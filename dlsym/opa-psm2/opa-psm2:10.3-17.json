{
    "matches": {
        "/tmp/vanessa/spack-stage/spack-stage-opa-psm2-10.3-17-ibdbtthddtktmwnuj3clawbqkq3b4xmw/spack-src/psm.c": "/*\n\n  This file is provided under a dual BSD/GPLv2 license.  When using or\n  redistributing this file, you may do so under either license.\n\n  GPL LICENSE SUMMARY\n\n  Copyright(c) 2016 Intel Corporation.\n\n  This program is free software; you can redistribute it and/or modify\n  it under the terms of version 2 of the GNU General Public License as\n  published by the Free Software Foundation.\n\n  This program is distributed in the hope that it will be useful, but\n  WITHOUT ANY WARRANTY; without even the implied warranty of\n  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n  General Public License for more details.\n\n  Contact Information:\n  Intel Corporation, www.intel.com\n\n  BSD LICENSE\n\n  Copyright(c) 2016 Intel Corporation.\n\n  Redistribution and use in source and binary forms, with or without\n  modification, are permitted provided that the following conditions\n  are met:\n\n    * Redistributions of source code must retain the above copyright\n      notice, this list of conditions and the following disclaimer.\n    * Redistributions in binary form must reproduce the above copyright\n      notice, this list of conditions and the following disclaimer in\n      the documentation and/or other materials provided with the\n      distribution.\n    * Neither the name of Intel Corporation nor the names of its\n      contributors may be used to endorse or promote products derived\n      from this software without specific prior written permission.\n\n  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n  \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n  LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n  A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n  OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n  SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n  LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n*/\n\n/* Copyright (c) 2003-2016 Intel Corporation. All rights reserved. */\n\n#include <dlfcn.h>\n#include \"psm_user.h\"\n#include \"opa_revision.h\"\n#include \"opa_udebug.h\"\n#include \"psm_mq_internal.h\"\n\nstatic int psmi_verno_major = PSM2_VERNO_MAJOR;\nstatic int psmi_verno_minor = PSM2_VERNO_MINOR;\nstatic int psmi_verno = PSMI_VERNO_MAKE(PSM2_VERNO_MAJOR, PSM2_VERNO_MINOR);\nstatic int psmi_verno_client_val;\nint psmi_epid_ver;\n\n#define PSMI_NOT_INITIALIZED    0\n#define PSMI_INITIALIZED        1\n#define PSMI_FINALIZED         -1\t/* Prevent the user from calling psm2_init\n\t\t\t\t\t * once psm_finalize has been called. */\nstatic int psmi_isinit = PSMI_NOT_INITIALIZED;\n\n/* Global lock used for endpoint creation and destroy\n * (in functions psm2_ep_open and psm2_ep_close) and also\n * for synchronization with recv_thread (so that recv_thread\n * will not work on an endpoint which is in a middle of closing). */\npsmi_lock_t psmi_creation_lock;\n\n#ifdef PSM_CUDA\nint is_cuda_enabled;\nint device_support_gpudirect;\nint cuda_runtime_version;\nint is_driver_gpudirect_enabled;\n#endif\n\n/*\n * Bit field that contains capability set.\n * Each bit represents different capability.\n * It is supposed to be filled with logical OR\n * on conditional compilation basis\n * along with future features/capabilities.\n * At the very beginning we start with Multi EPs.\n */\nuint64_t psm2_capabilities_bitset = PSM2_MULTI_EP_CAP;\n\nint psmi_verno_client()\n{\n\treturn psmi_verno_client_val;\n}\n\n/* This function is used to determine whether the current library build can\n * successfully communicate with another library that claims to be version\n * 'verno'.\n *\n * PSM 2.x is always ABI compatible, but this checks to see if two different\n * versions of the library can coexist.\n */\nint psmi_verno_isinteroperable(uint16_t verno)\n{\n\tif (PSMI_VERNO_GET_MAJOR(verno) != PSM2_VERNO_MAJOR)\n\t\treturn 0;\n\n\treturn 1;\n}\n\nint MOCKABLE(psmi_isinitialized)()\n{\n\treturn (psmi_isinit == PSMI_INITIALIZED);\n}\nMOCK_DEF_EPILOGUE(psmi_isinitialized);\n\n#ifdef PSM_CUDA\nint psmi_cuda_initialize()\n{\n\tpsm2_error_t err = PSM2_OK;\n\tint num_devices, dev;\n\tstruct cudaDeviceProp dev_prop;\n\tchar *dlerr;\n\n\tPSM2_LOG_MSG(\"entering\");\n\t_HFI_VDBG(\"Enabling CUDA support.\\n\");\n\n\tpsmi_cuda_lib = dlopen(\"libcuda.so\", RTLD_LAZY);\n\tpsmi_cudart_lib = dlopen(\"libcudart.so\", RTLD_LAZY);\n\tif (!psmi_cuda_lib || !psmi_cudart_lib) {\n\t\tdlerr = dlerror();\n\t\t_HFI_ERROR(\"Unable to open libcuda.so and libcudart.so.  Error %s\\n\",\n\t\t\t   dlerr ? dlerr : \"no dlerror()\");\n\t\tgoto fail;\n\t}\n\n\tpsmi_cudaRuntimeGetVersion = dlsym(psmi_cudart_lib, \"cudaRuntimeGetVersion\");\n\n\tif (!psmi_cudaRuntimeGetVersion) {\n\t\t_HFI_ERROR\n\t\t\t(\"Unable to resolve symbols in CUDA libraries.\\n\");\n\t\tgoto fail;\n\t}\n\n\tPSMI_CUDA_CALL(cudaRuntimeGetVersion, &cuda_runtime_version);\n\tif (cuda_runtime_version < 4010) {\n\t\t_HFI_ERROR(\"Please update CUDA runtime, required minimum version is 4.1 \\n\");\n\t\tgoto fail;\n\t}\n\n\n\tpsmi_cuCtxGetCurrent = dlsym(psmi_cuda_lib, \"cuCtxGetCurrent\");\n\tpsmi_cuCtxSetCurrent = dlsym(psmi_cuda_lib, \"cuCtxSetCurrent\");\n\tpsmi_cuPointerGetAttribute = dlsym(psmi_cuda_lib, \"cuPointerGetAttribute\");\n\tpsmi_cuPointerSetAttribute = dlsym(psmi_cuda_lib, \"cuPointerSetAttribute\");\n\n\tpsmi_cudaGetDeviceCount = dlsym(psmi_cudart_lib, \"cudaGetDeviceCount\");\n\tpsmi_cudaGetDeviceProperties = dlsym(psmi_cudart_lib, \"cudaGetDeviceProperties\");\n\tpsmi_cudaGetDevice = dlsym(psmi_cudart_lib, \"cudaGetDevice\");\n\tpsmi_cudaSetDevice = dlsym(psmi_cudart_lib, \"cudaSetDevice\");\n\tpsmi_cudaStreamCreate = dlsym(psmi_cudart_lib, \"cudaStreamCreate\");\n\tpsmi_cudaDeviceSynchronize = dlsym(psmi_cudart_lib, \"cudaDeviceSynchronize\");\n\tpsmi_cudaStreamSynchronize = dlsym(psmi_cudart_lib, \"cudaStreamSynchronize\");\n\tpsmi_cudaEventCreate = dlsym(psmi_cudart_lib, \"cudaEventCreate\");\n\tpsmi_cudaEventDestroy = dlsym(psmi_cudart_lib, \"cudaEventDestroy\");\n\tpsmi_cudaEventQuery = dlsym(psmi_cudart_lib, \"cudaEventQuery\");\n\tpsmi_cudaEventRecord = dlsym(psmi_cudart_lib, \"cudaEventRecord\");\n\tpsmi_cudaEventSynchronize = dlsym(psmi_cudart_lib, \"cudaEventSynchronize\");\n\tpsmi_cudaMalloc = dlsym(psmi_cudart_lib, \"cudaMalloc\");\n\tpsmi_cudaHostAlloc = dlsym(psmi_cudart_lib, \"cudaHostAlloc\");\n\tpsmi_cudaFreeHost = dlsym(psmi_cudart_lib, \"cudaFreeHost\");\n\tpsmi_cudaMemcpy = dlsym(psmi_cudart_lib, \"cudaMemcpy\");\n\tpsmi_cudaMemcpyAsync = dlsym(psmi_cudart_lib, \"cudaMemcpyAsync\");\n\n\tpsmi_cudaIpcGetMemHandle = dlsym(psmi_cudart_lib, \"cudaIpcGetMemHandle\");\n\tpsmi_cudaIpcOpenMemHandle = dlsym(psmi_cudart_lib, \"cudaIpcOpenMemHandle\");\n\tpsmi_cudaIpcCloseMemHandle = dlsym(psmi_cudart_lib, \"cudaIpcCloseMemHandle\");\n\n\tif (!psmi_cuCtxGetCurrent || !psmi_cuCtxSetCurrent ||\n\t    !psmi_cuPointerGetAttribute || !psmi_cuPointerSetAttribute ||\n\t    !psmi_cudaGetDeviceCount || !psmi_cudaGetDeviceProperties ||\n\t    !psmi_cudaGetDevice || !psmi_cudaSetDevice ||\n\t    !psmi_cudaStreamCreate ||\n\t    !psmi_cudaDeviceSynchronize || !psmi_cudaStreamSynchronize ||\n\t    !psmi_cudaEventCreate || !psmi_cudaEventDestroy ||\n\t    !psmi_cudaEventQuery || !psmi_cudaEventRecord ||\n\t    !psmi_cudaEventSynchronize ||\n\t    !psmi_cudaMalloc || !psmi_cudaHostAlloc || !psmi_cudaFreeHost ||\n\t    !psmi_cudaMemcpy || !psmi_cudaMemcpyAsync || !psmi_cudaIpcGetMemHandle ||\n\t    !psmi_cudaIpcOpenMemHandle || !psmi_cudaIpcCloseMemHandle) {\n\t\t_HFI_ERROR\n\t\t\t(\"Unable to resolve symbols in CUDA libraries.\\n\");\n\t\tgoto fail;\n\t}\n\n\tif (cuda_runtime_version > 7000) {\n\t\tpsmi_cudaStreamCreateWithFlags = dlsym(psmi_cudart_lib,\n\t\t\t\t\t\t       \"cudaStreamCreateWithFlags\");\n\t\tif (!psmi_cudaStreamCreateWithFlags) {\n\t\t\t_HFI_ERROR\n\t\t\t\t(\"Unable to resolve symbols in CUDA libraries.\\n\");\n\t\t\tgoto fail;\n\t\t}\n\t}\n\n\t/* Check if all devices support Unified Virtual Addressing. */\n\tPSMI_CUDA_CALL(cudaGetDeviceCount, &num_devices);\n\tfor (dev = 0; dev < num_devices; dev++) {\n\t\tPSMI_CUDA_CALL(cudaGetDeviceProperties, &dev_prop, dev);\n\t\tif (dev_prop.unifiedAddressing != 1) {\n\t\t\t_HFI_ERROR(\"CUDA device %d does not support Unified Virtual Addressing.\\n\", dev);\n\t\t\tgoto fail;\n\t\t}\n\t\t/* Only devices based on Kepler and\n\t\t * above can support GPU Direct.\n\t\t */\n\t\tif (dev_prop.major >= 3 && cuda_runtime_version >= 5000)\n\t\t\tdevice_support_gpudirect = 1;\n\t\telse {\n\t\t\tdevice_support_gpudirect = 0;\n\t\t\t_HFI_INFO(\"Device %d does not GPUDirect RDMA (Non-fatal error) \\n\", dev);\n\t\t}\n\t}\n\tPSM2_LOG_MSG(\"leaving\");\n\treturn err;\nfail:\n\terr = psmi_handle_error(PSMI_EP_NORETURN, PSM2_INTERNAL_ERR, \"Unable to initialize PSM2 CUDA support.\\n\");\n\treturn err;\n}\n#endif\n\npsm2_error_t __psm2_init(int *major, int *minor)\n{\n\tpsm2_error_t err = PSM2_OK;\n\tunion psmi_envvar_val env_tmask;\n\n\tpsmi_log_initialize();\n\n\tPSM2_LOG_MSG(\"entering\");\n#ifdef RDPMC_PERF_FRAMEWORK\n\tpsmi_rdpmc_perf_framework_init();\n#endif /* RDPMC_PERF_FRAMEWORK */\n\n\tGENERIC_PERF_INIT();\n\n\tif (psmi_isinit == PSMI_INITIALIZED)\n\t\tgoto update;\n\n\tif (psmi_isinit == PSMI_FINALIZED) {\n\t\terr = PSM2_IS_FINALIZED;\n\t\tgoto fail;\n\t}\n\n\tif (major == NULL || minor == NULL) {\n\t\terr = PSM2_PARAM_ERR;\n\t\tgoto fail;\n\t}\n\n\tpsmi_init_lock(&psmi_creation_lock);\n\n#ifdef PSM_DEBUG\n\tif (!getenv(\"PSM2_NO_WARN\"))\n\t\tfprintf(stderr,\n\t\t\t\"!!! WARNING !!! You are running an internal-only PSM *DEBUG* build.\\n\");\n#endif\n\n#ifdef PSM_PROFILE\n\tif (!getenv(\"PSM2_NO_WARN\"))\n\t\tfprintf(stderr,\n\t\t\t\"!!! WARNING !!! You are running an internal-only PSM *PROFILE* build.\\n\");\n#endif\n\n\t/* Make sure we complain if fault injection is enabled */\n\tif (getenv(\"PSM2_FI\") && !getenv(\"PSM2_NO_WARN\"))\n\t\tfprintf(stderr,\n\t\t\t\"!!! WARNING !!! You are running with fault injection enabled!\\n\");\n\n\t/* Make sure, as an internal check, that this version knows how to detect\n\t * compatibility with other library versions it may communicate with */\n\tif (psmi_verno_isinteroperable(psmi_verno) != 1) {\n\t\terr = psmi_handle_error(PSMI_EP_NORETURN, PSM2_INTERNAL_ERR,\n\t\t\t\t\t\"psmi_verno_isinteroperable() not updated for current version!\");\n\t\tgoto fail;\n\t}\n\n\t/* The only way to not support a client is if the major number doesn't\n\t * match */\n\tif (*major != PSM2_VERNO_MAJOR && *major != PSM2_VERNO_COMPAT_MAJOR) {\n\t\terr = psmi_handle_error(NULL, PSM2_INIT_BAD_API_VERSION,\n\t\t\t\t\t\"This library does not implement version %d.%d\",\n\t\t\t\t\t*major, *minor);\n\t\tgoto fail;\n\t}\n\n\t/* Make sure we don't keep track of a client that claims a higher version\n\t * number than we are */\n\tpsmi_verno_client_val =\n\t    min(PSMI_VERNO_MAKE(*major, *minor), psmi_verno);\n\n\t/* Check to see if we need to set Architecture flags to something\n\t * besides big core Xeons */\n\tcpuid_t id;\n\tpsmi_cpu_model = CPUID_MODEL_UNDEFINED;\n\n\t/* First check to ensure Genuine Intel */\n\tget_cpuid(0x0, 0, &id);\n\tif(id.ebx == CPUID_GENUINE_INTEL_EBX\n\t\t&& id.ecx == CPUID_GENUINE_INTEL_ECX\n\t\t&& id.edx == CPUID_GENUINE_INTEL_EDX)\n\t{\n\t\t/* Use cpuid with EAX=1 to get processor info */\n\t\tget_cpuid(0x1, 0, &id);\n\t\tpsmi_cpu_model = CPUID_GENUINE_INTEL;\n\t}\n\n\tif( (psmi_cpu_model == CPUID_GENUINE_INTEL) &&\n\t\t(id.eax & CPUID_FAMILY_MASK) == CPUID_FAMILY_XEON)\n\t{\n\t\tpsmi_cpu_model = ((id.eax & CPUID_MODEL_MASK) >> 4) |\n\t\t\t\t((id.eax & CPUID_EXMODEL_MASK) >> 12);\n\t}\n\n\tpsmi_isinit = PSMI_INITIALIZED;\n\t/* hfi_debug lives in libhfi.so */\n\tpsmi_getenv(\"PSM2_TRACEMASK\",\n\t\t    \"Mask flags for tracing\",\n\t\t    PSMI_ENVVAR_LEVEL_USER,\n\t\t    PSMI_ENVVAR_TYPE_ULONG_FLAGS,\n\t\t    (union psmi_envvar_val)hfi_debug, &env_tmask);\n\thfi_debug = (long)env_tmask.e_ulong;\n\n\t/* The \"real thing\" is done in hfi_proto.c as a constructor function, but\n\t * we getenv it here to report what we're doing with the setting */\n\t{\n\t\textern int __hfi_malloc_no_mmap;\n\t\tunion psmi_envvar_val env_mmap;\n\t\tchar *env = getenv(\"HFI_DISABLE_MMAP_MALLOC\");\n\t\tint broken = (env && *env && !__hfi_malloc_no_mmap);\n\t\tpsmi_getenv(\"HFI_DISABLE_MMAP_MALLOC\",\n\t\t\t    broken ? \"Skipping mmap disable for malloc()\" :\n\t\t\t    \"Disable mmap for malloc()\",\n\t\t\t    PSMI_ENVVAR_LEVEL_USER,\n\t\t\t    PSMI_ENVVAR_TYPE_YESNO,\n\t\t\t    (union psmi_envvar_val)0, &env_mmap);\n\t\tif (broken)\n\t\t\t_HFI_ERROR\n\t\t\t    (\"Couldn't successfully disable mmap in mallocs \"\n\t\t\t     \"with mallopt()\\n\");\n\t}\n\n\t{\n\t\tunion psmi_envvar_val env_epid_ver;\n\t\tpsmi_getenv(\"PSM2_ADDR_FMT\",\n\t\t\t\t\t\"Used to force PSM2 to use a particular version of EPID\",\n\t\t\t\t\tPSMI_ENVVAR_LEVEL_USER, PSMI_ENVVAR_TYPE_INT,\n\t\t\t\t\t(union psmi_envvar_val)PSMI_EPID_VERNO_DEFAULT, &env_epid_ver);\n\t\tpsmi_epid_ver = env_epid_ver.e_int;\n\t\tif (psmi_epid_ver > PSMI_MAX_EPID_VERNO_SUPPORTED) {\n\t\t\tpsmi_handle_error(PSMI_EP_NORETURN, PSM2_INTERNAL_ERR,\n\t\t\t\t\t  \" The max epid version supported in this version of PSM2 is %d \\n\"\n\t\t\t\t\t  \"Please upgrade PSM2 \\n\",\n\t\t\t\t\t  PSMI_MAX_EPID_VERNO_SUPPORTED);\n\t\t\tgoto fail;\n\t\t} else if (psmi_epid_ver < PSMI_MIN_EPID_VERNO_SUPPORTED) {\n\t\t\tpsmi_handle_error(PSMI_EP_NORETURN, PSM2_INTERNAL_ERR,\n\t\t\t\t\t  \" Invalid value provided through PSM2_ADDR_FMT \\n\");\n\t\t\tgoto fail;\n\t\t}\n\t}\n\n#ifdef PSM_CUDA\n\tunion psmi_envvar_val env_enable_cuda;\n\tpsmi_getenv(\"PSM2_CUDA\",\n\t\t    \"Enable (set envvar to 1) for cuda support in PSM (Disabled by default)\",\n\t\t    PSMI_ENVVAR_LEVEL_USER, PSMI_ENVVAR_TYPE_INT,\n\t\t    (union psmi_envvar_val)0, &env_enable_cuda);\n\tis_cuda_enabled = env_enable_cuda.e_int;\n#endif\n\n\tif (getenv(\"PSM2_IDENTIFY\")) {\n                Dl_info info_psm;\n\t\tchar ofed_delta[100] = \"\";\n\t\tstrcat(strcat(ofed_delta,\" built for OFED DELTA \"),psmi_hfi_IFS_version);\n                printf(\"%s %s PSM2 v%d.%d%s\\n\"\n\t\t       \"%s %s location %s\\n\"\n\t\t       \"%s %s build date %s\\n\"\n\t\t       \"%s %s src checksum %s\\n\"\n                       \"%s %s git checksum %s\\n\"\n                       \"%s %s built against driver interface v%d.%d\\n\",\n\t\t\t  hfi_get_mylabel(), hfi_ident_tag,\n\t\t\t\t\t     PSM2_VERNO_MAJOR,PSM2_VERNO_MINOR,\n\t\t\t\t\t     (strcmp(psmi_hfi_IFS_version,\"\") != 0) ? ofed_delta\n#ifdef PSM_CUDA\n\t\t\t\t\t\t: \"-cuda\",\n#else\n\t\t\t\t\t\t: \"\",\n#endif\n                          hfi_get_mylabel(), hfi_ident_tag, dladdr(psm2_init, &info_psm) ?\n\t\t\t\t\t     info_psm.dli_fname : \"libpsm2 not available\",\n                          hfi_get_mylabel(), hfi_ident_tag, psmi_hfi_build_timestamp,\n                          hfi_get_mylabel(), hfi_ident_tag, psmi_hfi_sources_checksum,\n\t\t\t  hfi_get_mylabel(), hfi_ident_tag,\n\t\t\t\t\t     (strcmp(psmi_hfi_git_checksum,\"\") != 0) ?\n\t\t\t\t\t     psmi_hfi_git_checksum : \"<not available>\",\n\t\t\t  hfi_get_mylabel(), hfi_ident_tag, HFI1_USER_SWMAJOR, HFI1_USER_SWMINOR);\n\t}\n\n\tif (getenv(\"PSM2_DIAGS\")) {\n\t\t_HFI_INFO(\"Running diags...\\n\");\n\t\tpsmi_diags();\n\t}\n\n\tpsmi_multi_ep_init();\n\n\tpsmi_faultinj_init();\n\n\tpsmi_epid_init();\n\n#ifdef PSM_CUDA\n\tif (PSMI_IS_CUDA_ENABLED) {\n\t\terr = psmi_cuda_initialize();\n\t\tif (err != PSM2_OK)\n\t\t\tgoto fail;\n\t}\n#endif\n\nupdate:\n\t*major = (int)psmi_verno_major;\n\t*minor = (int)psmi_verno_minor;\nfail:\n\tPSM2_LOG_MSG(\"leaving\");\n\treturn err;\n}\nPSMI_API_DECL(psm2_init)\n\n\nuint64_t __psm2_get_capability_mask(uint64_t req_cap_mask)\n{\n\treturn (psm2_capabilities_bitset & req_cap_mask);\n}\nPSMI_API_DECL(psm2_get_capability_mask)\n\n\npsm2_error_t __psm2_finalize(void)\n{\n\tstruct psmi_eptab_iterator itor;\n\tchar *hostname;\n\tpsm2_ep_t ep;\n\n\tPSM2_LOG_MSG(\"entering\");\n\n\tPSMI_ERR_UNLESS_INITIALIZED(NULL);\n\n\tGENERIC_PERF_DUMP(stderr);\n\tep = psmi_opened_endpoint;\n\twhile (ep != NULL) {\n\t\tpsmi_opened_endpoint = ep->user_ep_next;\n\t\tpsm2_ep_close(ep, PSM2_EP_CLOSE_GRACEFUL,\n\t\t\t     2 * PSMI_MIN_EP_CLOSE_TIMEOUT);\n\t\tep = psmi_opened_endpoint;\n\t}\n\n\tpsmi_epid_fini();\n\n\tpsmi_faultinj_fini();\n\n\t/* De-allocate memory for any allocated space to store hostnames */\n\tpsmi_epid_itor_init(&itor, PSMI_EP_HOSTNAME);\n\twhile ((hostname = psmi_epid_itor_next(&itor)))\n\t\tpsmi_free(hostname);\n\tpsmi_epid_itor_fini(&itor);\n\n\tpsmi_isinit = PSMI_FINALIZED;\n\tPSM2_LOG_MSG(\"leaving\");\n\tpsmi_log_fini();\n\treturn PSM2_OK;\n}\nPSMI_API_DECL(psm2_finalize)\n\n/*\n * Function exposed in >= 1.05\n */\npsm2_error_t\n__psm2_map_nid_hostname(int num, const uint64_t *nids, const char **hostnames)\n{\n\tint i;\n\tpsm2_error_t err = PSM2_OK;\n\n\tPSM2_LOG_MSG(\"entering\");\n\n\tPSMI_ERR_UNLESS_INITIALIZED(NULL);\n\n\tif (nids == NULL || hostnames == NULL) {\n\t\terr = PSM2_PARAM_ERR;\n\t\tgoto fail;\n\t}\n\n\tfor (i = 0; i < num; i++) {\n\t\tif ((err = psmi_epid_set_hostname(nids[i], hostnames[i], 1)))\n\t\t\tbreak;\n\t}\n\nfail:\n\tPSM2_LOG_MSG(\"leaving\");\n\treturn err;\n}\nPSMI_API_DECL(psm2_map_nid_hostname)\n\nvoid __psm2_epaddr_setlabel(psm2_epaddr_t epaddr, char const *epaddr_label)\n{\n\tPSM2_LOG_MSG(\"entering\");\n\tPSM2_LOG_MSG(\"leaving\");\n\treturn;\t\t\t/* ignore this function */\n}\nPSMI_API_DECL(psm2_epaddr_setlabel)\n\nvoid __psm2_epaddr_setctxt(psm2_epaddr_t epaddr, void *ctxt)\n{\n\n\t/* Eventually deprecate this API to use set/get opt as this is unsafe. */\n\tPSM2_LOG_MSG(\"entering\");\n\tpsm2_setopt(PSM2_COMPONENT_CORE, (const void *)epaddr,\n\t\t   PSM2_CORE_OPT_EP_CTXT, (const void *)ctxt, sizeof(void *));\n\tPSM2_LOG_MSG(\"leaving\");\n}\nPSMI_API_DECL(psm2_epaddr_setctxt)\n\nvoid *__psm2_epaddr_getctxt(psm2_epaddr_t epaddr)\n{\n\tpsm2_error_t err;\n\tuint64_t optlen = sizeof(void *);\n\tvoid *result = NULL;\n\n\tPSM2_LOG_MSG(\"entering\");\n\t/* Eventually deprecate this API to use set/get opt as this is unsafe. */\n\terr = psm2_getopt(PSM2_COMPONENT_CORE, (const void *)epaddr,\n\t\t\t PSM2_CORE_OPT_EP_CTXT, (void *)&result, &optlen);\n\n\tPSM2_LOG_MSG(\"leaving\");\n\n\tif (err == PSM2_OK)\n\t\treturn result;\n\telse\n\t\treturn NULL;\n}\nPSMI_API_DECL(psm2_epaddr_getctxt)\n\npsm2_error_t\n__psm2_setopt(psm2_component_t component, const void *component_obj,\n\t     int optname, const void *optval, uint64_t optlen)\n{\n\tpsm2_error_t rv;\n\tPSM2_LOG_MSG(\"entering\");\n\tswitch (component) {\n\tcase PSM2_COMPONENT_CORE:\n\t\trv = psmi_core_setopt(component_obj, optname, optval, optlen);\n\t\tPSM2_LOG_MSG(\"leaving\");\n\t\treturn rv;\n\t\tbreak;\n\tcase PSM2_COMPONENT_MQ:\n\t\t/* Use the deprecated MQ set/get opt for now which does not use optlen */\n\t\trv = psm2_mq_setopt((psm2_mq_t) component_obj, optname, optval);\n\t\tPSM2_LOG_MSG(\"leaving\");\n\t\treturn rv;\n\t\tbreak;\n\tcase PSM2_COMPONENT_AM:\n\t\t/* Hand off to active messages */\n\t\trv = psmi_am_setopt(component_obj, optname, optval, optlen);\n\t\tPSM2_LOG_MSG(\"leaving\");\n\t\treturn rv;\n\t\tbreak;\n\tcase PSM2_COMPONENT_IB:\n\t\t/* Hand off to IPS ptl to set option */\n\t\trv = psmi_ptl_ips.setopt(component_obj, optname, optval,\n\t\t\t\t\t   optlen);\n\t\tPSM2_LOG_MSG(\"leaving\");\n\t\treturn rv;\n\t\tbreak;\n\t}\n\n\t/* Unrecognized/unknown component */\n\trv = psmi_handle_error(NULL, PSM2_PARAM_ERR, \"Unknown component %u\",\n\t\t\t\t component);\n\tPSM2_LOG_MSG(\"leaving\");\n\treturn rv;\n}\nPSMI_API_DECL(psm2_setopt);\n\npsm2_error_t\n__psm2_getopt(psm2_component_t component, const void *component_obj,\n\t     int optname, void *optval, uint64_t *optlen)\n{\n\tpsm2_error_t rv;\n\n\tPSM2_LOG_MSG(\"entering\");\n\tswitch (component) {\n\tcase PSM2_COMPONENT_CORE:\n\t\trv = psmi_core_getopt(component_obj, optname, optval, optlen);\n\t\tPSM2_LOG_MSG(\"leaving\");\n\t\treturn rv;\n\t\tbreak;\n\tcase PSM2_COMPONENT_MQ:\n\t\t/* Use the deprecated MQ set/get opt for now which does not use optlen */\n\t\trv = psm2_mq_getopt((psm2_mq_t) component_obj, optname, optval);\n\t\tPSM2_LOG_MSG(\"leaving\");\n\t\treturn rv;\n\t\tbreak;\n\tcase PSM2_COMPONENT_AM:\n\t\t/* Hand off to active messages */\n\t\trv = psmi_am_getopt(component_obj, optname, optval, optlen);\n\t\tPSM2_LOG_MSG(\"leaving\");\n\t\treturn rv;\n\t\tbreak;\n\tcase PSM2_COMPONENT_IB:\n\t\t/* Hand off to IPS ptl to set option */\n\t\trv = psmi_ptl_ips.getopt(component_obj, optname, optval,\n\t\t\t\t\t   optlen);\n\t\tPSM2_LOG_MSG(\"leaving\");\n\t\treturn rv;\n\t\tbreak;\n\t}\n\n\t/* Unrecognized/unknown component */\n\trv = psmi_handle_error(NULL, PSM2_PARAM_ERR, \"Unknown component %u\",\n\t\t\t\t component);\n\tPSM2_LOG_MSG(\"leaving\");\n\treturn rv;\n}\nPSMI_API_DECL(psm2_getopt);\n\npsm2_error_t __psmi_poll_noop(ptl_t *ptl, int replyonly)\n{\n\tPSM2_LOG_MSG(\"entering\");\n\tPSM2_LOG_MSG(\"leaving\");\n\treturn PSM2_OK_NO_PROGRESS;\n}\nPSMI_API_DECL(psmi_poll_noop)\n\npsm2_error_t __psm2_poll(psm2_ep_t ep)\n{\n\tpsm2_error_t err1 = PSM2_OK, err2 = PSM2_OK;\n\tpsm2_ep_t tmp;\n\n\tPSM2_LOG_MSG(\"entering\");\n\n\tPSMI_ASSERT_INITIALIZED();\n\n\tPSMI_LOCK(ep->mq->progress_lock);\n\n\ttmp = ep;\n\tdo {\n\t\terr1 = ep->ptl_amsh.ep_poll(ep->ptl_amsh.ptl, 0);\t/* poll reqs & reps */\n\t\tif (err1 > PSM2_OK_NO_PROGRESS) {\t/* some error unrelated to polling */\n\t\t\tPSMI_UNLOCK(ep->mq->progress_lock);\n\t\t\tPSM2_LOG_MSG(\"leaving\");\n\t\t\treturn err1;\n\t\t}\n\n\t\terr2 = ep->ptl_ips.ep_poll(ep->ptl_ips.ptl, 0);\t/* get into ips_do_work */\n\t\tif (err2 > PSM2_OK_NO_PROGRESS) {\t/* some error unrelated to polling */\n\t\t\tPSMI_UNLOCK(ep->mq->progress_lock);\n\t\t\tPSM2_LOG_MSG(\"leaving\");\n\t\t\treturn err2;\n\t\t}\n\t\tep = ep->mctxt_next;\n\t} while (ep != tmp);\n\n\t/* This is valid because..\n\t * PSM2_OK & PSM2_OK_NO_PROGRESS => PSM2_OK\n\t * PSM2_OK & PSM2_OK => PSM2_OK\n\t * PSM2_OK_NO_PROGRESS & PSM2_OK => PSM2_OK\n\t * PSM2_OK_NO_PROGRESS & PSM2_OK_NO_PROGRESS => PSM2_OK_NO_PROGRESS */\n\tPSMI_UNLOCK(ep->mq->progress_lock);\n\tPSM2_LOG_MSG(\"leaving\");\n\treturn (err1 & err2);\n}\nPSMI_API_DECL(psm2_poll)\n\npsm2_error_t __psmi_poll_internal(psm2_ep_t ep, int poll_amsh)\n{\n\tpsm2_error_t err1 = PSM2_OK_NO_PROGRESS;\n\tpsm2_error_t err2;\n\tpsm2_ep_t tmp;\n\n\tPSM2_LOG_MSG(\"entering\");\n\tPSMI_LOCK_ASSERT(ep->mq->progress_lock);\n\n\ttmp = ep;\n\tdo {\n\t\tif (poll_amsh) {\n\t\t\terr1 = ep->ptl_amsh.ep_poll(ep->ptl_amsh.ptl, 0);\t/* poll reqs & reps */\n\t\t\tif (err1 > PSM2_OK_NO_PROGRESS) { /* some error unrelated to polling */\n\t\t\t\tPSM2_LOG_MSG(\"leaving\");\n\t\t\t\treturn err1;\n\t\t\t}\n\t\t}\n\n\t\terr2 = ep->ptl_ips.ep_poll(ep->ptl_ips.ptl, 0);\t/* get into ips_do_work */\n\t\tif (err2 > PSM2_OK_NO_PROGRESS) { /* some error unrelated to polling */\n\t\t\tPSM2_LOG_MSG(\"leaving\");\n\t\t\treturn err2;\n\t\t}\n\n\t\tep = ep->mctxt_next;\n\t} while (ep != tmp);\n\tPSM2_LOG_MSG(\"leaving\");\n\treturn (err1 & err2);\n}\nPSMI_API_DECL(psmi_poll_internal)\n#ifdef PSM_PROFILE\n/* These functions each have weak symbols */\nvoid psmi_profile_block()\n{\n\t;\t\t\t/* empty for profiler */\n}\n\nvoid psmi_profile_unblock()\n{\n\t;\t\t\t/* empty for profiler */\n}\n\nvoid psmi_profile_reblock(int did_no_progress)\n{\n\t;\t\t\t/* empty for profiler */\n}\n#endif\n",
        "/tmp/vanessa/spack-stage/spack-stage-opa-psm2-10.3-17-ibdbtthddtktmwnuj3clawbqkq3b4xmw/spack-src/ptl_ips/ips_opp_path_rec.c": "/*\n\n  This file is provided under a dual BSD/GPLv2 license.  When using or\n  redistributing this file, you may do so under either license.\n\n  GPL LICENSE SUMMARY\n\n  Copyright(c) 2015 Intel Corporation.\n\n  This program is free software; you can redistribute it and/or modify\n  it under the terms of version 2 of the GNU General Public License as\n  published by the Free Software Foundation.\n\n  This program is distributed in the hope that it will be useful, but\n  WITHOUT ANY WARRANTY; without even the implied warranty of\n  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n  General Public License for more details.\n\n  Contact Information:\n  Intel Corporation, www.intel.com\n\n  BSD LICENSE\n\n  Copyright(c) 2015 Intel Corporation.\n\n  Redistribution and use in source and binary forms, with or without\n  modification, are permitted provided that the following conditions\n  are met:\n\n    * Redistributions of source code must retain the above copyright\n      notice, this list of conditions and the following disclaimer.\n    * Redistributions in binary form must reproduce the above copyright\n      notice, this list of conditions and the following disclaimer in\n      the documentation and/or other materials provided with the\n      distribution.\n    * Neither the name of Intel Corporation nor the names of its\n      contributors may be used to endorse or promote products derived\n      from this software without specific prior written permission.\n\n  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n  \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n  LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n  A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n  OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n  SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n  LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n*/\n\n/* Copyright (c) 2003-2014 Intel Corporation. All rights reserved. */\n\n#include \"psm_user.h\"\n#include \"ipserror.h\"\n#include \"ips_proto.h\"\n#include \"ips_proto_internal.h\"\n#include <dlfcn.h>\n\n#define DF_OPP_LIBRARY \"libopasadb.so.1.0.0\"\n#define DATA_VFABRIC_OFFSET 8\n\n/* SLID and DLID are in network byte order */\nstatic psm2_error_t\nips_opp_get_path_rec(ips_path_type_t type, struct ips_proto *proto,\n\t\t     uint16_t slid, uint16_t dlid, uint16_t desthfi_type,\n\t\t     ips_path_rec_t **ppath_rec)\n{\n\tpsm2_error_t err = PSM2_OK;\n\tibta_path_rec_t query, opp_response;\n#ifdef _HFI_DEBUGGING\n\tint opp_response_set = 0;\n#endif\n\tips_path_rec_t *path_rec;\n\tint opp_err;\n\tENTRY elid, *epath = NULL;\n\tchar eplid[128];\n\tuint64_t timeout_ack_ms;\n\n\t/* Query path record query cache first */\n\tbzero(&query, sizeof(query));\n\tbzero(eplid, sizeof(eplid));\n\n\t/* Bulk service ID is control service id + 1 */\n\tswitch (type) {\n\tcase IPS_PATH_LOW_PRIORITY:\n\t\tquery.service_id =\n\t\t    __cpu_to_be64(proto->ep->service_id + DATA_VFABRIC_OFFSET);\n\t\tbreak;\n\tcase IPS_PATH_NORMAL_PRIORITY:\n\tcase IPS_PATH_HIGH_PRIORITY:\n\tdefault:\n\t\tquery.service_id = __cpu_to_be64(proto->ep->service_id);\n\t}\n\n\tquery.slid = slid;\n\tquery.dlid = dlid;\n\n\tsnprintf(eplid, sizeof(eplid), \"%s_%x_%x\",\n\t\t (type == IPS_PATH_LOW_PRIORITY) ? \"LOW\" : \"HIGH\",\n\t\t query.slid, query.dlid);\n\telid.key = eplid;\n\thsearch_r(elid, FIND, &epath, &proto->ips_path_rec_hash);\n\n\tif (!epath) {\t\t/* Unable to find path record in cache */\n\t\telid.key =\n\t\t    psmi_calloc(proto->ep, UNDEFINED, 1, strlen(eplid) + 1);\n\t\tpath_rec = (ips_path_rec_t *)\n\t\t    psmi_calloc(proto->ep, UNDEFINED, 1,\n\t\t\t\tsizeof(ips_path_rec_t));\n\t\tif (!elid.key || !path_rec) {\n\t\t\tif (elid.key)\n\t\t\t\tpsmi_free(elid.key);\n\t\t\tif (path_rec)\n\t\t\t\tpsmi_free(path_rec);\n\t\t\terr = PSM2_NO_MEMORY;\n\t\t\tgoto fail;\n\t\t}\n\n\t\t/* Get path record between local LID and remote */\n\t\topp_err =\n\t\t    proto->opp_fn.op_path_get_path_by_rec(proto->opp_ctxt,\n\t\t\t\t\t\t\t  &query,\n\t\t\t\t\t\t\t  &opp_response);\n\t\tif (opp_err) {\n\t\t\tpsmi_free(path_rec);\n\t\t\tpsmi_free(elid.key);\n\t\t\terr = PSM2_EPID_PATH_RESOLUTION;\n\t\t\tgoto fail;\n\t\t}\n#ifdef _HFI_DEBUGGING\n\t\topp_response_set = 1;\n#endif\n\t\t/* Create path record */\n\t\tpath_rec->pr_slid = opp_response.slid;\n\t\tpath_rec->pr_dlid = opp_response.dlid;\n\t\tpath_rec->pr_mtu =\n\t\t    min(opa_mtu_enum_to_int(opp_response.mtu & 0x3f),\n\t\t\tproto->epinfo.ep_mtu);\n\t\tpath_rec->pr_pkey = ntohs(opp_response.pkey);\n\t\tpath_rec->pr_sl = ntohs(opp_response.qos_class_sl);\n\t\tpath_rec->pr_static_ipd =\n\t\t    proto->ips_ipd_delay[opp_response.rate & 0x3f];\n\n\t\t/* Setup CCA parameters for path */\n\t\tif (path_rec->pr_sl > PSMI_SL_MAX) {\n\t\t\tpsmi_free(path_rec);\n\t\t\tpsmi_free(elid.key);\n\t\t\terr = PSM2_INTERNAL_ERR;\n\t\t\tgoto fail;\n\t\t}\n\t\tif (!(proto->ccti_ctrlmap & (1 << path_rec->pr_sl))) {\n\t\t\t_HFI_CCADBG(\"No CCA for sl %d, disable CCA\\n\",\n\t\t\t\t    path_rec->pr_sl);\n\t\t\tproto->flags &= ~IPS_PROTO_FLAG_CCA;\n\t\t\tproto->flags &= ~IPS_PROTO_FLAG_CCA_PRESCAN;\n\t\t}\n\t\tif (!(proto->ep->context.runtime_flags &\n\t\t\t\t\tHFI1_CAP_STATIC_RATE_CTRL)) {\n\t\t\t_HFI_CCADBG(\"No Static-Rate-Control, disable CCA\\n\");\n\t\t\tproto->flags &= ~IPS_PROTO_FLAG_CCA;\n\t\t\tproto->flags &= ~IPS_PROTO_FLAG_CCA_PRESCAN;\n\t\t}\n\n\t\tpath_rec->proto = proto;\n\t\tpath_rec->pr_ccti = proto->cace[path_rec->pr_sl].ccti_min;\n\t\tpath_rec->pr_timer_cca = NULL;\n\n\t\t/* Determine active IPD for path. Is max of static rate and CCT table */\n\t\tif (!(proto->flags & IPS_PROTO_FLAG_CCA)) {\n\t\t\tpath_rec->pr_active_ipd = 0;\n\t\t\tpath_rec->pr_cca_divisor = 0;\n\t\t} else if ((path_rec->pr_static_ipd) &&\n\t\t    ((path_rec->pr_static_ipd + 1) >\n\t\t     (proto->cct[path_rec->pr_ccti] & CCA_IPD_MASK))) {\n\t\t\tpath_rec->pr_active_ipd = path_rec->pr_static_ipd + 1;\n\t\t\tpath_rec->pr_cca_divisor = 0;\t/*Static rate has no CCA divisor */\n\t\t} else {\n\t\t\t/* Pick it from the CCT table */\n\t\t\tpath_rec->pr_active_ipd =\n\t\t\t    proto->cct[path_rec->pr_ccti] & CCA_IPD_MASK;\n\t\t\tpath_rec->pr_cca_divisor =\n\t\t\t    proto->cct[path_rec->pr_ccti] >> CCA_DIVISOR_SHIFT;\n\t\t}\n\n\t\t/* Compute max timeout based on pkt life time for path */\n\t\ttimeout_ack_ms =\n\t\t    ((4096UL * (1UL << (opp_response.pkt_life & 0x3f))) /\n\t\t     1000000UL);\n\t\ttimeout_ack_ms =\n\t\t    ms_2_cycles(IPS_PROTO_ERRCHK_MS_MIN_DEFAULT +\n\t\t\t\ttimeout_ack_ms);\n\t\tif (proto->epinfo.ep_timeout_ack_max < timeout_ack_ms)\n\t\t\tproto->epinfo.ep_timeout_ack_max = timeout_ack_ms;\n\n\t\t/* Add path record into cache */\n\t\tstrcpy(elid.key, eplid);\n\t\telid.data = (void *)path_rec;\n\t\thsearch_r(elid, ENTER, &epath, &proto->ips_path_rec_hash);\n\t} else\t\t\t/* Path record found in cache */\n\t\tpath_rec = (ips_path_rec_t *) epath->data;\n\n#ifdef _HFI_DEBUGGING\n\t/* Dump path record stats */\n\t_HFI_PRDBG(\"Path Record ServiceID: %\" PRIx64 \" %x -----> %x\\n\",\n\t\t   (uint64_t) __be64_to_cpu(query.service_id),\n\t\t   __be16_to_cpu(slid), __be16_to_cpu(dlid));\n\tif (opp_response_set)\n\t{\n\t\t_HFI_PRDBG(\"MTU: %x, %x\\n\", (opp_response.mtu & 0x3f),\n\t\t\t   path_rec->pr_mtu);\n\t\t_HFI_PRDBG(\"PKEY: 0x%04x\\n\", ntohs(opp_response.pkey));\n\t\t_HFI_PRDBG(\"SL: 0x%04x\\n\", ntohs(opp_response.qos_class_sl));\n\t\t_HFI_PRDBG(\"Rate: %x, IPD: %x\\n\", (opp_response.rate & 0x3f),\n\t\t\t   path_rec->pr_static_ipd);\n\t}\n\t_HFI_PRDBG(\"Timeout Init.: 0x%\" PRIx64 \" Max: 0x%\" PRIx64 \"\\n\",\n\t\t   proto->epinfo.ep_timeout_ack,\n\t\t   proto->epinfo.ep_timeout_ack_max);\n#endif\n\t/* Return the IPS path record */\n\t*ppath_rec = path_rec;\n\nfail:\n\treturn err;\n}\n\nstatic psm2_error_t\nips_opp_path_rec(struct ips_proto *proto,\n\t\t uint16_t slid, uint16_t dlid, uint16_t desthfi_type,\n\t\t unsigned long timeout, ips_path_grp_t **ppathgrp)\n{\n\tpsm2_error_t err = PSM2_OK;\n\tuint16_t pidx, cpath, num_path = (1 << proto->epinfo.ep_lmc);\n\tips_path_type_t path_type = IPS_PATH_NORMAL_PRIORITY;\n\tips_path_rec_t *path;\n\tips_path_grp_t *pathgrp;\n\tuint16_t path_slid, path_dlid;\n\tENTRY elid, *epath = NULL;\n\tchar eplid[128];\n\n\t/*\n\t * High Priority Path\n\t * ------------------\n\t *\n\t * Uses the \"base\" Service ID. For now there exists only 1 high priority\n\t * path between nodes even for non zero LMC fabrics.\n\t *\n\t * Normal/Low Priority Paths\n\t * -------------------------\n\t *\n\t * Currently these paths are the same i.e. they are queried for the same\n\t * Service ID/vFabric which is the Base Service ID for High Priority + 1.\n\t *\n\t * Use case Scenarios\n\t * ------------------\n\t *\n\t * Since with vFabrics we have the capability to define different QoS\n\t * parameters per vFabric it is envisioned that the IPS_PATH_HIGH_PRIORITY is\n\t * setup in a separate vFabric for high priority traffic. The NORMAL paths\n\t * are setup in a separate vFabric optimized for high bandwidth. This allows\n\t * us to potentially have control traffic (RTS, CTS etc.) not be bottlenecked\n\t * by bulk transfer data. All control messages (ACKs,NAKs, TID_GRANT etc.)\n\t * also use the high priority control vFabric.\n\t *\n\t * NOTE: In order to distinguish between the different vFabrics the user\n\t * specifies the service ID to use via mpirun (or environment variable).\n\t * This is the service ID for the high priority control traffic. The bulk\n\t * data vFabric is identified by service ID + 1. So for each MPI application\n\t * one should specify two service IDs for the high priority and bulk data.\n\t * Both these service IDs can be placed in the same vFabric which can be\n\t * configured for high priority or bandwidth traffic giving us the default\n\t * behavior upto Infinhfi 2.5 release.\n\t *\n\t * NOTE: All of the above would have really helped if the S20 silicon could\n\t * correctly support IBTA QoS features. Due to S20 design we can only have\n\t * high priority VLarb table (low priority VLarb table results in round\n\t * robin arbitration ignoring the weights!). But if this is fixed in a\n\t * subsequent chip respin then this may potentially help our scalability\n\t * on large fabrics.\n\t *\n\t * Mesh/Torus and DOR routed networks\n\t * ----------------------------------\n\t *\n\t * In a mesh/torus fabric we always have a non zero LMC (at least 1 can be\n\t * more). We would like to take advantage of dispersive routing on these\n\t * fabrics as well to obtain better \"worst case/congested\" bandwidth. For\n\t * these networks currently the base LIDs are used for UPDN routing which\n\t * is suboptimal on these networks. Higher order LIDs (+1 .. +N) use DOR\n\t * routing (Dimension Ordered Routing) to avoid deadlocks and provide\n\t * higher performance. If a fabric is disrupted then only the base UPDN\n\t * routing is available. PSM should continue to operate in this environment\n\t * albeit with degraded performance. In disrupted fabric the OPP path\n\t * record queries may fail for some DOR routed LIDs i.e. no path exists\n\t * PSM should hence ignore path record failures as they indicate a disrupted\n\t * fabric and only use valid paths that are returned from the replica. This\n\t * will degenerate to only using the UPDN paths on disrupted fabrics and DOR\n\t * routes only for fully configured fabrics. Note: For a clean fabric the\n\t * base LIDs that are configured for UPDN route will not exist in the replica\n\t * as DOR routes are preferred. Hence we will only dispersively route across\n\t * the DOR routes only using the UPDN route for disrupted fabrics.\n\t *\n\t * AS LONG AS ONE PATH EXISTS (for each of the priorities) COMMUNICATION CAN\n\t * TAKE PLACE.\n\t */\n\n\t/* Check if this path grp is already in hash table */\n\tsnprintf(eplid, sizeof(eplid), \"%x_%x\", slid, dlid);\n\telid.key = eplid;\n\thsearch_r(elid, FIND, &epath, &proto->ips_path_grp_hash);\n\n\tif (epath) {\t\t/* Find path group in cache */\n\t\t*ppathgrp = (ips_path_grp_t *) epath->data;\n\t\treturn err;\n\t}\n\n\t/* If base lids are only used then reset num_path to 1 */\n\tif (proto->flags & IPS_PROTO_FLAG_PPOLICY_STATIC_BASE)\n\t\tnum_path = 1;\n\n\t/* Allocate a new pathgroup */\n\telid.key = psmi_calloc(proto->ep, UNDEFINED, 1, strlen(eplid) + 1);\n\tpathgrp = (ips_path_grp_t *)\n\t    psmi_calloc(proto->ep, UNDEFINED, 1, sizeof(ips_path_grp_t) +\n\t\t\tnum_path * IPS_PATH_MAX_PRIORITY *\n\t\t\tsizeof(ips_path_rec_t *));\n\tif (!elid.key || !pathgrp) {\n\t\tif (elid.key)\n\t\t\tpsmi_free(elid.key);\n\t\tif (pathgrp)\n\t\t\tpsmi_free(pathgrp);\n\t\terr = PSM2_NO_MEMORY;\n\t\tgoto fail;\n\t}\n\n\t/* dlid is the peer base lid */\n\tpathgrp->pg_base_lid = __be16_to_cpu(dlid);\n\n\tpathgrp->pg_num_paths[IPS_PATH_HIGH_PRIORITY] =\n\t    pathgrp->pg_num_paths[IPS_PATH_NORMAL_PRIORITY] =\n\t    pathgrp->pg_num_paths[IPS_PATH_LOW_PRIORITY] = 0;\n\n\t/* For now there is always only one high priority path between nodes. */\n\tfor (pidx = 0, cpath = 0; pidx < num_path && cpath == 0; pidx++) {\n\t\tpath_slid = __cpu_to_be16(__be16_to_cpu(slid) + pidx);\n\t\tpath_dlid = __cpu_to_be16(__be16_to_cpu(dlid) + pidx);\n\n\t\terr = ips_opp_get_path_rec(IPS_PATH_HIGH_PRIORITY, proto,\n\t\t\t\t\t   path_slid, path_dlid,\n\t\t\t\t\t   desthfi_type, &path);\n\n\t\tif (err == PSM2_OK) {\t/* Valid high priority path found */\n\t\t\t/* Resolved high priority path successfully */\n\t\t\tpathgrp->pg_num_paths[IPS_PATH_HIGH_PRIORITY]++;\n\t\t\tpathgrp->pg_path[cpath][IPS_PATH_HIGH_PRIORITY] = path;\n\n\t\t\t/* Increment current path index */\n\t\t\tcpath++;\n\t\t}\n\t}\n\n\t/* Make sure we have atleast 1 high priority path */\n\tif (pathgrp->pg_num_paths[IPS_PATH_HIGH_PRIORITY] == 0) {\n\t\tpsmi_free(elid.key);\n\t\tpsmi_free(pathgrp);\n\t\terr = psmi_handle_error(NULL, PSM2_EPID_PATH_RESOLUTION,\n\t\t\t\t\t\"OFED Plus path lookup failed. Unable to resolve high priority network path for LID 0x%x <---> 0x%x. Is the SM running or service ID %\"\n\t\t\t\t\tPRIx64 \" defined?\", ntohs(slid),\n\t\t\t\t\tntohs(dlid),\n\t\t\t\t\t(uint64_t) proto->ep->service_id);\n\t\tgoto fail;\n\t}\n\n\t/* Once we have the high-priority path, set the partition key */\n\tif (hfi_set_pkey(proto->ep->context.ctrl,\n\t\t\t (uint16_t) pathgrp->pg_path[0][IPS_PATH_HIGH_PRIORITY]->pr_pkey) != 0) {\n\t\terr = psmi_handle_error(proto->ep, PSM2_EP_DEVICE_FAILURE,\n\t\t\t\t\t\"Couldn't set device pkey 0x%x: %s\",\n\t\t\t\t\t(int)pathgrp->pg_path[0][IPS_PATH_HIGH_PRIORITY]->pr_pkey,\n\t\t\t\t\tstrerror(errno));\n\t\tpsmi_free(elid.key);\n\t\tpsmi_free(pathgrp);\n\t\tgoto fail;\n\t}\n\n\n\t/* Next setup the bulk paths. If the subnet administrator has misconfigured\n\t * or rather not configured two separate service IDs we place the bulk\n\t * paths in the same vFabric as the control paths.\n\t */\n\n\tpath_type = IPS_PATH_NORMAL_PRIORITY;\n\tfor (pidx = 0, cpath = 0; pidx < num_path; pidx++) {\n\t\tpath_slid = __cpu_to_be16(__be16_to_cpu(slid) + pidx);\n\t\tpath_dlid = __cpu_to_be16(__be16_to_cpu(dlid) + pidx);\n\nretry_normal_path_res:\n\t\terr = ips_opp_get_path_rec(path_type, proto,\n\t\t\t\t\t   path_slid, path_dlid, desthfi_type,\n\t\t\t\t\t   &path);\n\t\tif (err != PSM2_OK) {\n\t\t\tif (path_type == IPS_PATH_NORMAL_PRIORITY) {\n\t\t\t\t/* Subnet may only be configured for one service ID/vFabric. Default\n\t\t\t\t * to using the control vFabric/service ID for bulk data as well.\n\t\t\t\t */\n\t\t\t\tpath_type = IPS_PATH_HIGH_PRIORITY;\n\t\t\t\tgoto retry_normal_path_res;\n\t\t\t}\n\n\t\t\t/* Unable to resolve path for <path_slid, path_dline>. This is possible\n\t\t\t * for disrupted fabrics using DOR routing so continue to acquire paths\n\t\t\t */\n\t\t\terr = PSM2_OK;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Valid path. */\n\t\tpathgrp->pg_path[cpath][IPS_PATH_NORMAL_PRIORITY] = path;\n\t\tpathgrp->pg_num_paths[IPS_PATH_NORMAL_PRIORITY]++;\n\t\tcpath++;\n\t}\n\n\t/* Make sure we have at least have a single bulk data transfer path */\n\tif (pathgrp->pg_num_paths[IPS_PATH_NORMAL_PRIORITY] == 0) {\n\t\tpsmi_free(elid.key);\n\t\tpsmi_free(pathgrp);\n\t\terr = psmi_handle_error(NULL, PSM2_EPID_PATH_RESOLUTION,\n\t\t\t\t\t\"OFED Plus path lookup failed. Unable to resolve normal priority network path for LID 0x%x <---> 0x%x. Is the SM running or service ID %\"\n\t\t\t\t\tPRIx64 \" defined?\", ntohs(slid),\n\t\t\t\t\tntohs(dlid),\n\t\t\t\t\t(uint64_t) proto->ep->service_id);\n\t\tgoto fail;\n\t}\n\n\tpath_type = IPS_PATH_LOW_PRIORITY;\n\tfor (pidx = 0, cpath = 0; pidx < num_path; pidx++) {\n\t\tpath_slid = __cpu_to_be16(__be16_to_cpu(slid) + pidx);\n\t\tpath_dlid = __cpu_to_be16(__be16_to_cpu(dlid) + pidx);\n\nretry_low_path_res:\n\t\terr = ips_opp_get_path_rec(path_type, proto,\n\t\t\t\t\t   path_slid, path_dlid, desthfi_type,\n\t\t\t\t\t   &path);\n\t\tif (err != PSM2_OK) {\n\t\t\tif (path_type == IPS_PATH_LOW_PRIORITY) {\n\t\t\t\t/* Subnet may only be configured for one service ID/vFabric. Default\n\t\t\t\t * to using the control vFabric/service ID for bulk data as well.\n\t\t\t\t */\n\t\t\t\tpath_type = IPS_PATH_HIGH_PRIORITY;\n\t\t\t\tgoto retry_low_path_res;\n\t\t\t}\n\n\t\t\t/* Unable to resolve path for <path_slid, path_dline>. This is possible\n\t\t\t * for disrupted fabrics using DOR routing so continue to acquire paths\n\t\t\t */\n\t\t\terr = PSM2_OK;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Valid path. */\n\t\tpathgrp->pg_path[cpath][IPS_PATH_LOW_PRIORITY] = path;\n\t\tpathgrp->pg_num_paths[IPS_PATH_LOW_PRIORITY]++;\n\t\tcpath++;\n\t}\n\n\t/* Make sure we have at least have a single bulk data transfer path */\n\tif (pathgrp->pg_num_paths[IPS_PATH_LOW_PRIORITY] == 0) {\n\t\tpsmi_free(elid.key);\n\t\tpsmi_free(pathgrp);\n\t\terr = psmi_handle_error(NULL, PSM2_EPID_PATH_RESOLUTION,\n\t\t\t\t\t\"OFED Plus path lookup failed. Unable to resolve low priority network path for LID 0x%x <---> 0x%x. Is the SM running or service ID %\"\n\t\t\t\t\tPRIx64 \" defined?\", ntohs(slid),\n\t\t\t\t\tntohs(dlid),\n\t\t\t\t\t(uint64_t) proto->ep->service_id);\n\t\tgoto fail;\n\t}\n\n\tif (proto->flags & IPS_PROTO_FLAG_PPOLICY_ADAPTIVE) {\n\t\tpathgrp->pg_next_path[IPS_PATH_NORMAL_PRIORITY] =\n\t\t    proto->epinfo.ep_context %\n\t\t    pathgrp->pg_num_paths[IPS_PATH_NORMAL_PRIORITY];\n\t\tpathgrp->pg_next_path[IPS_PATH_LOW_PRIORITY] =\n\t\t    proto->epinfo.ep_context %\n\t\t    pathgrp->pg_num_paths[IPS_PATH_LOW_PRIORITY];\n\t}\n\n\t/* Add path group into cache */\n\tstrcpy(elid.key, eplid);\n\telid.data = (void *)pathgrp;\n\thsearch_r(elid, ENTER, &epath, &proto->ips_path_grp_hash);\n\n\t*ppathgrp = pathgrp;\n\nfail:\n\tif (err != PSM2_OK)\n\t\t_HFI_PRDBG\n\t\t    (\"Unable to get path record for LID 0x%x <---> DLID 0x%x.\\n\",\n\t\t     slid, dlid);\n\treturn err;\n}\n\nstatic psm2_error_t ips_opp_fini(struct ips_proto *proto)\n{\n\tpsm2_error_t err = PSM2_OK;\n\n\tif (proto->opp_lib)\n\t\tdlclose(proto->opp_lib);\n\n\treturn err;\n}\n\npsm2_error_t ips_opp_init(struct ips_proto *proto)\n{\n\tpsm2_error_t err = PSM2_OK;\n\tchar hfiName[32];\n\n\tproto->opp_lib = dlopen(DF_OPP_LIBRARY, RTLD_NOW);\n\tif (!proto->opp_lib) {\n\t\tchar *err = dlerror();\n\t\t_HFI_ERROR\n\t\t    (\"Unable to open OFED Plus Plus library %s. Error: %s\\n\",\n\t\t     DF_OPP_LIBRARY, err ? err : \"no dlerror()\");\n\t\tgoto fail;\n\t}\n\n\t/* Resolve symbols that we require within opp library */\n\tproto->opp_fn.op_path_find_hca =\n\t    dlsym(proto->opp_lib, \"op_path_find_hfi\");\n\tproto->opp_fn.op_path_open = dlsym(proto->opp_lib, \"op_path_open\");\n\tproto->opp_fn.op_path_close = dlsym(proto->opp_lib, \"op_path_close\");\n\tproto->opp_fn.op_path_get_path_by_rec =\n\t    dlsym(proto->opp_lib, \"op_path_get_path_by_rec\");\n\n\t/* If we can't resovle any symbol then fail to load opp module */\n\tif (!proto->opp_fn.op_path_find_hca || !proto->opp_fn.op_path_open ||\n\t    !proto->opp_fn.op_path_close\n\t    || !proto->opp_fn.op_path_get_path_by_rec) {\n\t\t_HFI_ERROR\n\t\t    (\"Unable to resolve symbols in OPP library. Unloading.\\n\");\n\t\tgoto fail;\n\t}\n\n\t/* If PSM2_IDENTIFY is set display the OPP library location being used. */\n\tif (getenv(\"PSM2_IDENTIFY\")) {\n\t\tDl_info info_opp;\n\t\tprintf\n\t\t    (\"PSM2 path record queries using OFED Plus Plus (%s) from %s\\n\",\n\t\t     DF_OPP_LIBRARY, dladdr(proto->opp_fn.op_path_open,\n\t\t\t\t\t    &info_opp) ? info_opp.\n\t\t     dli_fname :\n\t\t     \"Unknown/unsupported version of OPP library found!\");\n\t}\n\n\t/* Obtain handle to hfi (requires verbs on node) */\n\tsnprintf(hfiName, sizeof(hfiName), \"hfi1_%d\",\n\t\t proto->ep->context.ctrl->__hfi_unit);\n\tproto->hndl = proto->opp_fn.op_path_find_hca(hfiName, &proto->device);\n\tif (!proto->hndl) {\n\t\t_HFI_ERROR\n\t\t    (\"OPP: Unable to find HFI %s. Disabling OPP interface for path record queries.\\n\",\n\t\t     hfiName);\n\t\tgoto fail;\n\t}\n\n\t/* Get OPP context */\n\tproto->opp_ctxt = proto->opp_fn.op_path_open(proto->device, 1);\n\tif (!proto->opp_ctxt) {\n\t\t_HFI_ERROR\n\t\t    (\"OPP: Unable to obtain OPP context. Disabling OPP interface for path record queries.\\n\");\n\t\tgoto fail;\n\t}\n\n\t/* Setup default errorcheck timeout. OPP may change it later. */\n\tproto->epinfo.ep_timeout_ack =\n\t    ms_2_cycles(IPS_PROTO_ERRCHK_MS_MIN_DEFAULT);\n\tproto->epinfo.ep_timeout_ack_max =\n\t    ms_2_cycles(IPS_PROTO_ERRCHK_MS_MIN_DEFAULT);\n\tproto->epinfo.ep_timeout_ack_factor = IPS_PROTO_ERRCHK_FACTOR_DEFAULT;\n\n\t/* OPP initialized successfully */\n\tproto->ibta.get_path_rec = ips_opp_path_rec;\n\tproto->ibta.fini = ips_opp_fini;\n\tproto->flags |= IPS_PROTO_FLAG_QUERY_PATH_REC;\n\n\treturn err;\n\nfail:\n\t_HFI_ERROR(\"Make sure SM is running...\\n\");\n\t_HFI_ERROR(\"Make sure service ibacm is running...\\n\");\n\t_HFI_ERROR(\"to start ibacm: service ibacm start\\n\");\n\t_HFI_ERROR(\"or enable it at boot time: opaconfig -E ibacm\\n\\n\");\n\n\terr = psmi_handle_error(NULL, PSM2_EPID_PATH_RESOLUTION,\n\t\t\t\t\"Unable to initialize OFED Plus library successfully.\\n\");\n\n\tif (proto->opp_lib)\n\t\tdlclose(proto->opp_lib);\n\n\treturn err;\n}\n"
    },
    "skipped": [],
    "total_files": 151
}