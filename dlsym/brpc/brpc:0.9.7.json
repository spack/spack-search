{
    "matches": {
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/src/brpc/details/tcmalloc_extension.cpp": "// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\n\n#include <pthread.h>\n#include <dlfcn.h>                               // dlsym\n#include <stdlib.h>                              // getenv\n#include \"butil/compiler_specific.h\"\n#include \"brpc/details/tcmalloc_extension.h\"\n\nnamespace {\ntypedef MallocExtension* (*GetInstanceFn)();\nstatic pthread_once_t g_get_instance_fn_once = PTHREAD_ONCE_INIT;\nstatic GetInstanceFn g_get_instance_fn = NULL;\nstatic void InitGetInstanceFn() {\n    g_get_instance_fn = (GetInstanceFn)dlsym(\n        RTLD_NEXT, \"_ZN15MallocExtension8instanceEv\");\n}\n} // namespace\n\nMallocExtension* BAIDU_WEAK MallocExtension::instance() {\n    // On fedora 26, this weak function is NOT overriden by the one in tcmalloc\n    // which is dynamically linked.The same issue can't be re-produced in\n    // Ubuntu and the exact cause is unknown yet. Using dlsym to get the\n    // function works around the issue right now. Note that we can't use dlsym\n    // to fully replace the weak-function mechanism since our code are generally\n    // not compiled with -rdynamic which writes symbols to the table that\n    // dlsym reads.\n    pthread_once(&g_get_instance_fn_once, InitGetInstanceFn);\n    if (g_get_instance_fn) {\n        return g_get_instance_fn();\n    }\n    return NULL;\n}\n\nbool IsHeapProfilerEnabled() {\n    return MallocExtension::instance() != NULL;\n}\n\nstatic bool check_TCMALLOC_SAMPLE_PARAMETER() {\n    char* str = getenv(\"TCMALLOC_SAMPLE_PARAMETER\");\n    if (str == NULL) {\n        return false;\n    }\n    char* endptr;\n    int val = strtol(str, &endptr, 10);\n    return (*endptr == '\\0' && val > 0);\n}\n\nbool has_TCMALLOC_SAMPLE_PARAMETER() {\n    static bool val = check_TCMALLOC_SAMPLE_PARAMETER();\n    return val;\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/src/bthread/mutex.cpp": "// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\n\n// bthread - A M:N threading library to make applications more concurrent.\n\n// Date: Sun Aug  3 12:46:15 CST 2014\n\n#include <pthread.h>\n#include <execinfo.h>\n#include <dlfcn.h>                               // dlsym\n#include <fcntl.h>                               // O_RDONLY\n#include \"butil/atomicops.h\"\n#include \"bvar/bvar.h\"\n#include \"bvar/collector.h\"\n#include \"butil/macros.h\"                         // BAIDU_CASSERT\n#include \"butil/containers/flat_map.h\"\n#include \"butil/iobuf.h\"\n#include \"butil/fd_guard.h\"\n#include \"butil/files/file.h\"\n#include \"butil/files/file_path.h\"\n#include \"butil/file_util.h\"\n#include \"butil/unique_ptr.h\"\n#include \"butil/third_party/murmurhash3/murmurhash3.h\"\n#include \"butil/logging.h\"\n#include \"butil/object_pool.h\"\n#include \"bthread/butex.h\"                       // butex_*\n#include \"bthread/processor.h\"                   // cpu_relax, barrier\n#include \"bthread/mutex.h\"                       // bthread_mutex_t\n#include \"bthread/sys_futex.h\"\n#include \"bthread/log.h\"\n\nextern \"C\" {\nextern void* _dl_sym(void* handle, const char* symbol, void* caller);\n}\n\nnamespace bthread {\n// Warm up backtrace before main().\nvoid* dummy_buf[4];\nconst int ALLOW_UNUSED dummy_bt = backtrace(dummy_buf, arraysize(dummy_buf));\n\n// For controlling contentions collected per second.\nstatic bvar::CollectorSpeedLimit g_cp_sl = BVAR_COLLECTOR_SPEED_LIMIT_INITIALIZER;\n\nconst size_t MAX_CACHED_CONTENTIONS = 512;\n// Skip frames which are always same: the unlock function and submit_contention()\nconst int SKIPPED_STACK_FRAMES = 2;\n\nstruct SampledContention : public bvar::Collected {\n    // time taken by lock and unlock, normalized according to sampling_range\n    int64_t duration_ns;\n    // number of samples, normalized according to to sampling_range\n    double count;\n    int nframes;          // #elements in stack\n    void* stack[26];      // backtrace.\n\n    // Implement bvar::Collected\n    void dump_and_destroy(size_t round) override;\n    void destroy() override;\n    bvar::CollectorSpeedLimit* speed_limit() override { return &g_cp_sl; }\n\n    // For combining samples with hashmap.\n    size_t hash_code() const {\n        if (nframes == 0) {\n            return 0;\n        }\n        uint32_t code = 1;\n        uint32_t seed = nframes;\n        butil::MurmurHash3_x86_32(stack, sizeof(void*) * nframes, seed, &code);\n        return code;\n    }\n};\n\nBAIDU_CASSERT(sizeof(SampledContention) == 256, be_friendly_to_allocator);\n\n// Functor to compare contentions.\nstruct ContentionEqual {\n    bool operator()(const SampledContention* c1,\n                    const SampledContention* c2) const {\n        return c1->hash_code() == c2->hash_code() &&\n            c1->nframes == c2->nframes &&\n            memcmp(c1->stack, c2->stack, sizeof(void*) * c1->nframes) == 0;\n    }\n};\n\n// Functor to hash contentions.\nstruct ContentionHash {\n    size_t operator()(const SampledContention* c) const {\n        return c->hash_code();\n    }\n};\n\n// The global context for contention profiler.\nclass ContentionProfiler {\npublic:\n    typedef butil::FlatMap<SampledContention*, SampledContention*,\n                          ContentionHash, ContentionEqual> ContentionMap;\n\n    explicit ContentionProfiler(const char* name);\n    ~ContentionProfiler();\n    \n    void dump_and_destroy(SampledContention* c);\n\n    // Write buffered data into resulting file. If `ending' is true, append\n    // content of /proc/self/maps and retry writing until buffer is empty.\n    void flush_to_disk(bool ending);\n\n    void init_if_needed();\nprivate:\n    bool _init;  // false before first dump_and_destroy is called\n    bool _first_write;      // true if buffer was not written to file yet.\n    std::string _filename;  // the file storing profiling result.\n    butil::IOBuf _disk_buf;  // temp buf before saving the file.\n    ContentionMap _dedup_map; // combining same samples to make result smaller.\n};\n\nContentionProfiler::ContentionProfiler(const char* name)\n    : _init(false)\n    , _first_write(true)\n    , _filename(name) {\n}\n\nContentionProfiler::~ContentionProfiler() {\n    if (!_init) {\n        // Don't write file if dump_and_destroy was never called. We may create\n        // such instances in ContentionProfilerStart.\n        return;\n    }\n    flush_to_disk(true);\n}\n\nvoid ContentionProfiler::init_if_needed() {\n    if (!_init) {\n        // Already output nanoseconds, always set cycles/second to 1000000000.\n        _disk_buf.append(\"--- contention\\ncycles/second=1000000000\\n\");\n        CHECK_EQ(0, _dedup_map.init(1024, 60));\n        _init = true;\n    }\n}\n    \nvoid ContentionProfiler::dump_and_destroy(SampledContention* c) {\n    init_if_needed();\n    // Categorize the contention.\n    SampledContention** p_c2 = _dedup_map.seek(c);\n    if (p_c2) {\n        // Most contentions are caused by several hotspots, this should be\n        // the common branch.\n        SampledContention* c2 = *p_c2;\n        c2->duration_ns += c->duration_ns;\n        c2->count += c->count;\n        c->destroy();\n    } else {\n        _dedup_map.insert(c, c);\n    }\n    if (_dedup_map.size() > MAX_CACHED_CONTENTIONS) {\n        flush_to_disk(false);\n    }\n}\n\nvoid ContentionProfiler::flush_to_disk(bool ending) {\n    BT_VLOG << \"flush_to_disk(ending=\" << ending << \")\";\n    \n    // Serialize contentions in _dedup_map into _disk_buf.\n    if (!_dedup_map.empty()) {\n        BT_VLOG << \"dedup_map=\" << _dedup_map.size();\n        butil::IOBufBuilder os;\n        for (ContentionMap::const_iterator\n                 it = _dedup_map.begin(); it != _dedup_map.end(); ++it) {\n            SampledContention* c = it->second;\n            os << c->duration_ns << ' ' << (size_t)ceil(c->count) << \" @\";\n            for (int i = SKIPPED_STACK_FRAMES; i < c->nframes; ++i) {\n                os << ' ' << (void*)c->stack[i];\n            }\n            os << '\\n';\n            c->destroy();\n        }\n        _dedup_map.clear();\n        _disk_buf.append(os.buf());\n    }\n\n    // Append /proc/self/maps to the end of the contention file, required by\n    // pprof.pl, otherwise the functions in sys libs are not interpreted.\n    if (ending) {\n        BT_VLOG << \"Append /proc/self/maps\";\n        // Failures are not critical, don't return directly.\n        butil::IOPortal mem_maps;\n        const butil::fd_guard fd(open(\"/proc/self/maps\", O_RDONLY));\n        if (fd >= 0) {\n            while (true) {\n                ssize_t nr = mem_maps.append_from_file_descriptor(fd, 8192);\n                if (nr < 0) {\n                    if (errno == EINTR) {\n                        continue;\n                    }\n                    PLOG(ERROR) << \"Fail to read /proc/self/maps\";\n                    break;\n                }\n                if (nr == 0) {\n                    _disk_buf.append(mem_maps);\n                    break;\n                }\n            }\n        } else {\n            PLOG(ERROR) << \"Fail to open /proc/self/maps\";\n        }\n    }\n    // Write _disk_buf into _filename\n    butil::File::Error error;\n    butil::FilePath path(_filename);\n    butil::FilePath dir = path.DirName();\n    if (!butil::CreateDirectoryAndGetError(dir, &error)) {\n        LOG(ERROR) << \"Fail to create directory=`\" << dir.value()\n                   << \"', \" << error;\n        return;\n    }\n    // Truncate on first write, append on later writes.\n    int flag = O_APPEND;\n    if (_first_write) {\n        _first_write = false;\n        flag = O_TRUNC;\n    }\n    butil::fd_guard fd(open(_filename.c_str(), O_WRONLY|O_CREAT|flag, 0666));\n    if (fd < 0) {\n        PLOG(ERROR) << \"Fail to open \" << _filename;\n        return;\n    }\n    // Write once normally, write until empty in the end.\n    do {\n        ssize_t nw = _disk_buf.cut_into_file_descriptor(fd);\n        if (nw < 0) {\n            if (errno == EINTR) {\n                continue;\n            }\n            PLOG(ERROR) << \"Fail to write into \" << _filename;\n            return;\n        }\n        BT_VLOG << \"Write \" << nw << \" bytes into \" << _filename;\n    } while (!_disk_buf.empty() && ending);\n}\n\n// If contention profiler is on, this variable will be set with a valid\n// instance. NULL otherwise.\nstatic ContentionProfiler* BAIDU_CACHELINE_ALIGNMENT g_cp = NULL;\n// Need this version to solve an issue that non-empty entries left by\n// previous contention profilers should be detected and overwritten.\nstatic uint64_t g_cp_version = 0;\n// Protecting accesss to g_cp.\nstatic pthread_mutex_t g_cp_mutex = PTHREAD_MUTEX_INITIALIZER;\n\n// The map storing information for profiling pthread_mutex. Different from\n// bthread_mutex, we can't save stuff into pthread_mutex, we neither can\n// save the info in TLS reliably, since a mutex can be unlocked in a different\n// thread from the one locked (although rare)\n// This map must be very fast, since it's accessed inside the lock.\n// Layout of the map:\n//  * Align each entry by cacheline so that different threads do not collide.\n//  * Hash the mutex into the map by its address. If the entry is occupied,\n//    cancel sampling.\n// The canceling rate should be small provided that programs are unlikely to\n// lock a lot of mutexes simultaneously.\nconst size_t MUTEX_MAP_SIZE = 1024;\nBAIDU_CASSERT((MUTEX_MAP_SIZE & (MUTEX_MAP_SIZE - 1)) == 0, must_be_power_of_2);\nstruct BAIDU_CACHELINE_ALIGNMENT MutexMapEntry {\n    butil::static_atomic<uint64_t> versioned_mutex;\n    bthread_contention_site_t csite;\n};\nstatic MutexMapEntry g_mutex_map[MUTEX_MAP_SIZE] = {}; // zero-initialize\n\nvoid SampledContention::dump_and_destroy(size_t /*round*/) {\n    if (g_cp) {\n        // Must be protected with mutex to avoid race with deletion of ctx.\n        // dump_and_destroy is called from dumping thread only so this mutex\n        // is not contended at most of time.\n        BAIDU_SCOPED_LOCK(g_cp_mutex);\n        if (g_cp) {\n            g_cp->dump_and_destroy(this);\n            return;\n        }\n    }\n    destroy();\n}\n\nvoid SampledContention::destroy() {\n    butil::return_object(this);\n}\n\n// Remember the conflict hashes for troubleshooting, should be 0 at most of time.\nstatic butil::static_atomic<int64_t> g_nconflicthash = BUTIL_STATIC_ATOMIC_INIT(0);\nstatic int64_t get_nconflicthash(void*) {\n    return g_nconflicthash.load(butil::memory_order_relaxed);\n}\n\n// Start profiling contention.\nbool ContentionProfilerStart(const char* filename) {\n    if (filename == NULL) {\n        LOG(ERROR) << \"Parameter [filename] is NULL\";\n        return false;\n    }\n    // g_cp is also the flag marking start/stop.\n    if (g_cp) {\n        return false;\n    }\n\n    // Create related global bvar lazily.\n    static bvar::PassiveStatus<int64_t> g_nconflicthash_var\n        (\"contention_profiler_conflict_hash\", get_nconflicthash, NULL);\n    static bvar::DisplaySamplingRatio g_sampling_ratio_var(\n        \"contention_profiler_sampling_ratio\", &g_cp_sl);\n    \n    // Optimistic locking. A not-used ContentionProfiler does not write file.\n    std::unique_ptr<ContentionProfiler> ctx(new ContentionProfiler(filename));\n    {\n        BAIDU_SCOPED_LOCK(g_cp_mutex);\n        if (g_cp) {\n            return false;\n        }\n        g_cp = ctx.release();\n        ++g_cp_version;  // invalidate non-empty entries that may exist.\n    }\n    return true;\n}\n\n// Stop contention profiler.\nvoid ContentionProfilerStop() {\n    ContentionProfiler* ctx = NULL;\n    if (g_cp) {\n        std::unique_lock<pthread_mutex_t> mu(g_cp_mutex);\n        if (g_cp) {\n            ctx = g_cp;\n            g_cp = NULL;\n            mu.unlock();\n\n            // make sure it's initialiazed in case no sample was gathered,\n            // otherwise nothing will be written and succeeding pprof will fail.\n            ctx->init_if_needed();\n            // Deletion is safe because usages of g_cp are inside g_cp_mutex.\n            delete ctx;\n            return;\n        }\n    }\n    LOG(ERROR) << \"Contention profiler is not started!\";\n}\n\nBUTIL_FORCE_INLINE bool\nis_contention_site_valid(const bthread_contention_site_t& cs) {\n    return cs.sampling_range;\n}\n\nBUTIL_FORCE_INLINE void\nmake_contention_site_invalid(bthread_contention_site_t* cs) {\n    cs->sampling_range = 0;\n}\n\n// Replace pthread_mutex_lock and pthread_mutex_unlock:\n// First call to sys_pthread_mutex_lock sets sys_pthread_mutex_lock to the\n// real function so that next calls go to the real function directly. This\n// technique avoids calling pthread_once each time.\ntypedef int (*MutexOp)(pthread_mutex_t*);\nint first_sys_pthread_mutex_lock(pthread_mutex_t* mutex);\nint first_sys_pthread_mutex_unlock(pthread_mutex_t* mutex);\nstatic MutexOp sys_pthread_mutex_lock = first_sys_pthread_mutex_lock;\nstatic MutexOp sys_pthread_mutex_unlock = first_sys_pthread_mutex_unlock;\nstatic pthread_once_t init_sys_mutex_lock_once = PTHREAD_ONCE_INIT;\n\n// dlsym may call malloc to allocate space for dlerror and causes contention\n// profiler to deadlock at boostraping when the program is linked with\n// libunwind. The deadlock bt:\n//   #0  0x00007effddc99b80 in __nanosleep_nocancel () at ../sysdeps/unix/syscall-template.S:81\n//   #1  0x00000000004b4df7 in butil::internal::SpinLockDelay(int volatile*, int, int) ()\n//   #2  0x00000000004b4d57 in SpinLock::SlowLock() ()\n//   #3  0x00000000004b4a63 in tcmalloc::ThreadCache::InitModule() ()\n//   #4  0x00000000004aa2b5 in tcmalloc::ThreadCache::GetCache() ()\n//   #5  0x000000000040c6c5 in (anonymous namespace)::do_malloc_no_errno(unsigned long) [clone.part.16] ()\n//   #6  0x00000000006fc125 in tc_calloc ()\n//   #7  0x00007effdd245690 in _dlerror_run (operate=operate@entry=0x7effdd245130 <dlsym_doit>, args=args@entry=0x7fff483dedf0) at dlerror.c:141\n//   #8  0x00007effdd245198 in __dlsym (handle=<optimized out>, name=<optimized out>) at dlsym.c:70\n//   #9  0x0000000000666517 in bthread::init_sys_mutex_lock () at bthread/mutex.cpp:358\n//   #10 0x00007effddc97a90 in pthread_once () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_once.S:103\n//   #11 0x000000000066649f in bthread::first_sys_pthread_mutex_lock (mutex=0xbaf880 <_ULx86_64_lock>) at bthread/mutex.cpp:366\n//   #12 0x00000000006678bc in pthread_mutex_lock_impl (mutex=0xbaf880 <_ULx86_64_lock>) at bthread/mutex.cpp:489\n//   #13 pthread_mutex_lock (__mutex=__mutex@entry=0xbaf880 <_ULx86_64_lock>) at bthread/mutex.cpp:751\n//   #14 0x00000000004c6ea1 in _ULx86_64_init () at x86_64/Gglobal.c:83\n//   #15 0x00000000004c44fb in _ULx86_64_init_local (cursor=0x7fff483df340, uc=0x7fff483def90) at x86_64/Ginit_local.c:47\n//   #16 0x00000000004b5012 in GetStackTrace(void**, int, int) ()\n//   #17 0x00000000004b2095 in tcmalloc::PageHeap::GrowHeap(unsigned long) ()\n//   #18 0x00000000004b23a3 in tcmalloc::PageHeap::New(unsigned long) ()\n//   #19 0x00000000004ad457 in tcmalloc::CentralFreeList::Populate() ()\n//   #20 0x00000000004ad628 in tcmalloc::CentralFreeList::FetchFromSpansSafe() ()\n//   #21 0x00000000004ad6a3 in tcmalloc::CentralFreeList::RemoveRange(void**, void**, int) ()\n//   #22 0x00000000004b3ed3 in tcmalloc::ThreadCache::FetchFromCentralCache(unsigned long, unsigned long) ()\n//   #23 0x00000000006fbb9a in tc_malloc ()\n// Call _dl_sym which is a private function in glibc to workaround the malloc\n// causing deadlock temporarily. This fix is hardly portable.\nstatic void init_sys_mutex_lock() {\n#if defined(OS_LINUX)\n    // TODO: may need dlvsym when GLIBC has multiple versions of a same symbol.\n    // http://blog.fesnel.com/blog/2009/08/25/preloading-with-multiple-symbol-versions\n    sys_pthread_mutex_lock = (MutexOp)_dl_sym(RTLD_NEXT, \"pthread_mutex_lock\", (void*)init_sys_mutex_lock);\n    sys_pthread_mutex_unlock = (MutexOp)_dl_sym(RTLD_NEXT, \"pthread_mutex_unlock\", (void*)init_sys_mutex_lock);\n#elif defined(OS_MACOSX)\n    // TODO: look workaround for dlsym on mac\n    sys_pthread_mutex_lock = (MutexOp)dlsym(RTLD_NEXT, \"pthread_mutex_lock\");\n    sys_pthread_mutex_unlock = (MutexOp)dlsym(RTLD_NEXT, \"pthread_mutex_unlock\");\n#endif\n}\n\n// Make sure pthread functions are ready before main().\nconst int ALLOW_UNUSED dummy = pthread_once(&init_sys_mutex_lock_once, init_sys_mutex_lock);\n\nint first_sys_pthread_mutex_lock(pthread_mutex_t* mutex) {\n    pthread_once(&init_sys_mutex_lock_once, init_sys_mutex_lock);\n    return sys_pthread_mutex_lock(mutex);\n}\nint first_sys_pthread_mutex_unlock(pthread_mutex_t* mutex) {\n    pthread_once(&init_sys_mutex_lock_once, init_sys_mutex_lock);\n    return sys_pthread_mutex_unlock(mutex);\n}\n\ninline uint64_t hash_mutex_ptr(const pthread_mutex_t* m) {\n    return butil::fmix64((uint64_t)m);\n}\n\n// Mark being inside locking so that pthread_mutex calls inside collecting\n// code are never sampled, otherwise deadlock may occur.\nstatic __thread bool tls_inside_lock = false;\n\n// Speed up with TLS:\n//   Most pthread_mutex are locked and unlocked in the same thread. Putting\n//   contention information in TLS avoids collisions that may occur in\n//   g_mutex_map. However when user unlocks in another thread, the info cached\n//   in the locking thread is not removed, making the space bloated. We use a\n//   simple strategy to solve the issue: If a thread has enough thread-local\n//   space to store the info, save it, otherwise save it in g_mutex_map. For\n//   a program that locks and unlocks in the same thread and does not lock a\n//   lot of mutexes simulateneously, this strategy always uses the TLS.\n#ifndef DONT_SPEEDUP_PTHREAD_CONTENTION_PROFILER_WITH_TLS\nconst int TLS_MAX_COUNT = 3;\nstruct MutexAndContentionSite {\n    pthread_mutex_t* mutex;\n    bthread_contention_site_t csite;\n};\nstruct TLSPthreadContentionSites {\n    int count;\n    uint64_t cp_version;\n    MutexAndContentionSite list[TLS_MAX_COUNT];\n};\nstatic __thread TLSPthreadContentionSites tls_csites = {0,0,{}};\n#endif  // DONT_SPEEDUP_PTHREAD_CONTENTION_PROFILER_WITH_TLS\n\n// Guaranteed in linux/win.\nconst int PTR_BITS = 48;\n\ninline bthread_contention_site_t*\nadd_pthread_contention_site(pthread_mutex_t* mutex) {\n    MutexMapEntry& entry = g_mutex_map[hash_mutex_ptr(mutex) & (MUTEX_MAP_SIZE - 1)];\n    butil::static_atomic<uint64_t>& m = entry.versioned_mutex;\n    uint64_t expected = m.load(butil::memory_order_relaxed);\n    // If the entry is not used or used by previous profiler, try to CAS it.\n    if (expected == 0 ||\n        (expected >> PTR_BITS) != (g_cp_version & ((1 << (64 - PTR_BITS)) - 1))) {\n        uint64_t desired = (g_cp_version << PTR_BITS) | (uint64_t)mutex;\n        if (m.compare_exchange_strong(\n                expected, desired, butil::memory_order_acquire)) {\n            return &entry.csite;\n        }\n    }\n    g_nconflicthash.fetch_add(1, butil::memory_order_relaxed);\n    return NULL;\n}\n\ninline bool remove_pthread_contention_site(\n    pthread_mutex_t* mutex, bthread_contention_site_t* saved_csite) {\n    MutexMapEntry& entry = g_mutex_map[hash_mutex_ptr(mutex) & (MUTEX_MAP_SIZE - 1)];\n    butil::static_atomic<uint64_t>& m = entry.versioned_mutex;\n    if ((m.load(butil::memory_order_relaxed) & ((((uint64_t)1) << PTR_BITS) - 1))\n        != (uint64_t)mutex) {\n        // This branch should be the most common case since most locks are\n        // neither contended nor sampled. We have one memory indirection and\n        // several bitwise operations here, the cost should be ~ 5-50ns\n        return false;\n    }\n    // Although this branch is inside a contended lock, we should also make it\n    // as simple as possible because altering the critical section too much\n    // may make unpredictable impact to thread interleaving status, which\n    // makes profiling result less accurate.\n    *saved_csite = entry.csite;\n    make_contention_site_invalid(&entry.csite);\n    m.store(0, butil::memory_order_release);\n    return true;\n}\n\n// Submit the contention along with the callsite('s stacktrace)\nvoid submit_contention(const bthread_contention_site_t& csite, int64_t now_ns) {\n    tls_inside_lock = true;\n    SampledContention* sc = butil::get_object<SampledContention>();\n    // Normalize duration_us and count so that they're addable in later\n    // processings. Notice that sampling_range is adjusted periodically by\n    // collecting thread.\n    sc->duration_ns = csite.duration_ns * bvar::COLLECTOR_SAMPLING_BASE\n        / csite.sampling_range;\n    sc->count = bvar::COLLECTOR_SAMPLING_BASE / (double)csite.sampling_range;\n    sc->nframes = backtrace(sc->stack, arraysize(sc->stack)); // may lock\n    sc->submit(now_ns / 1000);  // may lock\n    tls_inside_lock = false;\n}\n\nBUTIL_FORCE_INLINE int pthread_mutex_lock_impl(pthread_mutex_t* mutex) {\n    // Don't change behavior of lock when profiler is off.\n    if (!g_cp ||\n        // collecting code including backtrace() and submit() may call\n        // pthread_mutex_lock and cause deadlock. Don't sample.\n        tls_inside_lock) {\n        return sys_pthread_mutex_lock(mutex);\n    }\n    // Don't slow down non-contended locks.\n    int rc = pthread_mutex_trylock(mutex);\n    if (rc != EBUSY) {\n        return rc;\n    }\n    // Ask bvar::Collector if this (contended) locking should be sampled\n    const size_t sampling_range = bvar::is_collectable(&g_cp_sl);\n\n    bthread_contention_site_t* csite = NULL;\n#ifndef DONT_SPEEDUP_PTHREAD_CONTENTION_PROFILER_WITH_TLS\n    TLSPthreadContentionSites& fast_alt = tls_csites;\n    if (fast_alt.cp_version != g_cp_version) {\n        fast_alt.cp_version = g_cp_version;\n        fast_alt.count = 0;\n    }\n    if (fast_alt.count < TLS_MAX_COUNT) {\n        MutexAndContentionSite& entry = fast_alt.list[fast_alt.count++];\n        entry.mutex = mutex;\n        csite = &entry.csite;\n        if (!sampling_range) {\n            make_contention_site_invalid(&entry.csite);\n            return sys_pthread_mutex_lock(mutex);\n        }\n    }\n#endif\n    if (!sampling_range) {  // don't sample\n        return sys_pthread_mutex_lock(mutex);\n    }\n    // Lock and monitor the waiting time.\n    const int64_t start_ns = butil::cpuwide_time_ns();\n    rc = sys_pthread_mutex_lock(mutex);\n    if (!rc) { // Inside lock\n        if (!csite) {\n            csite = add_pthread_contention_site(mutex);\n            if (csite == NULL) {\n                return rc;\n            }\n        }\n        csite->duration_ns = butil::cpuwide_time_ns() - start_ns;\n        csite->sampling_range = sampling_range;\n    } // else rare\n    return rc;\n}\n\nBUTIL_FORCE_INLINE int pthread_mutex_unlock_impl(pthread_mutex_t* mutex) {\n    // Don't change behavior of unlock when profiler is off.\n    if (!g_cp || tls_inside_lock) {\n        // This branch brings an issue that an entry created by\n        // add_pthread_contention_site may not be cleared. Thus we add a \n        // 16-bit rolling version in the entry to find out such entry.\n        return sys_pthread_mutex_unlock(mutex);\n    }\n    int64_t unlock_start_ns = 0;\n    bool miss_in_tls = true;\n    bthread_contention_site_t saved_csite = {0,0};\n#ifndef DONT_SPEEDUP_PTHREAD_CONTENTION_PROFILER_WITH_TLS\n    TLSPthreadContentionSites& fast_alt = tls_csites;\n    for (int i = fast_alt.count - 1; i >= 0; --i) {\n        if (fast_alt.list[i].mutex == mutex) {\n            if (is_contention_site_valid(fast_alt.list[i].csite)) {\n                saved_csite = fast_alt.list[i].csite;\n                unlock_start_ns = butil::cpuwide_time_ns();\n            }\n            fast_alt.list[i] = fast_alt.list[--fast_alt.count];\n            miss_in_tls = false;\n            break;\n        }\n    }\n#endif\n    // Check the map to see if the lock is sampled. Notice that we're still\n    // inside critical section.\n    if (miss_in_tls) {\n        if (remove_pthread_contention_site(mutex, &saved_csite)) {\n            unlock_start_ns = butil::cpuwide_time_ns();\n        }\n    }\n    const int rc = sys_pthread_mutex_unlock(mutex);\n    // [Outside lock]\n    if (unlock_start_ns) {\n        const int64_t unlock_end_ns = butil::cpuwide_time_ns();\n        saved_csite.duration_ns += unlock_end_ns - unlock_start_ns;\n        submit_contention(saved_csite, unlock_end_ns);\n    }\n    return rc;\n}\n\n// Implement bthread_mutex_t related functions\nstruct MutexInternal {\n    butil::static_atomic<unsigned char> locked;\n    butil::static_atomic<unsigned char> contended;\n    unsigned short padding;\n};\n\nconst MutexInternal MUTEX_CONTENDED_RAW = {{1},{1},0};\nconst MutexInternal MUTEX_LOCKED_RAW = {{1},{0},0};\n// Define as macros rather than constants which can't be put in read-only\n// section and affected by initialization-order fiasco.\n#define BTHREAD_MUTEX_CONTENDED (*(const unsigned*)&bthread::MUTEX_CONTENDED_RAW)\n#define BTHREAD_MUTEX_LOCKED (*(const unsigned*)&bthread::MUTEX_LOCKED_RAW)\n\nBAIDU_CASSERT(sizeof(unsigned) == sizeof(MutexInternal),\n              sizeof_mutex_internal_must_equal_unsigned);\n\ninline int mutex_lock_contended(bthread_mutex_t* m) {\n    butil::atomic<unsigned>* whole = (butil::atomic<unsigned>*)m->butex;\n    while (whole->exchange(BTHREAD_MUTEX_CONTENDED) & BTHREAD_MUTEX_LOCKED) {\n        if (bthread::butex_wait(whole, BTHREAD_MUTEX_CONTENDED, NULL) < 0 &&\n            errno != EWOULDBLOCK && errno != EINTR/*note*/) {\n            // a mutex lock should ignore interrruptions in general since\n            // user code is unlikely to check the return value.\n            return errno;\n        }\n    }\n    return 0;\n}\n\ninline int mutex_timedlock_contended(\n    bthread_mutex_t* m, const struct timespec* __restrict abstime) {\n    butil::atomic<unsigned>* whole = (butil::atomic<unsigned>*)m->butex;\n    while (whole->exchange(BTHREAD_MUTEX_CONTENDED) & BTHREAD_MUTEX_LOCKED) {\n        if (bthread::butex_wait(whole, BTHREAD_MUTEX_CONTENDED, abstime) < 0 &&\n            errno != EWOULDBLOCK && errno != EINTR/*note*/) {\n            // a mutex lock should ignore interrruptions in general since\n            // user code is unlikely to check the return value.\n            return errno;\n        }\n    }\n    return 0;\n}\n\n#ifdef BTHREAD_USE_FAST_PTHREAD_MUTEX\nnamespace internal {\n\nint FastPthreadMutex::lock_contended() {\n    butil::atomic<unsigned>* whole = (butil::atomic<unsigned>*)&_futex;\n    while (whole->exchange(BTHREAD_MUTEX_CONTENDED) & BTHREAD_MUTEX_LOCKED) {\n        if (futex_wait_private(whole, BTHREAD_MUTEX_CONTENDED, NULL) < 0\n            && errno != EWOULDBLOCK) {\n            return errno;\n        }\n    }\n    return 0;\n}\n\nvoid FastPthreadMutex::lock() {\n    bthread::MutexInternal* split = (bthread::MutexInternal*)&_futex;\n    if (split->locked.exchange(1, butil::memory_order_acquire)) {\n        (void)lock_contended();\n    }\n}\n\nbool FastPthreadMutex::try_lock() {\n    bthread::MutexInternal* split = (bthread::MutexInternal*)&_futex;\n    return !split->locked.exchange(1, butil::memory_order_acquire);\n}\n\nvoid FastPthreadMutex::unlock() {\n    butil::atomic<unsigned>* whole = (butil::atomic<unsigned>*)&_futex;\n    const unsigned prev = whole->exchange(0, butil::memory_order_release);\n    // CAUTION: the mutex may be destroyed, check comments before butex_create\n    if (prev != BTHREAD_MUTEX_LOCKED) {\n        futex_wake_private(whole, 1);\n    }\n}\n\n} // namespace internal\n#endif // BTHREAD_USE_FAST_PTHREAD_MUTEX\n\n} // namespace bthread\n\nextern \"C\" {\n\nint bthread_mutex_init(bthread_mutex_t* __restrict m,\n                       const bthread_mutexattr_t* __restrict) {\n    bthread::make_contention_site_invalid(&m->csite);\n    m->butex = bthread::butex_create_checked<unsigned>();\n    if (!m->butex) {\n        return ENOMEM;\n    }\n    *m->butex = 0;\n    return 0;\n}\n\nint bthread_mutex_destroy(bthread_mutex_t* m) {\n    bthread::butex_destroy(m->butex);\n    return 0;\n}\n\nint bthread_mutex_trylock(bthread_mutex_t* m) {\n    bthread::MutexInternal* split = (bthread::MutexInternal*)m->butex;\n    if (!split->locked.exchange(1, butil::memory_order_acquire)) {\n        return 0;\n    }\n    return EBUSY;\n}\n\nint bthread_mutex_lock_contended(bthread_mutex_t* m) {\n    return bthread::mutex_lock_contended(m);\n}\n\nint bthread_mutex_lock(bthread_mutex_t* m) {\n    bthread::MutexInternal* split = (bthread::MutexInternal*)m->butex;\n    if (!split->locked.exchange(1, butil::memory_order_acquire)) {\n        return 0;\n    }\n    // Don't sample when contention profiler is off.\n    if (!bthread::g_cp) {\n        return bthread::mutex_lock_contended(m);\n    }\n    // Ask Collector if this (contended) locking should be sampled.\n    const size_t sampling_range = bvar::is_collectable(&bthread::g_cp_sl);\n    if (!sampling_range) { // Don't sample\n        return bthread::mutex_lock_contended(m);\n    }\n    // Start sampling.\n    const int64_t start_ns = butil::cpuwide_time_ns();\n    // NOTE: Don't modify m->csite outside lock since multiple threads are\n    // still contending with each other.\n    const int rc = bthread::mutex_lock_contended(m);\n    if (!rc) { // Inside lock\n        m->csite.duration_ns = butil::cpuwide_time_ns() - start_ns;\n        m->csite.sampling_range = sampling_range;\n    } // else rare\n    return rc;\n}\n\nint bthread_mutex_timedlock(bthread_mutex_t* __restrict m,\n                            const struct timespec* __restrict abstime) {\n    bthread::MutexInternal* split = (bthread::MutexInternal*)m->butex;\n    if (!split->locked.exchange(1, butil::memory_order_acquire)) {\n        return 0;\n    }\n    // Don't sample when contention profiler is off.\n    if (!bthread::g_cp) {\n        return bthread::mutex_timedlock_contended(m, abstime);\n    }\n    // Ask Collector if this (contended) locking should be sampled.\n    const size_t sampling_range = bvar::is_collectable(&bthread::g_cp_sl);\n    if (!sampling_range) { // Don't sample\n        return bthread::mutex_timedlock_contended(m, abstime);\n    }\n    // Start sampling.\n    const int64_t start_ns = butil::cpuwide_time_ns();\n    // NOTE: Don't modify m->csite outside lock since multiple threads are\n    // still contending with each other.\n    const int rc = bthread::mutex_timedlock_contended(m, abstime);\n    if (!rc) { // Inside lock\n        m->csite.duration_ns = butil::cpuwide_time_ns() - start_ns;\n        m->csite.sampling_range = sampling_range;\n    } else if (rc == ETIMEDOUT) {\n        // Failed to lock due to ETIMEDOUT, submit the elapse directly.\n        const int64_t end_ns = butil::cpuwide_time_ns();\n        const bthread_contention_site_t csite = {end_ns - start_ns, sampling_range};\n        bthread::submit_contention(csite, end_ns);\n    }\n    return rc;\n}\n\nint bthread_mutex_unlock(bthread_mutex_t* m) {\n    butil::atomic<unsigned>* whole = (butil::atomic<unsigned>*)m->butex;\n    bthread_contention_site_t saved_csite = {0, 0};\n    if (bthread::is_contention_site_valid(m->csite)) {\n        saved_csite = m->csite;\n        bthread::make_contention_site_invalid(&m->csite);\n    }\n    const unsigned prev = whole->exchange(0, butil::memory_order_release);\n    // CAUTION: the mutex may be destroyed, check comments before butex_create\n    if (prev == BTHREAD_MUTEX_LOCKED) {\n        return 0;\n    }\n    // Wakeup one waiter\n    if (!bthread::is_contention_site_valid(saved_csite)) {\n        bthread::butex_wake(whole);\n        return 0;\n    }\n    const int64_t unlock_start_ns = butil::cpuwide_time_ns();\n    bthread::butex_wake(whole);\n    const int64_t unlock_end_ns = butil::cpuwide_time_ns();\n    saved_csite.duration_ns += unlock_end_ns - unlock_start_ns;\n    bthread::submit_contention(saved_csite, unlock_end_ns);\n    return 0;\n}\n\nint pthread_mutex_lock (pthread_mutex_t *__mutex) {\n    return bthread::pthread_mutex_lock_impl(__mutex);\n}\nint pthread_mutex_unlock (pthread_mutex_t *__mutex) {\n    return bthread::pthread_mutex_unlock_impl(__mutex);\n}\n\n}  // extern \"C\"\n"
    },
    "skipped": [
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/pchan.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/echo_cpu_profiling.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/register_ns.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/302.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/connection_timedout.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/ubrpc_compare_1.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/apicontrol_compare_2.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/rpc_view_1.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/bthread_concurrency_3.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/backup_request_3.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/short_conn.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/baidu_dsp_compare_5.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/rpcz_6.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/qps_vs_threadnum.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/multi_client_latency_cdf.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/baidu_dsp_compare_4.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/status.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/version_service.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/baidu_dsp_compare_1.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/growth_profiler.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/bvar_dump_flags.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/rpc_replay_4.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/rpcz_7.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/baidu_dsp_compare_2.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/set_flag_with_form_3.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/chash.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/lalb_2.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/latency_cdf.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/baidu_dsp_compare_6.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/rpc_replay_3.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/bvar_noah2.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/vars_7.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/ns_filter.jpg",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/apicontrol_compare_5.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/rpcz_3.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/vars_6.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/raft_contention_3.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/reloadable_flags.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/set_flag_reject.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/restful_2.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/ubrpc_compare_2.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/twolevel_server_latency_cdf.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/set_flag_with_form.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/vars_4.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/heap_profiler_2.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/dummy_server_2.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/ns.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/logo.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/rpc_replay_1.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/rpc_replay_2.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/backup_request_2.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/vars_3.gif",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/resource_pool.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/rpc_press_2.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/single_conn.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/bthread_creation_qps.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/bthread_concurrency_1.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/qps_vs_reqsize.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/apicontrol_compare_1.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/threading_overview_1.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/bvar_dump_flags_2.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/set_flag_with_form_2.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/bthread_concurrency_2.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/status_2.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/baidu_dsp_compare_7.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/lalb_1.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/rpc_view_2.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/dummy_server_1.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/baidu_dsp_compare_9.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/rpcz_4.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/server_side.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/restful_3.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/rpc_replay_5.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/backup_request_4.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/bvar_noah1.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/full_worker_usage.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/client_side.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/lalb_5.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/high_cpu_usage.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/heap_profiler_1.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/the_r_after_flag.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/tcmalloc_stuck.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/health_service.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/backup_request_1.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/foobar_bvar.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/builtin_service_from_console.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/lalb_4.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/protobufs_service.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/qps_vs_multi_client.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/rpc.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/builtin_service_more.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/register_lb.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/bvar_noah3.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/baidu_dsp_compare_3.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/threading_overview_2.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/baidu_dsp_compare_8.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/dummy_server_3.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/rpcz_2.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/trace_printf.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/restful_1.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/apicontrol_compare_3.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/rpcz.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/lalb_3.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/normal_worker_usage.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/set_flag_invalid_value.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/normal_cpu_usage.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/vars_5.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/rpc_flow.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/raft_contention_2.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/write.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/vlog_service.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/baidu_dsp_compare_10.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/vars_2.gif",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/full_worker_usage_2.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/heap_profiler_3.gif",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/bvar_perf.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/rpc_press_1.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/vars_1.gif",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/pooled_conn.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/flag_setvalue.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/lb.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/ns_access_interval.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/rpc_view_3.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/rpcz_5.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/apicontrol_compare_4.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/bvar_flow.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/multi_server_latency_cdf.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/foobar_latency_cdf.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/images/raft_contention_1.png",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/cn/brpc_intro.pptx",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/en/brpc_internal.pptx",
        "/tmp/vanessa/spack-stage/spack-stage-brpc-0.9.7-ugrdzhaqqdcvbilw3aev4ouohf4eofxn/spack-src/docs/en/tutorial_on_building_services.pptx"
    ],
    "total_files": 1376
}