{
    "matches": {
        "/tmp/vanessa/spack-stage/spack-stage-libxsmm-1.8.3-5oxdpmrq6vevfdfgmhwzg36uxnjhprjk/spack-src/src/libxsmm_gemm.h": "/******************************************************************************\n** Copyright (c) 2015-2018, Intel Corporation                                **\n** All rights reserved.                                                      **\n**                                                                           **\n** Redistribution and use in source and binary forms, with or without        **\n** modification, are permitted provided that the following conditions        **\n** are met:                                                                  **\n** 1. Redistributions of source code must retain the above copyright         **\n**    notice, this list of conditions and the following disclaimer.          **\n** 2. Redistributions in binary form must reproduce the above copyright      **\n**    notice, this list of conditions and the following disclaimer in the    **\n**    documentation and/or other materials provided with the distribution.   **\n** 3. Neither the name of the copyright holder nor the names of its          **\n**    contributors may be used to endorse or promote products derived        **\n**    from this software without specific prior written permission.          **\n**                                                                           **\n** THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS       **\n** \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT         **\n** LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR     **\n** A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT      **\n** HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,    **\n** SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED  **\n** TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR    **\n** PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF    **\n** LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING      **\n** NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS        **\n** SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.              **\n******************************************************************************/\n/* Hans Pabst (Intel Corp.)\n******************************************************************************/\n#ifndef LIBXSMM_GEMM_H\n#define LIBXSMM_GEMM_H\n\n#include \"libxsmm_main.h\"\n\n#if defined(LIBXSMM_OFFLOAD_TARGET)\n# pragma offload_attribute(push,target(LIBXSMM_OFFLOAD_TARGET))\n#endif\n#if !defined(LIBXSMM_GEMM_WRAP_DYNAMIC) && defined(LIBXSMM_BUILD) && \\\n  (!defined(__BLAS) || (0 != __BLAS)) && defined(__GNUC__) && \\\n  !(defined(__APPLE__) && defined(__MACH__) && LIBXSMM_VERSION3(6, 1, 0) >= \\\n    LIBXSMM_VERSION3(__clang_major__, __clang_minor__, __clang_patchlevel__)) && \\\n  !defined(_WIN32) && !defined(__CYGWIN__)\n# include <dlfcn.h>\n# define LIBXSMM_GEMM_WRAP_DYNAMIC\n#endif\n#include <limits.h>\n#include <stdio.h>\n#include <math.h>\n#if defined(LIBXSMM_OFFLOAD_TARGET)\n# pragma offload_attribute(pop)\n#endif\n\n#if !defined(LIBXSMM_GEMM_LOCK)\n# define LIBXSMM_GEMM_LOCK LIBXSMM_LOCK_DEFAULT\n#endif\n\n#if !defined(LIBXSMM_GEMM_MMBATCH) && defined(LIBXSMM_BUILD) && \\\n    (defined(LIBXSMM_CONFIG_WRAP) && 0 != (LIBXSMM_CONFIG_WRAP)) && \\\n    (defined(LIBXSMM_GEMM_WRAP_STATIC) || defined(LIBXSMM_GEMM_WRAP_DYNAMIC) || \\\n    !defined(NDEBUG) || defined(_WIN32)) /* debug purpose */\n# define LIBXSMM_GEMM_MMBATCH\n#endif\n\n/** Undefine (disarm) MKL's DIRECT_CALL macros. */\n#if defined(MKL_DIRECT_CALL_SEQ) || defined(MKL_DIRECT_CALL)\n# if defined(sgemm_)\n#   undef sgemm_\n# endif\n# if defined(dgemm_)\n#   undef dgemm_\n# endif\n#endif\n\n#if !defined(LIBXSMM_GEMM_COLLAPSE)\n# define LIBXSMM_GEMM_COLLAPSE 2\n#endif\n\n#if !defined(LIBXSMM_GEMM_BATCHSCALE)\n# define LIBXSMM_GEMM_BATCHSCALE 1.5\n#endif\n\n#if !defined(LIBXSMM_NO_BLAS)\n# if !defined(__BLAS) || (0 != __BLAS)\n#   define LIBXSMM_NO_BLAS 0\n# else\n#   define LIBXSMM_NO_BLAS 1\n# endif\n#endif\n\n#define LIBXSMM_GEMM_NO_BYPASS(FLAGS, ALPHA, BETA) ( \\\n  0 == ((FLAGS) & (LIBXSMM_GEMM_FLAG_TRANS_A | LIBXSMM_GEMM_FLAG_TRANS_B)) && \\\n        (LIBXSMM_FEQ(1, ALPHA) /*|| LIBXSMM_FEQ(-1, ALPHA)*/) && \\\n        (LIBXSMM_FEQ(1, BETA) || LIBXSMM_FEQ(0, BETA)))\n\n#if !defined(LIBXSMM_GEMM_TILED_INNER_FALLBACK)\n# define LIBXSMM_GEMM_TILED_INNER_FALLBACK\n#endif\n#if defined(LIBXSMM_GEMM_TILED_INNER_FALLBACK)\n# define LIBXSMM_GEMM_TILED_FALLBACK_CHECK(CONDITION) if (CONDITION)\n# define LIBXSMM_GEMM_TILED_FALLBACK(TYPE, FLAGS, M, N, K, ALPHA, A, LDA, B, LDB, BETA, C, LDC) else { \\\n    LIBXSMM_FALLBACK0(TYPE, libxsmm_blasint, FLAGS, M, N, K, ALPHA, A, LDA, B, LDB, BETA, C, LDC); \\\n  }\n#else\n# define LIBXSMM_GEMM_TILED_FALLBACK_CHECK(CONDITION)\n# define LIBXSMM_GEMM_TILED_FALLBACK(TYPE, FLAGS, TILE_M, TILE_N, TILE_K, ALPHA, A, LDA, B, LDB, BETA, C, LDC)\n#endif\n\n#define LIBXSMM_GEMM_TILED_KERNEL(KERNEL_INNER_BETA1, TYPE, FLAGS, POS_I, POS_J, MAX_K, TILE_M, TILE_N, TILE_K, M, N, K, ALPHA, A, LDA, B, LDB, BETA, C, LDC) { \\\n  const libxsmm_blasint libxsmm_tiled_xgemm_kernel_tm_ = LIBXSMM_MIN(TILE_M, (M) - (POS_I)); \\\n  const libxsmm_blasint libxsmm_tiled_xgemm_kernel_tn_ = LIBXSMM_MIN(TILE_N, (N) - (POS_J)); \\\n  const libxsmm_blasint libxsmm_tiled_xgemm_kernel_tk_ = ((TILE_K) <= (K) ? (TILE_K) : ((K) - (MAX_K))); \\\n  const TYPE* libxsmm_tiled_xgemm_kernel_ia_ = (A) + (POS_I); \\\n  const TYPE* libxsmm_tiled_xgemm_kernel_ib_ = (B) + (POS_J) * (LDB); \\\n  const TYPE* libxsmm_tiled_xgemm_kernel_pa_ = libxsmm_tiled_xgemm_kernel_ia_ + (libxsmm_tiled_xgemm_kernel_tk_) * (LDA); \\\n  const TYPE* libxsmm_tiled_xgemm_kernel_pb_ = libxsmm_tiled_xgemm_kernel_ib_ + (libxsmm_tiled_xgemm_kernel_tk_); \\\n  TYPE *const libxsmm_tiled_xgemm_kernel_ic_ = (C) + (POS_J) * (LDC) + (POS_I), libxsmm_tiled_xgemm_kernel_beta_ = BETA; \\\n  libxsmm_gemm_descriptor libxsmm_tiled_xgemm_kernel_desc_ = { 0 }; \\\n  libxsmm_xmmfunction libxsmm_gemm_tiled_kernel_ = { 0 }; \\\n  libxsmm_blasint libxsmm_tiled_xgemm_kernel_k_ = 0; \\\n  assert(0 != (A) && 0 != (B) && 0 != (C)); \\\n  if (((TILE_M) == libxsmm_tiled_xgemm_kernel_tm_) && ((TILE_N) == libxsmm_tiled_xgemm_kernel_tn_) && ((TILE_K) == libxsmm_tiled_xgemm_kernel_tk_)) { \\\n    if (libxsmm_tiled_xgemm_kernel_k_ < (MAX_K)) { /* peel */ \\\n      LIBXSMM_GEMM_DESCRIPTOR(libxsmm_tiled_xgemm_kernel_desc_, LIBXSMM_GEMM_PRECISION(TYPE), FLAGS, TILE_M, TILE_N, TILE_K, \\\n        LDA, LDB, LDC, ALPHA, BETA, libxsmm_gemm_tiled_prefetch); \\\n      libxsmm_gemm_tiled_kernel_ = libxsmm_xmmdispatch(&libxsmm_tiled_xgemm_kernel_desc_); \\\n      LIBXSMM_GEMM_TILED_FALLBACK_CHECK(0 != libxsmm_gemm_tiled_kernel_.LIBXSMM_TPREFIX(TYPE, mm)) \\\n      { \\\n        LIBXSMM_MMCALL_PRF(libxsmm_gemm_tiled_kernel_.LIBXSMM_TPREFIX(TYPE, mm), \\\n          libxsmm_tiled_xgemm_kernel_ia_, libxsmm_tiled_xgemm_kernel_ib_, libxsmm_tiled_xgemm_kernel_ic_, \\\n          libxsmm_tiled_xgemm_kernel_pa_, libxsmm_tiled_xgemm_kernel_pb_, libxsmm_tiled_xgemm_kernel_ic_); \\\n      } \\\n      LIBXSMM_GEMM_TILED_FALLBACK(TYPE, FLAGS, TILE_M, TILE_N, TILE_K, \\\n        ALPHA, libxsmm_tiled_xgemm_kernel_ia_, LDA, libxsmm_tiled_xgemm_kernel_ib_, LDB, \\\n         BETA, libxsmm_tiled_xgemm_kernel_ic_, LDC); \\\n      libxsmm_tiled_xgemm_kernel_ia_ = libxsmm_tiled_xgemm_kernel_pa_; \\\n      libxsmm_tiled_xgemm_kernel_ib_ = libxsmm_tiled_xgemm_kernel_pb_; \\\n      libxsmm_tiled_xgemm_kernel_pa_ += (TILE_K) * (LDA); \\\n      libxsmm_tiled_xgemm_kernel_pb_ += TILE_K; \\\n      libxsmm_tiled_xgemm_kernel_k_ = TILE_K; \\\n      libxsmm_tiled_xgemm_kernel_beta_ = 1; \\\n    } \\\n    for (; libxsmm_tiled_xgemm_kernel_k_ < (MAX_K); libxsmm_tiled_xgemm_kernel_k_ += TILE_K) { /* inner */ \\\n      LIBXSMM_MMCALL_PRF((KERNEL_INNER_BETA1).LIBXSMM_TPREFIX(TYPE, mm), \\\n        libxsmm_tiled_xgemm_kernel_ia_, libxsmm_tiled_xgemm_kernel_ib_, libxsmm_tiled_xgemm_kernel_ic_, \\\n        libxsmm_tiled_xgemm_kernel_pa_, libxsmm_tiled_xgemm_kernel_pb_, libxsmm_tiled_xgemm_kernel_ic_); \\\n      libxsmm_tiled_xgemm_kernel_ia_ = libxsmm_tiled_xgemm_kernel_pa_; \\\n      libxsmm_tiled_xgemm_kernel_ib_ = libxsmm_tiled_xgemm_kernel_pb_; \\\n      libxsmm_tiled_xgemm_kernel_pa_ += (TILE_K) * (LDA); \\\n      libxsmm_tiled_xgemm_kernel_pb_ += TILE_K; \\\n    } \\\n  } \\\n  if (libxsmm_tiled_xgemm_kernel_k_ < (K)) { /* remainder */ \\\n    LIBXSMM_GEMM_DESCRIPTOR(libxsmm_tiled_xgemm_kernel_desc_, LIBXSMM_GEMM_PRECISION(TYPE), FLAGS, \\\n      libxsmm_tiled_xgemm_kernel_tm_, libxsmm_tiled_xgemm_kernel_tn_, (K) - libxsmm_tiled_xgemm_kernel_k_, \\\n      LDA, LDB, LDC, ALPHA, libxsmm_tiled_xgemm_kernel_beta_, libxsmm_gemm_tiled_prefetch); \\\n    libxsmm_gemm_tiled_kernel_ = libxsmm_xmmdispatch(&libxsmm_tiled_xgemm_kernel_desc_); \\\n    LIBXSMM_GEMM_TILED_FALLBACK_CHECK(0 != libxsmm_gemm_tiled_kernel_.LIBXSMM_TPREFIX(TYPE, mm)) \\\n    { \\\n      LIBXSMM_MMCALL_PRF(libxsmm_gemm_tiled_kernel_.LIBXSMM_TPREFIX(TYPE, mm), \\\n        libxsmm_tiled_xgemm_kernel_ia_, libxsmm_tiled_xgemm_kernel_ib_, libxsmm_tiled_xgemm_kernel_ic_, \\\n        libxsmm_tiled_xgemm_kernel_pa_, libxsmm_tiled_xgemm_kernel_pb_, libxsmm_tiled_xgemm_kernel_ic_); \\\n    } \\\n    LIBXSMM_GEMM_TILED_FALLBACK(TYPE, FLAGS, \\\n      libxsmm_tiled_xgemm_kernel_tm_, libxsmm_tiled_xgemm_kernel_tn_, (K) - libxsmm_tiled_xgemm_kernel_k_, \\\n      ALPHA, libxsmm_tiled_xgemm_kernel_ia_, LDA, libxsmm_tiled_xgemm_kernel_ib_, LDB, \\\n      libxsmm_tiled_xgemm_kernel_beta_, libxsmm_tiled_xgemm_kernel_ic_, LDC); \\\n  } \\\n}\n\n#if defined(NDEBUG)\n# define LIBXSMM_TILED_XGEMM_FALLBACK_PRINT(TYPE, FLAGS, MM, NN, KK, ALPHA, A, LDA, B, LDB, BETA, C, LDC)\n#else\n# define LIBXSMM_TILED_XGEMM_FALLBACK_PRINT(TYPE, FLAGS, MM, NN, KK, ALPHA, A, LDA, B, LDB, BETA, C, LDC) \\\n    if (INT_MAX != libxsmm_verbosity \\\n      && (unsigned int)LIBXSMM_ABS(libxsmm_verbosity) > libxsmm_update_mmstatistic(LIBXSMM_GEMM_PRECISION(TYPE), MM, NN, KK, 1/*try*/, 0)) \\\n    { \\\n      const char libxsmm_tiled_xgemm_transa_ = (char)(0 == ((FLAGS) & LIBXSMM_GEMM_FLAG_TRANS_A) ? 'N' : 'T'); \\\n      const char libxsmm_tiled_xgemm_transb_ = (char)(0 == ((FLAGS) & LIBXSMM_GEMM_FLAG_TRANS_B) ? 'N' : 'T'); \\\n      const TYPE libxsmm_tiled_xgemm_alpha_ = (TYPE)(ALPHA), libxsmm_tiled_xgemm_beta_ = (TYPE)(BETA); \\\n      if (0 < libxsmm_verbosity) { /* print fallback */ \\\n        LIBXSMM_FLOCK(stderr); \\\n        fprintf(stderr, \"LIBXSMM FALLBACK: \"); libxsmm_gemm_print(stderr, LIBXSMM_GEMM_PRECISION(TYPE), \\\n          &libxsmm_tiled_xgemm_transa_, &libxsmm_tiled_xgemm_transb_, &(MM), &(NN), &(KK), \\\n          &libxsmm_tiled_xgemm_alpha_, 0/*A*/, &(LDA), 0/*B*/, &(LDB), &libxsmm_tiled_xgemm_beta_, 0/*C*/, &(LDC)); \\\n        fprintf(stderr, \"\\n\"); \\\n        LIBXSMM_FUNLOCK(stderr); \\\n      } \\\n      else { /* dump matrices */ \\\n        libxsmm_gemm_print(0, LIBXSMM_GEMM_PRECISION(TYPE), \\\n          &libxsmm_tiled_xgemm_transa_, &libxsmm_tiled_xgemm_transb_, &(MM), &(NN), &(KK), \\\n          &libxsmm_tiled_xgemm_alpha_, A, &(LDA), B, &(LDB), &libxsmm_tiled_xgemm_beta_, C, &(LDC)); \\\n      } \\\n    }\n#endif\n\n#define LIBXSMM_TILED_XGEMM(PARALLEL, LOOP_START, KERNEL_START, SYNC, \\\n  MIN_TASKS, OVERHEAD, NT, TYPE, FLAGS, TILE_M, TILE_N, TILE_K, MM, NN, KK, ALPHA, A, LDA, B, LDB, BETA, C, LDC) \\\n{ /* use NN, etc. rather than N due to below char. constant */ \\\n  libxsmm_blasint libxsmm_tiled_xgemm_tm_ = 0, libxsmm_tiled_xgemm_tn_ = 0, libxsmm_tiled_xgemm_tk_ = 0; \\\n  libxsmm_blasint libxsmm_tiled_xgemm_num_m_ = 0, libxsmm_tiled_xgemm_num_n_ = 0, libxsmm_tiled_xgemm_num_k_ = 0; \\\n  libxsmm_xmmfunction libxsmm_tiled_xgemm_kernel_ = { 0 }; \\\n  if (0 != LIBXSMM_GEMM_NO_BYPASS(FLAGS, ALPHA, BETA)) { \\\n    assert(0 != (TILE_M) && 0 != (TILE_N) && 0 != (TILE_K)); \\\n    libxsmm_tiled_xgemm_num_m_ = ((MM) + (TILE_M) - 1) / (TILE_M); \\\n    libxsmm_tiled_xgemm_num_n_ = ((NN) + (TILE_N) - 1) / (TILE_N); \\\n    libxsmm_tiled_xgemm_num_k_ = ((KK) + (TILE_K) - 1) / (TILE_K); \\\n    { /* opening scope for additional variable declarations */ \\\n      const libxsmm_blasint libxsmm_tiled_xgemm_num_t_ = (OVERHEAD(NT) < libxsmm_tiled_xgemm_num_k_ && 1 < (LIBXSMM_GEMM_COLLAPSE)) \\\n        ? (libxsmm_tiled_xgemm_num_m_ * libxsmm_tiled_xgemm_num_n_) \\\n        : (libxsmm_tiled_xgemm_num_n_ <= libxsmm_tiled_xgemm_num_m_ ? libxsmm_tiled_xgemm_num_m_ : libxsmm_tiled_xgemm_num_n_); \\\n      const libxsmm_blasint libxsmm_tiled_xgemm_min_ntasks_ = MIN_TASKS(NT); \\\n      libxsmm_gemm_descriptor libxsmm_tiled_xgemm_desc_ = { 0 }; \\\n      if (libxsmm_tiled_xgemm_min_ntasks_ <= libxsmm_tiled_xgemm_num_t_) { /* ensure enough parallel slack */ \\\n        assert(0 != libxsmm_tiled_xgemm_num_m_ && 0 != libxsmm_tiled_xgemm_num_n_); \\\n        libxsmm_tiled_xgemm_tm_ = (MM) / libxsmm_tiled_xgemm_num_m_; \\\n        libxsmm_tiled_xgemm_tn_ = (NN) / libxsmm_tiled_xgemm_num_n_; \\\n      } \\\n      else if (OVERHEAD(NT) < libxsmm_tiled_xgemm_num_k_) { \\\n        const libxsmm_blasint libxsmm_tiled_xgemm_ratio_ = LIBXSMM_SQRT2(libxsmm_tiled_xgemm_min_ntasks_ / libxsmm_tiled_xgemm_num_t_); \\\n        libxsmm_tiled_xgemm_tn_ = (libxsmm_tiled_xgemm_num_n_ * libxsmm_tiled_xgemm_ratio_); \\\n        libxsmm_tiled_xgemm_tm_ = (libxsmm_tiled_xgemm_min_ntasks_ + libxsmm_tiled_xgemm_tn_ - 1) / libxsmm_tiled_xgemm_tn_; \\\n      } \\\n      else if (libxsmm_tiled_xgemm_num_n_ <= libxsmm_tiled_xgemm_num_m_) { \\\n        libxsmm_tiled_xgemm_tm_ = ((MM) + libxsmm_tiled_xgemm_min_ntasks_ - 1) / libxsmm_tiled_xgemm_min_ntasks_; \\\n        libxsmm_tiled_xgemm_tn_ = TILE_N; \\\n      } \\\n      else { \\\n        libxsmm_tiled_xgemm_tm_ = TILE_M; \\\n        libxsmm_tiled_xgemm_tn_ = ((NN) + libxsmm_tiled_xgemm_min_ntasks_ - 1) / libxsmm_tiled_xgemm_min_ntasks_; \\\n      } \\\n      libxsmm_tiled_xgemm_tk_ = TILE_K; \\\n      { /* adjust for non-square operand shapes */ \\\n        float libxsmm_tiled_xgemm_rm_ = 1.f, libxsmm_tiled_xgemm_rn_ = ((float)(NN)) / (MM), libxsmm_tiled_xgemm_rk_ = ((float)(KK)) / (MM); \\\n        if (1.f < libxsmm_tiled_xgemm_rn_) { libxsmm_tiled_xgemm_rm_ /= libxsmm_tiled_xgemm_rn_; libxsmm_tiled_xgemm_rn_ = 1.f; libxsmm_tiled_xgemm_rk_ /= libxsmm_tiled_xgemm_rn_; } \\\n        if (1.f < libxsmm_tiled_xgemm_rk_) { libxsmm_tiled_xgemm_rm_ /= libxsmm_tiled_xgemm_rk_; libxsmm_tiled_xgemm_rn_ /= libxsmm_tiled_xgemm_rk_; libxsmm_tiled_xgemm_rk_ = 1.f; } \\\n        libxsmm_tiled_xgemm_tm_ = (libxsmm_blasint)(libxsmm_tiled_xgemm_tm_ * libxsmm_tiled_xgemm_rm_ /*+ 0.5f*/); \\\n        libxsmm_tiled_xgemm_tn_ = (libxsmm_blasint)(libxsmm_tiled_xgemm_tn_ * libxsmm_tiled_xgemm_rn_ /*+ 0.5f*/); \\\n        libxsmm_tiled_xgemm_tk_ = (libxsmm_blasint)(libxsmm_tiled_xgemm_tk_ * libxsmm_tiled_xgemm_rk_ /*+ 0.5f*/); \\\n        libxsmm_tiled_xgemm_tm_ = (libxsmm_blasint)(1ULL << LIBXSMM_LOG2(libxsmm_tiled_xgemm_tm_)); \\\n        libxsmm_tiled_xgemm_tn_ = (libxsmm_blasint)(1ULL << LIBXSMM_LOG2(libxsmm_tiled_xgemm_tn_)); \\\n        libxsmm_tiled_xgemm_tk_ = (libxsmm_blasint)(1ULL << LIBXSMM_LOG2(libxsmm_tiled_xgemm_tk_)); \\\n        libxsmm_tiled_xgemm_tm_ = LIBXSMM_CLMP(libxsmm_tiled_xgemm_tm_, 8, MM); \\\n        libxsmm_tiled_xgemm_tn_ = LIBXSMM_CLMP(libxsmm_tiled_xgemm_tn_, 8, NN); \\\n        libxsmm_tiled_xgemm_tk_ = LIBXSMM_CLMP(libxsmm_tiled_xgemm_tk_, 8, KK); \\\n      } \\\n      LIBXSMM_GEMM_DESCRIPTOR(libxsmm_tiled_xgemm_desc_, LIBXSMM_GEMM_PRECISION(TYPE), FLAGS, \\\n        libxsmm_tiled_xgemm_tm_, libxsmm_tiled_xgemm_tn_, libxsmm_tiled_xgemm_tk_, \\\n        LDA, LDB, LDC, ALPHA, 1/*beta*/, libxsmm_gemm_tiled_prefetch); \\\n      libxsmm_tiled_xgemm_kernel_ = libxsmm_xmmdispatch(&libxsmm_tiled_xgemm_desc_); \\\n    } \\\n  } \\\n  if (0 != libxsmm_tiled_xgemm_kernel_.LIBXSMM_TPREFIX(TYPE, mm)) { assert(0 != libxsmm_tiled_xgemm_tk_); { \\\n    const int libxsmm_tiled_xgemm_amortized_ = (OVERHEAD(NT) * libxsmm_tiled_xgemm_tn_) < (KK); \\\n    const libxsmm_blasint libxsmm_tiled_xgemm_max_k_ = ((KK) / libxsmm_tiled_xgemm_tk_) * libxsmm_tiled_xgemm_tk_; \\\n    libxsmm_blasint libxsmm_tiled_xgemm_m_ = MM, libxsmm_tiled_xgemm_n_ = NN; \\\n    libxsmm_blasint libxsmm_tiled_xgemm_dm_ = libxsmm_tiled_xgemm_tm_, libxsmm_tiled_xgemm_dn_ = libxsmm_tiled_xgemm_tn_; \\\n    libxsmm_blasint libxsmm_tiled_xgemm_swap_ = 0; \\\n    if ((1 == (LIBXSMM_GEMM_COLLAPSE) || 0 == libxsmm_tiled_xgemm_amortized_) && \\\n      libxsmm_tiled_xgemm_tn_ * (MM) < libxsmm_tiled_xgemm_tm_ * (NN)) /* approx. of num_m < num_n */ \\\n    { \\\n      libxsmm_tiled_xgemm_swap_ = libxsmm_tiled_xgemm_dm_; libxsmm_tiled_xgemm_dm_ = libxsmm_tiled_xgemm_dn_; libxsmm_tiled_xgemm_dn_ = libxsmm_tiled_xgemm_swap_; \\\n      libxsmm_tiled_xgemm_swap_ = libxsmm_tiled_xgemm_m_; libxsmm_tiled_xgemm_m_ = libxsmm_tiled_xgemm_n_; libxsmm_tiled_xgemm_n_ = libxsmm_tiled_xgemm_swap_; \\\n    } \\\n    if (0 != libxsmm_tiled_xgemm_amortized_) { /* amortized overhead */ \\\n      PARALLEL \\\n      { \\\n        libxsmm_blasint libxsmm_tiled_xgemm_i_, libxsmm_tiled_xgemm_j_ = 0; \\\n        LOOP_START(LIBXSMM_GEMM_COLLAPSE) \\\n        for (libxsmm_tiled_xgemm_i_ = 0; libxsmm_tiled_xgemm_i_ < libxsmm_tiled_xgemm_m_; libxsmm_tiled_xgemm_i_ += libxsmm_tiled_xgemm_dm_) { \\\n          for (libxsmm_tiled_xgemm_j_ = 0; libxsmm_tiled_xgemm_j_ < libxsmm_tiled_xgemm_n_; libxsmm_tiled_xgemm_j_ += libxsmm_tiled_xgemm_dn_) { \\\n            KERNEL_START(firstprivate(libxsmm_tiled_xgemm_i_, libxsmm_tiled_xgemm_j_)) \\\n            LIBXSMM_GEMM_TILED_KERNEL(libxsmm_tiled_xgemm_kernel_, TYPE, FLAGS, \\\n              0 == libxsmm_tiled_xgemm_swap_ ? libxsmm_tiled_xgemm_i_ : libxsmm_tiled_xgemm_j_, \\\n              0 == libxsmm_tiled_xgemm_swap_ ? libxsmm_tiled_xgemm_j_ : libxsmm_tiled_xgemm_i_, \\\n              libxsmm_tiled_xgemm_max_k_, libxsmm_tiled_xgemm_tm_, libxsmm_tiled_xgemm_tn_, libxsmm_tiled_xgemm_tk_, \\\n              MM, NN, KK, ALPHA, A, LDA, B, LDB, BETA, C, LDC); \\\n          } \\\n        } \\\n      } \\\n    } \\\n    else { \\\n      PARALLEL \\\n      { \\\n        libxsmm_blasint libxsmm_tiled_xgemm_i_, libxsmm_tiled_xgemm_j_ = 0; \\\n        LOOP_START(1/*COLLAPSE*/) \\\n        for (libxsmm_tiled_xgemm_i_ = 0; libxsmm_tiled_xgemm_i_ < libxsmm_tiled_xgemm_m_; libxsmm_tiled_xgemm_i_ += libxsmm_tiled_xgemm_dm_) { \\\n          KERNEL_START(firstprivate(libxsmm_tiled_xgemm_i_)) \\\n          for (libxsmm_tiled_xgemm_j_ = 0; libxsmm_tiled_xgemm_j_ < libxsmm_tiled_xgemm_n_; libxsmm_tiled_xgemm_j_ += libxsmm_tiled_xgemm_dn_) { \\\n            LIBXSMM_GEMM_TILED_KERNEL(libxsmm_tiled_xgemm_kernel_, TYPE, FLAGS, \\\n              0 == libxsmm_tiled_xgemm_swap_ ? libxsmm_tiled_xgemm_i_ : libxsmm_tiled_xgemm_j_, \\\n              0 == libxsmm_tiled_xgemm_swap_ ? libxsmm_tiled_xgemm_j_ : libxsmm_tiled_xgemm_i_, \\\n              libxsmm_tiled_xgemm_max_k_, libxsmm_tiled_xgemm_tm_, libxsmm_tiled_xgemm_tn_, libxsmm_tiled_xgemm_tk_, \\\n              MM, NN, KK, ALPHA, A, LDA, B, LDB, BETA, C, LDC); \\\n          } \\\n        } \\\n      } \\\n    } \\\n    SYNC \\\n  }} \\\n  else { /* fall-back */ \\\n    assert(0 == LIBXSMM_NO_BLAS); \\\n    LIBXSMM_FALLBACK1(TYPE, libxsmm_blasint, FLAGS, MM, NN, KK, ALPHA, A, LDA, B, LDB, BETA, C, LDC); \\\n    LIBXSMM_TILED_XGEMM_FALLBACK_PRINT(TYPE, FLAGS, MM, NN, KK, ALPHA, A, LDA, B, LDB, BETA, C, LDC); \\\n  } \\\n}\n\n#if (!defined(__BLAS) || (0 != __BLAS))\n# define LIBXSMM_GEMM_WRAPPER_BLAS(TYPE, ORIGINAL, CALLER, SYMBOL) if (0 == (ORIGINAL)) { \\\n    union { const void* pv; LIBXSMM_GEMMFUNCTION_TYPE(TYPE) pf; \\\n      void (*sf)(LIBXSMM_GEMM_CONST char*, LIBXSMM_GEMM_CONST char*, \\\n        LIBXSMM_GEMM_CONST LIBXSMM_BLASINT*, LIBXSMM_GEMM_CONST LIBXSMM_BLASINT*, LIBXSMM_GEMM_CONST LIBXSMM_BLASINT*, \\\n        LIBXSMM_GEMM_CONST float*, LIBXSMM_GEMM_CONST float*, LIBXSMM_GEMM_CONST LIBXSMM_BLASINT*, LIBXSMM_GEMM_CONST float*, LIBXSMM_GEMM_CONST LIBXSMM_BLASINT*, \\\n        LIBXSMM_GEMM_CONST float*, float*, LIBXSMM_GEMM_CONST LIBXSMM_BLASINT*); \\\n      void (*df)(LIBXSMM_GEMM_CONST char*, LIBXSMM_GEMM_CONST char*, \\\n        LIBXSMM_GEMM_CONST LIBXSMM_BLASINT*, LIBXSMM_GEMM_CONST LIBXSMM_BLASINT*, LIBXSMM_GEMM_CONST LIBXSMM_BLASINT*, \\\n        LIBXSMM_GEMM_CONST double*, LIBXSMM_GEMM_CONST double*, LIBXSMM_GEMM_CONST LIBXSMM_BLASINT*, LIBXSMM_GEMM_CONST double*, LIBXSMM_GEMM_CONST LIBXSMM_BLASINT*, \\\n        LIBXSMM_GEMM_CONST double*, double*, LIBXSMM_GEMM_CONST LIBXSMM_BLASINT*); \\\n    } libxsmm_gemm_wrapper_blas_; \\\n    libxsmm_gemm_wrapper_blas_.LIBXSMM_TPREFIX(TYPE,f) = (SYMBOL); \\\n    if (libxsmm_gemm_wrapper_blas_.pv != (CALLER)) { \\\n      /*LIBXSMM_ATOMIC(LIBXSMM_ATOMIC_STORE, LIBXSMM_BITS)(&(ORIGINAL), libxsmm_gemm_wrapper_blas_.pf, LIBXSMM_ATOMIC_RELAXED);*/ \\\n      ORIGINAL = libxsmm_gemm_wrapper_blas_.pf; \\\n    } \\\n  }\n# define LIBXSMM_GEMV_WRAPPER_BLAS(TYPE, ORIGINAL, CALLER, SYMBOL) if (0 == (ORIGINAL)) { \\\n    union { const void* pv; LIBXSMM_GEMVFUNCTION_TYPE(TYPE) pf; \\\n      void (*sf)(LIBXSMM_GEMM_CONST char*, \\\n        LIBXSMM_GEMM_CONST LIBXSMM_BLASINT*, LIBXSMM_GEMM_CONST LIBXSMM_BLASINT*, \\\n        LIBXSMM_GEMM_CONST float*, LIBXSMM_GEMM_CONST float*, LIBXSMM_GEMM_CONST LIBXSMM_BLASINT*, LIBXSMM_GEMM_CONST float*, LIBXSMM_GEMM_CONST LIBXSMM_BLASINT*, \\\n        LIBXSMM_GEMM_CONST float*, float*, LIBXSMM_GEMM_CONST LIBXSMM_BLASINT*); \\\n      void (*df)(LIBXSMM_GEMM_CONST char*, \\\n        LIBXSMM_GEMM_CONST LIBXSMM_BLASINT*, LIBXSMM_GEMM_CONST LIBXSMM_BLASINT*, \\\n        LIBXSMM_GEMM_CONST double*, LIBXSMM_GEMM_CONST double*, LIBXSMM_GEMM_CONST LIBXSMM_BLASINT*, LIBXSMM_GEMM_CONST double*, LIBXSMM_GEMM_CONST LIBXSMM_BLASINT*, \\\n        LIBXSMM_GEMM_CONST double*, double*, LIBXSMM_GEMM_CONST LIBXSMM_BLASINT*); \\\n    } libxsmm_gemv_wrapper_blas_; \\\n    libxsmm_gemv_wrapper_blas_.LIBXSMM_TPREFIX(TYPE,f) = (SYMBOL); \\\n    if (libxsmm_gemv_wrapper_blas_.pv != (CALLER)) { \\\n      /*LIBXSMM_ATOMIC(LIBXSMM_ATOMIC_STORE, LIBXSMM_BITS)(&(ORIGINAL), libxsmm_gemv_wrapper_blas_.pf, LIBXSMM_ATOMIC_RELAXED);*/ \\\n      ORIGINAL = libxsmm_gemv_wrapper_blas_.pf; \\\n    } \\\n  }\n#else\n# define LIBXSMM_GEMM_WRAPPER_BLAS(TYPE, ORIGINAL, CALLER, SYMBOL) LIBXSMM_UNUSED(CALLER)\n# define LIBXSMM_GEMV_WRAPPER_BLAS(TYPE, ORIGINAL, CALLER, SYMBOL) LIBXSMM_UNUSED(CALLER)\n#endif\n\n#if defined(LIBXSMM_GEMM_WRAP) && defined(LIBXSMM_BUILD) && defined(LIBXSMM_BUILD_EXT) && \\\n  !(defined(__APPLE__) && defined(__MACH__) /*&& defined(__clang__)*/) && !defined(__CYGWIN__)\n# if (2 != (LIBXSMM_GEMM_WRAP)) /* SGEMM and DGEMM */\n#   define LIBXSMM_GEMM_WRAPPER_STATIC(TYPE, ORIGINAL, CALLER) LIBXSMM_GEMM_WRAPPER_BLAS(TYPE, ORIGINAL, CALLER, \\\n      LIBXSMM_FSYMBOL(LIBXSMM_CONCATENATE(__real_, LIBXSMM_TPREFIX(TYPE, gemm))))\n#   define LIBXSMM_GEMV_WRAPPER_STATIC(TYPE, ORIGINAL, CALLER) LIBXSMM_GEMM_WRAPPER_BLAS(TYPE, ORIGINAL, CALLER, \\\n      LIBXSMM_FSYMBOL(LIBXSMM_CONCATENATE(__real_, LIBXSMM_TPREFIX(TYPE, gemv))))\n# else /* DGEMM only */\n#   define LIBXSMM_GEMM_WRAPPER_STATIC(TYPE, ORIGINAL, CALLER) if (0 != LIBXSMM_EQUAL(TYPE, double)) { \\\n      LIBXSMM_GEMM_WRAPPER_BLAS(TYPE, ORIGINAL, CALLER, LIBXSMM_FSYMBOL(__real_dgemm)) \\\n    }\n#   define LIBXSMM_GEMV_WRAPPER_STATIC(TYPE, ORIGINAL, CALLER) if (0 != LIBXSMM_EQUAL(TYPE, double)) { \\\n      LIBXSMM_GEMM_WRAPPER_BLAS(TYPE, ORIGINAL, CALLER, LIBXSMM_FSYMBOL(__real_dgemv)) \\\n    }\n# endif\n# define LIBXSMM_GEMM_WRAP_STATIC\n#else\n# define LIBXSMM_GEMM_WRAPPER_STATIC(TYPE, ORIGINAL, CALLER)\n# define LIBXSMM_GEMV_WRAPPER_STATIC(TYPE, ORIGINAL, CALLER)\n#endif\n\n#if defined(LIBXSMM_GEMM_WRAP_DYNAMIC)\n# define LIBXSMM_GEMM_WRAPPER_DYNAMIC(TYPE, ORIGINAL, CALLER) \\\n    if (0 == (ORIGINAL)) { \\\n      union { const void* pv; LIBXSMM_GEMMFUNCTION_TYPE(TYPE) pf; } libxsmm_gemm_wrapper_dynamic_ = { 0 }; \\\n      dlerror(); /* clear an eventual error status */ \\\n      libxsmm_gemm_wrapper_dynamic_.pv = dlsym(RTLD_NEXT, LIBXSMM_STRINGIFY(LIBXSMM_GEMM_SYMBOL(TYPE))); \\\n      if (libxsmm_gemm_wrapper_dynamic_.pv != (CALLER)) { \\\n        /*LIBXSMM_ATOMIC_STORE(&(ORIGINAL), libxsmm_gemm_wrapper_dynamic_.pf, LIBXSMM_ATOMIC_RELAXED);*/ \\\n        ORIGINAL = libxsmm_gemm_wrapper_dynamic_.pf; \\\n      } \\\n      LIBXSMM_GEMM_WRAPPER_BLAS(TYPE, ORIGINAL, CALLER, LIBXSMM_GEMM_SYMBOL(TYPE)); \\\n    }\n# define LIBXSMM_GEMV_WRAPPER_DYNAMIC(TYPE, ORIGINAL, CALLER) \\\n    if (0 == (ORIGINAL)) { \\\n      union { const void* pv; LIBXSMM_GEMVFUNCTION_TYPE(TYPE) pf; } libxsmm_gemv_wrapper_dynamic_ = { 0 }; \\\n      dlerror(); /* clear an eventual error status */ \\\n      libxsmm_gemv_wrapper_dynamic_.pv = dlsym(RTLD_NEXT, LIBXSMM_STRINGIFY(LIBXSMM_GEMV_SYMBOL(TYPE))); \\\n      if (libxsmm_gemv_wrapper_dynamic_.pv != (CALLER)) { \\\n        /*LIBXSMM_ATOMIC_STORE(&(ORIGINAL), libxsmm_gemv_wrapper_dynamic_.pf, LIBXSMM_ATOMIC_RELAXED);*/ \\\n        ORIGINAL = libxsmm_gemv_wrapper_dynamic_.pf; \\\n      } \\\n      LIBXSMM_GEMV_WRAPPER_BLAS(TYPE, ORIGINAL, CALLER, LIBXSMM_GEMV_SYMBOL(TYPE)); \\\n    }\n#else\n# define LIBXSMM_GEMM_WRAPPER_DYNAMIC(TYPE, ORIGINAL, CALLER) LIBXSMM_GEMM_WRAPPER_BLAS( \\\n    TYPE, ORIGINAL, CALLER, LIBXSMM_GEMM_SYMBOL(TYPE))\n# define LIBXSMM_GEMV_WRAPPER_DYNAMIC(TYPE, ORIGINAL, CALLER) LIBXSMM_GEMV_WRAPPER_BLAS( \\\n    TYPE, ORIGINAL, CALLER, LIBXSMM_GEMV_SYMBOL(TYPE))\n#endif\n\n#if defined(NDEBUG) /* library code is expected to be mute */\n# define LIBXSMM_GEMM_WRAPPER(TYPE, ORIGINAL, CALLER) if (0 == (ORIGINAL)) { \\\n    LIBXSMM_GEMM_WRAPPER_STATIC(TYPE, ORIGINAL, CALLER); \\\n    LIBXSMM_GEMM_WRAPPER_DYNAMIC(TYPE, ORIGINAL, CALLER); \\\n  }\n#else\n# define LIBXSMM_GEMM_WRAPPER(TYPE, ORIGINAL, CALLER) if (0 == (ORIGINAL)) { \\\n    LIBXSMM_GEMM_WRAPPER_STATIC(TYPE, ORIGINAL, CALLER); \\\n    LIBXSMM_GEMM_WRAPPER_DYNAMIC(TYPE, ORIGINAL, CALLER); \\\n    if (0 == (ORIGINAL)) { \\\n      static int libxsmm_gemm_wrapper_error_once_ = 0; \\\n      if (1 == LIBXSMM_ATOMIC_ADD_FETCH(&libxsmm_gemm_wrapper_error_once_, 1, LIBXSMM_ATOMIC_RELAXED)) { \\\n        fprintf(stderr, \"LIBXSMM ERROR: application must be linked against LAPACK/BLAS!\\n\"); \\\n      } \\\n    } \\\n  }\n#endif\n\n\n/** Provides GEMM functions available via BLAS; NOT thread-safe. */\nLIBXSMM_API void libxsmm_gemm_init(int archid);\n\n/** Finalizes the GEMM facility; NOT thread-safe. */\nLIBXSMM_API void libxsmm_gemm_finalize(void);\n\nLIBXSMM_API unsigned char libxsmm_gemm_typesize(libxsmm_gemm_precision precision);\n\nLIBXSMM_API int libxsmm_gemm_prefetch2uid(libxsmm_gemm_prefetch_type prefetch);\nLIBXSMM_API libxsmm_gemm_prefetch_type libxsmm_gemm_uid2prefetch(int uid);\n\nLIBXSMM_API int libxsmm_dgemm_descriptor_init(libxsmm_gemm_descriptor* descriptor,\n  libxsmm_blasint m, libxsmm_blasint n, libxsmm_blasint k,\n  libxsmm_blasint lda, libxsmm_blasint ldb, libxsmm_blasint ldc,\n  double alpha, double beta, int flags, int prefetch);\nLIBXSMM_API int libxsmm_sgemm_descriptor_init(libxsmm_gemm_descriptor* descriptor,\n  libxsmm_blasint m, libxsmm_blasint n, libxsmm_blasint k,\n  libxsmm_blasint lda, libxsmm_blasint ldb, libxsmm_blasint ldc,\n  float alpha, float beta, int flags, int prefetch);\nLIBXSMM_API int libxsmm_wgemm_descriptor_init(libxsmm_gemm_descriptor* descriptor,\n  libxsmm_blasint m, libxsmm_blasint n, libxsmm_blasint k,\n  libxsmm_blasint lda, libxsmm_blasint ldb, libxsmm_blasint ldc,\n  int alpha, int beta, int flags, int prefetch);\n\n#if defined(LIBXSMM_GEMM_WRAP_STATIC)\nLIBXSMM_API void LIBXSMM_FSYMBOL(__real_sgemm)(\n  const char*, const char*, const libxsmm_blasint*, const libxsmm_blasint*, const libxsmm_blasint*,\n  const float*, const float*, const libxsmm_blasint*, const float* b, const libxsmm_blasint*,\n  const float*, float*, const libxsmm_blasint*);\nLIBXSMM_API void LIBXSMM_FSYMBOL(__real_dgemm)(\n  const char*, const char*, const libxsmm_blasint*, const libxsmm_blasint*, const libxsmm_blasint*,\n  const double*, const double*, const libxsmm_blasint*, const double* b, const libxsmm_blasint*,\n  const double*, double*, const libxsmm_blasint*);\n#endif /*defined(LIBXSMM_GEMM_WRAP_STATIC)*/\n\n#if defined(LIBXSMM_BUILD) && defined(LIBXSMM_BUILD_EXT)\nLIBXSMM_API void LIBXSMM_FSYMBOL(__wrap_sgemm)(\n  const char*, const char*, const libxsmm_blasint*, const libxsmm_blasint*, const libxsmm_blasint*,\n  const float*, const float*, const libxsmm_blasint*, const float* b, const libxsmm_blasint*,\n  const float*, float*, const libxsmm_blasint*);\nLIBXSMM_API void LIBXSMM_FSYMBOL(__wrap_dgemm)(\n  const char*, const char*, const libxsmm_blasint*, const libxsmm_blasint*, const libxsmm_blasint*,\n  const double*, const double*, const libxsmm_blasint*, const double* b, const libxsmm_blasint*,\n  const double*, double*, const libxsmm_blasint*);\n#endif\n\nLIBXSMM_GEMM_SYMBOL_DECL(LIBXSMM_GEMM_CONST, float);\nLIBXSMM_GEMM_SYMBOL_DECL(LIBXSMM_GEMM_CONST, double);\n\nLIBXSMM_EXTERN_C typedef union LIBXSMM_RETARGETABLE libxsmm_gemm_batchitem {\n  struct {\n    const void *a, *b;\n    void *c;\n  } value;\n  struct {\n    libxsmm_gemm_descriptor desc;\n    unsigned int count;\n    const char* symbol;\n  } stat;\n  /* TODO: consider padding */\n} libxsmm_gemm_batchitem;\n\nLIBXSMM_API int libxsmm_mmbatch_internal(libxsmm_xmmfunction kernel, libxsmm_blasint index_base, libxsmm_blasint index_stride,\n  const libxsmm_blasint stride_a[], const libxsmm_blasint stride_b[], const libxsmm_blasint stride_c[],\n  const void* a, const void* b, void* c, libxsmm_blasint batchsize, int tid, int nthreads,\n  const libxsmm_gemm_descriptor* info);\n\nLIBXSMM_API int libxsmm_dmmbatch_blas(const char* transa, const char* transb, libxsmm_blasint m, libxsmm_blasint n, libxsmm_blasint k,\n  const double* alpha, const void* a, const libxsmm_blasint* lda, const void* b, const libxsmm_blasint* ldb, const double* beta, void* c, const libxsmm_blasint* ldc,\n  libxsmm_blasint index_base, libxsmm_blasint index_stride, const libxsmm_blasint stride_a[], const libxsmm_blasint stride_b[], const libxsmm_blasint stride_c[],\n  libxsmm_blasint batchsize);\nLIBXSMM_API int libxsmm_smmbatch_blas(const char* transa, const char* transb, libxsmm_blasint m, libxsmm_blasint n, libxsmm_blasint k,\n  const float* alpha, const void* a, const libxsmm_blasint* lda, const void* b, const libxsmm_blasint* ldb, const float* beta, void* c, const libxsmm_blasint* ldc,\n  libxsmm_blasint index_base, libxsmm_blasint index_stride, const libxsmm_blasint stride_a[], const libxsmm_blasint stride_b[], const libxsmm_blasint stride_c[],\n  libxsmm_blasint batchsize);\n\nLIBXSMM_EXTERN_C typedef void (*libxsmm_mmbatch_flush_function)(void);\n\n/** Configuration table containing the tile sizes separate for DP and SP. */\nLIBXSMM_API_VARIABLE(/*const*/ unsigned int (*libxsmm_gemm_tile)[3/*M,N,K*/][8/*size-range*/]);\n/** auto-batch descriptor (filter). */\nLIBXSMM_API_VARIABLE(libxsmm_gemm_descriptor libxsmm_gemm_batchdesc);\n/** Records a batch of SMMs. */\nLIBXSMM_API_VARIABLE(libxsmm_gemm_batchitem* libxsmm_gemm_batcharray);\n/** Lock: libxsmm_mmbatch_begin, libxsmm_mmbatch_end, internal_mmbatch_flush. */\nLIBXSMM_API_VARIABLE(LIBXSMM_LOCK_TYPE(LIBXSMM_GEMM_LOCK) libxsmm_gemm_batchlock);\n/** Maximum size of the recorded batch. */\nLIBXSMM_API_VARIABLE(unsigned int libxsmm_gemm_batchsize);\n/** Grain/chunk size when processing batches. */\nLIBXSMM_API_VARIABLE(int libxsmm_gemm_chunksize);\n/** Determines the default prefetch strategy, which is used in case of LIBXSMM_PREFETCH_AUTO. */\nLIBXSMM_API_VARIABLE(int libxsmm_gemm_auto_prefetch_default);\n/** Determines the prefetch strategy, which is used in case of LIBXSMM_PREFETCH_AUTO. */\nLIBXSMM_API_VARIABLE(int libxsmm_gemm_auto_prefetch);\n/** Prefetch strategy for tiled GEMM. */\nLIBXSMM_API_VARIABLE(int libxsmm_gemm_tiled_prefetch);\n/** Determines if OpenMP tasks are used. */\nLIBXSMM_API_VARIABLE(int libxsmm_gemm_tasks);\n/**\n * Intercepted GEMM\n * - odd: sequential and non-tiled (small problem sizes only)\n * - even (or negative): parallelized and tiled (all problem sizes)\n * - 3: GEMV is intercepted; small problem sizes\n * - 4: GEMV is intercepted; all problem sizes\n */\nLIBXSMM_API_VARIABLE(int libxsmm_gemm_wrap);\n\n#endif /*LIBXSMM_GEMM_H*/\n\n"
    },
    "skipped": [
        "/tmp/vanessa/spack-stage/spack-stage-libxsmm-1.8.3-5oxdpmrq6vevfdfgmhwzg36uxnjhprjk/spack-src/documentation/cp2k.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-libxsmm-1.8.3-5oxdpmrq6vevfdfgmhwzg36uxnjhprjk/spack-src/documentation/libxsmm.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-libxsmm-1.8.3-5oxdpmrq6vevfdfgmhwzg36uxnjhprjk/spack-src/documentation/libxsmm_prof-vtune.png",
        "/tmp/vanessa/spack-stage/spack-stage-libxsmm-1.8.3-5oxdpmrq6vevfdfgmhwzg36uxnjhprjk/spack-src/documentation/tensorflow.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-libxsmm-1.8.3-5oxdpmrq6vevfdfgmhwzg36uxnjhprjk/spack-src/documentation/libxsmm_samples.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-libxsmm-1.8.3-5oxdpmrq6vevfdfgmhwzg36uxnjhprjk/spack-src/tests/mhd_image.raw",
        "/tmp/vanessa/spack-stage/spack-stage-libxsmm-1.8.3-5oxdpmrq6vevfdfgmhwzg36uxnjhprjk/spack-src/samples/iconv/iconv_in.mhd"
    ],
    "total_files": 492
}