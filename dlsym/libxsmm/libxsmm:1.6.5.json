{
    "matches": {
        "/tmp/vanessa/spack-stage/spack-stage-libxsmm-1.6.5-teyur5jco62o7r5e65g54hrwpqzooo2r/spack-src/src/libxsmm_gemm.h": "/******************************************************************************\n** Copyright (c) 2015-2017, Intel Corporation                                **\n** All rights reserved.                                                      **\n**                                                                           **\n** Redistribution and use in source and binary forms, with or without        **\n** modification, are permitted provided that the following conditions        **\n** are met:                                                                  **\n** 1. Redistributions of source code must retain the above copyright         **\n**    notice, this list of conditions and the following disclaimer.          **\n** 2. Redistributions in binary form must reproduce the above copyright      **\n**    notice, this list of conditions and the following disclaimer in the    **\n**    documentation and/or other materials provided with the distribution.   **\n** 3. Neither the name of the copyright holder nor the names of its          **\n**    contributors may be used to endorse or promote products derived        **\n**    from this software without specific prior written permission.          **\n**                                                                           **\n** THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS       **\n** \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT         **\n** LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR     **\n** A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT      **\n** HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,    **\n** SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED  **\n** TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR    **\n** PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF    **\n** LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING      **\n** NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS        **\n** SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.              **\n******************************************************************************/\n/* Hans Pabst (Intel Corp.)\n******************************************************************************/\n#ifndef LIBXSMM_GEMM_H\n#define LIBXSMM_GEMM_H\n\n#include <libxsmm.h>\n\n#if defined(LIBXSMM_OFFLOAD_TARGET)\n# pragma offload_attribute(push,target(LIBXSMM_OFFLOAD_TARGET))\n#endif\n#if !defined(LIBXSMM_GEMM_WRAP_DYNAMIC) && defined(LIBXSMM_BUILD) && \\\n  (!defined(__BLAS) || (0 != __BLAS)) && defined(__GNUC__) && \\\n  !(defined(__APPLE__) && defined(__MACH__) && LIBXSMM_VERSION3(6, 1, 0) >= \\\n    LIBXSMM_VERSION3(__clang_major__, __clang_minor__, __clang_patchlevel__)) && \\\n  !defined(_WIN32) && !defined(__CYGWIN__)\n# include <dlfcn.h>\n# define LIBXSMM_GEMM_WRAP_DYNAMIC\n#endif\n#include <stdio.h>\n#include <math.h>\n#if defined(LIBXSMM_OFFLOAD_TARGET)\n# pragma offload_attribute(pop)\n#endif\n\n/** Undefine (disarm) MKL's DIRECT_CALL macros. */\n#if defined(MKL_DIRECT_CALL_SEQ) || defined(MKL_DIRECT_CALL)\n# if defined(sgemm_)\n#   undef sgemm_\n# endif\n# if defined(dgemm_)\n#   undef dgemm_\n# endif\n#endif\n\n#if !defined(LIBXSMM_GEMM_COLLAPSE)\n# define LIBXSMM_GEMM_COLLAPSE 2\n#endif\n\n/** Enable tiled GEMM in non-ext. library */\n#if !defined(LIBXSMM_GEMM_TILED)\n/*# define LIBXSMM_GEMM_TILED*/\n#endif\n\n#if !defined(LIBXSMM_NO_BLAS)\n# if !defined(__BLAS) || (0 != __BLAS)\n#   define LIBXSMM_NO_BLAS 0\n# else\n#   define LIBXSMM_NO_BLAS 1\n# endif\n#endif\n\n#if defined(_CRAYC)\n# define LIBXSMM_EXT_FOR_SINGLE LIBXSMM_NOOP\n#else\n# define LIBXSMM_EXT_FOR_SINGLE LIBXSMM_EXT_SINGLE\n#endif\n\n#define LIBXSMM_GEMM_TILED_ABOVE_THRESHOLD(M, N, K) \\\n  (((LIBXSMM_MAX_M < (M)) || \\\n    (LIBXSMM_MAX_N < (N)) || \\\n    (LIBXSMM_MAX_K < (K))) ? 1 : 0)\n\n#define LIBXSMM_GEMM_NO_BYPASS(FLAGS, ALPHA, BETA) ( \\\n  0 == ((FLAGS) & (LIBXSMM_GEMM_FLAG_TRANS_A | LIBXSMM_GEMM_FLAG_TRANS_B)) && \\\n        (LIBXSMM_FEQ(1, ALPHA) /*|| LIBXSMM_FEQ(-1, ALPHA)*/) && \\\n        (LIBXSMM_FEQ(1, BETA) || LIBXSMM_FEQ(0, BETA)))\n\n#if !defined(LIBXSMM_GEMM_TILED_INNER_FALLBACK)\n# define LIBXSMM_GEMM_TILED_INNER_FALLBACK\n#endif\n#if defined(LIBXSMM_GEMM_TILED_INNER_FALLBACK)\n# define LIBXSMM_GEMM_TILED_FALLBACK_CHECK(CONDITION) if (CONDITION)\n# define LIBXSMM_GEMM_TILED_FALLBACK(TYPE, FLAGS, M, N, K, ALPHA, A, LDA, B, LDB, BETA, C, LDC) else { \\\n    LIBXSMM_FALLBACK0(TYPE, libxsmm_blasint, FLAGS, M, N, K, ALPHA, A, LDA, B, LDB, BETA, C, LDC); \\\n  }\n#else\n# define LIBXSMM_GEMM_TILED_FALLBACK_CHECK(CONDITION)\n# define LIBXSMM_GEMM_TILED_FALLBACK(TYPE, FLAGS, TILE_M, TILE_N, TILE_K, ALPHA, A, LDA, B, LDB, BETA, C, LDC)\n#endif\n\n#define LIBXSMM_GEMM_TILED_KERNEL(KERNEL_INNER_BETA1, TYPE, FLAGS, POS_I, POS_J, MAX_K, TILE_M, TILE_N, TILE_K, M, N, K, ALPHA, A, LDA, B, LDB, BETA, C, LDC) { \\\n  const libxsmm_blasint libxsmm_tiled_xgemm_kernel_tm_ = LIBXSMM_MIN(TILE_M, (M) - (POS_I)); \\\n  const libxsmm_blasint libxsmm_tiled_xgemm_kernel_tn_ = LIBXSMM_MIN(TILE_N, (N) - (POS_J)); \\\n  const libxsmm_blasint libxsmm_tiled_xgemm_kernel_tk_ = ((TILE_K) <= (K) ? (TILE_K) : ((K) - (MAX_K))); \\\n  const TYPE* libxsmm_tiled_xgemm_kernel_ia_ = (A) + (POS_I); \\\n  const TYPE* libxsmm_tiled_xgemm_kernel_ib_ = (B) + (POS_J) * (LDB); \\\n  const TYPE* libxsmm_tiled_xgemm_kernel_pa_ = libxsmm_tiled_xgemm_kernel_ia_ + (libxsmm_tiled_xgemm_kernel_tk_) * (LDA); \\\n  const TYPE* libxsmm_tiled_xgemm_kernel_pb_ = libxsmm_tiled_xgemm_kernel_ib_ + (libxsmm_tiled_xgemm_kernel_tk_); \\\n  TYPE *const libxsmm_tiled_xgemm_kernel_ic_ = (C) + (POS_J) * (LDC) + (POS_I), libxsmm_tiled_xgemm_kernel_beta_ = BETA; \\\n  libxsmm_gemm_descriptor libxsmm_tiled_xgemm_kernel_desc_; \\\n  libxsmm_xmmfunction libxsmm_gemm_tiled_kernel_ = { 0 }; \\\n  libxsmm_blasint libxsmm_tiled_xgemm_kernel_k_ = 0; \\\n  assert(0 != (A) && 0 != (B) && 0 != (C)); \\\n  if (((TILE_M) == libxsmm_tiled_xgemm_kernel_tm_) && ((TILE_N) == libxsmm_tiled_xgemm_kernel_tn_) && ((TILE_K) == libxsmm_tiled_xgemm_kernel_tk_)) { \\\n    if (libxsmm_tiled_xgemm_kernel_k_ < (MAX_K)) { /* peel */ \\\n      LIBXSMM_GEMM_DESCRIPTOR(libxsmm_tiled_xgemm_kernel_desc_, LIBXSMM_ALIGNMENT, FLAGS, TILE_M, TILE_N, TILE_K, \\\n        LDA, LDB, LDC, ALPHA, BETA, libxsmm_tiled_gemm_prefetch); \\\n      libxsmm_gemm_tiled_kernel_ = libxsmm_xmmdispatch(&libxsmm_tiled_xgemm_kernel_desc_); \\\n      LIBXSMM_GEMM_TILED_FALLBACK_CHECK(0 != libxsmm_gemm_tiled_kernel_.LIBXSMM_TPREFIX(TYPE, mm)) \\\n      { \\\n        LIBXSMM_MMCALL_PRF(libxsmm_gemm_tiled_kernel_.LIBXSMM_TPREFIX(TYPE, mm), \\\n          libxsmm_tiled_xgemm_kernel_ia_, libxsmm_tiled_xgemm_kernel_ib_, libxsmm_tiled_xgemm_kernel_ic_, \\\n          libxsmm_tiled_xgemm_kernel_pa_, libxsmm_tiled_xgemm_kernel_pb_, libxsmm_tiled_xgemm_kernel_ic_); \\\n      } \\\n      LIBXSMM_GEMM_TILED_FALLBACK(TYPE, FLAGS, TILE_M, TILE_N, TILE_K, \\\n        ALPHA, libxsmm_tiled_xgemm_kernel_ia_, LDA, libxsmm_tiled_xgemm_kernel_ib_, LDB, \\\n         BETA, libxsmm_tiled_xgemm_kernel_ic_, LDC); \\\n      libxsmm_tiled_xgemm_kernel_ia_ = libxsmm_tiled_xgemm_kernel_pa_; \\\n      libxsmm_tiled_xgemm_kernel_ib_ = libxsmm_tiled_xgemm_kernel_pb_; \\\n      libxsmm_tiled_xgemm_kernel_pa_ += (TILE_K) * (LDA); \\\n      libxsmm_tiled_xgemm_kernel_pb_ += TILE_K; \\\n      libxsmm_tiled_xgemm_kernel_k_ = TILE_K; \\\n      libxsmm_tiled_xgemm_kernel_beta_ = 1; \\\n    } \\\n    for (; libxsmm_tiled_xgemm_kernel_k_ < (MAX_K); libxsmm_tiled_xgemm_kernel_k_ += TILE_K) { /* inner */ \\\n      LIBXSMM_MMCALL_PRF((KERNEL_INNER_BETA1).LIBXSMM_TPREFIX(TYPE, mm), \\\n        libxsmm_tiled_xgemm_kernel_ia_, libxsmm_tiled_xgemm_kernel_ib_, libxsmm_tiled_xgemm_kernel_ic_, \\\n        libxsmm_tiled_xgemm_kernel_pa_, libxsmm_tiled_xgemm_kernel_pb_, libxsmm_tiled_xgemm_kernel_ic_); \\\n      libxsmm_tiled_xgemm_kernel_ia_ = libxsmm_tiled_xgemm_kernel_pa_; \\\n      libxsmm_tiled_xgemm_kernel_ib_ = libxsmm_tiled_xgemm_kernel_pb_; \\\n      libxsmm_tiled_xgemm_kernel_pa_ += (TILE_K) * (LDA); \\\n      libxsmm_tiled_xgemm_kernel_pb_ += TILE_K; \\\n    } \\\n  } \\\n  if (libxsmm_tiled_xgemm_kernel_k_ < (K)) { /* remainder */ \\\n    LIBXSMM_GEMM_DESCRIPTOR(libxsmm_tiled_xgemm_kernel_desc_, LIBXSMM_ALIGNMENT, FLAGS, \\\n      libxsmm_tiled_xgemm_kernel_tm_, libxsmm_tiled_xgemm_kernel_tn_, (K) - libxsmm_tiled_xgemm_kernel_k_, \\\n      LDA, LDB, LDC, ALPHA, libxsmm_tiled_xgemm_kernel_beta_, libxsmm_tiled_gemm_prefetch); \\\n    libxsmm_gemm_tiled_kernel_ = libxsmm_xmmdispatch(&libxsmm_tiled_xgemm_kernel_desc_); \\\n    LIBXSMM_GEMM_TILED_FALLBACK_CHECK(0 != libxsmm_gemm_tiled_kernel_.LIBXSMM_TPREFIX(TYPE, mm)) \\\n    { \\\n      LIBXSMM_MMCALL_PRF(libxsmm_gemm_tiled_kernel_.LIBXSMM_TPREFIX(TYPE, mm), \\\n        libxsmm_tiled_xgemm_kernel_ia_, libxsmm_tiled_xgemm_kernel_ib_, libxsmm_tiled_xgemm_kernel_ic_, \\\n        libxsmm_tiled_xgemm_kernel_pa_, libxsmm_tiled_xgemm_kernel_pb_, libxsmm_tiled_xgemm_kernel_ic_); \\\n    } \\\n    LIBXSMM_GEMM_TILED_FALLBACK(TYPE, FLAGS, libxsmm_tiled_xgemm_kernel_tm_, libxsmm_tiled_xgemm_kernel_tn_, \\\n      LIBXSMM_MIN(TILE_K, (K) - libxsmm_tiled_xgemm_kernel_k_), \\\n      ALPHA, libxsmm_tiled_xgemm_kernel_ia_, LDA, libxsmm_tiled_xgemm_kernel_ib_, LDB, \\\n      libxsmm_tiled_xgemm_kernel_beta_, libxsmm_tiled_xgemm_kernel_ic_, LDC); \\\n  } \\\n}\n\n#define LIBXSMM_TILED_XGEMM(PARALLEL, SINGLE_OUTER, SINGLE_INNER, COLLAPSE, LOOP_START, KERNEL_START, SYNC, \\\n  MIN_TASKS, OVERHEAD, NT, TYPE, FLAGS, TILE_M, TILE_N, TILE_K, MM, NN, KK, ALPHA, A, LDA, B, LDB, BETA, C, LDC) \\\nSINGLE_OUTER { /* use NN, etc. rather than N due to below char. constant */ \\\n  const int libxsmm_tiled_xgemm_above_threshold_ = LIBXSMM_GEMM_TILED_ABOVE_THRESHOLD(MM, NN, KK); \\\n  const int libxsmm_tiled_xgemm_no_bypass_ = LIBXSMM_GEMM_NO_BYPASS(FLAGS, ALPHA, BETA); \\\n  libxsmm_blasint libxsmm_tiled_xgemm_tm_ = 0, libxsmm_tiled_xgemm_tn_ = 0, libxsmm_tiled_xgemm_tk_ = 0; \\\n  libxsmm_blasint libxsmm_tiled_xgemm_num_m_ = 0, libxsmm_tiled_xgemm_num_n_ = 0, libxsmm_tiled_xgemm_num_k_ = 0; \\\n  libxsmm_xmmfunction libxsmm_tiled_xgemm_kernel_ = { 0 }; \\\n  SINGLE_INNER \\\n  if (0 != libxsmm_tiled_xgemm_above_threshold_ && 0 != libxsmm_tiled_xgemm_no_bypass_) { \\\n    libxsmm_tiled_xgemm_num_m_ = ((MM) + (TILE_M) - 1) / (TILE_M); \\\n    libxsmm_tiled_xgemm_num_n_ = ((NN) + (TILE_N) - 1) / (TILE_N); \\\n    libxsmm_tiled_xgemm_num_k_ = ((KK) + (TILE_K) - 1) / (TILE_K); \\\n    { /* opening scope for additional variable declarations */ \\\n      const libxsmm_blasint libxsmm_tiled_xgemm_num_t_ = (OVERHEAD(NT) < libxsmm_tiled_xgemm_num_k_ && 1 < (COLLAPSE)) \\\n        ? (libxsmm_tiled_xgemm_num_m_ * libxsmm_tiled_xgemm_num_n_) \\\n        : (libxsmm_tiled_xgemm_num_n_ <= libxsmm_tiled_xgemm_num_m_ ? libxsmm_tiled_xgemm_num_m_ : libxsmm_tiled_xgemm_num_n_); \\\n      const libxsmm_blasint libxsmm_tiled_xgemm_min_ntasks_ = MIN_TASKS(NT); \\\n      libxsmm_gemm_descriptor libxsmm_tiled_xgemm_desc_; \\\n      if (libxsmm_tiled_xgemm_min_ntasks_ <= libxsmm_tiled_xgemm_num_t_) { /* ensure enough parallel slack */ \\\n        libxsmm_tiled_xgemm_tm_ = (MM) / libxsmm_tiled_xgemm_num_m_; \\\n        libxsmm_tiled_xgemm_tn_ = (NN) / libxsmm_tiled_xgemm_num_n_; \\\n      } \\\n      else if (OVERHEAD(NT) < libxsmm_tiled_xgemm_num_k_) { \\\n        const libxsmm_blasint libxsmm_tiled_xgemm_ratio_ = LIBXSMM_SQRT2(libxsmm_tiled_xgemm_min_ntasks_ / libxsmm_tiled_xgemm_num_t_); \\\n        libxsmm_tiled_xgemm_tn_ = (libxsmm_tiled_xgemm_num_n_ * libxsmm_tiled_xgemm_ratio_); \\\n        libxsmm_tiled_xgemm_tm_ = (libxsmm_tiled_xgemm_min_ntasks_ + libxsmm_tiled_xgemm_tn_ - 1) / libxsmm_tiled_xgemm_tn_; \\\n      } \\\n      else if (libxsmm_tiled_xgemm_num_n_ <= libxsmm_tiled_xgemm_num_m_) { \\\n        libxsmm_tiled_xgemm_tm_ = ((MM) + libxsmm_tiled_xgemm_min_ntasks_ - 1) / libxsmm_tiled_xgemm_min_ntasks_; \\\n        libxsmm_tiled_xgemm_tn_ = TILE_N; \\\n      } \\\n      else { \\\n        libxsmm_tiled_xgemm_tm_ = TILE_M; \\\n        libxsmm_tiled_xgemm_tn_ = ((NN) + libxsmm_tiled_xgemm_min_ntasks_ - 1) / libxsmm_tiled_xgemm_min_ntasks_; \\\n      } \\\n      libxsmm_tiled_xgemm_tk_ = TILE_K; \\\n      { /* adjust for non-square operand shapes */ \\\n        float libxsmm_tiled_xgemm_rm_ = 1.f, libxsmm_tiled_xgemm_rn_ = ((float)(NN)) / (MM), libxsmm_tiled_xgemm_rk_ = ((float)(KK)) / (MM); \\\n        if (1.f < libxsmm_tiled_xgemm_rn_) { libxsmm_tiled_xgemm_rm_ /= libxsmm_tiled_xgemm_rn_; libxsmm_tiled_xgemm_rn_ = 1.f; libxsmm_tiled_xgemm_rk_ /= libxsmm_tiled_xgemm_rn_; } \\\n        if (1.f < libxsmm_tiled_xgemm_rk_) { libxsmm_tiled_xgemm_rm_ /= libxsmm_tiled_xgemm_rk_; libxsmm_tiled_xgemm_rn_ /= libxsmm_tiled_xgemm_rk_; libxsmm_tiled_xgemm_rk_ = 1.f; } \\\n        libxsmm_tiled_xgemm_tm_ = LIBXSMM_CLMP((libxsmm_blasint)(1 << LIBXSMM_LOG2(libxsmm_tiled_xgemm_tm_ * libxsmm_tiled_xgemm_rm_)/* + 0.5*/), 8, MM); \\\n        libxsmm_tiled_xgemm_tn_ = LIBXSMM_CLMP((libxsmm_blasint)(1 << LIBXSMM_LOG2(libxsmm_tiled_xgemm_tn_ * libxsmm_tiled_xgemm_rn_)/* + 0.5*/), 8, NN); \\\n        libxsmm_tiled_xgemm_tk_ = LIBXSMM_CLMP((libxsmm_blasint)(1 << LIBXSMM_LOG2(libxsmm_tiled_xgemm_tk_ * libxsmm_tiled_xgemm_rk_)/* + 0.5*/), 8, KK); \\\n      } \\\n      LIBXSMM_GEMM_DESCRIPTOR(libxsmm_tiled_xgemm_desc_, LIBXSMM_ALIGNMENT, FLAGS, \\\n        libxsmm_tiled_xgemm_tm_, libxsmm_tiled_xgemm_tn_, libxsmm_tiled_xgemm_tk_, \\\n        LDA, LDB, LDC, ALPHA, 1/*beta*/, libxsmm_tiled_gemm_prefetch); \\\n      libxsmm_tiled_xgemm_kernel_ = libxsmm_xmmdispatch(&libxsmm_tiled_xgemm_desc_); \\\n    } \\\n  } \\\n  if (0 != libxsmm_tiled_xgemm_kernel_.LIBXSMM_TPREFIX(TYPE, mm)) { \\\n    const int libxsmm_tiled_xgemm_amortized_ = (OVERHEAD(NT) * libxsmm_tiled_xgemm_tn_) < (KK); \\\n    const libxsmm_blasint libxsmm_tiled_xgemm_max_k_ = ((KK) / libxsmm_tiled_xgemm_tk_) * libxsmm_tiled_xgemm_tk_; \\\n    libxsmm_blasint libxsmm_tiled_xgemm_m_ = MM, libxsmm_tiled_xgemm_n_ = NN, libxsmm_tiled_xgemm_i_ = 0, libxsmm_tiled_xgemm_j_ = 0; \\\n    libxsmm_blasint libxsmm_tiled_xgemm_dm_ = libxsmm_tiled_xgemm_tm_, libxsmm_tiled_xgemm_dn_ = libxsmm_tiled_xgemm_tn_; \\\n    libxsmm_blasint libxsmm_tiled_xgemm_swap_ = 0; \\\n    if ((1 == (COLLAPSE) || 0 == libxsmm_tiled_xgemm_amortized_) && \\\n      libxsmm_tiled_xgemm_tn_ * (MM) < libxsmm_tiled_xgemm_tm_ * (NN)) /* approx. of num_m < num_n */ \\\n    { \\\n      libxsmm_tiled_xgemm_swap_ = libxsmm_tiled_xgemm_dm_; libxsmm_tiled_xgemm_dm_ = libxsmm_tiled_xgemm_dn_; libxsmm_tiled_xgemm_dn_ = libxsmm_tiled_xgemm_swap_; \\\n      libxsmm_tiled_xgemm_swap_ = libxsmm_tiled_xgemm_m_; libxsmm_tiled_xgemm_m_ = libxsmm_tiled_xgemm_n_; libxsmm_tiled_xgemm_n_ = libxsmm_tiled_xgemm_swap_; \\\n    } \\\n    if (0 != libxsmm_tiled_xgemm_amortized_) { /* amortized overhead */ \\\n      PARALLEL LOOP_START(COLLAPSE, libxsmm_tiled_xgemm_i_, libxsmm_tiled_xgemm_j_) \\\n      for (libxsmm_tiled_xgemm_i_ = 0; libxsmm_tiled_xgemm_i_ < libxsmm_tiled_xgemm_m_; libxsmm_tiled_xgemm_i_ += libxsmm_tiled_xgemm_dm_) { \\\n        for (libxsmm_tiled_xgemm_j_ = 0; libxsmm_tiled_xgemm_j_ < libxsmm_tiled_xgemm_n_; libxsmm_tiled_xgemm_j_ += libxsmm_tiled_xgemm_dn_) { \\\n          KERNEL_START(libxsmm_tiled_xgemm_i_, libxsmm_tiled_xgemm_j_) \\\n          LIBXSMM_GEMM_TILED_KERNEL(libxsmm_tiled_xgemm_kernel_, TYPE, FLAGS, \\\n            0 == libxsmm_tiled_xgemm_swap_ ? libxsmm_tiled_xgemm_i_ : libxsmm_tiled_xgemm_j_, \\\n            0 == libxsmm_tiled_xgemm_swap_ ? libxsmm_tiled_xgemm_j_ : libxsmm_tiled_xgemm_i_, \\\n            libxsmm_tiled_xgemm_max_k_, libxsmm_tiled_xgemm_tm_, libxsmm_tiled_xgemm_tn_, libxsmm_tiled_xgemm_tk_, \\\n            MM, NN, KK, ALPHA, A, LDA, B, LDB, BETA, C, LDC); \\\n        } \\\n      } \\\n    } \\\n    else { \\\n      PARALLEL LOOP_START(1/*COLLAPSE*/, libxsmm_tiled_xgemm_i_, libxsmm_tiled_xgemm_j_) \\\n      for (libxsmm_tiled_xgemm_i_ = 0; libxsmm_tiled_xgemm_i_ < libxsmm_tiled_xgemm_m_; libxsmm_tiled_xgemm_i_ += libxsmm_tiled_xgemm_dm_) { \\\n        KERNEL_START(libxsmm_tiled_xgemm_i_) \\\n        for (libxsmm_tiled_xgemm_j_ = 0; libxsmm_tiled_xgemm_j_ < libxsmm_tiled_xgemm_n_; libxsmm_tiled_xgemm_j_ += libxsmm_tiled_xgemm_dn_) { \\\n          LIBXSMM_GEMM_TILED_KERNEL(libxsmm_tiled_xgemm_kernel_, TYPE, FLAGS, \\\n            0 == libxsmm_tiled_xgemm_swap_ ? libxsmm_tiled_xgemm_i_ : libxsmm_tiled_xgemm_j_, \\\n            0 == libxsmm_tiled_xgemm_swap_ ? libxsmm_tiled_xgemm_j_ : libxsmm_tiled_xgemm_i_, \\\n            libxsmm_tiled_xgemm_max_k_, libxsmm_tiled_xgemm_tm_, libxsmm_tiled_xgemm_tn_, libxsmm_tiled_xgemm_tk_, \\\n            MM, NN, KK, ALPHA, A, LDA, B, LDB, BETA, C, LDC); \\\n        } \\\n      } \\\n    } \\\n    SYNC \\\n  } \\\n  else if ((0 == libxsmm_tiled_xgemm_above_threshold_ /* small problem size */ \\\n    && 0 != libxsmm_tiled_xgemm_no_bypass_)) \\\n  { \\\n    LIBXSMM_GEMM_DESCRIPTOR_TYPE(libxsmm_tiled_xgemm_smalldesc_, LIBXSMM_ALIGNMENT, FLAGS, MM, NN, KK, \\\n      LDA, LDB, LDC, ALPHA, BETA, libxsmm_tiled_gemm_prefetch); \\\n    libxsmm_tiled_xgemm_kernel_ = libxsmm_xmmdispatch(&libxsmm_tiled_xgemm_smalldesc_); \\\n    if (0 != libxsmm_tiled_xgemm_kernel_.LIBXSMM_TPREFIX(TYPE, mm)) { \\\n      LIBXSMM_MMCALL_ABC/*no prefetch*/(libxsmm_tiled_xgemm_kernel_.LIBXSMM_TPREFIX(TYPE, mm), A, B, C); \\\n    } \\\n    else { /* fall-back */ \\\n      assert(0 == LIBXSMM_NO_BLAS); \\\n      LIBXSMM_FALLBACK0(TYPE, libxsmm_blasint, FLAGS, MM, NN, KK, ALPHA, A, LDA, B, LDB, BETA, C, LDC); \\\n      if ((unsigned int)LIBXSMM_ABS(libxsmm_verbosity) > libxsmm_update_mmstatistic(FLAGS, MM, NN, KK, 1, 0)) { \\\n        const char libxsmm_tiled_xgemm_transa_ = (char)(0 == ((FLAGS) & LIBXSMM_GEMM_FLAG_TRANS_A) ? 'N' : 'T'); \\\n        const char libxsmm_tiled_xgemm_transb_ = (char)(0 == ((FLAGS) & LIBXSMM_GEMM_FLAG_TRANS_B) ? 'N' : 'T'); \\\n        const TYPE libxsmm_tiled_xgemm_alpha_ = (TYPE)(ALPHA), libxsmm_tiled_xgemm_beta_ = (TYPE)(BETA); \\\n        libxsmm_gemm_print(0 < libxsmm_verbosity ? stderr : 0, LIBXSMM_GEMM_TYPEFLAG(TYPE), \\\n          &libxsmm_tiled_xgemm_transa_, &libxsmm_tiled_xgemm_transb_, &(MM), &(NN), &(KK), \\\n          &libxsmm_tiled_xgemm_alpha_, A, &(LDA), B, &(LDB), &libxsmm_tiled_xgemm_beta_, C, &(LDC)); \\\n        if (0 < libxsmm_verbosity) fprintf(stderr, \"\\n\"); \\\n      } \\\n    } \\\n  } \\\n  else { /* fall-back */ \\\n    assert(0 == LIBXSMM_NO_BLAS); \\\n    LIBXSMM_FALLBACK1(TYPE, libxsmm_blasint, FLAGS, MM, NN, KK, ALPHA, A, LDA, B, LDB, BETA, C, LDC); \\\n    if ((unsigned int)LIBXSMM_ABS(libxsmm_verbosity) > libxsmm_update_mmstatistic(FLAGS, MM, NN, KK, 1, 0)) { \\\n      const char libxsmm_tiled_xgemm_transa_ = (char)(0 == ((FLAGS) & LIBXSMM_GEMM_FLAG_TRANS_A) ? 'N' : 'T'); \\\n      const char libxsmm_tiled_xgemm_transb_ = (char)(0 == ((FLAGS) & LIBXSMM_GEMM_FLAG_TRANS_B) ? 'N' : 'T'); \\\n      const TYPE libxsmm_tiled_xgemm_alpha_ = (TYPE)(ALPHA), libxsmm_tiled_xgemm_beta_ = (TYPE)(BETA); \\\n      libxsmm_gemm_print(0 < libxsmm_verbosity ? stderr : 0, LIBXSMM_GEMM_TYPEFLAG(TYPE), \\\n        &libxsmm_tiled_xgemm_transa_, &libxsmm_tiled_xgemm_transb_, &(MM), &(NN), &(KK), \\\n        &libxsmm_tiled_xgemm_alpha_, A, &(LDA), B, &(LDB), &libxsmm_tiled_xgemm_beta_, C, &(LDC)); \\\n      if (0 < libxsmm_verbosity) fprintf(stderr, \"\\n\"); \\\n    } \\\n  } \\\n}\n\n#if (!defined(__BLAS) || (0 != __BLAS))\n# define LIBXSMM_GEMM_WRAPPER_BLAS(TYPE, ORIGINAL, CALLER, SYMBOL) if (0 == (ORIGINAL)) { \\\n    union { const void* pv; LIBXSMM_GEMMFUNCTION_TYPE(TYPE) pf; } libxsmm_gemm_wrapper_blas_; \\\n    libxsmm_gemm_wrapper_blas_.pf = (SYMBOL); \\\n    if (libxsmm_gemm_wrapper_blas_.pv != (CALLER)) ORIGINAL = libxsmm_gemm_wrapper_blas_.pf; \\\n  }\n#else\n# define LIBXSMM_GEMM_WRAPPER_BLAS(TYPE, ORIGINAL, CALLER, SYMBOL) LIBXSMM_UNUSED(CALLER)\n#endif\n\n#if defined(LIBXSMM_GEMM_WRAP) && defined(LIBXSMM_BUILD) && defined(LIBXSMM_BUILD_EXT) && \\\n  !(defined(__APPLE__) && defined(__MACH__) /*&& defined(__clang__)*/) && !defined(__CYGWIN__)\n# if (2 != (LIBXSMM_GEMM_WRAP)) /* SGEMM and DGEMM */\n#   define LIBXSMM_GEMM_WRAPPER_STATIC(TYPE, ORIGINAL, CALLER) LIBXSMM_GEMM_WRAPPER_BLAS(TYPE, ORIGINAL, CALLER, \\\n      LIBXSMM_FSYMBOL(LIBXSMM_CONCATENATE(__real_, LIBXSMM_TPREFIX(TYPE, gemm))))\n# else /* DGEMM only */\n#   define LIBXSMM_GEMM_WRAPPER_STATIC(TYPE, ORIGINAL, CALLER) LIBXSMM_EQUAL(TYPE, double, \\\n      LIBXSMM_GEMM_WRAPPER_BLAS(TYPE, ORIGINAL, CALLER, LIBXSMM_FSYMBOL(__real_dgemm)))\n# endif\n# define LIBXSMM_GEMM_WRAP_STATIC\n#else\n# define LIBXSMM_GEMM_WRAPPER_STATIC(TYPE, ORIGINAL, CALLER)\n#endif\n\n#if defined(LIBXSMM_GEMM_WRAP_DYNAMIC)\n# define LIBXSMM_GEMM_WRAPPER_DYNAMIC(TYPE, ORIGINAL, CALLER) \\\n    if (0 == (ORIGINAL)) { \\\n      union { const void* pv; LIBXSMM_GEMMFUNCTION_TYPE(TYPE) pf; } libxsmm_gemm_wrapper_dynamic_ = { 0 }; \\\n      dlerror(); /* clear an eventual error status */ \\\n      libxsmm_gemm_wrapper_dynamic_.pv = dlsym(RTLD_NEXT, LIBXSMM_STRINGIFY(LIBXSMM_FSYMBOL(LIBXSMM_TPREFIX(TYPE, gemm)))); \\\n      if (libxsmm_gemm_wrapper_dynamic_.pv != (CALLER)) ORIGINAL = libxsmm_gemm_wrapper_dynamic_.pf; \\\n      LIBXSMM_GEMM_WRAPPER_BLAS(TYPE, ORIGINAL, CALLER, LIBXSMM_FSYMBOL(LIBXSMM_TPREFIX(TYPE, gemm))); \\\n    }\n#else\n# define LIBXSMM_GEMM_WRAPPER_DYNAMIC(TYPE, ORIGINAL, CALLER) LIBXSMM_GEMM_WRAPPER_BLAS( \\\n    TYPE, ORIGINAL, CALLER, LIBXSMM_FSYMBOL(LIBXSMM_TPREFIX(TYPE, gemm)))\n#endif\n\n#if defined(NDEBUG) /* library code is expected to be mute */\n# define LIBXSMM_GEMM_WRAPPER(TYPE, ORIGINAL, CALLER) if (0 == (ORIGINAL)) { \\\n    LIBXSMM_GEMM_WRAPPER_STATIC(TYPE, ORIGINAL, CALLER); \\\n    LIBXSMM_GEMM_WRAPPER_DYNAMIC(TYPE, ORIGINAL, CALLER); \\\n  }\n#else\n# define LIBXSMM_GEMM_WRAPPER(TYPE, ORIGINAL, CALLER) if (0 == (ORIGINAL)) { \\\n    LIBXSMM_GEMM_WRAPPER_STATIC(TYPE, ORIGINAL, CALLER); \\\n    LIBXSMM_GEMM_WRAPPER_DYNAMIC(TYPE, ORIGINAL, CALLER); \\\n    if (0 == (ORIGINAL)) { \\\n      static int libxsmm_gemm_wrapper_error_once_ = 0; \\\n      if (1 == LIBXSMM_ATOMIC_ADD_FETCH(&libxsmm_gemm_wrapper_error_once_, 1, LIBXSMM_ATOMIC_RELAXED)) { \\\n        fprintf(stderr, \"LIBXSMM: application must be linked against a LAPACK/BLAS implementation!\\n\"); \\\n      } \\\n    } \\\n  }\n#endif\n\n\n/** Provides GEMM functions available via BLAS; NOT thread-safe. */\nLIBXSMM_API void libxsmm_gemm_init(int archid, int prefetch/*default prefetch strategy*/);\n\n/** Finalizes the GEMM facility; NOT thread-safe. */\nLIBXSMM_API void libxsmm_gemm_finalize(void);\n\n#if defined(LIBXSMM_GEMM_WRAP_STATIC)\nLIBXSMM_EXTERN LIBXSMM_RETARGETABLE void LIBXSMM_FSYMBOL(__real_sgemm)(\n  const char*, const char*, const libxsmm_blasint*, const libxsmm_blasint*, const libxsmm_blasint*,\n  const float*, const float*, const libxsmm_blasint*, const float* b, const libxsmm_blasint*,\n  const float*, float*, const libxsmm_blasint*);\nLIBXSMM_EXTERN LIBXSMM_RETARGETABLE void LIBXSMM_FSYMBOL(__real_dgemm)(\n  const char*, const char*, const libxsmm_blasint*, const libxsmm_blasint*, const libxsmm_blasint*,\n  const double*, const double*, const libxsmm_blasint*, const double* b, const libxsmm_blasint*,\n  const double*, double*, const libxsmm_blasint*);\n#endif /*defined(LIBXSMM_GEMM_WRAP_STATIC)*/\n\n#if defined(LIBXSMM_BUILD) && defined(LIBXSMM_BUILD_EXT)\nLIBXSMM_EXTERN LIBXSMM_RETARGETABLE void LIBXSMM_FSYMBOL(__wrap_sgemm)(\n  const char*, const char*, const libxsmm_blasint*, const libxsmm_blasint*, const libxsmm_blasint*,\n  const float*, const float*, const libxsmm_blasint*, const float* b, const libxsmm_blasint*,\n  const float*, float*, const libxsmm_blasint*);\nLIBXSMM_EXTERN LIBXSMM_RETARGETABLE void LIBXSMM_FSYMBOL(__wrap_dgemm)(\n  const char*, const char*, const libxsmm_blasint*, const libxsmm_blasint*, const libxsmm_blasint*,\n  const double*, const double*, const libxsmm_blasint*, const double* b, const libxsmm_blasint*,\n  const double*, double*, const libxsmm_blasint*);\n#endif\n\nLIBXSMM_EXTERN LIBXSMM_RETARGETABLE void LIBXSMM_FSYMBOL(sgemm)(\n  const char*, const char*, const libxsmm_blasint*, const libxsmm_blasint*, const libxsmm_blasint*,\n  const float*, const float*, const libxsmm_blasint*, const float*, const libxsmm_blasint*,\n  const float*, float*, const libxsmm_blasint*);\nLIBXSMM_EXTERN LIBXSMM_RETARGETABLE void LIBXSMM_FSYMBOL(dgemm)(\n  const char*, const char*, const libxsmm_blasint*, const libxsmm_blasint*, const libxsmm_blasint*,\n  const double*, const double*, const libxsmm_blasint*, const double*, const libxsmm_blasint*,\n  const double*, double*, const libxsmm_blasint*);\n\n/** Configuration table containing the tile sizes separate for DP and SP. */\nLIBXSMM_EXTERN_C LIBXSMM_RETARGETABLE LIBXSMM_GEMM_DESCRIPTOR_DIM_TYPE libxsmm_gemm_tile[2/*DP/SP*/][3/*TILE_M,TILE_N,TILE_K*/];\n/** Prefetch strategy. */\nLIBXSMM_EXTERN_C LIBXSMM_RETARGETABLE int libxsmm_tiled_gemm_prefetch;\n\n#endif /*LIBXSMM_GEMM_H*/\n\n"
    },
    "skipped": [
        "/tmp/vanessa/spack-stage/spack-stage-libxsmm-1.6.5-teyur5jco62o7r5e65g54hrwpqzooo2r/spack-src/documentation/cp2k.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-libxsmm-1.6.5-teyur5jco62o7r5e65g54hrwpqzooo2r/spack-src/documentation/libxsmm.pdf"
    ],
    "total_files": 301
}