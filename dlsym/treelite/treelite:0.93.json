{
    "matches": {
        "/tmp/vanessa/spack-stage/spack-stage-treelite-0.93-s4ukd633kmmq7tssvr5g6tookxpxc2xt/spack-src/src/predictor/predictor.cc": "/*!\n * Copyright (c) 2017-2020 by Contributors\n * \\file predictor.cc\n * \\author Hyunsu Cho\n * \\brief Load prediction function exported as a shared library\n */\n\n#include <treelite/predictor.h>\n#include <treelite/math.h>\n#include <dmlc/logging.h>\n#include <dmlc/io.h>\n#include <dmlc/timer.h>\n#include <cstdint>\n#include <algorithm>\n#include <memory>\n#include <fstream>\n#include <limits>\n#include <functional>\n#include <type_traits>\n#include \"thread_pool/thread_pool.h\"\n\n#ifdef _WIN32\n#include <windows.h>\n#else\n#include <dlfcn.h>\n#endif\n\nnamespace {\n\nenum class InputType : uint8_t {\n  kSparseBatch = 0, kDenseBatch = 1\n};\n\nstruct InputToken {\n  InputType input_type;\n  const void* data;  // pointer to input data\n  bool pred_margin;  // whether to store raw margin or transformed scores\n  size_t num_feature;\n    // # features (columns) accepted by the tree ensemble model\n  size_t num_output_group;\n    // size of output per instance (row)\n  treelite::Predictor::PredFuncHandle pred_func_handle;\n  size_t rbegin, rend;\n    // range of instances (rows) assigned to each worker\n  float* out_pred;\n    // buffer to store output from each worker\n};\n\nstruct OutputToken {\n  size_t query_result_size;\n};\n\nusing PredThreadPool = treelite::ThreadPool<InputToken, OutputToken, treelite::Predictor>;\n\ninline treelite::Predictor::LibraryHandle OpenLibrary(const char* name) {\n#ifdef _WIN32\n  HMODULE handle = LoadLibraryA(name);\n#else\n  void* handle = dlopen(name, RTLD_LAZY | RTLD_LOCAL);\n#endif\n  return static_cast<treelite::Predictor::LibraryHandle>(handle);\n}\n\ninline void CloseLibrary(treelite::Predictor::LibraryHandle handle) {\n#ifdef _WIN32\n  FreeLibrary(static_cast<HMODULE>(handle));\n#else\n  dlclose(static_cast<void*>(handle));\n#endif\n}\n\ntemplate <typename HandleType>\ninline HandleType LoadFunction(treelite::Predictor::LibraryHandle lib_handle,\n                               const char* name) {\n#ifdef _WIN32\n  FARPROC func_handle = GetProcAddress(static_cast<HMODULE>(lib_handle), name);\n#else\n  void* func_handle = dlsym(static_cast<void*>(lib_handle), name);\n#endif\n  return static_cast<HandleType>(func_handle);\n}\n\ntemplate <typename PredFunc>\ninline size_t PredLoop(const treelite::CSRBatch* batch, size_t num_feature,\n                       size_t rbegin, size_t rend,\n                       float* out_pred, PredFunc func) {\n  CHECK_LE(batch->num_col, num_feature);\n  std::vector<TreelitePredictorEntry> inst(\n    std::max(batch->num_col, num_feature), {-1});\n  CHECK(rbegin < rend && rend <= batch->num_row);\n  CHECK(sizeof(size_t) < sizeof(int64_t)\n     || (rbegin <= static_cast<size_t>(std::numeric_limits<int64_t>::max())\n        && rend <= static_cast<size_t>(std::numeric_limits<int64_t>::max())));\n  const int64_t rbegin_ = static_cast<int64_t>(rbegin);\n  const int64_t rend_ = static_cast<int64_t>(rend);\n  const size_t num_col = batch->num_col;\n  const float* data = batch->data;\n  const uint32_t* col_ind = batch->col_ind;\n  const size_t* row_ptr = batch->row_ptr;\n  size_t total_output_size = 0;\n  for (int64_t rid = rbegin_; rid < rend_; ++rid) {\n    const size_t ibegin = row_ptr[rid];\n    const size_t iend = row_ptr[rid + 1];\n    for (size_t i = ibegin; i < iend; ++i) {\n      inst[col_ind[i]].fvalue = data[i];\n    }\n    total_output_size += func(rid, &inst[0], out_pred);\n    for (size_t i = ibegin; i < iend; ++i) {\n      inst[col_ind[i]].missing = -1;\n    }\n  }\n  return total_output_size;\n}\n\ntemplate <typename PredFunc>\ninline size_t PredLoop(const treelite::DenseBatch* batch, size_t num_feature,\n                       size_t rbegin, size_t rend,\n                       float* out_pred, PredFunc func) {\n  const bool nan_missing = treelite::math::CheckNAN(batch->missing_value);\n  CHECK_LE(batch->num_col, num_feature);\n  std::vector<TreelitePredictorEntry> inst(\n    std::max(batch->num_col, num_feature), {-1});\n  CHECK(rbegin < rend && rend <= batch->num_row);\n  CHECK(sizeof(size_t) < sizeof(int64_t)\n     || (rbegin <= static_cast<size_t>(std::numeric_limits<int64_t>::max())\n        && rend <= static_cast<size_t>(std::numeric_limits<int64_t>::max())));\n  const int64_t rbegin_ = static_cast<int64_t>(rbegin);\n  const int64_t rend_ = static_cast<int64_t>(rend);\n  const size_t num_col = batch->num_col;\n  const float missing_value = batch->missing_value;\n  const float* data = batch->data;\n  const float* row;\n  size_t total_output_size = 0;\n  for (int64_t rid = rbegin_; rid < rend_; ++rid) {\n    row = &data[rid * num_col];\n    for (size_t j = 0; j < num_col; ++j) {\n      if (treelite::math::CheckNAN(row[j])) {\n        CHECK(nan_missing)\n          << \"The missing_value argument must be set to NaN if there is any \"\n          << \"NaN in the matrix.\";\n      } else if (nan_missing || row[j] != missing_value) {\n        inst[j].fvalue = row[j];\n      }\n    }\n    total_output_size += func(rid, &inst[0], out_pred);\n    for (size_t j = 0; j < num_col; ++j) {\n      inst[j].missing = -1;\n    }\n  }\n  return total_output_size;\n}\n\ntemplate <typename BatchType>\ninline size_t PredictBatch_(const BatchType* batch, bool pred_margin,\n                            size_t num_feature, size_t num_output_group,\n                            treelite::Predictor::PredFuncHandle pred_func_handle,\n                            size_t rbegin, size_t rend,\n                            size_t expected_query_result_size, float* out_pred) {\n  CHECK(pred_func_handle != nullptr)\n    << \"A shared library needs to be loaded first using Load()\";\n  /* Pass the correct prediction function to PredLoop.\n     We also need to specify how the function should be called. */\n  size_t query_result_size;\n    // Dimension of output vector:\n    // can be either [num_data] or [num_class]*[num_data].\n    // Note that size of prediction may be smaller than out_pred (this occurs\n    // when pred_function is set to \"max_index\").\n  if (num_output_group > 1) {  // multi-class classification task\n    using PredFunc = size_t (*)(TreelitePredictorEntry*, int, float*);\n    PredFunc pred_func = reinterpret_cast<PredFunc>(pred_func_handle);\n    query_result_size =\n     PredLoop(batch, num_feature, rbegin, rend, out_pred,\n      [pred_func, num_output_group, pred_margin]\n      (int64_t rid, TreelitePredictorEntry* inst, float* out_pred) -> size_t {\n        return pred_func(inst, static_cast<int>(pred_margin),\n                         &out_pred[rid * num_output_group]);\n      });\n  } else {                     // every other task\n    using PredFunc = float (*)(TreelitePredictorEntry*, int);\n    PredFunc pred_func = reinterpret_cast<PredFunc>(pred_func_handle);\n    query_result_size =\n     PredLoop(batch, num_feature, rbegin, rend, out_pred,\n      [pred_func, pred_margin]\n      (int64_t rid, TreelitePredictorEntry* inst, float* out_pred) -> size_t {\n        out_pred[rid] = pred_func(inst, static_cast<int>(pred_margin));\n        return 1;\n      });\n  }\n  return query_result_size;\n}\n\ninline size_t PredictInst_(TreelitePredictorEntry* inst,\n                           bool pred_margin, size_t num_output_group,\n                           treelite::Predictor::PredFuncHandle pred_func_handle,\n                           size_t expected_query_result_size, float* out_pred) {\n  CHECK(pred_func_handle != nullptr)\n    << \"A shared library needs to be loaded first using Load()\";\n  size_t query_result_size;  // Dimention of output vector\n  if (num_output_group > 1) {  // multi-class classification task\n    using PredFunc = size_t (*)(TreelitePredictorEntry*, int, float*);\n    PredFunc pred_func = reinterpret_cast<PredFunc>(pred_func_handle);\n    query_result_size = pred_func(inst, static_cast<int>(pred_margin), out_pred);\n  } else {  // every other task\n    using PredFunc = float (*)(TreelitePredictorEntry*, int);\n    PredFunc pred_func = reinterpret_cast<PredFunc>(pred_func_handle);\n    out_pred[0] = pred_func(inst, static_cast<int>(pred_margin));\n    query_result_size = 1;\n  }\n  return query_result_size;\n}\n\n}  // anonymous namespace\n\nnamespace treelite {\n\nPredictor::Predictor(int num_worker_thread)\n                       : lib_handle_(nullptr),\n                         num_output_group_query_func_handle_(nullptr),\n                         num_feature_query_func_handle_(nullptr),\n                         pred_func_handle_(nullptr),\n                         thread_pool_handle_(nullptr),\n                         num_worker_thread_(num_worker_thread) {}\nPredictor::~Predictor() {\n  Free();\n}\n\nvoid\nPredictor::Load(const char* name) {\n  lib_handle_ = OpenLibrary(name);\n  if (lib_handle_ == nullptr) {\n    LOG(FATAL) << \"Failed to load dynamic shared library `\" << name << \"'\";\n  }\n\n  /* 1. query # of output groups */\n  num_output_group_query_func_handle_\n    = LoadFunction<QueryFuncHandle>(lib_handle_, \"get_num_output_group\");\n  using UnsignedQueryFunc = size_t (*)(void);\n  auto uint_query_func\n    = reinterpret_cast<UnsignedQueryFunc>(num_output_group_query_func_handle_);\n  CHECK(uint_query_func != nullptr)\n    << \"Dynamic shared library `\" << name\n    << \"' does not contain valid get_num_output_group() function\";\n  num_output_group_ = uint_query_func();\n\n  /* 2. query # of features */\n  num_feature_query_func_handle_\n    = LoadFunction<QueryFuncHandle>(lib_handle_, \"get_num_feature\");\n  uint_query_func = reinterpret_cast<UnsignedQueryFunc>(num_feature_query_func_handle_);\n  CHECK(uint_query_func != nullptr)\n    << \"Dynamic shared library `\" << name\n    << \"' does not contain valid get_num_feature() function\";\n  num_feature_ = uint_query_func();\n  CHECK_GT(num_feature_, 0) << \"num_feature cannot be zero\";\n\n  /* 3. query # of pred_transform name */\n  pred_transform_query_func_handle_\n    = LoadFunction<QueryFuncHandle>(lib_handle_, \"get_pred_transform\");\n  using StringQueryFunc = const char* (*)(void);\n  auto str_query_func =\n      reinterpret_cast<StringQueryFunc>(pred_transform_query_func_handle_);\n  if (str_query_func == nullptr) {\n    LOG(INFO) << \"Dynamic shared library `\" << name\n              << \"' does not contain valid get_pred_transform() function\";\n    pred_transform_ = \"unknown\";\n  } else {\n    pred_transform_ = str_query_func();\n  }\n\n  /* 4. query # of sigmoid_alpha */\n  sigmoid_alpha_query_func_handle_\n    = LoadFunction<QueryFuncHandle>(lib_handle_, \"get_sigmoid_alpha\");\n  using FloatQueryFunc = float (*)(void);\n  auto float_query_func =\n      reinterpret_cast<FloatQueryFunc>(sigmoid_alpha_query_func_handle_);\n  if (float_query_func == nullptr) {\n    LOG(INFO) << \"Dynamic shared library `\" << name\n              << \"' does not contain valid get_sigmoid_alpha() function\";\n    sigmoid_alpha_ = NAN;\n  } else {\n    sigmoid_alpha_ = float_query_func();\n  }\n\n  /* 5. query # of global_bias */\n  global_bias_query_func_handle_\n    = LoadFunction<QueryFuncHandle>(lib_handle_, \"get_global_bias\");\n  float_query_func = reinterpret_cast<FloatQueryFunc>(global_bias_query_func_handle_);\n  if (float_query_func == nullptr) {\n    LOG(INFO) << \"Dynamic shared library `\" << name\n              << \"' does not contain valid get_global_bias() function\";\n    global_bias_ = NAN;\n  } else {\n    global_bias_ = float_query_func();\n  }\n\n  /* 6. load appropriate function for margin prediction */\n  CHECK_GT(num_output_group_, 0) << \"num_output_group cannot be zero\";\n  if (num_output_group_ > 1) {   // multi-class classification\n    pred_func_handle_ = LoadFunction<PredFuncHandle>(lib_handle_,\n                                                     \"predict_multiclass\");\n    using PredFunc = size_t (*)(TreelitePredictorEntry*, int, float*);\n    PredFunc pred_func = reinterpret_cast<PredFunc>(pred_func_handle_);\n    CHECK(pred_func != nullptr)\n      << \"Dynamic shared library `\" << name\n      << \"' does not contain valid predict_multiclass() function\";\n  } else {                      // everything else\n    pred_func_handle_ = LoadFunction<PredFuncHandle>(lib_handle_, \"predict\");\n    using PredFunc = float (*)(TreelitePredictorEntry*, int);\n    PredFunc pred_func = reinterpret_cast<PredFunc>(pred_func_handle_);\n    CHECK(pred_func != nullptr)\n      << \"Dynamic shared library `\" << name\n      << \"' does not contain valid predict() function\";\n  }\n\n  if (num_worker_thread_ == -1) {\n    num_worker_thread_ = std::thread::hardware_concurrency();\n  }\n  thread_pool_handle_ = static_cast<ThreadPoolHandle>(\n      new PredThreadPool(num_worker_thread_ - 1, this,\n                         [](SpscQueue<InputToken>* incoming_queue,\n                            SpscQueue<OutputToken>* outgoing_queue,\n                            const Predictor* predictor) {\n      InputToken input;\n      while (incoming_queue->Pop(&input)) {\n        size_t query_result_size;\n        const size_t rbegin = input.rbegin;\n        const size_t rend = input.rend;\n        switch (input.input_type) {\n         case InputType::kSparseBatch:\n          {\n            const CSRBatch* batch = static_cast<const CSRBatch*>(input.data);\n            query_result_size\n              = PredictBatch_(batch, input.pred_margin, input.num_feature,\n                              input.num_output_group, input.pred_func_handle,\n                              rbegin, rend,\n                              predictor->QueryResultSize(batch, rbegin, rend),\n                              input.out_pred);\n          }\n          break;\n         case InputType::kDenseBatch:\n          {\n            const DenseBatch* batch = static_cast<const DenseBatch*>(input.data);\n            query_result_size\n              = PredictBatch_(batch, input.pred_margin, input.num_feature,\n                              input.num_output_group, input.pred_func_handle,\n                              rbegin, rend,\n                              predictor->QueryResultSize(batch, rbegin, rend),\n                              input.out_pred);\n          }\n          break;\n        }\n        outgoing_queue->Push(OutputToken{query_result_size});\n      }\n    }));\n}\n\nvoid\nPredictor::Free() {\n  CloseLibrary(lib_handle_);\n  delete static_cast<PredThreadPool*>(thread_pool_handle_);\n}\n\ntemplate <typename BatchType>\nstatic inline\nstd::vector<size_t> SplitBatch(const BatchType* batch, size_t split_factor) {\n  const size_t num_row = batch->num_row;\n  CHECK_LE(split_factor, num_row);\n  const size_t portion = num_row / split_factor;\n  const size_t remainder = num_row % split_factor;\n  std::vector<size_t> workload(split_factor, portion);\n  std::vector<size_t> row_ptr(split_factor + 1, 0);\n  for (size_t i = 0; i < remainder; ++i) {\n    ++workload[i];\n  }\n  size_t accum = 0;\n  for (size_t i = 0; i < split_factor; ++i) {\n    accum += workload[i];\n    row_ptr[i + 1] = accum;\n  }\n  return row_ptr;\n}\n\ntemplate <typename BatchType>\ninline size_t\nPredictor::PredictBatchBase_(const BatchType* batch, int verbose,\n                             bool pred_margin, float* out_result) {\n  static_assert(std::is_same<BatchType, DenseBatch>::value\n                || std::is_same<BatchType, CSRBatch>::value,\n                \"PredictBatchBase_: unrecognized batch type\");\n  const double tstart = dmlc::GetTime();\n  PredThreadPool* pool = static_cast<PredThreadPool*>(thread_pool_handle_);\n  const InputType input_type\n    = std::is_same<BatchType, CSRBatch>::value\n      ? InputType::kSparseBatch : InputType::kDenseBatch;\n  InputToken request{input_type, static_cast<const void*>(batch), pred_margin,\n                     num_feature_, num_output_group_, pred_func_handle_,\n                     0, batch->num_row, out_result};\n  OutputToken response;\n  CHECK_GT(batch->num_row, 0);\n  const int nthread = std::min(num_worker_thread_,\n                               static_cast<int>(batch->num_row));\n  const std::vector<size_t> row_ptr = SplitBatch(batch, nthread);\n  for (int tid = 0; tid < nthread - 1; ++tid) {\n    request.rbegin = row_ptr[tid];\n    request.rend = row_ptr[tid + 1];\n    pool->SubmitTask(tid, request);\n  }\n  size_t total_size = 0;\n  {\n    // assign work to master\n    const size_t rbegin = row_ptr[nthread - 1];\n    const size_t rend = row_ptr[nthread];\n    const size_t query_result_size\n      = PredictBatch_(batch, pred_margin, num_feature_, num_output_group_,\n                      pred_func_handle_,\n                      rbegin, rend, QueryResultSize(batch, rbegin, rend),\n                      out_result);\n    total_size += query_result_size;\n  }\n  for (int tid = 0; tid < nthread - 1; ++tid) {\n    if (pool->WaitForTask(tid, &response)) {\n      total_size += response.query_result_size;\n    }\n  }\n  // re-shape output if total_size < dimension of out_result\n  if (total_size < QueryResultSize(batch, 0, batch->num_row)) {\n    CHECK_GT(num_output_group_, 1);\n    CHECK_EQ(total_size % batch->num_row, 0);\n    const size_t query_size_per_instance = total_size / batch->num_row;\n    CHECK_GT(query_size_per_instance, 0);\n    CHECK_LT(query_size_per_instance, num_output_group_);\n    for (size_t rid = 0; rid < batch->num_row; ++rid) {\n      for (size_t k = 0; k < query_size_per_instance; ++k) {\n        out_result[rid * query_size_per_instance + k]\n          = out_result[rid * num_output_group_ + k];\n      }\n    }\n  }\n  const double tend = dmlc::GetTime();\n  if (verbose > 0) {\n    LOG(INFO) << \"Treelite: Finished prediction in \"\n              << tend - tstart << \" sec\";\n  }\n  return total_size;\n}\n\nsize_t\nPredictor::PredictBatch(const CSRBatch* batch, int verbose,\n                        bool pred_margin, float* out_result) {\n  return PredictBatchBase_(batch, verbose, pred_margin, out_result);\n}\n\nsize_t\nPredictor::PredictBatch(const DenseBatch* batch, int verbose,\n                        bool pred_margin, float* out_result) {\n  return PredictBatchBase_(batch, verbose, pred_margin, out_result);\n}\n\nsize_t\nPredictor::PredictInst(TreelitePredictorEntry* inst, bool pred_margin,\n                       float* out_result) {\n  size_t total_size;\n  total_size = PredictInst_(inst, pred_margin, num_output_group_,\n                            pred_func_handle_,\n                            QueryResultSizeSingleInst(), out_result);\n  return total_size;\n}\n\n}  // namespace treelite\n"
    },
    "skipped": [
        "/tmp/vanessa/spack-stage/spack-stage-treelite-0.93-s4ukd633kmmq7tssvr5g6tookxpxc2xt/spack-src/tests/examples/mushroom/mushroom.model",
        "/tmp/vanessa/spack-stage/spack-stage-treelite-0.93-s4ukd633kmmq7tssvr5g6tookxpxc2xt/spack-src/tests/examples/dermatology/dermatology.model",
        "/tmp/vanessa/spack-stage/spack-stage-treelite-0.93-s4ukd633kmmq7tssvr5g6tookxpxc2xt/spack-src/tests/examples/letor/mq2008.model",
        "/tmp/vanessa/spack-stage/spack-stage-treelite-0.93-s4ukd633kmmq7tssvr5g6tookxpxc2xt/spack-src/docs/_static/deployment.png"
    ],
    "total_files": 216
}