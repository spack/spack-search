{
    "matches": {
        "/tmp/vanessa/spack-stage/spack-stage-lvm2-2.03.05-f3l3iqzw3duerkzigowryif6fns7ok2e/spack-src/lib/mm/memlock.c": "/*\n * Copyright (C) 2003-2004 Sistina Software, Inc. All rights reserved.\n * Copyright (C) 2004-2011 Red Hat, Inc. All rights reserved.\n *\n * This file is part of LVM2.\n *\n * This copyrighted material is made available to anyone wishing to use,\n * modify, copy, or redistribute it subject to the terms and conditions\n * of the GNU Lesser General Public License v.2.1.\n *\n * You should have received a copy of the GNU Lesser General Public License\n * along with this program; if not, write to the Free Software Foundation,\n * Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n */\n\n#include \"lib/misc/lib.h\"\n#include \"lib/mm/memlock.h\"\n#include \"lib/config/defaults.h\"\n#include \"lib/config/config.h\"\n#include \"lib/commands/toolcontext.h\"\n\n#include <limits.h>\n#include <fcntl.h>\n#include <unistd.h>\n#include <sys/mman.h>\n#include <sys/time.h>\n#include <sys/resource.h>\n#include <malloc.h>\n\n#ifdef HAVE_VALGRIND\n#include <valgrind.h>\n#endif\n\n#ifndef DEVMAPPER_SUPPORT\n\nvoid memlock_inc_daemon(struct cmd_context *cmd)\n{\n\treturn;\n}\n\nvoid memlock_dec_daemon(struct cmd_context *cmd)\n{\n\treturn;\n}\n\nvoid critical_section_inc(struct cmd_context *cmd, const char *reason)\n{\n\treturn;\n}\n\nvoid critical_section_dec(struct cmd_context *cmd, const char *reason)\n{\n\treturn;\n}\n\nint critical_section(void)\n{\n\treturn 0;\n}\nvoid memlock_init(struct cmd_context *cmd)\n{\n\treturn;\n}\n\nvoid memlock_unlock(struct cmd_context *cmd)\n{\n\treturn;\n}\n\nvoid memlock_reset(void)\n{\n\treturn;\n}\n\nint memlock_count_daemon(void)\n{\n\treturn 0;\n}\n\n#else\t\t\t\t/* DEVMAPPER_SUPPORT */\n\nstatic size_t _size_stack;\nstatic size_t _size_malloc_tmp;\nstatic size_t _size_malloc = 2000000;\n\nstatic void *_malloc_mem = NULL;\nstatic int _mem_locked = 0;\nstatic int _priority_raised = 0;\nstatic int _critical_section = 0;\nstatic int _prioritized_section = 0;\nstatic int _memlock_count_daemon = 0;\nstatic int _priority;\nstatic int _default_priority;\n\n/* list of maps, that are unconditionaly ignored */\nstatic const char * const _ignore_maps[] = {\n\t\"[vdso]\",\n\t\"[vsyscall]\",\n\t\"[vectors]\",\n};\n\n/* default blacklist for maps */\nstatic const char * const _blacklist_maps[] = {\n\t\"locale/locale-archive\",\n\t\"/LC_MESSAGES/\",\n\t\"gconv/gconv-modules.cache\",\n\t\"/ld-2.\",\t\t/* not using dlopen,dlsym during mlock */\n\t\"/libaio.so.\",\t\t/* not using aio during mlock */\n\t\"/libattr.so.\",\t\t/* not using during mlock (udev) */\n\t\"/libblkid.so.\",\t/* not using blkid during mlock (udev) */\n\t\"/libbz2.so.\",\t\t/* not using during mlock (udev) */\n\t\"/libcap.so.\",\t\t/* not using during mlock (systemd) */\n\t\"/libdl-\",\t\t/* not using dlopen,dlsym during mlock */\n\t\"/libdw-\",\t\t/* not using during mlock (udev) */\n\t\"/libelf-\",\t\t/* not using during mlock (udev) */\n\t\"/libgcrypt.so.\",\t/* not using during mlock (systemd) */\n\t\"/libgpg-error.so.\",\t/* not using gpg-error during mlock (systemd) */\n\t\"/liblz4.so.\",\t\t/* not using lz4 during mlock (systemd) */\n\t\"/liblzma.so.\",\t\t/* not using lzma during mlock (systemd) */\n\t\"/libmount.so.\",\t/* not using mount during mlock (udev) */\n\t\"/libncurses.so.\",\t/* not using ncurses during mlock */\n\t\"/libpcre.so.\",\t\t/* not using pcre during mlock (selinux) */\n\t\"/libpcre2-\",\t\t/* not using pcre during mlock (selinux) */\n\t\"/libreadline.so.\",\t/* not using readline during mlock */\n\t\"/libresolv-\",\t\t/* not using during mlock (udev) */\n\t\"/libselinux.so.\",\t/* not using selinux during mlock */\n\t\"/libsepol.so.\",\t/* not using sepol during mlock */\n\t\"/libsystemd.so.\",\t/* not using systemd during mlock */\n\t\"/libtinfo.so.\",\t/* not using tinfo during mlock */\n\t\"/libudev.so.\",\t\t/* not using udev during mlock */\n\t\"/libuuid.so.\",\t\t/* not using uuid during mlock (blkid) */\n\t\"/libz.so.\",\t\t/* not using during mlock (udev) */\n\t\"/etc/selinux\",\t\t/* not using selinux during mlock */\n\t/* \"/libdevmapper-event.so\" */\n};\n\ntypedef enum { LVM_MLOCK, LVM_MUNLOCK } lvmlock_t;\n\nstatic unsigned _use_mlockall;\nstatic int _maps_fd;\nstatic size_t _maps_len = 8192; /* Initial buffer size for reading /proc/self/maps */\nstatic char *_maps_buffer;\nstatic char _procselfmaps[PATH_MAX] = \"\";\n#define SELF_MAPS \"/self/maps\"\n\nstatic size_t _mstats; /* statistic for maps locking */\n\nstatic void _touch_memory(void *mem, size_t size)\n{\n\tsize_t pagesize = lvm_getpagesize();\n\tchar *pos = mem;\n\tchar *end = pos + size - sizeof(long);\n\n\twhile (pos < end) {\n\t\t*(long *) pos = 1;\n\t\tpos += pagesize;\n\t}\n}\n\nstatic void _allocate_memory(void)\n{\n#ifndef VALGRIND_POOL\n\tvoid *stack_mem;\n\tstruct rlimit limit;\n\tint i, area = 0, missing = _size_malloc_tmp, max_areas = 32, hblks;\n\tchar *areas[max_areas];\n\n\t/* Check if we could preallocate requested stack */\n\tif ((getrlimit (RLIMIT_STACK, &limit) == 0) &&\n\t    ((_size_stack * 2) < limit.rlim_cur) &&\n\t    ((stack_mem = alloca(_size_stack))))\n\t\t_touch_memory(stack_mem, _size_stack);\n\t/* FIXME else warn user setting got ignored */\n\n        /*\n         *  When a brk() fails due to fragmented address space (which sometimes\n         *  happens when we try to grab 8M or so), glibc will make a new\n         *  arena. In this arena, the rules for using \u201cdirect\u201d mmap are relaxed,\n         *  circumventing the MAX_MMAPs and MMAP_THRESHOLD settings. We can,\n         *  however, detect when this happens with mallinfo() and try to co-opt\n         *  malloc into using MMAP as a MORECORE substitute instead of returning\n         *  MMAP'd memory directly. Since MMAP-as-MORECORE does not munmap the\n         *  memory on free(), this is good enough for our purposes.\n         */\n\twhile (missing > 0) {\n\t\tstruct mallinfo inf = mallinfo();\n\t\thblks = inf.hblks;\n\n\t\tif ((areas[area] = malloc(_size_malloc_tmp)))\n\t\t\t_touch_memory(areas[area], _size_malloc_tmp);\n\n\t\tinf = mallinfo();\n\n\t\tif (hblks < inf.hblks) {\n\t\t\t/* malloc cheated and used mmap, even though we told it\n\t\t\t   not to; we try with twice as many areas, each half\n\t\t\t   the size, to circumvent the faulty logic in glibc */\n\t\t\tfree(areas[area]);\n\t\t\t_size_malloc_tmp /= 2;\n\t\t} else {\n\t\t\t++ area;\n\t\t\tmissing -= _size_malloc_tmp;\n\t\t}\n\n\t\tif (area == max_areas && missing > 0) {\n\t\t\t/* Too bad. Warn the user and proceed, as things are\n\t\t\t * most likely going to work out anyway. */\n\t\t\tlog_warn(\"WARNING: Failed to reserve memory, %d bytes missing.\", missing);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif ((_malloc_mem = malloc(_size_malloc)))\n\t\t_touch_memory(_malloc_mem, _size_malloc);\n\n\t/* free up the reserves so subsequent malloc's can use that memory */\n\tfor (i = 0; i < area; ++i)\n\t\tfree(areas[i]);\n#endif\n}\n\nstatic void _release_memory(void)\n{\n\tfree(_malloc_mem);\n}\n\n/*\n * mlock/munlock memory areas from /proc/self/maps\n * format described in kernel/Documentation/filesystem/proc.txt\n */\nstatic int _maps_line(const struct dm_config_node *cn, lvmlock_t lock,\n\t\t      const char *line, size_t *mstats)\n{\n\tconst struct dm_config_value *cv;\n\tlong from, to;\n\tint pos;\n\tunsigned i;\n\tchar fr, fw, fx, fp;\n\tsize_t sz;\n\tconst char *lock_str = (lock == LVM_MLOCK) ? \"mlock\" : \"munlock\";\n\n\tif (sscanf(line, \"%lx-%lx %c%c%c%c%n\",\n\t\t   &from, &to, &fr, &fw, &fx, &fp, &pos) != 6) {\n\t\tlog_error(\"Failed to parse maps line: %s\", line);\n\t\treturn 0;\n\t}\n\n\t/* Select readable maps */\n\tif (fr != 'r') {\n\t\tlog_debug_mem(\"%s area unreadable %s : Skipping.\", lock_str, line);\n\t\treturn 1;\n\t}\n\n\t/* always ignored areas */\n\tfor (i = 0; i < DM_ARRAY_SIZE(_ignore_maps); ++i)\n\t\tif (strstr(line + pos, _ignore_maps[i])) {\n\t\t\tlog_debug_mem(\"%s ignore filter '%s' matches '%s': Skipping.\",\n\t\t\t\t      lock_str, _ignore_maps[i], line);\n\t\t\treturn 1;\n\t\t}\n\n\tsz = to - from;\n\tif (!cn) {\n\t\t/* If no blacklist configured, use an internal set */\n\t\tfor (i = 0; i < DM_ARRAY_SIZE(_blacklist_maps); ++i)\n\t\t\tif (strstr(line + pos, _blacklist_maps[i])) {\n\t\t\t\tlog_debug_mem(\"%s default filter '%s' matches '%s': Skipping.\",\n\t\t\t\t\t      lock_str, _blacklist_maps[i], line);\n\t\t\t\treturn 1;\n\t\t\t}\n\t} else {\n\t\tfor (cv = cn->v; cv; cv = cv->next) {\n\t\t\tif ((cv->type != DM_CFG_STRING) || !cv->v.str[0])\n\t\t\t\tcontinue;\n\t\t\tif (strstr(line + pos, cv->v.str)) {\n\t\t\t\tlog_debug_mem(\"%s_filter '%s' matches '%s': Skipping.\",\n\t\t\t\t\t      lock_str, cv->v.str, line);\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t}\n\t}\n\n#ifdef HAVE_VALGRIND\n\t/*\n\t * Valgrind is continually eating memory while executing code\n\t * so we need to deactivate check of locked memory size\n\t */\n#ifndef VALGRIND_POOL\n\tif (RUNNING_ON_VALGRIND)\n#endif\n\t\tsz -= sz; /* = 0, but avoids getting warning about dead assigment */\n\n#endif\n\t*mstats += sz;\n\tlog_debug_mem(\"%s %10ldKiB %12lx - %12lx %c%c%c%c%s\", lock_str,\n\t\t      ((long)sz + 1023) / 1024, from, to, fr, fw, fx, fp, line + pos);\n\n\tif (lock == LVM_MLOCK) {\n\t\tif (mlock((const void*)from, sz) < 0) {\n\t\t\tlog_sys_error(\"mlock\", line);\n\t\t\treturn 0;\n\t\t}\n\t} else {\n\t\tif (munlock((const void*)from, sz) < 0) {\n\t\t\tlog_sys_error(\"munlock\", line);\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\treturn 1;\n}\n\nstatic int _memlock_maps(struct cmd_context *cmd, lvmlock_t lock, size_t *mstats)\n{\n\tconst struct dm_config_node *cn;\n\tchar *line, *line_end;\n\tsize_t len;\n\tssize_t n;\n\tint ret = 1;\n\n\tif (_use_mlockall) {\n#ifdef MCL_CURRENT\n\t\tif (lock == LVM_MLOCK) {\n\t\t\tif (mlockall(MCL_CURRENT | MCL_FUTURE)) {\n\t\t\t\tlog_sys_error(\"mlockall\", \"\");\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t} else {\n\t\t\tif (munlockall()) {\n\t\t\t\tlog_sys_error(\"munlockall\", \"\");\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t}\n\t\treturn 1;\n#else\n\t\treturn 0;\n#endif\n\t}\n\n\t/* Reset statistic counters */\n\t*mstats = 0;\n\n\t/* read mapping into a single memory chunk without reallocation\n\t * in the middle of reading maps file */\n\tfor (len = 0;;) {\n\t\tif (!_maps_buffer || len >= _maps_len) {\n\t\t\tif (_maps_buffer)\n\t\t\t\t_maps_len *= 2;\n\t\t\tif (!(line = realloc(_maps_buffer, _maps_len))) {\n\t\t\t\tlog_error(\"Allocation of maps buffer failed.\");\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\t_maps_buffer = line;\n\t\t}\n\t\tif (lseek(_maps_fd, 0, SEEK_SET))\n\t\t\tlog_sys_error(\"lseek\", _procselfmaps);\n\t\tfor (len = 0 ; len < _maps_len; len += n) {\n\t\t\tif (!(n = read(_maps_fd, _maps_buffer + len, _maps_len - len)))\n\t\t\t\tbreak; /* EOF */\n\t\t\tif (n == -1) {\n\t\t\t\tlog_sys_error(\"read\", _procselfmaps);\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t}\n\t\tif (len < _maps_len) { /* fits in buffer */\n\t\t\t_maps_buffer[len] = '\\0';\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tline = _maps_buffer;\n\tcn = find_config_tree_array(cmd, activation_mlock_filter_CFG, NULL);\n\n\twhile ((line_end = strchr(line, '\\n'))) {\n\t\t*line_end = '\\0'; /* remove \\n */\n\t\tif (!_maps_line(cn, lock, line, mstats))\n\t\t\tret = 0;\n\t\tline = line_end + 1;\n\t}\n\n\tlog_debug_mem(\"%socked %ld bytes\",\n\t\t      (lock == LVM_MLOCK) ? \"L\" : \"Unl\", (long)*mstats);\n\n\treturn ret;\n}\n\n#ifdef DEBUG_MEMLOCK\n/*\n * LVM is not supposed to use mmap while devices are suspended.\n * This code causes a core dump if gets called.\"\n */\n#  ifdef __i386__\n#    define ARCH_X86\n#  endif /* __i386__ */\n#  ifdef __x86_64__\n#    ifndef ARCH_X86\n#      define ARCH_X86\n#    endif /* ARCH_X86 */\n#  endif /* __x86_64__ */\n\n#endif /* DEBUG_MEMLOCK */\n\n#ifdef ARCH_X86\n#ifndef _GNU_SOURCE\n#define _GNU_SOURCE\n#endif\n#include <dlfcn.h>\nstatic const unsigned char _instruction_hlt = 0x94;\nstatic char _mmap_orig;\nstatic unsigned char *_mmap_addr;\n#ifdef __i386__\nstatic char _mmap64_orig;\nstatic unsigned char *_mmap64_addr;\n#endif /* __i386__ */\n#endif /* ARCH_X86 */\n\nstatic int _disable_mmap(void)\n{\n#ifdef ARCH_X86\n\tvolatile unsigned char *abs_addr;\n\n\tif (!_mmap_addr) {\n\t\t_mmap_addr = (unsigned char *) dlsym(RTLD_NEXT, \"mmap\");\n\t\tif (_mmap_addr[0] == 0xff && _mmap_addr[1] == 0x25) { /* plt */\n#ifdef __x86_64__\n\t\t\tabs_addr = _mmap_addr + 6 + *(int32_t *)(_mmap_addr + 2);\n#endif /* __x86_64__ */\n#ifdef __i386__\n\t\t\tabs_addr = *(void **)(_mmap_addr + 2);\n#endif /* __i386__ */\n\t\t\t_mmap_addr = *(void **)abs_addr;\n\t\t} else\n\t\t\tlog_debug_mem(\"Can't find PLT jump entry assuming -fPIE linkage.\");\n\t\tif (mprotect((void *)((unsigned long)_mmap_addr & ~4095UL), 4096, PROT_READ|PROT_WRITE|PROT_EXEC)) {\n\t\t\tlog_sys_error(\"mprotect\", \"\");\n\t\t\t_mmap_addr = NULL;\n\t\t\treturn 0;\n\t\t}\n\t\t_mmap_orig = *_mmap_addr;\n\t}\n\tlog_debug_mem(\"Remapping mmap entry %02x to %02x.\", _mmap_orig, _instruction_hlt);\n\t*_mmap_addr = _instruction_hlt;\n\n#ifdef __i386__\n\tif (!_mmap64_addr) {\n\t\t_mmap64_addr = (unsigned char *) dlsym(RTLD_NEXT, \"mmap64\");\n\t\tif (_mmap64_addr[0] == 0xff && _mmap64_addr[1] == 0x25) {\n\t\t\tabs_addr = *(void **)(_mmap64_addr + 2);\n\t\t\t_mmap64_addr = *(void **)abs_addr;\n\t\t} /* Can't find PLT jump entry assuming -fPIE linkage */\n\t\tif (mprotect((void *)((unsigned long)_mmap64_addr & ~4095UL), 4096, PROT_READ|PROT_WRITE|PROT_EXEC)) {\n\t\t\tlog_sys_error(\"mprotect\", \"\");\n\t\t\t_mmap64_addr = NULL;\n\t\t\treturn 0;\n\t\t}\n\t\t_mmap64_orig = *_mmap64_addr;\n\t}\n\t*_mmap64_addr = INSTRUCTION_HLT;\n#endif /* __i386__ */\n#endif /* ARCH_X86 */\n\treturn 1;\n}\n\nstatic int _restore_mmap(void)\n{\n#ifdef ARCH_X86\n\tif (_mmap_addr)\n\t\t*_mmap_addr = _mmap_orig;\n#ifdef __i386__\n\tif (_mmap64_addr)\n\t\t*_mmap64_addr = _mmap64_orig;\n#endif /* __i386__ */\n\tlog_debug_mem(\"Restored mmap entry.\");\n#endif /* ARCH_X86 */\n\treturn 1;\n}\nstatic void _raise_priority(struct cmd_context *cmd)\n{\n\tif (_priority_raised)\n\t\treturn;\n\n\t_priority_raised = 1;\n\terrno = 0;\n\tif (((_priority = getpriority(PRIO_PROCESS, 0)) == -1) && errno)\n\t\tlog_sys_debug(\"getpriority\", \"\");\n\telse if (_default_priority < _priority) {\n\t\tif (setpriority(PRIO_PROCESS, 0, _default_priority) == 0)\n\t\t\tlog_debug_activation(\"Raised task priority %d -> %d.\",\n\t\t\t\t\t     _priority, _default_priority);\n\t\telse\n\t\t\tlog_warn(\"WARNING: setpriority %d failed: %s.\",\n\t\t\t\t _default_priority, strerror(errno));\n\t}\n}\n\nstatic void _restore_priority_if_possible(struct cmd_context *cmd)\n{\n\tif (!_priority_raised || _critical_section || _memlock_count_daemon)\n\t\treturn;\n\n\tif (setpriority(PRIO_PROCESS, 0, _priority) == 0)\n\t\tlog_debug_activation(\"Restoring original task priority %d.\", _priority);\n\telse\n\t\tlog_warn(\"WARNING: setpriority %u failed: %s.\",\n\t\t\t _priority, strerror(errno));\n\n\t_priority_raised = 0;\n}\n\n/* Stop memory getting swapped out */\nstatic void _lock_mem(struct cmd_context *cmd)\n{\n\t_allocate_memory();\n\t(void)strerror(0);\t\t/* Force libc.mo load */\n\t(void)dm_udev_get_sync_support(); /* udev is initialized */\n\tlog_very_verbose(\"Locking memory\");\n\n\t/*\n\t * For daemon we need to use mlockall()\n\t * so even future adition of thread which may not even use lvm lib\n\t * will not block memory locked thread\n\t * Note: assuming _memlock_count_daemon is updated before _memlock_count\n\t */\n\t_use_mlockall = _memlock_count_daemon ? 1 :\n\t\tfind_config_tree_bool(cmd, activation_use_mlockall_CFG, NULL);\n\n\tif (!_use_mlockall) {\n\t\tif (!*_procselfmaps &&\n\t\t    dm_snprintf(_procselfmaps, sizeof(_procselfmaps),\n\t\t\t\t\"%s\" SELF_MAPS, cmd->proc_dir) < 0) {\n\t\t\tlog_error(\"proc_dir too long\");\n\t\t\treturn;\n\t\t}\n\n\t\tif (!(_maps_fd = open(_procselfmaps, O_RDONLY))) {\n\t\t\tlog_sys_error(\"open\", _procselfmaps);\n\t\t\treturn;\n\t\t}\n\n\t\tif (!_disable_mmap())\n\t\t\tstack;\n\t}\n\n\tif (!_memlock_maps(cmd, LVM_MLOCK, &_mstats))\n\t\tstack;\n}\n\nstatic void _unlock_mem(struct cmd_context *cmd)\n{\n\tsize_t unlock_mstats;\n\n\tlog_very_verbose(\"Unlocking memory\");\n\n\tif (!_memlock_maps(cmd, LVM_MUNLOCK, &unlock_mstats))\n\t\tstack;\n\n\tif (!_use_mlockall) {\n\t\t_restore_mmap();\n\t\tif (close(_maps_fd))\n\t\t\tlog_sys_error(\"close\", _procselfmaps);\n\t\tfree(_maps_buffer);\n\t\t_maps_buffer = NULL;\n\t\tif (_mstats < unlock_mstats) {\n\t\t\tif ((_mstats + lvm_getpagesize()) < unlock_mstats)\n\t\t\t\tlog_error(INTERNAL_ERROR\n\t\t\t\t\t  \"Reserved memory (%ld) not enough: used %ld. Increase activation/reserved_memory?\",\n\t\t\t\t\t  (long)_mstats, (long)unlock_mstats);\n\t\t\telse\n\t\t\t\t/* FIXME Believed due to incorrect use of yes_no_prompt while locks held */\n\t\t\t\tlog_debug_mem(\"Suppressed internal error: Maps lock %ld < unlock %ld, a one-page difference.\",\n\t\t\t\t\t      (long)_mstats, (long)unlock_mstats);\n\t\t}\n\t}\n\n\t_restore_priority_if_possible(cmd);\n\n\t_release_memory();\n}\n\nstatic void _lock_mem_if_needed(struct cmd_context *cmd)\n{\n\tlog_debug_mem(\"Lock:   Memlock counters: prioritized:%d locked:%d critical:%d daemon:%d suspended:%d\",\n\t\t      _priority_raised, _mem_locked, _critical_section, _memlock_count_daemon, dm_get_suspended_counter());\n\tif (!_mem_locked &&\n\t    ((_critical_section + _memlock_count_daemon) == 1)) {\n\t\t_mem_locked = 1;\n\t\t_lock_mem(cmd);\n\t}\n}\n\nstatic void _unlock_mem_if_possible(struct cmd_context *cmd)\n{\n\tlog_debug_mem(\"Unlock: Memlock counters: prioritized:%d locked:%d critical:%d daemon:%d suspended:%d\",\n\t\t      _priority_raised, _mem_locked, _critical_section, _memlock_count_daemon, dm_get_suspended_counter());\n\tif (_mem_locked &&\n\t    !_critical_section &&\n\t    !_memlock_count_daemon) {\n\t\t_unlock_mem(cmd);\n\t\t_mem_locked = 0;\n\t}\n}\n\n/*\n * Critical section is only triggered with suspending reason.\n * Other reasons only raise process priority so the table manipulation\n * remains fast.\n *\n * Memory stays locked until 'memlock_unlock()' is called so when possible\n * it may stay locked across multiple crictical section entrances.\n */\nvoid critical_section_inc(struct cmd_context *cmd, const char *reason)\n{\n\tif (!_critical_section &&\n\t    (strcmp(reason, \"suspending\") == 0)) {\n\t\t/*\n\t\t * Profiles are loaded on-demand so make sure that before\n\t\t * entering the critical section all needed profiles are\n\t\t * loaded to avoid the disk access later.\n\t\t */\n\t\t(void) load_pending_profiles(cmd);\n\t\t_critical_section = 1;\n\t\tlog_debug_activation(\"Entering critical section (%s).\", reason);\n\t\t_lock_mem_if_needed(cmd);\n\t} else\n\t\tlog_debug_activation(\"Entering prioritized section (%s).\", reason);\n\n\t_raise_priority(cmd);\n\t_prioritized_section++;\n}\n\nvoid critical_section_dec(struct cmd_context *cmd, const char *reason)\n{\n\tif (_critical_section && !dm_get_suspended_counter()) {\n\t\t_critical_section = 0;\n\t\tlog_debug_activation(\"Leaving critical section (%s).\", reason);\n\t} else\n\t\tlog_debug_activation(\"Leaving section (%s).\", reason);\n\n\tif (_prioritized_section > 0)\n\t\t_prioritized_section--;\n}\n\nint critical_section(void)\n{\n\treturn _critical_section;\n}\n\nint prioritized_section(void)\n{\n\treturn _prioritized_section;\n}\n\n/*\n * The memlock_*_daemon functions will force the mlockall() call that we need\n * to stay in memory, but they will have no effect on device scans (unlike\n * normal critical_section_inc/dec). Memory is kept locked as long as either\n * of critical_section or memlock_daemon is in effect.\n */\n\nvoid memlock_inc_daemon(struct cmd_context *cmd)\n{\n\t++_memlock_count_daemon;\n\tif (_memlock_count_daemon == 1 && _critical_section > 0)\n\t\tlog_error(INTERNAL_ERROR \"_memlock_inc_daemon used in critical section.\");\n\tlog_debug_mem(\"memlock_count_daemon inc to %d\", _memlock_count_daemon);\n\t_lock_mem_if_needed(cmd);\n\t_raise_priority(cmd);\n}\n\nvoid memlock_dec_daemon(struct cmd_context *cmd)\n{\n\tif (!_memlock_count_daemon)\n\t\tlog_error(INTERNAL_ERROR \"_memlock_count_daemon has dropped below 0.\");\n\t--_memlock_count_daemon;\n\tlog_debug_mem(\"memlock_count_daemon dec to %d\", _memlock_count_daemon);\n\t_unlock_mem_if_possible(cmd);\n}\n\nvoid memlock_init(struct cmd_context *cmd)\n{\n\t/* When threaded, caller already limited stack size so just use the default. */\n\t_size_stack = 1024ULL * (cmd->threaded ? DEFAULT_RESERVED_STACK :\n\t\t\t\t find_config_tree_int(cmd, activation_reserved_stack_CFG, NULL));\n\t_size_malloc_tmp = find_config_tree_int(cmd, activation_reserved_memory_CFG, NULL) * 1024ULL;\n\t_default_priority = find_config_tree_int(cmd, activation_process_priority_CFG, NULL);\n}\n\nvoid memlock_reset(void)\n{\n\tlog_debug_mem(\"memlock reset.\");\n\t_mem_locked = 0;\n\t_priority_raised = 0;\n\t_critical_section = 0;\n\t_prioritized_section = 0;\n\t_memlock_count_daemon = 0;\n}\n\nvoid memlock_unlock(struct cmd_context *cmd)\n{\n\t_unlock_mem_if_possible(cmd);\n\t_restore_priority_if_possible(cmd);\n}\n\nint memlock_count_daemon(void)\n{\n\treturn _memlock_count_daemon;\n}\n\n#endif\n",
        "/tmp/vanessa/spack-stage/spack-stage-lvm2-2.03.05-f3l3iqzw3duerkzigowryif6fns7ok2e/spack-src/daemons/dmeventd/dmeventd.c": "/*\n * Copyright (C) 2005-2015 Red Hat, Inc. All rights reserved.\n *\n * This file is part of the device-mapper userspace tools.\n *\n * This copyrighted material is made available to anyone wishing to use,\n * modify, copy, or redistribute it subject to the terms and conditions\n * of the GNU Lesser General Public License v.2.1.\n *\n * You should have received a copy of the GNU Lesser General Public License\n * along with this program; if not, write to the Free Software Foundation,\n * Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n */\n\n/*\n * dmeventd - dm event daemon to monitor active mapped devices\n */\n\n\n#include \"libdevmapper-event.h\"\n#include \"dmeventd.h\"\n\n#include \"libdm/misc/dm-logging.h\"\n#include \"base/memory/zalloc.h\"\n\n#include <dlfcn.h>\n#include <pthread.h>\n#include <sys/file.h>\n#include <sys/stat.h>\n#include <sys/wait.h>\n#include <sys/time.h>\n#include <sys/resource.h>\n#include <signal.h>\n#include <arpa/inet.h>\t\t/* for htonl, ntohl */\n#include <fcntl.h>\t\t/* for musl libc */\n#include <unistd.h>\n#include <syslog.h>\n\n#ifdef __linux__\n/*\n * Kernel version 2.6.36 and higher has\n * new OOM killer adjustment interface.\n */\n#  define OOM_ADJ_FILE_OLD \"/proc/self/oom_adj\"\n#  define OOM_ADJ_FILE \"/proc/self/oom_score_adj\"\n\n/* From linux/oom.h */\n/* Old interface */\n#  define OOM_DISABLE (-17)\n#  define OOM_ADJUST_MIN (-16)\n/* New interface */\n#  define OOM_SCORE_ADJ_MIN (-1000)\n\n/* Systemd on-demand activation support */\n#  define SD_RUNTIME_UNIT_FILE_DIR DEFAULT_DM_RUN_DIR \"/systemd/system/\"\n#  define SD_ACTIVATION_ENV_VAR_NAME \"SD_ACTIVATION\"\n#  define SD_LISTEN_PID_ENV_VAR_NAME \"LISTEN_PID\"\n#  define SD_LISTEN_FDS_ENV_VAR_NAME \"LISTEN_FDS\"\n#  define SD_LISTEN_FDS_START 3\n#  define SD_FD_FIFO_SERVER SD_LISTEN_FDS_START\n#  define SD_FD_FIFO_CLIENT (SD_LISTEN_FDS_START + 1)\n\n#endif\n\n#define DM_SIGNALED_EXIT  1\n#define DM_SCHEDULED_EXIT 2\nstatic volatile sig_atomic_t _exit_now = 0;\t/* set to '1' when signal is given to exit */\n\n/* List (un)link macros. */\n#define\tLINK(x, head)\t\tdm_list_add(head, &(x)->list)\n#define\tLINK_DSO(dso)\t\tLINK(dso, &_dso_registry)\n#define\tLINK_THREAD(thread)\tLINK(thread, &_thread_registry)\n\n#define\tUNLINK(x)\t\tdm_list_del(&(x)->list)\n#define\tUNLINK_DSO(x)\t\tUNLINK(x)\n#define\tUNLINK_THREAD(x)\tUNLINK(x)\n\n#define DAEMON_NAME \"dmeventd\"\n\n/*\n  Global mutex for thread list access. Has to be held when:\n  - iterating thread list\n  - adding or removing elements from thread list\n  - changing or reading thread_status's fields:\n    processing, status, events\n  Use _lock_mutex() and _unlock_mutex() to hold/release it\n*/\nstatic pthread_mutex_t _global_mutex;\n\nstatic const size_t THREAD_STACK_SIZE = 300 * 1024;\n\n/* Default idle exit timeout 1 hour (in seconds) */\nstatic const time_t DMEVENTD_IDLE_EXIT_TIMEOUT = 60 * 60;\n\nstatic int _debug_level = 0;\nstatic int _use_syslog = 1;\nstatic int _systemd_activation = 0;\nstatic int _foreground = 0;\nstatic int _restart = 0;\nstatic time_t _idle_since = 0;\nstatic char **_initial_registrations = 0;\n\n/* FIXME Make configurable at runtime */\n\n/* All libdm messages */\n__attribute__((format(printf, 5, 6)))\nstatic void _libdm_log(int level, const char *file, int line,\n\t\t       int dm_errno_or_class, const char *format, ...)\n{\n\tva_list ap;\n\tva_start(ap, format);\n\tdm_event_log(\"#dm\", level, file, line, dm_errno_or_class, format, ap);\n\tva_end(ap);\n}\n\n/* All dmeventd messages */\n#undef LOG_MESG\n#define LOG_MESG(l, f, ln, e, x...) _dmeventd_log(l, f, ln, e, ## x)\n__attribute__((format(printf, 5, 6)))\nstatic void _dmeventd_log(int level, const char *file, int line,\n\t\t\t  int dm_errno_or_class, const char *format, ...)\n{\n\tva_list ap;\n\tva_start(ap, format);\n\tdm_event_log(\"dmeventd\", level, file, line, dm_errno_or_class, format, ap);\n\tva_end(ap);\n}\n\n#ifdef DEBUG\n#  define DEBUGLOG  log_debug\nstatic const char *decode_cmd(uint32_t cmd)\n{\n\tswitch (cmd) {\n\tcase DM_EVENT_CMD_ACTIVE:\t\t\treturn \"ACTIVE\";\n\tcase DM_EVENT_CMD_REGISTER_FOR_EVENT:\t\treturn \"REGISTER_FOR_EVENT\";\n\tcase DM_EVENT_CMD_UNREGISTER_FOR_EVENT:\t\treturn \"UNREGISTER_FOR_EVENT\";\n\tcase DM_EVENT_CMD_GET_REGISTERED_DEVICE:\treturn \"GET_REGISTERED_DEVICE\";\n\tcase DM_EVENT_CMD_GET_NEXT_REGISTERED_DEVICE:\treturn \"GET_NEXT_REGISTERED_DEVICE\";\n\tcase DM_EVENT_CMD_SET_TIMEOUT:\t\t\treturn \"SET_TIMEOUT\";\n\tcase DM_EVENT_CMD_GET_TIMEOUT:\t\t\treturn \"GET_TIMEOUT\";\n\tcase DM_EVENT_CMD_HELLO:\t\t\treturn \"HELLO\";\n\tcase DM_EVENT_CMD_DIE:\t\t\t\treturn \"DIE\";\n\tcase DM_EVENT_CMD_GET_STATUS:\t\t\treturn \"GET_STATUS\";\n\tcase DM_EVENT_CMD_GET_PARAMETERS:\t\treturn \"GET_PARAMETERS\";\n\tdefault:\t\t\t\t\treturn \"unknown\";\n\t}\n}\n\n#else\n#  define DEBUGLOG(fmt, args...) do { } while (0)\n#endif\n\n/* Data kept about a DSO. */\nstruct dso_data {\n\tstruct dm_list list;\n\n\tchar *dso_name;\t\t/* DSO name (eg, \"evms\", \"dmraid\", \"lvm2\"). */\n\n\tvoid *dso_handle;\t/* Opaque handle as returned from dlopen(). */\n\tunsigned int ref_count;\t/* Library reference count. */\n\n\t/*\n\t * Event processing.\n\t *\n\t * The DSO can do whatever appropriate steps if an event\n\t * happens such as changing the mapping in case a mirror\n\t * fails, update the application metadata etc.\n\t *\n\t * This function gets a dm_task that is a result of\n\t * DM_DEVICE_WAITEVENT ioctl (results equivalent to\n\t * DM_DEVICE_STATUS). It should not destroy it.\n\t * The caller must dispose of the task.\n\t */\n\tvoid (*process_event)(struct dm_task *dmt, enum dm_event_mask event, void **user);\n\n\t/*\n\t * Device registration.\n\t *\n\t * When an application registers a device for an event, the DSO\n\t * can carry out appropriate steps so that a later call to\n\t * the process_event() function is sane (eg, read metadata\n\t * and activate a mapping).\n\t */\n\tint (*register_device)(const char *device, const char *uuid, int major,\n\t\t\t       int minor, void **user);\n\n\t/*\n\t * Device unregistration.\n\t *\n\t * In case all devices of a mapping (eg, RAID10) are unregistered\n\t * for events, the DSO can recognize this and carry out appropriate\n\t * steps (eg, deactivate mapping, metadata update).\n\t */\n\tint (*unregister_device)(const char *device, const char *uuid,\n\t\t\t\t int major, int minor, void **user);\n};\nstatic DM_LIST_INIT(_dso_registry);\n\n/* Structure to keep parsed register variables from client message. */\nstruct message_data {\n\tchar *id;\n\tchar *dso_name;\t\t/* Name of DSO. */\n\tchar *device_uuid;\t/* Mapped device path. */\n\tchar *events_str;\t/* Events string as fetched from message. */\n\tenum dm_event_mask events_field;\t/* Events bitfield. */\n\tchar *timeout_str;\n\tuint32_t timeout_secs;\n\tstruct dm_event_daemon_message *msg;\t/* Pointer to message buffer. */\n};\n\n/* There are three states a thread can attain. */\nenum {\n\tDM_THREAD_REGISTERING,\t/* Registering, transitions to RUNNING */\n\tDM_THREAD_RUNNING,\t/* Working on events, transitions to DONE */\n\tDM_THREAD_DONE\t\t/* Terminated and cleanup is pending */\n};\n\n/*\n * Housekeeping of thread+device states.\n *\n * One thread per mapped device which can block on it until an event\n * occurs and the event processing function of the DSO gets called.\n */\nstruct thread_status {\n\tstruct dm_list list;\n\n\tpthread_t thread;\n\n\tstruct dso_data *dso_data;\t/* DSO this thread accesses. */\n\n\tstruct {\n\t\tchar *uuid;\n\t\tchar *name;\n\t\tint major, minor;\n\t} device;\n\tint processing;\t\t/* Set when event is being processed */\n\n\tint status;\t\t/* See DM_THREAD_{REGISTERING,RUNNING,DONE} */\n\n\tint events;\t\t/* bitfield for event filter. */\n\tint current_events;\t/* bitfield for occured events. */\n\tstruct dm_task *wait_task;\n\tint pending;\t\t/* Set when event filter change is pending */\n\ttime_t next_time;\n\tuint32_t timeout;\n\tstruct dm_list timeout_list;\n\tvoid *dso_private; /* dso per-thread status variable */\n\t/* TODO per-thread mutex */\n};\n\nstatic DM_LIST_INIT(_thread_registry);\nstatic DM_LIST_INIT(_thread_registry_unused);\n\nstatic int _timeout_running;\nstatic DM_LIST_INIT(_timeout_registry);\nstatic pthread_mutex_t _timeout_mutex = PTHREAD_MUTEX_INITIALIZER;\nstatic pthread_cond_t _timeout_cond = PTHREAD_COND_INITIALIZER;\n\n\n/**********\n *   DSO\n **********/\n\n/* DSO data allocate/free. */\nstatic void _free_dso_data(struct dso_data *data)\n{\n\tfree(data->dso_name);\n\tfree(data);\n}\n\nstatic struct dso_data *_alloc_dso_data(struct message_data *data)\n{\n\tstruct dso_data *ret = (typeof(ret)) zalloc(sizeof(*ret));\n\n\tif (!ret)\n\t\treturn_NULL;\n\n\tif (!(ret->dso_name = strdup(data->dso_name))) {\n\t\tfree(ret);\n\t\treturn_NULL;\n\t}\n\n\treturn ret;\n}\n\n/* DSO reference counting. */\nstatic void _lib_get(struct dso_data *data)\n{\n\tdata->ref_count++;\n}\n\nstatic void _lib_put(struct dso_data *data)\n{\n\tif (!--data->ref_count) {\n\t\tdlclose(data->dso_handle);\n\t\tUNLINK_DSO(data);\n\t\t_free_dso_data(data);\n\n\t\t/* Close control device if there is no plugin in-use */\n\t\tif (dm_list_empty(&_dso_registry)) {\n\t\t\tDEBUGLOG(\"Unholding control device.\");\n\t\t\tdm_hold_control_dev(0);\n\t\t\tdm_lib_release();\n\t\t\t_idle_since = time(NULL);\n\t\t}\n\t}\n}\n\n/* Find DSO data. */\nstatic struct dso_data *_lookup_dso(struct message_data *data)\n{\n\tstruct dso_data *dso_data, *ret = NULL;\n\n\tdm_list_iterate_items(dso_data, &_dso_registry)\n\t\tif (!strcmp(data->dso_name, dso_data->dso_name)) {\n\t\t\tret = dso_data;\n\t\t\tbreak;\n\t\t}\n\n\treturn ret;\n}\n\n/* Lookup DSO symbols we need. */\nstatic int _lookup_symbol(void *dl, void **symbol, const char *name)\n{\n\tif (!(*symbol = dlsym(dl, name)))\n\t\treturn_0;\n\n\treturn 1;\n}\n\nstatic int _lookup_symbols(void *dl, struct dso_data *data)\n{\n\treturn _lookup_symbol(dl, (void *) &data->process_event,\n\t\t\t     \"process_event\") &&\n\t    _lookup_symbol(dl, (void *) &data->register_device,\n\t\t\t  \"register_device\") &&\n\t    _lookup_symbol(dl, (void *) &data->unregister_device,\n\t\t\t  \"unregister_device\");\n}\n\n/* Load an application specific DSO. */\nstatic struct dso_data *_load_dso(struct message_data *data)\n{\n\tvoid *dl;\n\tstruct dso_data *ret;\n\tconst char *dlerr;\n\n\tif (!(dl = dlopen(data->dso_name, RTLD_NOW))) {\n\t\tdlerr = dlerror();\n\t\tgoto_bad;\n\t}\n\n\tif (!(ret = _alloc_dso_data(data))) {\n\t\tdlclose(dl);\n\t\tdlerr = \"no memory\";\n\t\tgoto_bad;\n\t}\n\n\tif (!(_lookup_symbols(dl, ret))) {\n\t\t_free_dso_data(ret);\n\t\tdlclose(dl);\n\t\tdlerr = \"symbols missing\";\n\t\tgoto_bad;\n\t}\n\n\t/* Keep control device open until last user closes */\n\tif (dm_list_empty(&_dso_registry)) {\n\t\tDEBUGLOG(\"Holding control device open.\");\n\t\tdm_hold_control_dev(1);\n\t\t_idle_since = 0;\n\t}\n\n\t/*\n\t * Keep handle to close the library once\n\t * we've got no references to it any more.\n\t */\n\tret->dso_handle = dl;\n\tLINK_DSO(ret);\n\n\treturn ret;\nbad:\n\tlog_error(\"dmeventd %s dlopen failed: %s.\", data->dso_name, dlerr);\n\tdata->msg->size = dm_asprintf(&(data->msg->data), \"%s %s dlopen failed: %s\",\n\t\t\t\t      data->id, data->dso_name, dlerr);\n\treturn NULL;\n}\n\n/************\n *  THREAD\n ************/\n\n/* Allocate/free the thread status structure for a monitoring thread. */\nstatic void _free_thread_status(struct thread_status *thread)\n{\n\n\t_lib_put(thread->dso_data);\n\tif (thread->wait_task)\n\t\tdm_task_destroy(thread->wait_task);\n\tfree(thread->device.uuid);\n\tfree(thread->device.name);\n\tfree(thread);\n}\n\n/* Note: events_field must not be 0, ensured by caller */\nstatic struct thread_status *_alloc_thread_status(const struct message_data *data,\n\t\t\t\t\t\t  struct dso_data *dso_data)\n{\n\tstruct thread_status *thread;\n\n\tif (!(thread = zalloc(sizeof(*thread)))) {\n\t\tlog_error(\"Cannot create new thread, out of memory.\");\n\t\treturn NULL;\n\t}\n\n\t_lib_get(dso_data);\n\tthread->dso_data = dso_data;\n\n\tif (!(thread->wait_task = dm_task_create(DM_DEVICE_WAITEVENT)))\n\t\tgoto_out;\n\n\tif (!dm_task_set_uuid(thread->wait_task, data->device_uuid))\n\t\tgoto_out;\n\n\tif (!(thread->device.uuid = strdup(data->device_uuid)))\n\t\tgoto_out;\n\n\t/* Until real name resolved, use UUID */\n\tif (!(thread->device.name = strdup(data->device_uuid)))\n\t\tgoto_out;\n\n\t/* runs ioctl and may register lvm2 pluging */\n\tthread->processing = 1;\n\tthread->status = DM_THREAD_REGISTERING;\n\n\tthread->events = data->events_field;\n\tthread->pending = DM_EVENT_REGISTRATION_PENDING;\n\tthread->timeout = data->timeout_secs;\n\tdm_list_init(&thread->timeout_list);\n\n\treturn thread;\n\nout:\n\t_free_thread_status(thread);\n\n\treturn NULL;\n}\n\n/*\n * Create a device monitoring thread.\n * N.B.  Error codes returned are positive.\n */\nstatic int _pthread_create_smallstack(pthread_t *t, void *(*fun)(void *), void *arg)\n{\n\tint r;\n\tpthread_t tmp;\n\tpthread_attr_t attr;\n\n\t/*\n\t * From pthread_attr_init man page:\n\t * POSIX.1-2001 documents an ENOMEM error for pthread_attr_init(); on\n\t * Linux these functions always succeed (but portable and future-proof\n\t * applications should nevertheless handle a possible error return).\n\t */\n\tif ((r = pthread_attr_init(&attr)) != 0) {\n\t\tlog_sys_error(\"pthread_attr_init\", \"\");\n\t\treturn r;\n\t}\n\n\t/*\n\t * We use a smaller stack since it gets preallocated in its entirety\n\t */\n\tpthread_attr_setstacksize(&attr, THREAD_STACK_SIZE + getpagesize());\n\n\t/*\n\t * If no-one will be waiting, we need to detach.\n\t */\n\tif (!t) {\n\t\tpthread_attr_setdetachstate(&attr, PTHREAD_CREATE_DETACHED);\n\t\tt = &tmp;\n\t}\n\n\tif ((r = pthread_create(t, &attr, fun, arg)))\n\t\tlog_sys_error(\"pthread_create\", \"\");\n\n\tpthread_attr_destroy(&attr);\n\n\treturn r;\n}\n\n/*\n * Fetch a string off src and duplicate it into *ptr.\n * Pay attention to zero-length and 'empty' strings ('-').\n */\n/* FIXME? move to libdevmapper to share with the client lib (need to\n   make delimiter a parameter then) */\nstatic int _fetch_string(char **ptr, char **src, const int delimiter)\n{\n\tint ret = 1;\n\tchar *p;\n\tsize_t len;\n\t*ptr = NULL; /* Empty field returns NULL pointer */\n\n\tif ((*src)[0] == '-') {\n\t\t/* Could be empty field '-', handle without allocation */\n\t\tif ((*src)[1] == '\\0') {\n\t\t\t(*src)++;\n\t\t\tgoto out;\n\t\t} else if ((*src)[1] == delimiter) {\n\t\t\t(*src) += 2;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tif ((p = strchr(*src, delimiter))) {\n\t\tif (*src < p) {\n\t\t\t*p = 0; /* Temporary exit with \\0 */\n\t\t\tif (!(*ptr = strdup(*src))) {\n\t\t\t\tlog_error(\"Failed to fetch item %s.\", *src);\n\t\t\t\tret = 0; /* Allocation fail */\n\t\t\t}\n\t\t\t*p = delimiter;\n\t\t\t*src = p;\n\t\t}\n\t\t(*src)++; /* Skip delmiter, next field */\n\t} else if ((len = strlen(*src))) {\n\t\t/* No delimiter, item ends with '\\0' */\n\t\tif (!(*ptr = strdup(*src))) {\n\t\t\tlog_error(\"Failed to fetch last item %s.\", *src);\n\t\t\tret = 0; /* Fail */\n\t\t}\n\t\t*src += len + 1;\n\t}\nout:\n\treturn ret;\n}\n\n/* Free message memory. */\nstatic void _free_message(struct message_data *message_data)\n{\n\tfree(message_data->id);\n\tfree(message_data->dso_name);\n\tfree(message_data->device_uuid);\n\tfree(message_data->events_str);\n\tfree(message_data->timeout_str);\n}\n\n/* Parse a register message from the client. */\nstatic int _parse_message(struct message_data *message_data)\n{\n\tint ret = 0;\n\tstruct dm_event_daemon_message *msg = message_data->msg;\n\tchar *p = msg->data;\n\n\tif (!msg->data)\n\t\treturn 0;\n\n\t/*\n\t * Retrieve application identifier, mapped device\n\t * path and events # string from message.\n\t */\n\tif (_fetch_string(&message_data->id, &p, ' ') &&\n\t    _fetch_string(&message_data->dso_name, &p, ' ') &&\n\t    _fetch_string(&message_data->device_uuid, &p, ' ') &&\n\t    _fetch_string(&message_data->events_str, &p, ' ') &&\n\t    _fetch_string(&message_data->timeout_str, &p, ' ')) {\n\t\tif (message_data->events_str)\n\t\t\tmessage_data->events_field =\n\t\t\t\tatoi(message_data->events_str);\n\t\tif (message_data->timeout_str)\n\t\t\tmessage_data->timeout_secs =\n\t\t\t\tatoi(message_data->timeout_str)\n\t\t\t\t? : DM_EVENT_DEFAULT_TIMEOUT;\n\t\tret = 1;\n\t}\n\n\tfree(msg->data);\n\tmsg->data = NULL;\n\n\treturn ret;\n}\n\n/* Global mutex to lock access to lists et al. See _global_mutex\n   above. */\nstatic int _lock_mutex(void)\n{\n\treturn pthread_mutex_lock(&_global_mutex);\n}\n\nstatic int _unlock_mutex(void)\n{\n\treturn pthread_mutex_unlock(&_global_mutex);\n}\n\n/* Check, if a device exists. */\nstatic int _fill_device_data(struct thread_status *ts)\n{\n\tstruct dm_task *dmt;\n\tstruct dm_info dmi;\n\tint ret = 0;\n\n\tif (!(dmt = dm_task_create(DM_DEVICE_INFO)))\n\t\treturn 0;\n\n\tif (!dm_task_set_uuid(dmt, ts->device.uuid))\n\t\tgoto fail;\n\n\tif (!dm_task_run(dmt))\n\t\tgoto fail;\n\n\tfree(ts->device.name);\n\tif (!(ts->device.name = strdup(dm_task_get_name(dmt))))\n\t\tgoto fail;\n\n\tif (!dm_task_get_info(dmt, &dmi))\n\t\tgoto fail;\n\n\tts->device.major = dmi.major;\n\tts->device.minor = dmi.minor;\n\tdm_task_set_event_nr(ts->wait_task, dmi.event_nr);\n\n\tret = 1;\nfail:\n\tdm_task_destroy(dmt);\n\n\treturn ret;\n}\n\nstatic struct dm_task *_get_device_status(struct thread_status *ts)\n{\n\tstruct dm_task *dmt = dm_task_create(DM_DEVICE_STATUS);\n\n\tif (!dmt)\n\t\treturn_NULL;\n\n\tif (!dm_task_set_uuid(dmt, ts->device.uuid)) {\n\t\tdm_task_destroy(dmt);\n\t\treturn_NULL;\n\t}\n\n\t/* Non-blocking status read */\n\tif (!dm_task_no_flush(dmt))\n\t\tlog_warn(\"WARNING: Can't set no_flush for dm status.\");\n\n\tif (!dm_task_run(dmt)) {\n\t\tdm_task_destroy(dmt);\n\t\treturn_NULL;\n\t}\n\n\treturn dmt;\n}\n\n/*\n * Find an existing thread for a device.\n *\n * Mutex must be held when calling this.\n */\nstatic struct thread_status *_lookup_thread_status(struct message_data *data)\n{\n\tstruct thread_status *thread;\n\n\tdm_list_iterate_items(thread, &_thread_registry)\n\t\tif (!strcmp(data->device_uuid, thread->device.uuid))\n\t\t\treturn thread;\n\n\treturn NULL;\n}\n\nstatic int _get_status(struct message_data *message_data)\n{\n\tstruct dm_event_daemon_message *msg = message_data->msg;\n\tstruct thread_status *thread;\n\tint i = 0, j;\n\tint ret = -ENOMEM;\n\tint count;\n\tint size = 0, current;\n\tsize_t len;\n\tchar **buffers;\n\tchar *message;\n\n\t_lock_mutex();\n\tcount = dm_list_size(&_thread_registry);\n\tbuffers = alloca(sizeof(char*) * count);\n\tdm_list_iterate_items(thread, &_thread_registry) {\n\t\tif ((current = dm_asprintf(buffers + i, \"0:%d %s %s %u %\" PRIu32 \";\",\n\t\t\t\t\t   i, thread->dso_data->dso_name,\n\t\t\t\t\t   thread->device.uuid, thread->events,\n\t\t\t\t\t   thread->timeout)) < 0) {\n\t\t\t_unlock_mutex();\n\t\t\tgoto out;\n\t\t}\n\t\t++i;\n\t\tsize += current; /* count with trailing '\\0' */\n\t}\n\t_unlock_mutex();\n\n\tlen = strlen(message_data->id);\n\tmsg->size = size + len + 1;\n\tfree(msg->data);\n\tif (!(msg->data = malloc(msg->size)))\n\t\tgoto out;\n\n\tmemcpy(msg->data, message_data->id, len);\n\tmessage = msg->data + len;\n\t*message++ = ' ';\n\tfor (j = 0; j < i; ++j) {\n\t\tlen = strlen(buffers[j]);\n\t\tmemcpy(message, buffers[j], len);\n\t\tmessage += len;\n\t}\n\n\tret = 0;\n out:\n\tfor (j = 0; j < i; ++j)\n\t\tfree(buffers[j]);\n\n\treturn ret;\n}\n\nstatic int _get_parameters(struct message_data *message_data) {\n\tstruct dm_event_daemon_message *msg = message_data->msg;\n\tint size;\n\n\tfree(msg->data);\n\tif ((size = dm_asprintf(&msg->data, \"%s pid=%d daemon=%s exec_method=%s\",\n\t\t\t\tmessage_data->id, getpid(),\n\t\t\t\t_foreground ? \"no\" : \"yes\",\n\t\t\t\t_systemd_activation ? \"systemd\" : \"direct\")) < 0) {\n\t\tstack;\n\t\treturn -ENOMEM;\n\t}\n\n\tmsg->size = (uint32_t) size;\n\n\treturn 0;\n}\n\n/* Cleanup at exit. */\nstatic void _exit_dm_lib(void)\n{\n\tdm_lib_release();\n\tdm_lib_exit();\n}\n\nstatic void _exit_timeout(void *unused __attribute__((unused)))\n{\n\t_timeout_running = 0;\n\tpthread_mutex_unlock(&_timeout_mutex);\n}\n\n/* Wake up monitor threads every so often. */\nstatic void *_timeout_thread(void *unused __attribute__((unused)))\n{\n\tstruct thread_status *thread;\n\tstruct timespec timeout;\n\ttime_t curr_time;\n\tint ret;\n\n\tDEBUGLOG(\"Timeout thread starting.\");\n\tpthread_cleanup_push(_exit_timeout, NULL);\n\tpthread_mutex_lock(&_timeout_mutex);\n\n\twhile (!dm_list_empty(&_timeout_registry)) {\n\t\ttimeout.tv_sec = 0;\n\t\ttimeout.tv_nsec = 0;\n\t\tcurr_time = time(NULL);\n\n\t\tdm_list_iterate_items_gen(thread, &_timeout_registry, timeout_list) {\n\t\t\tif (thread->next_time <= curr_time) {\n\t\t\t\tthread->next_time = curr_time + thread->timeout;\n\t\t\t\t_lock_mutex();\n\t\t\t\tif (thread->processing) {\n\t\t\t\t\t/* Cannot signal processing monitoring thread */\n\t\t\t\t\tlog_debug(\"Skipping SIGALRM to processing Thr %x for timeout.\",\n\t\t\t\t\t\t  (int) thread->thread);\n\t\t\t\t} else {\n\t\t\t\t\tDEBUGLOG(\"Sending SIGALRM to Thr %x for timeout.\",\n\t\t\t\t\t\t (int) thread->thread);\n\t\t\t\t\tret = pthread_kill(thread->thread, SIGALRM);\n\t\t\t\t\tif (ret && (ret != ESRCH))\n\t\t\t\t\t\tlog_error(\"Unable to wakeup Thr %x for timeout: %s.\",\n\t\t\t\t\t\t\t  (int) thread->thread, strerror(ret));\n\t\t\t\t}\n\t\t\t\t_unlock_mutex();\n\t\t\t}\n\n\t\t\tif (thread->next_time < timeout.tv_sec || !timeout.tv_sec)\n\t\t\t\ttimeout.tv_sec = thread->next_time;\n\t\t}\n\n\t\tpthread_cond_timedwait(&_timeout_cond, &_timeout_mutex,\n\t\t\t\t       &timeout);\n\t}\n\n\tDEBUGLOG(\"Timeout thread finished.\");\n\tpthread_cleanup_pop(1);\n\n\treturn NULL;\n}\n\nstatic int _register_for_timeout(struct thread_status *thread)\n{\n\tint ret = 0;\n\n\tpthread_mutex_lock(&_timeout_mutex);\n\n\tif (dm_list_empty(&thread->timeout_list)) {\n\t\tthread->next_time = time(NULL) + thread->timeout;\n\t\tdm_list_add(&_timeout_registry, &thread->timeout_list);\n\t\tif (_timeout_running)\n\t\t\tpthread_cond_signal(&_timeout_cond);\n\t}\n\n\tif (!_timeout_running &&\n\t    !(ret = _pthread_create_smallstack(NULL, _timeout_thread, NULL)))\n\t\t_timeout_running = 1;\n\n\tpthread_mutex_unlock(&_timeout_mutex);\n\n\treturn ret;\n}\n\nstatic void _unregister_for_timeout(struct thread_status *thread)\n{\n\tpthread_mutex_lock(&_timeout_mutex);\n\tif (!dm_list_empty(&thread->timeout_list)) {\n\t\tdm_list_del(&thread->timeout_list);\n\t\tdm_list_init(&thread->timeout_list);\n\t\tif (dm_list_empty(&_timeout_registry))\n\t\t\t/* No more work -> wakeup to finish quickly */\n\t\t\tpthread_cond_signal(&_timeout_cond);\n\t}\n\tpthread_mutex_unlock(&_timeout_mutex);\n}\n\n#ifdef DEBUG_SIGNALS\n/* Print list of signals within a signal set */\nstatic void _print_sigset(const char *prefix, const sigset_t *sigset)\n{\n\tint sig, cnt = 0;\n\n\tfor (sig = 1; sig < NSIG; sig++)\n\t\tif (!sigismember(sigset, sig)) {\n\t\t\tcnt++;\n\t\t\tlog_debug(\"%s%d (%s)\", prefix, sig, strsignal(sig));\n\t\t}\n\n\tif (!cnt)\n\t\tlog_debug(\"%s<empty signal set>\", prefix);\n}\n#endif\n\nenum {\n\tDM_WAIT_RETRY,\n\tDM_WAIT_INTR,\n\tDM_WAIT_FATAL\n};\n\n/* Wait on a device until an event occurs. */\nstatic int _event_wait(struct thread_status *thread)\n{\n\tsigset_t set, old;\n\tint ret = DM_WAIT_RETRY;\n\tstruct dm_info info;\n\n\t/* TODO: audit libdm thread usage */\n\n\t/*\n\t * This is so that you can break out of waiting on an event,\n\t * either for a timeout event, or to cancel the thread.\n\t */\n\tsigemptyset(&old);\n\tsigemptyset(&set);\n\tsigaddset(&set, SIGALRM);\n\tif (pthread_sigmask(SIG_UNBLOCK, &set, &old) != 0) {\n\t\tlog_sys_error(\"pthread_sigmask\", \"unblock alarm\");\n\t\treturn ret; /* What better */\n\t}\n\n\tif (dm_task_run(thread->wait_task)) {\n\t\tthread->current_events |= DM_EVENT_DEVICE_ERROR;\n\t\tret = DM_WAIT_INTR;\n\t\t/* Update event_nr */\n\t\tif (dm_task_get_info(thread->wait_task, &info))\n\t\t\tdm_task_set_event_nr(thread->wait_task, info.event_nr);\n\t} else {\n\t\tswitch (dm_task_get_errno(thread->wait_task)) {\n\t\tcase ENXIO:\n\t\t\tlog_error(\"%s disappeared, detaching.\",\n\t\t\t\t  thread->device.name);\n\t\t\tret = DM_WAIT_FATAL;\n\t\t\tbreak;\n\t\tcase EINTR:\n\t\t\tthread->current_events |= DM_EVENT_TIMEOUT;\n\t\t\tret = DM_WAIT_INTR;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tlog_sys_error(\"dm_task_run\", \"waitevent\");\n\t\t}\n\t}\n\n\tif (pthread_sigmask(SIG_SETMASK, &old, NULL) != 0)\n\t\tlog_sys_error(\"pthread_sigmask\", \"block alarm\");\n\n#ifdef DEBUG_SIGNALS\n\t_print_sigset(\"dmeventd blocking \", &old);\n#endif\n\tDEBUGLOG(\"Completed waitevent task for %s.\", thread->device.name);\n\n\treturn ret;\n}\n\n/* Register a device with the DSO. */\nstatic int _do_register_device(struct thread_status *thread)\n{\n\treturn thread->dso_data->register_device(thread->device.name,\n\t\t\t\t\t\t thread->device.uuid,\n\t\t\t\t\t\t thread->device.major,\n\t\t\t\t\t\t thread->device.minor,\n\t\t\t\t\t\t &(thread->dso_private));\n}\n\n/* Unregister a device with the DSO. */\nstatic int _do_unregister_device(struct thread_status *thread)\n{\n\treturn thread->dso_data->unregister_device(thread->device.name,\n\t\t\t\t\t\t   thread->device.uuid,\n\t\t\t\t\t\t   thread->device.major,\n\t\t\t\t\t\t   thread->device.minor,\n\t\t\t\t\t\t   &(thread->dso_private));\n}\n\n/* Process an event in the DSO. */\nstatic void _do_process_event(struct thread_status *thread)\n{\n\tstruct dm_task *task;\n\n\t/* NOTE: timeout event gets status */\n\ttask = (thread->current_events & DM_EVENT_TIMEOUT)\n\t\t? _get_device_status(thread) : thread->wait_task;\n\n\tif (!task)\n\t\tlog_error(\"Lost event in Thr %x.\", (int)thread->thread);\n\telse {\n\t\tthread->dso_data->process_event(task, thread->current_events, &(thread->dso_private));\n\t\tif (task != thread->wait_task)\n\t\t\tdm_task_destroy(task);\n\t}\n}\n\nstatic void _thread_unused(struct thread_status *thread)\n{\n\tUNLINK_THREAD(thread);\n\tLINK(thread, &_thread_registry_unused);\n}\n\n/* Thread cleanup handler to unregister device. */\nstatic void _monitor_unregister(void *arg)\n{\n\tstruct thread_status *thread = arg, *thread_iter;\n\n\tdm_list_iterate_items(thread_iter, &_thread_registry)\n\t\tif (thread_iter == thread) {\n\t\t\t/* Relink to _unused */\n\t\t\t_thread_unused(thread);\n\t\t\tbreak;\n\t\t}\n\n\tthread->events = 0;\t/* Filter is now empty */\n\tthread->pending = 0;\t/* Event pending resolved */\n\tthread->processing = 1;\t/* Process unregistering */\n\n\t_unlock_mutex();\n\n\tDEBUGLOG(\"Unregistering monitor for %s.\", thread->device.name);\n\t_unregister_for_timeout(thread);\n\n\tif ((thread->status != DM_THREAD_REGISTERING) &&\n\t    !_do_unregister_device(thread))\n\t\tlog_error(\"%s: %s unregister failed.\", __func__,\n\t\t\t  thread->device.name);\n\n\tDEBUGLOG(\"Marking Thr %x as DONE and unused.\", (int)thread->thread);\n\n\t_lock_mutex();\n\tthread->status = DM_THREAD_DONE; /* Last access to thread memory! */\n\t_unlock_mutex();\n}\n\n/* Device monitoring thread. */\nstatic void *_monitor_thread(void *arg)\n{\n\tstruct thread_status *thread = arg;\n\tint ret;\n\tsigset_t pendmask;\n\n\tpthread_setcanceltype(PTHREAD_CANCEL_DEFERRED, NULL);\n\tpthread_cleanup_push(_monitor_unregister, thread);\n\n\tif (!_fill_device_data(thread)) {\n\t\tlog_error(\"Failed to fill device data for %s.\", thread->device.uuid);\n\t\t_lock_mutex();\n\t\tgoto out;\n\t}\n\n\tif (!_do_register_device(thread)) {\n\t\tlog_error(\"Failed to register device %s.\", thread->device.name);\n\t\t_lock_mutex();\n\t\tgoto out;\n\t}\n\n\t_lock_mutex();\n\tthread->status = DM_THREAD_RUNNING;\n\tthread->processing = 0;\n\n\t/* Loop awaiting/analyzing device events. */\n\twhile (thread->events) {\n\n\t\tthread->pending = 0; /* Event is no longer pending...  */\n\n\t\t/*\n\t\t * Check against bitmask filter.\n\t\t *\n\t\t * If there's current events delivered from _event_wait() AND\n\t\t * the device got registered for those events AND\n\t\t * those events haven't been processed yet, call\n\t\t * the DSO's process_event() handler.\n\t\t */\n\t\tif (thread->events & thread->current_events) {\n\t\t\tthread->processing = 1;  /* Cannot be removed/signaled */\n\t\t\t_unlock_mutex();\n\n\t\t\t_do_process_event(thread);\n\t\t\tthread->current_events = 0; /* Current events processed */\n\n\t\t\t_lock_mutex();\n\t\t\tthread->processing = 0;\n\n\t\t\t/*\n\t\t\t * Thread can terminate itself from plugin via SIGALRM\n\t\t\t * Timer thread will not send signal while processing\n\t\t\t * TODO: maybe worth API change and return value for\n\t\t\t *       _do_process_event() instead of this signal solution\n\t\t\t */\n\t\t\tif (sigpending(&pendmask) < 0)\n\t\t\t\tlog_sys_error(\"sigpending\", \"\");\n\t\t\telse if (sigismember(&pendmask, SIGALRM))\n\t\t\t\tbreak;\n\t\t} else {\n\t\t\t_unlock_mutex();\n\n\t\t\tif ((ret = _event_wait(thread)) == DM_WAIT_RETRY)\n\t\t\t\tusleep(100); /* Avoid busy loop, wait without mutex */\n\n\t\t\t_lock_mutex();\n\n\t\t\tif (ret == DM_WAIT_FATAL)\n\t\t\t\tbreak;\n\t\t}\n\t}\nout:\n\t/* ';' fixes gcc compilation problem with older pthread macros\n\t * \"label at end of compound statement\" */\n\t;\n\n\tpthread_cleanup_pop(1);\n\n\treturn NULL;\n}\n\n/* Create a device monitoring thread. */\nstatic int _create_thread(struct thread_status *thread)\n{\n\treturn _pthread_create_smallstack(&thread->thread, _monitor_thread, thread);\n}\n\n/* Update events - needs to be locked */\nstatic int _update_events(struct thread_status *thread, int events)\n{\n\tint ret = 0;\n\n\tif (thread->events == events)\n\t\treturn 0; /* Nothing has changed */\n\n\tthread->events = events;\n\tthread->pending = DM_EVENT_REGISTRATION_PENDING;\n\n\t/* Only non-processing threads can be notified */\n\tif (!thread->processing) {\n\t\tDEBUGLOG(\"Sending SIGALRM to wakeup Thr %x.\", (int)thread->thread);\n\n\t\t/* Notify thread waiting in ioctl (to speed-up) */\n\t\tif ((ret = pthread_kill(thread->thread, SIGALRM))) {\n\t\t\tif (ret == ESRCH)\n\t\t\t\tthread->events = 0;  /* thread is gone */\n\t\t\telse\n\t\t\t\tlog_error(\"Unable to wakeup thread: %s\",\n\t\t\t\t\t  strerror(ret));\n\t\t}\n\t}\n\n\t/* Threads with no events has to be moved to unused */\n\tif (!thread->events)\n\t\t_thread_unused(thread);\n\n\treturn -ret;\n}\n\n/* Return success on daemon active check. */\nstatic int _active(struct message_data *message_data)\n{\n\treturn 0;\n}\n\n/*\n * Unregister for an event.\n *\n * Only one caller at a time here as with register_for_event().\n */\nstatic int _unregister_for_event(struct message_data *message_data)\n{\n\tstruct thread_status *thread;\n\tint ret;\n\n\t/*\n\t * Clear event in bitfield and deactivate\n\t * monitoring thread in case bitfield is 0.\n\t */\n\t_lock_mutex();\n\n\tif (!(thread = _lookup_thread_status(message_data))) {\n\t\t_unlock_mutex();\n\t\treturn -ENODEV;\n\t}\n\n\t/* AND mask event ~# from events bitfield. */\n\tret = _update_events(thread, (thread->events & ~message_data->events_field));\n\n\t_unlock_mutex();\n\n\t/* If there are no events, thread is later garbage\n\t * collected by _cleanup_unused_threads */\n\tif (message_data->events_field & DM_EVENT_TIMEOUT)\n\t\t_unregister_for_timeout(thread);\n\n\tDEBUGLOG(\"Unregistered event for %s.\", thread->device.name);\n\n\treturn ret;\n}\n\n/*\n * Register for an event.\n *\n * Only one caller at a time here, because we use\n * a FIFO and lock it against multiple accesses.\n */\nstatic int _register_for_event(struct message_data *message_data)\n{\n\tint ret = 0;\n\tstruct thread_status *thread;\n\tstruct dso_data *dso_data;\n\n\tif (!(dso_data = _lookup_dso(message_data)) &&\n\t    !(dso_data = _load_dso(message_data))) {\n\t\tstack;\n#ifdef ELIBACC\n\t\tret = ELIBACC;\n#else\n\t\tret = ENODEV;\n#endif\n\t\treturn ret;\n\t}\n\n\t_lock_mutex();\n\n\tif ((thread = _lookup_thread_status(message_data))) {\n\t\t/* OR event # into events bitfield. */\n\t\tret = _update_events(thread, (thread->events | message_data->events_field));\n\t} else {\n\t\t_unlock_mutex();\n\n\t\t/* Only creating thread during event processing\n\t\t * Remaining initialization happens within monitoring thread */\n\t\tif (!(thread = _alloc_thread_status(message_data, dso_data))) {\n\t\t\tstack;\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\tif ((ret = _create_thread(thread))) {\n\t\t\tstack;\n\t\t\t_free_thread_status(thread);\n\t\t\treturn -ret;\n\t\t}\n\n\t\t_lock_mutex();\n\t\t/* Note: same uuid can't be added in parallel */\n\t\tLINK_THREAD(thread);\n\t}\n\n\t_unlock_mutex();\n\n\t/* If creation of timeout thread fails (as it may), we fail\n\t   here completely. The client is responsible for either\n\t   retrying later or trying to register without timeout\n\t   events. However, if timeout thread cannot be started, it\n\t   usually means we are so starved on resources that we are\n\t   almost as good as dead already... */\n\tif ((message_data->events_field & DM_EVENT_TIMEOUT) &&\n\t    (ret = _register_for_timeout(thread))) {\n\t\tstack;\n\t\t_unregister_for_event(message_data);\n\t}\n\n\treturn -ret;\n}\n\n/*\n * Get registered device.\n *\n * Only one caller at a time here as with register_for_event().\n */\nstatic int _registered_device(struct message_data *message_data,\n\t\t\t     struct thread_status *thread)\n{\n\tint r;\n\tstruct dm_event_daemon_message *msg = message_data->msg;\n\n\tfree(msg->data);\n\n\tif ((r = dm_asprintf(&(msg->data), \"%s %s %s %u\",\n\t\t\t     message_data->id,\n\t\t\t     thread->dso_data->dso_name,\n\t\t\t     thread->device.uuid,\n\t\t\t     thread->events | thread->pending)) < 0)\n\t\treturn -ENOMEM;\n\n\tmsg->size = (uint32_t) r;\n\tDEBUGLOG(\"Registered %s.\", msg->data);\n\n\treturn 0;\n}\n\nstatic int _want_registered_device(char *dso_name, char *device_uuid,\n\t\t\t\t   struct thread_status *thread)\n{\n\t/* If DSO names and device paths are equal. */\n\tif (dso_name && device_uuid)\n\t\treturn !strcmp(dso_name, thread->dso_data->dso_name) &&\n\t\t    !strcmp(device_uuid, thread->device.uuid);\n\n\t/* If DSO names are equal. */\n\tif (dso_name)\n\t\treturn !strcmp(dso_name, thread->dso_data->dso_name);\n\n\t/* If device paths are equal. */\n\tif (device_uuid)\n\t\treturn !strcmp(device_uuid, thread->device.uuid);\n\n\treturn 1;\n}\n\nstatic int _get_registered_dev(struct message_data *message_data, int next)\n{\n\tstruct thread_status *thread, *hit = NULL;\n\tint ret = -ENOENT;\n\n\tDEBUGLOG(\"Get%s dso:%s  uuid:%s.\", next ? \"\" : \"Next\",\n\t\t message_data->dso_name,\n\t\t message_data->device_uuid);\n\t_lock_mutex();\n\n\t/* Iterate list of threads checking if we want a particular one. */\n\tdm_list_iterate_items(thread, &_thread_registry)\n\t\tif (_want_registered_device(message_data->dso_name,\n\t\t\t\t\t    message_data->device_uuid,\n\t\t\t\t\t    thread)) {\n\t\t\thit = thread;\n\t\t\tbreak;\n\t\t}\n\n\t/*\n\t * If we got a registered device and want the next one ->\n\t * fetch next conforming element off the list.\n\t */\n\tif (hit && !next)\n\t\tgoto reg;\n\n\t/*\n\t * If we didn't get a match, try the threads waiting to be deleted.\n\t * FIXME Do something similar if 'next' is set.\n\t */\n\tif (!hit && !next)\n\t\tdm_list_iterate_items(thread, &_thread_registry_unused)\n\t\t\tif (_want_registered_device(message_data->dso_name,\n\t\t\t\t\t\t    message_data->device_uuid, thread)) {\n\t\t\t\thit = thread;\n\t\t\t\tgoto reg;\n\t\t\t}\n\n\tif (!hit) {\n\t\tDEBUGLOG(\"Get%s not registered\", next ? \"\" : \"Next\");\n\t\tgoto out;\n\t}\n\n\twhile (1) {\n\t\tif (dm_list_end(&_thread_registry, &thread->list))\n\t\t\tgoto out;\n\n\t\tthread = dm_list_item(thread->list.n, struct thread_status);\n\t\tif (_want_registered_device(message_data->dso_name, NULL, thread)) {\n\t\t\thit = thread;\n\t\t\tbreak;\n\t\t}\n\t}\n\n      reg:\n\tret = _registered_device(message_data, hit);\n\n      out:\n\t_unlock_mutex();\n\n\treturn ret;\n}\n\nstatic int _get_registered_device(struct message_data *message_data)\n{\n\treturn _get_registered_dev(message_data, 0);\n}\n\nstatic int _get_next_registered_device(struct message_data *message_data)\n{\n\treturn _get_registered_dev(message_data, 1);\n}\n\nstatic int _set_timeout(struct message_data *message_data)\n{\n\tstruct thread_status *thread;\n\n\t_lock_mutex();\n\tthread = _lookup_thread_status(message_data);\n\t_unlock_mutex();\n\n\tif (!thread)\n\t\treturn -ENODEV;\n\n\t/* Lets reprogram timer */\n\tpthread_mutex_lock(&_timeout_mutex);\n\tthread->timeout = message_data->timeout_secs;\n\tthread->next_time = 0;\n\tpthread_cond_signal(&_timeout_cond);\n\tpthread_mutex_unlock(&_timeout_mutex);\n\n\treturn 0;\n}\n\nstatic int _get_timeout(struct message_data *message_data)\n{\n\tstruct thread_status *thread;\n\tstruct dm_event_daemon_message *msg = message_data->msg;\n\n\t_lock_mutex();\n\tthread = _lookup_thread_status(message_data);\n\t_unlock_mutex();\n\n\tif (!thread)\n\t\treturn -ENODEV;\n\n\tfree(msg->data);\n\tmsg->size = dm_asprintf(&(msg->data), \"%s %\" PRIu32,\n\t\t\t\tmessage_data->id, thread->timeout);\n\n\treturn (msg->data && msg->size) ? 0 : -ENOMEM;\n}\n\nstatic int _open_fifo(const char *path)\n{\n\tstruct stat st;\n\tint fd = -1;\n \n \t/*\n\t * FIXME Explicitly verify the code's requirement that path is secure:\n\t * - All parent directories owned by root without group/other write access unless sticky.\n\t */\n\n\t/* If path exists, only use it if it is root-owned fifo mode 0600 */\n\tif ((lstat(path, &st) < 0)) {\n\t\tif (errno != ENOENT) {\n\t\t\tlog_sys_error(\"stat\", path);\n\t\t\treturn -1;\n\t\t}\n\t} else if (!S_ISFIFO(st.st_mode) || st.st_uid ||\n\t\t   (st.st_mode & (S_IEXEC | S_IRWXG | S_IRWXO))) {\n\t\tlog_warn(\"WARNING: %s has wrong attributes: Replacing.\", path);\n\t\tif (unlink(path)) {\n\t\t\tlog_sys_error(\"unlink\", path);\n\t\t\treturn -1;\n\t\t}\n\t}\n\n\t/* Create fifo. */\n\t(void) dm_prepare_selinux_context(path, S_IFIFO);\n\tif ((mkfifo(path, 0600) == -1) && errno != EEXIST) {\n\t\tlog_sys_error(\"mkfifo\", path);\n\t\t(void) dm_prepare_selinux_context(NULL, 0);\n\t\tgoto fail;\n\t}\n\n\t(void) dm_prepare_selinux_context(NULL, 0);\n\n\t/* Need to open read+write or we will block or fail */\n\tif ((fd = open(path, O_RDWR)) < 0) {\n\t\tlog_sys_error(\"open\", path);\n\t\tgoto fail;\n\t}\n\n\t/* Warn about wrong permissions if applicable */\n\tif (fstat(fd, &st)) {\n\t\tlog_sys_error(\"fstat\", path);\n\t\tgoto fail;\n\t}\n\n\tif (!S_ISFIFO(st.st_mode) || st.st_uid ||\n\t    (st.st_mode & (S_IEXEC | S_IRWXG | S_IRWXO))) {\n\t\tlog_error(\"%s: fifo has incorrect attributes\", path);\n\t\tgoto fail;\n\t}\n\n\tif (fcntl(fd, F_SETFD, FD_CLOEXEC)) {\n\t\tlog_sys_error(\"fcntl(FD_CLOEXEC)\", path);\n\t\tgoto fail;\n\t}\n\n\treturn fd;\n\nfail:\n\tif ((fd >= 0) && close(fd))\n\t\tlog_sys_error(\"close\", path);\n\n\treturn -1;\n}\n\n/* Open fifos used for client communication. */\nstatic int _open_fifos(struct dm_event_fifos *fifos)\n{\n\t/* Create client fifo. */\n\tif ((fifos->client = _open_fifo(fifos->client_path)) < 0)\n\t\tgoto fail;\n\n\t/* Create server fifo. */\n\tif ((fifos->server = _open_fifo(fifos->server_path)) < 0)\n\t\tgoto fail;\n\n\treturn 1;\n\nfail:\n\tif (fifos->client >= 0 && close(fifos->client))\n\t\tlog_sys_error(\"close\", fifos->client_path);\n\n\treturn 0;\n}\n\n/*\n * Read message from client making sure that data is available\n * and a complete message is read.  Must not block indefinitely.\n */\nstatic int _client_read(struct dm_event_fifos *fifos,\n\t\t\tstruct dm_event_daemon_message *msg)\n{\n\tstruct timeval t;\n\tunsigned bytes = 0;\n\tint ret = 0;\n\tfd_set fds;\n\tsize_t size = 2 * sizeof(uint32_t);\t/* status + size */\n\tuint32_t *header = alloca(size);\n\tchar *buf = (char *)header;\n\n\tmsg->data = NULL;\n\n\terrno = 0;\n\twhile (bytes < size && errno != EOF) {\n\t\t/* Watch client read FIFO for input. */\n\t\tFD_ZERO(&fds);\n\t\tFD_SET(fifos->client, &fds);\n\t\tt.tv_sec = 1;\n\t\tt.tv_usec = 0;\n\t\tret = select(fifos->client + 1, &fds, NULL, NULL, &t);\n\n\t\tif (!ret && !bytes)\t/* nothing to read */\n\t\t\treturn 0;\n\n\t\tif (!ret)\t/* trying to finish read */\n\t\t\tcontinue;\n\n\t\tif (ret < 0)\t/* error */\n\t\t\treturn 0;\n\n\t\tret = read(fifos->client, buf + bytes, size - bytes);\n\t\tbytes += ret > 0 ? ret : 0;\n\t\tif (header && (bytes == 2 * sizeof(uint32_t))) {\n\t\t\tmsg->cmd = ntohl(header[0]);\n\t\t\tsize = msg->size = ntohl(header[1]);\n\t\t\tbytes = 0;\n\t\t\tif (!size)\n\t\t\t\tbreak; /* No data -> error */\n\t\t\tbuf = msg->data = malloc(msg->size);\n\t\t\tif (!buf)\n\t\t\t\tbreak; /* No mem -> error */\n\t\t\theader = 0;\n\t\t}\n\t}\n\n\tif (bytes != size) {\n\t\tfree(msg->data);\n\t\tmsg->data = NULL;\n\t\treturn 0;\n\t}\n\n\treturn 1;\n}\n\n/*\n * Write a message to the client making sure that it is ready to write.\n */\nstatic int _client_write(struct dm_event_fifos *fifos,\n\t\t\tstruct dm_event_daemon_message *msg)\n{\n\tuint32_t temp[2];\n\tunsigned bytes = 0;\n\tint ret = 0;\n\tfd_set fds;\n\n\tsize_t size = 2 * sizeof(uint32_t) + ((msg->data) ? msg->size : 0);\n\tuint32_t *header = malloc(size);\n\tchar *buf = (char *)header;\n\n\tif (!header) {\n\t\t/* Reply with ENOMEM message */\n\t\theader = temp;\n\t\tsize = sizeof(temp);\n\t\theader[0] = htonl(-ENOMEM);\n\t\theader[1] = 0;\n\t} else {\n\t\theader[0] = htonl(msg->cmd);\n\t\theader[1] = htonl((msg->data) ? msg->size : 0);\n\t\tif (msg->data)\n\t\t\tmemcpy(buf + 2 * sizeof(uint32_t), msg->data, msg->size);\n\t}\n\n\twhile (bytes < size) {\n\t\tdo {\n\t\t\t/* Watch client write FIFO to be ready for output. */\n\t\t\tFD_ZERO(&fds);\n\t\t\tFD_SET(fifos->server, &fds);\n\t\t} while (select(fifos->server + 1, NULL, &fds, NULL, NULL) != 1);\n\n\t\tif ((ret = write(fifos->server, buf + bytes, size - bytes)) > 0)\n\t\t\tbytes += ret;\n\t\telse if (errno == EIO)\n\t\t\tbreak;\n\t}\n\n\tif (header != temp)\n\t\tfree(header);\n\n\treturn (bytes == size);\n}\n\n/*\n * Handle a client request.\n *\n * We put the request handling functions into\n * a list because of the growing number.\n */\nstatic int _handle_request(struct dm_event_daemon_message *msg,\n\t\t\t  struct message_data *message_data)\n{\n\tswitch (msg->cmd) {\n\tcase DM_EVENT_CMD_REGISTER_FOR_EVENT:\n\t\tif (!message_data->events_field)\n\t\t\treturn -EINVAL;\n\t\treturn _register_for_event(message_data);\n\tcase DM_EVENT_CMD_UNREGISTER_FOR_EVENT:\n\t\treturn _unregister_for_event(message_data);\n\tcase DM_EVENT_CMD_GET_REGISTERED_DEVICE:\n\t\treturn _get_registered_device(message_data);\n\tcase DM_EVENT_CMD_GET_NEXT_REGISTERED_DEVICE:\n\t\treturn _get_next_registered_device(message_data);\n\tcase DM_EVENT_CMD_SET_TIMEOUT:\n\t\treturn _set_timeout(message_data);\n\tcase DM_EVENT_CMD_GET_TIMEOUT:\n\t\treturn _get_timeout(message_data);\n\tcase DM_EVENT_CMD_ACTIVE:\n\t\treturn _active(message_data);\n\tcase DM_EVENT_CMD_GET_STATUS:\n\t\treturn _get_status(message_data);\n\t/* dmeventd parameters of running dmeventd,\n\t * returns 'pid=<pid> daemon=<no/yes> exec_method=<direct/systemd>'\n\t * \tpid - pidfile of running dmeventd\n\t * \tdaemon - running as a daemon or not (foreground)?\n\t * \texec_method - \"direct\" if executed directly or\n\t * \t\t      \"systemd\" if executed via systemd\n\t */\n\tcase DM_EVENT_CMD_GET_PARAMETERS:\n\t\treturn _get_parameters(message_data);\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}\n\n/* Process a request passed from the communication thread. */\nstatic int _do_process_request(struct dm_event_daemon_message *msg)\n{\n\tint ret;\n\tchar *answer;\n\tstruct message_data message_data = { .msg =  msg };\n\n\t/* Parse the message. */\n\tif (msg->cmd == DM_EVENT_CMD_HELLO || msg->cmd == DM_EVENT_CMD_DIE)  {\n\t\tret = 0;\n\t\tanswer = msg->data;\n\t\tif (answer) {\n\t\t\tmsg->size = dm_asprintf(&(msg->data), \"%s %s %d\", answer,\n\t\t\t\t\t\t(msg->cmd == DM_EVENT_CMD_DIE) ? \"DYING\" : \"HELLO\",\n\t\t\t\t\t\tDM_EVENT_PROTOCOL_VERSION);\n\t\t\tfree(answer);\n\t\t}\n\t} else if (msg->cmd != DM_EVENT_CMD_ACTIVE && !_parse_message(&message_data)) {\n\t\tstack;\n\t\tret = -EINVAL;\n\t} else\n\t\tret = _handle_request(msg, &message_data);\n\n\tmsg->cmd = ret;\n\tif (!msg->data)\n\t\tmsg->size = dm_asprintf(&(msg->data), \"%s %s\", message_data.id, strerror(-ret));\n\n\t_free_message(&message_data);\n\n\treturn ret;\n}\n\n/* Only one caller at a time. */\nstatic void _process_request(struct dm_event_fifos *fifos)\n{\n\tstruct dm_event_daemon_message msg = { 0 };\n\tint cmd;\n\t/*\n\t * Read the request from the client (client_read, client_write\n\t * give true on success and false on failure).\n\t */\n\tif (!_client_read(fifos, &msg))\n\t\treturn;\n\n\tcmd = msg.cmd;\n\n\tDEBUGLOG(\">>> CMD:%s (0x%x) processing...\", decode_cmd(cmd), cmd);\n\n\t/* _do_process_request fills in msg (if memory allows for\n\t   data, otherwise just cmd and size = 0) */\n\t_do_process_request(&msg);\n\n\tif (!_client_write(fifos, &msg))\n\t\tstack;\n\n\tDEBUGLOG(\"<<< CMD:%s (0x%x) completed (result %d).\", decode_cmd(cmd), cmd, msg.cmd);\n\n\tfree(msg.data);\n\n\tif (cmd == DM_EVENT_CMD_DIE) {\n\t\tif (unlink(DMEVENTD_PIDFILE))\n\t\t\tlog_sys_error(\"unlink\", DMEVENTD_PIDFILE);\n\t\t_exit(0);\n\t}\n}\n\nstatic void _process_initial_registrations(void)\n{\n\tint i;\n\tchar *reg;\n\tstruct dm_event_daemon_message msg = { 0 };\n\n\tfor (i = 0; (reg = _initial_registrations[i]); ++i) {\n\t\tmsg.cmd = DM_EVENT_CMD_REGISTER_FOR_EVENT;\n\t\tif ((msg.size = strlen(reg))) {\n\t\t\tmsg.data = reg;\n\t\t\t_do_process_request(&msg);\n\t\t}\n\t}\n}\n\nstatic void _cleanup_unused_threads(void)\n{\n\tstruct dm_list *l;\n\tstruct thread_status *thread;\n\tint ret;\n\n\t_lock_mutex();\n\n\twhile ((l = dm_list_first(&_thread_registry_unused))) {\n\t\tthread = dm_list_item(l, struct thread_status);\n\t\tif (thread->status != DM_THREAD_DONE) {\n\t\t\tif (thread->processing)\n\t\t\t\tbreak; /* cleanup on the next round */\n\n\t\t\t/* Signal possibly sleeping thread */\n\t\t\tret = pthread_kill(thread->thread, SIGALRM);\n\t\t\tif (!ret || (ret != ESRCH))\n\t\t\t\tbreak; /* check again on the next round */\n\n\t\t\t/* thread is likely gone */\n\t\t}\n\n\t\tdm_list_del(l);\n\t\t_unlock_mutex();\n\n\t\tDEBUGLOG(\"Destroying Thr %x.\", (int)thread->thread);\n\n\t\tif (pthread_join(thread->thread, NULL))\n\t\t\tlog_sys_error(\"pthread_join\", \"\");\n\n\t\t_free_thread_status(thread);\n\t\t_lock_mutex();\n\t}\n\n\t_unlock_mutex();\n}\n\nstatic void _sig_alarm(int signum __attribute__((unused)))\n{\n\t/* empty SIG_IGN */;\n}\n\n/* Init thread signal handling. */\nstatic void _init_thread_signals(void)\n{\n\tsigset_t my_sigset;\n\tstruct sigaction act = { .sa_handler = _sig_alarm };\n\n\tsigaction(SIGALRM, &act, NULL);\n\tsigfillset(&my_sigset);\n\n\t/* These are used for exiting */\n\tsigdelset(&my_sigset, SIGTERM);\n\tsigdelset(&my_sigset, SIGINT);\n\tsigdelset(&my_sigset, SIGHUP);\n\tsigdelset(&my_sigset, SIGQUIT);\n\n\tpthread_sigmask(SIG_BLOCK, &my_sigset, NULL);\n}\n\n/*\n * exit_handler\n * @sig\n *\n * Set the global variable which the process should\n * be watching to determine when to exit.\n */\nstatic void _exit_handler(int sig __attribute__((unused)))\n{\n\t_exit_now = DM_SIGNALED_EXIT;\n}\n\n#ifdef __linux__\nstatic int _set_oom_adj(const char *oom_adj_path, int val)\n{\n\tFILE *fp;\n\n\tif (!(fp = fopen(oom_adj_path, \"w\"))) {\n\t\tlog_sys_error(\"open\", oom_adj_path);\n\t\treturn 0;\n\t}\n\n\tfprintf(fp, \"%i\", val);\n\n\tif (dm_fclose(fp))\n\t\tlog_sys_error(\"fclose\", oom_adj_path);\n\n\treturn 1;\n}\n\n/*\n * Protection against OOM killer if kernel supports it\n */\nstatic int _protect_against_oom_killer(void)\n{\n\tstruct stat st;\n\n\tif (stat(OOM_ADJ_FILE, &st) == -1) {\n\t\tif (errno != ENOENT)\n\t\t\tlog_sys_error(\"stat\", OOM_ADJ_FILE);\n\n\t\t/* Try old oom_adj interface as a fallback */\n\t\tif (stat(OOM_ADJ_FILE_OLD, &st) == -1) {\n\t\t\tlog_sys_error(\"stat\", OOM_ADJ_FILE_OLD);\n\t\t\treturn 1;\n\t\t}\n\n\t\treturn _set_oom_adj(OOM_ADJ_FILE_OLD, OOM_DISABLE) ||\n\t\t       _set_oom_adj(OOM_ADJ_FILE_OLD, OOM_ADJUST_MIN);\n\t}\n\n\treturn _set_oom_adj(OOM_ADJ_FILE, OOM_SCORE_ADJ_MIN);\n}\n\nstatic int _handle_preloaded_fifo(int fd, const char *path)\n{\n\tstruct stat st_fd, st_path;\n\tint flags;\n\n\tif ((flags = fcntl(fd, F_GETFD)) < 0)\n\t\treturn 0;\n\n\tif (flags & FD_CLOEXEC)\n\t\treturn 0;\n\n\tif (fstat(fd, &st_fd) < 0 || !S_ISFIFO(st_fd.st_mode))\n\t\treturn 0;\n\n\tif (stat(path, &st_path) < 0 ||\n\t    st_path.st_dev != st_fd.st_dev ||\n\t    st_path.st_ino != st_fd.st_ino)\n\t\treturn 0;\n\n\tif (fcntl(fd, F_SETFD, flags | FD_CLOEXEC) < 0)\n\t\treturn 0;\n\n\treturn 1;\n}\n\nstatic int _systemd_handover(struct dm_event_fifos *fifos)\n{\n\tconst char *e;\n\tchar *p;\n\tunsigned long env_pid, env_listen_fds;\n\tint r = 0;\n\n\t/* SD_ACTIVATION must be set! */\n\tif (!(e = getenv(SD_ACTIVATION_ENV_VAR_NAME)) || strcmp(e, \"1\"))\n\t\tgoto out;\n\n\t/* LISTEN_PID must be equal to our PID! */\n\tif (!(e = getenv(SD_LISTEN_PID_ENV_VAR_NAME)))\n\t\tgoto out;\n\n\terrno = 0;\n\tenv_pid = strtoul(e, &p, 10);\n\tif (errno || !p || *p || env_pid <= 0 ||\n\t    getpid() != (pid_t) env_pid)\n\t\tgoto out;\n\n\t/* LISTEN_FDS must be 2 and the fds must be FIFOSs! */\n\tif (!(e = getenv(SD_LISTEN_FDS_ENV_VAR_NAME)))\n\t\tgoto out;\n\n\terrno = 0;\n\tenv_listen_fds = strtoul(e, &p, 10);\n\tif (errno || !p || *p || env_listen_fds != 2)\n\t\tgoto out;\n\n\t/* Check and handle the FIFOs passed in */\n\tr = (_handle_preloaded_fifo(SD_FD_FIFO_SERVER, DM_EVENT_FIFO_SERVER) &&\n\t     _handle_preloaded_fifo(SD_FD_FIFO_CLIENT, DM_EVENT_FIFO_CLIENT));\n\n\tif (r) {\n\t\tfifos->server = SD_FD_FIFO_SERVER;\n\t\tfifos->server_path = DM_EVENT_FIFO_SERVER;\n\t\tfifos->client = SD_FD_FIFO_CLIENT;\n\t\tfifos->client_path = DM_EVENT_FIFO_CLIENT;\n\t}\n\nout:\n\tunsetenv(SD_ACTIVATION_ENV_VAR_NAME);\n\tunsetenv(SD_LISTEN_PID_ENV_VAR_NAME);\n\tunsetenv(SD_LISTEN_FDS_ENV_VAR_NAME);\n\treturn r;\n}\n\n#endif\n\nstatic void _remove_files_on_exit(void)\n{\n\tif (unlink(DMEVENTD_PIDFILE))\n\t\tlog_sys_error(\"unlink\", DMEVENTD_PIDFILE);\n\n\tif (!_systemd_activation) {\n\t\tif (unlink(DM_EVENT_FIFO_CLIENT))\n\t\t\tlog_sys_error(\"unlink\", DM_EVENT_FIFO_CLIENT);\n\n\t\tif (unlink(DM_EVENT_FIFO_SERVER))\n\t\t\tlog_sys_error(\"unlink\", DM_EVENT_FIFO_SERVER);\n\t}\n}\n\nstatic void _daemonize(void)\n{\n\tint child_status;\n\tint fd;\n\tpid_t pid;\n\tstruct rlimit rlim;\n\tstruct timeval tval;\n\tsigset_t my_sigset;\n\n\tsigemptyset(&my_sigset);\n\tif (sigprocmask(SIG_SETMASK, &my_sigset, NULL) < 0) {\n\t\tfprintf(stderr, \"Unable to restore signals.\\n\");\n\t\texit(EXIT_FAILURE);\n\t}\n\tsignal(SIGTERM, &_exit_handler);\n\n\tswitch (pid = fork()) {\n\tcase -1:\n\t\tlog_sys_error(\"fork\", \"\");\n\t\texit(EXIT_FAILURE);\n\tcase 0:\t\t/* Child */\n\t\tbreak;\n\n\tdefault:\n\t\t/* Wait for response from child */\n\t\twhile (!waitpid(pid, &child_status, WNOHANG) && !_exit_now) {\n\t\t\ttval.tv_sec = 0;\n\t\t\ttval.tv_usec = 250000;\t/* .25 sec */\n\t\t\tselect(0, NULL, NULL, NULL, &tval);\n\t\t}\n\n\t\tif (_exit_now)\t/* Child has signaled it is ok - we can exit now */\n\t\t\texit(EXIT_SUCCESS);\n\n\t\t/* Problem with child.  Determine what it is by exit code */\n\t\tswitch (WEXITSTATUS(child_status)) {\n\t\tcase EXIT_DESC_CLOSE_FAILURE:\n\t\tcase EXIT_DESC_OPEN_FAILURE:\n\t\tcase EXIT_FIFO_FAILURE:\n\t\tcase EXIT_CHDIR_FAILURE:\n\t\tdefault:\n\t\t\tfprintf(stderr, \"Child exited with code %d\\n\", WEXITSTATUS(child_status));\n\t\t\tbreak;\n\t\t}\n\n\t\texit(WEXITSTATUS(child_status));\n\t}\n\n\tif (chdir(\"/\"))\n\t\texit(EXIT_CHDIR_FAILURE);\n\n\tif (getrlimit(RLIMIT_NOFILE, &rlim) < 0)\n\t\tfd = 256;\t/* just have to guess */\n\telse\n\t\tfd = rlim.rlim_cur;\n\n\tfor (--fd; fd >= 0; fd--) {\n#ifdef __linux__\n\t\t/* Do not close fds preloaded by systemd! */\n\t\tif (_systemd_activation &&\n\t\t    (fd == SD_FD_FIFO_SERVER || fd == SD_FD_FIFO_CLIENT))\n\t\t\tcontinue;\n#endif\n\t\t(void) close(fd);\n\t}\n\n\tif ((open(\"/dev/null\", O_RDONLY) < 0) ||\n\t    (open(\"/dev/null\", O_WRONLY) < 0) ||\n\t    (open(\"/dev/null\", O_WRONLY) < 0))\n\t\texit(EXIT_DESC_OPEN_FAILURE);\n\n\tsetsid();\n}\n\nstatic int _reinstate_registrations(struct dm_event_fifos *fifos)\n{\n\tstatic const char _failed_parsing_msg[] = \"Failed to parse existing event registration.\\n\";\n\tstatic const char *_delim = \" \";\n\tstruct dm_event_daemon_message msg = { 0 };\n\tchar *endp, *dso_name, *dev_name, *mask, *timeout;\n\tunsigned long mask_value, timeout_value;\n\tint i, ret;\n\n\tret = daemon_talk(fifos, &msg, DM_EVENT_CMD_HELLO, NULL, NULL, 0, 0);\n\tfree(msg.data);\n\tmsg.data = NULL;\n\n\tif (ret) {\n\t\tfprintf(stderr, \"Failed to communicate with new instance of dmeventd.\\n\");\n\t\treturn 0;\n\t}\n\n\tfor (i = 0; _initial_registrations[i]; ++i) {\n\t\tif (!(strtok(_initial_registrations[i], _delim)) ||\n\t\t    !(dso_name = strtok(NULL, _delim)) ||\n\t\t    !(dev_name = strtok(NULL, _delim)) ||\n\t\t    !(mask = strtok(NULL, _delim)) ||\n\t\t    !(timeout = strtok(NULL, _delim))) {\n\t\t\tfputs(_failed_parsing_msg, stderr);\n\t\t\tcontinue;\n\t\t}\n\n\t\terrno = 0;\n\t\tmask_value = strtoul(mask, &endp, 10);\n\t\tif (errno || !endp || *endp) {\n\t\t\tfputs(_failed_parsing_msg, stderr);\n\t\t\tcontinue;\n\t\t}\n\n\t\terrno = 0;\n\t\ttimeout_value = strtoul(timeout, &endp, 10);\n\t\tif (errno || !endp || *endp) {\n\t\t\tfputs(_failed_parsing_msg, stderr);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (daemon_talk(fifos, &msg, DM_EVENT_CMD_REGISTER_FOR_EVENT,\n\t\t\t\tdso_name,\n\t\t\t\tdev_name,\n\t\t\t\t(enum dm_event_mask) mask_value,\n\t\t\t\ttimeout_value))\n\t\t\tfprintf(stderr, \"Failed to reinstate monitoring for device %s.\\n\", dev_name);\n\t}\n\n\treturn 1;\n}\n\nstatic void _restart_dmeventd(void)\n{\n\tstruct dm_event_fifos fifos = {\n\t\t.server = -1,\n\t\t.client = -1,\n\t\t/* FIXME Make these either configurable or depend directly on dmeventd_path */\n\t\t.client_path = DM_EVENT_FIFO_CLIENT,\n\t\t.server_path = DM_EVENT_FIFO_SERVER\n\t};\n\tstruct dm_event_daemon_message msg = { 0 };\n\tint i, count = 0;\n\tchar *message;\n\tint version;\n\tconst char *e;\n\n\t/* Get the list of registrations from the running daemon. */\n\tif (!init_fifos(&fifos)) {\n\t\tfprintf(stderr, \"WARNING: Could not initiate communication with existing dmeventd.\\n\");\n\t\texit(EXIT_FAILURE);\n\t}\n\n\tif (!dm_event_get_version(&fifos, &version)) {\n\t\tfprintf(stderr, \"WARNING: Could not communicate with existing dmeventd.\\n\");\n\t\tgoto bad;\n\t}\n\n\tif (version < 1) {\n\t\tfprintf(stderr, \"WARNING: The running dmeventd instance is too old.\\n\"\n\t\t\t\t\"Protocol version %d (required: 1). Action cancelled.\\n\",\n\t\t\t\tversion);\n\t\tgoto bad;\n\t}\n\n\tif (daemon_talk(&fifos, &msg, DM_EVENT_CMD_GET_STATUS, \"-\", \"-\", 0, 0))\n\t\tgoto bad;\n\n\tmessage = strchr(msg.data, ' ') + 1;\n\tfor (i = 0; msg.data[i]; ++i)\n\t\tif (msg.data[i] == ';') {\n\t\t\tmsg.data[i] = 0;\n\t\t\t++count;\n\t\t}\n\n\tif (!(_initial_registrations = malloc(sizeof(char*) * (count + 1)))) {\n\t\tfprintf(stderr, \"Memory allocation registration failed.\\n\");\n\t\tgoto bad;\n\t}\n\n\tfor (i = 0; i < count; ++i) {\n\t\tif (!(_initial_registrations[i] = strdup(message))) {\n\t\t\tfprintf(stderr, \"Memory allocation for message failed.\\n\");\n\t\t\tgoto bad;\n\t\t}\n\t\tmessage += strlen(message) + 1;\n\t}\n\t_initial_registrations[count] = NULL;\n\n\tif (version >= 2) {\n\t\tif (daemon_talk(&fifos, &msg, DM_EVENT_CMD_GET_PARAMETERS, \"-\", \"-\", 0, 0)) {\n\t\t\tfprintf(stderr, \"Failed to acquire parameters from old dmeventd.\\n\");\n\t\t\tgoto bad;\n\t\t}\n\t\tif (strstr(msg.data, \"exec_method=systemd\"))\n\t\t\t_systemd_activation = 1;\n\t}\n#ifdef __linux__\n\t/*\n\t* If the protocol version is old, just assume that if systemd is running,\n\t* the dmeventd is also run as a systemd service via fifo activation.\n\t*/\n\tif (version < 2) {\n\t\t/* This check is copied from sd-daemon.c. */\n\t\tstruct stat st;\n\t\tif (!lstat(SD_RUNTIME_UNIT_FILE_DIR, &st) && !!S_ISDIR(st.st_mode))\n\t\t\t_systemd_activation = 1;\n\t}\n#endif\n\n\tif (daemon_talk(&fifos, &msg, DM_EVENT_CMD_DIE, \"-\", \"-\", 0, 0)) {\n\t\tfprintf(stderr, \"Old dmeventd refused to die.\\n\");\n\t\tgoto bad;\n\t}\n\n\tif (!_systemd_activation &&\n\t    ((e = getenv(SD_ACTIVATION_ENV_VAR_NAME)) && strcmp(e, \"1\")))\n\t\t_systemd_activation = 1;\n\n\tfor (i = 0; i < 10; ++i) {\n\t\tif ((access(DMEVENTD_PIDFILE, F_OK) == -1) && (errno == ENOENT))\n\t\t\tbreak;\n\t\tusleep(10);\n\t}\n\n\tif (!_systemd_activation) {\n\t\tfini_fifos(&fifos);\n\t\treturn;\n\t}\n\n\t/* Reopen fifos. */\n\tfini_fifos(&fifos);\n\tif (!init_fifos(&fifos)) {\n\t\tfprintf(stderr, \"Could not initiate communication with new instance of dmeventd.\\n\");\n\t\texit(EXIT_FAILURE);\n\t}\n\n\tif (!_reinstate_registrations(&fifos)) {\n\t\tfprintf(stderr, \"Failed to reinstate monitoring with new instance of dmeventd.\\n\");\n\t\tgoto bad;\n\t}\n\n\tfini_fifos(&fifos);\n\texit(EXIT_SUCCESS);\nbad:\n\tfini_fifos(&fifos);\n\texit(EXIT_FAILURE);\n}\n\nstatic void _usage(char *prog, FILE *file)\n{\n\tfprintf(file, \"Usage:\\n\"\n\t\t\"%s [-d [-d [-d]]] [-f] [-h] [-l] [-R] [-V] [-?]\\n\\n\"\n\t\t\"   -d       Log debug messages to syslog (-d, -dd, -ddd)\\n\"\n\t\t\"   -f       Don't fork, run in the foreground\\n\"\n\t\t\"   -h       Show this help information\\n\"\n\t\t\"   -l       Log to stdout,stderr instead of syslog\\n\"\n\t\t\"   -?       Show this help information on stderr\\n\"\n\t\t\"   -R       Restart dmeventd\\n\"\n\t\t\"   -V       Show version of dmeventd\\n\\n\", prog);\n}\n\nint main(int argc, char *argv[])\n{\n\tsigned char opt;\n\tstruct dm_event_fifos fifos = {\n\t\t.client = -1,\n\t\t.server = -1,\n\t\t.client_path = DM_EVENT_FIFO_CLIENT,\n\t\t.server_path = DM_EVENT_FIFO_SERVER\n\t};\n\ttime_t now, idle_exit_timeout = DMEVENTD_IDLE_EXIT_TIMEOUT;\n\topterr = 0;\n\toptind = 0;\n\n\twhile ((opt = getopt(argc, argv, \"?fhVdlR\")) != EOF) {\n\t\tswitch (opt) {\n\t\tcase 'h':\n\t\t\t_usage(argv[0], stdout);\n\t\t\texit(EXIT_SUCCESS);\n\t\tcase '?':\n\t\t\t_usage(argv[0], stderr);\n\t\t\texit(EXIT_SUCCESS);\n\t\tcase 'R':\n\t\t\t_restart++;\n\t\t\tbreak;\n\t\tcase 'f':\n\t\t\t_foreground++;\n\t\t\tbreak;\n\t\tcase 'd':\n\t\t\t_debug_level++;\n\t\t\tbreak;\n\t\tcase 'l':\n\t\t\t_use_syslog = 0;\n\t\t\tbreak;\n\t\tcase 'V':\n\t\t\tprintf(\"dmeventd version: %s\\n\", DM_LIB_VERSION);\n\t\t\texit(EXIT_SUCCESS);\n\t\t}\n\t}\n\n\tif (!_foreground && !_use_syslog) {\n\t\tprintf(\"WARNING: Ignoring logging to stdout, needs options -f\\n\");\n\t\t_use_syslog = 1;\n\t}\n\t/*\n\t * Switch to C locale to avoid reading large locale-archive file\n\t * used by some glibc (on some distributions it takes over 100MB).\n\t * Daemon currently needs to use mlockall().\n\t */\n\tif (setenv(\"LC_ALL\", \"C\", 1))\n\t\tperror(\"Cannot set LC_ALL to C\");\n\n\tif (_restart)\n\t\t_restart_dmeventd();\n\n#ifdef __linux__\n\t_systemd_activation = _systemd_handover(&fifos);\n#endif\n\n\tif (!_foreground)\n\t\t_daemonize();\n\n\tif (_use_syslog)\n\t\topenlog(\"dmeventd\", LOG_PID, LOG_DAEMON);\n\n\tdm_event_log_set(_debug_level, _use_syslog);\n\tdm_log_with_errno_init(_libdm_log);\n\n\t(void) dm_prepare_selinux_context(DMEVENTD_PIDFILE, S_IFREG);\n\tif (dm_create_lockfile(DMEVENTD_PIDFILE) == 0)\n\t\texit(EXIT_FAILURE);\n\n\tatexit(_remove_files_on_exit);\n\t(void) dm_prepare_selinux_context(NULL, 0);\n\n\t/* Set the rest of the signals to cause '_exit_now' to be set */\n\tsignal(SIGTERM, &_exit_handler);\n\tsignal(SIGINT, &_exit_handler);\n\tsignal(SIGHUP, &_exit_handler);\n\tsignal(SIGQUIT, &_exit_handler);\n\n#ifdef __linux__\n\t/* Systemd has adjusted oom killer for us already */\n\tif (!_systemd_activation && !_protect_against_oom_killer())\n\t\tlog_warn(\"WARNING: Failed to protect against OOM killer.\");\n#endif\n\n\t_init_thread_signals();\n\n\tpthread_mutex_init(&_global_mutex, NULL);\n\n\tif (!_systemd_activation && !_open_fifos(&fifos))\n\t\texit(EXIT_FIFO_FAILURE);\n\n\t/* Signal parent, letting them know we are ready to go. */\n\tif (!_foreground)\n\t\tkill(getppid(), SIGTERM);\n\n\tlog_notice(\"dmeventd ready for processing.\");\n\n\t_idle_since = time(NULL);\n\n\tif (_initial_registrations)\n\t\t_process_initial_registrations();\n\n\tfor (;;) {\n\t\tif (_idle_since) {\n\t\t\tif (_exit_now) {\n\t\t\t\tif (_exit_now == DM_SCHEDULED_EXIT)\n\t\t\t\t\tbreak; /* Only prints shutdown message */\n\t\t\t\tlog_info(\"dmeventd detected break while being idle \"\n\t\t\t\t\t \"for %ld second(s), exiting.\",\n\t\t\t\t\t (long) (time(NULL) - _idle_since));\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (idle_exit_timeout) {\n\t\t\t\tnow = time(NULL);\n\t\t\t\tif (now < _idle_since)\n\t\t\t\t\t_idle_since = now; /* clock change? */\n\t\t\t\tnow -= _idle_since;\n\t\t\t\tif (now >= idle_exit_timeout) {\n\t\t\t\t\tlog_info(\"dmeventd was idle for %ld second(s), \"\n\t\t\t\t\t\t \"exiting.\", (long) now);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t} else if (_exit_now == DM_SIGNALED_EXIT) {\n\t\t\t_exit_now = DM_SCHEDULED_EXIT;\n\t\t\t/*\n\t\t\t * When '_exit_now' is set, signal has been received,\n\t\t\t * but can not simply exit unless all\n\t\t\t * threads are done processing.\n\t\t\t */\n\t\t\tlog_info(\"dmeventd received break, scheduling exit.\");\n\t\t}\n\t\t_process_request(&fifos);\n\t\t_cleanup_unused_threads();\n\t}\n\n\tpthread_mutex_destroy(&_global_mutex);\n\n\tlog_notice(\"dmeventd shutting down.\");\n\n\tif (fifos.client >= 0 && close(fifos.client))\n\t\tlog_sys_error(\"client close\", fifos.client_path);\n\tif (fifos.server >= 0 && close(fifos.server))\n\t\tlog_sys_error(\"server close\", fifos.server_path);\n\n\tif (_use_syslog)\n\t\tcloselog();\n\n\t_exit_dm_lib();\n\n\texit(EXIT_SUCCESS);\n}\n"
    },
    "skipped": [],
    "total_files": 1063
}