{
    "matches": {
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/src/nrnjava/njvm.cpp": "/*\n March 2001 modified by Michael Hines so that NEURON starts\n\tthe Java VM\n*/\n\n// nj_load() supports the load_java hoc command\n\n// nrn_InitializeJavaVM makes the Java virtual machine ready for use\n// this is done from ivocmain.cpp shortly after NEURON is launched.\n// Initializing just before the first load_java command did not work.\n// Mac and MSWIN dynamically load the jvm. \n\n#include <../../nrnconf.h>\n#ifdef WIN32\n#include <windows.h>\n#endif\n\n#include \"njconf.h\" // which jvm version to use\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <jni.h>\n#include <InterViews/resource.h>\n#include \"nrnoc2iv.h\"\n#include \"njvm.h\"\n#if HAVE_LOCALE_H\n// Java may set the locale so sprint(buf, \"%g\", 1.5) gives \"1,5\"\n// if so we will need to set it back.\n#include <locale.h>\n#endif\n#if defined(JVM_DLOPEN)\n#include <dlfcn.h>\njint nrn_CreateJavaVM(JavaVM **pvm, void **penv, void *args);\n#endif\n\n// Java virtual machine version\n// The Mac only has Java 1 via the MRJ. No reason not to always use\n// Java2 for mswin. Unix can use either (see njconf.h.in)\n// However, only Java2 is fully supported and allows additions to\n// the classpath from hoc.\n#if carbon\n#undef MAC\n#endif\n\n#ifndef USEJVM\n#if MAC\n#define USEJVM 1\n#else\n#define USEJVM 2\n#endif\n#endif\n\nextern \"C\" {\n// Java has threads and NEURON does not. It is important that when\n// Java calls a function in NEURON and then NEURON calls back a function\n// in Java that the proper thread environment is used. This is done\n// with the njvm.h macros jnisave and jnirestore that put the env into nrnjava_env\n// How are errors handled?\nJNIEnv* nrnjava_env;\nJNIEnv* nrnjava_root_env;\nJavaVM* nrnjava_vm; // CreateJavaVM fills this in but we do not use it.\nextern char* neuron_home;\nextern int(*p_hoc_load_java)();\nstatic int nj_load();\nextern void* (*p_java2nrn_cons)(Object*);\n\n#ifdef WIN32\n#undef _WIN32\n#define _WIN32\n#endif\n#ifdef _WIN32\nchar* hoc_back2forward(char*);\njint nrn_CreateJavaVM(JavaVM **pvm, void **penv, void *args);\n#endif\n#if MAC\nstatic jint nrn_GetDefaultJavaVMInitArgs(void*);\nstatic jint nrn_CreateJavaVM(JavaVM **pvm, JNIEnv **penv, void *args);\n#endif\n}\nint convertJavaClassToHoc(JNIEnv*, const char*, const char*, const char*);\nvoid nrnjava_init();\n\n#ifdef _WIN32\n#define PATH_SEPARATOR ';'\n#else /* UNIX */\n#define PATH_SEPARATOR ':'\n#endif\n\n#define NULL_CHECK(arg) nrn_assert((arg))\n#if USEJVM == 2\n/*\n * List of VM options to be specified when the VM is created.\n */\nstatic JavaVMOption *options;\nstatic int numOptions, maxOptions;\n#endif\n\nextern \"C\" { // needed by microsoft visual c++\n// support load_java command in hoc.\n// e.g. load_java(\"java.lang.String\", \"JString\")\n// p_hoc_load_java points to this\nstatic int nj_load() {\n\t// first time through, initialize\n\tif (!p_java2nrn_cons) {\n\t\tif (!nrnjava_root_env) {\n\t\t\thoc_execerror(\"The JavaVM is not available.\", 0);\n\t\t}\n\t\tnrnjava_init();\n\t\tif (!p_java2nrn_cons) {\n\t\t\thoc_execerror(\" Java portion of NEURON was not initialized.\", 0);\n\t\t}\n\t}\n\tchar* jname; // fully qualified name. e.g. java.lang.String\n\tchar* hname; // hoc name, e.g. JString\n\tchar* path = \"\"; // classpath addition to find jname. See NrnClassLoader.add\n\n\tjname = gargstr(1);\n\t// hocname same as jname if not specified as second arg\n\tif (ifarg(2)) {\n\t\thname = gargstr(2);\n\t}else{\n\t\thname = jname;\n\t}\n\tif (ifarg(3)) {\n\t\tpath = gargstr(3);\n\t}\n\t// see neuron/Neuron.java makeHocClass\n\treturn convertJavaClassToHoc(nrnjava_env, jname, hname, path);\n}\n}\n\n#if USEJVM == 2\n// copied from /usr/j2se/src.jar : src/launcher/java.c\n/*\n * Adds a new VM option with the given given name and value.\n */\nstatic void\nAddOption(char *str, void *info)\n{\n\tint i;\n    /*\n     * Expand options array if needed to accomodate at least one more\n     * VM option.\n     */\n    if (numOptions >= maxOptions) {\n\tif (options == 0) {\n\t    maxOptions = 4;\n\t    options = new JavaVMOption[maxOptions];\n\t} else {\n\t    JavaVMOption *tmp;\n\t    tmp = new JavaVMOption[maxOptions*2];\n\t    for (i=0; i < numOptions; ++i) {\n\t\ttmp[i].optionString = options[i].optionString;\n\t\ttmp[i].extraInfo = options[i].extraInfo;\n\t    }\n\t    maxOptions *= 2;\n\t    delete [] options;\n\t    options = tmp;\n\t}\n    }\n    options[numOptions].optionString = str;\n    options[numOptions++].extraInfo = info;\n}\n#endif\n\n// copied from /usr/j2se/src.jar : src/launcher/java.c\n/*\n * Prints the version information from the java.version and other properties.\n */\n\nstatic void\nPrintJavaVersion(JNIEnv *env)\n{\n    jclass ver;\n    jmethodID print;\n\n    NULL_CHECK(ver = (env)->FindClass(\"sun/misc/Version\"));\n    NULL_CHECK(print = (env)->GetStaticMethodID(ver, \"print\", \"()V\"));\n\n    (env)->CallStaticVoidMethod(ver, print);\n}\n\nstatic void myabort() {\n\tprintf(\"my abort\\n\");\n\texit(1);\n}\n\nstatic void myexit() {\n\tprintf(\"my exit\\n\");\n\texit(1);\n}\n\njint myvfprintf(FILE* fp, const char* format, va_list args);\n\njint myvfprintf(FILE* fp, const char* format, va_list args) {\n\tchar buf[1024];\n\tvsprintf(buf, format, args);\n\tprintf(\"%s\", buf);\n\treturn 1;\n}\n\n#if USEJVM == 1\n// allowing Mac classic dlopen and Unix static\nstatic void initialize_jvm1();\nstatic void initialize_jvm1() {\n\tchar* classpath;\n\tJDK1_1InitArgs args;\n\targs.version = 0x00010001;\n\t//args.debugging = 1;\n\t//args.vfprintf = myvfprintf;\n#if MAC\n\tif (nrn_GetDefaultJavaVMInitArgs(&args) < 0) {\n\t\treturn;\n\t}\n\tclasspath = new char[strlen(args.classpath) + 2*strlen(neuron_home) + 100];\n\t// following string for mac, then convert ; to :\n\tsprintf(classpath, \"%s;/%s/classes/neuron.jar\",\n\t args.classpath, neuron_home);\n\tfor (char* cp = classpath; *cp; ++cp) {\n\t\tif (*cp == ';') {\n\t\t\t*cp = ':';\n\t\t}else if (*cp == ':') {\n\t\t\t*cp = '/';\n\t\t}\n\t}\n#else\n\tJNI_GetDefaultJavaMVInitArgs(&args);\n\tconst char* ucpenv = getenv(\"CLASSPATH\");\n// Find classes first in the working directory where neuron was launched.\n// Then the users CLASSPATH\n// environment variable (if any). And lastly, the, $NEURONHOME/classes\n\tif (ucpenv == nil) {\n\t\tucpenv = \".\"; // can't hurt to have it twice\n\t}\n\tint len = strlen(args.classpath) + strlen(ucpenv) + 2*strlen(neuron_home) + 100;\n\tclasspath = new char[len];\n\t\t\n\tsprintf(classpath,\n\t\t\"%s%c.%c%s%c%s/classes/neuron.jar\",\n\t\targs.classpath, PATH_SEPARATOR, PATH_SEPARATOR,\n\t\tPATH_SEPARATOR, ucpenv, PATH_SEPARATOR,  neuron_home,\n\t);\n\n//printf(\"%s\\n\", classpath);\n\n\tsprintf(classpath, \"%s:.:%s/classes/neuron.jar\", args.classpath, neuron_home);\n#endif\n\targs.classpath = classpath;\n\t//for (int i = 0;  args.properties[i]; ++i) {\n\t\t//printf(\"properties |%s|\\n\", args.properties[i]);\n\t//}\n\t//args.debugging = 1;\n\t//args.vfprintf = myvfprintf;\n\tprintf(\"classpath |%s|\\n\", args.classpath);\n#if MAC\n\tjint res = nrn_CreateJavaVM(&nrnjava_vm, &nrnjava_root_env, (void*)&args);\n#else\n\tjint res = JNI_CreateJavaVM(&nrnjava_vm, (void**)&nrnjava_root_env, &args);\n#endif\n\tnrnjava_env = nrnjava_root_env;\n\tif (res < 0) {\n\t\tfprintf(stderr, \"JNI_CreateJavaVM returned %d\\n\", res);\n\t}else{\n\t\tp_hoc_load_java = nj_load;\n\t\tfprintf(stderr, \"Created Java VM\\n\");\n\t}\n}\n#endif\n\n#if USEJVM == 2\n// allowing mswin and unix dlopen and unix static\nstatic void initialize_jvm2();\nstatic void initialize_jvm2() {\n\tJavaVMInitArgs args;\n// Because we want to dynamically append to the classpath from hoc\n// we do all class loading through the neuron/NrnClassLoader in order\n// to defeat the security policy.\n\tchar* classpath;\n\tint len = strlen(neuron_home) + 100;\n\tclasspath = new char[len];\n\tsprintf(classpath, \"-Djava.class.path=%s/classes/nrnclsld.jar\",\tneuron_home);\n\n#if defined(_WIN32)\n\thoc_back2forward(classpath);\n#endif\n\n//printf(\"%s\\n\", classpath);\n\n\targs.version = JNI_VERSION_1_2;\n//printf(\"version = %lx\\n\", args.version);\n\t\n\tAddOption(classpath, nil);\n//\tAddOption(\"-verbose\", nil);\n//\tAddOption(\"abort\", myabort);\n//\tAddOption(\"exit\", myexit);\n\targs.nOptions = numOptions;\n\targs.options = options;\n\targs.ignoreUnrecognized = JNI_FALSE;\n\n#if defined(_WIN32) || defined(JVM_DLOPEN)\n\tjint res = nrn_CreateJavaVM(&nrnjava_vm, (void**)&nrnjava_root_env, &args);\n\tif (res == -10) { return; }\n#else\n\tjint res = JNI_CreateJavaVM(&nrnjava_vm, (void**)&nrnjava_root_env, &args);\n#endif\n\tnrnjava_env = nrnjava_root_env;\n\tdelete [] classpath;\n\tdelete [] options;\n\tif (res < 0) {\n\t\tswitch (res) {\n\t\tcase JNI_EVERSION:\n\t\t\tfprintf(stderr, \"JNI Version error. VM is not JNI_VERSION_1_2\\n\");\n\t\t\tbreak;\n\t\tcase JNI_ENOMEM:\n\t\t\tfprintf(stderr, \"Not enough memory\\n\");\n\t\t\tbreak;\n\t\tcase JNI_EINVAL:\n\t\t\tfprintf(stderr, \"invalid arguments\\n\");\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tfprintf(stderr, \"JNI_CreateJavaVM returned %d\\n\", res);\n\t\t\tbreak;\n\t\t}\n\t\tfprintf(stderr, \"Info: optional feature Java VM is not present.\\n\");\n\t}else{\n\t\tp_hoc_load_java = nj_load;\n\t\tif (nrn_istty_) {\n\t\t\tfprintf(stderr, \"Created Java VM\\n\");\n\t\t\tPrintJavaVersion(nrnjava_env);\n\t\t}\n\t}\n}\n#endif\n\nvoid nrn_InitializeJavaVM() {\n\tif (nrnjava_root_env) { // hmm. NEURON must have been loaded by java\n\t\tnrnjava_env = nrnjava_root_env;\n\t\tp_hoc_load_java = nj_load;\n\t} else {\n#if USEJVM == 2\n\t\tinitialize_jvm2();\n#else\n\t\tinitialize_jvm1();\n#endif\n\t}\n\n#if HAVE_LOCALE_H\n\t// in case Java set the locale such that the radix is a ',', set it\n\t// back to a '.'\n\tchar radixtest[50];\n\tsprintf(radixtest, \"%g\", 1.5);\n//printf(\"radixtest=|%s|\\n\", radixtest);\n\tif (strchr(radixtest, ',')) {\n\t\tsetlocale(LC_NUMERIC, \"C\");\n//\t\tsprintf(radixtest, \"%g\", 1.5);\n//printf(\"after setlocale(LC_NUMERIC, \\\"C\\\"), radixtest=|%s|\\n\", radixtest);\n\t}\n#endif\n}\n\n#if defined(JVM_DLOPEN)\n\n#include <InterViews/session.h>\n#include <OS/string.h>\n#include <InterViews/style.h>\ntypedef jint(*PCJVM)(JavaVM**, void**, void*);\n\njint nrn_CreateJavaVM(JavaVM **pvm, void **penv, void *args) {\n\tjint res;\n\n\t*pvm = 0;\n\t*penv = 0;\n\tSession* ses = Session::instance();\n\tString str(\"libjvm.so\");\n\tchar* name = \"jvmdll\";\n\tif (ses && !ses->style()->find_attribute(name, str)){\n//\t\tfprintf(stderr, \"\\\"%s\\\" not defined in nrn.defaults\\n\", name);\n\t\treturn -10;\n\t}\n\tvoid* handle = (void *) dlopen(str.string(), RTLD_NOW | RTLD_GLOBAL);\n\tif (!handle) {\n\t\tfprintf(stderr, \"dlopen(\\\"%s\\\") failed: %s\\n\", str.string(), dlerror());\n\t\treturn -1;\n\t}\n#if defined(DARWIN)\n\tPCJVM addr = (PCJVM)dlsym(handle, \"JNI_CreateJavaVM_Impl\");\n#else\n\tPCJVM addr = (PCJVM)dlsym(handle, \"JNI_CreateJavaVM\");\n#endif\n\tif (!addr) {\n\t\tfprintf(stderr, \"%s\\n\", dlerror());\n\t\treturn -1;\n\t}\n\tres = (*addr)(pvm, penv, args);\n\treturn res;\n}\n#endif\n\n#ifdef _WIN32\n#if _MSC_VER\n#undef bool\n#endif\n#if defined(__MWERKS__) && __MWERKS__ >= 7\n#undef bool\n#endif\n#include <InterViews/session.h>\n#include <OS/string.h>\n#include <InterViews/style.h>\nstatic int jerr_;\nstatic void *\ndlopen (const char *name, int)\n{\n  void *ret;\n\n    {\n      /* handle for the named library */\n      String str;\n\tjerr_ = 0;\n      if (!Session::instance()->style()->find_attribute(name, str)){\n      \t//fprintf(stderr, \"\\\"%s\\\" not defined in nrn.def\\n\", name);\n\tjerr_ = -10;\n        ret = NULL;\n      }else{\n          ret = (void *) LoadLibrary (str.string());\n          if (ret == NULL) {\n\t\tDWORD dw = GetLastError();\n            fprintf(stderr, \"LoadLibrary(\\\"%s\\\") failed with error %d\\n\", str.string(), dw);\n\t\tjerr_ = -1;\n\t  }\n      }\n    }\n\n  return ret;\n}\n\nstatic void *\ndlsym (void *handle, const char *name)\n{\n  void *ret = (void *) GetProcAddress ((HMODULE) handle, name);\n  if (!ret) {\n  \tfprintf(stderr, \"Could not GetProcAddress for \\\"%s\\\"\\n\", name);\n  }\n  return ret;\n}\n\n#if defined(_MSC_VER)\ntypedef jint(CALLBACK *PCJVM)(JavaVM**, void**, void*);\n#else\ntypedef jint(*PCJVM)(JavaVM**, void**, void*);\n#endif\n\njint nrn_CreateJavaVM(JavaVM **pvm, void **penv, void *args) {\n\tjint res;\n\n\t*pvm = 0;\n\t*penv = 0;\n\tvoid* handle = dlopen(\"jvmdll\", 0);\n\tif (!handle) { return jerr_; }\n\tPCJVM addr = (PCJVM)dlsym(handle, \"JNI_CreateJavaVM\");\n\tif (!addr) { return -1; }\n\tres = (*addr)(pvm, penv, args);\n\treturn res;\n}\n#endif\n\n#if MAC\nextern \"C\" {\nbool is_mac_dll(FSSpec*);\nextern OSErr __path2fss(const char* name, FSSpec*);\n}\ntypedef jint(*PCJVM)(JavaVM**, JNIEnv**, void*);\ntypedef jint(*PIJVM)(void*);\ntypedef CFragConnectionID(*PF)();\nstatic PCJVM caddr;\n\nstatic jint nrn_GetDefaultJavaVMInitArgs(void* args) {\n\tPIJVM iaddr = 0;\n\tlong i, cnt;\n\tCFragConnectionID id;\n\tCFragSymbolClass sc;\n\tPtr sa;\n\tStr255 sname;\n\tOSErr myErr;\n\tFSSpec fs;\n\tchar name[256];\n\t\n\tsprintf(name, \"%s:nrnjvmdll\", neuron_home);\n\t\n\tif ((__path2fss(name, &fs) == fnfErr) || !is_mac_dll(&fs)) {\n\t\tfprintf(stderr, \"%s is not the nrnjvmdll\\n\", name);\n\t\treturn -1;\n\t}\n\t\n\tmyErr = GetDiskFragment(&fs, 0, kCFragGoesToEOF,\n\t\t0, kLoadCFrag, &id, &sa, sname);\n\t//myErr = GetSharedLibrary(\"\\pMRJLib\", kPowerPCCFragArch, kLoadCFrag,\n\t//\t&id, &sa, sname);\n\tif (myErr) {\n\t\tsname[sname[0]+1]='\\0';\n\t\tfprintf(stderr, \"could not load the Java VM : %s\\n\", sname+1);\n\t\treturn -1;\n\t}\n\tsa = 0;\n\tmyErr = CountSymbols(id, &cnt);\n\t//printf(\"%d symbols exported\\n\", cnt);\n\tfor (i=0; i < cnt; ++i) {\n\t\tmyErr = GetIndSymbol(id, i, sname, &sa, &sc);\n\t\tsname[sname[0]+1] = '\\0';\n\t\t//printf(\"%d %s\\n\", i, sname+1);\n\t\tif (strcmp((char*)(sname+1), \"nrn2_GetDefaultJavaVMInitArgs\") == 0) {\n\t\t\tiaddr = (PIJVM)sa;\n\t\t}\n\t\tif (strcmp((char*)(sname+1), \"nrn2_CreateJavaVM\") == 0) {\n\t\t\tcaddr = (PCJVM)sa;\n\t\t}\n\t}\n\tif (iaddr) {\n\t\tjint res = (*iaddr)(args);\n\t\tif (res < 0) {\n\t\t\tfprintf(stderr, \"call to JNI_GetDefaultJavaVMInitArgs returned %d\\n\", res);\n\t\t}\n\t\treturn res;\n\t}\n\tfprintf(stderr, \"no address for JNI_GetDefaultJavaVMInitArgs\\n\");\n\treturn -1;\n}\n\nstatic jint nrn_CreateJavaVM(JavaVM **pvm, JNIEnv **penv, void *args) {\n\tjint res;\n\t*pvm = 0;\n\t*penv = 0;\n\tif (!caddr) {\n\t\tfprintf(stderr, \"no address for JNI_CreateJavaVM\\n\");\n\t\treturn -1;\n\t}\n\tres = (*caddr)(pvm, penv, args);\n\treturn res;\n}\n#endif\n",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/src/oc/cygwinprt.c": "#include <../../nrnconf.h>\n#include <errno.h>\n#include <unistd.h>\n#if defined(CYGWIN) || defined(MINGW)\n\n#if !defined(__MINGW32__)\n#include \"system.c\"\n#define my_off64_t loff_t\n#else\n#define my_off64_t off64_t\n#endif\n\n#include \"mswinprt.c\"\n\nmy_off64_t lseek64(int fd, my_off64_t offset, int whence) {\n\tfprintf(stderr, \"called lseek64\\n\");\n\tabort();\n}\n\n/* mingw does not have dlfcn.h */\n#if !defined(HAVE_DLFCN_H) || defined(__MINGW32__)\n\nvoid* dlopen(const char *name, int mode) {\n\tvoid *ret;\n\t/* handle for the named library */\n\tret = (void *) LoadLibrary(name);\n        if (ret == NULL) {\n\t\tDWORD dw = GetLastError();\n\t\tfprintf(stderr, \"LoadLibrary(\\\"%s\\\") failed with error %d\\n\", name, dw);\n\t}\n\treturn ret;\n}\n\nvoid* dlopen_noerr(const char *name, int mode) {return (void*)LoadLibrary(name);}\n\nvoid* dlsym(void *handle, const char *name) {\n\tvoid *ret = (void *) GetProcAddress ((HMODULE) handle, name);\n\tif (!ret) {\n\t\tfprintf(stderr, \"Could not GetProcAddress for \\\"%s\\\"\\n\", name);\n\t}\n\treturn ret;\n}\n\nint dlclose(void* handle) {\n}\n\nstatic char* dler_=\"\";\nchar* dlerror() {\n\treturn dler_;\n}\n#endif /* HAVE_DLFCN_H */\n\n#endif\n\n",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/src/nrnoc/osxdlfcn.h": "/*\nCopyright (c) 2002 Jorge Acereda  <jacereda@users.sourceforge.net> &\n                   Peter O'Gorman <ogorman@users.sourceforge.net>\n                   \nPortions may be copyright others, see the AUTHORS file included with this\ndistribution.\n\nMaintained by Peter O'Gorman <ogorman@users.sourceforge.net>\n\nBug Reports and other queries should go to <ogorman@users.sourceforge.net>\n\nPermission is hereby granted, free of charge, to any person obtaining\na copy of this software and associated documentation files (the\n\"Software\"), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\n\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\nLIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\nOF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\nWITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n*/\n#ifndef _DLFCN_H_\n#define _DLFCN_H_\n\n#ifdef __cplusplus\nextern \"C\" {\n#endif\n\n#if defined (__GNUC__) && __GNUC__ > 3\n#define dl_restrict __restrict\n#else\n#define dl_restrict\n#endif\n/*\n * Structure filled in by dladdr().\n */\n\ntypedef struct dl_info {\n        const char      *dli_fname;     /* Pathname of shared object */\n        void            *dli_fbase;     /* Base address of shared object */\n        const char      *dli_sname;     /* Name of nearest symbol */\n        void            *dli_saddr;     /* Address of nearest symbol */\n} Dl_info;\n\nextern void * dlopen(const char *path, int mode);\nextern void * dlsym(void * dl_restrict handle, const char * dl_restrict symbol);\nextern const char * dlerror(void);\nextern int dlclose(void * handle);\nextern int dladdr(const void * dl_restrict, Dl_info * dl_restrict);\n\n#define RTLD_LAZY\t0x1\n#define RTLD_NOW\t0x2\n#define RTLD_LOCAL\t0x4\n#define RTLD_GLOBAL\t0x8\n#define RTLD_NOLOAD\t0x10\n#define RTLD_NODELETE\t0x80\n\n/*\n * Special handle arguments for dlsym().\n */\n#define\tRTLD_NEXT\t\t((void *) -1)\t/* Search subsequent objects. */\n#define\tRTLD_DEFAULT\t((void *) -2)\t/* Use default search algorithm. */\n\n#ifdef __cplusplus\n}\n#endif\n\n#endif /* _DLFCN_H_ */\n",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/src/nrnoc/init.c": "#include <../../nrnconf.h>\n#include <nrnmpiuse.h>\n\nextern char* nrn_version();\n\n/* change this to correspond to the ../nmodl/nocpout nmodl_version_ string*/\nstatic char nmodl_version_[] =\n\"7.7.0\";\n\nstatic char banner[] =\n\"Duke, Yale, and the BlueBrain Project -- Copyright 1984-2019\\n\\\nSee http://neuron.yale.edu/neuron/credits\\n\";\n\n# include\t<stdio.h>\n#include <errno.h>\n#include <string.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include \"section.h\"\n#include \"parse.h\"\n#include \"nrniv_mf.h\"\n#include \"cabvars.h\"\n#include \"neuron.h\"\n#include \"membdef.h\"\n#include \"nrnmpi.h\"\n\n#ifdef WIN32\n#if defined(HAVE_DLFCN_H) && !defined(__MINGW32__)\n#include <dlfcn.h>\n#else\n#define RTLD_NOW 0\nextern void* dlopen(const char* name, int mode);\nextern void* dlsym(void* handle, char* name);\nextern int dlclose(void* handle);\nextern char* dlerror();\n#endif\n/*#include \"../mswin/windll/dll.h\"*/\n/*static struct DLL* dll;*/\n#endif // WIN32\n\n#if defined(WIN32) || defined(NRNMECH_DLL_STYLE)\nextern char* nrn_mech_dll; /* declared in hoc_init.c so ivocmain.cpp can see it */\nextern int nrn_noauto_dlopen_nrnmech; /* default 0 declared in hoc_init.c */\n#endif\n\n#if defined(WIN32)\n#undef DLL_DEFAULT_FNAME\n#define DLL_DEFAULT_FNAME \"nrnmech.dll\"\n#endif // WIN32\n\n#if defined(NRNMECH_DLL_STYLE)\n#if defined(DARWIN)\n\n#ifndef DLL_DEFAULT_FNAME\n#define DLL_DEFAULT_FNAME \"libnrnmech.dylib\"\n#endif\n\n#if __GNUC__ < 4\n#include \"osxdlfcn.h\"\n#include \"osxdlfcn.c\"\n#else\n#include <dlfcn.h>\n#endif // __GNUC__\n\n#else\n\n#if defined(HAVE_DLFCN_H) && !defined(__MINGW32__)\n#include <dlfcn.h>\n#endif\n\n#ifndef DLL_DEFAULT_FNAME\n#define DLL_DEFAULT_FNAME \"./libnrnmech.so\"\n#endif\n#endif\n#else // !defined(NRNMECH_DLL_STYLE)\n#if defined(HAVE_DLFCN_H) && !defined(__MINGW32__)\n#include <dlfcn.h>\n#endif\n#endif\n\n# define\tCHECK(name)\tif (hoc_lookup(name) != (Symbol *)0){\\\n\t\tIGNORE(fprintf(stderr, CHKmes, name));\\\n\t\tnrn_exit(1);}\n\nstatic char\tCHKmes[] = \"The user defined name, %s, already exists\\n\";\n\nvoid (*nrnpy_reg_mech_p_)(int);\n\nint secondorder=0;\nint state_discon_allowed_;\nextern int nrn_nobanner_;\ndouble t, dt, clamp_resist, celsius, htablemin, htablemax;\nint nrn_netrec_state_adjust = 0;\nint nrn_sparse_partrans = 0;\nhoc_List* section_list;\nint nrn_global_ncell = 0; /* used to be rootnodecount */\nextern double hoc_default_dll_loaded_;\nextern int nrn_istty_;\nextern int nrn_nobanner_;\n\n#if FISHER\n#include <stdlib.h>\n#include \"fisher.h\"\ndouble id_number;              /* for rcs control, set in setup_id_info() */\nchar login_name[20];           /* store user's login for sys.c & rcs.c    */\nchar *pipe_filter = \"more\";    /* allow for running NEURON in emacs       */\n#endif\n\nstatic HocParmLimits _hoc_parm_limits[] = {\n\t\"Ra\", 1e-6, 1e9,\n\t\"L\", 1e-4, 1e20,\n\t\"diam\", 1e-9, 1e9,\n\t\"cm\", 0., 1e9,\n\t\"rallbranch\", 1., 1e9,\n\t\"nseg\", 1., 1e9,\n\t\"celsius\", -273., 1e6,\n\t\"dt\", 1e-9, 1e15,\n\t0, 0., 0.\n};\n\nstatic HocParmUnits _hoc_parm_units[] = {\n\t\"Ra\", \"ohm-cm\",\n\t\"L\", \"um\",\n\t\"diam\", \"um\",\n\t\"cm\", \"uF/cm2\",\n\t\"celsius\", \"degC\",\n\t\"dt\", \"ms\",\n\t\"t\", \"ms\",\n\t\"v\", \"mV\",\n\t\"i_cap\", \"mA/cm2\",\n\t0, 0\n};\n\nextern Symlist* nrn_load_dll_called_;\nextern int nrn_load_dll_recover_error();\nextern void nrn_load_name_check(const char* name);\nstatic int memb_func_size_;\nMemb_func* memb_func;\nMemb_list* memb_list;\nshort* memb_order_;\nSymbol** pointsym;\nPoint_process** point_process;\nchar* pnt_map;\t\t/* so prop_free can know its a point mech*/\nBAMech** bamech_;\n\nTemplate** nrn_pnt_template_; /* for finding artificial cells */\n/* for synaptic events. */\npnt_receive_t* pnt_receive;\npnt_receive_init_t* pnt_receive_init;\nshort* pnt_receive_size;\n\n /* values are type numbers of mechanisms which do net_send call */\nint nrn_has_net_event_cnt_;\nint* nrn_has_net_event_;\nint* nrn_prop_param_size_;\nint* nrn_prop_dparam_size_;\nint* nrn_dparam_ptr_start_;\nint* nrn_dparam_ptr_end_;\ntypedef int (*bbcore_write_t)(void*, int, int*, double*, Datum*, Datum*, NrnThread*);\nbbcore_write_t* nrn_bbcore_write_;\nvoid hoc_reg_bbcore_write(int type, bbcore_write_t f) {\n\tnrn_bbcore_write_[type] = f;\n}\n\nconst char** nrn_nmodl_text_;\nvoid hoc_reg_nmodl_text(int type, const char* txt) {\n\tnrn_nmodl_text_[type] = txt;\n}\n\nconst char** nrn_nmodl_filename_;\nvoid hoc_reg_nmodl_filename(int type, const char* filename) {\n\tnrn_nmodl_filename_[type] = filename;\n}\n\nvoid  add_nrn_has_net_event(type) int type; {\n\t++nrn_has_net_event_cnt_;\n\tnrn_has_net_event_ = (int*)erealloc(nrn_has_net_event_, nrn_has_net_event_cnt_*sizeof(int));\n\tnrn_has_net_event_[nrn_has_net_event_cnt_ - 1] = type;\n}\n\n/* values are type numbers of mechanisms which have FOR_NETCONS statement */\nint nrn_fornetcon_cnt_; /* how many models have a FOR_NETCONS statement */\nint* nrn_fornetcon_type_; /* what are the type numbers */\nint* nrn_fornetcon_index_; /* what is the index into the ppvar array */\n\nvoid add_nrn_fornetcons(int type, int indx) {\n\tint i = nrn_fornetcon_cnt_++;\n\tnrn_fornetcon_type_ = (int*)erealloc(nrn_fornetcon_type_, (i+1)*sizeof(int));\n\tnrn_fornetcon_index_ = (int*)erealloc(nrn_fornetcon_index_, (i+1)*sizeof(int));\n\tnrn_fornetcon_type_[i] = type;\n\tnrn_fornetcon_index_[i]= indx;\n}\n\n/* array is parallel to memb_func. All are 0 except 1 for ARTIFICIAL_CELL */\nshort* nrn_is_artificial_;\nshort* nrn_artcell_qindex_;\n\nvoid  add_nrn_artcell(int type, int qi) {\n\tnrn_is_artificial_[type] = 1;\n\tnrn_artcell_qindex_[type] = qi;\n}\n\nint nrn_is_artificial(int pnttype) {\n\treturn (int)nrn_is_artificial_[pointsym[pnttype]->subtype];\n}\n\nint nrn_is_cable(void) {return 1;}\n\nvoid* nrn_realpath_dlopen(const char* relpath, int flags) {\n  char* abspath = NULL;\n  void* handle = NULL;\n\n  /* use realpath or _fullpath even if is already a full path */\n\n#if defined(HAVE_REALPATH)\n  abspath = realpath(relpath, NULL);\n#else /* not HAVE_REALPATH */\n#if defined(__MINGW32__)\n  abspath = _fullpath(NULL, relpath, 0);\n#else /* not __MINGW32__ */\n  abspath = strdup(relpath);\n#endif /* not __MINGW32__ */\n#endif /* not HAVE_REALPATH */\n  if (abspath) {\n    handle = dlopen(abspath, flags);\n    free(abspath);\n  }else{\n    int patherr = errno;\n    handle = dlopen(relpath, flags);\n    if (!handle) {\n      Fprintf(stderr, \"realpath failed errno=%d (%s) and dlopen failed with %s\\n\", patherr, strerror(patherr), relpath);\n    }\n  }\n  return handle;\n}\n\nint mswin_load_dll(const char* cp1) {\n\tvoid* handle;\n\tif (nrnmpi_myid < 1) if (!nrn_nobanner_ && nrn_istty_) {\n\t\tfprintf(stderr, \"loading membrane mechanisms from %s\\n\", cp1);\n\t}\n#if DARWIN\n\thandle = nrn_realpath_dlopen(cp1, RTLD_NOW);\n#else\n\thandle = dlopen(cp1, RTLD_NOW);\n#endif\n\tif (handle) {\n\t\tPfrv mreg = (Pfrv)dlsym(handle, \"modl_reg\");\n\t\tif (mreg) {\n\t\t\t(*mreg)();\n\t\t}else{\n\t\t\tfprintf(stderr, \"dlsym _modl_reg failed\\n%s\\n\", dlerror());\n\t\t\tdlclose(handle);\n\t\t\treturn 0;\n\t\t}\n\t\treturn 1;\n\t}else{\n\t\tfprintf(stderr, \"dlopen failed - \\n%s\\n\", dlerror());\n\t}\n\treturn 0;\n}\n\nvoid hoc_nrn_load_dll(void) {\n\tint i;\n\tFILE* f;\n\tconst char* fn;\n\tfn = expand_env_var(gargstr(1));\n\tf = fopen(fn, \"rb\");\n\tif (f) {\n\t\tfclose(f);\n\t\tnrn_load_dll_called_ = hoc_symlist;\n\t\thoc_symlist = hoc_built_in_symlist;\n\t\thoc_built_in_symlist = (Symlist*)0;\n\t\t/* If hoc_execerror, recover before that call */\n\t\ti = mswin_load_dll(fn);\n\t\thoc_built_in_symlist = hoc_symlist;\n\t\thoc_symlist = nrn_load_dll_called_;\n\t\tnrn_load_dll_called_ = (Symlist*)0;\n\t\thoc_retpushx((double)i);\n\t}else{\n\t\thoc_retpushx(0.);\n\t}\t\n}\n\nextern void nrn_threads_create(int);\n\nstatic DoubScal scdoub[] = {\n\t\"t\", &t,\n\t\"dt\", &dt,\n\t0,0\n};\n\nvoid hoc_last_init(void)\n{\n\tint i;\n\tPfrv *m;\n\tSymbol *s;\n\n\thoc_register_var(scdoub, (DoubVec*)0, (VoidFunc*)0);\n\tnrn_threads_create(1);\n\n \tif (nrnmpi_myid < 1) if (nrn_nobanner_ == 0) { \n\t    Fprintf(stderr, \"%s\\n\", nrn_version(1));\n\t    Fprintf(stderr, \"%s\\n\", banner);\n\t    IGNORE(fflush(stderr));\n \t} \n\tmemb_func_size_ = 30;\n\tmemb_func = (Memb_func*)ecalloc(memb_func_size_, sizeof(Memb_func));\n\tmemb_list = (Memb_list*)ecalloc(memb_func_size_, sizeof(Memb_list));\n\tpointsym = (Symbol**)ecalloc(memb_func_size_, sizeof(Symbol*));\n\tpoint_process = (Point_process**)ecalloc(memb_func_size_, sizeof(Point_process*));\n\tpnt_map = (char*)ecalloc(memb_func_size_, sizeof(char));\n\tmemb_func[1].alloc = cab_alloc;\n\tnrn_pnt_template_ = (Template**)ecalloc(memb_func_size_, sizeof(Template*));\n\tpnt_receive = (pnt_receive_t*)ecalloc(memb_func_size_, sizeof(pnt_receive_t));\n\tpnt_receive_init = (pnt_receive_init_t*)ecalloc(memb_func_size_, sizeof(pnt_receive_init_t));\n\tpnt_receive_size = (short*)ecalloc(memb_func_size_, sizeof(short));\n\tnrn_is_artificial_ = (short*)ecalloc(memb_func_size_, sizeof(short));\n\tnrn_artcell_qindex_ = (short*)ecalloc(memb_func_size_, sizeof(short));\n\tnrn_prop_param_size_ = (int*)ecalloc(memb_func_size_, sizeof(int));\n\tnrn_prop_dparam_size_ = (int*)ecalloc(memb_func_size_, sizeof(int));\n\tnrn_dparam_ptr_start_ = (int*)ecalloc(memb_func_size_, sizeof(int));\n\tnrn_dparam_ptr_end_ = (int*)ecalloc(memb_func_size_, sizeof(int));\n\tmemb_order_ = (short*)ecalloc(memb_func_size_, sizeof(short));\n\tbamech_ = (BAMech**)ecalloc(BEFORE_AFTER_SIZE, sizeof(BAMech*));\n\tnrn_mk_prop_pools(memb_func_size_);\n\tnrn_bbcore_write_ = (bbcore_write_t*)ecalloc(memb_func_size_, sizeof(bbcore_write_t));\n\tnrn_nmodl_text_ = (const char**)ecalloc(memb_func_size_, sizeof(const char*));\n\tnrn_nmodl_filename_ = (const char**)ecalloc(memb_func_size_, sizeof(const char*));\n\t\n#if KEEP_NSEG_PARM\n\t{extern int keep_nseg_parm_; keep_nseg_parm_ = 1; }\n#endif\n#if FISHER\n\t/* get login_name from 'LOGNAME' */\n\tstrcpy(login_name, getenv(\"LOGNAME\"));\n\t\n\tif (getenv(\"CAT_PIPE\")) {\n\t    pipe_filter = \"cat\";   /* preferred for emacs environment */\n\t} else {\n\t    pipe_filter = \"more\";  /* preferred for xterm environment */\n\t}\n#endif\n\n\tsection_list = hoc_l_newlist();\n\t\n\tCHECK(\"v\");\n\ts = hoc_install(\"v\", RANGEVAR, 0.0, &hoc_symlist);\n\ts->u.rng.type = VINDEX;\n\n\tCHECK(\"i_membrane_\");\n\ts = hoc_install(\"i_membrane_\", RANGEVAR, 0.0, &hoc_symlist);\n\ts->u.rng.type = IMEMFAST;\n\t\n\tfor (i = 0; usrprop[i].name; i++) {\n\t\tCHECK(usrprop[i].name);\n\t\ts = hoc_install(usrprop[i].name, UNDEF, 0.0, &hoc_symlist);\n\t\ts->type = VAR;\n\t\ts->subtype = USERPROPERTY;\n\t\ts->u.rng.type = usrprop[i].type;\n\t\ts->u.rng.index = usrprop[i].index;\n\t}\n\tSectionList_reg();\n\tSectionRef_reg();\n\tregister_mech(morph_mech, morph_alloc, (Pvmi)0, (Pvmi)0, (Pvmi)0, (Pvmi)0, -1, 0);\n\thoc_register_prop_size(MORPHOLOGY, 1, 0);\n\tfor (m = mechanism; *m; m++) {\n\t\t(*m)();\n\t}\n#if !MAC && !defined(WIN32)\n\tmodl_reg();\n#endif\n\thoc_register_limits(0, _hoc_parm_limits);\n\thoc_register_units(0, _hoc_parm_units);\n#if defined(WIN32) || defined(NRNMECH_DLL_STYLE)\n\t/* use the default if it exists (and not a binary special) */\n\tif (!nrn_mech_dll && !nrn_noauto_dlopen_nrnmech) {\n\t\tFILE* ff = fopen(DLL_DEFAULT_FNAME, \"r\");\n\t\tif (ff) {\n\t\t\tfclose(ff);\n\t\t\tnrn_mech_dll = DLL_DEFAULT_FNAME;\n\t\t}\n\t}\n\tif (nrn_mech_dll) {\n\t\tchar *cp1, *cp2;\n\t\thoc_default_dll_loaded_ = 1.;\n#if defined(WIN32)\n/* Sometimes (windows 10 and launch recent enthought canopy) it seems that\nmswin_load_dll fails if the filename is not a full path to nrnmech.dll\n*/\nif (strcmp(nrn_mech_dll, \"nrnmech.dll\") == 0) {\n  char buf[5100];\n  char* retval = getcwd(buf, 4096);\n  if (retval) {\n    strncat(buf, \"\\\\\", 100);\n    strncat(buf, nrn_mech_dll, 100);\n    mswin_load_dll(buf);\n  }\n}else{\n#endif /*WIN32*/\n\t\tfor (cp1 = nrn_mech_dll; *cp1; cp1 = cp2) {\n\t\t\tfor (cp2 = cp1; *cp2; ++cp2) {\n\t\t\t\tif (*cp2 == ';') {\n\t\t\t\t\t*cp2 = '\\0';\n\t\t\t\t\t++cp2;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tmswin_load_dll(cp1);\n\t\t}\n#if defined(WIN32)\n}\n#endif /*WIN32*/\n\t}\n#endif /* WIN32 || NRNMECH_DLL_STYLE */\n\ts = hoc_lookup(\"section_owner\");\n\ts->type = OBJECTFUNC;\n\n\t/* verify that all ions have a defined CHARGE */\n\tnrn_verify_ion_charge_defined();\n}\n\nvoid initnrn(void) {\n\tsecondorder = DEF_secondorder;\t/* >0 means crank-nicolson. 2 means currents\n\t\t\t\t   adjusted to t+dt/2 */\n\tt = 0;\t\t/* msec */\n\tdt = DEF_dt;\t/* msec */\n\tclamp_resist = DEF_clamp_resist;\t/*megohm*/\n\tcelsius = DEF_celsius;\t/* degrees celsius */\n\thoc_retpushx(1.);\n}\n\nstatic int pointtype = 1; /* starts at 1 since 0 means not point in pnt_map*/\nint n_memb_func;\n\n/* if vectorized then thread_data_size added to it */\nvoid nrn_register_mech_common(\n\tconst char **m,\n\tPvmp alloc,\n\tPvmi cur,\n\tPvmi jacob,\n\tPvmi stat,\n\tPvmi initialize,\n\tint nrnpointerindex, /* if -1 then there are none */\n\tint vectorized\n){\n\tstatic int type = 2;\t/* 0 unused, 1 for cable section */\n\tint j, k, modltype, pindx, modltypemax;\n\tSymbol *s;\n\tconst char **m2;\n\n\tnrn_load_name_check(m[1]);\n\n\tif (type >= memb_func_size_) {\n\t\tmemb_func_size_ += 20;\n\t\tmemb_func = (Memb_func*)erealloc(memb_func, memb_func_size_*sizeof(Memb_func));\n\t\tmemb_list = (Memb_list*)erealloc(memb_list, memb_func_size_*sizeof(Memb_list));\n\t\tpointsym = (Symbol**)erealloc(pointsym, memb_func_size_*sizeof(Symbol*));\n\t\tpoint_process = (Point_process**)erealloc(point_process, memb_func_size_*sizeof(Point_process*));\n\t\tpnt_map = (char*)erealloc(pnt_map, memb_func_size_*sizeof(char));\n\t\tnrn_pnt_template_ = (Template**)erealloc(nrn_pnt_template_, memb_func_size_*sizeof(Template*));\n\t\tpnt_receive = (pnt_receive_t*)erealloc(pnt_receive, memb_func_size_*sizeof(pnt_receive_t));\n\t\tpnt_receive_init = (pnt_receive_init_t*)erealloc(pnt_receive_init, memb_func_size_*sizeof(pnt_receive_init_t));\n\t\tpnt_receive_size = (short*)erealloc(pnt_receive_size, memb_func_size_*sizeof(short));\n\t\tnrn_is_artificial_ = (short*)erealloc(nrn_is_artificial_, memb_func_size_*sizeof(short));\n\t\tnrn_artcell_qindex_ = (short*)erealloc(nrn_artcell_qindex_, memb_func_size_*sizeof(short));\n\t\tnrn_prop_param_size_ = (int*)erealloc(nrn_prop_param_size_, memb_func_size_*sizeof(int));\n\t\tnrn_prop_dparam_size_ = (int*)erealloc(nrn_prop_dparam_size_, memb_func_size_*sizeof(int));\n\t\tnrn_dparam_ptr_start_ = (int*)erealloc(nrn_dparam_ptr_start_, memb_func_size_*sizeof(int));\n\t\tnrn_dparam_ptr_end_ = (int*)erealloc(nrn_dparam_ptr_end_, memb_func_size_*sizeof(int));\n\t\tmemb_order_ = (short*)erealloc(memb_order_, memb_func_size_*sizeof(short));\n\t\tnrn_bbcore_write_ = (bbcore_write_t*)erealloc(nrn_bbcore_write_, memb_func_size_*sizeof(bbcore_write_t));\n\t\tnrn_nmodl_text_ = (const char**)erealloc(nrn_nmodl_text_, memb_func_size_*sizeof(const char*));\n\t\tnrn_nmodl_filename_ = (const char**)erealloc(nrn_nmodl_filename_, memb_func_size_*sizeof(const char*));\n\t\tfor (j=memb_func_size_ - 20; j < memb_func_size_; ++j) {\n\t\t\tpnt_map[j] = 0;\n\t\t\tpoint_process[j] = (Point_process*)0;\n\t\t\tpointsym[j] = (Symbol*)0;\n\t\t\tnrn_pnt_template_[j] = (Template*)0;\n\t\t\tpnt_receive[j] = (pnt_receive_t)0;\n\t\t\tpnt_receive_init[j] = (pnt_receive_init_t)0;\n\t\t\tpnt_receive_size[j] = 0;\n\t\t\tnrn_is_artificial_[j] = 0;\n\t\t\tnrn_artcell_qindex_[j] = 0;\n\t\t\tmemb_order_[j] = 0;\n\t\t\tnrn_bbcore_write_[j] = (bbcore_write_t)0;\n\t\t\tnrn_nmodl_text_[j] = (const char*)0;\n\t\t\tnrn_nmodl_filename_[j] = (const char*) 0;\n\t\t}\n\t\tnrn_mk_prop_pools(memb_func_size_);\n\t}\n\n\tnrn_prop_param_size_[type] = 0; /* fill in later */\n\tnrn_prop_dparam_size_[type] = 0; /* fill in later */\n\tnrn_dparam_ptr_start_[type] = 0; /* fill in later */\n\tnrn_dparam_ptr_end_[type] = 0; /* fill in later */\n\tmemb_func[type].current = cur;\n\tmemb_func[type].jacob = jacob;\n\tmemb_func[type].alloc = alloc;\n\tmemb_func[type].state = stat;\n\tmemb_func[type].initialize = initialize;\n\tmemb_func[type].destructor = (void*)0;\n#if VECTORIZE\n\tmemb_func[type].vectorized = vectorized ? 1:0;\n\tmemb_func[type].thread_size_ = vectorized ? (vectorized - 1) : 0;\n\tmemb_func[type].thread_mem_init_ = (void*)0;\n\tmemb_func[type].thread_cleanup_ = (void*)0;\n\tmemb_func[type].thread_table_check_ = (void*)0;\n\tmemb_func[type]._update_ion_pointers = (void*)0;\n\tmemb_func[type].is_point = 0;\n\tmemb_func[type].hoc_mech = (void*)0;\n\tmemb_func[type].setdata_ = (void*)0;\n\tmemb_func[type].dparam_semantics = (int*)0;\n\tmemb_list[type].nodecount = 0;\n\tmemb_list[type]._thread = (Datum*)0;\n\tmemb_order_[type] = type;\n#endif\n#if CVODE\n\tmemb_func[type].ode_count = (void*)0;\n\tmemb_func[type].ode_map = (void*)0;\n\tmemb_func[type].ode_spec = (void*)0;\n\tmemb_func[type].ode_matsol = (void*)0;\n\tmemb_func[type].ode_synonym = (void*)0;\n\tmemb_func[type].singchan_ = (void*)0;\n#endif\n\t/* as of 5.2 nmodl translates so that the version string\n\t   is the first string in m. This allows the neuron application\n\t   to determine if nmodl c files are compatible with this version\n\t   Note that internal mechanisms have a version of \"0\" and are\n\t   by nature consistent.\n\t*/\n\t\n/*printf(\"%s %s\\n\", m[0], m[1]);*/\n\tif (strcmp(m[0], \"0\") == 0) { /* valid by nature */\n\t}else if (m[0][0] > '9') { /* must be 5.1 or before */\nFprintf(stderr, \"Mechanism %s needs to be re-translated.\\n\\\nIt's pre version 6.0 \\\"c\\\" code is incompatible with this neuron version.\\n\", m[0]);\n\t\tif (nrn_load_dll_recover_error()) {\n\t\t\thoc_execerror(\"Mechanism needs to be retranslated:\", m[0]);\n\t\t}else{\n\t\t\tnrn_exit(1);\n\t\t}\n\t}else if (strcmp(m[0], nmodl_version_) != 0){\nFprintf(stderr, \"Mechanism %s needs to be re-translated.\\n\\\nIt's version %s \\\"c\\\" code is incompatible with this neuron version.\\n\",\nm[1], m[0]);\n\t\tif (nrn_load_dll_recover_error()) {\n\t\t\thoc_execerror(\"Mechanism needs to be retranslated:\", m[1]);\n\t\t}else{\n\t\t\tnrn_exit(1);\n\t\t}\n\t}\n\n\ts = hoc_install(m[1], MECHANISM, 0.0, &hoc_symlist);\n\ts->subtype = type;\n\tmemb_func[type].sym = s;\n/*\tprintf(\"%s type=%d\\n\", s->name, type);*/\n\tm2 = m + 2;\n\tif (nrnpointerindex == -1) {\n\t\tmodltypemax = STATE;\n\t} else {\n\t\tmodltypemax = NRNPOINTER;\n\t}\n\tfor (k=0, j=0, modltype=nrnocCONST; modltype<=modltypemax; modltype++, j++){\n\t\t/*EMPTY*/\n\t\tfor (; m2[j]; j++, k++) {\n\t\t\t;\n\t\t}\n\t}\n\ts->s_varn = k;\n\ts->u.ppsym = (Symbol **) emalloc((unsigned)(j*sizeof(Symbol *)));\n/* this is set up for the possiblility of overloading range variables.\nWe are currently not allowing this. Hence the #if.\nIf never overloaded then no reason for list of symbols for each mechanism.\n*/\n/* the indexing is confusing because k refers to index in the range indx list\nand j refers to index in mechanism list which has 0 elements to separate\nnrnocCONST, DEPENDENT, and STATE */\n/* variable pointers added on at end, if they exist */\n/* allowing range variable arrays. Must extract dimension info from name[%d]*/\n/* pindx refers to index into the p-array */\n\tpindx = 0;\n\tfor (j=0, k=0, modltype=nrnocCONST; modltype <= modltypemax; modltype++, j++) {\n\t\tfor (; m2[j]; j++, k++) {\n\t\t\tSymbol *s2;\n\t\t\tchar buf[200], *cp; int indx; unsigned nsub=0;\n\t\t\tstrcpy(buf, m2[j]); /* not allowed to change constant string */\n\t\t\tindx = 1;\n\t\t\tcp = strchr(buf, '[');\n\t\t\tif (cp) {\n#if EXTRACELLULAR\n\t\t\t\tif (cp[1] == 'N') {\n\t\t\t\t\tindx = nlayer;\n\t\t\t\t}else\n#endif\n\t\t\t\t{\n\t\t\t\t\tsscanf(cp+1, \"%d\", &indx);\n\t\t\t\t}\n\t\t\t\tnsub = 1;\n\t\t\t\t*cp = '\\0';\n\t\t\t}\n\t\t\t/*SUPPRESS 624*/\n\t\t\tif ((s2 = hoc_lookup(buf))) {\n#if 0\n\t\t\t\tif (s2->subtype != RANGEVAR) {\n\t\t\t\t\tIGNORE(fprintf(stderr, CHKmes,\n\t\t\t\t\tbuf));\n\t\t\t\t}\n#else\nIGNORE(fprintf(stderr, CHKmes, buf));\n#endif\n\t\t\t}else{\n\t\t\t  s2 = hoc_install(buf, RANGEVAR, 0.0, &hoc_symlist);\n\t\t\t\ts2->subtype = modltype;\n\t\t\t\ts2->u.rng.type = type;\n\t\t\t\ts2->public = 1;\n\t\t\t\tif (modltype == NRNPOINTER) { /* not in p array */\n\t\t\t\t\ts2->u.rng.index = nrnpointerindex;\n\t\t\t\t} else {\n\t\t\t\t\ts2->u.rng.index = pindx;\n\t\t\t\t}\n\t\t\t  if (nsub) {\n\t\t\t\ts2->arayinfo = (Arrayinfo *) emalloc(\n\t\t\t\t  sizeof(Arrayinfo) + nsub * sizeof(int));\n\t\t\t\ts2->arayinfo->a_varn = (unsigned *)0;\n\t\t\t\ts2->arayinfo->refcount = 1;\n\t\t\t\ts2->arayinfo->nsub = nsub;\n\t\t\t\ts2->arayinfo->sub[0] = indx;\n\t\t\t  }\n\t\t\t  if (modltype == NRNPOINTER) {\n\t\t\t\tif (nrn_dparam_ptr_end_[type] == 0) {\n\t\t\t\t\tnrn_dparam_ptr_start_[type] = nrnpointerindex;\n\t\t\t\t}\n\t\t\t\tnrnpointerindex += indx;\n\t\t\t\tnrn_dparam_ptr_end_[type] = nrnpointerindex;\n\t\t\t  }else {\n\t\t\t\tpindx += indx;\n\t\t\t  }\n\t\t\t}\n\t\t\ts->u.ppsym[k] = s2;\n\t\t}\n\t}\n\t++type;\n\tn_memb_func = type;\n}\n\nvoid register_mech(\n\tconst char **m,\n\tPvmp alloc,\n\tPvmi cur,\n\tPvmi jacob,\n\tPvmi stat,\n\tPvmi initialize,\n\tint nrnpointerindex, /* if -1 then there are none */\n\tint vectorized\n){\n\tint type = n_memb_func;\n\tnrn_register_mech_common(m, alloc, cur, jacob, stat, initialize,\n\t\tnrnpointerindex, vectorized);\n\tif (nrnpy_reg_mech_p_) {\n\t\t(*nrnpy_reg_mech_p_)(type);\n\t}\n}\n\nvoid nrn_writes_conc(int type, int unused) {\n\tstatic int lastion = EXTRACELL+1;\n\tint i;\n\tfor (i=n_memb_func - 2; i >= lastion; --i) {\n\t\tmemb_order_[i+1] = memb_order_[i];\n\t}\n\tmemb_order_[lastion] = type;\n#if 0\n\tprintf(\"%s reordered from %d to %d\\n\", memb_func[type].sym->name, type, lastion);\n#endif\n\tif (nrn_is_ion(type)) {\n\t\t++lastion;\n\t}\n}\n\nvoid hoc_register_prop_size(int type, int psize, int dpsize) {\n\tnrn_prop_param_size_[type] = psize;\n\tnrn_prop_dparam_size_[type] = dpsize;\n\tif (memb_func[type].dparam_semantics) {\n\t\tfree(memb_func[type].dparam_semantics);\n\t\tmemb_func[type].dparam_semantics = (int*)0;\n\t}\n\tif (dpsize) {\n\t  memb_func[type].dparam_semantics = (int*)ecalloc(dpsize, sizeof(int));\n\t}\n}\nvoid hoc_register_dparam_semantics(int type, int ix, const char* name) {\n\t/* only interested in area, iontype, cvode_ieq,\n\t   netsend, pointer, pntproc, bbcorepointer, watch, diam,\n\t   fornetcon,\n\t   xx_ion and #xx_ion which will get\n\t   a semantics value of -1, -2, -3,\n\t   -4, -5, -6, -7, -8, -9, -10\n\t   type, and type+1000 respectively\n\t*/\n\tif (strcmp(name, \"area\") == 0) {\n\t\tmemb_func[type].dparam_semantics[ix] = -1;\n\t}else if (strcmp(name, \"iontype\") == 0) {\n\t\tmemb_func[type].dparam_semantics[ix] = -2;\n\t}else if (strcmp(name, \"cvodeieq\") == 0) {\n\t\tmemb_func[type].dparam_semantics[ix] = -3;\n\t}else if (strcmp(name, \"netsend\") == 0) {\n\t\tmemb_func[type].dparam_semantics[ix] = -4;\n\t}else if (strcmp(name, \"pointer\") == 0) {\n\t\tmemb_func[type].dparam_semantics[ix] = -5;\n\t}else if (strcmp(name, \"pntproc\") == 0) {\n\t\tmemb_func[type].dparam_semantics[ix] = -6;\n\t}else if (strcmp(name, \"bbcorepointer\") == 0) {\n\t\tmemb_func[type].dparam_semantics[ix] = -7;\n\t}else if (strcmp(name, \"watch\") == 0) {\n\t\tmemb_func[type].dparam_semantics[ix] = -8;\n\t}else if (strcmp(name, \"diam\") == 0) {\n\t\tmemb_func[type].dparam_semantics[ix] = -9;\n\t}else if (strcmp(name, \"fornetcon\") == 0) {\n\t\tmemb_func[type].dparam_semantics[ix] = -10;\n\t}else{\n\t\tint i = 0;\n\t\tif (name[0] == '#') { i = 1; }\n\t\tSymbol* s = hoc_lookup(name+i);\n\t\tif (s && s->type == MECHANISM) {\n\t\t\tmemb_func[type].dparam_semantics[ix] = s->subtype + i*1000;\n\t\t}else{\nfprintf(stderr, \"mechanism %s : unknown semantics for %s\\n\", memb_func[type].sym->name, name);\nassert(0);\n\t\t}\n\t}\n#if 0   \n\tprintf(\"dparam semantics %s ix=%d %s %d\\n\", memb_func[type].sym->name,\n\t  ix, name, memb_func[type].dparam_semantics[ix]);\n#endif\n}\n\n#if CVODE\nvoid hoc_register_cvode(\n\tint i,\n\tnrn_ode_count_t cnt,\n\tnrn_ode_map_t map,\n\tPvmi spec,\n\tPvmi matsol\n){\n\tmemb_func[i].ode_count = cnt;\n\tmemb_func[i].ode_map = map;\n\tmemb_func[i].ode_spec = spec;\n\tmemb_func[i].ode_matsol = matsol;\n}\nvoid hoc_register_synonym(int i, void (*syn)(int, double**, Datum**)){\n\tmemb_func[i].ode_synonym = syn;\n}\n#endif\n\nvoid register_destructor(Pvmp d) {\n\tmemb_func[n_memb_func - 1].destructor = d;\n}\n\nint point_reg_helper(Symbol* s2) {\n\tpointsym[pointtype] = s2;\n\ts2->public = 0;\n\tpnt_map[n_memb_func-1] = pointtype;\n\tmemb_func[n_memb_func-1].is_point = 1;\n\tif (nrnpy_reg_mech_p_) {\n\t\t(*nrnpy_reg_mech_p_)(n_memb_func-1);\n\t}\n\treturn pointtype++;\n}\n\nint point_register_mech(\n\tconst char **m,\n\tPvmp alloc,\n\tPvmi cur,\n\tPvmi jacob,\n\tPvmi stat,\n\tPvmi initialize,\n\tint nrnpointerindex,\n\tint vectorized,\n\n\tvoid* (*constructor)(Object*),\n\tvoid (*destructor)(void*),\n\tMember_func* fmember\n){\n\textern void steer_point_process();\n\tSymlist* sl;\n\tSymbol* s, *s2;\n\tvoid class2oc();\n\tnrn_load_name_check(m[1]);\n\tclass2oc(m[1], constructor, destructor, fmember, (void*)0, (void*)0, (void*)0);\n\ts = hoc_lookup(m[1]);\n\tsl = hoc_symlist;\n\thoc_symlist = s->u.template->symtable;\n\ts->u.template->steer = steer_point_process;\n\ts->u.template->is_point_ = pointtype;\n\tnrn_register_mech_common(m, alloc, cur, jacob, stat, initialize,\n\t\tnrnpointerindex, vectorized);\n\tnrn_pnt_template_[n_memb_func-1] = s->u.template;\n\ts2 = hoc_lookup(m[1]);\n\thoc_symlist = sl;\n\treturn point_reg_helper(s2);\n}\n\n/* some stuff from scopmath needed for built-in models */\n \n#if 0\ndouble* makevector(int nrows)\n{\n        double* v;\n        v = (double*)emalloc((unsigned)(nrows*sizeof(double)));\n        return v;\n}\n#endif\n  \nint _ninits;\nvoid _modl_cleanup(void){}\n\n#if 1\nvoid _modl_set_dt(double newdt) {\n\tdt = newdt;\n\tnrn_threads->_dt = newdt;\n}\nvoid _modl_set_dt_thread(double newdt, NrnThread* nt) {\n\tnt->_dt = newdt;\n}\ndouble _modl_get_dt_thread(NrnThread* nt) {\n\treturn nt->_dt;\n}\n#endif\t\n\nint nrn_pointing(double* pd) {\n\treturn pd ? 1 : 0;\n}\n\nint state_discon_flag_ = 0;\nvoid state_discontinuity(int i, double* pd, double d) {\n\tif (state_discon_allowed_ && state_discon_flag_ == 0) {\n\t\t*pd = d;\n/*printf(\"state_discontinuity t=%g pd=%lx d=%g\\n\", t, (long)pd, d);*/\n\t}\n}\n\nvoid hoc_register_limits(int type, HocParmLimits* limits)\n{\n\tint i;\n\tSymbol* sym;\n\tfor (i=0; limits[i].name; ++i) {\n\t\tsym = (Symbol*)0;\n\t\tif (type && memb_func[type].is_point) {\n\t\t\tSymbol* t;\n\t\t\tt = hoc_lookup(memb_func[type].sym->name);\n\t\t\tsym = hoc_table_lookup(\n\t\t\t\tlimits[i].name,\n\t\t\t\tt->u.template->symtable\n\t\t\t);\n\t\t}\n\t\tif (!sym) {\n\t\t\tsym = hoc_lookup(limits[i].name);\n\t\t}\n\t\thoc_symbol_limits(sym, limits[i].bnd[0], limits[i].bnd[1]);\n\t}\n}\n\nvoid hoc_register_units(int type, HocParmUnits* units)\n{\n\tint i;\n\tSymbol* sym;\n\tfor (i=0; units[i].name; ++i) {\n\t\tsym = (Symbol*)0;\n\t\tif (type && memb_func[type].is_point) {\n\t\t\tSymbol* t;\n\t\t\tt = hoc_lookup(memb_func[type].sym->name);\n\t\t\tsym = hoc_table_lookup(\n\t\t\t\tunits[i].name,\n\t\t\t\tt->u.template->symtable\n\t\t\t);\n\t\t}\n\t\tif (!sym) {\n\t\t\tsym = hoc_lookup(units[i].name);\n\t\t}\n\t\thoc_symbol_units(sym, units[i].units);\n\t}\n}\n\nvoid hoc_reg_ba(int mt, nrn_bamech_t f, int type)\n{\n\tBAMech* bam;\n\tswitch (type) { /* see bablk in src/nmodl/nocpout.c */\n\tcase 11: type = BEFORE_BREAKPOINT; break;\n\tcase 22: type = AFTER_SOLVE; break;\n\tcase 13: type = BEFORE_INITIAL; break;\n\tcase 23: type = AFTER_INITIAL; break;\n\tcase 14: type = BEFORE_STEP; break;\n\tdefault:\nprintf(\"before-after processing type %d for %s not implemented\\n\", type, memb_func[mt].sym->name);\n\t\tnrn_exit(1);\n\t}\n\tbam = (BAMech*)emalloc(sizeof(BAMech));\n\tbam->f = f;\n\tbam->type = mt;\n\tbam->next = bamech_[type];\n\tbamech_[type] = bam;\n}\n\nvoid _cvode_abstol(Symbol** s, double* tol, int i)\n{\n#if CVODE\n\tif (s && s[i]->extra) {\n\t\tdouble x;\n\t\tx = s[i]->extra->tolerance;\n\t\tif (x != 0) {\n\t\t\ttol[i] *= x;\n\t\t}\n\t}\n#endif\n}\n\nvoid hoc_register_tolerance(int type, HocStateTolerance* tol, Symbol*** stol)\n{\n#if CVODE\n\tint i;\n\tSymbol* sym;\n/*printf(\"register tolerance for %s\\n\", memb_func[type].sym->name);*/\n\tfor (i = 0; tol[i].name; ++i) {\n\t\tif (memb_func[type].is_point) {\n\t\t\tSymbol* t;\n\t\t\tt = hoc_lookup(memb_func[type].sym->name);\n\t\t\tsym = hoc_table_lookup(\n\t\t\t\ttol[i].name,\n\t\t\t\tt->u.template->symtable\n\t\t\t);\n\t\t}else{\n\t\t\tsym = hoc_lookup(tol[i].name);\n\t\t}\n\t\thoc_symbol_tolerance(sym, tol[i].tolerance);\n\t}\t\t\t\n\n\tif (memb_func[type].ode_count) {\n\t\tSymbol** psym, *msym, *vsym;\n\t\tdouble **pv;\n\t\tNode** pnode;\n\t\tProp* p;\n\t\textern Node** node_construct();\n\t\tint i, j, k, n, na, index=0;\n\t\t\n\t\tn = (*memb_func[type].ode_count)(type);\n\t\tif (n > 0) {\n\t\t\tpsym = (Symbol**)ecalloc(n, sizeof(Symbol*));\n\t\t\tpv = (double**)ecalloc(2*n, sizeof(double*));\n\t\t\tpnode = node_construct(1);\nprop_alloc(&(pnode[0]->prop), MORPHOLOGY, pnode[0]); /* in case we need diam */\np = prop_alloc(&(pnode[0]->prop), type, pnode[0]); /* this and any ions */\n(*memb_func[type].ode_map)(0, pv, pv+n, p->param, p->dparam, (double*)0, type);\n\t\t\tfor (i=0; i < n; ++i) {\n\t\t\t\tfor (p = pnode[0]->prop; p; p = p->next) {\n\t\t\t\t\tif (pv[i] >= p->param && pv[i] < (p->param + p->param_size)) {\n\t\t\t\t\t\tindex = pv[i] - p->param;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\t/* p is the prop and index is the index\n\t\t\t\t\tinto the p->param array */\n\t\t\t\tassert(p);\n\t\t\t\t/* need to find symbol for this */\n\t\t\t\tmsym = memb_func[p->type].sym;\n\t\t\t\tfor (j=0; j < msym->s_varn; ++j) {\n\t\t\t\t\tvsym = msym->u.ppsym[j];\n\t\t\t\t\tif (vsym->type == RANGEVAR && vsym->u.rng.index == index) {\n\t\t\t\t\t\tpsym[i] = vsym;\n/*printf(\"identified %s at index %d of %s\\n\", vsym->name, index, msym->name);*/\n\t\t\t\t\t\tif (ISARRAY(vsym)) {\n\t\t\t\t\t\t\tna = vsym->arayinfo->sub[0];\n\t\t\t\t\t\t\tfor (k=1; k < na; ++k) {\n\t\t\t\t\t\t\t\tpsym[++i] = vsym;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t} \n\t\t\t\t}\n\t\t\t\tassert (j < msym->s_varn);\n\t\t\t}\n\t\t\t\t\t\n\t\t\tnode_destruct(pnode, 1);\n\t\t\t*stol = psym;\n\t\t\tfree (pv);\n\t\t}\n\t}\n#endif\n}\n\nvoid _nrn_thread_reg(int i, int cons, void(*f)(Datum*)) {\n\tif (cons == 1) {\n\t\tmemb_func[i].thread_mem_init_ = f;\n\t}else if (cons == 0) {\n\t\tmemb_func[i].thread_cleanup_ = f;\n\t}else if (cons == 2) {\n\t\tmemb_func[i]._update_ion_pointers = f;\n\t}\n}\n\nvoid _nrn_thread_table_reg(int i, void(*f)(double*, Datum*, Datum*, void*, int)) {\n\tmemb_func[i].thread_table_check_ = f;\n}\n\nvoid _nrn_setdata_reg(int i, void(*call)(Prop*)) {\n\tmemb_func[i].setdata_ = call;\n}\n/* there is some question about the _extcall_thread variables, if any. */\ndouble nrn_call_mech_func(Symbol* s, int narg, Prop* p, int type) {\n\tdouble x;\t\n\textern double hoc_call_func(Symbol*, int);\n\tvoid (*call)(Prop*) = memb_func[type].setdata_;\n\tif (call) {\n\t\t(*call)(p);\n\t}\n\tx = hoc_call_func(s, narg);\n\treturn x;\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/src/nrnoc/osxdlfcn.c": "/*\nCopyright (c) 2002 Peter O'Gorman <ogorman@users.sourceforge.net>\n\nPermission is hereby granted, free of charge, to any person obtaining\na copy of this software and associated documentation files (the\n\"Software\"), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\n\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\nLIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\nOF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\nWITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n*/\n\n\n/* Just to prove that it isn't that hard to add Mac calls to your code :)\n   This works with pretty much everything, including kde3 xemacs and the gimp,\n   I'd guess that it'd work in at least 95% of cases, use this as your starting\n   point, rather than the mess that is dlfcn.c, assuming that your code does not\n   require ref counting or symbol lookups in dependent libraries\n*/\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <sys/types.h>\n#include <sys/stat.h>\n#include <stdarg.h>\n#include <limits.h>\n#include <mach-o/dyld.h>\n#include \"osxdlfcn.h\"\n\n#define ERR_STR_LEN 256\nstatic void *dlsymIntern(void *handle, const char *symbol);\nstatic const char *error(int setget, const char *str, ...);\n\n\n\n/* Set and get the error string for use by dlerror */\nstatic const char *error(int setget, const char *str, ...)\n{\n\tstatic char errstr[ERR_STR_LEN];\n\tstatic int err_filled = 0;\n\tconst char *retval;\n\tNSLinkEditErrors ler;\n\tint lerno;\n\tconst char *dylderrstr;\n\tconst char *file;\n\tva_list arg;\n\tif (setget <= 0)\n\t{\n\t\tva_start(arg, str);\n\t\tstrncpy(errstr, \"dlsimple: \", ERR_STR_LEN);\n\t\tvsnprintf(errstr + 10, ERR_STR_LEN - 10, str, arg);\n\t\tva_end(arg);\n\t/* We prefer to use the dyld error string if getset is 1*/\n\t\tif (setget == 0) {\n\t\t\tNSLinkEditError(&ler, &lerno, &file, &dylderrstr);\n\t\t\tfprintf(stderr,\"dyld: %s\\n\",dylderrstr);\n\t\t\tif (dylderrstr && strlen(dylderrstr))\n\t\t\t\tstrncpy(errstr,dylderrstr,ERR_STR_LEN);\n\t\t}\t\t\n\t\terr_filled = 1;\n\t\tretval = NULL;\n\t}\n\telse\n\t{\n\t\tif (!err_filled)\n\t\t\tretval = NULL;\n\t\telse\n\t\t\tretval = errstr;\n\t\terr_filled = 0;\n\t}\n\treturn retval;\n}\n\n/* dlopen */\nvoid *dlopen(const char *path, int mode)\n{\n\tvoid *module = 0;\n\tNSObjectFileImage ofi = 0;\n\tNSObjectFileImageReturnCode ofirc;\n\tstatic int (*make_private_module_public) (NSModule module) = 0;\n\tunsigned int flags =  NSLINKMODULE_OPTION_RETURN_ON_ERROR | NSLINKMODULE_OPTION_PRIVATE;\n\n\t/* If we got no path, the app wants the global namespace, use -1 as the marker\n\t   in this case */\n\tif (!path)\n\t\treturn (void *)-1;\n\n\t/* Create the object file image, works for things linked with the -bundle arg to ld */\n\tofirc = NSCreateObjectFileImageFromFile(path, &ofi);\n\tswitch (ofirc)\n\t{\n\t\tcase NSObjectFileImageSuccess:\n\t\t\t/* It was okay, so use NSLinkModule to link in the image */\n\t\t\tif (!(mode & RTLD_LAZY)) flags += NSLINKMODULE_OPTION_BINDNOW;\n\t\t\tmodule = NSLinkModule(ofi, path,flags);\n\t\t\t/* Don't forget to destroy the object file image, unless you like leaks */\n\t\t\tNSDestroyObjectFileImage(ofi);\n\t\t\t/* If the mode was global, then change the module, this avoids\n\t\t\t   multiply defined symbol errors to first load private then make\n\t\t\t   global. Silly, isn't it. */\n\t\t\tif ((mode & RTLD_GLOBAL))\n\t\t\t{\n\t\t\t  if (!make_private_module_public)\n\t\t\t  {\n\t\t\t    _dyld_func_lookup(\"__dyld_NSMakePrivateModulePublic\", \n\t\t\t\t(unsigned long *)&make_private_module_public);\n\t\t\t  }\n\t\t\t  make_private_module_public(module);\n\t\t\t}\n\t\t\tbreak;\n\t\tcase NSObjectFileImageInappropriateFile:\n\t\t\t/* It may have been a dynamic library rather than a bundle, try to load it */\n\t\t\tmodule = (void *)NSAddImage(path, NSADDIMAGE_OPTION_RETURN_ON_ERROR);\n\t\t\tbreak;\n\t\tcase NSObjectFileImageFailure:\n\t\t\terror(0,\"Object file setup failure :  \\\"%s\\\"\", path);\n\t\t\treturn 0;\n\t\tcase NSObjectFileImageArch:\n\t\t\terror(0,\"No object for this architecture :  \\\"%s\\\"\", path);\n\t\t\treturn 0;\n\t\tcase NSObjectFileImageFormat:\n\t\t\terror(0,\"Bad object file format :  \\\"%s\\\"\", path);\n\t\t\treturn 0;\n\t\tcase NSObjectFileImageAccess:\n\t\t\terror(0,\"Can't read object file :  \\\"%s\\\"\", path);\n\t\t\treturn 0;\t\t\n\t}\n\tif (!module)\n\t\terror(0, \"Can not open \\\"%s\\\"\", path);\n\treturn module;\n}\n\n/* dlsymIntern is used by dlsym to find the symbol */\nvoid *dlsymIntern(void *handle, const char *symbol)\n{\n\tNSSymbol *nssym = 0;\n\t/* If the handle is -1, if is the app global context */\n\tif (handle == (void *)-1)\n\t{\n\t\t/* Global context, use NSLookupAndBindSymbol */\n\t\tif (NSIsSymbolNameDefined(symbol))\n\t\t{\n\t\t\tnssym = NSLookupAndBindSymbol(symbol);\n\t\t}\n\n\t}\n\t/* Now see if the handle is a struch mach_header* or not, use NSLookupSymbol in image\n\t   for libraries, and NSLookupSymbolInModule for bundles */\n\telse\n\t{\n\t\t/* Check for both possible magic numbers depending on x86/ppc byte order */\n\t\tif ((((struct mach_header *)handle)->magic == MH_MAGIC) ||\n\t\t\t(((struct mach_header *)handle)->magic == MH_CIGAM))\n\t\t{\n\t\t\tif (NSIsSymbolNameDefinedInImage((struct mach_header *)handle, symbol))\n\t\t\t{\n\t\t\t\tnssym = NSLookupSymbolInImage((struct mach_header *)handle,\n\t\t\t\t\t\t\t\t\t\t\t  symbol,\n\t\t\t\t\t\t\t\t\t\t\t  NSLOOKUPSYMBOLINIMAGE_OPTION_BIND\n\t\t\t\t\t\t\t\t\t\t\t  | NSLOOKUPSYMBOLINIMAGE_OPTION_RETURN_ON_ERROR);\n\t\t\t}\n\n\t\t}\n\t\telse\n\t\t{\n\t\t\tnssym = NSLookupSymbolInModule(handle, symbol);\n\t\t}\n\t}\n\tif (!nssym)\n\t{\n\t\terror(0, \"Symbol \\\"%s\\\" Not found\", symbol);\n\t\treturn NULL;\n\t}\n\treturn NSAddressOfSymbol(nssym);\n}\n\nconst char *dlerror(void)\n{\n\treturn error(1, (char *)NULL);\n}\n\nint dlclose(void *handle)\n{\n\tif ((((struct mach_header *)handle)->magic == MH_MAGIC) ||\n\t\t(((struct mach_header *)handle)->magic == MH_CIGAM))\n\t{\n\t\terror(-1, \"Can't remove dynamic libraries on darwin\");\n\t\treturn 0;\n\t}\n\tif (!NSUnLinkModule(handle, 0))\n\t{\n\t\terror(0, \"unable to unlink module %s\", NSNameOfModule(handle));\n\t\treturn 1;\n\t}\n\treturn 0;\n}\n\n\n/* dlsym, prepend the underscore and call dlsymIntern */\nvoid *dlsym(void *handle, const char *symbol)\n{\n\tstatic char undersym[257];\t/* Saves calls to malloc(3) */\n\tint sym_len = strlen(symbol);\n\tvoid *value = NULL;\n\tchar *malloc_sym = NULL;\n\n\tif (sym_len < 256)\n\t{\n\t\tsnprintf(undersym, 256, \"_%s\", symbol);\n\t\tvalue = dlsymIntern(handle, undersym);\n\t}\n\telse\n\t{\n\t\tmalloc_sym = malloc(sym_len + 2);\n\t\tif (malloc_sym)\n\t\t{\n\t\t\tsprintf(malloc_sym, \"_%s\", symbol);\n\t\t\tvalue = dlsymIntern(handle, malloc_sym);\n\t\t\tfree(malloc_sym);\n\t\t}\n\t\telse\n\t\t{\n\t\t\terror(-1, \"Unable to allocate memory\");\n\t\t}\n\t}\n\treturn value;\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/src/nrniv/nrnpy.cpp": "#include <../../nrnconf.h>\n// For Linux and Max OS X,\n// Solve the problem of not knowing what version of Python the user has by\n// possibly deferring linking to libnrnpython.so to run time using the proper\n// Python interface\n\n#include <../nrnpython/nrnpython_config.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <InterViews/resource.h>\n#include \"nrnoc2iv.h\"\n#include \"classreg.h\"\n#include \"nonvintblock.h\"\n#include \"nrnmpi.h\"\n\nextern \"C\" {\nextern int nrn_nopython;\nextern int nrnpy_nositeflag;\nextern char* nrnpy_pyexe;\nextern int nrn_is_python_extension;\nint* nrnpy_site_problem_p;\nextern void (*p_nrnpython_start)(int);\nvoid nrnpython();\nstatic void (*p_nrnpython_real)();\nstatic void (*p_nrnpython_reg_real)();\nchar* hoc_back2forward(char* s);\nchar* hoc_forward2back(char* s);\n}\n\n// following is undefined or else has the value of sys.api_version\n// at time of configure (using the python first in the PATH).\n#if defined(NRNPYTHON_DYNAMICLOAD)\n\n#if defined(NRNCMAKE)\n// CMAKE installs libnrnpythonx.so not in <prefix>/x86_64/lib but <prefix>/lib\n#undef NRNHOSTCPU\n#define NRNHOSTCPU \".\"\n#endif\n\n#ifdef MINGW\n#define RTLD_NOW 0\n#define RTLD_GLOBAL 0\n#define RTLD_NOLOAD 0\nextern \"C\" {\nextern void* dlopen_noerr(const char* name, int mode);\n#define dlopen dlopen_noerr\nextern void* dlsym(void* handle, const char* name);\nextern int dlclose(void* handle);\nextern char* dlerror();\n}\n#else\n//#define _GNU_SOURCE\n#include <dlfcn.h>\n#endif\n\nextern \"C\" {\nextern char* neuron_home;\n}\n\n#if NRNPYTHON_DYNAMICLOAD >= 20 && NRNPYTHON_DYNAMICLOAD < 30\n\n#ifdef MINGW\nstatic const char* ver[] = {\"2.7\", 0};\n#else\nstatic const char* ver[] = {\"2.7\", \"2.6\", \"2.5\", 0};\n#endif // !MINGW\n\n#elif NRNPYTHON_DYNAMICLOAD >= 30\n\n#ifdef MINGW\nstatic const char* ver[] = {\"3.5\", 0};\n#else\nstatic const char* ver[] = {\"3.6\", \"3.5\", \"3.4\", 0};\n#endif // !MINGW\n\n#else //NRNPYTHON_DYNAMICLOAD < 20\n\nstatic const char* ver[] = {0};\n\n#endif //NRNPYTHON_DYNAMICLOAD < 20\n\nstatic int iver; // which python is loaded?\nstatic void* python_already_loaded();\nstatic void* load_python();\nstatic void load_nrnpython(int, const char*);\n#else //!defined(NRNPYTHON_DYNAMICLOAD)\nextern \"C\" {\nextern void nrnpython_start(int);\nextern void nrnpython_reg_real();\nextern void nrnpython_real();\n}\n#endif //defined(NRNPYTHON_DYNAMICLOAD)\n\nchar* nrnpy_pyhome;\n\nvoid nrnpython() {\n#if USE_PYTHON\n\tif (p_nrnpython_real) {\n\t\t(*p_nrnpython_real)();\n\t\treturn;\n\t}\n#endif\t\n\thoc_retpushx(0.);\n}\n\n// Stub class for when Python does not exist\nstatic void* p_cons(Object*) {\n\treturn 0;\n}\nstatic void p_destruct(void* v) {\n}\nstatic Member_func p_members[] = {0,0};\n\n#if NRNPYTHON_DYNAMICLOAD\nstatic char* nrnpy_pylib;\n\nstatic void siteprob(void) {\n\tif (nrnpy_site_problem_p && (*nrnpy_site_problem_p)) {\nprintf(\"Py_Initialize exited. PYTHONHOME probably needs to be set correctly.\\n\");\n\t\tif(nrnpy_pyhome) {\nprintf(\"The value of PYTHONHOME or our automatic guess based on the output of nrnpyenv.sh:\\n    export PYTHONHOME=%s\\ndid not work.\\n\", nrnpy_pyhome);\n\t\t}\nprintf(\"It will help to examine the output of:\\nnrnpyenv.sh\\n\\\nand set the indicated environment variables, or avoid python by adding\\n\\\nnopython: on\\n\\\nto %s/lib/nrn.defaults (or .nrn.defaults in your $HOME directory)\\n\",\nneuron_home);\n\t}\n}\n\nstatic void set_nrnpylib() {\n  nrnpy_pylib = getenv(\"NRN_PYLIB\");\n  nrnpy_pyhome = getenv(\"PYTHONHOME\");\n  if (nrnpy_pylib && nrnpy_pyhome) { return; }\n  // copy allows free of the copy if needed\n  if (nrnpy_pylib) { nrnpy_pylib = strdup(nrnpy_pylib); }\n  if (nrnpy_pyhome) { nrnpy_pyhome = strdup(nrnpy_pyhome); }\n\n  if (nrnmpi_myid_world == 0) {\n    int linesz = 1024 + (nrnpy_pyexe ? strlen(nrnpy_pyexe) : 0);\n    #ifdef MINGW\n    linesz += 3*strlen(neuron_home);\n    char* line = new char[linesz+1];\n    char* bnrnhome = strdup(neuron_home);\n    char* fnrnhome = strdup(neuron_home);\n    hoc_forward2back(bnrnhome);\n    hoc_back2forward(fnrnhome);\n    sprintf(line, \"%s\\\\mingw\\\\usr\\\\bin\\\\bash %s/bin/nrnpyenv.sh %s --NEURON_HOME=%s\",\n      bnrnhome,\n      fnrnhome,\n      (nrnpy_pyexe && strlen(nrnpy_pyexe) > 0) ? nrnpy_pyexe : \"\",\n      fnrnhome);\n    free(fnrnhome);\n    free(bnrnhome);\n    #else\n    char* line = new char[linesz+1];\n#if defined(NRNCMAKE)\n    sprintf(line, \"bash %s/../../bin/nrnpyenv.sh %s\",\n     neuron_home,\n#else\n    sprintf(line, \"bash %s/../../%s/bin/nrnpyenv.sh %s\",\n     neuron_home, NRNHOSTCPU,\n#endif\n      (nrnpy_pyexe && strlen(nrnpy_pyexe) > 0) ? nrnpy_pyexe : \"\");\n   #endif\n    FILE* p = popen(line, \"r\");\n    if (!p) {\n      printf(\"could not popen '%s'\\n\", line);\n    }else{\n      if (!fgets(line, linesz, p)) {\n        printf(\"failed: %s\\n\", line);\n      }\n      while(fgets(line, linesz, p)) {\n        char* cp;\n        // must get rid of beginning '\"' and trailing '\"\\n'\n        if (!nrnpy_pyhome && (cp = strstr(line, \"export PYTHONHOME=\"))) {\n          cp += 19;\n          cp[strlen(cp) - 2] = '\\0';\n          if (nrnpy_pyhome) { free(nrnpy_pyhome); }\n          nrnpy_pyhome = strdup(cp);\n        }else if (!nrnpy_pylib && (cp = strstr(line, \"export NRN_PYLIB=\"))) {\n          cp += 18;\n          cp[strlen(cp) - 2] = '\\0';\n          if (nrnpy_pylib) { free(nrnpy_pylib); }\n          nrnpy_pylib = strdup(cp);\n        }\n      }\n      pclose(p);\n    }\n    delete [] line;\n  }\n#if NRNMPI\n  if (nrnmpi_numprocs_world > 1) { // 0 broadcasts to everyone else.\n    nrnmpi_char_broadcast_world(&nrnpy_pylib, 0);\n    nrnmpi_char_broadcast_world(&nrnpy_pyhome, 0);\n  }\n#endif\n}\n\n#if 0\nstatic void set_pythonhome(void* handle){\n\tif (nrnmpi_myid == 0) {atexit(siteprob);}\n#ifdef MINGW\n#else\n\tif (getenv(\"PYTHONHOME\") || nrnpy_nositeflag) { return; }\n\tif (nrnpy_pyhome) {\n\t\tint res = setenv(\"PYTHONHOME\", nrnpy_pyhome, 1);\n\t\tassert(res == 0);\n\t\treturn;\n\t}\n\n\tDl_info dl_info;\n\tvoid* s = dlsym(handle, \"Py_Initialize\");\n        assert(s != NULL);\n\tint success = dladdr(s, &dl_info);\n\tif (success) {\n\t\t//printf(\"%s\\n\", dl_info.dli_fname);\n\t\tnrnpy_pyhome = strdup(dl_info.dli_fname);\n\t\tchar* p = nrnpy_pyhome;\n\t\tint n = strlen(p);\n\t\tint seen = 0;\n\t\tfor (int i = n-1; i > 0; --i) {\n\t\t\tif (p[i] == '/') {\n\t\t\t\tif (++seen >= 2) {\n\t\t\t\t\tp[i] = '\\0' ;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tint res = setenv(\"PYTHONHOME\", p, 1);\n\t\tassert(res == 0);\n\t}\n#endif\n}\n#endif // if 0\n#endif\n\nvoid nrnpython_reg() {\n\t//printf(\"nrnpython_reg in nrnpy.cpp\\n\");\n#if USE_PYTHON\n    if (nrn_nopython) {\n\tp_nrnpython_start = 0;\n\tp_nrnpython_real = 0;\n\tp_nrnpython_reg_real = 0;\n    }else{\n#if NRNPYTHON_DYNAMICLOAD\n\tvoid* handle = NULL;\n\n      if (!nrn_is_python_extension) {\n\t// As last resort (or for python3) load $NRN_PYLIB\n\tset_nrnpylib();\n\t//printf(\"nrnpy_pylib %s\\n\", nrnpy_pylib);\n\t//printf(\"nrnpy_pyhome %s\\n\", nrnpy_pyhome);\n\tif (nrnpy_pylib) {\n\t\thandle = dlopen(nrnpy_pylib, RTLD_NOW|RTLD_GLOBAL);\n\t\tif (!handle) {\n\t\t\tfprintf(stderr, \"Could not dlopen NRN_PYLIB: %s\\n\", nrnpy_pylib);\n\t\t\texit(1);\n\t\t}\n\t}\n\tif (!handle) { python_already_loaded();}\n\tif (!handle) { // embed python\n\t\thandle = load_python();\n\t}\n#if 0\n\t// No longer do this as Py_SetPythonHome is used\n\tif (handle) {\n\t\t// need to worry about the site.py problem\n\t\t// can fix with a proper PYTHONHOME but need to know\n\t\t// what path was used to load the python library.\n\t\tset_pythonhome(handle);\n\t}\n#endif\n      }else{\n        //printf(\"nrn_is_python_extension = %d\\n\", nrn_is_python_extension);\n      }\n\t// for some mysterious reason on max osx 10.12\n\t// (perhaps due to System Integrity Protection?) when python is\n\t// launched, python_already_loaded() returns a NULL handle unless\n\t// the full path to the dylib is used. Since we know it is loaded\n\t// in these circumstances, it is sufficient to go ahead and dlopen\n\t// the nrnpython interface library\n\tif (handle || nrn_is_python_extension) {\n\t\tload_nrnpython(nrn_is_python_extension, nrnpy_pylib);\n\t}\n#else\n\tp_nrnpython_start = nrnpython_start;\n\tp_nrnpython_real = nrnpython_real;\n\tp_nrnpython_reg_real = nrnpython_reg_real;\n#endif\n    }\n\tif (p_nrnpython_reg_real) {\n\t\t(*p_nrnpython_reg_real)();\n\t\tif (nrnpy_site_problem_p) {\n\t\t\t*nrnpy_site_problem_p = 1;\n\t\t}\n\t\treturn;\n\t}\n#endif\n\tclass2oc(\"PythonObject\", p_cons, p_destruct, p_members, NULL, NULL, NULL);\n}\n\n#if NRNPYTHON_DYNAMICLOAD // to end of file\n\n// important dlopen flags :\n// RTLD_NOLOAD returns NULL if not open, or handle if it is resident.\n\nstatic void* ver_dlo(int flag) {\n\tfor (int i = 0; ver[i]; ++i) {\n\t\tchar name[100];\n#ifdef MINGW\n\t\tsprintf(name, \"python%c%c.dll\", ver[i][0], ver[i][2]);\n#else\t\n#if DARWIN\n\t\tsprintf(name, \"libpython%s.dylib\", ver[i]);\n#else\n\t\tsprintf(name, \"libpython%s.so\", ver[i]);\n#endif\n#endif\n\t\tvoid* handle = dlopen(name, flag);\n\t\tiver = i;\n\t\tif (handle) {\n\t\t\treturn handle;\n\t\t}\n\t}\n\tiver = -1;\n\treturn NULL;\n}\n\nstatic void* python_already_loaded() {\n\tvoid* handle = ver_dlo(RTLD_NOW|RTLD_GLOBAL|RTLD_NOLOAD);\n\t//printf(\"python_already_loaded %d\\n\", iver);\n\treturn handle;\n}\n\nstatic void* load_python() {\n\tvoid* handle = ver_dlo(RTLD_NOW|RTLD_GLOBAL);\n\t//printf(\"load_python %d\\n\", iver);\n\treturn handle;\n}\n\nstatic void* load_sym(void* handle, const char* name) {\n\tvoid* p = dlsym(handle, name);\n\tif (!p) {\n\t\tprintf(\"Could not load %s\\n\", name);\n\t\texit(1);\n\t}\n\treturn p;\n}\n\nstatic void* load_nrnpython_helper(const char* npylib) {\n\tchar name[2048];\n#ifdef MINGW\n\tsprintf(name, \"%s.dll\", npylib);\n#else // !MINGW\n#if DARWIN\n#if defined(NRNCMAKE)\n\tsprintf(name, \"%s/../../lib/%s.dylib\", neuron_home, npylib);\n#else // !NRNCMAKE\n\tsprintf(name, \"%s/../../%s/lib/%s.dylib\", neuron_home, NRNHOSTCPU, npylib);\n#endif // NRNCMAKE\n#else // !DARWIN\n#if defined(NRNCMAKE)\n\tsprintf(name, \"%s/../../lib/%s.so\", neuron_home, npylib);\n#else // !NRNCMAKE\n\tsprintf(name, \"%s/../../%s/lib/%s.so\", neuron_home, NRNHOSTCPU, npylib);\n#endif // NRNCMAKE\n#endif // DARWIN\n#endif // MINGW\n\tvoid* handle = dlopen(name, RTLD_NOW);\n\treturn handle;\n}\n\nint digit_to_int(char ch) {\n  int d = ch - '0';\n  if ((unsigned) d < 10) {\n    return d;\n  }\n  d = ch - 'a';\n  if ((unsigned) d < 6) {\n    return d + 10;\n  }\n  d = ch - 'A';\n  if ((unsigned) d < 6) {\n    return d + 10;\n  }\n  return -1;\n}\n\nstatic int pylib2pyver10(const char* pylib) {\n  // check backwards for N.N or NN // obvious limitations\n  int n1 = -1; int n2 = -1;\n  for (const char* cp = pylib + strlen(pylib) -1 ; cp > pylib; --cp) {\n    if (isdigit(*cp)) {\n      if (n2 < 0) {\n        n2 = digit_to_int(*cp);\n      } else {\n        n1 = digit_to_int(*cp);\n        return n1*10 + n2;\n      }\n    }else if (*cp == '.') {\n      // skip\n    }else{ //\n      // start over\n      n2 = -1;\n    }\n  }\n  return 0;\n}\n\nstatic void load_nrnpython(int pyver10, const char* pylib) {\n\tvoid* handle = NULL;\n#if (defined(__MINGW32__) || (defined(USE_LIBNRNPYTHON_MAJORMINOR) && USE_LIBNRNPYTHON_MAJORMINOR == 1))\n\tchar name[256];\n\tint pv10 = pyver10;\n\tif (pyver10 < 1 && pylib) {\n\t\tpv10 = pylib2pyver10(pylib);\n\t}\n\tsprintf(name, \"libnrnpython%d\", pv10);\n\thandle = load_nrnpython_helper(name);\n\tif (!handle) {\n        printf(\"Could not load %s\\n\", name);\n        printf(\"pyver10=%d pylib=%s\\n\", pyver10, pylib ? pylib : \"NULL\");\n        return;\n\t}\n#else\n    handle = load_nrnpython_helper(\"libnrnpython3\");\n    if (!handle) {\n        handle = load_nrnpython_helper(\"libnrnpython2\");\n        if (!handle) {\n            printf(\"Could not load either libnrnpython3 or libnrnpython2\\n\");\n            printf(\"pyver10=%d pylib=%s\\n\", pyver10, pylib ? pylib : \"NULL\");\n            return;\n        }\n    }\n#endif\n\tp_nrnpython_start = (void(*)(int))load_sym(handle, \"nrnpython_start\");\n\tp_nrnpython_real = (void(*)())load_sym(handle, \"nrnpython_real\");\n\tp_nrnpython_reg_real = (void(*)())load_sym(handle, \"nrnpython_reg_real\");\n}\n\n#endif\n",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/src/nrniv/nrnbbcore_write.cpp": "#include <../../nrnconf.h>\n// A model built using NEURON is heavyweight in memory usage and that\n// prevents maximizing the number of cells that can be simulated on\n// a process. On the other hand, a tiny version of NEURON that contains\n// only the cache efficient structures, minimal memory usage arrays,\n// needed to do a simulation (no interpreter, hoc Objects, Section, etc.)\n// lacks the model building flexibility of NEURON.\n// Ideally, the only arrays needed for a tiny version simulation are those\n// enumerated in the NrnThread structure in src/nrnoc/multicore.h up to,\n// but not including, the Node** arrays. Also tiny versions of POINT_PROCESS,\n// PreSyn, NetCon, and SUFFIX mechanisms will be stripped down from\n// their full NEURON definitions and, it seems certain, many of the\n// double fields will be converted to some other, less memory using, types.\n// With this in mind, we envision that NEURON will incrementally construct\n// cache efficient whole cell structures which can be saved and read with\n// minimal processing into the tiny simulator. Note that this is a petabyte\n// level of data volume. Consider, for example, 128K cores each\n// preparing model data for several thousand cells using full NEURON where\n// there is not enough space for the simultaneous existence of\n// those several thousand cells --- but there is with the tiny version.\n\n// Several assumptions with regard to the nrnbbcore_read reader.\n// Since memory is filled with cells, whole cell\n// load balance should be adequate and so there is no provision for\n// multisplit. A process gets a list of the gid owned by that process\n// and allocates the needed\n// memory based on size variables for each gid, i.e.\n// number of nodes, number of instances of each mechanism type, and number\n// of NetCon instances. Also the offsets are calculated for where the\n// cell information is to reside in the cache efficient arrays.\n// The rest of the cell information is then copied\n// into memory with the proper offsets. Pointers to data, used in the old\n// NEURON world are converted to integer indices into a common data array.\n\n// A good deal of conceptual confusion resulted in earlier implementations\n// with regard to ordering of synapses and\n// artificial cells with and without gids. The ordering of the property\n// data for those is defined by the order in the NrnThread.tml list where\n// every Memb_list.data has an easily found index relative to its 'nodecount'.\n// (For artificial cells, since those are not ordered in a cache efficient\n// array, we get the index using int nrncore_art2index(double* param)\n// which looks up the index in a hash table. Earlier implementations\n// handled 'artificial cells without gids' specially which also\n// necessitated special handling of their NetCons and disallowed artificial\n// cells with gids. We now handle all artificial cells in a thread\n// in the same way as any other synapse (the assumption still holds that\n// any artificial cell without a gid in a thread can connect only to\n// targets in the same thread. Thus, a single NrnThread.synapses now contains\n// all synapses and all artificial cells belonging to that thread. All\n// the synapses and artificial cells are in NrnThread.tml order. So there\n// are no exceptions in filling Point_process pointers from the data indices\n// on the coreneuron side. PreSyn ordering is a bit more delicate.\n// From netpar.cpp, the gid2out_ hash table defines an output_gid\n// ordering and gives us all the PreSyn\n// associated with real and artificial cells having gids. But those are\n// randomly ordered and interleaved with 'no gid instances'\n// relative to the tml ordering.\n// Since the number of output PreSyn >= number of output_gid it makes sense\n// to order the PreSyn in the same way as defined by the tml ordering.\n// Thus, even though artificial cells with and without gids are mixed,\n// at least it is convenient to fill the PreSyn.psrc field.\n// Synapses are first but the artificial cells with and without gids are\n// mixed. The problem that needs to\n// be explicitly overcome is associating output gids with the proper PreSyn\n// and that can be done with a list parallel to the acell part of the\n// output_gid list that specifies the PreSyn list indices.\n// Note that allocation of large arrays allows considerable space savings\n// by eliminating overhead involved in allocation of many individual\n// instances.\n/*\nAssumptions regarding the scope of possible models.(Incomplete list)\nAll real cells have gids.\nArtificial cells without gids connect only to cells in the same thread.\nNo POINTER to data outside of NrnThread.\nNo POINTER to data in ARTIFICIAL_CELL (that data is not cache_efficient)\nnt->tml->pdata is not cache_efficient\n*/\n// See coreneuron/nrniv/nrn_setup.cpp for a description of\n// the file format written by this file.\n\n/*\nSupport direct transfer of model to dynamically loaded coreneuron library.\nTo do this we factored all major file writing components into a series\nof functions that return data that can be called from the coreneuron\nlibrary. The file writing functionality is kept by also calling those\nfunctions here as well.\nDirect transfer mode disables error checking with regard to every thread\nhaving a real cell with a gid. Of course real and artificial cells without\ngids do not have spike information in the output raster file. Trajectory\ncorrectness has not been validated for cells without gids.\n*/\n\n#include <stdio.h>\n#include <stdlib.h>\n\n// for idDirExist and makePath\n#include <ocfile.h>\n\n#include <nrnran123.h> // globalindex written to globals.dat\n#include <section.h>\n#include <parse.h>\n#include <nrnmpi.h>\n#include <netcon.h>\n#include <nrndae_c.h>\n#include <unistd.h>\n#include <algorithm>\n#include <nrnhash_alt.h>\n#include <nrnbbcore_write.h>\n#include <netcvode.h> // for nrnbbcore_vecplay_write\n#include <vrecitem.h> // for nrnbbcore_vecplay_write\n#include <nrnsection_mapping.h>\n#include <fstream>\n#include <sstream>\n\n#if defined(HAVE_DLFCN_H)\n#include <dlfcn.h>\n#endif\n\nextern NetCvode* net_cvode_instance;\n\nextern \"C\" { // to end of file\n\nextern void hoc_execerror(const char*, const char*);\nextern int* nrn_prop_param_size_;\nextern int* nrn_prop_dparam_size_;\nstatic int* bbcore_dparam_size; // cvodeieq not present\nextern char* pnt_map;\nextern short* nrn_is_artificial_;\nextern int nrn_is_ion(int type);\nextern double nrn_ion_charge(Symbol* sym);\nextern Symbol* hoc_lookup(const char*);\nextern int secondorder, diam_changed, v_structure_change, tree_changed;\n\n/* not NULL, need to write gap information */\nextern void (*nrnthread_v_transfer_)(NrnThread*);\nextern size_t nrnbbcore_gap_write(const char* path, int* group_ids);\n\n/* access the neuron.coreneuron pure python module */\nint (*nrnpy_nrncore_enable_value_p_)();\nchar* (*nrnpy_nrncore_arg_p_)(double tstop);\n\ntypedef void (*bbcore_write_t)(double*, int*, int*, int*, double*, Datum*, Datum*, NrnThread*);\nextern bbcore_write_t* nrn_bbcore_write_;\n\nstatic CellGroup* cellgroups_;\nstatic CellGroup* mk_cellgroups(); // gid, PreSyn, NetCon, Point_process relation.\nstatic void datumtransform(CellGroup*); // Datum.pval to int\nstatic void datumindex_fill(int, CellGroup&, DatumIndices&, Memb_list*); //helper\nstatic void write_byteswap1(const char* fname);\nstatic void write_memb_mech_types(const char* fname);\nstatic void write_memb_mech_types_direct(std::ostream& s);\nstatic void write_globals(const char* fname);\nstatic int get_global_int_item(const char* name);\nstatic void* get_global_dbl_item(void* p, const char* & name, int& size, double*& val);\nstatic void write_nrnthread(const char* fname, NrnThread& nt, CellGroup& cg);\n\nstatic void nrnthread_group_ids(int* groupids);\nstatic int nrnthread_dat1(int tid, int& n_presyn, int& n_netcon,\n  int*& output_gid, int*& netcon_srcgid);\nstatic int nrnthread_dat2_1(int tid, int& ngid, int& n_real_gid, int& nnode, int& ndiam,\n  int& nmech, int*& tml_index, int*& ml_nodecount, int& nidata,\n  int& nvdata, int& nweight);\nstatic int nrnthread_dat2_2(int tid, int*& v_parent_index, double*& a, double*& b,\n  double*& area, double*& v, double*& diamvec);\nstatic int nrnthread_dat2_mech(int tid, size_t i, int dsz_inst, int*& nodeindices,\n  double*& data, int*& pdata);\nstatic int nrnthread_dat2_3(int tid, int nweight, int*& output_vindex, double*& output_threshold,\n  int*& netcon_pnttype, int*& netcon_pntindex, double*& weights, double*& delays);\nstatic int nrnthread_dat2_corepointer(int tid, int& n);\nstatic int nrnthread_dat2_corepointer_mech(int tid, int type,\n  int& icnt, int& dcnt, int*& iarray, double*& darray);\nstatic int nrnthread_dat2_vecplay(int tid, int& n);\nstatic int nrnthread_dat2_vecplay_inst(int tid, int i, int& vptype, int& mtype,\n  int& ix, int& sz, double*& yvec, double*& tvec);\n\nstatic void write_nrnthread_task(const char*, CellGroup* cgs);\nstatic int* datum2int(int type, Memb_list* ml, NrnThread& nt, CellGroup& cg, DatumIndices& di, int ml_vdata_offset);\nstatic void setup_nrn_has_net_event();\nstatic int chkpnt;\n\n// Up to now all the artificial cells have been left out of the processing.\n// Since most processing is in the context of iteration over nt.tml it\n// might be easiest to transform the loops using a\n// copy of nt.tml with artificial cell types belonging to nt at the end.\n// Treat these artificial cell memb_list as much as possible like the others.\n// The only issue is that data for artificial cells is not in cache order\n// (after all there is no BREAKPOINT or SOLVE block for ARTIFICIAL_CELLs)\n// so we assume there will be no POINTER usage into that data.\n// Also, note that ml.nodecount for artificial cell does not refer to\n// a list of voltage nodes but just to the count of instances.\nstatic void mk_tml_with_art(void); // set up MlWithArt CellGroup.mlwithart\n\ndeclareNrnHash(PVoid2Int, void*, int)\nimplementNrnHash(PVoid2Int, void*, int)\nPVoid2Int* artdata2index_;\n\n/** mapping information */\nstatic NrnMappingInfo mapinfo;\n\n// to avoid incompatible dataset between neuron and coreneuron\n// add version string to the dataset files\nconst char *bbcore_write_version = \"1.2\";\n\n// direct transfer or via files? The latter makes use of group_gid for\n// filename construction.\nstatic bool corenrn_direct;\n\nstatic size_t part1();\nstatic void part2(const char*);\n\n// prerequisites for a NEURON model to be transferred to CoreNEURON.\nstatic void model_ready() {\n  // Do the model type checks first as some of them prevent the success\n  // of cvode.cache_efficient(1) and the error message associated with\n  // !use_cachevec would be misleading. \n  if (!nrndae_list_is_empty()) {\n    hoc_execerror(\"CoreNEURON cannot simulate a model that contains extra LinearMechanism or RxD equations\", NULL);\n  }\n  if (nrn_threads[0]._ecell_memb_list) {\n    hoc_execerror(\"CoreNEURON cannot simulate a model that contains the extracellular mechanism\", NULL);\n  }\n  if (corenrn_direct) {\n    if (cvode_active_) {\n      hoc_execerror(\"CoreNEURON can only use fixed step method.\", NULL);\n    }\n  }\n\n  if (!use_cachevec) {\n    hoc_execerror(\"NEURON model for CoreNEURON requires cvode.cache_efficient(1)\", NULL);\n  }\n  if (tree_changed || v_structure_change || diam_changed) {\n    hoc_execerror(\"NEURON model internal structures for CoreNEURON are out of date. Make sure call to finitialize(...) is after cvode.cache_efficient(1))\", NULL);\n  }\n}\n\n// accessible from ParallelContext.total_bytes()\nsize_t nrnbbcore_write() {\n  corenrn_direct = false;\n  model_ready();\n  char fname[1024];\n  std::string path(\".\");\n  if (ifarg(1)) {\n    path = hoc_gargstr(1);\n    if (nrnmpi_myid == 0) {\n      if (!isDirExist(path)) {\n        if (!makePath(path)) {\n          hoc_execerror(path.c_str(), \"directory did not exist and makePath for it failed\");\n        }\n      }\n    }\n#ifdef NRNMPI\n    nrnmpi_barrier();\n#endif\n  }\n\n  size_t rankbytes = part1(); // can arrange to be just before part2\n\n  nrn_assert(snprintf(fname, 1024, \"%s/%s\", path.c_str(), \"byteswap1.dat\") < 1024);\n  write_byteswap1(fname);\n\n  nrn_assert(snprintf(fname, 1024, \"%s/%s\", path.c_str(), \"bbcore_mech.dat\") < 1024);\n  write_memb_mech_types(fname);\n\n  nrn_assert(snprintf(fname, 1024, \"%s/%s\", path.c_str(), \"globals.dat\") < 1024);\n  write_globals(fname);\n\n  part2(path.c_str());\n  return rankbytes;\n}\n\nstatic size_t part1() {\n  size_t rankbytes = 0;\n  size_t nbytes;\n  NrnThread* nt;\n  NrnThreadMembList* tml;\n  if (!bbcore_dparam_size) {\n    bbcore_dparam_size = new int[n_memb_func];\n  }\n  for (int i=0; i < n_memb_func; ++i) {\n    int sz = nrn_prop_dparam_size_[i];\n    bbcore_dparam_size[i] = sz;\n    Memb_func* mf = memb_func + i;\n    if (mf && mf->dparam_semantics && sz && mf->dparam_semantics[sz-1] == -3) {\n        // cvode_ieq in NEURON but not CoreNEURON\n        bbcore_dparam_size[i] = sz - 1;\n    }\n  }\n  setup_nrn_has_net_event();\n  cellgroups_ = new CellGroup[nrn_nthread]; // here because following needs mlwithart\n  mk_tml_with_art();\n\n  FOR_THREADS(nt) {\n    size_t threadbytes = 0;\n    size_t npnt = 0;\n    size_t nart = 0;\n    int ith = nt->id;\n    //printf(\"rank %d thread %d\\n\", nrnmpi_myid, ith);\n    //printf(\"  ncell=%d nnode=%d\\n\", nt->ncell, nt->end);\n    //v_parent_index, _actual_a, _actual_b, _actual_area\n    nbytes = nt->end * (1*sizeof(int) + 3*sizeof(double));\n    threadbytes += nbytes;\n\n    int mechcnt = 0;\n    size_t mechcnt_instances = 0;\n    MlWithArt& mla = cellgroups_[ith].mlwithart;\n    for (size_t i = 0; i < mla.size(); ++i) {\n      int type = mla[i].first;\n      Memb_list* ml = mla[i].second;\n      ++mechcnt;\n      mechcnt_instances += ml->nodecount;\n      npnt += (memb_func[type].is_point ? ml->nodecount : 0);\n      int psize = nrn_prop_param_size_[type];\n      int dpsize = nrn_prop_dparam_size_[type]; // includes cvodeieq if present\n      //printf(\"%d %s ispnt %d  cnt %d  psize %d  dpsize %d\\n\",tml->index, memb_func[type].sym->name,\n      //memb_func[type].is_point, ml->nodecount, psize, dpsize);\n      // nodeindices, data, pdata + pnt with prop\n      int notart = nrn_is_artificial_[type] ? 0 : 1;\n      if (nrn_is_artificial_[type]) {\n        nart += ml->nodecount;\n      }\n      nbytes = ml->nodecount * (notart*sizeof(int) + 1*sizeof(double*) +\n        1*sizeof(Datum*) + psize*sizeof(double) + dpsize*sizeof(Datum));\n      threadbytes += nbytes;\n    }\n    nbytes += npnt * (sizeof(Point_process) + sizeof(Prop));\n    //printf(\"  mech in use %d  Point instances %ld  artcells %ld  total instances %ld\\n\",\n    //mechcnt, npnt, nart, mechcnt_instances);\n    //printf(\"  thread bytes %ld\\n\", threadbytes);\n    rankbytes += threadbytes;\n  }\n  \n  rankbytes += nrncore_netpar_bytes();\n  //printf(\"%d bytes %ld\\n\", nrnmpi_myid, rankbytes);\n  CellGroup* cgs = mk_cellgroups();\n\n  datumtransform(cgs);\n  return rankbytes;\n}\n\nstatic void part2_clean() {\n  if (artdata2index_) {\n    delete artdata2index_;\n    artdata2index_ = NULL;\n  }\n  delete [] cellgroups_;\n  cellgroups_ = NULL;\n}\n\nstatic void part2(const char* path) {\n  CellGroup* cgs = cellgroups_;\n  for (int i=0; i < nrn_nthread; ++i) {\n    chkpnt = 0;\n    write_nrnthread(path, nrn_threads[i], cgs[i]);\n  }\n\n  /** write mapping information */\n  if(mapinfo.size()) {\n    int gid = cgs[0].group_id;\n    nrn_write_mapping_info(path, gid, mapinfo);\n    mapinfo.clear();\n  }\n\n  if (nrnthread_v_transfer_) {\n    // see partrans.cpp. nrn_nthread files of path/icg_gap.dat\n    int* group_ids = new int[nrn_nthread];\n    for (int i=0; i < nrn_nthread; ++i) {\n      group_ids[i] = cgs[i].group_id;\n    }\n    nrnbbcore_gap_write(path, group_ids);\n    delete [] group_ids;\n  }\n\n  // filename data might have to be collected at hoc level since\n  // pc.nrnbbcore_write might be called\n  // many times per rank since model may be built as series of submodels.\n  if (ifarg(2)) {\n    Vect* cgidvec = vector_arg(2);\n    vector_resize(cgidvec, nrn_nthread);\n    double* px = vector_vec(cgidvec);\n    for (int i=0; i < nrn_nthread; ++i) {\n      px[i] = double(cgs[i].group_id);\n    }\n  }else{\n    write_nrnthread_task(path, cgs);\n  }\n\n  // clean up the art Memb_list of CellGroup[].mlwithart\n  for (int ith=0; ith < nrn_nthread; ++ith) {\n    MlWithArt& mla = cgs[ith].mlwithart;\n    for (size_t i = 0; i < mla.size(); ++i) {\n      int type = mla[i].first;\n      Memb_list* ml = mla[i].second;\n      if (nrn_is_artificial_[type]) {\n        delete [] ml->data;\n        delete [] ml->pdata;\n        delete ml;\n      }\n    }\n  }\n\n  part2_clean();\n}\n\nint nrncore_art2index(double* d) {\n  int i;\n  int result = artdata2index_->find(d, i);\n  assert(result);\n  return i;\n}\n\nextern \"C\" {\nextern int nrn_has_net_event_cnt_;\nextern int* nrn_has_net_event_;\n}\n\nstatic int* has_net_event_;\nstatic void setup_nrn_has_net_event() {\n  if (has_net_event_) { return; }\n  has_net_event_ = new int[n_memb_func];\n  for (int i=0; i < n_memb_func; ++i) {\n    has_net_event_[i] = 0;\n  }\n  for(int i=0; i < nrn_has_net_event_cnt_; ++i) {\n    has_net_event_[nrn_has_net_event_[i]] = 1;\n  }\n}\n\nstatic int nrn_has_net_event(int type) {\n  return has_net_event_[type];\n}\n\nvoid mk_tml_with_art() {\n  // copy NrnThread tml list and append ARTIFICIAL cell types \n  // but do not include PatternStim\n  // Now using cgs[tid].mlwithart instead of\n  // tml_with_art = new NrnThreadMembList*[nrn_nthread];\n  // to allow fast retrieval of type and Memb_list* given index into the vector.\n  CellGroup* cgs = cellgroups_;\n  // copy from NrnThread\n  for (int id = 0; id < nrn_nthread; ++id) {\n    MlWithArt& mla = cgs[id].mlwithart;\n    for (NrnThreadMembList* tml = nrn_threads[id].tml; tml; tml = tml->next) {\n      mla.push_back(MlWithArtItem(tml->index, tml->ml));\n    }\n  }\n  int *acnt = new int[nrn_nthread];\n  artdata2index_ = new PVoid2Int(1000);\n\n  for (int i = 0; i < n_memb_func; ++i) {\n    if (nrn_is_artificial_[i] && memb_list[i].nodecount) {\n      // skip PatternStim\n      if (strcmp(memb_func[i].sym->name, \"PatternStim\") == 0) { continue; }\n      if (strcmp(memb_func[i].sym->name, \"HDF5Reader\") == 0) { continue; }\n      Memb_list* ml = memb_list + i;\n      // how many artificial in each thread\n      for (int id = 0; id < nrn_nthread; ++id) {acnt[id] = 0;}\n      for (int j = 0; j < memb_list[i].nodecount; ++j) {\n        Point_process* pnt = (Point_process*)memb_list[i].pdata[j][1]._pvoid;\n        int id = ((NrnThread*)pnt->_vnt)->id;\n        ++acnt[id];\n      }\n\n      // allocate\n      for (int id = 0; id < nrn_nthread; ++id) {\n        if (acnt[id]) {\n          MlWithArt& mla = cgs[id].mlwithart;\n          ml = new Memb_list;\n          mla.push_back(MlWithArtItem(i, ml)); // need to delete ml when mla destroyed.\n          ml->nodecount = acnt[id];\n          ml->nodelist = NULL;\n          ml->nodeindices = NULL;\n          ml->prop = NULL;\n          ml->_thread = NULL;\n          ml->data = new double*[acnt[id]];\n          ml->pdata = new Datum*[acnt[id]];\n        }\n      }\n      // fill data and pdata pointers\n      // and fill the artdata2index hash table\n      for (int id = 0; id < nrn_nthread; ++id) {acnt[id] = 0;}\n      for (int j = 0; j < memb_list[i].nodecount; ++j) {\n        Point_process* pnt = (Point_process*)memb_list[i].pdata[j][1]._pvoid;\n        int id = ((NrnThread*)pnt->_vnt)->id;\n        Memb_list* ml = cgs[id].mlwithart.back().second;\n        ml->data[acnt[id]] = memb_list[i].data[j];\n        ml->pdata[acnt[id]] = memb_list[i].pdata[j];\n        artdata2index_->insert(ml->data[acnt[id]], acnt[id]);\n        ++acnt[id];\n      }\n    }\n  }\n  delete [] acnt;\n}\n\nCellGroup::CellGroup() {\n  n_output = n_real_output = n_presyn = n_netcon = n_mech = ntype = 0;\n  group_id = -1;\n  output_gid = output_vindex = 0;\n  netcons = 0; output_ps = 0;\n  ndiam = 0;\n  netcon_srcgid = netcon_pnttype = netcon_pntindex = 0;\n  datumindices = 0;\n  type2ml = new Memb_list*[n_memb_func];\n  for (int i=0; i < n_memb_func; ++i) {\n    type2ml[i] = 0;\n  }\n  ml_vdata_offset = NULL;\n}\n\nCellGroup::~CellGroup() {\n  if (output_gid) delete [] output_gid;\n  if (output_vindex) delete [] output_vindex;\n  if (netcon_srcgid) delete [] netcon_srcgid;\n  if (netcon_pnttype) delete [] netcon_pnttype;\n  if (netcon_pntindex) delete [] netcon_pntindex;\n  if (datumindices) delete [] datumindices;\n  if (netcons) delete [] netcons;\n  if (output_ps) delete [] output_ps;\n  if (ml_vdata_offset) delete [] ml_vdata_offset;\n  delete [] type2ml;\n}\n\nDatumIndices::DatumIndices() {\n  type = -1;\n  ion_type = ion_index = 0;\n}\n\nDatumIndices::~DatumIndices() {\n  if (ion_type) delete [] ion_type;\n  if (ion_index) delete [] ion_index;\n}\n\n// use the Hoc NetCon object list to segregate according to threads\n// and fill the CellGroup netcons, netcon_srcgid, netcon_pnttype, and\n// netcon_pntindex (called at end of mk_cellgroups);\nstatic void mk_cgs_netcon_info(CellGroup* cgs) {\n  // count the netcons for each thread\n  int* nccnt = new int[nrn_nthread];\n  for (int i=0; i < nrn_nthread; ++i) {\n    nccnt[i] = 0;\n  }\n  Symbol* ncsym = hoc_lookup(\"NetCon\");\n  hoc_List* ncl = ncsym->u.ctemplate->olist;\n  hoc_Item* q;\n  ITERATE(q, ncl) {\n    Object* ho = (Object*)VOIDITM(q);\n    NetCon* nc = (NetCon*)ho->u.this_pointer;\n    int ith = 0; // if no _vnt, put in thread 0\n    if (nc->target_ && nc->target_->_vnt) {\n      ith = ((NrnThread*)(nc->target_->_vnt))->id;\n    }\n    ++nccnt[ith];\n  }\n\n  // allocate\n  for (int i=0; i < nrn_nthread; ++i) {\n    cgs[i].n_netcon = nccnt[i];\n    cgs[i].netcons = new NetCon*[nccnt[i]+1];\n    cgs[i].netcon_srcgid = new int[nccnt[i]+1];\n    cgs[i].netcon_pnttype = new int[nccnt[i]+1];\n    cgs[i].netcon_pntindex = new int[nccnt[i]+1];\n  }\n\n  // reset counts and fill\n  for (int i=0; i < nrn_nthread; ++i) {\n    nccnt[i] = 0;\n  }\n  ITERATE(q, ncl) {\n    Object* ho = (Object*)VOIDITM(q);\n    NetCon* nc = (NetCon*)ho->u.this_pointer;\n    int ith = 0; // if no _vnt, put in thread 0\n    if (nc->target_ && nc->target_->_vnt) {\n      ith = ((NrnThread*)(nc->target_->_vnt))->id;\n    }\n    int i = nccnt[ith];\n    cgs[ith].netcons[i] = nc;\n\n    if (nc->target_) {\n      int type = nc->target_->prop->type;\n      cgs[ith].netcon_pnttype[i] = type;\n      if (nrn_is_artificial_[type]) {\n        cgs[ith].netcon_pntindex[i] = nrncore_art2index(nc->target_->prop->param);\n      }else{\n        // cache efficient so can calculate index from pointer\n        Memb_list* ml = cgs[ith].type2ml[type];\n        int sz = nrn_prop_param_size_[type];\n        double* d1 = ml->data[0];\n        double* d2 = nc->target_->prop->param;\n        assert(d2 >= d1 && d2 < (d1 + (sz*ml->nodecount)));\n        int ix = (d2 - d1)/sz;\n        cgs[ith].netcon_pntindex[i] = ix;\n      }\n    }else{\n      cgs[ith].netcon_pnttype[i] = 0;\n      cgs[ith].netcon_pntindex[i] = -1;\n    }\n\n    if (nc->src_) {\n      PreSyn* ps = nc->src_;\n      if (ps->gid_ >= 0) {\n        cgs[ith].netcon_srcgid[i] = ps->gid_;\n      }else{\n        if (ps->osrc_) {\n          assert(ps->thvar_ == NULL);\n          Point_process* pnt = (Point_process*)ps->osrc_->u.this_pointer;\n          int type = pnt->prop->type;\n          if (nrn_is_artificial_[type]) {\n            int ix = nrncore_art2index(pnt->prop->param);\n            cgs[ith].netcon_srcgid[i] = -(type + 1000*ix);\n          }else{\n            assert(nrn_has_net_event(type));\n            Memb_list* ml = cgs[ith].type2ml[type];\n            int sz = nrn_prop_param_size_[type];\n            double* d1 = ml->data[0];\n            double* d2 = pnt->prop->param;\n            assert(d2 >= d1 && d2 < (d1 + (sz*ml->nodecount)));\n            int ix = (d2 - d1)/sz;\n            cgs[ith].netcon_srcgid[i] = -(type + 1000*ix);\n          }\n        }else{\n          cgs[ith].netcon_srcgid[i] = -1;\n        }\n      }\n    }else{\n      cgs[ith].netcon_srcgid[i] = -1;\n    }\n    ++nccnt[ith];\n  }\n  delete [] nccnt;\n}\n\nCellGroup* mk_cellgroups() {\n  CellGroup* cgs = cellgroups_;\n  for (int i=0; i < nrn_nthread; ++i) {\n    int ncell = nrn_threads[i].ncell; // real cell count\n    int npre = ncell;\n    MlWithArt& mla = cgs[i].mlwithart;\n    for (size_t j = 0; j < mla.size(); ++j) {\n      int type = mla[j].first;\n      Memb_list* ml = mla[j].second;\n      cgs[i].type2ml[type] = ml;\n      if (nrn_has_net_event(type)) {\n        npre += ml->nodecount;\n      }\n    }\n    cgs[i].n_presyn = npre;\n    cgs[i].n_real_output = ncell;\n    cgs[i].output_ps = new PreSyn*[npre];\n    cgs[i].output_gid = new int[npre];\n    cgs[i].output_vindex = new int[npre];\n    // in case some cells do not have voltage presyns (eg threshold detection\n    // computed from a POINT_PROCESS NET_RECEIVE with WATCH and net_event)\n    // initialize as unused.\n    for (int j=0; j < npre; ++j) {\n      cgs[i].output_ps[j] = NULL;\n      cgs[i].output_gid[j] = -1;\n      cgs[i].output_vindex[j] = -1;\n    }\n\n    // fill in the artcell info\n    npre = ncell;\n    cgs[i].n_output = ncell; // add artcell (and PP with net_event) with gid in following loop\n    for (size_t j = 0; j < mla.size(); ++j) {\n      int type = mla[j].first;\n      Memb_list* ml = mla[j].second;\n      if (nrn_has_net_event(type)) {\n        for (int j=0; j < ml->nodecount; ++j) {\n          Point_process* pnt = (Point_process*)ml->pdata[j][1]._pvoid;\n          PreSyn* ps = (PreSyn*)pnt->presyn_;\n          cgs[i].output_ps[npre] = ps;\n          int agid = -1;\n          if (nrn_is_artificial_[type]) {\n            agid = -(type + 1000*nrncore_art2index(pnt->prop->param));\n          }else{ // POINT_PROCESS with net_event\n            int sz = nrn_prop_param_size_[type];\n            double* d1 = ml->data[0];\n            double* d2 = pnt->prop->param;\n            assert(d2 >= d1 && d2 < (d1 + (sz*ml->nodecount)));\n            int ix = (d2 - d1)/sz;\n            agid = -(type + 1000*ix);\n          }\n          if (ps) {\n            if (ps->output_index_ >= 0) { // has gid\n              cgs[i].output_gid[npre] = ps->output_index_;\n              if (cgs[i].group_id < 0) {\n                cgs[i].group_id = ps->output_index_;\n              }\n              ++cgs[i].n_output;\n            }else{\n              cgs[i].output_gid[npre] = agid;\n            }\n          }else{ // if an acell is never a source, it will not have a presyn\n            cgs[i].output_gid[npre] = -1;\n          }\n          // the way we associate an acell PreSyn with the Point_process.\n          cgs[i].output_vindex[npre] = agid;\n          ++npre;\n        }\n      }\n    }\n  }\n  // work at netpar.cpp because we don't have the output gid hash tables here.\n  // fill in the output_ps, output_gid, and output_vindex for the real cells.\n  nrncore_netpar_cellgroups_helper(cgs);\n\n  // use first real cell gid, if it exists, as the group_id\n  if (corenrn_direct == false) for (int i=0; i < nrn_nthread; ++i) {\n    if (cgs[i].n_real_output && cgs[i].output_gid[0] >= 0) {\n      cgs[i].group_id = cgs[i].output_gid[0];\n    }else if (cgs[i].group_id >= 0) {\n      // set above to first artificial cell with a ps->output_index >= 0\n    }else{\n      // Don't die yet as the thread may be empty. That just means no files\n      // output for this thread and no mention in files.dat.\n      // Can check for empty near end of datatransform(CellGroup* cgs)\n    }\n  }\n\n  // use the Hoc NetCon object list to segregate according to threads\n  // and fill the CellGroup netcons, netcon_srcgid, netcon_pnttype, and\n  // netcon_pntindex\n  mk_cgs_netcon_info(cgs);\n\n  return cgs;\n}\n\nvoid datumtransform(CellGroup* cgs) {\n  // ions, area, and POINTER to v.\n  for (int ith=0; ith < nrn_nthread; ++ith) {\n    NrnThread& nt = nrn_threads[ith];\n    CellGroup& cg = cgs[ith];\n    // how many mechanisms in use and how many DatumIndices do we need.\n    MlWithArt& mla = cgs[ith].mlwithart;\n    for (size_t j = 0; j < mla.size(); ++j) {\n      Memb_list* ml = mla[j].second;\n      ++cg.n_mech;\n      if (ml->pdata[0]) {\n        ++cg.ntype;\n      }\n    }\n    cg.datumindices = new DatumIndices[cg.ntype];\n    // specify type, allocate the space, and fill the indices\n    int i=0;\n    for (size_t j = 0; j < mla.size(); ++j) {\n      int type = mla[j].first;\n      Memb_list* ml = mla[j].second;\n      int sz = bbcore_dparam_size[type];\n      if (sz) {\n        DatumIndices& di = cg.datumindices[i++];\n        di.type = type;\n        int n = ml->nodecount * sz;\n        di.ion_type = new int[n];\n        di.ion_index = new int[n];\n        // fill the indices.\n        // had tointroduce a memb_func[i].dparam_semantics registered by each mod file.\n        datumindex_fill(ith, cg, di, ml);\n      }\n    }\n    // if model is being transferred via files, and\n    //   if there are no gids in the thread (group_id < 0), and\n    //     if the thread is not empty (mechanisms exist, n_mech > 0)\n    if (corenrn_direct == false && cg.group_id < 0 && cg.n_mech > 0) {\n      hoc_execerror(\"A nonempty thread has no real cell or ARTIFICIAL_CELL with a gid\", NULL);\n    }\n  }\n}\n\n// This function is related to stdindex2ptr in CoreNeuron to determine which values should\n// be transferred from CoreNeuron. Types correspond to the value to be transferred based on\n// mech_type enum or non-artificial cell mechanisms.\n// Limited to pointers to voltage, nt._nrn_fast_imem->_nrn_sav_rhs (fast_imem value) or\n// data of non-artificial cell mechanisms.\n// Requires cache_efficient mode.\n// Input double* and NrnThread. Output type and index.\n// type == 0 means could not determine index.\nint nrn_dblpntr2nrncore(double* pd, NrnThread& nt, int& type, int& index) {\n  assert(use_cachevec);\n  int nnode = nt.end;\n  type = 0;\n  if (pd >= nt._actual_v && pd < (nt._actual_v + nnode)) {\n    type = voltage; // signifies an index into voltage array portion of _data\n    index = pd - nt._actual_v;\n  } else if (nt._nrn_fast_imem && pd >= nt._nrn_fast_imem->_nrn_sav_rhs && pd < (nt._nrn_fast_imem->_nrn_sav_rhs + nnode)) {\n    type = i_membrane_; // signifies an index into i_membrane_ array portion of _data\n    index = pd - nt._nrn_fast_imem->_nrn_sav_rhs;\n  }else{\n    for (NrnThreadMembList* tml = nt.tml; tml; tml = tml->next) {\n      if (nrn_is_artificial_[tml->index]) { continue; }\n      Memb_list* ml1 = tml->ml;\n      int nn = nrn_prop_param_size_[tml->index] * ml1->nodecount;\n      if (pd >= ml1->data[0] && pd < (ml1->data[0] + nn)) {\n        type = tml->index;\n        index = pd - ml1->data[0];\n        break;\n      }\n    }\n  }\n  return type == 0 ? 1 : 0;\n}\n\nvoid datumindex_fill(int ith, CellGroup& cg, DatumIndices& di, Memb_list* ml) {\n  NrnThread& nt = nrn_threads[ith];\n  double* a = nt._actual_area;\n  int nnode = nt.end;\n  int mcnt = ml->nodecount;\n  int dsize = bbcore_dparam_size[di.type];\n  if (dsize == 0) { return; }\n  int* dmap = memb_func[di.type].dparam_semantics;\n  assert(dmap);\n  // what is the size of the nt._vdata portion needed for a single ml->dparam[i]\n  int vdata_size = 0;\n  for (int i=0; i < dsize; ++i) {\n    int* ds = memb_func[di.type].dparam_semantics;\n    if (ds[i] == -4 || ds[i] == -6 || ds[i] == -7 || ds[i] == 0) {\n      ++vdata_size;\n    }\n  }\n\n  int isart = nrn_is_artificial_[di.type];\n  for (int i=0; i < mcnt; ++i) {\n    // Prop* datum instance arrays are not in cache efficient order\n    // ie. ml->pdata[i] are not laid out end to end in memory.\n    // Also, ml->data for artificial cells is not in cache efficient order\n    // but in the artcell case there are no pointers to doubles and\n    // the _actual_area pointer should be left unfilled.\n    Datum* dparam = ml->pdata[i];\n    int offset = i*dsize;\n    int vdata_offset = i*vdata_size;\n    for (int j=0; j < dsize; ++j) {\n      int etype = -100; // uninterpreted\n      int eindex = -1;\n      if (dmap[j] == -1) { // double* into _actual_area\n        if (isart) {\n          etype = -1;\n          eindex = -1; // the signal to ignore in bbcore.\n        }else{\n          if (dparam[j].pval == &ml->nodelist[i]->_area) {\n            // possibility it points directly into Node._area instead of\n            // _actual_area. For our purposes we need to figure out the\n            // _actual_area index.\n            etype = -1;\n            eindex = ml->nodeindices[i];\n            assert(a[ml->nodeindices[i]] == *dparam[j].pval);\n          }else{\n            if (dparam[j].pval < a || dparam[j].pval >= (a + nnode)){\n              printf(\"%s dparam=%p a=%p a+nnode=%p j=%d\\n\",\n                  memb_func[di.type].sym->name, dparam[j].pval, a, a+nnode, j);\n              abort();\n            }\n            assert(dparam[j].pval >= a && dparam[j].pval < (a + nnode));\n            etype = -1;\n            eindex = dparam[j].pval - a;\n          }\n        }\n      }else if (dmap[j] == -2) { // this is an ion and dparam[j][0].i is the iontype\n        etype = -2;\n        eindex = dparam[j].i;\n      }else if (dmap[j] == -3) { // cvodeieq is always last and never seen\n        assert(dmap[j] != -3);\n      }else if (dmap[j] == -4) { // netsend (_tqitem pointer)\n        // eventually index into nt->_vdata\n        etype = -4;\n        eindex = vdata_offset++;\n      }else if (dmap[j] == -6) { // pntproc\n        // eventually index into nt->_vdata\n        etype = -6;\n        eindex = vdata_offset++;\n      }else if (dmap[j] == -7) { // bbcorepointer\n        // eventually index into nt->_vdata\n        etype = -6;\n        eindex = vdata_offset++;\n      }else if (dmap[j] == -8) { // watch\n        etype = -8;\n        eindex = 0;\n      }else if (dmap[j] == -9) { // diam\n        cg.ndiam = nt.end;\n        etype = -9;\n        // Rare for a mechanism to use dparam pointing to diam.\n        // MORPHOLOGY was never made cache efficient. And\n        // is not in the tml_with_art. \n        // Need to determine this node and then simple to search its\n        // mechanism list for MORPHOLOGY and then know the diam.\n        Node* nd = ml->nodelist[i];\n        double* pdiam = NULL;\n        for (Prop* p = nd->prop; p; p = p->next) {\n          if (p->type == MORPHOLOGY) {\n            pdiam = p->param;\n            break;\n          }\n        }\n        assert(dparam[j].pval == pdiam);\n        eindex = ml->nodeindices[i];\n      }else if (dmap[j] == -5) { // POINTER\n        // must be a pointer into nt->_data. Handling is similar to eion so\n        // give proper index into the type.\n        double* pd = dparam[j].pval;\n\tnrn_dblpntr2nrncore(pd, nt, etype, eindex);\n        if (etype == 0) {\n          fprintf(stderr, \"POINTER is not pointing to voltage or mechanism data. Perhaps it should be a BBCOREPOINTER\\n\");\n        }\n        assert(etype != 0);\n        // pointer into one of the tml types?\n      }else if (dmap[j] > 0 && dmap[j] < 1000) { // double* into eion type data\n        Memb_list* eml = cg.type2ml[dmap[j]];\n        assert(eml);\n        if(dparam[j].pval < eml->data[0]){\n          printf(\"%s dparam=%p data=%p j=%d etype=%d %s\\n\",\n              memb_func[di.type].sym->name, dparam[j].pval, eml->data[0], j,\n              dmap[j], memb_func[dmap[j]].sym->name);\n          abort();\n        }\n        assert(dparam[j].pval >= eml->data[0]);\n        etype = dmap[j];\n        if (dparam[j].pval >= (eml->data[0] +\n              (nrn_prop_param_size_[etype] * eml->nodecount))) {\n          printf(\"%s dparam=%p data=%p j=%d psize=%d nodecount=%d etype=%d %s\\n\",\n              memb_func[di.type].sym->name, dparam[j].pval, eml->data[0], j,\n              nrn_prop_param_size_[etype],\n              eml->nodecount, etype, memb_func[etype].sym->name);\n        }\n        assert(dparam[j].pval < (eml->data[0] +\n              (nrn_prop_param_size_[etype] * eml->nodecount)));\n        eindex = dparam[j].pval - eml->data[0];\n      }else if (dmap[j] > 1000) {//int* into ion dparam[xxx][0]\n        //store the actual ionstyle\n        etype = dmap[j];\n        eindex = *((int*)dparam[j]._pvoid);\n      } else {\n        char errmes[100];\n        sprintf(errmes, \"Unknown semantics type %d for dparam item %d of\", dmap[j], j);\n        hoc_execerror(errmes, memb_func[di.type].sym->name);\n      }\n      di.ion_type[offset + j] = etype;\n      di.ion_index[offset + j] = eindex;\n    }\n  }\n}\n\nstatic void write_byteswap1(const char* fname) {\n  if (nrnmpi_myid > 0) { return; } // only rank 0 writes this file\n  FILE* f = fopen(fname, \"wb\");\n  if (!f) {\n    hoc_execerror(\"nrnbbcore_write write_byteswap1 could not open for writing: %s\\n\", fname);\n  }\n  // write an endian sentinal value so reader can determine if byteswap needed.\n  int32_t x = 1;\n  fwrite(&x, sizeof(int32_t), 1, f);\n  fclose(f);\n}\n\nstatic void write_memb_mech_types(const char* fname) {\n  if (nrnmpi_myid > 0) { return; } // only rank 0 writes this file\n  std::ofstream fs(fname);\n  if (!fs.good()) {\n    hoc_execerror(\"nrnbbcore_write write_mem_mech_types could not open for writing: %s\\n\", fname);\n  }\n  write_memb_mech_types_direct(fs);\n}\n\nstatic void write_memb_mech_types_direct(std::ostream& s) {\n  // list of Memb_func names, types, point type info, is_ion\n  // and data, pdata instance sizes. If the mechanism is an eion type,\n  // the following line is the charge.\n  // Not all Memb_func are necessarily used in the model.\n  s << bbcore_write_version << std::endl;\n  s << n_memb_func << std::endl;\n  for (int type=2; type < n_memb_func; ++type) {\n    const char* w = \" \";\n    Memb_func& mf = memb_func[type];\n    s << mf.sym->name << w << type << w\n      << int(pnt_map[type]) << w // the pointtype, 0 means not a POINT_PROCESS\n      << nrn_is_artificial_[type] << w\n      << nrn_is_ion(type) << w\n      << nrn_prop_param_size_[type] << w << bbcore_dparam_size[type] << std::endl;\n\n    if (nrn_is_ion(type)) {\n        s << nrn_ion_charge(mf.sym) << std::endl;\n    }\n  }\n}\n\n// format is name value\n// with last line of 0 0\n//In case of an array, the line is name[num] with num lines following with\n// one value per line.  Values are %.20g format.\nstatic void write_globals(const char* fname) {\n\n  if (nrnmpi_myid > 0) { return; } // only rank 0 writes this file\n\n  FILE* f = fopen(fname, \"w\");\n  if (!f) {\n    hoc_execerror(\"nrnbbcore_write write_globals could not open for writing: %s\\n\", fname);\n  }\n\n  fprintf(f, \"%s\\n\", bbcore_write_version);\n  const char* name;\n  int size; // 0 means scalar, is 0 will still allocated one element for val.\n  double* val; // Allocated by new in get_global_item, must be delete [] here.\n  for (void* sp = NULL;\n        (sp = get_global_dbl_item(sp, name, size, val)) != NULL;) {\n    if (size) {\n      fprintf(f, \"%s[%d]\\n\", name, size);\n      for (int i=0; i < size; ++i) {\n        fprintf(f, \"%.20g\\n\", val[i]);\n      }\n    }else{\n      fprintf(f, \"%s %.20g\\n\", name, val[0]);\n    }\n    delete [] val;\n  }\n  fprintf(f, \"0 0\\n\"); \n  fprintf(f, \"secondorder %d\\n\", secondorder);\n  fprintf(f, \"Random123_globalindex %d\\n\", nrnran123_get_globalindex());\n\n  fclose(f);\n}\n\n// just for secondorder and Random123_globalindex\nstatic int get_global_int_item(const char* name) {\n  if (strcmp(name, \"secondorder\") == 0) {\n    return secondorder;\n  }else if(strcmp(name, \"Random123_global_index\") == 0) {\n    return nrnran123_get_globalindex();\n  }\n  return 0;\n}\n\n// successively return global double info. Begin with p==NULL.\n// Done when return NULL.\nstatic void* get_global_dbl_item(void* p, const char* & name, int& size, double*& val) {\n  Symbol* sp = (Symbol*)p;\n  if (sp == NULL) {\n    sp = hoc_built_in_symlist->first;\n  }\n  for (; sp; sp = sp->next) {\n    if (sp->type == VAR && sp->subtype == USERDOUBLE) {\n      name = sp->name;\n      if (ISARRAY(sp)) {\n        Arrayinfo* a = sp->arayinfo;\n        if (a->nsub == 1) {\n          size = a->sub[0];\n          val = new double[size];\n          for (int i=0; i < a->sub[0]; ++i) {\n            char n[256];\n            sprintf(n, \"%s[%d]\", sp->name, i);\n            val[i] =  *hoc_val_pointer(n);\n          }\n        }\n      }else{\n        size = 0;\n        val = new double[1];\n        val[0] = *sp->u.pval;\n      }\n      return sp->next;\n    }\n  }\n  return NULL;\n}\n\nvoid writeint_(int* p, size_t size, FILE* f) {\n  fprintf(f, \"chkpnt %d\\n\", chkpnt++);\n  size_t n = fwrite(p, sizeof(int), size, f);\n  assert(n == size);\n}\n\nvoid writedbl_(double* p, size_t size, FILE* f) {\n  fprintf(f, \"chkpnt %d\\n\", chkpnt++);\n  size_t n = fwrite(p, sizeof(double), size, f);\n  assert(n == size);\n}\n\n#define writeint(p,size) writeint_(p, size, f)\n#define writedbl(p,size) writedbl_(p, size, f)\n\nstatic void write_contiguous_art_data(double** data, int nitem, int szitem, FILE* f) {\n  fprintf(f, \"chkpnt %d\\n\", chkpnt++);\n  // the assumption is that an fwrite of nitem groups of szitem doubles can be\n  // fread as a single group of nitem*szitem doubles.\n  for (int i = 0; i < nitem; ++i) {\n    size_t n = fwrite(data[i], sizeof(double), szitem, f);\n    assert(n == szitem);\n  }\n}\n\nstatic double* contiguous_art_data(double** data, int nitem, int szitem) {\n  double* d1 = new double[nitem*szitem];\n  int k = 0;\n  for (int i = 0; i < nitem; ++i) {\n    for (int j=0; j < szitem; ++j) {\n      d1[k++] = data[i][j];\n    }\n  }\n  return d1;\n}\n\n// Vector.play information.\n// Must play into a data element in this thread\n// File format is # of play instances in this thread (generally VecPlayContinuous)\n// For each Play instance\n// VecPlayContinuousType (4), pd (index), y.size, yvec, tvec\n// Other VecPlay instance types are possible, such as VecPlayContinuous with\n// a discon vector or VecPlayStep with a DT or tvec, but are not implemented\n// at present. Assertion errors are generated if not type 0 of if we\n// cannot determine the index into the NrnThread._data .\n\nstatic int nrnthread_dat2_vecplay(int tid, int& n) {\n  if (tid >= nrn_nthread) { return 0; }\n  NrnThread& nt = nrn_threads[tid];\n\n  // count the instances for this thread\n  // error if not a VecPlayContinuous with no discon vector\n  n = 0;\n  PlayRecList* fp = net_cvode_instance->fixed_play_;\n  for (int i=0; i < fp->count(); ++i){\n    if (fp->item(i)->type() == VecPlayContinuousType) {\n      VecPlayContinuous* vp = (VecPlayContinuous*)fp->item(i);\n      if (vp->discon_indices_ == NULL) {\n        if (vp->ith_ == nt.id) {\n          assert(vp->y_ && vp->t_);\n          ++n;\n        }\n      }else{\n        assert(0);\n      }\n    }else{\n      assert(0);\n    }\n  }\n\n  return 1;\n}\n\nstatic int nrnthread_dat2_vecplay_inst(int tid, int i, int& vptype, int& mtype,\n  int& ix, int& sz, double*& yvec, double*& tvec) {\n\n  if (tid >= nrn_nthread) { return 0; }\n  NrnThread& nt = nrn_threads[tid];\n\n    PlayRecList* fp = net_cvode_instance->fixed_play_;\n    if (fp->item(i)->type() == VecPlayContinuousType) {\n      VecPlayContinuous* vp = (VecPlayContinuous*)fp->item(i);\n      if (vp->discon_indices_ == NULL) {\n        if (vp->ith_ == nt.id) {\n          double* pd = vp->pd_;\n          int found = 0;\n          vptype = vp->type();\n          for (NrnThreadMembList* tml = nt.tml; tml; tml = tml->next) {\n            if (nrn_is_artificial_[tml->index]) { continue; }\n            Memb_list* ml = tml->ml;\n            int nn = nrn_prop_param_size_[tml->index] * ml->nodecount;\n            if (pd >= ml->data[0] && pd < (ml->data[0] + nn)) {\n              mtype = tml->index;\n              ix = (pd - ml->data[0]);\n              sz = vector_capacity(vp->y_);\n              yvec = vector_vec(vp->y_);\n              tvec = vector_vec(vp->t_);\n              found = 1;\n              break;\n            }\n          }\n          assert(found);\n          return 1;\n        }\n      }\n    }\n\n  return 0;\n}\n\nstatic void nrnbbcore_vecplay_write(FILE* f, NrnThread& nt) {\n  // count the instances for this thread\n  // error if not a VecPlayContinuous with no discon vector\n  int n;\n  nrnthread_dat2_vecplay(nt.id, n);\n  fprintf(f, \"%d VecPlay instances\\n\", n);\n  PlayRecList* fp = net_cvode_instance->fixed_play_;\n  for (int i=0; i < fp->count(); ++i) {\n    int vptype, mtype, ix, sz; double *yvec, *tvec;\n    if (nrnthread_dat2_vecplay_inst(nt.id, i, vptype, mtype, ix, sz, yvec, tvec)) {\n      fprintf(f, \"%d\\n\", vptype);\n      fprintf(f, \"%d\\n\", mtype);\n      fprintf(f, \"%d\\n\", ix);\n      fprintf(f, \"%d\\n\", sz);\n      writedbl(yvec, sz);\n      writedbl(tvec, sz);\n    }\n  }\n}\n\nstatic int nrnthread_dat1(int tid, int& n_presyn, int& n_netcon,\n  int*& output_gid, int*& netcon_srcgid) {\n\n  if (tid >= nrn_nthread) { return 0; }\n  CellGroup& cg = cellgroups_[tid];\n  n_presyn = cg.n_presyn;\n  n_netcon = cg.n_netcon;\n  output_gid = cg.output_gid;  cg.output_gid = NULL;\n  netcon_srcgid = cg.netcon_srcgid;  cg.netcon_srcgid = NULL;\n  return 1;\n}\n\n// sizes and total data count\nstatic int nrnthread_dat2_1(int tid, int& ngid, int& n_real_gid, int& nnode, int& ndiam,\n  int& nmech, int*& tml_index, int*& ml_nodecount, int& nidata, int& nvdata, int& nweight) {\n  \n  if (tid >= nrn_nthread) { return 0; }\n  CellGroup& cg = cellgroups_[tid];\n  NrnThread& nt = nrn_threads[tid];\n\n  ngid = cg.n_output;\n  n_real_gid = cg.n_real_output;\n  nnode = nt.end;\n  ndiam = cg.ndiam;\n  nmech = cg.n_mech;\n\n  cg.ml_vdata_offset = new int[nmech];\n  int vdata_offset = 0;\n  tml_index = new int[nmech];\n  ml_nodecount = new int[nmech];\n  MlWithArt& mla = cg.mlwithart;\n  for (size_t j = 0; j < mla.size(); ++j) {\n    int type = mla[j].first;\n    Memb_list* ml = mla[j].second;\n    tml_index[j] = type;\n    ml_nodecount[j] = ml->nodecount;\n    cg.ml_vdata_offset[j] = vdata_offset;\n    int* ds = memb_func[type].dparam_semantics;\n    for (int psz=0; psz < bbcore_dparam_size[type]; ++psz) {\n      if (ds[psz] == -4 || ds[psz] == -6 || ds[psz] == -7 || ds[psz] == 0) {\n        //printf(\"%s ds[%d]=%d vdata_offset=%d\\n\", memb_func[type].sym->name, psz, ds[psz], vdata_offset);\n        vdata_offset += ml->nodecount;\n      }\n    }\n  }\n  nvdata = vdata_offset;\n  nidata = 0;\n  //  printf(\"nidata=%d nvdata=%d nnetcon=%d\\n\", nidata, nvdata, cg.n_netcon);\n  nweight = 0;\n  for (int i=0; i < cg.n_netcon; ++i) {\n    nweight += cg.netcons[i]->cnt_;\n  }\n\n  return 1;\n}\n\nstatic int nrnthread_dat2_2(int tid, int*& v_parent_index, double*& a, double*& b,\n  double*& area, double*& v, double*& diamvec) {\n\n  if (tid >= nrn_nthread) { return 0; }\n  CellGroup& cg = cellgroups_[tid];\n  NrnThread& nt = nrn_threads[tid];\n\n  assert(cg.n_real_output == nt.ncell);\n\n  // if not NULL then copy (for direct transfer target space already allocated)\n  bool copy = v_parent_index ? true : false;\n  int n = nt.end;\n  if (copy) {\n    for (int i=0; i < nt.end; ++i) {\n      v_parent_index[i] = nt._v_parent_index[i];\n      a[i] = nt._actual_a[i];\n      b[i] = nt._actual_b[i];\n      area[i] = nt._actual_area[i];\n      v[i] = nt._actual_v[i];\n    }\n  }else{\n    v_parent_index = nt._v_parent_index;\n    a = nt._actual_a;\n    b = nt._actual_b;\n    area = nt._actual_area;\n    v = nt._actual_v;\n  }\n  if (cg.ndiam) {\n    if (!copy) {\n      diamvec = new double[nt.end];\n    }\n    for (int i=0; i < nt.end; ++i) {\n      Node* nd = nt._v_node[i];\n      double diam = 0.0;\n      for (Prop* p = nd->prop; p; p = p->next) {\n        if (p->type == MORPHOLOGY) {\n          diam = p->param[0];\n          break;\n        }\n      }\n      diamvec[i] = diam;\n    }\n  }\n  return 1;\n}\n\nstatic int nrnthread_dat2_mech(int tid, size_t i, int dsz_inst, int*& nodeindices,\n  double*& data, int*& pdata) {\n\n  if (tid >= nrn_nthread) { return 0; }\n  CellGroup& cg = cellgroups_[tid];\n  NrnThread& nt = nrn_threads[tid];\n  MlWithArtItem& mlai = cg.mlwithart[i];\n  int type = mlai.first;\n  Memb_list* ml = mlai.second;\n  // for direct transfer, data=NULL means copy into passed space for nodeindices, data, and pdata\n  bool copy = data ? true : false;\n\n    int vdata_offset = cg.ml_vdata_offset[i];\n    int isart = nrn_is_artificial_[type];\n    int n = ml->nodecount;\n    int sz = nrn_prop_param_size_[type];\n    double* data1;\n    if (isart) { // data may not be contiguous\n      data1 = contiguous_art_data(ml->data, n, sz); // delete after use\n      nodeindices = NULL;\n    }else{\n      nodeindices = ml->nodeindices; // allocated below if copy\n      data1 = ml->data[0]; // do not delete after use\n    }\n    if (copy) {\n      if (!isart) {\n        nodeindices = (int*)emalloc(n*sizeof(int));\n        for (int i=0; i < n; ++i) {\n          nodeindices[i] = ml->nodeindices[i];\n        }\n      }\n      int nn = n*sz;\n      for (int i = 0; i < nn; ++i) {\n        data[i] = data1[i];\n      }\n      if (isart) {\n        delete [] data1;\n      }\n    }else{\n      data = data1;\n    }\n\n    sz = bbcore_dparam_size[type]; // nrn_prop_dparam_size off by 1 if cvode_ieq.\n    if (sz) {\n      int* pdata1;\n      pdata1 = datum2int(type, ml, nt, cg, cg.datumindices[dsz_inst], vdata_offset);\n      if (copy) {\n        int nn = n*sz;\n        for (int i=0; i < nn; ++i) {\n          pdata[i] = pdata1[i];\n        }\n        delete [] pdata1;\n      }else{\n        pdata = pdata1;\n      }\n    }else{\n      pdata = NULL;\n    }\n\n    return 1;\n}\n\nstatic int nrnthread_dat2_3(int tid, int nweight, int*& output_vindex, double*& output_threshold,\n  int*& netcon_pnttype, int*& netcon_pntindex, double*& weights, double*& delays) {\n\n  if (tid >= nrn_nthread) { return 0; }\n  CellGroup& cg = cellgroups_[tid];\n  NrnThread& nt = nrn_threads[tid];\n\n  output_vindex = new int[cg.n_presyn];\n  output_threshold = new double[cg.n_real_output];\n  for (int i=0; i < cg.n_presyn; ++i) {\n    output_vindex[i] = cg.output_vindex[i];\n  }\n  for (int i=0; i < cg.n_real_output; ++i) {\n    output_threshold[i] = cg.output_ps[i] ? cg.output_ps[i]->threshold_ : 0.0;\n  }\n\n  // connections\n  int n = cg.n_netcon;\n  //printf(\"n_netcon=%d nweight=%d\\n\", n, nweight);\n  netcon_pnttype = cg.netcon_pnttype; cg.netcon_pnttype = NULL;\n  netcon_pntindex = cg.netcon_pntindex; cg.netcon_pntindex = NULL;\n  // alloc a weight array and write netcon weights\n  weights = new double[nweight];\n  int iw = 0;\n  for (int i=0; i < n; ++ i) {\n    NetCon* nc = cg.netcons[i];\n    for (int j=0; j < nc->cnt_; ++j) {\n      weights[iw++] = nc->weight_[j];\n    }\n  }\n  // alloc a delay array and write netcon delays\n  delays = new double[n];\n  for (int i=0; i < n; ++ i) {\n    NetCon* nc = cg.netcons[i];\n    delays[i] = nc->delay_;\n  }\n\n  return 1;\n}\n\nstatic int nrnthread_dat2_corepointer(int tid, int& n) {\n\n  if (tid >= nrn_nthread) { return 0; }\n  NrnThread& nt = nrn_threads[tid];\n\n  n = 0;\n  MlWithArt& mla = cellgroups_[tid].mlwithart;\n  for (size_t i = 0; i < mla.size(); ++i) {\n    if (nrn_bbcore_write_[mla[i].first]) {\n      ++n;\n    }\n  }\n\n  return 1;\n}\n\nstatic int nrnthread_dat2_corepointer_mech(int tid, int type,\n int& icnt, int& dcnt, int*& iArray, double*& dArray) {\n\n  if (tid >= nrn_nthread) { return 0; }\n  NrnThread& nt = nrn_threads[tid];\n  CellGroup& cg = cellgroups_[tid];\n  Memb_list* ml = cg.type2ml[type];\n\n      dcnt = 0;\n      icnt = 0;\n      // data size and allocate\n      for (int i = 0; i < ml->nodecount; ++i) {\n        (*nrn_bbcore_write_[type])(NULL, NULL, &dcnt, &icnt, ml->data[i], ml->pdata[i], ml->_thread, &nt);\n      }\n      dArray = NULL;\n      iArray = NULL;\n      if (icnt)\n      {\n        iArray = new int[icnt];\n      }\n      if (dcnt)\n      {\n        dArray = new double[dcnt];\n      }\n      icnt = dcnt = 0;\n      // data values\n      for (int i = 0; i < ml->nodecount; ++i) {\n        (*nrn_bbcore_write_[type])(dArray, iArray, &dcnt, &icnt, ml->data[i], ml->pdata[i], ml->_thread, &nt);\n      }\n\n  return 1;\n}\n\nvoid nrnthread_group_ids(int* grp) {\n  for (int i = 0; i < nrn_nthread; ++i) {\n    grp[i] = cellgroups_[i].group_id;\n  }\n}\n\nvoid write_nrnthread(const char* path, NrnThread& nt, CellGroup& cg) {\n  char fname[1000];\n  if (cg.n_output <= 0) { return; }\n  assert(cg.group_id >= 0);\n  nrn_assert(snprintf(fname, 1000, \"%s/%d_1.dat\", path, cg.group_id) < 1000);\n  FILE* f = fopen(fname, \"wb\");\n  if (!f) {\n    hoc_execerror(\"nrnbbcore_write write_nrnthread could not open for writing:\", fname);\n  }\n  fprintf(f, \"%s\\n\", bbcore_write_version);\n\n  //nrnthread_dat1(int tid, int& n_presyn, int& n_netcon, int*& output_gid, int*& netcon_srcgid);\n  fprintf(f, \"%d npresyn\\n\", cg.n_presyn);\n  fprintf(f, \"%d nnetcon\\n\", cg.n_netcon);\n  writeint(cg.output_gid, cg.n_presyn);\n  writeint(cg.netcon_srcgid, cg.n_netcon);\n\n  if (cg.output_gid) {delete [] cg.output_gid; cg.output_gid = NULL; }\n  if (cg.netcon_srcgid) {delete [] cg.netcon_srcgid; cg.netcon_srcgid = NULL; }\n  fclose(f);\n\n  nrn_assert(snprintf(fname, 1000, \"%s/%d_2.dat\", path, cg.group_id) < 1000);\n  f = fopen(fname, \"w\");\n  if (!f) {\n    hoc_execerror(\"nrnbbcore_write write_nrnthread could not open for writing:\", fname);\n  }\n\n  fprintf(f, \"%s\\n\", bbcore_write_version);\n\n  // sizes and total data count\n  int ngid, n_real_gid, nnode, ndiam, nmech, *tml_index, *ml_nodecount, nidata,\n    nvdata, nweight;\n  nrnthread_dat2_1(nt.id, ngid, n_real_gid, nnode, ndiam,\n    nmech, tml_index, ml_nodecount, nidata, nvdata, nweight);\n\n  fprintf(f, \"%d ngid\\n\", ngid);\n  fprintf(f, \"%d n_real_gid\\n\", n_real_gid);\n  fprintf(f, \"%d nnode\\n\", nnode);\n  fprintf(f, \"%d ndiam\\n\", ndiam);\n  fprintf(f, \"%d nmech\\n\", nmech);\n\n  for (int i=0; i < nmech; ++i) {\n    fprintf(f, \"%d\\n\", tml_index[i]);\n    fprintf(f, \"%d\\n\", ml_nodecount[i]);\n  }\n  delete [] tml_index;\n  delete [] ml_nodecount;\n\n  fprintf(f, \"%d nidata\\n\", 0);\n  fprintf(f, \"%d nvdata\\n\", nvdata);\n  fprintf(f, \"%d nweight\\n\", nweight);\n\n  // data\n  int *v_parent_index=NULL; double *a=NULL, *b=NULL, *area=NULL, *v=NULL, *diamvec=NULL;\n  nrnthread_dat2_2(nt.id, v_parent_index, a, b, area, v, diamvec);\n  assert(cg.n_real_output == nt.ncell);\n  writeint(nt._v_parent_index, nt.end);\n  writedbl(nt._actual_a, nt.end);\n  writedbl(nt._actual_b, nt.end);\n  writedbl(nt._actual_area, nt.end);\n  writedbl(nt._actual_v, nt.end);\n  if (cg.ndiam) {\n    writedbl(diamvec, nt.end);\n    delete [] diamvec;\n  }\n\n  // mechanism data\n  int dsz_inst = 0;\n  MlWithArt& mla = cg.mlwithart;\n  for (size_t i = 0; i < mla.size(); ++i) {\n    int type = mla[i].first;\n    int *nodeindices=NULL, *pdata=NULL; double* data=NULL;\n    nrnthread_dat2_mech(nt.id, i, dsz_inst, nodeindices, data, pdata);\n    Memb_list* ml = mla[i].second;\n    int n = ml->nodecount;\n    int sz = nrn_prop_param_size_[type];\n    if (nodeindices) {\n      writeint(nodeindices, n);\n    }\n    writedbl(data, n * sz);\n    if (nrn_is_artificial_[type]) {\n      delete [] data;\n    }\n    sz = bbcore_dparam_size[type];\n    if (pdata) {\n      ++dsz_inst;\n      writeint(pdata, n * sz);\n      delete [] pdata;\n    }\n  }\n\n  int *output_vindex, *netcon_pnttype, *netcon_pntindex;\n  double *output_threshold, *weights, *delays;\n  nrnthread_dat2_3(nt.id, nweight, output_vindex, output_threshold,\n    netcon_pnttype, netcon_pntindex, weights, delays);\n  writeint(output_vindex, cg.n_presyn);\n  writedbl(output_threshold, cg.n_real_output);\n  delete [] output_threshold;\n\n  // connections\n  int n = cg.n_netcon;\n//printf(\"n_netcon=%d nweight=%d\\n\", n, nweight);\n  writeint(netcon_pnttype, n);\n  delete [] netcon_pnttype;\n  writeint(netcon_pntindex, n);\n  delete [] netcon_pntindex;\n  writedbl(weights, nweight);\n  delete [] weights;\n  writedbl(delays, n);\n  delete [] delays;\n\n  // special handling for BBCOREPOINTER\n  // how many mechanisms require it\n  nrnthread_dat2_corepointer(nt.id, n);\n  fprintf(f, \"%d bbcorepointer\\n\", n);\n  // for each of those, what is the mech type and data size\n  // and what is the data\n  for (size_t i = 0; i < mla.size(); ++i) {\n    int type = mla[i].first;\n    if (nrn_bbcore_write_[type]) {\n      int icnt, dcnt, *iArray; double* dArray;\n      nrnthread_dat2_corepointer_mech(nt.id, type, icnt, dcnt, iArray, dArray);\n      fprintf(f, \"%d\\n\", type);\n      fprintf(f, \"%d\\n%d\\n\", icnt, dcnt);\n      if (icnt) {\n        writeint(iArray, icnt);\n        delete [] iArray;\n      }\n      if (dcnt) \n      {\n        writedbl(dArray, dcnt);\n        delete [] dArray;\n      }\n    }\n  }\n\n  nrnbbcore_vecplay_write(f, nt);\n\n  fclose(f);\n}\n\n\n/** Write all dataset ids to files.dat.\n *\n * Format of the files.dat file is:\n *\n *     version string\n *     -1 (if model uses gap junction)\n *     n (number of datasets)\n *     id1\n *     id2\n *     ...\n *     idN\n */\nvoid write_nrnthread_task(const char* path, CellGroup* cgs)\n{\n  // ids of datasets that will be created\n  std::vector<int> iSend;\n\n  // ignore empty nrnthread (has -1 id)\n  for (int iInt = 0; iInt < nrn_nthread; ++iInt)\n  {\n    if ( cgs[iInt].group_id >= 0) {\n        iSend.push_back(cgs[iInt].group_id);\n    }\n  }\n\n  // receive and displacement buffers for mpi\n  std::vector<int> iRecv, iDispl;\n\n  if (nrnmpi_myid == 0)\n  {\n    iRecv.resize(nrnmpi_numprocs);\n    iDispl.resize(nrnmpi_numprocs);\n  }\n\n  // number of datasets on the current rank\n  int num_datasets = iSend.size();\n\n#ifdef NRNMPI\n  // gather number of datasets from each task\n  if (nrnmpi_numprocs > 1) {\n    nrnmpi_int_gather(&num_datasets, begin_ptr(iRecv), 1, 0);\n  }else{\n    iRecv[0] = num_datasets;\n  }\n#else\n  iRecv[0] = num_datasets;\n#endif\n\n  // total number of datasets across all ranks\n  int iSumThread = 0;\n\n  // calculate mpi displacements\n  if (nrnmpi_myid == 0)\n  {\n    for (int iInt = 0; iInt < nrnmpi_numprocs; ++iInt)\n    {\n      iDispl[iInt] = iSumThread;\n      iSumThread += iRecv[iInt];\n    }\n  }\n\n  // buffer for receiving all dataset ids\n  std::vector<int> iRecvVec(iSumThread);\n\n#ifdef NRNMPI\n  // gather ids into the array with correspondent offsets\n  if (nrnmpi_numprocs > 1) {\n    nrnmpi_int_gatherv(begin_ptr(iSend), num_datasets, begin_ptr(iRecvVec), begin_ptr(iRecv), begin_ptr(iDispl), 0);\n  }else{\n    for (int iInt = 0; iInt < num_datasets; ++iInt)\n    {\n      iRecvVec[iInt] = iSend[iInt];\n    }\n  }\n#else\n  for (int iInt = 0; iInt < num_datasets; ++iInt)\n  {\n    iRecvVec[iInt] = iSend[iInt];\n  }\n#endif\n\n  /// Writing the file with task, correspondent number of threads and list of correspondent first gids\n  if (nrnmpi_myid == 0)\n  {\n    std::stringstream ss;\n    ss << path << \"/files.dat\";\n\n    std::string filename = ss.str();\n\n    FILE *fp = fopen(filename.c_str(), \"w\");\n    if (!fp) {\n      hoc_execerror(\"nrnbbcore_write write_nrnthread_task could not open for writing:\", filename.c_str());\n    }\n\n    fprintf(fp, \"%s\\n\", bbcore_write_version);\n\n    // notify coreneuron that this model involves gap junctions\n    if (nrnthread_v_transfer_) {\n      fprintf(fp, \"-1\\n\");\n    }\n\n    // total number of datasets\n    fprintf(fp, \"%d\\n\", iSumThread);\n\n    // write all dataset ids\n    for (int i = 0; i < iRecvVec.size(); ++i)\n    {\n        fprintf(fp, \"%d\\n\", iRecvVec[i]);\n    }\n\n    fclose(fp);\n  }\n\n}\n\n\nint* datum2int(int type, Memb_list* ml, NrnThread& nt, CellGroup& cg, DatumIndices& di, int ml_vdata_offset) {\n  int isart = nrn_is_artificial_[di.type];\n  int sz = bbcore_dparam_size[type];\n  int* pdata = new int[ml->nodecount * sz];\n  for (int i=0; i < ml->nodecount; ++i) {\n    Datum* d = ml->pdata[i];\n    int ioff = i*sz;\n    for (int j = 0; j < sz; ++j) {\n      int jj = ioff + j;\n      int etype = di.ion_type[jj];\n      int eindex = di.ion_index[jj];\n      if (etype == -1) {\n        if (isart) {\n          pdata[jj] = -1; // maybe save this space eventually. but not many of these in bb models\n        }else{\n          pdata[jj] = eindex;\n        }\n      }else if (etype == -9) {\n        pdata[jj] = eindex;\n      }else if (etype > 0 && etype < 1000){//ion pointer and also POINTER\n        pdata[jj] = eindex;\n      }else if (etype > 1000 && etype < 2000) { //ionstyle can be explicit instead of pointer to int*\n        pdata[jj] = eindex;\n      }else if (etype == -2) { // an ion and this is the iontype\n        pdata[jj] = eindex;\n      }else if (etype == -4) { // netsend (_tqitem)\n        pdata[jj] = ml_vdata_offset + eindex;\n        //printf(\"etype %d jj=%d eindex=%d pdata=%d\\n\", etype, jj, eindex, pdata[jj]);\n      }else if (etype == -6) { // pntproc\n        pdata[jj] = ml_vdata_offset + eindex;\n        //printf(\"etype %d jj=%d eindex=%d pdata=%d\\n\", etype, jj, eindex, pdata[jj]);\n      }else if (etype == -7) { // bbcorepointer\n        pdata[jj] = ml_vdata_offset + eindex;\n        //printf(\"etype %d jj=%d eindex=%d pdata=%d\\n\", etype, jj, eindex, pdata[jj]);\n      }else if (etype == -5) { // POINTER to voltage\n        pdata[jj] = eindex;\n        //printf(\"etype %d\\n\", etype);\n      }else{ //uninterpreted\n        assert(eindex != -3); // avoided if last\n        pdata[jj] = 0;\n      }\n    }\n  }\n  return pdata;\n}\n\n\n/** @brief Count number of unique elements in the array.\n *  there is a copy of the vector but we are primarily\n *  using it for small section list vectors.\n */\nint count_distinct(double *data, int len) {\n    if( len == 0)\n        return 0;\n    std::vector<double> v;\n    v.assign(data, data + len);\n    std::sort(v.begin(), v.end());\n    return std::unique(v.begin(), v.end()) - v.begin();\n}\n\n/** @brief For BBP use case, we want to write section-segment\n *  mapping to gid_3.dat file. This information will be\n *  provided through neurodamus HOC interface with following\n *  format:\n *      gid : number of non-empty neurons in the cellgroup\n *      name : name of section list (like soma, axon, apic)\n *      nsec : number of sections\n *      sections : list of sections\n *      segments : list of segments\n */\nvoid nrnbbcore_register_mapping() {\n\n    // gid of a cell\n    int gid = *hoc_getarg(1);\n\n    // name of section list\n    std::string name = std::string(hoc_gargstr(2));\n\n    // hoc vectors: sections and segments\n    Vect* sec = vector_arg(3);\n    Vect* seg = vector_arg(4);\n\n    double* sections  = vector_vec(sec);\n    double* segments  = vector_vec(seg);\n\n    int nsec = vector_capacity(sec);\n    int nseg = vector_capacity(seg);\n\n    if( nsec != nseg ) {\n        std::cout << \"Error: Section and Segment mapping vectors should have same size!\\n\";\n        abort();\n    }\n\n    // number of unique sections\n    nsec = count_distinct(sections, nsec);\n\n    SecMapping *smap = new SecMapping(nsec, name);\n    smap->sections.assign(sections, sections+nseg);\n    smap->segments.assign(segments, segments+nseg);\n\n    // store mapping information\n    mapinfo.add_sec_mapping(gid, smap);\n}\n\n/** @brief dump mapping information to gid_3.dat file */\nvoid nrn_write_mapping_info(const char *path, int gid, NrnMappingInfo &minfo) {\n\n    /** full path of mapping file */\n    std::stringstream ss;\n    ss << path << \"/\" << gid << \"_3.dat\";\n\n    std::string fname(ss.str());\n    FILE *f = fopen(fname.c_str(), \"w\");\n\n    if (!f) {\n        hoc_execerror(\"nrnbbcore_write could not open for writing:\", fname.c_str());\n    }\n\n    fprintf(f, \"%s\\n\", bbcore_write_version);\n\n    /** number of gids in NrnThread */\n    fprintf(f, \"%zd\\n\", minfo.size());\n\n    /** all cells mapping information in NrnThread */\n    for(size_t i = 0; i < minfo.size(); i++) {\n        CellMapping *c = minfo.mapping[i];\n\n        /** gid, #section, #compartments,  #sectionlists */\n        fprintf(f, \"%d %d %d %zd\\n\", c->gid, c->num_sections(), c->num_segments(), c->size());\n\n        for(size_t j = 0; j < c->size(); j++) {\n            SecMapping* s = c->secmapping[j];\n            /** section list name, number of sections, number of segments */\n            fprintf(f, \"%s %d %zd\\n\", s->name.c_str(), s->nsec, s->size());\n\n            /** section - segment mapping */\n            if(s->size()) {\n                writeint(&(s->sections.front()), s->size());\n                writeint(&(s->segments.front()), s->size());\n            }\n        }\n    }\n    fclose(f);\n}\n\ntypedef void*(*CNB)(...);\ntypedef struct core2nrn_callback_t {\n  const char* name;\n  CNB f;\n} core2nrn_callback_t;\n\n// from partrans.cpp\nextern \"C\" {\nextern void get_partrans_setup_info(int, int&, int&, int&, int&, int*&, int*&, int*&);\n}\n\nextern \"C\" {\nvoid nrnthread_get_trajectory_requests(int tid, int& bsize, int& ntrajec, void**& vpr, int*& types, int*& indices, double**& pvars, double**& varrays);\nvoid nrnthread_trajectory_values(int tid, int n_pr, void** vpr, double t);\nvoid nrnthread_trajectory_return(int tid, int n_pr, int vecsz, void** vpr, double t);\n}\n\nstatic core2nrn_callback_t cnbs[]  = {\n  {\"nrn2core_group_ids_\", (CNB)nrnthread_group_ids},\n  {\"nrn2core_mkmech_info_\", (CNB)write_memb_mech_types_direct},\n  {\"nrn2core_get_global_dbl_item_\", (CNB)get_global_dbl_item},\n  {\"nrn2core_get_global_int_item_\", (CNB)get_global_int_item},\n  {\"nrn2core_get_partrans_setup_info_\", (CNB)get_partrans_setup_info},\n  {\"nrn2core_get_dat1_\", (CNB)nrnthread_dat1},\n  {\"nrn2core_get_dat2_1_\", (CNB)nrnthread_dat2_1},\n  {\"nrn2core_get_dat2_2_\", (CNB)nrnthread_dat2_2},\n  {\"nrn2core_get_dat2_mech_\", (CNB)nrnthread_dat2_mech},\n  {\"nrn2core_get_dat2_3_\", (CNB)nrnthread_dat2_3},\n  {\"nrn2core_get_dat2_corepointer_\", (CNB)nrnthread_dat2_corepointer},\n  {\"nrn2core_get_dat2_corepointer_mech_\", (CNB)nrnthread_dat2_corepointer_mech},\n  {\"nrn2core_get_dat2_vecplay_\", (CNB)nrnthread_dat2_vecplay},\n  {\"nrn2core_get_dat2_vecplay_inst_\", (CNB)nrnthread_dat2_vecplay_inst},\n  {\"nrn2core_part2_clean_\", (CNB)part2_clean},\n\n  {\"nrn2core_get_trajectory_requests_\", (CNB)nrnthread_get_trajectory_requests},\n  {\"nrn2core_trajectory_values_\", (CNB)nrnthread_trajectory_values},\n  {\"nrn2core_trajectory_return_\", (CNB)nrnthread_trajectory_return},\n  {NULL, NULL}\n};\n\n#if defined(HAVE_DLFCN_H)\n\nextern int nrn_use_fast_imem;\nextern char* neuron_home;\n\n/** Check if coreneuron is loaded into memory */\nbool is_coreneuron_loaded() {\n    bool is_loaded = false;\n    // check if corenrn_version symbol can be found\n    void * handle = dlopen(NULL, RTLD_NOW | RTLD_GLOBAL);\n    if (handle) {\n        void* fn = dlsym(handle, \"corenrn_version\");\n        is_loaded = fn == NULL ? false : true;\n        dlclose(handle);\n    }\n    return is_loaded;\n}\n\n/** Check if file with given path exist */\nbool file_exist(const std::string& path) {\n    std::ifstream f(path.c_str());\n    return f.good();\n}\n\n/** Open library with given path and return dlopen handle **/\nvoid* get_handle_for_lib(const char* path) {\n    void* handle = dlopen(path, RTLD_NOW|RTLD_GLOBAL);\n    if (!handle) {\n      fputs(dlerror(), stderr);\n      fputs(\"\\n\", stderr);\n      hoc_execerror(\"Could not dlopen CoreNEURON mechanism library : \", path);\n    }\n    return handle;\n}\n\n/** Get CoreNEURON mechanism library */\nvoid* get_coreneuron_handle() {\n\t// if already loaded into memory, directly return handle\n\tif (is_coreneuron_loaded()) {\n\t\treturn dlopen(NULL, RTLD_NOW|RTLD_GLOBAL);\n\t}\n\n\t// env variable get highest preference\n\tconst char* corenrn_lib = getenv(\"CORENEURONLIB\");\n\tif (corenrn_lib && file_exist(corenrn_lib)) {\n\t\treturn get_handle_for_lib(corenrn_lib);\n\t}\n\n\t// name of coreneuron library based on platform\n\t#if defined(MINGW)\n\tstd::string corenrn_mechlib_name(\"libcorenrnmech.dll\");\n\t#elif defined(DARWIN)\n\tstd::string corenrn_mechlib_name(\"libcorenrnmech.dylib\");\n\t#else\n\tstd::string corenrn_mechlib_name(\"libcorenrnmech.so\");\n\t#endif\n\n\t// first check if coreneuron specific library exist in <arch>/.libs\n\t// note that we need to get full path especially for OSX\n\tchar pwd[FILENAME_MAX];\n\tgetcwd(pwd, FILENAME_MAX);\n\n\tstd::stringstream s_path;\n\ts_path << pwd << \"/\" << NRNHOSTCPU << \"/\" << corenrn_mechlib_name;\n\tstd::string path = s_path.str();\n\n\tif (file_exist(path)) {\n\t\treturn get_handle_for_lib(path.c_str());\n\t}\n\n\t// last fallback is minimal library with internal mechanisms\n\ts_path.str(\"\");\n\t#if defined(MINGW)\n\ts_path << neuron_home << \"/lib/\" << corenrn_mechlib_name;\n\t#else\n\ts_path << neuron_home << \"/../../lib/\" << corenrn_mechlib_name;\n\t#endif\n\tpath = s_path.str();\n\n\t// if this last path doesn't exist then it's an error\n\tif (!file_exist(path)) {\n        hoc_execerror(\"Could not find CoreNEURON library\", NULL);\n\t}\n\n\treturn get_handle_for_lib(path.c_str());\n}\n\n/** Check if neuron & coreneuron are compatible */\nvoid check_coreneuron_compatibility(void* handle) {\n    // get handle to function in coreneuron\n    void* cn_version_sym = dlsym(handle, \"corenrn_version\");\n    if (!cn_version_sym) {\n      hoc_execerror(\"Could not get symbol corenrn_version from CoreNEURON\", NULL);\n    }\n    // call coreneuron function and get version string\n    const char* cn_bbcore_read_version = (*(const char*(*)())cn_version_sym)();\n\n    // make sure neuron and coreneuron version are same; otherwise throw an error\n    if (strcmp(bbcore_write_version, cn_bbcore_read_version) != 0) {\n      std::stringstream s_path;\n      s_path << bbcore_write_version << \" vs \" << cn_bbcore_read_version;\n      hoc_execerror(\"Incompatible NEURON and CoreNEURON versions :\", s_path.str().c_str());\n    }\n}\n\n/** Populate function pointers by mapping function pointers for callback */\nvoid map_coreneuron_callbacks(void* handle) {\n    for (int i=0; cnbs[i].name; ++i) {\n        void* sym = dlsym(handle, cnbs[i].name);\n        if (!sym) {\n            fprintf(stderr, \"Could not get symbol %s from CoreNEURON\\n\", cnbs[i].name);\n            hoc_execerror(\"dlsym returned NULL\", NULL);\n        }\n        void** c = (void**)sym;\n        *c = (void*)(cnbs[i].f);\n    }\n}\n\n/** Launch CoreNEURON in direct memory mode */\nint nrncore_run(const char* arg) {\n    // using direct memory mode\n    corenrn_direct = true;\n\n    // check that model can be transferred\n    model_ready();\n\n    // get coreneuron library handle\n    void* handle = get_coreneuron_handle();\n\n    // make sure coreneuron & neuron are compatible\n    check_coreneuron_compatibility(handle);\n\n    // setup the callback functions between neuron & coreneuron\n    map_coreneuron_callbacks(handle);\n\n    // lookup symbol from coreneuron for launching\n    void* launcher_sym = dlsym(handle, \"corenrn_embedded_run\");\n    if (!launcher_sym) {\n        hoc_execerror(\"Could not get symbol corenrn_embedded_run from\", NULL);\n    }\n\n    // prepare the model\n    part1();\n\n    int have_gap = nrnthread_v_transfer_ ? 1 : 0;\n#if !NRNMPI\n#define nrnmpi_use 0\n#endif\n\n    // typecast function pointer pointer\n    int (*coreneuron_launcher)(int, int, int, int, const char*) = (int (*)(int, int, int, int, const char*))launcher_sym;\n\n    // launch coreneuron\n    int result = coreneuron_launcher(nrn_nthread, have_gap, nrnmpi_use, nrn_use_fast_imem, arg);\n\n    // close handle and return result\n    dlclose(handle);\n    return result;\n}\n\n/** Return neuron.coreneuron.enable */\nint nrncore_is_enabled() {\n  if (nrnpy_nrncore_enable_value_p_) {\n    int b = (*nrnpy_nrncore_enable_value_p_)();\n    return b;\n  }\n  return 0;\n}\n\n/** Run coreneuron with arg string from neuron.coreneuron.nrncore_arg(tstop)\n *  Return 0 on success\n*/\nint nrncore_psolve(double tstop) {\n  if (nrnpy_nrncore_arg_p_) {\n    char* arg = (*nrnpy_nrncore_arg_p_)(tstop);\n    if (arg) {\n      nrncore_run(arg);\n      free(arg);\n      return 0;\n    }\n  }\n  return -1;\n}\n\n#else // !HAVE_DLFCN_H\n\nint nrncore_run(const char*) {\n  return -1;\n}\n\nint nrncore_is_enabled() {\n  return 0;\n}\n\nint nrncore_psolve(double tstop) {\n  return 0;\n}\n\n#endif //!HAVE_DLFCN_H\n\n} // end of extern \"C\"\n",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/src/nrnmpi/nrnmpi_dynam.c": "#include <../../nrnconf.h>\n#include \"nrnmpiuse.h\"\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <errno.h>\n#include <assert.h>\n\n#if NRNMPI_DYNAMICLOAD /* to end of file */\n\n#ifdef MINGW\n#define RTLD_NOW 0\n#define RTLD_GLOBAL 0\n#define RTLD_NOLOAD 0\nextern void* dlopen_noerr(const char* name, int mode);\n#define dlopen dlopen_noerr\nextern void* dlsym(void* handle, const char* name);\nextern int dlclose(void* handle);\nextern char* dlerror();\n#else\n#include <dlfcn.h>\n#endif\n\n#include \"nrnmpi.h\"\n\nextern char* cxx_char_alloc(int);\n\n#if DARWIN || defined(__linux__)\nextern const char* path_prefix_to_libnrniv();\n#endif\n\n#include \"mpispike.h\"\n#include \"nrnmpi_def_cinc\" /* nrnmpi global variables */\n#include \"nrnmpi_dynam_cinc\" /* autogenerated file */\n#include \"nrnmpi_dynam_wrappers.inc\" /* autogenerated file */\n#include \"nrnmpi_dynam_stubs.c\"\n\nstatic void* load_mpi(const char* name, char* mes) {\n\tint flag = RTLD_NOW | RTLD_GLOBAL;\n\tvoid* handle = dlopen(name, flag);\n\tif (!handle) {\n\t\tsprintf(mes, \"load_mpi: %s\\n\", dlerror());\n\t}else{\n\t\tsprintf(mes, \"load_mpi: %s successful\\n\", name);\n\t}\n\treturn handle;\n}\n\nstatic void* load_nrnmpi(const char* name, char* mes) {\n\tint i;\n\tint flag = RTLD_NOW | RTLD_GLOBAL;\n\tvoid* handle = dlopen(name, flag);\n\tif (!handle) {\n\t\tsprintf(mes, \"load_nrnmpi: %s\\n\", dlerror());\n\t\treturn 0;\n\t}\t\n\tsprintf(mes, \"load_nrnmpi: %s successful\\n\", name);\n\tfor (i = 0; ftable[i].name; ++i) {\n\t\tvoid* p = dlsym(handle, ftable[i].name);\n\t\tif (!p) {\n\t\t\tsprintf(mes+strlen(mes), \"load_nrnmpi: %s\\n\", dlerror());\n\t\t\treturn 0;\n\t\t}\t\n\t\t*ftable[i].ppf = p;\n\t}\n\t{\n\t\tchar* (**p)(int) = (char* (**)(int))dlsym(handle, \"p_cxx_char_alloc\");\n\t\tif (!p) {\n\t\t\tsprintf(mes+strlen(mes), \"load_nrnmpi: %s\\n\", dlerror());\n\t\t\treturn 0;\n\t\t}\n\t\t*p = cxx_char_alloc;\n\t}\n\treturn handle;\n}\n\nchar* nrnmpi_load(int is_python) {\n\tint ismes=0;\n\tchar* pmes;\n\tvoid* handle = NULL;\n\tpmes = (char*)malloc(4096);\n\tassert(pmes);\n\tpmes[0]='\\0';\n#if DARWIN\n\tsprintf(pmes, \"Try loading libmpi\\n\");\n\thandle = load_mpi(\"libmpi.dylib\", pmes+strlen(pmes));\n    /**\n     * If libmpi.dylib is not in the standard location and dlopen fails\n     * then try to use user provided or ctypes.find_library() provided\n     * mpi library path.\n     */\n    if(!handle) {\n        const char* mpi_lib_path = getenv(\"MPI_LIB_NRN_PATH\");\n        if (mpi_lib_path) {\n            handle = load_mpi(mpi_lib_path, pmes+strlen(pmes));\n            if (!handle) {\n                sprintf(pmes, \"Can not load libmpi.dylib and %s\", mpi_lib_path);\n            }\n        }\n    }\n#if defined(NRNCMAKE)\n\tif (handle) {\n\t\t/* loaded but is it openmpi or mpich */\n\t\tif (dlsym(handle, \"ompi_mpi_init\")) { /* it is openmpi */\n\t\t/* see man dyld */\n\t\t\tif (!load_nrnmpi(\"@loader_path/libnrnmpi_ompi.dylib\", pmes+strlen(pmes))) {\n\t\t\t\treturn pmes;\n\t\t\t}\n\t\t}else{ /* must be mpich. Could check for MPID_nem_mpich_init...*/\n\t\t\tif (!load_nrnmpi(\"@loader_path/libnrnmpi_mpich.dylib\", pmes+strlen(pmes))) {\n\t\t\t\treturn pmes;\n\t\t\t}\n\t\t}\n\t}else{\n\t\tismes = 1;\nsprintf(pmes+strlen(pmes), \"Is openmpi or mpich installed? If not in default location, \"\n                           \"need a LD_LIBRARY_PATH on Linux or DYLD_LIBRARY_PATH on Mac OS. \"\n                           \"On Mac OS, full path to a MPI library can be provided via \"\n                           \"environmental variable MPI_LIB_NRN_PATH\\n\");\n\t}\n#else /* autotools has only a libnrnmpi that is likely only for openmpi */\n\tif (handle) {\n\t\tif (!load_nrnmpi(\"@loader_path/libnrnmpi.dylib\", pmes+strlen(pmes))) {\n\t\t\treturn pmes;\n\t\t}\n\t}else{\n\t\tismes = 1;\nsprintf(pmes+strlen(pmes), \"Is openmpi installed? If not in default location, need a LD_LIBRARY_PATH.\\n\");\n\t}\n#endif /* not defined (NRNCMAKE) */\n#else /*not DARWIN*/\n#if defined(MINGW)\n\tsprintf(pmes, \"Try loading msmpi\\n\");\n\thandle = load_mpi(\"msmpi.dll\", pmes+strlen(pmes));\n\tif (handle) {\n#if defined(NRNCMAKE)\n\t\tif (!load_nrnmpi(\"libnrnmpi_msmpi.dll\", pmes+strlen(pmes))){\n#else\n\t\tif (!load_nrnmpi(\"libnrnmpi.dll\", pmes+strlen(pmes))){\n#endif\n\t\t\treturn pmes;\n\t\t}\n\t}else{\n\t\tismes = 1;\n\t\treturn pmes;\n\t}\n#else /*not MINGW so must be __linux__*/\n\n\t/**\n\t * libmpi.so is not standard but used by most of the implemenntation\n\t * (mpich, openmpi, intel-mpi, parastation-mpi, hpe-mpt) but not cray-mpich.\n\t * we first load libmpi and then libmpich.so as a fallaback for cray system.\n\t */\n\tsprintf(pmes, \"Try loading libmpi\\n\");\n\thandle = load_mpi(\"libmpi.so\", pmes+strlen(pmes));\n\tif (!handle) {\n\t    sprintf(pmes, \"Try loading libmpi and libmpich\\n\");\n\t    handle = load_mpi(\"libmpich.so\", pmes+strlen(pmes));\n\t}\n\n#if defined(NRNCMAKE)\n\tif (handle) {\n\t\t/* with CMAKE the problem of Python launch on LINUX not resolving\n\t\t   variables from already loaded shared libraries has returned.\n\t\t*/\n\t\tif (!dlopen(\"libnrniv.so\", RTLD_NOW | RTLD_NOLOAD | RTLD_GLOBAL)) {\n\t\t\tfprintf(stderr, \"Did not promote libnrniv.so to RTLD_GLOBAL: %s\\n\", dlerror());\n\t\t}\n\n\t\t/* safest to use full path for libnrnmpi... */\n\t\tconst char* prefix = path_prefix_to_libnrniv();\n\t\t/* enough space for prefix + \"libnrnmpi...\" */\n\t\tchar* lname = malloc(strlen(prefix) + 50);\n\t\tassert(lname);\n\t\t/* loaded but is it openmpi or mpich */\n\t\tif (dlsym(handle, \"ompi_mpi_init\")) { /* it is openmpi */\n\t\t\tsprintf(lname, \"%slibnrnmpi_ompi.so\", prefix);\n\t\t}else if (dlsym(handle, \"MPI_SGI_init\")) { /* it is sgi-mpt */\n\t\t\tsprintf(lname, \"%slibnrnmpi_mpt.so\", prefix);\n\t\t}else{ /* must be mpich. Could check for MPID_nem_mpich_init...*/\n\t\t\tsprintf(lname, \"%slibnrnmpi_mpich.so\", prefix);\n\t\t}\n\t\tif (!load_nrnmpi(lname, pmes+strlen(pmes))) {\n\t\t\tfree(lname);\n\t\t\treturn pmes;\n\t\t}\n\t\tfree(lname);\n\t}else{\n\t\tismes = 1;\nsprintf(pmes+strlen(pmes), \"Is openmpi, mpich, intel-mpi, sgi-mpt etc. installed? If not in default location, need a LD_LIBRARY_PATH.\\n\");\n\t}\n#else /* autotools */\n\tif (handle){\n\t\tif (!load_nrnmpi(NRN_LIBDIR\"/libnrnmpi.so\", pmes+strlen(pmes))){\n\t\t\treturn pmes;\n\t\t}\n\t}else{\n\t\tsprintf(pmes+strlen(pmes), \"Try loading mpich2\\n\");\n\t\thandle = load_mpi(\"libmpl.so\", pmes+strlen(pmes));\n\t\thandle = load_mpi(\"libmpich.so\", pmes+strlen(pmes));\n#if 0\n/* Not needed because the issue of Python launch on LINUX not resolving\n   variables from already loaded shared libraries (due to loading them with\n   RTLD_LOCAL) was solved at the src/nrnmpi/Makefile.am level via a change\n   to libnrnmpi_la_LIBADD\n*/\nif (!dlopen(\"liboc.so\", RTLD_NOW | RTLD_NOLOAD | RTLD_GLOBAL)) {\n\tfprintf(stderr, \"Did not promote liboc.so to RTLD_GLOBAL: %s\\n\", dlerror());\n}\nif (!dlopen(\"libnrniv.so\", RTLD_NOW | RTLD_NOLOAD | RTLD_GLOBAL)) {\n\tfprintf(stderr, \"Did not promote libnrniv.so to RTLD_GLOBAL: %s\\n\", dlerror());\n}\n#endif\n\t\tif(!load_nrnmpi(\"libnrnmpi.so\", pmes+strlen(pmes))){\n\t\t\treturn pmes;\n\t\t}\n\t}\n#endif /* not NRNCMAKE */\n#endif /*not MINGW*/\n#endif /* not DARWIN */\n\tif (!handle) {\n\t\tsprintf(pmes+strlen(pmes), \"could not dynamically load libmpi.so or libmpich.so\\n\");\n\t\treturn pmes;\n\t}\t\n\tfree(pmes);\n\treturn 0;\n}\n#endif\n",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/nmodl/src/pybind/pyembed.cpp": "/*************************************************************************\n * Copyright (C) 2018-2019 Blue Brain Project\n *\n * This file is part of NMODL distributed under the terms of the GNU\n * Lesser General Public License. See top-level LICENSE file for details.\n *************************************************************************/\n\n#include <cstdlib>\n#include <dlfcn.h>\n\n#include \"pybind/pyembed.hpp\"\n#include \"utils/logger.hpp\"\n\nnamespace nmodl {\n\nnamespace pybind_wrappers {\n\nbool EmbeddedPythonLoader::have_wrappers() {\n#if defined(NMODL_STATIC_PYWRAPPER)\n    static auto wrapper_api = nmodl::pybind_wrappers::init_pybind_wrap_api();\n    wrappers = &wrapper_api;\n    return true;\n#else\n    wrappers = static_cast<pybind_wrap_api*>(dlsym(RTLD_DEFAULT, \"nmodl_wrapper_api\"));\n    return wrappers != nullptr;\n#endif\n}\n\nvoid EmbeddedPythonLoader::load_libraries() {\n    const auto pylib_env = std::getenv(\"NMODL_PYLIB\");\n    if (!pylib_env) {\n        logger->critical(\"NMODL_PYLIB environment variable must be set to load embedded python\");\n        throw std::runtime_error(\"NMODL_PYLIB not set\");\n    }\n    const auto dlopen_opts = RTLD_NOW | RTLD_GLOBAL;\n    dlerror();  // reset old error conditions\n    pylib_handle = dlopen(pylib_env, dlopen_opts);\n    if (!pylib_handle) {\n        const auto errstr = dlerror();\n        logger->critical(\"Tried but failed to load {}\", pylib_env);\n        logger->critical(errstr);\n        throw std::runtime_error(\"Failed to dlopen\");\n    }\n    const auto pybind_wraplib_env = std::getenv(\"NMODL_WRAPLIB\");\n    if (!pybind_wraplib_env) {\n        logger->critical(\n            \"NMODL_WRAPLIB environment variable must be set to load the pybind wrapper library\");\n        throw std::runtime_error(\"NMODL_WRAPLIB not set\");\n    }\n    pybind_wrapper_handle = dlopen(pybind_wraplib_env, dlopen_opts);\n    if (!pybind_wrapper_handle) {\n        const auto errstr = dlerror();\n        logger->critical(\"Tried but failed to load {}\", pybind_wraplib_env);\n        logger->critical(errstr);\n        throw std::runtime_error(\"Failed to dlopen\");\n    }\n}\n\nvoid EmbeddedPythonLoader::populate_symbols() {\n    wrappers = static_cast<pybind_wrap_api*>(dlsym(pybind_wrapper_handle, \"nmodl_wrapper_api\"));\n    if (!wrappers) {\n        const auto errstr = dlerror();\n        logger->critical(\"Tried but failed to load pybind wrapper symbols\");\n        logger->critical(errstr);\n        throw std::runtime_error(\"Failed to dlsym\");\n    }\n}\n\nvoid EmbeddedPythonLoader::unload() {\n    if (pybind_wrapper_handle) {\n        dlclose(pybind_wrapper_handle);\n    }\n    if (pylib_handle) {\n        dlclose(pylib_handle);\n    }\n}\n\nconst pybind_wrap_api* EmbeddedPythonLoader::api() {\n    return wrappers;\n}\n\n\n}  // namespace pybind_wrappers\n\n}  // namespace nmodl\n",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/iv/src/lib/x11_dynam/ivx11_dynam.cpp": "extern \"C\" {\n\n/* All X11 structures, declarations, etc. */\n/* Do not know if this is needed here. */\n#define XUTIL_DEFINE_FUNCTIONS\n\n/* X11 structures, #define, and pointer definitions corresponding\n * to all extern X globals.\n*/\n#include <IV-X11/ivx11_declare.h>\n#define IVX11EXTERN /**/\n#include <IV-X11/ivx11_define.h>\n\n}\n\n#include <stdio.h>\n#include <dlfcn.h>\n#include <string>\n#include <IV-X11/ivx11_dynam.h>\n\nstatic void (*p_ivx11_assign)();\n\n/** @brief dlopen libivx11dynam.so and call its ivx11_assign.\n *  The library must be in the same directory as the shared library\n *  that contains the address of ivx11_dyload.\n */\nint ivx11_dyload() { // return 0 on success\n  /* only load once */\n  if (p_ivx11_assign) {\n    return 0;\n  }\n\n  /* see if ivx11_assign already loaded and if so use that */\n  p_ivx11_assign = (void(*)())dlsym(RTLD_DEFAULT, \"ivx11_assign\");\n  if (p_ivx11_assign) {\n    (*p_ivx11_assign)();\n    return 0;\n  }\n  /* dynamically load libivx11dynam.so and call its ivx11_assign() */\n\n  /* figure out path of libivx11dynam.so\n   * Assumes that library is in the same location as the library containing\n   * this function.\n   */\n  Dl_info info;\n  int rval = dladdr((void*)ivx11_dyload, &info);\n  std::string name;\n  if (rval) {\n    if (info.dli_fname) {\n      name = info.dli_fname;\n      if (info.dli_fname[0] == '/') { // likely full path\n        // dlopen this with RTLD_GLOBAL to make sure the dlopen of libivx11dynam\n        // will get its externs resolved (needed when launch python).\n        if (!dlopen(name.c_str(), RTLD_NOW | RTLD_NOLOAD | RTLD_GLOBAL)) {\n          printf(\"%s: RTLD_GLOBAL for %s\\n\", dlerror(), name.c_str());\n          return -1;\n        }\n\n        /* From the last '/' to the next '.' gets replaced by libivx11dynam */\n        size_t last_slash = name.rfind(\"/\");\n        size_t dot = name.find(\".\", last_slash);\n        if (dot == std::string::npos) {\n            printf(\"Can't determine the basename (last '/' to next '.') in \\\"%s\\\"\\n\", name.c_str());\n            return -1;\n        }\n        size_t len = dot - (last_slash + 1);\n        name.replace(last_slash+1, len, \"libivx11dynam\"); // keeps the .so or .dylib\n      }else{\n        printf(\"Not a full path \\\"%s\\\"\\n\", name.c_str());\n        return -1;\n      }\n    }else{\n      printf(\"dladdr no DL_info.dli_fname\\n\");\n      return -1;\n    }\n  }else{\n    printf(\"%s\\n\", dlerror());\n    return -1;\n  }\n\n  int flag = RTLD_NOW | RTLD_GLOBAL;\n  void* handle = dlopen(name.c_str(), flag);\n  if (!handle) {\n    //be quiet\n    //printf(\"%s: for %s\\n\", dlerror(), name.c_str());\n    return -1;\n  }\n  p_ivx11_assign = (void(*)())dlsym(handle, \"ivx11_assign\");\n  if (p_ivx11_assign) {\n    (*p_ivx11_assign)();\n  }else{\n    return -1;\n  }\n  return 0;\n}\n"
    },
    "skipped": [
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/src/mac/nrngui.icns",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/src/mac/nrniv.icns",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/src/mac/neurondemo.icns",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/src/mac/modlunit.icns",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/src/mac/mos2nrn.icns",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/src/mac/idraw.icns",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/src/mac/mknrndll.icns",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/src/mswin/nmodl2a.ico",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/src/mswin/nrniv10.ico",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/src/mswin/nrniv.ico",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/src/mswin/bin/mkdllbox.bat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/src/mswin/bin/instlzp.bat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/src/mswin/wnrnbbs/ddesrvr.ico",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/.git/objects/pack/pack-aa6b8bee8c7d3a4e64282e3f6d2acabf809a79e3.idx",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/.git/objects/pack/pack-aa6b8bee8c7d3a4e64282e3f6d2acabf809a79e3.pack",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/.git/modules/external/coreneuron/objects/pack/pack-bd68353a3edb46929aed0b2072353c998fd01766.idx",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/.git/modules/external/coreneuron/objects/pack/pack-bd68353a3edb46929aed0b2072353c998fd01766.pack",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/.git/modules/external/coreneuron/modules/external/Random123/objects/pack/pack-b5b66c51dc254902cf72f01cf1d62856d7067ee6.pack",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/.git/modules/external/coreneuron/modules/external/Random123/objects/pack/pack-b5b66c51dc254902cf72f01cf1d62856d7067ee6.idx",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/.git/modules/external/coreneuron/modules/external/nmodl/objects/pack/pack-d8c898b1bad86d0f11d25c48d9cfe40f49db0288.pack",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/.git/modules/external/coreneuron/modules/external/nmodl/objects/pack/pack-d8c898b1bad86d0f11d25c48d9cfe40f49db0288.idx",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/.git/modules/external/coreneuron/modules/external/nmodl/modules/ext/fmt/objects/pack/pack-367353b9aa1ef80716473b390b30888368a9ab9e.idx",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/.git/modules/external/coreneuron/modules/external/nmodl/modules/ext/fmt/objects/pack/pack-367353b9aa1ef80716473b390b30888368a9ab9e.pack",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/.git/modules/external/coreneuron/modules/external/nmodl/modules/ext/cli11/objects/pack/pack-98d46907785204ab08d018786bb3b05de7faed45.idx",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/.git/modules/external/coreneuron/modules/external/nmodl/modules/ext/cli11/objects/pack/pack-98d46907785204ab08d018786bb3b05de7faed45.pack",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/.git/modules/external/coreneuron/modules/external/nmodl/modules/ext/cli11/modules/extern/googletest/objects/pack/pack-d1af96735a91529d331daee0a9c9ee8c31f6d2da.idx",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/.git/modules/external/coreneuron/modules/external/nmodl/modules/ext/cli11/modules/extern/googletest/objects/pack/pack-d1af96735a91529d331daee0a9c9ee8c31f6d2da.pack",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/.git/modules/external/coreneuron/modules/external/nmodl/modules/ext/pybind11/objects/pack/pack-e3d331b3b7a31683386b84fd36a1d4d3f034c53c.idx",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/.git/modules/external/coreneuron/modules/external/nmodl/modules/ext/pybind11/objects/pack/pack-e3d331b3b7a31683386b84fd36a1d4d3f034c53c.pack",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/.git/modules/external/coreneuron/modules/external/nmodl/modules/ext/pybind11/modules/tools/clang/objects/pack/pack-7a1f279894ad4c01ef7af9ab88b9f2fc048559a6.idx",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/.git/modules/external/coreneuron/modules/external/nmodl/modules/ext/pybind11/modules/tools/clang/objects/pack/pack-7a1f279894ad4c01ef7af9ab88b9f2fc048559a6.pack",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/.git/modules/external/coreneuron/modules/external/nmodl/modules/ext/eigen/objects/pack/pack-8a950554fa091bf75836cfcddc71902b5fc1822c.pack",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/.git/modules/external/coreneuron/modules/external/nmodl/modules/ext/eigen/objects/pack/pack-8a950554fa091bf75836cfcddc71902b5fc1822c.idx",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/.git/modules/external/coreneuron/modules/external/nmodl/modules/ext/spdlog/objects/pack/pack-59b608580c93092111ab71ce5a0390930f984c60.pack",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/.git/modules/external/coreneuron/modules/external/nmodl/modules/ext/spdlog/objects/pack/pack-59b608580c93092111ab71ce5a0390930f984c60.idx",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/.git/modules/external/coreneuron/modules/external/nmodl/modules/cmake/hpc-coding-conventions/objects/pack/pack-f044489f31787b875dd05b3e4989bc9351640167.idx",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/.git/modules/external/coreneuron/modules/external/nmodl/modules/cmake/hpc-coding-conventions/objects/pack/pack-f044489f31787b875dd05b3e4989bc9351640167.pack",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/.git/modules/external/coreneuron/modules/external/CLI11/objects/pack/pack-98d46907785204ab08d018786bb3b05de7faed45.idx",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/.git/modules/external/coreneuron/modules/external/CLI11/objects/pack/pack-98d46907785204ab08d018786bb3b05de7faed45.pack",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/.git/modules/external/coreneuron/modules/external/CLI11/modules/extern/googletest/objects/pack/pack-d8d7265a7d7eb7f9985925206325110f400ff382.idx",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/.git/modules/external/coreneuron/modules/external/CLI11/modules/extern/googletest/objects/pack/pack-d8d7265a7d7eb7f9985925206325110f400ff382.pack",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/.git/modules/external/coreneuron/modules/external/mod2c/objects/pack/pack-c464cf19c92fa3808845793b5fc8200a6fe21edb.pack",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/.git/modules/external/coreneuron/modules/external/mod2c/objects/pack/pack-c464cf19c92fa3808845793b5fc8200a6fe21edb.idx",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/.git/modules/external/coding-conventions/objects/pack/pack-f044489f31787b875dd05b3e4989bc9351640167.idx",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/.git/modules/external/coding-conventions/objects/pack/pack-f044489f31787b875dd05b3e4989bc9351640167.pack",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/.git/modules/external/catch2/objects/pack/pack-d5c439efd648f912008ae7dd373f712e25e9f0ea.pack",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/.git/modules/external/catch2/objects/pack/pack-d5c439efd648f912008ae7dd373f712e25e9f0ea.idx",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/.git/modules/test/rxd/testdata/objects/pack/pack-c615b48020f2c2d8eac47cbb619fa269d46f6432.pack",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/.git/modules/test/rxd/testdata/objects/pack/pack-c615b48020f2c2d8eac47cbb619fa269d46f6432.idx",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/.git/modules/docs/new_doc/objects/pack/pack-04d128d18076a32445c8b8eb52aeadbb2c3ebd7a.idx",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/.git/modules/docs/new_doc/objects/pack/pack-04d128d18076a32445c8b8eb52aeadbb2c3ebd7a.pack",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/.git/modules/docs/py_doc/objects/pack/pack-ad6da48f67ca62e63160741f372bc5639668ca16.idx",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/.git/modules/docs/py_doc/objects/pack/pack-ad6da48f67ca62e63160741f372bc5639668ca16.pack",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/.git/modules/docs/tutorials/objects/pack/pack-7fbbdbe88315ff70789beea080ec568eebc93db2.pack",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/.git/modules/docs/tutorials/objects/pack/pack-7fbbdbe88315ff70789beea080ec568eebc93db2.idx",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/.git/modules/modules/iv/objects/pack/pack-3a2ec595026a3a2bb9c5394224273c4bc39247da.pack",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/.git/modules/modules/iv/objects/pack/pack-3a2ec595026a3a2bb9c5394224273c4bc39247da.idx",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/share/lib/python/neuron/help_data.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/tests/integration/ring/12_1.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/tests/integration/ring/13_2.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/tests/integration/ring/12_2.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/tests/integration/ring_gap/12_1.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/tests/integration/ring_gap/13_2.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/tests/integration/ring_gap/12_2.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/Random123/docs/html/structr123_1_1AESNI4x32__R.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/Random123/docs/html/ftv2mo.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/Random123/docs/html/ftv2splitbar.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/Random123/docs/html/nav_g.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/Random123/docs/html/ftv2pnode.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/Random123/docs/html/ftv2doc.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/Random123/docs/html/tab_h.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/Random123/docs/html/structr123_1_1AESNI1xm128i.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/Random123/docs/html/tab_s.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/Random123/docs/html/ftv2mlastnode.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/Random123/docs/html/ftv2folderopen.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/Random123/docs/html/tab_a.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/Random123/docs/html/ftv2plastnode.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/Random123/docs/html/ftv2vertline.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/Random123/docs/html/ftv2lastnode.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/Random123/docs/html/sync_on.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/Random123/docs/html/ftv2blank.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/Random123/docs/html/ftv2link.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/Random123/docs/html/nav_f.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/Random123/docs/html/structr123_1_1AESNI4x32.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/Random123/docs/html/tab_b.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/Random123/docs/html/open.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/Random123/docs/html/ftv2folderclosed.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/Random123/docs/html/bdwn.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/Random123/docs/html/bc_s.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/Random123/docs/html/nav_h.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/Random123/docs/html/ftv2ns.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/Random123/docs/html/ftv2cl.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/Random123/docs/html/structr123_1_1AESNI1xm128i__R.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/Random123/docs/html/sync_off.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/Random123/docs/html/ftv2mnode.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/Random123/docs/html/closed.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/Random123/docs/html/doxygen.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/Random123/docs/html/ftv2node.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/Random123/docs/html/search/close.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/Random123/docs/html/search/search_m.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/Random123/docs/html/search/search_r.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/Random123/docs/html/search/mag_sel.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/Random123/docs/html/search/search_l.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/nmodl/ext/fmt/doc/_static/fonts/glyphicons-halflings-regular.woff",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/nmodl/ext/fmt/doc/_static/fonts/glyphicons-halflings-regular.eot",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/nmodl/ext/fmt/doc/_static/fonts/glyphicons-halflings-regular.ttf",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/nmodl/ext/cli11/docs/CLI11_300.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/nmodl/ext/cli11/docs/CLI11_100.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/nmodl/ext/pybind11/docs/pybind11_vs_boost_python1.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/nmodl/ext/pybind11/docs/pybind11-logo.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/nmodl/ext/pybind11/docs/pybind11_vs_boost_python2.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/nmodl/ext/eigen/bench/btl/generic_bench/timers/STL_timer.hh",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/nmodl/ext/eigen/bench/btl/generic_bench/timers/mixed_perf_analyzer.hh",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/nmodl/ext/eigen/bench/btl/generic_bench/timers/STL_perf_analyzer.hh",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/nmodl/ext/eigen/bench/btl/generic_bench/utils/size_lin_log.hh",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/nmodl/ext/eigen/bench/btl/generic_bench/static/intel_bench_fixed_size.hh",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/nmodl/ext/eigen/bench/btl/generic_bench/static/static_size_generator.hh",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/nmodl/ext/eigen/doc/ftv2pnode.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/nmodl/ext/eigen/doc/Eigen_Silly_Professor_64x64.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/nmodl/ext/eigen/doc/ftv2node.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/nmodl/docs/background.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/nmodl/docs/logo.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/nmodl/docs/logo.graffle",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/nmodl/docs/images/nmodl-perf-stats.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/nmodl/docs/images/nmodl.ast.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/CLI11/docs/CLI11_300.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/external/CLI11/docs/CLI11_100.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/coreneuron/doc/binary_file_format.jpg",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/catch2/artwork/catch2-c-logo.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/catch2/artwork/catch2-hand-logo.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/external/catch2/artwork/catch2-logo-small.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/pure_diffusion_cvode.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/hh.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/ca_pump.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/react_region_specified.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/hh_param_cvode.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/hh_morph.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/nodes_update.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/hh_cvode.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/reaction_test.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/reaction_null_dest.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/include_flux_cvode.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/include_flux.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/cabuf.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/reaction_param_test.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/verify_no_initialization_order_issue.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/multicompartment_reactions_with_v.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/multicompartment_reactions_del.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/hh_param.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/cabuf_fixed_step.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/pure_diffusion.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/IraHH.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/multicompartment_reactions.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/multicompartment_mebrane_mismatch.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/wave1d/wave1d_taper_125_1.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/wave1d/wave1d_125_1.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/wave1d/wave1d_tree_125_1.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/wave1d/wave1d_tree2_125_1.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/wave1d/wave1d_25_5.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/wave1d/wave1d_tree2_25_5.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/wave1d/wave1d_tree_25_5.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/wave1d/wave1d_taper_25_5.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/ecs/ecs_example.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/ecs/ecs_multi_example_cvode.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/ecs/ecs_example_cvode.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/ecs/ecs_multi_example.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/ecs/ecs_before_sections.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/ecs/ecs_include_flux_cvode.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/ecs/ecs_include_flux.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/3d/pure_diffusion_3d_cvode.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/3d/include_flux3d_cvode.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/3d/circadian_rhythm.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/3d/pure_diffusion_3d.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/3d/include_flux3d.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/3d/multicompartment_reactions.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/hybrid/bistable_hybrid.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/hybrid/pure_diffusion_hybrid.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/hybrid/bistable_hybrid_cvode_change_nthread.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/hybrid/bistable_hybrid_cvode.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/hybrid/pure_diffusion_hybrid_cvode.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/rxdtests/hybrid/bistable_hybrid_change_nthread.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/ecs_example.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/pure_diffusion_cvode.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/ecs_diffusion_2d_tort.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/ecs_example_cvode_alpha.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/ecs_example_alpha_tort.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/ecs_diffusion_2d_alpha_tort.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/ecs_example_cvode.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/pure_diffusion_3d_anisotropic_x_cvode.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/pure_diffusion_3d_cvode.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/ecs_example_cvode_alpha_tort.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/ecs_include_flux_cvode.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/pure_diffusion_hybrid.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/pure_diffusion_3d_anisotropic_y_inhom_cvode.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/pure_diffusion_3d_anisotropic_z_inhom_cvode.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/pure_diffusion_3d_anisotropic_x_inhom_cvode.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/include_flux3d_cvode.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/ecs_diffusion_1d_cvode_tort.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/ecs_diffusion_1d_alpha.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/ics_currents_cvode.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/ecs_diffusion_1d_cvode.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/include_flux.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/ecs_diffusion_2d_alpha.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/ecs_diffusion_1d_cvode_alpha_tort.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/pure_diffusion_3d_anisotropic_z.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/ecs_diffusion_2d_cvode_tort.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/pure_diffusion_3d.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/pure_diffusion_hybrid_cvode.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/ecs_diffusion_1d.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/ecs_diffusion_2d.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/ecs_diffusion_2d_cvode_alpha.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/pure_diffusion_3d_anisotropic_y_cvode.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/ecs_diffusion_2d_cvode.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/include_flux3d.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/ecs_diffusion_2d_cvode_alpha_tort.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/pure_diffusion_3d_anisotropic_x.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/ecs_diffusion_1d_cvode_alpha.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/ecs_diffusion_1d_alpha_tort.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/ecs_example_cvode_tort.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/ics_currents.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/pure_diffusion_3d_anisotropic_z_inhom.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/pure_diffusion_3d_inhom.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/pure_diffusion_3d_inhom_cvode.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/ecs_diffusion_1d_tort.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/pure_diffusion_3d_anisotropic_x_inhom.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/currents.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/ecs_include_flux.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/pure_diffusion_3d_anisotropic_y.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/pure_diffusion.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/currents_cvode.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/ecs_example_tort.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/multicompartment_reactions.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/pure_diffusion_3d_anisotropic_z_cvode.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/pure_diffusion_3d_anisotropic_y_inhom.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/test/rxd/testdata/test/ecs_example_alpha.dat",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/logo.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/new_doc/images/svclmp.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/new_doc/customthemes/notdefault/static/sidebar.js",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/oldgrph.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/xstatebutton.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/glyphcircle.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/xmenu2.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/random-normal.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/rangevarplot1.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/geometry4.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/graph-align.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/deck-constructor.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/list-browser1.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/texteditor-map.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/boolean_dialog.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/guiwidgets-example.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/list-browser2b.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/section-connection.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/xvalue.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/graph-vector.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/mcran4-graph1.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/xslider.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/xbutton2.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/graph-xexpr.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/random-mcellran4.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/random-negexp.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/VectorPlay.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/secbrows-select.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/filechooser.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/secbrows-sectionList.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/value_panel.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/mcran4-graph2.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/xvarlabel.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/xradiobutton.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/makeFamily.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/xpvalue.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/xbutton.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/random-lognormal.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/rangevarplot2.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/xmenu1.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/linmod.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/plotsin2.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/random-binomial.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/vector-psth.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/plotsin.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/geometry1.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/graph-menuaction.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/mcran4-xvalue.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/geometry3.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/graph-fastflush.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/vbox-intercept.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/GatherVec.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/ExecCommand.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/vector-line.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/list-browser2.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/svclmp.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/fft2.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/string_dialog.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/symchooser.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/mechanismstandard.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/VecWrap.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/continue_dialog.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/geometry5.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/impedanx-logavsx.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/graph-constructor.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/vector-ploterr.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/geometry2.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/vector-histogram.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/graph-addexpr.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/random-geometric.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/random-poisson.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/vector-plot.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/py_doc/images/fft1.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/scm/images/image8.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/scm/images/image5.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/scm/images/image2.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/scm/images/image1.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/scm/images/image4.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/scm/images/image7.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/scm/images/image3.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/scm/images/image6.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/dev/HOCInterpreter/images/58788144.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/dev/HOCInterpreter/images/51567144.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/dev/HOCInterpreter/images/58788147.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/dev/HOCInterpreter/images/58786474.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/dev/HOCInterpreter/images/58791210.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/dev/HOCInterpreter/images/58791244.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/dev/HOCInterpreter/images/58791243.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/dev/HOCInterpreter/images/51567124.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/dev/HOCInterpreter/images/58788141.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/dev/HOCInterpreter/images/51567143.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/dev/HOCInterpreter/images/58788080.png",
        "/tmp/vanessa/spack-stage/spack-stage-neuron-7.8.2-xoewtv4e74qqse56yxuy2qkyejkdfvzl/spack-src/docs/dev/HOCInterpreter/images/51567142.png"
    ],
    "total_files": 8041
}