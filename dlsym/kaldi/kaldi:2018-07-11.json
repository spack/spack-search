{
    "matches": {
        "/tmp/vanessa/spack-stage/spack-stage-kaldi-2018-07-11-rv35kloqvg3o56a2oedih47hvccj5aqr/spack-src/src/cudamatrix/cu-device.cc": "// cudamatrix/cu-device.cc\n\n// Copyright 2009-2012  Karel Vesely\n//                2013  Lucas Ondel\n//           2013-2015  Johns Hopkins University (author: Daniel Povey)\n//                2015  Guoguo Chen\n\n// See ../../COPYING for clarification regarding multiple authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//  http://www.apache.org/licenses/LICENSE-2.0\n//\n// THIS CODE IS PROVIDED *AS IS* BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, EITHER EXPRESS OR IMPLIED, INCLUDING WITHOUT LIMITATION ANY IMPLIED\n// WARRANTIES OR CONDITIONS OF TITLE, FITNESS FOR A PARTICULAR PURPOSE,\n// MERCHANTABLITY OR NON-INFRINGEMENT.\n// See the Apache 2 License for the specific language governing permissions and\n// limitations under the License.\n\n\n\n#if HAVE_CUDA == 1\n\n#include <cublas_v2.h>\n#include <cuda.h>\n#include <cuda_runtime_api.h>\n\n#include <string>\n#include <vector>\n#include <algorithm>\n#ifndef _MSC_VER\n#include <dlfcn.h>\n#endif\n\n#include \"cudamatrix/cu-common.h\"\n#include \"cudamatrix/cu-device.h\"\n#include \"cudamatrix/cu-matrix.h\"\n#include \"base/kaldi-error.h\"\n#include \"base/kaldi-utils.h\"\n#include \"util/common-utils.h\"\n#include \"util/kaldi-io.h\"\n\nnamespace kaldi {\n\n/**\n   This function was added by Dan in July 2015 after upgrading on the CLSP\n   cluster to the CUDA 7.0 toolkit; the old mechanism of just calling\n   cudaThreadSynchronize() [==cudaDeviceSynchronize()] and having it\n   automagically select a GPU (when exclusive mode is on) doesn't seem to work\n   any more, in situations where GPU 0 is already being used.  This works.  It's\n   not 100% clear if the fact that the old code wasn't working was a bug, or a\n   changed feature (the NVidia docs were never super-clear regarding device\n   initialization).  But regardless, changing to this new mechanism should be\n   harmless even if the problem was specific to the CLSP grid.\n*/\n\nstatic bool GetCudaContext(int32 num_gpus, std::string *debug_str) {\n\n  // Our first attempt to get a device context is: we do cudaFree(0) and see if\n  // that returns no error code.  If it succeeds then we have a device\n  // context.  Apparently this is the canonical way to get a context.\n  if (cudaFree(0) == 0) {\n    cudaGetLastError();  // Clear any error status.\n    return true;\n  }\n\n  // The rest of this code represents how we used to get a device context, but\n  // now its purpose is mainly a debugging one.\n  std::ostringstream debug_stream;\n  debug_stream << \"num-gpus=\" << num_gpus << \". \";\n  for (int32 device = 0; device < num_gpus; device++) {\n    cudaSetDevice(device);\n    cudaError_t e = cudaFree(0);  // CUDA context gets created here.\n    if (e == cudaSuccess) {\n      if (debug_str)\n        *debug_str = debug_stream.str();\n      cudaGetLastError();  // Make sure the error state doesn't get returned in\n                           // the next cudaGetLastError().\n      return true;\n    }\n    debug_stream << \"Device \" << device << \": \" << cudaGetErrorString(e) << \".  \";\n  }\n  if (debug_str)\n    *debug_str = debug_stream.str();\n  return false;\n}\n\n/**\n * SelectGpuId(use_gpu)\n *\n * There are 3 'use_gpu' modes for GPU selection:\n * \"yes\"      -- Select GPU automatically (or get one by exclusive mode)\n *               and die if this fails.\n * \"optional\" -- Do as above, but if it fails, back off to CPU.\n * \"no\"       -- Run on CPU.\n *\n * In case of Compute exclusive mode, the GPU is selected by OS.\n *\n * Otherwise GPU selection is based on largest proportion of free memory.\n * This can eventually lead to multiple processes computing on single GPU,\n * which is slow. More practical is to use \"compute exclusive mode\".\n *\n * This method is to be called at the very beginning of the program\n * (before first allocation in cudamatrix), or not at all (default to CPU).\n *\n */\nvoid CuDevice::SelectGpuId(std::string use_gpu) {\n  // Possible modes\n  if (use_gpu != \"yes\" && use_gpu != \"no\" && use_gpu != \"optional\" && use_gpu != \"wait\") {\n    KALDI_ERR << \"Please choose : --use-gpu=yes|no|optional|wait, passed '\" << use_gpu << \"'\";\n  }\n\n  // Make sure this function is not called twice!\n  if (Enabled()) {\n    KALDI_ERR << \"There is already an active GPU \" << active_gpu_id_\n              << \", cannot change it on the fly!\";\n  }\n  // Allow the GPU to stay disabled\n  if (!Enabled() && use_gpu == \"no\") {\n    KALDI_LOG << \"Manually selected to compute on CPU.\";\n    return;\n  }\n\n  // Check that we have a gpu available\n  int32 num_gpus = 0;\n\n  cudaError_t e = cudaGetDeviceCount(&num_gpus);\n\n  if (num_gpus == 0) {\n    if (use_gpu == \"yes\" || use_gpu == \"wait\") {\n      KALDI_CUDA_ERR(e, \"No CUDA GPU detected!\");\n    }\n    if (use_gpu == \"optional\") {\n      KALDI_WARN << \"Running on CPU!!! No CUDA GPU detected...\";\n      return;\n    }\n  }\n\n  // Create a CUDA context.\n  std::string debug_str;\n  bool got_context = GetCudaContext(num_gpus, &debug_str);\n\n  if (use_gpu != \"wait\") {\n    if (!got_context) {\n      // So far no we don't have context, sleep a bit and retry.\n      int32 sec_sleep = (use_gpu == \"yes\" ? 20 : 2);\n      KALDI_WARN << \"Will try again to get a GPU after \" << sec_sleep\n                 << \" seconds.\";\n      Sleep(sec_sleep);\n      if (!GetCudaContext(num_gpus, &debug_str)) {\n        if (use_gpu == \"yes\") {\n          {\n            Input input;\n            input.Open(\"nvidia-smi 1>&2 |\");\n          }\n          KALDI_LOG << debug_str;\n          KALDI_ERR << \"Failed to create CUDA context, no more unused GPUs? \";\n        }\n        if (use_gpu == \"optional\") {\n          KALDI_WARN << \"Running on CPU!!! No more unused CUDA GPUs?\";\n          return;\n        }\n      }\n    }\n  } else {\n    int32 num_times = 0;\n    BaseFloat wait_time = 0.0;\n    while (!got_context) {\n      int32 sec_sleep = 5;\n      if (num_times == 0)\n        KALDI_WARN << \"Will try again indefinitely every \" << sec_sleep\n                   << \" seconds to get a GPU.\";\n      num_times++;\n      wait_time += sec_sleep;\n      Sleep(sec_sleep);\n      got_context = GetCudaContext(num_gpus, NULL);\n    }\n\n    KALDI_WARN << \"Waited \" << wait_time\n               << \" seconds before creating CUDA context\";\n  }\n\n  // Re-assure we have the context\n  KALDI_ASSERT(cudaSuccess == cudaThreadSynchronize());\n\n  // Check if the machine use compute exclusive mode\n  if (IsComputeExclusive()) {\n    KALDI_LOG << \"CUDA setup operating under Compute Exclusive Mode.\";\n    FinalizeActiveGpu();\n    return;\n  } else {\n    // Suggest to use compute exclusive mode\n    KALDI_WARN << \"Not in compute-exclusive mode.  Suggestion: use \"\n        \"'nvidia-smi -c 3' to set compute exclusive mode\";\n    // We want to choose the device more carefully, so release the CUDA context.\n    e = cudaThreadExit(); // deprecated, but for legacy reason not cudaDeviceReset\n    if (e != cudaSuccess) {\n      KALDI_CUDA_ERR(e, \"Failed to release CUDA context on a GPU\");\n    }\n\n    // And select the GPU according to proportion of free memory\n    if (SelectGpuIdAuto()) {\n      FinalizeActiveGpu();\n      return;\n    } else {\n      // Could not get GPU, after prevously having the CUDA context?\n      // Strange but not impossible...\n      if (use_gpu == \"yes\") {\n        KALDI_ERR << \"Error acquiring GPU.\";\n      }\n      if (use_gpu == \"optional\") {\n        KALDI_WARN << \"Running on CPU!!! Error acquiring GPU.\";\n        return;\n      }\n    }\n  }\n}\n\n\nvoid CuDevice::FinalizeActiveGpu() {\n  // The device at this point should have active GPU, so we can query its name\n  // and memory stats and notify user which GPU is finally used.\n\n  // Get the device-id of active device:\n  {\n    int32 act_gpu_id;\n    cudaError_t e = cudaGetDevice(&act_gpu_id);\n    if (e != cudaSuccess) {\n      KALDI_CUDA_ERR(e, \"Failed to get device-id of active device.\");\n    }\n    // Remember the id of active GPU\n    active_gpu_id_ = act_gpu_id; // CuDevice::Enabled() is true from now on\n    // Initialize CUBLAS.\n    CUBLAS_SAFE_CALL(cublasCreate(&handle_));\n    // Initialize the cuSPARSE library\n    CUSPARSE_SAFE_CALL(cusparseCreate(&cusparse_handle_));\n\n    // Notify user which GPU is finally used\n    char name[128];\n    DeviceGetName(name,128,act_gpu_id);\n\n    CU_SAFE_CALL(cudaGetDeviceProperties(&properties_, act_gpu_id));\n\n    KALDI_LOG << \"The active GPU is [\" << act_gpu_id << \"]: \" << name << \"\\t\"\n              << GetFreeMemory(&free_memory_at_startup_, NULL) << \" version \"\n              << properties_.major << \".\" << properties_.minor;\n  }\n  return;\n}\n\n\nbool CuDevice::DoublePrecisionSupported() {\n  if (!Enabled()) return true;\n  return properties_.major > 1 || (properties_.major == 1 && properties_.minor >= 3);\n  // Double precision is supported from version 1.3\n}\n\n\nbool CuDevice::IsComputeExclusive() {\n  // assume we already have an CUDA context created\n  KALDI_ASSERT(cudaSuccess == cudaThreadSynchronize());\n\n  // get the device-id and its device-properties\n  int32 gpu_id = -1;\n  cudaError_t e = cudaGetDevice(&gpu_id);\n  if (e != cudaSuccess) {\n    KALDI_CUDA_ERR(e, \"Failed to get current device\");\n  }\n  struct cudaDeviceProp gpu_prop;\n  e = cudaGetDeviceProperties(&gpu_prop, gpu_id);\n  if (e != cudaSuccess) {\n    KALDI_CUDA_ERR(e,  \"Failed to get device properties\");\n  }\n  // find out whether compute exclusive mode is used\n  switch (gpu_prop.computeMode) {\n    case cudaComputeModeExclusive :\n      return true;\n      break;\n#if (CUDA_VERSION >= 4000)\n    case cudaComputeModeExclusiveProcess :\n      return true;\n      break;\n#endif\n    default :\n      // in this case we release the GPU context...\n      return false;\n  }\n}\n\ntemplate<typename TA, typename TB>\nbool greater_pair(const std::pair<TA, TB> &left, const std::pair<TA, TB>& right) {\n  return left.second > right.second;\n}\n\nbool CuDevice::SelectGpuIdAuto() {\n  // Check that we have at least one gpu\n  int32 num_gpus = 0;\n  cudaError_t e = cudaGetDeviceCount(&num_gpus);\n  if (num_gpus == 0) {\n    KALDI_WARN << \"No CUDA devices found\";\n    if (e != cudaSuccess) {\n      KALDI_WARN << \"cudaGetDeviceCount() returned \" << e\n                 <<\", meaning: \\\"\" << cudaGetErrorString(e)  << \"\\\"\";\n    }\n    return false;\n  }\n\n  // The GPU is selected according to maximal free memory ratio\n  std::vector< std::pair<int, float> > free_mem_ratio(num_gpus);\n\n  // Get ratios of memory use, if possible\n  KALDI_LOG << \"Selecting from \" << num_gpus << \" GPUs\";\n  for(int32 n = 0; n < num_gpus; n++) {\n    int32 ret = cudaSetDevice(n);\n    switch(ret) {\n      case cudaSuccess : {\n        // create the CUDA context for the thread\n        cudaThreadSynchronize(); // deprecated, but for legacy not cudaDeviceSynchronize\n        // get GPU name\n        char name[128];\n        DeviceGetName(name,128,n);\n        // get GPU memory stats\n        int64 free, total;\n        std::string mem_stats;\n        mem_stats = GetFreeMemory(&free, &total);\n        // log\n        KALDI_LOG << \"cudaSetDevice(\" << n << \"): \"\n                  << name << \"\\t\" << mem_stats;\n\n        // We have seen that in some cases GetFreeMemory returns zero\n        // That will produce nan after division, which might confuse\n        // the sorting routine. Or maybe not, but let's keep it clean\n        if (total <= 0) {\n          KALDI_LOG << \"Total memory reported for device \" << n << \" is zero (or less).\";\n        }\n        float mem_ratio = total > 0 ? free/(float)total : 0;\n        free_mem_ratio[n] = std::make_pair(n, mem_ratio);\n\n        // destroy the CUDA context for the thread\n        cudaThreadExit(); // deprecated, but for legacy reason not cudaDeviceReset\n      } break;\n\n#if (CUDA_VERSION > 3020)\n      case cudaErrorDeviceAlreadyInUse :\n        KALDI_LOG << \"cudaSetDevice(\" << n << \"): \"\n                  << \"Device cannot be accessed, used EXCLUSIVE-THREAD mode...\";\n        break;\n#endif\n      case cudaErrorInvalidDevice :\n        KALDI_LOG << \"cudaSetDevice(\" << n << \"): \"\n                  << \"Device cannot be accessed, not a VALID CUDA device!\";\n        break;\n      default :\n        KALDI_LOG << \"cudaSetDevice(\" << n << \"): \"\n                  << \"returned \" << ret << \", \"\n                  << cudaGetErrorString((cudaError_t)ret);\n    }\n  }\n  // find GPU with max free memory\n  int32 max_id=0;\n  std::sort(free_mem_ratio.begin(), free_mem_ratio.end(),\n            greater_pair<int, float>);\n  // the free_mem_ratio should be bigger than zero\n  KALDI_ASSERT(free_mem_ratio[max_id].second > 0.0);\n\n  float dev_id;\n  float mem_ratio;\n  do {\n    // try to select the GPU in the best to worst order\n    // Note we have to check the return codes manually, as the CU_SAFE_CALL\n    // contains call to KALDI_ERR (which will cause the program to abort)\n\n    dev_id = free_mem_ratio[max_id].first;\n    mem_ratio = free_mem_ratio[max_id].second;\n\n    KALDI_LOG << \"Trying to select device: \" << dev_id << \" (automatically), mem_ratio: \" << mem_ratio;\n    e = cudaSetDevice(dev_id);\n    if (e != cudaSuccess) {\n      KALDI_WARN << \"Cannot select this device: return code \" << e\n                 << \", Error message: \\\"\" << cudaGetErrorString(e) << \"\\\"\";\n    } else {\n      e = cudaThreadSynchronize(); // deprecated, but for legacy not cudaDeviceSynchronize\n      if (e != cudaSuccess) {\n        KALDI_WARN << \"Cannot select this device: return code \" << e\n                   << \", Error message: \\\"\" << cudaGetErrorString(e) << \"\\\"\";\n      }\n    }\n    max_id++;\n  } while ((e != cudaSuccess) && (max_id < free_mem_ratio.size()));\n\n  if (e != cudaSuccess) {\n    KALDI_WARN << \"Failed to (automatically) select any device\";\n    return false;\n  }\n  KALDI_LOG << \"Success selecting device \" << dev_id << \" free mem ratio: \" << mem_ratio;\n  return true;\n}\n\n\nvoid CuDevice::AccuProfile(const char *function_name,\n                           const CuTimer &timer) {\n  if (GetVerboseLevel() >= 1) {\n    std::string key(function_name);\n    cudaDeviceSynchronize();\n    double elapsed = timer.Elapsed();\n\n    if (profile_map_.find(key) == profile_map_.end())\n      profile_map_[key] = elapsed;\n    else\n      profile_map_[key] += elapsed;\n  }\n}\n\nvoid CuDevice::PrintMemoryUsage() const {\n  if (Enabled()) {\n    allocator_.PrintMemoryUsage();\n    int64 free_memory_now;\n    GetFreeMemory(&free_memory_now, NULL);\n    KALDI_LOG << \"Memory used (according to the device): \"\n              << (free_memory_at_startup_ - free_memory_now) << \" bytes.\";\n  }\n}\n\nvoid CuDevice::PrintProfile() {\n  if (GetVerboseLevel() >= 1) {\n    std::ostringstream os;\n    os << \"-----\\n[cudevice profile]\\n\";\n    unordered_map<std::string, double, StringHasher>::iterator it;\n    std::vector<std::pair<double, std::string> > pairs;\n    double total_time = 0.0;\n    for(it = profile_map_.begin(); it != profile_map_.end(); ++it) {\n      std::string function_name = it->first;\n      double elapsed_time = it->second;\n      total_time += elapsed_time;\n      pairs.push_back(std::make_pair(elapsed_time, function_name));\n    }\n    // display from shortest to longest time, so tail will show the longest\n    // times at the end.\n    std::sort(pairs.begin(), pairs.end());\n    size_t max_print = 15, start_pos = (pairs.size() <= max_print ?\n                                        0 : pairs.size() - max_print);\n    for (size_t i = start_pos; i < pairs.size(); i++)\n      os << pairs[i].second << \"\\t\" << pairs[i].first << \"s\\n\";\n    os << \"Total GPU time:\\t\" << total_time << \"s (may involve some double-counting)\\n\";\n    os << \"-----\";\n    KALDI_LOG << os.str();\n    PrintMemoryUsage();\n  }\n}\n\n\nstd::string CuDevice::GetFreeMemory(int64* free, int64* total) const {\n  // WARNING! the CUDA API is inconsistent accross versions!\n#ifdef _MSC_VER\n  size_t mem_free, mem_total;\n  cuMemGetInfo_v2(&mem_free, &mem_total);\n#else\n#if (CUDA_VERSION >= 3020)\n  // define the function signature type\n  size_t mem_free, mem_total;\n#else\n  unsigned int mem_free, mem_total;\n#endif\n  {\n    // we will load cuMemGetInfo_v2 dynamically from libcuda.so\n    // pre-fill ``safe'' values that will not cause problems\n    mem_free = 1; mem_total = 1;\n    // open libcuda.so\n    void* libcuda = dlopen(\"libcuda.so\",RTLD_LAZY);\n    if (NULL == libcuda) {\n      KALDI_WARN << \"cannot open libcuda.so\";\n    } else {\n      // define the function signature type\n      // and get the symbol\n#if (CUDA_VERSION >= 3020)\n      typedef CUresult (*cu_fun_ptr)(size_t*, size_t*);\n      cu_fun_ptr dl_cuMemGetInfo = (cu_fun_ptr)dlsym(libcuda,\"cuMemGetInfo_v2\");\n#else\n      typedef CUresult (*cu_fun_ptr)(int*, int*);\n      cu_fun_ptr dl_cuMemGetInfo = (cu_fun_ptr)dlsym(libcuda,\"cuMemGetInfo\");\n#endif\n      if (NULL == dl_cuMemGetInfo) {\n        KALDI_WARN << \"cannot load cuMemGetInfo from libcuda.so\";\n      } else {\n        // call the function\n        dl_cuMemGetInfo(&mem_free, &mem_total);\n      }\n      // close the library\n      dlclose(libcuda);\n    }\n  }\n#endif\n  // copy the output values outside\n  if (NULL != free) *free = mem_free;\n  if (NULL != total) *total = mem_total;\n  // prepare the text output\n  std::ostringstream os;\n  os << \"free:\" << mem_free/(1024*1024) << \"M, \"\n     << \"used:\" << (mem_total-mem_free)/(1024*1024) << \"M, \"\n     << \"total:\" << mem_total/(1024*1024) << \"M, \"\n     << \"free/total:\" << mem_free/(float)mem_total;\n  return os.str();\n}\n\n\nvoid CuDevice::DeviceGetName(char* name, int32 len, int32 dev) {\n  // prefill with something reasonable\n  strncpy(name,\"Unknown GPU\",len);\n#ifdef _MSC_VER\n  cuDeviceGetName(name, len, dev);\n#else\n  // open libcuda.so\n  void* libcuda = dlopen(\"libcuda.so\",RTLD_LAZY);\n  if (NULL == libcuda) {\n    KALDI_WARN << \"cannot open libcuda.so\";\n  } else {\n    // define the function signature type\n    typedef CUresult (*cu_fun_ptr)(char*,int,CUdevice);\n    // get the symbol\n    cu_fun_ptr cuDeviceGetName_ptr = (cu_fun_ptr)dlsym(libcuda,\"cuDeviceGetName\");\n    if (NULL == cuDeviceGetName_ptr) {\n      KALDI_WARN << \"cannot load cuDeviceGetName from libcuda.so\";\n    } else {\n      // call the function\n      cuDeviceGetName_ptr(name, len, dev);\n    }\n    // close the library\n    dlclose(libcuda);\n  }\n#endif\n}\n\n\nvoid CuDevice::CheckGpuHealth() {\n  if (!Enabled()) return;\n  CuTimer t;\n  // prepare small matrices for a quick test\n  Matrix<BaseFloat> a(50, 100);\n  Matrix<BaseFloat> b(100 ,50);\n  a.SetRandn();\n  b.SetRandUniform();\n  // multiply 2 small matrices in CPU:\n  Matrix<BaseFloat> c(50, 50);\n  c.AddMatMat(1.0, a, kNoTrans, b, kNoTrans, 0.0);\n  // multiply same matrices in GPU:\n  CuMatrix<BaseFloat> c1(50, 50);\n  c1.AddMatMat(1.0, CuMatrix<BaseFloat>(a), kNoTrans, CuMatrix<BaseFloat>(b), kNoTrans, 0.0);\n  // check that relative differnence is <1%\n  AssertEqual(c, Matrix<BaseFloat>(c1), 0.01);\n  // measure time spent in this check\n  AccuProfile(__func__, t);\n}\n\nCuDevice::CuDevice() :\n    active_gpu_id_(-1), debug_stride_mode_(false),\n    num_debug_stride_allocations_(0), allocator_(CuAllocatorOptions()),\n    multi_threaded_(false) { }\n\n\n// The instance of the static singleton\nCuDevice CuDevice::global_device_;\n}\n\n\n#endif // HAVE_CUDA\n"
    },
    "skipped": [
        "/tmp/vanessa/spack-stage/spack-stage-kaldi-2018-07-11-rv35kloqvg3o56a2oedih47hvccj5aqr/spack-src/src/doc/KaldiModels.pptx",
        "/tmp/vanessa/spack-stage/spack-stage-kaldi-2018-07-11-rv35kloqvg3o56a2oedih47hvccj5aqr/spack-src/src/doc/KaldiScripts.pptx",
        "/tmp/vanessa/spack-stage/spack-stage-kaldi-2018-07-11-rv35kloqvg3o56a2oedih47hvccj5aqr/spack-src/src/doc/KaldiMatrix.pptx",
        "/tmp/vanessa/spack-stage/spack-stage-kaldi-2018-07-11-rv35kloqvg3o56a2oedih47hvccj5aqr/spack-src/src/doc/Kaldi.pptx",
        "/tmp/vanessa/spack-stage/spack-stage-kaldi-2018-07-11-rv35kloqvg3o56a2oedih47hvccj5aqr/spack-src/src/feat/test_data/test.wav.fbank_htk.2",
        "/tmp/vanessa/spack-stage/spack-stage-kaldi-2018-07-11-rv35kloqvg3o56a2oedih47hvccj5aqr/spack-src/src/feat/test_data/test.wav.fbank_htk.4",
        "/tmp/vanessa/spack-stage/spack-stage-kaldi-2018-07-11-rv35kloqvg3o56a2oedih47hvccj5aqr/spack-src/src/feat/test_data/test.wav",
        "/tmp/vanessa/spack-stage/spack-stage-kaldi-2018-07-11-rv35kloqvg3o56a2oedih47hvccj5aqr/spack-src/src/feat/test_data/test.wav.fbank_htk.1",
        "/tmp/vanessa/spack-stage/spack-stage-kaldi-2018-07-11-rv35kloqvg3o56a2oedih47hvccj5aqr/spack-src/src/feat/test_data/test.wav.fbank_htk.3",
        "/tmp/vanessa/spack-stage/spack-stage-kaldi-2018-07-11-rv35kloqvg3o56a2oedih47hvccj5aqr/spack-src/src/feat/test_data/test.wav.fea_htk.1",
        "/tmp/vanessa/spack-stage/spack-stage-kaldi-2018-07-11-rv35kloqvg3o56a2oedih47hvccj5aqr/spack-src/src/feat/test_data/test.wav.fea_htk.2",
        "/tmp/vanessa/spack-stage/spack-stage-kaldi-2018-07-11-rv35kloqvg3o56a2oedih47hvccj5aqr/spack-src/src/feat/test_data/test.wav.fea_htk.6",
        "/tmp/vanessa/spack-stage/spack-stage-kaldi-2018-07-11-rv35kloqvg3o56a2oedih47hvccj5aqr/spack-src/src/feat/test_data/test.wav.fea_htk.3",
        "/tmp/vanessa/spack-stage/spack-stage-kaldi-2018-07-11-rv35kloqvg3o56a2oedih47hvccj5aqr/spack-src/src/feat/test_data/test.wav.fea_htk.4",
        "/tmp/vanessa/spack-stage/spack-stage-kaldi-2018-07-11-rv35kloqvg3o56a2oedih47hvccj5aqr/spack-src/src/feat/test_data/test.wav.plp_htk.1",
        "/tmp/vanessa/spack-stage/spack-stage-kaldi-2018-07-11-rv35kloqvg3o56a2oedih47hvccj5aqr/spack-src/src/feat/test_data/test.wav.fea_htk.5",
        "/tmp/vanessa/spack-stage/spack-stage-kaldi-2018-07-11-rv35kloqvg3o56a2oedih47hvccj5aqr/spack-src/.git/objects/pack/pack-2a5c55b15a5a31de6b3710ba9272b03fbdce7536.pack",
        "/tmp/vanessa/spack-stage/spack-stage-kaldi-2018-07-11-rv35kloqvg3o56a2oedih47hvccj5aqr/spack-src/.git/objects/pack/pack-2a5c55b15a5a31de6b3710ba9272b03fbdce7536.idx",
        "/tmp/vanessa/spack-stage/spack-stage-kaldi-2018-07-11-rv35kloqvg3o56a2oedih47hvccj5aqr/spack-src/egs/ami/s5/local/english.glm",
        "/tmp/vanessa/spack-stage/spack-stage-kaldi-2018-07-11-rv35kloqvg3o56a2oedih47hvccj5aqr/spack-src/egs/ami/s5b/local/english.glm",
        "/tmp/vanessa/spack-stage/spack-stage-kaldi-2018-07-11-rv35kloqvg3o56a2oedih47hvccj5aqr/spack-src/egs/gp/s5/local/gp_norm_trans_CZ.pl",
        "/tmp/vanessa/spack-stage/spack-stage-kaldi-2018-07-11-rv35kloqvg3o56a2oedih47hvccj5aqr/spack-src/windows/NewGuidCmd.exe",
        "/tmp/vanessa/spack-stage/spack-stage-kaldi-2018-07-11-rv35kloqvg3o56a2oedih47hvccj5aqr/spack-src/misc/papers/asru11_toolkit_poster/kaldi-poster.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-kaldi-2018-07-11-rv35kloqvg3o56a2oedih47hvccj5aqr/spack-src/misc/papers/asru11_toolkit_poster/figures/KaldiTextAndLogo.png",
        "/tmp/vanessa/spack-stage/spack-stage-kaldi-2018-07-11-rv35kloqvg3o56a2oedih47hvccj5aqr/spack-src/misc/papers/asru11_toolkit_poster/figures/kaldi-lib.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-kaldi-2018-07-11-rv35kloqvg3o56a2oedih47hvccj5aqr/spack-src/misc/papers/asru11_toolkit/kaldi_asru.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-kaldi-2018-07-11-rv35kloqvg3o56a2oedih47hvccj5aqr/spack-src/misc/papers/asru11_toolkit/figs/kaldi-lib.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-kaldi-2018-07-11-rv35kloqvg3o56a2oedih47hvccj5aqr/spack-src/misc/logo/KaldiLogo.docx",
        "/tmp/vanessa/spack-stage/spack-stage-kaldi-2018-07-11-rv35kloqvg3o56a2oedih47hvccj5aqr/spack-src/misc/logo/KaldiTextAndLogoSmall.png",
        "/tmp/vanessa/spack-stage/spack-stage-kaldi-2018-07-11-rv35kloqvg3o56a2oedih47hvccj5aqr/spack-src/misc/logo/KaldiTextAndLogo.png",
        "/tmp/vanessa/spack-stage/spack-stage-kaldi-2018-07-11-rv35kloqvg3o56a2oedih47hvccj5aqr/spack-src/misc/logo/KaldiIco.png",
        "/tmp/vanessa/spack-stage/spack-stage-kaldi-2018-07-11-rv35kloqvg3o56a2oedih47hvccj5aqr/spack-src/misc/logo/KaldiLogo.png"
    ],
    "total_files": 5620
}