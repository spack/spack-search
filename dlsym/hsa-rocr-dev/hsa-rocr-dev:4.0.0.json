{
    "matches": {
        "/tmp/vanessa/spack-stage/spack-stage-hsa-rocr-dev-4.0.0-jaoqjbrbblmkyubesmkvsexepbvyifhf/spack-src/src/core/util/lnx/os_linux.cpp": "////////////////////////////////////////////////////////////////////////////////\n//\n// The University of Illinois/NCSA\n// Open Source License (NCSA)\n// \n// Copyright (c) 2014-2020, Advanced Micro Devices, Inc. All rights reserved.\n// \n// Developed by:\n// \n//                 AMD Research and AMD HSA Software Development\n// \n//                 Advanced Micro Devices, Inc.\n// \n//                 www.amd.com\n// \n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to\n// deal with the Software without restriction, including without limitation\n// the rights to use, copy, modify, merge, publish, distribute, sublicense,\n// and/or sell copies of the Software, and to permit persons to whom the\n// Software is furnished to do so, subject to the following conditions:\n// \n//  - Redistributions of source code must retain the above copyright notice,\n//    this list of conditions and the following disclaimers.\n//  - Redistributions in binary form must reproduce the above copyright\n//    notice, this list of conditions and the following disclaimers in\n//    the documentation and/or other materials provided with the distribution.\n//  - Neither the names of Advanced Micro Devices, Inc,\n//    nor the names of its contributors may be used to endorse or promote\n//    products derived from this Software without specific prior written\n//    permission.\n// \n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n// THE CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR\n// OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,\n// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n// DEALINGS WITH THE SOFTWARE.\n//\n////////////////////////////////////////////////////////////////////////////////\n\n#ifdef __linux__\n#include \"core/util/os.h\"\n#include \"core/util/utils.h\"\n\n#include <link.h>\n#include <dlfcn.h>\n#include <pthread.h>\n#include <limits.h>\n#include <sched.h>\n#include <sys/sysinfo.h>\n#include <sys/time.h>\n#include <sys/utsname.h>\n#include <unistd.h>\n#include <errno.h>\n#include <cstring>\n#include <atomic>\n#include <memory>\n#include <string>\n#include <utility>\n\nnamespace rocr {\nnamespace os {\n\nstruct ThreadArgs {\n  void* entry_args;\n  ThreadEntry entry_function;\n};\n\nvoid* __stdcall ThreadTrampoline(void* arg) {\n  ThreadArgs* ar = (ThreadArgs*)arg;\n  ThreadEntry CallMe = ar->entry_function;\n  void* Data = ar->entry_args;\n  delete ar;\n  CallMe(Data);\n  return NULL;\n}\n\n// Thread container allows multiple waits and separate close (destroy).\nclass os_thread {\n public:\n  explicit os_thread(ThreadEntry function, void* threadArgument, uint stackSize)\n      : thread(0), lock(nullptr), state(RUNNING) {\n    std::unique_ptr<ThreadArgs> args(new ThreadArgs);\n    lock = CreateMutex();\n    if (lock == nullptr) return;\n\n    args->entry_args = threadArgument;\n    args->entry_function = function;\n\n    pthread_attr_t attrib;\n    pthread_attr_init(&attrib);\n\n    if (stackSize != 0) {\n      stackSize = Max(uint(PTHREAD_STACK_MIN), stackSize);\n      stackSize = AlignUp(stackSize, 4096);\n      int err = pthread_attr_setstacksize(&attrib, stackSize);\n      assert(err == 0 && \"pthread_attr_setstacksize failed.\");\n    }\n\n    int err = pthread_create(&thread, &attrib, ThreadTrampoline, args.get());\n\n    // Probably a stack size error since system limits can be different from PTHREAD_STACK_MIN\n    // Attempt to grow the stack within reason.\n    if ((err == EINVAL) && stackSize != 0) {\n      while (stackSize < 20 * 1024 * 1024) {\n        stackSize *= 2;\n        pthread_attr_setstacksize(&attrib, stackSize);\n        err = pthread_create(&thread, &attrib, ThreadTrampoline, args.get());\n        if (err != EINVAL) break;\n      }\n    }\n\n    pthread_attr_destroy(&attrib);\n    if (err == 0)\n      args.release();\n    else\n      thread = 0;\n  }\n\n  os_thread(os_thread&& rhs) {\n    thread = rhs.thread;\n    lock = rhs.lock;\n    state = int(rhs.state);\n    rhs.thread = 0;\n    rhs.lock = nullptr;\n  }\n\n  os_thread(os_thread&) = delete;\n\n  ~os_thread() {\n    if (lock != nullptr) DestroyMutex(lock);\n    if ((state == RUNNING) && (thread != 0)) pthread_detach(thread);\n  }\n\n  bool Valid() { return (lock != nullptr) && (thread != 0); }\n\n  bool Wait() {\n    if (state == FINISHED) return true;\n    AcquireMutex(lock);\n    if (state == FINISHED) {\n      ReleaseMutex(lock);\n      return true;\n    }\n    int err = pthread_join(thread, NULL);\n    bool success = (err == 0);\n    if (success) state = FINISHED;\n    ReleaseMutex(lock);\n    return success;\n  }\n\n private:\n  pthread_t thread;\n  Mutex lock;\n  std::atomic<int> state;\n  enum { FINISHED = 0, RUNNING = 1 };\n};\n\nstatic_assert(sizeof(LibHandle) == sizeof(void*), \"OS abstraction size mismatch\");\nstatic_assert(sizeof(Mutex) == sizeof(pthread_mutex_t*), \"OS abstraction size mismatch\");\nstatic_assert(sizeof(Thread) == sizeof(os_thread*), \"OS abstraction size mismatch\");\n\nLibHandle LoadLib(std::string filename) {\n  void* ret = dlopen(filename.c_str(), RTLD_LAZY);\n  if (ret == nullptr) debug_print(\"LoadLib(%s) failed: %s\\n\", filename.c_str(), dlerror());\n  return *(LibHandle*)&ret;\n}\n\nvoid* GetExportAddress(LibHandle lib, std::string export_name) {\n  void* ret = dlsym(*(void**)&lib, export_name.c_str());\n\n  // dlsym searches the given library and all the library's load dependencies.\n  // Remaining code limits symbol lookup to only the library handle given.\n  // This lookup pattern matches Windows.\n  if (ret == NULL) return ret;\n\n  link_map* map;\n  int err = dlinfo(*(void**)&lib, RTLD_DI_LINKMAP, &map);\n  assert(err != -1 && \"dlinfo failed.\");\n\n  Dl_info info;\n  err = dladdr(ret, &info);\n  assert(err != 0 && \"dladdr failed.\");\n\n  if (strcmp(info.dli_fname, map->l_name) == 0) return ret;\n\n  return NULL;\n}\n\nvoid CloseLib(LibHandle lib) { dlclose(*(void**)&lib); }\n\nMutex CreateMutex() {\n  pthread_mutex_t* mutex = new pthread_mutex_t;\n  pthread_mutex_init(mutex, NULL);\n  return *(Mutex*)&mutex;\n}\n\nbool TryAcquireMutex(Mutex lock) {\n  return pthread_mutex_trylock(*(pthread_mutex_t**)&lock) == 0;\n}\n\nbool AcquireMutex(Mutex lock) {\n  return pthread_mutex_lock(*(pthread_mutex_t**)&lock) == 0;\n}\n\nvoid ReleaseMutex(Mutex lock) {\n  pthread_mutex_unlock(*(pthread_mutex_t**)&lock);\n}\n\nvoid DestroyMutex(Mutex lock) {\n  pthread_mutex_destroy(*(pthread_mutex_t**)&lock);\n  delete *(pthread_mutex_t**)&lock;\n}\n\nvoid Sleep(int delay_in_millisec) { usleep(delay_in_millisec * 1000); }\n\nvoid uSleep(int delayInUs) { usleep(delayInUs); }\n\nvoid YieldThread() { sched_yield(); }\n\nThread CreateThread(ThreadEntry function, void* threadArgument, uint stackSize) {\n  os_thread* result = new os_thread(function, threadArgument, stackSize);\n  if (!result->Valid()) {\n    delete result;\n    return nullptr;\n  }\n\n  return reinterpret_cast<Thread>(result);\n}\n\nvoid CloseThread(Thread thread) { delete reinterpret_cast<os_thread*>(thread); }\n\nbool WaitForThread(Thread thread) { return reinterpret_cast<os_thread*>(thread)->Wait(); }\n\nbool WaitForAllThreads(Thread* threads, uint threadCount) {\n  for (uint i = 0; i < threadCount; i++) WaitForThread(threads[i]);\n  return true;\n}\n\nbool IsEnvVarSet(std::string env_var_name) {\n  char* buff = NULL;\n  buff = getenv(env_var_name.c_str());\n  return (buff != NULL);\n}\n\nvoid SetEnvVar(std::string env_var_name, std::string env_var_value) {\n  setenv(env_var_name.c_str(), env_var_value.c_str(), 1);\n}\n\nstd::string GetEnvVar(std::string env_var_name) {\n  char* buff;\n  buff = getenv(env_var_name.c_str());\n  std::string ret;\n  if (buff) {\n    ret = buff;\n  }\n  return ret;\n}\n\nsize_t GetUserModeVirtualMemorySize() {\n#ifdef _LP64\n  // https://www.kernel.org/doc/Documentation/x86/x86_64/mm.txt :\n  // user space is 0000000000000000 - 00007fffffffffff (=47 bits)\n  return (size_t)(0x800000000000);\n#else\n  return (size_t)(0xffffffff);  // ~4GB\n#endif\n}\n\nsize_t GetUsablePhysicalHostMemorySize() {\n  struct sysinfo info = {0};\n  if (sysinfo(&info) != 0) {\n    return 0;\n  }\n\n  const size_t physical_size =\n      static_cast<size_t>(info.totalram * info.mem_unit);\n  return std::min(GetUserModeVirtualMemorySize(), physical_size);\n}\n\nuintptr_t GetUserModeVirtualMemoryBase() { return (uintptr_t)0; }\n\n// Os event implementation\ntypedef struct EventDescriptor_ {\n  pthread_cond_t event;\n  pthread_mutex_t mutex;\n  bool state;\n  bool auto_reset;\n} EventDescriptor;\n\nEventHandle CreateOsEvent(bool auto_reset, bool init_state) {\n  EventDescriptor* eventDescrp;\n  eventDescrp = (EventDescriptor*)malloc(sizeof(EventDescriptor));\n\n  pthread_mutex_init(&eventDescrp->mutex, NULL);\n  pthread_cond_init(&eventDescrp->event, NULL);\n  eventDescrp->auto_reset = auto_reset;\n  eventDescrp->state = init_state;\n\n  EventHandle handle = reinterpret_cast<EventHandle>(eventDescrp);\n\n  return handle;\n}\n\nint DestroyOsEvent(EventHandle event) {\n  if (event == NULL) {\n    return -1;\n  }\n\n  EventDescriptor* eventDescrp = reinterpret_cast<EventDescriptor*>(event);\n  int ret_code = pthread_cond_destroy(&eventDescrp->event);\n  ret_code |= pthread_mutex_destroy(&eventDescrp->mutex);\n  free(eventDescrp);\n  return ret_code;\n}\n\nint WaitForOsEvent(EventHandle event, unsigned int milli_seconds) {\n  if (event == NULL) {\n    return -1;\n  }\n\n  EventDescriptor* eventDescrp = reinterpret_cast<EventDescriptor*>(event);\n  // Event wait time is 0 and state is non-signaled, return directly\n  if (milli_seconds == 0) {\n    int tmp_ret = pthread_mutex_trylock(&eventDescrp->mutex);\n    if (tmp_ret == EBUSY) {\n      // Timeout\n      return 1;\n    }\n  }\n\n  int ret_code = 0;\n  pthread_mutex_lock(&eventDescrp->mutex);\n  if (!eventDescrp->state) {\n    if (milli_seconds == 0) {\n      ret_code = 1;\n    } else {\n      struct timespec ts;\n      struct timeval tp;\n\n      ret_code = gettimeofday(&tp, NULL);\n      ts.tv_sec = tp.tv_sec;\n      ts.tv_nsec = tp.tv_usec * 1000;\n\n      unsigned int sec = milli_seconds / 1000;\n      unsigned int mSec = milli_seconds % 1000;\n\n      ts.tv_sec += sec;\n      ts.tv_nsec += mSec * 1000000;\n\n      // More then one second, add 1 sec to the tv_sec elem\n      if (ts.tv_nsec > 1000000000) {\n        ts.tv_sec += 1;\n        ts.tv_nsec = ts.tv_nsec - 1000000000;\n      }\n\n      ret_code =\n          pthread_cond_timedwait(&eventDescrp->event, &eventDescrp->mutex, &ts);\n      // Time out\n      if (ret_code == 110) {\n        ret_code = 0x14003;  // 1 means time out in HSA\n      }\n\n      if (ret_code == 0 && eventDescrp->auto_reset) {\n        eventDescrp->state = false;\n      }\n    }\n  } else if (eventDescrp->auto_reset) {\n    eventDescrp->state = false;\n  }\n  pthread_mutex_unlock(&eventDescrp->mutex);\n\n  return ret_code;\n}\n\nint SetOsEvent(EventHandle event) {\n  if (event == NULL) {\n    return -1;\n  }\n\n  EventDescriptor* eventDescrp = reinterpret_cast<EventDescriptor*>(event);\n  int ret_code = 0;\n  ret_code = pthread_mutex_lock(&eventDescrp->mutex);\n  eventDescrp->state = true;\n  ret_code = pthread_mutex_unlock(&eventDescrp->mutex);\n  ret_code |= pthread_cond_signal(&eventDescrp->event);\n\n  return ret_code;\n}\n\nint ResetOsEvent(EventHandle event) {\n  if (event == NULL) {\n    return -1;\n  }\n\n  EventDescriptor* eventDescrp = reinterpret_cast<EventDescriptor*>(event);\n  int ret_code = 0;\n  ret_code = pthread_mutex_lock(&eventDescrp->mutex);\n  eventDescrp->state = false;\n  ret_code = pthread_mutex_unlock(&eventDescrp->mutex);\n\n  return ret_code;\n}\n\nstatic double invPeriod = 0.0;\n\nuint64_t ReadAccurateClock() {\n  if (invPeriod == 0.0) AccurateClockFrequency();\n  timespec time;\n  int err = clock_gettime(CLOCK_MONOTONIC_RAW, &time);\n  assert(err == 0 && \"clock_gettime(CLOCK_MONOTONIC_RAW,...) failed\");\n  return (uint64_t(time.tv_sec) * 1000000000ull + uint64_t(time.tv_nsec)) * invPeriod;\n}\n\nuint64_t AccurateClockFrequency() {\n  static clockid_t clock = CLOCK_MONOTONIC;\n  static std::atomic<bool> first(true);\n  // Check kernel version - not a concurrency concern.\n  // use non-RAW for getres due to bug in older 2.6.x kernels\n  if (first.load(std::memory_order_acquire)) {\n    utsname kernelInfo;\n    if (uname(&kernelInfo) == 0) {\n      try {\n        std::string ver = kernelInfo.release;\n        size_t idx;\n        int major = std::stoi(ver, &idx);\n        int minor = std::stoi(ver.substr(idx + 1));\n        if ((major >= 4) && (minor >= 4)) {\n          clock = CLOCK_MONOTONIC_RAW;\n        }\n      } catch (...) {\n        // Kernel version string doesn't conform to the standard pattern.\n        // Keep using the \"safe\" (non-RAW) clock.\n      }\n    }\n    first.store(false, std::memory_order_release);\n  }\n  timespec time;\n  int err = clock_getres(clock, &time);\n  assert(err == 0 && \"clock_getres(CLOCK_MONOTONIC(_RAW),...) failed\");\n  assert(time.tv_sec == 0 &&\n         \"clock_getres(CLOCK_MONOTONIC(_RAW),...) returned very low frequency \"\n         \"(<1Hz).\");\n  assert(time.tv_nsec < 0xFFFFFFFF &&\n         \"clock_getres(CLOCK_MONOTONIC(_RAW),...) returned very low frequency \"\n         \"(<1Hz).\");\n  if (invPeriod == 0.0) invPeriod = 1.0 / double(time.tv_nsec);\n  return 1000000000ull / uint64_t(time.tv_nsec);\n}\n}   //  namespace os\n}   //  namespace rocr\n\n#endif\n"
    },
    "skipped": [],
    "total_files": 178
}