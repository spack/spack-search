{
    "matches": {
        "/tmp/vanessa/spack-stage/spack-stage-ffmpeg-2.8.15-ozpyncprat26dr3j2bmhjj5jpw7za2d2/spack-src/libavformat/avisynth.c": "/*\n * AviSynth/AvxSynth support\n * Copyright (c) 2012 AvxSynth Team.\n *\n * This file is part of FFmpeg\n * FFmpeg is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License as published by the Free Software Foundation; either\n * version 2.1 of the License, or (at your option) any later version.\n *\n * FFmpeg is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with FFmpeg; if not, write to the Free Software\n * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n */\n\n#include \"libavutil/internal.h\"\n#include \"libavcodec/internal.h\"\n#include \"avformat.h\"\n#include \"internal.h\"\n#include \"config.h\"\n\n/* Enable function pointer definitions for runtime loading. */\n#define AVSC_NO_DECLSPEC\n\n/* Platform-specific directives for AviSynth vs AvxSynth. */\n#ifdef _WIN32\n  #include <windows.h>\n  #undef EXTERN_C\n  #include \"compat/avisynth/avisynth_c.h\"\n  #define AVISYNTH_LIB \"avisynth\"\n  #define USING_AVISYNTH\n#else\n  #include <dlfcn.h>\n  #include \"compat/avisynth/avxsynth_c.h\"\n  #define AVISYNTH_NAME \"libavxsynth\"\n  #define AVISYNTH_LIB AVISYNTH_NAME SLIBSUF\n\n  #define LoadLibrary(x) dlopen(x, RTLD_NOW | RTLD_LOCAL)\n  #define GetProcAddress dlsym\n  #define FreeLibrary dlclose\n#endif\n\ntypedef struct AviSynthLibrary {\n    void *library;\n#define AVSC_DECLARE_FUNC(name) name ## _func name\n    AVSC_DECLARE_FUNC(avs_bit_blt);\n    AVSC_DECLARE_FUNC(avs_clip_get_error);\n    AVSC_DECLARE_FUNC(avs_create_script_environment);\n    AVSC_DECLARE_FUNC(avs_delete_script_environment);\n    AVSC_DECLARE_FUNC(avs_get_audio);\n    AVSC_DECLARE_FUNC(avs_get_error);\n    AVSC_DECLARE_FUNC(avs_get_frame);\n    AVSC_DECLARE_FUNC(avs_get_version);\n    AVSC_DECLARE_FUNC(avs_get_video_info);\n    AVSC_DECLARE_FUNC(avs_invoke);\n    AVSC_DECLARE_FUNC(avs_release_clip);\n    AVSC_DECLARE_FUNC(avs_release_value);\n    AVSC_DECLARE_FUNC(avs_release_video_frame);\n    AVSC_DECLARE_FUNC(avs_take_clip);\n#ifdef USING_AVISYNTH\n    AVSC_DECLARE_FUNC(avs_bits_per_pixel);\n    AVSC_DECLARE_FUNC(avs_get_height_p);\n    AVSC_DECLARE_FUNC(avs_get_pitch_p);\n    AVSC_DECLARE_FUNC(avs_get_read_ptr_p);\n    AVSC_DECLARE_FUNC(avs_get_row_size_p);\n    AVSC_DECLARE_FUNC(avs_is_yv24);\n    AVSC_DECLARE_FUNC(avs_is_yv16);\n    AVSC_DECLARE_FUNC(avs_is_yv411);\n    AVSC_DECLARE_FUNC(avs_is_y8);\n#endif\n#undef AVSC_DECLARE_FUNC\n} AviSynthLibrary;\n\ntypedef struct AviSynthContext {\n    AVS_ScriptEnvironment *env;\n    AVS_Clip *clip;\n    const AVS_VideoInfo *vi;\n\n    /* avisynth_read_packet_video() iterates over this. */\n    int n_planes;\n    const int *planes;\n\n    int curr_stream;\n    int curr_frame;\n    int64_t curr_sample;\n\n    int error;\n\n    /* Linked list pointers. */\n    struct AviSynthContext *next;\n} AviSynthContext;\n\nstatic const int avs_planes_packed[1] = { 0 };\nstatic const int avs_planes_grey[1]   = { AVS_PLANAR_Y };\nstatic const int avs_planes_yuv[3]    = { AVS_PLANAR_Y, AVS_PLANAR_U,\n                                          AVS_PLANAR_V };\n\n/* A conflict between C++ global objects, atexit, and dynamic loading requires\n * us to register our own atexit handler to prevent double freeing. */\nstatic AviSynthLibrary avs_library;\nstatic int avs_atexit_called        = 0;\n\n/* Linked list of AviSynthContexts. An atexit handler destroys this list. */\nstatic AviSynthContext *avs_ctx_list = NULL;\n\nstatic av_cold void avisynth_atexit_handler(void);\n\nstatic av_cold int avisynth_load_library(void)\n{\n    avs_library.library = LoadLibrary(AVISYNTH_LIB);\n    if (!avs_library.library)\n        return AVERROR_UNKNOWN;\n\n#define LOAD_AVS_FUNC(name, continue_on_fail)                          \\\n        avs_library.name =                                             \\\n            (void *)GetProcAddress(avs_library.library, #name);        \\\n        if (!continue_on_fail && !avs_library.name)                    \\\n            goto fail;\n\n    LOAD_AVS_FUNC(avs_bit_blt, 0);\n    LOAD_AVS_FUNC(avs_clip_get_error, 0);\n    LOAD_AVS_FUNC(avs_create_script_environment, 0);\n    LOAD_AVS_FUNC(avs_delete_script_environment, 0);\n    LOAD_AVS_FUNC(avs_get_audio, 0);\n    LOAD_AVS_FUNC(avs_get_error, 1); // New to AviSynth 2.6\n    LOAD_AVS_FUNC(avs_get_frame, 0);\n    LOAD_AVS_FUNC(avs_get_version, 0);\n    LOAD_AVS_FUNC(avs_get_video_info, 0);\n    LOAD_AVS_FUNC(avs_invoke, 0);\n    LOAD_AVS_FUNC(avs_release_clip, 0);\n    LOAD_AVS_FUNC(avs_release_value, 0);\n    LOAD_AVS_FUNC(avs_release_video_frame, 0);\n    LOAD_AVS_FUNC(avs_take_clip, 0);\n#ifdef USING_AVISYNTH\n    LOAD_AVS_FUNC(avs_bits_per_pixel, 1);\n    LOAD_AVS_FUNC(avs_get_height_p, 1);\n    LOAD_AVS_FUNC(avs_get_pitch_p, 1);\n    LOAD_AVS_FUNC(avs_get_read_ptr_p, 1);\n    LOAD_AVS_FUNC(avs_get_row_size_p, 1);\n    LOAD_AVS_FUNC(avs_is_yv24, 1);\n    LOAD_AVS_FUNC(avs_is_yv16, 1);\n    LOAD_AVS_FUNC(avs_is_yv411, 1);\n    LOAD_AVS_FUNC(avs_is_y8, 1);\n#endif\n#undef LOAD_AVS_FUNC\n\n    atexit(avisynth_atexit_handler);\n    return 0;\n\nfail:\n    FreeLibrary(avs_library.library);\n    return AVERROR_UNKNOWN;\n}\n\n/* Note that avisynth_context_create and avisynth_context_destroy\n * do not allocate or free the actual context! That is taken care of\n * by libavformat. */\nstatic av_cold int avisynth_context_create(AVFormatContext *s)\n{\n    AviSynthContext *avs = s->priv_data;\n    int ret;\n\n    if (!avs_library.library)\n        if (ret = avisynth_load_library())\n            return ret;\n\n    avs->env = avs_library.avs_create_script_environment(3);\n    if (avs_library.avs_get_error) {\n        const char *error = avs_library.avs_get_error(avs->env);\n        if (error) {\n            av_log(s, AV_LOG_ERROR, \"%s\\n\", error);\n            return AVERROR_UNKNOWN;\n        }\n    }\n\n    if (!avs_ctx_list) {\n        avs_ctx_list = avs;\n    } else {\n        avs->next    = avs_ctx_list;\n        avs_ctx_list = avs;\n    }\n\n    return 0;\n}\n\nstatic av_cold void avisynth_context_destroy(AviSynthContext *avs)\n{\n    if (avs_atexit_called)\n        return;\n\n    if (avs == avs_ctx_list) {\n        avs_ctx_list = avs->next;\n    } else {\n        AviSynthContext *prev = avs_ctx_list;\n        while (prev->next != avs)\n            prev = prev->next;\n        prev->next = avs->next;\n    }\n\n    if (avs->clip) {\n        avs_library.avs_release_clip(avs->clip);\n        avs->clip = NULL;\n    }\n    if (avs->env) {\n        avs_library.avs_delete_script_environment(avs->env);\n        avs->env = NULL;\n    }\n}\n\nstatic av_cold void avisynth_atexit_handler(void)\n{\n    AviSynthContext *avs = avs_ctx_list;\n\n    while (avs) {\n        AviSynthContext *next = avs->next;\n        avisynth_context_destroy(avs);\n        avs = next;\n    }\n    FreeLibrary(avs_library.library);\n\n    avs_atexit_called = 1;\n}\n\n/* Create AVStream from audio and video data. */\nstatic int avisynth_create_stream_video(AVFormatContext *s, AVStream *st)\n{\n    AviSynthContext *avs = s->priv_data;\n    int planar = 0; // 0: packed, 1: YUV, 2: Y8\n\n    st->codec->codec_type = AVMEDIA_TYPE_VIDEO;\n    st->codec->codec_id   = AV_CODEC_ID_RAWVIDEO;\n    st->codec->width      = avs->vi->width;\n    st->codec->height     = avs->vi->height;\n\n    st->avg_frame_rate    = (AVRational) { avs->vi->fps_numerator,\n                                           avs->vi->fps_denominator };\n    st->start_time        = 0;\n    st->duration          = avs->vi->num_frames;\n    st->nb_frames         = avs->vi->num_frames;\n    avpriv_set_pts_info(st, 32, avs->vi->fps_denominator, avs->vi->fps_numerator);\n\n    switch (avs->vi->pixel_type) {\n#ifdef USING_AVISYNTH\n    case AVS_CS_YV24:\n        st->codec->pix_fmt = AV_PIX_FMT_YUV444P;\n        planar             = 1;\n        break;\n    case AVS_CS_YV16:\n        st->codec->pix_fmt = AV_PIX_FMT_YUV422P;\n        planar             = 1;\n        break;\n    case AVS_CS_YV411:\n        st->codec->pix_fmt = AV_PIX_FMT_YUV411P;\n        planar             = 1;\n        break;\n    case AVS_CS_Y8:\n        st->codec->pix_fmt = AV_PIX_FMT_GRAY8;\n        planar             = 2;\n        break;\n#endif\n    case AVS_CS_BGR24:\n        st->codec->pix_fmt = AV_PIX_FMT_BGR24;\n        break;\n    case AVS_CS_BGR32:\n        st->codec->pix_fmt = AV_PIX_FMT_RGB32;\n        break;\n    case AVS_CS_YUY2:\n        st->codec->pix_fmt = AV_PIX_FMT_YUYV422;\n        break;\n    case AVS_CS_YV12:\n        st->codec->pix_fmt = AV_PIX_FMT_YUV420P;\n        planar             = 1;\n        break;\n    case AVS_CS_I420: // Is this even used anywhere?\n        st->codec->pix_fmt = AV_PIX_FMT_YUV420P;\n        planar             = 1;\n        break;\n    default:\n        av_log(s, AV_LOG_ERROR,\n               \"unknown AviSynth colorspace %d\\n\", avs->vi->pixel_type);\n        avs->error = 1;\n        return AVERROR_UNKNOWN;\n    }\n\n    switch (planar) {\n    case 2: // Y8\n        avs->n_planes = 1;\n        avs->planes   = avs_planes_grey;\n        break;\n    case 1: // YUV\n        avs->n_planes = 3;\n        avs->planes   = avs_planes_yuv;\n        break;\n    default:\n        avs->n_planes = 1;\n        avs->planes   = avs_planes_packed;\n    }\n    return 0;\n}\n\nstatic int avisynth_create_stream_audio(AVFormatContext *s, AVStream *st)\n{\n    AviSynthContext *avs = s->priv_data;\n\n    st->codec->codec_type  = AVMEDIA_TYPE_AUDIO;\n    st->codec->sample_rate = avs->vi->audio_samples_per_second;\n    st->codec->channels    = avs->vi->nchannels;\n    st->duration           = avs->vi->num_audio_samples;\n    avpriv_set_pts_info(st, 64, 1, avs->vi->audio_samples_per_second);\n\n    switch (avs->vi->sample_type) {\n    case AVS_SAMPLE_INT8:\n        st->codec->codec_id = AV_CODEC_ID_PCM_U8;\n        break;\n    case AVS_SAMPLE_INT16:\n        st->codec->codec_id = AV_CODEC_ID_PCM_S16LE;\n        break;\n    case AVS_SAMPLE_INT24:\n        st->codec->codec_id = AV_CODEC_ID_PCM_S24LE;\n        break;\n    case AVS_SAMPLE_INT32:\n        st->codec->codec_id = AV_CODEC_ID_PCM_S32LE;\n        break;\n    case AVS_SAMPLE_FLOAT:\n        st->codec->codec_id = AV_CODEC_ID_PCM_F32LE;\n        break;\n    default:\n        av_log(s, AV_LOG_ERROR,\n               \"unknown AviSynth sample type %d\\n\", avs->vi->sample_type);\n        avs->error = 1;\n        return AVERROR_UNKNOWN;\n    }\n    return 0;\n}\n\nstatic int avisynth_create_stream(AVFormatContext *s)\n{\n    AviSynthContext *avs = s->priv_data;\n    AVStream *st;\n    int ret;\n    int id = 0;\n\n    if (avs_has_video(avs->vi)) {\n        st = avformat_new_stream(s, NULL);\n        if (!st)\n            return AVERROR_UNKNOWN;\n        st->id = id++;\n        if (ret = avisynth_create_stream_video(s, st))\n            return ret;\n    }\n    if (avs_has_audio(avs->vi)) {\n        st = avformat_new_stream(s, NULL);\n        if (!st)\n            return AVERROR_UNKNOWN;\n        st->id = id++;\n        if (ret = avisynth_create_stream_audio(s, st))\n            return ret;\n    }\n    return 0;\n}\n\nstatic int avisynth_open_file(AVFormatContext *s)\n{\n    AviSynthContext *avs = s->priv_data;\n    AVS_Value arg, val;\n    int ret;\n#ifdef USING_AVISYNTH\n    char filename_ansi[MAX_PATH * 4];\n    wchar_t filename_wc[MAX_PATH * 4];\n#endif\n\n    if (ret = avisynth_context_create(s))\n        return ret;\n\n#ifdef USING_AVISYNTH\n    /* Convert UTF-8 to ANSI code page */\n    MultiByteToWideChar(CP_UTF8, 0, s->filename, -1, filename_wc, MAX_PATH * 4);\n    WideCharToMultiByte(CP_THREAD_ACP, 0, filename_wc, -1, filename_ansi,\n                        MAX_PATH * 4, NULL, NULL);\n    arg = avs_new_value_string(filename_ansi);\n#else\n    arg = avs_new_value_string(s->filename);\n#endif\n    val = avs_library.avs_invoke(avs->env, \"Import\", arg, 0);\n    if (avs_is_error(val)) {\n        av_log(s, AV_LOG_ERROR, \"%s\\n\", avs_as_error(val));\n        ret = AVERROR_UNKNOWN;\n        goto fail;\n    }\n    if (!avs_is_clip(val)) {\n        av_log(s, AV_LOG_ERROR, \"AviSynth script did not return a clip\\n\");\n        ret = AVERROR_UNKNOWN;\n        goto fail;\n    }\n\n    avs->clip = avs_library.avs_take_clip(val, avs->env);\n    avs->vi   = avs_library.avs_get_video_info(avs->clip);\n\n#ifdef USING_AVISYNTH\n    /* On Windows, FFmpeg supports AviSynth interface version 6 or higher.\n     * This includes AviSynth 2.6 RC1 or higher, and AviSynth+ r1718 or higher,\n     * and excludes 2.5 and the 2.6 alphas. Since AvxSynth identifies itself\n     * as interface version 3 like 2.5.8, this needs to be special-cased. */\n\n    if (avs_library.avs_get_version(avs->clip) < 6) {\n        av_log(s, AV_LOG_ERROR,\n               \"AviSynth version is too old. Please upgrade to either AviSynth 2.6 >= RC1 or AviSynth+ >= r1718.\\n\");\n        ret = AVERROR_UNKNOWN;\n        goto fail;\n    }\n#endif\n\n    /* Release the AVS_Value as it will go out of scope. */\n    avs_library.avs_release_value(val);\n\n    if (ret = avisynth_create_stream(s))\n        goto fail;\n\n    return 0;\n\nfail:\n    avisynth_context_destroy(avs);\n    return ret;\n}\n\nstatic void avisynth_next_stream(AVFormatContext *s, AVStream **st,\n                                 AVPacket *pkt, int *discard)\n{\n    AviSynthContext *avs = s->priv_data;\n\n    avs->curr_stream++;\n    avs->curr_stream %= s->nb_streams;\n\n    *st = s->streams[avs->curr_stream];\n    if ((*st)->discard == AVDISCARD_ALL)\n        *discard = 1;\n    else\n        *discard = 0;\n\n    return;\n}\n\n/* Copy AviSynth clip data into an AVPacket. */\nstatic int avisynth_read_packet_video(AVFormatContext *s, AVPacket *pkt,\n                                      int discard)\n{\n    AviSynthContext *avs = s->priv_data;\n    AVS_VideoFrame *frame;\n    unsigned char *dst_p;\n    const unsigned char *src_p;\n    int n, i, plane, rowsize, planeheight, pitch, bits;\n    const char *error;\n\n    if (avs->curr_frame >= avs->vi->num_frames)\n        return AVERROR_EOF;\n\n    /* This must happen even if the stream is discarded to prevent desync. */\n    n = avs->curr_frame++;\n    if (discard)\n        return 0;\n\n#ifdef USING_AVISYNTH\n    /* Define the bpp values for the new AviSynth 2.6 colorspaces.\n     * Since AvxSynth doesn't have these functions, special-case\n     * it in order to avoid implicit declaration errors. */\n\n    if (avs_library.avs_is_yv24(avs->vi))\n        bits = 24;\n    else if (avs_library.avs_is_yv16(avs->vi))\n        bits = 16;\n    else if (avs_library.avs_is_yv411(avs->vi))\n        bits = 12;\n    else if (avs_library.avs_is_y8(avs->vi))\n        bits = 8;\n    else\n        bits = avs_library.avs_bits_per_pixel(avs->vi);\n#else\n    bits = avs_bits_per_pixel(avs->vi);\n#endif\n\n    /* Without the cast to int64_t, calculation overflows at about 9k x 9k\n     * resolution. */\n    pkt->size = (((int64_t)avs->vi->width *\n                  (int64_t)avs->vi->height) * bits) / 8;\n    if (!pkt->size)\n        return AVERROR_UNKNOWN;\n\n    if (av_new_packet(pkt, pkt->size) < 0)\n        return AVERROR(ENOMEM);\n\n    pkt->pts      = n;\n    pkt->dts      = n;\n    pkt->duration = 1;\n    pkt->stream_index = avs->curr_stream;\n\n    frame = avs_library.avs_get_frame(avs->clip, n);\n    error = avs_library.avs_clip_get_error(avs->clip);\n    if (error) {\n        av_log(s, AV_LOG_ERROR, \"%s\\n\", error);\n        avs->error = 1;\n        av_packet_unref(pkt);\n        return AVERROR_UNKNOWN;\n    }\n\n    dst_p = pkt->data;\n    for (i = 0; i < avs->n_planes; i++) {\n        plane = avs->planes[i];\n#ifdef USING_AVISYNTH\n        src_p = avs_library.avs_get_read_ptr_p(frame, plane);\n        pitch = avs_library.avs_get_pitch_p(frame, plane);\n\n        rowsize     = avs_library.avs_get_row_size_p(frame, plane);\n        planeheight = avs_library.avs_get_height_p(frame, plane);\n#else\n        src_p = avs_get_read_ptr_p(frame, plane);\n        pitch = avs_get_pitch_p(frame, plane);\n\n        rowsize     = avs_get_row_size_p(frame, plane);\n        planeheight = avs_get_height_p(frame, plane);\n#endif\n\n        /* Flip RGB video. */\n        if (avs_is_rgb24(avs->vi) || avs_is_rgb(avs->vi)) {\n            src_p = src_p + (planeheight - 1) * pitch;\n            pitch = -pitch;\n        }\n\n        avs_library.avs_bit_blt(avs->env, dst_p, rowsize, src_p, pitch,\n                                 rowsize, planeheight);\n        dst_p += rowsize * planeheight;\n    }\n\n    avs_library.avs_release_video_frame(frame);\n    return 0;\n}\n\nstatic int avisynth_read_packet_audio(AVFormatContext *s, AVPacket *pkt,\n                                      int discard)\n{\n    AviSynthContext *avs = s->priv_data;\n    AVRational fps, samplerate;\n    int samples;\n    int64_t n;\n    const char *error;\n\n    if (avs->curr_sample >= avs->vi->num_audio_samples)\n        return AVERROR_EOF;\n\n    fps.num        = avs->vi->fps_numerator;\n    fps.den        = avs->vi->fps_denominator;\n    samplerate.num = avs->vi->audio_samples_per_second;\n    samplerate.den = 1;\n\n    if (avs_has_video(avs->vi)) {\n        if (avs->curr_frame < avs->vi->num_frames)\n            samples = av_rescale_q(avs->curr_frame, samplerate, fps) -\n                      avs->curr_sample;\n        else\n            samples = av_rescale_q(1, samplerate, fps);\n    } else {\n        samples = 1000;\n    }\n\n    /* After seeking, audio may catch up with video. */\n    if (samples <= 0) {\n        pkt->size = 0;\n        pkt->data = NULL;\n        return 0;\n    }\n\n    if (avs->curr_sample + samples > avs->vi->num_audio_samples)\n        samples = avs->vi->num_audio_samples - avs->curr_sample;\n\n    /* This must happen even if the stream is discarded to prevent desync. */\n    n                 = avs->curr_sample;\n    avs->curr_sample += samples;\n    if (discard)\n        return 0;\n\n    pkt->size = avs_bytes_per_channel_sample(avs->vi) *\n                samples * avs->vi->nchannels;\n    if (!pkt->size)\n        return AVERROR_UNKNOWN;\n\n    if (av_new_packet(pkt, pkt->size) < 0)\n        return AVERROR(ENOMEM);\n\n    pkt->pts      = n;\n    pkt->dts      = n;\n    pkt->duration = samples;\n    pkt->stream_index = avs->curr_stream;\n\n    avs_library.avs_get_audio(avs->clip, pkt->data, n, samples);\n    error = avs_library.avs_clip_get_error(avs->clip);\n    if (error) {\n        av_log(s, AV_LOG_ERROR, \"%s\\n\", error);\n        avs->error = 1;\n        av_packet_unref(pkt);\n        return AVERROR_UNKNOWN;\n    }\n    return 0;\n}\n\nstatic av_cold int avisynth_read_header(AVFormatContext *s)\n{\n    int ret;\n\n    // Calling library must implement a lock for thread-safe opens.\n    if (ret = avpriv_lock_avformat())\n        return ret;\n\n    if (ret = avisynth_open_file(s)) {\n        avpriv_unlock_avformat();\n        return ret;\n    }\n\n    avpriv_unlock_avformat();\n    return 0;\n}\n\nstatic int avisynth_read_packet(AVFormatContext *s, AVPacket *pkt)\n{\n    AviSynthContext *avs = s->priv_data;\n    AVStream *st;\n    int discard = 0;\n    int ret;\n\n    if (avs->error)\n        return AVERROR_UNKNOWN;\n\n    /* If either stream reaches EOF, try to read the other one before\n     * giving up. */\n    avisynth_next_stream(s, &st, pkt, &discard);\n    if (st->codec->codec_type == AVMEDIA_TYPE_VIDEO) {\n        ret = avisynth_read_packet_video(s, pkt, discard);\n        if (ret == AVERROR_EOF && avs_has_audio(avs->vi)) {\n            avisynth_next_stream(s, &st, pkt, &discard);\n            return avisynth_read_packet_audio(s, pkt, discard);\n        }\n    } else {\n        ret = avisynth_read_packet_audio(s, pkt, discard);\n        if (ret == AVERROR_EOF && avs_has_video(avs->vi)) {\n            avisynth_next_stream(s, &st, pkt, &discard);\n            return avisynth_read_packet_video(s, pkt, discard);\n        }\n    }\n\n    return ret;\n}\n\nstatic av_cold int avisynth_read_close(AVFormatContext *s)\n{\n    if (avpriv_lock_avformat())\n        return AVERROR_UNKNOWN;\n\n    avisynth_context_destroy(s->priv_data);\n    avpriv_unlock_avformat();\n    return 0;\n}\n\nstatic int avisynth_read_seek(AVFormatContext *s, int stream_index,\n                              int64_t timestamp, int flags)\n{\n    AviSynthContext *avs = s->priv_data;\n    AVStream *st;\n    AVRational fps, samplerate;\n\n    if (avs->error)\n        return AVERROR_UNKNOWN;\n\n    fps        = (AVRational) { avs->vi->fps_numerator,\n                                avs->vi->fps_denominator };\n    samplerate = (AVRational) { avs->vi->audio_samples_per_second, 1 };\n\n    st = s->streams[stream_index];\n    if (st->codec->codec_type == AVMEDIA_TYPE_VIDEO) {\n        /* AviSynth frame counts are signed int. */\n        if ((timestamp >= avs->vi->num_frames) ||\n            (timestamp > INT_MAX)              ||\n            (timestamp < 0))\n            return AVERROR_EOF;\n        avs->curr_frame = timestamp;\n        if (avs_has_audio(avs->vi))\n            avs->curr_sample = av_rescale_q(timestamp, samplerate, fps);\n    } else {\n        if ((timestamp >= avs->vi->num_audio_samples) || (timestamp < 0))\n            return AVERROR_EOF;\n        /* Force frame granularity for seeking. */\n        if (avs_has_video(avs->vi)) {\n            avs->curr_frame  = av_rescale_q(timestamp, fps, samplerate);\n            avs->curr_sample = av_rescale_q(avs->curr_frame, samplerate, fps);\n        } else {\n            avs->curr_sample = timestamp;\n        }\n    }\n\n    return 0;\n}\n\nAVInputFormat ff_avisynth_demuxer = {\n    .name           = \"avisynth\",\n    .long_name      = NULL_IF_CONFIG_SMALL(\"AviSynth script\"),\n    .priv_data_size = sizeof(AviSynthContext),\n    .read_header    = avisynth_read_header,\n    .read_packet    = avisynth_read_packet,\n    .read_close     = avisynth_read_close,\n    .read_seek      = avisynth_read_seek,\n    .extensions     = \"avs\",\n};\n",
        "/tmp/vanessa/spack-stage/spack-stage-ffmpeg-2.8.15-ozpyncprat26dr3j2bmhjj5jpw7za2d2/spack-src/libavfilter/vf_frei0r.c": "/*\n * Copyright (c) 2010 Stefano Sabatini\n * This file is part of FFmpeg.\n *\n * FFmpeg is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License as published by the Free Software Foundation; either\n * version 2.1 of the License, or (at your option) any later version.\n *\n * FFmpeg is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with FFmpeg; if not, write to the Free Software\n * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n */\n\n/**\n * @file\n * frei0r wrapper\n */\n\n#include <dlfcn.h>\n#include <frei0r.h>\n#include <stdio.h>\n#include <string.h>\n#include <stdlib.h>\n#include \"config.h\"\n#include \"libavutil/avstring.h\"\n#include \"libavutil/common.h\"\n#include \"libavutil/imgutils.h\"\n#include \"libavutil/internal.h\"\n#include \"libavutil/mathematics.h\"\n#include \"libavutil/mem.h\"\n#include \"libavutil/opt.h\"\n#include \"libavutil/parseutils.h\"\n#include \"avfilter.h\"\n#include \"formats.h\"\n#include \"internal.h\"\n#include \"video.h\"\n\ntypedef f0r_instance_t (*f0r_construct_f)(unsigned int width, unsigned int height);\ntypedef void (*f0r_destruct_f)(f0r_instance_t instance);\ntypedef void (*f0r_deinit_f)(void);\ntypedef int (*f0r_init_f)(void);\ntypedef void (*f0r_get_plugin_info_f)(f0r_plugin_info_t *info);\ntypedef void (*f0r_get_param_info_f)(f0r_param_info_t *info, int param_index);\ntypedef void (*f0r_update_f)(f0r_instance_t instance, double time, const uint32_t *inframe, uint32_t *outframe);\ntypedef void (*f0r_update2_f)(f0r_instance_t instance, double time, const uint32_t *inframe1, const uint32_t *inframe2, const uint32_t *inframe3, uint32_t *outframe);\ntypedef void (*f0r_set_param_value_f)(f0r_instance_t instance, f0r_param_t param, int param_index);\ntypedef void (*f0r_get_param_value_f)(f0r_instance_t instance, f0r_param_t param, int param_index);\n\ntypedef struct Frei0rContext {\n    const AVClass *class;\n    f0r_update_f update;\n    void *dl_handle;            /* dynamic library handle   */\n    f0r_instance_t instance;\n    f0r_plugin_info_t plugin_info;\n\n    f0r_get_param_info_f  get_param_info;\n    f0r_get_param_value_f get_param_value;\n    f0r_set_param_value_f set_param_value;\n    f0r_construct_f       construct;\n    f0r_destruct_f        destruct;\n    f0r_deinit_f          deinit;\n\n    char *dl_name;\n    char *params;\n    AVRational framerate;\n\n    /* only used by the source */\n    int w, h;\n    AVRational time_base;\n    uint64_t pts;\n} Frei0rContext;\n\nstatic void *load_sym(AVFilterContext *ctx, const char *sym_name)\n{\n    Frei0rContext *s = ctx->priv;\n    void *sym = dlsym(s->dl_handle, sym_name);\n    if (!sym)\n        av_log(ctx, AV_LOG_ERROR, \"Could not find symbol '%s' in loaded module.\\n\", sym_name);\n    return sym;\n}\n\nstatic int set_param(AVFilterContext *ctx, f0r_param_info_t info, int index, char *param)\n{\n    Frei0rContext *s = ctx->priv;\n    union {\n        double d;\n        f0r_param_color_t col;\n        f0r_param_position_t pos;\n    } val;\n    char *tail;\n    uint8_t rgba[4];\n\n    switch (info.type) {\n    case F0R_PARAM_BOOL:\n        if      (!strcmp(param, \"y\")) val.d = 1.0;\n        else if (!strcmp(param, \"n\")) val.d = 0.0;\n        else goto fail;\n        break;\n\n    case F0R_PARAM_DOUBLE:\n        val.d = strtod(param, &tail);\n        if (*tail || val.d == HUGE_VAL)\n            goto fail;\n        break;\n\n    case F0R_PARAM_COLOR:\n        if (sscanf(param, \"%f/%f/%f\", &val.col.r, &val.col.g, &val.col.b) != 3) {\n            if (av_parse_color(rgba, param, -1, ctx) < 0)\n                goto fail;\n            val.col.r = rgba[0] / 255.0;\n            val.col.g = rgba[1] / 255.0;\n            val.col.b = rgba[2] / 255.0;\n        }\n        break;\n\n    case F0R_PARAM_POSITION:\n        if (sscanf(param, \"%lf/%lf\", &val.pos.x, &val.pos.y) != 2)\n            goto fail;\n        break;\n    }\n\n    s->set_param_value(s->instance, &val, index);\n    return 0;\n\nfail:\n    av_log(ctx, AV_LOG_ERROR, \"Invalid value '%s' for parameter '%s'.\\n\",\n           param, info.name);\n    return AVERROR(EINVAL);\n}\n\nstatic int set_params(AVFilterContext *ctx, const char *params)\n{\n    Frei0rContext *s = ctx->priv;\n    int i;\n\n    if (!params)\n        return 0;\n\n    for (i = 0; i < s->plugin_info.num_params; i++) {\n        f0r_param_info_t info;\n        char *param;\n        int ret;\n\n        s->get_param_info(&info, i);\n\n        if (*params) {\n            if (!(param = av_get_token(&params, \"|\")))\n                return AVERROR(ENOMEM);\n            if (*params)\n                params++;               /* skip ':' */\n            ret = set_param(ctx, info, i, param);\n            av_free(param);\n            if (ret < 0)\n                return ret;\n        }\n\n        av_log(ctx, AV_LOG_VERBOSE,\n               \"idx:%d name:'%s' type:%s explanation:'%s' \",\n               i, info.name,\n               info.type == F0R_PARAM_BOOL     ? \"bool\"     :\n               info.type == F0R_PARAM_DOUBLE   ? \"double\"   :\n               info.type == F0R_PARAM_COLOR    ? \"color\"    :\n               info.type == F0R_PARAM_POSITION ? \"position\" :\n               info.type == F0R_PARAM_STRING   ? \"string\"   : \"unknown\",\n               info.explanation);\n\n#ifdef DEBUG\n        av_log(ctx, AV_LOG_DEBUG, \"value:\");\n        switch (info.type) {\n            void *v;\n            double d;\n            char str[128];\n            f0r_param_color_t col;\n            f0r_param_position_t pos;\n\n        case F0R_PARAM_BOOL:\n            v = &d;\n            s->get_param_value(s->instance, v, i);\n            av_log(ctx, AV_LOG_DEBUG, \"%s\", d >= 0.5 && d <= 1.0 ? \"y\" : \"n\");\n            break;\n        case F0R_PARAM_DOUBLE:\n            v = &d;\n            s->get_param_value(s->instance, v, i);\n            av_log(ctx, AV_LOG_DEBUG, \"%f\", d);\n            break;\n        case F0R_PARAM_COLOR:\n            v = &col;\n            s->get_param_value(s->instance, v, i);\n            av_log(ctx, AV_LOG_DEBUG, \"%f/%f/%f\", col.r, col.g, col.b);\n            break;\n        case F0R_PARAM_POSITION:\n            v = &pos;\n            s->get_param_value(s->instance, v, i);\n            av_log(ctx, AV_LOG_DEBUG, \"%f/%f\", pos.x, pos.y);\n            break;\n        default: /* F0R_PARAM_STRING */\n            v = str;\n            s->get_param_value(s->instance, v, i);\n            av_log(ctx, AV_LOG_DEBUG, \"'%s'\", str);\n            break;\n        }\n#endif\n        av_log(ctx, AV_LOG_VERBOSE, \".\\n\");\n    }\n\n    return 0;\n}\n\nstatic int load_path(AVFilterContext *ctx, void **handle_ptr, const char *prefix, const char *name)\n{\n    char *path = av_asprintf(\"%s%s%s\", prefix, name, SLIBSUF);\n    if (!path)\n        return AVERROR(ENOMEM);\n    av_log(ctx, AV_LOG_DEBUG, \"Looking for frei0r effect in '%s'.\\n\", path);\n    *handle_ptr = dlopen(path, RTLD_NOW|RTLD_LOCAL);\n    av_free(path);\n    return 0;\n}\n\nstatic av_cold int frei0r_init(AVFilterContext *ctx,\n                               const char *dl_name, int type)\n{\n    Frei0rContext *s = ctx->priv;\n    f0r_init_f            f0r_init;\n    f0r_get_plugin_info_f f0r_get_plugin_info;\n    f0r_plugin_info_t *pi;\n    char *path;\n    int ret = 0;\n    int i;\n    static const char* const frei0r_pathlist[] = {\n        \"/usr/local/lib/frei0r-1/\",\n        \"/usr/lib/frei0r-1/\",\n        \"/usr/local/lib64/frei0r-1/\",\n        \"/usr/lib64/frei0r-1/\"\n    };\n\n    if (!dl_name) {\n        av_log(ctx, AV_LOG_ERROR, \"No filter name provided.\\n\");\n        return AVERROR(EINVAL);\n    }\n\n    /* see: http://frei0r.dyne.org/codedoc/html/group__pluglocations.html */\n    if ((path = av_strdup(getenv(\"FREI0R_PATH\")))) {\n#ifdef _WIN32\n        const char *separator = \";\";\n#else\n        const char *separator = \":\";\n#endif\n        char *p, *ptr = NULL;\n        for (p = path; p = av_strtok(p, separator, &ptr); p = NULL) {\n            /* add additional trailing slash in case it is missing */\n            char *p1 = av_asprintf(\"%s/\", p);\n            if (!p1) {\n                ret = AVERROR(ENOMEM);\n                goto check_path_end;\n            }\n            ret = load_path(ctx, &s->dl_handle, p1, dl_name);\n            av_free(p1);\n            if (ret < 0)\n                goto check_path_end;\n            if (s->dl_handle)\n                break;\n        }\n\n    check_path_end:\n        av_free(path);\n        if (ret < 0)\n            return ret;\n    }\n    if (!s->dl_handle && (path = getenv(\"HOME\"))) {\n        char *prefix = av_asprintf(\"%s/.frei0r-1/lib/\", path);\n        if (!prefix)\n            return AVERROR(ENOMEM);\n        ret = load_path(ctx, &s->dl_handle, prefix, dl_name);\n        av_free(prefix);\n        if (ret < 0)\n            return ret;\n    }\n    for (i = 0; !s->dl_handle && i < FF_ARRAY_ELEMS(frei0r_pathlist); i++) {\n        ret = load_path(ctx, &s->dl_handle, frei0r_pathlist[i], dl_name);\n        if (ret < 0)\n            return ret;\n    }\n    if (!s->dl_handle) {\n        av_log(ctx, AV_LOG_ERROR, \"Could not find module '%s'.\\n\", dl_name);\n        return AVERROR(EINVAL);\n    }\n\n    if (!(f0r_init                = load_sym(ctx, \"f0r_init\"           )) ||\n        !(f0r_get_plugin_info     = load_sym(ctx, \"f0r_get_plugin_info\")) ||\n        !(s->get_param_info  = load_sym(ctx, \"f0r_get_param_info\" )) ||\n        !(s->get_param_value = load_sym(ctx, \"f0r_get_param_value\")) ||\n        !(s->set_param_value = load_sym(ctx, \"f0r_set_param_value\")) ||\n        !(s->update          = load_sym(ctx, \"f0r_update\"         )) ||\n        !(s->construct       = load_sym(ctx, \"f0r_construct\"      )) ||\n        !(s->destruct        = load_sym(ctx, \"f0r_destruct\"       )) ||\n        !(s->deinit          = load_sym(ctx, \"f0r_deinit\"         )))\n        return AVERROR(EINVAL);\n\n    if (f0r_init() < 0) {\n        av_log(ctx, AV_LOG_ERROR, \"Could not init the frei0r module.\\n\");\n        return AVERROR(EINVAL);\n    }\n\n    f0r_get_plugin_info(&s->plugin_info);\n    pi = &s->plugin_info;\n    if (pi->plugin_type != type) {\n        av_log(ctx, AV_LOG_ERROR,\n               \"Invalid type '%s' for this plugin\\n\",\n               pi->plugin_type == F0R_PLUGIN_TYPE_FILTER ? \"filter\" :\n               pi->plugin_type == F0R_PLUGIN_TYPE_SOURCE ? \"source\" :\n               pi->plugin_type == F0R_PLUGIN_TYPE_MIXER2 ? \"mixer2\" :\n               pi->plugin_type == F0R_PLUGIN_TYPE_MIXER3 ? \"mixer3\" : \"unknown\");\n        return AVERROR(EINVAL);\n    }\n\n    av_log(ctx, AV_LOG_VERBOSE,\n           \"name:%s author:'%s' explanation:'%s' color_model:%s \"\n           \"frei0r_version:%d version:%d.%d num_params:%d\\n\",\n           pi->name, pi->author, pi->explanation,\n           pi->color_model == F0R_COLOR_MODEL_BGRA8888 ? \"bgra8888\" :\n           pi->color_model == F0R_COLOR_MODEL_RGBA8888 ? \"rgba8888\" :\n           pi->color_model == F0R_COLOR_MODEL_PACKED32 ? \"packed32\" : \"unknown\",\n           pi->frei0r_version, pi->major_version, pi->minor_version, pi->num_params);\n\n    return 0;\n}\n\nstatic av_cold int filter_init(AVFilterContext *ctx)\n{\n    Frei0rContext *s = ctx->priv;\n\n    return frei0r_init(ctx, s->dl_name, F0R_PLUGIN_TYPE_FILTER);\n}\n\nstatic av_cold void uninit(AVFilterContext *ctx)\n{\n    Frei0rContext *s = ctx->priv;\n\n    if (s->destruct && s->instance)\n        s->destruct(s->instance);\n    if (s->deinit)\n        s->deinit();\n    if (s->dl_handle)\n        dlclose(s->dl_handle);\n}\n\nstatic int config_input_props(AVFilterLink *inlink)\n{\n    AVFilterContext *ctx = inlink->dst;\n    Frei0rContext *s = ctx->priv;\n\n    if (s->destruct && s->instance)\n        s->destruct(s->instance);\n    if (!(s->instance = s->construct(inlink->w, inlink->h))) {\n        av_log(ctx, AV_LOG_ERROR, \"Impossible to load frei0r instance.\\n\");\n        return AVERROR(EINVAL);\n    }\n\n    return set_params(ctx, s->params);\n}\n\nstatic int query_formats(AVFilterContext *ctx)\n{\n    Frei0rContext *s = ctx->priv;\n    AVFilterFormats *formats = NULL;\n\n    if        (s->plugin_info.color_model == F0R_COLOR_MODEL_BGRA8888) {\n        ff_add_format(&formats, AV_PIX_FMT_BGRA);\n    } else if (s->plugin_info.color_model == F0R_COLOR_MODEL_RGBA8888) {\n        ff_add_format(&formats, AV_PIX_FMT_RGBA);\n    } else {                                   /* F0R_COLOR_MODEL_PACKED32 */\n        static const enum AVPixelFormat pix_fmts[] = {\n            AV_PIX_FMT_BGRA, AV_PIX_FMT_ARGB, AV_PIX_FMT_ABGR, AV_PIX_FMT_ARGB, AV_PIX_FMT_NONE\n        };\n        formats = ff_make_format_list(pix_fmts);\n    }\n\n    if (!formats)\n        return AVERROR(ENOMEM);\n\n    return ff_set_common_formats(ctx, formats);\n}\n\nstatic int filter_frame(AVFilterLink *inlink, AVFrame *in)\n{\n    Frei0rContext *s = inlink->dst->priv;\n    AVFilterLink *outlink = inlink->dst->outputs[0];\n    AVFrame *out;\n\n    out = ff_get_video_buffer(outlink, outlink->w, outlink->h);\n    if (!out) {\n        av_frame_free(&in);\n        return AVERROR(ENOMEM);\n    }\n    av_frame_copy_props(out, in);\n\n    s->update(s->instance, in->pts * av_q2d(inlink->time_base) * 1000,\n                   (const uint32_t *)in->data[0],\n                   (uint32_t *)out->data[0]);\n\n    av_frame_free(&in);\n\n    return ff_filter_frame(outlink, out);\n}\n\n#define OFFSET(x) offsetof(Frei0rContext, x)\n#define FLAGS AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_FILTERING_PARAM\nstatic const AVOption frei0r_options[] = {\n    { \"filter_name\",   NULL, OFFSET(dl_name), AV_OPT_TYPE_STRING, .flags = FLAGS },\n    { \"filter_params\", NULL, OFFSET(params),  AV_OPT_TYPE_STRING, .flags = FLAGS },\n    { NULL }\n};\n\nAVFILTER_DEFINE_CLASS(frei0r);\n\nstatic const AVFilterPad avfilter_vf_frei0r_inputs[] = {\n    {\n        .name         = \"default\",\n        .type         = AVMEDIA_TYPE_VIDEO,\n        .config_props = config_input_props,\n        .filter_frame = filter_frame,\n    },\n    { NULL }\n};\n\nstatic const AVFilterPad avfilter_vf_frei0r_outputs[] = {\n    {\n        .name = \"default\",\n        .type = AVMEDIA_TYPE_VIDEO,\n    },\n    { NULL }\n};\n\nAVFilter ff_vf_frei0r = {\n    .name          = \"frei0r\",\n    .description   = NULL_IF_CONFIG_SMALL(\"Apply a frei0r effect.\"),\n    .query_formats = query_formats,\n    .init          = filter_init,\n    .uninit        = uninit,\n    .priv_size     = sizeof(Frei0rContext),\n    .priv_class    = &frei0r_class,\n    .inputs        = avfilter_vf_frei0r_inputs,\n    .outputs       = avfilter_vf_frei0r_outputs,\n};\n\nstatic av_cold int source_init(AVFilterContext *ctx)\n{\n    Frei0rContext *s = ctx->priv;\n\n    s->time_base.num = s->framerate.den;\n    s->time_base.den = s->framerate.num;\n\n    return frei0r_init(ctx, s->dl_name, F0R_PLUGIN_TYPE_SOURCE);\n}\n\nstatic int source_config_props(AVFilterLink *outlink)\n{\n    AVFilterContext *ctx = outlink->src;\n    Frei0rContext *s = ctx->priv;\n\n    if (av_image_check_size(s->w, s->h, 0, ctx) < 0)\n        return AVERROR(EINVAL);\n    outlink->w = s->w;\n    outlink->h = s->h;\n    outlink->time_base = s->time_base;\n    outlink->frame_rate = av_inv_q(s->time_base);\n    outlink->sample_aspect_ratio = (AVRational){1,1};\n\n    if (s->destruct && s->instance)\n        s->destruct(s->instance);\n    if (!(s->instance = s->construct(outlink->w, outlink->h))) {\n        av_log(ctx, AV_LOG_ERROR, \"Impossible to load frei0r instance.\\n\");\n        return AVERROR(EINVAL);\n    }\n    if (!s->params) {\n        av_log(ctx, AV_LOG_ERROR, \"frei0r filter parameters not set.\\n\");\n        return AVERROR(EINVAL);\n    }\n\n    return set_params(ctx, s->params);\n}\n\nstatic int source_request_frame(AVFilterLink *outlink)\n{\n    Frei0rContext *s = outlink->src->priv;\n    AVFrame *frame = ff_get_video_buffer(outlink, outlink->w, outlink->h);\n\n    if (!frame)\n        return AVERROR(ENOMEM);\n\n    frame->sample_aspect_ratio = (AVRational) {1, 1};\n    frame->pts = s->pts++;\n\n    s->update(s->instance, av_rescale_q(frame->pts, s->time_base, (AVRational){1,1000}),\n                   NULL, (uint32_t *)frame->data[0]);\n\n    return ff_filter_frame(outlink, frame);\n}\n\nstatic const AVOption frei0r_src_options[] = {\n    { \"size\",          \"Dimensions of the generated video.\", OFFSET(w),         AV_OPT_TYPE_IMAGE_SIZE, { .str = \"320x240\" }, .flags = FLAGS },\n    { \"framerate\",     NULL,                                 OFFSET(framerate), AV_OPT_TYPE_VIDEO_RATE, { .str = \"25\" }, .flags = FLAGS },\n    { \"filter_name\",   NULL,                                 OFFSET(dl_name),   AV_OPT_TYPE_STRING,                  .flags = FLAGS },\n    { \"filter_params\", NULL,                                 OFFSET(params),    AV_OPT_TYPE_STRING,                  .flags = FLAGS },\n    { NULL },\n};\n\nAVFILTER_DEFINE_CLASS(frei0r_src);\n\nstatic const AVFilterPad avfilter_vsrc_frei0r_src_outputs[] = {\n    {\n        .name          = \"default\",\n        .type          = AVMEDIA_TYPE_VIDEO,\n        .request_frame = source_request_frame,\n        .config_props  = source_config_props\n    },\n    { NULL }\n};\n\nAVFilter ff_vsrc_frei0r_src = {\n    .name          = \"frei0r_src\",\n    .description   = NULL_IF_CONFIG_SMALL(\"Generate a frei0r source.\"),\n    .priv_size     = sizeof(Frei0rContext),\n    .priv_class    = &frei0r_src_class,\n    .init          = source_init,\n    .uninit        = uninit,\n    .query_formats = query_formats,\n    .inputs        = NULL,\n    .outputs       = avfilter_vsrc_frei0r_src_outputs,\n};\n",
        "/tmp/vanessa/spack-stage/spack-stage-ffmpeg-2.8.15-ozpyncprat26dr3j2bmhjj5jpw7za2d2/spack-src/libavfilter/af_ladspa.c": "/*\n * Copyright (c) 2013 Paul B Mahol\n * Copyright (c) 2011 Mina Nagy Zaki\n *\n * This file is part of FFmpeg.\n *\n * FFmpeg is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License as published by the Free Software Foundation; either\n * version 2.1 of the License, or (at your option) any later version.\n *\n * FFmpeg is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with FFmpeg; if not, write to the Free Software\n * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n */\n\n/**\n * @file\n * LADSPA wrapper\n */\n\n#include <dlfcn.h>\n#include <ladspa.h>\n#include \"libavutil/avstring.h\"\n#include \"libavutil/channel_layout.h\"\n#include \"libavutil/opt.h\"\n#include \"audio.h\"\n#include \"avfilter.h\"\n#include \"internal.h\"\n\ntypedef struct LADSPAContext {\n    const AVClass *class;\n    char *dl_name;\n    char *plugin;\n    char *options;\n    void *dl_handle;\n\n    unsigned long nb_inputs;\n    unsigned long *ipmap;      /* map input number to port number */\n\n    unsigned long nb_inputcontrols;\n    unsigned long *icmap;      /* map input control number to port number */\n    LADSPA_Data *ictlv;        /* input controls values */\n\n    unsigned long nb_outputs;\n    unsigned long *opmap;      /* map output number to port number */\n\n    unsigned long nb_outputcontrols;\n    unsigned long *ocmap;      /* map output control number to port number */\n    LADSPA_Data *octlv;        /* output controls values */\n\n    const LADSPA_Descriptor *desc;\n    int *ctl_needs_value;\n    int nb_handles;\n    LADSPA_Handle *handles;\n\n    int sample_rate;\n    int nb_samples;\n    int64_t pts;\n    int64_t duration;\n} LADSPAContext;\n\n#define OFFSET(x) offsetof(LADSPAContext, x)\n#define FLAGS AV_OPT_FLAG_AUDIO_PARAM | AV_OPT_FLAG_FILTERING_PARAM\nstatic const AVOption ladspa_options[] = {\n    { \"file\", \"set library name or full path\", OFFSET(dl_name), AV_OPT_TYPE_STRING, .flags = FLAGS },\n    { \"f\",    \"set library name or full path\", OFFSET(dl_name), AV_OPT_TYPE_STRING, .flags = FLAGS },\n    { \"plugin\", \"set plugin name\", OFFSET(plugin), AV_OPT_TYPE_STRING, .flags = FLAGS },\n    { \"p\",      \"set plugin name\", OFFSET(plugin), AV_OPT_TYPE_STRING, .flags = FLAGS },\n    { \"controls\", \"set plugin options\", OFFSET(options), AV_OPT_TYPE_STRING, .flags = FLAGS },\n    { \"c\",        \"set plugin options\", OFFSET(options), AV_OPT_TYPE_STRING, .flags = FLAGS },\n    { \"sample_rate\", \"set sample rate\", OFFSET(sample_rate), AV_OPT_TYPE_INT, {.i64=44100}, 1, INT32_MAX, FLAGS },\n    { \"s\",           \"set sample rate\", OFFSET(sample_rate), AV_OPT_TYPE_INT, {.i64=44100}, 1, INT32_MAX, FLAGS },\n    { \"nb_samples\", \"set the number of samples per requested frame\", OFFSET(nb_samples), AV_OPT_TYPE_INT, {.i64=1024}, 1, INT_MAX, FLAGS },\n    { \"n\",          \"set the number of samples per requested frame\", OFFSET(nb_samples), AV_OPT_TYPE_INT, {.i64=1024}, 1, INT_MAX, FLAGS },\n    { \"duration\", \"set audio duration\", OFFSET(duration), AV_OPT_TYPE_DURATION, {.i64=-1}, -1, INT64_MAX, FLAGS },\n    { \"d\",        \"set audio duration\", OFFSET(duration), AV_OPT_TYPE_DURATION, {.i64=-1}, -1, INT64_MAX, FLAGS },\n    { NULL }\n};\n\nAVFILTER_DEFINE_CLASS(ladspa);\n\nstatic void print_ctl_info(AVFilterContext *ctx, int level,\n                           LADSPAContext *s, int ctl, unsigned long *map,\n                           LADSPA_Data *values, int print)\n{\n    const LADSPA_PortRangeHint *h = s->desc->PortRangeHints + map[ctl];\n\n    av_log(ctx, level, \"c%i: %s [\", ctl, s->desc->PortNames[map[ctl]]);\n\n    if (LADSPA_IS_HINT_TOGGLED(h->HintDescriptor)) {\n        av_log(ctx, level, \"toggled (1 or 0)\");\n\n        if (LADSPA_IS_HINT_HAS_DEFAULT(h->HintDescriptor))\n            av_log(ctx, level, \" (default %i)\", (int)values[ctl]);\n    } else {\n        if (LADSPA_IS_HINT_INTEGER(h->HintDescriptor)) {\n            av_log(ctx, level, \"<int>\");\n\n            if (LADSPA_IS_HINT_BOUNDED_BELOW(h->HintDescriptor))\n                av_log(ctx, level, \", min: %i\", (int)h->LowerBound);\n\n            if (LADSPA_IS_HINT_BOUNDED_ABOVE(h->HintDescriptor))\n                av_log(ctx, level, \", max: %i\", (int)h->UpperBound);\n\n            if (print)\n                av_log(ctx, level, \" (value %d)\", (int)values[ctl]);\n            else if (LADSPA_IS_HINT_HAS_DEFAULT(h->HintDescriptor))\n                av_log(ctx, level, \" (default %d)\", (int)values[ctl]);\n        } else {\n            av_log(ctx, level, \"<float>\");\n\n            if (LADSPA_IS_HINT_BOUNDED_BELOW(h->HintDescriptor))\n                av_log(ctx, level, \", min: %f\", h->LowerBound);\n\n            if (LADSPA_IS_HINT_BOUNDED_ABOVE(h->HintDescriptor))\n                av_log(ctx, level, \", max: %f\", h->UpperBound);\n\n            if (print)\n                av_log(ctx, level, \" (value %f)\", values[ctl]);\n            else if (LADSPA_IS_HINT_HAS_DEFAULT(h->HintDescriptor))\n                av_log(ctx, level, \" (default %f)\", values[ctl]);\n        }\n\n        if (LADSPA_IS_HINT_SAMPLE_RATE(h->HintDescriptor))\n            av_log(ctx, level, \", multiple of sample rate\");\n\n        if (LADSPA_IS_HINT_LOGARITHMIC(h->HintDescriptor))\n            av_log(ctx, level, \", logarithmic scale\");\n    }\n\n    av_log(ctx, level, \"]\\n\");\n}\n\nstatic int filter_frame(AVFilterLink *inlink, AVFrame *in)\n{\n    AVFilterContext *ctx = inlink->dst;\n    LADSPAContext *s = ctx->priv;\n    AVFrame *out;\n    int i, h, p;\n\n    if (!s->nb_outputs ||\n        (av_frame_is_writable(in) && s->nb_inputs == s->nb_outputs &&\n        !(s->desc->Properties & LADSPA_PROPERTY_INPLACE_BROKEN))) {\n        out = in;\n    } else {\n        out = ff_get_audio_buffer(ctx->outputs[0], in->nb_samples);\n        if (!out) {\n            av_frame_free(&in);\n            return AVERROR(ENOMEM);\n        }\n        av_frame_copy_props(out, in);\n    }\n\n    for (h = 0; h < s->nb_handles; h++) {\n        for (i = 0; i < s->nb_inputs; i++) {\n            p = s->nb_handles > 1 ? h : i;\n            s->desc->connect_port(s->handles[h], s->ipmap[i],\n                                  (LADSPA_Data*)in->extended_data[p]);\n        }\n\n        for (i = 0; i < s->nb_outputs; i++) {\n            p = s->nb_handles > 1 ? h : i;\n            s->desc->connect_port(s->handles[h], s->opmap[i],\n                                  (LADSPA_Data*)out->extended_data[p]);\n        }\n\n        s->desc->run(s->handles[h], in->nb_samples);\n    }\n\n    for (i = 0; i < s->nb_outputcontrols; i++)\n        print_ctl_info(ctx, AV_LOG_VERBOSE, s, i, s->ocmap, s->octlv, 1);\n\n    if (out != in)\n        av_frame_free(&in);\n\n    return ff_filter_frame(ctx->outputs[0], out);\n}\n\nstatic int request_frame(AVFilterLink *outlink)\n{\n    AVFilterContext *ctx = outlink->src;\n    LADSPAContext *s = ctx->priv;\n    AVFrame *out;\n    int64_t t;\n    int i;\n\n    if (ctx->nb_inputs)\n        return ff_request_frame(ctx->inputs[0]);\n\n    t = av_rescale(s->pts, AV_TIME_BASE, s->sample_rate);\n    if (s->duration >= 0 && t >= s->duration)\n        return AVERROR_EOF;\n\n    out = ff_get_audio_buffer(outlink, s->nb_samples);\n    if (!out)\n        return AVERROR(ENOMEM);\n\n    for (i = 0; i < s->nb_outputs; i++)\n        s->desc->connect_port(s->handles[0], s->opmap[i],\n                (LADSPA_Data*)out->extended_data[i]);\n\n    s->desc->run(s->handles[0], s->nb_samples);\n\n    for (i = 0; i < s->nb_outputcontrols; i++)\n        print_ctl_info(ctx, AV_LOG_INFO, s, i, s->ocmap, s->octlv, 1);\n\n    out->sample_rate = s->sample_rate;\n    out->pts         = s->pts;\n    s->pts          += s->nb_samples;\n\n    return ff_filter_frame(outlink, out);\n}\n\nstatic void set_default_ctl_value(LADSPAContext *s, int ctl,\n                                  unsigned long *map, LADSPA_Data *values)\n{\n    const LADSPA_PortRangeHint *h = s->desc->PortRangeHints + map[ctl];\n    const LADSPA_Data lower = h->LowerBound;\n    const LADSPA_Data upper = h->UpperBound;\n\n    if (LADSPA_IS_HINT_DEFAULT_MINIMUM(h->HintDescriptor)) {\n        values[ctl] = lower;\n    } else if (LADSPA_IS_HINT_DEFAULT_MAXIMUM(h->HintDescriptor)) {\n        values[ctl] = upper;\n    } else if (LADSPA_IS_HINT_DEFAULT_0(h->HintDescriptor)) {\n        values[ctl] = 0.0;\n    } else if (LADSPA_IS_HINT_DEFAULT_1(h->HintDescriptor)) {\n        values[ctl] = 1.0;\n    } else if (LADSPA_IS_HINT_DEFAULT_100(h->HintDescriptor)) {\n        values[ctl] = 100.0;\n    } else if (LADSPA_IS_HINT_DEFAULT_440(h->HintDescriptor)) {\n        values[ctl] = 440.0;\n    } else if (LADSPA_IS_HINT_DEFAULT_LOW(h->HintDescriptor)) {\n        if (LADSPA_IS_HINT_LOGARITHMIC(h->HintDescriptor))\n            values[ctl] = exp(log(lower) * 0.75 + log(upper) * 0.25);\n        else\n            values[ctl] = lower * 0.75 + upper * 0.25;\n    } else if (LADSPA_IS_HINT_DEFAULT_MIDDLE(h->HintDescriptor)) {\n        if (LADSPA_IS_HINT_LOGARITHMIC(h->HintDescriptor))\n            values[ctl] = exp(log(lower) * 0.5 + log(upper) * 0.5);\n        else\n            values[ctl] = lower * 0.5 + upper * 0.5;\n    } else if (LADSPA_IS_HINT_DEFAULT_HIGH(h->HintDescriptor)) {\n        if (LADSPA_IS_HINT_LOGARITHMIC(h->HintDescriptor))\n            values[ctl] = exp(log(lower) * 0.25 + log(upper) * 0.75);\n        else\n            values[ctl] = lower * 0.25 + upper * 0.75;\n    }\n}\n\nstatic int connect_ports(AVFilterContext *ctx, AVFilterLink *link)\n{\n    LADSPAContext *s = ctx->priv;\n    int i, j;\n\n    s->nb_handles = s->nb_inputs == 1 && s->nb_outputs == 1 ? link->channels : 1;\n    s->handles    = av_calloc(s->nb_handles, sizeof(*s->handles));\n    if (!s->handles)\n        return AVERROR(ENOMEM);\n\n    for (i = 0; i < s->nb_handles; i++) {\n        s->handles[i] = s->desc->instantiate(s->desc, link->sample_rate);\n        if (!s->handles[i]) {\n            av_log(ctx, AV_LOG_ERROR, \"Could not instantiate plugin.\\n\");\n            return AVERROR_EXTERNAL;\n        }\n\n        // Connect the input control ports\n        for (j = 0; j < s->nb_inputcontrols; j++)\n            s->desc->connect_port(s->handles[i], s->icmap[j], s->ictlv + j);\n\n        // Connect the output control ports\n        for (j = 0; j < s->nb_outputcontrols; j++)\n            s->desc->connect_port(s->handles[i], s->ocmap[j], &s->octlv[j]);\n\n        if (s->desc->activate)\n            s->desc->activate(s->handles[i]);\n    }\n\n    av_log(ctx, AV_LOG_DEBUG, \"handles: %d\\n\", s->nb_handles);\n\n    return 0;\n}\n\nstatic int config_input(AVFilterLink *inlink)\n{\n    AVFilterContext *ctx = inlink->dst;\n\n    return connect_ports(ctx, inlink);\n}\n\nstatic int config_output(AVFilterLink *outlink)\n{\n    AVFilterContext *ctx = outlink->src;\n    int ret;\n\n    if (ctx->nb_inputs) {\n        AVFilterLink *inlink = ctx->inputs[0];\n\n        outlink->format      = inlink->format;\n        outlink->sample_rate = inlink->sample_rate;\n\n        ret = 0;\n    } else {\n        LADSPAContext *s = ctx->priv;\n\n        outlink->sample_rate = s->sample_rate;\n        outlink->time_base   = (AVRational){1, s->sample_rate};\n\n        ret = connect_ports(ctx, outlink);\n    }\n\n    return ret;\n}\n\nstatic void count_ports(const LADSPA_Descriptor *desc,\n                        unsigned long *nb_inputs, unsigned long *nb_outputs)\n{\n    LADSPA_PortDescriptor pd;\n    int i;\n\n    for (i = 0; i < desc->PortCount; i++) {\n        pd = desc->PortDescriptors[i];\n\n        if (LADSPA_IS_PORT_AUDIO(pd)) {\n            if (LADSPA_IS_PORT_INPUT(pd)) {\n                (*nb_inputs)++;\n            } else if (LADSPA_IS_PORT_OUTPUT(pd)) {\n                (*nb_outputs)++;\n            }\n        }\n    }\n}\n\nstatic void *try_load(const char *dir, const char *soname)\n{\n    char *path = av_asprintf(\"%s/%s.so\", dir, soname);\n    void *ret = NULL;\n\n    if (path) {\n        ret = dlopen(path, RTLD_LOCAL|RTLD_NOW);\n        av_free(path);\n    }\n\n    return ret;\n}\n\nstatic int set_control(AVFilterContext *ctx, unsigned long port, LADSPA_Data value)\n{\n    LADSPAContext *s = ctx->priv;\n    const char *label = s->desc->Label;\n    LADSPA_PortRangeHint *h = (LADSPA_PortRangeHint *)s->desc->PortRangeHints +\n                              s->icmap[port];\n\n    if (port >= s->nb_inputcontrols) {\n        av_log(ctx, AV_LOG_ERROR, \"Control c%ld is out of range [0 - %lu].\\n\",\n               port, s->nb_inputcontrols);\n        return AVERROR(EINVAL);\n    }\n\n    if (LADSPA_IS_HINT_BOUNDED_BELOW(h->HintDescriptor) &&\n            value < h->LowerBound) {\n        av_log(ctx, AV_LOG_ERROR,\n                \"%s: input control c%ld is below lower boundary of %0.4f.\\n\",\n                label, port, h->LowerBound);\n        return AVERROR(EINVAL);\n    }\n\n    if (LADSPA_IS_HINT_BOUNDED_ABOVE(h->HintDescriptor) &&\n            value > h->UpperBound) {\n        av_log(ctx, AV_LOG_ERROR,\n                \"%s: input control c%ld is above upper boundary of %0.4f.\\n\",\n                label, port, h->UpperBound);\n        return AVERROR(EINVAL);\n    }\n\n    s->ictlv[port] = value;\n\n    return 0;\n}\n\nstatic av_cold int init(AVFilterContext *ctx)\n{\n    LADSPAContext *s = ctx->priv;\n    LADSPA_Descriptor_Function descriptor_fn;\n    const LADSPA_Descriptor *desc;\n    LADSPA_PortDescriptor pd;\n    AVFilterPad pad = { NULL };\n    char *p, *arg, *saveptr = NULL;\n    unsigned long nb_ports;\n    int i;\n\n    if (!s->dl_name) {\n        av_log(ctx, AV_LOG_ERROR, \"No plugin name provided\\n\");\n        return AVERROR(EINVAL);\n    }\n\n    if (s->dl_name[0] == '/' || s->dl_name[0] == '.') {\n        // argument is a path\n        s->dl_handle = dlopen(s->dl_name, RTLD_LOCAL|RTLD_NOW);\n    } else {\n        // argument is a shared object name\n        char *paths = av_strdup(getenv(\"LADSPA_PATH\"));\n        const char *separator = \":\";\n\n        if (paths) {\n            p = paths;\n            while ((arg = av_strtok(p, separator, &saveptr)) && !s->dl_handle) {\n                s->dl_handle = try_load(arg, s->dl_name);\n                p = NULL;\n            }\n        }\n\n        av_free(paths);\n        if (!s->dl_handle && (paths = av_asprintf(\"%s/.ladspa/lib\", getenv(\"HOME\")))) {\n            s->dl_handle = try_load(paths, s->dl_name);\n            av_free(paths);\n        }\n\n        if (!s->dl_handle)\n            s->dl_handle = try_load(\"/usr/local/lib/ladspa\", s->dl_name);\n\n        if (!s->dl_handle)\n            s->dl_handle = try_load(\"/usr/lib/ladspa\", s->dl_name);\n    }\n    if (!s->dl_handle) {\n        av_log(ctx, AV_LOG_ERROR, \"Failed to load '%s'\\n\", s->dl_name);\n        return AVERROR(EINVAL);\n    }\n\n    descriptor_fn = dlsym(s->dl_handle, \"ladspa_descriptor\");\n    if (!descriptor_fn) {\n        av_log(ctx, AV_LOG_ERROR, \"Could not find ladspa_descriptor: %s\\n\", dlerror());\n        return AVERROR(EINVAL);\n    }\n\n    // Find the requested plugin, or list plugins\n    if (!s->plugin) {\n        av_log(ctx, AV_LOG_INFO, \"The '%s' library contains the following plugins:\\n\", s->dl_name);\n        av_log(ctx, AV_LOG_INFO, \"I = Input Channels\\n\");\n        av_log(ctx, AV_LOG_INFO, \"O = Output Channels\\n\");\n        av_log(ctx, AV_LOG_INFO, \"I:O %-25s %s\\n\", \"Plugin\", \"Description\");\n        av_log(ctx, AV_LOG_INFO, \"\\n\");\n        for (i = 0; desc = descriptor_fn(i); i++) {\n            unsigned long inputs = 0, outputs = 0;\n\n            count_ports(desc, &inputs, &outputs);\n            av_log(ctx, AV_LOG_INFO, \"%lu:%lu %-25s %s\\n\", inputs, outputs, desc->Label,\n                   (char *)av_x_if_null(desc->Name, \"?\"));\n            av_log(ctx, AV_LOG_VERBOSE, \"Maker: %s\\n\",\n                   (char *)av_x_if_null(desc->Maker, \"?\"));\n            av_log(ctx, AV_LOG_VERBOSE, \"Copyright: %s\\n\",\n                   (char *)av_x_if_null(desc->Copyright, \"?\"));\n        }\n        return AVERROR_EXIT;\n    } else {\n        for (i = 0;; i++) {\n            desc = descriptor_fn(i);\n            if (!desc) {\n                av_log(ctx, AV_LOG_ERROR, \"Could not find plugin: %s\\n\", s->plugin);\n                return AVERROR(EINVAL);\n            }\n\n            if (desc->Label && !strcmp(desc->Label, s->plugin))\n                break;\n        }\n    }\n\n    s->desc  = desc;\n    nb_ports = desc->PortCount;\n\n    s->ipmap = av_calloc(nb_ports, sizeof(*s->ipmap));\n    s->opmap = av_calloc(nb_ports, sizeof(*s->opmap));\n    s->icmap = av_calloc(nb_ports, sizeof(*s->icmap));\n    s->ocmap = av_calloc(nb_ports, sizeof(*s->ocmap));\n    s->ictlv = av_calloc(nb_ports, sizeof(*s->ictlv));\n    s->octlv = av_calloc(nb_ports, sizeof(*s->octlv));\n    s->ctl_needs_value = av_calloc(nb_ports, sizeof(*s->ctl_needs_value));\n    if (!s->ipmap || !s->opmap || !s->icmap ||\n        !s->ocmap || !s->ictlv || !s->octlv || !s->ctl_needs_value)\n        return AVERROR(ENOMEM);\n\n    for (i = 0; i < nb_ports; i++) {\n        pd = desc->PortDescriptors[i];\n\n        if (LADSPA_IS_PORT_AUDIO(pd)) {\n            if (LADSPA_IS_PORT_INPUT(pd)) {\n                s->ipmap[s->nb_inputs] = i;\n                s->nb_inputs++;\n            } else if (LADSPA_IS_PORT_OUTPUT(pd)) {\n                s->opmap[s->nb_outputs] = i;\n                s->nb_outputs++;\n            }\n        } else if (LADSPA_IS_PORT_CONTROL(pd)) {\n            if (LADSPA_IS_PORT_INPUT(pd)) {\n                s->icmap[s->nb_inputcontrols] = i;\n\n                if (LADSPA_IS_HINT_HAS_DEFAULT(desc->PortRangeHints[i].HintDescriptor))\n                    set_default_ctl_value(s, s->nb_inputcontrols, s->icmap, s->ictlv);\n                else\n                    s->ctl_needs_value[s->nb_inputcontrols] = 1;\n\n                s->nb_inputcontrols++;\n            } else if (LADSPA_IS_PORT_OUTPUT(pd)) {\n                s->ocmap[s->nb_outputcontrols] = i;\n                s->nb_outputcontrols++;\n            }\n        }\n    }\n\n    // List Control Ports if \"help\" is specified\n    if (s->options && !strcmp(s->options, \"help\")) {\n        if (!s->nb_inputcontrols) {\n            av_log(ctx, AV_LOG_INFO,\n                   \"The '%s' plugin does not have any input controls.\\n\",\n                   desc->Label);\n        } else {\n            av_log(ctx, AV_LOG_INFO,\n                   \"The '%s' plugin has the following input controls:\\n\",\n                   desc->Label);\n            for (i = 0; i < s->nb_inputcontrols; i++)\n                print_ctl_info(ctx, AV_LOG_INFO, s, i, s->icmap, s->ictlv, 0);\n        }\n        return AVERROR_EXIT;\n    }\n\n    // Parse control parameters\n    p = s->options;\n    while (s->options) {\n        LADSPA_Data val;\n        int ret;\n\n        if (!(arg = av_strtok(p, \"|\", &saveptr)))\n            break;\n        p = NULL;\n\n        if (sscanf(arg, \"c%d=%f\", &i, &val) != 2) {\n            av_log(ctx, AV_LOG_ERROR, \"Invalid syntax.\\n\");\n            return AVERROR(EINVAL);\n        }\n\n        if ((ret = set_control(ctx, i, val)) < 0)\n            return ret;\n        s->ctl_needs_value[i] = 0;\n    }\n\n    // Check if any controls are not set\n    for (i = 0; i < s->nb_inputcontrols; i++) {\n        if (s->ctl_needs_value[i]) {\n            av_log(ctx, AV_LOG_ERROR, \"Control c%d must be set.\\n\", i);\n            print_ctl_info(ctx, AV_LOG_ERROR, s, i, s->icmap, s->ictlv, 0);\n            return AVERROR(EINVAL);\n        }\n    }\n\n    pad.type = AVMEDIA_TYPE_AUDIO;\n\n    if (s->nb_inputs) {\n        pad.name = av_asprintf(\"in0:%s%lu\", desc->Label, s->nb_inputs);\n        if (!pad.name)\n            return AVERROR(ENOMEM);\n\n        pad.filter_frame = filter_frame;\n        pad.config_props = config_input;\n        if (ff_insert_inpad(ctx, ctx->nb_inputs, &pad) < 0) {\n            av_freep(&pad.name);\n            return AVERROR(ENOMEM);\n        }\n    }\n\n    av_log(ctx, AV_LOG_DEBUG, \"ports: %lu\\n\", nb_ports);\n    av_log(ctx, AV_LOG_DEBUG, \"inputs: %lu outputs: %lu\\n\",\n                              s->nb_inputs, s->nb_outputs);\n    av_log(ctx, AV_LOG_DEBUG, \"input controls: %lu output controls: %lu\\n\",\n                              s->nb_inputcontrols, s->nb_outputcontrols);\n\n    return 0;\n}\n\nstatic int query_formats(AVFilterContext *ctx)\n{\n    LADSPAContext *s = ctx->priv;\n    AVFilterFormats *formats;\n    AVFilterChannelLayouts *layouts;\n    static const enum AVSampleFormat sample_fmts[] = {\n        AV_SAMPLE_FMT_FLTP, AV_SAMPLE_FMT_NONE };\n\n    formats = ff_make_format_list(sample_fmts);\n    if (!formats)\n        return AVERROR(ENOMEM);\n    ff_set_common_formats(ctx, formats);\n\n    if (s->nb_inputs) {\n        formats = ff_all_samplerates();\n        if (!formats)\n            return AVERROR(ENOMEM);\n\n        ff_set_common_samplerates(ctx, formats);\n    } else {\n        int sample_rates[] = { s->sample_rate, -1 };\n\n        ff_set_common_samplerates(ctx, ff_make_format_list(sample_rates));\n    }\n\n    if (s->nb_inputs == 1 && s->nb_outputs == 1) {\n        // We will instantiate multiple LADSPA_Handle, one over each channel\n        layouts = ff_all_channel_layouts();\n        if (!layouts)\n            return AVERROR(ENOMEM);\n\n        ff_set_common_channel_layouts(ctx, layouts);\n    } else {\n        AVFilterLink *outlink = ctx->outputs[0];\n\n        if (s->nb_inputs >= 1) {\n            AVFilterLink *inlink = ctx->inputs[0];\n            int64_t inlayout = FF_COUNT2LAYOUT(s->nb_inputs);\n\n            layouts = NULL;\n            ff_add_channel_layout(&layouts, inlayout);\n            ff_channel_layouts_ref(layouts, &inlink->out_channel_layouts);\n\n            if (!s->nb_outputs)\n                ff_channel_layouts_ref(layouts, &outlink->in_channel_layouts);\n        }\n\n        if (s->nb_outputs >= 1) {\n            int64_t outlayout = FF_COUNT2LAYOUT(s->nb_outputs);\n\n            layouts = NULL;\n            ff_add_channel_layout(&layouts, outlayout);\n            ff_channel_layouts_ref(layouts, &outlink->in_channel_layouts);\n        }\n    }\n\n    return 0;\n}\n\nstatic av_cold void uninit(AVFilterContext *ctx)\n{\n    LADSPAContext *s = ctx->priv;\n    int i;\n\n    for (i = 0; i < s->nb_handles; i++) {\n        if (s->desc->deactivate)\n            s->desc->deactivate(s->handles[i]);\n        if (s->desc->cleanup)\n            s->desc->cleanup(s->handles[i]);\n    }\n\n    if (s->dl_handle)\n        dlclose(s->dl_handle);\n\n    av_freep(&s->ipmap);\n    av_freep(&s->opmap);\n    av_freep(&s->icmap);\n    av_freep(&s->ocmap);\n    av_freep(&s->ictlv);\n    av_freep(&s->octlv);\n    av_freep(&s->handles);\n    av_freep(&s->ctl_needs_value);\n\n    if (ctx->nb_inputs)\n        av_freep(&ctx->input_pads[0].name);\n}\n\nstatic int process_command(AVFilterContext *ctx, const char *cmd, const char *args,\n                           char *res, int res_len, int flags)\n{\n    LADSPA_Data value;\n    unsigned long port;\n\n    if (sscanf(cmd, \"c%ld\", &port) + sscanf(args, \"%f\", &value) != 2)\n        return AVERROR(EINVAL);\n\n    return set_control(ctx, port, value);\n}\n\nstatic const AVFilterPad ladspa_outputs[] = {\n    {\n        .name          = \"default\",\n        .type          = AVMEDIA_TYPE_AUDIO,\n        .config_props  = config_output,\n        .request_frame = request_frame,\n    },\n    { NULL }\n};\n\nAVFilter ff_af_ladspa = {\n    .name          = \"ladspa\",\n    .description   = NULL_IF_CONFIG_SMALL(\"Apply LADSPA effect.\"),\n    .priv_size     = sizeof(LADSPAContext),\n    .priv_class    = &ladspa_class,\n    .init          = init,\n    .uninit        = uninit,\n    .query_formats = query_formats,\n    .process_command = process_command,\n    .inputs        = 0,\n    .outputs       = ladspa_outputs,\n    .flags         = AVFILTER_FLAG_DYNAMIC_INPUTS,\n};\n",
        "/tmp/vanessa/spack-stage/spack-stage-ffmpeg-2.8.15-ozpyncprat26dr3j2bmhjj5jpw7za2d2/spack-src/libavcodec/nvenc.c": "/*\n * H.264 hardware encoding using nvidia nvenc\n * Copyright (c) 2014 Timo Rothenpieler <timo@rothenpieler.org>\n *\n * This file is part of FFmpeg.\n *\n * FFmpeg is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License as published by the Free Software Foundation; either\n * version 2.1 of the License, or (at your option) any later version.\n *\n * FFmpeg is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with FFmpeg; if not, write to the Free Software\n * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n */\n\n#if defined(_WIN32)\n#include <windows.h>\n#else\n#include <dlfcn.h>\n#endif\n\n#include <nvEncodeAPI.h>\n\n#include \"libavutil/internal.h\"\n#include \"libavutil/imgutils.h\"\n#include \"libavutil/avassert.h\"\n#include \"libavutil/opt.h\"\n#include \"libavutil/mem.h\"\n#include \"avcodec.h\"\n#include \"internal.h\"\n#include \"thread.h\"\n\n#if defined(_WIN32)\n#define CUDAAPI __stdcall\n#else\n#define CUDAAPI\n#endif\n\n#if defined(_WIN32)\n#define LOAD_FUNC(l, s) GetProcAddress(l, s)\n#define DL_CLOSE_FUNC(l) FreeLibrary(l)\n#else\n#define LOAD_FUNC(l, s) dlsym(l, s)\n#define DL_CLOSE_FUNC(l) dlclose(l)\n#endif\n\ntypedef enum cudaError_enum {\n    CUDA_SUCCESS = 0\n} CUresult;\ntypedef int CUdevice;\ntypedef void* CUcontext;\n\ntypedef CUresult(CUDAAPI *PCUINIT)(unsigned int Flags);\ntypedef CUresult(CUDAAPI *PCUDEVICEGETCOUNT)(int *count);\ntypedef CUresult(CUDAAPI *PCUDEVICEGET)(CUdevice *device, int ordinal);\ntypedef CUresult(CUDAAPI *PCUDEVICEGETNAME)(char *name, int len, CUdevice dev);\ntypedef CUresult(CUDAAPI *PCUDEVICECOMPUTECAPABILITY)(int *major, int *minor, CUdevice dev);\ntypedef CUresult(CUDAAPI *PCUCTXCREATE)(CUcontext *pctx, unsigned int flags, CUdevice dev);\ntypedef CUresult(CUDAAPI *PCUCTXPOPCURRENT)(CUcontext *pctx);\ntypedef CUresult(CUDAAPI *PCUCTXDESTROY)(CUcontext ctx);\n\ntypedef NVENCSTATUS (NVENCAPI* PNVENCODEAPICREATEINSTANCE)(NV_ENCODE_API_FUNCTION_LIST *functionList);\n\ntypedef struct NvencInputSurface\n{\n    NV_ENC_INPUT_PTR input_surface;\n    int width;\n    int height;\n\n    int lockCount;\n\n    NV_ENC_BUFFER_FORMAT format;\n} NvencInputSurface;\n\ntypedef struct NvencOutputSurface\n{\n    NV_ENC_OUTPUT_PTR output_surface;\n    int size;\n\n    NvencInputSurface* input_surface;\n\n    int busy;\n} NvencOutputSurface;\n\ntypedef struct NvencData\n{\n    union {\n        int64_t timestamp;\n        NvencOutputSurface *surface;\n    } u;\n} NvencData;\n\ntypedef struct NvencDataList\n{\n    NvencData* data;\n\n    uint32_t pos;\n    uint32_t count;\n    uint32_t size;\n} NvencDataList;\n\ntypedef struct NvencDynLoadFunctions\n{\n    PCUINIT cu_init;\n    PCUDEVICEGETCOUNT cu_device_get_count;\n    PCUDEVICEGET cu_device_get;\n    PCUDEVICEGETNAME cu_device_get_name;\n    PCUDEVICECOMPUTECAPABILITY cu_device_compute_capability;\n    PCUCTXCREATE cu_ctx_create;\n    PCUCTXPOPCURRENT cu_ctx_pop_current;\n    PCUCTXDESTROY cu_ctx_destroy;\n\n    NV_ENCODE_API_FUNCTION_LIST nvenc_funcs;\n    int nvenc_device_count;\n    CUdevice nvenc_devices[16];\n\n#if defined(_WIN32)\n    HMODULE cuda_lib;\n    HMODULE nvenc_lib;\n#else\n    void* cuda_lib;\n    void* nvenc_lib;\n#endif\n} NvencDynLoadFunctions;\n\ntypedef struct NvencValuePair\n{\n    const char *str;\n    uint32_t num;\n} NvencValuePair;\n\ntypedef struct NvencContext\n{\n    AVClass *avclass;\n\n    NvencDynLoadFunctions nvenc_dload_funcs;\n\n    NV_ENC_INITIALIZE_PARAMS init_encode_params;\n    NV_ENC_CONFIG encode_config;\n    CUcontext cu_context;\n\n    int max_surface_count;\n    NvencInputSurface *input_surfaces;\n    NvencOutputSurface *output_surfaces;\n\n    NvencDataList output_surface_queue;\n    NvencDataList output_surface_ready_queue;\n    NvencDataList timestamp_list;\n    int64_t last_dts;\n\n    void *nvencoder;\n\n    char *preset;\n    char *profile;\n    char *level;\n    char *tier;\n    int cbr;\n    int twopass;\n    int gpu;\n    int buffer_delay;\n} NvencContext;\n\nstatic const NvencValuePair nvenc_h264_level_pairs[] = {\n    { \"auto\", NV_ENC_LEVEL_AUTOSELECT },\n    { \"1\"   , NV_ENC_LEVEL_H264_1     },\n    { \"1.0\" , NV_ENC_LEVEL_H264_1     },\n    { \"1b\"  , NV_ENC_LEVEL_H264_1b    },\n    { \"1.0b\", NV_ENC_LEVEL_H264_1b    },\n    { \"1.1\" , NV_ENC_LEVEL_H264_11    },\n    { \"1.2\" , NV_ENC_LEVEL_H264_12    },\n    { \"1.3\" , NV_ENC_LEVEL_H264_13    },\n    { \"2\"   , NV_ENC_LEVEL_H264_2     },\n    { \"2.0\" , NV_ENC_LEVEL_H264_2     },\n    { \"2.1\" , NV_ENC_LEVEL_H264_21    },\n    { \"2.2\" , NV_ENC_LEVEL_H264_22    },\n    { \"3\"   , NV_ENC_LEVEL_H264_3     },\n    { \"3.0\" , NV_ENC_LEVEL_H264_3     },\n    { \"3.1\" , NV_ENC_LEVEL_H264_31    },\n    { \"3.2\" , NV_ENC_LEVEL_H264_32    },\n    { \"4\"   , NV_ENC_LEVEL_H264_4     },\n    { \"4.0\" , NV_ENC_LEVEL_H264_4     },\n    { \"4.1\" , NV_ENC_LEVEL_H264_41    },\n    { \"4.2\" , NV_ENC_LEVEL_H264_42    },\n    { \"5\"   , NV_ENC_LEVEL_H264_5     },\n    { \"5.0\" , NV_ENC_LEVEL_H264_5     },\n    { \"5.1\" , NV_ENC_LEVEL_H264_51    },\n    { NULL }\n};\n\nstatic const NvencValuePair nvenc_hevc_level_pairs[] = {\n    { \"auto\", NV_ENC_LEVEL_AUTOSELECT },\n    { \"1\"   , NV_ENC_LEVEL_HEVC_1     },\n    { \"1.0\" , NV_ENC_LEVEL_HEVC_1     },\n    { \"2\"   , NV_ENC_LEVEL_HEVC_2     },\n    { \"2.0\" , NV_ENC_LEVEL_HEVC_2     },\n    { \"2.1\" , NV_ENC_LEVEL_HEVC_21    },\n    { \"3\"   , NV_ENC_LEVEL_HEVC_3     },\n    { \"3.0\" , NV_ENC_LEVEL_HEVC_3     },\n    { \"3.1\" , NV_ENC_LEVEL_HEVC_31    },\n    { \"4\"   , NV_ENC_LEVEL_HEVC_4     },\n    { \"4.0\" , NV_ENC_LEVEL_HEVC_4     },\n    { \"4.1\" , NV_ENC_LEVEL_HEVC_41    },\n    { \"5\"   , NV_ENC_LEVEL_HEVC_5     },\n    { \"5.0\" , NV_ENC_LEVEL_HEVC_5     },\n    { \"5.1\" , NV_ENC_LEVEL_HEVC_51    },\n    { \"5.2\" , NV_ENC_LEVEL_HEVC_52    },\n    { \"6\"   , NV_ENC_LEVEL_HEVC_6     },\n    { \"6.0\" , NV_ENC_LEVEL_HEVC_6     },\n    { \"6.1\" , NV_ENC_LEVEL_HEVC_61    },\n    { \"6.2\" , NV_ENC_LEVEL_HEVC_62    },\n    { NULL }\n};\n\nstatic int input_string_to_uint32(AVCodecContext *avctx, const NvencValuePair *pair, const char *input, uint32_t *output)\n{\n    for (; pair->str; ++pair) {\n        if (!strcmp(input, pair->str)) {\n            *output = pair->num;\n            return 0;\n        }\n    }\n\n    return AVERROR(EINVAL);\n}\n\nstatic NvencData* data_queue_dequeue(NvencDataList* queue)\n{\n    uint32_t mask;\n    uint32_t read_pos;\n\n    av_assert0(queue);\n    av_assert0(queue->size);\n    av_assert0(queue->data);\n\n    if (!queue->count)\n        return NULL;\n\n    /* Size always is a multiple of two */\n    mask = queue->size - 1;\n    read_pos = (queue->pos - queue->count) & mask;\n    queue->count--;\n\n    return &queue->data[read_pos];\n}\n\nstatic int data_queue_enqueue(NvencDataList* queue, NvencData *data)\n{\n    NvencDataList new_queue;\n    NvencData* tmp_data;\n    uint32_t mask;\n\n    if (!queue->size) {\n        /* size always has to be a multiple of two */\n        queue->size = 4;\n        queue->pos = 0;\n        queue->count = 0;\n\n        queue->data = av_malloc(queue->size * sizeof(*(queue->data)));\n\n        if (!queue->data) {\n            queue->size = 0;\n            return AVERROR(ENOMEM);\n        }\n    }\n\n    if (queue->count == queue->size) {\n        new_queue.size = queue->size << 1;\n        new_queue.pos = 0;\n        new_queue.count = 0;\n        new_queue.data = av_malloc(new_queue.size * sizeof(*(queue->data)));\n\n        if (!new_queue.data)\n            return AVERROR(ENOMEM);\n\n        while (tmp_data = data_queue_dequeue(queue))\n            data_queue_enqueue(&new_queue, tmp_data);\n\n        av_free(queue->data);\n        *queue = new_queue;\n    }\n\n    mask = queue->size - 1;\n\n    queue->data[queue->pos] = *data;\n    queue->pos = (queue->pos + 1) & mask;\n    queue->count++;\n\n    return 0;\n}\n\nstatic int out_surf_queue_enqueue(NvencDataList* queue, NvencOutputSurface* surface)\n{\n    NvencData data;\n    data.u.surface = surface;\n\n    return data_queue_enqueue(queue, &data);\n}\n\nstatic NvencOutputSurface* out_surf_queue_dequeue(NvencDataList* queue)\n{\n    NvencData* res = data_queue_dequeue(queue);\n\n    if (!res)\n        return NULL;\n\n    return res->u.surface;\n}\n\nstatic int timestamp_queue_enqueue(NvencDataList* queue, int64_t timestamp)\n{\n    NvencData data;\n    data.u.timestamp = timestamp;\n\n    return data_queue_enqueue(queue, &data);\n}\n\nstatic int64_t timestamp_queue_dequeue(NvencDataList* queue)\n{\n    NvencData* res = data_queue_dequeue(queue);\n\n    if (!res)\n        return AV_NOPTS_VALUE;\n\n    return res->u.timestamp;\n}\n\n#define CHECK_LOAD_FUNC(t, f, s) \\\ndo { \\\n    (f) = (t)LOAD_FUNC(dl_fn->cuda_lib, s); \\\n    if (!(f)) { \\\n        av_log(avctx, AV_LOG_FATAL, \"Failed loading %s from CUDA library\\n\", s); \\\n        goto error; \\\n    } \\\n} while (0)\n\nstatic av_cold int nvenc_dyload_cuda(AVCodecContext *avctx)\n{\n    NvencContext *ctx = avctx->priv_data;\n    NvencDynLoadFunctions *dl_fn = &ctx->nvenc_dload_funcs;\n\n    if (dl_fn->cuda_lib)\n        return 1;\n\n#if defined(_WIN32)\n    dl_fn->cuda_lib = LoadLibrary(TEXT(\"nvcuda.dll\"));\n#else\n    dl_fn->cuda_lib = dlopen(\"libcuda.so\", RTLD_LAZY);\n#endif\n\n    if (!dl_fn->cuda_lib) {\n        av_log(avctx, AV_LOG_FATAL, \"Failed loading CUDA library\\n\");\n        goto error;\n    }\n\n    CHECK_LOAD_FUNC(PCUINIT, dl_fn->cu_init, \"cuInit\");\n    CHECK_LOAD_FUNC(PCUDEVICEGETCOUNT, dl_fn->cu_device_get_count, \"cuDeviceGetCount\");\n    CHECK_LOAD_FUNC(PCUDEVICEGET, dl_fn->cu_device_get, \"cuDeviceGet\");\n    CHECK_LOAD_FUNC(PCUDEVICEGETNAME, dl_fn->cu_device_get_name, \"cuDeviceGetName\");\n    CHECK_LOAD_FUNC(PCUDEVICECOMPUTECAPABILITY, dl_fn->cu_device_compute_capability, \"cuDeviceComputeCapability\");\n    CHECK_LOAD_FUNC(PCUCTXCREATE, dl_fn->cu_ctx_create, \"cuCtxCreate_v2\");\n    CHECK_LOAD_FUNC(PCUCTXPOPCURRENT, dl_fn->cu_ctx_pop_current, \"cuCtxPopCurrent_v2\");\n    CHECK_LOAD_FUNC(PCUCTXDESTROY, dl_fn->cu_ctx_destroy, \"cuCtxDestroy_v2\");\n\n    return 1;\n\nerror:\n\n    if (dl_fn->cuda_lib)\n        DL_CLOSE_FUNC(dl_fn->cuda_lib);\n\n    dl_fn->cuda_lib = NULL;\n\n    return 0;\n}\n\nstatic av_cold int check_cuda_errors(AVCodecContext *avctx, CUresult err, const char *func)\n{\n    if (err != CUDA_SUCCESS) {\n        av_log(avctx, AV_LOG_FATAL, \">> %s - failed with error code 0x%x\\n\", func, err);\n        return 0;\n    }\n    return 1;\n}\n#define check_cuda_errors(f) if (!check_cuda_errors(avctx, f, #f)) goto error\n\nstatic av_cold int nvenc_check_cuda(AVCodecContext *avctx)\n{\n    int device_count = 0;\n    CUdevice cu_device = 0;\n    char gpu_name[128];\n    int smminor = 0, smmajor = 0;\n    int i, smver, target_smver;\n\n    NvencContext *ctx = avctx->priv_data;\n    NvencDynLoadFunctions *dl_fn = &ctx->nvenc_dload_funcs;\n\n    switch (avctx->codec->id) {\n    case AV_CODEC_ID_H264:\n        target_smver = avctx->pix_fmt == AV_PIX_FMT_YUV444P ? 0x52 : 0x30;\n        break;\n    case AV_CODEC_ID_H265:\n        target_smver = 0x52;\n        break;\n    default:\n        av_log(avctx, AV_LOG_FATAL, \"nvenc: Unknown codec name\\n\");\n        goto error;\n    }\n\n    if (!nvenc_dyload_cuda(avctx))\n        return 0;\n\n    if (dl_fn->nvenc_device_count > 0)\n        return 1;\n\n    check_cuda_errors(dl_fn->cu_init(0));\n\n    check_cuda_errors(dl_fn->cu_device_get_count(&device_count));\n\n    if (!device_count) {\n        av_log(avctx, AV_LOG_FATAL, \"No CUDA capable devices found\\n\");\n        goto error;\n    }\n\n    av_log(avctx, AV_LOG_VERBOSE, \"%d CUDA capable devices found\\n\", device_count);\n\n    dl_fn->nvenc_device_count = 0;\n\n    for (i = 0; i < device_count; ++i) {\n        check_cuda_errors(dl_fn->cu_device_get(&cu_device, i));\n        check_cuda_errors(dl_fn->cu_device_get_name(gpu_name, sizeof(gpu_name), cu_device));\n        check_cuda_errors(dl_fn->cu_device_compute_capability(&smmajor, &smminor, cu_device));\n\n        smver = (smmajor << 4) | smminor;\n\n        av_log(avctx, AV_LOG_VERBOSE, \"[ GPU #%d - < %s > has Compute SM %d.%d, NVENC %s ]\\n\", i, gpu_name, smmajor, smminor, (smver >= target_smver) ? \"Available\" : \"Not Available\");\n\n        if (smver >= target_smver)\n            dl_fn->nvenc_devices[dl_fn->nvenc_device_count++] = cu_device;\n    }\n\n    if (!dl_fn->nvenc_device_count) {\n        av_log(avctx, AV_LOG_FATAL, \"No NVENC capable devices found\\n\");\n        goto error;\n    }\n\n    return 1;\n\nerror:\n\n    dl_fn->nvenc_device_count = 0;\n\n    return 0;\n}\n\nstatic av_cold int nvenc_dyload_nvenc(AVCodecContext *avctx)\n{\n    PNVENCODEAPICREATEINSTANCE nvEncodeAPICreateInstance = 0;\n    NVENCSTATUS nvstatus;\n\n    NvencContext *ctx = avctx->priv_data;\n    NvencDynLoadFunctions *dl_fn = &ctx->nvenc_dload_funcs;\n\n    if (!nvenc_check_cuda(avctx))\n        return 0;\n\n    if (dl_fn->nvenc_lib)\n        return 1;\n\n#if defined(_WIN32)\n    if (sizeof(void*) == 8) {\n        dl_fn->nvenc_lib = LoadLibrary(TEXT(\"nvEncodeAPI64.dll\"));\n    } else {\n        dl_fn->nvenc_lib = LoadLibrary(TEXT(\"nvEncodeAPI.dll\"));\n    }\n#else\n    dl_fn->nvenc_lib = dlopen(\"libnvidia-encode.so.1\", RTLD_LAZY);\n#endif\n\n    if (!dl_fn->nvenc_lib) {\n        av_log(avctx, AV_LOG_FATAL, \"Failed loading the nvenc library\\n\");\n        goto error;\n    }\n\n    nvEncodeAPICreateInstance = (PNVENCODEAPICREATEINSTANCE)LOAD_FUNC(dl_fn->nvenc_lib, \"NvEncodeAPICreateInstance\");\n\n    if (!nvEncodeAPICreateInstance) {\n        av_log(avctx, AV_LOG_FATAL, \"Failed to load nvenc entrypoint\\n\");\n        goto error;\n    }\n\n    dl_fn->nvenc_funcs.version = NV_ENCODE_API_FUNCTION_LIST_VER;\n\n    nvstatus = nvEncodeAPICreateInstance(&dl_fn->nvenc_funcs);\n\n    if (nvstatus != NV_ENC_SUCCESS) {\n        av_log(avctx, AV_LOG_FATAL, \"Failed to create nvenc instance\\n\");\n        goto error;\n    }\n\n    av_log(avctx, AV_LOG_VERBOSE, \"Nvenc initialized successfully\\n\");\n\n    return 1;\n\nerror:\n    if (dl_fn->nvenc_lib)\n        DL_CLOSE_FUNC(dl_fn->nvenc_lib);\n\n    dl_fn->nvenc_lib = NULL;\n\n    return 0;\n}\n\nstatic av_cold void nvenc_unload_nvenc(AVCodecContext *avctx)\n{\n    NvencContext *ctx = avctx->priv_data;\n    NvencDynLoadFunctions *dl_fn = &ctx->nvenc_dload_funcs;\n\n    DL_CLOSE_FUNC(dl_fn->nvenc_lib);\n    dl_fn->nvenc_lib = NULL;\n\n    dl_fn->nvenc_device_count = 0;\n\n    DL_CLOSE_FUNC(dl_fn->cuda_lib);\n    dl_fn->cuda_lib = NULL;\n\n    dl_fn->cu_init = NULL;\n    dl_fn->cu_device_get_count = NULL;\n    dl_fn->cu_device_get = NULL;\n    dl_fn->cu_device_get_name = NULL;\n    dl_fn->cu_device_compute_capability = NULL;\n    dl_fn->cu_ctx_create = NULL;\n    dl_fn->cu_ctx_pop_current = NULL;\n    dl_fn->cu_ctx_destroy = NULL;\n\n    av_log(avctx, AV_LOG_VERBOSE, \"Nvenc unloaded\\n\");\n}\n\nstatic av_cold int nvenc_encode_init(AVCodecContext *avctx)\n{\n    NV_ENC_OPEN_ENCODE_SESSION_EX_PARAMS encode_session_params = { 0 };\n    NV_ENC_PRESET_CONFIG preset_config = { 0 };\n    CUcontext cu_context_curr;\n    CUresult cu_res;\n    GUID encoder_preset = NV_ENC_PRESET_HQ_GUID;\n    GUID codec;\n    NVENCSTATUS nv_status = NV_ENC_SUCCESS;\n    int surfaceCount = 0;\n    int i, num_mbs;\n    int isLL = 0;\n    int lossless = 0;\n    int res = 0;\n    int dw, dh;\n\n    NvencContext *ctx = avctx->priv_data;\n    NvencDynLoadFunctions *dl_fn = &ctx->nvenc_dload_funcs;\n    NV_ENCODE_API_FUNCTION_LIST *p_nvenc = &dl_fn->nvenc_funcs;\n\n    if (!nvenc_dyload_nvenc(avctx))\n        return AVERROR_EXTERNAL;\n\n    ctx->last_dts = AV_NOPTS_VALUE;\n\n    ctx->encode_config.version = NV_ENC_CONFIG_VER;\n    ctx->init_encode_params.version = NV_ENC_INITIALIZE_PARAMS_VER;\n    preset_config.version = NV_ENC_PRESET_CONFIG_VER;\n    preset_config.presetCfg.version = NV_ENC_CONFIG_VER;\n    encode_session_params.version = NV_ENC_OPEN_ENCODE_SESSION_EX_PARAMS_VER;\n    encode_session_params.apiVersion = NVENCAPI_VERSION;\n\n    if (ctx->gpu >= dl_fn->nvenc_device_count) {\n        av_log(avctx, AV_LOG_FATAL, \"Requested GPU %d, but only %d GPUs are available!\\n\", ctx->gpu, dl_fn->nvenc_device_count);\n        res = AVERROR(EINVAL);\n        goto error;\n    }\n\n    ctx->cu_context = NULL;\n    cu_res = dl_fn->cu_ctx_create(&ctx->cu_context, 0, dl_fn->nvenc_devices[ctx->gpu]);\n\n    if (cu_res != CUDA_SUCCESS) {\n        av_log(avctx, AV_LOG_FATAL, \"Failed creating CUDA context for NVENC: 0x%x\\n\", (int)cu_res);\n        res = AVERROR_EXTERNAL;\n        goto error;\n    }\n\n    cu_res = dl_fn->cu_ctx_pop_current(&cu_context_curr);\n\n    if (cu_res != CUDA_SUCCESS) {\n        av_log(avctx, AV_LOG_FATAL, \"Failed popping CUDA context: 0x%x\\n\", (int)cu_res);\n        res = AVERROR_EXTERNAL;\n        goto error;\n    }\n\n    encode_session_params.device = ctx->cu_context;\n    encode_session_params.deviceType = NV_ENC_DEVICE_TYPE_CUDA;\n\n    nv_status = p_nvenc->nvEncOpenEncodeSessionEx(&encode_session_params, &ctx->nvencoder);\n    if (nv_status != NV_ENC_SUCCESS) {\n        ctx->nvencoder = NULL;\n        av_log(avctx, AV_LOG_FATAL, \"OpenEncodeSessionEx failed: 0x%x - invalid license key?\\n\", (int)nv_status);\n        res = AVERROR_EXTERNAL;\n        goto error;\n    }\n\n    if (ctx->preset) {\n        if (!strcmp(ctx->preset, \"hp\")) {\n            encoder_preset = NV_ENC_PRESET_HP_GUID;\n        } else if (!strcmp(ctx->preset, \"hq\")) {\n            encoder_preset = NV_ENC_PRESET_HQ_GUID;\n        } else if (!strcmp(ctx->preset, \"bd\")) {\n            encoder_preset = NV_ENC_PRESET_BD_GUID;\n        } else if (!strcmp(ctx->preset, \"ll\")) {\n            encoder_preset = NV_ENC_PRESET_LOW_LATENCY_DEFAULT_GUID;\n            isLL = 1;\n        } else if (!strcmp(ctx->preset, \"llhp\")) {\n            encoder_preset = NV_ENC_PRESET_LOW_LATENCY_HP_GUID;\n            isLL = 1;\n        } else if (!strcmp(ctx->preset, \"llhq\")) {\n            encoder_preset = NV_ENC_PRESET_LOW_LATENCY_HQ_GUID;\n            isLL = 1;\n        } else if (!strcmp(ctx->preset, \"lossless\")) {\n            encoder_preset = NV_ENC_PRESET_LOSSLESS_DEFAULT_GUID;\n            lossless = 1;\n        } else if (!strcmp(ctx->preset, \"losslesshp\")) {\n            encoder_preset = NV_ENC_PRESET_LOSSLESS_HP_GUID;\n            lossless = 1;\n        } else if (!strcmp(ctx->preset, \"default\")) {\n            encoder_preset = NV_ENC_PRESET_DEFAULT_GUID;\n        } else {\n            av_log(avctx, AV_LOG_FATAL, \"Preset \\\"%s\\\" is unknown! Supported presets: hp, hq, bd, ll, llhp, llhq, lossless, losslesshp, default\\n\", ctx->preset);\n            res = AVERROR(EINVAL);\n            goto error;\n        }\n    }\n\n    switch (avctx->codec->id) {\n    case AV_CODEC_ID_H264:\n        codec = NV_ENC_CODEC_H264_GUID;\n        break;\n    case AV_CODEC_ID_H265:\n        codec = NV_ENC_CODEC_HEVC_GUID;\n        break;\n    default:\n        av_log(avctx, AV_LOG_ERROR, \"nvenc: Unknown codec name\\n\");\n        res = AVERROR(EINVAL);\n        goto error;\n    }\n\n    nv_status = p_nvenc->nvEncGetEncodePresetConfig(ctx->nvencoder, codec, encoder_preset, &preset_config);\n    if (nv_status != NV_ENC_SUCCESS) {\n        av_log(avctx, AV_LOG_FATAL, \"GetEncodePresetConfig failed: 0x%x\\n\", (int)nv_status);\n        res = AVERROR_EXTERNAL;\n        goto error;\n    }\n\n    ctx->init_encode_params.encodeGUID = codec;\n    ctx->init_encode_params.encodeHeight = avctx->height;\n    ctx->init_encode_params.encodeWidth = avctx->width;\n\n    if (avctx->sample_aspect_ratio.num && avctx->sample_aspect_ratio.den &&\n        (avctx->sample_aspect_ratio.num != 1 || avctx->sample_aspect_ratio.num != 1)) {\n        av_reduce(&dw, &dh,\n                  avctx->width * avctx->sample_aspect_ratio.num,\n                  avctx->height * avctx->sample_aspect_ratio.den,\n                  1024 * 1024);\n        ctx->init_encode_params.darHeight = dh;\n        ctx->init_encode_params.darWidth = dw;\n    } else {\n        ctx->init_encode_params.darHeight = avctx->height;\n        ctx->init_encode_params.darWidth = avctx->width;\n    }\n\n    // De-compensate for hardware, dubiously, trying to compensate for\n    // playback at 704 pixel width.\n    if (avctx->width == 720 &&\n        (avctx->height == 480 || avctx->height == 576)) {\n        av_reduce(&dw, &dh,\n                  ctx->init_encode_params.darWidth * 44,\n                  ctx->init_encode_params.darHeight * 45,\n                  1024 * 1024);\n        ctx->init_encode_params.darHeight = dh;\n        ctx->init_encode_params.darWidth = dw;\n    }\n\n    ctx->init_encode_params.frameRateNum = avctx->time_base.den;\n    ctx->init_encode_params.frameRateDen = avctx->time_base.num * avctx->ticks_per_frame;\n\n    num_mbs = ((avctx->width + 15) >> 4) * ((avctx->height + 15) >> 4);\n    ctx->max_surface_count = (num_mbs >= 8160) ? 32 : 48;\n\n    if (ctx->buffer_delay >= ctx->max_surface_count)\n        ctx->buffer_delay = ctx->max_surface_count - 1;\n\n    ctx->init_encode_params.enableEncodeAsync = 0;\n    ctx->init_encode_params.enablePTD = 1;\n\n    ctx->init_encode_params.presetGUID = encoder_preset;\n\n    ctx->init_encode_params.encodeConfig = &ctx->encode_config;\n    memcpy(&ctx->encode_config, &preset_config.presetCfg, sizeof(ctx->encode_config));\n    ctx->encode_config.version = NV_ENC_CONFIG_VER;\n\n    if (avctx->refs >= 0) {\n        /* 0 means \"let the hardware decide\" */\n        switch (avctx->codec->id) {\n        case AV_CODEC_ID_H264:\n            ctx->encode_config.encodeCodecConfig.h264Config.maxNumRefFrames = avctx->refs;\n            break;\n        case AV_CODEC_ID_H265:\n            ctx->encode_config.encodeCodecConfig.hevcConfig.maxNumRefFramesInDPB = avctx->refs;\n            break;\n        /* Earlier switch/case will return if unknown codec is passed. */\n        }\n    }\n\n    if (avctx->gop_size > 0) {\n        if (avctx->max_b_frames >= 0) {\n            /* 0 is intra-only, 1 is I/P only, 2 is one B Frame, 3 two B frames, and so on. */\n            ctx->encode_config.frameIntervalP = avctx->max_b_frames + 1;\n        }\n\n        ctx->encode_config.gopLength = avctx->gop_size;\n        switch (avctx->codec->id) {\n        case AV_CODEC_ID_H264:\n            ctx->encode_config.encodeCodecConfig.h264Config.idrPeriod = avctx->gop_size;\n            break;\n        case AV_CODEC_ID_H265:\n            ctx->encode_config.encodeCodecConfig.hevcConfig.idrPeriod = avctx->gop_size;\n            break;\n        /* Earlier switch/case will return if unknown codec is passed. */\n        }\n    } else if (avctx->gop_size == 0) {\n        ctx->encode_config.frameIntervalP = 0;\n        ctx->encode_config.gopLength = 1;\n        switch (avctx->codec->id) {\n        case AV_CODEC_ID_H264:\n            ctx->encode_config.encodeCodecConfig.h264Config.idrPeriod = 1;\n            break;\n        case AV_CODEC_ID_H265:\n            ctx->encode_config.encodeCodecConfig.hevcConfig.idrPeriod = 1;\n            break;\n        /* Earlier switch/case will return if unknown codec is passed. */\n        }\n    }\n\n    /* when there're b frames, set dts offset */\n    if (ctx->encode_config.frameIntervalP >= 2)\n        ctx->last_dts = -2;\n\n    if (avctx->bit_rate > 0)\n        ctx->encode_config.rcParams.averageBitRate = avctx->bit_rate;\n\n    if (avctx->rc_max_rate > 0)\n        ctx->encode_config.rcParams.maxBitRate = avctx->rc_max_rate;\n\n    if (lossless) {\n        if (avctx->codec->id == AV_CODEC_ID_H264)\n            ctx->encode_config.encodeCodecConfig.h264Config.qpPrimeYZeroTransformBypassFlag = 1;\n\n        ctx->encode_config.rcParams.rateControlMode = NV_ENC_PARAMS_RC_CONSTQP;\n        ctx->encode_config.rcParams.constQP.qpInterB = 0;\n        ctx->encode_config.rcParams.constQP.qpInterP = 0;\n        ctx->encode_config.rcParams.constQP.qpIntra = 0;\n\n        avctx->qmin = -1;\n        avctx->qmax = -1;\n    } else if (ctx->cbr) {\n        if (!ctx->twopass) {\n            ctx->encode_config.rcParams.rateControlMode = NV_ENC_PARAMS_RC_CBR;\n        } else if (ctx->twopass == 1 || isLL) {\n            ctx->encode_config.rcParams.rateControlMode = NV_ENC_PARAMS_RC_2_PASS_QUALITY;\n\n            if (avctx->codec->id == AV_CODEC_ID_H264) {\n                ctx->encode_config.encodeCodecConfig.h264Config.adaptiveTransformMode = NV_ENC_H264_ADAPTIVE_TRANSFORM_ENABLE;\n                ctx->encode_config.encodeCodecConfig.h264Config.fmoMode = NV_ENC_H264_FMO_DISABLE;\n            }\n        } else {\n            ctx->encode_config.rcParams.rateControlMode = NV_ENC_PARAMS_RC_CBR;\n        }\n    } else if (avctx->global_quality > 0) {\n        ctx->encode_config.rcParams.rateControlMode = NV_ENC_PARAMS_RC_CONSTQP;\n        ctx->encode_config.rcParams.constQP.qpInterB = avctx->global_quality;\n        ctx->encode_config.rcParams.constQP.qpInterP = avctx->global_quality;\n        ctx->encode_config.rcParams.constQP.qpIntra = avctx->global_quality;\n\n        avctx->qmin = -1;\n        avctx->qmax = -1;\n    } else if (avctx->qmin >= 0 && avctx->qmax >= 0) {\n        if (ctx->twopass == 1) {\n            ctx->encode_config.rcParams.rateControlMode = NV_ENC_PARAMS_RC_2_PASS_VBR;\n\n            if (avctx->codec->id == AV_CODEC_ID_H264) {\n                ctx->encode_config.encodeCodecConfig.h264Config.adaptiveTransformMode = NV_ENC_H264_ADAPTIVE_TRANSFORM_ENABLE;\n                ctx->encode_config.encodeCodecConfig.h264Config.fmoMode = NV_ENC_H264_FMO_DISABLE;\n            }\n        } else {\n            ctx->encode_config.rcParams.rateControlMode = NV_ENC_PARAMS_RC_VBR;\n        }\n\n        ctx->encode_config.rcParams.enableMinQP = 1;\n        ctx->encode_config.rcParams.enableMaxQP = 1;\n\n        ctx->encode_config.rcParams.minQP.qpInterB = avctx->qmin;\n        ctx->encode_config.rcParams.minQP.qpInterP = avctx->qmin;\n        ctx->encode_config.rcParams.minQP.qpIntra = avctx->qmin;\n\n        ctx->encode_config.rcParams.maxQP.qpInterB = avctx->qmax;\n        ctx->encode_config.rcParams.maxQP.qpInterP = avctx->qmax;\n        ctx->encode_config.rcParams.maxQP.qpIntra = avctx->qmax;\n    }\n\n    if (avctx->rc_buffer_size > 0)\n        ctx->encode_config.rcParams.vbvBufferSize = avctx->rc_buffer_size;\n\n    if (avctx->flags & AV_CODEC_FLAG_INTERLACED_DCT) {\n        ctx->encode_config.frameFieldMode = NV_ENC_PARAMS_FRAME_FIELD_MODE_FIELD;\n    } else {\n        ctx->encode_config.frameFieldMode = NV_ENC_PARAMS_FRAME_FIELD_MODE_FRAME;\n    }\n\n    switch (avctx->codec->id) {\n    case AV_CODEC_ID_H264:\n        ctx->encode_config.encodeCodecConfig.h264Config.h264VUIParameters.colourDescriptionPresentFlag = 1;\n        ctx->encode_config.encodeCodecConfig.h264Config.h264VUIParameters.videoSignalTypePresentFlag = 1;\n\n        ctx->encode_config.encodeCodecConfig.h264Config.h264VUIParameters.colourMatrix = avctx->colorspace;\n        ctx->encode_config.encodeCodecConfig.h264Config.h264VUIParameters.colourPrimaries = avctx->color_primaries;\n        ctx->encode_config.encodeCodecConfig.h264Config.h264VUIParameters.transferCharacteristics = avctx->color_trc;\n\n        ctx->encode_config.encodeCodecConfig.h264Config.h264VUIParameters.videoFullRangeFlag = avctx->color_range == AVCOL_RANGE_JPEG;\n\n        ctx->encode_config.encodeCodecConfig.h264Config.disableSPSPPS = (avctx->flags & AV_CODEC_FLAG_GLOBAL_HEADER) ? 1 : 0;\n        ctx->encode_config.encodeCodecConfig.h264Config.repeatSPSPPS = (avctx->flags & AV_CODEC_FLAG_GLOBAL_HEADER) ? 0 : 1;\n\n        if (!ctx->profile) {\n            switch (avctx->profile) {\n            case FF_PROFILE_H264_HIGH_444_PREDICTIVE:\n                ctx->encode_config.profileGUID = NV_ENC_H264_PROFILE_HIGH_444_GUID;\n                break;\n            case FF_PROFILE_H264_BASELINE:\n                ctx->encode_config.profileGUID = NV_ENC_H264_PROFILE_BASELINE_GUID;\n                break;\n            case FF_PROFILE_H264_MAIN:\n                ctx->encode_config.profileGUID = NV_ENC_H264_PROFILE_MAIN_GUID;\n                break;\n            case FF_PROFILE_H264_HIGH:\n            case FF_PROFILE_UNKNOWN:\n                ctx->encode_config.profileGUID = NV_ENC_H264_PROFILE_HIGH_GUID;\n                break;\n            default:\n                av_log(avctx, AV_LOG_WARNING, \"Unsupported profile requested, falling back to high\\n\");\n                ctx->encode_config.profileGUID = NV_ENC_H264_PROFILE_HIGH_GUID;\n                break;\n            }\n        } else {\n            if (!strcmp(ctx->profile, \"high\")) {\n                ctx->encode_config.profileGUID = NV_ENC_H264_PROFILE_HIGH_GUID;\n                avctx->profile = FF_PROFILE_H264_HIGH;\n            } else if (!strcmp(ctx->profile, \"main\")) {\n                ctx->encode_config.profileGUID = NV_ENC_H264_PROFILE_MAIN_GUID;\n                avctx->profile = FF_PROFILE_H264_MAIN;\n            } else if (!strcmp(ctx->profile, \"baseline\")) {\n                ctx->encode_config.profileGUID = NV_ENC_H264_PROFILE_BASELINE_GUID;\n                avctx->profile = FF_PROFILE_H264_BASELINE;\n            } else if (!strcmp(ctx->profile, \"high444p\")) {\n                ctx->encode_config.profileGUID = NV_ENC_H264_PROFILE_HIGH_444_GUID;\n                avctx->profile = FF_PROFILE_H264_HIGH_444_PREDICTIVE;\n            } else {\n                av_log(avctx, AV_LOG_FATAL, \"Profile \\\"%s\\\" is unknown! Supported profiles: high, main, baseline\\n\", ctx->profile);\n                res = AVERROR(EINVAL);\n                goto error;\n            }\n        }\n\n        ctx->encode_config.encodeCodecConfig.h264Config.chromaFormatIDC = avctx->profile == FF_PROFILE_H264_HIGH_444_PREDICTIVE ? 3 : 1;\n\n        if (ctx->level) {\n            res = input_string_to_uint32(avctx, nvenc_h264_level_pairs, ctx->level, &ctx->encode_config.encodeCodecConfig.h264Config.level);\n\n            if (res) {\n                av_log(avctx, AV_LOG_FATAL, \"Level \\\"%s\\\" is unknown! Supported levels: auto, 1, 1b, 1.1, 1.2, 1.3, 2, 2.1, 2.2, 3, 3.1, 3.2, 4, 4.1, 4.2, 5, 5.1\\n\", ctx->level);\n                goto error;\n            }\n        } else {\n            ctx->encode_config.encodeCodecConfig.h264Config.level = NV_ENC_LEVEL_AUTOSELECT;\n        }\n\n        break;\n    case AV_CODEC_ID_H265:\n        ctx->encode_config.encodeCodecConfig.hevcConfig.disableSPSPPS = (avctx->flags & AV_CODEC_FLAG_GLOBAL_HEADER) ? 1 : 0;\n        ctx->encode_config.encodeCodecConfig.hevcConfig.repeatSPSPPS = (avctx->flags & AV_CODEC_FLAG_GLOBAL_HEADER) ? 0 : 1;\n\n        /* No other profile is supported in the current SDK version 5 */\n        ctx->encode_config.profileGUID = NV_ENC_HEVC_PROFILE_MAIN_GUID;\n        avctx->profile = FF_PROFILE_HEVC_MAIN;\n\n        if (ctx->level) {\n            res = input_string_to_uint32(avctx, nvenc_hevc_level_pairs, ctx->level, &ctx->encode_config.encodeCodecConfig.hevcConfig.level);\n\n            if (res) {\n                av_log(avctx, AV_LOG_FATAL, \"Level \\\"%s\\\" is unknown! Supported levels: auto, 1, 2, 2.1, 3, 3.1, 4, 4.1, 5, 5.1, 5.2, 6, 6.1, 6.2\\n\", ctx->level);\n                goto error;\n            }\n        } else {\n            ctx->encode_config.encodeCodecConfig.hevcConfig.level = NV_ENC_LEVEL_AUTOSELECT;\n        }\n\n        if (ctx->tier) {\n            if (!strcmp(ctx->tier, \"main\")) {\n                ctx->encode_config.encodeCodecConfig.hevcConfig.tier = NV_ENC_TIER_HEVC_MAIN;\n            } else if (!strcmp(ctx->tier, \"high\")) {\n                ctx->encode_config.encodeCodecConfig.hevcConfig.tier = NV_ENC_TIER_HEVC_HIGH;\n            } else {\n                av_log(avctx, AV_LOG_FATAL, \"Tier \\\"%s\\\" is unknown! Supported tiers: main, high\\n\", ctx->tier);\n                res = AVERROR(EINVAL);\n                goto error;\n            }\n        }\n\n        break;\n    /* Earlier switch/case will return if unknown codec is passed. */\n    }\n\n    nv_status = p_nvenc->nvEncInitializeEncoder(ctx->nvencoder, &ctx->init_encode_params);\n    if (nv_status != NV_ENC_SUCCESS) {\n        av_log(avctx, AV_LOG_FATAL, \"InitializeEncoder failed: 0x%x\\n\", (int)nv_status);\n        res = AVERROR_EXTERNAL;\n        goto error;\n    }\n\n    ctx->input_surfaces = av_malloc(ctx->max_surface_count * sizeof(*ctx->input_surfaces));\n\n    if (!ctx->input_surfaces) {\n        res = AVERROR(ENOMEM);\n        goto error;\n    }\n\n    ctx->output_surfaces = av_malloc(ctx->max_surface_count * sizeof(*ctx->output_surfaces));\n\n    if (!ctx->output_surfaces) {\n        res = AVERROR(ENOMEM);\n        goto error;\n    }\n\n    for (surfaceCount = 0; surfaceCount < ctx->max_surface_count; ++surfaceCount) {\n        NV_ENC_CREATE_INPUT_BUFFER allocSurf = { 0 };\n        NV_ENC_CREATE_BITSTREAM_BUFFER allocOut = { 0 };\n        allocSurf.version = NV_ENC_CREATE_INPUT_BUFFER_VER;\n        allocOut.version = NV_ENC_CREATE_BITSTREAM_BUFFER_VER;\n\n        allocSurf.width = (avctx->width + 31) & ~31;\n        allocSurf.height = (avctx->height + 31) & ~31;\n\n        allocSurf.memoryHeap = NV_ENC_MEMORY_HEAP_SYSMEM_CACHED;\n\n        switch (avctx->pix_fmt) {\n        case AV_PIX_FMT_YUV420P:\n            allocSurf.bufferFmt = NV_ENC_BUFFER_FORMAT_YV12_PL;\n            break;\n\n        case AV_PIX_FMT_NV12:\n            allocSurf.bufferFmt = NV_ENC_BUFFER_FORMAT_NV12_PL;\n            break;\n\n        case AV_PIX_FMT_YUV444P:\n            allocSurf.bufferFmt = NV_ENC_BUFFER_FORMAT_YUV444_PL;\n            break;\n\n        default:\n            av_log(avctx, AV_LOG_FATAL, \"Invalid input pixel format\\n\");\n            res = AVERROR(EINVAL);\n            goto error;\n        }\n\n        nv_status = p_nvenc->nvEncCreateInputBuffer(ctx->nvencoder, &allocSurf);\n        if (nv_status != NV_ENC_SUCCESS) {\n            av_log(avctx, AV_LOG_FATAL, \"CreateInputBuffer failed\\n\");\n            res = AVERROR_EXTERNAL;\n            goto error;\n        }\n\n        ctx->input_surfaces[surfaceCount].lockCount = 0;\n        ctx->input_surfaces[surfaceCount].input_surface = allocSurf.inputBuffer;\n        ctx->input_surfaces[surfaceCount].format = allocSurf.bufferFmt;\n        ctx->input_surfaces[surfaceCount].width = allocSurf.width;\n        ctx->input_surfaces[surfaceCount].height = allocSurf.height;\n\n        /* 1MB is large enough to hold most output frames. NVENC increases this automaticaly if it's not enough. */\n        allocOut.size = 1024 * 1024;\n\n        allocOut.memoryHeap = NV_ENC_MEMORY_HEAP_SYSMEM_CACHED;\n\n        nv_status = p_nvenc->nvEncCreateBitstreamBuffer(ctx->nvencoder, &allocOut);\n        if (nv_status != NV_ENC_SUCCESS) {\n            av_log(avctx, AV_LOG_FATAL, \"CreateBitstreamBuffer failed\\n\");\n            ctx->output_surfaces[surfaceCount++].output_surface = NULL;\n            res = AVERROR_EXTERNAL;\n            goto error;\n        }\n\n        ctx->output_surfaces[surfaceCount].output_surface = allocOut.bitstreamBuffer;\n        ctx->output_surfaces[surfaceCount].size = allocOut.size;\n        ctx->output_surfaces[surfaceCount].busy = 0;\n    }\n\n    if (avctx->flags & AV_CODEC_FLAG_GLOBAL_HEADER) {\n        uint32_t outSize = 0;\n        char tmpHeader[256];\n        NV_ENC_SEQUENCE_PARAM_PAYLOAD payload = { 0 };\n        payload.version = NV_ENC_SEQUENCE_PARAM_PAYLOAD_VER;\n\n        payload.spsppsBuffer = tmpHeader;\n        payload.inBufferSize = sizeof(tmpHeader);\n        payload.outSPSPPSPayloadSize = &outSize;\n\n        nv_status = p_nvenc->nvEncGetSequenceParams(ctx->nvencoder, &payload);\n        if (nv_status != NV_ENC_SUCCESS) {\n            av_log(avctx, AV_LOG_FATAL, \"GetSequenceParams failed\\n\");\n            goto error;\n        }\n\n        avctx->extradata_size = outSize;\n        avctx->extradata = av_mallocz(outSize + AV_INPUT_BUFFER_PADDING_SIZE);\n\n        if (!avctx->extradata) {\n            res = AVERROR(ENOMEM);\n            goto error;\n        }\n\n        memcpy(avctx->extradata, tmpHeader, outSize);\n    }\n\n    if (ctx->encode_config.frameIntervalP > 1)\n        avctx->has_b_frames = 2;\n\n    if (ctx->encode_config.rcParams.averageBitRate > 0)\n        avctx->bit_rate = ctx->encode_config.rcParams.averageBitRate;\n\n    return 0;\n\nerror:\n\n    for (i = 0; i < surfaceCount; ++i) {\n        p_nvenc->nvEncDestroyInputBuffer(ctx->nvencoder, ctx->input_surfaces[i].input_surface);\n        if (ctx->output_surfaces[i].output_surface)\n            p_nvenc->nvEncDestroyBitstreamBuffer(ctx->nvencoder, ctx->output_surfaces[i].output_surface);\n    }\n\n    if (ctx->nvencoder)\n        p_nvenc->nvEncDestroyEncoder(ctx->nvencoder);\n\n    if (ctx->cu_context)\n        dl_fn->cu_ctx_destroy(ctx->cu_context);\n\n    nvenc_unload_nvenc(avctx);\n\n    ctx->nvencoder = NULL;\n    ctx->cu_context = NULL;\n\n    return res;\n}\n\nstatic av_cold int nvenc_encode_close(AVCodecContext *avctx)\n{\n    NvencContext *ctx = avctx->priv_data;\n    NvencDynLoadFunctions *dl_fn = &ctx->nvenc_dload_funcs;\n    NV_ENCODE_API_FUNCTION_LIST *p_nvenc = &dl_fn->nvenc_funcs;\n    int i;\n\n    av_freep(&ctx->timestamp_list.data);\n    av_freep(&ctx->output_surface_ready_queue.data);\n    av_freep(&ctx->output_surface_queue.data);\n\n    for (i = 0; i < ctx->max_surface_count; ++i) {\n        p_nvenc->nvEncDestroyInputBuffer(ctx->nvencoder, ctx->input_surfaces[i].input_surface);\n        p_nvenc->nvEncDestroyBitstreamBuffer(ctx->nvencoder, ctx->output_surfaces[i].output_surface);\n    }\n    ctx->max_surface_count = 0;\n\n    p_nvenc->nvEncDestroyEncoder(ctx->nvencoder);\n    ctx->nvencoder = NULL;\n\n    dl_fn->cu_ctx_destroy(ctx->cu_context);\n    ctx->cu_context = NULL;\n\n    nvenc_unload_nvenc(avctx);\n\n    return 0;\n}\n\nstatic int process_output_surface(AVCodecContext *avctx, AVPacket *pkt, NvencOutputSurface *tmpoutsurf)\n{\n    NvencContext *ctx = avctx->priv_data;\n    NvencDynLoadFunctions *dl_fn = &ctx->nvenc_dload_funcs;\n    NV_ENCODE_API_FUNCTION_LIST *p_nvenc = &dl_fn->nvenc_funcs;\n\n    uint32_t slice_mode_data;\n    uint32_t *slice_offsets;\n    NV_ENC_LOCK_BITSTREAM lock_params = { 0 };\n    NVENCSTATUS nv_status;\n    int res = 0;\n\n    switch (avctx->codec->id) {\n    case AV_CODEC_ID_H264:\n      slice_mode_data = ctx->encode_config.encodeCodecConfig.h264Config.sliceModeData;\n      break;\n    case AV_CODEC_ID_H265:\n      slice_mode_data = ctx->encode_config.encodeCodecConfig.hevcConfig.sliceModeData;\n      break;\n    default:\n      av_log(avctx, AV_LOG_ERROR, \"nvenc: Unknown codec name\\n\");\n      res = AVERROR(EINVAL);\n      goto error;\n    }\n    slice_offsets = av_mallocz(slice_mode_data * sizeof(*slice_offsets));\n\n    if (!slice_offsets)\n        return AVERROR(ENOMEM);\n\n    lock_params.version = NV_ENC_LOCK_BITSTREAM_VER;\n\n    lock_params.doNotWait = 0;\n    lock_params.outputBitstream = tmpoutsurf->output_surface;\n    lock_params.sliceOffsets = slice_offsets;\n\n    nv_status = p_nvenc->nvEncLockBitstream(ctx->nvencoder, &lock_params);\n    if (nv_status != NV_ENC_SUCCESS) {\n        av_log(avctx, AV_LOG_ERROR, \"Failed locking bitstream buffer\\n\");\n        res = AVERROR_EXTERNAL;\n        goto error;\n    }\n\n    if (res = ff_alloc_packet2(avctx, pkt, lock_params.bitstreamSizeInBytes, 0)) {\n        p_nvenc->nvEncUnlockBitstream(ctx->nvencoder, tmpoutsurf->output_surface);\n        goto error;\n    }\n\n    memcpy(pkt->data, lock_params.bitstreamBufferPtr, lock_params.bitstreamSizeInBytes);\n\n    nv_status = p_nvenc->nvEncUnlockBitstream(ctx->nvencoder, tmpoutsurf->output_surface);\n    if (nv_status != NV_ENC_SUCCESS)\n        av_log(avctx, AV_LOG_ERROR, \"Failed unlocking bitstream buffer, expect the gates of mordor to open\\n\");\n\n    switch (lock_params.pictureType) {\n    case NV_ENC_PIC_TYPE_IDR:\n        pkt->flags |= AV_PKT_FLAG_KEY;\n#if FF_API_CODED_FRAME\nFF_DISABLE_DEPRECATION_WARNINGS\n    case NV_ENC_PIC_TYPE_I:\n        avctx->coded_frame->pict_type = AV_PICTURE_TYPE_I;\n        break;\n    case NV_ENC_PIC_TYPE_P:\n        avctx->coded_frame->pict_type = AV_PICTURE_TYPE_P;\n        break;\n    case NV_ENC_PIC_TYPE_B:\n        avctx->coded_frame->pict_type = AV_PICTURE_TYPE_B;\n        break;\n    case NV_ENC_PIC_TYPE_BI:\n        avctx->coded_frame->pict_type = AV_PICTURE_TYPE_BI;\n        break;\n    default:\n        av_log(avctx, AV_LOG_ERROR, \"Unknown picture type encountered, expect the output to be broken.\\n\");\n        av_log(avctx, AV_LOG_ERROR, \"Please report this error and include as much information on how to reproduce it as possible.\\n\");\n        res = AVERROR_EXTERNAL;\n        goto error;\nFF_ENABLE_DEPRECATION_WARNINGS\n#endif\n    }\n\n    pkt->pts = lock_params.outputTimeStamp;\n    pkt->dts = timestamp_queue_dequeue(&ctx->timestamp_list);\n\n    /* when there're b frame(s), set dts offset */\n    if (ctx->encode_config.frameIntervalP >= 2)\n        pkt->dts -= 1;\n\n    if (pkt->dts > pkt->pts)\n        pkt->dts = pkt->pts;\n\n    if (ctx->last_dts != AV_NOPTS_VALUE && pkt->dts <= ctx->last_dts)\n        pkt->dts = ctx->last_dts + 1;\n\n    ctx->last_dts = pkt->dts;\n\n    av_free(slice_offsets);\n\n    return 0;\n\nerror:\n\n    av_free(slice_offsets);\n    timestamp_queue_dequeue(&ctx->timestamp_list);\n\n    return res;\n}\n\nstatic int nvenc_encode_frame(AVCodecContext *avctx, AVPacket *pkt,\n    const AVFrame *frame, int *got_packet)\n{\n    NVENCSTATUS nv_status;\n    NvencOutputSurface *tmpoutsurf;\n    int res, i = 0;\n\n    NvencContext *ctx = avctx->priv_data;\n    NvencDynLoadFunctions *dl_fn = &ctx->nvenc_dload_funcs;\n    NV_ENCODE_API_FUNCTION_LIST *p_nvenc = &dl_fn->nvenc_funcs;\n\n    NV_ENC_PIC_PARAMS pic_params = { 0 };\n    pic_params.version = NV_ENC_PIC_PARAMS_VER;\n\n    if (frame) {\n        NV_ENC_LOCK_INPUT_BUFFER lockBufferParams = { 0 };\n        NvencInputSurface *inSurf = NULL;\n\n        for (i = 0; i < ctx->max_surface_count; ++i) {\n            if (!ctx->input_surfaces[i].lockCount) {\n                inSurf = &ctx->input_surfaces[i];\n                break;\n            }\n        }\n\n        av_assert0(inSurf);\n\n        inSurf->lockCount = 1;\n\n        lockBufferParams.version = NV_ENC_LOCK_INPUT_BUFFER_VER;\n        lockBufferParams.inputBuffer = inSurf->input_surface;\n\n        nv_status = p_nvenc->nvEncLockInputBuffer(ctx->nvencoder, &lockBufferParams);\n        if (nv_status != NV_ENC_SUCCESS) {\n            av_log(avctx, AV_LOG_ERROR, \"Failed locking nvenc input buffer\\n\");\n            return 0;\n        }\n\n        if (avctx->pix_fmt == AV_PIX_FMT_YUV420P) {\n            uint8_t *buf = lockBufferParams.bufferDataPtr;\n\n            av_image_copy_plane(buf, lockBufferParams.pitch,\n                frame->data[0], frame->linesize[0],\n                avctx->width, avctx->height);\n\n            buf += inSurf->height * lockBufferParams.pitch;\n\n            av_image_copy_plane(buf, lockBufferParams.pitch >> 1,\n                frame->data[2], frame->linesize[2],\n                avctx->width >> 1, avctx->height >> 1);\n\n            buf += (inSurf->height * lockBufferParams.pitch) >> 2;\n\n            av_image_copy_plane(buf, lockBufferParams.pitch >> 1,\n                frame->data[1], frame->linesize[1],\n                avctx->width >> 1, avctx->height >> 1);\n        } else if (avctx->pix_fmt == AV_PIX_FMT_NV12) {\n            uint8_t *buf = lockBufferParams.bufferDataPtr;\n\n            av_image_copy_plane(buf, lockBufferParams.pitch,\n                frame->data[0], frame->linesize[0],\n                avctx->width, avctx->height);\n\n            buf += inSurf->height * lockBufferParams.pitch;\n\n            av_image_copy_plane(buf, lockBufferParams.pitch,\n                frame->data[1], frame->linesize[1],\n                avctx->width, avctx->height >> 1);\n        } else if (avctx->pix_fmt == AV_PIX_FMT_YUV444P) {\n            uint8_t *buf = lockBufferParams.bufferDataPtr;\n\n            av_image_copy_plane(buf, lockBufferParams.pitch,\n                frame->data[0], frame->linesize[0],\n                avctx->width, avctx->height);\n\n            buf += inSurf->height * lockBufferParams.pitch;\n\n            av_image_copy_plane(buf, lockBufferParams.pitch,\n                frame->data[1], frame->linesize[1],\n                avctx->width, avctx->height);\n\n            buf += inSurf->height * lockBufferParams.pitch;\n\n            av_image_copy_plane(buf, lockBufferParams.pitch,\n                frame->data[2], frame->linesize[2],\n                avctx->width, avctx->height);\n        } else {\n            av_log(avctx, AV_LOG_FATAL, \"Invalid pixel format!\\n\");\n            return AVERROR(EINVAL);\n        }\n\n        nv_status = p_nvenc->nvEncUnlockInputBuffer(ctx->nvencoder, inSurf->input_surface);\n        if (nv_status != NV_ENC_SUCCESS) {\n            av_log(avctx, AV_LOG_FATAL, \"Failed unlocking input buffer!\\n\");\n            return AVERROR_EXTERNAL;\n        }\n\n        for (i = 0; i < ctx->max_surface_count; ++i)\n            if (!ctx->output_surfaces[i].busy)\n                break;\n\n        if (i == ctx->max_surface_count) {\n            inSurf->lockCount = 0;\n            av_log(avctx, AV_LOG_FATAL, \"No free output surface found!\\n\");\n            return AVERROR_EXTERNAL;\n        }\n\n        ctx->output_surfaces[i].input_surface = inSurf;\n\n        pic_params.inputBuffer = inSurf->input_surface;\n        pic_params.bufferFmt = inSurf->format;\n        pic_params.inputWidth = avctx->width;\n        pic_params.inputHeight = avctx->height;\n        pic_params.outputBitstream = ctx->output_surfaces[i].output_surface;\n        pic_params.completionEvent = 0;\n\n        if (avctx->flags & AV_CODEC_FLAG_INTERLACED_DCT) {\n            if (frame->top_field_first) {\n                pic_params.pictureStruct = NV_ENC_PIC_STRUCT_FIELD_TOP_BOTTOM;\n            } else {\n                pic_params.pictureStruct = NV_ENC_PIC_STRUCT_FIELD_BOTTOM_TOP;\n            }\n        } else {\n            pic_params.pictureStruct = NV_ENC_PIC_STRUCT_FRAME;\n        }\n\n        pic_params.encodePicFlags = 0;\n        pic_params.inputTimeStamp = frame->pts;\n        pic_params.inputDuration = 0;\n        switch (avctx->codec->id) {\n        case AV_CODEC_ID_H264:\n          pic_params.codecPicParams.h264PicParams.sliceMode = ctx->encode_config.encodeCodecConfig.h264Config.sliceMode;\n          pic_params.codecPicParams.h264PicParams.sliceModeData = ctx->encode_config.encodeCodecConfig.h264Config.sliceModeData;\n          break;\n        case AV_CODEC_ID_H265:\n          pic_params.codecPicParams.hevcPicParams.sliceMode = ctx->encode_config.encodeCodecConfig.hevcConfig.sliceMode;\n          pic_params.codecPicParams.hevcPicParams.sliceModeData = ctx->encode_config.encodeCodecConfig.hevcConfig.sliceModeData;\n          break;\n        default:\n          av_log(avctx, AV_LOG_ERROR, \"nvenc: Unknown codec name\\n\");\n          return AVERROR(EINVAL);\n        }\n\n        res = timestamp_queue_enqueue(&ctx->timestamp_list, frame->pts);\n\n        if (res)\n            return res;\n    } else {\n        pic_params.encodePicFlags = NV_ENC_PIC_FLAG_EOS;\n    }\n\n    nv_status = p_nvenc->nvEncEncodePicture(ctx->nvencoder, &pic_params);\n\n    if (frame && nv_status == NV_ENC_ERR_NEED_MORE_INPUT) {\n        res = out_surf_queue_enqueue(&ctx->output_surface_queue, &ctx->output_surfaces[i]);\n\n        if (res)\n            return res;\n\n        ctx->output_surfaces[i].busy = 1;\n    }\n\n    if (nv_status != NV_ENC_SUCCESS && nv_status != NV_ENC_ERR_NEED_MORE_INPUT) {\n        av_log(avctx, AV_LOG_ERROR, \"EncodePicture failed!\\n\");\n        return AVERROR_EXTERNAL;\n    }\n\n    if (nv_status != NV_ENC_ERR_NEED_MORE_INPUT) {\n        while (ctx->output_surface_queue.count) {\n            tmpoutsurf = out_surf_queue_dequeue(&ctx->output_surface_queue);\n            res = out_surf_queue_enqueue(&ctx->output_surface_ready_queue, tmpoutsurf);\n\n            if (res)\n                return res;\n        }\n\n        if (frame) {\n            res = out_surf_queue_enqueue(&ctx->output_surface_ready_queue, &ctx->output_surfaces[i]);\n\n            if (res)\n                return res;\n\n            ctx->output_surfaces[i].busy = 1;\n        }\n    }\n\n    if (ctx->output_surface_ready_queue.count && (!frame || ctx->output_surface_ready_queue.count + ctx->output_surface_queue.count >= ctx->buffer_delay)) {\n        tmpoutsurf = out_surf_queue_dequeue(&ctx->output_surface_ready_queue);\n\n        res = process_output_surface(avctx, pkt, tmpoutsurf);\n\n        if (res)\n            return res;\n\n        tmpoutsurf->busy = 0;\n        av_assert0(tmpoutsurf->input_surface->lockCount);\n        tmpoutsurf->input_surface->lockCount--;\n\n        *got_packet = 1;\n    } else {\n        *got_packet = 0;\n    }\n\n    return 0;\n}\n\nstatic const enum AVPixelFormat pix_fmts_nvenc[] = {\n    AV_PIX_FMT_YUV420P,\n    AV_PIX_FMT_NV12,\n    AV_PIX_FMT_YUV444P,\n    AV_PIX_FMT_NONE\n};\n\n#define OFFSET(x) offsetof(NvencContext, x)\n#define VE AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_ENCODING_PARAM\nstatic const AVOption options[] = {\n    { \"preset\", \"Set the encoding preset (one of hq, hp, bd, ll, llhq, llhp, default)\", OFFSET(preset), AV_OPT_TYPE_STRING, { .str = \"hq\" }, 0, 0, VE },\n    { \"profile\", \"Set the encoding profile (high, main or baseline)\", OFFSET(profile), AV_OPT_TYPE_STRING, { 0 }, 0, 0, VE },\n    { \"level\", \"Set the encoding level restriction (auto, 1.0, 1.0b, 1.1, 1.2, ..., 4.2, 5.0, 5.1)\", OFFSET(level), AV_OPT_TYPE_STRING, { 0 }, 0, 0, VE },\n    { \"tier\", \"Set the encoding tier (main or high)\", OFFSET(tier), AV_OPT_TYPE_STRING, { 0 }, 0, 0, VE },\n    { \"cbr\", \"Use cbr encoding mode\", OFFSET(cbr), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 1, VE },\n    { \"2pass\", \"Use 2pass cbr encoding mode\", OFFSET(twopass), AV_OPT_TYPE_INT, { .i64 = -1 }, -1, 1, VE },\n    { \"gpu\", \"Selects which NVENC capable GPU to use. First GPU is 0, second is 1, and so on.\", OFFSET(gpu), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, INT_MAX, VE },\n    { \"delay\", \"Delays frame output by the given amount of frames.\", OFFSET(buffer_delay), AV_OPT_TYPE_INT, { .i64 = INT_MAX }, 0, INT_MAX, VE },\n    { NULL }\n};\n\nstatic const AVCodecDefault nvenc_defaults[] = {\n    { \"b\", \"0\" },\n    { \"qmin\", \"-1\" },\n    { \"qmax\", \"-1\" },\n    { \"qdiff\", \"-1\" },\n    { \"qblur\", \"-1\" },\n    { \"qcomp\", \"-1\" },\n    { NULL },\n};\n\n#if CONFIG_NVENC_ENCODER\nstatic const AVClass nvenc_class = {\n    .class_name = \"nvenc\",\n    .item_name = av_default_item_name,\n    .option = options,\n    .version = LIBAVUTIL_VERSION_INT,\n};\n\nAVCodec ff_nvenc_encoder = {\n    .name = \"nvenc\",\n    .long_name = NULL_IF_CONFIG_SMALL(\"Nvidia NVENC h264 encoder\"),\n    .type = AVMEDIA_TYPE_VIDEO,\n    .id = AV_CODEC_ID_H264,\n    .priv_data_size = sizeof(NvencContext),\n    .init = nvenc_encode_init,\n    .encode2 = nvenc_encode_frame,\n    .close = nvenc_encode_close,\n    .capabilities = AV_CODEC_CAP_DELAY,\n    .priv_class = &nvenc_class,\n    .defaults = nvenc_defaults,\n    .pix_fmts = pix_fmts_nvenc,\n};\n#endif\n\n/* Add an alias for nvenc_h264 */\n#if CONFIG_NVENC_H264_ENCODER\nstatic const AVClass nvenc_h264_class = {\n    .class_name = \"nvenc_h264\",\n    .item_name = av_default_item_name,\n    .option = options,\n    .version = LIBAVUTIL_VERSION_INT,\n};\n\nAVCodec ff_nvenc_h264_encoder = {\n    .name = \"nvenc_h264\",\n    .long_name = NULL_IF_CONFIG_SMALL(\"Nvidia NVENC h264 encoder\"),\n    .type = AVMEDIA_TYPE_VIDEO,\n    .id = AV_CODEC_ID_H264,\n    .priv_data_size = sizeof(NvencContext),\n    .init = nvenc_encode_init,\n    .encode2 = nvenc_encode_frame,\n    .close = nvenc_encode_close,\n    .capabilities = AV_CODEC_CAP_DELAY,\n    .priv_class = &nvenc_h264_class,\n    .defaults = nvenc_defaults,\n    .pix_fmts = pix_fmts_nvenc,\n};\n#endif\n\n#if CONFIG_NVENC_HEVC_ENCODER\nstatic const AVClass nvenc_hevc_class = {\n    .class_name = \"nvenc_hevc\",\n    .item_name = av_default_item_name,\n    .option = options,\n    .version = LIBAVUTIL_VERSION_INT,\n};\n\nAVCodec ff_nvenc_hevc_encoder = {\n    .name = \"nvenc_hevc\",\n    .long_name = NULL_IF_CONFIG_SMALL(\"Nvidia NVENC hevc encoder\"),\n    .type = AVMEDIA_TYPE_VIDEO,\n    .id = AV_CODEC_ID_H265,\n    .priv_data_size = sizeof(NvencContext),\n    .init = nvenc_encode_init,\n    .encode2 = nvenc_encode_frame,\n    .close = nvenc_encode_close,\n    .capabilities = AV_CODEC_CAP_DELAY,\n    .priv_class = &nvenc_hevc_class,\n    .defaults = nvenc_defaults,\n    .pix_fmts = pix_fmts_nvenc,\n};\n#endif\n"
    },
    "skipped": [
        "/tmp/vanessa/spack-stage/spack-stage-ffmpeg-2.8.15-ozpyncprat26dr3j2bmhjj5jpw7za2d2/spack-src/tests/reference.pnm",
        "/tmp/vanessa/spack-stage/spack-stage-ffmpeg-2.8.15-ozpyncprat26dr3j2bmhjj5jpw7za2d2/spack-src/libavcodec/cinepakenc.c"
    ],
    "total_files": 3174
}