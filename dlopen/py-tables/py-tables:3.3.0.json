{
    "matches": {
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/setup.py": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\n\"\"\"Setup script for the tables package\"\"\"\n\nfrom __future__ import print_function\n\nimport os\nimport re\nimport sys\nimport ctypes\nimport tempfile\nimport textwrap\nimport subprocess\nfrom os.path import exists, expanduser\nimport glob\n\n# Using ``setuptools`` enables lots of goodies\nfrom setuptools import setup, find_packages\nimport pkg_resources\n\nfrom distutils.core import Extension\nfrom distutils.dep_util import newer\nfrom distutils.util import convert_path\nfrom distutils.ccompiler import new_compiler\nfrom distutils.version import LooseVersion\nimport distutils.spawn\n\n# We need to avoid importing numpy until we can be sure it's installed\n# This approach is based on this SO answer http://stackoverflow.com/a/21621689\n# This is also what pandas does.\nfrom setuptools.command.build_ext import build_ext\n\n# For guessing the capabilities of the CPU for C-Blosc\nimport cpuinfo\ncpu_info = cpuinfo.get_cpu_info()\n\n# The name for the pkg-config utility\nPKG_CONFIG = 'pkg-config'\n\n\n# Fetch the requisites\nwith open('requirements.txt') as f:\n    requirements = f.read().splitlines()\n\n\nclass BuildExtensions(build_ext):\n    \"\"\"Subclass setuptools build_ext command\n\n    BuildExtensions does two things\n    1) it makes sure numpy is available\n    2) it injects numpy's core/include directory in the include_dirs parameter\n       of all extensions\n    3) it runs the original build_ext command\n    \"\"\"\n\n    def run(self):\n        # According to\n        # https://pip.pypa.io/en/stable/reference/pip_install.html#installation-order\n        # at this point we can be sure pip has already installed numpy\n        numpy_incl = pkg_resources.resource_filename('numpy', 'core/include')\n\n        for ext in self.extensions:\n            if (hasattr(ext, 'include_dirs') and\n                    numpy_incl not in ext.include_dirs):\n                ext.include_dirs.append(numpy_incl)\n\n        build_ext.run(self)\n\n\ncmdclass = {'build_ext': BuildExtensions}\nsetuptools_kwargs = {}\n\n\n# Some functions for showing errors and warnings.\ndef _print_admonition(kind, head, body):\n    tw = textwrap.TextWrapper(initial_indent='   ', subsequent_indent='   ')\n\n    print(\".. %s:: %s\" % (kind.upper(), head))\n    for line in tw.wrap(body):\n        print(line)\n\n\ndef exit_with_error(head, body=''):\n    _print_admonition('error', head, body)\n    sys.exit(1)\n\n\ndef print_warning(head, body=''):\n    _print_admonition('warning', head, body)\n\n\n# The minimum required versions\nmin_python_version = (2, 6)\n# Check for Python\nif sys.version_info < min_python_version:\n    exit_with_error(\"You need Python 2.6 or greater to install PyTables!\")\nprint(\"* Using Python %s\" % sys.version.splitlines()[0])\n\n# Minumum equired versions for numpy, numexpr and HDF5\nexec(open(os.path.join('tables', 'req_versions.py')).read())\n\n\nVERSION = open('VERSION').read().strip()\n\n# ----------------------------------------------------------------------\n\ndebug = '--debug' in sys.argv\n\n# Global variables\nlib_dirs = []\ninc_dirs = [os.path.join('hdf5-blosc', 'src')]\noptional_libs = []\ndata_files = []    # list of data files to add to packages (mainly for DLL's)\n\ndefault_header_dirs = None\ndefault_library_dirs = None\ndefault_runtime_dirs = None\n\n\ndef add_from_path(envname, dirs):\n    try:\n        dirs.extend(os.environ[envname].split(os.pathsep))\n    except KeyError:\n        pass\n\n\ndef add_from_flags(envname, flag_key, dirs):\n    for flag in os.environ.get(envname, \"\").split():\n        if flag.startswith(flag_key):\n            dirs.append(flag[len(flag_key):])\n\nif os.name == 'posix':\n    prefixes = ('/usr/local', '/sw', '/opt', '/opt/local', '/usr', '/')\n\n    default_header_dirs = []\n    add_from_path(\"CPATH\", default_header_dirs)\n    add_from_path(\"C_INCLUDE_PATH\", default_header_dirs)\n    add_from_flags(\"CPPFLAGS\", \"-I\", default_header_dirs)\n    add_from_flags(\"CFLAGS\", \"-I\", default_header_dirs)\n    default_header_dirs.extend(\n        os.path.join(_tree, 'include') for _tree in prefixes\n    )\n\n    default_library_dirs = []\n    add_from_flags(\"LDFLAGS\", \"-L\", default_library_dirs)\n    default_library_dirs.extend(\n        os.path.join(_tree, _arch) for _tree in prefixes\n        for _arch in ('lib64', 'lib'))\n    default_runtime_dirs = default_library_dirs\n\nelif os.name == 'nt':\n    default_header_dirs = []  # no default, must be given explicitly\n    default_library_dirs = []  # no default, must be given explicitly\n    default_runtime_dirs = [  # look for DLL files in ``%PATH%``\n        _path for _path in os.environ['PATH'].split(';')]\n    # Add the \\Windows\\system to the runtime list (necessary for Vista)\n    default_runtime_dirs.append('\\\\windows\\\\system')\n    # Add the \\path_to_python\\DLLs and tables package to the list\n    default_runtime_dirs.extend(\n        [os.path.join(sys.prefix, 'Lib\\\\site-packages\\\\tables')])\n\n\n# Gcc 4.0.1 on Mac OS X 10.4 does not seem to include the default\n# header and library paths.  See ticket #18.\nif sys.platform.lower().startswith('darwin'):\n    inc_dirs.extend(default_header_dirs)\n    lib_dirs.extend(default_library_dirs)\n\n\ndef _find_file_path(name, locations, prefixes=[''], suffixes=['']):\n    for prefix in prefixes:\n        for suffix in suffixes:\n            for location in locations:\n                path = os.path.join(location, prefix + name + suffix)\n                if os.path.isfile(path):\n                    return path\n    return None\n\n\nclass Package(object):\n    def __init__(self, name, tag, header_name, library_name,\n                 target_function=None):\n        self.name = name\n        self.tag = tag\n        self.header_name = header_name\n        self.library_name = library_name\n        self.runtime_name = library_name\n        self.target_function = target_function\n\n    def find_header_path(self, locations=default_header_dirs):\n        return _find_file_path(self.header_name, locations, suffixes=['.h'])\n\n    def find_library_path(self, locations=default_library_dirs):\n        return _find_file_path(\n            self.library_name, locations,\n            self._library_prefixes, self._library_suffixes)\n\n    def find_runtime_path(self, locations=default_runtime_dirs):\n        \"\"\"\n        returns True if the runtime can be found\n        returns None otherwise\n        \"\"\"\n        # An explicit path can not be provided for runtime libraries.\n        # (The argument is accepted for compatibility with previous methods.)\n\n        # dlopen() won't tell us where the file is, just whether\n        # success occurred, so this returns True instead of a filename\n        for prefix in self._runtime_prefixes:\n            for suffix in self._runtime_suffixes:\n                try:\n                    ctypes.CDLL(prefix + self.runtime_name + suffix)\n                    return True\n                except OSError:\n                    pass\n\n    def _pkg_config(self, flags):\n        try:\n            cmd = [PKG_CONFIG] + flags.split() + [self.library_name]\n            config = subprocess.check_output(cmd, stderr=subprocess.STDOUT)\n\n        # subprocess.CalledProcessError is only available in Python >= 2.7\n        # except (OSError, subprocess.CalledProcessError):\n        except Exception:\n            return []\n        else:\n            return config.decode().strip().split()\n\n    def find_directories(self, location, use_pkgconfig=False):\n        dirdata = [\n            (self.header_name, self.find_header_path, default_header_dirs),\n            (self.library_name, self.find_library_path, default_library_dirs),\n            (self.runtime_name, self.find_runtime_path, default_runtime_dirs),\n        ]\n\n        locations = []\n        if location:\n            # The path of a custom install of the package has been\n            # provided, so the directories where the components\n            # (headers, libraries, runtime) are going to be searched\n            # are constructed by appending platform-dependent\n            # component directories to the given path.\n            # Remove leading and trailing '\"' chars that can mislead\n            # the finding routines on Windows machines\n            locations = [\n                os.path.join(location.strip('\"'), compdir)\n                for compdir in self._component_dirs\n            ]\n\n        if use_pkgconfig:\n            # header\n            pkgconfig_header_dirs = self._pkg_config('--cflags')\n            pkgconfig_header_dirs = [\n                d.lstrip('-I') for d in pkgconfig_header_dirs\n                if d.startswith('-I')\n            ]\n            if pkgconfig_header_dirs:\n                print('* pkg-config header dirs for %s:' % self.name,\n                      ', '.join(pkgconfig_header_dirs))\n\n            # library\n            pkgconfig_library_dirs = self._pkg_config('--libs-only-L')\n            pkgconfig_library_dirs = [\n                d.lstrip('-L') for d in pkgconfig_library_dirs\n                if d.startswith('-L')\n            ]\n            if pkgconfig_library_dirs:\n                print('* pkg-config library dirs for %s:' % self.name,\n                      ', '.join(pkgconfig_library_dirs))\n\n            # runtime\n            pkgconfig_runtime_dirs = pkgconfig_library_dirs\n\n            pkgconfig_dirs = [\n                pkgconfig_header_dirs,\n                pkgconfig_library_dirs,\n                pkgconfig_runtime_dirs,\n            ]\n        else:\n            pkgconfig_dirs = [None, None, None]\n\n        directories = [None, None, None]  # headers, libraries, runtime\n        for idx, (name, find_path, default_dirs) in enumerate(dirdata):\n            path = find_path(locations or pkgconfig_dirs[idx] or default_dirs)\n            if path:\n                if path is True:\n                    directories[idx] = True\n                    continue\n\n                # Take care of not returning a directory component\n                # included in the name.  For instance, if name is\n                # 'foo/bar' and path is '/path/foo/bar.h', do *not*\n                # take '/path/foo', but just '/path'.  This also works\n                # for name 'libfoo.so' and path '/path/libfoo.so'.\n                # This has been modified to just work over include files.\n                # For libraries, its names can be something like 'bzip2'\n                # and if they are located in places like:\n                #  \\stuff\\bzip2-1.0.3\\lib\\bzip2.lib\n                # then, the directory will be returned as '\\stuff' (!!)\n                # F. Alted 2006-02-16\n                if idx == 0:\n                    directories[idx] = os.path.dirname(path[:path.rfind(name)])\n                else:\n                    directories[idx] = os.path.dirname(path)\n\n        return tuple(directories)\n\n\nclass PosixPackage(Package):\n    _library_prefixes = ['lib']\n    _library_suffixes = ['.so', '.dylib', '.a']\n    _runtime_prefixes = _library_prefixes\n    _runtime_suffixes = ['.so', '.dylib']\n    _component_dirs = ['include', 'lib', 'lib64']\n\n\nclass WindowsPackage(Package):\n    _library_prefixes = ['']\n    _library_suffixes = ['.lib']\n    _runtime_prefixes = ['']\n    _runtime_suffixes = ['.dll']\n\n    # lookup in '.' seems necessary for LZO2\n    _component_dirs = ['include', 'lib', 'dll', 'bin', '.']\n\n    def find_runtime_path(self, locations=default_runtime_dirs):\n        # An explicit path can not be provided for runtime libraries.\n        # (The argument is accepted for compatibility with previous methods.)\n        return _find_file_path(\n            self.runtime_name, default_runtime_dirs,\n            self._runtime_prefixes, self._runtime_suffixes)\n\n\n# Get the HDF5 version provided the 'H5public.h' header\ndef get_hdf5_version(headername):\n    major_version = -1\n    minor_version = -1\n    release_version = -1\n    for line in open(headername):\n        if 'H5_VERS_MAJOR' in line:\n            major_version = int(re.split(\"\\s*\", line)[2])\n        if 'H5_VERS_MINOR' in line:\n            minor_version = int(re.split(\"\\s*\", line)[2])\n        if 'H5_VERS_RELEASE' in line:\n            release_version = int(re.split(\"\\s*\", line)[2])\n        if (major_version != -1 and minor_version != -1 and\n                release_version != -1):\n            break\n    if (major_version == -1 or minor_version == -1 or\n            release_version == -1):\n        exit_with_error(\"Unable to detect HDF5 library version!\")\n    return LooseVersion(\"%s.%s.%s\" % (major_version, minor_version,\n                                      release_version))\n\n# Get the Blosc version provided the 'blosc.h' header\ndef get_blosc_version(headername):\n    major_version = -1\n    minor_version = -1\n    release_version = -1\n    for line in open(headername):\n        if 'BLOSC_VERSION_MAJOR' in line:\n            major_version = int(re.split(\"\\s*\", line)[2])\n        if 'BLOSC_VERSION_MINOR' in line:\n            minor_version = int(re.split(\"\\s*\", line)[2])\n        if 'BLOSC_VERSION_RELEASE' in line:\n            release_version = int(re.split(\"\\s*\", line)[2])\n        if (major_version != -1 and minor_version != -1 and\n                release_version != -1):\n            break\n    if (major_version == -1 or minor_version == -1 or\n            release_version == -1):\n        exit_with_error(\"Unable to detect Blosc library version!\")\n    return \"%s.%s.%s\" % (major_version, minor_version, release_version)\n\n\n_cp = convert_path\nif os.name == 'posix':\n    _Package = PosixPackage\n    _platdep = {  # package tag -> platform-dependent components\n        'HDF5': ['hdf5'],\n        'LZO2': ['lzo2'],\n        'LZO': ['lzo'],\n        'BZ2': ['bz2'],\n        'BLOSC': ['blosc'],\n    }\nelif os.name == 'nt':\n    _Package = WindowsPackage\n    _platdep = {  # package tag -> platform-dependent components\n        'HDF5': ['hdf5', 'hdf5'],\n        'LZO2': ['lzo2', 'lzo2'],\n        'LZO': ['liblzo', 'lzo1'],\n        'BZ2': ['bzip2', 'bzip2'],\n        'BLOSC': ['blosc', 'blosc'],\n    }\n\n    # Copy the next DLL's to binaries by default.\n    try:\n        # We define BUILDWHEEL in appveyor.yml\n        # include zlib from conda:\n        if os.environ['APPVEYOR'] and os.environ['BUILDWHEEL']:\n            # Conda HDF5 is linked to zlib.dll (from conda package zlib)\n            # but szip.dll is not included in conda\n            dll_files = [os.environ['PYTHON']+'\\\\Library\\\\bin\\\\zlib.dll']\n    except KeyError:\n        # Update these paths for your own system!\n        dll_files = [\n                 #'\\\\windows\\\\system\\\\zlib1.dll',\n                 #'\\\\windows\\\\system\\\\szip.dll',\n                 ]\n\n    if debug:\n        _platdep['HDF5'] = ['hdf5_D', 'hdf5_D']\n\nhdf5_package = _Package(\"HDF5\", 'HDF5', 'H5public', *_platdep['HDF5'])\nhdf5_package.target_function = 'H5close'\nlzo2_package = _Package(\"LZO 2\", 'LZO2', _cp('lzo/lzo1x'), *_platdep['LZO2'])\nlzo2_package.target_function = 'lzo_version_date'\nlzo1_package = _Package(\"LZO 1\", 'LZO', 'lzo1x', *_platdep['LZO'])\nlzo1_package.target_function = 'lzo_version_date'\nbzip2_package = _Package(\"bzip2\", 'BZ2', 'bzlib', *_platdep['BZ2'])\nbzip2_package.target_function = 'BZ2_bzlibVersion'\nblosc_package = _Package(\"blosc\", 'BLOSC', 'blosc', *_platdep['BLOSC'])\nblosc_package.target_function = 'blosc_list_compressors'  # Blosc >= 1.3\n\n\n# -----------------------------------------------------------------\n\ndef_macros = [('NDEBUG', 1)]\n# Define macros for Windows platform\nif os.name == 'nt':\n    def_macros.append(('WIN32', 1))\n    def_macros.append(('_HDF5USEDLL_', 1))\n    def_macros.append(('H5_BUILT_AS_DYNAMIC_LIB', 1))\n\n# Allow setting the HDF5 dir and additional link flags either in\n# the environment or on the command line.\n# First check the environment...\nHDF5_DIR = os.environ.get('HDF5_DIR', '')\nLZO_DIR = os.environ.get('LZO_DIR', '')\nBZIP2_DIR = os.environ.get('BZIP2_DIR', '')\nBLOSC_DIR = os.environ.get('BLOSC_DIR', '')\nLFLAGS = os.environ.get('LFLAGS', '').split()\n# in GCC-style compilers, -w in extra flags will get rid of copious\n# 'uninitialized variable' Cython warnings. However, this shouldn't be\n# the default as it will suppress *all* the warnings, which definitely\n# is not a good idea.\nCFLAGS = os.environ.get('CFLAGS', '').split()\nLIBS = os.environ.get('LIBS', '').split()\n# We start using pkg-config since some distributions are putting HDF5\n# (and possibly other libraries) in exotic locations.  See issue #442.\nif distutils.spawn.find_executable(PKG_CONFIG):\n    USE_PKGCONFIG = os.environ.get('USE_PKGCONFIG', 'TRUE')\nelse:\n    USE_PKGCONFIG = 'FALSE'\n\n# ...then the command line.\n# Handle --hdf5=[PATH] --lzo=[PATH] --bzip2=[PATH] --blosc=[PATH]\n# --lflags=[FLAGS] --cflags=[FLAGS] and --debug\nargs = sys.argv[:]\nfor arg in args:\n    if arg.find('--hdf5=') == 0:\n        HDF5_DIR = expanduser(arg.split('=')[1])\n        sys.argv.remove(arg)\n    elif arg.find('--lzo=') == 0:\n        LZO_DIR = expanduser(arg.split('=')[1])\n        sys.argv.remove(arg)\n    elif arg.find('--bzip2=') == 0:\n        BZIP2_DIR = expanduser(arg.split('=')[1])\n        sys.argv.remove(arg)\n    elif arg.find('--blosc=') == 0:\n        BLOSC_DIR = expanduser(arg.split('=')[1])\n        sys.argv.remove(arg)\n    elif arg.find('--lflags=') == 0:\n        LFLAGS = arg.split('=')[1].split()\n        sys.argv.remove(arg)\n    elif arg.find('--cflags=') == 0:\n        CFLAGS = arg.split('=')[1].split()\n        sys.argv.remove(arg)\n    elif arg.find('--debug') == 0:\n        # For debugging (mainly compression filters)\n        if os.name != 'nt':  # to prevent including dlfcn.h by utils.c!!!\n            def_macros = [('DEBUG', 1)]\n        # Don't delete this argument. It maybe useful for distutils\n        # when adding more flags later on\n        # sys.argv.remove(arg)\n    elif arg.find('--use-pkgconfig') == 0:\n        USE_PKGCONFIG = arg.split('=')[1]\n        sys.argv.remove(arg)\n\nUSE_PKGCONFIG = True if USE_PKGCONFIG.upper() == 'TRUE' else False\nprint('* USE_PKGCONFIG:', USE_PKGCONFIG)\n\n\n# For windows, search for the hdf5 dll in the path and use it if found.\n# This is much more convenient than having to manually set an environment\n# variable to rebuild pytables\nif not HDF5_DIR and os.name == 'nt':\n    import ctypes.util\n    if not debug:\n        libdir = ctypes.util.find_library('hdf5.dll') or ctypes.util.find_library('hdf5dll.dll')\n    else:\n        libdir = ctypes.util.find_library('hdf5_D.dll') or ctypes.util.find_library('hdf5ddll.dll')\n    # Like 'C:\\\\Program Files\\\\HDF Group\\\\HDF5\\\\1.8.8\\\\bin\\\\hdf5dll.dll'\n    if libdir:\n        # Strip off the filename\n        libdir = os.path.dirname(libdir)\n        # Strip off the 'bin' directory\n        HDF5_DIR = os.path.dirname(libdir)\n        print(\"* Found HDF5 using system PATH ('%s')\" % libdir)\n\n# The next flag for the C compiler is needed for finding the C headers for\n# the Cython extensions\nCFLAGS.append(\"-Isrc\")\n\n# Force the 1.8.x HDF5 API even if the library as been compiled to use the\n# 1.6.x API by default\nCFLAGS.extend([\n    \"-DH5Acreate_vers=2\",\n    \"-DH5Aiterate_vers=2\",\n    \"-DH5Dcreate_vers=2\",\n    \"-DH5Dopen_vers=2\",\n    \"-DH5Eclear_vers=2\",\n    \"-DH5Eprint_vers=2\",\n    \"-DH5Epush_vers=2\",\n    \"-DH5Eset_auto_vers=2\",\n    \"-DH5Eget_auto_vers=2\",\n    \"-DH5Ewalk_vers=2\",\n    \"-DH5E_auto_t_vers=2\",\n    \"-DH5Gcreate_vers=2\",\n    \"-DH5Gopen_vers=2\",\n    \"-DH5Pget_filter_vers=2\",\n    \"-DH5Pget_filter_by_id_vers=2\",\n    # \"-DH5Pinsert_vers=2\",\n    # \"-DH5Pregister_vers=2\",\n    # \"-DH5Rget_obj_type_vers=2\",\n    \"-DH5Tarray_create_vers=2\",\n    # \"-DH5Tcommit_vers=2\",\n    \"-DH5Tget_array_dims_vers=2\",\n    # \"-DH5Topen_vers=2\",\n    \"-DH5Z_class_t_vers=2\",\n])\n# H5Oget_info_by_name seems to have performance issues (see gh-402), so we\n# need to use teh deprecated H5Gget_objinfo function\n# CFLAGS.append(\"-DH5_NO_DEPRECATED_SYMBOLS\")\n\n# Do not use numpy deprecated API\n# CFLAGS.append(\"-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION\")\n\n# Try to locate the compulsory and optional libraries.\nlzo2_enabled = False\ncompiler = new_compiler()\nfor (package, location) in [(hdf5_package, HDF5_DIR),\n                            (lzo2_package, LZO_DIR),\n                            (lzo1_package, LZO_DIR),\n                            (bzip2_package, BZIP2_DIR),\n                            (blosc_package, BLOSC_DIR)]:\n\n    if package.tag == 'LZO' and lzo2_enabled:\n        print(\"* Skipping detection of %s since %s has already been found.\"\n              % (lzo1_package.name, lzo2_package.name))\n        continue  # do not use LZO 1 if LZO 2 is available\n\n    (hdrdir, libdir, rundir) = package.find_directories(\n        location, use_pkgconfig=USE_PKGCONFIG)\n\n    # check if HDF5 library uses old DLL naming scheme\n    if hdrdir and package.tag == 'HDF5':\n        hdf5_header = os.path.join(hdrdir, \"H5public.h\")\n        hdf5_version = get_hdf5_version(hdf5_header)\n        if hdf5_version < min_hdf5_version:\n            exit_with_error(\n                \"Unsupported HDF5 version! HDF5 v%s+ required. \"\n                \"Found version v%s\" % (min_hdf5_version, hdf5_version))\n\n        if hdf5_version >= \"1.10\":\n            exit_with_error(\n                \"HDF5 1.10 release not supported. HDF5 v1.8 release required. \"\n                \"Found version v%s\" % (hdf5_version))\n\n        if os.name == 'nt' and hdf5_version < \"1.8.10\":\n            # Change in DLL naming happened in 1.8.10\n            hdf5_old_dll_name = 'hdf5dll' if not debug else 'hdf5ddll'\n            package.library_name = hdf5_old_dll_name\n            package.runtime_name = hdf5_old_dll_name\n            _platdep['HDF5'] = [hdf5_old_dll_name, hdf5_old_dll_name]\n            _, libdir, rundir = package.find_directories(location, use_pkgconfig=USE_PKGCONFIG)\n\n    # check if the library is in the standard compiler paths\n    if not libdir and package.target_function:\n        libdir = compiler.has_function(package.target_function,\n                                       libraries=(package.library_name,))\n\n    if not (hdrdir and libdir):\n        if package.tag in ['HDF5']:  # these are compulsory!\n            pname, ptag = package.name, package.tag\n            exit_with_error(\n                \"Could not find a local %s installation.\" % pname,\n                \"You may need to explicitly state \"\n                \"where your local %(name)s headers and library can be found \"\n                \"by setting the ``%(tag)s_DIR`` environment variable \"\n                \"or by using the ``--%(ltag)s`` command-line option.\"\n                % dict(name=pname, tag=ptag, ltag=ptag.lower()))\n        if package.tag == 'BLOSC':  # this is optional, but comes with sources\n            print(\"* Could not find %s headers and library; \"\n                  \"using internal sources.\" % package.name)\n        else:\n            print(\"* Could not find %s headers and library; \"\n                  \"disabling support for it.\" % package.name)\n\n        continue  # look for the next library\n\n    if libdir in (\"\", True):\n        print(\"* Found %s headers at ``%s``, the library is located in the \"\n              \"standard system search dirs.\" % (package.name, hdrdir))\n    else:\n        print(\"* Found %s headers at ``%s``, library at ``%s``.\"\n              % (package.name, hdrdir, libdir))\n\n    if hdrdir not in default_header_dirs:\n        inc_dirs.append(hdrdir)  # save header directory if needed\n    if libdir not in default_library_dirs and libdir not in (\"\", True):\n        # save library directory if needed\n        if os.name == \"nt\":\n            # Important to quote the libdir for Windows (Vista) systems\n            lib_dirs.append('\"%s\"' % libdir)\n        else:\n            lib_dirs.append(libdir)\n\n    if package.tag not in ['HDF5']:\n        # Keep record of the optional libraries found.\n        optional_libs.append(package.tag)\n        def_macros.append(('HAVE_%s_LIB' % package.tag, 1))\n\n    if hdrdir and package.tag == 'BLOSC':\n        blosc_header = os.path.join(hdrdir, \"blosc.h\")\n        blosc_version = get_blosc_version(blosc_header)\n        if blosc_version < min_blosc_version:\n            optional_libs.pop()  # Remove Blosc from the discovered libs\n            print_warning(\n                \"Unsupported Blosc version installed! Blosc %s+ required. \"\n                \"Found version %s.  Using internal Blosc sources.\" % (\n                    min_blosc_version, blosc_version))\n        if blosc_version < min_blosc_bitshuffle_version:\n            print_warning(\n                \"This Blosc version does not support the BitShuffle filter. \"\n                \"Minimum desirable version is %s.  Found version: %s\" % (\n                min_blosc_bitshuffle_version, blosc_version))\n\n    if not rundir:\n        loc = {\n            'posix': \"the default library paths.\",\n            'nt': \"any of the directories in %%PATH%%.\",\n        }[os.name]\n\n        print_warning(\n            \"Could not find the %s runtime.\" % package.name,\n            \"The %(name)s shared library was *not* found in %(loc)s \"\n            \"In case of runtime problems, please remember to install it.\"\n            % dict(name=package.name, loc=loc)\n        )\n\n    if os.name == \"nt\":\n        # LZO DLLs cannot be copied to the binary package for license reasons\n        if package.tag not in ['LZO', 'LZO2']:\n            dll_file = _platdep[package.tag][1] + '.dll'\n            # If DLL is not in rundir, do nothing.  This can be useful\n            # for BZIP2, that can be linked either statically (.LIB)\n            # or dinamically (.DLL)\n            if rundir is not None:\n                dll_files.append(os.path.join(rundir, dll_file))\n\n    if package.tag == 'LZO2':\n        lzo2_enabled = True\n\nif lzo2_enabled:\n    lzo_package = lzo2_package\nelse:\n    lzo_package = lzo1_package\n\n\n# ------------------------------------------------------------------------------\n\ncython_extnames = [\n    'utilsextension',\n    'hdf5extension',\n    'tableextension',\n    'linkextension',\n    '_comp_lzo',\n    '_comp_bzip2',\n    'lrucacheextension',\n    'indexesextension',\n]\n\n\ndef get_cython_extfiles(extnames):\n    extdir = 'tables'\n    extfiles = {}\n\n    for extname in extnames:\n        extfile = os.path.join(extdir, extname)\n        extpfile = '%s.pyx' % extfile\n        extcfile = '%s.c' % extfile\n\n        if not exists(extcfile) or newer(extpfile, extcfile):\n            # This is the only place where Cython is needed, but every\n            # developer should have it installed, so it should not be\n            # a hard requisite\n            from Cython.Build import cythonize\n            cythonize(extpfile)\n        extfiles[extname] = extcfile\n\n    return extfiles\n\n\ncython_extfiles = get_cython_extfiles(cython_extnames)\n\n# Update the version.h file if this file is newer\nif newer('VERSION', 'src/version.h'):\n    open('src/version.h', 'w').write(\n        '#define PYTABLES_VERSION \"%s\"\\n' % VERSION)\n\n# --------------------------------------------------------------------\n\n# Package information for ``setuptools``\n# PyTables contains data files for tests.\nsetuptools_kwargs['zip_safe'] = False\n\nsetuptools_kwargs['extras_require'] = {}\nsetuptools_kwargs['install_requires'] = requirements\n# Detect packages automatically.\nsetuptools_kwargs['packages'] = find_packages(exclude=['*.bench'])\n# Entry points for automatic creation of scripts.\nsetuptools_kwargs['entry_points'] = {\n    'console_scripts': [\n        'ptdump = tables.scripts.ptdump:main',\n        'ptrepack = tables.scripts.ptrepack:main',\n        'pt2to3 = tables.scripts.pt2to3:main',\n        'pttree = tables.scripts.pttree:main',\n        ],\n    }\n\n# Test suites.\nsetuptools_kwargs['test_suite'] = 'tables.tests.test_all.suite'\nsetuptools_kwargs['scripts'] = []\n\n# Copy additional data for packages that need it.\nsetuptools_kwargs['package_data'] = {\n    'tables.tests': ['*.h5', '*.mat'],\n    'tables.nodes.tests': ['*.dat', '*.xbm', '*.h5']}\n\n\n# Having the Python version included in the package name makes managing a\n# system with multiple versions of Python much easier.\n\ndef find_name(base='tables'):\n    '''If \"--name-with-python-version\" is on the command line then\n    append \"-pyX.Y\" to the base name'''\n    name = base\n    if '--name-with-python-version' in sys.argv:\n        name += '-py%i.%i' % (sys.version_info[0], sys.version_info[1])\n        sys.argv.remove('--name-with-python-version')\n    return name\n\n\nname = find_name()\n\nif os.name == \"nt\":\n    # Add DLL's to the final package for windows\n    data_files.extend([\n        ('Lib/site-packages/%s' % name, dll_files),\n    ])\n\nADDLIBS = [hdf5_package.library_name]\n\n# List of Blosc file dependencies\nblosc_sources = [\"hdf5-blosc/src/blosc_filter.c\"]\nif 'BLOSC' not in optional_libs:\n    # Compiling everything from sources\n    # Blosc + BloscLZ sources\n    blosc_sources += [f for f in glob.glob('c-blosc/blosc/*.c')\n                      if 'avx2' not in f and 'sse2' not in f]\n    # LZ4 sources\n    blosc_sources += glob.glob('c-blosc/internal-complibs/lz4*/*.c')\n    # Snappy sources\n    blosc_sources += glob.glob('c-blosc/internal-complibs/snappy*/*.cc')\n    # Zlib sources\n    blosc_sources += glob.glob('c-blosc/internal-complibs/zlib*/*.c')\n    # Zstd sources\n    blosc_sources += glob.glob('c-blosc/internal-complibs/zstd*/*/*.c')\n    # Finally, add all the include dirs...\n    inc_dirs += [os.path.join('c-blosc', 'blosc')]\n    inc_dirs += glob.glob('c-blosc/internal-complibs/*')\n    inc_dirs += glob.glob('c-blosc/internal-complibs/zstd*/common')\n    inc_dirs += glob.glob('c-blosc/internal-complibs/zstd*')\n    # ...and the macros for all the compressors supported\n    def_macros += [('HAVE_LZ4', 1), ('HAVE_SNAPPY', 1), ('HAVE_ZLIB', 1),\n                   ('HAVE_ZSTD', 1)]\n\n    # Add extra flags for optimizing shuffle in include Blosc\n    def compiler_has_flags(compiler, flags):\n        with tempfile.NamedTemporaryFile(mode='w', suffix='.c',\n                                         delete=False) as fd:\n            fd.write('int main() {return 0;}')\n\n        try:\n            compiler.compile([fd.name], extra_preargs=flags)\n        except Exception:\n            return False\n        else:\n            return True\n        finally:\n            os.remove(fd.name)\n\n    # SSE2\n    if 'sse2' in cpu_info['flags']:\n        print('SSE2 detected')\n        CFLAGS.append('-DSHUFFLE_SSE2_ENABLED')\n        if os.name == 'nt':\n            # Windows always should have support for SSE2\n            # (present in all x86/amd64 architectures since 2003)\n            def_macros += [('__SSE2__', 1)]\n        else:\n            # On UNIX, both gcc and clang understand -msse2\n            CFLAGS.append('-msse2')\n        blosc_sources += [f for f in glob.glob('c-blosc/blosc/*.c')\n                          if 'sse2' in f]\n    # AVX2\n    # Detection code for AVX2 only works for gcc/clang, not for MSVC yet\n    if ('avx2' in cpu_info['flags'] and\n        compiler_has_flags(compiler, [\"-mavx2\"])):\n        print('AVX2 detected')\n        CFLAGS.append('-DSHUFFLE_AVX2_ENABLED')\n        CFLAGS.append('-mavx2')\n        blosc_sources += [f for f in glob.glob('c-blosc/blosc/*.c')\n                          if 'avx2' in f]\nelse:\n    ADDLIBS += ['blosc']\n\n\nutilsExtension_libs = LIBS + ADDLIBS\nhdf5Extension_libs = LIBS + ADDLIBS\ntableExtension_libs = LIBS + ADDLIBS\nlinkExtension_libs = LIBS + ADDLIBS\nindexesExtension_libs = LIBS + ADDLIBS\nlrucacheExtension_libs = []    # Doesn't need external libraries\n\n# Compressor modules only need other libraries if they are enabled.\n_comp_lzo_libs = LIBS[:]\n_comp_bzip2_libs = LIBS[:]\nfor (package, complibs) in [(lzo_package, _comp_lzo_libs),\n                            (bzip2_package, _comp_bzip2_libs)]:\n\n    if package.tag in optional_libs:\n        complibs.extend([hdf5_package.library_name, package.library_name])\n\n\nextensions = [\n    Extension(\"tables.utilsextension\",\n              include_dirs=inc_dirs,\n              define_macros=def_macros,\n              sources=[cython_extfiles['utilsextension'],\n                       \"src/utils.c\",\n                       \"src/H5ARRAY.c\",\n                       \"src/H5ATTR.c\",\n                       ] + blosc_sources,\n              library_dirs=lib_dirs,\n              libraries=utilsExtension_libs,\n              extra_link_args=LFLAGS,\n              extra_compile_args=CFLAGS),\n\n    Extension(\"tables.hdf5extension\",\n              include_dirs=inc_dirs,\n              define_macros=def_macros,\n              sources=[cython_extfiles['hdf5extension'],\n                       \"src/utils.c\",\n                       \"src/typeconv.c\",\n                       \"src/H5ARRAY.c\",\n                       \"src/H5ARRAY-opt.c\",\n                       \"src/H5VLARRAY.c\",\n                       \"src/H5ATTR.c\",\n                       ] + blosc_sources,\n              library_dirs=lib_dirs,\n              libraries=hdf5Extension_libs,\n              extra_link_args=LFLAGS,\n              extra_compile_args=CFLAGS),\n\n    Extension(\"tables.tableextension\",\n              include_dirs=inc_dirs,\n              define_macros=def_macros,\n              sources=[cython_extfiles['tableextension'],\n                       \"src/utils.c\",\n                       \"src/typeconv.c\",\n                       \"src/H5TB-opt.c\",\n                       \"src/H5ATTR.c\",\n                       ] + blosc_sources,\n              library_dirs=lib_dirs,\n              libraries=tableExtension_libs,\n              extra_link_args=LFLAGS,\n              extra_compile_args=CFLAGS),\n\n    Extension(\"tables._comp_lzo\",\n              include_dirs=inc_dirs,\n              define_macros=def_macros,\n              sources=[cython_extfiles['_comp_lzo'],\n                       \"src/H5Zlzo.c\"],\n              library_dirs=lib_dirs,\n              libraries=_comp_lzo_libs,\n              extra_link_args=LFLAGS,\n              extra_compile_args=CFLAGS),\n\n    Extension(\"tables._comp_bzip2\",\n              include_dirs=inc_dirs,\n              define_macros=def_macros,\n              sources=[cython_extfiles['_comp_bzip2'],\n                       \"src/H5Zbzip2.c\"],\n              library_dirs=lib_dirs,\n              libraries=_comp_bzip2_libs,\n              extra_link_args=LFLAGS,\n              extra_compile_args=CFLAGS),\n\n    Extension(\"tables.linkextension\",\n              include_dirs=inc_dirs,\n              define_macros=def_macros,\n              sources=[cython_extfiles['linkextension']],\n              library_dirs=lib_dirs,\n              libraries=tableExtension_libs,\n              extra_link_args=LFLAGS,\n              extra_compile_args=CFLAGS),\n\n    Extension(\"tables.lrucacheextension\",\n              include_dirs=inc_dirs,\n              define_macros=def_macros,\n              sources=[cython_extfiles['lrucacheextension']],\n              library_dirs=lib_dirs,\n              libraries=lrucacheExtension_libs,\n              extra_link_args=LFLAGS,\n              extra_compile_args=CFLAGS),\n\n    Extension(\"tables.indexesextension\",\n              include_dirs=inc_dirs,\n              define_macros=def_macros,\n              sources=[cython_extfiles['indexesextension'],\n                       \"src/H5ARRAY-opt.c\",\n                       \"src/idx-opt.c\"],\n              library_dirs=lib_dirs,\n              libraries=indexesExtension_libs,\n              extra_link_args=LFLAGS,\n              extra_compile_args=CFLAGS),\n\n]\n\n\nclassifiers = \"\"\"\\\nDevelopment Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Information Technology\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nProgramming Language :: Python\nProgramming Language :: Python :: 2\nProgramming Language :: Python :: 3\nTopic :: Database\nTopic :: Software Development :: Libraries :: Python Modules\nOperating System :: Microsoft :: Windows\nOperating System :: Unix\n\"\"\"\n\nsetup(\n    name=name,\n    version=VERSION,\n    description='Hierarchical datasets for Python',\n    long_description=\"\"\"\\\nPyTables is a package for managing hierarchical datasets and\ndesigned to efficently cope with extremely large amounts of\ndata. PyTables is built on top of the HDF5 library and the\nNumPy package and features an object-oriented interface\nthat, combined with C-code generated from Cython sources,\nmakes of it a fast, yet extremely easy to use tool for\ninteractively save and retrieve large amounts of data.\n\n\"\"\",\n    classifiers=[c for c in classifiers.split(\"\\n\") if c],\n    author=('Francesc Alted, Ivan Vilata,'\n            'Antonio Valentino, Anthony Scopatz et al.'),\n    author_email='pytables@pytables.org',\n    maintainer='PyTables maintainers',\n    maintainer_email='pytables@pytables.org',\n    url='http://www.pytables.org/',\n    license='BSD 2-Clause',\n    platforms=['any'],\n    ext_modules=extensions,\n    cmdclass=cmdclass,\n    data_files=data_files,\n    **setuptools_kwargs\n)\n",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/src/utils.c": "#include <stdarg.h>\n#include \"utils.h\"\n#include \"version.h\"\n#include \"H5Zlzo.h\"                /* Import FILTER_LZO */\n#include \"H5Zbzip2.h\"              /* Import FILTER_BZIP2 */\n\n#if PY_MAJOR_VERSION > 2\n#define PyString_FromString PyUnicode_FromString\n#endif\n\n#ifndef NPY_COMPLEX192\ntypedef npy_cdouble npy_complex192;\n#endif\n\n#ifndef NPY_COMPLEX256\ntypedef npy_cdouble npy_complex256;\n#endif\n\n/* ---------------------------------------------------------------- */\n\n#ifdef WIN32\n#include <windows.h>\n\n/* This routine is meant to detect whether a dynamic library can be\n   loaded on Windows. This is only way to detect its presence without\n   harming the user.\n*/\nint getLibrary(char *libname) {\n    HINSTANCE hinstLib;\n\n    /* Load the dynamic library */\n    hinstLib = LoadLibrary(TEXT(libname));\n\n    if (hinstLib != NULL) {\n      /* Free the dynamic library */\n      FreeLibrary(hinstLib);\n      return 0;\n    }\n    else {\n      return -1;\n    }\n}\n\n#else  /* Unix platforms */\n#include <dlfcn.h>\n\n/* Routine to detect the existance of shared libraries in UNIX. This\n   has to be checked in MacOSX. However, this is not used right now in\n   utilsExtension.pyx because UNIX does not complain when trying to\n   load an extension library that depends on a shared library that it\n   is not in the system (python raises just the ImportError). */\nint getLibrary(char *libname) {\n    void *hinstLib;\n\n    /* Load the dynamic library */\n    hinstLib = dlopen(libname, RTLD_LAZY);\n\n    if (hinstLib != NULL) {\n      /* Free the dynamic library */\n      dlclose(hinstLib);\n      return 0;\n    }\n    else {\n      return -1;\n    }\n}\n\n\n#endif  /* Win32 */\n\nherr_t set_cache_size(hid_t file_id, size_t cache_size) {\n#if H5_VERS_MAJOR == 1 && H5_VERS_MINOR >= 7\n  /* MSVS2005 chokes on declarations after statements */\n  H5AC_cache_config_t config;\n#endif /* if H5_VERSION < \"1.7\" */\n  herr_t code;\n\n  code = 0;\n\n#if H5_VERS_MAJOR == 1 && H5_VERS_MINOR >= 7\n  config.version = H5AC__CURR_CACHE_CONFIG_VERSION;\n  code = H5Fget_mdc_config(file_id, &config);\n  config.set_initial_size = TRUE;\n  config.initial_size = cache_size;\n/*   config.incr_mode = H5C_incr__off; */\n/*   config.decr_mode = H5C_decr__off; */\n/*   printf(\"Setting cache size to: %d\\n\", cache_size); */\n  code = H5Fset_mdc_config(file_id, &config);\n/*   printf(\"Return code for H5Fset_mdc_config: %d\\n\", code); */\n\n#endif /* if H5_VERSION < \"1.7\" */\n\n  return code;\n\n}\n\nPyObject *_getTablesVersion() {\n  return PyString_FromString(PYTABLES_VERSION);\n}\n\nPyObject *getHDF5VersionInfo(void) {\n  long binver;\n  unsigned majnum, minnum, relnum;\n  char     strver[16];\n  PyObject *t;\n\n/*  H5get_libversion(&majnum, &minnum, &relnum); */\n  majnum = H5_VERS_MAJOR;\n  minnum = H5_VERS_MINOR;\n  relnum = H5_VERS_RELEASE;\n  /* Get a binary number */\n  binver = majnum << 16 | minnum << 8 | relnum;\n  /* A string number */\n  if (strcmp(H5_VERS_SUBRELEASE, \"\")) {\n    snprintf(strver, 16, \"%d.%d.%d-%s\", majnum, minnum, relnum,\n             H5_VERS_SUBRELEASE);\n  }\n  else {\n    snprintf(strver, 16, \"%d.%d.%d\", majnum, minnum, relnum);\n  }\n\n  t = PyTuple_New(2);\n  PyTuple_SetItem(t, 0, PyLong_FromLong(binver));\n  PyTuple_SetItem(t, 1, PyString_FromString(strver));\n  return t;\n}\n\n/****************************************************************\n**\n**  createNamesTuple(): Create Python tuple from a string of *char.\n**\n****************************************************************/\nPyObject *createNamesTuple(char *buffer[], int nelements)\n{\n  int i;\n  PyObject *t;\n  PyObject *str;\n\n  t = PyTuple_New(nelements);\n  for (i = 0; i < nelements; i++) {\n    str = PyString_FromString(buffer[i]);\n    PyTuple_SetItem(t, i, str);\n    /* PyTuple_SetItem does not need a decref, because it already do this */\n/*     Py_DECREF(str); */\n  }\n  return t;\n}\n\nPyObject *createNamesList(char *buffer[], int nelements)\n{\n  int i;\n  PyObject *t;\n  PyObject *str;\n\n  t = PyList_New(nelements);\n  for (i = 0; i < nelements; i++) {\n    str = PyString_FromString(buffer[i]);\n    PyList_SetItem(t, i, str);\n    /* PyList_SetItem does not need a decref, because it already do this */\n/*     Py_DECREF(str); */\n  }\n  return t;\n}\n\n/*-------------------------------------------------------------------------\n * Function: get_filter_names\n *\n * Purpose: Get the filter names for the chunks in a dataset\n *\n * Return: Success: 0, Failure: -1\n *\n * Programmer: Francesc Alted, faltet@pytables.com\n *\n * Date: December 19, 2003\n *\n * Comments:\n *\n * Modifications:\n *\n *\n *-------------------------------------------------------------------------\n */\n\nPyObject *get_filter_names( hid_t loc_id,\n                            const char *dset_name)\n{\n  hid_t    dset;\n  hid_t    dcpl;           /* dataset creation property list */\n  /*  hsize_t  chsize[64];     /\\* chunk size in elements *\\/ */\n  int      i, j;\n  int      nf;             /* number of filters */\n  unsigned filt_flags;     /* filter flags */\n  size_t   cd_nelmts;      /* filter client number of values */\n  unsigned cd_values[20];  /* filter client data values */\n  char     f_name[256];    /* filter name */\n  PyObject *filters;\n  PyObject *filter_values;\n\n  /* Open the dataset. */\n  if ( (dset = H5Dopen( loc_id, dset_name, H5P_DEFAULT )) < 0 ) {\n    goto out;\n  }\n\n  /* Get the properties container */\n  dcpl = H5Dget_create_plist(dset);\n  /* Collect information about filters on chunked storage */\n  if (H5D_CHUNKED==H5Pget_layout(dcpl)) {\n    filters = PyDict_New();\n    if ((nf = H5Pget_nfilters(dcpl))>0) {\n      for (i=0; i<nf; i++) {\n        cd_nelmts = 20;\n        H5Pget_filter(dcpl, i, &filt_flags, &cd_nelmts,\n                      cd_values, sizeof(f_name), f_name, NULL);\n        filter_values = PyTuple_New(cd_nelmts);\n        for (j=0;j<(long)cd_nelmts;j++) {\n          PyTuple_SetItem(filter_values, j, PyLong_FromLong(cd_values[j]));\n        }\n        PyMapping_SetItemString (filters, f_name, filter_values);\n      }\n    }\n  }\n  else {\n    /* http://aspn.activestate.com/ASPN/Cookbook/Python/Recipe/52309 */\n    Py_INCREF(Py_None);\n    filters = Py_None;   /* Not chunked, so return None */\n  }\n\n  H5Pclose(dcpl);\n  H5Dclose(dset);\n\n  return filters;\n\nout:\n  H5Dclose(dset);\n  Py_INCREF(Py_None);\n  return Py_None;        /* Not chunked, so return None */\n}\n\n\n/****************************************************************\n**\n**  get_objinfo(): Get information about the type of a child.\n**\n****************************************************************/\nint get_objinfo(hid_t loc_id, const char *name) {\n  herr_t     ret;            /* Generic return value         */\n  H5G_stat_t oinfo;\n  /* H5O_info_t oinfo; H5Oget_info_by_name seems to have performance issues (see gh-402) */\n\n  /* Get type of the object, without emiting an error in case the\n     node does not exist. */\n  H5E_BEGIN_TRY {\n    ret = H5Gget_objinfo(loc_id, name, FALSE, &oinfo);\n    /* H5Oget_info_by_name seems to have performance issues (see gh-402) */\n    /*ret = H5Oget_info_by_name(loc_id, name, &oinfo, H5P_DEFAULT);*/\n  } H5E_END_TRY;\n  if (ret < 0)\n    return -2;\n  return oinfo.type;\n}\n\n/****************************************************************\n**\n**  get_linkinfo(): Get information about the type of a link.\n**\n****************************************************************/\nint get_linkinfo(hid_t loc_id, const char *name) {\n  herr_t     ret;            /* Generic return value         */\n  H5L_info_t linfo;\n\n  /* Get type of the link, without emiting an error in case the\n     node does not exist. */\n  H5E_BEGIN_TRY {\n    ret = H5Lget_info(loc_id, name, &linfo, H5P_DEFAULT);\n  } H5E_END_TRY;\n  if (ret < 0)\n    return -2;\n  return linfo.type;\n}\n\n/****************************************************************\n**\n**  litercb(): Custom link iteration callback routine.\n**\n****************************************************************/\nherr_t litercb(hid_t loc_id, const char *name, const H5L_info_t *info,\n               void *data) {\n  PyObject   **out_info=(PyObject **)data;\n  PyObject   *strname;\n  herr_t     ret;\n  H5G_stat_t oinfo;\n  /*H5O_info_t oinfo; H5Oget_info_by_name seems to have performance issues (see gh-402) */\n  int        namedtypes = 0;\n\n  strname = PyString_FromString(name);\n\n  switch(info->type) {\n    case H5L_TYPE_SOFT:\n    case H5L_TYPE_EXTERNAL:\n      PyList_Append(out_info[2], strname);\n      break;\n    case H5L_TYPE_ERROR:  /* XXX: check */\n      PyList_Append(out_info[3], strname);\n      break;\n    case H5L_TYPE_HARD:\n      /* Get type of the object and check it */\n      ret = H5Gget_objinfo(loc_id, name, FALSE, &oinfo);\n      if (ret < 0)\n        return -1;\n\n      switch(oinfo.type) {\n        case H5G_GROUP:\n          PyList_Append(out_info[0], strname);\n          break;\n        case H5G_DATASET:\n          PyList_Append(out_info[1], strname);\n          break;\n        case H5G_TYPE:\n          ++namedtypes;\n          break;\n        case H5G_UNKNOWN:\n          PyList_Append(out_info[3], strname);\n          break;\n        case H5G_LINK:\n          /* should not happen */\n          PyList_Append(out_info[2], strname);\n          break;\n        default:\n          /* should not happen: assume it is an external link */\n          PyList_Append(out_info[2], strname);\n      }\n\n      /* H5Oget_info_by_name seems to have performance issues (see gh-402)\n      ret = H5Oget_info_by_name(loc_id, name, &oinfo, H5P_DEFAULT);\n      if (ret < 0)\n        return -1;\n\n      switch(oinfo.type) {\n        case H5O_TYPE_GROUP:\n          PyList_Append(out_info[0], strname);\n          break;\n        case H5O_TYPE_DATASET:\n          PyList_Append(out_info[1], strname);\n          break;\n        case H5O_TYPE_NAMED_DATATYPE:\n          ++namedtypes;\n          break;\n        case H5O_TYPE_UNKNOWN:\n          PyList_Append(out_info[3], strname);\n          break;\n        default:\n          / * should not happen * /\n          PyList_Append(out_info[3], strname);\n      }\n      */\n      break;\n    default:\n      /* should not happen */\n      PyList_Append(out_info[3], strname);\n  }\n  Py_DECREF(strname);\n\n  return 0 ;  /* Loop until no more objects remain in directory */\n}\n\n/****************************************************************\n**\n**  Giterate(): Group iteration routine.\n**\n****************************************************************/\nPyObject *Giterate(hid_t parent_id, hid_t loc_id, const char *name) {\n  hsize_t i=0;\n  PyObject  *t, *tgroup, *tleave, *tlink, *tunknown;\n  PyObject *info[4];\n\n  info[0] = tgroup = PyList_New(0);\n  info[1] = tleave = PyList_New(0);\n  info[2] = tlink = PyList_New(0);\n  info[3] = tunknown = PyList_New(0);\n\n  /* Iterate over all the childs behind loc_id (parent_id+loc_id).\n   * NOTE: using H5_INDEX_CRT_ORDER instead of H5_INDEX_NAME causes failures\n   * in the test suite */\n  H5Literate_by_name(parent_id, name, H5_INDEX_NAME, H5_ITER_NATIVE,\n                     &i, litercb, info, H5P_DEFAULT);\n\n  /* Create the tuple with the list of Groups and Datasets */\n  t = PyTuple_New(4);\n  PyTuple_SetItem(t, 0, tgroup);\n  PyTuple_SetItem(t, 1, tleave);\n  PyTuple_SetItem(t, 2, tlink);\n  PyTuple_SetItem(t, 3, tunknown);\n\n  return t;\n}\n\n/****************************************************************\n**\n**  aitercb(): Custom attribute iteration callback routine.\n**\n****************************************************************/\nstatic herr_t aitercb( hid_t loc_id, const char *name,\n                       const H5A_info_t *ainfo, void *op_data) {\n  PyObject *strname;\n\n  strname = PyString_FromString(name);\n  /* Return the name of the attribute on op_data */\n  PyList_Append(op_data, strname);\n  Py_DECREF(strname);\n  return(0);    /* Loop until no more attrs remain in object */\n}\n\n\n/****************************************************************\n**\n**  Aiterate(): Attribute set iteration routine.\n**\n****************************************************************/\nPyObject *Aiterate(hid_t loc_id) {\n  hsize_t i = 0;\n  PyObject *attrlist;                  /* List where the attrnames are put */\n\n  attrlist = PyList_New(0);\n  H5Aiterate(loc_id, H5_INDEX_CRT_ORDER, H5_ITER_NATIVE, &i,\n             (H5A_operator_t)aitercb, (void *)attrlist);\n\n  return attrlist;\n}\n\n\n/****************************************************************\n**\n**  getHDF5ClassID(): Returns class ID for loc_id.name. -1 if error.\n**\n****************************************************************/\nH5T_class_t getHDF5ClassID(hid_t loc_id,\n                           const char *name,\n                           H5D_layout_t *layout,\n                           hid_t *type_id,\n                           hid_t *dataset_id) {\n   H5T_class_t  class_id;\n   hid_t        plist;\n\n   /* Open the dataset. */\n   if ( (*dataset_id = H5Dopen( loc_id, name, H5P_DEFAULT )) < 0 )\n     return -1;\n\n   /* Get an identifier for the datatype. */\n   *type_id = H5Dget_type( *dataset_id );\n\n   /* Get the class. */\n   class_id = H5Tget_class( *type_id );\n\n   /* Get the layout of the datatype */\n   plist = H5Dget_create_plist(*dataset_id);\n   *layout = H5Pget_layout(plist);\n   H5Pclose(plist);\n\n   return class_id;\n\n}\n\n\n/* Helper routine that returns the rank, dims and byteorder for\n   UnImplemented objects. 2004\n*/\n\nPyObject *H5UIget_info( hid_t loc_id,\n                        const char *dset_name,\n                        char *byteorder)\n{\n  hid_t       dataset_id;\n  int         rank;\n  hsize_t     *dims;\n  hid_t       space_id;\n  H5T_class_t class_id;\n  H5T_order_t order;\n  hid_t       type_id;\n  PyObject    *t;\n  int         i;\n\n  /* Open the dataset. */\n  if ( (dataset_id = H5Dopen( loc_id, dset_name, H5P_DEFAULT )) < 0 ) {\n    Py_INCREF(Py_None);\n    return Py_None;     /* Not chunked, so return None */\n  }\n\n  /* Get an identifier for the datatype. */\n  type_id = H5Dget_type( dataset_id );\n\n  /* Get the class. */\n  class_id = H5Tget_class( type_id );\n\n  /* Get the dataspace handle */\n  if ( (space_id = H5Dget_space( dataset_id )) < 0 )\n    goto out;\n\n  /* Get rank */\n  if ( (rank = H5Sget_simple_extent_ndims( space_id )) < 0 )\n    goto out;\n\n  /* Book resources for dims */\n  dims = (hsize_t *)malloc(rank * sizeof(hsize_t));\n\n  /* Get dimensions */\n  if ( H5Sget_simple_extent_dims( space_id, dims, NULL) < 0 )\n    goto out;\n\n  /* Assign the dimensions to a tuple */\n  t = PyTuple_New(rank);\n  for(i=0;i<rank;i++) {\n    /* I don't know if I should increase the reference count for dims[i]! */\n    PyTuple_SetItem(t, i, PyLong_FromLong((long)dims[i]));\n  }\n\n  /* Release resources */\n  free(dims);\n\n  /* Terminate access to the dataspace */\n  if ( H5Sclose( space_id ) < 0 )\n    goto out;\n\n  /* Get the byteorder */\n  /* Only integer, float, time and enum classes can be byteordered */\n  if ((class_id == H5T_INTEGER) || (class_id == H5T_FLOAT)\n      || (class_id == H5T_BITFIELD) || (class_id == H5T_TIME)\n      ||  (class_id == H5T_ENUM)) {\n    order = H5Tget_order( type_id );\n    if (order == H5T_ORDER_LE)\n      strcpy(byteorder, \"little\");\n    else if (order == H5T_ORDER_BE)\n      strcpy(byteorder, \"big\");\n    else {\n      fprintf(stderr, \"Error: unsupported byteorder: %d\\n\", order);\n      goto out;\n    }\n  }\n  else {\n    strcpy(byteorder, \"irrelevant\");\n  }\n\n  /* End access to the dataset */\n  H5Dclose( dataset_id );\n\n  /* Return the dimensions tuple */\n  return t;\n\nout:\n H5Tclose( type_id );\n H5Dclose( dataset_id );\n Py_INCREF(Py_None);\n return Py_None;    /* Not chunked, so return None */\n\n}\n\n\n/* The next provides functions to support a complex datatype.\n   HDF5 does not provide an atomic type class for complex numbers\n   so we make one from a HDF5 compound type class.\n\n   Added by Tom Hedley <thedley@users.sourceforge.net> April 2004.\n   Adapted to support Tables by F. Alted September 2004.\n*/\n\n/* Test whether the datatype is of class complex\n   return 1 if it corresponds to our complex class, otherwise 0 */\n/* This may be ultimately confused with nested types with 2 components\n   called 'r' and 'i' and being floats, but in that case, the user\n   most probably wanted to keep a complex type, so getting a complex\n   instead of a nested type should not be a big issue (I hope!) :-/\n   F. Alted 2005-05-23 */\nint is_complex(hid_t type_id) {\n  hid_t class_id, base_type_id;\n  hid_t class1, class2;\n  char *colname1, *colname2;\n  int result = 0;\n  hsize_t nfields;\n\n  class_id = H5Tget_class(type_id);\n  if (class_id == H5T_COMPOUND) {\n    nfields = H5Tget_nmembers(type_id);\n    if (nfields == 2) {\n      colname1 = H5Tget_member_name(type_id, 0);\n      colname2 = H5Tget_member_name(type_id, 1);\n      if ((strcmp(colname1, \"r\") == 0) && (strcmp(colname2, \"i\") == 0)) {\n        class1 = H5Tget_member_class(type_id, 0);\n        class2 = H5Tget_member_class(type_id, 1);\n        if (class1 == H5T_FLOAT && class2 == H5T_FLOAT)\n          result = 1;\n      }\n      pt_H5free_memory(colname1);\n      pt_H5free_memory(colname2);\n    }\n  }\n  /* Is an Array of Complex? */\n  else if (class_id == H5T_ARRAY) {\n    /* Get the array base component */\n    base_type_id = H5Tget_super(type_id);\n    /* Call is_complex again */\n    result = is_complex(base_type_id);\n    H5Tclose(base_type_id);\n  }\n  return result;\n}\n\n\n/* Return the byteorder of a complex datatype.\n   It is obtained from the real part, which is the first member. */\nstatic H5T_order_t get_complex_order(hid_t type_id) {\n  hid_t class_id, base_type_id;\n  hid_t real_type = 0;\n  H5T_order_t result = 0;\n\n  class_id = H5Tget_class(type_id);\n  if (class_id == H5T_COMPOUND) {\n    real_type = H5Tget_member_type(type_id, 0);\n  }\n  else if (class_id == H5T_ARRAY) {\n    /* Get the array base component */\n    base_type_id = H5Tget_super(type_id);\n    /* Get the type of real component. */\n    real_type = H5Tget_member_type(base_type_id, 0);\n    H5Tclose(base_type_id);\n  }\n  if ((class_id == H5T_COMPOUND) || (class_id == H5T_ARRAY)) {\n    result = H5Tget_order(real_type);\n    H5Tclose(real_type);\n  }\n  return result;\n}\n\n\n/* Return the byteorder of a HDF5 data type */\n/* This is actually an extension of H5Tget_order to handle complex types */\nherr_t get_order(hid_t type_id, char *byteorder) {\n  H5T_order_t h5byteorder;\n  /*\n  hid_t class_id;\n\n  class_id = H5Tget_class(type_id);\n  */\n\n  if (is_complex(type_id)) {\n    h5byteorder = get_complex_order(type_id);\n  }\n  else {\n    h5byteorder = H5Tget_order(type_id);\n  }\n  if (h5byteorder == H5T_ORDER_LE) {\n    strcpy(byteorder, \"little\");\n    return h5byteorder;\n  }\n  else if (h5byteorder == H5T_ORDER_BE ) {\n    strcpy(byteorder, \"big\");\n    return h5byteorder;\n  }\n  else if (h5byteorder == H5T_ORDER_NONE ) {\n    strcpy(byteorder, \"irrelevant\");\n    return h5byteorder;\n  }\n  else {\n    /* This should never happen! */\n    fprintf(stderr, \"Error: unsupported byteorder <%d>\\n\", h5byteorder);\n    strcpy(byteorder, \"unsupported\");\n    return -1;\n  }\n}\n\n\n/* Set the byteorder of type_id. */\n/* This only works for datatypes that are not Complex. However,\n   these types should already been created with correct byteorder */\nherr_t set_order(hid_t type_id, const char *byteorder) {\n  herr_t status=0;\n\n  if (! is_complex(type_id)) {\n    if (strcmp(byteorder, \"little\") == 0)\n      status = H5Tset_order(type_id, H5T_ORDER_LE);\n    else if (strcmp(byteorder, \"big\") == 0)\n      status = H5Tset_order(type_id, H5T_ORDER_BE);\n    else if (strcmp(byteorder, \"irrelevant\") == 0) {\n      /* Do nothing because 'irrelevant' doesn't require setting the\n         byteorder explicitely */\n/*       status = H5Tset_order(type_id, H5T_ORDER_NONE ); */\n    }\n    else {\n      fprintf(stderr, \"Error: unsupported byteorder <%s>\\n\", byteorder);\n      status = -1;\n    }\n  }\n  return status;\n}\n\n\n/* Create a HDF5 atomic datatype that represents half precision floatting\n   point numbers defined by numpy as float16. */\nhid_t create_ieee_float16(const char *byteorder) {\n  hid_t float_id;\n\n  if (byteorder == NULL)\n    float_id = H5Tcopy(H5T_NATIVE_FLOAT);\n  else if (strcmp(byteorder, \"little\") == 0)\n    float_id = H5Tcopy(H5T_IEEE_F32LE);\n  else\n    float_id = H5Tcopy(H5T_IEEE_F32BE);\n\n  if (float_id < 0)\n    return float_id;\n\n  if (H5Tset_fields(float_id, 15, 10, 5, 0, 10) < 0)\n    return -1;\n\n  if (H5Tset_size(float_id, 2) < 0)\n    return -1;\n\n  if (H5Tset_ebias(float_id, 15) < 0)\n    return -1;\n\n  return float_id;\n}\n\n\n/* Create a HDF5 atomic datatype that represents quad precision floatting\n   point numbers. */\nhid_t create_ieee_quadprecision_float(const char *byteorder) {\n  hid_t float_id;\n\n  if (byteorder == NULL)\n    float_id = H5Tcopy(H5T_NATIVE_DOUBLE);\n  else if (strcmp(byteorder, \"little\") == 0)\n    float_id = H5Tcopy(H5T_IEEE_F64LE);\n  else\n    float_id = H5Tcopy(H5T_IEEE_F64BE);\n\n  if (float_id < 0)\n    return float_id;\n\n  if (H5Tset_size(float_id, 16) < 0)\n    return -1;\n\n  if ((H5Tset_precision(float_id, 128)) < 0)\n    return -1;\n\n  if (H5Tset_fields(float_id , 127, 112, 15, 0, 112) < 0)\n    return -1;\n\n  if (H5Tset_ebias(float_id, 16383) < 0)\n    return -1;\n\n  return float_id;\n}\n\n\n/* Create a HDF5 compound datatype that represents complex numbers\n   defined by numpy as complex64. */\nhid_t create_ieee_complex64(const char *byteorder) {\n  hid_t float_id, complex_id;\n\n  complex_id = H5Tcreate(H5T_COMPOUND, sizeof(npy_complex64));\n  if (byteorder == NULL)\n    float_id = H5Tcopy(H5T_NATIVE_FLOAT);\n  else if (strcmp(byteorder, \"little\") == 0)\n    float_id = H5Tcopy(H5T_IEEE_F32LE);\n  else\n    float_id = H5Tcopy(H5T_IEEE_F32BE);\n\n  if (float_id < 0)\n  {\n    H5Tclose(complex_id);\n    return float_id;\n  }\n\n  H5Tinsert(complex_id, \"r\", HOFFSET(npy_complex64, real), float_id);\n  H5Tinsert(complex_id, \"i\", HOFFSET(npy_complex64, imag), float_id);\n  H5Tclose(float_id);\n  return complex_id;\n}\n\n\n/* Counterpart for complex128 */\nhid_t create_ieee_complex128(const char *byteorder) {\n  hid_t float_id, complex_id;\n\n  complex_id = H5Tcreate(H5T_COMPOUND, sizeof(npy_complex128));\n  if (byteorder == NULL)\n    float_id = H5Tcopy(H5T_NATIVE_DOUBLE);\n  else if (strcmp(byteorder, \"little\") == 0)\n    float_id = H5Tcopy(H5T_IEEE_F64LE);\n  else\n    float_id = H5Tcopy(H5T_IEEE_F64BE);\n\n  if (float_id < 0)\n  {\n    H5Tclose(complex_id);\n    return float_id;\n  }\n\n  H5Tinsert(complex_id, \"r\", HOFFSET(npy_complex128, real), float_id);\n  H5Tinsert(complex_id, \"i\", HOFFSET(npy_complex128, imag), float_id);\n  H5Tclose(float_id);\n  return complex_id;\n}\n\n\n/* Counterpart for complex192 */\nhid_t create_ieee_complex192(const char *byteorder) {\n  herr_t err = 0;\n  hid_t float_id, complex_id;\n  H5T_order_t h5order = H5Tget_order(H5T_NATIVE_LDOUBLE);\n\n  complex_id = H5Tcreate(H5T_COMPOUND, sizeof(npy_complex192));\n  float_id = H5Tcopy(H5T_NATIVE_LDOUBLE);\n  if (float_id < 0)\n  {\n    H5Tclose(complex_id);\n    return float_id;\n  }\n\n  if ((strcmp(byteorder, \"little\") == 0) && (h5order != H5T_ORDER_LE))\n    err = H5Tset_order(float_id, H5T_ORDER_LE);\n  else if ((strcmp(byteorder, \"big\") == 0) && (h5order != H5T_ORDER_BE))\n    err = H5Tset_order(float_id, H5T_ORDER_BE);\n\n  if (err < 0)\n  {\n    H5Tclose(complex_id);\n    return err;\n  }\n\n  H5Tinsert(complex_id, \"r\", HOFFSET(npy_complex192, real), float_id);\n  H5Tinsert(complex_id, \"i\", HOFFSET(npy_complex192, imag), float_id);\n  H5Tclose(float_id);\n  return complex_id;\n}\n\n\n/* Counterpart for complex256 */\nhid_t create_ieee_complex256(const char *byteorder) {\n  herr_t err = 0;\n  hid_t float_id, complex_id;\n  H5T_order_t h5order = H5Tget_order(H5T_NATIVE_LDOUBLE);\n\n  complex_id = H5Tcreate(H5T_COMPOUND, sizeof(npy_complex256));\n  float_id = H5Tcopy(H5T_NATIVE_LDOUBLE);\n  if (float_id < 0)\n  {\n    H5Tclose(complex_id);\n    return float_id;\n  }\n\n  if ((strcmp(byteorder, \"little\") == 0) && (h5order != H5T_ORDER_LE))\n    err = H5Tset_order(float_id, H5T_ORDER_LE);\n  else if ((strcmp(byteorder, \"big\") == 0) && (h5order != H5T_ORDER_BE))\n    err = H5Tset_order(float_id, H5T_ORDER_BE);\n\n  if (err < 0)\n  {\n    H5Tclose(complex_id);\n    return err;\n  }\n\n  H5Tinsert(complex_id, \"r\", HOFFSET(npy_complex256, real), float_id);\n  H5Tinsert(complex_id, \"i\", HOFFSET(npy_complex256, imag), float_id);\n  H5Tclose(float_id);\n  return complex_id;\n}\n\n\n/* Return the number of significant bits in the real and imaginary parts */\n/* This is actually an extension of H5Tget_precision to handle complex types */\nsize_t get_complex_precision(hid_t type_id) {\n  hid_t real_type;\n  size_t result;\n  real_type = H5Tget_member_type(type_id, 0);\n  result = H5Tget_precision(real_type);\n  H5Tclose(real_type);\n  return result;\n}\n\n/* End of complex additions */\n\n\n/* The get_len_of_range has been taken from Python interpreter */\n\n/* Return number of items in range/xrange (lo, hi, step).  step > 0\n * required.  Return a value < 0 if & only if the true value is too\n * large to fit in a signed long.\n */\nhsize_t get_len_of_range(hsize_t lo, hsize_t hi, hsize_t step)\n{\n  /* -------------------------------------------------------------\n     If lo >= hi, the range is empty.\n     Else if n values are in the range, the last one is\n     lo + (n-1)*step, which must be <= hi-1.  Rearranging,\n     n <= (hi - lo - 1)/step + 1, so taking the floor of the RHS gives\n     the proper value.  Since lo < hi in this case, hi-lo-1 >= 0, so\n     the RHS is non-negative and so truncation is the same as the\n     floor.  Letting M be the largest positive long, the worst case\n     for the RHS numerator is hi=M, lo=-M-1, and then\n     hi-lo-1 = M-(-M-1)-1 = 2*M.  Therefore unsigned long has enough\n     precision to compute the RHS exactly.\n     Note: We are using here 64 bit ints because PyTables can deal\n     with 64-bit addresses even on 32-bit platforms.\n     F. Alted 2006-09-25\n     ---------------------------------------------------------------*/\n  hsize_t n = 0;\n  if (lo < hi) {\n    hsize_t diff = hi - lo - 1;\n    n = (hsize_t)(diff / step + 1);\n  }\n  return n;\n}\n\n\n/* Truncate the dataset to at most size rows  */\nherr_t truncate_dset( hid_t dataset_id,\n                      const int maindim,\n                      const hsize_t size)\n{\n\n hid_t    space_id;\n hsize_t  *dims = NULL;\n int      rank;\n\n  /* Get the dataspace handle */\n if ( (space_id = H5Dget_space(dataset_id)) < 0 )\n  goto out;\n\n /* Get the rank */\n if ( (rank = H5Sget_simple_extent_ndims(space_id)) < 0 )\n   goto out;\n\n if (rank) {    /* multidimensional case */\n   /* Book some memory for the selections */\n   dims = (hsize_t *)malloc(rank*sizeof(hsize_t));\n\n   /* Get dataset dimensionality */\n   if ( H5Sget_simple_extent_dims(space_id, dims, NULL) < 0 )\n     goto out;\n\n   /* Truncate the EArray */\n   dims[maindim] = size;\n   if ( H5Dset_extent(dataset_id, dims) < 0 )\n     goto out;\n\n   /* Release resources */\n   free(dims);\n }\n else {         /* scalar case (should never enter here) */\n     printf(\"A scalar Array cannot be truncated!.\\n\");\n     goto out;\n }\n\n /* Free resources */\n if ( H5Sclose(space_id) < 0 )\n   return -1;\n\n return 0;\n\nout:\n if (dims) free(dims);\n return -1;\n}\n\n\n/*\n * Helpers for management of HDF5 drivers\n */\n\n/* DIRECT driver */\n#ifndef H5_HAVE_DIRECT\n\nherr_t pt_H5Pset_fapl_direct(hid_t fapl_id, size_t alignment,\n                             size_t block_size, size_t cbuf_size)\n{\n return -1;\n}\n\n#endif /* H5_HAVE_DIRECT */\n\n\n/* WINDOWS driver */\n#ifndef H5_HAVE_WINDOWS\n\nherr_t pt_H5Pset_fapl_windows(hid_t fapl_id)\n{\n return -1;\n}\n\n#endif /* H5_HAVE_WINDOWS */\n\n\n#if (H5_HAVE_IMAGE_FILE != 1)\n/* HDF5 version < 1.8.9 */\n\nherr_t pt_H5Pset_file_image(hid_t fapl_id, void *buf_ptr, size_t buf_len) {\n return -1;\n}\n\nssize_t pt_H5Fget_file_image(hid_t file_id, void *buf_ptr, size_t buf_len) {\n return -1;\n}\n\n#endif /* (H5_HAVE_IMAGE_FILE != 1) */\n\n\n#if H5_VERSION_LE(1,8,12)\n\nherr_t pt_H5free_memory(void *buf) {\n free(buf);\n return 0;\n}\n\n#endif\n"
    },
    "skipped": [
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/tests/smpl_i32be.h5",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/tests/nested-type-with-gaps.h5",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/tests/smpl_i32le.h5",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/tests/test_ref_array2.mat",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/tests/zerodim-attrs-1.4.h5",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/tests/test_szip.h5",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/tests/Tables_lzo1_shuffle.h5",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/tests/elink2.h5",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/tests/non-chunked-table.h5",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/tests/python2.h5",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/tests/smpl_compound_chunked.h5",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/tests/issue_560.h5",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/tests/vlstr_attr.h5",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/tests/array_mdatom.h5",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/tests/Tables_lzo2.h5",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/tests/times-nested-be.h5",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/tests/smpl_f64le.h5",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/tests/float.h5",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/tests/blosc_bigendian.h5",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/tests/test_ref_array1.mat",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/tests/smpl_enum.h5",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/tests/matlab_file.mat",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/tests/smpl_f64be.h5",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/tests/vlunicode_endian.h5",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/tests/python3.h5",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/tests/Table2_1_lzo_nrv2e_shuffle.h5",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/tests/indexes_2_1.h5",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/tests/flavored_vlarrays-format1.6.h5",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/tests/smpl_i64le.h5",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/tests/smpl_SDSextendible.h5",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/tests/elink.h5",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/tests/smpl_unsupptype.h5",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/tests/slink.h5",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/tests/idx-std-1.x.h5",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/tests/scalar.h5",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/tests/Tables_lzo2_shuffle.h5",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/tests/attr-u16.h5",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/tests/test_vlarray.py",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/tests/Tables_lzo1.h5",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/tests/ex-noattr.h5",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/tests/time-table-vlarray-1_x.h5",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/tests/zerodim-attrs-1.3.h5",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/tests/oldflavor_numeric.h5",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/tests/issue_368.h5",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/tests/smpl_i64be.h5",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/tests/bug-idx.h5",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/tests/indexes_2_0.h5",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/tables/nodes/tests/test_filenode_v1.h5",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/source/usersguide/images/compressed-select-cache.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/source/usersguide/images/tutorial2-tableview.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/source/usersguide/images/compressed-select-cache-zlib.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/source/usersguide/images/tutorial1-1-tableview.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/source/usersguide/images/objecttree-h5.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/source/usersguide/images/indexes-sizes2.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/source/usersguide/images/compressed-recordsize-shuffle.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/source/usersguide/images/compressed-writing-shuffle.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/source/usersguide/images/create-chunksize-15GB.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/source/usersguide/images/compressed-writing-zlib.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/source/usersguide/images/Q8-1g-idx-sorted.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/source/usersguide/images/compressed-recordsize-zlib.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/source/usersguide/images/compressed-recordsize.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/source/usersguide/images/create-index-time-int32-float64.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/source/usersguide/images/random-chunksize-15GB.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/source/usersguide/images/filesizes-chunksize-15GB.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/source/usersguide/images/compressed-writing.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/source/usersguide/images/Q8-1g-idx-SSD.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/source/usersguide/images/compressed-select-nocache.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/source/usersguide/images/read-medium-psyco-nopsyco-comparison.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/source/usersguide/images/tutorial1-general.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/source/usersguide/images/objecttree.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/source/usersguide/images/Q7-10m-noidx.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/source/usersguide/images/compressed-select-cache-shuffle.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/source/usersguide/images/compressed-select-nocache-shuffle-only.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/source/usersguide/images/Q8-1g-noidx.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/source/usersguide/images/seq-chunksize-15GB.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/source/usersguide/images/Q8-1g-idx-optlevels.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/source/usersguide/images/write-medium-psyco-nopsyco-comparison.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/source/usersguide/images/Q8-1g-idx-compress.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/source/usersguide/images/tutorial1-2-tableview.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/source/usersguide/images/objecttree.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/source/usersguide/images/pytables-front-logo.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/source/images/NumFocusSponsoredStamp.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/source/images/favicon.ico",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/source/_theme/cloud/static/icon-seealso.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/source/_theme/cloud/static/icon-note.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/source/_theme/cloud/static/icon-warning.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/source/_theme/cloud/static/icon-todo.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/source/_static/logo-pytables-small.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/objects.inv",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_images/compressed-select-cache.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_images/tutorial2-tableview.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_images/compressed-select-cache-zlib.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_images/tutorial1-1-tableview.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_images/objecttree-h5.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_images/indexes-sizes2.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_images/compressed-recordsize-shuffle.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_images/compressed-writing-shuffle.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_images/create-chunksize-15GB.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_images/NumFocusSponsoredStamp.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_images/compressed-writing-zlib.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_images/Q8-1g-idx-sorted.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_images/compressed-recordsize-zlib.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_images/compressed-recordsize.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_images/create-index-time-int32-float64.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_images/random-chunksize-15GB.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_images/filesizes-chunksize-15GB.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_images/compressed-writing.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_images/Q8-1g-idx-SSD.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_images/compressed-select-nocache.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_images/read-medium-psyco-nopsyco-comparison.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_images/tutorial1-general.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_images/Q7-10m-noidx.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_images/compressed-select-cache-shuffle.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_images/compressed-select-nocache-shuffle-only.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_images/Q8-1g-noidx.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_images/seq-chunksize-15GB.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_images/Q8-1g-idx-optlevels.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_images/write-medium-psyco-nopsyco-comparison.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_images/Q8-1g-idx-compress.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_images/tutorial1-2-tableview.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_static/comment-close.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_static/down.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_static/down-pressed.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_static/plus.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_static/comment-bright.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_static/comment.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_static/icon-seealso.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_static/icon-note.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_static/up-pressed.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_static/icon-warning.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_static/file.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_static/ajax-loader.gif",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_static/favicon.ico",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_static/icon-todo.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_static/up.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_static/minus.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/html/_static/logo-pytables-small.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/sphinxext/ipython_console_highlighting.pyc",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/sphinxext/docscrape_sphinx.pyc",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/sphinxext/numpydoc.pyc",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/sphinxext/docscrape.pyc",
        "/tmp/vanessa/spack-stage/spack-stage-py-tables-3.3.0-qakg2odewimrjseywmy22nyxvmcrwyi7/spack-src/doc/sphinxext/__pycache__/ipython_console_highlighting.cpython-35.pyc"
    ],
    "total_files": 758
}