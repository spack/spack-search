{
    "matches": {
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/src/common/plugin.c": "/*****************************************************************************\\\n *  plugin.h - plugin architecture implementation.\n *****************************************************************************\n *  Copyright (C) 2002-2007 The Regents of the University of California.\n *  Copyright (C) 2008-2009 Lawrence Livermore National Security.\n *  Produced at Lawrence Livermore National Laboratory (cf, DISCLAIMER).\n *  Written by Jay Windley <jwindley@lnxi.com>.\n *  CODE-OCEC-09-009. All rights reserved.\n *  Portions Copyright (C) 2012 SchedMD LLC.\n *  Written by Danny Auble <da@schedmd.com>\n *\n *  This file is part of Slurm, a resource management program.\n *  For details, see <https://slurm.schedmd.com/>.\n *  Please also read the included file: DISCLAIMER.\n *\n *  Slurm is free software; you can redistribute it and/or modify it under\n *  the terms of the GNU General Public License as published by the Free\n *  Software Foundation; either version 2 of the License, or (at your option)\n *  any later version.\n *\n *  In addition, as a special exception, the copyright holders give permission\n *  to link the code of portions of this program with the OpenSSL library under\n *  certain conditions as described in each individual source file, and\n *  distribute linked combinations including the two. You must obey the GNU\n *  General Public License in all respects for all of the code used other than\n *  OpenSSL. If you modify file(s) with this exception, you may extend this\n *  exception to your version of the file(s), but you are not obligated to do\n *  so. If you do not wish to do so, delete this exception statement from your\n *  version.  If you delete this exception statement from all source files in\n *  the program, then also delete it here.\n *\n *  Slurm is distributed in the hope that it will be useful, but WITHOUT ANY\n *  WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n *  FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more\n *  details.\n *\n *  You should have received a copy of the GNU General Public License along\n *  with Slurm; if not, write to the Free Software Foundation, Inc.,\n *  51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA.\n\\*****************************************************************************/\n\n#include \"config.h\"\n\n#include <dlfcn.h>\n#include <errno.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <sys/stat.h>\n#include <sys/types.h>\n#include <unistd.h>\n\n#include \"src/common/xmalloc.h\"\n#include \"src/common/log.h\"\n#include \"src/common/plugrack.h\"\n#include \"src/common/strlcpy.h\"\n#include \"src/common/xstring.h\"\n#include \"src/common/slurm_protocol_api.h\"\n#include \"slurm/slurm_errno.h\"\n\nstrong_alias(plugin_get_syms,         slurm_plugin_get_syms);\nstrong_alias(plugin_load_and_link,    slurm_plugin_load_and_link);\nstrong_alias(plugin_strerror,         slurm_plugin_strerror);\nstrong_alias(plugin_unload,           slurm_plugin_unload);\n\n/* dlerror() on AIX sometimes fails, revert to strerror() as needed */\nstatic char *_dlerror(void)\n{\n\tint error_code = errno;\n\tchar *rc = dlerror();\n\n\tif ((rc == NULL) || (rc[0] == '\\0'))\n\t\trc = strerror(error_code);\n\n\treturn rc;\n}\n\nconst char * plugin_strerror(plugin_err_t e)\n{\n\tswitch (e) {\n\t\tcase EPLUGIN_SUCCESS:\n\t\t\treturn (\"Success\");\n\t\tcase EPLUGIN_NOTFOUND:\n\t\t\treturn (\"Plugin file not found\");\n\t\tcase EPLUGIN_ACCESS_ERROR:\n\t\t\treturn (\"Plugin access denied\");\n\t\tcase EPLUGIN_DLOPEN_FAILED:\n\t\t\treturn (\"Dlopen of plugin file failed\");\n\t\tcase EPLUGIN_INIT_FAILED:\n\t\t\treturn (\"Plugin init() callback failed\");\n\t\tcase EPLUGIN_MISSING_NAME:\n\t\t\treturn (\"Plugin name/type/version symbol missing\");\n\t\tcase EPLUGIN_MISSING_SYMBOL:\n\t\t\treturn (\"Plugin missing a required symbol use \"\n\t\t\t\t\"debug3 to see\");\n\t\tcase EPLUGIN_BAD_VERSION:\n\t\t\treturn (\"Incompatible plugin version\");\n\t}\n\treturn (\"Unknown error\");\n}\n\nint\nplugin_peek( const char *fq_path,\n\t\t\t char *plugin_type,\n\t\t\t const size_t type_len,\n\t\t\t uint32_t *plugin_version )\n{\n\tplugin_handle_t plug;\n\tchar *type;\n\tuint32_t *version;\n\n\tplug = dlopen( fq_path, RTLD_LAZY );\n\tif ( plug == NULL ) {\n\t\tdebug3( \"plugin_peek: dlopen(%s): %s\", fq_path, _dlerror() );\n\t\treturn SLURM_ERROR;\n\t}\n\tif ( ( type = dlsym( plug, PLUGIN_TYPE ) ) != NULL ) {\n\t\tif ( plugin_type != NULL ) {\n\t\t\tstrlcpy(plugin_type, type, type_len);\n\t\t}\n\t} else {\n\t\tdlclose( plug );\n\t\t/* could be vestigial library, don't treat as an error */\n\t\tverbose( \"%s: not a Slurm plugin\", fq_path );\n\t\treturn SLURM_ERROR;\n\t}\n\n\tversion = (uint32_t *) dlsym(plug, PLUGIN_VERSION);\n\tif (!version) {\n\t\tverbose(\"%s: plugin_version symbol not defined\", fq_path);\n\t} else if ((*version != SLURM_VERSION_NUMBER) && xstrcmp(type,\"spank\")){\n\t\t/* NOTE: We could alternatly test just the MAJOR.MINOR values */\n\t\tint plugin_major, plugin_minor, plugin_micro;\n\t\tplugin_major = SLURM_VERSION_MAJOR(*version);\n\t\tplugin_minor = SLURM_VERSION_MINOR(*version);\n\t\tplugin_micro = SLURM_VERSION_MICRO(*version);\n\t\tdlclose(plug);\n\t\tinfo(\"%s: Incompatible Slurm plugin version (%d.%02d.%d)\",\n\t\t     fq_path, plugin_major, plugin_minor, plugin_micro);\n\t\treturn SLURM_ERROR;\n\t}\n\n\tdlclose( plug );\n\treturn SLURM_SUCCESS;\n}\n\nplugin_err_t\nplugin_load_from_file(plugin_handle_t *p, const char *fq_path)\n{\n\tplugin_handle_t plug;\n\tint (*init)(void);\n\tuint32_t *version;\n\tchar *type = NULL;\n\n\t*p = PLUGIN_INVALID_HANDLE;\n\n\t/*\n\t *  Check for file existence and access permissions\n\t */\n\tif (access(fq_path, R_OK) < 0) {\n\t\tif (errno == ENOENT)\n\t\t\treturn EPLUGIN_NOTFOUND;\n\t\telse\n\t\t\treturn EPLUGIN_ACCESS_ERROR;\n\t}\n\n\t/*\n\t * Try to open the shared object.\n\t *\n\t * Use RTLD_LAZY to allow plugins to use symbols that may be\n\t * defined in only one slurm entity (e.g. srun and not slurmd),\n\t * when the use of that symbol is restricted to within the\n\t * entity from which it is available. (i.e. srun symbols are only\n\t * used in the context of srun, not slurmd.)\n\t *\n\t */\n\tplug = dlopen(fq_path, RTLD_LAZY);\n\tif (plug == NULL) {\n\t\terror(\"plugin_load_from_file: dlopen(%s): %s\",\n\t\t      fq_path,\n\t\t      _dlerror());\n\t\treturn EPLUGIN_DLOPEN_FAILED;\n\t}\n\n\t/* Now see if our required symbols are defined. */\n\tif ((dlsym(plug, PLUGIN_NAME) == NULL) ||\n\t    ((type = dlsym(plug, PLUGIN_TYPE)) == NULL)) {\n\t\tdlclose(plug);\n\t\treturn EPLUGIN_MISSING_NAME;\n\t}\n\n\tversion = (uint32_t *) dlsym(plug, PLUGIN_VERSION);\n\tif (!version) {\n\t\tverbose(\"%s: plugin_version symbol not defined\", fq_path);\n\t} else if ((*version != SLURM_VERSION_NUMBER) && xstrcmp(type,\"spank\")){\n\t\t/* NOTE: We could alternatly test just the MAJOR.MINOR values */\n\t\tint plugin_major, plugin_minor, plugin_micro;\n\t\tplugin_major = SLURM_VERSION_MAJOR(*version);\n\t\tplugin_minor = SLURM_VERSION_MINOR(*version);\n\t\tplugin_micro = SLURM_VERSION_MICRO(*version);\n\t\tdlclose(plug);\n\t\tinfo(\"%s: Incompatible Slurm plugin version (%d.%02d.%d)\",\n\t\t     fq_path, plugin_major, plugin_minor, plugin_micro);\n\t\treturn EPLUGIN_BAD_VERSION;\n\t}\n\n\t/*\n\t * Now call its init() function, if present.  If the function\n\t * returns nonzero, unload the plugin and signal an error.\n\t */\n\tif ((init = dlsym(plug, \"init\")) != NULL) {\n\t\tif ((*init)() != 0) {\n\t\t\tdlclose(plug);\n\t\t\treturn EPLUGIN_INIT_FAILED;\n\t\t}\n\t}\n\n\t*p = plug;\n\treturn EPLUGIN_SUCCESS;\n}\n\n/*\n * Load plugin and setup linking\n * IN type_name - name of plugin\n * IN n_syms - number of pointers in ptrs\n * IN names - pointer list of symbols to link\n * IN ptr - list of pointers to set with pointers given in names\n * RET opaque ptr to handler or PLUGIN_INVALID_HANDLE on error\n */\nplugin_handle_t\nplugin_load_and_link(const char *type_name, int n_syms,\n\t\t     const char *names[], void *ptrs[])\n{\n\tplugin_handle_t plug = PLUGIN_INVALID_HANDLE;\n\tstruct stat st;\n\tchar *head = NULL, *dir_array = NULL, *so_name = NULL;\n\tchar *file_name = NULL;\n\tint i = 0;\n\tplugin_err_t err = EPLUGIN_NOTFOUND;\n\n\tif (!type_name)\n\t\treturn plug;\n\tso_name = xstrdup_printf(\"%s.so\", type_name);\n\twhile (so_name[i]) {\n\t\tif (so_name[i] == '/')\n\t\t\tso_name[i] = '_';\n\t\ti++;\n\t}\n\tif (!(dir_array = slurm_get_plugin_dir())) {\n\t\terror(\"plugin_load_and_link: No plugin dir given\");\n\t\txfree(so_name);\n\t\treturn plug;\n\t}\n\n\thead = dir_array;\n\tfor (i = 0; ; i++) {\n\t\tbool got_colon = 0;\n\t\tif (dir_array[i] == ':') {\n\t\t\tdir_array[i] = '\\0';\n\t\t\tgot_colon = 1;\n\t\t} else if (dir_array[i] != '\\0')\n\t\t\tcontinue;\n\n\t\tfile_name = xstrdup_printf(\"%s/%s\", head, so_name);\n\t\tdebug3(\"Trying to load plugin %s\", file_name);\n\t\tif ((stat(file_name, &st) < 0) || (!S_ISREG(st.st_mode))) {\n\t\t\tdebug4(\"%s: Does not exist or not a regular file.\",\n\t\t\t       file_name);\n\t\t\txfree(file_name);\n\t\t\terr = EPLUGIN_NOTFOUND;\n\t\t} else {\n\t\t\tif ((err = plugin_load_from_file(&plug, file_name))\n\t\t\t   == EPLUGIN_SUCCESS) {\n\t\t\t\tif (plugin_get_syms(plug, n_syms,\n\t\t\t\t\t\t    names, ptrs) >= n_syms) {\n\t\t\t\t\tdebug3(\"Success.\");\n\t\t\t\t\txfree(file_name);\n\t\t\t\t\tbreak;\n\t\t\t\t} else {\n\t\t\t\t\t/*\n\t\t\t\t\t * Plugin loading failed part way\n\t\t\t\t\t * through loading, it is unknown what\n\t\t\t\t\t * actually happened but now process\n\t\t\t\t\t * memory is suspect and we are going to\n\t\t\t\t\t * abort since this should only ever\n\t\t\t\t\t * happen during development.\n\t\t\t\t\t */\n\t\t\t\t\tfatal(\"%s: Plugin loading failed due to missing symbols. Plugin is corrupted.\",\n\t\t\t\t\t      __func__);\n\t\t\t\t}\n\t\t\t} else\n\t\t\t\tplug = PLUGIN_INVALID_HANDLE;\n\t\t\txfree(file_name);\n\t\t}\n\n\t\tif (got_colon) {\n\t\t\thead = dir_array + i + 1;\n\t\t} else\n\t\t\tbreak;\n\t}\n\n\txfree(dir_array);\n\txfree(so_name);\n\terrno = err;\n\treturn plug;\n}\n/*\n * Must test plugin validity before doing dlopen() and dlsym()\n * operations because some implementations of these functions\n * crash if the library handle is not valid.\n */\n\nvoid\nplugin_unload( plugin_handle_t plug )\n{\n\tvoid (*fini)(void);\n\n\tif ( plug != PLUGIN_INVALID_HANDLE ) {\n\t\tif ( ( fini = dlsym( plug, \"fini\" ) ) != NULL ) {\n\t\t\t(*fini)();\n\t\t}\n#ifndef MEMORY_LEAK_DEBUG\n/**************************************************************************\\\n * To test for memory leaks, set MEMORY_LEAK_DEBUG to 1 using\n * \"configure --enable-memory-leak-debug\" then execute\n *\n * Note that without --enable-memory-leak-debug the daemon will\n * unload the shared objects at exit thus preventing valgrind\n * to display the stack where the eventual leaks may be.\n * It is always best to test with and without --enable-memory-leak-debug.\n\\**************************************************************************/\n\t\t(void) dlclose( plug );\n#endif\n\t}\n}\n\n\nvoid *\nplugin_get_sym( plugin_handle_t plug, const char *name )\n{\n\tif ( plug != PLUGIN_INVALID_HANDLE )\n\t\treturn dlsym( plug, name );\n\telse\n\t\treturn NULL;\n}\n\nconst char *\nplugin_get_name( plugin_handle_t plug )\n{\n\tif ( plug != PLUGIN_INVALID_HANDLE )\n\t\treturn (const char *) dlsym( plug, PLUGIN_NAME );\n\telse\n\t\treturn NULL;\n}\n\nconst char *\nplugin_get_type( plugin_handle_t plug )\n{\n\tif ( plug != PLUGIN_INVALID_HANDLE )\n\t\treturn (const char *) dlsym( plug, PLUGIN_TYPE );\n\telse\n\t\treturn NULL;\n}\n\nuint32_t\nplugin_get_version( plugin_handle_t plug )\n{\n\tuint32_t *ptr;\n\n\tif (plug == PLUGIN_INVALID_HANDLE)\n\t\treturn 0;\n\tptr = (uint32_t *) dlsym(plug, PLUGIN_VERSION);\n\treturn ptr ? *ptr : 0;\n}\n\nint\nplugin_get_syms( plugin_handle_t plug,\n\t\t int n_syms,\n\t\t const char *names[],\n\t\t void *ptrs[] )\n{\n\tint i, count;\n\n\tcount = 0;\n\tfor ( i = 0; i < n_syms; ++i ) {\n\t\tptrs[ i ] = dlsym( plug, names[ i ] );\n\t\tif ( ptrs[ i ] )\n\t\t\t++count;\n\t\telse\n\t\t\tdebug3(\"Couldn't find sym '%s' in the plugin\",\n\t\t\t       names[ i ]);\n\t}\n\n\treturn count;\n}\n\n/*\n * Create a priority context\n */\nextern plugin_context_t *plugin_context_create(\n\tconst char *plugin_type, const char *uler_type,\n\tvoid *ptrs[], const char *names[], size_t names_size)\n{\n\tplugin_context_t *c;\n\tint n_names;\n\n\tif (!uler_type) {\n\t\tdebug3(\"plugin_context_create: no uler type\");\n\t\treturn NULL;\n\t} else if (!plugin_type) {\n\t\tdebug3(\"plugin_context_create: no plugin type\");\n\t\treturn NULL;\n\t} else if (!names) {\n\t\terror(\"plugin_context_create: no symbols given for plugin %s\",\n\t\t      plugin_type);\n\t\treturn NULL;\n\t} else if (!ptrs) {\n\t\terror(\"plugin_context_create: no ptrs given for plugin %s\",\n\t\t      plugin_type);\n\t\treturn NULL;\n\t}\n\n\tc = xmalloc(sizeof(plugin_context_t));\n\tc->type = xstrdup(uler_type);\n\tc->cur_plugin = PLUGIN_INVALID_HANDLE;\n\n\tn_names = names_size / sizeof(char *);\n\n\t/* Find the correct plugin. */\n\tc->cur_plugin = plugin_load_and_link(c->type, n_names, names, ptrs);\n\tif (c->cur_plugin != PLUGIN_INVALID_HANDLE)\n\t\treturn c;\n\n\tif (errno != EPLUGIN_NOTFOUND) {\n\t\terror(\"Couldn't load specified plugin name for %s: %s\",\n\t\t      c->type, plugin_strerror(errno));\n\t\tgoto fail;\n\t}\n\n\terror(\"Couldn't find the specified plugin name for %s \"\n\t      \"looking at all files\",\n\t      c->type);\n\n\t/* Get plugin list. */\n\tif (!c->plugin_list) {\n\t\tchar *plugin_dir;\n\t\tc->plugin_list = plugrack_create(plugin_type);\n\t\tplugin_dir = slurm_get_plugin_dir();\n\t\tplugrack_read_dir(c->plugin_list, plugin_dir);\n\t\txfree(plugin_dir);\n\t}\n\n\tc->cur_plugin = plugrack_use_by_type(c->plugin_list, c->type);\n\tif (c->cur_plugin == PLUGIN_INVALID_HANDLE) {\n\t\terror(\"cannot find %s plugin for %s\", plugin_type, c->type);\n\t\tgoto fail;\n\t}\n\n\t/* Dereference the API. */\n\tif (plugin_get_syms(c->cur_plugin, n_names, names, ptrs) < n_names) {\n\t\terror(\"incomplete %s plugin detected\", plugin_type);\n\t\tgoto fail;\n\t}\n\n\treturn c;\nfail:\n\tplugin_context_destroy(c);\n\treturn NULL;\n}\n\n/*\n * Destroy a context\n */\nextern int plugin_context_destroy(plugin_context_t *c)\n{\n\tint rc = SLURM_SUCCESS;\n\t/*\n\t * Must check return code here because plugins might still\n\t * be loaded and active.\n\t */\n\tif (c->plugin_list) {\n\t\tif (plugrack_destroy(c->plugin_list) != SLURM_SUCCESS)\n\t\t\trc = SLURM_ERROR;\n\t} else\n\t\tplugin_unload(c->cur_plugin);\n\n\txfree(c->type);\n\txfree(c);\n\n\treturn rc;\n}\n\n/*\n * Return a list of plugin names that match the given type.\n *\n * IN plugin_type - Type of plugin to search for in the plugin_dir.\n * RET list of plugin names, NULL if none found.\n */\nextern List plugin_get_plugins_of_type(char *plugin_type)\n{\n\tList plugin_names = NULL;\n\tchar *plugin_dir = NULL, *dir = NULL, *save_ptr = NULL;\n\tchar *type_under = NULL, *type_slash = NULL;\n\tDIR *dirp;\n\tstruct dirent *e;\n\tint len;\n\n\tif (!(plugin_dir = slurm_get_plugin_dir())) {\n\t\terror(\"%s: No plugin dir given\", __func__);\n\t\tgoto done;\n\t}\n\n\ttype_under = xstrdup_printf(\"%s_\", plugin_type);\n\ttype_slash = xstrdup_printf(\"%s/\", plugin_type);\n\n\tdir = strtok_r(plugin_dir, \":\", &save_ptr);\n\twhile (dir) {\n\t\t/* Open the directory. */\n\t\tif (!(dirp = opendir(dir))) {\n\t\t\terror(\"cannot open plugin directory %s\", dir);\n\t\t\tgoto done;\n\t\t}\n\n\t\twhile (1) {\n\t\t\tchar full_name[128];\n\n\t\t\tif (!(e = readdir( dirp )))\n\t\t\t\tbreak;\n\t\t\t/* Check only files with \"plugintype_\" in them. */\n\t\t\tif (xstrncmp(e->d_name, type_under, strlen(type_under)))\n\t\t\t\tcontinue;\n\n\t\t\tlen = strlen(e->d_name);\n\t\t\tlen -= 3;\n\t\t\t/* Check only shared object files */\n\t\t\tif (xstrcmp(e->d_name+len, \".so\"))\n\t\t\t\tcontinue;\n\t\t\t/* add one for the / */\n\t\t\tlen++;\n\t\t\txassert(len < sizeof(full_name));\n\t\t\tsnprintf(full_name, len, \"%s%s\",\n\t\t\t\t type_slash, e->d_name + strlen(type_slash));\n\n\t\t\tif (!plugin_names)\n\t\t\t\tplugin_names = list_create(xfree_ptr);\n\t\t\tif (!list_find_first(plugin_names,\n\t\t\t\t\t     slurm_find_char_in_list,\n\t\t\t\t\t     full_name))\n\t\t\t\tlist_append(plugin_names, xstrdup(full_name));\n\t\t}\n\t\tclosedir(dirp);\n\n\t\tdir = strtok_r(NULL, \":\", &save_ptr);\n\t}\n\ndone:\n\txfree(plugin_dir);\n\txfree(type_under);\n\txfree(type_slash);\n\n\treturn plugin_names;\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/src/common/gpu.c": "/*****************************************************************************\\\n *  gpu.c - driver for gpu plugin\n *****************************************************************************\n *  Copyright (C) 2019 SchedMD LLC\n *  Written by Danny Auble <da@schedmd.com>\n *\n *  This file is part of Slurm, a resource management program.\n *  For details, see <https://slurm.schedmd.com/>.\n *  Please also read the included file: DISCLAIMER.\n *\n *  Slurm is free software; you can redistribute it and/or modify it under\n *  the terms of the GNU General Public License as published by the Free\n *  Software Foundation; either version 2 of the License, or (at your option)\n *  any later version.\n *\n *  In addition, as a special exception, the copyright holders give permission\n *  to link the code of portions of this program with the OpenSSL library under\n *  certain conditions as described in each individual source file, and\n *  distribute linked combinations including the two. You must obey the GNU\n *  General Public License in all respects for all of the code used other than\n *  OpenSSL. If you modify file(s) with this exception, you may extend this\n *  exception to your version of the file(s), but you are not obligated to do\n *  so. If you do not wish to do so, delete this exception statement from your\n *  version.  If you delete this exception statement from all source files in\n *  the program, then also delete it here.\n *\n *  Slurm is distributed in the hope that it will be useful, but WITHOUT ANY\n *  WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n *  FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more\n *  details.\n *\n *  You should have received a copy of the GNU General Public License along\n *  with Slurm; if not, write to the Free Software Foundation, Inc.,\n *  51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA.\n\\*****************************************************************************/\n\n#include <dlfcn.h>\n\n#include \"src/common/gpu.h\"\n#include \"src/common/plugin.h\"\n\n/* Gres symbols provided by the plugin */\ntypedef struct slurm_ops {\n\tvoid    (*reconfig)\t\t(void);\n\tList\t(*get_system_gpu_list) \t(node_config_load_t *node_conf);\n\tvoid\t(*step_hardware_init)\t(bitstr_t *usable_gpus,\n\t\t\t\t\t char *tres_freq);\n\tvoid\t(*step_hardware_fini)\t(void);\n\tchar   *(*test_cpu_conv)\t(char *cpu_range);\n} slurm_ops_t;\n\n/*\n * These strings must be kept in the same order as the fields\n * declared for slurm_ops_t.\n */\nstatic const char *syms[] = {\n\t\"gpu_p_reconfig\",\n\t\"gpu_p_get_system_gpu_list\",\n\t\"gpu_p_step_hardware_init\",\n\t\"gpu_p_step_hardware_fini\",\n\t\"gpu_p_test_cpu_conv\",\n};\n\n/* Local variables */\nstatic slurm_ops_t ops;\nstatic plugin_context_t *g_context = NULL;\nstatic pthread_mutex_t g_context_lock =\tPTHREAD_MUTEX_INITIALIZER;\nstatic bool init_run = false;\n\n/*\n *  Common function to dlopen() the appropriate gpu libraries, and\n *   report back type needed.\n */\nstatic char *_get_gpu_type(void)\n{\n\t/*\n\t *  Here we are dlopening the gpu .so to verify it exists on this node.\n\t */\n\tuint32_t autodetect_types = gres_get_autodetect_types();\n\n\tif (autodetect_types & GRES_AUTODETECT_NVML) {\n#ifdef HAVE_NVML\n\t\tif (!dlopen(\"libnvidia-ml.so\", RTLD_NOW | RTLD_GLOBAL))\n\t\t\tfatal(\"We were configured with nvml functionality, but that lib wasn't found on the system.\");\n\t\telse\n\t\t\treturn \"gpu/nvml\";\n#else\n\t\tfatal(\"We were configured to autodetect nvml functionality, but we weren't able to find that lib when Slurm was configured.\");\n#endif\n\t} else if (autodetect_types & GRES_AUTODETECT_RSMI) {\n#ifdef HAVE_RSMI\n\t\tif (!dlopen(\"librocm_smi64.so\", RTLD_NOW | RTLD_GLOBAL))\n\t\t\tfatal(\"Configured with rsmi, but that lib wasn't found.\");\n\t\telse\n\t\t\treturn \"gpu/rsmi\";\n#else\n\t\tfatal(\"Configured with rsmi, but rsmi isn't enabled during the build.\");\n#endif\n\t}\n\treturn \"gpu/generic\";\n}\n\n\n/*\n * Initialize the GRES plugins.\n *\n * Returns a Slurm errno.\n */\nextern int gpu_plugin_init(void)\n{\n\tint retval = SLURM_SUCCESS;\n\tchar *plugin_type = \"gpu\";\n\tchar *type = NULL;\n\n\tif (init_run && g_context)\n\t\treturn retval;\n\n\tslurm_mutex_lock(&g_context_lock);\n\n\tif (g_context)\n\t\tgoto done;\n\n\ttype = _get_gpu_type();\n\n\tg_context = plugin_context_create(\n\t\tplugin_type, type, (void **)&ops, syms, sizeof(syms));\n\n\tif (!g_context) {\n\t\terror(\"cannot create %s context for %s\", plugin_type, type);\n\t\tretval = SLURM_ERROR;\n\t\tgoto done;\n\t}\n\tinit_run = true;\n\ndone:\n\tslurm_mutex_unlock(&g_context_lock);\n\n\treturn retval;\n}\n\nextern int gpu_plugin_fini(void)\n{\n\tint rc;\n\n\tif (!g_context)\n\t\treturn SLURM_SUCCESS;\n\n\tslurm_mutex_lock(&g_context_lock);\n\tinit_run = false;\n\trc = plugin_context_destroy(g_context);\n\tg_context = NULL;\n\tslurm_mutex_unlock(&g_context_lock);\n\n\treturn rc;\n}\n\nextern void gpu_g_reconfig(void)\n{\n\tif (gpu_plugin_init() < 0)\n\t\treturn;\n\t(*(ops.reconfig))();\n}\n\nextern List gpu_g_get_system_gpu_list(node_config_load_t *node_conf)\n{\n\tif (gpu_plugin_init() < 0)\n\t\treturn NULL;\n\n\treturn (*(ops.get_system_gpu_list))(node_conf);\n}\n\nextern void gpu_g_step_hardware_init(bitstr_t *usable_gpus, char *tres_freq)\n{\n\tif (gpu_plugin_init() < 0)\n\t\treturn;\n\t(*(ops.step_hardware_init))(usable_gpus, tres_freq);\n}\n\nextern void gpu_g_step_hardware_fini(void)\n{\n\tif (gpu_plugin_init() < 0)\n\t\treturn;\n\t(*(ops.step_hardware_fini))();\n}\n\nextern char *gpu_g_test_cpu_conv(char *cpu_range)\n{\n\tif (gpu_plugin_init() < 0)\n\t\treturn NULL;\n\treturn (*(ops.test_cpu_conv))(cpu_range);\n\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/src/common/plugstack.c": "/*****************************************************************************\\\n *  plugstack.c -- stackable plugin architecture for node job kontrol (SPANK)\n *****************************************************************************\n *  Copyright (C) 2005-2007 The Regents of the University of California.\n *  Copyright (C) 2008-2010 Lawrence Livermore National Security.\n *  Produced at Lawrence Livermore National Laboratory (cf, DISCLAIMER).\n *  CODE-OCEC-09-009. All rights reserved.\n *\n *  This file is part of Slurm, a resource management program.\n *  For details, see <https://slurm.schedmd.com/>.\n *  Please also read the included file: DISCLAIMER.\n *\n *  Slurm is free software; you can redistribute it and/or modify it under\n *  the terms of the GNU General Public License as published by the Free\n *  Software Foundation; either version 2 of the License, or (at your option)\n *  any later version.\n *\n *  In addition, as a special exception, the copyright holders give permission\n *  to link the code of portions of this program with the OpenSSL library under\n *  certain conditions as described in each individual source file, and\n *  distribute linked combinations including the two. You must obey the GNU\n *  General Public License in all respects for all of the code used other than\n *  OpenSSL. If you modify file(s) with this exception, you may extend this\n *  exception to your version of the file(s), but you are not obligated to do\n *  so. If you do not wish to do so, delete this exception statement from your\n *  version.  If you delete this exception statement from all source files in\n *  the program, then also delete it here.\n *\n *  Slurm is distributed in the hope that it will be useful, but WITHOUT ANY\n *  WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n *  FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more\n *  details.\n *\n *  You should have received a copy of the GNU General Public License along\n *  with Slurm; if not, write to the Free Software Foundation, Inc.,\n *  51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA.\n\\*****************************************************************************/\n\n#define _GNU_SOURCE\n\n#include \"config.h\"\n\n#include <ctype.h>\n#include <dlfcn.h>\n#include <glob.h>\n#include <libgen.h>\n#include <stdlib.h>\n#include <string.h>\n\n#include \"src/common/plugin.h\"\n#include \"src/common/xmalloc.h\"\n#include \"src/common/xstring.h\"\n#include \"src/common/xassert.h\"\n#include \"src/common/strlcpy.h\"\n#include \"src/common/read_config.h\"\n#include \"src/common/plugstack.h\"\n#include \"src/common/optz.h\"\n#include \"src/common/job_options.h\"\n#include \"src/common/env.h\"\n\n#include \"src/slurmd/slurmstepd/slurmstepd_job.h\"\n\n#include \"slurm/spank.h\"\n\n#define REQUIRED \"required\"\n#define OPTIONAL \"optional\"\n#define INCLUDE  \"include\"\n\nstruct spank_plugin_operations {\n\tspank_f *init;\n\tspank_f *job_prolog;\n\tspank_f *init_post_opt;\n\tspank_f *local_user_init;\n\tspank_f *user_init;\n\tspank_f *task_init_privileged;\n\tspank_f *user_task_init;\n\tspank_f *task_post_fork;\n\tspank_f *task_exit;\n\tspank_f *job_epilog;\n\tspank_f *slurmd_exit;\n\tspank_f *exit;\n};\n\nconst int n_spank_syms = 12;\nconst char *spank_syms[] = {\n\t\"slurm_spank_init\",\n\t\"slurm_spank_job_prolog\",\n\t\"slurm_spank_init_post_opt\",\n\t\"slurm_spank_local_user_init\",\n\t\"slurm_spank_user_init\",\n\t\"slurm_spank_task_init_privileged\",\n\t\"slurm_spank_task_init\",\n\t\"slurm_spank_task_post_fork\",\n\t\"slurm_spank_task_exit\",\n\t\"slurm_spank_job_epilog\",\n\t\"slurm_spank_slurmd_exit\",\n\t\"slurm_spank_exit\"\n};\n\nstruct spank_plugin {\n\tconst char *name;\n\tchar *fq_path;\n\tplugin_handle_t plugin;\n\tbool required;\n\tint ac;\n\tchar **argv;\n\tstruct spank_plugin_operations ops;\n\tstruct spank_option *opts;\n\tstruct spank_stack *stack;\n};\n\n/*\n *  SPANK Plugin options\n */\n\nstruct spank_plugin_opt {\n\tstruct spank_option *opt;   /* Copy of plugin option info           */\n\tstruct spank_plugin *plugin;/* Link back to plugin structure        */\n\tint optval;                 /* Globally unique value                */\n\tint found:1;                /* 1 if option was found, 0 otherwise   */\n\tint disabled:1;             /* 1 if option is cached but disabled   */\n\tchar *optarg;               /* Option argument.                     */\n\tbool set;                   /* true if argument is set              */\n\tbool set_by_env;            /* true if argument is set by environ   */\n};\n\n/*\n *  SPANK plugin context type (local, remote, allocator)\n */\nenum spank_context_type {\n\tS_TYPE_NONE,\n\tS_TYPE_LOCAL,           /* LOCAL == srun              */\n\tS_TYPE_REMOTE,          /* REMOTE == slurmstepd       */\n\tS_TYPE_ALLOCATOR,       /* ALLOCATOR == sbatch/salloc */\n\tS_TYPE_SLURMD,          /* SLURMD == slurmd           */\n\tS_TYPE_JOB_SCRIPT,      /* JOB_SCRIPT == prolog/epilog*/\n};\n\n/*\n *  SPANK plugin hook types:\n */\ntypedef enum step_fn {\n\tSPANK_INIT = 0,\n\tSPANK_JOB_PROLOG = 2,\n\tSPANK_INIT_POST_OPT,\n\tLOCAL_USER_INIT,\n\tSTEP_USER_INIT,\n\tSTEP_TASK_INIT_PRIV,\n\tSTEP_USER_TASK_INIT,\n\tSTEP_TASK_POST_FORK,\n\tSTEP_TASK_EXIT,\n\tSPANK_JOB_EPILOG,\n\tSPANK_SLURMD_EXIT,\n\tSPANK_EXIT\n} step_fn_t;\n\n/*\n *  Job information in prolog/epilog context:\n */\nstruct job_script_info {\n\tuint32_t  jobid;\n\tuid_t     uid;\n\tgid_t gid;\n};\n\nstruct spank_handle {\n#   define SPANK_MAGIC 0x00a5a500\n\tint                  magic;  /* Magic identifier to ensure validity. */\n\tstruct spank_plugin *plugin; /* Current plugin using handle          */\n\tstep_fn_t            phase;  /* Which spank fn are we called from?   */\n\tvoid               * job;    /* Reference to current srun|slurmd job */\n\tstepd_step_task_info_t * task;   /* Reference to current\n\t\t\t\t\t      * task (if valid) */\n\tstruct spank_stack  *stack;  /* Reference to the current plugin stack*/\n};\n\n/*\n *  SPANK stack. The stack of loaded plugins and associated state.\n */\nstruct spank_stack {\n\tenum spank_context_type type;/*  Type of context for this stack      */\n\tList plugin_list;\t     /*  Stack of spank plugins              */\n\tList option_cache;           /*  Cache of plugin options in this ctx */\n\tint  spank_optval;           /*  optvalue for next plugin option     */\n\tconst char * plugin_path;    /*  default path to search for plugins  */\n};\n\n/*\n *  The global spank plugin stack:\n */\nstatic struct spank_stack *global_spank_stack = NULL;\n\n/*\n *  Forward declarations\n */\nstatic int _spank_plugin_options_cache(struct spank_plugin *p);\nstatic int _spank_stack_load (struct spank_stack *stack, const char *file);\nstatic void _spank_plugin_destroy (struct spank_plugin *);\nstatic void _spank_plugin_opt_destroy (struct spank_plugin_opt *);\nstatic int spank_stack_get_remote_options(struct spank_stack *, job_options_t);\nstatic int spank_stack_get_remote_options_env (struct spank_stack *, char **);\nstatic int spank_stack_set_remote_options_env (struct spank_stack * stack);\nstatic int dyn_spank_set_job_env (const char *var, const char *val, int ovwt);\nstatic char *_opt_env_name(struct spank_plugin_opt *p, char *buf, size_t siz);\n\nstatic void spank_stack_destroy (struct spank_stack *stack)\n{\n\tFREE_NULL_LIST (stack->plugin_list);\n\tFREE_NULL_LIST (stack->option_cache);\n\txfree (stack->plugin_path);\n\txfree (stack);\n}\n\nstatic struct spank_stack *\nspank_stack_create (const char *file, enum spank_context_type type)\n{\n\tslurm_ctl_conf_t *conf;\n\tstruct spank_stack *stack = xmalloc (sizeof (*stack));\n\n\tconf = slurm_conf_lock();\n\tstack->plugin_path = xstrdup (conf->plugindir);\n\tslurm_conf_unlock();\n\n\tstack->type = type;\n\tstack->spank_optval = 0xfff;\n\tstack->plugin_list =\n\t\tlist_create ((ListDelF) _spank_plugin_destroy);\n\tstack->option_cache =\n\t\tlist_create ((ListDelF) _spank_plugin_opt_destroy);\n\n\tif (_spank_stack_load (stack, file) < 0) {\n\t\tspank_stack_destroy (stack);\n\t\treturn (NULL);\n\t}\n\n\treturn (stack);\n}\n\nstatic List get_global_option_cache (void)\n{\n\tif (global_spank_stack)\n\t\treturn (global_spank_stack->option_cache);\n\telse\n\t\treturn (NULL);\n}\n\n\nstatic int plugin_in_list (List l, struct spank_plugin *sp)\n{\n\tint rc = 0;\n\tstruct spank_plugin *p;\n\tListIterator i = list_iterator_create (l);\n\twhile ((p = list_next (i))) {\n\t\tif (p->fq_path == sp->fq_path) {\n\t\t\trc = 1;\n\t\t\tbreak;\n\t\t}\n\t}\n\tlist_iterator_destroy (i);\n\treturn (rc);\n}\n\nstatic void _argv_append(char ***argv, int ac, const char *newarg)\n{\n\t*argv = xrealloc(*argv, (++ac + 1) * sizeof(char *));\n\t(*argv)[ac] = NULL;\n\t(*argv)[ac - 1] = xstrdup(newarg);\n\treturn;\n}\n\ntypedef enum {\n   CF_ERROR = 0,\n   CF_OPTIONAL,\n   CF_REQUIRED,\n   CF_INCLUDE,\n} cf_line_t;\n\nstatic cf_line_t _plugin_stack_line_type (const char *str)\n{\n\tif (xstrcmp(str, REQUIRED) == 0)\n\t\treturn (CF_REQUIRED);\n\telse if (xstrcmp(str, OPTIONAL) == 0)\n\t\treturn (CF_OPTIONAL);\n\telse if (xstrcmp(str, INCLUDE) == 0)\n\t\treturn (CF_INCLUDE);\n\telse {\n\t\terror(\"spank: Invalid option \\\"%s\\\". Must be %s, %s or %s\",\n\t\t     str, REQUIRED, OPTIONAL, INCLUDE);\n\t\treturn (CF_ERROR);\n\t}\n}\n\n\nstatic int\n_plugin_stack_parse_line(char *line, char **plugin, int *acp, char ***argv,\n\t\t\t cf_line_t * type)\n{\n\tint ac;\n\tconst char *separators = \" \\t\\n\";\n\tchar *path;\n\tchar *option;\n\tchar *s;\n\tchar **av;\n\tchar *sp;\n\n\t*plugin = NULL;\n\t*argv = NULL;\n\t*acp = 0;\n\n\t/* Nullify any comments\n\t */\n\tif ((s = strchr(line, '#')))\n\t\t*s = '\\0';\n\n\tif (!(option = strtok_r(line, separators, &sp)))\n\t\treturn (0);\n\n\tif (((*type) = _plugin_stack_line_type(option)) == CF_ERROR)\n\t\treturn (-1);\n\n\tif (!(path = strtok_r(NULL, separators, &sp)))\n\t\treturn (-1);\n\n\tac = 0;\n\tav = NULL;\n\n\twhile ((s = strtok_r(NULL, separators, &sp)))\n\t\t_argv_append(&av, ac++, s);\n\n\t*plugin = xstrdup(path);\n\t*argv = av;\n\t*acp = ac;\n\n\treturn (0);\n}\n\nstatic struct spank_plugin *_spank_plugin_create(struct spank_stack *stack,\n\t\t\t\t\t\t char *path, int ac,\n\t\t\t\t\t\t char **av, bool required)\n{\n\tstruct spank_plugin *plugin;\n\tplugin_handle_t p;\n\tplugin_err_t e;\n\tstruct spank_plugin_operations ops;\n\n\tif ((e = plugin_load_from_file(&p, path)) != EPLUGIN_SUCCESS) {\n\t\terror (\"spank: %s: %s\", path, plugin_strerror(e));\n\t\treturn NULL;\n\t}\n\n\tif (plugin_get_syms(p, n_spank_syms, spank_syms, (void **)&ops) == 0) {\n\t\terror(\"spank: \\\"%s\\\" exports 0 symbols\", path);\n\t\treturn NULL;\n\t}\n\n\tplugin = xmalloc(sizeof(struct spank_plugin));\n\n\tplugin->fq_path = path;\t/* fq_path is xstrdup'd in *process_line */\n\tplugin->plugin = p;\n\tplugin->name = plugin_get_name(p);\t/* no need to dup */\n\tplugin->required = required;\n\tplugin->ac = ac;\n\tplugin->argv = av;\n\tplugin->ops = ops;\n\tplugin->stack = stack;\n\n\t/*\n\t *  Do not load static plugin options table in allocator context.\n\t */\n\tif (stack->type != S_TYPE_ALLOCATOR)\n\t\tplugin->opts = plugin_get_sym(p, \"spank_options\");\n\n\treturn (plugin);\n}\n\nvoid _spank_plugin_destroy(struct spank_plugin *sp)\n{\n\tif (sp == NULL)\n\t\treturn;\n\n\txfree(sp->fq_path);\n\n\t/* No need to free \"name\" it was defined within plugin */\n\tsp->name = NULL;\n\n\tplugin_unload(sp->plugin);\n\tsp->plugin = NULL;\n\tif (sp->argv) {\n\t\tint i;\n\t\tfor (i = 0; sp->argv[i]; i++)\n\t\t\txfree(sp->argv[i]);\n\t\txfree(sp->argv);\n\t}\n\txfree(sp);\n\treturn;\n}\n\nstatic char *\n_spank_plugin_find (const char *path, const char *file)\n{\n\tchar dir [4096];\n\tchar *p, *entry;\n\tint pathlen = strlen (path);\n\n\tif (strlcpy(dir, path, sizeof (dir)) > sizeof (dir))\n\t\treturn (NULL);\n\n\t/*\n\t * Ensure PATH ends with a :\n\t */\n\tif (dir[pathlen - 1] != ':') {\n\t\tdir[pathlen] = ':';\n\t\tdir[pathlen+1] = '\\0';\n\t}\n\n\tentry = dir;\n\twhile ((p = strchr(entry, ':'))) {\n\t\tchar *fq_path;\n\t\t*(p++) = '\\0';\n\n\t\tfq_path = xstrdup (entry);\n\t\tif (entry [strlen(entry) - 1] != '/')\n\t\t\txstrcatchar (fq_path, '/');\n\t\txstrcat (fq_path, file);\n\n\t\tif (plugin_peek (fq_path, NULL, 0, NULL) != SLURM_ERROR)\n\t\t\treturn (fq_path);\n\n\t\txfree (fq_path);\n\t\tentry = p;\n\t}\n\n\treturn (NULL);\n}\n\nstatic int _spank_conf_include (struct spank_stack *,\n\tconst char *, int, const char *);\n\nstatic int\nspank_stack_plugin_valid_for_context (struct spank_stack *stack,\n\tstruct spank_plugin *p)\n{\n\tswitch (stack->type) {\n\tcase S_TYPE_JOB_SCRIPT:\n\t\tif (p->ops.job_prolog || p->ops.job_epilog)\n\t\t\treturn (1);\n\t\tbreak;\n\tcase S_TYPE_SLURMD:\n\t\tif (p->ops.slurmd_exit)\n\t\t\treturn (1);\n\t\tbreak;\n\tcase S_TYPE_LOCAL:\n\tcase S_TYPE_ALLOCATOR:\n\tcase S_TYPE_REMOTE:\n\t\t/*\n\t\t *  For backwards compatibility: All plugins were\n\t\t *   always loaded in these contexts, so continue\n\t\t *   to do so\n\t\t */\n\t\treturn (1);\n\tdefault:\n\t\treturn (0);\n\t}\n\treturn (0);\n}\n\nstatic int\n_spank_stack_process_line(struct spank_stack *stack,\n\tconst char *file, int line, char *buf)\n{\n\tchar **argv;\n\tint ac;\n\tchar *path;\n\tcf_line_t type = CF_REQUIRED;\n\tbool required;\n\n\tstruct spank_plugin *p;\n\n\tif (_plugin_stack_parse_line(buf, &path, &ac, &argv, &type) < 0) {\n\t\terror(\"spank: %s:%d: Invalid line. Ignoring.\", file, line);\n\t\treturn (0);\n\t}\n\n       if (type == CF_INCLUDE) {\n\t       int rc = _spank_conf_include (stack, file, line, path);\n\t       xfree (path);\n\t       return (rc);\n       }\n\n\tif (path == NULL)\t/* No plugin listed on this line */\n\t\treturn (0);\n\n\tif (path[0] != '/') {\n\t\tchar *f;\n\n\t\tif ((f = _spank_plugin_find (stack->plugin_path, path))) {\n\t\t\txfree (path);\n\t\t\tpath = f;\n\t\t}\n\t}\n\n\trequired = (type == CF_REQUIRED);\n\tif (!(p = _spank_plugin_create(stack, path, ac, argv, required))) {\n\t\tif (required)\n\t\t\terror (\"spank: %s:%d:\"\n\t\t\t       \" Failed to load plugin %s. Aborting.\",\n\t\t\t       file, line, path);\n\t\telse\n\t\t\tverbose (\"spank: %s:%d:\"\n\t\t\t\t \"Failed to load optional plugin %s. Ignored.\",\n\t\t\t\t file, line, path);\n\t\treturn (required ? -1 : 0);\n\t}\n\n\tif (plugin_in_list (stack->plugin_list, p)) {\n\t\terror (\"spank: %s: cowardly refusing to load a second time\",\n\t\t\tp->fq_path);\n\t\t_spank_plugin_destroy (p);\n\t\treturn (0);\n\t}\n\n\tif (!spank_stack_plugin_valid_for_context (stack, p)) {\n\t\tdebug2 (\"spank: %s: no callbacks in this context\", p->fq_path);\n\t\t_spank_plugin_destroy (p);\n\t\treturn (0);\n\t}\n\n\tdebug (\"spank: %s:%d: Loaded plugin %s\",\n\t\t\tfile, line, xbasename (p->fq_path));\n\n\tlist_append (stack->plugin_list, p);\n\t_spank_plugin_options_cache(p);\n\n\treturn (0);\n}\n\nstatic int _spank_stack_load(struct spank_stack *stack, const char *path)\n{\n\tint rc = 0;\n\tint line;\n\tchar buf[4096];\n\tint fd;\n\tFILE *fp;\n\n\tdebug (\"spank: opening plugin stack %s\", path);\n\n\t/*\n\t *  Try to open plugstack.conf. A missing config file is not an\n\t *   error, but is equivalent to an empty file.\n\t */\n\tif ((fd = open(path, O_RDONLY | O_CLOEXEC)) < 0 ||\n\t    (fp = fdopen(fd, \"r\")) == NULL) {\n\t\tif (errno == ENOENT)\n\t\t\treturn (0);\n\t\terror(\"spank: Failed to open %s: %m\", path);\n\t\treturn (-1);\n\t}\n\n\tline = 1;\n\twhile (fgets(buf, sizeof(buf), fp)) {\n\t\trc = _spank_stack_process_line(stack, path, line, buf);\n\t\tif (rc < 0)\n\t\t\tbreak;\n\t\tline++;\n\t}\n\n\tfclose(fp);\n\treturn (rc);\n}\n\nstatic int _spank_conf_include (struct spank_stack *stack,\n\t\tconst char *file, int lineno, const char *pattern)\n{\n\tint rc = 0;\n\tglob_t gl;\n\tsize_t i;\n\tchar *copy = NULL;\n\n\tif (pattern == NULL) {\n\t\terror (\"%s: %d: Invalid include directive\", file, lineno);\n\t\treturn (SLURM_ERROR);\n\t}\n\n\tif (pattern[0] != '/') {\n\t\tchar *dirc = xstrdup (file);\n\t\tchar *dname = dirname (dirc);\n\n\t\tif (dname != NULL)  {\n\t\t\txstrfmtcat (copy, \"%s/%s\", dname, pattern);\n\t\t\tpattern = copy;\n\t\t}\n\t\txfree (dirc);\n\t}\n\n\tdebug (\"%s: %d: include \\\"%s\\\"\", file, lineno, pattern);\n\n\trc = glob (pattern, 0, NULL, &gl);\n\tswitch (rc) {\n\t  case 0:\n\t  \tfor (i = 0; i < gl.gl_pathc; i++) {\n\t\t\trc = _spank_stack_load (stack, gl.gl_pathv[i]);\n\t\t\tif (rc < 0)\n\t\t\t\tbreak;\n\t\t}\n\t  \tbreak;\n\t  case GLOB_NOMATCH:\n\t\tbreak;\n\t  case GLOB_NOSPACE:\n\t\terrno = ENOMEM;\n\t\tbreak;\n\t  case GLOB_ABORTED:\n\t\tverbose (\"%s:%d: cannot read dir %s: %m\",\n\t\t\tfile, lineno, pattern);\n\t\tbreak;\n\t  default:\n\t\terror (\"Unknown glob(3) return code = %d\", rc);\n\t\tbreak;\n\t}\n\n\txfree (copy);\n\tglobfree (&gl);\n\treturn (rc);\n}\n\nstatic int\n_spank_handle_init(struct spank_handle *spank, struct spank_stack *stack,\n\t\tvoid * arg, int taskid, step_fn_t fn)\n{\n\tmemset(spank, 0, sizeof(*spank));\n\tspank->magic = SPANK_MAGIC;\n\tspank->plugin = NULL;\n\n\tspank->phase = fn;\n\tspank->stack = stack;\n\n\tif (arg != NULL) {\n\t\tspank->job = arg;\n\t\tif (stack->type == S_TYPE_REMOTE && taskid >= 0) {\n\t\t\tspank->task = ((stepd_step_rec_t *) arg)->task[taskid];\n\t\t}\n\t}\n\treturn (0);\n}\n\nstatic const char *_step_fn_name(step_fn_t type)\n{\n\tswitch (type) {\n\tcase SPANK_INIT:\n\t\treturn (\"init\");\n\tcase SPANK_JOB_PROLOG:\n\t\treturn (\"job_prolog\");\n\tcase SPANK_INIT_POST_OPT:\n\t\treturn (\"init_post_opt\");\n\tcase LOCAL_USER_INIT:\n\t\treturn (\"local_user_init\");\n\tcase STEP_USER_INIT:\n\t\treturn (\"user_init\");\n\tcase STEP_TASK_INIT_PRIV:\n\t\treturn (\"task_init_privileged\");\n\tcase STEP_USER_TASK_INIT:\n\t\treturn (\"task_init\");\n\tcase STEP_TASK_POST_FORK:\n\t\treturn (\"task_post_fork\");\n\tcase STEP_TASK_EXIT:\n\t\treturn (\"task_exit\");\n\tcase SPANK_JOB_EPILOG:\n\t\treturn (\"job_epilog\");\n\tcase SPANK_SLURMD_EXIT:\n\t\treturn (\"slurmd_exit\");\n\tcase SPANK_EXIT:\n\t\treturn (\"exit\");\n\t}\n\n\t/* NOTREACHED */\n\treturn (\"unknown\");\n}\n\nstatic spank_f *spank_plugin_get_fn (struct spank_plugin *sp, step_fn_t type)\n{\n\tswitch (type) {\n\tcase SPANK_INIT:\n\t\treturn (sp->ops.init);\n\tcase SPANK_JOB_PROLOG:\n\t\treturn (sp->ops.job_prolog);\n\tcase SPANK_INIT_POST_OPT:\n\t\treturn (sp->ops.init_post_opt);\n\tcase LOCAL_USER_INIT:\n\t\treturn (sp->ops.local_user_init);\n\tcase STEP_USER_INIT:\n\t\treturn (sp->ops.user_init);\n\tcase STEP_TASK_INIT_PRIV:\n\t\treturn (sp->ops.task_init_privileged);\n\tcase STEP_USER_TASK_INIT:\n\t\treturn (sp->ops.user_task_init);\n\tcase STEP_TASK_POST_FORK:\n\t\treturn (sp->ops.task_post_fork);\n\tcase STEP_TASK_EXIT:\n\t\treturn (sp->ops.task_exit);\n\tcase SPANK_JOB_EPILOG:\n\t\treturn (sp->ops.job_epilog);\n\tcase SPANK_SLURMD_EXIT:\n\t\treturn (sp->ops.slurmd_exit);\n\tcase SPANK_EXIT:\n\t\treturn (sp->ops.exit);\n\tdefault:\n\t\terror(\"Unhandled spank function type=%d\", type);\n\t\treturn (NULL);\n\t}\n\treturn (NULL);\n}\n\nstatic int _do_call_stack(struct spank_stack *stack,\n\tstep_fn_t type, void * job, int taskid)\n{\n\tint rc = 0;\n\tListIterator i;\n\tstruct spank_plugin *sp;\n\tstruct spank_handle spank[1];\n\tconst char *fn_name;\n\n\tif (!stack)\n\t\treturn (-1);\n\n\tif (_spank_handle_init(spank, stack, job, taskid, type) < 0) {\n\t\terror(\"spank: Failed to initialize handle for plugins\");\n\t\treturn (-1);\n\t}\n\n\tfn_name = _step_fn_name(type);\n\n\ti = list_iterator_create(stack->plugin_list);\n\twhile ((sp = list_next(i))) {\n\t\tconst char *name = xbasename(sp->fq_path);\n\t\tspank_f *spank_fn;\n\n\t\tspank->plugin = sp;\n\n\t\tspank_fn = spank_plugin_get_fn (sp, type);\n\t\tif (!spank_fn)\n\t\t\tcontinue;\n\n\t\trc = (*spank_fn) (spank, sp->ac, sp->argv);\n\t\tdebug2(\"spank: %s: %s = %d\", name, fn_name, rc);\n\n\t\tif ((rc < 0) && sp->required) {\n\t\t\terror(\"spank: required plugin %s: \"\n\t\t\t      \"%s() failed with rc=%d\", name, fn_name, rc);\n\t\t\tbreak;\n\t\t} else\n\t\t\trc = 0;\n\t}\n\n\tlist_iterator_destroy(i);\n\n\treturn (rc);\n}\n\nstruct spank_stack *spank_stack_init(enum spank_context_type context)\n{\n\tchar *path;\n\tstruct spank_stack *stack = NULL;\n\n\tif (!(path = xstrdup(slurmctld_conf.plugstack)))\n\t\tpath = get_extra_conf_path(\"plugstack.conf\");\n\n\tstack = spank_stack_create(path, context);\n\txfree(path);\n\n\treturn stack;\n}\n\nint _spank_init(enum spank_context_type context, stepd_step_rec_t * job)\n{\n\tstruct spank_stack *stack;\n\n\tif (!(stack = spank_stack_init (context)))\n\t\treturn (-1);\n\tglobal_spank_stack = stack;\n\n\treturn (_do_call_stack(stack, SPANK_INIT, job, -1));\n}\n\nstatic int spank_stack_post_opt (struct spank_stack * stack,\n\t\t\t\t stepd_step_rec_t *job)\n{\n\t/*\n\t *  Get any remote options from job launch message:\n\t */\n\tif (spank_stack_get_remote_options(stack, job->options) < 0) {\n\t\terror(\"spank: Unable to get remote options\");\n\t\treturn (-1);\n\t}\n\n\t/*\n\t *  Get any remote option passed thru environment\n\t */\n\tif (spank_stack_get_remote_options_env(stack, job->env) < 0) {\n\t\terror(\"spank: Unable to get remote options from environment\");\n\t\treturn (-1);\n\t}\n\n\t/*\n\t * Now clear any remaining options passed through environment\n\t */\n\tspank_clear_remote_options_env (job->env);\n\n\t/*\n\t *  Now that all options have been processed, we can\n\t *   call the post_opt handlers here in remote context.\n\t */\n\treturn (_do_call_stack(stack, SPANK_INIT_POST_OPT, job, -1));\n\n}\n\nstatic int spank_init_remote (stepd_step_rec_t *job)\n{\n\tif (_spank_init (S_TYPE_REMOTE, job) < 0)\n\t\treturn (-1);\n\n\t/*\n\t * _spank_init initializes global_spank_stack\n\t */\n\treturn (spank_stack_post_opt (global_spank_stack, job));\n}\n\nint spank_init (stepd_step_rec_t * job)\n{\n\tif (job)\n\t\treturn spank_init_remote (job);\n\telse\n\t\treturn _spank_init (S_TYPE_LOCAL, NULL);\n}\n\nint spank_init_allocator (void)\n{\n\treturn _spank_init (S_TYPE_ALLOCATOR, NULL);\n}\n\nint spank_slurmd_init (void)\n{\n\treturn _spank_init (S_TYPE_SLURMD, NULL);\n}\n\nint spank_init_post_opt (void)\n{\n\tstruct spank_stack *stack = global_spank_stack;\n\n\t/*\n\t *  Set remote options in our environment and the\n\t *   spank_job_env so that we can always pull them out\n\t *   on the remote side and/or job prolog epilog.\n\t */\n\tspank_stack_set_remote_options_env (stack);\n\n\treturn (_do_call_stack(stack, SPANK_INIT_POST_OPT, NULL, -1));\n}\n\nint spank_user(stepd_step_rec_t * job)\n{\n\treturn (_do_call_stack(global_spank_stack, STEP_USER_INIT, job, -1));\n}\n\nint spank_local_user(struct spank_launcher_job_info *job)\n{\n\treturn (_do_call_stack(global_spank_stack, LOCAL_USER_INIT, job, -1));\n}\n\nint spank_task_privileged(stepd_step_rec_t *job, int taskid)\n{\n\treturn (_do_call_stack(global_spank_stack, STEP_TASK_INIT_PRIV, job, taskid));\n}\n\nint spank_user_task(stepd_step_rec_t * job, int taskid)\n{\n\treturn (_do_call_stack(global_spank_stack, STEP_USER_TASK_INIT, job, taskid));\n}\n\nint spank_task_post_fork(stepd_step_rec_t * job, int taskid)\n{\n\treturn (_do_call_stack(global_spank_stack, STEP_TASK_POST_FORK, job, taskid));\n}\n\nint spank_task_exit(stepd_step_rec_t * job, int taskid)\n{\n\treturn (_do_call_stack(global_spank_stack, STEP_TASK_EXIT, job, taskid));\n}\n\nint spank_slurmd_exit (void)\n{\n\tint rc;\n\trc =  _do_call_stack (global_spank_stack, SPANK_SLURMD_EXIT, NULL, 0);\n\tspank_stack_destroy (global_spank_stack);\n\tglobal_spank_stack = NULL;\n\treturn (rc);\n}\n\nint spank_fini(stepd_step_rec_t * job)\n{\n\tint rc = _do_call_stack(global_spank_stack, SPANK_EXIT, job, -1);\n\n\tspank_stack_destroy (global_spank_stack);\n\tglobal_spank_stack = NULL;\n\n\treturn (rc);\n}\n\n/*\n *  Run job_epilog or job_prolog callbacks in a private spank context.\n */\nstatic int spank_job_script(step_fn_t fn, uint32_t jobid, uid_t uid, gid_t gid)\n{\n\tint rc = 0;\n\tstruct spank_stack *stack;\n\tstruct job_script_info jobinfo = { jobid, uid, gid };\n\n\tstack = spank_stack_init (S_TYPE_JOB_SCRIPT);\n\tif (!stack)\n\t\treturn (-1);\n\tglobal_spank_stack = stack;\n\n\trc = _do_call_stack (stack, fn, &jobinfo, -1);\n\n\tspank_stack_destroy (stack);\n\tglobal_spank_stack = NULL;\n\treturn (rc);\n}\n\nint spank_job_prolog(uint32_t jobid, uid_t uid, gid_t gid)\n{\n\treturn spank_job_script(SPANK_JOB_PROLOG, jobid, uid, gid);\n}\n\nint spank_job_epilog(uint32_t jobid, uid_t uid, gid_t gid)\n{\n\treturn spank_job_script(SPANK_JOB_EPILOG, jobid, uid, gid);\n}\n\n/*\n *  SPANK options functions\n */\n\nstatic int _spank_next_option_val(struct spank_stack *stack)\n{\n\treturn (stack->spank_optval++);\n}\n\nstatic struct spank_option * _spank_option_copy(struct spank_option *opt)\n{\n\tstruct spank_option *copy = xmalloc (sizeof (*copy));\n\n\tmemset (copy, 0, sizeof (*copy));\n\n\tcopy->name = xstrdup (opt->name);\n\tcopy->has_arg = opt->has_arg;\n\tcopy->val = opt->val;\n\tcopy->cb = opt->cb;\n\n\tif (opt->arginfo)\n\t\tcopy->arginfo = xstrdup (opt->arginfo);\n\tif (opt->usage)\n\t\tcopy->usage = xstrdup (opt->usage);\n\n\treturn (copy);\n}\n\nstatic void _spank_option_destroy(struct spank_option *opt)\n{\n\txfree (opt->name);\n\txfree (opt->arginfo);\n\txfree (opt->usage);\n\txfree (opt);\n}\n\nstatic struct spank_plugin_opt *_spank_plugin_opt_create(struct\n\t\t\t\t\t\t\t spank_plugin *p,\n\t\t\t\t\t\t\t struct\n\t\t\t\t\t\t\t spank_option *opt,\n\t\t\t\t\t\t\t int disabled)\n{\n\tstruct spank_plugin_opt *spopt = xmalloc(sizeof(*spopt));\n\tspopt->opt = _spank_option_copy (opt);\n\tspopt->plugin = p;\n\tspopt->optval = _spank_next_option_val(p->stack);\n\tspopt->found = 0;\n\tspopt->optarg = NULL;\n\tspopt->set = false;\n\tspopt->set_by_env = false;\n\n\tspopt->disabled = disabled;\n\n\treturn (spopt);\n}\n\nvoid _spank_plugin_opt_destroy(struct spank_plugin_opt *spopt)\n{\n\t_spank_option_destroy (spopt->opt);\n\txfree(spopt->optarg);\n\txfree(spopt);\n}\n\nstatic int _opt_by_val(struct spank_plugin_opt *opt, int *optvalp)\n{\n\treturn (opt->optval == *optvalp);\n}\n\nstatic int _opt_by_name(struct spank_plugin_opt *opt, char *optname)\n{\n\treturn (xstrcmp(opt->opt->name, optname) == 0);\n}\n\nstatic int\n_spank_option_register(struct spank_plugin *p, struct spank_option *opt)\n{\n\tint disabled = 0;\n\tstruct spank_plugin_opt *spopt;\n\tstruct spank_stack *stack;\n\tList option_cache;\n\n\tstack = p->stack;\n\tif (stack == NULL) {\n\t\terror (\"spank: %s: can't determine plugin context\", p->name);\n\t\treturn (ESPANK_BAD_ARG);\n\t}\n\toption_cache = stack->option_cache;\n\n\tspopt = list_find_first(option_cache,\n\t\t\t(ListFindF) _opt_by_name, opt->name);\n\tif (spopt) {\n\t\tstruct spank_plugin *q = spopt->plugin;\n\t\tinfo(\"spank: option \\\"%s\\\" provided by both %s and %s\",\n\t\t\t\topt->name, xbasename(p->fq_path),\n\t\t\t\txbasename(q->fq_path));\n\t\t/*\n\t\t *  Disable this option, but still cache it, in case\n\t\t *    options are loaded in a different order on the\n\t\t *    remote side.\n\t\t */\n\t\tdisabled = 1;\n\t}\n\n\tif ((strlen(opt->name) > SPANK_OPTION_MAXLEN)) {\n\t\terror(\"spank: option \\\"%s\\\" provided by %s too long. \"\n\t\t      \"Ignoring.\", opt->name, p->name);\n\t\treturn (ESPANK_NOSPACE);\n\t}\n\n\tdebug (\"SPANK: appending plugin option \\\"%s\\\"\", opt->name);\n\tlist_append(option_cache, _spank_plugin_opt_create(p, opt, disabled));\n\n\treturn (ESPANK_SUCCESS);\n}\n\nspank_err_t spank_option_register(spank_t sp, struct spank_option *opt)\n{\n\tif (sp->phase != SPANK_INIT)\n\t\treturn (ESPANK_BAD_ARG);\n\n\tif (!sp->plugin)\n\t\terror (\"Uh, oh, no current plugin!\");\n\n\tif (!opt || !opt->name || !opt->usage)\n\t\treturn (ESPANK_BAD_ARG);\n\n\treturn (_spank_option_register(sp->plugin, opt));\n}\n\nstatic int _spank_plugin_options_cache(struct spank_plugin *p)\n{\n\tstruct spank_option *opt = p->opts;\n\n\tif ((opt == NULL) || opt->name == NULL)\n\t\treturn (0);\n\n\tfor (; opt && opt->name != NULL; opt++)\n\t\t_spank_option_register(p, opt);\n\n\treturn (0);\n}\n\nstatic int _add_one_option(struct option **optz,\n\t\t\t   struct spank_plugin_opt *spopt)\n{\n\tstruct option opt;\n\n\topt.name = spopt->opt->name;\n\topt.has_arg = spopt->opt->has_arg;\n\topt.flag = NULL;\n\topt.val = spopt->optval;\n\n\tif (optz_add(optz, &opt) < 0) {\n\t\tif (errno == EEXIST) {\n\t\t\terror (\"Ignoring conflicting option \\\"%s\\\" \"\n\t\t\t       \"in plugin \\\"%s\\\"\",\n\t\t\t       opt.name, spopt->plugin->name);\n\t\t} else {\n\t\t\terror(\"Unable to add option \\\"%s\\\" \"\n\t\t\t      \"from plugin \\\"%s\\\"\",\n\t\t\t      opt.name, spopt->plugin->name);\n\t\t}\n\n\t\treturn (-1);\n\t}\n\n\treturn (0);\n}\n\n\nstruct option *spank_option_table_create(const struct option *orig)\n{\n\tstruct spank_plugin_opt *spopt;\n\tstruct option *opts = NULL;\n\tListIterator i = NULL;\n\n\tList option_cache = get_global_option_cache();\n\tif (option_cache == NULL)\n\t\treturn (NULL);\n\n\topts = optz_create();\n\n\t/*\n\t *  Start with original options:\n\t */\n\tif ((orig != NULL) && (optz_append(&opts, orig) < 0)) {\n\t\toptz_destroy(opts);\n\t\treturn (NULL);\n\t}\n\n\tif (option_cache == NULL || (list_count(option_cache) == 0))\n\t\treturn (opts);\n\n\ti = list_iterator_create(option_cache);\n\twhile ((spopt = list_next(i))) {\n\t\tif (!spopt->disabled && (_add_one_option (&opts, spopt) < 0))\n\t\t\tspopt->disabled = 1;\n\t}\n\n\tlist_iterator_destroy(i);\n\n\treturn (opts);\n}\n\nvoid spank_option_table_destroy(struct option *optz)\n{\n\toptz_destroy(optz);\n}\n\nstatic int _do_option_cb(struct spank_plugin_opt *opt, const char *arg,\n\t\t\t int remote)\n{\n\tint rc = 0;\n\n\txassert(opt);\n\txassert(arg);\n\n\t/*\n\t *  Call plugin callback if such a one exists\n\t */\n\tif (opt->opt->cb\n\t    && (rc = ((*opt->opt->cb) (opt->opt->val, arg, remote))))\n\t\treturn (rc);\n\n\t/*\n\t *  Set optarg and \"found\" so that option will be forwarded\n\t *    to remote side.\n\t */\n\tif (opt->opt->has_arg) {\n\t\txfree(opt->optarg);\n\t\topt->optarg = xstrdup(arg);\n\t}\n\topt->found = 1;\n\topt->set = true;\n\n\treturn rc;\n}\n\nextern int spank_process_option(int optval, const char *arg)\n{\n\tstruct spank_plugin_opt *opt;\n\tint rc = 0;\n\tList option_cache = get_global_option_cache();\n\n\tif (option_cache == NULL || (list_count(option_cache) == 0)) {\n\t\terror(\"No spank option cache\");\n\t\treturn (-1);\n\t}\n\n\topt = list_find_first(option_cache, (ListFindF)_opt_by_val, &optval);\n\tif (!opt) {\n\t\terror(\"Failed to find spank option for optval: %d\", optval);\n\t\treturn (-1);\n\t}\n\n\tif ((rc = _do_option_cb(opt, arg, 0))) {\n\t\terror(\"Invalid --%s argument: %s\", opt->opt->name, arg);\n\t\treturn (rc);\n\t}\n\n\treturn (0);\n}\n\nextern int spank_process_env_options()\n{\n\tchar var[1024];\n\tconst char *arg;\n\tstruct spank_plugin_opt *option;\n\tListIterator i;\n\tList option_cache = get_global_option_cache();\n\tint rc = 0;\n\n\tif (option_cache == NULL || (list_count(option_cache) == 0))\n\t\treturn 0;\n\n\ti = list_iterator_create(option_cache);\n\twhile ((option = list_next(i))) {\n\t\tchar *env_name;\n\t\tenv_name = xstrdup_printf(\"SLURM_SPANK_%s\",\n\t\t\t\t\t  _opt_env_name(option, var,\n\t\t\t\t\t\t\tsizeof(var)));\n\t\tif (!(arg = getenv(env_name))) {\n\t\t\txfree(env_name);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif ((rc = _do_option_cb(option, arg, 0))) {\n\t\t\terror(\"Invalid argument (%s) for environment variable: %s\",\n\t\t\t      arg, env_name);\n\t\t\txfree(env_name);\n\t\t\tbreak;\n\t\t}\n\t\toption->set_by_env = true;\n\t\txfree(env_name);\n\t}\n\tlist_iterator_destroy(i);\n\n\treturn rc;\n}\n\nstatic char *\n_find_word_boundary(char *str, char *from, char **next)\n{\n\tchar *p = from;\n\n\t/*\n\t * Back up past any non-whitespace if we are pointing in\n\t *  the middle of a word.\n\t */\n\twhile ((p != str) && !isspace ((int)*p))\n\t\t--p;\n\n\t/*\n\t * Next holds next word boundary\n\t */\n\t*next = p+1;\n\n\t/*\n\t * Now move back to the end of the previous word\n\t */\n\twhile ((p != str) && isspace ((int)*p))\n\t\t--p;\n\n\tif (p == str) {\n\t\t*next = str;\n\t\treturn (NULL);\n\t}\n\n\treturn (p+1);\n}\n\nstatic char *\n_get_next_segment (char **from, int width, char *buf, int bufsiz)\n{\n\tint len;\n\tchar * seg = *from;\n\tchar *p;\n\n\tif (**from == '\\0')\n\t\treturn (NULL);\n\n\tif ((len = strlen (*from)) <= width) {\n\t\t*from = *from + len;\n\t\treturn (seg);\n\t}\n\n\tif (!(p = _find_word_boundary (seg, *from + width, from))) {\n\t\t/*\n\t\t *\tNeed to break up a word. Use user-supplied buffer.\n\t\t */\n\t\tstrlcpy (buf, seg, width+1);\n\t\tbuf [width - 1]  = '-';\n\t\t/*\n\t\t * Adjust from to character eaten by '-'\n\t\t *  And return pointer to buf.\n\t\t */\n\t\t*from = seg + width - 1;\n\t\treturn (buf);\n\t}\n\n\t*p = '\\0';\n\n\treturn (seg);\n}\n\nstatic int\n_term_columns (void)\n{\n\tchar *val;\n\tint  cols = 80;\n\n\tif ((val = getenv (\"COLUMNS\"))) {\n\t\tchar *p;\n\t\tlong lval = strtol (val, &p, 10);\n\n\t\tif (p && (*p == '\\0'))\n\t\t\tcols = (int) lval;\n\t}\n\n\treturn (cols);\n}\n\nstatic void\n_spank_opt_print(struct spank_option *opt, FILE * fp, int left_pad, int width)\n{\n\tint n;\n\tchar *equals = \"\";\n\tchar *arginfo = \"\";\n\tchar *p, *q;\n\tchar info [81];\n\tchar seg [81];\n\tchar buf [4096];\n\n\tint  columns = _term_columns ();\n\tint  descrsiz = columns - width;\n\n\tif (opt->arginfo) {\n\t\tequals = \"=\";\n\t\targinfo = opt->arginfo;\n\t}\n\n\tn = snprintf(info, sizeof(info), \"%*s--%s%s%s\",\n\t\t     left_pad, \"\", opt->name, equals, arginfo);\n\n\tif ((n < 0) || (n > columns)) {\n\t\tconst char trunc[] = \"+\";\n\t\tint len = strlen(trunc);\n\t\tp = info + columns - len - 1;\n\t\tsnprintf(p, len + 1, \"%s\", trunc);\n\t}\n\n\n\tq = buf;\n\tstrlcpy (buf, opt->usage, sizeof (buf));\n\n\tp = _get_next_segment (&q, descrsiz, seg, sizeof (seg));\n\n\tif (n < width)\n\t\tfprintf(fp, \"%-*s%s\\n\", width, info, p);\n\telse\n\t\tfprintf(fp, \"\\n%s\\n%*s%s\\n\", info, width, \"\", p);\n\n\t/* Get remaining line-wrapped lines.\n\t */\n\twhile ((p = _get_next_segment (&q, descrsiz, seg, sizeof (seg))))\n\t\tfprintf(fp, \"%*s%s\\n\", width, \"\", p);\n\n\treturn;\n}\n\nint spank_print_options(FILE * fp, int left_pad, int width)\n{\n\tstruct spank_plugin_opt *p;\n\tListIterator i;\n\tList option_cache = get_global_option_cache();\n\n\tif ((option_cache == NULL) || (list_count(option_cache) == 0))\n\t\treturn (0);\n\n\tfprintf(fp, \"\\nOptions provided by plugins:\\n\");\n\n\ti = list_iterator_create(option_cache);\n\twhile ((p = list_next(i))) {\n\t\tif (p->disabled)\n\t\t\tcontinue;\n\t\t_spank_opt_print(p->opt, fp, left_pad, width);\n\t}\n\tlist_iterator_destroy(i);\n\n\treturn (0);\n}\n\n#define OPT_TYPE_SPANK 0x4400\n\nstatic char _canonical_char (char c)\n{\n\tif (!isalnum ((int)c))\n\t\treturn '_';\n\telse\n\t\treturn c;\n}\n\n/*\n *  Create spank option environment variable name from option name.\n */\nstatic char * _opt_env_name (struct spank_plugin_opt *p, char *buf, size_t siz)\n{\n\tconst char * name = p->opt->name;\n\tconst char * pname = p->plugin->name;\n\tint i, n;\n\n\tstrlcpy (buf, SPANK_OPTION_ENV_PREFIX, siz);\n\n\t/*\n\t *  First append the plugin name associated with this option:\n\t */\n\tn = 0;\n\tfor (i = strlen (buf); i < siz - 1 && n < strlen (pname); i++)\n\t    buf[i] = _canonical_char (pname[n++]);\n\n\t/*\n\t *  Append _\n\t */\n\tbuf[i] = '_';\n\tbuf[i+1] = '\\0';\n\n\t/*\n\t *  Now incorporate the option name:\n\t */\n\tn = 0;\n\tfor (i = strlen (buf); i < siz - 1 && n < strlen (name); i++)\n\t    buf[i] = _canonical_char (name[n++]);\n\tbuf[i] = '\\0';\n\n\treturn (buf);\n}\n\nstatic int _option_setenv (struct spank_plugin_opt *option)\n{\n\tchar var[1024];\n\tchar *arg = option->optarg;\n\n\t_opt_env_name(option, var, sizeof(var));\n\n\t/*\n\t * Old glibc behavior was to set the variable with an empty value if\n\t * the option was NULL. Newer glibc versions will segfault instead,\n\t * so feed it an empty string when necessary to maintain backwards\n\t * compatibility.\n\t */\n\tif (!option->optarg)\n\t\targ = \"\";\n\n\tif (setenv(var, arg, 1) < 0)\n\t\terror(\"failed to set %s=%s in env\", var, arg);\n\n\t/*\n\t * Use the possibly-NULL value and let the command itself figure\n\t * out how to handle it. This will usually result in \"(null)\"\n\t * instead of \"\" used above.\n\t */\n\n\tif (dyn_spank_set_job_env(var, option->optarg, 1) < 0)\n\t\terror(\"failed to set %s=%s in env\", var, option->optarg);\n\n\treturn (0);\n}\n\nstatic int spank_stack_set_remote_options_env (struct spank_stack *stack)\n{\n\tstruct spank_plugin_opt *p;\n\tListIterator i;\n\tList option_cache;\n\n\tif (stack == NULL)\n\t\treturn (0);\n\toption_cache = stack->option_cache;\n\n\tif ((option_cache == NULL) || (list_count(option_cache) == 0))\n\t\treturn (0);\n\n\ti = list_iterator_create(option_cache);\n\twhile ((p = list_next(i))) {\n\t\tif (p->found)\n\t\t\t_option_setenv (p);\n\t}\n\tlist_iterator_destroy(i);\n\treturn (0);\n}\n\nint spank_set_remote_options(job_options_t opts)\n{\n\tstruct spank_plugin_opt *p;\n\tListIterator i;\n\tList option_cache;\n\n\tif (global_spank_stack == NULL)\n\t\treturn (0);\n\toption_cache = global_spank_stack->option_cache;\n\n\tif ((option_cache == NULL) || (list_count(option_cache) == 0))\n\t\treturn (0);\n\n\ti = list_iterator_create(option_cache);\n\twhile ((p = list_next(i))) {\n\t\tchar optstr[1024];\n\n\t\tif (!p->found)\n\t\t\tcontinue;\n\n\t\tsnprintf(optstr, sizeof(optstr), \"%s:%s\",\n\t\t\t p->opt->name, p->plugin->name);\n\n\t\tjob_options_append(opts, OPT_TYPE_SPANK, optstr,\n\t\t\t\t   p->optarg);\n\t}\n\tlist_iterator_destroy(i);\n\treturn (0);\n}\n\nstruct opt_find_args {\n\tconst char *optname;\n\tconst char *plugin_name;\n};\n\nstatic int _opt_find(struct spank_plugin_opt *p,\n\t\t     struct opt_find_args *args)\n{\n\tif (xstrcmp(p->plugin->name, args->plugin_name) != 0)\n\t\treturn (0);\n\tif (xstrcmp(p->opt->name, args->optname) != 0)\n\t\treturn (0);\n\treturn (1);\n}\n\nstatic struct spank_plugin_opt *\nspank_stack_find_option_by_name(struct spank_stack *stack, const char *str)\n{\n\tstruct spank_plugin_opt *opt = NULL;\n\tstruct opt_find_args args;\n\tchar buf[256];\n\tchar *name;\n\tList option_cache = stack->option_cache;\n\n\tif (strlcpy(buf, str, sizeof(buf)) >= sizeof(buf)) {\n\t\terror(\"plugin option \\\"%s\\\" too big. Ignoring.\", str);\n\t\treturn (NULL);\n\t}\n\n\tif (!(name = strchr(buf, ':'))) {\n\t\terror(\"Malformed plugin option \\\"%s\\\" received. Ignoring\",\n\t\t      str);\n\t\treturn (NULL);\n\t}\n\n\t*(name++) = '\\0';\n\n\targs.optname = buf;\n\targs.plugin_name = name;\n\n\tif (option_cache) {\n\t\topt = list_find_first(option_cache, (ListFindF) _opt_find,\n\t\t\t\t      &args);\n\t\tif (opt == NULL) {\n\t\t\terror(\"Warning: SPANK plugin \\\"%s\\\" option \\\"%s\\\" not \"\n\t\t\t      \"found\", name, buf);\n\t\t\treturn (NULL);\n\t\t}\n\t} else {\n\t\terror(\"Warning: no SPANK plugin found to process option \\\"%s\\\"\",\n\t\t      name);\n\t\treturn (NULL);\n\t}\n\n\treturn (opt);\n}\n\nspank_err_t\nspank_option_getopt (spank_t sp, struct spank_option *opt, char **argp)\n{\n\tconst char *val;\n\tchar var[1024];\n\tList option_cache;\n\tstruct spank_plugin_opt *spopt;\n\n\tif (argp)\n\t\t*argp = NULL;\n\n\tif (!sp->plugin) {\n\t\terror (\"spank_option_getopt: Not called from a plugin!?\");\n\t\treturn (ESPANK_NOT_AVAIL);\n\t}\n\n\tif ((sp->phase == SPANK_INIT) ||\n\t    (sp->phase == SPANK_INIT_POST_OPT) ||\n\t    (sp->phase == STEP_TASK_POST_FORK) ||\n\t    (sp->phase == SPANK_SLURMD_EXIT) ||\n\t    (sp->phase == SPANK_EXIT))\n\t\treturn (ESPANK_NOT_AVAIL);\n\n\tif (!opt || !opt->name)\n\t\treturn (ESPANK_BAD_ARG);\n\n\tif (opt->has_arg && !argp)\n\t\treturn (ESPANK_BAD_ARG);\n\n\t/*\n\t *   First check the cache:\n\t */\n\toption_cache = sp->stack->option_cache;\n\tspopt = list_find_first (option_cache,\n\t\t\t\t (ListFindF) _opt_by_name,\n\t\t\t\t opt->name);\n\tif (spopt) {\n\t\t/*\n\t\t *  Return failure if option is cached but hasn't been\n\t\t *   used on the command line or specified by user.\n\t\t */\n\t\tif (!spopt->found)\n\t\t\treturn (ESPANK_ERROR);\n\n\t\tif (opt->has_arg && argp)\n\t\t\t*argp = spopt->optarg;\n\t\treturn (ESPANK_SUCCESS);\n\t}\n\n\t/*\n\t *  Otherwise, check current environment:\n\t *\n\t *  We need to check for variables that start with either\n\t *   the default spank option env prefix, or the default\n\t *   prefix + an *extra* prefix of SPANK_, in case we're\n\t *   running in prolog/epilog, where Slurm prepends SPANK_\n\t *   to all spank job environment variables.\n\t */\n\tspopt = _spank_plugin_opt_create (sp->plugin, opt, 0);\n\tmemcpy (var, \"SPANK_\", 6);\n\tif ((val = getenv (_opt_env_name(spopt, var+6, sizeof (var) - 6))) ||\n\t    (val = getenv (var))) {\n\t\tspopt->optarg = xstrdup (val);\n\t\tspopt->found = 1;\n\t\tif (opt->has_arg && argp)\n\t\t\t*argp = spopt->optarg;\n\t}\n\n\t/*\n\t *  Cache the result\n\t */\n\tlist_append (option_cache, spopt);\n\n\tif (!spopt->found)\n\t\treturn (ESPANK_ERROR);\n\n\treturn (ESPANK_SUCCESS);\n}\n\n\nint spank_get_remote_options_env (char **env)\n{\n\treturn spank_stack_get_remote_options_env (global_spank_stack, env);\n}\n\n\nstatic int\nspank_stack_get_remote_options_env (struct spank_stack *stack, char **env)\n{\n\tchar var [1024];\n\tconst char *arg;\n\tstruct spank_plugin_opt *option;\n\tListIterator i;\n\tList option_cache = stack->option_cache;\n\n\tif (!option_cache)\n\t\treturn (0);\n\n\ti = list_iterator_create (option_cache);\n\twhile ((option = list_next (i))) {\n\t\tif (!(arg = getenvp (env, _opt_env_name (option, var, sizeof(var)))))\n\t\t\tcontinue;\n\n\t\tif (_do_option_cb(option, arg, 1)) {\n\t\t\terror (\"spank: failed to process option %s=%s\",\n\t\t\t       option->opt->name, arg);\n\t\t}\n\n\t\t/*\n\t\t *  Now remove the environment variable.\n\t\t *   It is no longer needed.\n\t\t */\n\t\tunsetenvp (env, var);\n\n\t}\n\tlist_iterator_destroy (i);\n\n\treturn (0);\n}\n\nint spank_get_remote_options(job_options_t opts)\n{\n\treturn spank_stack_get_remote_options (global_spank_stack, opts);\n}\n\nstatic int\nspank_stack_get_remote_options(struct spank_stack *stack, job_options_t opts)\n{\n\tconst struct job_option_info *j;\n\n\tjob_options_iterator_reset(opts);\n\twhile ((j = job_options_next(opts))) {\n\t\tstruct spank_plugin_opt *opt;\n\n\t\tif (j->type != OPT_TYPE_SPANK)\n\t\t\tcontinue;\n\n\t\tif (!(opt = spank_stack_find_option_by_name(stack, j->option)))\n\t\t\tcontinue;\n\n\t\tif (_do_option_cb(opt, j->optarg, 1)) {\n\t\t\terror(\"spank: failed to process option %s=%s\",\n\t\t\t      opt->opt->name, j->optarg);\n\t\t}\n\t}\n\n\treturn (0);\n}\n\n/*\n *  Clear any environment variables for spank options.\n *   spank option env vars  have a prefix of SPANK_OPTION_ENV_PREFIX,\n *   or SPANK_ + SPANK_OPTION_ENV_PREFIX\n */\nint spank_clear_remote_options_env (char **env)\n{\n\tchar **ep;\n\tint len = strlen (SPANK_OPTION_ENV_PREFIX);\n\n\tfor (ep = env; *ep; ep++) {\n\t\tchar *p = *ep;\n\t\tif (xstrncmp (*ep, \"SPANK_\", 6) == 0)\n\t\t\tp = *ep+6;\n\t\tif (xstrncmp (p, SPANK_OPTION_ENV_PREFIX, len) == 0) {\n\t\t\tchar *end = strchr (p+len, '=');\n\t\t\tif (end) {\n\t\t\t\tchar name[1024];\n\t\t\t\tmemcpy (name, *ep, end - *ep);\n\t\t\t\tname [end - *ep] = '\\0';\n\t\t\t\tdebug(\"unsetenv (%s)\", name);\n\t\t\t\tunsetenvp (env, name);\n\t\t\t}\n\t\t}\n\t}\n\treturn (0);\n}\n\n\n\nstatic int tasks_execd (spank_t spank)\n{\n\treturn ( (spank->phase == STEP_TASK_POST_FORK)\n\t      || (spank->phase == STEP_TASK_EXIT)\n\t      || (spank->phase == SPANK_EXIT) );\n}\n\nstatic spank_err_t\n_global_to_local_id(stepd_step_rec_t *job, uint32_t gid, uint32_t *p2uint32)\n{\n\tint i;\n\t*p2uint32 = (uint32_t) -1;\n\tif ((job == NULL) || (gid >= job->ntasks))\n\t\treturn (ESPANK_BAD_ARG);\n\tfor (i = 0; i < job->node_tasks; i++) {\n\t\tif (job->task[i]->gtid == gid) {\n\t\t\t*p2uint32 = job->task[i]->id;\n\t\t\treturn (ESPANK_SUCCESS);\n\t\t}\n\t}\n\treturn (ESPANK_NOEXIST);\n}\n\n\n/*\n *  Return 1 if spank_item_t is valid for S_TYPE_LOCAL\n */\nstatic int _valid_in_local_context (spank_item_t item)\n{\n\tint rc = 0;\n\tswitch (item) {\n\tcase S_JOB_UID:\n\tcase S_JOB_GID:\n\tcase S_JOB_ID:\n\tcase S_JOB_STEPID:\n\tcase S_JOB_ARGV:\n\tcase S_JOB_ENV:\n\tcase S_JOB_TOTAL_TASK_COUNT:\n\tcase S_JOB_NNODES:\n\t\trc = 1;\n\t\tbreak;\n\tdefault:\n\t\trc = 0;\n\t}\n\treturn (rc);\n}\n\nstatic int _valid_in_allocator_context (spank_item_t item)\n{\n\tswitch (item) {\n\t  case S_JOB_UID:\n\t  case S_JOB_GID:\n\t\t  return 1;\n\t  default:\n\t\t  return 0;\n\t}\n}\n\nstatic spank_err_t _check_spank_item_validity (spank_t spank, spank_item_t item)\n{\n\t/*\n\t *  Valid in all contexts:\n\t */\n\tswitch (item) {\n\t  case S_SLURM_VERSION:\n\t  case S_SLURM_VERSION_MAJOR:\n\t  case S_SLURM_VERSION_MINOR:\n\t  case S_SLURM_VERSION_MICRO:\n\t\t  return ESPANK_SUCCESS;\n\t  default:\n\t\t  break; /* fallthru */\n\t}\n\n\t/*\n\t *  No spank_item_t is available in slurmd context at this time.\n\t */\n\tif (spank->stack->type == S_TYPE_SLURMD)\n\t\treturn ESPANK_NOT_AVAIL;\n\telse if (spank->stack->type == S_TYPE_JOB_SCRIPT) {\n\t\tif (item != S_JOB_GID && item != S_JOB_UID && item != S_JOB_ID)\n\t\t\treturn ESPANK_NOT_AVAIL;\n\t}\n\telse if (spank->stack->type == S_TYPE_LOCAL) {\n\t\tif (!_valid_in_local_context (item))\n\t\t\treturn ESPANK_NOT_REMOTE;\n\t\telse if (spank->job == NULL)\n\t\t\treturn ESPANK_NOT_AVAIL;\n\t}\n\telse if (spank->stack->type == S_TYPE_ALLOCATOR) {\n\t\tif (_valid_in_allocator_context (item)) {\n\t\t\tif (spank->job)\n\t\t\t\treturn ESPANK_SUCCESS;\n\t\t\telse\n\t\t\t\treturn ESPANK_NOT_AVAIL;\n\t\t}\n\t\telse if (_valid_in_local_context (item))\n\t\t\treturn ESPANK_BAD_ARG;\n\t\telse\n\t\t\treturn ESPANK_NOT_REMOTE;\n\t}\n\n\t/* All items presumably valid in remote context */\n\treturn ESPANK_SUCCESS;\n}\n\n/*\n *  Global functions for SPANK plugins\n */\n\nconst char * spank_strerror (spank_err_t err)\n{\n\tswitch (err) {\n\tcase ESPANK_SUCCESS:\n\t\treturn \"Success\";\n\tcase ESPANK_ERROR:\n\t\treturn \"Generic error\";\n\tcase ESPANK_BAD_ARG:\n\t\treturn \"Bad argument\";\n\tcase ESPANK_NOT_TASK:\n\t\treturn \"Not in task context\";\n\tcase ESPANK_ENV_EXISTS:\n\t\treturn \"Environment variable exists\";\n\tcase ESPANK_ENV_NOEXIST:\n\t\treturn \"No such environment variable\";\n\tcase ESPANK_NOSPACE:\n\t\treturn \"Buffer too small\";\n\tcase ESPANK_NOT_REMOTE:\n\t\treturn \"Valid only in remote context\";\n\tcase ESPANK_NOEXIST:\n\t\treturn \"Id/PID does not exist on this node\";\n\tcase ESPANK_NOT_EXECD:\n\t\treturn \"Lookup by PID requested, but no tasks running\";\n\tcase ESPANK_NOT_AVAIL:\n\t\treturn \"Item not available from this callback\";\n\tcase ESPANK_NOT_LOCAL:\n\t\treturn \"Valid only in local or allocator context\";\n\t}\n\n\treturn \"Unknown\";\n}\n\nint spank_symbol_supported (const char *name)\n{\n\tint i;\n\n\tif (name == NULL)\n\t\treturn (-1);\n\n\tfor (i = 0; i < n_spank_syms; i++) {\n\t\tif (xstrcmp (spank_syms [i], name) == 0)\n\t\t\treturn (1);\n\t}\n\n\treturn (0);\n}\n\nint spank_remote(spank_t spank)\n{\n\tif ((spank == NULL) || (spank->magic != SPANK_MAGIC))\n\t\treturn (-1);\n\tif (spank->stack->type == S_TYPE_REMOTE)\n\t\treturn (1);\n\telse\n\t\treturn (0);\n}\n\nspank_context_t spank_context (void)\n{\n\tif (global_spank_stack == NULL)\n\t\treturn S_CTX_ERROR;\n\tswitch (global_spank_stack->type) {\n\t  case S_TYPE_REMOTE:\n\t\t  return S_CTX_REMOTE;\n\t  case S_TYPE_LOCAL:\n\t\t  return S_CTX_LOCAL;\n\t  case S_TYPE_ALLOCATOR:\n\t\t  return S_CTX_ALLOCATOR;\n\t  case S_TYPE_SLURMD:\n\t\t  return S_CTX_SLURMD;\n\t  case S_TYPE_JOB_SCRIPT:\n\t\t  return S_CTX_JOB_SCRIPT;\n\t  default:\n\t\t  return S_CTX_ERROR;\n\t}\n\n\treturn S_CTX_ERROR;\n}\n\nspank_err_t spank_get_item(spank_t spank, spank_item_t item, ...)\n{\n\tint *p2int;\n\tuint32_t *p2uint32;\n\tuint64_t *p2uint64;\n\tuint32_t  uint32;\n\tuint16_t *p2uint16;\n\tuid_t *p2uid;\n\tgid_t *p2gid;\n\tgid_t **p2gids;\n\tpid_t *p2pid;\n\tpid_t  pid;\n\tchar ***p2argv;\n\tchar **p2str;\n\tchar **p2vers;\n\tstepd_step_task_info_t *task;\n\tstepd_step_rec_t  *slurmd_job = NULL;\n\tstruct spank_launcher_job_info *launcher_job = NULL;\n\tstruct job_script_info *s_job_info = NULL;\n\tva_list vargs;\n\tspank_err_t rc = ESPANK_SUCCESS;\n\n\tif ((spank == NULL) || (spank->magic != SPANK_MAGIC))\n\t\treturn (ESPANK_BAD_ARG);\n\n\t/*\n\t *  Check for validity of the given item in the current context\n\t */\n\trc = _check_spank_item_validity (spank, item);\n\tif (rc != ESPANK_SUCCESS)\n\t\treturn (rc);\n\n\tif (spank->stack->type == S_TYPE_LOCAL)\n\t\tlauncher_job = spank->job;\n\telse if (spank->stack->type == S_TYPE_REMOTE)\n\t\tslurmd_job = spank->job;\n\telse if (spank->stack->type == S_TYPE_JOB_SCRIPT)\n\t\ts_job_info = spank->job;\n\n\tva_start(vargs, item);\n\tswitch (item) {\n\tcase S_JOB_UID:\n\t\tp2uid = va_arg(vargs, uid_t *);\n\t\tif (spank->stack->type == S_TYPE_LOCAL)\n\t\t\t*p2uid = launcher_job->uid;\n\t\telse if (spank->stack->type == S_TYPE_REMOTE)\n\t\t\t*p2uid = slurmd_job->uid;\n\t\telse if (spank->stack->type == S_TYPE_JOB_SCRIPT)\n\t\t\t*p2uid = s_job_info->uid;\n\t\telse\n\t\t\t*p2uid = getuid();\n\t\tbreak;\n\tcase S_JOB_GID:\n\t\tp2gid = va_arg(vargs, gid_t *);\n\t\tif (spank->stack->type == S_TYPE_LOCAL)\n\t\t\t*p2gid = launcher_job->gid;\n\t\telse if (spank->stack->type == S_TYPE_REMOTE)\n\t\t\t*p2gid = slurmd_job->gid;\n\t\telse if (spank->stack->type == S_TYPE_JOB_SCRIPT)\n\t\t\t*p2gid = s_job_info->gid;\n\t\telse\n\t\t\t*p2gid = getgid();\n\t\tbreak;\n\tcase S_JOB_SUPPLEMENTARY_GIDS:\n\t\tp2gids = va_arg(vargs, gid_t **);\n\t\tp2int = va_arg(vargs, int *);\n\t\tif (slurmd_job) {\n\t\t\t*p2gids = slurmd_job->gids;\n\t\t\t*p2int = slurmd_job->ngids;\n\t\t} else {\n\t\t\t*p2gids = NULL;\n\t\t\t*p2int = 0;\n\t\t}\n\t\tbreak;\n\tcase S_JOB_ID:\n\t\tp2uint32 = va_arg(vargs, uint32_t *);\n\t\tif (spank->stack->type == S_TYPE_LOCAL)\n\t\t\t*p2uint32 = launcher_job->jobid;\n\t\telse if (spank->stack->type == S_TYPE_REMOTE)\n\t\t\t*p2uint32 = slurmd_job->jobid;\n\t\telse if (spank->stack->type == S_TYPE_JOB_SCRIPT)\n\t\t\t*p2uint32 = s_job_info->jobid;\n\t\tbreak;\n\tcase S_JOB_STEPID:\n\t\tp2uint32 = va_arg(vargs, uint32_t *);\n\t\tif (spank->stack->type == S_TYPE_LOCAL)\n\t\t\t*p2uint32 = launcher_job->stepid;\n\t\telse if (slurmd_job)\n\t\t\t*p2uint32 = slurmd_job->stepid;\n\t\telse\n\t\t\t*p2uint32 = 0;\n\t\tbreak;\n\tcase S_JOB_ARRAY_ID:\n\t\tp2uint32 = va_arg(vargs, uint32_t *);\n\t\tif (spank->stack->type == S_TYPE_REMOTE)\n\t\t\t*p2uint32 = slurmd_job->array_job_id;\n\t\telse\n\t\t\t*p2uint32 = 0;\n\t\tbreak;\n\tcase S_JOB_ARRAY_TASK_ID:\n\t\tp2uint32 = va_arg(vargs, uint32_t *);\n\t\tif (spank->stack->type == S_TYPE_REMOTE)\n\t\t\t*p2uint32 = slurmd_job->array_task_id;\n\t\telse\n\t\t\t*p2uint32 = 0;\n\t\tbreak;\n\tcase S_JOB_NNODES:\n\t\tp2uint32 = va_arg(vargs, uint32_t *);\n\t\tif (spank->stack->type == S_TYPE_LOCAL) {\n\t\t\tif (launcher_job->step_layout)\n\t\t\t\t*p2uint32 = launcher_job->step_layout->\n\t\t\t\t\t    node_cnt;\n\t\t\telse {\n\t\t\t\t*p2uint32 = 0;\n\t\t\t\trc = ESPANK_ENV_NOEXIST;\n\t\t\t}\n\t\t} else if (slurmd_job)\n\t\t\t*p2uint32 = slurmd_job->nnodes;\n\t\telse\n\t\t\t*p2uint32 = 0;\n\t\tbreak;\n\tcase S_JOB_NODEID:\n\t\tp2uint32 = va_arg(vargs, uint32_t *);\n\t\tif (slurmd_job)\n\t\t\t*p2uint32 = slurmd_job->nodeid;\n\t\telse\n\t\t\t*p2uint32 = 0;\n\t\tbreak;\n\tcase S_JOB_LOCAL_TASK_COUNT:\n\t\tp2uint32 = va_arg(vargs, uint32_t *);\n\t\tif (slurmd_job)\n\t\t\t*p2uint32 = slurmd_job->node_tasks;\n\t\telse\n\t\t\t*p2uint32 = 0;\n\t\tbreak;\n\tcase S_JOB_TOTAL_TASK_COUNT:\n\t\tp2uint32 = va_arg(vargs, uint32_t *);\n\t\tif (spank->stack->type == S_TYPE_LOCAL) {\n\t\t\tif (launcher_job->step_layout)\n\t\t\t\t*p2uint32 = launcher_job->step_layout->\n\t\t\t\t\t    task_cnt;\n\t\t\telse {\n\t\t\t\t*p2uint32 = 0;\n\t\t\t\trc = ESPANK_ENV_NOEXIST;\n\t\t\t}\n\t\t} else if (slurmd_job)\n\t\t\t*p2uint32 = slurmd_job->ntasks;\n\t\telse\n\t\t\t*p2uint32 = 0;\n\t\tbreak;\n\tcase S_JOB_NCPUS:\n\t\tp2uint16 = va_arg(vargs, uint16_t *);\n\t\tif (slurmd_job)\n\t\t\t*p2uint16 = slurmd_job->cpus;\n\t\telse\n\t\t\t*p2uint16 = 0;\n\t\tbreak;\n\tcase S_STEP_CPUS_PER_TASK:\n\t\tp2uint32 = va_arg(vargs, uint32_t *);\n\t\tif (slurmd_job)\n\t\t\t*p2uint32 = slurmd_job->cpus_per_task;\n\t\telse\n\t\t\t*p2uint32 = 0;\n\t\tbreak;\n\tcase S_JOB_ARGV:\n\t\tp2int = va_arg(vargs, int *);\n\t\tp2argv = va_arg(vargs, char ***);\n\t\tif (spank->stack->type == S_TYPE_LOCAL) {\n\t\t\t*p2int = launcher_job->argc;\n\t\t\t*p2argv = launcher_job->argv;\n\t\t} else if (slurmd_job) {\n\t\t\t*p2int = slurmd_job->argc;\n\t\t\t*p2argv = slurmd_job->argv;\n\t\t} else {\n\t\t\t*p2int = 0;\n\t\t\t*p2argv = NULL;\n\t\t}\n\t\tbreak;\n\tcase S_JOB_ENV:\n\t\tp2argv = va_arg(vargs, char ***);\n\t\tif (slurmd_job)\n\t\t\t*p2argv = slurmd_job->env;\n\t\telse\n\t\t\t*p2argv = NULL;\n\t\tbreak;\n\tcase S_TASK_ID:\n\t\tp2int = va_arg(vargs, int *);\n\t\tif (!spank->task) {\n\t\t\t*p2int = -1;\n\t\t\trc = ESPANK_NOT_TASK;\n\t\t} else {\n\t\t\t*p2int = spank->task->id;\n\t\t}\n\t\tbreak;\n\tcase S_TASK_GLOBAL_ID:\n\t\tp2uint32 = va_arg(vargs, uint32_t *);\n\t\tif (!spank->task) {\n\t\t\trc = ESPANK_NOT_TASK;\n\t\t} else {\n\t\t\t*p2uint32 = spank->task->gtid;\n\t\t}\n\t\tbreak;\n\tcase S_TASK_EXIT_STATUS:\n\t\tp2int = va_arg(vargs, int *);\n\t\tif (!spank->task || !spank->task->exited) {\n\t\t\trc = ESPANK_NOT_TASK;\n\t\t} else {\n\t\t\t*p2int = spank->task->estatus;\n\t\t}\n\t\tbreak;\n\tcase S_TASK_PID:\n\t\tp2pid = va_arg(vargs, pid_t *);\n\t\tif (!spank->task) {\n\t\t\trc = ESPANK_NOT_TASK;\n\t\t\t*p2pid = 0;\n\t\t} else {\n\t\t\t*p2pid = spank->task->pid;\n\t\t}\n\t\tbreak;\n\tcase S_JOB_PID_TO_GLOBAL_ID:\n\t\tpid = va_arg(vargs, pid_t);\n\t\tp2uint32 = va_arg(vargs, uint32_t *);\n\t\t*p2uint32 = (uint32_t) -1;\n\n\t\tif (!tasks_execd(spank))\n\t\t\trc = ESPANK_NOT_EXECD;\n\t\telse if (!(task = job_task_info_by_pid (slurmd_job, pid)))\n\t\t\trc = ESPANK_NOEXIST;\n\t\telse\n\t\t\t*p2uint32 = task->gtid;\n\t\tbreak;\n\tcase S_JOB_PID_TO_LOCAL_ID:\n\t\tpid = va_arg(vargs, pid_t);\n\t\tp2uint32 = va_arg(vargs, uint32_t *);\n\t\t*p2uint32 = (uint32_t) -1;\n\n\t\tif (!tasks_execd(spank))\n\t\t\trc = ESPANK_NOT_EXECD;\n\t\telse if (!(task = job_task_info_by_pid (slurmd_job, pid)))\n\t\t\trc = ESPANK_NOEXIST;\n\t\telse\n\t\t\t*p2uint32 = task->id;\n\t\tbreak;\n\tcase S_JOB_LOCAL_TO_GLOBAL_ID:\n\t\tuint32 = va_arg(vargs, uint32_t);\n\t\tp2uint32 = va_arg(vargs, uint32_t *);\n\t\t*p2uint32 = (uint32_t) -1;\n\n\t\tif (slurmd_job && (uint32 <= slurmd_job->node_tasks) &&\n\t\t    slurmd_job->task && slurmd_job->task[uint32]) {\n\t\t\t*p2uint32 = slurmd_job->task[uint32]->gtid;\n\t\t} else\n\t\t\trc = ESPANK_NOEXIST;\n\t\tbreak;\n\tcase S_JOB_GLOBAL_TO_LOCAL_ID:\n\t\tuint32 = va_arg(vargs, uint32_t);\n\t\tp2uint32 = va_arg(vargs, uint32_t *);\n\t\trc = _global_to_local_id (slurmd_job, uint32, p2uint32);\n\t\tbreak;\n\tcase S_JOB_ALLOC_CORES:\n\t\tp2str = va_arg(vargs, char **);\n\t\tif (slurmd_job)\n\t\t\t*p2str = slurmd_job->job_alloc_cores;\n\t\telse\n\t\t\t*p2str = NULL;\n\t\tbreak;\n\tcase S_JOB_ALLOC_MEM:\n\t\tp2uint64 = va_arg(vargs, uint64_t *);\n\t\tif (slurmd_job)\n\t\t\t*p2uint64 = slurmd_job->job_mem;\n\t\telse\n\t\t\t*p2uint64 = 0;\n\t\tbreak;\n\tcase S_STEP_ALLOC_CORES:\n\t\tp2str = va_arg(vargs, char **);\n\t\tif (slurmd_job)\n\t\t\t*p2str = slurmd_job->step_alloc_cores;\n\t\telse\n\t\t\t*p2str = NULL;\n\t\tbreak;\n\tcase S_STEP_ALLOC_MEM:\n\t\tp2uint64 = va_arg(vargs, uint64_t *);\n\t\tif (slurmd_job)\n\t\t\t*p2uint64 = slurmd_job->step_mem;\n\t\telse\n\t\t\t*p2uint64 = 0;\n\t\tbreak;\n\tcase S_SLURM_RESTART_COUNT:\n\t\tp2uint32 = va_arg(vargs, uint32_t *);\n\t\tif (slurmd_job)\n\t\t\t*p2uint32 = slurmd_job->restart_cnt;\n\t\telse\n\t\t\t*p2uint32 = 0;\n\t\tbreak;\n\tcase S_SLURM_VERSION:\n\t\tp2vers = va_arg(vargs, char  **);\n\t\t*p2vers = SLURM_VERSION_STRING;\n\t\tbreak;\n\tcase S_SLURM_VERSION_MAJOR:\n\t\tp2vers = va_arg(vargs, char  **);\n\t\t*p2vers = SLURM_MAJOR;\n\t\tbreak;\n\tcase S_SLURM_VERSION_MINOR:\n\t\tp2vers = va_arg(vargs, char  **);\n\t\t*p2vers = SLURM_MINOR;\n\t\tbreak;\n\tcase S_SLURM_VERSION_MICRO:\n\t\tp2vers = va_arg(vargs, char  **);\n\t\t*p2vers = SLURM_MICRO;\n\t\tbreak;\n\tdefault:\n\t\trc = ESPANK_BAD_ARG;\n\t\tbreak;\n\t}\n\tva_end(vargs);\n\treturn (rc);\n}\n\nspank_err_t spank_env_access_check (spank_t spank)\n{\n\tif ((spank == NULL) || (spank->magic != SPANK_MAGIC))\n\t\treturn (ESPANK_BAD_ARG);\n\tif (spank->stack->type != S_TYPE_REMOTE)\n\t\treturn (ESPANK_NOT_REMOTE);\n\tif (spank->job == NULL)\n\t\treturn (ESPANK_BAD_ARG);\n\treturn (ESPANK_SUCCESS);\n\n}\n\nspank_err_t spank_getenv(spank_t spank, const char *var, char *buf,\n\t\t\t int len)\n{\n\tchar *val;\n\tspank_err_t err = spank_env_access_check (spank);\n\n\tif (err != ESPANK_SUCCESS)\n\t\treturn (err);\n\n\tif (len < 0)\n\t\treturn (ESPANK_BAD_ARG);\n\n\tif (!(val = getenvp(((stepd_step_rec_t *) spank->job)->env, var)))\n\t\treturn (ESPANK_ENV_NOEXIST);\n\n\tif (strlcpy(buf, val, len) >= len)\n\t\treturn (ESPANK_NOSPACE);\n\n\treturn (ESPANK_SUCCESS);\n}\n\nspank_err_t spank_setenv(spank_t spank, const char *var, const char *val,\n\t\t\t int overwrite)\n{\n\tstepd_step_rec_t * job;\n\tspank_err_t err = spank_env_access_check (spank);\n\n\tif (err != ESPANK_SUCCESS)\n\t\treturn (err);\n\n\tif ((var == NULL) || (val == NULL))\n\t\treturn (ESPANK_BAD_ARG);\n\n\tjob = spank->job;\n\n\tif (getenvp(job->env, var) && !overwrite)\n\t\treturn (ESPANK_ENV_EXISTS);\n\n\tif (setenvf(&job->env, var, \"%s\", val) < 0)\n\t\treturn (ESPANK_ERROR);\n\n\treturn (ESPANK_SUCCESS);\n}\n\nspank_err_t spank_unsetenv (spank_t spank, const char *var)\n{\n\tspank_err_t err = spank_env_access_check (spank);\n\n\tif (err != ESPANK_SUCCESS)\n\t\treturn (err);\n\n\tif (var == NULL)\n\t\treturn (ESPANK_BAD_ARG);\n\n\tunsetenvp(((stepd_step_rec_t *) spank->job)->env, var);\n\n\treturn (ESPANK_SUCCESS);\n}\n\n\n/*\n *  Dynamically loaded versions of spank_*_job_env\n */\nconst char *dyn_spank_get_job_env(const char *name)\n{\n\tvoid *h = dlopen(NULL, 0);\n\tchar * (*fn)(const char *n);\n\tchar *rc;\n\n\tfn = dlsym(h, \"spank_get_job_env\");\n\tif (fn == NULL) {\n\t\t(void) dlclose(h);\n\t\treturn NULL;\n\t}\n\n\trc = ((*fn) (name));\n/*\t(void) dlclose(h);\tNOTE: DO NOT CLOSE OR SPANK WILL BREAK */\n\treturn rc;\n}\n\nint dyn_spank_set_job_env(const char *n, const char *v, int overwrite)\n{\n\tvoid *h = dlopen(NULL, 0);\n\tint (*fn)(const char *n, const char *v, int overwrite);\n\tint rc;\n\n\tfn = dlsym(h, \"spank_set_job_env\");\n\tif (fn == NULL) {\n\t\t(void) dlclose(h);\n\t\treturn (-1);\n\t}\n\n\trc = ((*fn) (n, v, overwrite));\n/*\t(void) dlclose(h);\tNOTE: DO NOT CLOSE OR SPANK WILL BREAK */\n\treturn rc;\n}\n\nextern int dyn_spank_unset_job_env(const char *n)\n{\n\tvoid *h = dlopen(NULL, 0);\n\tint (*fn)(const char *n);\n\tint rc;\n\n\tfn = dlsym(h, \"spank_unset_job_env\");\n\tif (fn == NULL) {\n\t\t(void) dlclose(h);\n\t\treturn (-1);\n\t}\n\n\trc = ((*fn) (n));\n/*\t(void) dlclose(h);\tNOTE: DO NOT CLOSE OR SPANK WILL BREAK */\n\treturn rc;\n}\n\nstatic spank_err_t spank_job_control_access_check (spank_t spank)\n{\n\tif ((spank == NULL) || (spank->magic != SPANK_MAGIC))\n\t\treturn (ESPANK_BAD_ARG);\n\n\tif (spank_remote (spank))\n\t\treturn (ESPANK_NOT_LOCAL);\n\n\tif (spank->stack->type == S_TYPE_SLURMD)\n\t\treturn (ESPANK_NOT_AVAIL);\n\n\treturn (ESPANK_SUCCESS);\n}\n\n\nspank_err_t spank_job_control_getenv (spank_t spank, const char *var,\n\t\t\tchar *buf, int len)\n{\n\tconst char *val;\n\tspank_err_t err;\n\n\tif ((err = spank_job_control_access_check (spank)))\n\t\treturn (err);\n\n\tif ((var == NULL) || (buf == NULL) || (len <= 0))\n\t\treturn (ESPANK_BAD_ARG);\n\n\tval = dyn_spank_get_job_env (var);\n\tif (val == NULL)\n\t\treturn (ESPANK_ENV_NOEXIST);\n\n\tif (strlcpy (buf, val, len) >= len)\n\t\treturn (ESPANK_NOSPACE);\n\n\treturn (ESPANK_SUCCESS);\n}\n\nspank_err_t spank_job_control_setenv (spank_t spank, const char *var,\n\t\t\tconst char *val, int overwrite)\n{\n\tspank_err_t err;\n\n\tif ((err = spank_job_control_access_check (spank)))\n\t\treturn (err);\n\n\tif ((var == NULL) || (val == NULL))\n\t\treturn (ESPANK_BAD_ARG);\n\n\tif (dyn_spank_set_job_env (var, val, overwrite) < 0)\n\t\treturn (ESPANK_BAD_ARG);\n\n\treturn (ESPANK_SUCCESS);\n}\n\nspank_err_t spank_job_control_unsetenv (spank_t spank, const char *var)\n{\n\tspank_err_t err;\n\n\tif ((err = spank_job_control_access_check (spank)))\n\t\treturn (err);\n\n\tif (var == NULL)\n\t\treturn (ESPANK_BAD_ARG);\n\n\tif (dyn_spank_unset_job_env (var) < 0)\n\t\treturn (ESPANK_BAD_ARG);\n\n\treturn (ESPANK_SUCCESS);\n}\n\n/*\n * spank_get_plugin_names\n * Get names of all spank plugins\n *\n * Parameters:\n * IN/OUT names\t- Pointer to char ** (should be NULL when called) output of\n *\t\t  function is allocated memory for the array of string\n *\t\t  pointers, and allocated memory for the strings. Array will\n *\t\t  be NULL terminated. Caller should manage the memory.\n * Returns:\n * \t\t- Number of allocated strings (excluding NULL terminator)\n */\nsize_t spank_get_plugin_names(char ***names)\n{\n\tstruct spank_plugin *p;\n\tListIterator i;\n\tsize_t n_names = 0;\n\n\tif (!global_spank_stack)\n\t\treturn 0;\n\n\ti = list_iterator_create(global_spank_stack->plugin_list);\n\twhile ((p = list_next(i))) {\n\t\t*names = xrecalloc(*names, ++n_names + 1, sizeof(char *));\n\t\t(*names)[n_names] = NULL;\n\t\t(*names)[n_names - 1] = xstrdup(p->name);\n\t}\n\tlist_iterator_destroy(i);\n\treturn n_names;\n}\n\n/*\n * spank_get_plugin_option_names\n * Get names of all spank plugins\n *\n * Parameters:\n * IN plugin_name\t- Name of spank plugin being considered\n *\t\t\t  (e.g., from spank_get_plugin_names)\n * IN/OUT opts\t\t- Pointer to char ** (should be NULL when called)\n *\t\t\t  output of function is allocated memory for the array\n *\t\t\t  of string pointers, and allocated memory for the\n *\t\t\t  strings. Array will be NULL terminated. Caller\n *\t\t\t  should manage the memory.\n * Returns:\n *\t\t\t- Number of allocated strings (excluding NULL\n *\t\t\t  terminator)\n */\nsize_t spank_get_plugin_option_names(const char *plugin_name, char ***opts)\n{\n\tstruct spank_plugin_opt *spopt;\n\tsize_t nopts = 0;\n\n\tList options = get_global_option_cache();\n\tListIterator i;\n\n\ti = list_iterator_create(options);\n\twhile ((spopt = list_next(i))) {\n\t\tif (spopt->disabled)\n\t\t\tcontinue;\n\t\tif (!xstrcmp(spopt->plugin->name, plugin_name)) {\n\t\t\t*opts = xrecalloc(*opts, ++nopts + 1, sizeof(char *));\n\t\t\t(*opts)[nopts] = NULL;\n\t\t\t(*opts)[nopts - 1] = xstrdup(spopt->opt->name);\n\t\t\tcontinue;\n\t\t}\n\t}\n\tlist_iterator_destroy(i);\n\treturn nopts;\n}\n\n/*\n * Get option value by common option name\n */\nextern char *spank_option_get(char *name)\n{\n\tList option_cache = get_global_option_cache();\n\tstruct spank_plugin_opt *spopt;\n\n\tif (!option_cache)\n\t\treturn NULL;\n\n\tspopt = list_find_first(option_cache,\n\t\t\t(ListFindF) _opt_by_name, name);\n\n\tif (spopt) {\n\t\tif (spopt->set && !spopt->optarg)\n\t\t\treturn xstrdup(\"set\");\n\t\tif (!spopt->set && !spopt->opt->has_arg)\n\t\t\treturn xstrdup(\"unset\");\n\t\tif (spopt->optarg)\n\t\t\treturn xstrdup(spopt->optarg);\n\t}\n\treturn NULL;\n}\n\n/*\n * Get plugin name by common option name\n */\nextern char *spank_option_plugin(char *optname)\n{\n\tList option_cache = get_global_option_cache();\n\tstruct spank_plugin_opt *spopt;\n\n\tif (!option_cache)\n\t\treturn NULL;\n\n\tspopt = list_find_first(option_cache,\n\t\t\t(ListFindF) _opt_by_name, optname);\n\n\tif (spopt)\n\t\treturn xstrdup(spopt->plugin->name);\n\treturn NULL;\n}\n\n/*\n * Is option set? Discover by common option name\n */\nextern bool spank_option_isset(char *name)\n{\n\tList option_cache = get_global_option_cache();\n\tstruct spank_plugin_opt *spopt;\n\n\tif (!option_cache)\n\t\treturn NULL;\n\n\tspopt = list_find_first(option_cache,\n\t\t\t(ListFindF) _opt_by_name, name);\n\tif (spopt)\n\t\treturn spopt->set;\n\treturn false;\n}\n\n/*\n * Function for iterating through all the common option data structure\n * and returning (via parameter arguments) the name and value of each\n * set slurm option.\n *\n * OUT plugin\t- pointer to string to store the plugin name\n * OUT name\t- pointer to string to store the option name\n * OUT value\t- pointer to string to store the value\n * IN/OUT state\t- internal state, should point to NULL for the first call\n * RETURNS\t- true if plugin/name/value set; false if no more options\n */\nextern bool spank_option_get_next_set(char **plugin, char **name,\n\t\t\t\t      char **value, void **state)\n{\n\tList option_cache = get_global_option_cache();\n\tListIterator *iter = (ListIterator *) *state;\n\tstruct spank_plugin_opt *spopt;\n\n\tif (option_cache == NULL)\n\t\treturn NULL;\n\n\tif (!iter) {\n\t\titer = xmalloc(sizeof(ListIterator));\n\t\t*iter = list_iterator_create(option_cache);\n\t\t*state = iter;\n\t}\n\n\twhile ((spopt = list_next(*iter))) {\n\t\tif (!spopt->set)\n\t\t\tcontinue;\n\t\t*plugin = xstrdup(spopt->plugin->name);\n\t\t*name = xstrdup(spopt->opt->name);\n\t\tif (spopt->optarg)\n\t\t\t*value = xstrdup(spopt->optarg);\n\t\telse if (spopt->set)\n\t\t\t*value = xstrdup(\"set\");\n\t\telse if (!spopt->set && !spopt->opt->has_arg)\n\t\t\t*value = xstrdup(\"unset\");\n\t\treturn true;\n\t}\n\n\tlist_iterator_destroy(*iter);\n\txfree(iter);\n\t*state = NULL;\n\n\treturn false;\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/src/plugins/acct_gather_energy/rsmi/acct_gather_energy_rsmi.c": "/*****************************************************************************\\\n *  acct_gather_energy_rsmi.c - slurm energy accounting plugin for AMD GPU.\n *****************************************************************************\n *  Copyright (C) 2019 SchedMD LLC\n *  Copyright (c) 2019, Advanced Micro Devices, Inc. All rights reserved.\n *  Written by Advanced Micro Devices,\n *  who borrowed from the ipmi plugin of the same type\n *\n *  This file is part of Slurm, a resource management program.\n *  For details, see <https://slurm.schedmd.com/>.\n *  Please also read the included file: DISCLAIMER.\n *\n *  Slurm is free software; you can redistribute it and/or modify it under\n *  the terms of the GNU General Public License as published by the Free\n *  Software Foundation; either version 2 of the License, or (at your option)\n *  any later version.\n *\n *  In addition, as a special exception, the copyright holders give permission\n *  to link the code of portions of this program with the OpenSSL library under\n *  certain conditions as described in each individual source file, and\n *  distribute linked combinations including the two. You must obey the GNU\n *  General Public License in all respects for all of the code used other than\n *  OpenSSL. If you modify file(s) with this exception, you may extend this\n *  exception to your version of the file(s), but you are not obligated to do\n *  so. If you do not wish to do so, delete this exception statement from your\n *  version.  If you delete this exception statement from all source files in\n *  the program, then also delete it here.\n *\n *  Slurm is distributed in the hope that it will be useful, but WITHOUT ANY\n *  WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n *  FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more\n *  details.\n *\n *  You should have received a copy of the GNU General Public License along\n *  with Slurm; if not, write to the Free Software Foundation, Inc.,\n *  51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA.\n *\n\\*****************************************************************************/\n\n/* acct_gather_energy_rsmi\n * This plugin initiates a node-level thread, which is running in Slurmd daemon\n * and reads periodically the current average energy from the AMD GPUs through\n * RSMI interface. It collects the energy consumption for all AMD GPUs for a\n * node. It is also running in Slurmstepd daemon and collects the energy\n * consumption for a job.\n */\n\n#include <rocm_smi/rocm_smi.h>\n#include <dlfcn.h>\n\n#include \"src/common/slurm_xlator.h\"\n#include \"src/common/slurm_acct_gather_energy.h\"\n#include \"src/common/slurm_acct_gather_profile.h\"\n#include \"src/common/gres.h\"\n\n#define DEFAULT_RSMI_TIMEOUT 10\n#define DEFAULT_RSMI_FREQ 30\n\n/*\n * These variables are required by the generic plugin interface.  If they\n * are not found in the plugin, the plugin loader will ignore it.\n *\n * plugin_name - a string giving a human-readable description of the\n * plugin.  There is no maximum length, but the symbol must refer to\n * a valid string.\n *\n * plugin_type - a string suggesting the type of the plugin or its\n * applicability to a particular form of data or method of data handling.\n * If the low-level plugin API is used, the contents of this string are\n * unimportant and may be anything.  Slurm uses the higher-level plugin\n * interface which requires this string to be of the form\n *\n *\t<application>/<method>\n *\n * where <application> is a description of the intended application of\n * the plugin (e.g., \"jobacct\" for Slurm job completion logging) and <method>\n * is a description of how this plugin satisfies that application.  Slurm will\n * only load job completion logging plugins if the plugin_type string has a\n * prefix of \"jobacct/\".\n *\n * plugin_version - an unsigned 32-bit integer containing the Slurm version\n * (major.minor.micro combined into a single number).\n */\nconst char plugin_name[] = \"AcctGatherEnergy rsmi plugin\";\nconst char plugin_type[] = \"acct_gather_energy/rsmi\";\nconst uint32_t plugin_version = SLURM_VERSION_NUMBER;\n\n// array of struct to track the status of a GPU\ntypedef struct {\n\tuint32_t last_update_watt;\n\ttime_t last_update_time;\n\ttime_t previous_update_time;\n\tacct_gather_energy_t energy;\n} gpu_status_t;\n\n/*\n * internal variables\n */\nstatic int context_id = -1;\n// copy of usable gpus and is only used by stepd for a job\nstatic bitstr_t\t*saved_usable_gpus = NULL;\n\nstatic gpu_status_t *gpus = NULL;\nstatic uint16_t gpus_len = 0;\nstatic uint64_t *start_current_energies = NULL;\n\nstatic int dataset_id = -1; // id of the dataset for profile data\n\nstatic uint64_t debug_flags = 0;\nstatic bool flag_energy_accounting_shutdown = false;\nstatic bool flag_thread_started = false;\nstatic pthread_mutex_t rsmi_mutex = PTHREAD_MUTEX_INITIALIZER;\nstatic pthread_cond_t rsmi_cond = PTHREAD_COND_INITIALIZER;\nstatic pthread_mutex_t launch_mutex = PTHREAD_MUTEX_INITIALIZER;\nstatic pthread_cond_t launch_cond = PTHREAD_COND_INITIALIZER;\n\nstatic stepd_step_rec_t *job = NULL;\n\npthread_t thread_rsmi_id_launcher = 0;\npthread_t thread_rsmi_id_run = 0;\n\n/*\n * Check running profile\n */\nstatic int _running_profile(void)\n{\n\tstatic bool run = false;\n\tstatic uint32_t profile_opt = ACCT_GATHER_PROFILE_NOT_SET;\n\n\tif (profile_opt == ACCT_GATHER_PROFILE_NOT_SET) {\n\t\tacct_gather_profile_g_get(ACCT_GATHER_PROFILE_RUNNING,\n\t\t\t\t\t  &profile_opt);\n\t\tif (profile_opt & ACCT_GATHER_PROFILE_ENERGY)\n\t\t\trun = true;\n\t}\n\n\treturn run;\n}\n\n/*\n * Send profile\n */\nstatic int _send_profile(void)\n{\n\tuint16_t i;\n\tuint64_t data[gpus_len];\n\ttime_t last_time = gpus[gpus_len - 1].last_update_time;\n\n\tif (!_running_profile())\n\t\treturn SLURM_SUCCESS;\n\n\tif (dataset_id < 0) {\n\t\tacct_gather_profile_dataset_t dataset[gpus_len + 1];\n\n\t\tfor (i = 0; i < gpus_len; i++) {\n\t\t\tdataset[i].name = xstrdup_printf(\"GPU%dPower\", i);\n\t\t\tdataset[i].type = PROFILE_FIELD_UINT64;\n\t\t}\n\t\tdataset[i].name = NULL;\n\t\tdataset[i].type = PROFILE_FIELD_NOT_SET;\n\t\tdataset_id = acct_gather_profile_g_create_dataset(\n\t\t\t\"Energy\", NO_PARENT, dataset);\n\t\tfor (i = 0; i < gpus_len; i++)\n\t\t\txfree(dataset[i].name);\n\t\tif (debug_flags & DEBUG_FLAG_ENERGY)\n\t\t\tdebug(\"Energy: dataset created (id = %d)\", dataset_id);\n\t\tif (dataset_id == SLURM_ERROR) {\n\t\t\terror(\"Energy: Failed to create the dataset\");\n\t\t\treturn SLURM_ERROR;\n\t\t}\n\t}\n\n\t/* pack an array of uint64_t with current power of gpus */\n\tmemset(data, 0, sizeof(data));\n\tfor (i = 0; i < gpus_len; i++) {\n\t\tdata[i] = gpus[i].energy.current_watts;\n\t\tlast_time = gpus[i].energy.poll_time;\n\t}\n\n\tif (debug_flags & DEBUG_FLAG_PROFILE) {\n\t\tfor (i = 0; i < gpus_len; i++) {\n\t\t\tinfo(\"PROFILE-Energy: GPU%dPower=%\"PRIu64\"\",\n\t\t\t     i, data[i]);\n\t\t}\n\t}\n\treturn acct_gather_profile_g_add_sample_data(dataset_id, (void *)data,\n\t\t\t\t\t\t     last_time);\n}\n\n/*\n * _read_rsmi_value read current average watts and update last_update_watt\n *\n * dv_ind         (IN) The device index\n * energy         (IN) A pointer to gpu_status_t structure\n */\nstatic int _read_rsmi_value(uint32_t dv_ind, gpu_status_t *gpu)\n{\n\tconst char *status_string;\n\tuint64_t curr_milli_watts;\n\trsmi_status_t rsmi_rc = rsmi_dev_power_ave_get(\n\t\tdv_ind, 0, &curr_milli_watts);\n\n\tif (rsmi_rc != RSMI_STATUS_SUCCESS) {\n\t\trsmi_rc = rsmi_status_string(rsmi_rc, &status_string);\n\t\terror(\"RSMI: Failed to get power: %s\", status_string);\n\t\tgpu->energy.current_watts = NO_VAL;\n\t\treturn SLURM_ERROR;\n\t}\n\n\tgpu->last_update_watt = curr_milli_watts/1000000;\n\tgpu->previous_update_time = gpu->last_update_time;\n\tgpu->last_update_time = time(NULL);\n\n\treturn SLURM_SUCCESS;\n}\n\n/*\n * _get_additional_consumption computes consumption between 2 times\n * time0\t(IN) Previous time\n * time1\t(IN) Current time\n * watt0\t(IN) Previous watts\n * watt1\t(IN) Current watts\n */\nstatic uint64_t _get_additional_consumption(time_t time0, time_t time1,\n\t\t\t\t\t    uint32_t watt0, uint32_t watt1)\n{\n\treturn (uint64_t) ((time1 - time0)*(watt1 + watt0)/2);\n}\n\n/* updates the given energy according to the last watts reading of the gpu\n * gpu\t\t(IN/OUT) A pointer to gpu_status_t structure\n * readings\t(IN) readings to calculate average watts\n */\nstatic void _update_energy(gpu_status_t *gpu, uint32_t readings)\n{\n\tuint32_t prev_watts;\n\tacct_gather_energy_t *e = &gpu->energy;\n\n\tif (e->current_watts && (e->current_watts != NO_VAL)) {\n\t\tprev_watts = e->current_watts;\n\t\te->ave_watts = ((e->ave_watts * readings) +\n\t\t\t\te->current_watts) / (readings + 1);\n\t\te->current_watts = gpu->last_update_watt;\n\t\tif (gpu->previous_update_time == 0)\n\t\t\te->base_consumed_energy = 0;\n\t\telse\n\t\t\te->base_consumed_energy =\n\t\t\t\t_get_additional_consumption(\n\t\t\t\t\tgpu->previous_update_time,\n\t\t\t\t\tgpu->last_update_time,\n\t\t\t\t\tprev_watts,\n\t\t\t\t\te->current_watts);\n\t\te->previous_consumed_energy = e->consumed_energy;\n\t\te->consumed_energy += e->base_consumed_energy;\n\t} else {\n\t\te->consumed_energy = 0;\n\t\te->ave_watts = 0;\n\t\te->current_watts = gpu->last_update_watt;\n\t}\n\te->poll_time = time(NULL);\n}\n\n/*\n * _thread_update_node_energy calls _read_rsmi_values and updates all values\n * for node consumption\n */\nstatic int _thread_update_node_energy(void)\n{\n\tint rc = SLURM_SUCCESS;\n\tuint16_t i;\n\tstatic uint32_t readings = 0;\n\n\tfor (i = 0; i < gpus_len; i++) {\n\t\trc = _read_rsmi_value(i, &gpus[i]);\n\t\tif (rc == SLURM_SUCCESS) {\n\t\t\t_update_energy(&gpus[i], readings);\n\t\t}\n\t}\n\treadings++;\n\n\tif (debug_flags & DEBUG_FLAG_ENERGY) {\n\t\tfor (i = 0; i < gpus_len; i++)\n\t\t\tinfo(\"rsmi-thread: gpu %u current_watts: %u, consumed %\"PRIu64\" Joules %\"PRIu64\" new, ave watts %u\",\n\t\t\t     i,\n\t\t\t     gpus[i].energy.current_watts,\n\t\t\t     gpus[i].energy.consumed_energy,\n\t\t\t     gpus[i].energy.base_consumed_energy,\n\t\t\t     gpus[i].energy.ave_watts);\n\t}\n\n\treturn rc;\n}\n\n/* Get the total # of GPUs in the system\n *\n * device_count\t(OUT) Number of available GPU devices\n */\nstatic void _rsmi_get_device_count(unsigned int *device_count)\n{\n\tconst char *status_string;\n\trsmi_status_t rsmi_rc = rsmi_num_monitor_devices(device_count);\n\n\tif (rsmi_rc != RSMI_STATUS_SUCCESS) {\n\t\trsmi_rc = rsmi_status_string(rsmi_rc, &status_string);\n\t\terror(\"RSMI: Failed to get device count: %s\", status_string);\n\t\t*device_count = 0;\n\t}\n}\n\n/*\n * _thread_init initializes values and conf for the rsmi thread\n */\nstatic int _thread_init(void)\n{\n\n\tif (gpus_len && gpus) {\n\t\tif (debug_flags & DEBUG_FLAG_ENERGY)\n\t\t\tinfo(\"%s thread init\", plugin_name);\n\t\treturn SLURM_SUCCESS;\n\t} else {\n\t\terror(\"%s thread init failed, no GPU available\", plugin_name);\n\t\treturn SLURM_ERROR;\n\t}\n}\n\n/*\n * _thread_rsmi_run is the thread calling rsmi periodically\n * and read the energy values from the AMD GPUs\n */\nstatic void *_thread_rsmi_run(void *no_data)\n{\n\tstruct timeval tvnow;\n\tstruct timespec abs;\n\n\tflag_energy_accounting_shutdown = false;\n\tif (debug_flags & DEBUG_FLAG_ENERGY)\n\t\tinfo(\"rsmi-thread: launched\");\n\n\t(void) pthread_setcancelstate(PTHREAD_CANCEL_ENABLE, NULL);\n\t(void) pthread_setcanceltype(PTHREAD_CANCEL_ASYNCHRONOUS, NULL);\n\n\tslurm_mutex_lock(&rsmi_mutex);\n\tif (_thread_init() != SLURM_SUCCESS) {\n\t\tif (debug_flags & DEBUG_FLAG_ENERGY)\n\t\t\tinfo(\"rsmi-thread: aborted\");\n\t\tslurm_mutex_unlock(&rsmi_mutex);\n\n\t\tslurm_mutex_lock(&launch_mutex);\n\t\tslurm_cond_signal(&launch_cond);\n\t\tslurm_mutex_unlock(&launch_mutex);\n\n\t\treturn NULL;\n\t}\n\n\t(void) pthread_setcanceltype(PTHREAD_CANCEL_DEFERRED, NULL);\n\n\tslurm_mutex_unlock(&rsmi_mutex);\n\tflag_thread_started = true;\n\n\tslurm_mutex_lock(&launch_mutex);\n\tslurm_cond_signal(&launch_cond);\n\tslurm_mutex_unlock(&launch_mutex);\n\n\t/* setup timer */\n\tgettimeofday(&tvnow, NULL);\n\tabs.tv_sec = tvnow.tv_sec;\n\tabs.tv_nsec = tvnow.tv_usec * 1000;\n\n\t//loop until slurm stop\n\twhile (!flag_energy_accounting_shutdown) {\n\t\tslurm_mutex_lock(&rsmi_mutex);\n\n\t\t_thread_update_node_energy();\n\n\t\t/* Sleep until the next time. */\n\t\tabs.tv_sec += DEFAULT_RSMI_FREQ;\n\t\tslurm_cond_timedwait(&rsmi_cond, &rsmi_mutex, &abs);\n\n\t\tslurm_mutex_unlock(&rsmi_mutex);\n\t}\n\n\tif (debug_flags & DEBUG_FLAG_ENERGY)\n\t\tinfo(\"rsmi-thread: ended\");\n\n\treturn NULL;\n}\n\n/*\n * _thread_launcher is the thread that launches rsmi thread\n */\nstatic void *_thread_launcher(void *no_data)\n{\n\tstruct timeval tvnow;\n\tstruct timespec abs;\n\n\tslurm_thread_create(&thread_rsmi_id_run, _thread_rsmi_run, NULL);\n\n\t/* setup timer */\n\tgettimeofday(&tvnow, NULL);\n\tabs.tv_sec = tvnow.tv_sec + DEFAULT_RSMI_TIMEOUT;\n\tabs.tv_nsec = tvnow.tv_usec * 1000;\n\n\tslurm_mutex_lock(&launch_mutex);\n\tslurm_cond_timedwait(&launch_cond, &launch_mutex, &abs);\n\tslurm_mutex_unlock(&launch_mutex);\n\n\tif (!flag_thread_started) {\n\t\terror(\"%s threads failed to start in a timely manner\",\n\t\t      plugin_name);\n\n\t\tflag_energy_accounting_shutdown = true;\n\n\t\t/*\n\t\t * It is a known thing we can hang up on RSMI calls cancel if\n\t\t * we must.\n\t\t */\n\t\tpthread_cancel(thread_rsmi_id_run);\n\n\t\t/*\n\t\t * Unlock just to make sure since we could have canceled the\n\t\t * thread while in the lock.\n\t\t */\n\t\tslurm_mutex_unlock(&rsmi_mutex);\n\t}\n\n\treturn NULL;\n}\n\nstatic void _add_energy(acct_gather_energy_t *energy_tot,\n\t\t\tacct_gather_energy_t *energy_new,\n\t\t\tint gpu_num)\n{\n\tif (energy_new->current_watts == NO_VAL)\n\t\treturn;\n\n\tenergy_tot->base_consumed_energy += energy_new->base_consumed_energy;\n\tenergy_tot->ave_watts += energy_new->ave_watts;\n\tenergy_tot->consumed_energy += energy_new->consumed_energy;\n\tenergy_tot->current_watts += energy_new->current_watts;\n\tenergy_tot->previous_consumed_energy +=\n\t\tenergy_new->previous_consumed_energy;\n\t/*\n\t * node poll_time is computed as the oldest poll_time of\n\t * the gpus\n\t */\n\tif (!energy_tot->poll_time ||\n\t    (energy_tot->poll_time > energy_new->poll_time))\n\t\tenergy_tot->poll_time = energy_new->poll_time;\n\tif (debug_flags & DEBUG_FLAG_ENERGY)\n\t\tinfo(\"%s: gpu: %d, current_watts: %u, consumed %\"PRIu64\" Joules %\"PRIu64\" new, ave watts %u\",\n\t\t     __func__,\n\t\t     gpu_num,\n\t\t     energy_new->current_watts,\n\t\t     energy_new->consumed_energy,\n\t\t     energy_new->base_consumed_energy,\n\t\t     energy_new->ave_watts);\n}\n\n/* Get the energy for a job\n * energy\t(IN) a pointer to a acct_gather_energy_t structure\n */\nstatic void _get_node_energy_up(acct_gather_energy_t *energy)\n{\n\tslurm_cgroup_conf_t *cg_conf;\n\tbool task_cgroup = false;\n\tbool constrained_devices = false;\n\tbool cgroups_active = false;\n\tchar *task_plugin_type = NULL;\n\n\tuint16_t i;\n\n\t// Check if GPUs are constrained by cgroups\n\tslurm_mutex_lock(&xcgroup_config_read_mutex);\n\tcg_conf = xcgroup_get_slurm_cgroup_conf();\n\tif (cg_conf && cg_conf->constrain_devices)\n\t\tconstrained_devices = true;\n\tslurm_mutex_unlock(&xcgroup_config_read_mutex);\n\n\t// Check if task/cgroup plugin is loaded\n\ttask_plugin_type = slurm_get_task_plugin();\n\tif (xstrstr(task_plugin_type, \"cgroup\"))\n\t\ttask_cgroup = true;\n\txfree(task_plugin_type);\n\n\t// If both of these are true, then GPUs will be constrained\n\tif (constrained_devices && task_cgroup) {\n\t\tcgroups_active = true;\n\t\tif (debug_flags & DEBUG_FLAG_ENERGY)\n\t\t\tdebug2(\"%s: cgroups are configured.\", __func__);\n\t} else {\n\t\tif (debug_flags & DEBUG_FLAG_ENERGY)\n\t\t\tdebug2(\"%s: cgroups are NOT configured.\", __func__);\n\t}\n\n\t// sum the energy of all gpus for this job\n\tmemset(energy, 0, sizeof(acct_gather_energy_t));\n\tfor (i = 0; i < gpus_len; i++) {\n\t\t// Skip if not using cgroups, or bit is not set\n\t\tif (cgroups_active && !bit_test(saved_usable_gpus, i)) {\n\t\t\tif (debug_flags & DEBUG_FLAG_ENERGY)\n\t\t\t\tdebug2(\"Passing over gpu %u\", i);\n\t\t\tcontinue;\n\t\t}\n\t\t_add_energy(energy, &gpus[i].energy, i);\n\t}\n\tif (debug_flags & DEBUG_FLAG_ENERGY)\n\t\tinfo(\"%s: current_watts: %u, consumed %\"PRIu64\" Joules %\"PRIu64\" new, ave watts %u\",\n\t\t     __func__,\n\t\t     energy->current_watts,\n\t\t     energy->consumed_energy,\n\t\t     energy->base_consumed_energy,\n\t\t     energy->ave_watts);\n}\n\n/* Get the energy for a node\n * energy\t(IN) a pointer to a acct_gather_energy_t structure\n */\nstatic void _get_node_energy(acct_gather_energy_t *energy)\n{\n\tuint16_t i;\n\n\t// sum the energy of all gpus for this node\n\tmemset(energy, 0, sizeof(acct_gather_energy_t));\n\tfor (i = 0; i < gpus_len; i++)\n\t\t_add_energy(energy, &gpus[i].energy, i);\n\tif (debug_flags & DEBUG_FLAG_ENERGY)\n\t\tinfo(\"%s: current_watts: %u, consumed %\"PRIu64\" Joules %\"PRIu64\" new, ave watts %u\",\n\t\t     __func__,\n\t\t     energy->current_watts,\n\t\t     energy->consumed_energy,\n\t\t     energy->base_consumed_energy,\n\t\t     energy->ave_watts);\n}\n\n/* Get the energy in joules for a job\n * delta\t(IN) Use cache if data is newer than this in seconds\n */\nstatic int _get_joules_task(uint16_t delta)\n{\n\ttime_t now = time(NULL);\n\tstatic bool stepd_first = true;\n\tuint64_t adjustment = 0;\n\tuint16_t i;\n\tacct_gather_energy_t *new, *old;\n\n\t/* gpus list */\n\tacct_gather_energy_t *energies = NULL;\n\tuint16_t gpu_cnt = 0;\n\n\txassert(context_id != -1);\n\n\tif (slurm_get_node_energy(\n\t\t    NULL, context_id, delta, &gpu_cnt, &energies)) {\n\t\terror(\"%s: can't get info from slurmd\", __func__);\n\t\treturn SLURM_ERROR;\n\t}\n\tif (stepd_first) {\n\t\tgpus_len = gpu_cnt;\n\t\tgpus = xcalloc(sizeof(gpu_status_t), gpus_len);\n\t\tstart_current_energies = xcalloc(sizeof(uint64_t), gpus_len);\n\t}\n\n\tif (gpu_cnt != gpus_len) {\n\t\terror(\"%s: received %u sensors, %u expected\",\n\t\t      __func__, gpu_cnt, gpus_len);\n\t\tacct_gather_energy_destroy(energies);\n\t\treturn SLURM_ERROR;\n\t}\n\n\tfor (i = 0; i < gpu_cnt; i++) {\n\t\tnew = &energies[i];\n\t\told = &gpus[i].energy;\n\t\tnew->previous_consumed_energy = old->consumed_energy;\n\n\t\tadjustment = _get_additional_consumption(\n\t\t\tnew->poll_time, now,\n\t\t\tnew->current_watts,\n\t\t\tnew->current_watts);\n\n\t\tif (!stepd_first) {\n\t\t\tnew->consumed_energy -= start_current_energies[i];\n\t\t\tnew->base_consumed_energy = adjustment +\n\t\t\t\t(new->consumed_energy - old->consumed_energy);\n\t\t} else {\n\t\t\t/*\n\t\t\t * This is just for the step, so take all the pervious\n\t\t\t * consumption out of the mix.\n\t\t\t */\n\t\t\tstart_current_energies[i] =\n\t\t\t\tnew->consumed_energy + adjustment;\n\t\t\tnew->base_consumed_energy = 0;\n\t\t}\n\n\t\tnew->consumed_energy = new->previous_consumed_energy\n\t\t\t+ new->base_consumed_energy;\n\t\tmemcpy(old, new, sizeof(acct_gather_energy_t));\n\n\t\tif (debug_flags & DEBUG_FLAG_ENERGY)\n\t\t\tinfo(\"%s: consumed %\"PRIu64\" Joules (received %\"PRIu64\"(%u watts) from slurmd)\",\n\t\t\t     __func__,\n\t\t\t     new->consumed_energy,\n\t\t\t     new->base_consumed_energy,\n\t\t\t     new->current_watts);\n\t}\n\n\tacct_gather_energy_destroy(energies);\n\n\tstepd_first = false;\n\n\treturn SLURM_SUCCESS;\n}\n\n/*\n * init() is called when the plugin is loaded, before any other functions\n * are called.  Put global initialization here.\n */\nextern int init(void)\n{\n\tif (!dlopen(\"librocm_smi64.so\", RTLD_NOW | RTLD_GLOBAL))\n\t\tfatal(\"RSMI configured, but wasn't found.\");\n\n\tdebug_flags = slurm_get_debug_flags();\n\n\t/* put anything that requires the .conf being read in\n\t   acct_gather_energy_p_conf_parse\n\t*/\n\n\trsmi_init(0);\n\n\treturn SLURM_SUCCESS;\n}\n\n/*\n * fini() is called when the plugin exits.\n */\nextern int fini(void)\n{\n\tif (!running_in_slurmdstepd())\n\t\treturn SLURM_SUCCESS;\n\n\tflag_energy_accounting_shutdown = true;\n\n\tslurm_mutex_lock(&launch_mutex);\n\t/* clean up the launch thread */\n\tslurm_cond_signal(&launch_cond);\n\tslurm_mutex_unlock(&launch_mutex);\n\n\tif (thread_rsmi_id_launcher)\n\t\tpthread_join(thread_rsmi_id_launcher, NULL);\n\n\tslurm_mutex_lock(&rsmi_mutex);\n\t/* clean up the run thread */\n\tslurm_cond_signal(&rsmi_cond);\n\tslurm_mutex_unlock(&rsmi_mutex);\n\n\tif (thread_rsmi_id_run)\n\t\tpthread_join(thread_rsmi_id_run, NULL);\n\n\txfree(gpus);\n\txfree(start_current_energies);\n\tFREE_NULL_BITMAP(saved_usable_gpus);\n\n\trsmi_shut_down();\n\treturn SLURM_SUCCESS;\n}\n\nextern int acct_gather_energy_p_update_node_energy(void)\n{\n\tint rc = SLURM_SUCCESS;\n\txassert(running_in_slurmdstepd());\n\n\treturn rc;\n}\n\nextern int acct_gather_energy_p_get_data(enum acct_energy_type data_type,\n\t\t\t\t\t void *data)\n{\n\tuint16_t i;\n\tint rc = SLURM_SUCCESS;\n\tacct_gather_energy_t *energy = (acct_gather_energy_t *)data;\n\ttime_t *last_poll = (time_t *)data;\n\tuint16_t *gpu_cnt = (uint16_t *)data;\n\n\txassert(running_in_slurmdstepd());\n\n\tswitch (data_type) {\n\tcase ENERGY_DATA_NODE_ENERGY_UP:\n\t\tslurm_mutex_lock(&rsmi_mutex);\n\t\tif (running_in_slurmd()) {\n\t\t\tif (_thread_init() == SLURM_SUCCESS) {\n\t\t\t\t_thread_update_node_energy();\n\t\t\t\t_get_node_energy(energy);\n\t\t\t}\n\t\t} else {\n\t\t\t_get_joules_task(10);\n\t\t\t_get_node_energy_up(energy);\n\t\t}\n\t\tslurm_mutex_unlock(&rsmi_mutex);\n\t\tbreak;\n\tcase ENERGY_DATA_NODE_ENERGY:\n\t\tslurm_mutex_lock(&rsmi_mutex);\n\t\t_get_node_energy(energy);\n\t\tslurm_mutex_unlock(&rsmi_mutex);\n\t\tbreak;\n\tcase ENERGY_DATA_LAST_POLL:\n\t\tslurm_mutex_lock(&rsmi_mutex);\n\t\t*last_poll = gpus[gpus_len-1].last_update_time;\n\t\tslurm_mutex_unlock(&rsmi_mutex);\n\t\tbreak;\n\tcase ENERGY_DATA_SENSOR_CNT:\n\t\tslurm_mutex_lock(&rsmi_mutex);\n\t\t*gpu_cnt = gpus_len;\n\t\tslurm_mutex_unlock(&rsmi_mutex);\n\t\tbreak;\n\tcase ENERGY_DATA_STRUCT:\n\t\tslurm_mutex_lock(&rsmi_mutex);\n\t\tfor (i = 0; i < gpus_len; i++)\n\t\t\tmemcpy(&energy[i], &gpus[i].energy,\n\t\t\t       sizeof(acct_gather_energy_t));\n\t\tslurm_mutex_unlock(&rsmi_mutex);\n\t\tbreak;\n\tcase ENERGY_DATA_JOULES_TASK:\n\t\tslurm_mutex_lock(&rsmi_mutex);\n\t\tif (running_in_slurmd()) {\n\t\t\tif (_thread_init() == SLURM_SUCCESS)\n\t\t\t\t_thread_update_node_energy();\n\t\t} else {\n\t\t\t_get_joules_task(10);\n\t\t}\n\t\tfor (i = 0; i < gpus_len; ++i)\n\t\t\tmemcpy(&energy[i], &gpus[i].energy,\n\t\t\t       sizeof(acct_gather_energy_t));\n\t\tslurm_mutex_unlock(&rsmi_mutex);\n\t\tbreak;\n\tdefault:\n\t\terror(\"%s: unknown enum %d\",\n\t\t      __func__, data_type);\n\t\trc = SLURM_ERROR;\n\t\tbreak;\n\t}\n\treturn rc;\n}\n\nextern int acct_gather_energy_p_set_data(enum acct_energy_type data_type,\n\t\t\t\t\t void *data)\n{\n\tint rc = SLURM_SUCCESS;\n\tint *delta = (int *)data;\n\n\txassert(running_in_slurmdstepd());\n\n\tswitch (data_type) {\n\tcase ENERGY_DATA_RECONFIG:\n\t\tdebug_flags = slurm_get_debug_flags();\n\t\tbreak;\n\tcase ENERGY_DATA_PROFILE:\n\t\tslurm_mutex_lock(&rsmi_mutex);\n\t\t_get_joules_task(*delta);\n\t\t_send_profile();\n\t\tslurm_mutex_unlock(&rsmi_mutex);\n\t\tbreak;\n\tcase ENERGY_DATA_STEP_PTR:\n\t{\n\t\tbitstr_t *usable_gpus = NULL;\n\n\t\t/* set global job if needed later */\n\t\tjob = (stepd_step_rec_t *)data;\n\n\t\trc = gres_get_step_info(job->step_gres_list, \"gpu\", 0,\n\t\t\t\t\tGRES_STEP_DATA_BITMAP,\n\t\t\t\t\t&usable_gpus);\n\t\tif (rc == SLURM_SUCCESS) {\n\t\t\t/*\n\t\t\t * Save a copy of the GPUs affected, so we can\n\t\t\t * reset things afterwards\n\t\t\t */\n\t\t\tFREE_NULL_BITMAP(saved_usable_gpus);\n\t\t\tsaved_usable_gpus = usable_gpus;\n\t\t\tusable_gpus = NULL;\n\t\t}\n\t\tif (debug_flags & DEBUG_FLAG_ENERGY)\n\t\t\tinfo(\"usable_gpus = %d of %ld\",\n\t\t\t     bit_set_count(saved_usable_gpus),\n\t\t\t     bit_size(saved_usable_gpus));\n\t\tbreak;\n\t}\n\tdefault:\n\t\terror(\"%s: unknown enum %d\",\n\t\t      __func__, data_type);\n\t\trc = SLURM_ERROR;\n\t\tbreak;\n\t}\n\treturn rc;\n}\n\nextern void acct_gather_energy_p_conf_options(s_p_options_t **full_options,\n\t\t\t\t\t      int *full_options_cnt)\n{\n\treturn;\n}\n\nextern void acct_gather_energy_p_conf_set(int context_id_in,\n\t\t\t\t\t  s_p_hashtbl_t *tbl)\n{\n\tstatic bool flag_init = false;\n\n\tcontext_id = context_id_in;\n\n\tif (!running_in_slurmdstepd())\n\t\treturn;\n\n\tif (!flag_init) {\n\t\tflag_init = true;\n\t\tif (running_in_slurmd()) {\n\t\t\t_rsmi_get_device_count((unsigned int *)&gpus_len);\n\t\t\tif (gpus_len) {\n\t\t\t\tgpus = xcalloc(sizeof(gpu_status_t), gpus_len);\n\t\t\t\tslurm_thread_create(&thread_rsmi_id_launcher,\n\t\t\t\t\t\t    _thread_launcher, NULL);\n\t\t\t}\n\t\t\tif (debug_flags & DEBUG_FLAG_ENERGY)\n\t\t\t\tinfo(\"%s thread launched\", plugin_name);\n\t\t} else\n\t\t\t_get_joules_task(0);\n\n\t}\n\n\tdebug(\"%s loaded\", plugin_name);\n\n\treturn;\n}\n\nextern void acct_gather_energy_p_conf_values(List *data)\n{\n\treturn;\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/src/plugins/mpi/pmi2/setup.c": "/*****************************************************************************\\\n **  setup.c - PMI2 server setup\n *****************************************************************************\n *  Copyright (C) 2011-2012 National University of Defense Technology.\n *  Written by Hongjia Cao <hjcao@nudt.edu.cn>.\n *  All rights reserved.\n *  Portions copyright (C) 2015 Mellanox Technologies Inc.\n *  Written by Artem Y. Polyakov <artemp@mellanox.com>.\n *  All rights reserved.\n *  Portions copyright (C) 2017 SchedMD LLC.\n *\n *  This file is part of Slurm, a resource management program.\n *  For details, see <https://slurm.schedmd.com/>.\n *  Please also read the included file: DISCLAIMER.\n *\n *  Slurm is free software; you can redistribute it and/or modify it under\n *  the terms of the GNU General Public License as published by the Free\n *  Software Foundation; either version 2 of the License, or (at your option)\n *  any later version.\n *\n *  In addition, as a special exception, the copyright holders give permission\n *  to link the code of portions of this program with the OpenSSL library under\n *  certain conditions as described in each individual source file, and\n *  distribute linked combinations including the two. You must obey the GNU\n *  General Public License in all respects for all of the code used other than\n *  OpenSSL. If you modify file(s) with this exception, you may extend this\n *  exception to your version of the file(s), but you are not obligated to do\n *  so. If you do not wish to do so, delete this exception statement from your\n *  version.  If you delete this exception statement from all source files in\n *  the program, then also delete it here.\n *\n *  Slurm is distributed in the hope that it will be useful, but WITHOUT ANY\n *  WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n *  FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more\n *  details.\n *\n *  You should have received a copy of the GNU General Public License along\n *  with Slurm; if not, write to the Free Software Foundation, Inc.,\n *  51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA.\n\\*****************************************************************************/\n\n#if defined(__FreeBSD__)\n#include <sys/socket.h>\t/* AF_INET */\n#endif\n\n#include <dlfcn.h>\n#include <fcntl.h>\n#include <poll.h>\n#include <signal.h>\n#include <stdlib.h>\n#include <string.h>\n#include <sys/types.h>\n#include <sys/un.h>\n#include <unistd.h>\n\n#include \"src/common/slurm_xlator.h\"\n#include \"src/common/net.h\"\n#include \"src/common/proc_args.h\"\n#include \"src/common/slurm_mpi.h\"\n#include \"src/common/xstring.h\"\n#include \"src/slurmd/slurmstepd/slurmstepd_job.h\"\n#include \"src/slurmd/common/reverse_tree_math.h\"\n\n#include \"setup.h\"\n#include \"tree.h\"\n#include \"pmi.h\"\n#include \"spawn.h\"\n#include \"kvs.h\"\n#include \"ring.h\"\n\n#define PMI2_SOCK_ADDR_FMT \"%s/sock.pmi2.%u.%u\"\n\n\nextern char **environ;\n\nstatic bool run_in_stepd = 0;\n\nint  tree_sock;\nint *task_socks;\nchar tree_sock_addr[128];\npmi2_job_info_t job_info;\npmi2_tree_info_t tree_info;\n\nstatic char *fmt_tree_sock_addr = NULL;\n\nextern bool\nin_stepd(void)\n{\n\treturn run_in_stepd;\n}\n\nstatic void\n_remove_tree_sock(void)\n{\n\tif (fmt_tree_sock_addr) {\n\t\tunlink(fmt_tree_sock_addr);\n\t\txfree(fmt_tree_sock_addr);\n\t}\n}\n\nstatic int\n_setup_stepd_job_info(const stepd_step_rec_t *job, char ***env)\n{\n\tchar *p;\n\tint i;\n\n\tmemset(&job_info, 0, sizeof(job_info));\n\n\tif (job->het_job_id && (job->het_job_id != NO_VAL)) {\n\t\tjob_info.jobid  = job->het_job_id;\n\t\tjob_info.stepid = job->stepid;\n\t\tjob_info.nnodes = job->het_job_nnodes;\n\t\tjob_info.nodeid = job->nodeid + job->het_job_node_offset;\n\t\tjob_info.ntasks = job->het_job_ntasks;\n\t\tjob_info.ltasks = job->node_tasks;\n\t\tjob_info.gtids = xmalloc(job_info.ltasks * sizeof(uint32_t));\n\t\tfor (i = 0; i < job_info.ltasks; i ++) {\n\t\t\tjob_info.gtids[i] = job->task[i]->gtid +\n\t\t\t\t\t    job->het_job_task_offset;\n\t\t}\n\t} else {\n\t\tjob_info.jobid  = job->jobid;\n\t\tjob_info.stepid = job->stepid;\n\t\tjob_info.nnodes = job->nnodes;\n\t\tjob_info.nodeid = job->nodeid;\n\t\tjob_info.ntasks = job->ntasks;\n\t\tjob_info.ltasks = job->node_tasks;\n\t\tjob_info.gtids = xmalloc(job_info.ltasks * sizeof(uint32_t));\n\t\tfor (i = 0; i < job_info.ltasks; i ++) {\n\t\t\tjob_info.gtids[i] = job->task[i]->gtid;\n\t\t}\n\t}\n\n\tp = getenvp(*env, PMI2_PMI_DEBUGGED_ENV);\n\tif (p) {\n\t\tjob_info.pmi_debugged = atoi(p);\n\t} else {\n\t\tjob_info.pmi_debugged = 0;\n\t}\n\tp = getenvp(*env, PMI2_SPAWN_SEQ_ENV);\n\tif (p) { \t\t/* spawned */\n\t\tjob_info.spawn_seq = atoi(p);\n\t\tunsetenvp(*env, PMI2_SPAWN_SEQ_ENV);\n\t\tp = getenvp(*env, PMI2_SPAWNER_JOBID_ENV);\n\t\tjob_info.spawner_jobid = xstrdup(p);\n\t\tunsetenvp(*env, PMI2_SPAWNER_JOBID_ENV);\n\t} else {\n\t\tjob_info.spawn_seq = 0;\n\t\tjob_info.spawner_jobid = NULL;\n\t}\n\tp = getenvp(*env, PMI2_PMI_JOBID_ENV);\n\tif (p) {\n\t\tjob_info.pmi_jobid = xstrdup(p);\n\t\tunsetenvp(*env, PMI2_PMI_JOBID_ENV);\n\t} else {\n\t\txstrfmtcat(job_info.pmi_jobid, \"%u.%u\", job_info.jobid,\n\t\t\t   job_info.stepid);\n\t}\n\tp = getenvp(*env, PMI2_STEP_NODES_ENV);\n\tif (!p) {\n\t\terror(\"mpi/pmi2: unable to find nodes in job environment\");\n\t\treturn SLURM_ERROR;\n\t} else {\n\t\tjob_info.step_nodelist = xstrdup(p);\n\t\tunsetenvp(*env, PMI2_STEP_NODES_ENV);\n\t}\n\t/*\n\t * how to get the mapping info from stepd directly?\n\t * there is the task distribution info in the launch_tasks_request_msg_t,\n\t * but it is not stored in the stepd_step_rec_t.\n\t */\n\tp = getenvp(*env, PMI2_PROC_MAPPING_ENV);\n\tif (!p) {\n\t\terror(\"PMI2_PROC_MAPPING_ENV not found\");\n\t\treturn SLURM_ERROR;\n\t} else {\n\t\tjob_info.proc_mapping = xstrdup(p);\n\t\tunsetenvp(*env, PMI2_PROC_MAPPING_ENV);\n\t}\n\n\tjob_info.job_env = env_array_copy((const char **)*env);\n\n\tjob_info.MPIR_proctable = NULL;\n\tjob_info.srun_opt = NULL;\n\n\t/* get the SLURM_STEP_RESV_PORTS\n\t */\n\tp = getenvp(*env, SLURM_STEP_RESV_PORTS);\n\tif (!p) {\n\t\tdebug(\"%s: %s not found in env\", __func__, SLURM_STEP_RESV_PORTS);\n\t} else {\n\t\tjob_info.resv_ports = xstrdup(p);\n\t\tinfo(\"%s: SLURM_STEP_RESV_PORTS found %s\", __func__, p);\n\t}\n\treturn SLURM_SUCCESS;\n}\n\nstatic int\n_setup_stepd_tree_info(char ***env)\n{\n\thostlist_t hl;\n\tchar *srun_host;\n\tuint16_t port;\n\tchar *p;\n\tint tree_width;\n\n\t/* job info available */\n\n\tmemset(&tree_info, 0, sizeof(tree_info));\n\n\thl = hostlist_create(job_info.step_nodelist);\n\tp = hostlist_nth(hl, job_info.nodeid); /* strdup-ed */\n\ttree_info.this_node = xstrdup(p);\n\tfree(p);\n\n\t/* this only controls the upward communication tree width */\n\tp = getenvp(*env, PMI2_TREE_WIDTH_ENV);\n\tif (p) {\n\t\ttree_width = atoi(p);\n\t\tif (tree_width < 2) {\n\t\t\tinfo(\"invalid PMI2 tree width value (%d) detected. \"\n\t\t\t     \"fallback to default value.\", tree_width);\n\t\t\ttree_width = slurm_get_tree_width();\n\t\t}\n\t} else {\n\t\ttree_width = slurm_get_tree_width();\n\t}\n\n\t/* TODO: cannot launch 0 tasks on node */\n\n\t/*\n\t * In tree position calculation, root of the tree is srun with id 0.\n\t * Stepd's id will be its nodeid plus 1.\n\t */\n\treverse_tree_info(job_info.nodeid + 1, job_info.nnodes + 1,\n\t\t\t  tree_width, &tree_info.parent_id,\n\t\t\t  &tree_info.num_children, &tree_info.depth,\n\t\t\t  &tree_info.max_depth);\n\ttree_info.parent_id --;\t       /* restore real nodeid */\n\tif (tree_info.parent_id < 0) {\t/* parent is srun */\n\t\ttree_info.parent_node = NULL;\n\t} else {\n\t\tp = hostlist_nth(hl, tree_info.parent_id);\n\t\ttree_info.parent_node = xstrdup(p);\n\t\tfree(p);\n\t}\n\thostlist_destroy(hl);\n\n\ttree_info.pmi_port = 0;\t/* not used */\n\n\tsrun_host = getenvp(*env, \"SLURM_SRUN_COMM_HOST\");\n\tif (!srun_host) {\n\t\terror(\"mpi/pmi2: unable to find srun comm ifhn in env\");\n\t\treturn SLURM_ERROR;\n\t}\n\tp = getenvp(*env, PMI2_SRUN_PORT_ENV);\n\tif (!p) {\n\t\terror(\"mpi/pmi2: unable to find srun pmi2 port in env\");\n\t\treturn SLURM_ERROR;\n\t}\n\tport = atoi(p);\n\n\ttree_info.srun_addr = xmalloc(sizeof(slurm_addr_t));\n\tslurm_set_addr(tree_info.srun_addr, port, srun_host);\n\n\tunsetenvp(*env, PMI2_SRUN_PORT_ENV);\n\n\t/* init kvs seq to 0. TODO: reduce array size */\n\ttree_info.children_kvs_seq = xmalloc(sizeof(uint32_t) *\n\t\t\t\t\t     job_info.nnodes);\n\n\treturn SLURM_SUCCESS;\n}\n\n/*\n * setup sockets for slurmstepd\n */\nstatic int\n_setup_stepd_sockets(const stepd_step_rec_t *job, char ***env)\n{\n\tstruct sockaddr_un sa;\n\tint i;\n\tchar *spool;\n\n\tdebug(\"mpi/pmi2: setup sockets\");\n\n\ttree_sock = socket(AF_UNIX, SOCK_STREAM, 0);\n\tif (tree_sock < 0) {\n\t\terror(\"mpi/pmi2: failed to create tree socket: %m\");\n\t\treturn SLURM_ERROR;\n\t}\n\tsa.sun_family = PF_UNIX;\n\n\t/*\n\t * tree_sock_addr has to remain unformatted since the formatting\n\t * happens on the slurmd side\n\t */\n\tspool = slurm_get_slurmd_spooldir(NULL);\n\tsnprintf(tree_sock_addr, sizeof(tree_sock_addr), PMI2_SOCK_ADDR_FMT,\n\t\t spool, job_info.jobid, job_info.stepid);\n\t/*\n\t * Make sure we adjust for the spool dir coming in on the address to\n\t * point to the right spot.\n\t * We need to unlink this later so we need a formatted version of the\n\t * string to unlink.\n\t */\n\txstrsubstitute(spool, \"%n\", job->node_name);\n\txstrsubstitute(spool, \"%h\", job->node_name);\n\txstrfmtcat(fmt_tree_sock_addr, PMI2_SOCK_ADDR_FMT, spool,\n\t\t   job_info.jobid, job_info.stepid);\n\t/*\n\t * If socket name would be truncated, emit error and exit\n\t */\n\tif (strlen(fmt_tree_sock_addr) >= sizeof(sa.sun_path)) {\n\t\terror(\"%s: Unix socket path '%s' is too long. (%ld > %ld)\",\n\t\t      __func__, fmt_tree_sock_addr,\n\t\t      (long int)(strlen(fmt_tree_sock_addr) + 1),\n\t\t      (long int)sizeof(sa.sun_path));\n\t\txfree(spool);\n\t\txfree(fmt_tree_sock_addr);\n\t\treturn SLURM_ERROR;\n\t}\n\n\tstrlcpy(sa.sun_path, fmt_tree_sock_addr, sizeof(sa.sun_path));\n\n\tunlink(sa.sun_path);    /* remove possible old socket */\n\txfree(spool);\n\n\tif (bind(tree_sock, (struct sockaddr *)&sa, SUN_LEN(&sa)) < 0) {\n\t\terror(\"mpi/pmi2: failed to bind tree socket: %m\");\n\t\tunlink(sa.sun_path);\n\t\treturn SLURM_ERROR;\n\t}\n\tif (listen(tree_sock, 64) < 0) {\n\t\terror(\"mpi/pmi2: failed to listen tree socket: %m\");\n\t\tunlink(sa.sun_path);\n\t\treturn SLURM_ERROR;\n\t}\n\n\ttask_socks = xmalloc(2 * job->node_tasks * sizeof(int));\n\tfor (i = 0; i < job->node_tasks; i ++) {\n\t\tsocketpair(AF_UNIX, SOCK_STREAM, 0, &task_socks[i * 2]);\n\t\t/* this must be delayed after the tasks have been forked */\n/* \t\tclose(TASK_PMI_SOCK(i)); */\n\t}\n\treturn SLURM_SUCCESS;\n}\n\nstatic int\n_setup_stepd_kvs(char ***env)\n{\n\tint rc = SLURM_SUCCESS, i = 0, pp_cnt = 0;\n\tchar *p, env_key[32], *ppkey, *ppval;\n\n\tkvs_seq = 1;\n\trc = temp_kvs_init();\n\tif (rc != SLURM_SUCCESS)\n\t\treturn rc;\n\n\trc = kvs_init();\n\tif (rc != SLURM_SUCCESS)\n\t\treturn rc;\n\n\t/* preput */\n\tp = getenvp(*env, PMI2_PREPUT_CNT_ENV);\n\tif (p) {\n\t\tpp_cnt = atoi(p);\n\t}\n\n\tfor (i = 0; i < pp_cnt; i ++) {\n\t\tsnprintf(env_key, 32, PMI2_PPKEY_ENV\"%d\", i);\n\t\tp = getenvp(*env, env_key);\n\t\tppkey = p; /* getenvp will not modify p */\n\t\tsnprintf(env_key, 32, PMI2_PPVAL_ENV\"%d\", i);\n\t\tp = getenvp(*env, env_key);\n\t\tppval = p;\n\t\tkvs_put(ppkey, ppval);\n\t}\n\n\t/*\n\t * For PMI11.\n\t * A better logic would be to put PMI_process_mapping in KVS only if\n\t * the task distribution method is not \"arbitrary\", because in\n\t * \"arbitrary\" distribution the process mapping variable is not correct.\n\t * MPICH2 may deduce the clique info from the hostnames. But that\n\t * is rather costly.\n\t */\n\tkvs_put(\"PMI_process_mapping\", job_info.proc_mapping);\n\n\treturn SLURM_SUCCESS;\n}\n\nextern int\npmi2_setup_stepd(const stepd_step_rec_t *job, char ***env)\n{\n\tint rc;\n\n\trun_in_stepd = true;\n\n\t/* job info */\n\trc = _setup_stepd_job_info(job, env);\n\tif (rc != SLURM_SUCCESS)\n\t\treturn rc;\n\n\t/* tree info */\n\trc = _setup_stepd_tree_info(env);\n\tif (rc != SLURM_SUCCESS)\n\t\treturn rc;\n\n\t/* sockets */\n\trc = _setup_stepd_sockets(job, env);\n\tif (rc != SLURM_SUCCESS)\n\t\treturn rc;\n\n\t/* kvs */\n\trc = _setup_stepd_kvs(env);\n\tif (rc != SLURM_SUCCESS)\n\t\treturn rc;\n\n\t/* TODO: finalize pmix_ring state somewhere */\n\t/* initialize pmix_ring state */\n\trc = pmix_ring_init(&job_info, env);\n\tif (rc != SLURM_SUCCESS)\n\t\treturn rc;\n\n\treturn SLURM_SUCCESS;\n}\n\nextern void\npmi2_cleanup_stepd(void)\n{\n\tclose(tree_sock);\n\t_remove_tree_sock();\n}\n/**************************************************************/\n\n/* returned string should be xfree-ed by caller */\nstatic char *\n_get_proc_mapping(const mpi_plugin_client_info_t *job)\n{\n\tuint32_t node_cnt, task_cnt, task_mapped, node_task_cnt, **tids;\n\tuint32_t task_dist, block;\n\tuint16_t *tasks, *rounds;\n\tint i, start_id, end_id;\n\tchar *mapping = NULL;\n\n\tnode_cnt = job->step_layout->node_cnt;\n\ttask_cnt = job->step_layout->task_cnt;\n\ttask_dist = job->step_layout->task_dist & SLURM_DIST_STATE_BASE;\n\ttasks = job->step_layout->tasks;\n\ttids = job->step_layout->tids;\n\n\t/* for now, PMI2 only supports vector processor mapping */\n\n\tif ((task_dist & SLURM_DIST_NODEMASK) == SLURM_DIST_NODECYCLIC) {\n\t\tmapping = xstrdup(\"(vector\");\n\n\t\trounds = xmalloc (node_cnt * sizeof(uint16_t));\n\t\ttask_mapped = 0;\n\t\twhile (task_mapped < task_cnt) {\n\t\t\tstart_id = 0;\n\t\t\t/* find start_id */\n\t\t\twhile (start_id < node_cnt) {\n\t\t\t\twhile (start_id < node_cnt &&\n\t\t\t\t       ( rounds[start_id] >= tasks[start_id] ||\n\t\t\t\t\t (task_mapped !=\n\t\t\t\t\t  tids[start_id][rounds[start_id]]) )) {\n\t\t\t\t\tstart_id ++;\n\t\t\t\t}\n\t\t\t\tif (start_id >= node_cnt)\n\t\t\t\t\tbreak;\n\t\t\t\t/* block is always 1 */\n\t\t\t\t/* find end_id */\n\t\t\t\tend_id = start_id;\n\t\t\t\twhile (end_id < node_cnt &&\n\t\t\t\t       ( rounds[end_id] < tasks[end_id] &&\n\t\t\t\t\t (task_mapped ==\n\t\t\t\t\t  tids[end_id][rounds[end_id]]) )) {\n\t\t\t\t\trounds[end_id] ++;\n\t\t\t\t\ttask_mapped ++;\n\t\t\t\t\tend_id ++;\n\t\t\t\t}\n\t\t\t\txstrfmtcat(mapping, \",(%u,%u,1)\", start_id,\n\t\t\t\t\t   end_id - start_id);\n\t\t\t\tstart_id = end_id;\n\t\t\t}\n\t\t}\n\t\txfree(rounds);\n\t\txstrcat(mapping, \")\");\n\t} else if (task_dist == SLURM_DIST_ARBITRARY) {\n\t\t/*\n\t\t * MPICH2 will think that each task runs on a seperate node.\n\t\t * The program will run, but no SHM will be used for\n\t\t * communication.\n\t\t */\n\t\tmapping = xstrdup(\"(vector\");\n\t\txstrfmtcat(mapping, \",(0,%u,1)\", job->step_layout->task_cnt);\n\t\txstrcat(mapping, \")\");\n\n\t} else if (task_dist == SLURM_DIST_PLANE) {\n\t\tmapping = xstrdup(\"(vector\");\n\n\t\trounds = xmalloc (node_cnt * sizeof(uint16_t));\n\t\ttask_mapped = 0;\n\t\twhile (task_mapped < task_cnt) {\n\t\t\tstart_id = 0;\n\t\t\t/* find start_id */\n\t\t\twhile (start_id < node_cnt) {\n\t\t\t\twhile (start_id < node_cnt &&\n\t\t\t\t       ( rounds[start_id] >= tasks[start_id] ||\n\t\t\t\t\t (task_mapped !=\n\t\t\t\t\t  tids[start_id][rounds[start_id]]) )) {\n\t\t\t\t\tstart_id ++;\n\t\t\t\t}\n\t\t\t\tif (start_id >= node_cnt)\n\t\t\t\t\tbreak;\n\t\t\t\t/* find start block. block may be less\n\t\t\t\t * than plane size */\n\t\t\t\tblock = 0;\n\t\t\t\twhile (rounds[start_id] < tasks[start_id] &&\n\t\t\t\t       (task_mapped ==\n\t\t\t\t\ttids[start_id][rounds[start_id]])) {\n\t\t\t\t\tblock ++;\n\t\t\t\t\trounds[start_id] ++;\n\t\t\t\t\ttask_mapped ++;\n\t\t\t\t}\n\t\t\t\t/* find end_id */\n\t\t\t\tend_id = start_id + 1;\n\t\t\t\twhile (end_id < node_cnt &&\n\t\t\t\t       (rounds[end_id] + block - 1 <\n\t\t\t\t\ttasks[end_id])) {\n\t\t\t\t\tfor (i = 0;\n\t\t\t\t\t     i < tasks[end_id] - rounds[end_id];\n\t\t\t\t\t     i ++) {\n\t\t\t\t\t\tif (task_mapped + i !=\n\t\t\t\t\t\t    tids[end_id][rounds[end_id]\n\t\t\t\t\t\t\t\t + i]) {\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif (i != block)\n\t\t\t\t\t\tbreak;\n\t\t\t\t\trounds[end_id] += block;\n\t\t\t\t\ttask_mapped += block;\n\t\t\t\t\tend_id ++;\n\t\t\t\t}\n\t\t\t\txstrfmtcat(mapping, \",(%u,%u,%u)\", start_id,\n\t\t\t\t\t   end_id - start_id, block);\n\t\t\t\tstart_id = end_id;\n\t\t\t}\n\t\t}\n\t\txfree(rounds);\n\t\txstrcat(mapping, \")\");\n\n\t} else {\t\t/* BLOCK mode */\n\t\tmapping = xstrdup(\"(vector\");\n\t\tstart_id = 0;\n\t\tnode_task_cnt = tasks[start_id];\n\t\tfor (i = start_id + 1; i < node_cnt; i ++) {\n\t\t\tif (node_task_cnt == tasks[i])\n\t\t\t\tcontinue;\n\t\t\txstrfmtcat(mapping, \",(%u,%u,%u)\", start_id,\n\t\t\t\t   i - start_id, node_task_cnt);\n\t\t\tstart_id = i;\n\t\t\tnode_task_cnt = tasks[i];\n\t\t}\n\t\txstrfmtcat(mapping, \",(%u,%u,%u))\", start_id, i - start_id,\n\t\t\t   node_task_cnt);\n\t}\n\n\tdebug(\"mpi/pmi2: processor mapping: %s\", mapping);\n\treturn mapping;\n}\n\nstatic int\n_setup_srun_job_info(const mpi_plugin_client_info_t *job)\n{\n\tchar *p;\n\tvoid *handle = NULL, *sym = NULL;\n\n\tmemset(&job_info, 0, sizeof(job_info));\n\n\tif (job->het_job_id && (job->het_job_id != NO_VAL)) {\n\t\tjob_info.jobid  = job->het_job_id;\n\t\tjob_info.stepid = job->stepid;\n\t\tjob_info.nnodes = job->step_layout->node_cnt;\n\t\tjob_info.ntasks = job->step_layout->task_cnt;\n\t} else {\n\t\tjob_info.jobid  = job->jobid;\n\t\tjob_info.stepid = job->stepid;\n\t\tjob_info.nnodes = job->step_layout->node_cnt;\n\t\tjob_info.ntasks = job->step_layout->task_cnt;\n\t}\n\tjob_info.nodeid = -1;\t/* id in tree. not used. */\n\tjob_info.ltasks = 0;\t/* not used */\n\tjob_info.gtids = NULL;\t/* not used */\n\n\tp = getenv(PMI2_PMI_DEBUGGED_ENV);\n\tif (p) {\n\t\tjob_info.pmi_debugged = atoi(p);\n\t} else {\n\t\tjob_info.pmi_debugged = 0;\n\t}\n\tp = getenv(PMI2_SPAWN_SEQ_ENV);\n\tif (p) { \t\t/* spawned */\n\t\tjob_info.spawn_seq = atoi(p);\n\t\tp = getenv(PMI2_SPAWNER_JOBID_ENV);\n\t\tjob_info.spawner_jobid = xstrdup(p);\n\t\t/* env unset in stepd */\n\t} else {\n\t\tjob_info.spawn_seq = 0;\n\t\tjob_info.spawner_jobid = NULL;\n\t}\n\n\tjob_info.step_nodelist = xstrdup(job->step_layout->node_list);\n\tjob_info.proc_mapping = _get_proc_mapping(job);\n\tif (job_info.proc_mapping == NULL) {\n\t\treturn SLURM_ERROR;\n\t}\n\tp = getenv(PMI2_PMI_JOBID_ENV);\n\tif (p) {\t\t/* spawned */\n\t\tjob_info.pmi_jobid = xstrdup(p);\n\t} else {\n\t\txstrfmtcat(job_info.pmi_jobid, \"%u.%u\", job_info.jobid,\n\t\t\t   job_info.stepid);\n\t}\n\tjob_info.job_env = env_array_copy((const char **)environ);\n\n\t/* hjcao: this is really dirty.\n\t   But writing a new launcher is not desirable. */\n\thandle = dlopen(NULL, RTLD_LAZY);\n\tif (handle == NULL) {\n\t\terror(\"mpi/pmi2: failed to dlopen()\");\n\t\treturn SLURM_ERROR;\n\t}\n\tsym = dlsym(handle, \"MPIR_proctable\");\n\tif (sym == NULL) {\n\t\t/* if called directly in API, there may be no symbol available */\n\t\tverbose (\"mpi/pmi2: failed to find symbol 'MPIR_proctable'\");\n\t\tjob_info.MPIR_proctable = NULL;\n\t} else {\n\t\tjob_info.MPIR_proctable = *(MPIR_PROCDESC **)sym;\n\t}\n\tsym = dlsym(handle, \"opt\");\n\tif (sym == NULL) {\n\t\tverbose(\"mpi/pmi2: failed to find symbol 'opt'\");\n\t\tjob_info.srun_opt = NULL;\n\t} else {\n\t\tjob_info.srun_opt = (slurm_opt_t *)sym;\n\t}\n\tdlclose(handle);\n\n\treturn SLURM_SUCCESS;\n}\n\nstatic int\n_setup_srun_tree_info(void)\n{\n\tchar *p;\n\tuint16_t p_port;\n\tchar *spool;\n\n\tmemset(&tree_info, 0, sizeof(tree_info));\n\n\ttree_info.this_node = \"launcher\"; /* not used */\n\ttree_info.parent_id = -2;   /* not used */\n\ttree_info.parent_node = NULL; /* not used */\n\ttree_info.num_children = job_info.nnodes;\n\ttree_info.depth = 0;\t /* not used */\n\ttree_info.max_depth = 0; /* not used */\n\t/* pmi_port set in _setup_srun_sockets */\n\tp = getenv(PMI2_SPAWNER_PORT_ENV);\n\tif (p) {\t\t/* spawned */\n\t\tp_port = atoi(p);\n\t\ttree_info.srun_addr = xmalloc(sizeof(slurm_addr_t));\n\t\t/* assume there is always a lo interface */\n\t\tslurm_set_addr(tree_info.srun_addr, p_port, \"127.0.0.1\");\n\t} else\n\t\ttree_info.srun_addr = NULL;\n\n\t/*\n\t * FIXME: We need to handle %n and %h in the spool dir, but don't have\n\t * the node name here\n\t */\n\tspool = slurm_get_slurmd_spooldir(NULL);\n\tsnprintf(tree_sock_addr, 128, PMI2_SOCK_ADDR_FMT,\n\t\t spool, job_info.jobid, job_info.stepid);\n\txfree(spool);\n\n\t/* init kvs seq to 0. TODO: reduce array size */\n\ttree_info.children_kvs_seq = xmalloc(sizeof(uint32_t) *\n\t\t\t\t\t     job_info.nnodes);\n\n\treturn SLURM_SUCCESS;\n}\n\nstatic int\n_setup_srun_socket(const mpi_plugin_client_info_t *job)\n{\n\tif (net_stream_listen(&tree_sock,\n\t\t\t      &tree_info.pmi_port) < 0) {\n\t\terror(\"mpi/pmi2: Failed to create tree socket\");\n\t\treturn SLURM_ERROR;\n\t}\n\tdebug(\"mpi/pmi2: srun pmi port: %hu\", tree_info.pmi_port);\n\n\treturn SLURM_SUCCESS;\n}\n\nstatic int\n_setup_srun_kvs(void)\n{\n\tint rc;\n\n\tkvs_seq = 1;\n\trc = temp_kvs_init();\n\treturn rc;\n}\n\nstatic int\n_setup_srun_environ(const mpi_plugin_client_info_t *job, char ***env)\n{\n\t/* ifhn will be set in SLURM_SRUN_COMM_HOST by slurmd */\n\tenv_array_overwrite_fmt(env, PMI2_SRUN_PORT_ENV, \"%hu\",\n\t\t\t\ttree_info.pmi_port);\n\tenv_array_overwrite_fmt(env, PMI2_STEP_NODES_ENV, \"%s\",\n\t\t\t\tjob_info.step_nodelist);\n\tenv_array_overwrite_fmt(env, PMI2_PROC_MAPPING_ENV, \"%s\",\n\t\t\t\tjob_info.proc_mapping);\n\treturn SLURM_SUCCESS;\n}\n\ninline static int\n_tasks_launched (void)\n{\n\tint i, all_launched = 1;\n\tif (job_info.MPIR_proctable == NULL)\n\t\treturn 1;\n\n\tfor (i = 0; i < job_info.ntasks; i ++) {\n\t\tif (job_info.MPIR_proctable[i].pid == 0) {\n\t\t\tall_launched = 0;\n\t\t\tbreak;\n\t\t}\n\t}\n\treturn all_launched;\n}\n\nstatic void *\n_task_launch_detection(void *unused)\n{\n\tspawn_resp_t *resp;\n\ttime_t start;\n\tint rc = 0;\n\n\t/*\n\t * mpir_init() is called in plugins/launch/slurm/launch_slurm.c before\n\t * mpi_hook_client_prelaunch() is called in api/step_launch.c\n\t */\n\tstart = time(NULL);\n\twhile (_tasks_launched() == 0) {\n\t\tusleep(1000*50);\n\t\tif (time(NULL) - start > 600) {\n\t\t\trc = 1;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t/* send a resp to spawner srun */\n\tresp = spawn_resp_new();\n\tresp->seq = job_info.spawn_seq;\n\tresp->jobid = xstrdup(job_info.pmi_jobid);\n\tresp->error_cnt = 0;\t/* TODO */\n\tresp->rc = rc;\n\tresp->pmi_port = tree_info.pmi_port;\n\n\tspawn_resp_send_to_srun(resp);\n\tspawn_resp_free(resp);\n\treturn NULL;\n}\n\nextern int\npmi2_setup_srun(const mpi_plugin_client_info_t *job, char ***env)\n{\n\tstatic pthread_mutex_t setup_mutex = PTHREAD_MUTEX_INITIALIZER;\n\tstatic pthread_cond_t setup_cond  = PTHREAD_COND_INITIALIZER;\n\tstatic int global_rc = NO_VAL16;\n\tint rc = SLURM_SUCCESS;\n\n\trun_in_stepd = false;\n\tif ((job->het_job_id == NO_VAL) || (job->het_job_task_offset == 0)) {\n\t\trc = _setup_srun_job_info(job);\n\t\tif (rc == SLURM_SUCCESS)\n\t\t\trc = _setup_srun_tree_info();\n\t\tif (rc == SLURM_SUCCESS)\n\t\t\trc = _setup_srun_socket(job);\n\t\tif (rc == SLURM_SUCCESS)\n\t\t\trc = _setup_srun_kvs();\n\t\tif (rc == SLURM_SUCCESS)\n\t\t\trc = _setup_srun_environ(job, env);\n\t\tif ((rc == SLURM_SUCCESS) && job_info.spawn_seq) {\n\t\t\tslurm_thread_create_detached(NULL,\n\t\t\t\t\t\t     _task_launch_detection,\n\t\t\t\t\t\t     NULL);\n\t\t}\n\t\tslurm_mutex_lock(&setup_mutex);\n\t\tglobal_rc = rc;\n\t\tslurm_cond_broadcast(&setup_cond);\n\t\tslurm_mutex_unlock(&setup_mutex);\n\t} else {\n\t\tslurm_mutex_lock(&setup_mutex);\n\t\twhile (global_rc == NO_VAL16)\n\t\t\tslurm_cond_wait(&setup_cond, &setup_mutex);\n\t\trc = global_rc;\n\t\tslurm_mutex_unlock(&setup_mutex);\n\t\tif (rc == SLURM_SUCCESS)\n\t\t\trc = _setup_srun_environ(job, env);\n \t}\n\n\treturn rc;\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/src/plugins/mpi/pmix/mpi_pmix.c": "/*****************************************************************************\\\n **  mpi_pmix.c - Main plugin callbacks for PMIx support in Slurm\n *****************************************************************************\n *  Copyright (C) 2014-2015 Artem Polyakov. All rights reserved.\n *  Copyright (C) 2015-2017 Mellanox Technologies. All rights reserved.\n *  Written by Artem Y. Polyakov <artpol84@gmail.com, artemp@mellanox.com>.\n *\n *  This file is part of Slurm, a resource management program.\n *  For details, see <https://slurm.schedmd.com/>.\n *  Please also read the included file: DISCLAIMER.\n *\n *  Slurm is free software; you can redistribute it and/or modify it under\n *  the terms of the GNU General Public License as published by the Free\n *  Software Foundation; either version 2 of the License, or (at your option)\n *  any later version.\n *\n *  In addition, as a special exception, the copyright holders give permission\n *  to link the code of portions of this program with the OpenSSL library under\n *  certain conditions as described in each individual source file, and\n *  distribute linked combinations including the two. You must obey the GNU\n *  General Public License in all respects for all of the code used other than\n *  OpenSSL. If you modify file(s) with this exception, you may extend this\n *  exception to your version of the file(s), but you are not obligated to do\n *  so. If you do not wish to do so, delete this exception statement from your\n *  version.  If you delete this exception statement from all source files in\n *  the program, then also delete it here.\n *\n *  Slurm is distributed in the hope that it will be useful, but WITHOUT ANY\n *  WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n *  FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more\n *  details.\n *\n *  You should have received a copy of the GNU General Public License along\n *  with Slurm; if not, write to the Free Software Foundation, Inc.,\n *  51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA.\n \\*****************************************************************************/\n\n#include <fcntl.h>\n#include <signal.h>\n#include <sys/types.h>\n#include <dlfcn.h>\n\n#include \"pmixp_common.h\"\n#include \"pmixp_server.h\"\n#include \"pmixp_debug.h\"\n#include \"pmixp_agent.h\"\n#include \"pmixp_info.h\"\n#include \"pmixp_dconn_ucx.h\"\n#include \"pmixp_client.h\"\n\n/*\n * These variables are required by the generic plugin interface.  If they\n * are not found in the plugin, the plugin loader will ignore it.\n *\n * plugin_name - a string giving a human-readable description of the\n * plugin.  There is no maximum length, but the symbol must refer to\n * a valid string.\n *\n * plugin_type - a string suggesting the type of the plugin or its\n * applicability to a particular form of data or method of data handling.\n * If the low-level plugin API is used, the contents of this string are\n * unimportant and may be anything.  Slurm uses the higher-level plugin\n * interface which requires this string to be of the form\n *\n *      <application>/<method>\n *\n * where <application> is a description of the intended application of\n * the plugin (e.g., \"switch\" for Slurm switch) and <method> is a description\n * of how this plugin satisfies that application.  Slurm will only load\n * a switch plugin if the plugin_type string has a prefix of \"switch/\".\n *\n * plugin_version - an unsigned 32-bit integer giving the version number\n * of the plugin.  If major and minor revisions are desired, the major\n * version number may be multiplied by a suitable magnitude constant such\n * as 100 or 1000.  Various Slurm versions will likely require a certain\n * minimum version for their plugins as this API matures.\n */\nconst char plugin_name[] = \"PMIx plugin\";\n\n#if (HAVE_PMIX_VER == 1)\nconst char plugin_type[] = \"mpi/pmix_v1\";\n#elif (HAVE_PMIX_VER == 2)\nconst char plugin_type[] = \"mpi/pmix_v2\";\n#elif (HAVE_PMIX_VER == 3)\nconst char plugin_type[] = \"mpi/pmix_v3\";\n#endif\n\nconst uint32_t plugin_version = SLURM_VERSION_NUMBER;\n\nvoid *libpmix_plug = NULL;\n\nchar *process_mapping = NULL;\n\nstatic void _libpmix_close(void *lib_plug)\n{\n\txassert(lib_plug);\n\tdlclose(lib_plug);\n}\n\nstatic void *_libpmix_open(void)\n{\n\tvoid *lib_plug = NULL;\n\tchar *full_path = NULL;\n\n#ifdef PMIXP_V1_LIBPATH\n\txstrfmtcat(full_path, \"%s/\", PMIXP_V1_LIBPATH);\n#elif defined PMIXP_V2_LIBPATH\n\txstrfmtcat(full_path, \"%s/\", PMIXP_V2_LIBPATH);\n#elif defined PMIXP_V3_LIBPATH\n\txstrfmtcat(full_path, \"%s/\", PMIXP_V3_LIBPATH);\n#endif\n\txstrfmtcat(full_path, \"libpmix.so\");\n\n\tlib_plug = dlopen(full_path, RTLD_LAZY | RTLD_GLOBAL);\n\txfree(full_path);\n\n\tif (lib_plug && (HAVE_PMIX_VER != pmixp_lib_get_version())) {\n\t\tPMIXP_ERROR(\"pmi/pmix: incorrect PMIx library version loaded %d was loaded, required %d version\",\n\t\t\t    pmixp_lib_get_version(), (int)HAVE_PMIX_VER);\n\t\t_libpmix_close(lib_plug);\n\t\tlib_plug = NULL;\n\t}\n\n\treturn lib_plug;\n}\n\n/*\n * init() is called when the plugin is loaded, before any other functions\n * are called.  Put global initialization here.\n */\nextern int init(void)\n{\n\tlibpmix_plug = _libpmix_open();\n\tif (!libpmix_plug) {\n\t\tPMIXP_ERROR(\"pmi/pmix: can not load PMIx library\");\n\t\treturn SLURM_ERROR;\n\t}\n\treturn SLURM_SUCCESS;\n}\n\nextern int fini(void)\n{\n\tPMIXP_DEBUG(\"%s: call fini()\", pmixp_info_hostname());\n\tpmixp_agent_stop();\n\tpmixp_stepd_finalize();\n\t_libpmix_close(libpmix_plug);\n\treturn SLURM_SUCCESS;\n}\n\nextern int p_mpi_hook_slurmstepd_prefork(\n\tconst stepd_step_rec_t *job, char ***env)\n{\n\tint ret;\n\tpmixp_debug_hang(0);\n\tPMIXP_DEBUG(\"start\");\n\n\tif (job->batch)\n\t\treturn SLURM_SUCCESS;\n\n\tif (SLURM_SUCCESS != (ret = pmixp_stepd_init(job, env))) {\n\t\tPMIXP_ERROR(\"pmixp_stepd_init() failed\");\n\t\tgoto err_ext;\n\t}\n\tif (SLURM_SUCCESS != (ret = pmixp_agent_start())) {\n\t\tPMIXP_ERROR(\"pmixp_agent_start() failed\");\n\t\tgoto err_ext;\n\t}\n\treturn SLURM_SUCCESS;\n\nerr_ext:\n\t/* Abort the whole job if error! */\n\tslurm_kill_job_step(job->jobid, job->stepid, SIGKILL);\n\treturn ret;\n}\n\nextern int p_mpi_hook_slurmstepd_task(\n\tconst mpi_plugin_task_info_t *job, char ***env)\n{\n\tchar **tmp_env = NULL;\n\tpmixp_debug_hang(0);\n\n\tPMIXP_DEBUG(\"Patch environment for task %d\", job->gtaskid);\n\n\tpmixp_lib_setup_fork(job->gtaskid, pmixp_info_namespace(), &tmp_env);\n\tif (NULL != tmp_env) {\n\t\tint i;\n\t\tfor (i = 0; NULL != tmp_env[i]; i++) {\n\t\t\tchar *value = strchr(tmp_env[i], '=');\n\t\t\tif (NULL != value) {\n\t\t\t\t*value = '\\0';\n\t\t\t\tvalue++;\n\t\t\t\tenv_array_overwrite(env,\n\t\t\t\t\t\t    (const char *)tmp_env[i],\n\t\t\t\t\t\t    value);\n\t\t\t}\n\t\t\tfree(tmp_env[i]);\n\t\t}\n\t\tfree(tmp_env);\n\t\ttmp_env = NULL;\n\t}\n\treturn SLURM_SUCCESS;\n}\n\nextern mpi_plugin_client_state_t *p_mpi_hook_client_prelaunch(\n\tconst mpi_plugin_client_info_t *job, char ***env)\n{\n\tstatic pthread_mutex_t setup_mutex = PTHREAD_MUTEX_INITIALIZER;\n\tstatic pthread_cond_t setup_cond  = PTHREAD_COND_INITIALIZER;\n\tstatic bool setup_done = false;\n\tuint32_t nnodes, ntasks, **tids;\n\tuint16_t *task_cnt;\n\n\tPMIXP_DEBUG(\"setup process mapping in srun\");\n\tif ((job->het_job_id == NO_VAL) || (job->het_job_task_offset == 0)) {\n\t\tnnodes = job->step_layout->node_cnt;\n\t\tntasks = job->step_layout->task_cnt;\n\t\ttask_cnt = job->step_layout->tasks;\n\t\ttids = job->step_layout->tids;\n\t\tprocess_mapping = pack_process_mapping(nnodes, ntasks,\n\t\t\t\t\t\t       task_cnt, tids);\n\t\tslurm_mutex_lock(&setup_mutex);\n\t\tsetup_done = true;\n\t\tslurm_cond_broadcast(&setup_cond);\n\t\tslurm_mutex_unlock(&setup_mutex);\n\t} else {\n\t\tslurm_mutex_lock(&setup_mutex);\n\t\twhile (!setup_done)\n\t\t\tslurm_cond_wait(&setup_cond, &setup_mutex);\n\t\tslurm_mutex_unlock(&setup_mutex);\n\t}\n\n\tif (!process_mapping) {\n\t\tPMIXP_ERROR(\"Cannot create process mapping\");\n\t\treturn NULL;\n\t}\n\tsetenvf(env, PMIXP_SLURM_MAPPING_ENV, \"%s\", process_mapping);\n\n\t/* only return NULL on error */\n\treturn (void *)0xdeadbeef;\n}\n\nextern int p_mpi_hook_client_fini(void)\n{\n\txfree(process_mapping);\n\n\treturn SLURM_SUCCESS;\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/src/plugins/mpi/pmix/pmixp_dconn_ucx.c": "/*****************************************************************************\\\n **  pmix_dconn_ucx.c - PMIx direct UCX connection\n *****************************************************************************\n *  Copyright (C) 2017      Mellanox Technologies. All rights reserved.\n *  Written by Artem Polyakov <artpol84@gmail.com, artemp@mellanox.com>.\n *\n *  This file is part of Slurm, a resource management program.\n *  For details, see <https://slurm.schedmd.com/>.\n *  Please also read the included file: DISCLAIMER.\n *\n *  Slurm is free software; you can redistribute it and/or modify it under\n *  the terms of the GNU General Public License as published by the Free\n *  Software Foundation; either version 2 of the License, or (at your option)\n *  any later version.\n *\n *  In addition, as a special exception, the copyright holders give permission\n *  to link the code of portions of this program with the OpenSSL library under\n *  certain conditions as described in each individual source file, and\n *  distribute linked combinations including the two. You must obey the GNU\n *  General Public License in all respects for all of the code used other than\n *  OpenSSL. If you modify file(s) with this exception, you may extend this\n *  exception to your version of the file(s), but you are not obligated to do\n *  so. If you do not wish to do so, delete this exception statement from your\n *  version.  If you delete this exception statement from all source files in\n *  the program, then also delete it here.\n *\n *  Slurm is distributed in the hope that it will be useful, but WITHOUT ANY\n *  WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n *  FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more\n *  details.\n *\n *  You should have received a copy of the GNU General Public License along\n *  with Slurm; if not, write to the Free Software Foundation, Inc.,\n *  51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA.\n \\*****************************************************************************/\n\n#include \"pmixp_dconn.h\"\n#include \"pmixp_dconn_ucx.h\"\n#include <unistd.h>\n#include <dlfcn.h>\n#include <ucp/api/ucp.h>\n\n/* local variables */\nstatic int _service_pipe[2];\n#define PMIXP_UCX_LIST_PREALLOC 16\nstatic pmixp_list_t _free_list;\nstatic pmixp_rlist_t _rcv_pending, _snd_pending;\nstatic pmixp_rlist_t _rcv_complete, _snd_complete;\nstatic int _server_fd = -1;\nstatic bool _direct_hdr_set = false;\nstatic pmixp_p2p_data_t _direct_hdr;\nstatic void *_host_hdr = NULL;\npthread_mutex_t _ucx_worker_lock;\n\n\n\n/* UCX objects */\nucp_context_h ucp_context;\nucp_worker_h ucp_worker;\nstatic ucp_address_t *_ucx_addr;\nstatic size_t _ucx_alen;\n\ntypedef enum {\n\tPMIXP_UCX_ACTIVE = 0,\n\tPMIXP_UCX_COMPLETE,\n\tPMIXP_UCX_FAILED\n} pmixp_ucx_status_t;\n\ntypedef struct {\n\tvolatile pmixp_ucx_status_t status;\n\tvoid *buffer;\n\tsize_t len;\n\tvoid *msg;\n} pmixp_ucx_req_t;\n\ntypedef struct {\n\tint nodeid;\n\tbool connected;\n\tucp_ep_h server_ep;\n\tvoid *ucx_addr;\n\tsize_t ucx_alen;\n\tpmixp_p2p_data_t eng_hdr;\n\tpmixp_rlist_t pending;\n} pmixp_dconn_ucx_t;\n\nstatic inline void _recv_req_release(pmixp_ucx_req_t *req)\n{\n\tif (req->buffer) {\n\t\txfree(req->buffer);\n\t}\n\tmemset(req, 0, sizeof(*req));\n\tucp_request_release(req);\n}\n\nstatic void request_init(void *request)\n{\n\tpmixp_ucx_req_t *req = (pmixp_ucx_req_t *) request;\n\treq->status = PMIXP_UCX_ACTIVE;\n\tmemset(req, 0, sizeof(*req));\n}\n\nstatic void send_handle(void *request, ucs_status_t status)\n{\n\tpmixp_ucx_req_t *req = (pmixp_ucx_req_t *) request;\n\tif (UCS_OK == status){\n\t\treq->status = PMIXP_UCX_COMPLETE;\n\t} else {\n\t\tPMIXP_ERROR(\"UCX send request failed: %s\",\n\t\t\t    ucs_status_string(status));\n\t\treq->status = PMIXP_UCX_FAILED;\n\t}\n}\n\nstatic void recv_handle(void *request, ucs_status_t status,\n\t\t\tucp_tag_recv_info_t *info)\n{\n\tpmixp_ucx_req_t *req = (pmixp_ucx_req_t *) request;\n\tif (UCS_OK == status){\n\t\treq->status = PMIXP_UCX_COMPLETE;\n\t} else {\n\t\tPMIXP_ERROR(\"UCX send request failed: %s\",\n\t\t\t    ucs_status_string(status));\n\t\treq->status = PMIXP_UCX_FAILED;\n\t}\n}\n\nstatic bool _epoll_readable(eio_obj_t *obj);\nstatic int _epoll_read(eio_obj_t *obj, List objs);\n\nstatic struct io_operations _epoll_ops = {\n\t.readable = _epoll_readable,\n\t.handle_read = _epoll_read\n};\n\nstatic bool _progress_readable(eio_obj_t *obj);\nstatic int _progress_read(eio_obj_t *obj, List objs);\n\nstatic struct io_operations _progress_ops = {\n\t.readable = _progress_readable,\n\t.handle_read = _progress_read\n};\n\nstatic void *_ucx_init(int nodeid, pmixp_p2p_data_t direct_hdr);\nstatic void _ucx_fini(void *_priv);\nstatic int _ucx_connect(void *_priv, void *ep_data, size_t ep_len,\n\t\t\tvoid *init_msg);\nstatic int _ucx_send(void *_priv, void *msg);\nstatic void _ucx_regio(eio_handle_t *h);\nstatic void *_ucx_lib_handler = NULL;\n\nstatic int _load_ucx_lib()\n{\n\t/* At the time of writing this UCX doesn't support\n\t * fork() and it's memory hooks are causing memory\n\t * corruptions in the forked processes.\n\t * To avoid that we need to disable memory hooks before\n\t * loading UCX library.\n\t */\n\tsetenv(\"UCX_MEM_MMAP_RELOC\", \"no\", 1);\n\tsetenv(\"UCX_MEM_MALLOC_HOOKS\", \"no\", 1);\n\tsetenv(\"UCX_MEM_MALLOC_RELOC\", \"no\", 1);\n\tsetenv(\"UCX_MEM_EVENTS\", \"no\", 1);\n\n#ifdef PMIXP_UCX_LIBPATH\n\t/* If this Slurm build doesn't allow RPATH's\n\t * try to open library by it's full path that\n\t * we have from autoconf\n\t */\n\tchar *full_path = NULL;\n\txstrfmtcat(full_path, \"%s/libucp.so\", PMIXP_UCX_LIBPATH);\n\t_ucx_lib_handler = dlopen(full_path, RTLD_LAZY | RTLD_GLOBAL);\n\txfree(full_path);\n\tif (_ucx_lib_handler) {\n\t\t/* successful, exit now */\n\t\treturn SLURM_SUCCESS;\n\t}\n\t/* fall-thru to see if libucp.so is located in the location\n\t * known by dynamic linker.\n\t */\n#endif\n\t_ucx_lib_handler = dlopen(\"libucp.so\", RTLD_LAZY | RTLD_GLOBAL);\n\tif (!_ucx_lib_handler) {\n\t\tchar *err = dlerror();\n\t\tPMIXP_ERROR(\"Cannot open UCX lib: %s\", (err) ? err : \"unknown\");\n\t\treturn SLURM_ERROR;\n\t}\n\treturn SLURM_SUCCESS;\n}\n\nstatic void _unload_ucx_lib()\n{\n\txassert(_ucx_lib_handler);\n\tif (_ucx_lib_handler) {\n\t\tdlclose(_ucx_lib_handler);\n\t}\n}\n\nint pmixp_dconn_ucx_prepare(pmixp_dconn_handlers_t *handlers,\n\t\t\t    char **ep_data, size_t *ep_len)\n{\n\tucp_config_t *config;\n\tucs_status_t status;\n\tucp_params_t ucp_params;\n\tucp_worker_params_t worker_params;\n\n\t/* By default UCX is not loaded until we explicitly\n\t * asked for that\n\t */\n\t_load_ucx_lib();\n\n\tslurm_mutex_init(&_ucx_worker_lock);\n\n\t/* container of the free elements */\n\tpmixp_list_init(&_free_list);\n\n\t/* Containers for the non-completed requests */\n\tpmixp_rlist_init(&_rcv_pending, &_free_list, PMIXP_UCX_LIST_PREALLOC);\n\tpmixp_rlist_init(&_snd_pending, &_free_list, PMIXP_UCX_LIST_PREALLOC);\n\n\t/* Temp lists to hold completed requests for _ucx_progress */\n\tpmixp_rlist_init(&_snd_complete, &_free_list, PMIXP_UCX_LIST_PREALLOC);\n\tpmixp_rlist_init(&_rcv_complete, &_free_list, PMIXP_UCX_LIST_PREALLOC);\n\n\n\tstatus = ucp_config_read(\"SLURM\", NULL, &config);\n\tif (status != UCS_OK) {\n\t\tPMIXP_ERROR(\"Fail to read UCX config: %s\",\n\t\t\t    ucs_status_string(status));\n\t\treturn SLURM_ERROR;\n\t}\n\n\tucp_params.features = UCP_FEATURE_TAG | UCP_FEATURE_WAKEUP;\n\tucp_params.request_size    = sizeof(pmixp_ucx_req_t);\n\tucp_params.request_init    = request_init;\n\tucp_params.request_cleanup = NULL;\n\tucp_params.field_mask      = UCP_PARAM_FIELD_FEATURES |\n\t\t\tUCP_PARAM_FIELD_REQUEST_SIZE |\n\t\t\tUCP_PARAM_FIELD_REQUEST_INIT |\n\t\t\tUCP_PARAM_FIELD_REQUEST_CLEANUP;\n\n\tstatus = ucp_init(&ucp_params, config, &ucp_context);\n\n\tucp_config_release(config);\n\tif (status != UCS_OK) {\n\t\tPMIXP_ERROR(\"Fail to init UCX: %s\",\n\t\t\t    ucs_status_string(status));\n\t\treturn SLURM_ERROR;\n\t}\n\n\tworker_params.field_mask  = UCP_WORKER_PARAM_FIELD_THREAD_MODE;\n\tworker_params.thread_mode = UCS_THREAD_MODE_MULTI;\n\n\tstatus = ucp_worker_create(ucp_context, &worker_params, &ucp_worker);\n\tif (status != UCS_OK) {\n\t\tPMIXP_ERROR(\"Fail to create UCX worker: %s\",\n\t\t\t    ucs_status_string(status));\n\t\tgoto err_worker;\n\t}\n\n\tstatus = ucp_worker_get_address(ucp_worker, &_ucx_addr, &_ucx_alen);\n\tif (status != UCS_OK) {\n\t\tPMIXP_ERROR(\"Fail to get UCX address: %s\",\n\t\t\t    ucs_status_string(status));\n\t\tgoto err_addr;\n\t}\n\n\tstatus = ucp_worker_get_efd(ucp_worker, &_server_fd);\n\tif (status != UCS_OK) {\n\t\tPMIXP_ERROR(\"Fail to get UCX epoll fd: %s\",\n\t\t\t    ucs_status_string(status));\n\t\tgoto err_efd;\n\t}\n\n\tmemset(handlers, 0, sizeof(*handlers));\n\thandlers->connect = _ucx_connect;\n\thandlers->init = _ucx_init;\n\thandlers->fini = _ucx_fini;\n\thandlers->send = _ucx_send;\n\thandlers->getio = NULL;\n\thandlers->regio = _ucx_regio;\n\n\t*ep_data = (void*)_ucx_addr;\n\t*ep_len  = (uint16_t)_ucx_alen;\n\n\treturn SLURM_SUCCESS;\n\nerr_efd:\n\tucp_worker_release_address(ucp_worker, _ucx_addr);\nerr_addr:\n\tucp_worker_destroy(ucp_worker);\nerr_worker:\n\tucp_cleanup(ucp_context);\n\treturn SLURM_ERROR;\n\n}\n\nstatic void _release_send_requests(pmixp_rlist_t *l)\n{\n\tsize_t count = pmixp_rlist_count(l);\n\tsize_t i;\n\tfor (i=0; i<count; i++) {\n\t\tpmixp_ucx_req_t *req;\n\t\treq = (pmixp_ucx_req_t*)pmixp_rlist_deq(l);\n\t\txassert(req);\n\n\t\tucp_request_cancel(ucp_worker, req);\n\t\tif (req->buffer) {\n\t\t\t/* NOTE: since we are finalizing, we don't really care\n\t\t\t * about the status */\n\t\t\t_direct_hdr.send_complete(req->msg, PMIXP_P2P_REGULAR,\n\t\t\t\t\t\t  SLURM_SUCCESS);\n\t\t}\n\t\tucp_request_release(req);\n\t}\n}\n\nstatic void _release_recv_requests(pmixp_rlist_t *l)\n{\n\tsize_t count = pmixp_rlist_count(l);\n\tsize_t i;\n\n\tfor (i=0; i < count; i++) {\n\t\tpmixp_ucx_req_t *req;\n\t\treq = (pmixp_ucx_req_t*)pmixp_rlist_deq(l);\n\t\txassert(req);\n\t\tucp_request_cancel(ucp_worker, req);\n\t\t_recv_req_release(req);\n\t}\n}\n\nvoid pmixp_dconn_ucx_stop()\n{\n\tslurm_mutex_lock(&_ucx_worker_lock);\n\t_release_send_requests(&_snd_pending);\n\t_release_send_requests(&_snd_complete);\n\n\t_release_recv_requests(&_rcv_pending);\n\t_release_recv_requests(&_rcv_complete);\n\tslurm_mutex_unlock(&_ucx_worker_lock);\n}\n\nvoid pmixp_dconn_ucx_finalize()\n{\n\tpmixp_list_elem_t *elem;\n\tsize_t count, i;\n\txassert(_direct_hdr_set);\n\n\tpmixp_rlist_fini(&_snd_pending);\n\tpmixp_rlist_fini(&_snd_complete);\n\tpmixp_rlist_fini(&_rcv_pending);\n\tpmixp_rlist_fini(&_rcv_complete);\n\n\t/* All elements from the previous lists should settle\n\t * down in this free list now. Release it!\n\t */\n\tcount = pmixp_list_count(&_free_list);\n\tfor (i=0; i < count; i++) {\n\t\telem = pmixp_list_deq(&_free_list);\n\t\tpmixp_list_elem_free(elem);\n\t}\n\n\t/* cleanup UCX */\n\tucp_worker_destroy(ucp_worker);\n\tucp_cleanup(ucp_context);\n\n\t/* unload UCX lib */\n\t_unload_ucx_lib();\n\tslurm_mutex_destroy(&_ucx_worker_lock);\n}\n\nstatic int _activate_progress()\n{\n\tchar buf = 'c';\n\tint rc = write(_service_pipe[1], &buf, sizeof(buf));\n\tif (sizeof(buf) != rc) {\n\t\tPMIXP_ERROR(\"Unable to activate UCX progress\");\n\t\tif (0 > rc) {\n\t\t\treturn rc;\n\t\t} else {\n\t\t\treturn SLURM_ERROR;\n\t\t}\n\t}\n\treturn SLURM_SUCCESS;\n}\n\nvoid _ucx_process_msg(char *buffer, size_t len)\n{\n\txassert(_direct_hdr_set);\n\t_direct_hdr.hdr_unpack_cb(buffer, _host_hdr);\n\n\tBuf buf = create_buf(buffer, len);\n\tset_buf_offset(buf, _direct_hdr.rhdr_net_size);\n\t_direct_hdr.new_msg(_host_hdr, buf);\n}\n\nstatic bool _ucx_progress()\n{\n\tpmixp_ucx_req_t *req = NULL;\n\tucp_tag_message_h msg_tag;\n\tucp_tag_recv_info_t info_tag;\n\tpmixp_list_elem_t *elem;\n\tbool new_msg = false;\n\tsize_t count, i;\n\tint events_observed = 0;\n\n\t/* protected progress of UCX */\n\tslurm_mutex_lock(&_ucx_worker_lock);\n\tucp_worker_progress(ucp_worker);\n\n\t/* check for new messages */\n\twhile (1) {\n\t\tmsg_tag = ucp_tag_probe_nb(ucp_worker, 1, 0,\n\t\t\t\t\t   1, &info_tag);\n\t\tif (NULL == msg_tag) {\n\t\t\tbreak;\n\t\t}\n\t\tevents_observed++;\n\n\t\tchar *msg = xmalloc(info_tag.length);\n\t\tpmixp_ucx_req_t *req = (pmixp_ucx_req_t*)\n\t\t\t\tucp_tag_msg_recv_nb(ucp_worker, (void*)msg,\n\t\t\t\t\t\t    info_tag.length,\n\t\t\t\t\t\t    ucp_dt_make_contig(1),\n\t\t\t\t\t\t    msg_tag, recv_handle);\n\t\tif (UCS_PTR_IS_ERR(req)) {\n\t\t\tPMIXP_ERROR(\"ucp_tag_msg_recv_nb failed: %s\",\n\t\t\t\t    ucs_status_string(UCS_PTR_STATUS(req)));\n\t\t\tcontinue;\n\t\t}\n\t\tnew_msg = true;\n\t\treq->buffer = msg;\n\t\treq->len = info_tag.length;\n\t\tif (PMIXP_UCX_ACTIVE == req->status) {\n\t\t\t/* this message is long enough, so it makes\n\t\t\t * sense to do the progres one more timer */\n\t\t\tpmixp_rlist_enq(&_rcv_pending, req);\n\t\t} else {\n\t\t\tpmixp_rlist_enq(&_rcv_complete, req);\n\t\t}\n\t}\n\n\tif (!new_msg && pmixp_rlist_empty(&_rcv_pending) &&\n\t\t\t\tpmixp_rlist_empty(&_snd_pending)) {\n\t\tgoto exit;\n\t}\n\n\t/* Check pending requests */\n\telem = pmixp_rlist_begin(&_rcv_pending);\n\twhile (pmixp_rlist_end(&_rcv_pending) != elem) {\n\t\treq = PMIXP_LIST_VAL(elem);\n\t\tif (PMIXP_UCX_ACTIVE == req->status){\n\t\t\t/* go to the next element */\n\t\t\telem = pmixp_rlist_next(&_rcv_pending, elem);\n\t\t} else {\n\t\t\t/* grab this element for processing */\n\t\t\telem = pmixp_rlist_rem(&_rcv_pending, elem);\n\t\t\tpmixp_rlist_enq(&_rcv_complete, req);\n\t\t\tevents_observed++;\n\t\t}\n\t}\n\n\telem = pmixp_rlist_begin(&_snd_pending);\n\twhile (pmixp_rlist_end(&_snd_pending) != elem) {\n\t\treq = PMIXP_LIST_VAL(elem);\n\t\tif (PMIXP_UCX_ACTIVE == req->status){\n\t\t\t/* go to the next element */\n\t\t\telem = pmixp_rlist_next(&_snd_pending, elem);\n\t\t} else {\n\t\t\t/* grab this element for processing */\n\t\t\telem = pmixp_rlist_rem(&_snd_pending, elem);\n\t\t\tpmixp_rlist_enq(&_snd_complete, req);\n\t\t\tevents_observed++;\n\t\t}\n\t}\n\tslurm_mutex_unlock(&_ucx_worker_lock);\n\n\t/* process sends and receives unlocked */\n\telem = pmixp_rlist_begin(&_rcv_complete);\n\twhile (pmixp_rlist_end(&_rcv_complete) != elem) {\n\t\treq = PMIXP_LIST_VAL(elem);\n\t\t/* Skip failed receives\n\t\t * TODO: what more can we do? */\n\t\tif (PMIXP_UCX_FAILED != req->status){\n\t\t\t_ucx_process_msg(req->buffer, req->len);\n\t\t}\n\t\telem = pmixp_rlist_next(&_rcv_complete, elem);\n\t}\n\n\telem = pmixp_rlist_begin(&_snd_complete);\n\twhile (pmixp_rlist_end(&_snd_complete) != elem) {\n\t\treq = PMIXP_LIST_VAL(elem);\n\t\tint rc = SLURM_SUCCESS;\n\t\tif (PMIXP_UCX_FAILED == req->status){\n\t\t\trc = SLURM_ERROR;\n\t\t}\n\t\txassert(_direct_hdr_set);\n\t\tif (req->buffer) {\n\t\t\t_direct_hdr.send_complete(req->msg,\n\t\t\t\t\t\t  PMIXP_P2P_REGULAR, rc);\n\t\t}\n\t\telem = pmixp_rlist_next(&_snd_complete, elem);\n\t}\n\n\tslurm_mutex_lock(&_ucx_worker_lock);\n\n\tcount = pmixp_rlist_count(&_rcv_complete);\n\tfor (i=0; i < count; i++){\n\t\treq = (pmixp_ucx_req_t *)pmixp_rlist_deq(&_rcv_complete);\n\t\t/* release request to UCX */\n\t\tmemset(req, 0, sizeof(*req));\n\t\tucp_request_release(req);\n\t}\n\n\tcount = pmixp_rlist_count(&_snd_complete);\n\tfor (i=0; i < count; i++) {\n\t\treq = (pmixp_ucx_req_t *)pmixp_rlist_deq(&_snd_complete);\n\t\t/* release request to UCX */\n\t\tmemset(req, 0, sizeof(*req));\n\t\tucp_request_release(req);\n\t}\n\nexit:\n\tslurm_mutex_unlock(&_ucx_worker_lock);\n\treturn !!(events_observed);\n}\n\nstatic bool _epoll_readable(eio_obj_t *obj)\n{\n\tucs_status_t status = UCS_ERR_BUSY;\n\n\t/* sanity check */\n\txassert(NULL != obj );\n\tif (obj->shutdown) {\n\t\t/* corresponding connection will be\n\t\t * cleaned up during plugin finalize\n\t\t */\n\t\treturn false;\n\t}\n\n\tdo {\n\t\t/* process all outstanding events */\n\t\twhile (_ucx_progress());\n\n\t\tif (pmixp_rlist_count(&_rcv_pending) ||\n\t\t    pmixp_rlist_count(&_snd_pending)){\n\t\t\t/* If we got pending requests don't wait\n\t\t\t * on epoll, activate poll interuprtion through\n\t\t\t * the service pipe\n\t\t\t */\n\t\t\t_activate_progress();\n\t\t\treturn false;\n\t\t}\n\n\t\t/* arm the poll fd */\n\t\tslurm_mutex_lock(&_ucx_worker_lock);\n\t\tstatus = ucp_worker_arm(ucp_worker);\n\t\tslurm_mutex_unlock(&_ucx_worker_lock);\n\t} while (UCS_ERR_BUSY == status);\n\n\treturn true;\n}\n\nstatic int _epoll_read(eio_obj_t *obj, List objs)\n{\n\tif (obj->shutdown) {\n\t\t/* corresponding connection will be\n\t\t * cleaned up during plugin finalize\n\t\t */\n\t\treturn 0;\n\t}\n\t/* process all outstanding events */\n\twhile (_ucx_progress());\n\treturn 0;\n}\n\nstatic bool _progress_readable(eio_obj_t *obj)\n{\n\t/* sanity check */\n\txassert(NULL != obj );\n\tif (obj->shutdown) {\n\t\t/* corresponding connection will be\n\t\t\t * cleaned up during plugin finalize\n\t\t\t */\n\t\treturn false;\n\t}\n\t/* all the control is located in epoll_readable\n\t * here we only say that we are readable\n\t */\n\treturn true;\n}\n\nstatic int _progress_read(eio_obj_t *obj, List objs)\n{\n\tchar buf;\n\n\t/* sanity check */\n\txassert(NULL != obj );\n\tif( obj->shutdown ){\n\t\t/* corresponding connection will be\n\t\t * cleaned up during plugin finalize\n\t\t */\n\t\treturn 0;\n\t}\n\n\t/* empty the pipe */\n\twhile (sizeof(buf) == read(_service_pipe[0], &buf, sizeof(buf)));\n\n\t/* process all outstanding events */\n\twhile (_ucx_progress());\n\n\treturn 0;\n}\n\nstatic void *_ucx_init(int nodeid, pmixp_p2p_data_t direct_hdr)\n{\n\tpmixp_dconn_ucx_t *priv = xmalloc(sizeof(pmixp_dconn_ucx_t));\n\tpriv->nodeid = nodeid;\n\tpriv->connected = false;\n\tif (!_direct_hdr_set) {\n\t\t_direct_hdr = direct_hdr;\n\t\t_direct_hdr_set = true;\n\t\t_host_hdr = xmalloc(_direct_hdr.rhdr_host_size);\n\t}\n\n\tslurm_mutex_lock(&_ucx_worker_lock);\n\tpmixp_rlist_init(&priv->pending, &_free_list, PMIXP_UCX_LIST_PREALLOC);\n\tslurm_mutex_unlock(&_ucx_worker_lock);\n\n\treturn (void*)priv;\n}\n\nstatic void _ucx_fini(void *_priv)\n{\n\tpmixp_dconn_ucx_t *priv = (pmixp_dconn_ucx_t *)_priv;\n\n\tif (priv->connected) {\n\t\txfree(priv->ucx_addr);\n\t\tslurm_mutex_lock(&_ucx_worker_lock);\n\t\tucp_ep_destroy(priv->server_ep);\n\t\tslurm_mutex_unlock(&_ucx_worker_lock);\n\t} else {\n\t\tslurm_mutex_lock(&_ucx_worker_lock);\n\t\tpmixp_rlist_fini(&priv->pending);\n\t\tslurm_mutex_unlock(&_ucx_worker_lock);\n\t}\n\txfree(priv);\n}\n\nstatic int _ucx_connect(void *_priv, void *ep_data, size_t ep_len,\n\t\t\tvoid *init_msg)\n{\n\tpmixp_dconn_ucx_t *priv = (pmixp_dconn_ucx_t *)_priv;\n\tucp_ep_params_t ep_params;\n\tucs_status_t status;\n\tint rc = SLURM_SUCCESS;\n\tsize_t i, count;\n\n\tpriv->ucx_addr = ep_data;\n\tpriv->ucx_alen = ep_len;\n\t/* Connect to the server */\n\tep_params.field_mask = UCP_EP_PARAM_FIELD_REMOTE_ADDRESS;\n\tep_params.address    = priv->ucx_addr;\n\n\tslurm_mutex_lock(&_ucx_worker_lock);\n\tstatus = ucp_ep_create(ucp_worker, &ep_params, &priv->server_ep);\n\tif (status != UCS_OK) {\n\t\tPMIXP_ERROR(\"ucp_ep_create failed: %s\",\n\t\t\t    ucs_status_string(status));\n\t\txfree(priv->ucx_addr);\n\t\tslurm_mutex_unlock(&_ucx_worker_lock);\n\t\treturn SLURM_ERROR;\n\t}\n\tpriv->connected = true;\n\n\t/* Enqueue initialization message if requested */\n\tif (init_msg) {\n\t\tpmixp_rlist_push(&priv->pending, init_msg);\n\t}\n\tslurm_mutex_unlock(&_ucx_worker_lock);\n\n\t/* we need to send data while being unlocked */\n\tif (SLURM_SUCCESS == rc){\n\t\tpmixp_list_elem_t *elem = NULL;\n\t\t/* Send all pending messages */\n\t\telem = pmixp_rlist_begin(&priv->pending);\n\t\twhile (pmixp_rlist_end(&priv->pending) != elem) {\n\t\t\t_ucx_send(_priv, PMIXP_LIST_VAL(elem));\n\t\t\telem = pmixp_rlist_next(&priv->pending, elem);\n\t\t}\n\t}\n\n\tslurm_mutex_lock(&_ucx_worker_lock);\n\n\tcount = pmixp_rlist_count(&priv->pending);\n\tfor (i=0; i < count; i++) {\n\t\t/* message is already processed, the value is\n\t\t * not valid anymore.\n\t\t * just dequeue from the list to ensure service\n\t\t * structures cleanup\n\t\t */\n\t\t(void)pmixp_rlist_deq(&priv->pending);\n\t}\n\t/* there will be no more pending messages, we can\n\t * safely release pending list now\n\t */\n\tpmixp_rlist_fini(&priv->pending);\n\tslurm_mutex_unlock(&_ucx_worker_lock);\n\n\treturn rc;\n}\n\n\nstatic int _ucx_send(void *_priv, void *msg)\n{\n\tpmixp_dconn_ucx_t *priv = (pmixp_dconn_ucx_t *)_priv;\n\tint rc = SLURM_SUCCESS;\n\tbool release = false;\n\n\tslurm_mutex_lock(&_ucx_worker_lock);\n\tif (!priv->connected) {\n\t\tpmixp_rlist_enq(&priv->pending, msg);\n\t} else {\n\t\tpmixp_ucx_req_t *req = NULL;\n\t\txassert(_direct_hdr_set);\n\t\tchar *mptr = _direct_hdr.buf_ptr(msg);\n\t\tsize_t msize = _direct_hdr.buf_size(msg);\n\t\treq = (pmixp_ucx_req_t*)\n\t\t\tucp_tag_send_nb(priv->server_ep,\n\t\t\t\t\t(void*)mptr, msize,\n\t\t\t\t\tucp_dt_make_contig(1),\n\t\t\t\t\tpmixp_info_nodeid(), send_handle);\n\t\tif (UCS_PTR_IS_ERR(req)) {\n\t\t\tPMIXP_ERROR(\"Unable to send UCX message: %s\\n\",\n\t\t\t\t    ucs_status_string(UCS_PTR_STATUS(req)));\n\t\t\tgoto exit;\n\t\t} else if (UCS_OK == UCS_PTR_STATUS(req)) {\n\t\t\t/* defer release until we unlock ucp worker */\n\t\t\trelease = true;\n\t\t} else {\n\t\t\treq->msg = msg;\n\t\t\treq->buffer = mptr;\n\t\t\treq->len = msize;\n\t\t\tpmixp_rlist_enq(&_snd_pending, (void*)req);\n\t\t\t_activate_progress();\n\n\t\t}\n\t}\nexit:\n\tslurm_mutex_unlock(&_ucx_worker_lock);\n\n\tif (release){\n\t\t_direct_hdr.send_complete(msg, PMIXP_P2P_INLINE,\n\t\t\t\t\t  SLURM_SUCCESS);\n\t}\n\treturn rc;\n}\n\nstatic void _ucx_regio(eio_handle_t *h)\n{\n\teio_obj_t *obj;\n\n\tpipe(_service_pipe);\n\tfd_set_nonblocking(_service_pipe[0]);\n\tfd_set_nonblocking(_service_pipe[1]);\n\tfd_set_close_on_exec(_service_pipe[0]);\n\tfd_set_close_on_exec(_service_pipe[1]);\n\n\tobj = eio_obj_create(_service_pipe[0], &_progress_ops, (void *)(-1));\n\teio_new_initial_obj(h, obj);\n\n\tobj = eio_obj_create(_server_fd, &_epoll_ops, (void *)(-1));\n\teio_new_initial_obj(h, obj);\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/src/lua/slurm_lua.c": "/*****************************************************************************\\\n *  slurm_lua.c - Lua integration common functions\n *****************************************************************************\n *  Copyright (C) 2015-2020 SchedMD LLC.\n *  Written by Tim Wickberg <tim@schedmd.com>\n *\n *  This file is part of Slurm, a resource management program.\n *  For details, see <https://slurm.schedmd.com/>.\n *  Please also read the included file: DISCLAIMER.\n *\n *  Slurm is free software; you can redistribute it and/or modify it under\n *  the terms of the GNU General Public License as published by the Free\n *  Software Foundation; either version 2 of the License, or (at your option)\n *  any later version.\n *\n *  In addition, as a special exception, the copyright holders give permission\n *  to link the code of portions of this program with the OpenSSL library under\n *  certain conditions as described in each individual source file, and\n *  distribute linked combinations including the two. You must obey the GNU\n *  General Public License in all respects for all of the code used other than\n *  OpenSSL. If you modify file(s) with this exception, you may extend this\n *  exception to your version of the file(s), but you are not obligated to do\n *  so. If you do not wish to do so, delete this exception statement from your\n *  version.  If you delete this exception statement from all source files in\n *  the program, then also delete it here.\n *\n *  Slurm is distributed in the hope that it will be useful, but WITHOUT ANY\n *  WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n *  FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more\n *  details.\n *\n *  You should have received a copy of the GNU General Public License along\n *  with Slurm; if not, write to the Free Software Foundation, Inc.,\n *  51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA.\n\\*****************************************************************************/\n\n#include <dlfcn.h>\n#include <stdio.h>\n#include \"config.h\"\n\n#include \"slurm/slurm.h\"\n#include \"slurm/slurm_errno.h\"\n\n#include <sys/stat.h>\n#include <sys/types.h>\n#include <unistd.h>\n\n#include \"src/common/log.h\"\n#include \"src/common/xstring.h\"\n#include \"src/lua/slurm_lua.h\"\n\nstatic const char *cluster_name = NULL;\n\n#ifdef HAVE_LUA\n\nstatic int _setup_stringarray(lua_State *L, int limit, char **data)\n{\n\t/*\n\t * if limit/data empty this will create an empty array intentionally to\n\t * allow the client code to iterate over it\n\t */\n\tlua_newtable(L);\n\tfor (int i = 0; i < limit && data && data[i]; i++) {\n\t\t/* by convention lua indexes array tables from 1 */\n\t\tlua_pushnumber(L, i + 1);\n\t\tlua_pushstring(L, data[i]);\n\t\tlua_settable(L, -3);\n\t}\n\treturn 1;\n}\n\n/*\n *  check that global symbol [name] in lua script is a function\n */\nstatic int _check_lua_script_function(lua_State *L, const char *name)\n{\n\tint rc = 0;\n\tlua_getglobal(L, name);\n\tif (!lua_isfunction(L, -1))\n\t\trc = -1;\n\tlua_pop(L, -1);\n\treturn (rc);\n}\n\n/*\n *   Verify all required functions are defined in the script\n */\nstatic int _check_lua_script_functions(lua_State *L, const char *plugin,\n\t\t\t\t       const char *script_path,\n\t\t\t\t       const char **req_fxns)\n{\n\tint rc = 0;\n\tconst char **ptr = NULL;\n\tfor (ptr = req_fxns; ptr && *ptr; ptr++) {\n\t\tif (_check_lua_script_function(L, *ptr) < 0) {\n\t\t\terror(\"%s: %s: missing required function %s\",\n\t\t\t      plugin, script_path, *ptr);\n\t\t\trc = -1;\n\t\t}\n\t}\n\n\treturn (rc);\n}\n\n/*\n *  Lua interface to Slurm log facility:\n */\nstatic int _log_lua_msg (lua_State *L)\n{\n\tconst char *prefix  = \"lua\";\n\tint        level    = 0;\n\tconst char *msg;\n\n\t/*\n\t *  Optional numeric prefix indicating the log level\n\t *  of the message.\n\t */\n\n\t/* Pop message off the lua stack */\n\tmsg = lua_tostring(L, -1);\n\tlua_pop(L, 1);\n\n\t/* Pop level off stack: */\n\tlevel = (int)lua_tonumber(L, -1);\n\tlua_pop(L, 1);\n\n\t/* Call appropriate slurm log function based on log-level argument */\n\tif (level > 4)\n\t\tdebug4 (\"%s: %s\", prefix, msg);\n\telse if (level == 4)\n\t\tdebug3 (\"%s: %s\", prefix, msg);\n\telse if (level == 3)\n\t\tdebug2 (\"%s: %s\", prefix, msg);\n\telse if (level == 2)\n\t\tdebug (\"%s: %s\", prefix, msg);\n\telse if (level == 1)\n\t\tverbose (\"%s: %s\", prefix, msg);\n\telse if (level == 0)\n\t\tinfo (\"%s: %s\", prefix, msg);\n\treturn (0);\n}\n\nstatic int _log_lua_error(lua_State *L)\n{\n\tconst char *prefix  = \"lua\";\n\tconst char *msg     = lua_tostring(L, -1);\n\terror (\"%s: %s\", prefix, msg);\n\treturn (0);\n}\n\nstatic const struct luaL_Reg slurm_functions [] = {\n\t{ \"log\", _log_lua_msg },\n\t{ \"error\", _log_lua_error },\n\t{ NULL, NULL }\n};\n\nstatic void _register_slurm_output_functions(lua_State *L)\n{\n\tchar *unpack_str;\n\tchar tmp_string[100];\n\n#if LUA_VERSION_NUM == 501\n\tunpack_str = \"unpack\";\n#else\n\tunpack_str = \"table.unpack\";\n#endif\n\t/*\n\t *  Register slurm output functions in a global \"slurm\" table\n\t */\n\tlua_newtable(L);\n\tslurm_lua_table_register(L, NULL, slurm_functions);\n\n\t/*\n\t *  Create more user-friendly lua versions of Slurm log functions.\n\t */\n\tsnprintf(tmp_string, sizeof(tmp_string),\n\t\t \"slurm.error (string.format(%s({...})))\",\n\t\t unpack_str);\n\tluaL_loadstring(L, tmp_string);\n\tlua_setfield(L, -2, \"log_error\");\n\tsnprintf(tmp_string, sizeof(tmp_string),\n\t\t \"slurm.log (0, string.format(%s({...})))\",\n\t\t unpack_str);\n\tluaL_loadstring(L, tmp_string);\n\tlua_setfield(L, -2, \"log_info\");\n\tsnprintf(tmp_string, sizeof(tmp_string),\n\t\t \"slurm.log (1, string.format(%s({...})))\",\n\t\t unpack_str);\n\tluaL_loadstring(L, tmp_string);\n\tlua_setfield(L, -2, \"log_verbose\");\n\tsnprintf(tmp_string, sizeof(tmp_string),\n\t\t \"slurm.log (2, string.format(%s({...})))\",\n\t\t unpack_str);\n\tluaL_loadstring(L, tmp_string);\n\tlua_setfield(L, -2, \"log_debug\");\n\tsnprintf(tmp_string, sizeof(tmp_string),\n\t\t \"slurm.log (3, string.format(%s({...})))\",\n\t\t unpack_str);\n\tluaL_loadstring(L, tmp_string);\n\tlua_setfield(L, -2, \"log_debug2\");\n\tsnprintf(tmp_string, sizeof(tmp_string),\n\t\t \"slurm.log (4, string.format(%s({...})))\",\n\t\t unpack_str);\n\tluaL_loadstring(L, tmp_string);\n\tlua_setfield(L, -2, \"log_debug3\");\n\tsnprintf(tmp_string, sizeof(tmp_string),\n\t\t \"slurm.log (5, string.format(%s({...})))\",\n\t\t unpack_str);\n\tluaL_loadstring(L, tmp_string);\n\tlua_setfield(L, -2, \"log_debug4\");\n\n\t/*\n\t * Error codes: slurm.SUCCESS, slurm.FAILURE, slurm.ERROR, etc.\n\t */\n\tlua_pushnumber(L, SLURM_ERROR);\n\tlua_setfield(L, -2, \"ERROR\");\n\tlua_pushnumber(L, SLURM_ERROR);\n\tlua_setfield(L, -2, \"FAILURE\");\n\tlua_pushnumber(L, SLURM_SUCCESS);\n\tlua_setfield(L, -2, \"SUCCESS\");\n\tlua_pushnumber(L, ESLURM_ACCESS_DENIED);\n\tlua_setfield(L, -2, \"ESLURM_ACCESS_DENIED\");\n\tlua_pushnumber(L, ESLURM_ACCOUNTING_POLICY);\n\tlua_setfield(L, -2, \"ESLURM_ACCOUNTING_POLICY\");\n\tlua_pushnumber(L, ESLURM_INVALID_ACCOUNT);\n\tlua_setfield(L, -2, \"ESLURM_INVALID_ACCOUNT\");\n\tlua_pushnumber(L, ESLURM_INVALID_LICENSES);\n\tlua_setfield(L, -2, \"ESLURM_INVALID_LICENSES\");\n\tlua_pushnumber(L, ESLURM_INVALID_NODE_COUNT);\n\tlua_setfield(L, -2, \"ESLURM_INVALID_NODE_COUNT\");\n\tlua_pushnumber(L, ESLURM_INVALID_TIME_LIMIT);\n\tlua_setfield(L, -2, \"ESLURM_INVALID_TIME_LIMIT\");\n\tlua_pushnumber(L, ESLURM_JOB_MISSING_SIZE_SPECIFICATION);\n\tlua_setfield(L, -2, \"ESLURM_JOB_MISSING_SIZE_SPECIFICATION\");\n\tlua_pushnumber(L, ESLURM_MISSING_TIME_LIMIT);\n\tlua_setfield(L, -2, \"ESLURM_MISSING_TIME_LIMIT\");\n\n\t/*\n\t * Other definitions needed to interpret data\n\t * slurm.MEM_PER_CPU, slurm.NO_VAL, etc.\n\t */\n\tlua_pushnumber(L, ALLOC_SID_ADMIN_HOLD);\n\tlua_setfield(L, -2, \"ALLOC_SID_ADMIN_HOLD\");\n\tlua_pushnumber(L, ALLOC_SID_USER_HOLD);\n\tlua_setfield(L, -2, \"ALLOC_SID_USER_HOLD\");\n\tlua_pushnumber(L, INFINITE);\n\tlua_setfield(L, -2, \"INFINITE\");\n\tlua_pushnumber(L, INFINITE64);\n\tlua_setfield(L, -2, \"INFINITE64\");\n\tlua_pushnumber(L, MAIL_JOB_BEGIN);\n\tlua_setfield(L, -2, \"MAIL_JOB_BEGIN\");\n\tlua_pushnumber(L, MAIL_JOB_END);\n\tlua_setfield(L, -2, \"MAIL_JOB_END\");\n\tlua_pushnumber(L, MAIL_JOB_FAIL);\n\tlua_setfield(L, -2, \"MAIL_JOB_FAIL\");\n\tlua_pushnumber(L, MAIL_JOB_REQUEUE);\n\tlua_setfield(L, -2, \"MAIL_JOB_REQUEUE\");\n\tlua_pushnumber(L, MAIL_JOB_TIME100);\n\tlua_setfield(L, -2, \"MAIL_JOB_TIME100\");\n\tlua_pushnumber(L, MAIL_JOB_TIME90);\n\tlua_setfield(L, -2, \"MAIL_JOB_TIME890\");\n\tlua_pushnumber(L, MAIL_JOB_TIME80);\n\tlua_setfield(L, -2, \"MAIL_JOB_TIME80\");\n\tlua_pushnumber(L, MAIL_JOB_TIME50);\n\tlua_setfield(L, -2, \"MAIL_JOB_TIME50\");\n\tlua_pushnumber(L, MAIL_JOB_STAGE_OUT);\n\tlua_setfield(L, -2, \"MAIL_JOB_STAGE_OUT\");\n\tlua_pushnumber(L, MEM_PER_CPU);\n\tlua_setfield(L, -2, \"MEM_PER_CPU\");\n\tlua_pushnumber(L, NICE_OFFSET);\n\tlua_setfield(L, -2, \"NICE_OFFSET\");\n\tlua_pushnumber(L, JOB_SHARED_NONE);\n\tlua_setfield(L, -2, \"JOB_SHARED_NONE\");\n\tlua_pushnumber(L, JOB_SHARED_OK);\n\tlua_setfield(L, -2, \"JOB_SHARED_OK\");\n\tlua_pushnumber(L, JOB_SHARED_USER);\n\tlua_setfield(L, -2, \"JOB_SHARED_USER\");\n\tlua_pushnumber(L, JOB_SHARED_MCS);\n\tlua_setfield(L, -2, \"JOB_SHARED_MCS\");\n\tlua_pushnumber(L, NO_VAL64);\n\tlua_setfield(L, -2, \"NO_VAL64\");\n\tlua_pushnumber(L, NO_VAL);\n\tlua_setfield(L, -2, \"NO_VAL\");\n\tlua_pushnumber(L, NO_VAL16);\n\tlua_setfield(L, -2, \"NO_VAL16\");\n\tlua_pushnumber(L, NO_VAL8);\n\tlua_setfield(L, -2, \"NO_VAL8\");\n\tlua_pushnumber(L, SHARED_FORCE);\n\tlua_setfield(L, -2, \"SHARED_FORCE\");\n\n\t/*\n\t * job_desc bitflags\n\t */\n\tlua_pushnumber(L, GRES_DISABLE_BIND);\n\tlua_setfield(L, -2, \"GRES_DISABLE_BIND\");\n\tlua_pushnumber(L, GRES_ENFORCE_BIND);\n\tlua_setfield(L, -2, \"GRES_ENFORCE_BIND\");\n\tlua_pushnumber(L, KILL_INV_DEP);\n\tlua_setfield(L, -2, \"KILL_INV_DEP\");\n\tlua_pushnumber(L, NO_KILL_INV_DEP);\n\tlua_setfield(L, -2, \"NO_KILL_INV_DEP\");\n\tlua_pushnumber(L, SPREAD_JOB);\n\tlua_setfield(L, -2, \"SPREAD_JOB\");\n\tlua_pushnumber(L, USE_MIN_NODES);\n\tlua_setfield(L, -2, \"USE_MIN_NODES\");\n\n\tlua_pushstring(L, cluster_name);\n\tlua_setfield(L, -2, \"CLUSTER_NAME\");\n}\n\nextern void slurm_lua_table_register(lua_State *L, const char *libname,\n\t\t\t\t     const luaL_Reg *l)\n{\n#if LUA_VERSION_NUM == 501\n\tluaL_register(L, libname, l);\n#else\n\tluaL_setfuncs(L, l, 0);\n\tif (libname)\n\t\tlua_setglobal(L, libname);\n#endif\n}\n\n/*\n * Get fields in an existing slurmctld job record.\n *\n * This is an incomplete list of job record fields. Add more as needed and\n * send patches to slurm-dev@schedmd.com.\n */\nextern int slurm_lua_job_record_field(lua_State *L, const job_record_t *job_ptr,\n\t\t\t\t      const char *name)\n{\n\tint i;\n\n\tif (!job_ptr) {\n\t\terror(\"_job_rec_field: job_ptr is NULL\");\n\t\tlua_pushnil(L);\n\t} else if (!xstrcmp(name, \"account\")) {\n\t\tlua_pushstring(L, job_ptr->account);\n\t} else if (!xstrcmp(name, \"admin_comment\")) {\n\t\tlua_pushstring(L, job_ptr->admin_comment);\n\t} else if (!xstrcmp(name, \"argv\")) {\n\t\tif (job_ptr->details)\n\t\t\t_setup_stringarray(L, job_ptr->details->argc,\n\t\t\t\t\t   job_ptr->details->argv);\n\t\telse\n\t\t\tlua_newtable(L);\n\t} else if (!xstrcmp(name, \"array_job_id\")) {\n\t\tlua_pushnumber(L, job_ptr->array_job_id);\n\t} else if (!xstrcmp(name, \"array_task_cnt\")) {\n\t\tif (job_ptr->array_recs)\n\t\t\tlua_pushnumber(L, job_ptr->array_recs->task_cnt);\n\t\telse\n\t\t\tlua_pushnil(L);\n\t} else if (!xstrcmp(name, \"array_task_id\")) {\n\t\tlua_pushnumber(L, job_ptr->array_task_id);\n\t} else if (!xstrcmp(name, \"batch_features\")) {\n\t\tlua_pushstring(L, job_ptr->batch_features);\n\t} else if (!xstrcmp(name, \"batch_host\")) {\n\t\tlua_pushstring(L, job_ptr->batch_host);\n\t} else if (!xstrcmp(name, \"best_switch\")) {\n\t\tlua_pushnumber(L, job_ptr->best_switch);\n\t} else if (!xstrcmp(name, \"burst_buffer\")) {\n\t\tlua_pushstring(L, job_ptr->burst_buffer);\n\t} else if (!xstrcmp(name, \"comment\")) {\n\t\tlua_pushstring(L, job_ptr->comment);\n\t} else if (!xstrcmp(name, \"cpus_per_tres\")) {\n\t\tlua_pushstring(L, job_ptr->cpus_per_tres);\n\t} else if (!xstrcmp(name, \"delay_boot\")) {\n\t\tlua_pushnumber(L, job_ptr->delay_boot);\n\t} else if (!xstrcmp(name, \"derived_ec\")) {\n\t\tlua_pushnumber(L, job_ptr->derived_ec);\n\t} else if (!xstrcmp(name, \"direct_set_prio\")) {\n\t\tlua_pushnumber(L, job_ptr->direct_set_prio);\n\t} else if (!xstrcmp(name, \"end_time\")) {\n\t\tlua_pushnumber(L, job_ptr->end_time);\n\t} else if (!xstrcmp(name, \"exit_code\")) {\n\t\tlua_pushnumber(L, job_ptr->exit_code);\n\t} else if (!xstrcmp(name, \"features\")) {\n\t\tif (job_ptr->details)\n\t\t\tlua_pushstring(L, job_ptr->details->features);\n\t\telse\n\t\t\tlua_pushnil(L);\n\t} else if (!xstrcmp(name, \"gres\")) {\n\t\t/* \"gres\" replaced by \"tres_per_node\" in v18.08 */\n\t\tlua_pushstring(L, job_ptr->tres_per_node);\n\t} else if (!xstrcmp(name, \"gres_req\")) {\n\t\tlua_pushstring(L, job_ptr->gres_req);\n\t} else if (!xstrcmp(name, \"gres_used\")) {\n\t\tlua_pushstring(L, job_ptr->gres_used);\n\t} else if (!xstrcmp(name, \"group_id\")) {\n\t\tlua_pushnumber(L, job_ptr->group_id);\n\t} else if (!xstrcmp(name, \"job_id\")) {\n\t\tlua_pushnumber(L, job_ptr->job_id);\n\t} else if (!xstrcmp(name, \"job_state\")) {\n\t\tlua_pushnumber(L, job_ptr->job_state);\n\t} else if (!xstrcmp(name, \"licenses\")) {\n\t\tlua_pushstring(L, job_ptr->licenses);\n\t} else if (!xstrcmp(name, \"max_cpus\")) {\n\t\tif (job_ptr->details)\n\t\t\tlua_pushnumber(L, job_ptr->details->max_cpus);\n\t\telse\n\t\t\tlua_pushnumber(L, 0);\n\t} else if (!xstrcmp(name, \"max_nodes\")) {\n\t\tif (job_ptr->details)\n\t\t\tlua_pushnumber(L, job_ptr->details->max_nodes);\n\t\telse\n\t\t\tlua_pushnumber(L, 0);\n\t} else if (!xstrcmp(name, \"mem_per_tres\")) {\n\t\tlua_pushstring(L, job_ptr->mem_per_tres);\n\t} else if (!xstrcmp(name, \"min_cpus\")) {\n\t\tif (job_ptr->details)\n\t\t\tlua_pushnumber(L, job_ptr->details->min_cpus);\n\t\telse\n\t\t\tlua_pushnumber(L, 0);\n\t} else if (!xstrcmp(name, \"min_mem_per_node\")) {\n\t\tif (job_ptr->details &&\n\t\t    (job_ptr->details->pn_min_memory != NO_VAL64) &&\n\t\t    !(job_ptr->details->pn_min_memory & MEM_PER_CPU))\n\t\t\tlua_pushnumber(L, job_ptr->details->pn_min_memory);\n\t\telse\n\t\t\tlua_pushnil(L);\n\t} else if (!xstrcmp(name, \"min_mem_per_cpu\")) {\n\t\tif (job_ptr->details &&\n\t\t    (job_ptr->details->pn_min_memory != NO_VAL64) &&\n\t\t    (job_ptr->details->pn_min_memory & MEM_PER_CPU))\n\t\t\tlua_pushnumber(L, job_ptr->details->pn_min_memory &\n\t\t\t\t       ~MEM_PER_CPU);\n\t\telse\n\t\t\tlua_pushnil(L);\n\t} else if (!xstrcmp(name, \"min_nodes\")) {\n\t\tif (job_ptr->details)\n\t\t\tlua_pushnumber(L, job_ptr->details->min_nodes);\n\t\telse\n\t\t\tlua_pushnumber(L, 0);\n\t} else if (!xstrcmp(name, \"name\")) {\n\t\tlua_pushstring(L, job_ptr->name);\n\t} else if (!xstrcmp(name, \"nice\")) {\n\t\tif (job_ptr->details)\n\t\t\tlua_pushnumber(L, job_ptr->details->nice);\n\t\telse\n\t\t\tlua_pushnumber(L, NO_VAL16);\n\t} else if (!xstrcmp(name, \"nodes\")) {\n\t\tlua_pushstring(L, job_ptr->nodes);\n\t} else if (!xstrcmp(name, \"origin_cluster\")) {\n\t\tlua_pushstring(L, job_ptr->origin_cluster);\n\t\t/* Continue support for old hetjob terminology. */\n\t} else if (!xstrcmp(name, \"pack_job_id\") ||\n\t\t   !xstrcmp(name, \"het_job_id\")) {\n\t\tlua_pushnumber(L, job_ptr->het_job_id);\n\t} else if (!xstrcmp(name, \"pack_job_id_set\") ||\n\t\t   !xstrcmp(name, \"het_job_id_set\")) {\n\t\tlua_pushstring(L, job_ptr->het_job_id_set);\n\t} else if (!xstrcmp(name, \"pack_job_offset\") ||\n\t\t   !xstrcmp(name, \"het_job_offset\")) {\n\t\tlua_pushnumber(L, job_ptr->het_job_offset);\n\t} else if (!xstrcmp(name, \"partition\")) {\n\t\tlua_pushstring(L, job_ptr->partition);\n\t} else if (!xstrcmp(name, \"pn_min_cpus\")) {\n\t\tif (job_ptr->details)\n\t\t\tlua_pushnumber(L, job_ptr->details->pn_min_cpus);\n\t\telse\n\t\t\tlua_pushnumber(L, NO_VAL);\n\t} else if (!xstrcmp(name, \"pn_min_memory\")) {\n\t\t/*\n\t\t * FIXME: Remove this in the future, lua can't handle 64bit\n\t\t * numbers!!!.  Use min_mem_per_node|cpu instead.\n\t\t */\n\t\tif (job_ptr->details)\n\t\t\tlua_pushnumber(L, job_ptr->details->pn_min_memory);\n\t\telse\n\t\t\tlua_pushnumber(L, NO_VAL64);\n\t} else if (!xstrcmp(name, \"priority\")) {\n\t\tlua_pushnumber(L, job_ptr->priority);\n\t} else if (!xstrcmp(name, \"qos\")) {\n\t\tif (job_ptr->qos_ptr) {\n\t\t\tlua_pushstring(L, job_ptr->qos_ptr->name);\n\t\t} else {\n\t\t\tlua_pushnil(L);\n\t\t}\n\t} else if (!xstrcmp(name, \"reboot\")) {\n\t\tlua_pushnumber(L, job_ptr->reboot);\n\t} else if (!xstrcmp(name, \"req_switch\")) {\n\t\tlua_pushnumber(L, job_ptr->req_switch);\n\t} else if (!xstrcmp(name, \"resizing\")) {\n\t\tint resizing = IS_JOB_RESIZING(job_ptr) ? 1 : 0;\n\t\tlua_pushnumber(L, resizing);\n\t} else if (!xstrcmp(name, \"restart_cnt\")) {\n\t\tlua_pushnumber(L, job_ptr->restart_cnt);\n\t} else if (!xstrcmp(name, \"resv_name\")) {\n\t\tlua_pushstring(L, job_ptr->resv_name);\n\t} else if (!xstrcmp(name, \"script\")) {\n\t\tBuf bscript = get_job_script(job_ptr);\n\t\tif (bscript) {\n\t\t\tchar *script = bscript->head;\n\t\t\tif (script && script[0] != '\\0')\n\t\t\t\tlua_pushstring(L, script);\n\t\t\telse\n\t\t\t\tlua_pushnil(L);\n\t\t} else\n\t\t\tlua_pushnil(L);\n\t\tfree_buf(bscript);\n \t} else if (!xstrcmp(name, \"site_factor\")) {\n\t\tif (job_ptr->site_factor == NO_VAL)\n\t\t\tlua_pushnumber(L, job_ptr->site_factor);\n\t\telse\n\t\t\tlua_pushnumber(L,\n\t\t\t\t       (((int64_t)job_ptr->site_factor)\n\t\t\t\t\t- NICE_OFFSET));\n\t} else if (!xstrcmp(name, \"spank_job_env\")) {\n\t\tif ((job_ptr->spank_job_env_size == 0) ||\n\t\t    (job_ptr->spank_job_env == NULL)) {\n\t\t\tlua_pushnil(L);\n\t\t} else {\n\t\t\tlua_newtable(L);\n\t\t\tfor (i = 0; i < job_ptr->spank_job_env_size; i++) {\n\t\t\t\tif (job_ptr->spank_job_env[i] != NULL) {\n\t\t\t\t\tlua_pushnumber(L, i);\n\t\t\t\t\tlua_pushstring(\n\t\t\t\t\t\tL, job_ptr->spank_job_env[i]);\n\t\t\t\t\tlua_settable(L, -3);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t} else if (!xstrcmp(name, \"spank_job_env_size\")) {\n\t\tlua_pushnumber(L, job_ptr->spank_job_env_size);\n\t} else if (!xstrcmp(name, \"start_time\")) {\n\t\tlua_pushnumber(L, job_ptr->start_time);\n\t} else if (!xstrcmp(name, \"std_err\")) {\n\t\tif (job_ptr->details)\n\t\t\tlua_pushstring(L, job_ptr->details->std_err);\n\t\telse\n\t\t\tlua_pushnil(L);\n\t} else if (!xstrcmp(name, \"std_in\")) {\n\t\tif (job_ptr->details)\n\t\t\tlua_pushstring(L, job_ptr->details->std_in);\n\t\telse\n\t\t\tlua_pushnil(L);\n\t} else if (!xstrcmp(name, \"std_out\")) {\n\t\tif (job_ptr->details)\n\t\t\tlua_pushstring(L, job_ptr->details->std_out);\n\t\telse\n\t\t\tlua_pushnil(L);\n\t} else if (!xstrcmp(name, \"submit_time\")) {\n\t\tif (job_ptr->details)\n\t\t\tlua_pushnumber(L, job_ptr->details->submit_time);\n\t\telse\n\t\t\tlua_pushnil(L);\n\t} else if (!xstrcmp(name, \"time_limit\")) {\n\t\tlua_pushnumber(L, job_ptr->time_limit);\n\t} else if (!xstrcmp(name, \"time_min\")) {\n\t\tlua_pushnumber(L, job_ptr->time_min);\n\t} else if (!xstrcmp(name, \"total_cpus\")) {\n\t\tlua_pushnumber(L, job_ptr->total_cpus);\n\t} else if (!xstrcmp(name, \"total_nodes\")) {\n\t\tlua_pushnumber(L, job_ptr->total_nodes);\n\t} else if (!xstrcmp(name, \"tres_alloc_str\")) {\n\t\tlua_pushstring(L, job_ptr->tres_alloc_str);\n\t} else if (!xstrcmp(name, \"tres_bind\")) {\n\t\tlua_pushstring(L, job_ptr->tres_bind);\n\t} else if (!xstrcmp(name, \"tres_freq\")) {\n\t\tlua_pushstring(L, job_ptr->tres_freq);\n\t} else if (!xstrcmp(name, \"tres_per_job\")) {\n\t\tlua_pushstring(L, job_ptr->tres_per_job);\n\t} else if (!xstrcmp(name, \"tres_per_node\")) {\n\t\tlua_pushstring(L, job_ptr->tres_per_node);\n\t} else if (!xstrcmp(name, \"tres_per_socket\")) {\n\t\tlua_pushstring(L, job_ptr->tres_per_socket);\n\t} else if (!xstrcmp(name, \"tres_per_task\")) {\n\t\tlua_pushstring(L, job_ptr->tres_per_task);\n\t} else if (!xstrcmp(name, \"user_id\")) {\n\t\tlua_pushnumber(L, job_ptr->user_id);\n\t} else if (!xstrcmp(name, \"user_name\")) {\n\t\tlua_pushstring(L, job_ptr->user_name);\n\t} else if (!xstrcmp(name, \"wait4switch\")) {\n\t\tlua_pushnumber(L, job_ptr->wait4switch);\n\t} else if (!xstrcmp(name, \"wait4switch_start\")) {\n\t\tlua_pushnumber(L, job_ptr->wait4switch_start);\n\t} else if (!xstrcmp(name, \"wckey\")) {\n\t\tlua_pushstring(L, job_ptr->wckey);\n\t} else if (!xstrcmp(name, \"work_dir\")) {\n\t\tif (job_ptr->details)\n\t\t\tlua_pushstring(L, job_ptr->details->work_dir);\n\t\telse\n\t\t\tlua_pushnil(L);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\n\treturn 1;\n}\n\nextern int slurm_lua_isnumber(lua_State *L, int index)\n{\n\t/* lua_isnumber didn't exist before lua5.3 */\n#if LUA_VERSION_NUM == 503\n\treturn lua_isnumber(L, index);\n#else\n\treturn lua_isnumber(L, index);\n#endif\n}\n\n\n/* Generic stack dump function for debugging purposes */\nextern void slurm_lua_stack_dump(const char *plugin, char *header, lua_State *L)\n{\n#if _DEBUG\n\tint i;\n\tint top = lua_gettop(L);\n\n\tinfo(\"%s: dumping %s stack, %d elements\", plugin, header, top);\n\tfor (i = 1; i <= top; i++) {  /* repeat for each level */\n\t\tint type = lua_type(L, i);\n\t\tswitch (type) {\n\t\tcase LUA_TSTRING:\n\t\t\tinfo(\"string[%d]:%s\", i, lua_tostring(L, i));\n\t\t\tbreak;\n\t\tcase LUA_TBOOLEAN:\n\t\t\tinfo(\"boolean[%d]:%s\", i,\n\t\t\t     lua_toboolean(L, i) ? \"true\" : \"false\");\n\t\t\tbreak;\n\t\tcase LUA_TNUMBER:\n\t\t\tinfo(\"number[%d]:%d\", i,\n\t\t\t     (int) lua_tonumber(L, i));\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tinfo(\"other[%d]:%s\", i, lua_typename(L, type));\n\t\t\tbreak;\n\t\t}\n\t}\n#endif\n}\n\nextern lua_State *slurm_lua_loadscript(lua_State *curr, const char *plugin,\n\t\t\t\t       const char *script_path,\n\t\t\t\t       const char **req_fxns,\n\t\t\t\t       time_t *load_time,\n\t\t\t\t       void (*local_options)(lua_State *L))\n{\n\n\tlua_State *new = NULL;\n\tstruct stat st;\n\tint rc = 0;\n\n\tif (stat(script_path, &st) != 0) {\n\t\tif (curr) {\n\t\t\t(void) error(\"%s: Unable to stat %s, using old script: %s\",\n\t\t\t             plugin, script_path, strerror(errno));\n\t\t\treturn curr;\n\t\t}\n\t\t(void) error(\"%s: Unable to stat %s: %s\",\n\t\t             plugin, script_path, strerror(errno));\n\t\treturn NULL;\n\t}\n\n\tif (st.st_mtime <= *load_time) {\n\t\tdebug3(\"%s: %s: skipping loading Lua script: %s\", plugin,\n\t\t       __func__, script_path);\n\t\treturn curr;\n\t}\n\tdebug3(\"%s: %s: loading Lua script: %s\", __func__, plugin, script_path);\n\n\t/*\n\t *  Initilize lua\n\t */\n\tif (!(new = luaL_newstate())) {\n\t\terror(\"%s: %s: luaL_newstate() failed to allocate.\",\n\t\t      plugin, __func__);\n\t\treturn curr;\n\t}\n\n\tluaL_openlibs(new);\n\tif (luaL_loadfile(new, script_path)) {\n\t\tif (curr) {\n\t\t\terror(\"%s: %s: %s, using previous script\",\n\t\t\t      plugin, script_path,\n\t\t\t      lua_tostring(new, -1));\n\t\t\tlua_close(new);\n\t\t\treturn curr;\n\t\t}\n\t\terror(\"%s: %s: %s\", plugin, script_path,\n\t\t      lua_tostring(new, -1));\n\t\tlua_pop(new, 1);\n\t\tlua_close(new);\n\t\treturn NULL;\n\t}\n\n\t/*\n\t *  Register Slurm functions in lua state:\n\t *  logging and slurm structure read/write functions\n\t */\n\t_register_slurm_output_functions(new);\n\tif (*(local_options))\n\t\t(*(local_options))(new);\n\telse\n\t\tlua_setglobal(new, \"slurm\"); /* done in local_options */\n\n\n\t/*\n\t *  Run the user script:\n\t */\n\tif (lua_pcall(new, 0, 1, 0)) {\n\t\tif (curr) {\n\t\t\terror(\"%s: %s: %s, using previous script\",\n\t\t\t      plugin, script_path,\n\t\t\t      lua_tostring(new, -1));\n\t\t\tlua_close(new);\n\t\t\treturn curr;\n\t\t}\n\t\terror(\"%s: %s: %s\", plugin, script_path,\n\t\t      lua_tostring(new, -1));\n\t\tlua_pop(new, 1);\n\t\tlua_close(new);\n\t\treturn NULL;\n\t}\n\n\t/*\n\t *  Get any return code from the lua script\n\t */\n\trc = (int) lua_tonumber(new, -1);\n\tif (rc != SLURM_SUCCESS) {\n\t\tif (curr) {\n\t\t\t(void) error(\"%s: %s: returned %d on load, using previous script\",\n\t\t\t             plugin, script_path, rc);\n\t\t\tlua_close(new);\n\t\t\treturn curr;\n\t\t}\n\t\t(void) error(\"%s: %s: returned %d on load\", plugin,\n\t\t\t     script_path, rc);\n\t\tlua_pop(new, 1);\n\t\tlua_close(new);\n\t\treturn NULL;\n\t}\n\n\t/*\n\t *  Check for required lua script functions:\n\t */\n\trc = _check_lua_script_functions(new, plugin, script_path, req_fxns);\n\tif (rc != SLURM_SUCCESS) {\n\t\tif (curr) {\n\t\t\t(void) error(\"%s: %s: required function(s) not present, using previous script\",\n\t\t\t             plugin, script_path);\n\t\t\tlua_close(new);\n\t\t\treturn curr;\n\t\t}\n\t\tlua_close(new);\n\t\treturn NULL;\n\t}\n\n\t*load_time = st.st_mtime;\n\treturn new;\n}\n#endif\n\n/*\n *  Init function to dlopen() the appropriate Lua libraries, and\n *  ensure the lua version matches what we compiled against along with other\n *  init things.\n */\nextern int slurm_lua_init(void)\n{\n\tslurm_lua_fini();\n\n\t/*\n\t *  Need to dlopen() liblua.so with RTLD_GLOBAL in order to\n\t *   ensure symbols from liblua are available to libs opened\n\t *   by any lua scripts.\n\t */\n\tif (!LUA_VERSION_NUM) {\n\t\tfatal(\"Slurm wasn't configured against any LUA lib but you are trying to use it like it was.  Please check config.log and reconfigure against liblua.  Make sure you have lua devel installed.\");\n\t} else if (!dlopen(\"liblua.so\",       RTLD_NOW | RTLD_GLOBAL) &&\n#if LUA_VERSION_NUM == 503\n\t\t   !dlopen(\"liblua-5.3.so\",   RTLD_NOW | RTLD_GLOBAL) &&\n\t\t   !dlopen(\"liblua5.3.so\",    RTLD_NOW | RTLD_GLOBAL) &&\n\t\t   !dlopen(\"liblua5.3.so.0\",  RTLD_NOW | RTLD_GLOBAL) &&\n\t\t   !dlopen(\"liblua.so.5.3\",   RTLD_NOW | RTLD_GLOBAL)\n#elif LUA_VERSION_NUM == 502\n\t\t   !dlopen(\"liblua-5.2.so\",   RTLD_NOW | RTLD_GLOBAL) &&\n\t\t   !dlopen(\"liblua5.2.so\",    RTLD_NOW | RTLD_GLOBAL) &&\n\t\t   !dlopen(\"liblua5.2.so.0\",  RTLD_NOW | RTLD_GLOBAL) &&\n\t\t   !dlopen(\"liblua.so.5.2\",   RTLD_NOW | RTLD_GLOBAL)\n#else\n\t\t   !dlopen(\"liblua-5.1.so\",   RTLD_NOW | RTLD_GLOBAL) &&\n\t\t   !dlopen(\"liblua5.1.so\",    RTLD_NOW | RTLD_GLOBAL) &&\n\t\t   !dlopen(\"liblua5.1.so.0\",  RTLD_NOW | RTLD_GLOBAL) &&\n\t\t   !dlopen(\"liblua.so.5.1\",   RTLD_NOW | RTLD_GLOBAL)\n#endif\n\t\t) {\n\t\treturn error(\"Failed to open liblua.so: %s\", dlerror());\n\t}\n\n\tcluster_name = slurm_get_cluster_name();\n\n\treturn SLURM_SUCCESS;\n}\n\n/*\n * Close down the lib, free memory and such.\n */\nextern void slurm_lua_fini(void)\n{\n\txfree(cluster_name);\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/src/lua/slurm_lua.h": "/*****************************************************************************\\\n *  slurm_lua.h - Lua integration common functions\n *****************************************************************************\n *  Copyright (C) 2015-2020 SchedMD LLC.\n *  Written by Tim Wickberg <tim@schedmd.com>\n *\n *  This file is part of Slurm, a resource management program.\n *  For details, see <https://slurm.schedmd.com/>.\n *  Please also read the included file: DISCLAIMER.\n *\n *  Slurm is free software; you can redistribute it and/or modify it under\n *  the terms of the GNU General Public License as published by the Free\n *  Software Foundation; either version 2 of the License, or (at your option)\n *  any later version.\n *\n *  In addition, as a special exception, the copyright holders give permission\n *  to link the code of portions of this program with the OpenSSL library under\n *  certain conditions as described in each individual source file, and\n *  distribute linked combinations including the two. You must obey the GNU\n *  General Public License in all respects for all of the code used other than\n *  OpenSSL. If you modify file(s) with this exception, you may extend this\n *  exception to your version of the file(s), but you are not obligated to do\n *  so. If you do not wish to do so, delete this exception statement from your\n *  version.  If you delete this exception statement from all source files in\n *  the program, then also delete it here.\n *\n *  Slurm is distributed in the hope that it will be useful, but WITHOUT ANY\n *  WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n *  FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more\n *  details.\n *\n *  You should have received a copy of the GNU General Public License along\n *  with Slurm; if not, write to the Free Software Foundation, Inc.,\n *  51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA.\n\\*****************************************************************************/\n\n#ifndef _SLURM_LUA_H\n#define _SLURM_LUA_H\n\n#ifdef HAVE_LUA\n\n#include <lua.h>\n#include <lauxlib.h>\n#include <lualib.h>\n#include \"src/slurmctld/slurmctld.h\"\n\n/* Generic stack dump function for debugging purposes */\nextern void slurm_lua_stack_dump(const char *plugin,\n\t\t\t\t char *header, lua_State *L);\n\n/*\n * function for create a new lua state object, loading a lua script, setting up\n * basic slurm/lua integration and returning the lua state to the caller.\n * If the script mtime is greater than *load_time, a new lua state will be\n * allocated and configured, the caller should close the old one after\n * completing any remaining setup.\n *\n * Parameters:\n * curr (in)   - current lua state object, should be NULL on first call\n * plugin (in) - string identifying the calling plugin, e.g. \"job_submit/lua\"\n * script_path (in) - path to script file\n * req_fxns (in) - NULL terminated array of functions that must exist in the\n *                 script\n * load_time (in/out) - mtime of script from the curr lua state object\n *\n * Returns:\n * pointer to new lua_State object - the caller should complete setup of the\n *                                   new environment, and possibly free any\n *                                   existing.\n * NULL -- an error occured, the caller should continue using the current object\n * same value as curr - no error, or a strong suggestion that the caller should\n *                      continue using the same state obj, with no further setup\n */\nextern lua_State *slurm_lua_loadscript(lua_State *curr, const char *plugin,\n\t\t\t\t       const char *script_path,\n\t\t\t\t       const char **req_fxns,\n\t\t\t\t       time_t *load_time,\n\t\t\t\t       void (*local_options)(lua_State *L));\nextern void slurm_lua_table_register(lua_State *L, const char *libname,\n\t\t\t\t     const luaL_Reg *l);\n\n/*\n * Get fields in an existing slurmctld job record.\n *\n * This is an incomplete list of job record fields. Add more as needed and\n * send patches to slurm-dev@schedmd.com.\n */\nextern int slurm_lua_job_record_field(lua_State *L, const job_record_t *job_ptr,\n\t\t\t\t      const char *name);\n\nextern int slurm_lua_isinteger(lua_State *L, int index);\n\n#else\n# define LUA_VERSION_NUM 0\n#endif\n\n/*\n *  Init function to dlopen() the appropriate Lua libraries, and\n *  ensure the lua version matches what we compiled against along with other\n *  init things.\n */\nextern int slurm_lua_init(void);\n\n/*\n * Close down the lib, free memory and such.\n */\nextern void slurm_lua_fini(void);\n\n#endif\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/src/slurmctld/controller.c": "/*****************************************************************************\\\n *  controller.c - main control machine daemon for slurm\n *****************************************************************************\n *  Copyright (C) 2002-2007 The Regents of the University of California.\n *  Copyright (C) 2008-2010 Lawrence Livermore National Security.\n *  Portions Copyright (C) 2010-2016 SchedMD LLC.\n *  Produced at Lawrence Livermore National Laboratory (cf, DISCLAIMER).\n *  Written by Morris Jette <jette1@llnl.gov>, Kevin Tew <tew1@llnl.gov>\n *  CODE-OCEC-09-009. All rights reserved.\n *\n *  This file is part of Slurm, a resource management program.\n *  For details, see <https://slurm.schedmd.com/>.\n *  Please also read the included file: DISCLAIMER.\n *\n *  Slurm is free software; you can redistribute it and/or modify it under\n *  the terms of the GNU General Public License as published by the Free\n *  Software Foundation; either version 2 of the License, or (at your option)\n *  any later version.\n *\n *  In addition, as a special exception, the copyright holders give permission\n *  to link the code of portions of this program with the OpenSSL library under\n *  certain conditions as described in each individual source file, and\n *  distribute linked combinations including the two. You must obey the GNU\n *  General Public License in all respects for all of the code used other than\n *  OpenSSL. If you modify file(s) with this exception, you may extend this\n *  exception to your version of the file(s), but you are not obligated to do\n *  so. If you do not wish to do so, delete this exception statement from your\n *  version.  If you delete this exception statement from all source files in\n *  the program, then also delete it here.\n *\n *  Slurm is distributed in the hope that it will be useful, but WITHOUT ANY\n *  WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n *  FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more\n *  details.\n *\n *  You should have received a copy of the GNU General Public License along\n *  with Slurm; if not, write to the Free Software Foundation, Inc.,\n *  51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA.\n\\*****************************************************************************/\n\n#include \"config.h\"\n\n#if HAVE_SYS_PRCTL_H\n#  include <sys/prctl.h>\n#endif\n\n#include <errno.h>\n#include <grp.h>\n#include <poll.h>\n#include <pthread.h>\n#include <signal.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <sys/resource.h>\n#include <sys/stat.h>\n#include <unistd.h>\n\n#include \"slurm/slurm_errno.h\"\n\n#include \"src/common/assoc_mgr.h\"\n#include \"src/common/daemonize.h\"\n#include \"src/common/fd.h\"\n#include \"src/common/gres.h\"\n#include \"src/common/group_cache.h\"\n#include \"src/common/hostlist.h\"\n#include \"src/common/layouts_mgr.h\"\n#include \"src/common/log.h\"\n#include \"src/common/macros.h\"\n#include \"src/common/node_features.h\"\n#include \"src/common/node_select.h\"\n#include \"src/common/pack.h\"\n#include \"src/common/power.h\"\n#include \"src/common/prep.h\"\n#include \"src/common/proc_args.h\"\n#include \"src/common/read_config.h\"\n#include \"src/common/slurm_acct_gather_profile.h\"\n#include \"src/common/slurm_accounting_storage.h\"\n#include \"src/common/slurm_auth.h\"\n#include \"src/common/slurm_ext_sensors.h\"\n#include \"src/common/slurm_jobacct_gather.h\"\n#include \"src/common/slurm_jobcomp.h\"\n#include \"src/common/slurm_mcs.h\"\n#include \"src/common/slurm_priority.h\"\n#include \"src/common/slurm_protocol_api.h\"\n#include \"src/common/slurm_protocol_interface.h\"\n#include \"src/common/slurm_rlimits_info.h\"\n#include \"src/common/slurm_route.h\"\n#include \"src/common/slurm_topology.h\"\n#include \"src/common/switch.h\"\n#include \"src/common/timers.h\"\n#include \"src/common/track_script.h\"\n#include \"src/common/uid.h\"\n#include \"src/common/xcgroup_read_config.h\"\n#include \"src/common/xsignal.h\"\n#include \"src/common/xstring.h\"\n\n#include \"src/slurmctld/acct_policy.h\"\n#include \"src/slurmctld/agent.h\"\n#include \"src/slurmctld/burst_buffer.h\"\n#include \"src/slurmctld/fed_mgr.h\"\n#include \"src/slurmctld/front_end.h\"\n#include \"src/slurmctld/gang.h\"\n#include \"src/slurmctld/heartbeat.h\"\n#include \"src/slurmctld/job_scheduler.h\"\n#include \"src/slurmctld/job_submit.h\"\n#include \"src/slurmctld/licenses.h\"\n#include \"src/slurmctld/locks.h\"\n#include \"src/slurmctld/ping_nodes.h\"\n#include \"src/slurmctld/port_mgr.h\"\n#include \"src/slurmctld/power_save.h\"\n#include \"src/slurmctld/powercapping.h\"\n#include \"src/slurmctld/preempt.h\"\n#include \"src/slurmctld/proc_req.h\"\n#include \"src/slurmctld/read_config.h\"\n#include \"src/slurmctld/reservation.h\"\n#include \"src/slurmctld/sched_plugin.h\"\n#include \"src/slurmctld/slurmctld.h\"\n#include \"src/slurmctld/slurmctld_plugstack.h\"\n#include \"src/slurmctld/srun_comm.h\"\n#include \"src/slurmctld/state_save.h\"\n#include \"src/slurmctld/trigger_mgr.h\"\n\n\n#define DEFAULT_DAEMONIZE 1\t/* Run as daemon by default if set */\n#define DEFAULT_RECOVER   1\t/* Default state recovery on restart\n\t\t\t\t * 0 = use no saved state information\n\t\t\t\t * 1 = recover saved job state,\n\t\t\t\t *     node DOWN/DRAIN state & reason information\n\t\t\t\t * 2 = recover state saved from last shutdown */\n#define MIN_CHECKIN_TIME  3\t/* Nodes have this number of seconds to\n\t\t\t\t * check-in before we ping them */\n#define SHUTDOWN_WAIT     2\t/* Time to wait for backup server shutdown */\n#define JOB_COUNT_INTERVAL 30   /* Time to update running job count */\n\n/**************************************************************************\\\n * To test for memory leaks, set MEMORY_LEAK_DEBUG to 1 using\n * \"configure --enable-memory-leak-debug\" then execute\n *\n * $ valgrind --tool=memcheck --leak-check=yes --num-callers=40 \\\n *   --leak-resolution=high ./slurmctld -Dc >valg.ctld.out 2>&1\n *\n * Then exercise the slurmctld functionality before executing\n * > scontrol shutdown\n *\n * Note that --enable-memory-leak-debug will cause the daemon to\n * unload the shared objects at exit thus preventing valgrind\n * to display the stack where the eventual leaks may be.\n * It is always best to test with and without --enable-memory-leak-debug.\n *\n * On some systems _keyvalue_regex_init() will generate two blocks \"definitely\n *    lost\", both of size zero.\n * On some systems dlopen() will generate a small number of \"definitely\n *    lost\" blocks that are not cleared by dlclose().\n * On some systems, pthread_create() will generated a small number of\n *    \"possibly lost\" blocks.\n * Otherwise the report should be free of errors. Remember to reset\n *    MEMORY_LEAK_DEBUG to 0 for production use (non-seamless backup\n *    controller use).\n\\**************************************************************************/\n\n/* Log to stderr and syslog until becomes a daemon */\nlog_options_t log_opts = LOG_OPTS_INITIALIZER;\n/* Scheduler Log options */\nlog_options_t sched_log_opts = SCHEDLOG_OPTS_INITIALIZER;\n\n/* Global variables */\nbool    preempt_send_user_signal = false;\nuint16_t accounting_enforce = 0;\nint\tassociation_based_accounting = 0;\nvoid *\tacct_db_conn = NULL;\nint\tbackup_inx;\nint\tbatch_sched_delay = 3;\nuint32_t cluster_cpus = 0;\ntime_t\tcontrol_time = 0;\nbool disable_remote_singleton = false;\nint max_depend_depth = 10;\ntime_t\tlast_proc_req_start = 0;\nbool\tping_nodes_now = false;\npthread_cond_t purge_thread_cond = PTHREAD_COND_INITIALIZER;\npthread_mutex_t purge_thread_lock = PTHREAD_MUTEX_INITIALIZER;\npthread_mutex_t check_bf_running_lock = PTHREAD_MUTEX_INITIALIZER;\nint\tsched_interval = 60;\nslurmctld_config_t slurmctld_config;\ndiag_stats_t slurmctld_diag_stats;\nint\tslurmctld_primary = 1;\nbool\twant_nodes_reboot = true;\nint   slurmctld_tres_cnt = 0;\nslurmdb_cluster_rec_t *response_cluster_rec = NULL;\nbool    test_config = false;\nint     test_config_rc = 0;\nuint16_t running_cache = 0;\npthread_mutex_t assoc_cache_mutex = PTHREAD_MUTEX_INITIALIZER;\npthread_cond_t assoc_cache_cond = PTHREAD_COND_INITIALIZER;\n\n/* Local variables */\nstatic pthread_t assoc_cache_thread = (pthread_t) 0;\nstatic bool\tbu_acct_reg = false;\nstatic int\tbu_rc = SLURM_SUCCESS;\nstatic int\tbu_thread_cnt = 0;\nstatic pthread_cond_t bu_cond = PTHREAD_COND_INITIALIZER;\nstatic pthread_mutex_t bu_mutex = PTHREAD_MUTEX_INITIALIZER;\nstatic int\tdaemonize = DEFAULT_DAEMONIZE;\nstatic int\tdebug_level = 0;\nstatic char *\tdebug_logfile = NULL;\nstatic bool\tdump_core = false;\nstatic int      job_sched_cnt = 0;\nstatic uint32_t max_server_threads = MAX_SERVER_THREADS;\nstatic time_t\tnext_stats_reset = 0;\nstatic int\tnew_nice = 0;\nstatic int\trecover   = DEFAULT_RECOVER;\nstatic pthread_mutex_t sched_cnt_mutex = PTHREAD_MUTEX_INITIALIZER;\nstatic pid_t\tslurmctld_pid;\nstatic char *\tslurm_conf_filename;\n\n/*\n * Static list of signals to block in this process\n * *Must be zero-terminated*\n */\nstatic int controller_sigarray[] = {\n\tSIGINT,  SIGTERM, SIGCHLD, SIGUSR1,\n\tSIGUSR2, SIGTSTP, SIGXCPU, SIGQUIT,\n\tSIGPIPE, SIGALRM, SIGABRT, SIGHUP, 0\n};\n\ntypedef struct primary_thread_arg {\n\tpid_t cpid;\n\tchar *prog_type;\n} primary_thread_arg_t;\n\nstatic int          _accounting_cluster_ready();\nstatic int          _accounting_mark_all_nodes_down(char *reason);\nstatic void *       _assoc_cache_mgr(void *no_data);\nstatic int          _controller_index(void);\nstatic void         _become_slurm_user(void);\nstatic void         _create_clustername_file(void);\nstatic void         _default_sigaction(int sig);\nstatic void         _get_fed_updates();\nstatic void         _init_config(void);\nstatic void         _init_pidfile(void);\nstatic int          _init_tres(void);\nstatic void         _kill_old_slurmctld(void);\nstatic void         _parse_commandline(int argc, char **argv);\nstatic void *       _purge_files_thread(void *no_data);\nstatic void         _remove_assoc(slurmdb_assoc_rec_t *rec);\nstatic void         _remove_qos(slurmdb_qos_rec_t *rec);\nstatic void         _run_primary_prog(bool primary_on);\nstatic void *       _service_connection(void *arg);\nstatic void         _set_work_dir(void);\nstatic int          _shutdown_backup_controller(void);\nstatic void *       _slurmctld_background(void *no_data);\nstatic void *       _slurmctld_rpc_mgr(void *no_data);\nstatic void *       _slurmctld_signal_hand(void *no_data);\nstatic void         _test_thread_limit(void);\nstatic void         _update_assoc(slurmdb_assoc_rec_t *rec);\ninline static void  _update_cred_key(void);\nstatic void         _update_diag_job_state_counts(void);\nstatic void         _update_cluster_tres(void);\nstatic void         _update_nice(void);\nstatic void         _update_qos(slurmdb_qos_rec_t *rec);\ninline static void  _usage(char *prog_name);\nstatic bool         _verify_clustername(void);\nstatic bool         _wait_for_server_thread(void);\nstatic void *       _wait_primary_prog(void *arg);\n\n/* main - slurmctld main function, start various threads and process RPCs */\nint main(int argc, char **argv)\n{\n\tint cnt, error_code, i;\n\tstruct timeval start, now;\n\tstruct stat stat_buf;\n\tstruct rlimit rlim;\n\t/* Locks: Write configuration, job, node, and partition */\n\tslurmctld_lock_t config_write_lock = {\n\t\tWRITE_LOCK, WRITE_LOCK, WRITE_LOCK, WRITE_LOCK, NO_LOCK };\n\tslurm_trigger_callbacks_t callbacks;\n\tprep_callbacks_t prep_callbacks = {\n\t\t.prolog_slurmctld = prep_prolog_slurmctld_callback,\n\t\t.epilog_slurmctld = prep_epilog_slurmctld_callback,\n\t};\n\tbool create_clustername_file;\n\tchar *conf_file;\n\n\t/*\n\t * Make sure we have no extra open files which\n\t * would be propagated to spawned tasks.\n\t */\n\tcnt = sysconf(_SC_OPEN_MAX);\n\tfor (i = 3; i < cnt; i++)\n\t\tclose(i);\n\n\t/*\n\t * Establish initial configuration\n\t */\n\t_init_config();\n\t_parse_commandline(argc, argv);\n\tlog_init(argv[0], log_opts, LOG_DAEMON, NULL);\n\tsched_log_init(argv[0], sched_log_opts, LOG_DAEMON, NULL);\n\tslurmctld_pid = getpid();\n\t/*\n\t * Must pass in an explicit filename to slurm_conf_init() to avoid\n\t * the \"configless\" mode of operation kicking in if no file is\n\t * currently available.\n\t */\n\tif (!(conf_file = slurm_conf_filename))\n\t\tif (!(conf_file = getenv(\"SLURM_CONF\")))\n\t\t\tconf_file = default_slurm_config_file;\n\tslurm_conf_init(conf_file);\n\n\tupdate_logging();\n\n\tmemset(&slurmctld_diag_stats, 0, sizeof(slurmctld_diag_stats));\n\t/*\n\t * Calculate speed of gettimeofday() for sdiag.\n\t * Large delays indicate the Linux vDSO is not in use, which\n\t * will lead to significant scheduler performance issues.\n\t */\n\tgettimeofday(&start, NULL);\n\n\tfor (i=0; i < 1000; i++) {\n\t\tgettimeofday(&now, NULL);\n\t}\n\n\tslurmctld_diag_stats.latency  = (now.tv_sec  - start.tv_sec) * 1000000;\n\tslurmctld_diag_stats.latency +=  now.tv_usec - start.tv_usec;\n\n\tif (slurmctld_diag_stats.latency > 200)\n\t\terror(\"High latency for 1000 calls to gettimeofday(): %d microseconds\",\n\t\t      slurmctld_diag_stats.latency);\n\n\t/*\n\t * Verify clustername from conf matches value in spool dir\n\t * exit if inconsistent to protect state files from corruption.\n\t * This needs to be done before we kill the old one just in case we\n\t * fail.\n\t */\n\tcreate_clustername_file = _verify_clustername();\n\n\t_update_nice();\n\tif (!test_config)\n\t\t_kill_old_slurmctld();\n\n\tfor (i = 0; i < 3; i++)\n\t\tfd_set_close_on_exec(i);\n\n\tif (daemonize) {\n\t\tslurmctld_config.daemonize = 1;\n\t\tif (xdaemon())\n\t\t\terror(\"daemon(): %m\");\n\t\tlog_set_timefmt(slurmctld_conf.log_fmt);\n\t\tlog_alter(log_opts, LOG_DAEMON,\n\t\t\t  slurmctld_conf.slurmctld_logfile);\n\t\tsched_log_alter(sched_log_opts, LOG_DAEMON,\n\t\t\t\tslurmctld_conf.sched_logfile);\n\t\tsched_debug(\"slurmctld starting\");\n\t} else {\n\t\tslurmctld_config.daemonize = 0;\n\t}\n\n\tif (!test_config) {\n\t\t/*\n\t\t * Need to create pidfile here in case we setuid() below\n\t\t * (init_pidfile() exits if it can't initialize pid file).\n\t\t * On Linux we also need to make this setuid job explicitly\n\t\t * able to write a core dump.\n\t\t */\n\t\t_init_pidfile();\n\t\t_become_slurm_user();\n\t}\n\n\t/*\n\t * Create StateSaveLocation directory if necessary.\n\t */\n\tset_slurmctld_state_loc();\n\n\tif (create_clustername_file)\n\t\t_create_clustername_file();\n\n\tif (daemonize)\n\t\t_set_work_dir();\n\n\tif (stat(slurmctld_conf.mail_prog, &stat_buf) != 0) {\n\t\terror(\"Configured MailProg is invalid\");\n\t\ttest_config_rc = 1;\n\t}\n\n\tif (!xstrcmp(slurmctld_conf.accounting_storage_type,\n\t\t     \"accounting_storage/none\")) {\n\t\tif (xstrcmp(slurmctld_conf.job_acct_gather_type,\n\t\t\t    \"jobacct_gather/none\"))\n\t\t\terror(\"Job accounting information gathered, \"\n\t\t\t      \"but not stored\");\n\t} else {\n\t\tif (!xstrcmp(slurmctld_conf.job_acct_gather_type,\n\t\t\t     \"jobacct_gather/none\"))\n\t\t\tinfo(\"Job accounting information stored, \"\n\t\t\t     \"but details not gathered\");\n\t}\n\n\tif (license_init(slurmctld_conf.licenses) != SLURM_SUCCESS) {\n\t\tif (test_config) {\n\t\t\terror(\"Invalid Licenses value: %s\",\n\t\t\t      slurmctld_conf.licenses);\n\t\t\ttest_config_rc = 1;\n\t\t} else {\n\t\t\tfatal(\"Invalid Licenses value: %s\",\n\t\t\t      slurmctld_conf.licenses);\n\t\t}\n\t}\n\n#ifdef PR_SET_DUMPABLE\n\tif (prctl(PR_SET_DUMPABLE, 1) < 0)\n\t\tdebug (\"Unable to set dumpable to 1\");\n#endif /* PR_SET_DUMPABLE */\n\n\t/* Warn if the stack size is not unlimited */\n\tif ((getrlimit(RLIMIT_STACK, &rlim) == 0) &&\n\t    (rlim.rlim_cur != RLIM_INFINITY))\n\t\tinfo(\"Stack size set to %ld\", rlim.rlim_max);\n\n\ttest_core_limit();\n\t_test_thread_limit();\n\n\t/*\n\t * This must happen before we spawn any threads\n\t * which are not designed to handle them\n\t */\n\tif (xsignal_block(controller_sigarray) < 0)\n\t\terror(\"Unable to block signals\");\n\n\tassociation_based_accounting =\n\t\tslurm_get_is_association_based_accounting();\n\taccounting_enforce = slurmctld_conf.accounting_storage_enforce;\n\tif (!xstrcasecmp(slurmctld_conf.accounting_storage_type,\n\t\t\t \"accounting_storage/slurmdbd\")) {\n\t\twith_slurmdbd = 1;\n\t\t/* we need job_list not to be NULL */\n\t\tinit_job_conf();\n\t}\n\n\tif (accounting_enforce && !association_based_accounting) {\n\t\taccounting_enforce = 0;\n\t\tslurmctld_conf.conf_flags &= (~CTL_CONF_WCKEY);\n\t\tslurmctld_conf.accounting_storage_enforce = 0;\n\n\t\terror(\"You can not have AccountingStorageEnforce \"\n\t\t      \"set for AccountingStorageType='%s'\",\n\t\t      slurmctld_conf.accounting_storage_type);\n\t}\n\n\tmemset(&callbacks, 0, sizeof(slurm_trigger_callbacks_t));\n\tcallbacks.acct_full   = trigger_primary_ctld_acct_full;\n\tcallbacks.dbd_fail    = trigger_primary_dbd_fail;\n\tcallbacks.dbd_resumed = trigger_primary_dbd_res_op;\n\tcallbacks.db_fail     = trigger_primary_db_fail;\n\tcallbacks.db_resumed  = trigger_primary_db_res_op;\n\n\tif (!test_config)\n\t\tinfo(\"%s version %s started on cluster %s\", slurm_prog_name,\n\t\t     SLURM_VERSION_STRING, slurmctld_conf.cluster_name);\n\tif ((error_code = gethostname_short(slurmctld_config.node_name_short,\n\t\t\t\t\t    MAX_SLURM_NAME)) &&\n\t    !test_config)\n\t\tfatal(\"getnodename_short error %s\", slurm_strerror(error_code));\n\tif ((error_code = gethostname(slurmctld_config.node_name_long,\n\t\t\t\t      MAX_SLURM_NAME)) &&\n\t    !test_config)\n\t\tfatal(\"getnodename error %s\", slurm_strerror(error_code));\n\n\t/* init job credential stuff */\n\tslurmctld_config.cred_ctx = slurm_cred_creator_ctx_create(\n\t\t\tslurmctld_conf.job_credential_private_key);\n\tif (!slurmctld_config.cred_ctx) {\n\t\tif (test_config) {\n\t\t\terror(\"slurm_cred_creator_ctx_create(%s): %m\",\n\t\t\t\tslurmctld_conf.job_credential_private_key);\n\t\t\ttest_config_rc = 1;\n\t\t} else {\n\t\t\tfatal(\"slurm_cred_creator_ctx_create(%s): %m\",\n\t\t\t\tslurmctld_conf.job_credential_private_key);\n\t\t}\n\t}\n\n\t/* Must set before plugins are loaded. */\n\tbackup_inx = _controller_index();\n\tif (backup_inx == -1) {\n\t\terror(\"This host (%s/%s) not a valid controller\",\n\t\t      slurmctld_config.node_name_short,\n\t\t      slurmctld_config.node_name_long);\n\t\texit(1);\n\t}\n\n\tif (test_config) {\n\t\tslurmctld_primary = 1;\n\t} else if (backup_inx > 0) {\n\t\tslurmctld_primary = 0;\n\n\t\tif (xstrcasestr(slurmctld_conf.sched_params,\n\t\t\t\t\"no_backup_scheduling\"))\n\t\t\tslurmctld_config.scheduling_disabled = true;\n\t}\n\n\tconfigless_setup();\n\n\t/*\n\t * Initialize plugins.\n\t * If running configuration test, report ALL failures.\n\t */\n\tif (slurm_auth_init(NULL) != SLURM_SUCCESS) {\n\t\tif (test_config) {\n\t\t\terror(\"failed to initialize authentication plugin\");\n\t\t\ttest_config_rc = 1;\n\t\t} else {\n\t\t\tfatal(\"failed to initialize authentication plugin\");\n\t\t}\n\t}\n\tif (slurm_select_init(0) != SLURM_SUCCESS) {\n\t\tif (test_config) {\n\t\t\terror(\"failed to initialize node selection plugin\");\n\t\t\ttest_config_rc = 1;\n\t\t} else {\n\t\t\tfatal(\"failed to initialize node selection plugin\");\n\t\t}\n\t}\n\t/* gres_plugin_init() must follow slurm_select_init() */\n\tif (gres_plugin_init() != SLURM_SUCCESS) {\n\t\tif (test_config) {\n\t\t\terror(\"failed to initialize gres plugin\");\n\t\t\ttest_config_rc = 1;\n\t\t} else {\n\t\t\tfatal(\"failed to initialize gres plugin\");\n\t\t}\n\t}\n\tif (slurm_preempt_init() != SLURM_SUCCESS) {\n\t\tif (test_config) {\n\t\t\terror(\"failed to initialize preempt plugin\");\n\t\t\ttest_config_rc = 1;\n\t\t} else {\n\t\t\tfatal(\"failed to initialize preempt plugin\");\n\t\t}\n\t}\n\tif (acct_gather_conf_init() != SLURM_SUCCESS) {\n\t\tif (test_config) {\n\t\t\terror(\"failed to initialize acct_gather plugins\");\n\t\t\ttest_config_rc = 1;\n\t\t} else {\n\t\t\tfatal(\"failed to initialize acct_gather plugins\");\n\t\t}\n\t}\n\tif (jobacct_gather_init() != SLURM_SUCCESS) {\n\t\tif (test_config) {\n\t\t\terror(\"failed to initialize jobacct_gather plugin\");\n\t\t\ttest_config_rc = 1;\n\t\t} else {\n\t\t\tfatal(\"failed to initialize jobacct_gather plugin\");\n\t\t}\n\t}\n\tif (job_submit_plugin_init() != SLURM_SUCCESS) {\n\t\tif (test_config) {\n\t\t\terror(\"failed to initialize job_submit plugin\");\n\t\t\ttest_config_rc = 1;\n\t\t} else {\n\t\t\tfatal(\"failed to initialize job_submit plugin\");\n\t\t}\n\t}\n\tif (prep_plugin_init(&prep_callbacks) != SLURM_SUCCESS) {\n\t\tif (test_config) {\n\t\t\terror(\"failed to initialize prep plugin\");\n\t\t\ttest_config_rc = 1;\n\t\t} else {\n\t\t\tfatal(\"failed to initialize prep plugin\");\n\t\t}\n\t}\n\tif (ext_sensors_init() != SLURM_SUCCESS) {\n\t\tif (test_config) {\n\t\t\terror(\"failed to initialize ext_sensors plugin\");\n\t\t\ttest_config_rc = 1;\n\t\t} else {\n\t\t\tfatal(\"failed to initialize ext_sensors plugin\");\n\t\t}\n\t}\n\tif (node_features_g_init() != SLURM_SUCCESS) {\n\t\tif (test_config) {\n\t\t\terror(\"failed to initialize node_features plugin\");\n\t\t\ttest_config_rc = 1;\n\t\t} else {\n\t\t\tfatal(\"failed to initialize node_features plugin\");\n\t\t}\n\t}\n\tif (switch_g_slurmctld_init() != SLURM_SUCCESS) {\n\t\tif (test_config) {\n\t\t\terror(\"failed to initialize switch plugin\");\n\t\t\ttest_config_rc = 1;\n\t\t} else {\n\t\t\tfatal(\"failed to initialize switch plugin\");\n\t\t}\n\t}\n\tconfig_power_mgr();\n\tagent_init();\n\tif (node_features_g_node_power() && !power_save_test()) {\n\t\tif (test_config) {\n\t\t\terror(\"PowerSave required with NodeFeatures plugin, \"\n\t\t\t      \"but not fully configured (SuspendProgram, \"\n\t\t\t      \"ResumeProgram and SuspendTime all required)\");\n\t\t\ttest_config_rc = 1;\n\t\t} else {\n\t\t\tfatal(\"PowerSave required with NodeFeatures plugin, \"\n\t\t\t      \"but not fully configured (SuspendProgram, \"\n\t\t\t      \"ResumeProgram and SuspendTime all required)\");\n\t\t}\n\t}\n\n\twhile (1) {\n\t\t/* initialization for each primary<->backup switch */\n\t\txfree(slurmctld_config.auth_info);\n\t\tslurmctld_config.auth_info = slurm_get_auth_info();\n\t\tslurmctld_config.shutdown_time = (time_t) 0;\n\t\tslurmctld_config.resume_backup = false;\n\n\t\t/* start in primary or backup mode */\n\t\tif (!slurmctld_primary) {\n\t\t\tslurm_sched_fini();\t/* make sure shutdown */\n\t\t\t_run_primary_prog(false);\n\t\t\trun_backup(&callbacks);\n\t\t\tagent_init();\t/* Killed at any previous shutdown */\n\t\t\t(void) _shutdown_backup_controller();\n\t\t\tif (slurm_acct_storage_init(NULL) != SLURM_SUCCESS)\n\t\t\t\tfatal(\"failed to initialize accounting_storage plugin\");\n\t\t} else if (test_config || slurmctld_primary) {\n\t\t\tif (!test_config) {\n\t\t\t\t(void) _shutdown_backup_controller();\n\t\t\t\ttrigger_primary_ctld_res_ctrl();\n\t\t\t\tctld_assoc_mgr_init(&callbacks);\n\t\t\t}\n\t\t\tif (slurm_acct_storage_init(NULL) != SLURM_SUCCESS) {\n\t\t\t\tif (test_config) {\n\t\t\t\t\terror(\"failed to initialize accounting_storage plugin\");\n\t\t\t\t\ttest_config_rc = 1;\n\t\t\t\t} else {\n\t\t\t\t\tfatal(\"failed to initialize accounting_storage plugin\");\n\t\t\t\t}\n\t\t\t}\n\t\t\t/* Now recover the remaining state information */\n\t\t\tlock_slurmctld(config_write_lock);\n\t\t\tif (switch_g_restore(slurmctld_conf.state_save_location,\n\t\t\t\t\t   recover ? true : false)) {\n\t\t\t\tif (test_config) {\n\t\t\t\t\terror(\"failed to initialize switch plugin\");\n\t\t\t\t\ttest_config_rc = 1;\n\t\t\t\t} else {\n\t\t\t\t\tfatal(\"failed to initialize switch plugin\");\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (test_config) {\n\t\t\t\tchar *result_str;\n\t\t\t\tif ((error_code = read_slurm_conf(0, false))) {\n\t\t\t\t\terror(\"read_slurm_conf reading %s: %s\",\n\t\t\t\t\t      slurmctld_conf.slurm_conf,\n\t\t\t\t\t      slurm_strerror(error_code));\n\t\t\t\t\ttest_config_rc = 1;\n\t\t\t\t}\n\t\t\t\tunlock_slurmctld(config_write_lock);\n\t\t\t\tif (config_test_result() != SLURM_SUCCESS)\n\t\t\t\t\ttest_config_rc = 1;\n\n\t\t\t\tif (test_config_rc == 0)\n\t\t\t\t\tresult_str = \"Succeeded\";\n\t\t\t\telse\n\t\t\t\t\tresult_str = \"FAILED\";\n\t\t\t\tlog_opts.stderr_level  = LOG_LEVEL_INFO;\n\t\t\t\tlog_opts.logfile_level = LOG_LEVEL_QUIET;\n\t\t\t\tlog_opts.syslog_level  = LOG_LEVEL_QUIET;\n\t\t\t\tlog_alter(log_opts, SYSLOG_FACILITY_DAEMON,\n\t\t\t\t\t  slurmctld_conf.slurmctld_logfile);\n\t\t\t\tinfo(\"%s configuration test\", result_str);\n\t\t\t\texit(test_config_rc);\n\t\t\t}\n\n\t\t\tif ((error_code = read_slurm_conf(recover, false))) {\n\t\t\t\tfatal(\"read_slurm_conf reading %s: %s\",\n\t\t\t\t      slurmctld_conf.slurm_conf,\n\t\t\t\t      slurm_strerror(error_code));\n\t\t\t}\n\t\t\tunlock_slurmctld(config_write_lock);\n\t\t\tselect_g_select_nodeinfo_set_all();\n\n\t\t\tif (recover == 0) {\n\t\t\t\tslurmctld_init_db = 1;\n\t\t\t\t_accounting_mark_all_nodes_down(\"cold-start\");\n\t\t\t}\n\t\t}\n\n\t\tif (!acct_db_conn) {\n\t\t\tacct_db_conn = acct_storage_g_get_connection(\n\t\t\t\t&callbacks, 0, NULL, false,\n\t\t\t\tslurmctld_conf.cluster_name);\n\t\t\tclusteracct_storage_g_register_ctld(\n\t\t\t\tacct_db_conn, slurmctld_conf.slurmctld_port);\n\t\t\t/*\n\t\t\t * We only send in a variable the first time\n\t\t\t * we call this since we are setting up static\n\t\t\t * variables inside the function sending a\n\t\t\t * NULL will just use those set before.\n\t\t\t */\n\t\t\tif (assoc_mgr_init(acct_db_conn, NULL, errno) &&\n\t\t\t    (accounting_enforce & ACCOUNTING_ENFORCE_ASSOCS) &&\n\t\t\t    !running_cache) {\n\t\t\t\ttrigger_primary_dbd_fail();\n\t\t\t\terror(\"assoc_mgr_init failure\");\n\t\t\t\tfatal(\"slurmdbd and/or database must be up at \"\n\t\t\t\t      \"slurmctld start time\");\n\t\t\t}\n\t\t}\n\n\t\tinfo(\"Running as primary controller\");\n\t\t_run_primary_prog(true);\n\t\tcontrol_time = time(NULL);\n\t\theartbeat_start();\n\t\tif ((slurmctld_config.resume_backup == false) &&\n\t\t    (slurmctld_primary == 1)) {\n\t\t\ttrigger_primary_ctld_res_op();\n\t\t}\n\n\t\t_accounting_cluster_ready();\n\n\t\t/*\n\t\t * call after registering so that the current cluster's\n\t\t * control_host and control_port will be filled in.\n\t\t */\n\t\tfed_mgr_init(acct_db_conn);\n\n\t\t/*\n\t\t * For cross-cluster job dependencies to work, we need to have\n\t\t * initialized federation first. So rather than calling this\n\t\t * from read_slurm_conf() we call it here immediately after\n\t\t * fed_mgr_init().\n\t\t */\n\t\trestore_job_dependencies();\n\n\t\tif (slurm_priority_init() != SLURM_SUCCESS)\n\t\t\tfatal(\"failed to initialize priority plugin\");\n\t\tif (slurm_sched_init() != SLURM_SUCCESS)\n\t\t\tfatal(\"failed to initialize scheduling plugin\");\n\t\tif (slurmctld_plugstack_init())\n\t\t\tfatal(\"failed to initialize slurmctld_plugstack\");\n\t\tif (bb_g_init() != SLURM_SUCCESS)\n\t\t\tfatal(\"failed to initialize burst buffer plugin\");\n\t\tif (power_g_init() != SLURM_SUCCESS)\n\t\t\tfatal(\"failed to initialize power management plugin\");\n\t\tif (slurm_mcs_init() != SLURM_SUCCESS)\n\t\t\tfatal(\"failed to initialize mcs plugin\");\n\n\t\t/*\n\t\t * create attached thread to process RPCs\n\t\t */\n\t\tserver_thread_incr();\n\t\tslurm_thread_create(&slurmctld_config.thread_id_rpc,\n\t\t\t\t    _slurmctld_rpc_mgr, NULL);\n\n\t\t/*\n\t\t * create attached thread for signal handling\n\t\t */\n\t\tslurm_thread_create(&slurmctld_config.thread_id_sig,\n\t\t\t\t    _slurmctld_signal_hand, NULL);\n\n\t\t/*\n\t\t * create attached thread for state save\n\t\t */\n\t\tslurm_thread_create(&slurmctld_config.thread_id_save,\n\t\t\t\t    slurmctld_state_save, NULL);\n\n\t\t/*\n\t\t * create attached thread for node power management\n  \t\t */\n\t\tstart_power_mgr(&slurmctld_config.thread_id_power);\n\n\t\t/*\n\t\t * create attached thread for purging completed job files\n\t\t */\n\t\tslurm_thread_create(&slurmctld_config.thread_id_purge_files,\n\t\t\t\t    _purge_files_thread, NULL);\n\n\t\t/*\n\t\t * process slurm background activities, could run as pthread\n\t\t */\n\t\t_slurmctld_background(NULL);\n\n\t\t/* termination of controller */\n\t\tswitch_g_save(slurmctld_conf.state_save_location);\n\t\tslurm_priority_fini();\n\t\tslurmctld_plugstack_fini();\n\t\tshutdown_state_save();\n\t\tslurm_mutex_lock(&purge_thread_lock);\n\t\tslurm_cond_signal(&purge_thread_cond); /* wake up last time */\n\t\tslurm_mutex_unlock(&purge_thread_lock);\n\t\tpthread_join(slurmctld_config.thread_id_purge_files, NULL);\n\t\tpthread_join(slurmctld_config.thread_id_sig,  NULL);\n\t\tpthread_join(slurmctld_config.thread_id_rpc,  NULL);\n\t\tpthread_join(slurmctld_config.thread_id_save, NULL);\n\t\tslurmctld_config.thread_id_purge_files = (pthread_t) 0;\n\t\tslurmctld_config.thread_id_sig  = (pthread_t) 0;\n\t\tslurmctld_config.thread_id_rpc  = (pthread_t) 0;\n\t\tslurmctld_config.thread_id_save = (pthread_t) 0;\n\n\t\t/* kill all scripts running by the slurmctld */\n\t\ttrack_script_flush();\n\n\t\tbb_g_fini();\n\t\tpower_g_fini();\n\t\tslurm_mcs_fini();\n\t\tfed_mgr_fini();\n\n\t\tif (running_cache) {\n\t\t\t/* break out and end the association cache\n\t\t\t * thread since we are shutting down, no reason\n\t\t\t * to wait for current info from the database */\n\t\t\tslurm_mutex_lock(&assoc_cache_mutex);\n\t\t\trunning_cache = NO_VAL16;\n\t\t\tslurm_cond_signal(&assoc_cache_cond);\n\t\t\tslurm_mutex_unlock(&assoc_cache_mutex);\n\t\t\tpthread_join(assoc_cache_thread, NULL);\n\t\t}\n\n\t\t/* Save any pending state save RPCs */\n\t\tacct_storage_g_close_connection(&acct_db_conn);\n\t\tslurm_acct_storage_fini();\n\n\t\t/*\n\t\t * join the power save thread after saving all state\n\t\t * since it could wait a while waiting for spawned\n\t\t * processes to exit\n\t\t */\n\t\tpthread_join(slurmctld_config.thread_id_power, NULL);\n\t\tslurmctld_config.thread_id_power = (pthread_t) 0;\n\n\t\t/* stop the heartbeat last */\n\t\theartbeat_stop();\n\n\t\t/*\n\t\t * Run SlurmctldPrimaryOffProg only if we are the primary\n\t\t * (backup_inx == 0). The backup controllers (backup_inx > 0)\n\t\t * already run it when dropping to standby mode.\n\t\t */\n\t\tif (slurmctld_primary)\n\t\t\t_run_primary_prog(false);\n\n\t\tif (slurmctld_config.resume_backup == false)\n\t\t\tbreak;\n\n\t\t/* primary controller doesn't resume backup mode */\n\t\tif ((slurmctld_config.resume_backup == true) &&\n\t\t    (slurmctld_primary == 1))\n\t\t\tbreak;\n\n\t\trecover = 2;\n\t}\n\n\tlayouts_fini();\n\tg_slurm_jobcomp_fini();\n\n\t/*\n\t * Since pidfile is created as user root (its owner is\n\t *   changed to SlurmUser) SlurmUser may not be able to\n\t *   remove it, so this is not necessarily an error.\n\t */\n\tif (unlink(slurmctld_conf.slurmctld_pidfile) < 0) {\n\t\tverbose(\"Unable to remove pidfile '%s': %m\",\n\t\t\tslurmctld_conf.slurmctld_pidfile);\n\t}\n\n\n#ifdef MEMORY_LEAK_DEBUG\n{\n\t/*\n\t * This should purge all allocated memory.\n\t *  Anything left over represents a leak.\n\t */\n\n\n\t/*\n\t * Give running agents a chance to complete and free memory.\n\t * Wait up to 6 seconds.\n\t */\n\tfor (i = 0; i < 60; i++) {\n\t\tagent_purge();\n\t\tusleep(100000);\n\t\tcnt = get_agent_count();\n\t\tif (cnt == 0)\n\t\t\tbreak;\n\t}\n\tif (cnt)\n\t\terror(\"Left %d agent threads active\", cnt);\n\n\tslurm_sched_fini();\t/* Stop all scheduling */\n\n\t/* Purge our local data structures */\n\tconfigless_clear();\n\txcgroup_fini_slurm_cgroup_conf();\n\tpower_save_fini();\n\tjob_fini();\n\tpart_fini();\t/* part_fini() must precede node_fini() */\n\tnode_fini();\n\tnode_features_g_fini();\n\tpurge_front_end_state();\n\tresv_fini();\n\ttrigger_fini();\n\tassoc_mgr_fini(1);\n\treserve_port_config(NULL);\n\tfree_rpc_stats();\n\n\t/* Some plugins are needed to purge job/node data structures,\n\t * unplug after other data structures are purged */\n\text_sensors_fini();\n\tgres_plugin_fini();\n\tjob_submit_plugin_fini();\n\tprep_plugin_fini();\n\tslurm_preempt_fini();\n\tjobacct_gather_fini();\n\tacct_gather_conf_destroy();\n\tslurm_select_fini();\n\tslurm_topo_fini();\n\tslurm_auth_fini();\n\tswitch_fini();\n\troute_fini();\n\n\t/* purge remaining data structures */\n\tgroup_cache_purge();\n\tlicense_free();\n\tslurm_cred_ctx_destroy(slurmctld_config.cred_ctx);\n\tslurm_cred_fini();\t/* must be after ctx_destroy */\n\tslurm_conf_destroy();\n\tslurm_api_clear_config();\n\tcluster_rec_free();\n\ttrack_script_fini();\n\tusleep(500000);\n}\n#else\n\t/*\n\t * Give REQUEST_SHUTDOWN a chance to get propagated, up to 3 seconds.\n\t */\n\tfor (i = 0; i < 30; i++) {\n\t\tagent_purge();\n\t\tcnt = get_agent_count();\n\t\tif (cnt == 0)\n\t\t\tbreak;\n\t\tusleep(100000);\n\t}\n\tif (i >= 30)\n\t\tinfo(\"Dropped %d hung communications to shutdown\", cnt);\n\n\t/*\n\t * do this outside of MEMORY_LEAK_DEBUG so that remote connections get\n\t * closed.\n\t */\n\n#endif\n\n\txfree(slurmctld_config.auth_info);\n\tif (cnt) {\n\t\tinfo(\"Slurmctld shutdown completing with %d active agent thread\",\n\t\t     cnt);\n\t}\n\tlog_fini();\n\tsched_log_fini();\n\n\tif (dump_core)\n\t\tabort();\n\telse\n\t\texit(0);\n}\n\n/* initialization of common slurmctld configuration */\nstatic void  _init_config(void)\n{\n\tstruct rlimit rlim;\n\n\trlimits_maximize_nofile();\n\tif (getrlimit(RLIMIT_CORE, &rlim) == 0) {\n\t\trlim.rlim_cur = rlim.rlim_max;\n\t\t(void) setrlimit(RLIMIT_CORE, &rlim);\n\t}\n\tif (getrlimit(RLIMIT_STACK, &rlim) == 0) {\n\t\t/* slurmctld can spawn lots of pthreads.\n\t\t * Set the (per thread) stack size to a\n\t\t * more \"reasonable\" value to avoid running\n\t\t * out of virtual memory and dying */\n\t\trlim.rlim_cur = rlim.rlim_max;\n\t\t(void) setrlimit(RLIMIT_STACK, &rlim);\n\t}\n\tif (getrlimit(RLIMIT_DATA, &rlim) == 0) {\n\t\trlim.rlim_cur = rlim.rlim_max;\n\t\t(void) setrlimit(RLIMIT_DATA, &rlim);\n\t}\n\n\tmemset(&slurmctld_config, 0, sizeof(slurmctld_config_t));\n\tslurm_cond_init(&slurmctld_config.backup_finish_cond, NULL);\n\tslurmctld_config.boot_time      = time(NULL);\n\tslurmctld_config.daemonize      = DEFAULT_DAEMONIZE;\n\tslurmctld_config.resume_backup  = false;\n\tslurmctld_config.server_thread_count = 0;\n\tslurmctld_config.shutdown_time  = (time_t) 0;\n\tslurmctld_config.thread_id_main = pthread_self();\n\tslurmctld_config.scheduling_disabled  = false;\n\tslurmctld_config.submissions_disabled = false;\n\ttrack_script_init();\n\tslurm_mutex_init(&slurmctld_config.thread_count_lock);\n\tslurm_cond_init(&slurmctld_config.thread_count_cond, NULL);\n\tslurmctld_config.thread_id_main    = (pthread_t) 0;\n\tslurmctld_config.thread_id_sig     = (pthread_t) 0;\n\tslurmctld_config.thread_id_rpc     = (pthread_t) 0;\n}\n\n/* Read configuration file.\n * Same name as API function for use in accounting_storage plugin.\n * Anything you add to this function must be added to the\n * _slurm_rpc_reconfigure_controller function inside proc_req.c try\n * to keep these in sync.\n */\nstatic void _reconfigure_slurm(void)\n{\n\t/* Locks: Write configuration, job, node, and partition */\n\tslurmctld_lock_t config_write_lock = {\n\t\tWRITE_LOCK, WRITE_LOCK, WRITE_LOCK, WRITE_LOCK, NO_LOCK };\n\tint rc;\n\n\tif (slurmctld_config.shutdown_time)\n\t\treturn;\n\n\t/*\n\t * XXX - need to shut down the scheduler\n\t * plugin, re-read the configuration, and then\n\t * restart the (possibly new) plugin.\n\t */\n\tlock_slurmctld(config_write_lock);\n\trc = read_slurm_conf(2, true);\n\tif (rc)\n\t\terror(\"read_slurm_conf: %s\", slurm_strerror(rc));\n\telse {\n\t\t_update_cred_key();\n\t\tset_slurmctld_state_loc();\n\t}\n\n\tgs_reconfig();\n\tunlock_slurmctld(config_write_lock);\n\txcgroup_reconfig_slurm_cgroup_conf();\n\tassoc_mgr_set_missing_uids();\n\tstart_power_mgr(&slurmctld_config.thread_id_power);\n\ttrigger_reconfig();\n\tpriority_g_reconfig(true);\t/* notify priority plugin too */\n\tsave_all_state();\t\t/* Has own locking */\n\tqueue_job_scheduler();\n}\n\n/* Request that the job scheduler execute soon (typically within seconds) */\nextern void queue_job_scheduler(void)\n{\n\tslurm_mutex_lock(&sched_cnt_mutex);\n\tjob_sched_cnt++;\n\tslurm_mutex_unlock(&sched_cnt_mutex);\n}\n\n/* _slurmctld_signal_hand - Process daemon-wide signals */\nstatic void *_slurmctld_signal_hand(void *no_data)\n{\n\tint sig;\n\tint i, rc;\n\tint sig_array[] = {SIGINT, SIGTERM, SIGHUP, SIGABRT, SIGUSR2, 0};\n\tsigset_t set;\n\n#if HAVE_SYS_PRCTL_H\n\tif (prctl(PR_SET_NAME, \"sigmgr\", NULL, NULL, NULL) < 0) {\n\t\terror(\"%s: cannot set my name to %s %m\", __func__, \"sigmgr\");\n\t}\n#endif\n\t(void) pthread_setcancelstate(PTHREAD_CANCEL_ENABLE, NULL);\n\t(void) pthread_setcanceltype(PTHREAD_CANCEL_ASYNCHRONOUS, NULL);\n\n\t/* Make sure no required signals are ignored (possibly inherited) */\n\tfor (i = 0; sig_array[i]; i++)\n\t\t_default_sigaction(sig_array[i]);\n\twhile (1) {\n\t\txsignal_sigset_create(sig_array, &set);\n\t\trc = sigwait(&set, &sig);\n\t\tif (rc == EINTR)\n\t\t\tcontinue;\n\t\tswitch (sig) {\n\t\tcase SIGINT:\t/* kill -2  or <CTRL-C> */\n\t\tcase SIGTERM:\t/* kill -15 */\n\t\t\tinfo(\"Terminate signal (SIGINT or SIGTERM) received\");\n\t\t\tslurmctld_config.shutdown_time = time(NULL);\n\t\t\tslurmctld_shutdown();\n\t\t\treturn NULL;\t/* Normal termination */\n\t\t\tbreak;\n\t\tcase SIGHUP:\t/* kill -1 */\n\t\t\tinfo(\"Reconfigure signal (SIGHUP) received\");\n\t\t\t_reconfigure_slurm();\n\t\t\tbreak;\n\t\tcase SIGABRT:\t/* abort */\n\t\t\tinfo(\"SIGABRT received\");\n\t\t\tslurmctld_config.shutdown_time = time(NULL);\n\t\t\tslurmctld_shutdown();\n\t\t\tdump_core = true;\n\t\t\treturn NULL;\n\t\tcase SIGUSR2:\n\t\t\tinfo(\"Logrotate signal (SIGUSR2) received\");\n\t\t\tupdate_logging();\n\t\t\tbreak;\n\t\tdefault:\n\t\t\terror(\"Invalid signal (%d) received\", sig);\n\t\t}\n\t}\n}\n\nstatic void _default_sigaction(int sig)\n{\n\tstruct sigaction act;\n\tif (sigaction(sig, NULL, &act)) {\n\t\terror(\"sigaction(%d): %m\", sig);\n\t\treturn;\n\t}\n\tif (act.sa_handler != SIG_IGN)\n\t\treturn;\n\n\tact.sa_handler = SIG_DFL;\n\tif (sigaction(sig, &act, NULL))\n\t\terror(\"sigaction(%d): %m\", sig);\n}\n\nstatic void _sig_handler(int signal)\n{\n}\n\n/*\n * _slurmctld_rpc_mgr - Read incoming RPCs and create pthread for each\n */\nstatic void *_slurmctld_rpc_mgr(void *no_data)\n{\n\tint newsockfd;\n\tstruct pollfd *fds;\n\tslurm_addr_t cli_addr, srv_addr;\n\tuint16_t port;\n\tchar ip[32];\n\tint fd_next = 0, i, nports;\n\tconnection_arg_t *conn_arg = NULL;\n\t/* Locks: Read config */\n\tslurmctld_lock_t config_read_lock = {\n\t\tREAD_LOCK, NO_LOCK, NO_LOCK, NO_LOCK, NO_LOCK };\n\tint sigarray[] = {SIGUSR1, 0};\n\n#if HAVE_SYS_PRCTL_H\n\tif (prctl(PR_SET_NAME, \"rpcmgr\", NULL, NULL, NULL) < 0) {\n\t\terror(\"%s: cannot set my name to %s %m\", __func__, \"rpcmgr\");\n\t}\n#endif\n\n\t(void) pthread_setcancelstate(PTHREAD_CANCEL_ENABLE, NULL);\n\t(void) pthread_setcanceltype(PTHREAD_CANCEL_ASYNCHRONOUS, NULL);\n\tdebug3(\"%s pid = %u\", __func__, getpid());\n\n\t/* initialize ports for RPCs */\n\tlock_slurmctld(config_read_lock);\n\tnports = slurmctld_conf.slurmctld_port_count;\n\tif (nports == 0) {\n\t\tfatal(\"slurmctld port count is zero\");\n\t\treturn NULL;\t/* Fix CLANG false positive */\n\t}\n\tfds = xcalloc(nports, sizeof(struct pollfd));\n\tfor (i = 0; i < nports; i++) {\n\t\tfds[i].fd = slurm_init_msg_engine_port(\n\t\t\tslurmctld_conf.slurmctld_port + i);\n\t\tfds[i].events = POLLIN;\n\t\tif (fds[i].fd == SLURM_ERROR) {\n\t\t\tfatal(\"slurm_init_msg_engine_port error %m\");\n\t\t\treturn NULL;\t/* Fix CLANG false positive */\n\t\t}\n\t\tfd_set_close_on_exec(fds[i].fd);\n\t\tif (slurm_get_stream_addr(fds[i].fd, &srv_addr)) {\n\t\t\terror(\"slurm_get_stream_addr error %m\");\n\t\t} else {\n\t\t\tslurm_get_ip_str(&srv_addr, &port, ip, sizeof(ip));\n\t\t\tdebug2(\"slurmctld listening on %s:%d\", ip, ntohs(port));\n\t\t}\n\t}\n\tunlock_slurmctld(config_read_lock);\n\n\t/*\n\t * Prepare to catch SIGUSR1 to interrupt accept().\n\t * This signal is generated by the slurmctld signal\n\t * handler thread upon receipt of SIGABRT, SIGINT,\n\t * or SIGTERM. That thread does all processing of\n\t * all signals.\n\t */\n\txsignal(SIGUSR1, _sig_handler);\n\txsignal_unblock(sigarray);\n\n\t/*\n\t * Process incoming RPCs until told to shutdown\n\t */\n\twhile (_wait_for_server_thread()) {\n\t\tif (poll(fds, nports, -1) == -1) {\n\t\t\tif (errno != EINTR)\n\t\t\t\terror(\"slurm_accept_msg_conn select: %m\");\n\t\t\tserver_thread_decr();\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* find one to process */\n\t\tfor (i = 0; i < nports; i++) {\n\t\t\tif (fds[(fd_next + i) % nports].revents) {\n\t\t\t\ti = (fd_next + i) % nports;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tfd_next = (i + 1) % nports;\n\n\t\t/*\n\t\t * accept needed for stream implementation is a no-op in\n\t\t * message implementation that just passes sockfd to newsockfd\n\t\t */\n\t\tif ((newsockfd = slurm_accept_msg_conn(fds[i].fd, &cli_addr))\n\t\t    == SLURM_ERROR) {\n\t\t\tif (errno != EINTR)\n\t\t\t\terror(\"slurm_accept_msg_conn: %m\");\n\t\t\tserver_thread_decr();\n\t\t\tcontinue;\n\t\t}\n\t\tfd_set_close_on_exec(newsockfd);\n\t\tconn_arg = xmalloc(sizeof(connection_arg_t));\n\t\tconn_arg->newsockfd = newsockfd;\n\t\tmemcpy(&conn_arg->cli_addr, &cli_addr, sizeof(slurm_addr_t));\n\n\t\tif (slurmctld_conf.debug_flags & DEBUG_FLAG_PROTOCOL) {\n\t\t\tchar inetbuf[64];\n\n\t\t\tslurm_print_slurm_addr(&cli_addr,\n\t\t\t\t\t\tinetbuf,\n\t\t\t\t\t\tsizeof(inetbuf));\n\t\t\tinfo(\"%s: accept() connection from %s\", __func__, inetbuf);\n\t\t}\n\n\t\tif (slurmctld_config.shutdown_time) {\n\t\t\tslurmctld_diag_stats.proc_req_raw++;\n\t\t\t_service_connection(conn_arg);\n\t\t} else {\n\t\t\tslurm_thread_create_detached(NULL, _service_connection,\n\t\t\t\t\t\t     conn_arg);\n\t\t}\n\t}\n\n\tdebug3(\"%s shutting down\", __func__);\n\tfor (i = 0; i < nports; i++)\n\t\tclose(fds[i].fd);\n\txfree(fds);\n\tserver_thread_decr();\n\tpthread_exit((void *) 0);\n\treturn NULL;\n}\n\n/*\n * _service_connection - service the RPC\n * IN/OUT arg - really just the connection's file descriptor, freed\n *\tupon completion\n * RET - NULL\n */\nstatic void *_service_connection(void *arg)\n{\n\tconnection_arg_t *conn = (connection_arg_t *) arg;\n\tvoid *return_code = NULL;\n\tslurm_msg_t msg;\n\n#if HAVE_SYS_PRCTL_H\n\tif (prctl(PR_SET_NAME, \"srvcn\", NULL, NULL, NULL) < 0) {\n\t\terror(\"%s: cannot set my name to %s %m\", __func__, \"srvcn\");\n\t}\n#endif\n\tslurm_msg_t_init(&msg);\n\tmsg.flags |= SLURM_MSG_KEEP_BUFFER;\n\t/*\n\t * slurm_receive_msg sets msg connection fd to accepted fd. This allows\n\t * possibility for slurmctld_req() to close accepted connection.\n\t */\n\tif (slurm_receive_msg(conn->newsockfd, &msg, 0) != 0) {\n\t\tchar addr_buf[32];\n\t\tslurm_print_slurm_addr(&conn->cli_addr, addr_buf,\n\t\t\t\t       sizeof(addr_buf));\n\t\terror(\"slurm_receive_msg [%s]: %m\", addr_buf);\n\t\t/* close the new socket */\n\t\tclose(conn->newsockfd);\n\t\tgoto cleanup;\n\t}\n\n\tif (errno != SLURM_SUCCESS) {\n\t\tif (errno == SLURM_PROTOCOL_VERSION_ERROR) {\n\t\t\tslurm_send_rc_msg(&msg, SLURM_PROTOCOL_VERSION_ERROR);\n\t\t} else\n\t\t\tinfo(\"_service_connection/slurm_receive_msg %m\");\n\t} else {\n\t\t/* process the request */\n\t\tslurmctld_req(&msg, conn);\n\t}\n\n\tif ((conn->newsockfd >= 0) && (close(conn->newsockfd) < 0))\n\t\terror (\"close(%d): %m\",  conn->newsockfd);\n\ncleanup:\n\tslurm_free_msg_members(&msg);\n\txfree(arg);\n\tserver_thread_decr();\n\n\treturn return_code;\n}\n\n/* Increment slurmctld_config.server_thread_count and don't return\n * until its value is no larger than MAX_SERVER_THREADS,\n * RET true unless shutdown in progress */\nstatic bool _wait_for_server_thread(void)\n{\n\tbool print_it = true;\n\tbool rc = true;\n\n\tslurm_mutex_lock(&slurmctld_config.thread_count_lock);\n\twhile (1) {\n\t\tif (slurmctld_config.shutdown_time) {\n\t\t\trc = false;\n\t\t\tbreak;\n\t\t}\n\t\tif (slurmctld_config.server_thread_count < max_server_threads) {\n\t\t\tslurmctld_config.server_thread_count++;\n\t\t\tbreak;\n\t\t} else {\n\t\t\t/* wait for state change and retry,\n\t\t\t * just a delay and not an error.\n\t\t\t * This can happen when the epilog completes\n\t\t\t * on a bunch of nodes at the same time, which\n\t\t\t * can easily happen for highly parallel jobs. */\n\t\t\tif (print_it) {\n\t\t\t\tstatic time_t last_print_time = 0;\n\t\t\t\ttime_t now = time(NULL);\n\t\t\t\tif (difftime(now, last_print_time) > 2) {\n\t\t\t\t\tverbose(\"server_thread_count over \"\n\t\t\t\t\t\t\"limit (%d), waiting\",\n\t\t\t\t\t\tslurmctld_config.\n\t\t\t\t\t\tserver_thread_count);\n\t\t\t\t\tlast_print_time = now;\n\t\t\t\t}\n\t\t\t\tprint_it = false;\n\t\t\t}\n\t\t\tslurm_cond_wait(&slurmctld_config.thread_count_cond,\n\t\t\t\t\t&slurmctld_config.thread_count_lock);\n\t\t}\n\t}\n\tslurm_mutex_unlock(&slurmctld_config.thread_count_lock);\n\treturn rc;\n}\n\n/* Decrement slurmctld thread count (as applies to thread limit) */\nextern void server_thread_decr(void)\n{\n\tslurm_mutex_lock(&slurmctld_config.thread_count_lock);\n\tif (slurmctld_config.server_thread_count > 0)\n\t\tslurmctld_config.server_thread_count--;\n\telse\n\t\terror(\"slurmctld_config.server_thread_count underflow\");\n\tslurm_cond_broadcast(&slurmctld_config.thread_count_cond);\n\tslurm_mutex_unlock(&slurmctld_config.thread_count_lock);\n}\n\n/* Increment slurmctld thread count (as applies to thread limit) */\nextern void server_thread_incr(void)\n{\n\tslurm_mutex_lock(&slurmctld_config.thread_count_lock);\n\tslurmctld_config.server_thread_count++;\n\tslurm_mutex_unlock(&slurmctld_config.thread_count_lock);\n}\n\nstatic int _accounting_cluster_ready(void)\n{\n\tint rc = SLURM_ERROR;\n\ttime_t event_time = time(NULL);\n\tbitstr_t *total_node_bitmap = NULL;\n\tchar *cluster_nodes = NULL, *cluster_tres_str;\n\tslurmctld_lock_t node_write_lock = {\n\t\tNO_LOCK, NO_LOCK, WRITE_LOCK, WRITE_LOCK, NO_LOCK };\n\tassoc_mgr_lock_t locks = { .tres = WRITE_LOCK };\n\n\tlock_slurmctld(node_write_lock);\n\t/* Now get the names of all the nodes on the cluster at this\n\t   time and send it also.\n\t*/\n\ttotal_node_bitmap = bit_alloc(node_record_count);\n\tbit_nset(total_node_bitmap, 0, node_record_count-1);\n\tcluster_nodes = bitmap2node_name_sortable(total_node_bitmap, 0);\n\tFREE_NULL_BITMAP(total_node_bitmap);\n\n\tassoc_mgr_lock(&locks);\n\n\tcluster_tres_str = slurmdb_make_tres_string(\n\t\tassoc_mgr_tres_list, TRES_STR_FLAG_SIMPLE);\n\tassoc_mgr_unlock(&locks);\n\n\tunlock_slurmctld(node_write_lock);\n\n\trc = clusteracct_storage_g_cluster_tres(acct_db_conn,\n\t\t\t\t\t\tcluster_nodes,\n\t\t\t\t\t\tcluster_tres_str, event_time,\n\t\t\t\t\t\tSLURM_PROTOCOL_VERSION);\n\n\txfree(cluster_nodes);\n\txfree(cluster_tres_str);\n\n\t/*\n\t * FIXME: We should do things differently here depending on the return\n\t *        value.  If NODES_CHANGE or FIRST_REQ we probably want to send\n\t *        most everything to accounting, but if just the TRES changed it\n\t *        means the nodes didn't change and we might not need to send\n\t *        anything.\n\t */\n\tif ((rc == ACCOUNTING_FIRST_REG) ||\n\t    (rc == ACCOUNTING_NODES_CHANGE_DB) ||\n\t    (rc == ACCOUNTING_TRES_CHANGE_DB)) {\n\t\t/* see if we are running directly to a database\n\t\t * instead of a slurmdbd.\n\t\t */\n\t\tsend_all_to_accounting(event_time, rc);\n\t\trc = SLURM_SUCCESS;\n\t}\n\n\treturn rc;\n}\n\nstatic int _accounting_mark_all_nodes_down(char *reason)\n{\n\tchar *state_file;\n\tstruct stat stat_buf;\n\tnode_record_t *node_ptr;\n\tint i;\n\ttime_t event_time;\n\tint rc = SLURM_ERROR;\n\n\tstate_file = xstrdup_printf(\"%s/node_state\",\n\t\t\t\t    slurmctld_conf.state_save_location);\n\tif (stat(state_file, &stat_buf)) {\n\t\tdebug(\"_accounting_mark_all_nodes_down: could not stat(%s) \"\n\t\t      \"to record node down time\", state_file);\n\t\tevent_time = time(NULL);\n\t} else {\n\t\tevent_time = stat_buf.st_mtime;\n\t}\n\txfree(state_file);\n\n\tif ((rc = acct_storage_g_flush_jobs_on_cluster(acct_db_conn,\n\t\t\t\t\t\t      event_time))\n\t   == SLURM_ERROR)\n\t\treturn rc;\n\n\tnode_ptr = node_record_table_ptr;\n\tfor (i = 0; i < node_record_count; i++, node_ptr++) {\n\t\tif (!node_ptr->name)\n\t\t\tcontinue;\n\t\tif ((rc = clusteracct_storage_g_node_down(\n\t\t\t    acct_db_conn,\n\t\t\t    node_ptr, event_time,\n\t\t\t    reason, slurmctld_conf.slurm_user_id))\n\t\t   == SLURM_ERROR)\n\t\t\tbreak;\n\t}\n\treturn rc;\n}\n\nstatic void _remove_assoc(slurmdb_assoc_rec_t *rec)\n{\n\tint cnt = 0;\n\n\tbb_g_reconfig();\n\n\tcnt = job_hold_by_assoc_id(rec->id);\n\n\tif (cnt) {\n\t\tinfo(\"Removed association id:%u user:%s, held %u jobs\",\n\t\t     rec->id, rec->user, cnt);\n\t} else\n\t\tdebug(\"Removed association id:%u user:%s\", rec->id, rec->user);\n}\n\nstatic void _remove_qos(slurmdb_qos_rec_t *rec)\n{\n\tint cnt = 0;\n\tListIterator itr;\n\tpart_record_t *part_ptr;\n\tslurmctld_lock_t part_write_lock =\n\t\t{ NO_LOCK, NO_LOCK, NO_LOCK, WRITE_LOCK, NO_LOCK };\n\n\tlock_slurmctld(part_write_lock);\n\tif (part_list) {\n\t\titr = list_iterator_create(part_list);\n\t\twhile ((part_ptr = list_next(itr))) {\n\t\t\tif (part_ptr->qos_ptr != rec)\n\t\t\t\tcontinue;\n\t\t\tinfo(\"Partition %s's QOS %s was just removed, \"\n\t\t\t     \"you probably didn't mean for this to happen \"\n\t\t\t     \"unless you are also removing the partition.\",\n\t\t\t     part_ptr->name, rec->name);\n\t\t\tpart_ptr->qos_ptr = NULL;\n\t\t}\n\t\tlist_iterator_destroy(itr);\n\t}\n\tunlock_slurmctld(part_write_lock);\n\n\tbb_g_reconfig();\n\n\tcnt = job_hold_by_qos_id(rec->id);\n\n\tif (cnt) {\n\t\tinfo(\"Removed QOS:%s held %u jobs\", rec->name, cnt);\n\t} else\n\t\tdebug(\"Removed QOS:%s\", rec->name);\n}\n\nstatic void _update_assoc(slurmdb_assoc_rec_t *rec)\n{\n\tListIterator job_iterator;\n\tjob_record_t *job_ptr;\n\t/* Write lock on jobs */\n\tslurmctld_lock_t job_write_lock =\n\t\t{ NO_LOCK, WRITE_LOCK, NO_LOCK, NO_LOCK, NO_LOCK };\n\n\tif (!job_list || !accounting_enforce\n\t    || !(accounting_enforce & ACCOUNTING_ENFORCE_LIMITS))\n\t\treturn;\n\n\tlock_slurmctld(job_write_lock);\n\tjob_iterator = list_iterator_create(job_list);\n\twhile ((job_ptr = list_next(job_iterator))) {\n\t\tif ((rec != job_ptr->assoc_ptr) || (!IS_JOB_PENDING(job_ptr)))\n\t\t\tcontinue;\n\n\t\tacct_policy_update_pending_job(job_ptr);\n\t}\n\tlist_iterator_destroy(job_iterator);\n\tunlock_slurmctld(job_write_lock);\n}\n\nstatic void _resize_qos(void)\n{\n\tListIterator itr;\n\tpart_record_t *part_ptr;\n\tslurmctld_lock_t part_write_lock =\n\t\t{ NO_LOCK, NO_LOCK, NO_LOCK, WRITE_LOCK, NO_LOCK };\n\n\tlock_slurmctld(part_write_lock);\n\tif (part_list) {\n\t\titr = list_iterator_create(part_list);\n\t\twhile ((part_ptr = list_next(itr))) {\n\t\t\tif (part_ptr->allow_qos) {\n\t\t\t\tinfo(\"got count for %s of %\"BITSTR_FMT, part_ptr->name,\n\t\t\t\t     bit_size(part_ptr->allow_qos_bitstr));\n\t\t\t\tqos_list_build(part_ptr->allow_qos,\n\t\t\t\t\t       &part_ptr->allow_qos_bitstr);\n\t\t\t\tinfo(\"now count for %s of %\"BITSTR_FMT, part_ptr->name,\n\t\t\t\t     bit_size(part_ptr->allow_qos_bitstr));\n\t\t\t}\n\t\t\tif (part_ptr->deny_qos)\n\t\t\t\tqos_list_build(part_ptr->deny_qos,\n\t\t\t\t\t       &part_ptr->deny_qos_bitstr);\n\t\t}\n\t\tlist_iterator_destroy(itr);\n\t}\n\tunlock_slurmctld(part_write_lock);\n}\n\nstatic void _update_qos(slurmdb_qos_rec_t *rec)\n{\n\tListIterator job_iterator;\n\tjob_record_t *job_ptr;\n\t/* Write lock on jobs */\n\tslurmctld_lock_t job_write_lock =\n\t\t{ NO_LOCK, WRITE_LOCK, NO_LOCK, NO_LOCK, NO_LOCK };\n\n\tif (!job_list || !accounting_enforce\n\t    || !(accounting_enforce & ACCOUNTING_ENFORCE_LIMITS))\n\t\treturn;\n\n\tlock_slurmctld(job_write_lock);\n\tjob_iterator = list_iterator_create(job_list);\n\twhile ((job_ptr = list_next(job_iterator))) {\n\t\tif ((rec != job_ptr->qos_ptr) || (!IS_JOB_PENDING(job_ptr)))\n\t\t\tcontinue;\n\n\t\tacct_policy_update_pending_job(job_ptr);\n\t}\n\tlist_iterator_destroy(job_iterator);\n\tunlock_slurmctld(job_write_lock);\n}\n\nstatic int _init_tres(void)\n{\n\tchar *temp_char = slurm_get_accounting_storage_tres();\n\tList char_list;\n\tList add_list = NULL;\n\tslurmdb_tres_rec_t *tres_rec;\n\tslurmdb_update_object_t update_object;\n\tassoc_mgr_lock_t locks = { .tres = READ_LOCK };\n\n\tif (!temp_char) {\n\t\terror(\"No tres defined, this should never happen\");\n\t\treturn SLURM_ERROR;\n\t}\n\n\tchar_list = list_create(xfree_ptr);\n\tslurm_addto_char_list(char_list, temp_char);\n\txfree(temp_char);\n\n\tmemset(&update_object, 0, sizeof(slurmdb_update_object_t));\n\tif (!association_based_accounting) {\n\t\tupdate_object.type = SLURMDB_ADD_TRES;\n\t\tupdate_object.objects = list_create(slurmdb_destroy_tres_rec);\n\t} else if (!g_tres_count)\n\t\tfatal(\"You are running with a database but for some reason \"\n\t\t      \"we have no TRES from it.  This should only happen if \"\n\t\t      \"the database is down and you don't have \"\n\t\t      \"any state files.\");\n\telse if ((g_tres_count < TRES_ARRAY_TOTAL_CNT) ||\n\t\t (xstrcmp(assoc_mgr_tres_array[TRES_ARRAY_BILLING]->type,\n\t\t\t  \"billing\")))\n\t\tfatal(\"You are running with a database but for some reason we have less TRES than should be here (%d < %d) and/or the \\\"billing\\\" TRES is missing. This should only happen if the database is down after an upgrade.\",\n\t\t      g_tres_count, TRES_ARRAY_TOTAL_CNT);\n\n\twhile ((temp_char = list_pop(char_list))) {\n\t\ttres_rec = xmalloc(sizeof(slurmdb_tres_rec_t));\n\n\t\ttres_rec->type = temp_char;\n\n\t\tif (!xstrcasecmp(temp_char, \"cpu\"))\n\t\t\ttres_rec->id = TRES_CPU;\n\t\telse if (!xstrcasecmp(temp_char, \"mem\"))\n\t\t\ttres_rec->id = TRES_MEM;\n\t\telse if (!xstrcasecmp(temp_char, \"energy\"))\n\t\t\ttres_rec->id = TRES_ENERGY;\n\t\telse if (!xstrcasecmp(temp_char, \"node\"))\n\t\t\ttres_rec->id = TRES_NODE;\n\t\telse if (!xstrcasecmp(temp_char, \"billing\"))\n\t\t\ttres_rec->id = TRES_BILLING;\n\t\telse if (!xstrcasecmp(temp_char, \"vmem\"))\n\t\t\ttres_rec->id = TRES_VMEM;\n\t\telse if (!xstrcasecmp(temp_char, \"pages\"))\n\t\t\ttres_rec->id = TRES_PAGES;\n\t\telse if (!xstrncasecmp(temp_char, \"bb/\", 3)) {\n\t\t\ttres_rec->type[2] = '\\0';\n\t\t\ttres_rec->name = xstrdup(temp_char+3);\n\t\t\tif (!tres_rec->name)\n\t\t\t\tfatal(\"Burst Buffer type tres need to have a \"\n\t\t\t\t      \"name, (i.e. bb/datawarp).  You gave %s\",\n\t\t\t\t      temp_char);\n\t\t\telse if (!xstrcmp(tres_rec->name, \"cray\"))\n\t\t\t\tfatal(\"The Burst Buffer tres 'bb/cray' changed to 'bb/datawarp'.  Please alter AccountingStorageTRES in your slurm.conf and restart.\");\n\t\t} else if (!xstrncasecmp(temp_char, \"gres/\", 5)) {\n\t\t\ttres_rec->type[4] = '\\0';\n\t\t\ttres_rec->name = xstrdup(temp_char+5);\n\t\t\tif (!tres_rec->name)\n\t\t\t\tfatal(\"Gres type tres need to have a name, \"\n\t\t\t\t      \"(i.e. Gres/GPU).  You gave %s\",\n\t\t\t\t      temp_char);\n\t\t} else if (!xstrncasecmp(temp_char, \"license/\", 8)) {\n\t\t\ttres_rec->type[7] = '\\0';\n\t\t\ttres_rec->name = xstrdup(temp_char+8);\n\t\t\tif (!tres_rec->name)\n\t\t\t\tfatal(\"License type tres need to \"\n\t\t\t\t      \"have a name, (i.e. License/Foo).  \"\n\t\t\t\t      \"You gave %s\",\n\t\t\t\t      temp_char);\n\t\t} else if (!xstrncasecmp(temp_char, \"fs/\", 3)) {\n\t\t\ttres_rec->type[2] = '\\0';\n\t\t\ttres_rec->name = xstrdup(temp_char+3);\n\t\t\tif (!tres_rec->name)\n\t\t\t\tfatal(\"Filesystem type tres need to have a name, (i.e. fs/disk).  You gave %s\",\n\t\t\t\t      temp_char);\n\t\t\tif (!xstrncasecmp(tres_rec->name, \"disk\", 4))\n\t\t\t\ttres_rec->id = TRES_FS_DISK;\n\t\t} else if (!xstrncasecmp(temp_char, \"ic/\", 3)) {\n\t\t\ttres_rec->type[2] = '\\0';\n\t\t\ttres_rec->name = xstrdup(temp_char+3);\n\t\t\tif (!tres_rec->name)\n\t\t\t\tfatal(\"Interconnect type tres need to have a name, (i.e. ic/ofed).  You gave %s\",\n\t\t\t\t      temp_char);\n\t\t} else {\n\t\t\tfatal(\"%s: Unknown tres type '%s', acceptable types are Billing,CPU,Energy,FS/,Gres/,IC/,License/,Mem,Node,Pages,VMem\",\n\t\t\t      __func__, temp_char);\n\t\t\txfree(tres_rec->type);\n\t\t\txfree(tres_rec);\n\t\t}\n\n\t\tif (!association_based_accounting) {\n\t\t\tif (!tres_rec->id)\n\t\t\t\tfatal(\"Unless running with a database you \"\n\t\t\t\t      \"can only run with certain TRES, \"\n\t\t\t\t      \"%s%s%s is not one of them.  \"\n\t\t\t\t      \"Either set up \"\n\t\t\t\t      \"a database preferably with a slurmdbd \"\n\t\t\t\t      \"or remove this TRES from your \"\n\t\t\t\t      \"configuration.\",\n\t\t\t\t      tres_rec->type, tres_rec->name ? \"/\" : \"\",\n\t\t\t\t      tres_rec->name ? tres_rec->name : \"\");\n\t\t\tlist_append(update_object.objects, tres_rec);\n\t\t} else if (!tres_rec->id &&\n\t\t\t   assoc_mgr_fill_in_tres(\n\t\t\t\t   acct_db_conn, tres_rec,\n\t\t\t\t   ACCOUNTING_ENFORCE_TRES, NULL, 0)\n\t\t\t   != SLURM_SUCCESS) {\n\t\t\tif (!add_list)\n\t\t\t\tadd_list = list_create(\n\t\t\t\t\tslurmdb_destroy_tres_rec);\n\t\t\tinfo(\"Couldn't find tres %s%s%s in the database, \"\n\t\t\t     \"creating.\",\n\t\t\t     tres_rec->type, tres_rec->name ? \"/\" : \"\",\n\t\t\t     tres_rec->name ? tres_rec->name : \"\");\n\t\t\tlist_append(add_list, tres_rec);\n\t\t} else\n\t\t\tslurmdb_destroy_tres_rec(tres_rec);\n\t}\n\tFREE_NULL_LIST(char_list);\n\n\tif (add_list) {\n\t\tif (acct_storage_g_add_tres(acct_db_conn,\n\t\t\t\t\t    slurmctld_conf.slurm_user_id,\n\t\t\t\t\t    add_list) != SLURM_SUCCESS)\n\t\t\tfatal(\"Problem adding tres to the database, \"\n\t\t\t      \"can't continue until database is able to \"\n\t\t\t      \"make new tres\");\n\t\t/* refresh list here since the updates are not\n\t\t   sent dynamically */\n\t\tassoc_mgr_refresh_lists(acct_db_conn, ASSOC_MGR_CACHE_TRES);\n\t\tFREE_NULL_LIST(add_list);\n\t}\n\n\tif (!association_based_accounting) {\n\t\tassoc_mgr_update_tres(&update_object, false);\n\t\tlist_destroy(update_object.objects);\n\t}\n\n\t/* Set up the slurmctld_tres_cnt here (Current code is set to\n\t * not have this ever change).\n\t*/\n\tassoc_mgr_lock(&locks);\n\tslurmctld_tres_cnt = g_tres_count;\n\tassoc_mgr_unlock(&locks);\n\n\treturn SLURM_SUCCESS;\n}\n\n/*\n * NOTE: the job_write_lock as well as the assoc_mgr TRES Read lock should be\n * locked before coming in here.\n */\nstatic void _update_job_tres(job_record_t *job_ptr)\n{\n\txassert(verify_lock(JOB_LOCK, WRITE_LOCK));\n\n\t/* If this returns 1 it means the positions were\n\t   altered so just rebuild it.\n\t*/\n\tif (assoc_mgr_set_tres_cnt_array(&job_ptr->tres_req_cnt,\n\t\t\t\t\t job_ptr->tres_req_str,\n\t\t\t\t\t 0, true))\n\t\tjob_set_req_tres(job_ptr, true);\n\tif (assoc_mgr_set_tres_cnt_array(&job_ptr->tres_alloc_cnt,\n\t\t\t\t\t job_ptr->tres_alloc_str,\n\t\t\t\t\t 0, true))\n\t\tjob_set_alloc_tres(job_ptr, true);\n\n\tupdate_job_limit_set_tres(&job_ptr->limit_set.tres);\n}\n\n/* any association manager locks should be unlocked before hand */\nstatic void _update_cluster_tres(void)\n{\n\tListIterator job_iterator;\n\tjob_record_t *job_ptr;\n\t/* Write lock on jobs */\n\tslurmctld_lock_t job_write_lock =\n\t\t{ NO_LOCK, WRITE_LOCK, NO_LOCK, NO_LOCK, NO_LOCK };\n\tassoc_mgr_lock_t locks = { .tres = READ_LOCK };\n\n\tif (!job_list)\n\t\treturn;\n\n\tlock_slurmctld(job_write_lock);\n\tassoc_mgr_lock(&locks);\n\tjob_iterator = list_iterator_create(job_list);\n\twhile ((job_ptr = list_next(job_iterator)))\n\t\t_update_job_tres(job_ptr);\n\tlist_iterator_destroy(job_iterator);\n\n\tassoc_mgr_unlock(&locks);\n\tunlock_slurmctld(job_write_lock);\n}\n\n\nstatic void _queue_reboot_msg(void)\n{\n\tagent_arg_t *reboot_agent_args = NULL;\n\tnode_record_t *node_ptr;\n\tchar *host_str;\n\ttime_t now = time(NULL);\n\tint i;\n\tbool want_reboot;\n\tuint16_t resume_timeout = slurm_get_resume_timeout();\n\n\twant_nodes_reboot = false;\n\tfor (i = 0, node_ptr = node_record_table_ptr;\n\t     i < node_record_count; i++, node_ptr++) {\n\t\t/* Allow nodes in maintenance reservations to reboot\n\t\t * (they previously could not).\n\t\t */\n\t\tif (!IS_NODE_REBOOT(node_ptr))\n\t\t\tcontinue;\t/* No reboot needed */\n\t\tif (IS_NODE_COMPLETING(node_ptr)) {\n\t\t\twant_nodes_reboot = true;\n\t\t\tcontinue;\n\t\t}\n\t\tif (node_ptr->boot_req_time + resume_timeout > now) {\n\t\t\tdebug2(\"%s: Still waiting for boot of node %s\",\n\t\t\t       __func__, node_ptr->name);\n\t\t\tcontinue;\n\t\t}\n                /* only active idle nodes, don't reboot\n                 * nodes that are idle but have suspended\n                 * jobs on them\n                 */\n\t\tif (IS_NODE_IDLE(node_ptr)\n                    && !IS_NODE_NO_RESPOND(node_ptr)\n                    && !IS_NODE_POWER_UP(node_ptr)\n                    && node_ptr->sus_job_cnt == 0)\n\t\t\twant_reboot = true;\n\t\telse if (IS_NODE_FUTURE(node_ptr) &&\n\t\t\t (node_ptr->last_response == (time_t) 0))\n\t\t\twant_reboot = true; /* system just restarted */\n\t\telse if (IS_NODE_DOWN(node_ptr))\n\t\t\twant_reboot = true;\n\t\telse\n\t\t\twant_reboot = false;\n\t\tif (!want_reboot) {\n\t\t\twant_nodes_reboot = true;\t/* defer reboot */\n\t\t\tcontinue;\n\t\t}\n\t\tif (reboot_agent_args == NULL) {\n\t\t\treboot_agent_args = xmalloc(sizeof(agent_arg_t));\n\t\t\treboot_agent_args->msg_type = REQUEST_REBOOT_NODES;\n\t\t\treboot_agent_args->retry = 0;\n\t\t\treboot_agent_args->hostlist = hostlist_create(NULL);\n\t\t\treboot_agent_args->protocol_version =\n\t\t\t\tSLURM_PROTOCOL_VERSION;\n\t\t}\n\t\tif (reboot_agent_args->protocol_version\n\t\t    > node_ptr->protocol_version)\n\t\t\treboot_agent_args->protocol_version =\n\t\t\t\tnode_ptr->protocol_version;\n\t\thostlist_push_host(reboot_agent_args->hostlist, node_ptr->name);\n\t\treboot_agent_args->node_count++;\n\t\t/*\n\t\t * node_ptr->node_state &= ~NODE_STATE_MAINT;\n\t\t * The NODE_STATE_MAINT bit will just get set again as long\n\t\t * as the node remains in the maintenance reservation, so\n\t\t * don't clear it here because it won't do anything.\n\t\t */\n\t\tnode_ptr->node_state &=  NODE_STATE_FLAGS;\n\t\tnode_ptr->node_state |=  NODE_STATE_DOWN;\n\n\t\tbit_clear(avail_node_bitmap, i);\n\t\tbit_clear(idle_node_bitmap, i);\n\n\t\tnode_ptr->boot_req_time = now;\n\t\tnode_ptr->last_response = now + slurm_get_resume_timeout();\n\n\t\tif (node_ptr->reason &&\n\t\t    !xstrstr(node_ptr->reason, \"reboot issued\"))\n\t\t\txstrcat(node_ptr->reason, \" : reboot issued\");\n\n\t\tclusteracct_storage_g_node_down(acct_db_conn, node_ptr, now,\n\t\t\t\t\t\tNULL,\n\t\t\t\t\t\tslurmctld_conf.slurm_user_id);\n\t}\n\tif (reboot_agent_args != NULL) {\n\t\thostlist_uniq(reboot_agent_args->hostlist);\n\t\thost_str = hostlist_ranged_string_xmalloc(\n\t\t\t\treboot_agent_args->hostlist);\n\t\tdebug(\"Queuing reboot request for nodes %s\", host_str);\n\t\txfree(host_str);\n\t\tagent_queue_request(reboot_agent_args);\n\t\tlast_node_update = now;\n\t\tschedule_node_save();\n\t}\n}\n\n/*\n * _slurmctld_background - process slurmctld background activities\n *\tpurge defunct job records, save state, schedule jobs, and\n *\tping other nodes\n */\nstatic void *_slurmctld_background(void *no_data)\n{\n\tstatic time_t last_sched_time;\n\tstatic time_t last_full_sched_time;\n\tstatic time_t last_checkpoint_time;\n\tstatic time_t last_group_time;\n\tstatic time_t last_health_check_time;\n\tstatic time_t last_acct_gather_node_time;\n\tstatic time_t last_ext_sensors_time;\n\tstatic time_t last_no_resp_msg_time;\n\tstatic time_t last_ping_node_time = (time_t) 0;\n\tstatic time_t last_ping_srun_time;\n\tstatic time_t last_purge_job_time;\n\tstatic time_t last_resv_time;\n\tstatic time_t last_timelimit_time;\n\tstatic time_t last_assert_primary_time;\n\tstatic time_t last_trigger;\n\tstatic time_t last_node_acct;\n\tstatic time_t last_ctld_bu_ping;\n\tstatic time_t last_uid_update;\n\tstatic time_t last_reboot_msg_time;\n\ttime_t now;\n\tint no_resp_msg_interval, ping_interval, purge_job_interval;\n\tint i;\n\tuint32_t job_limit;\n\tDEF_TIMERS;\n\n\t/* Locks: Read config */\n\tslurmctld_lock_t config_read_lock = {\n\t\tREAD_LOCK, NO_LOCK, NO_LOCK, NO_LOCK, NO_LOCK };\n\t/* Locks: Read config, read job */\n\tslurmctld_lock_t job_read_lock = {\n\t\tREAD_LOCK, READ_LOCK, NO_LOCK, NO_LOCK, NO_LOCK };\n\t/* Locks: Read config, write job, write node, read partition */\n\tslurmctld_lock_t job_write_lock = {\n\t\tREAD_LOCK, WRITE_LOCK, WRITE_LOCK, READ_LOCK, READ_LOCK };\n\t/* Locks: Write job */\n\tslurmctld_lock_t job_write_lock2 = {\n\t\tNO_LOCK, WRITE_LOCK, NO_LOCK, NO_LOCK, NO_LOCK };\n\t/* Locks: Read config, write job, write node\n\t * (Might kill jobs on nodes set DOWN) */\n\tslurmctld_lock_t node_write_lock = {\n\t\tREAD_LOCK, WRITE_LOCK, WRITE_LOCK, NO_LOCK, NO_LOCK };\n\t/* Locks: Write node */\n\tslurmctld_lock_t node_write_lock2 = {\n\t\tNO_LOCK, NO_LOCK, WRITE_LOCK, NO_LOCK, NO_LOCK };\n\t/* Locks: Write partition */\n\tslurmctld_lock_t part_write_lock = {\n\t\tNO_LOCK, NO_LOCK, NO_LOCK, WRITE_LOCK, NO_LOCK };\n\t/* Locks: Read job and node */\n\tslurmctld_lock_t job_node_read_lock = {\n\t\tNO_LOCK, READ_LOCK, READ_LOCK, NO_LOCK, NO_LOCK };\n\t/*\n\t * purge_old_job modifes jobs and reads conf info. It can also\n\t * call re_kill_job(), which can modify nodes and reads fed info.\n\t */\n\tslurmctld_lock_t purge_job_locks = {\n\t\t.conf = READ_LOCK, .job = WRITE_LOCK,\n\t\t.node = WRITE_LOCK, .fed = READ_LOCK\n\t};\n\n\t/* Let the dust settle before doing work */\n\tnow = time(NULL);\n\tlast_sched_time = last_full_sched_time = now;\n\tlast_checkpoint_time = last_group_time = now;\n\tlast_purge_job_time = last_trigger = last_health_check_time = now;\n\tlast_timelimit_time = last_assert_primary_time = now;\n\tlast_no_resp_msg_time = last_resv_time = last_ctld_bu_ping = now;\n\tlast_uid_update = last_reboot_msg_time = now;\n\tlast_acct_gather_node_time = last_ext_sensors_time = now;\n\n\n\tlast_ping_srun_time = now;\n\tlast_node_acct = now;\n\t(void) pthread_setcancelstate(PTHREAD_CANCEL_ENABLE, NULL);\n\t(void) pthread_setcanceltype(PTHREAD_CANCEL_ASYNCHRONOUS, NULL);\n\tdebug3(\"_slurmctld_background pid = %u\", getpid());\n\n\twhile (1) {\n\t\tfor (i = 0; ((i < 10) && (slurmctld_config.shutdown_time == 0));\n\t\t     i++) {\n\t\t\tusleep(100000);\n\t\t}\n\n\t\tnow = time(NULL);\n\t\tSTART_TIMER;\n\n\t\tif (slurmctld_conf.slurmctld_debug <= 3)\n\t\t\tno_resp_msg_interval = 300;\n\t\telse if (slurmctld_conf.slurmctld_debug == 4)\n\t\t\tno_resp_msg_interval = 60;\n\t\telse\n\t\t\tno_resp_msg_interval = 1;\n\n\t\tif ((slurmctld_conf.min_job_age > 0) &&\n\t\t    (slurmctld_conf.min_job_age < PURGE_JOB_INTERVAL)) {\n\t\t\t/* Purge jobs more quickly, especially for high job flow */\n\t\t\tpurge_job_interval = MAX(10, slurmctld_conf.min_job_age);\n\t\t} else\n\t\t\tpurge_job_interval = PURGE_JOB_INTERVAL;\n\n\t\tif (slurmctld_conf.slurmd_timeout) {\n\t\t\t/* We ping nodes that haven't responded in SlurmdTimeout/3,\n\t\t\t * but need to do the test at a higher frequency or we might\n\t\t\t * DOWN nodes with times that fall in the gap. */\n\t\t\tping_interval = slurmctld_conf.slurmd_timeout / 3;\n\t\t} else {\n\t\t\t/* This will just ping non-responding nodes\n\t\t\t * and restore them to service */\n\t\t\tping_interval = 100;\t/* 100 seconds */\n\t\t}\n\n\t\tif (!last_ping_node_time) {\n\t\t\tlast_ping_node_time = now + (time_t)MIN_CHECKIN_TIME -\n\t\t\t\t\t      ping_interval;\n\t\t}\n\n\t\tif (slurmctld_config.shutdown_time) {\n\t\t\tstruct timespec ts = {0, 0};\n\t\t\tstruct timeval now;\n\t\t\tint exp_thread_cnt =\n\t\t\t\tslurmctld_config.resume_backup ? 1 : 0;\n\t\t\t/* wait for RPC's to complete */\n\t\t\tgettimeofday(&now, NULL);\n\t\t\tts.tv_sec = now.tv_sec + CONTROL_TIMEOUT;\n\t\t\tts.tv_nsec = now.tv_usec * 1000;\n\n\t\t\tslurm_mutex_lock(&slurmctld_config.thread_count_lock);\n\t\t\twhile (slurmctld_config.server_thread_count >\n\t\t\t       exp_thread_cnt) {\n\t\t\t\tslurm_cond_timedwait(\n\t\t\t\t\t&slurmctld_config.thread_count_cond,\n\t\t\t\t\t&slurmctld_config.thread_count_lock,\n\t\t\t\t\t&ts);\n\t\t\t}\n\t\t\tif (slurmctld_config.server_thread_count >\n\t\t\t    exp_thread_cnt) {\n\t\t\t\tinfo(\"shutdown server_thread_count=%d\",\n\t\t\t\t     slurmctld_config.server_thread_count);\n\t\t\t}\n\t\t\tslurm_mutex_unlock(&slurmctld_config.thread_count_lock);\n\n\t\t\tif (!report_locks_set()) {\n\t\t\t\tinfo(\"Saving all slurm state\");\n\t\t\t\tsave_all_state();\n\t\t\t} else {\n\t\t\t\terror(\"Semaphores still set after %d seconds, \"\n\t\t\t\t      \"can not save state\", CONTROL_TIMEOUT);\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\n\t\tif (difftime(now, last_resv_time) >= 5) {\n\t\t\tlock_slurmctld(node_write_lock);\n\t\t\tnow = time(NULL);\n\t\t\tlast_resv_time = now;\n\t\t\tif (set_node_maint_mode(false) > 0)\n\t\t\t\tqueue_job_scheduler();\n\t\t\tunlock_slurmctld(node_write_lock);\n\t\t}\n\n\t\tif (difftime(now, last_no_resp_msg_time) >=\n\t\t    no_resp_msg_interval) {\n\t\t\tlock_slurmctld(node_write_lock2);\n\t\t\tnow = time(NULL);\n\t\t\tlast_no_resp_msg_time = now;\n\t\t\tnode_no_resp_msg();\n\t\t\tunlock_slurmctld(node_write_lock2);\n\t\t}\n\n\t\tif (difftime(now, last_timelimit_time) >= PERIODIC_TIMEOUT) {\n\t\t\tlock_slurmctld(job_write_lock);\n\t\t\tnow = time(NULL);\n\t\t\tlast_timelimit_time = now;\n\t\t\tdebug2(\"Testing job time limits and checkpoints\");\n\t\t\tjob_time_limit();\n\t\t\tjob_resv_check();\n\t\t\tunlock_slurmctld(job_write_lock);\n\n\t\t\tlock_slurmctld(node_write_lock);\n\t\t\tcheck_reboot_nodes();\n\t\t\tunlock_slurmctld(node_write_lock);\n\t\t}\n\n\t\tif (slurmctld_conf.health_check_interval &&\n\t\t    (difftime(now, last_health_check_time) >=\n\t\t     slurmctld_conf.health_check_interval) &&\n\t\t    is_ping_done()) {\n\t\t\tlock_slurmctld(node_write_lock);\n\t\t\tif (slurmctld_conf.health_check_node_state &\n\t\t\t     HEALTH_CHECK_CYCLE) {\n\t\t\t\t/* Call run_health_check() on each cycle */\n\t\t\t} else {\n\t\t\t\tnow = time(NULL);\n\t\t\t\tlast_health_check_time = now;\n\t\t\t}\n\t\t\trun_health_check();\n\t\t\tunlock_slurmctld(node_write_lock);\n\t\t}\n\n\t\tif (slurmctld_conf.acct_gather_node_freq &&\n\t\t    (difftime(now, last_acct_gather_node_time) >=\n\t\t     slurmctld_conf.acct_gather_node_freq) &&\n\t\t    is_ping_done()) {\n\t\t\tlock_slurmctld(node_write_lock);\n\t\t\tnow = time(NULL);\n\t\t\tlast_acct_gather_node_time = now;\n\t\t\tupdate_nodes_acct_gather_data();\n\t\t\tunlock_slurmctld(node_write_lock);\n\t\t}\n\n\t\tif (slurmctld_conf.ext_sensors_freq &&\n\t\t    (difftime(now, last_ext_sensors_time) >=\n\t\t     slurmctld_conf.ext_sensors_freq) &&\n\t\t    is_ping_done()) {\n\t\t\tlock_slurmctld(node_write_lock);\n\t\t\tnow = time(NULL);\n\t\t\tlast_ext_sensors_time = now;\n\t\t\text_sensors_g_update_component_data();\n\t\t\tunlock_slurmctld(node_write_lock);\n\t\t}\n\n\t\tif (((difftime(now, last_ping_node_time) >= ping_interval) ||\n\t\t     ping_nodes_now) && is_ping_done()) {\n\t\t\tlock_slurmctld(node_write_lock);\n\t\t\tnow = time(NULL);\n\t\t\tlast_ping_node_time = now;\n\t\t\tping_nodes_now = false;\n\t\t\tping_nodes();\n\t\t\tunlock_slurmctld(node_write_lock);\n\t\t}\n\n\t\tif (slurmctld_conf.inactive_limit &&\n\t\t    ((now - last_ping_srun_time) >=\n\t\t     (slurmctld_conf.inactive_limit / 3))) {\n\t\t\tlock_slurmctld(job_read_lock);\n\t\t\tnow = time(NULL);\n\t\t\tlast_ping_srun_time = now;\n\t\t\tdebug2(\"Performing srun ping\");\n\t\t\tsrun_ping();\n\t\t\tunlock_slurmctld(job_read_lock);\n\t\t}\n\n\t\tif (want_nodes_reboot && (now > last_reboot_msg_time)) {\n\t\t\tlock_slurmctld(node_write_lock);\n\t\t\tnow = time(NULL);\n\t\t\tlast_reboot_msg_time = now;\n\t\t\t_queue_reboot_msg();\n\t\t\tunlock_slurmctld(node_write_lock);\n\t\t}\n\n\t\t/* Process any pending agent work */\n\t\tagent_trigger(RPC_RETRY_INTERVAL, true);\n\n\t\tif (slurmctld_conf.group_time &&\n\t\t    (difftime(now, last_group_time)\n\t\t     >= slurmctld_conf.group_time)) {\n\t\t\tlock_slurmctld(part_write_lock);\n\t\t\tnow = time(NULL);\n\t\t\tlast_group_time = now;\n\t\t\tload_part_uid_allow_list(slurmctld_conf.group_force);\n\t\t\tunlock_slurmctld(part_write_lock);\n\t\t\tgroup_cache_cleanup();\n\t\t}\n\n\t\tif (difftime(now, last_purge_job_time) >= purge_job_interval) {\n\t\t\t/*\n\t\t\t * If backfill is running, it will have a List of\n\t\t\t * job_record pointers which could include this\n\t\t\t * job. Skip over in that case to prevent\n\t\t\t * _attempt_backfill() from potentially dereferencing an\n\t\t\t * invalid pointer.\n\t\t\t */\n\t\t\tslurm_mutex_lock(&check_bf_running_lock);\n\t\t\tif (!slurmctld_diag_stats.bf_active) {\n\t\t\t\tlock_slurmctld(purge_job_locks);\n\t\t\t\tnow = time(NULL);\n\t\t\t\tlast_purge_job_time = now;\n\t\t\t\tdebug2(\"Performing purge of old job records\");\n\t\t\t\tpurge_old_job();\n\t\t\t\tunlock_slurmctld(purge_job_locks);\n\t\t\t}\n\t\t\tslurm_mutex_unlock(&check_bf_running_lock);\n\t\t}\n\n\t\tjob_limit = NO_VAL;\n\t\tif (difftime(now, last_full_sched_time) >= sched_interval) {\n\t\t\tslurm_mutex_lock(&sched_cnt_mutex);\n\t\t\t/* job_limit = job_sched_cnt;\tIgnored */\n\t\t\tjob_limit = INFINITE;\n\t\t\tjob_sched_cnt = 0;\n\t\t\tslurm_mutex_unlock(&sched_cnt_mutex);\n\t\t\tlast_full_sched_time = now;\n\t\t} else {\n\t\t\tslurm_mutex_lock(&sched_cnt_mutex);\n\t\t\tif (job_sched_cnt &&\n\t\t\t    (difftime(now, last_sched_time) >=\n\t\t\t     batch_sched_delay)) {\n\t\t\t\tjob_limit = 0;\t/* Default depth */\n\t\t\t\tjob_sched_cnt = 0;\n\t\t\t}\n\t\t\tslurm_mutex_unlock(&sched_cnt_mutex);\n\t\t}\n\t\tif (job_limit != NO_VAL) {\n\t\t\tlock_slurmctld(job_write_lock2);\n\t\t\tnow = time(NULL);\n\t\t\tlast_sched_time = now;\n\t\t\tbb_g_load_state(false);\t/* May alter job nice/prio */\n\t\t\tunlock_slurmctld(job_write_lock2);\n\t\t\tif (schedule(job_limit))\n\t\t\t\tlast_checkpoint_time = 0; /* force state save */\n\t\t\tset_job_elig_time();\n\t\t}\n\n\t\tif (slurmctld_conf.slurmctld_timeout &&\n\t\t    (difftime(now, last_ctld_bu_ping) >\n\t\t     slurmctld_conf.slurmctld_timeout)) {\n\t\t\tping_controllers(true);\n\t\t\tlast_ctld_bu_ping = now;\n\t\t}\n\n\t\tif (difftime(now, last_trigger) > TRIGGER_INTERVAL) {\n\t\t\tlock_slurmctld(job_node_read_lock);\n\t\t\tnow = time(NULL);\n\t\t\tlast_trigger = now;\n\t\t\ttrigger_process();\n\t\t\tunlock_slurmctld(job_node_read_lock);\n\t\t}\n\n\t\tif (difftime(now, last_checkpoint_time) >=\n\t\t    PERIODIC_CHECKPOINT) {\n\t\t\tnow = time(NULL);\n\t\t\tlast_checkpoint_time = now;\n\t\t\tdebug2(\"Performing full system state save\");\n\t\t\tsave_all_state();\n\t\t}\n\n\t\tif (difftime(now, last_node_acct) >= PERIODIC_NODE_ACCT) {\n\t\t\t/* Report current node state to account for added\n\t\t\t * or reconfigured nodes.  Locks are done\n\t\t\t * inside _accounting_cluster_ready, don't\n\t\t\t * lock here. */\n\t\t\tnow = time(NULL);\n\t\t\tlast_node_acct = now;\n\t\t\t_accounting_cluster_ready();\n\t\t}\n\n\t\tif (difftime(now, slurmctld_diag_stats.job_states_ts) >=\n\t\t    JOB_COUNT_INTERVAL) {\n\t\t\tlock_slurmctld(job_read_lock);\n\t\t\t_update_diag_job_state_counts();\n\t\t\tunlock_slurmctld(job_read_lock);\n\t\t}\n\n\t\t/* Stats will reset at midnight (approx) local time. */\n\t\tif (last_proc_req_start == 0) {\n\t\t\tlast_proc_req_start = now;\n\t\t\tnext_stats_reset = now - (now % 86400) + 86400;\n\t\t} else if (now >= next_stats_reset) {\n\t\t\tnext_stats_reset = now - (now % 86400) + 86400;\n\t\t\treset_stats(0);\n\t\t}\n\n\t\t/*\n\t\t * Reassert this machine as the primary controller.\n\t\t * A network or security problem could result in\n\t\t * the backup controller assuming control even\n\t\t * while the real primary controller is running.\n\t\t */\n\t\tlock_slurmctld(config_read_lock);\n\t\tif (slurmctld_primary && slurmctld_conf.slurmctld_timeout &&\n\t\t    (difftime(now, last_assert_primary_time) >=\n\t\t     slurmctld_conf.slurmctld_timeout)) {\n\t\t\tnow = time(NULL);\n\t\t\tlast_assert_primary_time = now;\n\t\t\t(void) _shutdown_backup_controller();\n\t\t}\n\t\tunlock_slurmctld(config_read_lock);\n\n\t\tif (difftime(now, last_uid_update) >= 3600) {\n\t\t\t/*\n\t\t\t * Make sure we update the uids in the\n\t\t\t * assoc_mgr if there were any users\n\t\t\t * with unknown uids at the time of startup.\n\t\t\t */\n\t\t\tnow = time(NULL);\n\t\t\tlast_uid_update = now;\n\t\t\tassoc_mgr_set_missing_uids();\n\t\t}\n\n\t\tEND_TIMER2(\"_slurmctld_background\");\n\t}\n\n\tdebug3(\"_slurmctld_background shutting down\");\n\n\treturn NULL;\n}\n\n/* save_all_state - save entire slurmctld state for later recovery */\nextern void save_all_state(void)\n{\n\t/* Each of these functions lock their own databases */\n\tschedule_front_end_save();\n\tschedule_job_save();\n\tschedule_node_save();\n\tschedule_part_save();\n\tschedule_resv_save();\n\tschedule_trigger_save();\n\n\tselect_g_state_save(slurmctld_conf.state_save_location);\n\tdump_assoc_mgr_state();\n\tfed_mgr_state_save(slurmctld_conf.state_save_location);\n}\n\n/* make sure the assoc_mgr is up and running with the most current state */\nextern void ctld_assoc_mgr_init(slurm_trigger_callbacks_t *callbacks)\n{\n\tassoc_init_args_t assoc_init_arg;\n\tint num_jobs = 0;\n\tslurmctld_lock_t job_read_lock =\n\t\t{ NO_LOCK, READ_LOCK, NO_LOCK, NO_LOCK, NO_LOCK };\n\n\tmemset(&assoc_init_arg, 0, sizeof(assoc_init_args_t));\n\tassoc_init_arg.enforce = accounting_enforce;\n\tassoc_init_arg.running_cache = &running_cache;\n\tassoc_init_arg.add_license_notify = license_add_remote;\n\tassoc_init_arg.resize_qos_notify = _resize_qos;\n\tassoc_init_arg.remove_assoc_notify = _remove_assoc;\n\tassoc_init_arg.remove_license_notify = license_remove_remote;\n\tassoc_init_arg.remove_qos_notify = _remove_qos;\n\tassoc_init_arg.sync_license_notify = license_sync_remote;\n\tassoc_init_arg.update_assoc_notify = _update_assoc;\n\tassoc_init_arg.update_license_notify = license_update_remote;\n\tassoc_init_arg.update_qos_notify = _update_qos;\n\tassoc_init_arg.update_cluster_tres = _update_cluster_tres;\n\tassoc_init_arg.update_resvs = update_assocs_in_resvs;\n\tassoc_init_arg.cache_level = ASSOC_MGR_CACHE_ASSOC |\n\t\t\t\t     ASSOC_MGR_CACHE_USER  |\n\t\t\t\t     ASSOC_MGR_CACHE_QOS   |\n\t\t\t\t     ASSOC_MGR_CACHE_RES   |\n                         \t     ASSOC_MGR_CACHE_TRES;\n\tif (slurmctld_conf.conf_flags & CTL_CONF_WCKEY)\n\t\tassoc_init_arg.cache_level |= ASSOC_MGR_CACHE_WCKEY;\n\tassoc_init_arg.state_save_location =\n\t\t&slurmctld_conf.state_save_location;\n\t/* Don't save state but blow away old lists if they exist. */\n\tassoc_mgr_fini(0);\n\n\tif (acct_db_conn)\n\t\tacct_storage_g_close_connection(&acct_db_conn);\n\n\tacct_db_conn = acct_storage_g_get_connection(\n\t\tcallbacks, 0, NULL, false,\n\t\tslurmctld_conf.cluster_name);\n\tclusteracct_storage_g_register_ctld(\n\t\tacct_db_conn, slurmctld_conf.slurmctld_port);\n\n\tif (assoc_mgr_init(acct_db_conn, &assoc_init_arg, errno)) {\n\t\tif (accounting_enforce & ACCOUNTING_ENFORCE_ASSOCS)\n\t\t\terror(\"Association database appears down, \"\n\t\t\t      \"reading from state file.\");\n\t\telse\n\t\t\tdebug(\"Association database appears down, \"\n\t\t\t      \"reading from state file.\");\n\t\t/*\n\t\t * We ignore the error here since this might not exist.  If\n\t\t * there is a real error we will get it from\n\t\t * load_assoc_mgr_state.\n\t\t */\n\t\t(void)load_assoc_mgr_last_tres();\n\n\t\tif ((load_assoc_mgr_state(0) != SLURM_SUCCESS)\n\t\t    && (accounting_enforce & ACCOUNTING_ENFORCE_ASSOCS)) {\n\t\t\terror(\"Unable to get any information from \"\n\t\t\t      \"the state file\");\n\t\t\tfatal(\"slurmdbd and/or database must be up at \"\n\t\t\t      \"slurmctld start time\");\n\t\t}\n\t}\n\n\t/* Now load the usage from a flat file since it isn't kept in\n\t   the database\n\t*/\n\tload_assoc_usage();\n\tload_qos_usage();\n\n\tlock_slurmctld(job_read_lock);\n\tif (job_list)\n\t\tnum_jobs = list_count(job_list);\n\tunlock_slurmctld(job_read_lock);\n\n\t_init_tres();\n\n\t/* This thread is looking for when we get correct data from\n\t   the database so we can update the assoc_ptr's in the jobs\n\t*/\n\tif (running_cache || num_jobs) {\n\t\tslurm_thread_create(&assoc_cache_thread,\n\t\t\t\t    _assoc_cache_mgr, NULL);\n\t}\n\n}\n\n/* send all info for the controller to accounting */\nextern void send_all_to_accounting(time_t event_time, int db_rc)\n{\n\t/* ignore the rcs here because if there was an error we will\n\t   push the requests on the queue and process them when the\n\t   database server comes back up.\n\t*/\n\tdebug2(\"send_all_to_accounting: called %s\", rpc_num2string(db_rc));\n\tswitch (db_rc) {\n\tcase ACCOUNTING_FIRST_REG:\n\tcase ACCOUNTING_NODES_CHANGE_DB:\n\t\tsend_jobs_to_accounting();\n\t\tsend_resvs_to_accounting(db_rc);\n\t\t/* fall through */\n\tcase ACCOUNTING_TRES_CHANGE_DB:\n\t\t/* No need to do jobs or resvs when only the TRES change. */\n\t\tsend_nodes_to_accounting(event_time);\n\t\tbreak;\n\tdefault:\n\t\terror(\"unknown rc of %d given\", db_rc);\n\t}\n}\n\nstatic int _add_node_gres_tres(void *x, void *arg)\n{\n\tuint64_t gres_cnt;\n\tint tres_pos;\n\tslurmdb_tres_rec_t *tres_rec_in = (slurmdb_tres_rec_t *)x;\n\tnode_record_t *node_ptr = (node_record_t *) arg;\n\n\txassert(tres_rec_in);\n\n\tif (xstrcmp(tres_rec_in->type, \"gres\"))\n\t\treturn 0;\n\n\tgres_cnt = gres_plugin_node_config_cnt(node_ptr->gres_list,\n\t\t\t\t\t       tres_rec_in->name);\n\n\t/*\n\t * Set the count here for named GRES as we don't store the count the\n\t * same way we do for unnamed GRES.\n\t */\n\tif (strchr(tres_rec_in->name, ':'))\n\t\ttres_rec_in->count += gres_cnt;\n\n\tif ((tres_pos = assoc_mgr_find_tres_pos(tres_rec_in, true)) != -1)\n\t\tnode_ptr->tres_cnt[tres_pos] = gres_cnt;\n\n\treturn 0;\n}\n\n/*\n * Set the node's billing tres to the highest billing of all partitions that the\n * node is a part of.\n */\nstatic void _set_node_billing_tres(node_record_t *node_ptr, uint64_t cpu_count,\n\t\t\t\t   bool assoc_mgr_locked)\n{\n\tint i;\n\tpart_record_t *part_ptr = NULL;\n\tdouble max_billing = 0;\n\txassert(node_ptr);\n\n\tfor (i = 0; i < node_ptr->part_cnt; i++) {\n\t\tdouble tmp_billing;\n\t\tpart_ptr = node_ptr->part_pptr[i];\n\t\tif (!part_ptr->billing_weights)\n\t\t\tcontinue;\n\n\t\ttmp_billing = assoc_mgr_tres_weighted(node_ptr->tres_cnt,\n\t\t\t\t\t\tpart_ptr->billing_weights,\n\t\t\t\t\t\tslurmctld_conf.priority_flags,\n\t\t\t\t\t\tassoc_mgr_locked);\n\t\tmax_billing = MAX(max_billing, tmp_billing);\n\t}\n\n\t/* Set to the configured cpu_count if no partition has\n\t * tresbillingweights set because the job will be allocated the job's\n\t * cpu count if there are no tresbillingweights defined. */\n\tif (!max_billing)\n\t\tmax_billing = cpu_count;\n\tnode_ptr->tres_cnt[TRES_ARRAY_BILLING] = max_billing;\n}\n\nextern void set_cluster_tres(bool assoc_mgr_locked)\n{\n\tnode_record_t *node_ptr;\n\tslurmdb_tres_rec_t *tres_rec, *cpu_tres = NULL, *mem_tres = NULL;\n\tint i;\n\tuint64_t cluster_billing = 0;\n\tchar *unique_tres = NULL;\n\tassoc_mgr_lock_t locks = { .tres = WRITE_LOCK };\n\n\txassert(verify_lock(NODE_LOCK, WRITE_LOCK));\n\txassert(verify_lock(PART_LOCK, WRITE_LOCK));\n\n\tif (!assoc_mgr_locked)\n\t\tassoc_mgr_lock(&locks);\n\n\txassert(assoc_mgr_tres_array);\n\n\tfor (i = 0; i < g_tres_count; i++) {\n\t\ttres_rec = assoc_mgr_tres_array[i];\n\n\t\tif (!tres_rec->type) {\n\t\t\terror(\"TRES %d doesn't have a type given, this should never happen\",\n\t\t\t      tres_rec->id);\n\t\t\tcontinue; /* this should never happen */\n\t\t}\n\n\t\tif (unique_tres)\n\t\t\txstrfmtcat(unique_tres, \",%s\",\n\t\t\t\t   assoc_mgr_tres_name_array[i]);\n\t\telse\n\t\t\tunique_tres = xstrdup(assoc_mgr_tres_name_array[i]);\n\n\n\t\t/* reset them now since we are about to add to them */\n\t\ttres_rec->count = 0;\n\t\tif (tres_rec->id == TRES_CPU) {\n\t\t\tcpu_tres = tres_rec;\n\t\t\tcontinue;\n\t\t} else if (tres_rec->id == TRES_MEM) {\n\t\t\tmem_tres = tres_rec;\n\t\t\tcontinue;\n\t\t} else if (!xstrcmp(tres_rec->type, \"bb\")) {\n\t\t\ttres_rec->count = bb_g_get_system_size(tres_rec->name);\n\t\t\tcontinue;\n\t\t} else if (!xstrcmp(tres_rec->type, \"gres\")) {\n\t\t\t/*\n\t\t\t * Skip named GRES as we don't store\n\t\t\t * the count the same way we do for unnamed GRES.\n\t\t\t */\n\t\t\tif (strchr(tres_rec->name, ':'))\n\t\t\t\tcontinue;\n\n\t\t\ttres_rec->count = gres_get_system_cnt(tres_rec->name);\n\t\t\tif (tres_rec->count == NO_VAL64)\n\t\t\t\ttres_rec->count = 0;   /* GRES name not found */\n\t\t\tcontinue;\n\t\t} else if (!xstrcmp(tres_rec->type, \"license\")) {\n\t\t\ttres_rec->count = get_total_license_cnt(\n\t\t\t\ttres_rec->name);\n\t\t\tcontinue;\n\t\t}\n\t\t/* FIXME: set up the other tres here that aren't specific */\n\t}\n\n\tslurm_set_accounting_storage_tres(unique_tres);\n\txfree(unique_tres);\n\n\tcluster_cpus = 0;\n\n\tnode_ptr = node_record_table_ptr;\n\tfor (i = 0; i < node_record_count; i++, node_ptr++) {\n\t\tuint64_t cpu_count = 0, mem_count = 0;\n\t\tif (!node_ptr->name)\n\t\t\tcontinue;\n\n\t\tcpu_count += node_ptr->config_ptr->cpus;\n\t\tmem_count += node_ptr->config_ptr->real_memory;\n\n\t\tcluster_cpus += cpu_count;\n\t\tif (mem_tres)\n\t\t\tmem_tres->count += mem_count;\n\n\t\tif (!node_ptr->tres_cnt)\n\t\t\tnode_ptr->tres_cnt = xcalloc(slurmctld_tres_cnt,\n\t\t\t\t\t\t     sizeof(uint64_t));\n\t\tnode_ptr->tres_cnt[TRES_ARRAY_CPU] = cpu_count;\n\t\tnode_ptr->tres_cnt[TRES_ARRAY_MEM] = mem_count;\n\n\t\tlist_for_each(assoc_mgr_tres_list,\n\t\t\t      _add_node_gres_tres, node_ptr);\n\n\t\t_set_node_billing_tres(node_ptr, cpu_count, true);\n\t\tcluster_billing += node_ptr->tres_cnt[TRES_ARRAY_BILLING];\n\n\t\txfree(node_ptr->tres_str);\n\t\tnode_ptr->tres_str =\n\t\t\tassoc_mgr_make_tres_str_from_array(node_ptr->tres_cnt,\n\t\t\t\t\t\t\t   TRES_STR_FLAG_SIMPLE,\n\t\t\t\t\t\t\t   true);\n\t\txfree(node_ptr->tres_fmt_str);\n\t\tnode_ptr->tres_fmt_str =\n\t\t\tassoc_mgr_make_tres_str_from_array(\n\t\t\t\tnode_ptr->tres_cnt,\n\t\t\t\tTRES_STR_CONVERT_UNITS,\n\t\t\t\ttrue);\n\t}\n\n\t/* FIXME: cluster_cpus probably needs to be removed and handled\n\t * differently in the spots this is used.\n\t */\n\tif (cpu_tres)\n\t\tcpu_tres->count = cluster_cpus;\n\n\tassoc_mgr_tres_array[TRES_ARRAY_NODE]->count = node_record_count;\n\tassoc_mgr_tres_array[TRES_ARRAY_BILLING]->count = cluster_billing;\n\n\tset_partition_tres();\n\n\tif (!assoc_mgr_locked)\n\t\tassoc_mgr_unlock(&locks);\n}\n\n/*\n * slurmctld_shutdown - wake up _slurm_rpc_mgr thread via signal\n * RET 0 or error code\n */\nint slurmctld_shutdown(void)\n{\n\tsched_debug(\"slurmctld terminating\");\n\tif (slurmctld_config.thread_id_rpc) {\n\t\tpthread_kill(slurmctld_config.thread_id_rpc, SIGUSR1);\n\t\treturn SLURM_SUCCESS;\n\t} else {\n\t\terror(\"thread_id_rpc not set\");\n\t\treturn SLURM_ERROR;\n\t}\n}\n\n/* Variables for commandline passing using getopt */\nextern char *optarg;\nextern int optind, opterr, optopt;\n\n/*\n * _parse_commandline - parse and process any command line arguments\n * IN argc - number of command line arguments\n * IN argv - the command line arguments\n * IN/OUT conf_ptr - pointer to current configuration, update as needed\n */\nstatic void _parse_commandline(int argc, char **argv)\n{\n\tint c = 0;\n\tchar *tmp_char;\n\n\topterr = 0;\n\twhile ((c = getopt(argc, argv, \"cdDf:hiL:n:rRvV\")) != -1) {\n\t\tswitch (c) {\n\t\tcase 'c':\n\t\t\trecover = 0;\n\t\t\tbreak;\n\t\tcase 'd':\n\t\t\tdaemonize = 1;\n\t\t\tbreak;\n\t\tcase 'D':\n\t\t\tdaemonize = 0;\n\t\t\tbreak;\n\t\tcase 'f':\n\t\t\txfree(slurm_conf_filename);\n\t\t\tslurm_conf_filename = xstrdup(optarg);\n\t\t\tbreak;\n\t\tcase 'h':\n\t\t\t_usage(argv[0]);\n\t\t\texit(0);\n\t\t\tbreak;\n\t\tcase 'i':\n\t\t\tignore_state_errors = true;\n\t\t\tbreak;\n\t\tcase 'L':\n\t\t\txfree(debug_logfile);\n\t\t\tdebug_logfile = xstrdup(optarg);\n\t\t\tbreak;\n\t\tcase 'n':\n\t\t\tnew_nice = strtol(optarg, &tmp_char, 10);\n\t\t\tif (tmp_char[0] != '\\0') {\n\t\t\t\terror(\"Invalid option for -n option (nice \"\n\t\t\t\t      \"value), ignored\");\n\t\t\t\tnew_nice = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 'r':\n\t\t\trecover = 1;\n\t\t\tbreak;\n\t\tcase 'R':\n\t\t\trecover = 2;\n\t\t\tbreak;\n\t\tcase 'v':\n\t\t\tdebug_level++;\n\t\t\tbreak;\n\t\tcase 'V':\n\t\t\tprint_slurm_version();\n\t\t\texit(0);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\t_usage(argv[0]);\n\t\t\texit(1);\n\t\t}\n\t}\n\tif (test_config) {\n\t\tdaemonize = 0;\n\t\trecover = 0;\n\t\tconfig_test_start();\n\t}\n}\n\n/* _usage - print a message describing the command line arguments of\n *\tslurmctld */\nstatic void _usage(char *prog_name)\n{\n\tfprintf(stderr, \"Usage: %s [OPTIONS]\\n\", prog_name);\n#if (DEFAULT_RECOVER != 0)\n\tfprintf(stderr, \"  -c      \"\n\t\t\t\"\\tDo not recover state from last checkpoint.\\n\");\n#endif\n#if (DEFAULT_DAEMONIZE == 0)\n\tfprintf(stderr, \"  -d      \"\n\t\t\t\"\\tRun daemon in background.\\n\");\n#endif\n#if (DEFAULT_DAEMONIZE != 0)\n\tfprintf(stderr, \"  -D      \"\n\t\t\t\"\\tRun daemon in foreground, with logging copied to stdout.\\n\");\n#endif\n\tfprintf(stderr, \"  -f file \"\n\t\t\t\"\\tUse specified file for slurmctld configuration.\\n\");\n\tfprintf(stderr, \"  -h      \"\n\t\t\t\"\\tPrint this help message.\\n\");\n\tfprintf(stderr, \"  -i      \"\n\t\t\t\"\\tIgnore errors found while reading in state files on startup.\\n\");\n\tfprintf(stderr, \"  -L logfile \"\n\t\t\t\"\\tLog messages to the specified file.\\n\");\n\tfprintf(stderr, \"  -n value \"\n\t\t\t\"\\tRun the daemon at the specified nice value.\\n\");\n#if (DEFAULT_RECOVER == 0)\n\tfprintf(stderr, \"  -r      \"\n\t\t\t\"\\tRecover state from last checkpoint.\\n\");\n#else\n\tfprintf(stderr, \"  -R      \"\n\t\t\t\"\\tRecover full state from last checkpoint.\\n\");\n#endif\n\tfprintf(stderr, \"  -v      \"\n\t\t\t\"\\tVerbose mode. Multiple -v's increase verbosity.\\n\");\n\tfprintf(stderr, \"  -V      \"\n\t\t\t\"\\tPrint version information and exit.\\n\");\n}\n\nstatic void *_shutdown_bu_thread(void *arg)\n{\n\tint bu_inx, rc = SLURM_SUCCESS, rc2 = SLURM_SUCCESS;\n\tslurm_msg_t req;\n\tbool acct_reg = false;\n\n\tbu_inx = *((int *) arg);\n\txfree(arg);\n\n\tslurm_msg_t_init(&req);\n\tslurm_set_addr(&req.address, slurmctld_conf.slurmctld_port,\n\t\t       slurmctld_conf.control_addr[bu_inx]);\n\treq.msg_type = REQUEST_CONTROL;\n\tdebug(\"Requesting control from backup controller %s\",\n\t      slurmctld_conf.control_machine[bu_inx]);\n\tif (slurm_send_recv_rc_msg_only_one(&req, &rc2,\n\t\t\t\t(CONTROL_TIMEOUT * 1000)) < 0) {\n\t\terror(\"%s:send/recv %s: %m\",\n\t\t      __func__, slurmctld_conf.control_machine[bu_inx]);\n\t\trc = SLURM_ERROR;\n\t} else if (rc2 == ESLURM_DISABLED) {\n\t\tdebug(\"backup controller %s responding\",\n\t\t      slurmctld_conf.control_machine[bu_inx]);\n\t} else if (rc2 == SLURM_SUCCESS) {\n\t\tdebug(\"backup controller %s has relinquished control\",\n\t\t      slurmctld_conf.control_machine[bu_inx]);\n\t\tacct_reg = true;\n\t} else {\n\t\terror(\"%s (%s): %s\", __func__,\n\t\t      slurmctld_conf.control_machine[bu_inx],\n\t\t      slurm_strerror(rc2));\n\t\trc = SLURM_ERROR;\n\t}\n\n\tslurm_mutex_lock(&bu_mutex);\n\tif (acct_reg)\n\t\tbu_acct_reg = true;\n\tif (rc != SLURM_SUCCESS)\n\t\tbu_rc = rc;\n\tbu_thread_cnt--;\n\tslurm_cond_signal(&bu_cond);\n\tslurm_mutex_unlock(&bu_mutex);\n\treturn NULL;\n}\n\n/*\n * Tell the backup_controllers to relinquish control, primary control_machine\n *\thas resumed operation. Messages sent to all controllers in parallel.\n * RET 0 or an error code\n * NOTE: READ lock_slurmctld config before entry (or be single-threaded)\n */\nstatic int _shutdown_backup_controller(void)\n{\n\tint i, *arg;\n\n\tbu_acct_reg = false;\n\tbu_rc = SLURM_SUCCESS;\n\tfor (i = 1; i < slurmctld_conf.control_cnt; i++) {\n\t\tif ((slurmctld_conf.control_addr[i] == NULL) ||\n\t\t    (slurmctld_conf.control_addr[i][0] == '\\0'))\n\t\t\tcontinue;\n\n\t\targ = xmalloc(sizeof(int));\n\t\t*arg = i;\n\t\tslurm_thread_create_detached(NULL, _shutdown_bu_thread, arg);\n\t\tslurm_mutex_lock(&bu_mutex);\n\t\tbu_thread_cnt++;\n\t\tslurm_mutex_unlock(&bu_mutex);\n\t}\n\n\tslurm_mutex_lock(&bu_mutex);\n\twhile (bu_thread_cnt != 0) {\n\t\tslurm_cond_wait(&bu_cond, &bu_mutex);\n\t}\n\tslurm_mutex_unlock(&bu_mutex);\n\n\tif (bu_acct_reg) {\n\t\t/*\n\t\t * In case primary controller really did not terminate,\n\t\t * but just temporarily became non-responsive\n\t\t */\n\t\tclusteracct_storage_g_register_ctld(acct_db_conn,\n\t\t\t\t\tslurmctld_conf.slurmctld_port);\n\t}\n\n\treturn bu_rc;\n}\n\n/* Reset the job credential key based upon configuration parameters */\nstatic void _update_cred_key(void)\n{\n\txassert(verify_lock(CONF_LOCK, READ_LOCK));\n\n\tslurm_cred_ctx_key_update(slurmctld_config.cred_ctx,\n\t\t\t\t  slurmctld_conf.job_credential_private_key);\n}\n\n/* Reset slurmctld logging based upon configuration parameters\n *   uses common slurmctld_conf data structure\n * NOTE: READ lock_slurmctld config before entry */\nvoid update_logging(void)\n{\n\tint rc;\n\tuid_t slurm_user_id  = slurmctld_conf.slurm_user_id;\n\tgid_t slurm_user_gid = gid_from_uid(slurm_user_id);\n\n\t/* Preserve execute line arguments (if any) */\n\tif (debug_level) {\n\t\tslurmctld_conf.slurmctld_debug = MIN(\n\t\t\t(LOG_LEVEL_INFO + debug_level),\n\t\t\t(LOG_LEVEL_END - 1));\n\t}\n\tif (test_config) {\n\t\tlog_opts.stderr_level  = LOG_LEVEL_ERROR;\n\t\tlog_opts.logfile_level = LOG_LEVEL_QUIET;\n\t\tlog_opts.syslog_level  = LOG_LEVEL_QUIET;\n\t} else if (slurmctld_conf.slurmctld_debug != NO_VAL16) {\n\t\tlog_opts.logfile_level = slurmctld_conf.slurmctld_debug;\n\t}\n\tif (debug_logfile) {\n\t\txfree(slurmctld_conf.slurmctld_logfile);\n\t\tslurmctld_conf.slurmctld_logfile = xstrdup(debug_logfile);\n\t}\n\n\tif (daemonize)\n\t\tlog_opts.stderr_level = LOG_LEVEL_QUIET;\n\telse\n\t\tlog_opts.stderr_level = slurmctld_conf.slurmctld_debug;\n\n\tif (slurmctld_conf.slurmctld_syslog_debug != LOG_LEVEL_END) {\n\t\tlog_opts.syslog_level = slurmctld_conf.slurmctld_syslog_debug;\n\t} else if (!daemonize) {\n\t\tlog_opts.syslog_level = LOG_LEVEL_QUIET;\n\t} else if ((slurmctld_conf.slurmctld_debug > LOG_LEVEL_QUIET)\n\t\t   && !slurmctld_conf.slurmctld_logfile) {\n\t\tlog_opts.syslog_level = slurmctld_conf.slurmctld_debug;\n\t} else\n\t\tlog_opts.syslog_level = LOG_LEVEL_FATAL;\n\n\tlog_alter(log_opts, SYSLOG_FACILITY_DAEMON,\n\t\t  slurmctld_conf.slurmctld_logfile);\n\n\tlog_set_timefmt(slurmctld_conf.log_fmt);\n\n\tdebug(\"Log file re-opened\");\n\n\t/*\n\t * SchedLogLevel restore\n\t */\n\tif (slurmctld_conf.sched_log_level != NO_VAL16)\n\t\tsched_log_opts.logfile_level = slurmctld_conf.sched_log_level;\n\n\tsched_log_alter(sched_log_opts, LOG_DAEMON,\n\t\t\tslurmctld_conf.sched_logfile);\n\n\tif (slurmctld_conf.slurmctld_logfile) {\n\t\trc = chown(slurmctld_conf.slurmctld_logfile,\n\t\t\t   slurm_user_id, slurm_user_gid);\n\t\tif (rc && daemonize) {\n\t\t\terror(\"chown(%s, %d, %d): %m\",\n\t\t\t      slurmctld_conf.slurmctld_logfile,\n\t\t\t      (int) slurm_user_id, (int) slurm_user_gid);\n\t\t}\n\t}\n\tif (slurmctld_conf.sched_logfile) {\n\t\trc = chown(slurmctld_conf.sched_logfile,\n\t\t\t   slurm_user_id, slurm_user_gid);\n\t\tif (rc && daemonize) {\n\t\t\terror(\"chown(%s, %d, %d): %m\",\n\t\t\t      slurmctld_conf.sched_logfile,\n\t\t\t      (int) slurm_user_id, (int) slurm_user_gid);\n\t\t}\n\t}\n}\n\n/* Reset slurmd nice value */\nstatic void _update_nice(void)\n{\n\tint cur_nice;\n\tid_t pid;\n\n\tif (new_nice == 0)\t/* No change */\n\t\treturn;\n\n\tpid = getpid();\n\tcur_nice = getpriority(PRIO_PROCESS, pid);\n\tif (cur_nice == new_nice)\n\t\treturn;\n\tif (setpriority(PRIO_PROCESS, pid, new_nice))\n\t\terror(\"Unable to reset nice value to %d: %m\", new_nice);\n}\n\n/* Verify that ClusterName from slurm.conf matches the state directory.\n * If mismatched exit to protect state files from corruption.\n * If the clustername file does not exist, return true so we can create it later\n * after dropping privileges. */\nstatic bool _verify_clustername(void)\n{\n\tFILE *fp;\n\tchar *filename = NULL;\n\tchar name[512] = {0};\n\tbool create_file = false;\n\n\txstrfmtcat(filename, \"%s/clustername\",\n\t\t   slurmctld_conf.state_save_location);\n\n\tif ((fp = fopen(filename, \"r\"))) {\n\t\t/* read value and compare */\n\t\tif (!fgets(name, sizeof(name), fp)) {\n\t\t\terror(\"%s: reading cluster name from clustername file\",\n\t\t\t      __func__);\n\t\t}\n\t\tfclose(fp);\n\t\tif (xstrcmp(name, slurmctld_conf.cluster_name)) {\n\t\t\tfatal(\"CLUSTER NAME MISMATCH.\\n\"\n\t\t\t      \"slurmctld has been started with \\\"\"\n\t\t\t      \"ClusterName=%s\\\", but read \\\"%s\\\" from \"\n\t\t\t      \"the state files in StateSaveLocation.\\n\"\n\t\t\t      \"Running multiple clusters from a shared \"\n\t\t\t      \"StateSaveLocation WILL CAUSE CORRUPTION.\\n\"\n\t\t\t      \"Remove %s to override this safety check if \"\n\t\t\t      \"this is intentional (e.g., the ClusterName \"\n\t\t\t      \"has changed).\", slurmctld_conf.cluster_name,\n\t\t\t      name, filename);\n\t\t\texit(1);\n\t\t}\n\t} else if (slurmctld_conf.cluster_name)\n\t\tcreate_file = true;\n\n\txfree(filename);\n\n\treturn create_file;\n}\n\nstatic void _create_clustername_file(void)\n{\n\tFILE *fp;\n\tchar *filename = NULL;\n\n\tif (!slurmctld_conf.cluster_name)\n\t\treturn;\n\n\tfilename = xstrdup_printf(\"%s/clustername\",\n\t\t\t\t  slurmctld_conf.state_save_location);\n\n\tdebug(\"creating clustername file: %s\", filename);\n\tif (!(fp = fopen(filename, \"w\"))) {\n\t\tfatal(\"%s: failed to create file %s\", __func__, filename);\n\t\texit(1);\n\t}\n\n\tif (fputs(slurmctld_conf.cluster_name, fp) < 0) {\n\t\tfatal(\"%s: failed to write to file %s\", __func__, filename);\n\t\texit(1);\n\t}\n\tfclose(fp);\n\n\txfree(filename);\n}\n\n/* Kill the currently running slurmctld\n * NOTE: No need to lock the config data since we are still single-threaded */\nstatic void _kill_old_slurmctld(void)\n{\n\tint fd;\n\tpid_t oldpid = read_pidfile(slurmctld_conf.slurmctld_pidfile, &fd);\n\tif (oldpid != (pid_t) 0) {\n\t\tinfo (\"killing old slurmctld[%ld]\", (long) oldpid);\n\t\tkill(oldpid, SIGTERM);\n\n\t\t/*\n\t\t * Wait for previous daemon to terminate\n\t\t */\n\t\tif (fd_get_readw_lock(fd) < 0)\n\t\t\tfatal (\"unable to wait for readw lock: %m\");\n\t\t(void) close(fd); /* Ignore errors */\n\t}\n}\n\n/* NOTE: No need to lock the config data since we are still single-threaded */\nstatic void _init_pidfile(void)\n{\n\tif (!xstrcmp(slurmctld_conf.slurmctld_pidfile,\n\t\t     slurmctld_conf.slurmd_pidfile))\n\t\terror(\"SlurmctldPid == SlurmdPid, use different names\");\n\n\t/* Don't close the fd returned here since we need to keep the\n\t * fd open to maintain the write lock */\n\t(void) create_pidfile(slurmctld_conf.slurmctld_pidfile,\n\t\t\t      slurmctld_conf.slurm_user_id);\n}\n\n/*\n * set_slurmctld_state_loc - create state directory as needed and \"cd\" to it\n * NOTE: config read lock must be set on entry\n */\nextern void set_slurmctld_state_loc(void)\n{\n\tint rc;\n\tstruct stat st;\n\tconst char *path = slurmctld_conf.state_save_location;\n\n\t/*\n\t * If state save location does not exist, try to create it.\n\t *  Otherwise, ensure path is a directory as expected, and that\n\t *  we have permission to write to it.\n\t */\n\tif (((rc = stat(path, &st)) < 0) && (errno == ENOENT)) {\n\t\tif (mkdir(path, 0755) < 0)\n\t\t\tfatal(\"mkdir(%s): %m\", path);\n\t}\n\telse if (rc < 0)\n\t\tfatal(\"Unable to stat state save loc: %s: %m\", path);\n\telse if (!S_ISDIR(st.st_mode))\n\t\tfatal(\"State save loc: %s: Not a directory!\", path);\n\telse if (access(path, R_OK|W_OK|X_OK) < 0)\n\t\tfatal(\"Incorrect permissions on state save loc: %s\", path);\n}\n\n/* _assoc_cache_mgr - hold out until we have real data from the\n * database so we can reset the job ptr's assoc ptr's */\nstatic void *_assoc_cache_mgr(void *no_data)\n{\n\tListIterator itr = NULL;\n\tjob_record_t *job_ptr = NULL;\n\tpart_record_t *part_ptr = NULL;\n\tslurmdb_qos_rec_t qos_rec;\n\tslurmdb_assoc_rec_t assoc_rec;\n\t/* Write lock on jobs, nodes and partitions */\n\tslurmctld_lock_t job_write_lock =\n\t\t{ NO_LOCK, WRITE_LOCK, WRITE_LOCK, WRITE_LOCK, NO_LOCK };\n\tassoc_mgr_lock_t locks =\n\t\t{ .assoc = READ_LOCK, .qos = READ_LOCK, .tres = WRITE_LOCK,\n\t\t  .user = READ_LOCK };\n\n\twhile (running_cache == 1) {\n\t\tslurm_mutex_lock(&assoc_cache_mutex);\n\t\tslurm_cond_wait(&assoc_cache_cond, &assoc_cache_mutex);\n\t\t/* This is here to see if we are exiting.  If we get\n\t\t   NO_VAL then just return since we are closing down.\n\t\t*/\n\t\tif (running_cache == NO_VAL16) {\n\t\t\tslurm_mutex_unlock(&assoc_cache_mutex);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tlock_slurmctld(job_write_lock);\n\t\t/*\n\t\t * Make sure not to have the job_write_lock, assoc_mgr or the\n\t\t * slurmdbd_lock locked when refresh_lists is called or you may\n\t\t * get deadlock.\n\t\t */\n\t\tassoc_mgr_refresh_lists(acct_db_conn, 0);\n\t\tif (g_tres_count != slurmctld_tres_cnt) {\n\t\t\tinfo(\"TRES in database does not match cache \"\n\t\t\t     \"(%u != %u).  Updating...\",\n\t\t\t     g_tres_count, slurmctld_tres_cnt);\n\t\t\t_init_tres();\n\t\t}\n\t\tif (running_cache == 1)\n\t\t\tunlock_slurmctld(job_write_lock);\n\n\t\tslurm_mutex_unlock(&assoc_cache_mutex);\n\t}\n\n\tif (!job_list) {\n\t\t/* This could happen in rare occations, it doesn't\n\t\t * matter since when the job_list is populated things\n\t\t * will be in sync.\n\t\t */\n\t\tdebug2(\"No job list yet\");\n\t\tunlock_slurmctld(job_write_lock);\n\t\tgoto handle_parts;\n\t}\n\n\tdebug2(\"got real data from the database \"\n\t       \"refreshing the association ptr's for %d jobs\",\n\t       list_count(job_list));\n\tassoc_mgr_lock(&locks);\n\titr = list_iterator_create(job_list);\n\twhile ((job_ptr = list_next(itr))) {\n\t\t_update_job_tres(job_ptr);\n\n\t\tif (job_ptr->assoc_id) {\n\t\t\tmemset(&assoc_rec, 0,\n\t\t\t       sizeof(slurmdb_assoc_rec_t));\n\t\t\tassoc_rec.id = job_ptr->assoc_id;\n\n\t\t\tdebug(\"assoc is %zx (%d) for %pJ\",\n\t\t\t      (size_t)job_ptr->assoc_ptr, job_ptr->assoc_id,\n\t\t\t      job_ptr);\n\n\t\t\tif (assoc_mgr_fill_in_assoc(\n\t\t\t\t    acct_db_conn, &assoc_rec,\n\t\t\t\t    accounting_enforce,\n\t\t\t\t    (slurmdb_assoc_rec_t **)\n\t\t\t\t    &job_ptr->assoc_ptr, true)) {\n\t\t\t\tverbose(\"Invalid association id %u for %pJ\",\n\t\t\t\t\tjob_ptr->assoc_id, job_ptr);\n\t\t\t\t/* not a fatal error, association could have\n\t\t\t\t * been removed */\n\t\t\t}\n\n\t\t\tdebug(\"now assoc is %zx (%d) for %pJ\",\n\t\t\t      (size_t)job_ptr->assoc_ptr, job_ptr->assoc_id,\n\t\t\t      job_ptr);\n\t\t}\n\t\tif (job_ptr->qos_id) {\n\t\t\tmemset(&qos_rec, 0, sizeof(slurmdb_qos_rec_t));\n\t\t\tqos_rec.id = job_ptr->qos_id;\n\t\t\tif ((assoc_mgr_fill_in_qos(\n\t\t\t\t    acct_db_conn, &qos_rec,\n\t\t\t\t    accounting_enforce,\n\t\t\t\t    (slurmdb_qos_rec_t **)&job_ptr->qos_ptr,\n\t\t\t\t    true))\n\t\t\t   != SLURM_SUCCESS) {\n\t\t\t\tverbose(\"Invalid qos (%u) for %pJ\",\n\t\t\t\t\tjob_ptr->qos_id, job_ptr);\n\t\t\t\t/* not a fatal error, qos could have\n\t\t\t\t * been removed */\n\t\t\t}\n\t\t}\n\t}\n\tlist_iterator_destroy(itr);\n\nhandle_parts:\n\tif (!part_list) {\n\t\t/* This could happen in rare occations, it doesn't\n\t\t * matter since when the job_list is populated things\n\t\t * will be in sync.\n\t\t */\n\t\tdebug2(\"No part list yet\");\n\t\tgoto end_it;\n\t}\n\n\titr = list_iterator_create(part_list);\n\twhile ((part_ptr = list_next(itr))) {\n\t\tif (part_ptr->allow_qos)\n\t\t\tqos_list_build(part_ptr->allow_qos,\n\t\t\t\t       &part_ptr->allow_qos_bitstr);\n\n\t\tif (part_ptr->deny_qos)\n\t\t\tqos_list_build(part_ptr->deny_qos,\n\t\t\t\t       &part_ptr->deny_qos_bitstr);\n\n\t\tif (part_ptr->qos_char) {\n\t\t\tslurmdb_qos_rec_t qos_rec;\n\n\t\t\tmemset(&qos_rec, 0, sizeof(slurmdb_qos_rec_t));\n\t\t\tqos_rec.name = part_ptr->qos_char;\n\t\t\tpart_ptr->qos_ptr = NULL;\n\t\t\tif (assoc_mgr_fill_in_qos(\n\t\t\t\t    acct_db_conn, &qos_rec, accounting_enforce,\n\t\t\t\t    (slurmdb_qos_rec_t **)&part_ptr->qos_ptr,\n\t\t\t\t    true)\n\t\t\t    != SLURM_SUCCESS) {\n\t\t\t\tfatal(\"Partition %s has an invalid qos (%s), \"\n\t\t\t\t      \"please check your configuration\",\n\t\t\t\t      part_ptr->name, qos_rec.name);\n\t\t\t}\n\t\t}\n\t}\n\tlist_iterator_destroy(itr);\n\nend_it:\n\n\tset_cluster_tres(true);\n\n\tassoc_mgr_unlock(&locks);\n\t/* issuing a reconfig will reset the pointers on the burst\n\t   buffers */\n\tbb_g_reconfig();\n\n\tunlock_slurmctld(job_write_lock);\n\t/* This needs to be after the lock and after we update the\n\t   jobs so if we need to send them we are set. */\n\t_accounting_cluster_ready();\n\t_get_fed_updates();\n\n\treturn NULL;\n}\n\nstatic void _become_slurm_user(void)\n{\n\tgid_t slurm_user_gid;\n\n\t/* Determine SlurmUser gid */\n\tslurm_user_gid = gid_from_uid(slurmctld_conf.slurm_user_id);\n\tif (slurm_user_gid == (gid_t) -1) {\n\t\tfatal(\"Failed to determine gid of SlurmUser(%u)\",\n\t\t      slurmctld_conf.slurm_user_id);\n\t}\n\n\t/* Initialize supplementary groups ID list for SlurmUser */\n\tif (getuid() == 0) {\n\t\t/* root does not need supplementary groups */\n\t\tif ((slurmctld_conf.slurm_user_id == 0) &&\n\t\t    (setgroups(0, NULL) != 0)) {\n\t\t\tfatal(\"Failed to drop supplementary groups, \"\n\t\t\t      \"setgroups: %m\");\n\t\t} else if ((slurmctld_conf.slurm_user_id != 0) &&\n\t\t\t   initgroups(slurmctld_conf.slurm_user_name,\n\t\t\t\t      slurm_user_gid)) {\n\t\t\tfatal(\"Failed to set supplementary groups, \"\n\t\t\t      \"initgroups: %m\");\n\t\t}\n\t} else if (test_config) {\n\t\treturn;\n\t} else {\n\t\tinfo(\"Not running as root. Can't drop supplementary groups\");\n\t}\n\n\t/* Set GID to GID of SlurmUser */\n\tif ((slurm_user_gid != getegid()) &&\n\t    (setgid(slurm_user_gid))) {\n\t\tfatal(\"Failed to set GID to %d\", slurm_user_gid);\n\t}\n\n\t/* Set UID to UID of SlurmUser */\n\tif ((slurmctld_conf.slurm_user_id != getuid()) &&\n\t    (setuid(slurmctld_conf.slurm_user_id))) {\n\t\tfatal(\"Can not set uid to SlurmUser(%u): %m\",\n\t\t      slurmctld_conf.slurm_user_id);\n\t}\n}\n\n/*\n * Find this host in the controller index, or return -1 on error.\n */\nstatic int _controller_index(void)\n{\n\tint i;\n\n\t/*\n\t * Slurm internal HA mode (or no HA).\n\t * Each controller is separately defined, and a single hostname is in\n\t * each control_machine entry.\n\t */\n\tfor (i = 0; i < slurmctld_conf.control_cnt; i++) {\n\t\tif (slurmctld_conf.control_machine[i] &&\n\t\t    slurmctld_conf.control_addr[i]    &&\n\t\t    (!xstrcmp(slurmctld_config.node_name_short,\n\t\t\t      slurmctld_conf.control_machine[i])  ||\n\t\t     !xstrcmp(slurmctld_config.node_name_long,\n\t\t\t      slurmctld_conf.control_machine[i]))) {\n\t\t\treturn i;\n\t\t}\n\t}\n\n\t/*\n\t * External HA mode. Here a single control_addr has been defined,\n\t * but multiple hostnames are in control_machine[0] with comma\n\t * separation. If our hostname matches any of those, we are considered\n\t * to be a valid controller, and which is active much be managed by\n\t * an external HA solution.\n\t */\n\tif (xstrchr(slurmctld_conf.control_machine[0], ',')) {\n\t\tchar *token, *last = NULL;\n\t\tchar *tmp_name = xstrdup(slurmctld_conf.control_machine[0]);\n\n\t\ttoken = strtok_r(tmp_name, \",\", &last);\n\t\twhile (token) {\n\t\t\tif (!xstrcmp(slurmctld_config.node_name_short, token) ||\n\t\t\t    !xstrcmp(slurmctld_config.node_name_long, token)) {\n\t\t\t\txfree(tmp_name);\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\ttoken = strtok_r(NULL, \",\", &last);\n\t\t}\n\t\txfree(tmp_name);\n\t}\n\n\treturn -1;\n}\n\n\nstatic void _test_thread_limit(void)\n{\n#ifdef RLIMIT_NOFILE\n{\n\tstruct rlimit rlim[1];\n\tif (getrlimit(RLIMIT_NOFILE, rlim) < 0)\n\t\terror(\"Unable to get file count limit\");\n\telse if ((rlim->rlim_cur != RLIM_INFINITY) &&\n\t\t (max_server_threads > rlim->rlim_cur)) {\n\t\tmax_server_threads = rlim->rlim_cur;\n\t\tinfo(\"Reducing max_server_thread to %u due to file count limit \"\n\t\t     \"of %u\", max_server_threads, max_server_threads);\n\t}\n}\n#endif\n\treturn;\n}\n\nstatic void  _set_work_dir(void)\n{\n\tbool success = false;\n\n\tif (slurmctld_conf.slurmctld_logfile &&\n\t    (slurmctld_conf.slurmctld_logfile[0] == '/')) {\n\t\tchar *slash_ptr, *work_dir;\n\t\twork_dir = xstrdup(slurmctld_conf.slurmctld_logfile);\n\t\tslash_ptr = strrchr(work_dir, '/');\n\t\tif (slash_ptr == work_dir)\n\t\t\twork_dir[1] = '\\0';\n\t\telse\n\t\t\tslash_ptr[0] = '\\0';\n\t\tif ((access(work_dir, W_OK) != 0) || (chdir(work_dir) < 0))\n\t\t\terror(\"chdir(%s): %m\", work_dir);\n\t\telse\n\t\t\tsuccess = true;\n\t\txfree(work_dir);\n\t}\n\n\tif (!success) {\n\t\tif ((access(slurmctld_conf.state_save_location, W_OK) != 0) ||\n\t\t    (chdir(slurmctld_conf.state_save_location) < 0)) {\n\t\t\terror(\"chdir(%s): %m\",\n\t\t\t      slurmctld_conf.state_save_location);\n\t\t} else\n\t\t\tsuccess = true;\n\t}\n\n\tif (!success) {\n\t\tif ((access(\"/var/tmp\", W_OK) != 0) ||\n\t\t    (chdir(\"/var/tmp\") < 0)) {\n\t\t\terror(\"chdir(/var/tmp): %m\");\n\t\t} else\n\t\t\tinfo(\"chdir to /var/tmp\");\n\t}\n}\n\n/*\n * _purge_files_thread - separate thread to remove job batch/environ files\n * from the state directory. Runs async from purge_old_jobs to avoid\n * holding locks while the files are removed, which can cause performance\n * problems under high throughput conditions.\n *\n * Uses the purge_cond to wakeup on demand, then works through the global\n * purge_files_list of job_ids and removes their files.\n */\nstatic void *_purge_files_thread(void *no_data)\n{\n\tint *job_id;\n\n\t/*\n\t * Use the purge_files_list as a queue. _delete_job_details()\n\t * in job_mgr.c always enqueues (at the end), while\n\t *_purge_files_thread consumes off the front.\n\t *\n\t * There is a potential race condition if the job numbers have\n\t * wrapped between _purge_thread removing the state files and\n\t * get_next_job_id trying to re-assign it. This is mitigated\n\t * the call to _dup_job_file_test() in job_mgr.c ensuring\n\t * there is no existing directory for an id before assigning it.\n\t */\n\n\t/*\n\t * pthread_cond_wait requires a lock to release and reclaim.\n\t * the List structure is already handling locking for itself,\n\t * so this lock isn't actually useful, and the thread calling\n\t * pthread_cond_signal isn't required to have the lock. So\n\t * lock it once and hold it until slurmctld shuts down.\n\t */\n\tslurm_mutex_lock(&purge_thread_lock);\n\twhile (!slurmctld_config.shutdown_time) {\n\t\tslurm_cond_wait(&purge_thread_cond, &purge_thread_lock);\n\t\tdebug2(\"%s: starting, %d jobs to purge\", __func__,\n\t\t       list_count(purge_files_list));\n\n\t\t/*\n\t\t * Use list_dequeue here (instead of list_flush) as it will not\n\t\t * hold up the list lock when we try to enqueue jobs that need\n\t\t * to be freed.\n\t\t */\n\t\twhile ((job_id = list_dequeue(purge_files_list))) {\n\t\t\tdebug2(\"%s: purging files from JobId=%u\",\n\t\t\t       __func__, *job_id);\n\t\t\tdelete_job_desc_files(*job_id);\n\t\t\txfree(job_id);\n\t\t}\n\t}\n\tslurm_mutex_unlock(&purge_thread_lock);\n\treturn NULL;\n}\n\nstatic void _get_fed_updates(void)\n{\n\tList fed_list = NULL;\n\tslurmdb_update_object_t update = {0};\n\tslurmdb_federation_cond_t fed_cond;\n\n\tslurmdb_init_federation_cond(&fed_cond, 0);\n\tfed_cond.cluster_list = list_create(NULL);\n\tlist_append(fed_cond.cluster_list, slurmctld_conf.cluster_name);\n\n\tfed_list = acct_storage_g_get_federations(acct_db_conn,\n\t\t\t\t\t\t  slurmctld_conf.slurm_user_id,\n\t\t\t\t\t\t  &fed_cond);\n\tFREE_NULL_LIST(fed_cond.cluster_list);\n\n\tif (fed_list) {\n\t\tupdate.objects = fed_list;\n\t\tfed_mgr_update_feds(&update);\n\t}\n\n\tFREE_NULL_LIST(fed_list);\n}\n\nstatic int _foreach_job_running(void *object, void *arg)\n{\n\tjob_record_t *job_ptr = (job_record_t *)object;\n\n\tif (IS_JOB_PENDING(job_ptr)) {\n\t\tint job_cnt = (job_ptr->array_recs &&\n\t\t\t       job_ptr->array_recs->task_cnt) ?\n\t\t\tjob_ptr->array_recs->task_cnt : 1;\n\t\tslurmctld_diag_stats.jobs_pending += job_cnt;\n\t}\n\tif (IS_JOB_RUNNING(job_ptr))\n\t\tslurmctld_diag_stats.jobs_running++;\n\n\treturn SLURM_SUCCESS;\n}\n\nstatic void _update_diag_job_state_counts(void)\n{\n\tslurmctld_diag_stats.jobs_running = 0;\n\tslurmctld_diag_stats.jobs_pending = 0;\n\tslurmctld_diag_stats.job_states_ts = time(NULL);\n\tlist_for_each(job_list, _foreach_job_running, NULL);\n}\n\nstatic void *_wait_primary_prog(void *arg)\n{\n\tprimary_thread_arg_t *wait_arg = (primary_thread_arg_t *) arg;\n\tint status = 0;\n\n\twaitpid(wait_arg->cpid, &status, 0);\n\tif (status != 0) {\n\t\terror(\"%s: %s exit status %u:%u\", __func__, wait_arg->prog_type,\n\t\t      WEXITSTATUS(status), WTERMSIG(status));\n\t} else {\n\t\tinfo(\"%s: %s completed successfully\", __func__,\n\t\t     wait_arg->prog_type);\n\t}\n\txfree(wait_arg->prog_type);\n\txfree(wait_arg);\n\treturn (void *) NULL;\n}\n\nstatic void _run_primary_prog(bool primary_on)\n{\n\tprimary_thread_arg_t *wait_arg;\n\tchar *prog_name, *prog_type;\n\tchar *argv[2], *sep;\n\tpid_t cpid;\n\tint i;\n\n\tif (primary_on) {\n\t\tprog_name = slurmctld_conf.slurmctld_primary_on_prog;\n\t\tprog_type = \"SlurmctldPrimaryOnProg\";\n\t} else {\n\t\tprog_name = slurmctld_conf.slurmctld_primary_off_prog;\n\t\tprog_type = \"SlurmctldPrimaryOffProg\";\n\t}\n\n\tif ((prog_name == NULL) || (prog_name[0] == '\\0'))\n\t\treturn;\n\n\tif (access(prog_name, X_OK) < 0) {\n\t\terror(\"%s: Invalid %s: %m\", __func__, prog_type);\n\t\treturn;\n\t}\n\n\tsep = strrchr(prog_name, '/');\n\tif (sep)\n\t\targv[0] = sep + 1;\n\telse\n\t\targv[0] = prog_name;\n\targv[1] = NULL;\n\tif ((cpid = fork()) < 0) {\t/* Error */\n\t\terror(\"%s fork error: %m\", __func__);\n\t\treturn;\n\t}\n\tif (cpid == 0) {\t\t/* Child */\n\t\tfor (i = 0; i < 1024; i++)\n\t\t\t(void) close(i);\n\t\tsetpgid(0, 0);\n\t\texecv(prog_name, argv);\n\t\texit(127);\n\t}\n\n\t/* Create thread to wait for and log program completion */\n\twait_arg = xmalloc(sizeof(primary_thread_arg_t));\n\twait_arg->cpid = cpid;\n\twait_arg->prog_type = xstrdup(prog_type);\n\tslurm_thread_create_detached(NULL, _wait_primary_prog, wait_arg);\n}\n\n/*\n * Respond to request for backup slurmctld status\n */\nextern void slurm_rpc_control_status(slurm_msg_t *msg, time_t control_time)\n{\n\tslurm_msg_t response_msg;\n\tcontrol_status_msg_t data;\n\n\tresponse_init(&response_msg, msg);\n\tresponse_msg.msg_type = RESPONSE_CONTROL_STATUS;\n\tresponse_msg.data = &data;\n\tresponse_msg.data_size = sizeof(control_status_msg_t);\n\tmemset(&data, 0, sizeof(data));\n\tdata.backup_inx = backup_inx;\n\tdata.control_time = control_time;\n\tslurm_send_node_msg(msg->conn_fd, &response_msg);\n}\n\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/src/slurmd/slurmd/slurmd.c": "/*****************************************************************************\\\n *  src/slurmd/slurmd/slurmd.c - main slurm node server daemon\n *****************************************************************************\n *  Copyright (C) 2002-2007 The Regents of the University of California.\n *  Copyright (C) 2008-2010 Lawrence Livermore National Security.\n *  Portions Copyright (C) 2008 Vijay Ramasubramanian.\n *  Portions Copyright (C) 2010-2013 SchedMD LLC.\n *  Copyright (C) 2013      Intel, Inc.\n *  Produced at Lawrence Livermore National Laboratory (cf, DISCLAIMER).\n *  Written by Mark Grondona <mgrondona@llnl.gov>.\n *  CODE-OCEC-09-009. All rights reserved.\n *\n *  This file is part of Slurm, a resource management program.\n *  For details, see <https://slurm.schedmd.com/>.\n *  Please also read the included file: DISCLAIMER.\n *\n *  Slurm is free software; you can redistribute it and/or modify it under\n *  the terms of the GNU General Public License as published by the Free\n *  Software Foundation; either version 2 of the License, or (at your option)\n *  any later version.\n *\n *  In addition, as a special exception, the copyright holders give permission\n *  to link the code of portions of this program with the OpenSSL library under\n *  certain conditions as described in each individual source file, and\n *  distribute linked combinations including the two. You must obey the GNU\n *  General Public License in all respects for all of the code used other than\n *  OpenSSL. If you modify file(s) with this exception, you may extend this\n *  exception to your version of the file(s), but you are not obligated to do\n *  so. If you do not wish to do so, delete this exception statement from your\n *  version.  If you delete this exception statement from all source files in\n *  the program, then also delete it here.\n *\n *  Slurm is distributed in the hope that it will be useful, but WITHOUT ANY\n *  WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n *  FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more\n *  details.\n *\n *  You should have received a copy of the GNU General Public License along\n *  with Slurm; if not, write to the Free Software Foundation, Inc.,\n *  51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA.\n\\*****************************************************************************/\n\n#include \"config.h\"\n\n/* Needed for sched_setaffinity */\n#define _GNU_SOURCE\n\n#if HAVE_HWLOC\n#  include <hwloc.h>\n#endif\n\n#include <dirent.h>\n#include <dlfcn.h>\n#include <fcntl.h>\n#include <grp.h>\n#include <pthread.h>\n#include <sched.h>\n#include <stdlib.h>\n#include <string.h>\n#include <sys/mman.h>\n#include <sys/param.h>\n#include <sys/resource.h>\n#include <sys/stat.h>\n#include <sys/time.h>\n#include <sys/types.h>\n#include <sys/utsname.h>\n#include <unistd.h>\n\n#include \"src/common/assoc_mgr.h\"\n#include \"src/common/bitstring.h\"\n#include \"src/common/cpu_frequency.h\"\n#include \"src/common/daemonize.h\"\n#include \"src/common/fd.h\"\n#include \"src/common/fetch_config.h\"\n#include \"src/common/forward.h\"\n#include \"src/common/gres.h\"\n#include \"src/common/group_cache.h\"\n#include \"src/common/hostlist.h\"\n#include \"src/common/list.h\"\n#include \"src/common/log.h\"\n#include \"src/common/macros.h\"\n#include \"src/common/msg_aggr.h\"\n#include \"src/common/node_conf.h\"\n#include \"src/common/node_features.h\"\n#include \"src/common/node_select.h\"\n#include \"src/common/pack.h\"\n#include \"src/common/parse_time.h\"\n#include \"src/common/plugstack.h\"\n#include \"src/common/prep.h\"\n#include \"src/common/proc_args.h\"\n#include \"src/common/read_config.h\"\n#include \"src/common/slurm_auth.h\"\n#include \"src/common/slurm_cred.h\"\n#include \"src/common/slurm_acct_gather_energy.h\"\n#include \"src/common/slurm_jobacct_gather.h\"\n#include \"src/common/slurm_mcs.h\"\n#include \"src/common/slurm_protocol_api.h\"\n#include \"src/common/slurm_rlimits_info.h\"\n#include \"src/common/slurm_route.h\"\n#include \"src/common/slurm_topology.h\"\n#include \"src/common/stepd_api.h\"\n#include \"src/common/switch.h\"\n#include \"src/common/uid.h\"\n#include \"src/common/xcgroup_read_config.h\"\n#include \"src/common/xmalloc.h\"\n#include \"src/common/xstring.h\"\n#include \"src/common/xsignal.h\"\n\n#include \"src/slurmd/common/core_spec_plugin.h\"\n#include \"src/slurmd/common/job_container_plugin.h\"\n#include \"src/slurmd/common/proctrack.h\"\n#include \"src/slurmd/common/run_script.h\"\n#include \"src/slurmd/common/set_oomadj.h\"\n#include \"src/slurmd/common/setproctitle.h\"\n#include \"src/slurmd/common/slurmd_cgroup.h\"\n#include \"src/slurmd/common/slurmstepd_init.h\"\n#include \"src/slurmd/common/task_plugin.h\"\n#include \"src/slurmd/common/xcpuinfo.h\"\n\n#include \"src/slurmd/slurmd/get_mach_stat.h\"\n#include \"src/slurmd/slurmd/req.h\"\n#include \"src/slurmd/slurmd/slurmd.h\"\n\n#ifndef MAXHOSTNAMELEN\n#  define MAXHOSTNAMELEN\t64\n#endif\n\n#define MAX_THREADS\t\t256\n\n#define _free_and_set(__dst, __src)\t\t\\\n\tdo {\t\t\t\t\t\\\n\t\txfree(__dst); __dst = __src;\t\\\n\t} while (0)\n\n/* global, copied to STDERR_FILENO in tasks before the exec */\nint devnull = -1;\nbool get_reg_resp = 1;\nslurmd_conf_t * conf = NULL;\nint fini_job_cnt = 0;\nuint32_t *fini_job_id = NULL;\npthread_mutex_t fini_job_mutex = PTHREAD_MUTEX_INITIALIZER;\npthread_mutex_t tres_mutex     = PTHREAD_MUTEX_INITIALIZER;\npthread_cond_t  tres_cond      = PTHREAD_COND_INITIALIZER;\nbool tres_packed = false;\n\n/*\n * count of active threads\n */\nstatic int             active_threads = 0;\nstatic pthread_mutex_t active_mutex   = PTHREAD_MUTEX_INITIALIZER;\nstatic pthread_cond_t  active_cond    = PTHREAD_COND_INITIALIZER;\n\nstatic pthread_mutex_t fork_mutex     = PTHREAD_MUTEX_INITIALIZER;\n\ntypedef struct connection {\n\tint fd;\n\tslurm_addr_t *cli_addr;\n} conn_t;\n\n/*\n * Global data for resource specialization\n */\n#define MAX_CPUSTR 256\nstatic bitstr_t\t*res_core_bitmap;\t/* reserved abstract cores bitmap */\nstatic bitstr_t\t*res_cpu_bitmap;\t/* reserved abstract CPUs bitmap */\nstatic char\t*res_abs_cores = NULL;\t/* reserved abstract cores list */\nstatic int32_t\tres_abs_core_size = 0;\t/* Length of res_abs_cores variable */\nstatic char\tres_abs_cpus[MAX_CPUSTR]; /* reserved abstract CPUs list */\nstatic char\t*res_mac_cpus = NULL;\t/* reserved machine CPUs list */\nstatic int\tncores;\t\t\t/* number of cores on this node */\nstatic int\tncpus;\t\t\t/* number of CPUs on this node */\n\n/*\n * static shutdown and reconfigure flags:\n */\nstatic sig_atomic_t _shutdown = 0;\nstatic sig_atomic_t _reconfig = 0;\nstatic sig_atomic_t _update_log = 0;\nstatic pthread_t msg_pthread = (pthread_t) 0;\nstatic time_t sent_reg_time = (time_t) 0;\n\nstatic void      _atfork_final(void);\nstatic void      _atfork_prepare(void);\nstatic int       _convert_spec_cores(void);\nstatic int       _core_spec_init(void);\nstatic void      _create_msg_socket(void);\nstatic void      _decrement_thd_count(void);\nstatic void      _destroy_conf(void);\nstatic int       _drain_node(char *reason);\nstatic void      _fill_registration_msg(slurm_node_registration_status_msg_t *);\nstatic uint64_t  _get_int(const char *my_str);\nstatic void      _handle_connection(int fd, slurm_addr_t *client);\nstatic void      _hup_handler(int);\nstatic void      _increment_thd_count(void);\nstatic void      _init_conf(void);\nstatic void      _install_fork_handlers(void);\nstatic bool      _is_core_spec_cray(void);\nstatic void      _kill_old_slurmd(void);\nstatic int       _memory_spec_init(void);\nstatic void      _msg_engine(void);\nstatic uint64_t  _parse_msg_aggr_params(int type, char *params);\nstatic void      _print_conf(void);\nstatic void      _print_config(void);\nstatic void      _print_gres(void);\nstatic void      _process_cmdline(int ac, char **av);\nstatic void      _read_config(void);\nstatic void      _reconfigure(void);\nstatic void     *_registration_engine(void *arg);\nstatic void      _resource_spec_fini(void);\nstatic int       _resource_spec_init(void);\nstatic int       _restore_cred_state(slurm_cred_ctx_t ctx);\nstatic void      _select_spec_cores(void);\nstatic void     *_service_connection(void *);\nstatic void      _set_msg_aggr_params(void);\nstatic int       _set_slurmd_spooldir(const char *dir);\nstatic int       _set_topo_info(void);\nstatic int       _slurmd_init(void);\nstatic int       _slurmd_fini(void);\nstatic void      _update_logging(void);\nstatic void      _update_nice(void);\nstatic void      _usage(void);\nstatic void      _usr_handler(int);\nstatic int       _validate_and_convert_cpu_list(void);\nstatic void      _wait_for_all_threads(int secs);\n\n/**************************************************************************\\\n * To test for memory leaks, set MEMORY_LEAK_DEBUG to 1 using\n * \"configure --enable-memory-leak-debug\" then execute\n *\n * $ valgrind --tool=memcheck --leak-check=yes --num-callers=40 \\\n *   --leak-resolution=high --child-silent-after-fork=yes \\\n *   --suppressions=<DIR>/hwloc/hwloc-valgrind.supp \\\n *   ./slurmd -Dc >valg.slurmd.out 2>&1\n *\n * Then exercise the slurmctld functionality before executing\n * > scontrol shutdown\n *\n * Note that --enable-memory-leak-debug will cause the daemon to\n * unload the shared objects at exit thus preventing valgrind\n * to display the stack where the eventual leaks may be.\n * It is always best to test with and without --enable-memory-leak-debug.\n *\n * The HWLOC library generates quite a few memory leaks unless the following\n *    option is added to the valgrind execute line:\n *    --suppressions=<INSTALL_DIR>/share/hwloc/hwloc-valgrind.supp\n * On some systems _keyvalue_regex_init() will generate two blocks \"definitely\n *    lost\", both of size zero.\n * On some systems dlopen() will generate a small number of \"definitely\n *    lost\" blocks that are not cleared by dlclose().\n * On some systems, pthread_create() will generated a small number of\n *    \"possibly lost\" blocks.\n * Otherwise the report should be free of errors. Remember to reset\n *    MEMORY_LEAK_DEBUG to 0 for production use (non-seamless backup\n *    controller use).\n\\**************************************************************************/\n\nint\nmain (int argc, char **argv)\n{\n\tint i, pidfd;\n\tint blocked_signals[] = {SIGPIPE, 0};\n\tint cc;\n\tchar *oom_value;\n\tuint32_t slurmd_uid = 0;\n\tuint32_t curr_uid = 0;\n\tchar time_stamp[256];\n\tlog_options_t lopts = LOG_OPTS_INITIALIZER;\n\n\t/* NOTE: logfile is NULL at this point */\n\tlog_init(argv[0], lopts, LOG_DAEMON, NULL);\n\n\t/*\n\t * Make sure we have no extra open files which\n\t * would be propagated to spawned tasks.\n\t */\n\tcc = sysconf(_SC_OPEN_MAX);\n\tfor (i = 3; i < cc; i++)\n\t\tclose(i);\n\n\t/*\n\t * Drop supplementary groups.\n\t */\n\tif (geteuid() == 0) {\n\t\tif (setgroups(0, NULL) != 0) {\n\t\t\tfatal(\"Failed to drop supplementary groups, \"\n\t\t\t      \"setgroups: %m\");\n\t\t}\n\t} else {\n\t\tdebug(\"Not running as root. Can't drop supplementary groups\");\n\t}\n\n\t/*\n\t * Create and set default values for the slurmd global\n\t * config variable \"conf\"\n\t */\n\tconf = xmalloc(sizeof(slurmd_conf_t));\n\t_init_conf();\n\tconf->argv = &argv;\n\tconf->argc = &argc;\n\n\tif (_slurmd_init() < 0) {\n\t\terror( \"slurmd initialization failed\" );\n\t\tfflush( NULL );\n\t\texit(1);\n\t}\n\n\tslurmd_uid = slurm_get_slurmd_user_id();\n\tcurr_uid = getuid();\n\tif (curr_uid != slurmd_uid) {\n\t\tchar *slurmd_user = uid_to_string_or_null(slurmd_uid);\n\t\tchar *curr_user = uid_to_string_or_null(curr_uid);\n\n\t\tfatal(\"You are running slurmd as something other than user %s(%u). \"\n\t\t      \"If you want to run as this user add SlurmdUser=%s to the slurm.conf file.\",\n\t\t      slurmd_user, slurmd_uid, curr_user);\n\t}\n\tinit_setproctitle(argc, argv);\n\n\txsignal(SIGTERM, slurmd_shutdown);\n\txsignal(SIGINT,  slurmd_shutdown);\n\txsignal(SIGHUP,  _hup_handler);\n\txsignal(SIGUSR2, _usr_handler);\n\txsignal_block(blocked_signals);\n\n\tdebug3(\"slurmd initialization successful\");\n\n\t/*\n\t * Become a daemon if desired.\n\t */\n\tif (conf->daemonize) {\n\t\tif (xdaemon())\n\t\t\terror(\"Couldn't daemonize slurmd: %m\");\n\t}\n\ttest_core_limit();\n\tinfo(\"slurmd version %s started\", SLURM_VERSION_STRING);\n\tdebug3(\"finished daemonize\");\n\n\tif ((oom_value = getenv(\"SLURMD_OOM_ADJ\"))) {\n\t\ti = atoi(oom_value);\n\t\tdebug(\"Setting slurmd oom_adj to %d\", i);\n\t\tset_oom_adj(i);\n\t}\n\n\t_kill_old_slurmd();\n\n\tif (conf->mlock_pages) {\n\t\t/*\n\t\t * Call mlockall() if available to ensure slurmd\n\t\t *  doesn't get swapped out\n\t\t */\n#ifdef _POSIX_MEMLOCK\n\t\tif (mlockall (MCL_FUTURE | MCL_CURRENT) < 0)\n\t\t\terror (\"failed to mlock() slurmd pages: %m\");\n#else\n\t\terror (\"mlockall() system call does not appear to be available\");\n#endif /* _POSIX_MEMLOCK */\n\t}\n\n\n\t/*\n\t * Restore any saved revoked credential information\n\t */\n\tif (!conf->cleanstart && (_restore_cred_state(conf->vctx) < 0))\n\t\treturn SLURM_ERROR;\n\n\tif (jobacct_gather_init() != SLURM_SUCCESS)\n\t\tfatal(\"Unable to initialize jobacct_gather\");\n\tif (job_container_init() < 0)\n\t\tfatal(\"Unable to initialize job_container plugin.\");\n\tif (container_g_restore(conf->spooldir, !conf->cleanstart))\n\t\terror(\"Unable to restore job_container state.\");\n\tif (prep_plugin_init(NULL) != SLURM_SUCCESS)\n\t\tfatal(\"failed to initialize prep plugin\");\n\tif (core_spec_g_init() < 0)\n\t\tfatal(\"Unable to initialize core specialization plugin.\");\n\tif (switch_g_node_init() < 0)\n\t\tfatal(\"Unable to initialize interconnect.\");\n\tif (node_features_g_init() != SLURM_SUCCESS)\n\t\tfatal(\"failed to initialize node_features plugin\");\n\tif (conf->cleanstart && switch_g_clear_node_state())\n\t\tfatal(\"Unable to clear interconnect state.\");\n\tswitch_g_slurmd_init();\n\tfile_bcast_init();\n\n\t_create_msg_socket();\n\n\tconf->pid = getpid();\n\tpidfd = create_pidfile(conf->pidfile, 0);\n\n\trfc2822_timestamp(time_stamp, sizeof(time_stamp));\n\tinfo(\"%s started on %s\", slurm_prog_name, time_stamp);\n\n\t_install_fork_handlers();\n\tslurm_conf_install_fork_handlers();\n\trecord_launched_jobs();\n\n\trun_script_health_check();\n\n\tmsg_aggr_sender_init(conf->hostname, conf->port,\n\t\t\t     conf->msg_aggr_window_time,\n\t\t\t     conf->msg_aggr_window_msgs);\n\n\tslurm_thread_create_detached(NULL, _registration_engine, NULL);\n\n\t_msg_engine();\n\n\t/*\n\t * Close fd here, otherwise we'll deadlock since create_pidfile()\n\t * flocks the pidfile.\n\t */\n\tif (pidfd >= 0)\t\t\t/* valid pidfd, non-error */\n\t\t(void) close(pidfd);\t/* Ignore errors */\n\tif (unlink(conf->pidfile) < 0)\n\t\terror(\"Unable to remove pidfile `%s': %m\", conf->pidfile);\n\n\t_wait_for_all_threads(120);\n\t_slurmd_fini();\n\t_destroy_conf();\n\tslurm_cred_fini();\t/* must be after _destroy_conf() */\n\tgroup_cache_purge();\n\tfile_bcast_purge();\n\n\tinfo(\"Slurmd shutdown completing\");\n\tlog_fini();\n       \treturn 0;\n}\n\n/*\n * Spawn a thread to make sure we send at least one registration message to\n * slurmctld. If slurmctld restarts, it will request another registration\n * message.\n */\nstatic void *\n_registration_engine(void *arg)\n{\n\t_increment_thd_count();\n\n\twhile (!_shutdown) {\n\t\tif ((sent_reg_time == (time_t) 0) &&\n\t\t    (send_registration_msg(SLURM_SUCCESS, true) !=\n\t\t     SLURM_SUCCESS)) {\n\t\t\tdebug(\"Unable to register with slurm controller, retrying\");\n\t\t} else if (_shutdown || sent_reg_time) {\n\t\t\tbreak;\n\t\t}\n\t\tsleep(1);\n\t}\n\n\t_decrement_thd_count();\n\treturn NULL;\n}\n\nstatic void\n_msg_engine(void)\n{\n\tslurm_addr_t *cli;\n\tint sock;\n\n\tmsg_pthread = pthread_self();\n\tslurmd_req(NULL);\t/* initialize timer */\n\twhile (!_shutdown) {\n\t\tif (_reconfig) {\n\t\t\tint rpc_wait = MAX(5, slurm_get_msg_timeout() / 2);\n\t\t\tverbose(\"got reconfigure request\");\n\t\t\t/* Wait for RPCs to finish */\n\t\t\t_wait_for_all_threads(rpc_wait);\n\t\t\tif (_shutdown)\n\t\t\t\tbreak;\n\t\t\t_reconfigure();\n\t\t}\n\t\tif (_update_log)\n\t\t\t_update_logging();\n\t\tcli = xmalloc (sizeof (slurm_addr_t));\n\t\tif ((sock = slurm_accept_msg_conn(conf->lfd, cli)) >= 0) {\n\t\t\t_handle_connection(sock, cli);\n\t\t\tcontinue;\n\t\t}\n\t\t/*\n\t\t *  Otherwise, accept() failed.\n\t\t */\n\t\txfree (cli);\n\t\tif (errno == EINTR)\n\t\t\tcontinue;\n\t\terror(\"accept: %m\");\n\t}\n\tverbose(\"got shutdown request\");\n\tclose(conf->lfd);\n\treturn;\n}\n\nstatic void\n_decrement_thd_count(void)\n{\n\tslurm_mutex_lock(&active_mutex);\n\tif (active_threads > 0)\n\t\tactive_threads--;\n\tslurm_cond_signal(&active_cond);\n\tslurm_mutex_unlock(&active_mutex);\n}\n\nstatic void\n_increment_thd_count(void)\n{\n\tbool logged = false;\n\n\tslurm_mutex_lock(&active_mutex);\n\twhile (active_threads >= MAX_THREADS) {\n\t\tif (!logged) {\n\t\t\tinfo(\"active_threads == MAX_THREADS(%d)\",\n\t\t\t     MAX_THREADS);\n\t\t\tlogged = true;\n\t\t}\n\t\tslurm_cond_wait(&active_cond, &active_mutex);\n\t}\n\tactive_threads++;\n\tslurm_mutex_unlock(&active_mutex);\n}\n\n/* secs IN - wait up to this number of seconds for all threads to complete */\nstatic void\n_wait_for_all_threads(int secs)\n{\n\tstruct timespec ts;\n\tint rc;\n\n\tts.tv_sec  = time(NULL);\n\tts.tv_nsec = 0;\n\tts.tv_sec += secs;\n\n\tslurm_mutex_lock(&active_mutex);\n\twhile (active_threads > 0) {\n\t\tverbose(\"waiting on %d active threads\", active_threads);\n\t\trc = pthread_cond_timedwait(&active_cond, &active_mutex, &ts);\n\t\tif (rc == ETIMEDOUT) {\n\t\t\terror(\"Timeout waiting for completion of %d threads\",\n\t\t\t      active_threads);\n\t\t\tslurm_cond_signal(&active_cond);\n\t\t\tslurm_mutex_unlock(&active_mutex);\n\t\t\treturn;\n\t\t}\n\t}\n\tslurm_cond_signal(&active_cond);\n\tslurm_mutex_unlock(&active_mutex);\n\tverbose(\"all threads complete\");\n}\n\nstatic void _handle_connection(int fd, slurm_addr_t *cli)\n{\n\tconn_t *arg = xmalloc(sizeof(conn_t));\n\n\targ->fd       = fd;\n\targ->cli_addr = cli;\n\n\tfd_set_close_on_exec(fd);\n\n\t_increment_thd_count();\n\tslurm_thread_create_detached(NULL, _service_connection, arg);\n}\n\nstatic void *\n_service_connection(void *arg)\n{\n\tconn_t *con = (conn_t *) arg;\n\tslurm_msg_t *msg = xmalloc(sizeof(slurm_msg_t));\n\tint rc = SLURM_SUCCESS;\n\n\tdebug3(\"in the service_connection\");\n\tslurm_msg_t_init(msg);\n\tif ((rc = slurm_receive_msg_and_forward(con->fd, con->cli_addr, msg, 0))\n\t   != SLURM_SUCCESS) {\n\t\terror(\"service_connection: slurm_receive_msg: %m\");\n\t\t/*\n\t\t * if this fails we need to make sure the nodes we forward\n\t\t * to are taken care of and sent back. This way the control\n\t\t * also has a better idea what happened to us\n\t\t */\n\t\tslurm_send_rc_msg(msg, rc);\n\t\tgoto cleanup;\n\t}\n\tdebug2(\"Start processing RPC: %s\", rpc_num2string(msg->msg_type));\n\n\tif (msg->msg_type != MESSAGE_COMPOSITE)\n\t\tslurmd_req(msg);\n\ncleanup:\n\tif ((msg->conn_fd >= 0) && close(msg->conn_fd) < 0)\n\t\terror (\"close(%d): %m\", con->fd);\n\n\txfree(con->cli_addr);\n\txfree(con);\n\tdebug2(\"Finish processing RPC: %s\", rpc_num2string(msg->msg_type));\n\tslurm_free_msg(msg);\n\t_decrement_thd_count();\n\treturn NULL;\n}\n\nstatic void _handle_node_reg_resp(slurm_msg_t *resp_msg)\n{\n\tint rc;\n\tslurm_node_reg_resp_msg_t *resp = NULL;\n\n\tswitch (resp_msg->msg_type) {\n\tcase RESPONSE_NODE_REGISTRATION:\n\t\tresp = (slurm_node_reg_resp_msg_t *) resp_msg->data;\n\t\tbreak;\n\tcase RESPONSE_SLURM_RC:\n\t\trc = ((return_code_msg_t *) resp_msg->data)->return_code;\n\t\tslurm_free_return_code_msg(resp_msg->data);\n\t\tif (rc)\n\t\t\tslurm_seterrno(rc);\n\t\tresp = NULL;\n\t\tbreak;\n\tdefault:\n\t\tslurm_seterrno(SLURM_UNEXPECTED_MSG_ERROR);\n\t\tbreak;\n\t}\n\n\n\tif (resp) {\n\t\t/*\n\t\t * We don't care about the assoc/qos locks\n\t\t * assoc_mgr_post_tres_list is requesting as those lists\n\t\t * don't exist here.\n\t\t */\n\t\tassoc_mgr_lock_t locks = { .tres = WRITE_LOCK };\n\n\t\t/*\n\t\t * We only needed the resp to get the tres the first time,\n\t\t * Set it so we don't request it again.\n\t\t */\n\t\tif (get_reg_resp)\n\t\t\tget_reg_resp = false;\n\n\t\tassoc_mgr_lock(&locks);\n\t\tassoc_mgr_post_tres_list(resp->tres_list);\n\t\tdebug(\"%s: slurmctld sent back %u TRES.\",\n\t\t       __func__, g_tres_count);\n\t\tassoc_mgr_unlock(&locks);\n\n\t\t/*\n\t\t * Signal any threads potentially waiting to run.\n\t\t */\n\t\tslurm_mutex_lock(&tres_mutex);\n\t\tslurm_cond_broadcast(&tres_cond);\n\t\tslurm_mutex_unlock(&tres_mutex);\n\n\t\t/* assoc_mgr_post_tres_list will destroy the list */\n\t\tresp->tres_list = NULL;\n\t}\n}\n\nextern int\nsend_registration_msg(uint32_t status, bool startup)\n{\n\tint ret_val = SLURM_SUCCESS;\n\tslurm_node_registration_status_msg_t *msg =\n\t\txmalloc (sizeof (slurm_node_registration_status_msg_t));\n\n\tif (startup)\n\t\tmsg->flags |= SLURMD_REG_FLAG_STARTUP;\n\tif (get_reg_resp)\n\t\tmsg->flags |= SLURMD_REG_FLAG_RESP;\n\n\t_fill_registration_msg(msg);\n\tmsg->status  = status;\n\n\tif (conf->msg_aggr_window_msgs > 1) {\n\t\tslurm_msg_t *req = xmalloc_nz(sizeof(slurm_msg_t));\n\n\t\tslurm_msg_t_init(req);\n\t\treq->msg_type = MESSAGE_NODE_REGISTRATION_STATUS;\n\t\treq->data     = msg;\n\n\t\tmsg_aggr_add_msg(req, 1, _handle_node_reg_resp);\n\t} else {\n\t\tslurm_msg_t req;\n\t\tslurm_msg_t resp_msg;\n\n\t\tslurm_msg_t_init(&req);\n\t\tslurm_msg_t_init(&resp_msg);\n\n\t\treq.msg_type = MESSAGE_NODE_REGISTRATION_STATUS;\n\t\treq.data     = msg;\n\n\t\tret_val = slurm_send_recv_controller_msg(&req, &resp_msg,\n\t\t\t\t\t\t\t working_cluster_rec);\n\t\tslurm_free_node_registration_status_msg(msg);\n\n\t\tif (ret_val < 0) {\n\t\t\terror(\"Unable to register: %m\");\n\t\t\tret_val = SLURM_ERROR;\n\t\t\tgoto fail;\n\t\t}\n\n\t\t_handle_node_reg_resp(&resp_msg);\n\t\tif (resp_msg.msg_type != RESPONSE_SLURM_RC) {\n\t\t\t/* RESPONSE_SLURM_RC freed by _handle_node_reg_resp() */\n\t\t\tslurm_free_msg_data(resp_msg.msg_type, resp_msg.data);\n\t\t}\n\t\tif (errno) {\n\t\t\tret_val = errno;\n\t\t\terrno = 0;\n\t\t}\n\n\t}\n\n\tif (ret_val == SLURM_SUCCESS)\n\t\tsent_reg_time = time(NULL);\nfail:\n\treturn ret_val;\n}\n\nstatic void\n_fill_registration_msg(slurm_node_registration_status_msg_t *msg)\n{\n\tList steps;\n\tListIterator i;\n\tstep_loc_t *stepd;\n\tint  n;\n\tchar *arch, *os;\n\tstruct utsname buf;\n\tstatic bool first_msg = true;\n\tstatic time_t slurmd_start_time = 0;\n\tBuf gres_info;\n\n\tmsg->node_name   = xstrdup (conf->node_name);\n\tmsg->version     = xstrdup(SLURM_VERSION_STRING);\n\n\tmsg->cpus\t = conf->cpus;\n\tmsg->boards\t = conf->boards;\n\tmsg->sockets\t = conf->sockets;\n\tmsg->cores\t = conf->cores;\n\tmsg->threads\t = conf->threads;\n\tif (res_abs_cpus[0] == '\\0')\n\t\tmsg->cpu_spec_list = NULL;\n\telse\n\t\tmsg->cpu_spec_list = xstrdup (res_abs_cpus);\n\tmsg->real_memory = conf->real_memory_size;\n\tmsg->tmp_disk    = conf->tmp_disk_space;\n\tmsg->hash_val    = slurm_get_hash_val();\n\tget_cpu_load(&msg->cpu_load);\n\tget_free_mem(&msg->free_mem);\n\n\tgres_info = init_buf(1024);\n\tif (gres_plugin_node_config_pack(gres_info) != SLURM_SUCCESS)\n\t\terror(\"error packing gres configuration\");\n\telse\n\t\tmsg->gres_info   = gres_info;\n\n\tget_up_time(&conf->up_time);\n\tmsg->up_time     = conf->up_time;\n\tif (slurmd_start_time == 0)\n\t\tslurmd_start_time = time(NULL);\n\tmsg->slurmd_start_time = slurmd_start_time;\n\n\tnode_features_g_node_state(&msg->features_avail, &msg->features_active);\n\n\tif (first_msg) {\n\t\tfirst_msg = false;\n\t\tinfo(\"CPUs=%u Boards=%u Sockets=%u Cores=%u Threads=%u \"\n\t\t     \"Memory=%\"PRIu64\" TmpDisk=%u Uptime=%u CPUSpecList=%s \"\n\t\t     \"FeaturesAvail=%s FeaturesActive=%s\",\n\t\t     msg->cpus, msg->boards, msg->sockets, msg->cores,\n\t\t     msg->threads, msg->real_memory, msg->tmp_disk,\n\t\t     msg->up_time, msg->cpu_spec_list, msg->features_avail,\n\t\t     msg->features_active);\n\t} else {\n\t\tdebug3(\"CPUs=%u Boards=%u Sockets=%u Cores=%u Threads=%u \"\n\t\t       \"Memory=%\"PRIu64\" TmpDisk=%u Uptime=%u CPUSpecList=%s \"\n\t\t       \"FeaturesAvail=%s FeaturesActive=%s\",\n\t\t       msg->cpus, msg->boards, msg->sockets, msg->cores,\n\t\t       msg->threads, msg->real_memory, msg->tmp_disk,\n\t\t       msg->up_time, msg->cpu_spec_list, msg->features_avail,\n\t\t       msg->features_active);\n\t}\n\tuname(&buf);\n\tif ((arch = getenv(\"SLURM_ARCH\")))\n\t\tmsg->arch = xstrdup(arch);\n\telse\n\t\tmsg->arch = xstrdup(buf.machine);\n\tif ((os = getenv(\"SLURM_OS\"))) {\n\t\tmsg->os   = xstrdup(os);\n\t} else {\n\t\txstrfmtcat(msg->os, \"%s %s %s\",\n\t\t\t   buf.sysname, buf.release, buf.version);\n\t}\n\n\tif (msg->flags & SLURMD_REG_FLAG_STARTUP) {\n\t\tif (switch_g_alloc_node_info(&msg->switch_nodeinfo))\n\t\t\terror(\"switch_g_alloc_node_info: %m\");\n\t\tif (switch_g_build_node_info(msg->switch_nodeinfo))\n\t\t\terror(\"switch_g_build_node_info: %m\");\n\t}\n\n\tsteps = stepd_available(conf->spooldir, conf->node_name);\n\tmsg->job_count = list_count(steps);\n\tmsg->job_id    = xmalloc(msg->job_count * sizeof(*msg->job_id));\n\t/* Note: Running batch jobs will have step_id == NO_VAL */\n\tmsg->step_id   = xmalloc(msg->job_count * sizeof(*msg->step_id));\n\n\ti = list_iterator_create(steps);\n\tn = 0;\n\twhile ((stepd = list_next(i))) {\n\t\tint fd;\n\t\tfd = stepd_connect(stepd->directory, stepd->nodename,\n\t\t\t\t   stepd->jobid, stepd->stepid,\n\t\t\t\t   &stepd->protocol_version);\n\t\tif (fd == -1) {\n\t\t\t--(msg->job_count);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (stepd_state(fd, stepd->protocol_version)\n\t\t    == SLURMSTEPD_NOT_RUNNING) {\n\t\t\tdebug(\"stale domain socket for stepd %u.%u \",\n\t\t\t      stepd->jobid, stepd->stepid);\n\t\t\t--(msg->job_count);\n\t\t\tclose(fd);\n\t\t\tcontinue;\n\t\t}\n\n\t\tclose(fd);\n\t\tif (stepd->stepid == NO_VAL) {\n\t\t\tdebug(\"%s: found apparently running job %u\",\n\t\t\t      __func__, stepd->jobid);\n\t\t} else {\n\t\t\tdebug(\"%s: found apparently running step %u.%u\",\n\t\t\t      __func__, stepd->jobid, stepd->stepid);\n\t\t}\n\t\tmsg->job_id[n]  = stepd->jobid;\n\t\tmsg->step_id[n] = stepd->stepid;\n\t\tn++;\n\t}\n\tlist_iterator_destroy(i);\n\tFREE_NULL_LIST(steps);\n\n\tif (!msg->energy)\n\t\tmsg->energy = acct_gather_energy_alloc(1);\n\tacct_gather_energy_g_get_sum(ENERGY_DATA_NODE_ENERGY, msg->energy);\n\n\tmsg->timestamp = time(NULL);\n\n\treturn;\n}\n\n/*\n * Replace first \"%h\" in path string with actual hostname.\n * Replace first \"%n\" in path string with NodeName.\n */\nstatic void\n_massage_pathname(char **path)\n{\n\tif (path && *path) {\n\t\tif (conf->hostname)\n\t\t\txstrsubstitute(*path, \"%h\", conf->hostname);\n\t\tif (conf->node_name)\n\t\t\txstrsubstitute(*path, \"%n\", conf->node_name);\n\t}\n}\n\n/*\n * Read the slurm configuration file (slurm.conf) and substitute some\n * values into the slurmd configuration in preference of the defaults.\n */\nstatic void\n_read_config(void)\n{\n\tchar *bcast_address;\n\tchar *path_pubkey = NULL;\n\tslurm_ctl_conf_t *cf = NULL;\n\tint cc;\n\tbool cgroup_mem_confinement = false;\n\n#ifndef HAVE_FRONT_END\n\tbool cr_flag = false, gang_flag = false;\n\tbool config_overrides = false;\n#endif\n\n\tslurm_mutex_lock(&conf->config_mutex);\n\tcf = slurm_conf_lock();\n\n\txfree(conf->auth_info);\n\tconf->auth_info = xstrdup(cf->authinfo);\n\n\tconf->last_update = time(NULL);\n\n\tif (conf->conffile == NULL)\n\t\tconf->conffile = xstrdup(cf->slurm_conf);\n\n\tconf->slurm_user_id =  cf->slurm_user_id;\n\n\tconf->cr_type = cf->select_type_param;\n\n\txfree(conf->gres);\n\n\tpath_pubkey = xstrdup(cf->job_credential_public_certificate);\n\n\tif (!conf->logfile)\n\t\tconf->logfile = xstrdup(cf->slurmd_logfile);\n\n#ifndef HAVE_FRONT_END\n\tif (!xstrcmp(cf->select_type, \"select/cons_res\") ||\n\t    !xstrcmp(cf->select_type, \"select/cons_tres\"))\n\t\tcr_flag = true;\n\tif (!xstrcmp(cf->select_type, \"select/cray_aries\") &&\n\t    ((cf->select_type_param & CR_OTHER_CONS_RES) ||\n\t     (cf->select_type_param & CR_OTHER_CONS_TRES)))\n\t\tcr_flag = true;\n\n\tif (cf->preempt_mode & PREEMPT_MODE_GANG)\n\t\tgang_flag = true;\n#endif\n\n\tslurm_conf_unlock();\n\t/* node_name may already be set from a command line parameter */\n\tif (conf->node_name == NULL)\n\t\tconf->node_name = slurm_conf_get_nodename(conf->hostname);\n\t/*\n\t * If we didn't match the form of the hostname already stored in\n\t * conf->hostname, check to see if we match any valid aliases\n\t */\n\tif (conf->node_name == NULL)\n\t\tconf->node_name = slurm_conf_get_aliased_nodename();\n\n\tif (conf->node_name == NULL)\n\t\tconf->node_name = slurm_conf_get_nodename(\"localhost\");\n\n\tif (conf->node_name == NULL)\n\t\tfatal(\"Unable to determine this slurmd's NodeName\");\n\n\tif ((bcast_address = slurm_conf_get_bcast_address(conf->node_name))) {\n\t\tchar *comm_params = slurm_get_comm_parameters();\n\t\tif (xstrcasestr(comm_params, \"NoInAddrAny\"))\n\t\t\tfatal(\"Cannot use BcastAddr option on this node with CommunicationParameters=NoInAddrAny\");\n\t\txfree(comm_params);\n\t\txfree(bcast_address);\n\t}\n\n\t_massage_pathname(&conf->logfile);\n\n\tconf->port = slurm_conf_get_port(conf->node_name);\n\tslurm_conf_get_cpus_bsct(conf->node_name,\n\t\t\t\t &conf->conf_cpus, &conf->conf_boards,\n\t\t\t\t &conf->conf_sockets, &conf->conf_cores,\n\t\t\t\t &conf->conf_threads);\n\n\tslurm_conf_get_res_spec_info(conf->node_name,\n\t\t\t\t     &conf->cpu_spec_list,\n\t\t\t\t     &conf->core_spec_cnt,\n\t\t\t\t     &conf->mem_spec_limit);\n\n\t/* store hardware properties in slurmd_config */\n\txfree(conf->block_map);\n\txfree(conf->block_map_inv);\n\n\t/*\n\t * This must be reset before _update_logging(), otherwise the\n\t * slurmstepd processes will not get the reconfigure request,\n\t * and logs may be lost if the path changed or the log was rotated.\n\t */\n\t_free_and_set(conf->spooldir, xstrdup(cf->slurmd_spooldir));\n\t_massage_pathname(&conf->spooldir);\n\t/*\n\t * Only rebuild this if running configless, which is indicated by\n\t * the presence of a conf_server value.\n\t */\n\tif (conf->conf_server)\n\t\t_free_and_set(conf->conf_cache,\n\t\t\t      xstrdup_printf(\"%s/conf-cache\", conf->spooldir));\n\n\t_update_logging();\n\t_update_nice();\n\n\tconf->actual_cpus = 0;\n\n\t/*\n\t * xcpuinfo_hwloc_topo_get here needs spooldir to be set before\n\t * it will work properly.  This is the earliest we can unset def_config.\n\t */\n\tconf->def_config = false;\n\txcpuinfo_hwloc_topo_get(&conf->actual_cpus,\n\t\t\t\t&conf->actual_boards,\n\t\t\t\t&conf->actual_sockets,\n\t\t\t\t&conf->actual_cores,\n\t\t\t\t&conf->actual_threads,\n\t\t\t\t&conf->block_map_size,\n\t\t\t\t&conf->block_map, &conf->block_map_inv);\n#ifdef HAVE_FRONT_END\n\t/*\n\t * When running with multiple frontends, the slurmd S:C:T values are not\n\t * relevant, hence ignored by both _register_front_ends (sets all to 1)\n\t * and validate_nodes_via_front_end (uses slurm.conf values).\n\t * Report actual hardware configuration.\n\t */\n\tconf->cpus    = conf->actual_cpus;\n\tconf->boards  = conf->actual_boards;\n\tconf->sockets = conf->actual_sockets;\n\tconf->cores   = conf->actual_cores;\n\tconf->threads = conf->actual_threads;\n#else\n\t/* If the actual resources on a node differ than what is in\n\t * the configuration file and we are using\n\t * cons_res or gang scheduling we have to use what is in the\n\t * configuration file because the slurmctld creates bitmaps\n\t * for scheduling before these nodes check in.\n\t */\n\tconfig_overrides = cf->conf_flags & CTL_CONF_OR;\n\tif (!config_overrides && (conf->actual_cpus < conf->conf_cpus)) {\n\t\tconf->cpus    = conf->actual_cpus;\n\t\tconf->boards  = conf->actual_boards;\n\t\tconf->sockets = conf->actual_sockets;\n\t\tconf->cores   = conf->actual_cores;\n\t\tconf->threads = conf->actual_threads;\n\t} else if (!config_overrides && (cr_flag || gang_flag) &&\n\t\t   (conf->actual_sockets != conf->conf_sockets) &&\n\t\t   (conf->actual_cores != conf->conf_cores) &&\n\t\t   ((conf->actual_sockets * conf->actual_cores) ==\n\t\t    (conf->conf_sockets * conf->conf_cores))) {\n\t\t/* Socket and core count can be changed when KNL node reboots\n\t\t * in a different NUMA configuration */\n\t\tinfo(\"Node reconfigured socket/core boundaries \"\n\t\t     \"SocketsPerBoard=%u:%u(hw) CoresPerSocket=%u:%u(hw)\",\n\t\t     conf->conf_sockets, conf->actual_sockets,\n\t\t     conf->conf_cores, conf->actual_cores);\n\t\tconf->cpus    = conf->conf_cpus;\n\t\tconf->boards  = conf->conf_boards;\n\t\tconf->sockets = conf->actual_sockets;\n\t\tconf->cores   = conf->actual_cores;\n\t\tconf->threads = conf->conf_threads;\n\t} else {\n\t\tconf->cpus    = conf->conf_cpus;\n\t\tconf->boards  = conf->conf_boards;\n\t\tconf->sockets = conf->conf_sockets;\n\t\tconf->cores   = conf->conf_cores;\n\t\tconf->threads = conf->conf_threads;\n\t}\n\n\tif ((conf->cpus    != conf->actual_cpus)    ||\n\t    (conf->sockets != conf->actual_sockets) ||\n\t    (conf->cores   != conf->actual_cores)   ||\n\t    (conf->threads != conf->actual_threads)) {\n\t\tlog_var(config_overrides ? LOG_LEVEL_INFO : LOG_LEVEL_ERROR,\n\t\t\t\"Node configuration differs from hardware: CPUs=%u:%u(hw) Boards=%u:%u(hw) SocketsPerBoard=%u:%u(hw) CoresPerSocket=%u:%u(hw) ThreadsPerCore=%u:%u(hw)\",\n\t\t\tconf->cpus,    conf->actual_cpus,\n\t\t\tconf->boards,  conf->actual_boards,\n\t\t\tconf->sockets, conf->actual_sockets,\n\t\t\tconf->cores,   conf->actual_cores,\n\t\t\tconf->threads, conf->actual_threads);\n\t}\n#endif\n\n\tget_memory(&conf->real_memory_size);\n\tget_up_time(&conf->up_time);\n\n\tcf = slurm_conf_lock();\n\tget_tmp_disk(&conf->tmp_disk_space, cf->tmp_fs);\n\t_free_and_set(conf->cluster_name, xstrdup(cf->cluster_name));\n\t_free_and_set(conf->epilog,   xstrdup(cf->epilog));\n\t_free_and_set(conf->prolog,   xstrdup(cf->prolog));\n\t_free_and_set(conf->tmpfs,    xstrdup(cf->tmp_fs));\n\t_free_and_set(conf->health_check_program,\n\t\t      xstrdup(cf->health_check_program));\n\t_free_and_set(conf->pidfile,  xstrdup(cf->slurmd_pidfile));\n\t_massage_pathname(&conf->pidfile);\n\t_free_and_set(conf->plugstack,   xstrdup(cf->plugstack));\n\t_free_and_set(conf->select_type, xstrdup(cf->select_type));\n\t_free_and_set(conf->task_prolog, xstrdup(cf->task_prolog));\n\t_free_and_set(conf->task_epilog, xstrdup(cf->task_epilog));\n\t_free_and_set(conf->pubkey,   path_pubkey);\n\t_free_and_set(conf->x11_params, xstrdup(cf->x11_params));\n\n\tconf->debug_flags = cf->debug_flags;\n\tconf->syslog_debug = cf->slurmd_syslog_debug;\n\tconf->propagate_prio = cf->propagate_prio_process;\n\n\t_free_and_set(conf->job_acct_gather_freq,\n\t\t      xstrdup(cf->job_acct_gather_freq));\n\n\tconf->acct_freq_task = NO_VAL16;\n\tcc = acct_gather_parse_freq(PROFILE_TASK,\n\t\t\t\t    conf->job_acct_gather_freq);\n\tif (cc != -1)\n\t\tconf->acct_freq_task = cc;\n\n\t_free_and_set(conf->acct_gather_energy_type,\n\t\t      xstrdup(cf->acct_gather_energy_type));\n\t_free_and_set(conf->acct_gather_filesystem_type,\n\t\t      xstrdup(cf->acct_gather_filesystem_type));\n\t_free_and_set(conf->acct_gather_interconnect_type,\n\t\t      xstrdup(cf->acct_gather_interconnect_type));\n\t_free_and_set(conf->acct_gather_profile_type,\n\t\t      xstrdup(cf->acct_gather_profile_type));\n\t_free_and_set(conf->job_acct_gather_type,\n\t\t      xstrdup(cf->job_acct_gather_type));\n\t_free_and_set(conf->msg_aggr_params,\n\t\t      xstrdup(cf->msg_aggr_params));\n\t_set_msg_aggr_params();\n\n\tif ( (conf->node_name == NULL) ||\n\t     (conf->node_name[0] == '\\0') )\n\t\tfatal(\"Node name lookup failure\");\n\n\tif (cf->control_addr == NULL)\n\t\tfatal(\"Unable to establish controller machine\");\n\tif (cf->slurmctld_port == 0)\n\t\tfatal(\"Unable to establish controller port\");\n\tconf->slurmd_timeout = cf->slurmd_timeout;\n\tconf->kill_wait = cf->kill_wait;\n\tconf->use_pam = cf->conf_flags & CTL_CONF_PAM;\n\tconf->task_plugin_param = cf->task_plugin_param;\n\tconf->health_check_interval = cf->health_check_interval;\n\tconf->job_acct_oom_kill = cf->job_acct_oom_kill;\n\n\tslurm_mutex_unlock(&conf->config_mutex);\n\n\tslurm_conf_unlock();\n\n\tcgroup_mem_confinement = xcgroup_mem_cgroup_job_confinement();\n\tif (slurmctld_conf.job_acct_oom_kill && cgroup_mem_confinement)\n\t\tfatal(\"Jobs memory is being constrained by both TaskPlugin cgroup and JobAcctGather plugin. This enables two incompatible memory enforcement mechanisms, one of them must be disabled.\");\n}\n\n/*\n * Build a slurmd configuration buffer _once_ for sending to slurmstepd\n * This must happen after all configuration is available, including topology\n */\nstatic void _build_conf_buf(void)\n{\n\tslurm_mutex_lock(&conf->config_mutex);\n\tFREE_NULL_BUFFER(conf->buf);\n\tconf->buf = init_buf(0);\n\tpack_slurmd_conf_lite(conf, conf->buf);\n\tif (assoc_mgr_tres_list) {\n\t\tassoc_mgr_lock_t locks = { .tres = READ_LOCK };\n\t\tassoc_mgr_lock(&locks);\n\t\tslurm_pack_list(assoc_mgr_tres_list,\n\t\t\t\tslurmdb_pack_tres_rec, conf->buf,\n\t\t\t\tSLURM_PROTOCOL_VERSION);\n\t\tassoc_mgr_unlock(&locks);\n\t\ttres_packed = true;\n\t} else\n\t\ttres_packed = false;\n\n\tslurm_mutex_unlock(&conf->config_mutex);\n}\n\nstatic void\n_reconfigure(void)\n{\n\tuint32_t cpu_cnt;\n\tnode_record_t *node_rec;\n\tList gres_list = NULL;\n\n\t_reconfig = 0;\n\tslurm_conf_reinit(conf->conffile);\n\txcgroup_reconfig_slurm_cgroup_conf();\n\t_read_config();\n\n\t/*\n\t * Rebuild topology information and refresh slurmd topo infos\n\t */\n\tslurm_topo_build_config();\n\t_set_topo_info();\n\troute_g_reconfigure();\n\tcpu_freq_reconfig();\n\n\tmsg_aggr_sender_reconfig(conf->msg_aggr_window_time,\n\t\t\t\t conf->msg_aggr_window_msgs);\n\n\t/*\n\t * In case the administrator changed the cpu frequency set capabilities\n\t * on this node, rebuild the cpu frequency table information\n\t */\n\tcpu_freq_init(conf);\n\n\t/*\n\t * If configured, apply resource specialization\n\t */\n\t_resource_spec_init();\n\n\t_print_conf();\n\n\t/*\n\t * Make best effort at changing to new public key\n\t */\n\tslurm_cred_ctx_key_update(conf->vctx, conf->pubkey);\n\n\t/*\n\t * Purge the username -> grouplist cache.\n\t */\n\tgroup_cache_purge();\n\n\tgres_plugin_reconfig();\n\t(void) switch_g_reconfig();\n\tcontainer_g_reconfig();\n\tprep_plugin_reconfig();\n\tcpu_cnt = MAX(conf->conf_cpus, conf->block_map_size);\n\n\tinit_node_conf();\n\tbuild_all_nodeline_info(true, 0);\n\tbuild_all_frontend_info(true);\n\tnode_rec = find_node_record2(conf->node_name);\n\tif (node_rec && node_rec->config_ptr) {\n\t\t(void) gres_plugin_init_node_config(conf->node_name,\n\t\t\t\t\t\t    node_rec->config_ptr->gres,\n\t\t\t\t\t\t    &gres_list);\n\n\t\t/* Send the slurm.conf GRES to the stepd */\n\t\tconf->gres = xstrdup(node_rec->config_ptr->gres);\n\t}\n\t(void) gres_plugin_node_config_load(cpu_cnt, conf->node_name, gres_list,\n\t\t\t\t\t    NULL, (void *)&xcpuinfo_mac_to_abs);\n\tFREE_NULL_LIST(gres_list);\n\n\t_build_conf_buf();\n\n\tsend_registration_msg(SLURM_SUCCESS, false);\n\n\tacct_gather_reconfig();\n\n\t/* reconfigure energy */\n\tacct_gather_energy_g_set_data(ENERGY_DATA_RECONFIG, NULL);\n\n\t/*\n\t * XXX: reopen slurmd port?\n\t */\n}\n\nstatic void\n_print_conf(void)\n{\n\tslurm_ctl_conf_t *cf;\n\tchar *str = NULL, time_str[32];\n\tint i;\n\n\tif (conf->log_opts.stderr_level < LOG_LEVEL_DEBUG3)\n\t\treturn;\n\n\tcf = slurm_conf_lock();\n\tdebug3(\"NodeName    = %s\",       conf->node_name);\n\tdebug3(\"TopoAddr    = %s\",       conf->node_topo_addr);\n\tdebug3(\"TopoPattern = %s\",       conf->node_topo_pattern);\n\tdebug3(\"ClusterName = %s\",       conf->cluster_name);\n\tdebug3(\"Confile     = `%s'\",     conf->conffile);\n\tdebug3(\"Debug       = %d\",       cf->slurmd_debug);\n\tdebug3(\"CPUs        = %-2u (CF: %2u, HW: %2u)\",\n\t       conf->cpus,\n\t       conf->conf_cpus,\n\t       conf->actual_cpus);\n\tdebug3(\"Boards      = %-2u (CF: %2u, HW: %2u)\",\n\t       conf->boards,\n\t       conf->conf_boards,\n\t       conf->actual_boards);\n\tdebug3(\"Sockets     = %-2u (CF: %2u, HW: %2u)\",\n\t       conf->sockets,\n\t       conf->conf_sockets,\n\t       conf->actual_sockets);\n\tdebug3(\"Cores       = %-2u (CF: %2u, HW: %2u)\",\n\t       conf->cores,\n\t       conf->conf_cores,\n\t       conf->actual_cores);\n\tdebug3(\"Threads     = %-2u (CF: %2u, HW: %2u)\",\n\t       conf->threads,\n\t       conf->conf_threads,\n\t       conf->actual_threads);\n\n\tsecs2time_str((time_t)conf->up_time, time_str, sizeof(time_str));\n\tdebug3(\"UpTime      = %u = %s\", conf->up_time, time_str);\n\n\tfor (i = 0; i < conf->block_map_size; i++)\n\t\txstrfmtcat(str, \"%s%u\", (str ? \",\" : \"\"),\n\t\t\t   conf->block_map[i]);\n\tdebug3(\"Block Map   = %s\", str);\n\txfree(str);\n\tfor (i = 0; i < conf->block_map_size; i++)\n\t\txstrfmtcat(str, \"%s%u\", (str ? \",\" : \"\"),\n\t\t\t   conf->block_map_inv[i]);\n\tdebug3(\"Inverse Map = %s\", str);\n\txfree(str);\n\n\tdebug3(\"RealMemory  = %\"PRIu64\"\",conf->real_memory_size);\n\tdebug3(\"TmpDisk     = %u\",       conf->tmp_disk_space);\n\tdebug3(\"Epilog      = `%s'\",     conf->epilog);\n\tdebug3(\"Logfile     = `%s'\",     cf->slurmd_logfile);\n\tdebug3(\"HealthCheck = `%s'\",     conf->health_check_program);\n\tdebug3(\"NodeName    = %s\",       conf->node_name);\n\tdebug3(\"Port        = %u\",       conf->port);\n\tdebug3(\"Prolog      = `%s'\",     conf->prolog);\n\tdebug3(\"TmpFS       = `%s'\",     conf->tmpfs);\n\tdebug3(\"Public Cert = `%s'\",     conf->pubkey);\n\tdebug3(\"Slurmstepd  = `%s'\",     conf->stepd_loc);\n\tdebug3(\"Spool Dir   = `%s'\",     conf->spooldir);\n\tdebug3(\"Syslog Debug  = %d\",     cf->slurmd_syslog_debug);\n\tdebug3(\"Pid File    = `%s'\",     conf->pidfile);\n\tdebug3(\"Slurm UID   = %u\",       conf->slurm_user_id);\n\tdebug3(\"TaskProlog  = `%s'\",     conf->task_prolog);\n\tdebug3(\"TaskEpilog  = `%s'\",     conf->task_epilog);\n\tdebug3(\"TaskPluginParam = %u\",   conf->task_plugin_param);\n\tdebug3(\"Use PAM     = %u\",       conf->use_pam);\n\tslurm_conf_unlock();\n}\n\n/* Initialize slurmd configuration table.\n * Everything is already NULL/zero filled when called */\nstatic void\n_init_conf(void)\n{\n\tchar  host[MAXHOSTNAMELEN];\n\tlog_options_t lopts = LOG_OPTS_INITIALIZER;\n\n\tif (gethostname_short(host, MAXHOSTNAMELEN) < 0) {\n\t\terror(\"Unable to get my hostname: %m\");\n\t\texit(1);\n\t}\n\tconf->hostname    = xstrdup(host);\n\tconf->daemonize   =  1;\n\tconf->def_config  =  true;\n\tconf->lfd         = -1;\n\tconf->log_opts    = lopts;\n\tconf->debug_level = LOG_LEVEL_INFO;\n\tconf->pidfile     = xstrdup(DEFAULT_SLURMD_PIDFILE);\n\tconf->spooldir\t  = xstrdup(DEFAULT_SPOOLDIR);\n\tconf->print_gres   = false;\n\n\tslurm_mutex_init(&conf->config_mutex);\n\n\tconf->starting_steps = list_create(xfree_ptr);\n\tslurm_cond_init(&conf->starting_steps_cond, NULL);\n\tconf->prolog_running_jobs = list_create(xfree_ptr);\n\tslurm_cond_init(&conf->prolog_running_cond, NULL);\n\treturn;\n}\n\nstatic void\n_destroy_conf(void)\n{\n\tif (conf) {\n\t\txfree(conf->acct_gather_energy_type);\n\t\txfree(conf->acct_gather_filesystem_type);\n\t\txfree(conf->acct_gather_interconnect_type);\n\t\txfree(conf->acct_gather_profile_type);\n\t\txfree(conf->auth_info);\n\t\txfree(conf->block_map);\n\t\txfree(conf->block_map_inv);\n\t\tFREE_NULL_BUFFER(conf->buf);\n\t\txfree(conf->cluster_name);\n\t\txfree(conf->conffile);\n\t\txfree(conf->conf_server);\n\t\txfree(conf->conf_cache);\n\t\txfree(conf->cpu_spec_list);\n\t\txfree(conf->epilog);\n\t\txfree(conf->health_check_program);\n\t\txfree(conf->hostname);\n\t\tif (conf->hwloc_xml) {\n\t\t\t/*\n\t\t\t * When a slurmd is taking over the place of the next\n\t\t\t * slurmd it will have already made this file.  So don't\n\t\t\t * remove it or it will remove it for the new slurmd.\n\t\t\t */\n\t\t\t/* (void)remove(conf->hwloc_xml); */\n\t\t\txfree(conf->hwloc_xml);\n\t\t}\n\t\txfree(conf->job_acct_gather_freq);\n\t\txfree(conf->job_acct_gather_type);\n\t\txfree(conf->logfile);\n\t\txfree(conf->msg_aggr_params);\n\t\txfree(conf->node_name);\n\t\txfree(conf->node_topo_addr);\n\t\txfree(conf->node_topo_pattern);\n\t\txfree(conf->pidfile);\n\t\txfree(conf->plugstack);\n\t\txfree(conf->prolog);\n\t\txfree(conf->pubkey);\n\t\txfree(conf->select_type);\n\t\txfree(conf->spooldir);\n\t\txfree(conf->stepd_loc);\n\t\txfree(conf->task_prolog);\n\t\txfree(conf->task_epilog);\n\t\txfree(conf->tmpfs);\n\t\txfree(conf->x11_params);\n\t\txfree(conf->gres);\n\t\tslurm_mutex_destroy(&conf->config_mutex);\n\t\tFREE_NULL_LIST(conf->starting_steps);\n\t\tslurm_cond_destroy(&conf->starting_steps_cond);\n\t\tFREE_NULL_LIST(conf->prolog_running_jobs);\n\t\tslurm_cond_destroy(&conf->prolog_running_cond);\n\t\tslurm_cred_ctx_destroy(conf->vctx);\n\t\txfree(conf);\n\t}\n\treturn;\n}\n\nstatic void\n_print_config(void)\n{\n\tint days, hours, mins, secs;\n\tchar name[128];\n\n\tgethostname_short(name, sizeof(name));\n\tprintf(\"NodeName=%s \", name);\n\n\txcpuinfo_hwloc_topo_get(&conf->actual_cpus,\n\t\t\t\t&conf->actual_boards,\n\t\t\t\t&conf->actual_sockets,\n\t\t\t\t&conf->actual_cores,\n\t\t\t\t&conf->actual_threads,\n\t\t\t\t&conf->block_map_size,\n\t\t\t\t&conf->block_map, &conf->block_map_inv);\n\tprintf(\"CPUs=%u Boards=%u SocketsPerBoard=%u CoresPerSocket=%u \"\n\t       \"ThreadsPerCore=%u \",\n\t       conf->actual_cpus, conf->actual_boards, conf->actual_sockets,\n\t       conf->actual_cores, conf->actual_threads);\n\n\tget_memory(&conf->real_memory_size);\n\tprintf(\"RealMemory=%\"PRIu64\"\\n\", conf->real_memory_size);\n\n\tget_up_time(&conf->up_time);\n\tsecs  =  conf->up_time % 60;\n\tmins  = (conf->up_time / 60) % 60;\n\thours = (conf->up_time / 3600) % 24;\n\tdays  = (conf->up_time / 86400);\n\tprintf(\"UpTime=%u-%2.2u:%2.2u:%2.2u\\n\", days, hours, mins, secs);\n}\n\nstatic void _print_gres(void)\n{\n\tList gres_list = NULL;\n\tstruct node_record *node_rec = NULL;\n\tlog_options_t *o = &conf->log_opts;\n\n\to->logfile_level = LOG_LEVEL_QUIET;\n\to->stderr_level = LOG_LEVEL_INFO;\n\to->syslog_level = LOG_LEVEL_INFO;\n\to->prefix_level = false;\n\tlog_alter(conf->log_opts, SYSLOG_FACILITY_USER, NULL);\n\tnode_rec = find_node_record(conf->node_name);\n\n\tif (node_rec && node_rec->config_ptr) {\n\t\tgres_plugin_init_node_config(conf->node_name,\n\t\t\t\t\t     node_rec->config_ptr->gres,\n\t\t\t\t\t     &gres_list);\n\n\t\tgres_plugin_node_config_load(1024, /*Do not need real #CPU*/\n\t\t\t\t\t     conf->node_name, gres_list, NULL,\n\t\t\t\t\t     (void *)&xcpuinfo_mac_to_abs);\n\t\tFREE_NULL_LIST(gres_list);\n\t} else {\n\t\tfatal(\"Unable to find node record for node:%s\",\n\t\t      conf->node_name);\n\t}\n\n\texit(0);\n}\n\nstatic void\n_process_cmdline(int ac, char **av)\n{\n\tstatic char *opt_string = \"bcCd:Df:GhL:Mn:N:vV\";\n\tint c;\n\tchar *tmp_char;\n\n\tenum {\n\t\tLONG_OPT_ENUM_START = 0x100,\n\t\tLONG_OPT_CONF_SERVER,\n\t};\n\n\tstatic struct option long_options[] = {\n\t\t{\"conf-server\",\t\trequired_argument, 0, LONG_OPT_CONF_SERVER},\n\t\t{\"version\",\t\tno_argument,       0, 'V'},\n\t\t{NULL,\t\t\t0,                 0, 0}\n\t};\n\n\tconf->prog = xbasename(av[0]);\n\n\twhile ((c = getopt_long(ac, av, opt_string, long_options, NULL)) > 0) {\n\t\tswitch (c) {\n\t\tcase 'b':\n\t\t\tconf->boot_time = 1;\n\t\t\tbreak;\n\t\tcase 'c':\n\t\t\tconf->cleanstart = 1;\n\t\t\tbreak;\n\t\tcase 'C':\n\t\t\t_print_config();\n\t\t\texit(0);\n\t\t\tbreak;\n\t\tcase 'd':\n\t\t\txfree(conf->stepd_loc);\n\t\t\tconf->stepd_loc = xstrdup(optarg);\n\t\t\tbreak;\n\t\tcase 'D':\n\t\t\tconf->daemonize = 0;\n\t\t\tbreak;\n\t\tcase 'f':\n\t\t\txfree(conf->conffile);\n\t\t\tconf->conffile = xstrdup(optarg);\n\t\t\tbreak;\n\t\tcase 'G':\n\t\t\tconf->print_gres = true;\n\t\t\tbreak;\n\t\tcase 'h':\n\t\t\t_usage();\n\t\t\texit(0);\n\t\t\tbreak;\n\t\tcase 'L':\n\t\t\txfree(conf->logfile);\n\t\t\tconf->logfile = xstrdup(optarg);\n\t\t\tbreak;\n\t\tcase 'M':\n\t\t\tconf->mlock_pages = 1;\n\t\t\tbreak;\n\t\tcase 'n':\n\t\t\tconf->nice = strtol(optarg, &tmp_char, 10);\n\t\t\tif (tmp_char[0] != '\\0') {\n\t\t\t\terror(\"Invalid option for -n option (nice value), ignored\");\n\t\t\t\tconf->nice = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 'N':\n\t\t\txfree(conf->node_name);\n\t\t\tconf->node_name = xstrdup(optarg);\n\t\t\tbreak;\n\t\tcase 'v':\n\t\t\tconf->debug_level++;\n\t\t\tconf->debug_level_set = 1;\n\t\t\tbreak;\n\t\tcase 'V':\n\t\t\tprint_slurm_version();\n\t\t\texit(0);\n\t\t\tbreak;\n\t\tcase LONG_OPT_CONF_SERVER:\n\t\t\tconf->conf_server = xstrdup(optarg);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\t_usage();\n\t\t\texit(1);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t/*\n\t *  If slurmstepd path wasn't overridden by command line, set\n\t *  it to the default here:\n\t */\n\tif (!conf->stepd_loc)\n\t\tconf->stepd_loc = slurm_get_stepd_loc();\n}\n\n\nstatic void\n_create_msg_socket(void)\n{\n\tint ld = slurm_init_msg_engine_port(conf->port);\n\n\tif (ld < 0) {\n\t\terror(\"Unable to bind listen port (%u): %m\",\n\t\t      conf->port);\n\t\texit(1);\n\t}\n\n\tfd_set_close_on_exec(ld);\n\n\tconf->lfd = ld;\n\n\tdebug3(\"Successfully opened slurm listen port %u\", conf->port);\n\n\treturn;\n}\n\nstatic void\n_stepd_cleanup_batch_dirs(const char *directory, const char *nodename)\n{\n\tDIR *dp;\n\tstruct dirent *ent;\n\tstruct stat stat_buf;\n\n\t/*\n\t * Make sure that \"directory\" exists and is a directory.\n\t */\n\tif (stat(directory, &stat_buf) < 0) {\n\t\terror(\"SlurmdSpoolDir stat error %s: %m\", directory);\n\t\treturn;\n\t} else if (!S_ISDIR(stat_buf.st_mode)) {\n\t\terror(\"SlurmdSpoolDir is not a directory %s\", directory);\n\t\treturn;\n\t}\n\n\tif ((dp = opendir(directory)) == NULL) {\n\t\terror(\"SlurmdSpoolDir open error %s: %m\", directory);\n\t\treturn;\n\t}\n\n\twhile ((ent = readdir(dp)) != NULL) {\n\t\tif (!xstrncmp(ent->d_name, \"job\", 3) &&\n\t\t    (ent->d_name[3] >= '0') && (ent->d_name[3] <= '9')) {\n\t\t\tchar *dir_path = NULL, *file_path = NULL;\n\t\t\txstrfmtcat(dir_path, \"%s/%s\", directory, ent->d_name);\n\t\t\txstrfmtcat(file_path, \"%s/slurm_script\", dir_path);\n\t\t\tinfo(\"%s: Purging vestigial job script %s\",\n\t\t\t     __func__, file_path);\n\t\t\t(void) unlink(file_path);\n\t\t\t(void) rmdir(dir_path);\n\t\t\txfree(dir_path);\n\t\t\txfree(file_path);\n\t\t}\n\t}\n\tclosedir(dp);\n}\n\n/*\n * See precedence rules before in comment for _establish_configuration().\n */\nstatic bool _slurm_conf_file_exists(void)\n{\n\tstruct stat stat_buf;\n\n\tif (conf->conffile)\n\t\treturn true;\n\tif ((conf->conffile = xstrdup(getenv(\"SLURM_CONF\"))))\n\t\treturn true;\n\n\tif (!stat(default_slurm_config_file, &stat_buf)) {\n\t\tconf->conffile = xstrdup(default_slurm_config_file);\n\t\treturn true;\n\t}\n\n\treturn false;\n}\n\n/*\n * Create /run/slurm/ if it does not exist, and add a symlink from\n * /run/slurm/conf to the conf-cache directory.\n *\n * User commands will test this if they've been unsuccessful locating\n * an alternate config.\n *\n * In the future we may disable this with a setting in SlurmdParameters,\n * but at the moment you would need to have enabled configless mode which\n * implies you are probably okay with this.\n *\n * It is not considered a critical error if this does not work on your system,\n * thus the minimized error handling.\n *\n * No attempt is made to deal with multiple-slurmd mode. Last slurmd started\n * will win.\n */\nstatic void _handle_slash_run(void)\n{\n\tif (_set_slurmd_spooldir(\"/run/slurm\") < 0) {\n\t\terror(\"Unable to create /run/slurm dir\");\n\t\treturn;\n\t}\n\n\t(void) unlink(\"/run/slurm/conf\");\n\n\tif (symlink(conf->conf_cache, \"/run/slurm/conf\"))\n\t\terror(\"Unable to create /run/slurm/conf symlink: %m\");\n}\n\n/*\n * Configuration precedence rules for slurmd:\n * 1. conf_server if set\n * 2. SLURM_CONF_SERVER if set (not documented, meant for testing only)\n * 3. direct file\n *   a. conffile (-f option) if not NULL\n *   b. SLURM_CONF if not NULL\n *   c. default_slurm_config_file if it exists\n * 4. DNS SRV records if available\n */\nstatic int _establish_configuration(void)\n{\n\tconfig_response_msg_t *configs;\n\n\tif (!conf->conf_server && _slurm_conf_file_exists()) {\n\t\tdebug(\"%s: config will load from file\", __func__);\n\t\tslurm_conf_init(conf->conffile);\n\t\treturn SLURM_SUCCESS;\n\t}\n\n\tif (!(configs = fetch_config(conf->conf_server,\n\t\t\t\t     CONFIG_REQUEST_SLURMD))) {\n\t\terror(\"%s: failed to load configs\", __func__);\n\t\treturn SLURM_ERROR;\n\t}\n\n\tconf->spooldir = configs->slurmd_spooldir;\n\tconfigs->slurmd_spooldir = NULL;\n\t/*\n\t * One limitation - if node_name was not set through -N\n\t * the %n replacement here will not be possible since we can't\n\t * load the node tables yet.\n\t */\n\t_massage_pathname(&conf->spooldir);\n\tif (_set_slurmd_spooldir(conf->spooldir) < 0) {\n\t\terror(\"Unable to initialize slurmd spooldir\");\n\t\treturn SLURM_ERROR;\n\t}\n\n\txfree(conf->conf_cache);\n\txstrfmtcat(conf->conf_cache, \"%s/conf-cache\", conf->spooldir);\n\tif (_set_slurmd_spooldir(conf->conf_cache) < 0) {\n\t\terror(\"Unable to initialize slurmd conf-cache dir\");\n\t\treturn SLURM_ERROR;\n\t}\n\n\tif (write_configs_to_conf_cache(configs, conf->conf_cache))\n\t\treturn SLURM_ERROR;\n\n\tslurm_free_config_response_msg(configs);\n\txfree(conf->conffile);\n\txstrfmtcat(conf->conffile, \"%s/slurm.conf\", conf->conf_cache);\n\n\t/*\n\t * Be sure to force this in the environment as get_extra_conf_path()\n\t * will pull from there. Not setting it means the plugins may fail\n\t * to load their own configs... which may not cause problems for\n\t * slurmd but will cause slurmstepd to fail later on.\n\t */\n\tsetenv(\"SLURM_CONF\", conf->conffile, 1);\n\n\t_handle_slash_run();\n\n\treturn SLURM_SUCCESS;\n}\n\nstatic int\n_slurmd_init(void)\n{\n\tstruct rlimit rlim;\n\tstruct stat stat_buf;\n\tuint32_t cpu_cnt;\n\tnode_record_t *node_rec;\n\tList gres_list = NULL;\n\tint rc;\n\n\t/*\n\t * Process commandline arguments first, since one option may be\n\t * an alternate location for the slurm config file.\n\t */\n\t_process_cmdline(*conf->argc, *conf->argv);\n\n\t/*\n\t * Work out how this node is going to be configured. If running in\n\t * \"configless\" mode, also populate the conf-cache directory.\n\t */\n\tif (_establish_configuration())\n\t\treturn SLURM_ERROR;\n\n\t/*\n\t * Build nodes table like in slurmctld\n\t * This is required by the topology stack\n\t * Node tables setup must precede _read_config() so that the\n\t * proper hostname is set.\n\t */\n\tslurm_conf_init(conf->conffile);\n\tinit_node_conf();\n\n\tif (slurm_select_init(1) != SLURM_SUCCESS)\n\t\treturn SLURM_ERROR;\n\tif (conf->print_gres)\n\t\tslurm_set_debug_flags(DEBUG_FLAG_GRES);\n\tif (gres_plugin_init() != SLURM_SUCCESS)\n\t\treturn SLURM_ERROR;\n\tbuild_all_nodeline_info(true, 0);\n\tbuild_all_frontend_info(true);\n\n\t/*\n\t * Read global slurm config file, override necessary values from\n\t * defaults and command line.\n\t */\n\t_read_config();\n\n\t/*\n\t * slurmd -G, calling it here rather than from _process_cmdline\n\t * since it relies on gres_plugin_init and _read_config.\n\t */\n\tif (conf->print_gres)\n\t\t_print_gres();\n\n\t/*\n\t * Make sure all further plugin init() calls see this value to ensure\n\t * they read from the correct directory, and that the slurmstepd\n\t * picks up the correct configuration when fork()'d.\n\t * Required for correct operation of the -f flag.\n\t */\n\tsetenv(\"SLURM_CONF\", conf->conffile, 1);\n\n\t/*\n\t * Create slurmd spool directory if necessary.\n\t */\n\tif (_set_slurmd_spooldir(conf->spooldir) < 0) {\n\t\terror(\"Unable to initialize slurmd spooldir\");\n\t\treturn SLURM_ERROR;\n\t}\n\n\t/* Set up the hwloc whole system xml file */\n\tif (xcpuinfo_init() != XCPUINFO_SUCCESS)\n\t\treturn SLURM_ERROR;\n\n\tfini_job_cnt = cpu_cnt = MAX(conf->conf_cpus, conf->block_map_size);\n\tfini_job_id = xmalloc(sizeof(uint32_t) * fini_job_cnt);\n\tnode_rec = find_node_record2(conf->node_name);\n\tif (node_rec && node_rec->config_ptr) {\n\t\t(void) gres_plugin_init_node_config(conf->node_name,\n\t\t\t\t\t\t    node_rec->config_ptr->gres,\n\t\t\t\t\t\t    &gres_list);\n\t\t/* Send the slurm.conf GRES to the stepd */\n\t\tconf->gres = xstrdup(node_rec->config_ptr->gres);\n\t}\n\trc = gres_plugin_node_config_load(cpu_cnt, conf->node_name, gres_list,\n\t\t\t\t\t  NULL, (void *)&xcpuinfo_mac_to_abs);\n\tFREE_NULL_LIST(gres_list);\n\tif (rc != SLURM_SUCCESS)\n\t\treturn SLURM_ERROR;\n\tif (slurm_topo_init() != SLURM_SUCCESS)\n\t\treturn SLURM_ERROR;\n\n\t/*\n\t * Get and set slurmd topology information\n\t * Build node hash table first to speed up the topo build\n\t */\n\trehash_node();\n\tslurm_topo_build_config();\n\t_set_topo_info();\n\t_build_conf_buf();\n\troute_init(conf->node_name);\n\n\t/*\n\t * Check for cpu frequency set capabilities on this node\n\t */\n\tcpu_freq_init(conf);\n\n\t/*\n\t * If configured, apply resource specialization\n\t */\n\t_resource_spec_init();\n\n\t_print_conf();\n\n\tif (slurm_proctrack_init() != SLURM_SUCCESS)\n\t\treturn SLURM_ERROR;\n\tif (slurmd_task_init() != SLURM_SUCCESS)\n\t\treturn SLURM_ERROR;\n\tif (slurm_auth_init(NULL) != SLURM_SUCCESS)\n\t\treturn SLURM_ERROR;\n\tif (spank_slurmd_init() < 0)\n\t\treturn SLURM_ERROR;\n\n\tif (getrlimit(RLIMIT_CPU, &rlim) == 0) {\n\t\trlim.rlim_cur = rlim.rlim_max;\n\t\tsetrlimit(RLIMIT_CPU, &rlim);\n\t\tif (rlim.rlim_max != RLIM_INFINITY) {\n\t\t\terror(\"Slurmd process CPU time limit is %d seconds\",\n\t\t\t      (int) rlim.rlim_max);\n\t\t}\n\t}\n\n\tif (getrlimit(RLIMIT_CORE, &rlim) == 0) {\n\t\trlim.rlim_cur = rlim.rlim_max;\n\t\tsetrlimit(RLIMIT_CORE, &rlim);\n\t}\n\n\trlimits_maximize_nofile();\n\n\t/*\n\t * Create a context for verifying slurm job credentials\n\t */\n\tif (!(conf->vctx = slurm_cred_verifier_ctx_create(conf->pubkey)))\n\t\treturn SLURM_ERROR;\n\n\tif (conf->cleanstart) {\n\t\t/*\n\t\t * Need to kill any running slurmd's here\n\t\t */\n\t\t_kill_old_slurmd();\n\n\t\tstepd_cleanup_sockets(conf->spooldir, conf->node_name);\n\t\t_stepd_cleanup_batch_dirs(conf->spooldir, conf->node_name);\n\t}\n\n\tif (conf->daemonize) {\n\t\tbool success = false;\n\n\t\tif (conf->logfile && (conf->logfile[0] == '/')) {\n\t\t\tchar *slash_ptr, *work_dir;\n\t\t\twork_dir = xstrdup(conf->logfile);\n\t\t\tslash_ptr = strrchr(work_dir, '/');\n\t\t\tif (slash_ptr == work_dir)\n\t\t\t\twork_dir[1] = '\\0';\n\t\t\telse\n\t\t\t\tslash_ptr[0] = '\\0';\n\t\t\tif ((access(work_dir, W_OK) != 0) ||\n\t\t\t    (chdir(work_dir) < 0)) {\n\t\t\t\terror(\"Unable to chdir to %s\", work_dir);\n\t\t\t} else\n\t\t\t\tsuccess = true;\n\t\t\txfree(work_dir);\n\t\t}\n\n\t\tif (!success) {\n\t\t\tif ((access(conf->spooldir, W_OK) != 0) ||\n\t\t\t    (chdir(conf->spooldir) < 0)) {\n\t\t\t\terror(\"Unable to chdir to %s\", conf->spooldir);\n\t\t\t} else\n\t\t\t\tsuccess = true;\n\t\t}\n\n\t\tif (!success) {\n\t\t\tif ((access(\"/var/tmp\", W_OK) != 0) ||\n\t\t\t    (chdir(\"/var/tmp\") < 0)) {\n\t\t\t\terror(\"chdir(/var/tmp): %m\");\n\t\t\t\treturn SLURM_ERROR;\n\t\t\t} else\n\t\t\t\tinfo(\"chdir to /var/tmp\");\n\t\t}\n\t}\n\n\tif ((devnull = open(\"/dev/null\", O_RDWR | O_CLOEXEC)) < 0) {\n\t\terror(\"Unable to open /dev/null: %m\");\n\t\treturn SLURM_ERROR;\n\t}\n\n\t/* make sure we have slurmstepd installed */\n\tif (stat(conf->stepd_loc, &stat_buf))\n\t\tfatal(\"Unable to find slurmstepd file at %s\", conf->stepd_loc);\n\tif (!S_ISREG(stat_buf.st_mode))\n\t\tfatal(\"slurmstepd not a file at %s\", conf->stepd_loc);\n\n\treturn SLURM_SUCCESS;\n}\n\nstatic int\n_restore_cred_state(slurm_cred_ctx_t ctx)\n{\n\tchar *file_name = NULL, *data = NULL;\n\tuint32_t data_offset = 0;\n\tint cred_fd, data_allocated, data_read = 0;\n\tBuf buffer = NULL;\n\n\tif ( (mkdir(conf->spooldir, 0755) < 0) && (errno != EEXIST) ) {\n\t\tfatal(\"mkdir(%s): %m\", conf->spooldir);\n\t\treturn SLURM_ERROR;\n\t}\n\n\tfile_name = xstrdup(conf->spooldir);\n\txstrcat(file_name, \"/cred_state\");\n\tcred_fd = open(file_name, O_RDONLY);\n\tif (cred_fd < 0)\n\t\tgoto cleanup;\n\n\tdata_allocated = 1024;\n\tdata = xmalloc(data_allocated);\n\twhile ((data_read = read(cred_fd, data + data_offset, 1024)) == 1024) {\n\t\tdata_offset += data_read;\n\t\tdata_allocated += 1024;\n\t\txrealloc(data, data_allocated);\n\t}\n\tdata_offset += data_read;\n\tclose(cred_fd);\n\tbuffer = create_buf(data, data_offset);\n\n\tslurm_cred_ctx_unpack(ctx, buffer);\n\ncleanup:\n\txfree(file_name);\n\tif (buffer)\n\t\tfree_buf(buffer);\n\treturn SLURM_SUCCESS;\n}\n\nstatic int\n_slurmd_fini(void)\n{\n\tassoc_mgr_fini(false);\n\tnode_features_g_fini();\n\tcore_spec_g_fini();\n\tswitch_g_node_fini();\n\tjobacct_gather_fini();\n\tacct_gather_profile_fini();\n\tsave_cred_state(conf->vctx);\n\tswitch_fini();\n\tslurmd_task_fini();\n\tslurm_conf_destroy();\n\tslurm_proctrack_fini();\n\tslurm_auth_fini();\n\tnode_fini2();\n\tgres_plugin_fini();\n\tprep_plugin_fini();\n\tslurm_topo_fini();\n\tslurmd_req(NULL);\t/* purge memory allocated by slurmd_req() */\n\tfini_setproctitle();\n\tslurm_select_fini();\n\tspank_slurmd_exit();\n\tcpu_freq_fini();\n\t_resource_spec_fini();\n\tjob_container_fini();\n\tacct_gather_conf_destroy();\n\tfini_system_cgroup();\n\troute_fini();\n\txcpuinfo_fini();\n\tslurm_mutex_lock(&fini_job_mutex);\n\txfree(fini_job_id);\n\tfini_job_cnt = 0;\n\tslurm_mutex_unlock(&fini_job_mutex);\n\n\treturn SLURM_SUCCESS;\n}\n\n/*\n * save_cred_state - save the current credential list to a file\n * IN list - list of credentials\n * RET int - zero or error code\n */\nint save_cred_state(slurm_cred_ctx_t ctx)\n{\n\tchar *old_file, *new_file, *reg_file;\n\tint cred_fd = -1, error_code = SLURM_SUCCESS, rc;\n\tBuf buffer = NULL;\n\tstatic pthread_mutex_t state_mutex = PTHREAD_MUTEX_INITIALIZER;\n\n\told_file = xstrdup(conf->spooldir);\n\txstrcat(old_file, \"/cred_state.old\");\n\treg_file = xstrdup(conf->spooldir);\n\txstrcat(reg_file, \"/cred_state\");\n\tnew_file = xstrdup(conf->spooldir);\n\txstrcat(new_file, \"/cred_state.new\");\n\n\tslurm_mutex_lock(&state_mutex);\n\tif ((cred_fd = creat(new_file, 0600)) < 0) {\n\t\terror(\"creat(%s): %m\", new_file);\n\t\tif (errno == ENOSPC)\n\t\t\t_drain_node(\"SlurmdSpoolDir is full\");\n\t\terror_code = errno;\n\t\tgoto cleanup;\n\t}\n\tbuffer = init_buf(1024);\n\tslurm_cred_ctx_pack(ctx, buffer);\n\trc = write(cred_fd, get_buf_data(buffer), get_buf_offset(buffer));\n\tif (rc != get_buf_offset(buffer)) {\n\t\terror(\"write %s error %m\", new_file);\n\t\t(void) unlink(new_file);\n\t\tif ((rc < 0) && (errno == ENOSPC))\n\t\t\t_drain_node(\"SlurmdSpoolDir is full\");\n\t\terror_code = errno;\n\t\tgoto cleanup;\n\t}\n\t(void) unlink(old_file);\n\tif (link(reg_file, old_file))\n\t\tdebug4(\"unable to create link for %s -> %s: %m\",\n\t\t       reg_file, old_file);\n\t(void) unlink(reg_file);\n\tif (link(new_file, reg_file))\n\t\tdebug4(\"unable to create link for %s -> %s: %m\",\n\t\t       new_file, reg_file);\n\t(void) unlink(new_file);\n\ncleanup:\n\tslurm_mutex_unlock(&state_mutex);\n\txfree(old_file);\n\txfree(reg_file);\n\txfree(new_file);\n\tif (buffer)\n\t\tfree_buf(buffer);\n\tif (cred_fd >= 0)\n\t\tclose(cred_fd);\n\treturn error_code;\n}\n\nstatic int _drain_node(char *reason)\n{\n\tslurm_msg_t req_msg;\n\tupdate_node_msg_t update_node_msg;\n\n\tmemset(&update_node_msg, 0, sizeof(update_node_msg_t));\n\tupdate_node_msg.node_names = conf->node_name;\n\tupdate_node_msg.node_state = NODE_STATE_DRAIN;\n\tupdate_node_msg.reason = reason;\n\tupdate_node_msg.reason_uid = getuid();\n\tupdate_node_msg.weight = NO_VAL;\n\tslurm_msg_t_init(&req_msg);\n\treq_msg.msg_type = REQUEST_UPDATE_NODE;\n\treq_msg.data = &update_node_msg;\n\n\tif (slurm_send_only_controller_msg(&req_msg, working_cluster_rec) < 0)\n\t\treturn SLURM_ERROR;\n\n\treturn SLURM_SUCCESS;\n}\n\nextern void slurmd_shutdown(int signum)\n{\n\tif (signum == SIGTERM || signum == SIGINT) {\n\t\t_shutdown = 1;\n\t\tif (msg_pthread && (pthread_self() != msg_pthread))\n\t\t\tpthread_kill(msg_pthread, SIGTERM);\n\t\tmsg_aggr_sender_fini();\n\t}\n}\n\nstatic void\n_hup_handler(int signum)\n{\n\tif (signum == SIGHUP) {\n\t\t_reconfig = 1;\n\t}\n}\n\nstatic void\n_usr_handler(int signum)\n{\n\tif (signum == SIGUSR2) {\n\t\t_update_log = 1;\n\t}\n}\n\n\nstatic void\n_usage(void)\n{\n\tfprintf(stderr, \"\\\nUsage: %s [OPTIONS]\\n\\\n   -b                         Report node reboot now.\\n\\\n   -c                         Force cleanup of slurmd shared memory.\\n\\\n   -C                         Print node configuration information and exit.\\n\\\n   --conf-server host[:port]  Get confgs from slurmctld at `host[:port]`.\\n\\\n   -d stepd                   Pathname to the slurmstepd program.\\n\\\n   -D                         Run daemon in foreground.\\n\\\n   -f config                  Read configuration from the specified file.\\n\\\n   -G                         Print node's GRES configuration and exit.\\n\\\n   -h                         Print this help message.\\n\\\n   -L logfile                 Log messages to the file `logfile'.\\n\\\n   -M                         Use mlock() to lock slurmd pages into memory.\\n\\\n   -n value                   Run the daemon at the specified nice value.\\n\\\n   -N node                    Run the daemon for specified nodename.\\n\\\n   -v                         Verbose mode. Multiple -v's increase verbosity.\\n\\\n   -V                         Print version information and exit.\\n\",\n\t\tconf->prog);\n\treturn;\n}\n\n/*\n * create spool directory as needed\n */\nstatic int _set_slurmd_spooldir(const char *dir)\n{\n\tdebug3(\"%s: initializing slurmd spool directory `%s`\", __func__, dir);\n\n\tif (mkdir(dir, 0755) < 0) {\n\t\tif (errno != EEXIST) {\n\t\t\tfatal(\"mkdir(%s): %m\", conf->spooldir);\n\t\t\treturn SLURM_ERROR;\n\t\t}\n\t}\n\n\t/*\n\t * Ensure spool directory permissions are correct.\n\t */\n\tif (chmod(dir, 0755) < 0) {\n\t\terror(\"chmod(%s, 0755): %m\", conf->spooldir);\n\t\treturn SLURM_ERROR;\n\t}\n\n\treturn SLURM_SUCCESS;\n}\n\n/* Kill the currently running slurmd\n *\n * Returns file descriptor for the existing pidfile so that the\n * current slurmd can wait on termination of the old.\n */\nstatic void\n_kill_old_slurmd(void)\n{\n\tint fd;\n\tpid_t oldpid = read_pidfile(conf->pidfile, &fd);\n\tif (oldpid != (pid_t) 0) {\n\t\tinfo (\"killing old slurmd[%lu]\", (unsigned long) oldpid);\n\t\tkill(oldpid, SIGTERM);\n\n\t\t/*\n\t\t * Wait for previous daemon to terminate\n\t\t */\n\t\tif (fd_get_readw_lock(fd) < 0) {\n\t\t\tfatal (\"error getting readw lock on file %s: %m\",\n\t\t\t       conf->pidfile);\n\t\t}\n\t\t(void) close(fd); /* Ignore errors */\n\t}\n}\n\n/* Reset slurmd logging based upon configuration parameters */\nstatic void _update_logging(void)\n{\n\tList steps;\n\tListIterator i;\n\tstep_loc_t *stepd;\n\tlog_options_t *o = &conf->log_opts;\n\tslurm_ctl_conf_t *cf;\n\n\t_update_log = 0;\n\t/* Preserve execute line verbose arguments (if any) */\n\tcf = slurm_conf_lock();\n\tif (!conf->debug_level_set && (cf->slurmd_debug != NO_VAL16))\n\t\tconf->debug_level = cf->slurmd_debug;\n\tconf->syslog_debug = cf->slurmd_syslog_debug;\n\tconf->log_fmt = cf->log_fmt;\n\tslurm_conf_unlock();\n\n\to->logfile_level = conf->debug_level;\n\n\tif (conf->daemonize)\n\t\to->stderr_level = LOG_LEVEL_QUIET;\n\telse\n\t\to->stderr_level = conf->debug_level;\n\n\tif (conf->syslog_debug != LOG_LEVEL_END) {\n\t\to->syslog_level = conf->syslog_debug;\n\t} else if (!conf->daemonize) {\n\t\to->syslog_level = LOG_LEVEL_QUIET;\n\t} else if ((conf->debug_level > LOG_LEVEL_QUIET) && !conf->logfile) {\n\t\to->syslog_level = conf->debug_level;\n\t} else\n\t\to->syslog_level = LOG_LEVEL_FATAL;\n\n\tlog_alter(conf->log_opts, SYSLOG_FACILITY_DAEMON, conf->logfile);\n\tlog_set_timefmt(conf->log_fmt);\n\n\t/*\n\t * If logging to syslog and running in\n\t * MULTIPLE_SLURMD mode add my node_name\n\t * in the name tag for syslog.\n\t */\n\n\tdebug(\"Log file re-opened\");\n\n#if defined(MULTIPLE_SLURMD)\n\tif (conf->logfile == NULL) {\n\t\tchar buf[64];\n\n\t\tsnprintf(buf, sizeof(buf), \"slurmd-%s\", conf->node_name);\n\t\tlog_set_argv0(buf);\n\t}\n#endif\n\n\t/*\n\t * Send reconfig to each stepd so they will rotate as well.\n\t */\n\n\tsteps = stepd_available(conf->spooldir, conf->node_name);\n\ti = list_iterator_create(steps);\n\twhile ((stepd = list_next(i))) {\n\t\tint fd;\n\t\tfd = stepd_connect(stepd->directory, stepd->nodename,\n\t\t\t\t   stepd->jobid, stepd->stepid,\n\t\t\t\t   &stepd->protocol_version);\n\t\tif (fd == -1)\n\t\t\tcontinue;\n\n\t\tif (stepd_reconfig(fd, stepd->protocol_version)\n\t\t    != SLURM_SUCCESS)\n\t\t\tdebug(\"Reconfig jobid=%u.%u failed: %m\",\n\t\t\t      stepd->jobid, stepd->stepid);\n\t\tclose(fd);\n\t}\n\tlist_iterator_destroy(i);\n\tFREE_NULL_LIST(steps);\n}\n\n/* Reset slurmd nice value */\nstatic void _update_nice(void)\n{\n\tint cur_nice;\n\tid_t pid;\n\n\tif (conf->nice == 0)\t/* No change */\n\t\treturn;\n\n\tpid = getpid();\n\tcur_nice = getpriority(PRIO_PROCESS, pid);\n\tif (cur_nice == conf->nice)\n\t\treturn;\n\tif (setpriority(PRIO_PROCESS, pid, conf->nice))\n\t\terror(\"Unable to reset nice value to %d: %m\", conf->nice);\n}\n\n/*\n *  Lock the fork mutex to protect fork-critical regions\n */\nstatic void _atfork_prepare(void)\n{\n\tslurm_mutex_lock(&fork_mutex);\n}\n\n/*\n *  Unlock  fork mutex to allow fork-critical functions to continue\n */\nstatic void _atfork_final(void)\n{\n\tslurm_mutex_unlock(&fork_mutex);\n}\n\nstatic void _install_fork_handlers(void)\n{\n\tint err;\n\n\terr = pthread_atfork(&_atfork_prepare, &_atfork_final, &_atfork_final);\n\tif (err) error (\"pthread_atfork: %m\");\n\n\treturn;\n}\n\n/*\n * set topology address and address pattern of slurmd node\n */\nstatic int _set_topo_info(void)\n{\n\tint rc;\n\tchar *addr = NULL, *pattern = NULL;\n\n\tslurm_mutex_lock(&conf->config_mutex);\n\trc = slurm_topo_get_node_addr(conf->node_name, &addr, &pattern);\n\tif (rc == SLURM_SUCCESS) {\n\t\txfree(conf->node_topo_addr);\n\t\txfree(conf->node_topo_pattern);\n\t\tconf->node_topo_addr = addr;\n\t\tconf->node_topo_pattern = pattern;\n\t}\n\tslurm_mutex_unlock(&conf->config_mutex);\n\n\treturn rc;\n}\n\nstatic uint64_t _get_int(const char *my_str)\n{\n\tchar *end = NULL;\n\tuint64_t value;\n\n\tif (!my_str)\n\t\treturn NO_VAL;\n\tvalue = strtol(my_str, &end, 10);\n\tif (my_str == end)\n\t\treturn NO_VAL;\n\treturn value;\n}\n\nstatic uint64_t _parse_msg_aggr_params(int type, char *params)\n{\n\tuint64_t value = NO_VAL;\n\tchar *sub_str = NULL;\n\n\tif (!params)\n\t\treturn NO_VAL;\n\n\tswitch (type) {\n\tcase WINDOW_TIME:\n\t\tif ((sub_str = xstrcasestr(params, \"WindowTime=\")))\n\t\t\tvalue = _get_int(sub_str + 11);\n\t\tbreak;\n\tcase WINDOW_MSGS:\n\t\tif ((sub_str = xstrcasestr(params, \"WindowMsgs=\")))\n\t\t\tvalue = _get_int(sub_str + 11);\n\t\tbreak;\n\tdefault:\n\t\tfatal(\"invalid message aggregation parameters: %s\", params);\n\t}\n\treturn value;\n}\n\nstatic void _set_msg_aggr_params(void)\n{\n\tconf->msg_aggr_window_time = _parse_msg_aggr_params(WINDOW_TIME,\n\t\t\t       conf->msg_aggr_params);\n\tconf->msg_aggr_window_msgs = _parse_msg_aggr_params(WINDOW_MSGS,\n\t\t\t       conf->msg_aggr_params);\n\n\tif (conf->msg_aggr_window_time == NO_VAL)\n\t\tconf->msg_aggr_window_time = DEFAULT_MSG_AGGR_WINDOW_TIME;\n\tif (conf->msg_aggr_window_msgs == NO_VAL)\n\t\tconf->msg_aggr_window_msgs = DEFAULT_MSG_AGGR_WINDOW_MSGS;\n\tif (conf->msg_aggr_window_msgs > 1) {\n\t\tinfo(\"Message aggregation enabled: WindowMsgs=%\"PRIu64\", WindowTime=%\"PRIu64,\n\t\t     conf->msg_aggr_window_msgs, conf->msg_aggr_window_time);\n\t} else\n\t\tinfo(\"Message aggregation disabled\");\n}\n\n/*\n * Initialize resource specialization\n */\nstatic int _resource_spec_init(void)\n{\n\tfini_system_cgroup();\t/* Prevent memory leak */\n\tif (_core_spec_init() != SLURM_SUCCESS)\n\t\terror(\"Resource spec: core specialization disabled\");\n\tif (_memory_spec_init() != SLURM_SUCCESS)\n\t\terror(\"Resource spec: system cgroup memory limit disabled\");\n\treturn SLURM_SUCCESS;\n}\n\n/* Return true if CoreSpecPlugin=core_spec/cray */\nstatic bool _is_core_spec_cray(void)\n{\n\tbool use_core_spec_cray = false;\n\tchar *core_spec_plugin = slurm_get_core_spec_plugin();\n\tif (core_spec_plugin && strstr(core_spec_plugin, \"cray\"))\n\t\tuse_core_spec_cray = true;\n\txfree(core_spec_plugin);\n\treturn use_core_spec_cray;\n}\n\n/*\n * If configured, initialize core specialization\n */\nstatic int _core_spec_init(void)\n{\n#if defined(__APPLE__)\n\terror(\"%s: not supported on macOS\", __func__);\n\treturn SLURM_SUCCESS;\n#else\n\tint i, rval;\n\tpid_t pid;\n\tuint32_t task_params;\n\tbool slurmd_off_spec;\n\tbitstr_t *res_mac_bitmap;\n\tcpu_set_t mask;\n\n\tif ((conf->core_spec_cnt == 0) && (conf->cpu_spec_list == NULL)) {\n\t\tdebug(\"Resource spec: No specialized cores configured by \"\n\t\t      \"default on this node\");\n\t\treturn SLURM_SUCCESS;\n\t}\n\tif (_is_core_spec_cray()) {\t/* No need to use cgroups */\n\t\tdebug(\"Using core_spec/cray to manage specialized cores\");\n\t\treturn SLURM_SUCCESS;\n\t}\n\n\tncores = conf->sockets * conf->cores;\n\tncpus = ncores * conf->threads;\n\tres_abs_core_size = ncores * 4;\n\tres_abs_cores = xmalloc(res_abs_core_size);\n\tres_core_bitmap = bit_alloc(ncores);\n\tres_cpu_bitmap  = bit_alloc(ncpus);\n\tres_abs_cpus[0] = '\\0';\n\n\tif (conf->cpu_spec_list != NULL) {\n\t\t/* CPUSpecList designated in slurm.conf */\n\t\tdebug2(\"Resource spec: configured CPU specialization list: %s\",\n\t\t\tconf->cpu_spec_list);\n\t\tif (_validate_and_convert_cpu_list() != SLURM_SUCCESS) {\n\t\t\terror(\"Resource spec: unable to process CPUSpecList\");\n\t\t\t_resource_spec_fini();\n\t\t\treturn SLURM_ERROR;\n\t\t}\n\t} else {\n\t\t/* CoreSpecCount designated in slurm.conf */\n\t\tdebug2(\"Resource spec: configured core specialization \"\n\t\t       \"count: %u\", conf->core_spec_cnt);\n\t\tif (conf->core_spec_cnt >= ncores) {\n\t\t\terror(\"Resource spec: CoreSpecCount too large\");\n\t\t\t_resource_spec_fini();\n\t\t\treturn SLURM_ERROR;\n\t\t}\n\t\t_select_spec_cores();\n\t\tif (_convert_spec_cores() != SLURM_SUCCESS) {\n\t\t\terror(\"Resource spec: unable to convert \"\n\t\t\t      \"selected cores to machine CPU IDs\");\n\t\t\t_resource_spec_fini();\n\t\t\treturn SLURM_ERROR;\n\t\t}\n\t}\n\n\tpid = getpid();\n\ttask_params = slurm_get_task_plugin_param();\n\tslurmd_off_spec = (task_params & SLURMD_OFF_SPEC);\n\n\tif (check_corespec_cgroup_job_confinement()) {\n\t\tif (init_system_cpuset_cgroup() != SLURM_SUCCESS) {\n\t\t\terror(\"Resource spec: unable to initialize system \"\n\t\t\t      \"cpuset cgroup\");\n\t\t\t_resource_spec_fini();\n\t\t\treturn SLURM_ERROR;\n\t\t}\n\t\tif (slurmd_off_spec) {\n\t\t\tchar other_mac_cpus[1024];\n\t\t\tres_mac_bitmap = bit_alloc(ncpus);\n\t\t\tbit_unfmt(res_mac_bitmap, res_mac_cpus);\n\t\t\tbit_not(res_mac_bitmap);\n\t\t\tbit_fmt(other_mac_cpus, sizeof(other_mac_cpus),\n\t\t\t\tres_mac_bitmap);\n\t\t\tbit_free(res_mac_bitmap);\n\t\t\trval = set_system_cgroup_cpus(other_mac_cpus);\n\t\t} else {\n\t\t\trval = set_system_cgroup_cpus(res_mac_cpus);\n\t\t}\n\t\tif (rval != SLURM_SUCCESS) {\n\t\t\terror(\"Resource spec: unable to set reserved CPU IDs in \"\n\t\t\t      \"system cpuset cgroup\");\n\t\t\t_resource_spec_fini();\n\t\t\treturn SLURM_ERROR;\n\t\t}\n\t\tif (attach_system_cpuset_pid(pid) != SLURM_SUCCESS) {\n\t\t\terror(\"Resource spec: unable to attach slurmd to \"\n\t\t\t      \"system cpuset cgroup\");\n\t\t\t_resource_spec_fini();\n\t\t\treturn SLURM_ERROR;\n\t\t}\n\t} else {\n\t\tres_mac_bitmap = bit_alloc(ncpus);\n\t\tbit_unfmt(res_mac_bitmap, res_mac_cpus);\n\t\tCPU_ZERO(&mask);\n\t\tfor (i = 0; i < ncpus; i++) {\n\t\t\tbool cpu_in_spec = bit_test(res_mac_bitmap, i);\n\t\t\tif (slurmd_off_spec != cpu_in_spec) {\n\t\t\t\tCPU_SET(i, &mask);\n}\n\t\t}\n\t\tbit_free(res_mac_bitmap);\n\n#ifdef __FreeBSD__\n\t\trval = cpuset_setaffinity(CPU_LEVEL_WHICH, CPU_WHICH_PID,\n\t\t\t\t\t  pid, sizeof(cpu_set_t), &mask);\n#else\n\t\trval = sched_setaffinity(pid, sizeof(cpu_set_t), &mask);\n#endif\n\n\t\tif (rval != 0) {\n\t\t\terror(\"Resource spec: unable to establish slurmd CPU \"\n\t\t\t      \"affinity: %m\");\n\t\t\t_resource_spec_fini();\n\t\t\treturn SLURM_ERROR;\n\t\t}\n\t}\n\n\tinfo(\"Resource spec: Reserved abstract CPU IDs: %s\", res_abs_cpus);\n\tinfo(\"Resource spec: Reserved machine CPU IDs: %s\", res_mac_cpus);\n\t_resource_spec_fini();\n\n\treturn SLURM_SUCCESS;\n#endif\n}\n\n/*\n * If configured, initialize system memory limit\n */\nstatic int _memory_spec_init(void)\n{\n\tpid_t pid;\n\n\tif (conf->mem_spec_limit == 0) {\n\t\tdebug(\"Resource spec: Reserved system memory limit not \"\n\t\t      \"configured for this node\");\n\t\treturn SLURM_SUCCESS;\n\t}\n\tif (!xcgroup_mem_cgroup_job_confinement()) {\n\t\tif (slurm_get_select_type_param() & CR_MEMORY) {\n\t\t\terror(\"Resource spec: Limited MemSpecLimit support. \"\n\t\t\t     \"Slurmd daemon not memory constrained. \"\n\t\t\t     \"Reserved %\"PRIu64\" MB\", conf->mem_spec_limit);\n\t\t\treturn SLURM_SUCCESS;\n\t\t}\n\t\terror(\"Resource spec: cgroup job confinement not configured. \"\n\t\t      \"Full MemSpecLimit support requires task/cgroup and \"\n\t\t      \"ConstrainRAMSpace=yes in cgroup.conf\");\n\t\treturn SLURM_ERROR;\n\t}\n\tif (init_system_memory_cgroup() != SLURM_SUCCESS) {\n\t\terror(\"Resource spec: unable to initialize system \"\n\t\t      \"memory cgroup\");\n\t\treturn SLURM_ERROR;\n\t}\n\tif (set_system_cgroup_mem_limit(conf->mem_spec_limit)\n\t\t\t!= SLURM_SUCCESS) {\n\t\terror(\"Resource spec: unable to set memory limit in \"\n\t\t      \"system memory cgroup\");\n\t\treturn SLURM_ERROR;\n\t}\n\tif (disable_system_cgroup_mem_oom()) {\n\t\terror(\"Resource spec: unable to disable OOM Killer in \"\n\t\t      \"system memory cgroup\");\n\t\treturn SLURM_ERROR;\n\t}\n\tpid = getpid();\n\tif (attach_system_memory_pid(pid) != SLURM_SUCCESS) {\n\t\terror(\"Resource spec: unable to attach slurmd to \"\n\t\t      \"system memory cgroup\");\n\t\treturn SLURM_ERROR;\n\t}\n\tinfo(\"Resource spec: system cgroup memory limit set to %\"PRIu64\" MB\",\n\t     conf->mem_spec_limit);\n\treturn SLURM_SUCCESS;\n}\n\n/*\n * Select cores and CPUs to be reserved for core specialization.\n * IN:\n *  \tconf->sockets\t\t= number of sockets on this node\n *   \tconf->cores\t\t= number of cores per socket on this node\n * \tconf->threads\t\t= number of threads per core on this node\n * \tconf->core_spec_cnt \t= number of cores to be reserved\n * OUT:\n * \tres_core_bitmap\t\t= bitmap of selected cores\n * \tres_cpu_bitmap\t\t= bitmap of selected CPUs\n */\nstatic void _select_spec_cores(void)\n{\n\tint spec_cores, res_core, res_sock, res_off, core_off, thread_off;\n\tint from_core, to_core, incr_core, from_sock, to_sock, incr_sock;\n\tchar *sched_params = slurm_get_sched_params();\n\tbool spec_cores_first;\n\n\tif (xstrcasestr(sched_params, \"spec_cores_first\"))\n\t\tspec_cores_first = true;\n\telse\n\t\tspec_cores_first = false;\n\txfree(sched_params);\n\n\tif (spec_cores_first) {\n\t\tfrom_core = 0;\n\t\tto_core   = conf->cores;\n\t\tincr_core = 1;\n\t\tfrom_sock = 0;\n\t\tto_sock   = conf->sockets;\n\t\tincr_sock = 1;\n\t} else {\n\t\tfrom_core = conf->cores - 1;\n\t\tto_core   = -1;\n\t\tincr_core = -1;\n\t\tfrom_sock = conf->sockets - 1;\n\t\tto_sock   = -1;\n\t\tincr_sock = -1;\n\t}\n\tspec_cores = conf->core_spec_cnt;\n\tfor (res_core = from_core;\n\t     (spec_cores && (res_core != to_core)); res_core += incr_core) {\n\t\tfor (res_sock = from_sock;\n\t\t     (spec_cores && (res_sock != to_sock));\n\t\t      res_sock += incr_sock) {\n\t\t\tcore_off = ((res_sock*conf->cores) + res_core) *\n\t\t\t\t\tconf->threads;\n\t\t\tfor (thread_off = 0; thread_off < conf->threads;\n\t\t\t     thread_off++) {\n\t\t\t\tbit_set(res_cpu_bitmap, core_off + thread_off);\n\t\t\t}\n\t\t\tres_off = (res_sock * conf->cores) + res_core;\n\t\t\tbit_set(res_core_bitmap, res_off);\n\t\t\tspec_cores--;\n\t\t}\n\t}\n\treturn;\n}\n\n/*\n * Convert Core/CPU bitmaps into lists\n * IN:\n * \tres_core_bitmap\t\t= bitmap of selected cores\n * \tres_cpu_bitmap\t\t= bitmap of selected CPUs\n * OUT:\n * \tres_abs_cores\t\t= list of abstract core IDs\n * \tres_abs_cpus\t\t= list of abstract CPU IDs\n * \tres_mac_cpus\t\t= list of machine CPU IDs\n */\nstatic int _convert_spec_cores(void)\n{\n\tbit_fmt(res_abs_cores, res_abs_core_size, res_core_bitmap);\n\tbit_fmt(res_abs_cpus, sizeof(res_abs_cpus), res_cpu_bitmap);\n\tif (xcpuinfo_abs_to_mac(res_abs_cores, &res_mac_cpus) != SLURM_SUCCESS)\n\t\treturn SLURM_ERROR;\n\treturn SLURM_SUCCESS;\n}\n\n/*\n * Validate and convert CPU list\n * IN:\n *  \tconf->sockets\t\t= number of sockets on this node\n *   \tconf->cores\t\t= number of cores per socket on this node\n * \tconf->threads\t\t= number of threads per core on this node\n * \tconf->cpu_spec_list \t= configured list of CPU IDs to be reserved\n * OUT:\n *\tres_cpu_bitmap\t\t= bitmap of input abstract CPUs\n *\tres_core_bitmap\t\t= bitmap of cores\n *\tres_abs_cores\t\t= list of abstract core IDs\n *\tres_abs_cpus\t\t= converted list of abstract CPU IDs\n *\tres_mac_cpus\t\t= converted list of machine CPU IDs\n */\nstatic int _validate_and_convert_cpu_list(void)\n{\n\tint core_off, thread_inx, thread_off;\n\n\t/* create CPU bitmap from input CPU list */\n\tif (bit_unfmt(res_cpu_bitmap, conf->cpu_spec_list) != 0) {\n\t\treturn SLURM_ERROR;\n\t}\n\t/* create core bitmap and list from CPU bitmap */\n\tfor (thread_off = 0; thread_off < ncpus; thread_off++) {\n\t\tif (bit_test(res_cpu_bitmap, thread_off) == 1)\n\t\t\tbit_set(res_core_bitmap, thread_off/(conf->threads));\n\t}\n\tbit_fmt(res_abs_cores, res_abs_core_size, res_core_bitmap);\n\t/* create output abstract CPU list from core bitmap */\n\tfor (core_off = 0; core_off < ncores; core_off++) {\n\t\tif (bit_test(res_core_bitmap, core_off) == 1) {\n\t\t\tfor (thread_off = 0; thread_off < conf->threads;\n\t\t\t     thread_off++) {\n\t\t\t\tthread_inx = (core_off * (int) conf->threads) +\n\t\t\t\t\t     thread_off;\n\t\t\t\tbit_set(res_cpu_bitmap, thread_inx);\n\t\t\t}\n\t\t}\n\t}\n\tbit_fmt(res_abs_cpus, sizeof(res_abs_cpus), res_cpu_bitmap);\n\t/* create output machine CPU list from core list */\n\tif (xcpuinfo_abs_to_mac(res_abs_cores, &res_mac_cpus)\n\t\t   != XCPUINFO_SUCCESS)\n\t\treturn SLURM_ERROR;\n\treturn SLURM_SUCCESS;\n}\n\nstatic void _resource_spec_fini(void)\n{\n\txfree(res_abs_cores);\n\txfree(res_mac_cpus);\n\tFREE_NULL_BITMAP(res_core_bitmap);\n\tFREE_NULL_BITMAP(res_cpu_bitmap);\n}\n\n/*\n * Run the configured health check program\n *\n * Returns the run result. If the health check program\n * is not defined, returns success immediately.\n */\nextern int run_script_health_check(void)\n{\n\tint rc = SLURM_SUCCESS;\n\n\tif (conf->health_check_program && (conf->health_check_interval != 0)) {\n\t\tchar *env[1] = { NULL };\n\t\trc = run_script(\"health_check\", conf->health_check_program,\n\t\t\t\t0, 60, env, 0);\n\t}\n\n\treturn rc;\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/auxdir/libtool.m4": "# libtool.m4 - Configure libtool for the host system. -*-Autoconf-*-\n#\n#   Copyright (C) 1996-2001, 2003-2015 Free Software Foundation, Inc.\n#   Written by Gordon Matzigkeit, 1996\n#\n# This file is free software; the Free Software Foundation gives\n# unlimited permission to copy and/or distribute it, with or without\n# modifications, as long as this notice is preserved.\n\nm4_define([_LT_COPYING], [dnl\n# Copyright (C) 2014 Free Software Foundation, Inc.\n# This is free software; see the source for copying conditions.  There is NO\n# warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\n# GNU Libtool is free software; you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation; either version 2 of of the License, or\n# (at your option) any later version.\n#\n# As a special exception to the GNU General Public License, if you\n# distribute this file as part of a program or library that is built\n# using GNU Libtool, you may include this file under the  same\n# distribution terms that you use for the rest of that program.\n#\n# GNU Libtool is distributed in the hope that it will be useful, but\n# WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program.  If not, see <http://www.gnu.org/licenses/>.\n])\n\n# serial 58 LT_INIT\n\n\n# LT_PREREQ(VERSION)\n# ------------------\n# Complain and exit if this libtool version is less that VERSION.\nm4_defun([LT_PREREQ],\n[m4_if(m4_version_compare(m4_defn([LT_PACKAGE_VERSION]), [$1]), -1,\n       [m4_default([$3],\n\t\t   [m4_fatal([Libtool version $1 or higher is required],\n\t\t             63)])],\n       [$2])])\n\n\n# _LT_CHECK_BUILDDIR\n# ------------------\n# Complain if the absolute build directory name contains unusual characters\nm4_defun([_LT_CHECK_BUILDDIR],\n[case `pwd` in\n  *\\ * | *\\\t*)\n    AC_MSG_WARN([Libtool does not cope well with whitespace in `pwd`]) ;;\nesac\n])\n\n\n# LT_INIT([OPTIONS])\n# ------------------\nAC_DEFUN([LT_INIT],\n[AC_PREREQ([2.62])dnl We use AC_PATH_PROGS_FEATURE_CHECK\nAC_REQUIRE([AC_CONFIG_AUX_DIR_DEFAULT])dnl\nAC_BEFORE([$0], [LT_LANG])dnl\nAC_BEFORE([$0], [LT_OUTPUT])dnl\nAC_BEFORE([$0], [LTDL_INIT])dnl\nm4_require([_LT_CHECK_BUILDDIR])dnl\n\ndnl Autoconf doesn't catch unexpanded LT_ macros by default:\nm4_pattern_forbid([^_?LT_[A-Z_]+$])dnl\nm4_pattern_allow([^(_LT_EOF|LT_DLGLOBAL|LT_DLLAZY_OR_NOW|LT_MULTI_MODULE)$])dnl\ndnl aclocal doesn't pull ltoptions.m4, ltsugar.m4, or ltversion.m4\ndnl unless we require an AC_DEFUNed macro:\nAC_REQUIRE([LTOPTIONS_VERSION])dnl\nAC_REQUIRE([LTSUGAR_VERSION])dnl\nAC_REQUIRE([LTVERSION_VERSION])dnl\nAC_REQUIRE([LTOBSOLETE_VERSION])dnl\nm4_require([_LT_PROG_LTMAIN])dnl\n\n_LT_SHELL_INIT([SHELL=${CONFIG_SHELL-/bin/sh}])\n\ndnl Parse OPTIONS\n_LT_SET_OPTIONS([$0], [$1])\n\n# This can be used to rebuild libtool when needed\nLIBTOOL_DEPS=$ltmain\n\n# Always use our own libtool.\nLIBTOOL='$(SHELL) $(top_builddir)/libtool'\nAC_SUBST(LIBTOOL)dnl\n\n_LT_SETUP\n\n# Only expand once:\nm4_define([LT_INIT])\n])# LT_INIT\n\n# Old names:\nAU_ALIAS([AC_PROG_LIBTOOL], [LT_INIT])\nAU_ALIAS([AM_PROG_LIBTOOL], [LT_INIT])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_PROG_LIBTOOL], [])\ndnl AC_DEFUN([AM_PROG_LIBTOOL], [])\n\n\n# _LT_PREPARE_CC_BASENAME\n# -----------------------\nm4_defun([_LT_PREPARE_CC_BASENAME], [\n# Calculate cc_basename.  Skip known compiler wrappers and cross-prefix.\nfunc_cc_basename ()\n{\n    for cc_temp in @S|@*\"\"; do\n      case $cc_temp in\n        compile | *[[\\\\/]]compile | ccache | *[[\\\\/]]ccache ) ;;\n        distcc | *[[\\\\/]]distcc | purify | *[[\\\\/]]purify ) ;;\n        \\-*) ;;\n        *) break;;\n      esac\n    done\n    func_cc_basename_result=`$ECHO \"$cc_temp\" | $SED \"s%.*/%%; s%^$host_alias-%%\"`\n}\n])# _LT_PREPARE_CC_BASENAME\n\n\n# _LT_CC_BASENAME(CC)\n# -------------------\n# It would be clearer to call AC_REQUIREs from _LT_PREPARE_CC_BASENAME,\n# but that macro is also expanded into generated libtool script, which\n# arranges for $SED and $ECHO to be set by different means.\nm4_defun([_LT_CC_BASENAME],\n[m4_require([_LT_PREPARE_CC_BASENAME])dnl\nAC_REQUIRE([_LT_DECL_SED])dnl\nAC_REQUIRE([_LT_PROG_ECHO_BACKSLASH])dnl\nfunc_cc_basename $1\ncc_basename=$func_cc_basename_result\n])\n\n\n# _LT_FILEUTILS_DEFAULTS\n# ----------------------\n# It is okay to use these file commands and assume they have been set\n# sensibly after 'm4_require([_LT_FILEUTILS_DEFAULTS])'.\nm4_defun([_LT_FILEUTILS_DEFAULTS],\n[: ${CP=\"cp -f\"}\n: ${MV=\"mv -f\"}\n: ${RM=\"rm -f\"}\n])# _LT_FILEUTILS_DEFAULTS\n\n\n# _LT_SETUP\n# ---------\nm4_defun([_LT_SETUP],\n[AC_REQUIRE([AC_CANONICAL_HOST])dnl\nAC_REQUIRE([AC_CANONICAL_BUILD])dnl\nAC_REQUIRE([_LT_PREPARE_SED_QUOTE_VARS])dnl\nAC_REQUIRE([_LT_PROG_ECHO_BACKSLASH])dnl\n\n_LT_DECL([], [PATH_SEPARATOR], [1], [The PATH separator for the build system])dnl\ndnl\n_LT_DECL([], [host_alias], [0], [The host system])dnl\n_LT_DECL([], [host], [0])dnl\n_LT_DECL([], [host_os], [0])dnl\ndnl\n_LT_DECL([], [build_alias], [0], [The build system])dnl\n_LT_DECL([], [build], [0])dnl\n_LT_DECL([], [build_os], [0])dnl\ndnl\nAC_REQUIRE([AC_PROG_CC])dnl\nAC_REQUIRE([LT_PATH_LD])dnl\nAC_REQUIRE([LT_PATH_NM])dnl\ndnl\nAC_REQUIRE([AC_PROG_LN_S])dnl\ntest -z \"$LN_S\" && LN_S=\"ln -s\"\n_LT_DECL([], [LN_S], [1], [Whether we need soft or hard links])dnl\ndnl\nAC_REQUIRE([LT_CMD_MAX_LEN])dnl\n_LT_DECL([objext], [ac_objext], [0], [Object file suffix (normally \"o\")])dnl\n_LT_DECL([], [exeext], [0], [Executable file suffix (normally \"\")])dnl\ndnl\nm4_require([_LT_FILEUTILS_DEFAULTS])dnl\nm4_require([_LT_CHECK_SHELL_FEATURES])dnl\nm4_require([_LT_PATH_CONVERSION_FUNCTIONS])dnl\nm4_require([_LT_CMD_RELOAD])dnl\nm4_require([_LT_CHECK_MAGIC_METHOD])dnl\nm4_require([_LT_CHECK_SHAREDLIB_FROM_LINKLIB])dnl\nm4_require([_LT_CMD_OLD_ARCHIVE])dnl\nm4_require([_LT_CMD_GLOBAL_SYMBOLS])dnl\nm4_require([_LT_WITH_SYSROOT])dnl\nm4_require([_LT_CMD_TRUNCATE])dnl\n\n_LT_CONFIG_LIBTOOL_INIT([\n# See if we are running on zsh, and set the options that allow our\n# commands through without removal of \\ escapes INIT.\nif test -n \"\\${ZSH_VERSION+set}\"; then\n   setopt NO_GLOB_SUBST\nfi\n])\nif test -n \"${ZSH_VERSION+set}\"; then\n   setopt NO_GLOB_SUBST\nfi\n\n_LT_CHECK_OBJDIR\n\nm4_require([_LT_TAG_COMPILER])dnl\n\ncase $host_os in\naix3*)\n  # AIX sometimes has problems with the GCC collect2 program.  For some\n  # reason, if we set the COLLECT_NAMES environment variable, the problems\n  # vanish in a puff of smoke.\n  if test set != \"${COLLECT_NAMES+set}\"; then\n    COLLECT_NAMES=\n    export COLLECT_NAMES\n  fi\n  ;;\nesac\n\n# Global variables:\nofile=libtool\ncan_build_shared=yes\n\n# All known linkers require a '.a' archive for static linking (except MSVC,\n# which needs '.lib').\nlibext=a\n\nwith_gnu_ld=$lt_cv_prog_gnu_ld\n\nold_CC=$CC\nold_CFLAGS=$CFLAGS\n\n# Set sane defaults for various variables\ntest -z \"$CC\" && CC=cc\ntest -z \"$LTCC\" && LTCC=$CC\ntest -z \"$LTCFLAGS\" && LTCFLAGS=$CFLAGS\ntest -z \"$LD\" && LD=ld\ntest -z \"$ac_objext\" && ac_objext=o\n\n_LT_CC_BASENAME([$compiler])\n\n# Only perform the check for file, if the check method requires it\ntest -z \"$MAGIC_CMD\" && MAGIC_CMD=file\ncase $deplibs_check_method in\nfile_magic*)\n  if test \"$file_magic_cmd\" = '$MAGIC_CMD'; then\n    _LT_PATH_MAGIC\n  fi\n  ;;\nesac\n\n# Use C for the default configuration in the libtool script\nLT_SUPPORTED_TAG([CC])\n_LT_LANG_C_CONFIG\n_LT_LANG_DEFAULT_CONFIG\n_LT_CONFIG_COMMANDS\n])# _LT_SETUP\n\n\n# _LT_PREPARE_SED_QUOTE_VARS\n# --------------------------\n# Define a few sed substitution that help us do robust quoting.\nm4_defun([_LT_PREPARE_SED_QUOTE_VARS],\n[# Backslashify metacharacters that are still active within\n# double-quoted strings.\nsed_quote_subst='s/\\([[\"`$\\\\]]\\)/\\\\\\1/g'\n\n# Same as above, but do not quote variable references.\ndouble_quote_subst='s/\\([[\"`\\\\]]\\)/\\\\\\1/g'\n\n# Sed substitution to delay expansion of an escaped shell variable in a\n# double_quote_subst'ed string.\ndelay_variable_subst='s/\\\\\\\\\\\\\\\\\\\\\\$/\\\\\\\\\\\\$/g'\n\n# Sed substitution to delay expansion of an escaped single quote.\ndelay_single_quote_subst='s/'\\''/'\\'\\\\\\\\\\\\\\'\\''/g'\n\n# Sed substitution to avoid accidental globbing in evaled expressions\nno_glob_subst='s/\\*/\\\\\\*/g'\n])\n\n# _LT_PROG_LTMAIN\n# ---------------\n# Note that this code is called both from 'configure', and 'config.status'\n# now that we use AC_CONFIG_COMMANDS to generate libtool.  Notably,\n# 'config.status' has no value for ac_aux_dir unless we are using Automake,\n# so we pass a copy along to make sure it has a sensible value anyway.\nm4_defun([_LT_PROG_LTMAIN],\n[m4_ifdef([AC_REQUIRE_AUX_FILE], [AC_REQUIRE_AUX_FILE([ltmain.sh])])dnl\n_LT_CONFIG_LIBTOOL_INIT([ac_aux_dir='$ac_aux_dir'])\nltmain=$ac_aux_dir/ltmain.sh\n])# _LT_PROG_LTMAIN\n\n\n## ------------------------------------- ##\n## Accumulate code for creating libtool. ##\n## ------------------------------------- ##\n\n# So that we can recreate a full libtool script including additional\n# tags, we accumulate the chunks of code to send to AC_CONFIG_COMMANDS\n# in macros and then make a single call at the end using the 'libtool'\n# label.\n\n\n# _LT_CONFIG_LIBTOOL_INIT([INIT-COMMANDS])\n# ----------------------------------------\n# Register INIT-COMMANDS to be passed to AC_CONFIG_COMMANDS later.\nm4_define([_LT_CONFIG_LIBTOOL_INIT],\n[m4_ifval([$1],\n          [m4_append([_LT_OUTPUT_LIBTOOL_INIT],\n                     [$1\n])])])\n\n# Initialize.\nm4_define([_LT_OUTPUT_LIBTOOL_INIT])\n\n\n# _LT_CONFIG_LIBTOOL([COMMANDS])\n# ------------------------------\n# Register COMMANDS to be passed to AC_CONFIG_COMMANDS later.\nm4_define([_LT_CONFIG_LIBTOOL],\n[m4_ifval([$1],\n          [m4_append([_LT_OUTPUT_LIBTOOL_COMMANDS],\n                     [$1\n])])])\n\n# Initialize.\nm4_define([_LT_OUTPUT_LIBTOOL_COMMANDS])\n\n\n# _LT_CONFIG_SAVE_COMMANDS([COMMANDS], [INIT_COMMANDS])\n# -----------------------------------------------------\nm4_defun([_LT_CONFIG_SAVE_COMMANDS],\n[_LT_CONFIG_LIBTOOL([$1])\n_LT_CONFIG_LIBTOOL_INIT([$2])\n])\n\n\n# _LT_FORMAT_COMMENT([COMMENT])\n# -----------------------------\n# Add leading comment marks to the start of each line, and a trailing\n# full-stop to the whole comment if one is not present already.\nm4_define([_LT_FORMAT_COMMENT],\n[m4_ifval([$1], [\nm4_bpatsubst([m4_bpatsubst([$1], [^ *], [# ])],\n              [['`$\\]], [\\\\\\&])]m4_bmatch([$1], [[!?.]$], [], [.])\n)])\n\n\n\n## ------------------------ ##\n## FIXME: Eliminate VARNAME ##\n## ------------------------ ##\n\n\n# _LT_DECL([CONFIGNAME], VARNAME, VALUE, [DESCRIPTION], [IS-TAGGED?])\n# -------------------------------------------------------------------\n# CONFIGNAME is the name given to the value in the libtool script.\n# VARNAME is the (base) name used in the configure script.\n# VALUE may be 0, 1 or 2 for a computed quote escaped value based on\n# VARNAME.  Any other value will be used directly.\nm4_define([_LT_DECL],\n[lt_if_append_uniq([lt_decl_varnames], [$2], [, ],\n    [lt_dict_add_subkey([lt_decl_dict], [$2], [libtool_name],\n\t[m4_ifval([$1], [$1], [$2])])\n    lt_dict_add_subkey([lt_decl_dict], [$2], [value], [$3])\n    m4_ifval([$4],\n\t[lt_dict_add_subkey([lt_decl_dict], [$2], [description], [$4])])\n    lt_dict_add_subkey([lt_decl_dict], [$2],\n\t[tagged?], [m4_ifval([$5], [yes], [no])])])\n])\n\n\n# _LT_TAGDECL([CONFIGNAME], VARNAME, VALUE, [DESCRIPTION])\n# --------------------------------------------------------\nm4_define([_LT_TAGDECL], [_LT_DECL([$1], [$2], [$3], [$4], [yes])])\n\n\n# lt_decl_tag_varnames([SEPARATOR], [VARNAME1...])\n# ------------------------------------------------\nm4_define([lt_decl_tag_varnames],\n[_lt_decl_filter([tagged?], [yes], $@)])\n\n\n# _lt_decl_filter(SUBKEY, VALUE, [SEPARATOR], [VARNAME1..])\n# ---------------------------------------------------------\nm4_define([_lt_decl_filter],\n[m4_case([$#],\n  [0], [m4_fatal([$0: too few arguments: $#])],\n  [1], [m4_fatal([$0: too few arguments: $#: $1])],\n  [2], [lt_dict_filter([lt_decl_dict], [$1], [$2], [], lt_decl_varnames)],\n  [3], [lt_dict_filter([lt_decl_dict], [$1], [$2], [$3], lt_decl_varnames)],\n  [lt_dict_filter([lt_decl_dict], $@)])[]dnl\n])\n\n\n# lt_decl_quote_varnames([SEPARATOR], [VARNAME1...])\n# --------------------------------------------------\nm4_define([lt_decl_quote_varnames],\n[_lt_decl_filter([value], [1], $@)])\n\n\n# lt_decl_dquote_varnames([SEPARATOR], [VARNAME1...])\n# ---------------------------------------------------\nm4_define([lt_decl_dquote_varnames],\n[_lt_decl_filter([value], [2], $@)])\n\n\n# lt_decl_varnames_tagged([SEPARATOR], [VARNAME1...])\n# ---------------------------------------------------\nm4_define([lt_decl_varnames_tagged],\n[m4_assert([$# <= 2])dnl\n_$0(m4_quote(m4_default([$1], [[, ]])),\n    m4_ifval([$2], [[$2]], [m4_dquote(lt_decl_tag_varnames)]),\n    m4_split(m4_normalize(m4_quote(_LT_TAGS)), [ ]))])\nm4_define([_lt_decl_varnames_tagged],\n[m4_ifval([$3], [lt_combine([$1], [$2], [_], $3)])])\n\n\n# lt_decl_all_varnames([SEPARATOR], [VARNAME1...])\n# ------------------------------------------------\nm4_define([lt_decl_all_varnames],\n[_$0(m4_quote(m4_default([$1], [[, ]])),\n     m4_if([$2], [],\n\t   m4_quote(lt_decl_varnames),\n\tm4_quote(m4_shift($@))))[]dnl\n])\nm4_define([_lt_decl_all_varnames],\n[lt_join($@, lt_decl_varnames_tagged([$1],\n\t\t\tlt_decl_tag_varnames([[, ]], m4_shift($@))))dnl\n])\n\n\n# _LT_CONFIG_STATUS_DECLARE([VARNAME])\n# ------------------------------------\n# Quote a variable value, and forward it to 'config.status' so that its\n# declaration there will have the same value as in 'configure'.  VARNAME\n# must have a single quote delimited value for this to work.\nm4_define([_LT_CONFIG_STATUS_DECLARE],\n[$1='`$ECHO \"$][$1\" | $SED \"$delay_single_quote_subst\"`'])\n\n\n# _LT_CONFIG_STATUS_DECLARATIONS\n# ------------------------------\n# We delimit libtool config variables with single quotes, so when\n# we write them to config.status, we have to be sure to quote all\n# embedded single quotes properly.  In configure, this macro expands\n# each variable declared with _LT_DECL (and _LT_TAGDECL) into:\n#\n#    <var>='`$ECHO \"$<var>\" | $SED \"$delay_single_quote_subst\"`'\nm4_defun([_LT_CONFIG_STATUS_DECLARATIONS],\n[m4_foreach([_lt_var], m4_quote(lt_decl_all_varnames),\n    [m4_n([_LT_CONFIG_STATUS_DECLARE(_lt_var)])])])\n\n\n# _LT_LIBTOOL_TAGS\n# ----------------\n# Output comment and list of tags supported by the script\nm4_defun([_LT_LIBTOOL_TAGS],\n[_LT_FORMAT_COMMENT([The names of the tagged configurations supported by this script])dnl\navailable_tags='_LT_TAGS'dnl\n])\n\n\n# _LT_LIBTOOL_DECLARE(VARNAME, [TAG])\n# -----------------------------------\n# Extract the dictionary values for VARNAME (optionally with TAG) and\n# expand to a commented shell variable setting:\n#\n#    # Some comment about what VAR is for.\n#    visible_name=$lt_internal_name\nm4_define([_LT_LIBTOOL_DECLARE],\n[_LT_FORMAT_COMMENT(m4_quote(lt_dict_fetch([lt_decl_dict], [$1],\n\t\t\t\t\t   [description])))[]dnl\nm4_pushdef([_libtool_name],\n    m4_quote(lt_dict_fetch([lt_decl_dict], [$1], [libtool_name])))[]dnl\nm4_case(m4_quote(lt_dict_fetch([lt_decl_dict], [$1], [value])),\n    [0], [_libtool_name=[$]$1],\n    [1], [_libtool_name=$lt_[]$1],\n    [2], [_libtool_name=$lt_[]$1],\n    [_libtool_name=lt_dict_fetch([lt_decl_dict], [$1], [value])])[]dnl\nm4_ifval([$2], [_$2])[]m4_popdef([_libtool_name])[]dnl\n])\n\n\n# _LT_LIBTOOL_CONFIG_VARS\n# -----------------------\n# Produce commented declarations of non-tagged libtool config variables\n# suitable for insertion in the LIBTOOL CONFIG section of the 'libtool'\n# script.  Tagged libtool config variables (even for the LIBTOOL CONFIG\n# section) are produced by _LT_LIBTOOL_TAG_VARS.\nm4_defun([_LT_LIBTOOL_CONFIG_VARS],\n[m4_foreach([_lt_var],\n    m4_quote(_lt_decl_filter([tagged?], [no], [], lt_decl_varnames)),\n    [m4_n([_LT_LIBTOOL_DECLARE(_lt_var)])])])\n\n\n# _LT_LIBTOOL_TAG_VARS(TAG)\n# -------------------------\nm4_define([_LT_LIBTOOL_TAG_VARS],\n[m4_foreach([_lt_var], m4_quote(lt_decl_tag_varnames),\n    [m4_n([_LT_LIBTOOL_DECLARE(_lt_var, [$1])])])])\n\n\n# _LT_TAGVAR(VARNAME, [TAGNAME])\n# ------------------------------\nm4_define([_LT_TAGVAR], [m4_ifval([$2], [$1_$2], [$1])])\n\n\n# _LT_CONFIG_COMMANDS\n# -------------------\n# Send accumulated output to $CONFIG_STATUS.  Thanks to the lists of\n# variables for single and double quote escaping we saved from calls\n# to _LT_DECL, we can put quote escaped variables declarations\n# into 'config.status', and then the shell code to quote escape them in\n# for loops in 'config.status'.  Finally, any additional code accumulated\n# from calls to _LT_CONFIG_LIBTOOL_INIT is expanded.\nm4_defun([_LT_CONFIG_COMMANDS],\n[AC_PROVIDE_IFELSE([LT_OUTPUT],\n\tdnl If the libtool generation code has been placed in $CONFIG_LT,\n\tdnl instead of duplicating it all over again into config.status,\n\tdnl then we will have config.status run $CONFIG_LT later, so it\n\tdnl needs to know what name is stored there:\n        [AC_CONFIG_COMMANDS([libtool],\n            [$SHELL $CONFIG_LT || AS_EXIT(1)], [CONFIG_LT='$CONFIG_LT'])],\n    dnl If the libtool generation code is destined for config.status,\n    dnl expand the accumulated commands and init code now:\n    [AC_CONFIG_COMMANDS([libtool],\n        [_LT_OUTPUT_LIBTOOL_COMMANDS], [_LT_OUTPUT_LIBTOOL_COMMANDS_INIT])])\n])#_LT_CONFIG_COMMANDS\n\n\n# Initialize.\nm4_define([_LT_OUTPUT_LIBTOOL_COMMANDS_INIT],\n[\n\n# The HP-UX ksh and POSIX shell print the target directory to stdout\n# if CDPATH is set.\n(unset CDPATH) >/dev/null 2>&1 && unset CDPATH\n\nsed_quote_subst='$sed_quote_subst'\ndouble_quote_subst='$double_quote_subst'\ndelay_variable_subst='$delay_variable_subst'\n_LT_CONFIG_STATUS_DECLARATIONS\nLTCC='$LTCC'\nLTCFLAGS='$LTCFLAGS'\ncompiler='$compiler_DEFAULT'\n\n# A function that is used when there is no print builtin or printf.\nfunc_fallback_echo ()\n{\n  eval 'cat <<_LTECHO_EOF\n\\$[]1\n_LTECHO_EOF'\n}\n\n# Quote evaled strings.\nfor var in lt_decl_all_varnames([[ \\\n]], lt_decl_quote_varnames); do\n    case \\`eval \\\\\\\\\\$ECHO \\\\\\\\\"\"\\\\\\\\\\$\\$var\"\\\\\\\\\"\\` in\n    *[[\\\\\\\\\\\\\\`\\\\\"\\\\\\$]]*)\n      eval \"lt_\\$var=\\\\\\\\\\\\\"\\\\\\`\\\\\\$ECHO \\\\\"\\\\\\$\\$var\\\\\" | \\\\\\$SED \\\\\"\\\\\\$sed_quote_subst\\\\\"\\\\\\`\\\\\\\\\\\\\"\" ## exclude from sc_prohibit_nested_quotes\n      ;;\n    *)\n      eval \"lt_\\$var=\\\\\\\\\\\\\"\\\\\\$\\$var\\\\\\\\\\\\\"\"\n      ;;\n    esac\ndone\n\n# Double-quote double-evaled strings.\nfor var in lt_decl_all_varnames([[ \\\n]], lt_decl_dquote_varnames); do\n    case \\`eval \\\\\\\\\\$ECHO \\\\\\\\\"\"\\\\\\\\\\$\\$var\"\\\\\\\\\"\\` in\n    *[[\\\\\\\\\\\\\\`\\\\\"\\\\\\$]]*)\n      eval \"lt_\\$var=\\\\\\\\\\\\\"\\\\\\`\\\\\\$ECHO \\\\\"\\\\\\$\\$var\\\\\" | \\\\\\$SED -e \\\\\"\\\\\\$double_quote_subst\\\\\" -e \\\\\"\\\\\\$sed_quote_subst\\\\\" -e \\\\\"\\\\\\$delay_variable_subst\\\\\"\\\\\\`\\\\\\\\\\\\\"\" ## exclude from sc_prohibit_nested_quotes\n      ;;\n    *)\n      eval \"lt_\\$var=\\\\\\\\\\\\\"\\\\\\$\\$var\\\\\\\\\\\\\"\"\n      ;;\n    esac\ndone\n\n_LT_OUTPUT_LIBTOOL_INIT\n])\n\n# _LT_GENERATED_FILE_INIT(FILE, [COMMENT])\n# ------------------------------------\n# Generate a child script FILE with all initialization necessary to\n# reuse the environment learned by the parent script, and make the\n# file executable.  If COMMENT is supplied, it is inserted after the\n# '#!' sequence but before initialization text begins.  After this\n# macro, additional text can be appended to FILE to form the body of\n# the child script.  The macro ends with non-zero status if the\n# file could not be fully written (such as if the disk is full).\nm4_ifdef([AS_INIT_GENERATED],\n[m4_defun([_LT_GENERATED_FILE_INIT],[AS_INIT_GENERATED($@)])],\n[m4_defun([_LT_GENERATED_FILE_INIT],\n[m4_require([AS_PREPARE])]dnl\n[m4_pushdef([AS_MESSAGE_LOG_FD])]dnl\n[lt_write_fail=0\ncat >$1 <<_ASEOF || lt_write_fail=1\n#! $SHELL\n# Generated by $as_me.\n$2\nSHELL=\\${CONFIG_SHELL-$SHELL}\nexport SHELL\n_ASEOF\ncat >>$1 <<\\_ASEOF || lt_write_fail=1\nAS_SHELL_SANITIZE\n_AS_PREPARE\nexec AS_MESSAGE_FD>&1\n_ASEOF\ntest 0 = \"$lt_write_fail\" && chmod +x $1[]dnl\nm4_popdef([AS_MESSAGE_LOG_FD])])])# _LT_GENERATED_FILE_INIT\n\n# LT_OUTPUT\n# ---------\n# This macro allows early generation of the libtool script (before\n# AC_OUTPUT is called), incase it is used in configure for compilation\n# tests.\nAC_DEFUN([LT_OUTPUT],\n[: ${CONFIG_LT=./config.lt}\nAC_MSG_NOTICE([creating $CONFIG_LT])\n_LT_GENERATED_FILE_INIT([\"$CONFIG_LT\"],\n[# Run this file to recreate a libtool stub with the current configuration.])\n\ncat >>\"$CONFIG_LT\" <<\\_LTEOF\nlt_cl_silent=false\nexec AS_MESSAGE_LOG_FD>>config.log\n{\n  echo\n  AS_BOX([Running $as_me.])\n} >&AS_MESSAGE_LOG_FD\n\nlt_cl_help=\"\\\n'$as_me' creates a local libtool stub from the current configuration,\nfor use in further configure time tests before the real libtool is\ngenerated.\n\nUsage: $[0] [[OPTIONS]]\n\n  -h, --help      print this help, then exit\n  -V, --version   print version number, then exit\n  -q, --quiet     do not print progress messages\n  -d, --debug     don't remove temporary files\n\nReport bugs to <bug-libtool@gnu.org>.\"\n\nlt_cl_version=\"\\\nm4_ifset([AC_PACKAGE_NAME], [AC_PACKAGE_NAME ])config.lt[]dnl\nm4_ifset([AC_PACKAGE_VERSION], [ AC_PACKAGE_VERSION])\nconfigured by $[0], generated by m4_PACKAGE_STRING.\n\nCopyright (C) 2011 Free Software Foundation, Inc.\nThis config.lt script is free software; the Free Software Foundation\ngives unlimited permision to copy, distribute and modify it.\"\n\nwhile test 0 != $[#]\ndo\n  case $[1] in\n    --version | --v* | -V )\n      echo \"$lt_cl_version\"; exit 0 ;;\n    --help | --h* | -h )\n      echo \"$lt_cl_help\"; exit 0 ;;\n    --debug | --d* | -d )\n      debug=: ;;\n    --quiet | --q* | --silent | --s* | -q )\n      lt_cl_silent=: ;;\n\n    -*) AC_MSG_ERROR([unrecognized option: $[1]\nTry '$[0] --help' for more information.]) ;;\n\n    *) AC_MSG_ERROR([unrecognized argument: $[1]\nTry '$[0] --help' for more information.]) ;;\n  esac\n  shift\ndone\n\nif $lt_cl_silent; then\n  exec AS_MESSAGE_FD>/dev/null\nfi\n_LTEOF\n\ncat >>\"$CONFIG_LT\" <<_LTEOF\n_LT_OUTPUT_LIBTOOL_COMMANDS_INIT\n_LTEOF\n\ncat >>\"$CONFIG_LT\" <<\\_LTEOF\nAC_MSG_NOTICE([creating $ofile])\n_LT_OUTPUT_LIBTOOL_COMMANDS\nAS_EXIT(0)\n_LTEOF\nchmod +x \"$CONFIG_LT\"\n\n# configure is writing to config.log, but config.lt does its own redirection,\n# appending to config.log, which fails on DOS, as config.log is still kept\n# open by configure.  Here we exec the FD to /dev/null, effectively closing\n# config.log, so it can be properly (re)opened and appended to by config.lt.\nlt_cl_success=:\ntest yes = \"$silent\" &&\n  lt_config_lt_args=\"$lt_config_lt_args --quiet\"\nexec AS_MESSAGE_LOG_FD>/dev/null\n$SHELL \"$CONFIG_LT\" $lt_config_lt_args || lt_cl_success=false\nexec AS_MESSAGE_LOG_FD>>config.log\n$lt_cl_success || AS_EXIT(1)\n])# LT_OUTPUT\n\n\n# _LT_CONFIG(TAG)\n# ---------------\n# If TAG is the built-in tag, create an initial libtool script with a\n# default configuration from the untagged config vars.  Otherwise add code\n# to config.status for appending the configuration named by TAG from the\n# matching tagged config vars.\nm4_defun([_LT_CONFIG],\n[m4_require([_LT_FILEUTILS_DEFAULTS])dnl\n_LT_CONFIG_SAVE_COMMANDS([\n  m4_define([_LT_TAG], m4_if([$1], [], [C], [$1]))dnl\n  m4_if(_LT_TAG, [C], [\n    # See if we are running on zsh, and set the options that allow our\n    # commands through without removal of \\ escapes.\n    if test -n \"${ZSH_VERSION+set}\"; then\n      setopt NO_GLOB_SUBST\n    fi\n\n    cfgfile=${ofile}T\n    trap \"$RM \\\"$cfgfile\\\"; exit 1\" 1 2 15\n    $RM \"$cfgfile\"\n\n    cat <<_LT_EOF >> \"$cfgfile\"\n#! $SHELL\n# Generated automatically by $as_me ($PACKAGE) $VERSION\n# NOTE: Changes made to this file will be lost: look at ltmain.sh.\n\n# Provide generalized library-building support services.\n# Written by Gordon Matzigkeit, 1996\n\n_LT_COPYING\n_LT_LIBTOOL_TAGS\n\n# Configured defaults for sys_lib_dlsearch_path munging.\n: \\${LT_SYS_LIBRARY_PATH=\"$configure_time_lt_sys_library_path\"}\n\n# ### BEGIN LIBTOOL CONFIG\n_LT_LIBTOOL_CONFIG_VARS\n_LT_LIBTOOL_TAG_VARS\n# ### END LIBTOOL CONFIG\n\n_LT_EOF\n\n    cat <<'_LT_EOF' >> \"$cfgfile\"\n\n# ### BEGIN FUNCTIONS SHARED WITH CONFIGURE\n\n_LT_PREPARE_MUNGE_PATH_LIST\n_LT_PREPARE_CC_BASENAME\n\n# ### END FUNCTIONS SHARED WITH CONFIGURE\n\n_LT_EOF\n\n  case $host_os in\n  aix3*)\n    cat <<\\_LT_EOF >> \"$cfgfile\"\n# AIX sometimes has problems with the GCC collect2 program.  For some\n# reason, if we set the COLLECT_NAMES environment variable, the problems\n# vanish in a puff of smoke.\nif test set != \"${COLLECT_NAMES+set}\"; then\n  COLLECT_NAMES=\n  export COLLECT_NAMES\nfi\n_LT_EOF\n    ;;\n  esac\n\n  _LT_PROG_LTMAIN\n\n  # We use sed instead of cat because bash on DJGPP gets confused if\n  # if finds mixed CR/LF and LF-only lines.  Since sed operates in\n  # text mode, it properly converts lines to CR/LF.  This bash problem\n  # is reportedly fixed, but why not run on old versions too?\n  sed '$q' \"$ltmain\" >> \"$cfgfile\" \\\n     || (rm -f \"$cfgfile\"; exit 1)\n\n   mv -f \"$cfgfile\" \"$ofile\" ||\n    (rm -f \"$ofile\" && cp \"$cfgfile\" \"$ofile\" && rm -f \"$cfgfile\")\n  chmod +x \"$ofile\"\n],\n[cat <<_LT_EOF >> \"$ofile\"\n\ndnl Unfortunately we have to use $1 here, since _LT_TAG is not expanded\ndnl in a comment (ie after a #).\n# ### BEGIN LIBTOOL TAG CONFIG: $1\n_LT_LIBTOOL_TAG_VARS(_LT_TAG)\n# ### END LIBTOOL TAG CONFIG: $1\n_LT_EOF\n])dnl /m4_if\n],\n[m4_if([$1], [], [\n    PACKAGE='$PACKAGE'\n    VERSION='$VERSION'\n    RM='$RM'\n    ofile='$ofile'], [])\n])dnl /_LT_CONFIG_SAVE_COMMANDS\n])# _LT_CONFIG\n\n\n# LT_SUPPORTED_TAG(TAG)\n# ---------------------\n# Trace this macro to discover what tags are supported by the libtool\n# --tag option, using:\n#    autoconf --trace 'LT_SUPPORTED_TAG:$1'\nAC_DEFUN([LT_SUPPORTED_TAG], [])\n\n\n# C support is built-in for now\nm4_define([_LT_LANG_C_enabled], [])\nm4_define([_LT_TAGS], [])\n\n\n# LT_LANG(LANG)\n# -------------\n# Enable libtool support for the given language if not already enabled.\nAC_DEFUN([LT_LANG],\n[AC_BEFORE([$0], [LT_OUTPUT])dnl\nm4_case([$1],\n  [C],\t\t\t[_LT_LANG(C)],\n  [C++],\t\t[_LT_LANG(CXX)],\n  [Go],\t\t\t[_LT_LANG(GO)],\n  [Java],\t\t[_LT_LANG(GCJ)],\n  [Fortran 77],\t\t[_LT_LANG(F77)],\n  [Fortran],\t\t[_LT_LANG(FC)],\n  [Windows Resource],\t[_LT_LANG(RC)],\n  [m4_ifdef([_LT_LANG_]$1[_CONFIG],\n    [_LT_LANG($1)],\n    [m4_fatal([$0: unsupported language: \"$1\"])])])dnl\n])# LT_LANG\n\n\n# _LT_LANG(LANGNAME)\n# ------------------\nm4_defun([_LT_LANG],\n[m4_ifdef([_LT_LANG_]$1[_enabled], [],\n  [LT_SUPPORTED_TAG([$1])dnl\n  m4_append([_LT_TAGS], [$1 ])dnl\n  m4_define([_LT_LANG_]$1[_enabled], [])dnl\n  _LT_LANG_$1_CONFIG($1)])dnl\n])# _LT_LANG\n\n\nm4_ifndef([AC_PROG_GO], [\n############################################################\n# NOTE: This macro has been submitted for inclusion into   #\n#  GNU Autoconf as AC_PROG_GO.  When it is available in    #\n#  a released version of Autoconf we should remove this    #\n#  macro and use it instead.                               #\n############################################################\nm4_defun([AC_PROG_GO],\n[AC_LANG_PUSH(Go)dnl\nAC_ARG_VAR([GOC],     [Go compiler command])dnl\nAC_ARG_VAR([GOFLAGS], [Go compiler flags])dnl\n_AC_ARG_VAR_LDFLAGS()dnl\nAC_CHECK_TOOL(GOC, gccgo)\nif test -z \"$GOC\"; then\n  if test -n \"$ac_tool_prefix\"; then\n    AC_CHECK_PROG(GOC, [${ac_tool_prefix}gccgo], [${ac_tool_prefix}gccgo])\n  fi\nfi\nif test -z \"$GOC\"; then\n  AC_CHECK_PROG(GOC, gccgo, gccgo, false)\nfi\n])#m4_defun\n])#m4_ifndef\n\n\n# _LT_LANG_DEFAULT_CONFIG\n# -----------------------\nm4_defun([_LT_LANG_DEFAULT_CONFIG],\n[AC_PROVIDE_IFELSE([AC_PROG_CXX],\n  [LT_LANG(CXX)],\n  [m4_define([AC_PROG_CXX], defn([AC_PROG_CXX])[LT_LANG(CXX)])])\n\nAC_PROVIDE_IFELSE([AC_PROG_F77],\n  [LT_LANG(F77)],\n  [m4_define([AC_PROG_F77], defn([AC_PROG_F77])[LT_LANG(F77)])])\n\nAC_PROVIDE_IFELSE([AC_PROG_FC],\n  [LT_LANG(FC)],\n  [m4_define([AC_PROG_FC], defn([AC_PROG_FC])[LT_LANG(FC)])])\n\ndnl The call to [A][M_PROG_GCJ] is quoted like that to stop aclocal\ndnl pulling things in needlessly.\nAC_PROVIDE_IFELSE([AC_PROG_GCJ],\n  [LT_LANG(GCJ)],\n  [AC_PROVIDE_IFELSE([A][M_PROG_GCJ],\n    [LT_LANG(GCJ)],\n    [AC_PROVIDE_IFELSE([LT_PROG_GCJ],\n      [LT_LANG(GCJ)],\n      [m4_ifdef([AC_PROG_GCJ],\n\t[m4_define([AC_PROG_GCJ], defn([AC_PROG_GCJ])[LT_LANG(GCJ)])])\n       m4_ifdef([A][M_PROG_GCJ],\n\t[m4_define([A][M_PROG_GCJ], defn([A][M_PROG_GCJ])[LT_LANG(GCJ)])])\n       m4_ifdef([LT_PROG_GCJ],\n\t[m4_define([LT_PROG_GCJ], defn([LT_PROG_GCJ])[LT_LANG(GCJ)])])])])])\n\nAC_PROVIDE_IFELSE([AC_PROG_GO],\n  [LT_LANG(GO)],\n  [m4_define([AC_PROG_GO], defn([AC_PROG_GO])[LT_LANG(GO)])])\n\nAC_PROVIDE_IFELSE([LT_PROG_RC],\n  [LT_LANG(RC)],\n  [m4_define([LT_PROG_RC], defn([LT_PROG_RC])[LT_LANG(RC)])])\n])# _LT_LANG_DEFAULT_CONFIG\n\n# Obsolete macros:\nAU_DEFUN([AC_LIBTOOL_CXX], [LT_LANG(C++)])\nAU_DEFUN([AC_LIBTOOL_F77], [LT_LANG(Fortran 77)])\nAU_DEFUN([AC_LIBTOOL_FC], [LT_LANG(Fortran)])\nAU_DEFUN([AC_LIBTOOL_GCJ], [LT_LANG(Java)])\nAU_DEFUN([AC_LIBTOOL_RC], [LT_LANG(Windows Resource)])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_LIBTOOL_CXX], [])\ndnl AC_DEFUN([AC_LIBTOOL_F77], [])\ndnl AC_DEFUN([AC_LIBTOOL_FC], [])\ndnl AC_DEFUN([AC_LIBTOOL_GCJ], [])\ndnl AC_DEFUN([AC_LIBTOOL_RC], [])\n\n\n# _LT_TAG_COMPILER\n# ----------------\nm4_defun([_LT_TAG_COMPILER],\n[AC_REQUIRE([AC_PROG_CC])dnl\n\n_LT_DECL([LTCC], [CC], [1], [A C compiler])dnl\n_LT_DECL([LTCFLAGS], [CFLAGS], [1], [LTCC compiler flags])dnl\n_LT_TAGDECL([CC], [compiler], [1], [A language specific compiler])dnl\n_LT_TAGDECL([with_gcc], [GCC], [0], [Is the compiler the GNU compiler?])dnl\n\n# If no C compiler was specified, use CC.\nLTCC=${LTCC-\"$CC\"}\n\n# If no C compiler flags were specified, use CFLAGS.\nLTCFLAGS=${LTCFLAGS-\"$CFLAGS\"}\n\n# Allow CC to be a program name with arguments.\ncompiler=$CC\n])# _LT_TAG_COMPILER\n\n\n# _LT_COMPILER_BOILERPLATE\n# ------------------------\n# Check for compiler boilerplate output or warnings with\n# the simple compiler test code.\nm4_defun([_LT_COMPILER_BOILERPLATE],\n[m4_require([_LT_DECL_SED])dnl\nac_outfile=conftest.$ac_objext\necho \"$lt_simple_compile_test_code\" >conftest.$ac_ext\neval \"$ac_compile\" 2>&1 >/dev/null | $SED '/^$/d; /^ *+/d' >conftest.err\n_lt_compiler_boilerplate=`cat conftest.err`\n$RM conftest*\n])# _LT_COMPILER_BOILERPLATE\n\n\n# _LT_LINKER_BOILERPLATE\n# ----------------------\n# Check for linker boilerplate output or warnings with\n# the simple link test code.\nm4_defun([_LT_LINKER_BOILERPLATE],\n[m4_require([_LT_DECL_SED])dnl\nac_outfile=conftest.$ac_objext\necho \"$lt_simple_link_test_code\" >conftest.$ac_ext\neval \"$ac_link\" 2>&1 >/dev/null | $SED '/^$/d; /^ *+/d' >conftest.err\n_lt_linker_boilerplate=`cat conftest.err`\n$RM -r conftest*\n])# _LT_LINKER_BOILERPLATE\n\n# _LT_REQUIRED_DARWIN_CHECKS\n# -------------------------\nm4_defun_once([_LT_REQUIRED_DARWIN_CHECKS],[\n  case $host_os in\n    rhapsody* | darwin*)\n    AC_CHECK_TOOL([DSYMUTIL], [dsymutil], [:])\n    AC_CHECK_TOOL([NMEDIT], [nmedit], [:])\n    AC_CHECK_TOOL([LIPO], [lipo], [:])\n    AC_CHECK_TOOL([OTOOL], [otool], [:])\n    AC_CHECK_TOOL([OTOOL64], [otool64], [:])\n    _LT_DECL([], [DSYMUTIL], [1],\n      [Tool to manipulate archived DWARF debug symbol files on Mac OS X])\n    _LT_DECL([], [NMEDIT], [1],\n      [Tool to change global to local symbols on Mac OS X])\n    _LT_DECL([], [LIPO], [1],\n      [Tool to manipulate fat objects and archives on Mac OS X])\n    _LT_DECL([], [OTOOL], [1],\n      [ldd/readelf like tool for Mach-O binaries on Mac OS X])\n    _LT_DECL([], [OTOOL64], [1],\n      [ldd/readelf like tool for 64 bit Mach-O binaries on Mac OS X 10.4])\n\n    AC_CACHE_CHECK([for -single_module linker flag],[lt_cv_apple_cc_single_mod],\n      [lt_cv_apple_cc_single_mod=no\n      if test -z \"$LT_MULTI_MODULE\"; then\n\t# By default we will add the -single_module flag. You can override\n\t# by either setting the environment variable LT_MULTI_MODULE\n\t# non-empty at configure time, or by adding -multi_module to the\n\t# link flags.\n\trm -rf libconftest.dylib*\n\techo \"int foo(void){return 1;}\" > conftest.c\n\techo \"$LTCC $LTCFLAGS $LDFLAGS -o libconftest.dylib \\\n-dynamiclib -Wl,-single_module conftest.c\" >&AS_MESSAGE_LOG_FD\n\t$LTCC $LTCFLAGS $LDFLAGS -o libconftest.dylib \\\n\t  -dynamiclib -Wl,-single_module conftest.c 2>conftest.err\n        _lt_result=$?\n\t# If there is a non-empty error log, and \"single_module\"\n\t# appears in it, assume the flag caused a linker warning\n        if test -s conftest.err && $GREP single_module conftest.err; then\n\t  cat conftest.err >&AS_MESSAGE_LOG_FD\n\t# Otherwise, if the output was created with a 0 exit code from\n\t# the compiler, it worked.\n\telif test -f libconftest.dylib && test 0 = \"$_lt_result\"; then\n\t  lt_cv_apple_cc_single_mod=yes\n\telse\n\t  cat conftest.err >&AS_MESSAGE_LOG_FD\n\tfi\n\trm -rf libconftest.dylib*\n\trm -f conftest.*\n      fi])\n\n    AC_CACHE_CHECK([for -exported_symbols_list linker flag],\n      [lt_cv_ld_exported_symbols_list],\n      [lt_cv_ld_exported_symbols_list=no\n      save_LDFLAGS=$LDFLAGS\n      echo \"_main\" > conftest.sym\n      LDFLAGS=\"$LDFLAGS -Wl,-exported_symbols_list,conftest.sym\"\n      AC_LINK_IFELSE([AC_LANG_PROGRAM([],[])],\n\t[lt_cv_ld_exported_symbols_list=yes],\n\t[lt_cv_ld_exported_symbols_list=no])\n\tLDFLAGS=$save_LDFLAGS\n    ])\n\n    AC_CACHE_CHECK([for -force_load linker flag],[lt_cv_ld_force_load],\n      [lt_cv_ld_force_load=no\n      cat > conftest.c << _LT_EOF\nint forced_loaded() { return 2;}\n_LT_EOF\n      echo \"$LTCC $LTCFLAGS -c -o conftest.o conftest.c\" >&AS_MESSAGE_LOG_FD\n      $LTCC $LTCFLAGS -c -o conftest.o conftest.c 2>&AS_MESSAGE_LOG_FD\n      echo \"$AR cru libconftest.a conftest.o\" >&AS_MESSAGE_LOG_FD\n      $AR cru libconftest.a conftest.o 2>&AS_MESSAGE_LOG_FD\n      echo \"$RANLIB libconftest.a\" >&AS_MESSAGE_LOG_FD\n      $RANLIB libconftest.a 2>&AS_MESSAGE_LOG_FD\n      cat > conftest.c << _LT_EOF\nint main() { return 0;}\n_LT_EOF\n      echo \"$LTCC $LTCFLAGS $LDFLAGS -o conftest conftest.c -Wl,-force_load,./libconftest.a\" >&AS_MESSAGE_LOG_FD\n      $LTCC $LTCFLAGS $LDFLAGS -o conftest conftest.c -Wl,-force_load,./libconftest.a 2>conftest.err\n      _lt_result=$?\n      if test -s conftest.err && $GREP force_load conftest.err; then\n\tcat conftest.err >&AS_MESSAGE_LOG_FD\n      elif test -f conftest && test 0 = \"$_lt_result\" && $GREP forced_load conftest >/dev/null 2>&1; then\n\tlt_cv_ld_force_load=yes\n      else\n\tcat conftest.err >&AS_MESSAGE_LOG_FD\n      fi\n        rm -f conftest.err libconftest.a conftest conftest.c\n        rm -rf conftest.dSYM\n    ])\n    case $host_os in\n    rhapsody* | darwin1.[[012]])\n      _lt_dar_allow_undefined='$wl-undefined ${wl}suppress' ;;\n    darwin1.*)\n      _lt_dar_allow_undefined='$wl-flat_namespace $wl-undefined ${wl}suppress' ;;\n    darwin*) # darwin 5.x on\n      # if running on 10.5 or later, the deployment target defaults\n      # to the OS version, if on x86, and 10.4, the deployment\n      # target defaults to 10.4. Don't you love it?\n      case ${MACOSX_DEPLOYMENT_TARGET-10.0},$host in\n\t10.0,*86*-darwin8*|10.0,*-darwin[[91]]*)\n\t  _lt_dar_allow_undefined='$wl-undefined ${wl}dynamic_lookup' ;;\n\t10.[[012]][[,.]]*)\n\t  _lt_dar_allow_undefined='$wl-flat_namespace $wl-undefined ${wl}suppress' ;;\n\t10.*)\n\t  _lt_dar_allow_undefined='$wl-undefined ${wl}dynamic_lookup' ;;\n      esac\n    ;;\n  esac\n    if test yes = \"$lt_cv_apple_cc_single_mod\"; then\n      _lt_dar_single_mod='$single_module'\n    fi\n    if test yes = \"$lt_cv_ld_exported_symbols_list\"; then\n      _lt_dar_export_syms=' $wl-exported_symbols_list,$output_objdir/$libname-symbols.expsym'\n    else\n      _lt_dar_export_syms='~$NMEDIT -s $output_objdir/$libname-symbols.expsym $lib'\n    fi\n    if test : != \"$DSYMUTIL\" && test no = \"$lt_cv_ld_force_load\"; then\n      _lt_dsymutil='~$DSYMUTIL $lib || :'\n    else\n      _lt_dsymutil=\n    fi\n    ;;\n  esac\n])\n\n\n# _LT_DARWIN_LINKER_FEATURES([TAG])\n# ---------------------------------\n# Checks for linker and compiler features on darwin\nm4_defun([_LT_DARWIN_LINKER_FEATURES],\n[\n  m4_require([_LT_REQUIRED_DARWIN_CHECKS])\n  _LT_TAGVAR(archive_cmds_need_lc, $1)=no\n  _LT_TAGVAR(hardcode_direct, $1)=no\n  _LT_TAGVAR(hardcode_automatic, $1)=yes\n  _LT_TAGVAR(hardcode_shlibpath_var, $1)=unsupported\n  if test yes = \"$lt_cv_ld_force_load\"; then\n    _LT_TAGVAR(whole_archive_flag_spec, $1)='`for conv in $convenience\\\"\\\"; do test  -n \\\"$conv\\\" && new_convenience=\\\"$new_convenience $wl-force_load,$conv\\\"; done; func_echo_all \\\"$new_convenience\\\"`'\n    m4_case([$1], [F77], [_LT_TAGVAR(compiler_needs_object, $1)=yes],\n                  [FC],  [_LT_TAGVAR(compiler_needs_object, $1)=yes])\n  else\n    _LT_TAGVAR(whole_archive_flag_spec, $1)=''\n  fi\n  _LT_TAGVAR(link_all_deplibs, $1)=yes\n  _LT_TAGVAR(allow_undefined_flag, $1)=$_lt_dar_allow_undefined\n  case $cc_basename in\n     ifort*|nagfor*) _lt_dar_can_shared=yes ;;\n     *) _lt_dar_can_shared=$GCC ;;\n  esac\n  if test yes = \"$_lt_dar_can_shared\"; then\n    output_verbose_link_cmd=func_echo_all\n    _LT_TAGVAR(archive_cmds, $1)=\"\\$CC -dynamiclib \\$allow_undefined_flag -o \\$lib \\$libobjs \\$deplibs \\$compiler_flags -install_name \\$rpath/\\$soname \\$verstring $_lt_dar_single_mod$_lt_dsymutil\"\n    _LT_TAGVAR(module_cmds, $1)=\"\\$CC \\$allow_undefined_flag -o \\$lib -bundle \\$libobjs \\$deplibs \\$compiler_flags$_lt_dsymutil\"\n    _LT_TAGVAR(archive_expsym_cmds, $1)=\"sed 's|^|_|' < \\$export_symbols > \\$output_objdir/\\$libname-symbols.expsym~\\$CC -dynamiclib \\$allow_undefined_flag -o \\$lib \\$libobjs \\$deplibs \\$compiler_flags -install_name \\$rpath/\\$soname \\$verstring $_lt_dar_single_mod$_lt_dar_export_syms$_lt_dsymutil\"\n    _LT_TAGVAR(module_expsym_cmds, $1)=\"sed -e 's|^|_|' < \\$export_symbols > \\$output_objdir/\\$libname-symbols.expsym~\\$CC \\$allow_undefined_flag -o \\$lib -bundle \\$libobjs \\$deplibs \\$compiler_flags$_lt_dar_export_syms$_lt_dsymutil\"\n    m4_if([$1], [CXX],\n[   if test yes != \"$lt_cv_apple_cc_single_mod\"; then\n      _LT_TAGVAR(archive_cmds, $1)=\"\\$CC -r -keep_private_externs -nostdlib -o \\$lib-master.o \\$libobjs~\\$CC -dynamiclib \\$allow_undefined_flag -o \\$lib \\$lib-master.o \\$deplibs \\$compiler_flags -install_name \\$rpath/\\$soname \\$verstring$_lt_dsymutil\"\n      _LT_TAGVAR(archive_expsym_cmds, $1)=\"sed 's|^|_|' < \\$export_symbols > \\$output_objdir/\\$libname-symbols.expsym~\\$CC -r -keep_private_externs -nostdlib -o \\$lib-master.o \\$libobjs~\\$CC -dynamiclib \\$allow_undefined_flag -o \\$lib \\$lib-master.o \\$deplibs \\$compiler_flags -install_name \\$rpath/\\$soname \\$verstring$_lt_dar_export_syms$_lt_dsymutil\"\n    fi\n],[])\n  else\n  _LT_TAGVAR(ld_shlibs, $1)=no\n  fi\n])\n\n# _LT_SYS_MODULE_PATH_AIX([TAGNAME])\n# ----------------------------------\n# Links a minimal program and checks the executable\n# for the system default hardcoded library path. In most cases,\n# this is /usr/lib:/lib, but when the MPI compilers are used\n# the location of the communication and MPI libs are included too.\n# If we don't find anything, use the default library path according\n# to the aix ld manual.\n# Store the results from the different compilers for each TAGNAME.\n# Allow to override them for all tags through lt_cv_aix_libpath.\nm4_defun([_LT_SYS_MODULE_PATH_AIX],\n[m4_require([_LT_DECL_SED])dnl\nif test set = \"${lt_cv_aix_libpath+set}\"; then\n  aix_libpath=$lt_cv_aix_libpath\nelse\n  AC_CACHE_VAL([_LT_TAGVAR([lt_cv_aix_libpath_], [$1])],\n  [AC_LINK_IFELSE([AC_LANG_PROGRAM],[\n  lt_aix_libpath_sed='[\n      /Import File Strings/,/^$/ {\n\t  /^0/ {\n\t      s/^0  *\\([^ ]*\\) *$/\\1/\n\t      p\n\t  }\n      }]'\n  _LT_TAGVAR([lt_cv_aix_libpath_], [$1])=`dump -H conftest$ac_exeext 2>/dev/null | $SED -n -e \"$lt_aix_libpath_sed\"`\n  # Check for a 64-bit object if we didn't find anything.\n  if test -z \"$_LT_TAGVAR([lt_cv_aix_libpath_], [$1])\"; then\n    _LT_TAGVAR([lt_cv_aix_libpath_], [$1])=`dump -HX64 conftest$ac_exeext 2>/dev/null | $SED -n -e \"$lt_aix_libpath_sed\"`\n  fi],[])\n  if test -z \"$_LT_TAGVAR([lt_cv_aix_libpath_], [$1])\"; then\n    _LT_TAGVAR([lt_cv_aix_libpath_], [$1])=/usr/lib:/lib\n  fi\n  ])\n  aix_libpath=$_LT_TAGVAR([lt_cv_aix_libpath_], [$1])\nfi\n])# _LT_SYS_MODULE_PATH_AIX\n\n\n# _LT_SHELL_INIT(ARG)\n# -------------------\nm4_define([_LT_SHELL_INIT],\n[m4_divert_text([M4SH-INIT], [$1\n])])# _LT_SHELL_INIT\n\n\n\n# _LT_PROG_ECHO_BACKSLASH\n# -----------------------\n# Find how we can fake an echo command that does not interpret backslash.\n# In particular, with Autoconf 2.60 or later we add some code to the start\n# of the generated configure script that will find a shell with a builtin\n# printf (that we can use as an echo command).\nm4_defun([_LT_PROG_ECHO_BACKSLASH],\n[ECHO='\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'\nECHO=$ECHO$ECHO$ECHO$ECHO$ECHO\nECHO=$ECHO$ECHO$ECHO$ECHO$ECHO$ECHO\n\nAC_MSG_CHECKING([how to print strings])\n# Test print first, because it will be a builtin if present.\nif test \"X`( print -r -- -n ) 2>/dev/null`\" = X-n && \\\n   test \"X`print -r -- $ECHO 2>/dev/null`\" = \"X$ECHO\"; then\n  ECHO='print -r --'\nelif test \"X`printf %s $ECHO 2>/dev/null`\" = \"X$ECHO\"; then\n  ECHO='printf %s\\n'\nelse\n  # Use this function as a fallback that always works.\n  func_fallback_echo ()\n  {\n    eval 'cat <<_LTECHO_EOF\n$[]1\n_LTECHO_EOF'\n  }\n  ECHO='func_fallback_echo'\nfi\n\n# func_echo_all arg...\n# Invoke $ECHO with all args, space-separated.\nfunc_echo_all ()\n{\n    $ECHO \"$*\"\n}\n\ncase $ECHO in\n  printf*) AC_MSG_RESULT([printf]) ;;\n  print*) AC_MSG_RESULT([print -r]) ;;\n  *) AC_MSG_RESULT([cat]) ;;\nesac\n\nm4_ifdef([_AS_DETECT_SUGGESTED],\n[_AS_DETECT_SUGGESTED([\n  test -n \"${ZSH_VERSION+set}${BASH_VERSION+set}\" || (\n    ECHO='\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'\n    ECHO=$ECHO$ECHO$ECHO$ECHO$ECHO\n    ECHO=$ECHO$ECHO$ECHO$ECHO$ECHO$ECHO\n    PATH=/empty FPATH=/empty; export PATH FPATH\n    test \"X`printf %s $ECHO`\" = \"X$ECHO\" \\\n      || test \"X`print -r -- $ECHO`\" = \"X$ECHO\" )])])\n\n_LT_DECL([], [SHELL], [1], [Shell to use when invoking shell scripts])\n_LT_DECL([], [ECHO], [1], [An echo program that protects backslashes])\n])# _LT_PROG_ECHO_BACKSLASH\n\n\n# _LT_WITH_SYSROOT\n# ----------------\nAC_DEFUN([_LT_WITH_SYSROOT],\n[AC_MSG_CHECKING([for sysroot])\nAC_ARG_WITH([sysroot],\n[AS_HELP_STRING([--with-sysroot@<:@=DIR@:>@],\n  [Search for dependent libraries within DIR (or the compiler's sysroot\n   if not specified).])],\n[], [with_sysroot=no])\n\ndnl lt_sysroot will always be passed unquoted.  We quote it here\ndnl in case the user passed a directory name.\nlt_sysroot=\ncase $with_sysroot in #(\n yes)\n   if test yes = \"$GCC\"; then\n     lt_sysroot=`$CC --print-sysroot 2>/dev/null`\n   fi\n   ;; #(\n /*)\n   lt_sysroot=`echo \"$with_sysroot\" | sed -e \"$sed_quote_subst\"`\n   ;; #(\n no|'')\n   ;; #(\n *)\n   AC_MSG_RESULT([$with_sysroot])\n   AC_MSG_ERROR([The sysroot must be an absolute path.])\n   ;;\nesac\n\n AC_MSG_RESULT([${lt_sysroot:-no}])\n_LT_DECL([], [lt_sysroot], [0], [The root where to search for ]dnl\n[dependent libraries, and where our libraries should be installed.])])\n\n# _LT_ENABLE_LOCK\n# ---------------\nm4_defun([_LT_ENABLE_LOCK],\n[AC_ARG_ENABLE([libtool-lock],\n  [AS_HELP_STRING([--disable-libtool-lock],\n    [avoid locking (might break parallel builds)])])\ntest no = \"$enable_libtool_lock\" || enable_libtool_lock=yes\n\n# Some flags need to be propagated to the compiler or linker for good\n# libtool support.\ncase $host in\nia64-*-hpux*)\n  # Find out what ABI is being produced by ac_compile, and set mode\n  # options accordingly.\n  echo 'int i;' > conftest.$ac_ext\n  if AC_TRY_EVAL(ac_compile); then\n    case `/usr/bin/file conftest.$ac_objext` in\n      *ELF-32*)\n\tHPUX_IA64_MODE=32\n\t;;\n      *ELF-64*)\n\tHPUX_IA64_MODE=64\n\t;;\n    esac\n  fi\n  rm -rf conftest*\n  ;;\n*-*-irix6*)\n  # Find out what ABI is being produced by ac_compile, and set linker\n  # options accordingly.\n  echo '[#]line '$LINENO' \"configure\"' > conftest.$ac_ext\n  if AC_TRY_EVAL(ac_compile); then\n    if test yes = \"$lt_cv_prog_gnu_ld\"; then\n      case `/usr/bin/file conftest.$ac_objext` in\n\t*32-bit*)\n\t  LD=\"${LD-ld} -melf32bsmip\"\n\t  ;;\n\t*N32*)\n\t  LD=\"${LD-ld} -melf32bmipn32\"\n\t  ;;\n\t*64-bit*)\n\t  LD=\"${LD-ld} -melf64bmip\"\n\t;;\n      esac\n    else\n      case `/usr/bin/file conftest.$ac_objext` in\n\t*32-bit*)\n\t  LD=\"${LD-ld} -32\"\n\t  ;;\n\t*N32*)\n\t  LD=\"${LD-ld} -n32\"\n\t  ;;\n\t*64-bit*)\n\t  LD=\"${LD-ld} -64\"\n\t  ;;\n      esac\n    fi\n  fi\n  rm -rf conftest*\n  ;;\n\nmips64*-*linux*)\n  # Find out what ABI is being produced by ac_compile, and set linker\n  # options accordingly.\n  echo '[#]line '$LINENO' \"configure\"' > conftest.$ac_ext\n  if AC_TRY_EVAL(ac_compile); then\n    emul=elf\n    case `/usr/bin/file conftest.$ac_objext` in\n      *32-bit*)\n\temul=\"${emul}32\"\n\t;;\n      *64-bit*)\n\temul=\"${emul}64\"\n\t;;\n    esac\n    case `/usr/bin/file conftest.$ac_objext` in\n      *MSB*)\n\temul=\"${emul}btsmip\"\n\t;;\n      *LSB*)\n\temul=\"${emul}ltsmip\"\n\t;;\n    esac\n    case `/usr/bin/file conftest.$ac_objext` in\n      *N32*)\n\temul=\"${emul}n32\"\n\t;;\n    esac\n    LD=\"${LD-ld} -m $emul\"\n  fi\n  rm -rf conftest*\n  ;;\n\nx86_64-*kfreebsd*-gnu|x86_64-*linux*|powerpc*-*linux*| \\\ns390*-*linux*|s390*-*tpf*|sparc*-*linux*)\n  # Find out what ABI is being produced by ac_compile, and set linker\n  # options accordingly.  Note that the listed cases only cover the\n  # situations where additional linker options are needed (such as when\n  # doing 32-bit compilation for a host where ld defaults to 64-bit, or\n  # vice versa); the common cases where no linker options are needed do\n  # not appear in the list.\n  echo 'int i;' > conftest.$ac_ext\n  if AC_TRY_EVAL(ac_compile); then\n    case `/usr/bin/file conftest.o` in\n      *32-bit*)\n\tcase $host in\n\t  x86_64-*kfreebsd*-gnu)\n\t    LD=\"${LD-ld} -m elf_i386_fbsd\"\n\t    ;;\n\t  x86_64-*linux*)\n\t    case `/usr/bin/file conftest.o` in\n\t      *x86-64*)\n\t\tLD=\"${LD-ld} -m elf32_x86_64\"\n\t\t;;\n\t      *)\n\t\tLD=\"${LD-ld} -m elf_i386\"\n\t\t;;\n\t    esac\n\t    ;;\n\t  powerpc64le-*linux*)\n\t    LD=\"${LD-ld} -m elf32lppclinux\"\n\t    ;;\n\t  powerpc64-*linux*)\n\t    LD=\"${LD-ld} -m elf32ppclinux\"\n\t    ;;\n\t  s390x-*linux*)\n\t    LD=\"${LD-ld} -m elf_s390\"\n\t    ;;\n\t  sparc64-*linux*)\n\t    LD=\"${LD-ld} -m elf32_sparc\"\n\t    ;;\n\tesac\n\t;;\n      *64-bit*)\n\tcase $host in\n\t  x86_64-*kfreebsd*-gnu)\n\t    LD=\"${LD-ld} -m elf_x86_64_fbsd\"\n\t    ;;\n\t  x86_64-*linux*)\n\t    LD=\"${LD-ld} -m elf_x86_64\"\n\t    ;;\n\t  powerpcle-*linux*)\n\t    LD=\"${LD-ld} -m elf64lppc\"\n\t    ;;\n\t  powerpc-*linux*)\n\t    LD=\"${LD-ld} -m elf64ppc\"\n\t    ;;\n\t  s390*-*linux*|s390*-*tpf*)\n\t    LD=\"${LD-ld} -m elf64_s390\"\n\t    ;;\n\t  sparc*-*linux*)\n\t    LD=\"${LD-ld} -m elf64_sparc\"\n\t    ;;\n\tesac\n\t;;\n    esac\n  fi\n  rm -rf conftest*\n  ;;\n\n*-*-sco3.2v5*)\n  # On SCO OpenServer 5, we need -belf to get full-featured binaries.\n  SAVE_CFLAGS=$CFLAGS\n  CFLAGS=\"$CFLAGS -belf\"\n  AC_CACHE_CHECK([whether the C compiler needs -belf], lt_cv_cc_needs_belf,\n    [AC_LANG_PUSH(C)\n     AC_LINK_IFELSE([AC_LANG_PROGRAM([[]],[[]])],[lt_cv_cc_needs_belf=yes],[lt_cv_cc_needs_belf=no])\n     AC_LANG_POP])\n  if test yes != \"$lt_cv_cc_needs_belf\"; then\n    # this is probably gcc 2.8.0, egcs 1.0 or newer; no need for -belf\n    CFLAGS=$SAVE_CFLAGS\n  fi\n  ;;\n*-*solaris*)\n  # Find out what ABI is being produced by ac_compile, and set linker\n  # options accordingly.\n  echo 'int i;' > conftest.$ac_ext\n  if AC_TRY_EVAL(ac_compile); then\n    case `/usr/bin/file conftest.o` in\n    *64-bit*)\n      case $lt_cv_prog_gnu_ld in\n      yes*)\n        case $host in\n        i?86-*-solaris*|x86_64-*-solaris*)\n          LD=\"${LD-ld} -m elf_x86_64\"\n          ;;\n        sparc*-*-solaris*)\n          LD=\"${LD-ld} -m elf64_sparc\"\n          ;;\n        esac\n        # GNU ld 2.21 introduced _sol2 emulations.  Use them if available.\n        if ${LD-ld} -V | grep _sol2 >/dev/null 2>&1; then\n          LD=${LD-ld}_sol2\n        fi\n        ;;\n      *)\n\tif ${LD-ld} -64 -r -o conftest2.o conftest.o >/dev/null 2>&1; then\n\t  LD=\"${LD-ld} -64\"\n\tfi\n\t;;\n      esac\n      ;;\n    esac\n  fi\n  rm -rf conftest*\n  ;;\nesac\n\nneed_locks=$enable_libtool_lock\n])# _LT_ENABLE_LOCK\n\n\n# _LT_PROG_AR\n# -----------\nm4_defun([_LT_PROG_AR],\n[AC_CHECK_TOOLS(AR, [ar], false)\n: ${AR=ar}\n: ${AR_FLAGS=cru}\n_LT_DECL([], [AR], [1], [The archiver])\n_LT_DECL([], [AR_FLAGS], [1], [Flags to create an archive])\n\nAC_CACHE_CHECK([for archiver @FILE support], [lt_cv_ar_at_file],\n  [lt_cv_ar_at_file=no\n   AC_COMPILE_IFELSE([AC_LANG_PROGRAM],\n     [echo conftest.$ac_objext > conftest.lst\n      lt_ar_try='$AR $AR_FLAGS libconftest.a @conftest.lst >&AS_MESSAGE_LOG_FD'\n      AC_TRY_EVAL([lt_ar_try])\n      if test 0 -eq \"$ac_status\"; then\n\t# Ensure the archiver fails upon bogus file names.\n\trm -f conftest.$ac_objext libconftest.a\n\tAC_TRY_EVAL([lt_ar_try])\n\tif test 0 -ne \"$ac_status\"; then\n          lt_cv_ar_at_file=@\n        fi\n      fi\n      rm -f conftest.* libconftest.a\n     ])\n  ])\n\nif test no = \"$lt_cv_ar_at_file\"; then\n  archiver_list_spec=\nelse\n  archiver_list_spec=$lt_cv_ar_at_file\nfi\n_LT_DECL([], [archiver_list_spec], [1],\n  [How to feed a file listing to the archiver])\n])# _LT_PROG_AR\n\n\n# _LT_CMD_OLD_ARCHIVE\n# -------------------\nm4_defun([_LT_CMD_OLD_ARCHIVE],\n[_LT_PROG_AR\n\nAC_CHECK_TOOL(STRIP, strip, :)\ntest -z \"$STRIP\" && STRIP=:\n_LT_DECL([], [STRIP], [1], [A symbol stripping program])\n\nAC_CHECK_TOOL(RANLIB, ranlib, :)\ntest -z \"$RANLIB\" && RANLIB=:\n_LT_DECL([], [RANLIB], [1],\n    [Commands used to install an old-style archive])\n\n# Determine commands to create old-style static archives.\nold_archive_cmds='$AR $AR_FLAGS $oldlib$oldobjs'\nold_postinstall_cmds='chmod 644 $oldlib'\nold_postuninstall_cmds=\n\nif test -n \"$RANLIB\"; then\n  case $host_os in\n  bitrig* | openbsd*)\n    old_postinstall_cmds=\"$old_postinstall_cmds~\\$RANLIB -t \\$tool_oldlib\"\n    ;;\n  *)\n    old_postinstall_cmds=\"$old_postinstall_cmds~\\$RANLIB \\$tool_oldlib\"\n    ;;\n  esac\n  old_archive_cmds=\"$old_archive_cmds~\\$RANLIB \\$tool_oldlib\"\nfi\n\ncase $host_os in\n  darwin*)\n    lock_old_archive_extraction=yes ;;\n  *)\n    lock_old_archive_extraction=no ;;\nesac\n_LT_DECL([], [old_postinstall_cmds], [2])\n_LT_DECL([], [old_postuninstall_cmds], [2])\n_LT_TAGDECL([], [old_archive_cmds], [2],\n    [Commands used to build an old-style archive])\n_LT_DECL([], [lock_old_archive_extraction], [0],\n    [Whether to use a lock for old archive extraction])\n])# _LT_CMD_OLD_ARCHIVE\n\n\n# _LT_COMPILER_OPTION(MESSAGE, VARIABLE-NAME, FLAGS,\n#\t\t[OUTPUT-FILE], [ACTION-SUCCESS], [ACTION-FAILURE])\n# ----------------------------------------------------------------\n# Check whether the given compiler option works\nAC_DEFUN([_LT_COMPILER_OPTION],\n[m4_require([_LT_FILEUTILS_DEFAULTS])dnl\nm4_require([_LT_DECL_SED])dnl\nAC_CACHE_CHECK([$1], [$2],\n  [$2=no\n   m4_if([$4], , [ac_outfile=conftest.$ac_objext], [ac_outfile=$4])\n   echo \"$lt_simple_compile_test_code\" > conftest.$ac_ext\n   lt_compiler_flag=\"$3\"  ## exclude from sc_useless_quotes_in_assignment\n   # Insert the option either (1) after the last *FLAGS variable, or\n   # (2) before a word containing \"conftest.\", or (3) at the end.\n   # Note that $ac_compile itself does not contain backslashes and begins\n   # with a dollar sign (not a hyphen), so the echo should work correctly.\n   # The option is referenced via a variable to avoid confusing sed.\n   lt_compile=`echo \"$ac_compile\" | $SED \\\n   -e 's:.*FLAGS}\\{0,1\\} :&$lt_compiler_flag :; t' \\\n   -e 's: [[^ ]]*conftest\\.: $lt_compiler_flag&:; t' \\\n   -e 's:$: $lt_compiler_flag:'`\n   (eval echo \"\\\"\\$as_me:$LINENO: $lt_compile\\\"\" >&AS_MESSAGE_LOG_FD)\n   (eval \"$lt_compile\" 2>conftest.err)\n   ac_status=$?\n   cat conftest.err >&AS_MESSAGE_LOG_FD\n   echo \"$as_me:$LINENO: \\$? = $ac_status\" >&AS_MESSAGE_LOG_FD\n   if (exit $ac_status) && test -s \"$ac_outfile\"; then\n     # The compiler can only warn and ignore the option if not recognized\n     # So say no if there are warnings other than the usual output.\n     $ECHO \"$_lt_compiler_boilerplate\" | $SED '/^$/d' >conftest.exp\n     $SED '/^$/d; /^ *+/d' conftest.err >conftest.er2\n     if test ! -s conftest.er2 || diff conftest.exp conftest.er2 >/dev/null; then\n       $2=yes\n     fi\n   fi\n   $RM conftest*\n])\n\nif test yes = \"[$]$2\"; then\n    m4_if([$5], , :, [$5])\nelse\n    m4_if([$6], , :, [$6])\nfi\n])# _LT_COMPILER_OPTION\n\n# Old name:\nAU_ALIAS([AC_LIBTOOL_COMPILER_OPTION], [_LT_COMPILER_OPTION])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_LIBTOOL_COMPILER_OPTION], [])\n\n\n# _LT_LINKER_OPTION(MESSAGE, VARIABLE-NAME, FLAGS,\n#                  [ACTION-SUCCESS], [ACTION-FAILURE])\n# ----------------------------------------------------\n# Check whether the given linker option works\nAC_DEFUN([_LT_LINKER_OPTION],\n[m4_require([_LT_FILEUTILS_DEFAULTS])dnl\nm4_require([_LT_DECL_SED])dnl\nAC_CACHE_CHECK([$1], [$2],\n  [$2=no\n   save_LDFLAGS=$LDFLAGS\n   LDFLAGS=\"$LDFLAGS $3\"\n   echo \"$lt_simple_link_test_code\" > conftest.$ac_ext\n   if (eval $ac_link 2>conftest.err) && test -s conftest$ac_exeext; then\n     # The linker can only warn and ignore the option if not recognized\n     # So say no if there are warnings\n     if test -s conftest.err; then\n       # Append any errors to the config.log.\n       cat conftest.err 1>&AS_MESSAGE_LOG_FD\n       $ECHO \"$_lt_linker_boilerplate\" | $SED '/^$/d' > conftest.exp\n       $SED '/^$/d; /^ *+/d' conftest.err >conftest.er2\n       if diff conftest.exp conftest.er2 >/dev/null; then\n         $2=yes\n       fi\n     else\n       $2=yes\n     fi\n   fi\n   $RM -r conftest*\n   LDFLAGS=$save_LDFLAGS\n])\n\nif test yes = \"[$]$2\"; then\n    m4_if([$4], , :, [$4])\nelse\n    m4_if([$5], , :, [$5])\nfi\n])# _LT_LINKER_OPTION\n\n# Old name:\nAU_ALIAS([AC_LIBTOOL_LINKER_OPTION], [_LT_LINKER_OPTION])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_LIBTOOL_LINKER_OPTION], [])\n\n\n# LT_CMD_MAX_LEN\n#---------------\nAC_DEFUN([LT_CMD_MAX_LEN],\n[AC_REQUIRE([AC_CANONICAL_HOST])dnl\n# find the maximum length of command line arguments\nAC_MSG_CHECKING([the maximum length of command line arguments])\nAC_CACHE_VAL([lt_cv_sys_max_cmd_len], [dnl\n  i=0\n  teststring=ABCD\n\n  case $build_os in\n  msdosdjgpp*)\n    # On DJGPP, this test can blow up pretty badly due to problems in libc\n    # (any single argument exceeding 2000 bytes causes a buffer overrun\n    # during glob expansion).  Even if it were fixed, the result of this\n    # check would be larger than it should be.\n    lt_cv_sys_max_cmd_len=12288;    # 12K is about right\n    ;;\n\n  gnu*)\n    # Under GNU Hurd, this test is not required because there is\n    # no limit to the length of command line arguments.\n    # Libtool will interpret -1 as no limit whatsoever\n    lt_cv_sys_max_cmd_len=-1;\n    ;;\n\n  cygwin* | mingw* | cegcc*)\n    # On Win9x/ME, this test blows up -- it succeeds, but takes\n    # about 5 minutes as the teststring grows exponentially.\n    # Worse, since 9x/ME are not pre-emptively multitasking,\n    # you end up with a \"frozen\" computer, even though with patience\n    # the test eventually succeeds (with a max line length of 256k).\n    # Instead, let's just punt: use the minimum linelength reported by\n    # all of the supported platforms: 8192 (on NT/2K/XP).\n    lt_cv_sys_max_cmd_len=8192;\n    ;;\n\n  mint*)\n    # On MiNT this can take a long time and run out of memory.\n    lt_cv_sys_max_cmd_len=8192;\n    ;;\n\n  amigaos*)\n    # On AmigaOS with pdksh, this test takes hours, literally.\n    # So we just punt and use a minimum line length of 8192.\n    lt_cv_sys_max_cmd_len=8192;\n    ;;\n\n  bitrig* | darwin* | dragonfly* | freebsd* | netbsd* | openbsd*)\n    # This has been around since 386BSD, at least.  Likely further.\n    if test -x /sbin/sysctl; then\n      lt_cv_sys_max_cmd_len=`/sbin/sysctl -n kern.argmax`\n    elif test -x /usr/sbin/sysctl; then\n      lt_cv_sys_max_cmd_len=`/usr/sbin/sysctl -n kern.argmax`\n    else\n      lt_cv_sys_max_cmd_len=65536\t# usable default for all BSDs\n    fi\n    # And add a safety zone\n    lt_cv_sys_max_cmd_len=`expr $lt_cv_sys_max_cmd_len \\/ 4`\n    lt_cv_sys_max_cmd_len=`expr $lt_cv_sys_max_cmd_len \\* 3`\n    ;;\n\n  interix*)\n    # We know the value 262144 and hardcode it with a safety zone (like BSD)\n    lt_cv_sys_max_cmd_len=196608\n    ;;\n\n  os2*)\n    # The test takes a long time on OS/2.\n    lt_cv_sys_max_cmd_len=8192\n    ;;\n\n  osf*)\n    # Dr. Hans Ekkehard Plesser reports seeing a kernel panic running configure\n    # due to this test when exec_disable_arg_limit is 1 on Tru64. It is not\n    # nice to cause kernel panics so lets avoid the loop below.\n    # First set a reasonable default.\n    lt_cv_sys_max_cmd_len=16384\n    #\n    if test -x /sbin/sysconfig; then\n      case `/sbin/sysconfig -q proc exec_disable_arg_limit` in\n        *1*) lt_cv_sys_max_cmd_len=-1 ;;\n      esac\n    fi\n    ;;\n  sco3.2v5*)\n    lt_cv_sys_max_cmd_len=102400\n    ;;\n  sysv5* | sco5v6* | sysv4.2uw2*)\n    kargmax=`grep ARG_MAX /etc/conf/cf.d/stune 2>/dev/null`\n    if test -n \"$kargmax\"; then\n      lt_cv_sys_max_cmd_len=`echo $kargmax | sed 's/.*[[\t ]]//'`\n    else\n      lt_cv_sys_max_cmd_len=32768\n    fi\n    ;;\n  *)\n    lt_cv_sys_max_cmd_len=`(getconf ARG_MAX) 2> /dev/null`\n    if test -n \"$lt_cv_sys_max_cmd_len\" && \\\n       test undefined != \"$lt_cv_sys_max_cmd_len\"; then\n      lt_cv_sys_max_cmd_len=`expr $lt_cv_sys_max_cmd_len \\/ 4`\n      lt_cv_sys_max_cmd_len=`expr $lt_cv_sys_max_cmd_len \\* 3`\n    else\n      # Make teststring a little bigger before we do anything with it.\n      # a 1K string should be a reasonable start.\n      for i in 1 2 3 4 5 6 7 8; do\n        teststring=$teststring$teststring\n      done\n      SHELL=${SHELL-${CONFIG_SHELL-/bin/sh}}\n      # If test is not a shell built-in, we'll probably end up computing a\n      # maximum length that is only half of the actual maximum length, but\n      # we can't tell.\n      while { test X`env echo \"$teststring$teststring\" 2>/dev/null` \\\n\t         = \"X$teststring$teststring\"; } >/dev/null 2>&1 &&\n\t      test 17 != \"$i\" # 1/2 MB should be enough\n      do\n        i=`expr $i + 1`\n        teststring=$teststring$teststring\n      done\n      # Only check the string length outside the loop.\n      lt_cv_sys_max_cmd_len=`expr \"X$teststring\" : \".*\" 2>&1`\n      teststring=\n      # Add a significant safety factor because C++ compilers can tack on\n      # massive amounts of additional arguments before passing them to the\n      # linker.  It appears as though 1/2 is a usable value.\n      lt_cv_sys_max_cmd_len=`expr $lt_cv_sys_max_cmd_len \\/ 2`\n    fi\n    ;;\n  esac\n])\nif test -n \"$lt_cv_sys_max_cmd_len\"; then\n  AC_MSG_RESULT($lt_cv_sys_max_cmd_len)\nelse\n  AC_MSG_RESULT(none)\nfi\nmax_cmd_len=$lt_cv_sys_max_cmd_len\n_LT_DECL([], [max_cmd_len], [0],\n    [What is the maximum length of a command?])\n])# LT_CMD_MAX_LEN\n\n# Old name:\nAU_ALIAS([AC_LIBTOOL_SYS_MAX_CMD_LEN], [LT_CMD_MAX_LEN])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_LIBTOOL_SYS_MAX_CMD_LEN], [])\n\n\n# _LT_HEADER_DLFCN\n# ----------------\nm4_defun([_LT_HEADER_DLFCN],\n[AC_CHECK_HEADERS([dlfcn.h], [], [], [AC_INCLUDES_DEFAULT])dnl\n])# _LT_HEADER_DLFCN\n\n\n# _LT_TRY_DLOPEN_SELF (ACTION-IF-TRUE, ACTION-IF-TRUE-W-USCORE,\n#                      ACTION-IF-FALSE, ACTION-IF-CROSS-COMPILING)\n# ----------------------------------------------------------------\nm4_defun([_LT_TRY_DLOPEN_SELF],\n[m4_require([_LT_HEADER_DLFCN])dnl\nif test yes = \"$cross_compiling\"; then :\n  [$4]\nelse\n  lt_dlunknown=0; lt_dlno_uscore=1; lt_dlneed_uscore=2\n  lt_status=$lt_dlunknown\n  cat > conftest.$ac_ext <<_LT_EOF\n[#line $LINENO \"configure\"\n#include \"confdefs.h\"\n\n#if HAVE_DLFCN_H\n#include <dlfcn.h>\n#endif\n\n#include <stdio.h>\n\n#ifdef RTLD_GLOBAL\n#  define LT_DLGLOBAL\t\tRTLD_GLOBAL\n#else\n#  ifdef DL_GLOBAL\n#    define LT_DLGLOBAL\t\tDL_GLOBAL\n#  else\n#    define LT_DLGLOBAL\t\t0\n#  endif\n#endif\n\n/* We may have to define LT_DLLAZY_OR_NOW in the command line if we\n   find out it does not work in some platform. */\n#ifndef LT_DLLAZY_OR_NOW\n#  ifdef RTLD_LAZY\n#    define LT_DLLAZY_OR_NOW\t\tRTLD_LAZY\n#  else\n#    ifdef DL_LAZY\n#      define LT_DLLAZY_OR_NOW\t\tDL_LAZY\n#    else\n#      ifdef RTLD_NOW\n#        define LT_DLLAZY_OR_NOW\tRTLD_NOW\n#      else\n#        ifdef DL_NOW\n#          define LT_DLLAZY_OR_NOW\tDL_NOW\n#        else\n#          define LT_DLLAZY_OR_NOW\t0\n#        endif\n#      endif\n#    endif\n#  endif\n#endif\n\n/* When -fvisibility=hidden is used, assume the code has been annotated\n   correspondingly for the symbols needed.  */\n#if defined __GNUC__ && (((__GNUC__ == 3) && (__GNUC_MINOR__ >= 3)) || (__GNUC__ > 3))\nint fnord () __attribute__((visibility(\"default\")));\n#endif\n\nint fnord () { return 42; }\nint main ()\n{\n  void *self = dlopen (0, LT_DLGLOBAL|LT_DLLAZY_OR_NOW);\n  int status = $lt_dlunknown;\n\n  if (self)\n    {\n      if (dlsym (self,\"fnord\"))       status = $lt_dlno_uscore;\n      else\n        {\n\t  if (dlsym( self,\"_fnord\"))  status = $lt_dlneed_uscore;\n          else puts (dlerror ());\n\t}\n      /* dlclose (self); */\n    }\n  else\n    puts (dlerror ());\n\n  return status;\n}]\n_LT_EOF\n  if AC_TRY_EVAL(ac_link) && test -s \"conftest$ac_exeext\" 2>/dev/null; then\n    (./conftest; exit; ) >&AS_MESSAGE_LOG_FD 2>/dev/null\n    lt_status=$?\n    case x$lt_status in\n      x$lt_dlno_uscore) $1 ;;\n      x$lt_dlneed_uscore) $2 ;;\n      x$lt_dlunknown|x*) $3 ;;\n    esac\n  else :\n    # compilation failed\n    $3\n  fi\nfi\nrm -fr conftest*\n])# _LT_TRY_DLOPEN_SELF\n\n\n# LT_SYS_DLOPEN_SELF\n# ------------------\nAC_DEFUN([LT_SYS_DLOPEN_SELF],\n[m4_require([_LT_HEADER_DLFCN])dnl\nif test yes != \"$enable_dlopen\"; then\n  enable_dlopen=unknown\n  enable_dlopen_self=unknown\n  enable_dlopen_self_static=unknown\nelse\n  lt_cv_dlopen=no\n  lt_cv_dlopen_libs=\n\n  case $host_os in\n  beos*)\n    lt_cv_dlopen=load_add_on\n    lt_cv_dlopen_libs=\n    lt_cv_dlopen_self=yes\n    ;;\n\n  mingw* | pw32* | cegcc*)\n    lt_cv_dlopen=LoadLibrary\n    lt_cv_dlopen_libs=\n    ;;\n\n  cygwin*)\n    lt_cv_dlopen=dlopen\n    lt_cv_dlopen_libs=\n    ;;\n\n  darwin*)\n    # if libdl is installed we need to link against it\n    AC_CHECK_LIB([dl], [dlopen],\n\t\t[lt_cv_dlopen=dlopen lt_cv_dlopen_libs=-ldl],[\n    lt_cv_dlopen=dyld\n    lt_cv_dlopen_libs=\n    lt_cv_dlopen_self=yes\n    ])\n    ;;\n\n  tpf*)\n    # Don't try to run any link tests for TPF.  We know it's impossible\n    # because TPF is a cross-compiler, and we know how we open DSOs.\n    lt_cv_dlopen=dlopen\n    lt_cv_dlopen_libs=\n    lt_cv_dlopen_self=no\n    ;;\n\n  *)\n    AC_CHECK_FUNC([shl_load],\n\t  [lt_cv_dlopen=shl_load],\n      [AC_CHECK_LIB([dld], [shl_load],\n\t    [lt_cv_dlopen=shl_load lt_cv_dlopen_libs=-ldld],\n\t[AC_CHECK_FUNC([dlopen],\n\t      [lt_cv_dlopen=dlopen],\n\t  [AC_CHECK_LIB([dl], [dlopen],\n\t\t[lt_cv_dlopen=dlopen lt_cv_dlopen_libs=-ldl],\n\t    [AC_CHECK_LIB([svld], [dlopen],\n\t\t  [lt_cv_dlopen=dlopen lt_cv_dlopen_libs=-lsvld],\n\t      [AC_CHECK_LIB([dld], [dld_link],\n\t\t    [lt_cv_dlopen=dld_link lt_cv_dlopen_libs=-ldld])\n\t      ])\n\t    ])\n\t  ])\n\t])\n      ])\n    ;;\n  esac\n\n  if test no = \"$lt_cv_dlopen\"; then\n    enable_dlopen=no\n  else\n    enable_dlopen=yes\n  fi\n\n  case $lt_cv_dlopen in\n  dlopen)\n    save_CPPFLAGS=$CPPFLAGS\n    test yes = \"$ac_cv_header_dlfcn_h\" && CPPFLAGS=\"$CPPFLAGS -DHAVE_DLFCN_H\"\n\n    save_LDFLAGS=$LDFLAGS\n    wl=$lt_prog_compiler_wl eval LDFLAGS=\\\"\\$LDFLAGS $export_dynamic_flag_spec\\\"\n\n    save_LIBS=$LIBS\n    LIBS=\"$lt_cv_dlopen_libs $LIBS\"\n\n    AC_CACHE_CHECK([whether a program can dlopen itself],\n\t  lt_cv_dlopen_self, [dnl\n\t  _LT_TRY_DLOPEN_SELF(\n\t    lt_cv_dlopen_self=yes, lt_cv_dlopen_self=yes,\n\t    lt_cv_dlopen_self=no, lt_cv_dlopen_self=cross)\n    ])\n\n    if test yes = \"$lt_cv_dlopen_self\"; then\n      wl=$lt_prog_compiler_wl eval LDFLAGS=\\\"\\$LDFLAGS $lt_prog_compiler_static\\\"\n      AC_CACHE_CHECK([whether a statically linked program can dlopen itself],\n\t  lt_cv_dlopen_self_static, [dnl\n\t  _LT_TRY_DLOPEN_SELF(\n\t    lt_cv_dlopen_self_static=yes, lt_cv_dlopen_self_static=yes,\n\t    lt_cv_dlopen_self_static=no,  lt_cv_dlopen_self_static=cross)\n      ])\n    fi\n\n    CPPFLAGS=$save_CPPFLAGS\n    LDFLAGS=$save_LDFLAGS\n    LIBS=$save_LIBS\n    ;;\n  esac\n\n  case $lt_cv_dlopen_self in\n  yes|no) enable_dlopen_self=$lt_cv_dlopen_self ;;\n  *) enable_dlopen_self=unknown ;;\n  esac\n\n  case $lt_cv_dlopen_self_static in\n  yes|no) enable_dlopen_self_static=$lt_cv_dlopen_self_static ;;\n  *) enable_dlopen_self_static=unknown ;;\n  esac\nfi\n_LT_DECL([dlopen_support], [enable_dlopen], [0],\n\t [Whether dlopen is supported])\n_LT_DECL([dlopen_self], [enable_dlopen_self], [0],\n\t [Whether dlopen of programs is supported])\n_LT_DECL([dlopen_self_static], [enable_dlopen_self_static], [0],\n\t [Whether dlopen of statically linked programs is supported])\n])# LT_SYS_DLOPEN_SELF\n\n# Old name:\nAU_ALIAS([AC_LIBTOOL_DLOPEN_SELF], [LT_SYS_DLOPEN_SELF])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_LIBTOOL_DLOPEN_SELF], [])\n\n\n# _LT_COMPILER_C_O([TAGNAME])\n# ---------------------------\n# Check to see if options -c and -o are simultaneously supported by compiler.\n# This macro does not hard code the compiler like AC_PROG_CC_C_O.\nm4_defun([_LT_COMPILER_C_O],\n[m4_require([_LT_DECL_SED])dnl\nm4_require([_LT_FILEUTILS_DEFAULTS])dnl\nm4_require([_LT_TAG_COMPILER])dnl\nAC_CACHE_CHECK([if $compiler supports -c -o file.$ac_objext],\n  [_LT_TAGVAR(lt_cv_prog_compiler_c_o, $1)],\n  [_LT_TAGVAR(lt_cv_prog_compiler_c_o, $1)=no\n   $RM -r conftest 2>/dev/null\n   mkdir conftest\n   cd conftest\n   mkdir out\n   echo \"$lt_simple_compile_test_code\" > conftest.$ac_ext\n\n   lt_compiler_flag=\"-o out/conftest2.$ac_objext\"\n   # Insert the option either (1) after the last *FLAGS variable, or\n   # (2) before a word containing \"conftest.\", or (3) at the end.\n   # Note that $ac_compile itself does not contain backslashes and begins\n   # with a dollar sign (not a hyphen), so the echo should work correctly.\n   lt_compile=`echo \"$ac_compile\" | $SED \\\n   -e 's:.*FLAGS}\\{0,1\\} :&$lt_compiler_flag :; t' \\\n   -e 's: [[^ ]]*conftest\\.: $lt_compiler_flag&:; t' \\\n   -e 's:$: $lt_compiler_flag:'`\n   (eval echo \"\\\"\\$as_me:$LINENO: $lt_compile\\\"\" >&AS_MESSAGE_LOG_FD)\n   (eval \"$lt_compile\" 2>out/conftest.err)\n   ac_status=$?\n   cat out/conftest.err >&AS_MESSAGE_LOG_FD\n   echo \"$as_me:$LINENO: \\$? = $ac_status\" >&AS_MESSAGE_LOG_FD\n   if (exit $ac_status) && test -s out/conftest2.$ac_objext\n   then\n     # The compiler can only warn and ignore the option if not recognized\n     # So say no if there are warnings\n     $ECHO \"$_lt_compiler_boilerplate\" | $SED '/^$/d' > out/conftest.exp\n     $SED '/^$/d; /^ *+/d' out/conftest.err >out/conftest.er2\n     if test ! -s out/conftest.er2 || diff out/conftest.exp out/conftest.er2 >/dev/null; then\n       _LT_TAGVAR(lt_cv_prog_compiler_c_o, $1)=yes\n     fi\n   fi\n   chmod u+w . 2>&AS_MESSAGE_LOG_FD\n   $RM conftest*\n   # SGI C++ compiler will create directory out/ii_files/ for\n   # template instantiation\n   test -d out/ii_files && $RM out/ii_files/* && rmdir out/ii_files\n   $RM out/* && rmdir out\n   cd ..\n   $RM -r conftest\n   $RM conftest*\n])\n_LT_TAGDECL([compiler_c_o], [lt_cv_prog_compiler_c_o], [1],\n\t[Does compiler simultaneously support -c and -o options?])\n])# _LT_COMPILER_C_O\n\n\n# _LT_COMPILER_FILE_LOCKS([TAGNAME])\n# ----------------------------------\n# Check to see if we can do hard links to lock some files if needed\nm4_defun([_LT_COMPILER_FILE_LOCKS],\n[m4_require([_LT_ENABLE_LOCK])dnl\nm4_require([_LT_FILEUTILS_DEFAULTS])dnl\n_LT_COMPILER_C_O([$1])\n\nhard_links=nottested\nif test no = \"$_LT_TAGVAR(lt_cv_prog_compiler_c_o, $1)\" && test no != \"$need_locks\"; then\n  # do not overwrite the value of need_locks provided by the user\n  AC_MSG_CHECKING([if we can lock with hard links])\n  hard_links=yes\n  $RM conftest*\n  ln conftest.a conftest.b 2>/dev/null && hard_links=no\n  touch conftest.a\n  ln conftest.a conftest.b 2>&5 || hard_links=no\n  ln conftest.a conftest.b 2>/dev/null && hard_links=no\n  AC_MSG_RESULT([$hard_links])\n  if test no = \"$hard_links\"; then\n    AC_MSG_WARN(['$CC' does not support '-c -o', so 'make -j' may be unsafe])\n    need_locks=warn\n  fi\nelse\n  need_locks=no\nfi\n_LT_DECL([], [need_locks], [1], [Must we lock files when doing compilation?])\n])# _LT_COMPILER_FILE_LOCKS\n\n\n# _LT_CHECK_OBJDIR\n# ----------------\nm4_defun([_LT_CHECK_OBJDIR],\n[AC_CACHE_CHECK([for objdir], [lt_cv_objdir],\n[rm -f .libs 2>/dev/null\nmkdir .libs 2>/dev/null\nif test -d .libs; then\n  lt_cv_objdir=.libs\nelse\n  # MS-DOS does not allow filenames that begin with a dot.\n  lt_cv_objdir=_libs\nfi\nrmdir .libs 2>/dev/null])\nobjdir=$lt_cv_objdir\n_LT_DECL([], [objdir], [0],\n         [The name of the directory that contains temporary libtool files])dnl\nm4_pattern_allow([LT_OBJDIR])dnl\nAC_DEFINE_UNQUOTED([LT_OBJDIR], \"$lt_cv_objdir/\",\n  [Define to the sub-directory where libtool stores uninstalled libraries.])\n])# _LT_CHECK_OBJDIR\n\n\n# _LT_LINKER_HARDCODE_LIBPATH([TAGNAME])\n# --------------------------------------\n# Check hardcoding attributes.\nm4_defun([_LT_LINKER_HARDCODE_LIBPATH],\n[AC_MSG_CHECKING([how to hardcode library paths into programs])\n_LT_TAGVAR(hardcode_action, $1)=\nif test -n \"$_LT_TAGVAR(hardcode_libdir_flag_spec, $1)\" ||\n   test -n \"$_LT_TAGVAR(runpath_var, $1)\" ||\n   test yes = \"$_LT_TAGVAR(hardcode_automatic, $1)\"; then\n\n  # We can hardcode non-existent directories.\n  if test no != \"$_LT_TAGVAR(hardcode_direct, $1)\" &&\n     # If the only mechanism to avoid hardcoding is shlibpath_var, we\n     # have to relink, otherwise we might link with an installed library\n     # when we should be linking with a yet-to-be-installed one\n     ## test no != \"$_LT_TAGVAR(hardcode_shlibpath_var, $1)\" &&\n     test no != \"$_LT_TAGVAR(hardcode_minus_L, $1)\"; then\n    # Linking always hardcodes the temporary library directory.\n    _LT_TAGVAR(hardcode_action, $1)=relink\n  else\n    # We can link without hardcoding, and we can hardcode nonexisting dirs.\n    _LT_TAGVAR(hardcode_action, $1)=immediate\n  fi\nelse\n  # We cannot hardcode anything, or else we can only hardcode existing\n  # directories.\n  _LT_TAGVAR(hardcode_action, $1)=unsupported\nfi\nAC_MSG_RESULT([$_LT_TAGVAR(hardcode_action, $1)])\n\nif test relink = \"$_LT_TAGVAR(hardcode_action, $1)\" ||\n   test yes = \"$_LT_TAGVAR(inherit_rpath, $1)\"; then\n  # Fast installation is not supported\n  enable_fast_install=no\nelif test yes = \"$shlibpath_overrides_runpath\" ||\n     test no = \"$enable_shared\"; then\n  # Fast installation is not necessary\n  enable_fast_install=needless\nfi\n_LT_TAGDECL([], [hardcode_action], [0],\n    [How to hardcode a shared library path into an executable])\n])# _LT_LINKER_HARDCODE_LIBPATH\n\n\n# _LT_CMD_STRIPLIB\n# ----------------\nm4_defun([_LT_CMD_STRIPLIB],\n[m4_require([_LT_DECL_EGREP])\nstriplib=\nold_striplib=\nAC_MSG_CHECKING([whether stripping libraries is possible])\nif test -n \"$STRIP\" && $STRIP -V 2>&1 | $GREP \"GNU strip\" >/dev/null; then\n  test -z \"$old_striplib\" && old_striplib=\"$STRIP --strip-debug\"\n  test -z \"$striplib\" && striplib=\"$STRIP --strip-unneeded\"\n  AC_MSG_RESULT([yes])\nelse\n# FIXME - insert some real tests, host_os isn't really good enough\n  case $host_os in\n  darwin*)\n    if test -n \"$STRIP\"; then\n      striplib=\"$STRIP -x\"\n      old_striplib=\"$STRIP -S\"\n      AC_MSG_RESULT([yes])\n    else\n      AC_MSG_RESULT([no])\n    fi\n    ;;\n  *)\n    AC_MSG_RESULT([no])\n    ;;\n  esac\nfi\n_LT_DECL([], [old_striplib], [1], [Commands to strip libraries])\n_LT_DECL([], [striplib], [1])\n])# _LT_CMD_STRIPLIB\n\n\n# _LT_PREPARE_MUNGE_PATH_LIST\n# ---------------------------\n# Make sure func_munge_path_list() is defined correctly.\nm4_defun([_LT_PREPARE_MUNGE_PATH_LIST],\n[[# func_munge_path_list VARIABLE PATH\n# -----------------------------------\n# VARIABLE is name of variable containing _space_ separated list of\n# directories to be munged by the contents of PATH, which is string\n# having a format:\n# \"DIR[:DIR]:\"\n#       string \"DIR[ DIR]\" will be prepended to VARIABLE\n# \":DIR[:DIR]\"\n#       string \"DIR[ DIR]\" will be appended to VARIABLE\n# \"DIRP[:DIRP]::[DIRA:]DIRA\"\n#       string \"DIRP[ DIRP]\" will be prepended to VARIABLE and string\n#       \"DIRA[ DIRA]\" will be appended to VARIABLE\n# \"DIR[:DIR]\"\n#       VARIABLE will be replaced by \"DIR[ DIR]\"\nfunc_munge_path_list ()\n{\n    case x@S|@2 in\n    x)\n        ;;\n    *:)\n        eval @S|@1=\\\"`$ECHO @S|@2 | $SED 's/:/ /g'` \\@S|@@S|@1\\\"\n        ;;\n    x:*)\n        eval @S|@1=\\\"\\@S|@@S|@1 `$ECHO @S|@2 | $SED 's/:/ /g'`\\\"\n        ;;\n    *::*)\n        eval @S|@1=\\\"\\@S|@@S|@1\\ `$ECHO @S|@2 | $SED -e 's/.*:://' -e 's/:/ /g'`\\\"\n        eval @S|@1=\\\"`$ECHO @S|@2 | $SED -e 's/::.*//' -e 's/:/ /g'`\\ \\@S|@@S|@1\\\"\n        ;;\n    *)\n        eval @S|@1=\\\"`$ECHO @S|@2 | $SED 's/:/ /g'`\\\"\n        ;;\n    esac\n}\n]])# _LT_PREPARE_PATH_LIST\n\n\n# _LT_SYS_DYNAMIC_LINKER([TAG])\n# -----------------------------\n# PORTME Fill in your ld.so characteristics\nm4_defun([_LT_SYS_DYNAMIC_LINKER],\n[AC_REQUIRE([AC_CANONICAL_HOST])dnl\nm4_require([_LT_DECL_EGREP])dnl\nm4_require([_LT_FILEUTILS_DEFAULTS])dnl\nm4_require([_LT_DECL_OBJDUMP])dnl\nm4_require([_LT_DECL_SED])dnl\nm4_require([_LT_CHECK_SHELL_FEATURES])dnl\nm4_require([_LT_PREPARE_MUNGE_PATH_LIST])dnl\nAC_MSG_CHECKING([dynamic linker characteristics])\nm4_if([$1],\n\t[], [\nif test yes = \"$GCC\"; then\n  case $host_os in\n    darwin*) lt_awk_arg='/^libraries:/,/LR/' ;;\n    *) lt_awk_arg='/^libraries:/' ;;\n  esac\n  case $host_os in\n    mingw* | cegcc*) lt_sed_strip_eq='s|=\\([[A-Za-z]]:\\)|\\1|g' ;;\n    *) lt_sed_strip_eq='s|=/|/|g' ;;\n  esac\n  lt_search_path_spec=`$CC -print-search-dirs | awk $lt_awk_arg | $SED -e \"s/^libraries://\" -e $lt_sed_strip_eq`\n  case $lt_search_path_spec in\n  *\\;*)\n    # if the path contains \";\" then we assume it to be the separator\n    # otherwise default to the standard path separator (i.e. \":\") - it is\n    # assumed that no part of a normal pathname contains \";\" but that should\n    # okay in the real world where \";\" in dirpaths is itself problematic.\n    lt_search_path_spec=`$ECHO \"$lt_search_path_spec\" | $SED 's/;/ /g'`\n    ;;\n  *)\n    lt_search_path_spec=`$ECHO \"$lt_search_path_spec\" | $SED \"s/$PATH_SEPARATOR/ /g\"`\n    ;;\n  esac\n  # Ok, now we have the path, separated by spaces, we can step through it\n  # and add multilib dir if necessary...\n  lt_tmp_lt_search_path_spec=\n  lt_multi_os_dir=/`$CC $CPPFLAGS $CFLAGS $LDFLAGS -print-multi-os-directory 2>/dev/null`\n  # ...but if some path component already ends with the multilib dir we assume\n  # that all is fine and trust -print-search-dirs as is (GCC 4.2? or newer).\n  case \"$lt_multi_os_dir; $lt_search_path_spec \" in\n  \"/; \"* | \"/.; \"* | \"/./; \"* | *\"$lt_multi_os_dir \"* | *\"$lt_multi_os_dir/ \"*)\n    lt_multi_os_dir=\n    ;;\n  esac\n  for lt_sys_path in $lt_search_path_spec; do\n    if test -d \"$lt_sys_path$lt_multi_os_dir\"; then\n      lt_tmp_lt_search_path_spec=\"$lt_tmp_lt_search_path_spec $lt_sys_path$lt_multi_os_dir\"\n    elif test -n \"$lt_multi_os_dir\"; then\n      test -d \"$lt_sys_path\" && \\\n\tlt_tmp_lt_search_path_spec=\"$lt_tmp_lt_search_path_spec $lt_sys_path\"\n    fi\n  done\n  lt_search_path_spec=`$ECHO \"$lt_tmp_lt_search_path_spec\" | awk '\nBEGIN {RS = \" \"; FS = \"/|\\n\";} {\n  lt_foo = \"\";\n  lt_count = 0;\n  for (lt_i = NF; lt_i > 0; lt_i--) {\n    if ($lt_i != \"\" && $lt_i != \".\") {\n      if ($lt_i == \"..\") {\n        lt_count++;\n      } else {\n        if (lt_count == 0) {\n          lt_foo = \"/\" $lt_i lt_foo;\n        } else {\n          lt_count--;\n        }\n      }\n    }\n  }\n  if (lt_foo != \"\") { lt_freq[[lt_foo]]++; }\n  if (lt_freq[[lt_foo]] == 1) { print lt_foo; }\n}'`\n  # AWK program above erroneously prepends '/' to C:/dos/paths\n  # for these hosts.\n  case $host_os in\n    mingw* | cegcc*) lt_search_path_spec=`$ECHO \"$lt_search_path_spec\" |\\\n      $SED 's|/\\([[A-Za-z]]:\\)|\\1|g'` ;;\n  esac\n  sys_lib_search_path_spec=`$ECHO \"$lt_search_path_spec\" | $lt_NL2SP`\nelse\n  sys_lib_search_path_spec=\"/lib /usr/lib /usr/local/lib\"\nfi])\nlibrary_names_spec=\nlibname_spec='lib$name'\nsoname_spec=\nshrext_cmds=.so\npostinstall_cmds=\npostuninstall_cmds=\nfinish_cmds=\nfinish_eval=\nshlibpath_var=\nshlibpath_overrides_runpath=unknown\nversion_type=none\ndynamic_linker=\"$host_os ld.so\"\nsys_lib_dlsearch_path_spec=\"/lib /usr/lib\"\nneed_lib_prefix=unknown\nhardcode_into_libs=no\n\n# when you set need_version to no, make sure it does not cause -set_version\n# flags to be left without arguments\nneed_version=unknown\n\nAC_ARG_VAR([LT_SYS_LIBRARY_PATH],\n[User-defined run-time library search path.])\n\ncase $host_os in\naix3*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  library_names_spec='$libname$release$shared_ext$versuffix $libname.a'\n  shlibpath_var=LIBPATH\n\n  # AIX 3 has no versioning support, so we append a major version to the name.\n  soname_spec='$libname$release$shared_ext$major'\n  ;;\n\naix[[4-9]]*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  need_lib_prefix=no\n  need_version=no\n  hardcode_into_libs=yes\n  if test ia64 = \"$host_cpu\"; then\n    # AIX 5 supports IA64\n    library_names_spec='$libname$release$shared_ext$major $libname$release$shared_ext$versuffix $libname$shared_ext'\n    shlibpath_var=LD_LIBRARY_PATH\n  else\n    # With GCC up to 2.95.x, collect2 would create an import file\n    # for dependence libraries.  The import file would start with\n    # the line '#! .'.  This would cause the generated library to\n    # depend on '.', always an invalid library.  This was fixed in\n    # development snapshots of GCC prior to 3.0.\n    case $host_os in\n      aix4 | aix4.[[01]] | aix4.[[01]].*)\n      if { echo '#if __GNUC__ > 2 || (__GNUC__ == 2 && __GNUC_MINOR__ >= 97)'\n\t   echo ' yes '\n\t   echo '#endif'; } | $CC -E - | $GREP yes > /dev/null; then\n\t:\n      else\n\tcan_build_shared=no\n      fi\n      ;;\n    esac\n    # Using Import Files as archive members, it is possible to support\n    # filename-based versioning of shared library archives on AIX. While\n    # this would work for both with and without runtime linking, it will\n    # prevent static linking of such archives. So we do filename-based\n    # shared library versioning with .so extension only, which is used\n    # when both runtime linking and shared linking is enabled.\n    # Unfortunately, runtime linking may impact performance, so we do\n    # not want this to be the default eventually. Also, we use the\n    # versioned .so libs for executables only if there is the -brtl\n    # linker flag in LDFLAGS as well, or --with-aix-soname=svr4 only.\n    # To allow for filename-based versioning support, we need to create\n    # libNAME.so.V as an archive file, containing:\n    # *) an Import File, referring to the versioned filename of the\n    #    archive as well as the shared archive member, telling the\n    #    bitwidth (32 or 64) of that shared object, and providing the\n    #    list of exported symbols of that shared object, eventually\n    #    decorated with the 'weak' keyword\n    # *) the shared object with the F_LOADONLY flag set, to really avoid\n    #    it being seen by the linker.\n    # At run time we better use the real file rather than another symlink,\n    # but for link time we create the symlink libNAME.so -> libNAME.so.V\n\n    case $with_aix_soname,$aix_use_runtimelinking in\n    # AIX (on Power*) has no versioning support, so currently we cannot hardcode correct\n    # soname into executable. Probably we can add versioning support to\n    # collect2, so additional links can be useful in future.\n    aix,yes) # traditional libtool\n      dynamic_linker='AIX unversionable lib.so'\n      # If using run time linking (on AIX 4.2 or later) use lib<name>.so\n      # instead of lib<name>.a to let people know that these are not\n      # typical AIX shared libraries.\n      library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n      ;;\n    aix,no) # traditional AIX only\n      dynamic_linker='AIX lib.a[(]lib.so.V[)]'\n      # We preserve .a as extension for shared libraries through AIX4.2\n      # and later when we are not doing run time linking.\n      library_names_spec='$libname$release.a $libname.a'\n      soname_spec='$libname$release$shared_ext$major'\n      ;;\n    svr4,*) # full svr4 only\n      dynamic_linker=\"AIX lib.so.V[(]$shared_archive_member_spec.o[)]\"\n      library_names_spec='$libname$release$shared_ext$major $libname$shared_ext'\n      # We do not specify a path in Import Files, so LIBPATH fires.\n      shlibpath_overrides_runpath=yes\n      ;;\n    *,yes) # both, prefer svr4\n      dynamic_linker=\"AIX lib.so.V[(]$shared_archive_member_spec.o[)], lib.a[(]lib.so.V[)]\"\n      library_names_spec='$libname$release$shared_ext$major $libname$shared_ext'\n      # unpreferred sharedlib libNAME.a needs extra handling\n      postinstall_cmds='test -n \"$linkname\" || linkname=\"$realname\"~func_stripname \"\" \".so\" \"$linkname\"~$install_shared_prog \"$dir/$func_stripname_result.$libext\" \"$destdir/$func_stripname_result.$libext\"~test -z \"$tstripme\" || test -z \"$striplib\" || $striplib \"$destdir/$func_stripname_result.$libext\"'\n      postuninstall_cmds='for n in $library_names $old_library; do :; done~func_stripname \"\" \".so\" \"$n\"~test \"$func_stripname_result\" = \"$n\" || func_append rmfiles \" $odir/$func_stripname_result.$libext\"'\n      # We do not specify a path in Import Files, so LIBPATH fires.\n      shlibpath_overrides_runpath=yes\n      ;;\n    *,no) # both, prefer aix\n      dynamic_linker=\"AIX lib.a[(]lib.so.V[)], lib.so.V[(]$shared_archive_member_spec.o[)]\"\n      library_names_spec='$libname$release.a $libname.a'\n      soname_spec='$libname$release$shared_ext$major'\n      # unpreferred sharedlib libNAME.so.V and symlink libNAME.so need extra handling\n      postinstall_cmds='test -z \"$dlname\" || $install_shared_prog $dir/$dlname $destdir/$dlname~test -z \"$tstripme\" || test -z \"$striplib\" || $striplib $destdir/$dlname~test -n \"$linkname\" || linkname=$realname~func_stripname \"\" \".a\" \"$linkname\"~(cd \"$destdir\" && $LN_S -f $dlname $func_stripname_result.so)'\n      postuninstall_cmds='test -z \"$dlname\" || func_append rmfiles \" $odir/$dlname\"~for n in $old_library $library_names; do :; done~func_stripname \"\" \".a\" \"$n\"~func_append rmfiles \" $odir/$func_stripname_result.so\"'\n      ;;\n    esac\n    shlibpath_var=LIBPATH\n  fi\n  ;;\n\namigaos*)\n  case $host_cpu in\n  powerpc)\n    # Since July 2007 AmigaOS4 officially supports .so libraries.\n    # When compiling the executable, add -use-dynld -Lsobjs: to the compileline.\n    library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n    ;;\n  m68k)\n    library_names_spec='$libname.ixlibrary $libname.a'\n    # Create ${libname}_ixlibrary.a entries in /sys/libs.\n    finish_eval='for lib in `ls $libdir/*.ixlibrary 2>/dev/null`; do libname=`func_echo_all \"$lib\" | $SED '\\''s%^.*/\\([[^/]]*\\)\\.ixlibrary$%\\1%'\\''`; $RM /sys/libs/${libname}_ixlibrary.a; $show \"cd /sys/libs && $LN_S $lib ${libname}_ixlibrary.a\"; cd /sys/libs && $LN_S $lib ${libname}_ixlibrary.a || exit 1; done'\n    ;;\n  esac\n  ;;\n\nbeos*)\n  library_names_spec='$libname$shared_ext'\n  dynamic_linker=\"$host_os ld.so\"\n  shlibpath_var=LIBRARY_PATH\n  ;;\n\nbsdi[[45]]*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  need_version=no\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  finish_cmds='PATH=\"\\$PATH:/sbin\" ldconfig $libdir'\n  shlibpath_var=LD_LIBRARY_PATH\n  sys_lib_search_path_spec=\"/shlib /usr/lib /usr/X11/lib /usr/contrib/lib /lib /usr/local/lib\"\n  sys_lib_dlsearch_path_spec=\"/shlib /usr/lib /usr/local/lib\"\n  # the default ld.so.conf also contains /usr/contrib/lib and\n  # /usr/X11R6/lib (/usr/X11 is a link to /usr/X11R6), but let us allow\n  # libtool to hard-code these into programs\n  ;;\n\ncygwin* | mingw* | pw32* | cegcc*)\n  version_type=windows\n  shrext_cmds=.dll\n  need_version=no\n  need_lib_prefix=no\n\n  case $GCC,$cc_basename in\n  yes,*)\n    # gcc\n    library_names_spec='$libname.dll.a'\n    # DLL is installed to $(libdir)/../bin by postinstall_cmds\n    postinstall_cmds='base_file=`basename \\$file`~\n      dlpath=`$SHELL 2>&1 -c '\\''. $dir/'\\''\\$base_file'\\''i; echo \\$dlname'\\''`~\n      dldir=$destdir/`dirname \\$dlpath`~\n      test -d \\$dldir || mkdir -p \\$dldir~\n      $install_prog $dir/$dlname \\$dldir/$dlname~\n      chmod a+x \\$dldir/$dlname~\n      if test -n '\\''$stripme'\\'' && test -n '\\''$striplib'\\''; then\n        eval '\\''$striplib \\$dldir/$dlname'\\'' || exit \\$?;\n      fi'\n    postuninstall_cmds='dldll=`$SHELL 2>&1 -c '\\''. $file; echo \\$dlname'\\''`~\n      dlpath=$dir/\\$dldll~\n       $RM \\$dlpath'\n    shlibpath_overrides_runpath=yes\n\n    case $host_os in\n    cygwin*)\n      # Cygwin DLLs use 'cyg' prefix rather than 'lib'\n      soname_spec='`echo $libname | sed -e 's/^lib/cyg/'``echo $release | $SED -e 's/[[.]]/-/g'`$versuffix$shared_ext'\nm4_if([$1], [],[\n      sys_lib_search_path_spec=\"$sys_lib_search_path_spec /usr/lib/w32api\"])\n      ;;\n    mingw* | cegcc*)\n      # MinGW DLLs use traditional 'lib' prefix\n      soname_spec='$libname`echo $release | $SED -e 's/[[.]]/-/g'`$versuffix$shared_ext'\n      ;;\n    pw32*)\n      # pw32 DLLs use 'pw' prefix rather than 'lib'\n      library_names_spec='`echo $libname | sed -e 's/^lib/pw/'``echo $release | $SED -e 's/[[.]]/-/g'`$versuffix$shared_ext'\n      ;;\n    esac\n    dynamic_linker='Win32 ld.exe'\n    ;;\n\n  *,cl*)\n    # Native MSVC\n    libname_spec='$name'\n    soname_spec='$libname`echo $release | $SED -e 's/[[.]]/-/g'`$versuffix$shared_ext'\n    library_names_spec='$libname.dll.lib'\n\n    case $build_os in\n    mingw*)\n      sys_lib_search_path_spec=\n      lt_save_ifs=$IFS\n      IFS=';'\n      for lt_path in $LIB\n      do\n        IFS=$lt_save_ifs\n        # Let DOS variable expansion print the short 8.3 style file name.\n        lt_path=`cd \"$lt_path\" 2>/dev/null && cmd //C \"for %i in (\".\") do @echo %~si\"`\n        sys_lib_search_path_spec=\"$sys_lib_search_path_spec $lt_path\"\n      done\n      IFS=$lt_save_ifs\n      # Convert to MSYS style.\n      sys_lib_search_path_spec=`$ECHO \"$sys_lib_search_path_spec\" | sed -e 's|\\\\\\\\|/|g' -e 's| \\\\([[a-zA-Z]]\\\\):| /\\\\1|g' -e 's|^ ||'`\n      ;;\n    cygwin*)\n      # Convert to unix form, then to dos form, then back to unix form\n      # but this time dos style (no spaces!) so that the unix form looks\n      # like /cygdrive/c/PROGRA~1:/cygdr...\n      sys_lib_search_path_spec=`cygpath --path --unix \"$LIB\"`\n      sys_lib_search_path_spec=`cygpath --path --dos \"$sys_lib_search_path_spec\" 2>/dev/null`\n      sys_lib_search_path_spec=`cygpath --path --unix \"$sys_lib_search_path_spec\" | $SED -e \"s/$PATH_SEPARATOR/ /g\"`\n      ;;\n    *)\n      sys_lib_search_path_spec=$LIB\n      if $ECHO \"$sys_lib_search_path_spec\" | [$GREP ';[c-zC-Z]:/' >/dev/null]; then\n        # It is most probably a Windows format PATH.\n        sys_lib_search_path_spec=`$ECHO \"$sys_lib_search_path_spec\" | $SED -e 's/;/ /g'`\n      else\n        sys_lib_search_path_spec=`$ECHO \"$sys_lib_search_path_spec\" | $SED -e \"s/$PATH_SEPARATOR/ /g\"`\n      fi\n      # FIXME: find the short name or the path components, as spaces are\n      # common. (e.g. \"Program Files\" -> \"PROGRA~1\")\n      ;;\n    esac\n\n    # DLL is installed to $(libdir)/../bin by postinstall_cmds\n    postinstall_cmds='base_file=`basename \\$file`~\n      dlpath=`$SHELL 2>&1 -c '\\''. $dir/'\\''\\$base_file'\\''i; echo \\$dlname'\\''`~\n      dldir=$destdir/`dirname \\$dlpath`~\n      test -d \\$dldir || mkdir -p \\$dldir~\n      $install_prog $dir/$dlname \\$dldir/$dlname'\n    postuninstall_cmds='dldll=`$SHELL 2>&1 -c '\\''. $file; echo \\$dlname'\\''`~\n      dlpath=$dir/\\$dldll~\n       $RM \\$dlpath'\n    shlibpath_overrides_runpath=yes\n    dynamic_linker='Win32 link.exe'\n    ;;\n\n  *)\n    # Assume MSVC wrapper\n    library_names_spec='$libname`echo $release | $SED -e 's/[[.]]/-/g'`$versuffix$shared_ext $libname.lib'\n    dynamic_linker='Win32 ld.exe'\n    ;;\n  esac\n  # FIXME: first we should search . and the directory the executable is in\n  shlibpath_var=PATH\n  ;;\n\ndarwin* | rhapsody*)\n  dynamic_linker=\"$host_os dyld\"\n  version_type=darwin\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='$libname$release$major$shared_ext $libname$shared_ext'\n  soname_spec='$libname$release$major$shared_ext'\n  shlibpath_overrides_runpath=yes\n  shlibpath_var=DYLD_LIBRARY_PATH\n  shrext_cmds='`test .$module = .yes && echo .so || echo .dylib`'\nm4_if([$1], [],[\n  sys_lib_search_path_spec=\"$sys_lib_search_path_spec /usr/local/lib\"])\n  sys_lib_dlsearch_path_spec='/usr/local/lib /lib /usr/lib'\n  ;;\n\ndgux*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  shlibpath_var=LD_LIBRARY_PATH\n  ;;\n\nfreebsd* | dragonfly*)\n  # DragonFly does not have aout.  When/if they implement a new\n  # versioning mechanism, adjust this.\n  if test -x /usr/bin/objformat; then\n    objformat=`/usr/bin/objformat`\n  else\n    case $host_os in\n    freebsd[[23]].*) objformat=aout ;;\n    *) objformat=elf ;;\n    esac\n  fi\n  version_type=freebsd-$objformat\n  case $version_type in\n    freebsd-elf*)\n      library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n      soname_spec='$libname$release$shared_ext$major'\n      need_version=no\n      need_lib_prefix=no\n      ;;\n    freebsd-*)\n      library_names_spec='$libname$release$shared_ext$versuffix $libname$shared_ext$versuffix'\n      need_version=yes\n      ;;\n  esac\n  shlibpath_var=LD_LIBRARY_PATH\n  case $host_os in\n  freebsd2.*)\n    shlibpath_overrides_runpath=yes\n    ;;\n  freebsd3.[[01]]* | freebsdelf3.[[01]]*)\n    shlibpath_overrides_runpath=yes\n    hardcode_into_libs=yes\n    ;;\n  freebsd3.[[2-9]]* | freebsdelf3.[[2-9]]* | \\\n  freebsd4.[[0-5]] | freebsdelf4.[[0-5]] | freebsd4.1.1 | freebsdelf4.1.1)\n    shlibpath_overrides_runpath=no\n    hardcode_into_libs=yes\n    ;;\n  *) # from 4.6 on, and DragonFly\n    shlibpath_overrides_runpath=yes\n    hardcode_into_libs=yes\n    ;;\n  esac\n  ;;\n\nhaiku*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  need_lib_prefix=no\n  need_version=no\n  dynamic_linker=\"$host_os runtime_loader\"\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  shlibpath_var=LIBRARY_PATH\n  shlibpath_overrides_runpath=no\n  sys_lib_dlsearch_path_spec='/boot/home/config/lib /boot/common/lib /boot/system/lib'\n  hardcode_into_libs=yes\n  ;;\n\nhpux9* | hpux10* | hpux11*)\n  # Give a soname corresponding to the major version so that dld.sl refuses to\n  # link against other versions.\n  version_type=sunos\n  need_lib_prefix=no\n  need_version=no\n  case $host_cpu in\n  ia64*)\n    shrext_cmds='.so'\n    hardcode_into_libs=yes\n    dynamic_linker=\"$host_os dld.so\"\n    shlibpath_var=LD_LIBRARY_PATH\n    shlibpath_overrides_runpath=yes # Unless +noenvvar is specified.\n    library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n    soname_spec='$libname$release$shared_ext$major'\n    if test 32 = \"$HPUX_IA64_MODE\"; then\n      sys_lib_search_path_spec=\"/usr/lib/hpux32 /usr/local/lib/hpux32 /usr/local/lib\"\n      sys_lib_dlsearch_path_spec=/usr/lib/hpux32\n    else\n      sys_lib_search_path_spec=\"/usr/lib/hpux64 /usr/local/lib/hpux64\"\n      sys_lib_dlsearch_path_spec=/usr/lib/hpux64\n    fi\n    ;;\n  hppa*64*)\n    shrext_cmds='.sl'\n    hardcode_into_libs=yes\n    dynamic_linker=\"$host_os dld.sl\"\n    shlibpath_var=LD_LIBRARY_PATH # How should we handle SHLIB_PATH\n    shlibpath_overrides_runpath=yes # Unless +noenvvar is specified.\n    library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n    soname_spec='$libname$release$shared_ext$major'\n    sys_lib_search_path_spec=\"/usr/lib/pa20_64 /usr/ccs/lib/pa20_64\"\n    sys_lib_dlsearch_path_spec=$sys_lib_search_path_spec\n    ;;\n  *)\n    shrext_cmds='.sl'\n    dynamic_linker=\"$host_os dld.sl\"\n    shlibpath_var=SHLIB_PATH\n    shlibpath_overrides_runpath=no # +s is required to enable SHLIB_PATH\n    library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n    soname_spec='$libname$release$shared_ext$major'\n    ;;\n  esac\n  # HP-UX runs *really* slowly unless shared libraries are mode 555, ...\n  postinstall_cmds='chmod 555 $lib'\n  # or fails outright, so override atomically:\n  install_override_mode=555\n  ;;\n\ninterix[[3-9]]*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  dynamic_linker='Interix 3.x ld.so.1 (PE, like ELF)'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=no\n  hardcode_into_libs=yes\n  ;;\n\nirix5* | irix6* | nonstopux*)\n  case $host_os in\n    nonstopux*) version_type=nonstopux ;;\n    *)\n\tif test yes = \"$lt_cv_prog_gnu_ld\"; then\n\t\tversion_type=linux # correct to gnu/linux during the next big refactor\n\telse\n\t\tversion_type=irix\n\tfi ;;\n  esac\n  need_lib_prefix=no\n  need_version=no\n  soname_spec='$libname$release$shared_ext$major'\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$release$shared_ext $libname$shared_ext'\n  case $host_os in\n  irix5* | nonstopux*)\n    libsuff= shlibsuff=\n    ;;\n  *)\n    case $LD in # libtool.m4 will add one of these switches to LD\n    *-32|*\"-32 \"|*-melf32bsmip|*\"-melf32bsmip \")\n      libsuff= shlibsuff= libmagic=32-bit;;\n    *-n32|*\"-n32 \"|*-melf32bmipn32|*\"-melf32bmipn32 \")\n      libsuff=32 shlibsuff=N32 libmagic=N32;;\n    *-64|*\"-64 \"|*-melf64bmip|*\"-melf64bmip \")\n      libsuff=64 shlibsuff=64 libmagic=64-bit;;\n    *) libsuff= shlibsuff= libmagic=never-match;;\n    esac\n    ;;\n  esac\n  shlibpath_var=LD_LIBRARY${shlibsuff}_PATH\n  shlibpath_overrides_runpath=no\n  sys_lib_search_path_spec=\"/usr/lib$libsuff /lib$libsuff /usr/local/lib$libsuff\"\n  sys_lib_dlsearch_path_spec=\"/usr/lib$libsuff /lib$libsuff\"\n  hardcode_into_libs=yes\n  ;;\n\n# No shared lib support for Linux oldld, aout, or coff.\nlinux*oldld* | linux*aout* | linux*coff*)\n  dynamic_linker=no\n  ;;\n\nlinux*android*)\n  version_type=none # Android doesn't support versioned libraries.\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='$libname$release$shared_ext'\n  soname_spec='$libname$release$shared_ext'\n  finish_cmds=\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=yes\n\n  # This implies no fast_install, which is unacceptable.\n  # Some rework will be needed to allow for fast_install\n  # before this can be enabled.\n  hardcode_into_libs=yes\n\n  dynamic_linker='Android linker'\n  # Don't embed -rpath directories since the linker doesn't support them.\n  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n  ;;\n\n# This must be glibc/ELF.\nlinux* | k*bsd*-gnu | kopensolaris*-gnu | gnu*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  finish_cmds='PATH=\"\\$PATH:/sbin\" ldconfig -n $libdir'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=no\n\n  # Some binutils ld are patched to set DT_RUNPATH\n  AC_CACHE_VAL([lt_cv_shlibpath_overrides_runpath],\n    [lt_cv_shlibpath_overrides_runpath=no\n    save_LDFLAGS=$LDFLAGS\n    save_libdir=$libdir\n    eval \"libdir=/foo; wl=\\\"$_LT_TAGVAR(lt_prog_compiler_wl, $1)\\\"; \\\n\t LDFLAGS=\\\"\\$LDFLAGS $_LT_TAGVAR(hardcode_libdir_flag_spec, $1)\\\"\"\n    AC_LINK_IFELSE([AC_LANG_PROGRAM([],[])],\n      [AS_IF([ ($OBJDUMP -p conftest$ac_exeext) 2>/dev/null | grep \"RUNPATH.*$libdir\" >/dev/null],\n\t [lt_cv_shlibpath_overrides_runpath=yes])])\n    LDFLAGS=$save_LDFLAGS\n    libdir=$save_libdir\n    ])\n  shlibpath_overrides_runpath=$lt_cv_shlibpath_overrides_runpath\n\n  # This implies no fast_install, which is unacceptable.\n  # Some rework will be needed to allow for fast_install\n  # before this can be enabled.\n  hardcode_into_libs=yes\n\n  # Ideally, we could use ldconfig to report *all* directores which are\n  # searched for libraries, however this is still not possible.  Aside from not\n  # being certain /sbin/ldconfig is available, command\n  # 'ldconfig -N -X -v | grep ^/' on 64bit Fedora does not report /usr/lib64,\n  # even though it is searched at run-time.  Try to do the best guess by\n  # appending ld.so.conf contents (and includes) to the search path.\n  if test -f /etc/ld.so.conf; then\n    lt_ld_extra=`awk '/^include / { system(sprintf(\"cd /etc; cat %s 2>/dev/null\", \\[$]2)); skip = 1; } { if (!skip) print \\[$]0; skip = 0; }' < /etc/ld.so.conf | $SED -e 's/#.*//;/^[\t ]*hwcap[\t ]/d;s/[:,\t]/ /g;s/=[^=]*$//;s/=[^= ]* / /g;s/\"//g;/^$/d' | tr '\\n' ' '`\n    sys_lib_dlsearch_path_spec=\"/lib /usr/lib $lt_ld_extra\"\n  fi\n\n  # We used to test for /lib/ld.so.1 and disable shared libraries on\n  # powerpc, because MkLinux only supported shared libraries with the\n  # GNU dynamic linker.  Since this was broken with cross compilers,\n  # most powerpc-linux boxes support dynamic linking these days and\n  # people can always --disable-shared, the test was removed, and we\n  # assume the GNU/Linux dynamic linker is in use.\n  dynamic_linker='GNU/Linux ld.so'\n  ;;\n\nnetbsdelf*-gnu)\n  version_type=linux\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='${libname}${release}${shared_ext}$versuffix ${libname}${release}${shared_ext}$major ${libname}${shared_ext}'\n  soname_spec='${libname}${release}${shared_ext}$major'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=no\n  hardcode_into_libs=yes\n  dynamic_linker='NetBSD ld.elf_so'\n  ;;\n\nnetbsd*)\n  version_type=sunos\n  need_lib_prefix=no\n  need_version=no\n  if echo __ELF__ | $CC -E - | $GREP __ELF__ >/dev/null; then\n    library_names_spec='$libname$release$shared_ext$versuffix $libname$shared_ext$versuffix'\n    finish_cmds='PATH=\"\\$PATH:/sbin\" ldconfig -m $libdir'\n    dynamic_linker='NetBSD (a.out) ld.so'\n  else\n    library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n    soname_spec='$libname$release$shared_ext$major'\n    dynamic_linker='NetBSD ld.elf_so'\n  fi\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=yes\n  hardcode_into_libs=yes\n  ;;\n\nnewsos6)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=yes\n  ;;\n\n*nto* | *qnx*)\n  version_type=qnx\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=no\n  hardcode_into_libs=yes\n  dynamic_linker='ldqnx.so'\n  ;;\n\nopenbsd* | bitrig*)\n  version_type=sunos\n  sys_lib_dlsearch_path_spec=/usr/lib\n  need_lib_prefix=no\n  if test -z \"`echo __ELF__ | $CC -E - | $GREP __ELF__`\"; then\n    need_version=no\n  else\n    need_version=yes\n  fi\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$shared_ext$versuffix'\n  finish_cmds='PATH=\"\\$PATH:/sbin\" ldconfig -m $libdir'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=yes\n  ;;\n\nos2*)\n  libname_spec='$name'\n  version_type=windows\n  shrext_cmds=.dll\n  need_version=no\n  need_lib_prefix=no\n  # OS/2 can only load a DLL with a base name of 8 characters or less.\n  soname_spec='`test -n \"$os2dllname\" && libname=\"$os2dllname\";\n    v=$($ECHO $release$versuffix | tr -d .-);\n    n=$($ECHO $libname | cut -b -$((8 - ${#v})) | tr . _);\n    $ECHO $n$v`$shared_ext'\n  library_names_spec='${libname}_dll.$libext'\n  dynamic_linker='OS/2 ld.exe'\n  shlibpath_var=BEGINLIBPATH\n  sys_lib_search_path_spec=\"/lib /usr/lib /usr/local/lib\"\n  sys_lib_dlsearch_path_spec=$sys_lib_search_path_spec\n  postinstall_cmds='base_file=`basename \\$file`~\n    dlpath=`$SHELL 2>&1 -c '\\''. $dir/'\\''\\$base_file'\\''i; $ECHO \\$dlname'\\''`~\n    dldir=$destdir/`dirname \\$dlpath`~\n    test -d \\$dldir || mkdir -p \\$dldir~\n    $install_prog $dir/$dlname \\$dldir/$dlname~\n    chmod a+x \\$dldir/$dlname~\n    if test -n '\\''$stripme'\\'' && test -n '\\''$striplib'\\''; then\n      eval '\\''$striplib \\$dldir/$dlname'\\'' || exit \\$?;\n    fi'\n  postuninstall_cmds='dldll=`$SHELL 2>&1 -c '\\''. $file; $ECHO \\$dlname'\\''`~\n    dlpath=$dir/\\$dldll~\n    $RM \\$dlpath'\n  ;;\n\nosf3* | osf4* | osf5*)\n  version_type=osf\n  need_lib_prefix=no\n  need_version=no\n  soname_spec='$libname$release$shared_ext$major'\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  shlibpath_var=LD_LIBRARY_PATH\n  sys_lib_search_path_spec=\"/usr/shlib /usr/ccs/lib /usr/lib/cmplrs/cc /usr/lib /usr/local/lib /var/shlib\"\n  sys_lib_dlsearch_path_spec=$sys_lib_search_path_spec\n  ;;\n\nrdos*)\n  dynamic_linker=no\n  ;;\n\nsolaris*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=yes\n  hardcode_into_libs=yes\n  # ldd complains unless libraries are executable\n  postinstall_cmds='chmod +x $lib'\n  ;;\n\nsunos4*)\n  version_type=sunos\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$shared_ext$versuffix'\n  finish_cmds='PATH=\"\\$PATH:/usr/etc\" ldconfig $libdir'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=yes\n  if test yes = \"$with_gnu_ld\"; then\n    need_lib_prefix=no\n  fi\n  need_version=yes\n  ;;\n\nsysv4 | sysv4.3*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  shlibpath_var=LD_LIBRARY_PATH\n  case $host_vendor in\n    sni)\n      shlibpath_overrides_runpath=no\n      need_lib_prefix=no\n      runpath_var=LD_RUN_PATH\n      ;;\n    siemens)\n      need_lib_prefix=no\n      ;;\n    motorola)\n      need_lib_prefix=no\n      need_version=no\n      shlibpath_overrides_runpath=no\n      sys_lib_search_path_spec='/lib /usr/lib /usr/ccs/lib'\n      ;;\n  esac\n  ;;\n\nsysv4*MP*)\n  if test -d /usr/nec; then\n    version_type=linux # correct to gnu/linux during the next big refactor\n    library_names_spec='$libname$shared_ext.$versuffix $libname$shared_ext.$major $libname$shared_ext'\n    soname_spec='$libname$shared_ext.$major'\n    shlibpath_var=LD_LIBRARY_PATH\n  fi\n  ;;\n\nsysv5* | sco3.2v5* | sco5v6* | unixware* | OpenUNIX* | sysv4*uw2*)\n  version_type=sco\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=yes\n  hardcode_into_libs=yes\n  if test yes = \"$with_gnu_ld\"; then\n    sys_lib_search_path_spec='/usr/local/lib /usr/gnu/lib /usr/ccs/lib /usr/lib /lib'\n  else\n    sys_lib_search_path_spec='/usr/ccs/lib /usr/lib'\n    case $host_os in\n      sco3.2v5*)\n        sys_lib_search_path_spec=\"$sys_lib_search_path_spec /lib\"\n\t;;\n    esac\n  fi\n  sys_lib_dlsearch_path_spec='/usr/lib'\n  ;;\n\ntpf*)\n  # TPF is a cross-target only.  Preferred cross-host = GNU/Linux.\n  version_type=linux # correct to gnu/linux during the next big refactor\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=no\n  hardcode_into_libs=yes\n  ;;\n\nuts4*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  shlibpath_var=LD_LIBRARY_PATH\n  ;;\n\n*)\n  dynamic_linker=no\n  ;;\nesac\nAC_MSG_RESULT([$dynamic_linker])\ntest no = \"$dynamic_linker\" && can_build_shared=no\n\nvariables_saved_for_relink=\"PATH $shlibpath_var $runpath_var\"\nif test yes = \"$GCC\"; then\n  variables_saved_for_relink=\"$variables_saved_for_relink GCC_EXEC_PREFIX COMPILER_PATH LIBRARY_PATH\"\nfi\n\nif test set = \"${lt_cv_sys_lib_search_path_spec+set}\"; then\n  sys_lib_search_path_spec=$lt_cv_sys_lib_search_path_spec\nfi\n\nif test set = \"${lt_cv_sys_lib_dlsearch_path_spec+set}\"; then\n  sys_lib_dlsearch_path_spec=$lt_cv_sys_lib_dlsearch_path_spec\nfi\n\n# remember unaugmented sys_lib_dlsearch_path content for libtool script decls...\nconfigure_time_dlsearch_path=$sys_lib_dlsearch_path_spec\n\n# ... but it needs LT_SYS_LIBRARY_PATH munging for other configure-time code\nfunc_munge_path_list sys_lib_dlsearch_path_spec \"$LT_SYS_LIBRARY_PATH\"\n\n# to be used as default LT_SYS_LIBRARY_PATH value in generated libtool\nconfigure_time_lt_sys_library_path=$LT_SYS_LIBRARY_PATH\n\n_LT_DECL([], [variables_saved_for_relink], [1],\n    [Variables whose values should be saved in libtool wrapper scripts and\n    restored at link time])\n_LT_DECL([], [need_lib_prefix], [0],\n    [Do we need the \"lib\" prefix for modules?])\n_LT_DECL([], [need_version], [0], [Do we need a version for libraries?])\n_LT_DECL([], [version_type], [0], [Library versioning type])\n_LT_DECL([], [runpath_var], [0],  [Shared library runtime path variable])\n_LT_DECL([], [shlibpath_var], [0],[Shared library path variable])\n_LT_DECL([], [shlibpath_overrides_runpath], [0],\n    [Is shlibpath searched before the hard-coded library search path?])\n_LT_DECL([], [libname_spec], [1], [Format of library name prefix])\n_LT_DECL([], [library_names_spec], [1],\n    [[List of archive names.  First name is the real one, the rest are links.\n    The last name is the one that the linker finds with -lNAME]])\n_LT_DECL([], [soname_spec], [1],\n    [[The coded name of the library, if different from the real name]])\n_LT_DECL([], [install_override_mode], [1],\n    [Permission mode override for installation of shared libraries])\n_LT_DECL([], [postinstall_cmds], [2],\n    [Command to use after installation of a shared archive])\n_LT_DECL([], [postuninstall_cmds], [2],\n    [Command to use after uninstallation of a shared archive])\n_LT_DECL([], [finish_cmds], [2],\n    [Commands used to finish a libtool library installation in a directory])\n_LT_DECL([], [finish_eval], [1],\n    [[As \"finish_cmds\", except a single script fragment to be evaled but\n    not shown]])\n_LT_DECL([], [hardcode_into_libs], [0],\n    [Whether we should hardcode library paths into libraries])\n_LT_DECL([], [sys_lib_search_path_spec], [2],\n    [Compile-time system search path for libraries])\n_LT_DECL([sys_lib_dlsearch_path_spec], [configure_time_dlsearch_path], [2],\n    [Detected run-time system search path for libraries])\n_LT_DECL([], [configure_time_lt_sys_library_path], [2],\n    [Explicit LT_SYS_LIBRARY_PATH set during ./configure time])\n])# _LT_SYS_DYNAMIC_LINKER\n\n\n# _LT_PATH_TOOL_PREFIX(TOOL)\n# --------------------------\n# find a file program that can recognize shared library\nAC_DEFUN([_LT_PATH_TOOL_PREFIX],\n[m4_require([_LT_DECL_EGREP])dnl\nAC_MSG_CHECKING([for $1])\nAC_CACHE_VAL(lt_cv_path_MAGIC_CMD,\n[case $MAGIC_CMD in\n[[\\\\/*] |  ?:[\\\\/]*])\n  lt_cv_path_MAGIC_CMD=$MAGIC_CMD # Let the user override the test with a path.\n  ;;\n*)\n  lt_save_MAGIC_CMD=$MAGIC_CMD\n  lt_save_ifs=$IFS; IFS=$PATH_SEPARATOR\ndnl $ac_dummy forces splitting on constant user-supplied paths.\ndnl POSIX.2 word splitting is done only on the output of word expansions,\ndnl not every word.  This closes a longstanding sh security hole.\n  ac_dummy=\"m4_if([$2], , $PATH, [$2])\"\n  for ac_dir in $ac_dummy; do\n    IFS=$lt_save_ifs\n    test -z \"$ac_dir\" && ac_dir=.\n    if test -f \"$ac_dir/$1\"; then\n      lt_cv_path_MAGIC_CMD=$ac_dir/\"$1\"\n      if test -n \"$file_magic_test_file\"; then\n\tcase $deplibs_check_method in\n\t\"file_magic \"*)\n\t  file_magic_regex=`expr \"$deplibs_check_method\" : \"file_magic \\(.*\\)\"`\n\t  MAGIC_CMD=$lt_cv_path_MAGIC_CMD\n\t  if eval $file_magic_cmd \\$file_magic_test_file 2> /dev/null |\n\t    $EGREP \"$file_magic_regex\" > /dev/null; then\n\t    :\n\t  else\n\t    cat <<_LT_EOF 1>&2\n\n*** Warning: the command libtool uses to detect shared libraries,\n*** $file_magic_cmd, produces output that libtool cannot recognize.\n*** The result is that libtool may fail to recognize shared libraries\n*** as such.  This will affect the creation of libtool libraries that\n*** depend on shared libraries, but programs linked with such libtool\n*** libraries will work regardless of this problem.  Nevertheless, you\n*** may want to report the problem to your system manager and/or to\n*** bug-libtool@gnu.org\n\n_LT_EOF\n\t  fi ;;\n\tesac\n      fi\n      break\n    fi\n  done\n  IFS=$lt_save_ifs\n  MAGIC_CMD=$lt_save_MAGIC_CMD\n  ;;\nesac])\nMAGIC_CMD=$lt_cv_path_MAGIC_CMD\nif test -n \"$MAGIC_CMD\"; then\n  AC_MSG_RESULT($MAGIC_CMD)\nelse\n  AC_MSG_RESULT(no)\nfi\n_LT_DECL([], [MAGIC_CMD], [0],\n\t [Used to examine libraries when file_magic_cmd begins with \"file\"])dnl\n])# _LT_PATH_TOOL_PREFIX\n\n# Old name:\nAU_ALIAS([AC_PATH_TOOL_PREFIX], [_LT_PATH_TOOL_PREFIX])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_PATH_TOOL_PREFIX], [])\n\n\n# _LT_PATH_MAGIC\n# --------------\n# find a file program that can recognize a shared library\nm4_defun([_LT_PATH_MAGIC],\n[_LT_PATH_TOOL_PREFIX(${ac_tool_prefix}file, /usr/bin$PATH_SEPARATOR$PATH)\nif test -z \"$lt_cv_path_MAGIC_CMD\"; then\n  if test -n \"$ac_tool_prefix\"; then\n    _LT_PATH_TOOL_PREFIX(file, /usr/bin$PATH_SEPARATOR$PATH)\n  else\n    MAGIC_CMD=:\n  fi\nfi\n])# _LT_PATH_MAGIC\n\n\n# LT_PATH_LD\n# ----------\n# find the pathname to the GNU or non-GNU linker\nAC_DEFUN([LT_PATH_LD],\n[AC_REQUIRE([AC_PROG_CC])dnl\nAC_REQUIRE([AC_CANONICAL_HOST])dnl\nAC_REQUIRE([AC_CANONICAL_BUILD])dnl\nm4_require([_LT_DECL_SED])dnl\nm4_require([_LT_DECL_EGREP])dnl\nm4_require([_LT_PROG_ECHO_BACKSLASH])dnl\n\nAC_ARG_WITH([gnu-ld],\n    [AS_HELP_STRING([--with-gnu-ld],\n\t[assume the C compiler uses GNU ld @<:@default=no@:>@])],\n    [test no = \"$withval\" || with_gnu_ld=yes],\n    [with_gnu_ld=no])dnl\n\nac_prog=ld\nif test yes = \"$GCC\"; then\n  # Check if gcc -print-prog-name=ld gives a path.\n  AC_MSG_CHECKING([for ld used by $CC])\n  case $host in\n  *-*-mingw*)\n    # gcc leaves a trailing carriage return, which upsets mingw\n    ac_prog=`($CC -print-prog-name=ld) 2>&5 | tr -d '\\015'` ;;\n  *)\n    ac_prog=`($CC -print-prog-name=ld) 2>&5` ;;\n  esac\n  case $ac_prog in\n    # Accept absolute paths.\n    [[\\\\/]]* | ?:[[\\\\/]]*)\n      re_direlt='/[[^/]][[^/]]*/\\.\\./'\n      # Canonicalize the pathname of ld\n      ac_prog=`$ECHO \"$ac_prog\"| $SED 's%\\\\\\\\%/%g'`\n      while $ECHO \"$ac_prog\" | $GREP \"$re_direlt\" > /dev/null 2>&1; do\n\tac_prog=`$ECHO $ac_prog| $SED \"s%$re_direlt%/%\"`\n      done\n      test -z \"$LD\" && LD=$ac_prog\n      ;;\n  \"\")\n    # If it fails, then pretend we aren't using GCC.\n    ac_prog=ld\n    ;;\n  *)\n    # If it is relative, then search for the first ld in PATH.\n    with_gnu_ld=unknown\n    ;;\n  esac\nelif test yes = \"$with_gnu_ld\"; then\n  AC_MSG_CHECKING([for GNU ld])\nelse\n  AC_MSG_CHECKING([for non-GNU ld])\nfi\nAC_CACHE_VAL(lt_cv_path_LD,\n[if test -z \"$LD\"; then\n  lt_save_ifs=$IFS; IFS=$PATH_SEPARATOR\n  for ac_dir in $PATH; do\n    IFS=$lt_save_ifs\n    test -z \"$ac_dir\" && ac_dir=.\n    if test -f \"$ac_dir/$ac_prog\" || test -f \"$ac_dir/$ac_prog$ac_exeext\"; then\n      lt_cv_path_LD=$ac_dir/$ac_prog\n      # Check to see if the program is GNU ld.  I'd rather use --version,\n      # but apparently some variants of GNU ld only accept -v.\n      # Break only if it was the GNU/non-GNU ld that we prefer.\n      case `\"$lt_cv_path_LD\" -v 2>&1 </dev/null` in\n      *GNU* | *'with BFD'*)\n\ttest no != \"$with_gnu_ld\" && break\n\t;;\n      *)\n\ttest yes != \"$with_gnu_ld\" && break\n\t;;\n      esac\n    fi\n  done\n  IFS=$lt_save_ifs\nelse\n  lt_cv_path_LD=$LD # Let the user override the test with a path.\nfi])\nLD=$lt_cv_path_LD\nif test -n \"$LD\"; then\n  AC_MSG_RESULT($LD)\nelse\n  AC_MSG_RESULT(no)\nfi\ntest -z \"$LD\" && AC_MSG_ERROR([no acceptable ld found in \\$PATH])\n_LT_PATH_LD_GNU\nAC_SUBST([LD])\n\n_LT_TAGDECL([], [LD], [1], [The linker used to build libraries])\n])# LT_PATH_LD\n\n# Old names:\nAU_ALIAS([AM_PROG_LD], [LT_PATH_LD])\nAU_ALIAS([AC_PROG_LD], [LT_PATH_LD])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AM_PROG_LD], [])\ndnl AC_DEFUN([AC_PROG_LD], [])\n\n\n# _LT_PATH_LD_GNU\n#- --------------\nm4_defun([_LT_PATH_LD_GNU],\n[AC_CACHE_CHECK([if the linker ($LD) is GNU ld], lt_cv_prog_gnu_ld,\n[# I'd rather use --version here, but apparently some GNU lds only accept -v.\ncase `$LD -v 2>&1 </dev/null` in\n*GNU* | *'with BFD'*)\n  lt_cv_prog_gnu_ld=yes\n  ;;\n*)\n  lt_cv_prog_gnu_ld=no\n  ;;\nesac])\nwith_gnu_ld=$lt_cv_prog_gnu_ld\n])# _LT_PATH_LD_GNU\n\n\n# _LT_CMD_RELOAD\n# --------------\n# find reload flag for linker\n#   -- PORTME Some linkers may need a different reload flag.\nm4_defun([_LT_CMD_RELOAD],\n[AC_CACHE_CHECK([for $LD option to reload object files],\n  lt_cv_ld_reload_flag,\n  [lt_cv_ld_reload_flag='-r'])\nreload_flag=$lt_cv_ld_reload_flag\ncase $reload_flag in\n\"\" | \" \"*) ;;\n*) reload_flag=\" $reload_flag\" ;;\nesac\nreload_cmds='$LD$reload_flag -o $output$reload_objs'\ncase $host_os in\n  cygwin* | mingw* | pw32* | cegcc*)\n    if test yes != \"$GCC\"; then\n      reload_cmds=false\n    fi\n    ;;\n  darwin*)\n    if test yes = \"$GCC\"; then\n      reload_cmds='$LTCC $LTCFLAGS -nostdlib $wl-r -o $output$reload_objs'\n    else\n      reload_cmds='$LD$reload_flag -o $output$reload_objs'\n    fi\n    ;;\nesac\n_LT_TAGDECL([], [reload_flag], [1], [How to create reloadable object files])dnl\n_LT_TAGDECL([], [reload_cmds], [2])dnl\n])# _LT_CMD_RELOAD\n\n\n# _LT_PATH_DD\n# -----------\n# find a working dd\nm4_defun([_LT_PATH_DD],\n[AC_CACHE_CHECK([for a working dd], [ac_cv_path_lt_DD],\n[printf 0123456789abcdef0123456789abcdef >conftest.i\ncat conftest.i conftest.i >conftest2.i\n: ${lt_DD:=$DD}\nAC_PATH_PROGS_FEATURE_CHECK([lt_DD], [dd],\n[if \"$ac_path_lt_DD\" bs=32 count=1 <conftest2.i >conftest.out 2>/dev/null; then\n  cmp -s conftest.i conftest.out \\\n  && ac_cv_path_lt_DD=\"$ac_path_lt_DD\" ac_path_lt_DD_found=:\nfi])\nrm -f conftest.i conftest2.i conftest.out])\n])# _LT_PATH_DD\n\n\n# _LT_CMD_TRUNCATE\n# ----------------\n# find command to truncate a binary pipe\nm4_defun([_LT_CMD_TRUNCATE],\n[m4_require([_LT_PATH_DD])\nAC_CACHE_CHECK([how to truncate binary pipes], [lt_cv_truncate_bin],\n[printf 0123456789abcdef0123456789abcdef >conftest.i\ncat conftest.i conftest.i >conftest2.i\nlt_cv_truncate_bin=\nif \"$ac_cv_path_lt_DD\" bs=32 count=1 <conftest2.i >conftest.out 2>/dev/null; then\n  cmp -s conftest.i conftest.out \\\n  && lt_cv_truncate_bin=\"$ac_cv_path_lt_DD bs=4096 count=1\"\nfi\nrm -f conftest.i conftest2.i conftest.out\ntest -z \"$lt_cv_truncate_bin\" && lt_cv_truncate_bin=\"$SED -e 4q\"])\n_LT_DECL([lt_truncate_bin], [lt_cv_truncate_bin], [1],\n  [Command to truncate a binary pipe])\n])# _LT_CMD_TRUNCATE\n\n\n# _LT_CHECK_MAGIC_METHOD\n# ----------------------\n# how to check for library dependencies\n#  -- PORTME fill in with the dynamic library characteristics\nm4_defun([_LT_CHECK_MAGIC_METHOD],\n[m4_require([_LT_DECL_EGREP])\nm4_require([_LT_DECL_OBJDUMP])\nAC_CACHE_CHECK([how to recognize dependent libraries],\nlt_cv_deplibs_check_method,\n[lt_cv_file_magic_cmd='$MAGIC_CMD'\nlt_cv_file_magic_test_file=\nlt_cv_deplibs_check_method='unknown'\n# Need to set the preceding variable on all platforms that support\n# interlibrary dependencies.\n# 'none' -- dependencies not supported.\n# 'unknown' -- same as none, but documents that we really don't know.\n# 'pass_all' -- all dependencies passed with no checks.\n# 'test_compile' -- check by making test program.\n# 'file_magic [[regex]]' -- check by looking for files in library path\n# that responds to the $file_magic_cmd with a given extended regex.\n# If you have 'file' or equivalent on your system and you're not sure\n# whether 'pass_all' will *always* work, you probably want this one.\n\ncase $host_os in\naix[[4-9]]*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nbeos*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nbsdi[[45]]*)\n  lt_cv_deplibs_check_method='file_magic ELF [[0-9]][[0-9]]*-bit [[ML]]SB (shared object|dynamic lib)'\n  lt_cv_file_magic_cmd='/usr/bin/file -L'\n  lt_cv_file_magic_test_file=/shlib/libc.so\n  ;;\n\ncygwin*)\n  # func_win32_libid is a shell function defined in ltmain.sh\n  lt_cv_deplibs_check_method='file_magic ^x86 archive import|^x86 DLL'\n  lt_cv_file_magic_cmd='func_win32_libid'\n  ;;\n\nmingw* | pw32*)\n  # Base MSYS/MinGW do not provide the 'file' command needed by\n  # func_win32_libid shell function, so use a weaker test based on 'objdump',\n  # unless we find 'file', for example because we are cross-compiling.\n  if ( file / ) >/dev/null 2>&1; then\n    lt_cv_deplibs_check_method='file_magic ^x86 archive import|^x86 DLL'\n    lt_cv_file_magic_cmd='func_win32_libid'\n  else\n    # Keep this pattern in sync with the one in func_win32_libid.\n    lt_cv_deplibs_check_method='file_magic file format (pei*-i386(.*architecture: i386)?|pe-arm-wince|pe-x86-64)'\n    lt_cv_file_magic_cmd='$OBJDUMP -f'\n  fi\n  ;;\n\ncegcc*)\n  # use the weaker test based on 'objdump'. See mingw*.\n  lt_cv_deplibs_check_method='file_magic file format pe-arm-.*little(.*architecture: arm)?'\n  lt_cv_file_magic_cmd='$OBJDUMP -f'\n  ;;\n\ndarwin* | rhapsody*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nfreebsd* | dragonfly*)\n  if echo __ELF__ | $CC -E - | $GREP __ELF__ > /dev/null; then\n    case $host_cpu in\n    i*86 )\n      # Not sure whether the presence of OpenBSD here was a mistake.\n      # Let's accept both of them until this is cleared up.\n      lt_cv_deplibs_check_method='file_magic (FreeBSD|OpenBSD|DragonFly)/i[[3-9]]86 (compact )?demand paged shared library'\n      lt_cv_file_magic_cmd=/usr/bin/file\n      lt_cv_file_magic_test_file=`echo /usr/lib/libc.so.*`\n      ;;\n    esac\n  else\n    lt_cv_deplibs_check_method=pass_all\n  fi\n  ;;\n\nhaiku*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nhpux10.20* | hpux11*)\n  lt_cv_file_magic_cmd=/usr/bin/file\n  case $host_cpu in\n  ia64*)\n    lt_cv_deplibs_check_method='file_magic (s[[0-9]][[0-9]][[0-9]]|ELF-[[0-9]][[0-9]]) shared object file - IA64'\n    lt_cv_file_magic_test_file=/usr/lib/hpux32/libc.so\n    ;;\n  hppa*64*)\n    [lt_cv_deplibs_check_method='file_magic (s[0-9][0-9][0-9]|ELF[ -][0-9][0-9])(-bit)?( [LM]SB)? shared object( file)?[, -]* PA-RISC [0-9]\\.[0-9]']\n    lt_cv_file_magic_test_file=/usr/lib/pa20_64/libc.sl\n    ;;\n  *)\n    lt_cv_deplibs_check_method='file_magic (s[[0-9]][[0-9]][[0-9]]|PA-RISC[[0-9]]\\.[[0-9]]) shared library'\n    lt_cv_file_magic_test_file=/usr/lib/libc.sl\n    ;;\n  esac\n  ;;\n\ninterix[[3-9]]*)\n  # PIC code is broken on Interix 3.x, that's why |\\.a not |_pic\\.a here\n  lt_cv_deplibs_check_method='match_pattern /lib[[^/]]+(\\.so|\\.a)$'\n  ;;\n\nirix5* | irix6* | nonstopux*)\n  case $LD in\n  *-32|*\"-32 \") libmagic=32-bit;;\n  *-n32|*\"-n32 \") libmagic=N32;;\n  *-64|*\"-64 \") libmagic=64-bit;;\n  *) libmagic=never-match;;\n  esac\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\n# This must be glibc/ELF.\nlinux* | k*bsd*-gnu | kopensolaris*-gnu | gnu*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nnetbsd* | netbsdelf*-gnu)\n  if echo __ELF__ | $CC -E - | $GREP __ELF__ > /dev/null; then\n    lt_cv_deplibs_check_method='match_pattern /lib[[^/]]+(\\.so\\.[[0-9]]+\\.[[0-9]]+|_pic\\.a)$'\n  else\n    lt_cv_deplibs_check_method='match_pattern /lib[[^/]]+(\\.so|_pic\\.a)$'\n  fi\n  ;;\n\nnewos6*)\n  lt_cv_deplibs_check_method='file_magic ELF [[0-9]][[0-9]]*-bit [[ML]]SB (executable|dynamic lib)'\n  lt_cv_file_magic_cmd=/usr/bin/file\n  lt_cv_file_magic_test_file=/usr/lib/libnls.so\n  ;;\n\n*nto* | *qnx*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nopenbsd* | bitrig*)\n  if test -z \"`echo __ELF__ | $CC -E - | $GREP __ELF__`\"; then\n    lt_cv_deplibs_check_method='match_pattern /lib[[^/]]+(\\.so\\.[[0-9]]+\\.[[0-9]]+|\\.so|_pic\\.a)$'\n  else\n    lt_cv_deplibs_check_method='match_pattern /lib[[^/]]+(\\.so\\.[[0-9]]+\\.[[0-9]]+|_pic\\.a)$'\n  fi\n  ;;\n\nosf3* | osf4* | osf5*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nrdos*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nsolaris*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nsysv5* | sco3.2v5* | sco5v6* | unixware* | OpenUNIX* | sysv4*uw2*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nsysv4 | sysv4.3*)\n  case $host_vendor in\n  motorola)\n    lt_cv_deplibs_check_method='file_magic ELF [[0-9]][[0-9]]*-bit [[ML]]SB (shared object|dynamic lib) M[[0-9]][[0-9]]* Version [[0-9]]'\n    lt_cv_file_magic_test_file=`echo /usr/lib/libc.so*`\n    ;;\n  ncr)\n    lt_cv_deplibs_check_method=pass_all\n    ;;\n  sequent)\n    lt_cv_file_magic_cmd='/bin/file'\n    lt_cv_deplibs_check_method='file_magic ELF [[0-9]][[0-9]]*-bit [[LM]]SB (shared object|dynamic lib )'\n    ;;\n  sni)\n    lt_cv_file_magic_cmd='/bin/file'\n    lt_cv_deplibs_check_method=\"file_magic ELF [[0-9]][[0-9]]*-bit [[LM]]SB dynamic lib\"\n    lt_cv_file_magic_test_file=/lib/libc.so\n    ;;\n  siemens)\n    lt_cv_deplibs_check_method=pass_all\n    ;;\n  pc)\n    lt_cv_deplibs_check_method=pass_all\n    ;;\n  esac\n  ;;\n\ntpf*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\nos2*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\nesac\n])\n\nfile_magic_glob=\nwant_nocaseglob=no\nif test \"$build\" = \"$host\"; then\n  case $host_os in\n  mingw* | pw32*)\n    if ( shopt | grep nocaseglob ) >/dev/null 2>&1; then\n      want_nocaseglob=yes\n    else\n      file_magic_glob=`echo aAbBcCdDeEfFgGhHiIjJkKlLmMnNoOpPqQrRsStTuUvVwWxXyYzZ | $SED -e \"s/\\(..\\)/s\\/[[\\1]]\\/[[\\1]]\\/g;/g\"`\n    fi\n    ;;\n  esac\nfi\n\nfile_magic_cmd=$lt_cv_file_magic_cmd\ndeplibs_check_method=$lt_cv_deplibs_check_method\ntest -z \"$deplibs_check_method\" && deplibs_check_method=unknown\n\n_LT_DECL([], [deplibs_check_method], [1],\n    [Method to check whether dependent libraries are shared objects])\n_LT_DECL([], [file_magic_cmd], [1],\n    [Command to use when deplibs_check_method = \"file_magic\"])\n_LT_DECL([], [file_magic_glob], [1],\n    [How to find potential files when deplibs_check_method = \"file_magic\"])\n_LT_DECL([], [want_nocaseglob], [1],\n    [Find potential files using nocaseglob when deplibs_check_method = \"file_magic\"])\n])# _LT_CHECK_MAGIC_METHOD\n\n\n# LT_PATH_NM\n# ----------\n# find the pathname to a BSD- or MS-compatible name lister\nAC_DEFUN([LT_PATH_NM],\n[AC_REQUIRE([AC_PROG_CC])dnl\nAC_CACHE_CHECK([for BSD- or MS-compatible name lister (nm)], lt_cv_path_NM,\n[if test -n \"$NM\"; then\n  # Let the user override the test.\n  lt_cv_path_NM=$NM\nelse\n  lt_nm_to_check=${ac_tool_prefix}nm\n  if test -n \"$ac_tool_prefix\" && test \"$build\" = \"$host\"; then\n    lt_nm_to_check=\"$lt_nm_to_check nm\"\n  fi\n  for lt_tmp_nm in $lt_nm_to_check; do\n    lt_save_ifs=$IFS; IFS=$PATH_SEPARATOR\n    for ac_dir in $PATH /usr/ccs/bin/elf /usr/ccs/bin /usr/ucb /bin; do\n      IFS=$lt_save_ifs\n      test -z \"$ac_dir\" && ac_dir=.\n      tmp_nm=$ac_dir/$lt_tmp_nm\n      if test -f \"$tmp_nm\" || test -f \"$tmp_nm$ac_exeext\"; then\n\t# Check to see if the nm accepts a BSD-compat flag.\n\t# Adding the 'sed 1q' prevents false positives on HP-UX, which says:\n\t#   nm: unknown option \"B\" ignored\n\t# Tru64's nm complains that /dev/null is an invalid object file\n\t# MSYS converts /dev/null to NUL, MinGW nm treats NUL as empty\n\tcase $build_os in\n\tmingw*) lt_bad_file=conftest.nm/nofile ;;\n\t*) lt_bad_file=/dev/null ;;\n\tesac\n\tcase `\"$tmp_nm\" -B $lt_bad_file 2>&1 | sed '1q'` in\n\t*$lt_bad_file* | *'Invalid file or object type'*)\n\t  lt_cv_path_NM=\"$tmp_nm -B\"\n\t  break 2\n\t  ;;\n\t*)\n\t  case `\"$tmp_nm\" -p /dev/null 2>&1 | sed '1q'` in\n\t  */dev/null*)\n\t    lt_cv_path_NM=\"$tmp_nm -p\"\n\t    break 2\n\t    ;;\n\t  *)\n\t    lt_cv_path_NM=${lt_cv_path_NM=\"$tmp_nm\"} # keep the first match, but\n\t    continue # so that we can try to find one that supports BSD flags\n\t    ;;\n\t  esac\n\t  ;;\n\tesac\n      fi\n    done\n    IFS=$lt_save_ifs\n  done\n  : ${lt_cv_path_NM=no}\nfi])\nif test no != \"$lt_cv_path_NM\"; then\n  NM=$lt_cv_path_NM\nelse\n  # Didn't find any BSD compatible name lister, look for dumpbin.\n  if test -n \"$DUMPBIN\"; then :\n    # Let the user override the test.\n  else\n    AC_CHECK_TOOLS(DUMPBIN, [dumpbin \"link -dump\"], :)\n    case `$DUMPBIN -symbols -headers /dev/null 2>&1 | sed '1q'` in\n    *COFF*)\n      DUMPBIN=\"$DUMPBIN -symbols -headers\"\n      ;;\n    *)\n      DUMPBIN=:\n      ;;\n    esac\n  fi\n  AC_SUBST([DUMPBIN])\n  if test : != \"$DUMPBIN\"; then\n    NM=$DUMPBIN\n  fi\nfi\ntest -z \"$NM\" && NM=nm\nAC_SUBST([NM])\n_LT_DECL([], [NM], [1], [A BSD- or MS-compatible name lister])dnl\n\nAC_CACHE_CHECK([the name lister ($NM) interface], [lt_cv_nm_interface],\n  [lt_cv_nm_interface=\"BSD nm\"\n  echo \"int some_variable = 0;\" > conftest.$ac_ext\n  (eval echo \"\\\"\\$as_me:$LINENO: $ac_compile\\\"\" >&AS_MESSAGE_LOG_FD)\n  (eval \"$ac_compile\" 2>conftest.err)\n  cat conftest.err >&AS_MESSAGE_LOG_FD\n  (eval echo \"\\\"\\$as_me:$LINENO: $NM \\\\\\\"conftest.$ac_objext\\\\\\\"\\\"\" >&AS_MESSAGE_LOG_FD)\n  (eval \"$NM \\\"conftest.$ac_objext\\\"\" 2>conftest.err > conftest.out)\n  cat conftest.err >&AS_MESSAGE_LOG_FD\n  (eval echo \"\\\"\\$as_me:$LINENO: output\\\"\" >&AS_MESSAGE_LOG_FD)\n  cat conftest.out >&AS_MESSAGE_LOG_FD\n  if $GREP 'External.*some_variable' conftest.out > /dev/null; then\n    lt_cv_nm_interface=\"MS dumpbin\"\n  fi\n  rm -f conftest*])\n])# LT_PATH_NM\n\n# Old names:\nAU_ALIAS([AM_PROG_NM], [LT_PATH_NM])\nAU_ALIAS([AC_PROG_NM], [LT_PATH_NM])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AM_PROG_NM], [])\ndnl AC_DEFUN([AC_PROG_NM], [])\n\n# _LT_CHECK_SHAREDLIB_FROM_LINKLIB\n# --------------------------------\n# how to determine the name of the shared library\n# associated with a specific link library.\n#  -- PORTME fill in with the dynamic library characteristics\nm4_defun([_LT_CHECK_SHAREDLIB_FROM_LINKLIB],\n[m4_require([_LT_DECL_EGREP])\nm4_require([_LT_DECL_OBJDUMP])\nm4_require([_LT_DECL_DLLTOOL])\nAC_CACHE_CHECK([how to associate runtime and link libraries],\nlt_cv_sharedlib_from_linklib_cmd,\n[lt_cv_sharedlib_from_linklib_cmd='unknown'\n\ncase $host_os in\ncygwin* | mingw* | pw32* | cegcc*)\n  # two different shell functions defined in ltmain.sh;\n  # decide which one to use based on capabilities of $DLLTOOL\n  case `$DLLTOOL --help 2>&1` in\n  *--identify-strict*)\n    lt_cv_sharedlib_from_linklib_cmd=func_cygming_dll_for_implib\n    ;;\n  *)\n    lt_cv_sharedlib_from_linklib_cmd=func_cygming_dll_for_implib_fallback\n    ;;\n  esac\n  ;;\n*)\n  # fallback: assume linklib IS sharedlib\n  lt_cv_sharedlib_from_linklib_cmd=$ECHO\n  ;;\nesac\n])\nsharedlib_from_linklib_cmd=$lt_cv_sharedlib_from_linklib_cmd\ntest -z \"$sharedlib_from_linklib_cmd\" && sharedlib_from_linklib_cmd=$ECHO\n\n_LT_DECL([], [sharedlib_from_linklib_cmd], [1],\n    [Command to associate shared and link libraries])\n])# _LT_CHECK_SHAREDLIB_FROM_LINKLIB\n\n\n# _LT_PATH_MANIFEST_TOOL\n# ----------------------\n# locate the manifest tool\nm4_defun([_LT_PATH_MANIFEST_TOOL],\n[AC_CHECK_TOOL(MANIFEST_TOOL, mt, :)\ntest -z \"$MANIFEST_TOOL\" && MANIFEST_TOOL=mt\nAC_CACHE_CHECK([if $MANIFEST_TOOL is a manifest tool], [lt_cv_path_mainfest_tool],\n  [lt_cv_path_mainfest_tool=no\n  echo \"$as_me:$LINENO: $MANIFEST_TOOL '-?'\" >&AS_MESSAGE_LOG_FD\n  $MANIFEST_TOOL '-?' 2>conftest.err > conftest.out\n  cat conftest.err >&AS_MESSAGE_LOG_FD\n  if $GREP 'Manifest Tool' conftest.out > /dev/null; then\n    lt_cv_path_mainfest_tool=yes\n  fi\n  rm -f conftest*])\nif test yes != \"$lt_cv_path_mainfest_tool\"; then\n  MANIFEST_TOOL=:\nfi\n_LT_DECL([], [MANIFEST_TOOL], [1], [Manifest tool])dnl\n])# _LT_PATH_MANIFEST_TOOL\n\n\n# _LT_DLL_DEF_P([FILE])\n# ---------------------\n# True iff FILE is a Windows DLL '.def' file.\n# Keep in sync with func_dll_def_p in the libtool script\nAC_DEFUN([_LT_DLL_DEF_P],\n[dnl\n  test DEF = \"`$SED -n dnl\n    -e '\\''s/^[[\t ]]*//'\\'' dnl Strip leading whitespace\n    -e '\\''/^\\(;.*\\)*$/d'\\'' dnl      Delete empty lines and comments\n    -e '\\''s/^\\(EXPORTS\\|LIBRARY\\)\\([[\t ]].*\\)*$/DEF/p'\\'' dnl\n    -e q dnl                          Only consider the first \"real\" line\n    $1`\" dnl\n])# _LT_DLL_DEF_P\n\n\n# LT_LIB_M\n# --------\n# check for math library\nAC_DEFUN([LT_LIB_M],\n[AC_REQUIRE([AC_CANONICAL_HOST])dnl\nLIBM=\ncase $host in\n*-*-beos* | *-*-cegcc* | *-*-cygwin* | *-*-haiku* | *-*-pw32* | *-*-darwin*)\n  # These system don't have libm, or don't need it\n  ;;\n*-ncr-sysv4.3*)\n  AC_CHECK_LIB(mw, _mwvalidcheckl, LIBM=-lmw)\n  AC_CHECK_LIB(m, cos, LIBM=\"$LIBM -lm\")\n  ;;\n*)\n  AC_CHECK_LIB(m, cos, LIBM=-lm)\n  ;;\nesac\nAC_SUBST([LIBM])\n])# LT_LIB_M\n\n# Old name:\nAU_ALIAS([AC_CHECK_LIBM], [LT_LIB_M])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_CHECK_LIBM], [])\n\n\n# _LT_COMPILER_NO_RTTI([TAGNAME])\n# -------------------------------\nm4_defun([_LT_COMPILER_NO_RTTI],\n[m4_require([_LT_TAG_COMPILER])dnl\n\n_LT_TAGVAR(lt_prog_compiler_no_builtin_flag, $1)=\n\nif test yes = \"$GCC\"; then\n  case $cc_basename in\n  nvcc*)\n    _LT_TAGVAR(lt_prog_compiler_no_builtin_flag, $1)=' -Xcompiler -fno-builtin' ;;\n  *)\n    _LT_TAGVAR(lt_prog_compiler_no_builtin_flag, $1)=' -fno-builtin' ;;\n  esac\n\n  _LT_COMPILER_OPTION([if $compiler supports -fno-rtti -fno-exceptions],\n    lt_cv_prog_compiler_rtti_exceptions,\n    [-fno-rtti -fno-exceptions], [],\n    [_LT_TAGVAR(lt_prog_compiler_no_builtin_flag, $1)=\"$_LT_TAGVAR(lt_prog_compiler_no_builtin_flag, $1) -fno-rtti -fno-exceptions\"])\nfi\n_LT_TAGDECL([no_builtin_flag], [lt_prog_compiler_no_builtin_flag], [1],\n\t[Compiler flag to turn off builtin functions])\n])# _LT_COMPILER_NO_RTTI\n\n\n# _LT_CMD_GLOBAL_SYMBOLS\n# ----------------------\nm4_defun([_LT_CMD_GLOBAL_SYMBOLS],\n[AC_REQUIRE([AC_CANONICAL_HOST])dnl\nAC_REQUIRE([AC_PROG_CC])dnl\nAC_REQUIRE([AC_PROG_AWK])dnl\nAC_REQUIRE([LT_PATH_NM])dnl\nAC_REQUIRE([LT_PATH_LD])dnl\nm4_require([_LT_DECL_SED])dnl\nm4_require([_LT_DECL_EGREP])dnl\nm4_require([_LT_TAG_COMPILER])dnl\n\n# Check for command to grab the raw symbol name followed by C symbol from nm.\nAC_MSG_CHECKING([command to parse $NM output from $compiler object])\nAC_CACHE_VAL([lt_cv_sys_global_symbol_pipe],\n[\n# These are sane defaults that work on at least a few old systems.\n# [They come from Ultrix.  What could be older than Ultrix?!! ;)]\n\n# Character class describing NM global symbol codes.\nsymcode='[[BCDEGRST]]'\n\n# Regexp to match symbols that can be accessed directly from C.\nsympat='\\([[_A-Za-z]][[_A-Za-z0-9]]*\\)'\n\n# Define system-specific variables.\ncase $host_os in\naix*)\n  symcode='[[BCDT]]'\n  ;;\ncygwin* | mingw* | pw32* | cegcc*)\n  symcode='[[ABCDGISTW]]'\n  ;;\nhpux*)\n  if test ia64 = \"$host_cpu\"; then\n    symcode='[[ABCDEGRST]]'\n  fi\n  ;;\nirix* | nonstopux*)\n  symcode='[[BCDEGRST]]'\n  ;;\nosf*)\n  symcode='[[BCDEGQRST]]'\n  ;;\nsolaris*)\n  symcode='[[BDRT]]'\n  ;;\nsco3.2v5*)\n  symcode='[[DT]]'\n  ;;\nsysv4.2uw2*)\n  symcode='[[DT]]'\n  ;;\nsysv5* | sco5v6* | unixware* | OpenUNIX*)\n  symcode='[[ABDT]]'\n  ;;\nsysv4)\n  symcode='[[DFNSTU]]'\n  ;;\nesac\n\n# If we're using GNU nm, then use its standard symbol codes.\ncase `$NM -V 2>&1` in\n*GNU* | *'with BFD'*)\n  symcode='[[ABCDGIRSTW]]' ;;\nesac\n\nif test \"$lt_cv_nm_interface\" = \"MS dumpbin\"; then\n  # Gets list of data symbols to import.\n  lt_cv_sys_global_symbol_to_import=\"sed -n -e 's/^I .* \\(.*\\)$/\\1/p'\"\n  # Adjust the below global symbol transforms to fixup imported variables.\n  lt_cdecl_hook=\" -e 's/^I .* \\(.*\\)$/extern __declspec(dllimport) char \\1;/p'\"\n  lt_c_name_hook=\" -e 's/^I .* \\(.*\\)$/  {\\\"\\1\\\", (void *) 0},/p'\"\n  lt_c_name_lib_hook=\"\\\n  -e 's/^I .* \\(lib.*\\)$/  {\\\"\\1\\\", (void *) 0},/p'\\\n  -e 's/^I .* \\(.*\\)$/  {\\\"lib\\1\\\", (void *) 0},/p'\"\nelse\n  # Disable hooks by default.\n  lt_cv_sys_global_symbol_to_import=\n  lt_cdecl_hook=\n  lt_c_name_hook=\n  lt_c_name_lib_hook=\nfi\n\n# Transform an extracted symbol line into a proper C declaration.\n# Some systems (esp. on ia64) link data and code symbols differently,\n# so use this general approach.\nlt_cv_sys_global_symbol_to_cdecl=\"sed -n\"\\\n$lt_cdecl_hook\\\n\" -e 's/^T .* \\(.*\\)$/extern int \\1();/p'\"\\\n\" -e 's/^$symcode$symcode* .* \\(.*\\)$/extern char \\1;/p'\"\n\n# Transform an extracted symbol line into symbol name and symbol address\nlt_cv_sys_global_symbol_to_c_name_address=\"sed -n\"\\\n$lt_c_name_hook\\\n\" -e 's/^: \\(.*\\) .*$/  {\\\"\\1\\\", (void *) 0},/p'\"\\\n\" -e 's/^$symcode$symcode* .* \\(.*\\)$/  {\\\"\\1\\\", (void *) \\&\\1},/p'\"\n\n# Transform an extracted symbol line into symbol name with lib prefix and\n# symbol address.\nlt_cv_sys_global_symbol_to_c_name_address_lib_prefix=\"sed -n\"\\\n$lt_c_name_lib_hook\\\n\" -e 's/^: \\(.*\\) .*$/  {\\\"\\1\\\", (void *) 0},/p'\"\\\n\" -e 's/^$symcode$symcode* .* \\(lib.*\\)$/  {\\\"\\1\\\", (void *) \\&\\1},/p'\"\\\n\" -e 's/^$symcode$symcode* .* \\(.*\\)$/  {\\\"lib\\1\\\", (void *) \\&\\1},/p'\"\n\n# Handle CRLF in mingw tool chain\nopt_cr=\ncase $build_os in\nmingw*)\n  opt_cr=`$ECHO 'x\\{0,1\\}' | tr x '\\015'` # option cr in regexp\n  ;;\nesac\n\n# Try without a prefix underscore, then with it.\nfor ac_symprfx in \"\" \"_\"; do\n\n  # Transform symcode, sympat, and symprfx into a raw symbol and a C symbol.\n  symxfrm=\"\\\\1 $ac_symprfx\\\\2 \\\\2\"\n\n  # Write the raw and C identifiers.\n  if test \"$lt_cv_nm_interface\" = \"MS dumpbin\"; then\n    # Fake it for dumpbin and say T for any non-static function,\n    # D for any global variable and I for any imported variable.\n    # Also find C++ and __fastcall symbols from MSVC++,\n    # which start with @ or ?.\n    lt_cv_sys_global_symbol_pipe=\"$AWK ['\"\\\n\"     {last_section=section; section=\\$ 3};\"\\\n\"     /^COFF SYMBOL TABLE/{for(i in hide) delete hide[i]};\"\\\n\"     /Section length .*#relocs.*(pick any)/{hide[last_section]=1};\"\\\n\"     /^ *Symbol name *: /{split(\\$ 0,sn,\\\":\\\"); si=substr(sn[2],2)};\"\\\n\"     /^ *Type *: code/{print \\\"T\\\",si,substr(si,length(prfx))};\"\\\n\"     /^ *Type *: data/{print \\\"I\\\",si,substr(si,length(prfx))};\"\\\n\"     \\$ 0!~/External *\\|/{next};\"\\\n\"     / 0+ UNDEF /{next}; / UNDEF \\([^|]\\)*()/{next};\"\\\n\"     {if(hide[section]) next};\"\\\n\"     {f=\\\"D\\\"}; \\$ 0~/\\(\\).*\\|/{f=\\\"T\\\"};\"\\\n\"     {split(\\$ 0,a,/\\||\\r/); split(a[2],s)};\"\\\n\"     s[1]~/^[@?]/{print f,s[1],s[1]; next};\"\\\n\"     s[1]~prfx {split(s[1],t,\\\"@\\\"); print f,t[1],substr(t[1],length(prfx))}\"\\\n\"     ' prfx=^$ac_symprfx]\"\n  else\n    lt_cv_sys_global_symbol_pipe=\"sed -n -e 's/^.*[[\t ]]\\($symcode$symcode*\\)[[\t ]][[\t ]]*$ac_symprfx$sympat$opt_cr$/$symxfrm/p'\"\n  fi\n  lt_cv_sys_global_symbol_pipe=\"$lt_cv_sys_global_symbol_pipe | sed '/ __gnu_lto/d'\"\n\n  # Check to see that the pipe works correctly.\n  pipe_works=no\n\n  rm -f conftest*\n  cat > conftest.$ac_ext <<_LT_EOF\n#ifdef __cplusplus\nextern \"C\" {\n#endif\nchar nm_test_var;\nvoid nm_test_func(void);\nvoid nm_test_func(void){}\n#ifdef __cplusplus\n}\n#endif\nint main(){nm_test_var='a';nm_test_func();return(0);}\n_LT_EOF\n\n  if AC_TRY_EVAL(ac_compile); then\n    # Now try to grab the symbols.\n    nlist=conftest.nm\n    $ECHO \"$as_me:$LINENO: $NM conftest.$ac_objext | $lt_cv_sys_global_symbol_pipe > $nlist\" >&AS_MESSAGE_LOG_FD\n    if eval \"$NM\" conftest.$ac_objext \\| \"$lt_cv_sys_global_symbol_pipe\" \\> $nlist 2>&AS_MESSAGE_LOG_FD && test -s \"$nlist\"; then\n      # Try sorting and uniquifying the output.\n      if sort \"$nlist\" | uniq > \"$nlist\"T; then\n\tmv -f \"$nlist\"T \"$nlist\"\n      else\n\trm -f \"$nlist\"T\n      fi\n\n      # Make sure that we snagged all the symbols we need.\n      if $GREP ' nm_test_var$' \"$nlist\" >/dev/null; then\n\tif $GREP ' nm_test_func$' \"$nlist\" >/dev/null; then\n\t  cat <<_LT_EOF > conftest.$ac_ext\n/* Keep this code in sync between libtool.m4, ltmain, lt_system.h, and tests.  */\n#if defined _WIN32 || defined __CYGWIN__ || defined _WIN32_WCE\n/* DATA imports from DLLs on WIN32 can't be const, because runtime\n   relocations are performed -- see ld's documentation on pseudo-relocs.  */\n# define LT@&t@_DLSYM_CONST\n#elif defined __osf__\n/* This system does not cope well with relocations in const data.  */\n# define LT@&t@_DLSYM_CONST\n#else\n# define LT@&t@_DLSYM_CONST const\n#endif\n\n#ifdef __cplusplus\nextern \"C\" {\n#endif\n\n_LT_EOF\n\t  # Now generate the symbol file.\n\t  eval \"$lt_cv_sys_global_symbol_to_cdecl\"' < \"$nlist\" | $GREP -v main >> conftest.$ac_ext'\n\n\t  cat <<_LT_EOF >> conftest.$ac_ext\n\n/* The mapping between symbol names and symbols.  */\nLT@&t@_DLSYM_CONST struct {\n  const char *name;\n  void       *address;\n}\nlt__PROGRAM__LTX_preloaded_symbols[[]] =\n{\n  { \"@PROGRAM@\", (void *) 0 },\n_LT_EOF\n\t  $SED \"s/^$symcode$symcode* .* \\(.*\\)$/  {\\\"\\1\\\", (void *) \\&\\1},/\" < \"$nlist\" | $GREP -v main >> conftest.$ac_ext\n\t  cat <<\\_LT_EOF >> conftest.$ac_ext\n  {0, (void *) 0}\n};\n\n/* This works around a problem in FreeBSD linker */\n#ifdef FREEBSD_WORKAROUND\nstatic const void *lt_preloaded_setup() {\n  return lt__PROGRAM__LTX_preloaded_symbols;\n}\n#endif\n\n#ifdef __cplusplus\n}\n#endif\n_LT_EOF\n\t  # Now try linking the two files.\n\t  mv conftest.$ac_objext conftstm.$ac_objext\n\t  lt_globsym_save_LIBS=$LIBS\n\t  lt_globsym_save_CFLAGS=$CFLAGS\n\t  LIBS=conftstm.$ac_objext\n\t  CFLAGS=\"$CFLAGS$_LT_TAGVAR(lt_prog_compiler_no_builtin_flag, $1)\"\n\t  if AC_TRY_EVAL(ac_link) && test -s conftest$ac_exeext; then\n\t    pipe_works=yes\n\t  fi\n\t  LIBS=$lt_globsym_save_LIBS\n\t  CFLAGS=$lt_globsym_save_CFLAGS\n\telse\n\t  echo \"cannot find nm_test_func in $nlist\" >&AS_MESSAGE_LOG_FD\n\tfi\n      else\n\techo \"cannot find nm_test_var in $nlist\" >&AS_MESSAGE_LOG_FD\n      fi\n    else\n      echo \"cannot run $lt_cv_sys_global_symbol_pipe\" >&AS_MESSAGE_LOG_FD\n    fi\n  else\n    echo \"$progname: failed program was:\" >&AS_MESSAGE_LOG_FD\n    cat conftest.$ac_ext >&5\n  fi\n  rm -rf conftest* conftst*\n\n  # Do not use the global_symbol_pipe unless it works.\n  if test yes = \"$pipe_works\"; then\n    break\n  else\n    lt_cv_sys_global_symbol_pipe=\n  fi\ndone\n])\nif test -z \"$lt_cv_sys_global_symbol_pipe\"; then\n  lt_cv_sys_global_symbol_to_cdecl=\nfi\nif test -z \"$lt_cv_sys_global_symbol_pipe$lt_cv_sys_global_symbol_to_cdecl\"; then\n  AC_MSG_RESULT(failed)\nelse\n  AC_MSG_RESULT(ok)\nfi\n\n# Response file support.\nif test \"$lt_cv_nm_interface\" = \"MS dumpbin\"; then\n  nm_file_list_spec='@'\nelif $NM --help 2>/dev/null | grep '[[@]]FILE' >/dev/null; then\n  nm_file_list_spec='@'\nfi\n\n_LT_DECL([global_symbol_pipe], [lt_cv_sys_global_symbol_pipe], [1],\n    [Take the output of nm and produce a listing of raw symbols and C names])\n_LT_DECL([global_symbol_to_cdecl], [lt_cv_sys_global_symbol_to_cdecl], [1],\n    [Transform the output of nm in a proper C declaration])\n_LT_DECL([global_symbol_to_import], [lt_cv_sys_global_symbol_to_import], [1],\n    [Transform the output of nm into a list of symbols to manually relocate])\n_LT_DECL([global_symbol_to_c_name_address],\n    [lt_cv_sys_global_symbol_to_c_name_address], [1],\n    [Transform the output of nm in a C name address pair])\n_LT_DECL([global_symbol_to_c_name_address_lib_prefix],\n    [lt_cv_sys_global_symbol_to_c_name_address_lib_prefix], [1],\n    [Transform the output of nm in a C name address pair when lib prefix is needed])\n_LT_DECL([nm_interface], [lt_cv_nm_interface], [1],\n    [The name lister interface])\n_LT_DECL([], [nm_file_list_spec], [1],\n    [Specify filename containing input files for $NM])\n]) # _LT_CMD_GLOBAL_SYMBOLS\n\n\n# _LT_COMPILER_PIC([TAGNAME])\n# ---------------------------\nm4_defun([_LT_COMPILER_PIC],\n[m4_require([_LT_TAG_COMPILER])dnl\n_LT_TAGVAR(lt_prog_compiler_wl, $1)=\n_LT_TAGVAR(lt_prog_compiler_pic, $1)=\n_LT_TAGVAR(lt_prog_compiler_static, $1)=\n\nm4_if([$1], [CXX], [\n  # C++ specific cases for pic, static, wl, etc.\n  if test yes = \"$GXX\"; then\n    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n    _LT_TAGVAR(lt_prog_compiler_static, $1)='-static'\n\n    case $host_os in\n    aix*)\n      # All AIX code is PIC.\n      if test ia64 = \"$host_cpu\"; then\n\t# AIX 5 now supports IA64 processor\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n      fi\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n      ;;\n\n    amigaos*)\n      case $host_cpu in\n      powerpc)\n            # see comment about AmigaOS4 .so support\n            _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n        ;;\n      m68k)\n            # FIXME: we need at least 68020 code to build shared libraries, but\n            # adding the '-m68020' flag to GCC prevents building anything better,\n            # like '-m68040'.\n            _LT_TAGVAR(lt_prog_compiler_pic, $1)='-m68020 -resident32 -malways-restore-a4'\n        ;;\n      esac\n      ;;\n\n    beos* | irix5* | irix6* | nonstopux* | osf3* | osf4* | osf5*)\n      # PIC is the default for these OSes.\n      ;;\n    mingw* | cygwin* | os2* | pw32* | cegcc*)\n      # This hack is so that the source file can tell whether it is being\n      # built for inclusion in a dll (and should export symbols for example).\n      # Although the cygwin gcc ignores -fPIC, still need this for old-style\n      # (--disable-auto-import) libraries\n      m4_if([$1], [GCJ], [],\n\t[_LT_TAGVAR(lt_prog_compiler_pic, $1)='-DDLL_EXPORT'])\n      case $host_os in\n      os2*)\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='$wl-static'\n\t;;\n      esac\n      ;;\n    darwin* | rhapsody*)\n      # PIC is the default on this platform\n      # Common symbols not allowed in MH_DYLIB files\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fno-common'\n      ;;\n    *djgpp*)\n      # DJGPP does not support shared libraries at all\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)=\n      ;;\n    haiku*)\n      # PIC is the default for Haiku.\n      # The \"-static\" flag exists, but is broken.\n      _LT_TAGVAR(lt_prog_compiler_static, $1)=\n      ;;\n    interix[[3-9]]*)\n      # Interix 3.x gcc -fpic/-fPIC options generate broken code.\n      # Instead, we relocate shared libraries at runtime.\n      ;;\n    sysv4*MP*)\n      if test -d /usr/nec; then\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)=-Kconform_pic\n      fi\n      ;;\n    hpux*)\n      # PIC is the default for 64-bit PA HP-UX, but not for 32-bit\n      # PA HP-UX.  On IA64 HP-UX, PIC is the default but the pic flag\n      # sets the default TLS model and affects inlining.\n      case $host_cpu in\n      hppa*64*)\n\t;;\n      *)\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n\t;;\n      esac\n      ;;\n    *qnx* | *nto*)\n      # QNX uses GNU C++, but need to define -shared option too, otherwise\n      # it will coredump.\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC -shared'\n      ;;\n    *)\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n      ;;\n    esac\n  else\n    case $host_os in\n      aix[[4-9]]*)\n\t# All AIX code is PIC.\n\tif test ia64 = \"$host_cpu\"; then\n\t  # AIX 5 now supports IA64 processor\n\t  _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n\telse\n\t  _LT_TAGVAR(lt_prog_compiler_static, $1)='-bnso -bI:/lib/syscalls.exp'\n\tfi\n\t;;\n      chorus*)\n\tcase $cc_basename in\n\tcxch68*)\n\t  # Green Hills C++ Compiler\n\t  # _LT_TAGVAR(lt_prog_compiler_static, $1)=\"--no_auto_instantiation -u __main -u __premain -u _abort -r $COOL_DIR/lib/libOrb.a $MVME_DIR/lib/CC/libC.a $MVME_DIR/lib/classix/libcx.s.a\"\n\t  ;;\n\tesac\n\t;;\n      mingw* | cygwin* | os2* | pw32* | cegcc*)\n\t# This hack is so that the source file can tell whether it is being\n\t# built for inclusion in a dll (and should export symbols for example).\n\tm4_if([$1], [GCJ], [],\n\t  [_LT_TAGVAR(lt_prog_compiler_pic, $1)='-DDLL_EXPORT'])\n\t;;\n      dgux*)\n\tcase $cc_basename in\n\t  ec++*)\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n\t    ;;\n\t  ghcx*)\n\t    # Green Hills C++ Compiler\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-pic'\n\t    ;;\n\t  *)\n\t    ;;\n\tesac\n\t;;\n      freebsd* | dragonfly*)\n\t# FreeBSD uses GNU C++\n\t;;\n      hpux9* | hpux10* | hpux11*)\n\tcase $cc_basename in\n\t  CC*)\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='$wl-a ${wl}archive'\n\t    if test ia64 != \"$host_cpu\"; then\n\t      _LT_TAGVAR(lt_prog_compiler_pic, $1)='+Z'\n\t    fi\n\t    ;;\n\t  aCC*)\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='$wl-a ${wl}archive'\n\t    case $host_cpu in\n\t    hppa*64*|ia64*)\n\t      # +Z the default\n\t      ;;\n\t    *)\n\t      _LT_TAGVAR(lt_prog_compiler_pic, $1)='+Z'\n\t      ;;\n\t    esac\n\t    ;;\n\t  *)\n\t    ;;\n\tesac\n\t;;\n      interix*)\n\t# This is c89, which is MS Visual C++ (no shared libs)\n\t# Anyone wants to do a port?\n\t;;\n      irix5* | irix6* | nonstopux*)\n\tcase $cc_basename in\n\t  CC*)\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='-non_shared'\n\t    # CC pic flag -KPIC is the default.\n\t    ;;\n\t  *)\n\t    ;;\n\tesac\n\t;;\n      linux* | k*bsd*-gnu | kopensolaris*-gnu | gnu*)\n\tcase $cc_basename in\n\t  KCC*)\n\t    # KAI C++ Compiler\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='--backend -Wl,'\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n\t    ;;\n\t  ecpc* )\n\t    # old Intel C++ for x86_64, which still supported -KPIC.\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='-static'\n\t    ;;\n\t  icpc* )\n\t    # Intel C++, used to be incompatible with GCC.\n\t    # ICC 10 doesn't accept -KPIC any more.\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='-static'\n\t    ;;\n\t  pgCC* | pgcpp*)\n\t    # Portland Group C++ compiler\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fpic'\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n\t    ;;\n\t  cxx*)\n\t    # Compaq C++\n\t    # Make sure the PIC flag is empty.  It appears that all Alpha\n\t    # Linux and Compaq Tru64 Unix objects are PIC.\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)=\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='-non_shared'\n\t    ;;\n\t  xlc* | xlC* | bgxl[[cC]]* | mpixl[[cC]]*)\n\t    # IBM XL 8.0, 9.0 on PPC and BlueGene\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-qpic'\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='-qstaticlink'\n\t    ;;\n\t  *)\n\t    case `$CC -V 2>&1 | sed 5q` in\n\t    *Sun\\ C*)\n\t      # Sun C++ 5.9\n\t      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n\t      _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n\t      _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Qoption ld '\n\t      ;;\n\t    esac\n\t    ;;\n\tesac\n\t;;\n      lynxos*)\n\t;;\n      m88k*)\n\t;;\n      mvs*)\n\tcase $cc_basename in\n\t  cxx*)\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-W c,exportall'\n\t    ;;\n\t  *)\n\t    ;;\n\tesac\n\t;;\n      netbsd* | netbsdelf*-gnu)\n\t;;\n      *qnx* | *nto*)\n        # QNX uses GNU C++, but need to define -shared option too, otherwise\n        # it will coredump.\n        _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC -shared'\n        ;;\n      osf3* | osf4* | osf5*)\n\tcase $cc_basename in\n\t  KCC*)\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='--backend -Wl,'\n\t    ;;\n\t  RCC*)\n\t    # Rational C++ 2.4.1\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-pic'\n\t    ;;\n\t  cxx*)\n\t    # Digital/Compaq C++\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t    # Make sure the PIC flag is empty.  It appears that all Alpha\n\t    # Linux and Compaq Tru64 Unix objects are PIC.\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)=\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='-non_shared'\n\t    ;;\n\t  *)\n\t    ;;\n\tesac\n\t;;\n      psos*)\n\t;;\n      solaris*)\n\tcase $cc_basename in\n\t  CC* | sunCC*)\n\t    # Sun C++ 4.2, 5.x and Centerline C++\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Qoption ld '\n\t    ;;\n\t  gcx*)\n\t    # Green Hills C++ Compiler\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-PIC'\n\t    ;;\n\t  *)\n\t    ;;\n\tesac\n\t;;\n      sunos4*)\n\tcase $cc_basename in\n\t  CC*)\n\t    # Sun C++ 4.x\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-pic'\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n\t    ;;\n\t  lcc*)\n\t    # Lucid\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-pic'\n\t    ;;\n\t  *)\n\t    ;;\n\tesac\n\t;;\n      sysv5* | unixware* | sco3.2v5* | sco5v6* | OpenUNIX*)\n\tcase $cc_basename in\n\t  CC*)\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n\t    ;;\n\tesac\n\t;;\n      tandem*)\n\tcase $cc_basename in\n\t  NCC*)\n\t    # NonStop-UX NCC 3.20\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n\t    ;;\n\t  *)\n\t    ;;\n\tesac\n\t;;\n      vxworks*)\n\t;;\n      *)\n\t_LT_TAGVAR(lt_prog_compiler_can_build_shared, $1)=no\n\t;;\n    esac\n  fi\n],\n[\n  if test yes = \"$GCC\"; then\n    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n    _LT_TAGVAR(lt_prog_compiler_static, $1)='-static'\n\n    case $host_os in\n      aix*)\n      # All AIX code is PIC.\n      if test ia64 = \"$host_cpu\"; then\n\t# AIX 5 now supports IA64 processor\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n      fi\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n      ;;\n\n    amigaos*)\n      case $host_cpu in\n      powerpc)\n            # see comment about AmigaOS4 .so support\n            _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n        ;;\n      m68k)\n            # FIXME: we need at least 68020 code to build shared libraries, but\n            # adding the '-m68020' flag to GCC prevents building anything better,\n            # like '-m68040'.\n            _LT_TAGVAR(lt_prog_compiler_pic, $1)='-m68020 -resident32 -malways-restore-a4'\n        ;;\n      esac\n      ;;\n\n    beos* | irix5* | irix6* | nonstopux* | osf3* | osf4* | osf5*)\n      # PIC is the default for these OSes.\n      ;;\n\n    mingw* | cygwin* | pw32* | os2* | cegcc*)\n      # This hack is so that the source file can tell whether it is being\n      # built for inclusion in a dll (and should export symbols for example).\n      # Although the cygwin gcc ignores -fPIC, still need this for old-style\n      # (--disable-auto-import) libraries\n      m4_if([$1], [GCJ], [],\n\t[_LT_TAGVAR(lt_prog_compiler_pic, $1)='-DDLL_EXPORT'])\n      case $host_os in\n      os2*)\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='$wl-static'\n\t;;\n      esac\n      ;;\n\n    darwin* | rhapsody*)\n      # PIC is the default on this platform\n      # Common symbols not allowed in MH_DYLIB files\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fno-common'\n      ;;\n\n    haiku*)\n      # PIC is the default for Haiku.\n      # The \"-static\" flag exists, but is broken.\n      _LT_TAGVAR(lt_prog_compiler_static, $1)=\n      ;;\n\n    hpux*)\n      # PIC is the default for 64-bit PA HP-UX, but not for 32-bit\n      # PA HP-UX.  On IA64 HP-UX, PIC is the default but the pic flag\n      # sets the default TLS model and affects inlining.\n      case $host_cpu in\n      hppa*64*)\n\t# +Z the default\n\t;;\n      *)\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n\t;;\n      esac\n      ;;\n\n    interix[[3-9]]*)\n      # Interix 3.x gcc -fpic/-fPIC options generate broken code.\n      # Instead, we relocate shared libraries at runtime.\n      ;;\n\n    msdosdjgpp*)\n      # Just because we use GCC doesn't mean we suddenly get shared libraries\n      # on systems that don't support them.\n      _LT_TAGVAR(lt_prog_compiler_can_build_shared, $1)=no\n      enable_shared=no\n      ;;\n\n    *nto* | *qnx*)\n      # QNX uses GNU C++, but need to define -shared option too, otherwise\n      # it will coredump.\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC -shared'\n      ;;\n\n    sysv4*MP*)\n      if test -d /usr/nec; then\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)=-Kconform_pic\n      fi\n      ;;\n\n    *)\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n      ;;\n    esac\n\n    case $cc_basename in\n    nvcc*) # Cuda Compiler Driver 2.2\n      _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Xlinker '\n      if test -n \"$_LT_TAGVAR(lt_prog_compiler_pic, $1)\"; then\n        _LT_TAGVAR(lt_prog_compiler_pic, $1)=\"-Xcompiler $_LT_TAGVAR(lt_prog_compiler_pic, $1)\"\n      fi\n      ;;\n    esac\n  else\n    # PORTME Check for flag to pass linker flags through the system compiler.\n    case $host_os in\n    aix*)\n      _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n      if test ia64 = \"$host_cpu\"; then\n\t# AIX 5 now supports IA64 processor\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n      else\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='-bnso -bI:/lib/syscalls.exp'\n      fi\n      ;;\n\n    darwin* | rhapsody*)\n      # PIC is the default on this platform\n      # Common symbols not allowed in MH_DYLIB files\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fno-common'\n      case $cc_basename in\n      nagfor*)\n        # NAG Fortran compiler\n        _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,-Wl,,'\n        _LT_TAGVAR(lt_prog_compiler_pic, $1)='-PIC'\n        _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n        ;;\n      esac\n      ;;\n\n    mingw* | cygwin* | pw32* | os2* | cegcc*)\n      # This hack is so that the source file can tell whether it is being\n      # built for inclusion in a dll (and should export symbols for example).\n      m4_if([$1], [GCJ], [],\n\t[_LT_TAGVAR(lt_prog_compiler_pic, $1)='-DDLL_EXPORT'])\n      case $host_os in\n      os2*)\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='$wl-static'\n\t;;\n      esac\n      ;;\n\n    hpux9* | hpux10* | hpux11*)\n      _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n      # PIC is the default for IA64 HP-UX and 64-bit HP-UX, but\n      # not for PA HP-UX.\n      case $host_cpu in\n      hppa*64*|ia64*)\n\t# +Z the default\n\t;;\n      *)\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)='+Z'\n\t;;\n      esac\n      # Is there a better lt_prog_compiler_static that works with the bundled CC?\n      _LT_TAGVAR(lt_prog_compiler_static, $1)='$wl-a ${wl}archive'\n      ;;\n\n    irix5* | irix6* | nonstopux*)\n      _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n      # PIC (with -KPIC) is the default.\n      _LT_TAGVAR(lt_prog_compiler_static, $1)='-non_shared'\n      ;;\n\n    linux* | k*bsd*-gnu | kopensolaris*-gnu | gnu*)\n      case $cc_basename in\n      # old Intel for x86_64, which still supported -KPIC.\n      ecc*)\n\t_LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='-static'\n        ;;\n      # flang / f18. f95 an alias for gfortran or flang on Debian\n      flang* | f18* | f95*)\n\t_LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='-static'\n        ;;\n      # icc used to be incompatible with GCC.\n      # ICC 10 doesn't accept -KPIC any more.\n      icc* | ifort*)\n\t_LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='-static'\n        ;;\n      # Lahey Fortran 8.1.\n      lf95*)\n\t_LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)='--shared'\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='--static'\n\t;;\n      nagfor*)\n\t# NAG Fortran compiler\n\t_LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,-Wl,,'\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)='-PIC'\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n\t;;\n      tcc*)\n\t# Fabrice Bellard et al's Tiny C Compiler\n\t_LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='-static'\n\t;;\n      pgcc* | pgf77* | pgf90* | pgf95* | pgfortran*)\n        # Portland Group compilers (*not* the Pentium gcc compiler,\n\t# which looks to be a dead project)\n\t_LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)='-fpic'\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n        ;;\n      ccc*)\n        _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n        # All Alpha code is PIC.\n        _LT_TAGVAR(lt_prog_compiler_static, $1)='-non_shared'\n        ;;\n      xl* | bgxl* | bgf* | mpixl*)\n\t# IBM XL C 8.0/Fortran 10.1, 11.1 on PPC and BlueGene\n\t_LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)='-qpic'\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='-qstaticlink'\n\t;;\n      *)\n\tcase `$CC -V 2>&1 | sed 5q` in\n\t*Sun\\ Ceres\\ Fortran* | *Sun*Fortran*\\ [[1-7]].* | *Sun*Fortran*\\ 8.[[0-3]]*)\n\t  # Sun Fortran 8.3 passes all unrecognized flags to the linker\n\t  _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n\t  _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n\t  _LT_TAGVAR(lt_prog_compiler_wl, $1)=''\n\t  ;;\n\t*Sun\\ F* | *Sun*Fortran*)\n\t  _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n\t  _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n\t  _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Qoption ld '\n\t  ;;\n\t*Sun\\ C*)\n\t  # Sun C 5.9\n\t  _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n\t  _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n\t  _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t  ;;\n        *Intel*\\ [[CF]]*Compiler*)\n\t  _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t  _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n\t  _LT_TAGVAR(lt_prog_compiler_static, $1)='-static'\n\t  ;;\n\t*Portland\\ Group*)\n\t  _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t  _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fpic'\n\t  _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n\t  ;;\n\tesac\n\t;;\n      esac\n      ;;\n\n    newsos6)\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n      _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n      ;;\n\n    *nto* | *qnx*)\n      # QNX uses GNU C++, but need to define -shared option too, otherwise\n      # it will coredump.\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC -shared'\n      ;;\n\n    osf3* | osf4* | osf5*)\n      _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n      # All OSF/1 code is PIC.\n      _LT_TAGVAR(lt_prog_compiler_static, $1)='-non_shared'\n      ;;\n\n    rdos*)\n      _LT_TAGVAR(lt_prog_compiler_static, $1)='-non_shared'\n      ;;\n\n    solaris*)\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n      _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n      case $cc_basename in\n      f77* | f90* | f95* | sunf77* | sunf90* | sunf95*)\n\t_LT_TAGVAR(lt_prog_compiler_wl, $1)='-Qoption ld ';;\n      *)\n\t_LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,';;\n      esac\n      ;;\n\n    sunos4*)\n      _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Qoption ld '\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-PIC'\n      _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n      ;;\n\n    sysv4 | sysv4.2uw2* | sysv4.3*)\n      _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n      _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n      ;;\n\n    sysv4*MP*)\n      if test -d /usr/nec; then\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)='-Kconform_pic'\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n      fi\n      ;;\n\n    sysv5* | unixware* | sco3.2v5* | sco5v6* | OpenUNIX*)\n      _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n      _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n      ;;\n\n    unicos*)\n      _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n      _LT_TAGVAR(lt_prog_compiler_can_build_shared, $1)=no\n      ;;\n\n    uts4*)\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-pic'\n      _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n      ;;\n\n    *)\n      _LT_TAGVAR(lt_prog_compiler_can_build_shared, $1)=no\n      ;;\n    esac\n  fi\n])\ncase $host_os in\n  # For platforms that do not support PIC, -DPIC is meaningless:\n  *djgpp*)\n    _LT_TAGVAR(lt_prog_compiler_pic, $1)=\n    ;;\n  *)\n    _LT_TAGVAR(lt_prog_compiler_pic, $1)=\"$_LT_TAGVAR(lt_prog_compiler_pic, $1)@&t@m4_if([$1],[],[ -DPIC],[m4_if([$1],[CXX],[ -DPIC],[])])\"\n    ;;\nesac\n\nAC_CACHE_CHECK([for $compiler option to produce PIC],\n  [_LT_TAGVAR(lt_cv_prog_compiler_pic, $1)],\n  [_LT_TAGVAR(lt_cv_prog_compiler_pic, $1)=$_LT_TAGVAR(lt_prog_compiler_pic, $1)])\n_LT_TAGVAR(lt_prog_compiler_pic, $1)=$_LT_TAGVAR(lt_cv_prog_compiler_pic, $1)\n\n#\n# Check to make sure the PIC flag actually works.\n#\nif test -n \"$_LT_TAGVAR(lt_prog_compiler_pic, $1)\"; then\n  _LT_COMPILER_OPTION([if $compiler PIC flag $_LT_TAGVAR(lt_prog_compiler_pic, $1) works],\n    [_LT_TAGVAR(lt_cv_prog_compiler_pic_works, $1)],\n    [$_LT_TAGVAR(lt_prog_compiler_pic, $1)@&t@m4_if([$1],[],[ -DPIC],[m4_if([$1],[CXX],[ -DPIC],[])])], [],\n    [case $_LT_TAGVAR(lt_prog_compiler_pic, $1) in\n     \"\" | \" \"*) ;;\n     *) _LT_TAGVAR(lt_prog_compiler_pic, $1)=\" $_LT_TAGVAR(lt_prog_compiler_pic, $1)\" ;;\n     esac],\n    [_LT_TAGVAR(lt_prog_compiler_pic, $1)=\n     _LT_TAGVAR(lt_prog_compiler_can_build_shared, $1)=no])\nfi\n_LT_TAGDECL([pic_flag], [lt_prog_compiler_pic], [1],\n\t[Additional compiler flags for building library objects])\n\n_LT_TAGDECL([wl], [lt_prog_compiler_wl], [1],\n\t[How to pass a linker flag through the compiler])\n#\n# Check to make sure the static flag actually works.\n#\nwl=$_LT_TAGVAR(lt_prog_compiler_wl, $1) eval lt_tmp_static_flag=\\\"$_LT_TAGVAR(lt_prog_compiler_static, $1)\\\"\n_LT_LINKER_OPTION([if $compiler static flag $lt_tmp_static_flag works],\n  _LT_TAGVAR(lt_cv_prog_compiler_static_works, $1),\n  $lt_tmp_static_flag,\n  [],\n  [_LT_TAGVAR(lt_prog_compiler_static, $1)=])\n_LT_TAGDECL([link_static_flag], [lt_prog_compiler_static], [1],\n\t[Compiler flag to prevent dynamic linking])\n])# _LT_COMPILER_PIC\n\n\n# _LT_LINKER_SHLIBS([TAGNAME])\n# ----------------------------\n# See if the linker supports building shared libraries.\nm4_defun([_LT_LINKER_SHLIBS],\n[AC_REQUIRE([LT_PATH_LD])dnl\nAC_REQUIRE([LT_PATH_NM])dnl\nm4_require([_LT_PATH_MANIFEST_TOOL])dnl\nm4_require([_LT_FILEUTILS_DEFAULTS])dnl\nm4_require([_LT_DECL_EGREP])dnl\nm4_require([_LT_DECL_SED])dnl\nm4_require([_LT_CMD_GLOBAL_SYMBOLS])dnl\nm4_require([_LT_TAG_COMPILER])dnl\nAC_MSG_CHECKING([whether the $compiler linker ($LD) supports shared libraries])\nm4_if([$1], [CXX], [\n  _LT_TAGVAR(export_symbols_cmds, $1)='$NM $libobjs $convenience | $global_symbol_pipe | $SED '\\''s/.* //'\\'' | sort | uniq > $export_symbols'\n  _LT_TAGVAR(exclude_expsyms, $1)=['_GLOBAL_OFFSET_TABLE_|_GLOBAL__F[ID]_.*']\n  case $host_os in\n  aix[[4-9]]*)\n    # If we're using GNU nm, then we don't want the \"-C\" option.\n    # -C means demangle to GNU nm, but means don't demangle to AIX nm.\n    # Without the \"-l\" option, or with the \"-B\" option, AIX nm treats\n    # weak defined symbols like other global defined symbols, whereas\n    # GNU nm marks them as \"W\".\n    # While the 'weak' keyword is ignored in the Export File, we need\n    # it in the Import File for the 'aix-soname' feature, so we have\n    # to replace the \"-B\" option with \"-P\" for AIX nm.\n    if $NM -V 2>&1 | $GREP 'GNU' > /dev/null; then\n      _LT_TAGVAR(export_symbols_cmds, $1)='$NM -Bpg $libobjs $convenience | awk '\\''{ if (((\\$ 2 == \"T\") || (\\$ 2 == \"D\") || (\\$ 2 == \"B\") || (\\$ 2 == \"W\")) && ([substr](\\$ 3,1,1) != \".\")) { if (\\$ 2 == \"W\") { print \\$ 3 \" weak\" } else { print \\$ 3 } } }'\\'' | sort -u > $export_symbols'\n    else\n      _LT_TAGVAR(export_symbols_cmds, $1)='`func_echo_all $NM | $SED -e '\\''s/B\\([[^B]]*\\)$/P\\1/'\\''` -PCpgl $libobjs $convenience | awk '\\''{ if (((\\$ 2 == \"T\") || (\\$ 2 == \"D\") || (\\$ 2 == \"B\") || (\\$ 2 == \"W\") || (\\$ 2 == \"V\") || (\\$ 2 == \"Z\")) && ([substr](\\$ 1,1,1) != \".\")) { if ((\\$ 2 == \"W\") || (\\$ 2 == \"V\") || (\\$ 2 == \"Z\")) { print \\$ 1 \" weak\" } else { print \\$ 1 } } }'\\'' | sort -u > $export_symbols'\n    fi\n    ;;\n  pw32*)\n    _LT_TAGVAR(export_symbols_cmds, $1)=$ltdll_cmds\n    ;;\n  cygwin* | mingw* | cegcc*)\n    case $cc_basename in\n    cl*)\n      _LT_TAGVAR(exclude_expsyms, $1)='_NULL_IMPORT_DESCRIPTOR|_IMPORT_DESCRIPTOR_.*'\n      ;;\n    *)\n      _LT_TAGVAR(export_symbols_cmds, $1)='$NM $libobjs $convenience | $global_symbol_pipe | $SED -e '\\''/^[[BCDGRS]][[ ]]/s/.*[[ ]]\\([[^ ]]*\\)/\\1 DATA/;s/^.*[[ ]]__nm__\\([[^ ]]*\\)[[ ]][[^ ]]*/\\1 DATA/;/^I[[ ]]/d;/^[[AITW]][[ ]]/s/.* //'\\'' | sort | uniq > $export_symbols'\n      _LT_TAGVAR(exclude_expsyms, $1)=['[_]+GLOBAL_OFFSET_TABLE_|[_]+GLOBAL__[FID]_.*|[_]+head_[A-Za-z0-9_]+_dll|[A-Za-z0-9_]+_dll_iname']\n      ;;\n    esac\n    ;;\n  linux* | k*bsd*-gnu | gnu*)\n    _LT_TAGVAR(link_all_deplibs, $1)=no\n    ;;\n  *)\n    _LT_TAGVAR(export_symbols_cmds, $1)='$NM $libobjs $convenience | $global_symbol_pipe | $SED '\\''s/.* //'\\'' | sort | uniq > $export_symbols'\n    ;;\n  esac\n], [\n  runpath_var=\n  _LT_TAGVAR(allow_undefined_flag, $1)=\n  _LT_TAGVAR(always_export_symbols, $1)=no\n  _LT_TAGVAR(archive_cmds, $1)=\n  _LT_TAGVAR(archive_expsym_cmds, $1)=\n  _LT_TAGVAR(compiler_needs_object, $1)=no\n  _LT_TAGVAR(enable_shared_with_static_runtimes, $1)=no\n  _LT_TAGVAR(export_dynamic_flag_spec, $1)=\n  _LT_TAGVAR(export_symbols_cmds, $1)='$NM $libobjs $convenience | $global_symbol_pipe | $SED '\\''s/.* //'\\'' | sort | uniq > $export_symbols'\n  _LT_TAGVAR(hardcode_automatic, $1)=no\n  _LT_TAGVAR(hardcode_direct, $1)=no\n  _LT_TAGVAR(hardcode_direct_absolute, $1)=no\n  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)=\n  _LT_TAGVAR(hardcode_libdir_separator, $1)=\n  _LT_TAGVAR(hardcode_minus_L, $1)=no\n  _LT_TAGVAR(hardcode_shlibpath_var, $1)=unsupported\n  _LT_TAGVAR(inherit_rpath, $1)=no\n  _LT_TAGVAR(link_all_deplibs, $1)=unknown\n  _LT_TAGVAR(module_cmds, $1)=\n  _LT_TAGVAR(module_expsym_cmds, $1)=\n  _LT_TAGVAR(old_archive_from_new_cmds, $1)=\n  _LT_TAGVAR(old_archive_from_expsyms_cmds, $1)=\n  _LT_TAGVAR(thread_safe_flag_spec, $1)=\n  _LT_TAGVAR(whole_archive_flag_spec, $1)=\n  # include_expsyms should be a list of space-separated symbols to be *always*\n  # included in the symbol list\n  _LT_TAGVAR(include_expsyms, $1)=\n  # exclude_expsyms can be an extended regexp of symbols to exclude\n  # it will be wrapped by ' (' and ')$', so one must not match beginning or\n  # end of line.  Example: 'a|bc|.*d.*' will exclude the symbols 'a' and 'bc',\n  # as well as any symbol that contains 'd'.\n  _LT_TAGVAR(exclude_expsyms, $1)=['_GLOBAL_OFFSET_TABLE_|_GLOBAL__F[ID]_.*']\n  # Although _GLOBAL_OFFSET_TABLE_ is a valid symbol C name, most a.out\n  # platforms (ab)use it in PIC code, but their linkers get confused if\n  # the symbol is explicitly referenced.  Since portable code cannot\n  # rely on this symbol name, it's probably fine to never include it in\n  # preloaded symbol tables.\n  # Exclude shared library initialization/finalization symbols.\ndnl Note also adjust exclude_expsyms for C++ above.\n  extract_expsyms_cmds=\n\n  case $host_os in\n  cygwin* | mingw* | pw32* | cegcc*)\n    # FIXME: the MSVC++ port hasn't been tested in a loooong time\n    # When not using gcc, we currently assume that we are using\n    # Microsoft Visual C++.\n    if test yes != \"$GCC\"; then\n      with_gnu_ld=no\n    fi\n    ;;\n  interix*)\n    # we just hope/assume this is gcc and not c89 (= MSVC++)\n    with_gnu_ld=yes\n    ;;\n  openbsd* | bitrig*)\n    with_gnu_ld=no\n    ;;\n  linux* | k*bsd*-gnu | gnu*)\n    _LT_TAGVAR(link_all_deplibs, $1)=no\n    ;;\n  esac\n\n  _LT_TAGVAR(ld_shlibs, $1)=yes\n\n  # On some targets, GNU ld is compatible enough with the native linker\n  # that we're better off using the native interface for both.\n  lt_use_gnu_ld_interface=no\n  if test yes = \"$with_gnu_ld\"; then\n    case $host_os in\n      aix*)\n\t# The AIX port of GNU ld has always aspired to compatibility\n\t# with the native linker.  However, as the warning in the GNU ld\n\t# block says, versions before 2.19.5* couldn't really create working\n\t# shared libraries, regardless of the interface used.\n\tcase `$LD -v 2>&1` in\n\t  *\\ \\(GNU\\ Binutils\\)\\ 2.19.5*) ;;\n\t  *\\ \\(GNU\\ Binutils\\)\\ 2.[[2-9]]*) ;;\n\t  *\\ \\(GNU\\ Binutils\\)\\ [[3-9]]*) ;;\n\t  *)\n\t    lt_use_gnu_ld_interface=yes\n\t    ;;\n\tesac\n\t;;\n      *)\n\tlt_use_gnu_ld_interface=yes\n\t;;\n    esac\n  fi\n\n  if test yes = \"$lt_use_gnu_ld_interface\"; then\n    # If archive_cmds runs LD, not CC, wlarc should be empty\n    wlarc='$wl'\n\n    # Set some defaults for GNU ld with shared library support. These\n    # are reset later if shared libraries are not supported. Putting them\n    # here allows them to be overridden if necessary.\n    runpath_var=LD_RUN_PATH\n    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n    _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl--export-dynamic'\n    # ancient GNU ld didn't support --whole-archive et. al.\n    if $LD --help 2>&1 | $GREP 'no-whole-archive' > /dev/null; then\n      _LT_TAGVAR(whole_archive_flag_spec, $1)=$wlarc'--whole-archive$convenience '$wlarc'--no-whole-archive'\n    else\n      _LT_TAGVAR(whole_archive_flag_spec, $1)=\n    fi\n    supports_anon_versioning=no\n    case `$LD -v | $SED -e 's/([^)]\\+)\\s\\+//' 2>&1` in\n      *GNU\\ gold*) supports_anon_versioning=yes ;;\n      *\\ [[01]].* | *\\ 2.[[0-9]].* | *\\ 2.10.*) ;; # catch versions < 2.11\n      *\\ 2.11.93.0.2\\ *) supports_anon_versioning=yes ;; # RH7.3 ...\n      *\\ 2.11.92.0.12\\ *) supports_anon_versioning=yes ;; # Mandrake 8.2 ...\n      *\\ 2.11.*) ;; # other 2.11 versions\n      *) supports_anon_versioning=yes ;;\n    esac\n\n    # See if GNU ld supports shared libraries.\n    case $host_os in\n    aix[[3-9]]*)\n      # On AIX/PPC, the GNU linker is very broken\n      if test ia64 != \"$host_cpu\"; then\n\t_LT_TAGVAR(ld_shlibs, $1)=no\n\tcat <<_LT_EOF 1>&2\n\n*** Warning: the GNU linker, at least up to release 2.19, is reported\n*** to be unable to reliably create shared libraries on AIX.\n*** Therefore, libtool is disabling shared libraries support.  If you\n*** really care for shared libraries, you may want to install binutils\n*** 2.20 or above, or modify your PATH so that a non-GNU linker is found.\n*** You will then need to restart the configuration process.\n\n_LT_EOF\n      fi\n      ;;\n\n    amigaos*)\n      case $host_cpu in\n      powerpc)\n            # see comment about AmigaOS4 .so support\n            _LT_TAGVAR(archive_cmds, $1)='$CC -shared $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n            _LT_TAGVAR(archive_expsym_cmds, $1)=''\n        ;;\n      m68k)\n            _LT_TAGVAR(archive_cmds, $1)='$RM $output_objdir/a2ixlibrary.data~$ECHO \"#define NAME $libname\" > $output_objdir/a2ixlibrary.data~$ECHO \"#define LIBRARY_ID 1\" >> $output_objdir/a2ixlibrary.data~$ECHO \"#define VERSION $major\" >> $output_objdir/a2ixlibrary.data~$ECHO \"#define REVISION $revision\" >> $output_objdir/a2ixlibrary.data~$AR $AR_FLAGS $lib $libobjs~$RANLIB $lib~(cd $output_objdir && a2ixlibrary -32)'\n            _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n            _LT_TAGVAR(hardcode_minus_L, $1)=yes\n        ;;\n      esac\n      ;;\n\n    beos*)\n      if $LD --help 2>&1 | $GREP ': supported targets:.* elf' > /dev/null; then\n\t_LT_TAGVAR(allow_undefined_flag, $1)=unsupported\n\t# Joseph Beckenbach <jrb3@best.com> says some releases of gcc\n\t# support --undefined.  This deserves some investigation.  FIXME\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -nostart $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n      else\n\t_LT_TAGVAR(ld_shlibs, $1)=no\n      fi\n      ;;\n\n    cygwin* | mingw* | pw32* | cegcc*)\n      # _LT_TAGVAR(hardcode_libdir_flag_spec, $1) is actually meaningless,\n      # as there is no search path for DLLs.\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n      _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl--export-all-symbols'\n      _LT_TAGVAR(allow_undefined_flag, $1)=unsupported\n      _LT_TAGVAR(always_export_symbols, $1)=no\n      _LT_TAGVAR(enable_shared_with_static_runtimes, $1)=yes\n      _LT_TAGVAR(export_symbols_cmds, $1)='$NM $libobjs $convenience | $global_symbol_pipe | $SED -e '\\''/^[[BCDGRS]][[ ]]/s/.*[[ ]]\\([[^ ]]*\\)/\\1 DATA/;s/^.*[[ ]]__nm__\\([[^ ]]*\\)[[ ]][[^ ]]*/\\1 DATA/;/^I[[ ]]/d;/^[[AITW]][[ ]]/s/.* //'\\'' | sort | uniq > $export_symbols'\n      _LT_TAGVAR(exclude_expsyms, $1)=['[_]+GLOBAL_OFFSET_TABLE_|[_]+GLOBAL__[FID]_.*|[_]+head_[A-Za-z0-9_]+_dll|[A-Za-z0-9_]+_dll_iname']\n\n      if $LD --help 2>&1 | $GREP 'auto-import' > /dev/null; then\n        _LT_TAGVAR(archive_cmds, $1)='$CC -shared $libobjs $deplibs $compiler_flags -o $output_objdir/$soname $wl--enable-auto-image-base -Xlinker --out-implib -Xlinker $lib'\n\t# If the export-symbols file already is a .def file, use it as\n\t# is; otherwise, prepend EXPORTS...\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='if _LT_DLL_DEF_P([$export_symbols]); then\n          cp $export_symbols $output_objdir/$soname.def;\n        else\n          echo EXPORTS > $output_objdir/$soname.def;\n          cat $export_symbols >> $output_objdir/$soname.def;\n        fi~\n        $CC -shared $output_objdir/$soname.def $libobjs $deplibs $compiler_flags -o $output_objdir/$soname $wl--enable-auto-image-base -Xlinker --out-implib -Xlinker $lib'\n      else\n\t_LT_TAGVAR(ld_shlibs, $1)=no\n      fi\n      ;;\n\n    haiku*)\n      _LT_TAGVAR(archive_cmds, $1)='$CC -shared $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n      _LT_TAGVAR(link_all_deplibs, $1)=yes\n      ;;\n\n    os2*)\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n      _LT_TAGVAR(hardcode_minus_L, $1)=yes\n      _LT_TAGVAR(allow_undefined_flag, $1)=unsupported\n      shrext_cmds=.dll\n      _LT_TAGVAR(archive_cmds, $1)='$ECHO \"LIBRARY ${soname%$shared_ext} INITINSTANCE TERMINSTANCE\" > $output_objdir/$libname.def~\n\t$ECHO \"DESCRIPTION \\\"$libname\\\"\" >> $output_objdir/$libname.def~\n\t$ECHO \"DATA MULTIPLE NONSHARED\" >> $output_objdir/$libname.def~\n\t$ECHO EXPORTS >> $output_objdir/$libname.def~\n\temxexp $libobjs | $SED /\"_DLL_InitTerm\"/d >> $output_objdir/$libname.def~\n\t$CC -Zdll -Zcrtdll -o $output_objdir/$soname $libobjs $deplibs $compiler_flags $output_objdir/$libname.def~\n\temximp -o $lib $output_objdir/$libname.def'\n      _LT_TAGVAR(archive_expsym_cmds, $1)='$ECHO \"LIBRARY ${soname%$shared_ext} INITINSTANCE TERMINSTANCE\" > $output_objdir/$libname.def~\n\t$ECHO \"DESCRIPTION \\\"$libname\\\"\" >> $output_objdir/$libname.def~\n\t$ECHO \"DATA MULTIPLE NONSHARED\" >> $output_objdir/$libname.def~\n\t$ECHO EXPORTS >> $output_objdir/$libname.def~\n\tprefix_cmds=\"$SED\"~\n\tif test EXPORTS = \"`$SED 1q $export_symbols`\"; then\n\t  prefix_cmds=\"$prefix_cmds -e 1d\";\n\tfi~\n\tprefix_cmds=\"$prefix_cmds -e \\\"s/^\\(.*\\)$/_\\1/g\\\"\"~\n\tcat $export_symbols | $prefix_cmds >> $output_objdir/$libname.def~\n\t$CC -Zdll -Zcrtdll -o $output_objdir/$soname $libobjs $deplibs $compiler_flags $output_objdir/$libname.def~\n\temximp -o $lib $output_objdir/$libname.def'\n      _LT_TAGVAR(old_archive_From_new_cmds, $1)='emximp -o $output_objdir/${libname}_dll.a $output_objdir/$libname.def'\n      _LT_TAGVAR(enable_shared_with_static_runtimes, $1)=yes\n      ;;\n\n    interix[[3-9]]*)\n      _LT_TAGVAR(hardcode_direct, $1)=no\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath,$libdir'\n      _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-E'\n      # Hack: On Interix 3.x, we cannot compile PIC because of a broken gcc.\n      # Instead, shared libraries are loaded at an image base (0x10000000 by\n      # default) and relocated if they conflict, which is a slow very memory\n      # consuming and fragmenting process.  To avoid this, we pick a random,\n      # 256 KiB-aligned image base between 0x50000000 and 0x6FFC0000 at link\n      # time.  Moving up from 0x10000000 also allows more sbrk(2) space.\n      _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-h,$soname $wl--image-base,`expr ${RANDOM-$$} % 4096 / 2 \\* 262144 + 1342177280` -o $lib'\n      _LT_TAGVAR(archive_expsym_cmds, $1)='sed \"s|^|_|\" $export_symbols >$output_objdir/$soname.expsym~$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-h,$soname $wl--retain-symbols-file,$output_objdir/$soname.expsym $wl--image-base,`expr ${RANDOM-$$} % 4096 / 2 \\* 262144 + 1342177280` -o $lib'\n      ;;\n\n    gnu* | linux* | tpf* | k*bsd*-gnu | kopensolaris*-gnu)\n      tmp_diet=no\n      if test linux-dietlibc = \"$host_os\"; then\n\tcase $cc_basename in\n\t  diet\\ *) tmp_diet=yes;;\t# linux-dietlibc with static linking (!diet-dyn)\n\tesac\n      fi\n      if $LD --help 2>&1 | $EGREP ': supported targets:.* elf' > /dev/null \\\n\t && test no = \"$tmp_diet\"\n      then\n\ttmp_addflag=' $pic_flag'\n\ttmp_sharedflag='-shared'\n\tcase $cc_basename,$host_cpu in\n        pgcc*)\t\t\t\t# Portland Group C compiler\n\t  _LT_TAGVAR(whole_archive_flag_spec, $1)='$wl--whole-archive`for conv in $convenience\\\"\\\"; do test  -n \\\"$conv\\\" && new_convenience=\\\"$new_convenience,$conv\\\"; done; func_echo_all \\\"$new_convenience\\\"` $wl--no-whole-archive'\n\t  tmp_addflag=' $pic_flag'\n\t  ;;\n\tpgf77* | pgf90* | pgf95* | pgfortran*)\n\t\t\t\t\t# Portland Group f77 and f90 compilers\n\t  _LT_TAGVAR(whole_archive_flag_spec, $1)='$wl--whole-archive`for conv in $convenience\\\"\\\"; do test  -n \\\"$conv\\\" && new_convenience=\\\"$new_convenience,$conv\\\"; done; func_echo_all \\\"$new_convenience\\\"` $wl--no-whole-archive'\n\t  tmp_addflag=' $pic_flag -Mnomain' ;;\n\tecc*,ia64* | icc*,ia64*)\t# Intel C compiler on ia64\n\t  tmp_addflag=' -i_dynamic' ;;\n\tefc*,ia64* | ifort*,ia64*)\t# Intel Fortran compiler on ia64\n\t  tmp_addflag=' -i_dynamic -nofor_main' ;;\n\tifc* | ifort*)\t\t\t# Intel Fortran compiler\n\t  tmp_addflag=' -nofor_main' ;;\n\tlf95*)\t\t\t\t# Lahey Fortran 8.1\n\t  _LT_TAGVAR(whole_archive_flag_spec, $1)=\n\t  tmp_sharedflag='--shared' ;;\n        nagfor*)                        # NAGFOR 5.3\n          tmp_sharedflag='-Wl,-shared' ;;\n\txl[[cC]]* | bgxl[[cC]]* | mpixl[[cC]]*) # IBM XL C 8.0 on PPC (deal with xlf below)\n\t  tmp_sharedflag='-qmkshrobj'\n\t  tmp_addflag= ;;\n\tnvcc*)\t# Cuda Compiler Driver 2.2\n\t  _LT_TAGVAR(whole_archive_flag_spec, $1)='$wl--whole-archive`for conv in $convenience\\\"\\\"; do test  -n \\\"$conv\\\" && new_convenience=\\\"$new_convenience,$conv\\\"; done; func_echo_all \\\"$new_convenience\\\"` $wl--no-whole-archive'\n\t  _LT_TAGVAR(compiler_needs_object, $1)=yes\n\t  ;;\n\tesac\n\tcase `$CC -V 2>&1 | sed 5q` in\n\t*Sun\\ C*)\t\t\t# Sun C 5.9\n\t  _LT_TAGVAR(whole_archive_flag_spec, $1)='$wl--whole-archive`new_convenience=; for conv in $convenience\\\"\\\"; do test -z \\\"$conv\\\" || new_convenience=\\\"$new_convenience,$conv\\\"; done; func_echo_all \\\"$new_convenience\\\"` $wl--no-whole-archive'\n\t  _LT_TAGVAR(compiler_needs_object, $1)=yes\n\t  tmp_sharedflag='-G' ;;\n\t*Sun\\ F*)\t\t\t# Sun Fortran 8.3\n\t  tmp_sharedflag='-G' ;;\n\tesac\n\t_LT_TAGVAR(archive_cmds, $1)='$CC '\"$tmp_sharedflag\"\"$tmp_addflag\"' $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n\n        if test yes = \"$supports_anon_versioning\"; then\n          _LT_TAGVAR(archive_expsym_cmds, $1)='echo \"{ global:\" > $output_objdir/$libname.ver~\n            cat $export_symbols | sed -e \"s/\\(.*\\)/\\1;/\" >> $output_objdir/$libname.ver~\n            echo \"local: *; };\" >> $output_objdir/$libname.ver~\n            $CC '\"$tmp_sharedflag\"\"$tmp_addflag\"' $libobjs $deplibs $compiler_flags $wl-soname $wl$soname $wl-version-script $wl$output_objdir/$libname.ver -o $lib'\n        fi\n\n\tcase $cc_basename in\n\ttcc*)\n\t  _LT_TAGVAR(export_dynamic_flag_spec, $1)='-rdynamic'\n\t  ;;\n\txlf* | bgf* | bgxlf* | mpixlf*)\n\t  # IBM XL Fortran 10.1 on PPC cannot create shared libs itself\n\t  _LT_TAGVAR(whole_archive_flag_spec, $1)='--whole-archive$convenience --no-whole-archive'\n\t  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n\t  _LT_TAGVAR(archive_cmds, $1)='$LD -shared $libobjs $deplibs $linker_flags -soname $soname -o $lib'\n\t  if test yes = \"$supports_anon_versioning\"; then\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)='echo \"{ global:\" > $output_objdir/$libname.ver~\n              cat $export_symbols | sed -e \"s/\\(.*\\)/\\1;/\" >> $output_objdir/$libname.ver~\n              echo \"local: *; };\" >> $output_objdir/$libname.ver~\n              $LD -shared $libobjs $deplibs $linker_flags -soname $soname -version-script $output_objdir/$libname.ver -o $lib'\n\t  fi\n\t  ;;\n\tesac\n      else\n        _LT_TAGVAR(ld_shlibs, $1)=no\n      fi\n      ;;\n\n    netbsd* | netbsdelf*-gnu)\n      if echo __ELF__ | $CC -E - | $GREP __ELF__ >/dev/null; then\n\t_LT_TAGVAR(archive_cmds, $1)='$LD -Bshareable $libobjs $deplibs $linker_flags -o $lib'\n\twlarc=\n      else\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-soname $wl$soname $wl-retain-symbols-file $wl$export_symbols -o $lib'\n      fi\n      ;;\n\n    solaris*)\n      if $LD -v 2>&1 | $GREP 'BFD 2\\.8' > /dev/null; then\n\t_LT_TAGVAR(ld_shlibs, $1)=no\n\tcat <<_LT_EOF 1>&2\n\n*** Warning: The releases 2.8.* of the GNU linker cannot reliably\n*** create shared libraries on Solaris systems.  Therefore, libtool\n*** is disabling shared libraries support.  We urge you to upgrade GNU\n*** binutils to release 2.9.1 or newer.  Another option is to modify\n*** your PATH or compiler configuration so that the native linker is\n*** used, and then restart.\n\n_LT_EOF\n      elif $LD --help 2>&1 | $GREP ': supported targets:.* elf' > /dev/null; then\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-soname $wl$soname $wl-retain-symbols-file $wl$export_symbols -o $lib'\n      else\n\t_LT_TAGVAR(ld_shlibs, $1)=no\n      fi\n      ;;\n\n    sysv5* | sco3.2v5* | sco5v6* | unixware* | OpenUNIX*)\n      case `$LD -v 2>&1` in\n        *\\ [[01]].* | *\\ 2.[[0-9]].* | *\\ 2.1[[0-5]].*)\n\t_LT_TAGVAR(ld_shlibs, $1)=no\n\tcat <<_LT_EOF 1>&2\n\n*** Warning: Releases of the GNU linker prior to 2.16.91.0.3 cannot\n*** reliably create shared libraries on SCO systems.  Therefore, libtool\n*** is disabling shared libraries support.  We urge you to upgrade GNU\n*** binutils to release 2.16.91.0.3 or newer.  Another option is to modify\n*** your PATH or compiler configuration so that the native linker is\n*** used, and then restart.\n\n_LT_EOF\n\t;;\n\t*)\n\t  # For security reasons, it is highly recommended that you always\n\t  # use absolute paths for naming shared libraries, and exclude the\n\t  # DT_RUNPATH tag from executables and libraries.  But doing so\n\t  # requires that you compile everything twice, which is a pain.\n\t  if $LD --help 2>&1 | $GREP ': supported targets:.* elf' > /dev/null; then\n\t    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n\t    _LT_TAGVAR(archive_cmds, $1)='$CC -shared $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $libobjs $deplibs $compiler_flags $wl-soname $wl$soname $wl-retain-symbols-file $wl$export_symbols -o $lib'\n\t  else\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t  fi\n\t;;\n      esac\n      ;;\n\n    sunos4*)\n      _LT_TAGVAR(archive_cmds, $1)='$LD -assert pure-text -Bshareable -o $lib $libobjs $deplibs $linker_flags'\n      wlarc=\n      _LT_TAGVAR(hardcode_direct, $1)=yes\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      ;;\n\n    *)\n      if $LD --help 2>&1 | $GREP ': supported targets:.* elf' > /dev/null; then\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-soname $wl$soname $wl-retain-symbols-file $wl$export_symbols -o $lib'\n      else\n\t_LT_TAGVAR(ld_shlibs, $1)=no\n      fi\n      ;;\n    esac\n\n    if test no = \"$_LT_TAGVAR(ld_shlibs, $1)\"; then\n      runpath_var=\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)=\n      _LT_TAGVAR(export_dynamic_flag_spec, $1)=\n      _LT_TAGVAR(whole_archive_flag_spec, $1)=\n    fi\n  else\n    # PORTME fill in a description of your system's linker (not GNU ld)\n    case $host_os in\n    aix3*)\n      _LT_TAGVAR(allow_undefined_flag, $1)=unsupported\n      _LT_TAGVAR(always_export_symbols, $1)=yes\n      _LT_TAGVAR(archive_expsym_cmds, $1)='$LD -o $output_objdir/$soname $libobjs $deplibs $linker_flags -bE:$export_symbols -T512 -H512 -bM:SRE~$AR $AR_FLAGS $lib $output_objdir/$soname'\n      # Note: this linker hardcodes the directories in LIBPATH if there\n      # are no directories specified by -L.\n      _LT_TAGVAR(hardcode_minus_L, $1)=yes\n      if test yes = \"$GCC\" && test -z \"$lt_prog_compiler_static\"; then\n\t# Neither direct hardcoding nor static linking is supported with a\n\t# broken collect2.\n\t_LT_TAGVAR(hardcode_direct, $1)=unsupported\n      fi\n      ;;\n\n    aix[[4-9]]*)\n      if test ia64 = \"$host_cpu\"; then\n\t# On IA64, the linker does run time linking by default, so we don't\n\t# have to do anything special.\n\taix_use_runtimelinking=no\n\texp_sym_flag='-Bexport'\n\tno_entry_flag=\n      else\n\t# If we're using GNU nm, then we don't want the \"-C\" option.\n\t# -C means demangle to GNU nm, but means don't demangle to AIX nm.\n\t# Without the \"-l\" option, or with the \"-B\" option, AIX nm treats\n\t# weak defined symbols like other global defined symbols, whereas\n\t# GNU nm marks them as \"W\".\n\t# While the 'weak' keyword is ignored in the Export File, we need\n\t# it in the Import File for the 'aix-soname' feature, so we have\n\t# to replace the \"-B\" option with \"-P\" for AIX nm.\n\tif $NM -V 2>&1 | $GREP 'GNU' > /dev/null; then\n\t  _LT_TAGVAR(export_symbols_cmds, $1)='$NM -Bpg $libobjs $convenience | awk '\\''{ if (((\\$ 2 == \"T\") || (\\$ 2 == \"D\") || (\\$ 2 == \"B\") || (\\$ 2 == \"W\")) && ([substr](\\$ 3,1,1) != \".\")) { if (\\$ 2 == \"W\") { print \\$ 3 \" weak\" } else { print \\$ 3 } } }'\\'' | sort -u > $export_symbols'\n\telse\n\t  _LT_TAGVAR(export_symbols_cmds, $1)='`func_echo_all $NM | $SED -e '\\''s/B\\([[^B]]*\\)$/P\\1/'\\''` -PCpgl $libobjs $convenience | awk '\\''{ if (((\\$ 2 == \"T\") || (\\$ 2 == \"D\") || (\\$ 2 == \"B\") || (\\$ 2 == \"W\") || (\\$ 2 == \"V\") || (\\$ 2 == \"Z\")) && ([substr](\\$ 1,1,1) != \".\")) { if ((\\$ 2 == \"W\") || (\\$ 2 == \"V\") || (\\$ 2 == \"Z\")) { print \\$ 1 \" weak\" } else { print \\$ 1 } } }'\\'' | sort -u > $export_symbols'\n\tfi\n\taix_use_runtimelinking=no\n\n\t# Test if we are trying to use run time linking or normal\n\t# AIX style linking. If -brtl is somewhere in LDFLAGS, we\n\t# have runtime linking enabled, and use it for executables.\n\t# For shared libraries, we enable/disable runtime linking\n\t# depending on the kind of the shared library created -\n\t# when \"with_aix_soname,aix_use_runtimelinking\" is:\n\t# \"aix,no\"   lib.a(lib.so.V) shared, rtl:no,  for executables\n\t# \"aix,yes\"  lib.so          shared, rtl:yes, for executables\n\t#            lib.a           static archive\n\t# \"both,no\"  lib.so.V(shr.o) shared, rtl:yes\n\t#            lib.a(lib.so.V) shared, rtl:no,  for executables\n\t# \"both,yes\" lib.so.V(shr.o) shared, rtl:yes, for executables\n\t#            lib.a(lib.so.V) shared, rtl:no\n\t# \"svr4,*\"   lib.so.V(shr.o) shared, rtl:yes, for executables\n\t#            lib.a           static archive\n\tcase $host_os in aix4.[[23]]|aix4.[[23]].*|aix[[5-9]]*)\n\t  for ld_flag in $LDFLAGS; do\n\t  if (test x-brtl = \"x$ld_flag\" || test x-Wl,-brtl = \"x$ld_flag\"); then\n\t    aix_use_runtimelinking=yes\n\t    break\n\t  fi\n\t  done\n\t  if test svr4,no = \"$with_aix_soname,$aix_use_runtimelinking\"; then\n\t    # With aix-soname=svr4, we create the lib.so.V shared archives only,\n\t    # so we don't have lib.a shared libs to link our executables.\n\t    # We have to force runtime linking in this case.\n\t    aix_use_runtimelinking=yes\n\t    LDFLAGS=\"$LDFLAGS -Wl,-brtl\"\n\t  fi\n\t  ;;\n\tesac\n\n\texp_sym_flag='-bexport'\n\tno_entry_flag='-bnoentry'\n      fi\n\n      # When large executables or shared objects are built, AIX ld can\n      # have problems creating the table of contents.  If linking a library\n      # or program results in \"error TOC overflow\" add -mminimal-toc to\n      # CXXFLAGS/CFLAGS for g++/gcc.  In the cases where that is not\n      # enough to fix the problem, add -Wl,-bbigtoc to LDFLAGS.\n\n      _LT_TAGVAR(archive_cmds, $1)=''\n      _LT_TAGVAR(hardcode_direct, $1)=yes\n      _LT_TAGVAR(hardcode_direct_absolute, $1)=yes\n      _LT_TAGVAR(hardcode_libdir_separator, $1)=':'\n      _LT_TAGVAR(link_all_deplibs, $1)=yes\n      _LT_TAGVAR(file_list_spec, $1)='$wl-f,'\n      case $with_aix_soname,$aix_use_runtimelinking in\n      aix,*) ;; # traditional, no import file\n      svr4,* | *,yes) # use import file\n\t# The Import File defines what to hardcode.\n\t_LT_TAGVAR(hardcode_direct, $1)=no\n\t_LT_TAGVAR(hardcode_direct_absolute, $1)=no\n\t;;\n      esac\n\n      if test yes = \"$GCC\"; then\n\tcase $host_os in aix4.[[012]]|aix4.[[012]].*)\n\t# We only want to do this on AIX 4.2 and lower, the check\n\t# below for broken collect2 doesn't work under 4.3+\n\t  collect2name=`$CC -print-prog-name=collect2`\n\t  if test -f \"$collect2name\" &&\n\t   strings \"$collect2name\" | $GREP resolve_lib_name >/dev/null\n\t  then\n\t  # We have reworked collect2\n\t  :\n\t  else\n\t  # We have old collect2\n\t  _LT_TAGVAR(hardcode_direct, $1)=unsupported\n\t  # It fails to find uninstalled libraries when the uninstalled\n\t  # path is not listed in the libpath.  Setting hardcode_minus_L\n\t  # to unsupported forces relinking\n\t  _LT_TAGVAR(hardcode_minus_L, $1)=yes\n\t  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n\t  _LT_TAGVAR(hardcode_libdir_separator, $1)=\n\t  fi\n\t  ;;\n\tesac\n\tshared_flag='-shared'\n\tif test yes = \"$aix_use_runtimelinking\"; then\n\t  shared_flag=\"$shared_flag \"'$wl-G'\n\tfi\n\t# Need to ensure runtime linking is disabled for the traditional\n\t# shared library, or the linker may eventually find shared libraries\n\t# /with/ Import File - we do not want to mix them.\n\tshared_flag_aix='-shared'\n\tshared_flag_svr4='-shared $wl-G'\n      else\n\t# not using gcc\n\tif test ia64 = \"$host_cpu\"; then\n\t# VisualAge C++, Version 5.5 for AIX 5L for IA-64, Beta 3 Release\n\t# chokes on -Wl,-G. The following line is correct:\n\t  shared_flag='-G'\n\telse\n\t  if test yes = \"$aix_use_runtimelinking\"; then\n\t    shared_flag='$wl-G'\n\t  else\n\t    shared_flag='$wl-bM:SRE'\n\t  fi\n\t  shared_flag_aix='$wl-bM:SRE'\n\t  shared_flag_svr4='$wl-G'\n\tfi\n      fi\n\n      _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-bexpall'\n      # It seems that -bexpall does not export symbols beginning with\n      # underscore (_), so it is better to generate a list of symbols to export.\n      _LT_TAGVAR(always_export_symbols, $1)=yes\n      if test aix,yes = \"$with_aix_soname,$aix_use_runtimelinking\"; then\n\t# Warning - without using the other runtime loading flags (-brtl),\n\t# -berok will link without error, but may produce a broken library.\n\t_LT_TAGVAR(allow_undefined_flag, $1)='-berok'\n        # Determine the default libpath from the value encoded in an\n        # empty executable.\n        _LT_SYS_MODULE_PATH_AIX([$1])\n        _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-blibpath:$libdir:'\"$aix_libpath\"\n        _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -o $output_objdir/$soname $libobjs $deplibs $wl'$no_entry_flag' $compiler_flags `if test -n \"$allow_undefined_flag\"; then func_echo_all \"$wl$allow_undefined_flag\"; else :; fi` $wl'$exp_sym_flag:\\$export_symbols' '$shared_flag\n      else\n\tif test ia64 = \"$host_cpu\"; then\n\t  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-R $libdir:/usr/lib:/lib'\n\t  _LT_TAGVAR(allow_undefined_flag, $1)=\"-z nodefs\"\n\t  _LT_TAGVAR(archive_expsym_cmds, $1)=\"\\$CC $shared_flag\"' -o $output_objdir/$soname $libobjs $deplibs '\"\\$wl$no_entry_flag\"' $compiler_flags $wl$allow_undefined_flag '\"\\$wl$exp_sym_flag:\\$export_symbols\"\n\telse\n\t # Determine the default libpath from the value encoded in an\n\t # empty executable.\n\t _LT_SYS_MODULE_PATH_AIX([$1])\n\t _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-blibpath:$libdir:'\"$aix_libpath\"\n\t  # Warning - without using the other run time loading flags,\n\t  # -berok will link without error, but may produce a broken library.\n\t  _LT_TAGVAR(no_undefined_flag, $1)=' $wl-bernotok'\n\t  _LT_TAGVAR(allow_undefined_flag, $1)=' $wl-berok'\n\t  if test yes = \"$with_gnu_ld\"; then\n\t    # We only use this code for GNU lds that support --whole-archive.\n\t    _LT_TAGVAR(whole_archive_flag_spec, $1)='$wl--whole-archive$convenience $wl--no-whole-archive'\n\t  else\n\t    # Exported symbols can be pulled into shared objects from archives\n\t    _LT_TAGVAR(whole_archive_flag_spec, $1)='$convenience'\n\t  fi\n\t  _LT_TAGVAR(archive_cmds_need_lc, $1)=yes\n\t  _LT_TAGVAR(archive_expsym_cmds, $1)='$RM -r $output_objdir/$realname.d~$MKDIR $output_objdir/$realname.d'\n\t  # -brtl affects multiple linker settings, -berok does not and is overridden later\n\t  compiler_flags_filtered='`func_echo_all \"$compiler_flags \" | $SED -e \"s%-brtl\\\\([[, ]]\\\\)%-berok\\\\1%g\"`'\n\t  if test svr4 != \"$with_aix_soname\"; then\n\t    # This is similar to how AIX traditionally builds its shared libraries.\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)=\"$_LT_TAGVAR(archive_expsym_cmds, $1)\"'~$CC '$shared_flag_aix' -o $output_objdir/$realname.d/$soname $libobjs $deplibs $wl-bnoentry '$compiler_flags_filtered'$wl-bE:$export_symbols$allow_undefined_flag~$AR $AR_FLAGS $output_objdir/$libname$release.a $output_objdir/$realname.d/$soname'\n\t  fi\n\t  if test aix != \"$with_aix_soname\"; then\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)=\"$_LT_TAGVAR(archive_expsym_cmds, $1)\"'~$CC '$shared_flag_svr4' -o $output_objdir/$realname.d/$shared_archive_member_spec.o $libobjs $deplibs $wl-bnoentry '$compiler_flags_filtered'$wl-bE:$export_symbols$allow_undefined_flag~$STRIP -e $output_objdir/$realname.d/$shared_archive_member_spec.o~( func_echo_all \"#! $soname($shared_archive_member_spec.o)\"; if test shr_64 = \"$shared_archive_member_spec\"; then func_echo_all \"# 64\"; else func_echo_all \"# 32\"; fi; cat $export_symbols ) > $output_objdir/$realname.d/$shared_archive_member_spec.imp~$AR $AR_FLAGS $output_objdir/$soname $output_objdir/$realname.d/$shared_archive_member_spec.o $output_objdir/$realname.d/$shared_archive_member_spec.imp'\n\t  else\n\t    # used by -dlpreopen to get the symbols\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)=\"$_LT_TAGVAR(archive_expsym_cmds, $1)\"'~$MV  $output_objdir/$realname.d/$soname $output_objdir'\n\t  fi\n\t  _LT_TAGVAR(archive_expsym_cmds, $1)=\"$_LT_TAGVAR(archive_expsym_cmds, $1)\"'~$RM -r $output_objdir/$realname.d'\n\tfi\n      fi\n      ;;\n\n    amigaos*)\n      case $host_cpu in\n      powerpc)\n            # see comment about AmigaOS4 .so support\n            _LT_TAGVAR(archive_cmds, $1)='$CC -shared $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n            _LT_TAGVAR(archive_expsym_cmds, $1)=''\n        ;;\n      m68k)\n            _LT_TAGVAR(archive_cmds, $1)='$RM $output_objdir/a2ixlibrary.data~$ECHO \"#define NAME $libname\" > $output_objdir/a2ixlibrary.data~$ECHO \"#define LIBRARY_ID 1\" >> $output_objdir/a2ixlibrary.data~$ECHO \"#define VERSION $major\" >> $output_objdir/a2ixlibrary.data~$ECHO \"#define REVISION $revision\" >> $output_objdir/a2ixlibrary.data~$AR $AR_FLAGS $lib $libobjs~$RANLIB $lib~(cd $output_objdir && a2ixlibrary -32)'\n            _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n            _LT_TAGVAR(hardcode_minus_L, $1)=yes\n        ;;\n      esac\n      ;;\n\n    bsdi[[45]]*)\n      _LT_TAGVAR(export_dynamic_flag_spec, $1)=-rdynamic\n      ;;\n\n    cygwin* | mingw* | pw32* | cegcc*)\n      # When not using gcc, we currently assume that we are using\n      # Microsoft Visual C++.\n      # hardcode_libdir_flag_spec is actually meaningless, as there is\n      # no search path for DLLs.\n      case $cc_basename in\n      cl*)\n\t# Native MSVC\n\t_LT_TAGVAR(hardcode_libdir_flag_spec, $1)=' '\n\t_LT_TAGVAR(allow_undefined_flag, $1)=unsupported\n\t_LT_TAGVAR(always_export_symbols, $1)=yes\n\t_LT_TAGVAR(file_list_spec, $1)='@'\n\t# Tell ltmain to make .lib files, not .a files.\n\tlibext=lib\n\t# Tell ltmain to make .dll files, not .so files.\n\tshrext_cmds=.dll\n\t# FIXME: Setting linknames here is a bad hack.\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -o $output_objdir/$soname $libobjs $compiler_flags $deplibs -Wl,-DLL,-IMPLIB:\"$tool_output_objdir$libname.dll.lib\"~linknames='\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='if _LT_DLL_DEF_P([$export_symbols]); then\n            cp \"$export_symbols\" \"$output_objdir/$soname.def\";\n            echo \"$tool_output_objdir$soname.def\" > \"$output_objdir/$soname.exp\";\n          else\n            $SED -e '\\''s/^/-link -EXPORT:/'\\'' < $export_symbols > $output_objdir/$soname.exp;\n          fi~\n          $CC -o $tool_output_objdir$soname $libobjs $compiler_flags $deplibs \"@$tool_output_objdir$soname.exp\" -Wl,-DLL,-IMPLIB:\"$tool_output_objdir$libname.dll.lib\"~\n          linknames='\n\t# The linker will not automatically build a static lib if we build a DLL.\n\t# _LT_TAGVAR(old_archive_from_new_cmds, $1)='true'\n\t_LT_TAGVAR(enable_shared_with_static_runtimes, $1)=yes\n\t_LT_TAGVAR(exclude_expsyms, $1)='_NULL_IMPORT_DESCRIPTOR|_IMPORT_DESCRIPTOR_.*'\n\t_LT_TAGVAR(export_symbols_cmds, $1)='$NM $libobjs $convenience | $global_symbol_pipe | $SED -e '\\''/^[[BCDGRS]][[ ]]/s/.*[[ ]]\\([[^ ]]*\\)/\\1,DATA/'\\'' | $SED -e '\\''/^[[AITW]][[ ]]/s/.*[[ ]]//'\\'' | sort | uniq > $export_symbols'\n\t# Don't use ranlib\n\t_LT_TAGVAR(old_postinstall_cmds, $1)='chmod 644 $oldlib'\n\t_LT_TAGVAR(postlink_cmds, $1)='lt_outputfile=\"@OUTPUT@\"~\n          lt_tool_outputfile=\"@TOOL_OUTPUT@\"~\n          case $lt_outputfile in\n            *.exe|*.EXE) ;;\n            *)\n              lt_outputfile=$lt_outputfile.exe\n              lt_tool_outputfile=$lt_tool_outputfile.exe\n              ;;\n          esac~\n          if test : != \"$MANIFEST_TOOL\" && test -f \"$lt_outputfile.manifest\"; then\n            $MANIFEST_TOOL -manifest \"$lt_tool_outputfile.manifest\" -outputresource:\"$lt_tool_outputfile\" || exit 1;\n            $RM \"$lt_outputfile.manifest\";\n          fi'\n\t;;\n      *)\n\t# Assume MSVC wrapper\n\t_LT_TAGVAR(hardcode_libdir_flag_spec, $1)=' '\n\t_LT_TAGVAR(allow_undefined_flag, $1)=unsupported\n\t# Tell ltmain to make .lib files, not .a files.\n\tlibext=lib\n\t# Tell ltmain to make .dll files, not .so files.\n\tshrext_cmds=.dll\n\t# FIXME: Setting linknames here is a bad hack.\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -o $lib $libobjs $compiler_flags `func_echo_all \"$deplibs\" | $SED '\\''s/ -lc$//'\\''` -link -dll~linknames='\n\t# The linker will automatically build a .lib file if we build a DLL.\n\t_LT_TAGVAR(old_archive_from_new_cmds, $1)='true'\n\t# FIXME: Should let the user specify the lib program.\n\t_LT_TAGVAR(old_archive_cmds, $1)='lib -OUT:$oldlib$oldobjs$old_deplibs'\n\t_LT_TAGVAR(enable_shared_with_static_runtimes, $1)=yes\n\t;;\n      esac\n      ;;\n\n    darwin* | rhapsody*)\n      _LT_DARWIN_LINKER_FEATURES($1)\n      ;;\n\n    dgux*)\n      _LT_TAGVAR(archive_cmds, $1)='$LD -G -h $soname -o $lib $libobjs $deplibs $linker_flags'\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      ;;\n\n    # FreeBSD 2.2.[012] allows us to include c++rt0.o to get C++ constructor\n    # support.  Future versions do this automatically, but an explicit c++rt0.o\n    # does not break anything, and helps significantly (at the cost of a little\n    # extra space).\n    freebsd2.2*)\n      _LT_TAGVAR(archive_cmds, $1)='$LD -Bshareable -o $lib $libobjs $deplibs $linker_flags /usr/lib/c++rt0.o'\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-R$libdir'\n      _LT_TAGVAR(hardcode_direct, $1)=yes\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      ;;\n\n    # Unfortunately, older versions of FreeBSD 2 do not have this feature.\n    freebsd2.*)\n      _LT_TAGVAR(archive_cmds, $1)='$LD -Bshareable -o $lib $libobjs $deplibs $linker_flags'\n      _LT_TAGVAR(hardcode_direct, $1)=yes\n      _LT_TAGVAR(hardcode_minus_L, $1)=yes\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      ;;\n\n    # FreeBSD 3 and greater uses gcc -shared to do shared libraries.\n    freebsd* | dragonfly*)\n      _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag -o $lib $libobjs $deplibs $compiler_flags'\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-R$libdir'\n      _LT_TAGVAR(hardcode_direct, $1)=yes\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      ;;\n\n    hpux9*)\n      if test yes = \"$GCC\"; then\n\t_LT_TAGVAR(archive_cmds, $1)='$RM $output_objdir/$soname~$CC -shared $pic_flag $wl+b $wl$install_libdir -o $output_objdir/$soname $libobjs $deplibs $compiler_flags~test \"x$output_objdir/$soname\" = \"x$lib\" || mv $output_objdir/$soname $lib'\n      else\n\t_LT_TAGVAR(archive_cmds, $1)='$RM $output_objdir/$soname~$LD -b +b $install_libdir -o $output_objdir/$soname $libobjs $deplibs $linker_flags~test \"x$output_objdir/$soname\" = \"x$lib\" || mv $output_objdir/$soname $lib'\n      fi\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl+b $wl$libdir'\n      _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n      _LT_TAGVAR(hardcode_direct, $1)=yes\n\n      # hardcode_minus_L: Not really in the search PATH,\n      # but as the default location of the library.\n      _LT_TAGVAR(hardcode_minus_L, $1)=yes\n      _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-E'\n      ;;\n\n    hpux10*)\n      if test yes,no = \"$GCC,$with_gnu_ld\"; then\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $wl+h $wl$soname $wl+b $wl$install_libdir -o $lib $libobjs $deplibs $compiler_flags'\n      else\n\t_LT_TAGVAR(archive_cmds, $1)='$LD -b +h $soname +b $install_libdir -o $lib $libobjs $deplibs $linker_flags'\n      fi\n      if test no = \"$with_gnu_ld\"; then\n\t_LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl+b $wl$libdir'\n\t_LT_TAGVAR(hardcode_libdir_separator, $1)=:\n\t_LT_TAGVAR(hardcode_direct, $1)=yes\n\t_LT_TAGVAR(hardcode_direct_absolute, $1)=yes\n\t_LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-E'\n\t# hardcode_minus_L: Not really in the search PATH,\n\t# but as the default location of the library.\n\t_LT_TAGVAR(hardcode_minus_L, $1)=yes\n      fi\n      ;;\n\n    hpux11*)\n      if test yes,no = \"$GCC,$with_gnu_ld\"; then\n\tcase $host_cpu in\n\thppa*64*)\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -shared $wl+h $wl$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t  ;;\n\tia64*)\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $wl+h $wl$soname $wl+nodefaultrpath -o $lib $libobjs $deplibs $compiler_flags'\n\t  ;;\n\t*)\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $wl+h $wl$soname $wl+b $wl$install_libdir -o $lib $libobjs $deplibs $compiler_flags'\n\t  ;;\n\tesac\n      else\n\tcase $host_cpu in\n\thppa*64*)\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -b $wl+h $wl$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t  ;;\n\tia64*)\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -b $wl+h $wl$soname $wl+nodefaultrpath -o $lib $libobjs $deplibs $compiler_flags'\n\t  ;;\n\t*)\n\tm4_if($1, [], [\n\t  # Older versions of the 11.00 compiler do not understand -b yet\n\t  # (HP92453-01 A.11.01.20 doesn't, HP92453-01 B.11.X.35175-35176.GP does)\n\t  _LT_LINKER_OPTION([if $CC understands -b],\n\t    _LT_TAGVAR(lt_cv_prog_compiler__b, $1), [-b],\n\t    [_LT_TAGVAR(archive_cmds, $1)='$CC -b $wl+h $wl$soname $wl+b $wl$install_libdir -o $lib $libobjs $deplibs $compiler_flags'],\n\t    [_LT_TAGVAR(archive_cmds, $1)='$LD -b +h $soname +b $install_libdir -o $lib $libobjs $deplibs $linker_flags'])],\n\t  [_LT_TAGVAR(archive_cmds, $1)='$CC -b $wl+h $wl$soname $wl+b $wl$install_libdir -o $lib $libobjs $deplibs $compiler_flags'])\n\t  ;;\n\tesac\n      fi\n      if test no = \"$with_gnu_ld\"; then\n\t_LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl+b $wl$libdir'\n\t_LT_TAGVAR(hardcode_libdir_separator, $1)=:\n\n\tcase $host_cpu in\n\thppa*64*|ia64*)\n\t  _LT_TAGVAR(hardcode_direct, $1)=no\n\t  _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n\t  ;;\n\t*)\n\t  _LT_TAGVAR(hardcode_direct, $1)=yes\n\t  _LT_TAGVAR(hardcode_direct_absolute, $1)=yes\n\t  _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-E'\n\n\t  # hardcode_minus_L: Not really in the search PATH,\n\t  # but as the default location of the library.\n\t  _LT_TAGVAR(hardcode_minus_L, $1)=yes\n\t  ;;\n\tesac\n      fi\n      ;;\n\n    irix5* | irix6* | nonstopux*)\n      if test yes = \"$GCC\"; then\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-soname $wl$soname `test -n \"$verstring\" && func_echo_all \"$wl-set_version $wl$verstring\"` $wl-update_registry $wl$output_objdir/so_locations -o $lib'\n\t# Try to use the -exported_symbol ld option, if it does not\n\t# work, assume that -exports_file does not work either and\n\t# implicitly export all symbols.\n\t# This should be the same for all languages, so no per-tag cache variable.\n\tAC_CACHE_CHECK([whether the $host_os linker accepts -exported_symbol],\n\t  [lt_cv_irix_exported_symbol],\n\t  [save_LDFLAGS=$LDFLAGS\n\t   LDFLAGS=\"$LDFLAGS -shared $wl-exported_symbol ${wl}foo $wl-update_registry $wl/dev/null\"\n\t   AC_LINK_IFELSE(\n\t     [AC_LANG_SOURCE(\n\t        [AC_LANG_CASE([C], [[int foo (void) { return 0; }]],\n\t\t\t      [C++], [[int foo (void) { return 0; }]],\n\t\t\t      [Fortran 77], [[\n      subroutine foo\n      end]],\n\t\t\t      [Fortran], [[\n      subroutine foo\n      end]])])],\n\t      [lt_cv_irix_exported_symbol=yes],\n\t      [lt_cv_irix_exported_symbol=no])\n           LDFLAGS=$save_LDFLAGS])\n\tif test yes = \"$lt_cv_irix_exported_symbol\"; then\n          _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-soname $wl$soname `test -n \"$verstring\" && func_echo_all \"$wl-set_version $wl$verstring\"` $wl-update_registry $wl$output_objdir/so_locations $wl-exports_file $wl$export_symbols -o $lib'\n\tfi\n\t_LT_TAGVAR(link_all_deplibs, $1)=no\n      else\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared $libobjs $deplibs $compiler_flags -soname $soname `test -n \"$verstring\" && func_echo_all \"-set_version $verstring\"` -update_registry $output_objdir/so_locations -o $lib'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $libobjs $deplibs $compiler_flags -soname $soname `test -n \"$verstring\" && func_echo_all \"-set_version $verstring\"` -update_registry $output_objdir/so_locations -exports_file $export_symbols -o $lib'\n      fi\n      _LT_TAGVAR(archive_cmds_need_lc, $1)='no'\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n      _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n      _LT_TAGVAR(inherit_rpath, $1)=yes\n      _LT_TAGVAR(link_all_deplibs, $1)=yes\n      ;;\n\n    linux*)\n      case $cc_basename in\n      tcc*)\n\t# Fabrice Bellard et al's Tiny C Compiler\n\t_LT_TAGVAR(ld_shlibs, $1)=yes\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag -o $lib $libobjs $deplibs $compiler_flags'\n\t;;\n      esac\n      ;;\n\n    netbsd* | netbsdelf*-gnu)\n      if echo __ELF__ | $CC -E - | $GREP __ELF__ >/dev/null; then\n\t_LT_TAGVAR(archive_cmds, $1)='$LD -Bshareable -o $lib $libobjs $deplibs $linker_flags'  # a.out\n      else\n\t_LT_TAGVAR(archive_cmds, $1)='$LD -shared -o $lib $libobjs $deplibs $linker_flags'      # ELF\n      fi\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-R$libdir'\n      _LT_TAGVAR(hardcode_direct, $1)=yes\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      ;;\n\n    newsos6)\n      _LT_TAGVAR(archive_cmds, $1)='$LD -G -h $soname -o $lib $libobjs $deplibs $linker_flags'\n      _LT_TAGVAR(hardcode_direct, $1)=yes\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n      _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      ;;\n\n    *nto* | *qnx*)\n      ;;\n\n    openbsd* | bitrig*)\n      if test -f /usr/libexec/ld.so; then\n\t_LT_TAGVAR(hardcode_direct, $1)=yes\n\t_LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n\t_LT_TAGVAR(hardcode_direct_absolute, $1)=yes\n\tif test -z \"`echo __ELF__ | $CC -E - | $GREP __ELF__`\"; then\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag -o $lib $libobjs $deplibs $compiler_flags'\n\t  _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $pic_flag -o $lib $libobjs $deplibs $compiler_flags $wl-retain-symbols-file,$export_symbols'\n\t  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath,$libdir'\n\t  _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-E'\n\telse\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag -o $lib $libobjs $deplibs $compiler_flags'\n\t  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath,$libdir'\n\tfi\n      else\n\t_LT_TAGVAR(ld_shlibs, $1)=no\n      fi\n      ;;\n\n    os2*)\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n      _LT_TAGVAR(hardcode_minus_L, $1)=yes\n      _LT_TAGVAR(allow_undefined_flag, $1)=unsupported\n      shrext_cmds=.dll\n      _LT_TAGVAR(archive_cmds, $1)='$ECHO \"LIBRARY ${soname%$shared_ext} INITINSTANCE TERMINSTANCE\" > $output_objdir/$libname.def~\n\t$ECHO \"DESCRIPTION \\\"$libname\\\"\" >> $output_objdir/$libname.def~\n\t$ECHO \"DATA MULTIPLE NONSHARED\" >> $output_objdir/$libname.def~\n\t$ECHO EXPORTS >> $output_objdir/$libname.def~\n\temxexp $libobjs | $SED /\"_DLL_InitTerm\"/d >> $output_objdir/$libname.def~\n\t$CC -Zdll -Zcrtdll -o $output_objdir/$soname $libobjs $deplibs $compiler_flags $output_objdir/$libname.def~\n\temximp -o $lib $output_objdir/$libname.def'\n      _LT_TAGVAR(archive_expsym_cmds, $1)='$ECHO \"LIBRARY ${soname%$shared_ext} INITINSTANCE TERMINSTANCE\" > $output_objdir/$libname.def~\n\t$ECHO \"DESCRIPTION \\\"$libname\\\"\" >> $output_objdir/$libname.def~\n\t$ECHO \"DATA MULTIPLE NONSHARED\" >> $output_objdir/$libname.def~\n\t$ECHO EXPORTS >> $output_objdir/$libname.def~\n\tprefix_cmds=\"$SED\"~\n\tif test EXPORTS = \"`$SED 1q $export_symbols`\"; then\n\t  prefix_cmds=\"$prefix_cmds -e 1d\";\n\tfi~\n\tprefix_cmds=\"$prefix_cmds -e \\\"s/^\\(.*\\)$/_\\1/g\\\"\"~\n\tcat $export_symbols | $prefix_cmds >> $output_objdir/$libname.def~\n\t$CC -Zdll -Zcrtdll -o $output_objdir/$soname $libobjs $deplibs $compiler_flags $output_objdir/$libname.def~\n\temximp -o $lib $output_objdir/$libname.def'\n      _LT_TAGVAR(old_archive_From_new_cmds, $1)='emximp -o $output_objdir/${libname}_dll.a $output_objdir/$libname.def'\n      _LT_TAGVAR(enable_shared_with_static_runtimes, $1)=yes\n      ;;\n\n    osf3*)\n      if test yes = \"$GCC\"; then\n\t_LT_TAGVAR(allow_undefined_flag, $1)=' $wl-expect_unresolved $wl\\*'\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared$allow_undefined_flag $libobjs $deplibs $compiler_flags $wl-soname $wl$soname `test -n \"$verstring\" && func_echo_all \"$wl-set_version $wl$verstring\"` $wl-update_registry $wl$output_objdir/so_locations -o $lib'\n      else\n\t_LT_TAGVAR(allow_undefined_flag, $1)=' -expect_unresolved \\*'\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared$allow_undefined_flag $libobjs $deplibs $compiler_flags -soname $soname `test -n \"$verstring\" && func_echo_all \"-set_version $verstring\"` -update_registry $output_objdir/so_locations -o $lib'\n      fi\n      _LT_TAGVAR(archive_cmds_need_lc, $1)='no'\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n      _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n      ;;\n\n    osf4* | osf5*)\t# as osf3* with the addition of -msym flag\n      if test yes = \"$GCC\"; then\n\t_LT_TAGVAR(allow_undefined_flag, $1)=' $wl-expect_unresolved $wl\\*'\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared$allow_undefined_flag $pic_flag $libobjs $deplibs $compiler_flags $wl-msym $wl-soname $wl$soname `test -n \"$verstring\" && func_echo_all \"$wl-set_version $wl$verstring\"` $wl-update_registry $wl$output_objdir/so_locations -o $lib'\n\t_LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n      else\n\t_LT_TAGVAR(allow_undefined_flag, $1)=' -expect_unresolved \\*'\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared$allow_undefined_flag $libobjs $deplibs $compiler_flags -msym -soname $soname `test -n \"$verstring\" && func_echo_all \"-set_version $verstring\"` -update_registry $output_objdir/so_locations -o $lib'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='for i in `cat $export_symbols`; do printf \"%s %s\\\\n\" -exported_symbol \"\\$i\" >> $lib.exp; done; printf \"%s\\\\n\" \"-hidden\">> $lib.exp~\n          $CC -shared$allow_undefined_flag $wl-input $wl$lib.exp $compiler_flags $libobjs $deplibs -soname $soname `test -n \"$verstring\" && $ECHO \"-set_version $verstring\"` -update_registry $output_objdir/so_locations -o $lib~$RM $lib.exp'\n\n\t# Both c and cxx compiler support -rpath directly\n\t_LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-rpath $libdir'\n      fi\n      _LT_TAGVAR(archive_cmds_need_lc, $1)='no'\n      _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n      ;;\n\n    solaris*)\n      _LT_TAGVAR(no_undefined_flag, $1)=' -z defs'\n      if test yes = \"$GCC\"; then\n\twlarc='$wl'\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $wl-z ${wl}text $wl-h $wl$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='echo \"{ global:\" > $lib.exp~cat $export_symbols | $SED -e \"s/\\(.*\\)/\\1;/\" >> $lib.exp~echo \"local: *; };\" >> $lib.exp~\n          $CC -shared $pic_flag $wl-z ${wl}text $wl-M $wl$lib.exp $wl-h $wl$soname -o $lib $libobjs $deplibs $compiler_flags~$RM $lib.exp'\n      else\n\tcase `$CC -V 2>&1` in\n\t*\"Compilers 5.0\"*)\n\t  wlarc=''\n\t  _LT_TAGVAR(archive_cmds, $1)='$LD -G$allow_undefined_flag -h $soname -o $lib $libobjs $deplibs $linker_flags'\n\t  _LT_TAGVAR(archive_expsym_cmds, $1)='echo \"{ global:\" > $lib.exp~cat $export_symbols | $SED -e \"s/\\(.*\\)/\\1;/\" >> $lib.exp~echo \"local: *; };\" >> $lib.exp~\n            $LD -G$allow_undefined_flag -M $lib.exp -h $soname -o $lib $libobjs $deplibs $linker_flags~$RM $lib.exp'\n\t  ;;\n\t*)\n\t  wlarc='$wl'\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -G$allow_undefined_flag -h $soname -o $lib $libobjs $deplibs $compiler_flags'\n\t  _LT_TAGVAR(archive_expsym_cmds, $1)='echo \"{ global:\" > $lib.exp~cat $export_symbols | $SED -e \"s/\\(.*\\)/\\1;/\" >> $lib.exp~echo \"local: *; };\" >> $lib.exp~\n            $CC -G$allow_undefined_flag -M $lib.exp -h $soname -o $lib $libobjs $deplibs $compiler_flags~$RM $lib.exp'\n\t  ;;\n\tesac\n      fi\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-R$libdir'\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      case $host_os in\n      solaris2.[[0-5]] | solaris2.[[0-5]].*) ;;\n      *)\n\t# The compiler driver will combine and reorder linker options,\n\t# but understands '-z linker_flag'.  GCC discards it without '$wl',\n\t# but is careful enough not to reorder.\n\t# Supported since Solaris 2.6 (maybe 2.5.1?)\n\tif test yes = \"$GCC\"; then\n\t  _LT_TAGVAR(whole_archive_flag_spec, $1)='$wl-z ${wl}allextract$convenience $wl-z ${wl}defaultextract'\n\telse\n\t  _LT_TAGVAR(whole_archive_flag_spec, $1)='-z allextract$convenience -z defaultextract'\n\tfi\n\t;;\n      esac\n      _LT_TAGVAR(link_all_deplibs, $1)=yes\n      ;;\n\n    sunos4*)\n      if test sequent = \"$host_vendor\"; then\n\t# Use $CC to link under sequent, because it throws in some extra .o\n\t# files that make .init and .fini sections work.\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -G $wl-h $soname -o $lib $libobjs $deplibs $compiler_flags'\n      else\n\t_LT_TAGVAR(archive_cmds, $1)='$LD -assert pure-text -Bstatic -o $lib $libobjs $deplibs $linker_flags'\n      fi\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n      _LT_TAGVAR(hardcode_direct, $1)=yes\n      _LT_TAGVAR(hardcode_minus_L, $1)=yes\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      ;;\n\n    sysv4)\n      case $host_vendor in\n\tsni)\n\t  _LT_TAGVAR(archive_cmds, $1)='$LD -G -h $soname -o $lib $libobjs $deplibs $linker_flags'\n\t  _LT_TAGVAR(hardcode_direct, $1)=yes # is this really true???\n\t;;\n\tsiemens)\n\t  ## LD is ld it makes a PLAMLIB\n\t  ## CC just makes a GrossModule.\n\t  _LT_TAGVAR(archive_cmds, $1)='$LD -G -o $lib $libobjs $deplibs $linker_flags'\n\t  _LT_TAGVAR(reload_cmds, $1)='$CC -r -o $output$reload_objs'\n\t  _LT_TAGVAR(hardcode_direct, $1)=no\n        ;;\n\tmotorola)\n\t  _LT_TAGVAR(archive_cmds, $1)='$LD -G -h $soname -o $lib $libobjs $deplibs $linker_flags'\n\t  _LT_TAGVAR(hardcode_direct, $1)=no #Motorola manual says yes, but my tests say they lie\n\t;;\n      esac\n      runpath_var='LD_RUN_PATH'\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      ;;\n\n    sysv4.3*)\n      _LT_TAGVAR(archive_cmds, $1)='$LD -G -h $soname -o $lib $libobjs $deplibs $linker_flags'\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      _LT_TAGVAR(export_dynamic_flag_spec, $1)='-Bexport'\n      ;;\n\n    sysv4*MP*)\n      if test -d /usr/nec; then\n\t_LT_TAGVAR(archive_cmds, $1)='$LD -G -h $soname -o $lib $libobjs $deplibs $linker_flags'\n\t_LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n\trunpath_var=LD_RUN_PATH\n\thardcode_runpath_var=yes\n\t_LT_TAGVAR(ld_shlibs, $1)=yes\n      fi\n      ;;\n\n    sysv4*uw2* | sysv5OpenUNIX* | sysv5UnixWare7.[[01]].[[10]]* | unixware7* | sco3.2v5.0.[[024]]*)\n      _LT_TAGVAR(no_undefined_flag, $1)='$wl-z,text'\n      _LT_TAGVAR(archive_cmds_need_lc, $1)=no\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      runpath_var='LD_RUN_PATH'\n\n      if test yes = \"$GCC\"; then\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $wl-Bexport:$export_symbols $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n      else\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -G $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='$CC -G $wl-Bexport:$export_symbols $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n      fi\n      ;;\n\n    sysv5* | sco3.2v5* | sco5v6*)\n      # Note: We CANNOT use -z defs as we might desire, because we do not\n      # link with -lc, and that would cause any symbols used from libc to\n      # always be unresolved, which means just about no library would\n      # ever link correctly.  If we're not using GNU ld we use -z text\n      # though, which does catch some bad symbols but isn't as heavy-handed\n      # as -z defs.\n      _LT_TAGVAR(no_undefined_flag, $1)='$wl-z,text'\n      _LT_TAGVAR(allow_undefined_flag, $1)='$wl-z,nodefs'\n      _LT_TAGVAR(archive_cmds_need_lc, $1)=no\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-R,$libdir'\n      _LT_TAGVAR(hardcode_libdir_separator, $1)=':'\n      _LT_TAGVAR(link_all_deplibs, $1)=yes\n      _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-Bexport'\n      runpath_var='LD_RUN_PATH'\n\n      if test yes = \"$GCC\"; then\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $wl-Bexport:$export_symbols $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n      else\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -G $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='$CC -G $wl-Bexport:$export_symbols $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n      fi\n      ;;\n\n    uts4*)\n      _LT_TAGVAR(archive_cmds, $1)='$LD -G -h $soname -o $lib $libobjs $deplibs $linker_flags'\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      ;;\n\n    *)\n      _LT_TAGVAR(ld_shlibs, $1)=no\n      ;;\n    esac\n\n    if test sni = \"$host_vendor\"; then\n      case $host in\n      sysv4 | sysv4.2uw2* | sysv4.3* | sysv5*)\n\t_LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-Blargedynsym'\n\t;;\n      esac\n    fi\n  fi\n])\nAC_MSG_RESULT([$_LT_TAGVAR(ld_shlibs, $1)])\ntest no = \"$_LT_TAGVAR(ld_shlibs, $1)\" && can_build_shared=no\n\n_LT_TAGVAR(with_gnu_ld, $1)=$with_gnu_ld\n\n_LT_DECL([], [libext], [0], [Old archive suffix (normally \"a\")])dnl\n_LT_DECL([], [shrext_cmds], [1], [Shared library suffix (normally \".so\")])dnl\n_LT_DECL([], [extract_expsyms_cmds], [2],\n    [The commands to extract the exported symbol list from a shared archive])\n\n#\n# Do we need to explicitly link libc?\n#\ncase \"x$_LT_TAGVAR(archive_cmds_need_lc, $1)\" in\nx|xyes)\n  # Assume -lc should be added\n  _LT_TAGVAR(archive_cmds_need_lc, $1)=yes\n\n  if test yes,yes = \"$GCC,$enable_shared\"; then\n    case $_LT_TAGVAR(archive_cmds, $1) in\n    *'~'*)\n      # FIXME: we may have to deal with multi-command sequences.\n      ;;\n    '$CC '*)\n      # Test whether the compiler implicitly links with -lc since on some\n      # systems, -lgcc has to come before -lc. If gcc already passes -lc\n      # to ld, don't add -lc before -lgcc.\n      AC_CACHE_CHECK([whether -lc should be explicitly linked in],\n\t[lt_cv_]_LT_TAGVAR(archive_cmds_need_lc, $1),\n\t[$RM conftest*\n\techo \"$lt_simple_compile_test_code\" > conftest.$ac_ext\n\n\tif AC_TRY_EVAL(ac_compile) 2>conftest.err; then\n\t  soname=conftest\n\t  lib=conftest\n\t  libobjs=conftest.$ac_objext\n\t  deplibs=\n\t  wl=$_LT_TAGVAR(lt_prog_compiler_wl, $1)\n\t  pic_flag=$_LT_TAGVAR(lt_prog_compiler_pic, $1)\n\t  compiler_flags=-v\n\t  linker_flags=-v\n\t  verstring=\n\t  output_objdir=.\n\t  libname=conftest\n\t  lt_save_allow_undefined_flag=$_LT_TAGVAR(allow_undefined_flag, $1)\n\t  _LT_TAGVAR(allow_undefined_flag, $1)=\n\t  if AC_TRY_EVAL(_LT_TAGVAR(archive_cmds, $1) 2\\>\\&1 \\| $GREP \\\" -lc \\\" \\>/dev/null 2\\>\\&1)\n\t  then\n\t    lt_cv_[]_LT_TAGVAR(archive_cmds_need_lc, $1)=no\n\t  else\n\t    lt_cv_[]_LT_TAGVAR(archive_cmds_need_lc, $1)=yes\n\t  fi\n\t  _LT_TAGVAR(allow_undefined_flag, $1)=$lt_save_allow_undefined_flag\n\telse\n\t  cat conftest.err 1>&5\n\tfi\n\t$RM conftest*\n\t])\n      _LT_TAGVAR(archive_cmds_need_lc, $1)=$lt_cv_[]_LT_TAGVAR(archive_cmds_need_lc, $1)\n      ;;\n    esac\n  fi\n  ;;\nesac\n\n_LT_TAGDECL([build_libtool_need_lc], [archive_cmds_need_lc], [0],\n    [Whether or not to add -lc for building shared libraries])\n_LT_TAGDECL([allow_libtool_libs_with_static_runtimes],\n    [enable_shared_with_static_runtimes], [0],\n    [Whether or not to disallow shared libs when runtime libs are static])\n_LT_TAGDECL([], [export_dynamic_flag_spec], [1],\n    [Compiler flag to allow reflexive dlopens])\n_LT_TAGDECL([], [whole_archive_flag_spec], [1],\n    [Compiler flag to generate shared objects directly from archives])\n_LT_TAGDECL([], [compiler_needs_object], [1],\n    [Whether the compiler copes with passing no objects directly])\n_LT_TAGDECL([], [old_archive_from_new_cmds], [2],\n    [Create an old-style archive from a shared archive])\n_LT_TAGDECL([], [old_archive_from_expsyms_cmds], [2],\n    [Create a temporary old-style archive to link instead of a shared archive])\n_LT_TAGDECL([], [archive_cmds], [2], [Commands used to build a shared archive])\n_LT_TAGDECL([], [archive_expsym_cmds], [2])\n_LT_TAGDECL([], [module_cmds], [2],\n    [Commands used to build a loadable module if different from building\n    a shared archive.])\n_LT_TAGDECL([], [module_expsym_cmds], [2])\n_LT_TAGDECL([], [with_gnu_ld], [1],\n    [Whether we are building with GNU ld or not])\n_LT_TAGDECL([], [allow_undefined_flag], [1],\n    [Flag that allows shared libraries with undefined symbols to be built])\n_LT_TAGDECL([], [no_undefined_flag], [1],\n    [Flag that enforces no undefined symbols])\n_LT_TAGDECL([], [hardcode_libdir_flag_spec], [1],\n    [Flag to hardcode $libdir into a binary during linking.\n    This must work even if $libdir does not exist])\n_LT_TAGDECL([], [hardcode_libdir_separator], [1],\n    [Whether we need a single \"-rpath\" flag with a separated argument])\n_LT_TAGDECL([], [hardcode_direct], [0],\n    [Set to \"yes\" if using DIR/libNAME$shared_ext during linking hardcodes\n    DIR into the resulting binary])\n_LT_TAGDECL([], [hardcode_direct_absolute], [0],\n    [Set to \"yes\" if using DIR/libNAME$shared_ext during linking hardcodes\n    DIR into the resulting binary and the resulting library dependency is\n    \"absolute\", i.e impossible to change by setting $shlibpath_var if the\n    library is relocated])\n_LT_TAGDECL([], [hardcode_minus_L], [0],\n    [Set to \"yes\" if using the -LDIR flag during linking hardcodes DIR\n    into the resulting binary])\n_LT_TAGDECL([], [hardcode_shlibpath_var], [0],\n    [Set to \"yes\" if using SHLIBPATH_VAR=DIR during linking hardcodes DIR\n    into the resulting binary])\n_LT_TAGDECL([], [hardcode_automatic], [0],\n    [Set to \"yes\" if building a shared library automatically hardcodes DIR\n    into the library and all subsequent libraries and executables linked\n    against it])\n_LT_TAGDECL([], [inherit_rpath], [0],\n    [Set to yes if linker adds runtime paths of dependent libraries\n    to runtime path list])\n_LT_TAGDECL([], [link_all_deplibs], [0],\n    [Whether libtool must link a program against all its dependency libraries])\n_LT_TAGDECL([], [always_export_symbols], [0],\n    [Set to \"yes\" if exported symbols are required])\n_LT_TAGDECL([], [export_symbols_cmds], [2],\n    [The commands to list exported symbols])\n_LT_TAGDECL([], [exclude_expsyms], [1],\n    [Symbols that should not be listed in the preloaded symbols])\n_LT_TAGDECL([], [include_expsyms], [1],\n    [Symbols that must always be exported])\n_LT_TAGDECL([], [prelink_cmds], [2],\n    [Commands necessary for linking programs (against libraries) with templates])\n_LT_TAGDECL([], [postlink_cmds], [2],\n    [Commands necessary for finishing linking programs])\n_LT_TAGDECL([], [file_list_spec], [1],\n    [Specify filename containing input files])\ndnl FIXME: Not yet implemented\ndnl _LT_TAGDECL([], [thread_safe_flag_spec], [1],\ndnl    [Compiler flag to generate thread safe objects])\n])# _LT_LINKER_SHLIBS\n\n\n# _LT_LANG_C_CONFIG([TAG])\n# ------------------------\n# Ensure that the configuration variables for a C compiler are suitably\n# defined.  These variables are subsequently used by _LT_CONFIG to write\n# the compiler configuration to 'libtool'.\nm4_defun([_LT_LANG_C_CONFIG],\n[m4_require([_LT_DECL_EGREP])dnl\nlt_save_CC=$CC\nAC_LANG_PUSH(C)\n\n# Source file extension for C test sources.\nac_ext=c\n\n# Object file extension for compiled C test sources.\nobjext=o\n_LT_TAGVAR(objext, $1)=$objext\n\n# Code to be used in simple compile tests\nlt_simple_compile_test_code=\"int some_variable = 0;\"\n\n# Code to be used in simple link tests\nlt_simple_link_test_code='int main(){return(0);}'\n\n_LT_TAG_COMPILER\n# Save the default compiler, since it gets overwritten when the other\n# tags are being tested, and _LT_TAGVAR(compiler, []) is a NOP.\ncompiler_DEFAULT=$CC\n\n# save warnings/boilerplate of simple test code\n_LT_COMPILER_BOILERPLATE\n_LT_LINKER_BOILERPLATE\n\n## CAVEAT EMPTOR:\n## There is no encapsulation within the following macros, do not change\n## the running order or otherwise move them around unless you know exactly\n## what you are doing...\nif test -n \"$compiler\"; then\n  _LT_COMPILER_NO_RTTI($1)\n  _LT_COMPILER_PIC($1)\n  _LT_COMPILER_C_O($1)\n  _LT_COMPILER_FILE_LOCKS($1)\n  _LT_LINKER_SHLIBS($1)\n  _LT_SYS_DYNAMIC_LINKER($1)\n  _LT_LINKER_HARDCODE_LIBPATH($1)\n  LT_SYS_DLOPEN_SELF\n  _LT_CMD_STRIPLIB\n\n  # Report what library types will actually be built\n  AC_MSG_CHECKING([if libtool supports shared libraries])\n  AC_MSG_RESULT([$can_build_shared])\n\n  AC_MSG_CHECKING([whether to build shared libraries])\n  test no = \"$can_build_shared\" && enable_shared=no\n\n  # On AIX, shared libraries and static libraries use the same namespace, and\n  # are all built from PIC.\n  case $host_os in\n  aix3*)\n    test yes = \"$enable_shared\" && enable_static=no\n    if test -n \"$RANLIB\"; then\n      archive_cmds=\"$archive_cmds~\\$RANLIB \\$lib\"\n      postinstall_cmds='$RANLIB $lib'\n    fi\n    ;;\n\n  aix[[4-9]]*)\n    if test ia64 != \"$host_cpu\"; then\n      case $enable_shared,$with_aix_soname,$aix_use_runtimelinking in\n      yes,aix,yes) ;;\t\t\t# shared object as lib.so file only\n      yes,svr4,*) ;;\t\t\t# shared object as lib.so archive member only\n      yes,*) enable_static=no ;;\t# shared object in lib.a archive as well\n      esac\n    fi\n    ;;\n  esac\n  AC_MSG_RESULT([$enable_shared])\n\n  AC_MSG_CHECKING([whether to build static libraries])\n  # Make sure either enable_shared or enable_static is yes.\n  test yes = \"$enable_shared\" || enable_static=yes\n  AC_MSG_RESULT([$enable_static])\n\n  _LT_CONFIG($1)\nfi\nAC_LANG_POP\nCC=$lt_save_CC\n])# _LT_LANG_C_CONFIG\n\n\n# _LT_LANG_CXX_CONFIG([TAG])\n# --------------------------\n# Ensure that the configuration variables for a C++ compiler are suitably\n# defined.  These variables are subsequently used by _LT_CONFIG to write\n# the compiler configuration to 'libtool'.\nm4_defun([_LT_LANG_CXX_CONFIG],\n[m4_require([_LT_FILEUTILS_DEFAULTS])dnl\nm4_require([_LT_DECL_EGREP])dnl\nm4_require([_LT_PATH_MANIFEST_TOOL])dnl\nif test -n \"$CXX\" && ( test no != \"$CXX\" &&\n    ( (test g++ = \"$CXX\" && `g++ -v >/dev/null 2>&1` ) ||\n    (test g++ != \"$CXX\"))); then\n  AC_PROG_CXXCPP\nelse\n  _lt_caught_CXX_error=yes\nfi\n\nAC_LANG_PUSH(C++)\n_LT_TAGVAR(archive_cmds_need_lc, $1)=no\n_LT_TAGVAR(allow_undefined_flag, $1)=\n_LT_TAGVAR(always_export_symbols, $1)=no\n_LT_TAGVAR(archive_expsym_cmds, $1)=\n_LT_TAGVAR(compiler_needs_object, $1)=no\n_LT_TAGVAR(export_dynamic_flag_spec, $1)=\n_LT_TAGVAR(hardcode_direct, $1)=no\n_LT_TAGVAR(hardcode_direct_absolute, $1)=no\n_LT_TAGVAR(hardcode_libdir_flag_spec, $1)=\n_LT_TAGVAR(hardcode_libdir_separator, $1)=\n_LT_TAGVAR(hardcode_minus_L, $1)=no\n_LT_TAGVAR(hardcode_shlibpath_var, $1)=unsupported\n_LT_TAGVAR(hardcode_automatic, $1)=no\n_LT_TAGVAR(inherit_rpath, $1)=no\n_LT_TAGVAR(module_cmds, $1)=\n_LT_TAGVAR(module_expsym_cmds, $1)=\n_LT_TAGVAR(link_all_deplibs, $1)=unknown\n_LT_TAGVAR(old_archive_cmds, $1)=$old_archive_cmds\n_LT_TAGVAR(reload_flag, $1)=$reload_flag\n_LT_TAGVAR(reload_cmds, $1)=$reload_cmds\n_LT_TAGVAR(no_undefined_flag, $1)=\n_LT_TAGVAR(whole_archive_flag_spec, $1)=\n_LT_TAGVAR(enable_shared_with_static_runtimes, $1)=no\n\n# Source file extension for C++ test sources.\nac_ext=cpp\n\n# Object file extension for compiled C++ test sources.\nobjext=o\n_LT_TAGVAR(objext, $1)=$objext\n\n# No sense in running all these tests if we already determined that\n# the CXX compiler isn't working.  Some variables (like enable_shared)\n# are currently assumed to apply to all compilers on this platform,\n# and will be corrupted by setting them based on a non-working compiler.\nif test yes != \"$_lt_caught_CXX_error\"; then\n  # Code to be used in simple compile tests\n  lt_simple_compile_test_code=\"int some_variable = 0;\"\n\n  # Code to be used in simple link tests\n  lt_simple_link_test_code='int main(int, char *[[]]) { return(0); }'\n\n  # ltmain only uses $CC for tagged configurations so make sure $CC is set.\n  _LT_TAG_COMPILER\n\n  # save warnings/boilerplate of simple test code\n  _LT_COMPILER_BOILERPLATE\n  _LT_LINKER_BOILERPLATE\n\n  # Allow CC to be a program name with arguments.\n  lt_save_CC=$CC\n  lt_save_CFLAGS=$CFLAGS\n  lt_save_LD=$LD\n  lt_save_GCC=$GCC\n  GCC=$GXX\n  lt_save_with_gnu_ld=$with_gnu_ld\n  lt_save_path_LD=$lt_cv_path_LD\n  if test -n \"${lt_cv_prog_gnu_ldcxx+set}\"; then\n    lt_cv_prog_gnu_ld=$lt_cv_prog_gnu_ldcxx\n  else\n    $as_unset lt_cv_prog_gnu_ld\n  fi\n  if test -n \"${lt_cv_path_LDCXX+set}\"; then\n    lt_cv_path_LD=$lt_cv_path_LDCXX\n  else\n    $as_unset lt_cv_path_LD\n  fi\n  test -z \"${LDCXX+set}\" || LD=$LDCXX\n  CC=${CXX-\"c++\"}\n  CFLAGS=$CXXFLAGS\n  compiler=$CC\n  _LT_TAGVAR(compiler, $1)=$CC\n  _LT_CC_BASENAME([$compiler])\n\n  if test -n \"$compiler\"; then\n    # We don't want -fno-exception when compiling C++ code, so set the\n    # no_builtin_flag separately\n    if test yes = \"$GXX\"; then\n      _LT_TAGVAR(lt_prog_compiler_no_builtin_flag, $1)=' -fno-builtin'\n    else\n      _LT_TAGVAR(lt_prog_compiler_no_builtin_flag, $1)=\n    fi\n\n    if test yes = \"$GXX\"; then\n      # Set up default GNU C++ configuration\n\n      LT_PATH_LD\n\n      # Check if GNU C++ uses GNU ld as the underlying linker, since the\n      # archiving commands below assume that GNU ld is being used.\n      if test yes = \"$with_gnu_ld\"; then\n        _LT_TAGVAR(archive_cmds, $1)='$CC $pic_flag -shared -nostdlib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname -o $lib'\n        _LT_TAGVAR(archive_expsym_cmds, $1)='$CC $pic_flag -shared -nostdlib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname $wl-retain-symbols-file $wl$export_symbols -o $lib'\n\n        _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n        _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl--export-dynamic'\n\n        # If archive_cmds runs LD, not CC, wlarc should be empty\n        # XXX I think wlarc can be eliminated in ltcf-cxx, but I need to\n        #     investigate it a little bit more. (MM)\n        wlarc='$wl'\n\n        # ancient GNU ld didn't support --whole-archive et. al.\n        if eval \"`$CC -print-prog-name=ld` --help 2>&1\" |\n\t  $GREP 'no-whole-archive' > /dev/null; then\n          _LT_TAGVAR(whole_archive_flag_spec, $1)=$wlarc'--whole-archive$convenience '$wlarc'--no-whole-archive'\n        else\n          _LT_TAGVAR(whole_archive_flag_spec, $1)=\n        fi\n      else\n        with_gnu_ld=no\n        wlarc=\n\n        # A generic and very simple default shared library creation\n        # command for GNU C++ for the case where it uses the native\n        # linker, instead of GNU ld.  If possible, this setting should\n        # overridden to take advantage of the native linker features on\n        # the platform it is being used on.\n        _LT_TAGVAR(archive_cmds, $1)='$CC -shared -nostdlib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags -o $lib'\n      fi\n\n      # Commands to make compiler produce verbose output that lists\n      # what \"hidden\" libraries, object files and flags are used when\n      # linking a shared library.\n      output_verbose_link_cmd='$CC -shared $CFLAGS -v conftest.$objext 2>&1 | $GREP -v \"^Configured with:\" | $GREP \" \\-L\"'\n\n    else\n      GXX=no\n      with_gnu_ld=no\n      wlarc=\n    fi\n\n    # PORTME: fill in a description of your system's C++ link characteristics\n    AC_MSG_CHECKING([whether the $compiler linker ($LD) supports shared libraries])\n    _LT_TAGVAR(ld_shlibs, $1)=yes\n    case $host_os in\n      aix3*)\n        # FIXME: insert proper C++ library support\n        _LT_TAGVAR(ld_shlibs, $1)=no\n        ;;\n      aix[[4-9]]*)\n        if test ia64 = \"$host_cpu\"; then\n          # On IA64, the linker does run time linking by default, so we don't\n          # have to do anything special.\n          aix_use_runtimelinking=no\n          exp_sym_flag='-Bexport'\n          no_entry_flag=\n        else\n          aix_use_runtimelinking=no\n\n          # Test if we are trying to use run time linking or normal\n          # AIX style linking. If -brtl is somewhere in LDFLAGS, we\n          # have runtime linking enabled, and use it for executables.\n          # For shared libraries, we enable/disable runtime linking\n          # depending on the kind of the shared library created -\n          # when \"with_aix_soname,aix_use_runtimelinking\" is:\n          # \"aix,no\"   lib.a(lib.so.V) shared, rtl:no,  for executables\n          # \"aix,yes\"  lib.so          shared, rtl:yes, for executables\n          #            lib.a           static archive\n          # \"both,no\"  lib.so.V(shr.o) shared, rtl:yes\n          #            lib.a(lib.so.V) shared, rtl:no,  for executables\n          # \"both,yes\" lib.so.V(shr.o) shared, rtl:yes, for executables\n          #            lib.a(lib.so.V) shared, rtl:no\n          # \"svr4,*\"   lib.so.V(shr.o) shared, rtl:yes, for executables\n          #            lib.a           static archive\n          case $host_os in aix4.[[23]]|aix4.[[23]].*|aix[[5-9]]*)\n\t    for ld_flag in $LDFLAGS; do\n\t      case $ld_flag in\n\t      *-brtl*)\n\t        aix_use_runtimelinking=yes\n\t        break\n\t        ;;\n\t      esac\n\t    done\n\t    if test svr4,no = \"$with_aix_soname,$aix_use_runtimelinking\"; then\n\t      # With aix-soname=svr4, we create the lib.so.V shared archives only,\n\t      # so we don't have lib.a shared libs to link our executables.\n\t      # We have to force runtime linking in this case.\n\t      aix_use_runtimelinking=yes\n\t      LDFLAGS=\"$LDFLAGS -Wl,-brtl\"\n\t    fi\n\t    ;;\n          esac\n\n          exp_sym_flag='-bexport'\n          no_entry_flag='-bnoentry'\n        fi\n\n        # When large executables or shared objects are built, AIX ld can\n        # have problems creating the table of contents.  If linking a library\n        # or program results in \"error TOC overflow\" add -mminimal-toc to\n        # CXXFLAGS/CFLAGS for g++/gcc.  In the cases where that is not\n        # enough to fix the problem, add -Wl,-bbigtoc to LDFLAGS.\n\n        _LT_TAGVAR(archive_cmds, $1)=''\n        _LT_TAGVAR(hardcode_direct, $1)=yes\n        _LT_TAGVAR(hardcode_direct_absolute, $1)=yes\n        _LT_TAGVAR(hardcode_libdir_separator, $1)=':'\n        _LT_TAGVAR(link_all_deplibs, $1)=yes\n        _LT_TAGVAR(file_list_spec, $1)='$wl-f,'\n        case $with_aix_soname,$aix_use_runtimelinking in\n        aix,*) ;;\t# no import file\n        svr4,* | *,yes) # use import file\n          # The Import File defines what to hardcode.\n          _LT_TAGVAR(hardcode_direct, $1)=no\n          _LT_TAGVAR(hardcode_direct_absolute, $1)=no\n          ;;\n        esac\n\n        if test yes = \"$GXX\"; then\n          case $host_os in aix4.[[012]]|aix4.[[012]].*)\n          # We only want to do this on AIX 4.2 and lower, the check\n          # below for broken collect2 doesn't work under 4.3+\n\t  collect2name=`$CC -print-prog-name=collect2`\n\t  if test -f \"$collect2name\" &&\n\t     strings \"$collect2name\" | $GREP resolve_lib_name >/dev/null\n\t  then\n\t    # We have reworked collect2\n\t    :\n\t  else\n\t    # We have old collect2\n\t    _LT_TAGVAR(hardcode_direct, $1)=unsupported\n\t    # It fails to find uninstalled libraries when the uninstalled\n\t    # path is not listed in the libpath.  Setting hardcode_minus_L\n\t    # to unsupported forces relinking\n\t    _LT_TAGVAR(hardcode_minus_L, $1)=yes\n\t    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n\t    _LT_TAGVAR(hardcode_libdir_separator, $1)=\n\t  fi\n          esac\n          shared_flag='-shared'\n\t  if test yes = \"$aix_use_runtimelinking\"; then\n\t    shared_flag=$shared_flag' $wl-G'\n\t  fi\n\t  # Need to ensure runtime linking is disabled for the traditional\n\t  # shared library, or the linker may eventually find shared libraries\n\t  # /with/ Import File - we do not want to mix them.\n\t  shared_flag_aix='-shared'\n\t  shared_flag_svr4='-shared $wl-G'\n        else\n          # not using gcc\n          if test ia64 = \"$host_cpu\"; then\n\t  # VisualAge C++, Version 5.5 for AIX 5L for IA-64, Beta 3 Release\n\t  # chokes on -Wl,-G. The following line is correct:\n\t  shared_flag='-G'\n          else\n\t    if test yes = \"$aix_use_runtimelinking\"; then\n\t      shared_flag='$wl-G'\n\t    else\n\t      shared_flag='$wl-bM:SRE'\n\t    fi\n\t    shared_flag_aix='$wl-bM:SRE'\n\t    shared_flag_svr4='$wl-G'\n          fi\n        fi\n\n        _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-bexpall'\n        # It seems that -bexpall does not export symbols beginning with\n        # underscore (_), so it is better to generate a list of symbols to\n\t# export.\n        _LT_TAGVAR(always_export_symbols, $1)=yes\n\tif test aix,yes = \"$with_aix_soname,$aix_use_runtimelinking\"; then\n          # Warning - without using the other runtime loading flags (-brtl),\n          # -berok will link without error, but may produce a broken library.\n          # The \"-G\" linker flag allows undefined symbols.\n          _LT_TAGVAR(no_undefined_flag, $1)='-bernotok'\n          # Determine the default libpath from the value encoded in an empty\n          # executable.\n          _LT_SYS_MODULE_PATH_AIX([$1])\n          _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-blibpath:$libdir:'\"$aix_libpath\"\n\n          _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -o $output_objdir/$soname $libobjs $deplibs $wl'$no_entry_flag' $compiler_flags `if test -n \"$allow_undefined_flag\"; then func_echo_all \"$wl$allow_undefined_flag\"; else :; fi` $wl'$exp_sym_flag:\\$export_symbols' '$shared_flag\n        else\n          if test ia64 = \"$host_cpu\"; then\n\t    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-R $libdir:/usr/lib:/lib'\n\t    _LT_TAGVAR(allow_undefined_flag, $1)=\"-z nodefs\"\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)=\"\\$CC $shared_flag\"' -o $output_objdir/$soname $libobjs $deplibs '\"\\$wl$no_entry_flag\"' $compiler_flags $wl$allow_undefined_flag '\"\\$wl$exp_sym_flag:\\$export_symbols\"\n          else\n\t    # Determine the default libpath from the value encoded in an\n\t    # empty executable.\n\t    _LT_SYS_MODULE_PATH_AIX([$1])\n\t    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-blibpath:$libdir:'\"$aix_libpath\"\n\t    # Warning - without using the other run time loading flags,\n\t    # -berok will link without error, but may produce a broken library.\n\t    _LT_TAGVAR(no_undefined_flag, $1)=' $wl-bernotok'\n\t    _LT_TAGVAR(allow_undefined_flag, $1)=' $wl-berok'\n\t    if test yes = \"$with_gnu_ld\"; then\n\t      # We only use this code for GNU lds that support --whole-archive.\n\t      _LT_TAGVAR(whole_archive_flag_spec, $1)='$wl--whole-archive$convenience $wl--no-whole-archive'\n\t    else\n\t      # Exported symbols can be pulled into shared objects from archives\n\t      _LT_TAGVAR(whole_archive_flag_spec, $1)='$convenience'\n\t    fi\n\t    _LT_TAGVAR(archive_cmds_need_lc, $1)=yes\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)='$RM -r $output_objdir/$realname.d~$MKDIR $output_objdir/$realname.d'\n\t    # -brtl affects multiple linker settings, -berok does not and is overridden later\n\t    compiler_flags_filtered='`func_echo_all \"$compiler_flags \" | $SED -e \"s%-brtl\\\\([[, ]]\\\\)%-berok\\\\1%g\"`'\n\t    if test svr4 != \"$with_aix_soname\"; then\n\t      # This is similar to how AIX traditionally builds its shared\n\t      # libraries. Need -bnortl late, we may have -brtl in LDFLAGS.\n\t      _LT_TAGVAR(archive_expsym_cmds, $1)=\"$_LT_TAGVAR(archive_expsym_cmds, $1)\"'~$CC '$shared_flag_aix' -o $output_objdir/$realname.d/$soname $libobjs $deplibs $wl-bnoentry '$compiler_flags_filtered'$wl-bE:$export_symbols$allow_undefined_flag~$AR $AR_FLAGS $output_objdir/$libname$release.a $output_objdir/$realname.d/$soname'\n\t    fi\n\t    if test aix != \"$with_aix_soname\"; then\n\t      _LT_TAGVAR(archive_expsym_cmds, $1)=\"$_LT_TAGVAR(archive_expsym_cmds, $1)\"'~$CC '$shared_flag_svr4' -o $output_objdir/$realname.d/$shared_archive_member_spec.o $libobjs $deplibs $wl-bnoentry '$compiler_flags_filtered'$wl-bE:$export_symbols$allow_undefined_flag~$STRIP -e $output_objdir/$realname.d/$shared_archive_member_spec.o~( func_echo_all \"#! $soname($shared_archive_member_spec.o)\"; if test shr_64 = \"$shared_archive_member_spec\"; then func_echo_all \"# 64\"; else func_echo_all \"# 32\"; fi; cat $export_symbols ) > $output_objdir/$realname.d/$shared_archive_member_spec.imp~$AR $AR_FLAGS $output_objdir/$soname $output_objdir/$realname.d/$shared_archive_member_spec.o $output_objdir/$realname.d/$shared_archive_member_spec.imp'\n\t    else\n\t      # used by -dlpreopen to get the symbols\n\t      _LT_TAGVAR(archive_expsym_cmds, $1)=\"$_LT_TAGVAR(archive_expsym_cmds, $1)\"'~$MV  $output_objdir/$realname.d/$soname $output_objdir'\n\t    fi\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)=\"$_LT_TAGVAR(archive_expsym_cmds, $1)\"'~$RM -r $output_objdir/$realname.d'\n          fi\n        fi\n        ;;\n\n      beos*)\n\tif $LD --help 2>&1 | $GREP ': supported targets:.* elf' > /dev/null; then\n\t  _LT_TAGVAR(allow_undefined_flag, $1)=unsupported\n\t  # Joseph Beckenbach <jrb3@best.com> says some releases of gcc\n\t  # support --undefined.  This deserves some investigation.  FIXME\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -nostart $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n\telse\n\t  _LT_TAGVAR(ld_shlibs, $1)=no\n\tfi\n\t;;\n\n      chorus*)\n        case $cc_basename in\n          *)\n\t  # FIXME: insert proper C++ library support\n\t  _LT_TAGVAR(ld_shlibs, $1)=no\n\t  ;;\n        esac\n        ;;\n\n      cygwin* | mingw* | pw32* | cegcc*)\n\tcase $GXX,$cc_basename in\n\t,cl* | no,cl*)\n\t  # Native MSVC\n\t  # hardcode_libdir_flag_spec is actually meaningless, as there is\n\t  # no search path for DLLs.\n\t  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)=' '\n\t  _LT_TAGVAR(allow_undefined_flag, $1)=unsupported\n\t  _LT_TAGVAR(always_export_symbols, $1)=yes\n\t  _LT_TAGVAR(file_list_spec, $1)='@'\n\t  # Tell ltmain to make .lib files, not .a files.\n\t  libext=lib\n\t  # Tell ltmain to make .dll files, not .so files.\n\t  shrext_cmds=.dll\n\t  # FIXME: Setting linknames here is a bad hack.\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -o $output_objdir/$soname $libobjs $compiler_flags $deplibs -Wl,-DLL,-IMPLIB:\"$tool_output_objdir$libname.dll.lib\"~linknames='\n\t  _LT_TAGVAR(archive_expsym_cmds, $1)='if _LT_DLL_DEF_P([$export_symbols]); then\n              cp \"$export_symbols\" \"$output_objdir/$soname.def\";\n              echo \"$tool_output_objdir$soname.def\" > \"$output_objdir/$soname.exp\";\n            else\n              $SED -e '\\''s/^/-link -EXPORT:/'\\'' < $export_symbols > $output_objdir/$soname.exp;\n            fi~\n            $CC -o $tool_output_objdir$soname $libobjs $compiler_flags $deplibs \"@$tool_output_objdir$soname.exp\" -Wl,-DLL,-IMPLIB:\"$tool_output_objdir$libname.dll.lib\"~\n            linknames='\n\t  # The linker will not automatically build a static lib if we build a DLL.\n\t  # _LT_TAGVAR(old_archive_from_new_cmds, $1)='true'\n\t  _LT_TAGVAR(enable_shared_with_static_runtimes, $1)=yes\n\t  # Don't use ranlib\n\t  _LT_TAGVAR(old_postinstall_cmds, $1)='chmod 644 $oldlib'\n\t  _LT_TAGVAR(postlink_cmds, $1)='lt_outputfile=\"@OUTPUT@\"~\n            lt_tool_outputfile=\"@TOOL_OUTPUT@\"~\n            case $lt_outputfile in\n              *.exe|*.EXE) ;;\n              *)\n                lt_outputfile=$lt_outputfile.exe\n                lt_tool_outputfile=$lt_tool_outputfile.exe\n                ;;\n            esac~\n            func_to_tool_file \"$lt_outputfile\"~\n            if test : != \"$MANIFEST_TOOL\" && test -f \"$lt_outputfile.manifest\"; then\n              $MANIFEST_TOOL -manifest \"$lt_tool_outputfile.manifest\" -outputresource:\"$lt_tool_outputfile\" || exit 1;\n              $RM \"$lt_outputfile.manifest\";\n            fi'\n\t  ;;\n\t*)\n\t  # g++\n\t  # _LT_TAGVAR(hardcode_libdir_flag_spec, $1) is actually meaningless,\n\t  # as there is no search path for DLLs.\n\t  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n\t  _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl--export-all-symbols'\n\t  _LT_TAGVAR(allow_undefined_flag, $1)=unsupported\n\t  _LT_TAGVAR(always_export_symbols, $1)=no\n\t  _LT_TAGVAR(enable_shared_with_static_runtimes, $1)=yes\n\n\t  if $LD --help 2>&1 | $GREP 'auto-import' > /dev/null; then\n\t    _LT_TAGVAR(archive_cmds, $1)='$CC -shared -nostdlib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags -o $output_objdir/$soname $wl--enable-auto-image-base -Xlinker --out-implib -Xlinker $lib'\n\t    # If the export-symbols file already is a .def file, use it as\n\t    # is; otherwise, prepend EXPORTS...\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)='if _LT_DLL_DEF_P([$export_symbols]); then\n              cp $export_symbols $output_objdir/$soname.def;\n            else\n              echo EXPORTS > $output_objdir/$soname.def;\n              cat $export_symbols >> $output_objdir/$soname.def;\n            fi~\n            $CC -shared -nostdlib $output_objdir/$soname.def $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags -o $output_objdir/$soname $wl--enable-auto-image-base -Xlinker --out-implib -Xlinker $lib'\n\t  else\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t  fi\n\t  ;;\n\tesac\n\t;;\n      darwin* | rhapsody*)\n        _LT_DARWIN_LINKER_FEATURES($1)\n\t;;\n\n      os2*)\n\t_LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n\t_LT_TAGVAR(hardcode_minus_L, $1)=yes\n\t_LT_TAGVAR(allow_undefined_flag, $1)=unsupported\n\tshrext_cmds=.dll\n\t_LT_TAGVAR(archive_cmds, $1)='$ECHO \"LIBRARY ${soname%$shared_ext} INITINSTANCE TERMINSTANCE\" > $output_objdir/$libname.def~\n\t  $ECHO \"DESCRIPTION \\\"$libname\\\"\" >> $output_objdir/$libname.def~\n\t  $ECHO \"DATA MULTIPLE NONSHARED\" >> $output_objdir/$libname.def~\n\t  $ECHO EXPORTS >> $output_objdir/$libname.def~\n\t  emxexp $libobjs | $SED /\"_DLL_InitTerm\"/d >> $output_objdir/$libname.def~\n\t  $CC -Zdll -Zcrtdll -o $output_objdir/$soname $libobjs $deplibs $compiler_flags $output_objdir/$libname.def~\n\t  emximp -o $lib $output_objdir/$libname.def'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='$ECHO \"LIBRARY ${soname%$shared_ext} INITINSTANCE TERMINSTANCE\" > $output_objdir/$libname.def~\n\t  $ECHO \"DESCRIPTION \\\"$libname\\\"\" >> $output_objdir/$libname.def~\n\t  $ECHO \"DATA MULTIPLE NONSHARED\" >> $output_objdir/$libname.def~\n\t  $ECHO EXPORTS >> $output_objdir/$libname.def~\n\t  prefix_cmds=\"$SED\"~\n\t  if test EXPORTS = \"`$SED 1q $export_symbols`\"; then\n\t    prefix_cmds=\"$prefix_cmds -e 1d\";\n\t  fi~\n\t  prefix_cmds=\"$prefix_cmds -e \\\"s/^\\(.*\\)$/_\\1/g\\\"\"~\n\t  cat $export_symbols | $prefix_cmds >> $output_objdir/$libname.def~\n\t  $CC -Zdll -Zcrtdll -o $output_objdir/$soname $libobjs $deplibs $compiler_flags $output_objdir/$libname.def~\n\t  emximp -o $lib $output_objdir/$libname.def'\n\t_LT_TAGVAR(old_archive_From_new_cmds, $1)='emximp -o $output_objdir/${libname}_dll.a $output_objdir/$libname.def'\n\t_LT_TAGVAR(enable_shared_with_static_runtimes, $1)=yes\n\t;;\n\n      dgux*)\n        case $cc_basename in\n          ec++*)\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n          ghcx*)\n\t    # Green Hills C++ Compiler\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n          *)\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n        esac\n        ;;\n\n      freebsd2.*)\n        # C++ shared libraries reported to be fairly broken before\n\t# switch to ELF\n        _LT_TAGVAR(ld_shlibs, $1)=no\n        ;;\n\n      freebsd-elf*)\n        _LT_TAGVAR(archive_cmds_need_lc, $1)=no\n        ;;\n\n      freebsd* | dragonfly*)\n        # FreeBSD 3 and later use GNU C++ and GNU ld with standard ELF\n        # conventions\n        _LT_TAGVAR(ld_shlibs, $1)=yes\n        ;;\n\n      haiku*)\n        _LT_TAGVAR(archive_cmds, $1)='$CC -shared $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n        _LT_TAGVAR(link_all_deplibs, $1)=yes\n        ;;\n\n      hpux9*)\n        _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl+b $wl$libdir'\n        _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n        _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-E'\n        _LT_TAGVAR(hardcode_direct, $1)=yes\n        _LT_TAGVAR(hardcode_minus_L, $1)=yes # Not in the search PATH,\n\t\t\t\t             # but as the default\n\t\t\t\t             # location of the library.\n\n        case $cc_basename in\n          CC*)\n            # FIXME: insert proper C++ library support\n            _LT_TAGVAR(ld_shlibs, $1)=no\n            ;;\n          aCC*)\n            _LT_TAGVAR(archive_cmds, $1)='$RM $output_objdir/$soname~$CC -b $wl+b $wl$install_libdir -o $output_objdir/$soname $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags~test \"x$output_objdir/$soname\" = \"x$lib\" || mv $output_objdir/$soname $lib'\n            # Commands to make compiler produce verbose output that lists\n            # what \"hidden\" libraries, object files and flags are used when\n            # linking a shared library.\n            #\n            # There doesn't appear to be a way to prevent this compiler from\n            # explicitly linking system object files so we need to strip them\n            # from the output so that they don't get included in the library\n            # dependencies.\n            output_verbose_link_cmd='templist=`($CC -b $CFLAGS -v conftest.$objext 2>&1) | $EGREP \" \\-L\"`; list= ; for z in $templist; do case $z in conftest.$objext) list=\"$list $z\";; *.$objext);; *) list=\"$list $z\";;esac; done; func_echo_all \"$list\"'\n            ;;\n          *)\n            if test yes = \"$GXX\"; then\n              _LT_TAGVAR(archive_cmds, $1)='$RM $output_objdir/$soname~$CC -shared -nostdlib $pic_flag $wl+b $wl$install_libdir -o $output_objdir/$soname $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags~test \"x$output_objdir/$soname\" = \"x$lib\" || mv $output_objdir/$soname $lib'\n            else\n              # FIXME: insert proper C++ library support\n              _LT_TAGVAR(ld_shlibs, $1)=no\n            fi\n            ;;\n        esac\n        ;;\n\n      hpux10*|hpux11*)\n        if test no = \"$with_gnu_ld\"; then\n\t  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl+b $wl$libdir'\n\t  _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n\n          case $host_cpu in\n            hppa*64*|ia64*)\n              ;;\n            *)\n\t      _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-E'\n              ;;\n          esac\n        fi\n        case $host_cpu in\n          hppa*64*|ia64*)\n            _LT_TAGVAR(hardcode_direct, $1)=no\n            _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n            ;;\n          *)\n            _LT_TAGVAR(hardcode_direct, $1)=yes\n            _LT_TAGVAR(hardcode_direct_absolute, $1)=yes\n            _LT_TAGVAR(hardcode_minus_L, $1)=yes # Not in the search PATH,\n\t\t\t\t\t         # but as the default\n\t\t\t\t\t         # location of the library.\n            ;;\n        esac\n\n        case $cc_basename in\n          CC*)\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n          aCC*)\n\t    case $host_cpu in\n\t      hppa*64*)\n\t        _LT_TAGVAR(archive_cmds, $1)='$CC -b $wl+h $wl$soname -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags'\n\t        ;;\n\t      ia64*)\n\t        _LT_TAGVAR(archive_cmds, $1)='$CC -b $wl+h $wl$soname $wl+nodefaultrpath -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags'\n\t        ;;\n\t      *)\n\t        _LT_TAGVAR(archive_cmds, $1)='$CC -b $wl+h $wl$soname $wl+b $wl$install_libdir -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags'\n\t        ;;\n\t    esac\n\t    # Commands to make compiler produce verbose output that lists\n\t    # what \"hidden\" libraries, object files and flags are used when\n\t    # linking a shared library.\n\t    #\n\t    # There doesn't appear to be a way to prevent this compiler from\n\t    # explicitly linking system object files so we need to strip them\n\t    # from the output so that they don't get included in the library\n\t    # dependencies.\n\t    output_verbose_link_cmd='templist=`($CC -b $CFLAGS -v conftest.$objext 2>&1) | $GREP \" \\-L\"`; list= ; for z in $templist; do case $z in conftest.$objext) list=\"$list $z\";; *.$objext);; *) list=\"$list $z\";;esac; done; func_echo_all \"$list\"'\n\t    ;;\n          *)\n\t    if test yes = \"$GXX\"; then\n\t      if test no = \"$with_gnu_ld\"; then\n\t        case $host_cpu in\n\t          hppa*64*)\n\t            _LT_TAGVAR(archive_cmds, $1)='$CC -shared -nostdlib -fPIC $wl+h $wl$soname -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags'\n\t            ;;\n\t          ia64*)\n\t            _LT_TAGVAR(archive_cmds, $1)='$CC -shared -nostdlib $pic_flag $wl+h $wl$soname $wl+nodefaultrpath -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags'\n\t            ;;\n\t          *)\n\t            _LT_TAGVAR(archive_cmds, $1)='$CC -shared -nostdlib $pic_flag $wl+h $wl$soname $wl+b $wl$install_libdir -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags'\n\t            ;;\n\t        esac\n\t      fi\n\t    else\n\t      # FIXME: insert proper C++ library support\n\t      _LT_TAGVAR(ld_shlibs, $1)=no\n\t    fi\n\t    ;;\n        esac\n        ;;\n\n      interix[[3-9]]*)\n\t_LT_TAGVAR(hardcode_direct, $1)=no\n\t_LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n\t_LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath,$libdir'\n\t_LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-E'\n\t# Hack: On Interix 3.x, we cannot compile PIC because of a broken gcc.\n\t# Instead, shared libraries are loaded at an image base (0x10000000 by\n\t# default) and relocated if they conflict, which is a slow very memory\n\t# consuming and fragmenting process.  To avoid this, we pick a random,\n\t# 256 KiB-aligned image base between 0x50000000 and 0x6FFC0000 at link\n\t# time.  Moving up from 0x10000000 also allows more sbrk(2) space.\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-h,$soname $wl--image-base,`expr ${RANDOM-$$} % 4096 / 2 \\* 262144 + 1342177280` -o $lib'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='sed \"s|^|_|\" $export_symbols >$output_objdir/$soname.expsym~$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-h,$soname $wl--retain-symbols-file,$output_objdir/$soname.expsym $wl--image-base,`expr ${RANDOM-$$} % 4096 / 2 \\* 262144 + 1342177280` -o $lib'\n\t;;\n      irix5* | irix6*)\n        case $cc_basename in\n          CC*)\n\t    # SGI C++\n\t    _LT_TAGVAR(archive_cmds, $1)='$CC -shared -all -multigot $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags -soname $soname `test -n \"$verstring\" && func_echo_all \"-set_version $verstring\"` -update_registry $output_objdir/so_locations -o $lib'\n\n\t    # Archives containing C++ object files must be created using\n\t    # \"CC -ar\", where \"CC\" is the IRIX C++ compiler.  This is\n\t    # necessary to make sure instantiated templates are included\n\t    # in the archive.\n\t    _LT_TAGVAR(old_archive_cmds, $1)='$CC -ar -WR,-u -o $oldlib $oldobjs'\n\t    ;;\n          *)\n\t    if test yes = \"$GXX\"; then\n\t      if test no = \"$with_gnu_ld\"; then\n\t        _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag -nostdlib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname `test -n \"$verstring\" && func_echo_all \"$wl-set_version $wl$verstring\"` $wl-update_registry $wl$output_objdir/so_locations -o $lib'\n\t      else\n\t        _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag -nostdlib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname `test -n \"$verstring\" && func_echo_all \"$wl-set_version $wl$verstring\"` -o $lib'\n\t      fi\n\t    fi\n\t    _LT_TAGVAR(link_all_deplibs, $1)=yes\n\t    ;;\n        esac\n        _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n        _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n        _LT_TAGVAR(inherit_rpath, $1)=yes\n        ;;\n\n      linux* | k*bsd*-gnu | kopensolaris*-gnu | gnu*)\n        case $cc_basename in\n          KCC*)\n\t    # Kuck and Associates, Inc. (KAI) C++ Compiler\n\n\t    # KCC will only create a shared library if the output file\n\t    # ends with \".so\" (or \".sl\" for HP-UX), so rename the library\n\t    # to its proper name (with version) after linking.\n\t    _LT_TAGVAR(archive_cmds, $1)='tempext=`echo $shared_ext | $SED -e '\\''s/\\([[^()0-9A-Za-z{}]]\\)/\\\\\\\\\\1/g'\\''`; templib=`echo $lib | $SED -e \"s/\\$tempext\\..*/.so/\"`; $CC $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags --soname $soname -o \\$templib; mv \\$templib $lib'\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)='tempext=`echo $shared_ext | $SED -e '\\''s/\\([[^()0-9A-Za-z{}]]\\)/\\\\\\\\\\1/g'\\''`; templib=`echo $lib | $SED -e \"s/\\$tempext\\..*/.so/\"`; $CC $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags --soname $soname -o \\$templib $wl-retain-symbols-file,$export_symbols; mv \\$templib $lib'\n\t    # Commands to make compiler produce verbose output that lists\n\t    # what \"hidden\" libraries, object files and flags are used when\n\t    # linking a shared library.\n\t    #\n\t    # There doesn't appear to be a way to prevent this compiler from\n\t    # explicitly linking system object files so we need to strip them\n\t    # from the output so that they don't get included in the library\n\t    # dependencies.\n\t    output_verbose_link_cmd='templist=`$CC $CFLAGS -v conftest.$objext -o libconftest$shared_ext 2>&1 | $GREP \"ld\"`; rm -f libconftest$shared_ext; list= ; for z in $templist; do case $z in conftest.$objext) list=\"$list $z\";; *.$objext);; *) list=\"$list $z\";;esac; done; func_echo_all \"$list\"'\n\n\t    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath,$libdir'\n\t    _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl--export-dynamic'\n\n\t    # Archives containing C++ object files must be created using\n\t    # \"CC -Bstatic\", where \"CC\" is the KAI C++ compiler.\n\t    _LT_TAGVAR(old_archive_cmds, $1)='$CC -Bstatic -o $oldlib $oldobjs'\n\t    ;;\n\t  icpc* | ecpc* )\n\t    # Intel C++\n\t    with_gnu_ld=yes\n\t    # version 8.0 and above of icpc choke on multiply defined symbols\n\t    # if we add $predep_objects and $postdep_objects, however 7.1 and\n\t    # earlier do not add the objects themselves.\n\t    case `$CC -V 2>&1` in\n\t      *\"Version 7.\"*)\n\t        _LT_TAGVAR(archive_cmds, $1)='$CC -shared $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname -o $lib'\n\t\t_LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname $wl-retain-symbols-file $wl$export_symbols -o $lib'\n\t\t;;\n\t      *)  # Version 8.0 or newer\n\t        tmp_idyn=\n\t        case $host_cpu in\n\t\t  ia64*) tmp_idyn=' -i_dynamic';;\n\t\tesac\n\t        _LT_TAGVAR(archive_cmds, $1)='$CC -shared'\"$tmp_idyn\"' $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n\t\t_LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared'\"$tmp_idyn\"' $libobjs $deplibs $compiler_flags $wl-soname $wl$soname $wl-retain-symbols-file $wl$export_symbols -o $lib'\n\t\t;;\n\t    esac\n\t    _LT_TAGVAR(archive_cmds_need_lc, $1)=no\n\t    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath,$libdir'\n\t    _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl--export-dynamic'\n\t    _LT_TAGVAR(whole_archive_flag_spec, $1)='$wl--whole-archive$convenience $wl--no-whole-archive'\n\t    ;;\n          pgCC* | pgcpp*)\n            # Portland Group C++ compiler\n\t    case `$CC -V` in\n\t    *pgCC\\ [[1-5]].* | *pgcpp\\ [[1-5]].*)\n\t      _LT_TAGVAR(prelink_cmds, $1)='tpldir=Template.dir~\n               rm -rf $tpldir~\n               $CC --prelink_objects --instantiation_dir $tpldir $objs $libobjs $compile_deplibs~\n               compile_command=\"$compile_command `find $tpldir -name \\*.o | sort | $NL2SP`\"'\n\t      _LT_TAGVAR(old_archive_cmds, $1)='tpldir=Template.dir~\n                rm -rf $tpldir~\n                $CC --prelink_objects --instantiation_dir $tpldir $oldobjs$old_deplibs~\n                $AR $AR_FLAGS $oldlib$oldobjs$old_deplibs `find $tpldir -name \\*.o | sort | $NL2SP`~\n                $RANLIB $oldlib'\n\t      _LT_TAGVAR(archive_cmds, $1)='tpldir=Template.dir~\n                rm -rf $tpldir~\n                $CC --prelink_objects --instantiation_dir $tpldir $predep_objects $libobjs $deplibs $convenience $postdep_objects~\n                $CC -shared $pic_flag $predep_objects $libobjs $deplibs `find $tpldir -name \\*.o | sort | $NL2SP` $postdep_objects $compiler_flags $wl-soname $wl$soname -o $lib'\n\t      _LT_TAGVAR(archive_expsym_cmds, $1)='tpldir=Template.dir~\n                rm -rf $tpldir~\n                $CC --prelink_objects --instantiation_dir $tpldir $predep_objects $libobjs $deplibs $convenience $postdep_objects~\n                $CC -shared $pic_flag $predep_objects $libobjs $deplibs `find $tpldir -name \\*.o | sort | $NL2SP` $postdep_objects $compiler_flags $wl-soname $wl$soname $wl-retain-symbols-file $wl$export_symbols -o $lib'\n\t      ;;\n\t    *) # Version 6 and above use weak symbols\n\t      _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname -o $lib'\n\t      _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $pic_flag $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname $wl-retain-symbols-file $wl$export_symbols -o $lib'\n\t      ;;\n\t    esac\n\n\t    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl--rpath $wl$libdir'\n\t    _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl--export-dynamic'\n\t    _LT_TAGVAR(whole_archive_flag_spec, $1)='$wl--whole-archive`for conv in $convenience\\\"\\\"; do test  -n \\\"$conv\\\" && new_convenience=\\\"$new_convenience,$conv\\\"; done; func_echo_all \\\"$new_convenience\\\"` $wl--no-whole-archive'\n            ;;\n\t  cxx*)\n\t    # Compaq C++\n\t    _LT_TAGVAR(archive_cmds, $1)='$CC -shared $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname -o $lib'\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname  -o $lib $wl-retain-symbols-file $wl$export_symbols'\n\n\t    runpath_var=LD_RUN_PATH\n\t    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-rpath $libdir'\n\t    _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n\n\t    # Commands to make compiler produce verbose output that lists\n\t    # what \"hidden\" libraries, object files and flags are used when\n\t    # linking a shared library.\n\t    #\n\t    # There doesn't appear to be a way to prevent this compiler from\n\t    # explicitly linking system object files so we need to strip them\n\t    # from the output so that they don't get included in the library\n\t    # dependencies.\n\t    output_verbose_link_cmd='templist=`$CC -shared $CFLAGS -v conftest.$objext 2>&1 | $GREP \"ld\"`; templist=`func_echo_all \"$templist\" | $SED \"s/\\(^.*ld.*\\)\\( .*ld .*$\\)/\\1/\"`; list= ; for z in $templist; do case $z in conftest.$objext) list=\"$list $z\";; *.$objext);; *) list=\"$list $z\";;esac; done; func_echo_all \"X$list\" | $Xsed'\n\t    ;;\n\t  xl* | mpixl* | bgxl*)\n\t    # IBM XL 8.0 on PPC, with GNU ld\n\t    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n\t    _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl--export-dynamic'\n\t    _LT_TAGVAR(archive_cmds, $1)='$CC -qmkshrobj $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n\t    if test yes = \"$supports_anon_versioning\"; then\n\t      _LT_TAGVAR(archive_expsym_cmds, $1)='echo \"{ global:\" > $output_objdir/$libname.ver~\n                cat $export_symbols | sed -e \"s/\\(.*\\)/\\1;/\" >> $output_objdir/$libname.ver~\n                echo \"local: *; };\" >> $output_objdir/$libname.ver~\n                $CC -qmkshrobj $libobjs $deplibs $compiler_flags $wl-soname $wl$soname $wl-version-script $wl$output_objdir/$libname.ver -o $lib'\n\t    fi\n\t    ;;\n\t  *)\n\t    case `$CC -V 2>&1 | sed 5q` in\n\t    *Sun\\ C*)\n\t      # Sun C++ 5.9\n\t      _LT_TAGVAR(no_undefined_flag, $1)=' -zdefs'\n\t      _LT_TAGVAR(archive_cmds, $1)='$CC -G$allow_undefined_flag -h$soname -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags'\n\t      _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -G$allow_undefined_flag -h$soname -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-retain-symbols-file $wl$export_symbols'\n\t      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-R$libdir'\n\t      _LT_TAGVAR(whole_archive_flag_spec, $1)='$wl--whole-archive`new_convenience=; for conv in $convenience\\\"\\\"; do test -z \\\"$conv\\\" || new_convenience=\\\"$new_convenience,$conv\\\"; done; func_echo_all \\\"$new_convenience\\\"` $wl--no-whole-archive'\n\t      _LT_TAGVAR(compiler_needs_object, $1)=yes\n\n\t      # Not sure whether something based on\n\t      # $CC $CFLAGS -v conftest.$objext -o libconftest$shared_ext 2>&1\n\t      # would be better.\n\t      output_verbose_link_cmd='func_echo_all'\n\n\t      # Archives containing C++ object files must be created using\n\t      # \"CC -xar\", where \"CC\" is the Sun C++ compiler.  This is\n\t      # necessary to make sure instantiated templates are included\n\t      # in the archive.\n\t      _LT_TAGVAR(old_archive_cmds, $1)='$CC -xar -o $oldlib $oldobjs'\n\t      ;;\n\t    esac\n\t    ;;\n\tesac\n\t;;\n\n      lynxos*)\n        # FIXME: insert proper C++ library support\n\t_LT_TAGVAR(ld_shlibs, $1)=no\n\t;;\n\n      m88k*)\n        # FIXME: insert proper C++ library support\n        _LT_TAGVAR(ld_shlibs, $1)=no\n\t;;\n\n      mvs*)\n        case $cc_basename in\n          cxx*)\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n\t  *)\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n\tesac\n\t;;\n\n      netbsd*)\n        if echo __ELF__ | $CC -E - | $GREP __ELF__ >/dev/null; then\n\t  _LT_TAGVAR(archive_cmds, $1)='$LD -Bshareable  -o $lib $predep_objects $libobjs $deplibs $postdep_objects $linker_flags'\n\t  wlarc=\n\t  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-R$libdir'\n\t  _LT_TAGVAR(hardcode_direct, $1)=yes\n\t  _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n\tfi\n\t# Workaround some broken pre-1.5 toolchains\n\toutput_verbose_link_cmd='$CC -shared $CFLAGS -v conftest.$objext 2>&1 | $GREP conftest.$objext | $SED -e \"s:-lgcc -lc -lgcc::\"'\n\t;;\n\n      *nto* | *qnx*)\n        _LT_TAGVAR(ld_shlibs, $1)=yes\n\t;;\n\n      openbsd* | bitrig*)\n\tif test -f /usr/libexec/ld.so; then\n\t  _LT_TAGVAR(hardcode_direct, $1)=yes\n\t  _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n\t  _LT_TAGVAR(hardcode_direct_absolute, $1)=yes\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags -o $lib'\n\t  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath,$libdir'\n\t  if test -z \"`echo __ELF__ | $CC -E - | grep __ELF__`\"; then\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $pic_flag $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-retain-symbols-file,$export_symbols -o $lib'\n\t    _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-E'\n\t    _LT_TAGVAR(whole_archive_flag_spec, $1)=$wlarc'--whole-archive$convenience '$wlarc'--no-whole-archive'\n\t  fi\n\t  output_verbose_link_cmd=func_echo_all\n\telse\n\t  _LT_TAGVAR(ld_shlibs, $1)=no\n\tfi\n\t;;\n\n      osf3* | osf4* | osf5*)\n        case $cc_basename in\n          KCC*)\n\t    # Kuck and Associates, Inc. (KAI) C++ Compiler\n\n\t    # KCC will only create a shared library if the output file\n\t    # ends with \".so\" (or \".sl\" for HP-UX), so rename the library\n\t    # to its proper name (with version) after linking.\n\t    _LT_TAGVAR(archive_cmds, $1)='tempext=`echo $shared_ext | $SED -e '\\''s/\\([[^()0-9A-Za-z{}]]\\)/\\\\\\\\\\1/g'\\''`; templib=`echo \"$lib\" | $SED -e \"s/\\$tempext\\..*/.so/\"`; $CC $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags --soname $soname -o \\$templib; mv \\$templib $lib'\n\n\t    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath,$libdir'\n\t    _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n\n\t    # Archives containing C++ object files must be created using\n\t    # the KAI C++ compiler.\n\t    case $host in\n\t      osf3*) _LT_TAGVAR(old_archive_cmds, $1)='$CC -Bstatic -o $oldlib $oldobjs' ;;\n\t      *) _LT_TAGVAR(old_archive_cmds, $1)='$CC -o $oldlib $oldobjs' ;;\n\t    esac\n\t    ;;\n          RCC*)\n\t    # Rational C++ 2.4.1\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n          cxx*)\n\t    case $host in\n\t      osf3*)\n\t        _LT_TAGVAR(allow_undefined_flag, $1)=' $wl-expect_unresolved $wl\\*'\n\t        _LT_TAGVAR(archive_cmds, $1)='$CC -shared$allow_undefined_flag $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $soname `test -n \"$verstring\" && func_echo_all \"$wl-set_version $verstring\"` -update_registry $output_objdir/so_locations -o $lib'\n\t        _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n\t\t;;\n\t      *)\n\t        _LT_TAGVAR(allow_undefined_flag, $1)=' -expect_unresolved \\*'\n\t        _LT_TAGVAR(archive_cmds, $1)='$CC -shared$allow_undefined_flag $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags -msym -soname $soname `test -n \"$verstring\" && func_echo_all \"-set_version $verstring\"` -update_registry $output_objdir/so_locations -o $lib'\n\t        _LT_TAGVAR(archive_expsym_cmds, $1)='for i in `cat $export_symbols`; do printf \"%s %s\\\\n\" -exported_symbol \"\\$i\" >> $lib.exp; done~\n                  echo \"-hidden\">> $lib.exp~\n                  $CC -shared$allow_undefined_flag $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags -msym -soname $soname $wl-input $wl$lib.exp  `test -n \"$verstring\" && $ECHO \"-set_version $verstring\"` -update_registry $output_objdir/so_locations -o $lib~\n                  $RM $lib.exp'\n\t        _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-rpath $libdir'\n\t\t;;\n\t    esac\n\n\t    _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n\n\t    # Commands to make compiler produce verbose output that lists\n\t    # what \"hidden\" libraries, object files and flags are used when\n\t    # linking a shared library.\n\t    #\n\t    # There doesn't appear to be a way to prevent this compiler from\n\t    # explicitly linking system object files so we need to strip them\n\t    # from the output so that they don't get included in the library\n\t    # dependencies.\n\t    output_verbose_link_cmd='templist=`$CC -shared $CFLAGS -v conftest.$objext 2>&1 | $GREP \"ld\" | $GREP -v \"ld:\"`; templist=`func_echo_all \"$templist\" | $SED \"s/\\(^.*ld.*\\)\\( .*ld.*$\\)/\\1/\"`; list= ; for z in $templist; do case $z in conftest.$objext) list=\"$list $z\";; *.$objext);; *) list=\"$list $z\";;esac; done; func_echo_all \"$list\"'\n\t    ;;\n\t  *)\n\t    if test yes,no = \"$GXX,$with_gnu_ld\"; then\n\t      _LT_TAGVAR(allow_undefined_flag, $1)=' $wl-expect_unresolved $wl\\*'\n\t      case $host in\n\t        osf3*)\n\t          _LT_TAGVAR(archive_cmds, $1)='$CC -shared -nostdlib $allow_undefined_flag $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname `test -n \"$verstring\" && func_echo_all \"$wl-set_version $wl$verstring\"` $wl-update_registry $wl$output_objdir/so_locations -o $lib'\n\t\t  ;;\n\t        *)\n\t          _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag -nostdlib $allow_undefined_flag $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-msym $wl-soname $wl$soname `test -n \"$verstring\" && func_echo_all \"$wl-set_version $wl$verstring\"` $wl-update_registry $wl$output_objdir/so_locations -o $lib'\n\t\t  ;;\n\t      esac\n\n\t      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n\t      _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n\n\t      # Commands to make compiler produce verbose output that lists\n\t      # what \"hidden\" libraries, object files and flags are used when\n\t      # linking a shared library.\n\t      output_verbose_link_cmd='$CC -shared $CFLAGS -v conftest.$objext 2>&1 | $GREP -v \"^Configured with:\" | $GREP \" \\-L\"'\n\n\t    else\n\t      # FIXME: insert proper C++ library support\n\t      _LT_TAGVAR(ld_shlibs, $1)=no\n\t    fi\n\t    ;;\n        esac\n        ;;\n\n      psos*)\n        # FIXME: insert proper C++ library support\n        _LT_TAGVAR(ld_shlibs, $1)=no\n        ;;\n\n      sunos4*)\n        case $cc_basename in\n          CC*)\n\t    # Sun C++ 4.x\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n          lcc*)\n\t    # Lucid\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n          *)\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n        esac\n        ;;\n\n      solaris*)\n        case $cc_basename in\n          CC* | sunCC*)\n\t    # Sun C++ 4.2, 5.x and Centerline C++\n            _LT_TAGVAR(archive_cmds_need_lc,$1)=yes\n\t    _LT_TAGVAR(no_undefined_flag, $1)=' -zdefs'\n\t    _LT_TAGVAR(archive_cmds, $1)='$CC -G$allow_undefined_flag -h$soname -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags'\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)='echo \"{ global:\" > $lib.exp~cat $export_symbols | $SED -e \"s/\\(.*\\)/\\1;/\" >> $lib.exp~echo \"local: *; };\" >> $lib.exp~\n              $CC -G$allow_undefined_flag $wl-M $wl$lib.exp -h$soname -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags~$RM $lib.exp'\n\n\t    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-R$libdir'\n\t    _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n\t    case $host_os in\n\t      solaris2.[[0-5]] | solaris2.[[0-5]].*) ;;\n\t      *)\n\t\t# The compiler driver will combine and reorder linker options,\n\t\t# but understands '-z linker_flag'.\n\t        # Supported since Solaris 2.6 (maybe 2.5.1?)\n\t\t_LT_TAGVAR(whole_archive_flag_spec, $1)='-z allextract$convenience -z defaultextract'\n\t        ;;\n\t    esac\n\t    _LT_TAGVAR(link_all_deplibs, $1)=yes\n\n\t    output_verbose_link_cmd='func_echo_all'\n\n\t    # Archives containing C++ object files must be created using\n\t    # \"CC -xar\", where \"CC\" is the Sun C++ compiler.  This is\n\t    # necessary to make sure instantiated templates are included\n\t    # in the archive.\n\t    _LT_TAGVAR(old_archive_cmds, $1)='$CC -xar -o $oldlib $oldobjs'\n\t    ;;\n          gcx*)\n\t    # Green Hills C++ Compiler\n\t    _LT_TAGVAR(archive_cmds, $1)='$CC -shared $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-h $wl$soname -o $lib'\n\n\t    # The C++ compiler must be used to create the archive.\n\t    _LT_TAGVAR(old_archive_cmds, $1)='$CC $LDFLAGS -archive -o $oldlib $oldobjs'\n\t    ;;\n          *)\n\t    # GNU C++ compiler with Solaris linker\n\t    if test yes,no = \"$GXX,$with_gnu_ld\"; then\n\t      _LT_TAGVAR(no_undefined_flag, $1)=' $wl-z ${wl}defs'\n\t      if $CC --version | $GREP -v '^2\\.7' > /dev/null; then\n\t        _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag -nostdlib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-h $wl$soname -o $lib'\n\t        _LT_TAGVAR(archive_expsym_cmds, $1)='echo \"{ global:\" > $lib.exp~cat $export_symbols | $SED -e \"s/\\(.*\\)/\\1;/\" >> $lib.exp~echo \"local: *; };\" >> $lib.exp~\n                  $CC -shared $pic_flag -nostdlib $wl-M $wl$lib.exp $wl-h $wl$soname -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags~$RM $lib.exp'\n\n\t        # Commands to make compiler produce verbose output that lists\n\t        # what \"hidden\" libraries, object files and flags are used when\n\t        # linking a shared library.\n\t        output_verbose_link_cmd='$CC -shared $CFLAGS -v conftest.$objext 2>&1 | $GREP -v \"^Configured with:\" | $GREP \" \\-L\"'\n\t      else\n\t        # g++ 2.7 appears to require '-G' NOT '-shared' on this\n\t        # platform.\n\t        _LT_TAGVAR(archive_cmds, $1)='$CC -G -nostdlib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-h $wl$soname -o $lib'\n\t        _LT_TAGVAR(archive_expsym_cmds, $1)='echo \"{ global:\" > $lib.exp~cat $export_symbols | $SED -e \"s/\\(.*\\)/\\1;/\" >> $lib.exp~echo \"local: *; };\" >> $lib.exp~\n                  $CC -G -nostdlib $wl-M $wl$lib.exp $wl-h $wl$soname -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags~$RM $lib.exp'\n\n\t        # Commands to make compiler produce verbose output that lists\n\t        # what \"hidden\" libraries, object files and flags are used when\n\t        # linking a shared library.\n\t        output_verbose_link_cmd='$CC -G $CFLAGS -v conftest.$objext 2>&1 | $GREP -v \"^Configured with:\" | $GREP \" \\-L\"'\n\t      fi\n\n\t      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-R $wl$libdir'\n\t      case $host_os in\n\t\tsolaris2.[[0-5]] | solaris2.[[0-5]].*) ;;\n\t\t*)\n\t\t  _LT_TAGVAR(whole_archive_flag_spec, $1)='$wl-z ${wl}allextract$convenience $wl-z ${wl}defaultextract'\n\t\t  ;;\n\t      esac\n\t    fi\n\t    ;;\n        esac\n        ;;\n\n    sysv4*uw2* | sysv5OpenUNIX* | sysv5UnixWare7.[[01]].[[10]]* | unixware7* | sco3.2v5.0.[[024]]*)\n      _LT_TAGVAR(no_undefined_flag, $1)='$wl-z,text'\n      _LT_TAGVAR(archive_cmds_need_lc, $1)=no\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      runpath_var='LD_RUN_PATH'\n\n      case $cc_basename in\n        CC*)\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -G $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t  _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -G $wl-Bexport:$export_symbols $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t  ;;\n\t*)\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -shared $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t  _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $wl-Bexport:$export_symbols $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t  ;;\n      esac\n      ;;\n\n      sysv5* | sco3.2v5* | sco5v6*)\n\t# Note: We CANNOT use -z defs as we might desire, because we do not\n\t# link with -lc, and that would cause any symbols used from libc to\n\t# always be unresolved, which means just about no library would\n\t# ever link correctly.  If we're not using GNU ld we use -z text\n\t# though, which does catch some bad symbols but isn't as heavy-handed\n\t# as -z defs.\n\t_LT_TAGVAR(no_undefined_flag, $1)='$wl-z,text'\n\t_LT_TAGVAR(allow_undefined_flag, $1)='$wl-z,nodefs'\n\t_LT_TAGVAR(archive_cmds_need_lc, $1)=no\n\t_LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n\t_LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-R,$libdir'\n\t_LT_TAGVAR(hardcode_libdir_separator, $1)=':'\n\t_LT_TAGVAR(link_all_deplibs, $1)=yes\n\t_LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-Bexport'\n\trunpath_var='LD_RUN_PATH'\n\n\tcase $cc_basename in\n          CC*)\n\t    _LT_TAGVAR(archive_cmds, $1)='$CC -G $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -G $wl-Bexport:$export_symbols $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t    _LT_TAGVAR(old_archive_cmds, $1)='$CC -Tprelink_objects $oldobjs~\n              '\"$_LT_TAGVAR(old_archive_cmds, $1)\"\n\t    _LT_TAGVAR(reload_cmds, $1)='$CC -Tprelink_objects $reload_objs~\n              '\"$_LT_TAGVAR(reload_cmds, $1)\"\n\t    ;;\n\t  *)\n\t    _LT_TAGVAR(archive_cmds, $1)='$CC -shared $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $wl-Bexport:$export_symbols $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t    ;;\n\tesac\n      ;;\n\n      tandem*)\n        case $cc_basename in\n          NCC*)\n\t    # NonStop-UX NCC 3.20\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n          *)\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n        esac\n        ;;\n\n      vxworks*)\n        # FIXME: insert proper C++ library support\n        _LT_TAGVAR(ld_shlibs, $1)=no\n        ;;\n\n      *)\n        # FIXME: insert proper C++ library support\n        _LT_TAGVAR(ld_shlibs, $1)=no\n        ;;\n    esac\n\n    AC_MSG_RESULT([$_LT_TAGVAR(ld_shlibs, $1)])\n    test no = \"$_LT_TAGVAR(ld_shlibs, $1)\" && can_build_shared=no\n\n    _LT_TAGVAR(GCC, $1)=$GXX\n    _LT_TAGVAR(LD, $1)=$LD\n\n    ## CAVEAT EMPTOR:\n    ## There is no encapsulation within the following macros, do not change\n    ## the running order or otherwise move them around unless you know exactly\n    ## what you are doing...\n    _LT_SYS_HIDDEN_LIBDEPS($1)\n    _LT_COMPILER_PIC($1)\n    _LT_COMPILER_C_O($1)\n    _LT_COMPILER_FILE_LOCKS($1)\n    _LT_LINKER_SHLIBS($1)\n    _LT_SYS_DYNAMIC_LINKER($1)\n    _LT_LINKER_HARDCODE_LIBPATH($1)\n\n    _LT_CONFIG($1)\n  fi # test -n \"$compiler\"\n\n  CC=$lt_save_CC\n  CFLAGS=$lt_save_CFLAGS\n  LDCXX=$LD\n  LD=$lt_save_LD\n  GCC=$lt_save_GCC\n  with_gnu_ld=$lt_save_with_gnu_ld\n  lt_cv_path_LDCXX=$lt_cv_path_LD\n  lt_cv_path_LD=$lt_save_path_LD\n  lt_cv_prog_gnu_ldcxx=$lt_cv_prog_gnu_ld\n  lt_cv_prog_gnu_ld=$lt_save_with_gnu_ld\nfi # test yes != \"$_lt_caught_CXX_error\"\n\nAC_LANG_POP\n])# _LT_LANG_CXX_CONFIG\n\n\n# _LT_FUNC_STRIPNAME_CNF\n# ----------------------\n# func_stripname_cnf prefix suffix name\n# strip PREFIX and SUFFIX off of NAME.\n# PREFIX and SUFFIX must not contain globbing or regex special\n# characters, hashes, percent signs, but SUFFIX may contain a leading\n# dot (in which case that matches only a dot).\n#\n# This function is identical to the (non-XSI) version of func_stripname,\n# except this one can be used by m4 code that may be executed by configure,\n# rather than the libtool script.\nm4_defun([_LT_FUNC_STRIPNAME_CNF],[dnl\nAC_REQUIRE([_LT_DECL_SED])\nAC_REQUIRE([_LT_PROG_ECHO_BACKSLASH])\nfunc_stripname_cnf ()\n{\n  case @S|@2 in\n  .*) func_stripname_result=`$ECHO \"@S|@3\" | $SED \"s%^@S|@1%%; s%\\\\\\\\@S|@2\\$%%\"`;;\n  *)  func_stripname_result=`$ECHO \"@S|@3\" | $SED \"s%^@S|@1%%; s%@S|@2\\$%%\"`;;\n  esac\n} # func_stripname_cnf\n])# _LT_FUNC_STRIPNAME_CNF\n\n\n# _LT_SYS_HIDDEN_LIBDEPS([TAGNAME])\n# ---------------------------------\n# Figure out \"hidden\" library dependencies from verbose\n# compiler output when linking a shared library.\n# Parse the compiler output and extract the necessary\n# objects, libraries and library flags.\nm4_defun([_LT_SYS_HIDDEN_LIBDEPS],\n[m4_require([_LT_FILEUTILS_DEFAULTS])dnl\nAC_REQUIRE([_LT_FUNC_STRIPNAME_CNF])dnl\n# Dependencies to place before and after the object being linked:\n_LT_TAGVAR(predep_objects, $1)=\n_LT_TAGVAR(postdep_objects, $1)=\n_LT_TAGVAR(predeps, $1)=\n_LT_TAGVAR(postdeps, $1)=\n_LT_TAGVAR(compiler_lib_search_path, $1)=\n\ndnl we can't use the lt_simple_compile_test_code here,\ndnl because it contains code intended for an executable,\ndnl not a library.  It's possible we should let each\ndnl tag define a new lt_????_link_test_code variable,\ndnl but it's only used here...\nm4_if([$1], [], [cat > conftest.$ac_ext <<_LT_EOF\nint a;\nvoid foo (void) { a = 0; }\n_LT_EOF\n], [$1], [CXX], [cat > conftest.$ac_ext <<_LT_EOF\nclass Foo\n{\npublic:\n  Foo (void) { a = 0; }\nprivate:\n  int a;\n};\n_LT_EOF\n], [$1], [F77], [cat > conftest.$ac_ext <<_LT_EOF\n      subroutine foo\n      implicit none\n      integer*4 a\n      a=0\n      return\n      end\n_LT_EOF\n], [$1], [FC], [cat > conftest.$ac_ext <<_LT_EOF\n      subroutine foo\n      implicit none\n      integer a\n      a=0\n      return\n      end\n_LT_EOF\n], [$1], [GCJ], [cat > conftest.$ac_ext <<_LT_EOF\npublic class foo {\n  private int a;\n  public void bar (void) {\n    a = 0;\n  }\n};\n_LT_EOF\n], [$1], [GO], [cat > conftest.$ac_ext <<_LT_EOF\npackage foo\nfunc foo() {\n}\n_LT_EOF\n])\n\n_lt_libdeps_save_CFLAGS=$CFLAGS\ncase \"$CC $CFLAGS \" in #(\n*\\ -flto*\\ *) CFLAGS=\"$CFLAGS -fno-lto\" ;;\n*\\ -fwhopr*\\ *) CFLAGS=\"$CFLAGS -fno-whopr\" ;;\n*\\ -fuse-linker-plugin*\\ *) CFLAGS=\"$CFLAGS -fno-use-linker-plugin\" ;;\nesac\n\ndnl Parse the compiler output and extract the necessary\ndnl objects, libraries and library flags.\nif AC_TRY_EVAL(ac_compile); then\n  # Parse the compiler output and extract the necessary\n  # objects, libraries and library flags.\n\n  # Sentinel used to keep track of whether or not we are before\n  # the conftest object file.\n  pre_test_object_deps_done=no\n\n  for p in `eval \"$output_verbose_link_cmd\"`; do\n    case $prev$p in\n\n    -L* | -R* | -l*)\n       # Some compilers place space between \"-{L,R}\" and the path.\n       # Remove the space.\n       if test x-L = \"$p\" ||\n          test x-R = \"$p\"; then\n\t prev=$p\n\t continue\n       fi\n\n       # Expand the sysroot to ease extracting the directories later.\n       if test -z \"$prev\"; then\n         case $p in\n         -L*) func_stripname_cnf '-L' '' \"$p\"; prev=-L; p=$func_stripname_result ;;\n         -R*) func_stripname_cnf '-R' '' \"$p\"; prev=-R; p=$func_stripname_result ;;\n         -l*) func_stripname_cnf '-l' '' \"$p\"; prev=-l; p=$func_stripname_result ;;\n         esac\n       fi\n       case $p in\n       =*) func_stripname_cnf '=' '' \"$p\"; p=$lt_sysroot$func_stripname_result ;;\n       esac\n       if test no = \"$pre_test_object_deps_done\"; then\n\t case $prev in\n\t -L | -R)\n\t   # Internal compiler library paths should come after those\n\t   # provided the user.  The postdeps already come after the\n\t   # user supplied libs so there is no need to process them.\n\t   if test -z \"$_LT_TAGVAR(compiler_lib_search_path, $1)\"; then\n\t     _LT_TAGVAR(compiler_lib_search_path, $1)=$prev$p\n\t   else\n\t     _LT_TAGVAR(compiler_lib_search_path, $1)=\"${_LT_TAGVAR(compiler_lib_search_path, $1)} $prev$p\"\n\t   fi\n\t   ;;\n\t # The \"-l\" case would never come before the object being\n\t # linked, so don't bother handling this case.\n\t esac\n       else\n\t if test -z \"$_LT_TAGVAR(postdeps, $1)\"; then\n\t   _LT_TAGVAR(postdeps, $1)=$prev$p\n\t else\n\t   _LT_TAGVAR(postdeps, $1)=\"${_LT_TAGVAR(postdeps, $1)} $prev$p\"\n\t fi\n       fi\n       prev=\n       ;;\n\n    *.lto.$objext) ;; # Ignore GCC LTO objects\n    *.$objext)\n       # This assumes that the test object file only shows up\n       # once in the compiler output.\n       if test \"$p\" = \"conftest.$objext\"; then\n\t pre_test_object_deps_done=yes\n\t continue\n       fi\n\n       if test no = \"$pre_test_object_deps_done\"; then\n\t if test -z \"$_LT_TAGVAR(predep_objects, $1)\"; then\n\t   _LT_TAGVAR(predep_objects, $1)=$p\n\t else\n\t   _LT_TAGVAR(predep_objects, $1)=\"$_LT_TAGVAR(predep_objects, $1) $p\"\n\t fi\n       else\n\t if test -z \"$_LT_TAGVAR(postdep_objects, $1)\"; then\n\t   _LT_TAGVAR(postdep_objects, $1)=$p\n\t else\n\t   _LT_TAGVAR(postdep_objects, $1)=\"$_LT_TAGVAR(postdep_objects, $1) $p\"\n\t fi\n       fi\n       ;;\n\n    *) ;; # Ignore the rest.\n\n    esac\n  done\n\n  # Clean up.\n  rm -f a.out a.exe\nelse\n  echo \"libtool.m4: error: problem compiling $1 test program\"\nfi\n\n$RM -f confest.$objext\nCFLAGS=$_lt_libdeps_save_CFLAGS\n\n# PORTME: override above test on systems where it is broken\nm4_if([$1], [CXX],\n[case $host_os in\ninterix[[3-9]]*)\n  # Interix 3.5 installs completely hosed .la files for C++, so rather than\n  # hack all around it, let's just trust \"g++\" to DTRT.\n  _LT_TAGVAR(predep_objects,$1)=\n  _LT_TAGVAR(postdep_objects,$1)=\n  _LT_TAGVAR(postdeps,$1)=\n  ;;\nesac\n])\n\ncase \" $_LT_TAGVAR(postdeps, $1) \" in\n*\" -lc \"*) _LT_TAGVAR(archive_cmds_need_lc, $1)=no ;;\nesac\n _LT_TAGVAR(compiler_lib_search_dirs, $1)=\nif test -n \"${_LT_TAGVAR(compiler_lib_search_path, $1)}\"; then\n _LT_TAGVAR(compiler_lib_search_dirs, $1)=`echo \" ${_LT_TAGVAR(compiler_lib_search_path, $1)}\" | $SED -e 's! -L! !g' -e 's!^ !!'`\nfi\n_LT_TAGDECL([], [compiler_lib_search_dirs], [1],\n    [The directories searched by this compiler when creating a shared library])\n_LT_TAGDECL([], [predep_objects], [1],\n    [Dependencies to place before and after the objects being linked to\n    create a shared library])\n_LT_TAGDECL([], [postdep_objects], [1])\n_LT_TAGDECL([], [predeps], [1])\n_LT_TAGDECL([], [postdeps], [1])\n_LT_TAGDECL([], [compiler_lib_search_path], [1],\n    [The library search path used internally by the compiler when linking\n    a shared library])\n])# _LT_SYS_HIDDEN_LIBDEPS\n\n\n# _LT_LANG_F77_CONFIG([TAG])\n# --------------------------\n# Ensure that the configuration variables for a Fortran 77 compiler are\n# suitably defined.  These variables are subsequently used by _LT_CONFIG\n# to write the compiler configuration to 'libtool'.\nm4_defun([_LT_LANG_F77_CONFIG],\n[AC_LANG_PUSH(Fortran 77)\nif test -z \"$F77\" || test no = \"$F77\"; then\n  _lt_disable_F77=yes\nfi\n\n_LT_TAGVAR(archive_cmds_need_lc, $1)=no\n_LT_TAGVAR(allow_undefined_flag, $1)=\n_LT_TAGVAR(always_export_symbols, $1)=no\n_LT_TAGVAR(archive_expsym_cmds, $1)=\n_LT_TAGVAR(export_dynamic_flag_spec, $1)=\n_LT_TAGVAR(hardcode_direct, $1)=no\n_LT_TAGVAR(hardcode_direct_absolute, $1)=no\n_LT_TAGVAR(hardcode_libdir_flag_spec, $1)=\n_LT_TAGVAR(hardcode_libdir_separator, $1)=\n_LT_TAGVAR(hardcode_minus_L, $1)=no\n_LT_TAGVAR(hardcode_automatic, $1)=no\n_LT_TAGVAR(inherit_rpath, $1)=no\n_LT_TAGVAR(module_cmds, $1)=\n_LT_TAGVAR(module_expsym_cmds, $1)=\n_LT_TAGVAR(link_all_deplibs, $1)=unknown\n_LT_TAGVAR(old_archive_cmds, $1)=$old_archive_cmds\n_LT_TAGVAR(reload_flag, $1)=$reload_flag\n_LT_TAGVAR(reload_cmds, $1)=$reload_cmds\n_LT_TAGVAR(no_undefined_flag, $1)=\n_LT_TAGVAR(whole_archive_flag_spec, $1)=\n_LT_TAGVAR(enable_shared_with_static_runtimes, $1)=no\n\n# Source file extension for f77 test sources.\nac_ext=f\n\n# Object file extension for compiled f77 test sources.\nobjext=o\n_LT_TAGVAR(objext, $1)=$objext\n\n# No sense in running all these tests if we already determined that\n# the F77 compiler isn't working.  Some variables (like enable_shared)\n# are currently assumed to apply to all compilers on this platform,\n# and will be corrupted by setting them based on a non-working compiler.\nif test yes != \"$_lt_disable_F77\"; then\n  # Code to be used in simple compile tests\n  lt_simple_compile_test_code=\"\\\n      subroutine t\n      return\n      end\n\"\n\n  # Code to be used in simple link tests\n  lt_simple_link_test_code=\"\\\n      program t\n      end\n\"\n\n  # ltmain only uses $CC for tagged configurations so make sure $CC is set.\n  _LT_TAG_COMPILER\n\n  # save warnings/boilerplate of simple test code\n  _LT_COMPILER_BOILERPLATE\n  _LT_LINKER_BOILERPLATE\n\n  # Allow CC to be a program name with arguments.\n  lt_save_CC=$CC\n  lt_save_GCC=$GCC\n  lt_save_CFLAGS=$CFLAGS\n  CC=${F77-\"f77\"}\n  CFLAGS=$FFLAGS\n  compiler=$CC\n  _LT_TAGVAR(compiler, $1)=$CC\n  _LT_CC_BASENAME([$compiler])\n  GCC=$G77\n  if test -n \"$compiler\"; then\n    AC_MSG_CHECKING([if libtool supports shared libraries])\n    AC_MSG_RESULT([$can_build_shared])\n\n    AC_MSG_CHECKING([whether to build shared libraries])\n    test no = \"$can_build_shared\" && enable_shared=no\n\n    # On AIX, shared libraries and static libraries use the same namespace, and\n    # are all built from PIC.\n    case $host_os in\n      aix3*)\n        test yes = \"$enable_shared\" && enable_static=no\n        if test -n \"$RANLIB\"; then\n          archive_cmds=\"$archive_cmds~\\$RANLIB \\$lib\"\n          postinstall_cmds='$RANLIB $lib'\n        fi\n        ;;\n      aix[[4-9]]*)\n\tif test ia64 != \"$host_cpu\"; then\n\t  case $enable_shared,$with_aix_soname,$aix_use_runtimelinking in\n\t  yes,aix,yes) ;;\t\t# shared object as lib.so file only\n\t  yes,svr4,*) ;;\t\t# shared object as lib.so archive member only\n\t  yes,*) enable_static=no ;;\t# shared object in lib.a archive as well\n\t  esac\n\tfi\n        ;;\n    esac\n    AC_MSG_RESULT([$enable_shared])\n\n    AC_MSG_CHECKING([whether to build static libraries])\n    # Make sure either enable_shared or enable_static is yes.\n    test yes = \"$enable_shared\" || enable_static=yes\n    AC_MSG_RESULT([$enable_static])\n\n    _LT_TAGVAR(GCC, $1)=$G77\n    _LT_TAGVAR(LD, $1)=$LD\n\n    ## CAVEAT EMPTOR:\n    ## There is no encapsulation within the following macros, do not change\n    ## the running order or otherwise move them around unless you know exactly\n    ## what you are doing...\n    _LT_COMPILER_PIC($1)\n    _LT_COMPILER_C_O($1)\n    _LT_COMPILER_FILE_LOCKS($1)\n    _LT_LINKER_SHLIBS($1)\n    _LT_SYS_DYNAMIC_LINKER($1)\n    _LT_LINKER_HARDCODE_LIBPATH($1)\n\n    _LT_CONFIG($1)\n  fi # test -n \"$compiler\"\n\n  GCC=$lt_save_GCC\n  CC=$lt_save_CC\n  CFLAGS=$lt_save_CFLAGS\nfi # test yes != \"$_lt_disable_F77\"\n\nAC_LANG_POP\n])# _LT_LANG_F77_CONFIG\n\n\n# _LT_LANG_FC_CONFIG([TAG])\n# -------------------------\n# Ensure that the configuration variables for a Fortran compiler are\n# suitably defined.  These variables are subsequently used by _LT_CONFIG\n# to write the compiler configuration to 'libtool'.\nm4_defun([_LT_LANG_FC_CONFIG],\n[AC_LANG_PUSH(Fortran)\n\nif test -z \"$FC\" || test no = \"$FC\"; then\n  _lt_disable_FC=yes\nfi\n\n_LT_TAGVAR(archive_cmds_need_lc, $1)=no\n_LT_TAGVAR(allow_undefined_flag, $1)=\n_LT_TAGVAR(always_export_symbols, $1)=no\n_LT_TAGVAR(archive_expsym_cmds, $1)=\n_LT_TAGVAR(export_dynamic_flag_spec, $1)=\n_LT_TAGVAR(hardcode_direct, $1)=no\n_LT_TAGVAR(hardcode_direct_absolute, $1)=no\n_LT_TAGVAR(hardcode_libdir_flag_spec, $1)=\n_LT_TAGVAR(hardcode_libdir_separator, $1)=\n_LT_TAGVAR(hardcode_minus_L, $1)=no\n_LT_TAGVAR(hardcode_automatic, $1)=no\n_LT_TAGVAR(inherit_rpath, $1)=no\n_LT_TAGVAR(module_cmds, $1)=\n_LT_TAGVAR(module_expsym_cmds, $1)=\n_LT_TAGVAR(link_all_deplibs, $1)=unknown\n_LT_TAGVAR(old_archive_cmds, $1)=$old_archive_cmds\n_LT_TAGVAR(reload_flag, $1)=$reload_flag\n_LT_TAGVAR(reload_cmds, $1)=$reload_cmds\n_LT_TAGVAR(no_undefined_flag, $1)=\n_LT_TAGVAR(whole_archive_flag_spec, $1)=\n_LT_TAGVAR(enable_shared_with_static_runtimes, $1)=no\n\n# Source file extension for fc test sources.\nac_ext=${ac_fc_srcext-f}\n\n# Object file extension for compiled fc test sources.\nobjext=o\n_LT_TAGVAR(objext, $1)=$objext\n\n# No sense in running all these tests if we already determined that\n# the FC compiler isn't working.  Some variables (like enable_shared)\n# are currently assumed to apply to all compilers on this platform,\n# and will be corrupted by setting them based on a non-working compiler.\nif test yes != \"$_lt_disable_FC\"; then\n  # Code to be used in simple compile tests\n  lt_simple_compile_test_code=\"\\\n      subroutine t\n      return\n      end\n\"\n\n  # Code to be used in simple link tests\n  lt_simple_link_test_code=\"\\\n      program t\n      end\n\"\n\n  # ltmain only uses $CC for tagged configurations so make sure $CC is set.\n  _LT_TAG_COMPILER\n\n  # save warnings/boilerplate of simple test code\n  _LT_COMPILER_BOILERPLATE\n  _LT_LINKER_BOILERPLATE\n\n  # Allow CC to be a program name with arguments.\n  lt_save_CC=$CC\n  lt_save_GCC=$GCC\n  lt_save_CFLAGS=$CFLAGS\n  CC=${FC-\"f95\"}\n  CFLAGS=$FCFLAGS\n  compiler=$CC\n  GCC=$ac_cv_fc_compiler_gnu\n\n  _LT_TAGVAR(compiler, $1)=$CC\n  _LT_CC_BASENAME([$compiler])\n\n  if test -n \"$compiler\"; then\n    AC_MSG_CHECKING([if libtool supports shared libraries])\n    AC_MSG_RESULT([$can_build_shared])\n\n    AC_MSG_CHECKING([whether to build shared libraries])\n    test no = \"$can_build_shared\" && enable_shared=no\n\n    # On AIX, shared libraries and static libraries use the same namespace, and\n    # are all built from PIC.\n    case $host_os in\n      aix3*)\n        test yes = \"$enable_shared\" && enable_static=no\n        if test -n \"$RANLIB\"; then\n          archive_cmds=\"$archive_cmds~\\$RANLIB \\$lib\"\n          postinstall_cmds='$RANLIB $lib'\n        fi\n        ;;\n      aix[[4-9]]*)\n\tif test ia64 != \"$host_cpu\"; then\n\t  case $enable_shared,$with_aix_soname,$aix_use_runtimelinking in\n\t  yes,aix,yes) ;;\t\t# shared object as lib.so file only\n\t  yes,svr4,*) ;;\t\t# shared object as lib.so archive member only\n\t  yes,*) enable_static=no ;;\t# shared object in lib.a archive as well\n\t  esac\n\tfi\n        ;;\n    esac\n    AC_MSG_RESULT([$enable_shared])\n\n    AC_MSG_CHECKING([whether to build static libraries])\n    # Make sure either enable_shared or enable_static is yes.\n    test yes = \"$enable_shared\" || enable_static=yes\n    AC_MSG_RESULT([$enable_static])\n\n    _LT_TAGVAR(GCC, $1)=$ac_cv_fc_compiler_gnu\n    _LT_TAGVAR(LD, $1)=$LD\n\n    ## CAVEAT EMPTOR:\n    ## There is no encapsulation within the following macros, do not change\n    ## the running order or otherwise move them around unless you know exactly\n    ## what you are doing...\n    _LT_SYS_HIDDEN_LIBDEPS($1)\n    _LT_COMPILER_PIC($1)\n    _LT_COMPILER_C_O($1)\n    _LT_COMPILER_FILE_LOCKS($1)\n    _LT_LINKER_SHLIBS($1)\n    _LT_SYS_DYNAMIC_LINKER($1)\n    _LT_LINKER_HARDCODE_LIBPATH($1)\n\n    _LT_CONFIG($1)\n  fi # test -n \"$compiler\"\n\n  GCC=$lt_save_GCC\n  CC=$lt_save_CC\n  CFLAGS=$lt_save_CFLAGS\nfi # test yes != \"$_lt_disable_FC\"\n\nAC_LANG_POP\n])# _LT_LANG_FC_CONFIG\n\n\n# _LT_LANG_GCJ_CONFIG([TAG])\n# --------------------------\n# Ensure that the configuration variables for the GNU Java Compiler compiler\n# are suitably defined.  These variables are subsequently used by _LT_CONFIG\n# to write the compiler configuration to 'libtool'.\nm4_defun([_LT_LANG_GCJ_CONFIG],\n[AC_REQUIRE([LT_PROG_GCJ])dnl\nAC_LANG_SAVE\n\n# Source file extension for Java test sources.\nac_ext=java\n\n# Object file extension for compiled Java test sources.\nobjext=o\n_LT_TAGVAR(objext, $1)=$objext\n\n# Code to be used in simple compile tests\nlt_simple_compile_test_code=\"class foo {}\"\n\n# Code to be used in simple link tests\nlt_simple_link_test_code='public class conftest { public static void main(String[[]] argv) {}; }'\n\n# ltmain only uses $CC for tagged configurations so make sure $CC is set.\n_LT_TAG_COMPILER\n\n# save warnings/boilerplate of simple test code\n_LT_COMPILER_BOILERPLATE\n_LT_LINKER_BOILERPLATE\n\n# Allow CC to be a program name with arguments.\nlt_save_CC=$CC\nlt_save_CFLAGS=$CFLAGS\nlt_save_GCC=$GCC\nGCC=yes\nCC=${GCJ-\"gcj\"}\nCFLAGS=$GCJFLAGS\ncompiler=$CC\n_LT_TAGVAR(compiler, $1)=$CC\n_LT_TAGVAR(LD, $1)=$LD\n_LT_CC_BASENAME([$compiler])\n\n# GCJ did not exist at the time GCC didn't implicitly link libc in.\n_LT_TAGVAR(archive_cmds_need_lc, $1)=no\n\n_LT_TAGVAR(old_archive_cmds, $1)=$old_archive_cmds\n_LT_TAGVAR(reload_flag, $1)=$reload_flag\n_LT_TAGVAR(reload_cmds, $1)=$reload_cmds\n\n## CAVEAT EMPTOR:\n## There is no encapsulation within the following macros, do not change\n## the running order or otherwise move them around unless you know exactly\n## what you are doing...\nif test -n \"$compiler\"; then\n  _LT_COMPILER_NO_RTTI($1)\n  _LT_COMPILER_PIC($1)\n  _LT_COMPILER_C_O($1)\n  _LT_COMPILER_FILE_LOCKS($1)\n  _LT_LINKER_SHLIBS($1)\n  _LT_LINKER_HARDCODE_LIBPATH($1)\n\n  _LT_CONFIG($1)\nfi\n\nAC_LANG_RESTORE\n\nGCC=$lt_save_GCC\nCC=$lt_save_CC\nCFLAGS=$lt_save_CFLAGS\n])# _LT_LANG_GCJ_CONFIG\n\n\n# _LT_LANG_GO_CONFIG([TAG])\n# --------------------------\n# Ensure that the configuration variables for the GNU Go compiler\n# are suitably defined.  These variables are subsequently used by _LT_CONFIG\n# to write the compiler configuration to 'libtool'.\nm4_defun([_LT_LANG_GO_CONFIG],\n[AC_REQUIRE([LT_PROG_GO])dnl\nAC_LANG_SAVE\n\n# Source file extension for Go test sources.\nac_ext=go\n\n# Object file extension for compiled Go test sources.\nobjext=o\n_LT_TAGVAR(objext, $1)=$objext\n\n# Code to be used in simple compile tests\nlt_simple_compile_test_code=\"package main; func main() { }\"\n\n# Code to be used in simple link tests\nlt_simple_link_test_code='package main; func main() { }'\n\n# ltmain only uses $CC for tagged configurations so make sure $CC is set.\n_LT_TAG_COMPILER\n\n# save warnings/boilerplate of simple test code\n_LT_COMPILER_BOILERPLATE\n_LT_LINKER_BOILERPLATE\n\n# Allow CC to be a program name with arguments.\nlt_save_CC=$CC\nlt_save_CFLAGS=$CFLAGS\nlt_save_GCC=$GCC\nGCC=yes\nCC=${GOC-\"gccgo\"}\nCFLAGS=$GOFLAGS\ncompiler=$CC\n_LT_TAGVAR(compiler, $1)=$CC\n_LT_TAGVAR(LD, $1)=$LD\n_LT_CC_BASENAME([$compiler])\n\n# Go did not exist at the time GCC didn't implicitly link libc in.\n_LT_TAGVAR(archive_cmds_need_lc, $1)=no\n\n_LT_TAGVAR(old_archive_cmds, $1)=$old_archive_cmds\n_LT_TAGVAR(reload_flag, $1)=$reload_flag\n_LT_TAGVAR(reload_cmds, $1)=$reload_cmds\n\n## CAVEAT EMPTOR:\n## There is no encapsulation within the following macros, do not change\n## the running order or otherwise move them around unless you know exactly\n## what you are doing...\nif test -n \"$compiler\"; then\n  _LT_COMPILER_NO_RTTI($1)\n  _LT_COMPILER_PIC($1)\n  _LT_COMPILER_C_O($1)\n  _LT_COMPILER_FILE_LOCKS($1)\n  _LT_LINKER_SHLIBS($1)\n  _LT_LINKER_HARDCODE_LIBPATH($1)\n\n  _LT_CONFIG($1)\nfi\n\nAC_LANG_RESTORE\n\nGCC=$lt_save_GCC\nCC=$lt_save_CC\nCFLAGS=$lt_save_CFLAGS\n])# _LT_LANG_GO_CONFIG\n\n\n# _LT_LANG_RC_CONFIG([TAG])\n# -------------------------\n# Ensure that the configuration variables for the Windows resource compiler\n# are suitably defined.  These variables are subsequently used by _LT_CONFIG\n# to write the compiler configuration to 'libtool'.\nm4_defun([_LT_LANG_RC_CONFIG],\n[AC_REQUIRE([LT_PROG_RC])dnl\nAC_LANG_SAVE\n\n# Source file extension for RC test sources.\nac_ext=rc\n\n# Object file extension for compiled RC test sources.\nobjext=o\n_LT_TAGVAR(objext, $1)=$objext\n\n# Code to be used in simple compile tests\nlt_simple_compile_test_code='sample MENU { MENUITEM \"&Soup\", 100, CHECKED }'\n\n# Code to be used in simple link tests\nlt_simple_link_test_code=$lt_simple_compile_test_code\n\n# ltmain only uses $CC for tagged configurations so make sure $CC is set.\n_LT_TAG_COMPILER\n\n# save warnings/boilerplate of simple test code\n_LT_COMPILER_BOILERPLATE\n_LT_LINKER_BOILERPLATE\n\n# Allow CC to be a program name with arguments.\nlt_save_CC=$CC\nlt_save_CFLAGS=$CFLAGS\nlt_save_GCC=$GCC\nGCC=\nCC=${RC-\"windres\"}\nCFLAGS=\ncompiler=$CC\n_LT_TAGVAR(compiler, $1)=$CC\n_LT_CC_BASENAME([$compiler])\n_LT_TAGVAR(lt_cv_prog_compiler_c_o, $1)=yes\n\nif test -n \"$compiler\"; then\n  :\n  _LT_CONFIG($1)\nfi\n\nGCC=$lt_save_GCC\nAC_LANG_RESTORE\nCC=$lt_save_CC\nCFLAGS=$lt_save_CFLAGS\n])# _LT_LANG_RC_CONFIG\n\n\n# LT_PROG_GCJ\n# -----------\nAC_DEFUN([LT_PROG_GCJ],\n[m4_ifdef([AC_PROG_GCJ], [AC_PROG_GCJ],\n  [m4_ifdef([A][M_PROG_GCJ], [A][M_PROG_GCJ],\n    [AC_CHECK_TOOL(GCJ, gcj,)\n      test set = \"${GCJFLAGS+set}\" || GCJFLAGS=\"-g -O2\"\n      AC_SUBST(GCJFLAGS)])])[]dnl\n])\n\n# Old name:\nAU_ALIAS([LT_AC_PROG_GCJ], [LT_PROG_GCJ])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([LT_AC_PROG_GCJ], [])\n\n\n# LT_PROG_GO\n# ----------\nAC_DEFUN([LT_PROG_GO],\n[AC_CHECK_TOOL(GOC, gccgo,)\n])\n\n\n# LT_PROG_RC\n# ----------\nAC_DEFUN([LT_PROG_RC],\n[AC_CHECK_TOOL(RC, windres,)\n])\n\n# Old name:\nAU_ALIAS([LT_AC_PROG_RC], [LT_PROG_RC])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([LT_AC_PROG_RC], [])\n\n\n# _LT_DECL_EGREP\n# --------------\n# If we don't have a new enough Autoconf to choose the best grep\n# available, choose the one first in the user's PATH.\nm4_defun([_LT_DECL_EGREP],\n[AC_REQUIRE([AC_PROG_EGREP])dnl\nAC_REQUIRE([AC_PROG_FGREP])dnl\ntest -z \"$GREP\" && GREP=grep\n_LT_DECL([], [GREP], [1], [A grep program that handles long lines])\n_LT_DECL([], [EGREP], [1], [An ERE matcher])\n_LT_DECL([], [FGREP], [1], [A literal string matcher])\ndnl Non-bleeding-edge autoconf doesn't subst GREP, so do it here too\nAC_SUBST([GREP])\n])\n\n\n# _LT_DECL_OBJDUMP\n# --------------\n# If we don't have a new enough Autoconf to choose the best objdump\n# available, choose the one first in the user's PATH.\nm4_defun([_LT_DECL_OBJDUMP],\n[AC_CHECK_TOOL(OBJDUMP, objdump, false)\ntest -z \"$OBJDUMP\" && OBJDUMP=objdump\n_LT_DECL([], [OBJDUMP], [1], [An object symbol dumper])\nAC_SUBST([OBJDUMP])\n])\n\n# _LT_DECL_DLLTOOL\n# ----------------\n# Ensure DLLTOOL variable is set.\nm4_defun([_LT_DECL_DLLTOOL],\n[AC_CHECK_TOOL(DLLTOOL, dlltool, false)\ntest -z \"$DLLTOOL\" && DLLTOOL=dlltool\n_LT_DECL([], [DLLTOOL], [1], [DLL creation program])\nAC_SUBST([DLLTOOL])\n])\n\n# _LT_DECL_SED\n# ------------\n# Check for a fully-functional sed program, that truncates\n# as few characters as possible.  Prefer GNU sed if found.\nm4_defun([_LT_DECL_SED],\n[AC_PROG_SED\ntest -z \"$SED\" && SED=sed\nXsed=\"$SED -e 1s/^X//\"\n_LT_DECL([], [SED], [1], [A sed program that does not truncate output])\n_LT_DECL([], [Xsed], [\"\\$SED -e 1s/^X//\"],\n    [Sed that helps us avoid accidentally triggering echo(1) options like -n])\n])# _LT_DECL_SED\n\nm4_ifndef([AC_PROG_SED], [\n############################################################\n# NOTE: This macro has been submitted for inclusion into   #\n#  GNU Autoconf as AC_PROG_SED.  When it is available in   #\n#  a released version of Autoconf we should remove this    #\n#  macro and use it instead.                               #\n############################################################\n\nm4_defun([AC_PROG_SED],\n[AC_MSG_CHECKING([for a sed that does not truncate output])\nAC_CACHE_VAL(lt_cv_path_SED,\n[# Loop through the user's path and test for sed and gsed.\n# Then use that list of sed's as ones to test for truncation.\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  test -z \"$as_dir\" && as_dir=.\n  for lt_ac_prog in sed gsed; do\n    for ac_exec_ext in '' $ac_executable_extensions; do\n      if $as_executable_p \"$as_dir/$lt_ac_prog$ac_exec_ext\"; then\n        lt_ac_sed_list=\"$lt_ac_sed_list $as_dir/$lt_ac_prog$ac_exec_ext\"\n      fi\n    done\n  done\ndone\nIFS=$as_save_IFS\nlt_ac_max=0\nlt_ac_count=0\n# Add /usr/xpg4/bin/sed as it is typically found on Solaris\n# along with /bin/sed that truncates output.\nfor lt_ac_sed in $lt_ac_sed_list /usr/xpg4/bin/sed; do\n  test ! -f \"$lt_ac_sed\" && continue\n  cat /dev/null > conftest.in\n  lt_ac_count=0\n  echo $ECHO_N \"0123456789$ECHO_C\" >conftest.in\n  # Check for GNU sed and select it if it is found.\n  if \"$lt_ac_sed\" --version 2>&1 < /dev/null | grep 'GNU' > /dev/null; then\n    lt_cv_path_SED=$lt_ac_sed\n    break\n  fi\n  while true; do\n    cat conftest.in conftest.in >conftest.tmp\n    mv conftest.tmp conftest.in\n    cp conftest.in conftest.nl\n    echo >>conftest.nl\n    $lt_ac_sed -e 's/a$//' < conftest.nl >conftest.out || break\n    cmp -s conftest.out conftest.nl || break\n    # 10000 chars as input seems more than enough\n    test 10 -lt \"$lt_ac_count\" && break\n    lt_ac_count=`expr $lt_ac_count + 1`\n    if test \"$lt_ac_count\" -gt \"$lt_ac_max\"; then\n      lt_ac_max=$lt_ac_count\n      lt_cv_path_SED=$lt_ac_sed\n    fi\n  done\ndone\n])\nSED=$lt_cv_path_SED\nAC_SUBST([SED])\nAC_MSG_RESULT([$SED])\n])#AC_PROG_SED\n])#m4_ifndef\n\n# Old name:\nAU_ALIAS([LT_AC_PROG_SED], [AC_PROG_SED])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([LT_AC_PROG_SED], [])\n\n\n# _LT_CHECK_SHELL_FEATURES\n# ------------------------\n# Find out whether the shell is Bourne or XSI compatible,\n# or has some other useful features.\nm4_defun([_LT_CHECK_SHELL_FEATURES],\n[if ( (MAIL=60; unset MAIL) || exit) >/dev/null 2>&1; then\n  lt_unset=unset\nelse\n  lt_unset=false\nfi\n_LT_DECL([], [lt_unset], [0], [whether the shell understands \"unset\"])dnl\n\n# test EBCDIC or ASCII\ncase `echo X|tr X '\\101'` in\n A) # ASCII based system\n    # \\n is not interpreted correctly by Solaris 8 /usr/ucb/tr\n  lt_SP2NL='tr \\040 \\012'\n  lt_NL2SP='tr \\015\\012 \\040\\040'\n  ;;\n *) # EBCDIC based system\n  lt_SP2NL='tr \\100 \\n'\n  lt_NL2SP='tr \\r\\n \\100\\100'\n  ;;\nesac\n_LT_DECL([SP2NL], [lt_SP2NL], [1], [turn spaces into newlines])dnl\n_LT_DECL([NL2SP], [lt_NL2SP], [1], [turn newlines into spaces])dnl\n])# _LT_CHECK_SHELL_FEATURES\n\n\n# _LT_PATH_CONVERSION_FUNCTIONS\n# -----------------------------\n# Determine what file name conversion functions should be used by\n# func_to_host_file (and, implicitly, by func_to_host_path).  These are needed\n# for certain cross-compile configurations and native mingw.\nm4_defun([_LT_PATH_CONVERSION_FUNCTIONS],\n[AC_REQUIRE([AC_CANONICAL_HOST])dnl\nAC_REQUIRE([AC_CANONICAL_BUILD])dnl\nAC_MSG_CHECKING([how to convert $build file names to $host format])\nAC_CACHE_VAL(lt_cv_to_host_file_cmd,\n[case $host in\n  *-*-mingw* )\n    case $build in\n      *-*-mingw* ) # actually msys\n        lt_cv_to_host_file_cmd=func_convert_file_msys_to_w32\n        ;;\n      *-*-cygwin* )\n        lt_cv_to_host_file_cmd=func_convert_file_cygwin_to_w32\n        ;;\n      * ) # otherwise, assume *nix\n        lt_cv_to_host_file_cmd=func_convert_file_nix_to_w32\n        ;;\n    esac\n    ;;\n  *-*-cygwin* )\n    case $build in\n      *-*-mingw* ) # actually msys\n        lt_cv_to_host_file_cmd=func_convert_file_msys_to_cygwin\n        ;;\n      *-*-cygwin* )\n        lt_cv_to_host_file_cmd=func_convert_file_noop\n        ;;\n      * ) # otherwise, assume *nix\n        lt_cv_to_host_file_cmd=func_convert_file_nix_to_cygwin\n        ;;\n    esac\n    ;;\n  * ) # unhandled hosts (and \"normal\" native builds)\n    lt_cv_to_host_file_cmd=func_convert_file_noop\n    ;;\nesac\n])\nto_host_file_cmd=$lt_cv_to_host_file_cmd\nAC_MSG_RESULT([$lt_cv_to_host_file_cmd])\n_LT_DECL([to_host_file_cmd], [lt_cv_to_host_file_cmd],\n         [0], [convert $build file names to $host format])dnl\n\nAC_MSG_CHECKING([how to convert $build file names to toolchain format])\nAC_CACHE_VAL(lt_cv_to_tool_file_cmd,\n[#assume ordinary cross tools, or native build.\nlt_cv_to_tool_file_cmd=func_convert_file_noop\ncase $host in\n  *-*-mingw* )\n    case $build in\n      *-*-mingw* ) # actually msys\n        lt_cv_to_tool_file_cmd=func_convert_file_msys_to_w32\n        ;;\n    esac\n    ;;\nesac\n])\nto_tool_file_cmd=$lt_cv_to_tool_file_cmd\nAC_MSG_RESULT([$lt_cv_to_tool_file_cmd])\n_LT_DECL([to_tool_file_cmd], [lt_cv_to_tool_file_cmd],\n         [0], [convert $build files to toolchain format])dnl\n])# _LT_PATH_CONVERSION_FUNCTIONS\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/auxdir/ltoptions.m4": "# Helper functions for option handling.                    -*- Autoconf -*-\n#\n#   Copyright (C) 2004-2005, 2007-2009, 2011-2015 Free Software\n#   Foundation, Inc.\n#   Written by Gary V. Vaughan, 2004\n#\n# This file is free software; the Free Software Foundation gives\n# unlimited permission to copy and/or distribute it, with or without\n# modifications, as long as this notice is preserved.\n\n# serial 8 ltoptions.m4\n\n# This is to help aclocal find these macros, as it can't see m4_define.\nAC_DEFUN([LTOPTIONS_VERSION], [m4_if([1])])\n\n\n# _LT_MANGLE_OPTION(MACRO-NAME, OPTION-NAME)\n# ------------------------------------------\nm4_define([_LT_MANGLE_OPTION],\n[[_LT_OPTION_]m4_bpatsubst($1__$2, [[^a-zA-Z0-9_]], [_])])\n\n\n# _LT_SET_OPTION(MACRO-NAME, OPTION-NAME)\n# ---------------------------------------\n# Set option OPTION-NAME for macro MACRO-NAME, and if there is a\n# matching handler defined, dispatch to it.  Other OPTION-NAMEs are\n# saved as a flag.\nm4_define([_LT_SET_OPTION],\n[m4_define(_LT_MANGLE_OPTION([$1], [$2]))dnl\nm4_ifdef(_LT_MANGLE_DEFUN([$1], [$2]),\n        _LT_MANGLE_DEFUN([$1], [$2]),\n    [m4_warning([Unknown $1 option '$2'])])[]dnl\n])\n\n\n# _LT_IF_OPTION(MACRO-NAME, OPTION-NAME, IF-SET, [IF-NOT-SET])\n# ------------------------------------------------------------\n# Execute IF-SET if OPTION is set, IF-NOT-SET otherwise.\nm4_define([_LT_IF_OPTION],\n[m4_ifdef(_LT_MANGLE_OPTION([$1], [$2]), [$3], [$4])])\n\n\n# _LT_UNLESS_OPTIONS(MACRO-NAME, OPTION-LIST, IF-NOT-SET)\n# -------------------------------------------------------\n# Execute IF-NOT-SET unless all options in OPTION-LIST for MACRO-NAME\n# are set.\nm4_define([_LT_UNLESS_OPTIONS],\n[m4_foreach([_LT_Option], m4_split(m4_normalize([$2])),\n\t    [m4_ifdef(_LT_MANGLE_OPTION([$1], _LT_Option),\n\t\t      [m4_define([$0_found])])])[]dnl\nm4_ifdef([$0_found], [m4_undefine([$0_found])], [$3\n])[]dnl\n])\n\n\n# _LT_SET_OPTIONS(MACRO-NAME, OPTION-LIST)\n# ----------------------------------------\n# OPTION-LIST is a space-separated list of Libtool options associated\n# with MACRO-NAME.  If any OPTION has a matching handler declared with\n# LT_OPTION_DEFINE, dispatch to that macro; otherwise complain about\n# the unknown option and exit.\nm4_defun([_LT_SET_OPTIONS],\n[# Set options\nm4_foreach([_LT_Option], m4_split(m4_normalize([$2])),\n    [_LT_SET_OPTION([$1], _LT_Option)])\n\nm4_if([$1],[LT_INIT],[\n  dnl\n  dnl Simply set some default values (i.e off) if boolean options were not\n  dnl specified:\n  _LT_UNLESS_OPTIONS([LT_INIT], [dlopen], [enable_dlopen=no\n  ])\n  _LT_UNLESS_OPTIONS([LT_INIT], [win32-dll], [enable_win32_dll=no\n  ])\n  dnl\n  dnl If no reference was made to various pairs of opposing options, then\n  dnl we run the default mode handler for the pair.  For example, if neither\n  dnl 'shared' nor 'disable-shared' was passed, we enable building of shared\n  dnl archives by default:\n  _LT_UNLESS_OPTIONS([LT_INIT], [shared disable-shared], [_LT_ENABLE_SHARED])\n  _LT_UNLESS_OPTIONS([LT_INIT], [static disable-static], [_LT_ENABLE_STATIC])\n  _LT_UNLESS_OPTIONS([LT_INIT], [pic-only no-pic], [_LT_WITH_PIC])\n  _LT_UNLESS_OPTIONS([LT_INIT], [fast-install disable-fast-install],\n\t\t   [_LT_ENABLE_FAST_INSTALL])\n  _LT_UNLESS_OPTIONS([LT_INIT], [aix-soname=aix aix-soname=both aix-soname=svr4],\n\t\t   [_LT_WITH_AIX_SONAME([aix])])\n  ])\n])# _LT_SET_OPTIONS\n\n\n## --------------------------------- ##\n## Macros to handle LT_INIT options. ##\n## --------------------------------- ##\n\n# _LT_MANGLE_DEFUN(MACRO-NAME, OPTION-NAME)\n# -----------------------------------------\nm4_define([_LT_MANGLE_DEFUN],\n[[_LT_OPTION_DEFUN_]m4_bpatsubst(m4_toupper([$1__$2]), [[^A-Z0-9_]], [_])])\n\n\n# LT_OPTION_DEFINE(MACRO-NAME, OPTION-NAME, CODE)\n# -----------------------------------------------\nm4_define([LT_OPTION_DEFINE],\n[m4_define(_LT_MANGLE_DEFUN([$1], [$2]), [$3])[]dnl\n])# LT_OPTION_DEFINE\n\n\n# dlopen\n# ------\nLT_OPTION_DEFINE([LT_INIT], [dlopen], [enable_dlopen=yes\n])\n\nAU_DEFUN([AC_LIBTOOL_DLOPEN],\n[_LT_SET_OPTION([LT_INIT], [dlopen])\nAC_DIAGNOSE([obsolete],\n[$0: Remove this warning and the call to _LT_SET_OPTION when you\nput the 'dlopen' option into LT_INIT's first parameter.])\n])\n\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_LIBTOOL_DLOPEN], [])\n\n\n# win32-dll\n# ---------\n# Declare package support for building win32 dll's.\nLT_OPTION_DEFINE([LT_INIT], [win32-dll],\n[enable_win32_dll=yes\n\ncase $host in\n*-*-cygwin* | *-*-mingw* | *-*-pw32* | *-*-cegcc*)\n  AC_CHECK_TOOL(AS, as, false)\n  AC_CHECK_TOOL(DLLTOOL, dlltool, false)\n  AC_CHECK_TOOL(OBJDUMP, objdump, false)\n  ;;\nesac\n\ntest -z \"$AS\" && AS=as\n_LT_DECL([], [AS],      [1], [Assembler program])dnl\n\ntest -z \"$DLLTOOL\" && DLLTOOL=dlltool\n_LT_DECL([], [DLLTOOL], [1], [DLL creation program])dnl\n\ntest -z \"$OBJDUMP\" && OBJDUMP=objdump\n_LT_DECL([], [OBJDUMP], [1], [Object dumper program])dnl\n])# win32-dll\n\nAU_DEFUN([AC_LIBTOOL_WIN32_DLL],\n[AC_REQUIRE([AC_CANONICAL_HOST])dnl\n_LT_SET_OPTION([LT_INIT], [win32-dll])\nAC_DIAGNOSE([obsolete],\n[$0: Remove this warning and the call to _LT_SET_OPTION when you\nput the 'win32-dll' option into LT_INIT's first parameter.])\n])\n\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_LIBTOOL_WIN32_DLL], [])\n\n\n# _LT_ENABLE_SHARED([DEFAULT])\n# ----------------------------\n# implement the --enable-shared flag, and supports the 'shared' and\n# 'disable-shared' LT_INIT options.\n# DEFAULT is either 'yes' or 'no'.  If omitted, it defaults to 'yes'.\nm4_define([_LT_ENABLE_SHARED],\n[m4_define([_LT_ENABLE_SHARED_DEFAULT], [m4_if($1, no, no, yes)])dnl\nAC_ARG_ENABLE([shared],\n    [AS_HELP_STRING([--enable-shared@<:@=PKGS@:>@],\n\t[build shared libraries @<:@default=]_LT_ENABLE_SHARED_DEFAULT[@:>@])],\n    [p=${PACKAGE-default}\n    case $enableval in\n    yes) enable_shared=yes ;;\n    no) enable_shared=no ;;\n    *)\n      enable_shared=no\n      # Look at the argument we got.  We use all the common list separators.\n      lt_save_ifs=$IFS; IFS=$IFS$PATH_SEPARATOR,\n      for pkg in $enableval; do\n\tIFS=$lt_save_ifs\n\tif test \"X$pkg\" = \"X$p\"; then\n\t  enable_shared=yes\n\tfi\n      done\n      IFS=$lt_save_ifs\n      ;;\n    esac],\n    [enable_shared=]_LT_ENABLE_SHARED_DEFAULT)\n\n    _LT_DECL([build_libtool_libs], [enable_shared], [0],\n\t[Whether or not to build shared libraries])\n])# _LT_ENABLE_SHARED\n\nLT_OPTION_DEFINE([LT_INIT], [shared], [_LT_ENABLE_SHARED([yes])])\nLT_OPTION_DEFINE([LT_INIT], [disable-shared], [_LT_ENABLE_SHARED([no])])\n\n# Old names:\nAC_DEFUN([AC_ENABLE_SHARED],\n[_LT_SET_OPTION([LT_INIT], m4_if([$1], [no], [disable-])[shared])\n])\n\nAC_DEFUN([AC_DISABLE_SHARED],\n[_LT_SET_OPTION([LT_INIT], [disable-shared])\n])\n\nAU_DEFUN([AM_ENABLE_SHARED], [AC_ENABLE_SHARED($@)])\nAU_DEFUN([AM_DISABLE_SHARED], [AC_DISABLE_SHARED($@)])\n\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AM_ENABLE_SHARED], [])\ndnl AC_DEFUN([AM_DISABLE_SHARED], [])\n\n\n\n# _LT_ENABLE_STATIC([DEFAULT])\n# ----------------------------\n# implement the --enable-static flag, and support the 'static' and\n# 'disable-static' LT_INIT options.\n# DEFAULT is either 'yes' or 'no'.  If omitted, it defaults to 'yes'.\nm4_define([_LT_ENABLE_STATIC],\n[m4_define([_LT_ENABLE_STATIC_DEFAULT], [m4_if($1, no, no, yes)])dnl\nAC_ARG_ENABLE([static],\n    [AS_HELP_STRING([--enable-static@<:@=PKGS@:>@],\n\t[build static libraries @<:@default=]_LT_ENABLE_STATIC_DEFAULT[@:>@])],\n    [p=${PACKAGE-default}\n    case $enableval in\n    yes) enable_static=yes ;;\n    no) enable_static=no ;;\n    *)\n     enable_static=no\n      # Look at the argument we got.  We use all the common list separators.\n      lt_save_ifs=$IFS; IFS=$IFS$PATH_SEPARATOR,\n      for pkg in $enableval; do\n\tIFS=$lt_save_ifs\n\tif test \"X$pkg\" = \"X$p\"; then\n\t  enable_static=yes\n\tfi\n      done\n      IFS=$lt_save_ifs\n      ;;\n    esac],\n    [enable_static=]_LT_ENABLE_STATIC_DEFAULT)\n\n    _LT_DECL([build_old_libs], [enable_static], [0],\n\t[Whether or not to build static libraries])\n])# _LT_ENABLE_STATIC\n\nLT_OPTION_DEFINE([LT_INIT], [static], [_LT_ENABLE_STATIC([yes])])\nLT_OPTION_DEFINE([LT_INIT], [disable-static], [_LT_ENABLE_STATIC([no])])\n\n# Old names:\nAC_DEFUN([AC_ENABLE_STATIC],\n[_LT_SET_OPTION([LT_INIT], m4_if([$1], [no], [disable-])[static])\n])\n\nAC_DEFUN([AC_DISABLE_STATIC],\n[_LT_SET_OPTION([LT_INIT], [disable-static])\n])\n\nAU_DEFUN([AM_ENABLE_STATIC], [AC_ENABLE_STATIC($@)])\nAU_DEFUN([AM_DISABLE_STATIC], [AC_DISABLE_STATIC($@)])\n\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AM_ENABLE_STATIC], [])\ndnl AC_DEFUN([AM_DISABLE_STATIC], [])\n\n\n\n# _LT_ENABLE_FAST_INSTALL([DEFAULT])\n# ----------------------------------\n# implement the --enable-fast-install flag, and support the 'fast-install'\n# and 'disable-fast-install' LT_INIT options.\n# DEFAULT is either 'yes' or 'no'.  If omitted, it defaults to 'yes'.\nm4_define([_LT_ENABLE_FAST_INSTALL],\n[m4_define([_LT_ENABLE_FAST_INSTALL_DEFAULT], [m4_if($1, no, no, yes)])dnl\nAC_ARG_ENABLE([fast-install],\n    [AS_HELP_STRING([--enable-fast-install@<:@=PKGS@:>@],\n    [optimize for fast installation @<:@default=]_LT_ENABLE_FAST_INSTALL_DEFAULT[@:>@])],\n    [p=${PACKAGE-default}\n    case $enableval in\n    yes) enable_fast_install=yes ;;\n    no) enable_fast_install=no ;;\n    *)\n      enable_fast_install=no\n      # Look at the argument we got.  We use all the common list separators.\n      lt_save_ifs=$IFS; IFS=$IFS$PATH_SEPARATOR,\n      for pkg in $enableval; do\n\tIFS=$lt_save_ifs\n\tif test \"X$pkg\" = \"X$p\"; then\n\t  enable_fast_install=yes\n\tfi\n      done\n      IFS=$lt_save_ifs\n      ;;\n    esac],\n    [enable_fast_install=]_LT_ENABLE_FAST_INSTALL_DEFAULT)\n\n_LT_DECL([fast_install], [enable_fast_install], [0],\n\t [Whether or not to optimize for fast installation])dnl\n])# _LT_ENABLE_FAST_INSTALL\n\nLT_OPTION_DEFINE([LT_INIT], [fast-install], [_LT_ENABLE_FAST_INSTALL([yes])])\nLT_OPTION_DEFINE([LT_INIT], [disable-fast-install], [_LT_ENABLE_FAST_INSTALL([no])])\n\n# Old names:\nAU_DEFUN([AC_ENABLE_FAST_INSTALL],\n[_LT_SET_OPTION([LT_INIT], m4_if([$1], [no], [disable-])[fast-install])\nAC_DIAGNOSE([obsolete],\n[$0: Remove this warning and the call to _LT_SET_OPTION when you put\nthe 'fast-install' option into LT_INIT's first parameter.])\n])\n\nAU_DEFUN([AC_DISABLE_FAST_INSTALL],\n[_LT_SET_OPTION([LT_INIT], [disable-fast-install])\nAC_DIAGNOSE([obsolete],\n[$0: Remove this warning and the call to _LT_SET_OPTION when you put\nthe 'disable-fast-install' option into LT_INIT's first parameter.])\n])\n\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_ENABLE_FAST_INSTALL], [])\ndnl AC_DEFUN([AM_DISABLE_FAST_INSTALL], [])\n\n\n# _LT_WITH_AIX_SONAME([DEFAULT])\n# ----------------------------------\n# implement the --with-aix-soname flag, and support the `aix-soname=aix'\n# and `aix-soname=both' and `aix-soname=svr4' LT_INIT options. DEFAULT\n# is either `aix', `both' or `svr4'.  If omitted, it defaults to `aix'.\nm4_define([_LT_WITH_AIX_SONAME],\n[m4_define([_LT_WITH_AIX_SONAME_DEFAULT], [m4_if($1, svr4, svr4, m4_if($1, both, both, aix))])dnl\nshared_archive_member_spec=\ncase $host,$enable_shared in\npower*-*-aix[[5-9]]*,yes)\n  AC_MSG_CHECKING([which variant of shared library versioning to provide])\n  AC_ARG_WITH([aix-soname],\n    [AS_HELP_STRING([--with-aix-soname=aix|svr4|both],\n      [shared library versioning (aka \"SONAME\") variant to provide on AIX, @<:@default=]_LT_WITH_AIX_SONAME_DEFAULT[@:>@.])],\n    [case $withval in\n    aix|svr4|both)\n      ;;\n    *)\n      AC_MSG_ERROR([Unknown argument to --with-aix-soname])\n      ;;\n    esac\n    lt_cv_with_aix_soname=$with_aix_soname],\n    [AC_CACHE_VAL([lt_cv_with_aix_soname],\n      [lt_cv_with_aix_soname=]_LT_WITH_AIX_SONAME_DEFAULT)\n    with_aix_soname=$lt_cv_with_aix_soname])\n  AC_MSG_RESULT([$with_aix_soname])\n  if test aix != \"$with_aix_soname\"; then\n    # For the AIX way of multilib, we name the shared archive member\n    # based on the bitwidth used, traditionally 'shr.o' or 'shr_64.o',\n    # and 'shr.imp' or 'shr_64.imp', respectively, for the Import File.\n    # Even when GNU compilers ignore OBJECT_MODE but need '-maix64' flag,\n    # the AIX toolchain works better with OBJECT_MODE set (default 32).\n    if test 64 = \"${OBJECT_MODE-32}\"; then\n      shared_archive_member_spec=shr_64\n    else\n      shared_archive_member_spec=shr\n    fi\n  fi\n  ;;\n*)\n  with_aix_soname=aix\n  ;;\nesac\n\n_LT_DECL([], [shared_archive_member_spec], [0],\n    [Shared archive member basename, for filename based shared library versioning on AIX])dnl\n])# _LT_WITH_AIX_SONAME\n\nLT_OPTION_DEFINE([LT_INIT], [aix-soname=aix], [_LT_WITH_AIX_SONAME([aix])])\nLT_OPTION_DEFINE([LT_INIT], [aix-soname=both], [_LT_WITH_AIX_SONAME([both])])\nLT_OPTION_DEFINE([LT_INIT], [aix-soname=svr4], [_LT_WITH_AIX_SONAME([svr4])])\n\n\n# _LT_WITH_PIC([MODE])\n# --------------------\n# implement the --with-pic flag, and support the 'pic-only' and 'no-pic'\n# LT_INIT options.\n# MODE is either 'yes' or 'no'.  If omitted, it defaults to 'both'.\nm4_define([_LT_WITH_PIC],\n[AC_ARG_WITH([pic],\n    [AS_HELP_STRING([--with-pic@<:@=PKGS@:>@],\n\t[try to use only PIC/non-PIC objects @<:@default=use both@:>@])],\n    [lt_p=${PACKAGE-default}\n    case $withval in\n    yes|no) pic_mode=$withval ;;\n    *)\n      pic_mode=default\n      # Look at the argument we got.  We use all the common list separators.\n      lt_save_ifs=$IFS; IFS=$IFS$PATH_SEPARATOR,\n      for lt_pkg in $withval; do\n\tIFS=$lt_save_ifs\n\tif test \"X$lt_pkg\" = \"X$lt_p\"; then\n\t  pic_mode=yes\n\tfi\n      done\n      IFS=$lt_save_ifs\n      ;;\n    esac],\n    [pic_mode=m4_default([$1], [default])])\n\n_LT_DECL([], [pic_mode], [0], [What type of objects to build])dnl\n])# _LT_WITH_PIC\n\nLT_OPTION_DEFINE([LT_INIT], [pic-only], [_LT_WITH_PIC([yes])])\nLT_OPTION_DEFINE([LT_INIT], [no-pic], [_LT_WITH_PIC([no])])\n\n# Old name:\nAU_DEFUN([AC_LIBTOOL_PICMODE],\n[_LT_SET_OPTION([LT_INIT], [pic-only])\nAC_DIAGNOSE([obsolete],\n[$0: Remove this warning and the call to _LT_SET_OPTION when you\nput the 'pic-only' option into LT_INIT's first parameter.])\n])\n\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_LIBTOOL_PICMODE], [])\n\n## ----------------- ##\n## LTDL_INIT Options ##\n## ----------------- ##\n\nm4_define([_LTDL_MODE], [])\nLT_OPTION_DEFINE([LTDL_INIT], [nonrecursive],\n\t\t [m4_define([_LTDL_MODE], [nonrecursive])])\nLT_OPTION_DEFINE([LTDL_INIT], [recursive],\n\t\t [m4_define([_LTDL_MODE], [recursive])])\nLT_OPTION_DEFINE([LTDL_INIT], [subproject],\n\t\t [m4_define([_LTDL_MODE], [subproject])])\n\nm4_define([_LTDL_TYPE], [])\nLT_OPTION_DEFINE([LTDL_INIT], [installable],\n\t\t [m4_define([_LTDL_TYPE], [installable])])\nLT_OPTION_DEFINE([LTDL_INIT], [convenience],\n\t\t [m4_define([_LTDL_TYPE], [convenience])])\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/auxdir/ltmain.sh": "#! /bin/sh\n## DO NOT EDIT - This file generated from ./build-aux/ltmain.in\n##               by inline-source v2014-01-03.01\n\n# libtool (GNU libtool) 2.4.6\n# Provide generalized library-building support services.\n# Written by Gordon Matzigkeit <gord@gnu.ai.mit.edu>, 1996\n\n# Copyright (C) 1996-2015 Free Software Foundation, Inc.\n# This is free software; see the source for copying conditions.  There is NO\n# warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\n# GNU Libtool is free software; you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation; either version 2 of the License, or\n# (at your option) any later version.\n#\n# As a special exception to the GNU General Public License,\n# if you distribute this file as part of a program or library that\n# is built using GNU Libtool, you may include this file under the\n# same distribution terms that you use for the rest of that program.\n#\n# GNU Libtool is distributed in the hope that it will be useful, but\n# WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\n\nPROGRAM=libtool\nPACKAGE=libtool\nVERSION=\"2.4.6 Debian-2.4.6-10\"\npackage_revision=2.4.6\n\n\n## ------ ##\n## Usage. ##\n## ------ ##\n\n# Run './libtool --help' for help with using this script from the\n# command line.\n\n\n## ------------------------------- ##\n## User overridable command paths. ##\n## ------------------------------- ##\n\n# After configure completes, it has a better idea of some of the\n# shell tools we need than the defaults used by the functions shared\n# with bootstrap, so set those here where they can still be over-\n# ridden by the user, but otherwise take precedence.\n\n: ${AUTOCONF=\"autoconf\"}\n: ${AUTOMAKE=\"automake\"}\n\n\n## -------------------------- ##\n## Source external libraries. ##\n## -------------------------- ##\n\n# Much of our low-level functionality needs to be sourced from external\n# libraries, which are installed to $pkgauxdir.\n\n# Set a version string for this script.\nscriptversion=2015-01-20.17; # UTC\n\n# General shell script boiler plate, and helper functions.\n# Written by Gary V. Vaughan, 2004\n\n# Copyright (C) 2004-2015 Free Software Foundation, Inc.\n# This is free software; see the source for copying conditions.  There is NO\n# warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\n# This program is free software; you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation; either version 3 of the License, or\n# (at your option) any later version.\n\n# As a special exception to the GNU General Public License, if you distribute\n# this file as part of a program or library that is built using GNU Libtool,\n# you may include this file under the same distribution terms that you use\n# for the rest of that program.\n\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNES FOR A PARTICULAR PURPOSE. See the GNU\n# General Public License for more details.\n\n# You should have received a copy of the GNU General Public License\n# along with this program. If not, see <http://www.gnu.org/licenses/>.\n\n# Please report bugs or propose patches to gary@gnu.org.\n\n\n## ------ ##\n## Usage. ##\n## ------ ##\n\n# Evaluate this file near the top of your script to gain access to\n# the functions and variables defined here:\n#\n#   . `echo \"$0\" | ${SED-sed} 's|[^/]*$||'`/build-aux/funclib.sh\n#\n# If you need to override any of the default environment variable\n# settings, do that before evaluating this file.\n\n\n## -------------------- ##\n## Shell normalisation. ##\n## -------------------- ##\n\n# Some shells need a little help to be as Bourne compatible as possible.\n# Before doing anything else, make sure all that help has been provided!\n\nDUALCASE=1; export DUALCASE # for MKS sh\nif test -n \"${ZSH_VERSION+set}\" && (emulate sh) >/dev/null 2>&1; then :\n  emulate sh\n  NULLCMD=:\n  # Pre-4.2 versions of Zsh do word splitting on ${1+\"$@\"}, which\n  # is contrary to our usage.  Disable this feature.\n  alias -g '${1+\"$@\"}'='\"$@\"'\n  setopt NO_GLOB_SUBST\nelse\n  case `(set -o) 2>/dev/null` in *posix*) set -o posix ;; esac\nfi\n\n# NLS nuisances: We save the old values in case they are required later.\n_G_user_locale=\n_G_safe_locale=\nfor _G_var in LANG LANGUAGE LC_ALL LC_CTYPE LC_COLLATE LC_MESSAGES\ndo\n  eval \"if test set = \\\"\\${$_G_var+set}\\\"; then\n          save_$_G_var=\\$$_G_var\n          $_G_var=C\n\t  export $_G_var\n\t  _G_user_locale=\\\"$_G_var=\\\\\\$save_\\$_G_var; \\$_G_user_locale\\\"\n\t  _G_safe_locale=\\\"$_G_var=C; \\$_G_safe_locale\\\"\n\tfi\"\ndone\n\n# CDPATH.\n(unset CDPATH) >/dev/null 2>&1 && unset CDPATH\n\n# Make sure IFS has a sensible default\nsp=' '\nnl='\n'\nIFS=\"$sp\t$nl\"\n\n# There are apparently some retarded systems that use ';' as a PATH separator!\nif test \"${PATH_SEPARATOR+set}\" != set; then\n  PATH_SEPARATOR=:\n  (PATH='/bin;/bin'; FPATH=$PATH; sh -c :) >/dev/null 2>&1 && {\n    (PATH='/bin:/bin'; FPATH=$PATH; sh -c :) >/dev/null 2>&1 ||\n      PATH_SEPARATOR=';'\n  }\nfi\n\n\n\n## ------------------------- ##\n## Locate command utilities. ##\n## ------------------------- ##\n\n\n# func_executable_p FILE\n# ----------------------\n# Check that FILE is an executable regular file.\nfunc_executable_p ()\n{\n    test -f \"$1\" && test -x \"$1\"\n}\n\n\n# func_path_progs PROGS_LIST CHECK_FUNC [PATH]\n# --------------------------------------------\n# Search for either a program that responds to --version with output\n# containing \"GNU\", or else returned by CHECK_FUNC otherwise, by\n# trying all the directories in PATH with each of the elements of\n# PROGS_LIST.\n#\n# CHECK_FUNC should accept the path to a candidate program, and\n# set $func_check_prog_result if it truncates its output less than\n# $_G_path_prog_max characters.\nfunc_path_progs ()\n{\n    _G_progs_list=$1\n    _G_check_func=$2\n    _G_PATH=${3-\"$PATH\"}\n\n    _G_path_prog_max=0\n    _G_path_prog_found=false\n    _G_save_IFS=$IFS; IFS=${PATH_SEPARATOR-:}\n    for _G_dir in $_G_PATH; do\n      IFS=$_G_save_IFS\n      test -z \"$_G_dir\" && _G_dir=.\n      for _G_prog_name in $_G_progs_list; do\n        for _exeext in '' .EXE; do\n          _G_path_prog=$_G_dir/$_G_prog_name$_exeext\n          func_executable_p \"$_G_path_prog\" || continue\n          case `\"$_G_path_prog\" --version 2>&1` in\n            *GNU*) func_path_progs_result=$_G_path_prog _G_path_prog_found=: ;;\n            *)     $_G_check_func $_G_path_prog\n\t\t   func_path_progs_result=$func_check_prog_result\n\t\t   ;;\n          esac\n          $_G_path_prog_found && break 3\n        done\n      done\n    done\n    IFS=$_G_save_IFS\n    test -z \"$func_path_progs_result\" && {\n      echo \"no acceptable sed could be found in \\$PATH\" >&2\n      exit 1\n    }\n}\n\n\n# We want to be able to use the functions in this file before configure\n# has figured out where the best binaries are kept, which means we have\n# to search for them ourselves - except when the results are already set\n# where we skip the searches.\n\n# Unless the user overrides by setting SED, search the path for either GNU\n# sed, or the sed that truncates its output the least.\ntest -z \"$SED\" && {\n  _G_sed_script=s/aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa/bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb/\n  for _G_i in 1 2 3 4 5 6 7; do\n    _G_sed_script=$_G_sed_script$nl$_G_sed_script\n  done\n  echo \"$_G_sed_script\" 2>/dev/null | sed 99q >conftest.sed\n  _G_sed_script=\n\n  func_check_prog_sed ()\n  {\n    _G_path_prog=$1\n\n    _G_count=0\n    printf 0123456789 >conftest.in\n    while :\n    do\n      cat conftest.in conftest.in >conftest.tmp\n      mv conftest.tmp conftest.in\n      cp conftest.in conftest.nl\n      echo '' >> conftest.nl\n      \"$_G_path_prog\" -f conftest.sed <conftest.nl >conftest.out 2>/dev/null || break\n      diff conftest.out conftest.nl >/dev/null 2>&1 || break\n      _G_count=`expr $_G_count + 1`\n      if test \"$_G_count\" -gt \"$_G_path_prog_max\"; then\n        # Best one so far, save it but keep looking for a better one\n        func_check_prog_result=$_G_path_prog\n        _G_path_prog_max=$_G_count\n      fi\n      # 10*(2^10) chars as input seems more than enough\n      test 10 -lt \"$_G_count\" && break\n    done\n    rm -f conftest.in conftest.tmp conftest.nl conftest.out\n  }\n\n  func_path_progs \"sed gsed\" func_check_prog_sed $PATH:/usr/xpg4/bin\n  rm -f conftest.sed\n  SED=$func_path_progs_result\n}\n\n\n# Unless the user overrides by setting GREP, search the path for either GNU\n# grep, or the grep that truncates its output the least.\ntest -z \"$GREP\" && {\n  func_check_prog_grep ()\n  {\n    _G_path_prog=$1\n\n    _G_count=0\n    _G_path_prog_max=0\n    printf 0123456789 >conftest.in\n    while :\n    do\n      cat conftest.in conftest.in >conftest.tmp\n      mv conftest.tmp conftest.in\n      cp conftest.in conftest.nl\n      echo 'GREP' >> conftest.nl\n      \"$_G_path_prog\" -e 'GREP$' -e '-(cannot match)-' <conftest.nl >conftest.out 2>/dev/null || break\n      diff conftest.out conftest.nl >/dev/null 2>&1 || break\n      _G_count=`expr $_G_count + 1`\n      if test \"$_G_count\" -gt \"$_G_path_prog_max\"; then\n        # Best one so far, save it but keep looking for a better one\n        func_check_prog_result=$_G_path_prog\n        _G_path_prog_max=$_G_count\n      fi\n      # 10*(2^10) chars as input seems more than enough\n      test 10 -lt \"$_G_count\" && break\n    done\n    rm -f conftest.in conftest.tmp conftest.nl conftest.out\n  }\n\n  func_path_progs \"grep ggrep\" func_check_prog_grep $PATH:/usr/xpg4/bin\n  GREP=$func_path_progs_result\n}\n\n\n## ------------------------------- ##\n## User overridable command paths. ##\n## ------------------------------- ##\n\n# All uppercase variable names are used for environment variables.  These\n# variables can be overridden by the user before calling a script that\n# uses them if a suitable command of that name is not already available\n# in the command search PATH.\n\n: ${CP=\"cp -f\"}\n: ${ECHO=\"printf %s\\n\"}\n: ${EGREP=\"$GREP -E\"}\n: ${FGREP=\"$GREP -F\"}\n: ${LN_S=\"ln -s\"}\n: ${MAKE=\"make\"}\n: ${MKDIR=\"mkdir\"}\n: ${MV=\"mv -f\"}\n: ${RM=\"rm -f\"}\n: ${SHELL=\"${CONFIG_SHELL-/bin/sh}\"}\n\n\n## -------------------- ##\n## Useful sed snippets. ##\n## -------------------- ##\n\nsed_dirname='s|/[^/]*$||'\nsed_basename='s|^.*/||'\n\n# Sed substitution that helps us do robust quoting.  It backslashifies\n# metacharacters that are still active within double-quoted strings.\nsed_quote_subst='s|\\([`\"$\\\\]\\)|\\\\\\1|g'\n\n# Same as above, but do not quote variable references.\nsed_double_quote_subst='s/\\([\"`\\\\]\\)/\\\\\\1/g'\n\n# Sed substitution that turns a string into a regex matching for the\n# string literally.\nsed_make_literal_regex='s|[].[^$\\\\*\\/]|\\\\&|g'\n\n# Sed substitution that converts a w32 file name or path\n# that contains forward slashes, into one that contains\n# (escaped) backslashes.  A very naive implementation.\nsed_naive_backslashify='s|\\\\\\\\*|\\\\|g;s|/|\\\\|g;s|\\\\|\\\\\\\\|g'\n\n# Re-'\\' parameter expansions in output of sed_double_quote_subst that\n# were '\\'-ed in input to the same.  If an odd number of '\\' preceded a\n# '$' in input to sed_double_quote_subst, that '$' was protected from\n# expansion.  Since each input '\\' is now two '\\'s, look for any number\n# of runs of four '\\'s followed by two '\\'s and then a '$'.  '\\' that '$'.\n_G_bs='\\\\'\n_G_bs2='\\\\\\\\'\n_G_bs4='\\\\\\\\\\\\\\\\'\n_G_dollar='\\$'\nsed_double_backslash=\"\\\n  s/$_G_bs4/&\\\\\n/g\n  s/^$_G_bs2$_G_dollar/$_G_bs&/\n  s/\\\\([^$_G_bs]\\\\)$_G_bs2$_G_dollar/\\\\1$_G_bs2$_G_bs$_G_dollar/g\n  s/\\n//g\"\n\n\n## ----------------- ##\n## Global variables. ##\n## ----------------- ##\n\n# Except for the global variables explicitly listed below, the following\n# functions in the '^func_' namespace, and the '^require_' namespace\n# variables initialised in the 'Resource management' section, sourcing\n# this file will not pollute your global namespace with anything\n# else. There's no portable way to scope variables in Bourne shell\n# though, so actually running these functions will sometimes place\n# results into a variable named after the function, and often use\n# temporary variables in the '^_G_' namespace. If you are careful to\n# avoid using those namespaces casually in your sourcing script, things\n# should continue to work as you expect. And, of course, you can freely\n# overwrite any of the functions or variables defined here before\n# calling anything to customize them.\n\nEXIT_SUCCESS=0\nEXIT_FAILURE=1\nEXIT_MISMATCH=63  # $? = 63 is used to indicate version mismatch to missing.\nEXIT_SKIP=77\t  # $? = 77 is used to indicate a skipped test to automake.\n\n# Allow overriding, eg assuming that you follow the convention of\n# putting '$debug_cmd' at the start of all your functions, you can get\n# bash to show function call trace with:\n#\n#    debug_cmd='eval echo \"${FUNCNAME[0]} $*\" >&2' bash your-script-name\ndebug_cmd=${debug_cmd-\":\"}\nexit_cmd=:\n\n# By convention, finish your script with:\n#\n#    exit $exit_status\n#\n# so that you can set exit_status to non-zero if you want to indicate\n# something went wrong during execution without actually bailing out at\n# the point of failure.\nexit_status=$EXIT_SUCCESS\n\n# Work around backward compatibility issue on IRIX 6.5. On IRIX 6.4+, sh\n# is ksh but when the shell is invoked as \"sh\" and the current value of\n# the _XPG environment variable is not equal to 1 (one), the special\n# positional parameter $0, within a function call, is the name of the\n# function.\nprogpath=$0\n\n# The name of this program.\nprogname=`$ECHO \"$progpath\" |$SED \"$sed_basename\"`\n\n# Make sure we have an absolute progpath for reexecution:\ncase $progpath in\n  [\\\\/]*|[A-Za-z]:\\\\*) ;;\n  *[\\\\/]*)\n     progdir=`$ECHO \"$progpath\" |$SED \"$sed_dirname\"`\n     progdir=`cd \"$progdir\" && pwd`\n     progpath=$progdir/$progname\n     ;;\n  *)\n     _G_IFS=$IFS\n     IFS=${PATH_SEPARATOR-:}\n     for progdir in $PATH; do\n       IFS=$_G_IFS\n       test -x \"$progdir/$progname\" && break\n     done\n     IFS=$_G_IFS\n     test -n \"$progdir\" || progdir=`pwd`\n     progpath=$progdir/$progname\n     ;;\nesac\n\n\n## ----------------- ##\n## Standard options. ##\n## ----------------- ##\n\n# The following options affect the operation of the functions defined\n# below, and should be set appropriately depending on run-time para-\n# meters passed on the command line.\n\nopt_dry_run=false\nopt_quiet=false\nopt_verbose=false\n\n# Categories 'all' and 'none' are always available.  Append any others\n# you will pass as the first argument to func_warning from your own\n# code.\nwarning_categories=\n\n# By default, display warnings according to 'opt_warning_types'.  Set\n# 'warning_func'  to ':' to elide all warnings, or func_fatal_error to\n# treat the next displayed warning as a fatal error.\nwarning_func=func_warn_and_continue\n\n# Set to 'all' to display all warnings, 'none' to suppress all\n# warnings, or a space delimited list of some subset of\n# 'warning_categories' to display only the listed warnings.\nopt_warning_types=all\n\n\n## -------------------- ##\n## Resource management. ##\n## -------------------- ##\n\n# This section contains definitions for functions that each ensure a\n# particular resource (a file, or a non-empty configuration variable for\n# example) is available, and if appropriate to extract default values\n# from pertinent package files. Call them using their associated\n# 'require_*' variable to ensure that they are executed, at most, once.\n#\n# It's entirely deliberate that calling these functions can set\n# variables that don't obey the namespace limitations obeyed by the rest\n# of this file, in order that that they be as useful as possible to\n# callers.\n\n\n# require_term_colors\n# -------------------\n# Allow display of bold text on terminals that support it.\nrequire_term_colors=func_require_term_colors\nfunc_require_term_colors ()\n{\n    $debug_cmd\n\n    test -t 1 && {\n      # COLORTERM and USE_ANSI_COLORS environment variables take\n      # precedence, because most terminfo databases neglect to describe\n      # whether color sequences are supported.\n      test -n \"${COLORTERM+set}\" && : ${USE_ANSI_COLORS=\"1\"}\n\n      if test 1 = \"$USE_ANSI_COLORS\"; then\n        # Standard ANSI escape sequences\n        tc_reset='\u001b[0m'\n        tc_bold='\u001b[1m';   tc_standout='\u001b[7m'\n        tc_red='\u001b[31m';   tc_green='\u001b[32m'\n        tc_blue='\u001b[34m';  tc_cyan='\u001b[36m'\n      else\n        # Otherwise trust the terminfo database after all.\n        test -n \"`tput sgr0 2>/dev/null`\" && {\n          tc_reset=`tput sgr0`\n          test -n \"`tput bold 2>/dev/null`\" && tc_bold=`tput bold`\n          tc_standout=$tc_bold\n          test -n \"`tput smso 2>/dev/null`\" && tc_standout=`tput smso`\n          test -n \"`tput setaf 1 2>/dev/null`\" && tc_red=`tput setaf 1`\n          test -n \"`tput setaf 2 2>/dev/null`\" && tc_green=`tput setaf 2`\n          test -n \"`tput setaf 4 2>/dev/null`\" && tc_blue=`tput setaf 4`\n          test -n \"`tput setaf 5 2>/dev/null`\" && tc_cyan=`tput setaf 5`\n        }\n      fi\n    }\n\n    require_term_colors=:\n}\n\n\n## ----------------- ##\n## Function library. ##\n## ----------------- ##\n\n# This section contains a variety of useful functions to call in your\n# scripts. Take note of the portable wrappers for features provided by\n# some modern shells, which will fall back to slower equivalents on\n# less featureful shells.\n\n\n# func_append VAR VALUE\n# ---------------------\n# Append VALUE onto the existing contents of VAR.\n\n  # We should try to minimise forks, especially on Windows where they are\n  # unreasonably slow, so skip the feature probes when bash or zsh are\n  # being used:\n  if test set = \"${BASH_VERSION+set}${ZSH_VERSION+set}\"; then\n    : ${_G_HAVE_ARITH_OP=\"yes\"}\n    : ${_G_HAVE_XSI_OPS=\"yes\"}\n    # The += operator was introduced in bash 3.1\n    case $BASH_VERSION in\n      [12].* | 3.0 | 3.0*) ;;\n      *)\n        : ${_G_HAVE_PLUSEQ_OP=\"yes\"}\n        ;;\n    esac\n  fi\n\n  # _G_HAVE_PLUSEQ_OP\n  # Can be empty, in which case the shell is probed, \"yes\" if += is\n  # useable or anything else if it does not work.\n  test -z \"$_G_HAVE_PLUSEQ_OP\" \\\n    && (eval 'x=a; x+=\" b\"; test \"a b\" = \"$x\"') 2>/dev/null \\\n    && _G_HAVE_PLUSEQ_OP=yes\n\nif test yes = \"$_G_HAVE_PLUSEQ_OP\"\nthen\n  # This is an XSI compatible shell, allowing a faster implementation...\n  eval 'func_append ()\n  {\n    $debug_cmd\n\n    eval \"$1+=\\$2\"\n  }'\nelse\n  # ...otherwise fall back to using expr, which is often a shell builtin.\n  func_append ()\n  {\n    $debug_cmd\n\n    eval \"$1=\\$$1\\$2\"\n  }\nfi\n\n\n# func_append_quoted VAR VALUE\n# ----------------------------\n# Quote VALUE and append to the end of shell variable VAR, separated\n# by a space.\nif test yes = \"$_G_HAVE_PLUSEQ_OP\"; then\n  eval 'func_append_quoted ()\n  {\n    $debug_cmd\n\n    func_quote_for_eval \"$2\"\n    eval \"$1+=\\\\ \\$func_quote_for_eval_result\"\n  }'\nelse\n  func_append_quoted ()\n  {\n    $debug_cmd\n\n    func_quote_for_eval \"$2\"\n    eval \"$1=\\$$1\\\\ \\$func_quote_for_eval_result\"\n  }\nfi\n\n\n# func_append_uniq VAR VALUE\n# --------------------------\n# Append unique VALUE onto the existing contents of VAR, assuming\n# entries are delimited by the first character of VALUE.  For example:\n#\n#   func_append_uniq options \" --another-option option-argument\"\n#\n# will only append to $options if \" --another-option option-argument \"\n# is not already present somewhere in $options already (note spaces at\n# each end implied by leading space in second argument).\nfunc_append_uniq ()\n{\n    $debug_cmd\n\n    eval _G_current_value='`$ECHO $'$1'`'\n    _G_delim=`expr \"$2\" : '\\(.\\)'`\n\n    case $_G_delim$_G_current_value$_G_delim in\n      *\"$2$_G_delim\"*) ;;\n      *) func_append \"$@\" ;;\n    esac\n}\n\n\n# func_arith TERM...\n# ------------------\n# Set func_arith_result to the result of evaluating TERMs.\n  test -z \"$_G_HAVE_ARITH_OP\" \\\n    && (eval 'test 2 = $(( 1 + 1 ))') 2>/dev/null \\\n    && _G_HAVE_ARITH_OP=yes\n\nif test yes = \"$_G_HAVE_ARITH_OP\"; then\n  eval 'func_arith ()\n  {\n    $debug_cmd\n\n    func_arith_result=$(( $* ))\n  }'\nelse\n  func_arith ()\n  {\n    $debug_cmd\n\n    func_arith_result=`expr \"$@\"`\n  }\nfi\n\n\n# func_basename FILE\n# ------------------\n# Set func_basename_result to FILE with everything up to and including\n# the last / stripped.\nif test yes = \"$_G_HAVE_XSI_OPS\"; then\n  # If this shell supports suffix pattern removal, then use it to avoid\n  # forking. Hide the definitions single quotes in case the shell chokes\n  # on unsupported syntax...\n  _b='func_basename_result=${1##*/}'\n  _d='case $1 in\n        */*) func_dirname_result=${1%/*}$2 ;;\n        *  ) func_dirname_result=$3        ;;\n      esac'\n\nelse\n  # ...otherwise fall back to using sed.\n  _b='func_basename_result=`$ECHO \"$1\" |$SED \"$sed_basename\"`'\n  _d='func_dirname_result=`$ECHO \"$1\"  |$SED \"$sed_dirname\"`\n      if test \"X$func_dirname_result\" = \"X$1\"; then\n        func_dirname_result=$3\n      else\n        func_append func_dirname_result \"$2\"\n      fi'\nfi\n\neval 'func_basename ()\n{\n    $debug_cmd\n\n    '\"$_b\"'\n}'\n\n\n# func_dirname FILE APPEND NONDIR_REPLACEMENT\n# -------------------------------------------\n# Compute the dirname of FILE.  If nonempty, add APPEND to the result,\n# otherwise set result to NONDIR_REPLACEMENT.\neval 'func_dirname ()\n{\n    $debug_cmd\n\n    '\"$_d\"'\n}'\n\n\n# func_dirname_and_basename FILE APPEND NONDIR_REPLACEMENT\n# --------------------------------------------------------\n# Perform func_basename and func_dirname in a single function\n# call:\n#   dirname:  Compute the dirname of FILE.  If nonempty,\n#             add APPEND to the result, otherwise set result\n#             to NONDIR_REPLACEMENT.\n#             value returned in \"$func_dirname_result\"\n#   basename: Compute filename of FILE.\n#             value retuned in \"$func_basename_result\"\n# For efficiency, we do not delegate to the functions above but instead\n# duplicate the functionality here.\neval 'func_dirname_and_basename ()\n{\n    $debug_cmd\n\n    '\"$_b\"'\n    '\"$_d\"'\n}'\n\n\n# func_echo ARG...\n# ----------------\n# Echo program name prefixed message.\nfunc_echo ()\n{\n    $debug_cmd\n\n    _G_message=$*\n\n    func_echo_IFS=$IFS\n    IFS=$nl\n    for _G_line in $_G_message; do\n      IFS=$func_echo_IFS\n      $ECHO \"$progname: $_G_line\"\n    done\n    IFS=$func_echo_IFS\n}\n\n\n# func_echo_all ARG...\n# --------------------\n# Invoke $ECHO with all args, space-separated.\nfunc_echo_all ()\n{\n    $ECHO \"$*\"\n}\n\n\n# func_echo_infix_1 INFIX ARG...\n# ------------------------------\n# Echo program name, followed by INFIX on the first line, with any\n# additional lines not showing INFIX.\nfunc_echo_infix_1 ()\n{\n    $debug_cmd\n\n    $require_term_colors\n\n    _G_infix=$1; shift\n    _G_indent=$_G_infix\n    _G_prefix=\"$progname: $_G_infix: \"\n    _G_message=$*\n\n    # Strip color escape sequences before counting printable length\n    for _G_tc in \"$tc_reset\" \"$tc_bold\" \"$tc_standout\" \"$tc_red\" \"$tc_green\" \"$tc_blue\" \"$tc_cyan\"\n    do\n      test -n \"$_G_tc\" && {\n        _G_esc_tc=`$ECHO \"$_G_tc\" | $SED \"$sed_make_literal_regex\"`\n        _G_indent=`$ECHO \"$_G_indent\" | $SED \"s|$_G_esc_tc||g\"`\n      }\n    done\n    _G_indent=\"$progname: \"`echo \"$_G_indent\" | $SED 's|.| |g'`\"  \" ## exclude from sc_prohibit_nested_quotes\n\n    func_echo_infix_1_IFS=$IFS\n    IFS=$nl\n    for _G_line in $_G_message; do\n      IFS=$func_echo_infix_1_IFS\n      $ECHO \"$_G_prefix$tc_bold$_G_line$tc_reset\" >&2\n      _G_prefix=$_G_indent\n    done\n    IFS=$func_echo_infix_1_IFS\n}\n\n\n# func_error ARG...\n# -----------------\n# Echo program name prefixed message to standard error.\nfunc_error ()\n{\n    $debug_cmd\n\n    $require_term_colors\n\n    func_echo_infix_1 \"  $tc_standout${tc_red}error$tc_reset\" \"$*\" >&2\n}\n\n\n# func_fatal_error ARG...\n# -----------------------\n# Echo program name prefixed message to standard error, and exit.\nfunc_fatal_error ()\n{\n    $debug_cmd\n\n    func_error \"$*\"\n    exit $EXIT_FAILURE\n}\n\n\n# func_grep EXPRESSION FILENAME\n# -----------------------------\n# Check whether EXPRESSION matches any line of FILENAME, without output.\nfunc_grep ()\n{\n    $debug_cmd\n\n    $GREP \"$1\" \"$2\" >/dev/null 2>&1\n}\n\n\n# func_len STRING\n# ---------------\n# Set func_len_result to the length of STRING. STRING may not\n# start with a hyphen.\n  test -z \"$_G_HAVE_XSI_OPS\" \\\n    && (eval 'x=a/b/c;\n      test 5aa/bb/cc = \"${#x}${x%%/*}${x%/*}${x#*/}${x##*/}\"') 2>/dev/null \\\n    && _G_HAVE_XSI_OPS=yes\n\nif test yes = \"$_G_HAVE_XSI_OPS\"; then\n  eval 'func_len ()\n  {\n    $debug_cmd\n\n    func_len_result=${#1}\n  }'\nelse\n  func_len ()\n  {\n    $debug_cmd\n\n    func_len_result=`expr \"$1\" : \".*\" 2>/dev/null || echo $max_cmd_len`\n  }\nfi\n\n\n# func_mkdir_p DIRECTORY-PATH\n# ---------------------------\n# Make sure the entire path to DIRECTORY-PATH is available.\nfunc_mkdir_p ()\n{\n    $debug_cmd\n\n    _G_directory_path=$1\n    _G_dir_list=\n\n    if test -n \"$_G_directory_path\" && test : != \"$opt_dry_run\"; then\n\n      # Protect directory names starting with '-'\n      case $_G_directory_path in\n        -*) _G_directory_path=./$_G_directory_path ;;\n      esac\n\n      # While some portion of DIR does not yet exist...\n      while test ! -d \"$_G_directory_path\"; do\n        # ...make a list in topmost first order.  Use a colon delimited\n\t# list incase some portion of path contains whitespace.\n        _G_dir_list=$_G_directory_path:$_G_dir_list\n\n        # If the last portion added has no slash in it, the list is done\n        case $_G_directory_path in */*) ;; *) break ;; esac\n\n        # ...otherwise throw away the child directory and loop\n        _G_directory_path=`$ECHO \"$_G_directory_path\" | $SED -e \"$sed_dirname\"`\n      done\n      _G_dir_list=`$ECHO \"$_G_dir_list\" | $SED 's|:*$||'`\n\n      func_mkdir_p_IFS=$IFS; IFS=:\n      for _G_dir in $_G_dir_list; do\n\tIFS=$func_mkdir_p_IFS\n        # mkdir can fail with a 'File exist' error if two processes\n        # try to create one of the directories concurrently.  Don't\n        # stop in that case!\n        $MKDIR \"$_G_dir\" 2>/dev/null || :\n      done\n      IFS=$func_mkdir_p_IFS\n\n      # Bail out if we (or some other process) failed to create a directory.\n      test -d \"$_G_directory_path\" || \\\n        func_fatal_error \"Failed to create '$1'\"\n    fi\n}\n\n\n# func_mktempdir [BASENAME]\n# -------------------------\n# Make a temporary directory that won't clash with other running\n# libtool processes, and avoids race conditions if possible.  If\n# given, BASENAME is the basename for that directory.\nfunc_mktempdir ()\n{\n    $debug_cmd\n\n    _G_template=${TMPDIR-/tmp}/${1-$progname}\n\n    if test : = \"$opt_dry_run\"; then\n      # Return a directory name, but don't create it in dry-run mode\n      _G_tmpdir=$_G_template-$$\n    else\n\n      # If mktemp works, use that first and foremost\n      _G_tmpdir=`mktemp -d \"$_G_template-XXXXXXXX\" 2>/dev/null`\n\n      if test ! -d \"$_G_tmpdir\"; then\n        # Failing that, at least try and use $RANDOM to avoid a race\n        _G_tmpdir=$_G_template-${RANDOM-0}$$\n\n        func_mktempdir_umask=`umask`\n        umask 0077\n        $MKDIR \"$_G_tmpdir\"\n        umask $func_mktempdir_umask\n      fi\n\n      # If we're not in dry-run mode, bomb out on failure\n      test -d \"$_G_tmpdir\" || \\\n        func_fatal_error \"cannot create temporary directory '$_G_tmpdir'\"\n    fi\n\n    $ECHO \"$_G_tmpdir\"\n}\n\n\n# func_normal_abspath PATH\n# ------------------------\n# Remove doubled-up and trailing slashes, \".\" path components,\n# and cancel out any \"..\" path components in PATH after making\n# it an absolute path.\nfunc_normal_abspath ()\n{\n    $debug_cmd\n\n    # These SED scripts presuppose an absolute path with a trailing slash.\n    _G_pathcar='s|^/\\([^/]*\\).*$|\\1|'\n    _G_pathcdr='s|^/[^/]*||'\n    _G_removedotparts=':dotsl\n\t\ts|/\\./|/|g\n\t\tt dotsl\n\t\ts|/\\.$|/|'\n    _G_collapseslashes='s|/\\{1,\\}|/|g'\n    _G_finalslash='s|/*$|/|'\n\n    # Start from root dir and reassemble the path.\n    func_normal_abspath_result=\n    func_normal_abspath_tpath=$1\n    func_normal_abspath_altnamespace=\n    case $func_normal_abspath_tpath in\n      \"\")\n        # Empty path, that just means $cwd.\n        func_stripname '' '/' \"`pwd`\"\n        func_normal_abspath_result=$func_stripname_result\n        return\n        ;;\n      # The next three entries are used to spot a run of precisely\n      # two leading slashes without using negated character classes;\n      # we take advantage of case's first-match behaviour.\n      ///*)\n        # Unusual form of absolute path, do nothing.\n        ;;\n      //*)\n        # Not necessarily an ordinary path; POSIX reserves leading '//'\n        # and for example Cygwin uses it to access remote file shares\n        # over CIFS/SMB, so we conserve a leading double slash if found.\n        func_normal_abspath_altnamespace=/\n        ;;\n      /*)\n        # Absolute path, do nothing.\n        ;;\n      *)\n        # Relative path, prepend $cwd.\n        func_normal_abspath_tpath=`pwd`/$func_normal_abspath_tpath\n        ;;\n    esac\n\n    # Cancel out all the simple stuff to save iterations.  We also want\n    # the path to end with a slash for ease of parsing, so make sure\n    # there is one (and only one) here.\n    func_normal_abspath_tpath=`$ECHO \"$func_normal_abspath_tpath\" | $SED \\\n          -e \"$_G_removedotparts\" -e \"$_G_collapseslashes\" -e \"$_G_finalslash\"`\n    while :; do\n      # Processed it all yet?\n      if test / = \"$func_normal_abspath_tpath\"; then\n        # If we ascended to the root using \"..\" the result may be empty now.\n        if test -z \"$func_normal_abspath_result\"; then\n          func_normal_abspath_result=/\n        fi\n        break\n      fi\n      func_normal_abspath_tcomponent=`$ECHO \"$func_normal_abspath_tpath\" | $SED \\\n          -e \"$_G_pathcar\"`\n      func_normal_abspath_tpath=`$ECHO \"$func_normal_abspath_tpath\" | $SED \\\n          -e \"$_G_pathcdr\"`\n      # Figure out what to do with it\n      case $func_normal_abspath_tcomponent in\n        \"\")\n          # Trailing empty path component, ignore it.\n          ;;\n        ..)\n          # Parent dir; strip last assembled component from result.\n          func_dirname \"$func_normal_abspath_result\"\n          func_normal_abspath_result=$func_dirname_result\n          ;;\n        *)\n          # Actual path component, append it.\n          func_append func_normal_abspath_result \"/$func_normal_abspath_tcomponent\"\n          ;;\n      esac\n    done\n    # Restore leading double-slash if one was found on entry.\n    func_normal_abspath_result=$func_normal_abspath_altnamespace$func_normal_abspath_result\n}\n\n\n# func_notquiet ARG...\n# --------------------\n# Echo program name prefixed message only when not in quiet mode.\nfunc_notquiet ()\n{\n    $debug_cmd\n\n    $opt_quiet || func_echo ${1+\"$@\"}\n\n    # A bug in bash halts the script if the last line of a function\n    # fails when set -e is in force, so we need another command to\n    # work around that:\n    :\n}\n\n\n# func_relative_path SRCDIR DSTDIR\n# --------------------------------\n# Set func_relative_path_result to the relative path from SRCDIR to DSTDIR.\nfunc_relative_path ()\n{\n    $debug_cmd\n\n    func_relative_path_result=\n    func_normal_abspath \"$1\"\n    func_relative_path_tlibdir=$func_normal_abspath_result\n    func_normal_abspath \"$2\"\n    func_relative_path_tbindir=$func_normal_abspath_result\n\n    # Ascend the tree starting from libdir\n    while :; do\n      # check if we have found a prefix of bindir\n      case $func_relative_path_tbindir in\n        $func_relative_path_tlibdir)\n          # found an exact match\n          func_relative_path_tcancelled=\n          break\n          ;;\n        $func_relative_path_tlibdir*)\n          # found a matching prefix\n          func_stripname \"$func_relative_path_tlibdir\" '' \"$func_relative_path_tbindir\"\n          func_relative_path_tcancelled=$func_stripname_result\n          if test -z \"$func_relative_path_result\"; then\n            func_relative_path_result=.\n          fi\n          break\n          ;;\n        *)\n          func_dirname $func_relative_path_tlibdir\n          func_relative_path_tlibdir=$func_dirname_result\n          if test -z \"$func_relative_path_tlibdir\"; then\n            # Have to descend all the way to the root!\n            func_relative_path_result=../$func_relative_path_result\n            func_relative_path_tcancelled=$func_relative_path_tbindir\n            break\n          fi\n          func_relative_path_result=../$func_relative_path_result\n          ;;\n      esac\n    done\n\n    # Now calculate path; take care to avoid doubling-up slashes.\n    func_stripname '' '/' \"$func_relative_path_result\"\n    func_relative_path_result=$func_stripname_result\n    func_stripname '/' '/' \"$func_relative_path_tcancelled\"\n    if test -n \"$func_stripname_result\"; then\n      func_append func_relative_path_result \"/$func_stripname_result\"\n    fi\n\n    # Normalisation. If bindir is libdir, return '.' else relative path.\n    if test -n \"$func_relative_path_result\"; then\n      func_stripname './' '' \"$func_relative_path_result\"\n      func_relative_path_result=$func_stripname_result\n    fi\n\n    test -n \"$func_relative_path_result\" || func_relative_path_result=.\n\n    :\n}\n\n\n# func_quote_for_eval ARG...\n# --------------------------\n# Aesthetically quote ARGs to be evaled later.\n# This function returns two values:\n#   i) func_quote_for_eval_result\n#      double-quoted, suitable for a subsequent eval\n#  ii) func_quote_for_eval_unquoted_result\n#      has all characters that are still active within double\n#      quotes backslashified.\nfunc_quote_for_eval ()\n{\n    $debug_cmd\n\n    func_quote_for_eval_unquoted_result=\n    func_quote_for_eval_result=\n    while test 0 -lt $#; do\n      case $1 in\n        *[\\\\\\`\\\"\\$]*)\n\t  _G_unquoted_arg=`printf '%s\\n' \"$1\" |$SED \"$sed_quote_subst\"` ;;\n        *)\n          _G_unquoted_arg=$1 ;;\n      esac\n      if test -n \"$func_quote_for_eval_unquoted_result\"; then\n\tfunc_append func_quote_for_eval_unquoted_result \" $_G_unquoted_arg\"\n      else\n        func_append func_quote_for_eval_unquoted_result \"$_G_unquoted_arg\"\n      fi\n\n      case $_G_unquoted_arg in\n        # Double-quote args containing shell metacharacters to delay\n        # word splitting, command substitution and variable expansion\n        # for a subsequent eval.\n        # Many Bourne shells cannot handle close brackets correctly\n        # in scan sets, so we specify it separately.\n        *[\\[\\~\\#\\^\\&\\*\\(\\)\\{\\}\\|\\;\\<\\>\\?\\'\\ \\\t]*|*]*|\"\")\n          _G_quoted_arg=\\\"$_G_unquoted_arg\\\"\n          ;;\n        *)\n          _G_quoted_arg=$_G_unquoted_arg\n\t  ;;\n      esac\n\n      if test -n \"$func_quote_for_eval_result\"; then\n\tfunc_append func_quote_for_eval_result \" $_G_quoted_arg\"\n      else\n        func_append func_quote_for_eval_result \"$_G_quoted_arg\"\n      fi\n      shift\n    done\n}\n\n\n# func_quote_for_expand ARG\n# -------------------------\n# Aesthetically quote ARG to be evaled later; same as above,\n# but do not quote variable references.\nfunc_quote_for_expand ()\n{\n    $debug_cmd\n\n    case $1 in\n      *[\\\\\\`\\\"]*)\n\t_G_arg=`$ECHO \"$1\" | $SED \\\n\t    -e \"$sed_double_quote_subst\" -e \"$sed_double_backslash\"` ;;\n      *)\n        _G_arg=$1 ;;\n    esac\n\n    case $_G_arg in\n      # Double-quote args containing shell metacharacters to delay\n      # word splitting and command substitution for a subsequent eval.\n      # Many Bourne shells cannot handle close brackets correctly\n      # in scan sets, so we specify it separately.\n      *[\\[\\~\\#\\^\\&\\*\\(\\)\\{\\}\\|\\;\\<\\>\\?\\'\\ \\\t]*|*]*|\"\")\n        _G_arg=\\\"$_G_arg\\\"\n        ;;\n    esac\n\n    func_quote_for_expand_result=$_G_arg\n}\n\n\n# func_stripname PREFIX SUFFIX NAME\n# ---------------------------------\n# strip PREFIX and SUFFIX from NAME, and store in func_stripname_result.\n# PREFIX and SUFFIX must not contain globbing or regex special\n# characters, hashes, percent signs, but SUFFIX may contain a leading\n# dot (in which case that matches only a dot).\nif test yes = \"$_G_HAVE_XSI_OPS\"; then\n  eval 'func_stripname ()\n  {\n    $debug_cmd\n\n    # pdksh 5.2.14 does not do ${X%$Y} correctly if both X and Y are\n    # positional parameters, so assign one to ordinary variable first.\n    func_stripname_result=$3\n    func_stripname_result=${func_stripname_result#\"$1\"}\n    func_stripname_result=${func_stripname_result%\"$2\"}\n  }'\nelse\n  func_stripname ()\n  {\n    $debug_cmd\n\n    case $2 in\n      .*) func_stripname_result=`$ECHO \"$3\" | $SED -e \"s%^$1%%\" -e \"s%\\\\\\\\$2\\$%%\"`;;\n      *)  func_stripname_result=`$ECHO \"$3\" | $SED -e \"s%^$1%%\" -e \"s%$2\\$%%\"`;;\n    esac\n  }\nfi\n\n\n# func_show_eval CMD [FAIL_EXP]\n# -----------------------------\n# Unless opt_quiet is true, then output CMD.  Then, if opt_dryrun is\n# not true, evaluate CMD.  If the evaluation of CMD fails, and FAIL_EXP\n# is given, then evaluate it.\nfunc_show_eval ()\n{\n    $debug_cmd\n\n    _G_cmd=$1\n    _G_fail_exp=${2-':'}\n\n    func_quote_for_expand \"$_G_cmd\"\n    eval \"func_notquiet $func_quote_for_expand_result\"\n\n    $opt_dry_run || {\n      eval \"$_G_cmd\"\n      _G_status=$?\n      if test 0 -ne \"$_G_status\"; then\n\teval \"(exit $_G_status); $_G_fail_exp\"\n      fi\n    }\n}\n\n\n# func_show_eval_locale CMD [FAIL_EXP]\n# ------------------------------------\n# Unless opt_quiet is true, then output CMD.  Then, if opt_dryrun is\n# not true, evaluate CMD.  If the evaluation of CMD fails, and FAIL_EXP\n# is given, then evaluate it.  Use the saved locale for evaluation.\nfunc_show_eval_locale ()\n{\n    $debug_cmd\n\n    _G_cmd=$1\n    _G_fail_exp=${2-':'}\n\n    $opt_quiet || {\n      func_quote_for_expand \"$_G_cmd\"\n      eval \"func_echo $func_quote_for_expand_result\"\n    }\n\n    $opt_dry_run || {\n      eval \"$_G_user_locale\n\t    $_G_cmd\"\n      _G_status=$?\n      eval \"$_G_safe_locale\"\n      if test 0 -ne \"$_G_status\"; then\n\teval \"(exit $_G_status); $_G_fail_exp\"\n      fi\n    }\n}\n\n\n# func_tr_sh\n# ----------\n# Turn $1 into a string suitable for a shell variable name.\n# Result is stored in $func_tr_sh_result.  All characters\n# not in the set a-zA-Z0-9_ are replaced with '_'. Further,\n# if $1 begins with a digit, a '_' is prepended as well.\nfunc_tr_sh ()\n{\n    $debug_cmd\n\n    case $1 in\n    [0-9]* | *[!a-zA-Z0-9_]*)\n      func_tr_sh_result=`$ECHO \"$1\" | $SED -e 's/^\\([0-9]\\)/_\\1/' -e 's/[^a-zA-Z0-9_]/_/g'`\n      ;;\n    * )\n      func_tr_sh_result=$1\n      ;;\n    esac\n}\n\n\n# func_verbose ARG...\n# -------------------\n# Echo program name prefixed message in verbose mode only.\nfunc_verbose ()\n{\n    $debug_cmd\n\n    $opt_verbose && func_echo \"$*\"\n\n    :\n}\n\n\n# func_warn_and_continue ARG...\n# -----------------------------\n# Echo program name prefixed warning message to standard error.\nfunc_warn_and_continue ()\n{\n    $debug_cmd\n\n    $require_term_colors\n\n    func_echo_infix_1 \"${tc_red}warning$tc_reset\" \"$*\" >&2\n}\n\n\n# func_warning CATEGORY ARG...\n# ----------------------------\n# Echo program name prefixed warning message to standard error. Warning\n# messages can be filtered according to CATEGORY, where this function\n# elides messages where CATEGORY is not listed in the global variable\n# 'opt_warning_types'.\nfunc_warning ()\n{\n    $debug_cmd\n\n    # CATEGORY must be in the warning_categories list!\n    case \" $warning_categories \" in\n      *\" $1 \"*) ;;\n      *) func_internal_error \"invalid warning category '$1'\" ;;\n    esac\n\n    _G_category=$1\n    shift\n\n    case \" $opt_warning_types \" in\n      *\" $_G_category \"*) $warning_func ${1+\"$@\"} ;;\n    esac\n}\n\n\n# func_sort_ver VER1 VER2\n# -----------------------\n# 'sort -V' is not generally available.\n# Note this deviates from the version comparison in automake\n# in that it treats 1.5 < 1.5.0, and treats 1.4.4a < 1.4-p3a\n# but this should suffice as we won't be specifying old\n# version formats or redundant trailing .0 in bootstrap.conf.\n# If we did want full compatibility then we should probably\n# use m4_version_compare from autoconf.\nfunc_sort_ver ()\n{\n    $debug_cmd\n\n    printf '%s\\n%s\\n' \"$1\" \"$2\" \\\n      | sort -t. -k 1,1n -k 2,2n -k 3,3n -k 4,4n -k 5,5n -k 6,6n -k 7,7n -k 8,8n -k 9,9n\n}\n\n# func_lt_ver PREV CURR\n# ---------------------\n# Return true if PREV and CURR are in the correct order according to\n# func_sort_ver, otherwise false.  Use it like this:\n#\n#  func_lt_ver \"$prev_ver\" \"$proposed_ver\" || func_fatal_error \"...\"\nfunc_lt_ver ()\n{\n    $debug_cmd\n\n    test \"x$1\" = x`func_sort_ver \"$1\" \"$2\" | $SED 1q`\n}\n\n\n# Local variables:\n# mode: shell-script\n# sh-indentation: 2\n# eval: (add-hook 'before-save-hook 'time-stamp)\n# time-stamp-pattern: \"10/scriptversion=%:y-%02m-%02d.%02H; # UTC\"\n# time-stamp-time-zone: \"UTC\"\n# End:\n#! /bin/sh\n\n# Set a version string for this script.\nscriptversion=2015-10-07.11; # UTC\n\n# A portable, pluggable option parser for Bourne shell.\n# Written by Gary V. Vaughan, 2010\n\n# Copyright (C) 2010-2015 Free Software Foundation, Inc.\n# This is free software; see the source for copying conditions.  There is NO\n# warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n\n# You should have received a copy of the GNU General Public License\n# along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\n# Please report bugs or propose patches to gary@gnu.org.\n\n\n## ------ ##\n## Usage. ##\n## ------ ##\n\n# This file is a library for parsing options in your shell scripts along\n# with assorted other useful supporting features that you can make use\n# of too.\n#\n# For the simplest scripts you might need only:\n#\n#   #!/bin/sh\n#   . relative/path/to/funclib.sh\n#   . relative/path/to/options-parser\n#   scriptversion=1.0\n#   func_options ${1+\"$@\"}\n#   eval set dummy \"$func_options_result\"; shift\n#   ...rest of your script...\n#\n# In order for the '--version' option to work, you will need to have a\n# suitably formatted comment like the one at the top of this file\n# starting with '# Written by ' and ending with '# warranty; '.\n#\n# For '-h' and '--help' to work, you will also need a one line\n# description of your script's purpose in a comment directly above the\n# '# Written by ' line, like the one at the top of this file.\n#\n# The default options also support '--debug', which will turn on shell\n# execution tracing (see the comment above debug_cmd below for another\n# use), and '--verbose' and the func_verbose function to allow your script\n# to display verbose messages only when your user has specified\n# '--verbose'.\n#\n# After sourcing this file, you can plug processing for additional\n# options by amending the variables from the 'Configuration' section\n# below, and following the instructions in the 'Option parsing'\n# section further down.\n\n## -------------- ##\n## Configuration. ##\n## -------------- ##\n\n# You should override these variables in your script after sourcing this\n# file so that they reflect the customisations you have added to the\n# option parser.\n\n# The usage line for option parsing errors and the start of '-h' and\n# '--help' output messages. You can embed shell variables for delayed\n# expansion at the time the message is displayed, but you will need to\n# quote other shell meta-characters carefully to prevent them being\n# expanded when the contents are evaled.\nusage='$progpath [OPTION]...'\n\n# Short help message in response to '-h' and '--help'.  Add to this or\n# override it after sourcing this library to reflect the full set of\n# options your script accepts.\nusage_message=\"\\\n       --debug        enable verbose shell tracing\n   -W, --warnings=CATEGORY\n                      report the warnings falling in CATEGORY [all]\n   -v, --verbose      verbosely report processing\n       --version      print version information and exit\n   -h, --help         print short or long help message and exit\n\"\n\n# Additional text appended to 'usage_message' in response to '--help'.\nlong_help_message=\"\nWarning categories include:\n       'all'          show all warnings\n       'none'         turn off all the warnings\n       'error'        warnings are treated as fatal errors\"\n\n# Help message printed before fatal option parsing errors.\nfatal_help=\"Try '\\$progname --help' for more information.\"\n\n\n\n## ------------------------- ##\n## Hook function management. ##\n## ------------------------- ##\n\n# This section contains functions for adding, removing, and running hooks\n# to the main code.  A hook is just a named list of of function, that can\n# be run in order later on.\n\n# func_hookable FUNC_NAME\n# -----------------------\n# Declare that FUNC_NAME will run hooks added with\n# 'func_add_hook FUNC_NAME ...'.\nfunc_hookable ()\n{\n    $debug_cmd\n\n    func_append hookable_fns \" $1\"\n}\n\n\n# func_add_hook FUNC_NAME HOOK_FUNC\n# ---------------------------------\n# Request that FUNC_NAME call HOOK_FUNC before it returns.  FUNC_NAME must\n# first have been declared \"hookable\" by a call to 'func_hookable'.\nfunc_add_hook ()\n{\n    $debug_cmd\n\n    case \" $hookable_fns \" in\n      *\" $1 \"*) ;;\n      *) func_fatal_error \"'$1' does not accept hook functions.\" ;;\n    esac\n\n    eval func_append ${1}_hooks '\" $2\"'\n}\n\n\n# func_remove_hook FUNC_NAME HOOK_FUNC\n# ------------------------------------\n# Remove HOOK_FUNC from the list of functions called by FUNC_NAME.\nfunc_remove_hook ()\n{\n    $debug_cmd\n\n    eval ${1}_hooks='`$ECHO \"\\$'$1'_hooks\" |$SED \"s| '$2'||\"`'\n}\n\n\n# func_run_hooks FUNC_NAME [ARG]...\n# ---------------------------------\n# Run all hook functions registered to FUNC_NAME.\n# It is assumed that the list of hook functions contains nothing more\n# than a whitespace-delimited list of legal shell function names, and\n# no effort is wasted trying to catch shell meta-characters or preserve\n# whitespace.\nfunc_run_hooks ()\n{\n    $debug_cmd\n\n    _G_rc_run_hooks=false\n\n    case \" $hookable_fns \" in\n      *\" $1 \"*) ;;\n      *) func_fatal_error \"'$1' does not support hook funcions.n\" ;;\n    esac\n\n    eval _G_hook_fns=\\$$1_hooks; shift\n\n    for _G_hook in $_G_hook_fns; do\n      if eval $_G_hook '\"$@\"'; then\n        # store returned options list back into positional\n        # parameters for next 'cmd' execution.\n        eval _G_hook_result=\\$${_G_hook}_result\n        eval set dummy \"$_G_hook_result\"; shift\n        _G_rc_run_hooks=:\n      fi\n    done\n\n    $_G_rc_run_hooks && func_run_hooks_result=$_G_hook_result\n}\n\n\n\n## --------------- ##\n## Option parsing. ##\n## --------------- ##\n\n# In order to add your own option parsing hooks, you must accept the\n# full positional parameter list in your hook function, you may remove/edit\n# any options that you action, and then pass back the remaining unprocessed\n# options in '<hooked_function_name>_result', escaped suitably for\n# 'eval'.  In this case you also must return $EXIT_SUCCESS to let the\n# hook's caller know that it should pay attention to\n# '<hooked_function_name>_result'.  Returning $EXIT_FAILURE signalizes that\n# arguments are left untouched by the hook and therefore caller will ignore the\n# result variable.\n#\n# Like this:\n#\n#    my_options_prep ()\n#    {\n#        $debug_cmd\n#\n#        # Extend the existing usage message.\n#        usage_message=$usage_message'\n#      -s, --silent       don'\\''t print informational messages\n#    '\n#        # No change in '$@' (ignored completely by this hook).  There is\n#        # no need to do the equivalent (but slower) action:\n#        # func_quote_for_eval ${1+\"$@\"}\n#        # my_options_prep_result=$func_quote_for_eval_result\n#        false\n#    }\n#    func_add_hook func_options_prep my_options_prep\n#\n#\n#    my_silent_option ()\n#    {\n#        $debug_cmd\n#\n#        args_changed=false\n#\n#        # Note that for efficiency, we parse as many options as we can\n#        # recognise in a loop before passing the remainder back to the\n#        # caller on the first unrecognised argument we encounter.\n#        while test $# -gt 0; do\n#          opt=$1; shift\n#          case $opt in\n#            --silent|-s) opt_silent=:\n#                         args_changed=:\n#                         ;;\n#            # Separate non-argument short options:\n#            -s*)         func_split_short_opt \"$_G_opt\"\n#                         set dummy \"$func_split_short_opt_name\" \\\n#                             \"-$func_split_short_opt_arg\" ${1+\"$@\"}\n#                         shift\n#                         args_changed=:\n#                         ;;\n#            *)           # Make sure the first unrecognised option \"$_G_opt\"\n#                         # is added back to \"$@\", we could need that later\n#                         # if $args_changed is true.\n#                         set dummy \"$_G_opt\" ${1+\"$@\"}; shift; break ;;\n#          esac\n#        done\n#\n#        if $args_changed; then\n#          func_quote_for_eval ${1+\"$@\"}\n#          my_silent_option_result=$func_quote_for_eval_result\n#        fi\n#\n#        $args_changed\n#    }\n#    func_add_hook func_parse_options my_silent_option\n#\n#\n#    my_option_validation ()\n#    {\n#        $debug_cmd\n#\n#        $opt_silent && $opt_verbose && func_fatal_help \"\\\n#    '--silent' and '--verbose' options are mutually exclusive.\"\n#\n#        false\n#    }\n#    func_add_hook func_validate_options my_option_validation\n#\n# You'll also need to manually amend $usage_message to reflect the extra\n# options you parse.  It's preferable to append if you can, so that\n# multiple option parsing hooks can be added safely.\n\n\n# func_options_finish [ARG]...\n# ----------------------------\n# Finishing the option parse loop (call 'func_options' hooks ATM).\nfunc_options_finish ()\n{\n    $debug_cmd\n\n    _G_func_options_finish_exit=false\n    if func_run_hooks func_options ${1+\"$@\"}; then\n      func_options_finish_result=$func_run_hooks_result\n      _G_func_options_finish_exit=:\n    fi\n\n    $_G_func_options_finish_exit\n}\n\n\n# func_options [ARG]...\n# ---------------------\n# All the functions called inside func_options are hookable. See the\n# individual implementations for details.\nfunc_hookable func_options\nfunc_options ()\n{\n    $debug_cmd\n\n    _G_rc_options=false\n\n    for my_func in options_prep parse_options validate_options options_finish\n    do\n      if eval func_$my_func '${1+\"$@\"}'; then\n        eval _G_res_var='$'\"func_${my_func}_result\"\n        eval set dummy \"$_G_res_var\" ; shift\n        _G_rc_options=:\n      fi\n    done\n\n    # Save modified positional parameters for caller.  As a top-level\n    # options-parser function we always need to set the 'func_options_result'\n    # variable (regardless the $_G_rc_options value).\n    if $_G_rc_options; then\n      func_options_result=$_G_res_var\n    else\n      func_quote_for_eval ${1+\"$@\"}\n      func_options_result=$func_quote_for_eval_result\n    fi\n\n    $_G_rc_options\n}\n\n\n# func_options_prep [ARG]...\n# --------------------------\n# All initialisations required before starting the option parse loop.\n# Note that when calling hook functions, we pass through the list of\n# positional parameters.  If a hook function modifies that list, and\n# needs to propagate that back to rest of this script, then the complete\n# modified list must be put in 'func_run_hooks_result' before\n# returning $EXIT_SUCCESS (otherwise $EXIT_FAILURE is returned).\nfunc_hookable func_options_prep\nfunc_options_prep ()\n{\n    $debug_cmd\n\n    # Option defaults:\n    opt_verbose=false\n    opt_warning_types=\n\n    _G_rc_options_prep=false\n    if func_run_hooks func_options_prep ${1+\"$@\"}; then\n      _G_rc_options_prep=:\n      # save modified positional parameters for caller\n      func_options_prep_result=$func_run_hooks_result\n    fi\n\n    $_G_rc_options_prep\n}\n\n\n# func_parse_options [ARG]...\n# ---------------------------\n# The main option parsing loop.\nfunc_hookable func_parse_options\nfunc_parse_options ()\n{\n    $debug_cmd\n\n    func_parse_options_result=\n\n    _G_rc_parse_options=false\n    # this just eases exit handling\n    while test $# -gt 0; do\n      # Defer to hook functions for initial option parsing, so they\n      # get priority in the event of reusing an option name.\n      if func_run_hooks func_parse_options ${1+\"$@\"}; then\n        eval set dummy \"$func_run_hooks_result\"; shift\n        _G_rc_parse_options=:\n      fi\n\n      # Break out of the loop if we already parsed every option.\n      test $# -gt 0 || break\n\n      _G_match_parse_options=:\n      _G_opt=$1\n      shift\n      case $_G_opt in\n        --debug|-x)   debug_cmd='set -x'\n                      func_echo \"enabling shell trace mode\"\n                      $debug_cmd\n                      ;;\n\n        --no-warnings|--no-warning|--no-warn)\n                      set dummy --warnings none ${1+\"$@\"}\n                      shift\n\t\t      ;;\n\n        --warnings|--warning|-W)\n                      if test $# = 0 && func_missing_arg $_G_opt; then\n                        _G_rc_parse_options=:\n                        break\n                      fi\n                      case \" $warning_categories $1\" in\n                        *\" $1 \"*)\n                          # trailing space prevents matching last $1 above\n                          func_append_uniq opt_warning_types \" $1\"\n                          ;;\n                        *all)\n                          opt_warning_types=$warning_categories\n                          ;;\n                        *none)\n                          opt_warning_types=none\n                          warning_func=:\n                          ;;\n                        *error)\n                          opt_warning_types=$warning_categories\n                          warning_func=func_fatal_error\n                          ;;\n                        *)\n                          func_fatal_error \\\n                             \"unsupported warning category: '$1'\"\n                          ;;\n                      esac\n                      shift\n                      ;;\n\n        --verbose|-v) opt_verbose=: ;;\n        --version)    func_version ;;\n        -\\?|-h)       func_usage ;;\n        --help)       func_help ;;\n\n\t# Separate optargs to long options (plugins may need this):\n\t--*=*)        func_split_equals \"$_G_opt\"\n\t              set dummy \"$func_split_equals_lhs\" \\\n                          \"$func_split_equals_rhs\" ${1+\"$@\"}\n                      shift\n                      ;;\n\n       # Separate optargs to short options:\n        -W*)\n                      func_split_short_opt \"$_G_opt\"\n                      set dummy \"$func_split_short_opt_name\" \\\n                          \"$func_split_short_opt_arg\" ${1+\"$@\"}\n                      shift\n                      ;;\n\n        # Separate non-argument short options:\n        -\\?*|-h*|-v*|-x*)\n                      func_split_short_opt \"$_G_opt\"\n                      set dummy \"$func_split_short_opt_name\" \\\n                          \"-$func_split_short_opt_arg\" ${1+\"$@\"}\n                      shift\n                      ;;\n\n        --)           _G_rc_parse_options=: ; break ;;\n        -*)           func_fatal_help \"unrecognised option: '$_G_opt'\" ;;\n        *)            set dummy \"$_G_opt\" ${1+\"$@\"}; shift\n                      _G_match_parse_options=false\n                      break\n                      ;;\n      esac\n\n      $_G_match_parse_options && _G_rc_parse_options=:\n    done\n\n\n    if $_G_rc_parse_options; then\n      # save modified positional parameters for caller\n      func_quote_for_eval ${1+\"$@\"}\n      func_parse_options_result=$func_quote_for_eval_result\n    fi\n\n    $_G_rc_parse_options\n}\n\n\n# func_validate_options [ARG]...\n# ------------------------------\n# Perform any sanity checks on option settings and/or unconsumed\n# arguments.\nfunc_hookable func_validate_options\nfunc_validate_options ()\n{\n    $debug_cmd\n\n    _G_rc_validate_options=false\n\n    # Display all warnings if -W was not given.\n    test -n \"$opt_warning_types\" || opt_warning_types=\" $warning_categories\"\n\n    if func_run_hooks func_validate_options ${1+\"$@\"}; then\n      # save modified positional parameters for caller\n      func_validate_options_result=$func_run_hooks_result\n      _G_rc_validate_options=:\n    fi\n\n    # Bail if the options were screwed!\n    $exit_cmd $EXIT_FAILURE\n\n    $_G_rc_validate_options\n}\n\n\n\n## ----------------- ##\n## Helper functions. ##\n## ----------------- ##\n\n# This section contains the helper functions used by the rest of the\n# hookable option parser framework in ascii-betical order.\n\n\n# func_fatal_help ARG...\n# ----------------------\n# Echo program name prefixed message to standard error, followed by\n# a help hint, and exit.\nfunc_fatal_help ()\n{\n    $debug_cmd\n\n    eval \\$ECHO \\\"\"Usage: $usage\"\\\"\n    eval \\$ECHO \\\"\"$fatal_help\"\\\"\n    func_error ${1+\"$@\"}\n    exit $EXIT_FAILURE\n}\n\n\n# func_help\n# ---------\n# Echo long help message to standard output and exit.\nfunc_help ()\n{\n    $debug_cmd\n\n    func_usage_message\n    $ECHO \"$long_help_message\"\n    exit 0\n}\n\n\n# func_missing_arg ARGNAME\n# ------------------------\n# Echo program name prefixed message to standard error and set global\n# exit_cmd.\nfunc_missing_arg ()\n{\n    $debug_cmd\n\n    func_error \"Missing argument for '$1'.\"\n    exit_cmd=exit\n}\n\n\n# func_split_equals STRING\n# ------------------------\n# Set func_split_equals_lhs and func_split_equals_rhs shell variables after\n# splitting STRING at the '=' sign.\ntest -z \"$_G_HAVE_XSI_OPS\" \\\n    && (eval 'x=a/b/c;\n      test 5aa/bb/cc = \"${#x}${x%%/*}${x%/*}${x#*/}${x##*/}\"') 2>/dev/null \\\n    && _G_HAVE_XSI_OPS=yes\n\nif test yes = \"$_G_HAVE_XSI_OPS\"\nthen\n  # This is an XSI compatible shell, allowing a faster implementation...\n  eval 'func_split_equals ()\n  {\n      $debug_cmd\n\n      func_split_equals_lhs=${1%%=*}\n      func_split_equals_rhs=${1#*=}\n      test \"x$func_split_equals_lhs\" = \"x$1\" \\\n        && func_split_equals_rhs=\n  }'\nelse\n  # ...otherwise fall back to using expr, which is often a shell builtin.\n  func_split_equals ()\n  {\n      $debug_cmd\n\n      func_split_equals_lhs=`expr \"x$1\" : 'x\\([^=]*\\)'`\n      func_split_equals_rhs=\n      test \"x$func_split_equals_lhs\" = \"x$1\" \\\n        || func_split_equals_rhs=`expr \"x$1\" : 'x[^=]*=\\(.*\\)$'`\n  }\nfi #func_split_equals\n\n\n# func_split_short_opt SHORTOPT\n# -----------------------------\n# Set func_split_short_opt_name and func_split_short_opt_arg shell\n# variables after splitting SHORTOPT after the 2nd character.\nif test yes = \"$_G_HAVE_XSI_OPS\"\nthen\n  # This is an XSI compatible shell, allowing a faster implementation...\n  eval 'func_split_short_opt ()\n  {\n      $debug_cmd\n\n      func_split_short_opt_arg=${1#??}\n      func_split_short_opt_name=${1%\"$func_split_short_opt_arg\"}\n  }'\nelse\n  # ...otherwise fall back to using expr, which is often a shell builtin.\n  func_split_short_opt ()\n  {\n      $debug_cmd\n\n      func_split_short_opt_name=`expr \"x$1\" : 'x-\\(.\\)'`\n      func_split_short_opt_arg=`expr \"x$1\" : 'x-.\\(.*\\)$'`\n  }\nfi #func_split_short_opt\n\n\n# func_usage\n# ----------\n# Echo short help message to standard output and exit.\nfunc_usage ()\n{\n    $debug_cmd\n\n    func_usage_message\n    $ECHO \"Run '$progname --help |${PAGER-more}' for full usage\"\n    exit 0\n}\n\n\n# func_usage_message\n# ------------------\n# Echo short help message to standard output.\nfunc_usage_message ()\n{\n    $debug_cmd\n\n    eval \\$ECHO \\\"\"Usage: $usage\"\\\"\n    echo\n    $SED -n 's|^# ||\n        /^Written by/{\n          x;p;x\n        }\n\th\n\t/^Written by/q' < \"$progpath\"\n    echo\n    eval \\$ECHO \\\"\"$usage_message\"\\\"\n}\n\n\n# func_version\n# ------------\n# Echo version message to standard output and exit.\nfunc_version ()\n{\n    $debug_cmd\n\n    printf '%s\\n' \"$progname $scriptversion\"\n    $SED -n '\n        /(C)/!b go\n        :more\n        /\\./!{\n          N\n          s|\\n# | |\n          b more\n        }\n        :go\n        /^# Written by /,/# warranty; / {\n          s|^# ||\n          s|^# *$||\n          s|\\((C)\\)[ 0-9,-]*[ ,-]\\([1-9][0-9]* \\)|\\1 \\2|\n          p\n        }\n        /^# Written by / {\n          s|^# ||\n          p\n        }\n        /^warranty; /q' < \"$progpath\"\n\n    exit $?\n}\n\n\n# Local variables:\n# mode: shell-script\n# sh-indentation: 2\n# eval: (add-hook 'before-save-hook 'time-stamp)\n# time-stamp-pattern: \"10/scriptversion=%:y-%02m-%02d.%02H; # UTC\"\n# time-stamp-time-zone: \"UTC\"\n# End:\n\n# Set a version string.\nscriptversion='(GNU libtool) 2.4.6'\n\n\n# func_echo ARG...\n# ----------------\n# Libtool also displays the current mode in messages, so override\n# funclib.sh func_echo with this custom definition.\nfunc_echo ()\n{\n    $debug_cmd\n\n    _G_message=$*\n\n    func_echo_IFS=$IFS\n    IFS=$nl\n    for _G_line in $_G_message; do\n      IFS=$func_echo_IFS\n      $ECHO \"$progname${opt_mode+: $opt_mode}: $_G_line\"\n    done\n    IFS=$func_echo_IFS\n}\n\n\n# func_warning ARG...\n# -------------------\n# Libtool warnings are not categorized, so override funclib.sh\n# func_warning with this simpler definition.\nfunc_warning ()\n{\n    $debug_cmd\n\n    $warning_func ${1+\"$@\"}\n}\n\n\n## ---------------- ##\n## Options parsing. ##\n## ---------------- ##\n\n# Hook in the functions to make sure our own options are parsed during\n# the option parsing loop.\n\nusage='$progpath [OPTION]... [MODE-ARG]...'\n\n# Short help message in response to '-h'.\nusage_message=\"Options:\n       --config             show all configuration variables\n       --debug              enable verbose shell tracing\n   -n, --dry-run            display commands without modifying any files\n       --features           display basic configuration information and exit\n       --mode=MODE          use operation mode MODE\n       --no-warnings        equivalent to '-Wnone'\n       --preserve-dup-deps  don't remove duplicate dependency libraries\n       --quiet, --silent    don't print informational messages\n       --tag=TAG            use configuration variables from tag TAG\n   -v, --verbose            print more informational messages than default\n       --version            print version information\n   -W, --warnings=CATEGORY  report the warnings falling in CATEGORY [all]\n   -h, --help, --help-all   print short, long, or detailed help message\n\"\n\n# Additional text appended to 'usage_message' in response to '--help'.\nfunc_help ()\n{\n    $debug_cmd\n\n    func_usage_message\n    $ECHO \"$long_help_message\n\nMODE must be one of the following:\n\n       clean           remove files from the build directory\n       compile         compile a source file into a libtool object\n       execute         automatically set library path, then run a program\n       finish          complete the installation of libtool libraries\n       install         install libraries or executables\n       link            create a library or an executable\n       uninstall       remove libraries from an installed directory\n\nMODE-ARGS vary depending on the MODE.  When passed as first option,\n'--mode=MODE' may be abbreviated as 'MODE' or a unique abbreviation of that.\nTry '$progname --help --mode=MODE' for a more detailed description of MODE.\n\nWhen reporting a bug, please describe a test case to reproduce it and\ninclude the following information:\n\n       host-triplet:   $host\n       shell:          $SHELL\n       compiler:       $LTCC\n       compiler flags: $LTCFLAGS\n       linker:         $LD (gnu? $with_gnu_ld)\n       version:        $progname $scriptversion Debian-2.4.6-10\n       automake:       `($AUTOMAKE --version) 2>/dev/null |$SED 1q`\n       autoconf:       `($AUTOCONF --version) 2>/dev/null |$SED 1q`\n\nReport bugs to <bug-libtool@gnu.org>.\nGNU libtool home page: <http://www.gnu.org/s/libtool/>.\nGeneral help using GNU software: <http://www.gnu.org/gethelp/>.\"\n    exit 0\n}\n\n\n# func_lo2o OBJECT-NAME\n# ---------------------\n# Transform OBJECT-NAME from a '.lo' suffix to the platform specific\n# object suffix.\n\nlo2o=s/\\\\.lo\\$/.$objext/\no2lo=s/\\\\.$objext\\$/.lo/\n\nif test yes = \"$_G_HAVE_XSI_OPS\"; then\n  eval 'func_lo2o ()\n  {\n    case $1 in\n      *.lo) func_lo2o_result=${1%.lo}.$objext ;;\n      *   ) func_lo2o_result=$1               ;;\n    esac\n  }'\n\n  # func_xform LIBOBJ-OR-SOURCE\n  # ---------------------------\n  # Transform LIBOBJ-OR-SOURCE from a '.o' or '.c' (or otherwise)\n  # suffix to a '.lo' libtool-object suffix.\n  eval 'func_xform ()\n  {\n    func_xform_result=${1%.*}.lo\n  }'\nelse\n  # ...otherwise fall back to using sed.\n  func_lo2o ()\n  {\n    func_lo2o_result=`$ECHO \"$1\" | $SED \"$lo2o\"`\n  }\n\n  func_xform ()\n  {\n    func_xform_result=`$ECHO \"$1\" | $SED 's|\\.[^.]*$|.lo|'`\n  }\nfi\n\n\n# func_fatal_configuration ARG...\n# -------------------------------\n# Echo program name prefixed message to standard error, followed by\n# a configuration failure hint, and exit.\nfunc_fatal_configuration ()\n{\n    func__fatal_error ${1+\"$@\"} \\\n      \"See the $PACKAGE documentation for more information.\" \\\n      \"Fatal configuration error.\"\n}\n\n\n# func_config\n# -----------\n# Display the configuration for all the tags in this script.\nfunc_config ()\n{\n    re_begincf='^# ### BEGIN LIBTOOL'\n    re_endcf='^# ### END LIBTOOL'\n\n    # Default configuration.\n    $SED \"1,/$re_begincf CONFIG/d;/$re_endcf CONFIG/,\\$d\" < \"$progpath\"\n\n    # Now print the configurations for the tags.\n    for tagname in $taglist; do\n      $SED -n \"/$re_begincf TAG CONFIG: $tagname\\$/,/$re_endcf TAG CONFIG: $tagname\\$/p\" < \"$progpath\"\n    done\n\n    exit $?\n}\n\n\n# func_features\n# -------------\n# Display the features supported by this script.\nfunc_features ()\n{\n    echo \"host: $host\"\n    if test yes = \"$build_libtool_libs\"; then\n      echo \"enable shared libraries\"\n    else\n      echo \"disable shared libraries\"\n    fi\n    if test yes = \"$build_old_libs\"; then\n      echo \"enable static libraries\"\n    else\n      echo \"disable static libraries\"\n    fi\n\n    exit $?\n}\n\n\n# func_enable_tag TAGNAME\n# -----------------------\n# Verify that TAGNAME is valid, and either flag an error and exit, or\n# enable the TAGNAME tag.  We also add TAGNAME to the global $taglist\n# variable here.\nfunc_enable_tag ()\n{\n    # Global variable:\n    tagname=$1\n\n    re_begincf=\"^# ### BEGIN LIBTOOL TAG CONFIG: $tagname\\$\"\n    re_endcf=\"^# ### END LIBTOOL TAG CONFIG: $tagname\\$\"\n    sed_extractcf=/$re_begincf/,/$re_endcf/p\n\n    # Validate tagname.\n    case $tagname in\n      *[!-_A-Za-z0-9,/]*)\n        func_fatal_error \"invalid tag name: $tagname\"\n        ;;\n    esac\n\n    # Don't test for the \"default\" C tag, as we know it's\n    # there but not specially marked.\n    case $tagname in\n        CC) ;;\n    *)\n        if $GREP \"$re_begincf\" \"$progpath\" >/dev/null 2>&1; then\n\t  taglist=\"$taglist $tagname\"\n\n\t  # Evaluate the configuration.  Be careful to quote the path\n\t  # and the sed script, to avoid splitting on whitespace, but\n\t  # also don't use non-portable quotes within backquotes within\n\t  # quotes we have to do it in 2 steps:\n\t  extractedcf=`$SED -n -e \"$sed_extractcf\" < \"$progpath\"`\n\t  eval \"$extractedcf\"\n        else\n\t  func_error \"ignoring unknown tag $tagname\"\n        fi\n        ;;\n    esac\n}\n\n\n# func_check_version_match\n# ------------------------\n# Ensure that we are using m4 macros, and libtool script from the same\n# release of libtool.\nfunc_check_version_match ()\n{\n    if test \"$package_revision\" != \"$macro_revision\"; then\n      if test \"$VERSION\" != \"$macro_version\"; then\n        if test -z \"$macro_version\"; then\n          cat >&2 <<_LT_EOF\n$progname: Version mismatch error.  This is $PACKAGE $VERSION, but the\n$progname: definition of this LT_INIT comes from an older release.\n$progname: You should recreate aclocal.m4 with macros from $PACKAGE $VERSION\n$progname: and run autoconf again.\n_LT_EOF\n        else\n          cat >&2 <<_LT_EOF\n$progname: Version mismatch error.  This is $PACKAGE $VERSION, but the\n$progname: definition of this LT_INIT comes from $PACKAGE $macro_version.\n$progname: You should recreate aclocal.m4 with macros from $PACKAGE $VERSION\n$progname: and run autoconf again.\n_LT_EOF\n        fi\n      else\n        cat >&2 <<_LT_EOF\n$progname: Version mismatch error.  This is $PACKAGE $VERSION, revision $package_revision,\n$progname: but the definition of this LT_INIT comes from revision $macro_revision.\n$progname: You should recreate aclocal.m4 with macros from revision $package_revision\n$progname: of $PACKAGE $VERSION and run autoconf again.\n_LT_EOF\n      fi\n\n      exit $EXIT_MISMATCH\n    fi\n}\n\n\n# libtool_options_prep [ARG]...\n# -----------------------------\n# Preparation for options parsed by libtool.\nlibtool_options_prep ()\n{\n    $debug_mode\n\n    # Option defaults:\n    opt_config=false\n    opt_dlopen=\n    opt_dry_run=false\n    opt_help=false\n    opt_mode=\n    opt_preserve_dup_deps=false\n    opt_quiet=false\n\n    nonopt=\n    preserve_args=\n\n    _G_rc_lt_options_prep=:\n\n    # Shorthand for --mode=foo, only valid as the first argument\n    case $1 in\n    clean|clea|cle|cl)\n      shift; set dummy --mode clean ${1+\"$@\"}; shift\n      ;;\n    compile|compil|compi|comp|com|co|c)\n      shift; set dummy --mode compile ${1+\"$@\"}; shift\n      ;;\n    execute|execut|execu|exec|exe|ex|e)\n      shift; set dummy --mode execute ${1+\"$@\"}; shift\n      ;;\n    finish|finis|fini|fin|fi|f)\n      shift; set dummy --mode finish ${1+\"$@\"}; shift\n      ;;\n    install|instal|insta|inst|ins|in|i)\n      shift; set dummy --mode install ${1+\"$@\"}; shift\n      ;;\n    link|lin|li|l)\n      shift; set dummy --mode link ${1+\"$@\"}; shift\n      ;;\n    uninstall|uninstal|uninsta|uninst|unins|unin|uni|un|u)\n      shift; set dummy --mode uninstall ${1+\"$@\"}; shift\n      ;;\n    *)\n      _G_rc_lt_options_prep=false\n      ;;\n    esac\n\n    if $_G_rc_lt_options_prep; then\n      # Pass back the list of options.\n      func_quote_for_eval ${1+\"$@\"}\n      libtool_options_prep_result=$func_quote_for_eval_result\n    fi\n\n    $_G_rc_lt_options_prep\n}\nfunc_add_hook func_options_prep libtool_options_prep\n\n\n# libtool_parse_options [ARG]...\n# ---------------------------------\n# Provide handling for libtool specific options.\nlibtool_parse_options ()\n{\n    $debug_cmd\n\n    _G_rc_lt_parse_options=false\n\n    # Perform our own loop to consume as many options as possible in\n    # each iteration.\n    while test $# -gt 0; do\n      _G_match_lt_parse_options=:\n      _G_opt=$1\n      shift\n      case $_G_opt in\n        --dry-run|--dryrun|-n)\n                        opt_dry_run=:\n                        ;;\n\n        --config)       func_config ;;\n\n        --dlopen|-dlopen)\n                        opt_dlopen=\"${opt_dlopen+$opt_dlopen\n}$1\"\n                        shift\n                        ;;\n\n        --preserve-dup-deps)\n                        opt_preserve_dup_deps=: ;;\n\n        --features)     func_features ;;\n\n        --finish)       set dummy --mode finish ${1+\"$@\"}; shift ;;\n\n        --help)         opt_help=: ;;\n\n        --help-all)     opt_help=': help-all' ;;\n\n        --mode)         test $# = 0 && func_missing_arg $_G_opt && break\n                        opt_mode=$1\n                        case $1 in\n                          # Valid mode arguments:\n                          clean|compile|execute|finish|install|link|relink|uninstall) ;;\n\n                          # Catch anything else as an error\n                          *) func_error \"invalid argument for $_G_opt\"\n                             exit_cmd=exit\n                             break\n                             ;;\n                        esac\n                        shift\n                        ;;\n\n        --no-silent|--no-quiet)\n                        opt_quiet=false\n                        func_append preserve_args \" $_G_opt\"\n                        ;;\n\n        --no-warnings|--no-warning|--no-warn)\n                        opt_warning=false\n                        func_append preserve_args \" $_G_opt\"\n                        ;;\n\n        --no-verbose)\n                        opt_verbose=false\n                        func_append preserve_args \" $_G_opt\"\n                        ;;\n\n        --silent|--quiet)\n                        opt_quiet=:\n                        opt_verbose=false\n                        func_append preserve_args \" $_G_opt\"\n                        ;;\n\n        --tag)          test $# = 0 && func_missing_arg $_G_opt && break\n                        opt_tag=$1\n                        func_append preserve_args \" $_G_opt $1\"\n                        func_enable_tag \"$1\"\n                        shift\n                        ;;\n\n        --verbose|-v)   opt_quiet=false\n                        opt_verbose=:\n                        func_append preserve_args \" $_G_opt\"\n                        ;;\n\n        # An option not handled by this hook function:\n        *)              set dummy \"$_G_opt\" ${1+\"$@\"} ; shift\n                        _G_match_lt_parse_options=false\n                        break\n                        ;;\n      esac\n      $_G_match_lt_parse_options && _G_rc_lt_parse_options=:\n    done\n\n    if $_G_rc_lt_parse_options; then\n      # save modified positional parameters for caller\n      func_quote_for_eval ${1+\"$@\"}\n      libtool_parse_options_result=$func_quote_for_eval_result\n    fi\n\n    $_G_rc_lt_parse_options\n}\nfunc_add_hook func_parse_options libtool_parse_options\n\n\n\n# libtool_validate_options [ARG]...\n# ---------------------------------\n# Perform any sanity checks on option settings and/or unconsumed\n# arguments.\nlibtool_validate_options ()\n{\n    # save first non-option argument\n    if test 0 -lt $#; then\n      nonopt=$1\n      shift\n    fi\n\n    # preserve --debug\n    test : = \"$debug_cmd\" || func_append preserve_args \" --debug\"\n\n    case $host in\n      # Solaris2 added to fix http://debbugs.gnu.org/cgi/bugreport.cgi?bug=16452\n      # see also: http://gcc.gnu.org/bugzilla/show_bug.cgi?id=59788\n      *cygwin* | *mingw* | *pw32* | *cegcc* | *solaris2* | *os2*)\n        # don't eliminate duplications in $postdeps and $predeps\n        opt_duplicate_compiler_generated_deps=:\n        ;;\n      *)\n        opt_duplicate_compiler_generated_deps=$opt_preserve_dup_deps\n        ;;\n    esac\n\n    $opt_help || {\n      # Sanity checks first:\n      func_check_version_match\n\n      test yes != \"$build_libtool_libs\" \\\n        && test yes != \"$build_old_libs\" \\\n        && func_fatal_configuration \"not configured to build any kind of library\"\n\n      # Darwin sucks\n      eval std_shrext=\\\"$shrext_cmds\\\"\n\n      # Only execute mode is allowed to have -dlopen flags.\n      if test -n \"$opt_dlopen\" && test execute != \"$opt_mode\"; then\n        func_error \"unrecognized option '-dlopen'\"\n        $ECHO \"$help\" 1>&2\n        exit $EXIT_FAILURE\n      fi\n\n      # Change the help message to a mode-specific one.\n      generic_help=$help\n      help=\"Try '$progname --help --mode=$opt_mode' for more information.\"\n    }\n\n    # Pass back the unparsed argument list\n    func_quote_for_eval ${1+\"$@\"}\n    libtool_validate_options_result=$func_quote_for_eval_result\n}\nfunc_add_hook func_validate_options libtool_validate_options\n\n\n# Process options as early as possible so that --help and --version\n# can return quickly.\nfunc_options ${1+\"$@\"}\neval set dummy \"$func_options_result\"; shift\n\n\n\n## ----------- ##\n##    Main.    ##\n## ----------- ##\n\nmagic='%%%MAGIC variable%%%'\nmagic_exe='%%%MAGIC EXE variable%%%'\n\n# Global variables.\nextracted_archives=\nextracted_serial=0\n\n# If this variable is set in any of the actions, the command in it\n# will be execed at the end.  This prevents here-documents from being\n# left over by shells.\nexec_cmd=\n\n\n# A function that is used when there is no print builtin or printf.\nfunc_fallback_echo ()\n{\n  eval 'cat <<_LTECHO_EOF\n$1\n_LTECHO_EOF'\n}\n\n# func_generated_by_libtool\n# True iff stdin has been generated by Libtool. This function is only\n# a basic sanity check; it will hardly flush out determined imposters.\nfunc_generated_by_libtool_p ()\n{\n  $GREP \"^# Generated by .*$PACKAGE\" > /dev/null 2>&1\n}\n\n# func_lalib_p file\n# True iff FILE is a libtool '.la' library or '.lo' object file.\n# This function is only a basic sanity check; it will hardly flush out\n# determined imposters.\nfunc_lalib_p ()\n{\n    test -f \"$1\" &&\n      $SED -e 4q \"$1\" 2>/dev/null | func_generated_by_libtool_p\n}\n\n# func_lalib_unsafe_p file\n# True iff FILE is a libtool '.la' library or '.lo' object file.\n# This function implements the same check as func_lalib_p without\n# resorting to external programs.  To this end, it redirects stdin and\n# closes it afterwards, without saving the original file descriptor.\n# As a safety measure, use it only where a negative result would be\n# fatal anyway.  Works if 'file' does not exist.\nfunc_lalib_unsafe_p ()\n{\n    lalib_p=no\n    if test -f \"$1\" && test -r \"$1\" && exec 5<&0 <\"$1\"; then\n\tfor lalib_p_l in 1 2 3 4\n\tdo\n\t    read lalib_p_line\n\t    case $lalib_p_line in\n\t\t\\#\\ Generated\\ by\\ *$PACKAGE* ) lalib_p=yes; break;;\n\t    esac\n\tdone\n\texec 0<&5 5<&-\n    fi\n    test yes = \"$lalib_p\"\n}\n\n# func_ltwrapper_script_p file\n# True iff FILE is a libtool wrapper script\n# This function is only a basic sanity check; it will hardly flush out\n# determined imposters.\nfunc_ltwrapper_script_p ()\n{\n    test -f \"$1\" &&\n      $lt_truncate_bin < \"$1\" 2>/dev/null | func_generated_by_libtool_p\n}\n\n# func_ltwrapper_executable_p file\n# True iff FILE is a libtool wrapper executable\n# This function is only a basic sanity check; it will hardly flush out\n# determined imposters.\nfunc_ltwrapper_executable_p ()\n{\n    func_ltwrapper_exec_suffix=\n    case $1 in\n    *.exe) ;;\n    *) func_ltwrapper_exec_suffix=.exe ;;\n    esac\n    $GREP \"$magic_exe\" \"$1$func_ltwrapper_exec_suffix\" >/dev/null 2>&1\n}\n\n# func_ltwrapper_scriptname file\n# Assumes file is an ltwrapper_executable\n# uses $file to determine the appropriate filename for a\n# temporary ltwrapper_script.\nfunc_ltwrapper_scriptname ()\n{\n    func_dirname_and_basename \"$1\" \"\" \".\"\n    func_stripname '' '.exe' \"$func_basename_result\"\n    func_ltwrapper_scriptname_result=$func_dirname_result/$objdir/${func_stripname_result}_ltshwrapper\n}\n\n# func_ltwrapper_p file\n# True iff FILE is a libtool wrapper script or wrapper executable\n# This function is only a basic sanity check; it will hardly flush out\n# determined imposters.\nfunc_ltwrapper_p ()\n{\n    func_ltwrapper_script_p \"$1\" || func_ltwrapper_executable_p \"$1\"\n}\n\n\n# func_execute_cmds commands fail_cmd\n# Execute tilde-delimited COMMANDS.\n# If FAIL_CMD is given, eval that upon failure.\n# FAIL_CMD may read-access the current command in variable CMD!\nfunc_execute_cmds ()\n{\n    $debug_cmd\n\n    save_ifs=$IFS; IFS='~'\n    for cmd in $1; do\n      IFS=$sp$nl\n      eval cmd=\\\"$cmd\\\"\n      IFS=$save_ifs\n      func_show_eval \"$cmd\" \"${2-:}\"\n    done\n    IFS=$save_ifs\n}\n\n\n# func_source file\n# Source FILE, adding directory component if necessary.\n# Note that it is not necessary on cygwin/mingw to append a dot to\n# FILE even if both FILE and FILE.exe exist: automatic-append-.exe\n# behavior happens only for exec(3), not for open(2)!  Also, sourcing\n# 'FILE.' does not work on cygwin managed mounts.\nfunc_source ()\n{\n    $debug_cmd\n\n    case $1 in\n    */* | *\\\\*)\t. \"$1\" ;;\n    *)\t\t. \"./$1\" ;;\n    esac\n}\n\n\n# func_resolve_sysroot PATH\n# Replace a leading = in PATH with a sysroot.  Store the result into\n# func_resolve_sysroot_result\nfunc_resolve_sysroot ()\n{\n  func_resolve_sysroot_result=$1\n  case $func_resolve_sysroot_result in\n  =*)\n    func_stripname '=' '' \"$func_resolve_sysroot_result\"\n    func_resolve_sysroot_result=$lt_sysroot$func_stripname_result\n    ;;\n  esac\n}\n\n# func_replace_sysroot PATH\n# If PATH begins with the sysroot, replace it with = and\n# store the result into func_replace_sysroot_result.\nfunc_replace_sysroot ()\n{\n  case $lt_sysroot:$1 in\n  ?*:\"$lt_sysroot\"*)\n    func_stripname \"$lt_sysroot\" '' \"$1\"\n    func_replace_sysroot_result='='$func_stripname_result\n    ;;\n  *)\n    # Including no sysroot.\n    func_replace_sysroot_result=$1\n    ;;\n  esac\n}\n\n# func_infer_tag arg\n# Infer tagged configuration to use if any are available and\n# if one wasn't chosen via the \"--tag\" command line option.\n# Only attempt this if the compiler in the base compile\n# command doesn't match the default compiler.\n# arg is usually of the form 'gcc ...'\nfunc_infer_tag ()\n{\n    $debug_cmd\n\n    if test -n \"$available_tags\" && test -z \"$tagname\"; then\n      CC_quoted=\n      for arg in $CC; do\n\tfunc_append_quoted CC_quoted \"$arg\"\n      done\n      CC_expanded=`func_echo_all $CC`\n      CC_quoted_expanded=`func_echo_all $CC_quoted`\n      case $@ in\n      # Blanks in the command may have been stripped by the calling shell,\n      # but not from the CC environment variable when configure was run.\n      \" $CC \"* | \"$CC \"* | \" $CC_expanded \"* | \"$CC_expanded \"* | \\\n      \" $CC_quoted\"* | \"$CC_quoted \"* | \" $CC_quoted_expanded \"* | \"$CC_quoted_expanded \"*) ;;\n      # Blanks at the start of $base_compile will cause this to fail\n      # if we don't check for them as well.\n      *)\n\tfor z in $available_tags; do\n\t  if $GREP \"^# ### BEGIN LIBTOOL TAG CONFIG: $z$\" < \"$progpath\" > /dev/null; then\n\t    # Evaluate the configuration.\n\t    eval \"`$SED -n -e '/^# ### BEGIN LIBTOOL TAG CONFIG: '$z'$/,/^# ### END LIBTOOL TAG CONFIG: '$z'$/p' < $progpath`\"\n\t    CC_quoted=\n\t    for arg in $CC; do\n\t      # Double-quote args containing other shell metacharacters.\n\t      func_append_quoted CC_quoted \"$arg\"\n\t    done\n\t    CC_expanded=`func_echo_all $CC`\n\t    CC_quoted_expanded=`func_echo_all $CC_quoted`\n\t    case \"$@ \" in\n\t    \" $CC \"* | \"$CC \"* | \" $CC_expanded \"* | \"$CC_expanded \"* | \\\n\t    \" $CC_quoted\"* | \"$CC_quoted \"* | \" $CC_quoted_expanded \"* | \"$CC_quoted_expanded \"*)\n\t      # The compiler in the base compile command matches\n\t      # the one in the tagged configuration.\n\t      # Assume this is the tagged configuration we want.\n\t      tagname=$z\n\t      break\n\t      ;;\n\t    esac\n\t  fi\n\tdone\n\t# If $tagname still isn't set, then no tagged configuration\n\t# was found and let the user know that the \"--tag\" command\n\t# line option must be used.\n\tif test -z \"$tagname\"; then\n\t  func_echo \"unable to infer tagged configuration\"\n\t  func_fatal_error \"specify a tag with '--tag'\"\n#\telse\n#\t  func_verbose \"using $tagname tagged configuration\"\n\tfi\n\t;;\n      esac\n    fi\n}\n\n\n\n# func_write_libtool_object output_name pic_name nonpic_name\n# Create a libtool object file (analogous to a \".la\" file),\n# but don't create it if we're doing a dry run.\nfunc_write_libtool_object ()\n{\n    write_libobj=$1\n    if test yes = \"$build_libtool_libs\"; then\n      write_lobj=\\'$2\\'\n    else\n      write_lobj=none\n    fi\n\n    if test yes = \"$build_old_libs\"; then\n      write_oldobj=\\'$3\\'\n    else\n      write_oldobj=none\n    fi\n\n    $opt_dry_run || {\n      cat >${write_libobj}T <<EOF\n# $write_libobj - a libtool object file\n# Generated by $PROGRAM (GNU $PACKAGE) $VERSION\n#\n# Please DO NOT delete this file!\n# It is necessary for linking the library.\n\n# Name of the PIC object.\npic_object=$write_lobj\n\n# Name of the non-PIC object\nnon_pic_object=$write_oldobj\n\nEOF\n      $MV \"${write_libobj}T\" \"$write_libobj\"\n    }\n}\n\n\n##################################################\n# FILE NAME AND PATH CONVERSION HELPER FUNCTIONS #\n##################################################\n\n# func_convert_core_file_wine_to_w32 ARG\n# Helper function used by file name conversion functions when $build is *nix,\n# and $host is mingw, cygwin, or some other w32 environment. Relies on a\n# correctly configured wine environment available, with the winepath program\n# in $build's $PATH.\n#\n# ARG is the $build file name to be converted to w32 format.\n# Result is available in $func_convert_core_file_wine_to_w32_result, and will\n# be empty on error (or when ARG is empty)\nfunc_convert_core_file_wine_to_w32 ()\n{\n  $debug_cmd\n\n  func_convert_core_file_wine_to_w32_result=$1\n  if test -n \"$1\"; then\n    # Unfortunately, winepath does not exit with a non-zero error code, so we\n    # are forced to check the contents of stdout. On the other hand, if the\n    # command is not found, the shell will set an exit code of 127 and print\n    # *an error message* to stdout. So we must check for both error code of\n    # zero AND non-empty stdout, which explains the odd construction:\n    func_convert_core_file_wine_to_w32_tmp=`winepath -w \"$1\" 2>/dev/null`\n    if test \"$?\" -eq 0 && test -n \"$func_convert_core_file_wine_to_w32_tmp\"; then\n      func_convert_core_file_wine_to_w32_result=`$ECHO \"$func_convert_core_file_wine_to_w32_tmp\" |\n        $SED -e \"$sed_naive_backslashify\"`\n    else\n      func_convert_core_file_wine_to_w32_result=\n    fi\n  fi\n}\n# end: func_convert_core_file_wine_to_w32\n\n\n# func_convert_core_path_wine_to_w32 ARG\n# Helper function used by path conversion functions when $build is *nix, and\n# $host is mingw, cygwin, or some other w32 environment. Relies on a correctly\n# configured wine environment available, with the winepath program in $build's\n# $PATH. Assumes ARG has no leading or trailing path separator characters.\n#\n# ARG is path to be converted from $build format to win32.\n# Result is available in $func_convert_core_path_wine_to_w32_result.\n# Unconvertible file (directory) names in ARG are skipped; if no directory names\n# are convertible, then the result may be empty.\nfunc_convert_core_path_wine_to_w32 ()\n{\n  $debug_cmd\n\n  # unfortunately, winepath doesn't convert paths, only file names\n  func_convert_core_path_wine_to_w32_result=\n  if test -n \"$1\"; then\n    oldIFS=$IFS\n    IFS=:\n    for func_convert_core_path_wine_to_w32_f in $1; do\n      IFS=$oldIFS\n      func_convert_core_file_wine_to_w32 \"$func_convert_core_path_wine_to_w32_f\"\n      if test -n \"$func_convert_core_file_wine_to_w32_result\"; then\n        if test -z \"$func_convert_core_path_wine_to_w32_result\"; then\n          func_convert_core_path_wine_to_w32_result=$func_convert_core_file_wine_to_w32_result\n        else\n          func_append func_convert_core_path_wine_to_w32_result \";$func_convert_core_file_wine_to_w32_result\"\n        fi\n      fi\n    done\n    IFS=$oldIFS\n  fi\n}\n# end: func_convert_core_path_wine_to_w32\n\n\n# func_cygpath ARGS...\n# Wrapper around calling the cygpath program via LT_CYGPATH. This is used when\n# when (1) $build is *nix and Cygwin is hosted via a wine environment; or (2)\n# $build is MSYS and $host is Cygwin, or (3) $build is Cygwin. In case (1) or\n# (2), returns the Cygwin file name or path in func_cygpath_result (input\n# file name or path is assumed to be in w32 format, as previously converted\n# from $build's *nix or MSYS format). In case (3), returns the w32 file name\n# or path in func_cygpath_result (input file name or path is assumed to be in\n# Cygwin format). Returns an empty string on error.\n#\n# ARGS are passed to cygpath, with the last one being the file name or path to\n# be converted.\n#\n# Specify the absolute *nix (or w32) name to cygpath in the LT_CYGPATH\n# environment variable; do not put it in $PATH.\nfunc_cygpath ()\n{\n  $debug_cmd\n\n  if test -n \"$LT_CYGPATH\" && test -f \"$LT_CYGPATH\"; then\n    func_cygpath_result=`$LT_CYGPATH \"$@\" 2>/dev/null`\n    if test \"$?\" -ne 0; then\n      # on failure, ensure result is empty\n      func_cygpath_result=\n    fi\n  else\n    func_cygpath_result=\n    func_error \"LT_CYGPATH is empty or specifies non-existent file: '$LT_CYGPATH'\"\n  fi\n}\n#end: func_cygpath\n\n\n# func_convert_core_msys_to_w32 ARG\n# Convert file name or path ARG from MSYS format to w32 format.  Return\n# result in func_convert_core_msys_to_w32_result.\nfunc_convert_core_msys_to_w32 ()\n{\n  $debug_cmd\n\n  # awkward: cmd appends spaces to result\n  func_convert_core_msys_to_w32_result=`( cmd //c echo \"$1\" ) 2>/dev/null |\n    $SED -e 's/[ ]*$//' -e \"$sed_naive_backslashify\"`\n}\n#end: func_convert_core_msys_to_w32\n\n\n# func_convert_file_check ARG1 ARG2\n# Verify that ARG1 (a file name in $build format) was converted to $host\n# format in ARG2. Otherwise, emit an error message, but continue (resetting\n# func_to_host_file_result to ARG1).\nfunc_convert_file_check ()\n{\n  $debug_cmd\n\n  if test -z \"$2\" && test -n \"$1\"; then\n    func_error \"Could not determine host file name corresponding to\"\n    func_error \"  '$1'\"\n    func_error \"Continuing, but uninstalled executables may not work.\"\n    # Fallback:\n    func_to_host_file_result=$1\n  fi\n}\n# end func_convert_file_check\n\n\n# func_convert_path_check FROM_PATHSEP TO_PATHSEP FROM_PATH TO_PATH\n# Verify that FROM_PATH (a path in $build format) was converted to $host\n# format in TO_PATH. Otherwise, emit an error message, but continue, resetting\n# func_to_host_file_result to a simplistic fallback value (see below).\nfunc_convert_path_check ()\n{\n  $debug_cmd\n\n  if test -z \"$4\" && test -n \"$3\"; then\n    func_error \"Could not determine the host path corresponding to\"\n    func_error \"  '$3'\"\n    func_error \"Continuing, but uninstalled executables may not work.\"\n    # Fallback.  This is a deliberately simplistic \"conversion\" and\n    # should not be \"improved\".  See libtool.info.\n    if test \"x$1\" != \"x$2\"; then\n      lt_replace_pathsep_chars=\"s|$1|$2|g\"\n      func_to_host_path_result=`echo \"$3\" |\n        $SED -e \"$lt_replace_pathsep_chars\"`\n    else\n      func_to_host_path_result=$3\n    fi\n  fi\n}\n# end func_convert_path_check\n\n\n# func_convert_path_front_back_pathsep FRONTPAT BACKPAT REPL ORIG\n# Modifies func_to_host_path_result by prepending REPL if ORIG matches FRONTPAT\n# and appending REPL if ORIG matches BACKPAT.\nfunc_convert_path_front_back_pathsep ()\n{\n  $debug_cmd\n\n  case $4 in\n  $1 ) func_to_host_path_result=$3$func_to_host_path_result\n    ;;\n  esac\n  case $4 in\n  $2 ) func_append func_to_host_path_result \"$3\"\n    ;;\n  esac\n}\n# end func_convert_path_front_back_pathsep\n\n\n##################################################\n# $build to $host FILE NAME CONVERSION FUNCTIONS #\n##################################################\n# invoked via '$to_host_file_cmd ARG'\n#\n# In each case, ARG is the path to be converted from $build to $host format.\n# Result will be available in $func_to_host_file_result.\n\n\n# func_to_host_file ARG\n# Converts the file name ARG from $build format to $host format. Return result\n# in func_to_host_file_result.\nfunc_to_host_file ()\n{\n  $debug_cmd\n\n  $to_host_file_cmd \"$1\"\n}\n# end func_to_host_file\n\n\n# func_to_tool_file ARG LAZY\n# converts the file name ARG from $build format to toolchain format. Return\n# result in func_to_tool_file_result.  If the conversion in use is listed\n# in (the comma separated) LAZY, no conversion takes place.\nfunc_to_tool_file ()\n{\n  $debug_cmd\n\n  case ,$2, in\n    *,\"$to_tool_file_cmd\",*)\n      func_to_tool_file_result=$1\n      ;;\n    *)\n      $to_tool_file_cmd \"$1\"\n      func_to_tool_file_result=$func_to_host_file_result\n      ;;\n  esac\n}\n# end func_to_tool_file\n\n\n# func_convert_file_noop ARG\n# Copy ARG to func_to_host_file_result.\nfunc_convert_file_noop ()\n{\n  func_to_host_file_result=$1\n}\n# end func_convert_file_noop\n\n\n# func_convert_file_msys_to_w32 ARG\n# Convert file name ARG from (mingw) MSYS to (mingw) w32 format; automatic\n# conversion to w32 is not available inside the cwrapper.  Returns result in\n# func_to_host_file_result.\nfunc_convert_file_msys_to_w32 ()\n{\n  $debug_cmd\n\n  func_to_host_file_result=$1\n  if test -n \"$1\"; then\n    func_convert_core_msys_to_w32 \"$1\"\n    func_to_host_file_result=$func_convert_core_msys_to_w32_result\n  fi\n  func_convert_file_check \"$1\" \"$func_to_host_file_result\"\n}\n# end func_convert_file_msys_to_w32\n\n\n# func_convert_file_cygwin_to_w32 ARG\n# Convert file name ARG from Cygwin to w32 format.  Returns result in\n# func_to_host_file_result.\nfunc_convert_file_cygwin_to_w32 ()\n{\n  $debug_cmd\n\n  func_to_host_file_result=$1\n  if test -n \"$1\"; then\n    # because $build is cygwin, we call \"the\" cygpath in $PATH; no need to use\n    # LT_CYGPATH in this case.\n    func_to_host_file_result=`cygpath -m \"$1\"`\n  fi\n  func_convert_file_check \"$1\" \"$func_to_host_file_result\"\n}\n# end func_convert_file_cygwin_to_w32\n\n\n# func_convert_file_nix_to_w32 ARG\n# Convert file name ARG from *nix to w32 format.  Requires a wine environment\n# and a working winepath. Returns result in func_to_host_file_result.\nfunc_convert_file_nix_to_w32 ()\n{\n  $debug_cmd\n\n  func_to_host_file_result=$1\n  if test -n \"$1\"; then\n    func_convert_core_file_wine_to_w32 \"$1\"\n    func_to_host_file_result=$func_convert_core_file_wine_to_w32_result\n  fi\n  func_convert_file_check \"$1\" \"$func_to_host_file_result\"\n}\n# end func_convert_file_nix_to_w32\n\n\n# func_convert_file_msys_to_cygwin ARG\n# Convert file name ARG from MSYS to Cygwin format.  Requires LT_CYGPATH set.\n# Returns result in func_to_host_file_result.\nfunc_convert_file_msys_to_cygwin ()\n{\n  $debug_cmd\n\n  func_to_host_file_result=$1\n  if test -n \"$1\"; then\n    func_convert_core_msys_to_w32 \"$1\"\n    func_cygpath -u \"$func_convert_core_msys_to_w32_result\"\n    func_to_host_file_result=$func_cygpath_result\n  fi\n  func_convert_file_check \"$1\" \"$func_to_host_file_result\"\n}\n# end func_convert_file_msys_to_cygwin\n\n\n# func_convert_file_nix_to_cygwin ARG\n# Convert file name ARG from *nix to Cygwin format.  Requires Cygwin installed\n# in a wine environment, working winepath, and LT_CYGPATH set.  Returns result\n# in func_to_host_file_result.\nfunc_convert_file_nix_to_cygwin ()\n{\n  $debug_cmd\n\n  func_to_host_file_result=$1\n  if test -n \"$1\"; then\n    # convert from *nix to w32, then use cygpath to convert from w32 to cygwin.\n    func_convert_core_file_wine_to_w32 \"$1\"\n    func_cygpath -u \"$func_convert_core_file_wine_to_w32_result\"\n    func_to_host_file_result=$func_cygpath_result\n  fi\n  func_convert_file_check \"$1\" \"$func_to_host_file_result\"\n}\n# end func_convert_file_nix_to_cygwin\n\n\n#############################################\n# $build to $host PATH CONVERSION FUNCTIONS #\n#############################################\n# invoked via '$to_host_path_cmd ARG'\n#\n# In each case, ARG is the path to be converted from $build to $host format.\n# The result will be available in $func_to_host_path_result.\n#\n# Path separators are also converted from $build format to $host format.  If\n# ARG begins or ends with a path separator character, it is preserved (but\n# converted to $host format) on output.\n#\n# All path conversion functions are named using the following convention:\n#   file name conversion function    : func_convert_file_X_to_Y ()\n#   path conversion function         : func_convert_path_X_to_Y ()\n# where, for any given $build/$host combination the 'X_to_Y' value is the\n# same.  If conversion functions are added for new $build/$host combinations,\n# the two new functions must follow this pattern, or func_init_to_host_path_cmd\n# will break.\n\n\n# func_init_to_host_path_cmd\n# Ensures that function \"pointer\" variable $to_host_path_cmd is set to the\n# appropriate value, based on the value of $to_host_file_cmd.\nto_host_path_cmd=\nfunc_init_to_host_path_cmd ()\n{\n  $debug_cmd\n\n  if test -z \"$to_host_path_cmd\"; then\n    func_stripname 'func_convert_file_' '' \"$to_host_file_cmd\"\n    to_host_path_cmd=func_convert_path_$func_stripname_result\n  fi\n}\n\n\n# func_to_host_path ARG\n# Converts the path ARG from $build format to $host format. Return result\n# in func_to_host_path_result.\nfunc_to_host_path ()\n{\n  $debug_cmd\n\n  func_init_to_host_path_cmd\n  $to_host_path_cmd \"$1\"\n}\n# end func_to_host_path\n\n\n# func_convert_path_noop ARG\n# Copy ARG to func_to_host_path_result.\nfunc_convert_path_noop ()\n{\n  func_to_host_path_result=$1\n}\n# end func_convert_path_noop\n\n\n# func_convert_path_msys_to_w32 ARG\n# Convert path ARG from (mingw) MSYS to (mingw) w32 format; automatic\n# conversion to w32 is not available inside the cwrapper.  Returns result in\n# func_to_host_path_result.\nfunc_convert_path_msys_to_w32 ()\n{\n  $debug_cmd\n\n  func_to_host_path_result=$1\n  if test -n \"$1\"; then\n    # Remove leading and trailing path separator characters from ARG.  MSYS\n    # behavior is inconsistent here; cygpath turns them into '.;' and ';.';\n    # and winepath ignores them completely.\n    func_stripname : : \"$1\"\n    func_to_host_path_tmp1=$func_stripname_result\n    func_convert_core_msys_to_w32 \"$func_to_host_path_tmp1\"\n    func_to_host_path_result=$func_convert_core_msys_to_w32_result\n    func_convert_path_check : \";\" \\\n      \"$func_to_host_path_tmp1\" \"$func_to_host_path_result\"\n    func_convert_path_front_back_pathsep \":*\" \"*:\" \";\" \"$1\"\n  fi\n}\n# end func_convert_path_msys_to_w32\n\n\n# func_convert_path_cygwin_to_w32 ARG\n# Convert path ARG from Cygwin to w32 format.  Returns result in\n# func_to_host_file_result.\nfunc_convert_path_cygwin_to_w32 ()\n{\n  $debug_cmd\n\n  func_to_host_path_result=$1\n  if test -n \"$1\"; then\n    # See func_convert_path_msys_to_w32:\n    func_stripname : : \"$1\"\n    func_to_host_path_tmp1=$func_stripname_result\n    func_to_host_path_result=`cygpath -m -p \"$func_to_host_path_tmp1\"`\n    func_convert_path_check : \";\" \\\n      \"$func_to_host_path_tmp1\" \"$func_to_host_path_result\"\n    func_convert_path_front_back_pathsep \":*\" \"*:\" \";\" \"$1\"\n  fi\n}\n# end func_convert_path_cygwin_to_w32\n\n\n# func_convert_path_nix_to_w32 ARG\n# Convert path ARG from *nix to w32 format.  Requires a wine environment and\n# a working winepath.  Returns result in func_to_host_file_result.\nfunc_convert_path_nix_to_w32 ()\n{\n  $debug_cmd\n\n  func_to_host_path_result=$1\n  if test -n \"$1\"; then\n    # See func_convert_path_msys_to_w32:\n    func_stripname : : \"$1\"\n    func_to_host_path_tmp1=$func_stripname_result\n    func_convert_core_path_wine_to_w32 \"$func_to_host_path_tmp1\"\n    func_to_host_path_result=$func_convert_core_path_wine_to_w32_result\n    func_convert_path_check : \";\" \\\n      \"$func_to_host_path_tmp1\" \"$func_to_host_path_result\"\n    func_convert_path_front_back_pathsep \":*\" \"*:\" \";\" \"$1\"\n  fi\n}\n# end func_convert_path_nix_to_w32\n\n\n# func_convert_path_msys_to_cygwin ARG\n# Convert path ARG from MSYS to Cygwin format.  Requires LT_CYGPATH set.\n# Returns result in func_to_host_file_result.\nfunc_convert_path_msys_to_cygwin ()\n{\n  $debug_cmd\n\n  func_to_host_path_result=$1\n  if test -n \"$1\"; then\n    # See func_convert_path_msys_to_w32:\n    func_stripname : : \"$1\"\n    func_to_host_path_tmp1=$func_stripname_result\n    func_convert_core_msys_to_w32 \"$func_to_host_path_tmp1\"\n    func_cygpath -u -p \"$func_convert_core_msys_to_w32_result\"\n    func_to_host_path_result=$func_cygpath_result\n    func_convert_path_check : : \\\n      \"$func_to_host_path_tmp1\" \"$func_to_host_path_result\"\n    func_convert_path_front_back_pathsep \":*\" \"*:\" : \"$1\"\n  fi\n}\n# end func_convert_path_msys_to_cygwin\n\n\n# func_convert_path_nix_to_cygwin ARG\n# Convert path ARG from *nix to Cygwin format.  Requires Cygwin installed in a\n# a wine environment, working winepath, and LT_CYGPATH set.  Returns result in\n# func_to_host_file_result.\nfunc_convert_path_nix_to_cygwin ()\n{\n  $debug_cmd\n\n  func_to_host_path_result=$1\n  if test -n \"$1\"; then\n    # Remove leading and trailing path separator characters from\n    # ARG. msys behavior is inconsistent here, cygpath turns them\n    # into '.;' and ';.', and winepath ignores them completely.\n    func_stripname : : \"$1\"\n    func_to_host_path_tmp1=$func_stripname_result\n    func_convert_core_path_wine_to_w32 \"$func_to_host_path_tmp1\"\n    func_cygpath -u -p \"$func_convert_core_path_wine_to_w32_result\"\n    func_to_host_path_result=$func_cygpath_result\n    func_convert_path_check : : \\\n      \"$func_to_host_path_tmp1\" \"$func_to_host_path_result\"\n    func_convert_path_front_back_pathsep \":*\" \"*:\" : \"$1\"\n  fi\n}\n# end func_convert_path_nix_to_cygwin\n\n\n# func_dll_def_p FILE\n# True iff FILE is a Windows DLL '.def' file.\n# Keep in sync with _LT_DLL_DEF_P in libtool.m4\nfunc_dll_def_p ()\n{\n  $debug_cmd\n\n  func_dll_def_p_tmp=`$SED -n \\\n    -e 's/^[\t ]*//' \\\n    -e '/^\\(;.*\\)*$/d' \\\n    -e 's/^\\(EXPORTS\\|LIBRARY\\)\\([\t ].*\\)*$/DEF/p' \\\n    -e q \\\n    \"$1\"`\n  test DEF = \"$func_dll_def_p_tmp\"\n}\n\n\n# func_mode_compile arg...\nfunc_mode_compile ()\n{\n    $debug_cmd\n\n    # Get the compilation command and the source file.\n    base_compile=\n    srcfile=$nonopt  #  always keep a non-empty value in \"srcfile\"\n    suppress_opt=yes\n    suppress_output=\n    arg_mode=normal\n    libobj=\n    later=\n    pie_flag=\n\n    for arg\n    do\n      case $arg_mode in\n      arg  )\n\t# do not \"continue\".  Instead, add this to base_compile\n\tlastarg=$arg\n\targ_mode=normal\n\t;;\n\n      target )\n\tlibobj=$arg\n\targ_mode=normal\n\tcontinue\n\t;;\n\n      normal )\n\t# Accept any command-line options.\n\tcase $arg in\n\t-o)\n\t  test -n \"$libobj\" && \\\n\t    func_fatal_error \"you cannot specify '-o' more than once\"\n\t  arg_mode=target\n\t  continue\n\t  ;;\n\n\t-pie | -fpie | -fPIE)\n          func_append pie_flag \" $arg\"\n\t  continue\n\t  ;;\n\n\t-shared | -static | -prefer-pic | -prefer-non-pic)\n\t  func_append later \" $arg\"\n\t  continue\n\t  ;;\n\n\t-no-suppress)\n\t  suppress_opt=no\n\t  continue\n\t  ;;\n\n\t-Xcompiler)\n\t  arg_mode=arg  #  the next one goes into the \"base_compile\" arg list\n\t  continue      #  The current \"srcfile\" will either be retained or\n\t  ;;            #  replaced later.  I would guess that would be a bug.\n\n\t-Wc,*)\n\t  func_stripname '-Wc,' '' \"$arg\"\n\t  args=$func_stripname_result\n\t  lastarg=\n\t  save_ifs=$IFS; IFS=,\n\t  for arg in $args; do\n\t    IFS=$save_ifs\n\t    func_append_quoted lastarg \"$arg\"\n\t  done\n\t  IFS=$save_ifs\n\t  func_stripname ' ' '' \"$lastarg\"\n\t  lastarg=$func_stripname_result\n\n\t  # Add the arguments to base_compile.\n\t  func_append base_compile \" $lastarg\"\n\t  continue\n\t  ;;\n\n\t*)\n\t  # Accept the current argument as the source file.\n\t  # The previous \"srcfile\" becomes the current argument.\n\t  #\n\t  lastarg=$srcfile\n\t  srcfile=$arg\n\t  ;;\n\tesac  #  case $arg\n\t;;\n      esac    #  case $arg_mode\n\n      # Aesthetically quote the previous argument.\n      func_append_quoted base_compile \"$lastarg\"\n    done # for arg\n\n    case $arg_mode in\n    arg)\n      func_fatal_error \"you must specify an argument for -Xcompile\"\n      ;;\n    target)\n      func_fatal_error \"you must specify a target with '-o'\"\n      ;;\n    *)\n      # Get the name of the library object.\n      test -z \"$libobj\" && {\n\tfunc_basename \"$srcfile\"\n\tlibobj=$func_basename_result\n      }\n      ;;\n    esac\n\n    # Recognize several different file suffixes.\n    # If the user specifies -o file.o, it is replaced with file.lo\n    case $libobj in\n    *.[cCFSifmso] | \\\n    *.ada | *.adb | *.ads | *.asm | \\\n    *.c++ | *.cc | *.ii | *.class | *.cpp | *.cxx | \\\n    *.[fF][09]? | *.for | *.java | *.go | *.obj | *.sx | *.cu | *.cup)\n      func_xform \"$libobj\"\n      libobj=$func_xform_result\n      ;;\n    esac\n\n    case $libobj in\n    *.lo) func_lo2o \"$libobj\"; obj=$func_lo2o_result ;;\n    *)\n      func_fatal_error \"cannot determine name of library object from '$libobj'\"\n      ;;\n    esac\n\n    func_infer_tag $base_compile\n\n    for arg in $later; do\n      case $arg in\n      -shared)\n\ttest yes = \"$build_libtool_libs\" \\\n\t  || func_fatal_configuration \"cannot build a shared library\"\n\tbuild_old_libs=no\n\tcontinue\n\t;;\n\n      -static)\n\tbuild_libtool_libs=no\n\tbuild_old_libs=yes\n\tcontinue\n\t;;\n\n      -prefer-pic)\n\tpic_mode=yes\n\tcontinue\n\t;;\n\n      -prefer-non-pic)\n\tpic_mode=no\n\tcontinue\n\t;;\n      esac\n    done\n\n    func_quote_for_eval \"$libobj\"\n    test \"X$libobj\" != \"X$func_quote_for_eval_result\" \\\n      && $ECHO \"X$libobj\" | $GREP '[]~#^*{};<>?\"'\"'\"'\t &()|`$[]' \\\n      && func_warning \"libobj name '$libobj' may not contain shell special characters.\"\n    func_dirname_and_basename \"$obj\" \"/\" \"\"\n    objname=$func_basename_result\n    xdir=$func_dirname_result\n    lobj=$xdir$objdir/$objname\n\n    test -z \"$base_compile\" && \\\n      func_fatal_help \"you must specify a compilation command\"\n\n    # Delete any leftover library objects.\n    if test yes = \"$build_old_libs\"; then\n      removelist=\"$obj $lobj $libobj ${libobj}T\"\n    else\n      removelist=\"$lobj $libobj ${libobj}T\"\n    fi\n\n    # On Cygwin there's no \"real\" PIC flag so we must build both object types\n    case $host_os in\n    cygwin* | mingw* | pw32* | os2* | cegcc*)\n      pic_mode=default\n      ;;\n    esac\n    if test no = \"$pic_mode\" && test pass_all != \"$deplibs_check_method\"; then\n      # non-PIC code in shared libraries is not supported\n      pic_mode=default\n    fi\n\n    # Calculate the filename of the output object if compiler does\n    # not support -o with -c\n    if test no = \"$compiler_c_o\"; then\n      output_obj=`$ECHO \"$srcfile\" | $SED 's%^.*/%%; s%\\.[^.]*$%%'`.$objext\n      lockfile=$output_obj.lock\n    else\n      output_obj=\n      need_locks=no\n      lockfile=\n    fi\n\n    # Lock this critical section if it is needed\n    # We use this script file to make the link, it avoids creating a new file\n    if test yes = \"$need_locks\"; then\n      until $opt_dry_run || ln \"$progpath\" \"$lockfile\" 2>/dev/null; do\n\tfunc_echo \"Waiting for $lockfile to be removed\"\n\tsleep 2\n      done\n    elif test warn = \"$need_locks\"; then\n      if test -f \"$lockfile\"; then\n\t$ECHO \"\\\n*** ERROR, $lockfile exists and contains:\n`cat $lockfile 2>/dev/null`\n\nThis indicates that another process is trying to use the same\ntemporary object file, and libtool could not work around it because\nyour compiler does not support '-c' and '-o' together.  If you\nrepeat this compilation, it may succeed, by chance, but you had better\navoid parallel builds (make -j) in this platform, or get a better\ncompiler.\"\n\n\t$opt_dry_run || $RM $removelist\n\texit $EXIT_FAILURE\n      fi\n      func_append removelist \" $output_obj\"\n      $ECHO \"$srcfile\" > \"$lockfile\"\n    fi\n\n    $opt_dry_run || $RM $removelist\n    func_append removelist \" $lockfile\"\n    trap '$opt_dry_run || $RM $removelist; exit $EXIT_FAILURE' 1 2 15\n\n    func_to_tool_file \"$srcfile\" func_convert_file_msys_to_w32\n    srcfile=$func_to_tool_file_result\n    func_quote_for_eval \"$srcfile\"\n    qsrcfile=$func_quote_for_eval_result\n\n    # Only build a PIC object if we are building libtool libraries.\n    if test yes = \"$build_libtool_libs\"; then\n      # Without this assignment, base_compile gets emptied.\n      fbsd_hideous_sh_bug=$base_compile\n\n      if test no != \"$pic_mode\"; then\n\tcommand=\"$base_compile $qsrcfile $pic_flag\"\n      else\n\t# Don't build PIC code\n\tcommand=\"$base_compile $qsrcfile\"\n      fi\n\n      func_mkdir_p \"$xdir$objdir\"\n\n      if test -z \"$output_obj\"; then\n\t# Place PIC objects in $objdir\n\tfunc_append command \" -o $lobj\"\n      fi\n\n      func_show_eval_locale \"$command\"\t\\\n          'test -n \"$output_obj\" && $RM $removelist; exit $EXIT_FAILURE'\n\n      if test warn = \"$need_locks\" &&\n\t test \"X`cat $lockfile 2>/dev/null`\" != \"X$srcfile\"; then\n\t$ECHO \"\\\n*** ERROR, $lockfile contains:\n`cat $lockfile 2>/dev/null`\n\nbut it should contain:\n$srcfile\n\nThis indicates that another process is trying to use the same\ntemporary object file, and libtool could not work around it because\nyour compiler does not support '-c' and '-o' together.  If you\nrepeat this compilation, it may succeed, by chance, but you had better\navoid parallel builds (make -j) in this platform, or get a better\ncompiler.\"\n\n\t$opt_dry_run || $RM $removelist\n\texit $EXIT_FAILURE\n      fi\n\n      # Just move the object if needed, then go on to compile the next one\n      if test -n \"$output_obj\" && test \"X$output_obj\" != \"X$lobj\"; then\n\tfunc_show_eval '$MV \"$output_obj\" \"$lobj\"' \\\n\t  'error=$?; $opt_dry_run || $RM $removelist; exit $error'\n      fi\n\n      # Allow error messages only from the first compilation.\n      if test yes = \"$suppress_opt\"; then\n\tsuppress_output=' >/dev/null 2>&1'\n      fi\n    fi\n\n    # Only build a position-dependent object if we build old libraries.\n    if test yes = \"$build_old_libs\"; then\n      if test yes != \"$pic_mode\"; then\n\t# Don't build PIC code\n\tcommand=\"$base_compile $qsrcfile$pie_flag\"\n      else\n\tcommand=\"$base_compile $qsrcfile $pic_flag\"\n      fi\n      if test yes = \"$compiler_c_o\"; then\n\tfunc_append command \" -o $obj\"\n      fi\n\n      # Suppress compiler output if we already did a PIC compilation.\n      func_append command \"$suppress_output\"\n      func_show_eval_locale \"$command\" \\\n        '$opt_dry_run || $RM $removelist; exit $EXIT_FAILURE'\n\n      if test warn = \"$need_locks\" &&\n\t test \"X`cat $lockfile 2>/dev/null`\" != \"X$srcfile\"; then\n\t$ECHO \"\\\n*** ERROR, $lockfile contains:\n`cat $lockfile 2>/dev/null`\n\nbut it should contain:\n$srcfile\n\nThis indicates that another process is trying to use the same\ntemporary object file, and libtool could not work around it because\nyour compiler does not support '-c' and '-o' together.  If you\nrepeat this compilation, it may succeed, by chance, but you had better\navoid parallel builds (make -j) in this platform, or get a better\ncompiler.\"\n\n\t$opt_dry_run || $RM $removelist\n\texit $EXIT_FAILURE\n      fi\n\n      # Just move the object if needed\n      if test -n \"$output_obj\" && test \"X$output_obj\" != \"X$obj\"; then\n\tfunc_show_eval '$MV \"$output_obj\" \"$obj\"' \\\n\t  'error=$?; $opt_dry_run || $RM $removelist; exit $error'\n      fi\n    fi\n\n    $opt_dry_run || {\n      func_write_libtool_object \"$libobj\" \"$objdir/$objname\" \"$objname\"\n\n      # Unlock the critical section if it was locked\n      if test no != \"$need_locks\"; then\n\tremovelist=$lockfile\n        $RM \"$lockfile\"\n      fi\n    }\n\n    exit $EXIT_SUCCESS\n}\n\n$opt_help || {\n  test compile = \"$opt_mode\" && func_mode_compile ${1+\"$@\"}\n}\n\nfunc_mode_help ()\n{\n    # We need to display help for each of the modes.\n    case $opt_mode in\n      \"\")\n        # Generic help is extracted from the usage comments\n        # at the start of this file.\n        func_help\n        ;;\n\n      clean)\n        $ECHO \\\n\"Usage: $progname [OPTION]... --mode=clean RM [RM-OPTION]... FILE...\n\nRemove files from the build directory.\n\nRM is the name of the program to use to delete files associated with each FILE\n(typically '/bin/rm').  RM-OPTIONS are options (such as '-f') to be passed\nto RM.\n\nIf FILE is a libtool library, object or program, all the files associated\nwith it are deleted. Otherwise, only FILE itself is deleted using RM.\"\n        ;;\n\n      compile)\n      $ECHO \\\n\"Usage: $progname [OPTION]... --mode=compile COMPILE-COMMAND... SOURCEFILE\n\nCompile a source file into a libtool library object.\n\nThis mode accepts the following additional options:\n\n  -o OUTPUT-FILE    set the output file name to OUTPUT-FILE\n  -no-suppress      do not suppress compiler output for multiple passes\n  -prefer-pic       try to build PIC objects only\n  -prefer-non-pic   try to build non-PIC objects only\n  -shared           do not build a '.o' file suitable for static linking\n  -static           only build a '.o' file suitable for static linking\n  -Wc,FLAG          pass FLAG directly to the compiler\n\nCOMPILE-COMMAND is a command to be used in creating a 'standard' object file\nfrom the given SOURCEFILE.\n\nThe output file name is determined by removing the directory component from\nSOURCEFILE, then substituting the C source code suffix '.c' with the\nlibrary object suffix, '.lo'.\"\n        ;;\n\n      execute)\n        $ECHO \\\n\"Usage: $progname [OPTION]... --mode=execute COMMAND [ARGS]...\n\nAutomatically set library path, then run a program.\n\nThis mode accepts the following additional options:\n\n  -dlopen FILE      add the directory containing FILE to the library path\n\nThis mode sets the library path environment variable according to '-dlopen'\nflags.\n\nIf any of the ARGS are libtool executable wrappers, then they are translated\ninto their corresponding uninstalled binary, and any of their required library\ndirectories are added to the library path.\n\nThen, COMMAND is executed, with ARGS as arguments.\"\n        ;;\n\n      finish)\n        $ECHO \\\n\"Usage: $progname [OPTION]... --mode=finish [LIBDIR]...\n\nComplete the installation of libtool libraries.\n\nEach LIBDIR is a directory that contains libtool libraries.\n\nThe commands that this mode executes may require superuser privileges.  Use\nthe '--dry-run' option if you just want to see what would be executed.\"\n        ;;\n\n      install)\n        $ECHO \\\n\"Usage: $progname [OPTION]... --mode=install INSTALL-COMMAND...\n\nInstall executables or libraries.\n\nINSTALL-COMMAND is the installation command.  The first component should be\neither the 'install' or 'cp' program.\n\nThe following components of INSTALL-COMMAND are treated specially:\n\n  -inst-prefix-dir PREFIX-DIR  Use PREFIX-DIR as a staging area for installation\n\nThe rest of the components are interpreted as arguments to that command (only\nBSD-compatible install options are recognized).\"\n        ;;\n\n      link)\n        $ECHO \\\n\"Usage: $progname [OPTION]... --mode=link LINK-COMMAND...\n\nLink object files or libraries together to form another library, or to\ncreate an executable program.\n\nLINK-COMMAND is a command using the C compiler that you would use to create\na program from several object files.\n\nThe following components of LINK-COMMAND are treated specially:\n\n  -all-static       do not do any dynamic linking at all\n  -avoid-version    do not add a version suffix if possible\n  -bindir BINDIR    specify path to binaries directory (for systems where\n                    libraries must be found in the PATH setting at runtime)\n  -dlopen FILE      '-dlpreopen' FILE if it cannot be dlopened at runtime\n  -dlpreopen FILE   link in FILE and add its symbols to lt_preloaded_symbols\n  -export-dynamic   allow symbols from OUTPUT-FILE to be resolved with dlsym(3)\n  -export-symbols SYMFILE\n                    try to export only the symbols listed in SYMFILE\n  -export-symbols-regex REGEX\n                    try to export only the symbols matching REGEX\n  -LLIBDIR          search LIBDIR for required installed libraries\n  -lNAME            OUTPUT-FILE requires the installed library libNAME\n  -module           build a library that can dlopened\n  -no-fast-install  disable the fast-install mode\n  -no-install       link a not-installable executable\n  -no-undefined     declare that a library does not refer to external symbols\n  -o OUTPUT-FILE    create OUTPUT-FILE from the specified objects\n  -objectlist FILE  use a list of object files found in FILE to specify objects\n  -os2dllname NAME  force a short DLL name on OS/2 (no effect on other OSes)\n  -precious-files-regex REGEX\n                    don't remove output files matching REGEX\n  -release RELEASE  specify package release information\n  -rpath LIBDIR     the created library will eventually be installed in LIBDIR\n  -R[ ]LIBDIR       add LIBDIR to the runtime path of programs and libraries\n  -shared           only do dynamic linking of libtool libraries\n  -shrext SUFFIX    override the standard shared library file extension\n  -static           do not do any dynamic linking of uninstalled libtool libraries\n  -static-libtool-libs\n                    do not do any dynamic linking of libtool libraries\n  -version-info CURRENT[:REVISION[:AGE]]\n                    specify library version info [each variable defaults to 0]\n  -weak LIBNAME     declare that the target provides the LIBNAME interface\n  -Wc,FLAG\n  -Xcompiler FLAG   pass linker-specific FLAG directly to the compiler\n  -Wl,FLAG\n  -Xlinker FLAG     pass linker-specific FLAG directly to the linker\n  -XCClinker FLAG   pass link-specific FLAG to the compiler driver (CC)\n\nAll other options (arguments beginning with '-') are ignored.\n\nEvery other argument is treated as a filename.  Files ending in '.la' are\ntreated as uninstalled libtool libraries, other files are standard or library\nobject files.\n\nIf the OUTPUT-FILE ends in '.la', then a libtool library is created,\nonly library objects ('.lo' files) may be specified, and '-rpath' is\nrequired, except when creating a convenience library.\n\nIf OUTPUT-FILE ends in '.a' or '.lib', then a standard library is created\nusing 'ar' and 'ranlib', or on Windows using 'lib'.\n\nIf OUTPUT-FILE ends in '.lo' or '.$objext', then a reloadable object file\nis created, otherwise an executable program is created.\"\n        ;;\n\n      uninstall)\n        $ECHO \\\n\"Usage: $progname [OPTION]... --mode=uninstall RM [RM-OPTION]... FILE...\n\nRemove libraries from an installation directory.\n\nRM is the name of the program to use to delete files associated with each FILE\n(typically '/bin/rm').  RM-OPTIONS are options (such as '-f') to be passed\nto RM.\n\nIf FILE is a libtool library, all the files associated with it are deleted.\nOtherwise, only FILE itself is deleted using RM.\"\n        ;;\n\n      *)\n        func_fatal_help \"invalid operation mode '$opt_mode'\"\n        ;;\n    esac\n\n    echo\n    $ECHO \"Try '$progname --help' for more information about other modes.\"\n}\n\n# Now that we've collected a possible --mode arg, show help if necessary\nif $opt_help; then\n  if test : = \"$opt_help\"; then\n    func_mode_help\n  else\n    {\n      func_help noexit\n      for opt_mode in compile link execute install finish uninstall clean; do\n\tfunc_mode_help\n      done\n    } | $SED -n '1p; 2,$s/^Usage:/  or: /p'\n    {\n      func_help noexit\n      for opt_mode in compile link execute install finish uninstall clean; do\n\techo\n\tfunc_mode_help\n      done\n    } |\n    $SED '1d\n      /^When reporting/,/^Report/{\n\tH\n\td\n      }\n      $x\n      /information about other modes/d\n      /more detailed .*MODE/d\n      s/^Usage:.*--mode=\\([^ ]*\\) .*/Description of \\1 mode:/'\n  fi\n  exit $?\nfi\n\n\n# func_mode_execute arg...\nfunc_mode_execute ()\n{\n    $debug_cmd\n\n    # The first argument is the command name.\n    cmd=$nonopt\n    test -z \"$cmd\" && \\\n      func_fatal_help \"you must specify a COMMAND\"\n\n    # Handle -dlopen flags immediately.\n    for file in $opt_dlopen; do\n      test -f \"$file\" \\\n\t|| func_fatal_help \"'$file' is not a file\"\n\n      dir=\n      case $file in\n      *.la)\n\tfunc_resolve_sysroot \"$file\"\n\tfile=$func_resolve_sysroot_result\n\n\t# Check to see that this really is a libtool archive.\n\tfunc_lalib_unsafe_p \"$file\" \\\n\t  || func_fatal_help \"'$lib' is not a valid libtool archive\"\n\n\t# Read the libtool library.\n\tdlname=\n\tlibrary_names=\n\tfunc_source \"$file\"\n\n\t# Skip this library if it cannot be dlopened.\n\tif test -z \"$dlname\"; then\n\t  # Warn if it was a shared library.\n\t  test -n \"$library_names\" && \\\n\t    func_warning \"'$file' was not linked with '-export-dynamic'\"\n\t  continue\n\tfi\n\n\tfunc_dirname \"$file\" \"\" \".\"\n\tdir=$func_dirname_result\n\n\tif test -f \"$dir/$objdir/$dlname\"; then\n\t  func_append dir \"/$objdir\"\n\telse\n\t  if test ! -f \"$dir/$dlname\"; then\n\t    func_fatal_error \"cannot find '$dlname' in '$dir' or '$dir/$objdir'\"\n\t  fi\n\tfi\n\t;;\n\n      *.lo)\n\t# Just add the directory containing the .lo file.\n\tfunc_dirname \"$file\" \"\" \".\"\n\tdir=$func_dirname_result\n\t;;\n\n      *)\n\tfunc_warning \"'-dlopen' is ignored for non-libtool libraries and objects\"\n\tcontinue\n\t;;\n      esac\n\n      # Get the absolute pathname.\n      absdir=`cd \"$dir\" && pwd`\n      test -n \"$absdir\" && dir=$absdir\n\n      # Now add the directory to shlibpath_var.\n      if eval \"test -z \\\"\\$$shlibpath_var\\\"\"; then\n\teval \"$shlibpath_var=\\\"\\$dir\\\"\"\n      else\n\teval \"$shlibpath_var=\\\"\\$dir:\\$$shlibpath_var\\\"\"\n      fi\n    done\n\n    # This variable tells wrapper scripts just to set shlibpath_var\n    # rather than running their programs.\n    libtool_execute_magic=$magic\n\n    # Check if any of the arguments is a wrapper script.\n    args=\n    for file\n    do\n      case $file in\n      -* | *.la | *.lo ) ;;\n      *)\n\t# Do a test to see if this is really a libtool program.\n\tif func_ltwrapper_script_p \"$file\"; then\n\t  func_source \"$file\"\n\t  # Transform arg to wrapped name.\n\t  file=$progdir/$program\n\telif func_ltwrapper_executable_p \"$file\"; then\n\t  func_ltwrapper_scriptname \"$file\"\n\t  func_source \"$func_ltwrapper_scriptname_result\"\n\t  # Transform arg to wrapped name.\n\t  file=$progdir/$program\n\tfi\n\t;;\n      esac\n      # Quote arguments (to preserve shell metacharacters).\n      func_append_quoted args \"$file\"\n    done\n\n    if $opt_dry_run; then\n      # Display what would be done.\n      if test -n \"$shlibpath_var\"; then\n\teval \"\\$ECHO \\\"\\$shlibpath_var=\\$$shlibpath_var\\\"\"\n\techo \"export $shlibpath_var\"\n      fi\n      $ECHO \"$cmd$args\"\n      exit $EXIT_SUCCESS\n    else\n      if test -n \"$shlibpath_var\"; then\n\t# Export the shlibpath_var.\n\teval \"export $shlibpath_var\"\n      fi\n\n      # Restore saved environment variables\n      for lt_var in LANG LANGUAGE LC_ALL LC_CTYPE LC_COLLATE LC_MESSAGES\n      do\n\teval \"if test \\\"\\${save_$lt_var+set}\\\" = set; then\n                $lt_var=\\$save_$lt_var; export $lt_var\n\t      else\n\t\t$lt_unset $lt_var\n\t      fi\"\n      done\n\n      # Now prepare to actually exec the command.\n      exec_cmd=\\$cmd$args\n    fi\n}\n\ntest execute = \"$opt_mode\" && func_mode_execute ${1+\"$@\"}\n\n\n# func_mode_finish arg...\nfunc_mode_finish ()\n{\n    $debug_cmd\n\n    libs=\n    libdirs=\n    admincmds=\n\n    for opt in \"$nonopt\" ${1+\"$@\"}\n    do\n      if test -d \"$opt\"; then\n\tfunc_append libdirs \" $opt\"\n\n      elif test -f \"$opt\"; then\n\tif func_lalib_unsafe_p \"$opt\"; then\n\t  func_append libs \" $opt\"\n\telse\n\t  func_warning \"'$opt' is not a valid libtool archive\"\n\tfi\n\n      else\n\tfunc_fatal_error \"invalid argument '$opt'\"\n      fi\n    done\n\n    if test -n \"$libs\"; then\n      if test -n \"$lt_sysroot\"; then\n        sysroot_regex=`$ECHO \"$lt_sysroot\" | $SED \"$sed_make_literal_regex\"`\n        sysroot_cmd=\"s/\\([ ']\\)$sysroot_regex/\\1/g;\"\n      else\n        sysroot_cmd=\n      fi\n\n      # Remove sysroot references\n      if $opt_dry_run; then\n        for lib in $libs; do\n          echo \"removing references to $lt_sysroot and '=' prefixes from $lib\"\n        done\n      else\n        tmpdir=`func_mktempdir`\n        for lib in $libs; do\n\t  $SED -e \"$sysroot_cmd s/\\([ ']-[LR]\\)=/\\1/g; s/\\([ ']\\)=/\\1/g\" $lib \\\n\t    > $tmpdir/tmp-la\n\t  mv -f $tmpdir/tmp-la $lib\n\tdone\n        ${RM}r \"$tmpdir\"\n      fi\n    fi\n\n    if test -n \"$finish_cmds$finish_eval\" && test -n \"$libdirs\"; then\n      for libdir in $libdirs; do\n\tif test -n \"$finish_cmds\"; then\n\t  # Do each command in the finish commands.\n\t  func_execute_cmds \"$finish_cmds\" 'admincmds=\"$admincmds\n'\"$cmd\"'\"'\n\tfi\n\tif test -n \"$finish_eval\"; then\n\t  # Do the single finish_eval.\n\t  eval cmds=\\\"$finish_eval\\\"\n\t  $opt_dry_run || eval \"$cmds\" || func_append admincmds \"\n       $cmds\"\n\tfi\n      done\n    fi\n\n    # Exit here if they wanted silent mode.\n    $opt_quiet && exit $EXIT_SUCCESS\n\n    if test -n \"$finish_cmds$finish_eval\" && test -n \"$libdirs\"; then\n      echo \"----------------------------------------------------------------------\"\n      echo \"Libraries have been installed in:\"\n      for libdir in $libdirs; do\n\t$ECHO \"   $libdir\"\n      done\n      echo\n      echo \"If you ever happen to want to link against installed libraries\"\n      echo \"in a given directory, LIBDIR, you must either use libtool, and\"\n      echo \"specify the full pathname of the library, or use the '-LLIBDIR'\"\n      echo \"flag during linking and do at least one of the following:\"\n      if test -n \"$shlibpath_var\"; then\n\techo \"   - add LIBDIR to the '$shlibpath_var' environment variable\"\n\techo \"     during execution\"\n      fi\n      if test -n \"$runpath_var\"; then\n\techo \"   - add LIBDIR to the '$runpath_var' environment variable\"\n\techo \"     during linking\"\n      fi\n      if test -n \"$hardcode_libdir_flag_spec\"; then\n\tlibdir=LIBDIR\n\teval flag=\\\"$hardcode_libdir_flag_spec\\\"\n\n\t$ECHO \"   - use the '$flag' linker flag\"\n      fi\n      if test -n \"$admincmds\"; then\n\t$ECHO \"   - have your system administrator run these commands:$admincmds\"\n      fi\n      if test -f /etc/ld.so.conf; then\n\techo \"   - have your system administrator add LIBDIR to '/etc/ld.so.conf'\"\n      fi\n      echo\n\n      echo \"See any operating system documentation about shared libraries for\"\n      case $host in\n\tsolaris2.[6789]|solaris2.1[0-9])\n\t  echo \"more information, such as the ld(1), crle(1) and ld.so(8) manual\"\n\t  echo \"pages.\"\n\t  ;;\n\t*)\n\t  echo \"more information, such as the ld(1) and ld.so(8) manual pages.\"\n\t  ;;\n      esac\n      echo \"----------------------------------------------------------------------\"\n    fi\n    exit $EXIT_SUCCESS\n}\n\ntest finish = \"$opt_mode\" && func_mode_finish ${1+\"$@\"}\n\n\n# func_mode_install arg...\nfunc_mode_install ()\n{\n    $debug_cmd\n\n    # There may be an optional sh(1) argument at the beginning of\n    # install_prog (especially on Windows NT).\n    if test \"$SHELL\" = \"$nonopt\" || test /bin/sh = \"$nonopt\" ||\n       # Allow the use of GNU shtool's install command.\n       case $nonopt in *shtool*) :;; *) false;; esac\n    then\n      # Aesthetically quote it.\n      func_quote_for_eval \"$nonopt\"\n      install_prog=\"$func_quote_for_eval_result \"\n      arg=$1\n      shift\n    else\n      install_prog=\n      arg=$nonopt\n    fi\n\n    # The real first argument should be the name of the installation program.\n    # Aesthetically quote it.\n    func_quote_for_eval \"$arg\"\n    func_append install_prog \"$func_quote_for_eval_result\"\n    install_shared_prog=$install_prog\n    case \" $install_prog \" in\n      *[\\\\\\ /]cp\\ *) install_cp=: ;;\n      *) install_cp=false ;;\n    esac\n\n    # We need to accept at least all the BSD install flags.\n    dest=\n    files=\n    opts=\n    prev=\n    install_type=\n    isdir=false\n    stripme=\n    no_mode=:\n    for arg\n    do\n      arg2=\n      if test -n \"$dest\"; then\n\tfunc_append files \" $dest\"\n\tdest=$arg\n\tcontinue\n      fi\n\n      case $arg in\n      -d) isdir=: ;;\n      -f)\n\tif $install_cp; then :; else\n\t  prev=$arg\n\tfi\n\t;;\n      -g | -m | -o)\n\tprev=$arg\n\t;;\n      -s)\n\tstripme=\" -s\"\n\tcontinue\n\t;;\n      -*)\n\t;;\n      *)\n\t# If the previous option needed an argument, then skip it.\n\tif test -n \"$prev\"; then\n\t  if test X-m = \"X$prev\" && test -n \"$install_override_mode\"; then\n\t    arg2=$install_override_mode\n\t    no_mode=false\n\t  fi\n\t  prev=\n\telse\n\t  dest=$arg\n\t  continue\n\tfi\n\t;;\n      esac\n\n      # Aesthetically quote the argument.\n      func_quote_for_eval \"$arg\"\n      func_append install_prog \" $func_quote_for_eval_result\"\n      if test -n \"$arg2\"; then\n\tfunc_quote_for_eval \"$arg2\"\n      fi\n      func_append install_shared_prog \" $func_quote_for_eval_result\"\n    done\n\n    test -z \"$install_prog\" && \\\n      func_fatal_help \"you must specify an install program\"\n\n    test -n \"$prev\" && \\\n      func_fatal_help \"the '$prev' option requires an argument\"\n\n    if test -n \"$install_override_mode\" && $no_mode; then\n      if $install_cp; then :; else\n\tfunc_quote_for_eval \"$install_override_mode\"\n\tfunc_append install_shared_prog \" -m $func_quote_for_eval_result\"\n      fi\n    fi\n\n    if test -z \"$files\"; then\n      if test -z \"$dest\"; then\n\tfunc_fatal_help \"no file or destination specified\"\n      else\n\tfunc_fatal_help \"you must specify a destination\"\n      fi\n    fi\n\n    # Strip any trailing slash from the destination.\n    func_stripname '' '/' \"$dest\"\n    dest=$func_stripname_result\n\n    # Check to see that the destination is a directory.\n    test -d \"$dest\" && isdir=:\n    if $isdir; then\n      destdir=$dest\n      destname=\n    else\n      func_dirname_and_basename \"$dest\" \"\" \".\"\n      destdir=$func_dirname_result\n      destname=$func_basename_result\n\n      # Not a directory, so check to see that there is only one file specified.\n      set dummy $files; shift\n      test \"$#\" -gt 1 && \\\n\tfunc_fatal_help \"'$dest' is not a directory\"\n    fi\n    case $destdir in\n    [\\\\/]* | [A-Za-z]:[\\\\/]*) ;;\n    *)\n      for file in $files; do\n\tcase $file in\n\t*.lo) ;;\n\t*)\n\t  func_fatal_help \"'$destdir' must be an absolute directory name\"\n\t  ;;\n\tesac\n      done\n      ;;\n    esac\n\n    # This variable tells wrapper scripts just to set variables rather\n    # than running their programs.\n    libtool_install_magic=$magic\n\n    staticlibs=\n    future_libdirs=\n    current_libdirs=\n    for file in $files; do\n\n      # Do each installation.\n      case $file in\n      *.$libext)\n\t# Do the static libraries later.\n\tfunc_append staticlibs \" $file\"\n\t;;\n\n      *.la)\n\tfunc_resolve_sysroot \"$file\"\n\tfile=$func_resolve_sysroot_result\n\n\t# Check to see that this really is a libtool archive.\n\tfunc_lalib_unsafe_p \"$file\" \\\n\t  || func_fatal_help \"'$file' is not a valid libtool archive\"\n\n\tlibrary_names=\n\told_library=\n\trelink_command=\n\tfunc_source \"$file\"\n\n\t# Add the libdir to current_libdirs if it is the destination.\n\tif test \"X$destdir\" = \"X$libdir\"; then\n\t  case \"$current_libdirs \" in\n\t  *\" $libdir \"*) ;;\n\t  *) func_append current_libdirs \" $libdir\" ;;\n\t  esac\n\telse\n\t  # Note the libdir as a future libdir.\n\t  case \"$future_libdirs \" in\n\t  *\" $libdir \"*) ;;\n\t  *) func_append future_libdirs \" $libdir\" ;;\n\t  esac\n\tfi\n\n\tfunc_dirname \"$file\" \"/\" \"\"\n\tdir=$func_dirname_result\n\tfunc_append dir \"$objdir\"\n\n\tif test -n \"$relink_command\"; then\n\t  # Determine the prefix the user has applied to our future dir.\n\t  inst_prefix_dir=`$ECHO \"$destdir\" | $SED -e \"s%$libdir\\$%%\"`\n\n\t  # Don't allow the user to place us outside of our expected\n\t  # location b/c this prevents finding dependent libraries that\n\t  # are installed to the same prefix.\n\t  # At present, this check doesn't affect windows .dll's that\n\t  # are installed into $libdir/../bin (currently, that works fine)\n\t  # but it's something to keep an eye on.\n\t  test \"$inst_prefix_dir\" = \"$destdir\" && \\\n\t    func_fatal_error \"error: cannot install '$file' to a directory not ending in $libdir\"\n\n\t  if test -n \"$inst_prefix_dir\"; then\n\t    # Stick the inst_prefix_dir data into the link command.\n\t    relink_command=`$ECHO \"$relink_command\" | $SED \"s%@inst_prefix_dir@%-inst-prefix-dir $inst_prefix_dir%\"`\n\t  else\n\t    relink_command=`$ECHO \"$relink_command\" | $SED \"s%@inst_prefix_dir@%%\"`\n\t  fi\n\n\t  func_warning \"relinking '$file'\"\n\t  func_show_eval \"$relink_command\" \\\n\t    'func_fatal_error \"error: relink '\\''$file'\\'' with the above command before installing it\"'\n\tfi\n\n\t# See the names of the shared library.\n\tset dummy $library_names; shift\n\tif test -n \"$1\"; then\n\t  realname=$1\n\t  shift\n\n\t  srcname=$realname\n\t  test -n \"$relink_command\" && srcname=${realname}T\n\n\t  # Install the shared library and build the symlinks.\n\t  func_show_eval \"$install_shared_prog $dir/$srcname $destdir/$realname\" \\\n\t      'exit $?'\n\t  tstripme=$stripme\n\t  case $host_os in\n\t  cygwin* | mingw* | pw32* | cegcc*)\n\t    case $realname in\n\t    *.dll.a)\n\t      tstripme=\n\t      ;;\n\t    esac\n\t    ;;\n\t  os2*)\n\t    case $realname in\n\t    *_dll.a)\n\t      tstripme=\n\t      ;;\n\t    esac\n\t    ;;\n\t  esac\n\t  if test -n \"$tstripme\" && test -n \"$striplib\"; then\n\t    func_show_eval \"$striplib $destdir/$realname\" 'exit $?'\n\t  fi\n\n\t  if test \"$#\" -gt 0; then\n\t    # Delete the old symlinks, and create new ones.\n\t    # Try 'ln -sf' first, because the 'ln' binary might depend on\n\t    # the symlink we replace!  Solaris /bin/ln does not understand -f,\n\t    # so we also need to try rm && ln -s.\n\t    for linkname\n\t    do\n\t      test \"$linkname\" != \"$realname\" \\\n\t\t&& func_show_eval \"(cd $destdir && { $LN_S -f $realname $linkname || { $RM $linkname && $LN_S $realname $linkname; }; })\"\n\t    done\n\t  fi\n\n\t  # Do each command in the postinstall commands.\n\t  lib=$destdir/$realname\n\t  func_execute_cmds \"$postinstall_cmds\" 'exit $?'\n\tfi\n\n\t# Install the pseudo-library for information purposes.\n\tfunc_basename \"$file\"\n\tname=$func_basename_result\n\tinstname=$dir/${name}i\n\tfunc_show_eval \"$install_prog $instname $destdir/$name\" 'exit $?'\n\n\t# Maybe install the static library, too.\n\ttest -n \"$old_library\" && func_append staticlibs \" $dir/$old_library\"\n\t;;\n\n      *.lo)\n\t# Install (i.e. copy) a libtool object.\n\n\t# Figure out destination file name, if it wasn't already specified.\n\tif test -n \"$destname\"; then\n\t  destfile=$destdir/$destname\n\telse\n\t  func_basename \"$file\"\n\t  destfile=$func_basename_result\n\t  destfile=$destdir/$destfile\n\tfi\n\n\t# Deduce the name of the destination old-style object file.\n\tcase $destfile in\n\t*.lo)\n\t  func_lo2o \"$destfile\"\n\t  staticdest=$func_lo2o_result\n\t  ;;\n\t*.$objext)\n\t  staticdest=$destfile\n\t  destfile=\n\t  ;;\n\t*)\n\t  func_fatal_help \"cannot copy a libtool object to '$destfile'\"\n\t  ;;\n\tesac\n\n\t# Install the libtool object if requested.\n\ttest -n \"$destfile\" && \\\n\t  func_show_eval \"$install_prog $file $destfile\" 'exit $?'\n\n\t# Install the old object if enabled.\n\tif test yes = \"$build_old_libs\"; then\n\t  # Deduce the name of the old-style object file.\n\t  func_lo2o \"$file\"\n\t  staticobj=$func_lo2o_result\n\t  func_show_eval \"$install_prog \\$staticobj \\$staticdest\" 'exit $?'\n\tfi\n\texit $EXIT_SUCCESS\n\t;;\n\n      *)\n\t# Figure out destination file name, if it wasn't already specified.\n\tif test -n \"$destname\"; then\n\t  destfile=$destdir/$destname\n\telse\n\t  func_basename \"$file\"\n\t  destfile=$func_basename_result\n\t  destfile=$destdir/$destfile\n\tfi\n\n\t# If the file is missing, and there is a .exe on the end, strip it\n\t# because it is most likely a libtool script we actually want to\n\t# install\n\tstripped_ext=\n\tcase $file in\n\t  *.exe)\n\t    if test ! -f \"$file\"; then\n\t      func_stripname '' '.exe' \"$file\"\n\t      file=$func_stripname_result\n\t      stripped_ext=.exe\n\t    fi\n\t    ;;\n\tesac\n\n\t# Do a test to see if this is really a libtool program.\n\tcase $host in\n\t*cygwin* | *mingw*)\n\t    if func_ltwrapper_executable_p \"$file\"; then\n\t      func_ltwrapper_scriptname \"$file\"\n\t      wrapper=$func_ltwrapper_scriptname_result\n\t    else\n\t      func_stripname '' '.exe' \"$file\"\n\t      wrapper=$func_stripname_result\n\t    fi\n\t    ;;\n\t*)\n\t    wrapper=$file\n\t    ;;\n\tesac\n\tif func_ltwrapper_script_p \"$wrapper\"; then\n\t  notinst_deplibs=\n\t  relink_command=\n\n\t  func_source \"$wrapper\"\n\n\t  # Check the variables that should have been set.\n\t  test -z \"$generated_by_libtool_version\" && \\\n\t    func_fatal_error \"invalid libtool wrapper script '$wrapper'\"\n\n\t  finalize=:\n\t  for lib in $notinst_deplibs; do\n\t    # Check to see that each library is installed.\n\t    libdir=\n\t    if test -f \"$lib\"; then\n\t      func_source \"$lib\"\n\t    fi\n\t    libfile=$libdir/`$ECHO \"$lib\" | $SED 's%^.*/%%g'`\n\t    if test -n \"$libdir\" && test ! -f \"$libfile\"; then\n\t      func_warning \"'$lib' has not been installed in '$libdir'\"\n\t      finalize=false\n\t    fi\n\t  done\n\n\t  relink_command=\n\t  func_source \"$wrapper\"\n\n\t  outputname=\n\t  if test no = \"$fast_install\" && test -n \"$relink_command\"; then\n\t    $opt_dry_run || {\n\t      if $finalize; then\n\t        tmpdir=`func_mktempdir`\n\t\tfunc_basename \"$file$stripped_ext\"\n\t\tfile=$func_basename_result\n\t        outputname=$tmpdir/$file\n\t        # Replace the output file specification.\n\t        relink_command=`$ECHO \"$relink_command\" | $SED 's%@OUTPUT@%'\"$outputname\"'%g'`\n\n\t        $opt_quiet || {\n\t          func_quote_for_expand \"$relink_command\"\n\t\t  eval \"func_echo $func_quote_for_expand_result\"\n\t        }\n\t        if eval \"$relink_command\"; then :\n\t          else\n\t\t  func_error \"error: relink '$file' with the above command before installing it\"\n\t\t  $opt_dry_run || ${RM}r \"$tmpdir\"\n\t\t  continue\n\t        fi\n\t        file=$outputname\n\t      else\n\t        func_warning \"cannot relink '$file'\"\n\t      fi\n\t    }\n\t  else\n\t    # Install the binary that we compiled earlier.\n\t    file=`$ECHO \"$file$stripped_ext\" | $SED \"s%\\([^/]*\\)$%$objdir/\\1%\"`\n\t  fi\n\tfi\n\n\t# remove .exe since cygwin /usr/bin/install will append another\n\t# one anyway\n\tcase $install_prog,$host in\n\t*/usr/bin/install*,*cygwin*)\n\t  case $file:$destfile in\n\t  *.exe:*.exe)\n\t    # this is ok\n\t    ;;\n\t  *.exe:*)\n\t    destfile=$destfile.exe\n\t    ;;\n\t  *:*.exe)\n\t    func_stripname '' '.exe' \"$destfile\"\n\t    destfile=$func_stripname_result\n\t    ;;\n\t  esac\n\t  ;;\n\tesac\n\tfunc_show_eval \"$install_prog\\$stripme \\$file \\$destfile\" 'exit $?'\n\t$opt_dry_run || if test -n \"$outputname\"; then\n\t  ${RM}r \"$tmpdir\"\n\tfi\n\t;;\n      esac\n    done\n\n    for file in $staticlibs; do\n      func_basename \"$file\"\n      name=$func_basename_result\n\n      # Set up the ranlib parameters.\n      oldlib=$destdir/$name\n      func_to_tool_file \"$oldlib\" func_convert_file_msys_to_w32\n      tool_oldlib=$func_to_tool_file_result\n\n      func_show_eval \"$install_prog \\$file \\$oldlib\" 'exit $?'\n\n      if test -n \"$stripme\" && test -n \"$old_striplib\"; then\n\tfunc_show_eval \"$old_striplib $tool_oldlib\" 'exit $?'\n      fi\n\n      # Do each command in the postinstall commands.\n      func_execute_cmds \"$old_postinstall_cmds\" 'exit $?'\n    done\n\n    test -n \"$future_libdirs\" && \\\n      func_warning \"remember to run '$progname --finish$future_libdirs'\"\n\n    if test -n \"$current_libdirs\"; then\n      # Maybe just do a dry run.\n      $opt_dry_run && current_libdirs=\" -n$current_libdirs\"\n      exec_cmd='$SHELL \"$progpath\" $preserve_args --finish$current_libdirs'\n    else\n      exit $EXIT_SUCCESS\n    fi\n}\n\ntest install = \"$opt_mode\" && func_mode_install ${1+\"$@\"}\n\n\n# func_generate_dlsyms outputname originator pic_p\n# Extract symbols from dlprefiles and create ${outputname}S.o with\n# a dlpreopen symbol table.\nfunc_generate_dlsyms ()\n{\n    $debug_cmd\n\n    my_outputname=$1\n    my_originator=$2\n    my_pic_p=${3-false}\n    my_prefix=`$ECHO \"$my_originator\" | $SED 's%[^a-zA-Z0-9]%_%g'`\n    my_dlsyms=\n\n    if test -n \"$dlfiles$dlprefiles\" || test no != \"$dlself\"; then\n      if test -n \"$NM\" && test -n \"$global_symbol_pipe\"; then\n\tmy_dlsyms=${my_outputname}S.c\n      else\n\tfunc_error \"not configured to extract global symbols from dlpreopened files\"\n      fi\n    fi\n\n    if test -n \"$my_dlsyms\"; then\n      case $my_dlsyms in\n      \"\") ;;\n      *.c)\n\t# Discover the nlist of each of the dlfiles.\n\tnlist=$output_objdir/$my_outputname.nm\n\n\tfunc_show_eval \"$RM $nlist ${nlist}S ${nlist}T\"\n\n\t# Parse the name list into a source file.\n\tfunc_verbose \"creating $output_objdir/$my_dlsyms\"\n\n\t$opt_dry_run || $ECHO > \"$output_objdir/$my_dlsyms\" \"\\\n/* $my_dlsyms - symbol resolution table for '$my_outputname' dlsym emulation. */\n/* Generated by $PROGRAM (GNU $PACKAGE) $VERSION */\n\n#ifdef __cplusplus\nextern \\\"C\\\" {\n#endif\n\n#if defined __GNUC__ && (((__GNUC__ == 4) && (__GNUC_MINOR__ >= 4)) || (__GNUC__ > 4))\n#pragma GCC diagnostic ignored \\\"-Wstrict-prototypes\\\"\n#endif\n\n/* Keep this code in sync between libtool.m4, ltmain, lt_system.h, and tests.  */\n#if defined _WIN32 || defined __CYGWIN__ || defined _WIN32_WCE\n/* DATA imports from DLLs on WIN32 can't be const, because runtime\n   relocations are performed -- see ld's documentation on pseudo-relocs.  */\n# define LT_DLSYM_CONST\n#elif defined __osf__\n/* This system does not cope well with relocations in const data.  */\n# define LT_DLSYM_CONST\n#else\n# define LT_DLSYM_CONST const\n#endif\n\n#define STREQ(s1, s2) (strcmp ((s1), (s2)) == 0)\n\n/* External symbol declarations for the compiler. */\\\n\"\n\n\tif test yes = \"$dlself\"; then\n\t  func_verbose \"generating symbol list for '$output'\"\n\n\t  $opt_dry_run || echo ': @PROGRAM@ ' > \"$nlist\"\n\n\t  # Add our own program objects to the symbol list.\n\t  progfiles=`$ECHO \"$objs$old_deplibs\" | $SP2NL | $SED \"$lo2o\" | $NL2SP`\n\t  for progfile in $progfiles; do\n\t    func_to_tool_file \"$progfile\" func_convert_file_msys_to_w32\n\t    func_verbose \"extracting global C symbols from '$func_to_tool_file_result'\"\n\t    $opt_dry_run || eval \"$NM $func_to_tool_file_result | $global_symbol_pipe >> '$nlist'\"\n\t  done\n\n\t  if test -n \"$exclude_expsyms\"; then\n\t    $opt_dry_run || {\n\t      eval '$EGREP -v \" ($exclude_expsyms)$\" \"$nlist\" > \"$nlist\"T'\n\t      eval '$MV \"$nlist\"T \"$nlist\"'\n\t    }\n\t  fi\n\n\t  if test -n \"$export_symbols_regex\"; then\n\t    $opt_dry_run || {\n\t      eval '$EGREP -e \"$export_symbols_regex\" \"$nlist\" > \"$nlist\"T'\n\t      eval '$MV \"$nlist\"T \"$nlist\"'\n\t    }\n\t  fi\n\n\t  # Prepare the list of exported symbols\n\t  if test -z \"$export_symbols\"; then\n\t    export_symbols=$output_objdir/$outputname.exp\n\t    $opt_dry_run || {\n\t      $RM $export_symbols\n\t      eval \"$SED -n -e '/^: @PROGRAM@ $/d' -e 's/^.* \\(.*\\)$/\\1/p' \"'< \"$nlist\" > \"$export_symbols\"'\n\t      case $host in\n\t      *cygwin* | *mingw* | *cegcc* )\n                eval \"echo EXPORTS \"'> \"$output_objdir/$outputname.def\"'\n                eval 'cat \"$export_symbols\" >> \"$output_objdir/$outputname.def\"'\n\t        ;;\n\t      esac\n\t    }\n\t  else\n\t    $opt_dry_run || {\n\t      eval \"$SED -e 's/\\([].[*^$]\\)/\\\\\\\\\\1/g' -e 's/^/ /' -e 's/$/$/'\"' < \"$export_symbols\" > \"$output_objdir/$outputname.exp\"'\n\t      eval '$GREP -f \"$output_objdir/$outputname.exp\" < \"$nlist\" > \"$nlist\"T'\n\t      eval '$MV \"$nlist\"T \"$nlist\"'\n\t      case $host in\n\t        *cygwin* | *mingw* | *cegcc* )\n\t          eval \"echo EXPORTS \"'> \"$output_objdir/$outputname.def\"'\n\t          eval 'cat \"$nlist\" >> \"$output_objdir/$outputname.def\"'\n\t          ;;\n\t      esac\n\t    }\n\t  fi\n\tfi\n\n\tfor dlprefile in $dlprefiles; do\n\t  func_verbose \"extracting global C symbols from '$dlprefile'\"\n\t  func_basename \"$dlprefile\"\n\t  name=$func_basename_result\n          case $host in\n\t    *cygwin* | *mingw* | *cegcc* )\n\t      # if an import library, we need to obtain dlname\n\t      if func_win32_import_lib_p \"$dlprefile\"; then\n\t        func_tr_sh \"$dlprefile\"\n\t        eval \"curr_lafile=\\$libfile_$func_tr_sh_result\"\n\t        dlprefile_dlbasename=\n\t        if test -n \"$curr_lafile\" && func_lalib_p \"$curr_lafile\"; then\n\t          # Use subshell, to avoid clobbering current variable values\n\t          dlprefile_dlname=`source \"$curr_lafile\" && echo \"$dlname\"`\n\t          if test -n \"$dlprefile_dlname\"; then\n\t            func_basename \"$dlprefile_dlname\"\n\t            dlprefile_dlbasename=$func_basename_result\n\t          else\n\t            # no lafile. user explicitly requested -dlpreopen <import library>.\n\t            $sharedlib_from_linklib_cmd \"$dlprefile\"\n\t            dlprefile_dlbasename=$sharedlib_from_linklib_result\n\t          fi\n\t        fi\n\t        $opt_dry_run || {\n\t          if test -n \"$dlprefile_dlbasename\"; then\n\t            eval '$ECHO \": $dlprefile_dlbasename\" >> \"$nlist\"'\n\t          else\n\t            func_warning \"Could not compute DLL name from $name\"\n\t            eval '$ECHO \": $name \" >> \"$nlist\"'\n\t          fi\n\t          func_to_tool_file \"$dlprefile\" func_convert_file_msys_to_w32\n\t          eval \"$NM \\\"$func_to_tool_file_result\\\" 2>/dev/null | $global_symbol_pipe |\n\t            $SED -e '/I __imp/d' -e 's/I __nm_/D /;s/_nm__//' >> '$nlist'\"\n\t        }\n\t      else # not an import lib\n\t        $opt_dry_run || {\n\t          eval '$ECHO \": $name \" >> \"$nlist\"'\n\t          func_to_tool_file \"$dlprefile\" func_convert_file_msys_to_w32\n\t          eval \"$NM \\\"$func_to_tool_file_result\\\" 2>/dev/null | $global_symbol_pipe >> '$nlist'\"\n\t        }\n\t      fi\n\t    ;;\n\t    *)\n\t      $opt_dry_run || {\n\t        eval '$ECHO \": $name \" >> \"$nlist\"'\n\t        func_to_tool_file \"$dlprefile\" func_convert_file_msys_to_w32\n\t        eval \"$NM \\\"$func_to_tool_file_result\\\" 2>/dev/null | $global_symbol_pipe >> '$nlist'\"\n\t      }\n\t    ;;\n          esac\n\tdone\n\n\t$opt_dry_run || {\n\t  # Make sure we have at least an empty file.\n\t  test -f \"$nlist\" || : > \"$nlist\"\n\n\t  if test -n \"$exclude_expsyms\"; then\n\t    $EGREP -v \" ($exclude_expsyms)$\" \"$nlist\" > \"$nlist\"T\n\t    $MV \"$nlist\"T \"$nlist\"\n\t  fi\n\n\t  # Try sorting and uniquifying the output.\n\t  if $GREP -v \"^: \" < \"$nlist\" |\n\t      if sort -k 3 </dev/null >/dev/null 2>&1; then\n\t\tsort -k 3\n\t      else\n\t\tsort +2\n\t      fi |\n\t      uniq > \"$nlist\"S; then\n\t    :\n\t  else\n\t    $GREP -v \"^: \" < \"$nlist\" > \"$nlist\"S\n\t  fi\n\n\t  if test -f \"$nlist\"S; then\n\t    eval \"$global_symbol_to_cdecl\"' < \"$nlist\"S >> \"$output_objdir/$my_dlsyms\"'\n\t  else\n\t    echo '/* NONE */' >> \"$output_objdir/$my_dlsyms\"\n\t  fi\n\n\t  func_show_eval '$RM \"${nlist}I\"'\n\t  if test -n \"$global_symbol_to_import\"; then\n\t    eval \"$global_symbol_to_import\"' < \"$nlist\"S > \"$nlist\"I'\n\t  fi\n\n\t  echo >> \"$output_objdir/$my_dlsyms\" \"\\\n\n/* The mapping between symbol names and symbols.  */\ntypedef struct {\n  const char *name;\n  void *address;\n} lt_dlsymlist;\nextern LT_DLSYM_CONST lt_dlsymlist\nlt_${my_prefix}_LTX_preloaded_symbols[];\\\n\"\n\n\t  if test -s \"$nlist\"I; then\n\t    echo >> \"$output_objdir/$my_dlsyms\" \"\\\nstatic void lt_syminit(void)\n{\n  LT_DLSYM_CONST lt_dlsymlist *symbol = lt_${my_prefix}_LTX_preloaded_symbols;\n  for (; symbol->name; ++symbol)\n    {\"\n\t    $SED 's/.*/      if (STREQ (symbol->name, \\\"&\\\")) symbol->address = (void *) \\&&;/' < \"$nlist\"I >> \"$output_objdir/$my_dlsyms\"\n\t    echo >> \"$output_objdir/$my_dlsyms\" \"\\\n    }\n}\"\n\t  fi\n\t  echo >> \"$output_objdir/$my_dlsyms\" \"\\\nLT_DLSYM_CONST lt_dlsymlist\nlt_${my_prefix}_LTX_preloaded_symbols[] =\n{ {\\\"$my_originator\\\", (void *) 0},\"\n\n\t  if test -s \"$nlist\"I; then\n\t    echo >> \"$output_objdir/$my_dlsyms\" \"\\\n  {\\\"@INIT@\\\", (void *) &lt_syminit},\"\n\t  fi\n\n\t  case $need_lib_prefix in\n\t  no)\n\t    eval \"$global_symbol_to_c_name_address\" < \"$nlist\" >> \"$output_objdir/$my_dlsyms\"\n\t    ;;\n\t  *)\n\t    eval \"$global_symbol_to_c_name_address_lib_prefix\" < \"$nlist\" >> \"$output_objdir/$my_dlsyms\"\n\t    ;;\n\t  esac\n\t  echo >> \"$output_objdir/$my_dlsyms\" \"\\\n  {0, (void *) 0}\n};\n\n/* This works around a problem in FreeBSD linker */\n#ifdef FREEBSD_WORKAROUND\nstatic const void *lt_preloaded_setup() {\n  return lt_${my_prefix}_LTX_preloaded_symbols;\n}\n#endif\n\n#ifdef __cplusplus\n}\n#endif\\\n\"\n\t} # !$opt_dry_run\n\n\tpic_flag_for_symtable=\n\tcase \"$compile_command \" in\n\t*\" -static \"*) ;;\n\t*)\n\t  case $host in\n\t  # compiling the symbol table file with pic_flag works around\n\t  # a FreeBSD bug that causes programs to crash when -lm is\n\t  # linked before any other PIC object.  But we must not use\n\t  # pic_flag when linking with -static.  The problem exists in\n\t  # FreeBSD 2.2.6 and is fixed in FreeBSD 3.1.\n\t  *-*-freebsd2.*|*-*-freebsd3.0*|*-*-freebsdelf3.0*)\n\t    pic_flag_for_symtable=\" $pic_flag -DFREEBSD_WORKAROUND\" ;;\n\t  *-*-hpux*)\n\t    pic_flag_for_symtable=\" $pic_flag\"  ;;\n\t  *)\n\t    $my_pic_p && pic_flag_for_symtable=\" $pic_flag\"\n\t    ;;\n\t  esac\n\t  ;;\n\tesac\n\tsymtab_cflags=\n\tfor arg in $LTCFLAGS; do\n\t  case $arg in\n\t  -pie | -fpie | -fPIE) ;;\n\t  *) func_append symtab_cflags \" $arg\" ;;\n\t  esac\n\tdone\n\n\t# Now compile the dynamic symbol file.\n\tfunc_show_eval '(cd $output_objdir && $LTCC$symtab_cflags -c$no_builtin_flag$pic_flag_for_symtable \"$my_dlsyms\")' 'exit $?'\n\n\t# Clean up the generated files.\n\tfunc_show_eval '$RM \"$output_objdir/$my_dlsyms\" \"$nlist\" \"${nlist}S\" \"${nlist}T\" \"${nlist}I\"'\n\n\t# Transform the symbol file into the correct name.\n\tsymfileobj=$output_objdir/${my_outputname}S.$objext\n\tcase $host in\n\t*cygwin* | *mingw* | *cegcc* )\n\t  if test -f \"$output_objdir/$my_outputname.def\"; then\n\t    compile_command=`$ECHO \"$compile_command\" | $SED \"s%@SYMFILE@%$output_objdir/$my_outputname.def $symfileobj%\"`\n\t    finalize_command=`$ECHO \"$finalize_command\" | $SED \"s%@SYMFILE@%$output_objdir/$my_outputname.def $symfileobj%\"`\n\t  else\n\t    compile_command=`$ECHO \"$compile_command\" | $SED \"s%@SYMFILE@%$symfileobj%\"`\n\t    finalize_command=`$ECHO \"$finalize_command\" | $SED \"s%@SYMFILE@%$symfileobj%\"`\n\t  fi\n\t  ;;\n\t*)\n\t  compile_command=`$ECHO \"$compile_command\" | $SED \"s%@SYMFILE@%$symfileobj%\"`\n\t  finalize_command=`$ECHO \"$finalize_command\" | $SED \"s%@SYMFILE@%$symfileobj%\"`\n\t  ;;\n\tesac\n\t;;\n      *)\n\tfunc_fatal_error \"unknown suffix for '$my_dlsyms'\"\n\t;;\n      esac\n    else\n      # We keep going just in case the user didn't refer to\n      # lt_preloaded_symbols.  The linker will fail if global_symbol_pipe\n      # really was required.\n\n      # Nullify the symbol file.\n      compile_command=`$ECHO \"$compile_command\" | $SED \"s% @SYMFILE@%%\"`\n      finalize_command=`$ECHO \"$finalize_command\" | $SED \"s% @SYMFILE@%%\"`\n    fi\n}\n\n# func_cygming_gnu_implib_p ARG\n# This predicate returns with zero status (TRUE) if\n# ARG is a GNU/binutils-style import library. Returns\n# with nonzero status (FALSE) otherwise.\nfunc_cygming_gnu_implib_p ()\n{\n  $debug_cmd\n\n  func_to_tool_file \"$1\" func_convert_file_msys_to_w32\n  func_cygming_gnu_implib_tmp=`$NM \"$func_to_tool_file_result\" | eval \"$global_symbol_pipe\" | $EGREP ' (_head_[A-Za-z0-9_]+_[ad]l*|[A-Za-z0-9_]+_[ad]l*_iname)$'`\n  test -n \"$func_cygming_gnu_implib_tmp\"\n}\n\n# func_cygming_ms_implib_p ARG\n# This predicate returns with zero status (TRUE) if\n# ARG is an MS-style import library. Returns\n# with nonzero status (FALSE) otherwise.\nfunc_cygming_ms_implib_p ()\n{\n  $debug_cmd\n\n  func_to_tool_file \"$1\" func_convert_file_msys_to_w32\n  func_cygming_ms_implib_tmp=`$NM \"$func_to_tool_file_result\" | eval \"$global_symbol_pipe\" | $GREP '_NULL_IMPORT_DESCRIPTOR'`\n  test -n \"$func_cygming_ms_implib_tmp\"\n}\n\n# func_win32_libid arg\n# return the library type of file 'arg'\n#\n# Need a lot of goo to handle *both* DLLs and import libs\n# Has to be a shell function in order to 'eat' the argument\n# that is supplied when $file_magic_command is called.\n# Despite the name, also deal with 64 bit binaries.\nfunc_win32_libid ()\n{\n  $debug_cmd\n\n  win32_libid_type=unknown\n  win32_fileres=`file -L $1 2>/dev/null`\n  case $win32_fileres in\n  *ar\\ archive\\ import\\ library*) # definitely import\n    win32_libid_type=\"x86 archive import\"\n    ;;\n  *ar\\ archive*) # could be an import, or static\n    # Keep the egrep pattern in sync with the one in _LT_CHECK_MAGIC_METHOD.\n    if eval $OBJDUMP -f $1 | $SED -e '10q' 2>/dev/null |\n       $EGREP 'file format (pei*-i386(.*architecture: i386)?|pe-arm-wince|pe-x86-64)' >/dev/null; then\n      case $nm_interface in\n      \"MS dumpbin\")\n\tif func_cygming_ms_implib_p \"$1\" ||\n\t   func_cygming_gnu_implib_p \"$1\"\n\tthen\n\t  win32_nmres=import\n\telse\n\t  win32_nmres=\n\tfi\n\t;;\n      *)\n\tfunc_to_tool_file \"$1\" func_convert_file_msys_to_w32\n\twin32_nmres=`eval $NM -f posix -A \\\"$func_to_tool_file_result\\\" |\n\t  $SED -n -e '\n\t    1,100{\n\t\t/ I /{\n\t\t    s|.*|import|\n\t\t    p\n\t\t    q\n\t\t}\n\t    }'`\n\t;;\n      esac\n      case $win32_nmres in\n      import*)  win32_libid_type=\"x86 archive import\";;\n      *)        win32_libid_type=\"x86 archive static\";;\n      esac\n    fi\n    ;;\n  *DLL*)\n    win32_libid_type=\"x86 DLL\"\n    ;;\n  *executable*) # but shell scripts are \"executable\" too...\n    case $win32_fileres in\n    *MS\\ Windows\\ PE\\ Intel*)\n      win32_libid_type=\"x86 DLL\"\n      ;;\n    esac\n    ;;\n  esac\n  $ECHO \"$win32_libid_type\"\n}\n\n# func_cygming_dll_for_implib ARG\n#\n# Platform-specific function to extract the\n# name of the DLL associated with the specified\n# import library ARG.\n# Invoked by eval'ing the libtool variable\n#    $sharedlib_from_linklib_cmd\n# Result is available in the variable\n#    $sharedlib_from_linklib_result\nfunc_cygming_dll_for_implib ()\n{\n  $debug_cmd\n\n  sharedlib_from_linklib_result=`$DLLTOOL --identify-strict --identify \"$1\"`\n}\n\n# func_cygming_dll_for_implib_fallback_core SECTION_NAME LIBNAMEs\n#\n# The is the core of a fallback implementation of a\n# platform-specific function to extract the name of the\n# DLL associated with the specified import library LIBNAME.\n#\n# SECTION_NAME is either .idata$6 or .idata$7, depending\n# on the platform and compiler that created the implib.\n#\n# Echos the name of the DLL associated with the\n# specified import library.\nfunc_cygming_dll_for_implib_fallback_core ()\n{\n  $debug_cmd\n\n  match_literal=`$ECHO \"$1\" | $SED \"$sed_make_literal_regex\"`\n  $OBJDUMP -s --section \"$1\" \"$2\" 2>/dev/null |\n    $SED '/^Contents of section '\"$match_literal\"':/{\n      # Place marker at beginning of archive member dllname section\n      s/.*/====MARK====/\n      p\n      d\n    }\n    # These lines can sometimes be longer than 43 characters, but\n    # are always uninteresting\n    /:[\t ]*file format pe[i]\\{,1\\}-/d\n    /^In archive [^:]*:/d\n    # Ensure marker is printed\n    /^====MARK====/p\n    # Remove all lines with less than 43 characters\n    /^.\\{43\\}/!d\n    # From remaining lines, remove first 43 characters\n    s/^.\\{43\\}//' |\n    $SED -n '\n      # Join marker and all lines until next marker into a single line\n      /^====MARK====/ b para\n      H\n      $ b para\n      b\n      :para\n      x\n      s/\\n//g\n      # Remove the marker\n      s/^====MARK====//\n      # Remove trailing dots and whitespace\n      s/[\\. \\t]*$//\n      # Print\n      /./p' |\n    # we now have a list, one entry per line, of the stringified\n    # contents of the appropriate section of all members of the\n    # archive that possess that section. Heuristic: eliminate\n    # all those that have a first or second character that is\n    # a '.' (that is, objdump's representation of an unprintable\n    # character.) This should work for all archives with less than\n    # 0x302f exports -- but will fail for DLLs whose name actually\n    # begins with a literal '.' or a single character followed by\n    # a '.'.\n    #\n    # Of those that remain, print the first one.\n    $SED -e '/^\\./d;/^.\\./d;q'\n}\n\n# func_cygming_dll_for_implib_fallback ARG\n# Platform-specific function to extract the\n# name of the DLL associated with the specified\n# import library ARG.\n#\n# This fallback implementation is for use when $DLLTOOL\n# does not support the --identify-strict option.\n# Invoked by eval'ing the libtool variable\n#    $sharedlib_from_linklib_cmd\n# Result is available in the variable\n#    $sharedlib_from_linklib_result\nfunc_cygming_dll_for_implib_fallback ()\n{\n  $debug_cmd\n\n  if func_cygming_gnu_implib_p \"$1\"; then\n    # binutils import library\n    sharedlib_from_linklib_result=`func_cygming_dll_for_implib_fallback_core '.idata$7' \"$1\"`\n  elif func_cygming_ms_implib_p \"$1\"; then\n    # ms-generated import library\n    sharedlib_from_linklib_result=`func_cygming_dll_for_implib_fallback_core '.idata$6' \"$1\"`\n  else\n    # unknown\n    sharedlib_from_linklib_result=\n  fi\n}\n\n\n# func_extract_an_archive dir oldlib\nfunc_extract_an_archive ()\n{\n    $debug_cmd\n\n    f_ex_an_ar_dir=$1; shift\n    f_ex_an_ar_oldlib=$1\n    if test yes = \"$lock_old_archive_extraction\"; then\n      lockfile=$f_ex_an_ar_oldlib.lock\n      until $opt_dry_run || ln \"$progpath\" \"$lockfile\" 2>/dev/null; do\n\tfunc_echo \"Waiting for $lockfile to be removed\"\n\tsleep 2\n      done\n    fi\n    func_show_eval \"(cd \\$f_ex_an_ar_dir && $AR x \\\"\\$f_ex_an_ar_oldlib\\\")\" \\\n\t\t   'stat=$?; rm -f \"$lockfile\"; exit $stat'\n    if test yes = \"$lock_old_archive_extraction\"; then\n      $opt_dry_run || rm -f \"$lockfile\"\n    fi\n    if ($AR t \"$f_ex_an_ar_oldlib\" | sort | sort -uc >/dev/null 2>&1); then\n     :\n    else\n      func_fatal_error \"object name conflicts in archive: $f_ex_an_ar_dir/$f_ex_an_ar_oldlib\"\n    fi\n}\n\n\n# func_extract_archives gentop oldlib ...\nfunc_extract_archives ()\n{\n    $debug_cmd\n\n    my_gentop=$1; shift\n    my_oldlibs=${1+\"$@\"}\n    my_oldobjs=\n    my_xlib=\n    my_xabs=\n    my_xdir=\n\n    for my_xlib in $my_oldlibs; do\n      # Extract the objects.\n      case $my_xlib in\n\t[\\\\/]* | [A-Za-z]:[\\\\/]*) my_xabs=$my_xlib ;;\n\t*) my_xabs=`pwd`\"/$my_xlib\" ;;\n      esac\n      func_basename \"$my_xlib\"\n      my_xlib=$func_basename_result\n      my_xlib_u=$my_xlib\n      while :; do\n        case \" $extracted_archives \" in\n\t*\" $my_xlib_u \"*)\n\t  func_arith $extracted_serial + 1\n\t  extracted_serial=$func_arith_result\n\t  my_xlib_u=lt$extracted_serial-$my_xlib ;;\n\t*) break ;;\n\tesac\n      done\n      extracted_archives=\"$extracted_archives $my_xlib_u\"\n      my_xdir=$my_gentop/$my_xlib_u\n\n      func_mkdir_p \"$my_xdir\"\n\n      case $host in\n      *-darwin*)\n\tfunc_verbose \"Extracting $my_xabs\"\n\t# Do not bother doing anything if just a dry run\n\t$opt_dry_run || {\n\t  darwin_orig_dir=`pwd`\n\t  cd $my_xdir || exit $?\n\t  darwin_archive=$my_xabs\n\t  darwin_curdir=`pwd`\n\t  func_basename \"$darwin_archive\"\n\t  darwin_base_archive=$func_basename_result\n\t  darwin_arches=`$LIPO -info \"$darwin_archive\" 2>/dev/null | $GREP Architectures 2>/dev/null || true`\n\t  if test -n \"$darwin_arches\"; then\n\t    darwin_arches=`$ECHO \"$darwin_arches\" | $SED -e 's/.*are://'`\n\t    darwin_arch=\n\t    func_verbose \"$darwin_base_archive has multiple architectures $darwin_arches\"\n\t    for darwin_arch in  $darwin_arches; do\n\t      func_mkdir_p \"unfat-$$/$darwin_base_archive-$darwin_arch\"\n\t      $LIPO -thin $darwin_arch -output \"unfat-$$/$darwin_base_archive-$darwin_arch/$darwin_base_archive\" \"$darwin_archive\"\n\t      cd \"unfat-$$/$darwin_base_archive-$darwin_arch\"\n\t      func_extract_an_archive \"`pwd`\" \"$darwin_base_archive\"\n\t      cd \"$darwin_curdir\"\n\t      $RM \"unfat-$$/$darwin_base_archive-$darwin_arch/$darwin_base_archive\"\n\t    done # $darwin_arches\n            ## Okay now we've a bunch of thin objects, gotta fatten them up :)\n\t    darwin_filelist=`find unfat-$$ -type f -name \\*.o -print -o -name \\*.lo -print | $SED -e \"$sed_basename\" | sort -u`\n\t    darwin_file=\n\t    darwin_files=\n\t    for darwin_file in $darwin_filelist; do\n\t      darwin_files=`find unfat-$$ -name $darwin_file -print | sort | $NL2SP`\n\t      $LIPO -create -output \"$darwin_file\" $darwin_files\n\t    done # $darwin_filelist\n\t    $RM -rf unfat-$$\n\t    cd \"$darwin_orig_dir\"\n\t  else\n\t    cd $darwin_orig_dir\n\t    func_extract_an_archive \"$my_xdir\" \"$my_xabs\"\n\t  fi # $darwin_arches\n\t} # !$opt_dry_run\n\t;;\n      *)\n        func_extract_an_archive \"$my_xdir\" \"$my_xabs\"\n\t;;\n      esac\n      my_oldobjs=\"$my_oldobjs \"`find $my_xdir -name \\*.$objext -print -o -name \\*.lo -print | sort | $NL2SP`\n    done\n\n    func_extract_archives_result=$my_oldobjs\n}\n\n\n# func_emit_wrapper [arg=no]\n#\n# Emit a libtool wrapper script on stdout.\n# Don't directly open a file because we may want to\n# incorporate the script contents within a cygwin/mingw\n# wrapper executable.  Must ONLY be called from within\n# func_mode_link because it depends on a number of variables\n# set therein.\n#\n# ARG is the value that the WRAPPER_SCRIPT_BELONGS_IN_OBJDIR\n# variable will take.  If 'yes', then the emitted script\n# will assume that the directory where it is stored is\n# the $objdir directory.  This is a cygwin/mingw-specific\n# behavior.\nfunc_emit_wrapper ()\n{\n\tfunc_emit_wrapper_arg1=${1-no}\n\n\t$ECHO \"\\\n#! $SHELL\n\n# $output - temporary wrapper script for $objdir/$outputname\n# Generated by $PROGRAM (GNU $PACKAGE) $VERSION\n#\n# The $output program cannot be directly executed until all the libtool\n# libraries that it depends on are installed.\n#\n# This wrapper script should never be moved out of the build directory.\n# If it is, it will not operate correctly.\n\n# Sed substitution that helps us do robust quoting.  It backslashifies\n# metacharacters that are still active within double-quoted strings.\nsed_quote_subst='$sed_quote_subst'\n\n# Be Bourne compatible\nif test -n \\\"\\${ZSH_VERSION+set}\\\" && (emulate sh) >/dev/null 2>&1; then\n  emulate sh\n  NULLCMD=:\n  # Zsh 3.x and 4.x performs word splitting on \\${1+\\\"\\$@\\\"}, which\n  # is contrary to our usage.  Disable this feature.\n  alias -g '\\${1+\\\"\\$@\\\"}'='\\\"\\$@\\\"'\n  setopt NO_GLOB_SUBST\nelse\n  case \\`(set -o) 2>/dev/null\\` in *posix*) set -o posix;; esac\nfi\nBIN_SH=xpg4; export BIN_SH # for Tru64\nDUALCASE=1; export DUALCASE # for MKS sh\n\n# The HP-UX ksh and POSIX shell print the target directory to stdout\n# if CDPATH is set.\n(unset CDPATH) >/dev/null 2>&1 && unset CDPATH\n\nrelink_command=\\\"$relink_command\\\"\n\n# This environment variable determines our operation mode.\nif test \\\"\\$libtool_install_magic\\\" = \\\"$magic\\\"; then\n  # install mode needs the following variables:\n  generated_by_libtool_version='$macro_version'\n  notinst_deplibs='$notinst_deplibs'\nelse\n  # When we are sourced in execute mode, \\$file and \\$ECHO are already set.\n  if test \\\"\\$libtool_execute_magic\\\" != \\\"$magic\\\"; then\n    file=\\\"\\$0\\\"\"\n\n    qECHO=`$ECHO \"$ECHO\" | $SED \"$sed_quote_subst\"`\n    $ECHO \"\\\n\n# A function that is used when there is no print builtin or printf.\nfunc_fallback_echo ()\n{\n  eval 'cat <<_LTECHO_EOF\n\\$1\n_LTECHO_EOF'\n}\n    ECHO=\\\"$qECHO\\\"\n  fi\n\n# Very basic option parsing. These options are (a) specific to\n# the libtool wrapper, (b) are identical between the wrapper\n# /script/ and the wrapper /executable/ that is used only on\n# windows platforms, and (c) all begin with the string \"--lt-\"\n# (application programs are unlikely to have options that match\n# this pattern).\n#\n# There are only two supported options: --lt-debug and\n# --lt-dump-script. There is, deliberately, no --lt-help.\n#\n# The first argument to this parsing function should be the\n# script's $0 value, followed by \"$@\".\nlt_option_debug=\nfunc_parse_lt_options ()\n{\n  lt_script_arg0=\\$0\n  shift\n  for lt_opt\n  do\n    case \\\"\\$lt_opt\\\" in\n    --lt-debug) lt_option_debug=1 ;;\n    --lt-dump-script)\n        lt_dump_D=\\`\\$ECHO \\\"X\\$lt_script_arg0\\\" | $SED -e 's/^X//' -e 's%/[^/]*$%%'\\`\n        test \\\"X\\$lt_dump_D\\\" = \\\"X\\$lt_script_arg0\\\" && lt_dump_D=.\n        lt_dump_F=\\`\\$ECHO \\\"X\\$lt_script_arg0\\\" | $SED -e 's/^X//' -e 's%^.*/%%'\\`\n        cat \\\"\\$lt_dump_D/\\$lt_dump_F\\\"\n        exit 0\n      ;;\n    --lt-*)\n        \\$ECHO \\\"Unrecognized --lt- option: '\\$lt_opt'\\\" 1>&2\n        exit 1\n      ;;\n    esac\n  done\n\n  # Print the debug banner immediately:\n  if test -n \\\"\\$lt_option_debug\\\"; then\n    echo \\\"$outputname:$output:\\$LINENO: libtool wrapper (GNU $PACKAGE) $VERSION\\\" 1>&2\n  fi\n}\n\n# Used when --lt-debug. Prints its arguments to stdout\n# (redirection is the responsibility of the caller)\nfunc_lt_dump_args ()\n{\n  lt_dump_args_N=1;\n  for lt_arg\n  do\n    \\$ECHO \\\"$outputname:$output:\\$LINENO: newargv[\\$lt_dump_args_N]: \\$lt_arg\\\"\n    lt_dump_args_N=\\`expr \\$lt_dump_args_N + 1\\`\n  done\n}\n\n# Core function for launching the target application\nfunc_exec_program_core ()\n{\n\"\n  case $host in\n  # Backslashes separate directories on plain windows\n  *-*-mingw | *-*-os2* | *-cegcc*)\n    $ECHO \"\\\n      if test -n \\\"\\$lt_option_debug\\\"; then\n        \\$ECHO \\\"$outputname:$output:\\$LINENO: newargv[0]: \\$progdir\\\\\\\\\\$program\\\" 1>&2\n        func_lt_dump_args \\${1+\\\"\\$@\\\"} 1>&2\n      fi\n      exec \\\"\\$progdir\\\\\\\\\\$program\\\" \\${1+\\\"\\$@\\\"}\n\"\n    ;;\n\n  *)\n    $ECHO \"\\\n      if test -n \\\"\\$lt_option_debug\\\"; then\n        \\$ECHO \\\"$outputname:$output:\\$LINENO: newargv[0]: \\$progdir/\\$program\\\" 1>&2\n        func_lt_dump_args \\${1+\\\"\\$@\\\"} 1>&2\n      fi\n      exec \\\"\\$progdir/\\$program\\\" \\${1+\\\"\\$@\\\"}\n\"\n    ;;\n  esac\n  $ECHO \"\\\n      \\$ECHO \\\"\\$0: cannot exec \\$program \\$*\\\" 1>&2\n      exit 1\n}\n\n# A function to encapsulate launching the target application\n# Strips options in the --lt-* namespace from \\$@ and\n# launches target application with the remaining arguments.\nfunc_exec_program ()\n{\n  case \\\" \\$* \\\" in\n  *\\\\ --lt-*)\n    for lt_wr_arg\n    do\n      case \\$lt_wr_arg in\n      --lt-*) ;;\n      *) set x \\\"\\$@\\\" \\\"\\$lt_wr_arg\\\"; shift;;\n      esac\n      shift\n    done ;;\n  esac\n  func_exec_program_core \\${1+\\\"\\$@\\\"}\n}\n\n  # Parse options\n  func_parse_lt_options \\\"\\$0\\\" \\${1+\\\"\\$@\\\"}\n\n  # Find the directory that this script lives in.\n  thisdir=\\`\\$ECHO \\\"\\$file\\\" | $SED 's%/[^/]*$%%'\\`\n  test \\\"x\\$thisdir\\\" = \\\"x\\$file\\\" && thisdir=.\n\n  # Follow symbolic links until we get to the real thisdir.\n  file=\\`ls -ld \\\"\\$file\\\" | $SED -n 's/.*-> //p'\\`\n  while test -n \\\"\\$file\\\"; do\n    destdir=\\`\\$ECHO \\\"\\$file\\\" | $SED 's%/[^/]*\\$%%'\\`\n\n    # If there was a directory component, then change thisdir.\n    if test \\\"x\\$destdir\\\" != \\\"x\\$file\\\"; then\n      case \\\"\\$destdir\\\" in\n      [\\\\\\\\/]* | [A-Za-z]:[\\\\\\\\/]*) thisdir=\\\"\\$destdir\\\" ;;\n      *) thisdir=\\\"\\$thisdir/\\$destdir\\\" ;;\n      esac\n    fi\n\n    file=\\`\\$ECHO \\\"\\$file\\\" | $SED 's%^.*/%%'\\`\n    file=\\`ls -ld \\\"\\$thisdir/\\$file\\\" | $SED -n 's/.*-> //p'\\`\n  done\n\n  # Usually 'no', except on cygwin/mingw when embedded into\n  # the cwrapper.\n  WRAPPER_SCRIPT_BELONGS_IN_OBJDIR=$func_emit_wrapper_arg1\n  if test \\\"\\$WRAPPER_SCRIPT_BELONGS_IN_OBJDIR\\\" = \\\"yes\\\"; then\n    # special case for '.'\n    if test \\\"\\$thisdir\\\" = \\\".\\\"; then\n      thisdir=\\`pwd\\`\n    fi\n    # remove .libs from thisdir\n    case \\\"\\$thisdir\\\" in\n    *[\\\\\\\\/]$objdir ) thisdir=\\`\\$ECHO \\\"\\$thisdir\\\" | $SED 's%[\\\\\\\\/][^\\\\\\\\/]*$%%'\\` ;;\n    $objdir )   thisdir=. ;;\n    esac\n  fi\n\n  # Try to get the absolute directory name.\n  absdir=\\`cd \\\"\\$thisdir\\\" && pwd\\`\n  test -n \\\"\\$absdir\\\" && thisdir=\\\"\\$absdir\\\"\n\"\n\n\tif test yes = \"$fast_install\"; then\n\t  $ECHO \"\\\n  program=lt-'$outputname'$exeext\n  progdir=\\\"\\$thisdir/$objdir\\\"\n\n  if test ! -f \\\"\\$progdir/\\$program\\\" ||\n     { file=\\`ls -1dt \\\"\\$progdir/\\$program\\\" \\\"\\$progdir/../\\$program\\\" 2>/dev/null | $SED 1q\\`; \\\\\n       test \\\"X\\$file\\\" != \\\"X\\$progdir/\\$program\\\"; }; then\n\n    file=\\\"\\$\\$-\\$program\\\"\n\n    if test ! -d \\\"\\$progdir\\\"; then\n      $MKDIR \\\"\\$progdir\\\"\n    else\n      $RM \\\"\\$progdir/\\$file\\\"\n    fi\"\n\n\t  $ECHO \"\\\n\n    # relink executable if necessary\n    if test -n \\\"\\$relink_command\\\"; then\n      if relink_command_output=\\`eval \\$relink_command 2>&1\\`; then :\n      else\n\t\\$ECHO \\\"\\$relink_command_output\\\" >&2\n\t$RM \\\"\\$progdir/\\$file\\\"\n\texit 1\n      fi\n    fi\n\n    $MV \\\"\\$progdir/\\$file\\\" \\\"\\$progdir/\\$program\\\" 2>/dev/null ||\n    { $RM \\\"\\$progdir/\\$program\\\";\n      $MV \\\"\\$progdir/\\$file\\\" \\\"\\$progdir/\\$program\\\"; }\n    $RM \\\"\\$progdir/\\$file\\\"\n  fi\"\n\telse\n\t  $ECHO \"\\\n  program='$outputname'\n  progdir=\\\"\\$thisdir/$objdir\\\"\n\"\n\tfi\n\n\t$ECHO \"\\\n\n  if test -f \\\"\\$progdir/\\$program\\\"; then\"\n\n\t# fixup the dll searchpath if we need to.\n\t#\n\t# Fix the DLL searchpath if we need to.  Do this before prepending\n\t# to shlibpath, because on Windows, both are PATH and uninstalled\n\t# libraries must come first.\n\tif test -n \"$dllsearchpath\"; then\n\t  $ECHO \"\\\n    # Add the dll search path components to the executable PATH\n    PATH=$dllsearchpath:\\$PATH\n\"\n\tfi\n\n\t# Export our shlibpath_var if we have one.\n\tif test yes = \"$shlibpath_overrides_runpath\" && test -n \"$shlibpath_var\" && test -n \"$temp_rpath\"; then\n\t  $ECHO \"\\\n    # Add our own library path to $shlibpath_var\n    $shlibpath_var=\\\"$temp_rpath\\$$shlibpath_var\\\"\n\n    # Some systems cannot cope with colon-terminated $shlibpath_var\n    # The second colon is a workaround for a bug in BeOS R4 sed\n    $shlibpath_var=\\`\\$ECHO \\\"\\$$shlibpath_var\\\" | $SED 's/::*\\$//'\\`\n\n    export $shlibpath_var\n\"\n\tfi\n\n\t$ECHO \"\\\n    if test \\\"\\$libtool_execute_magic\\\" != \\\"$magic\\\"; then\n      # Run the actual program with our arguments.\n      func_exec_program \\${1+\\\"\\$@\\\"}\n    fi\n  else\n    # The program doesn't exist.\n    \\$ECHO \\\"\\$0: error: '\\$progdir/\\$program' does not exist\\\" 1>&2\n    \\$ECHO \\\"This script is just a wrapper for \\$program.\\\" 1>&2\n    \\$ECHO \\\"See the $PACKAGE documentation for more information.\\\" 1>&2\n    exit 1\n  fi\nfi\\\n\"\n}\n\n\n# func_emit_cwrapperexe_src\n# emit the source code for a wrapper executable on stdout\n# Must ONLY be called from within func_mode_link because\n# it depends on a number of variable set therein.\nfunc_emit_cwrapperexe_src ()\n{\n\tcat <<EOF\n\n/* $cwrappersource - temporary wrapper executable for $objdir/$outputname\n   Generated by $PROGRAM (GNU $PACKAGE) $VERSION\n\n   The $output program cannot be directly executed until all the libtool\n   libraries that it depends on are installed.\n\n   This wrapper executable should never be moved out of the build directory.\n   If it is, it will not operate correctly.\n*/\nEOF\n\t    cat <<\"EOF\"\n#ifdef _MSC_VER\n# define _CRT_SECURE_NO_DEPRECATE 1\n#endif\n#include <stdio.h>\n#include <stdlib.h>\n#ifdef _MSC_VER\n# include <direct.h>\n# include <process.h>\n# include <io.h>\n#else\n# include <unistd.h>\n# include <stdint.h>\n# ifdef __CYGWIN__\n#  include <io.h>\n# endif\n#endif\n#include <malloc.h>\n#include <stdarg.h>\n#include <assert.h>\n#include <string.h>\n#include <ctype.h>\n#include <errno.h>\n#include <fcntl.h>\n#include <sys/stat.h>\n\n#define STREQ(s1, s2) (strcmp ((s1), (s2)) == 0)\n\n/* declarations of non-ANSI functions */\n#if defined __MINGW32__\n# ifdef __STRICT_ANSI__\nint _putenv (const char *);\n# endif\n#elif defined __CYGWIN__\n# ifdef __STRICT_ANSI__\nchar *realpath (const char *, char *);\nint putenv (char *);\nint setenv (const char *, const char *, int);\n# endif\n/* #elif defined other_platform || defined ... */\n#endif\n\n/* portability defines, excluding path handling macros */\n#if defined _MSC_VER\n# define setmode _setmode\n# define stat    _stat\n# define chmod   _chmod\n# define getcwd  _getcwd\n# define putenv  _putenv\n# define S_IXUSR _S_IEXEC\n#elif defined __MINGW32__\n# define setmode _setmode\n# define stat    _stat\n# define chmod   _chmod\n# define getcwd  _getcwd\n# define putenv  _putenv\n#elif defined __CYGWIN__\n# define HAVE_SETENV\n# define FOPEN_WB \"wb\"\n/* #elif defined other platforms ... */\n#endif\n\n#if defined PATH_MAX\n# define LT_PATHMAX PATH_MAX\n#elif defined MAXPATHLEN\n# define LT_PATHMAX MAXPATHLEN\n#else\n# define LT_PATHMAX 1024\n#endif\n\n#ifndef S_IXOTH\n# define S_IXOTH 0\n#endif\n#ifndef S_IXGRP\n# define S_IXGRP 0\n#endif\n\n/* path handling portability macros */\n#ifndef DIR_SEPARATOR\n# define DIR_SEPARATOR '/'\n# define PATH_SEPARATOR ':'\n#endif\n\n#if defined _WIN32 || defined __MSDOS__ || defined __DJGPP__ || \\\n  defined __OS2__\n# define HAVE_DOS_BASED_FILE_SYSTEM\n# define FOPEN_WB \"wb\"\n# ifndef DIR_SEPARATOR_2\n#  define DIR_SEPARATOR_2 '\\\\'\n# endif\n# ifndef PATH_SEPARATOR_2\n#  define PATH_SEPARATOR_2 ';'\n# endif\n#endif\n\n#ifndef DIR_SEPARATOR_2\n# define IS_DIR_SEPARATOR(ch) ((ch) == DIR_SEPARATOR)\n#else /* DIR_SEPARATOR_2 */\n# define IS_DIR_SEPARATOR(ch) \\\n\t(((ch) == DIR_SEPARATOR) || ((ch) == DIR_SEPARATOR_2))\n#endif /* DIR_SEPARATOR_2 */\n\n#ifndef PATH_SEPARATOR_2\n# define IS_PATH_SEPARATOR(ch) ((ch) == PATH_SEPARATOR)\n#else /* PATH_SEPARATOR_2 */\n# define IS_PATH_SEPARATOR(ch) ((ch) == PATH_SEPARATOR_2)\n#endif /* PATH_SEPARATOR_2 */\n\n#ifndef FOPEN_WB\n# define FOPEN_WB \"w\"\n#endif\n#ifndef _O_BINARY\n# define _O_BINARY 0\n#endif\n\n#define XMALLOC(type, num)      ((type *) xmalloc ((num) * sizeof(type)))\n#define XFREE(stale) do { \\\n  if (stale) { free (stale); stale = 0; } \\\n} while (0)\n\n#if defined LT_DEBUGWRAPPER\nstatic int lt_debug = 1;\n#else\nstatic int lt_debug = 0;\n#endif\n\nconst char *program_name = \"libtool-wrapper\"; /* in case xstrdup fails */\n\nvoid *xmalloc (size_t num);\nchar *xstrdup (const char *string);\nconst char *base_name (const char *name);\nchar *find_executable (const char *wrapper);\nchar *chase_symlinks (const char *pathspec);\nint make_executable (const char *path);\nint check_executable (const char *path);\nchar *strendzap (char *str, const char *pat);\nvoid lt_debugprintf (const char *file, int line, const char *fmt, ...);\nvoid lt_fatal (const char *file, int line, const char *message, ...);\nstatic const char *nonnull (const char *s);\nstatic const char *nonempty (const char *s);\nvoid lt_setenv (const char *name, const char *value);\nchar *lt_extend_str (const char *orig_value, const char *add, int to_end);\nvoid lt_update_exe_path (const char *name, const char *value);\nvoid lt_update_lib_path (const char *name, const char *value);\nchar **prepare_spawn (char **argv);\nvoid lt_dump_script (FILE *f);\nEOF\n\n\t    cat <<EOF\n#if __GNUC__ < 4 || (__GNUC__ == 4 && __GNUC_MINOR__ < 5)\n# define externally_visible volatile\n#else\n# define externally_visible __attribute__((externally_visible)) volatile\n#endif\nexternally_visible const char * MAGIC_EXE = \"$magic_exe\";\nconst char * LIB_PATH_VARNAME = \"$shlibpath_var\";\nEOF\n\n\t    if test yes = \"$shlibpath_overrides_runpath\" && test -n \"$shlibpath_var\" && test -n \"$temp_rpath\"; then\n              func_to_host_path \"$temp_rpath\"\n\t      cat <<EOF\nconst char * LIB_PATH_VALUE   = \"$func_to_host_path_result\";\nEOF\n\t    else\n\t      cat <<\"EOF\"\nconst char * LIB_PATH_VALUE   = \"\";\nEOF\n\t    fi\n\n\t    if test -n \"$dllsearchpath\"; then\n              func_to_host_path \"$dllsearchpath:\"\n\t      cat <<EOF\nconst char * EXE_PATH_VARNAME = \"PATH\";\nconst char * EXE_PATH_VALUE   = \"$func_to_host_path_result\";\nEOF\n\t    else\n\t      cat <<\"EOF\"\nconst char * EXE_PATH_VARNAME = \"\";\nconst char * EXE_PATH_VALUE   = \"\";\nEOF\n\t    fi\n\n\t    if test yes = \"$fast_install\"; then\n\t      cat <<EOF\nconst char * TARGET_PROGRAM_NAME = \"lt-$outputname\"; /* hopefully, no .exe */\nEOF\n\t    else\n\t      cat <<EOF\nconst char * TARGET_PROGRAM_NAME = \"$outputname\"; /* hopefully, no .exe */\nEOF\n\t    fi\n\n\n\t    cat <<\"EOF\"\n\n#define LTWRAPPER_OPTION_PREFIX         \"--lt-\"\n\nstatic const char *ltwrapper_option_prefix = LTWRAPPER_OPTION_PREFIX;\nstatic const char *dumpscript_opt       = LTWRAPPER_OPTION_PREFIX \"dump-script\";\nstatic const char *debug_opt            = LTWRAPPER_OPTION_PREFIX \"debug\";\n\nint\nmain (int argc, char *argv[])\n{\n  char **newargz;\n  int  newargc;\n  char *tmp_pathspec;\n  char *actual_cwrapper_path;\n  char *actual_cwrapper_name;\n  char *target_name;\n  char *lt_argv_zero;\n  int rval = 127;\n\n  int i;\n\n  program_name = (char *) xstrdup (base_name (argv[0]));\n  newargz = XMALLOC (char *, (size_t) argc + 1);\n\n  /* very simple arg parsing; don't want to rely on getopt\n   * also, copy all non cwrapper options to newargz, except\n   * argz[0], which is handled differently\n   */\n  newargc=0;\n  for (i = 1; i < argc; i++)\n    {\n      if (STREQ (argv[i], dumpscript_opt))\n\t{\nEOF\n\t    case $host in\n\t      *mingw* | *cygwin* )\n\t\t# make stdout use \"unix\" line endings\n\t\techo \"          setmode(1,_O_BINARY);\"\n\t\t;;\n\t      esac\n\n\t    cat <<\"EOF\"\n\t  lt_dump_script (stdout);\n\t  return 0;\n\t}\n      if (STREQ (argv[i], debug_opt))\n\t{\n          lt_debug = 1;\n          continue;\n\t}\n      if (STREQ (argv[i], ltwrapper_option_prefix))\n        {\n          /* however, if there is an option in the LTWRAPPER_OPTION_PREFIX\n             namespace, but it is not one of the ones we know about and\n             have already dealt with, above (inluding dump-script), then\n             report an error. Otherwise, targets might begin to believe\n             they are allowed to use options in the LTWRAPPER_OPTION_PREFIX\n             namespace. The first time any user complains about this, we'll\n             need to make LTWRAPPER_OPTION_PREFIX a configure-time option\n             or a configure.ac-settable value.\n           */\n          lt_fatal (__FILE__, __LINE__,\n\t\t    \"unrecognized %s option: '%s'\",\n                    ltwrapper_option_prefix, argv[i]);\n        }\n      /* otherwise ... */\n      newargz[++newargc] = xstrdup (argv[i]);\n    }\n  newargz[++newargc] = NULL;\n\nEOF\n\t    cat <<EOF\n  /* The GNU banner must be the first non-error debug message */\n  lt_debugprintf (__FILE__, __LINE__, \"libtool wrapper (GNU $PACKAGE) $VERSION\\n\");\nEOF\n\t    cat <<\"EOF\"\n  lt_debugprintf (__FILE__, __LINE__, \"(main) argv[0]: %s\\n\", argv[0]);\n  lt_debugprintf (__FILE__, __LINE__, \"(main) program_name: %s\\n\", program_name);\n\n  tmp_pathspec = find_executable (argv[0]);\n  if (tmp_pathspec == NULL)\n    lt_fatal (__FILE__, __LINE__, \"couldn't find %s\", argv[0]);\n  lt_debugprintf (__FILE__, __LINE__,\n                  \"(main) found exe (before symlink chase) at: %s\\n\",\n\t\t  tmp_pathspec);\n\n  actual_cwrapper_path = chase_symlinks (tmp_pathspec);\n  lt_debugprintf (__FILE__, __LINE__,\n                  \"(main) found exe (after symlink chase) at: %s\\n\",\n\t\t  actual_cwrapper_path);\n  XFREE (tmp_pathspec);\n\n  actual_cwrapper_name = xstrdup (base_name (actual_cwrapper_path));\n  strendzap (actual_cwrapper_path, actual_cwrapper_name);\n\n  /* wrapper name transforms */\n  strendzap (actual_cwrapper_name, \".exe\");\n  tmp_pathspec = lt_extend_str (actual_cwrapper_name, \".exe\", 1);\n  XFREE (actual_cwrapper_name);\n  actual_cwrapper_name = tmp_pathspec;\n  tmp_pathspec = 0;\n\n  /* target_name transforms -- use actual target program name; might have lt- prefix */\n  target_name = xstrdup (base_name (TARGET_PROGRAM_NAME));\n  strendzap (target_name, \".exe\");\n  tmp_pathspec = lt_extend_str (target_name, \".exe\", 1);\n  XFREE (target_name);\n  target_name = tmp_pathspec;\n  tmp_pathspec = 0;\n\n  lt_debugprintf (__FILE__, __LINE__,\n\t\t  \"(main) libtool target name: %s\\n\",\n\t\t  target_name);\nEOF\n\n\t    cat <<EOF\n  newargz[0] =\n    XMALLOC (char, (strlen (actual_cwrapper_path) +\n\t\t    strlen (\"$objdir\") + 1 + strlen (actual_cwrapper_name) + 1));\n  strcpy (newargz[0], actual_cwrapper_path);\n  strcat (newargz[0], \"$objdir\");\n  strcat (newargz[0], \"/\");\nEOF\n\n\t    cat <<\"EOF\"\n  /* stop here, and copy so we don't have to do this twice */\n  tmp_pathspec = xstrdup (newargz[0]);\n\n  /* do NOT want the lt- prefix here, so use actual_cwrapper_name */\n  strcat (newargz[0], actual_cwrapper_name);\n\n  /* DO want the lt- prefix here if it exists, so use target_name */\n  lt_argv_zero = lt_extend_str (tmp_pathspec, target_name, 1);\n  XFREE (tmp_pathspec);\n  tmp_pathspec = NULL;\nEOF\n\n\t    case $host_os in\n\t      mingw*)\n\t    cat <<\"EOF\"\n  {\n    char* p;\n    while ((p = strchr (newargz[0], '\\\\')) != NULL)\n      {\n\t*p = '/';\n      }\n    while ((p = strchr (lt_argv_zero, '\\\\')) != NULL)\n      {\n\t*p = '/';\n      }\n  }\nEOF\n\t    ;;\n\t    esac\n\n\t    cat <<\"EOF\"\n  XFREE (target_name);\n  XFREE (actual_cwrapper_path);\n  XFREE (actual_cwrapper_name);\n\n  lt_setenv (\"BIN_SH\", \"xpg4\"); /* for Tru64 */\n  lt_setenv (\"DUALCASE\", \"1\");  /* for MSK sh */\n  /* Update the DLL searchpath.  EXE_PATH_VALUE ($dllsearchpath) must\n     be prepended before (that is, appear after) LIB_PATH_VALUE ($temp_rpath)\n     because on Windows, both *_VARNAMEs are PATH but uninstalled\n     libraries must come first. */\n  lt_update_exe_path (EXE_PATH_VARNAME, EXE_PATH_VALUE);\n  lt_update_lib_path (LIB_PATH_VARNAME, LIB_PATH_VALUE);\n\n  lt_debugprintf (__FILE__, __LINE__, \"(main) lt_argv_zero: %s\\n\",\n\t\t  nonnull (lt_argv_zero));\n  for (i = 0; i < newargc; i++)\n    {\n      lt_debugprintf (__FILE__, __LINE__, \"(main) newargz[%d]: %s\\n\",\n\t\t      i, nonnull (newargz[i]));\n    }\n\nEOF\n\n\t    case $host_os in\n\t      mingw*)\n\t\tcat <<\"EOF\"\n  /* execv doesn't actually work on mingw as expected on unix */\n  newargz = prepare_spawn (newargz);\n  rval = (int) _spawnv (_P_WAIT, lt_argv_zero, (const char * const *) newargz);\n  if (rval == -1)\n    {\n      /* failed to start process */\n      lt_debugprintf (__FILE__, __LINE__,\n\t\t      \"(main) failed to launch target \\\"%s\\\": %s\\n\",\n\t\t      lt_argv_zero, nonnull (strerror (errno)));\n      return 127;\n    }\n  return rval;\nEOF\n\t\t;;\n\t      *)\n\t\tcat <<\"EOF\"\n  execv (lt_argv_zero, newargz);\n  return rval; /* =127, but avoids unused variable warning */\nEOF\n\t\t;;\n\t    esac\n\n\t    cat <<\"EOF\"\n}\n\nvoid *\nxmalloc (size_t num)\n{\n  void *p = (void *) malloc (num);\n  if (!p)\n    lt_fatal (__FILE__, __LINE__, \"memory exhausted\");\n\n  return p;\n}\n\nchar *\nxstrdup (const char *string)\n{\n  return string ? strcpy ((char *) xmalloc (strlen (string) + 1),\n\t\t\t  string) : NULL;\n}\n\nconst char *\nbase_name (const char *name)\n{\n  const char *base;\n\n#if defined HAVE_DOS_BASED_FILE_SYSTEM\n  /* Skip over the disk name in MSDOS pathnames. */\n  if (isalpha ((unsigned char) name[0]) && name[1] == ':')\n    name += 2;\n#endif\n\n  for (base = name; *name; name++)\n    if (IS_DIR_SEPARATOR (*name))\n      base = name + 1;\n  return base;\n}\n\nint\ncheck_executable (const char *path)\n{\n  struct stat st;\n\n  lt_debugprintf (__FILE__, __LINE__, \"(check_executable): %s\\n\",\n                  nonempty (path));\n  if ((!path) || (!*path))\n    return 0;\n\n  if ((stat (path, &st) >= 0)\n      && (st.st_mode & (S_IXUSR | S_IXGRP | S_IXOTH)))\n    return 1;\n  else\n    return 0;\n}\n\nint\nmake_executable (const char *path)\n{\n  int rval = 0;\n  struct stat st;\n\n  lt_debugprintf (__FILE__, __LINE__, \"(make_executable): %s\\n\",\n                  nonempty (path));\n  if ((!path) || (!*path))\n    return 0;\n\n  if (stat (path, &st) >= 0)\n    {\n      rval = chmod (path, st.st_mode | S_IXOTH | S_IXGRP | S_IXUSR);\n    }\n  return rval;\n}\n\n/* Searches for the full path of the wrapper.  Returns\n   newly allocated full path name if found, NULL otherwise\n   Does not chase symlinks, even on platforms that support them.\n*/\nchar *\nfind_executable (const char *wrapper)\n{\n  int has_slash = 0;\n  const char *p;\n  const char *p_next;\n  /* static buffer for getcwd */\n  char tmp[LT_PATHMAX + 1];\n  size_t tmp_len;\n  char *concat_name;\n\n  lt_debugprintf (__FILE__, __LINE__, \"(find_executable): %s\\n\",\n                  nonempty (wrapper));\n\n  if ((wrapper == NULL) || (*wrapper == '\\0'))\n    return NULL;\n\n  /* Absolute path? */\n#if defined HAVE_DOS_BASED_FILE_SYSTEM\n  if (isalpha ((unsigned char) wrapper[0]) && wrapper[1] == ':')\n    {\n      concat_name = xstrdup (wrapper);\n      if (check_executable (concat_name))\n\treturn concat_name;\n      XFREE (concat_name);\n    }\n  else\n    {\n#endif\n      if (IS_DIR_SEPARATOR (wrapper[0]))\n\t{\n\t  concat_name = xstrdup (wrapper);\n\t  if (check_executable (concat_name))\n\t    return concat_name;\n\t  XFREE (concat_name);\n\t}\n#if defined HAVE_DOS_BASED_FILE_SYSTEM\n    }\n#endif\n\n  for (p = wrapper; *p; p++)\n    if (*p == '/')\n      {\n\thas_slash = 1;\n\tbreak;\n      }\n  if (!has_slash)\n    {\n      /* no slashes; search PATH */\n      const char *path = getenv (\"PATH\");\n      if (path != NULL)\n\t{\n\t  for (p = path; *p; p = p_next)\n\t    {\n\t      const char *q;\n\t      size_t p_len;\n\t      for (q = p; *q; q++)\n\t\tif (IS_PATH_SEPARATOR (*q))\n\t\t  break;\n\t      p_len = (size_t) (q - p);\n\t      p_next = (*q == '\\0' ? q : q + 1);\n\t      if (p_len == 0)\n\t\t{\n\t\t  /* empty path: current directory */\n\t\t  if (getcwd (tmp, LT_PATHMAX) == NULL)\n\t\t    lt_fatal (__FILE__, __LINE__, \"getcwd failed: %s\",\n                              nonnull (strerror (errno)));\n\t\t  tmp_len = strlen (tmp);\n\t\t  concat_name =\n\t\t    XMALLOC (char, tmp_len + 1 + strlen (wrapper) + 1);\n\t\t  memcpy (concat_name, tmp, tmp_len);\n\t\t  concat_name[tmp_len] = '/';\n\t\t  strcpy (concat_name + tmp_len + 1, wrapper);\n\t\t}\n\t      else\n\t\t{\n\t\t  concat_name =\n\t\t    XMALLOC (char, p_len + 1 + strlen (wrapper) + 1);\n\t\t  memcpy (concat_name, p, p_len);\n\t\t  concat_name[p_len] = '/';\n\t\t  strcpy (concat_name + p_len + 1, wrapper);\n\t\t}\n\t      if (check_executable (concat_name))\n\t\treturn concat_name;\n\t      XFREE (concat_name);\n\t    }\n\t}\n      /* not found in PATH; assume curdir */\n    }\n  /* Relative path | not found in path: prepend cwd */\n  if (getcwd (tmp, LT_PATHMAX) == NULL)\n    lt_fatal (__FILE__, __LINE__, \"getcwd failed: %s\",\n              nonnull (strerror (errno)));\n  tmp_len = strlen (tmp);\n  concat_name = XMALLOC (char, tmp_len + 1 + strlen (wrapper) + 1);\n  memcpy (concat_name, tmp, tmp_len);\n  concat_name[tmp_len] = '/';\n  strcpy (concat_name + tmp_len + 1, wrapper);\n\n  if (check_executable (concat_name))\n    return concat_name;\n  XFREE (concat_name);\n  return NULL;\n}\n\nchar *\nchase_symlinks (const char *pathspec)\n{\n#ifndef S_ISLNK\n  return xstrdup (pathspec);\n#else\n  char buf[LT_PATHMAX];\n  struct stat s;\n  char *tmp_pathspec = xstrdup (pathspec);\n  char *p;\n  int has_symlinks = 0;\n  while (strlen (tmp_pathspec) && !has_symlinks)\n    {\n      lt_debugprintf (__FILE__, __LINE__,\n\t\t      \"checking path component for symlinks: %s\\n\",\n\t\t      tmp_pathspec);\n      if (lstat (tmp_pathspec, &s) == 0)\n\t{\n\t  if (S_ISLNK (s.st_mode) != 0)\n\t    {\n\t      has_symlinks = 1;\n\t      break;\n\t    }\n\n\t  /* search backwards for last DIR_SEPARATOR */\n\t  p = tmp_pathspec + strlen (tmp_pathspec) - 1;\n\t  while ((p > tmp_pathspec) && (!IS_DIR_SEPARATOR (*p)))\n\t    p--;\n\t  if ((p == tmp_pathspec) && (!IS_DIR_SEPARATOR (*p)))\n\t    {\n\t      /* no more DIR_SEPARATORS left */\n\t      break;\n\t    }\n\t  *p = '\\0';\n\t}\n      else\n\t{\n\t  lt_fatal (__FILE__, __LINE__,\n\t\t    \"error accessing file \\\"%s\\\": %s\",\n\t\t    tmp_pathspec, nonnull (strerror (errno)));\n\t}\n    }\n  XFREE (tmp_pathspec);\n\n  if (!has_symlinks)\n    {\n      return xstrdup (pathspec);\n    }\n\n  tmp_pathspec = realpath (pathspec, buf);\n  if (tmp_pathspec == 0)\n    {\n      lt_fatal (__FILE__, __LINE__,\n\t\t\"could not follow symlinks for %s\", pathspec);\n    }\n  return xstrdup (tmp_pathspec);\n#endif\n}\n\nchar *\nstrendzap (char *str, const char *pat)\n{\n  size_t len, patlen;\n\n  assert (str != NULL);\n  assert (pat != NULL);\n\n  len = strlen (str);\n  patlen = strlen (pat);\n\n  if (patlen <= len)\n    {\n      str += len - patlen;\n      if (STREQ (str, pat))\n\t*str = '\\0';\n    }\n  return str;\n}\n\nvoid\nlt_debugprintf (const char *file, int line, const char *fmt, ...)\n{\n  va_list args;\n  if (lt_debug)\n    {\n      (void) fprintf (stderr, \"%s:%s:%d: \", program_name, file, line);\n      va_start (args, fmt);\n      (void) vfprintf (stderr, fmt, args);\n      va_end (args);\n    }\n}\n\nstatic void\nlt_error_core (int exit_status, const char *file,\n\t       int line, const char *mode,\n\t       const char *message, va_list ap)\n{\n  fprintf (stderr, \"%s:%s:%d: %s: \", program_name, file, line, mode);\n  vfprintf (stderr, message, ap);\n  fprintf (stderr, \".\\n\");\n\n  if (exit_status >= 0)\n    exit (exit_status);\n}\n\nvoid\nlt_fatal (const char *file, int line, const char *message, ...)\n{\n  va_list ap;\n  va_start (ap, message);\n  lt_error_core (EXIT_FAILURE, file, line, \"FATAL\", message, ap);\n  va_end (ap);\n}\n\nstatic const char *\nnonnull (const char *s)\n{\n  return s ? s : \"(null)\";\n}\n\nstatic const char *\nnonempty (const char *s)\n{\n  return (s && !*s) ? \"(empty)\" : nonnull (s);\n}\n\nvoid\nlt_setenv (const char *name, const char *value)\n{\n  lt_debugprintf (__FILE__, __LINE__,\n\t\t  \"(lt_setenv) setting '%s' to '%s'\\n\",\n                  nonnull (name), nonnull (value));\n  {\n#ifdef HAVE_SETENV\n    /* always make a copy, for consistency with !HAVE_SETENV */\n    char *str = xstrdup (value);\n    setenv (name, str, 1);\n#else\n    size_t len = strlen (name) + 1 + strlen (value) + 1;\n    char *str = XMALLOC (char, len);\n    sprintf (str, \"%s=%s\", name, value);\n    if (putenv (str) != EXIT_SUCCESS)\n      {\n        XFREE (str);\n      }\n#endif\n  }\n}\n\nchar *\nlt_extend_str (const char *orig_value, const char *add, int to_end)\n{\n  char *new_value;\n  if (orig_value && *orig_value)\n    {\n      size_t orig_value_len = strlen (orig_value);\n      size_t add_len = strlen (add);\n      new_value = XMALLOC (char, add_len + orig_value_len + 1);\n      if (to_end)\n        {\n          strcpy (new_value, orig_value);\n          strcpy (new_value + orig_value_len, add);\n        }\n      else\n        {\n          strcpy (new_value, add);\n          strcpy (new_value + add_len, orig_value);\n        }\n    }\n  else\n    {\n      new_value = xstrdup (add);\n    }\n  return new_value;\n}\n\nvoid\nlt_update_exe_path (const char *name, const char *value)\n{\n  lt_debugprintf (__FILE__, __LINE__,\n\t\t  \"(lt_update_exe_path) modifying '%s' by prepending '%s'\\n\",\n                  nonnull (name), nonnull (value));\n\n  if (name && *name && value && *value)\n    {\n      char *new_value = lt_extend_str (getenv (name), value, 0);\n      /* some systems can't cope with a ':'-terminated path #' */\n      size_t len = strlen (new_value);\n      while ((len > 0) && IS_PATH_SEPARATOR (new_value[len-1]))\n        {\n          new_value[--len] = '\\0';\n        }\n      lt_setenv (name, new_value);\n      XFREE (new_value);\n    }\n}\n\nvoid\nlt_update_lib_path (const char *name, const char *value)\n{\n  lt_debugprintf (__FILE__, __LINE__,\n\t\t  \"(lt_update_lib_path) modifying '%s' by prepending '%s'\\n\",\n                  nonnull (name), nonnull (value));\n\n  if (name && *name && value && *value)\n    {\n      char *new_value = lt_extend_str (getenv (name), value, 0);\n      lt_setenv (name, new_value);\n      XFREE (new_value);\n    }\n}\n\nEOF\n\t    case $host_os in\n\t      mingw*)\n\t\tcat <<\"EOF\"\n\n/* Prepares an argument vector before calling spawn().\n   Note that spawn() does not by itself call the command interpreter\n     (getenv (\"COMSPEC\") != NULL ? getenv (\"COMSPEC\") :\n      ({ OSVERSIONINFO v; v.dwOSVersionInfoSize = sizeof(OSVERSIONINFO);\n         GetVersionEx(&v);\n         v.dwPlatformId == VER_PLATFORM_WIN32_NT;\n      }) ? \"cmd.exe\" : \"command.com\").\n   Instead it simply concatenates the arguments, separated by ' ', and calls\n   CreateProcess().  We must quote the arguments since Win32 CreateProcess()\n   interprets characters like ' ', '\\t', '\\\\', '\"' (but not '<' and '>') in a\n   special way:\n   - Space and tab are interpreted as delimiters. They are not treated as\n     delimiters if they are surrounded by double quotes: \"...\".\n   - Unescaped double quotes are removed from the input. Their only effect is\n     that within double quotes, space and tab are treated like normal\n     characters.\n   - Backslashes not followed by double quotes are not special.\n   - But 2*n+1 backslashes followed by a double quote become\n     n backslashes followed by a double quote (n >= 0):\n       \\\" -> \"\n       \\\\\\\" -> \\\"\n       \\\\\\\\\\\" -> \\\\\"\n */\n#define SHELL_SPECIAL_CHARS \"\\\"\\\\ \\001\\002\\003\\004\\005\\006\\007\\010\\011\\012\\013\\014\\015\\016\\017\\020\\021\\022\\023\\024\\025\\026\\027\\030\\031\\032\\033\\034\\035\\036\\037\"\n#define SHELL_SPACE_CHARS \" \\001\\002\\003\\004\\005\\006\\007\\010\\011\\012\\013\\014\\015\\016\\017\\020\\021\\022\\023\\024\\025\\026\\027\\030\\031\\032\\033\\034\\035\\036\\037\"\nchar **\nprepare_spawn (char **argv)\n{\n  size_t argc;\n  char **new_argv;\n  size_t i;\n\n  /* Count number of arguments.  */\n  for (argc = 0; argv[argc] != NULL; argc++)\n    ;\n\n  /* Allocate new argument vector.  */\n  new_argv = XMALLOC (char *, argc + 1);\n\n  /* Put quoted arguments into the new argument vector.  */\n  for (i = 0; i < argc; i++)\n    {\n      const char *string = argv[i];\n\n      if (string[0] == '\\0')\n\tnew_argv[i] = xstrdup (\"\\\"\\\"\");\n      else if (strpbrk (string, SHELL_SPECIAL_CHARS) != NULL)\n\t{\n\t  int quote_around = (strpbrk (string, SHELL_SPACE_CHARS) != NULL);\n\t  size_t length;\n\t  unsigned int backslashes;\n\t  const char *s;\n\t  char *quoted_string;\n\t  char *p;\n\n\t  length = 0;\n\t  backslashes = 0;\n\t  if (quote_around)\n\t    length++;\n\t  for (s = string; *s != '\\0'; s++)\n\t    {\n\t      char c = *s;\n\t      if (c == '\"')\n\t\tlength += backslashes + 1;\n\t      length++;\n\t      if (c == '\\\\')\n\t\tbackslashes++;\n\t      else\n\t\tbackslashes = 0;\n\t    }\n\t  if (quote_around)\n\t    length += backslashes + 1;\n\n\t  quoted_string = XMALLOC (char, length + 1);\n\n\t  p = quoted_string;\n\t  backslashes = 0;\n\t  if (quote_around)\n\t    *p++ = '\"';\n\t  for (s = string; *s != '\\0'; s++)\n\t    {\n\t      char c = *s;\n\t      if (c == '\"')\n\t\t{\n\t\t  unsigned int j;\n\t\t  for (j = backslashes + 1; j > 0; j--)\n\t\t    *p++ = '\\\\';\n\t\t}\n\t      *p++ = c;\n\t      if (c == '\\\\')\n\t\tbackslashes++;\n\t      else\n\t\tbackslashes = 0;\n\t    }\n\t  if (quote_around)\n\t    {\n\t      unsigned int j;\n\t      for (j = backslashes; j > 0; j--)\n\t\t*p++ = '\\\\';\n\t      *p++ = '\"';\n\t    }\n\t  *p = '\\0';\n\n\t  new_argv[i] = quoted_string;\n\t}\n      else\n\tnew_argv[i] = (char *) string;\n    }\n  new_argv[argc] = NULL;\n\n  return new_argv;\n}\nEOF\n\t\t;;\n\t    esac\n\n            cat <<\"EOF\"\nvoid lt_dump_script (FILE* f)\n{\nEOF\n\t    func_emit_wrapper yes |\n\t      $SED -n -e '\ns/^\\(.\\{79\\}\\)\\(..*\\)/\\1\\\n\\2/\nh\ns/\\([\\\\\"]\\)/\\\\\\1/g\ns/$/\\\\n/\ns/\\([^\\n]*\\).*/  fputs (\"\\1\", f);/p\ng\nD'\n            cat <<\"EOF\"\n}\nEOF\n}\n# end: func_emit_cwrapperexe_src\n\n# func_win32_import_lib_p ARG\n# True if ARG is an import lib, as indicated by $file_magic_cmd\nfunc_win32_import_lib_p ()\n{\n    $debug_cmd\n\n    case `eval $file_magic_cmd \\\"\\$1\\\" 2>/dev/null | $SED -e 10q` in\n    *import*) : ;;\n    *) false ;;\n    esac\n}\n\n# func_suncc_cstd_abi\n# !!ONLY CALL THIS FOR SUN CC AFTER $compile_command IS FULLY EXPANDED!!\n# Several compiler flags select an ABI that is incompatible with the\n# Cstd library. Avoid specifying it if any are in CXXFLAGS.\nfunc_suncc_cstd_abi ()\n{\n    $debug_cmd\n\n    case \" $compile_command \" in\n    *\" -compat=g \"*|*\\ -std=c++[0-9][0-9]\\ *|*\" -library=stdcxx4 \"*|*\" -library=stlport4 \"*)\n      suncc_use_cstd_abi=no\n      ;;\n    *)\n      suncc_use_cstd_abi=yes\n      ;;\n    esac\n}\n\n# func_mode_link arg...\nfunc_mode_link ()\n{\n    $debug_cmd\n\n    case $host in\n    *-*-cygwin* | *-*-mingw* | *-*-pw32* | *-*-os2* | *-cegcc*)\n      # It is impossible to link a dll without this setting, and\n      # we shouldn't force the makefile maintainer to figure out\n      # what system we are compiling for in order to pass an extra\n      # flag for every libtool invocation.\n      # allow_undefined=no\n\n      # FIXME: Unfortunately, there are problems with the above when trying\n      # to make a dll that has undefined symbols, in which case not\n      # even a static library is built.  For now, we need to specify\n      # -no-undefined on the libtool link line when we can be certain\n      # that all symbols are satisfied, otherwise we get a static library.\n      allow_undefined=yes\n      ;;\n    *)\n      allow_undefined=yes\n      ;;\n    esac\n    libtool_args=$nonopt\n    base_compile=\"$nonopt $@\"\n    compile_command=$nonopt\n    finalize_command=$nonopt\n\n    compile_rpath=\n    finalize_rpath=\n    compile_shlibpath=\n    finalize_shlibpath=\n    convenience=\n    old_convenience=\n    deplibs=\n    old_deplibs=\n    compiler_flags=\n    linker_flags=\n    dllsearchpath=\n    lib_search_path=`pwd`\n    inst_prefix_dir=\n    new_inherited_linker_flags=\n\n    avoid_version=no\n    bindir=\n    dlfiles=\n    dlprefiles=\n    dlself=no\n    export_dynamic=no\n    export_symbols=\n    export_symbols_regex=\n    generated=\n    libobjs=\n    ltlibs=\n    module=no\n    no_install=no\n    objs=\n    os2dllname=\n    non_pic_objects=\n    precious_files_regex=\n    prefer_static_libs=no\n    preload=false\n    prev=\n    prevarg=\n    release=\n    rpath=\n    xrpath=\n    perm_rpath=\n    temp_rpath=\n    thread_safe=no\n    vinfo=\n    vinfo_number=no\n    weak_libs=\n    single_module=$wl-single_module\n    func_infer_tag $base_compile\n\n    # We need to know -static, to get the right output filenames.\n    for arg\n    do\n      case $arg in\n      -shared)\n\ttest yes != \"$build_libtool_libs\" \\\n\t  && func_fatal_configuration \"cannot build a shared library\"\n\tbuild_old_libs=no\n\tbreak\n\t;;\n      -all-static | -static | -static-libtool-libs)\n\tcase $arg in\n\t-all-static)\n\t  if test yes = \"$build_libtool_libs\" && test -z \"$link_static_flag\"; then\n\t    func_warning \"complete static linking is impossible in this configuration\"\n\t  fi\n\t  if test -n \"$link_static_flag\"; then\n\t    dlopen_self=$dlopen_self_static\n\t  fi\n\t  prefer_static_libs=yes\n\t  ;;\n\t-static)\n\t  if test -z \"$pic_flag\" && test -n \"$link_static_flag\"; then\n\t    dlopen_self=$dlopen_self_static\n\t  fi\n\t  prefer_static_libs=built\n\t  ;;\n\t-static-libtool-libs)\n\t  if test -z \"$pic_flag\" && test -n \"$link_static_flag\"; then\n\t    dlopen_self=$dlopen_self_static\n\t  fi\n\t  prefer_static_libs=yes\n\t  ;;\n\tesac\n\tbuild_libtool_libs=no\n\tbuild_old_libs=yes\n\tbreak\n\t;;\n      esac\n    done\n\n    # See if our shared archives depend on static archives.\n    test -n \"$old_archive_from_new_cmds\" && build_old_libs=yes\n\n    # Go through the arguments, transforming them on the way.\n    while test \"$#\" -gt 0; do\n      arg=$1\n      shift\n      func_quote_for_eval \"$arg\"\n      qarg=$func_quote_for_eval_unquoted_result\n      func_append libtool_args \" $func_quote_for_eval_result\"\n\n      # If the previous option needs an argument, assign it.\n      if test -n \"$prev\"; then\n\tcase $prev in\n\toutput)\n\t  func_append compile_command \" @OUTPUT@\"\n\t  func_append finalize_command \" @OUTPUT@\"\n\t  ;;\n\tesac\n\n\tcase $prev in\n\tbindir)\n\t  bindir=$arg\n\t  prev=\n\t  continue\n\t  ;;\n\tdlfiles|dlprefiles)\n\t  $preload || {\n\t    # Add the symbol object into the linking commands.\n\t    func_append compile_command \" @SYMFILE@\"\n\t    func_append finalize_command \" @SYMFILE@\"\n\t    preload=:\n\t  }\n\t  case $arg in\n\t  *.la | *.lo) ;;  # We handle these cases below.\n\t  force)\n\t    if test no = \"$dlself\"; then\n\t      dlself=needless\n\t      export_dynamic=yes\n\t    fi\n\t    prev=\n\t    continue\n\t    ;;\n\t  self)\n\t    if test dlprefiles = \"$prev\"; then\n\t      dlself=yes\n\t    elif test dlfiles = \"$prev\" && test yes != \"$dlopen_self\"; then\n\t      dlself=yes\n\t    else\n\t      dlself=needless\n\t      export_dynamic=yes\n\t    fi\n\t    prev=\n\t    continue\n\t    ;;\n\t  *)\n\t    if test dlfiles = \"$prev\"; then\n\t      func_append dlfiles \" $arg\"\n\t    else\n\t      func_append dlprefiles \" $arg\"\n\t    fi\n\t    prev=\n\t    continue\n\t    ;;\n\t  esac\n\t  ;;\n\texpsyms)\n\t  export_symbols=$arg\n\t  test -f \"$arg\" \\\n\t    || func_fatal_error \"symbol file '$arg' does not exist\"\n\t  prev=\n\t  continue\n\t  ;;\n\texpsyms_regex)\n\t  export_symbols_regex=$arg\n\t  prev=\n\t  continue\n\t  ;;\n\tframework)\n\t  case $host in\n\t    *-*-darwin*)\n\t      case \"$deplibs \" in\n\t\t*\" $qarg.ltframework \"*) ;;\n\t\t*) func_append deplibs \" $qarg.ltframework\" # this is fixed later\n\t\t   ;;\n\t      esac\n\t      ;;\n\t  esac\n\t  prev=\n\t  continue\n\t  ;;\n\tinst_prefix)\n\t  inst_prefix_dir=$arg\n\t  prev=\n\t  continue\n\t  ;;\n\tmllvm)\n\t  # Clang does not use LLVM to link, so we can simply discard any\n\t  # '-mllvm $arg' options when doing the link step.\n\t  prev=\n\t  continue\n\t  ;;\n\tobjectlist)\n\t  if test -f \"$arg\"; then\n\t    save_arg=$arg\n\t    moreargs=\n\t    for fil in `cat \"$save_arg\"`\n\t    do\n#\t      func_append moreargs \" $fil\"\n\t      arg=$fil\n\t      # A libtool-controlled object.\n\n\t      # Check to see that this really is a libtool object.\n\t      if func_lalib_unsafe_p \"$arg\"; then\n\t\tpic_object=\n\t\tnon_pic_object=\n\n\t\t# Read the .lo file\n\t\tfunc_source \"$arg\"\n\n\t\tif test -z \"$pic_object\" ||\n\t\t   test -z \"$non_pic_object\" ||\n\t\t   test none = \"$pic_object\" &&\n\t\t   test none = \"$non_pic_object\"; then\n\t\t  func_fatal_error \"cannot find name of object for '$arg'\"\n\t\tfi\n\n\t\t# Extract subdirectory from the argument.\n\t\tfunc_dirname \"$arg\" \"/\" \"\"\n\t\txdir=$func_dirname_result\n\n\t\tif test none != \"$pic_object\"; then\n\t\t  # Prepend the subdirectory the object is found in.\n\t\t  pic_object=$xdir$pic_object\n\n\t\t  if test dlfiles = \"$prev\"; then\n\t\t    if test yes = \"$build_libtool_libs\" && test yes = \"$dlopen_support\"; then\n\t\t      func_append dlfiles \" $pic_object\"\n\t\t      prev=\n\t\t      continue\n\t\t    else\n\t\t      # If libtool objects are unsupported, then we need to preload.\n\t\t      prev=dlprefiles\n\t\t    fi\n\t\t  fi\n\n\t\t  # CHECK ME:  I think I busted this.  -Ossama\n\t\t  if test dlprefiles = \"$prev\"; then\n\t\t    # Preload the old-style object.\n\t\t    func_append dlprefiles \" $pic_object\"\n\t\t    prev=\n\t\t  fi\n\n\t\t  # A PIC object.\n\t\t  func_append libobjs \" $pic_object\"\n\t\t  arg=$pic_object\n\t\tfi\n\n\t\t# Non-PIC object.\n\t\tif test none != \"$non_pic_object\"; then\n\t\t  # Prepend the subdirectory the object is found in.\n\t\t  non_pic_object=$xdir$non_pic_object\n\n\t\t  # A standard non-PIC object\n\t\t  func_append non_pic_objects \" $non_pic_object\"\n\t\t  if test -z \"$pic_object\" || test none = \"$pic_object\"; then\n\t\t    arg=$non_pic_object\n\t\t  fi\n\t\telse\n\t\t  # If the PIC object exists, use it instead.\n\t\t  # $xdir was prepended to $pic_object above.\n\t\t  non_pic_object=$pic_object\n\t\t  func_append non_pic_objects \" $non_pic_object\"\n\t\tfi\n\t      else\n\t\t# Only an error if not doing a dry-run.\n\t\tif $opt_dry_run; then\n\t\t  # Extract subdirectory from the argument.\n\t\t  func_dirname \"$arg\" \"/\" \"\"\n\t\t  xdir=$func_dirname_result\n\n\t\t  func_lo2o \"$arg\"\n\t\t  pic_object=$xdir$objdir/$func_lo2o_result\n\t\t  non_pic_object=$xdir$func_lo2o_result\n\t\t  func_append libobjs \" $pic_object\"\n\t\t  func_append non_pic_objects \" $non_pic_object\"\n\t        else\n\t\t  func_fatal_error \"'$arg' is not a valid libtool object\"\n\t\tfi\n\t      fi\n\t    done\n\t  else\n\t    func_fatal_error \"link input file '$arg' does not exist\"\n\t  fi\n\t  arg=$save_arg\n\t  prev=\n\t  continue\n\t  ;;\n\tos2dllname)\n\t  os2dllname=$arg\n\t  prev=\n\t  continue\n\t  ;;\n\tprecious_regex)\n\t  precious_files_regex=$arg\n\t  prev=\n\t  continue\n\t  ;;\n\trelease)\n\t  release=-$arg\n\t  prev=\n\t  continue\n\t  ;;\n\trpath | xrpath)\n\t  # We need an absolute path.\n\t  case $arg in\n\t  [\\\\/]* | [A-Za-z]:[\\\\/]*) ;;\n\t  *)\n\t    func_fatal_error \"only absolute run-paths are allowed\"\n\t    ;;\n\t  esac\n\t  if test rpath = \"$prev\"; then\n\t    case \"$rpath \" in\n\t    *\" $arg \"*) ;;\n\t    *) func_append rpath \" $arg\" ;;\n\t    esac\n\t  else\n\t    case \"$xrpath \" in\n\t    *\" $arg \"*) ;;\n\t    *) func_append xrpath \" $arg\" ;;\n\t    esac\n\t  fi\n\t  prev=\n\t  continue\n\t  ;;\n\tshrext)\n\t  shrext_cmds=$arg\n\t  prev=\n\t  continue\n\t  ;;\n\tweak)\n\t  func_append weak_libs \" $arg\"\n\t  prev=\n\t  continue\n\t  ;;\n\txcclinker)\n\t  func_append linker_flags \" $qarg\"\n\t  func_append compiler_flags \" $qarg\"\n\t  prev=\n\t  func_append compile_command \" $qarg\"\n\t  func_append finalize_command \" $qarg\"\n\t  continue\n\t  ;;\n\txcompiler)\n\t  func_append compiler_flags \" $qarg\"\n\t  prev=\n\t  func_append compile_command \" $qarg\"\n\t  func_append finalize_command \" $qarg\"\n\t  continue\n\t  ;;\n\txlinker)\n\t  func_append linker_flags \" $qarg\"\n\t  func_append compiler_flags \" $wl$qarg\"\n\t  prev=\n\t  func_append compile_command \" $wl$qarg\"\n\t  func_append finalize_command \" $wl$qarg\"\n\t  continue\n\t  ;;\n\t*)\n\t  eval \"$prev=\\\"\\$arg\\\"\"\n\t  prev=\n\t  continue\n\t  ;;\n\tesac\n      fi # test -n \"$prev\"\n\n      prevarg=$arg\n\n      case $arg in\n      -all-static)\n\tif test -n \"$link_static_flag\"; then\n\t  # See comment for -static flag below, for more details.\n\t  func_append compile_command \" $link_static_flag\"\n\t  func_append finalize_command \" $link_static_flag\"\n\tfi\n\tcontinue\n\t;;\n\n      -allow-undefined)\n\t# FIXME: remove this flag sometime in the future.\n\tfunc_fatal_error \"'-allow-undefined' must not be used because it is the default\"\n\t;;\n\n      -avoid-version)\n\tavoid_version=yes\n\tcontinue\n\t;;\n\n      -bindir)\n\tprev=bindir\n\tcontinue\n\t;;\n\n      -dlopen)\n\tprev=dlfiles\n\tcontinue\n\t;;\n\n      -dlpreopen)\n\tprev=dlprefiles\n\tcontinue\n\t;;\n\n      -export-dynamic)\n\texport_dynamic=yes\n\tcontinue\n\t;;\n\n      -export-symbols | -export-symbols-regex)\n\tif test -n \"$export_symbols\" || test -n \"$export_symbols_regex\"; then\n\t  func_fatal_error \"more than one -exported-symbols argument is not allowed\"\n\tfi\n\tif test X-export-symbols = \"X$arg\"; then\n\t  prev=expsyms\n\telse\n\t  prev=expsyms_regex\n\tfi\n\tcontinue\n\t;;\n\n      -framework)\n\tprev=framework\n\tcontinue\n\t;;\n\n      -inst-prefix-dir)\n\tprev=inst_prefix\n\tcontinue\n\t;;\n\n      # The native IRIX linker understands -LANG:*, -LIST:* and -LNO:*\n      # so, if we see these flags be careful not to treat them like -L\n      -L[A-Z][A-Z]*:*)\n\tcase $with_gcc/$host in\n\tno/*-*-irix* | /*-*-irix*)\n\t  func_append compile_command \" $arg\"\n\t  func_append finalize_command \" $arg\"\n\t  ;;\n\tesac\n\tcontinue\n\t;;\n\n      -L*)\n\tfunc_stripname \"-L\" '' \"$arg\"\n\tif test -z \"$func_stripname_result\"; then\n\t  if test \"$#\" -gt 0; then\n\t    func_fatal_error \"require no space between '-L' and '$1'\"\n\t  else\n\t    func_fatal_error \"need path for '-L' option\"\n\t  fi\n\tfi\n\tfunc_resolve_sysroot \"$func_stripname_result\"\n\tdir=$func_resolve_sysroot_result\n\t# We need an absolute path.\n\tcase $dir in\n\t[\\\\/]* | [A-Za-z]:[\\\\/]*) ;;\n\t*)\n\t  absdir=`cd \"$dir\" && pwd`\n\t  test -z \"$absdir\" && \\\n\t    func_fatal_error \"cannot determine absolute directory name of '$dir'\"\n\t  dir=$absdir\n\t  ;;\n\tesac\n\tcase \"$deplibs \" in\n\t*\" -L$dir \"* | *\" $arg \"*)\n\t  # Will only happen for absolute or sysroot arguments\n\t  ;;\n\t*)\n\t  # Preserve sysroot, but never include relative directories\n\t  case $dir in\n\t    [\\\\/]* | [A-Za-z]:[\\\\/]* | =*) func_append deplibs \" $arg\" ;;\n\t    *) func_append deplibs \" -L$dir\" ;;\n\t  esac\n\t  func_append lib_search_path \" $dir\"\n\t  ;;\n\tesac\n\tcase $host in\n\t*-*-cygwin* | *-*-mingw* | *-*-pw32* | *-*-os2* | *-cegcc*)\n\t  testbindir=`$ECHO \"$dir\" | $SED 's*/lib$*/bin*'`\n\t  case :$dllsearchpath: in\n\t  *\":$dir:\"*) ;;\n\t  ::) dllsearchpath=$dir;;\n\t  *) func_append dllsearchpath \":$dir\";;\n\t  esac\n\t  case :$dllsearchpath: in\n\t  *\":$testbindir:\"*) ;;\n\t  ::) dllsearchpath=$testbindir;;\n\t  *) func_append dllsearchpath \":$testbindir\";;\n\t  esac\n\t  ;;\n\tesac\n\tcontinue\n\t;;\n\n      -l*)\n\tif test X-lc = \"X$arg\" || test X-lm = \"X$arg\"; then\n\t  case $host in\n\t  *-*-cygwin* | *-*-mingw* | *-*-pw32* | *-*-beos* | *-cegcc* | *-*-haiku*)\n\t    # These systems don't actually have a C or math library (as such)\n\t    continue\n\t    ;;\n\t  *-*-os2*)\n\t    # These systems don't actually have a C library (as such)\n\t    test X-lc = \"X$arg\" && continue\n\t    ;;\n\t  *-*-openbsd* | *-*-freebsd* | *-*-dragonfly* | *-*-bitrig*)\n\t    # Do not include libc due to us having libc/libc_r.\n\t    test X-lc = \"X$arg\" && continue\n\t    ;;\n\t  *-*-rhapsody* | *-*-darwin1.[012])\n\t    # Rhapsody C and math libraries are in the System framework\n\t    func_append deplibs \" System.ltframework\"\n\t    continue\n\t    ;;\n\t  *-*-sco3.2v5* | *-*-sco5v6*)\n\t    # Causes problems with __ctype\n\t    test X-lc = \"X$arg\" && continue\n\t    ;;\n\t  *-*-sysv4.2uw2* | *-*-sysv5* | *-*-unixware* | *-*-OpenUNIX*)\n\t    # Compiler inserts libc in the correct place for threads to work\n\t    test X-lc = \"X$arg\" && continue\n\t    ;;\n\t  esac\n\telif test X-lc_r = \"X$arg\"; then\n\t case $host in\n\t *-*-openbsd* | *-*-freebsd* | *-*-dragonfly* | *-*-bitrig*)\n\t   # Do not include libc_r directly, use -pthread flag.\n\t   continue\n\t   ;;\n\t esac\n\tfi\n\tfunc_append deplibs \" $arg\"\n\tcontinue\n\t;;\n\n      -mllvm)\n\tprev=mllvm\n\tcontinue\n\t;;\n\n      -module)\n\tmodule=yes\n\tcontinue\n\t;;\n\n      # Tru64 UNIX uses -model [arg] to determine the layout of C++\n      # classes, name mangling, and exception handling.\n      # Darwin uses the -arch flag to determine output architecture.\n      -model|-arch|-isysroot|--sysroot)\n\tfunc_append compiler_flags \" $arg\"\n\tfunc_append compile_command \" $arg\"\n\tfunc_append finalize_command \" $arg\"\n\tprev=xcompiler\n\tcontinue\n\t;;\n\n      -mt|-mthreads|-kthread|-Kthread|-pthread|-pthreads|--thread-safe \\\n      |-threads|-fopenmp|-openmp|-mp|-xopenmp|-omp|-qsmp=*)\n\tfunc_append compiler_flags \" $arg\"\n\tfunc_append compile_command \" $arg\"\n\tfunc_append finalize_command \" $arg\"\n\tcase \"$new_inherited_linker_flags \" in\n\t    *\" $arg \"*) ;;\n\t    * ) func_append new_inherited_linker_flags \" $arg\" ;;\n\tesac\n\tcontinue\n\t;;\n\n      -multi_module)\n\tsingle_module=$wl-multi_module\n\tcontinue\n\t;;\n\n      -no-fast-install)\n\tfast_install=no\n\tcontinue\n\t;;\n\n      -no-install)\n\tcase $host in\n\t*-*-cygwin* | *-*-mingw* | *-*-pw32* | *-*-os2* | *-*-darwin* | *-cegcc*)\n\t  # The PATH hackery in wrapper scripts is required on Windows\n\t  # and Darwin in order for the loader to find any dlls it needs.\n\t  func_warning \"'-no-install' is ignored for $host\"\n\t  func_warning \"assuming '-no-fast-install' instead\"\n\t  fast_install=no\n\t  ;;\n\t*) no_install=yes ;;\n\tesac\n\tcontinue\n\t;;\n\n      -no-undefined)\n\tallow_undefined=no\n\tcontinue\n\t;;\n\n      -objectlist)\n\tprev=objectlist\n\tcontinue\n\t;;\n\n      -os2dllname)\n\tprev=os2dllname\n\tcontinue\n\t;;\n\n      -o) prev=output ;;\n\n      -precious-files-regex)\n\tprev=precious_regex\n\tcontinue\n\t;;\n\n      -release)\n\tprev=release\n\tcontinue\n\t;;\n\n      -rpath)\n\tprev=rpath\n\tcontinue\n\t;;\n\n      -R)\n\tprev=xrpath\n\tcontinue\n\t;;\n\n      -R*)\n\tfunc_stripname '-R' '' \"$arg\"\n\tdir=$func_stripname_result\n\t# We need an absolute path.\n\tcase $dir in\n\t[\\\\/]* | [A-Za-z]:[\\\\/]*) ;;\n\t=*)\n\t  func_stripname '=' '' \"$dir\"\n\t  dir=$lt_sysroot$func_stripname_result\n\t  ;;\n\t*)\n\t  func_fatal_error \"only absolute run-paths are allowed\"\n\t  ;;\n\tesac\n\tcase \"$xrpath \" in\n\t*\" $dir \"*) ;;\n\t*) func_append xrpath \" $dir\" ;;\n\tesac\n\tcontinue\n\t;;\n\n      -shared)\n\t# The effects of -shared are defined in a previous loop.\n\tcontinue\n\t;;\n\n      -shrext)\n\tprev=shrext\n\tcontinue\n\t;;\n\n      -static | -static-libtool-libs)\n\t# The effects of -static are defined in a previous loop.\n\t# We used to do the same as -all-static on platforms that\n\t# didn't have a PIC flag, but the assumption that the effects\n\t# would be equivalent was wrong.  It would break on at least\n\t# Digital Unix and AIX.\n\tcontinue\n\t;;\n\n      -thread-safe)\n\tthread_safe=yes\n\tcontinue\n\t;;\n\n      -version-info)\n\tprev=vinfo\n\tcontinue\n\t;;\n\n      -version-number)\n\tprev=vinfo\n\tvinfo_number=yes\n\tcontinue\n\t;;\n\n      -weak)\n        prev=weak\n\tcontinue\n\t;;\n\n      -Wc,*)\n\tfunc_stripname '-Wc,' '' \"$arg\"\n\targs=$func_stripname_result\n\targ=\n\tsave_ifs=$IFS; IFS=,\n\tfor flag in $args; do\n\t  IFS=$save_ifs\n          func_quote_for_eval \"$flag\"\n\t  func_append arg \" $func_quote_for_eval_result\"\n\t  func_append compiler_flags \" $func_quote_for_eval_result\"\n\tdone\n\tIFS=$save_ifs\n\tfunc_stripname ' ' '' \"$arg\"\n\targ=$func_stripname_result\n\t;;\n\n      -Wl,*)\n\tfunc_stripname '-Wl,' '' \"$arg\"\n\targs=$func_stripname_result\n\targ=\n\tsave_ifs=$IFS; IFS=,\n\tfor flag in $args; do\n\t  IFS=$save_ifs\n          func_quote_for_eval \"$flag\"\n\t  func_append arg \" $wl$func_quote_for_eval_result\"\n\t  func_append compiler_flags \" $wl$func_quote_for_eval_result\"\n\t  func_append linker_flags \" $func_quote_for_eval_result\"\n\tdone\n\tIFS=$save_ifs\n\tfunc_stripname ' ' '' \"$arg\"\n\targ=$func_stripname_result\n\t;;\n\n      -Xcompiler)\n\tprev=xcompiler\n\tcontinue\n\t;;\n\n      -Xlinker)\n\tprev=xlinker\n\tcontinue\n\t;;\n\n      -XCClinker)\n\tprev=xcclinker\n\tcontinue\n\t;;\n\n      # -msg_* for osf cc\n      -msg_*)\n\tfunc_quote_for_eval \"$arg\"\n\targ=$func_quote_for_eval_result\n\t;;\n\n      # Flags to be passed through unchanged, with rationale:\n      # -64, -mips[0-9]      enable 64-bit mode for the SGI compiler\n      # -r[0-9][0-9]*        specify processor for the SGI compiler\n      # -xarch=*, -xtarget=* enable 64-bit mode for the Sun compiler\n      # +DA*, +DD*           enable 64-bit mode for the HP compiler\n      # -q*                  compiler args for the IBM compiler\n      # -m*, -t[45]*, -txscale* architecture-specific flags for GCC\n      # -F/path              path to uninstalled frameworks, gcc on darwin\n      # -p, -pg, --coverage, -fprofile-*  profiling flags for GCC\n      # -fstack-protector*   stack protector flags for GCC\n      # @file                GCC response files\n      # -tp=*                Portland pgcc target processor selection\n      # --sysroot=*          for sysroot support\n      # -O*, -g*, -flto*, -fwhopr*, -fuse-linker-plugin GCC link-time optimization\n      # -specs=*             GCC specs files\n      # -stdlib=*            select c++ std lib with clang\n      # -fsanitize=*         Clang/GCC memory and address sanitizer\n      # -fuse-ld=*           Linker select flags for GCC\n      -64|-mips[0-9]|-r[0-9][0-9]*|-xarch=*|-xtarget=*|+DA*|+DD*|-q*|-m*| \\\n      -t[45]*|-txscale*|-p|-pg|--coverage|-fprofile-*|-F*|@*|-tp=*|--sysroot=*| \\\n      -O*|-g*|-flto*|-fwhopr*|-fuse-linker-plugin|-fstack-protector*|-stdlib=*| \\\n      -specs=*|-fsanitize=*|-fuse-ld=*)\n        func_quote_for_eval \"$arg\"\n\targ=$func_quote_for_eval_result\n        func_append compile_command \" $arg\"\n        func_append finalize_command \" $arg\"\n        func_append compiler_flags \" $arg\"\n        continue\n        ;;\n\n      -Z*)\n        if test os2 = \"`expr $host : '.*\\(os2\\)'`\"; then\n          # OS/2 uses -Zxxx to specify OS/2-specific options\n\t  compiler_flags=\"$compiler_flags $arg\"\n\t  func_append compile_command \" $arg\"\n\t  func_append finalize_command \" $arg\"\n\t  case $arg in\n\t  -Zlinker | -Zstack)\n\t    prev=xcompiler\n\t    ;;\n\t  esac\n\t  continue\n        else\n\t  # Otherwise treat like 'Some other compiler flag' below\n\t  func_quote_for_eval \"$arg\"\n\t  arg=$func_quote_for_eval_result\n        fi\n\t;;\n\n      # Some other compiler flag.\n      -* | +*)\n        func_quote_for_eval \"$arg\"\n\targ=$func_quote_for_eval_result\n\t;;\n\n      *.$objext)\n\t# A standard object.\n\tfunc_append objs \" $arg\"\n\t;;\n\n      *.lo)\n\t# A libtool-controlled object.\n\n\t# Check to see that this really is a libtool object.\n\tif func_lalib_unsafe_p \"$arg\"; then\n\t  pic_object=\n\t  non_pic_object=\n\n\t  # Read the .lo file\n\t  func_source \"$arg\"\n\n\t  if test -z \"$pic_object\" ||\n\t     test -z \"$non_pic_object\" ||\n\t     test none = \"$pic_object\" &&\n\t     test none = \"$non_pic_object\"; then\n\t    func_fatal_error \"cannot find name of object for '$arg'\"\n\t  fi\n\n\t  # Extract subdirectory from the argument.\n\t  func_dirname \"$arg\" \"/\" \"\"\n\t  xdir=$func_dirname_result\n\n\t  test none = \"$pic_object\" || {\n\t    # Prepend the subdirectory the object is found in.\n\t    pic_object=$xdir$pic_object\n\n\t    if test dlfiles = \"$prev\"; then\n\t      if test yes = \"$build_libtool_libs\" && test yes = \"$dlopen_support\"; then\n\t\tfunc_append dlfiles \" $pic_object\"\n\t\tprev=\n\t\tcontinue\n\t      else\n\t\t# If libtool objects are unsupported, then we need to preload.\n\t\tprev=dlprefiles\n\t      fi\n\t    fi\n\n\t    # CHECK ME:  I think I busted this.  -Ossama\n\t    if test dlprefiles = \"$prev\"; then\n\t      # Preload the old-style object.\n\t      func_append dlprefiles \" $pic_object\"\n\t      prev=\n\t    fi\n\n\t    # A PIC object.\n\t    func_append libobjs \" $pic_object\"\n\t    arg=$pic_object\n\t  }\n\n\t  # Non-PIC object.\n\t  if test none != \"$non_pic_object\"; then\n\t    # Prepend the subdirectory the object is found in.\n\t    non_pic_object=$xdir$non_pic_object\n\n\t    # A standard non-PIC object\n\t    func_append non_pic_objects \" $non_pic_object\"\n\t    if test -z \"$pic_object\" || test none = \"$pic_object\"; then\n\t      arg=$non_pic_object\n\t    fi\n\t  else\n\t    # If the PIC object exists, use it instead.\n\t    # $xdir was prepended to $pic_object above.\n\t    non_pic_object=$pic_object\n\t    func_append non_pic_objects \" $non_pic_object\"\n\t  fi\n\telse\n\t  # Only an error if not doing a dry-run.\n\t  if $opt_dry_run; then\n\t    # Extract subdirectory from the argument.\n\t    func_dirname \"$arg\" \"/\" \"\"\n\t    xdir=$func_dirname_result\n\n\t    func_lo2o \"$arg\"\n\t    pic_object=$xdir$objdir/$func_lo2o_result\n\t    non_pic_object=$xdir$func_lo2o_result\n\t    func_append libobjs \" $pic_object\"\n\t    func_append non_pic_objects \" $non_pic_object\"\n\t  else\n\t    func_fatal_error \"'$arg' is not a valid libtool object\"\n\t  fi\n\tfi\n\t;;\n\n      *.$libext)\n\t# An archive.\n\tfunc_append deplibs \" $arg\"\n\tfunc_append old_deplibs \" $arg\"\n\tcontinue\n\t;;\n\n      *.la)\n\t# A libtool-controlled library.\n\n\tfunc_resolve_sysroot \"$arg\"\n\tif test dlfiles = \"$prev\"; then\n\t  # This library was specified with -dlopen.\n\t  func_append dlfiles \" $func_resolve_sysroot_result\"\n\t  prev=\n\telif test dlprefiles = \"$prev\"; then\n\t  # The library was specified with -dlpreopen.\n\t  func_append dlprefiles \" $func_resolve_sysroot_result\"\n\t  prev=\n\telse\n\t  func_append deplibs \" $func_resolve_sysroot_result\"\n\tfi\n\tcontinue\n\t;;\n\n      # Some other compiler argument.\n      *)\n\t# Unknown arguments in both finalize_command and compile_command need\n\t# to be aesthetically quoted because they are evaled later.\n\tfunc_quote_for_eval \"$arg\"\n\targ=$func_quote_for_eval_result\n\t;;\n      esac # arg\n\n      # Now actually substitute the argument into the commands.\n      if test -n \"$arg\"; then\n\tfunc_append compile_command \" $arg\"\n\tfunc_append finalize_command \" $arg\"\n      fi\n    done # argument parsing loop\n\n    test -n \"$prev\" && \\\n      func_fatal_help \"the '$prevarg' option requires an argument\"\n\n    if test yes = \"$export_dynamic\" && test -n \"$export_dynamic_flag_spec\"; then\n      eval arg=\\\"$export_dynamic_flag_spec\\\"\n      func_append compile_command \" $arg\"\n      func_append finalize_command \" $arg\"\n    fi\n\n    oldlibs=\n    # calculate the name of the file, without its directory\n    func_basename \"$output\"\n    outputname=$func_basename_result\n    libobjs_save=$libobjs\n\n    if test -n \"$shlibpath_var\"; then\n      # get the directories listed in $shlibpath_var\n      eval shlib_search_path=\\`\\$ECHO \\\"\\$$shlibpath_var\\\" \\| \\$SED \\'s/:/ /g\\'\\`\n    else\n      shlib_search_path=\n    fi\n    eval sys_lib_search_path=\\\"$sys_lib_search_path_spec\\\"\n    eval sys_lib_dlsearch_path=\\\"$sys_lib_dlsearch_path_spec\\\"\n\n    # Definition is injected by LT_CONFIG during libtool generation.\n    func_munge_path_list sys_lib_dlsearch_path \"$LT_SYS_LIBRARY_PATH\"\n\n    func_dirname \"$output\" \"/\" \"\"\n    output_objdir=$func_dirname_result$objdir\n    func_to_tool_file \"$output_objdir/\"\n    tool_output_objdir=$func_to_tool_file_result\n    # Create the object directory.\n    func_mkdir_p \"$output_objdir\"\n\n    # Determine the type of output\n    case $output in\n    \"\")\n      func_fatal_help \"you must specify an output file\"\n      ;;\n    *.$libext) linkmode=oldlib ;;\n    *.lo | *.$objext) linkmode=obj ;;\n    *.la) linkmode=lib ;;\n    *) linkmode=prog ;; # Anything else should be a program.\n    esac\n\n    specialdeplibs=\n\n    libs=\n    # Find all interdependent deplibs by searching for libraries\n    # that are linked more than once (e.g. -la -lb -la)\n    for deplib in $deplibs; do\n      if $opt_preserve_dup_deps; then\n\tcase \"$libs \" in\n\t*\" $deplib \"*) func_append specialdeplibs \" $deplib\" ;;\n\tesac\n      fi\n      func_append libs \" $deplib\"\n    done\n\n    if test lib = \"$linkmode\"; then\n      libs=\"$predeps $libs $compiler_lib_search_path $postdeps\"\n\n      # Compute libraries that are listed more than once in $predeps\n      # $postdeps and mark them as special (i.e., whose duplicates are\n      # not to be eliminated).\n      pre_post_deps=\n      if $opt_duplicate_compiler_generated_deps; then\n\tfor pre_post_dep in $predeps $postdeps; do\n\t  case \"$pre_post_deps \" in\n\t  *\" $pre_post_dep \"*) func_append specialdeplibs \" $pre_post_deps\" ;;\n\t  esac\n\t  func_append pre_post_deps \" $pre_post_dep\"\n\tdone\n      fi\n      pre_post_deps=\n    fi\n\n    deplibs=\n    newdependency_libs=\n    newlib_search_path=\n    need_relink=no # whether we're linking any uninstalled libtool libraries\n    notinst_deplibs= # not-installed libtool libraries\n    notinst_path= # paths that contain not-installed libtool libraries\n\n    case $linkmode in\n    lib)\n\tpasses=\"conv dlpreopen link\"\n\tfor file in $dlfiles $dlprefiles; do\n\t  case $file in\n\t  *.la) ;;\n\t  *)\n\t    func_fatal_help \"libraries can '-dlopen' only libtool libraries: $file\"\n\t    ;;\n\t  esac\n\tdone\n\t;;\n    prog)\n\tcompile_deplibs=\n\tfinalize_deplibs=\n\talldeplibs=false\n\tnewdlfiles=\n\tnewdlprefiles=\n\tpasses=\"conv scan dlopen dlpreopen link\"\n\t;;\n    *)  passes=\"conv\"\n\t;;\n    esac\n\n    for pass in $passes; do\n      # The preopen pass in lib mode reverses $deplibs; put it back here\n      # so that -L comes before libs that need it for instance...\n      if test lib,link = \"$linkmode,$pass\"; then\n\t## FIXME: Find the place where the list is rebuilt in the wrong\n\t##        order, and fix it there properly\n        tmp_deplibs=\n\tfor deplib in $deplibs; do\n\t  tmp_deplibs=\"$deplib $tmp_deplibs\"\n\tdone\n\tdeplibs=$tmp_deplibs\n      fi\n\n      if test lib,link = \"$linkmode,$pass\" ||\n\t test prog,scan = \"$linkmode,$pass\"; then\n\tlibs=$deplibs\n\tdeplibs=\n      fi\n      if test prog = \"$linkmode\"; then\n\tcase $pass in\n\tdlopen) libs=$dlfiles ;;\n\tdlpreopen) libs=$dlprefiles ;;\n\tlink)\n\t  libs=\"$deplibs %DEPLIBS%\"\n\t  test \"X$link_all_deplibs\" != Xno && libs=\"$libs $dependency_libs\"\n\t  ;;\n\tesac\n      fi\n      if test lib,dlpreopen = \"$linkmode,$pass\"; then\n\t# Collect and forward deplibs of preopened libtool libs\n\tfor lib in $dlprefiles; do\n\t  # Ignore non-libtool-libs\n\t  dependency_libs=\n\t  func_resolve_sysroot \"$lib\"\n\t  case $lib in\n\t  *.la)\tfunc_source \"$func_resolve_sysroot_result\" ;;\n\t  esac\n\n\t  # Collect preopened libtool deplibs, except any this library\n\t  # has declared as weak libs\n\t  for deplib in $dependency_libs; do\n\t    func_basename \"$deplib\"\n            deplib_base=$func_basename_result\n\t    case \" $weak_libs \" in\n\t    *\" $deplib_base \"*) ;;\n\t    *) func_append deplibs \" $deplib\" ;;\n\t    esac\n\t  done\n\tdone\n\tlibs=$dlprefiles\n      fi\n      if test dlopen = \"$pass\"; then\n\t# Collect dlpreopened libraries\n\tsave_deplibs=$deplibs\n\tdeplibs=\n      fi\n\n      for deplib in $libs; do\n\tlib=\n\tfound=false\n\tcase $deplib in\n\t-mt|-mthreads|-kthread|-Kthread|-pthread|-pthreads|--thread-safe \\\n        |-threads|-fopenmp|-openmp|-mp|-xopenmp|-omp|-qsmp=*)\n\t  if test prog,link = \"$linkmode,$pass\"; then\n\t    compile_deplibs=\"$deplib $compile_deplibs\"\n\t    finalize_deplibs=\"$deplib $finalize_deplibs\"\n\t  else\n\t    func_append compiler_flags \" $deplib\"\n\t    if test lib = \"$linkmode\"; then\n\t\tcase \"$new_inherited_linker_flags \" in\n\t\t    *\" $deplib \"*) ;;\n\t\t    * ) func_append new_inherited_linker_flags \" $deplib\" ;;\n\t\tesac\n\t    fi\n\t  fi\n\t  continue\n\t  ;;\n\t-l*)\n\t  if test lib != \"$linkmode\" && test prog != \"$linkmode\"; then\n\t    func_warning \"'-l' is ignored for archives/objects\"\n\t    continue\n\t  fi\n\t  func_stripname '-l' '' \"$deplib\"\n\t  name=$func_stripname_result\n\t  if test lib = \"$linkmode\"; then\n\t    searchdirs=\"$newlib_search_path $lib_search_path $compiler_lib_search_dirs $sys_lib_search_path $shlib_search_path\"\n\t  else\n\t    searchdirs=\"$newlib_search_path $lib_search_path $sys_lib_search_path $shlib_search_path\"\n\t  fi\n\t  for searchdir in $searchdirs; do\n\t    for search_ext in .la $std_shrext .so .a; do\n\t      # Search the libtool library\n\t      lib=$searchdir/lib$name$search_ext\n\t      if test -f \"$lib\"; then\n\t\tif test .la = \"$search_ext\"; then\n\t\t  found=:\n\t\telse\n\t\t  found=false\n\t\tfi\n\t\tbreak 2\n\t      fi\n\t    done\n\t  done\n\t  if $found; then\n\t    # deplib is a libtool library\n\t    # If $allow_libtool_libs_with_static_runtimes && $deplib is a stdlib,\n\t    # We need to do some special things here, and not later.\n\t    if test yes = \"$allow_libtool_libs_with_static_runtimes\"; then\n\t      case \" $predeps $postdeps \" in\n\t      *\" $deplib \"*)\n\t\tif func_lalib_p \"$lib\"; then\n\t\t  library_names=\n\t\t  old_library=\n\t\t  func_source \"$lib\"\n\t\t  for l in $old_library $library_names; do\n\t\t    ll=$l\n\t\t  done\n\t\t  if test \"X$ll\" = \"X$old_library\"; then # only static version available\n\t\t    found=false\n\t\t    func_dirname \"$lib\" \"\" \".\"\n\t\t    ladir=$func_dirname_result\n\t\t    lib=$ladir/$old_library\n\t\t    if test prog,link = \"$linkmode,$pass\"; then\n\t\t      compile_deplibs=\"$deplib $compile_deplibs\"\n\t\t      finalize_deplibs=\"$deplib $finalize_deplibs\"\n\t\t    else\n\t\t      deplibs=\"$deplib $deplibs\"\n\t\t      test lib = \"$linkmode\" && newdependency_libs=\"$deplib $newdependency_libs\"\n\t\t    fi\n\t\t    continue\n\t\t  fi\n\t\tfi\n\t\t;;\n\t      *) ;;\n\t      esac\n\t    fi\n\t  else\n\t    # deplib doesn't seem to be a libtool library\n\t    if test prog,link = \"$linkmode,$pass\"; then\n\t      compile_deplibs=\"$deplib $compile_deplibs\"\n\t      finalize_deplibs=\"$deplib $finalize_deplibs\"\n\t    else\n\t      deplibs=\"$deplib $deplibs\"\n\t      test lib = \"$linkmode\" && newdependency_libs=\"$deplib $newdependency_libs\"\n\t    fi\n\t    continue\n\t  fi\n\t  ;; # -l\n\t*.ltframework)\n\t  if test prog,link = \"$linkmode,$pass\"; then\n\t    compile_deplibs=\"$deplib $compile_deplibs\"\n\t    finalize_deplibs=\"$deplib $finalize_deplibs\"\n\t  else\n\t    deplibs=\"$deplib $deplibs\"\n\t    if test lib = \"$linkmode\"; then\n\t\tcase \"$new_inherited_linker_flags \" in\n\t\t    *\" $deplib \"*) ;;\n\t\t    * ) func_append new_inherited_linker_flags \" $deplib\" ;;\n\t\tesac\n\t    fi\n\t  fi\n\t  continue\n\t  ;;\n\t-L*)\n\t  case $linkmode in\n\t  lib)\n\t    deplibs=\"$deplib $deplibs\"\n\t    test conv = \"$pass\" && continue\n\t    newdependency_libs=\"$deplib $newdependency_libs\"\n\t    func_stripname '-L' '' \"$deplib\"\n\t    func_resolve_sysroot \"$func_stripname_result\"\n\t    func_append newlib_search_path \" $func_resolve_sysroot_result\"\n\t    ;;\n\t  prog)\n\t    if test conv = \"$pass\"; then\n\t      deplibs=\"$deplib $deplibs\"\n\t      continue\n\t    fi\n\t    if test scan = \"$pass\"; then\n\t      deplibs=\"$deplib $deplibs\"\n\t    else\n\t      compile_deplibs=\"$deplib $compile_deplibs\"\n\t      finalize_deplibs=\"$deplib $finalize_deplibs\"\n\t    fi\n\t    func_stripname '-L' '' \"$deplib\"\n\t    func_resolve_sysroot \"$func_stripname_result\"\n\t    func_append newlib_search_path \" $func_resolve_sysroot_result\"\n\t    ;;\n\t  *)\n\t    func_warning \"'-L' is ignored for archives/objects\"\n\t    ;;\n\t  esac # linkmode\n\t  continue\n\t  ;; # -L\n\t-R*)\n\t  if test link = \"$pass\"; then\n\t    func_stripname '-R' '' \"$deplib\"\n\t    func_resolve_sysroot \"$func_stripname_result\"\n\t    dir=$func_resolve_sysroot_result\n\t    # Make sure the xrpath contains only unique directories.\n\t    case \"$xrpath \" in\n\t    *\" $dir \"*) ;;\n\t    *) func_append xrpath \" $dir\" ;;\n\t    esac\n\t  fi\n\t  deplibs=\"$deplib $deplibs\"\n\t  continue\n\t  ;;\n\t*.la)\n\t  func_resolve_sysroot \"$deplib\"\n\t  lib=$func_resolve_sysroot_result\n\t  ;;\n\t*.$libext)\n\t  if test conv = \"$pass\"; then\n\t    deplibs=\"$deplib $deplibs\"\n\t    continue\n\t  fi\n\t  case $linkmode in\n\t  lib)\n\t    # Linking convenience modules into shared libraries is allowed,\n\t    # but linking other static libraries is non-portable.\n\t    case \" $dlpreconveniencelibs \" in\n\t    *\" $deplib \"*) ;;\n\t    *)\n\t      valid_a_lib=false\n\t      case $deplibs_check_method in\n\t\tmatch_pattern*)\n\t\t  set dummy $deplibs_check_method; shift\n\t\t  match_pattern_regex=`expr \"$deplibs_check_method\" : \"$1 \\(.*\\)\"`\n\t\t  if eval \"\\$ECHO \\\"$deplib\\\"\" 2>/dev/null | $SED 10q \\\n\t\t    | $EGREP \"$match_pattern_regex\" > /dev/null; then\n\t\t    valid_a_lib=:\n\t\t  fi\n\t\t;;\n\t\tpass_all)\n\t\t  valid_a_lib=:\n\t\t;;\n\t      esac\n\t      if $valid_a_lib; then\n\t\techo\n\t\t$ECHO \"*** Warning: Linking the shared library $output against the\"\n\t\t$ECHO \"*** static library $deplib is not portable!\"\n\t\tdeplibs=\"$deplib $deplibs\"\n\t      else\n\t\techo\n\t\t$ECHO \"*** Warning: Trying to link with static lib archive $deplib.\"\n\t\techo \"*** I have the capability to make that library automatically link in when\"\n\t\techo \"*** you link to this library.  But I can only do this if you have a\"\n\t\techo \"*** shared version of the library, which you do not appear to have\"\n\t\techo \"*** because the file extensions .$libext of this argument makes me believe\"\n\t\techo \"*** that it is just a static archive that I should not use here.\"\n\t      fi\n\t      ;;\n\t    esac\n\t    continue\n\t    ;;\n\t  prog)\n\t    if test link != \"$pass\"; then\n\t      deplibs=\"$deplib $deplibs\"\n\t    else\n\t      compile_deplibs=\"$deplib $compile_deplibs\"\n\t      finalize_deplibs=\"$deplib $finalize_deplibs\"\n\t    fi\n\t    continue\n\t    ;;\n\t  esac # linkmode\n\t  ;; # *.$libext\n\t*.lo | *.$objext)\n\t  if test conv = \"$pass\"; then\n\t    deplibs=\"$deplib $deplibs\"\n\t  elif test prog = \"$linkmode\"; then\n\t    if test dlpreopen = \"$pass\" || test yes != \"$dlopen_support\" || test no = \"$build_libtool_libs\"; then\n\t      # If there is no dlopen support or we're linking statically,\n\t      # we need to preload.\n\t      func_append newdlprefiles \" $deplib\"\n\t      compile_deplibs=\"$deplib $compile_deplibs\"\n\t      finalize_deplibs=\"$deplib $finalize_deplibs\"\n\t    else\n\t      func_append newdlfiles \" $deplib\"\n\t    fi\n\t  fi\n\t  continue\n\t  ;;\n\t%DEPLIBS%)\n\t  alldeplibs=:\n\t  continue\n\t  ;;\n\tesac # case $deplib\n\n\t$found || test -f \"$lib\" \\\n\t  || func_fatal_error \"cannot find the library '$lib' or unhandled argument '$deplib'\"\n\n\t# Check to see that this really is a libtool archive.\n\tfunc_lalib_unsafe_p \"$lib\" \\\n\t  || func_fatal_error \"'$lib' is not a valid libtool archive\"\n\n\tfunc_dirname \"$lib\" \"\" \".\"\n\tladir=$func_dirname_result\n\n\tdlname=\n\tdlopen=\n\tdlpreopen=\n\tlibdir=\n\tlibrary_names=\n\told_library=\n\tinherited_linker_flags=\n\t# If the library was installed with an old release of libtool,\n\t# it will not redefine variables installed, or shouldnotlink\n\tinstalled=yes\n\tshouldnotlink=no\n\tavoidtemprpath=\n\n\n\t# Read the .la file\n\tfunc_source \"$lib\"\n\n\t# Convert \"-framework foo\" to \"foo.ltframework\"\n\tif test -n \"$inherited_linker_flags\"; then\n\t  tmp_inherited_linker_flags=`$ECHO \"$inherited_linker_flags\" | $SED 's/-framework \\([^ $]*\\)/\\1.ltframework/g'`\n\t  for tmp_inherited_linker_flag in $tmp_inherited_linker_flags; do\n\t    case \" $new_inherited_linker_flags \" in\n\t      *\" $tmp_inherited_linker_flag \"*) ;;\n\t      *) func_append new_inherited_linker_flags \" $tmp_inherited_linker_flag\";;\n\t    esac\n\t  done\n\tfi\n\tdependency_libs=`$ECHO \" $dependency_libs\" | $SED 's% \\([^ $]*\\).ltframework% -framework \\1%g'`\n\tif test lib,link = \"$linkmode,$pass\" ||\n\t   test prog,scan = \"$linkmode,$pass\" ||\n\t   { test prog != \"$linkmode\" && test lib != \"$linkmode\"; }; then\n\t  test -n \"$dlopen\" && func_append dlfiles \" $dlopen\"\n\t  test -n \"$dlpreopen\" && func_append dlprefiles \" $dlpreopen\"\n\tfi\n\n\tif test conv = \"$pass\"; then\n\t  # Only check for convenience libraries\n\t  deplibs=\"$lib $deplibs\"\n\t  if test -z \"$libdir\"; then\n\t    if test -z \"$old_library\"; then\n\t      func_fatal_error \"cannot find name of link library for '$lib'\"\n\t    fi\n\t    # It is a libtool convenience library, so add in its objects.\n\t    func_append convenience \" $ladir/$objdir/$old_library\"\n\t    func_append old_convenience \" $ladir/$objdir/$old_library\"\n\t    tmp_libs=\n\t    for deplib in $dependency_libs; do\n\t      deplibs=\"$deplib $deplibs\"\n\t      if $opt_preserve_dup_deps; then\n\t\tcase \"$tmp_libs \" in\n\t\t*\" $deplib \"*) func_append specialdeplibs \" $deplib\" ;;\n\t\tesac\n\t      fi\n\t      func_append tmp_libs \" $deplib\"\n\t    done\n\t  elif test prog != \"$linkmode\" && test lib != \"$linkmode\"; then\n\t    func_fatal_error \"'$lib' is not a convenience library\"\n\t  fi\n\t  continue\n\tfi # $pass = conv\n\n\n\t# Get the name of the library we link against.\n\tlinklib=\n\tif test -n \"$old_library\" &&\n\t   { test yes = \"$prefer_static_libs\" ||\n\t     test built,no = \"$prefer_static_libs,$installed\"; }; then\n\t  linklib=$old_library\n\telse\n\t  for l in $old_library $library_names; do\n\t    linklib=$l\n\t  done\n\tfi\n\tif test -z \"$linklib\"; then\n\t  func_fatal_error \"cannot find name of link library for '$lib'\"\n\tfi\n\n\t# This library was specified with -dlopen.\n\tif test dlopen = \"$pass\"; then\n\t  test -z \"$libdir\" \\\n\t    && func_fatal_error \"cannot -dlopen a convenience library: '$lib'\"\n\t  if test -z \"$dlname\" ||\n\t     test yes != \"$dlopen_support\" ||\n\t     test no = \"$build_libtool_libs\"\n\t  then\n\t    # If there is no dlname, no dlopen support or we're linking\n\t    # statically, we need to preload.  We also need to preload any\n\t    # dependent libraries so libltdl's deplib preloader doesn't\n\t    # bomb out in the load deplibs phase.\n\t    func_append dlprefiles \" $lib $dependency_libs\"\n\t  else\n\t    func_append newdlfiles \" $lib\"\n\t  fi\n\t  continue\n\tfi # $pass = dlopen\n\n\t# We need an absolute path.\n\tcase $ladir in\n\t[\\\\/]* | [A-Za-z]:[\\\\/]*) abs_ladir=$ladir ;;\n\t*)\n\t  abs_ladir=`cd \"$ladir\" && pwd`\n\t  if test -z \"$abs_ladir\"; then\n\t    func_warning \"cannot determine absolute directory name of '$ladir'\"\n\t    func_warning \"passing it literally to the linker, although it might fail\"\n\t    abs_ladir=$ladir\n\t  fi\n\t  ;;\n\tesac\n\tfunc_basename \"$lib\"\n\tlaname=$func_basename_result\n\n\t# Find the relevant object directory and library name.\n\tif test yes = \"$installed\"; then\n\t  if test ! -f \"$lt_sysroot$libdir/$linklib\" && test -f \"$abs_ladir/$linklib\"; then\n\t    func_warning \"library '$lib' was moved.\"\n\t    dir=$ladir\n\t    absdir=$abs_ladir\n\t    libdir=$abs_ladir\n\t  else\n\t    dir=$lt_sysroot$libdir\n\t    absdir=$lt_sysroot$libdir\n\t  fi\n\t  test yes = \"$hardcode_automatic\" && avoidtemprpath=yes\n\telse\n\t  if test ! -f \"$ladir/$objdir/$linklib\" && test -f \"$abs_ladir/$linklib\"; then\n\t    dir=$ladir\n\t    absdir=$abs_ladir\n\t    # Remove this search path later\n\t    func_append notinst_path \" $abs_ladir\"\n\t  else\n\t    dir=$ladir/$objdir\n\t    absdir=$abs_ladir/$objdir\n\t    # Remove this search path later\n\t    func_append notinst_path \" $abs_ladir\"\n\t  fi\n\tfi # $installed = yes\n\tfunc_stripname 'lib' '.la' \"$laname\"\n\tname=$func_stripname_result\n\n\t# This library was specified with -dlpreopen.\n\tif test dlpreopen = \"$pass\"; then\n\t  if test -z \"$libdir\" && test prog = \"$linkmode\"; then\n\t    func_fatal_error \"only libraries may -dlpreopen a convenience library: '$lib'\"\n\t  fi\n\t  case $host in\n\t    # special handling for platforms with PE-DLLs.\n\t    *cygwin* | *mingw* | *cegcc* )\n\t      # Linker will automatically link against shared library if both\n\t      # static and shared are present.  Therefore, ensure we extract\n\t      # symbols from the import library if a shared library is present\n\t      # (otherwise, the dlopen module name will be incorrect).  We do\n\t      # this by putting the import library name into $newdlprefiles.\n\t      # We recover the dlopen module name by 'saving' the la file\n\t      # name in a special purpose variable, and (later) extracting the\n\t      # dlname from the la file.\n\t      if test -n \"$dlname\"; then\n\t        func_tr_sh \"$dir/$linklib\"\n\t        eval \"libfile_$func_tr_sh_result=\\$abs_ladir/\\$laname\"\n\t        func_append newdlprefiles \" $dir/$linklib\"\n\t      else\n\t        func_append newdlprefiles \" $dir/$old_library\"\n\t        # Keep a list of preopened convenience libraries to check\n\t        # that they are being used correctly in the link pass.\n\t        test -z \"$libdir\" && \\\n\t          func_append dlpreconveniencelibs \" $dir/$old_library\"\n\t      fi\n\t    ;;\n\t    * )\n\t      # Prefer using a static library (so that no silly _DYNAMIC symbols\n\t      # are required to link).\n\t      if test -n \"$old_library\"; then\n\t        func_append newdlprefiles \" $dir/$old_library\"\n\t        # Keep a list of preopened convenience libraries to check\n\t        # that they are being used correctly in the link pass.\n\t        test -z \"$libdir\" && \\\n\t          func_append dlpreconveniencelibs \" $dir/$old_library\"\n\t      # Otherwise, use the dlname, so that lt_dlopen finds it.\n\t      elif test -n \"$dlname\"; then\n\t        func_append newdlprefiles \" $dir/$dlname\"\n\t      else\n\t        func_append newdlprefiles \" $dir/$linklib\"\n\t      fi\n\t    ;;\n\t  esac\n\tfi # $pass = dlpreopen\n\n\tif test -z \"$libdir\"; then\n\t  # Link the convenience library\n\t  if test lib = \"$linkmode\"; then\n\t    deplibs=\"$dir/$old_library $deplibs\"\n\t  elif test prog,link = \"$linkmode,$pass\"; then\n\t    compile_deplibs=\"$dir/$old_library $compile_deplibs\"\n\t    finalize_deplibs=\"$dir/$old_library $finalize_deplibs\"\n\t  else\n\t    deplibs=\"$lib $deplibs\" # used for prog,scan pass\n\t  fi\n\t  continue\n\tfi\n\n\n\tif test prog = \"$linkmode\" && test link != \"$pass\"; then\n\t  func_append newlib_search_path \" $ladir\"\n\t  deplibs=\"$lib $deplibs\"\n\n\t  linkalldeplibs=false\n\t  if test no != \"$link_all_deplibs\" || test -z \"$library_names\" ||\n\t     test no = \"$build_libtool_libs\"; then\n\t    linkalldeplibs=:\n\t  fi\n\n\t  tmp_libs=\n\t  for deplib in $dependency_libs; do\n\t    case $deplib in\n\t    -L*) func_stripname '-L' '' \"$deplib\"\n\t         func_resolve_sysroot \"$func_stripname_result\"\n\t         func_append newlib_search_path \" $func_resolve_sysroot_result\"\n\t\t ;;\n\t    esac\n\t    # Need to link against all dependency_libs?\n\t    if $linkalldeplibs; then\n\t      deplibs=\"$deplib $deplibs\"\n\t    else\n\t      # Need to hardcode shared library paths\n\t      # or/and link against static libraries\n\t      newdependency_libs=\"$deplib $newdependency_libs\"\n\t    fi\n\t    if $opt_preserve_dup_deps; then\n\t      case \"$tmp_libs \" in\n\t      *\" $deplib \"*) func_append specialdeplibs \" $deplib\" ;;\n\t      esac\n\t    fi\n\t    func_append tmp_libs \" $deplib\"\n\t  done # for deplib\n\t  continue\n\tfi # $linkmode = prog...\n\n\tif test prog,link = \"$linkmode,$pass\"; then\n\t  if test -n \"$library_names\" &&\n\t     { { test no = \"$prefer_static_libs\" ||\n\t         test built,yes = \"$prefer_static_libs,$installed\"; } ||\n\t       test -z \"$old_library\"; }; then\n\t    # We need to hardcode the library path\n\t    if test -n \"$shlibpath_var\" && test -z \"$avoidtemprpath\"; then\n\t      # Make sure the rpath contains only unique directories.\n\t      case $temp_rpath: in\n\t      *\"$absdir:\"*) ;;\n\t      *) func_append temp_rpath \"$absdir:\" ;;\n\t      esac\n\t    fi\n\n\t    # Hardcode the library path.\n\t    # Skip directories that are in the system default run-time\n\t    # search path.\n\t    case \" $sys_lib_dlsearch_path \" in\n\t    *\" $absdir \"*) ;;\n\t    *)\n\t      case \"$compile_rpath \" in\n\t      *\" $absdir \"*) ;;\n\t      *) func_append compile_rpath \" $absdir\" ;;\n\t      esac\n\t      ;;\n\t    esac\n\t    case \" $sys_lib_dlsearch_path \" in\n\t    *\" $libdir \"*) ;;\n\t    *)\n\t      case \"$finalize_rpath \" in\n\t      *\" $libdir \"*) ;;\n\t      *) func_append finalize_rpath \" $libdir\" ;;\n\t      esac\n\t      ;;\n\t    esac\n\t  fi # $linkmode,$pass = prog,link...\n\n\t  if $alldeplibs &&\n\t     { test pass_all = \"$deplibs_check_method\" ||\n\t       { test yes = \"$build_libtool_libs\" &&\n\t\t test -n \"$library_names\"; }; }; then\n\t    # We only need to search for static libraries\n\t    continue\n\t  fi\n\tfi\n\n\tlink_static=no # Whether the deplib will be linked statically\n\tuse_static_libs=$prefer_static_libs\n\tif test built = \"$use_static_libs\" && test yes = \"$installed\"; then\n\t  use_static_libs=no\n\tfi\n\tif test -n \"$library_names\" &&\n\t   { test no = \"$use_static_libs\" || test -z \"$old_library\"; }; then\n\t  case $host in\n\t  *cygwin* | *mingw* | *cegcc* | *os2*)\n\t      # No point in relinking DLLs because paths are not encoded\n\t      func_append notinst_deplibs \" $lib\"\n\t      need_relink=no\n\t    ;;\n\t  *)\n\t    if test no = \"$installed\"; then\n\t      func_append notinst_deplibs \" $lib\"\n\t      need_relink=yes\n\t    fi\n\t    ;;\n\t  esac\n\t  # This is a shared library\n\n\t  # Warn about portability, can't link against -module's on some\n\t  # systems (darwin).  Don't bleat about dlopened modules though!\n\t  dlopenmodule=\n\t  for dlpremoduletest in $dlprefiles; do\n\t    if test \"X$dlpremoduletest\" = \"X$lib\"; then\n\t      dlopenmodule=$dlpremoduletest\n\t      break\n\t    fi\n\t  done\n\t  if test -z \"$dlopenmodule\" && test yes = \"$shouldnotlink\" && test link = \"$pass\"; then\n\t    echo\n\t    if test prog = \"$linkmode\"; then\n\t      $ECHO \"*** Warning: Linking the executable $output against the loadable module\"\n\t    else\n\t      $ECHO \"*** Warning: Linking the shared library $output against the loadable module\"\n\t    fi\n\t    $ECHO \"*** $linklib is not portable!\"\n\t  fi\n\t  if test lib = \"$linkmode\" &&\n\t     test yes = \"$hardcode_into_libs\"; then\n\t    # Hardcode the library path.\n\t    # Skip directories that are in the system default run-time\n\t    # search path.\n\t    case \" $sys_lib_dlsearch_path \" in\n\t    *\" $absdir \"*) ;;\n\t    *)\n\t      case \"$compile_rpath \" in\n\t      *\" $absdir \"*) ;;\n\t      *) func_append compile_rpath \" $absdir\" ;;\n\t      esac\n\t      ;;\n\t    esac\n\t    case \" $sys_lib_dlsearch_path \" in\n\t    *\" $libdir \"*) ;;\n\t    *)\n\t      case \"$finalize_rpath \" in\n\t      *\" $libdir \"*) ;;\n\t      *) func_append finalize_rpath \" $libdir\" ;;\n\t      esac\n\t      ;;\n\t    esac\n\t  fi\n\n\t  if test -n \"$old_archive_from_expsyms_cmds\"; then\n\t    # figure out the soname\n\t    set dummy $library_names\n\t    shift\n\t    realname=$1\n\t    shift\n\t    libname=`eval \"\\\\$ECHO \\\"$libname_spec\\\"\"`\n\t    # use dlname if we got it. it's perfectly good, no?\n\t    if test -n \"$dlname\"; then\n\t      soname=$dlname\n\t    elif test -n \"$soname_spec\"; then\n\t      # bleh windows\n\t      case $host in\n\t      *cygwin* | mingw* | *cegcc* | *os2*)\n\t        func_arith $current - $age\n\t\tmajor=$func_arith_result\n\t\tversuffix=-$major\n\t\t;;\n\t      esac\n\t      eval soname=\\\"$soname_spec\\\"\n\t    else\n\t      soname=$realname\n\t    fi\n\n\t    # Make a new name for the extract_expsyms_cmds to use\n\t    soroot=$soname\n\t    func_basename \"$soroot\"\n\t    soname=$func_basename_result\n\t    func_stripname 'lib' '.dll' \"$soname\"\n\t    newlib=libimp-$func_stripname_result.a\n\n\t    # If the library has no export list, then create one now\n\t    if test -f \"$output_objdir/$soname-def\"; then :\n\t    else\n\t      func_verbose \"extracting exported symbol list from '$soname'\"\n\t      func_execute_cmds \"$extract_expsyms_cmds\" 'exit $?'\n\t    fi\n\n\t    # Create $newlib\n\t    if test -f \"$output_objdir/$newlib\"; then :; else\n\t      func_verbose \"generating import library for '$soname'\"\n\t      func_execute_cmds \"$old_archive_from_expsyms_cmds\" 'exit $?'\n\t    fi\n\t    # make sure the library variables are pointing to the new library\n\t    dir=$output_objdir\n\t    linklib=$newlib\n\t  fi # test -n \"$old_archive_from_expsyms_cmds\"\n\n\t  if test prog = \"$linkmode\" || test relink != \"$opt_mode\"; then\n\t    add_shlibpath=\n\t    add_dir=\n\t    add=\n\t    lib_linked=yes\n\t    case $hardcode_action in\n\t    immediate | unsupported)\n\t      if test no = \"$hardcode_direct\"; then\n\t\tadd=$dir/$linklib\n\t\tcase $host in\n\t\t  *-*-sco3.2v5.0.[024]*) add_dir=-L$dir ;;\n\t\t  *-*-sysv4*uw2*) add_dir=-L$dir ;;\n\t\t  *-*-sysv5OpenUNIX* | *-*-sysv5UnixWare7.[01].[10]* | \\\n\t\t    *-*-unixware7*) add_dir=-L$dir ;;\n\t\t  *-*-darwin* )\n\t\t    # if the lib is a (non-dlopened) module then we cannot\n\t\t    # link against it, someone is ignoring the earlier warnings\n\t\t    if /usr/bin/file -L $add 2> /dev/null |\n\t\t\t $GREP \": [^:]* bundle\" >/dev/null; then\n\t\t      if test \"X$dlopenmodule\" != \"X$lib\"; then\n\t\t\t$ECHO \"*** Warning: lib $linklib is a module, not a shared library\"\n\t\t\tif test -z \"$old_library\"; then\n\t\t\t  echo\n\t\t\t  echo \"*** And there doesn't seem to be a static archive available\"\n\t\t\t  echo \"*** The link will probably fail, sorry\"\n\t\t\telse\n\t\t\t  add=$dir/$old_library\n\t\t\tfi\n\t\t      elif test -n \"$old_library\"; then\n\t\t\tadd=$dir/$old_library\n\t\t      fi\n\t\t    fi\n\t\tesac\n\t      elif test no = \"$hardcode_minus_L\"; then\n\t\tcase $host in\n\t\t*-*-sunos*) add_shlibpath=$dir ;;\n\t\tesac\n\t\tadd_dir=-L$dir\n\t\tadd=-l$name\n\t      elif test no = \"$hardcode_shlibpath_var\"; then\n\t\tadd_shlibpath=$dir\n\t\tadd=-l$name\n\t      else\n\t\tlib_linked=no\n\t      fi\n\t      ;;\n\t    relink)\n\t      if test yes = \"$hardcode_direct\" &&\n\t         test no = \"$hardcode_direct_absolute\"; then\n\t\tadd=$dir/$linklib\n\t      elif test yes = \"$hardcode_minus_L\"; then\n\t\tadd_dir=-L$absdir\n\t\t# Try looking first in the location we're being installed to.\n\t\tif test -n \"$inst_prefix_dir\"; then\n\t\t  case $libdir in\n\t\t    [\\\\/]*)\n\t\t      func_append add_dir \" -L$inst_prefix_dir$libdir\"\n\t\t      ;;\n\t\t  esac\n\t\tfi\n\t\tadd=-l$name\n\t      elif test yes = \"$hardcode_shlibpath_var\"; then\n\t\tadd_shlibpath=$dir\n\t\tadd=-l$name\n\t      else\n\t\tlib_linked=no\n\t      fi\n\t      ;;\n\t    *) lib_linked=no ;;\n\t    esac\n\n\t    if test yes != \"$lib_linked\"; then\n\t      func_fatal_configuration \"unsupported hardcode properties\"\n\t    fi\n\n\t    if test -n \"$add_shlibpath\"; then\n\t      case :$compile_shlibpath: in\n\t      *\":$add_shlibpath:\"*) ;;\n\t      *) func_append compile_shlibpath \"$add_shlibpath:\" ;;\n\t      esac\n\t    fi\n\t    if test prog = \"$linkmode\"; then\n\t      test -n \"$add_dir\" && compile_deplibs=\"$add_dir $compile_deplibs\"\n\t      test -n \"$add\" && compile_deplibs=\"$add $compile_deplibs\"\n\t    else\n\t      test -n \"$add_dir\" && deplibs=\"$add_dir $deplibs\"\n\t      test -n \"$add\" && deplibs=\"$add $deplibs\"\n\t      if test yes != \"$hardcode_direct\" &&\n\t\t test yes != \"$hardcode_minus_L\" &&\n\t\t test yes = \"$hardcode_shlibpath_var\"; then\n\t\tcase :$finalize_shlibpath: in\n\t\t*\":$libdir:\"*) ;;\n\t\t*) func_append finalize_shlibpath \"$libdir:\" ;;\n\t\tesac\n\t      fi\n\t    fi\n\t  fi\n\n\t  if test prog = \"$linkmode\" || test relink = \"$opt_mode\"; then\n\t    add_shlibpath=\n\t    add_dir=\n\t    add=\n\t    # Finalize command for both is simple: just hardcode it.\n\t    if test yes = \"$hardcode_direct\" &&\n\t       test no = \"$hardcode_direct_absolute\"; then\n\t      add=$libdir/$linklib\n\t    elif test yes = \"$hardcode_minus_L\"; then\n\t      add_dir=-L$libdir\n\t      add=-l$name\n\t    elif test yes = \"$hardcode_shlibpath_var\"; then\n\t      case :$finalize_shlibpath: in\n\t      *\":$libdir:\"*) ;;\n\t      *) func_append finalize_shlibpath \"$libdir:\" ;;\n\t      esac\n\t      add=-l$name\n\t    elif test yes = \"$hardcode_automatic\"; then\n\t      if test -n \"$inst_prefix_dir\" &&\n\t\t test -f \"$inst_prefix_dir$libdir/$linklib\"; then\n\t\tadd=$inst_prefix_dir$libdir/$linklib\n\t      else\n\t\tadd=$libdir/$linklib\n\t      fi\n\t    else\n\t      # We cannot seem to hardcode it, guess we'll fake it.\n\t      add_dir=-L$libdir\n\t      # Try looking first in the location we're being installed to.\n\t      if test -n \"$inst_prefix_dir\"; then\n\t\tcase $libdir in\n\t\t  [\\\\/]*)\n\t\t    func_append add_dir \" -L$inst_prefix_dir$libdir\"\n\t\t    ;;\n\t\tesac\n\t      fi\n\t      add=-l$name\n\t    fi\n\n\t    if test prog = \"$linkmode\"; then\n\t      test -n \"$add_dir\" && finalize_deplibs=\"$add_dir $finalize_deplibs\"\n\t      test -n \"$add\" && finalize_deplibs=\"$add $finalize_deplibs\"\n\t    else\n\t      test -n \"$add_dir\" && deplibs=\"$add_dir $deplibs\"\n\t      test -n \"$add\" && deplibs=\"$add $deplibs\"\n\t    fi\n\t  fi\n\telif test prog = \"$linkmode\"; then\n\t  # Here we assume that one of hardcode_direct or hardcode_minus_L\n\t  # is not unsupported.  This is valid on all known static and\n\t  # shared platforms.\n\t  if test unsupported != \"$hardcode_direct\"; then\n\t    test -n \"$old_library\" && linklib=$old_library\n\t    compile_deplibs=\"$dir/$linklib $compile_deplibs\"\n\t    finalize_deplibs=\"$dir/$linklib $finalize_deplibs\"\n\t  else\n\t    compile_deplibs=\"-l$name -L$dir $compile_deplibs\"\n\t    finalize_deplibs=\"-l$name -L$dir $finalize_deplibs\"\n\t  fi\n\telif test yes = \"$build_libtool_libs\"; then\n\t  # Not a shared library\n\t  if test pass_all != \"$deplibs_check_method\"; then\n\t    # We're trying link a shared library against a static one\n\t    # but the system doesn't support it.\n\n\t    # Just print a warning and add the library to dependency_libs so\n\t    # that the program can be linked against the static library.\n\t    echo\n\t    $ECHO \"*** Warning: This system cannot link to static lib archive $lib.\"\n\t    echo \"*** I have the capability to make that library automatically link in when\"\n\t    echo \"*** you link to this library.  But I can only do this if you have a\"\n\t    echo \"*** shared version of the library, which you do not appear to have.\"\n\t    if test yes = \"$module\"; then\n\t      echo \"*** But as you try to build a module library, libtool will still create \"\n\t      echo \"*** a static module, that should work as long as the dlopening application\"\n\t      echo \"*** is linked with the -dlopen flag to resolve symbols at runtime.\"\n\t      if test -z \"$global_symbol_pipe\"; then\n\t\techo\n\t\techo \"*** However, this would only work if libtool was able to extract symbol\"\n\t\techo \"*** lists from a program, using 'nm' or equivalent, but libtool could\"\n\t\techo \"*** not find such a program.  So, this module is probably useless.\"\n\t\techo \"*** 'nm' from GNU binutils and a full rebuild may help.\"\n\t      fi\n\t      if test no = \"$build_old_libs\"; then\n\t\tbuild_libtool_libs=module\n\t\tbuild_old_libs=yes\n\t      else\n\t\tbuild_libtool_libs=no\n\t      fi\n\t    fi\n\t  else\n\t    deplibs=\"$dir/$old_library $deplibs\"\n\t    link_static=yes\n\t  fi\n\tfi # link shared/static library?\n\n\tif test lib = \"$linkmode\"; then\n\t  if test -n \"$dependency_libs\" &&\n\t     { test yes != \"$hardcode_into_libs\" ||\n\t       test yes = \"$build_old_libs\" ||\n\t       test yes = \"$link_static\"; }; then\n\t    # Extract -R from dependency_libs\n\t    temp_deplibs=\n\t    for libdir in $dependency_libs; do\n\t      case $libdir in\n\t      -R*) func_stripname '-R' '' \"$libdir\"\n\t           temp_xrpath=$func_stripname_result\n\t\t   case \" $xrpath \" in\n\t\t   *\" $temp_xrpath \"*) ;;\n\t\t   *) func_append xrpath \" $temp_xrpath\";;\n\t\t   esac;;\n\t      *) func_append temp_deplibs \" $libdir\";;\n\t      esac\n\t    done\n\t    dependency_libs=$temp_deplibs\n\t  fi\n\n\t  func_append newlib_search_path \" $absdir\"\n\t  # Link against this library\n\t  test no = \"$link_static\" && newdependency_libs=\"$abs_ladir/$laname $newdependency_libs\"\n\t  # ... and its dependency_libs\n\t  tmp_libs=\n\t  for deplib in $dependency_libs; do\n\t    newdependency_libs=\"$deplib $newdependency_libs\"\n\t    case $deplib in\n              -L*) func_stripname '-L' '' \"$deplib\"\n                   func_resolve_sysroot \"$func_stripname_result\";;\n              *) func_resolve_sysroot \"$deplib\" ;;\n            esac\n\t    if $opt_preserve_dup_deps; then\n\t      case \"$tmp_libs \" in\n\t      *\" $func_resolve_sysroot_result \"*)\n                func_append specialdeplibs \" $func_resolve_sysroot_result\" ;;\n\t      esac\n\t    fi\n\t    func_append tmp_libs \" $func_resolve_sysroot_result\"\n\t  done\n\n\t  if test no != \"$link_all_deplibs\"; then\n\t    # Add the search paths of all dependency libraries\n\t    for deplib in $dependency_libs; do\n\t      path=\n\t      case $deplib in\n\t      -L*) path=$deplib ;;\n\t      *.la)\n\t        func_resolve_sysroot \"$deplib\"\n\t        deplib=$func_resolve_sysroot_result\n\t        func_dirname \"$deplib\" \"\" \".\"\n\t\tdir=$func_dirname_result\n\t\t# We need an absolute path.\n\t\tcase $dir in\n\t\t[\\\\/]* | [A-Za-z]:[\\\\/]*) absdir=$dir ;;\n\t\t*)\n\t\t  absdir=`cd \"$dir\" && pwd`\n\t\t  if test -z \"$absdir\"; then\n\t\t    func_warning \"cannot determine absolute directory name of '$dir'\"\n\t\t    absdir=$dir\n\t\t  fi\n\t\t  ;;\n\t\tesac\n\t\tif $GREP \"^installed=no\" $deplib > /dev/null; then\n\t\tcase $host in\n\t\t*-*-darwin*)\n\t\t  depdepl=\n\t\t  eval deplibrary_names=`$SED -n -e 's/^library_names=\\(.*\\)$/\\1/p' $deplib`\n\t\t  if test -n \"$deplibrary_names\"; then\n\t\t    for tmp in $deplibrary_names; do\n\t\t      depdepl=$tmp\n\t\t    done\n\t\t    if test -f \"$absdir/$objdir/$depdepl\"; then\n\t\t      depdepl=$absdir/$objdir/$depdepl\n\t\t      darwin_install_name=`$OTOOL -L $depdepl | awk '{if (NR == 2) {print $1;exit}}'`\n                      if test -z \"$darwin_install_name\"; then\n                          darwin_install_name=`$OTOOL64 -L $depdepl  | awk '{if (NR == 2) {print $1;exit}}'`\n                      fi\n\t\t      func_append compiler_flags \" $wl-dylib_file $wl$darwin_install_name:$depdepl\"\n\t\t      func_append linker_flags \" -dylib_file $darwin_install_name:$depdepl\"\n\t\t      path=\n\t\t    fi\n\t\t  fi\n\t\t  ;;\n\t\t*)\n\t\t  path=-L$absdir/$objdir\n\t\t  ;;\n\t\tesac\n\t\telse\n\t\t  eval libdir=`$SED -n -e 's/^libdir=\\(.*\\)$/\\1/p' $deplib`\n\t\t  test -z \"$libdir\" && \\\n\t\t    func_fatal_error \"'$deplib' is not a valid libtool archive\"\n\t\t  test \"$absdir\" != \"$libdir\" && \\\n\t\t    func_warning \"'$deplib' seems to be moved\"\n\n\t\t  path=-L$absdir\n\t\tfi\n\t\t;;\n\t      esac\n\t      case \" $deplibs \" in\n\t      *\" $path \"*) ;;\n\t      *) deplibs=\"$path $deplibs\" ;;\n\t      esac\n\t    done\n\t  fi # link_all_deplibs != no\n\tfi # linkmode = lib\n      done # for deplib in $libs\n      if test link = \"$pass\"; then\n\tif test prog = \"$linkmode\"; then\n\t  compile_deplibs=\"$new_inherited_linker_flags $compile_deplibs\"\n\t  finalize_deplibs=\"$new_inherited_linker_flags $finalize_deplibs\"\n\telse\n\t  compiler_flags=\"$compiler_flags \"`$ECHO \" $new_inherited_linker_flags\" | $SED 's% \\([^ $]*\\).ltframework% -framework \\1%g'`\n\tfi\n      fi\n      dependency_libs=$newdependency_libs\n      if test dlpreopen = \"$pass\"; then\n\t# Link the dlpreopened libraries before other libraries\n\tfor deplib in $save_deplibs; do\n\t  deplibs=\"$deplib $deplibs\"\n\tdone\n      fi\n      if test dlopen != \"$pass\"; then\n\ttest conv = \"$pass\" || {\n\t  # Make sure lib_search_path contains only unique directories.\n\t  lib_search_path=\n\t  for dir in $newlib_search_path; do\n\t    case \"$lib_search_path \" in\n\t    *\" $dir \"*) ;;\n\t    *) func_append lib_search_path \" $dir\" ;;\n\t    esac\n\t  done\n\t  newlib_search_path=\n\t}\n\n\tif test prog,link = \"$linkmode,$pass\"; then\n\t  vars=\"compile_deplibs finalize_deplibs\"\n\telse\n\t  vars=deplibs\n\tfi\n\tfor var in $vars dependency_libs; do\n\t  # Add libraries to $var in reverse order\n\t  eval tmp_libs=\\\"\\$$var\\\"\n\t  new_libs=\n\t  for deplib in $tmp_libs; do\n\t    # FIXME: Pedantically, this is the right thing to do, so\n\t    #        that some nasty dependency loop isn't accidentally\n\t    #        broken:\n\t    #new_libs=\"$deplib $new_libs\"\n\t    # Pragmatically, this seems to cause very few problems in\n\t    # practice:\n\t    case $deplib in\n\t    -L*) new_libs=\"$deplib $new_libs\" ;;\n\t    -R*) ;;\n\t    *)\n\t      # And here is the reason: when a library appears more\n\t      # than once as an explicit dependence of a library, or\n\t      # is implicitly linked in more than once by the\n\t      # compiler, it is considered special, and multiple\n\t      # occurrences thereof are not removed.  Compare this\n\t      # with having the same library being listed as a\n\t      # dependency of multiple other libraries: in this case,\n\t      # we know (pedantically, we assume) the library does not\n\t      # need to be listed more than once, so we keep only the\n\t      # last copy.  This is not always right, but it is rare\n\t      # enough that we require users that really mean to play\n\t      # such unportable linking tricks to link the library\n\t      # using -Wl,-lname, so that libtool does not consider it\n\t      # for duplicate removal.\n\t      case \" $specialdeplibs \" in\n\t      *\" $deplib \"*) new_libs=\"$deplib $new_libs\" ;;\n\t      *)\n\t\tcase \" $new_libs \" in\n\t\t*\" $deplib \"*) ;;\n\t\t*) new_libs=\"$deplib $new_libs\" ;;\n\t\tesac\n\t\t;;\n\t      esac\n\t      ;;\n\t    esac\n\t  done\n\t  tmp_libs=\n\t  for deplib in $new_libs; do\n\t    case $deplib in\n\t    -L*)\n\t      case \" $tmp_libs \" in\n\t      *\" $deplib \"*) ;;\n\t      *) func_append tmp_libs \" $deplib\" ;;\n\t      esac\n\t      ;;\n\t    *) func_append tmp_libs \" $deplib\" ;;\n\t    esac\n\t  done\n\t  eval $var=\\\"$tmp_libs\\\"\n\tdone # for var\n      fi\n\n      # Add Sun CC postdeps if required:\n      test CXX = \"$tagname\" && {\n        case $host_os in\n        linux*)\n          case `$CC -V 2>&1 | sed 5q` in\n          *Sun\\ C*) # Sun C++ 5.9\n            func_suncc_cstd_abi\n\n            if test no != \"$suncc_use_cstd_abi\"; then\n              func_append postdeps ' -library=Cstd -library=Crun'\n            fi\n            ;;\n          esac\n          ;;\n\n        solaris*)\n          func_cc_basename \"$CC\"\n          case $func_cc_basename_result in\n          CC* | sunCC*)\n            func_suncc_cstd_abi\n\n            if test no != \"$suncc_use_cstd_abi\"; then\n              func_append postdeps ' -library=Cstd -library=Crun'\n            fi\n            ;;\n          esac\n          ;;\n        esac\n      }\n\n      # Last step: remove runtime libs from dependency_libs\n      # (they stay in deplibs)\n      tmp_libs=\n      for i in $dependency_libs; do\n\tcase \" $predeps $postdeps $compiler_lib_search_path \" in\n\t*\" $i \"*)\n\t  i=\n\t  ;;\n\tesac\n\tif test -n \"$i\"; then\n\t  func_append tmp_libs \" $i\"\n\tfi\n      done\n      dependency_libs=$tmp_libs\n    done # for pass\n    if test prog = \"$linkmode\"; then\n      dlfiles=$newdlfiles\n    fi\n    if test prog = \"$linkmode\" || test lib = \"$linkmode\"; then\n      dlprefiles=$newdlprefiles\n    fi\n\n    case $linkmode in\n    oldlib)\n      if test -n \"$dlfiles$dlprefiles\" || test no != \"$dlself\"; then\n\tfunc_warning \"'-dlopen' is ignored for archives\"\n      fi\n\n      case \" $deplibs\" in\n      *\\ -l* | *\\ -L*)\n\tfunc_warning \"'-l' and '-L' are ignored for archives\" ;;\n      esac\n\n      test -n \"$rpath\" && \\\n\tfunc_warning \"'-rpath' is ignored for archives\"\n\n      test -n \"$xrpath\" && \\\n\tfunc_warning \"'-R' is ignored for archives\"\n\n      test -n \"$vinfo\" && \\\n\tfunc_warning \"'-version-info/-version-number' is ignored for archives\"\n\n      test -n \"$release\" && \\\n\tfunc_warning \"'-release' is ignored for archives\"\n\n      test -n \"$export_symbols$export_symbols_regex\" && \\\n\tfunc_warning \"'-export-symbols' is ignored for archives\"\n\n      # Now set the variables for building old libraries.\n      build_libtool_libs=no\n      oldlibs=$output\n      func_append objs \"$old_deplibs\"\n      ;;\n\n    lib)\n      # Make sure we only generate libraries of the form 'libNAME.la'.\n      case $outputname in\n      lib*)\n\tfunc_stripname 'lib' '.la' \"$outputname\"\n\tname=$func_stripname_result\n\teval shared_ext=\\\"$shrext_cmds\\\"\n\teval libname=\\\"$libname_spec\\\"\n\t;;\n      *)\n\ttest no = \"$module\" \\\n\t  && func_fatal_help \"libtool library '$output' must begin with 'lib'\"\n\n\tif test no != \"$need_lib_prefix\"; then\n\t  # Add the \"lib\" prefix for modules if required\n\t  func_stripname '' '.la' \"$outputname\"\n\t  name=$func_stripname_result\n\t  eval shared_ext=\\\"$shrext_cmds\\\"\n\t  eval libname=\\\"$libname_spec\\\"\n\telse\n\t  func_stripname '' '.la' \"$outputname\"\n\t  libname=$func_stripname_result\n\tfi\n\t;;\n      esac\n\n      if test -n \"$objs\"; then\n\tif test pass_all != \"$deplibs_check_method\"; then\n\t  func_fatal_error \"cannot build libtool library '$output' from non-libtool objects on this host:$objs\"\n\telse\n\t  echo\n\t  $ECHO \"*** Warning: Linking the shared library $output against the non-libtool\"\n\t  $ECHO \"*** objects $objs is not portable!\"\n\t  func_append libobjs \" $objs\"\n\tfi\n      fi\n\n      test no = \"$dlself\" \\\n\t|| func_warning \"'-dlopen self' is ignored for libtool libraries\"\n\n      set dummy $rpath\n      shift\n      test 1 -lt \"$#\" \\\n\t&& func_warning \"ignoring multiple '-rpath's for a libtool library\"\n\n      install_libdir=$1\n\n      oldlibs=\n      if test -z \"$rpath\"; then\n\tif test yes = \"$build_libtool_libs\"; then\n\t  # Building a libtool convenience library.\n\t  # Some compilers have problems with a '.al' extension so\n\t  # convenience libraries should have the same extension an\n\t  # archive normally would.\n\t  oldlibs=\"$output_objdir/$libname.$libext $oldlibs\"\n\t  build_libtool_libs=convenience\n\t  build_old_libs=yes\n\tfi\n\n\ttest -n \"$vinfo\" && \\\n\t  func_warning \"'-version-info/-version-number' is ignored for convenience libraries\"\n\n\ttest -n \"$release\" && \\\n\t  func_warning \"'-release' is ignored for convenience libraries\"\n      else\n\n\t# Parse the version information argument.\n\tsave_ifs=$IFS; IFS=:\n\tset dummy $vinfo 0 0 0\n\tshift\n\tIFS=$save_ifs\n\n\ttest -n \"$7\" && \\\n\t  func_fatal_help \"too many parameters to '-version-info'\"\n\n\t# convert absolute version numbers to libtool ages\n\t# this retains compatibility with .la files and attempts\n\t# to make the code below a bit more comprehensible\n\n\tcase $vinfo_number in\n\tyes)\n\t  number_major=$1\n\t  number_minor=$2\n\t  number_revision=$3\n\t  #\n\t  # There are really only two kinds -- those that\n\t  # use the current revision as the major version\n\t  # and those that subtract age and use age as\n\t  # a minor version.  But, then there is irix\n\t  # that has an extra 1 added just for fun\n\t  #\n\t  case $version_type in\n\t  # correct linux to gnu/linux during the next big refactor\n\t  darwin|freebsd-elf|linux|osf|windows|none)\n\t    func_arith $number_major + $number_minor\n\t    current=$func_arith_result\n\t    age=$number_minor\n\t    revision=$number_revision\n\t    ;;\n\t  freebsd-aout|qnx|sunos)\n\t    current=$number_major\n\t    revision=$number_minor\n\t    age=0\n\t    ;;\n\t  irix|nonstopux)\n\t    func_arith $number_major + $number_minor\n\t    current=$func_arith_result\n\t    age=$number_minor\n\t    revision=$number_minor\n\t    lt_irix_increment=no\n\t    ;;\n\t  *)\n\t    func_fatal_configuration \"$modename: unknown library version type '$version_type'\"\n\t    ;;\n\t  esac\n\t  ;;\n\tno)\n\t  current=$1\n\t  revision=$2\n\t  age=$3\n\t  ;;\n\tesac\n\n\t# Check that each of the things are valid numbers.\n\tcase $current in\n\t0|[1-9]|[1-9][0-9]|[1-9][0-9][0-9]|[1-9][0-9][0-9][0-9]|[1-9][0-9][0-9][0-9][0-9]) ;;\n\t*)\n\t  func_error \"CURRENT '$current' must be a nonnegative integer\"\n\t  func_fatal_error \"'$vinfo' is not valid version information\"\n\t  ;;\n\tesac\n\n\tcase $revision in\n\t0|[1-9]|[1-9][0-9]|[1-9][0-9][0-9]|[1-9][0-9][0-9][0-9]|[1-9][0-9][0-9][0-9][0-9]) ;;\n\t*)\n\t  func_error \"REVISION '$revision' must be a nonnegative integer\"\n\t  func_fatal_error \"'$vinfo' is not valid version information\"\n\t  ;;\n\tesac\n\n\tcase $age in\n\t0|[1-9]|[1-9][0-9]|[1-9][0-9][0-9]|[1-9][0-9][0-9][0-9]|[1-9][0-9][0-9][0-9][0-9]) ;;\n\t*)\n\t  func_error \"AGE '$age' must be a nonnegative integer\"\n\t  func_fatal_error \"'$vinfo' is not valid version information\"\n\t  ;;\n\tesac\n\n\tif test \"$age\" -gt \"$current\"; then\n\t  func_error \"AGE '$age' is greater than the current interface number '$current'\"\n\t  func_fatal_error \"'$vinfo' is not valid version information\"\n\tfi\n\n\t# Calculate the version variables.\n\tmajor=\n\tversuffix=\n\tverstring=\n\tcase $version_type in\n\tnone) ;;\n\n\tdarwin)\n\t  # Like Linux, but with the current version available in\n\t  # verstring for coding it into the library header\n\t  func_arith $current - $age\n\t  major=.$func_arith_result\n\t  versuffix=$major.$age.$revision\n\t  # Darwin ld doesn't like 0 for these options...\n\t  func_arith $current + 1\n\t  minor_current=$func_arith_result\n\t  xlcverstring=\"$wl-compatibility_version $wl$minor_current $wl-current_version $wl$minor_current.$revision\"\n\t  verstring=\"-compatibility_version $minor_current -current_version $minor_current.$revision\"\n          # On Darwin other compilers\n          case $CC in\n              nagfor*)\n                  verstring=\"$wl-compatibility_version $wl$minor_current $wl-current_version $wl$minor_current.$revision\"\n                  ;;\n              *)\n                  verstring=\"-compatibility_version $minor_current -current_version $minor_current.$revision\"\n                  ;;\n          esac\n\t  ;;\n\n\tfreebsd-aout)\n\t  major=.$current\n\t  versuffix=.$current.$revision\n\t  ;;\n\n\tfreebsd-elf)\n\t  func_arith $current - $age\n\t  major=.$func_arith_result\n\t  versuffix=$major.$age.$revision\n\t  ;;\n\n\tirix | nonstopux)\n\t  if test no = \"$lt_irix_increment\"; then\n\t    func_arith $current - $age\n\t  else\n\t    func_arith $current - $age + 1\n\t  fi\n\t  major=$func_arith_result\n\n\t  case $version_type in\n\t    nonstopux) verstring_prefix=nonstopux ;;\n\t    *)         verstring_prefix=sgi ;;\n\t  esac\n\t  verstring=$verstring_prefix$major.$revision\n\n\t  # Add in all the interfaces that we are compatible with.\n\t  loop=$revision\n\t  while test 0 -ne \"$loop\"; do\n\t    func_arith $revision - $loop\n\t    iface=$func_arith_result\n\t    func_arith $loop - 1\n\t    loop=$func_arith_result\n\t    verstring=$verstring_prefix$major.$iface:$verstring\n\t  done\n\n\t  # Before this point, $major must not contain '.'.\n\t  major=.$major\n\t  versuffix=$major.$revision\n\t  ;;\n\n\tlinux) # correct to gnu/linux during the next big refactor\n\t  func_arith $current - $age\n\t  major=.$func_arith_result\n\t  versuffix=$major.$age.$revision\n\t  ;;\n\n\tosf)\n\t  func_arith $current - $age\n\t  major=.$func_arith_result\n\t  versuffix=.$current.$age.$revision\n\t  verstring=$current.$age.$revision\n\n\t  # Add in all the interfaces that we are compatible with.\n\t  loop=$age\n\t  while test 0 -ne \"$loop\"; do\n\t    func_arith $current - $loop\n\t    iface=$func_arith_result\n\t    func_arith $loop - 1\n\t    loop=$func_arith_result\n\t    verstring=$verstring:$iface.0\n\t  done\n\n\t  # Make executables depend on our current version.\n\t  func_append verstring \":$current.0\"\n\t  ;;\n\n\tqnx)\n\t  major=.$current\n\t  versuffix=.$current\n\t  ;;\n\n\tsco)\n\t  major=.$current\n\t  versuffix=.$current\n\t  ;;\n\n\tsunos)\n\t  major=.$current\n\t  versuffix=.$current.$revision\n\t  ;;\n\n\twindows)\n\t  # Use '-' rather than '.', since we only want one\n\t  # extension on DOS 8.3 file systems.\n\t  func_arith $current - $age\n\t  major=$func_arith_result\n\t  versuffix=-$major\n\t  ;;\n\n\t*)\n\t  func_fatal_configuration \"unknown library version type '$version_type'\"\n\t  ;;\n\tesac\n\n\t# Clear the version info if we defaulted, and they specified a release.\n\tif test -z \"$vinfo\" && test -n \"$release\"; then\n\t  major=\n\t  case $version_type in\n\t  darwin)\n\t    # we can't check for \"0.0\" in archive_cmds due to quoting\n\t    # problems, so we reset it completely\n\t    verstring=\n\t    ;;\n\t  *)\n\t    verstring=0.0\n\t    ;;\n\t  esac\n\t  if test no = \"$need_version\"; then\n\t    versuffix=\n\t  else\n\t    versuffix=.0.0\n\t  fi\n\tfi\n\n\t# Remove version info from name if versioning should be avoided\n\tif test yes,no = \"$avoid_version,$need_version\"; then\n\t  major=\n\t  versuffix=\n\t  verstring=\n\tfi\n\n\t# Check to see if the archive will have undefined symbols.\n\tif test yes = \"$allow_undefined\"; then\n\t  if test unsupported = \"$allow_undefined_flag\"; then\n\t    if test yes = \"$build_old_libs\"; then\n\t      func_warning \"undefined symbols not allowed in $host shared libraries; building static only\"\n\t      build_libtool_libs=no\n\t    else\n\t      func_fatal_error \"can't build $host shared library unless -no-undefined is specified\"\n\t    fi\n\t  fi\n\telse\n\t  # Don't allow undefined symbols.\n\t  allow_undefined_flag=$no_undefined_flag\n\tfi\n\n      fi\n\n      func_generate_dlsyms \"$libname\" \"$libname\" :\n      func_append libobjs \" $symfileobj\"\n      test \" \" = \"$libobjs\" && libobjs=\n\n      if test relink != \"$opt_mode\"; then\n\t# Remove our outputs, but don't remove object files since they\n\t# may have been created when compiling PIC objects.\n\tremovelist=\n\ttempremovelist=`$ECHO \"$output_objdir/*\"`\n\tfor p in $tempremovelist; do\n\t  case $p in\n\t    *.$objext | *.gcno)\n\t       ;;\n\t    $output_objdir/$outputname | $output_objdir/$libname.* | $output_objdir/$libname$release.*)\n\t       if test -n \"$precious_files_regex\"; then\n\t\t if $ECHO \"$p\" | $EGREP -e \"$precious_files_regex\" >/dev/null 2>&1\n\t\t then\n\t\t   continue\n\t\t fi\n\t       fi\n\t       func_append removelist \" $p\"\n\t       ;;\n\t    *) ;;\n\t  esac\n\tdone\n\ttest -n \"$removelist\" && \\\n\t  func_show_eval \"${RM}r \\$removelist\"\n      fi\n\n      # Now set the variables for building old libraries.\n      if test yes = \"$build_old_libs\" && test convenience != \"$build_libtool_libs\"; then\n\tfunc_append oldlibs \" $output_objdir/$libname.$libext\"\n\n\t# Transform .lo files to .o files.\n\toldobjs=\"$objs \"`$ECHO \"$libobjs\" | $SP2NL | $SED \"/\\.$libext$/d; $lo2o\" | $NL2SP`\n      fi\n\n      # Eliminate all temporary directories.\n      #for path in $notinst_path; do\n      #\tlib_search_path=`$ECHO \"$lib_search_path \" | $SED \"s% $path % %g\"`\n      #\tdeplibs=`$ECHO \"$deplibs \" | $SED \"s% -L$path % %g\"`\n      #\tdependency_libs=`$ECHO \"$dependency_libs \" | $SED \"s% -L$path % %g\"`\n      #done\n\n      if test -n \"$xrpath\"; then\n\t# If the user specified any rpath flags, then add them.\n\ttemp_xrpath=\n\tfor libdir in $xrpath; do\n\t  func_replace_sysroot \"$libdir\"\n\t  func_append temp_xrpath \" -R$func_replace_sysroot_result\"\n\t  case \"$finalize_rpath \" in\n\t  *\" $libdir \"*) ;;\n\t  *) func_append finalize_rpath \" $libdir\" ;;\n\t  esac\n\tdone\n\tif test yes != \"$hardcode_into_libs\" || test yes = \"$build_old_libs\"; then\n\t  dependency_libs=\"$temp_xrpath $dependency_libs\"\n\tfi\n      fi\n\n      # Make sure dlfiles contains only unique files that won't be dlpreopened\n      old_dlfiles=$dlfiles\n      dlfiles=\n      for lib in $old_dlfiles; do\n\tcase \" $dlprefiles $dlfiles \" in\n\t*\" $lib \"*) ;;\n\t*) func_append dlfiles \" $lib\" ;;\n\tesac\n      done\n\n      # Make sure dlprefiles contains only unique files\n      old_dlprefiles=$dlprefiles\n      dlprefiles=\n      for lib in $old_dlprefiles; do\n\tcase \"$dlprefiles \" in\n\t*\" $lib \"*) ;;\n\t*) func_append dlprefiles \" $lib\" ;;\n\tesac\n      done\n\n      if test yes = \"$build_libtool_libs\"; then\n\tif test -n \"$rpath\"; then\n\t  case $host in\n\t  *-*-cygwin* | *-*-mingw* | *-*-pw32* | *-*-os2* | *-*-beos* | *-cegcc* | *-*-haiku*)\n\t    # these systems don't actually have a c library (as such)!\n\t    ;;\n\t  *-*-rhapsody* | *-*-darwin1.[012])\n\t    # Rhapsody C library is in the System framework\n\t    func_append deplibs \" System.ltframework\"\n\t    ;;\n\t  *-*-netbsd*)\n\t    # Don't link with libc until the a.out ld.so is fixed.\n\t    ;;\n\t  *-*-openbsd* | *-*-freebsd* | *-*-dragonfly*)\n\t    # Do not include libc due to us having libc/libc_r.\n\t    ;;\n\t  *-*-sco3.2v5* | *-*-sco5v6*)\n\t    # Causes problems with __ctype\n\t    ;;\n\t  *-*-sysv4.2uw2* | *-*-sysv5* | *-*-unixware* | *-*-OpenUNIX*)\n\t    # Compiler inserts libc in the correct place for threads to work\n\t    ;;\n\t  *)\n\t    # Add libc to deplibs on all other systems if necessary.\n\t    if test yes = \"$build_libtool_need_lc\"; then\n\t      func_append deplibs \" -lc\"\n\t    fi\n\t    ;;\n\t  esac\n\tfi\n\n\t# Transform deplibs into only deplibs that can be linked in shared.\n\tname_save=$name\n\tlibname_save=$libname\n\trelease_save=$release\n\tversuffix_save=$versuffix\n\tmajor_save=$major\n\t# I'm not sure if I'm treating the release correctly.  I think\n\t# release should show up in the -l (ie -lgmp5) so we don't want to\n\t# add it in twice.  Is that correct?\n\trelease=\n\tversuffix=\n\tmajor=\n\tnewdeplibs=\n\tdroppeddeps=no\n\tcase $deplibs_check_method in\n\tpass_all)\n\t  # Don't check for shared/static.  Everything works.\n\t  # This might be a little naive.  We might want to check\n\t  # whether the library exists or not.  But this is on\n\t  # osf3 & osf4 and I'm not really sure... Just\n\t  # implementing what was already the behavior.\n\t  newdeplibs=$deplibs\n\t  ;;\n\ttest_compile)\n\t  # This code stresses the \"libraries are programs\" paradigm to its\n\t  # limits. Maybe even breaks it.  We compile a program, linking it\n\t  # against the deplibs as a proxy for the library.  Then we can check\n\t  # whether they linked in statically or dynamically with ldd.\n\t  $opt_dry_run || $RM conftest.c\n\t  cat > conftest.c <<EOF\n\t  int main() { return 0; }\nEOF\n\t  $opt_dry_run || $RM conftest\n\t  if $LTCC $LTCFLAGS -o conftest conftest.c $deplibs; then\n\t    ldd_output=`ldd conftest`\n\t    for i in $deplibs; do\n\t      case $i in\n\t      -l*)\n\t\tfunc_stripname -l '' \"$i\"\n\t\tname=$func_stripname_result\n\t\tif test yes = \"$allow_libtool_libs_with_static_runtimes\"; then\n\t\t  case \" $predeps $postdeps \" in\n\t\t  *\" $i \"*)\n\t\t    func_append newdeplibs \" $i\"\n\t\t    i=\n\t\t    ;;\n\t\t  esac\n\t\tfi\n\t\tif test -n \"$i\"; then\n\t\t  libname=`eval \"\\\\$ECHO \\\"$libname_spec\\\"\"`\n\t\t  deplib_matches=`eval \"\\\\$ECHO \\\"$library_names_spec\\\"\"`\n\t\t  set dummy $deplib_matches; shift\n\t\t  deplib_match=$1\n\t\t  if test `expr \"$ldd_output\" : \".*$deplib_match\"` -ne 0; then\n\t\t    func_append newdeplibs \" $i\"\n\t\t  else\n\t\t    droppeddeps=yes\n\t\t    echo\n\t\t    $ECHO \"*** Warning: dynamic linker does not accept needed library $i.\"\n\t\t    echo \"*** I have the capability to make that library automatically link in when\"\n\t\t    echo \"*** you link to this library.  But I can only do this if you have a\"\n\t\t    echo \"*** shared version of the library, which I believe you do not have\"\n\t\t    echo \"*** because a test_compile did reveal that the linker did not use it for\"\n\t\t    echo \"*** its dynamic dependency list that programs get resolved with at runtime.\"\n\t\t  fi\n\t\tfi\n\t\t;;\n\t      *)\n\t\tfunc_append newdeplibs \" $i\"\n\t\t;;\n\t      esac\n\t    done\n\t  else\n\t    # Error occurred in the first compile.  Let's try to salvage\n\t    # the situation: Compile a separate program for each library.\n\t    for i in $deplibs; do\n\t      case $i in\n\t      -l*)\n\t\tfunc_stripname -l '' \"$i\"\n\t\tname=$func_stripname_result\n\t\t$opt_dry_run || $RM conftest\n\t\tif $LTCC $LTCFLAGS -o conftest conftest.c $i; then\n\t\t  ldd_output=`ldd conftest`\n\t\t  if test yes = \"$allow_libtool_libs_with_static_runtimes\"; then\n\t\t    case \" $predeps $postdeps \" in\n\t\t    *\" $i \"*)\n\t\t      func_append newdeplibs \" $i\"\n\t\t      i=\n\t\t      ;;\n\t\t    esac\n\t\t  fi\n\t\t  if test -n \"$i\"; then\n\t\t    libname=`eval \"\\\\$ECHO \\\"$libname_spec\\\"\"`\n\t\t    deplib_matches=`eval \"\\\\$ECHO \\\"$library_names_spec\\\"\"`\n\t\t    set dummy $deplib_matches; shift\n\t\t    deplib_match=$1\n\t\t    if test `expr \"$ldd_output\" : \".*$deplib_match\"` -ne 0; then\n\t\t      func_append newdeplibs \" $i\"\n\t\t    else\n\t\t      droppeddeps=yes\n\t\t      echo\n\t\t      $ECHO \"*** Warning: dynamic linker does not accept needed library $i.\"\n\t\t      echo \"*** I have the capability to make that library automatically link in when\"\n\t\t      echo \"*** you link to this library.  But I can only do this if you have a\"\n\t\t      echo \"*** shared version of the library, which you do not appear to have\"\n\t\t      echo \"*** because a test_compile did reveal that the linker did not use this one\"\n\t\t      echo \"*** as a dynamic dependency that programs can get resolved with at runtime.\"\n\t\t    fi\n\t\t  fi\n\t\telse\n\t\t  droppeddeps=yes\n\t\t  echo\n\t\t  $ECHO \"*** Warning!  Library $i is needed by this library but I was not able to\"\n\t\t  echo \"*** make it link in!  You will probably need to install it or some\"\n\t\t  echo \"*** library that it depends on before this library will be fully\"\n\t\t  echo \"*** functional.  Installing it before continuing would be even better.\"\n\t\tfi\n\t\t;;\n\t      *)\n\t\tfunc_append newdeplibs \" $i\"\n\t\t;;\n\t      esac\n\t    done\n\t  fi\n\t  ;;\n\tfile_magic*)\n\t  set dummy $deplibs_check_method; shift\n\t  file_magic_regex=`expr \"$deplibs_check_method\" : \"$1 \\(.*\\)\"`\n\t  for a_deplib in $deplibs; do\n\t    case $a_deplib in\n\t    -l*)\n\t      func_stripname -l '' \"$a_deplib\"\n\t      name=$func_stripname_result\n\t      if test yes = \"$allow_libtool_libs_with_static_runtimes\"; then\n\t\tcase \" $predeps $postdeps \" in\n\t\t*\" $a_deplib \"*)\n\t\t  func_append newdeplibs \" $a_deplib\"\n\t\t  a_deplib=\n\t\t  ;;\n\t\tesac\n\t      fi\n\t      if test -n \"$a_deplib\"; then\n\t\tlibname=`eval \"\\\\$ECHO \\\"$libname_spec\\\"\"`\n\t\tif test -n \"$file_magic_glob\"; then\n\t\t  libnameglob=`func_echo_all \"$libname\" | $SED -e $file_magic_glob`\n\t\telse\n\t\t  libnameglob=$libname\n\t\tfi\n\t\ttest yes = \"$want_nocaseglob\" && nocaseglob=`shopt -p nocaseglob`\n\t\tfor i in $lib_search_path $sys_lib_search_path $shlib_search_path; do\n\t\t  if test yes = \"$want_nocaseglob\"; then\n\t\t    shopt -s nocaseglob\n\t\t    potential_libs=`ls $i/$libnameglob[.-]* 2>/dev/null`\n\t\t    $nocaseglob\n\t\t  else\n\t\t    potential_libs=`ls $i/$libnameglob[.-]* 2>/dev/null`\n\t\t  fi\n\t\t  for potent_lib in $potential_libs; do\n\t\t      # Follow soft links.\n\t\t      if ls -lLd \"$potent_lib\" 2>/dev/null |\n\t\t\t $GREP \" -> \" >/dev/null; then\n\t\t\tcontinue\n\t\t      fi\n\t\t      # The statement above tries to avoid entering an\n\t\t      # endless loop below, in case of cyclic links.\n\t\t      # We might still enter an endless loop, since a link\n\t\t      # loop can be closed while we follow links,\n\t\t      # but so what?\n\t\t      potlib=$potent_lib\n\t\t      while test -h \"$potlib\" 2>/dev/null; do\n\t\t\tpotliblink=`ls -ld $potlib | $SED 's/.* -> //'`\n\t\t\tcase $potliblink in\n\t\t\t[\\\\/]* | [A-Za-z]:[\\\\/]*) potlib=$potliblink;;\n\t\t\t*) potlib=`$ECHO \"$potlib\" | $SED 's|[^/]*$||'`\"$potliblink\";;\n\t\t\tesac\n\t\t      done\n\t\t      if eval $file_magic_cmd \\\"\\$potlib\\\" 2>/dev/null |\n\t\t\t $SED -e 10q |\n\t\t\t $EGREP \"$file_magic_regex\" > /dev/null; then\n\t\t\tfunc_append newdeplibs \" $a_deplib\"\n\t\t\ta_deplib=\n\t\t\tbreak 2\n\t\t      fi\n\t\t  done\n\t\tdone\n\t      fi\n\t      if test -n \"$a_deplib\"; then\n\t\tdroppeddeps=yes\n\t\techo\n\t\t$ECHO \"*** Warning: linker path does not have real file for library $a_deplib.\"\n\t\techo \"*** I have the capability to make that library automatically link in when\"\n\t\techo \"*** you link to this library.  But I can only do this if you have a\"\n\t\techo \"*** shared version of the library, which you do not appear to have\"\n\t\techo \"*** because I did check the linker path looking for a file starting\"\n\t\tif test -z \"$potlib\"; then\n\t\t  $ECHO \"*** with $libname but no candidates were found. (...for file magic test)\"\n\t\telse\n\t\t  $ECHO \"*** with $libname and none of the candidates passed a file format test\"\n\t\t  $ECHO \"*** using a file magic. Last file checked: $potlib\"\n\t\tfi\n\t      fi\n\t      ;;\n\t    *)\n\t      # Add a -L argument.\n\t      func_append newdeplibs \" $a_deplib\"\n\t      ;;\n\t    esac\n\t  done # Gone through all deplibs.\n\t  ;;\n\tmatch_pattern*)\n\t  set dummy $deplibs_check_method; shift\n\t  match_pattern_regex=`expr \"$deplibs_check_method\" : \"$1 \\(.*\\)\"`\n\t  for a_deplib in $deplibs; do\n\t    case $a_deplib in\n\t    -l*)\n\t      func_stripname -l '' \"$a_deplib\"\n\t      name=$func_stripname_result\n\t      if test yes = \"$allow_libtool_libs_with_static_runtimes\"; then\n\t\tcase \" $predeps $postdeps \" in\n\t\t*\" $a_deplib \"*)\n\t\t  func_append newdeplibs \" $a_deplib\"\n\t\t  a_deplib=\n\t\t  ;;\n\t\tesac\n\t      fi\n\t      if test -n \"$a_deplib\"; then\n\t\tlibname=`eval \"\\\\$ECHO \\\"$libname_spec\\\"\"`\n\t\tfor i in $lib_search_path $sys_lib_search_path $shlib_search_path; do\n\t\t  potential_libs=`ls $i/$libname[.-]* 2>/dev/null`\n\t\t  for potent_lib in $potential_libs; do\n\t\t    potlib=$potent_lib # see symlink-check above in file_magic test\n\t\t    if eval \"\\$ECHO \\\"$potent_lib\\\"\" 2>/dev/null | $SED 10q | \\\n\t\t       $EGREP \"$match_pattern_regex\" > /dev/null; then\n\t\t      func_append newdeplibs \" $a_deplib\"\n\t\t      a_deplib=\n\t\t      break 2\n\t\t    fi\n\t\t  done\n\t\tdone\n\t      fi\n\t      if test -n \"$a_deplib\"; then\n\t\tdroppeddeps=yes\n\t\techo\n\t\t$ECHO \"*** Warning: linker path does not have real file for library $a_deplib.\"\n\t\techo \"*** I have the capability to make that library automatically link in when\"\n\t\techo \"*** you link to this library.  But I can only do this if you have a\"\n\t\techo \"*** shared version of the library, which you do not appear to have\"\n\t\techo \"*** because I did check the linker path looking for a file starting\"\n\t\tif test -z \"$potlib\"; then\n\t\t  $ECHO \"*** with $libname but no candidates were found. (...for regex pattern test)\"\n\t\telse\n\t\t  $ECHO \"*** with $libname and none of the candidates passed a file format test\"\n\t\t  $ECHO \"*** using a regex pattern. Last file checked: $potlib\"\n\t\tfi\n\t      fi\n\t      ;;\n\t    *)\n\t      # Add a -L argument.\n\t      func_append newdeplibs \" $a_deplib\"\n\t      ;;\n\t    esac\n\t  done # Gone through all deplibs.\n\t  ;;\n\tnone | unknown | *)\n\t  newdeplibs=\n\t  tmp_deplibs=`$ECHO \" $deplibs\" | $SED 's/ -lc$//; s/ -[LR][^ ]*//g'`\n\t  if test yes = \"$allow_libtool_libs_with_static_runtimes\"; then\n\t    for i in $predeps $postdeps; do\n\t      # can't use Xsed below, because $i might contain '/'\n\t      tmp_deplibs=`$ECHO \" $tmp_deplibs\" | $SED \"s|$i||\"`\n\t    done\n\t  fi\n\t  case $tmp_deplibs in\n\t  *[!\\\t\\ ]*)\n\t    echo\n\t    if test none = \"$deplibs_check_method\"; then\n\t      echo \"*** Warning: inter-library dependencies are not supported in this platform.\"\n\t    else\n\t      echo \"*** Warning: inter-library dependencies are not known to be supported.\"\n\t    fi\n\t    echo \"*** All declared inter-library dependencies are being dropped.\"\n\t    droppeddeps=yes\n\t    ;;\n\t  esac\n\t  ;;\n\tesac\n\tversuffix=$versuffix_save\n\tmajor=$major_save\n\trelease=$release_save\n\tlibname=$libname_save\n\tname=$name_save\n\n\tcase $host in\n\t*-*-rhapsody* | *-*-darwin1.[012])\n\t  # On Rhapsody replace the C library with the System framework\n\t  newdeplibs=`$ECHO \" $newdeplibs\" | $SED 's/ -lc / System.ltframework /'`\n\t  ;;\n\tesac\n\n\tif test yes = \"$droppeddeps\"; then\n\t  if test yes = \"$module\"; then\n\t    echo\n\t    echo \"*** Warning: libtool could not satisfy all declared inter-library\"\n\t    $ECHO \"*** dependencies of module $libname.  Therefore, libtool will create\"\n\t    echo \"*** a static module, that should work as long as the dlopening\"\n\t    echo \"*** application is linked with the -dlopen flag.\"\n\t    if test -z \"$global_symbol_pipe\"; then\n\t      echo\n\t      echo \"*** However, this would only work if libtool was able to extract symbol\"\n\t      echo \"*** lists from a program, using 'nm' or equivalent, but libtool could\"\n\t      echo \"*** not find such a program.  So, this module is probably useless.\"\n\t      echo \"*** 'nm' from GNU binutils and a full rebuild may help.\"\n\t    fi\n\t    if test no = \"$build_old_libs\"; then\n\t      oldlibs=$output_objdir/$libname.$libext\n\t      build_libtool_libs=module\n\t      build_old_libs=yes\n\t    else\n\t      build_libtool_libs=no\n\t    fi\n\t  else\n\t    echo \"*** The inter-library dependencies that have been dropped here will be\"\n\t    echo \"*** automatically added whenever a program is linked with this library\"\n\t    echo \"*** or is declared to -dlopen it.\"\n\n\t    if test no = \"$allow_undefined\"; then\n\t      echo\n\t      echo \"*** Since this library must not contain undefined symbols,\"\n\t      echo \"*** because either the platform does not support them or\"\n\t      echo \"*** it was explicitly requested with -no-undefined,\"\n\t      echo \"*** libtool will only create a static version of it.\"\n\t      if test no = \"$build_old_libs\"; then\n\t\toldlibs=$output_objdir/$libname.$libext\n\t\tbuild_libtool_libs=module\n\t\tbuild_old_libs=yes\n\t      else\n\t\tbuild_libtool_libs=no\n\t      fi\n\t    fi\n\t  fi\n\tfi\n\t# Done checking deplibs!\n\tdeplibs=$newdeplibs\n      fi\n      # Time to change all our \"foo.ltframework\" stuff back to \"-framework foo\"\n      case $host in\n\t*-*-darwin*)\n\t  newdeplibs=`$ECHO \" $newdeplibs\" | $SED 's% \\([^ $]*\\).ltframework% -framework \\1%g'`\n\t  new_inherited_linker_flags=`$ECHO \" $new_inherited_linker_flags\" | $SED 's% \\([^ $]*\\).ltframework% -framework \\1%g'`\n\t  deplibs=`$ECHO \" $deplibs\" | $SED 's% \\([^ $]*\\).ltframework% -framework \\1%g'`\n\t  ;;\n      esac\n\n      # move library search paths that coincide with paths to not yet\n      # installed libraries to the beginning of the library search list\n      new_libs=\n      for path in $notinst_path; do\n\tcase \" $new_libs \" in\n\t*\" -L$path/$objdir \"*) ;;\n\t*)\n\t  case \" $deplibs \" in\n\t  *\" -L$path/$objdir \"*)\n\t    func_append new_libs \" -L$path/$objdir\" ;;\n\t  esac\n\t  ;;\n\tesac\n      done\n      for deplib in $deplibs; do\n\tcase $deplib in\n\t-L*)\n\t  case \" $new_libs \" in\n\t  *\" $deplib \"*) ;;\n\t  *) func_append new_libs \" $deplib\" ;;\n\t  esac\n\t  ;;\n\t*) func_append new_libs \" $deplib\" ;;\n\tesac\n      done\n      deplibs=$new_libs\n\n      # All the library-specific variables (install_libdir is set above).\n      library_names=\n      old_library=\n      dlname=\n\n      # Test again, we may have decided not to build it any more\n      if test yes = \"$build_libtool_libs\"; then\n\t# Remove $wl instances when linking with ld.\n\t# FIXME: should test the right _cmds variable.\n\tcase $archive_cmds in\n\t  *\\$LD\\ *) wl= ;;\n        esac\n\tif test yes = \"$hardcode_into_libs\"; then\n\t  # Hardcode the library paths\n\t  hardcode_libdirs=\n\t  dep_rpath=\n\t  rpath=$finalize_rpath\n\t  test relink = \"$opt_mode\" || rpath=$compile_rpath$rpath\n\t  for libdir in $rpath; do\n\t    if test -n \"$hardcode_libdir_flag_spec\"; then\n\t      if test -n \"$hardcode_libdir_separator\"; then\n\t\tfunc_replace_sysroot \"$libdir\"\n\t\tlibdir=$func_replace_sysroot_result\n\t\tif test -z \"$hardcode_libdirs\"; then\n\t\t  hardcode_libdirs=$libdir\n\t\telse\n\t\t  # Just accumulate the unique libdirs.\n\t\t  case $hardcode_libdir_separator$hardcode_libdirs$hardcode_libdir_separator in\n\t\t  *\"$hardcode_libdir_separator$libdir$hardcode_libdir_separator\"*)\n\t\t    ;;\n\t\t  *)\n\t\t    func_append hardcode_libdirs \"$hardcode_libdir_separator$libdir\"\n\t\t    ;;\n\t\t  esac\n\t\tfi\n\t      else\n\t\teval flag=\\\"$hardcode_libdir_flag_spec\\\"\n\t\tfunc_append dep_rpath \" $flag\"\n\t      fi\n\t    elif test -n \"$runpath_var\"; then\n\t      case \"$perm_rpath \" in\n\t      *\" $libdir \"*) ;;\n\t      *) func_append perm_rpath \" $libdir\" ;;\n\t      esac\n\t    fi\n\t  done\n\t  # Substitute the hardcoded libdirs into the rpath.\n\t  if test -n \"$hardcode_libdir_separator\" &&\n\t     test -n \"$hardcode_libdirs\"; then\n\t    libdir=$hardcode_libdirs\n\t    eval \"dep_rpath=\\\"$hardcode_libdir_flag_spec\\\"\"\n\t  fi\n\t  if test -n \"$runpath_var\" && test -n \"$perm_rpath\"; then\n\t    # We should set the runpath_var.\n\t    rpath=\n\t    for dir in $perm_rpath; do\n\t      func_append rpath \"$dir:\"\n\t    done\n\t    eval \"$runpath_var='$rpath\\$$runpath_var'; export $runpath_var\"\n\t  fi\n\t  test -n \"$dep_rpath\" && deplibs=\"$dep_rpath $deplibs\"\n\tfi\n\n\tshlibpath=$finalize_shlibpath\n\ttest relink = \"$opt_mode\" || shlibpath=$compile_shlibpath$shlibpath\n\tif test -n \"$shlibpath\"; then\n\t  eval \"$shlibpath_var='$shlibpath\\$$shlibpath_var'; export $shlibpath_var\"\n\tfi\n\n\t# Get the real and link names of the library.\n\teval shared_ext=\\\"$shrext_cmds\\\"\n\teval library_names=\\\"$library_names_spec\\\"\n\tset dummy $library_names\n\tshift\n\trealname=$1\n\tshift\n\n\tif test -n \"$soname_spec\"; then\n\t  eval soname=\\\"$soname_spec\\\"\n\telse\n\t  soname=$realname\n\tfi\n\tif test -z \"$dlname\"; then\n\t  dlname=$soname\n\tfi\n\n\tlib=$output_objdir/$realname\n\tlinknames=\n\tfor link\n\tdo\n\t  func_append linknames \" $link\"\n\tdone\n\n\t# Use standard objects if they are pic\n\ttest -z \"$pic_flag\" && libobjs=`$ECHO \"$libobjs\" | $SP2NL | $SED \"$lo2o\" | $NL2SP`\n\ttest \"X$libobjs\" = \"X \" && libobjs=\n\n\tdelfiles=\n\tif test -n \"$export_symbols\" && test -n \"$include_expsyms\"; then\n\t  $opt_dry_run || cp \"$export_symbols\" \"$output_objdir/$libname.uexp\"\n\t  export_symbols=$output_objdir/$libname.uexp\n\t  func_append delfiles \" $export_symbols\"\n\tfi\n\n\torig_export_symbols=\n\tcase $host_os in\n\tcygwin* | mingw* | cegcc*)\n\t  if test -n \"$export_symbols\" && test -z \"$export_symbols_regex\"; then\n\t    # exporting using user supplied symfile\n\t    func_dll_def_p \"$export_symbols\" || {\n\t      # and it's NOT already a .def file. Must figure out\n\t      # which of the given symbols are data symbols and tag\n\t      # them as such. So, trigger use of export_symbols_cmds.\n\t      # export_symbols gets reassigned inside the \"prepare\n\t      # the list of exported symbols\" if statement, so the\n\t      # include_expsyms logic still works.\n\t      orig_export_symbols=$export_symbols\n\t      export_symbols=\n\t      always_export_symbols=yes\n\t    }\n\t  fi\n\t  ;;\n\tesac\n\n\t# Prepare the list of exported symbols\n\tif test -z \"$export_symbols\"; then\n\t  if test yes = \"$always_export_symbols\" || test -n \"$export_symbols_regex\"; then\n\t    func_verbose \"generating symbol list for '$libname.la'\"\n\t    export_symbols=$output_objdir/$libname.exp\n\t    $opt_dry_run || $RM $export_symbols\n\t    cmds=$export_symbols_cmds\n\t    save_ifs=$IFS; IFS='~'\n\t    for cmd1 in $cmds; do\n\t      IFS=$save_ifs\n\t      # Take the normal branch if the nm_file_list_spec branch\n\t      # doesn't work or if tool conversion is not needed.\n\t      case $nm_file_list_spec~$to_tool_file_cmd in\n\t\t*~func_convert_file_noop | *~func_convert_file_msys_to_w32 | ~*)\n\t\t  try_normal_branch=yes\n\t\t  eval cmd=\\\"$cmd1\\\"\n\t\t  func_len \" $cmd\"\n\t\t  len=$func_len_result\n\t\t  ;;\n\t\t*)\n\t\t  try_normal_branch=no\n\t\t  ;;\n\t      esac\n\t      if test yes = \"$try_normal_branch\" \\\n\t\t && { test \"$len\" -lt \"$max_cmd_len\" \\\n\t\t      || test \"$max_cmd_len\" -le -1; }\n\t      then\n\t\tfunc_show_eval \"$cmd\" 'exit $?'\n\t\tskipped_export=false\n\t      elif test -n \"$nm_file_list_spec\"; then\n\t\tfunc_basename \"$output\"\n\t\toutput_la=$func_basename_result\n\t\tsave_libobjs=$libobjs\n\t\tsave_output=$output\n\t\toutput=$output_objdir/$output_la.nm\n\t\tfunc_to_tool_file \"$output\"\n\t\tlibobjs=$nm_file_list_spec$func_to_tool_file_result\n\t\tfunc_append delfiles \" $output\"\n\t\tfunc_verbose \"creating $NM input file list: $output\"\n\t\tfor obj in $save_libobjs; do\n\t\t  func_to_tool_file \"$obj\"\n\t\t  $ECHO \"$func_to_tool_file_result\"\n\t\tdone > \"$output\"\n\t\teval cmd=\\\"$cmd1\\\"\n\t\tfunc_show_eval \"$cmd\" 'exit $?'\n\t\toutput=$save_output\n\t\tlibobjs=$save_libobjs\n\t\tskipped_export=false\n\t      else\n\t\t# The command line is too long to execute in one step.\n\t\tfunc_verbose \"using reloadable object file for export list...\"\n\t\tskipped_export=:\n\t\t# Break out early, otherwise skipped_export may be\n\t\t# set to false by a later but shorter cmd.\n\t\tbreak\n\t      fi\n\t    done\n\t    IFS=$save_ifs\n\t    if test -n \"$export_symbols_regex\" && test : != \"$skipped_export\"; then\n\t      func_show_eval '$EGREP -e \"$export_symbols_regex\" \"$export_symbols\" > \"${export_symbols}T\"'\n\t      func_show_eval '$MV \"${export_symbols}T\" \"$export_symbols\"'\n\t    fi\n\t  fi\n\tfi\n\n\tif test -n \"$export_symbols\" && test -n \"$include_expsyms\"; then\n\t  tmp_export_symbols=$export_symbols\n\t  test -n \"$orig_export_symbols\" && tmp_export_symbols=$orig_export_symbols\n\t  $opt_dry_run || eval '$ECHO \"$include_expsyms\" | $SP2NL >> \"$tmp_export_symbols\"'\n\tfi\n\n\tif test : != \"$skipped_export\" && test -n \"$orig_export_symbols\"; then\n\t  # The given exports_symbols file has to be filtered, so filter it.\n\t  func_verbose \"filter symbol list for '$libname.la' to tag DATA exports\"\n\t  # FIXME: $output_objdir/$libname.filter potentially contains lots of\n\t  # 's' commands, which not all seds can handle. GNU sed should be fine\n\t  # though. Also, the filter scales superlinearly with the number of\n\t  # global variables. join(1) would be nice here, but unfortunately\n\t  # isn't a blessed tool.\n\t  $opt_dry_run || $SED -e '/[ ,]DATA/!d;s,\\(.*\\)\\([ \\,].*\\),s|^\\1$|\\1\\2|,' < $export_symbols > $output_objdir/$libname.filter\n\t  func_append delfiles \" $export_symbols $output_objdir/$libname.filter\"\n\t  export_symbols=$output_objdir/$libname.def\n\t  $opt_dry_run || $SED -f $output_objdir/$libname.filter < $orig_export_symbols > $export_symbols\n\tfi\n\n\ttmp_deplibs=\n\tfor test_deplib in $deplibs; do\n\t  case \" $convenience \" in\n\t  *\" $test_deplib \"*) ;;\n\t  *)\n\t    func_append tmp_deplibs \" $test_deplib\"\n\t    ;;\n\t  esac\n\tdone\n\tdeplibs=$tmp_deplibs\n\n\tif test -n \"$convenience\"; then\n\t  if test -n \"$whole_archive_flag_spec\" &&\n\t    test yes = \"$compiler_needs_object\" &&\n\t    test -z \"$libobjs\"; then\n\t    # extract the archives, so we have objects to list.\n\t    # TODO: could optimize this to just extract one archive.\n\t    whole_archive_flag_spec=\n\t  fi\n\t  if test -n \"$whole_archive_flag_spec\"; then\n\t    save_libobjs=$libobjs\n\t    eval libobjs=\\\"\\$libobjs $whole_archive_flag_spec\\\"\n\t    test \"X$libobjs\" = \"X \" && libobjs=\n\t  else\n\t    gentop=$output_objdir/${outputname}x\n\t    func_append generated \" $gentop\"\n\n\t    func_extract_archives $gentop $convenience\n\t    func_append libobjs \" $func_extract_archives_result\"\n\t    test \"X$libobjs\" = \"X \" && libobjs=\n\t  fi\n\tfi\n\n\tif test yes = \"$thread_safe\" && test -n \"$thread_safe_flag_spec\"; then\n\t  eval flag=\\\"$thread_safe_flag_spec\\\"\n\t  func_append linker_flags \" $flag\"\n\tfi\n\n\t# Make a backup of the uninstalled library when relinking\n\tif test relink = \"$opt_mode\"; then\n\t  $opt_dry_run || eval '(cd $output_objdir && $RM ${realname}U && $MV $realname ${realname}U)' || exit $?\n\tfi\n\n\t# Do each of the archive commands.\n\tif test yes = \"$module\" && test -n \"$module_cmds\"; then\n\t  if test -n \"$export_symbols\" && test -n \"$module_expsym_cmds\"; then\n\t    eval test_cmds=\\\"$module_expsym_cmds\\\"\n\t    cmds=$module_expsym_cmds\n\t  else\n\t    eval test_cmds=\\\"$module_cmds\\\"\n\t    cmds=$module_cmds\n\t  fi\n\telse\n\t  if test -n \"$export_symbols\" && test -n \"$archive_expsym_cmds\"; then\n\t    eval test_cmds=\\\"$archive_expsym_cmds\\\"\n\t    cmds=$archive_expsym_cmds\n\t  else\n\t    eval test_cmds=\\\"$archive_cmds\\\"\n\t    cmds=$archive_cmds\n\t  fi\n\tfi\n\n\tif test : != \"$skipped_export\" &&\n\t   func_len \" $test_cmds\" &&\n\t   len=$func_len_result &&\n\t   test \"$len\" -lt \"$max_cmd_len\" || test \"$max_cmd_len\" -le -1; then\n\t  :\n\telse\n\t  # The command line is too long to link in one step, link piecewise\n\t  # or, if using GNU ld and skipped_export is not :, use a linker\n\t  # script.\n\n\t  # Save the value of $output and $libobjs because we want to\n\t  # use them later.  If we have whole_archive_flag_spec, we\n\t  # want to use save_libobjs as it was before\n\t  # whole_archive_flag_spec was expanded, because we can't\n\t  # assume the linker understands whole_archive_flag_spec.\n\t  # This may have to be revisited, in case too many\n\t  # convenience libraries get linked in and end up exceeding\n\t  # the spec.\n\t  if test -z \"$convenience\" || test -z \"$whole_archive_flag_spec\"; then\n\t    save_libobjs=$libobjs\n\t  fi\n\t  save_output=$output\n\t  func_basename \"$output\"\n\t  output_la=$func_basename_result\n\n\t  # Clear the reloadable object creation command queue and\n\t  # initialize k to one.\n\t  test_cmds=\n\t  concat_cmds=\n\t  objlist=\n\t  last_robj=\n\t  k=1\n\n\t  if test -n \"$save_libobjs\" && test : != \"$skipped_export\" && test yes = \"$with_gnu_ld\"; then\n\t    output=$output_objdir/$output_la.lnkscript\n\t    func_verbose \"creating GNU ld script: $output\"\n\t    echo 'INPUT (' > $output\n\t    for obj in $save_libobjs\n\t    do\n\t      func_to_tool_file \"$obj\"\n\t      $ECHO \"$func_to_tool_file_result\" >> $output\n\t    done\n\t    echo ')' >> $output\n\t    func_append delfiles \" $output\"\n\t    func_to_tool_file \"$output\"\n\t    output=$func_to_tool_file_result\n\t  elif test -n \"$save_libobjs\" && test : != \"$skipped_export\" && test -n \"$file_list_spec\"; then\n\t    output=$output_objdir/$output_la.lnk\n\t    func_verbose \"creating linker input file list: $output\"\n\t    : > $output\n\t    set x $save_libobjs\n\t    shift\n\t    firstobj=\n\t    if test yes = \"$compiler_needs_object\"; then\n\t      firstobj=\"$1 \"\n\t      shift\n\t    fi\n\t    for obj\n\t    do\n\t      func_to_tool_file \"$obj\"\n\t      $ECHO \"$func_to_tool_file_result\" >> $output\n\t    done\n\t    func_append delfiles \" $output\"\n\t    func_to_tool_file \"$output\"\n\t    output=$firstobj\\\"$file_list_spec$func_to_tool_file_result\\\"\n\t  else\n\t    if test -n \"$save_libobjs\"; then\n\t      func_verbose \"creating reloadable object files...\"\n\t      output=$output_objdir/$output_la-$k.$objext\n\t      eval test_cmds=\\\"$reload_cmds\\\"\n\t      func_len \" $test_cmds\"\n\t      len0=$func_len_result\n\t      len=$len0\n\n\t      # Loop over the list of objects to be linked.\n\t      for obj in $save_libobjs\n\t      do\n\t\tfunc_len \" $obj\"\n\t\tfunc_arith $len + $func_len_result\n\t\tlen=$func_arith_result\n\t\tif test -z \"$objlist\" ||\n\t\t   test \"$len\" -lt \"$max_cmd_len\"; then\n\t\t  func_append objlist \" $obj\"\n\t\telse\n\t\t  # The command $test_cmds is almost too long, add a\n\t\t  # command to the queue.\n\t\t  if test 1 -eq \"$k\"; then\n\t\t    # The first file doesn't have a previous command to add.\n\t\t    reload_objs=$objlist\n\t\t    eval concat_cmds=\\\"$reload_cmds\\\"\n\t\t  else\n\t\t    # All subsequent reloadable object files will link in\n\t\t    # the last one created.\n\t\t    reload_objs=\"$objlist $last_robj\"\n\t\t    eval concat_cmds=\\\"\\$concat_cmds~$reload_cmds~\\$RM $last_robj\\\"\n\t\t  fi\n\t\t  last_robj=$output_objdir/$output_la-$k.$objext\n\t\t  func_arith $k + 1\n\t\t  k=$func_arith_result\n\t\t  output=$output_objdir/$output_la-$k.$objext\n\t\t  objlist=\" $obj\"\n\t\t  func_len \" $last_robj\"\n\t\t  func_arith $len0 + $func_len_result\n\t\t  len=$func_arith_result\n\t\tfi\n\t      done\n\t      # Handle the remaining objects by creating one last\n\t      # reloadable object file.  All subsequent reloadable object\n\t      # files will link in the last one created.\n\t      test -z \"$concat_cmds\" || concat_cmds=$concat_cmds~\n\t      reload_objs=\"$objlist $last_robj\"\n\t      eval concat_cmds=\\\"\\$concat_cmds$reload_cmds\\\"\n\t      if test -n \"$last_robj\"; then\n\t        eval concat_cmds=\\\"\\$concat_cmds~\\$RM $last_robj\\\"\n\t      fi\n\t      func_append delfiles \" $output\"\n\n\t    else\n\t      output=\n\t    fi\n\n\t    ${skipped_export-false} && {\n\t      func_verbose \"generating symbol list for '$libname.la'\"\n\t      export_symbols=$output_objdir/$libname.exp\n\t      $opt_dry_run || $RM $export_symbols\n\t      libobjs=$output\n\t      # Append the command to create the export file.\n\t      test -z \"$concat_cmds\" || concat_cmds=$concat_cmds~\n\t      eval concat_cmds=\\\"\\$concat_cmds$export_symbols_cmds\\\"\n\t      if test -n \"$last_robj\"; then\n\t\teval concat_cmds=\\\"\\$concat_cmds~\\$RM $last_robj\\\"\n\t      fi\n\t    }\n\n\t    test -n \"$save_libobjs\" &&\n\t      func_verbose \"creating a temporary reloadable object file: $output\"\n\n\t    # Loop through the commands generated above and execute them.\n\t    save_ifs=$IFS; IFS='~'\n\t    for cmd in $concat_cmds; do\n\t      IFS=$save_ifs\n\t      $opt_quiet || {\n\t\t  func_quote_for_expand \"$cmd\"\n\t\t  eval \"func_echo $func_quote_for_expand_result\"\n\t      }\n\t      $opt_dry_run || eval \"$cmd\" || {\n\t\tlt_exit=$?\n\n\t\t# Restore the uninstalled library and exit\n\t\tif test relink = \"$opt_mode\"; then\n\t\t  ( cd \"$output_objdir\" && \\\n\t\t    $RM \"${realname}T\" && \\\n\t\t    $MV \"${realname}U\" \"$realname\" )\n\t\tfi\n\n\t\texit $lt_exit\n\t      }\n\t    done\n\t    IFS=$save_ifs\n\n\t    if test -n \"$export_symbols_regex\" && ${skipped_export-false}; then\n\t      func_show_eval '$EGREP -e \"$export_symbols_regex\" \"$export_symbols\" > \"${export_symbols}T\"'\n\t      func_show_eval '$MV \"${export_symbols}T\" \"$export_symbols\"'\n\t    fi\n\t  fi\n\n          ${skipped_export-false} && {\n\t    if test -n \"$export_symbols\" && test -n \"$include_expsyms\"; then\n\t      tmp_export_symbols=$export_symbols\n\t      test -n \"$orig_export_symbols\" && tmp_export_symbols=$orig_export_symbols\n\t      $opt_dry_run || eval '$ECHO \"$include_expsyms\" | $SP2NL >> \"$tmp_export_symbols\"'\n\t    fi\n\n\t    if test -n \"$orig_export_symbols\"; then\n\t      # The given exports_symbols file has to be filtered, so filter it.\n\t      func_verbose \"filter symbol list for '$libname.la' to tag DATA exports\"\n\t      # FIXME: $output_objdir/$libname.filter potentially contains lots of\n\t      # 's' commands, which not all seds can handle. GNU sed should be fine\n\t      # though. Also, the filter scales superlinearly with the number of\n\t      # global variables. join(1) would be nice here, but unfortunately\n\t      # isn't a blessed tool.\n\t      $opt_dry_run || $SED -e '/[ ,]DATA/!d;s,\\(.*\\)\\([ \\,].*\\),s|^\\1$|\\1\\2|,' < $export_symbols > $output_objdir/$libname.filter\n\t      func_append delfiles \" $export_symbols $output_objdir/$libname.filter\"\n\t      export_symbols=$output_objdir/$libname.def\n\t      $opt_dry_run || $SED -f $output_objdir/$libname.filter < $orig_export_symbols > $export_symbols\n\t    fi\n\t  }\n\n\t  libobjs=$output\n\t  # Restore the value of output.\n\t  output=$save_output\n\n\t  if test -n \"$convenience\" && test -n \"$whole_archive_flag_spec\"; then\n\t    eval libobjs=\\\"\\$libobjs $whole_archive_flag_spec\\\"\n\t    test \"X$libobjs\" = \"X \" && libobjs=\n\t  fi\n\t  # Expand the library linking commands again to reset the\n\t  # value of $libobjs for piecewise linking.\n\n\t  # Do each of the archive commands.\n\t  if test yes = \"$module\" && test -n \"$module_cmds\"; then\n\t    if test -n \"$export_symbols\" && test -n \"$module_expsym_cmds\"; then\n\t      cmds=$module_expsym_cmds\n\t    else\n\t      cmds=$module_cmds\n\t    fi\n\t  else\n\t    if test -n \"$export_symbols\" && test -n \"$archive_expsym_cmds\"; then\n\t      cmds=$archive_expsym_cmds\n\t    else\n\t      cmds=$archive_cmds\n\t    fi\n\t  fi\n\tfi\n\n\tif test -n \"$delfiles\"; then\n\t  # Append the command to remove temporary files to $cmds.\n\t  eval cmds=\\\"\\$cmds~\\$RM $delfiles\\\"\n\tfi\n\n\t# Add any objects from preloaded convenience libraries\n\tif test -n \"$dlprefiles\"; then\n\t  gentop=$output_objdir/${outputname}x\n\t  func_append generated \" $gentop\"\n\n\t  func_extract_archives $gentop $dlprefiles\n\t  func_append libobjs \" $func_extract_archives_result\"\n\t  test \"X$libobjs\" = \"X \" && libobjs=\n\tfi\n\n\tsave_ifs=$IFS; IFS='~'\n\tfor cmd in $cmds; do\n\t  IFS=$sp$nl\n\t  eval cmd=\\\"$cmd\\\"\n\t  IFS=$save_ifs\n\t  $opt_quiet || {\n\t    func_quote_for_expand \"$cmd\"\n\t    eval \"func_echo $func_quote_for_expand_result\"\n\t  }\n\t  $opt_dry_run || eval \"$cmd\" || {\n\t    lt_exit=$?\n\n\t    # Restore the uninstalled library and exit\n\t    if test relink = \"$opt_mode\"; then\n\t      ( cd \"$output_objdir\" && \\\n\t        $RM \"${realname}T\" && \\\n\t\t$MV \"${realname}U\" \"$realname\" )\n\t    fi\n\n\t    exit $lt_exit\n\t  }\n\tdone\n\tIFS=$save_ifs\n\n\t# Restore the uninstalled library and exit\n\tif test relink = \"$opt_mode\"; then\n\t  $opt_dry_run || eval '(cd $output_objdir && $RM ${realname}T && $MV $realname ${realname}T && $MV ${realname}U $realname)' || exit $?\n\n\t  if test -n \"$convenience\"; then\n\t    if test -z \"$whole_archive_flag_spec\"; then\n\t      func_show_eval '${RM}r \"$gentop\"'\n\t    fi\n\t  fi\n\n\t  exit $EXIT_SUCCESS\n\tfi\n\n\t# Create links to the real library.\n\tfor linkname in $linknames; do\n\t  if test \"$realname\" != \"$linkname\"; then\n\t    func_show_eval '(cd \"$output_objdir\" && $RM \"$linkname\" && $LN_S \"$realname\" \"$linkname\")' 'exit $?'\n\t  fi\n\tdone\n\n\t# If -module or -export-dynamic was specified, set the dlname.\n\tif test yes = \"$module\" || test yes = \"$export_dynamic\"; then\n\t  # On all known operating systems, these are identical.\n\t  dlname=$soname\n\tfi\n      fi\n      ;;\n\n    obj)\n      if test -n \"$dlfiles$dlprefiles\" || test no != \"$dlself\"; then\n\tfunc_warning \"'-dlopen' is ignored for objects\"\n      fi\n\n      case \" $deplibs\" in\n      *\\ -l* | *\\ -L*)\n\tfunc_warning \"'-l' and '-L' are ignored for objects\" ;;\n      esac\n\n      test -n \"$rpath\" && \\\n\tfunc_warning \"'-rpath' is ignored for objects\"\n\n      test -n \"$xrpath\" && \\\n\tfunc_warning \"'-R' is ignored for objects\"\n\n      test -n \"$vinfo\" && \\\n\tfunc_warning \"'-version-info' is ignored for objects\"\n\n      test -n \"$release\" && \\\n\tfunc_warning \"'-release' is ignored for objects\"\n\n      case $output in\n      *.lo)\n\ttest -n \"$objs$old_deplibs\" && \\\n\t  func_fatal_error \"cannot build library object '$output' from non-libtool objects\"\n\n\tlibobj=$output\n\tfunc_lo2o \"$libobj\"\n\tobj=$func_lo2o_result\n\t;;\n      *)\n\tlibobj=\n\tobj=$output\n\t;;\n      esac\n\n      # Delete the old objects.\n      $opt_dry_run || $RM $obj $libobj\n\n      # Objects from convenience libraries.  This assumes\n      # single-version convenience libraries.  Whenever we create\n      # different ones for PIC/non-PIC, this we'll have to duplicate\n      # the extraction.\n      reload_conv_objs=\n      gentop=\n      # if reload_cmds runs $LD directly, get rid of -Wl from\n      # whole_archive_flag_spec and hope we can get by with turning comma\n      # into space.\n      case $reload_cmds in\n        *\\$LD[\\ \\$]*) wl= ;;\n      esac\n      if test -n \"$convenience\"; then\n\tif test -n \"$whole_archive_flag_spec\"; then\n\t  eval tmp_whole_archive_flags=\\\"$whole_archive_flag_spec\\\"\n\t  test -n \"$wl\" || tmp_whole_archive_flags=`$ECHO \"$tmp_whole_archive_flags\" | $SED 's|,| |g'`\n\t  reload_conv_objs=$reload_objs\\ $tmp_whole_archive_flags\n\telse\n\t  gentop=$output_objdir/${obj}x\n\t  func_append generated \" $gentop\"\n\n\t  func_extract_archives $gentop $convenience\n\t  reload_conv_objs=\"$reload_objs $func_extract_archives_result\"\n\tfi\n      fi\n\n      # If we're not building shared, we need to use non_pic_objs\n      test yes = \"$build_libtool_libs\" || libobjs=$non_pic_objects\n\n      # Create the old-style object.\n      reload_objs=$objs$old_deplibs' '`$ECHO \"$libobjs\" | $SP2NL | $SED \"/\\.$libext$/d; /\\.lib$/d; $lo2o\" | $NL2SP`' '$reload_conv_objs\n\n      output=$obj\n      func_execute_cmds \"$reload_cmds\" 'exit $?'\n\n      # Exit if we aren't doing a library object file.\n      if test -z \"$libobj\"; then\n\tif test -n \"$gentop\"; then\n\t  func_show_eval '${RM}r \"$gentop\"'\n\tfi\n\n\texit $EXIT_SUCCESS\n      fi\n\n      test yes = \"$build_libtool_libs\" || {\n\tif test -n \"$gentop\"; then\n\t  func_show_eval '${RM}r \"$gentop\"'\n\tfi\n\n\t# Create an invalid libtool object if no PIC, so that we don't\n\t# accidentally link it into a program.\n\t# $show \"echo timestamp > $libobj\"\n\t# $opt_dry_run || eval \"echo timestamp > $libobj\" || exit $?\n\texit $EXIT_SUCCESS\n      }\n\n      if test -n \"$pic_flag\" || test default != \"$pic_mode\"; then\n\t# Only do commands if we really have different PIC objects.\n\treload_objs=\"$libobjs $reload_conv_objs\"\n\toutput=$libobj\n\tfunc_execute_cmds \"$reload_cmds\" 'exit $?'\n      fi\n\n      if test -n \"$gentop\"; then\n\tfunc_show_eval '${RM}r \"$gentop\"'\n      fi\n\n      exit $EXIT_SUCCESS\n      ;;\n\n    prog)\n      case $host in\n\t*cygwin*) func_stripname '' '.exe' \"$output\"\n\t          output=$func_stripname_result.exe;;\n      esac\n      test -n \"$vinfo\" && \\\n\tfunc_warning \"'-version-info' is ignored for programs\"\n\n      test -n \"$release\" && \\\n\tfunc_warning \"'-release' is ignored for programs\"\n\n      $preload \\\n\t&& test unknown,unknown,unknown = \"$dlopen_support,$dlopen_self,$dlopen_self_static\" \\\n\t&& func_warning \"'LT_INIT([dlopen])' not used. Assuming no dlopen support.\"\n\n      case $host in\n      *-*-rhapsody* | *-*-darwin1.[012])\n\t# On Rhapsody replace the C library is the System framework\n\tcompile_deplibs=`$ECHO \" $compile_deplibs\" | $SED 's/ -lc / System.ltframework /'`\n\tfinalize_deplibs=`$ECHO \" $finalize_deplibs\" | $SED 's/ -lc / System.ltframework /'`\n\t;;\n      esac\n\n      case $host in\n      *-*-darwin*)\n\t# Don't allow lazy linking, it breaks C++ global constructors\n\t# But is supposedly fixed on 10.4 or later (yay!).\n\tif test CXX = \"$tagname\"; then\n\t  case ${MACOSX_DEPLOYMENT_TARGET-10.0} in\n\t    10.[0123])\n\t      func_append compile_command \" $wl-bind_at_load\"\n\t      func_append finalize_command \" $wl-bind_at_load\"\n\t    ;;\n\t  esac\n\tfi\n\t# Time to change all our \"foo.ltframework\" stuff back to \"-framework foo\"\n\tcompile_deplibs=`$ECHO \" $compile_deplibs\" | $SED 's% \\([^ $]*\\).ltframework% -framework \\1%g'`\n\tfinalize_deplibs=`$ECHO \" $finalize_deplibs\" | $SED 's% \\([^ $]*\\).ltframework% -framework \\1%g'`\n\t;;\n      esac\n\n\n      # move library search paths that coincide with paths to not yet\n      # installed libraries to the beginning of the library search list\n      new_libs=\n      for path in $notinst_path; do\n\tcase \" $new_libs \" in\n\t*\" -L$path/$objdir \"*) ;;\n\t*)\n\t  case \" $compile_deplibs \" in\n\t  *\" -L$path/$objdir \"*)\n\t    func_append new_libs \" -L$path/$objdir\" ;;\n\t  esac\n\t  ;;\n\tesac\n      done\n      for deplib in $compile_deplibs; do\n\tcase $deplib in\n\t-L*)\n\t  case \" $new_libs \" in\n\t  *\" $deplib \"*) ;;\n\t  *) func_append new_libs \" $deplib\" ;;\n\t  esac\n\t  ;;\n\t*) func_append new_libs \" $deplib\" ;;\n\tesac\n      done\n      compile_deplibs=$new_libs\n\n\n      func_append compile_command \" $compile_deplibs\"\n      func_append finalize_command \" $finalize_deplibs\"\n\n      if test -n \"$rpath$xrpath\"; then\n\t# If the user specified any rpath flags, then add them.\n\tfor libdir in $rpath $xrpath; do\n\t  # This is the magic to use -rpath.\n\t  case \"$finalize_rpath \" in\n\t  *\" $libdir \"*) ;;\n\t  *) func_append finalize_rpath \" $libdir\" ;;\n\t  esac\n\tdone\n      fi\n\n      # Now hardcode the library paths\n      rpath=\n      hardcode_libdirs=\n      for libdir in $compile_rpath $finalize_rpath; do\n\tif test -n \"$hardcode_libdir_flag_spec\"; then\n\t  if test -n \"$hardcode_libdir_separator\"; then\n\t    if test -z \"$hardcode_libdirs\"; then\n\t      hardcode_libdirs=$libdir\n\t    else\n\t      # Just accumulate the unique libdirs.\n\t      case $hardcode_libdir_separator$hardcode_libdirs$hardcode_libdir_separator in\n\t      *\"$hardcode_libdir_separator$libdir$hardcode_libdir_separator\"*)\n\t\t;;\n\t      *)\n\t\tfunc_append hardcode_libdirs \"$hardcode_libdir_separator$libdir\"\n\t\t;;\n\t      esac\n\t    fi\n\t  else\n\t    eval flag=\\\"$hardcode_libdir_flag_spec\\\"\n\t    func_append rpath \" $flag\"\n\t  fi\n\telif test -n \"$runpath_var\"; then\n\t  case \"$perm_rpath \" in\n\t  *\" $libdir \"*) ;;\n\t  *) func_append perm_rpath \" $libdir\" ;;\n\t  esac\n\tfi\n\tcase $host in\n\t*-*-cygwin* | *-*-mingw* | *-*-pw32* | *-*-os2* | *-cegcc*)\n\t  testbindir=`$ECHO \"$libdir\" | $SED -e 's*/lib$*/bin*'`\n\t  case :$dllsearchpath: in\n\t  *\":$libdir:\"*) ;;\n\t  ::) dllsearchpath=$libdir;;\n\t  *) func_append dllsearchpath \":$libdir\";;\n\t  esac\n\t  case :$dllsearchpath: in\n\t  *\":$testbindir:\"*) ;;\n\t  ::) dllsearchpath=$testbindir;;\n\t  *) func_append dllsearchpath \":$testbindir\";;\n\t  esac\n\t  ;;\n\tesac\n      done\n      # Substitute the hardcoded libdirs into the rpath.\n      if test -n \"$hardcode_libdir_separator\" &&\n\t test -n \"$hardcode_libdirs\"; then\n\tlibdir=$hardcode_libdirs\n\teval rpath=\\\" $hardcode_libdir_flag_spec\\\"\n      fi\n      compile_rpath=$rpath\n\n      rpath=\n      hardcode_libdirs=\n      for libdir in $finalize_rpath; do\n\tif test -n \"$hardcode_libdir_flag_spec\"; then\n\t  if test -n \"$hardcode_libdir_separator\"; then\n\t    if test -z \"$hardcode_libdirs\"; then\n\t      hardcode_libdirs=$libdir\n\t    else\n\t      # Just accumulate the unique libdirs.\n\t      case $hardcode_libdir_separator$hardcode_libdirs$hardcode_libdir_separator in\n\t      *\"$hardcode_libdir_separator$libdir$hardcode_libdir_separator\"*)\n\t\t;;\n\t      *)\n\t\tfunc_append hardcode_libdirs \"$hardcode_libdir_separator$libdir\"\n\t\t;;\n\t      esac\n\t    fi\n\t  else\n\t    eval flag=\\\"$hardcode_libdir_flag_spec\\\"\n\t    func_append rpath \" $flag\"\n\t  fi\n\telif test -n \"$runpath_var\"; then\n\t  case \"$finalize_perm_rpath \" in\n\t  *\" $libdir \"*) ;;\n\t  *) func_append finalize_perm_rpath \" $libdir\" ;;\n\t  esac\n\tfi\n      done\n      # Substitute the hardcoded libdirs into the rpath.\n      if test -n \"$hardcode_libdir_separator\" &&\n\t test -n \"$hardcode_libdirs\"; then\n\tlibdir=$hardcode_libdirs\n\teval rpath=\\\" $hardcode_libdir_flag_spec\\\"\n      fi\n      finalize_rpath=$rpath\n\n      if test -n \"$libobjs\" && test yes = \"$build_old_libs\"; then\n\t# Transform all the library objects into standard objects.\n\tcompile_command=`$ECHO \"$compile_command\" | $SP2NL | $SED \"$lo2o\" | $NL2SP`\n\tfinalize_command=`$ECHO \"$finalize_command\" | $SP2NL | $SED \"$lo2o\" | $NL2SP`\n      fi\n\n      func_generate_dlsyms \"$outputname\" \"@PROGRAM@\" false\n\n      # template prelinking step\n      if test -n \"$prelink_cmds\"; then\n\tfunc_execute_cmds \"$prelink_cmds\" 'exit $?'\n      fi\n\n      wrappers_required=:\n      case $host in\n      *cegcc* | *mingw32ce*)\n        # Disable wrappers for cegcc and mingw32ce hosts, we are cross compiling anyway.\n        wrappers_required=false\n        ;;\n      *cygwin* | *mingw* )\n        test yes = \"$build_libtool_libs\" || wrappers_required=false\n        ;;\n      *)\n        if test no = \"$need_relink\" || test yes != \"$build_libtool_libs\"; then\n          wrappers_required=false\n        fi\n        ;;\n      esac\n      $wrappers_required || {\n\t# Replace the output file specification.\n\tcompile_command=`$ECHO \"$compile_command\" | $SED 's%@OUTPUT@%'\"$output\"'%g'`\n\tlink_command=$compile_command$compile_rpath\n\n\t# We have no uninstalled library dependencies, so finalize right now.\n\texit_status=0\n\tfunc_show_eval \"$link_command\" 'exit_status=$?'\n\n\tif test -n \"$postlink_cmds\"; then\n\t  func_to_tool_file \"$output\"\n\t  postlink_cmds=`func_echo_all \"$postlink_cmds\" | $SED -e 's%@OUTPUT@%'\"$output\"'%g' -e 's%@TOOL_OUTPUT@%'\"$func_to_tool_file_result\"'%g'`\n\t  func_execute_cmds \"$postlink_cmds\" 'exit $?'\n\tfi\n\n\t# Delete the generated files.\n\tif test -f \"$output_objdir/${outputname}S.$objext\"; then\n\t  func_show_eval '$RM \"$output_objdir/${outputname}S.$objext\"'\n\tfi\n\n\texit $exit_status\n      }\n\n      if test -n \"$compile_shlibpath$finalize_shlibpath\"; then\n\tcompile_command=\"$shlibpath_var=\\\"$compile_shlibpath$finalize_shlibpath\\$$shlibpath_var\\\" $compile_command\"\n      fi\n      if test -n \"$finalize_shlibpath\"; then\n\tfinalize_command=\"$shlibpath_var=\\\"$finalize_shlibpath\\$$shlibpath_var\\\" $finalize_command\"\n      fi\n\n      compile_var=\n      finalize_var=\n      if test -n \"$runpath_var\"; then\n\tif test -n \"$perm_rpath\"; then\n\t  # We should set the runpath_var.\n\t  rpath=\n\t  for dir in $perm_rpath; do\n\t    func_append rpath \"$dir:\"\n\t  done\n\t  compile_var=\"$runpath_var=\\\"$rpath\\$$runpath_var\\\" \"\n\tfi\n\tif test -n \"$finalize_perm_rpath\"; then\n\t  # We should set the runpath_var.\n\t  rpath=\n\t  for dir in $finalize_perm_rpath; do\n\t    func_append rpath \"$dir:\"\n\t  done\n\t  finalize_var=\"$runpath_var=\\\"$rpath\\$$runpath_var\\\" \"\n\tfi\n      fi\n\n      if test yes = \"$no_install\"; then\n\t# We don't need to create a wrapper script.\n\tlink_command=$compile_var$compile_command$compile_rpath\n\t# Replace the output file specification.\n\tlink_command=`$ECHO \"$link_command\" | $SED 's%@OUTPUT@%'\"$output\"'%g'`\n\t# Delete the old output file.\n\t$opt_dry_run || $RM $output\n\t# Link the executable and exit\n\tfunc_show_eval \"$link_command\" 'exit $?'\n\n\tif test -n \"$postlink_cmds\"; then\n\t  func_to_tool_file \"$output\"\n\t  postlink_cmds=`func_echo_all \"$postlink_cmds\" | $SED -e 's%@OUTPUT@%'\"$output\"'%g' -e 's%@TOOL_OUTPUT@%'\"$func_to_tool_file_result\"'%g'`\n\t  func_execute_cmds \"$postlink_cmds\" 'exit $?'\n\tfi\n\n\texit $EXIT_SUCCESS\n      fi\n\n      case $hardcode_action,$fast_install in\n        relink,*)\n\t  # Fast installation is not supported\n\t  link_command=$compile_var$compile_command$compile_rpath\n\t  relink_command=$finalize_var$finalize_command$finalize_rpath\n\n\t  func_warning \"this platform does not like uninstalled shared libraries\"\n\t  func_warning \"'$output' will be relinked during installation\"\n\t  ;;\n        *,yes)\n\t  link_command=$finalize_var$compile_command$finalize_rpath\n\t  relink_command=`$ECHO \"$compile_var$compile_command$compile_rpath\" | $SED 's%@OUTPUT@%\\$progdir/\\$file%g'`\n          ;;\n\t*,no)\n\t  link_command=$compile_var$compile_command$compile_rpath\n\t  relink_command=$finalize_var$finalize_command$finalize_rpath\n          ;;\n\t*,needless)\n\t  link_command=$finalize_var$compile_command$finalize_rpath\n\t  relink_command=\n          ;;\n      esac\n\n      # Replace the output file specification.\n      link_command=`$ECHO \"$link_command\" | $SED 's%@OUTPUT@%'\"$output_objdir/$outputname\"'%g'`\n\n      # Delete the old output files.\n      $opt_dry_run || $RM $output $output_objdir/$outputname $output_objdir/lt-$outputname\n\n      func_show_eval \"$link_command\" 'exit $?'\n\n      if test -n \"$postlink_cmds\"; then\n\tfunc_to_tool_file \"$output_objdir/$outputname\"\n\tpostlink_cmds=`func_echo_all \"$postlink_cmds\" | $SED -e 's%@OUTPUT@%'\"$output_objdir/$outputname\"'%g' -e 's%@TOOL_OUTPUT@%'\"$func_to_tool_file_result\"'%g'`\n\tfunc_execute_cmds \"$postlink_cmds\" 'exit $?'\n      fi\n\n      # Now create the wrapper script.\n      func_verbose \"creating $output\"\n\n      # Quote the relink command for shipping.\n      if test -n \"$relink_command\"; then\n\t# Preserve any variables that may affect compiler behavior\n\tfor var in $variables_saved_for_relink; do\n\t  if eval test -z \\\"\\${$var+set}\\\"; then\n\t    relink_command=\"{ test -z \\\"\\${$var+set}\\\" || $lt_unset $var || { $var=; export $var; }; }; $relink_command\"\n\t  elif eval var_value=\\$$var; test -z \"$var_value\"; then\n\t    relink_command=\"$var=; export $var; $relink_command\"\n\t  else\n\t    func_quote_for_eval \"$var_value\"\n\t    relink_command=\"$var=$func_quote_for_eval_result; export $var; $relink_command\"\n\t  fi\n\tdone\n\trelink_command=\"(cd `pwd`; $relink_command)\"\n\trelink_command=`$ECHO \"$relink_command\" | $SED \"$sed_quote_subst\"`\n      fi\n\n      # Only actually do things if not in dry run mode.\n      $opt_dry_run || {\n\t# win32 will think the script is a binary if it has\n\t# a .exe suffix, so we strip it off here.\n\tcase $output in\n\t  *.exe) func_stripname '' '.exe' \"$output\"\n\t         output=$func_stripname_result ;;\n\tesac\n\t# test for cygwin because mv fails w/o .exe extensions\n\tcase $host in\n\t  *cygwin*)\n\t    exeext=.exe\n\t    func_stripname '' '.exe' \"$outputname\"\n\t    outputname=$func_stripname_result ;;\n\t  *) exeext= ;;\n\tesac\n\tcase $host in\n\t  *cygwin* | *mingw* )\n\t    func_dirname_and_basename \"$output\" \"\" \".\"\n\t    output_name=$func_basename_result\n\t    output_path=$func_dirname_result\n\t    cwrappersource=$output_path/$objdir/lt-$output_name.c\n\t    cwrapper=$output_path/$output_name.exe\n\t    $RM $cwrappersource $cwrapper\n\t    trap \"$RM $cwrappersource $cwrapper; exit $EXIT_FAILURE\" 1 2 15\n\n\t    func_emit_cwrapperexe_src > $cwrappersource\n\n\t    # The wrapper executable is built using the $host compiler,\n\t    # because it contains $host paths and files. If cross-\n\t    # compiling, it, like the target executable, must be\n\t    # executed on the $host or under an emulation environment.\n\t    $opt_dry_run || {\n\t      $LTCC $LTCFLAGS -o $cwrapper $cwrappersource\n\t      $STRIP $cwrapper\n\t    }\n\n\t    # Now, create the wrapper script for func_source use:\n\t    func_ltwrapper_scriptname $cwrapper\n\t    $RM $func_ltwrapper_scriptname_result\n\t    trap \"$RM $func_ltwrapper_scriptname_result; exit $EXIT_FAILURE\" 1 2 15\n\t    $opt_dry_run || {\n\t      # note: this script will not be executed, so do not chmod.\n\t      if test \"x$build\" = \"x$host\"; then\n\t\t$cwrapper --lt-dump-script > $func_ltwrapper_scriptname_result\n\t      else\n\t\tfunc_emit_wrapper no > $func_ltwrapper_scriptname_result\n\t      fi\n\t    }\n\t  ;;\n\t  * )\n\t    $RM $output\n\t    trap \"$RM $output; exit $EXIT_FAILURE\" 1 2 15\n\n\t    func_emit_wrapper no > $output\n\t    chmod +x $output\n\t  ;;\n\tesac\n      }\n      exit $EXIT_SUCCESS\n      ;;\n    esac\n\n    # See if we need to build an old-fashioned archive.\n    for oldlib in $oldlibs; do\n\n      case $build_libtool_libs in\n        convenience)\n\t  oldobjs=\"$libobjs_save $symfileobj\"\n\t  addlibs=$convenience\n\t  build_libtool_libs=no\n\t  ;;\n\tmodule)\n\t  oldobjs=$libobjs_save\n\t  addlibs=$old_convenience\n\t  build_libtool_libs=no\n          ;;\n\t*)\n\t  oldobjs=\"$old_deplibs $non_pic_objects\"\n\t  $preload && test -f \"$symfileobj\" \\\n\t    && func_append oldobjs \" $symfileobj\"\n\t  addlibs=$old_convenience\n\t  ;;\n      esac\n\n      if test -n \"$addlibs\"; then\n\tgentop=$output_objdir/${outputname}x\n\tfunc_append generated \" $gentop\"\n\n\tfunc_extract_archives $gentop $addlibs\n\tfunc_append oldobjs \" $func_extract_archives_result\"\n      fi\n\n      # Do each command in the archive commands.\n      if test -n \"$old_archive_from_new_cmds\" && test yes = \"$build_libtool_libs\"; then\n\tcmds=$old_archive_from_new_cmds\n      else\n\n\t# Add any objects from preloaded convenience libraries\n\tif test -n \"$dlprefiles\"; then\n\t  gentop=$output_objdir/${outputname}x\n\t  func_append generated \" $gentop\"\n\n\t  func_extract_archives $gentop $dlprefiles\n\t  func_append oldobjs \" $func_extract_archives_result\"\n\tfi\n\n\t# POSIX demands no paths to be encoded in archives.  We have\n\t# to avoid creating archives with duplicate basenames if we\n\t# might have to extract them afterwards, e.g., when creating a\n\t# static archive out of a convenience library, or when linking\n\t# the entirety of a libtool archive into another (currently\n\t# not supported by libtool).\n\tif (for obj in $oldobjs\n\t    do\n\t      func_basename \"$obj\"\n\t      $ECHO \"$func_basename_result\"\n\t    done | sort | sort -uc >/dev/null 2>&1); then\n\t  :\n\telse\n\t  echo \"copying selected object files to avoid basename conflicts...\"\n\t  gentop=$output_objdir/${outputname}x\n\t  func_append generated \" $gentop\"\n\t  func_mkdir_p \"$gentop\"\n\t  save_oldobjs=$oldobjs\n\t  oldobjs=\n\t  counter=1\n\t  for obj in $save_oldobjs\n\t  do\n\t    func_basename \"$obj\"\n\t    objbase=$func_basename_result\n\t    case \" $oldobjs \" in\n\t    \" \") oldobjs=$obj ;;\n\t    *[\\ /]\"$objbase \"*)\n\t      while :; do\n\t\t# Make sure we don't pick an alternate name that also\n\t\t# overlaps.\n\t\tnewobj=lt$counter-$objbase\n\t\tfunc_arith $counter + 1\n\t\tcounter=$func_arith_result\n\t\tcase \" $oldobjs \" in\n\t\t*[\\ /]\"$newobj \"*) ;;\n\t\t*) if test ! -f \"$gentop/$newobj\"; then break; fi ;;\n\t\tesac\n\t      done\n\t      func_show_eval \"ln $obj $gentop/$newobj || cp $obj $gentop/$newobj\"\n\t      func_append oldobjs \" $gentop/$newobj\"\n\t      ;;\n\t    *) func_append oldobjs \" $obj\" ;;\n\t    esac\n\t  done\n\tfi\n\tfunc_to_tool_file \"$oldlib\" func_convert_file_msys_to_w32\n\ttool_oldlib=$func_to_tool_file_result\n\teval cmds=\\\"$old_archive_cmds\\\"\n\n\tfunc_len \" $cmds\"\n\tlen=$func_len_result\n\tif test \"$len\" -lt \"$max_cmd_len\" || test \"$max_cmd_len\" -le -1; then\n\t  cmds=$old_archive_cmds\n\telif test -n \"$archiver_list_spec\"; then\n\t  func_verbose \"using command file archive linking...\"\n\t  for obj in $oldobjs\n\t  do\n\t    func_to_tool_file \"$obj\"\n\t    $ECHO \"$func_to_tool_file_result\"\n\t  done > $output_objdir/$libname.libcmd\n\t  func_to_tool_file \"$output_objdir/$libname.libcmd\"\n\t  oldobjs=\" $archiver_list_spec$func_to_tool_file_result\"\n\t  cmds=$old_archive_cmds\n\telse\n\t  # the command line is too long to link in one step, link in parts\n\t  func_verbose \"using piecewise archive linking...\"\n\t  save_RANLIB=$RANLIB\n\t  RANLIB=:\n\t  objlist=\n\t  concat_cmds=\n\t  save_oldobjs=$oldobjs\n\t  oldobjs=\n\t  # Is there a better way of finding the last object in the list?\n\t  for obj in $save_oldobjs\n\t  do\n\t    last_oldobj=$obj\n\t  done\n\t  eval test_cmds=\\\"$old_archive_cmds\\\"\n\t  func_len \" $test_cmds\"\n\t  len0=$func_len_result\n\t  len=$len0\n\t  for obj in $save_oldobjs\n\t  do\n\t    func_len \" $obj\"\n\t    func_arith $len + $func_len_result\n\t    len=$func_arith_result\n\t    func_append objlist \" $obj\"\n\t    if test \"$len\" -lt \"$max_cmd_len\"; then\n\t      :\n\t    else\n\t      # the above command should be used before it gets too long\n\t      oldobjs=$objlist\n\t      if test \"$obj\" = \"$last_oldobj\"; then\n\t\tRANLIB=$save_RANLIB\n\t      fi\n\t      test -z \"$concat_cmds\" || concat_cmds=$concat_cmds~\n\t      eval concat_cmds=\\\"\\$concat_cmds$old_archive_cmds\\\"\n\t      objlist=\n\t      len=$len0\n\t    fi\n\t  done\n\t  RANLIB=$save_RANLIB\n\t  oldobjs=$objlist\n\t  if test -z \"$oldobjs\"; then\n\t    eval cmds=\\\"\\$concat_cmds\\\"\n\t  else\n\t    eval cmds=\\\"\\$concat_cmds~\\$old_archive_cmds\\\"\n\t  fi\n\tfi\n      fi\n      func_execute_cmds \"$cmds\" 'exit $?'\n    done\n\n    test -n \"$generated\" && \\\n      func_show_eval \"${RM}r$generated\"\n\n    # Now create the libtool archive.\n    case $output in\n    *.la)\n      old_library=\n      test yes = \"$build_old_libs\" && old_library=$libname.$libext\n      func_verbose \"creating $output\"\n\n      # Preserve any variables that may affect compiler behavior\n      for var in $variables_saved_for_relink; do\n\tif eval test -z \\\"\\${$var+set}\\\"; then\n\t  relink_command=\"{ test -z \\\"\\${$var+set}\\\" || $lt_unset $var || { $var=; export $var; }; }; $relink_command\"\n\telif eval var_value=\\$$var; test -z \"$var_value\"; then\n\t  relink_command=\"$var=; export $var; $relink_command\"\n\telse\n\t  func_quote_for_eval \"$var_value\"\n\t  relink_command=\"$var=$func_quote_for_eval_result; export $var; $relink_command\"\n\tfi\n      done\n      # Quote the link command for shipping.\n      relink_command=\"(cd `pwd`; $SHELL \\\"$progpath\\\" $preserve_args --mode=relink $libtool_args @inst_prefix_dir@)\"\n      relink_command=`$ECHO \"$relink_command\" | $SED \"$sed_quote_subst\"`\n      if test yes = \"$hardcode_automatic\"; then\n\trelink_command=\n      fi\n\n      # Only create the output if not a dry run.\n      $opt_dry_run || {\n\tfor installed in no yes; do\n\t  if test yes = \"$installed\"; then\n\t    if test -z \"$install_libdir\"; then\n\t      break\n\t    fi\n\t    output=$output_objdir/${outputname}i\n\t    # Replace all uninstalled libtool libraries with the installed ones\n\t    newdependency_libs=\n\t    for deplib in $dependency_libs; do\n\t      case $deplib in\n\t      *.la)\n\t\tfunc_basename \"$deplib\"\n\t\tname=$func_basename_result\n\t\tfunc_resolve_sysroot \"$deplib\"\n\t\teval libdir=`$SED -n -e 's/^libdir=\\(.*\\)$/\\1/p' $func_resolve_sysroot_result`\n\t\ttest -z \"$libdir\" && \\\n\t\t  func_fatal_error \"'$deplib' is not a valid libtool archive\"\n\t\tfunc_append newdependency_libs \" ${lt_sysroot:+=}$libdir/$name\"\n\t\t;;\n\t      -L*)\n\t\tfunc_stripname -L '' \"$deplib\"\n\t\tfunc_replace_sysroot \"$func_stripname_result\"\n\t\tfunc_append newdependency_libs \" -L$func_replace_sysroot_result\"\n\t\t;;\n\t      -R*)\n\t\tfunc_stripname -R '' \"$deplib\"\n\t\tfunc_replace_sysroot \"$func_stripname_result\"\n\t\tfunc_append newdependency_libs \" -R$func_replace_sysroot_result\"\n\t\t;;\n\t      *) func_append newdependency_libs \" $deplib\" ;;\n\t      esac\n\t    done\n\t    dependency_libs=$newdependency_libs\n\t    newdlfiles=\n\n\t    for lib in $dlfiles; do\n\t      case $lib in\n\t      *.la)\n\t        func_basename \"$lib\"\n\t\tname=$func_basename_result\n\t\teval libdir=`$SED -n -e 's/^libdir=\\(.*\\)$/\\1/p' $lib`\n\t\ttest -z \"$libdir\" && \\\n\t\t  func_fatal_error \"'$lib' is not a valid libtool archive\"\n\t\tfunc_append newdlfiles \" ${lt_sysroot:+=}$libdir/$name\"\n\t\t;;\n\t      *) func_append newdlfiles \" $lib\" ;;\n\t      esac\n\t    done\n\t    dlfiles=$newdlfiles\n\t    newdlprefiles=\n\t    for lib in $dlprefiles; do\n\t      case $lib in\n\t      *.la)\n\t\t# Only pass preopened files to the pseudo-archive (for\n\t\t# eventual linking with the app. that links it) if we\n\t\t# didn't already link the preopened objects directly into\n\t\t# the library:\n\t\tfunc_basename \"$lib\"\n\t\tname=$func_basename_result\n\t\teval libdir=`$SED -n -e 's/^libdir=\\(.*\\)$/\\1/p' $lib`\n\t\ttest -z \"$libdir\" && \\\n\t\t  func_fatal_error \"'$lib' is not a valid libtool archive\"\n\t\tfunc_append newdlprefiles \" ${lt_sysroot:+=}$libdir/$name\"\n\t\t;;\n\t      esac\n\t    done\n\t    dlprefiles=$newdlprefiles\n\t  else\n\t    newdlfiles=\n\t    for lib in $dlfiles; do\n\t      case $lib in\n\t\t[\\\\/]* | [A-Za-z]:[\\\\/]*) abs=$lib ;;\n\t\t*) abs=`pwd`\"/$lib\" ;;\n\t      esac\n\t      func_append newdlfiles \" $abs\"\n\t    done\n\t    dlfiles=$newdlfiles\n\t    newdlprefiles=\n\t    for lib in $dlprefiles; do\n\t      case $lib in\n\t\t[\\\\/]* | [A-Za-z]:[\\\\/]*) abs=$lib ;;\n\t\t*) abs=`pwd`\"/$lib\" ;;\n\t      esac\n\t      func_append newdlprefiles \" $abs\"\n\t    done\n\t    dlprefiles=$newdlprefiles\n\t  fi\n\t  $RM $output\n\t  # place dlname in correct position for cygwin\n\t  # In fact, it would be nice if we could use this code for all target\n\t  # systems that can't hard-code library paths into their executables\n\t  # and that have no shared library path variable independent of PATH,\n\t  # but it turns out we can't easily determine that from inspecting\n\t  # libtool variables, so we have to hard-code the OSs to which it\n\t  # applies here; at the moment, that means platforms that use the PE\n\t  # object format with DLL files.  See the long comment at the top of\n\t  # tests/bindir.at for full details.\n\t  tdlname=$dlname\n\t  case $host,$output,$installed,$module,$dlname in\n\t    *cygwin*,*lai,yes,no,*.dll | *mingw*,*lai,yes,no,*.dll | *cegcc*,*lai,yes,no,*.dll)\n\t      # If a -bindir argument was supplied, place the dll there.\n\t      if test -n \"$bindir\"; then\n\t\tfunc_relative_path \"$install_libdir\" \"$bindir\"\n\t\ttdlname=$func_relative_path_result/$dlname\n\t      else\n\t\t# Otherwise fall back on heuristic.\n\t\ttdlname=../bin/$dlname\n\t      fi\n\t      ;;\n\t  esac\n\t  $ECHO > $output \"\\\n# $outputname - a libtool library file\n# Generated by $PROGRAM (GNU $PACKAGE) $VERSION\n#\n# Please DO NOT delete this file!\n# It is necessary for linking the library.\n\n# The name that we can dlopen(3).\ndlname='$tdlname'\n\n# Names of this library.\nlibrary_names='$library_names'\n\n# The name of the static archive.\nold_library='$old_library'\n\n# Linker flags that cannot go in dependency_libs.\ninherited_linker_flags='$new_inherited_linker_flags'\n\n# Libraries that this one depends upon.\ndependency_libs='$dependency_libs'\n\n# Names of additional weak libraries provided by this library\nweak_library_names='$weak_libs'\n\n# Version information for $libname.\ncurrent=$current\nage=$age\nrevision=$revision\n\n# Is this an already installed library?\ninstalled=$installed\n\n# Should we warn about portability when linking against -modules?\nshouldnotlink=$module\n\n# Files to dlopen/dlpreopen\ndlopen='$dlfiles'\ndlpreopen='$dlprefiles'\n\n# Directory that this library needs to be installed in:\nlibdir='$install_libdir'\"\n\t  if test no,yes = \"$installed,$need_relink\"; then\n\t    $ECHO >> $output \"\\\nrelink_command=\\\"$relink_command\\\"\"\n\t  fi\n\tdone\n      }\n\n      # Do a symbolic link so that the libtool archive can be found in\n      # LD_LIBRARY_PATH before the program is installed.\n      func_show_eval '( cd \"$output_objdir\" && $RM \"$outputname\" && $LN_S \"../$outputname\" \"$outputname\" )' 'exit $?'\n      ;;\n    esac\n    exit $EXIT_SUCCESS\n}\n\nif test link = \"$opt_mode\" || test relink = \"$opt_mode\"; then\n  func_mode_link ${1+\"$@\"}\nfi\n\n\n# func_mode_uninstall arg...\nfunc_mode_uninstall ()\n{\n    $debug_cmd\n\n    RM=$nonopt\n    files=\n    rmforce=false\n    exit_status=0\n\n    # This variable tells wrapper scripts just to set variables rather\n    # than running their programs.\n    libtool_install_magic=$magic\n\n    for arg\n    do\n      case $arg in\n      -f) func_append RM \" $arg\"; rmforce=: ;;\n      -*) func_append RM \" $arg\" ;;\n      *) func_append files \" $arg\" ;;\n      esac\n    done\n\n    test -z \"$RM\" && \\\n      func_fatal_help \"you must specify an RM program\"\n\n    rmdirs=\n\n    for file in $files; do\n      func_dirname \"$file\" \"\" \".\"\n      dir=$func_dirname_result\n      if test . = \"$dir\"; then\n\todir=$objdir\n      else\n\todir=$dir/$objdir\n      fi\n      func_basename \"$file\"\n      name=$func_basename_result\n      test uninstall = \"$opt_mode\" && odir=$dir\n\n      # Remember odir for removal later, being careful to avoid duplicates\n      if test clean = \"$opt_mode\"; then\n\tcase \" $rmdirs \" in\n\t  *\" $odir \"*) ;;\n\t  *) func_append rmdirs \" $odir\" ;;\n\tesac\n      fi\n\n      # Don't error if the file doesn't exist and rm -f was used.\n      if { test -L \"$file\"; } >/dev/null 2>&1 ||\n\t { test -h \"$file\"; } >/dev/null 2>&1 ||\n\t test -f \"$file\"; then\n\t:\n      elif test -d \"$file\"; then\n\texit_status=1\n\tcontinue\n      elif $rmforce; then\n\tcontinue\n      fi\n\n      rmfiles=$file\n\n      case $name in\n      *.la)\n\t# Possibly a libtool archive, so verify it.\n\tif func_lalib_p \"$file\"; then\n\t  func_source $dir/$name\n\n\t  # Delete the libtool libraries and symlinks.\n\t  for n in $library_names; do\n\t    func_append rmfiles \" $odir/$n\"\n\t  done\n\t  test -n \"$old_library\" && func_append rmfiles \" $odir/$old_library\"\n\n\t  case $opt_mode in\n\t  clean)\n\t    case \" $library_names \" in\n\t    *\" $dlname \"*) ;;\n\t    *) test -n \"$dlname\" && func_append rmfiles \" $odir/$dlname\" ;;\n\t    esac\n\t    test -n \"$libdir\" && func_append rmfiles \" $odir/$name $odir/${name}i\"\n\t    ;;\n\t  uninstall)\n\t    if test -n \"$library_names\"; then\n\t      # Do each command in the postuninstall commands.\n\t      func_execute_cmds \"$postuninstall_cmds\" '$rmforce || exit_status=1'\n\t    fi\n\n\t    if test -n \"$old_library\"; then\n\t      # Do each command in the old_postuninstall commands.\n\t      func_execute_cmds \"$old_postuninstall_cmds\" '$rmforce || exit_status=1'\n\t    fi\n\t    # FIXME: should reinstall the best remaining shared library.\n\t    ;;\n\t  esac\n\tfi\n\t;;\n\n      *.lo)\n\t# Possibly a libtool object, so verify it.\n\tif func_lalib_p \"$file\"; then\n\n\t  # Read the .lo file\n\t  func_source $dir/$name\n\n\t  # Add PIC object to the list of files to remove.\n\t  if test -n \"$pic_object\" && test none != \"$pic_object\"; then\n\t    func_append rmfiles \" $dir/$pic_object\"\n\t  fi\n\n\t  # Add non-PIC object to the list of files to remove.\n\t  if test -n \"$non_pic_object\" && test none != \"$non_pic_object\"; then\n\t    func_append rmfiles \" $dir/$non_pic_object\"\n\t  fi\n\tfi\n\t;;\n\n      *)\n\tif test clean = \"$opt_mode\"; then\n\t  noexename=$name\n\t  case $file in\n\t  *.exe)\n\t    func_stripname '' '.exe' \"$file\"\n\t    file=$func_stripname_result\n\t    func_stripname '' '.exe' \"$name\"\n\t    noexename=$func_stripname_result\n\t    # $file with .exe has already been added to rmfiles,\n\t    # add $file without .exe\n\t    func_append rmfiles \" $file\"\n\t    ;;\n\t  esac\n\t  # Do a test to see if this is a libtool program.\n\t  if func_ltwrapper_p \"$file\"; then\n\t    if func_ltwrapper_executable_p \"$file\"; then\n\t      func_ltwrapper_scriptname \"$file\"\n\t      relink_command=\n\t      func_source $func_ltwrapper_scriptname_result\n\t      func_append rmfiles \" $func_ltwrapper_scriptname_result\"\n\t    else\n\t      relink_command=\n\t      func_source $dir/$noexename\n\t    fi\n\n\t    # note $name still contains .exe if it was in $file originally\n\t    # as does the version of $file that was added into $rmfiles\n\t    func_append rmfiles \" $odir/$name $odir/${name}S.$objext\"\n\t    if test yes = \"$fast_install\" && test -n \"$relink_command\"; then\n\t      func_append rmfiles \" $odir/lt-$name\"\n\t    fi\n\t    if test \"X$noexename\" != \"X$name\"; then\n\t      func_append rmfiles \" $odir/lt-$noexename.c\"\n\t    fi\n\t  fi\n\tfi\n\t;;\n      esac\n      func_show_eval \"$RM $rmfiles\" 'exit_status=1'\n    done\n\n    # Try to remove the $objdir's in the directories where we deleted files\n    for dir in $rmdirs; do\n      if test -d \"$dir\"; then\n\tfunc_show_eval \"rmdir $dir >/dev/null 2>&1\"\n      fi\n    done\n\n    exit $exit_status\n}\n\nif test uninstall = \"$opt_mode\" || test clean = \"$opt_mode\"; then\n  func_mode_uninstall ${1+\"$@\"}\nfi\n\ntest -z \"$opt_mode\" && {\n  help=$generic_help\n  func_fatal_help \"you must specify a MODE\"\n}\n\ntest -z \"$exec_cmd\" && \\\n  func_fatal_help \"invalid operation mode '$opt_mode'\"\n\nif test -n \"$exec_cmd\"; then\n  eval exec \"$exec_cmd\"\n  exit $EXIT_FAILURE\nfi\n\nexit $exit_status\n\n\n# The TAGs below are defined such that we never get into a situation\n# where we disable both kinds of libraries.  Given conflicting\n# choices, we go for a static library, that is the most portable,\n# since we can't tell whether shared libraries were disabled because\n# the user asked for that or because the platform doesn't support\n# them.  This is particularly important on AIX, because we don't\n# support having both static and shared libraries enabled at the same\n# time on that platform, so we default to a shared-only configuration.\n# If a disable-shared tag is given, we'll fallback to a static-only\n# configuration.  But we'll never go from static-only to shared-only.\n\n# ### BEGIN LIBTOOL TAG CONFIG: disable-shared\nbuild_libtool_libs=no\nbuild_old_libs=yes\n# ### END LIBTOOL TAG CONFIG: disable-shared\n\n# ### BEGIN LIBTOOL TAG CONFIG: disable-static\nbuild_old_libs=`case $build_libtool_libs in yes) echo no;; *) echo yes;; esac`\n# ### END LIBTOOL TAG CONFIG: disable-static\n\n# Local Variables:\n# mode:shell-script\n# sh-indentation:2\n# End:\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/auxdir/x_ac_dlfcn.m4": "# $NetBSD$\n\nAC_DEFUN([X_AC_DLFCN], [\n  AC_MSG_CHECKING([library containing dlopen])\n  AC_CHECK_LIB([], [dlopen], [ac_have_dlopen=yes; DL_LIBS=\"\"],\n    [AC_CHECK_LIB([dl], [dlopen], [ac_have_dlopen=yes; DL_LIBS=\"-ldl\"],\n      [AC_CHECK_LIB([svdl], [dlopen], [ac_have_dlopen=yes; DL_LIBS=\"-lsvdl\"])])])\n\n  AC_SUBST(DL_LIBS)\n])\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/contribs/pam_slurm_adopt/helper.c": "/*****************************************************************************\\\n *  pam_slurm_adopt/helper.c\n *****************************************************************************\n *  Useful portions extracted from pam_slurm.c by Ryan Cox <ryan_cox@byu.edu>\n *\n *  Copyright (C) 2002-2007 The Regents of the University of California.\n *  Copyright (C) 2008-2009 Lawrence Livermore National Security.\n *  Produced at Lawrence Livermore National Laboratory (cf, DISCLAIMER).\n *  UCRL-CODE-2002-040.\n *\n *  Written by Chris Dunlap <cdunlap@llnl.gov>\n *         and Jim Garlick  <garlick@llnl.gov>\n *         modified for Slurm by Moe Jette <jette@llnl.gov>.\n *\n *  This file is part of pam_slurm, a PAM module for restricting access to\n *  the compute nodes within a cluster based on information obtained from\n *  Simple Linux Utility for Resource Managment (Slurm).  For details, see\n *  <http://www.llnl.gov/linux/slurm/>.\n *\n *  pam_slurm is free software; you can redistribute it and/or modify it\n *  under the terms of the GNU General Public License as published by the\n *  Free Software Foundation; either version 2 of the License, or (at your\n *  option) any later version.\n *\n *  pam_slurm is distributed in the hope that it will be useful, but WITHOUT\n *  ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n *  FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n *  for more details.\n *\n *  You should have received a copy of the GNU General Public License along\n *  with pam_slurm; if not, write to the Free Software Foundation, Inc.,\n *  51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA.\n\\*****************************************************************************/\n\n#ifndef PAM_MODULE_NAME\n#  define PAM_MODULE_NAME \"pam_slurm_adopt\"\n#endif\n\n#if HAVE_CONFIG_H\n#  include \"config.h\"\n#endif\n\n#include <ctype.h>\n#include <errno.h>\n#include <pwd.h>\n#include <stdarg.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <sys/param.h>\n#include <sys/types.h>\n#include <syslog.h>\n#include <unistd.h>\n#include <dlfcn.h>\n\n#include \"slurm/slurm.h\"\n#include \"src/common/slurm_xlator.h\"\n\n/*  Define the externally visible functions in this file.\n */\n#define PAM_SM_ACCOUNT\n#include <security/pam_modules.h>\n#include <security/_pam_macros.h>\n\n\n/* Define the functions to be called before and after load since _init\n * and _fini are obsolete, and their use can lead to unpredicatable\n * results.\n */\nvoid __attribute__ ((constructor)) libpam_slurm_init(void);\nvoid __attribute__ ((destructor)) libpam_slurm_fini(void);\n\n/*\n *  Handle for libslurm.so\n *\n *  We open libslurm.so via dlopen () in order to pass the\n *   flag RTDL_GLOBAL so that subsequently loaded modules have\n *   access to libslurm symbols. This is pretty much only needed\n *   for dynamically loaded modules that would otherwise be\n *   linked against libslurm.\n *\n */\nstatic void * slurm_h = NULL;\n\n/* This function is necessary because libpam_slurm_init is called without access\n * to the pam handle.\n */\nstatic void\n_log_msg(int level, const char *format, ...)\n{\n\tva_list args;\n\n\topenlog(PAM_MODULE_NAME, LOG_CONS | LOG_PID, LOG_AUTHPRIV);\n\tva_start(args, format);\n\tvsyslog(level, format, args);\n\tva_end(args);\n\tcloselog();\n\treturn;\n}\n\n/*\n *  Sends a message to the application informing the user\n *  that access was denied due to Slurm.\n */\nextern void\nsend_user_msg(pam_handle_t *pamh, const char *mesg)\n{\n\tint retval;\n\tstruct pam_conv *conv;\n\tvoid *dummy;    /* needed to eliminate warning:\n\t\t\t * dereferencing type-punned pointer will\n\t\t\t * break strict-aliasing rules */\n\tstruct pam_message msg[1];\n\tconst struct pam_message *pmsg[1];\n\tstruct pam_response *prsp;\n\n\tinfo(\"send_user_msg: %s\", mesg);\n\t/*  Get conversation function to talk with app.\n\t */\n\tretval = pam_get_item(pamh, PAM_CONV, (const void **) &dummy);\n\tconv = (struct pam_conv *) dummy;\n\tif (retval != PAM_SUCCESS) {\n\t\t_log_msg(LOG_ERR, \"unable to get pam_conv: %s\",\n\t\t\t pam_strerror(pamh, retval));\n\t\treturn;\n\t}\n\n\t/*  Construct msg to send to app.\n\t */\n\tmsg[0].msg_style = PAM_ERROR_MSG;\n\tmsg[0].msg = mesg;\n\tpmsg[0] = &msg[0];\n\tprsp = NULL;\n\n\t/*  Send msg to app and free the (meaningless) rsp.\n\t */\n\tretval = conv->conv(1, pmsg, &prsp, conv->appdata_ptr);\n\tif (retval != PAM_SUCCESS)\n\t\t_log_msg(LOG_ERR, \"unable to converse with app: %s\",\n\t\t\t pam_strerror(pamh, retval));\n\tif (prsp != NULL)\n\t\t_pam_drop_reply(prsp, 1);\n\n\treturn;\n}\n\n/*\n * Dynamically open system's libslurm.so with RTLD_GLOBAL flag.\n * This allows subsequently loaded modules access to libslurm symbols.\n */\nextern void libpam_slurm_init (void)\n{\n\tchar libslurmname[64];\n\n\tif (slurm_h)\n\t\treturn;\n\n\t/* First try to use the same libslurm version (\"libslurm.so.24.0.0\"),\n\t * Second try to match the major version number (\"libslurm.so.24\"),\n\t * Otherwise use \"libslurm.so\" */\n\tif (snprintf(libslurmname, sizeof(libslurmname),\n\t\t\t\"libslurm.so.%d.%d.%d\", SLURM_API_CURRENT,\n\t\t\tSLURM_API_REVISION, SLURM_API_AGE) >=\n\t\t\t(signed) sizeof(libslurmname) ) {\n\t\t_log_msg (LOG_ERR, \"Unable to write libslurmname\\n\");\n\t} else if ((slurm_h = dlopen(libslurmname, RTLD_NOW|RTLD_GLOBAL))) {\n\t\treturn;\n\t} else {\n\t\t_log_msg (LOG_INFO, \"Unable to dlopen %s: %s\\n\",\n\t\t\tlibslurmname, dlerror ());\n\t}\n\n\tif (snprintf(libslurmname, sizeof(libslurmname), \"libslurm.so.%d\",\n\t\t\tSLURM_API_CURRENT) >= (signed) sizeof(libslurmname) ) {\n\t\t_log_msg (LOG_ERR, \"Unable to write libslurmname\\n\");\n\t} else if ((slurm_h = dlopen(libslurmname, RTLD_NOW|RTLD_GLOBAL))) {\n\t\treturn;\n\t} else {\n\t\t_log_msg (LOG_INFO, \"Unable to dlopen %s: %s\\n\",\n\t\t\tlibslurmname, dlerror ());\n\t}\n\n\tif (!(slurm_h = dlopen(\"libslurm.so\", RTLD_NOW|RTLD_GLOBAL))) {\n\t\t_log_msg (LOG_ERR, \"Unable to dlopen libslurm.so: %s\\n\",\n\t\t\t  dlerror ());\n\t}\n\n\treturn;\n}\n\nextern void libpam_slurm_fini (void)\n{\n\tif (slurm_h)\n\t\tdlclose (slurm_h);\n\treturn;\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/contribs/pam/pam_slurm.c": "/*****************************************************************************\\\n *  pam_slurm.c\n *****************************************************************************\n *  Copyright (C) 2002-2007 The Regents of the University of California.\n *  Copyright (C) 2008-2009 Lawrence Livermore National Security.\n *  Produced at Lawrence Livermore National Laboratory (cf, DISCLAIMER).\n *  UCRL-CODE-2002-040.\n *\n *  Written by Chris Dunlap <cdunlap@llnl.gov>\n *         and Jim Garlick  <garlick@llnl.gov>\n *         modified for Slurm by Moe Jette <jette@llnl.gov>.\n *\n *  This file is part of pam_slurm, a PAM module for restricting access to\n *  the compute nodes within a cluster based on information obtained from\n *  Simple Linux Utility for Resource Managment (Slurm).  For details, see\n *  <http://www.llnl.gov/linux/slurm/>.\n *\n *  pam_slurm is free software; you can redistribute it and/or modify it\n *  under the terms of the GNU General Public License as published by the\n *  Free Software Foundation; either version 2 of the License, or (at your\n *  option) any later version.\n *\n *  pam_slurm is distributed in the hope that it will be useful, but WITHOUT\n *  ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n *  FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n *  for more details.\n *\n *  You should have received a copy of the GNU General Public License along\n *  with pam_slurm; if not, write to the Free Software Foundation, Inc.,\n *  51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA.\n\\*****************************************************************************/\n\n#if HAVE_CONFIG_H\n#  include \"config.h\"\n#endif\n\n#include <ctype.h>\n#include <errno.h>\n#include <pwd.h>\n#include <stdarg.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <sys/param.h>\n#include <sys/stat.h>\n#include <sys/types.h>\n#include <syslog.h>\n#include <unistd.h>\n#include <dlfcn.h>\n\n#include \"slurm/slurm.h\"\n#include \"src/common/xmalloc.h\"\n#include \"src/common/read_config.h\"\n\n/*  Define the externally visible functions in this file.\n */\n#define PAM_SM_ACCOUNT\n#include <security/pam_modules.h>\n#include <security/_pam_macros.h>\n\n\nstruct _options {\n\tint disable_sys_info;\n\tint enable_debug;\n\tint enable_silence;\n\tconst char *msg_prefix;\n\tconst char *msg_suffix;\n};\n\n/* Define the functions to be called before and after load since _init\n * and _fini are obsolete, and their use can lead to unpredicatable\n * results.\n */\nvoid __attribute__ ((constructor)) libpam_slurm_init(void);\nvoid __attribute__ ((destructor)) libpam_slurm_fini(void);\n\n/*\n *  Handle for libslurm.so\n *\n *  We open libslurm.so via dlopen () in order to pass the\n *   flag RTDL_GLOBAL so that subsequently loaded modules have\n *   access to libslurm symbols. This is pretty much only needed\n *   for dynamically loaded modules that would otherwise be\n *   linked against libslurm.\n *\n */\nstatic void * slurm_h = NULL;\nstatic int    pam_debug   = 0;\n\nstatic void _log_msg(int level, const char *format, ...);\nstatic void _parse_args(struct _options *opts, int argc, const char **argv);\nstatic int  _hostrange_member(char *hostname, char *str);\nstatic int  _slurm_match_allocation(uid_t uid);\nstatic void _send_denial_msg(pam_handle_t *pamh, struct _options *opts,\n\t\t\t     const char *user, uid_t uid);\n\n#define DBG(msg,args...)\t\t\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\\\n\t\tif (pam_debug)\t\t\t\t\t\\\n\t\t\t_log_msg(LOG_INFO, msg, ##args);\t\\\n\t} while (0);\n\n/**********************************\\\n *  Account Management Functions  *\n\\**********************************/\n\nPAM_EXTERN int\npam_sm_acct_mgmt(pam_handle_t *pamh, int flags, int argc, const char **argv)\n{\n\tstruct _options opts;\n\tint retval;\n\tchar *user;\n\tvoid *dummy;  /* needed to eliminate warning:\n\t\t       * dereferencing type-punned pointer will break\n\t\t       * strict-aliasing rules */\n\tstruct passwd *pw;\n\tuid_t uid;\n\tint auth = PAM_PERM_DENIED;\n\n\t_parse_args(&opts, argc, argv);\n\tif (flags & PAM_SILENT)\n\t\topts.enable_silence = 1;\n\n\tretval = pam_get_item(pamh, PAM_USER, (const void **) &dummy);\n\tuser = (char *) dummy;\n\tif ((retval != PAM_SUCCESS) || (user == NULL) || (*user == '\\0')) {\n\t\t_log_msg(LOG_ERR, \"unable to identify user: %s\",\n\t\t\t pam_strerror(pamh, retval));\n\t\treturn(PAM_USER_UNKNOWN);\n\t}\n\tif (!(pw = getpwnam(user))) {\n\t\t_log_msg(LOG_ERR, \"user %s does not exist\", user);\n\t\treturn(PAM_USER_UNKNOWN);\n\t}\n\tuid = pw->pw_uid;\n\n\tif (uid == 0)\n\t\tauth = PAM_SUCCESS;\n\telse if (_slurm_match_allocation(uid))\n\t\tauth = PAM_SUCCESS;\n\n\tif ((auth != PAM_SUCCESS) && (!opts.enable_silence))\n\t\t_send_denial_msg(pamh, &opts, user, uid);\n\n\t/*\n\t *  Generate an entry to the system log if access was\n\t *   denied (!PAM_SUCCESS) or disable_sys_info is not set\n\t */\n\tif ((auth != PAM_SUCCESS) || (!opts.disable_sys_info)) {\n\t\t_log_msg(LOG_INFO, \"access %s for user %s (uid=%d)\",\n\t\t\t (auth == PAM_SUCCESS) ? \"granted\" : \"denied\",\n\t\t\t user, uid);\n\t}\n\n\treturn(auth);\n}\n\n\n/************************\\\n *  Internal Functions  *\n\\************************/\n\n/*\n *  Writes message described by the 'format' string to syslog.\n */\nstatic void\n_log_msg(int level, const char *format, ...)\n{\n\tva_list args;\n\n\topenlog(\"pam_slurm\", LOG_CONS | LOG_PID, LOG_AUTHPRIV);\n\tva_start(args, format);\n\tvsyslog(level, format, args);\n\tva_end(args);\n\tcloselog();\n\treturn;\n}\n\n/*\n *  Parses module args passed via PAM's config.\n */\nstatic void\n_parse_args(struct _options *opts, int argc, const char **argv)\n{\n\tint i;\n\n\topts->disable_sys_info = 0;\n\topts->enable_debug = 0;\n\topts->enable_silence = 0;\n\topts->msg_prefix = \"\";\n\topts->msg_suffix = \"\";\n\n\t/*  rsh_kludge:\n\t *  The rsh service under RH71 (rsh-0.17-2.5) truncates the first char\n\t *  of this msg.  The rsh client sends 3 NUL-terminated ASCII strings:\n\t *  client-user-name, server-user-name, and command string.  The server\n\t *  then validates the user.  If the user is valid, it responds with a\n\t *  1-byte zero; o/w, it responds with a 1-byte one followed by an ASCII\n\t *  error message and a newline.  RH's server is using the default PAM\n\t *  conversation function which doesn't prepend the message with a\n\t *  single-byte error code.  As a result, the client receives a string,\n\t *  interprets the first byte as a non-zero status, and treats the\n\t *  remaining string as an error message.  The rsh_kludge prepends a\n\t *  newline which will be interpreted by the rsh client as an\n\t *  error status.\n\t *\n\t *  rlogin_kludge:\n\t *  The rlogin service under RH71 (rsh-0.17-2.5) does not perform a\n\t *  carriage-return after the PAM error message is displayed\n\t *  which results\n\t *  in the \"staircase-effect\" of the next message. The rlogin_kludge\n\t *  appends a carriage-return to prevent this.\n\t */\n\tfor (i=0; i<argc; i++) {\n\t\tif (!strcmp(argv[i], \"debug\"))\n\t\t\topts->enable_debug = pam_debug = 1;\n\t\telse if (!strcmp(argv[i], \"no_sys_info\"))\n\t\t\topts->disable_sys_info = 1;\n\t\telse if (!strcmp(argv[i], \"no_warn\"))\n\t\t\topts->enable_silence = 1;\n\t\telse if (!strcmp(argv[i], \"rsh_kludge\"))\n\t\t\topts->msg_prefix = \"\\n\";\n\t\telse if (!strcmp(argv[i], \"rlogin_kludge\"))\n\t\t\topts->msg_suffix = \"\\r\";\n\t\telse\n\t\t\t_log_msg(LOG_ERR, \"unknown option [%s]\", argv[i]);\n\t}\n\treturn;\n}\n\n/*\n *  Return 1 if 'hostname' is a member of 'str', a Slurm-style host list as\n *  returned by Slurm database queries, else 0.  The 'str' argument is\n *  truncated to the base prefix as a side-effect.\n */\nstatic int\n_hostrange_member(char *hostname, char *str)\n{\n\thostlist_t hl;\n\tint found_host;\n\n\tif (!*hostname || !*str)\n\t\treturn 0;\n\n\tif ((hl = slurm_hostlist_create(str)) == NULL)\n\t\treturn 0;\n\tfound_host = slurm_hostlist_find(hl, hostname);\n\tslurm_hostlist_destroy(hl);\n\n\tif (found_host == -1)\n\t\treturn 0;\n\telse\n\t\treturn 1;\n}\n\n/* _gethostname_short - equivalent to gethostname, but return only the first\n * component of the fully qualified name\n * (e.g. \"linux123.foo.bar\" becomes \"linux123\")\n *\n * Copied from src/common/read_config.c because it is not exported\n * through libslurm.\n *\n * OUT name\n */\nstatic int\n_gethostname_short (char *name, size_t len)\n{\n\tint error_code, name_len;\n\tchar *dot_ptr, path_name[1024];\n\n\terror_code = gethostname(path_name, sizeof(path_name));\n\tif (error_code)\n\t\treturn error_code;\n\n\tdot_ptr = strchr (path_name, '.');\n\tif (dot_ptr == NULL)\n\t\tdot_ptr = path_name + strlen(path_name);\n\telse\n\t\tdot_ptr[0] = '\\0';\n\n\tname_len = (dot_ptr - path_name);\n\tif (name_len > len)\n\t\treturn ENAMETOOLONG;\n\n\tstrcpy(name, path_name);\n\treturn 0;\n}\n\n\n/*\n *  Query the Slurm database to find out if 'uid' has been allocated\n *  this node. If so, return 1 indicating that 'uid' is authorized to\n *  this node else return 0.\n */\nstatic int\n_slurm_match_allocation(uid_t uid)\n{\n\tint authorized = 0, i;\n\tchar hostname[MAXHOSTNAMELEN];\n\tchar *nodename = NULL;\n\tjob_info_msg_t * msg;\n\n\tif (_gethostname_short(hostname, sizeof(hostname)) < 0) {\n\t\t_log_msg(LOG_ERR, \"gethostname: %m\");\n\t\treturn 0;\n\t}\n\n\tif (!(nodename = slurm_conf_get_nodename(hostname))) {\n\t\tif (!(nodename = slurm_conf_get_aliased_nodename())) {\n\t\t\t/* if no match, try localhost (Should only be\n\t\t\t * valid in a test environment) */\n\t\t\tif (!(nodename =\n\t\t\t      slurm_conf_get_nodename(\"localhost\"))) {\n\t\t\t\t_log_msg(LOG_ERR,\n\t\t\t\t\t \"slurm_conf_get_aliased_nodename: \"\n\t\t\t\t\t \"no hostname found\");\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t}\n\t}\n\n\tDBG (\"does uid %ld have \\\"%s\\\" allocated?\", uid, nodename);\n\n\tif (slurm_load_job_user(&msg, uid, SHOW_ALL) < 0) {\n\t\t_log_msg(LOG_ERR, \"slurm_load_job_user: %s\",\n\t\t\t slurm_strerror(errno));\n\t\treturn 0;\n\t}\n\n\tDBG (\"slurm_load_jobs returned %d records\", msg->record_count);\n\n\tfor (i = 0; i < msg->record_count; i++) {\n\t\tjob_info_t *j = &msg->job_array[i];\n\n\t\tif (j->job_state == JOB_RUNNING) {\n\n\t\t\tDBG (\"jobid %ld: nodes=\\\"%s\\\"\", j->job_id, j->nodes);\n\n\t\t\tif (_hostrange_member(nodename, j->nodes) ) {\n\t\t\t\tDBG (\"user %ld allocated node %s in job %ld\",\n\t\t\t\t     uid, nodename, j->job_id);\n\t\t\t\tauthorized = 1;\n\t\t\t\tbreak;\n\t\t\t} else {\n\t\t\t\tchar *nodename;\n\t\t\t\tnodename = slurm_conf_get_nodename(hostname);\n\t\t\t\tif (nodename) {\n\t\t\t\t\tif (_hostrange_member(nodename,\n\t\t\t\t\t\t\t      j->nodes)) {\n\t\t\t\t\t\tDBG (\"user %ld allocated node %s in job %ld\",\n\t\t\t\t\t\t     uid, nodename, j->job_id);\n\t\t\t\t\t\tauthorized = 1;\n\t\t\t\t\t\txfree(nodename);\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\txfree(nodename);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\txfree(nodename);\n\tslurm_free_job_info_msg (msg);\n\n\treturn authorized;\n}\n\n/*\n *  Sends a message to the application informing the user\n *  that access was denied due to Slurm.\n */\nstatic void\n_send_denial_msg(pam_handle_t *pamh, struct _options *opts,\n\t\t const char *user, uid_t uid)\n{\n\tint retval;\n\tstruct pam_conv *conv;\n\tvoid *dummy;    /* needed to eliminate warning:\n\t\t\t * dereferencing type-punned pointer will\n\t\t\t * break strict-aliasing rules */\n\tint n;\n\tchar str[PAM_MAX_MSG_SIZE];\n\tstruct pam_message msg[1];\n\tconst struct pam_message *pmsg[1];\n\tstruct pam_response *prsp;\n\n\t/*  Get conversation function to talk with app.\n\t */\n\tretval = pam_get_item(pamh, PAM_CONV, (const void **) &dummy);\n\tconv = (struct pam_conv *) dummy;\n\tif (retval != PAM_SUCCESS) {\n\t\t_log_msg(LOG_ERR, \"unable to get pam_conv: %s\",\n\t\t\t pam_strerror(pamh, retval));\n\t\treturn;\n\t}\n\n\t/*  Construct msg to send to app.\n\t */\n\tn = snprintf(str, sizeof(str),\n\t\t     \"%sAccess denied: user %s (uid=%d) has no active jobs on this node.%s\",\n\t\t     opts->msg_prefix, user, uid, opts->msg_suffix);\n\tif ((n < 0) || (n >= sizeof(str)))\n\t\t_log_msg(LOG_ERR, \"exceeded buffer for pam_conv message\");\n\tmsg[0].msg_style = PAM_ERROR_MSG;\n\tmsg[0].msg = str;\n\tpmsg[0] = &msg[0];\n\tprsp = NULL;\n\n\t/*  Send msg to app and free the (meaningless) rsp.\n\t */\n\tretval = conv->conv(1, pmsg, &prsp, conv->appdata_ptr);\n\tif (retval != PAM_SUCCESS)\n\t\t_log_msg(LOG_ERR, \"unable to converse with app: %s\",\n\t\t\t pam_strerror(pamh, retval));\n\tif (prsp != NULL)\n\t\t_pam_drop_reply(prsp, 1);\n\n\treturn;\n}\n\n/*\n * Dynamically open system's libslurm.so with RTLD_GLOBAL flag.\n *  This allows subsequently loaded modules access to libslurm symbols.\n */\nextern void libpam_slurm_init (void)\n{\n\tchar libslurmname[64];\n\n\tif (slurm_h)\n\t\treturn;\n\n\t/* First try to use the same libslurm version (\"libslurm.so.24.0.0\"),\n\t * Second try to match the major version number (\"libslurm.so.24\"),\n\t * Otherwise use \"libslurm.so\" */\n\tif (snprintf(libslurmname, sizeof(libslurmname),\n\t\t\t\"libslurm.so.%d.%d.%d\", SLURM_API_CURRENT,\n\t\t\tSLURM_API_REVISION, SLURM_API_AGE) >=\n\t\t\tsizeof(libslurmname) ) {\n\t\t_log_msg (LOG_ERR, \"Unable to write libslurmname\\n\");\n\t} else if ((slurm_h = dlopen(libslurmname, RTLD_NOW|RTLD_GLOBAL))) {\n\t\treturn;\n\t} else {\n\t\t_log_msg (LOG_INFO, \"Unable to dlopen %s: %s\\n\",\n\t\t\tlibslurmname, dlerror ());\n\t}\n\n\tif (snprintf(libslurmname, sizeof(libslurmname), \"libslurm.so.%d\",\n\t\t\tSLURM_API_CURRENT) >= sizeof(libslurmname) ) {\n\t\t_log_msg (LOG_ERR, \"Unable to write libslurmname\\n\");\n\t} else if ((slurm_h = dlopen(libslurmname, RTLD_NOW|RTLD_GLOBAL))) {\n\t\treturn;\n\t} else {\n\t\t_log_msg (LOG_INFO, \"Unable to dlopen %s: %s\\n\",\n\t\t\tlibslurmname, dlerror ());\n\t}\n\n\tif (!(slurm_h = dlopen(\"libslurm.so\", RTLD_NOW|RTLD_GLOBAL))) {\n\t\t_log_msg (LOG_ERR, \"Unable to dlopen libslurm.so: %s\\n\",\n \t\t\t  dlerror ());\n\t}\n\n\treturn;\n}\n\nextern void libpam_slurm_fini (void)\n{\n \tif (slurm_h)\n\t\tdlclose (slurm_h);\n\treturn;\n}\n\n\n/*************************************\\\n *  Statically Loaded Module Struct  *\n\\*************************************/\n\n#ifdef PAM_STATIC\nstruct pam_module _pam_rms_modstruct = {\n\t\"pam_slurm\",\n\tNULL,\n\tNULL,\n\tpam_sm_acct_mgmt,\n\tNULL,\n\tNULL,\n\tNULL,\n};\n#endif /* PAM_STATIC */\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/preemption_plugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Slurm Preemption Plugin API</a></h1>\n\n<h2> Overview</h2>\n<p> This document describes Slurm preemption plugins and the API that defines\nthem. It is intended as a resource to programmers wishing to write their own\nSlurm preemption plugins.</p>\n\n<p>Slurm preemption plugins are Slurm plugins that identify which jobs\ncan be preempted by a pending job. They must conform to the Slurm Plugin\nAPI with the following specifications:</p>\n\n<p><span class=\"commandline\">const char\nplugin_type[]=\"<i>major/minor</i>\"</span><br>\nThe major type must be &quot;preempt.&quot; The minor type can be any\nrecognizable abbreviation for the type of preemption.\nWe recommend, for example:</p>\n\n<ul>\n<li><b>none</b> &mdash; This plugin prevents any job preemption.</li>\n<li><b>partition_prio</b> &mdash; This plugin permit pending jobs from one\npartition to preempt jobs from a lower priority partition.</li>\n<li><b>qos</b> &mdash; This plugin permits jobs to preempt others based\nupon their Quality Of Service values as defined in the Slurm database.</li>\n</ul>\n\n<p><span class=\"commandline\">const char plugin_name[]</span><br>\nSome descriptive name for the plugin.\nThere is no requirement with respect to its format.</p>\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loaded by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<p>The programmer is urged to study\n<span class=\"commandline\">src/plugins/preempt/partition_prio/preempt_partition_prio.c</span>\nfor an example implementation of a Slurm preemption plugin.</p>\n\n\n<h2>API Functions</h2>\n<p>The following functions must appear. Functions which are not implemented\nshould be stubbed.</p>\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\">List find_preemptable_jobs(job_record_t *job_ptr)</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Identifies the jobs\nwhich can be preempted by a specific pending job.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\">job_ptr</span> (input) a pointer to the\npending job which is attempting to be started</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: A list of pointers to\njobs which may be preempted.\nThe list should be be released using the <i>list_destroy</i> function when\nno longer required.\nThis list should be sorted in order from most attractive to\npreempt to least attractive to preempt (e.g. lowest to highest priority).\nFor example, even within a given partition or QOS one might want to\nsmaller jobs first.</p>\n\n<p class=\"commandline\">uint16_t job_preempt_mode(job_record_t *job_ptr)</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Identifies the mechanism\nused to preempt the specified job.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\">job_ptr</span> (input) a pointer to the\nrunning job to be preempted</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: PREEMPT_MODE as defined in\nthe slurm/slurm.h file</p>\n\n<p class=\"commandline\">bool preemption_enabled(void)</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Report whether or not job\npreemption is enabled.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: true if running jobs may be\npreempted, otherwise false</p>\n\n\n<p style=\"text-align:center;\">Last modified 23 October 2019</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/acct_gather_profile_plugins.shtml": "<!--#include virtual=\"header.txt\"-->\n<!--  Copyright (C) 2013 Bull S. A. S.\n      Bull, Rue Jean Jaures, B.P.68, 78340, Les Clayes-sous-Bois. -->\n\n<h1><a name=\"top\">Slurm Profile Accounting Plugin API (AcctGatherProfileType)</a></h1>\n\n<h2> Overview</h2>\n<p> This document describes Slurm profile accounting plugins and the API that\ndefines them. It is intended as a resource to programmers wishing to write\ntheir own Slurm profile accounting plugins.\n\n<p>A profiling plugin allows more detailed information on the execution of jobs\nthan can reasonably be kept in the accounting database. (All jobs may also not\nbe profiled.)\n\nA seperate\n<a href=\"hdf5_profile_user_guide.html\">User Guide</a> documents how to use\nthe hdf5 version of the plugin. An influxdb plugin is also available since\nSlurm 17.11.\n\n<p>The plugin provides an API for making calls to store data at various\npoints in a step's lifecycle. It collects data periodically from potentially\nseveral sources. The periodic samples are eventually\nconsolidated into one <i>time series</i> dataset for each node of a job.\n\n<p>The plugin's primary work is done within slurmstepd on the compute nodes.\nIt assumes a shared file system, presumably on the management network. This\navoids having to transfer files back to the controller at step end. Data is\ntypically gathered at job_acct_gather interval or acct_gather_energy interval\nand the volume is not expected to be burdensome.\n\n<p>The <i>hdf5</i> and <i>influxdb</i> implementations record I/O counts from\nthe network interface (Interconnect), I/O counts from the node from the Lustre\nparallel file system, disk I/O counts, cpu and memory utilization\nfor each task, and a record of energy use.\n\n<p>The <i>hdf5</i> implementation stores this data in a HDF5 file for each step\non each node for the jobs. A separate program\n(<a href=\"sh5util.html\">sh5util</a>) is provided to\nconsolidate all the node-step files in one container for the job.\nHDF5 is a well known structured data set that allows different types of\nrelated data to be stored in one file. Its internal structure resembles a\nfile system with <i>groups</i> being similar to <i>directories</i> and\n<i>data sets</i> being similar to <i>files</i>. There are commodity programs,\nnotably <b>HDF5View</b> for viewing and manipulating these files.\n<b>sh5util</b> also provides some capability for extracting subsets of date\nfor import into other analysis tools like spreadsheets.\n\n<p>This plugin is incompatible with --enable-front-end. It you need to\nsimulate a large configuration, please use --enable-multiple-slurmd.\n<p>Slurm profile accounting plugins must conform to the Slurm Plugin API with\nthe following specifications:\n<p><span class=\"commandline\">const char\nplugin_name[]=\"<i>full&nbsp;text&nbsp;name</i>\"</span>\n<p style=\"margin-left:.2in\">\nA free-formatted ASCII text string that identifies the plugin.\n\n<p><span class=\"commandline\">const char\nplugin_type[]=\"<i>major/minor</i>\"</span><br>\n<p style=\"margin-left:.2in\">\nThe major type must be &quot;acct_gather_profile.&quot;\nThe minor type can be any suitable name\nfor the type of profile accounting. We currently use\n<ul>\n<li><b>none</b> &mdash; No profile data is gathered.\n<li><b>hdf5</b> &mdash; Gets profile data about energy use, i/o sources\n(Lustre, network) and task data such as local disk i/o,  CPU and memory usage.\n</ul>\n\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loaded by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<p>The programmer is urged to study\n<span class=\"commandline\">\nsrc/plugins/acct_gather_profile/acct_gather_profile_hdf5.c</span> and\n<span class=\"commandline\">src/common/slurm_acct_gather_profile.c</span>\nfor a sample implementation of a Slurm profile accounting plugin.\n\n<h2>API Functions</h2>\n<p>All of the following functions are required. Functions which are not\nimplemented must be stubbed.\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\">\nvoid acct_gather_profile_g_conf_options(void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nCalled from slurmstepd between fork() and exec() of application.\nClose open files<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nvoid acct_gather_profile_g_conf_options(s_p_options_t **full_options,\nint *full_options_cnt)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nDefines configuration options in acct_gather.conf<br>\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">full(out) option definitions.</span>\n<span class=\"commandline\">full_options_cnt(out) number in full.</span>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nvoid acct_gather_profile_g_conf_set(s_p_hashtbl_t *tbl)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nSet configuration options from acct_gather.conf<br>\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">tbl -- hash table of options./span>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nvoid acct_gather_profile_g_conf_get(s_p_hashtbl_t *tbl)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nGets configuration options from acct_gather.conf<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">void* pointer to slurm_acct_gather_conf_t</span>\n on success, or<br> <span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nint acct_gather_profile_p_node_step_start(stepd_step_rec_t* job)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nCalled once per step on each node from slurmstepd, before launching tasks.\n<br />\nProvides an opportunity to create files and other node-step level\ninitialization.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job -- slumd_job_t structure containing information\nabout the step. </span>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint acct_gather_profile_p_node_step_end(stepd_step_rec_t* job)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nCalled once per step on each node from slurmstepd, after all tasks end.\n<br />\nProvides an opportunity to close files, etc.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job -- slumd_job_t structure containing information\nabout the step. </span>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint acct_gather_profile_p_task_start(stepd_step_rec_t* job, uint32_t taskid)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nCalled once per task from slurmstepd, BEFORE node step start is called.\n<br />\nProvides an opportunity to gather beginning values from node counters\n(bytes_read ...)\n<br />\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job -- slumd_job_t structure containing information\nabout the step. </span>\n<br /><span class=\"commandline\">taskid -- Slurm taskid. </span>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint acct_gather_profile_p_task_end(stepd_step_rec_t* job, pid_t taskpid)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nCalled once per task from slurmstepd.\n<br />\nProvides an opportunity to put final data for a task.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job -- slumd_job_t structure containing information\nabout the step. </span>\n<br /><span class=\"commandline\">pid -- task process id (pid_t). </span>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint acct_gather_profile_p_add_sample_data(uint32_t type, void* data);\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nPut data at the Node Samples level. Typically called from something called\nat either job_acct_gather interval or acct_gather_energy interval.\n<br />\nAll samples in the same group will eventually be consolidated in one\ntime series.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<br /><span class=\"commandline\">type -- identifies the type of data. </span>\n<br /><span class=\"commandline\">data -- data structure to be put to the file.\n</span>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<h2>Parameters</h2>\n\n<p>These parameters can be used in the slurm.conf to configure the\nplugin and the frequency at which to gather node profile data.</p>\n<dl>\n<dt><span class=\"commandline\">AcctGatherProfileType</span>\n<dd>Specifies which plugin should be used.\n</dl>\n\n<p>The <a href=\"acct_gather.conf.html\">acct_gather.conf</a> provides profile\nconfiguration options.\n<dl>\n<dt><span class=\"commandline\">ProfileDir</span>\n<dd>Path to location in a shared file system in which to write profile data.\nThere is no default as there is no standard location for a shared file system.\nIt this parameter is not specified, no profiling will occur.\n<dt><span class=\"commandline\">ProfileDefaultProfile</span>\n<dd>Default setting for --profile command line option for srun, salloc, sbatch.\n</dl>\n<p>The default profile value is <b>none</b> which means no profiling will be done\nfor jobs. The hdf5 plugin also includes;</p>\n<ul>\n<li>\n<b>energy</b> sample energy use for the node.\n</li>\n<li>\n<b>lustre</b> sample i/o to the Lustre file system for the node.\n</li>\n<li>\n<b>network</b> sample i/o through the network (interconnect) interface\nfor the node.\n</li>\n<li>\n<b>task</b> sample local disk I/O, cpu  and memory use for each task.\n</li>\n<li>\n<b>all</b> all of the above.\n</li>\n</ul>\n<p>Use caution when setting the default to values other than none as a file for\neach job will be created. This option is provided for test systems.</p>\n\n<p>Most of the sources of profile data are associated with various\nacct_gather plugins. The acct_gather.conf file has setting for various\nsampling mechanisms that can be used to change the frequency at which\nsamples occur.</p>\n\n<h2>Data Types</h2>\n<p>A plugin-like structure is implemented to generalize HDF5 data operations from\nvarious sources. A <i>C</i> <b>typedef</b> is defined for each datatype. These\ndeclarations are in /common/slurm_acct_gather_profile.h so the datatype are\ncommon to all profile plugins.</p>\n\n<p>The operations are defined via structures of function pointers, and they are\ndefined in /plugins/acct_gather_profile/common/profile_hdf5.h and should work\non any HDF5 implementation, not only hdf5.</p>\n\n<p>Functions must be implemented to perform various operations for the datatype.\nThe api for the plugin includes an argument for the datatype so that the\nimplementation of that api can call the specific operation for that datatype.</p>\n\n<p>Groups in the HDF5 file containing a dataset will include an attribute for\nthe datatype so that the program that merges step files into the job can\ndiscover the type of the group and do the right thing.</p>\n\n<p>For example, the typedef for the energy sample datatype;</p>\n<pre>\ntypedef struct profile_energy {\n    char     tod[TOD_LEN];\t// Not used in node-step\n    time_t   time;\n    uint64_t watts;\n    uint64_t cpu_freq;\n} profile_energy_t;\n</pre>\n<p>\nA <i>factory</i> method is implemented for each type to construct a structure\nwith functions implementing various operations for the type.\nThe following structure of functions is required for each type.\n<pre>\n/*\n * Structure of function pointers of common operations on a\n * profile data type. (Some may be stubs, particularly if the data type\n * does not represent a time series.\n *\tdataset_size -- size of one dataset (structure size).\n *      create_memory_datatype -- creates hdf5 memory datatype\n *          corresponding to the datatype structure.\n *      create_file_datatype -- creates hdf5 file datatype\n *          corresponding to the datatype structure.\n *      create_s_memory_datatype -- creates hdf5 memory datatype\n *          corresponding to the summary datatype structure.\n *      create_s_file_datatype -- creates hdf5 file datatype\n *          corresponding to the summary datatype structure.\n *      init_job_series -- allocates a buffer for a complete time\n *          series (in job merge) and initializes each member\n *      merge_step_series -- merges all the individual time samples\n *          into a single data set with one item per sample.\n *          Data items can be scaled (e.g. subtracting beginning time)\n *          differenced (to show counts in interval) or other things\n *          appropriate for the series.\n *      series_total -- accumulate or average members in the entire\n *          series to be added to the file as totals for the node or\n *          task.\n *      extract_series -- format members of a structure for putting\n *          to a file data extracted from a time series to be imported into\n *          another analysis tool. (e.g. format as comma separated value.)\n *      extract_totals -- format members of a structure for putting\n *          to a file data extracted from a time series total to be imported\n *          into another analysis tool. (e.g. format as comma,separated value.)\n */\ntypedef struct profile_hdf5_ops {\n    int   (*dataset_size) ();\n    hid_t (*create_memory_datatype) ();\n    hid_t (*create_file_datatype) ();\n    hid_t (*create_s_memory_datatype) ();\n    hid_t (*create_s_file_datatype) ();\n    void* (*init_job_series) (int, int);\n    void  (*merge_step_series) (hid_t, void*, void*, void*);\n    void* (*series_total) (int, void*);\n    void  (*extract_series) (FILE*, bool, int, int, char*,\n\t\t\t\t       char*, void*);\n    void  (*extract_totals) (FILE*, bool, int, int, char*,\n\t\t\t\t       char*, void*);\n} profile_hdf5_ops_t;\n</pre>\n\n<p>Note there are two different data types for supporting time series.<br>\n1) A primary type is defined for gathering data in the node step file.\nIt is typically named profile_{series_name}_t.<br>\n2) Another type is defined for summarizing series totals.\nIt is typically named profile_{series_name}_s_t. It does not have a 'factory'.\nIt is only used in the functions of the primary data type and the\nprimaries structure has operations to create appropriate hdf5 objects.</p>\n\n<p>When adding a new type, the <b>profile_factory</b> function has to be\nmodified to return an <i>ops</i> for the type.</p>\n\n<p>Interaction between type and hdf5.</p>\n<ul>\n<li>\nThe profile_{type}_t structure is used by callers of the <b>add_sample_data</b>\nfunctions.\n</li>\n<li>\nHDF5 needs a <b>memory</b>_datatype to transform this structure into its\ndataset object in memory. The <i>create_memory_datatype</i> function creates\nthe appropriate object.\n</li>\n<li>\nHDF5 needs a <b>file</b>_datatype to transform the dataset into how it will be\nwritten to the HDF5 file (or to transform what it reads from a file into a\ndataset.) The <i>create_file_datatype</i> function creates\nthe appropriate object.\n</li>\n</ul>\n\n\n<p style=\"text-align:center;\">Last modified 27 March 2015</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/mcs_plugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Multi-Category Security (MCS) Plugin Programmer Guide</a></h1>\n\n<h2> Overview</h2>\n<p> This document describes Slurm's MCS plugins and the API that\ndefines them. It is intended as a resource to programmers wishing to write\ntheir own Slurm MCS plugins.\n\n<p>Slurm MCS plugins must conform to the\nSlurm Plugin API with the following specifications:\n\n<p><span class=\"commandline\">const char\nplugin_name[]=\"<i>full&nbsp;text&nbsp;name</i>\"</span>\n<p style=\"margin-left:.2in\">\nA free-formatted ASCII text string that identifies the plugin.\n\n<p><span class=\"commandline\">const char\nplugin_type[]=\"<i>major/minor</i>\"</span><br>\n<p style=\"margin-left:.2in\">\nThe major type must be &quot;mcs.&quot;\nThe minor type can be any suitable name\nfor the MCS. We recommend, for example :\n<ul>\n<li><b>account</b> &mdash; Use user account as the category to associate jobs to.\n<li><b>none</b> &mdash; Default. No category associated to jobs.\n<li><b>user</b> &mdash; Use user name as the category to associate jobs to.\n<li><b>group</b> &mdash; Use a user group as the category to associate jobs to.\n</ul>\n\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\n<p style=\"margin-left:.2in\">\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loaded by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<p>The programmer is urged to study\n<span class=\"commandline\">src/plugins/mcs/group</span> and\n<span class=\"commandline\">src/common/slurm_mcs.c</span>\nfor an example implementation of a Slurm MCS plugin.\n\n<h2>API Functions</h2>\n<p>All of the following functions are required. Functions which are not\nimplemented must be stubbed.\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\">int mcs_p_set_mcs_label(job_record_t *job_ptr, char *label)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nVerify and set or calculate MCS_label for a job.<br>\nCalled by _job_create to get the mcs_label for a job.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\"> job_ptr  </span>  (input/output) pointer to the slurmctld job\nstructure. This can be used to get user_id and group_id.\nAssign MCS_label if possible.<br>\n<span class=\"commandline\"> label </span>    (input) pointer to requested label or NULL if not specified.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS </span> on success, or\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">int mcs_p_check_mcs_label(uint32_t user_id, char *mcs_label)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nFor command squeue/scontrol show nodes in case of option private. Check the compatibility between\nMCS_label of user and MCS_label of jobs/nodes.<br>\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">user_id, mcs_label (input).\n</span>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<h2>Parameters</h2>\n<p>These parameters can be used in the slurm.conf to configure the plugin.</p>\n<dl>\n<dt><span class=\"commandline\">MCSPlugin</span>\n<dd>Specifies which plugin should be used.\n<dt><span class=\"commandline\">MCSParameters</span>\n<dd>If MCSPlugin!=mcs/none, specifies options\n\n\n<p style=\"text-align:center;\">Last modified 23 October 2019</p>\n\n<!--#include virtual=\"footer.txt\"-->\n\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/core_spec_plugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Core Specialization Plugin Programmer Guide</a></h1>\n\n<h2> Overview</h2>\n<p> This document describes the Slurm core specialization plugins and the APIs\nthat defines them. It is intended as a resource to programmers wishing to write\ntheir own Slurm core specialization plugin. This is version 100 of the API.\n\n<p>Slurm core specialization plugins must conform to the\nSlurm Plugin API with the following specifications:\n\n<p><span class=\"commandline\">const char\nplugin_name[]=\"<i>full&nbsp;text&nbsp;name</i>\"</span>\n<p style=\"margin-left:.2in\">\nA free-formatted ASCII text string that identifies the plugin.\n\n<p><span class=\"commandline\">const char\nplugin_type[]=\"<i>major/minor</i>\"</span><br>\n<p style=\"margin-left:.2in\">\nThe major type must be &quot;core_spec&quot;.\nThe minor type can be any suitable name for the type of core specialization\npackage.\nThe following core specialization plugins are included in the Slurm distribution\n<ul>\n<li><b>cray_aries</b> &mdash; Use Cray XC APIs to enforce core specialization.</li>\n<li><b>none</b> &mdash; Can be configured to log calls to its functions, but\notherwise does nothing.</li>\n</ul>\n<p>Slurm can be configured to use multiple core specialization plugins if desired.</p>\n\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loaded by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<p><b>NOTE:</b> These functions all accept as an argument the job step's\ncontainer ID (as set by the proctrack plugin).\nEach job step will have a different container ID.\nSince a job may execute multiple job steps sequentially and/or in parallel;\nthese functions will be called once for each job step on each compute node.</p>\n\n\n<h2>API Functions</h2>\n<p>All of the following functions are required. Functions which are not\nimplemented must be stubbed.\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\">\nint core_spec_p_set(uint64_t cont_id, uint16_t core_count)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nThis function is called by the slurmstepd daemon after the job step's tasks\nhave been forked and exec'ed, and immediately before they are released from\na held state.\nNote that each job step will have a different container ID.\nNote that since a job may execute multiple job steps sequentially and/or in\nparallel; this function will be called once for each job step on each compute\nnode.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">cont_id</span>\n(input) the job step's container ID as set by the proctrack plugin.<br>\n<span class=\"commandline\">core_count</span>\n(input) number of specialized cores to be reserved for the job.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint core_spec_p_clear(uint64_t cont_id)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nThis function is called by the slurmstepd daemon after the job step's tasks\nhave all exited.\nNote that each job step will have a different container ID.\nNote that since a job may execute multiple job steps sequentially and/or in\nparallel; this function will be called once for each job step on each compute\nnode.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">cont_id</span>\n(input) the job step's container ID as set by the proctrack plugin.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint core_spec_p_suspend(uint64_t cont_id, uint16_t core_count)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nThis function is called by the slurmstepd daemon immediately after the job\nstep's tasks have all been sent a SIGSTOP signal.\nNote that each job step will have a different container ID.\nNote that since a job may execute multiple job steps sequentially and/or in\nparallel; this function will be called once for each job step on each compute\nnode.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">cont_id</span>\n(input) the job step's container ID as set by the proctrack plugin.<br>\n<span class=\"commandline\">core_count</span>\n(input) number of specialized cores to be reserved for the job.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint core_spec_p_resume(uint64_t cont_id, uint16_t core_count)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nThis function is called by the slurmstepd daemon immediately before the job\nstep's tasks will all be sent a SIGCONT signal.\nNote that each job step will have a different container ID.\nNote that since a job may execute multiple job steps sequentially and/or in\nparallel; this function will be called once for each job step on each compute\nnode.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">cont_id</span>\n(input) the job step's container ID as set by the proctrack plugin.<br>\n<span class=\"commandline\">core_count</span>\n(input) number of specialized cores to be reserved for the job.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n\n<p style=\"text-align:center;\">Last modified 27 March 2015</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/selectplugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Resource Selection Plugin Programmer Guide</a></h1>\n\n<h2>Overview</h2>\n<p>This document describe. Slurm resource selection plugins and the API that defines\nthem. It is intended as a resource to programmers wishing to write their own Slurm\nnode selection plugins.</p>\n\n<p>Slurm node selection plugins are Slurm plugins that implement the Slurm node selection\nAPI described herein. They are intended to provide a mechanism for both selecting\nnodes for pending jobs and performing any system-specific tasks for job launch or\ntermination. The plugins must conform to the Slurm Plugin API with the following\nspecifications:</p>\n<p><span class=\"commandline\">const char plugin_type[]</span><br>\nThe major type must be &quot;select.&quot; The minor type can be any recognizable\nabbreviation for the type of node selection algorithm. We recommend, for example:</p>\n<ul>\n<li><b>cons_res</b> &mdash; A plugin that can allocate individual processors,\nmemory, etc. within nodes. This plugin is recommended for systems with\nmany non-parallel programs sharing nodes. For more information see\n<a href=cons_res.html>Consumable Resources in Slurm</a>.</li>\n<li><b>cray_aries</b> &mdash; Cray XE and XT system node selector. Note that this\nplugin not only selects the nodes for a job, but performs some initialization\nand termination functions for the job. This plugin also serves as a wrapper\nfor the <i>select/linear</i> plugin which enforces various limits and\nprovides support for resource selection optimized for the system topology.</li>\n<li><b>linear</b> &mdash; A plugin that selects nodes assuming a one-dimensional\narray of nodes. The nodes are selected so as to minimize the number of consecutive\nsets of nodes utilizing a best-fit algorithm. While supporting shared nodes,\nthis plugin does not allocate individual processors, but can allocate memory to jobs.\nThis plugin is recommended for systems without shared nodes.</li>\n</ul>\n\n<p><span class=\"commandline\">const char plugin_name[]</span><br>\nSome descriptive name for the plugin.\nThere is no requirement with respect to its format.</p>\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loaded by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<p>A simplified flow of logic follows:\n<pre>\n/* slurmctld daemon starts, recover state */\nif ((<i>select_p_node_init)</i>()     != SLURM_SUCCESS) ||\n    (<i>select_p_state_restore)</i>() != SLURM_SUCCESS) ||\n    (<i>select_p_job_init)</i>()      != SLURM_SUCCESS))\n   abort\n\n/* wait for job arrival */\nif (<i>select_p_job_test</i>(all available nodes) != SLURM_SUCCESS) {\n   if (<i>select_p_job_test</i>(all configured nodes) != SLURM_SUCCESS)\n      /* reject the job and tell the user it can never run */\n   else\n      /* leave the job queued for later execution */\n} else {\n   /* update job's node list and node bitmap */\n   if (<i>select_p_job_begin</i>() != SLURM_SUCCESS)\n      /* leave the job queued for later execution */\n   else {\n      while (!<i>select_p_job_ready</i>())\n\t wait\n      /* execute the job */\n      /* wait for job to end or be terminated */\n      <i>select_p_job_fini</i>()\n    }\n}\n\n/* wait for slurmctld shutdown request */\n<i>select_p_state_save</i>()\n</pre>\n<p>Depending upon failure modes, it is possible that\n<span class=\"commandline\">select_p_state_save()</span>\nwill not be called at slurmctld termination.\nWhen slurmctld is restarted, other function calls may be replayed.\n<span class=\"commandline\">select_p_node_init()</span> may be used\nto synchronize the plugin's state with that of slurmctld.</p>\n\n\n<h2>Data Objects</h2>\n<p> These functions are expected to read and/or modify data structures directly in\nthe slurmctld daemon's memory. Slurmctld is a multi-threaded program with independent\nread and write locks on each data structure type. Therefore the type of operations\npermitted on various data structures is identified for each function.</p>\n\n<p>These functions make use of bitmaps corresponding to the nodes in a table.\nThe function <span class=\"commandline\">select_p_node_init()</span> should\nbe used to establish the initial mapping of bitmap entries to nodes.\nFunctions defined in <i>src/common/bitmap.h</i> should be used for bitmap\nmanipulations (these functions are directly accessible from the plugin).</p>\n\n\n<h2>API Functions</h2>\n<p>The following functions must appear. Functions which are not implemented should\nbe stubbed.</p>\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<h3>State Save Functions</h3>\n\n<p class=\"commandline\">int select_p_state_save (char *dir_name);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Save any global node selection state\ninformation to a file within the specified directory. The actual file name used is plugin specific.\nIt is recommended that the global switch state contain a magic number for validation purposes.\nThis function is called by the slurmctld daemon on shutdown.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<span class=\"commandline\"> dir_name</span>&nbsp;\n&nbsp;&nbsp;(input) fully-qualified pathname of a directory into which user SlurmUser (as defined\nin slurm.conf) can create a file and write state information into that file. Cannot be NULL.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR.</p>\n\n<p class=\"commandline\">int select_p_state_restore (char *dir_name);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Restore any global node selection state\ninformation from a file within the specified directory. The actual file name used is plugin specific.\nIt is recommended that any magic number associated with the global switch state be verified.\nThis function is called by the slurmctld daemon on startup.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<span class=\"commandline\"> dir_name</span>&nbsp;\n&nbsp;&nbsp;(input) fully-qualified pathname of a directory containing a state information file\nfrom which user SlurmUser (as defined in slurm.conf) can read. Cannot be NULL.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR, causing slurmctld to exit.</p>\n\n\n<h3>State Initialization Functions</h3>\n\n<p class=\"commandline\">int select_p_node_init(node_record_t *node_ptr, int node_cnt);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Note the initialization of the\nnode record data structure. This function is called by the slurmctld daemon\nwhen the node records are initially established and again when any nodes are\nadded to or removed from the data structure. </p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> node_ptr</span>&nbsp;&nbsp;&nbsp;(input) pointer\nto the node data records. Data in these records can read. Nodes deleted after initialization\nmay have their the <i>name</i> field in the record cleared (zero length) rather than\nrebuilding the node records and bitmaps.<br><br>\n<span class=\"commandline\"> node_cnt</span>&nbsp; &nbsp;&nbsp;(input) number\nof node data records.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR, causing slurmctld to exit.</p>\n\n<p class=\"commandline\">int select_p_job_init(List job_list);<p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Used at slurmctld daemon\nstartup to synchronize plugin (and node) state with that of currently active\njobs.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\"> job_list</span>&nbsp; &nbsp;&nbsp;(input)\nlist of slurm jobs from slurmctld job records.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR.</p>\n\n<p class=\"commandline\">int select_p_reconfigure (void);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Used to notify plugin\nof change in partition configuration or general configuration change.\nThe plugin will test global variables for changes as appropriate.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful, otherwise SLURM_ERROR</p>\n\n\n\n<h3>Node-Specific Functions</h3>\n\n<p class=\"commandline\">select_nodeinfo_t *select_p_select_nodeinfo_alloc(void);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Allocate a buffer for select\nplugin specific information about a node. Use select_p_select_nodeinfo_free()\nto free the returned data structure.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: A buffer for select plugin specific\ninformation about a node or NULL on failure. Use select_p_select_nodeinfo_free()\nto free this data structure.</p>\n\n<p class=\"commandline\">int select_p_select_nodeinfo_pack(select_nodeinfo_t *nodeinfo,\nBuf buffer, uint16_t protocol_version);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Pack select plugin specific\ninformation about a node into a buffer for node queries.</p>\n<p style=\"margin-left:.2in\"><b>Argument</b>:<br>\n<span class=\"commandline\"> nodeinfo</span>&nbsp; &nbsp;&nbsp;(input) Node information to be packed.<br>\n<span class=\"commandline\"> buffer</span>&nbsp; &nbsp;&nbsp;(input/output) pointer\nto buffer into which the node information is packed.<br>\n<span class=\"commandline\"> protocol_version</span>&nbsp; &nbsp;&nbsp;(input)\nVersion number of the data packing mechanism (needed for backward compatibility).</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful, otherwise SLURM_ERROR</p>\n\n<p class=\"commandline\">int select_p_select_nodeinfo_unpack(select_nodeinfo_t **nodeinfo,\nBuf buffer, uint16_t protocol_version);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Unpack select plugin specific\ninformation about a node from a buffer for node queries. Use\nselect_p_select_nodeinfo_free() to free the returned data structure.</p>\n<p style=\"margin-left:.2in\"><b>Argument</b>:<br>\n<span class=\"commandline\"> nodeinfo</span>&nbsp; &nbsp;&nbsp;(output) Node\ninformation unpacked from the buffer. Use select_p_select_nodeinfo_free()\nto free the returned data structure.<br>\n<span class=\"commandline\"> buffer</span>&nbsp; &nbsp;&nbsp;(input/output) pointer\nto buffer from which the node information is to be unpacked.<br>\n<span class=\"commandline\"> protocol_version</span>&nbsp; &nbsp;&nbsp;(input)\nVersion number of the data packing mechanism (needed for backward compatibility).</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful, otherwise SLURM_ERROR</p>\n\n<p class=\"commandline\">int select_p_select_nodeinfo_free(select_nodeinfo_t *nodeinfo);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Free a buffer which was\npreviously allocated for select plugin specific information about a node.</p>\n<p style=\"margin-left:.2in\"><b>Argument</b>:\n<span class=\"commandline\"> nodeinfo</span>&nbsp; &nbsp;&nbsp;(input/output) The buffer to be freed.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful, otherwise SLURM_ERROR</p>\n\n<p class=\"commandline\">int int select_p_select_nodeinfo_set(job_record_t *job_ptr);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Reset select plugin specific\ninformation about a job. Called by slurmctld daemon after that job's state has\nbeen restored (at startup) or job has been scheduled.</p>\n<p style=\"margin-left:.2in\"><b>Argument</b>:\n<span class=\"commandline\"> job_ptr</span>&nbsp; &nbsp;&nbsp;(input) Pointer\nto the updated job.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR.</p>\n\n<p class=\"commandline\">int select_p_select_nodeinfo_set_all(void);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Update select plugin specific\ninformation about every node as needed.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR.</p>\n\n<p class=\"commandline\">int select_p_select_nodeinfo_get(select_nodeinfo_t *nodeinfo,\nenum select_nodedata_type dinfo, enum node_states state, void *data);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Get information from a\nselect plugin's node specific data structure.</p>\n<p style=\"margin-left:.2in\"><b>Argument</b>:<br>\n<span class=\"commandline\"> nodeinfo</span>&nbsp; &nbsp;&nbsp;(input) Node information\ndata structure from which information is to get retrieved.<br>\n<span class=\"commandline\"> dinfo</span>&nbsp; &nbsp;&nbsp;(input) Data type to\nbe retrieved.<br>\n<span class=\"commandline\"> state</span>&nbsp; &nbsp;&nbsp;(input) Node state filter\nto be applied (e.g. only get information about ALLOCATED nodes).<br>\n<span class=\"commandline\"> data</span>&nbsp; &nbsp;&nbsp;(output) The retrieved data.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR.</p>\n\n<p class=\"commandline\">int select_p_update_node_config (int index);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: note that a node has\nregistered with a different configuration than previously registered.\nFor example, the node was configured with 1GB of memory in slurm.conf,\nbut actually registered with 2GB of memory.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> index</span>&nbsp;&nbsp;&nbsp;(input) zero origin index\nof the node in reference to the entire system.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful, otherwise SLURM_ERROR</p>\n\n<p class=\"commandline\">bool select_p_node_ranking(node_record_t *node_ptr, int node_cnt)</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: This function is called by the slurmctld\ndaemon at start time to set node rank information for recording the nodes to\noptimize application performance. </p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> node_ptr</span>&nbsp;&nbsp;&nbsp;(input/output) pointer\nto the node data structure. Each node's node rank field may be set.<br>\n<span class=\"commandline\"> node_cnt</span>&nbsp;&nbsp;&nbsp;(input) number\nof nodes configured on the system.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: true if node rank information has\nbeen set.</p>\n\n<p class=\"commandline\">int select_p_update_node_state(node_record_t *node_ptr);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: push a node state change\ninto the plugin. The index should be the index from the slurmctld of\nthe entire system.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> node_ptr</span>&nbsp;&nbsp;&nbsp;(input/output) pointer\nto the node data structure. Each node's node rank field may be set.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful, otherwise SLURM_ERROR</p>\n\n\n\n<h3>Job-Specific Functions</h3>\n\n<p class=\"commandline\">select_jobinfo_t *select_p_select_jobinfo_alloc(void);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Allocate a buffer for select\nplugin specific information about a job. Use select_p_select_jobinfo_free()\nto free the allocated memory.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: Pointer to a select plugin buffer\nfor a job or NULL on failure. Use select_p_select_jobinfo_free() to free the\nallocated memory.</p>\n\n<p class=\"commandline\">select_jobinfo_t *select_p_select_jobinfo_copy(select_jobinfo_t *jobinfo);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Copy the buffer containing select\nplugin specific information about a job. Use select_p_select_jobinfo_free()\nto free the allocated memory.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\"> jobinfo</span>&nbsp; &nbsp;&nbsp;(input) pointer\nto the select plugin specific information about a job.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: A copy of jobinfo or NULL on\nfailure. Use select_p_select_jobinfo_free() to free the allocated memory.</p>\n\n<p class=\"commandline\">int select_p_select_jobinfo_free(select_jobinfo_t *jobinfo);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Free the buffer containing select\nplugin specific information about a job.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\"> jobinfo</span>&nbsp; &nbsp;&nbsp;(input) pointer\nto the select plugin specific information about a job.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR.</p>\n\n<p class=\"commandline\">int select_p_select_jobinfo_pack(select_jobinfo_t *jobinfo,\nBuf buffer, uint16_t protocol_version);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Pack into a buffer the contents\nof the select plugin specific information about a job.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> jobinfo</span>&nbsp; &nbsp;&nbsp;(input) pointer\nto the select plugin specific information about a job.<br>\n<span class=\"commandline\"> buffer</span>&nbsp; &nbsp;&nbsp;(input/output) pointer\nto buffer into which the job information is packed.<br>\n<span class=\"commandline\"> protocol_version</span>&nbsp; &nbsp;&nbsp;(input)\nVersion number of the data packing mechanism (needed for backward compatibility).</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR.</p>\n\n<p class=\"commandline\">int select_p_select_jobinfo_unpack(select_jobinfo_t **jobinfo_pptr,\nBuf buffer, uint16_t protocol_version);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Unpack from a buffer the contents\nof the select plugin specific information about a job.\nThe returned value must be freed using select_p_select_jobinfo_free().</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> jobinfo</span>&nbsp; &nbsp;&nbsp;(output) pointer\nto the select plugin specific information about a job. The returned value must\nbe freed using select_p_select_jobinfo_free().<br>\n<span class=\"commandline\"> buffer</span>&nbsp; &nbsp;&nbsp;(input/output) pointer\nto buffer from which the job information is unpacked.<br>\n<span class=\"commandline\"> protocol_version</span>&nbsp; &nbsp;&nbsp;(input)\nVersion number of the data packing mechanism (needed for backward compatibility).</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR.</p>\n\n<p class=\"commandline\">int select_p_select_jobinfo_get(select_jobinfo_t *jobinfo,\nenum select_jobdata_type data_type, void *data);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Get the contents of a field\nfrom the select plugin specific information about a job.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> jobinfo</span>&nbsp; &nbsp;&nbsp;(input) pointer\nto the select plugin specific information about a job to be read.<br>\n<span class=\"commandline\"> data_type</span>&nbsp; &nbsp;&nbsp;(input) identification\nof the field to be retrieved.<br>\n<span class=\"commandline\"> data</span>&nbsp; &nbsp;&nbsp;(output) data read\nfrom the job record.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR.</p>\n\n<p class=\"commandline\">int select_p_select_jobinfo_set(select_jobinfo_t *jobinfo,\nenum select_jobdata_type data_type, void *data);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Set a field in the select\nplugin specific information about a job.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> jobinfo</span>&nbsp; &nbsp;&nbsp;(input/output) pointer\nto the select plugin specific information about a job to be modified.<br>\n<span class=\"commandline\"> data_type</span>&nbsp; &nbsp;&nbsp;(input) identification\nof the field to be set.<br>\n<span class=\"commandline\"> data</span>&nbsp; &nbsp;&nbsp;(input) data to be written\ninto the job record.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR.</p>\n\n<p class=\"commandline\">char *select_p_select_jobinfo_sprint(select_jobinfo_t *jobinfo,\nchar *buf, size_t size, int mode);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Print the contents of the select\nplugin specific information about a job.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> jobinfo</span>&nbsp; &nbsp;&nbsp;(input) pointer\nto the select plugin specific information about a job.<br>\n<span class=\"commandline\"> buf</span>&nbsp; &nbsp;&nbsp;(input/output) buffer\ninto which the contents are written.<br>\n<span class=\"commandline\"> size</span>&nbsp; &nbsp;&nbsp;(input) size of buf in bytes.<br>\n<span class=\"commandline\"> mode</span>&nbsp; &nbsp;&nbsp;(input) print mode, see enum select_print_mode.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: Pointer to the buf on success or NULL on failure.</p>\n\n<p class=\"commandline\">char *select_p_select_jobinfo_xstrdup(select_jobinfo_t *jobinfo, int mode);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Print the contents of the select\nplugin specific information about a job. The return value must be released using the xfree() function.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> jobinfo</span>&nbsp; &nbsp;&nbsp;(input) pointer\nto the select plugin specific information about a job.<br>\n<span class=\"commandline\"> mode</span>&nbsp; &nbsp;&nbsp;(input) print mode, see enum select_print_mode.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: Pointer to a string on success or NULL on failure.\nCall xfree() to release the memory allocated for the return value.</p>\n\n<p class=\"commandline\">int select_p_job_test(job_record_t *job_ptr,\nbitstr_t *bitmap, uint32_t min_nodes, uint32_t max_nodes, uint32_t req_nodes, uint32_t mode,\nList preemption_candidates, List *preempted_jobs, bitstr_t *exc_core_bitmap);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Given a job's scheduling requirement\nspecification and a set of nodes which might  be used to satisfy the request, identify\nthe nodes which \"best\" satisfy the request. Note that nodes being considered for allocation\nto the job may include nodes already allocated to other jobs, even if node sharing is\nnot permitted. This is done to ascertain whether or not job may be allocated resources\nat some later time (when the other jobs complete). This permits Slurm to reject\nnon-runnable jobs at submit time rather than after they have spent hours queued.\nInforming users of problems at job submission time permits them to quickly resubmit\nthe job with appropriate constraints.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> job_ptr</span>&nbsp; &nbsp;&nbsp;(input) pointer\nto the job being considered for scheduling. Data in this job record may safely be read.\nData of particular interest include <i>details->contiguous</i> (set if allocated nodes\nshould be contiguous), <i>num_procs</i> (minimum processors in allocation) and\n<i>details->req_node_bitmap</i> (specific required nodes).<br>\n<span class=\"commandline\"> bitmap</span>&nbsp; &nbsp;&nbsp;(input/output)\nbits representing nodes which might be allocated to the job are set on input.\nThis function should clear the bits representing nodes not required to satisfy\njob's scheduling request.\nBits left set will represent nodes to be used for this job. Note that the job's\nrequired nodes (<i>details->req_node_bitmap</i>) will be a superset\n<i>bitmap</i> when the function is called.<br>\n<span class=\"commandline\"> min_nodes</span>&nbsp; &nbsp;&nbsp;(input)\nminimum number of nodes to allocate to this job. Note this reflects both job\nand partition specifications.<br>\n<span class=\"commandline\"> max_nodes</span>&nbsp; &nbsp;&nbsp;(input)\nmaximum number of nodes to allocate to this job. Note this reflects both job\nand partition specifications.<br>\n<span class=\"commandline\"> req_nodes</span>&nbsp; &nbsp;&nbsp;(input)\nthe requested (desired)  of nodes to allocate to this job. This reflects job's\nmaximum node specification (if supplied).<br>\n<span class=\"commandline\"> mode</span>&nbsp; &nbsp;&nbsp;(input)\ncontrols the mode of operation. Valid options are:<br>\n* SELECT_MODE_RUN_NOW: try to schedule job now<br>\n* SELECT_MODE_TEST_ONLY: test if job can ever run<br>\n* SELECT_MODE_WILL_RUN: determine when and where job can run<br>\n<span class=\"commandline\"> preemption_candidates</span>&nbsp; &nbsp;&nbsp;(input)\nlist of pointers to jobs which may be preempted in order to initiate this\npending job. May be NULL if there are no preemption candidates.<br>\n<span class=\"commandline\"> preempted_jobs</span>&nbsp; &nbsp;&nbsp;(input/output)\nlist of jobs which must be preempted in order to initiate the pending job.\nIf the value is NULL, no job list is returned.\nIf the list pointed to has a value of NULL, a new list will be created\notherwise the existing list will be overwritten.\nUse the <i>list_destroy</i> function to destroy the list when no longer\nneeded.<br>\n<span class=\"commandline\"> exc_core_bitmap</span>&nbsp; &nbsp;&nbsp;(input)\nbitmap of cores held for advanced reservations.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR .</p>\n\n<p class=\"commandline\">int select_p_job_begin(job_record_t *job_ptr);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Note the initiation of the specified job\nis about to begin. This function is called immediately after\n<span class=\"commandline\">select_p_job_test()</span> successfully completes for this job.\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\"> job_ptr</span>&nbsp; &nbsp;&nbsp;(input) pointer\nto the job being initialized. Data in this job record may safely be read or written.\nThe <i>nodes</i> and <i>node_bitmap</i> fields of this job record identify the\nnodes which have already been selected for this job to use.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR, which causes the job to be requeued for\nlater execution.</p>\n\n<p class=\"commandline\">int select_p_job_ready(job_record_t *job_ptr);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Test if resources are configured\nand ready for job execution.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\"> job_ptr</span>&nbsp; &nbsp;&nbsp;(input) pointer\nto the job being initialized. Data in this job record may safely be read.\nThe <i>nodes</i> and <i>node_bitmap</i> fields of this job record identify the\nnodes which have already been selected for this job to use. </p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: 1 if the job may begin execution,\n0 otherwise.</p>\n\n<p class=\"commandline\">int select_p_job_fini(job_record_t *job_ptr);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Note the termination of the\nspecified job. This function is called as the termination process for the\njob begins (prior to killing the tasks).</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\"> job_ptr</span>&nbsp; &nbsp;&nbsp;(input) pointer\nto the job being terminated. Data in this job record may safely be read or written.\nThe <i>nodes</i> and/or <i>node_bitmap</i> fields of this job record identify the\nnodes which were selected for this job to use.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR.</p>\n\n<p class=\"commandline\">int select_p_job_signal(job_record_t *job_ptr,\nint signal);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Signal the specified job.\nThis is needed for architectures where the job steps are launched by a\nmechanism outside of Slurm, for example when ALPS is used on Cray systems.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> job_ptr</span>&nbsp; &nbsp;&nbsp;(input) pointer\nto the job to be signaled.<br>\n<span class=\"commandline\"> signal</span>&nbsp; &nbsp;&nbsp;(input) signal to\nbe sent to the job.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On\nfailure, the plugin should return a Slurm error code.</p>\n\n\n<p class=\"commandline\">int select_p_job_mem_confirm(job_record_t *job_ptr);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Confirm that a job's memory\nallocation is still valid after a node is restarted. This is an issue if the\njob is allocated all of the memory on a node and that node is restarted with a\ndifferent memory size than at the time it is allocated to the job. This would\nmostly be an issue on an Intel KNL node where the memory size would vary with\nthe MCDRAM cache mode.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> job_ptr</span>&nbsp; &nbsp;&nbsp;(input) pointer\nto the job to be validated.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On\nfailure, the plugin should return a Slurm error code.</p>\n\n<p class=\"commandline\">int select_p_job_suspend(job_record_t *job_ptr,\nbool indf_susp);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Suspend the specified job.\nRelease resources for use by other jobs.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> job_ptr</span>&nbsp; &nbsp;&nbsp;(input) pointer\nto the job being suspended. Data in this job record may safely be read or\nwritten.  The <i>nodes</i> and/or <i>node_bitmap</i> fields of this job record\nidentify the nodes which were selected for this job to use.<br>\n<span class=\"commandline\"> indf_susp</span>&nbsp; &nbsp;&nbsp;(input) flag\nwhich if set indicates the job is being suspended indefinitely by the user or\nadministrator. If not set, the job is being suspended temporarily for gang\nscheduling.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On\nfailure, the plugin should return a Slurm error code.</p>\n\n<p class=\"commandline\">int select_p_job_resume(job_record_t *job_ptr,\nbool indf_susp);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Resume the specified job\nwhich was previously suspended.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> job_ptr</span>&nbsp; &nbsp;&nbsp;(input) pointer\nto the job being resumed. Data in this job record may safely be read or\nwritten.  The <i>nodes</i> and/or <i>node_bitmap</i> fields of this job record\nidentify the nodes which were selected for this job to use.<br>\n<span class=\"commandline\"> indf_susp</span>&nbsp; &nbsp;&nbsp;(input) flag\nwhich if set indicates the job is being resumed after being suspended\nindefinitely by the user or administrator. If not set, the job is being\nresumed after being temporarily suspended for gang scheduling.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On\nfailure, the plugin should return a Slurm error code.</p>\n\n<p class=\"commandline\">int select_p_job_expand_allow (void);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Report the ability of this\nselect plugin to expand jobs.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: True if job expansion is\nsupported, otherwise false.</p>\n\n<p class=\"commandline\">int select_p_job_expand(job_record_t *from_job_ptr,\njob_record_t *to_job_ptr);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Transfer all resources\ncurrently allocated to one job to another job. One job is left with no\nallocated resources and the other job is left with the resources previously\nallocated to both jobs.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> from_job_ptr</span>&nbsp; &nbsp;&nbsp;(input) pointer\nto the job being to have all of its resources removed.<br>\n<span class=\"commandline\"> to_job_ptr</span>&nbsp; &nbsp;&nbsp;(input) pointer\nto the job getting all of the resources previously either job.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On\nfailure, the plugin should return a Slurm error code.</p>\n\n<p class=\"commandline\">int select_p_job_resized(job_record_t *job_ptr,\nnode_record_t *node_ptr);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Remove the specified node\nfrom the job's allocation.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> job_ptr</span>&nbsp; &nbsp;&nbsp;(input) pointer\nto the job being decreased in size.<br>\n<span class=\"commandline\"> node_ptr</span>&nbsp; &nbsp;&nbsp;(input) pointer\nto the node being removed from a job's allocation.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On\nfailure, the plugin should return a Slurm error code.</p>\n\n\n\n<h3>Step-Specific Functions</h3>\n\n<p class=\"commandline\">bitstr_t *select_p_step_pick_nodes(job_record_t *job_ptr,\nselect_jobinfo_t *step_jobinfo, uint32_t node_count)</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: If the select plugin needs to\nselect nodes for a job step, then do so here.<br>\n<b>NOTE:</b> The logic within the slurmctld daemon directly selects resources\nfor a job step for all other select plugins at present.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> job_ptr</span>&nbsp; &nbsp;&nbsp;(input)\nPointer to the job which is attempting to allocate a job step.</br>\n<span class=\"commandline\"> step_jobinfo</span>&nbsp; &nbsp;&nbsp;(input/output)\nOn input, this is a pointer to an empty buffer. On output for a successful\njob step allocation, this structure is filled in with detailed information\nabout the job step allocation.</br>\n<span class=\"commandline\"> node_count</span>&nbsp; &nbsp;&nbsp;(input)\nNumber of nodes required by the new job step.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: If successful, then return a\nbitmap of the nodes allocated to the job step, otherwise return NULL and the\nlogic within the slurmctld daemon will select the nodes to be allocated to\nthe job step.</p>\n\n<p class=\"commandline\">int select_p_step_finish(step_record_t *step_ptr, bool killing_step)</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Note that a job step is completing execution</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> step_ptr</span>&nbsp; &nbsp;&nbsp;(input)\nPointer to the step which has completed execution.<br>\n<span class=\"commandline\"> killing_step</span>&nbsp; &nbsp;&nbsp;(input)\nTrue if we are beginning the termination of the step (for example, when SIGKILL is being sent);\nFalse if the termination of the step has completed (all processes have exited).</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR.</p>\n\n\n\n<h3>Advanced Reservation Functions</h3>\n\n<p class=\"commandline\">bitstr_t * select_p_resv_test(resv_desc_msg_t *resv_desc_ptr, uint32_t node_cnt, bitstr_t *avail_bitmap, bitstr_t **core_bitmap)</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Identify the nodes which best\nsatisfy a reservation request taking system topology into consideration if\napplicable.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> resv_desc_ptr</span>&nbsp; &nbsp;&nbsp;(input/output)\nthe request of the reservation.  The node_list could be changed inside\nof the plugin.<br>\n<span class=\"commandline\"> node_cnt</span>&nbsp; &nbsp;&nbsp;(input)\nnumber of nodes required to satisfy the reservation request.<br>\n<span class=\"commandline\"> avail_bitmap</span>&nbsp; &nbsp;&nbsp;(input/output)\na bitmap of the nodes which are available for use in creating the reservation.<br>\n<span class=\"commandline\"> core_bitmap</span>&nbsp; &nbsp;&nbsp;(input/output)\ncores which can not be used for this reservation IN, and cores to be\nused in the reservation OUT (flush bitstr then apply only used cores).<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: A bitmap of the nodes which should\nbe used for the advanced reservation or NULL if the selected nodes can not\nbe used for an advanced reservation.</p>\n\n\n<h3>Get Information Functions</h3>\n\n<p class=\"commandline\">int select_p_get_info_from_plugin(enum select_plugindata_info dinfo,\njob_record_t *job_ptr, void *data);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Get plugin-specific information\nabout a job.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> info</span>&nbsp; &nbsp;&nbsp;(input) identifies\nthe type of data to be updated.<br>\n<span class=\"commandline\"> job_ptr</span>&nbsp; &nbsp;&nbsp;(input) pointer to\nthe job related to the query (if applicable; may be NULL).<br>\n<span class=\"commandline\"> data</span>&nbsp; &nbsp;&nbsp;(output) the requested data.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR.</p>\n\n\n<h3>Block Allocator interface</h3>\n\n<p class=\"commandline\">void select_p_ba_init(node_info_msg_t *node_info_ptr, bool sanity_check);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Setup the cluster dims returned\nby select_p_ba_get_dims().</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> node_info_ptr</span>&nbsp; &nbsp;&nbsp;(input)\nInformation about the nodes on a system.<br>\n<span class=\"commandline\"> sanity_check</span>&nbsp; &nbsp;&nbsp;(input) if set\nthen validate that the node name suffix values represent coordinates which are\nwithin the system's dimension size (see function select_p_ba_get_dims).</p>\n\n<p class=\"commandline\">int *select_p_ba_get_dims(void);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Return an array containing\nthe number of elements in each dimension of the system size.\nOnly used by Cray ALPS at present.\n<p style=\"margin-left:.2in\"><b>Returns</b>: An array containing the number of\nelements in each dimension of the system size.</p>\n\n\n<p style=\"text-align:center;\">Last modified 23 October 2019</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/accounting_storageplugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Slurm Accounting Storage Plugin API</a></h1>\n\n<h2> Overview</h2>\n<p> This document describes Slurm Accounting Storage plugins and the API that\ndefines them. It is intended as a resource to programmers wishing to write\ntheir own Slurm Job Accounting Storage plugins. This is version 1 of the API.\n\n<p>Slurm Accounting Storage plugins must conform to the\nSlurm Plugin API with the following specifications:\n\n<p><span class=\"commandline\">const char\nplugin_name[]=\"<i>full&nbsp;text&nbsp;name</i>\"</span>\n<p style=\"margin-left:.2in\">\nA free-formatted ASCII text string that identifies the plugin.\n\n<p><span class=\"commandline\">const char\nplugin_type[]=\"<i>major/minor</i>\"</span><br>\n<p style=\"margin-left:.2in\">\nThe major type must be &quot;accounting_storage.&quot;\nThe minor type can be any suitable name\nfor the type of accounting package. We currently use\n<ul>\n<li><b>filetxt</b> &mdash; Information written to a text file.\n<li><b>mysql</b> &mdash; Store information in a mysql database (using\n  the InnoDB storage engine).\n<li><b>slurmdbd</b> &mdash; Send information to the Slurm Database\n  Daemon (SlurmDBD).  Extra configuration is needed and described <a href=\"accounting.html\">here</a>.\n<li><b>none</b> &mdash; Information is not stored anywhere.\n</ul>\n\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loaded by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<p>The programmer is urged to study\n<span class=\"commandline\">src/plugins/accounting_storage/mysql</span>\nfor a sample implementation of a Slurm Accounting Storage plugin.\n<p>The Accounting Storage plugin was written to be an interface\nto storage data collected by the Job Accounting Gather plugin.  When\nadding a new database you may want to add common functions in a common\nfile in the src/database dir.  Refer to src/database/mysql_common.c|.h for an\nexample so other plugins can also use that database type to write out\ninformation.\n\n\n<h2>API Functions</h2>\n\n<p>The Job Accounting Storage API uses hooks in the slurmctld.</p>\n\n<p>All of the following functions are required. Functions which are not\nimplemented must be stubbed.</p>\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<h3>Functions called by the accounting_storage plugin</h3>\n\n<p class=\"commandline\">void *acct_storage_p_get_connection(bool\n  make_agent, int conn_num, uint16_t *persist_conn_flags,\n  bool rollback, char *location)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nacct_storage_p_get_connection() is called to get a connection to the\n  storage medium. acct_storage_p_close_connection() should be used to\n  free the pointer returned by this function.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">make_agent</span> (input) to make an agent\nthread or not.  This is primarily used in the slurmdbd plugin.<br>\n<span class=\"commandline\">conn_num</span> (input) connection number to\nthe plugin.  In many cases you should plan on multiple simultaneous\nconnections to the plugin.  This number is useful since the debug\nmessages can print this out to determine which connection the message\nis from.<br>\n<span class=\"commandline\">persist_conn_flags</span> (output) Flags passed back\nfrom the server if talking to the dbd (optional).<br>\n<span class=\"commandline\">rollback</span> (input) Allow rollback to\nhappen or not (in use with databases that support rollback).<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">void *</span> which is an opaque structure\nused inside the plugin to connect to the storage type on success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">int acct_storage_p_close_connection(void **db_conn)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nacct_storage_p_close_connection() is called at the end of the program that has\ncalled acct_storage_p_get_connection(). This function closes the connection to\nthe storage type.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input/output) connection to\nthe storage type; all memory will be freed inside this function and\nset to NULL.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">int acct_storage_p_commit(void *db_conn, bool commit)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nacct_storage_p_commit() is called at a point where you would either\n  want changes to storage to be committed or rolled back.  This function\n  should also send appropriate update messages to the various slurmctlds.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">commit</span> (input) true for commit, false\nto rollback if connection was set up to rollback. <br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint acct_storage_p_add_users(void *db_conn, uint32_t uid, List user_list)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nCalled to add users to the storage type.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the function.<br>\n<span class=\"commandline\">user_list</span> (input) list of\nacct_user_rec_t *'s containing information about the users being added.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint acct_storage_p_add_coord(void *db_conn, uint32_t uid, List acct_list, acct_user_cond_t *user_cond)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nCalled to link specified users to the specified accounts as coordinators.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the function.<br>\n<span class=\"commandline\">acct_list</span> (input) list of\nacct_account_rec_t *'s containing information about the accounts to\nadd the coordinators to. <br>\n<span class=\"commandline\">user_cond</span> (input) contain a list of\nusers to add to be coordinators of the acct_list.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint acct_storage_p_add_accts(void *db_conn, uint32_t uid, List acct_list)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nCalled to add accounts to the storage type.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the function. <br>\n<span class=\"commandline\">acct_list</span> (input) list of\nacct_account_rec_t *'s containing information about the accounts to add. <br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint acct_storage_p_add_clusters(void *db_conn, uint32_t uid, List cluster_list)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nCalled to add clusters to the storage type.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the function.<br>\n<span class=\"commandline\">cluster_list</span> (input) list of\nacct_cluster_rec_t *'s containing information about the clusters to add. <br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint acct_storage_p_add_assocs(void *db_conn, uint32_t uid, List assoc_list)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nCalled to add associations to the storage type.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the function.<br>\n<span class=\"commandline\">assoc_list</span> (input) list of\nacct_assoc_rec_t *'s containing information about the\nassociations to add. <br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint acct_storage_p_add_qos(void *db_conn, uint32_t uid, List qos_list)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nCalled to add QOS's to the storage type.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the function.<br>\n<span class=\"commandline\">qos_list</span> (input) list of\nacct_qos_rec_t *'s containing information about the qos to add. <br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint acct_storage_p_add_wckeys(void *db_conn, uint32_t uid, List wckey_list)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nCalled to add wckeys to the storage type.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the function.<br>\n<span class=\"commandline\">wckey_list</span> (input) list of\nacct_wckey_rec_t *'s containing information about the wckeys to add. <br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint acct_storage_p_add_reservation(void *db_conn,\nacct_reservation_rec_t *resv)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nCalled to add reservations to the storage type.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">resv</span> (input) Reservation to be added. <br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nList acct_storage_p_modify_users(void *db_conn, uint32_t uid,\nacct_user_cond_t *user_cond, acct_user_rec_t *user)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUsed to modify existing users in the storage type.  The condition\n  could include very vague information about the user, so this\n  function should be robust in the ability to give everything the user\n  is asking for.  This is the reason a list of modified users is\n  returned so the caller knows what has been changed, sometimes by mistake.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the function.<br>\n<span class=\"commandline\">user_cond</span> (input) conditional about\nwhich users need to change.  User names or ids should not need to be stated.<br>\n<span class=\"commandline\">user</span> (input) what the changes\nshould be on the users identified by the conditional.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">List</span> containing names of users\nmodified on success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nList acct_storage_p_modify_accounts(void *db_conn, uint32_t uid,\nacct_account_cond_t *acct_cond, acct_account_rec_t *acct)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUsed to modify existing accounts in the storage type.  The condition\n  could include very vague information about the account, so this\n  function should be robust in the ability to give everything the account\n  is asking for.  This is the reason a list of modified accounts is\n  returned so the caller knows what has been changed, sometimes by mistake.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the function.<br>\n<span class=\"commandline\">acct_cond</span> (input) conditional about\nwhich accounts need to change.  Account names should not need to be stated.<br>\n<span class=\"commandline\">acct</span> (input) what the changes\nshould be on the accounts identified by the conditional.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">List</span> containing names of users\nmodified on success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nList acct_storage_p_modify_clusters(void *db_conn, uint32_t uid,\nacct_cluster_cond_t *cluster_cond, acct_cluster_rec_t *cluster)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUsed to modify existing clusters in the storage type.  The condition\n  could include very vague information about the cluster, so this\n  function should be robust in the ability to give everything the cluster\n  is asking for.  This is the reason a list of modified clusters is\n  returned so the caller knows what has been changed, sometimes by mistake.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the function.<br>\n<span class=\"commandline\">cluster_cond</span> (input) conditional about\nwhich clusters need to change.  Cluster names should not need to be stated.<br>\n<span class=\"commandline\">cluster</span> (input) what the changes\nshould be on the clusters identified by the conditional.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">List</span> containing names of clusters\nmodified on success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nList acct_storage_p_modify_assocs(void *db_conn, uint32_t uid,\nacct_assoc_cond_t *assoc_cond, acct_assoc_rec_t *assoc)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUsed to modify existing associations in the storage type.  The condition\n  could include very vague information about the association, so this\n  function should be robust in the ability to give everything the association\n  is asking for.  This is the reason a list of modified associations is\n  returned so the caller knows what has been changed, sometimes by mistake.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the function.<br>\n<span class=\"commandline\">assoc_cond</span> (input) conditional about\nwhich associations need to change.  Association ids should not need to be stated.<br>\n<span class=\"commandline\">assoc</span> (input) what the changes\nshould be on the associations identified by the conditional.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">List</span> containing names of associations\nmodified on success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nList acct_storage_p_modify_job(void *db_conn, uint32_t uid,\nacct_job_modify_cond_t *job_cond, acct_job_rec_t *job)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUsed to modify two fields (the derived exit code and the comment string) of an\nexisting job in the storage type.  Can only modify one job at a time.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type.<br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the function.<br>\n<span class=\"commandline\">job_cond</span> (input) conditional about\nwhich job need to change.<br>\n<span class=\"commandline\">job</span> (input) what the changes\nshould be on the job identified by the conditional.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">List</span> containing ID of job\nmodified on success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nList acct_storage_p_modify_qos(void *db_conn, uint32_t uid,\nacct_qos_cond_t *qos_cond, acct_qos_rec_t *qos)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUsed to modify existing qos in the storage type.  The condition\n  could include very vague information about the qos, so this\n  function should be robust in the ability to give everything the qos\n  is asking for.  This is the reason a list of modified qos is\n  returned so the caller knows what has been changed, sometimes by mistake.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type.<br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the function.<br>\n<span class=\"commandline\">qos_cond</span> (input) conditional about\nwhich qos need to change.  Qos names should not need to be stated.<br>\n<span class=\"commandline\">qos</span> (input) what the changes\nshould be on the qos identified by the conditional.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">List</span> containing names of qos\nmodified on success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nList acct_storage_p_modify_wckeys(void *db_conn, uint32_t uid,\nacct_wckey_cond_t *wckey_cond, acct_wckey_rec_t *wckey)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUsed to modify existing wckeys in the storage type.  The condition\n  could include very vague information about the wckeys, so this\n  function should be robust in the ability to give everything the wckey\n  is asking for.  This is the reason a list of modified wckey is\n  returned so the caller knows what has been changed, sometimes by mistake.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type.<br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the function.<br>\n<span class=\"commandline\">wckey_cond</span> (input) conditional about\nwhich wckeys need to change.  Wckey names should not need to be stated.<br>\n<span class=\"commandline\">wckey</span> (input) what the changes\nshould be on the wckey identified by the conditional.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">List</span> containing names of wckeys\nmodified on success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nint acct_storage_p_modify_reservation(void *db_conn,\nacct_reservation_rec_t *resv)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nCalled to modify reservations in the storage type.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">resv</span> (input) Reservation to be\nmodified (id) must be set in the structure. <br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nList acct_storage_p_remove_users(void *db_conn, uint32_t uid,\nacct_user_cond_t *user_cond)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUsed to remove users from the storage type.  This will remove all\n  associations.  Must check to make sure all running jobs are finished\n  before this is allowed to execute.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the function.<br>\n<span class=\"commandline\">user_cond</span> (input) conditional about\nwhich users to be removed.  User names or ids should not need to be stated.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">List</span> containing names of users\nremoved on success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nList acct_storage_p_remove_coord(void *db_conn, uint32_t uid,\nList acct_list, acct_user_cond_t *user_cond)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUsed to remove coordinators from the storage type.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the function.<br>\n<span class=\"commandline\">acct_list</span> (input) list of accounts\nassociated with the users.<br>\n<span class=\"commandline\">user_cond</span> (input) conditional about\nwhich users to be removed as coordinators.  User names or ids should be stated.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">List</span> containing names of users\nremoved as coordinators on success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nList acct_storage_p_remove_accounts(void *db_conn, uint32_t uid,\nacct_account_cond_t *acct_cond)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUsed to remove accounts from the storage type. This will remove all\n  associations from these accounts.  You need to make sure no jobs are\n  running with any association that is to be removed.  If any of these\n  accounts are default accounts for users that must also change before\n  an account can be removed.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the function.<br>\n<span class=\"commandline\">acct_cond</span> (input) conditional about\nwhich accounts to be removed.  Account names should not need to be stated.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">List</span> containing names of accounts\nremoved on success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nList acct_storage_p_remove_clusters(void *db_conn, uint32_t uid,\nacct_cluster_cond_t *cluster_cond)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUsed to remove clusters from the storage type. This will remove all\n  associations from these clusters.  You need to make sure no jobs are\n  running with any association that is to be removed.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the function.<br>\n<span class=\"commandline\">cluster_cond</span> (input) conditional about\nwhich clusters to be removed.  Cluster names should not need to be stated.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">List</span> containing names of clusters\nremoved on success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nList acct_storage_p_remove_assocs(void *db_conn, uint32_t uid,\nacct_assoc_cond_t *assoc_cond)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUsed to remove associations from the storage type.  You need to make\n  sure no jobs are running with any association that is to be removed.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the function.<br>\n<span class=\"commandline\">assoc_cond</span> (input) conditional about\nwhich associations to be removed.  Association ids should not need to be stated.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">List</span> containing names of associations\nremoved on success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nList acct_storage_p_remove_qos(void *db_conn, uint32_t uid,\nacct_qos_cond_t *qos_cond)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUsed to remove qos from the storage type.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the function.<br>\n<span class=\"commandline\">qos_cond</span> (input) conditional about\nwhich qos to be removed.  Qos names should not need to be stated.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">List</span> containing names of qos\nremoved on success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nList acct_storage_p_remove_wckeys(void *db_conn, uint32_t uid,\nacct_wckey_cond_t *wckey_cond)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUsed to remove wckeys from the storage type.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the function.<br>\n<span class=\"commandline\">wckey_cond</span> (input) conditional about\nwhich wckeys to be removed.  Wckey names should not need to be stated.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">List</span> containing names of wckeys\nremoved on success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nint acct_storage_p_remove_reservation(void *db_conn,\nacct_reservation_rec_t *resv)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nCalled to remove reservations in the storage type.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">resv</span> (input) Reservation to be\nremoved (id) must be set in the structure. <br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nList acct_storage_p_get_users(void *db_conn, uint32_t uid,\nacct_user_cond_t *user_cond)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nGet a list of acct_user_rec_t *'s based on the conditional sent.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the\nfunction.<br>\n<span class=\"commandline\">user_cond</span> (input) conditional about\nwhich users are to be returned.  User names or ids should not need to\nbe stated.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">List</span> containing acct_user_rec_t *'s\non success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nList acct_storage_p_get_accts(void *db_conn, uint32_t uid,\nacct_account_cond_t *acct_cond)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nGet a list of acct_account_rec_t *'s based on the conditional sent.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the\nfunction.<br>\n<span class=\"commandline\">acct_cond</span> (input) conditional about\nwhich accounts are to be returned.  Account names should not need to\nbe stated.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">List</span> containing acct_account_rec_t *'s\non success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nList acct_storage_p_get_clusters(void *db_conn, uint32_t uid,\nacct_cluster_cond_t *cluster_cond)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nGet a list of acct_cluster_rec_t *'s based on the conditional sent.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the\nfunction.<br>\n<span class=\"commandline\">cluster_cond</span> (input) conditional about\nwhich clusters are to be returned.  Cluster names should not need to\nbe stated.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">List</span> containing acct_cluster_rec_t *'s\non success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nList acct_storage_p_get_assocs(void *db_conn, uint32_t uid,\nacct_assoc_cond_t *assoc_cond)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nGet a list of acct_assoc_rec_t *'s based on the conditional sent.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the\nfunction.<br>\n<span class=\"commandline\">assoc_cond</span> (input) conditional about\nwhich associations are to be returned.  Association names should not need to\nbe stated.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">List</span> containing acct_assoc_rec_t *'s\non success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nList acct_storage_p_get_events(void *db_conn, uint32_t uid,\nacct_event_cond_t *event_cond)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nGet a list of acct_event_rec_t *'s based on the conditional sent.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the\nfunction.<br>\n<span class=\"commandline\">event_cond</span> (input) conditional about\nwhich events are to be returned.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">List</span> containing acct_event_rec_t *'s\non success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nList acct_storage_p_get_qos(void *db_conn, uint32_t uid,\nacct_qos_cond_t *qos_cond)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nGet a list of acct_qos_rec_t *'s based on the conditional sent.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the\nfunction.<br>\n<span class=\"commandline\">qos_cond</span> (input) conditional about\nwhich qos are to be returned.  Qos names should not need to\nbe stated.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">List</span> containing acct_qos_rec_t *'s\non success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nList acct_storage_p_get_wckeys(void *db_conn, uint32_t uid,\nacct_wckey_cond_t *wckey_cond)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nGet a list of acct_wckey_rec_t *'s based on the conditional sent.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the\nfunction.<br>\n<span class=\"commandline\">wckey_cond</span> (input) conditional about\nwhich wckeys are to be returned.  Wckey names should not need to\nbe stated.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">List</span> containing acct_wckey_rec_t *'s\non success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nList acct_storage_p_get_txn(void *db_conn, uint32_t uid,\nacct_txn_cond_t *txn_cond)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nGet a list of acct_txn_rec_t *'s (transactions) based on the conditional sent.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the\nfunction.<br>\n<span class=\"commandline\">txn_cond</span> (input) conditional about\nwhich transactions are to be returned.  Transaction ids should not need to\nbe stated.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">List</span> containing acct_txn_rec_t *'s\non success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nint acct_storage_p_get_usage(void *db_conn, uint32_t uid, void *in, int type,\ntime_t start, time_t end)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nGet usage for a specific association or wckey.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type.<br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the\nfunction.<br>\n<span class=\"commandline\">in</span> (input/out) can be anything that\ngathers usage like acct_assoc_rec_t * or acct_wckey_rec_t *.<br>\n<span class=\"commandline\">type</span> (input) really\nslurmdbd_msg_type_t should let the plugin know what the structure is\nthat was sent in some how.<br>\n<span class=\"commandline\">start</span> (input) start time of the usage.<br>\n<span class=\"commandline\">end</span> (input) end time of the usage.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint acct_storage_p_roll_usage(void *db_conn, time_t sent_start, time_t sent_end,\nuint16_t archive_data, rollup_stats_t *rollup_stats)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nroll up association, cluster, and wckey usage in the storage.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type.<br>\n<span class=\"commandline\">sent_start</span> (input) start time of the rollup.<br>\n<span class=\"commandline\">sent_end</span> (input) end time of the rollup.<br>\n<span class=\"commandline\">archive_data</span> (input) archive the results if not zero.<br>\n<span class=\"commandline\">rollup_stats</span> (input/output) performance statistics.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint clusteracct_storage_p_node_down(void *db_conn, char *cluster,\nnode_record_t *node_ptr, time_t event_time, char *reason)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nMark nodes down in the storage type.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type.<br>\n<span class=\"commandline\">cluster</span> (input) name of cluster node\nis on.<br>\n<span class=\"commandline\">node_ptr</span> (input) pointer to the node\nstructure marked down.<br>\n<span class=\"commandline\">event_time</span> (input) time event happened.<br>\n<span class=\"commandline\">reason</span> (input) if different from what\nis set in the node_ptr, the reason the node is down.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint clusteracct_storage_p_node_up(void *db_conn, char *cluster,\nnode_record_t *node_ptr, time_t event_time)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nMark nodes up in the storage type.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type.<br>\n<span class=\"commandline\">cluster</span> (input) name of cluster node\nis on.<br>\n<span class=\"commandline\">node_ptr</span> (input) pointer to the node\nstructure marked up.<br>\n<span class=\"commandline\">event_time</span> (input) time event happened.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint clusteracct_storage_p_cluster_procs(void *db_conn, char *cluster,\nchar *cluster_nodes, uint32_t procs, time_t event_time)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUpdate storage type with the current number of processors on a given cluster.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">cluster</span> (input) name of cluster.<br>\n<span class=\"commandline\">cluster_nodes</span> (input) ranged list of\nnodes on system.<br>\n<span class=\"commandline\">procs</span> (input) number of processors on\nsystem.<br>\n<span class=\"commandline\">event_time</span> (input) time event happened.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint clusteracct_storage_p_get_usage(void *db_conn, uint32_t uid, void\n*cluster_rec, int type, time_t start, time_t end)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nGet usage for a specific cluster.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type.<br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the\nfunction.<br>\n<span class=\"commandline\">cluster_rec</span> (input/out)\nacct_cluster_rec_t * already set with the cluster name.  Usage will be\nfilled in.<br>\n<span class=\"commandline\">type</span> (input) really\nslurmdbd_msg_type_t should let the plugin know what the structure is\nthat was sent in some how for this it is just DBD_GET_CLUSTER_USAGE.<br>\n<span class=\"commandline\">start</span> (input) start time of the usage.<br>\n<span class=\"commandline\">end</span> (input) end time of the usage.<br>\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint clusteracct_storage_p_register_ctld(void *db_conn, char *cluster,\nuint16_t port)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUsed when a controller is turned on to tell the storage type where the\n  slurmctld for a given cluster is located at.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type.<br>\n<span class=\"commandline\">cluster</span> (input) name of cluster.<br>\n<span class=\"commandline\">port</span> (input) port on host cluster is\nrunning on the host is grabbed from the connection.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint clusteracct_storage_p_fini_ctld(void *db_conn, char *ip,\nuint16_t port, char *cluster_nodes)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUsed when a controller is turned off to tell the storage type the\n  slurmctld has gone away.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type.<br>\n<span class=\"commandline\">ip</span> (input) ip of connected slurmctld.<br>\n<span class=\"commandline\">port</span> (input) port on host cluster is\nrunning on the host is grabbed from the connection.<br>\n<span class=\"commandline\">cluster_nodes</span> (input) name of all\nnodes currently on the cluster.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint jobacct_storage_p_job_start(void *db_conn, job_record_t *job_ptr)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nNote that a job is about to begin execution or has just changed size.\nThe job's state will include the JOB_RESIZING flag if and only if it has\njust changed size. Otherwise the job is beginning execution for the first time.\nNote the existance of <i>resize_time</i> in the job record if one wishes to\nrecord information about a job at each size (i.e. a history of the job as\nits size changes through time).</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type.<br>\n<span class=\"commandline\">job_ptr</span> (input) information about the job in\nslurmctld.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint jobacct_storage_p_job_complete(void *db_conn, job_record_t *job_ptr)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nNote that a job is about to terminate or change size.\nThe job's state will include the JOB_RESIZING flag if and only if it is about\nto change size. Otherwise the job is terminating.\nNote the existance of <i>resize_time</i> in the job record if one wishes to\nrecord information about a job at each size (i.e. a history of the job as\nits size changes through time).</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type.<br>\n<span class=\"commandline\">job_ptr</span> (input) information about the job in\nslurmctld.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint jobacct_storage_p_step_start(void *db_conn, step_record_t *step_ptr)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\njobacct_storage_p_step_start() is called in the jobacct plugin at the\nallocation of a new step in the slurmctld, this inserts info about the\nbeginning of a step.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type.<br>\n<span class=\"commandline\">step_ptr</span> (input) information about the step in\nslurmctld.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint jobacct_storage_p_step_complete(void *db_conn, step_record_t *step_ptr)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\njobacct_storage_p_step_complete() is called in the jobacct plugin at\nthe end of a step in the slurmctld, this updates the ending\ninformation about a step.\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type.<br>\n<span class=\"commandline\">step_ptr</span> (input) information about the step in\nslurmctld.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint jobacct_storage_p_job_suspend(void *db_conn, job_record_t *job_ptr)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\njobacct_storage_p_suspend() is called in the jobacct plugin when a\njob is suspended or resumed in the slurmctld, this updates the\ndatabase about the suspended time of the job.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type.<br>\n<span class=\"commandline\">job_ptr</span> (input) information about the job in\nslurmctld.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">none</span>\n\n<p class=\"commandline\">\nList jobacct_storage_p_get_jobs_cond(void *db_conn, uint32_t uid,\nacct_job_cond_t *job_cond)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\njobacct_storage_p_get_jobs_cond() is called to get a list of jobs from the\ndatabase given the conditional.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type.<br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the function.<br>\n<span class=\"commandline\">job_cond</span> (input) conditional about\nwhich jobs to get.  Job ids should not need to be stated.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">List of job_rec_t's</span> on success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nint jobacct_storage_p_archive(void *db_conn, acct_archive_cond_t *arch_cond)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nused to archive old data.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type.<br>\n<span class=\"commandline\">arch_cond</span> (input) conditional about\nwhat to archive.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint jobacct_storage_p_archive_load(void *db_conn, acct_archive_rect *arch_rec)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nused to load old archive data.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type.<br>\n<span class=\"commandline\">arch_rec</span> (input) information about\nwhat to load.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint acct_storage_p_update_shares_used(void *db_conn, List acct_list)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUsed to update shares used in the storage type.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type.<br>\n<span class=\"commandline\">acct_list</span> (input) List of shares_used_object_t.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint acct_storage_p_flush_jobs_on_cluster(void *db_conn, char *cluster, time_t event_time)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nused to mark all jobs in the storage type as finished.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type.<br>\n<span class=\"commandline\">cluster</span> (input) name of cluster to\napply end to.<br>\n<span class=\"commandline\">event_time</span> (input) when the flush happened.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint acct_storage_p_reconfig(void *db_conn)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nReconfigure the plugin.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n\n\n<h2>Parameters</h2>\n<p>These parameters can be used in the slurm.conf to set up\nconnections to the database all have defaults based on the plugin type\nused.\n<dl>\n<dt><span class=\"commandline\">AccountingStorageType</span>\n<dd>Specifies which plugin should be used.\n<dt><span class=\"commandline\">AccountingStorageLoc</span>\n<dd>Let the plugin the name of the logfile/database name to use.\n<dt><span class=\"commandline\">AccountingStorageHost</span>\n<dd>Let the plugin know the host where the database is.\n<dt><span class=\"commandline\">AccountingStoragePort</span>\n<dd>Let the plugin know the port to connect to.\n<dt><span class=\"commandline\">AccountingStorageUser</span>\n<dd>Let the plugin know the name of the user to connect to the\ndatabase with.\n<dt><span class=\"commandline\">AccountingStoragePass</span>\n<dd>Let the plugin know the password of the user connecting to the database.\n<dt><span class=\"commandline\">AccountingStorageEnforce</span>\n<dd>Specifies if we should enforce certain things be in existence\n  before allowing job submissions and such valid options are\n  \"associations, limits, qos, and wckeys\". You can use any combination\n  of those listed.\n</dl>\n\n\n<p style=\"text-align:center;\">Last modified 23 October 2019</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/taskplugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Slurm Task Plugin Programmer Guide</a></h1>\n\n<h2> Overview</h2>\n<p> This document describes Slurm task management plugins and the API\nthat defines them. It is intended as a resource to programmers wishing\nto write their own Slurm scheduler plugins.</p>\n\n<p>Slurm task management plugins are Slurm plugins that implement the\nSlurm task management API described herein. They would typically be\nused to control task affinity (i.e. binding tasks to processors).\nThey must conform to the Slurm Plugin API with the following\nspecifications:</p>\n<p><span class=\"commandline\">const char plugin_type[]</span><br>\nThe major type must be &quot;task.&quot; The minor type can be any recognizable\nabbreviation for the type of task management. We recommend, for example:</p>\n<ul>\n<li><b>affinity</b> &mdash; A plugin that implements task binding to processors.\nThe actual mechanism used to task binding is dependent upon the available\ninfrastructure as determined by the \"configure\" program when Slurm is built\nand the value of the <b>TaskPluginParam</b> as defined in the <b>slurm.conf</b>\n(Slurm configuration file).</li>\n<li><b>cgroup</b> &mdash; Use Linux cgroups for binding tasks to resources.</li>\n<li><b>none</b> &mdash; A plugin that implements the API without providing any\nservices. This is the default behavior and provides no task binding.</li>\n</ul>\n\n<p><span class=\"commandline\">const char plugin_name[]</span><br>\nSome descriptive name for the plugin.\nThere is no requirement with respect to its format.</p>\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loaded by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n\n<h2>Data Objects</h2>\n<p>The implementation must maintain (though not necessarily directly export) an\nenumerated <span class=\"commandline\">errno</span>  to allow Slurm to discover\nas practically as possible the reason for any failed API call.\nThese values must not be used as return values in integer-valued functions\nin the API. The proper error return value from integer-valued functions is\nSLURM_ERROR.</p>\n\n<h2>API Functions</h2>\n<p>The following functions must appear. Functions which are not implemented should\nbe stubbed.</p>\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\">int task_p_slurmd_batch_request (batch_job_launch_msg_t *req);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Prepare to launch a batch job.\nEstablish node, socket, and core resource availability for it.\nExecuted by the <b>slurmd</b> daemon as user root.</p>\n<p style=\"margin-left:.2in\"><b>Argument</b>:<br>\n<span class=\"commandline\">req</span>&nbsp;&nbsp;&nbsp;(input/output)\nBatch job launch request specification.\nSee <b>src/common/slurm_protocol_defs.h</b> for the\ndata structure definition.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful.\nOn failure, the plugin should return SLURM_ERROR and set the errno to an\nappropriate value to indicate the reason for failure.</p>\n\n<p class=\"commandline\">int task_p_slurmd_launch_request (\nlaunch_tasks_request_msg_t *req, uint32_t node_id);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Prepare to launch a job.\nEstablish node, socket, and core resource availability for it.\nExecuted by the <b>slurmd</b> daemon as user root.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\">req</span>&nbsp;&nbsp;&nbsp;(input/output)\nTask launch request specification including node, socket, and\ncore specifications.\nSee <b>src/common/slurm_protocol_defs.h</b> for the\ndata structure definition.<br>\n<span class=\"commandline\">node_id</span>&nbsp;&nbsp;&nbsp;(input)\nID of the node on which resources are being acquired (zero origin).</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful.\nOn failure, the plugin should return SLURM_ERROR and set the errno to an\nappropriate value to indicate the reason for failure.</p>\n\n<p class=\"commandline\">int task_p_slurmd_reserve_resources (\nlaunch_tasks_request_msg_t *req, uint32_t node_id);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Reserve resources for\nthe initiation of a job. Executed by the <b>slurmd</b> daemon as user root.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\">req</span>&nbsp;&nbsp;&nbsp;(input)\nTask launch request specification including node, socket, and\ncore specifications.\nSee <b>src/common/slurm_protocol_defs.h</b> for the\ndata structure definition.<br>\n<span class=\"commandline\">node_id</span>&nbsp;&nbsp;&nbsp;(input)\nID of the node on which the resources are being acquired\n(zero origin).</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful.\nOn failure, the plugin should return SLURM_ERROR and set the errno to an\nappropriate value to indicate the reason for failure.</p>\n\n<p class=\"commandline\">int task_p_slurmd_suspend_job (uint32_t job_id);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Temporarily release resources\npreviously reserved for a job.\nExecuted by the <b>slurmd</b> daemon as user root.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\">job_id</span>&nbsp;&nbsp;&nbsp;(input)\nID of the job which is being suspended.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful.\nOn failure, the plugin should return SLURM_ERROR and set the errno to an\nappropriate value to indicate the reason for failure.</p>\n\n<p class=\"commandline\">int task_p_slurmd_resume_job (uint32_t job_id);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Reclaim resources which\nwere previously released using the task_p_slurmd_suspend_job function.\nExecuted by the <b>slurmd</b> daemon as user root.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\">job_id</span>&nbsp;&nbsp;&nbsp;(input)\nID of the job which is being resumed.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful.\nOn failure, the plugin should return SLURM_ERROR and set the errno to an\nappropriate value to indicate the reason for failure.</p>\n\n<p class=\"commandline\">int task_p_slurmd_release_resources (uint32_t job_id);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Release resources previously\nreserved for a job. Executed by the <b>slurmd</b> daemon as user root.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\">job_id</span>&nbsp;&nbsp;&nbsp;(input)\nID of the job which has completed.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful.\nOn failure, the plugin should return SLURM_ERROR and set the errno to an\nappropriate value to indicate the reason for failure.</p>\n\n<p class=\"commandline\">int task_p_pre_setuid (stepd_step_rec_t *job);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: task_p_pre_setuid() is called\nbefore setting the UID for the user to launch his jobs.\nExecuted by the <b>slurmstepd</b> program as user root.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\">job</span>&nbsp;&nbsp;&nbsp;(input)\npointer to the job to be initiated.\nSee <b>src/slurmd/slurmstepd/slurmstepd_job.h</b> for the\ndata structure definition.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful.\nOn failure, the plugin should return SLURM_ERROR and set the errno to an\nappropriate value to indicate the reason for failure.</p>\n\n<p class=\"commandline\">int task_p_pre_launch_priv (stepd_step_rec_t *job);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: task_p_pre_launch_priv() is called\nby each forked task just after the fork. Note that no particular task related\ninformation is available in the job structure at that time.\nExecuted by the <b>slurmstepd</b> program as user root.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\">job</span>&nbsp;&nbsp;&nbsp;(input)\npointer to the job to be initiated.\nSee <b>src/slurmd/slurmstepd/slurmstepd_job.h</b> for the\ndata structure definition.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful.\nOn failure, the plugin should return SLURM_ERROR and set the errno to an\nappropriate value to indicate the reason for failure.</p>\n\n<p class=\"commandline\">int task_p_pre_launch (stepd_step_rec_t *job);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: task_p_pre_launch() is called\nprior to exec of application task.\nExecuted by the <b>slurmstepd</b> program as the job's owner.\nIt is followed by <b>TaskProlog</b> program (as configured in <b>slurm.conf</b>)\nand <b>--task-prolog</b> (from <b>srun</b> command line).</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\">job</span>&nbsp;&nbsp;&nbsp;(input)\npointer to the job to be initiated.\nSee <b>src/slurmd/slurmstepd/slurmstepd_job.h</b> for the\ndata structure definition.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful.\nOn failure, the plugin should return SLURM_ERROR and set the errno to an\nappropriate value to indicate the reason for failure.</p>\n\n<a name=\"get_errno\"><p class=\"commandline\">int task_p_post_term\n(stepd_step_rec_t *job, slurmd_task_p_info_t *task);</p></a>\n<p style=\"margin-left:.2in\"><b>Description</b>: task_p_term() is called\nafter termination of job step.\nExecuted by the <b>slurmstepd</b> program as the job's owner.\nIt is preceded by <b>--task-epilog</b> (from <b>srun</b> command line)\nfollowed by <b>TaskEpilog</b> program (as configured in <b>slurm.conf</b>).</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\">job</span>&nbsp;&nbsp;&nbsp;(input)\npointer to the job which has terminated.\nSee src/slurmd/slurmstepd/slurmstepd_job.h for the\ndata structure definition.<br>\n<span class=\"commandline\">task</span>&nbsp;&nbsp;&nbsp;(input)\npointer to the task which has terminated.\nSee src/slurmd/slurmstepd/slurmstepd_job.h for the\ndata structure definition.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful.\nOn failure, the plugin should return SLURM_ERROR and set the errno to an\nappropriate value to indicate the reason for failure.</p>\n\n<p class=\"commandline\">int task_p_post_step (stepd_step_rec_t *job);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: task_p_post_step() is called\nafter termination of all the tasks of the job step.\nExecuted by the <b>slurmstepd</b> program as user root.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\">job</span>&nbsp;&nbsp;&nbsp;(input)\npointer to the job which has terminated.\nSee <b>src/slurmd/slurmstepd/slurmstepd_job.h</b> for the\ndata structure definition.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful.\nOn failure, the plugin should return SLURM_ERROR and set the errno to an\nappropriate value to indicate the reason for failure.</p>\n\n\n<p style=\"text-align:center;\">Last modified 30 January 2018</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/node_features_plugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Node Features Plugin Programmer Guide</a></h1>\n\n<h2> Overview</h2>\n<p>This document describes the node features plugin that is responsible for\nmanaging a node's active features. This is typically used for changing a node's\ncharacteristics at boot time. For example, an Intel Knights Landing (KNL)\nprocessor can be booted in various MCDRAM and NUMA modes.\nThis document is intended as a resource to programmers wishing to write their\nown node features plugin.</p>\n\n<p><span class=\"commandline\">const char\nplugin_name[]=\"<i>launch&nbsp;Slurm&nbsp;plugin</i>\"</span>\n<p style=\"margin-left:.2in\">\n\n<p><span class=\"commandline\">const char\nplugin_type[]=\"<i>node_features/[knl_cray]</i>\"</span><br>\n<p style=\"margin-left:.2in\">\n\n<ul>\n<li><b>knl_cray</b> &mdash; Use Cray's capmc command to manage an Intel KNL processor.</li>\n<li><b>knl_generic</b> &mdash; Use Intel commands to manage KNL processor.</li>\n</ul>\n\n<p><span class=\"commandline\">const uint32_t plugin_version=SLURM_VERSION_NUMBER</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loaded by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<p>The programmer is urged to study\n<span class=\"commandline\">src/plugins/node_features/knl_cray/node_features_knl_cray.c</span>\nfor a sample implementation of a Slurm node features plugin.\n\n<h2>API Functions</h2>\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> int fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\"> bool node_features_p_changeable_feature(char *feature)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Determine if this (one) specified node feature is under the control of this plugin.\n  The feature must be in a node's available features in order for the node to be\n  reconfigured and the feature become active.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n  <span class=\"commandline\"> feature:</span> One node feature.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">true</span> this feature can be set by this plugin<br>\n  <span class=\"commandline\">false</span> this feature can not be et this plugin.</p>\n\n<p class=\"commandline\"> int node_features_p_reconfig(void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Note that the configuration has changed, read configuration parameters again.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> uint32_t node_features_p_boot_time(void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Return the estimated node reboot time in units of seconds.\n  Used as a basis for optimizing scheduling decisions.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  Estimated boot time in seconds.</p>\n\n<p class=\"commandline\"> int node_features_p_get_node(char *node_list)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Update active and available features on specified nodes.\n  Executed from the slurmctld daemon only and directly updates internal\n  node data structures.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n  <span class=\"commandline\"> node_list:</span> Regular expression identifying\n  the nodes to be updated. Update information about all nodes is value is NULL.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> int node_features_p_job_valid(char *job_features)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Determine of the user's job constraint string is valid.\n  This may be used to limit the type of operators supported (Slurm's active\n  feature logic only supports the AND operator) and prevent illegal\n  combinations of node features (e.g. multiple NUMA modes).\n  Executed from the slurmctld daemon only when either the job submit or\n  modify operation is invoked.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n  <span class=\"commandline\"> job_features:</span> Job constraints specified by\n  the user (-c/--constraint options).<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> char *node_features_p_job_xlate(char *job_features)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Translate a job's feature request to the node features needed at boot time.\n  Job features not required by this plugin (e.g. rack number) will not be\n  returned. For example, a user requested features may be \"cache&quad&knl&rack1\".\n  Since the \"knl\" and \"rack1\" represent physical characteristics of the node\n  and are not used by the node features plugin to boot the node, this function's\n  return value will be \"cache,quad\".\n  Executed from the slurmctld daemon only.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n  <span class=\"commandline\"> job_features:</span> Job constraints specified by\n  the user (-c/--constraint options).<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  Node features used by this plugin when configuring or booting a node.\n  A string with its memory allocated by xmalloc (i.e. the return value\n  must be released using Slurm's xfree function).</p>\n\n<p class=\"commandline\"> bitstr_t *node_features_g_get_node_bitmap(void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Return a bitmap of the nodes under this plugin's control. This may be a subset\n  of the nodes on a cluster of heterogeneous nodes (e.g. some KNL and some\n  Haswell nodes on the same cluster).\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  Bitmap of the nodes under this plugin's control.\n  If no NodeFeatures plugins configured this may be NULL.\n  Use FREE_NULL_BITMAP() function to release returned memory.\n\n<p class=\"commandline\"> bool node_features_p_node_power(void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Report if the PowerSave mode is required to boot nodes.\n  Executed from the slurmctld daemon only.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  True if the plugin requires PowerSave mode for booting nodes.\n\n<p class=\"commandline\"> void node_features_p_node_state(char **avail_modes, char **current_mode)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Get this node's available and current features (e.g. MCDRAM and NUMA\n  settings from BIOS for a KNL processor, for example\n  avail_modes=\"cache,flat,equal,a2a,quad,hemi,snc2,snc4\" and\n  current_mode=\"cache,quad\").\n  Executed from the slurmd daemon only.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n  <span class=\"commandline\"> avail_modes:</span> Nodes state features which are\n  available. Value is allocated or appended to as appropriate with xmalloc functions.<br>\n  <span class=\"commandline\"> current_modes:</span> Nodes state features which\n  are currently in effect. Value is allocated or appended to as appropriate\n  with xmalloc functions.</p>\n\n<p class=\"commandline\"> bool node_features_g_node_update_valid(void *node_ptr, update_node_msg_t *update_node_msg)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Determine if this node update request is valid. For example, validate that a\n   non-KNL node does not include any MCDRAM or NUMA modes that are KNL specific.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n  <span class=\"commandline\"> node_ptr:</span> Pointer to node_record_t record\n  being updated.<br>\n  <span class=\"commandline\"> update_node_msg:</span> Node update request.</br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  True if the update request is valid, otherwise false.</p>\n\n\n<p class=\"commandline\"> uint32_t node_features_g_reboot_weight(void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Return the node \"weight\" field if reboot required to change mode.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  Node \"weight\" field if reboot required to change mode.</p>\n\n<p class=\"commandline\"> char *node_features_p_node_xlate(char *new_features, char *orig_features, char *avail_features, int node_inx)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Translate a node's new active feature specification as needed to preserve any\n  original features (i.e. features outside of the domain of this plugin).\n  Also validate that the new features are a subset of available features.\n  For example, a node's new features may be \"cache,quad\", while its original\n  features may have been \"knl,rack1,flat,hemi\".\n  The original plugin-specific features are \"flat,hemi\", while\n  features configured outside of the domain of this plugin are \"knl,rack1\".\n  In this case, this function's return value will be \"knl,rack1,cache,quad\".\n  This function may also be used to ensure a specific ordering of features\n  (e.g. on a KNL node, always put the MCDRAM mode before the NUMA mode).\n  Executed from the slurmctld daemon only.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n  <span class=\"commandline\"> new_features:</span> Node's new active features.<br>\n  <span class=\"commandline\"> orig_features:</span> Node's previous active feature state.<br>\n  <span class=\"commandline\"> avail_features:</span> Node's available features.<br>\n  <span class=\"commandline\"> node_inx:</span> Node's index in the slurmctld daemon's node record table.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  Node's currently active features, validate and sorted.\n  A string with its memory allocated by xmalloc (i.e. the return value\n  must be released using Slurm's xfree function).</p>\n\n<p class=\"commandline\"> char *node_features_p_node_xlate2(char *new_features)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Translate a node's newly configured available feature specification as needed\n  to order the entries as desired.\n  For example on a KNL node, always put the MCDRAM mode before the NUMA mode\n  (i.e. an input of \"hemi,flat\" is translated to \"flat,hemi\").\n  Executed from the slurmctld daemon only.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n  <span class=\"commandline\"> new_features:</span> Node's newly configured features.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  Node's currently available features, validate and sorted.\n  A string with its memory allocated by xmalloc (i.e. the return value\n  must be released using Slurm's xfree function).</p>\n\n<p class=\"commandline\"> void node_features_p_step_config(bool mem_sort, bitstr_t *numa_bitmap)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Perform any desired initialization operations prior to launching a job step.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n  <span class=\"commandline\"> mem_sort:</span> If true, run zonesort before launching a job step.<br>\n  <span class=\"commandline\"> numa_bitmap:</span> Identify NUMA nodes on which to execute zonesort.\n  If NULL, then execute zonesort on all NUMA nodes</p>\n\n<p class=\"commandline\"> char *node_features_p_user_update(uid_t uid)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Determine if the specified user can modify the currently available node\n  features.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n  <span class=\"commandline\"> uid:</span> User ID of user making request.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  True if user can change node active features to other available features.</p>\n\n\n<p style=\"text-align:center;\">Last modified 23 October 2019</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/slurmctld_plugstack.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Slurmctld Generic Plugin Programmer Guide</a></h1>\n\n<h2> Overview</h2>\n\n<p> This document describes slurmctld daemon's generic plugins and the API that\ndefines them. It is intended as a resource to programmers wishing to write\ntheir own slurmctld generic plugins. This is version 100 of the API.\n\n<p>The slurmctld generic plugin must conform to the\nSlurm Plugin API with the following specifications:\n\n<p><span class=\"commandline\">const char\nplugin_name[]=\"<i>full&nbsp;text&nbsp;name</i>\"</span>\n<p style=\"margin-left:.2in\">\nA free-formatted ASCII text string that identifies the plugin.\n\n<p><span class=\"commandline\">const char\nplugin_type[]=\"<i>major/minor</i>\"</span><br>\n<p style=\"margin-left:.2in\">\nThe major type must be &quot;slurmctld_plugstack.&quot;\nThe minor type can be any suitable name for the type of slurmctld package.\nSlurm can be configured to use multiple slurmctld_plugstack plugins if desired.</p>\n\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loaded by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<h2>API Functions</h2>\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p class=\"commandline\"> List slurmctld_plugstack_p_get_config (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when there's a REQUEST_BUILD_INFO RPC call. It must fill a List with\n  config_key_pair_t elements that represents the configurable parameters of\n  the plugin.\n  Normally used when for scontrol and sview to dump the configuration.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  List of keyword - value pairs.\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p>The init function will be called when the slurmctld daemon begins accepting RPCs.\nThe fini function will be called when the slurmctld daemon stops accepting RPCs.\nOther functions can be called at any time.\nIn the case of the backup slurmctld daemon, the init and fini functions may\nbe called multiple times (when it assumes control functions and then when it\nrelinquishes them to the primary slurmctld daemon).</p>\n\n\n<p style=\"text-align:center;\">Last modified 24 January 2018</p>\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/switchplugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Slurm Switch Plugin API</a></h1>\n\n<h2> Overview</h2>\n<p> This document describe. Slurm switch (interconnect) plugins and the API that defines\nthem. It is intended as a resource to programmers wishing to write their own Slurm\nswitch plugins.\nNote that many of the API functions are used only by one of the daemons. For\nexample the slurmctld daemon builds a job step's switch credential\n(<span class=\"commandline\">switch_p_build_jobinfo</span>) while the\nslurmd daemon enables and disables that credential for the job step's\ntasks on a particular node(<span class=\"commandline\">switch_p_job_init</span>,\netc.). </p>\n\n<p>Slurm switch plugins are Slurm plugins that implement the Slurm switch or interconnect\nAPI described herein. They must conform to the Slurm Plugin API with the following\nspecifications:</p>\n<p><span class=\"commandline\">const char plugin_type[]</span><br>\nThe major type must be &quot;switch.&quot; The minor type can be any recognizable\nabbreviation for the type of switch. We recommend, for example:</p>\n<ul>\n<li><b>none</b> &mdash; A plugin that implements the API without providing any actual\nswitch service. This is the case for Ethernet and Myrinet interconnects.</li>\n</ul>\n\n<p><span class=\"commandline\">const char plugin_name[]</span><br>\nSome descriptive name for the plugin.\nThere is no requirement with respect to its format.</p>\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loaded by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n\n<h2>Data Objects</h2>\n<p> The implementation must support two opaque data classes.\nOne is used as an job step's switch &quot;credential.&quot;\nThis class must encapsulate all job step specific information necessary\nfor the operation of the API specification below.\nThe second is a node's switch state record.\nBoth data classes are referred to in Slurm code using an anonymous\npointer (void *).</p>\n\n<h2>API Functions</h2>\n<p>The following functions must appear. Functions which are not implemented should\nbe stubbed.</p>\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<h3>Global Switch State Functions</h3>\n<p class=\"commandline\">int switch_p_libstate_save (char *dir_name);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Save any global switch state to a file\nwithin the specified directory. The actual file name used is plugin specific. It is recommended\nthat the global switch state contain a magic number for validation purposes. This function\nis called by the slurmctld daemon on shutdown. Note that if the slurmctld daemon fails,\nthis function will not be called. The plugin may save state independently and/or make\nuse of the switch_p_job_step_allocated function to restore state.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<span class=\"commandline\"> dir_name</span>&nbsp;\n&nbsp;&nbsp;(input) fully-qualified pathname of a directory into which user SlurmUser (as defined\nin slurm.conf) can create a file and write state information into that file. Cannot be NULL.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int switch_p_libstate_restore(char *dir_name, bool recover);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Restore any global switch state from a file\nwithin the specified directory. The actual file name used is plugin specific. It is recommended\nthat any magic number associated with the global switch state be verified. This function\nis called by the slurmctld daemon on startup.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> dir_name</span>&nbsp;\n&nbsp;&nbsp;(input) fully-qualified pathname of a directory containing a state information file\nfrom which user SlurmUser (as defined in slurm.conf) can read. Cannot be NULL.<br>\n<span class=\"commandline\"><span class=\"commandline\"> recover</span>&nbsp;\ntrue of restart with state preserved, false if no state recovery. </p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int switch_p_libstate_clear (void);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Clear switch state information.\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n\n<h3>Node's Switch State Monitoring Functions</h3>\n\n<p>Nodes will register with current switch state information when the slurmd daemon\nis initiated. The slurmctld daemon will also request that slurmd supply current\nswitch state information on a periodic basis.</p>\n\n<p class=\"commandline\">int switch_p_clear_node_state (void);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Initialize node state.\nIf any switch state has previously been established for a job step, it will be cleared.\nThis will be used to establish a \"clean\" state for the switch on the node upon\nwhich it is executed.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int switch_p_alloc_node_info(switch_node_info_t *switch_node);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Allocate storage for a node's switch\nstate record. It is recommended that the record contain a magic number for validation\npurposes.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<span class=\"commandline\"> switch_node</span>&nbsp;\n&nbsp;&nbsp;(output) location for writing location of node's switch state record.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int switch_p_build_node_info(switch_node_info_t switch_node);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Fill in a previously allocated switch state\nrecord for the node on which this function is executed.\nIt is recommended that the magic number be validated.\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int switch_p_pack_node_info (switch_node_info_t switch_node,\nBuf buffer);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Pack the data associated with a\nnode's switch state into a buffer for network transmission.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> switch_node</span>&nbsp; &nbsp;&nbsp;(input) an existing\nnode's switch state record.<br>\n<span class=\"commandline\"> buffer</span>&nbsp; &nbsp;&nbsp;(input/output) buffer onto\nwhich the switch state information is appended.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>:\nThe number of bytes written should be returned if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int switch_p_unpack_node_info (switch_node_info_t **switch_node,\nBuf buffer);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Allocate and unpack\n  the data associated with a node's switch state record from a buffer.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> switch_node</span>&nbsp; &nbsp;&nbsp;(output) a\nnode switch state record will be allocated and filled in with data read from\nthe buffer.<br>\n<span class=\"commandline\"> buffer</span>&nbsp; &nbsp;&nbsp;(input/output) buffer from\nwhich the record's contents are read.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">void switch_p_free_node_info (switch_node_info_t switch_node);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Release the storage associated with\na node's switch state record.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<span class=\"commandline\"> switch_node</span>&nbsp;\n&nbsp;&nbsp;(input/output) a previously allocated node switch state record.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: None</p>\n\n<p class=\"commandline\">char * switch_p_sprintf_node_info (switch_node_info_t switch_node,\nchar *buf, size_t size);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Print the contents of a node's switch state\nrecord to a buffer.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> switch_node</span>&nbsp; &nbsp;&nbsp;(input) a\nnode's switch state record.<br>\n<span class=\"commandline\"> buf</span>&nbsp; &nbsp;&nbsp;(input/output) point to\nbuffer into which the switch state record is to be written.<br>\nof buf in bytes.<br>\n<span class=\"commandline\"> size</span>&nbsp; &nbsp;&nbsp;(input) size\nof buf in bytes.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: Location of buffer, same as <i>buf</i>.</p>\n\n<h3>Job's Switch Credential Management Functions</h3>\n<p class=\"commandline\">int switch_p_alloc_jobinfo(switch_jobinfo_t\n  *switch_job, uint32_t job_id, uint32_t step_id);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Allocate storage for a job step's switch credential.\nIt is recommended that the credential contain a magic number for validation purposes.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> switch_job</span>&nbsp;\n&nbsp;&nbsp;(output) location for writing location of job step's\nswitch credential.\n<span class=\"commandline\"> job_id</span>&nbsp; &nbsp;&nbsp;(input) the\njob id for this job step NO_VAL for not set.<br>\n<span class=\"commandline\"> step_id</span>&nbsp; &nbsp;&nbsp;(input) the\nstep id for this job step NO_VAL for not set.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int switch_p_build_jobinfo (switch_jobinfo_t switch_job,\nslurm_step_layout_t *step_layout, char *network);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Build a job's switch credential.\nIt is recommended that the credential's magic number be validated.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\">switch_job</span>&nbsp; &nbsp;&nbsp;(input/output) Job's\nswitch credential to be updated<br>\n<span class=\"commandline\">step_layout</span>&nbsp;&nbsp;&nbsp; (input) the layout of the step with at least the node_list, tasks and tids set.<br>\n<span class=\"commandline\">network</span>&nbsp;&nbsp;&nbsp; (input) Job step's network\nspecification from srun command. </p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">switch_jobinfo_t switch_p_copy_jobinfo  (switch_jobinfo_t switch_job);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Allocate storage for a job's switch credential\nand copy an existing credential to that location.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<span class=\"commandline\"> switch_job</span>&nbsp;\n&nbsp;&nbsp;(input) an existing job step switch credential.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: A newly allocated job step switch\ncredential containing a copy of the function argument.</p>\n\n<p class=\"commandline\">void switch_p_free_jobinfo (switch_jobinfo_t switch_job);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Release the storage associated with a job's\n switch credential.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<span class=\"commandline\"> switch_job</span>&nbsp;\n&nbsp;&nbsp;(input) an existing job step switch credential.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: None</p>\n\n<p class=\"commandline\">int switch_p_pack_jobinfo (switch_jobinfo_t switch_job, Buf buffer);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Pack the data associated with a job step's\nswitch credential into a buffer for network transmission.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> switch_job</span>&nbsp; &nbsp;&nbsp;(input) an\nexisting job step switch credential.<br>\n<span class=\"commandline\"> buffer</span>&nbsp; &nbsp;&nbsp;(input/output) buffer onto\nwhich the credential's contents are appended.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>:\nThe number of bytes written should be returned if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int switch_p_unpack_jobinfo (switch_jobinfo_t **switch_job, Buf buffer);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Allocate and unpack the data associated with a job's\nswitch credential from a buffer.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> switch_job</span>&nbsp;\n&nbsp;&nbsp;(output) a job step switch credential will be allocated and filled in with data read from the buffer.<br>\n<span class=\"commandline\"> buffer</span>&nbsp; &nbsp;&nbsp;(input/output) buffer from\nwhich the credential's contents are read.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int switch_p_get_jobinfo (switch_jobinfo_t switch_job, int data_type, void *data);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Get some specific data from a job's switch credential.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> switch_job</span>&nbsp; &nbsp;&nbsp;(input) a job's switch credential.<br>\n<span class=\"commandline\"> data_type</span>&nbsp; &nbsp;&nbsp;(input) identification\nas to the type of data requested. The interpretation of this value is plugin dependent.<br>\n<span class=\"commandline\"> data</span>&nbsp; &nbsp;&nbsp;(output) filled in with the desired\ndata. The form of this data is dependent upon the value of data_type and the plugin.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int switch_p_job_step_complete (switch_jobinfo_t switch_job,\nchar *nodelist);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Note that the job step associated\nwith the specified nodelist has completed execution.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> switch_job</span> &nbsp;&nbsp;&nbsp;(input)\nThe completed job step's switch credential.<br>\n<span class=\"commandline\"> nodelist</span>&nbsp; &nbsp;&nbsp;(input) A list of nodes\non which the job step has completed. This may contain expressions to specify\nnode ranges. (e.g. \"linux[1-20]\" or \"linux[2,4,6,8]\").</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int switch_p_job_step_part_comp (switch_jobinfo_t switch_job,\nchar *nodelist);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Note that the job step has completed\nexecution on the specified node list. The job step is not necessarily completed on all\nnodes, but switch resources associated with it on the specified nodes are no longer\nin use.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> switch_job</span> &nbsp;&nbsp;&nbsp;(input)\nThe completed job's switch credential.<br>\n<span class=\"commandline\"> nodelist</span>&nbsp; &nbsp;&nbsp;(input) A list of nodes\non which the job step has completed. This may contain expressions to specify node ranges.\n(e.g. \"linux[1-20]\" or \"linux[2,4,6,8]\").</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">bool switch_p_part_comp (void);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Indicate if the switch plugin should\nprocess partial job step completions (i.e. switch_g_job_step_part_comp). Support\nof partition completions is compute intensive, so it should be avoided unless switch\nresources are in short supply (e.g. former switch/nrt).</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: True if partition step completions are\nto be recorded. False if only full job step completions are to be noted.</p>\n\n<p class=\"commandline\">void switch_p_print_jobinfo(FILE *fp, switch_jobinfo_t switch_job);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Print the contents of a job's\nswitch credential to a file.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> fp</span>&nbsp; &nbsp;&nbsp;(input) pointer to an open file.<br>\n<span class=\"commandline\"> switch_job</span>&nbsp; &nbsp;&nbsp;(input) a job's\nswitch credential.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p class=\"commandline\">char *switch_p_sprint_jobinfo(switch_jobinfo_t switch_job,\nchar *buf, size_t size);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Print the contents of a job's\nswitch credential to a buffer.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> switch_job</span>&nbsp; &nbsp;&nbsp;(input) a job's\nswitch credential.<br>\n<span class=\"commandline\"> buf</span>&nbsp; &nbsp;&nbsp;(input/output) pointer to\nbuffer into which the job credential information is to be written.<br>\n<span class=\"commandline\"> size</span>&nbsp; &nbsp;&nbsp;(input) size of buf in\nbytes</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: location of buffer, same as <i>buf</i>.</p>\n\n<p class=\"commandline\">int switch_p_get_data_jobinfo(switch_jobinfo_t switch_job,\nint key, void *resulting_data);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Get data from a job step's\nswitch credential.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> switch_job</span>&nbsp; &nbsp;&nbsp;(input) a job\nstep's switch credential.<br>\n<span class=\"commandline\"> key</span>&nbsp; &nbsp;&nbsp;(input) identification\nof the type of data to be retrieved from the switch credential. NOTE: The\ninterpretation of this key is dependent upon the switch type. <br>\n<span class=\"commandline\"> resulting_data</span>&nbsp; &nbsp;&nbsp;(input/output)\npointer to where the requested data should be stored. </p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n\n<h3>Node Specific Switch Management Functions</h3>\n<p class=\"commandline\">int switch_p_node_init (void);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: This function is run from the top level slurmd\nonly once per slurmd run. It may be used, for instance, to perform some one-time\ninterconnect setup or spawn an error handling thread.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<span class=\"commandline\"> None</span></p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int switch_p_node_fini (void);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: This function is called once as slurmd exits\n(slurmd will wait for this function to return before continuing the exit process).</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<span class=\"commandline\"> None</span></p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<h3>Job Step Management Functions</h3>\n<pre>\n=========================================================================\nProcess 1 (root)        Process 2 (root, user)  |  Process 3 (user task)\n                                                |\nswitch_p_job_preinit                            |\nfork ------------------ switch_p_job_init       |\nwaitpid                 setuid, chdir, etc.     |\n                        fork N procs -----------+--- switch_p_job_attach\n                        wait all                |    exec mpi process\n                        switch_p_job_fini*      |\nswitch_p_job_postfini                           |\n=========================================================================\n</pre>\n\n<p class=\"commandline\">int switch_p_job_preinit (switch_jobinfo_t jobinfo switch_job);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Preinit is run as root in the first slurmd process,\nthe so called job step manager. This function can be used to perform any initialization\nthat needs to be performed in the same process as switch_p_job_fini().</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\"> switch_job</span>&nbsp; &nbsp;&nbsp;(input) a job's\nswitch credential.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int switch_p_job_init (stepd_step_rec_t *job, uid_t uid);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Initialize interconnect on node for a job.\nThis function is run from the second slurmd process (some interconnect implementations\nmay require the switch_p_job_init functions to be executed from a separate process\nthan the process executing switch_p_job_fini() [e.g. Quadrics Elan]).</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> job</span>&nbsp; &nbsp;&nbsp;(input)\nstructure representing the slurmstepd's view of the job step.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int switch_p_job_attach ( switch_jobinfo_t switch_job, char ***env,\nuint32_t nodeid, uint32_t procid, uint32_t nnodes, uint32_t nprocs, uint32_t rank );</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Attach process to interconnect\n(Called from within the process, so it is appropriate to set interconnect specific\nenvironment variables here).</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> switch_job</span>&nbsp; &nbsp;&nbsp;(input) a job's\nswitch credential.<br>\n<span class=\"commandline\"> env</span>&nbsp; &nbsp;&nbsp;(input/output) the\nenvironment variables to be set upon job step initiation. Switch specific\nenvironment variables are added as needed.<br>\n<span class=\"commandline\"> nodeid</span>&nbsp; &nbsp;&nbsp;(input) zero-origin\nid of this node.<br>\n<span class=\"commandline\"> procid</span>&nbsp; &nbsp;&nbsp;(input) zero-origin\nprocess id local to slurmd and <b>not</b> equivalent to the global task id or MPI rank.<br>\n<span class=\"commandline\"> nnodes</span>&nbsp; &nbsp;&nbsp;(input) count of\nnodes allocated to this job step.<br>\n<span class=\"commandline\"> nprocs</span>&nbsp; &nbsp;&nbsp;(input) total count of\nprocesses or tasks to be initiated for this job step.<br>\n<span class=\"commandline\"> rank</span>&nbsp; &nbsp;&nbsp;(input) zero-origin\nid of this task.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int switch_p_job_fini (switch_jobinfo_t jobinfo switch_job);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: This function is run from the same process\nas switch_p_job_init() after all job tasks have exited. It is *not* run as root, because\nthe process in question has already setuid to the job step owner.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\"> switch_job</span>&nbsp; &nbsp;&nbsp;(input) a job\nstep's switch credential.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int switch_p_job_postfini ( stepd_step_rec_t *job );</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: This function is run from the initial slurmd\nprocess (same process as switch_p_job_preinit()), and is run as root. Any cleanup routines\nthat need to be run with root privileges should be run from this function.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> job</span>&nbsp; &nbsp;&nbsp;(input)\nstructure representing the slurmstepd's view of the job step.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int switch_p_job_step_allocated (switch_jobinfo_t\njobinfo switch_job, char *nodelist);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Note that the identified\njob step is active at restart time. This function can be used to\nrestore global switch state information based upon job steps known to be\nactive at restart time. Use of this function is preferred over switch state\nsaved and restored by the switch plugin. Direct use of job step switch\ninformation eliminates the possibility of inconsistent state information\nbetween the switch and job steps.\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> switch_job</span>&nbsp; &nbsp;&nbsp;(input) a job's\nswitch credential.<br>\n<span class=\"commandline\"> nodelist</span>&nbsp; &nbsp;&nbsp;(input) the nodes\nallocated to a job step.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<h3>Job Management Suspend/Resume Functions</h3>\n\n<p class=\"commandline\">int switch_p_job_suspend_test(switch_jobinfo_t *switch_job);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Determine if a specific job\nstep can be preempted.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> switch_job</span>&nbsp; &nbsp;&nbsp;(input) a job\nstep's switch credential.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if the job step can be\npreempted and SLURM_ERROR otherwise.</p>\n\n<p class=\"commandline\">void switch_p_job_suspend_info_get(switch_jobinfo_t *switch_job,\nvoid **suspend_info);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Pack any information needed\nfor a job step to be preempted into an opaque data structure.<br>\n<b>NOTE</b>: Use switch_p_job_suspend_info_free() to free the opaque data structure.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> switch_job</span>&nbsp; &nbsp;&nbsp;(input) a job\nstep's switch credential.<br>\n<span class=\"commandline\"> suspend_info</span>&nbsp; &nbsp;&nbsp;(input/output)\ninformation needed for a job to be preempted. This should be NULL for the\nfirst call and data about job steps will be added to the opaque data structure\nfor addition function call (i.e. for each addition job step).</p>\n\n<p class=\"commandline\">void switch_p_job_suspend_info_pack(void *suspend_info, Buf buffer);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Pack the information needed\nfor a job to be preempted into a buffer</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> suspend_info</span>&nbsp; &nbsp;&nbsp;(input)\ninformation needed for a job to be preempted, including information for all\nsteps in that job.<br>\n<span class=\"commandline\"> buffer</span>&nbsp; &nbsp;&nbsp;(input/output)\nthe buffer that has suspend_info added to it.</p>\n\n<p class=\"commandline\">int switch_p_job_suspend_info_unpack(void **suspend_info, Buf buffer);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Unpack the information needed\nfor a job to be preempted from a buffer.<br>\n<b>NOTE</b>: Use switch_p_job_suspend_info_free() to free the opaque data structure.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> suspend_info</span>&nbsp; &nbsp;&nbsp;(output)\ninformation needed for a job to be preempted, including information for all\nsteps in that job.<br>\n<span class=\"commandline\"> buffer</span>&nbsp; &nbsp;&nbsp;(input/output)\nthe buffer that has suspend_info extracted from it.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if the suspend_info\ndata was successfully read from buffer and SLURM_ERROR otherwise.</p>\n\n<p class=\"commandline\">int switch_p_job_suspend(void *suspend_info, int max_wait);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Suspend a job's use of switch\nresources. This may reset MPI timeout values and/or release switch resources.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> suspend_info</span>&nbsp; &nbsp;&nbsp;(input)\ninformation needed for a job to be preempted, including information for all\nsteps in that job.<br>\n<span class=\"commandline\"> max_wait</span>&nbsp; &nbsp;&nbsp;(input) maximum\ntime interval to wait for the operation to complete, in seconds</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if job's switch\nresources suspended and SLURM_ERROR otherwise.</p>\n\n<p class=\"commandline\">int switch_p_job_resume(void *suspend_info, int max_wait);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Resume a job's use of switch\nresources. This may reset MPI timeout values and/or release switch resources.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> suspend_info</span>&nbsp; &nbsp;&nbsp;(input)\ninformation needed for a job to be resumed, including information for all\nsteps in that job.<br>\n<span class=\"commandline\"> max_wait</span>&nbsp; &nbsp;&nbsp;(input) maximum\ntime interval to wait for the operation to complete, in seconds</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if job's switch\nresources resumed and SLURM_ERROR otherwise.</p>\n\n<p class=\"commandline\">void switch_p_job_suspend_info_free(void *suspend_info);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Free the resources allocated\nto store job suspend/resume information as generated by the\nswitch_p_job_suspend_info_get() and switch_p_job_suspend_info_unpack() functions.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> suspend_info</span>&nbsp; &nbsp;&nbsp;(input)\ninformation needed for a job to be preempted, including information for all\nsteps in that job.</p>\n\n<h3>Job Step Management Suspend/Resume Functions</h3>\n\n<p class=\"commandline\">int switch_p_job_step_pre_suspend (stepd_step_rec_t *jobstep);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Perform any job step pre-suspend functionality (done before the application PIDs are stopped).</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> job</span>&nbsp; &nbsp;&nbsp;(input)\nstructure representing the slurmstepd's view of the job step.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if the job step can be\nsuspended and SLURM_ERROR otherwise.</p>\n\n<p class=\"commandline\">int switch_p_job_step_post_suspend (stepd_step_rec_t *jobstep);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Perform any job step post-suspend functionality (done after the application PIDs are stopped).</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> job</span>&nbsp; &nbsp;&nbsp;(input)\nstructure representing the slurmstepd's view of the job step.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if the job step has been suspended and SLURM_ERROR otherwise.</p>\n\n<p class=\"commandline\">int switch_p_job_step_pre_resume (stepd_step_rec_t *jobstep);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Perform any job step pre-resume functionality (done before the application PIDs are re-started).</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> job</span>&nbsp; &nbsp;&nbsp;(input)\nstructure representing the slurmstepd's view of the job step.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if the job step can be\nresumed and SLURM_ERROR otherwise.</p>\n\n<p class=\"commandline\">int switch_p_job_step_post_resume (stepd_step_rec_t *jobstep);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Perform any job step post-resume functionality (done after the application PIDs are re-started).</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> job</span>&nbsp; &nbsp;&nbsp;(input)\nstructure representing the slurmstepd's view of the job step.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if the job step has been resumed and SLURM_ERROR otherwise.</p>\n\n\n<p style=\"text-align:center;\">Last modified 7 March 2019</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/acct_gather_energy_plugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Slurm Energy Accounting Plugin API (AcctGatherEnergyType)</a></h1>\n\n<h2> Overview</h2>\n<p> This document describes Slurm's energy accounting plugins and the API that\ndefines them. It is intended as a resource to programmers wishing to write\ntheir own Slurm energy accounting plugins.\n\n<p>Slurm energy accounting plugins must conform to the\nSlurm Plugin API with the following specifications:\n\n<p><span class=\"commandline\">const char\nplugin_name[]=\"<i>full&nbsp;text&nbsp;name</i>\"</span>\n<p style=\"margin-left:.2in\">\nA free-formatted ASCII text string that identifies the plugin.\n\n<p><span class=\"commandline\">const char\nplugin_type[]=\"<i>major/minor</i>\"</span><br>\n<p style=\"margin-left:.2in\">\nThe major type must be &quot;acct_gather_energy.&quot;\nThe minor type can be any suitable name\nfor the type of energy accounting. We currently use\n<ul>\n<li><b>none</b> &mdash; No energy consumption data is provided.\n<li><b>ipmi</b> &mdash; Gets energy consumption data from the\nBMC (Baseboard Management Controller) using the\nIPMI (Intelligent Platform Management Interface) tool.\n<li><b>rapl</b> &mdash; Gets energy consumption data from hardware sensors on each\ncore/socket, using RAPL (Running Average Power Limit) sensors. Note that\nenabling RAPL may require the execution of the command \"sudo modprobe msr\".\n<li><b>xcc</b> &mdash; Gets energy consumption data from the Lenovo ThinkSystem\nSD650 XClarity Controller (XCC) using IPMI OEM raw commands.\n</ul>\n\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loaded by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<p>The programmer is urged to study\n<span class=\"commandline\">src/plugins/acct_gather_energy/rapl</span> and \n<span class=\"commandline\">src/common/slurm_acct_gather_energy.c</span>\nfor a sample implementation of a Slurm energy accounting plugin.\n\n<h2>API Functions</h2>\n<p>All of the following functions are required. Functions which are not\nimplemented must be stubbed.\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\">int acct_gather_energy_p_update_node_energy(void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUpdates energy accounting data for a node.\nSets/updates the energy and power accounting values in the acct_gather_energy_t\nstructure for the node on which it is called.\nCalled by the slurmd daemon.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\"> None</span>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">int acct_gather_energy_p_get_data(enum acct_energy_type data_type, acct_gather_energy_t *energy)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUpdates and returns energy consumption of a task, or returns current energy and \npower consumption of a node, according to specified data_type.\nCalled by jobacct_gather plugin to update and return energy consumption of a \ntask.\nCalled by slurmd to return energy and power consumption of a node.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\"> data_type</span> (input) type of energy/power data \nto be returned.<br>\n<span class=\"commandline\"> energy</span> (input) pointer to acct_gather_energy_t \nstruct in which energy/power data is to be returned.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">int acct_gather_energy_p_set_data(enum acct_energy_type data_type, acct_gather_energy_t *energy)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nSets the energy consumption data for a node. Not currently used.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\"> data_type</span> (input) type of energy/power data \nto be set.<br>\n<span class=\"commandline\"> energy</span> (input) pointer to acct_gather_energy_t \nstruct from which energy/power data is to be taken.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<h2>Parameters</h2>\n<p>These parameters can be used in the slurm.conf to configure the\nplugin and the frequency at which to gather node energy data.</p>\n<dl>\n<dt><span class=\"commandline\">AcctGatherEnergyType</span>\n<dd>Specifies which plugin should be used.\n<dt><span class=\"commandline\">AcctGatherNodeFreq</span>\n<dd>Time interval between pollings in seconds.\n</dl>\n\n\n<p style=\"text-align:center;\">Last modified 14 April 2020</p>\n\n<!--#include virtual=\"footer.txt\"-->\n\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/proctrack_plugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Slurm Process Tracking Plugin API</a></h1>\n\n<h2> Overview</h2>\n<p> This document describes Slurm process tracking plugins and the API\nthat defines them.\nIt is intended as a resource to programmers wishing to write their\nown Slurm process tracking plugins.\nNote that process tracking plugin is designed for use with Slurm job steps.\nThere is a <a href=\"job_container_plugins.html\">job_container plugin</a>\ndesigned for use with Slurm jobs.</p>\n\n<p>Slurm process tracking plugins are Slurm plugins that implement\nthe Slurm process tracking API described herein.\nThey must conform to the Slurm Plugin API with the following\nspecifications:</p>\n\n<p><span class=\"commandline\">const char plugin_type[]</span><br>\nThe major type must be &quot;proctrack.&quot;\nThe minor type can be any recognizable abbreviation for the type\nof proctrack. We recommend, for example:</p>\n<ul>\n<li><b>cray_aries</b> &mdash; Use Cray XC job containers.</li>\n<li><b>cgroup</b> &mdash; Use Linux cgroups for process tracking. This is the\nrecommended mechanism for non CRAY systems. </li>\n<li><b>linuxproc</b> &mdash; Perform process tracking based upon a scan\nof the Linux process table and use the parent process ID to determine\nwhat processes are members of a Slurm job. NOTE: This mechanism is\nnot entirely reliable for process tracking.</li>\n<li><b>pgid</b> &mdash; Use process group ID to determine\nwhat processes are members of a Slurm job. NOTE: This mechanism is\nnot entirely reliable for process tracking.</li>\n</ul>\n\n<p><span class=\"commandline\">const char plugin_name[]</span><br>\nSome descriptive name for the plugin.\nThere is no requirement with respect to its format.</p>\n\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loaded by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<p>The programmer is urged to study\n<span class=\"commandline\">src/plugins/proctrack/pgid/proctrack_pgid.c</span>\nfor an example implementation of a Slurm proctrack plugin.</p>\n\n<h2>Data Objects</h2>\n<p> The implementation must support a container id of type uint64_t.\nThis container ID is maintained by the plugin directly in the slurmd\njob structure using the field named <i>cont_id</i>.</p>\n\n<p>The implementation must maintain (though not necessarily directly export) an\nenumerated <b>errno</b> to allow Slurm to discover as practically as possible\nthe reason for any failed API call.\nThese values must not be used as return values in integer-valued functions\nin the API.\nThe proper error return value from integer-valued functions is SLURM_ERROR.\nThe implementation should endeavor to provide useful and pertinent information\nby whatever means is practical.\nSuccessful API calls are not required to reset errno to a known value.</p>\n\n\n<h2>API Functions</h2>\n<p>The following functions must appear. Functions which are not implemented should\nbe stubbed.</p>\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\">int proctrack_p_create (stepd_step_rec_t *job);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Create a container.\nThe caller should ensure that be valid\n<span class=\"commandline\">proctrack_p_destroy()</span> is called.\nThis function must put the container ID directory in the job structure's\nvariable <i>cont_id</i>.</p>\n<p style=\"margin-left:.2in\"><b>Argument</b>:\n<span class=\"commandline\"> job</span>&nbsp; &nbsp;&nbsp;(input/output)\nPointer to a slurmd job structure.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int proctrack_p_add (stepd_step_rec_t *job, pid_t pid);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Add a specific process ID\nto a given job step's container.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> job</span>&nbsp; &nbsp;&nbsp;(input)\nPointer to a slurmd job structure.<br>\n<span class=\"commandline\"> pid</span>&nbsp; &nbsp;&nbsp;(input)\nThe ID of the process to add to this job's container.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int proctrack_p_signal (uint64_t id, int signal);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Signal all processes in a given\njob step container.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> id</span> &nbsp;&nbsp;(input)\nJob step container's ID.<br>\n<span class=\"commandline\"> signal</span> &nbsp;&nbsp;(input)\nSignal to be sent to processes. Note that a signal of zero\njust tests for the existence of processes in a given job step container.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if the signal\nwas sent.\nIf the signal can not be sent, the function should return SLURM_ERROR and set\nits errno to an appropriate value to indicate the reason for failure.</p>\n\n\n<p class=\"commandline\">int proctrack_p_destroy (uint64_t id);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Destroy or otherwise\ninvalidate a job step container.\nThis does not imply the container is empty, just that it is no longer\nneeded.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\"> id</span> &nbsp;&nbsp; (input)\nJob step container's ID.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">uint64_t proctrack_p_find (pid_t pid);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>:\nGiven a process ID, return its job step container ID.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\"> pid</span>&nbsp; &nbsp;&nbsp;(input)\nA process ID.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: The job step container ID\nwith this process or zero if none is found.</p>\n\n<p class=\"commandline\">uint32_t proctrack_p_get_pids (uint64_t cont_id, pid_t **pids, int *npids);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>:\nGiven a process container ID, fill in all the process IDs in the container.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\"> cont_id</span>&nbsp; &nbsp;&nbsp;(input)\nA job step container ID.<br>\n<span class=\"commandline\"> pids</span>&nbsp; &nbsp;&nbsp;(output)\nArray of process IDs in the container.<br>\n<span class=\"commandline\"> npids</span>&nbsp; &nbsp;&nbsp;(output)\nCount of process IDs in the container.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if\n  successful, SLURM_ERROR else.</p>\n\n\n<p style=\"text-align:center;\">Last modified 14 January 2019</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/cred_plugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Slurm Credential Plugin Programmer Guide</a></h1>\n\n<h2> Overview</h2>\n<p> This document describe. Slurm credential plugins and the API that\ndefines them.\nIt is intended as a resource to programmers wishing to write their own\nSlurm credential plugins.</p>\n\n<p>Slurm credential plugins are Slurm plugins that implement\na digital signature mechanism.\nThe slurmctld daemon generates a job step credential, signs it,\nand transmits it to an srun program.\nThe srun program then transmits it to the slurmd daemons directly.\nThe slurmctld daemon does not communicate directly with the slurmd\ndaemons at this time for performance reasons, but the job step\ncredential must be validated by the slurmd daemon as being\ngenerated by the slurmctld daemon.\nDigital signatures provide this validation mechanism.\nThe plugins must conform to the Slurm Plugin API with the following\nspecifications:</p>\n\n<p><span class=\"commandline\">const char plugin_type[]</span><br>\nThe major type must be &quot;cred.&quot;\nThe minor type can be any recognizable abbreviation for the type of\ncredential mechanism.\nWe recommend, for example:</p>\n<ul>\n<li><b>munge</b> &mdash; LLNL's Munge system.</li>\n</ul></p>\n\n<p><span class=\"commandline\">const char plugin_name[]</span><br>\nSome descriptive name for the plugin.\nThere is no requirement with respect to its format.</p>\n\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loaded by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<h2>Data Objects</h2>\n<p>The implementation must maintain (though not necessarily directly export) an\nenumerated <span class=\"commandline\">errno</span> to allow Slurm to discover\nas practically as possible the reason for any failed API call.\nPlugin-specific enumerated integer values may be used when appropriate.\n\n<p>These values must not be used as return values in integer-valued\nfunctions in the API.\nThe proper error return value from integer-valued functions is SLURM_ERROR.\nThe implementation should endeavor to provide useful and pertinent\ninformation by whatever means is practical.\nSuccessful API calls are not required to reset any errno to a known value.\nHowever, the initial value of any errno, prior to any error condition\narising, should be SLURM_SUCCESS. </p>\n\n<h2>API Functions</h2>\n<p>The following functions must appear.\nFunctions which are not implemented should be stubbed.</p>\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\">void *cred_read_private_key(const char *path);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Generate a private key\nbased upon the contents of the supplied file.</p>\n<p style=\"margin-left:.2in\"><b>Argument</b>:<span class=\"commandline\">path</span>&nbsp;\n&nbsp;&nbsp;(input) fully-qualified pathname to the private key\nas specified by the <b>JobCredentialPrivateKey</b> configuration parameter.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: The pointer to a key on\nsuccess or NULL on failure.\nCall cred_p_destroy_key() to release memory associated with this key.</p>\n\n\n<p class=\"commandline\">void *cred_p_read_public_key(const char *path);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Generate a public key\nbased upon the contents of the supplied file.</p>\n<p style=\"margin-left:.2in\"><b>Argument</b>:<span class=\"commandline\">path</span>&nbsp;\n&nbsp;&nbsp;(input) fully-qualified pathname to the public key\nas specified by the <b>JobCredentialPublicCertificate</b> configuration\nparameter.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: The pointer to a key on\nsuccess or NULL on failure.\nCall cred_p_destroy_key() to release memory associated with this key.</p>\n\n\n<p class=\"commandline\">void cred_p_destroy_key(void *key);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Release storage for\na public or private key.</p>\n<p style=\"margin-left:.2in\"><b>Argument</b>:<span class=\"commandline\"> key</span>&nbsp;\n&nbsp;&nbsp;(input/output) pointer to the key previously allocated\nby cred_p_read_private_key() or cred_p_read_public_key().</p>\n\n\n<p class=\"commandline\">char *cred_p_str_error(void);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Return a string\ndescribing the last error generated by the credential software.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: A pointer to a string.</p>\n\n<p class=\"commandline\">int cred_p_sign(void *key, char *buffer, int buf_size,\nchar **sig_pp, unsigned int *sig_size_p);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Generate a signature for\nthe supplied buffer.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:</br>\n<span class=\"commandline\"> key</span>&nbsp;\n&nbsp;&nbsp;(input) pointer to the key previously generated by\ncred_p_read_private_key() or cred_p_read_public_key().<br>\n<span class=\"commandline\"> buffer</span>&nbsp; &nbsp;&nbsp;(input) data to\nbe signed.<br>\n<span class=\"commandline\"> buf_size</span>&nbsp; &nbsp;&nbsp;(input)\nsize of buffer, in bytes.<br>\n<span class=\"commandline\"> sig_pp</span>&nbsp; &nbsp;&nbsp;(input/output)\nLocation in which to store the signature. NOTE: The storage for\nsig_pp should be allocated using xmalloc() and will be freed by\nthe caller using xfree().<br>\n<span class=\"commandline\"> sig_size_p</span>&nbsp; &nbsp;&nbsp;(input/output)\nLocation in which to store the size of the signature (sig_pp).</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful.\nOn failure, the plugin should return SLURM_ERROR and set the errno to an\nappropriate value to indicate the reason for failure.</p>\n\n<p class=\"commandline\">int cred_p_verify_sign(void *key, char *buffer,\nint buf_size, char *signature, unsigned int sig_size);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Generate a signature for\nthe supplied buffer.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:</br>\n<span class=\"commandline\"> key</span>&nbsp;\n&nbsp;&nbsp;(input) pointer to the key previously generated by\ncred_p_read_private_key() or cred_p_read_public_key().<br>\n<span class=\"commandline\"> buffer</span>&nbsp; &nbsp;&nbsp;(input) data\npreviously signed by cred_p_sign().<br>\n<span class=\"commandline\"> buf_size</span>&nbsp; &nbsp;&nbsp;(input)\nsize of buffer, in bytes.<br>\n<span class=\"commandline\"> signature</span>&nbsp; &nbsp;&nbsp;(input)\nSignature as returned in sig_pp by the cred_p_sign() function and\nto be confirmed.</br>\n<span class=\"commandline\"> sig_size</span>&nbsp; &nbsp;&nbsp;(input)\nSize of the signature as returned in sig_size_p by cred_p_sign().</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful.\nOn failure, the plugin should return SLURM_ERROR and set the errno to an\nappropriate value to indicate the reason for failure.</p>\n\n\n<p style=\"text-align:center;\">Last modified 7 January 2019</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/prep_plugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">PrEp Plugin API</a></h1>\n\n<h2>Overview</h2>\n<p>This document describes the Slurm PrEp &mdash; short for \"Pr\"olog and\n\"Ep\"ilog &mdash; plugins API. It is intended as a resource to programmers\nwishing to write their own Slurm prep plugins.</p>\n\n<p>The purpose of the prep plugin APIs to provide a native C interface to the\nsame hooks traditionally used by the <i>Prolog</i>, <i>Epilog</i>,\n<i>PrologSlurmctld</i>, and <i>EpilogSlurmctld</i> scripts. Those interfaces\nare now implemented through the <i>prep/script</i> plugin, and that plugin\nserves as a good example of how to approach development of additional\nplugins.</p>\n\n<p>Slurm PrEp plugins must conform to the Slurm Plugin API with the following\nspecifications:</p>\n\n<p><span class=\"commandline\">\nconst char plugin_name[]=\"<i>full&nbsp;text&nbsp;name</i>\"\n</span></p>\n<p style=\"margin-left:.2in\">\nA free-formatted ASCII text string that identifies the plugin.\n</p>\n\n<p><span class=\"commandline\">\nconst char plugin_type[]=\"<i>major/minor</i>\"\n</span></p>\n<p style=\"margin-left:.2in\">\nThe major type must be &quot;prep&quot;.\nThe minor type can be any suitable name for the type of prep plugin.\n</p>\n\n<p><span class=\"commandline\">const uint32_t plugin_version</span></p>\n<p style=\"margin-left:.2in\">\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loaded by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.\n</p>\n\n<p>Slurm can be configured to use multiple prep plugins if desired through the\nPrEpPlugins configuration option. Additional plugins should be comma-separated.\nNote that, by default, the <i>prep/script</i> plugin is loaded if that option\nis not set, but will not be loaded if an explict setting has been made. Thus,\nif you do set that option, and intend to still use the <i>Prolog</i>,\n<i>Epilog</i>, <i>PrologSlurmctld</i>, and/or <i>EpilogSlurmctld</i> options\nyou will need to ensure both your additional plugin and <i>prep/script</i> are\nset.</p>\n\n<p>Special care must be used when developing against the\n<span class=\"commandline\">prep_p_prolog_slurmctld()</span> or\n<span class=\"commandline\">prep_p_epilog_slurmctld()</span> interfaces. These\nfunctions are called while the slurmctld holds a number of internal locks,\nand need to return quickly otherwise slurmctld responsiveness and system\nthroughput will be impacted. For simple logging, this is not required, and\nthe \"async\" option can be left to false. But, especially for anything\ncommunicating with an external API or spawning additional processes, it is\nhighly recommended to first make a local copy of any job record details\nrequired, and then spawn a separate processing thread &mdash; which, by default,\nwill not have inherited any slurmctld locks &mdash; to continue processing.\nYou must set the async return value to true, and call the corresponding\n<span class=\"commandline\">prolog_slurmctld_callback()</span> or\n<span class=\"commandline\">epilog_slurmctld_callback()</span> function before\nthe thread exits. These callbacks are provided as function pointers when the\nslurmctld starts through\n<span class=\"commandline\">prep_p_register_callbacks()</span> call, and these\nfunction pointers should be cached locally in your plugin.</p>\n\n<h2>API Functions</h2>\n<p>All of the following functions are required. Functions which are not\nimplemented must be stubbed.</p>\n\n<p class=\"commandline\">int init(void)</p>\n<p style=\"margin-left:.2in\"><b>Description</b>:<br />\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br />\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br />\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\">void fini(void)</p>\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\">\nvoid prep_p_register_callbacks(prep_callbacks_t *callbacks)\n</p>\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nThis function is called by the slurmctld to pass function pointer addresses\nused with asynchronous operation with the prep_p_prolog_slurmctld() and\nprep_p_epilog_slurmctld() interfaces. These pointers must be saved if\nasynchronous operation is used, otherwise this function can be an empty stub.\n</p>\n\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">callbacks</span>\n(input) contains function pointers for use with asynchronous operation within the slurmctld\n</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p class=\"commandline\">\nint prep_p_prolog(job_env_t *job_env, slurm_cred_t *cred)\n</p>\n<p style=\"margin-left:.2in\"><b>Description</b>:<br />\nCalled within the slurmd as root before the first step of a job starts on the\ncompute node.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br />\n<span class=\"commandline\">job_env</span>\n(input) details from the step launch request<br />\n<span class=\"commandline\">cred</span>\n(input) launch credential with additional verifiable launch details signed by\nthe slurmctld<br />\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure, will cause job failure.\n</p>\n\n<p class=\"commandline\">\nint prep_p_epilog(job_env_t *job_env, slurm_cred_t *cred)\n</p>\n<p style=\"margin-left:.2in\"><b>Description</b>:<br />\nCalled within the slurmd as root after all job steps have completed.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br />\n<span class=\"commandline\">job_env</span>\n(input) details from the step launch request<br />\n<span class=\"commandline\">cred</span>\n(input) launch credential with additional verifiable launch details signed by\nthe slurmctld<br />\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure, will cause job failure.\n</p>\n\n<p class=\"commandline\">\nint prep_p_prolog_slurmctld(job_record_t *job_ptr, bool *async)\n</p>\n<p style=\"margin-left:.2in\"><b>Description</b>:<br />\nCalled within the slurmctld before a job launches.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br />\n<span class=\"commandline\">job_ptr</span>\n(input) raw job record<br />\n<span class=\"commandline\">async</span>\n(output) set to true if this interface has spawned a separate processing thread\nthat must complete before the job starts execution<br />\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure, will cause job failure.\n</p>\n\n<p class=\"commandline\">\nint prep_p_epilog_slurmctld(job_record_t *job_ptr, bool *async)\n</p>\n<p style=\"margin-left:.2in\"><b>Description</b>:<br />\nCalled within the slurmctld before a job launches.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br />\n<span class=\"commandline\">job_ptr</span>\n(input) raw job record<br />\n<span class=\"commandline\">async</span>\n(output) set to true if this interface has spawned a separate processing thread\nthat must complete before the job is marked complete<br />\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure, will cause job failure.\n</p>\n\n<p style=\"text-align:center;\">Last modified 22 April 2020</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/jobacct_gatherplugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Slurm Job Accounting Gather Plugin API</a></h1>\n\n<h2> Overview</h2>\n<p> This document describes Slurm job accounting gather plugins and the API that\ndefines them. It is intended as a resource to programmers wishing to write\ntheir own Slurm job accounting gather plugins.\n\n<p>Slurm job accounting gather plugins must conform to the\nSlurm Plugin API with the following specifications:\n\n<p><span class=\"commandline\">const char\nplugin_name[]=\"<i>full&nbsp;text&nbsp;name</i>\"</span>\n<p style=\"margin-left:.2in\">\nA free-formatted ASCII text string that identifies the plugin.\n\n<p><span class=\"commandline\">const char\nplugin_type[]=\"<i>major/minor</i>\"</span><br>\n<p style=\"margin-left:.2in\">\nThe major type must be &quot;jobacct_gather.&quot;\nThe minor type can be any suitable name\nfor the type of accounting package. We currently use\n<ul>\n<li><b>cgroup</b> &mdash; Gathers information from Linux cgroup\ninfrastructure and adds this information to the standard rusage\ninformation also gathered for each job. (Experimental, not to be used\n  in production.)\n<li><b>linux</b> &mdash; Gathers information from Linux /proc table and adds this\ninformation to the standard rusage information also gathered for each job.\n<li><b>none</b> &mdash; No information gathered.\n</ul>\n\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loaded by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<p>The <b>sacct</b> program can be used to display gathered data from regular\naccounting and from these plugins.</p>\n<p>The programmer is urged to study\n<span class=\"commandline\">src/plugins/jobacct_gather/linux</span> and\n<span class=\"commandline\">src/common/slurm_jobacct_gather.[c|h]</span>\nfor a sample implementation of a Slurm job accounting gather plugin.\n\n\n<h2>API Functions</h2>\n<p>All of the following functions are required. Functions which are not\nimplemented must be stubbed.\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\">int jobacct_gather_p_poll_data(List task_list, bool pgid_plugin, uint64_t cont_id)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nBuild a table of all current processes.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\"> task_list</span> (in/out) List containing\ncurrent processes <br>\n<span class=\"commandline\"> pgid_plugin</span> (input) if we are\nrunning with the pgid plugin<br>\n<span class=\"commandline\"> cont_id</span> (input) container id of processes if not running with pgid\n\n<p class=\"commandline\">int jobacct_gather_p_endpoll(void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nCalled when the process is finished to stop the\npolling thread.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">none</span>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">int jobacct_gather_p_add_task(pid_t pid, uint16_t tid)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUsed to add a task to the poller.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\"> pid</span> (input) Process id <br>\n<span class=\"commandline\"> tid</span> (input) slurm global task id\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n\n\n<h2>Job Account Gathering</h2>\n<p>All of the following functions are not required but may be used.\n\n<p class=\"commandline\">int jobacct_gather_init(void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nLoads the job account gather plugin.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">int jobacct_gather_fini(void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUnloads the job account gathering plugin.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">int jobacct_gather_startpoll(uin16_t frequency)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nCreates and starts the polling thread.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\"> frequency </span> (input) frequency of the polling.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">void jobacct_gather_change_poll(uint16_t frequency)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nChanges the polling thread to a new frequency.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\"> frequency </span> (input) frequency of the polling\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">void jobacct_gather_suspend_poll(void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nTemporarily stops the polling thread.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">void jobacct_gather_resume_poll(void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nResumes the polling thread that was stopped.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandine\">jobacctinfo_t *jobacct_gather_stat_task(pid_t\n  pid)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nGets the basis of the information of the task.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">pid</span> (input) process id.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">jobacctinfo_t *jobacct_gather_remove_task(pid_t pid)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nRemoves the task.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">pid</span> (input) process id.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">int\n  jobacct_gather_set_proctrack_container_id(uint64_t id)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n Sets the proctrack container to a given id.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">id</span> (input) id to set.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">int jobacct_gather_set_mem_limit(uint32_t job_id,\n  uint32_t step_id, uint64_t mem_limit)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nSets the memory limit  of the job account.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job_id</span> (input) id of the job.<br>\n<span class=\"commandline\">sted_id</span> (input) id of the step.<br>\n<span class=\"commandline\">mem_limit</span> (input) memory limit in megabytes.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">void jobacct_gather_handle_mem_limit(uint64_t total_job_mem, uint64_t total_job_vsize)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nCalled to find out how much memory is used.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\"> total_job_mem</span> (input) total\namount of memory for jobs.<br>\n<span class=\"commandline\"> total_job_vsize</span> (input) the\ntotal job size.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<h2>Job Account Info</h2>\n<p>All of the following functions are not required but may be used.\n\n<p class=\"commandline\">jobacctinfo_t *jobacctinfo_create(jobacct_id_t *jobacct_id)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nCreates the job account info.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\"> jobacct_id</span> (input) the job\naccount id.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">void jobacctinfo_destroy(void *object)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nDestroys the job account info.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\"> object</span> (input) the job that needs to be destroyed\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">int jobacctinfo_setinfo(jobacctinfo_t *jobacct, enum jobacct_data_type type, void *data)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nSet the information for the job.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\"> jobacct</span> (input) job account<br>\n<span class=\"commandline\"> type</span>(input) enum telling the plugin how to transform the data.<br>\n<span class=\"commandline\"> data</span> (input/output) Is a void * and\nthe actual data type depends upon the first argument to this function (type).\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">int jobacctinfo_getinfo(jobacctinfo_t *jobacct, enum jobacct_data_type type, void *data)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nGets the information about the job.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\"> jobacct</span> (input) job account.<br>\n<span class=\"commandline\">type</span> (input) the\ndata type of the job account.\n<span class=\"commandline\">data</span>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\"> void jobacctinfo_pack(jobacctinfo_t *jobacct,\nuint16_t rpc_version, Buf buffer)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nPacks the job account information.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">jobacct</span> (input) the job account.<br>\n<span class=\"commandline\">rpc_version</span> (input) the\nrpc version.<br>\n<span class=\"commandline\">buffer</span> (input) the buffer.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">int jobacctinfo_unpack(jobacctinfo_t **jobacct,\nuint16_t rpc_version, Buf buffer)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUnpacks the job account information.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">jobacct</span> (input) the job account.<br>\n<span class=\"commandline\">rpc_version</span> (input) the rpc\nversion.<br>\n<span class=\"commandline\">buffer</span> (input) the buffer.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">void jobacctinfo_aggregate(jobacctinfo_t *dest, jobacctinfo_t *from)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nAggregates the jobs.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">dest</span> (input) New destination of the job.<br>\n<span class=\"commandline\">from</span> (input) Original location of job.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">void jobacctinfo_2_stats(slurmdb_stats_t *stats, jobacctinfo_t *jobacct)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nGets the stats of the job in accounting.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">stats</span> (input) slurm data base stat.<br>\n<span class=\"commandline\">jobacct</span> (input) the job account.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n\n<h2>Parameters</h2>\n<p>These parameters can be used in the slurm.conf to configure the\nplugin and the frequency at which to gather information about running jobs.</p>\n<dl>\n<dt><span class=\"commandline\">JobAcctGatherType</span>\n<dd>Specifies which plugin should be used.\n<dt><span class=\"commandline\">JobAcctGatherFrequency</span>\n<dd>Time interval between pollings in seconds.\n</dl>\n\n\n<p style=\"text-align:center;\">Last modified 27 March 2015</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/topology_plugin.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Topology Plugin Programmer Guide</a></h1>\n\n<h2> Overview</h2>\n<p> This document describes Slurm topology plugin and the API that\ndefines them.\nIt is intended as a resource to programmers wishing to write their own\nSlurm topology plugin.</p>\n\n<p>Slurm topology plugins are Slurm plugins that implement\nconvey system topology information so that Slurm is able to\noptimize resource allocations and minimize communication overhead.\nThe plugins must conform to the Slurm Plugin API with the following\nspecifications:</p>\n\n<p><span class=\"commandline\">const char plugin_type[]</span><br>\nThe major type must be &quot;topology.&quot;\nThe minor type specifies the type of topology mechanism.\nWe recommend, for example:</p>\n<ul>\n<li><b>3d_torus</b> &mdash; Optimize placement for a three dimensional torus.</li>\n<li><b>none</b> &mdash; No topology information.</li>\n<li><b>tree</b> &mdash; Optimize placement based upon a hierarchy of network\nswitches.</li>\n</ul></p>\n\n<p><span class=\"commandline\">const char plugin_name[]</span><br>\nSome descriptive name for the plugin.\nThere is no requirement with respect to its format.</p>\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loaded by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<p>The actions performed by these plugins vary widely.\nIn the case of <b>3d_torus</b>, the nodes in configuration file\nare re-ordered so that nodes which are nearby in the one-dimensional\ntable are also nearby in logical three-dimensional space.\nIn the case of <b>tree</b>, a tabled is built to reflect network\ntopology and that table is later used by the <b>select</b> plugin\nto optimize placement.\nNote carefully, however, the versioning discussion below.</p>\n\n<h2>Data Objects</h2>\n<p>The implementation must maintain (though not necessarily directly export) an\nenumerated <span class=\"commandline\">errno</span> to allow Slurm to discover\nas practically as possible the reason for any failed API call.\nPlugin-specific enumerated integer values may be used when appropriate.\n\n<p>These values must not be used as return values in integer-valued\nfunctions in the API.\nThe proper error return value from integer-valued functions is SLURM_ERROR.\nThe implementation should endeavor to provide useful and pertinent\ninformation by whatever means is practical.\nSuccessful API calls are not required to reset any errno to a known value.\nHowever, the initial value of any errno, prior to any error condition\narising, should be SLURM_SUCCESS. </p>\n\n<h2>API Functions</h2>\n<p>The following functions must appear.\nFunctions which are not implemented should be stubbed.</p>\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\">int topo_build_config(void);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Generate topology information.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS or\nSLURM_ERROR on failure.</p>\n\n<p class=\"commandline\">bool topo_generate_node_ranking(void)</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Determine if this plugin will\nreorder the node records based upon each job's node rank field.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: true if node reording is supported,\nfalse otherwise.</p>\n\n<p class=\"commandline\">int topo_get_node_addr(char* node_name, char** paddr, char** ppatt);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Get Topology address of a given node.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<b>node_name</b> (input) name of the targeted node<br>\n<b>paddr</b> (output) returns the topology address of the node and connected\nswitches. If there are multiple switches at some level in the hierarchy, they\nwill be represented using Slurm's hostlist expression (e.g. \"s0\" and \"s1\" are\nreported as \"s[0-1]\").  Each level in the hierarchy is separated by a period.\nThe last element will always be the node's name (i.e. \"s0.s10.nodename\")<br>\n<b>ppatt</b> (output) returns the pattern of the topology address. Each level\nin the hierarchy is separated by a period. The final element will always be\n\"node\" (i.e. \"switch.switch.node\")<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS or\nSLURM_ERROR on failure.</p>\n\n\n<p style=\"text-align:center;\">Last modified 27 March 2015</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/site_factor.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Slurm Priority Site Factor Plugin API</a></h1>\n\n<h2>Overview</h2>\n<p> This document describes Slurm site_factor plugins and the API that defines\nthem. It is intended as a resource to programmers wishing to write their own\nSlurm site_factor plugins.</p>\n\n<p>Slurm site_factor plugins are Slurm plugins that implement the Slurm\nsite_factor API described herein. They are designed to provide the site a\nway to build a custom multifactor priority factor, and will only be loaded\nand operation alongside\n<span class=\"commandline\">PriorityType=priority/multifactor</span>.</p>\n\n<p>The plugins are meant to set and update the\n<span class=\"commandline\">site_factor</span> value in the\n<span class=\"commandline\">job_record_t</span> corresponding to a given job.\nNote that the <span class=\"commandline\">site_factor</span> itself is an\nunsigned integer, but uses <span class=\"commandline\">NICE_OFFSET</span> as\nan offset to allow the value to be positive or negative. The plugin itself\nmust add <span class=\"commandline\">NICE_OFFSET</span> to the value stored to\n<span class=\"commandline\">site_factor</span> for proper operation, otherwise\nthe value itself will be extremely negative, and the job priority will likely\ndrop to 1. (The lowest value that does not correspond to a held job.)</p>\n\n<p>Plugins must conform to the Slurm Plugin API with the following\nspecifications:</p>\n\n<p><span class=\"commandline\">const char plugin_type[]=\"<i>major/minor</i>\"</span><br>\nThe major type must be &quot;site_factor&quot; The minor type can be any\nrecognizable abbreviation for the specific plugin.</p>\n\n\n<p><span class=\"commandline\">const char plugin_name[]</span><br>\nSome descriptive name for the plugin.\nThere is no requirement with respect to its format.</p>\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loaded by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<h2>API Functions</h2>\n<p>The following functions must appear. Functions which are not implemented\nmust be stubbed, or the plugin will fail to load.</p>\n\n<p class=\"commandline\">int init(void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\">void fini(void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\">void site_factor_p_reconfig(void)</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Refresh the plugin's\nconfiguration. Called whenever slurmctld is reconfigured.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: void</p>\n\n<p class=\"commandline\">void site_factor_p_set(job_record_t *job_ptr)</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Sets the site_priority of the job, if desired.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\">job_ptr</span> (input) pointer to the job record.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: void</p>\n\n<p class=\"commandline\">void site_factor_p_update(void)</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Handle periodic updates to\nall site_priority values in the job_list. Called every </p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: void</p>\n\n<h2>Parameters</h2>\n<p>These parameters can be used in the slurm.conf to configure the\nplugin and the frequency at which to gather information about running jobs.</p>\n<dl>\n<dt><span class=\"commandline\">PrioritySiteFactorParameters</span></dt>\n<dd>Optional parameters for the site_factor plugin. Interpretation of any\nvalue is left to the site_factor plugin itself.</dd>\n<dt><span class=\"commandline\">PrioritySiteFactorPlugin</span></dt>\n<dd>Specifies which plugin should be used.</dd>\n<dt><span class=\"commandline\">PriorityCalcPeriod</span></dt>\n<dd>Interval between calls to\n<span class=\"commandline\">site_factor_p_update()</span></dd>\n</dl>\n\n<p style=\"text-align:center;\">Last modified 23 October 2019</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/launch_plugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Launch Plugin API</a></h1>\n\n<h2> Overview</h2>\n<p> This document describes the launch plugin that is responsible for\n  launching a parallel task in Slurm and the API that defines them. It\n  is intended as a resource to programmers wishing to write their own\n  launch plugin.\n\n<p><span class=\"commandline\">const char\nplugin_name[]=\"<i>launch&nbsp;Slurm&nbsp;plugin</i>\"</span>\n<p style=\"margin-left:.2in\">\n\n<p><span class=\"commandline\">const char\nplugin_type[]=\"<i>launch/slurm</i>\"</span><br>\n<p style=\"margin-left:.2in\">\n\n<ul>\n<li><b>slurm</b> &mdash; Use Slurm's default launching infrastructure</li>\n</ul>\n\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loaded by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<p>The programmer is urged to study\n<span class=\"commandline\">src/plugins/launch/slurm/launch_slurm.c</span>\nfor a sample implementation of a Slurm launch plugin.\n\n<h2>API Functions</h2>\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\"> int launch_p_setup_srun_opt(char **rest, opt_t *opt_local)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Sets up the srun operation.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n  <span class=\"commandline\"> rest:</span> extra parameters on the\n  command line not processed by srun<br>\n  <span class=\"commandline\"> opt_local:</span> task launch options from srun command\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\"> int launch_p_handle_multi_prog_verify(int command_pos, opt_t *opt_local)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Is called to verify a multi-prog file if verifying needs to be done.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n  <span class=\"commandline\"> command_pos:</span> to be used with\n  global opt variable to tell which spot the command is in opt.argv.<br>\n  <span class=\"commandline\"> opt_local:</span> task launch options from srun command\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">1</span> if handled, or<br>\n  <span class=\"commandline\">0</span> if not.\n\n<p class=\"commandline\"> int launch_p_create_job_step(srun_job_t *job,\n  bool use_all_cpus, void (*signal_function)(int), sig_atomic_t\n  *destroy_job, opt_t *opt_local, int pack_offset)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Creates the job step.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n  <span class=\"commandline\"> job:</span> the job to run.<br>\n  <span class=\"commandline\"> use_all_cpus:</span> choice whether to use\n  all cpus.<br>\n  <span class=\"commandline\"> signal_function:</span> function that\n  handles the signals coming in.<br>\n  <span class=\"commandline\"> destroy_job:</span> pointer to a global\n  flag signifying if the job was canceled while allocating.\n  <span class=\"commandline\"> opt_local:</span> task launch options from srun command<br>\n  <span class=\"commandline\"> pack_offset:</span> zero-origin index into a\n  heterogeneous job allocation, -1 if not heterogeneous job\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\"> launch_p_step_launch(srun_job_t *job,\n  slurm_step_io_fds_t *cio_fds, uint32_t *global_rc, opt_t *opt_local)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Launches the job step.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n  <span class=\"commandline\"> job:</span> the job to launch.<br>\n  <span class=\"commandline\"> cio_fds:</span> filled in io descriptors<br>\n  <span class=\"commandline\"> global_rc:</span> srun global return code.<br>\n  <span class=\"commandline\"> opt_local:</span> task launch options from srun command\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\"> int launch_p_step_wait(srun_job_t *job, bool\n  got_alloc, opt_t *opt_local, int pack_offset)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Waits for the job to be finished.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n  <span class=\"commandline\"> job:</span> the job to wait for.<br>\n  <span class=\"commandline\"> got_alloc:</span> if the resource\n  allocation was created inside srun.<br>\n  <span class=\"commandline\"> opt_local:</span> task launch options from srun command<br>\n  <span class=\"commandline\"> pack_offset:</span> zero-origin index into a\n  heterogeneous job allocation, -1 if not heterogeneous job\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\"> int launch_p_step_terminate(void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Terminates the job step.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\"> void launch_p_print_status(void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Gets the status of the job.\n\n<p class=\"commandline\"> void launch_p_fwd_signal(int signal)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Sends a forward signal to any underlying tasks.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n  <span class=\"commandline\"> signal:</span> the signal that needs to be sent.\n\n\n<p style=\"text-align:center;\">Last modified 14 June 2018</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/schedplugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Slurm Scheduler Plugin API</a></h1>\n\n<h2> Overview</h2>\n<p> This document describe. Slurm scheduler plugins and the API that defines\nthem. It is intended as a resource to programmers wishing to write their own Slurm\nscheduler plugins.</p>\n\n<p>It is noteworthy that two different models are used for job scheduling.\nThe <b>backfill</b> scheduler let. Slurm establishes the initial job priority\nand can periodically alter job priorities to change their order within the queue.\nDevelopers may use the model that best fits their needs.\nNote that a separate <a href=\"selectplugins.html\">node selection plugin</a>\nis available for controlling that aspect of scheduling.</p>\n\n<p>Slurm scheduler plugins are Slurm plugins that implement the Slurm scheduler\nAPI described herein. They must conform to the Slurm Plugin API with the following\nspecifications:</p>\n<p><span class=\"commandline\">const char plugin_type[]</span><br>\nThe major type must be &quot;sched.&quot; The minor type can be any recognizable\nabbreviation for the type of scheduler. We recommend, for example:</p>\n<ul>\n<li><b>builtin</b> &mdash; A plugin that implements the API without providing any actual\nscheduling services. This is the default behavior and implements first-in-first-out scheduling.</li>\n<li><b>backfill</b> &mdash; Raise the priority of jobs if doing so results in their starting earlier\nwithout any delay in the expected initiation time of any higher priority job.</li>\n</ul>\n\n<p><span class=\"commandline\">const char plugin_name[]</span><br>\nSome descriptive name for the plugin.\nThere is no requirement with respect to its format.</p>\n\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loaded by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<h2>API Functions</h2>\n<p>The following functions must appear. Functions which are not implemented should\nbe stubbed.</p>\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\">int slurm_sched_p_reconfig (void);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Reread any configuration files.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>: None</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On fail\nure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int slurm_sched_p_schedule (void);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: For passive schedulers, invoke a scheduling pass.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>: None</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int slurm_sched_p_newalloc(job_record_t *job_ptr);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Note the successful allocation of resources to a job.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>: Pointer to the slurmctld job structure. This can be used to\nget partition, allocated resources, time limit, etc.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int slurm_sched_p_freealloc(job_record_t *job_ptr);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Note the successful release of resources for a job.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>: Pointer to the slurmctld job structure. This can be used to\nget partition, allocated resources, time limit, etc.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">uint32_t slurm_sched_p_initial_priority(uint32_t last_prio, job_record_t *job_ptr);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Establish the initial priority of a new job.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<b>last_prio</b> (input) default priority of the previously submitted job.\nThis can be used to provide First-In-First-Out scheduling by assigning the\nnew job a priority lower than this value.\nThis could also be used to establish an initial priority of zero for all jobs,\nrepresenting a \"held\" state.\nThe scheduler plugin can then decide where and when to initiate pending jobs\nby altering their priority and (optionally) list of required nodes.<br>\n<b>job_ptr</b> (input)\nPointer to the slurmctld job structure. This can be used to get partition,\nresource requirements, time limit, etc.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: The priority to be assigned to this job.</p>\n\n<p class=\"commandline\">void slurm_sched_p_job_is_pending (void);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Note that some job is pending execution.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>: None</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: Nothing.</p>\n\n<p class=\"commandline\">void slurm_sched_p_partition_change (void);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Note that some partition state change\nhappened such as time or size limits.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>: None</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: Nothing.</p>\n\n<p class=\"commandline\">char *slurm_sched_p_get_conf (void);</p></a>\n<p style=\"margin-left:.2in\"><b>Description</b>: Return scheduler specific\nconfiguration information to be reported for the <i>scontrol show configuration</i>\ncommand.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>: None</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: A string containing configuration\ninformation. The return value is released using the <i>xfree()</i> function.</p>\n\n<p style=\"text-align:center;\">Last modified 23 October 2019</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/mpi_guide.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1>MPI and UPC Users Guide</h1>\n\n<p>MPI use depends upon the type of MPI being used.\nThere are three fundamentally different modes of operation used\nby these various MPI implementation.\n<ol>\n<li>Slurm directly launches the tasks and performs initialization of\ncommunications through the PMI2 or PMIx APIs. (Supported by most\nmodern MPI implementations.)</li>\n<li>Slurm creates a resource allocation for the job and then\nmpirun launches tasks using Slurm's infrastructure (older versions of\nOpenMPI).</li>\n<li>Slurm creates a resource allocation for the job and then\nmpirun launches tasks using some mechanism other than Slurm,\nsuch as SSH or RSH.\nThese tasks initiated outside of Slurm's monitoring\nor control. Slurm's epilog should be configured to purge\nthese tasks when the job's allocation is relinquished. The\nuse of pam_slurm_adopt is also strongly recommended.</li>\n</ol>\n<p><b>Note</b>: Slurm is not directly launching the user application in case 3,\nwhich may prevent the desired behavior of binding tasks to CPUs and/or\naccounting. Some versions of some MPI implementations work, so testing your\nparticular installation may be required to determie the actual behavior.</p>\n\n<p>Two Slurm parameters control which MPI implementation will be\nsupported. Proper configuration is essential for Slurm to establish the\nproper environment for the MPI job, such as setting the appropriate\nenvironment variables. The <i>MpiDefault</i> configuration parameter\nin <i>slurm.conf</i> establishes the system default MPI to be supported.\nThe <i>srun</i> option <i>--mpi=</i> (or the equivalent environment\nvariable <i>SLURM_MPI_TYPE</i> can be used to specify when a\ndifferent MPI implementation is to be supported for an individual job).</p>\n\n<p><b>Note</b>: Use of an MPI implementation without the appropriate Slurm\nplugin may result in application failure. If multiple MPI implementations\nare used on a system then some users may be required to explicitly specify\na suitable Slurm MPI plugin.</p>\n\n<p>Links to instructions for using several varieties of MPI/PMI\nwith Slurm are provided below.\n<ul>\n<li><a href=\"#intel_mpi\">Intel-MPI</a></li>\n<li><a href=\"#mpich2\">MPICH2</a></li>\n<li><a href=\"#mvapich2\">MVAPICH2</a></li>\n<li><a href=\"#open_mpi\">Open MPI</a></li>\n<li><a href=\"#pmix\">PMIx</a></li>\n<li><a href=\"#UPC\">UPC</a></li>\n</ul></p>\n<hr size=4 width=\"100%\">\n\n<h2><a name=\"pmix\" href=\"https://www.open-mpi.org/projects/pmix/\"><b>PMIx</b>\n</a></h2>\n\n<h3>Building PMIx</h3>\n\n<p>Before building PMIx, it is advisable to read these\n<a href=\"https://pmix.org/support/how-to/\">How-To Guides</a>. They provide\nsome details on\n<a href=\"https://pmix.org/code/getting-the-reference-implementation\">\nbuilding dependencies and installation steps</a> as well as some relevant notes\nwith regards to <a href=\"https://pmix.org/support/how-to/slurm-support\">Slurm\nSupport</a>.</p>\n\n<p>This section is intended to complement the PMIx FAQ with some notes on how to\nprepare Slurm and PMIx to work together. PMIx can be obtained from the official\n<a href=\"https://github.com/pmix/pmix\">PMIx GitHub</a> repository, either by\ncloning the repository or by downloading a packaged release.</p>\n\n<p>Slurm support for PMIx was first included in Slurm 16.05 based on the PMIx\nv1.2 release. It has since been updated to support the PMIx v2.x and v3.x\nseries, as per the following table:\n<ul>\n<li>Slurm 16.05+ supports only the PMIx v1.x series, starting with v1.2.0. This\nSlurm version specifically does <b>not</b> support PMIx v2.x and above.</li>\n<li>Slurm 17.11+ supports both PMIx v1.2+ and v2.x but not v3.x.</li>\n<li>Slurm 18.08+ supports PMIx v1.2+, v2.x and v3.x.</li>\n</ul>\nIf running PMIx v1, it is recommended to run at least 1.2.5 since older\nversions may have some compatibility issues with support of pmi and pmi2 APIs.\n\nNote also that Intel MPI doesn't officially support PMIx, so thought it can\nrun there is not any guarantee.\n</p>\n\n<p>Altough it is recommended to build PMIx from the\n<a href=\"https://github.com/pmix/pmix/releases\">packaged releases</a>, here is\nan example on how to build PMIx v2.1 by cloning the git repository:\n</p>\n\n<pre>\nuser@testbox:~/git$ mkdir -p pmix/build/2.1 pmix/install/2.1\nuser@testbox:~/git$ cd pmix\nuser@testbox:~/git/pmix$ git clone https://github.com/pmix/pmix.git source\nuser@testbox:~/git/pmix$ cd source/\nuser@testbox:~/git/pmix/source$ git branch -a\nuser@testbox:~/git/pmix/source$ git checkout v2.1\nuser@testbox:~/git/pmix/source$ git pull\nuser@testbox:~/git/pmix/source$ ./autogen.sh\nuser@testbox:~/git/pmix/source$ cd ../build/2.1/\nuser@testbox:~/git/pmix/build/2.1$ ../../source/configure \\\n&gt; --prefix=/home/user/git/pmix/install/2.1\nuser@testbox:~/git/pmix/build/2.1$ make -j install >/dev/null\nuser@testbox:~/git/pmix/build/2.1$ cd ../../install/2.1/\nuser@testbox:~/git/pmix/install/2.1$ grep PMIX_VERSION include/pmix_version.h\n#define PMIX_VERSION_MAJOR 2L\n#define PMIX_VERSION_MINOR 1L\nuser@testbox:~/git/pmix/install/2.1$\n</pre>\n\n<p>For the purpose of these instructions let's imagine PMIx v2.1 has been\ninstalled on the following path:</p>\n\n<pre>\nuser@testbox:/home/user/git/pmix/install/2.1\n</pre>\n\n<p>Additional PMIx notes can be found in the SchedMD\n<a href=\"publications.html\">Publications and Presentations</a> page.</p>\n\n<h3>Building Slurm with PMIx support</h3>\n\n<p>At configure time, Slurm looks by default for a PMIx installation under:</p>\n\n<pre>\n/usr\n/usr/local\n</pre>\n\n<p>If PMIx isn't installed in any of the previous locations, the Slurm configure\nscript can be requested to point to the non default location. Here's an example:\n</p>\n\n<pre>\nuser@testbox:~/slurm/17.11/testbox/slurm$ ../../slurm/configure \\\n&gt; --prefix=/home/user/slurm/17.11/testbox \\\n&gt; <b>--with-pmix=/home/user/git/pmix/install/2.1</b> \\\n&gt; --enable-multiple-slurmd\n</pre>\n\n<p>Or the analogous with RPM based building:</p>\n\n<pre>\n[user@testbox Downloads]$ rpmbuild \\\n&gt; --define '_prefix /home/user/slurm/17.11/testbox' \\\n&gt; --define '_slurm_sysconfdir /home/user/slurm/17.11/testbox/etc' \\\n&gt; --with multiple_slurmd \\\n&gt; <b>--define '_with_pmix --with-pmix=/home/user/git/pmix/install/2.1'</b> \\\n&gt; -ta slurm-17.11.1.tar.bz2\n</pre>\n\n<p>NOTE: It is also possible to build against multiple PMIx versions with a ':'\nseparator. For instance to build against 1.2 and 2.1:</p>\n\n<pre>\n...\n&gt; <b>--with-pmix=/path/to/pmix/install/1.2:/path/to/pmix/install/2.1</b> \\\n...\n</pre>\n\n<p>NOTE: When submitting a job, the desired version can then be selected using\nany of the available from --mpi=list. The default for pmix will be the highest\nversion of the library:</p>\n\n<pre>\nuser@testbox:~/t$ srun --mpi=list\nsrun: MPI types are...\nsrun: pmix_v1\nsrun: pmi2\nsrun: none\nsrun: pmix\nsrun: pmix_v2\n</pre>\n\n<p>NOTE: There is no need to configure Slurm with the multiple-slurmd option,\nbut if it is configured with it, additional steps will be required to make PMIx\nwork. That case is covered a few paragraphs below.\n</p>\n\n<p>Continuing with the configuration, if Slurm is unable to locate the PMIx\ninstallation and/or finds it but considers it not usable, the configure output\nshould log something like this:</p>\n\n<pre>\nchecking for pmix installation...\nconfigure: WARNING: unable to locate pmix installation\n</pre>\n\n<p>Otherwise, if Slurm finds it and considers it usable, something like this:\n</p>\n\n<pre>\nchecking for pmix installation... /home/user/git/pmix/install/2.1\n</pre>\n\n<p>Inspecting the generated config.log in the Slurm build directory might\nprovide even more detail for troubleshooting purposes. After configuration,\nwe can proceed to install Slurm (using make or rpm accordingly):</p>\n\n<pre>\nuser@testbox:~/slurm/17.11/testbox/slurm$ make -j install > /dev/null\nuser@testbox:~/slurm/17.11/testbox/slurm$ cd ../lib/slurm/\nuser@testbox:~/slurm/17.11/testbox/lib/slurm$ ls -l | grep pmix\nlrwxrwxrwx 1 user user       16 Dec  6 19:35 mpi_pmix.so -> ./mpi_pmix_v2.so\n-rw-r--r-- 1 user user  7008260 Dec  6 19:35 mpi_pmix_v2.a\n-rwxr-xr-x 1 user user     1040 Dec  6 19:35 mpi_pmix_v2.la\n-rwxr-xr-x 1 user user  1020112 Dec  6 19:35 mpi_pmix_v2.so\nuser@testbox:~/slurm/17.11/testbox/lib/slurm$\n</pre>\n\n<p>If support for PMI2 version is also needed, it can also be installed from\nthe contribs directory:</p>\n\n<pre>\nuser@testbox:~/slurm/17.11/testbox/lib/slurm$ cd ../../slurm/contribs/pmi2\nuser@testbox:~/slurm/17.11/testbox/slurm/contribs/pmi2$ make -j install\nuser@testbox:~/slurm/17.11/testbox/slurm/contribs/pmi2$ cd ../../../lib\nuser@testbox:~/slurm/17.11/testbox/lib$ ls -l | grep pmi\n-rw-r--r-- 1 user user   498144 Dec  6 20:05 libpmi2.a\n-rwxr-xr-x 1 user user      958 Dec  6 20:05 libpmi2.la\nlrwxrwxrwx 1 user user       16 Dec  6 20:05 libpmi2.so -> libpmi2.so.0.0.0\nlrwxrwxrwx 1 user user       16 Dec  6 20:05 libpmi2.so.0 -> libpmi2.so.0.0.0\n-rwxr-xr-x 1 user user   214512 Dec  6 20:05 libpmi2.so.0.0.0\n-rw-r--r-- 1 user user   414680 Dec  6 19:35 libpmi.a\n-rwxr-xr-x 1 user user     1011 Dec  6 19:35 libpmi.la\nlrwxrwxrwx 1 user user       15 Dec  6 19:35 libpmi.so -> libpmi.so.0.0.0\nlrwxrwxrwx 1 user user       15 Dec  6 19:35 libpmi.so.0 -> libpmi.so.0.0.0\n-rwxr-xr-x 1 user user   230552 Dec  6 19:35 libpmi.so.0.0.0\nuser@testbox:~/slurm/17.11/testbox/lib$\n</pre>\n\n<p>NOTE: Since both Slurm and PMIx provide libpmi[2].so libraries, we recommend\nto install both pieces of software in different locations. Otherwise, both\nlibraries provided by Slurm and PMIx might end up being installed under standard\nlocations like /usr/lib64 and the package manager erroring out and reporting\nthe conflict. It is planned to alleviate that by putting these libraries in a\nseparate libpmi-slurm package.</p>\n\n<p>NOTE: If support for multiple-slurmd is required, the TmpFS option in\nslurm.conf needs to be specified and as many directory paths as nodes be\ncreated. These directories are used by the Slurm PMIx plugin to create temporal\nfiles and/or UNIX sockets. Here's an example setup for two nodes named\ncompute[1-2]:\n</p>\n\n<pre>\nTmpFS=/home/user/slurm/17.11/testbox/spool/slurmd-tmpfs-%n\nuser@testbox:~/slurm/17.11/testbox$ mkdir spool/slurmd-tmpfs-compute1\nuser@testbox:~/slurm/17.11/testbox$ mkdir spool/slurmd-tmpfs-compute2\n</pre>\n\n<h3>Testing Slurm and PMIx</h3>\n\n<p>It is possible to directly test Slurm and PMIx without the need of a MPI\nimplementation software being installed. Here's an example indicating that\nboth components work properly:</p>\n\n<pre>\nuser@testbox:~/t$ srun --mpi=list\nsrun: MPI types are...\nsrun: pmi2\nsrun: none\nsrun: pmix\nsrun: pmix_v2\nuser@testbox:~/t$ srun --mpi=pmix -n2 -N2 \\\n&gt; ~/git/pmix/build/2.1/test/pmix_client -n 2 --job-fence -c\nOK\nOK\nuser@testbox:~/t$ srun --mpi=pmix_v2 -n2 -N2 \\\n&gt; ~/git/pmix/build/2.1/test/pmix_client -n 2 --job-fence -c\nOK\nOK\nuser@testbox:~/t$\n</pre>\n\n<h2><a name=\"open_mpi\" href=\"http://www.open-mpi.org/\"><b>OpenMPI</b></a></h2>\n\n<p>The current versions of Slurm and Open MPI support task launch using the\n<span class=\"commandline\">srun</span> command.\nIt relies upon Slurm managing reservations of communication ports for use by\nthe Open MPI version 1.5.</p>\n\n<p>If OpenMPI is configured with <i>--with-pmi</i> either pmi or pmi2,\nthe OMPI jobs can be launched directly using the srun command. This is\nthe preferred mode of operation. If the pmi2 support is enabled, the option\n'--mpi=pmi2' or '--mpi=pmi2_v2' must be specified on the srun command line.\nAlternately configure 'MpiDefault=pmi' or 'MpiDefault=pmi_v2' in slurm.conf.</p>\n\n<p>Starting with Open MPI version 3.1, PMIx version 2 is natively supported.\nTo launch Open MPI application using PMIx version 2 the '--mpi=pmix_v2' option\nmust be specified on the srun command line or 'MpiDefault=pmi_v2' configured\nin slurm.conf. Open MPI version 4.0, adds support for PMIx version 3 and is\ninvoked in the same way, with '--mpi=pmix_v3'.</p>\n\n<p>In Open MPI version 2.0, PMIx is natively supported too. To launch\nOpen MPI application using PMIx the '--mpi=pmix' or '--mpi=pmix_v1' option has\nto be specified on the srun command line. It is also possible to build OpenMPI\nusing an external PMIx installation. That option can take one of three values:\n\"internal\", \"external\", or a valid directory name. \"internal\" (or no DIR value)\nforces Open MPI to use its internal copy of PMIx. \"external\" forces Open MPI to\nuse an external installation of PMIx. Supplying a valid directory name also\nforces Open MPI to use an external installation of PMIx, and adds DIR/include,\nDIR/lib, and DIR/lib64 to the search path for headers and libraries.\nNote that Open MPI does not support --without-pmix. Note also that if building\nOpenMPI using an external PMIx installation, both OpenMPI and PMIx need to be\nbuilt against the same libevent/hwloc installations, otherwise a warning is\nshown. OpenMPI configure script provides the options <b>--with-libevent=PATH</b>\n and/or <b>--with-hwloc=PATH</b> to make OpenMPI match what PMIx was built\nagainst.</p>\n\n<p>A set of environment variables are available to control the behavior of Slurm\nPMIx plugin:\n<ul>\n<li><i>SLURM_PMIX_SRV_TMPDIR</i> base directory for PMIx/server service files.\n<li><i>SLURM_PMIX_TMPDIR</i> base directory for applications session\ndirectories.\n<li><i>SLURM_PMIX_DIRECT_CONN</i> (default - yes) enables (1/yes/true) or\ndisables (0/no/false) controls wheter direct connections between slurmstepd's\nare astablished or Slurm RPCs are used for data exchange. Direct connection\nshows better performanse for fully-packed nodes when PMIx is running in the\ndirect-modex mode.\n</ul>\n\n<p>For older versions of OMPI not compiled with the pmi support\nthe system administrator must specify the range of ports to be reserved\nin the <i>slurm.conf</i> file using the <i>MpiParams</i> parameter.\nFor example: MpiParams=ports=12000-12999\n\n<p>\nAlternatively tasks can be launched  using the srun command\nplus the option <i>--resv-ports</i> or using the environment\nvariable <i>SLURM_RESV_PORT</i>, which is equivalent to always including\n<i>--resv-ports</i> on srun's execute line.\n\nThe ports reserved on every allocated node will be identified in an\nenvironment variable available to the tasks as shown here:\nSLURM_STEP_RESV_PORTS=12000-12015<p>\n\n<pre>\n$ salloc -n4 sh   # allocates 4 processors and spawns shell for job\n&gt; srun a.out\n&gt; exit   # exits shell spawned by initial salloc command\n</pre>\n\n<p>or</p>\n\n<pre>\n&gt; srun -n 4 a.out\n</pre>\n\n<p>or using the pmi2 support</p>\n\n<pre>\n&gt; srun --mpi=pmi2 -n 4 a.out\n</pre>\n\n<p>or using the pmix support</p>\n\n<pre>\n&gt; srun --mpi=pmix -n 4 a.out\n</pre>\n\n<p>If the ports reserved for a job step are found by the Open MPI library\nto be in use, a message of this form will be printed and the job step\nwill be re-launched:<br>\n<i>srun: error: sun000: task 0 unble to claim reserved port, retrying</i><br>\nAfter three failed attempts, the job step will be aborted.\nRepeated failures should be reported to your system administrator in\norder to rectify the problem by cancelling the processes holding those\nports.</p>\n\n<p>NOTE: Some kernels and system configurations have resulted in a locked memory\ntoo small for proper OpemMPI functionality, resulting in application failure\nwith a segmentation fault. This may be fixed by configuring the slurmd daemon\nto execute with a larger limit. For example, add \"LimitMEMLOCK=infinity\" to\nyour slurmd.service file.</p>\n\n<hr size=4 width=\"100%\">\n\n<h2><a name=\"intel_mpi\"><b>Intel MPI</b></a></h2>\n\n<p>Intel&reg; MPI Library for Linux OS supports the following methods of\nlaunching the MPI jobs under the control of the Slurm job manager:</p>\n\n<li><a href=\"#intel_mpirun_mpd\">The <i>mpirun</i> command over the MPD Process Manager (PM)</a></li>\n<li><a href=\"#intel_mpirun_hydra\">The <i>mpirun</i> command over the Hydra PM</a></li>\n<li><a href=\"#intel_mpiexec_hydra\">The <i>mpiexec.hydra</i> command (Hydra PM)</a></li>\n<li><a href=\"#intel_srun\">The <i>srun</i> command (Slurm, recommended)</a></li>\n</ul>\n<p>This description provides detailed information on all of these methods.</p>\n\n<h3><a name=\"intel_mpirun_mpd\">The mpirun Command over the MPD Process Manager</a></h3>\n<p>Slurm is supported by the <i>mpirun</i> command of the Intel&reg; MPI Library 3.1\nBuild 029 for Linux OS and later releases.</p>\n<p>When launched within a session allocated using the Slurm commands <i>sbatch</i> or\n<i>salloc</i>, the <i>mpirun</i> command automatically detects and queries certain Slurm\nenvironment variables to obtain the list of the allocated cluster nodes.</p>\n<p>Use the following commands to start an MPI job within an existing Slurm\nsession over the MPD PM:</p>\n<pre>\n<i>export I_MPI_PROCESS_MANAGER=mpd\nmpirun -n &lt;num_procs&gt; a.out</i>\n</pre>\n\n<h3><a name=\"intel_mpirun_hydra\">The mpirun Command over the Hydra Process Manager</a></h3>\n<p>Slurm is supported by the <i>mpirun</i> command of the Intel&reg; MPI Library 4.0\nUpdate 3 through the Hydra PM by default. The behavior of this command is\nanalogous to the MPD case described above.</p>\n<p>Use the one of the following commands to start an MPI job within an existing\nSlurm session over the Hydra PM:</p>\n<pre>\n<i>mpirun -n &lt;num_procs&gt; a.out</i>\n</pre>\n<p>or</p>\n<pre>\n<i>mpirun -bootstrap slurm -n &lt;num_procs&gt; a.out</i>\n</pre>\n<p>We recommend that you use the second command. It uses the <i>srun</i> command\nrather than the default <i>ssh</i> based method to launch the remote Hydra PM\nservice processes.<p>\n\n<h3><a name=\"intel_mpiexec_hydra\">The mpiexec.hydra Command (Hydra Process Manager)</a></h3>\n<p>Slurm is supported by the Intel&reg; MPI Library 4.0 Update 3 directly\nthrough the Hydra PM.</p>\n<p>Use the following command to start an MPI job within an existing Slurm session:</p>\n<pre>\n<i>mpiexec.hydra -bootstrap slurm -n &lt;num_procs&gt; a.out</i>\n</pre>\n\n<h3><a name=\"intel_srun\">The srun Command (Slurm, recommended)</a></h3>\n<p>This advanced method is supported by the Intel&reg; MPI Library 4.0 Update 3.\nThis method is the best integrated with Slurm and supports process tracking,\naccounting, task affinity, suspend/resume and other features.\n Use the following commands to allocate a Slurm session and start an MPI job in\nit, or to start an MPI job within a Slurm session already created using the\n<i>sbatch</i> or <i>salloc</i> commands:</p>\n<ul>\n<li>Set the <i>I_MPI_PMI_LIBRARY</i> environment variable to point to the\nSlurm Process Management Interface (PMI) library:</li>\n<pre>\n<i>export I_MPI_PMI_LIBRARY=/path/to/slurm/pmi/library/libpmi.so</i>\n</pre>\n<p>NOTE: Due to licensing reasons IMPI doesn't link directly to any external\nPMI implementation. Instead one must point to the desired library just\nexporting the environment variable mentioned above, which will then be dlopened\nby IMPI. Also, there is no official support provided by Intel against PMIx\nlibraries. Since IMPI is based on MPICH, using PMIx with Intel may work due\nPMIx mantaining compatibility with pmi and pmi2, which are the ones used in\nMPICH, but it is not guaranteed to run in all cases.\n</p>\n<li>Use the <i>srun</i> command to launch the MPI job:</li>\n<pre>\n<i>srun -n &lt;num_procs&gt; a.out</i>\n</pre>\n</ul>\n\n<p>Above information used by permission from <a href=\"http://www.intel.com\">Intel</a>.\nFor more information see\n<a href=\"https://software.intel.com/en-us/intel-mpi-library\">Intel MPI Library</a>.\n\n<h2><a name=\"mpich2\" href=\"https://www.mpich.org/\"><b>MPICH (a.k.a. MPICH2)</b></a></h2>\n\n<p>MPICH2 jobs can be launched using the <b>srun</b> command using\n  pmi 1 or 2, or <b>mpiexec</b>.\nAll modes of operation are described below.</p>\n\n<h3>MPICH2 with srun and PMI version 2</h3>\n\n<p>MPICH2 must be built specifically for use with Slurm and PMI2 using a configure\nline similar to that shown below.</p>\n<pre>\n./configure --with-slurm=&lt;PATH&gt; --with-pmi=pmi2\n</pre>\n<p>\nThe PATH must point to the Slurm installation directory, in other words the parent\ndirectory of bin and lib.\nIn addition, if Slurm is not configured with <i>MpiDefault=pmi2</i>, then\nthe srun command must be invoked with the option <i>--mpi=pmi2</i> as shown\nin the example below below.</p>\n<pre>\nsrun -n4 --mpi=pmi2 ./a.out\n</pre>\n\n<p>\nThe PMI2 support in Slurm works only if the MPI implementation supports it, in other words if the MPI has\nthe PMI2 interface implemented. The <i>--mpi=pmi2</i> will load the  library <i>lib/slurm/mpi_pmi2.so</i>\nwhich provides the server side functionality but the client side must implement <i>PMI2_Init()</i>\nand the other interface calls.<br>\n\n<p>\nThis does require that the MPICH intallation have been installed with the <i>--with-pmi=pmi2</i> configure option.<br>\n\n<p>\nTo check if the MPI version you are using supports PMI2 check for PMI2_* symbols in the MPI library.\n<p>\nSlurm provides a version of the PMI2 client library in the contribs directory. This library gets\ninstalled in the Slurm lib directory. If your MPI implementation supports PMI2 and you wish to use\nthe Slurm provided library you have to link the Slurm provided library explicitly:\n<pre>\n$ mpicc -L&lt;path_to_pmi2_lib&gt; -lpmi2 ...\n$ srun -n20 a.out\n</pre>\n\n<h3>MPICH2 with srun and PMI version 1</h3>\n\n<p>Link your program with\nSlurm's implementation of the PMI library so that tasks can communicate\nhost and port information at startup. (The system administrator can add\nthese option to the mpicc and mpif77 commands directly, so the user will not\nneed to bother). For example:\n<pre>\n$ mpicc -L&lt;path_to_slurm_lib&gt; -lpmi ...\n$ srun -n20 a.out\n</pre>\n<b>NOTES:</b>\n<ul>\n<li>Some MPICH2 functions are not currently supported by the PMI\nlibrary integrated with Slurm</li>\n<li>Set the environment variable <b>PMI_DEBUG</b> to a numeric value\nof 1 or higher for the PMI library to print debugging information.\nUse srun's -l option for better clarity.</li>\n<li>Set the environment variable <b>SLURM_PMI_KVS_NO_DUP_KEYS</b> for\nimproved performance with MPICH2 by eliminating a test for duplicate keys.</li>\n<li>The environment variables can be used to tune performance depending upon\nnetwork performance: <b>PMI_FANOUT</b>, <b>PMI_FANOUT_OFF_HOST</b>, and\n<b>PMI_TIME</b>.\nSee the srun man pages in the INPUT ENVIRONMENT VARIABLES section for a more\ninformation.</li>\n<li>Information about building MPICH2 for use with Slurm is described on the\n<a href=\"http://wiki.mcs.anl.gov/mpich2/index.php/Frequently_Asked_Questions#Q:_How_do_I_use_MPICH2_with_slurm.3F\">\nMPICH2 FAQ</a> web page and below.</li>\n</ul></p>\n\n<h3>MPICH2 with mpiexec</h3>\n\n<p>Do not add any flags to mpich and build the default\n(e.g. \"<i>./configure -prefix ... </i>\".\nDo NOT pass the --with-slurm, --with-pmi, --enable-pmiport options).<br>\nDo not add -lpmi to your application (it will force slurm's pmi 1\ninterface which doesn't support PMI_Spawn_multiple).<br>\nLaunch the application using salloc to create the job allocation and mpiexec\nto launch the tasks. A simple example is shown below.</p>\n<pre>salloc -N 2 mpiexec my_application</pre>\n<p>All MPI_comm_spawn work fine now going through hydra's PMI 1.1 interface.</p>\n\n<hr size=4 width=\"100%\">\n\n<h2><a name=\"mvapich2\" href=\"http://mvapich.cse.ohio-state.edu/\"><b>MVAPICH (a.k.a. MVAPICH2)</b></a></h2>\n\n<p>MVAPICH2 supports launching multithreaded programs by Slurm as well as\nmpirun_rsh.\nPlease note that if you intend to use use srun, you need to build MVAPICH2\nwith Slurm support with a command line of this sort:</p>\n<pre>\n$ ./configure --with-pmi=pmi2 --with-pm=slurm\n</pre>\n\n<p>Use of Slurm's <i>pmi2</i> plugin provides substantially higher performance and\nscalability than Slurm's <i>pmi</i> plugin.\nIf <i>pmi2</i> is not configured to be Slurm's default MPI plugin at your site,\nthis can be specified using the srun command's \"--mpi-pmi2\" option as shown\nbelow or with the environment variable setting of \"SLURM_MPI_TYPE=pmi2\".</p>\n<pre>\n$ srun -n16 --mpi=pmi2 a.out\n</pre>\n\n<p>MVAPICH2 can be built using the following options:<br>\n--with-pmi=pmi2 \\<br>\n--with-pm=slurm \\<br>\n--with-slurm=&lt;install directory&gt; \\<br>\n--enable-slurm=yes</p>\n\n<p>For more information, please see the\n<a href=\"http://mvapich.cse.ohio-state.edu/static/media/mvapich/mvapich2-2.0-userguide.html\">MVAPICH2 User Guide</a></p>\n\n<hr size=4 width=\"100%\">\n\n<h2><a name=\"UPC\" href=\"http://upc.lbl.gov/\"><b>UPC (Unified Parallel C)</b></a></h2>\n\n<p>Berkeley UPC (and likely other UPC implementations) rely upon Slurm to\nallocate resources and launch the application's tasks. The UPC library then\nread. Slurm environment variables in order to determine how the job's task\ncount and location. One would build the UPC program in the normal manner\nthen initiate it using a command line of this sort:</p>\n<pre>\n$ srun -N4 -n16 a.out\n</pre>\n\n<hr size=4 width=\"100%\">\n\n<p style=\"text-align:center;\">Last modified 18 December 2019</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/route_plugin.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Slurm Route Plugin Programmer Guide</a></h1>\n\n<h2> Overview</h2>\n<p> This document describes Slurm Route plugin and the API that\ndefines them.\nIt is intended as a resource to programmers wishing to write their own\nSlurm Route plugin.</p>\n\n<p>Slurm Route plugins are Slurm plugins that redirect RPCs through\nintermediate forwarding nodes. The routing mechanism is similar\nto message forwarding which was designed to move message processing overhead\noff the controller. The main difference is that the routine table is\ndefined in the configuration. For example,\nthe topology implementation uses the topology.conf file.</p>\n\n<p>The plugins must conform to the Slurm Plugin API with the following\nspecifications:</p>\n\n<p><span class=\"commandline\">const char plugin_type[]</span><br>\nThe major type must be &quot;rout&quot;\nThe minor type specifies the type of route mechanism.\n</p>\n<ul>\n<li><b>default</b> &mdash; No routing information.</li>\n<li><b>topology</b> &mdash; Route messages using topology.conf information.</li>\n</ul></p>\n\n<p><span class=\"commandline\">const char plugin_name[]</span><br>\nSome descriptive name for the plugin.\nThere is no requirement with respect to its format.</p>\n<p><span class=\"commandline\">uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loaded by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<h2>Data Objects</h2>\n<p>The implementation must maintain (though not necessarily directly export) an\nenumerated <span class=\"commandline\">errno</span> to allow Slurm to discover\nas practically as possible the reason for any failed API call.\nPlugin-specific enumerated integer values may be used when appropriate.\n\n<p>These values must not be used as return values in integer-valued\nfunctions in the API.\nThe proper error return value from integer-valued functions is SLURM_ERROR.\nThe implementation should endeavor to provide useful and pertinent\ninformation by whatever means is practical.\nSuccessful API calls are not required to reset any errno to a known value.\nHowever, the initial value of any errno, prior to any error condition\narising, should be SLURM_SUCCESS. </p>\n\n<h2>API Functions</h2>\n<p>The following functions must appear.\nFunctions which are not implemented should be stubbed.</p>\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n\n<p class=\"commandline\">\nextern int route_g_split_hostlist(hostlist_t hl,\n\t\t\t\t     hostlist_t** sp_hl,\n\t\t\t\t     int* count);\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nSplit an input hostlist into a set of hostlists to forward to.\n\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">hl (in) hostlist to split</span>\n<span class=\"commandline\">sp_hl (out) the array of hostlist that will be\nmalloced</span>\n<span class=\"commandline\">count (out) the count of created hostlist</span>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nextern int route_g_reconfigure ( void );\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nReset internal state during reconfigure.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nextern slurm_addr_t* route_g_next_collector ( bool *is_collector );\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nget address of parent in message tree.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">is_collector (out) flag indication this node\nis a collector.\n</span>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">slurm_addr_t*</span>\naddress of node to send messages to be aggregated <br>\n<span class=\"commandline\">NULL</span> if not set.\n\n<p class=\"commandline\">\nextern slurm_addr_t* route_g_next_collector_backup ( void );\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nget address of parent's backup in message tree.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">slurm_addr_t*</span>\naddress of node to send messages to be aggregated when primary collector\nis down. <br>\n<span class=\"commandline\">NULL</span> if not set.\n\n\n<p style=\"text-align:center;\">Last modified 27 March 2015</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/job_submit_plugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Job Submit Plugin API</a></h1>\n\n<h2> Overview</h2>\n<p> This document describes Slurm job submit plugins and the API that\ndefines them. It is intended as a resource to programmers wishing to write\ntheir own Slurm job submit plugins. This is version 100 of the API.</p>\n\n<p>Slurm job submit plugins must conform to the\nSlurm Plugin API with the following specifications:</p>\n\n<p><span class=\"commandline\">const char\nplugin_name[]=\"<i>full&nbsp;text&nbsp;name</i>\"</span>\n<p style=\"margin-left:.2in\">\nA free-formatted ASCII text string that identifies the plugin.\n\n<p><span class=\"commandline\">const char\nplugin_type[]=\"<i>major/minor</i>\"</span><br>\n<p style=\"margin-left:.2in\">\nThe major type must be &quot;job_submit.&quot;\nThe minor type can be any suitable name for the type of job submission package.\nWe include samples in the Slurm distribution for\n<ul>\n<li><b>all_partitions</b> &mdash; Set default partition to all partitions on\nthe cluster.</li>\n<li><b>defaults</b> &mdash; Set default values for job submission or modify\nrequests.</li>\n<li><b>logging</b> &mdash; Log select job submission and modification\nparameters.</li>\n<li><b>lua</b> &mdash; Interface to <a href=\"http://www.lua.org\">Lua</a> scripts\nimplementing these functions (actually a slight variation of them). Sample Lua\nscripts can be found with the Slurm distribution in the directory\n<i>contribs/lua</i>. The default installation location of the Lua scripts is\nthe same location as the Slurm configuration file, <i>slurm.conf</i>.</li>\n<li><b>partition</b> &mdash; Sets a job's default partition based upon job\nsubmission parameters and available partitions.</li>\n</ul>\n\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loaded by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<p>Slurm can be configured to use multiple job_submit plugins if desired,\nhowever the lua plugin will only execute one lua script named \"job_submit.lua\"\nlocated in the default script directory (typically the subdirectory \"etc\" of\nthe installation directory).</p>\n\n\n<h2>API Functions</h2>\n<p>All of the following functions are required. Functions which are not\nimplemented must be stubbed.\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\">\nint job_submit(struct job_descriptor *job_desc, uint32_t submit_uid, char **error_msg)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nThis function is called by the slurmctld daemon with job submission parameters\nsupplied by the salloc, sbatch or srun command. It can be used to log and/or\nmodify the job parameters supplied by the user as desired. Note that this\nfunction has access to the slurmctld's global data structures, for example\nto examine the available partitions, reservations, etc.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job_desc</span>\n(input/output) the job allocation request specifications.<br>\n<span class=\"commandline\">submit_uid</span>\n(input) user ID initiating the request.<br>\n<span class=\"commandline\">error_msg</span>\n(output) If the argument is not null, then a plugin generated error message\ncan be stored here. The error message is expected to have allocated memory\nwhich Slurm will release using the xfree function. The error message is always\npropagated to the caller, no matter the return code.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint job_modify(struct job_descriptor *job_desc, job_record_t *job_ptr, uint32_t modify_uid)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nThis function is called by the slurmctld daemon with job modification parameters\nsupplied by the scontrol or sview command. It can be used to log and/or\nmodify the job parameters supplied by the user as desired. Note that this\nfunction has access to the slurmctld's global data structures, for example to\nexamine the available partitions, reservations, etc.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job_desc</span>\n(input/output) the job allocation request specifications.<br>\n<span class=\"commandline\">job_ptr</span>\n(input/output) slurmctld daemon's current data structure for the job to\nbe modified.<br>\n<span class=\"commandline\">modify_uid</span>\n(input) user ID initiating the request.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<h2>Lua Functions</h2>\n<p>The Lua functions differ slightly from those implemented in C for\nbetter ease of use. Sample Lua scripts can be found with the Slurm distribution\nin the directory <i>contribs/lua</i>. The default installation location of\nthe Lua scripts is the same location as the Slurm configuration file,\n<i>slurm.conf</i>.\nReading and writing of job environment variables using Lua is possible\nby referencing the environment variables as a data structure containing\nnamed elements. For example:<br>\nif (job_desc.environment.LANGUAGE == \"en_US\") then<br>\n....</p>\n\n\n<p class=\"commandline\">\nint slurm_job_submit(job_desc_msg_t *job_desc, List part_list, uint32_t\nsubmit_uid)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nThis function is called by the slurmctld daemon with job submission parameters\nsupplied by the salloc, sbatch or srun command. It can be used to log and/or\nmodify the job parameters supplied by the user as desired. Note that this\nfunction has access to the slurmctld's global data structures, for example\nto examine the available partitions, reservations, etc.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job_desc</span>\n(input/output) the job allocation request specifications.<br>\n<span class=\"commandline\">part_list</span>\n(input) List of pointer to partitions which this user is authorized to use.<br>\n<span class=\"commandline\">submit_uid</span>\n(input) user ID initiating the request.<br>\n<a name=\"job_modify_returns\"></a><p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">slurm.SUCCESS</span> &mdash;\nJob submission accepted by plugin.<br>\n<span class=\"commandline\">slurm.FAILURE</span> &mdash;\nJob submission rejected due to error (Deprecated in 19.05).<br>\n<span class=\"commandline\">slurm.ERROR</span> &mdash;\nJob submission rejected due to error.<br>\n<span class=\"commandline\">slurm.ESLURM_ACCESS_DENIED</span> &mdash;\nJob submission rejected due to access denied.<br>\n<span class=\"commandline\">slurm.ESLURM_ACCOUNTING_POLICY</span> &mdash;\nJob submission rejected due to accounting policy.<br>\n<span class=\"commandline\">slurm.ESLURM_INVALID_ACCOUNT</span> &mdash;\nJob submission rejected due to invalid account.<br>\n<span class=\"commandline\">slurm.ESLURM_INVALID_LICENSES</span> &mdash;\nJob submission rejected due to access licenses.<br>\n<span class=\"commandline\">slurm.ESLURM_INVALID_TIME_LIMIT</span> &mdash;\nJob submission rejected due to invalid time limit.<br>\n<span class=\"commandline\">slurm.ESLURM_JOB_MISSING_SIZE_SPECIFICATION</span> &mdash;\nJob submission rejected due to missing size specification.<br>\n<span class=\"commandline\">slurm.ESLURM_MISSING_TIME_LIMIT</span> &mdash;\nJob submission rejected due to missing time limit.<br>\n\n<p class=\"commandline\">\nint slurm_job_modify(job_desc_msg_t *job_desc, job_record_t *job_ptr,\nList part_list, int modify_uid)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nThis function is called by the slurmctld daemon with job modification parameters\nsupplied by the scontrol or sview command. It can be used to log and/or\nmodify the job parameters supplied by the user as desired. Note that this\nfunction has access to the slurmctld's global data structures, for example to\nexamine the available partitions, reservations, etc.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job_desc</span>\n(input/output) the job allocation request specifications.<br>\n<span class=\"commandline\">job_ptr</span>\n(input/output) slurmctld daemon's current data structure for the job to\nbe modified.<br>\n<span class=\"commandline\">part_list</span>\n(input) List of pointer to partitions which this user is authorized to use.<br>\n<span class=\"commandline\">modify_uid</span>\n(input) user ID initiating the request.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<a href=\"#job_modify_returns\">Returns from job_modify() are the same as the returns from job_submit().</a>\n\n<h2>Lua Job Attributes</h2>\n<p>The available job attributes change occasionally with different versions of\nSlurm. To find the job attributes that are available for the version of Slurm\nyou're using, go to the <a href=\"https://github.com/SchedMD/slurm\"> SchedMD\ngithub page</a>, and navigate to\n<b>src/plugins/job_submit/lua/job_submit_lua.c</b>.\n<b>_job_rec_field()</b> contains the list of attributes available for the\njob_record (e.g. current record in Slurm). <b>_get_job_req_field()</b> contains\nthe list of attributes available for the job_descriptor (e.g. submission or\nmodification request).\n</p>\n\n<h2>Building</h2>\n<p>Generally using a LUA interface for a job submit plugin is best:\nIt is simple to write and maintain with minimal dependencies upon the Slurm\ndata structures.\nHowever using C does provide a mechanism to get more information than available\nusing LUA including full access to all of the data structures and functions\nin the slurmctld daemon.\nThe simplest way to build a C program would be to just replace one of the\njob submit plugins included in the Slurm distribution with your own code\n(i.e. use a patch with your own code).\nThen just build and install Slurm with that new code.\nBuilding a new plugin outside of the Slurm distribution is possible, but\nfar more complex.\nIt also requires access to a multitude of Slurm header files as shown in the\nprocedure below.</p>\n\n<a name=\"job_modify_manualbuild\">\n<ol>\n<li>You will need to at least partly build Slurm first. The \"configure\" command\nmust be executed in order to build the \"config.h\" file in the build directory.</li>\n\n<li>Create a local directory somewhere for your files to build with.\nAlso create subdirectories named \".libs\" and \".deps\".</li>\n\n<li>Copy a \".deps/job_submit_*Plo\" file from another job_submit plugin's \".deps\"\ndirectory (made as part of the build process) into your local \".deps\" subdirectory.\nRename the file as appropriate to reflect your plugins name (e.g. rename\n\"job_submit_partition.Plo\" to be something like \"job_submit_mine.Plo\").</li>\n\n<li>Compile and link your plugin. Those options might differ depending\nupon your build environment. Check the options used for building the\nother job_submit plugins and modify the example below as required.</li>\n\n<li>Install the plugin.</li>\n</ol>\n\n<pre>\n# Example:\n# The Slurm source is in ~/SLURM/slurm.git\n# The Slurm build directory is ~/SLURM/slurm.build\n# The plugin build is to take place in the directory\n#   \"~/SLURM/my_submit\"\n# The installation location is \"/usr/local\"\n\n# Build Slurm from ~/SLURM/slurm.build\n# (or at least run \"~/SLURM/slurm.git/configure\")\n\n# Set up your plugin files\ncd ~/SLURM\nmkdir my_submit\ncd my_submit\nmkdir .libs\nmkdir .deps\n# Create your plugin code\nvi job_submit_mine.c\n\n# Copy up a dependency file\ncp ~/SLURM/slurm.build/src/plugins/job_submit/partition/.deps/job_submit_partition.Plo \\\n   .deps/job_submit_mine.Plo\n\n# Compile\ngcc -DHAVE_CONFIG_H -I~/SLURM/slurm.build -I~/slurm.git \\\n   -g -O2 -pthread -fno-gcse -Werror -Wall -g -O0       \\\n   -fno-strict-aliasing -MT job_submit_mine.lo          \\\n   -MD -MP -MF .deps/job_submit_mine.Tpo                \\\n   -c job_submit_mine.c -o .libs/job_submit_mine.o\n\n# Some clean up\nmv -f .deps/job_submit_mine.Tpo .deps/job_submit_mine.Plo\nrm -fr .libs/job_submit_mine.a .libs/job_submit_mine.la \\\n   .libs/job_submit_mine.lai job_submit_mine.so\n\n# Link\ngcc -shared -fPIC -DPIC .libs/job_submit_mine.o -O2         \\\n   -pthread -O0 -pthread -Wl,-soname -Wl,job_submit_mine.so \\\n   -o job_submit_mine.so\n\n# Install\ncp job_submit_mine.so file \\\n   /usr/local/lib/slurm/job_submit_mine.so\n</pre>\n\n<p style=\"text-align:center;\">Last modified 18 December 2019</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/faq.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Frequently Asked Questions</a></h1>\n\n<h2>For Management</h2>\n<ul>\n<li><a href=\"#foss\">Why should I use Slurm or other Free Open Source Software (FOSS)?</a></li>\n</ul>\n\n<h2>For Users</h2>\n<ul>\n<li><a href=\"#comp\">Why is my job/node in a COMPLETING state?</a></li>\n<li><a href=\"#rlimit\">Why are my resource limits not propagated?</a></li>\n<li><a href=\"#pending\">Why is my job not running?</a></li>\n<li><a href=\"#sharing\">Why does the srun --overcommit option not permit\n  multiple jobs to run on nodes?</a></li>\n<li><a href=\"#purge\">Why is my job killed prematurely?</a></li>\n<li><a href=\"#opts\">Why are my srun options ignored?</a></li>\n<li><a href=\"#backfill\">Why is the Slurm backfill scheduler not starting my\n  job?</a></li>\n<li><a href=\"#steps\">How can I run multiple jobs from within a single\n  script?</a></li>\n<li><a href=\"#multi_batch\">How can I run a job within an existing job\n  allocation?</a></li>\n<li><a href=\"#user_env\">How does Slurm establish the environment for my\n  job?</a></li>\n<li><a href=\"#prompt\">How can I get shell prompts in interactive mode?</a></li>\n<li><a href=\"#batch_out\">How can I get the task ID in the output or error file\n  name for a batch job?</a></li>\n<li><a href=\"#parallel_make\">Can the <i>make</i> command utilize the resources\n  allocated to a Slurm job?</a></li>\n<li><a href=\"#terminal\">Can tasks be launched with a remote (pseudo)\n  terminal?</a></li>\n<li><a href=\"#force\">What does &quot;srun: Force Terminated job&quot;\n  indicate?</a></li>\n<li><a href=\"#early_exit\">What does this mean: &quot;srun: First task exited\n  30s ago&quot; followed by &quot;srun Job Failed&quot;?</a></li>\n<li><a href=\"#memlock\">Why is my MPI job  failing due to the locked memory\n  (memlock) limit being too low?</a></li>\n<li><a href=\"#inactive\">Why is my batch job that launches no job steps being\n  killed?</a></li>\n<li><a href=\"#arbitrary\">How do I run specific tasks on certain nodes\n  in my allocation?</a></li>\n<li><a href=\"#hold\">How can I temporarily prevent a job from running\n  (e.g. place it into a <i>hold</i> state)?</a></li>\n<li><a href=\"#mem_limit\">Why are jobs not getting the appropriate\n  memory limit?</a></li>\n<li><a href=\"#mailing_list\">Is an archive available of messages posted to\n  the <i>slurm-users</i> mailing list?</a></li>\n<li><a href=\"#job_size\">Can I change my job's size after it has started\n  running?</a></li>\n<li><a href=\"#mpi_symbols\">Why is my MPICH2 or MVAPICH2 job not running with\n  Slurm? Why does the DAKOTA program not run with Slurm?</a></li>\n<li><a href=\"#estimated_start_time\">Why does squeue (and \"scontrol show\n  jobid\") sometimes not display a job's estimated start time?</a></li>\n<li><a href=\"#ansys\">How can I run an Ansys program with Slurm?</a></li>\n<li><a href=\"#req\">How can a job in a complete or failed state be requeued?</a></li>\n<li><a href=\"#cpu_count\">Slurm documentation refers to CPUs, cores and threads.\n  What exactly is considered a CPU?</a></li>\n<li><a href=\"#sbatch_srun\">What is the difference between the sbatch\n  and srun commands?</a></li>\n<li><a href=\"#squeue_color\">Can squeue output be color coded?</a></li>\n<li><a href=\"#x11\">Can Slurm export an X11 display on an allocated compute node?</a></li>\n<li><a href=\"#unbuffered_cr\">Why is the srun --u/--unbuffered option adding\n   a carriage return to my output?</a></li>\n<li><a href=\"#sview_colors\">Why is sview not coloring/highlighting nodes\n    properly?</a></li>\n</ul>\n\n<h2>For Administrators</h2>\n<ul>\n<li><a href=\"#suspend\">How is job suspend/resume useful?</a></li>\n<li><a href=\"#return_to_service\">Why is a node shown in state DOWN when the node\n  has registered for service?</a></li>\n<li><a href=\"#down_node\">What happens when a node crashes?</a></li>\n<li><a href=\"#multi_job\">How can I control the execution of multiple\n  jobs per node?</a></li>\n<li><a href=\"#inc_plugin\">When the Slurm daemon starts, it prints\n  &quot;cannot resolve X plugin operations&quot; and exits. What does this mean?</a></li>\n<li><a href=\"#pam_exclude\">How can I exclude some users from pam_slurm?</a></li>\n<li><a href=\"#maint_time\">How can I dry up the workload for a maintenance\n  period?</a></li>\n<li><a href=\"#pam\">How can PAM be used to control a user's limits on or\n  access to compute nodes?</a></li>\n<li><a href=\"#time\">Why are jobs allocated nodes and then unable to initiate\n  programs on some nodes?</a></li>\n<li><a href=\"#ping\"> Why does <i>slurmctld</i> log that some nodes\n  are not responding even if they are not in any partition?</a></li>\n<li><a href=\"#controller\"> How should I relocate the primary or backup\n  controller?</a></li>\n<li><a href=\"#multi_slurm\">Can multiple Slurm systems be run in\n  parallel for testing purposes?</a></li>\n<li><a href=\"#multi_slurmd\">Can Slurm emulate a larger cluster?</a></li>\n<li><a href=\"#extra_procs\">Can Slurm emulate nodes with more\n  resources than physically exist on the node?</a></li>\n<li><a href=\"#credential_replayed\">What does a\n  &quot;credential replayed&quot; error in the <i>SlurmdLogFile</i>\n  indicate?</a></li>\n<li><a href=\"#large_time\">What does\n  &quot;Warning: Note very large processing time&quot;\n  in the <i>SlurmctldLogFile</i> indicate?</a></li>\n<li><a href=\"#limit_propagation\">Is resource limit propagation\n  useful on a homogeneous cluster?</a></li>\n<li><a href=\"#clock\">Do I need to maintain synchronized clocks\n  on the cluster?</a></li>\n<li><a href=\"#cred_invalid\">Why are &quot;Invalid job credential&quot; errors\n  generated?</a></li>\n<li><a href=\"#cred_replay\">Why are\n  &quot;Task launch failed on node ... Job credential replayed&quot;\n  errors generated?</a></li>\n<li><a href=\"#globus\">Can Slurm be used with Globus?</a></li>\n<li><a href=\"#file_limit\">What causes the error\n  &quot;Unable to accept new connection: Too many open files&quot;?</a></li>\n<li><a href=\"#slurmd_log\">Why does the setting of <i>SlurmdDebug</i> fail\n  to log job step information at the appropriate level?</a></li>\n<li><a href=\"#rpm\">Why aren't pam_slurm.so, auth_none.so, or other components in a\n  Slurm RPM?</a></li>\n<li><a href=\"#slurmdbd\">Why should I use the slurmdbd instead of the\n  regular database plugins?</a></li>\n<li><a href=\"#debug\">How can I build Slurm with debugging symbols?</a></li>\n<li><a href=\"#state_preserve\">How can I easily preserve drained node\n  information between major Slurm updates?</a></li>\n<li><a href=\"#health_check\">Why doesn't the <i>HealthCheckProgram</i>\n  execute on DOWN nodes?</a></li>\n<li><a href=\"#batch_lost\">What is the meaning of the error\n  &quot;Batch JobId=# missing from batch node &lt;node&gt; (not found\n  BatchStartTime after startup)&quot;?</a></li>\n<li><a href=\"#accept_again\">What does the message\n  &quot;srun: error: Unable to accept connection: Resources temporarily unavailable&quot;\n  indicate?</a></li>\n<li><a href=\"#task_prolog\">How could I automatically print a job's\n  Slurm job ID to its standard output?</a></li>\n<li><a href=\"#orphan_procs\">Why are user processes and <i>srun</i>\n  running even though the job is supposed to be completed?</a></li>\n<li><a href=\"#slurmd_oom\">How can I prevent the <i>slurmd</i> and\n  <i>slurmstepd</i> daemons from being killed when a node's memory\n  is exhausted?</a></li>\n<li><a href=\"#ubuntu\">I see the host of my calling node as 127.0.1.1\n  instead of the correct IP address.  Why is that?</a></li>\n<li><a href=\"#stop_sched\">How can I stop Slurm from scheduling jobs?</a></li>\n<li><a href=\"#scontrol_multi_jobs\">Can I update multiple jobs with a single\n<i>scontrol</i> command?</a></li>\n<li><a href=\"#amazon_ec2\">Can Slurm be used to run jobs on Amazon's EC2?</a></li>\n<li><a href=\"#core_dump\">If a Slurm daemon core dumps, where can I find the\n  core file?</a></li>\n<li><a href=\"#totalview\">How can TotalView be configured to operate with\n  Slurm?</a></li>\n<li><a href=\"#git_patch\">How can a patch file be generated from a Slurm commit\n  in GitHub?</a></li>\n<li><a href=\"#enforce_limits\">Why are the resource limits set in the database\n  not being enforced?</a></li>\n<li><a href=\"#restore_priority\">After manually setting a job priority value,\n  how can its priority value be returned to being managed by the\n  priority/multifactor plugin?</a></li>\n<li><a href=\"#health_check_example\">Does anyone have an example node health check\nscript for Slurm?</a></li>\n<li><a href=\"#add_nodes\">What process should I follow to add nodes to Slurm?</a></li>\n<li><a href=\"#licenses\">Can Slurm be configured to manage licenses?</a></li>\n<li><a href=\"#salloc_default_command\">Can the salloc command be configured to\n  launch a shell on a node in the job's allocation?</a></li>\n<li><a href=\"#upgrade\">What should I be aware of when upgrading Slurm?</a></li>\n<li><a href=\"#torque\">How easy is it to switch from PBS or Torque to Slurm?</a></li>\n<li><a href=\"#sssd\">How can I get SSSD to work with Slurm?</a></li>\n<li><a href=\"#ha_db\">How critical is configuring high availability for my\n  database?</a></li>\n<li><a href=\"#sql\">How can I use double quotes in MySQL queries?</a></li>\n<li><a href=\"#reboot\">Why is a compute node down with the reason set to\n\"Node unexpectedly rebooted\"?</a></li>\n<li><a href=\"#reqspec\">How can a job which has exited with a specific exit code\n   be requeued?</a></li>\n<li><a href=\"#user_account\">Can a user's account be changed in the database?</a></li>\n<li><a href=\"#mpi_perf\">What might account for MPI performance being below the\n   expected level?</a></li>\n<li><a href=\"#state_info\">How could some jobs submitted immediately before the\n   slurmctld daemon crashed be lost?</a></li>\n<li><a href=\"#delete_partition\">How do I safely remove partitions?</a></li>\n<li><a href=\"#cpu_freq\">Why is Slurm unable to set the CPU frequency for jobs?</a></li>\n<li><a href=\"#cluster_acct\">When adding a new cluster, how can the Slurm cluster\n    configuration be copied from an existing cluster to the new cluster?</a></li>\n<li><a href=\"#cray_dvs\">How can I update Slurm on a Cray DVS file system without\n    rebooting the nodes?</a></li>\n<li><a href=\"#dbd_rebuild\">How can I rebuild the database hierarchy?</a></li>\n<li><a href=\"#routing queue\">How can a routing queue be configured?</a></li>\n<li><a href=\"#squeue_script\">How can I suspend, resume, hold or release all\n    of the jobs belonging to a specific user, partition, etc?</a></li>\n<li><a href=\"#changed_uid\">I had to change a user's UID and now they cannot submit\n    jobs. How do I get the new UID to take effect?</a></li>\n<li><a href=\"#mysql_duplicate\">Slurmdbd is failing to start with a 'Duplicate entry'\n    error in the database. How do I fix that?</a></li>\n<li><a href=\"#cray_sigbus\">Why are applications on my Cray system failing\n    with SIGBUS (bus error)?</a></li>\n<li><a href=\"#sysv_memory\">How do I configure Slurm to work with System V IPC\n    enabled applications?</a></li>\n</ul>\n\n<h2>For Management</h2>\n<p><a name=\"foss\"><b>Why should I use Slurm or other Free Open Source Software (FOSS)?</b></a><br>\nFree Open Source Software (FOSS) does not mean that it is without cost.\nIt does mean that the you have access to the code so that you are free to\nuse it, study it, and/or enhance it.\nThese reasons contribute to Slurm (and FOSS in general) being subject to\nactive research and development worldwide, displacing proprietary software\nin many environments.\nIf the software is large and complex, like Slurm or the Linux kernel,\nthen while there is no license fee, its use is not without cost.</p>\n<p>If your work is important, you'll want the leading Slurm experts at your\ndisposal to keep your systems operating at peak efficiency.\nWhile Slurm has a global development community incorporating leading edge\ntechnology, <a href=\"https://www.schedmd.com\">SchedMD</a> personnel have developed\nmost of the code and can provide competitively priced commercial support.\nSchedMD works with various organizations to provide a range of support\noptions ranging from remote level-3 support to 24x7 on-site personnel.\nCustomers switching from commercial workload mangers to Slurm typically\nreport higher scalability, better performance and lower costs.</p>\n\n<h2>For Users</h2>\n<p><a name=\"comp\"><b>Why is my job/node in a COMPLETING state?</b></a><br>\nWhen a job is terminating, both the job and its nodes enter the COMPLETING state.\nAs the Slurm daemon on each node determines that all processes associated with\nthe job have terminated, that node changes state to IDLE or some other appropriate\nstate for use by other jobs.\nWhen every node allocated to a job has determined that all processes associated\nwith it have terminated, the job changes state to COMPLETED or some other\nappropriate state (e.g. FAILED).\nNormally, this happens within a second.\nHowever, if the job has processes that cannot be terminated with a SIGKILL\nsignal, the job and one or more nodes can remain in the COMPLETING state\nfor an extended period of time.\nThis may be indicative of processes hung waiting for a core file\nto complete I/O or operating system failure.\nIf this state persists, the system administrator should check for processes\nassociated with the job that cannot be terminated then use the\n<span class=\"commandline\">scontrol</span> command to change the node's\nstate to DOWN (e.g. &quot;scontrol update NodeName=<i>name</i> State=DOWN Reason=hung_completing&quot;),\nreboot the node, then reset the node's state to IDLE\n(e.g. &quot;scontrol update NodeName=<i>name</i> State=RESUME&quot;).\nNote that setting the node DOWN will terminate all running or suspended\njobs associated with that node.\nAn alternative is to set the node's state to DRAIN until all jobs\nassociated with it terminate before setting it DOWN and re-booting.</p>\n<p>Note that Slurm has two configuration parameters that may be used to\nautomate some of this process.\n<i>UnkillableStepProgram</i> specifies a program to execute when\nnon-killable processes are identified.\n<i>UnkillableStepTimeout</i> specifies how long to wait for processes\nto terminate.\nSee the \"man slurm.conf\" for more information about these parameters.</p>\n\n<p><a name=\"rlimit\"><b>Why are my resource limits not propagated?</b></a><br>\nWhen the <span class=\"commandline\">srun</span> command executes, it captures the\nresource limits in effect at submit time on the node where srun executes.\nThese limits are propagated to the allocated nodes before initiating the\nuser's job.\nThe Slurm daemons running on the allocated nodes then try to establish\nidentical resource limits for the job being initiated.\nThere are several possible reasons for not being able to establish those\nresource limits.\n<ul>\n<li>The hard resource limits applied to Slurm's slurmd daemon are lower\nthan the user's soft resources limits on the submit host. Typically\nthe slurmd daemon is initiated by the init daemon with the operating\nsystem default limits. This may be addressed either through use of the\nulimit command in the /etc/sysconfig/slurm file or enabling\n<a href=\"#pam\">PAM in Slurm</a>.</li>\n<li>The user's hard resource limits on the allocated node are lower than\nthe same user's soft hard resource limits on the node from which the\njob was submitted. It is recommended that the system administrator\nestablish uniform hard resource limits for users on all nodes\nwithin a cluster to prevent this from occurring.</li>\n<li>PropagateResourceLimits or PropagateResourceLimitsExcept parameters are\nconfigured in slurm.conf and avoid propagation of specified limits.</li>\n</ul>\n</p>\n<p>NOTE: This may produce the error message &quot;Can't propagate RLIMIT_...&quot;.\nThe error message is printed only if the user explicitly specifies that\nthe resource limit should be propagated or the srun command is running\nwith verbose logging of actions from the slurmd daemon (e.g. \"srun -d6 ...\").</p>\n\n<p><a name=\"pending\"><b>Why is my job not running?</b></a><br>\nThe answer to this question depends on a lot of factors. The main one is which\nscheduler is used by Slurm. Executing the command</p>\n<blockquote>\n<p> <span class=\"commandline\">scontrol show config | grep SchedulerType</span></p>\n</blockquote>\n<p> will supply this information. If the scheduler type is <b>builtin</b>, then\njobs will be executed in the order of submission for a given partition. Even if\nresources are available to initiate your job immediately, it will be deferred\nuntil no previously submitted job is pending. If the scheduler type is <b>backfill</b>,\nthen jobs will generally be executed in the order of submission for a given partition\nwith one exception: later submitted jobs will be initiated early if doing so does\nnot delay the expected execution time of an earlier submitted job. In order for\nbackfill scheduling to be effective, users' jobs should specify reasonable time\nlimits. If jobs do not specify time limits, then all jobs will receive the same\ntime limit (that associated with the partition), and the ability to backfill schedule\njobs will be limited. The backfill scheduler does not alter job specifications\nof required or excluded nodes, so jobs which specify nodes will substantially\nreduce the effectiveness of backfill scheduling. See the <a href=\"#backfill\">\nbackfill</a> section for more details. For any scheduler, you can check priorities\nof jobs using the command <span class=\"commandline\">scontrol show job</span>.\nOther reasons can include waiting for resources, memory, qos, reservations, etc.\nAs a guideline, issue an <span class=\"commandline\">scontrol show job &lt;jobid&gt;</span>\nand look at the field <i>State</i> and <i>Reason</i> to investigate the cause.</p></p>\n\n<p><a name=\"sharing\"><b>Why does the srun --overcommit option not permit multiple jobs\nto run on nodes?</b></a><br>\nThe <b>--overcommit</b> option is a means of indicating that a job or job step is willing\nto execute more than one task per processor in the job's allocation. For example,\nconsider a cluster of two processor nodes. The srun execute line may be something\nof this sort</p>\n<blockquote>\n<p><span class=\"commandline\">srun --ntasks=4 --nodes=1 a.out</span></p>\n</blockquote>\n<p>This will result in not one, but two nodes being allocated so that each of the four\ntasks is given its own processor. Note that the srun <b>--nodes</b> option specifies\na minimum node count and optionally a maximum node count. A command line of</p>\n<blockquote>\n<p><span class=\"commandline\">srun --ntasks=4 --nodes=1-1 a.out</span></p>\n</blockquote>\n<p>would result in the request being rejected. If the <b>--overcommit</b> option\nis added to either command line, then only one node will be allocated for all\nfour tasks to use.</p>\n<p>More than one job can execute simultaneously on the same compute resource\n(e.g. CPU) through the use of srun's <b>--oversubscribe</b> option in\nconjunction with the <b>OverSubscribe</b> parameter in Slurm's partition\nconfiguration. See the man pages for srun and slurm.conf for more information.</p>\n\n<p><a name=\"purge\"><b>Why is my job killed prematurely?</b></a><br>\nSlurm has a job purging mechanism to remove inactive jobs (resource allocations)\nbefore reaching its time limit, which could be infinite.\nThis inactivity time limit is configurable by the system administrator.\nYou can check its value with the command</p>\n<blockquote>\n<p><span class=\"commandline\">scontrol show config | grep InactiveLimit</span></p>\n</blockquote>\n<p>The value of InactiveLimit is in seconds.\nA zero value indicates that job purging is disabled.\nA job is considered inactive if it has no active job steps or if the srun\ncommand creating the job is not responding.\nIn the case of a batch job, the srun command terminates after the job script\nis submitted.\nTherefore batch job pre- and post-processing is limited to the InactiveLimit.\nContact your system administrator if you believe the InactiveLimit value\nshould be changed.\n\n<p><a name=\"opts\"><b>Why are my srun options ignored?</b></a><br>\nEverything after the command <span class=\"commandline\">srun</span> is\nexamined to determine if it is a valid option for srun. The first\ntoken that is not a valid option for srun is considered the command\nto execute and everything after that is treated as an option to\nthe command. For example:</p>\n<blockquote>\n<p><span class=\"commandline\">srun -N2 hostname -pdebug</span></p>\n</blockquote>\n<p>srun processes \"-N2\" as an option to itself. \"hostname\" is the\ncommand to execute and \"-pdebug\" is treated as an option to the\nhostname command. This will change the name of the computer\non which Slurm executes the command - Very bad, <b>Don't run\nthis command as user root!</b></p>\n\n<p><a name=\"backfill\"><b>Why is the Slurm backfill scheduler not starting my job?\n</b></a><br>\nThe most common problem is failing to set job time limits. If all jobs have\nthe same time limit (for example the partition's time limit), then backfill\nwill not be effective. Note that partitions can have both default and maximum\ntime limits, which can be helpful in configuring a system for effective\nbackfill scheduling.</p>\n\n<p>In addition, there are a multitude of backfill scheduling parameters\nwhich can impact which jobs are considered for backfill scheduling, such\nas the maximum number of jobs tested per user. For more information see\nthe slurm.conf man page and check the configuration of SchedulingParameters\non your system.</p>\n\n<p><a name=\"steps\"><b>How can I run multiple jobs from within a\nsingle script?</b></a><br>\nA Slurm job is just a resource allocation. You can execute many\njob steps within that allocation, either in parallel or sequentially.\nSome jobs actually launch thousands of job steps this way. The job\nsteps will be allocated nodes that are not already allocated to\nother job steps. This essentially provides a second level of resource\nmanagement within the job for the job steps.</p>\n\n<p><a name=\"multi_batch\"><b>How can I run a job within an existing\njob allocation?</b></a><br>\nThere is an srun option <i>--jobid</i> that can be used to specify\na job's ID.\nFor a batch job or within an existing resource allocation, the\nenvironment variable <i>SLURM_JOB_ID</i> has already been defined,\nso all job steps will run within that job allocation unless\notherwise specified.\nThe one exception to this is when submitting batch jobs.\nWhen a batch job is submitted from within an existing batch job,\nit is treated as a new job allocation request and will get a\nnew job ID unless explicitly set with the <i>--jobid</i> option.\nIf you specify that a batch job should use an existing allocation,\nthat job allocation will be released upon the termination of\nthat batch job.</p>\n\n<p><a name=\"user_env\"><b>How does Slurm establish the environment\nfor my job?</b></a><br>\nSlurm processes are not run under a shell, but directly exec'ed\nby the <i>slurmd</i> daemon (assuming <i>srun</i> is used to launch\nthe processes).\nThe environment variables in effect at the time the <i>srun</i> command\nis executed are propagated to the spawned processes.\nThe <i>~/.profile</i> and <i>~/.bashrc</i> scripts are not executed\nas part of the process launch. You can also look at the <i>--export</i> option of\nsrun and sbatch. See man pages for details.</p>\n\n<p><a name=\"prompt\"><b>How can I get shell prompts in interactive\nmode?</b></a><br>\n<i>srun --pty bash -i</i><br/>\nSrun's <i>--pty</i> option runs task zero in pseudo terminal mode.\nBash's <i>-i</i> option tells it to run in interactive mode (with prompts).\n<br/>You can also configure <i>SallocDefaultCommand</i> in <i>slurm.conf</i>\nto automatically launch a shell, e.g.:\n<pre>\nSallocDefaultCommand=\"srun -n1 -N1 --mem-per-cpu=0 --pty --preserve-env --cpu-bind=no --mpi=none $SHELL\"\n</pre>\n<p>And then run <i>salloc</i> directly which will provide you an allocation with\nan interactive shell console.</p>\n\n<p><a name=\"batch_out\"><b>How can I get the task ID in the output\nor error file name for a batch job?</b></a><br>\nIf you want separate output by task, you will need to build a script\ncontaining this specification. For example:</p>\n<pre>\n$ cat test\n#!/bin/sh\necho begin_test\nsrun -o out_%j_%t hostname\n\n$ sbatch -n7 -o out_%j test\nsbatch: Submitted batch job 65541\n\n$ ls -l out*\n-rw-rw-r--  1 jette jette 11 Jun 15 09:15 out_65541\n-rw-rw-r--  1 jette jette  6 Jun 15 09:15 out_65541_0\n-rw-rw-r--  1 jette jette  6 Jun 15 09:15 out_65541_1\n-rw-rw-r--  1 jette jette  6 Jun 15 09:15 out_65541_2\n-rw-rw-r--  1 jette jette  6 Jun 15 09:15 out_65541_3\n-rw-rw-r--  1 jette jette  6 Jun 15 09:15 out_65541_4\n-rw-rw-r--  1 jette jette  6 Jun 15 09:15 out_65541_5\n-rw-rw-r--  1 jette jette  6 Jun 15 09:15 out_65541_6\n\n$ cat out_65541\nbegin_test\n\n$ cat out_65541_2\ntdev2\n</pre>\n\n<p><a name=\"parallel_make\"><b>Can the <i>make</i> command\nutilize the resources allocated to a Slurm job?</b></a><br>\nYes. There is a patch available for GNU make version 3.81\navailable as part of the Slurm distribution in the file\n<i>contribs/make-3.81.slurm.patch</i>.  For GNU make version 4.0 you\ncan use the patch in the file <i>contribs/make-4.0.slurm.patch</i>.\nThis patch will use Slurm to launch tasks across a job's current resource\nallocation. Depending upon the size of modules to be compiled, this may\nor may not improve performance. If most modules are thousands of lines\nlong, the use of additional resources should more than compensate for the\noverhead of Slurm's task launch. Use with make's <i>-j</i> option within an\nexisting Slurm allocation. Outside of a Slurm allocation, make's behavior\nwill be unchanged.</p>\n\n<p><a name=\"terminal\"><b>Can tasks be launched with a remote (pseudo)\nterminal?</b></a><br>\nYou have several ways to do so, the recommended ones are the following:<br>\nThe simplest method is to make use of srun's <i>--pty</i> option,\n(e.g. <i>srun --pty bash -i</i>).\nSrun's <i>--pty</i> option runs task zero in pseudo terminal mode. Bash's\n<i>-i</i> option instructs it to run in interactive mode (with prompts).<br>\nIn addition to that method you have the option to define the\n<i>SallocDefaultCommand</i> to run a task in pseudo terminal mode directly,\nso you get the prompt just invoking salloc:\n<pre>SallocDefaultCommand=\"srun -n1 -N1 --mem-per-cpu=0 --pty --preserve-env --cpu-bind=no --mpi=none $SHELL\"</pre>\n<p>Finally you can make use of X11 feature and run a graphical terminal.\n(e.g. <i>srun xterm</i>).</p>\n\n<p><a name=\"force\"><b>What does &quot;srun: Force Terminated job&quot;\nindicate?</b></a><br>\nThe srun command normally terminates when the standard output and\nerror I/O from the spawned tasks end. This does not necessarily\nhappen at the same time that a job step is terminated. For example,\na file system problem could render a spawned task non-killable\nat the same time that I/O to srun is pending. Alternately a network\nproblem could prevent the I/O from being transmitted to srun.\nIn any event, the srun command is notified when a job step is\nterminated, either upon reaching its time limit or being explicitly\nkilled. If the srun has not already terminated, the message\n&quot;srun: Force Terminated job&quot; is printed.\nIf the job step's I/O does not terminate in a timely fashion\nthereafter, pending I/O is abandoned and the srun command\nexits.</p>\n\n<p><a name=\"early_exit\"><b>What does this mean:\n&quot;srun: First task exited 30s ago&quot;\nfollowed by &quot;srun Job Failed&quot;?</b></a><br>\nThe srun command monitors when tasks exit. By default, 30 seconds\nafter the first task exists, the job is killed.\nThis typically indicates some type of job failure and continuing\nto execute a parallel job when one of the tasks has exited is\nnot normally productive. This behavior can be changed using srun's\n<i>--wait=&lt;time&gt;</i> option to either change the timeout\nperiod or disable the timeout altogether. See srun's man page\nfor details.</p>\n\n<p><a name=\"memlock\"><b>Why is my MPI job  failing due to the\nlocked memory (memlock) limit being too low?</b></a><br>\nBy default, Slurm propagates all of your resource limits at the\ntime of job submission to the spawned tasks.\nThis can be disabled by specifically excluding the propagation of\nspecific limits in the <i>slurm.conf</i> file. For example\n<i>PropagateResourceLimitsExcept=MEMLOCK</i> might be used to\nprevent the propagation of a user's locked memory limit from a\nlogin node to a dedicated node used for his parallel job.\nIf the user's resource limit is not propagated, the limit in\neffect for the <i>slurmd</i> daemon will be used for the spawned job.\nA simple way to control this is to ensure that user <i>root</i> has a\nsufficiently large resource limit and ensuring that <i>slurmd</i> takes\nfull advantage of this limit. For example, you can set user root's\nlocked memory limit ulimit to be unlimited on the compute nodes (see\n<i>\"man limits.conf\"</i>) and ensuring that <i>slurmd</i> takes\nfull advantage of this limit (e.g. by adding <i>\"LimitMEMLOCK=infinity\"</i>\nto your systemd's <i>slurmd.service</i> file). It may also be desirable to lock\nthe slurmd daemon's memory to help ensure that it keeps responding if memory\nswapping begins. A sample <i>/etc/sysconfig/slurm</i> which can be read from\nsystemd is shown below.\nRelated information about <a href=\"#pam\">PAM</a> is also available.</p>\n<pre>\n#\n# Example /etc/sysconfig/slurm\n#\n# Memlocks the slurmd process's memory so that if a node\n# starts swapping, the slurmd will continue to respond\nSLURMD_OPTIONS=\"-M\"\n</pre>\n\n<p><a name=\"inactive\"><b>Why is my batch job that launches no\njob steps being killed?</b></a><br>\nSlurm has a configuration parameter <i>InactiveLimit</i> intended\nto kill jobs that do not spawn any job steps for a configurable\nperiod of time. Your system administrator may modify the <i>InactiveLimit</i>\nto satisfy your needs. Alternately, you can just spawn a job step\nat the beginning of your script to execute in the background. It\nwill be purged when your script exits or your job otherwise terminates.\nA line of this sort near the beginning of your script should suffice:<br>\n<i>srun -N1 -n1 sleep 999999 &</i></p>\n\n<p><a name=\"arbitrary\"><b>How do I run specific tasks on certain nodes\nin my allocation?</b></a><br>\nOne of the distribution methods for srun '<b>-m</b>\nor <b>--distribution</b>' is 'arbitrary'.  This means you can tell Slurm to\nlayout your tasks in any fashion you want.  For instance if I had an\nallocation of 2 nodes and wanted to run 4 tasks on the first node and\n1 task on the second and my nodes allocated from SLURM_JOB_NODELIST\nwhere tux[0-1] my srun line would look like this:<br><br>\n<i>srun -n5 -m arbitrary -w tux[0,0,0,0,1] hostname</i><br><br>\nIf I wanted something similar but wanted the third task to be on tux 1\nI could run this:<br><br>\n<i>srun -n5 -m arbitrary -w tux[0,0,1,0,0] hostname</i><br><br>\nHere is a simple Perl script named arbitrary.pl that can be ran to easily lay\nout tasks on nodes as they are in SLURM_JOB_NODELIST.</p>\n<pre>\n#!/usr/bin/perl\nmy @tasks = split(',', $ARGV[0]);\nmy @nodes = `scontrol show hostnames $SLURM_JOB_NODELIST`;\nmy $node_cnt = $#nodes + 1;\nmy $task_cnt = $#tasks + 1;\n\nif ($node_cnt < $task_cnt) {\n\tprint STDERR \"ERROR: You only have $node_cnt nodes, but requested layout on $task_cnt nodes.\\n\";\n\t$task_cnt = $node_cnt;\n}\n\nmy $cnt = 0;\nmy $layout;\nforeach my $task (@tasks) {\n\tmy $node = $nodes[$cnt];\n\tlast if !$node;\n\tchomp($node);\n\tfor(my $i=0; $i < $task; $i++) {\n\t\t$layout .= \",\" if $layout;\n\t\t$layout .= \"$node\";\n\t}\n\t$cnt++;\n}\nprint $layout;\n</pre>\n\n<p>We can now use this script in our srun line in this fashion.<br><br>\n<i>srun -m arbitrary -n5 -w `arbitrary.pl 4,1` -l hostname</i><br><br>\n<p>This will layout 4 tasks on the first node in the allocation and 1\ntask on the second node.</p>\n\n<p><a name=\"hold\"><b>How can I temporarily prevent a job from running\n(e.g. place it into a <i>hold</i> state)?</b></a><br>\nThe easiest way to do this is to change a job's earliest begin time\n(optionally set at job submit time using the <i>--begin</i> option).\nThe example below places a job into hold state (preventing its initiation\nfor 30 days) and later permitting it to start now.</p>\n<pre>\n$ scontrol update JobId=1234 StartTime=now+30days\n... later ...\n$ scontrol update JobId=1234 StartTime=now\n</pre>\n\n<p><a name=\"mem_limit\"><b>Why are jobs not getting the appropriate\nmemory limit?</b></a><br>\nThis is probably a variation on the <a href=\"#memlock\">locked memory limit</a>\nproblem described above.\nUse the same solution for the AS (Address Space), RSS (Resident Set Size),\nor other limits as needed.</p>\n\n<p><a name=\"mailing_list\"><b>Is an archive available of messages posted to\nthe <i>slurm-users</i> mailing list?</b></a><br>\nYes, it is at <a href=\"http://groups.google.com/group/slurm-users\">\nhttp://groups.google.com/group/slurm-users</a></p>\n\n<p><a name=\"job_size\"><b>Can I change my job's size after it has started\nrunning?</b></a><br>\nSlurm supports the ability to both increase and decrease the size of jobs.\nWhile the size of a pending job may be changed with few restrictions, several\nsignificant restrictions apply to changing the size of a running job, as noted\nbelow:\n<ol>\n<li>Requesting fewer hardware resources, and changing partition, qos,\nreservation, licenses, etc. is only allowed for pending jobs.</li>\n<li>Job(s) changing size must not be in a suspended state, including jobs\nsuspended for gang scheduling. The jobs must be in a state of pending or\nrunning.</li>\n<li>Job expansion for running jobs is disabled by default.\nSite administrators can enable this capability by setting\n<i>SchedulerParameters=permit_job_expansion</i> in <i>slurm.conf</i></li>\n</ol>\n</p>\n\n<p>Use the <i>scontrol</i> command to change a job's size either by specifying\na new node count (<i>NumNodes=</i>) for the job or identify the specific nodes\n(<i>NodeList=</i>) that you want the job to retain.\nAny job steps running on the nodes which are relinquished by the job will be\nkilled unless initiated with the <i>--no-kill</i> option.\nAfter the job size is changed, some environment variables created by Slurm\ncontaining information about the job's environment will no longer be valid and\nshould either be removed or altered (e.g. SLURM_JOB_NODES, SLURM_JOB_NODELIST and\nSLURM_NTASKS).\nThe <i>scontrol</i> command will generate a script that can be executed to\nreset local environment variables.\nYou must retain the SLURM_JOB_ID environment variable in order for the\n<i>srun</i> command to gather information about the job's current state and\nspecify the desired node and/or task count in subsequent <i>srun</i> invocations.\nA new accounting record is generated when a job is resized, showing the job to\nhave been resubmitted and restarted at the new size.\nAn example is shown below.</p>\n<pre>\n#!/bin/bash\nsrun my_big_job\nscontrol update JobId=$SLURM_JOB_ID NumNodes=2\n. slurm_job_${SLURM_JOB_ID}_resize.sh\nsrun -N2 my_small_job\nrm slurm_job_${SLURM_JOB_ID}_resize.*\n</pre>\n\n<p><b>Increasing a job's size</b><br>\nDirectly increasing the size of a running job would adversely affect the\nscheduling of pending jobs.\nFor the sake of fairness in job scheduling, expanding a running job requires\nthe user to submit a new job, but specify the option\n<i>--dependency=expand:&lt;jobid&gt;</i>.\nThis option tells Slurm that the job, when scheduled, can be used to expand\nthe specified jobid.\nOther job options would be used to identify the required resources\n(e.g. task count, node count, node features, etc.).\nThis new job's time limit will be automatically set to reflect the end time of\nthe job being expanded.\nThis new job's generic resources specification will be automatically set\nequal to that of the job being merged to. This is due to the current Slurm\nrestriction of all nodes associated with a job needing to have the same\ngeneric resource specification (i.e. a job can not have one GPU on one\nnode and two GPUs on another node), although this restriction may be removed\nin the future. This restriction can pose some problems when both jobs can be\nallocated resources on the same node, in which case the generic resources\nallocated to the new job will be released. If the jobs are allocated resources\non different nodes, the generic resources associated with the resulting job\nallocation after the merge will be consistent as expected.\nAny licenses associated with the new job will be added to those available in\nthe job being merged to.\nNote that partition and Quality Of Service (QOS) limits will be applied\nindependently to the new job allocation so the expanded job may exceed size\nlimits configured for an individual job.</p>\n\n<p>After the new job is allocated resources, merge that job's allocation\ninto that of the original job by executing:<br>\n<i>scontrol update jobid=&lt;jobid&gt; NumNodes=0</i><br>\nThe <i>jobid</i> above is that of the job to relinquish its resources.\nTo provide more control over when the job expansion occurs, the resources are\nnot merged into the original job until explicitly requested.\nThese resources will be transferred to the original job and the scontrol\ncommand will generate a script to reset variables in the second\njob's environment to reflect its modified resource allocation (which would\nbe no resources).\nOne would normally exit this second job at this point, since it has no\nassociated resources.\nIn order to generate a script to modify the environment variables for the\nexpanded job, execute:<br>\n<i>scontrol update jobid=&lt;jobid&gt; NumNodes=ALL</i><br>\nThen execute the script generated.\nNote that this command does not change the original job's size, but only\ngenerates the script to change its environment variables.\nUntil the environment variables are modified (e.g. the job's node count,\nCPU count, hostlist, etc.), any srun command will only consider the resources\nin the original resource allocation.\nNote that the original job may have active job steps at the time of its\nexpansion, but they will not be affected by the change.\nAn example of the procedure is shown below in which the original job\nallocation waits until the second resource allocation request can be\nsatisfied. The job requesting additional resources could also use the sbatch\ncommand and permit the original job to continue execution at its initial size.\nNote that the development of additional user tools to manage Slurm resource\nallocations is planned in the future to make this process both simpler and\nmore flexible.</p>\n\n<pre>\n$ salloc -N4 -C haswell bash\nsalloc: Granted job allocation 65542\n$ srun hostname\nicrm1\nicrm2\nicrm3\nicrm4\n\n$ salloc -N4 -C knl,snc4,flat --dependency=expand:$SLURM_JOB_ID bash\nsalloc: Granted job allocation 65543\n$ scontrol update jobid=$SLURM_JOB_ID NumNodes=0\nTo reset Slurm environment variables, execute\n  For bash or sh shells:  . ./slurm_job_65543_resize.sh\n  For csh shells:         source ./slurm_job_65543_resize.csh\n$ exit\nexit\nsalloc: Relinquishing job allocation 65543\n\n$ scontrol update jobid=$SLURM_JOB_ID NumNodes=ALL\nTo reset Slurm environment variables, execute\n  For bash or sh shells:  . ./slurm_job_65542_resize.sh\n  For csh shells:         source ./slurm_job_65542_resize.csh\n$ . ./slurm_job_${SLURM_JOB_ID}_resize.sh\n\n$ srun hostname\nicrm1\nicrm2\nicrm3\nicrm4\nicrm5\nicrm6\nicrm7\nicrm8\n$ exit\nexit\nsalloc: Relinquishing job allocation 65542\n</pre>\n\n<p><a name=\"mpi_symbols\"><b>Why is my MPICH2 or MVAPICH2 job not running with\nSlurm? Why does the DAKOTA program not run with Slurm?</b></a><br>\nThe Slurm library used to support MPICH2 or MVAPICH2 references a variety of\nsymbols. If those symbols resolve to functions or variables in your program\nrather than the appropriate library, the application will fail. For example\n<a href=\"http://dakota.sandia.gov\">DAKOTA</a>, versions 5.1 and\nolder, contains a function named regcomp, which will get used rather\nthan the POSIX regex functions. Rename DAKOTA's function and\nreferences from regcomp to something else to make it work properly.</p>\n\n<p><a name=\"estimated_start_time\"><b>Why does squeue (and \"scontrol show\njobid\") sometimes not display a job's  estimated start time?</b></a><br>\nWhen the backfill scheduler is configured, it provides an estimated start time\nfor jobs that are candidates for backfill. Pending jobs with dependencies\nwill not have an estimate as it is difficult to predict what resources will\nbe available when the jobs they are dependent on terminate. Also note that\nthe estimate is better for jobs expected to start soon, as most running jobs\nend before their estimated time. There are other restrictions on backfill that\nmay apply. See the <a href=\"#backfill\">backfill</a> section for more details.\n</p>\n\n<p><a name=\"ansys\"><b>How can I run an Ansys program with Slurm?</b></a><br>\nIf you are talking about an interactive run of the Ansys app, then you can use\nthis simple script (it is for Ansys Fluent):</p>\n<pre>\n$ cat ./fluent-srun.sh\n#!/usr/bin/env bash\nHOSTSFILE=.hostlist-job$SLURM_JOB_ID\nif [ \"$SLURM_PROCID\" == \"0\" ]; then\n   srun hostname -f > $HOSTSFILE\n   fluent -t $SLURM_NTASKS -cnf=$HOSTSFILE -ssh 3d\n   rm -f $HOSTSFILE\nfi\nexit 0\n</pre>\n\n<p>To run an interactive session, use srun like this:</p>\n<pre>\n$ srun -n &lt;tasks&gt; ./fluent-srun.sh\n</pre>\n\n<p><a name=\"req\"><b>How can a job in a complete or failed state be requeued?</b></a>\n<br>\n<p>\nSlurm supports requeueing jobs in a done or failed state. Use the\ncommand:</p>\n<p align=left><b>scontrol requeue job_id</b></p>\n</head>\n<p>The job will then be requeued back in the PENDING state and scheduled again.\nSee man(1) scontrol.\n</p>\n<p>Consider a simple job like this:</p>\n<pre>\n$cat zoppo\n#!/bin/sh\necho \"hello, world\"\nexit 10\n\n$sbatch -o here ./zoppo\nSubmitted batch job 10\n</pre>\n<p>\nThe job finishes in FAILED state because it exits with\na non zero value. We can requeue the job back to\nthe PENDING state and the job will be dispatched again.\n</p>\n<pre>\n$ scontrol requeue 10\n$ squeue\n     JOBID PARTITION  NAME     USER   ST   TIME  NODES NODELIST(REASON)\n      10      mira    zoppo    david  PD   0:00    1   (NonZeroExitCode)\n$ squeue\n    JOBID PARTITION   NAME     USER ST     TIME  NODES NODELIST(REASON)\n      10      mira    zoppo    david  R    0:03    1      alanz1\n</pre>\n<p>Slurm supports requeuing jobs in a hold state with the command:</p>\n<p align=left><b>'scontrol requeuehold job_id'</b></p>\n<p>The job can be in state RUNNING, SUSPENDED, COMPLETED or FAILED\nbefore being requeued.</p>\n<pre>\n$ scontrol requeuehold 10\n$ squeue\n    JOBID PARTITION  NAME     USER ST       TIME  NODES NODELIST(REASON)\n    10      mira    zoppo    david PD       0:00      1 (JobHeldUser)\n</pre>\n\n</p>\n\n<p><a name=\"cpu_count\"><b>Slurm documentation refers to CPUs, cores and threads.\nWhat exactly is considered a CPU?</b></a><br>\nIf your nodes are configured with hyperthreading, then a CPU is equivalent\nto a hyperthread.\nOtherwise a CPU is equivalent to a core.\nYou can determine if your nodes have more than one thread per core\nusing the command \"scontrol show node\" and looking at the values of\n\"ThreadsPerCore\".</p>\n<p>Note that even on systems with hyperthreading enabled, the resources will\ngenerally be allocated to jobs at the level of a core (see NOTE below).\nTwo different jobs will not share a core except through the use of a partition\nOverSubscribe configuration parameter.\nFor example, a job requesting resources for three tasks on a node with\nThreadsPerCore=2 will be allocated two full cores.\nNote that Slurm commands contain a multitude of options to control\nresource allocation with respect to base boards, sockets, cores and threads.</p>\n<p>(<b>NOTE:</b> An exception to this would be if the system administrator\nconfigured SelectTypeParameters=CR_CPU and each node's CPU count without its\nsocket/core/thread specification. In that case, each thread would be\nindependently scheduled as a CPU. This is not a typical configuration.)</p>\n\n<p><a name=\"sbatch_srun\"><b>What is the difference between the sbatch\n  and srun commands?</b></a><br>\nThe srun command has two different modes of operation. First, if not run within\nan existing job (i.e. not within a Slurm job allocation created by salloc or\nsbatch), then it will create a job allocation and spawn an application.\nIf run within an existing allocation, the srun command only spawns the\napplication.\nFor this question, we will only address the first mode of operation and compare\ncreating a job allocation using the sbatch and srun commands.</p>\n\n<p>The srun command is designed for interactive use, with someone monitoring\nthe output.\nThe output of the application is seen as output of the srun command,\ntypically at the user's terminal.\nThe sbatch command is designed to submit a script for later execution and its\noutput is written to a file.\nCommand options used in the job allocation are almost identical.\nThe most noticeable difference in options is that the sbatch command supports\nthe concept of <a href=\"job_array.html\">job arrays</a>, while srun does not.\nAnother significant difference is in fault tolerance.\nFailures involving sbatch jobs typically result in the job being requeued\nand executed again, while failures involving srun typically result in an\nerror message being generated with the expectation that the user will respond\nin an appropriate fashion.</p>\n\n<p><a name=\"squeue_color\"><b>Can squeue output be color coded?</b></a><br>\nThe squeue command output is not color coded, but other tools can be used to\nadd color. One such tool is ColorWrapper\n(<a href=\"https://github.com/rrthomas/cw\">https://github.com/rrthomas/cw</a>).\nA sample ColorWrapper configuration file and output are shown below.</p>\n<pre>\npath /bin:/usr/bin:/sbin:/usr/sbin:&lt;env&gt;\nusepty\nbase green+\nmatch red:default (Resources)\nmatch black:default (null)\nmatch black:cyan N/A\nregex cyan:default  PD .*$\nregex red:default ^\\d*\\s*C .*$\nregex red:default ^\\d*\\s*CG .*$\nregex red:default ^\\d*\\s*NF .*$\nregex white:default ^JOBID.*\n</pre>\n<img src=\"squeue_color.png\" width=600>\n\n<p><a name=\"x11\"><b>Can Slurm export an X11 display on an allocated compute node?</b></a><br/>\nYou can use the X11 builtin feature starting at version 17.11.\nIt is enabled by setting <i>PrologFlags=x11</i> in <i>slurm.conf</i>.\nOther X11 plugins must be deactivated.\n<br/>\nRun it as shown:\n</p>\n<pre>\n$ ssh -X user@login1\n$ srun -n1 --pty --x11 xclock\n</pre>\n<p>\nAn alternative for older versions is to build and install an optional SPANK\nplugin for that functionality. Instructions to build and install the plugin\nfollow. This SPANK plugin will not work if used in combination with native X11\nsupport so you must disable it compiling Slurm with <i>--disable-x11</i>. This\nplugin relies on openssh library and it provides features such as GSSAPI\nsupport.<br/> Update the Slurm installation path as needed:</p>\n<pre>\n# It may be obvious, but don't forget the -X on ssh\n$ ssh -X alex@testserver.com\n\n# Get the plugin\n$ mkdir git\n$ cd git\n$ git clone https://github.com/hautreux/slurm-spank-x11.git\n$ cd slurm-spank-x11\n\n# Manually edit the X11_LIBEXEC_PROG macro definition\n$ vi slurm-spank-x11.c\n$ vi slurm-spank-x11-plug.c\n$ grep \"define X11_\" slurm-spank-x11.c\n#define X11_LIBEXEC_PROG \"/opt/slurm/17.02/libexec/slurm-spank-x11\"\n$ grep \"define X11_LIBEXEC_PROG\" slurm-spank-x11-plug.c\n#define X11_LIBEXEC_PROG \"/opt/slurm/17.02/libexec/slurm-spank-x11\"\n\n\n# Compile\n$ gcc -g -o slurm-spank-x11 slurm-spank-x11.c\n$ gcc -g -I/opt/slurm/17.02/include -shared -fPIC -o x11.so slurm-spank-x11-plug.c\n\n# Install\n$ mkdir -p /opt/slurm/17.02/libexec\n$ install -m 755 slurm-spank-x11 /opt/slurm/17.02/libexec\n$ install -m 755 x11.so /opt/slurm/17.02/lib/slurm\n\n# Configure\n$ echo -e \"optional x11.so\" >> /opt/slurm/17.02/etc/plugstack.conf\n$ cd ~/tests\n\n# Run\n$ srun -n1 --pty --x11 xclock\nalex@node1's password:\n</pre>\n\n<p><a name=\"unbuffered_cr\"><b>Why is the srun --u/--unbuffered option adding\n   a carriage character return to my output?</b></a><br>\nThe libc library used by many programs internally buffers output rather than\nwriting it immediately. This is done for performance reasons.\nThe only way to disable this internal buffering is to configure the program to\nwrite to a pseudo terminal (PTY) rather than to a regular file.\nThis configuration causes <u>some</u> implementations of libc to prepend the\ncarriage return character before all line feed characters.\nRemoving the carriage return character would result in desired formatting\nin some instances, while causing bad formatting in other cases.\nIn any case, Slurm is not adding the carriage return character, but displaying\nthe actual program's output.</p>\n\n<p><a name=\"sview_colors\"><b>Why is sview not coloring/highlighting nodes\n    properly?</b></a><br>\nsview color-coding is affected by the GTK theme. The node status grid\nis made up of button widgets and certain GTK themes don't show the color\nsetting as desired. Changing GTK themes can restore proper color-coding.</p>\n\n\n\n<h2>For Administrators</h2>\n\n<p><a name=\"suspend\"><b>How is job suspend/resume useful?</b></a><br>\nJob suspend/resume is most useful to get particularly large jobs initiated\nin a timely fashion with minimal overhead. Say you want to get a full-system\njob initiated. Normally you would need to either cancel all running jobs\nor wait for them to terminate. Canceling jobs results in the loss of\ntheir work to that point from their beginning.\nWaiting for the jobs to terminate can take hours, depending upon your\nsystem configuration. A more attractive alternative is to suspend the\nrunning jobs, run the full-system job, then resume the suspended jobs.\nThis can easily be accomplished by configuring a special queue for\nfull-system jobs and using a script to control the process.\nThe script would stop the other partitions, suspend running jobs in those\npartitions, and start the full-system partition.\nThe process can be reversed when desired.\nOne can effectively gang schedule (time-slice) multiple jobs\nusing this mechanism, although the algorithms to do so can get quite\ncomplex.\nSuspending and resuming a job makes use of the SIGSTOP and SIGCONT\nsignals respectively, so swap and disk space should be sufficient to\naccommodate all jobs allocated to a node, either running or suspended.\n\n<p><a name=\"return_to_service\"><b>Why is a node shown in state\nDOWN when the node has registered for service?</b></a><br>\nThe configuration parameter <i>ReturnToService</i> in <i>slurm.conf</i>\ncontrols how DOWN nodes are handled.\nSet its value to one in order for DOWN nodes to automatically be\nreturned to service once the <i>slurmd</i> daemon registers\nwith a valid node configuration.\nA value of zero is the default and results in a node staying DOWN\nuntil an administrator explicitly returns it to service using\nthe command &quot;scontrol update NodeName=whatever State=RESUME&quot;.\nSee &quot;man slurm.conf&quot; and &quot;man scontrol&quot; for more\ndetails.</p>\n\n<p><a name=\"down_node\"><b>What happens when a node crashes?</b></a><br>\nA node is set DOWN when the slurmd daemon on it stops responding\nfor <i>SlurmdTimeout</i> as defined in <i>slurm.conf</i>.\nThe node can also be set DOWN when certain errors occur or the\nnode's configuration is inconsistent with that defined in <i>slurm.conf</i>.\nAny active job on that node will be killed unless it was submitted\nwith the srun option <i>--no-kill</i>.\nAny active job step on that node will be killed.\nSee the slurm.conf and srun man pages for more information.</p>\n\n<p><a name=\"multi_job\"><b>How can I control the execution of multiple\njobs per node?</b></a><br>\nThere are two mechanisms to control this.\nIf you want to allocate individual processors on a node to jobs,\nconfigure <i>SelectType=select/cons_res</i>.\nSee <a href=\"cons_res.html\">Consumable Resources in Slurm</a>\nfor details about this configuration.\nIf you want to allocate whole nodes to jobs, configure\nconfigure <i>SelectType=select/linear</i>.\nEach partition also has a configuration parameter <i>OverSubscribe</i>\nthat enables more than one job to execute on each node.\nSee <i>man slurm.conf</i> for more information about these\nconfiguration parameters.</p>\n\n<p><a name=\"inc_plugin\"><b>When the Slurm daemon starts, it\nprints &quot;cannot resolve X plugin operations&quot; and exits.\nWhat does this mean?</b></a><br>\nThis means that symbols expected in the plugin were\nnot found by the daemon. This typically happens when the\nplugin was built or installed improperly or the configuration\nfile is telling the plugin to use an old plugin (say from the\nprevious version of Slurm). Restart the daemon in verbose mode\nfor more information (e.g. &quot;slurmctld -Dvvvvv&quot;).\n\n<p><a name=\"pam_exclude\"><b>How can I exclude some users from pam_slurm?</b></a><br>\n<b>CAUTION:</b> Please test this on a test machine/VM before you actually do\nthis on your Slurm computers.</p>\n\n<p><b>Step 1.</b> Make sure pam_listfile.so exists on your system.\nThe following command is an example on Redhat 6:</p>\n<pre>\nls -la /lib64/security/pam_listfile.so\n</pre>\n\n<p><b>Step 2.</b> Create user list (e.g. /etc/ssh/allowed_users):</p>\n<pre>\n# /etc/ssh/allowed_users\nroot\nmyadmin\n</pre>\n<p>And, change file mode to keep it secret from regular users(Optional):</p>\n<pre>\nchmod 600 /etc/ssh/allowed_users\n</pre>\n<p><b>NOTE:</b> root is not necessarily listed on the allowed_users, but I\nfeel somewhat safe if it's on the list.</p>\n\n<p><b>Step 3.</b> On /etc/pam.d/sshd, add pam_listfile.so with sufficient flag\nbefore pam_slurm.so (e.g. my /etc/pam.d/sshd looks like this):</p>\n<pre>\n#%PAM-1.0\nauth       required     pam_sepermit.so\nauth       include      password-auth\naccount    sufficient   pam_listfile.so item=user sense=allow file=/etc/ssh/allowed_users onerr=fail\naccount    required     pam_slurm.so\naccount    required     pam_nologin.so\naccount    include      password-auth\npassword   include      password-auth\n# pam_selinux.so close should be the first session rule\nsession    required     pam_selinux.so close\nsession    required     pam_loginuid.so\n# pam_selinux.so open should only be followed by sessions to be executed in the user context\nsession    required     pam_selinux.so open env_params\nsession    optional     pam_keyinit.so force revoke\nsession    include      password-auth\n</pre>\n<p>(Information courtesy of Koji Tanaka, Indiana University)</p>\n\n<p><a name=\"maint_time\"><b>How can I dry up the workload for a\nmaintenance period?</b></a><br>\nCreate a resource reservation as described b. Slurm's\n<a href=\"reservations.html\">Resource Reservation Guide</a>.\n\n<p><a name=\"pam\"><b>How can PAM be used to control a user's limits on\nor access to compute nodes?</b></a><br>\nTo control a user's limits on a compute node:<br>\n<p>First, enable Slurm's use of PAM by setting <i>UsePAM=1</i> in\n<i>slurm.conf</i>.</p>\n<p>Second, establish PAM configuration file(s) for Slurm in <i>/etc/pam.conf</i>\nor the appropriate files in the <i>/etc/pam.d</i> directory (e.g.\n<i>/etc/pam.d/sshd</i> by adding the line \"account required pam_slurm.so\".\nA basic configuration you might use is:</p>\n<pre>\naccount  required  pam_unix.so\naccount  required  pam_slurm.so\nauth     required  pam_localuser.so\nsession  required  pam_limits.so\n</pre>\n<p>Third, set the desired limits in <i>/etc/security/limits.conf</i>.\nFor example, to set the locked memory limit to unlimited for all users:</p>\n<pre>\n*   hard   memlock   unlimited\n*   soft   memlock   unlimited\n</pre>\n<p>Finally, you need to disable Slurm's forwarding of the limits from the\nsession from which the <i>srun</i> initiating the job ran. By default\nall resource limits are propagated from that session. For example, adding\nthe following line to <i>slurm.conf</i> will prevent the locked memory\nlimit from being propagated:<i>PropagateResourceLimitsExcept=MEMLOCK</i>.</p>\n\n<p>To control a user's access to a compute node:</p>\n<p>The pam_slurm_adopt and pam_slurm modules prevent users from\nlogging into nodes that they have not been allocated (except for user\nroot, which can always login).\nThey are both included with the Slurm distribution.\n<p>The pam_slurm_adopt module is highly recommended for most installations,\nand is documented in its <a href=\"pam_slurm_adopt.shtml\">own guide</a>.</p>\n<p>pam_slurm is older and less functional.\nThese modules are built by default for RPM packages, but can be disabled using\nthe .rpmmacros option \"%_without_pam 1\" or by entering the command line\noption \"--without pam\" when the configure program is executed.\nTheir source code is in the \"contribs/pam\" and \"contribs/pam_slurm_adopt\"\ndirectories respectively.</p>\n<p>The use of either pam_slurm_adopt or pam_slurm does not require\n<i>UsePAM</i> being set. The two uses of PAM are independent.</p>\n\n<p><a name=\"time\"><b>Why are jobs allocated nodes and then unable\nto initiate programs on some nodes?</b></a><br>\nThis typically indicates that the time on some nodes is not consistent\nwith the node on which the <i>slurmctld</i> daemon executes. In order to\ninitiate a job step (or batch job), the <i>slurmctld</i> daemon generates\na credential containing a time stamp. If the <i>slurmd</i> daemon\nreceives a credential containing a time stamp later than the current\ntime or more than a few minutes in the past, it will be rejected.\nIf you check in the <i>SlurmdLogFile</i> on the nodes of interest, you\nwill likely see messages of this sort: \"<i>Invalid job credential from\n&lt;some IP address&gt;: Job credential expired</i>.\" Make the times\nconsistent across all of the nodes and all should be well.\n\n<p><a name=\"ping\"><b>Why does <i>slurmctld</i> log that some nodes\nare not responding even if they are not in any partition?</b></a><br>\nThe <i>slurmctld</i> daemon periodically pings the <i>slurmd</i>\ndaemon on every configured node, even if not associated with any\npartition. You can control the frequency of this ping with the\n<i>SlurmdTimeout</i> configuration parameter in <i>slurm.conf</i>.\n\n<p><a name=\"controller\"><b>How should I relocate the primary or\nbackup controller?</b></a><br>\nIf the cluster's computers used for the primary or backup controller\nwill be out of service for an extended period of time, it may be desirable\nto relocate them. In order to do so, follow this procedure:</p>\n<ol>\n<li>Stop all Slurm daemons</li>\n<li>Modify the <i>SlurmctldHost</i> values in the <i>slurm.conf</i> file</li>\n<li>Distribute the updated <i>slurm.conf</i> file to all nodes</li>\n<li>Copy the <i>StateSaveLocation</i> directory to the new host and\nmake sure the permissions allow the <i>SlurmUser</i> to read and write it.\n<li>Restart all Slurm daemons</li>\n</ol>\n<p>There should be no loss of any running or pending jobs. Ensure that\nany nodes added to the cluster have a current <i>slurm.conf</i> file\ninstalled.\n<b>CAUTION:</b> If two nodes are simultaneously configured as the primary\ncontroller (two nodes on which <i>SlurmctldHost</i> specify the local host\nand the <i>slurmctld</i> daemon is executing on each), system behavior will be\ndestructive. If a compute node has an incorrect <i>SlurmctldHost</i> parameter,\nthat node may be rendered unusable, but no other harm will result.\n\n<p><a name=\"multi_slurm\"><b>Can multiple Slurm systems be run in\nparallel for testing purposes?</b></a><br>\nYes, this is a great way to test new versions of Slurm.\nJust install the test version in a different location with a different\n<i>slurm.conf</i>.\nThe test system's <i>slurm.conf</i> should specify different\npathnames and port numbers to avoid conflicts.\nThe only problem is if more than one version of Slurm is configured\nwith <i>burst_buffer/*</i> plugins or others that may interact with external\nsystem APIs.\nIn that case, there can be conflicting API requests from\nthe different Slurm systems.\nThis can be avoided by configuring the test system with <i>burst_buffer/none</i>.\n\n<p><a name=\"multi_slurmd\"><b>Can Slurm emulate a larger cluster?</b></a><br>\nYes, this can be useful for testing purposes.\nIt has also been used to partition \"fat\" nodes into multiple Slurm nodes.\nThere are two ways to do this.\nThe best method for most conditions is to run one <i>slurmd</i>\ndaemon per emulated node in the cluster as follows.\n<ol>\n<li>When executing the <i>configure</i> program, use the option\n<i>--enable-multiple-slurmd</i> (or add that option to your <i>~/.rpmmacros</i>\nfile).</li>\n<li>Build and install Slurm in the usual manner.</li>\n<li>In <i>slurm.conf</i> define the desired node names (arbitrary\nnames used only by Slurm) as <i>NodeName</i> along with the actual\naddress of the physical node in <i>NodeHostname</i>. Multiple\n<i>NodeName</i> values can be mapped to a single\n<i>NodeHostname</i>.  Note that each <i>NodeName</i> on a single\nphysical node needs to be configured to use a different port number\n(set <i>Port</i> to a unique value on each line for each node).  You\nwill also want to use the \"%n\" symbol in slurmd related path options in\nslurm.conf (<i>SlurmdLogFile</i> and <i>SlurmdPidFile</i>). </li>\n<li>When starting the <i>slurmd</i> daemon, include the <i>NodeName</i>\nof the node that it is supposed to serve on the execute line (e.g.\n\"slurmd -N hostname\").</li>\n<li> This is an example of the <i>slurm.conf</i> file with the  emulated nodes\nand ports configuration. Any valid value for the CPUs, memory or other\nvalid node resources can be specified.</li>\n</ol>\n\n<pre>\nNodeName=dummy26[1-100] NodeHostName=achille Port=[6001-6100] NodeAddr=127.0.0.1 CPUs=4 RealMemory=6000\nPartitionName=mira Default=yes Nodes=dummy26[1-100]\n</pre>\n\n<p>See the\n<a href=\"programmer_guide.html#multiple_slurmd_support\">Programmers Guide</a>\nfor more details about configuring multiple slurmd support.</p>\n\n<p>In order to emulate a really large cluster, it can be more\nconvenient to use a single <i>slurmd</i> daemon.\nThat daemon will not be able to launch many tasks, but can\nsuffice for developing or testing scheduling software.\nDo not run job steps with more than a couple of tasks each\nor execute more than a few jobs at any given time.\nDoing so may result in the <i>slurmd</i> daemon exhausting its\nmemory and failing.\n<b>Use this method with caution.</b>\n<ol>\n<li>Execute the <i>configure</i> program with your normal options\nplus <i>--enable-front-end</i> (this will define HAVE_FRONT_END in\nthe resulting <i>config.h</i> file.</li>\n<li>Build and install Slurm in the usual manner.</li>\n<li>In <i>slurm.conf</i> define the desired node names (arbitrary\nnames used only by Slurm) as <i>NodeName</i> along with the actual\nname and address of the <b>one</b> physical node in <i>NodeHostName</i>\nand <i>NodeAddr</i>.\nUp to 64k nodes can be configured in this virtual cluster.</li>\n<li>Start your <i>slurmctld</i> and one <i>slurmd</i> daemon.\nIt is advisable to use the \"-c\" option to start the daemons without\ntrying to preserve any state files from previous executions.\nBe sure to use the \"-c\" option when switching from this mode too.</li>\n<li>Create job allocations as desired, but do not run job steps\nwith more than a couple of tasks.</li>\n</ol>\n\n<pre>\n$ ./configure --enable-debug --enable-front-end --prefix=... --sysconfdir=...\n$ make install\n$ grep NodeHostName slurm.conf\n<i>NodeName=dummy[1-1200] NodeHostName=localhost NodeAddr=127.0.0.1</i>\n$ slurmctld -c\n$ slurmd -c\n$ sinfo\n<i>PARTITION AVAIL  TIMELIMIT NODES  STATE NODELIST</i>\n<i>pdebug*      up      30:00  1200   idle dummy[1-1200]</i>\n$ cat tmp\n<i>#!/bin/bash</i>\n<i>sleep 30</i>\n$ srun -N200 -b tmp\n<i>srun: jobid 65537 submitted</i>\n$ srun -N200 -b tmp\n<i>srun: jobid 65538 submitted</i>\n$ srun -N800 -b tmp\n<i>srun: jobid 65539 submitted</i>\n$ squeue\n<i>JOBID PARTITION  NAME   USER  ST  TIME  NODES NODELIST(REASON)</i>\n<i>65537    pdebug   tmp  jette   R  0:03    200 dummy[1-200]</i>\n<i>65538    pdebug   tmp  jette   R  0:03    200 dummy[201-400]</i>\n<i>65539    pdebug   tmp  jette   R  0:02    800 dummy[401-1200]</i>\n</pre>\n\n<p><a name=\"extra_procs\"><b>Can Slurm emulate nodes with more\nresources than physically exist on the node?</b></a><br>\nYes. In the slurm.conf file, configure <i>SlurmdParameters=config_overrides</i>\nand specify\nany desired node resource specifications (<i>CPUs</i>, <i>Sockets</i>,\n<i>CoresPerSocket</i>, <i>ThreadsPerCore</i>, and/or <i>TmpDisk</i>).\nSlurm will use the resource specification for each node that is\ngiven in <i>slurm.conf</i> and will not check these specifications\nagainst those actually found on the node. The system would best be configured\nwith <i>TaskPlugin=task/none</i>, so that launched tasks can run on any\navailable CPU under operating system control.\n\n<p><a name=\"credential_replayed\"><b>What does a\n&quot;credential replayed&quot;\nerror in the <i>SlurmdLogFile</i> indicate?</b></a><br>\nThis error is indicative of the <i>slurmd</i> daemon not being able\nto respond to job initiation requests from the <i>srun</i> command\nin a timely fashion (a few seconds).\n<i>Srun</i> responds by resending the job initiation request.\nWhen the <i>slurmd</i> daemon finally starts to respond, it\nprocesses both requests.\nThe second request is rejected and the event is logged with\nthe \"credential replayed\" error.\nIf you check the <i>SlurmdLogFile</i> and <i>SlurmctldLogFile</i>,\nyou should see signs of the <i>slurmd</i> daemon's non-responsiveness.\nA variety of factors can be responsible for this problem\nincluding\n<ul>\n<li>Diskless nodes encountering network problems</li>\n<li>Very slow Network Information Service (NIS)</li>\n<li>The <i>Prolog</i> script taking a long time to complete</li>\n</ul>\n<p>Configure <i>MessageTimeout</i> in slurm.conf to a value higher than the\ndefault 5 seconds.</p>\n\n<p><a name=\"large_time\"><b>What does\n&quot;Warning: Note very large processing time&quot;\nin the <i>SlurmctldLogFile</i> indicate?</b></a><br>\nThis error is indicative of some operation taking an unexpectedly\nlong time to complete, over one second to be specific.\nSetting the value of the <i>SlurmctldDebug</i> configuration parameter\nto <i>debug2</i> or higher should identify which operation(s) are\nexperiencing long delays.\nThis message typically indicates long delays in file system access\n(writing state information or getting user information).\nAnother possibility is that the node on which the slurmctld\ndaemon executes has exhausted memory and is paging.\nTry running the program <i>top</i> to check for this possibility.\n\n<p><a name=\"limit_propagation\"><b>Is resource limit propagation\nuseful on a homogeneous cluster?</b></a><br>\nResource limit propagation permits a user to modify resource limits\nand submit a job with those limits.\nBy default, Slurm automatically propagates all resource limits in\neffect at the time of job submission to the tasks spawned as part\nof that job.\nSystem administrators can utilize the <i>PropagateResourceLimits</i>\nand <i>PropagateResourceLimitsExcept</i> configuration parameters to\nchange this behavior.\nUsers can override defaults using the <i>srun --propagate</i>\noption.\nSee <i>\"man slurm.conf\"</i> and <i>\"man srun\"</i> for more information\nabout these options.\n\n<p><a name=\"clock\"><b>Do I need to maintain synchronized\nclocks on the cluster?</b></a><br>\nIn general, yes. Having inconsistent clocks may cause nodes to\nbe unusable. Slurm log files should contain references to\nexpired credentials. For example:\n<pre>\nerror: Munge decode failed: Expired credential\nENCODED: Wed May 12 12:34:56 2008\nDECODED: Wed May 12 12:01:12 2008\n</pre>\n\n<p><a name=\"cred_invalid\"><b>Why are &quot;Invalid job credential&quot;\nerrors generated?</b></a><br>\nThis error is indicative of Slurm's job credential files being inconsistent across\nthe cluster. All nodes in the cluster must have the matching public and private\nkeys as defined by <b>JobCredPrivateKey</b> and <b>JobCredPublicKey</b> in the\nSlurm configuration file <b>slurm.conf</b>.\n\n<p><a name=\"cred_replay\"><b>Why are\n&quot;Task launch failed on node ... Job credential replayed&quot;\nerrors generated?</b></a><br>\nThis error indicates that a job credential generated by the slurmctld daemon\ncorresponds to a job that the slurmd daemon has already revoked.\nThe slurmctld daemon selects job ID values based upon the configured\nvalue of <b>FirstJobId</b> (the default value is 1) and each job gets\na value one larger than the previous job.\nOn job termination, the slurmctld daemon notifies the slurmd on each\nallocated node that all processes associated with that job should be\nterminated.\nThe slurmd daemon maintains a list of the jobs which have already been\nterminated to avoid replay of task launch requests.\nIf the slurmctld daemon is cold-started (with the &quot;-c&quot; option\nor &quot;/etc/init.d/slurm startclean&quot;), it starts job ID values\nover based upon <b>FirstJobId</b>.\nIf the slurmd is not also cold-started, it will reject job launch requests\nfor jobs that it considers terminated.\nThis solution to this problem is to cold-start all slurmd daemons whenever\nthe slurmctld daemon is cold-started.\n\n<p><a name=\"globus\"><b>Can Slurm be used with Globus?</b></a><br>\nYes. Build and install Slurm's Torque/PBS command wrappers along with\nthe Perl APIs from Slurm's <i>contribs</i> directory and configure\n<a href=\"http://www-unix.globus.org/\">Globus</a> to use those PBS commands.\nNote there are RPMs available for both of these packages, named\n<i>torque</i> and <i>perlapi</i> respectively.\n\n<p><a name=\"file_limit\"><b>What causes the error\n&quot;Unable to accept new connection: Too many open files&quot;?</b></a><br>\nThe srun command automatically increases its open file limit to\nthe hard limit in order to process all of the standard input and output\nconnections to the launched tasks. It is recommended that you set the\nopen file hard limit to 8192 across the cluster.\n\n<p><a name=\"slurmd_log\"><b>Why does the setting of <i>SlurmdDebug</i>\nfail to log job step information at the appropriate level?</b></a><br>\nThere are two programs involved here. One is <b>slurmd</b>, which is\na persistent daemon running at the desired debug level. The second\nprogram is <b>slurmstepd</b>, which executes the user job and its\ndebug level is controlled by the user. Submitting the job with\nan option of <i>--debug=#</i> will result in the desired level of\ndetail being logged in the <i>SlurmdLogFile</i> plus the output\nof the program.\n\n<p><a name=\"rpm\"><b>Why aren't pam_slurm.so, auth_none.so, or other components in a\nSlurm RPM?</b></a><br>\nIt is possible that at build time the required dependencies for building the\nlibrary are missing. If you want to build the library then install pam-devel\nand compile again. See the file slurm.spec in the Slurm distribution for a list\nof other options that you can specify at compile time with rpmbuild flags\nand your <i>rpmmacros</i> file.\n\nThe auth_none plugin is in a separate RPM and not built by default.\nUsing the auth_none plugin means that Slurm communications are not\nauthenticated, so you probably do not want to run in this mode of operation\nexcept for testing purposes. If you want to build the auth_none RPM then\nadd <i>--with auth_none</i> on the rpmbuild command line or add\n<i>%_with_auth_none</i> to your ~/rpmmacros file. See the file slurm.spec\nin the Slurm distribution for a list of other options.\n\n<p><a name=\"slurmdbd\"><b>Why should I use the slurmdbd instead of the\nregular database plugins?</b></a><br>\nWhile the normal storage plugins will work fine without the added\nlayer of the slurmdbd there are some great benefits to using the\nslurmdbd.\n<ol>\n<li>Added security.  Using the slurmdbd you can have an authenticated\nconnection to the database.</li>\n<li>Offloading processing from the controller. With the slurmdbd there is no\nslowdown to the controller due to a slow or overloaded database.</li>\n<li>Keeping enterprise wide accounting from all Slurm clusters in one database.\nThe slurmdbd is multi-threaded and designed to handle all the\naccounting for the entire enterprise.</li>\n<li>With the database plugins you can query with sacct accounting stats from\nany node Slurm is installed on. With the slurmdbd you can also query any\ncluster using the slurmdbd from any other cluster's nodes. Other tools like\nsreport are also available.</li>\n</ol>\n\n<p><a name=\"debug\"><b>How can I build Slurm with debugging symbols?</b></a></br>\nWhen configuring, run the configure script with <i>--enable-developer</i> option.\nThat will provide asserts, debug messages and the <i>-Werror</i> flag, that\nwill in turn activate <i>--enable-debug</i>.\n<br/>With the <i>--enable-debug</i> flag, the code will be compiled with\n<i>-ggdb3</i> and <i>-g -O1 -fno-strict-aliasing</i> flags that will produce\nextra debugging information. Another possible option to use is\n<i>--disable-optimizations</i> that will set <i>-O0</i>.\nSee also <i>auxdir/x_ac_debug.m4</i> for more details.\n\n<p><a name=\"state_preserve\"><b>How can I easily preserve drained node\ninformation between major Slurm updates?</b></a><br>\nMajor Slurm updates generally have changes in the state save files and\ncommunication protocols, so a cold-start (without state) is generally\nrequired. If you have nodes in a DRAIN state and want to preserve that\ninformation, you can easily build a script to preserve that information\nusing the <i>sinfo</i> command. The following command line will report the\n<i>Reason</i> field for every node in a DRAIN state and write the output\nin a form that can be executed later to restore state.\n<pre>\nsinfo -t drain -h -o \"scontrol update nodename='%N' state=drain reason='%E'\"\n</pre>\n\n<p><a name=\"health_check\"><b>Why doesn't the <i>HealthCheckProgram</i>\nexecute on DOWN nodes?</a></b><br>\nHierarchical communications are used for sending this message. If there\nare DOWN nodes in the communications hierarchy, messages will need to\nbe re-routed. This limits Slurm's ability to tightly synchronize the\nexecution of the <i>HealthCheckProgram</i> across the cluster, which\ncould adversely impact performance of parallel applications.\nThe use of CRON or node startup scripts may be better suited to ensure\nthat <i>HealthCheckProgram</i> gets executed on nodes that are DOWN\nin Slurm.\n\n<p><a name=\"batch_lost\"><b>What is the meaning of the error\n&quot;Batch JobId=# missing from batch node &lt;node&gt; (not found\n  BatchStartTime after startup)&quot;?</b></a><br>\nA shell is launched on node zero of a job's allocation to execute\nthe submitted program. The <i>slurmd</i> daemon executing on each compute\nnode will periodically report to the <i>slurmctld</i> what programs it\nis executing. If a batch program is expected to be running on some\nnode (i.e. node zero of the job's allocation) and is not found, the\nmessage above will be logged and the job canceled. This typically is\nassociated with exhausting memory on the node or some other critical\nfailure that cannot be recovered from.\n\n<p><a name=\"accept_again\"><b>What does the message\n&quot;srun: error: Unable to accept connection: Resources temporarily unavailable&quot;\nindicate?</b></a><br>\nThis has been reported on some larger clusters running SUSE Linux when\na user's resource limits are reached. You may need to increase limits\nfor locked memory and stack size to resolve this problem.\n\n<p><a name=\"task_prolog\"><b>How could I automatically print a job's\nSlurm job ID to its standard output?</b></a></br>\nThe configured <i>TaskProlog</i> is the only thing that can write to\nthe job's standard output or set extra environment variables for a job\nor job step. To write to the job's standard output, precede the message\nwith \"print \". To export environment variables, output a line of this\nform \"export name=value\". The example below will print a job's Slurm\njob ID and allocated hosts for a batch job only.\n\n<pre>\n#!/bin/sh\n#\n# Sample TaskProlog script that will print a batch job's\n# job ID and node list to the job's stdout\n#\n\nif [ X\"$SLURM_STEP_ID\" = \"X\" -a X\"$SLURM_PROCID\" = \"X\"0 ]\nthen\n  echo \"print ==========================================\"\n  echo \"print SLURM_JOB_ID = $SLURM_JOB_ID\"\n  echo \"print SLURM_JOB_NODELIST = $SLURM_JOB_NODELIST\"\n  echo \"print ==========================================\"\nfi\n</pre>\n\n<p><a name=\"orphan_procs\"><b>Why are user processes and <i>srun</i>\nrunning even though the job is supposed to be completed?</b></a></br>\nSlurm relies upon a configurable process tracking plugin to determine\nwhen all of the processes associated with a job or job step have completed.\nThose plugins relying upon a kernel patch can reliably identify every process.\nThose plugins dependent upon process group IDs or parent process IDs are not\nreliable. See the <i>ProctrackType</i> description in the <i>slurm.conf</i>\nman page for details. We rely upon the cgroup plugin for most systems.</p>\n\n<p><a name=\"slurmd_oom\"><b>How can I prevent the <i>slurmd</i> and\n<i>slurmstepd</i> daemons from being killed when a node's memory\nis exhausted?</b></a></br>\nYou can set the value in the <i>/proc/self/oom_adj</i> for\n<i>slurmd</i> and <i>slurmstepd</i> by initiating the <i>slurmd</i>\ndaemon with the <i>SLURMD_OOM_ADJ</i> and/or <i>SLURMSTEPD_OOM_ADJ</i>\nenvironment variables set to the desired values.\nA value of -17 typically will disable killing.</p>\n\n<p><a name=\"ubuntu\"><b>I see the host of my calling node as 127.0.1.1\n    instead of the correct IP address.  Why is that?</b></a></br>\nSome systems by default will put your host in the /etc/hosts file as\nsomething like</p>\n<pre>\n127.0.1.1\tsnowflake.llnl.gov\tsnowflake\n</pre>\n<p>This will cause srun and Slurm commands to use the 127.0.1.1 address\ninstead of the correct address and prevent communications between nodes.\nThe solution is to either remove this line or configure a different NodeAddr\nthat is known by your other nodes.</p>\n\n<p>The CommunicationParameters=NoInAddrAny configuration parameter is subject to\nthis same problem, which can also be addressed by removing the actual node\nname from the \"127.0.1.1\" as well as the \"127.0.0.1\"\naddresses in the /etc/hosts file.  It is ok if they point to\nlocalhost, but not the actual name of the node.</p>\n\n<p><a name=\"stop_sched\"><b>How can I stop Slurm from scheduling jobs?</b></a></br>\nYou can stop Slurm from scheduling jobs on a per partition basis by setting\nthat partition's state to DOWN. Set its state UP to resume scheduling.\nFor example:\n<pre>\n$ scontrol update PartitionName=foo State=DOWN\n$ scontrol update PartitionName=bar State=UP\n</pre></p>\n\n<p><a name=\"scontrol_multi_jobs\"><b>Can I update multiple jobs with a\nsingle <i>scontrol</i> command?</b></a></br>\nNo, but you can probably use <i>squeue</i> to build the script taking\nadvantage of its filtering and formatting options. For example:\n<pre>\n$ squeue -tpd -h -o \"scontrol update jobid=%i priority=1000\" >my.script\n</pre></p>\n\n<p><a name=\"amazon_ec2\"><b>Can Slurm be used to run jobs on\nAmazon's EC2?</b></a></br>\nYes, here is a description of Slurm use with\n<a href=\"http://aws.amazon.com/ec2/\">Amazon's EC2</a> courtesy of\nAshley Pittman:</p>\n<p>I do this regularly and have no problem with it, the approach I take is to\nstart as many instances as I want and have a wrapper around\nec2-describe-instances that builds a /etc/hosts file with fixed hostnames\nand the actual IP addresses that have been allocated.  The only other step\nthen is to generate a slurm.conf based on how many node you've chosen to boot\nthat day.  I run this wrapper script on my laptop and it generates the files\nand they rsyncs them to all the instances automatically.</p>\n<p>One thing I found is that Slurm refuses to start if any nodes specified in\nthe slurm.conf file aren't resolvable, I initially tried to specify cloud[0-15]\nin slurm.conf, but then if I configure less than 16 nodes in /etc/hosts this\ndoesn't work so I dynamically generate the slurm.conf as well as the hosts\nfile.</p>\n<p>As a comment about EC2 I run just run generic AMIs and have a persistent EBS\nstorage device which I attach to the first instance when I start up.  This\ncontains a /usr/local which has my software like Slurm, pdsh and MPI installed\nwhich I then copy over the /usr/local on the first instance and NFS export to\nall other instances.  This way I have persistent home directories and a very\nsimple first-login script that configures the virtual cluster for me.</p>\n\n<p><a name=\"core_dump\"><b>If a Slurm daemon core dumps, where can I find the\ncore file?</b></a></br>\nIf <i>slurmctld</i> is started with the -D option, then the core file will be\nwritten to the current working directory. If <i>SlurmctldLogFile</i> is an\nabsolute path, the core file will be written to this directory. Otherwise the\ncore file will be written to the <i>StateSaveLocation</i>, or \"/var/tmp/\" as a\nlast resort.<br>\nSlurmUser must have write permission on the directories. If none of the above\ndirectories have write permission for SlurmUser, no core file will be produced.\nFor testing purposes the command \"scontrol abort\" can be used to abort the\nslurmctld daemon and generate a core file.\n\n<p>If <i>slurmd</i> is started with the -D option, then the core file will also be\nwritten to the current working directory. If <i>SlurmdLogFile</i> is an\nabsolute path, the core file will be written to the this directory.\nOtherwise the core file will be written to the <i>SlurmdSpoolDir</i>, or\n\"/var/tmp/\" as a last resort.<br>\nIf none of the above directories can be written, no core file will be produced.\n</p>\n\n<p>For <i>slurmstepd</i>, the core file will depend upon when the failure\noccurs. If it is running in a privileged phase, it will be in the same location\nas that described above for the slurmd daemon. If it is running in an\nunprivileged phase, it will be in the spawned job's working directory.</p>\n\n\n<p>Nevertheless, in some operating systems this can vary:\n<ul>\n<li>\nI.e. in RHEL the event\nmay be captured by abrt daemon and generated in the defined abrt configured\ndump location (i.e. /var/spool/abrt).\n</li>\n<li>\nIn Cray XC ATP\n(Abnormal Termination Processing) daemon acts the same way, if it is enabled.\n</li>\n</ul>\n</p>\n\n<p>Normally, distributions need some more tweaking in order to allow the core\nfiles to be generated correctly.</p>\n\n<p>slurmstepd uses the setuid() (set user ID) function to escalate\nprivileges. It is possible that in certain systems and for security policies,\nthis causes the core files not to be generated.\n<br>To allow the generation in such systems you usually must enable the\nsuid_dumpable kernel parameter:</p>\n\nSet:<br>\n /proc/sys/fs/suid_dumpable to 2<br>\nor<br>\n sysctl fs.suid_dumpable=2<br><br>\nor set it permanently in sysctl.conf<br>\n fs.suid_dumpable = 2<br><br>\n\n<p>The value of 2, \"suidsafe\", makes any binary which normally not be dumped is\ndumped readable by root only.<br>This allows the end user to remove such a dump\nbut not access it directly. For security reasons core dumps in this mode will\nnot overwrite one another or other files.<br> This mode is appropriate when\nadministrators are attempting to debug problems in a normal environment.</p>\n\n<p>Then you must also set the core pattern to an absolute pathname:</p>\n\n<pre>sysctl kernel.core_pattern=/tmp/core.%e.%p</pre>\n\n<p>We recommend reading your distribution's documentation about the\nconfiguration of these parameters.</p>\n\n<p>It is also usually needed to configure the system core limits, since it can be\nset to 0.</p>\n<pre>\n$ grep core /etc/security/limits.conf\n#        - core - limits the core file size (KB)\n*               hard    core            unlimited\n*               soft    core            unlimited\n</pre>\n<p>In some systems it is not enough to set a hard limit, you must set also a\nsoft limit.</p>\n\n<p>Also, for generating the limits in userspace, the\n<i>PropagateResourceLimits=CORE</i> parameter in slurm.conf could be needed.</p>\n\n<p>Be also sure to give SlurmUser the appropriate permissions to write in the\ncore location directories.</p>\n\n<p> NOTE: On a diskless node depending on the core_pattern or if\n/var/spool/abrt is pointing to an in-memory filespace like tmpfs, if the job\ncaused an OOM, then the generation of the core may fill up your machine's\nmemory and hang it. It is encouraged then to make coredumps go to a persistent\nstorage. Be careful of multiple nodes writting a core dump to a shared\nfilesystem since it may significantly impact it.\n</p>\n\n<b>Other exceptions:</b>\n\n<p>On Centos 6, also set \"ProcessUnpackaged = yes\" in the file\n/etc/abrt/abrt-action-save-package-data.conf.\n\n<p>On RHEL6, also set \"DAEMON_COREFILE_LIMIT=unlimited\" in the file\nrc.d/init.d/functions.</p>\n\n<p>On a SELinux enabled system, or on a distribution with similar security\nsystem, get sure it is allowing to dump cores:</p>\n\n<pre>$ getsebool allow_daemons_dump_core</pre>\n\n<p>coredumpctl can also give valuable information:</p>\n\n<pre>$ coredumpctl info</pre>\n\n<p><a name=\"totalview\"><b>How can TotalView be configured to operate with\n  Slurm?</b></a></br>\nThe following lines should also be added to the global <i>.tvdrc</i> file\nfor TotalView to operate with Slurm:\n<pre>\n# Enable debug server bulk launch: Checked\ndset -set_as_default TV::bulk_launch_enabled true\n\n# Command:\n# Beginning with TV 7X.1, TV supports Slurm and %J.\n# Specify --mem-per-cpu=0 in case Slurm configured with default memory\n# value and we want TotalView to share the job's memory limit without\n# consuming any of the job's memory so as to block other job steps.\ndset -set_as_default TV::bulk_launch_string {srun --mem-per-cpu=0 -N%N -n%N -w`awk -F. 'BEGIN {ORS=\",\"} {if (NR==%N) ORS=\"\"; print $1}' %t1` -l --input=none %B/tvdsvr%K -callback_host %H -callback_ports %L -set_pws %P -verbosity %V -working_directory %D %F}\n\n# Temp File 1 Prototype:\n# Host Lines:\n# Slurm NodeNames need to be unadorned hostnames. In case %R returns\n# fully qualified hostnames, list the hostnames in %t1 here, and use\n# awk in the launch string above to strip away domain name suffixes.\ndset -set_as_default TV::bulk_launch_tmpfile1_host_lines {%R}\n</pre></p>\n<!-- OLD FORMAT\ndset TV::parallel_configs {\n\tname: Slurm;\n\tdescription: Slurm;\n\tstarter: srun %s %p %a;\n\tstyle: manager_process;\n\ttasks_option: -n;\n\tnodes_option: -N;\n\tenv: ;\n\tforce_env: false;\n}\n!-->\n\n<p><a name=\"git_patch\"><b>How can a patch file be generated from a Slurm\ncommit in GitHub?</b></a></br>\nFind and open the commit in GitHub then append \".patch\" to the URL and save\nthe resulting file. For an example, see:\n<a href=\"https://github.com/SchedMD/slurm/commit/91e543d433bed11e0df13ce0499be641774c99a3.patch\">\nhttps://github.com/SchedMD/slurm/commit/91e543d433bed11e0df13ce0499be641774c99a3.patch</a>\n</p>\n\n<p><a name=\"enforce_limits\"><b>Why are the resource limits set in the\ndatabase not being enforced?</b></a></br>\nIn order to enforce resource limits, set the value of\n<b>AccountingStorageEnforce</b> in each cluster's slurm.conf configuration\nfile appropriately. If <b>AccountingStorageEnforce</b> does not contains\nan option of \"limits\", then resource limits will not be enforced on that cluster.\nSee <a href=\"resource_limits.html\">Resource Limits</a> for more information.</p>\n\n<p><a name=\"restore_priority\"><b>After manually setting a job priority\nvalue, how can its priority value be returned to being managed by the\npriority/multifactor plugin?</b></a></br>\nHold and then release the job as shown below.</p>\n<pre>\n$ scontrol hold &lt;jobid&gt;\n$ scontrol release &lt;jobid&gt;\n</pre>\n\n<p><a name=\"health_check_example\"><b>Does anyone have an example node\nhealth check script for Slurm?</b></a></br>\nProbably the most comprehensive and lightweight health check tool out\nthere is\n<a href=\"https://github.com/mej/nhc\">Node Health Check</a>.\nIt has integration with Slurm as well as Torque resource managers.</p>\n\n<p><a name=\"add_nodes\"><b>What process should I follow to add nodes to Slurm?</b></a></br>\nThe slurmctld daemon has a multitude of bitmaps to track state of nodes and cores\nin the system. Adding nodes to a running system would require the slurmctld daemon\nto rebuild all of those bitmaps, which the developers feel would be safer to do by\nrestarting the daemon. Communications from the slurmd daemons on the compute\nnodes to the slurmctld daemon include a configuration file checksum, so you\nprobably also want to maintain a common slurm.conf file on all nodes. The\nfollowing procedure is recommended:\n<ol>\n<li>Stop the slurmctld daemon (e.g. \"systemctl stop slurmctld\" on the head node)</li>\n<li>Update the slurm.conf file on all nodes in the cluster</li>\n<li>Restart the slurmd daemons on all nodes (e.g. \"systemctl restart slurmd\" on all nodes)</li>\n<li>Restart the slurmctld daemon (e.g. \"systemctl start slurmctld\" on the head node)</li>\n</ol>\n\n<p>NOTE: Jobs submitted with srun, and that are waiting for an allocation,\nprior to new nodes being added to the slurm.conf can fail if the job is\nallocated one of the new nodes.\n\n<p><a name=\"licenses\"><b>Can Slurm be configured to manage licenses?</b></a></br>\nSlurm is not currently integrated with FlexLM, but it does provide for the\nallocation of global resources called licenses. Use the Licenses configuration\nparameter in your slurm.conf file (e.g. \"Licenses=foo:10,bar:20\").\nJobs can request licenses and be granted exclusive use of those resources\n(e.g. \"sbatch --licenses=foo:2,bar:1 ...\").\nIt is not currently possible to change the total number of licenses on a system\nwithout restarting the slurmctld daemon, but it is possible to dynamically\nreserve licenses and remove them from being available to jobs on the system\n(e.g. \"scontrol update reservation=licenses_held licenses=foo:5,bar:2\").</p>\n\n<p><a name=\"salloc_default_command\"><b>Can the salloc command be configured to\nlaunch a shell on a node in the job's allocation?</b></a></br>\nYes, just use the SallocDefaultCommand configuration parameter in your\nslurm.conf file as shown below.</p>\n<pre>\nSallocDefaultCommand=\"srun -n1 -N1 --mem-per-cpu=0 --pty --preserve-env --cpu-bind=no --mpi=none $SHELL\"\n</pre>\n\n<p>\nFor Cray systems, add --gres=craynetwork:0 to the options.\n<pre>\nSallocDefaultCommand=\"srun -n1 -N1 --mem-per-cpu=0 --gres=craynetwork:0 --pty --preserve-env --mpi=none $SHELL\"\n</pre>\n</p>\n\n<p><a name=\"upgrade\"><b>What should I be aware of when upgrading Slurm?</b></a></br>\nSee the Quick Start Administrator Guide <a href=\"quickstart_admin.html#upgrade\">Upgrade</a>\nsection for details.</p>\n\n<p><a name=\"torque\"><b>How easy is it to switch from PBS or Torque to Slurm?</b></a></br>\nA lot of users don't even notice the difference.\nSlurm has wrappers available for the mpiexec, pbsnodes, qdel, qhold, qrls,\nqstat, and qsub commands (see contribs/torque in the distribution and the\n\"slurm-torque\" RPM).\nThere is also a wrapper for the showq command at\n<a href=\"https://github.com/pedmon/slurm_showq\">\nhttps://github.com/pedmon/slurm_showq</a>.</p>\n\n<p>Slurm recognizes and translates the \"#PBS\" options in batch scripts.\nMost, but not all options are supported.</p>\n\n<p>Slurm also includes a SPANK plugin that will set all of the PBS environment\nvariables based upon the Slurm environment (e.g. PBS_JOBID, PBS_JOBNAME,\nPBS_WORKDIR, etc.).\nOne environment not set by PBS_ENVIRONMENT, which if set would result in the\nfailure of some MPI implementations.\nThe plugin will be installed in<br>\n&lt;install_directory&gt;/lib/slurm/spank_pbs.so<br>\nSee the SPANK man page for configuration details.</p>\n\n<p><a name=\"sssd\"><b>How can I get SSSD to work with Slurm?</b></a></br>\nSSSD or System Security Services Deamon does not allow enumeration of\ngroup members by default. Note that enabling enumeration in large\nenvironments might not be feasible. However, Slurm does not need enumeration\nexcept for some specific quirky configurations (multiple groups with the same\nGID), so it's probably safe to leave enumeration disabled.\nSSSD is also case sensitive by default for some configurations, which could\npossibly raise other issues. Add the following lines\nto <i>/etc/sssd/sssd.conf</i> on your head node to address these issues:</p>\n<pre>\nenumerate = True\ncase_sensitive = False\n</pre>\n\n<p><a name=\"ha_db\"><b>How critical is configuring high availability for my\ndatabase?</b></a></br>\n<ul>\n<li>Consider if you really need a high-availability MySQL setup. A short outage\nof slurmdbd is not a problem, because slurmctld will store all data in memory\nand send it to slurmdbd when it resumes operations. The slurmctld daemon will\nalso cache all user limits and fair share information.</li>\n<li>You cannot use NDB, since SlurmDBD's MySQL implementation uses keys on BLOB\nvalues (and potentially other features on the incompatibility list).</li>\n<li>You can set up \"classical\" Linux HA, with heartbeat/corosync to migrate IP\nbetween primary/backup mysql servers and:</li>\n<ul>\n<li>Configure one way replication of mysql, and change primary/backup roles on\nfailure</li>\n<li>Use shared storage for primary/backup mysql servers database, and start\nbackup on primary mysql failure.</li>\n</ul>\n</ul>\n\n<p><a name=\"sql\"><b>How can I use double quotes in MySQL queries?</b></a></br>\nExecute:\n<pre>\nSET session sql_mode='ANSI_QUOTES';\n</pre>\n<p>This will allow double quotes in queries like this:</p>\n<pre>\nshow columns from \"tux_assoc_table\" where Field='is_def';\n</pre>\n\n<p><a name=\"reboot\"><b>Why is a compute node down with the reason set to\n\"Node unexpectedly rebooted\"?</b></a></br>\nThis is indicative of the slurmctld daemon running on the cluster's head node\nas well as the slurmd daemon on the compute node when the compute node reboots.\nIf you want to prevent this condition from setting the node into a DOWN state\nthen configure ReturnToService to 2. See the slurm.conf man page for details.\nOtherwise use scontrol or sview to manually return the node to service.</p>\n\n<p><a name=\"reqspec\"><b>How can a job which has exited with a specific exit\n  code be requeued?</b></a></br>\nSlurm supports requeue in hold with a <b>SPECIAL_EXIT</b> state using the\ncommand:</p>\n\n<pre>scontrol requeuehold State=SpecialExit job_id</pre>\n\n<p>This is useful when users want to requeue and flag a job which has exited\nwith a specific error case. See man scontrol(1) for more details.</p>\n\n<pre>\n$ scontrol requeuehold State=SpecialExit 10\n$ squeue\n   JOBID PARTITION  NAME     USER  ST       TIME  NODES NODELIST(REASON)\n    10      mira    zoppo    david SE       0:00      1 (JobHeldUser)\n</pre>\n<p>\nThe job can be later released and run again.\n</p>\n<p>\nThe requeueing of jobs which exit with a specific exit code can be\nautomated using an <b>EpilogSlurmctld</b>, see man(5) slurm.conf.\nThis is an example of a script which exit code depends on the existence\nof a file.\n</p>\n\n<pre>\n$ cat exitme\n#!/bin/sh\n#\necho \"hi! `date`\"\nif [ ! -e \"/tmp/myfile\" ]; then\n  echo \"going out with 8\"\n  exit 8\nfi\nrm /tmp/myfile\necho \"going out with 0\"\nexit 0\n</pre>\n<p>\nThis is an example of an EpilogSlurmctld that checks the job exit value\nlooking at the <b>SLURM_JOB_EXIT2</b> environment variable and requeues a job if\nit exited with value 8. The SLURM_JOB_EXIT2 has the format \"exit:sig\", the first\nnumber is the exit code, typically as set by the exit() function.\nThe second number of the signal that caused the process to terminate if\nit was terminated by a signal.\n</p>\n\n<pre>\n$ cat slurmctldepilog\n#!/bin/sh\n\nexport PATH=/bin:/home/slurm/linux/bin\nLOG=/home/slurm/linux/log/logslurmepilog\n\necho \"Start `date`\" >> $LOG 2>&1\necho \"Job $SLURM_JOB_ID exitcode $SLURM_JOB_EXIT_CODE2\" >> $LOG 2>&1\nexitcode=`echo $SLURM_JOB_EXIT_CODE2|awk '{split($0, a, \":\"); print a[1]}'` >> $LOG 2>&1\nif [ \"$exitcode\" == \"8\" ]; then\n   echo \"Found REQUEUE_EXIT_CODE: $REQUEUE_EXIT_CODE\" >> $LOG 2>&1\n   scontrol requeuehold state=SpecialExit $SLURM_JOB_ID >> $LOG 2>&1\n   echo $? >> $LOG 2>&1\nelse\n   echo \"Job $SLURM_JOB_ID exit all right\" >> $LOG 2>&1\nfi\necho \"Done `date`\" >> $LOG 2>&1\n\nexit 0\n</pre>\n<p>\nUsing the exitme script as an example, we have it exit with a value of 8 on\nthe first run, then when it gets requeued in hold with SpecialExit state\nwe touch the file /tmp/myfile, then release the job which will finish\nin a COMPLETE state.\n</p>\n\n<p><a name=\"user_account\"><b>Can a user's account be changed in the database?</b></a></br>\nA user's account can not be changed directly. A new association needs to be\ncreated for the user with the new account. Then the association with the old\naccount can be deleted.</p>\n<pre>\n# Assume user \"adam\" is initially in account \"physics\"\nsacctmgr create user name=adam cluster=tux account=physics\nsacctmgr delete user name=adam cluster=tux account=chemistry\n</pre>\n\n<p><a name=\"mpi_perf\"><b>What might account for MPI performance being below\n  the expected level?</b></a><br>\nStarting the slurmd daemons with limited locked memory can account for this.\nAdding the line \"ulimit -l unlimited\" to the <i>/etc/sysconfig/slurm</i> file can\nfix this.</p>\n\n<p><a name=\"state_info\"><b>How could some jobs submitted immediately before\n   the slurmctld daemon crashed be lost?</b></a><br>\nAny time the slurmctld daemon or hardware fails before state information reaches\ndisk can result in lost state.\nSlurmctld writes state frequently (every five seconds by default), but with\nlarge numbers of jobs, the formatting and writing of records can take seconds\nand recent changes might not be written to disk.\nAnother example is if the state information is written to file, but that\ninformation is cached in memory rather than written to disk when the node fails.\nThe interval between state saves being written to disk can be configured at\nbuild time by defining SAVE_MAX_WAIT to a different value than five.</p>\n\n<p><a name=\"delete_partition\"><b>How do I safely remove partitions?\n</b></a><br>\nPartitions should be removed using the\n\"scontrol delete PartitionName=&lt;partition&gt;\" command. This is because\nscontrol will prevent any partitions from being removed that are in use.\nPartitions need to be removed from the slurm.conf after being removed using\nscontrol or they will return after a restart.\nAn existing job's partition(s) can be updated with the \"scontrol update\nJobId=&lt;jobid&gt; Partition=&lt;partition(s)&gt;\" command.\nRemoving a partition from the slurm.conf and restarting will cancel any existing\njobs that reference the removed partitions.\n</p>\n\n<p><a name=\"cpu_freq\"><b>Why is Slurm unable to set the CPU frequency for\n   jobs?</b></a><br>\nFirst check that Slurm is configured to bind jobs to specific CPUs by\nmaking sure that TaskPlugin is configured to either affinity or cgroup.\nNext check that that your processor is configured to permit frequency\ncontrol by examining the values in the file\n<i>/sys/devices/system/cpu/cpu0/cpufreq</i> where \"cpu0\" represents a CPU ID 0.\nOf particular interest is the file <i>scaling_available_governors</i>,\nwhich identifies the CPU governors available.\nIf \"userspace\" is not an available CPU governor, this may well be due to the\n<i>intel_pstate</i> driver being installed.\nInformation about disabling the <i>intel_pstate</i> driver is available\nfrom<br>\n<a href=\"https://bugzilla.kernel.org/show_bug.cgi?id=57141\">\nhttps://bugzilla.kernel.org/show_bug.cgi?id=57141</a> and<br>\n<a href=\"http://unix.stackexchange.com/questions/121410/setting-cpu-governor-to-on-demand-or-conservative\">\nhttp://unix.stackexchange.com/questions/121410/setting-cpu-governor-to-on-demand-or-conservative</a>.</p>\n\n<p><a name=\"cluster_acct\"><b>When adding a new cluster, how can the Slurm cluster\n    configuration be copied from an existing cluster to the new cluster?</b></a><br>\nAccounts need to be configured for the cluster. An easy way to copy information from\nan existing cluster is to use the sacctmgr command to dump that cluster's information,\nmodify it using some editor, the load the new information using the sacctmgr\ncommand. See the sacctmgr man page for details, including an example.</p>\n\n<p><a name=\"cray_dvs\"><b>How can I update Slurm on a Cray DVS file system\n   without rebooting the nodes?</b></a><br>\nThe problem with DVS caching is related to the fact that the dereferenced value\nof /opt/slurm/default symlink is cached in the DVS attribute cache, and that\ncache is not dropped when the rest of the VM caches are.</p>\n\n<p>The Cray Native Slurm installation manual indicates that Slurm should\nhave a \"default\" symlink run through /etc/alternatives.\nAs an alternative to that:\n<ol>\n<li>Institute a policy that all changes to files which could be open\npersistently (i.e., .so files) are always modified by creating a new access\npath.  I.e., installations go to a new directory.</li>\n<li>Dump the /etc/alternatives stuff, just use a regular symlink, e.g., default\npoints to 15.8.0-1.</li>\n<li>Add a new mountpoint on all the compute nodes for /dsl/opt/slurm where the\nattrcache_timeout attribute is reduced from 14440s to 60s (or 15s -- whatever):<br>\nmount -t dvs /opt/slurm /dsl/opt/slurm -o<br>\npath=/dsl/opt/slurm,nodename=c0-0c0s0n0,loadbalance,cache,ro,attrcache_timeout=15<br>\nIn the example above, c0-0c0s0n0 is the single DVS server for the system.</li>\n</ol>\n<p>Using this strategy avoids the caching problems, making upgrades simple.\nOne just has to wait for about 20 seconds after changing the default symlinks\nbefore starting the slurmds again.</p>\n<p>(Information courtesy of Douglas Jacobsen, NERSC,\nLawrence Berkeley National Laboratory)</p>\n\n<p><a name=\"dbd_rebuild\"><b>How can I rebuild the database hierarchy?</b></a><br>\nIf you see errors of this sort:</p>\n<pre>\nerror: Can't find parent id 3358 for assoc 1504, this should never happen.\n</pre>\n<p>in the slurmctld log file, this is indicative that the database hierarchy\ninformation has been corrupted, typically due to a hardware failure or\nadministrator error in directly modifying the database. In order to rebuild\nthe database information, start the slurmdbd daemon with the \"-R\" option\nfollowed by an optional comma separated list of cluster names to operate on.</p>\n\n<p><a name=\"routing queue\"><b>How can a routing queue be configured?</b></a><br>\nA job submit plugin is designed to have access to a job request from a user,\nplus information about all of the available system partitions/queue.\nAn administrator can write a C plugin or LUA script to set an incoming job's\npartition based upon its size, time limit, etc.\nSee the <a href=\"https://slurm.schedmd.com/job_submit_plugins.html\"> Job Submit Plugin API</a>\nguide for more information.\nAlso see the available job submit plugins distributed with Slurm for examples\n(look in the \"src/plugins/job_submit\" directory).</p>\n\n<p><a name=\"squeue_script\"><b>How can I suspend, resume, hold or release all\n    of the jobs belonging to a specific user, partition, etc?</b></a><br>\nThere isn't any filtering by user, partition, etc. available in the scontrol\ncommand; however the squeue command can be used to perform the filtering and\nbuild a script which you can then execute. For example:\n<pre>\n$ squeue -u adam -h -o \"scontrol hold %i\" &gt;hold_script\n</pre>\n\n<p><a name=\"changed_uid\"><b>I had to change a user's UID and now they cannot submit\n    jobs. How do I get the new UID to take effect?</b></a><br>\nWhen changing UIDs, you will also need to restart the slurmctld for the changes to\ntake effect. Normally, when adding a new user to the system, the UID is filled in\nautomatically and immediately. If the user isn't known on the system yet, there is a\nthread that runs every hour that fills in those UIDs when they become known, but it\ndoesn't recognize UID changes of preexisting users. But you can simply restart the\nslurmctld for those changes to be recognized.</p>\n\n<p><a name=\"mysql_duplicate\"><b>Slurmdbd is failing to start with a 'Duplicate entry'\n    error in the database. How do I fix that?</b></a><br>\nThis problem has been rarely observed with MySQL, but not MariaDB.\nThe root cause of the failure seems to be reaching the upper limit on the auto increment field.\nUpgrading to MariaDB is recommended.\nIf that is not possible then: backup the database, remove the duplicate record(s),\nand restart the slurmdbd daemon as shown below.</p>\n<pre>\n$ slurmdbd -Dvv\n...\nslurmdbd: debug:  Table \"cray_job_table\" has changed.  Updating...\nslurmdbd: error: mysql_query failed: 1062 Duplicate entry '2711-1478734628' for key 'id_job'\n...\n\n$ mysqldump --single-transaction -u&lt;user&gt; -p&lt;user&gt; slurm_acct_db &gt;/tmp/slurm_db_backup.sql\n\n$ mysql\nmysql> use slurm_acct_db;\nmysql> delete from cray_job_table where id_job='2711-1478734628';\nmysql> quit;\nBye\n</pre>\n\n<p>If necessary, you can edit the database dump and recreate the database as\nshown below.</p>\n<pre>\n$ mysql\nmysql> drop database slurm_acct_db;\nmysql> create database slurm_acct_db;\nmysql> quit;\nBye\n\n$ mysql -u&lt;user&gt; -p&lt;user&gt; &lt;/tmp/slurm_db_backup.sql\n</pre>\n\n<p><a name=\"cray_sigbus\"><b>Why are applications on my Cray system failing\n    with SIGBUS (bus error)?</b></a><br>\nBy default, Slurm flushes Lustre file system and kernel caches upon completion\nof each job step. If multiple applications are run simultaneously on compute\nnodes (either multiple applications from a single Slurm job or multiple jobs)\nthe result can be significant performance degradation and even bus errors.\nFailures occur more frequently when more applications are executed at the same\ntime on individual compute nodes.\nFailures are also more common when Lustre file systems are used.</p>\n\n<p>Two approaches exist to address this issue.\nOne is to disable the flushing of caches, which can be accomplished by adding\n\"LaunchParameters=lustre_no_flush\" to your Slurm configuration file\n\"slurm.conf\".\nA second approach is to modify the Cray file system as described below in order to\nprevent Slurm-specific files needing to be re-resolved over DFS.\nThis second approach does not address files used by applications, only those\nused directly by Slurm.</p>\n\n<p>On Cray CLE6.0, by default, nodes get the operating system, including the\nSlurm installation and all of its plugins, via a DVS mount of \"/\".\nReally \"/\" is an overlay filesystem where the lower portion is a loop-mounted\nsquashfs layer and the upper layer is tmpfs.\nWhen buffer caches are flushed during a dlopen (used by Slurm to load its\nplugins), a timeout may result from waiting to re-resolve a Slurm plugin over\nDVS.</p>\n\n<p>The NERSC solution is to localize all files related to Slurm or involved in\nslurmstepd launch into that tmpfs layer at boot time.\nThis is possible by creating a new netroot preload file:</p>\n\n<pre>\n# cat compute-preload.nersc\n/usr/lib64/libslurm*so*\n/usr/lib64/slurm/*.so\n/usr/sbin/slurmd\n/usr/sbin/slurmstepd\n/usr/bin/sbatch\n/usr/bin/srun\n/usr/bin/sbcast\n/usr/bin/numactl\n/usr/lib64/libnuma*so*\n/lib64/ast/libast.so*\n/lib64/ast/libcmd.so*\n/lib64/ast/libdll.so*\n/lib64/ast/libshell.so*\n/lib64/libacl.so*\n/lib64/libattr.so*\n/lib64/libc.so*\n/lib64/libcap.so*\n/lib64/libdl.so*\n/lib64/libgcc_s.so*\n...\n</pre>\n\n<p>NERSC generates its preload file by including everything installed by Slurm\nRPMs plus files identified as being used by Slurm's slurmd daemon on the compute\nnode by running the \"strace -f\" command while the slurmd daemon is launching\na job step.</p>\n\n<p>Once the netroot preload file is generated, it needs to then be included in the\ncray_netroot_preload_worksheet CLE configuration. For example:</p>\n\n<pre>\ncray_netroot_preload.settings.load.data.label.compute: null\ncray_netroot_preload.settings.load.data.compute.targets: []\ncray_netroot_preload.settings.load.data.compute.content_lists:\n- dist/compute-preload.cray\n- dist/compute-preload.nersc\ncray_netroot_preload.settings.load.data.compute.size_limit: 0\n</pre>\n\n<p>This is a generally useful technique for preventing remote lookups of commonly\naccessed files within jobs.</p>\n\n<p><a name=\"sysv_memory\"><b>How do I configure Slurm to work with System V IPC\n    enabled applications?</b></a><br>\nSlurm is generally agnostic to\n<a href=\"http://man7.org/linux/man-pages/man2/ipc.2.html\">\nSystem V IPC</a> (a.k.a. \"sysv ipc\" in the Linux kernel).\nMemory accounting of processes using sysv ipc changes depending on the value\nof <a href=\"https://www.kernel.org/doc/Documentation/sysctl/kernel.txt\">\nsysctl kernel.shm_rmid_forced</a> (added in Linux kernel 3.1):\n<ul>\n<li>shm_rmid_forced = 1</li>\nForces all shared memory usage of processes to be accounted and reported by the\nkernel to Slurm. This breaks the separate namespace of sysv ipc and may cause\nunexpected application issues without careful planning. Processes that share\nthe same sysv ipc namespaces across jobs may end up getting OOM killed when\nanother job ends and their allocation percentage increases.\n<li>shm_rmid_forced = 0 (default in most Linux distributions)</li>\nSystem V memory usage will not be reported by Slurm for jobs.\nIt is generally suggested to configure the\n<a href=\"https://www.kernel.org/doc/Documentation/sysctl/kernel.txt\">\nsysctl kernel.shmmax</a> parameter. The value of kernel.shmmax times the\nmaximum number of job processes should be deducted from each node's\nconfigured RealMemory in your slurm.conf. Most Linux distributions set the\ndefault to what is effectively unlimited, which can cause the OOM killer\nto activate for unrelated new jobs or even for the slurmd process. If any\nprocesses use sysv memory mechanisms, the Linux kernel OOM killer will never\nbe able to free the used memory. A Slurm job epilog script will be needed to\nfree any of the user memory. Setting kernel.shmmax=0 will disable sysv ipc\nmemory allocations but may cause application issues.\n</ul>\n</p>\n\n<p style=\"text-align:center;\">Last modified 17 July 2020</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/job_container_plugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Job Container Plugin API</a></h1>\n\n<h2> Overview</h2>\n<p> This document describes Slurm job container plugins and the API\nthat defines them.\nIt is intended as a resource to programmers wishing to write their\nown Slurm job container plugins.\nNote that job container plugin is designed for use with Slurm jobs.\nIt also applies to the sbcast server process on compute nodes.\nThere is a <a href=\"proctrack_plugins.html\">proctrack plugin</a>\ndesigned for use with Slurm job steps.</p>\n\n<p>Slurm job container plugins are Slurm plugins that implement\nthe Slurm job container API described herein.\nThey must conform to the Slurm Plugin API with the following\nspecifications:</p>\n\n<p><span class=\"commandline\">const char plugin_type[]</span><br>\nThe major type must be &quot;job_container.&quot;\nThe minor type can be any recognizable abbreviation for the type\nof proctrack. We recommend, for example:</p>\n<ul>\n<li><b>cncu</b> &mdash; Designed for use on Cray systems only and interface with\nCompute Node Clean Up (CNCU) the Cray infrastructure.</li>\n<li><b>none</b> &mdash; Designed for all other systems.</li>\n</ul>\n\n<p><span class=\"commandline\">const char plugin_name[]</span><br>\nSome descriptive name for the plugin.\nThere is no requirement with respect to its format.</p>\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loaded by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<p>The programmer is urged to study\n<span class=\"commandline\">src/plugins/proctrack/job_container/job_container_cncu.c</span>\nfor an example implementation of a Slurm proctrack plugin.</p>\n\n<h2>Data Objects</h2>\n<p> The implementation must support a container ID of type uint64_t.\nThis container ID is generated by the\n<a href=\"proctrack_plugins.html\">proctrack plugin</a>.</p>\n\n<p>The implementation must maintain (though not necessarily directly export) an\nenumerated <b>errno</b> to allow Slurm to discover as practically as possible\nthe reason for any failed API call.\nThese values must not be used as return values in integer-valued functions\nin the API.\nThe proper error return value from integer-valued functions is SLURM_ERROR.\nThe implementation should endeavor to provide useful and pertinent information\nby whatever means is practical.\nSuccessful API calls are not required to reset errno to a known value.</p>\n\n\n<h2>API Functions</h2>\n<p>The following functions must appear. Functions which are not implemented should\nbe stubbed.</p>\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\">int container_p_create (uint32_t job_id);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Create a container.\nThe caller should ensure that the valid\n<span class=\"commandline\">container_p_delete()</span> is called.</p>\n<p style=\"margin-left:.2in\"><b>Argument</b>:\n<span class=\"commandline\"> job_id</span>&nbsp; &nbsp;&nbsp;(input)\nJob ID.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int container_p_add_cont (uint32_t job_id, uint64_t cont_id);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Add a specific process tracking\ncontainer (PAGG) to a given job's container.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> job_id</span>&nbsp; &nbsp;&nbsp;(input)\nJob ID.<br>\n<span class=\"commandline\"> cont_id</span>&nbsp; &nbsp;&nbsp;(input)\nProcess tracking container value as set by the proctrack plugin.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int container_p_delete (uint32_t job_id);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Destroy or otherwise\ninvalidate a job container.\nThis does not imply the container is empty, just that it is no longer\nneeded.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\"> job_id</span> &nbsp;&nbsp; (input)\nJob ID.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int container_p_join(uint32_t job_id, uid_t uid);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Add this process\nto a given job's container. The process is first placed into a process tracking\ncontainer (PAGG).</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> job_id</span>&nbsp; &nbsp;&nbsp;(input)\nJob ID.<br>\n<span class=\"commandline\"> uid</span>&nbsp; &nbsp;&nbsp;(input)\nOwning user ID.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">void container_p_reconfig (void);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Note change in configuration,\nespecially the value of the DebugFlags with respect to JobContainer.</p>\n\n\n<p style=\"text-align:center;\">Last modified 22 April 2019</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/jobcompplugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Slurm Job Completion Logging Plugin API</a></h1>\n\n<h2> Overview</h2>\n<p>This document describes Slurm job completion logging plugins and the API that defines\nthem. It is intended as a resource to programmers wishing to write their own Slurm\njob completion logging plugins.</p>\n<p>Slurm job completion logging plugins are Slurm plugins that implement the Slurm\nAPI for logging job information upon their completion. This may be used to log job information\nto a text file, database, etc. The plugins must conform to the Slurm Plugin API with the following\nspecifications:</p>\n<p><span class=\"commandline\">const char plugin_type[]</span><br>\nThe major type must be &quot;jobcomp.&quot; The minor type can be any recognizable\nabbreviation for the type of scheduler. We recommend, for example:</p>\n<ul>\n<li><b>none</b> &mdash; No job logging.</li>\n<li><b>elasticsearch</b> &mdash; Log job information to an Elasticsearch server.</li>\n<li><b>filetxt</b> &mdash; Log job information to a text file.</li>\n<li><b>mysql</b> &mdash; Job completion is written to a mysql database.</li>\n<li><b>script</b> &mdash; Execute a script passing in job information in environment variables.</li>\n</ul>\n\n<p><span class=\"commandline\">const char plugin_name[]</span><br>\nSome descriptive name for the plugin.\nThere is no requirement with respect to its format.</p>\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loaded by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<p>The programmer is urged to study\n<span class=\"commandline\">src/plugins/jobcomp/filetxt/jobcomp_filetxt.c</span> and\n<span class=\"commandline\">src/plugins/jobcomp/none/jobcomp_none.c</span>\nfor sample implementations of a Slurm job completion logging plugin.</p>\n\n<h2>API Functions</h2>\n<p>The following functions must appear. Functions which are not implemented should be stubbed.</p>\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\">int slurm_jobcomp_set_location (char * location);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Specify the location to be used for job logging.</p>\n<p style=\"margin-left:.2in\"><b>Argument</b>:<span class=\"commandline\"> location</span>&nbsp;\n&nbsp;&nbsp;(input) specification of where logging should be done. The interpretation of\nthis string is at the discretion of the plugin implementation.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int slurm_jobcomp_log_record(job_record_t *job_ptr);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Note that a job is about to\nterminate or change size. The job's state will include the JOB_RESIZING flag\nif and only if it is about to change size. Otherwise the job is terminating.\nNote the existence of <i>resize_time</i> in the job record if one wishes to\nrecord information about a job at each size (i.e. a history of the job as\nits size changes through time).</p>\n<p style=\"margin-left:.2in\"><b>Argument</b>: <br>\n<span class=\"commandline\"> job_ptr</span>&nbsp;&nbsp;&nbsp;(input) Pointer to\njob record as defined in <i>src/slurmctld/slurmctld.h</i></p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">\nList slurm_jobcomp_get_jobs(acct_job_cond_t *job_cond);</a></p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Get completed job info from\nstorage.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> job_cond</span>&nbsp; &nbsp;&nbsp;\n(input) specification of filters to identify the jobs we wish information about\n(start time, end time, cluster name, user id, etc).\nacct_job_cond_t is defined in common/slurm_accounting_storage.h.\n<p style=\"margin-left:.2in\"><b>Returns</b>: A list of job records or NULL on \nerror. Elements on the list are of type jobcomp_job_rec_t, which is\ndefined in common/slurm_jobcomp.h.\nAny returned list must be destroyed to avoid memory leaks.\n\n<p class=\"commandline\">\nvoid slurm_jobcomp_archive(List selected_parts, void *params)\n<p style=\"margin-left:.2in\"><b>Description</b>: used to archive old data.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">List selected_parts </span>\n(input) list containing char *'s of names of partitions to query against.<br>\n<span class=\"commandline\">void *params </span>\n(input) to be cast as sacct_parameters_t in the plugin.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None</p>\n\n\n<p style=\"text-align:center;\">Last modified 23 October 2019</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/mpiplugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Slurm MPI Plugin API</a></h1>\n\n<h2> Overview</h2>\n<p> This document describes Slurm MPI selection plugins and the API that defines\nthem. It is intended as a resource to programmers wishing to write their own Slurm\nnode selection plugins.</p>\n\n<p>Slurm MPI selection plugins are Slurm plugins that implement the which version of\nmpi is used during execution of the new Slurm job. API described herein. They are\nintended to provide a mechanism for both selecting MPI versions for pending jobs and\nperforming any mpi-specific tasks for job launch or termination. The plugins must\nconform to the Slurm Plugin API with the following specifications:</p>\n<p><span class=\"commandline\">const char plugin_type[]</span><br>\nThe major type must be &quot;mpi.&quot; The minor type can be any recognizable\nabbreviation for the type of node selection algorithm. We recommend, for example:</p>\n<ul>\n<li><b>pmi2</b> &mdash; For use with MPI2 and MVAPICH2.</li>\n<li><b>pmix</b> &mdash; Exascale PMI implementation (currently supported by\n\tOpenMPI starting from version 2.0)</li>\n<li><b>none</b> &mdash; For use with most other versions of MPI.</li>\n</ul>\n<p><span class=\"commandline\">const char plugin_name[]</span><br>\nSome descriptive name for the plugin.\nThere is no requirement with respect to its format.</p>\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loaded by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<p>A simplified flow of logic follows:\n<ul>\n<li>srun is able to specify the correct mpi to use with --mpi=MPITYPE</li>\n<li>\n\tsrun command runs\n\t<span class=\"commandline\">p_mpi_hook_client_prelaunch()</span>\n\twhich will set up the correct environment for the specified mpi.\n</li>\n<li>\n\tslurmstepd process runs\n\t<span class=\"commandline\">p_mpi_hook_slurmstepd_prefork()</span>\n\twhich will set configure the slurmd to use the correct mpi as well to interact with the srun.\n</li>\n<li>\n\tslurmstepd process runs\n\t<span class=\"commandline\">p_mpi_hook_slurmstepd_task()</span>\n\twhich executes immediately before fork/exec of each task.\n</li>\n<li>\n\tsrun command runs\n\t<span class=\"commandline\">p_mpi_hook_client_fini()</span>\n\twhich executes after all tasks have finished.\n</li>\n</ul>\n\n\n<h2>Data Objects</h2>\n<p> These functions are expected to read and/or modify data structures directly in\nthe slurmd daemon's and srun memory. Slurmd is a multi-threaded program with independent\nread and write locks on each data structure type. Therefore the type of operations\npermitted on various data structures is identified for each function.</p>\n\n<h2>Environment Variables</h2>\n<p> Slurm will set the following environment variables for plugins:</p>\n<ul>\n<li><b>SLURM_MPI_TYPE</b> &mdash; MPI plugin name that has been loaded for job. </li>\n</ul>\n\n<h2>API Functions</h2>\n<p>The following functions should be defined or at least be stubbed.</p>\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded or reloaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed or reloaded. Clear any allocated storage\n  here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p style=\"margin-left:.2in\"><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\">mpi_plugin_client_state_t*  p_mpi_hook_client_prelaunch  (const mpi_plugin_client_info_t *job, char ***env)</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Called by srun to configure the slurmd's environment\nto that of the correct mpi.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\">job</span>&nbsp;\n&nbsp;&nbsp;(input) Pointer to the Job Step (stepd_step_rec_t) that about to run.\nCannot be NULL.<br>\n<span class=\"commandline\">env</span>&nbsp;\n&nbsp;&nbsp;(input/output) Pointer to pointer of job environment to allow plugin\nto modify job environment as needed.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On\nfailure, the plugin should return SLURM_ERROR.</p>\n\n<p class=\"commandline\">int p_mpi_hook_slurmstepd_prefork(const stepd_step_rec_t *job, char ***env)</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Called by slurmstepd before\nforking to create the first job process.  Most all the real processing happens\nhere. This is not called for batch jobs and extern steps.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\">job</span>&nbsp;\n&nbsp;&nbsp;(input) Pointer to the Job Step (stepd_step_rec_t) that about to run.\nCannot be NULL.<br>\n<span class=\"commandline\">env</span>&nbsp;\n&nbsp;&nbsp;(input/output) Pointer to pointer of job environment to allow plugin\nto modify job environment as needed.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On\nfailure, the plugin should return SLURM_ERROR.</p>\n\n<p class=\"commandline\">void p_mpi_hook_slurmstepd_task(const mpi_plugin_task_info_t *job, char ***env)</p>\n<p style=\"margin-left:.2in\"><b>Description</b>:&nbsp;\nCalled by slurmstepd process immediately after fork and becoming job user, but\nimmediatly prior to exec of user task. This is not called for batch job steps\nand extern steps.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\">job</span>&nbsp;\n&nbsp;&nbsp;(input) Pointer to the Job Step (stepd_step_rec_t) that about to run.\nCannot be NULL.<br>\n<span class=\"commandline\">env</span>&nbsp;\n&nbsp;&nbsp;(input/output) Pointer to pointer of job environment to allow plugin\nto modify job environment as needed.\n</p><p style=\"margin-left:.2in\"><b>Returns</b>: void returning function. </p>\n\n<p class=\"commandline\">int p_mpi_hook_client_fini(mpi_plugin_client_state_t *state);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Called by srun after all tasks\nare complete. Cleans up anything that needs cleaning up after execution.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\">state</span>&nbsp;Launch state of MPI. Currently, a\ntypedef of void.\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On\nfailure, the plugin should return SLURM_ERROR, causing slurmctld to exit.</p>\n\n<p style=\"text-align:center;\">Last modified 15 December 2018</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/plugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Slurm Plugin API</a></h1>\n<h2>Overview</h2>\n<p>A Slurm plugin is a dynamically linked code object which is loaded explicitly\nat run time by the Slurm libraries. A plugin provides a customized implementation\nof a well-defined API connected to tasks such as authentication, interconnect\nfabric, and task scheduling.</p>\n<h2>Identification</h2>\n<p>A Slurm plugin identifies itself by a short character string formatted similarly\nto a MIME type: <i>&lt;major&gt;/&lt;minor&gt;</i>. The major type identifies\nwhich API the plugin implements. The minor type uniquely distinguishes a plugin\nfrom other plugins that implement that same API, by such means as the intended\nplatform or the internal algorithm. For example, a plugin to interface to the\nMaui scheduler would give its type as &quot;sched/maui.&quot; It would implement\nthe Slurm Scheduler API.</p>\n\n<h2>Versioning</h2>\n<p>Slurm plugin version numbers comprise a major, minor and micro revision number.\nIf the major and/or minor revision number changes, this indicates major changes\nto the Slurm functionality including changes to APIs, command options, and\nplugins.\nThese plugin changes may include new functions and/or function arguments.\nIf only the micro revision number changes, this is indicative of bug fixes\nand possibly minor enhancements which should not adversely impact users.\nIn all cases, rebuilding and installing all Slurm plugins is recommended\nat upgrade time.\nNot all compute nodes in a cluster need be updated at the same time, but\nall Slurm APIs, commands, plugins, etc. on a compute node should represent\nthe same version of Slurm.</p>\n\n\n<h2>Data Objects</h2>\n\n<p>A plugin must define and export the following symbols:</p>\n<ul>\n<li><span class=\"commandline\">char plugin_type[]<br>\n</span> a unique, short, formatted string to identify the plugin's purpose as\ndescribed above. A &quot;null&quot; plugin (i.e., one that implements the desired\nAPI as stubs) should have a minor type of &quot;none.&quot;</li>\n<li><span class=\"commandline\">char plugin_name[]<br>\n</span> a free-form string that identifies the plugin in human-readable terms,\nsuch as &quot;Kerberos authentication.&quot; Slurm will use this string to identify\nthe plugin to end users.</li>\n</ul>\n<p>A plugin may optionally define and export the following symbols:</p>\n<ul>\n<li>const uint32_t plugin_version<br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loaded by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n</ul>\n\n<h2>API Functions in All Plugins</h2>\n<p class=\"commandline\">int init (void);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: If present, this function is called\njust after the plugin is loaded. This allows the plugin to perform any global\ninitialization prior to any actual API calls.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>: None.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if the plugin's initialization\nwas successful. Any other return value indicates to Slurm that the plugin should\nbe unloaded and not used.</p>\n<p class=\"commandline\">void fini (void);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: If present, this function is called\njust before the plugin is unloaded. This allows the plugin to do any finalization\nafter the last plugin-specific API call is made.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>: None.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n<p>The functions need not appear. The plugin may provide either\n<span class=\"commandline\">init()</span> or <span class=\"commandline\">fini()</span> or both.</p>\n<h2>Thread Safety</h2>\n\n<p>Slurm is a multithreaded application. The Slurm plugin library may exercise\nthe plugin functions in a re-entrant fashion. It is the responsibility of the\nplugin author to provide the necessarily mutual exclusion and synchronization\nin order to avoid the pitfalls of re-entrant code.</p>\n<h2>Run-time Support</h2>\n<p>The standard system libraries are available to the plugin. The Slurm libraries\nare also available and plugin authors are encouraged to make use of them rather\nthan develop their own substitutes. Plugins should use the Slurm log to print\nerror messages.</p>\n<p>The plugin author is responsible for specifying any specific non-standard libraries\nneeded for correct operation. Plugins will not load if their dependent libraries\nare not available, so it is the installer's job to make sure the specified libraries\nare available.</p>\n<h2>Performance</h2>\n<p>All plugin functions are expected to execute very quickly. If any function\nentails delays (e.g. transactions with other systems), it should be written to\nutilize a thread for that functionality. This thread may be created by the\n<span class=\"commandline\">init()</span> function and deleted by the\n<span class=\"commandline\">fini()</span> functions. See <b>plugins/sched/backfill</b>\nfor an example of how to do this.</p>\n\n<h2>Data Structure Consistency</h2>\n\n<p>\n  In certain situations Slurm iterates over different data structures elements\n  using counters. For example, with environment variable arrays.\n  In order to avoid buffer overflows and other undesired situations, when a\n  plugin modifies certain elements it must also update these counters accordingly.\n  Other situations may require other types of changes.\n</p>\n<p>\n  The following advice indicates which structures have arrays with associated\n  counters that must be maintained when modifying data, plus other possible\n  important information to take in consideration when manipulating these\n  structures.\n  This list is not fully exhaustive due to constant modifications in code,\n  but it is a first start point and basic guideline for most common situations.\n  Complete structure information can be seen in the <i>slurm/slurm.h.in</i>\n  file.\n</p>\n\n<h3>slurm_job_info_t (job_info_t) Data Structure</h3>\n<pre>\n  uint32_t env_size;\n  char **environment;\n\n  uint32_t spank_job_env_size;\n  char **spank_job_env;\n\n  uint32_t gres_detail_cnt;\n  char **gres_detail_str;\n</pre>\n<p>\n  These pairs of array pointers and element counters must kept updated in order\n  to avoid subsequent buffer overflows, so if you update the array you must\n  also update the related counter.\n</p>\n<pre>\n  char *nodes;\n  int32_t *node_inx;\n\n  int32_t *req_node_inx;\n  char *req_nodes;\n</pre>\n<p>\n  <i>node_inx</i> and <i>req_node_inx</i> represents a list of index pairs for\n  ranges of nodes defined in the <i>nodes</i> and <i>req_nodes</i> fields\n  respectively. In each case, both array variables must match the count.\n</p>\n<pre>\n  uint32_t het_job_id;\n  char *het_job_id_set;\n</pre>\n<p>\n  The <i>het_job_id</i> field should be the first element of the\n  <i>het_job_id_set</i> array.\n</p>\n\n<h3>job_step_info_t Data Structure</h3>\n<pre>\n  char *nodes;\n  int32_t *node_inx;\n</pre>\n<p>\n  <i>node_inx</i> represents a list of index pairs for range of nodes defined in\n  <i>nodes</i>. Both variables must match the node count.\n</p>\n\n<h3>priority_factors_object_t Data Structure</h3>\n<pre>\n  uint32_t tres_cnt;\n  char **tres_names;\n  double *tres_weights;\n</pre>\n<p>\n  This value must match the configured TRES on the system, otherwise\n  iteration over the <i>tres_names</i> or <i>tres_weights</i> arrays can cause\n  buffer overflows.\n</p>\n\n<h3>job_step_pids_t Data Structure</h3>\n<pre>\n  uint32_t pid_cnt;\n  uint32_t *pid;\n</pre>\n<p>\n  Array <i>pid</i> represents the list of Process IDs for the job step, and\n  <i>pid_cnt</i> is the counter that must match the size of the array.\n</p>\n\n<h3>slurm_step_layout_t Data Structure</h3>\n<pre>\n  uint32_t node_cnt;\n  char *node_list;\n</pre>\n<p>\n  The <i>node_list</i> array size must match <i>node_cnt</i>.\n</p>\n<pre>\n  uint16_t *tasks;\n  uint32_t node_cnt;\n  uint32_t task_cnt;\n</pre>\n<p>\n  In the <i>tasks</i> array, each element is the number of tasks assigned\n  to the corresponding node, to its size must match <i>node_cnt</i>. Moreover\n  <i>task_cnt</i> represents the sum of tasks registered in <i>tasks</i>.\n</p>\n<pre>\n  uint32_t **tids;\n</pre>\n<p>\n  <i>tids</i> is an array of length <i>node_cnt</i> of task ID arrays. Each\n  subarray is designated by the corresponding value in the <i>tasks</i> array,\n  so <i>tasks</i>, <i>tids</i> and <i>task_cnt</i> must be set to match this\n  layout.\n</p>\n\n<h3>slurm_step_launch_params_t Data Structure</h3>\n<pre>\n  uint32_t envc;\n  char **env;\n</pre>\n<p>\n  When modifying the environment variables in the <i>env</i> array, you must\n  also modify the <i>envc</i> counter accordingly to prevent buffer overflows\n  in subsequent loops over that array.\n</p>\n<pre>\n  uint32_t het_job_nnodes;\n  uint32_t het_job_ntasks;\n\n  uint16_t *het_job_task_cnts;\n  uint32_t **het_job_tids;\n  uint32_t *het_job_node_list;\n</pre>\n<p>\n  This <i>het_job_*</i> related variables must match the current heterogeneous\n  job configuration.\n  <br>\n  For example, if for whatever reason you are reducing the number of tasks for\n  a node in a heterogeneous job, you should at least remove that task ID from\n  <i>het_job_tids</i>, decrement <i>het_job_ntasks</i> and\n  <i>het_job_task_cnts</i>, and possibly decrement the number of nodes of the\n  heterogeneous job in <i>het_job_nnodes</i> and <i>het_job_node_list</i>.\n</p>\n<pre>\n  char **spank_job_env;\n  uint32_t spank_job_env_size;\n</pre>\n<p>\n  When modifying the <i>spank_job_env</i> structure, the\n  <i>spank_job_env_size</i> field must be updated to prevent buffer overflows\n  in subsequent loops over that array.\n</p>\n\n<h3>node_info_t Data Structure</h3>\n<pre>\n  char *features;\n  char *features_act;\n</pre>\n<p>\n  In a system containing Intel KNL processors the <i>features_act</i> field is\n  set by the plugin to match the currently running modes on the node. On other\n  systems the <i>features_act</i> is not usually used.\n  If you program such a plugin you must ensure that <i>features_act</i> contains\n  a subset of <i>features</i>.\n</p>\n<pre>\nchar *reason;\ntime_t reason_time;\nuint32_t reason_uid;\n</pre>\n<p>\n  If <i>reason</i> is modified then <i>reason_time</i> and <i>reason_uid</i>\n  should be updated.\n</p>\n\n<h3>reserve_info_t Data Structure</h3>\n<pre>\n  int32_t *node_inx;\n  uint32_t node_cnt;\n</pre>\n<p>\n  <i>node_inx</i> represents a list of index pairs for range of nodes associated\n  with the reservation and its count must equal <i>node_cnt</i>.\n</p>\n\n<h3>partition_info_t Data Structure</h3>\n<p>\n  No special advice.\n</p>\n\n<h3>slurm_step_layout_req_t Data Structure</h3>\n<p>\n  No special advice.\n</p>\n\n<h3>slurm_step_ctx_params_t</h3>\n<p>\n  No special advice.\n</p>\n\n\n<p style=\"text-align:center;\">Last modified 20 January 2020</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/bb_plugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Burst Buffer Plugin Programmer Guide</a></h1>\n\n<h2> Overview</h2>\n<p> This document describes the Slurm burst buffer plugins and the\nAPIs that defines them. It is intended as a resource to programmers\nwishing to write their own Slurm burst buffer plugin.\n\n<p>Slurm burst buffer plugins must conform to the\nSlurm Plugin API with the following specifications:\n\n<p><span class=\"commandline\">const char\nplugin_name[]=\"<i>full&nbsp;text&nbsp;name</i>\"</span>\n<p style=\"margin-left:.2in\">\nA free-formatted ASCII text string that identifies the plugin.\n\n<p><span class=\"commandline\">const char\nplugin_type[]=\"<i>major/minor</i>\"</span><br>\n<p style=\"margin-left:.2in\">\n\nThe major type must be &quot;burst_buffer&quot;.\nThe minor type can be any suitable name for the type of burst buffer\npackage.\nThe following burst buffer plugins are included in the Slurm distribution\n<ul>\n<li><b>datawrap</b> &mdash; Use Cray APIs to provide burst buffer.</li>\n<li><b>generic</b> &mdash; Use generic burst buffer plugin.</li>\n</ul>\n\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loaded by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<h2>API Functions</h2>\n<p>All of the following functions are required. Functions which are not\nimplemented must be stubbed.\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nCalled when the plugin is loaded, before any other functions are\ncalled. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nCalled when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\">\nint bb_p_load_state(bool init_config)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nThis function loads the current state of the burst buffer.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">init_config</span>\n(input) true if called as part of slurmctld initialization.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\nA Slurm errno\n\n<p class=\"commandline\">\nint bb_p_state_pack(uid_t uid, Buf buffer, uint16_t protocol_version)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nPack current burst buffer state information for network transmission.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">uid</span>\n(input) Owning user ID.<br>\n<span class=\"commandline\">buffer</span>\n(input) buffer that will be packed.<br>\n<span class=\"commandline\">protocol_version</span>\n(input) Version number of the data packing mechanism.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\nA Slurm errno\n\n<p class=\"commandline\">\nint bb_p_reconfig(void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nReread the burst buffer config file when it is updated.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\nA Slurm errno\n\n<p class=\"commandline\">\nuint64_t bb_p_get_system_size(char *name)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nGet the total burst buffer size in MB of a given plugin name.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">name</span>\n(input) Plugin name of the burst buffer. If name is NULL, return the total\nspace of all burst buffer plugins.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\nThe size of the burst buffer in MB.\n\n<p class=\"commandline\">\nint bb_p_job_validate(job_desc_msg_t *job_desc, uid_t submit_uid)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nValidation of a job submit request with respect to burst buffer option.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job_desc</span>\n(input) Job submission request.<br>\n<span class=\"commandline\">submit_uid</span>\n(input) ID of the user submitting the job.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\nA Slurm errno.\n\n<p class=\"commandline\">\nint bb_p_job_validate2(job_record_t *job_ptr, char **err_msg)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nValidation of a job submit request with respect to burst buffer option.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job_ptr</span>\n(input) Job record for the job request with respect to burst buffer.<br>\n<span class=\"commandline\">err_msg</span>\n(output) Error message, sent directlt to job submission command<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\nA Slurm errno.\n\n<p class=\"commandline\">\nvoid bb_p_job_set_tres_cnt(job_record_t *job_ptr,\nuint64_t *tres_cnt, bool locked);\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nSet the tres count in the job recored.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job_ptr</span>\n(input) Job record to be set.<br>\n<span class=\"commandline\">tres_cnt</span>\n(input/output) Fill in this already allocated array with tres_cnts<br>\n<span class=\"commandline\">locked</span>\n(input) If tres read lock is locked or not.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\nNone\n\n<p class=\"commandline\">\ntime_t bb_p_job_get_est_start(job_record_t *job_ptr)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nGet an estimation of when a job can start.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job_ptr</span>\n(input) Start time of this job.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\nEstimated start time of job_ptr.\n\n<p class=\"commandline\">\nint bb_p_job_try_stage_in(void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nAllocate burst buffers to jobs expected to start soonest.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\nA Slurm errno\n\n<p class=\"commandline\">\nint bb_p_job_test_stage_in(job_record_t *job_ptr, bool test_only)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nDetermine if a job's burst buffer stage-in is complete.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job_ptr</span>\n(input) Job record to test.<br>\n<span class=\"commandline\">test_only</span>\n(input) If false, then attempt to load burst buffer if possible.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n0 stage-in is underway<br>\n1 stage-in complete<br>\n-1 state-in not started or burst buffer in some unexpeced state.\n\n<p class=\"commandline\">\nint bb_p_job_begin(job_record_t *job_ptr)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nAttempt to claim burst buffer resources.<br>\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job_ptr</span>\n(input) Job record to test.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\nA Slurm errno\n\n<p class=\"commandline\">\nint bb_p_job_revoke_alloc(job_record_t *job_ptr)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nRevoke allocation, but do not release resources.\nExecuted after bb_g_job_begin if there was an allocation failure.\nDoes not release previously allocated resources.<br>\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job_ptr</span>\n(input) Job record to test.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\nA Slurm errno\n\n<p class=\"commandline\">\nint bb_p_job_start_stage_out(job_record_t *job_ptr)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nTrigger a job's burst buffer stage out to begin.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job_ptr</span>\n(input) Job to stage out.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\nA Slurm errno\n\n<p class=\"commandline\">\nint bb_p_job_test_post_run(job_record_t *job_ptr)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nDetermine of jobs's post run operation is complete.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job_ptr</span>\n(input) Job to check if post run operation is complete.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n0 - post run operation is underway<br>\n1 - post run operation complete<br>\n-1 - fatal error\n\n<p class=\"commandline\">\nint bb_p_job_test_stage_out(job_record_t *job_ptr)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nDetermine of jobs's stage out is complete.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job_ptr</span>\n(input) Job to check if stage out is complete.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n0 - stage-out is underway<br>\n1 - stage-out complete<br>\n-1 - fatal error\n\n<p class=\"commandline\">\nint bb_p_job_cancel(job_record_t *job_ptr)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nTerminate any file staging and release burst buffer resources.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job_ptr</span>\n(input) Job to cancel.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\nA Slurm errno\n\n<p class=\"commandline\">\nchar *bb_p_xlate_bb_2_tres_str(char *burst_buffer)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nTranslate burst buffer string to TRES string.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">burst_buffer</span>\n(input) Burst buffer to translate to TRES string<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\nThe TRES string of the given burst buffer (Note: User must xfree the\nreturn value).\n\n\n<p style=\"text-align:center;\">Last modified 23 October 2019</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/gres_plugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Slurm Generic Resource (GRES) Plugin API</a></h1>\n\n<h2>Overview</h2>\n<p>This document describes Slurm generic resource (GRES) plugins and the API\nthat defines them. It is intended as a resource to programmers wishing to write\ntheir own Slurm GRES plugins.</p>\n\n<p>Slurm GRES plugins must conform to the\nSlurm Plugin API with the following specifications:</p>\n\n<span class=\"commandline\">const char *plugin_type=\"<i>major/minor</i>\"</span>\n<p style=\"margin-left:.2in\">\n<span class=\"commandline\"><i>major</i></span> must be\n<span class=\"commandline\">gres</span>.\n<span class=\"commandline\"><i>minor</i></span> can be any suitable name\nrepresenting the GRES type of the plugin.</p>\n\n<span class=\"commandline\">const char *plugin_name</span>\n<p style=\"margin-left:.2in\">\nSome descriptive name for the plugin.\nThere is no requirement with respect to its format.</p>\n\n<span class=\"commandline\">const uint32_t plugin_version</span>\n<p style=\"margin-left:.2in\">\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loaded by Slurm commands and\ndaemons from any version; however, this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<p>We include samples in the Slurm distribution for:\n<ul>\n<li><b>gpu</b> &mdash; Manage GPUs (Graphics Processing Units).\n<li><b>mps</b> &mdash; Manage MPS (CUDA Multi-Process Service).\n</ul>\n\n\n<h2>API Functions</h2>\n<p>All of the following functions are required. Functions which are not\nimplemented must be stubbed.\n\n<p class=\"commandline\"> int init(void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: None.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini(void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: None.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: <span class=\"commandline\">init()</span> and\n<span class=\"commandline\">fini()</span> are not the same as those\ndescribed in the <span class=\"commandline\">dlopen(3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\">\nint node_config_load(List gres_conf_list, node_config_load_t *config)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nThis function is called by the <i>slurmd</i> daemon after the <i>slurm.conf</i>\nand <i>gres.conf</i> files have been read.\nIt can be used to validate or infer the system configuration by testing the\nactual hardware resources available or just confirm that an entry for the\nresource was included in the <i>gres.conf</i> file.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">gres_conf_list</span>\n(input/output) a list of configuration records generated by reading the\n<i>slurm.conf</i> and <i>gres.conf</i> files<br>\n<span class=\"commandline\">config</span>\n(input) Additional data. Contains fields\n<span class=\"commandline\">cpu_cnt</span> and\n<span class=\"commandline\">xcpuinfo_mac_to_abs</span>.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nvoid job_set_env(char ***job_env_ptr, void *gres_ptr, int node_inx)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nThis function is called by the <i>slurmd</i> daemon after the getting a job\ncredential and can be used to set environment variables for the job based\nupon GRES state information in that credential.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job_env_ptr</span>\n(input/output) pointer to the job's environment variable structure.<br>\n<span class=\"commandline\">gres_ptr</span>\n(input) pointer to the job's GRES allocation information.<br>\n<span class=\"commandline\">node_inx</span>\n(input) zero origin node index, used to interpret node-specific GRES data.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p class=\"commandline\">\nvoid step_set_env(char ***job_env_ptr, void *gres_ptr)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nThis function is called by the <i>slurmd</i> daemon after the getting a job\nstep credential and can be used to set environment variables for the job step\nbased upon GRES state information in that credential.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job_env_ptr</span>\n(input/output) pointer to the job step's environment variable structure.<br>\n<span class=\"commandline\">gres_ptr</span>\n(input) pointer to the step's GRES allocation information.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p class=\"commandline\">\nvoid send_stepd(int fd)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nThis function is called by the <i>slurmd</i> daemon to send any needed\ninformation to the <i>slurmstepd</i> step shepherd.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">fd</span>\n(input) file descriptor to write information to.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p class=\"commandline\">\nvoid recv_stepd(int fd)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nThis function is called by the <i>slurmstepd</i> step shepherd to read any\nneeded information from the <i>slurmd</i> daemon.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">fd</span>\n(input) file descriptor to read information from.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p class=\"commandline\">\nint job_info(gres_job_state_t *job_gres_data, uint32_t node_inx,\nenum gres_job_data_type data_type, void *data)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nThis function is used to extract plugin-specific data from the job's GRES\ndata structure. Note that\n<span class=\"commandline\">enum gres_job_data_type</span> values\n<span class=\"commandline\">GRES_JOB_DATA_COUNT</span> and\n<span class=\"commandline\">GRES_JOB_DATA_BITMAP</span> are processed in common\ncode rather than within the plugin and return data types of\n<span class=\"commandline\">uint32_t*</span> and\n<span class=\"commandline\">bitstr_t**</span>, respectively.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job_gres_data</span>\n(input) Information about the job's GRES resources.<br>\n<span class=\"commandline\">node_inx</span>\n(input) Zero origin index within the job's resource allocation for which\ndata is desired.<br>\n<span class=\"commandline\">data_type</span>\n(input) Type of information to be gathered from the data structure.<br>\n<span class=\"commandline\">data</span>\n(output) Pointer to data within <span class=\"commandline\">job_gres_data</span>.\nNo data is copied or needs to be freed.\nData type depends upon the value of\n<span class=\"commandline\">data_type</span>.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint step_info(gres_step_state_t *step_gres_data, uint32_t node_inx,\nenum gres_step_data_type data_type, void *data)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nThis function is used to extract plugin-specific data from the step's GRES\ndata structure. Note that\n<span class=\"commandline\">enum gres_job_data_type</span> values\n<span class=\"commandline\">GRES_JOB_DATA_COUNT</span> and\n<span class=\"commandline\">GRES_JOB_DATA_BITMAP</span> are processed in common\ncode rather than within the plugin and return data types of\n<span class=\"commandline\">uint32_t*</span> and\n<span class=\"commandline\">bitstr_t**</span>, respectively.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">step_gres_data</span>\n(input) Information about the step's GRES resources.<br>\n<span class=\"commandline\">node_inx</span>\n(input) Zero origin index within the job's resource allocation for which\ndata is desired.<br>\n<span class=\"commandline\">data_type</span>\n(input) Type of information to be gathered from the data structure.<br>\n<span class=\"commandline\">data</span>\n(output) Pointer to data within <span class=\"commandline\">step_gres_data</span>.\nNo data is copied or needs to be freed.\nData type depends upon the value of <span class=\"commandline\">data_type</span>.\n<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nList get_devices(void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nThis function returns the list of GRES devices.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: None.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\nReturns a <span class=\"commandline\">List</span> of GRES device records of type\n<span class=\"commandline\">gres_slurmd_conf_t</span>.\n\n<p class=\"commandline\">\nvoid step_hardware_init(bitstr_t *usable_gres, char *settings)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nConfigure device hardware corresponding to all the GRES devices of the plugin\ntype. The <i>slurmstepd</i> calls this function while privileged and before\ntasks are forked and executed. The\n<i>gres/gpu</i> plugin sets GPU frequencies\nhere.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">usable_gres</span>\n(input) A bit string specifying all GRES devices of the plugin type allocated\nto the step.<br>\n<span class=\"commandline\">settings</span>\n(input) A string containing device hardware settings to be set for all specified\nhardware devices.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p class=\"commandline\">\nvoid step_hardware_fini(void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nDo hardware configuration after the step is finished while privileged. This is\nmeant to allow Slurm to undo hardware configuration changes performed by\n<span class=\"commandline\">step_hardware_init()</span>.\nThe <i>slurmstepd</i> calls this function while privileged and after tasks\ncomplete. The <i>gres/gpu</i> plugin resets GPU frequencies to high here.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>: None.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p class=\"commandline\">\ngres_epilog_info_t *epilog_build_env(gres_job_state_t *gres_job_ptr)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nGiven a job's GRES allocation data, translated that to the data required by\n<span class=\"commandline\">epilog_set_env()</span> to set environment variables\nfor the <i>Prolog</i> and <i>Epilog</i> programs.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">gres_job_ptr</span>\n(input) job's GRES allocation data.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: Data structure containing the\ninformation required by <span class=\"commandline\">epilog_set_env()</span>\nto set environment variables for the <i>Prolog</i> and <i>Epilog</i>\nprograms.</p>\n\n<p class=\"commandline\">\nvoid epilog_set_env(char ***epilog_env_ptr, gres_epilog_info_t *epilog_info,\nint node_inx)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nSet GRES specific environment variables for the <i>Prolog</i> and\n<i>Epilog</i> programs.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">epilog_env_ptr</span>\n(input) environment variables set for the <i>Prolog</i> and <i>Epilog</i>\nprograms. This array may be reallocated as needed to contain additional\nenvironment variables.<br>\n<span class=\"commandline\">epilog_info</span>\n(input) GRES specific job allocation information. Built by\n<span class=\"commandline\">epilog_build_env()</span>.<br>\n<span class=\"commandline\">node_inx</span>\n(input) zero-origin index of this node in the job's allocation. Needed to\nidentify the resources on a specific node allocated to this job.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p style=\"text-align:center;\">Last modified 5 March 2019</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/power_plugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Power Management Plugin Programmer Guide</a></h1>\n\n<h2> Overview</h2>\n<p> This document describes the Slurm power management plugins and the APIs that\ndefines them. It is intended as a resource to programmers wishing to write\ntheir own Slurm power management plugin. This is version 100 of the API.\n\n<p>Slurm power management plugins must conform to the\nSlurm Plugin API with the following specifications:\n\n<p><span class=\"commandline\">const char\nplugin_name[]=\"<i>full&nbsp;text&nbsp;name</i>\"</span>\n<p style=\"margin-left:.2in\">\nA free-formatted ASCII text string that identifies the plugin.\n\n<p><span class=\"commandline\">const char\nplugin_type[]=\"<i>major/minor</i>\"</span><br>\n<p style=\"margin-left:.2in\">\nThe major type must be &quot;power&quot;.\nThe minor type can be any suitable name for the type of power management\npackage.\nThe following power management plugins are included in the Slurm distribution\n<ul>\n<li><b>cray_aries</b> &mdash; Use Cray XC APIs to provide power management.</li>\n<li><b>none</b> &mdash; Can be configured to log calls to its functions, but\notherwise does nothing.</li>\n</ul>\n\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loaded by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<p>Slurm can be configured to use multiple power management plugins if desired.</p>\n\n\n<h2>API Functions</h2>\n<p>All of the following functions are required. Functions which are not\nimplemented must be stubbed.\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\">\nvoid power_p_reconfig(void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nThis function is called when updated configuration information should be read.\n\n<p class=\"commandline\">\nvoid power_p_job_resume(job_record_t *job_ptr)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nNote that a previously suspended job is being resumed.\nCalled by the slurmctld daemon.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job_ptr</span>\n(input) pointer to the job record being resumed.\n\n<p class=\"commandline\">\nvoid power_p_job_start(job_record_t *job_ptr)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nNote that a job has been allocated resources and is about to begin execution.\nCalled by the slurmctld daemon.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job_ptr</span>\n(input) pointer to the job record being started.\n\n\n<p style=\"text-align:center;\">Last modified 23 October 2019</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/priority_plugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Slurm Priority Plugin API</a></h1>\n\n<h2> Overview</h2>\n<p> This document describes Slurm priority plugins and the API that defines\nthem. It is intended as a resource to programmers wishing to write their own\nSlurm priority plugins.</p>\n\n<p>Slurm priority plugins are Slurm plugins that implement the Slurm priority\nAPI described herein. They must conform to the Slurm Plugin API with the\nfollowing specifications:</p>\n\n<p><span class=\"commandline\">const char\nplugin_type[]=\"<i>major/minor</i>\"</span><br>\nThe major type must be &quot;priority.&quot; The minor type can be any\nrecognizable abbreviation for the type of priority.\nWe recommend, for example:</p>\n\n<ul>\n<li><b>basic</b> &mdash; A plugin that implements the API and provides basic FIFO\njob priority.</li>\n<li><b>multifactor</b> &mdash; The multi-factor job priority plugin.</li>\n</ul>\n\n<p><span class=\"commandline\">const char plugin_name[]</span><br>\nSome descriptive name for the plugin.\nThere is no requirement with respect to its format.</p>\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loaded by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<p>The programmer is urged to study\n<span class=\"commandline\">src/plugins/priority/basic/priority_basic.c</span>\nfor an example implementation of a Slurm priority plugin.</p>\n\n\n<h2>Data Objects</h2>\n<p>The implementation must maintain (though not necessarily directly export) an\nenumerated <b>errno</b> to allow Slurm to discover as practically as possible\nthe reason for any failed API call.  Plugin-specific enumerated integer values\nmay be used when appropriate.</p>\n\n<p>These values must not be used as return values in integer-valued functions\nin the API. The proper error return value from integer-valued functions is\nSLURM_ERROR. The implementation should endeavor to provide useful and pertinent\ninformation by whatever means is practical. Successful API calls are not\nrequired to reset any errno to a known value. However, the initial value of any\nerrno, prior to any error condition arising, should be SLURM_SUCCESS. </p>\n\n<p class=\"commandline\"> job_record</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: A slurmctld structure that\ncontains details about a job.</p>\n\n<p class=\"commandline\"> acct_assoc_rec_t</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: A slurm_accounting_storage\nstructure that contains details about an association.</p>\n\n<p class=\"commandline\"> priority_factors_object_t</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: A structure that contains a\njob's priority factors.</p>\n\n<p class=\"commandline\"> priority_factors_request_msg_t</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Used to request job priority\nfactors.  Contains a list of specific job and user ids of the jobs the user\nwants to see.</p>\n\n<p class=\"commandline\"> priority_factors_response_msg_t</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Used to return the list of\npriority_factors_object_t's containing the job priority factors the user has\nasked to see.</p>\n\n\n<h2>API Functions</h2>\n<p>The following functions must appear. Functions which are not implemented should\nbe stubbed.</p>\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\">uint32_t priority_p_set(uint32_t last_prio, job_record_t *job_ptr)</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Sets the priority of the job.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\">last_prio</span> (input) the priority assigned to the\nlast job<br>\n<span class=\"commandline\">job_ptr</span> (input) pointer to the job record.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: the priority assigned to the job</p>\n\n<p class=\"commandline\">void priority_p_reconfig(bool assoc_clear)</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Refresh the plugin's\nconfiguration. Called whenever slurmctld is reconfigured.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\">assoc_clear</span> (input) true if association\nand QOS used_cpu_run_secs field has been reset. This should be set to true\nwhen Slurm is reconfigured, but false if an RPC is used to change only the\ndebug level of debug flags.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: void</p>\n\n<p class=\"commandline\">void priority_p_set_assoc_usage(acct_assoc_rec_t *assoc)</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Set the normalized and\neffective usage for an association.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\">assoc</span> (input/output) pointer to the association.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: void</p>\n\n<p class=\"commandline\">List priority_p_get_priority_factors_list(priority_factors_request_msg_t *req_msg)</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Retrieves the priority factors\nfor all or specified jobs.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\">req_msg</span> (input) pointer to the message request\nthat contains the specific jobs or users of interest (of any).</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: a list of priority_factors_object_t's\ncontaining the requested job priority factors</p>\n\n<p class=\"commandline\">void priority_p_job_end(job_record_t *job_ptr)</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Handle ending of job\n  with decayable limits.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\">job_ptr</span> (input) pointer to the job record.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: void</p>\n\n\n<p style=\"text-align:center;\">Last modified 23 October 2019</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/authplugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Slurm Authentication Plugin API</a></h1>\n\n<h2> Overview</h2>\n<p> This document describes Slurm authentication plugins and the API that defines\nthem. It is intended as a resource to programmers wishing to write their own Slurm\nauthentication plugins.</p>\n<p>Slurm authentication plugins are Slurm plugins that implement the Slurm authentication\nAPI described herein. They must conform to the Slurm Plugin API with the following\nspecifications:</p>\n<p><span class=\"commandline\">const char plugin_type[]</span><br>\nThe major type must be &quot;auth.&quot; The minor type can be any recognizable\nabbreviation for the type of authentication. We recommend, for example:</p>\n<ul>\n<li><b>none</b> &mdash; A plugin that implements the API without providing any actual\nauthentication service. This may be used for testing purposes, but is not suitable for\nproduction use due to lack of effective security.</li>\n<li><b>munge</b> &mdash; LLNL's Munge protocol (recommended plugin for production use).</li>\n</ul>\n\n<p><span class=\"commandline\">const char plugin_name[]</span><br>\nSome descriptive name for the plugin.\nThere is no requirement with respect to its format.</p>\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loaded by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<p>The programmer is urged to study <span class=\"commandline\">src/plugins/auth/none/auth_none.c</span>\nfor an example implementation of a Slurm authentication plugin.</p>\n<h2>Data Objects</h2>\n<p> The implementation must support an opaque class, which it defines, to be used\nas an authentication &quot;credential.&quot; This class must encapsulate all user-specific\ninformation necessary for the operation of the API specification below. The credential\nis referred to in Slurm code by an anonymous pointer (void *).</p>\n\n<h2>API Functions</h2>\n<p>The following functions must appear. Functions which are not implemented should\nbe stubbed.</p>\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\">void *slurm_auth_create(char *auth_info);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Allocates from the free store\nan anonymous credential object and returns a pointer to it. The pointer should\nbe valid until passed to <span class=\"commandline\">slurm_auth_destroy()</span> for\ndisposal. Slurm will not pass\ncredentials to the API which have not been allocated by this function.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\">argv</span> &nbsp;&nbsp;(input) plugin specific\ninformation.\n<span class=\"commandline\">auth_info</span> &nbsp;&nbsp;(input) plugin specific\nidentification of the server.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: A pointer to a newly allocated credential\nif successful. On failure, the plugin should return NULL and set its errno to\nan appropriate value to indicate the reason for failure.</p>\n<p class=\"commandline\">int slurm_auth_destroy (void *cr);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Deallocates a credential that\nwas allocated with <span class=\"commandline\">slurm_auth_alloc()</span> and any\nassociated storage that has been allocated for it during its use.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<span class=\"commandline\"> cr</span>&nbsp;\n&nbsp;&nbsp;(input) pointer to the credential that is to be deallocated. Cannot\nbe NULL.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int slurm_auth_verify (void *cr, char *auth_info );</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Verifies that a credential is\nin order and correctly identifies the associated user. It also verifies that the\ncredential has not expired. If verification is successful, the return values of\n<span class=\"commandline\">slurm_auth_get_uid()</span> and\n<span class=\"commandline\">slurm_auth_get_gid()</span>\nin subsequent calls must correspond to the actual verified system UID and GID\nof the user associated with the credential. Verification must fail if the credential\nhas not previously been activated, even if a credential implementation cannot\nexist in an unactivated state. A credential's valid term is defined at activation\nand verification must fail if the credential has expired, even if it would otherwise\nbe valid.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">cr</span> &nbsp;&nbsp;(input) pointer to the credential\nwhich is to be verified. Cannot be NULL.<br>\n<span class=\"commandline\">auth_info</span> &nbsp;&nbsp;(input) plugin specific\nidentification of the server.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if the credential is\nverified to be in order and has not expired. If the credential cannot be verified,\nor if the credential has expired, the function should return SLURM_ERROR and set\nits errno to an appropriate value to indicate the reason for failure.</p>\n\n<p class=\"commandline\">uid_t slurm_auth_get_uid(void *cred);<br>\ngid_t slurm_auth_get_gid (void *cred);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Extracts the numerical UID or GID\nof the user corresponding to the given credential.\nOnly valid after <span class=\"commandline\">slurm_auth_verify()</span> has\nbeen called on a given credential.\nAn unverified credential does not immediately give rise to an error condition\nin these functions, but instead will return SLURM_AUTH_NOBODY for the UID and GID.\nA plugin may consider the lack of verification as an error.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n <span class=\"commandline\">cred</span> &nbsp;&nbsp; (input) pointer to the credential\ncontaining the desired identification.  Cannot be NULL.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: If successful, the Linux UID (GID)\nassociated with the credential. In case of error, SLURM_AUTH_NOBODY should be\nreturned and errno set appropriately to indicate the cause of the failure.</p>\n\n<p class=\"commandline\">int slurm_auth_pack (void *cr, Buf buf);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Marshals a credential into a buffer\nfor transmission according to the Slurm packing protocol. All authentication plugins\nmust first pack the plugin_type and then the plugin_version data before any plugin-specific\ndata elements are packed. slurm_auth_pack() and slurm_auth_pack() are strictly\nreciprocal. The esult of a packing followed by an unpacking must be a functionally\nequivalent credential. A credential is deemed appropriate for marshalling at any\ntime after its allocation and before its destruction.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\">cr</span>&nbsp; &nbsp;&nbsp;(input) pointer to the credential\nto pack.<br>\n<span class=\"commandline\">buf</span>&nbsp;&nbsp;&nbsp; (input/output) the buffer\ninto which the credential should be packed.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure\nthe plugin should return SLURM_ERROR and set the errno to indicate the reason\nfor the failure.</p>\n<p class=\"commandline\">int slurm_auth_unpack (void *cr, Buf buf);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Unmarshals a credential from a\nbuffer according to the Slurm packing protocol into a supplied (and presumed empty)\ncredential object. The unmarshalled credential is not assumed to be activated\nor verified. The <span class=\"commandline\">plugin_type</span> and <span class=\"commandline\">plugin_version</span>\ndata should first be unpacked from the buffer and verified for applicability.\nThe API does not enforce that they must be equivalent, merely compatible. Compatibility\nis implementation-dependent.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\">cr</span> &nbsp;&nbsp;&nbsp;(output) pointer to the\ncredential to pack.<br>\n<span class=\"commandline\">buf</span> &nbsp;&nbsp;&nbsp;(input/output) the buffer\nfrom which the credential should be unpacked.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if the credential was\nsuccessfully unpacked. In case of failure, the function should return SLURM_ERROR\nand set errno appropriately to indicate the cause of the failure. If the function\nfails, no assumptions are made about the state of the credential except its suitability\nfor destruction via <span class=\"commandline\">slurm_auth_destroy()</span>.</p>\n\n<p style=\"text-align:center;\">Last modified 7 March 2019</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/cli_filter_plugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">cli_filter Plugin API</a></h1>\n\n<h2>Overview</h2>\n<p>This document describes Slurm cli_filter plugins and the API that\ndefines them. It is intended as a resource to programmers wishing to write\ntheir own Slurm cli_filter plugins.</p>\n\n<p> The purpose of the cli_filter plugins is to provide programmatic hooks\nduring the execution of the <b>salloc</b>, <b>sbatch</b>, and <b>srun</b>\ncommand line interface (CLI) programs. Three hooks are defined:\n<ul>\n<li><b>setup_defaults</b> &mdash; Called before any option processing is done,\n<i>per job component</i>, allowing a plugin to replace default option\nvalues.</li>\n<li><b>pre_submit</b> &mdash; Called after option processing <i>per job\ncomponent</i> but before any communication\nis made with the slurm controller. This location\nis ideal for policy enforcement because the plugin can read all the options\nsupplied by the user (as well as the environment) - thus invalid job requests\ncan be stopped before they ever reach the slurmctld.</li>\n<li><b>post_submit</b> &mdash; Called after the jobid (and, in the case of\n<b>srun</b>, after the stepid) is generated, and typically before or in\nparallel with job execution.  In combination with data collected in the\npre_submit() hook, this is an ideal location for logging activity.</li>\n</p>\n\n<p>\ncli_filter plugins vary from the <a href=\"job_submit_plugins.html\">job_submit\nplugin</a> as it is entirely executed client-side, whereas job_submit is\nprocessed server-side (within the slurm controller). The benefit of the\ncli_filter is that it has access to all command line options in a simple and\nconsistent interface as well as being safer to run disruptive operations\n(e.g., quota checks or other long running operations you might want to use\nfor integrating policy decisions), which can be problematic if run from the\ncontroller. The disadvantage of the cli_filter is that it must not be relied\nupon for security purposes as an enterprising user can circumvent it simply\nby providing loading an alternate slurm.conf with the CliFilterPlugins option\ndisabled. If you plan to use the cli_filter for managing policies, you should\nalso configure a job_submit plugin to reinforce those policies.</p>\n\n<p>Slurm cli_filter plugins must conform to the\nSlurm Plugin API with the following specifications:</p>\n\n<p><span class=\"commandline\">const char\nplugin_name[]=\"<i>full&nbsp;text&nbsp;name</i>\"</span>\n<p style=\"margin-left:.2in\">\nA free-formatted ASCII text string that identifies the plugin.\n\n<p><span class=\"commandline\">const char\nplugin_type[]=\"<i>major/minor</i>\"</span><br>\n<p style=\"margin-left:.2in\">\nThe major type must be &quot;cli_filter.&quot;\nThe minor type can be any suitable name for the type of job submission package.\nWe include samples in the Slurm distribution for\n<ul>\n<li><b>none</b> &mdash; An empty plugin with no actions taken, a useful starting\ntemplate for a new plugin.</li>\n</ul>\n\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loaded by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<p>Slurm can be configured to use multiple cli_filter plugins if desired,\nhowever the lua plugin will only execute one lua script named \"cli_filter.lua\"\nlocated in the default script directory (typically the subdirectory \"etc\" of\nthe installation directory).</p>\n\n\n<h2>API Functions</h2>\n<p>All of the following functions are required. Functions which are not\nimplemented must be stubbed.\n\n<p class=\"commandline\">int init(void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\">void fini(void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\">int setup_defaults(slurm_opt_t *options, bool early)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nThis function is called by the salloc, sbatch, or srun command line interface\n(CLI) programs shortly before processing any options from the environment,\ncommand line, or script (#SBATCH). The hook may be run multiple times per job\ncomponent, once for an early pass (if implemented by the CLI), and again for\nthe main pass.\nThe options and early arguments are meant to be passed to <b>slurm_option_set()</b>\nwhich will set the option if it is in the appropriate pass. Failures to set\nan option may be a symptom of trying to set the option on the wrong pass. Given\nthat you should not return SLURM_ERROR simply because of a failure to set an option.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">options</span>\n(input) slurm option data structure; meant to be passed to the slurm_option_* API\nwithin <i>src/common/slurm_opt.h</i>.<br>\n<span class=\"commandline\">early</span>\n(input) boolean indicating if this is the early pass or not; meant to be passed to\nthe slurm_option_* API within <i>src/common/slurm_opt.h</i>.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure, will terminate execution\nof the CLI.\n\n<p class=\"commandline\">int pre_submit(slurm_opt_t *options, int offset)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nThis function is called by the CLI after option processing but before any\ncommunication with the slurmctld is made.  This is after all setup_defaults()\nhooks are executed (for the current job component), environment variables\nprocessed, command line options and #SBATCH directives interpreted.\n<b>pre_submit()</b> is called before any parts of\nthe data structure are rewritten, so it is safe to\nboth read and write or unset any options from the plugin that you desire.\nNote that post_submit() cannot safely read (or write) the options, so you should\nsave any state for logging in post_submit() during pre_submit(). This function is\ncalled once per job component.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">options</span>\n(input/output) the job allocation request specifications.<br>\n<span class=\"commandline\">offset</span>\n(input) integer value for the current hetjob offset; should be used as a key when\nstoring data for communication between pre_submit() and post_submit().<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure, will terminate execution\nof the CLI.\n\n<p class=\"commandline\">void post_submit(int offset, uint32_t jobid, uint32_t stepid)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nThis function is called by the CLI after a jobid (and, if srun, a stepid) has\nbeen assigned by the controller.  It is no longer safe to read or write to the\noptions data structure, so it has been removed from this function.  You should\nsave any state you need in pre_submit() using het_job_offset as a key, since\nthe function is called separately for every job component, and access\nit here.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">offset</span>\n(input) integer value for the current hetjob offset; should be used as a key\nwhen storing data for communication between pre_submit() and post_submit().<br>\n<span class=\"commandline\">jobid</span>\n(input) job id of the job<br>\n<span class=\"commandline\">stepid</span>\n(input) step id of the job if appropriate, NO_VAL otherwise<br>\n\n<p style=\"text-align:center;\">Last modified 2 June 2020</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/ext_sensorsplugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">External Sensors Plugin API (ExtSensorsType)</a></h1>\n\n<h2> Overview</h2>\n<p> This document describe. Slurm external sensors plugins and the API that\ndefines them. It is intended as a resource to programmers wishing to write\ntheir own Slurm external sensors plugins.\n\n<p>Slurm external sensors plugins must conform to the\nSlurm Plugin API with the following specifications:\n\n<p><span class=\"commandline\">const char\nplugin_name[]=\"<i>full&nbsp;text&nbsp;name</i>\"</span>\n<p style=\"margin-left:.2in\">\nA free-formatted ASCII text string that identifies the plugin.\n\n<p><span class=\"commandline\">const char\nplugin_type[]=\"<i>major/minor</i>\"</span><br>\n<p style=\"margin-left:.2in\">\nThe major type must be &quot;ext_sensors.&quot;\nThe minor type can be any suitable name\nfor the type of external sensors. We currently use\n<ul>\n<li><b>none</b> &mdash; No external sensors data is collected.\n<li><b>rrd</b> &mdash; Gets external sensors data from the\nRRD database.\n</ul>\n\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loaded by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<p>The programmer is urged to study\n<span class=\"commandline\">src/plugins/ext_sensors/rrd</span> and\n<span class=\"commandline\">src/common/slurm_ext_sensors.c</span>\nfor a sample implementation of a Slurm external sensors plugin.\n\n<h2>API Functions</h2>\n<p>All of the following functions are required. Functions which are not\nimplemented must be stubbed.\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\">extern int ext_sensors_read_conf(void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nReads the external sensors plugin configuration file (ext_sensors.conf)\nand populates the configuration structure.\nCalled by the slurmctld daemon.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\"> None</span>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">extern int ext_sensors_free_conf(void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nFrees the memory allocated for the external sensors configuration.\nCalled by the slurmctld daemon.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\"> None</span>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">extern int ext_sensors_p_update_component_data(void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUpdates external sensors data for data types and component types as configured\nin ext_sensors.conf.\nCalled by the slurmctld daemon.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\"> None</span>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">extern int ext_sensors_p_get_stepstartdata(step_record_t *step_rec)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nSets external sensors data in the step record when a job step starts.\nCalled by slurmctld.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\"> step_rec</span> (input) pointer to step record.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">extern int ext_sensors_p_get_stependdata(step_record_t *step_rec)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nSets external sensors data in the step record when a job step ends.\nCalled by slurmctld.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\"> step_rec</span> (input) pointer to step record.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<h2>Parameters</h2>\n<p>These parameters can be used in the slurm.conf to configure the\nplugin and the frequency at which to gather external sensors data.</p>\n<dl>\n<dt><span class=\"commandline\">ExtSensorsType</span>\n<dd>Specifies which external sensors plugin should be used.\n<dt><span class=\"commandline\">ExtSensorsFreq</span>\n<dd>Time interval between pollings in seconds.\n</dl>>\n\n\n<p style=\"text-align:center;\">Last modified 23 October 2019</p>\n\n<!--#include virtual=\"footer.txt\"-->\n"
    },
    "skipped": [
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/contribs/cray/libalps_test_programs.tar.gz",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/plane_ex1.gif",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/plane_ex7.gif",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/k_function.gif",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/Slurm_Individual.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/hdf5_job_outline.png",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/arch.gif",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/schedmd.png",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/ibm_pe_fig2.png",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/ibm_pe_fig1.png",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/squeue_color.png",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/plane_ex6.gif",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/plane_ex4.gif",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/allocation_pies.gif",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/plane_ex3.gif",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/plane_ex5.gif",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/coding_style.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/rosetta.gif",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/mc_support.gif",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/plane_ex2.gif",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/topo_ex1.gif",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/slurm_logo.png",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/entities.gif",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/Slurm_Entity.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/hdf5_task_attr.png",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/fonts.ttf",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/example_usage.gif",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/topo_ex2.gif",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-20-02-4-1-t6ggqgntav2fdfy5ib3ifouqdnf6m5tu/spack-src/doc/html/usage_pies.gif"
    ],
    "total_files": 2557
}