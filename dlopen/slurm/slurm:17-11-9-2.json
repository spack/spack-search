{
    "matches": {
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/BUILD.NOTES": "This information is meant primarily for the Slurm developers. \nSystem administrators should read the instructions at\nhttps://slurm.schedmd.com/quickstart_admin.html\n(also found in the file doc/html/quickstart_admin.shtml).\nThe \"INSTALL\" file contains generic Linux build instructions.\n\nSimple build/install on Linux:\n  ./configure --enable-debug \\\n              --prefix=<install-dir> --sysconfdir=<config-dir>\n  make\n  make install\n\nTo build the files in the contribs directory:\n  make contrib\n  make install-contrib\n  (The RPMs are built by default)\n\nIf you make changes to any auxdir/* or Makefile.am file, then run\n_snowflake_ (where there are recent versions of autoconf, automake \nand libtool installed):\n ./autogen.sh\nthen check-in the new Makefile.am and Makefile.in files\n\nHere is a step-by-step HOWTO for creating a new release of Slurm on a\nLinux cluster (See BlueGene and AIX specific notes below for some differences).\n0. Get current copies of Slurm and buildfarm\n   > git clone https://<user_name>@github.com/chaos/slurm.git\n   > svn co https://eris.llnl.gov/svn/chaos/private/buildfarm/trunk buildfarm\n   place the buildfarm directory in your search path\n   > export PATH=~/buildfarm:$PATH\n1. Update NEWS and META files for the new release. In the META file,\n   the API, Major, Minor, Micro, Version, and Release fields must all\n   by up-to-date. **** DON'T UPDATE META UNTIL RIGHT BEFORE THE TAG ****\n   The Release field should always be 1 unless one of\n   the following is true\n   - Changes were made to the spec file, documentation, or example\n     files, but not to code.\n   - this is a prerelease (Release = 0.preX)\n2. Tag the repository with the appropriate name for the new version.\n   Note the first three digits are the version number. For a proper release,\n   the last digit is \"1\" (except for a rebuild without code changes which\n   could be \"2\"). For pre-releases, the last digit should be \"0\" followed by\n   \"pre#\" or \"rc#\".\n   > git tag -a slurm-2-6-7-1 -m \"create tag v2.6.7\"  OR\n   > git tag -a slurm-2-7-0-0pre5 -m \"create tag v2.7.0-pre5\"\n   > git push --tags\n3. Use the rpm make target to create the new RPMs. This requires a .rpmmacros \n   (.rpmrc for newer versions of rpmbuild) file containing:\n\t%_slurm_sysconfdir      /etc/slurm\n\t%_with_debug            1\n\t%_with_sgijob\t\t1\n   NOTE: build will make a tar-ball based upon ALL of the files in your current\n   local directory. If that includes scratch files, everyone will get those\n   files in the tar-ball. For that reason, it is a good idea to clone a clean\n   copy of the repository and build from that\n   > git clone https://<user_name>@github.com/chaos/slurm.git <local_dir>\n   Build using the following syntax:\n   > build  --snapshot   -s <local_dir>  OR\n   > build  --nosnapshot -s <local_dir>\n   --nosnapshot will name the tar-ball and RPMs based upon the META file\n   --snapshot will name the tar-ball and RPMs based upon the META file plus a\n   timestamp. Do this to make a tar-ball for a non-tagged release.\n   NOTE: <local_dir> should be a fully-qualified pathname\n4. scp the files to schedmd.com in to ~/www/download/latest or\n   ~/www/download/development. Move the older files to ~/www/download/archive,\n   login to schedmd.com, cd to ~/download, and execute \"php process.php\" to\n   update the web pages.\n\nBlueGene build notes:\n0. If on a bgp system and you want sview export these variables\n   > export CFLAGS=\"-I/opt/gnome/lib/gtk-2.0/include -I/opt/gnome/lib/glib-2.0/include $CFLAGS\"\n   > export LIBS=\"-L/usr/X11R6/lib64 $LIBS\"\n   > export CMD_LDFLAGS='-L/usr/X11R6/lib64'\n   > export PKG_CONFIG_PATH=\"/opt/gnome/lib64/pkgconfig/:$PKG_CONFIG_PATH\"\n1. Use the rpm make target to create the new RPMs. This requires a .rpmmacros\n   (.rpmrc for newer versions of rpmbuild) file containing:\n\t%_prefix                /usr\n\t%_slurm_sysconfdir      /etc/slurm\n\t%_with_bluegene         1\n\t%_without_pam\t\t1\n\t%_with_debug            1\n   Build on Service Node with using the following syntax\n   > rpmbuild -ta slurm-...bz2\n   The RPM files get written to the directory\n   /usr/src/packages/RPMS/ppc64\n\nTo build and run on AIX:\n0. Get current copies of Slurm and buildfarm\n   > git clone https://<user_name>@github.com/chaos/slurm.git\n   > svn co https://eris.llnl.gov/svn/chaos/private/buildfarm/trunk buildfarm\n   put the buildfarm directory in your search path\n   > export PATH=~/buildfarm:$PATH\n\n   Put the buildfarm directory in your search path\n   Also, you will need several commands to appear FIRST in your PATH:\n\n      /usr/local/tools/gnu/aix_5_64_fed/bin/install\n      /usr/local/gnu/bin/tar\n      /usr/bin/gcc\n\n   I do this by making symlinks to those commands in the buildfarm directory,\n   then making the buildfarm directory the first one in my PATH.\n   Also, make certain that the \"proctrack\" rpm is installed.\n1. Export some environment variables\n   > export OBJECT_MODE=32\n   > export PKG_CONFIG=\"/usr/bin/pkg-config\"\n2. Build with:\n   > ./configure --enable-debug --prefix=/opt/freeware \\\n\t--sysconfdir=/opt/freeware/etc/slurm \\\n\t--with-ssl=/opt/freeware --with-munge=/opt/freeware \\\n\t--with-proctrack=/opt/freeware\n   make\n   make uninstall  # remove old shared libraries, aix caches them\n   make install\n3. To build RPMs (NOTE: GNU tools early in PATH as described above in #0):\n   Create a .rpmmacros file specifying system specific files:\n\t#\n\t# RPM Macros for use with Slurm on AIX\n\t# The system-wide macros for RPM are in /usr/lib/rpm/macros\n\t# and this overrides a few of them\n\t#\n\t%_prefix                /opt/freeware\n\t%_slurm_sysconfdir      %{_prefix}/etc/slurm\n        %_defaultdocdir         %{_prefix}/doc\n\t%_with_debug            1\n\t%_with_aix\t\t1\n\t%with_ssl               \"--with-ssl=/opt/freeware\"\n\t%with_munge             \"--with-munge=/opt/freeware\"\n\t%with_proctrack         \"--with-proctrack=/opt/freeware\"\n   Log in to the machine \"uP\".  uP is currently the lowest-common-denominator\n   AIX machine.\n   NOTE: build will make a tar-ball based upon ALL of the files in your current\n   local directory. If that includes scratch files, everyone will get those\n   files in the tar-ball. For that reason, it is a good idea to clone a clean\n   copy of the repository and build from that\n   > git clone https://<user_name>@github.com/chaos/slurm.git <local_dir>\n   Build using the following syntax:\n   > export CC=/usr/bin/gcc\n   > build  --snapshot   -s <local_dir>  OR\n   > build  --nosnapshot -s <local_dir>\n   --nosnapshot will name the tar-ball and RPMs based upon the META file\n   --snapshot will name the tar-ball and RPMs based upon the META file plus a\n   timestamp. Do this to make a tar-ball for a non-tagged release.\n4. Test POE after telling POE where to find Slurm's LoadLeveler wrapper.\n   > export MP_RMLIB=./slurm_ll_api.so\n   > export CHECKPOINT=yes\n5. > poe hostname -rmpool debug\n6. To debug, set SLURM_LL_API_DEBUG=3 before running poe - will create a file\n     /tmp/slurm.*\n   It can also be helpful to use poe options \"-ilevel 6 -pmdlog yes\"\n   There will be a log file create named /tmp/mplog.<jobid>.<taskid>\n7. If you update proctrack, be sure to run \"slibclean\" to clear cached\n   version.\n8. Remove the RPMs that we don't want:\n   rm -f slurm-perlapi*rpm slurm-torque*rpm\n   and install the other RPMs into /usr/admin/inst.images/slurm/aix5.3 on an \n   OCF AIX machine (pdev is a good choice).\n\nDebian build notes:\nSince Debian doesn't have PRMs, the rpmbuild program can not locate\ndependencies, so build without them by patching the build program:\nIndex: build\n===================================================================\n--- build       (revision 173)\n+++ build       (working copy)\n@@ -798,6 +798,7 @@\n     $cmd .= \" --define \\\"_tmppath $rpmdir/TMP\\\"\";\n     $cmd .= \" --define \\\"_topdir $rpmdir\\\"\";\n     $cmd .= \" --define \\\"build_bin_rpm 1\\\"\";\n+    $cmd .= \" --nodeps\";\n     if (defined $conf{rpm_dist}) {\n         my $dist = length $conf{rpm_dist} ? $conf{rpm_dist} : \"%{nil}\";\n         $cmd .= \" --define \\\"dist $dist\\\"\";\n\nAIX/Federation switch window problems\nTo clean switch windows:     ntblclean =w 8 -a sni0\nTo get switch window status: ntblstatus\n\nBlueGene bglblock boot problem diagnosis\n  - Logon to the Service Node (bglsn, ubglsn)\n  - Execute /admin/bglscripts/fatalras\n    This will produce a list of failures including Rack and Midplane number\n    <date> R<rack> M<midplane> <failure details>\n  - Translate the Rack and Midplane to Slurm node id: smap -R r<rack><midplane>\n  - Drain only the bad Slurm node, return others to service using scontrol\n\nConfiguration file update procedures:\n  - cd /usr/bgl/dist/slurm (on bgli)\n  - co -l <filename>\n  - vi <filename>\n  - ci -u <filename>\n  - make install\n  - then run \"dist_local slurm\" on SN and FENs to update /etc/slurm\n\nSome RPM commands:\n  rpm -qa | grep slurm                  (determine what is installed)\n  rpm -qpl slurm-1.1.9-1.rpm            (check contents of an rpm)\n  rpm -e slurm-1.1.8-1                  (erase an rpm)\n  rpm --upgrade slurm-1.1.9-1.rpm       (replace existing rpm with new version)\n  rpm -i --ignoresize slurm-1.1.9-1.rpm (install a new rpm)\nFor main Slurm plugin installation on BGL service node:\n  rpm -i --force --nodeps --ignoresize slurm-1.1.9-1.rpm\n  rpm -U --force --nodeps --ignoresize slurm-1.1.9-1.rpm  (upgrade option)\n\nTo clear a wedged job:\n  /bgl/startMMCSconsole\n  > delete bgljob ####\n  > free RMP###\n\nStarting and stopping daemons on Linux:\n  /etc/init.d/slurm stop\n  /etc/init.d/slurm start\n\nPatches:\n  - cd to the top level src directory\n  - Run the patch command with epilog_complete.patch as stdin:\n    patch -p[path_level_to_filter] [--dry-run] < epilog_complete.patch\n\nTo get the process and job IDs with proctrack/sgi_job:\n  - jstat -p\n\nCVS and gnats:\nInclude \"gnats:<id> e.g. \"(gnats:123)\" as part of cvs commit to\nautomatically record that update in gnats database. NOTE: Does\nnot change gnats bug state, but records source files associated\nwith the bug.\n\nFor memory leaks (for AIX use zerofault, zf; for linux use valgrind)\n - Run configure with the option \"--enable-memory-leak-debug\" to completely\n   release allocated memory when the daemons exit\n - valgrind --tool=memcheck --leak-check=yes --num-callers=8 --leak-resolution=med \\\n   ./slurmctld -Dc >valg.ctld.out 2>&1\n - valgrind --tool=memcheck --leak-check=yes --num-callers=8 --leak-resolution=med \\\n   ./slurmd -Dc >valg.slurmd.out 2>&1    (Probably only one one node of cluster)\n - valgrind --tool=memcheck --leak-check=yes --num-callers=8 --leak-resolution=med \\\n   ./slurmdbd -D >valg.dbd.out 2>&1\n - Run the regression test. In the globals.local file include:\n   \"set enable_memory_leak_debug 1\"\n - Shutdown the daemons using \"scontrol shutdown\"\n - Examine the end of the log files for leaks. pthread_create() and dlopen()\n   have small memory leaks on some systems, which do not grow over time\n - Functions in the plugins will not have their symbols preserved when the\n   plugin is unloaded and the function names will appear as \"???\" in the\n   valgrind backtrace after shutdown. Rebuilding the daemons without the\n   configure option of \"--enable-memory-leak-debug\" typically prevents the\n   plugin from being unloaded so the symbols will be properly reported. However\n   many memory leaks will be reported due to not unloading plugins. You will\n   need to match the call sequence from the first log (with\n   \"--enable-memory-leak-debug\") to the second log (without\n   \"--enable-memory-leak-debug\" and ignore memory leaks reported that are not\n   real leaks in the second log) to identify the full code path through plugins.\n\nJob profiling:\n - \"export CFLAGS=-pg\", then run \"configure\" and \"make install\" as usual.\n - Run the slurm daemons through a stress test and exit normally\n - Run \"gprof [executable-file] >outfile\"\n\nBefore new major release:\n - Test on ia64, i386, x86_64, BGQ, NRT/POE, Cray\n - Test on Elan and IB switches\n - Test fail-over of slurmctld\n - Test pam_slurm and pam_slurm_adopt.\n - Test for memory leaks in slurmctld, slurmd and slurmdbd with various plugins\n - Change API version number\n - Run \"make check\" (requires \"dejagnu\" package)\n - Test that the prolog and epilog run\n - Run the test suite with SlurmUser NOT being self\n - Test for errors reported by CLANG tool:\n   NOTE: Run \"configure\" with \"--enable-developer\" option so assert functions\n   take effect.\n   scan-build -k -v make >m.sb.out 2>&1 \n   # and look for output in /tmp/scan-build-<DATE>\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/src/common/xlua.c": "/*****************************************************************************\\\n *  xlua.h - Lua integration common functions\n *****************************************************************************\n *  Copyright (C) 2015 SchedMD LLC.\n *  Written by Tim Wickberg <tim@schedmd.com>\n *\n *  This file is part of SLURM, a resource management program.\n *  For details, see <https://slurm.schedmd.com/>.\n *  Please also read the included file: DISCLAIMER.\n *\n *  SLURM is free software; you can redistribute it and/or modify it under\n *  the terms of the GNU General Public License as published by the Free\n *  Software Foundation; either version 2 of the License, or (at your option)\n *  any later version.\n *\n *  In addition, as a special exception, the copyright holders give permission\n *  to link the code of portions of this program with the OpenSSL library under\n *  certain conditions as described in each individual source file, and\n *  distribute linked combinations including the two. You must obey the GNU\n *  General Public License in all respects for all of the code used other than\n *  OpenSSL. If you modify file(s) with this exception, you may extend this\n *  exception to your version of the file(s), but you are not obligated to do\n *  so. If you do not wish to do so, delete this exception statement from your\n *  version.  If you delete this exception statement from all source files in\n *  the program, then also delete it here.\n *\n *  SLURM is distributed in the hope that it will be useful, but WITHOUT ANY\n *  WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n *  FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more\n *  details.\n *\n *  You should have received a copy of the GNU General Public License along\n *  with SLURM; if not, write to the Free Software Foundation, Inc.,\n *  51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA.\n\\*****************************************************************************/\n\n#include \"src/common/xlua.h\"\n\n#ifdef HAVE_LUA\n# include <lua.h>\n#else\n# define LUA_VERSION_NUM 0\n#endif\n/*\n *  Common function to dlopen() the appropriate Lua libraries, and\n *   ensure the lua version matches what we compiled against.\n */\nint xlua_dlopen(void)\n{\n\t/*\n\t *  Need to dlopen() liblua.so with RTLD_GLOBAL in order to\n\t *   ensure symbols from liblua are available to libs opened\n\t *   by any lua scripts.\n\t */\n\tif (!LUA_VERSION_NUM) {\n\t\tfatal(\"Slurm wasn't configured against any LUA lib but you are trying to use it like it was.  Please check config.log and reconfigure against liblua.  Make sure you have lua devel installed.\");\n\t} else if (!dlopen(\"liblua.so\",       RTLD_NOW | RTLD_GLOBAL) &&\n#if LUA_VERSION_NUM == 503\n\t\t   !dlopen(\"liblua-5.3.so\",   RTLD_NOW | RTLD_GLOBAL) &&\n\t\t   !dlopen(\"liblua5.3.so\",    RTLD_NOW | RTLD_GLOBAL) &&\n\t\t   !dlopen(\"liblua5.3.so.0\",  RTLD_NOW | RTLD_GLOBAL) &&\n\t\t   !dlopen(\"liblua.so.5.3\",   RTLD_NOW | RTLD_GLOBAL)\n#elif LUA_VERSION_NUM == 502\n\t\t   !dlopen(\"liblua-5.2.so\",   RTLD_NOW | RTLD_GLOBAL) &&\n\t\t   !dlopen(\"liblua5.2.so\",    RTLD_NOW | RTLD_GLOBAL) &&\n\t\t   !dlopen(\"liblua5.2.so.0\",  RTLD_NOW | RTLD_GLOBAL) &&\n\t\t   !dlopen(\"liblua.so.5.2\",   RTLD_NOW | RTLD_GLOBAL)\n#else\n\t\t   !dlopen(\"liblua-5.1.so\",   RTLD_NOW | RTLD_GLOBAL) &&\n\t\t   !dlopen(\"liblua5.1.so\",    RTLD_NOW | RTLD_GLOBAL) &&\n\t\t   !dlopen(\"liblua5.1.so.0\",  RTLD_NOW | RTLD_GLOBAL) &&\n\t\t   !dlopen(\"liblua.so.5.1\",   RTLD_NOW | RTLD_GLOBAL)\n#endif\n\t\t) {\n\t\treturn error(\"Failed to open liblua.so: %s\", dlerror());\n\t}\n\treturn SLURM_SUCCESS;\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/src/common/xlua.h": "/*****************************************************************************\\\n *  xlua.h - Lua integration common functions\n *****************************************************************************\n *  Copyright (C) 2015 SchedMD LLC.\n *  Written by Tim Wickberg <tim@schedmd.com>\n *\n *  This file is part of SLURM, a resource management program.\n *  For details, see <https://slurm.schedmd.com/>.\n *  Please also read the included file: DISCLAIMER.\n *\n *  SLURM is free software; you can redistribute it and/or modify it under\n *  the terms of the GNU General Public License as published by the Free\n *  Software Foundation; either version 2 of the License, or (at your option)\n *  any later version.\n *\n *  In addition, as a special exception, the copyright holders give permission\n *  to link the code of portions of this program with the OpenSSL library under\n *  certain conditions as described in each individual source file, and\n *  distribute linked combinations including the two. You must obey the GNU\n *  General Public License in all respects for all of the code used other than\n *  OpenSSL. If you modify file(s) with this exception, you may extend this\n *  exception to your version of the file(s), but you are not obligated to do\n *  so. If you do not wish to do so, delete this exception statement from your\n *  version.  If you delete this exception statement from all source files in\n *  the program, then also delete it here.\n *\n *  SLURM is distributed in the hope that it will be useful, but WITHOUT ANY\n *  WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n *  FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more\n *  details.\n *\n *  You should have received a copy of the GNU General Public License along\n *  with SLURM; if not, write to the Free Software Foundation, Inc.,\n *  51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA.\n\\*****************************************************************************/\n\n#ifndef _SLURM_XLUA_H\n#define _SLURM_XLUA_H\n\n#include <dlfcn.h>\n#include <stdio.h>\n\n#include \"slurm/slurm.h\"\n#include \"slurm/slurm_errno.h\"\n#include \"src/common/log.h\"\n\nint xlua_dlopen();\n\n#endif\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/src/common/plugin.c": "/*****************************************************************************\\\n *  plugin.h - plugin architecture implementation.\n *****************************************************************************\n *  Copyright (C) 2002-2007 The Regents of the University of California.\n *  Copyright (C) 2008-2009 Lawrence Livermore National Security.\n *  Produced at Lawrence Livermore National Laboratory (cf, DISCLAIMER).\n *  Written by Jay Windley <jwindley@lnxi.com>.\n *  CODE-OCEC-09-009. All rights reserved.\n *  Portions Copyright (C) 2012 SchedMD LLC.\n *  Written by Danny Auble <da@schedmd.com>\n *\n *  This file is part of SLURM, a resource management program.\n *  For details, see <https://slurm.schedmd.com/>.\n *  Please also read the included file: DISCLAIMER.\n *\n *  SLURM is free software; you can redistribute it and/or modify it under\n *  the terms of the GNU General Public License as published by the Free\n *  Software Foundation; either version 2 of the License, or (at your option)\n *  any later version.\n *\n *  In addition, as a special exception, the copyright holders give permission\n *  to link the code of portions of this program with the OpenSSL library under\n *  certain conditions as described in each individual source file, and\n *  distribute linked combinations including the two. You must obey the GNU\n *  General Public License in all respects for all of the code used other than\n *  OpenSSL. If you modify file(s) with this exception, you may extend this\n *  exception to your version of the file(s), but you are not obligated to do\n *  so. If you do not wish to do so, delete this exception statement from your\n *  version.  If you delete this exception statement from all source files in\n *  the program, then also delete it here.\n *\n *  SLURM is distributed in the hope that it will be useful, but WITHOUT ANY\n *  WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n *  FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more\n *  details.\n *\n *  You should have received a copy of the GNU General Public License along\n *  with SLURM; if not, write to the Free Software Foundation, Inc.,\n *  51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA.\n\\*****************************************************************************/\n\n#include \"config.h\"\n\n#include <dlfcn.h>\n#include <errno.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <sys/stat.h>\n#include <sys/types.h>\n#include <unistd.h>\n\n#include \"src/common/xmalloc.h\"\n#include \"src/common/log.h\"\n#include \"src/common/plugrack.h\"\n#include \"src/common/strlcpy.h\"\n#include \"src/common/xstring.h\"\n#include \"src/common/slurm_protocol_api.h\"\n#include \"slurm/slurm_errno.h\"\n\nstrong_alias(plugin_get_syms,         slurm_plugin_get_syms);\nstrong_alias(plugin_load_and_link,    slurm_plugin_load_and_link);\nstrong_alias(plugin_strerror,         slurm_plugin_strerror);\nstrong_alias(plugin_unload,           slurm_plugin_unload);\n\n/* dlerror() on AIX sometimes fails, revert to strerror() as needed */\nstatic char *_dlerror(void)\n{\n\tint error_code = errno;\n\tchar *rc = dlerror();\n\n\tif ((rc == NULL) || (rc[0] == '\\0'))\n\t\trc = strerror(error_code);\n\n\treturn rc;\n}\n\nconst char * plugin_strerror(plugin_err_t e)\n{\n\tswitch (e) {\n\t\tcase EPLUGIN_SUCCESS:\n\t\t\treturn (\"Success\");\n\t\tcase EPLUGIN_NOTFOUND:\n\t\t\treturn (\"Plugin file not found\");\n\t\tcase EPLUGIN_ACCESS_ERROR:\n\t\t\treturn (\"Plugin access denied\");\n\t\tcase EPLUGIN_DLOPEN_FAILED:\n\t\t\treturn (\"Dlopen of plugin file failed\");\n\t\tcase EPLUGIN_INIT_FAILED:\n\t\t\treturn (\"Plugin init() callback failed\");\n\t\tcase EPLUGIN_MISSING_NAME:\n\t\t\treturn (\"Plugin name/type/version symbol missing\");\n\t\tcase EPLUGIN_MISSING_SYMBOL:\n\t\t\treturn (\"Plugin missing a required symbol use \"\n\t\t\t\t\"debug3 to see\");\n\t\tcase EPLUGIN_BAD_VERSION:\n\t\t\treturn (\"Incompatible plugin version\");\n\t}\n\treturn (\"Unknown error\");\n}\n\nint\nplugin_peek( const char *fq_path,\n\t\t\t char *plugin_type,\n\t\t\t const size_t type_len,\n\t\t\t uint32_t *plugin_version )\n{\n\tplugin_handle_t plug;\n\tchar *type;\n\tuint32_t *version;\n\n\tplug = dlopen( fq_path, RTLD_LAZY );\n\tif ( plug == NULL ) {\n\t\tdebug3( \"plugin_peek: dlopen(%s): %s\", fq_path, _dlerror() );\n\t\treturn SLURM_ERROR;\n\t}\n\tif ( ( type = dlsym( plug, PLUGIN_TYPE ) ) != NULL ) {\n\t\tif ( plugin_type != NULL ) {\n\t\t\tstrlcpy(plugin_type, type, type_len);\n\t\t}\n\t} else {\n\t\tdlclose( plug );\n\t\t/* could be vestigial library, don't treat as an error */\n\t\tverbose( \"%s: not a SLURM plugin\", fq_path );\n\t\treturn SLURM_ERROR;\n\t}\n\n\tversion = (uint32_t *) dlsym(plug, PLUGIN_VERSION);\n\tif (!version) {\n\t\tverbose(\"%s: plugin_version symbol not defined\", fq_path);\n\t} else if ((*version != SLURM_VERSION_NUMBER) && xstrcmp(type,\"spank\")){\n\t\t/* NOTE: We could alternatly test just the MAJOR.MINOR values */\n\t\tint plugin_major, plugin_minor, plugin_micro;\n\t\tplugin_major = SLURM_VERSION_MAJOR(*version);\n\t\tplugin_minor = SLURM_VERSION_MINOR(*version);\n\t\tplugin_micro = SLURM_VERSION_MICRO(*version);\n\t\tdlclose(plug);\n\t\tinfo(\"%s: Incompatible Slurm plugin version (%d.%d.%d)\",\n\t\t     fq_path, plugin_major, plugin_minor, plugin_micro);\n\t\treturn SLURM_ERROR;\n\t}\n\n\tdlclose( plug );\n\treturn SLURM_SUCCESS;\n}\n\nplugin_err_t\nplugin_load_from_file(plugin_handle_t *p, const char *fq_path)\n{\n\tplugin_handle_t plug;\n\tint (*init)(void);\n\tuint32_t *version;\n\tchar *type = NULL;\n\n\t*p = PLUGIN_INVALID_HANDLE;\n\n\t/*\n\t *  Check for file existence and access permissions\n\t */\n\tif (access(fq_path, R_OK) < 0) {\n\t\tif (errno == ENOENT)\n\t\t\treturn EPLUGIN_NOTFOUND;\n\t\telse\n\t\t\treturn EPLUGIN_ACCESS_ERROR;\n\t}\n\n\t/*\n\t * Try to open the shared object.\n\t *\n\t * Use RTLD_LAZY to allow plugins to use symbols that may be\n\t * defined in only one slurm entity (e.g. srun and not slurmd),\n\t * when the use of that symbol is restricted to within the\n\t * entity from which it is available. (i.e. srun symbols are only\n\t * used in the context of srun, not slurmd.)\n\t *\n\t */\n\tplug = dlopen(fq_path, RTLD_LAZY);\n\tif (plug == NULL) {\n\t\terror(\"plugin_load_from_file: dlopen(%s): %s\",\n\t\t      fq_path,\n\t\t      _dlerror());\n\t\treturn EPLUGIN_DLOPEN_FAILED;\n\t}\n\n\t/* Now see if our required symbols are defined. */\n\tif ((dlsym(plug, PLUGIN_NAME) == NULL) ||\n\t    ((type = dlsym(plug, PLUGIN_TYPE)) == NULL)) {\n\t\tdlclose(plug);\n\t\treturn EPLUGIN_MISSING_NAME;\n\t}\n\n\tversion = (uint32_t *) dlsym(plug, PLUGIN_VERSION);\n\tif (!version) {\n\t\tverbose(\"%s: plugin_version symbol not defined\", fq_path);\n\t} else if ((*version != SLURM_VERSION_NUMBER) && xstrcmp(type,\"spank\")){\n\t\t/* NOTE: We could alternatly test just the MAJOR.MINOR values */\n\t\tint plugin_major, plugin_minor, plugin_micro;\n\t\tplugin_major = SLURM_VERSION_MAJOR(*version);\n\t\tplugin_minor = SLURM_VERSION_MINOR(*version);\n\t\tplugin_micro = SLURM_VERSION_MICRO(*version);\n\t\tdlclose(plug);\n\t\tinfo(\"%s: Incompatible Slurm plugin version (%d.%d.%d)\",\n\t\t     fq_path, plugin_major, plugin_minor, plugin_micro);\n\t\treturn EPLUGIN_BAD_VERSION;\n\t}\n\n\t/*\n\t * Now call its init() function, if present.  If the function\n\t * returns nonzero, unload the plugin and signal an error.\n\t */\n\tif ((init = dlsym(plug, \"init\")) != NULL) {\n\t\tif ((*init)() != 0) {\n\t\t\tdlclose(plug);\n\t\t\treturn EPLUGIN_INIT_FAILED;\n\t\t}\n\t}\n\n\t*p = plug;\n\treturn EPLUGIN_SUCCESS;\n}\n\nplugin_handle_t\nplugin_load_and_link(const char *type_name, int n_syms,\n\t\t     const char *names[], void *ptrs[])\n{\n\tplugin_handle_t plug = PLUGIN_INVALID_HANDLE;\n\tstruct stat st;\n\tchar *head = NULL, *dir_array = NULL, *so_name = NULL;\n\tchar *file_name = NULL;\n\tint i = 0;\n\tplugin_err_t err = EPLUGIN_NOTFOUND;\n\n\tif (!type_name)\n\t\treturn plug;\n\tso_name = xstrdup_printf(\"%s.so\", type_name);\n\twhile (so_name[i]) {\n\t\tif (so_name[i] == '/')\n\t\t\tso_name[i] = '_';\n\t\ti++;\n\t}\n\tif (!(dir_array = slurm_get_plugin_dir())) {\n\t\terror(\"plugin_load_and_link: No plugin dir given\");\n\t\txfree(so_name);\n\t\treturn plug;\n\t}\n\n\thead = dir_array;\n\tfor (i = 0; ; i++) {\n\t\tbool got_colon = 0;\n\t\tif (dir_array[i] == ':') {\n\t\t\tdir_array[i] = '\\0';\n\t\t\tgot_colon = 1;\n\t\t} else if (dir_array[i] != '\\0')\n\t\t\tcontinue;\n\n\t\tfile_name = xstrdup_printf(\"%s/%s\", head, so_name);\n\t\tdebug3(\"Trying to load plugin %s\", file_name);\n\t\tif ((stat(file_name, &st) < 0) || (!S_ISREG(st.st_mode))) {\n\t\t\tdebug4(\"%s: Does not exist or not a regular file.\",\n\t\t\t       file_name);\n\t\t\txfree(file_name);\n\t\t\terr = EPLUGIN_NOTFOUND;\n\t\t} else {\n\t\t\tif ((err = plugin_load_from_file(&plug, file_name))\n\t\t\t   == EPLUGIN_SUCCESS) {\n\t\t\t\tif (plugin_get_syms(plug, n_syms,\n\t\t\t\t\t\t    names, ptrs) >= n_syms) {\n\t\t\t\t\tdebug3(\"Success.\");\n\t\t\t\t\txfree(file_name);\n\t\t\t\t\tbreak;\n\t\t\t\t} else {\n\t\t\t\t\t(void) dlclose(plug);\n\t\t\t\t\terr = EPLUGIN_MISSING_SYMBOL;\n\t\t\t\t\tplug = PLUGIN_INVALID_HANDLE;\n\t\t\t\t}\n\t\t\t} else\n\t\t\t\tplug = PLUGIN_INVALID_HANDLE;\n\t\t\txfree(file_name);\n\t\t}\n\n\t\tif (got_colon) {\n\t\t\thead = dir_array + i + 1;\n\t\t} else\n\t\t\tbreak;\n\t}\n\n\txfree(dir_array);\n\txfree(so_name);\n\terrno = err;\n\treturn plug;\n}\n/*\n * Must test plugin validity before doing dlopen() and dlsym()\n * operations because some implementations of these functions\n * crash if the library handle is not valid.\n */\n\nvoid\nplugin_unload( plugin_handle_t plug )\n{\n\tvoid (*fini)(void);\n\n\tif ( plug != PLUGIN_INVALID_HANDLE ) {\n\t\tif ( ( fini = dlsym( plug, \"fini\" ) ) != NULL ) {\n\t\t\t(*fini)();\n\t\t}\n#ifndef MEMORY_LEAK_DEBUG\n/**************************************************************************\\\n * To test for memory leaks, set MEMORY_LEAK_DEBUG to 1 using\n * \"configure --enable-memory-leak-debug\" then execute\n *\n * Note that without --enable-memory-leak-debug the daemon will\n * unload the shared objects at exit thus preventing valgrind\n * to display the stack where the eventual leaks may be.\n * It is always best to test with and without --enable-memory-leak-debug.\n\\**************************************************************************/\n\t\t(void) dlclose( plug );\n#endif\n\t}\n}\n\n\nvoid *\nplugin_get_sym( plugin_handle_t plug, const char *name )\n{\n\tif ( plug != PLUGIN_INVALID_HANDLE )\n\t\treturn dlsym( plug, name );\n\telse\n\t\treturn NULL;\n}\n\nconst char *\nplugin_get_name( plugin_handle_t plug )\n{\n\tif ( plug != PLUGIN_INVALID_HANDLE )\n\t\treturn (const char *) dlsym( plug, PLUGIN_NAME );\n\telse\n\t\treturn NULL;\n}\n\nconst char *\nplugin_get_type( plugin_handle_t plug )\n{\n\tif ( plug != PLUGIN_INVALID_HANDLE )\n\t\treturn (const char *) dlsym( plug, PLUGIN_TYPE );\n\telse\n\t\treturn NULL;\n}\n\nuint32_t\nplugin_get_version( plugin_handle_t plug )\n{\n\tuint32_t *ptr;\n\n\tif (plug == PLUGIN_INVALID_HANDLE)\n\t\treturn 0;\n\tptr = (uint32_t *) dlsym(plug, PLUGIN_VERSION);\n\treturn ptr ? *ptr : 0;\n}\n\nint\nplugin_get_syms( plugin_handle_t plug,\n\t\t int n_syms,\n\t\t const char *names[],\n\t\t void *ptrs[] )\n{\n\tint i, count;\n\n\tcount = 0;\n\tfor ( i = 0; i < n_syms; ++i ) {\n\t\tptrs[ i ] = dlsym( plug, names[ i ] );\n\t\tif ( ptrs[ i ] )\n\t\t\t++count;\n\t\telse\n\t\t\tdebug3(\"Couldn't find sym '%s' in the plugin\",\n\t\t\t       names[ i ]);\n\t}\n\n\treturn count;\n}\n\n/*\n * Create a priority context\n */\nextern plugin_context_t *plugin_context_create(\n\tconst char *plugin_type, const char *uler_type,\n\tvoid *ptrs[], const char *names[], size_t names_size)\n{\n\tplugin_context_t *c;\n\tint n_names;\n\n\tif (!uler_type) {\n\t\tdebug3(\"plugin_context_create: no uler type\");\n\t\treturn NULL;\n\t} else if (!plugin_type) {\n\t\tdebug3(\"plugin_context_create: no plugin type\");\n\t\treturn NULL;\n\t} else if (!names) {\n\t\terror(\"plugin_context_create: no symbols given for plugin %s\",\n\t\t      plugin_type);\n\t\treturn NULL;\n\t} else if (!ptrs) {\n\t\terror(\"plugin_context_create: no ptrs given for plugin %s\",\n\t\t      plugin_type);\n\t\treturn NULL;\n\t}\n\n\tc = xmalloc(sizeof(plugin_context_t));\n\tc->type = xstrdup(uler_type);\n\tc->cur_plugin = PLUGIN_INVALID_HANDLE;\n\n\tn_names = names_size / sizeof(char *);\n\n\t/* Find the correct plugin. */\n\tc->cur_plugin = plugin_load_and_link(c->type, n_names, names, ptrs);\n\tif (c->cur_plugin != PLUGIN_INVALID_HANDLE)\n\t\treturn c;\n\n\tif (errno != EPLUGIN_NOTFOUND) {\n\t\terror(\"Couldn't load specified plugin name for %s: %s\",\n\t\t      c->type, plugin_strerror(errno));\n\t\tgoto fail;\n\t}\n\n\terror(\"Couldn't find the specified plugin name for %s \"\n\t      \"looking at all files\",\n\t      c->type);\n\n\t/* Get plugin list. */\n\tif (!c->plugin_list) {\n\t\tchar *plugin_dir;\n\t\tc->plugin_list = plugrack_create();\n\t\tif (!c->plugin_list) {\n\t\t\terror(\"cannot create plugin manager\");\n\t\t\tgoto fail;\n\t\t}\n\t\tplugrack_set_major_type(c->plugin_list, plugin_type);\n\t\tplugrack_set_paranoia(\n\t\t\tc->plugin_list, PLUGRACK_PARANOIA_NONE, 0);\n\t\tplugin_dir = slurm_get_plugin_dir();\n\t\tplugrack_read_dir(c->plugin_list, plugin_dir);\n\t\txfree(plugin_dir);\n\t}\n\n\tc->cur_plugin = plugrack_use_by_type(c->plugin_list, c->type);\n\tif (c->cur_plugin == PLUGIN_INVALID_HANDLE) {\n\t\terror(\"cannot find %s plugin for %s\", plugin_type, c->type);\n\t\tgoto fail;\n\t}\n\n\t/* Dereference the API. */\n\tif (plugin_get_syms(c->cur_plugin, n_names, names, ptrs) < n_names) {\n\t\terror(\"incomplete %s plugin detected\", plugin_type);\n\t\tgoto fail;\n\t}\n\n\treturn c;\nfail:\n\tplugin_context_destroy(c);\n\treturn NULL;\n}\n\n/*\n * Destroy a context\n */\nextern int plugin_context_destroy(plugin_context_t *c)\n{\n\tint rc = SLURM_SUCCESS;\n\t/*\n\t * Must check return code here because plugins might still\n\t * be loaded and active.\n\t */\n\tif (c->plugin_list) {\n\t\tif (plugrack_destroy(c->plugin_list) != SLURM_SUCCESS)\n\t\t\trc = SLURM_ERROR;\n\t} else\n\t\tplugin_unload(c->cur_plugin);\n\n\txfree(c->type);\n\txfree(c);\n\n\treturn rc;\n}\n\n/*\n * Return a list of plugin names that match the given type.\n *\n * IN plugin_type - Type of plugin to search for in the plugin_dir.\n * RET list of plugin names, NULL if none found.\n */\nextern List plugin_get_plugins_of_type(char *plugin_type)\n{\n\tList plugin_names = NULL;\n\tchar *plugin_dir = NULL, *dir = NULL, *save_ptr = NULL;\n\tchar *type_under = NULL, *type_slash = NULL;\n\tDIR *dirp;\n\tstruct dirent *e;\n\tint len;\n\n\tif (!(plugin_dir = slurm_get_plugin_dir())) {\n\t\terror(\"%s: No plugin dir given\", __func__);\n\t\tgoto done;\n\t}\n\n\ttype_under = xstrdup_printf(\"%s_\", plugin_type);\n\ttype_slash = xstrdup_printf(\"%s/\", plugin_type);\n\n\tdir = strtok_r(plugin_dir, \":\", &save_ptr);\n\twhile (dir) {\n\t\t/* Open the directory. */\n\t\tif (!(dirp = opendir(dir))) {\n\t\t\terror(\"cannot open plugin directory %s\", dir);\n\t\t\tgoto done;\n\t\t}\n\n\t\twhile (1) {\n\t\t\tchar full_name[128];\n\n\t\t\tif (!(e = readdir( dirp )))\n\t\t\t\tbreak;\n\t\t\t/* Check only files with \"plugintype_\" in them. */\n\t\t\tif (xstrncmp(e->d_name, type_under, strlen(type_under)))\n\t\t\t\tcontinue;\n\n\t\t\tlen = strlen(e->d_name);\n\t\t\tlen -= 3;\n\t\t\t/* Check only shared object files */\n\t\t\tif (xstrcmp(e->d_name+len, \".so\"))\n\t\t\t\tcontinue;\n\t\t\t/* add one for the / */\n\t\t\tlen++;\n\t\t\txassert(len < sizeof(full_name));\n\t\t\tsnprintf(full_name, len, \"%s%s\",\n\t\t\t\t type_slash, e->d_name + strlen(type_slash));\n\n\t\t\tif (!plugin_names)\n\t\t\t\tplugin_names = list_create(slurm_destroy_char);\n\t\t\tif (!list_find_first(plugin_names,\n\t\t\t\t\t     slurm_find_char_in_list,\n\t\t\t\t\t     full_name))\n\t\t\t\tlist_append(plugin_names, xstrdup(full_name));\n\t\t}\n\t\tclosedir(dirp);\n\n\t\tdir = strtok_r(NULL, \":\", &save_ptr);\n\t}\n\ndone:\n\txfree(plugin_dir);\n\txfree(type_under);\n\txfree(type_slash);\n\n\treturn plugin_names;\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/src/common/plugstack.c": "/*****************************************************************************\\\n *  plugstack.c -- stackable plugin architecture for node job kontrol (SPANK)\n *****************************************************************************\n *  Copyright (C) 2005-2007 The Regents of the University of California.\n *  Copyright (C) 2008-2010 Lawrence Livermore National Security.\n *  Produced at Lawrence Livermore National Laboratory (cf, DISCLAIMER).\n *  CODE-OCEC-09-009. All rights reserved.\n *\n *  This file is part of SLURM, a resource management program.\n *  For details, see <https://slurm.schedmd.com/>.\n *  Please also read the included file: DISCLAIMER.\n *\n *  SLURM is free software; you can redistribute it and/or modify it under\n *  the terms of the GNU General Public License as published by the Free\n *  Software Foundation; either version 2 of the License, or (at your option)\n *  any later version.\n *\n *  In addition, as a special exception, the copyright holders give permission\n *  to link the code of portions of this program with the OpenSSL library under\n *  certain conditions as described in each individual source file, and\n *  distribute linked combinations including the two. You must obey the GNU\n *  General Public License in all respects for all of the code used other than\n *  OpenSSL. If you modify file(s) with this exception, you may extend this\n *  exception to your version of the file(s), but you are not obligated to do\n *  so. If you do not wish to do so, delete this exception statement from your\n *  version.  If you delete this exception statement from all source files in\n *  the program, then also delete it here.\n *\n *  SLURM is distributed in the hope that it will be useful, but WITHOUT ANY\n *  WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n *  FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more\n *  details.\n *\n *  You should have received a copy of the GNU General Public License along\n *  with SLURM; if not, write to the Free Software Foundation, Inc.,\n *  51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA.\n\\*****************************************************************************/\n\n#include \"config.h\"\n\n#include <ctype.h>\n#include <dlfcn.h>\n#include <glob.h>\n#include <libgen.h>\n#include <stdlib.h>\n#include <string.h>\n\n#include \"src/common/plugin.h\"\n#include \"src/common/xmalloc.h\"\n#include \"src/common/xstring.h\"\n#include \"src/common/xassert.h\"\n#include \"src/common/safeopen.h\"\n#include \"src/common/strlcpy.h\"\n#include \"src/common/read_config.h\"\n#include \"src/common/plugstack.h\"\n#include \"src/common/optz.h\"\n#include \"src/common/job_options.h\"\n#include \"src/common/env.h\"\n\n#include \"src/slurmd/slurmstepd/slurmstepd_job.h\"\n/*#include \"src/srun/srun_job.h\"*/\n\n#include \"slurm/spank.h\"\n\n#define REQUIRED \"required\"\n#define OPTIONAL \"optional\"\n#define INCLUDE  \"include\"\n\nstruct spank_plugin_operations {\n\tspank_f *init;\n\tspank_f *slurmd_init;\n\tspank_f *job_prolog;\n\tspank_f *init_post_opt;\n\tspank_f *local_user_init;\n\tspank_f *user_init;\n\tspank_f *task_init_privileged;\n\tspank_f *user_task_init;\n\tspank_f *task_post_fork;\n\tspank_f *task_exit;\n\tspank_f *job_epilog;\n\tspank_f *slurmd_exit;\n\tspank_f *exit;\n};\n\nconst int n_spank_syms = 13;\nconst char *spank_syms[] = {\n\t\"slurm_spank_init\",\n\t\"slurm_spank_slurmd_init\",\n\t\"slurm_spank_job_prolog\",\n\t\"slurm_spank_init_post_opt\",\n\t\"slurm_spank_local_user_init\",\n\t\"slurm_spank_user_init\",\n\t\"slurm_spank_task_init_privileged\",\n\t\"slurm_spank_task_init\",\n\t\"slurm_spank_task_post_fork\",\n\t\"slurm_spank_task_exit\",\n\t\"slurm_spank_job_epilog\",\n\t\"slurm_spank_slurmd_exit\",\n\t\"slurm_spank_exit\"\n};\n\nstruct spank_plugin {\n\tconst char *name;\n\tchar *fq_path;\n\tplugin_handle_t plugin;\n\tbool required;\n\tint ac;\n\tchar **argv;\n\tstruct spank_plugin_operations ops;\n\tstruct spank_option *opts;\n\tstruct spank_stack *stack;\n};\n\n/*\n *  SPANK Plugin options\n */\n\n#define SPANK_OPTION_ENV_PREFIX \"_SLURM_SPANK_OPTION_\"\n\nstruct spank_plugin_opt {\n\tstruct spank_option *opt;   /* Copy of plugin option info           */\n\tstruct spank_plugin *plugin;/* Link back to plugin structure        */\n\tint optval;                 /* Globally unique value                */\n\tint found:1;                /* 1 if option was found, 0 otherwise   */\n\tint disabled:1;             /* 1 if option is cached but disabled   */\n\tchar *optarg;               /* Option argument.                     */\n};\n\n/*\n *  SPANK plugin context type (local, remote, allocator)\n */\nenum spank_context_type {\n\tS_TYPE_NONE,\n\tS_TYPE_LOCAL,           /* LOCAL == srun              */\n\tS_TYPE_REMOTE,          /* REMOTE == slurmstepd       */\n\tS_TYPE_ALLOCATOR,       /* ALLOCATOR == sbatch/salloc */\n\tS_TYPE_SLURMD,          /* SLURMD == slurmd           */\n\tS_TYPE_JOB_SCRIPT,      /* JOB_SCRIPT == prolog/epilog*/\n};\n\n/*\n *  SPANK plugin hook types:\n */\ntypedef enum step_fn {\n\tSPANK_INIT = 0,\n\tSPANK_SLURMD_INIT,\n\tSPANK_JOB_PROLOG,\n\tSPANK_INIT_POST_OPT,\n\tLOCAL_USER_INIT,\n\tSTEP_USER_INIT,\n\tSTEP_TASK_INIT_PRIV,\n\tSTEP_USER_TASK_INIT,\n\tSTEP_TASK_POST_FORK,\n\tSTEP_TASK_EXIT,\n\tSPANK_JOB_EPILOG,\n\tSPANK_SLURMD_EXIT,\n\tSPANK_EXIT\n} step_fn_t;\n\n/*\n *  Job information in prolog/epilog context:\n */\nstruct job_script_info {\n\tuint32_t  jobid;\n\tuid_t     uid;\n};\n\nstruct spank_handle {\n#   define SPANK_MAGIC 0x00a5a500\n\tint                  magic;  /* Magic identifier to ensure validity. */\n\tstruct spank_plugin *plugin; /* Current plugin using handle          */\n\tstep_fn_t            phase;  /* Which spank fn are we called from?   */\n\tvoid               * job;    /* Reference to current srun|slurmd job */\n\tstepd_step_task_info_t * task;   /* Reference to current\n\t\t\t\t\t      * task (if valid) */\n\tstruct spank_stack  *stack;  /* Reference to the current plugin stack*/\n};\n\n/*\n *  SPANK stack. The stack of loaded plugins and associated state.\n */\nstruct spank_stack {\n\tenum spank_context_type type;/*  Type of context for this stack      */\n\tList plugin_list;\t     /*  Stack of spank plugins              */\n\tList option_cache;           /*  Cache of plugin options in this ctx */\n\tint  spank_optval;           /*  optvalue for next plugin option     */\n\tconst char * plugin_path;    /*  default path to search for plugins  */\n};\n\n/*\n *  The global spank plugin stack:\n */\nstatic struct spank_stack *global_spank_stack = NULL;\n\n/*\n *  Forward declarations\n */\nstatic int _spank_plugin_options_cache(struct spank_plugin *p);\nstatic int _spank_stack_load (struct spank_stack *stack, const char *file);\nstatic void _spank_plugin_destroy (struct spank_plugin *);\nstatic void _spank_plugin_opt_destroy (struct spank_plugin_opt *);\nstatic int spank_stack_get_remote_options(struct spank_stack *, job_options_t);\nstatic int spank_stack_get_remote_options_env (struct spank_stack *, char **);\nstatic int spank_stack_set_remote_options_env (struct spank_stack * stack);\nstatic int dyn_spank_set_job_env (const char *var, const char *val, int ovwt);\nstatic char *_opt_env_name(struct spank_plugin_opt *p, char *buf, size_t siz);\n\nstatic void spank_stack_destroy (struct spank_stack *stack)\n{\n\tFREE_NULL_LIST (stack->plugin_list);\n\tFREE_NULL_LIST (stack->option_cache);\n\txfree (stack->plugin_path);\n\txfree (stack);\n}\n\nstatic struct spank_stack *\nspank_stack_create (const char *file, enum spank_context_type type)\n{\n\tslurm_ctl_conf_t *conf;\n\tstruct spank_stack *stack = xmalloc (sizeof (*stack));\n\n\tconf = slurm_conf_lock();\n\tstack->plugin_path = xstrdup (conf->plugindir);\n\tslurm_conf_unlock();\n\n\tstack->type = type;\n\tstack->spank_optval = 0xfff;\n\tstack->plugin_list =\n\t\tlist_create ((ListDelF) _spank_plugin_destroy);\n\tstack->option_cache =\n\t\tlist_create ((ListDelF) _spank_plugin_opt_destroy);\n\n\tif (_spank_stack_load (stack, file) < 0) {\n\t\tspank_stack_destroy (stack);\n\t\treturn (NULL);\n\t}\n\n\treturn (stack);\n}\n\nstatic List get_global_option_cache (void)\n{\n\tif (global_spank_stack)\n\t\treturn (global_spank_stack->option_cache);\n\telse\n\t\treturn (NULL);\n}\n\n\nstatic int plugin_in_list (List l, struct spank_plugin *sp)\n{\n\tint rc = 0;\n\tstruct spank_plugin *p;\n\tListIterator i = list_iterator_create (l);\n\twhile ((p = list_next (i))) {\n\t\tif (p->fq_path == sp->fq_path) {\n\t\t\trc = 1;\n\t\t\tbreak;\n\t\t}\n\t}\n\tlist_iterator_destroy (i);\n\treturn (rc);\n}\n\nstatic void _argv_append(char ***argv, int ac, const char *newarg)\n{\n\t*argv = xrealloc(*argv, (++ac + 1) * sizeof(char *));\n\t(*argv)[ac] = NULL;\n\t(*argv)[ac - 1] = xstrdup(newarg);\n\treturn;\n}\n\ntypedef enum {\n   CF_ERROR = 0,\n   CF_OPTIONAL,\n   CF_REQUIRED,\n   CF_INCLUDE,\n} cf_line_t;\n\nstatic cf_line_t _plugin_stack_line_type (const char *str)\n{\n\tif (xstrcmp(str, REQUIRED) == 0)\n\t\treturn (CF_REQUIRED);\n\telse if (xstrcmp(str, OPTIONAL) == 0)\n\t\treturn (CF_OPTIONAL);\n\telse if (xstrcmp(str, INCLUDE) == 0)\n\t\treturn (CF_INCLUDE);\n\telse {\n\t\terror(\"spank: Invalid option \\\"%s\\\". Must be %s, %s or %s\",\n\t\t     str, REQUIRED, OPTIONAL, INCLUDE);\n\t\treturn (CF_ERROR);\n\t}\n}\n\n\nstatic int\n_plugin_stack_parse_line(char *line, char **plugin, int *acp, char ***argv,\n\t\t\t cf_line_t * type)\n{\n\tint ac;\n\tconst char *separators = \" \\t\\n\";\n\tchar *path;\n\tchar *option;\n\tchar *s;\n\tchar **av;\n\tchar *sp;\n\n\t*plugin = NULL;\n\t*argv = NULL;\n\t*acp = 0;\n\n\t/* Nullify any comments\n\t */\n\tif ((s = strchr(line, '#')))\n\t\t*s = '\\0';\n\n\tif (!(option = strtok_r(line, separators, &sp)))\n\t\treturn (0);\n\n\tif (((*type) = _plugin_stack_line_type(option)) == CF_ERROR)\n\t\treturn (-1);\n\n\tif (!(path = strtok_r(NULL, separators, &sp)))\n\t\treturn (-1);\n\n\tac = 0;\n\tav = NULL;\n\n\twhile ((s = strtok_r(NULL, separators, &sp)))\n\t\t_argv_append(&av, ac++, s);\n\n\t*plugin = xstrdup(path);\n\t*argv = av;\n\t*acp = ac;\n\n\treturn (0);\n}\n\nstatic struct spank_plugin *_spank_plugin_create(struct spank_stack *stack,\n\t\t\t\t\t\t char *path, int ac,\n\t\t\t\t\t\t char **av, bool required)\n{\n\tstruct spank_plugin *plugin;\n\tplugin_handle_t p;\n\tplugin_err_t e;\n\tstruct spank_plugin_operations ops;\n\n\tif ((e = plugin_load_from_file(&p, path)) != EPLUGIN_SUCCESS) {\n\t\terror (\"spank: %s: %s\", path, plugin_strerror(e));\n\t\treturn NULL;\n\t}\n\n\tif (plugin_get_syms(p, n_spank_syms, spank_syms, (void **)&ops) == 0) {\n\t\terror(\"spank: \\\"%s\\\" exports 0 symbols\", path);\n\t\treturn NULL;\n\t}\n\n\tplugin = xmalloc(sizeof(struct spank_plugin));\n\n\tplugin->fq_path = path;\t/* fq_path is xstrdup'd in *process_line */\n\tplugin->plugin = p;\n\tplugin->name = plugin_get_name(p);\t/* no need to dup */\n\tplugin->required = required;\n\tplugin->ac = ac;\n\tplugin->argv = av;\n\tplugin->ops = ops;\n\tplugin->stack = stack;\n\n\t/*\n\t *  Do not load static plugin options table in allocator context.\n\t */\n\tif (stack->type != S_TYPE_ALLOCATOR)\n\t\tplugin->opts = plugin_get_sym(p, \"spank_options\");\n\n\treturn (plugin);\n}\n\nvoid _spank_plugin_destroy(struct spank_plugin *sp)\n{\n\tif (sp == NULL)\n\t\treturn;\n\n\txfree(sp->fq_path);\n\n\t/* No need to free \"name\" it was defined within plugin */\n\tsp->name = NULL;\n\n\tplugin_unload(sp->plugin);\n\tsp->plugin = NULL;\n\tif (sp->argv) {\n\t\tint i;\n\t\tfor (i = 0; sp->argv[i]; i++)\n\t\t\txfree(sp->argv[i]);\n\t\txfree(sp->argv);\n\t}\n\txfree(sp);\n\treturn;\n}\n\nstatic char *\n_spank_plugin_find (const char *path, const char *file)\n{\n\tchar dir [4096];\n\tchar *p, *entry;\n\tint pathlen = strlen (path);\n\n\tif (strlcpy(dir, path, sizeof (dir)) > sizeof (dir))\n\t\treturn (NULL);\n\n\t/*\n\t * Ensure PATH ends with a :\n\t */\n\tif (dir[pathlen - 1] != ':') {\n\t\tdir[pathlen] = ':';\n\t\tdir[pathlen+1] = '\\0';\n\t}\n\n\tentry = dir;\n\twhile ((p = strchr(entry, ':'))) {\n\t\tchar *fq_path;\n\t\t*(p++) = '\\0';\n\n\t\tfq_path = xstrdup (entry);\n\t\tif (entry [strlen(entry) - 1] != '/')\n\t\t\txstrcatchar (fq_path, '/');\n\t\txstrcat (fq_path, file);\n\n\t\tif (plugin_peek (fq_path, NULL, 0, NULL) != SLURM_ERROR)\n\t\t\treturn (fq_path);\n\n\t\txfree (fq_path);\n\t\tentry = p;\n\t}\n\n\treturn (NULL);\n}\n\nstatic int _spank_conf_include (struct spank_stack *,\n\tconst char *, int, const char *);\n\nstatic int\nspank_stack_plugin_valid_for_context (struct spank_stack *stack,\n\tstruct spank_plugin *p)\n{\n\tswitch (stack->type) {\n\tcase S_TYPE_JOB_SCRIPT:\n\t\tif (p->ops.job_prolog || p->ops.job_epilog)\n\t\t\treturn (1);\n\t\tbreak;\n\tcase S_TYPE_SLURMD:\n\t\tif (p->ops.slurmd_init || p->ops.slurmd_exit)\n\t\t\treturn (1);\n\t\tbreak;\n\tcase S_TYPE_LOCAL:\n\tcase S_TYPE_ALLOCATOR:\n\tcase S_TYPE_REMOTE:\n\t\t/*\n\t\t *  For backwards compatibility: All plugins were\n\t\t *   always loaded in these contexts, so continue\n\t\t *   to do so\n\t\t */\n\t\treturn (1);\n\tdefault:\n\t\treturn (0);\n\t}\n\treturn (0);\n}\n\nstatic int\n_spank_stack_process_line(struct spank_stack *stack,\n\tconst char *file, int line, char *buf)\n{\n\tchar **argv;\n\tint ac;\n\tchar *path;\n\tcf_line_t type = CF_REQUIRED;\n\tbool required;\n\n\tstruct spank_plugin *p;\n\n\tif (_plugin_stack_parse_line(buf, &path, &ac, &argv, &type) < 0) {\n\t\terror(\"spank: %s:%d: Invalid line. Ignoring.\", file, line);\n\t\treturn (0);\n\t}\n\n       if (type == CF_INCLUDE) {\n\t       int rc = _spank_conf_include (stack, file, line, path);\n\t       xfree (path);\n\t       return (rc);\n       }\n\n\tif (path == NULL)\t/* No plugin listed on this line */\n\t\treturn (0);\n\n\tif (path[0] != '/') {\n\t\tchar *f;\n\n\t\tif ((f = _spank_plugin_find (stack->plugin_path, path))) {\n\t\t\txfree (path);\n\t\t\tpath = f;\n\t\t}\n\t}\n\n\trequired = (type == CF_REQUIRED);\n\tif (!(p = _spank_plugin_create(stack, path, ac, argv, required))) {\n\t\tif (required)\n\t\t\terror (\"spank: %s:%d:\"\n\t\t\t       \" Failed to load plugin %s. Aborting.\",\n\t\t\t       file, line, path);\n\t\telse\n\t\t\tverbose (\"spank: %s:%d:\"\n\t\t\t\t \"Failed to load optional plugin %s. Ignored.\",\n\t\t\t\t file, line, path);\n\t\treturn (required ? -1 : 0);\n\t}\n\n\tif (plugin_in_list (stack->plugin_list, p)) {\n\t\terror (\"spank: %s: cowardly refusing to load a second time\",\n\t\t\tp->fq_path);\n\t\t_spank_plugin_destroy (p);\n\t\treturn (0);\n\t}\n\n\tif (!spank_stack_plugin_valid_for_context (stack, p)) {\n\t\tdebug2 (\"spank: %s: no callbacks in this context\", p->fq_path);\n\t\t_spank_plugin_destroy (p);\n\t\treturn (0);\n\t}\n\n\tdebug (\"spank: %s:%d: Loaded plugin %s\",\n\t\t\tfile, line, xbasename (p->fq_path));\n\n\tlist_append (stack->plugin_list, p);\n\t_spank_plugin_options_cache(p);\n\n\treturn (0);\n}\n\n\nstatic int _spank_stack_load(struct spank_stack *stack, const char *path)\n{\n\tint rc = 0;\n\tint line;\n\tchar buf[4096];\n\tFILE *fp;\n\n\tdebug (\"spank: opening plugin stack %s\", path);\n\n\t/*\n\t *  Try to open plugstack.conf. A missing config file is not an\n\t *   error, but is equivalent to an empty file.\n\t */\n\tif (!(fp = safeopen(path, \"r\", SAFEOPEN_NOCREATE|SAFEOPEN_LINK_OK))) {\n\t\tif (errno == ENOENT)\n\t\t\treturn (0);\n\t\terror(\"spank: Failed to open %s: %m\", path);\n\t\treturn (-1);\n\t}\n\n\tline = 1;\n\twhile (fgets(buf, sizeof(buf), fp)) {\n\t\trc = _spank_stack_process_line(stack, path, line, buf);\n\t\tif (rc < 0)\n\t\t\tbreak;\n\t\tline++;\n\t}\n\n\tfclose(fp);\n\treturn (rc);\n}\n\nstatic int _spank_conf_include (struct spank_stack *stack,\n\t\tconst char *file, int lineno, const char *pattern)\n{\n\tint rc = 0;\n\tglob_t gl;\n\tsize_t i;\n\tchar *copy = NULL;\n\n\tif (pattern == NULL) {\n\t\terror (\"%s: %d: Invalid include directive\", file, lineno);\n\t\treturn (SLURM_ERROR);\n\t}\n\n\tif (pattern[0] != '/') {\n\t\tchar *dirc = xstrdup (file);\n\t\tchar *dname = dirname (dirc);\n\n\t\tif (dname != NULL)  {\n\t\t\txstrfmtcat (copy, \"%s/%s\", dname, pattern);\n\t\t\tpattern = copy;\n\t\t}\n\t\txfree (dirc);\n\t}\n\n\tdebug (\"%s: %d: include \\\"%s\\\"\", file, lineno, pattern);\n\n\trc = glob (pattern, 0, NULL, &gl);\n\tswitch (rc) {\n\t  case 0:\n\t  \tfor (i = 0; i < gl.gl_pathc; i++) {\n\t\t\trc = _spank_stack_load (stack, gl.gl_pathv[i]);\n\t\t\tif (rc < 0)\n\t\t\t\tbreak;\n\t\t}\n\t  \tbreak;\n\t  case GLOB_NOMATCH:\n\t\tbreak;\n\t  case GLOB_NOSPACE:\n\t\terrno = ENOMEM;\n\t\tbreak;\n\t  case GLOB_ABORTED:\n\t\tverbose (\"%s:%d: cannot read dir %s: %m\",\n\t\t\tfile, lineno, pattern);\n\t\tbreak;\n\t  default:\n\t\terror (\"Unknown glob(3) return code = %d\", rc);\n\t\tbreak;\n\t}\n\n\txfree (copy);\n\tglobfree (&gl);\n\treturn (rc);\n}\n\nstatic int\n_spank_handle_init(struct spank_handle *spank, struct spank_stack *stack,\n\t\tvoid * arg, int taskid, step_fn_t fn)\n{\n\tmemset(spank, 0, sizeof(*spank));\n\tspank->magic = SPANK_MAGIC;\n\tspank->plugin = NULL;\n\n\tspank->phase = fn;\n\tspank->stack = stack;\n\n\tif (arg != NULL) {\n\t\tspank->job = arg;\n\t\tif (stack->type == S_TYPE_REMOTE && taskid >= 0) {\n\t\t\tspank->task = ((stepd_step_rec_t *) arg)->task[taskid];\n\t\t}\n\t}\n\treturn (0);\n}\n\nstatic const char *_step_fn_name(step_fn_t type)\n{\n\tswitch (type) {\n\tcase SPANK_INIT:\n\t\treturn (\"init\");\n\tcase SPANK_SLURMD_INIT:\n\t\treturn (\"slurmd_init\");\n\tcase SPANK_JOB_PROLOG:\n\t\treturn (\"job_prolog\");\n\tcase SPANK_INIT_POST_OPT:\n\t\treturn (\"init_post_opt\");\n\tcase LOCAL_USER_INIT:\n\t\treturn (\"local_user_init\");\n\tcase STEP_USER_INIT:\n\t\treturn (\"user_init\");\n\tcase STEP_TASK_INIT_PRIV:\n\t\treturn (\"task_init_privileged\");\n\tcase STEP_USER_TASK_INIT:\n\t\treturn (\"task_init\");\n\tcase STEP_TASK_POST_FORK:\n\t\treturn (\"task_post_fork\");\n\tcase STEP_TASK_EXIT:\n\t\treturn (\"task_exit\");\n\tcase SPANK_JOB_EPILOG:\n\t\treturn (\"job_epilog\");\n\tcase SPANK_SLURMD_EXIT:\n\t\treturn (\"slurmd_exit\");\n\tcase SPANK_EXIT:\n\t\treturn (\"exit\");\n\t}\n\n\t/* NOTREACHED */\n\treturn (\"unknown\");\n}\n\nstatic spank_f *spank_plugin_get_fn (struct spank_plugin *sp, step_fn_t type)\n{\n\tswitch (type) {\n\tcase SPANK_INIT:\n\t\treturn (sp->ops.init);\n\tcase SPANK_SLURMD_INIT:\n\t\treturn (sp->ops.slurmd_init);\n\tcase SPANK_JOB_PROLOG:\n\t\treturn (sp->ops.job_prolog);\n\tcase SPANK_INIT_POST_OPT:\n\t\treturn (sp->ops.init_post_opt);\n\tcase LOCAL_USER_INIT:\n\t\treturn (sp->ops.local_user_init);\n\tcase STEP_USER_INIT:\n\t\treturn (sp->ops.user_init);\n\tcase STEP_TASK_INIT_PRIV:\n\t\treturn (sp->ops.task_init_privileged);\n\tcase STEP_USER_TASK_INIT:\n\t\treturn (sp->ops.user_task_init);\n\tcase STEP_TASK_POST_FORK:\n\t\treturn (sp->ops.task_post_fork);\n\tcase STEP_TASK_EXIT:\n\t\treturn (sp->ops.task_exit);\n\tcase SPANK_JOB_EPILOG:\n\t\treturn (sp->ops.job_epilog);\n\tcase SPANK_SLURMD_EXIT:\n\t\treturn (sp->ops.slurmd_exit);\n\tcase SPANK_EXIT:\n\t\treturn (sp->ops.exit);\n\tdefault:\n\t\terror (\"Unhandled spank function type=%d\\n\", type);\n\t\treturn (NULL);\n\t}\n\treturn (NULL);\n}\n\nstatic int _do_call_stack(struct spank_stack *stack,\n\tstep_fn_t type, void * job, int taskid)\n{\n\tint rc = 0;\n\tListIterator i;\n\tstruct spank_plugin *sp;\n\tstruct spank_handle spank[1];\n\tconst char *fn_name;\n\n\tif (!stack)\n\t\treturn (-1);\n\n\tif (_spank_handle_init(spank, stack, job, taskid, type) < 0) {\n\t\terror(\"spank: Failed to initialize handle for plugins\");\n\t\treturn (-1);\n\t}\n\n\tfn_name = _step_fn_name(type);\n\n\ti = list_iterator_create(stack->plugin_list);\n\twhile ((sp = list_next(i))) {\n\t\tconst char *name = xbasename(sp->fq_path);\n\t\tspank_f *spank_fn;\n\n\t\tspank->plugin = sp;\n\n\t\tspank_fn = spank_plugin_get_fn (sp, type);\n\t\tif (!spank_fn)\n\t\t\tcontinue;\n\n\t\trc = (*spank_fn) (spank, sp->ac, sp->argv);\n\t\tdebug2(\"spank: %s: %s = %d\", name, fn_name, rc);\n\n\t\tif ((rc < 0) && sp->required) {\n\t\t\terror(\"spank: required plugin %s: \"\n\t\t\t      \"%s() failed with rc=%d\", name, fn_name, rc);\n\t\t\tbreak;\n\t\t} else\n\t\t\trc = 0;\n\t}\n\n\tlist_iterator_destroy(i);\n\n\treturn (rc);\n}\n\nstruct spank_stack *spank_stack_init(enum spank_context_type context)\n{\n\tslurm_ctl_conf_t *conf = slurm_conf_lock();\n\tconst char *path = conf->plugstack;\n\tslurm_conf_unlock();\n\n\treturn spank_stack_create (path, context);\n}\n\nint _spank_init(enum spank_context_type context, stepd_step_rec_t * job)\n{\n\tstruct spank_stack *stack;\n\n\tif (!(stack = spank_stack_init (context)))\n\t\treturn (-1);\n\tglobal_spank_stack = stack;\n\n\treturn (_do_call_stack(stack, SPANK_INIT, job, -1));\n}\n\nstatic int spank_stack_post_opt (struct spank_stack * stack,\n\t\t\t\t stepd_step_rec_t *job)\n{\n\t/*\n\t *  Get any remote options from job launch message:\n\t */\n\tif (spank_stack_get_remote_options(stack, job->options) < 0) {\n\t\terror(\"spank: Unable to get remote options\");\n\t\treturn (-1);\n\t}\n\n\t/*\n\t *  Get any remote option passed thru environment\n\t */\n\tif (spank_stack_get_remote_options_env(stack, job->env) < 0) {\n\t\terror(\"spank: Unable to get remote options from environment\");\n\t\treturn (-1);\n\t}\n\n\t/*\n\t * Now clear any remaining options passed through environment\n\t */\n\tspank_clear_remote_options_env (job->env);\n\n\t/*\n\t *  Now that all options have been processed, we can\n\t *   call the post_opt handlers here in remote context.\n\t */\n\treturn (_do_call_stack(stack, SPANK_INIT_POST_OPT, job, -1));\n\n}\n\nstatic int spank_init_remote (stepd_step_rec_t *job)\n{\n\tif (_spank_init (S_TYPE_REMOTE, job) < 0)\n\t\treturn (-1);\n\n\t/*\n\t * _spank_init initializes global_spank_stack\n\t */\n\treturn (spank_stack_post_opt (global_spank_stack, job));\n}\n\nint spank_init (stepd_step_rec_t * job)\n{\n\tif (job)\n\t\treturn spank_init_remote (job);\n\telse\n\t\treturn _spank_init (S_TYPE_LOCAL, NULL);\n}\n\nint spank_init_allocator (void)\n{\n\treturn _spank_init (S_TYPE_ALLOCATOR, NULL);\n}\n\nint spank_slurmd_init (void)\n{\n\treturn _spank_init (S_TYPE_SLURMD, NULL);\n}\n\nint spank_init_post_opt (void)\n{\n\tstruct spank_stack *stack = global_spank_stack;\n\n\t/*\n\t *  Set remote options in our environment and the\n\t *   spank_job_env so that we can always pull them out\n\t *   on the remote side and/or job prolog epilog.\n\t */\n\tspank_stack_set_remote_options_env (stack);\n\n\treturn (_do_call_stack(stack, SPANK_INIT_POST_OPT, NULL, -1));\n}\n\nint spank_user(stepd_step_rec_t * job)\n{\n\treturn (_do_call_stack(global_spank_stack, STEP_USER_INIT, job, -1));\n}\n\nint spank_local_user(struct spank_launcher_job_info *job)\n{\n\treturn (_do_call_stack(global_spank_stack, LOCAL_USER_INIT, job, -1));\n}\n\nint spank_task_privileged(stepd_step_rec_t *job, int taskid)\n{\n\treturn (_do_call_stack(global_spank_stack, STEP_TASK_INIT_PRIV, job, taskid));\n}\n\nint spank_user_task(stepd_step_rec_t * job, int taskid)\n{\n\treturn (_do_call_stack(global_spank_stack, STEP_USER_TASK_INIT, job, taskid));\n}\n\nint spank_task_post_fork(stepd_step_rec_t * job, int taskid)\n{\n\treturn (_do_call_stack(global_spank_stack, STEP_TASK_POST_FORK, job, taskid));\n}\n\nint spank_task_exit(stepd_step_rec_t * job, int taskid)\n{\n\treturn (_do_call_stack(global_spank_stack, STEP_TASK_EXIT, job, taskid));\n}\n\nint spank_slurmd_exit (void)\n{\n\tint rc;\n\trc =  _do_call_stack (global_spank_stack, SPANK_SLURMD_EXIT, NULL, 0);\n\tspank_stack_destroy (global_spank_stack);\n\tglobal_spank_stack = NULL;\n\treturn (rc);\n}\n\nint spank_fini(stepd_step_rec_t * job)\n{\n\tint rc = _do_call_stack(global_spank_stack, SPANK_EXIT, job, -1);\n\n\tspank_stack_destroy (global_spank_stack);\n\tglobal_spank_stack = NULL;\n\n\treturn (rc);\n}\n\n/*\n *  Run job_epilog or job_prolog callbacks in a private spank context.\n */\nstatic int spank_job_script (step_fn_t fn, uint32_t jobid, uid_t uid)\n{\n\tint rc = 0;\n\tstruct spank_stack *stack;\n\tstruct job_script_info jobinfo = { jobid, uid };\n\n\tstack = spank_stack_init (S_TYPE_JOB_SCRIPT);\n\tif (!stack)\n\t\treturn (-1);\n\tglobal_spank_stack = stack;\n\n\trc = _do_call_stack (stack, fn, &jobinfo, -1);\n\n\tspank_stack_destroy (stack);\n\tglobal_spank_stack = NULL;\n\treturn (rc);\n}\n\nint spank_job_prolog (uint32_t jobid, uid_t uid)\n{\n\treturn spank_job_script (SPANK_JOB_PROLOG, jobid, uid);\n}\n\nint spank_job_epilog (uint32_t jobid, uid_t uid)\n{\n\treturn spank_job_script (SPANK_JOB_EPILOG, jobid, uid);\n}\n\n/*\n *  SPANK options functions\n */\n\nstatic int _spank_next_option_val(struct spank_stack *stack)\n{\n\treturn (stack->spank_optval++);\n}\n\nstatic struct spank_option * _spank_option_copy(struct spank_option *opt)\n{\n\tstruct spank_option *copy = xmalloc (sizeof (*copy));\n\n\tmemset (copy, 0, sizeof (*copy));\n\n\tcopy->name = xstrdup (opt->name);\n\tcopy->has_arg = opt->has_arg;\n\tcopy->val = opt->val;\n\tcopy->cb = opt->cb;\n\n\tif (opt->arginfo)\n\t\tcopy->arginfo = xstrdup (opt->arginfo);\n\tif (opt->usage)\n\t\tcopy->usage = xstrdup (opt->usage);\n\n\treturn (copy);\n}\n\nstatic void _spank_option_destroy(struct spank_option *opt)\n{\n\txfree (opt->name);\n\txfree (opt->arginfo);\n\txfree (opt->usage);\n\txfree (opt);\n}\n\nstatic struct spank_plugin_opt *_spank_plugin_opt_create(struct\n\t\t\t\t\t\t\t spank_plugin *p,\n\t\t\t\t\t\t\t struct\n\t\t\t\t\t\t\t spank_option *opt,\n\t\t\t\t\t\t\t int disabled)\n{\n\tstruct spank_plugin_opt *spopt = xmalloc(sizeof(*spopt));\n\tspopt->opt = _spank_option_copy (opt);\n\tspopt->plugin = p;\n\tspopt->optval = _spank_next_option_val(p->stack);\n\tspopt->found = 0;\n\tspopt->optarg = NULL;\n\n\tspopt->disabled = disabled;\n\n\treturn (spopt);\n}\n\nvoid _spank_plugin_opt_destroy(struct spank_plugin_opt *spopt)\n{\n\t_spank_option_destroy (spopt->opt);\n\txfree(spopt->optarg);\n\txfree(spopt);\n}\n\nstatic int _opt_by_val(struct spank_plugin_opt *opt, int *optvalp)\n{\n\treturn (opt->optval == *optvalp);\n}\n\nstatic int _opt_by_name(struct spank_plugin_opt *opt, char *optname)\n{\n\treturn (xstrcmp(opt->opt->name, optname) == 0);\n}\n\nstatic int\n_spank_option_register(struct spank_plugin *p, struct spank_option *opt)\n{\n\tint disabled = 0;\n\tstruct spank_plugin_opt *spopt;\n\tstruct spank_stack *stack;\n\tList option_cache;\n\n\tstack = p->stack;\n\tif (stack == NULL) {\n\t\terror (\"spank: %s: can't determine plugin context\", p->name);\n\t\treturn (ESPANK_BAD_ARG);\n\t}\n\toption_cache = stack->option_cache;\n\n\tspopt = list_find_first(option_cache,\n\t\t\t(ListFindF) _opt_by_name, opt->name);\n\tif (spopt) {\n\t\tstruct spank_plugin *q = spopt->plugin;\n\t\tinfo(\"spank: option \\\"%s\\\" provided by both %s and %s\",\n\t\t\t\topt->name, xbasename(p->fq_path),\n\t\t\t\txbasename(q->fq_path));\n\t\t/*\n\t\t *  Disable this option, but still cache it, in case\n\t\t *    options are loaded in a different order on the\n\t\t *    remote side.\n\t\t */\n\t\tdisabled = 1;\n\t}\n\n\tif ((strlen(opt->name) > SPANK_OPTION_MAXLEN)) {\n\t\terror(\"spank: option \\\"%s\\\" provided by %s too long. \"\n\t\t      \"Ignoring.\", opt->name, p->name);\n\t\treturn (ESPANK_NOSPACE);\n\t}\n\n\tdebug (\"SPANK: appending plugin option \\\"%s\\\"\", opt->name);\n\tlist_append(option_cache, _spank_plugin_opt_create(p, opt, disabled));\n\n\treturn (ESPANK_SUCCESS);\n}\n\nspank_err_t spank_option_register(spank_t sp, struct spank_option *opt)\n{\n\tif (sp->phase != SPANK_INIT)\n\t\treturn (ESPANK_BAD_ARG);\n\n\tif (!sp->plugin)\n\t\terror (\"Uh, oh, no current plugin!\");\n\n\tif (!opt || !opt->name || !opt->usage)\n\t\treturn (ESPANK_BAD_ARG);\n\n\treturn (_spank_option_register(sp->plugin, opt));\n}\n\nstatic int _spank_plugin_options_cache(struct spank_plugin *p)\n{\n\tstruct spank_option *opt = p->opts;\n\n\tif ((opt == NULL) || opt->name == NULL)\n\t\treturn (0);\n\n\tfor (; opt && opt->name != NULL; opt++)\n\t\t_spank_option_register(p, opt);\n\n\treturn (0);\n}\n\nstatic int _add_one_option(struct option **optz,\n\t\t\t   struct spank_plugin_opt *spopt)\n{\n\tstruct option opt;\n\n\topt.name = spopt->opt->name;\n\topt.has_arg = spopt->opt->has_arg;\n\topt.flag = NULL;\n\topt.val = spopt->optval;\n\n\tif (optz_add(optz, &opt) < 0) {\n\t\tif (errno == EEXIST) {\n\t\t\terror (\"Ignoring conflicting option \\\"%s\\\" \"\n\t\t\t       \"in plugin \\\"%s\\\"\",\n\t\t\t       opt.name, spopt->plugin->name);\n\t\t} else {\n\t\t\terror(\"Unable to add option \\\"%s\\\" \"\n\t\t\t      \"from plugin \\\"%s\\\"\",\n\t\t\t      opt.name, spopt->plugin->name);\n\t\t}\n\n\t\treturn (-1);\n\t}\n\n\treturn (0);\n}\n\n\nstruct option *spank_option_table_create(const struct option *orig)\n{\n\tstruct spank_plugin_opt *spopt;\n\tstruct option *opts = NULL;\n\tListIterator i = NULL;\n\n\tList option_cache = get_global_option_cache();\n\tif (option_cache == NULL)\n\t\treturn (NULL);\n\n\topts = optz_create();\n\n\t/*\n\t *  Start with original options:\n\t */\n\tif ((orig != NULL) && (optz_append(&opts, orig) < 0)) {\n\t\toptz_destroy(opts);\n\t\treturn (NULL);\n\t}\n\n\tif (option_cache == NULL || (list_count(option_cache) == 0))\n\t\treturn (opts);\n\n\ti = list_iterator_create(option_cache);\n\twhile ((spopt = list_next(i))) {\n\t\tif (!spopt->disabled && (_add_one_option (&opts, spopt) < 0))\n\t\t\tspopt->disabled = 1;\n\t}\n\n\tlist_iterator_destroy(i);\n\n\treturn (opts);\n}\n\nvoid spank_option_table_destroy(struct option *optz)\n{\n\toptz_destroy(optz);\n}\n\nstatic int _do_option_cb(struct spank_plugin_opt *opt, const char *arg)\n{\n\tint rc = 0;\n\n\txassert(opt);\n\txassert(arg);\n\n\t/*\n\t *  Call plugin callback if such a one exists\n\t */\n\tif (opt->opt->cb\n\t    && (rc = ((*opt->opt->cb) (opt->opt->val, arg, 0))) < 0)\n\t\treturn (rc);\n\n\t/*\n\t *  Set optarg and \"found\" so that option will be forwarded\n\t *    to remote side.\n\t */\n\tif (opt->opt->has_arg)\n\t\topt->optarg = xstrdup(arg);\n\topt->found = 1;\n\n\treturn rc;\n}\n\nextern int spank_process_option(int optval, const char *arg)\n{\n\tstruct spank_plugin_opt *opt;\n\tint rc = 0;\n\tList option_cache = get_global_option_cache();\n\n\tif (option_cache == NULL || (list_count(option_cache) == 0)) {\n\t\terror(\"No spank option cache\");\n\t\treturn (-1);\n\t}\n\n\topt = list_find_first(option_cache, (ListFindF)_opt_by_val, &optval);\n\tif (!opt) {\n\t\terror(\"Failed to find spank option for optval: %d\", optval);\n\t\treturn (-1);\n\t}\n\n\tif ((rc = _do_option_cb(opt, arg))) {\n\t\terror(\"Invalid --%s argument: %s\", opt->opt->name, arg);\n\t\treturn (rc);\n\t}\n\n\treturn (0);\n}\n\nextern int spank_process_env_options()\n{\n\tchar var[1024];\n\tconst char *arg;\n\tstruct spank_plugin_opt *option;\n\tListIterator i;\n\tList option_cache = get_global_option_cache();\n\tint rc = 0;\n\n\tif (option_cache == NULL || (list_count(option_cache) == 0))\n\t\treturn 0;\n\n\ti = list_iterator_create(option_cache);\n\twhile ((option = list_next(i))) {\n\t\tchar *env_name;\n\t\tenv_name = xstrdup_printf(\"SLURM_SPANK_%s\",\n\t\t\t\t\t  _opt_env_name(option, var,\n\t\t\t\t\t\t\tsizeof(var)));\n\t\tif (!(arg = getenv(env_name))) {\n\t\t\txfree(env_name);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif ((rc = _do_option_cb(option, arg))) {\n\t\t\terror(\"Invalid argument (%s) for environment variable: %s\",\n\t\t\t      arg, env_name);\n\t\t\txfree(env_name);\n\t\t\tbreak;\n\t\t}\n\t\txfree(env_name);\n\t}\n\tlist_iterator_destroy(i);\n\n\treturn rc;\n}\n\nstatic char *\n_find_word_boundary(char *str, char *from, char **next)\n{\n\tchar *p = from;\n\n\t/*\n\t * Back up past any non-whitespace if we are pointing in\n\t *  the middle of a word.\n\t */\n\twhile ((p != str) && !isspace ((int)*p))\n\t\t--p;\n\n\t/*\n\t * Next holds next word boundary\n\t */\n\t*next = p+1;\n\n\t/*\n\t * Now move back to the end of the previous word\n\t */\n\twhile ((p != str) && isspace ((int)*p))\n\t\t--p;\n\n\tif (p == str) {\n\t\t*next = str;\n\t\treturn (NULL);\n\t}\n\n\treturn (p+1);\n}\n\nstatic char *\n_get_next_segment (char **from, int width, char *buf, int bufsiz)\n{\n\tint len;\n\tchar * seg = *from;\n\tchar *p;\n\n\tif (**from == '\\0')\n\t\treturn (NULL);\n\n\tif ((len = strlen (*from)) <= width) {\n\t\t*from = *from + len;\n\t\treturn (seg);\n\t}\n\n\tif (!(p = _find_word_boundary (seg, *from + width, from))) {\n\t\t/*\n\t\t *\tNeed to break up a word. Use user-supplied buffer.\n\t\t */\n\t\tstrlcpy (buf, seg, width+1);\n\t\tbuf [width - 1]  = '-';\n\t\t/*\n\t\t * Adjust from to character eaten by '-'\n\t\t *  And return pointer to buf.\n\t\t */\n\t\t*from = seg + width - 1;\n\t\treturn (buf);\n\t}\n\n\t*p = '\\0';\n\n\treturn (seg);\n}\n\nstatic int\n_term_columns (void)\n{\n\tchar *val;\n\tint  cols = 80;\n\n\tif ((val = getenv (\"COLUMNS\"))) {\n\t\tchar *p;\n\t\tlong lval = strtol (val, &p, 10);\n\n\t\tif (p && (*p == '\\0'))\n\t\t\tcols = (int) lval;\n\t}\n\n\treturn (cols);\n}\n\nstatic void\n_spank_opt_print(struct spank_option *opt, FILE * fp, int left_pad, int width)\n{\n\tint n;\n\tchar *equals = \"\";\n\tchar *arginfo = \"\";\n\tchar *p, *q;\n\tchar info [81];\n\tchar seg [81];\n\tchar buf [4096];\n\n\tint  columns = _term_columns ();\n\tint  descrsiz = columns - width;\n\n\tif (opt->arginfo) {\n\t\tequals = \"=\";\n\t\targinfo = opt->arginfo;\n\t}\n\n\tn = snprintf(info, sizeof(info), \"%*s--%s%s%s\",\n\t\t     left_pad, \"\", opt->name, equals, arginfo);\n\n\tif ((n < 0) || (n > columns)) {\n\t\tconst char trunc[] = \"+\";\n\t\tint len = strlen(trunc);\n\t\tp = info + columns - len - 1;\n\t\tsnprintf(p, len + 1, \"%s\", trunc);\n\t}\n\n\n\tq = buf;\n\tstrlcpy (buf, opt->usage, sizeof (buf));\n\n\tp = _get_next_segment (&q, descrsiz, seg, sizeof (seg));\n\n\tif (n < width)\n\t\tfprintf(fp, \"%-*s%s\\n\", width, info, p);\n\telse\n\t\tfprintf(fp, \"\\n%s\\n%*s%s\\n\", info, width, \"\", p);\n\n\t/* Get remaining line-wrapped lines.\n\t */\n\twhile ((p = _get_next_segment (&q, descrsiz, seg, sizeof (seg))))\n\t\tfprintf(fp, \"%*s%s\\n\", width, \"\", p);\n\n\treturn;\n}\n\nint spank_print_options(FILE * fp, int left_pad, int width)\n{\n\tstruct spank_plugin_opt *p;\n\tListIterator i;\n\tList option_cache = get_global_option_cache();\n\n\tif ((option_cache == NULL) || (list_count(option_cache) == 0))\n\t\treturn (0);\n\n\tfprintf(fp, \"\\nOptions provided by plugins:\\n\");\n\n\ti = list_iterator_create(option_cache);\n\twhile ((p = list_next(i))) {\n\t\tif (p->disabled)\n\t\t\tcontinue;\n\t\t_spank_opt_print(p->opt, fp, left_pad, width);\n\t}\n\tlist_iterator_destroy(i);\n\n\treturn (0);\n}\n\n#define OPT_TYPE_SPANK 0x4400\n\nstatic char _canonical_char (char c)\n{\n\tif (!isalnum ((int)c))\n\t\treturn '_';\n\telse\n\t\treturn c;\n}\n\n/*\n *  Create spank option environment variable name from option name.\n */\nstatic char * _opt_env_name (struct spank_plugin_opt *p, char *buf, size_t siz)\n{\n\tconst char * name = p->opt->name;\n\tconst char * pname = p->plugin->name;\n\tint i, n;\n\n\tstrlcpy (buf, SPANK_OPTION_ENV_PREFIX, siz);\n\n\t/*\n\t *  First append the plugin name associated with this option:\n\t */\n\tn = 0;\n\tfor (i = strlen (buf); i < siz - 1 && n < strlen (pname); i++)\n\t    buf[i] = _canonical_char (pname[n++]);\n\n\t/*\n\t *  Append _\n\t */\n\tbuf[i] = '_';\n\tbuf[i+1] = '\\0';\n\n\t/*\n\t *  Now incorporate the option name:\n\t */\n\tn = 0;\n\tfor (i = strlen (buf); i < siz - 1 && n < strlen (name); i++)\n\t    buf[i] = _canonical_char (name[n++]);\n\tbuf[i] = '\\0';\n\n\treturn (buf);\n}\n\nstatic int _option_setenv (struct spank_plugin_opt *option)\n{\n\tchar var[1024];\n\tchar *arg = option->optarg;\n\n\t_opt_env_name(option, var, sizeof(var));\n\n\t/*\n\t * Old glibc behavior was to set the variable with an empty value if\n\t * the option was NULL. Newer glibc versions will segfault instead,\n\t * so feed it an empty string when necessary to maintain backwards\n\t * compatibility.\n\t */\n\tif (!option->optarg)\n\t\targ = \"\";\n\n\tif (setenv(var, arg, 1) < 0)\n\t\terror(\"failed to set %s=%s in env\", var, arg);\n\n\t/*\n\t * Use the possibly-NULL value and let the command itself figure\n\t * out how to handle it. This will usually result in \"(null)\"\n\t * instead of \"\" used above.\n\t */\n\n\tif (dyn_spank_set_job_env(var, option->optarg, 1) < 0)\n\t\terror(\"failed to set %s=%s in env\", var, option->optarg);\n\n\treturn (0);\n}\n\nstatic int spank_stack_set_remote_options_env (struct spank_stack *stack)\n{\n\tstruct spank_plugin_opt *p;\n\tListIterator i;\n\tList option_cache;\n\n\tif (stack == NULL)\n\t\treturn (0);\n\toption_cache = stack->option_cache;\n\n\tif ((option_cache == NULL) || (list_count(option_cache) == 0))\n\t\treturn (0);\n\n\ti = list_iterator_create(option_cache);\n\twhile ((p = list_next(i))) {\n\t\tif (p->found)\n\t\t\t_option_setenv (p);\n\t}\n\tlist_iterator_destroy(i);\n\treturn (0);\n}\n\nint spank_set_remote_options(job_options_t opts)\n{\n\tstruct spank_plugin_opt *p;\n\tListIterator i;\n\tList option_cache;\n\n\tif (global_spank_stack == NULL)\n\t\treturn (0);\n\toption_cache = global_spank_stack->option_cache;\n\n\tif ((option_cache == NULL) || (list_count(option_cache) == 0))\n\t\treturn (0);\n\n\ti = list_iterator_create(option_cache);\n\twhile ((p = list_next(i))) {\n\t\tchar optstr[1024];\n\n\t\tif (!p->found)\n\t\t\tcontinue;\n\n\t\tsnprintf(optstr, sizeof(optstr), \"%s:%s\",\n\t\t\t p->opt->name, p->plugin->name);\n\n\t\tjob_options_append(opts, OPT_TYPE_SPANK, optstr,\n\t\t\t\t   p->optarg);\n\t}\n\tlist_iterator_destroy(i);\n\treturn (0);\n}\n\nstruct opt_find_args {\n\tconst char *optname;\n\tconst char *plugin_name;\n};\n\nstatic int _opt_find(struct spank_plugin_opt *p,\n\t\t     struct opt_find_args *args)\n{\n\tif (xstrcmp(p->plugin->name, args->plugin_name) != 0)\n\t\treturn (0);\n\tif (xstrcmp(p->opt->name, args->optname) != 0)\n\t\treturn (0);\n\treturn (1);\n}\n\nstatic struct spank_plugin_opt *\nspank_stack_find_option_by_name(struct spank_stack *stack, const char *str)\n{\n\tstruct spank_plugin_opt *opt = NULL;\n\tstruct opt_find_args args;\n\tchar buf[256];\n\tchar *name;\n\tList option_cache = stack->option_cache;\n\n\tif (strlcpy(buf, str, sizeof(buf)) >= sizeof(buf)) {\n\t\terror(\"plugin option \\\"%s\\\" too big. Ignoring.\", str);\n\t\treturn (NULL);\n\t}\n\n\tif (!(name = strchr(buf, ':'))) {\n\t\terror(\"Malformed plugin option \\\"%s\\\" received. Ignoring\",\n\t\t      str);\n\t\treturn (NULL);\n\t}\n\n\t*(name++) = '\\0';\n\n\targs.optname = buf;\n\targs.plugin_name = name;\n\n\tif (option_cache) {\n\t\topt = list_find_first(option_cache, (ListFindF) _opt_find,\n\t\t\t\t      &args);\n\t\tif (opt == NULL) {\n\t\t\terror(\"Warning: SPANK plugin \\\"%s\\\" option \\\"%s\\\" not \"\n\t\t\t      \"found\", name, buf);\n\t\t\treturn (NULL);\n\t\t}\n\t} else {\n\t\terror(\"Warning: no SPANK plugin found to process option \\\"%s\\\"\",\n\t\t      name);\n\t\treturn (NULL);\n\t}\n\n\treturn (opt);\n}\n\nspank_err_t\nspank_option_getopt (spank_t sp, struct spank_option *opt, char **argp)\n{\n\tconst char *val;\n\tchar var[1024];\n\tList option_cache;\n\tstruct spank_plugin_opt *spopt;\n\n\tif (argp)\n\t\t*argp = NULL;\n\n\tif (!sp->plugin) {\n\t\terror (\"spank_option_getopt: Not called from a plugin!?\");\n\t\treturn (ESPANK_NOT_AVAIL);\n\t}\n\n\tif (sp->phase == SPANK_INIT)\n\t\treturn (ESPANK_NOT_AVAIL);\n\n\tif (!opt || !opt->name)\n\t\treturn (ESPANK_BAD_ARG);\n\n\tif (opt->has_arg && !argp)\n\t\treturn (ESPANK_BAD_ARG);\n\n\t/*\n\t *   First check the cache:\n\t */\n\toption_cache = sp->stack->option_cache;\n\tspopt = list_find_first (option_cache,\n\t\t\t\t (ListFindF) _opt_by_name,\n\t\t\t\t opt->name);\n\tif (spopt) {\n\t\t/*\n\t\t *  Return failure if option is cached but hasn't been\n\t\t *   used on the command line or specified by user.\n\t\t */\n\t\tif (!spopt->found)\n\t\t\treturn (ESPANK_ERROR);\n\n\t\tif (opt->has_arg && argp)\n\t\t\t*argp = spopt->optarg;\n\t\treturn (ESPANK_SUCCESS);\n\t}\n\n\t/*\n\t *  Otherwise, check current environment:\n\t *\n\t *  We need to check for variables that start with either\n\t *   the default spank option env prefix, or the default\n\t *   prefix + an *extra* prefix of SPANK_, in case we're\n\t *   running in prolog/epilog, where SLURM prepends SPANK_\n\t *   to all spank job environment variables.\n\t */\n\tspopt = _spank_plugin_opt_create (sp->plugin, opt, 0);\n\tmemcpy (var, \"SPANK_\", 6);\n\tif ((val = getenv (_opt_env_name(spopt, var+6, sizeof (var) - 6))) ||\n\t    (val = getenv (var))) {\n\t\tspopt->optarg = xstrdup (val);\n\t\tspopt->found = 1;\n\t\tif (opt->has_arg && argp)\n\t\t\t*argp = spopt->optarg;\n\t}\n\n\t/*\n\t *  Cache the result\n\t */\n\tlist_append (option_cache, spopt);\n\n\tif (!spopt->found)\n\t\treturn (ESPANK_ERROR);\n\n\treturn (ESPANK_SUCCESS);\n}\n\n\nint spank_get_remote_options_env (char **env)\n{\n\treturn spank_stack_get_remote_options_env (global_spank_stack, env);\n}\n\n\nstatic int\nspank_stack_get_remote_options_env (struct spank_stack *stack, char **env)\n{\n\tchar var [1024];\n\tconst char *arg;\n\tstruct spank_plugin_opt *option;\n\tListIterator i;\n\tList option_cache = stack->option_cache;\n\n\tif (!option_cache)\n\t\treturn (0);\n\n\ti = list_iterator_create (option_cache);\n\twhile ((option = list_next (i))) {\n\t\tstruct spank_option *p = option->opt;\n\n\t\tif (!(arg = getenvp (env, _opt_env_name (option, var, sizeof(var)))))\n\t\t\tcontinue;\n\n\t\tif (p->cb && (((*p->cb) (p->val, arg, 1)) < 0)) {\n\t\t\terror (\"spank: failed to process option %s=%s\",\n\t\t\t       p->name, arg);\n\t\t}\n\n\t\t/*\n\t\t *  Now remove the environment variable.\n\t\t *   It is no longer needed.\n\t\t */\n\t\tunsetenvp (env, var);\n\n\t}\n\tlist_iterator_destroy (i);\n\n\treturn (0);\n}\n\nint spank_get_remote_options(job_options_t opts)\n{\n\treturn spank_stack_get_remote_options (global_spank_stack, opts);\n}\n\nstatic int\nspank_stack_get_remote_options(struct spank_stack *stack, job_options_t opts)\n{\n\tconst struct job_option_info *j;\n\n\tjob_options_iterator_reset(opts);\n\twhile ((j = job_options_next(opts))) {\n\t\tstruct spank_plugin_opt *opt;\n\t\tstruct spank_option *p;\n\n\t\tif (j->type != OPT_TYPE_SPANK)\n\t\t\tcontinue;\n\n\t\tif (!(opt = spank_stack_find_option_by_name(stack, j->option)))\n\t\t\tcontinue;\n\n\t\tp = opt->opt;\n\n\t\tif (p->cb && (((*p->cb) (p->val, j->optarg, 1)) < 0)) {\n\t\t\terror(\"spank: failed to process option %s=%s\",\n\t\t\t      p->name, j->optarg);\n\t\t}\n\t}\n\n\treturn (0);\n}\n\n/*\n *  Clear any environment variables for spank options.\n *   spank option env vars  have a prefix of SPANK_OPTION_ENV_PREFIX,\n *   or SPANK_ + SPANK_OPTION_ENV_PREFIX\n */\nint spank_clear_remote_options_env (char **env)\n{\n\tchar **ep;\n\tint len = strlen (SPANK_OPTION_ENV_PREFIX);\n\n\tfor (ep = env; *ep; ep++) {\n\t\tchar *p = *ep;\n\t\tif (xstrncmp (*ep, \"SPANK_\", 6) == 0)\n\t\t\tp = *ep+6;\n\t\tif (xstrncmp (p, SPANK_OPTION_ENV_PREFIX, len) == 0) {\n\t\t\tchar *end = strchr (p+len, '=');\n\t\t\tif (end) {\n\t\t\t\tchar name[1024];\n\t\t\t\tmemcpy (name, *ep, end - *ep);\n\t\t\t\tname [end - *ep] = '\\0';\n\t\t\t\tdebug (\"unsetenv (%s)\\n\", name);\n\t\t\t\tunsetenvp (env, name);\n\t\t\t}\n\t\t}\n\t}\n\treturn (0);\n}\n\n\n\nstatic int tasks_execd (spank_t spank)\n{\n\treturn ( (spank->phase == STEP_TASK_POST_FORK)\n\t      || (spank->phase == STEP_TASK_EXIT)\n\t      || (spank->phase == SPANK_EXIT) );\n}\n\nstatic spank_err_t\n_global_to_local_id(stepd_step_rec_t *job, uint32_t gid, uint32_t *p2uint32)\n{\n\tint i;\n\t*p2uint32 = (uint32_t) -1;\n\tif ((job == NULL) || (gid >= job->ntasks))\n\t\treturn (ESPANK_BAD_ARG);\n\tfor (i = 0; i < job->node_tasks; i++) {\n\t\tif (job->task[i]->gtid == gid) {\n\t\t\t*p2uint32 = job->task[i]->id;\n\t\t\treturn (ESPANK_SUCCESS);\n\t\t}\n\t}\n\treturn (ESPANK_NOEXIST);\n}\n\n\n/*\n *  Return 1 if spank_item_t is valid for S_TYPE_LOCAL\n */\nstatic int _valid_in_local_context (spank_item_t item)\n{\n\tint rc = 0;\n\tswitch (item) {\n\tcase S_JOB_UID:\n\tcase S_JOB_GID:\n\tcase S_JOB_ID:\n\tcase S_JOB_STEPID:\n\tcase S_JOB_ARGV:\n\tcase S_JOB_ENV:\n\tcase S_JOB_TOTAL_TASK_COUNT:\n\tcase S_JOB_NNODES:\n\t\trc = 1;\n\t\tbreak;\n\tdefault:\n\t\trc = 0;\n\t}\n\treturn (rc);\n}\n\nstatic int _valid_in_allocator_context (spank_item_t item)\n{\n\tswitch (item) {\n\t  case S_JOB_UID:\n\t  case S_JOB_GID:\n\t\t  return 1;\n\t  default:\n\t\t  return 0;\n\t}\n}\n\nstatic spank_err_t _check_spank_item_validity (spank_t spank, spank_item_t item)\n{\n\t/*\n\t *  Valid in all contexts:\n\t */\n\tswitch (item) {\n\t  case S_SLURM_VERSION:\n\t  case S_SLURM_VERSION_MAJOR:\n\t  case S_SLURM_VERSION_MINOR:\n\t  case S_SLURM_VERSION_MICRO:\n\t\t  return ESPANK_SUCCESS;\n\t  default:\n\t\t  break; /* fallthru */\n\t}\n\n\t/*\n\t *  No spank_item_t is available in slurmd context at this time.\n\t */\n\tif (spank->stack->type == S_TYPE_SLURMD)\n\t\treturn ESPANK_NOT_AVAIL;\n\telse if (spank->stack->type == S_TYPE_JOB_SCRIPT) {\n\t\tif (item != S_JOB_UID && item != S_JOB_ID)\n\t\t\treturn ESPANK_NOT_AVAIL;\n\t}\n\telse if (spank->stack->type == S_TYPE_LOCAL) {\n\t\tif (!_valid_in_local_context (item))\n\t\t\treturn ESPANK_NOT_REMOTE;\n\t\telse if (spank->job == NULL)\n\t\t\treturn ESPANK_NOT_AVAIL;\n\t}\n\telse if (spank->stack->type == S_TYPE_ALLOCATOR) {\n\t\tif (_valid_in_allocator_context (item)) {\n\t\t\tif (spank->job)\n\t\t\t\treturn ESPANK_SUCCESS;\n\t\t\telse\n\t\t\t\treturn ESPANK_NOT_AVAIL;\n\t\t}\n\t\telse if (_valid_in_local_context (item))\n\t\t\treturn ESPANK_BAD_ARG;\n\t\telse\n\t\t\treturn ESPANK_NOT_REMOTE;\n\t}\n\n\t/* All items presumably valid in remote context */\n\treturn ESPANK_SUCCESS;\n}\n\n/*\n *  Global functions for SPANK plugins\n */\n\nconst char * spank_strerror (spank_err_t err)\n{\n\tswitch (err) {\n\tcase ESPANK_SUCCESS:\n\t\treturn \"Success\";\n\tcase ESPANK_ERROR:\n\t\treturn \"Generic error\";\n\tcase ESPANK_BAD_ARG:\n\t\treturn \"Bad argument\";\n\tcase ESPANK_NOT_TASK:\n\t\treturn \"Not in task context\";\n\tcase ESPANK_ENV_EXISTS:\n\t\treturn \"Environment variable exists\";\n\tcase ESPANK_ENV_NOEXIST:\n\t\treturn \"No such environment variable\";\n\tcase ESPANK_NOSPACE:\n\t\treturn \"Buffer too small\";\n\tcase ESPANK_NOT_REMOTE:\n\t\treturn \"Valid only in remote context\";\n\tcase ESPANK_NOEXIST:\n\t\treturn \"Id/PID does not exist on this node\";\n\tcase ESPANK_NOT_EXECD:\n\t\treturn \"Lookup by PID requested, but no tasks running\";\n\tcase ESPANK_NOT_AVAIL:\n\t\treturn \"Item not available from this callback\";\n\tcase ESPANK_NOT_LOCAL:\n\t\treturn \"Valid only in local or allocator context\";\n\t}\n\n\treturn \"Unknown\";\n}\n\nint spank_symbol_supported (const char *name)\n{\n\tint i;\n\n\tif (name == NULL)\n\t\treturn (-1);\n\n\tfor (i = 0; i < n_spank_syms; i++) {\n\t\tif (xstrcmp (spank_syms [i], name) == 0)\n\t\t\treturn (1);\n\t}\n\n\treturn (0);\n}\n\nint spank_remote(spank_t spank)\n{\n\tif ((spank == NULL) || (spank->magic != SPANK_MAGIC))\n\t\treturn (-1);\n\tif (spank->stack->type == S_TYPE_REMOTE)\n\t\treturn (1);\n\telse\n\t\treturn (0);\n}\n\nspank_context_t spank_context (void)\n{\n\tif (global_spank_stack == NULL)\n\t\treturn S_CTX_ERROR;\n\tswitch (global_spank_stack->type) {\n\t  case S_TYPE_REMOTE:\n\t\t  return S_CTX_REMOTE;\n\t  case S_TYPE_LOCAL:\n\t\t  return S_CTX_LOCAL;\n\t  case S_TYPE_ALLOCATOR:\n\t\t  return S_CTX_ALLOCATOR;\n\t  case S_TYPE_SLURMD:\n\t\t  return S_CTX_SLURMD;\n\t  case S_TYPE_JOB_SCRIPT:\n\t\t  return S_CTX_JOB_SCRIPT;\n\t  default:\n\t\t  return S_CTX_ERROR;\n\t}\n\n\treturn S_CTX_ERROR;\n}\n\nspank_err_t spank_get_item(spank_t spank, spank_item_t item, ...)\n{\n\tint *p2int;\n\tuint32_t *p2uint32;\n\tuint64_t *p2uint64;\n\tuint32_t  uint32;\n\tuint16_t *p2uint16;\n\tuid_t *p2uid;\n\tgid_t *p2gid;\n\tgid_t **p2gids;\n\tpid_t *p2pid;\n\tpid_t  pid;\n\tchar ***p2argv;\n\tchar **p2str;\n\tchar **p2vers;\n\tstepd_step_task_info_t *task;\n\tstepd_step_rec_t  *slurmd_job = NULL;\n\tstruct spank_launcher_job_info *launcher_job = NULL;\n\tstruct job_script_info *s_job_info = NULL;\n\tva_list vargs;\n\tspank_err_t rc = ESPANK_SUCCESS;\n\n\tif ((spank == NULL) || (spank->magic != SPANK_MAGIC))\n\t\treturn (ESPANK_BAD_ARG);\n\n\t/*\n\t *  Check for validity of the given item in the current context\n\t */\n\trc = _check_spank_item_validity (spank, item);\n\tif (rc != ESPANK_SUCCESS)\n\t\treturn (rc);\n\n\tif (spank->stack->type == S_TYPE_LOCAL)\n\t\tlauncher_job = spank->job;\n\telse if (spank->stack->type == S_TYPE_REMOTE)\n\t\tslurmd_job = spank->job;\n\telse if (spank->stack->type == S_TYPE_JOB_SCRIPT)\n\t\ts_job_info = spank->job;\n\n\tva_start(vargs, item);\n\tswitch (item) {\n\tcase S_JOB_UID:\n\t\tp2uid = va_arg(vargs, uid_t *);\n\t\tif (spank->stack->type == S_TYPE_LOCAL)\n\t\t\t*p2uid = launcher_job->uid;\n\t\telse if (spank->stack->type == S_TYPE_REMOTE)\n\t\t\t*p2uid = slurmd_job->uid;\n\t\telse if (spank->stack->type == S_TYPE_JOB_SCRIPT)\n\t\t\t*p2uid = s_job_info->uid;\n\t\telse\n\t\t\t*p2uid = getuid();\n\t\tbreak;\n\tcase S_JOB_GID:\n\t\tp2gid = va_arg(vargs, gid_t *);\n\t\tif (spank->stack->type == S_TYPE_LOCAL)\n\t\t\t*p2gid = launcher_job->gid;\n\t\telse if (spank->stack->type == S_TYPE_REMOTE)\n\t\t\t*p2gid = slurmd_job->gid;\n\t\telse\n\t\t\t*p2gid = getgid();\n\t\tbreak;\n\tcase S_JOB_SUPPLEMENTARY_GIDS:\n\t\tp2gids = va_arg(vargs, gid_t **);\n\t\tp2int = va_arg(vargs, int *);\n\t\tif (slurmd_job) {\n\t\t\t*p2gids = slurmd_job->gids;\n\t\t\t*p2int = slurmd_job->ngids;\n\t\t} else {\n\t\t\t*p2gids = NULL;\n\t\t\t*p2int = 0;\n\t\t}\n\t\tbreak;\n\tcase S_JOB_ID:\n\t\tp2uint32 = va_arg(vargs, uint32_t *);\n\t\tif (spank->stack->type == S_TYPE_LOCAL)\n\t\t\t*p2uint32 = launcher_job->jobid;\n\t\telse if (spank->stack->type == S_TYPE_REMOTE)\n\t\t\t*p2uint32 = slurmd_job->jobid;\n\t\telse if (spank->stack->type == S_TYPE_JOB_SCRIPT)\n\t\t\t*p2uint32 = s_job_info->jobid;\n\t\tbreak;\n\tcase S_JOB_STEPID:\n\t\tp2uint32 = va_arg(vargs, uint32_t *);\n\t\tif (spank->stack->type == S_TYPE_LOCAL)\n\t\t\t*p2uint32 = launcher_job->stepid;\n\t\telse if (slurmd_job)\n\t\t\t*p2uint32 = slurmd_job->stepid;\n\t\telse\n\t\t\t*p2uint32 = 0;\n\t\tbreak;\n\tcase S_JOB_NNODES:\n\t\tp2uint32 = va_arg(vargs, uint32_t *);\n\t\tif (spank->stack->type == S_TYPE_LOCAL) {\n\t\t\tif (launcher_job->step_layout)\n\t\t\t\t*p2uint32 = launcher_job->step_layout->\n\t\t\t\t\t    node_cnt;\n\t\t\telse {\n\t\t\t\t*p2uint32 = 0;\n\t\t\t\trc = ESPANK_ENV_NOEXIST;\n\t\t\t}\n\t\t} else if (slurmd_job)\n\t\t\t*p2uint32 = slurmd_job->nnodes;\n\t\telse\n\t\t\t*p2uint32 = 0;\n\t\tbreak;\n\tcase S_JOB_NODEID:\n\t\tp2uint32 = va_arg(vargs, uint32_t *);\n\t\tif (slurmd_job)\n\t\t\t*p2uint32 = slurmd_job->nodeid;\n\t\telse\n\t\t\t*p2uint32 = 0;\n\t\tbreak;\n\tcase S_JOB_LOCAL_TASK_COUNT:\n\t\tp2uint32 = va_arg(vargs, uint32_t *);\n\t\tif (slurmd_job)\n\t\t\t*p2uint32 = slurmd_job->node_tasks;\n\t\telse\n\t\t\t*p2uint32 = 0;\n\t\tbreak;\n\tcase S_JOB_TOTAL_TASK_COUNT:\n\t\tp2uint32 = va_arg(vargs, uint32_t *);\n\t\tif (spank->stack->type == S_TYPE_LOCAL) {\n\t\t\tif (launcher_job->step_layout)\n\t\t\t\t*p2uint32 = launcher_job->step_layout->\n\t\t\t\t\t    task_cnt;\n\t\t\telse {\n\t\t\t\t*p2uint32 = 0;\n\t\t\t\trc = ESPANK_ENV_NOEXIST;\n\t\t\t}\n\t\t} else if (slurmd_job)\n\t\t\t*p2uint32 = slurmd_job->ntasks;\n\t\telse\n\t\t\t*p2uint32 = 0;\n\t\tbreak;\n\tcase S_JOB_NCPUS:\n\t\tp2uint16 = va_arg(vargs, uint16_t *);\n\t\tif (slurmd_job)\n\t\t\t*p2uint16 = slurmd_job->cpus;\n\t\telse\n\t\t\t*p2uint16 = 0;\n\t\tbreak;\n\tcase S_STEP_CPUS_PER_TASK:\n\t\tp2uint32 = va_arg(vargs, uint32_t *);\n\t\tif (slurmd_job)\n\t\t\t*p2uint32 = slurmd_job->cpus_per_task;\n\t\telse\n\t\t\t*p2uint32 = 0;\n\t\tbreak;\n\tcase S_JOB_ARGV:\n\t\tp2int = va_arg(vargs, int *);\n\t\tp2argv = va_arg(vargs, char ***);\n\t\tif (spank->stack->type == S_TYPE_LOCAL) {\n\t\t\t*p2int = launcher_job->argc;\n\t\t\t*p2argv = launcher_job->argv;\n\t\t} else if (slurmd_job) {\n\t\t\t*p2int = slurmd_job->argc;\n\t\t\t*p2argv = slurmd_job->argv;\n\t\t} else {\n\t\t\t*p2int = 0;\n\t\t\t*p2argv = NULL;\n\t\t}\n\t\tbreak;\n\tcase S_JOB_ENV:\n\t\tp2argv = va_arg(vargs, char ***);\n\t\tif (slurmd_job)\n\t\t\t*p2argv = slurmd_job->env;\n\t\telse\n\t\t\t*p2argv = NULL;\n\t\tbreak;\n\tcase S_TASK_ID:\n\t\tp2int = va_arg(vargs, int *);\n\t\tif (!spank->task) {\n\t\t\t*p2int = -1;\n\t\t\trc = ESPANK_NOT_TASK;\n\t\t} else {\n\t\t\t*p2int = spank->task->id;\n\t\t}\n\t\tbreak;\n\tcase S_TASK_GLOBAL_ID:\n\t\tp2uint32 = va_arg(vargs, uint32_t *);\n\t\tif (!spank->task) {\n\t\t\trc = ESPANK_NOT_TASK;\n\t\t} else {\n\t\t\t*p2uint32 = spank->task->gtid;\n\t\t}\n\t\tbreak;\n\tcase S_TASK_EXIT_STATUS:\n\t\tp2int = va_arg(vargs, int *);\n\t\tif (!spank->task || !spank->task->exited) {\n\t\t\trc = ESPANK_NOT_TASK;\n\t\t} else {\n\t\t\t*p2int = spank->task->estatus;\n\t\t}\n\t\tbreak;\n\tcase S_TASK_PID:\n\t\tp2pid = va_arg(vargs, pid_t *);\n\t\tif (!spank->task) {\n\t\t\trc = ESPANK_NOT_TASK;\n\t\t\t*p2pid = 0;\n\t\t} else {\n\t\t\t*p2pid = spank->task->pid;\n\t\t}\n\t\tbreak;\n\tcase S_JOB_PID_TO_GLOBAL_ID:\n\t\tpid = va_arg(vargs, pid_t);\n\t\tp2uint32 = va_arg(vargs, uint32_t *);\n\t\t*p2uint32 = (uint32_t) -1;\n\n\t\tif (!tasks_execd(spank))\n\t\t\trc = ESPANK_NOT_EXECD;\n\t\telse if (!(task = job_task_info_by_pid (slurmd_job, pid)))\n\t\t\trc = ESPANK_NOEXIST;\n\t\telse\n\t\t\t*p2uint32 = task->gtid;\n\t\tbreak;\n\tcase S_JOB_PID_TO_LOCAL_ID:\n\t\tpid = va_arg(vargs, pid_t);\n\t\tp2uint32 = va_arg(vargs, uint32_t *);\n\t\t*p2uint32 = (uint32_t) -1;\n\n\t\tif (!tasks_execd(spank))\n\t\t\trc = ESPANK_NOT_EXECD;\n\t\telse if (!(task = job_task_info_by_pid (slurmd_job, pid)))\n\t\t\trc = ESPANK_NOEXIST;\n\t\telse\n\t\t\t*p2uint32 = task->id;\n\t\tbreak;\n\tcase S_JOB_LOCAL_TO_GLOBAL_ID:\n\t\tuint32 = va_arg(vargs, uint32_t);\n\t\tp2uint32 = va_arg(vargs, uint32_t *);\n\t\t*p2uint32 = (uint32_t) -1;\n\n\t\tif (slurmd_job && (uint32 <= slurmd_job->node_tasks) &&\n\t\t    slurmd_job->task && slurmd_job->task[uint32]) {\n\t\t\t*p2uint32 = slurmd_job->task[uint32]->gtid;\n\t\t} else\n\t\t\trc = ESPANK_NOEXIST;\n\t\tbreak;\n\tcase S_JOB_GLOBAL_TO_LOCAL_ID:\n\t\tuint32 = va_arg(vargs, uint32_t);\n\t\tp2uint32 = va_arg(vargs, uint32_t *);\n\t\trc = _global_to_local_id (slurmd_job, uint32, p2uint32);\n\t\tbreak;\n\tcase S_JOB_ALLOC_CORES:\n\t\tp2str = va_arg(vargs, char **);\n\t\tif (slurmd_job)\n\t\t\t*p2str = slurmd_job->job_alloc_cores;\n\t\telse\n\t\t\t*p2str = NULL;\n\t\tbreak;\n\tcase S_JOB_ALLOC_MEM:\n\t\tp2uint64 = va_arg(vargs, uint64_t *);\n\t\tif (slurmd_job)\n\t\t\t*p2uint64 = slurmd_job->job_mem;\n\t\telse\n\t\t\t*p2uint64 = 0;\n\t\tbreak;\n\tcase S_STEP_ALLOC_CORES:\n\t\tp2str = va_arg(vargs, char **);\n\t\tif (slurmd_job)\n\t\t\t*p2str = slurmd_job->step_alloc_cores;\n\t\telse\n\t\t\t*p2str = NULL;\n\t\tbreak;\n\tcase S_STEP_ALLOC_MEM:\n\t\tp2uint64 = va_arg(vargs, uint64_t *);\n\t\tif (slurmd_job)\n\t\t\t*p2uint64 = slurmd_job->step_mem;\n\t\telse\n\t\t\t*p2uint64 = 0;\n\t\tbreak;\n\tcase S_SLURM_RESTART_COUNT:\n\t\tp2uint32 = va_arg(vargs, uint32_t *);\n\t\tif (slurmd_job)\n\t\t\t*p2uint32 = slurmd_job->restart_cnt;\n\t\telse\n\t\t\t*p2uint32 = 0;\n\t\tbreak;\n\tcase S_SLURM_VERSION:\n\t\tp2vers = va_arg(vargs, char  **);\n\t\t*p2vers = SLURM_VERSION_STRING;\n\t\tbreak;\n\tcase S_SLURM_VERSION_MAJOR:\n\t\tp2vers = va_arg(vargs, char  **);\n\t\t*p2vers = SLURM_MAJOR;\n\t\tbreak;\n\tcase S_SLURM_VERSION_MINOR:\n\t\tp2vers = va_arg(vargs, char  **);\n\t\t*p2vers = SLURM_MINOR;\n\t\tbreak;\n\tcase S_SLURM_VERSION_MICRO:\n\t\tp2vers = va_arg(vargs, char  **);\n\t\t*p2vers = SLURM_MICRO;\n\t\tbreak;\n\tdefault:\n\t\trc = ESPANK_BAD_ARG;\n\t\tbreak;\n\t}\n\tva_end(vargs);\n\treturn (rc);\n}\n\nspank_err_t spank_env_access_check (spank_t spank)\n{\n\tif ((spank == NULL) || (spank->magic != SPANK_MAGIC))\n\t\treturn (ESPANK_BAD_ARG);\n\tif (spank->stack->type != S_TYPE_REMOTE)\n\t\treturn (ESPANK_NOT_REMOTE);\n\tif (spank->job == NULL)\n\t\treturn (ESPANK_BAD_ARG);\n\treturn (ESPANK_SUCCESS);\n\n}\n\nspank_err_t spank_getenv(spank_t spank, const char *var, char *buf,\n\t\t\t int len)\n{\n\tchar *val;\n\tspank_err_t err = spank_env_access_check (spank);\n\n\tif (err != ESPANK_SUCCESS)\n\t\treturn (err);\n\n\tif (len < 0)\n\t\treturn (ESPANK_BAD_ARG);\n\n\tif (!(val = getenvp(((stepd_step_rec_t *) spank->job)->env, var)))\n\t\treturn (ESPANK_ENV_NOEXIST);\n\n\tif (strlcpy(buf, val, len) >= len)\n\t\treturn (ESPANK_NOSPACE);\n\n\treturn (ESPANK_SUCCESS);\n}\n\nspank_err_t spank_setenv(spank_t spank, const char *var, const char *val,\n\t\t\t int overwrite)\n{\n\tstepd_step_rec_t * job;\n\tspank_err_t err = spank_env_access_check (spank);\n\n\tif (err != ESPANK_SUCCESS)\n\t\treturn (err);\n\n\tif ((var == NULL) || (val == NULL))\n\t\treturn (ESPANK_BAD_ARG);\n\n\tjob = spank->job;\n\n\tif (getenvp(job->env, var) && !overwrite)\n\t\treturn (ESPANK_ENV_EXISTS);\n\n\tif (setenvf(&job->env, var, \"%s\", val) < 0)\n\t\treturn (ESPANK_ERROR);\n\n\treturn (ESPANK_SUCCESS);\n}\n\nspank_err_t spank_unsetenv (spank_t spank, const char *var)\n{\n\tspank_err_t err = spank_env_access_check (spank);\n\n\tif (err != ESPANK_SUCCESS)\n\t\treturn (err);\n\n\tif (var == NULL)\n\t\treturn (ESPANK_BAD_ARG);\n\n\tunsetenvp(((stepd_step_rec_t *) spank->job)->env, var);\n\n\treturn (ESPANK_SUCCESS);\n}\n\n\n/*\n *  Dynamically loaded versions of spank_*_job_env\n */\nconst char *dyn_spank_get_job_env(const char *name)\n{\n\tvoid *h = dlopen(NULL, 0);\n\tchar * (*fn)(const char *n);\n\tchar *rc;\n\n\tfn = dlsym(h, \"spank_get_job_env\");\n\tif (fn == NULL) {\n\t\t(void) dlclose(h);\n\t\treturn NULL;\n\t}\n\n\trc = ((*fn) (name));\n/*\t(void) dlclose(h);\tNOTE: DO NOT CLOSE OR SPANK WILL BREAK */\n\treturn rc;\n}\n\nint dyn_spank_set_job_env(const char *n, const char *v, int overwrite)\n{\n\tvoid *h = dlopen(NULL, 0);\n\tint (*fn)(const char *n, const char *v, int overwrite);\n\tint rc;\n\n\tfn = dlsym(h, \"spank_set_job_env\");\n\tif (fn == NULL) {\n\t\t(void) dlclose(h);\n\t\treturn (-1);\n\t}\n\n\trc = ((*fn) (n, v, overwrite));\n/*\t(void) dlclose(h);\tNOTE: DO NOT CLOSE OR SPANK WILL BREAK */\n\treturn rc;\n}\n\nextern int dyn_spank_unset_job_env(const char *n)\n{\n\tvoid *h = dlopen(NULL, 0);\n\tint (*fn)(const char *n);\n\tint rc;\n\n\tfn = dlsym(h, \"spank_unset_job_env\");\n\tif (fn == NULL) {\n\t\t(void) dlclose(h);\n\t\treturn (-1);\n\t}\n\n\trc = ((*fn) (n));\n/*\t(void) dlclose(h);\tNOTE: DO NOT CLOSE OR SPANK WILL BREAK */\n\treturn rc;\n}\n\nstatic spank_err_t spank_job_control_access_check (spank_t spank)\n{\n\tif ((spank == NULL) || (spank->magic != SPANK_MAGIC))\n\t\treturn (ESPANK_BAD_ARG);\n\n\tif (spank_remote (spank))\n\t\treturn (ESPANK_NOT_LOCAL);\n\n\tif (spank->stack->type == S_TYPE_SLURMD)\n\t\treturn (ESPANK_NOT_AVAIL);\n\n\treturn (ESPANK_SUCCESS);\n}\n\n\nspank_err_t spank_job_control_getenv (spank_t spank, const char *var,\n\t\t\tchar *buf, int len)\n{\n\tconst char *val;\n\tspank_err_t err;\n\n\tif ((err = spank_job_control_access_check (spank)))\n\t\treturn (err);\n\n\tif ((var == NULL) || (buf == NULL) || (len <= 0))\n\t\treturn (ESPANK_BAD_ARG);\n\n\tval = dyn_spank_get_job_env (var);\n\tif (val == NULL)\n\t\treturn (ESPANK_ENV_NOEXIST);\n\n\tif (strlcpy (buf, val, len) >= len)\n\t\treturn (ESPANK_NOSPACE);\n\n\treturn (ESPANK_SUCCESS);\n}\n\nspank_err_t spank_job_control_setenv (spank_t spank, const char *var,\n\t\t\tconst char *val, int overwrite)\n{\n\tspank_err_t err;\n\n\tif ((err = spank_job_control_access_check (spank)))\n\t\treturn (err);\n\n\tif ((var == NULL) || (val == NULL))\n\t\treturn (ESPANK_BAD_ARG);\n\n\tif (dyn_spank_set_job_env (var, val, overwrite) < 0)\n\t\treturn (ESPANK_BAD_ARG);\n\n\treturn (ESPANK_SUCCESS);\n}\n\nspank_err_t spank_job_control_unsetenv (spank_t spank, const char *var)\n{\n\tspank_err_t err;\n\n\tif ((err = spank_job_control_access_check (spank)))\n\t\treturn (err);\n\n\tif (var == NULL)\n\t\treturn (ESPANK_BAD_ARG);\n\n\tif (dyn_spank_unset_job_env (var) < 0)\n\t\treturn (ESPANK_BAD_ARG);\n\n\treturn (ESPANK_SUCCESS);\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/src/plugins/job_submit/lua/job_submit_lua.c": "/*****************************************************************************\\\n *  job_submit_lua.c - Set defaults in job submit request specifications.\n *****************************************************************************\n *  Copyright (C) 2010 Lawrence Livermore National Security.\n *  Portions Copyright (C) 2010-2015 SchedMD LLC <https://www.schedmd.com>.\n *  Produced at Lawrence Livermore National Laboratory (cf, DISCLAIMER).\n *  Written by Danny Auble <da@llnl.gov>\n *  CODE-OCEC-09-009. All rights reserved.\n *\n *  This file is part of SLURM, a resource management program.\n *  For details, see <https://slurm.schedmd.com/>.\n *  Please also read the included file: DISCLAIMER.\n *\n *  SLURM is free software; you can redistribute it and/or modify it under\n *  the terms of the GNU General Public License as published by the Free\n *  Software Foundation; either version 2 of the License, or (at your option)\n *  any later version.\n *\n *  In addition, as a special exception, the copyright holders give permission\n *  to link the code of portions of this program with the OpenSSL library under\n *  certain conditions as described in each individual source file, and\n *  distribute linked combinations including the two. You must obey the GNU\n *  General Public License in all respects for all of the code used other than\n *  OpenSSL. If you modify file(s) with this exception, you may extend this\n *  exception to your version of the file(s), but you are not obligated to do\n *  so. If you do not wish to do so, delete this exception statement from your\n *  version.  If you delete this exception statement from all source files in\n *  the program, then also delete it here.\n *\n *  SLURM is distributed in the hope that it will be useful, but WITHOUT ANY\n *  WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n *  FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more\n *  details.\n *\n *  You should have received a copy of the GNU General Public License along\n *  with SLURM; if not, write to the Free Software Foundation, Inc.,\n *  51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA.\n\\*****************************************************************************/\n\n#include <dlfcn.h>\n#include <inttypes.h>\n#include <pthread.h>\n#include <signal.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <sys/stat.h>\n#include <sys/types.h>\n#include <unistd.h>\n\n#include <lua.h>\n#include <lauxlib.h>\n#include <lualib.h>\n\n#include \"slurm/slurm.h\"\n#include \"slurm/slurm_errno.h\"\n\n#include \"src/common/slurm_xlator.h\"\n#include \"src/common/assoc_mgr.h\"\n#include \"src/common/xlua.h\"\n#include \"src/common/uid.h\"\n#include \"src/slurmctld/locks.h\"\n#include \"src/slurmctld/slurmctld.h\"\n#include \"src/slurmctld/reservation.h\"\n\n#define _DEBUG 0\n#define MIN_ACCTG_FREQUENCY 30\n\n/*\n * These variables are required by the generic plugin interface.  If they\n * are not found in the plugin, the plugin loader will ignore it.\n *\n * plugin_name - a string giving a human-readable description of the\n * plugin.  There is no maximum length, but the symbol must refer to\n * a valid string.\n *\n * plugin_type - a string suggesting the type of the plugin or its\n * applicability to a particular form of data or method of data handling.\n * If the low-level plugin API is used, the contents of this string are\n * unimportant and may be anything.  SLURM uses the higher-level plugin\n * interface which requires this string to be of the form\n *\n *\t<application>/<method>\n *\n * where <application> is a description of the intended application of\n * the plugin (e.g., \"auth\" for SLURM authentication) and <method> is a\n * description of how this plugin satisfies that application.  SLURM will\n * only load authentication plugins if the plugin_type string has a prefix\n * of \"auth/\".\n *\n * plugin_version - an unsigned 32-bit integer containing the Slurm version\n * (major.minor.micro combined into a single number).\n */\nconst char plugin_name[]       \t= \"Job submit lua plugin\";\nconst char plugin_type[]       \t= \"job_submit/lua\";\nconst uint32_t plugin_version   = SLURM_VERSION_NUMBER;\n\nstatic const char lua_script_path[] = DEFAULT_SCRIPT_DIR \"/job_submit.lua\";\nstatic time_t lua_script_last_loaded = (time_t) 0;\nstatic lua_State *L = NULL;\nstatic char *user_msg = NULL;\n\ntime_t last_lua_jobs_update = (time_t) 0;\ntime_t last_lua_resv_update = (time_t) 0;\n\n/*\n *  Mutex for protecting multi-threaded access to this plugin.\n *   (Only 1 thread at a time should be in here)\n */\nstatic pthread_mutex_t lua_lock = PTHREAD_MUTEX_INITIALIZER;\n\n/* These are defined here so when we link with something other than\n * the slurmctld we will have these symbols defined.  They will get\n * overwritten when linking with the slurmctld.\n */\n#if defined (__APPLE__)\nint accounting_enforce __attribute__((weak_import)) = 0;\nvoid *acct_db_conn  __attribute__((weak_import)) = NULL;\n#else\nint accounting_enforce = 0;\nvoid *acct_db_conn = NULL;\n#endif\n\n/*****************************************************************************\\\n * We've provided a simple example of the type of things you can do with this\n * plugin. If you develop another plugin that may be of interest to others\n * please post it to slurm-dev@schedmd.com  Thanks!\n\\*****************************************************************************/\n\n/* Generic stack dump function for debugging purposes */\nstatic void _stack_dump (char *header, lua_State *L)\n{\n#if _DEBUG\n\tint i;\n\tint top = lua_gettop(L);\n\n\tinfo(\"%s: dumping job_submit/lua stack, %d elements\", header, top);\n\tfor (i = 1; i <= top; i++) {  /* repeat for each level */\n\t\tint type = lua_type(L, i);\n\t\tswitch (type) {\n\t\t\tcase LUA_TSTRING:\n\t\t\t\tinfo(\"string[%d]:%s\", i, lua_tostring(L, i));\n\t\t\t\tbreak;\n\t\t\tcase LUA_TBOOLEAN:\n\t\t\t\tinfo(\"boolean[%d]:%s\", i,\n\t\t\t\t     lua_toboolean(L, i) ? \"true\" : \"false\");\n\t\t\t\tbreak;\n\t\t\tcase LUA_TNUMBER:\n\t\t\t\tinfo(\"number[%d]:%d\", i,\n\t\t\t\t     (int) lua_tonumber(L, i));\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tinfo(\"other[%d]:%s\", i, lua_typename(L, type));\n\t\t\t\tbreak;\n\t\t}\n\t}\n#endif\n}\n\n/*\n *  Lua interface to SLURM log facility:\n */\nstatic int _log_lua_msg (lua_State *L)\n{\n\tconst char *prefix  = \"job_submit.lua\";\n\tint        level    = 0;\n\tconst char *msg;\n\n\t/*\n\t *  Optional numeric prefix indicating the log level\n\t *  of the message.\n\t */\n\n\t/*\n\t *  Pop message off the lua stack\n\t */\n\tmsg = lua_tostring(L, -1);\n\tlua_pop (L, 1);\n\t/*\n\t *  Pop level off stack:\n\t */\n\tlevel = (int)lua_tonumber (L, -1);\n\tlua_pop (L, 1);\n\n\t/*\n\t *  Call appropriate slurm log function based on log-level argument\n\t */\n\tif (level > 4)\n\t\tdebug4 (\"%s: %s\", prefix, msg);\n\telse if (level == 4)\n\t\tdebug3 (\"%s: %s\", prefix, msg);\n\telse if (level == 3)\n\t\tdebug2 (\"%s: %s\", prefix, msg);\n\telse if (level == 2)\n\t\tdebug (\"%s: %s\", prefix, msg);\n\telse if (level == 1)\n\t\tverbose (\"%s: %s\", prefix, msg);\n\telse if (level == 0)\n\t\tinfo (\"%s: %s\", prefix, msg);\n\treturn (0);\n}\n\nstatic int _log_lua_error (lua_State *L)\n{\n\tconst char *prefix  = \"job_submit.lua\";\n\tconst char *msg     = lua_tostring (L, -1);\n\terror (\"%s: %s\", prefix, msg);\n\treturn (0);\n}\n\nstatic int _log_lua_user_msg (lua_State *L)\n{\n\tconst char *msg = lua_tostring(L, -1);\n\tchar *tmp = NULL;\n\n\tif (user_msg) {\n\t\txstrfmtcat(tmp, \"%s\\n%s\", user_msg, msg);\n\t\txfree(user_msg);\n\t\tuser_msg = tmp;\n\t\ttmp = NULL;\n\t} else {\n\t\tuser_msg = xstrdup(msg);\n\t}\n\n\treturn (0);\n}\n\nstatic const struct luaL_Reg slurm_functions [] = {\n\t{ \"log\",\t_log_lua_msg   },\n\t{ \"error\",\t_log_lua_error },\n\t{ \"user_msg\",\t_log_lua_user_msg },\n\t{ NULL,\t\tNULL        }\n};\n\n/* Get the default account for a user (or NULL if not present) */\nstatic char *_get_default_account(uint32_t user_id)\n{\n\tslurmdb_user_rec_t user;\n\n\tmemset(&user, 0, sizeof(slurmdb_user_rec_t));\n\tuser.uid = user_id;\n\tif (assoc_mgr_fill_in_user(acct_db_conn, &user, accounting_enforce,\n\t\t\t\t   NULL) != SLURM_ERROR) {\n\t\treturn user.default_acct;\n\t} else {\n\t\treturn NULL;\n\t}\n}\n\n/* Get the default QOS for an association (or NULL if not present) */\nstatic char *_get_default_qos(uint32_t user_id, char *account, char *partition)\n{\n\tslurmdb_assoc_rec_t assoc;\n\tslurmdb_qos_rec_t qos;\n\tuint32_t qos_id = 0;\n\n\tmemset(&assoc, 0, sizeof(slurmdb_assoc_rec_t));\n\tassoc.uid = user_id;\n\tassoc.partition = partition;\n\tif (account) {\n\t\tassoc.acct = account;\n\t} else {\n\t\tassoc.acct = _get_default_account(user_id);\n\t}\n\n\tif (assoc_mgr_fill_in_assoc(acct_db_conn, &assoc, accounting_enforce,\n\t\t\t\t    NULL, false) != SLURM_ERROR)\n\t\tqos_id = assoc.def_qos_id;\n\n\tif (!qos_id)\n\t\treturn NULL;\n\n\tmemset(&qos, 0, sizeof(slurmdb_qos_rec_t));\n\tqos.id = qos_id;\n\tif (assoc_mgr_fill_in_qos(acct_db_conn, &qos, accounting_enforce,\n\t\t\t\t  NULL, false) != SLURM_ERROR) {\n\t\treturn qos.name;\n\t} else {\n\t\treturn NULL;\n\t}\n}\n\n/* Get fields in an existing slurmctld job record.\n *\n * This is an incomplete list of job record fields. Add more as needed and\n * send patches to slurm-dev@schedmd.com.\n */\nstatic int _job_rec_field(const struct job_record *job_ptr,\n                          const char *name)\n{\n\tint i;\n\n\tif (job_ptr == NULL) {\n\t\terror(\"_job_rec_field: job_ptr is NULL\");\n\t\tlua_pushnil (L);\n\t} else if (!xstrcmp(name, \"account\")) {\n\t\tlua_pushstring (L, job_ptr->account);\n\t} else if (!xstrcmp(name, \"admin_comment\")) {\n\t\tlua_pushstring (L, job_ptr->admin_comment);\n\t} else if (!xstrcmp(name, \"array_task_cnt\")) {\n\t\tif (job_ptr->array_recs)\n\t\t\tlua_pushnumber (L, job_ptr->array_recs->task_cnt);\n\t\telse\n\t\t\tlua_pushnil (L);\n\t} else if (!xstrcmp(name, \"burst_buffer\")) {\n\t\tlua_pushstring (L, job_ptr->burst_buffer);\n\t} else if (!xstrcmp(name, \"comment\")) {\n\t\tlua_pushstring (L, job_ptr->comment);\n\t} else if (!xstrcmp(name, \"delay_boot\")) {\n\t\tlua_pushnumber (L, job_ptr->delay_boot);\n\t} else if (!xstrcmp(name, \"direct_set_prio\")) {\n\t\tlua_pushnumber (L, job_ptr->direct_set_prio);\n\t} else if (!xstrcmp(name, \"features\")) {\n\t\tif (job_ptr->details)\n\t\t\tlua_pushstring (L, job_ptr->details->features);\n\t\telse\n\t\t\tlua_pushnil (L);\n\t} else if (!xstrcmp(name, \"gres\")) {\n\t\tlua_pushstring (L, job_ptr->gres);\n\t} else if (!xstrcmp(name, \"job_id\")) {\n\t\tlua_pushnumber (L, job_ptr->job_id);\n\t} else if (!xstrcmp(name, \"job_state\")) {\n\t\tlua_pushnumber (L, job_ptr->job_state);\n\t} else if (!xstrcmp(name, \"licenses\")) {\n\t\tlua_pushstring (L, job_ptr->licenses);\n\t} else if (!xstrcmp(name, \"max_cpus\")) {\n\t\tif (job_ptr->details)\n\t\t\tlua_pushnumber (L, job_ptr->details->max_cpus);\n\t\telse\n\t\t\tlua_pushnumber (L, 0);\n\t} else if (!xstrcmp(name, \"max_nodes\")) {\n\t\tif (job_ptr->details)\n\t\t\tlua_pushnumber (L, job_ptr->details->max_nodes);\n\t\telse\n\t\t\tlua_pushnumber (L, 0);\n\t} else if (!xstrcmp(name, \"min_cpus\")) {\n\t\tif (job_ptr->details)\n\t\t\tlua_pushnumber (L, job_ptr->details->min_cpus);\n\t\telse\n\t\t\tlua_pushnumber (L, 0);\n\t} else if (!xstrcmp(name, \"min_mem_per_node\")) {\n\t\tif (job_ptr->details &&\n\t\t    !(job_ptr->details->pn_min_memory & MEM_PER_CPU))\n\t\t\tlua_pushnumber(L, job_ptr->details->pn_min_memory);\n\t\telse\n\t\t\tlua_pushnil(L);\n\t} else if (!xstrcmp(name, \"min_mem_per_cpu\")) {\n\t\tif (job_ptr->details &&\n\t\t    (job_ptr->details->pn_min_memory & MEM_PER_CPU))\n\t\t\tlua_pushnumber(L, job_ptr->details->pn_min_memory &\n\t\t\t\t       ~MEM_PER_CPU);\n\t\telse\n\t\t\tlua_pushnil(L);\n\t} else if (!xstrcmp(name, \"min_nodes\")) {\n\t\tif (job_ptr->details)\n\t\t\tlua_pushnumber (L, job_ptr->details->min_nodes);\n\t\telse\n\t\t\tlua_pushnumber (L, 0);\n\t} else if (!xstrcmp(name, \"nice\")) {\n\t\tif (job_ptr->details)\n\t\t\tlua_pushnumber (L, job_ptr->details->nice);\n\t\telse\n\t\t\tlua_pushnumber (L, NO_VAL16);\n\t} else if (!xstrcmp(name, \"pack_job_id\")) {\n\t\tlua_pushnumber (L, job_ptr->pack_job_id);\n\t} else if (!xstrcmp(name, \"pack_job_id_set\")) {\n\t\tlua_pushstring (L, job_ptr->pack_job_id_set);\n\t} else if (!xstrcmp(name, \"pack_job_offset\")) {\n\t\tlua_pushnumber (L, job_ptr->pack_job_offset);\n\t} else if (!xstrcmp(name, \"partition\")) {\n\t\tlua_pushstring (L, job_ptr->partition);\n\t} else if (!xstrcmp(name, \"pn_min_cpus\")) {\n\t\tif (job_ptr->details)\n\t\t\tlua_pushnumber (L, job_ptr->details->pn_min_cpus);\n\t\telse\n\t\t\tlua_pushnumber (L, NO_VAL);\n\t} else if (!xstrcmp(name, \"pn_min_memory\")) {\n\t\t/*\n\t\t * FIXME: Remove this in the future, lua can't handle 64bit\n\t\t * numbers!!!.  Use min_mem_per_node|cpu instead.\n\t\t */\n\t\tif (job_ptr->details)\n\t\t\tlua_pushnumber (L, job_ptr->details->pn_min_memory);\n\t\telse\n\t\t\tlua_pushnumber (L, NO_VAL64);\n\t} else if (!xstrcmp(name, \"priority\")) {\n\t\tlua_pushnumber (L, job_ptr->priority);\n\t} else if (!xstrcmp(name, \"qos\")) {\n\t\tif (job_ptr->qos_ptr) {\n\t\t\tlua_pushstring (L, job_ptr->qos_ptr->name);\n\t\t} else {\n\t\t\tlua_pushnil (L);\n\t\t}\n\t} else if (!xstrcmp(name, \"reboot\")) {\n\t\tlua_pushnumber (L, job_ptr->reboot);\n\t} else if (!xstrcmp(name, \"req_switch\")) {\n\t\tlua_pushnumber (L, job_ptr->req_switch);\n\t} else if (!xstrcmp(name, \"spank_job_env\")) {\n\t\tif ((job_ptr->spank_job_env_size == 0) ||\n\t\t    (job_ptr->spank_job_env == NULL)) {\n\t\t\tlua_pushnil (L);\n\t\t} else {\n\t\t\tlua_newtable(L);\n\t\t\tfor (i = 0; i < job_ptr->spank_job_env_size; i++) {\n\t\t\t\tif (job_ptr->spank_job_env[i] != NULL) {\n\t\t\t\t\tlua_pushnumber (L, i);\n\t\t\t\t\tlua_pushstring (L,\n\t\t\t\t\t\tjob_ptr->spank_job_env[i]);\n\t\t\t\t\tlua_settable (L, -3);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t} else if (!xstrcmp(name, \"spank_job_env_size\")) {\n\t\tlua_pushnumber (L, job_ptr->spank_job_env_size);\n\t} else if (!xstrcmp(name, \"time_limit\")) {\n\t\tlua_pushnumber (L, job_ptr->time_limit);\n\t} else if (!xstrcmp(name, \"time_min\")) {\n\t\tlua_pushnumber (L, job_ptr->time_min);\n\t} else if (!xstrcmp(name, \"wait4switch\")) {\n\t\tlua_pushnumber (L, job_ptr->wait4switch);\n\t} else if (!xstrcmp(name, \"wckey\")) {\n\t\tlua_pushstring (L, job_ptr->wckey);\n\t} else {\n\t\tlua_pushnil (L);\n\t}\n\n\treturn 1;\n}\n\n/* Get fields in an existing slurmctld job_record */\nstatic int _job_rec_field_index(lua_State *L)\n{\n\tconst char *name = luaL_checkstring(L, 2);\n\tstruct job_record *job_ptr;\n\n\tlua_getmetatable(L, -2);\n\tlua_getfield(L, -1, \"_job_rec_ptr\");\n\tjob_ptr = lua_touserdata(L, -1);\n\n\treturn _job_rec_field(job_ptr, name);\n}\n\n/* Get the list of existing slurmctld job records. */\nstatic void _update_jobs_global(void)\n{\n\tchar job_id_buf[11]; /* Big enough for a uint32_t */\n\tListIterator iter;\n\tstruct job_record *job_ptr;\n\n\tif (last_lua_jobs_update >= last_job_update) {\n\t\treturn;\n\t}\n\n\tlua_getglobal(L, \"slurm\");\n\tlua_newtable(L);\n\n\titer = list_iterator_create(job_list);\n\twhile ((job_ptr = (struct job_record *) list_next(iter))) {\n\t\t/* Create an empty table, with a metatable that looks up the\n\t\t * data for the individual job.\n\t\t */\n\t\tlua_newtable(L);\n\n\t\tlua_newtable(L);\n\t\tlua_pushcfunction(L, _job_rec_field_index);\n\t\tlua_setfield(L, -2, \"__index\");\n\t\t/* Store the job_record in the metatable, so the index\n\t\t * function knows which job it's getting data for.\n\t\t */\n\t\tlua_pushlightuserdata(L, job_ptr);\n\t\tlua_setfield(L, -2, \"_job_rec_ptr\");\n\t\tlua_setmetatable(L, -2);\n\n\t\t/* Lua copies passed strings, so we can reuse the buffer. */\n\t\tsnprintf(job_id_buf, sizeof(job_id_buf),\n\t\t         \"%d\", job_ptr->job_id);\n\t\tlua_setfield(L, -2, job_id_buf);\n\t}\n\tlast_lua_jobs_update = last_job_update;\n\tlist_iterator_destroy(iter);\n\n\tlua_setfield(L, -2, \"jobs\");\n\tlua_pop(L, 1);\n}\n\nstatic int _resv_field(const slurmctld_resv_t *resv_ptr,\n                       const char *name)\n{\n\tif (resv_ptr == NULL) {\n\t\terror(\"_resv_field: resv_ptr is NULL\");\n\t\tlua_pushnil(L);\n\t} else if (!xstrcmp(name, \"accounts\")) {\n\t\tlua_pushstring(L, resv_ptr->accounts);\n\t} else if (!xstrcmp(name, \"assoc_list\")) {\n\t\tlua_pushstring(L, resv_ptr->assoc_list);\n\t} else if (!xstrcmp(name, \"duration\")) {\n\t\tlua_pushnumber(L, resv_ptr->duration);\n\t} else if (!xstrcmp(name, \"end_time\")) {\n\t\tlua_pushnumber(L, resv_ptr->end_time);\n\t} else if (!xstrcmp(name, \"features\")) {\n\t\tlua_pushstring(L, resv_ptr->features);\n\t} else if (!xstrcmp(name, \"flags\")) {\n\t\tlua_pushnumber(L, resv_ptr->flags);\n\t} else if (!xstrcmp(name, \"full_nodes\")) {\n\t\tlua_pushboolean(L, resv_ptr->full_nodes);\n\t} else if (!xstrcmp(name, \"flags_set_node\")) {\n\t\tlua_pushboolean(L, resv_ptr->flags_set_node);\n\t} else if (!xstrcmp(name, \"licenses\")) {\n\t\tlua_pushstring(L, resv_ptr->licenses);\n\t} else if (!xstrcmp(name, \"node_cnt\")) {\n\t\tlua_pushnumber(L, resv_ptr->node_cnt);\n\t} else if (!xstrcmp(name, \"node_list\")) {\n\t\tlua_pushstring(L, resv_ptr->node_list);\n\t} else if (!xstrcmp(name, \"partition\")) {\n\t\tlua_pushstring(L, resv_ptr->partition);\n\t} else if (!xstrcmp(name, \"start_time\")) {\n\t\tlua_pushnumber(L, resv_ptr->start_time);\n\t} else if (!xstrcmp(name, \"users\")) {\n\t\tlua_pushstring(L, resv_ptr->users);\n\t} else {\n\t\tlua_pushnil(L);\n\t}\n\n\treturn 1;\n}\n\n/* Get fields in an existing slurmctld reservation record */\nstatic int _resv_field_index(lua_State *L)\n{\n\tconst char *name = luaL_checkstring(L, 2);\n\tslurmctld_resv_t *resv_ptr;\n\n\tlua_getmetatable(L, -2);\n\tlua_getfield(L, -1, \"_resv_ptr\");\n\tresv_ptr = lua_touserdata(L, -1);\n\n\treturn _resv_field(resv_ptr, name);\n}\n\n/* Get the list of existing slurmctld reservation records. */\nstatic void _update_resvs_global(void)\n{\n\tListIterator iter;\n\tslurmctld_resv_t *resv_ptr;\n\n\tif (last_lua_resv_update >= last_resv_update) {\n\t\treturn;\n\t}\n\n\tlua_getglobal(L, \"slurm\");\n\tlua_newtable(L);\n\n\titer = list_iterator_create(resv_list);\n\twhile ((resv_ptr = (slurmctld_resv_t *) list_next(iter))) {\n\t\t/* Create an empty table, with a metatable that looks up the\n\t\t * data for the individual reservation.\n\t\t */\n\t\tlua_newtable(L);\n\n\t\tlua_newtable(L);\n\t\tlua_pushcfunction(L, _resv_field_index);\n\t\tlua_setfield(L, -2, \"__index\");\n\t\t/* Store the slurmctld_resv_t in the metatable, so the index\n\t\t * function knows which reservation it's getting data for.\n\t\t */\n\t\tlua_pushlightuserdata(L, resv_ptr);\n\t\tlua_setfield(L, -2, \"_resv_ptr\");\n\t\tlua_setmetatable(L, -2);\n\n\t\tlua_setfield(L, -2, resv_ptr->name);\n\t}\n\tlast_lua_resv_update = last_resv_update;\n\tlist_iterator_destroy(iter);\n\n\tlua_setfield(L, -2, \"reservations\");\n\tlua_pop(L, 1);\n}\n\n/* Set fields in the job request structure on job submit or modify */\nstatic int _set_job_env_field(lua_State *L)\n{\n\tconst char *name, *value_str;\n\tstruct job_descriptor *job_desc;\n\tchar *name_eq = NULL;\n\tint i, j, name_len;\n\n\tname = luaL_checkstring(L, 2);\n\tname_eq = xstrdup(name);\n\txstrcat(name_eq, \"=\");\n\tname_len = strlen(name_eq);\n\tlua_getmetatable(L, -3);\n\tlua_getfield(L, -1, \"_job_desc\");\n\tjob_desc = lua_touserdata(L, -1);\n\tif (job_desc == NULL) {\n\t\terror(\"%s: job_desc is NULL\", __func__);\n\t} else if (job_desc->environment == NULL) {\n\t\terror(\"%s: job_desc->environment is NULL\", __func__);\n\t\tlua_pushnil(L);\n\t} else {\n\t\tvalue_str = luaL_checkstring(L, 3);\n\t\tfor (i = 0; job_desc->environment[i]; i++) {\n\t\t\tif (!xstrncmp(job_desc->environment[i], name_eq,\n\t\t\t\t      name_len)) {\n\t\t\t\tjob_desc->environment[i][name_len] = '\\0';\n\t\t\t\txstrcat(job_desc->environment[i], value_str);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (!job_desc->environment[i]) {\n\t\t\tjob_desc->environment = xrealloc(job_desc->environment,\n\t\t\t\t\t\t\t sizeof(char*) * (i+2));\n\t\t\tfor (j = i; j >= 1; j--) {\n\t\t\t\tjob_desc->environment[j] =\n\t\t\t\t\tjob_desc->environment[j-1];\n\t\t\t}\n\t\t\tjob_desc->environment[0] = xstrdup(name_eq);\n\t\t\txstrcat(job_desc->environment[0], value_str);\n\t\t\tjob_desc->env_size++;\n\t\t}\n\t}\n\txfree(name_eq);\n\n\treturn 0;\n}\n\nstatic int _job_env_field(const struct job_descriptor *job_desc,\n\t\t\t  const char *name)\n{\n\tchar *name_eq = \"\";\n\tint i, name_len;\n\n\tname_eq = xstrdup(name);\n\txstrcat(name_eq, \"=\");\n\tname_len = strlen(name_eq);\n\tif (job_desc == NULL) {\n\t\terror(\"%s: job_desc is NULL\", __func__);\n\t\tlua_pushnil (L);\n\t} else if (job_desc->environment == NULL) {\n\t\terror(\"%s: job_desc->environment is NULL\", __func__);\n\t\tlua_pushnil (L);\n\t} else {\n\t\tfor (i = 0; job_desc->environment[i]; i++) {\n\t\t\tif (!xstrncmp(job_desc->environment[i], name_eq,\n\t\t\t\t      name_len)) {\n\t\t\t\tlua_pushstring (L, job_desc->environment[i] +\n\t\t\t\t\t\t   name_len);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (!job_desc->environment[i])\n\t\t\tlua_pushnil (L);\n\t}\n\txfree(name_eq);\n\n\treturn 1;\n}\n\n/* Get fields in the job request record on job submit or modify */\nstatic int _get_job_env_field_name(lua_State *L)\n{\n\tconst struct job_descriptor *job_desc = lua_touserdata(L, 1);\n\tconst char *name = luaL_checkstring(L, 2);\n\treturn _job_env_field(job_desc, name);\n}\n\n/* Get fields in an existing slurmctld job_descriptor record */\nstatic int _job_env_field_index(lua_State *L)\n{\n\tconst char *name;\n\tstruct job_descriptor *job_desc;\n\n\tname = luaL_checkstring(L, 2);\n\tlua_getmetatable(L, -2);\n\tlua_getfield(L, -1, \"_job_desc\");\n\tjob_desc = lua_touserdata(L, -1);\n\treturn _job_env_field(job_desc, name);\n}\n\nstatic void _push_job_env(struct job_descriptor *job_desc)\n{\n\tlua_newtable(L);\n\n\tlua_newtable(L);\n\tlua_pushcfunction(L, _job_env_field_index);\n\tlua_setfield(L, -2, \"__index\");\n\tlua_pushcfunction(L, _set_job_env_field);\n\tlua_setfield(L, -2, \"__newindex\");\n\t/* Store the job descriptor in the metatable, so the index\n\t * function knows which struct it's getting data for.\n\t */\n\tlua_pushlightuserdata(L, job_desc);\n\tlua_setfield(L, -2, \"_job_desc\");\n\tlua_setmetatable(L, -2);\n}\n\nstatic int _get_job_req_field(const struct job_descriptor *job_desc,\n\t\t\t      const char *name)\n{\n\tint i;\n\n\tif (job_desc == NULL) {\n\t\terror(\"%s: job_desc is NULL\", __func__);\n\t\tlua_pushnil (L);\n\t} else if (!xstrcmp(name, \"account\")) {\n\t\tlua_pushstring (L, job_desc->account);\n\t} else if (!xstrcmp(name, \"acctg_freq\")) {\n\t\tlua_pushstring (L, job_desc->acctg_freq);\n\t} else if (!xstrcmp(name, \"admin_comment\")) {\n\t\tlua_pushstring (L, job_desc->admin_comment);\n\t} else if (!xstrcmp(name, \"alloc_node\")) {\n\t\tlua_pushstring (L, job_desc->alloc_node);\n\t} else if (!xstrcmp(name, \"array_inx\")) {\n\t\tlua_pushstring (L, job_desc->array_inx);\n\t} else if (!xstrcmp(name, \"begin_time\")) {\n\t\tlua_pushnumber (L, job_desc->begin_time);\n\t} else if (!xstrcmp(name, \"bitflags\")) {\n\t\tlua_pushnumber (L, job_desc->bitflags);\n\t} else if (!xstrcmp(name, \"boards_per_node\")) {\n\t\tlua_pushnumber (L, job_desc->boards_per_node);\n\t} else if (!xstrcmp(name, \"burst_buffer\")) {\n\t\tlua_pushstring (L, job_desc->burst_buffer);\n\t} else if (!xstrcmp(name, \"clusters\")) {\n\t\tlua_pushstring (L, job_desc->clusters);\n\t} else if (!xstrcmp(name, \"comment\")) {\n\t\tlua_pushstring (L, job_desc->comment);\n\t} else if (!xstrcmp(name, \"contiguous\")) {\n\t\tlua_pushnumber (L, job_desc->contiguous);\n\t} else if (!xstrcmp(name, \"cores_per_socket\")) {\n\t\tlua_pushnumber (L, job_desc->cores_per_socket);\n\t} else if (!xstrcmp(name, \"cpu_freq_min\")) {\n\t\tlua_pushnumber (L, job_desc->cpu_freq_min);\n\t} else if (!xstrcmp(name, \"cpu_freq_max\")) {\n\t\tlua_pushnumber (L, job_desc->cpu_freq_max);\n\t} else if (!xstrcmp(name, \"cpu_freq_gov\")) {\n\t\tlua_pushnumber (L, job_desc->cpu_freq_gov);\n\t} else if (!xstrcmp(name, \"cpus_per_task\")) {\n\t\tlua_pushnumber (L, job_desc->cpus_per_task);\n\t} else if (!xstrcmp(name, \"default_account\")) {\n\t\tlua_pushstring (L, _get_default_account(job_desc->user_id));\n\t} else if (!xstrcmp(name, \"default_qos\")) {\n\t\tlua_pushstring (L, _get_default_qos(job_desc->user_id,\n\t\t\t\t\t\t    job_desc->account,\n\t\t\t\t\t\t    job_desc->partition));\n\t} else if (!xstrcmp(name, \"delay_boot\")) {\n\t\tlua_pushnumber (L, job_desc->delay_boot);\n\t} else if (!xstrcmp(name, \"dependency\")) {\n\t\tlua_pushstring (L, job_desc->dependency);\n\t} else if (!xstrcmp(name, \"end_time\")) {\n\t\tlua_pushnumber (L, job_desc->end_time);\n\t} else if (!xstrcmp(name, \"environment\")) {\n\t\t_push_job_env ((struct job_descriptor *)job_desc); // No const\n\t} else if (!xstrcmp(name, \"extra\")) {\n\t\tlua_pushstring (L, job_desc->extra);\n\t} else if (!xstrcmp(name, \"exc_nodes\")) {\n\t\tlua_pushstring (L, job_desc->exc_nodes);\n\t} else if (!xstrcmp(name, \"features\")) {\n\t\tlua_pushstring (L, job_desc->features);\n\t} else if (!xstrcmp(name, \"gres\")) {\n\t\tlua_pushstring (L, job_desc->gres);\n\t} else if (!xstrcmp(name, \"group_id\")) {\n\t\tlua_pushnumber (L, job_desc->group_id);\n\t} else if (!xstrcmp(name, \"immediate\")) {\n\t\tlua_pushnumber (L, job_desc->immediate);\n\t} else if (!xstrcmp(name, \"licenses\")) {\n\t\tlua_pushstring (L, job_desc->licenses);\n\t} else if (!xstrcmp(name, \"mail_type\")) {\n\t\tlua_pushnumber (L, job_desc->mail_type);\n\t} else if (!xstrcmp(name, \"mail_user\")) {\n\t\tlua_pushstring (L, job_desc->mail_user);\n\t} else if (!xstrcmp(name, \"max_cpus\")) {\n\t\tlua_pushnumber (L, job_desc->max_cpus);\n\t} else if (!xstrcmp(name, \"max_nodes\")) {\n\t\tlua_pushnumber (L, job_desc->max_nodes);\n\t} else if (!xstrcmp(name, \"min_cpus\")) {\n\t\tlua_pushnumber (L, job_desc->min_cpus);\n\t} else if (!xstrcmp(name, \"min_mem_per_node\") &&\n\t\t   !(job_desc->pn_min_memory & MEM_PER_CPU)) {\n\t\tlua_pushnumber (L, job_desc->pn_min_memory);\n\t} else if (!xstrcmp(name, \"min_mem_per_cpu\") &&\n\t\t   (job_desc->pn_min_memory & MEM_PER_CPU)) {\n\t\tlua_pushnumber (L, (job_desc->pn_min_memory & (~MEM_PER_CPU)));\n\t} else if (!xstrcmp(name, \"min_nodes\")) {\n\t\tlua_pushnumber (L, job_desc->min_nodes);\n\t} else if (!xstrcmp(name, \"name\")) {\n\t\tlua_pushstring (L, job_desc->name);\n\t} else if (!xstrcmp(name, \"nice\")) {\n\t\tlua_pushnumber (L, job_desc->nice);\n\t} else if (!xstrcmp(name, \"ntasks_per_board\")) {\n\t\tlua_pushnumber (L, job_desc->ntasks_per_board);\n\t} else if (!xstrcmp(name, \"ntasks_per_core\")) {\n\t\tlua_pushnumber (L, job_desc->ntasks_per_core);\n\t} else if (!xstrcmp(name, \"ntasks_per_node\")) {\n\t\tlua_pushnumber (L, job_desc->ntasks_per_node);\n\t} else if (!xstrcmp(name, \"ntasks_per_socket\")) {\n\t\tlua_pushnumber (L, job_desc->ntasks_per_socket);\n\t} else if (!xstrcmp(name, \"num_tasks\")) {\n\t\tlua_pushnumber (L, job_desc->num_tasks);\n\t} else if (!xstrcmp(name, \"pack_job_offset\")) {\n\t\tlua_pushnumber (L, job_desc->pack_job_offset);\n\t} else if (!xstrcmp(name, \"partition\")) {\n\t\tlua_pushstring (L, job_desc->partition);\n\t} else if (!xstrcmp(name, \"power_flags\")) {\n\t\tlua_pushnumber (L, job_desc->power_flags);\n\t} else if (!xstrcmp(name, \"pn_min_cpus\")) {\n\t\tlua_pushnumber (L, job_desc->pn_min_cpus);\n\t} else if (!xstrcmp(name, \"pn_min_memory\")) {\n\t\t/*\n\t\t * FIXME: Remove this in the future, lua can't handle 64bit\n\t\t * numbers!!!.  Use min_mem_per_node|cpu instead.\n\t\t */\n\t\tlua_pushnumber (L, job_desc->pn_min_memory);\n\t} else if (!xstrcmp(name, \"pn_min_tmp_disk\")) {\n\t\tlua_pushnumber (L, job_desc->pn_min_tmp_disk);\n\t} else if (!xstrcmp(name, \"priority\")) {\n\t\tlua_pushnumber (L, job_desc->priority);\n\t} else if (!xstrcmp(name, \"qos\")) {\n\t\tlua_pushstring (L, job_desc->qos);\n\t} else if (!xstrcmp(name, \"reboot\")) {\n\t\tlua_pushnumber (L, job_desc->reboot);\n\t} else if (!xstrcmp(name, \"req_nodes\")) {\n\t\tlua_pushstring (L, job_desc->req_nodes);\n\t} else if (!xstrcmp(name, \"req_switch\")) {\n\t\tlua_pushnumber (L, job_desc->req_switch);\n\t} else if (!xstrcmp(name, \"requeue\")) {\n\t\tlua_pushnumber (L, job_desc->requeue);\n\t} else if (!xstrcmp(name, \"reservation\")) {\n\t\tlua_pushstring (L, job_desc->reservation);\n\t} else if (!xstrcmp(name, \"script\")) {\n\t\tlua_pushstring (L, job_desc->script);\n\t} else if (!xstrcmp(name, \"shared\")) {\n\t\tlua_pushnumber (L, job_desc->shared);\n\t} else if (!xstrcmp(name, \"sockets_per_board\")) {\n\t\tlua_pushnumber (L, job_desc->sockets_per_board);\n\t} else if (!xstrcmp(name, \"sockets_per_node\")) {\n\t\tlua_pushnumber (L, job_desc->sockets_per_node);\n\t} else if (!xstrcmp(name, \"spank_job_env\")) {\n\t\tif ((job_desc->spank_job_env_size == 0) ||\n\t\t    (job_desc->spank_job_env == NULL)) {\n\t\t\tlua_pushnil (L);\n\t\t} else {\n\t\t\tlua_newtable(L);\n\t\t\tfor (i = 0; i < job_desc->spank_job_env_size; i++) {\n\t\t\t\tif (job_desc->spank_job_env[i] != NULL) {\n\t\t\t\t\tlua_pushnumber (L, i);\n\t\t\t\t\tlua_pushstring (L,\n\t\t\t\t\t\tjob_desc->spank_job_env[i]);\n\t\t\t\t\tlua_settable (L, -3);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t} else if (!xstrcmp(name, \"spank_job_env_size\")) {\n\t\tlua_pushnumber (L, job_desc->spank_job_env_size);\n\t} else if (!xstrcmp(name, \"std_err\")) {\n\t\tlua_pushstring (L, job_desc->std_err);\n\t} else if (!xstrcmp(name, \"std_in\")) {\n\t\tlua_pushstring (L, job_desc->std_in);\n\t} else if (!xstrcmp(name, \"std_out\")) {\n\t\tlua_pushstring (L, job_desc->std_out);\n\t} else if (!xstrcmp(name, \"threads_per_core\")) {\n\t\tlua_pushnumber (L, job_desc->threads_per_core);\n\t} else if (!xstrcmp(name, \"time_limit\")) {\n\t\tlua_pushnumber (L, job_desc->time_limit);\n\t} else if (!xstrcmp(name, \"time_min\")) {\n\t\tlua_pushnumber (L, job_desc->time_min);\n\t} else if (!xstrcmp(name, \"user_id\")) {\n\t\tlua_pushnumber (L, job_desc->user_id);\n\t} else if (!xstrcmp(name, \"user_name\")) {\n\t\tchar *username = uid_to_string_or_null(job_desc->user_id);\n\t\tlua_pushstring (L, username);\n\t\txfree(username);\n\t} else if (!xstrcmp(name, \"wait4switch\")) {\n\t\tlua_pushnumber (L, job_desc->wait4switch);\n\t} else if (!xstrcmp(name, \"work_dir\")) {\n\t\tlua_pushstring (L, job_desc->work_dir);\n\t} else if (!xstrcmp(name, \"wckey\")) {\n\t\tlua_pushstring (L, job_desc->wckey);\n\t} else {\n\t\tlua_pushnil (L);\n\t}\n\n\treturn 1;\n}\n\n/* Get fields in the job request record on job submit or modify */\nstatic int _get_job_req_field_name(lua_State *L)\n{\n\tconst struct job_descriptor *job_desc = lua_touserdata(L, 1);\n\tconst char *name = luaL_checkstring(L, 2);\n\n\treturn _get_job_req_field(job_desc, name);\n}\n\n/* Get fields in an existing slurmctld job_descriptor record */\nstatic int _get_job_req_field_index(lua_State *L)\n{\n\tconst char *name;\n\tstruct job_descriptor *job_desc;\n\n\tname = luaL_checkstring(L, 2);\n\tlua_getmetatable(L, -2);\n\tlua_getfield(L, -1, \"_job_desc\");\n\tjob_desc = lua_touserdata(L, -1);\n\n\treturn _get_job_req_field(job_desc, name);\n}\n\n/* Set fields in the job request structure on job submit or modify */\nstatic int _set_job_req_field(lua_State *L)\n{\n\tconst char *name, *value_str;\n\tstruct job_descriptor *job_desc;\n\n\tname = luaL_checkstring(L, 2);\n\tlua_getmetatable(L, -3);\n\tlua_getfield(L, -1, \"_job_desc\");\n\tjob_desc = lua_touserdata(L, -1);\n\tif (job_desc == NULL) {\n\t\terror(\"%s: job_desc is NULL\", __func__);\n\t} else if (!xstrcmp(name, \"account\")) {\n\t\tvalue_str = luaL_checkstring(L, 3);\n\t\txfree(job_desc->account);\n\t\tif (strlen(value_str))\n\t\t\tjob_desc->account = xstrdup(value_str);\n\t} else if (!xstrcmp(name, \"acctg_freq\")) {\n\t\tvalue_str = luaL_checkstring(L, 3);\n\t\txfree(job_desc->acctg_freq);\n\t\tif (strlen(value_str))\n\t\t\tjob_desc->acctg_freq = xstrdup(value_str);\n\t} else if (!xstrcmp(name, \"admin_comment\")) {\n\t\tvalue_str = luaL_checkstring(L, 3);\n\t\txfree(job_desc->admin_comment);\n\t\tif (strlen(value_str))\n\t\t\tjob_desc->admin_comment = xstrdup(value_str);\n\t} else if (!xstrcmp(name, \"array_inx\")) {\n\t\tvalue_str = luaL_checkstring(L, 3);\n\t\txfree(job_desc->array_inx);\n\t\tif (strlen(value_str))\n\t\t\tjob_desc->array_inx = xstrdup(value_str);\n\t} else if (!xstrcmp(name, \"begin_time\")) {\n\t\tjob_desc->begin_time = luaL_checknumber(L, 3);\n\t} else if (!xstrcmp(name, \"bitflags\")) {\n\t\tjob_desc->bitflags = luaL_checknumber(L, 3);\n\t} else if (!xstrcmp(name, \"burst_buffer\")) {\n\t\tvalue_str = luaL_checkstring(L, 3);\n\t\txfree(job_desc->burst_buffer);\n\t\tif (strlen(value_str))\n\t\t\tjob_desc->burst_buffer = xstrdup(value_str);\n\t} else if (!xstrcmp(name, \"clusters\")) {\n\t\tvalue_str = luaL_checkstring(L, 3);\n\t\txfree(job_desc->clusters);\n\t\tif (strlen(value_str))\n\t\t\tjob_desc->clusters = xstrdup(value_str);\n\t} else if (!xstrcmp(name, \"comment\")) {\n\t\tvalue_str = luaL_checkstring(L, 3);\n\t\txfree(job_desc->comment);\n\t\tif (strlen(value_str))\n\t\t\tjob_desc->comment = xstrdup(value_str);\n\t} else if (!xstrcmp(name, \"contiguous\")) {\n\t\tjob_desc->contiguous = luaL_checknumber(L, 3);\n\t} else if (!xstrcmp(name, \"cores_per_socket\")) {\n\t\tjob_desc->cores_per_socket = luaL_checknumber(L, 3);\n\t} else if (!xstrcmp(name, \"cpus_per_task\")) {\n\t\tjob_desc->cpus_per_task = luaL_checknumber(L, 3);\n\t} else if (!xstrcmp(name, \"cpu_freq_min\")) {\n\t\tjob_desc->cpu_freq_min = luaL_checknumber(L, 3);\n\t} else if (!xstrcmp(name, \"cpu_freq_max\")) {\n\t\tjob_desc->cpu_freq_max = luaL_checknumber(L, 3);\n\t} else if (!xstrcmp(name, \"cpu_freq_gov\")) {\n\t\tjob_desc->cpu_freq_gov = luaL_checknumber(L, 3);\n\t} else if (!xstrcmp(name, \"dependency\")) {\n\t\tvalue_str = luaL_checkstring(L, 3);\n\t\txfree(job_desc->dependency);\n\t\tif (strlen(value_str))\n\t\t\tjob_desc->dependency = xstrdup(value_str);\n\t} else if (!xstrcmp(name, \"delay_boot\")) {\n\t\tjob_desc->delay_boot = luaL_checknumber(L, 3);\n\t} else if (!xstrcmp(name, \"end_time\")) {\n\t\tjob_desc->end_time = luaL_checknumber(L, 3);\n\t} else if (!xstrcmp(name, \"extra\")) {\n\t\tvalue_str = luaL_checkstring(L, 3);\n\t\txfree(job_desc->extra);\n\t\tif (strlen(value_str))\n\t\t\tjob_desc->extra = xstrdup(value_str);\n\t} else if (!xstrcmp(name, \"exc_nodes\")) {\n\t\tvalue_str = luaL_checkstring(L, 3);\n\t\txfree(job_desc->exc_nodes);\n\t\tif (strlen(value_str))\n\t\t\tjob_desc->exc_nodes = xstrdup(value_str);\n\t} else if (!xstrcmp(name, \"features\")) {\n\t\tvalue_str = luaL_checkstring(L, 3);\n\t\txfree(job_desc->features);\n\t\tif (strlen(value_str))\n\t\t\tjob_desc->features = xstrdup(value_str);\n\t} else if (!xstrcmp(name, \"gres\")) {\n\t\tvalue_str = luaL_checkstring(L, 3);\n\t\txfree(job_desc->gres);\n\t\tif (strlen(value_str))\n\t\t\tjob_desc->gres = xstrdup(value_str);\n\t} else if (!xstrcmp(name, \"immediate\")) {\n\t\tjob_desc->immediate = luaL_checknumber(L, 3);\n\t} else if (!xstrcmp(name, \"licenses\")) {\n\t\tvalue_str = luaL_checkstring(L, 3);\n\t\txfree(job_desc->licenses);\n\t\tif (strlen(value_str))\n\t\t\tjob_desc->licenses = xstrdup(value_str);\n\t} else if (!xstrcmp(name, \"max_cpus\")) {\n\t\tjob_desc->max_cpus = luaL_checknumber(L, 3);\n\t} else if (!xstrcmp(name, \"max_nodes\")) {\n\t\tjob_desc->max_nodes = luaL_checknumber(L, 3);\n\t} else if (!xstrcmp(name, \"min_cpus\")) {\n\t\tjob_desc->min_cpus = luaL_checknumber(L, 3);\n\t} else if (!xstrcmp(name, \"min_mem_per_cpu\")) {\n\t\tjob_desc->pn_min_memory = luaL_checknumber(L, 3);\n\t\tjob_desc->pn_min_memory |= MEM_PER_CPU;\n\t} else if (!xstrcmp(name, \"min_mem_per_node\")) {\n\t\tjob_desc->pn_min_memory = luaL_checknumber(L, 3);\n\t} else if (!xstrcmp(name, \"min_nodes\")) {\n\t\tjob_desc->min_nodes = luaL_checknumber(L, 3);\n\t} else if (!xstrcmp(name, \"name\")) {\n\t\tvalue_str = luaL_checkstring(L, 3);\n\t\txfree(job_desc->name);\n\t\tif (strlen(value_str))\n\t\t\tjob_desc->name = xstrdup(value_str);\n\t} else if (!xstrcmp(name, \"nice\")) {\n\t\tjob_desc->nice = luaL_checknumber(L, 3);\n\t} else if (!xstrcmp(name, \"ntasks_per_node\")) {\n\t\tjob_desc->ntasks_per_node = luaL_checknumber(L, 3);\n\t} else if (!xstrcmp(name, \"ntasks_per_socket\")) {\n\t\tjob_desc->ntasks_per_socket = luaL_checknumber(L, 3);\n\t} else if (!xstrcmp(name, \"num_tasks\")) {\n\t\tjob_desc->num_tasks = luaL_checknumber(L, 3);\n\t} else if (!xstrcmp(name, \"partition\")) {\n\t\tvalue_str = luaL_checkstring(L, 3);\n\t\txfree(job_desc->partition);\n\t\tif (strlen(value_str))\n\t\t\tjob_desc->partition = xstrdup(value_str);\n\t} else if (!xstrcmp(name, \"power_flags\")) {\n\t\tjob_desc->power_flags = luaL_checknumber(L, 3);\n\t} else if (!xstrcmp(name, \"pn_min_cpus\")) {\n\t\tjob_desc->pn_min_cpus = luaL_checknumber(L, 3);\n\t} else if (!xstrcmp(name, \"pn_min_memory\")) {\n\t\t/*\n\t\t * FIXME: Remove this in the future, lua can't handle 64bit\n\t\t * numbers!!!.  Use min_mem_per_node|cpu instead.\n\t\t */\n\t\tjob_desc->pn_min_memory = luaL_checknumber(L, 3);\n\t} else if (!xstrcmp(name, \"pn_min_tmp_disk\")) {\n\t\tjob_desc->pn_min_tmp_disk = luaL_checknumber(L, 3);\n\t} else if (!xstrcmp(name, \"priority\")) {\n\t\tjob_desc->priority = luaL_checknumber(L, 3);\n\t} else if (!xstrcmp(name, \"qos\")) {\n\t\tvalue_str = luaL_checkstring(L, 3);\n\t\txfree(job_desc->qos);\n\t\tif (strlen(value_str))\n\t\t\tjob_desc->qos = xstrdup(value_str);\n\t} else if (!xstrcmp(name, \"reboot\")) {\n\t\tjob_desc->reboot = luaL_checknumber(L, 3);\n\t} else if (!xstrcmp(name, \"req_nodes\")) {\n\t\tvalue_str = luaL_checkstring(L, 3);\n\t\txfree(job_desc->req_nodes);\n\t\tif (strlen(value_str))\n\t\t\tjob_desc->req_nodes = xstrdup(value_str);\n\t} else if (!xstrcmp(name, \"req_switch\")) {\n\t\tjob_desc->req_switch = luaL_checknumber(L, 3);\n\t} else if (!xstrcmp(name, \"requeue\")) {\n\t\tjob_desc->requeue = luaL_checknumber(L, 3);\n\t} else if (!xstrcmp(name, \"reservation\")) {\n\t\tvalue_str = luaL_checkstring(L, 3);\n\t\txfree(job_desc->reservation);\n\t\tif (strlen(value_str))\n\t\t\tjob_desc->reservation = xstrdup(value_str);\n\t} else if (!xstrcmp(name, \"script\")) {\n\t\tvalue_str = luaL_checkstring(L, 3);\n\t\txfree(job_desc->script);\n\t\tif (strlen(value_str))\n\t\t\tjob_desc->script = xstrdup(value_str);\n\t} else if (!xstrcmp(name, \"shared\")) {\n\t\tjob_desc->shared = luaL_checknumber(L, 3);\n\t} else if (!xstrcmp(name, \"sockets_per_node\")) {\n\t\tjob_desc->sockets_per_node = luaL_checknumber(L, 3);\n\t} else if (!xstrcmp(name, \"std_err\")) {\n\t\tvalue_str = luaL_checkstring(L, 3);\n\t\txfree(job_desc->std_err);\n\t\tif (strlen(value_str))\n\t\t\tjob_desc->std_err = xstrdup(value_str);\n\t} else if (!xstrcmp(name, \"std_in\")) {\n\t\tvalue_str = luaL_checkstring(L, 3);\n\t\txfree(job_desc->std_in);\n\t\tif (strlen(value_str))\n\t\t\tjob_desc->std_in = xstrdup(value_str);\n\t} else if (!xstrcmp(name, \"std_out\")) {\n\t\tvalue_str = luaL_checkstring(L, 3);\n\t\txfree(job_desc->std_out);\n\t\tif (strlen(value_str))\n\t\t\tjob_desc->std_out = xstrdup(value_str);\n\t} else if (!xstrcmp(name, \"threads_per_core\")) {\n\t\tjob_desc->threads_per_core = luaL_checknumber(L, 3);\n\t} else if (!xstrcmp(name, \"time_limit\")) {\n\t\tjob_desc->time_limit = luaL_checknumber(L, 3);\n\t} else if (!xstrcmp(name, \"time_min\")) {\n\t\tjob_desc->time_min = luaL_checknumber(L, 3);\n\t} else if (!xstrcmp(name, \"wait4switch\")) {\n\t\tjob_desc->wait4switch = luaL_checknumber(L, 3);\n\t} else if (!xstrcmp(name, \"wckey\")) {\n\t\tvalue_str = luaL_checkstring(L, 3);\n\t\txfree(job_desc->wckey);\n\t\tif (strlen(value_str))\n\t\t\tjob_desc->wckey = xstrdup(value_str);\n\t} else if (!xstrcmp(name, \"work_dir\")) {\n\t\tvalue_str = luaL_checkstring(L, 3);\n\t\txfree(job_desc->work_dir);\n\t\tif (strlen(value_str))\n\t\t\tjob_desc->work_dir = xstrdup(value_str);\n\t} else {\n\t\terror(\"_set_job_field: unrecognized field: %s\", name);\n\t}\n\n\treturn 0;\n}\n\nstatic void _push_job_desc(struct job_descriptor *job_desc)\n{\n\tlua_newtable(L);\n\n\tlua_newtable(L);\n\tlua_pushcfunction(L, _get_job_req_field_index);\n\tlua_setfield(L, -2, \"__index\");\n\tlua_pushcfunction(L, _set_job_req_field);\n\tlua_setfield(L, -2, \"__newindex\");\n\t/* Store the job descriptor in the metatable, so the index\n\t * function knows which struct it's getting data for.\n\t */\n\tlua_pushlightuserdata(L, job_desc);\n\tlua_setfield(L, -2, \"_job_desc\");\n\tlua_setmetatable(L, -2);\n}\n\nstatic void _push_job_rec(struct job_record *job_ptr)\n{\n\tlua_newtable(L);\n\n\tlua_newtable(L);\n\tlua_pushcfunction(L, _job_rec_field_index);\n\tlua_setfield(L, -2, \"__index\");\n\t/* Store the job_ptr in the metatable, so the index\n\t * function knows which struct it's getting data for.\n\t */\n\tlua_pushlightuserdata(L, job_ptr);\n\tlua_setfield(L, -2, \"_job_rec_ptr\");\n\tlua_setmetatable(L, -2);\n}\n\n/* Get fields in an existing slurmctld partition record\n *\n * This is an incomplete list of partition record fields. Add more as needed\n * and send patches to slurm-dev@schedmd.com\n */\nstatic int _part_rec_field(const struct part_record *part_ptr,\n                           const char *name)\n{\n\tif (part_ptr == NULL) {\n\t\terror(\"_get_part_field: part_ptr is NULL\");\n\t\tlua_pushnil (L);\n\t} else if (!xstrcmp(name, \"allow_qos\")) {\n\t\tlua_pushstring (L, part_ptr->allow_qos);\n\t} else if (!xstrcmp(name, \"default_time\")) {\n\t\tlua_pushnumber (L, part_ptr->default_time);\n\t} else if (!xstrcmp(name, \"def_mem_per_cpu\") &&\n\t\t  (part_ptr->def_mem_per_cpu & MEM_PER_CPU)) {\n\t\tlua_pushnumber (L, part_ptr->def_mem_per_cpu & (~MEM_PER_CPU));\n\t} else if (!xstrcmp(name, \"def_mem_per_node\") &&\n\t\t  !(part_ptr->def_mem_per_cpu & MEM_PER_CPU)) {\n\t\tlua_pushnumber (L, part_ptr->def_mem_per_cpu);\n\t} else if (!xstrcmp(name, \"flag_default\")) {\n\t\tint is_default = 0;\n\t\tif (part_ptr->flags & PART_FLAG_DEFAULT)\n\t\t\tis_default = 1;\n\t\tlua_pushnumber (L, is_default);\n\t} else if (!xstrcmp(name, \"flags\")) {\n\t\tlua_pushnumber (L, part_ptr->flags);\n\t} else if (!xstrcmp(name, \"max_cpus_per_node\")) {\n\t\tlua_pushnumber (L, part_ptr->max_cpus_per_node);\n\t} else if (!xstrcmp(name, \"max_mem_per_cpu\") &&\n\t\t  (part_ptr->max_mem_per_cpu & MEM_PER_CPU)) {\n\t\tlua_pushnumber (L, part_ptr->max_mem_per_cpu & (~MEM_PER_CPU));\n\t} else if (!xstrcmp(name, \"max_mem_per_node\") &&\n\t\t  !(part_ptr->max_mem_per_cpu & MEM_PER_CPU)) {\n\t\tlua_pushnumber (L, part_ptr->max_mem_per_cpu);\n\t} else if (!xstrcmp(name, \"max_nodes\")) {\n\t\tlua_pushnumber (L, part_ptr->max_nodes);\n\t} else if (!xstrcmp(name, \"max_nodes_orig\")) {\n\t\tlua_pushnumber (L, part_ptr->max_nodes_orig);\n\t} else if (!xstrcmp(name, \"max_share\")) {\n\t\tlua_pushnumber (L, part_ptr->max_share);\n\t} else if (!xstrcmp(name, \"max_time\")) {\n\t\tlua_pushnumber (L, part_ptr->max_time);\n\t} else if (!xstrcmp(name, \"min_nodes\")) {\n\t\tlua_pushnumber (L, part_ptr->min_nodes);\n\t} else if (!xstrcmp(name, \"min_nodes_orig\")) {\n\t\tlua_pushnumber (L, part_ptr->min_nodes_orig);\n\t} else if (!xstrcmp(name, \"name\")) {\n\t\tlua_pushstring (L, part_ptr->name);\n\t} else if (!xstrcmp(name, \"nodes\")) {\n\t\tlua_pushstring (L, part_ptr->nodes);\n\t} else if (!xstrcmp(name, \"priority_job_factor\")) {\n\t\tlua_pushnumber (L, part_ptr->priority_job_factor);\n\t} else if (!xstrcmp(name, \"priority_tier\")) {\n\t\tlua_pushnumber (L, part_ptr->priority_tier);\n\t} else if (!xstrcmp(name, \"qos\")) {\n\t\tlua_pushstring (L, part_ptr->qos_char);\n\t} else if (!xstrcmp(name, \"state_up\")) {\n\t\tlua_pushnumber (L, part_ptr->state_up);\n\t} else {\n\t\tlua_pushnil (L);\n\t}\n\n\treturn 1;\n}\n\nstatic int _get_part_rec_field (lua_State *L)\n{\n\tconst struct part_record *part_ptr = lua_touserdata(L, 1);\n\tconst char *name = luaL_checkstring(L, 2);\n\n\treturn _part_rec_field(part_ptr, name);\n}\n\nstatic int _part_rec_field_index(lua_State *L)\n{\n\tconst char *name = luaL_checkstring(L, 2);\n\tstruct part_record *part_ptr;\n\n\tlua_getmetatable(L, -2);\n\tlua_getfield(L, -1, \"_part_rec_ptr\");\n\tpart_ptr = lua_touserdata(L, -1);\n\n\treturn _part_rec_field(part_ptr, name);\n}\n\nstatic bool _user_can_use_part(uint32_t user_id, uint32_t submit_uid,\n\t\t\t       struct part_record *part_ptr)\n{\n\tint i;\n\n\tif (user_id == 0) {\n\t\tif (part_ptr->flags & PART_FLAG_NO_ROOT)\n\t\t\treturn false;\n\t\treturn true;\n\t}\n\n\tif ((part_ptr->flags & PART_FLAG_ROOT_ONLY) && (submit_uid != 0))\n\t\treturn false;\n\n\tif (part_ptr->allow_uids == NULL)\n\t\treturn true;\t/* No user ID filters */\n\n\tfor (i=0; part_ptr->allow_uids[i]; i++) {\n\t\tif (user_id == part_ptr->allow_uids[i])\n\t\t\treturn true;\n\t}\n\treturn false;\n}\n\nstatic void _push_partition_list(uint32_t user_id, uint32_t submit_uid)\n{\n\tListIterator part_iterator;\n\tstruct part_record *part_ptr;\n\n\tlua_newtable(L);\n\tpart_iterator = list_iterator_create(part_list);\n\twhile ((part_ptr = (struct part_record *) list_next(part_iterator))) {\n\t\tif (!_user_can_use_part(user_id, submit_uid, part_ptr))\n\t\t\tcontinue;\n\n\t\t/* Create an empty table, with a metatable that looks up the\n\t\t * data for the partition.\n\t\t */\n\t\tlua_newtable(L);\n\n\t\tlua_newtable(L);\n\t\tlua_pushcfunction(L, _part_rec_field_index);\n\t\tlua_setfield(L, -2, \"__index\");\n\t\t/* Store the part_record in the metatable, so the index\n\t\t * function knows which job it's getting data for.\n\t\t */\n\t\tlua_pushlightuserdata(L, part_ptr);\n\t\tlua_setfield(L, -2, \"_part_rec_ptr\");\n\t\tlua_setmetatable(L, -2);\n\n\t\tlua_setfield(L, -2, part_ptr->name);\n\t}\n\tlist_iterator_destroy(part_iterator);\n}\n\nstatic void _lua_table_register(lua_State *L, const char *libname,\n\t\t\t\tconst luaL_Reg *l)\n{\n#if LUA_VERSION_NUM == 501\n\tluaL_register(L, libname, l);\n#else\n\tluaL_setfuncs(L, l, 0);\n\tif (libname)\n\t\tlua_setglobal(L, libname);\n#endif\n}\n\nstatic void _register_lua_slurm_output_functions (void)\n{\n\tchar *unpack_str;\n\tchar tmp_string[100];\n\n#if LUA_VERSION_NUM == 501\n\tunpack_str = \"unpack\";\n#else\n\tunpack_str = \"table.unpack\";\n#endif\n\t/*\n\t *  Register slurm output functions in a global \"slurm\" table\n\t */\n\tlua_newtable (L);\n\t_lua_table_register(L, NULL, slurm_functions);\n\t/*\n\t *  Create more user-friendly lua versions of SLURM log functions.\n\t */\n\tsnprintf(tmp_string, sizeof(tmp_string),\n\t\t \"slurm.error (string.format(%s({...})))\",\n\t\t unpack_str);\n\tluaL_loadstring (L, tmp_string);\n\tlua_setfield (L, -2, \"log_error\");\n\tsnprintf(tmp_string, sizeof(tmp_string),\n\t\t \"slurm.log (0, string.format(%s({...})))\",\n\t\t unpack_str);\n\tluaL_loadstring (L, tmp_string);\n\tlua_setfield (L, -2, \"log_info\");\n\tsnprintf(tmp_string, sizeof(tmp_string),\n\t\t \"slurm.log (1, string.format(%s({...})))\",\n\t\t unpack_str);\n\tluaL_loadstring (L, tmp_string);\n\tlua_setfield (L, -2, \"log_verbose\");\n\tsnprintf(tmp_string, sizeof(tmp_string),\n\t\t \"slurm.log (2, string.format(%s({...})))\",\n\t\t unpack_str);\n\tluaL_loadstring (L, tmp_string);\n\tlua_setfield (L, -2, \"log_debug\");\n\tsnprintf(tmp_string, sizeof(tmp_string),\n\t\t \"slurm.log (3, string.format(%s({...})))\",\n\t\t unpack_str);\n\tluaL_loadstring (L, tmp_string);\n\tlua_setfield (L, -2, \"log_debug2\");\n\tsnprintf(tmp_string, sizeof(tmp_string),\n\t\t \"slurm.log (4, string.format(%s({...})))\",\n\t\t unpack_str);\n\tluaL_loadstring (L, tmp_string);\n\tlua_setfield (L, -2, \"log_debug3\");\n\tsnprintf(tmp_string, sizeof(tmp_string),\n\t\t \"slurm.log (5, string.format(%s({...})))\",\n\t\t unpack_str);\n\tluaL_loadstring (L, tmp_string);\n\tlua_setfield (L, -2, \"log_debug4\");\n\tsnprintf(tmp_string, sizeof(tmp_string),\n\t\t \"slurm.user_msg (string.format(%s({...})))\",\n\t\t unpack_str);\n\tluaL_loadstring (L, tmp_string);\n\tlua_setfield (L, -2, \"log_user\");\n\n\t/*\n\t * Error codes: slurm.SUCCESS, slurm.FAILURE, slurm.ERROR, etc.\n\t */\n\tlua_pushnumber (L, SLURM_FAILURE);\n\tlua_setfield (L, -2, \"FAILURE\");\n\tlua_pushnumber (L, SLURM_ERROR);\n\tlua_setfield (L, -2, \"ERROR\");\n\tlua_pushnumber (L, SLURM_SUCCESS);\n\tlua_setfield (L, -2, \"SUCCESS\");\n\tlua_pushnumber (L, ESLURM_INVALID_LICENSES);\n\tlua_setfield (L, -2, \"ESLURM_INVALID_LICENSES\");\n\tlua_pushnumber (L, ESLURM_INVALID_TIME_LIMIT);\n\tlua_setfield (L, -2, \"ESLURM_INVALID_TIME_LIMIT\");\n\n\t/*\n\t * Other definitions needed to interpret data\n\t * slurm.MEM_PER_CPU, slurm.NO_VAL, etc.\n\t */\n\tlua_pushnumber (L, ALLOC_SID_ADMIN_HOLD);\n\tlua_setfield (L, -2, \"ALLOC_SID_ADMIN_HOLD\");\n\tlua_pushnumber (L, ALLOC_SID_USER_HOLD);\n\tlua_setfield (L, -2, \"ALLOC_SID_USER_HOLD\");\n\tlua_pushnumber (L, INFINITE);\n\tlua_setfield (L, -2, \"INFINITE\");\n\tlua_pushnumber (L, INFINITE64);\n\tlua_setfield (L, -2, \"INFINITE64\");\n\tlua_pushnumber (L, MAIL_JOB_BEGIN);\n\tlua_setfield (L, -2, \"MAIL_JOB_BEGIN\");\n\tlua_pushnumber (L, MAIL_JOB_END);\n\tlua_setfield (L, -2, \"MAIL_JOB_END\");\n\tlua_pushnumber (L, MAIL_JOB_FAIL);\n\tlua_setfield (L, -2, \"MAIL_JOB_FAIL\");\n\tlua_pushnumber (L, MAIL_JOB_REQUEUE);\n\tlua_setfield (L, -2, \"MAIL_JOB_REQUEUE\");\n\tlua_pushnumber (L, MAIL_JOB_TIME100);\n\tlua_setfield (L, -2, \"MAIL_JOB_TIME100\");\n\tlua_pushnumber (L, MAIL_JOB_TIME90);\n\tlua_setfield (L, -2, \"MAIL_JOB_TIME890\");\n\tlua_pushnumber (L, MAIL_JOB_TIME80);\n\tlua_setfield (L, -2, \"MAIL_JOB_TIME80\");\n\tlua_pushnumber (L, MAIL_JOB_TIME50);\n\tlua_setfield (L, -2, \"MAIL_JOB_TIME50\");\n\tlua_pushnumber (L, MAIL_JOB_STAGE_OUT);\n\tlua_setfield (L, -2, \"MAIL_JOB_STAGE_OUT\");\n\tlua_pushnumber (L, MEM_PER_CPU);\n\tlua_setfield (L, -2, \"MEM_PER_CPU\");\n\tlua_pushnumber (L, NICE_OFFSET);\n\tlua_setfield (L, -2, \"NICE_OFFSET\");\n\tlua_pushnumber (L, JOB_SHARED_NONE);\n\tlua_setfield (L, -2, \"JOB_SHARED_NONE\");\n\tlua_pushnumber (L, JOB_SHARED_OK);\n\tlua_setfield (L, -2, \"JOB_SHARED_OK\");\n\tlua_pushnumber (L, JOB_SHARED_USER);\n\tlua_setfield (L, -2, \"JOB_SHARED_USER\");\n\tlua_pushnumber (L, JOB_SHARED_MCS);\n\tlua_setfield (L, -2, \"JOB_SHARED_MCS\");\n\tlua_pushnumber (L, NO_VAL64);\n\tlua_setfield (L, -2, \"NO_VAL64\");\n\tlua_pushnumber (L, NO_VAL);\n\tlua_setfield (L, -2, \"NO_VAL\");\n\tlua_pushnumber (L, NO_VAL16);\n\tlua_setfield (L, -2, \"NO_VAL16\");\n\tlua_pushnumber (L, NO_VAL8);\n\tlua_setfield (L, -2, \"NO_VAL8\");\n\tlua_pushnumber (L, SHARED_FORCE);\n\tlua_setfield (L, -2, \"SHARED_FORCE\");\n\n\t/*\n\t * job_desc bitflags\n\t */\n\tlua_pushnumber (L, GRES_ENFORCE_BIND);\n\tlua_setfield (L, -2, \"GRES_ENFORCE_BIND\");\n\tlua_pushnumber (L, KILL_INV_DEP);\n\tlua_setfield (L, -2, \"KILL_INV_DEP\");\n\tlua_pushnumber (L, NO_KILL_INV_DEP);\n\tlua_setfield (L, -2, \"NO_KILL_INV_DEP\");\n\tlua_pushnumber (L, SPREAD_JOB);\n\tlua_setfield (L, -2, \"SPREAD_JOB\");\n\tlua_pushnumber (L, USE_MIN_NODES);\n\tlua_setfield (L, -2, \"USE_MIN_NODES\");\n\n\tlua_setglobal (L, \"slurm\");\n\n\tlast_lua_jobs_update = 0;\n\t_update_jobs_global();\n\tlast_lua_resv_update = 0;\n\t_update_resvs_global();\n}\n\nstatic void _register_lua_slurm_struct_functions (void)\n{\n\tlua_pushcfunction(L, _get_job_env_field_name);\n\tlua_setglobal(L, \"_get_job_env_field_name\");\n\tlua_pushcfunction(L, _get_job_req_field_name);\n\tlua_setglobal(L, \"_get_job_req_field_name\");\n\tlua_pushcfunction(L, _set_job_env_field);\n\tlua_setglobal(L, \"_set_job_env_field\");\n\tlua_pushcfunction(L, _set_job_req_field);\n\tlua_setglobal(L, \"_set_job_req_field\");\n\tlua_pushcfunction(L, _get_part_rec_field);\n\tlua_setglobal(L, \"_get_part_rec_field\");\n}\n\n/*\n *  check that global symbol [name] in lua script is a function\n */\nstatic int _check_lua_script_function(const char *name)\n{\n\tint rc = 0;\n\tlua_getglobal(L, name);\n\tif (!lua_isfunction(L, -1))\n\t\trc = -1;\n\tlua_pop(L, -1);\n\treturn (rc);\n}\n\n/*\n *   Verify all required functions are defined in the job_submit/lua script\n */\nstatic int _check_lua_script_functions(void)\n{\n\tint rc = 0;\n\tint i;\n\tconst char *fns[] = {\n\t\t\"slurm_job_submit\",\n\t\t\"slurm_job_modify\",\n\t\tNULL\n\t};\n\n\ti = 0;\n\tdo {\n\t\tif (_check_lua_script_function(fns[i]) < 0) {\n\t\t\terror(\"job_submit/lua: %s: \"\n\t\t\t      \"missing required function %s\",\n\t\t\t      lua_script_path, fns[i]);\n\t\t\trc = -1;\n\t\t}\n\t} while (fns[++i]);\n\n\treturn (rc);\n}\n\nstatic int _load_script(void)\n{\n\tint rc = SLURM_SUCCESS;\n\tstruct stat st;\n\tlua_State *L_orig = L;\n\n\tif (stat(lua_script_path, &st) != 0) {\n\t\tif (L_orig) {\n\t\t\t(void) error(\"Unable to stat %s, \"\n\t\t\t             \"using old script: %s\",\n\t\t\t             lua_script_path, strerror(errno));\n\t\t\treturn SLURM_SUCCESS;\n\t\t}\n\t\treturn error(\"Unable to stat %s: %s\",\n\t\t             lua_script_path, strerror(errno));\n\t}\n\t\n\tif (st.st_mtime <= lua_script_last_loaded) {\n\t\treturn SLURM_SUCCESS;\n\t}\n\n\t/*\n\t *  Initilize lua\n\t */\n\tL = luaL_newstate();\n\tluaL_openlibs(L);\n\tif (luaL_loadfile(L, lua_script_path)) {\n\t\tif (L_orig) {\n\t\t\t(void) error(\"lua: %s: %s, using previous script\",\n\t\t\t             lua_script_path, lua_tostring(L, -1));\n\t\t\tlua_close(L);\n\t\t\tL = L_orig;\n\t\t\treturn SLURM_SUCCESS;\n\t\t}\n\t\trc = error(\"lua: %s: %s\", lua_script_path,\n\t\t           lua_tostring(L, -1));\n\t\tlua_pop(L, 1);\n\t\treturn rc;\n\t}\n\n\t/*\n\t *  Register SLURM functions in lua state:\n\t *  logging and slurm structure read/write functions\n\t */\n\t_register_lua_slurm_output_functions();\n\t_register_lua_slurm_struct_functions();\n\n\t/*\n\t *  Run the user script:\n\t */\n\tif (lua_pcall(L, 0, 1, 0) != 0) {\n\t\tif (L_orig) {\n\t\t\t(void) error(\"job_submit/lua: %s: %s, \"\n\t\t\t             \"using previous script\",\n\t\t\t             lua_script_path, lua_tostring(L, -1));\n\t\t\tlua_close(L);\n\t\t\tL = L_orig;\n\t\t\treturn SLURM_SUCCESS;\n\t\t}\n\t\trc = error(\"job_submit/lua: %s: %s\",\n\t\t           lua_script_path, lua_tostring(L, -1));\n\t\tlua_pop(L, 1);\n\t\treturn rc;\n\t}\n\n\t/*\n\t *  Get any return code from the lua script\n\t */\n\trc = (int) lua_tonumber(L, -1);\n\tif (rc != SLURM_SUCCESS) {\n\t\tif (L_orig) {\n\t\t\t(void) error(\"job_submit/lua: %s: returned %d \"\n\t\t\t             \"on load, using previous script\",\n\t\t\t             lua_script_path, rc);\n\t\t\tlua_close(L);\n\t\t\tL = L_orig;\n\t\t\treturn SLURM_SUCCESS;\n\t\t}\n\t\t(void) error(\"job_submit/lua: %s: returned %d on load\",\n\t\t             lua_script_path, rc);\n\t\tlua_pop (L, 1);\n\t\treturn rc;\n\t}\n\n\t/*\n\t *  Check for required lua script functions:\n\t */\n\trc = _check_lua_script_functions();\n\tif (rc != SLURM_SUCCESS) {\n\t\tif (L_orig) {\n\t\t\t(void) error(\"job_submit/lua: %s: \"\n\t\t\t             \"required function(s) not present, \"\n\t\t\t             \"using previous script\",\n\t\t\t             lua_script_path);\n\t\t\tlua_close(L);\n\t\t\tL = L_orig;\n\t\t\treturn SLURM_SUCCESS;\n\t\t}\n\t\treturn rc;\n\t}\n\n\tif (L_orig)\n\t\tlua_close(L_orig);\n\tlua_script_last_loaded = time(NULL);\n\treturn SLURM_SUCCESS;\n}\n\n/*\n *  NOTE: The init callback should never be called multiple times,\n *   let alone called from multiple threads. Therefore, locking\n *   is unnecessary here.\n */\nint init(void)\n{\n\tint rc = SLURM_SUCCESS;\n\n\t/*\n\t * Need to dlopen() the Lua library to ensure plugins see\n\t * appropriate symptoms\n\t */\n\tif ((rc = xlua_dlopen()) != SLURM_SUCCESS)\n\t\treturn rc;\n\n\treturn _load_script();\n}\n\nint fini(void)\n{\n\tlua_close (L);\n\treturn SLURM_SUCCESS;\n}\n\n\n/* Lua script hook called for \"submit job\" event. */\nextern int job_submit(struct job_descriptor *job_desc, uint32_t submit_uid,\n\t\t      char **err_msg)\n{\n\tint rc = SLURM_ERROR;\n\tslurm_mutex_lock (&lua_lock);\n\n\t(void) _load_script();\n\n\t/*\n\t *  All lua script functions should have been verified during\n\t *   initialization:\n\t */\n\tlua_getglobal(L, \"slurm_job_submit\");\n\tif (lua_isnil(L, -1))\n\t\tgoto out;\n\n\t_update_jobs_global();\n\t_update_resvs_global();\n\n\t_push_job_desc(job_desc);\n\t_push_partition_list(job_desc->user_id, submit_uid);\n\tlua_pushnumber (L, submit_uid);\n\t_stack_dump(\"job_submit, before lua_pcall\", L);\n\tif (lua_pcall (L, 3, 1, 0) != 0) {\n\t\terror(\"%s/lua: %s: %s\",\n\t\t      __func__, lua_script_path, lua_tostring (L, -1));\n\t} else {\n\t\tif (lua_isnumber(L, -1)) {\n\t\t\trc = lua_tonumber(L, -1);\n\t\t} else {\n\t\t\tinfo(\"%s/lua: %s: non-numeric return code\",\n\t\t\t      __func__, lua_script_path);\n\t\t\trc = SLURM_SUCCESS;\n\t\t}\n\t\tlua_pop(L, 1);\n\t}\n\t_stack_dump(\"job_submit, after lua_pcall\", L);\n\tif (user_msg) {\n\t\t*err_msg = user_msg;\n\t\tuser_msg = NULL;\n\t}\n\nout:\tslurm_mutex_unlock (&lua_lock);\n\treturn rc;\n}\n\n/* Lua script hook called for \"modify job\" event. */\nextern int job_modify(struct job_descriptor *job_desc,\n\t\t      struct job_record *job_ptr, uint32_t submit_uid)\n{\n\tint rc = SLURM_ERROR;\n\tslurm_mutex_lock (&lua_lock);\n\n\t/*\n\t *  All lua script functions should have been verified during\n\t *   initialization:\n\t */\n\tlua_getglobal(L, \"slurm_job_modify\");\n\tif (lua_isnil(L, -1))\n\t\tgoto out;\n\n\t_update_jobs_global();\n\t_update_resvs_global();\n\n\t_push_job_desc(job_desc);\n\t_push_job_rec(job_ptr);\n\t_push_partition_list(job_ptr->user_id, submit_uid);\n\tlua_pushnumber (L, submit_uid);\n\t_stack_dump(\"job_modify, before lua_pcall\", L);\n\tif (lua_pcall (L, 4, 1, 0) != 0) {\n\t\terror(\"%s/lua: %s: %s\",\n\t\t      __func__, lua_script_path, lua_tostring (L, -1));\n\t} else {\n\t\tif (lua_isnumber(L, -1)) {\n\t\t\trc = lua_tonumber(L, -1);\n\t\t} else {\n\t\t\tinfo(\"%s/lua: %s: non-numeric return code\",\n\t\t\t     __func__, lua_script_path);\n\t\t\trc = SLURM_SUCCESS;\n\t\t}\n\t\tlua_pop(L, 1);\n\t}\n\t_stack_dump(\"job_modify, after lua_pcall\", L);\n\tif (user_msg) {\n\t\terror(\"Use of log.user() in job_modify is not supported. \"\n\t\t      \"Message discarded: (\\\"%s\\\")\", user_msg);\n\t\txfree(user_msg);\n\t}\n\nout:\tslurm_mutex_unlock (&lua_lock);\n\treturn rc;\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/src/plugins/switch/nrt/nrt.c": "/*****************************************************************************\\\n *  nrt.c - Library routines for initiating jobs using IBM's NRT (Network\n *          Routing Table)\n *****************************************************************************\n *  Copyright (C) 2004-2007 The Regents of the University of California.\n *  Copyright (C) 2008 Lawrence Livermore National Security.\n *  Copyright (C) 2011-2014 SchedMD LLC.\n *  Original switch/federation plugin written by Jason King <jking@llnl.gov>\n *  Largely re-written for NRT support by Morris Jette <jette@schedmd.com>\n *\n *  This file is part of SLURM, a resource management program.\n *  For details, see <https://slurm.schedmd.com/>.\n *  Please also read the included file: DISCLAIMER.\n *\n *  SLURM is free software; you can redistribute it and/or modify it under\n *  the terms of the GNU General Public License as published by the Free\n *  Software Foundation; either version 2 of the License, or (at your option)\n *  any later version.\n *\n *  In addition, as a special exception, the copyright holders give permission\n *  to link the code of portions of this program with the OpenSSL library under\n *  certain conditions as described in each individual source file, and\n *  distribute linked combinations including the two. You must obey the GNU\n *  General Public License in all respects for all of the code used other than\n *  OpenSSL. If you modify file(s) with this exception, you may extend this\n *  exception to your version of the file(s), but you are not obligated to do\n *  so. If you do not wish to do so, delete this exception statement from your\n *  version.  If you delete this exception statement from all source files in\n *  the program, then also delete it here.\n *\n *  SLURM is distributed in the hope that it will be useful, but WITHOUT ANY\n *  WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n *  FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more\n *  details.\n *\n *  You should have received a copy of the GNU General Public License along\n *  with SLURM; if not, write to the Free Software Foundation, Inc.,\n *  51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA.\n *****************************************************************************\n *  NOTE: The NRT API communicates with IBM's Protocol Network Services Deamon\n *  (PNSD). PNSD logs are written to /tmp/serverlog.\n *\n *  NOTE: To get good POE error message it may be necessary to execute\n *  export LANG=en_US\n *\n *  NOTE: POE core files always written to /tmp\n *\n *  NOTE: POE and PMD initiallly load /usr/lib64/libpermapi.so rather than the\n *  library specified by MP_PRE_RMLIB in /etc/poe.limits. For now we need to\n *  put SLURM's libpermapi.so in /usr/lib64. IBM to address later.\n\\*****************************************************************************/\n\n#include \"config.h\"\n\n#include <assert.h>\n#include <arpa/inet.h>\n#include <dlfcn.h>\n#include <nrt.h>\n#include <pthread.h>\n#include <stdlib.h>\n#include <sys/socket.h>\n#include <sys/stat.h>\n#include <sys/types.h>\n\n#include \"slurm/slurm_errno.h\"\n#include \"src/common/slurm_xlator.h\"\n#include \"src/common/strlcpy.h\"\n#include \"src/common/read_config.h\"\n#include \"src/common/node_conf.h\"\n#include \"src/plugins/switch/nrt/nrt_keys.h\"\n#include \"src/plugins/switch/nrt/slurm_nrt.h\"\n\n/* This plugin may execute on a head node WITHOUT the libnrt.so file.\n * Dynamically load the library only on demand. */\nvoid *nrt_handle = NULL;\nchar *nrt_sym[]  = {\n\t\"nrt_command\",\n\tNULL\n};\ntypedef struct {\n\tint (*nrt_command)(int version, nrt_cmd_type_t cmd_type, void *cmd);\n} nrt_api_t;\nnrt_api_t nrt_api;\n\nstatic int nrt_cmd_wrap(int version, nrt_cmd_type_t cmd_type, void *cmd)\n{\n\tint i, rc;\n\n\tif (!nrt_handle) {\n\t\tvoid **api_pptr = (void **) &nrt_api;\n#ifdef LIBNRT_SO\n\t\tnrt_handle = dlopen(LIBNRT_SO, RTLD_LAZY);\n#endif\n\t\tif (!nrt_handle)\n\t\t\tfatal(\"Can not open libnrt.so\");\n\n\t\tdlerror();\t/* Clear any existing error */\n\t\tfor ( i = 0; nrt_sym[i]; ++i ) {\n\t\t        api_pptr[i] = dlsym(nrt_handle, nrt_sym[i]);\n\t\t        if (!api_pptr[i]) {\n\t\t\t\tfatal(\"Can't find %s in libnrt.so\",\n\t\t\t\t      nrt_sym[i]);\n\t\t\t}\n\t\t}\n\t}\n\n\trc = ((*(nrt_api.nrt_command))(version, cmd_type, cmd));\n\treturn rc;\n}\n\nextern int drain_nodes ( char *nodes, char *reason, uint32_t reason_uid );\n\n/*\n * Definitions local to this module\n */\n#define NRT_NULL_MAGIC  \t0xDEAFDEAF\n#define NRT_NODEINFO_MAGIC\t0xc00cc00a\n#define NRT_JOBINFO_MAGIC\t0xc00cc00b\n\n#define NRT_LIBSTATE_MAGIC\t0xc00cc00c\n#define NRT_HOSTLEN\t\t20\n#define NRT_NODECOUNT\t\t128\n#define NRT_HASHCOUNT\t\t128\n#define NRT_MAX_ADAPTERS (NRT_MAX_ADAPTERS_PER_TYPE * NRT_MAX_ADAPTER_TYPES)\n#define NRT_MAX_PROTO_CNT\t20\n\n/* Use slurm protocol version as a global version number.\n */\n#define NRT_STATE_VERSION      \"PROTOCOL_VERSION\"\n\npthread_mutex_t\t\tglobal_lock = PTHREAD_MUTEX_INITIALIZER;\nextern bool\t\tnrt_need_state_save;\nslurm_nrt_libstate_t *\tnrt_state = NULL;\nmode_t\t\t\tnrt_umask;\n\n/*\n * Data structures specific to switch/nrt\n *\n * We are going to some trouble to keep these defs private so slurm\n * hackers not interested in the interconnect details can just pass around\n * the opaque types.  All use of the data structure internals is local to this\n * module.\n */\n\n/* Notes about job_key:\n * - It must be unique for every job step.\n * - It is a 32-bit quantity.\n * - We might use the bottom 16-bits of job ID an step ID, but that could\n *   result in conflicts for long-lived jobs or job steps.\n */\ntypedef struct slurm_nrt_window {\n\tnrt_window_id_t window_id;\n\twin_state_t state;\n\tnrt_job_key_t job_key;\n} slurm_nrt_window_t;\n\ntypedef struct slurm_nrt_block {\n\tuint32_t rcontext_block_use;\t/* RDMA context blocks used */\n\tnrt_job_key_t job_key;\n} slurm_nrt_block_t;\n\ntypedef struct slurm_nrt_adapter {\n\tchar adapter_name[NRT_MAX_ADAPTER_NAME_LEN];\n\tnrt_adapter_t adapter_type;\n\tnrt_cau_index_t cau_indexes_avail;\n\tnrt_cau_index_t cau_indexes_used;\n\tnrt_imm_send_slot_t immed_slots_avail;\n\tnrt_imm_send_slot_t immed_slots_used;\n\tin_addr_t ipv4_addr;\n\tstruct in6_addr ipv6_addr;\n\tnrt_logical_id_t lid;\n\tnrt_network_id_t network_id;\n\tnrt_port_id_t port_id;\n\tuint64_t rcontext_block_count;\t/* # of RDMA context blocks */\n\tuint64_t rcontext_block_used;\t/* # of RDMA context blocks used */\n\tuint16_t block_count;\n\tslurm_nrt_block_t *block_list;\n\tuint64_t special;\n\tnrt_window_id_t window_count;\n\tslurm_nrt_window_t *window_list;\n} slurm_nrt_adapter_t;\n\nstruct slurm_nrt_nodeinfo {\n\tuint32_t magic;\n\tchar name[NRT_HOSTLEN];\n\tuint32_t adapter_count;\n\tslurm_nrt_adapter_t *adapter_list;\n\tstruct slurm_nrt_nodeinfo *next;\n\tnrt_node_number_t node_number;\n};\n\nstruct slurm_nrt_libstate {\n\tuint32_t magic;\n\tuint32_t node_count;\n\tuint32_t node_max;\n\tslurm_nrt_nodeinfo_t *node_list;\n\tuint32_t hash_max;\n\tslurm_nrt_nodeinfo_t **hash_table;\n\tnrt_job_key_t key_index;\n};\n\nstruct slurm_nrt_jobinfo {\n\tuint32_t magic;\n\t/* version from nrt_version() */\n\t/* adapter from lid in table */\n\t/* uid from getuid() */\n\t/* pid from getpid() */\n\tnrt_job_key_t job_key;\n\tuint8_t bulk_xfer;\t/* flag */\n\tuint32_t bulk_xfer_resources;\n\tuint16_t cau_indexes;\n\tuint16_t immed_slots;\n\tuint8_t ip_v4;\t\t/* flag */\n\tuint8_t user_space;\t/* flag */\n\tuint16_t tables_per_task;\n\tnrt_tableinfo_t *tableinfo;\n\n\thostlist_t nodenames;\n\tuint32_t num_tasks;\n};\n\ntypedef struct {\n\tchar adapter_name[NRT_MAX_ADAPTER_NAME_LEN];\n\tnrt_adapter_t adapter_type;\n} nrt_cache_entry_t;\n\n\ntypedef struct nrt_protocol_info {\n\tchar protocol_name[NRT_MAX_PROTO_NAME_LEN];\n} nrt_protocol_info_t;\n\ntypedef struct nrt_protocol_table {\n\tnrt_protocol_info_t protocol_table[NRT_MAX_PROTO_CNT];\n\tint protocol_table_cnt;\t/* Count of entries in protocol_table */\n} nrt_protocol_table_t;\n\ntypedef struct slurm_nrt_suspend_info {\n\tuint32_t job_key_count;\n\tuint32_t job_key_array_size;\n\tnrt_job_key_t *job_key;\n} slurm_nrt_suspend_info_t;\n\nstatic int lid_cache_size = 0;\nstatic nrt_cache_entry_t lid_cache[NRT_MAX_ADAPTERS];\nstatic bool dynamic_window_err = false;\t/* print error only once */\n\n/* Keep track of local ID so slurmd can determine which switch tables\n * are for that particular node */\nstatic uint64_t my_lpar_id = 0;\nstatic uint64_t my_lid = 0;\nstatic bool     my_lpar_id_set = false;\nstatic uint64_t my_network_id = 0;\nstatic bool     my_network_id_set = false;\n\n/* Local functions */\nstatic char *\t_adapter_type_str(nrt_adapter_t type);\nstatic int\t_add_block_use(slurm_nrt_jobinfo_t *jp,\n\t\t\t       slurm_nrt_adapter_t *adapter);\nstatic int\t_add_immed_use(char *hostname, slurm_nrt_jobinfo_t *jp,\n\t\t\t       slurm_nrt_adapter_t *adapter);\nstatic int\t_allocate_windows_all(slurm_nrt_jobinfo_t *jp, char *hostname,\n\t\t\tuint32_t node_id, nrt_task_id_t task_id,\n\t\t\tnrt_adapter_t adapter_type, int network_id,\n\t\t\tnrt_protocol_table_t *protocol_table, int instances,\n\t\t\tint task_inx);\nstatic int\t_allocate_window_single(char *adapter_name,\n\t\t\tslurm_nrt_jobinfo_t *jp, char *hostname,\n\t\t\tuint32_t node_id, nrt_task_id_t task_id,\n\t\t\tnrt_adapter_t adapter_type, int network_id,\n\t\t\tnrt_protocol_table_t *protocol_table, int instances,\n\t\t\tint task_inx);\nstatic slurm_nrt_libstate_t *_alloc_libstate(void);\nstatic slurm_nrt_nodeinfo_t *_alloc_node(slurm_nrt_libstate_t *lp, char *name);\nstatic int\t_copy_node(slurm_nrt_nodeinfo_t *dest,\n\t\t\t   slurm_nrt_nodeinfo_t *src);\nstatic int\t_fake_unpack_adapters(Buf buf, slurm_nrt_nodeinfo_t *n,\n\t\t\t\t      uint16_t protocol_version);\nstatic int\t_fill_in_adapter_cache(void);\nstatic slurm_nrt_nodeinfo_t *\n\t\t_find_node(slurm_nrt_libstate_t *lp, char *name);\nstatic slurm_nrt_window_t *\n\t\t_find_window(slurm_nrt_adapter_t *adapter, uint16_t window_id);\nstatic slurm_nrt_window_t *_find_free_window(slurm_nrt_adapter_t *adapter);\nstatic slurm_nrt_nodeinfo_t *_find_node(slurm_nrt_libstate_t *lp, char *name);\nstatic bool\t_free_block_use(slurm_nrt_jobinfo_t *jp,\n\t\t\t\tslurm_nrt_adapter_t *adapter);\nstatic void\t_free_libstate(slurm_nrt_libstate_t *lp);\nstatic int\t_get_adapters(slurm_nrt_nodeinfo_t *n);\nstatic int\t_get_my_id(void);\nstatic void\t_hash_add_nodeinfo(slurm_nrt_libstate_t *state,\n\t\t\t\t   slurm_nrt_nodeinfo_t *node);\nstatic int\t_hash_index(char *name);\nstatic void\t_hash_rebuild(slurm_nrt_libstate_t *state);\nstatic void\t_init_adapter_cache(void);\nstatic preemption_state_t _job_preempt_state(nrt_job_key_t job_key);\nstatic int\t_job_step_window_state(slurm_nrt_jobinfo_t *jp,\n\t\t\t\t       hostlist_t hl, win_state_t state);\nstatic int\t_load_min_window_id(char *adapter_name,\n\t\t\t\t    nrt_adapter_t adapter_type);\nstatic nrt_job_key_t _next_key(void);\nstatic int\t_pack_libstate(slurm_nrt_libstate_t *lp, Buf buffer,\n\t\t\t       uint16_t protocol_version);\nstatic void\t_pack_tableinfo(nrt_tableinfo_t *tableinfo, Buf buf,\n\t\t\t\tslurm_nrt_jobinfo_t *jp,\n\t\t\t\tuint16_t protocol_version);\nstatic char *\t_state_str(win_state_t state);\nstatic int\t_unload_window_all_jobs(char *adapter_name,\n\t\t\t\t\tnrt_adapter_t adapter_type,\n\t\t\t\t\tnrt_window_id_t window_id);\nstatic int\t_unpack_libstate(slurm_nrt_libstate_t *lp, Buf buffer);\nstatic int\t_unpack_nodeinfo(slurm_nrt_nodeinfo_t *n, Buf buf,\n\t\t\t\t bool believe_window_status,\n\t\t\t\t uint16_t protocol_version);\nstatic int\t_unpack_tableinfo(nrt_tableinfo_t *tableinfo,\n\t\t\t\t  Buf buf, slurm_nrt_jobinfo_t *jp,\n\t\t\t\t  uint16_t protocol_version);\nstatic int\t_wait_for_all_windows(nrt_tableinfo_t *tableinfo);\nstatic int\t_wait_for_window_unloaded(char *adapter_name,\n\t\t\t\t\t  nrt_adapter_t adapter_type,\n\t\t\t\t\t  nrt_window_id_t window_id,\n\t\t\t\t\t  int retry);\nstatic int\t_wait_job(nrt_job_key_t job_key,preemption_state_t want_state,\n\t\t\t  int max_wait_secs);\nstatic char *\t_win_state_str(win_state_t state);\nstatic int\t_window_state_set(slurm_nrt_jobinfo_t *jp, char *hostname,\n\t\t\t\t  win_state_t state);\n\n/* The lid caching functions were created to avoid unnecessary\n * function calls each time we need to load network tables on a node.\n * _init_cache() simply initializes the cache to save values and\n * needs to be called before any other cache functions are called.\n *\n * Used by: slurmd/slurmstepd\n */\nstatic void\n_init_adapter_cache(void)\n{\n\tlid_cache_size = 0;\n}\n\n/* Use nrt_adapter_resources to cache information about local adapters.\n *\n * Used by: slurmstepd\n */\nstatic int\n_fill_in_adapter_cache(void)\n{\n\tint err, i, j, rc = SLURM_SUCCESS;\n\tnrt_cmd_query_adapter_types_t adapter_types;\n\tunsigned int num_adapter_types;\n\tnrt_adapter_t adapter_type[NRT_MAX_ADAPTER_TYPES];\n\tnrt_cmd_query_adapter_names_t adapter_names;\n\tunsigned int max_windows, num_adapter_names;\n\n\tif (debug_flags & DEBUG_FLAG_SWITCH)\n\t\tinfo(\"_fill_in_adapter_cache: begin\");\n\n\tadapter_types.num_adapter_types = &num_adapter_types;\n\tadapter_types.adapter_types = adapter_type;\n\tfor (i = 0; i < 2; i++) {\n\t\terr = nrt_cmd_wrap(NRT_VERSION, NRT_CMD_QUERY_ADAPTER_TYPES,\n\t\t\t\t   &adapter_types);\n\t\tif (err != NRT_EAGAIN)\n\t\t\tbreak;\n\t\terror(\"nrt_cmd_wrap(adapter_types): %s\", nrt_err_str(err));\n\t\terror(\"Is pnsd daemon started? Retrying...\");\n\t\t/* Run \"/opt/ibmhpc/pecurrent/ppe.pami/pnsd/pnsd -A\" */\n\t\tsleep(5);\n\t}\n\tif (err != NRT_SUCCESS) {\n\t\terror(\"nrt_cmd_wrap(adapter_types): %s\", nrt_err_str(err));\n\t\treturn SLURM_ERROR;\n\t}\n\n\tfor (i = 0; i < num_adapter_types; i++) {\n\t\tif (debug_flags & DEBUG_FLAG_SWITCH)\n\t\t\tinfo(\"adapter_type[%d]: %u\", i, adapter_type[i]);\n\n\t\tadapter_names.adapter_type = adapter_type[i];\n\t\tadapter_names.num_adapter_names = &num_adapter_names;\n\t\tadapter_names.max_windows = &max_windows;\n\t\terr = nrt_cmd_wrap(NRT_VERSION, NRT_CMD_QUERY_ADAPTER_NAMES,\n\t\t\t\t   &adapter_names);\n\t\tif (err != NRT_SUCCESS) {\n\t\t\terror(\"nrt_cmd_wrap(adapter_names, %u): %s\",\n\t\t\t      adapter_names.adapter_type, nrt_err_str(err));\n\t\t\trc = SLURM_ERROR;\n\t\t\tcontinue;\n\t\t}\n\t\tfor (j = 0; j < num_adapter_names; j++) {\n\t\t\tif (debug_flags & DEBUG_FLAG_SWITCH) {\n\t\t\t\tinfo(\"adapter_names[%d]: %s\",\n\t\t\t\t     j, adapter_names.adapter_names[j]);\n\t\t\t}\n\t\t\tlid_cache[lid_cache_size].adapter_type = adapter_names.\n\t\t\t\t\t\t\t\t adapter_type;\n\t\t\tstrlcpy(lid_cache[lid_cache_size].adapter_name,\n\t\t\t\tadapter_names.adapter_names[j],\n\t\t\t\tNRT_MAX_ADAPTER_NAME_LEN);\n\t\t\tlid_cache_size++;\n\t\t}\n\t}\n\tif (debug_flags & DEBUG_FLAG_SWITCH)\n\t\tinfo(\"_fill_in_adapter_cache: complete: %d\", rc);\n\n\treturn rc;\n}\n\n/* The idea behind keeping the hash table was to avoid a linear\n * search of the node list each time we want to retrieve or\n * modify a node's data.  The _hash_index function translates\n * a node name to an index into the hash table.\n *\n * Used by: slurmctld\n */\nstatic int\n_hash_index(char *name)\n{\n\tint index = 0;\n\tint j;\n\n\txassert(name);\n\n\t/* Multiply each character by its numerical position in the\n\t * name string to add a bit of entropy, because host names such\n\t * as cluster[0001-1000] can cause excessive index collisions.\n\t */\n\tfor (j = 1; *name; name++, j++)\n\t\tindex += (int)*name * j;\n\tindex %= nrt_state->hash_max;\n\n\treturn index;\n}\n\n/* Tries to find a node fast using the hash table\n *\n * Used by: slurmctld\n */\nstatic slurm_nrt_nodeinfo_t *\n_find_node(slurm_nrt_libstate_t *lp, char *name)\n{\n\tint i;\n\tslurm_nrt_nodeinfo_t *n;\n\tstruct node_record *node_ptr;\n\n\txassert(name);\n\txassert(lp);\n\n\tif (lp->node_count == 0)\n\t\treturn NULL;\n\n\tif (lp->hash_table) {\n\t\ti = _hash_index(name);\n\t\tn = lp->hash_table[i];\n\t\twhile (n) {\n\t\t\txassert(n->magic == NRT_NODEINFO_MAGIC);\n\t\t\tif (!xstrncmp(n->name, name, NRT_HOSTLEN))\n\t\t\t\treturn n;\n\t\t\tn = n->next;\n\t\t}\n\t}\n\n\t/* This code is only needed if NodeName and NodeHostName differ */\n\tnode_ptr = find_node_record(name);\n\tif (node_ptr && lp->hash_table) {\n\t\ti = _hash_index(node_ptr->node_hostname);\n\t\tn = lp->hash_table[i];\n\t\twhile (n) {\n\t\t\txassert(n->magic == NRT_NODEINFO_MAGIC);\n\t\t\tif (!xstrncmp(n->name, node_ptr->node_hostname,\n\t\t\t\t      NRT_HOSTLEN))\n\t\t\t\treturn n;\n\t\t\tn = n->next;\n\t\t}\n\t}\n\n\treturn NULL;\n}\n\n/* Add the hash entry for a newly created slurm_nrt_nodeinfo_t\n */\nstatic void\n_hash_add_nodeinfo(slurm_nrt_libstate_t *state, slurm_nrt_nodeinfo_t *node)\n{\n\tint index;\n\n\txassert(state);\n\txassert(state->hash_table);\n\txassert(state->hash_max >= state->node_count);\n\tif (!node->name[0])\n\t\treturn;\n\tindex = _hash_index(node->name);\n\tnode->next = state->hash_table[index];\n\tstate->hash_table[index] = node;\n}\n\n/* Recreates the hash table for the node list.\n *\n * Used by: slurmctld\n */\nstatic void\n_hash_rebuild(slurm_nrt_libstate_t *state)\n{\n\tint i;\n\n\txassert(state);\n\n\tif (state->hash_table)\n\t\txfree(state->hash_table);\n\tif ((state->node_count > state->hash_max) || (state->hash_max == 0))\n\t\tstate->hash_max += NRT_HASHCOUNT;\n\tstate->hash_table = (slurm_nrt_nodeinfo_t **)\n\t\t\t    xmalloc(sizeof(slurm_nrt_nodeinfo_t *) *\n\t\t\t    state->hash_max);\n\tfor (i = 0; i < state->node_count; i++)\n\t\t_hash_add_nodeinfo(state, &(state->node_list[i]));\n}\n\nstatic slurm_nrt_window_t *\n_find_window(slurm_nrt_adapter_t *adapter, uint16_t window_id)\n{\n\tint i;\n\tslurm_nrt_window_t *window;\n\n\tfor (i = 0; i < adapter->window_count; i++) {\n\t\twindow = &adapter->window_list[i];\n\t\tif (window->window_id == window_id)\n\t\t\treturn window;\n\t}\n\n\tdebug3(\"Unable to _find_window %hu on adapter %s\",\n\t       window_id, adapter->adapter_name);\n\treturn (slurm_nrt_window_t *) NULL;\n}\n\n/*\n * For one node, free all of the RDMA blocks and windows belonging to a\n * particular job step (as identified by the job_key).\n */\nstatic void\n_free_resources_by_job(slurm_nrt_jobinfo_t *jp, char *node_name)\n{\n\tslurm_nrt_nodeinfo_t *node;\n\tslurm_nrt_adapter_t *adapter;\n\tslurm_nrt_window_t *window;\n\tint i, j;\n\n\t/* debug3(\"_free_resources_by_job_key(%u, %s)\", jp->job_key, node_name); */\n\tif ((node = _find_node(nrt_state, node_name)) == NULL)\n\t\treturn;\n\n\tif (node->adapter_list == NULL) {\n\t\terror(\"switch/nrt: _free_resources_by_job, \"\n\t\t      \"adapter_list NULL for node %s\", node_name);\n\t\treturn;\n\t}\n\tfor (i = 0; i < node->adapter_count; i++) {\n\t\tadapter = &node->adapter_list[i];\n\n\t\t(void) _free_block_use(jp, adapter);\n\t\tif (adapter->window_list == NULL) {\n\t\t\terror(\"switch/nrt: _free_resources_by_job, \"\n\t\t\t      \"window_list NULL for node %s adapter %s\",\n\t\t\t      node->name, adapter->adapter_name);\n\t\t\tcontinue;\n\t\t}\n\t\t/* We could check here to see if this adapter's name\n\t\t * is in the nrt_jobinfo tablinfo list to avoid the next\n\t\t * loop if the adapter isn't in use by the job step.\n\t\t * However, the added searching and string comparisons\n\t\t * probably aren't worth it, especially since MOST job\n\t\t * steps will use all of the adapters.\n\t\t */\n\t\tfor (j = 0; j < adapter->window_count; j++) {\n\t\t\twindow = &adapter->window_list[j];\n\n\t\t\tif (window->job_key == jp->job_key) {\n\t\t\t\t/* debug3(\"Freeing adapter %s window %d\",\n\t\t\t\t   adapter->name, window->id); */\n\t\t\t\twindow->state = NRT_WIN_AVAILABLE;\n\t\t\t\twindow->job_key = 0;\n\t\t\t\tif (jp->immed_slots >\n\t\t\t\t    adapter->immed_slots_used) {\n\t\t\t\t\terror(\"switch/nrt: immed_slots_used \"\n\t\t\t\t\t      \"underflow\");\n\t\t\t\t\tadapter->immed_slots_used = 0;\n\t\t\t\t} else {\n\t\t\t\t\tadapter->immed_slots_used -=\n\t\t\t\t\t\tjp->immed_slots;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}\n\n/*\n * Find all of the windows used by this job step and set their\n * status to \"state\".\n *\n * Used by: slurmctld\n */\nstatic int\n_job_step_window_state(slurm_nrt_jobinfo_t *jp, hostlist_t hl,\n\t\t       win_state_t state)\n{\n\thostlist_iterator_t hi;\n\tchar *host;\n\tint err, rc = SLURM_SUCCESS;\n\n\txassert(!hostlist_is_empty(hl));\n\n\tif ((jp == NULL) || (jp->magic == NRT_NULL_MAGIC)) {\n\t\tdebug2(\"(%s: %d: %s) job->switch_job was NULL\",\n\t\t       THIS_FILE, __LINE__, __func__);\n\t\treturn SLURM_ERROR;\n\t}\n\n\txassert(jp->magic == NRT_JOBINFO_MAGIC);\n\n\tif ((jp == NULL) || (hostlist_is_empty(hl)))\n\t\treturn SLURM_ERROR;\n\n\tif ((jp->tables_per_task == 0) || (jp->tableinfo == NULL) ||\n\t    (jp->tableinfo[0].table_length == 0) || (!jp->user_space))\n\t\treturn SLURM_SUCCESS;\n\n\thi = hostlist_iterator_create(hl);\n\tslurm_mutex_lock(&global_lock);\n\twhile ((host = hostlist_next(hi))) {\n\t\terr = _window_state_set(jp, host, state);\n\t\trc = MAX(rc, err);\n\t\tfree(host);\n\t}\n\tslurm_mutex_unlock(&global_lock);\n\thostlist_iterator_destroy(hi);\n\n\treturn rc;\n}\n\nstatic char *_state_str(win_state_t state)\n{\n\tif (state == NRT_WIN_UNAVAILABLE)\n\t\treturn \"Unavailable\";\n\tif (state == NRT_WIN_INVALID)\n\t\treturn \"Invalid\";\n\tif (state == NRT_WIN_AVAILABLE)\n\t\treturn \"Available\";\n\tif (state == NRT_WIN_RESERVED)\n\t\treturn \"Reserved\";\n\tif (state == NRT_WIN_READY)\n\t\treturn \"Ready\";\n\tif (state == NRT_WIN_RUNNING)\n\t\treturn \"Running\";\n\treturn \"Unknown\";\n}\n\n/* Find the correct NRT structs and set the state\n * of the switch windows for the specified task_id.\n *\n * Used by: slurmctld\n */\nstatic int\n_window_state_set(slurm_nrt_jobinfo_t *jp, char *hostname, win_state_t state)\n{\n\tslurm_nrt_nodeinfo_t *node = NULL;\n\tslurm_nrt_adapter_t *adapter = NULL;\n\tslurm_nrt_window_t *window = NULL;\n\tint i, j;\n\tint rc = SLURM_SUCCESS;\n\tbool adapter_found;\n\tuint16_t win_id = 0;\n\tnrt_job_key_t job_key = jp->job_key;\n\tnrt_table_id_t table_cnt = jp->tables_per_task;\n\tnrt_tableinfo_t *tableinfo = jp->tableinfo;\n\tnrt_task_id_t task_id;\n\n\txassert(tableinfo);\n\txassert(hostname);\n\n\tnode = _find_node(nrt_state, hostname);\n\tif (node == NULL) {\n\t\terror(\"Failed to find node in node_list: %s\", hostname);\n\t\treturn SLURM_ERROR;\n\t}\n\tif (node->adapter_list == NULL) {\n\t\terror(\"Found node, but adapter_list is NULL\");\n\t\treturn SLURM_ERROR;\n\t}\n\n\tfor (i = 0; i < table_cnt; i++) {\n\t\tif (tableinfo[i].table == NULL) {\n\t\t\terror(\"tableinfo[%d].table is NULL\", i);\n\t\t\trc = SLURM_ERROR;\n\t\t\tcontinue;\n\t\t}\n\n\t\tadapter_found = false;\n\t\t/* Find the adapter that matches the one in tableinfo */\n\t\tfor (j = 0; j < node->adapter_count; j++) {\n\t\t\tadapter = &node->adapter_list[j];\n\t\t\tif (xstrcasecmp(adapter->adapter_name,\n\t\t\t\t\ttableinfo[i].adapter_name))\n\t\t\t\tcontinue;\n\t\t\tfor (task_id = 0; task_id < tableinfo[i].table_length;\n\t\t\t     task_id++) {\n\t\t\t\tif (adapter->adapter_type == NRT_IB) {\n\t\t\t\t\tnrt_ib_task_info_t *ib_tbl_ptr;\n\t\t\t\t\tib_tbl_ptr  = tableinfo[i].table;\n\t\t\t\t\tib_tbl_ptr += task_id;\n\t\t\t\t\tif (ib_tbl_ptr == NULL) {\n\t\t\t\t\t\terror(\"tableinfo[%d].table[%d]\"\n\t\t\t\t\t\t      \" is NULL\", i, task_id);\n\t\t\t\t\t\trc = SLURM_ERROR;\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\tif (adapter->lid ==\n\t\t\t\t\t    ib_tbl_ptr->base_lid) {\n\t\t\t\t\t\tadapter_found = true;\n\t\t\t\t\t\twin_id = ib_tbl_ptr->win_id;\n\t\t\t\t\t\tdebug3(\"Setting status %s \"\n\t\t\t\t\t\t       \"adapter %s lid %hu \"\n\t\t\t\t\t\t       \"window %hu for task %d\",\n\t\t\t\t\t\t       _state_str(state),\n\t\t\t\t\t\t       adapter->adapter_name,\n\t\t\t\t\t\t       ib_tbl_ptr->base_lid,\n\t\t\t\t\t\t       ib_tbl_ptr->win_id,\n\t\t\t\t\t\t       task_id);\n\t\t\t\t\t}\n\t\t\t\t} else if (adapter->adapter_type == NRT_HFI) {\n\t\t\t\t\tnrt_hfi_task_info_t *hfi_tbl_ptr;\n\t\t\t\t\thfi_tbl_ptr  = tableinfo[i].table;\n\t\t\t\t\thfi_tbl_ptr += task_id;\n\t\t\t\t\tif (hfi_tbl_ptr == NULL) {\n\t\t\t\t\t\terror(\"tableinfo[%d].table[%d]\"\n\t\t\t\t\t\t      \" is NULL\", i, task_id);\n\t\t\t\t\t\trc = SLURM_ERROR;\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\tif (adapter->lid == hfi_tbl_ptr->lid) {\n\t\t\t\t\t\tadapter_found = true;\n\t\t\t\t\t\twin_id = hfi_tbl_ptr->win_id;\n\t\t\t\t\t\tdebug3(\"Setting status %s \"\n\t\t\t\t\t\t       \"adapter %s lid %hu \"\n\t\t\t\t\t\t       \"window %hu for task %d\",\n\t\t\t\t\t\t       _state_str(state),\n\t\t\t\t\t\t       adapter->adapter_name,\n\t\t\t\t\t\t       hfi_tbl_ptr->lid,\n\t\t\t\t\t\t       hfi_tbl_ptr->win_id,\n\t\t\t\t\t\t       task_id);\n\t\t\t\t\t}\n\t\t\t\t}\n#if NRT_VERSION < 1300\n\t\t\t\telse if ((adapter->adapter_type==NRT_HPCE) ||\n\t\t\t\t\t   (adapter->adapter_type==NRT_KMUX)) {\n\t\t\t\t\tnrt_hpce_task_info_t *hpce_tbl_ptr;\n\t\t\t\t\thpce_tbl_ptr  = tableinfo[i].table;\n\t\t\t\t\thpce_tbl_ptr += task_id;\n\t\t\t\t\tif (hpce_tbl_ptr == NULL) {\n\t\t\t\t\t\terror(\"tableinfo[%d].table[%d]\"\n\t\t\t\t\t\t      \" is NULL\", i, task_id);\n\t\t\t\t\t\trc = SLURM_ERROR;\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\tif (adapter->network_id ==\n\t\t\t\t\t    tableinfo[i].network_id) {\n\t\t\t\t\t\tadapter_found = true;\n\t\t\t\t\t\twin_id = hpce_tbl_ptr->win_id;\n\t\t\t\t\t\tdebug3(\"Setting status %s \"\n\t\t\t\t\t\t       \"adapter %s window %hu \"\n\t\t\t\t\t\t       \"for task %d\",\n\t\t\t\t\t\t       _state_str(state),\n\t\t\t\t\t\t       adapter->adapter_name,\n\t\t\t\t\t\t       hpce_tbl_ptr->win_id,\n\t\t\t\t\t\t       task_id);\n\t\t\t\t\t}\n\t\t\t\t}\n#endif\n\t\t\t\telse {\n\t\t\t\t\terror(\"switch/nrt: _window_state_set:\"\n\t\t\t\t\t      \" Missing support for adapter \"\n\t\t\t\t\t      \"type %s\",\n\t\t\t\t\t      _adapter_type_str(adapter->\n\t\t\t\t\t\t\t\tadapter_type));\n\t\t\t\t}\n\n\t\t\t\twindow = _find_window(adapter, win_id);\n\t\t\t\tif (window) {\n\t\t\t\t\twindow->state = state;\n\t\t\t\t\tif (state == NRT_WIN_UNAVAILABLE) {\n\t\t\t\t\t\twindow->job_key = job_key;\n\t\t\t\t\t\tadapter->immed_slots_used +=\n\t\t\t\t\t\t\tjp->immed_slots;\n\t\t\t\t\t} else\n\t\t\t\t\t\twindow->job_key = 0;\n\t\t\t\t}\n\t\t\t}  /* for each task */\n\t\t\tif (adapter_found) {\n\t\t\t\t_add_block_use(jp, adapter);\n\t\t\t} else {\n\t\t\t\terror(\"switch/nrt: Did not find adapter %s of \"\n\t\t\t\t      \"type %s with lid %hu \",\n\t\t\t\t      adapter->adapter_name,\n\t\t\t\t      _adapter_type_str(adapter->adapter_type),\n\t\t\t\t      adapter->lid);\n\t\t\t\trc = SLURM_ERROR;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t}  /* for each adapter */\n\t}  /* for each table */\n\n\treturn rc;\n}\n\n/* If the node is already in the node list then simply return\n * a pointer to it, otherwise dynamically allocate memory to the\n * node list if necessary.\n *\n * Used by: slurmctld\n */\nstatic slurm_nrt_nodeinfo_t *\n_alloc_node(slurm_nrt_libstate_t *lp, char *name)\n{\n\tslurm_nrt_nodeinfo_t *n = NULL;\n\tint new_bufsize;\n\tbool need_hash_rebuild = false;\n\n\txassert(lp);\n\n\tif (name != NULL) {\n\t\tn = _find_node(lp, name);\n\t\tif (n != NULL)\n\t\t\treturn n;\n\t}\n\n\tnrt_need_state_save = true;\n\n\tif (lp->node_count >= lp->node_max) {\n\t\tlp->node_max += NRT_NODECOUNT;\n\t\tnew_bufsize = lp->node_max * sizeof(slurm_nrt_nodeinfo_t);\n\t\tif (lp->node_list == NULL) {\n\t\t\tlp->node_list = (slurm_nrt_nodeinfo_t *)\n\t\t\t\t\txmalloc(new_bufsize);\n\t\t} else {\n\t\t\tlp->node_list = (slurm_nrt_nodeinfo_t *)\n\t\t\t\t\txrealloc(lp->node_list, new_bufsize);\n\t\t}\n\t\tneed_hash_rebuild = true;\n\t}\n\tif (lp->node_list == NULL) {\n\t\tslurm_seterrno(ENOMEM);\n\t\treturn NULL;\n\t}\n\n\tn = lp->node_list + (lp->node_count++);\n\tn->magic = NRT_NODEINFO_MAGIC;\n\tn->name[0] = '\\0';\n\tn->adapter_list = (slurm_nrt_adapter_t *)\n\t\t\t  xmalloc(NRT_MAXADAPTERS *\n\t\t\t  sizeof(struct slurm_nrt_adapter));\n\n\tif (name != NULL) {\n\t\tstrlcpy(n->name, name, NRT_HOSTLEN);\n\t\tif (need_hash_rebuild || (lp->node_count > lp->hash_max))\n\t\t\t_hash_rebuild(lp);\n\t\telse\n\t\t\t_hash_add_nodeinfo(lp, n);\n\t}\n\n\treturn n;\n}\n\nstatic slurm_nrt_window_t *\n_find_free_window(slurm_nrt_adapter_t *adapter)\n{\n\tstatic int last_inx = 0;\n\tslurm_nrt_window_t *window;\n\tint i;\n\n\tfor (i = 0; i < adapter->window_count; i++, last_inx++) {\n\t\tif (last_inx >= adapter->window_count)\n\t\t\tlast_inx = 0;\n\t\twindow = &adapter->window_list[last_inx];\n\t\tif (window->state == NRT_WIN_AVAILABLE)\n\t\t\treturn window;\n\t}\n\n\tslurm_seterrno(ESLURM_INTERCONNECT_BUSY);\n\treturn (slurm_nrt_window_t *) NULL;\n}\n\nstatic void _table_alloc(nrt_tableinfo_t *tableinfo, int table_inx,\n\t\t\t nrt_adapter_t adapter_type)\n{\n\tint table_size;\n\n\tif (tableinfo[table_inx].table)\n\t\treturn;\n\tif (adapter_type == NRT_IB)\n\t\ttable_size = sizeof(nrt_ib_task_info_t);\n\telse if (adapter_type == NRT_HFI)\n\t\ttable_size = sizeof(nrt_hfi_task_info_t);\n\telse if (adapter_type == NRT_IPONLY)\n\t\ttable_size = sizeof(nrt_ip_task_info_t);\n#if NRT_VERSION < 1300\n\telse if ((adapter_type == NRT_HPCE) || (adapter_type == NRT_KMUX))\n\t\ttable_size = sizeof(nrt_hpce_task_info_t);\n#endif\n\telse {\n\t\terror(\"Missing support for adapter type %s\",\n\t\t      _adapter_type_str(adapter_type));\n\t\treturn;\n\t}\n\ttableinfo[table_inx].table = xmalloc(table_size *\n\t\t\t\t\t     tableinfo[table_inx].\n\t\t\t\t\t     table_length);\n\treturn;\n}\n\n/* Track RDMA or CAU resources allocated to a job on each adapter */\nstatic int\n_add_block_use(slurm_nrt_jobinfo_t *jp, slurm_nrt_adapter_t *adapter)\n{\n\tint i;\n\tslurm_nrt_block_t *block_ptr, *free_block;\n\tnrt_cau_index_t new_cau_count = 0;\n\tuint64_t new_rcontext_blocks  = 0;\n\n\t/*\n\t * Validate sufficient CAU resources\n\t *\n\t * From Bill LePera, IBM, July 14, 2012:\n\t * CAU indexes on HFI are allocated on a job-context basis.  That means\n\t * the CAU indexes are shared among tables with the same job key and\n\t * context ID.  In this scenario you would set the total number of CAU\n\t * indexes desired in the num_cau_indexs field for all the tables with\n\t * the same job key and context ID, but PNSD will only allocate that\n\t * number one time for all the tables.  For example, If job key 1234,\n\t * context ID 0 is striped across four networks, it will have four\n\t * NRTs.  If that job requests 2 CAU indexes, the num_cau_indexes field\n\t * in each NRT should be set to 2.  However, PNSD will only allocate 2\n\t * indexes for that job.\n\t */\n\tif (jp->cau_indexes) {\n\t\tif (adapter->cau_indexes_avail < jp->cau_indexes) {\n\t\t\tinfo(\"switch/nrt: Insufficient cau_indexes resources \"\n\t\t\t     \"on adapter %s (%hu < %hu)\",\n\t\t\t     adapter->adapter_name, adapter->cau_indexes_avail,\n\t\t\t     jp->cau_indexes);\n\t\t\treturn SLURM_ERROR;\n\t\t}\n\t\tnew_cau_count = adapter->cau_indexes_used + jp->cau_indexes;\n\t\tif (adapter->cau_indexes_avail < new_cau_count) {\n\t\t\tinfo(\"switch/nrt: Insufficient cau_indexes resources \"\n\t\t\t     \"available on adapter %s (%hu < %hu)\",\n\t\t\t     adapter->adapter_name, adapter->cau_indexes_avail,\n\t\t\t     new_cau_count);\n\t\t\tslurm_seterrno(ESLURM_INTERCONNECT_BUSY);\n\t\t\treturn SLURM_ERROR;\n\t\t}\n\t}\n\n\t/* Validate sufficient RDMA resources */\n\tif (jp->bulk_xfer && jp->bulk_xfer_resources) {\n\t\tif (adapter->rcontext_block_count < jp->bulk_xfer_resources) {\n\t\t\tinfo(\"switch/nrt: Insufficient bulk_xfer resources on \"\n\t\t\t     \"adapter %s (%\"PRIu64\" < %u)\",\n\t\t\t     adapter->adapter_name,\n\t\t\t     adapter->rcontext_block_count,\n\t\t\t     jp->bulk_xfer_resources);\n\t\t\treturn SLURM_ERROR;\n\t\t}\n\t\tnew_rcontext_blocks = adapter->rcontext_block_used +\n\t\t\t\t      jp->bulk_xfer_resources;\n\t\tif (adapter->rcontext_block_count < new_rcontext_blocks) {\n\t\t\tinfo(\"switch/nrt: Insufficient bulk_xfer resources \"\n\t\t\t     \"available on adapter %s (%\"PRIu64\" < %\"PRIu64\")\",\n\t\t\t     adapter->adapter_name,\n\t\t\t     adapter->rcontext_block_count,\n\t\t\t     new_rcontext_blocks);\n\t\t\tslurm_seterrno(ESLURM_INTERCONNECT_BUSY);\n\t\t\treturn SLURM_ERROR;\n\t\t}\n\t} else {\n\t\tjp->bulk_xfer_resources = 0;\t/* match jp->bulk_xfer */\n\t}\n\n\tif ((new_cau_count == 0) && (new_rcontext_blocks == 0))\n\t\treturn SLURM_SUCCESS;\t/* No work */\n\n\t/* Add job_key to our table and update the resource used information */\n\tfree_block = NULL;\n\tblock_ptr = adapter->block_list;\n\tfor (i = 0; i < adapter->block_count; i++, block_ptr++) {\n\t\tif (block_ptr->job_key == jp->job_key) {\n\t\t\tfree_block = block_ptr;\n\t\t\tbreak;\n\t\t} else if ((block_ptr->job_key == 0) && (free_block == 0)) {\n\t\t\tfree_block = block_ptr;\n\t\t}\n\t}\n\tif (free_block == NULL) {\n\t\txrealloc(adapter->block_list,\n\t\t\t sizeof(slurm_nrt_block_t) *\n\t\t\t\t (adapter->block_count + 8));\n\t\tfree_block = adapter->block_list + adapter->block_count;\n\t\tadapter->block_count += 8;\n\t}\n\n\tfree_block->job_key = jp->job_key;\n\tfree_block->rcontext_block_use = jp->bulk_xfer_resources;\n\tif (new_cau_count)\n\t\tadapter->cau_indexes_used    = new_cau_count;\n\tif (new_rcontext_blocks)\n\t\tadapter->rcontext_block_used = new_rcontext_blocks;\n\n#if 0\n\tblock_ptr = adapter->block_list;\n\tfor (i = 0; i < adapter->block_count; i++, block_ptr++) {\n\t\tif (block_ptr->job_key) {\n\t\t\tinfo(\"adapter:%s block:%d job_key:%u blocks:%u\",\n\t\t\t     adapter->adapter_name, i, block_ptr->job_key,\n\t\t\t     free_block->rcontext_block_use);\n\t\t}\n\t}\n#endif\n\treturn SLURM_SUCCESS;\n}\n\nstatic int _add_immed_use(char *hostname, slurm_nrt_jobinfo_t *jp,\n\t\t\t  slurm_nrt_adapter_t *adapter)\n{\n\tif (adapter->immed_slots_avail < jp->immed_slots) {\n\t\tinfo(\"switch/nrt: Insufficient immediate slots on \"\n\t\t     \"node %s adapter %s\",\n\t\t     hostname, adapter->adapter_name);\n\t\treturn SLURM_ERROR;\n\t}\n\n\tadapter->immed_slots_used += jp->immed_slots;\n\tif (adapter->immed_slots_avail < adapter->immed_slots_used) {\n\t\tinfo(\"switch/nrt: Insufficient immediate slots available on \"\n\t\t     \"node %s adapter %s\",\n\t\t     hostname, adapter->adapter_name);\n\t\tadapter->immed_slots_used -= jp->immed_slots;\n\t\tslurm_seterrno(ESLURM_INTERCONNECT_BUSY);\n\t\treturn SLURM_ERROR;\n\t}\n\n\treturn SLURM_SUCCESS;\n}\n\nstatic bool\n_free_block_use(slurm_nrt_jobinfo_t *jp, slurm_nrt_adapter_t *adapter)\n{\n\tslurm_nrt_block_t *block_ptr;\n\tbool found_job = false;\n\tint i;\n\n\tif ((jp->bulk_xfer && jp->bulk_xfer_resources) || jp->cau_indexes) {\n\t\tblock_ptr = adapter->block_list;\n\t\tfor (i = 0; i < adapter->block_count; i++, block_ptr++) {\n\t\t\tif (block_ptr->job_key != jp->job_key)\n\t\t\t\tcontinue;\n\n\t\t\tif (jp->cau_indexes > adapter->cau_indexes_used) {\n\t\t\t\terror(\"switch/nrt: cau_indexes_used underflow\");\n\t\t\t\tadapter->cau_indexes_used = 0;\n\t\t\t} else {\n\t\t\t\tadapter->cau_indexes_used -= jp->cau_indexes;\n\t\t\t}\n\n\t\t\tif (block_ptr->rcontext_block_use >\n\t\t\t    adapter->rcontext_block_used) {\n\t\t\t\terror(\"switch/nrt: rcontext_block_used \"\n\t\t\t\t      \"underflow\");\n\t\t\t\tadapter->rcontext_block_used = 0;\n\t\t\t} else {\n\t\t\t\tadapter->rcontext_block_used -=\n\t\t\t\t\tblock_ptr->rcontext_block_use;\n\t\t\t}\n\t\t\tblock_ptr->job_key = 0;\n\t\t\tblock_ptr->rcontext_block_use = 0;\n\t\t\tfound_job = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn found_job;\n}\n\n/* For a given process, fill out an nrt_creator_per_task_input_t\n * struct (an array of these makes up the network table loaded\n * for each job).  Assign adapters, lids and switch windows to\n * each task in a job.\n *\n * Used by: slurmctld\n */\nstatic int\n_allocate_windows_all(slurm_nrt_jobinfo_t *jp, char *hostname,\n\t\t      uint32_t node_id, nrt_task_id_t task_id,\n\t\t      nrt_adapter_t adapter_type, int network_id,\n\t\t      nrt_protocol_table_t *protocol_table, int instances,\n\t\t      int task_inx)\n{\n\tnrt_tableinfo_t *tableinfo = jp->tableinfo;\n\tnrt_job_key_t job_key = jp->job_key;\n\tbool ip_v4 = jp->ip_v4;\n\tbool user_space = jp->user_space;\n\tnrt_node_number_t node_number;\n\tslurm_nrt_nodeinfo_t *node;\n\tslurm_nrt_adapter_t *adapter;\n\tslurm_nrt_window_t *window;\n\tnrt_context_id_t context_id;\n\tnrt_table_id_t table_id;\n\tint i, j, table_inx;\n\n\txassert(tableinfo);\n\txassert(hostname);\n\n\tdebug2(\"in _allocate_windows_all\");\n\tnode = _find_node(nrt_state, hostname);\n\tif (node == NULL) {\n\t\terror(\"Failed to find node in node_list: %s\", hostname);\n\t\treturn SLURM_ERROR;\n\t}\n\n\t/* From Bill LePera, IBM, 4/18/2012:\n\t * The node_number field is normally set to the 32-bit IPv4 address\n\t * of the local node's host name. */\n\tnode_number = node->node_number;\n\n\t/* Reserve a window on each adapter for this task */\n\ttable_inx = -1;\n\tfor (context_id = 0; context_id < protocol_table->protocol_table_cnt;\n\t     context_id++) {\n\t\ttable_id = -1;\n\t\tfor (i = 0; i < node->adapter_count; i++) {\n\t\t\tadapter = &node->adapter_list[i];\n\t\t\tif ((adapter_type != NRT_MAX_ADAPTER_TYPES) &&\n\t\t\t    (adapter->adapter_type != adapter_type))\n\t\t\t\tcontinue;\n//\t\t\tif ((network_id >= 0) &&\n//\t\t\t    (adapter->network_id != network_id))\n//\t\t\t\tcontinue;\n\t\t\tif (user_space &&\n\t\t\t    (adapter->adapter_type == NRT_IPONLY))\n\t\t\t\tcontinue;\n\t\t\tif ((context_id == 0) && (task_inx == 0) &&\n\t\t\t    (_add_block_use(jp, adapter))) {\n\t\t\t\tgoto alloc_fail;\n\t\t\t}\n\t\t\tfor (j = 0; j < instances; j++) {\n\t\t\t\ttable_id++;\n\t\t\t\ttable_inx++;\n\t\t\t\tif (table_inx >= jp->tables_per_task) {\n\t\t\t\t\terror(\"switch/nrt: adapter count too \"\n\t\t\t\t\t      \"high, host=%s\", hostname);\n\t\t\t\t\tgoto alloc_fail;\n\t\t\t\t}\n\t\t\t\tif (user_space) {\n\t\t\t\t\twindow = _find_free_window(adapter);\n\t\t\t\t\tif (window == NULL) {\n\t\t\t\t\t\tinfo(\"switch/nrt: \"\n\t\t\t\t\t\t      \"No free windows on \"\n\t\t\t\t\t\t     \"node %s adapter %s\",\n\t\t\t\t\t\t     node->name,\n\t\t\t\t\t\t     adapter->adapter_name);\n\t\t\t\t\t\tgoto alloc_fail;\n\t\t\t\t\t}\n\t\t\t\t\tif (_add_immed_use(hostname, jp,\n\t\t\t\t\t\t\t   adapter))\n\t\t\t\t\t\tgoto alloc_fail;\n\t\t\t\t\twindow->state = NRT_WIN_UNAVAILABLE;\n\t\t\t\t\twindow->job_key = job_key;\n\t\t\t\t}\n\n\t\t\t\tif (!user_space) {\n\t\t\t\t\tnrt_ip_task_info_t *ip_table;\n\t\t\t\t\t_table_alloc(tableinfo, table_inx,\n\t\t\t\t\t\t     NRT_IPONLY);\n\t\t\t\t\tip_table = (nrt_ip_task_info_t *)\n\t\t\t\t\t\t   tableinfo[table_inx].table;\n\t\t\t\t\tip_table += task_id;\n\t\t\t\t\tip_table->node_number  = node_number;\n\t\t\t\t\tip_table->task_id      = task_id;\n\t\t\t\t\tif (ip_v4) {\n\t\t\t\t\t\tmemcpy(&ip_table->ip.ipv4_addr,\n\t\t\t\t\t\t       &adapter->ipv4_addr,\n\t\t\t\t\t\t       sizeof(in_addr_t));\n\t\t\t\t\t} else {\n\t\t\t\t\t\tmemcpy(&ip_table->ip.ipv6_addr,\n\t\t\t\t\t\t       &adapter->ipv6_addr,\n\t\t\t\t\t\t       sizeof(struct in6_addr));\n\t\t\t\t\t}\n\t\t\t\t} else if (adapter->adapter_type == NRT_IB) {\n\t\t\t\t\tnrt_ib_task_info_t *ib_table;\n\t\t\t\t\t_table_alloc(tableinfo, table_inx,\n\t\t\t\t\t\t     adapter->adapter_type);\n\t\t\t\t\tib_table = (nrt_ib_task_info_t *)\n\t\t\t\t\t\t   tableinfo[table_inx].table;\n\t\t\t\t\tib_table += task_id;\n\t\t\t\t\tstrlcpy(ib_table->device_name,\n\t\t\t\t\t\tadapter->adapter_name,\n\t\t\t\t\t\tNRT_MAX_DEVICENAME_SIZE);\n\t\t\t\t\tib_table->base_lid = adapter->lid;\n\t\t\t\t\tib_table->port_id  = 1;\n\t\t\t\t\tib_table->lmc      = 0;\n\t\t\t\t\tib_table->node_number = node_number;\n\t\t\t\t\tib_table->task_id  = task_id;\n\t\t\t\t\tib_table->win_id   = window->window_id;\n\t\t\t\t} else if (adapter->adapter_type == NRT_HFI) {\n\t\t\t\t\tnrt_hfi_task_info_t *hfi_table;\n\t\t\t\t\t_table_alloc(tableinfo, table_inx,\n\t\t\t\t\t\t     adapter->adapter_type);\n\t\t\t\t\thfi_table = (nrt_hfi_task_info_t *)\n\t\t\t\t\t\t    tableinfo[table_inx].table;\n\t\t\t\t\thfi_table += task_id;\n\t\t\t\t\thfi_table->lid = adapter->lid;\n\t\t\t\t\thfi_table->lpar_id = adapter->special;\n\t\t\t\t\thfi_table->task_id = task_id;\n\t\t\t\t\thfi_table->win_id = window->window_id;\n\t\t\t\t}\n#if NRT_VERSION < 1300\n\t\t\t\telse if ((adapter->adapter_type == NRT_HPCE)||\n\t\t\t\t\t   (adapter->adapter_type == NRT_KMUX)){\n\t\t\t\t\tnrt_hpce_task_info_t *hpce_table;\n\t\t\t\t\t_table_alloc(tableinfo, table_inx,\n\t\t\t\t\t\t     adapter->adapter_type);\n\t\t\t\t\thpce_table = (nrt_hpce_task_info_t *)\n\t\t\t\t\t\t     tableinfo[table_inx].table;\n\t\t\t\t\thpce_table += task_id;\n\t\t\t\t\thpce_table->node_number = node_number;\n\t\t\t\t\thpce_table->task_id = task_id;\n\t\t\t\t\thpce_table->win_id = window->window_id;\n\t\t\t\t}\n#endif\n\t\t\t\telse {\n\t\t\t\t\terror(\"switch/nrt: Missing support \"\n\t\t\t\t\t      \"for adapter type %s\",\n\t\t\t\t\t      _adapter_type_str(adapter->\n\t\t\t\t\t\t\t\tadapter_type));\n\t\t\t\t\tgoto alloc_fail;\n\t\t\t\t}\n\n\t\t\t\tstrlcpy(tableinfo[table_inx].adapter_name,\n\t\t\t\t\tadapter->adapter_name,\n\t\t\t\t\tNRT_MAX_ADAPTER_NAME_LEN);\n\t\t\t\ttableinfo[table_inx].adapter_type = adapter->\n\t\t\t\t\t\t\t\t    adapter_type;\n\t\t\t\ttableinfo[table_inx].network_id = adapter->\n\t\t\t\t\t\t\t\t  network_id;\n\t\t\t\tstrlcpy(tableinfo[table_inx].protocol_name,\n\t\t\t\t\tprotocol_table->\n\t\t\t\t\tprotocol_table[context_id].\n\t\t\t\t\tprotocol_name,\n\t\t\t\t\tNRT_MAX_PROTO_NAME_LEN);\n\t\t\t\ttableinfo[table_inx].context_id = context_id;\n\t\t\t\ttableinfo[table_inx].instance   = j + 1;\n\t\t\t\ttableinfo[table_inx].table_id   = table_id;\n\t\t\t}  /* for each table */\n\t\t}  /* for each context */\n\t}  /* for each adapter */\n\n\tif (++table_inx < jp->tables_per_task) {\n\t\t/* This node has too few adapters of this type */\n\t\terror(\"switch/nrt: adapter count too low, host=%s\", hostname);\n\t\tdrain_nodes(hostname, \"Too few switch adapters\", 0);\n\t\tgoto alloc_fail;\n\t}\n\n\treturn SLURM_SUCCESS;\n\nalloc_fail:\n\t/* Unable to allocate all necessary resources.\n\t * Free what has been allocated so far. */\n\t_free_resources_by_job(jp, hostname);\n\treturn SLURM_ERROR;\n}\n\n\n/* For a given process, fill out an nrt_creator_per_task_input_t\n * struct (an array of these makes up the network table loaded\n * for each job).  Assign a single adapter, lid and switch window to\n * a task in a job.\n *\n * Used by: slurmctld\n */\nstatic int\n_allocate_window_single(char *adapter_name, slurm_nrt_jobinfo_t *jp,\n\t\t\tchar *hostname, uint32_t node_id,\n\t\t\tnrt_task_id_t task_id, nrt_adapter_t adapter_type,\n\t\t\tint network_id, nrt_protocol_table_t *protocol_table,\n\t\t        int instances, int task_inx)\n{\n\tnrt_tableinfo_t *tableinfo = jp->tableinfo;\n\tnrt_job_key_t job_key = jp->job_key;\n\tbool ip_v4 = jp->ip_v4;\n\tbool user_space = jp->user_space;\n\tnrt_node_number_t node_number;\n\tslurm_nrt_nodeinfo_t *node;\n\tslurm_nrt_adapter_t *adapter = NULL;\n\tslurm_nrt_window_t *window;\n\tint i, table_inx;\n\tnrt_context_id_t context_id;\n\tnrt_table_id_t table_id;\n\n\txassert(tableinfo);\n\txassert(hostname);\n\n\tnode = _find_node(nrt_state, hostname);\n\tif (node == NULL) {\n\t\terror(\"switch/nrt: Failed to find node in node_list: %s\",\n\t\t      hostname);\n\t\treturn SLURM_ERROR;\n\t}\n\tif (!adapter_name)\t/* Fix CLANG false positive */\n\t\treturn SLURM_ERROR;\n\n\t/* From Bill LePera, IBM, 4/18/2012:\n\t * The node_number field is normally set to the 32-bit IPv4 address\n\t * of the local node's host name. */\n\tnode_number = node->node_number;\n\n\t/* find the adapter */\n\tfor (i = 0; i < node->adapter_count; i++) {\n\t\tdebug2(\"adapter %s at index %d\",\n\t\t       node->adapter_list[i].adapter_name, i);\n\t\tif (adapter_name) {\n\t\t\tif (!xstrcasecmp(node->adapter_list[i].adapter_name,\n\t\t\t\t\t adapter_name)) {\n\t\t\t\tadapter = &node->adapter_list[i];\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tcontinue;\n\t\t}\n\t\tif ((adapter_type != NRT_MAX_ADAPTER_TYPES) &&\n\t\t    (node->adapter_list[i].adapter_type == adapter_type)) {\n\t\t\tadapter = &node->adapter_list[i];\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (adapter == NULL) {\n\t\tinfo(\"switch/nrt: Failed to find adapter %s of type %s on \"\n\t\t     \"node %s\",\n\t\t     adapter_name, _adapter_type_str(adapter_type), hostname);\n\t\treturn SLURM_ERROR;\n\t}\n\n\ttable_inx = -1;\n\tfor (context_id = 0; context_id < protocol_table->protocol_table_cnt;\n\t     context_id++) {\n\t\tif ((context_id == 0) && (task_inx == 0) &&\n\t\t    (_add_block_use(jp, adapter))) {\n\t\t\tgoto alloc_fail;\n\t\t}\n\t\tfor (table_id = 0; table_id < instances; table_id++) {\n\t\t\ttable_inx++;\n\t\t\tif (user_space) {\n\t\t\t\t/* Reserve a window on the adapter for task */\n\t\t\t\twindow = _find_free_window(adapter);\n\t\t\t\tif (window == NULL) {\n\t\t\t\t\tinfo(\"switch/nrt: No free windows \"\n\t\t\t\t\t     \"on node %s adapter %s\",\n\t\t\t\t\t     node->name,\n\t\t\t\t\t     adapter->adapter_name);\n\t\t\t\t\tgoto alloc_fail;\n\t\t\t\t}\n\t\t\t\tif (_add_immed_use(hostname, jp, adapter))\n\t\t\t\t\tgoto alloc_fail;\n\t\t\t\twindow->state = NRT_WIN_UNAVAILABLE;\n\t\t\t\twindow->job_key = job_key;\n\t\t\t}\n\n\t\t\tif (!user_space) {\n\t\t\t\tnrt_ip_task_info_t *ip_table;\n\t\t\t\t_table_alloc(tableinfo, table_inx, NRT_IPONLY);\n\t\t\t\tip_table = (nrt_ip_task_info_t *)\n\t\t\t\t\t   tableinfo[table_inx].table;\n\t\t\t\tip_table += task_id;\n\t\t\t\tip_table->node_number  = node_number;\n\t\t\t\tip_table->task_id      = task_id;\n\t\t\t\tif (ip_v4) {\n\t\t\t\t\tmemcpy(&ip_table->ip.ipv4_addr,\n\t\t\t\t\t       &adapter->ipv4_addr,\n\t\t\t\t\t       sizeof(in_addr_t));\n\t\t\t\t} else {\n\t\t\t\t\tmemcpy(&ip_table->ip.ipv6_addr,\n\t\t\t\t\t       &adapter->ipv6_addr,\n\t\t\t\t\t       sizeof(struct in6_addr));\n\t\t\t\t}\n\t\t\t} else if (adapter_type == NRT_IB) {\n\t\t\t\tnrt_ib_task_info_t *ib_table;\n\t\t\t\t_table_alloc(tableinfo, table_inx,\n\t\t\t\t\t     adapter_type);\n\t\t\t\tib_table = (nrt_ib_task_info_t *)\n\t\t\t\t\t   tableinfo[table_inx].table;\n\t\t\t\tib_table += task_id;\n\t\t\t\tstrlcpy(ib_table->device_name, adapter_name,\n\t\t\t\t\tNRT_MAX_DEVICENAME_SIZE);\n\t\t\t\tib_table->base_lid = adapter->lid;\n\t\t\t\tib_table->port_id  = 1;\n\t\t\t\tib_table->lmc      = 0;\n\t\t\t\tib_table->node_number = node_number;\n\t\t\t\tib_table->task_id  = task_id;\n\t\t\t\tib_table->win_id   = window->window_id;\n\t\t\t} else if (adapter_type == NRT_HFI) {\n\t\t\t\tnrt_hfi_task_info_t *hfi_table;\n\t\t\t\t_table_alloc(tableinfo, table_inx,\n\t\t\t\t\t     adapter_type);\n\t\t\t\thfi_table = (nrt_hfi_task_info_t *)\n\t\t\t\t\t    tableinfo[table_inx].table;\n\t\t\t\thfi_table += task_id;\n\t\t\t\thfi_table->lid = adapter->lid;\n\t\t\t\thfi_table->lpar_id = adapter->special;\n\t\t\t\thfi_table->task_id = task_id;\n\t\t\t\thfi_table->win_id = window->window_id;\n\t\t\t}\n#if NRT_VERSION < 1300\n\t\t\telse if ((adapter_type == NRT_HPCE) ||\n\t\t\t\t   (adapter_type == NRT_KMUX)) {\n\t\t\t\tnrt_hpce_task_info_t *hpce_table;\n\t\t\t\t_table_alloc(tableinfo, table_inx,\n\t\t\t\t\t     adapter_type);\n\t\t\t\thpce_table = (nrt_hpce_task_info_t *)\n\t\t\t\t\t     tableinfo[table_inx].table;\n\t\t\t\thpce_table += task_id;\n\t\t\t\thpce_table->task_id = task_id;\n\t\t\t\thpce_table->win_id = window->window_id;\n\t\t\t}\n#endif\n\t\t\telse {\n\t\t\t\terror(\"Missing support for adapter type %s\",\n\t\t\t\t      _adapter_type_str(adapter_type));\n\t\t\t\tgoto alloc_fail;\n\t\t\t}\n\n\t\t\tstrlcpy(tableinfo[table_inx].adapter_name, adapter_name,\n\t\t\t\tNRT_MAX_ADAPTER_NAME_LEN);\n\t\t\ttableinfo[table_inx].adapter_type = adapter->\n\t\t\t\t\t\t\t    adapter_type;\n\t\t\ttableinfo[table_inx].network_id = adapter->network_id;\n\t\t\tstrlcpy(tableinfo[table_inx].protocol_name,\n\t\t\t\tprotocol_table->protocol_table[context_id].\n\t\t\t\tprotocol_name,\n\t\t\t\tNRT_MAX_PROTO_NAME_LEN);\n\t\t\ttableinfo[table_inx].context_id = context_id;\n\t\t\ttableinfo[table_inx].instance   = table_id + 1;\n\t\t\ttableinfo[table_inx].table_id   = table_id;\n\t\t}  /* for each table */\n\t}  /* for each context */\n\n\treturn SLURM_SUCCESS;\n\nalloc_fail:\n\t/* Unable to allocate all necessary resources.\n\t * Free what has been allocated so far. */\n\t_free_resources_by_job(jp, hostname);\n\treturn SLURM_ERROR;\n}\n\nstatic char *\n_win_state_str(win_state_t state)\n{\n\tif (state == NRT_WIN_UNAVAILABLE)\n\t\treturn \"Unavailable\";\n\telse if (state == NRT_WIN_INVALID)\n\t\treturn \"Invalid\";\n\telse if (state == NRT_WIN_AVAILABLE)\n\t\treturn \"Available\";\n\telse if (state == NRT_WIN_RESERVED)\n\t\treturn \"Reserved\";\n\telse if (state == NRT_WIN_READY)\n\t\treturn \"Ready\";\n\telse if (state == NRT_WIN_RUNNING)\n\t\treturn \"Running\";\n\telse {\n\t\tstatic char buf[16];\n\t\tsnprintf(buf, sizeof(buf), \"%d\", state);\n\t\treturn buf;\n\t}\n}\n\nstatic char *\n_adapter_type_str(nrt_adapter_t type)\n{\n\tstatic char buf[10];\n\n\tswitch (type) {\n\tcase NRT_IB:\n\t\treturn \"IB\";\n\tcase NRT_HFI:\n\t\treturn \"HFI\";\n\tcase NRT_IPONLY:\n\t\treturn \"IP_ONLY\";\n#if NRT_VERSION < 1300\n\tcase NRT_HPCE:\n\t\treturn \"HPC_Ethernet\";\n\tcase NRT_KMUX:\n\t\treturn \"Kernel_Emulated_HPCE\";\n#endif\n\tdefault:\n\t\tsnprintf(buf, sizeof(buf), \"%d\", type);\n\t\treturn buf;\n\t}\n\n\treturn NULL;\t/* Never used */\n}\n\nstatic char *\n_port_status_str(nrt_port_status_t status)\n{\n\tif (status == 0)\n\t\treturn \"Down\";\n\telse if (status == 1)\n\t\treturn \"Up\";\n\telse if (status == 2)\n\t\treturn \"Unconfig\";\n\telse {\n\t\tstatic char buf[16];\n\t\tsnprintf(buf, sizeof(buf), \"%d\", status);\n\t\treturn buf;\n\t}\n}\n\n/* Used by: slurmd */\nstatic void\n_print_adapter_info(nrt_adapter_info_t *adapter_info)\n{\n\tchar addr_v4_str[128], addr_v6_str[128];\n\tint i;\n\n\tif (!adapter_info) {\n\t\terror(\"_print_adapter_info with NULL adapter_info\");\n\t\treturn;\n\t}\n\n\tinfo(\"--Begin Adapter Info--\");\n\tinfo(\"  adapter_name: %s\", adapter_info->adapter_name);\n\tinfo(\"  adapter_type: %s\",\n\t     _adapter_type_str(adapter_info->adapter_type));\n\tinfo(\"  cau_indexes_avail: %hu\", adapter_info->cau_indexes_avail);\n\tinfo(\"  immed_slots_avail: %hu\", adapter_info->immed_slots_avail);\n\tinet_ntop(AF_INET, &adapter_info->node_number,\n\t\t  addr_v4_str, sizeof(addr_v4_str));\n\tinfo(\"  node_number: %s\", addr_v4_str);\n\tinfo(\"  num_ports: %hu\", adapter_info->num_ports);\n\tinfo(\"  rcontext_block_count: %\"PRIu64\"\",\n\t     adapter_info->rcontext_block_count);\n\tinfo(\"  window_count: %hu\", adapter_info->window_count);\n\tfor (i = 0; i < adapter_info->num_ports; i++) {\n\t\tinet_ntop(AF_INET,\n\t\t\t  &adapter_info->port[i].ipv4_addr,\n\t\t\t  addr_v4_str, sizeof(addr_v4_str));\n\t\tinet_ntop(AF_INET6,\n\t\t\t  &adapter_info->port[i].ipv6_addr,\n\t\t\t  addr_v6_str, sizeof(addr_v6_str));\n\t\tinfo(\"    port_id:%hu status:%s lid:%u \"\n\t\t     \"network_id:%lu special:%lu \"\n\t\t     \"ipv4_addr:%s ipv6_addr:%s/%hu\",\n\t\t     adapter_info->port[i].port_id,\n\t\t     _port_status_str(adapter_info->port[i].status),\n\t\t     adapter_info->port[i].lid,\n\t\t     adapter_info->port[i].network_id,\n\t\t     adapter_info->port[i].special,\n\t\t     addr_v4_str, addr_v6_str,\n\t\t     adapter_info->port[i].ipv6_prefix_len);\n\t}\n#if 0\n\t/* This always seems to count up from 0 to window_count-1 */\n\tfor (i = 0; i < adapter_info->window_count; i++)\n\t\tinfo(\"    window_id: %u\", adapter_info->window_list[i]);\n#endif\n\tinfo(\"--End Adapter Info--\");\n}\n\n/* Used by: slurmd */\nstatic void\n_print_adapter_status(nrt_cmd_status_adapter_t *status_adapter)\n{\n\tint i;\n\tnrt_window_id_t window_cnt;\n\tnrt_status_t *status = *(status_adapter->status_array);\n\tchar window_str[128];\n\thostset_t hs;\n\n\ths = hostset_create(\"\");\n\tinfo(\"--Begin Adapter Status--\");\n\tinfo(\"  adapter_name: %s\", status_adapter->adapter_name);\n\tinfo(\"  adapter_type: %s\",\n\t     _adapter_type_str(status_adapter->adapter_type));\n\twindow_cnt = *(status_adapter->window_count);\n\tinfo(\"  window_count: %hu\", window_cnt);\n\tinfo(\"  --------\");\n\tfor (i = 0; i < window_cnt; i++) {\n\t\tif ((status[i].state == NRT_WIN_AVAILABLE) &&\n\t\t    (i >= NRT_DEBUG_CNT)) {\n\t\t\tsnprintf(window_str, sizeof(window_str), \"%d\",\n\t\t\t\t status[i].window_id);\n\t\t\thostset_insert(hs, window_str);\n\t\t\tcontinue;\n\t\t}\n\t\tinfo(\"  window_id: %hu\", status[i].window_id);\n\t\tinfo(\"  state: %s\", _win_state_str(status[i].state));\n\t\tif (status[i].state >= NRT_WIN_RESERVED) {\n\t\t\tinfo(\"  bulk_xfer: %hu\", status[i].bulk_transfer);\n\t\t\tinfo(\"  client_pid: %u\",\n\t\t\t     (uint32_t)status[i].client_pid);\n\t\t\tinfo(\"  rcontext_blocks: %u\",\n\t\t\t     status[i].rcontext_blocks);\n\t\t\tinfo(\"  uid: %u\", (uint32_t) status[i].uid);\n\t\t}\n\t\tinfo(\"  --------\");\n\t}\n\tif (hostset_count(hs) > 0) {\n\t\thostset_ranged_string(hs, sizeof(window_str), window_str);\n\t\tinfo(\"  suppress data for available windows %s\", window_str);\n\t\tinfo(\"  --------\");\n\t}\n\tinfo(\"--End Adapter Status--\");\n\thostset_destroy(hs);\n}\n\n/* Used by: slurmd, slurmctld */\nstatic void\n_print_nodeinfo(slurm_nrt_nodeinfo_t *n)\n{\n\tint i, j;\n\tslurm_nrt_adapter_t *a;\n\tslurm_nrt_window_t *w;\n\tchar addr_str[128];\n\tchar window_str[128];\n\thostset_t hs;\n\n\txassert(n);\n\txassert(n->magic == NRT_NODEINFO_MAGIC);\n\n\tinfo(\"--Begin Node Info--\");\n\tinfo(\"  node: %s\", n->name);\n\tinet_ntop(AF_INET, &n->node_number, addr_str,sizeof(addr_str));\n\tinfo(\"  node_number: %s\", addr_str);\n\tinfo(\"  adapter_count: %u\", n->adapter_count);\n\tfor (i = 0; i < n->adapter_count; i++) {\n\t\ta = n->adapter_list + i;\n\t\tinfo(\"  adapter_name: %s\", a->adapter_name);\n\t\tinfo(\"    adapter_type: %s\",\n\t\t     _adapter_type_str(a->adapter_type));\n\t\tinfo(\"    cau_indexes_avail: %hu\", a->cau_indexes_avail);\n\t\tif (a->cau_indexes_used) {\n\t\t\t/* This information is only available in Power7-IH\n\t\t\t * and only in slurmctld's data structure */\n\t\t\tinfo(\"    cau_indexes_used:  %hu\",a->cau_indexes_used);\n\t\t}\n\t\tinfo(\"    immed_slots_avail: %hu\", a->immed_slots_avail);\n\t\tif (a->immed_slots_used) {\n\t\t\t/* This information is only available in Power7-IH\n\t\t\t * and only in slurmctld's data structure */\n\t\t\tinfo(\"    immed_slots_used:  %hu\",a->immed_slots_used);\n\t\t}\n\t\tinet_ntop(AF_INET, &a->ipv4_addr, addr_str, sizeof(addr_str));\n\t\tinfo(\"    ipv4_addr: %s\", addr_str);\n\t\tinet_ntop(AF_INET6, &a->ipv6_addr, addr_str, sizeof(addr_str));\n\t\tinfo(\"    ipv6_addr: %s\", addr_str);\n\t\tinfo(\"    lid: %u\", a->lid);\n\t\tinfo(\"    network_id: %lu\", a->network_id);\n\n\t\tinfo(\"    port_id: %hu\", a->port_id);\n\t\tinfo(\"    rcontext_block_count: %\"PRIu64\"\",\n\t\t     a->rcontext_block_count);\n\t\tinfo(\"    rcontext_block_used:  %\"PRIu64\"\",\n\t\t     a->rcontext_block_used);\n\t\tinfo(\"    special: %lu\", a->special);\n\n\t\tinfo(\"    window_count: %hu\", a->window_count);\n\t\ths = hostset_create(\"\");\n\t\tw = a->window_list;\n\t\tfor (j = 0; j < a->window_count; j++) {\n\t\t\tif ((w[j].state == NRT_WIN_AVAILABLE) &&\n\t\t\t    (j >= NRT_DEBUG_CNT)) {\n\t\t\t\tsnprintf(window_str, sizeof(window_str), \"%d\",\n\t\t\t\t\t w[j].window_id);\n\t\t\t\thostset_insert(hs, window_str);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tinfo(\"      window:%hu state:%s job_key:%u\",\n\t\t\t     w[j].window_id, _win_state_str(w[j].state),\n\t\t\t     w[j].job_key);\n\t\t}\n\t\tif (hostset_count(hs) > 0) {\n\t\t\thostset_ranged_string(hs, sizeof(window_str),\n\t\t\t\t\t      window_str);\n\t\t\tinfo(\"      suppress data for available windows %s\",\n\t\t\t     window_str);\n\t\t\tinfo(\"      -------- \");\n\t\t}\n\t\thostset_destroy(hs);\n\n\t\tinfo(\"    block_count: %hu\", a->block_count);\n\t\tfor (j = 0; j < a->block_count; j++) {\n\t\t\tif (a->block_list[j].job_key) {\n\t\t\t\tinfo(\"      job_key[%d]: %u\",\n\t\t\t\t     j, a->block_list[j].job_key);\n\t\t\t}\n\t\t}\n\t}\n\tinfo(\"--End Node Info--\");\n}\n\n/* Used by: slurmctld */\nstatic void\n_print_libstate(const slurm_nrt_libstate_t *l)\n{\n\tint i;\n\n\txassert(l);\n\txassert(l->magic == NRT_LIBSTATE_MAGIC);\n\n\tinfo(\"--Begin libstate--\");\n\tinfo(\"  node_count = %u\", l->node_count);\n\tinfo(\"  node_max = %u\", l->node_max);\n\tinfo(\"  hash_max = %u\", l->hash_max);\n\tinfo(\"  key_index = %u\", l->key_index);\n\tfor (i = 0; i < l->node_count; i++) {\n\t\t_print_nodeinfo(&l->node_list[i]);\n\t}\n\tinfo(\"--End libstate--\");\n}\n/* Used by: all */\nstatic void\n_print_table(void *table, int size, nrt_adapter_t adapter_type, bool ip_v4)\n{\n\tchar addr_str[128];\n\tint i;\n\n\txassert(table);\n\txassert(size > 0);\n\n\tinfo(\"--Begin NRT table--\");\n\tfor (i = 0; i < size; i++) {\n\t\tif (adapter_type == NRT_IB) {\n\t\t\tnrt_ib_task_info_t *ib_tbl_ptr;\n\t\t\tib_tbl_ptr = table;\n\t\t\tib_tbl_ptr += i;\n\t\t\tinfo(\"  task_id: %u\", ib_tbl_ptr->task_id);\n\t\t\tinfo(\"  win_id: %hu\", ib_tbl_ptr->win_id);\n\t\t\tinet_ntop(AF_INET, &ib_tbl_ptr->node_number, addr_str,\n\t\t\t\t  sizeof(addr_str));\n\t\t\tinfo(\"  node_number: %s\", addr_str);\n/*\t\t\tinfo(\"  node_number: %u\", ib_tbl_ptr->node_number); */\n\t\t\tinfo(\"  device_name: %s\", ib_tbl_ptr->device_name);\n\t\t\tinfo(\"  base_lid: %u\", ib_tbl_ptr->base_lid);\n\t\t\tinfo(\"  port_id: %hu\", ib_tbl_ptr->port_id);\n\t\t\tinfo(\"  lmc: %hu\", ib_tbl_ptr->lmc);\n\t\t\tinfo(\"  port_status: %hu\", ib_tbl_ptr->port_status);\n\t\t} else if (adapter_type == NRT_HFI) {\n\t\t\tnrt_hfi_task_info_t *hfi_tbl_ptr;\n\t\t\thfi_tbl_ptr = table;\n\t\t\thfi_tbl_ptr += i;\n\t\t\tinfo(\"  task_id: %u\", hfi_tbl_ptr->task_id);\n\t\t\tinfo(\"  lpar_id: %u\", hfi_tbl_ptr->lpar_id);\n\t\t\tinfo(\"  lid: %u\", hfi_tbl_ptr->lid);\n\t\t\tinfo(\"  win_id: %hu\", hfi_tbl_ptr->win_id);\n\t\t}\n#if NRT_VERSION < 1300\n\t\telse if ((adapter_type == NRT_HPCE) ||\n\t\t           (adapter_type == NRT_KMUX)) {\n\t\t\tnrt_hpce_task_info_t *hpce_tbl_ptr;\n\t\t\thpce_tbl_ptr = table;\n\t\t\thpce_tbl_ptr += i;\n\t\t\tinfo(\"  task_id: %u\", hpce_tbl_ptr->task_id);\n\t\t\tinfo(\"  win_id: %hu\", hpce_tbl_ptr->win_id);\n\t\t\tinet_ntop(AF_INET, &hpce_tbl_ptr->node_number,\n\t\t\t\t  addr_str, sizeof(addr_str));\n\t\t\tinfo(\"  node_number: %s\", addr_str);\n/*\t\t\tinfo(\"  node_number: %u\", hpce_tbl_ptr->node_number); */\n\t\t\tinfo(\"  device_name: %s\", hpce_tbl_ptr->device_name);\n\t\t}\n#endif\n\t\telse if (adapter_type == NRT_IPONLY) {\n\t\t\tnrt_ip_task_info_t *ip_tbl_ptr;\n\t\t\tchar addr_str[128];\n\t\t\tip_tbl_ptr = table;\n\t\t\tip_tbl_ptr += i;\n\t\t\tinfo(\"  task_id: %u\", ip_tbl_ptr->task_id);\n\t\t\tinet_ntop(AF_INET, &ip_tbl_ptr->node_number, addr_str,\n\t\t\t\t  sizeof(addr_str));\n\t\t\tinfo(\"  node_number: %s\", addr_str);\n/*\t\t\tinfo(\"  node_number: %u\", ip_tbl_ptr->node_number); */\n\t\t\tif (ip_v4) {\n\t\t\t\tinet_ntop(AF_INET, &ip_tbl_ptr->ip.ipv4_addr,\n\t\t\t\t\t  addr_str, sizeof(addr_str));\n\t\t\t\tinfo(\"  ipv4_addr: %s\", addr_str);\n\t\t\t} else {\n\t\t\t\tinet_ntop(AF_INET6, &ip_tbl_ptr->ip.ipv6_addr,\n\t\t\t\t\t  addr_str, sizeof(addr_str));\n\t\t\t\tinfo(\"  ipv6_addr: %s\", addr_str);\n\t\t\t}\n\t\t} else {\n\t\t\terror(\"Unsupported adapter_type: %s\",\n\t\t\t      _adapter_type_str(adapter_type));\n\t\t}\n\t\tinfo(\"  ------\");\n\t}\n\tinfo(\"--End NRT table--\");\n}\n\n/* Used by: slurmd, slurmctld */\nstatic void\n_print_jobinfo(slurm_nrt_jobinfo_t *j)\n{\n\tint i;\n\tchar buf[128];\n\tnrt_adapter_t adapter_type;\n\n\tif ((j == NULL) || (j->magic == NRT_NULL_MAGIC)) {\n\t\tdebug2(\"(%s: %d: %s) job->switch_job was NULL\",\n\t\t       THIS_FILE, __LINE__, __func__);\n\t\treturn;\n\t}\n\n\txassert(j->magic == NRT_JOBINFO_MAGIC);\n\n\tinfo(\"--Begin Jobinfo--\");\n\tinfo(\"  job_key: %u\", j->job_key);\n\tinfo(\"  bulk_xfer: %hu\", j->bulk_xfer);\n\tinfo(\"  bulk_xfer_resources: %u\", j->bulk_xfer_resources);\n\tinfo(\"  cau_indexes: %hu\", j->cau_indexes);\n\tinfo(\"  immed_slots: %hu\", j->immed_slots);\n\tinfo(\"  ip_v4: %hu\", j->ip_v4);\n\tinfo(\"  user_space: %hu\", j->user_space);\n\tinfo(\"  tables_per_task: %hu\", j->tables_per_task);\n\tif (j->nodenames)\n\t\thostlist_ranged_string(j->nodenames, sizeof(buf), buf);\n\telse\n\t\tstrcpy(buf, \"(NULL)\");\n\tinfo(\"  nodenames: %s (slurmctld internal use only)\", buf);\n\tinfo(\"  num_tasks: %d\", j->num_tasks);\n\tfor (i = 0; i < j->tables_per_task; i++) {\n\t\tinfo(\"--Header NRT table--\");\n\t\tinfo(\"  adapter_name: %s\", j->tableinfo[i].adapter_name);\n\t\tinfo(\"  adapter_type: %s\",\n\t\t     _adapter_type_str(j->tableinfo[i].adapter_type));\n\t\tinfo(\"  context_id: %u\", j->tableinfo[i].context_id);\n\t\tinfo(\"  instance: %u\", j->tableinfo[i].instance);\n\t\tinfo(\"  network_id: %lu\", j->tableinfo[i].network_id);\n\t\tinfo(\"  protocol_name: %s\", j->tableinfo[i].protocol_name);\n\t\tinfo(\"  table_id: %u\", j->tableinfo[i].table_id);\n\t\tif (j->user_space)\n\t\t\tadapter_type = j->tableinfo[i].adapter_type;\n\t\telse\n\t\t\tadapter_type = NRT_IPONLY;\n\t\t_print_table(j->tableinfo[i].table,\n\t\t\t     j->tableinfo[i].table_length, adapter_type,\n\t\t\t     j->ip_v4);\n\t}\n\tinfo(\"--End Jobinfo--\");\n}\n\nstatic void\n_print_load_table(nrt_cmd_load_table_t *load_table)\n{\n\tnrt_table_info_t *table_info = load_table->table_info;\n\tnrt_adapter_t adapter_type;\n\n\tinfo(\"--- Begin load table ---\");\n\tinfo(\"  num_tasks: %u\", table_info->num_tasks);\n\tinfo(\"  job_key: %u\", table_info->job_key);\n\tinfo(\"  uid: %u\", (uint32_t)table_info->uid);\n\tinfo(\"  pid: %u\", (uint32_t)table_info->pid);\n\tinfo(\"  network_id: %lu\", table_info->network_id);\n\tinfo(\"  adapter_type: %s\",_adapter_type_str(table_info->adapter_type));\n\tinfo(\"  is_user_space: %d\", (int)table_info->is_user_space);\n\tinfo(\"  is_ipv4: %hu\", (int)table_info->is_ipv4);\n\tinfo(\"  context_id: %u\", table_info->context_id);\n\tinfo(\"  table_id: %u\", table_info->table_id);\n\tinfo(\"  job_name: %s\", table_info->job_name);\n\tinfo(\"  protocol_name: %s\", table_info->protocol_name);\n\tinfo(\"  use_bulk_transfer: %hu\", (int)table_info->use_bulk_transfer);\n\tinfo(\"  bulk_transfer_resources: %u\",\n\t     table_info->bulk_transfer_resources);\n\tinfo(\"  immed_send_slots_per_win: %u\",\n\t     table_info->immed_send_slots_per_win);\n\tinfo(\"  num_cau_indexes: %u\", table_info->num_cau_indexes);\n\tif (table_info->is_user_space)\n\t\tadapter_type = table_info->adapter_type;\n\telse\n\t\tadapter_type = NRT_IPONLY;\n\t_print_table(load_table->per_task_input, table_info->num_tasks,\n\t\t     adapter_type, table_info->is_ipv4);\n\tinfo(\"--- End load table ---\");\n}\n\nstatic slurm_nrt_libstate_t *\n_alloc_libstate(void)\n{\n\tslurm_nrt_libstate_t *tmp;\n\n\ttmp = (slurm_nrt_libstate_t *) xmalloc(sizeof(slurm_nrt_libstate_t));\n\ttmp->magic = NRT_LIBSTATE_MAGIC;\n\ttmp->node_count = 0;\n\ttmp->node_max = 0;\n\ttmp->node_list = NULL;\n\ttmp->hash_max = 0;\n\ttmp->hash_table = NULL;\n\t/* Start key from random point, old key values are cached,\n\t * which seems to prevent re-use for a while */\n\ttmp->key_index = (nrt_job_key_t) time(NULL);\n\n\treturn tmp;\n}\n\n/* Allocate and initialize memory for the persistent libstate.\n *\n * Used by: slurmctld\n */\nextern int\nnrt_init(void)\n{\n\tslurm_nrt_libstate_t *tmp;\n\n\ttmp = _alloc_libstate();\n\tslurm_mutex_lock(&global_lock);\n\txassert(!nrt_state);\n\tnrt_state = tmp;\n\tslurm_mutex_unlock(&global_lock);\n\n\treturn SLURM_SUCCESS;\n}\n\nextern int\nnrt_slurmctld_init(void)\n{\n\t/* No op */\n\treturn SLURM_SUCCESS;\n}\n\nextern int\nnrt_slurmd_init(void)\n{\n\t/*\n\t * This is a work-around for the nrt_* functions calling umask(0)\n\t */\n\tnrt_umask = umask(0077);\n\tumask(nrt_umask);\n\n\treturn SLURM_SUCCESS;\n}\n\nextern int\nnrt_slurmd_step_init(void)\n{\n\t/*\n\t * This is a work-around for the nrt_* functions calling umask(0)\n\t */\n\tnrt_umask = umask(0077);\n\tumask(nrt_umask);\n\n\t_init_adapter_cache();\n\t_fill_in_adapter_cache();\n\n\treturn SLURM_SUCCESS;\n}\n\n/* Used by: slurmd, slurmctld */\nextern int\nnrt_alloc_jobinfo(slurm_nrt_jobinfo_t **j)\n{\n\tslurm_nrt_jobinfo_t *new;\n\n\txassert(j != NULL);\n\tnew = (slurm_nrt_jobinfo_t *) xmalloc(sizeof(slurm_nrt_jobinfo_t));\n\tnew->magic = NRT_JOBINFO_MAGIC;\n\tnew->job_key = (nrt_job_key_t) -1;\n\t*j = new;\n\n\treturn 0;\n}\n\n/* Used by: slurmd, slurmctld */\nextern int\nnrt_alloc_nodeinfo(slurm_nrt_nodeinfo_t **n)\n{\n\tslurm_nrt_nodeinfo_t *new;\n\n\txassert(n);\n\n\tnew = (slurm_nrt_nodeinfo_t *) xmalloc(sizeof(slurm_nrt_nodeinfo_t));\n\tnew->adapter_list = (slurm_nrt_adapter_t *)\n\t\t\t    xmalloc(sizeof(slurm_nrt_adapter_t) *\n\t\t\t    NRT_MAX_ADAPTER_TYPES * NRT_MAX_ADAPTERS_PER_TYPE);\n\tnew->magic = NRT_NODEINFO_MAGIC;\n\tnew->adapter_count = 0;\n\tnew->next = NULL;\n\n\t*n = new;\n\n\treturn 0;\n}\n\nstatic int _get_my_id(void)\n{\n\tint err, i, j, k, rc = SLURM_SUCCESS;\n\tnrt_cmd_query_adapter_types_t adapter_types;\n\tunsigned int num_adapter_types;\n\tnrt_adapter_t adapter_type[NRT_MAX_ADAPTER_TYPES];\n\tnrt_cmd_query_adapter_names_t adapter_names;\n\tunsigned int max_windows, num_adapter_names;\n\tnrt_cmd_query_adapter_info_t query_adapter_info;\n\tnrt_adapter_info_t adapter_info;\n\tnrt_status_t *status_array = NULL;\n\n\tadapter_types.num_adapter_types = &num_adapter_types;\n\tadapter_types.adapter_types = adapter_type;\n\tadapter_info.window_list = NULL;\n\tfor (i = 0; i < 2; i++) {\n\t\terr = nrt_cmd_wrap(NRT_VERSION, NRT_CMD_QUERY_ADAPTER_TYPES,\n\t\t\t\t   &adapter_types);\n\t\tif (err != NRT_EAGAIN)\n\t\t\tbreak;\n\t\tusleep(1000);\n\t}\n\tif (err != NRT_SUCCESS) {\n\t\terror(\"nrt_cmd_wrap(adapter_types): %s\", nrt_err_str(err));\n\t\treturn SLURM_ERROR;\n\t}\n\n\tfor (i = 0; i < num_adapter_types; i++) {\n\t\tadapter_names.adapter_type = adapter_type[i];\n\t\tadapter_names.num_adapter_names = &num_adapter_names;\n\t\tadapter_names.max_windows = &max_windows;\n\t\terr = nrt_cmd_wrap(NRT_VERSION, NRT_CMD_QUERY_ADAPTER_NAMES,\n\t\t\t\t  &adapter_names);\n\t\tif (err != NRT_SUCCESS) {\n\t\t\terror(\"nrt_cmd_wrap(adapter_names, %s): %s\",\n\t\t\t      _adapter_type_str(adapter_names.adapter_type),\n\t\t\t      nrt_err_str(err));\n\t\t\trc = SLURM_ERROR;\n\t\t\tcontinue;\n\t\t}\n\t\tfor (j = 0; j < num_adapter_names; j++) {\n\t\t\tif (my_network_id_set && my_lpar_id_set)\n\t\t\t\tbreak;\n\t\t\tif (my_network_id_set &&\n\t\t\t    (adapter_names.adapter_type != NRT_HFI))\n\t\t\t\tcontinue;\n\t\t\tquery_adapter_info.adapter_name = adapter_names.\n\t\t\t\t\t\t\t  adapter_names[j];\n\t\t\tquery_adapter_info.adapter_type = adapter_names.\n\t\t\t\t\t\t\t  adapter_type;\n\t\t\tquery_adapter_info.adapter_info = &adapter_info;\n\t\t\tadapter_info.window_list = xmalloc(max_windows *\n\t\t\t\t\t\t   sizeof(nrt_window_id_t));\n\t\t\terr = nrt_cmd_wrap(NRT_VERSION,\n\t\t\t\t\t   NRT_CMD_QUERY_ADAPTER_INFO,\n\t\t\t\t\t   &query_adapter_info);\n\t\t\tif (err != NRT_SUCCESS) {\n\t\t\t\terror(\"nrt_cmd_wrap(adapter_into, %s, %s): %s\",\n\t\t\t\t      query_adapter_info.adapter_name,\n\t\t\t\t      _adapter_type_str(query_adapter_info.\n\t\t\t\t\t\t\tadapter_type),\n\t\t\t\t      nrt_err_str(err));\n\t\t\t\trc = SLURM_ERROR;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (!my_network_id_set &&\n\t\t\t    (adapter_info.node_number != 0)) {\n\t\t\t\tmy_network_id  = adapter_info.node_number;\n\t\t\t\tmy_network_id_set = true;\n\t\t\t}\n\t\t\tif (my_lpar_id_set ||\n\t\t\t    (adapter_names.adapter_type != NRT_HFI))\n\t\t\t\tcontinue;\n\t\t\tfor (k = 0; k < adapter_info.num_ports; k++) {\n\t\t\t\tif (adapter_info.port[k].status != 1)\n\t\t\t\t\tcontinue;\n\t\t\t\tmy_lpar_id = adapter_info.port[k].special;\n\t\t\t\tmy_lid = adapter_info.port[k].lid;\n\t\t\t\tmy_lpar_id_set = true;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\txfree(adapter_info.window_list);\n\t}\n\tif (status_array)\n\t\tfree(status_array);\n\n\treturn rc;\n}\n\n/* Load the minimum usable window ID on a given adapater.\n *\n * NOTES: Bill LePera, IBM: Out of 256 windows on each HFI device, the first\n * 4 are reserved for the HFI device driver's use. Next are the dynamic windows\n * (default 32), followed by the windows available to be scheduled by PNSD\n * and the job schedulers. This is why the output of nrt_status shows the\n * first window number reported as 36. */\nstatic int\n_load_min_window_id(char *adapter_name, nrt_adapter_t adapter_type)\n{\n\tFILE *fp;\n\tchar buf[128], path[256];\n\tsize_t sz;\n\tint min_window_id = 0;\n\n\tif (adapter_type != NRT_HFI)\n\t\treturn min_window_id;\n\n\tmin_window_id = 4;\n\tsnprintf(path, sizeof(path),\n\t\t \"/sys/devices/virtual/hfi/%s/num_dynamic_win\", adapter_name);\n\tfp = fopen(path, \"r\");\n\tif (fp) {\n\t\tmemset(buf, 0, sizeof(buf));\n\t\tsz = fread(buf, 1, sizeof(buf), fp);\n\t\tif (sz) {\n\t\t\tbuf[sz] = '\\0';\n\t\t\tmin_window_id += strtol(buf, NULL, 0);\n\t\t}\n\t\t(void) fclose(fp);\n\t}\n\n\treturn min_window_id;\n}\n\nstatic int\n_get_adapters(slurm_nrt_nodeinfo_t *n)\n{\n\tint err, i, j, k, rc = SLURM_SUCCESS;\n\tnrt_cmd_query_adapter_types_t adapter_types;\n\tunsigned int num_adapter_types;\n\tnrt_adapter_t adapter_type[NRT_MAX_ADAPTER_TYPES];\n\tnrt_cmd_query_adapter_names_t adapter_names;\n\tunsigned int max_windows, num_adapter_names;\n\tnrt_cmd_status_adapter_t adapter_status;\n\tnrt_cmd_query_adapter_info_t query_adapter_info;\n\tnrt_adapter_info_t adapter_info;\n\tnrt_status_t *status_array = NULL;\n\tnrt_window_id_t window_count;\n\tint min_window_id = 0, total_adapters = 0;\n\tslurm_nrt_adapter_t *adapter_ptr;\n\n\tif (debug_flags & DEBUG_FLAG_SWITCH)\n\t\tinfo(\"_get_adapters: begin\");\n\n\tadapter_types.num_adapter_types = &num_adapter_types;\n\tadapter_types.adapter_types = adapter_type;\n\tadapter_info.window_list = NULL;\n\tfor (i = 0; i < 2; i++) {\n\t\terr = nrt_cmd_wrap(NRT_VERSION, NRT_CMD_QUERY_ADAPTER_TYPES,\n\t\t\t\t   &adapter_types);\n\t\tif (err != NRT_EAGAIN)\n\t\t\tbreak;\n\t\terror(\"nrt_cmd_wrap(adapter_types): %s\", nrt_err_str(err));\n\t\terror(\"Is PNSD daemon started? Retrying...\");\n\t\t/* Run \"/opt/ibmhpc/pecurrent/ppe.pami/pnsd/pnsd -A\" */\n\t\tsleep(5);\n\t}\n\tif (err != NRT_SUCCESS) {\n\t\terror(\"nrt_cmd_wrap(adapter_types): %s\", nrt_err_str(err));\n\t\treturn SLURM_ERROR;\n\t}\n\tif (debug_flags & DEBUG_FLAG_SWITCH) {\n\t\tfor (i = 0; i < num_adapter_types; i++) {\n\t\t\tinfo(\"nrt_cmd_wrap(adapter_types): %s\",\n\t\t\t     _adapter_type_str(adapter_types.adapter_types[i]));\n\t\t}\n\t}\n\n\tfor (i = 0; i < num_adapter_types; i++) {\n\t\tadapter_names.adapter_type = adapter_type[i];\n\t\tadapter_names.num_adapter_names = &num_adapter_names;\n\t\tadapter_names.max_windows = &max_windows;\n\t\terr = nrt_cmd_wrap(NRT_VERSION, NRT_CMD_QUERY_ADAPTER_NAMES,\n\t\t\t\t   &adapter_names);\n\t\tif (err != NRT_SUCCESS) {\n\t\t\terror(\"nrt_cmd_wrap(adapter_names, %s): %s\",\n\t\t\t      _adapter_type_str(adapter_names.adapter_type),\n\t\t\t      nrt_err_str(err));\n\t\t\trc = SLURM_ERROR;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Get the total adapter count here and print afterwards. */\n\t\ttotal_adapters += num_adapter_names;\n\t\tif (total_adapters > NRT_MAXADAPTERS)\n\t\t\tcontinue;\n\n\t\tif (debug_flags & DEBUG_FLAG_SWITCH) {\n\t\t\tfor (j = 0; j < num_adapter_names; j++) {\n\t\t\t\tinfo(\"nrt_cmd_wrap(adapter_names, %s, %s) \"\n\t\t\t\t     \"max_windows: %hu\",\n\t\t\t\t      adapter_names.adapter_names[j],\n\t\t\t\t      _adapter_type_str(adapter_names.\n\t\t\t\t\t\t\tadapter_type),\n\t\t\t\t      max_windows);\n\t\t\t}\n\t\t}\n\n\t\tfor (j = 0; j < num_adapter_names; j++) {\n\t\t\tmin_window_id = _load_min_window_id(\n\t\t\t\t\t\tadapter_names.adapter_names[j],\n\t\t\t\t\t\tadapter_names.adapter_type);\n\t\t\tif (status_array) {\n\t\t\t\tfree(status_array);\n\t\t\t\tstatus_array = NULL;\n\t\t\t}\n\t\t\tadapter_status.adapter_name = adapter_names.\n\t\t\t\t\t\t      adapter_names[j];\n\t\t\tadapter_status.adapter_type = adapter_names.\n\t\t\t\t\t\t      adapter_type;\n\t\t\tadapter_status.status_array = &status_array;\n\t\t\tadapter_status.window_count = &window_count;\n\t\t\terr = nrt_cmd_wrap(NRT_VERSION, NRT_CMD_STATUS_ADAPTER,\n\t\t\t\t\t   &adapter_status);\n\t\t\tif (err != NRT_SUCCESS) {\n\t\t\t\terror(\"nrt_cmd_wrap(status_adapter, %s, %s): %s\",\n\t\t\t\t      adapter_status.adapter_name,\n\t\t\t\t      _adapter_type_str(adapter_status.\n\t\t\t\t\t\t\tadapter_type),\n\t\t\t\t      nrt_err_str(err));\n\t\t\t\trc = SLURM_ERROR;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (window_count > max_windows) {\n\t\t\t\t/* This happens if IP_ONLY devices are\n\t\t\t\t * allocated with tables_per_task > 0 */\n\t\t\t\tchar *reason;\n\t\t\t\tif (adapter_status.adapter_type == NRT_IPONLY)\n\t\t\t\t\treason = \", Known libnrt bug\";\n\t\t\t\telse\n\t\t\t\t\treason = \"\";\n\t\t\t\tdebug(\"nrt_cmd_wrap(status_adapter, %s, %s): \"\n\t\t\t\t      \"window_count > max_windows (%u > %hu)%s\",\n\t\t\t\t      adapter_status.adapter_name,\n\t\t\t\t      _adapter_type_str(adapter_status.\n\t\t\t\t\t\t\tadapter_type),\n\t\t\t\t      window_count, max_windows, reason);\n\t\t\t\t/* Reset value to avoid logging bad data */\n\t\t\t\twindow_count = max_windows;\n\t\t\t}\n\t\t\tif (debug_flags & DEBUG_FLAG_SWITCH) {\n\t\t\t\tinfo(\"nrt_cmd_wrap(status_adapter, %s, %s)\",\n\t\t\t\t     adapter_status.adapter_name,\n\t\t\t\t     _adapter_type_str(adapter_status.\n\t\t\t\t\t\t       adapter_type));\n\t\t\t\t_print_adapter_status(&adapter_status);\n\t\t\t}\n\t\t\tadapter_ptr = &n->adapter_list[n->adapter_count];\n\t\t\tstrlcpy(adapter_ptr->adapter_name,\n\t\t\t\tadapter_status.adapter_name,\n\t\t\t\tNRT_MAX_ADAPTER_NAME_LEN);\n\t\t\tadapter_ptr->adapter_type = adapter_status.\n\t\t\t\t\t\t    adapter_type;\n\t\t\tadapter_ptr->window_count = adapter_status.\n\t\t\t\t\t\t    window_count[0];\n\t\t\tadapter_ptr->window_list =\n\t\t\t\txmalloc(sizeof(slurm_nrt_window_t) *\n\t\t\t\t\twindow_count);\n\t\t\tn->adapter_count++;\n\n\t\t\tfor (k = 0; k < window_count; k++) {\n\t\t\t\tslurm_nrt_window_t *window_ptr;\n\t\t\t\twindow_ptr = adapter_ptr->window_list + k;\n\t\t\t\twindow_ptr->window_id = status_array[k].\n\t\t\t\t\t\t\twindow_id;\n\t\t\t\twindow_ptr->state = status_array[k].state;\n\t\t\t\t/* window_ptr->job_key = Not_Available */\n\t\t\t\tif ((adapter_ptr->adapter_type == NRT_HFI) &&\n\t\t\t\t    (!dynamic_window_err) &&\n\t\t\t\t    (window_ptr->window_id < min_window_id)) {\n\t\t\t\t\terror(\"switch/nrt: Dynamic window \"\n\t\t\t\t\t      \"configuration error for %s, \"\n\t\t\t\t\t      \"window_id=%u < min_window_id:%d\",\n\t\t\t\t\t      adapter_status.adapter_name,\n\t\t\t\t\t      window_ptr->window_id,\n\t\t\t\t\t      min_window_id);\n\t\t\t\t\tdynamic_window_err = true;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t/* Now get adapter info (port_id, network_id, etc.) */\n\t\t\tquery_adapter_info.adapter_name = adapter_names.\n\t\t\t\t\t\t\t  adapter_names[j];\n\t\t\tquery_adapter_info.adapter_type = adapter_names.\n\t\t\t\t\t\t\t  adapter_type;\n\t\t\tquery_adapter_info.adapter_info = &adapter_info;\n\t\t\tadapter_info.window_list = xmalloc(max_windows *\n\t\t\t\t\t\t   sizeof(nrt_window_id_t));\n\t\t\terr = nrt_cmd_wrap(NRT_VERSION,\n\t\t\t\t\t   NRT_CMD_QUERY_ADAPTER_INFO,\n\t\t\t\t\t   &query_adapter_info);\n\t\t\tif (err != NRT_SUCCESS) {\n\t\t\t\terror(\"nrt_cmd_wrap(adapter_into, %s, %s): %s\",\n\t\t\t\t      query_adapter_info.adapter_name,\n\t\t\t\t      _adapter_type_str(query_adapter_info.\n\t\t\t\t\t\t\tadapter_type),\n\t\t\t\t      nrt_err_str(err));\n\t\t\t\trc = SLURM_ERROR;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (debug_flags & DEBUG_FLAG_SWITCH) {\n\t\t\t\tinfo(\"nrt_cmd_wrap(adapter_info, %s, %s)\",\n\t\t\t\t     query_adapter_info.adapter_name,\n\t\t\t\t     _adapter_type_str(query_adapter_info.\n\t\t\t\t\t\t       adapter_type));\n\t\t\t\t_print_adapter_info(&adapter_info);\n\t\t\t}\n\t\t\tif (adapter_info.node_number != 0) {\n\t\t\t\tn->node_number = adapter_info.node_number;\n\t\t\t\tmy_network_id  = adapter_info.node_number;\n\t\t\t\tmy_network_id_set = true;\n\t\t\t}\n\t\t\tadapter_ptr->cau_indexes_avail =\n\t\t\t\tadapter_info.cau_indexes_avail;\n\t\t\tadapter_ptr->immed_slots_avail =\n\t\t\t\tadapter_info.immed_slots_avail;\n\t\t\tadapter_ptr->rcontext_block_count =\n\t\t\t\tadapter_info.rcontext_block_count;\n\t\t\tfor (k = 0; k < adapter_info.num_ports; k++) {\n\t\t\t\tif (adapter_info.port[k].status != 1)\n\t\t\t\t\tcontinue;\n\t\t\t\tadapter_ptr->ipv4_addr = adapter_info.port[k].\n\t\t\t\t\t\t\t ipv4_addr;\n\t\t\t\tadapter_ptr->ipv6_addr = adapter_info.port[k].\n\t\t\t\t\t\t\t ipv6_addr;\n\t\t\t\tadapter_ptr->lid = adapter_info.port[k].lid;\n\t\t\t\tadapter_ptr->network_id = adapter_info.port[k].\n\t\t\t\t\t\t\t  network_id;\n\t\t\t\tadapter_ptr->port_id = adapter_info.port[k].\n\t\t\t\t\t\t       port_id;\n\t\t\t\tadapter_ptr->special = adapter_info.port[k].\n\t\t\t\t\t\t       special;\n\t\t\t\tif (adapter_ptr->adapter_type == NRT_HFI) {\n\t\t\t\t\tmy_lpar_id = adapter_ptr->special;\n\t\t\t\t\tmy_lid = adapter_ptr->lid;\n\t\t\t\t\tmy_lpar_id_set = true;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif ((adapter_ptr->ipv4_addr == 0) &&\n\t\t\t    (adapter_info.num_ports > 0)) {\n\t\t\t\tadapter_ptr->ipv4_addr = adapter_info.port[0].\n\t\t\t\t\t\t\t ipv4_addr;\n\t\t\t\tadapter_ptr->ipv6_addr = adapter_info.port[0].\n\t\t\t\t\t\t\t ipv6_addr;\n\t\t\t}\n\t\t\txfree(adapter_info.window_list);\n\t\t}\n\t\tif (status_array) {\n\t\t\tfree(status_array);\n\t\t\tstatus_array = NULL;\n\t\t}\n\n\t}\n\n\tif (total_adapters > NRT_MAXADAPTERS) {\n\t\tfatal(\"switch/nrt: More adapters found (%u) on \"\n\t\t      \"node than supported (%u). \"\n\t\t      \"Increase NRT_MAXADAPTERS and rebuild slurm\",\n\t\t      total_adapters, NRT_MAXADAPTERS);\n\t}\n\n\tif (debug_flags & DEBUG_FLAG_SWITCH) {\n\t\t_print_nodeinfo(n);\n\t\tinfo(\"_get_adapters: complete: %d\", rc);\n\t}\n\treturn rc;\n}\n\n/* Assumes a pre-allocated nodeinfo structure and uses _get_adapters\n * to do the dirty work.  We probably collect more information about\n * the adapters on a give node than we need to, but it was done\n * in the interest of being prepared for future requirements.\n *\n * Used by: slurmd\n */\nextern int\nnrt_build_nodeinfo(slurm_nrt_nodeinfo_t *n, char *name)\n{\n\tint err;\n\n\txassert(n);\n\txassert(n->magic == NRT_NODEINFO_MAGIC);\n\txassert(name);\n\n\tstrlcpy(n->name, name, NRT_HOSTLEN);\n\tslurm_mutex_lock(&global_lock);\n\terr = _get_adapters(n);\n\tslurm_mutex_unlock(&global_lock);\n\n\treturn err;\n}\n\n/* Used by: all */\nextern int\nnrt_pack_nodeinfo(slurm_nrt_nodeinfo_t *n, Buf buf,\n\t\t  uint16_t protocol_version)\n{\n\tslurm_nrt_adapter_t *a;\n\tuint16_t dummy16;\n\tint i, j, offset;\n\n\txassert(n);\n\txassert(n->magic == NRT_NODEINFO_MAGIC);\n\txassert(buf);\n\tif (debug_flags & DEBUG_FLAG_SWITCH) {\n\t\tinfo(\"nrt_pack_nodeinfo():\");\n\t\t_print_nodeinfo(n);\n\t}\n\toffset = get_buf_offset(buf);\n\tpack32(n->magic, buf);\n\tpackmem(n->name, NRT_HOSTLEN, buf);\n\tpack32(n->node_number, buf);\n\tpack32(n->adapter_count, buf);\n\tfor (i = 0; i < n->adapter_count; i++) {\n\t\ta = n->adapter_list + i;\n\t\tpackmem(a->adapter_name, NRT_MAX_ADAPTER_NAME_LEN, buf);\n\t\tdummy16 = a->adapter_type;\n\t\tpack16(dummy16, buf);\t/* adapter_type is an int */\n\t\tpack16(a->cau_indexes_avail, buf);\n\t\tpack16(a->immed_slots_avail, buf);\n\t\tpack32(a->ipv4_addr, buf);\n\t\tfor (j = 0; j < 16; j++)\n\t\t\tpack8(a->ipv6_addr.s6_addr[j], buf);\n\t\tpack32(a->lid, buf);\n\t\tpack64(a->network_id, buf);\n\t\tpack8(a->port_id, buf);\n\t\tpack64(a->rcontext_block_count, buf);\n\t\tpack64(a->special, buf);\n\t\tpack16(a->window_count, buf);\n\t\tfor (j = 0; j < a->window_count; j++) {\n\t\t\tuint32_t state = a->window_list[j].state;\n\t\t\tpack16(a->window_list[j].window_id, buf);\n\t\t\tpack32(state, buf);\n\t\t\tpack32(a->window_list[j].job_key, buf);\n\t\t}\n\t}\n\n\treturn(get_buf_offset(buf) - offset);\n}\n\n/* Used by: all */\nstatic int\n_copy_node(slurm_nrt_nodeinfo_t *dest, slurm_nrt_nodeinfo_t *src)\n{\n\tint i, j;\n\tslurm_nrt_adapter_t *sa = NULL;\n\tslurm_nrt_adapter_t *da = NULL;\n\n\txassert(dest);\n\txassert(src);\n\txassert(dest->magic == NRT_NODEINFO_MAGIC);\n\txassert(src->magic == NRT_NODEINFO_MAGIC);\n\n\tif (debug_flags & DEBUG_FLAG_SWITCH) {\n\t\tinfo(\"_copy_node():\");\n\t\t_print_nodeinfo(src);\n\t}\n\n\tstrlcpy(dest->name, src->name, NRT_HOSTLEN);\n\tdest->node_number = src->node_number;\n\tdest->adapter_count = src->adapter_count;\n\tfor (i = 0; i < dest->adapter_count; i++) {\n\t\tsa = src->adapter_list + i;\n\t\tda = dest->adapter_list +i;\n\t\tstrlcpy(da->adapter_name, sa->adapter_name,\n\t\t\tNRT_MAX_ADAPTER_NAME_LEN);\n\t\tda->adapter_type = sa->adapter_type;\n\t\tda->cau_indexes_avail = sa->cau_indexes_avail;\n\t\tda->immed_slots_avail = sa->immed_slots_avail;\n\t\tda->ipv4_addr    = sa->ipv4_addr;\n\t\tda->ipv6_addr    = sa->ipv6_addr;\n\t\tda->lid          = sa->lid;\n\t\tda->network_id   = sa->network_id;\n\t\tda->port_id      = sa->port_id;\n\t\tda->rcontext_block_count = sa->rcontext_block_count;\n\t\tda->special      = sa->special;\n\t\tda->window_count = sa->window_count;\n\t\tda->window_list = (slurm_nrt_window_t *)\n\t\t\t\t  xmalloc(sizeof(slurm_nrt_window_t) *\n\t\t\t\t  da->window_count);\n\t\tfor (j = 0; j < da->window_count; j++) {\n\t\t\tda->window_list[j].window_id = sa->window_list[j].\n\t\t\t\t\t\t       window_id;\n\t\t\tda->window_list[j].state = sa->window_list[j].state;\n\t\t\tda->window_list[j].job_key = sa->window_list[j].\n\t\t\t\t\t\t     job_key;\n\t\t}\n\t}\n\n\treturn SLURM_SUCCESS;\n}\n\nstatic int\n_cmp_ipv6(struct in6_addr *addr1, struct in6_addr *addr2)\n{\n\tint i;\n\n\tfor (i = 0; i < 16; i++) {\n\t\tif (addr1->s6_addr[i] != addr2->s6_addr[i])\n\t\t\treturn 1;\n\t}\n\n\treturn 0;\n}\n\n/* Throw away adapter window portion of the nodeinfo.\n *\n * Used by: _unpack_nodeinfo\n */\nstatic int\n_fake_unpack_adapters(Buf buf, slurm_nrt_nodeinfo_t *n,\n\t\t      uint16_t protocol_version)\n{\n\tslurm_nrt_adapter_t *tmp_a = NULL;\n\tslurm_nrt_window_t *tmp_w = NULL;\n\tuint16_t dummy16;\n\tuint32_t dummy32;\n\tchar *name_ptr;\n\tuint8_t  port_id;\n\tuint16_t adapter_type, cau_indexes_avail, immed_slots_avail;\n\tuint16_t window_count;\n\tuint32_t adapter_count, ipv4_addr, lid;\n\tuint64_t network_id, rcontext_block_count, special;\n\tstruct in6_addr ipv6_addr;\n\tint i, j, k;\n\n\tsafe_unpack32(&adapter_count, buf);\n\tif (n && (n->adapter_count != adapter_count)) {\n\t\terror(\"switch/nrt: node %s adapter count reset from %u to %u\",\n\t\t      n->name, n->adapter_count, adapter_count);\n\t\tif (n->adapter_count < adapter_count)\n\t\t\tdrain_nodes(n->name, \"Too few switch adapters\", 0);\n\t}\n\tfor (i = 0; i < adapter_count; i++) {\n\t\tsafe_unpackmem_ptr(&name_ptr, &dummy32, buf);\n\t\tif (dummy32 != NRT_MAX_ADAPTER_NAME_LEN)\n\t\t\tgoto unpack_error;\n\t\tsafe_unpack16(&adapter_type, buf);\n\t\tsafe_unpack16(&cau_indexes_avail, buf);\n\t\tsafe_unpack16(&immed_slots_avail, buf);\n\t\tsafe_unpack32(&ipv4_addr, buf);\n\t\tfor (j = 0; j < 16; j++)\n\t\t\tsafe_unpack8(&ipv6_addr.s6_addr[j], buf);\n\t\tsafe_unpack32(&lid, buf);\n\t\tsafe_unpack64(&network_id, buf);\n\t\tsafe_unpack8 (&port_id, buf);\n\t\tsafe_unpack64(&rcontext_block_count, buf);\n\t\tsafe_unpack64(&special, buf);\n\t\tsafe_unpack16(&window_count, buf);\n\n\t\t/* no copy, just advances buf counters */\n\t\tfor (j = 0; j < window_count; j++) {\n\t\t\tsafe_unpack16(&dummy16, buf);\t/* window_id */\n\t\t\tsafe_unpack32(&dummy32, buf);\t/* state */\n\t\t\tsafe_unpack32(&dummy32, buf);\t/* job_key */\n\t\t}\n\n\t\tfor (j = 0; j < n->adapter_count; j++) {\n\t\t\ttmp_a = n->adapter_list + j;\n\t\t\tif (xstrcmp(tmp_a->adapter_name, name_ptr))\n\t\t\t\tcontinue;\n\t\t\tif (tmp_a->cau_indexes_avail != cau_indexes_avail) {\n\t\t\t\tinfo(\"switch/nrt: resetting cau_indexes_avail \"\n\t\t\t\t     \"on node %s adapter %s\",\n\t\t\t\t     n->name, tmp_a->adapter_name);\n\t\t\t\ttmp_a->cau_indexes_avail = cau_indexes_avail;\n\t\t\t}\n\t\t\tif (tmp_a->immed_slots_avail != immed_slots_avail) {\n\t\t\t\tinfo(\"switch/nrt: resetting immed_slots_avail \"\n\t\t\t\t     \"on node %s adapter %s\",\n\t\t\t\t     n->name, tmp_a->adapter_name);\n\t\t\t\ttmp_a->immed_slots_avail = immed_slots_avail;\n\t\t\t}\n\t\t\tif (tmp_a->ipv4_addr != ipv4_addr) {\n\t\t\t\tinfo(\"switch/nrt: resetting ipv4_addr \"\n\t\t\t\t     \"on node %s adapter %s\",\n\t\t\t\t     n->name, tmp_a->adapter_name);\n\t\t\t\ttmp_a->ipv4_addr = ipv4_addr;\n\t\t\t}\n\t\t\tif (_cmp_ipv6(&tmp_a->ipv6_addr, &ipv6_addr) != 0) {\n\t\t\t\tinfo(\"switch/nrt: resetting ipv6_addr \"\n\t\t\t\t     \"on node %s adapter %s\",\n\t\t\t\t     n->name, tmp_a->adapter_name);\n\t\t\t\tfor (k = 0; k < 16; k++) {\n\t\t\t\t\ttmp_a->ipv6_addr.s6_addr[k] =\n\t\t\t\t\t\tipv6_addr.s6_addr[k];\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (tmp_a->lid != lid) {\n\t\t\t\tinfo(\"switch/nrt: resetting lid \"\n\t\t\t\t     \"on node %s adapter %s\",\n\t\t\t\t     n->name, tmp_a->adapter_name);\n\t\t\t\ttmp_a->lid = lid;\n\t\t\t}\n\t\t\tif (tmp_a->network_id != network_id) {\n\t\t\t\tinfo(\"switch/nrt: resetting network_id \"\n\t\t\t\t     \"on node %s adapter %s\",\n\t\t\t\t     n->name, tmp_a->adapter_name);\n\t\t\t\ttmp_a->network_id = network_id;\n\t\t\t}\n\t\t\tif (tmp_a->port_id != port_id) {\n\t\t\t\tinfo(\"switch/nrt: resetting port_id \"\n\t\t\t\t     \"on node %s adapter %s\",\n\t\t\t\t     n->name, tmp_a->adapter_name);\n\t\t\t\ttmp_a->port_id = port_id;\n\t\t\t}\n\t\t\tif (tmp_a->rcontext_block_count !=\n\t\t\t    rcontext_block_count) {\n\t\t\t\tinfo(\"switch/nrt: resetting \"\n\t\t\t\t     \"rcontext_block_count on node %s \"\n\t\t\t\t     \"adapter %s\",\n\t\t\t\t     n->name, tmp_a->adapter_name);\n\t\t\t\ttmp_a->rcontext_block_count =\n\t\t\t\t\trcontext_block_count;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\n\t\tif (j == n->adapter_count) {\n\t\t\terror(\"switch/nrt: node %s adapter %s being added\",\n\t\t\t      n->name, name_ptr);\n\t\t\tn->adapter_count++;\n\t\t\txrealloc(n->adapter_list,\n\t\t\t\t sizeof(slurm_nrt_adapter_t) *\n\t\t\t\t n->adapter_count);\n\t\t\ttmp_a = n->adapter_list + j;\n\t\t\tstrlcpy(tmp_a->adapter_name, name_ptr,\n\t\t\t\tNRT_MAX_ADAPTER_NAME_LEN);\n\t\t\ttmp_a->adapter_type = adapter_type;\n\t\t\t/* tmp_a->block_count = 0 */\n\t\t\t/* tmp_a->block_list = NULL */\n\t\t\ttmp_a->cau_indexes_avail = cau_indexes_avail;\n\t\t\ttmp_a->immed_slots_avail = immed_slots_avail;\n\t\t\ttmp_a->ipv4_addr = ipv4_addr;\n\t\t\tfor (k = 0; k < 16; k++) {\n\t\t\t\ttmp_a->ipv6_addr.s6_addr[k] =\n\t\t\t\t\tipv6_addr.s6_addr[k];\n\t\t\t}\n\t\t\ttmp_a->lid = lid;\n\t\t\ttmp_a->network_id = network_id;\n\t\t\ttmp_a->port_id = port_id;\n\t\t\ttmp_a->rcontext_block_count = rcontext_block_count;\n\t\t\ttmp_a->special = special;\n\t\t\ttmp_a->window_count = window_count;\n\t\t\ttmp_w = (slurm_nrt_window_t *)\n\t\t\t\txmalloc(sizeof(slurm_nrt_window_t) *\n\t\t\t\ttmp_a->window_count);\n\t\t\tfor (k = 0; k < tmp_a->window_count; k++) {\n\t\t\t\ttmp_w[k].state = NRT_WIN_AVAILABLE;\n\t\t\t\ttmp_w[k].job_key = 0;\n\t\t\t}\n\t\t\ttmp_a->window_list = tmp_w;\n\t\t}\n\t}\n\n\treturn SLURM_SUCCESS;\n\nunpack_error:\n\treturn SLURM_ERROR;\n}\n\n\n/* Unpack nodeinfo and update persistent libstate.\n *\n * If believe_window_status is true, we honor the window status variables\n * from the packed nrt_nodeinfo_t.  If it is false we set the status of\n * all windows to NRT_WIN_AVAILABLE.\n *\n * Used by: slurmctld\n */\nstatic int\n_unpack_nodeinfo(slurm_nrt_nodeinfo_t *n, Buf buf, bool believe_window_status,\n\t\t uint16_t protocol_version)\n{\n\tint i, j, rc = SLURM_SUCCESS;\n\tslurm_nrt_adapter_t *tmp_a = NULL;\n\tslurm_nrt_window_t *tmp_w = NULL;\n\tnrt_node_number_t node_number;\n\tuint32_t size;\n\tslurm_nrt_nodeinfo_t *tmp_n = NULL;\n\tchar *name_ptr, name[NRT_HOSTLEN];\n\tuint32_t magic;\n\tuint16_t dummy16;\n\n\t/* NOTE!  We don't care at this point whether n is valid.\n\t * If it's NULL, we will just forego the copy at the end.\n\t */\n\txassert(buf);\n\n\t/* Extract node name from buffer */\n\tsafe_unpack32(&magic, buf);\n\tif (magic != NRT_NODEINFO_MAGIC)\n\t\tslurm_seterrno_ret(EBADMAGIC_NRT_NODEINFO);\n\tsafe_unpackmem_ptr(&name_ptr, &size, buf);\n\tif (size != NRT_HOSTLEN)\n\t\tgoto unpack_error;\n\tmemcpy(name, name_ptr, size);\n\tsafe_unpack32(&node_number, buf);\n\n\t/* When the slurmctld is in normal operating mode (NOT backup mode),\n\t * the global nrt_state structure should NEVER be NULL at the time that\n\t * this function is called.  Therefore, if nrt_state is NULL here,\n\t * we assume that the controller is in backup mode.  In backup mode,\n\t * the slurmctld only unpacks RPCs to find out their identity.\n\t * Most of the RPCs, including the one calling this function, are\n\t * simply ignored.\n\t *\n\t * So, here we just do a fake unpack to advance the buffer pointer.\n\t */\n\tif (nrt_state == NULL) {\n\t\tif (_fake_unpack_adapters(buf, NULL, protocol_version)\n\t\t    != SLURM_SUCCESS) {\n\t\t\tslurm_seterrno_ret(EUNPACK);\n\t\t} else {\n\t\t\treturn SLURM_SUCCESS;\n\t\t}\n\t}\n\n\t/* If we already have nodeinfo for this node, we ignore this message.\n\t * The slurmctld's view of window allocation is always better than\n\t * the slurmd's view.  We only need the slurmd's view if the slurmctld\n\t * has no nodeinfo at all for that node.\n\t */\n\tif (name != NULL) {\n\t\ttmp_n = _find_node(nrt_state, name);\n\t\tif (tmp_n != NULL) {\n\t\t\ttmp_n->node_number = node_number;\n\t\t\tif (_fake_unpack_adapters(buf, tmp_n, protocol_version)\n\t\t\t    != SLURM_SUCCESS) {\n\t\t\t\tslurm_seterrno_ret(EUNPACK);\n\t\t\t} else {\n\t\t\t\tgoto copy_node;\n\t\t\t}\n\t\t}\n\t}\n\n\t/*\n\t * Update global libstate with this nodes' info.\n\t */\n\ttmp_n = _alloc_node(nrt_state, name);\n\tif (tmp_n == NULL)\n\t\treturn SLURM_ERROR;\n\ttmp_n->magic = magic;\n\ttmp_n->node_number = node_number;\n\tsafe_unpack32(&tmp_n->adapter_count, buf);\n\tif (tmp_n->adapter_count > NRT_MAXADAPTERS) {\n\t\terror(\"switch/nrt: More adapters found on node %s than \"\n\t\t      \"supported. Increase NRT_MAXADAPTERS and rebuild slurm\",\n\t\t      name);\n\t\ttmp_n->adapter_count = NRT_MAXADAPTERS;\n\t}\n\tfor (i = 0; i < tmp_n->adapter_count; i++) {\n\t\ttmp_a = tmp_n->adapter_list + i;\n\t\tsafe_unpackmem_ptr(&name_ptr, &size, buf);\n\t\tif (size != NRT_MAX_ADAPTER_NAME_LEN)\n\t\t\tgoto unpack_error;\n\t\tmemcpy(tmp_a->adapter_name, name_ptr, size);\n\t\tsafe_unpack16(&dummy16, buf);\n\t\ttmp_a->adapter_type = dummy16;\t/* adapter_type is an int */\n\t\tsafe_unpack16(&tmp_a->cau_indexes_avail, buf);\n\t\tsafe_unpack16(&tmp_a->immed_slots_avail, buf);\n\t\tsafe_unpack32(&tmp_a->ipv4_addr, buf);\n\t\tfor (j = 0; j < 16; j++) {\n\t\t\tsafe_unpack8(&tmp_a->ipv6_addr.s6_addr[j], buf);\n\t\t}\n\t\tsafe_unpack32(&tmp_a->lid, buf);\n\t\tsafe_unpack64(&tmp_a->network_id, buf);\n\t\tsafe_unpack8(&tmp_a->port_id, buf);\n\t\tsafe_unpack64(&tmp_a->rcontext_block_count, buf);\n\t\tsafe_unpack64(&tmp_a->special, buf);\n\t\tsafe_unpack16(&tmp_a->window_count, buf);\n\t\ttmp_w = (slurm_nrt_window_t *)\n\t\t\txmalloc(sizeof(slurm_nrt_window_t) *\n\t\t\ttmp_a->window_count);\n\t\tfor (j = 0; j < tmp_a->window_count; j++) {\n\t\t\tsafe_unpack16(&tmp_w[j].window_id, buf);\n\t\t\tsafe_unpack32(&tmp_w[j].state, buf);\n\t\t\tsafe_unpack32(&tmp_w[j].job_key, buf);\n\t\t\tif (!believe_window_status) {\n\t\t\t\ttmp_w[j].state = NRT_WIN_AVAILABLE;\n\t\t\t\ttmp_w[j].job_key = 0;\n\t\t\t}\n\t\t}\n\t\ttmp_a->window_list = tmp_w;\n\t\ttmp_w = NULL;  /* don't free if unpack error on next adapter */\n\t}\n\tif (debug_flags & DEBUG_FLAG_SWITCH) {\n\t\tinfo(\"_unpack_nodeinfo\");\n\t\t_print_nodeinfo(tmp_n);\n\t}\n\ncopy_node:\n\t/* Only copy the node_info structure if the caller wants it */\n\tif ((n != NULL) && (_copy_node(n, tmp_n) != SLURM_SUCCESS))\n\t\trc = SLURM_ERROR;\n\treturn rc;\n\nunpack_error:\n\txfree(tmp_w);\n\tslurm_seterrno_ret(EUNPACK);\n}\n\n/* Unpack nodeinfo and update persistent libstate.\n *\n * Used by: slurmctld\n */\nextern int\nnrt_unpack_nodeinfo(slurm_nrt_nodeinfo_t *n, Buf buf, uint16_t protocol_version)\n{\n\tint rc;\n\n\tslurm_mutex_lock(&global_lock);\n\trc = _unpack_nodeinfo(n, buf, false, protocol_version);\n\tslurm_mutex_unlock(&global_lock);\n\treturn rc;\n}\n\n/* Used by: slurmd, slurmctld */\nextern void\nnrt_free_nodeinfo(slurm_nrt_nodeinfo_t *n, bool ptr_into_array)\n{\n\tslurm_nrt_adapter_t *adapter;\n\tint i;\n\n\tif (!n)\n\t\treturn;\n\n\txassert(n->magic == NRT_NODEINFO_MAGIC);\n\n\tif (debug_flags & DEBUG_FLAG_SWITCH) {\n\t\tinfo(\"nrt_free_nodeinfo\");\n\t\t_print_nodeinfo(n);\n\t}\n\n\tif (n->adapter_list) {\n\t\tadapter = n->adapter_list;\n\t\tfor (i = 0; i < n->adapter_count; i++)\n\t\t\txfree(adapter[i].window_list);\n\t\txfree(n->adapter_list);\n\t}\n\tif (!ptr_into_array)\n\t\txfree(n);\n}\n\n/* Find all of the windows used by job step \"jp\" on the hosts\n * designated in hostlist \"hl\" and mark their state NRT_WIN_AVAILABLE.\n *\n * Used by: slurmctld\n */\nextern int\nnrt_job_step_complete(slurm_nrt_jobinfo_t *jp, hostlist_t hl)\n{\n\thostlist_t uniq_hl;\n\thostlist_iterator_t hi;\n\tchar *node_name;\n\n\txassert(!hostlist_is_empty(hl));\n\tif ((jp == NULL) || (jp->magic == NRT_NULL_MAGIC)) {\n\t\tdebug2(\"(%s: %d: %s) job->switch_job was NULL\",\n\t\t       THIS_FILE, __LINE__, __func__);\n\t\treturn SLURM_ERROR;\n\t}\n\n\txassert(jp->magic == NRT_JOBINFO_MAGIC);\n\n\tif ((jp == NULL) || (hostlist_is_empty(hl)))\n\t\treturn SLURM_ERROR;\n\n\tif ((jp->tables_per_task == 0) || (jp->tableinfo == NULL) ||\n\t    (jp->tableinfo[0].table_length == 0))\n\t\treturn SLURM_SUCCESS;\n\n\t/* The hl hostlist may contain duplicate node_names (poe -hostfile\n\t * triggers duplicates in the hostlist).  Since there\n\t * is no reason to call _free_resources_by_job more than once\n\t * per node_name, we create a new unique hostlist.\n\t */\n\tuniq_hl = hostlist_copy(hl);\n\thostlist_uniq(uniq_hl);\n\thi = hostlist_iterator_create(uniq_hl);\n\n\tslurm_mutex_lock(&global_lock);\n\tif (nrt_state != NULL) {\n\t\twhile ((node_name = hostlist_next(hi)) != NULL) {\n\t\t\t_free_resources_by_job(jp, node_name);\n\t\t\tfree(node_name);\n\t\t}\n\t} else { /* nrt_state == NULL */\n\t\t/* If there is no state at all, the job is already cleaned\n\t\t * up. :)  This should really only happen when the backup\n\t\t * controller is calling job_fini() just before it takes over\n\t\t * the role of active controller.\n\t\t */\n\t\tdebug(\"nrt_job_step_complete called when nrt_state == NULL\");\n\t}\n\tslurm_mutex_unlock(&global_lock);\n\n\thostlist_iterator_destroy(hi);\n\thostlist_destroy(uniq_hl);\n\treturn SLURM_SUCCESS;\n}\n\n/* Find all of the windows used by job step \"jp\" and mark their\n * state NRT_WIN_UNAVAILABLE.\n *\n * Used by the slurmctld at startup time to restore the allocation\n * status of any job steps that were running at the time the previous\n * slurmctld was shutdown.  Also used to restore the allocation\n * status after a call to switch_g_clear().\n */\nextern int\nnrt_job_step_allocated(slurm_nrt_jobinfo_t *jp, hostlist_t hl)\n{\n\tint rc;\n\n\tif (debug_flags & DEBUG_FLAG_SWITCH) {\n\t\tinfo(\"nrt_job_step_allocated: resetting window state\");\n\t\t_print_jobinfo(jp);\n\t}\n\n\trc = _job_step_window_state(jp, hl, NRT_WIN_UNAVAILABLE);\n\n\tif (debug_flags & DEBUG_FLAG_SWITCH) {\n\t\tinfo(\"nrt_job_step_allocated: window state reset complete\");\n\t\t_print_libstate(nrt_state);\n\t}\n\n\treturn rc;\n}\n\n/* Assign a unique key to each job.  The key is used later to\n * gain access to the network table loaded on each node of a job.\n *\n * Used by: slurmctld\n */\nstatic nrt_job_key_t\n_next_key(void)\n{\n\tnrt_job_key_t key;\n\n\txassert(nrt_state);\n\n\tslurm_mutex_lock(&global_lock);\n\tkey = nrt_state->key_index;\n\tif (key == 0)\n\t\tkey++;\n\tnrt_state->key_index = (nrt_job_key_t) (key + 1);\n\tslurm_mutex_unlock(&global_lock);\n\n\treturn key;\n}\n\n/* Translate a protocol string (e.g. \"lapi,mpi\" into a table.\n * Caller must free returned value. */\nstatic nrt_protocol_table_t *_get_protocol_table(char *protocol)\n{\n\tnrt_protocol_table_t *protocol_table;\n\tchar *protocol_str, *save_ptr = NULL, *token;\n\tint i;\n\n\tprotocol_table = xmalloc(sizeof(nrt_protocol_table_t));\n\n\tif (!protocol)\n\t\tprotocol = \"mpi\";\n\tprotocol_str = xstrdup(protocol);\n\ttoken = strtok_r(protocol_str, \",\", &save_ptr);\n\twhile (token) {\n\t\tfor (i = 0; i < protocol_table->protocol_table_cnt; i++) {\n\t\t\tif (!xstrcmp(token, protocol_table->protocol_table[i].\n\t\t\t\t\t    protocol_name))\n\t\t\t\tbreak;\n\t\t}\n\t\tif ((i >= protocol_table->protocol_table_cnt) &&\n\t\t    (i < NRT_MAX_PROTO_CNT)) {\n\t\t\t/* Need to add new protocol type */\n\t\t\tstrlcpy(protocol_table->protocol_table[i].protocol_name,\n\t\t\t\ttoken, NRT_MAX_PROTO_NAME_LEN);\n\t\t\tprotocol_table->protocol_table_cnt++;\n\t\t}\n\t\ttoken = strtok_r(NULL, \",\", &save_ptr);\n\t}\n\txfree(protocol_str);\n\n\treturn protocol_table;\n}\n\n/* For an adapter type, return it's relative priority to use as a default */\nstatic inline int\n_adapter_type_pref(nrt_adapter_t adapter_type)\n{\n\tif (adapter_type == NRT_IPONLY)\n\t\treturn 9;\n\tif (adapter_type == NRT_HFI)\n\t\treturn 8;\n\tif (adapter_type == NRT_IB)\n\t\treturn 7;\n#if NRT_VERSION < 1300\n\tif (adapter_type == NRT_HPCE)\n\t\treturn 6;\n\tif (adapter_type == NRT_KMUX)\n\t\treturn 5;\n#endif\n\treturn 0;\n}\n\n/* Setup everything for the job.  Assign tasks across\n * nodes based on the hostlist given and create the network table used\n * on all nodes of the job.\n *\n * Used by: slurmctld\n */\nextern int\nnrt_build_jobinfo(slurm_nrt_jobinfo_t *jp, hostlist_t hl,\n\t\t  uint16_t *tasks_per_node, uint32_t **tids, bool sn_all,\n\t\t  char *adapter_name, nrt_adapter_t dev_type,\n\t\t  bool bulk_xfer, uint32_t bulk_xfer_resources,\n\t\t  bool ip_v4, bool user_space, char *protocol, int instances,\n\t\t  int cau, int immed)\n{\n\tint nnodes, nprocs = 0;\n\thostlist_iterator_t hi;\n\tchar *host = NULL;\n\tint i, j;\n\tslurm_nrt_nodeinfo_t *node;\n\tint rc;\n\tnrt_adapter_t adapter_type = NRT_MAX_ADAPTER_TYPES;\n\tint network_id = -1;\n\tnrt_protocol_table_t *protocol_table = NULL;\n\tnrt_adapter_t def_adapter_type = NRT_ADAP_UNSUPPORTED;\n\tint def_adapter_count = 0;\n\tint def_adapter_inx   = -1;\n\n\n\tif ((jp == NULL) || (jp->magic == NRT_NULL_MAGIC)) {\n\t\tdebug2(\"(%s: %d: %s) job->switch_job was NULL\",\n\t\t       THIS_FILE, __LINE__, __func__);\n\t\treturn SLURM_ERROR;\n\t}\n\n\txassert(jp->magic == NRT_JOBINFO_MAGIC);\n\txassert(tasks_per_node);\n\n\tif (dev_type != NRT_MAX_ADAPTER_TYPES)\n\t\tadapter_type = dev_type;\n\n\tnnodes = hostlist_count(hl);\n\tfor (i = 0; i < nnodes; i++)\n\t\tnprocs += tasks_per_node[i];\n\n\tif ((nnodes <= 0) || (nprocs <= 0))\n\t\tslurm_seterrno_ret(EINVAL);\n\n\tjp->bulk_xfer   = (uint8_t) bulk_xfer;\n\tjp->bulk_xfer_resources = bulk_xfer_resources;\n\tjp->ip_v4       = (uint8_t) ip_v4;\n\tjp->job_key     = _next_key();\n\tjp->nodenames   = hostlist_copy(hl);\n\tjp->num_tasks   = nprocs;\n\tjp->user_space  = (uint8_t) user_space;\n\n\t/*\n\t * Peek at the first host to figure out tables_per_task and adapter\n\t * type. This driver assumes that all nodes have the same number of\n\t * adapters per node.  Bad things will happen if this assumption is\n\t * incorrect.\n\t */\n\thi = hostlist_iterator_create(hl);\n\thost = hostlist_next(hi);\n\tslurm_mutex_lock(&global_lock);\n\tnode = _find_node(nrt_state, host);\n\tif (host != NULL)\n\t\tfree(host);\n\tif (node && node->adapter_list) {\n\t\tfor (i = 0; i < node->adapter_count; i++) {\n\t\t\tnrt_adapter_t ad_type;\n\t\t\t/* Match specific adapter name */\n\t\t\tif (adapter_name &&\n\t\t\t    xstrcmp(adapter_name,\n\t\t\t\t    node->adapter_list[i].adapter_name)) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t/* Match specific adapter type (IB, HFI, etc) */\n\t\t\tad_type = node->adapter_list[i].adapter_type;\n\t\t\tif ((adapter_type != NRT_MAX_ADAPTER_TYPES) &&\n\t\t\t    (adapter_type != ad_type))\n\t\t\t\tcontinue;\n\t\t\tif (jp->user_space && (ad_type == NRT_IPONLY))\n\t\t\t\tcontinue;\n\n\t\t\t/* Identify highest-priority adapter type */\n\t\t\tif (_adapter_type_pref(def_adapter_type) <\n\t\t\t    _adapter_type_pref(ad_type)) {\n\t\t\t\tdef_adapter_type  = ad_type;\n\t\t\t\tdef_adapter_count = 1;\n\t\t\t\tdef_adapter_inx   = i;\n\t\t\t} else if (_adapter_type_pref(def_adapter_type) ==\n\t\t\t           _adapter_type_pref(ad_type)) {\n\t\t\t\tdef_adapter_count++;\n\t\t\t}\n\t\t}\n\t\tif (!sn_all && (def_adapter_count > 0)) {\n\t\t\tif (!adapter_name) {\n\t\t\t\tadapter_name = node->\n\t\t\t\t\t       adapter_list[def_adapter_inx].\n\t\t\t\t\t       adapter_name;\n\t\t\t}\n\t\t\tnetwork_id = node->adapter_list[def_adapter_inx].\n\t\t\t\t     network_id;\n\t\t\tdef_adapter_count = 1;\n\t\t}\n\t\tif ((adapter_type == NRT_MAX_ADAPTER_TYPES) &&\n\t\t    (def_adapter_count > 0))\n\t\t\tadapter_type = def_adapter_type;\n\t}\n\tif (def_adapter_count >= 1) {\n\t\tjp->tables_per_task = def_adapter_count;\n\t} else {\n\t\tjp->tables_per_task = 0;\n\t\tinfo(\"switch/nrt: no adapter found for job\");\n\t}\n\tslurm_mutex_unlock(&global_lock);\n\tif (jp->tables_per_task == 0) {\n\t\thostlist_iterator_destroy(hi);\n\t\treturn SLURM_FAILURE;\n\t}\n\thostlist_iterator_reset(hi);\n\n\t/* Even for 1 node jobs the network needs to be set up. */\n\n\tif (adapter_type == NRT_IPONLY) {\n\t\t/* If tables_per_task != 0 for adapter_type == NRT_IPONLY\n\t\t * then the device's window count in NRT is incremented.\n\t\t * When we later read the adapter information, the adapter\n\t\t * reports a maximum window count of zero and a current\n\t\t * window count that is non zero. However, setting the value\n\t\t * to zero results in the MPI job failing. This appears to\n\t\t * be due to a bug in IBM's NRT library. */\n\t\t/* jp->tables_per_task = 0; */\n\t}\n\tif ((adapter_type == NRT_HFI) && jp->user_space) {\n\t\tjp->cau_indexes = (uint16_t) cau;\n\t\tjp->immed_slots = (uint16_t) immed;\n\t} else {\n\t\t/* The table load will always fail if cau_indexes or\n\t\t * immed_slots are non-zero unless running on an HFI network\n\t\t * with User Space communications, so ignore user options.\n\t\t * Alternately we can check for non-zero user option and\n\t\t * return SLURM_FAILURE here. */\n\t\tif ((cau != 0) || (immed != 0)) {\n\t\t\tdebug(\"switch/nrt: cau:%hu immed:%hu ignored for job\",\n\t\t\t      cau, immed);\n\t\t}\n\t\tjp->cau_indexes = 0;\n\t\tjp->immed_slots = 0;\n\t}\n\n\tif (instances <= 0) {\n\t\tinfo(\"switch/nrt: invalid instances specification (%d)\",\n\t\t     instances);\n\t\thostlist_iterator_destroy(hi);\n\t\treturn SLURM_FAILURE;\n\t}\n\tjp->tables_per_task *= instances;\n\n\tprotocol_table = _get_protocol_table(protocol);\n\tif ((protocol_table == NULL) ||\n\t    (protocol_table->protocol_table_cnt <= 0)) {\n\t\tinfo(\"switch/nrt: invalid protocol specification (%s)\",\n\t\t     protocol);\n\t\txfree(protocol_table);\n\t\thostlist_iterator_destroy(hi);\n\t\treturn SLURM_FAILURE;\n\t}\n\tjp->tables_per_task *= protocol_table->protocol_table_cnt;\n\n\t/* Allocate memory for each nrt_tableinfo_t */\n\tjp->tableinfo = (nrt_tableinfo_t *) xmalloc(jp->tables_per_task *\n\t\t\t\t\t\t    sizeof(nrt_tableinfo_t));\n\tfor (i = 0; i < jp->tables_per_task; i++) {\n\t\tjp->tableinfo[i].table_length = nprocs;\n\t\t/* jp->tableinfo[i].table allocated with windows function */\n\t}\n\n\tif (debug_flags & DEBUG_FLAG_SWITCH) {\n\t\tinfo(\"Allocating windows: adapter_name:%s adapter_type:%s\",\n\t\t     adapter_name, _adapter_type_str(adapter_type));\n\t} else {\n\t\tdebug3(\"Allocating windows\");\n\t}\n\n\tif (jp->tables_per_task) {\n\t\tslurm_mutex_lock(&global_lock);\n\t\tfor  (i = 0; i < nnodes; i++) {\n\t\t\thost = hostlist_next(hi);\n\t\t\tif (!host)\n\t\t\t\terror(\"Failed to get next host\");\n\n\t\t\tfor (j = 0; j < tasks_per_node[i]; j++) {\n\t\t\t\tif (adapter_name == NULL) {\n\t\t\t\t\trc = _allocate_windows_all(jp, host, i,\n\t\t\t\t\t\t\t\ttids[i][j],\n\t\t\t\t\t\t\t\tadapter_type,\n\t\t\t\t\t\t\t\tnetwork_id,\n\t\t\t\t\t\t\t\tprotocol_table,\n\t\t\t\t\t\t\t\tinstances, j);\n\t\t\t\t} else {\n\t\t\t\t\trc = _allocate_window_single(\n\t\t\t\t\t\t\t\tadapter_name,\n\t\t\t\t\t\t\t\tjp, host, i,\n\t\t\t\t\t\t\t\ttids[i][j],\n\t\t\t\t\t\t\t\tadapter_type,\n\t\t\t\t\t\t\t\tnetwork_id,\n\t\t\t\t\t\t\t\tprotocol_table,\n\t\t\t\t\t\t\t\tinstances, j);\n\t\t\t\t}\n\t\t\t\tif (rc != SLURM_SUCCESS) {\n\t\t\t\t\tslurm_mutex_unlock(&global_lock);\n\t\t\t\t\tgoto fail;\n\t\t\t\t}\n\t\t\t}\n\t\t\tfree(host);\n\t\t}\n\t\tslurm_mutex_unlock(&global_lock);\n\t}\n\n\n\tif (debug_flags & DEBUG_FLAG_SWITCH) {\n\t\tinfo(\"nrt_build_jobinfo\");\n\t\t_print_jobinfo(jp);\n\t}\n\n\thostlist_iterator_destroy(hi);\n\txfree(protocol_table);\n\treturn SLURM_SUCCESS;\n\nfail:\n\tfree(host);\n\thostlist_iterator_destroy(hi);\n\txfree(protocol_table);\n\t(void) nrt_job_step_complete(jp, hl);\t/* Release resources already\n\t\t\t\t\t\t * allocated */\n\t/* slurmctld will call nrt_free_jobinfo(jp) to free memory */\n\treturn SLURM_FAILURE;\n}\n\nstatic void\n_pack_tableinfo(nrt_tableinfo_t *tableinfo, Buf buf, slurm_nrt_jobinfo_t *jp,\n\t\tuint16_t protocol_version)\n{\n\tuint32_t adapter_type;\n\tbool ip_v4;\n\tint i, j;\n\n\txassert(tableinfo);\n\txassert(jp);\n\n\tip_v4 = jp->ip_v4;\n\tpackmem(tableinfo->adapter_name, NRT_MAX_ADAPTER_NAME_LEN, buf);\n\tadapter_type = tableinfo->adapter_type;\n\tpack32(adapter_type, buf);\n\tpack16(tableinfo->context_id, buf);\n\tpack32(tableinfo->instance, buf);\n\tpack64(tableinfo->network_id, buf);\n\tpackmem(tableinfo->protocol_name, NRT_MAX_PROTO_NAME_LEN, buf);\n\tif (!jp->user_space)\n\t\tadapter_type = NRT_IPONLY;\n\tpack16(tableinfo->table_id, buf);\n\tpack32(tableinfo->table_length, buf);\n\n\tif (adapter_type == NRT_IB) {\n\t\tnrt_ib_task_info_t *ib_tbl_ptr;\n\t\tfor (i = 0, ib_tbl_ptr = tableinfo->table;\n\t\t     i < tableinfo->table_length;\n\t\t     i++, ib_tbl_ptr++) {\n\t\t\tpackmem(ib_tbl_ptr->device_name,\n\t\t\t\tNRT_MAX_DEVICENAME_SIZE, buf);\n\t\t\tpack32(ib_tbl_ptr->base_lid, buf);\n\t\t\tpack8(ib_tbl_ptr->lmc, buf);\n\t\t\tpack32(ib_tbl_ptr->node_number, buf);\n\t\t\tpack8(ib_tbl_ptr->port_id, buf);\n\t\t\tpack32(ib_tbl_ptr->task_id, buf);\n\t\t\tpack16(ib_tbl_ptr->win_id, buf);\n\t\t}\n\t} else if (adapter_type == NRT_IPONLY) {\n\t\tnrt_ip_task_info_t *ip_tbl_ptr;\n\t\tfor (i = 0, ip_tbl_ptr = tableinfo->table;\n\t\t     i < tableinfo->table_length;\n\t\t     i++, ip_tbl_ptr++) {\n\t\t\tif (ip_v4) {\n\t\t\t\tpackmem((char *) &ip_tbl_ptr->ip.ipv4_addr,\n\t\t\t\t\tsizeof(in_addr_t), buf);\n\t\t\t} else {\n\t\t\t\tfor (j = 0; j < 16; j++) {\n\t\t\t\t\tpack8(ip_tbl_ptr->ip.ipv6_addr.\n\t\t\t\t\t      s6_addr[j], buf);\n\t\t\t\t}\n\t\t\t}\n\t\t\tpack32(ip_tbl_ptr->node_number, buf);\n\t\t\tpack16(ip_tbl_ptr->reserved, buf);\n\t\t\tpack32(ip_tbl_ptr->task_id, buf);\n\t\t}\n\t} else if (adapter_type == NRT_HFI) {\n\t\tnrt_hfi_task_info_t *hfi_tbl_ptr;\n\t\tfor (i = 0, hfi_tbl_ptr = tableinfo->table;\n\t\t     i < tableinfo->table_length;\n\t\t     i++, hfi_tbl_ptr++) {\n\t\t\tuint16_t tmp_16;\n\t\t\tuint8_t  tmp_8;\n\t\t\tpack32(hfi_tbl_ptr->task_id, buf);\n\t\t\ttmp_16 = hfi_tbl_ptr->lid;\n\t\t\tpack16(tmp_16, buf);\n\t\t\ttmp_8 = hfi_tbl_ptr->lpar_id;\n\t\t\tpack8(tmp_8, buf);\n\t\t\ttmp_8 = hfi_tbl_ptr->win_id;\n\t\t\tpack8(tmp_8, buf);\n\t\t}\n\t}\n#if NRT_VERSION < 1300\n\telse if ((adapter_type == NRT_HPCE) || (adapter_type == NRT_KMUX)) {\n\t\tnrt_hpce_task_info_t *hpce_tbl_ptr;\n\t\tfor (i = 0, hpce_tbl_ptr = tableinfo->table;\n\t\t     i < tableinfo->table_length;\n\t\t     i++, hpce_tbl_ptr++) {\n\t\t\tpack32(hpce_tbl_ptr->task_id, buf);\n\t\t\tpack16(hpce_tbl_ptr->win_id, buf);\n\t\t\tpack32(hpce_tbl_ptr->node_number, buf);\n\t\t\tpackmem(hpce_tbl_ptr->device_name,\n\t\t\t\tNRT_MAX_DEVICENAME_SIZE, buf);\n\t\t}\n\t}\n#endif\n\telse {\n\t\terror(\"_pack_tableinfo: Missing support for adapter type %s\",\n\t\t      _adapter_type_str(adapter_type));\n\t}\n}\n\n/* Used by: all */\nextern int\nnrt_pack_jobinfo(slurm_nrt_jobinfo_t *j, Buf buf, uint16_t protocol_version)\n{\n\tint i;\n\n\txassert(buf);\n\n\t/*\n\t * There is nothing to pack, so pack in magic telling unpack not to\n\t * attempt to unpack anything.\n\t */\n\tif ((j == NULL) || (j->magic == NRT_NULL_MAGIC)) {\n\t\tpack32(NRT_NULL_MAGIC, buf);\n\t\treturn SLURM_SUCCESS;\n\t}\n\n\txassert(j->magic == NRT_JOBINFO_MAGIC);\n\n\tif (debug_flags & DEBUG_FLAG_SWITCH) {\n\t\tinfo(\"nrt_pack_jobinfo:\");\n\t\t_print_jobinfo(j);\n\t}\n\n\tpack32(j->magic, buf);\n\tpack32(j->job_key, buf);\n\tpack8(j->bulk_xfer, buf);\n\tpack32(j->bulk_xfer_resources, buf);\n\tpack16(j->cau_indexes, buf);\n\tpack16(j->immed_slots, buf);\n\tpack8(j->ip_v4, buf);\n\tpack8(j->user_space, buf);\n\tpack16(j->tables_per_task, buf);\n\tpack32(j->num_tasks, buf);\n\n\tfor (i = 0; i < j->tables_per_task; i++)\n\t\t_pack_tableinfo(&j->tableinfo[i], buf, j, protocol_version);\n\n\treturn SLURM_SUCCESS;\n}\n\n/* return 0 on success, -1 on failure */\nstatic int\n_unpack_tableinfo(nrt_tableinfo_t *tableinfo, Buf buf, slurm_nrt_jobinfo_t *jp,\n\t\t  uint16_t protocol_version)\n{\n\tuint32_t tmp_32, adapter_type;\n\tuint16_t tmp_16;\n\tuint8_t  tmp_8;\n\tchar *name_ptr;\n\tint i, j;\n\tbool ip_v4;\n\n\txassert(jp);\n\txassert(tableinfo);\n\n\tsafe_unpackmem_ptr(&name_ptr, &tmp_32, buf);\n\tif (tmp_32 != NRT_MAX_ADAPTER_NAME_LEN)\n\t\tgoto unpack_error;\n\tmemcpy(tableinfo->adapter_name, name_ptr, tmp_32);\n\tsafe_unpack32(&adapter_type, buf);\n\ttableinfo->adapter_type = (int) adapter_type;\n\tsafe_unpack16(&tableinfo->context_id, buf);\n\tsafe_unpack32(&tableinfo->instance, buf);\n\tsafe_unpack64(&tableinfo->network_id, buf);\n\tsafe_unpackmem_ptr(&name_ptr, &tmp_32, buf);\n\tif (tmp_32 != NRT_MAX_PROTO_NAME_LEN)\n\t\tgoto unpack_error;\n\tmemcpy(tableinfo->protocol_name, name_ptr, tmp_32);\n\tip_v4 = jp->ip_v4;\n\tif (!jp->user_space)\n\t\tadapter_type = NRT_IPONLY;\n\tsafe_unpack16(&tableinfo->table_id, buf);\n\tsafe_unpack32(&tableinfo->table_length, buf);\n\n\tif (adapter_type == NRT_IB) {\n\t\tnrt_ib_task_info_t *ib_tbl_ptr;\n\t\ttableinfo->table = (nrt_ib_task_info_t *)\n\t\t\t\t   xmalloc(tableinfo->table_length *\n\t\t\t\t   sizeof(nrt_ib_task_info_t));\n\t\tfor (i = 0, ib_tbl_ptr = tableinfo->table;\n\t\t     i < tableinfo->table_length;\n\t\t     i++, ib_tbl_ptr++) {\n\t\t\tsafe_unpackmem(ib_tbl_ptr->device_name, &tmp_32, buf);\n\t\t\tif (tmp_32 != NRT_MAX_DEVICENAME_SIZE)\n\t\t\t\tgoto unpack_error;\n\t\t\tsafe_unpack32(&ib_tbl_ptr->base_lid, buf);\n\t\t\tsafe_unpack8(&ib_tbl_ptr->lmc, buf);\n\t\t\tsafe_unpack32(&ib_tbl_ptr->node_number, buf);\n\t\t\tsafe_unpack8(&ib_tbl_ptr->port_id, buf);\n\t\t\tsafe_unpack32(&ib_tbl_ptr->task_id, buf);\n\t\t\tsafe_unpack16(&ib_tbl_ptr->win_id, buf);\n\t\t}\n\t} else if (adapter_type == NRT_IPONLY) {\n\t\tnrt_ip_task_info_t *ip_tbl_ptr;\n\t\ttableinfo->table = (nrt_ip_task_info_t *)\n\t\t\t\t   xmalloc(tableinfo->table_length *\n\t\t\t\t   sizeof(nrt_ip_task_info_t));\n\t\tfor (i = 0, ip_tbl_ptr = tableinfo->table;\n\t\t     i < tableinfo->table_length;\n\t\t     i++, ip_tbl_ptr++) {\n\t\t\tif (ip_v4) {\n\t\t\t\tsafe_unpackmem((char *)\n\t\t\t\t\t       &ip_tbl_ptr->ip.ipv4_addr,\n\t\t\t\t\t       &tmp_32, buf);\n\t\t\t\tif (tmp_32 != sizeof(in_addr_t))\n\t\t\t\t\tgoto unpack_error;\n\t\t\t} else {\n\t\t\t\tfor (j = 0; j < 16; j++) {\n\t\t\t\t\tsafe_unpack8(&ip_tbl_ptr->ip.ipv6_addr.\n\t\t\t\t\t\t     s6_addr[j], buf);\n\t\t\t\t}\n\t\t\t}\n\t\t\tsafe_unpack32(&ip_tbl_ptr->node_number, buf);\n\t\t\tsafe_unpack16(&ip_tbl_ptr->reserved, buf);\n\t\t\tsafe_unpack32(&ip_tbl_ptr->task_id, buf);\n\t\t}\n\t} else if (adapter_type == NRT_HFI) {\n\t\tnrt_hfi_task_info_t *hfi_tbl_ptr;\n\t\ttableinfo->table = (nrt_hfi_task_info_t *)\n\t\t\t\t   xmalloc(tableinfo->table_length *\n\t\t\t\t   sizeof(nrt_hfi_task_info_t));\n\t\tfor (i = 0, hfi_tbl_ptr = tableinfo->table;\n\t\t     i < tableinfo->table_length;\n\t\t     i++, hfi_tbl_ptr++) {\n\n\t\t\tsafe_unpack32(&hfi_tbl_ptr->task_id, buf);\n\t\t\tsafe_unpack16(&tmp_16, buf);\n\t\t\thfi_tbl_ptr->lid = tmp_16;\n\t\t\tsafe_unpack8(&tmp_8, buf);\n\t\t\thfi_tbl_ptr->lpar_id = tmp_8;\n\t\t\tsafe_unpack8(&tmp_8, buf);\n\t\t\thfi_tbl_ptr->win_id = tmp_8;\n\t\t}\n\t}\n#if NRT_VERSION < 1300\n\telse if ((adapter_type == NRT_HPCE) || (adapter_type == NRT_KMUX)) {\n\t\tnrt_hpce_task_info_t *hpce_tbl_ptr;\n\t\ttableinfo->table = (nrt_hpce_task_info_t *)\n\t\t\t\t   xmalloc(tableinfo->table_length *\n\t\t\t\t   sizeof(nrt_hpce_task_info_t));\n\t\tfor (i = 0, hpce_tbl_ptr = tableinfo->table;\n\t\t     i < tableinfo->table_length;\n\t\t     i++, hpce_tbl_ptr++) {\n\t\t\tsafe_unpack32(&hpce_tbl_ptr->task_id, buf);\n\t\t\tsafe_unpack16(&hpce_tbl_ptr->win_id, buf);\n\t\t\tsafe_unpack32(&hpce_tbl_ptr->node_number, buf);\n\t\t\tsafe_unpackmem(hpce_tbl_ptr->device_name, &tmp_32,buf);\n\t\t\tif (tmp_32 != NRT_MAX_DEVICENAME_SIZE)\n\t\t\t\tgoto unpack_error;\n\t\t}\n\t}\n#endif\n\telse {\n\t\terror(\"_unpack_tableinfo: Missing support for adapter type %s\",\n\t\t      _adapter_type_str(adapter_type));\n\t}\n\n\treturn SLURM_SUCCESS;\n\nunpack_error: /* safe_unpackXX are macros which jump to unpack_error */\n\terror(\"unpack error in _unpack_tableinfo\");\n\treturn SLURM_ERROR;\n}\n\n/* Used by: all */\nextern int\nnrt_unpack_jobinfo(slurm_nrt_jobinfo_t **j_pptr, Buf buf,\n\t\t   uint16_t protocol_version)\n{\n\tint i;\n\tslurm_nrt_jobinfo_t *j;\n\n\txassert(j_pptr);\n\txassert(buf);\n\n\tnrt_alloc_jobinfo(j_pptr);\n\tj = *j_pptr;\n\n\tsafe_unpack32(&j->magic, buf);\n\n\tif (j->magic == NRT_NULL_MAGIC) {\n\t\tdebug2(\"(%s: %d: %s) Nothing to unpack.\",\n\t\t       THIS_FILE, __LINE__, __func__);\n\t\treturn SLURM_SUCCESS;\n\t}\n\n\txassert(j->magic == NRT_JOBINFO_MAGIC);\n\n\tsafe_unpack32(&j->job_key, buf);\n\tsafe_unpack8(&j->bulk_xfer, buf);\n\tsafe_unpack32(&j->bulk_xfer_resources, buf);\n\tsafe_unpack16(&j->cau_indexes, buf);\n\tsafe_unpack16(&j->immed_slots, buf);\n\tsafe_unpack8(&j->ip_v4, buf);\n\tsafe_unpack8(&j->user_space, buf);\n\tsafe_unpack16(&j->tables_per_task, buf);\n\tsafe_unpack32(&j->num_tasks, buf);\n\n\tj->tableinfo = (nrt_tableinfo_t *) xmalloc(j->tables_per_task *\n\t\t\t\t\t\t   sizeof(nrt_tableinfo_t));\n\tfor (i = 0; i < j->tables_per_task; i++) {\n\t\tif (_unpack_tableinfo(&j->tableinfo[i], buf, j,\n\t\t\t\t      protocol_version))\n\t\t\tgoto unpack_error;\n\t}\n\n\tif (debug_flags & DEBUG_FLAG_SWITCH) {\n\t\tinfo(\"nrt_unpack_jobinfo:\");\n\t\t_print_jobinfo(j);\n\t}\n\n\treturn SLURM_SUCCESS;\n\nunpack_error:\n\terror(\"nrt_unpack_jobinfo error\");\n\n\tnrt_free_jobinfo(*j_pptr);\n\t*j_pptr = NULL;\n\n\tslurm_seterrno_ret(EUNPACK);\n\treturn SLURM_ERROR;\n}\n\n/* Used by: all */\nextern void\nnrt_free_jobinfo(slurm_nrt_jobinfo_t *jp)\n{\n\tint i;\n\tnrt_tableinfo_t *tableinfo;\n\n\tif (!jp)\n\t\treturn;\n\n\tif (jp->magic != NRT_JOBINFO_MAGIC) {\n\t\terror(\"jp is not a switch/nrt slurm_nrt_jobinfo_t\");\n\t\treturn;\n\t}\n\n\tjp->magic = 0;\n\tif ((jp->tables_per_task > 0) && (jp->tableinfo != NULL)) {\n\t\tfor (i = 0; i < jp->tables_per_task; i++) {\n\t\t\ttableinfo = &jp->tableinfo[i];\n\t\t\txfree(tableinfo->table);\n\t\t}\n\t}\n\txfree(jp->tableinfo);\n\tif (jp->nodenames)\n\t\thostlist_destroy(jp->nodenames);\n\n\txfree(jp);\n\tjp = NULL;\n\n\treturn;\n}\n\n/* Return data to code for which jobinfo is an opaque type.\n *\n * Used by: all\n */\nextern int\nnrt_get_jobinfo(slurm_nrt_jobinfo_t *jp, int key, void *data)\n{\n\tnrt_tableinfo_t **tableinfo = (nrt_tableinfo_t **) data;\n\tint *tables_per = (int *) data;\n\tint *job_key = (int *) data;\n\n\tif ((jp == NULL) || (jp->magic == NRT_NULL_MAGIC)) {\n\t\tdebug2(\"(%s: %d: %s) job->switch_job was NULL\",\n\t\t       THIS_FILE, __LINE__, __func__);\n\t\treturn SLURM_SUCCESS;\n\t}\n\n\txassert(jp->magic == NRT_JOBINFO_MAGIC);\n\n\tswitch (key) {\n\t\tcase NRT_JOBINFO_TABLEINFO:\n\t\t\t*tableinfo = jp->tableinfo;\n\t\t\tbreak;\n\t\tcase NRT_JOBINFO_TABLESPERTASK:\n\t\t\t*tables_per = (int) jp->tables_per_task;\n\t\t\tbreak;\n\t\tcase NRT_JOBINFO_KEY:\n\t\t\t*job_key = (int) jp->job_key;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tslurm_seterrno_ret(EINVAL);\n\t}\n\n\treturn SLURM_SUCCESS;\n}\n\n/*\n * Check up to \"retry\" times for \"window_id\" on \"adapter_name\"\n * to switch to the NRT_WIN_AVAILABLE.  Sleep one second between\n * each retry.\n *\n * Used by: slurmd\n */\nstatic int\n_wait_for_window_unloaded(char *adapter_name, nrt_adapter_t adapter_type,\n\t\t\t  nrt_window_id_t window_id, int retry)\n{\n\tint err, i, j;\n\tint rc = SLURM_ERROR;\n\tnrt_cmd_status_adapter_t status_adapter;\n\tnrt_status_t *status_array = NULL;\n\tnrt_window_id_t window_count;\n\n\tstatus_adapter.adapter_name = adapter_name;\n\tstatus_adapter.adapter_type = adapter_type;\n\tstatus_adapter.status_array = &status_array;\n\tstatus_adapter.window_count = &window_count;\n\n\tfor (i = 0; i < retry; i++) {\n\t\tif (i > 0)\n\t\t\tusleep(100000);\n\n\t\tif (status_array) {\n\t\t\tfree(status_array);\n\t\t\tstatus_array = NULL;\n\t\t}\n\t\terr = nrt_cmd_wrap(NRT_VERSION, NRT_CMD_STATUS_ADAPTER,\n\t\t\t\t   &status_adapter);\n\t\tif (err != NRT_SUCCESS) {\n\t\t\terror(\"nrt_status_adapter(%s, %s): %s\", adapter_name,\n\t\t\t      _adapter_type_str(adapter_type),\n\t\t\t      nrt_err_str(err));\n\t\t\tbreak;\n\t\t}\n\t\tif (debug_flags & DEBUG_FLAG_SWITCH) {\n\t\t\tinfo(\"_wait_for_window_unloaded\");\n\t\t\t_print_adapter_status(&status_adapter);\n\t\t}\n\t\tif (!status_array)\t/* Fix for CLANG false positive */\n\t\t\tbreak;\n\t\tfor (j = 0; j < window_count; j++) {\n\t\t\tif (status_array[j].window_id == window_id)\n\t\t\t\tbreak;\n\t\t}\n\t\tif (j >= window_count) {\n\t\t\terror(\"nrt_status_adapter(%s, %s), window %hu not \"\n\t\t\t      \"found\",\n\t\t\t      adapter_name, _adapter_type_str(adapter_type),\n\t\t\t      window_id);\n\t\t\tbreak;\n\t\t}\n\t\tdebug2(\"nrt_status_adapter(%s, %s), window %u state %s\",\n\t\t       adapter_name,\n\t\t       _adapter_type_str(adapter_type), window_id,\n\t\t       _win_state_str(status_array[j].state));\n\t\tif (status_array[j].state == NRT_WIN_AVAILABLE) {\n\t\t\trc = SLURM_SUCCESS;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (status_array)\n\t\tfree(status_array);\n\n\treturn rc;\n}\n\n/*\n * Look through the table and find all of the NRT that are for an adapter on\n * this node.  Wait until the window from each local NRT is in the\n * NRT_WIN_AVAILABLE.\n *\n * Used by: slurmd\n */\nstatic int\n_wait_for_all_windows(nrt_tableinfo_t *tableinfo)\n{\n\tint err, i, rc = SLURM_SUCCESS;\n\tint retry = 15;\n\tnrt_window_id_t window_id = 0;\n\n\tif (!my_lpar_id_set && !my_network_id_set)\n\t\t_get_my_id();\n\n\tfor (i = 0; i < tableinfo->table_length; i++) {\n\t\tif (tableinfo->adapter_type == NRT_IB) {\n\t\t\tnrt_ib_task_info_t *ib_tbl_ptr;\n\t\t\tib_tbl_ptr = (nrt_ib_task_info_t *) tableinfo->table;\n\t\t\tib_tbl_ptr += i;\n\t\t\tif (ib_tbl_ptr->node_number != my_network_id)\n\t\t\t\tcontinue;\n\t\t\twindow_id = ib_tbl_ptr->win_id;\n\t\t} else if (tableinfo->adapter_type == NRT_HFI) {\n\t\t\tnrt_hfi_task_info_t *hfi_tbl_ptr;\n\t\t\thfi_tbl_ptr = (nrt_hfi_task_info_t *) tableinfo->table;\n\t\t\thfi_tbl_ptr += i;\n\t\t\tif ((hfi_tbl_ptr->lpar_id != my_lpar_id) ||\n\t\t\t    (hfi_tbl_ptr->lid != my_lid))\n\t\t\t\tcontinue;\n\t\t\twindow_id = hfi_tbl_ptr->win_id;\n\t\t}\n#if NRT_VERSION < 1300\n\t\telse if ((tableinfo->adapter_type == NRT_HPCE) ||\n\t\t           (tableinfo->adapter_type == NRT_KMUX)) {\n\t\t\tnrt_hpce_task_info_t *hpce_tbl_ptr;\n\t\t\thpce_tbl_ptr = (nrt_hpce_task_info_t *) tableinfo->\n\t\t\t\t\t\t\t\ttable;\n\t\t\thpce_tbl_ptr += i;\n\t\t\tif (hpce_tbl_ptr->node_number != my_network_id)\n\t\t\t\tcontinue;\n\t\t\twindow_id = hpce_tbl_ptr->win_id;\n\t\t}\n#endif\n\t\telse {\n\t\t\terror(\"_wait_for_all_windows: Missing support for \"\n\t\t\t      \"adapter_type %s\",\n\t\t\t      _adapter_type_str(tableinfo->adapter_type));\n\t\t}\n\n\t\terr = _wait_for_window_unloaded(tableinfo->adapter_name,\n\t\t\t\t\t\ttableinfo->adapter_type,\n\t\t\t\t\t\twindow_id, retry);\n\t\tif (err != SLURM_SUCCESS) {\n\t\t\terror(\"Window %hu adapter %s did not \"\n\t\t\t      \"become free within %d seconds\",\n\t\t\t      window_id, tableinfo->adapter_name, retry);\n\t\t\trc = err;\n\t\t}\n\t}\n\n\treturn rc;\n}\n\n/* Load a network table on node.  If table contains more than one window\n * for a given adapter, load the table only once for that adapter.\n *\n * Used by: slurmd\n *\n * Notes on context_id and table_id from Bill LePera, IBM, 6/7/2012:\n *\n * Each NRT is uniquely identified by a combination of three elements: job_key,\n * context_id, and table_id.  context_id and table_id usually start at zero and\n * are incremented based on how many NRTs are required to define all the\n * resources used for a job, based on factors like striping, instances, and\n * number of protocols.\n *\n * For example, a scheduler building an NRT for a job using a single protocol,\n * single network (no striping), and a single instance would set both\n * context_id and table_id to zero.  A multi-protocol job (one that used both\n * MPI and PAMI, for example), would build at least one NRT for each protocol.\n * In this case, there would be two NRTs, with context_id 0 and 1.  If you are\n * still using a single network and single instance, the table_id's for both\n * NRTs would be zero, and these would be the only two NRTs needed for the job.\n *\n * The table_id is incremented on a per-protocol basis, based on number of\n * networks (or stripes) and number of instances.  For example, a single-\n * protocol job running across two networks using four instances would need\n * 2 * 4 = 8 NRTs, with context_id set to 0 for each, and table_id 0 - 7.  If\n * this same job was a multi-protocol job, you would need 16 NRTs total\n * (2 protocols * 2 networks * 4 instances), with context_id 0 and 1, and\n * table_id 0-7 within each protocol.\n */\nextern int\nnrt_load_table(slurm_nrt_jobinfo_t *jp, int uid, int pid, char *job_name)\n{\n\tint i;\n\tint err;\n\tchar *adapter_name;\n\tint rc;\n\tnrt_cmd_load_table_t load_table;\n\tnrt_table_info_t table_info;\n\n\tif ((jp == NULL) || (jp->magic == NRT_NULL_MAGIC)) {\n\t\tdebug2(\"(%s: %d: %s) job->switch_job was NULL\",\n\t\t       THIS_FILE, __LINE__, __func__);\n\t\treturn SLURM_ERROR;\n\t}\n\n\txassert(jp->magic == NRT_JOBINFO_MAGIC);\n\n\tif (debug_flags & DEBUG_FLAG_SWITCH) {\n\t\tinfo(\"nrt_load_table\");\n\t\t_print_jobinfo(jp);\n\t}\n\n\tfor (i = 0; i < jp->tables_per_task; i++) {\n\t\tif (debug_flags & DEBUG_FLAG_SWITCH) {\n\t\t\tnrt_adapter_t adapter_type;\n\t\t\tif (jp->user_space)\n\t\t\t\tadapter_type = jp->tableinfo[i].adapter_type;\n\t\t\telse\n\t\t\t\tadapter_type = NRT_IPONLY;\n\t\t\t_print_table(jp->tableinfo[i].table,\n\t\t\t\t     jp->tableinfo[i].table_length,\n\t\t\t\t     adapter_type, jp->ip_v4);\n\t\t}\n\n\t\tadapter_name = jp->tableinfo[i].adapter_name;\n\t\tif (jp->user_space) {\n\t\t\trc = _wait_for_all_windows(&jp->tableinfo[i]);\n\t\t\tif (rc != SLURM_SUCCESS)\n\t\t\t\treturn rc;\n\t\t}\n\n\t\tif (adapter_name == NULL)\n\t\t\tcontinue;\n\n\t\tmemset(&table_info, 0, sizeof(nrt_table_info_t));\n\t\ttable_info.num_tasks = jp->tableinfo[i].table_length;\n\t\ttable_info.job_key = jp->job_key;\n\t\t/* Enable job preeption and release of resources */\n#ifdef PREEMPT_RELEASE_RESOURCES_MASK\n\t\ttable_info.job_options = PREEMPT_RELEASE_RESOURCES_MASK;\n#endif\n\t\ttable_info.uid = uid;\n\t\ttable_info.network_id = jp->tableinfo[i].network_id;\n\t\ttable_info.pid = pid;\n\t\ttable_info.adapter_type = jp->tableinfo[i].adapter_type;\n\t\tif (jp->user_space)\n\t\t\ttable_info.is_user_space = 1;\n\t\tif (jp->ip_v4)\n\t\t\ttable_info.is_ipv4 = 1;\n\t\t/* IP V6: table_info.is_ipv4 initialized above by memset() */\n\t\ttable_info.context_id = jp->tableinfo[i].context_id;\n\t\ttable_info.table_id = jp->tableinfo[i].table_id;\n\t\tif (job_name) {\n\t\t\tchar *sep = strrchr(job_name,'/');\n\t\t\tif (sep)\n\t\t\t\tsep++;\n\t\t\telse\n\t\t\t\tsep = job_name;\n\t\t\tstrlcpy(table_info.job_name, sep,\n\t\t\t\tNRT_MAX_JOB_NAME_LEN);\n\t\t} else {\n\t\t\ttable_info.job_name[0] = '\\0';\n\t\t}\n\t\tstrlcpy(table_info.protocol_name,\n\t\t\tjp->tableinfo[i].protocol_name,\n\t\t\tNRT_MAX_PROTO_NAME_LEN);\n\t\ttable_info.use_bulk_transfer = jp->bulk_xfer;\n\t\ttable_info.bulk_transfer_resources = jp->bulk_xfer_resources;\n\t\t/* The following fields only apply to Power7 processors\n\t\t * and have no effect on x86 processors:\n\t\t * immed_send_slots_per_win\n\t\t * num_cau_indexes */\n\t\ttable_info.num_cau_indexes = jp->cau_indexes;\n\t\ttable_info.immed_send_slots_per_win = jp->immed_slots;\n\t\tload_table.table_info = &table_info;\n\t\tload_table.per_task_input = jp->tableinfo[i].table;\n\n\t\tif (debug_flags & DEBUG_FLAG_SWITCH)\n\t\t\t_print_load_table(&load_table);\n\n\t\terr = nrt_cmd_wrap(NRT_VERSION, NRT_CMD_LOAD_TABLE,\n\t\t\t\t   &load_table);\n\t\tif (err != NRT_SUCCESS) {\n\t\t\terror(\"nrt_cmd_wrap(load table): %s\", nrt_err_str(err));\n\t\t\treturn SLURM_ERROR;\n\t\t}\n\t}\n\tumask(nrt_umask);\n\n\tif (debug_flags & DEBUG_FLAG_SWITCH)\n\t\tinfo(\"nrt_load_table complete\");\n\n\treturn SLURM_SUCCESS;\n}\n\nstatic int\n_unload_window_all_jobs(char *adapter_name, nrt_adapter_t adapter_type,\n\t\t\tnrt_window_id_t window_id)\n{\n\tint err, i;\n\tnrt_cmd_unload_window_t unload_window;\n\tnrt_cmd_query_jobs_t nrt_jobs;\n\tnrt_job_key_t job_count, *job_keys = NULL;\n\n\tnrt_jobs.adapter_name = adapter_name;\n\tnrt_jobs.adapter_type = adapter_type;\n\tnrt_jobs.job_count = &job_count;\n\tnrt_jobs.job_keys = &job_keys;\n\terr = nrt_cmd_wrap(NRT_VERSION, NRT_CMD_QUERY_JOBS, &nrt_jobs);\n\tif (err != NRT_SUCCESS) {\n\t\terror(\"nrt_cmd_wrap(query_jobs, %s, %s): %s\",\n\t\t       adapter_name, _adapter_type_str(adapter_type),\n\t\t       nrt_err_str(err));\n\t\tif (job_keys)\n\t\t\tfree(job_keys);\n\t\treturn err;\n\t}\n\n\tfor (i = 0; i < job_count; i++) {\n\t\tunload_window.adapter_name = adapter_name;\n\t\tunload_window.adapter_type = adapter_type;\n\t\tunload_window.job_key = job_keys[i];\n\t\tunload_window.window_id = window_id;\n\n\t\terr = nrt_cmd_wrap(NRT_VERSION, NRT_CMD_UNLOAD_WINDOW,\n\t\t\t\t   &unload_window);\n\t\tif (err == NRT_SUCCESS) {\n\t\t\tinfo(\"nrt_cmd_wrap(unload_window, %s, %s, %u, %hu)\",\n\t\t\t      adapter_name, _adapter_type_str(adapter_type),\n\t\t\t      job_keys[i], window_id);\n\t\t}\n\t}\n\n\tif (job_keys)\n\t\tfree(job_keys);\n\treturn SLURM_FAILURE;\n}\n\nstatic int _unload_job_table(slurm_nrt_jobinfo_t *jp)\n{\n\tint err, i, rc = SLURM_SUCCESS;\n\tnrt_cmd_unload_table_t unload_table;\n\n\tunload_table.job_key = jp->job_key;\n\tfor (i = 0; i < jp->tables_per_task; i++) {\n\t\tunload_table.context_id = jp->tableinfo[i].context_id;\n\t\tunload_table.table_id   = jp->tableinfo[i].table_id;\n\t\tif (debug_flags & DEBUG_FLAG_SWITCH) {\n\t\t\tinfo(\"Unload table for job_key:%u \"\n\t\t\t     \"context_id:%u table_id:%u\",\n\t\t\t     unload_table.job_key, unload_table.context_id,\n\t\t\t     unload_table.table_id);\n\t\t\t}\n\t\terr = nrt_cmd_wrap(NRT_VERSION, NRT_CMD_UNLOAD_TABLE,\n\t\t\t\t   &unload_table);\n\t\tif (err != NRT_SUCCESS) {\n\t\t\terror(\"Unable to unload table for job_key:%u \"\n\t\t\t      \"context_id:%u table_id:%u error:%s\",\n\t\t\t      unload_table.job_key, unload_table.context_id,\n\t\t\t      unload_table.table_id, nrt_err_str(err));\n\t\t\trc = SLURM_ERROR;\n\t\t}\n\t}\n\treturn rc;\n}\n\n/* Assumes that, on error, new switch state information will be\n * read from node.\n *\n * Used by: slurmd\n */\nextern int\nnrt_unload_table(slurm_nrt_jobinfo_t *jp)\n{\n\tif ((jp == NULL) || (jp->magic == NRT_NULL_MAGIC)) {\n\t\tdebug2(\"(%s: %d: %s) job->switch_job was NULL\",\n\t\t       THIS_FILE, __LINE__, __func__);\n\t\treturn SLURM_ERROR;\n\t}\n\n\txassert(jp->magic == NRT_JOBINFO_MAGIC);\n\n\tif (debug_flags & DEBUG_FLAG_SWITCH) {\n\t\tinfo(\"nrt_unload_table\");\n\t\t_print_jobinfo(jp);\n\t}\n\n\treturn _unload_job_table(jp);\n}\n\nextern int\nnrt_fini(void)\n{\n\treturn SLURM_SUCCESS;\n}\n\nstatic void\n_free_libstate(slurm_nrt_libstate_t *lp)\n{\n\tint i;\n\n\tif (!lp)\n\t\treturn;\n\tif (lp->node_list != NULL) {\n\t\tfor (i = 0; i < lp->node_count; i++)\n\t\t\tnrt_free_nodeinfo(&lp->node_list[i], true);\n\t\txfree(lp->node_list);\n\t}\n\txfree(lp->hash_table);\n\txfree(lp);\n}\n\n/* Used by: slurmctld */\nstatic int\n_pack_libstate(slurm_nrt_libstate_t *lp, Buf buffer, uint16_t protocol_version)\n{\n\tint offset;\n\tint i;\n\n\txassert(lp);\n\txassert(lp->magic == NRT_LIBSTATE_MAGIC);\n\n\tif (debug_flags & DEBUG_FLAG_SWITCH) {\n \t\tinfo(\"_pack_libstate\");\n\t\t_print_libstate(lp);\n\t}\n\n\toffset = get_buf_offset(buffer);\n\tpackstr(NRT_STATE_VERSION, buffer);\n\tpack16(SLURM_PROTOCOL_VERSION, buffer);\n\tpack32(lp->magic, buffer);\n\tpack32(lp->node_count, buffer);\n\tfor (i = 0; i < lp->node_count; i++)\n\t\t(void)nrt_pack_nodeinfo(&lp->node_list[i], buffer,\n\t\t\t\t\tprotocol_version);\n\t/* don't pack hash_table, we'll just rebuild on restore */\n\tpack32(lp->key_index, buffer);\n\n\treturn(get_buf_offset(buffer) - offset);\n}\n\n/* Used by: slurmctld */\nextern void\nnrt_libstate_save(Buf buffer, bool free_flag)\n{\n\tslurm_mutex_lock(&global_lock);\n\n\tif (nrt_state != NULL)\n\t\t_pack_libstate(nrt_state, buffer, SLURM_PROTOCOL_VERSION);\n\n\t/* Clean up nrt_state since backup slurmctld can repeatedly\n\t * save and restore state */\n\tif (free_flag) {\n\t\t_free_libstate(nrt_state);\n\t\tnrt_state = NULL;\t/* freed above */\n\t}\n\tslurm_mutex_unlock(&global_lock);\n}\n\n/* Used by: slurmctld */\nstatic int\n_unpack_libstate(slurm_nrt_libstate_t *lp, Buf buffer)\n{\n\tchar *ver_str = NULL;\n\tuint32_t ver_str_len;\n\tuint16_t protocol_version = NO_VAL16;\n\tuint32_t node_count;\n\tint i;\n\n\t/* Validate state version */\n\tsafe_unpackstr_xmalloc(&ver_str, &ver_str_len, buffer);\n\tdebug3(\"Version string in job_state header is %s\", ver_str);\n\tif (ver_str && !xstrcmp(ver_str, NRT_STATE_VERSION))\n\t\tsafe_unpack16(&protocol_version, buffer);\n\n\tif (protocol_version == NO_VAL16) {\n\t\terror(\"******************************************************\");\n\t\terror(\"Can not recover switch/nrt state, incompatible version\");\n\t\terror(\"******************************************************\");\n\t\txfree(ver_str);\n\t\treturn EFAULT;\n\t}\n\txfree(ver_str);\n\n\txassert(lp->magic == NRT_LIBSTATE_MAGIC);\n\tsafe_unpack32(&lp->magic, buffer);\n\tsafe_unpack32(&node_count, buffer);\n\tfor (i = 0; i < node_count; i++) {\n\t\tif (_unpack_nodeinfo(NULL, buffer, false,\n\t\t\t\t     protocol_version) != SLURM_SUCCESS)\n\t\t\tgoto unpack_error;\n\t}\n\tif (lp->node_count != node_count) {\n\t\terror(\"Failed to recover switch state of all nodes (%u of %u)\",\n\t\t      lp->node_count, node_count);\n\t\treturn SLURM_ERROR;\n\t}\n\tsafe_unpack32(&lp->key_index, buffer);\n\n\tif (debug_flags & DEBUG_FLAG_SWITCH) {\n\t \tinfo(\"_unpack_libstate\");\n\t\t_print_libstate(lp);\n\t}\n\n\treturn SLURM_SUCCESS;\n\nunpack_error:\n\terror(\"unpack error in _unpack_libstate\");\n\tslurm_seterrno_ret(EBADMAGIC_NRT_LIBSTATE);\n\treturn SLURM_ERROR;\n}\n\n/* Used by: slurmctld */\nextern int\nnrt_libstate_restore(Buf buffer)\n{\n\tint rc;\n\n\tslurm_mutex_lock(&global_lock);\n\txassert(!nrt_state);\n\n\tnrt_state = _alloc_libstate();\n\tif (!nrt_state) {\n\t\terror(\"nrt_libstate_restore nrt_state is NULL\");\n\t\tslurm_mutex_unlock(&global_lock);\n\t\treturn SLURM_FAILURE;\n\t}\n\trc = _unpack_libstate(nrt_state, buffer);\n\tslurm_mutex_unlock(&global_lock);\n\n\treturn rc;\n}\n\nextern int\nnrt_libstate_clear(void)\n{\n\tint i, j, k;\n\tslurm_nrt_nodeinfo_t *node;\n\tslurm_nrt_adapter_t *adapter;\n\tslurm_nrt_window_t *window;\n\n\n\tif (debug_flags & DEBUG_FLAG_SWITCH)\n\t\tinfo(\"Clearing state on all windows in global NRT state\");\n\telse\n\t\tdebug3(\"Clearing state on all windows in global NRT state\");\n\n\tslurm_mutex_lock(&global_lock);\n\tif (!nrt_state || !nrt_state->node_list) {\n\t\terror(\"nrt_state or node_list not initialized!\");\n\t\tslurm_mutex_unlock(&global_lock);\n\t\treturn SLURM_ERROR;\n\t}\n\n\tfor (i = 0; i < nrt_state->node_count; i++) {\n\t\tnode = &nrt_state->node_list[i];\n\t\tif (!node->adapter_list)\n\t\t\tcontinue;\n\t\tfor (j = 0; j < node->adapter_count; j++) {\n\t\t\tadapter = &node->adapter_list[i];\n\t\t\tif (!adapter || !adapter->window_list)\n\t\t\t\tcontinue;\n\t\t\tfor (k = 0; k < adapter->window_count; k++) {\n\t\t\t\twindow = &adapter->window_list[k];\n\t\t\t\tif (!window)\n\t\t\t\t\tcontinue;\n\t\t\t\twindow->state = NRT_WIN_UNAVAILABLE;\n\t\t\t}\n\t\t}\n\t}\n\tslurm_mutex_unlock(&global_lock);\n\n\treturn SLURM_SUCCESS;\n}\n\nextern int\nnrt_clear_node_state(void)\n{\n\tstatic bool first_use = true;\n\tint err, i, j, k, rc = SLURM_SUCCESS;\n\tnrt_cmd_query_adapter_types_t adapter_types;\n\tunsigned int num_adapter_types;\n\tnrt_adapter_t adapter_type[NRT_MAX_ADAPTER_TYPES];\n\tnrt_cmd_query_adapter_names_t adapter_names;\n\tunsigned int max_windows, num_adapter_names;\n\tnrt_cmd_status_adapter_t adapter_status;\n\tnrt_window_id_t window_count;\n\tnrt_status_t *status_array = NULL;\n\twin_state_t state;\n\tnrt_cmd_clean_window_t clean_window;\n\tchar window_str[128];\n\tbool orphan_procs = false;\n\thostset_t hs = NULL;\n\n\tif (debug_flags & DEBUG_FLAG_SWITCH)\n\t\tinfo(\"nrt_clear_node_state: begin\");\n\n\tadapter_types.num_adapter_types = &num_adapter_types;\n\tadapter_types.adapter_types = adapter_type;\n\tfor (i = 0; i < 2; i++) {\n\t\terr = nrt_cmd_wrap(NRT_VERSION, NRT_CMD_QUERY_ADAPTER_TYPES,\n\t\t\t\t   &adapter_types);\n\t\tif (err != NRT_EAGAIN)\n\t\t\tbreak;\n\t\terror(\"nrt_cmd_wrap(adapter_types): %s\", nrt_err_str(err));\n\t\terror(\"Is pnsd daemon started? Retrying...\");\n\t\t/* Run \"/opt/ibmhpc/pecurrent/ppe.pami/pnsd/pnsd -A\" */\n\t\tsleep(5);\n\t}\n\tif (err != NRT_SUCCESS) {\n\t\terror(\"nrt_cmd_wrap(adapter_types): %s\", nrt_err_str(err));\n\t\treturn SLURM_ERROR;\n\t}\n\tif (debug_flags & DEBUG_FLAG_SWITCH) {\n\t\tfor (i = 0; i < num_adapter_types; i++) {\n\t\t\tinfo(\"nrt_cmd_wrap(adapter_types): %s\",\n\t\t\t    _adapter_type_str(adapter_types.adapter_types[i]));\n\t\t}\n\t}\n\n\tfor (i = 0; i < num_adapter_types; i++) {\n\t\tadapter_names.adapter_type = adapter_type[i];\n\t\tadapter_names.num_adapter_names = &num_adapter_names;\n\t\tadapter_names.max_windows = &max_windows;\n\t\terr = nrt_cmd_wrap(NRT_VERSION, NRT_CMD_QUERY_ADAPTER_NAMES,\n\t\t\t\t   &adapter_names);\n\t\tif (err != NRT_SUCCESS) {\n\t\t\terror(\"nrt_cmd_wrap(adapter_names, %s): %s\",\n\t\t\t      _adapter_type_str(adapter_names.adapter_type),\n\t\t\t      nrt_err_str(err));\n\t\t\trc = SLURM_ERROR;\n\t\t\tcontinue;\n\t\t}\n\t\tif (debug_flags & DEBUG_FLAG_SWITCH) {\n\t\t\tfor (j = 0; j < num_adapter_names; j++) {\n\t\t\t\tinfo(\"nrt_cmd_wrap(adapter_names, %s, %s) \"\n\t\t\t\t     \"max_windows: %hu\",\n\t\t\t\t     adapter_names.adapter_names[j],\n\t\t\t\t     _adapter_type_str(adapter_names.\n\t\t\t\t\t\t       adapter_type),\n\t\t\t\t     max_windows);\n\t\t\t}\n\t\t}\n\n\t\tfor (j = 0; j < num_adapter_names; j++) {\n\t\t\tif (status_array) {\n\t\t\t\tfree(status_array);\n\t\t\t\tstatus_array = NULL;\n\t\t\t}\n\t\t\tadapter_status.adapter_name = adapter_names.\n\t\t\t\t\t\t      adapter_names[j];\n\t\t\tadapter_status.adapter_type = adapter_names.\n\t\t\t\t\t\t      adapter_type;\n\t\t\tadapter_status.status_array = &status_array;\n\t\t\tadapter_status.window_count = &window_count;\n\t\t\terr = nrt_cmd_wrap(NRT_VERSION, NRT_CMD_STATUS_ADAPTER,\n\t\t\t\t\t   &adapter_status);\n\t\t\tif (err != NRT_SUCCESS) {\n\t\t\t\terror(\"nrt_cmd_wrap(status_adapter, %s, %s): %s\",\n\t\t\t\t      adapter_status.adapter_name,\n\t\t\t\t      _adapter_type_str(adapter_status.\n\t\t\t\t\t\t\tadapter_type),\n\t\t\t\t      nrt_err_str(err));\n\t\t\t\trc = SLURM_ERROR;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (window_count > max_windows) {\n\t\t\t\t/* This happens if IP_ONLY devices are\n\t\t\t\t * allocated with tables_per_task > 0 */\n\t\t\t\tchar *reason;\n\t\t\t\tif (adapter_status.adapter_type == NRT_IPONLY)\n\t\t\t\t\treason = \", Known libnrt bug\";\n\t\t\t\telse\n\t\t\t\t\treason = \"\";\n\t\t\t\tif (first_use) {\n\t\t\t\t\terror(\"nrt_cmd_wrap(status_adapter, \"\n\t\t\t\t\t      \"%s, %s): window_count > \"\n\t\t\t\t\t      \"max_windows (%u > %hu)%s\",\n\t\t\t\t\t      adapter_status.adapter_name,\n\t\t\t\t\t      _adapter_type_str(adapter_status.\n\t\t\t\t\t\t\t\tadapter_type),\n\t\t\t\t\t      window_count, max_windows,\n\t\t\t\t\t      reason);\n\t\t\t\t} else {\n\t\t\t\t\tdebug(\"nrt_cmd_wrap(status_adapter, \"\n\t\t\t\t\t      \"%s, %s): window_count > \"\n\t\t\t\t\t      \"max_windows (%u > %hu)%s\",\n\t\t\t\t\t      adapter_status.adapter_name,\n\t\t\t\t\t      _adapter_type_str(adapter_status.\n\t\t\t\t\t\t\t\tadapter_type),\n\t\t\t\t\t      window_count, max_windows,\n\t\t\t\t\t      reason);\n\t\t\t\t}\n\t\t\t\t/* Reset value to avoid logging bad data */\n\t\t\t\twindow_count = max_windows;\n\t\t\t}\n\t\t\tif (debug_flags & DEBUG_FLAG_SWITCH) {\n\t\t\t\tinfo(\"nrt_cmd_wrap(status_adapter, %s, %s) \"\n\t\t\t\t     \"window_count: %hu\",\n\t\t\t\t     adapter_status.adapter_name,\n\t\t\t\t     _adapter_type_str(adapter_status.\n\t\t\t\t\t\t       adapter_type),\n\t\t\t\t     window_count);\n\t\t\t\tfor (k = 0; k < window_count; k++) {\n\t\t\t\t\twin_state_t state = status_array[k].\n\t\t\t\t\t\t\t    state;\n\t\t\t\t\tif ((state == NRT_WIN_AVAILABLE) &&\n\t\t\t\t\t    (k >= NRT_DEBUG_CNT))\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\tinfo(\"window_id:%d uid:%d pid:%d \"\n\t\t\t\t\t     \"state:%s\",\n\t\t\t\t\t     status_array[k].window_id,\n\t\t\t\t\t     status_array[k].uid,\n\t\t\t\t\t     status_array[k].client_pid,\n\t\t\t\t\t     _win_state_str(state));\n\t\t\t\t}\n\n\t\t\t\ths = hostset_create(\"\");\n\t\t\t}\n\t\t\tfor (k = 0; k < window_count; k++) {\n\t\t\t\tif (debug_flags & DEBUG_FLAG_SWITCH) {\n\t\t\t\t\tsnprintf(window_str,\n\t\t\t\t\t\t sizeof(window_str), \"%d\",\n\t\t\t\t\t\t clean_window.window_id);\n\t\t\t\t\thostset_insert(hs, window_str);\n\t\t\t\t}\n\t\t\t\tstate = status_array[k].state;\n\t\t\t\tif ((state == NRT_WIN_RESERVED) ||\n\t\t\t\t    (state == NRT_WIN_READY) ||\n\t\t\t\t    (state == NRT_WIN_RUNNING)) {\n\t\t\t\t\t_unload_window_all_jobs(\n\t\t\t\t\t\tadapter_status.adapter_name,\n\t\t\t\t\t\tadapter_status.adapter_type,\n\t\t\t\t\t\tstatus_array[k].window_id);\n\t\t\t\t}\n\t\t\t\tclean_window.adapter_name = adapter_names.\n\t\t\t\t\t\t\t    adapter_names[j];\n\t\t\t\tclean_window.adapter_type = adapter_names.\n\t\t\t\t\t\t\t    adapter_type;\n\t\t\t\tclean_window.leave_inuse_or_kill = KILL;\n\t\t\t\tclean_window.window_id = status_array[k].\n\t\t\t\t\t\t\t window_id;\n\t\t\t\terr = nrt_cmd_wrap(NRT_VERSION,\n\t\t\t\t\t\t   NRT_CMD_CLEAN_WINDOW,\n\t\t\t\t\t\t   &clean_window);\n\t\t\t\tif (err == NRT_WRONG_WINDOW_STATE)\n\t\t\t\t\torphan_procs = true;\n\t\t\t\tif (err != NRT_SUCCESS) {\n\t\t\t\t\terror(\"nrt_cmd_wrap(clean_window, \"\n\t\t\t\t\t      \"%s, %s, %u): %s\",\n\t\t\t\t\t      clean_window.adapter_name,\n\t\t\t\t\t      _adapter_type_str(clean_window.\n\t\t\t\t\t\t\t\tadapter_type),\n\t\t\t\t\t      clean_window.window_id,\n\t\t\t\t\t      nrt_err_str(err));\n\t\t\t\t\trc = SLURM_ERROR;\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (debug_flags & DEBUG_FLAG_SWITCH) {\n\t\t\t\tif (hostset_count(hs) > 0) {\n\t\t\t\t\thostset_ranged_string(hs,\n\t\t\t\t\t\t\t      sizeof(window_str),\n\t\t\t\t\t\t\t      window_str);\n\t\t\t\t\tinfo(\"nrt_cmd_wrap(clean_window, \"\n\t\t\t\t\t     \"%s, %s, %s)\",\n\t\t\t\t\t     adapter_names.adapter_names[j],\n\t\t\t\t\t     _adapter_type_str(adapter_names.\n\t\t\t\t\t\t\t       adapter_type),\n\t\t\t\t\t     window_str);\n\t\t\t\t}\n\t\t\t\thostset_destroy(hs);\n\t\t\t}\n\t\t}\n\t}\n\tif (status_array)\n\t\tfree(status_array);\n\tif (debug_flags & DEBUG_FLAG_SWITCH)\n\t\tinfo(\"nrt_clear_node_state: complete:%d\", rc);\n\tif (orphan_procs) {\n\t\terror(\"switch/nrt: THERE APPEAR TO BE ORPHAN PROCESSES \"\n\t\t      \"HOLDING SWITCH WINDOWS\");\n\t\terror(\"switch/nrt: You must manually find and kill these \"\n\t\t      \"processes before using this node\");\n\t\terror(\"switch/nrt: Use of ProctrackType=proctrack/cgroup \"\n\t\t      \"generally prevents this\");\n\t}\n\n\treturn rc;\n}\n\nextern char *nrt_err_str(int rc)\n{\n\tstatic char str[16];\n\n\tswitch (rc) {\n\tcase NRT_ALREADY_LOADED:\n\t\treturn \"Already loaded\";\n\tcase NRT_BAD_VERSION:\n\t\treturn \"Bad version\";\n\tcase NRT_CAU_EXCEEDED:\n\t\treturn \"CAU index request exeeds available resources\";\n\tcase NRT_CAU_RESERVE:\n\t\treturn \"Error during CAU index reserve\";\n\tcase NRT_CAU_UNRESERVE:\n\t\treturn \"Error during CAU index unreserve\";\n\tcase NRT_EADAPTER:\n\t\treturn \"Invalid adapter name\";\n\tcase NRT_EADAPTYPE:\n\t\treturn \"Invalid adapter type\";\n\tcase NRT_EAGAIN:\n\t\treturn \"Try call again later\";\n\tcase NRT_EINVAL:\n\t\treturn \"Invalid input paramter\";\n\tcase NRT_EIO:\n\t\treturn \"Adapter reported a DOWN state\";\n\tcase NRT_EMEM:\n\t\treturn \"Memory allocation error\";\n\tcase NRT_EPERM:\n\t\treturn \"Permission denied, not root\";\n\tcase NRT_ERR_COMMAND_TYPE:\n\t\treturn \"Invalid command type\";\n\tcase NRT_ESYSTEM:\n\t\treturn \"A system error occured\";\n\tcase NRT_IMM_SEND_RESERVE:\n\t\treturn \"Error during immediate send slot reserve\";\n\tcase NRT_NO_FREE_WINDOW:\n\t\treturn \"No free window\";\n\tcase NRT_NO_RDMA_AVAIL:\n\t\treturn \"No RDMA windows available\";\n\tcase NRT_NTBL_LOAD_FAILED:\n\t\treturn \"Failed to load NTBL\";\n\tcase NRT_NTBL_NOT_FOUND:\n\t\treturn \"NTBL not found\";\n\tcase NRT_NTBL_UNLOAD_FAILED:\n\t\treturn \"Failed to unload NTBL\";\n\tcase NRT_OP_NOT_VALID:\n\t\treturn \"Requested operation not valid for given device\";\n\tcase NRT_PNSDAPI:\n\t\treturn \"Error communicating with Protocol Network Services \"\n\t\t       \"Daemon\";\n\tcase NRT_RDMA_CLEAN_FAILED:\n\t\treturn \"Task RDMA cleanup failed\";\n\tcase NRT_SUCCESS:\n\t\treturn \"Success\";\n\tcase NRT_TIMEOUT:\n\t\treturn \"No response back from PNSD/job\";\n\tcase NRT_UNKNOWN_ADAPTER:\n\t\treturn \"Unknown adaper\";\n\tcase NRT_WIN_CLOSE_FAILED:\n\t\treturn \"Task can not close window\";\n\tcase NRT_WIN_OPEN_FAILED:\n\t\treturn \"Task can not open window\";\n\tcase NRT_WRONG_PREEMPT_STATE:\n\t\treturn \"Invalid preemption state\";\n\tcase NRT_WRONG_WINDOW_STATE:\n\t\treturn \"Wrong window state\";\n\t}\n\n\tsnprintf(str, sizeof(str), \"%d\", rc);\n\treturn str;\n}\n\n\n/* Determine if a token is the name of an adapter\n * IN token - token from job's \"network\" specification\n * IN list - hostlist of allocated nodes\n * RET - True if token is a adapter name, false otherwise */\nextern bool nrt_adapter_name_check(char *token, hostlist_t hl)\n{\n\tint i;\n\thostlist_iterator_t hi;\n\tslurm_nrt_nodeinfo_t *node;\n\tchar *host;\n\tbool name_found = false;\n\n\tif (!token || !hl)\n\t\treturn name_found;\n\n\thi = hostlist_iterator_create(hl);\n\thost = hostlist_next(hi);\n\thostlist_iterator_destroy(hi);\n\tslurm_mutex_lock(&global_lock);\n\tnode = _find_node(nrt_state, host);\n\tif (host)\n\t\tfree(host);\n\tif (node && node->adapter_list) {\n\t\tfor (i = 0; i < node->adapter_count; i++) {\n\t\t\tif (xstrcmp(token,node->adapter_list[i].adapter_name))\n\t\t\t\tcontinue;\n\t\t\tname_found = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\tslurm_mutex_unlock(&global_lock);\n\n\treturn name_found;\n}\n\nstatic preemption_state_t _job_preempt_state(nrt_job_key_t job_key)\n{\n\tnrt_cmd_query_preemption_state_t preempt_state;\n\tpreemption_state_t state;\n\tint err;\n\n\tpreempt_state.job_key\t= job_key;\n\tpreempt_state.state\t= &state;\n\terr = nrt_cmd_wrap(NRT_VERSION, NRT_CMD_QUERY_PREEMPTION_STATE,\n\t\t\t   &preempt_state);\n\tif (err != NRT_SUCCESS) {\n\t\terror(\"nrt_cmd_wrap(preempt_state, %u): %s\",\n\t\t      job_key, nrt_err_str(err));\n\t\treturn PES_INIT;\t/* No good return value for error */\n\t}\n\treturn state;\n}\n\nstatic char *_job_state_str(preemption_state_t curr_state)\n{\n\tstatic char buf[10];\n\n\tswitch (curr_state) {\n\tcase PES_INIT:\n\t\treturn \"Init\";\n\tcase PES_JOB_RUNNING:\n\t\treturn \"Running\";\n\tcase PES_PREEMPTION_INPROGRESS:\n\t\treturn \"Preemption_in_progress\";\n\tcase PES_JOB_PREEMPTED:\n\t\treturn \"Preempted\";\n\tcase PES_PREEMPTION_FAILED:\n\t\treturn \"Preemption_failed\";\n\tcase PES_RESUME_INPROGRESS:\n\t\treturn \"Resume_in_progress\";\n\tcase PES_RESUME_FAILED:\n\t\treturn \"Resume_failed\";\n\tdefault:\n\t\tsnprintf(buf, sizeof(buf), \"%d\", curr_state);\n\t\treturn buf;\n\t}\n}\n\n/* Return 0 when job in desired state, -1 on error */\nstatic int _wait_job(nrt_job_key_t job_key, preemption_state_t want_state,\n\t\t     int max_wait_secs)\n{\n\tpreemption_state_t curr_state;\n\tchar *state_str = NULL;\n\ttime_t start_time = time(NULL), now;\n\tint i;\n\n\tfor (i = 0; ; i++) {\n\t\tif (i)\n\t\t\tusleep(100000);\n\t\tcurr_state = _job_preempt_state(job_key);\n\t\t/* Job's state is initially PES_INIT, even when running.\n\t\t * It only goes to state PES_JOB_RUNNING after suspend and\n\t\t * resume. */\n\t\tif ((curr_state == want_state) ||\n\t\t    ((curr_state == PES_INIT) &&\n\t\t     (want_state == PES_JOB_RUNNING))) {\n\t\t\tdebug(\"switch/nrt: Desired job state in %d msec\",\n\t\t\t      (100 * i));\n\t\t\treturn 0;\n\t\t}\n\t\t/* info(\"job_key:%u state:%d\", job_key, curr_state); */\n\t\tif ((curr_state == PES_PREEMPTION_FAILED) ||\n\t\t    (curr_state == PES_RESUME_FAILED))\n\t\t\treturn -1;\n\t\tif (want_state == PES_JOB_RUNNING) {\n\t\t\tif ((curr_state != PES_INIT) &&\n\t\t\t    (curr_state != PES_RESUME_INPROGRESS))\n\t\t\t\treturn -1;\n\t\t} else if (want_state == PES_JOB_PREEMPTED) {\n\t\t\tif (curr_state != PES_PREEMPTION_INPROGRESS)\n\t\t\t\treturn 0;\n\t\t} else {\n\t\t\terror(\"_wait_job: invalid desired state: %d\",\n\t\t\t      want_state);\n\t\t\treturn -1;\n\t\t}\n\t\tif (max_wait_secs) {\n\t\t\tnow = time(NULL);\n\t\t\tif ((now - start_time) > max_wait_secs)\n\t\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (want_state == PES_JOB_RUNNING)\n\t\tstate_str = \"Running\";\n\telse if (want_state == PES_JOB_PREEMPTED)\n\t\tstate_str = \"Preempted\";\n\terror(\"switch/nrt: Desired job state of %s not reached in %d sec, \"\n\t      \"Current job state is %s\",\n\t      state_str, (int)(now - start_time), _job_state_str(curr_state));\n\treturn -1;\n}\n\nextern int nrt_preempt_job_test(slurm_nrt_jobinfo_t *jp)\n{\n#ifdef PREEMPT_RELEASE_RESOURCES_MASK\n\tif (jp->cau_indexes) {\n\t\tinfo(\"Unable to preempt job with allocated CAU\");\n\t\treturn SLURM_ERROR;\n\t}\n\treturn SLURM_SUCCESS;\n#else\n\tinfo(\"switch/nrt: This version of libnrt.so does not support job \"\n\t     \"suspend/resume\");\n\treturn SLURM_ERROR;\n#endif\n}\n\nextern void nrt_suspend_job_info_get(slurm_nrt_jobinfo_t *jp,\n\t\t\t\t     void **suspend_info)\n{\n\tslurm_nrt_suspend_info_t *susp_info_ptr;\n\tif (!jp)\n\t\treturn;\n\tif (*suspend_info == NULL) {\n\t\tsusp_info_ptr = xmalloc(sizeof(slurm_nrt_suspend_info_t));\n\t\tsusp_info_ptr->job_key_array_size = 8;\n\t\tsusp_info_ptr->job_key = xmalloc(sizeof(nrt_job_key_t) * 8);\n\t\t*suspend_info = susp_info_ptr;\n\t} else {\n\t\tsusp_info_ptr = *suspend_info;\n\t\tif ((susp_info_ptr->job_key_count + 1) >=\n\t\t    susp_info_ptr->job_key_array_size) {\n\t\t\tsusp_info_ptr->job_key_array_size *= 2;\n\t\t\txrealloc(susp_info_ptr->job_key,\n\t\t\t\t sizeof(nrt_job_key_t) *\n\t\t\t\t susp_info_ptr->job_key_array_size);\n\t\t}\n\t}\n\tsusp_info_ptr->job_key[susp_info_ptr->job_key_count++] = jp->job_key;\n}\n\nextern void nrt_suspend_job_info_pack(void *suspend_info, Buf buffer,\n\t\t\t\t      uint16_t protocol_version)\n{\n\tslurm_nrt_suspend_info_t *susp_info_ptr;\n\n\tif (!suspend_info) {\n\t\tuint32_t tmp_32 = 0;\n\t\tpack32(tmp_32, buffer);\n\t\treturn;\n\t}\n\tsusp_info_ptr = (slurm_nrt_suspend_info_t *) suspend_info;\n\tpack32(susp_info_ptr->job_key_count, buffer);\n\tpack32_array(susp_info_ptr->job_key, susp_info_ptr->job_key_count,\n\t\t     buffer);\n\tif (debug_flags & DEBUG_FLAG_SWITCH) {\n\t\tint i;\n\t\tfor (i = 0; i < susp_info_ptr->job_key_count; i++) {\n\t\t\tinfo(\"nrt_suspend_job_info_pack: job_key[%d]:%u\",\n\t\t\t     i, susp_info_ptr->job_key[i]);\n\t\t}\n\t}\n}\n\nextern int nrt_suspend_job_info_unpack(void **suspend_info, Buf buffer,\n\t\t\t\t       uint16_t protocol_version)\n{\n\tslurm_nrt_suspend_info_t *susp_info_ptr = NULL;\n\tuint32_t tmp_32;\n\n\t*suspend_info = NULL;\n\tsafe_unpack32(&tmp_32, buffer);\n\tif (tmp_32 == 0)\n\t\treturn SLURM_SUCCESS;\n\n\tsusp_info_ptr = xmalloc(sizeof(slurm_nrt_suspend_info_t));\n\tsusp_info_ptr->job_key_count = tmp_32;\n\tsusp_info_ptr->job_key_array_size = tmp_32;\n\tsafe_unpack32_array(&susp_info_ptr->job_key, &tmp_32, buffer);\n\tif (tmp_32 != susp_info_ptr->job_key_count)\n\t\tgoto unpack_error;\n\t*suspend_info = susp_info_ptr;\n\tif (debug_flags & DEBUG_FLAG_SWITCH) {\n\t\tint i;\n\t\tfor (i = 0; i < susp_info_ptr->job_key_count; i++) {\n\t\t\tinfo(\"nrt_suspend_job_info_pack: job_key[%d]:%u\",\n\t\t\t     i, susp_info_ptr->job_key[i]);\n\t\t}\n\t}\n\n\treturn SLURM_SUCCESS;\n\nunpack_error:\n\terror(\"nrt_suspend_job_info_unpack: unpack error\");\n\txfree(susp_info_ptr->job_key);\n\txfree(susp_info_ptr);\n\treturn SLURM_ERROR;\n}\n\nextern void nrt_suspend_job_info_free(void *suspend_info)\n{\n\tslurm_nrt_suspend_info_t *susp_info_ptr;\n\n\tsusp_info_ptr = (slurm_nrt_suspend_info_t *) suspend_info;\n\tif (susp_info_ptr) {\n\t\txfree(susp_info_ptr->job_key);\n\t\txfree(susp_info_ptr);\n\t}\n}\n\nstatic int _preempt_job(nrt_job_key_t job_key, int max_wait_secs)\n{\n\tnrt_cmd_preempt_job_t preempt_job;\n\tint err;\n\n\tpreempt_job.job_key\t= job_key;\n#ifdef PREEMPT_RELEASE_RESOURCES_MASK\n\tpreempt_job.option\t= PREEMPT_RELEASE_RESOURCES_MASK;\n#else\n\tpreempt_job.option\t= 0x0001;\n#endif\n\tpreempt_job.timeout_val\t= NULL;    /* Should be set? What value? */\n\tif (_wait_job(job_key, PES_JOB_RUNNING, max_wait_secs))\n\t\treturn SLURM_ERROR;\n\t/* NOTE: This function is non-blocking.\n\t * To detect completeion, poll on NRT_CMD_QUERY_PREEMPTION_STATE */\n\terr = nrt_cmd_wrap(NRT_VERSION, NRT_CMD_PREEMPT_JOB, &preempt_job);\n\tif (err != NRT_SUCCESS) {\n\t\terror(\"nrt_cmd_wrap(preempt job, %u): %s\", job_key,\n\t\t      nrt_err_str(err));\n\t\treturn SLURM_ERROR;\n\t}\n\tif (debug_flags & DEBUG_FLAG_SWITCH)\n\t\tinfo(\"nrt_cmd_wrap(preempting job, %u)\", job_key);\n\tif (_wait_job(job_key, PES_JOB_PREEMPTED, max_wait_secs))\n\t\treturn SLURM_ERROR;\n\tif (debug_flags & DEBUG_FLAG_SWITCH)\n\t\tinfo(\"nrt_cmd_wrap(preempted job, %u)\", job_key);\n\treturn SLURM_SUCCESS;\n}\n\nextern int nrt_preempt_job(void *suspend_info, int max_wait_secs)\n{\n\tslurm_nrt_suspend_info_t *susp_info_ptr;\n\tint err, i, rc = SLURM_SUCCESS;\n\n\tsusp_info_ptr = (slurm_nrt_suspend_info_t *) suspend_info;\n\tif (susp_info_ptr) {\n\t\tfor (i = 0; i < susp_info_ptr->job_key_count; i++) {\n\t\t\terr = _preempt_job(susp_info_ptr->job_key[i],\n\t\t\t\t\t   max_wait_secs);\n\t\t\tif (err != SLURM_SUCCESS)\n\t\t\t\trc = err;\n\t\t}\n\t}\n\treturn rc;\n}\n\nstatic int _resume_job(nrt_job_key_t job_key, int max_wait_secs)\n{\n\tnrt_cmd_resume_job_t resume_job;\n\tint err;\n\n\tresume_job.job_key\t= job_key;\n#ifdef PREEMPT_RELEASE_RESOURCES_MASK\n\tresume_job.option\t= PREEMPT_RELEASE_RESOURCES_MASK;\n#else\n\tresume_job.option\t= 0x0001;\n#endif\n\tresume_job.timeout_val\t= NULL;    /* Should be set? What value? */\n\t/* NOTE: This function is non-blocking.\n\t * To detect completeion, poll on NRT_CMD_QUERY_PREEMPTION_STATE */\n\terr = nrt_cmd_wrap(NRT_VERSION, NRT_CMD_RESUME_JOB, &resume_job);\n\tif (err != NRT_SUCCESS) {\n\t\terror(\"nrt_cmd_wrap(resume job, %u): %s\", job_key,\n\t\t      nrt_err_str(err));\n\t\treturn SLURM_ERROR;\n\t}\n\tif (debug_flags & DEBUG_FLAG_SWITCH)\n\t\tinfo(\"nrt_cmd_wrap(resuming job, %u)\", job_key);\n\tif (_wait_job(job_key, PES_JOB_RUNNING, max_wait_secs))\n\t\treturn SLURM_ERROR;\n\tif (debug_flags & DEBUG_FLAG_SWITCH)\n\t\tinfo(\"nrt_cmd_wrap(resumed job, %u)\", job_key);\n\treturn SLURM_SUCCESS;\n}\n\nextern int nrt_resume_job(void *suspend_info, int max_wait_secs)\n{\n\tslurm_nrt_suspend_info_t *susp_info_ptr;\n\tint err, i, rc = SLURM_SUCCESS;\n\n\tsusp_info_ptr = (slurm_nrt_suspend_info_t *) suspend_info;\n\tif (susp_info_ptr) {\n\t\tfor (i = 0; i < susp_info_ptr->job_key_count; i++) {\n\t\t\terr = _resume_job(susp_info_ptr->job_key[i],\n\t\t\t\t\t  max_wait_secs);\n\t\t\tif (err != SLURM_SUCCESS)\n\t\t\t\trc = err;\n\t\t}\n\t}\n\treturn rc;\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/src/plugins/switch/nrt/libpermapi/shr_64.c": "/*****************************************************************************\\\n *  shr_64.c - This plug is used by POE to interact with SLURM.\n *****************************************************************************\n *  Copyright (C) 2012 SchedMD LLC.\n *  Written by Danny Auble <da@schedmd.com> et. al.\n *\n *  This file is part of SLURM, a resource management program.\n *  For details, see <https://slurm.schedmd.com/>.\n *  Please also read the included file: DISCLAIMER.\n *\n *  SLURM is free software; you can redistribute it and/or modify it under\n *  the terms of the GNU General Public License as published by the Free\n *  Software Foundation; either version 2 of the License, or (at your option)\n *  any later version.\n *\n *  In addition, as a special exception, the copyright holders give permission\n *  to link the code of portions of this program with the OpenSSL library under\n *  certain conditions as described in each individual source file, and\n *  distribute linked combinations including the two. You must obey the GNU\n *  General Public License in all respects for all of the code used other than\n *  OpenSSL. If you modify file(s) with this exception, you may extend this\n *  exception to your version of the file(s), but you are not obligated to do\n *  so. If you do not wish to do so, delete this exception statement from your\n *  version.  If you delete this exception statement from all source files in\n *  the program, then also delete it here.\n *\n *  SLURM is distributed in the hope that it will be useful, but WITHOUT ANY\n *  WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n *  FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more\n *  details.\n *\n *  You should have received a copy of the GNU General Public License along\n *  with SLURM; if not, write to the Free Software Foundation, Inc.,\n *  51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA.\n\\*****************************************************************************/\n\n#include \"config.h\"\n\n#include <arpa/inet.h>\n#include <ctype.h>\n#include <dlfcn.h>\n#include <fcntl.h>\n#include <nrt.h>\n#include <permapi.h>\n#include <stdlib.h>\n#include <unistd.h>\n\n#include \"src/common/slurm_xlator.h\"\n#include \"slurm/slurm.h\"\n#include \"slurm/slurm_errno.h\"\n\n#include \"src/api/step_ctx.h\"\n\n#include \"src/common/hostlist.h\"\n#include \"src/common/list.h\"\n#include \"src/common/log.h\"\n#include \"src/common/parse_time.h\"\n#include \"src/common/plugstack.h\"\n#include \"src/common/slurm_protocol_pack.h\"\n#include \"src/common/xmalloc.h\"\n#include \"src/common/xstring.h\"\n\n#include \"src/srun/libsrun/allocate.h\"\n#include \"src/srun/libsrun/launch.h\"\n#include \"src/srun/libsrun/opt.h\"\n#include \"src/srun/libsrun/srun_job.h\"\n#include \"src/plugins/switch/nrt/nrt_keys.h\"\n\nbool srun_max_timer = false;\nbool srun_shutdown  = false;\n\nstatic char *poe_cmd_fname = NULL;\nstatic void *my_handle = NULL;\nstatic srun_job_t *job = NULL;\nstatic bool got_alloc = false;\nstatic bool slurm_started = false;\nstatic log_options_t log_opts = LOG_OPTS_STDERR_ONLY;\nstatic host_usage_t *host_usage = NULL;\nstatic hostlist_t total_hl = NULL;\nstatic int err_msg_len = 400;\n\nint sig_array[] = {\n\tSIGINT,  SIGQUIT, SIGCONT, SIGTERM, SIGHUP,\n\tSIGALRM, SIGUSR1, SIGUSR2, SIGPIPE, 0 };\n\nextern char **environ;\n\n/* IBM internal definitions to get information on how and who is\n * calling us.\n */\n#define PM_POE  0\n#define PM_PMD  1\nextern int pm_type;\nextern int pmdlog;\nextern FILE *pmd_lfp;\n\ntypedef struct agent_data {\n\tuint32_t   fe_auth_key;\n\tint fe_comm_socket;\n} agent_data_t;\n\nstatic char *_name_from_addr(char *addr)\n{\n\thost_usage_t *host_ptr;\n\n\txassert(host_usage);\n\thost_ptr = host_usage;\n\twhile (host_ptr && host_ptr->host_address) {\n\t\tif (!xstrcmp(addr, host_ptr->host_address))\n\t\t\treturn host_ptr->host_name;\n\t\thost_ptr++;\n\t}\n\treturn NULL;\n}\n\nstatic void _pack_srun_ctx(slurm_step_ctx_t *ctx, Buf buffer)\n{\n\tuint8_t tmp_8 = 0;\n\n\tif (ctx)\n\t\ttmp_8 = 1;\n\tpack8(tmp_8, buffer);\n\tif (!ctx || !ctx->step_req || !ctx->step_resp) {\n\t\terror(\"_pack_srun_ctx: ctx is NULL\");\n\t\treturn;\n\t}\n\tpack_job_step_create_request_msg(ctx->step_req, buffer,\n\t\t\t\t\t SLURM_PROTOCOL_VERSION);\n\tpack_job_step_create_response_msg(ctx->step_resp, buffer,\n\t\t\t\t\t  SLURM_PROTOCOL_VERSION);\n\tpack32((uint32_t)ctx->launch_state->slurmctld_socket_fd, buffer);\n}\n\nstatic int _unpack_srun_ctx(slurm_step_ctx_t **step_ctx, Buf buffer)\n{\n\tslurm_step_ctx_t *ctx = NULL;\n\tuint8_t tmp_8;\n\tint rc;\n\tuint32_t tmp_32;\n\n\t*step_ctx = NULL;\n\tsafe_unpack8(&tmp_8, buffer);\n\tif (tmp_8 == 0) {\n\t\terror(\"_unpack_srun_ctx: ctx is NULL\");\n\t\treturn SLURM_ERROR;\n\t}\n\n\tctx = xmalloc(sizeof(slurm_step_ctx_t));\n\tctx->magic = STEP_CTX_MAGIC;\n\trc = unpack_job_step_create_request_msg(&ctx->step_req, buffer,\n\t\t\t\t\t\tSLURM_PROTOCOL_VERSION);\n\tif (rc != SLURM_SUCCESS)\n\t\tgoto unpack_error;\n\n\trc = unpack_job_step_create_response_msg(&ctx->step_resp, buffer,\n\t\t\t\t\t\t SLURM_PROTOCOL_VERSION);\n\tif (rc != SLURM_SUCCESS)\n\t\tgoto unpack_error;\n\n\tctx->job_id\t= ctx->step_req->job_id;\n\tctx->user_id\t= ctx->step_req->user_id;\n\n\tsafe_unpack32(&tmp_32, buffer);\n\tctx->launch_state = step_launch_state_create(ctx);\n\tctx->launch_state->slurmctld_socket_fd = tmp_32;\n\n\t*step_ctx = ctx;\n\treturn SLURM_SUCCESS;\n\nunpack_error:\n\terror(\"_unpack_srun_ctx: unpack error\");\n\tif (ctx && ctx->step_req)\n\t\tslurm_free_job_step_create_request_msg(ctx->step_req);\n\tif (ctx && ctx->step_resp)\n\t\tslurm_free_job_step_create_response_msg(ctx->step_resp);\n\txfree(ctx);\n\treturn SLURM_ERROR;\n}\n\nstatic Buf _pack_srun_job_rec(void)\n{\n\tBuf buffer;\n\thost_usage_t *host_ptr;\n\n\tbuffer = init_buf(4096);\n\tpack32(job->nhosts, buffer);\n\n\tpackstr(job->alias_list, buffer);\n\tpackstr(job->nodelist, buffer);\n\n\t_pack_srun_ctx(job->step_ctx, buffer);\n\n\t/* Since we can't rely on slurm_conf_get_nodename_from_addr\n\t   working on a PERCS machine reliably we will sort all the\n\t   IP's as we know them and ship them over if/when a PMD needs to\n\t   forward the fanout.\n\t*/\n\txassert(host_usage);\n\thost_ptr = host_usage;\n\twhile (host_ptr && host_ptr->host_name) {\n\t\tpackstr(host_ptr->host_name, buffer);\n\t\tpackstr(host_ptr->host_address, buffer);\n\t\thost_ptr++;\n\t}\n\treturn buffer;\n}\n\nstatic srun_job_t * _unpack_srun_job_rec(Buf buffer)\n{\n\tuint32_t tmp_32;\n\tsrun_job_t *job_data;\n\thost_usage_t *host_ptr;\n\tint i;\n\n\tjob_data = xmalloc(sizeof(srun_job_t));\n\tsafe_unpack32(&job_data->nhosts, buffer);\n\n\tsafe_unpackstr_xmalloc(&job_data->alias_list, &tmp_32, buffer);\n\tsafe_unpackstr_xmalloc(&job_data->nodelist, &tmp_32, buffer);\n\n\tif (_unpack_srun_ctx(&job_data->step_ctx, buffer))\n\t\tgoto unpack_error;\n\n\thost_usage = xmalloc(sizeof(host_usage_t) * (job_data->nhosts+1));\n\thost_ptr = host_usage;\n\tfor (i=0; i<job_data->nhosts; i++) {\n\t\tsafe_unpackstr_xmalloc(&host_ptr->host_name, &tmp_32, buffer);\n\t\tsafe_unpackstr_xmalloc(&host_ptr->host_address,\n\t\t\t\t       &tmp_32, buffer);\n\t\thost_ptr++;\n\t}\n\n\tslurm_step_ctx_params_t_init(&job_data->ctx_params);\n\n\treturn job_data;\n\nunpack_error:\n\terror(\"_unpack_srun_job_rec: unpack error\");\n\txfree(job_data->alias_list);\n\txfree(job_data->nodelist);\n\txfree(job_data);\n\treturn NULL;\n}\n\n/* Validate a message connection\n * Return: true=valid/authenticated */\nstatic bool _validate_connect(int socket_conn, uint32_t auth_key)\n{\n\tstruct timeval tv;\n\tfd_set read_fds;\n\tuint32_t read_key;\n\tbool valid = false;\n\tint i, n_fds;\n\n\tn_fds = socket_conn;\n\twhile (1) {\n\t\tFD_ZERO(&read_fds);\n\t\tFD_SET(socket_conn, &read_fds);\n\n\t\ttv.tv_sec = 10;\n\t\ttv.tv_usec = 0;\n\t\ti = select((n_fds + 1), &read_fds, NULL, NULL, &tv);\n\t\tif (i == 0)\n\t\t\tbreak;\n\t\tif (i < 0) {\n\t\t\tif (errno == EINTR)\n\t\t\t\tcontinue;\n\t\t\tbreak;\n\t\t}\n\t\ti = slurm_read_stream(socket_conn, (char *)&read_key,\n\t\t\t\t      sizeof(read_key));\n\t\tif ((i == sizeof(read_key)) && (read_key == auth_key)) {\n\t\t\tvalid = true;\n\t\t} else {\n\t\t\terror(\"error validating incoming socket connection\");\n\t\t\tsleep(1);\t/* Help prevent brute force attack */\n\t\t}\n\t\tbreak;\n\t}\n\n\treturn valid;\n}\n\n/* Process a message from PMD */\nstatic void _agent_proc_connect(int fe_comm_socket,uint32_t fe_auth_key)\n{\n\tint fe_comm_conn = -1;\n\tslurm_addr_t be_addr;\n\tbool be_connected = false;\n\tBuf buffer = NULL;\n\tuint32_t buf_size;\n\tchar *buf_data;\n\tint i, offset = 0;\n\n\twhile (1) {\n\t\tfe_comm_conn = slurm_accept_msg_conn(fe_comm_socket, &be_addr);\n\t\tif (fe_comm_conn != SLURM_SOCKET_ERROR) {\n\t\t\tif (_validate_connect(fe_comm_conn, fe_auth_key))\n\t\t\t\tbe_connected = true;\n\t\t\tbreak;\n\t\t}\n\t\tif (errno != EINTR) {\n\t\t\terror(\"slurm_accept_msg_conn: %m\");\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (!be_connected)\n\t\tgoto fini;\n\n\tbuffer = _pack_srun_job_rec();\n\tbuf_size = get_buf_offset(buffer);\n\tbuf_data = (char *) &buf_size;\n\ti = slurm_write_stream_timeout(fe_comm_conn, buf_data,\n\t\t\t\t       sizeof(buf_size), 8000);\n\tif (i < sizeof(buf_size)) {\n\t\terror(\"_agent_proc_connect write: %m\");\n\t\tgoto fini;\n\t}\n\n\tbuf_data = get_buf_data(buffer);\n\twhile (buf_size > offset) {\n\t\ti = slurm_write_stream_timeout(fe_comm_conn, buf_data + offset,\n\t\t\t\t\t       buf_size - offset, 8000);\n\t\tif (i < 0) {\n\t\t\tif ((errno != EAGAIN) && (errno != EINTR)) {\n\t\t\t\terror(\"_agent_proc_connect write: %m\");\n\t\t\t\tbreak;\n\t\t\t}\n\t\t} else if (i > 0) {\n\t\t\toffset += i;\n\t\t} else {\n\t\t\terror(\"_agent_proc_connect write: timeout\");\n\t\t\tbreak;\n\t\t}\n\t}\n\nfini:\tif (fe_comm_conn >= 0)\n\t\tclose(fe_comm_conn);\n\tif (buffer)\n\t\tfree_buf(buffer);\n}\n\n/* Thread to wait for and process messgaes from PMD (via libpermapi) */\nstatic void *_agent_thread(void *arg)\n{\n        agent_data_t *agent_data_ptr = (agent_data_t *) arg;\n\tuint32_t   fe_auth_key    = agent_data_ptr->fe_auth_key;\n\tint fe_comm_socket = agent_data_ptr->fe_comm_socket;\n\tfd_set except_fds, read_fds;\n\tstruct timeval tv;\n\tint i, n_fds;\n\n\txfree(agent_data_ptr);\n\tn_fds = fe_comm_socket;\n\twhile (fe_comm_socket >= 0) {\n\t\tFD_ZERO(&except_fds);\n\t\tFD_SET(fe_comm_socket, &except_fds);\n\t\tFD_ZERO(&read_fds);\n\t\tFD_SET(fe_comm_socket, &read_fds);\n\n\t\ttv.tv_sec =  0;\n\t\ttv.tv_usec = 0;\n\t\ti = select((n_fds + 1), &read_fds, NULL, &except_fds, &tv);\n\t\tif ((i == 0) ||\n\t\t    ((i == -1) && (errno == EINTR))) {\n\t\t\t;\n\t\t} else if (i == -1) {\n\t\t\terror(\"select(): %m\");\n\t\t\tbreak;\n\t\t} else {\t/* i > 0, ready for I/O */\n\t\t\t_agent_proc_connect(fe_comm_socket, fe_auth_key);;\n\t\t}\n\t}\n\tslurm_shutdown_msg_engine(fe_comm_socket);\n\n\treturn NULL;\n}\n\n/* Generate and return a pseudo-random 32-bit authentication key */\nstatic uint32_t _gen_auth_key(void)\n{\n\tstruct timeval tv;\n\tuint32_t key;\n\n\tgettimeofday(&tv, NULL);\n\tkey  = (tv.tv_sec % 1000) * 1000000;\n\tkey += tv.tv_usec;\n\n\treturn key;\n}\n\n/* Spawn a shell to receive communications from PMD and spawn additional\n * PMD on other nodes using a fanout mechanism other than SLURM. */\nstatic void _spawn_fe_agent(void)\n{\n\tchar hostname[256];\n\tuint32_t   fe_auth_key = 0;\n\tint fe_comm_socket = -1;\n\tslurm_addr_t comm_addr;\n\tuint16_t comm_port;\n\tagent_data_t *agent_data_ptr;\n\n\t/* Open socket for back-end program to communicate with */\n\tif ((fe_comm_socket = slurm_init_msg_engine_port(0)) < 0) {\n\t\terror(\"init_msg_engine_port: %m\");\n\t\treturn;\n\t}\n\tif (slurm_get_stream_addr(fe_comm_socket, &comm_addr) < 0) {\n\t\terror(\"slurm_get_stream_addr: %m\");\n\t\treturn;\n\t}\n\tcomm_port = ntohs(((struct sockaddr_in) comm_addr).sin_port);\n\tfe_auth_key = _gen_auth_key();\n\tif (gethostname_short(hostname, sizeof(hostname)))\n\t\tfatal(\"gethostname_short(): %m\");\n\n\t/* Set up environment variables for the plugin (as called by PMD)\n\t * to load job information */\n\tsetenvfs(\"SLURM_FE_KEY=%u\", fe_auth_key);\n\tsetenvfs(\"SLURM_FE_SOCKET=%s:%hu\", hostname, comm_port);\n\n\tagent_data_ptr = xmalloc(sizeof(agent_data_t));\n\tagent_data_ptr->fe_auth_key = fe_auth_key;\n\tagent_data_ptr->fe_comm_socket = fe_comm_socket;\n\n\tslurm_thread_create_detached(NULL, _agent_thread, agent_data_ptr);\n}\n\n/*\n * Return a string representation of an array of uint16_t elements.\n * Each value in the array is printed in decimal notation and elements\n * are separated by a comma.  If sequential elements in the array\n * contain the same value, the value is written out just once followed\n * by \"(xN)\", where \"N\" is the number of times the value is repeated.\n *\n * Example:\n *   The array \"1, 2, 1, 1, 1, 3, 2\" becomes the string \"1,2,1(x3),3,2\"\n *\n * Returns an xmalloc'ed string.  Free with xfree().\n */\nstatic char *_uint16_array_to_str(int array_len, const uint16_t *array)\n{\n\tint i;\n\tint previous = 0;\n\tchar *sep = \",\";  /* seperator */\n\tchar *str = xstrdup(\"\");\n\n\tif (array == NULL)\n\t\treturn str;\n\n\tfor (i = 0; i < array_len; i++) {\n\t\tif ((i+1 < array_len)\n\t\t    && (array[i] == array[i+1])) {\n\t\t\tprevious++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (i == array_len-1) /* last time through loop */\n\t\t\tsep = \"\";\n\t\tif (previous > 0) {\n\t\t\txstrfmtcat(str, \"%u(x%u)%s\",\n\t\t\t\t   array[i], previous+1, sep);\n\t\t} else {\n\t\t\txstrfmtcat(str, \"%u%s\", array[i], sep);\n\t\t}\n\t\tprevious = 0;\n\t}\n\n\treturn str;\n}\n\nsrun_job_t * _read_job_srun_agent(void)\n{\n\tchar *key_str  = getenv(\"SLURM_FE_KEY\");\n\tchar *sock_str = getenv(\"SLURM_FE_SOCKET\");\n\tchar buf[32], *host, *sep;\n\tint resp_socket;\n\tuint16_t resp_port;\n\tuint32_t resp_auth_key, buf_size;\n\tsrun_job_t *srun_job = NULL;\n\tslurm_addr_t resp_addr;\n\tchar *job_data;\n\tBuf buffer;\n\tint i, offset = 0;\n\n\tif (!key_str) {\n\t\terror(\"SLURM_FE_KEY environment variable not set\");\n\t\treturn NULL;\n\t}\n\tif (!sock_str) {\n\t\terror(\"SLURM_FE_SOCKET environment variable not set\");\n\t\treturn NULL;\n\t}\n\thost = xstrdup(sock_str);\n\tsep = strchr(host, ':');\n\tif (!sep) {\n\t\terror(\"_read_job_srun_agent(): SLURM_FE_SOCKET is invalid: %s\",\n\t\t      sock_str);\n\t\txfree(host);\n\t\treturn NULL;\n\t}\n\tsep[0] = '\\0';\n\tresp_port = atoi(sep + 1);\n\tslurm_set_addr(&resp_addr, resp_port, host);\n\txfree(host);\n\tresp_socket = slurm_open_stream(&resp_addr, true);\n\tif (resp_socket < 0) {\n\t\terror(\"slurm_open_stream(%s): %m\", sock_str);\n\t\treturn NULL;\n\t}\n\n\tresp_auth_key = atoi(key_str);\n\tmemcpy(buf + 0, &resp_auth_key, 4);\n\ti = slurm_write_stream_timeout(resp_socket, buf, 4, 8000);\n\tif (i < 4) {\n\t\terror(\"_read_job_srun_agent write: %m\");\n\t\treturn NULL;\n\t}\n\n\ti = slurm_read_stream_timeout(resp_socket, (char *) &buf_size, 4, 8000);\n\tif (i < 4) {\n\t\terror(\"_read_job_srun_agent read (i=%d): %m\", i);\n\t\treturn NULL;\n\t}\n\tjob_data = xmalloc(buf_size);\n\twhile (buf_size > offset) {\n\t\ti = slurm_read_stream_timeout(resp_socket, job_data + offset,\n\t\t\t\t\t      buf_size - offset, 8000);\n\t\tif (i < 0) {\n\t\t\tif ((errno != EAGAIN) && (errno != EINTR)) {\n\t\t\t\terror(\"_read_job_srun_agent read (buf=%d): %m\",\n\t\t\t\t      i);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t} else if (i > 0) {\n\t\t\toffset += i;\n\t\t} else {\n\t\t\terror(\"_read_job_srun_agent read: timeout\");\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tslurm_shutdown_msg_engine(resp_socket);\n\tbuffer = create_buf(job_data, buf_size);\n\tsrun_job = _unpack_srun_job_rec(buffer);\n\tfree_buf(buffer);\t/* This does xfree(job_data) */\n\n\treturn srun_job;\n}\n\n/* Given a program name, return its communication protocol */\nstatic char *_get_cmd_protocol(char *cmd)\n{\n\tint stdout_pipe[2] = {-1, -1}, stderr_pipe[2] = {-1, -1};\n\tint read_size, buf_rem = 16 * 1024, offset = 0, status;\n\tpid_t pid;\n\tchar *buf, *protocol = \"mpi\";\n\n\tif ((pipe(stdout_pipe) == -1) || (pipe(stderr_pipe) == -1)) {\n\t\terror(\"pipe: %m\");\n\t\treturn \"mpi\";\n\t}\n\n\tpid = fork();\n\tif (pid < 0) {\n\t\terror(\"fork: %m\");\n\t\treturn \"mpi\";\n\t} else if (pid == 0) {\n\t\tif ((dup2(stdout_pipe[1], 1) == -1) ||\n\t\t    (dup2(stderr_pipe[1], 2) == -1)) {\n\t\t\terror(\"dup2: %m\");\n\t\t\treturn NULL;\n\t\t}\n\t\t(void) close(0);\t/* stdin */\n\t\t(void) close(stdout_pipe[0]);\n\t\t(void) close(stdout_pipe[1]);\n\t\t(void) close(stderr_pipe[0]);\n\t\t(void) close(stderr_pipe[1]);\n\n\t\texeclp(\"/usr/bin/ldd\", \"ldd\", cmd, NULL);\n\t\terror(\"execv(ldd) error: %m\");\n\t\treturn NULL;\n\t}\n\n\t(void) close(stdout_pipe[1]);\n\t(void) close(stderr_pipe[1]);\n\tbuf = xmalloc(buf_rem);\n\twhile ((read_size = read(stdout_pipe[0], &buf[offset], buf_rem))) {\n\t\tif (read_size > 0) {\n\t\t\tbuf_rem -= read_size;\n\t\t\toffset  += read_size;\n\t\t\tif (buf_rem == 0)\n\t\t\t\tbreak;\n\t\t} else if ((errno != EAGAIN) || (errno != EINTR)) {\n\t\t\terror(\"read(pipe): %m\");\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (strstr(buf, \"libmpi\"))\n\t\tprotocol = \"mpi\";\n\telse if (strstr(buf, \"libshmem.so\"))\n\t\tprotocol = \"shmem\";\n\telse if (strstr(buf, \"libxlpgas.so\"))\n\t\tprotocol = \"pgas\";\n\telse if (strstr(buf, \"libpami.so\"))\n\t\tprotocol = \"pami\";\n\telse if (strstr(buf, \"liblapi.so\"))\n\t\tprotocol = \"lapi\";\n\txfree(buf);\n\twhile ((waitpid(pid, &status, 0) == -1) && (errno == EINTR))\n\t\t;\n\t(void) close(stdout_pipe[0]);\n\t(void) close(stderr_pipe[0]);\n\n\treturn protocol;\n}\n\n/*\n * Parse a multi-prog input file line\n * total_tasks - Number of tasks in the job,\n *               also size of the cmd, args, and protocol arrays\n * line IN - line to parse\n * cmd OUT  - command to execute, caller must xfree this\n * args OUT - arguments to the command, caller must xfree this\n * protocol OUT - communication protocol of the command, do not xfree this\n */\nstatic void _parse_prog_line(int total_tasks, char *in_line, char **cmd,\n\t\t\t     char **args, char **protocol)\n{\n\tint i, task_id;\n\tint first_arg_inx = 0, last_arg_inx = 0;\n\tint first_cmd_inx,  last_cmd_inx;\n\tint first_task_inx, last_task_inx;\n\thostset_t hs = NULL;\n\tchar *task_id_str, *tmp_str = NULL;\n\tchar *line_args = NULL, *line_cmd = NULL, *line_protocol = NULL;\n\n\t/* Get the task ID string */\n\tfor (i = 0; in_line[i]; i++)\n\t\tif (!isspace(in_line[i]))\n\t\t\tbreak;\n\n\tif (!in_line[i]) /* empty line */\n\t\treturn;\n\telse if (in_line[i] == '#')\n\t\treturn;\n\telse if (!isdigit(in_line[i]))\n\t\tgoto bad_line;\n\tfirst_task_inx = i;\n\tfor (i++; in_line[i]; i++) {\n\t\tif (isspace(in_line[i]))\n\t\t\tbreak;\n\t}\n\tif (!isspace(in_line[i]))\n\t\tgoto bad_line;\n\tlast_task_inx = i;\n\n\t/* Get the command */\n\tfor (i++; in_line[i]; i++) {\n\t\tif (!isspace(in_line[i]))\n\t\t\tbreak;\n\t}\n\tif (in_line[i] == '\\0')\n\t\tgoto bad_line;\n\tfirst_cmd_inx = i;\n\tfor (i++; in_line[i]; i++) {\n\t\tif (isspace(in_line[i]))\n\t\t\tbreak;\n\t}\n\tif (!isspace(in_line[i]))\n\t\tgoto bad_line;\n\tlast_cmd_inx = i;\n\n\t/* Get the command's arguments */\n\tfor (i++; in_line[i]; i++) {\n\t\tif (!isspace(in_line[i]))\n\t\t\tbreak;\n\t}\n\tif (in_line[i])\n\t\tfirst_arg_inx = i;\n\tfor ( ; in_line[i]; i++) {\n\t\tif (in_line[i] == '\\n') {\n\t\t\tlast_arg_inx = i;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t/* Now transfer data to the function arguments */\n\tin_line[last_task_inx] = '\\0';\n\txstrfmtcat(tmp_str, \"[%s]\", in_line + first_task_inx);\n\ths = hostset_create(tmp_str);\n\txfree(tmp_str);\n\tin_line[last_task_inx] = ' ';\n\tif (!hs)\n\t\tgoto bad_line;\n\n\tin_line[last_cmd_inx] = '\\0';\n\tline_cmd = xstrdup(in_line + first_cmd_inx);\n\tin_line[last_cmd_inx] = ' ';\n\n\tif (last_arg_inx)\n\t\tin_line[last_arg_inx] = '\\0';\n\tif (first_arg_inx)\n\t\tline_args = xstrdup(in_line + first_arg_inx);\n\tif (last_arg_inx)\n\t\tin_line[last_arg_inx] = '\\n';\n\n\tline_protocol = _get_cmd_protocol(line_cmd);\n\twhile ((task_id_str = hostset_pop(hs))) {\n\t\ttask_id = strtol(task_id_str, &tmp_str, 10);\n\t\tif ((tmp_str[0] != '\\0') || (task_id < 0))\n\t\t\tgoto bad_line;\n\t\tif (task_id >= total_tasks)\n\t\t\tcontinue;\n\t\tcmd[task_id]  = xstrdup(line_cmd);\n\t\targs[task_id] = xstrdup(line_args);\n\t\tprotocol[task_id] = line_protocol;\n\t}\n\n\txfree(line_args);\n\txfree(line_cmd);\n\thostset_destroy(hs);\n\treturn;\n\nbad_line:\n\terror(\"invalid input line: %s\", in_line);\n\txfree(line_args);\n\txfree(line_cmd);\n\tif (hs)\n\t\thostset_destroy(hs);\n\treturn;\n}\n\n/*\n * Read a line from SLURM MPMD command file or write the equivalent POE line.\n * line IN/OUT - line to read or write\n * length IN - size of line in bytes\n * step_id IN - -1 if input line, otherwise the step ID to output\n * task_id IN - count of tasks in job step (if step_id == -1)\n *              task_id to report (if step_id != -1)\n * RET true if more lines to get\n */\nstatic bool _multi_prog_parse(char *line, int length, int step_id, int task_id)\n{\n\tstatic int total_tasks = 0;\n\tstatic char **args = NULL, **cmd = NULL, **protocol = NULL;\n\tint i;\n\n\tif (step_id < 0) {\n\t\tif (!args) {\n\t\t\targs = xmalloc(sizeof(char *) * task_id);\n\t\t\tcmd  = xmalloc(sizeof(char *) * task_id);\n\t\t\tprotocol = xmalloc(sizeof(char *) * task_id);\n\t\t\ttotal_tasks = task_id;\n\t\t}\n\n\t\t_parse_prog_line(total_tasks, line, cmd, args, protocol);\n\t\treturn true;\n\t}\n\n\txassert(args);\n\txassert(cmd);\n\txassert(protocol);\n\n\tif (task_id >= total_tasks) {\n\t\tfor (i = 0; i < total_tasks; i++) {\n\t\t\txfree(args[i]);\n\t\t\txfree(cmd[i]);\n\t\t}\n\t\txfree(args);\n\t\txfree(cmd);\n\t\txfree(protocol);\n\t\ttotal_tasks = 0;\n\t\treturn false;\n\t}\n\n\tif (!cmd[task_id]) {\n\t\terror(\"Configuration file invalid, no record for task id %d\",\n\t\t      task_id);\n\t\treturn true;\n\t} else if (args[task_id]) {\n\t\t/* <cmd>@<step_id>%<total_tasks>%<protocol>:<num_tasks> <args...> */\n\t\tsnprintf(line, length, \"%s@%d%c%d%c%s:%d %s\",\n\t\t\t cmd[task_id], step_id, '%', total_tasks, '%',\n\t\t\t protocol[task_id], 1, args[task_id]);\n\t\treturn true;\n\t} else {\n\t\t/* <cmd>@<step_id>%<total_tasks>%<protocol>:<num_tasks> */\n\t\tsnprintf(line, length, \"%s@%d%c%d%c%s:%d\",\n\t\t\t cmd[task_id], step_id, '%', total_tasks, '%',\n\t\t\t protocol[task_id], 1);\n\t\treturn true;\n\t}\n}\n\n/* Convert a SLURM format MPMD file into a POE MPMD command file */\nstatic void _re_write_cmdfile(char *slurm_cmd_fname, char *poe_cmd_fname,\n\t\t\t      uint32_t step_id, int task_cnt)\n{\n\tchar *buf, in_line[512];\n\tint fd, i, j, k;\n\tFILE *fp;\n\n\tif (!slurm_cmd_fname || !poe_cmd_fname)\n\t\treturn;\n\n\tbuf = xmalloc(1024);\n\tfp = fopen(slurm_cmd_fname, \"r\");\n\tif (!fp) {\n\t\terror(\"fopen(%s): %m\", slurm_cmd_fname);\n\t\treturn;\n\t}\n\n\t/* Read and parse SLURM MPMD format file here */\n\twhile (fgets(in_line, sizeof(in_line), fp))\n\t\t_multi_prog_parse(in_line, 512, -1, task_cnt);\n\tfclose(fp);\n\n\t/* Write LoadLeveler MPMD format file here */\n\tfor (i = 0; ; i++) {\n\t\tif (!_multi_prog_parse(in_line, 512, step_id, i))\n\t\t\tbreak;\n\t\tj = xstrfmtcat(buf, \"%s\\n\", in_line);\n\t}\n\ti = 0;\n\tj = strlen(buf);\n\tfd = open(poe_cmd_fname, O_TRUNC | O_RDWR);\n\tif (fd < 0) {\n\t\terror(\"open(%s): %m\", poe_cmd_fname);\n\t\txfree(buf);\n\t\treturn;\n\t}\n\twhile ((k = write(fd, &buf[i], j))) {\n\t\tif (k > 0) {\n\t\t\ti += k;\n\t\t\tj -= k;\n\t\t} else if ((errno != EAGAIN) && (errno != EINTR)) {\n\t\t\terror(\"write(cmdfile): %m\");\n\t\t\tbreak;\n\t\t}\n\t}\n\tclose(fd);\n\txfree(buf);\n}\n\nvoid _self_complete(srun_job_complete_msg_t *comp_msg)\n{\n\tkill(getpid(), SIGKILL);\n}\n\nvoid _self_signal(int signal)\n{\n\tkill(getpid(), signal);\n}\n\nvoid _self_timeout(srun_timeout_msg_t *timeout_msg)\n{\n\ttime_t now = time(NULL);\n\tchar time_str[24];\n\n\tif (now < timeout_msg->timeout) {\n\t\tslurm_make_time_str(&timeout_msg->timeout,\n\t\t\t\t    time_str, sizeof(time_str));\n\t\tdebug(\"step %u.%u will timeout at %s\",\n\t\t      timeout_msg->job_id, timeout_msg->step_id, time_str);\n\t\treturn;\n\t}\n\n\tslurm_make_time_str(&now, time_str, sizeof(time_str));\n\terror(\"*** STEP %u.%u CANCELLED AT %s DUE TO TIME LIMIT ***\",\n\t      timeout_msg->job_id, timeout_msg->step_id, time_str);\n\t_self_signal(SIGKILL);\n}\n\n/************************************/\n\n/* The connection communicates information to and from the resource\n * manager, so that the resource manager can start the parallel task\n * manager, and is available for the caller to communicate directly\n * with the parallel task manager.\n * IN resource_mgr - The resource manager handle returned by pe_rm_init.\n * IN connect_param - Input parameter structure (rm_connect_param)\n *        that contains the following:\n *        machine_count: The count of hosts/machines.\n *        machine_name: The array of machine names on which to connect.\n *        executable: The name of the executable to be started.\n * IN rm_timeout - The integer value that defines a connection timeout\n *        value. This value is defined by the MP_RM_TIMEOUT\n *        environment variable. A value less than zero indicates there\n *        is no timeout. A value equal to zero means to immediately\n *        return with no wait or retry. A value greater than zero\n *        means to wait the specified amount of time (in seconds).\n * OUT rm_sockfds - An array of socket file descriptors, that are\n *        allocated by the caller, to be returned as output, of the connection.\n * OUT error_msg - An error message that explains the error.\n * RET 0 - SUCCESS, nonzero on failure.\n */\nextern int pe_rm_connect(rmhandle_t resource_mgr,\n\t\t\t rm_connect_param *connect_param,\n\t\t\t int *rm_sockfds, int rm_timeout, char **error_msg)\n{\n\tslurm_step_launch_callbacks_t step_callbacks;\n//\tsrun_job_t *job = *(srun_job_t **)resource_mgr;\n\tint my_argc = 1;\n\tchar *my_argv[2] = { connect_param->executable, NULL };\n//\tchar *my_argv[2] = { \"/bin/hostname\", NULL };\n\tslurm_step_io_fds_t cio_fds = SLURM_STEP_IO_FDS_INITIALIZER;\n\tuint32_t global_rc = 0, orig_task_num;\n\tint i, ii = 0, rc, fd_cnt, node_cnt;\n\tint *ctx_sockfds = NULL;\n\tchar *name = NULL, *total_node_list = NULL;\n\tstatic uint32_t task_num = 0;\n\thostlist_t hl = NULL;\n\n\txassert(job);\n\n\tif (pm_type == PM_PMD) {\n\t\tdebug(\"got pe_rm_connect called from PMD\");\n\t\t/* Set up how many tasks the PMD is going to launch. */\n\t\tjob->ntasks = 1 + task_num;\n\t} else if (pm_type == PM_POE) {\n\t\tdebug(\"got pe_rm_connect called\");\n\t\tlaunch_common_set_stdio_fds(job, &cio_fds, &opt);\n\t} else {\n\t\t*error_msg = malloc(sizeof(char) * err_msg_len);\n\t\tsnprintf(*error_msg, err_msg_len,\n\t\t\t \"pe_rm_connect: unknown caller\");\n\t\terror(\"%s\", *error_msg);\n\t\treturn -1;\n\t}\n\n\t/* translate the ip to a node list which SLURM uses to send\n\t   messages instead of IP addresses (at this point anyway)\n\t*/\n\tfor (i=0; i<connect_param->machine_count; i++) {\n\t\tname = _name_from_addr(connect_param->machine_name[i]);\n\t\tif (!name) {\n\t\t\tif (hl)\n\t\t\t\thostlist_destroy(hl);\n\t\t\t*error_msg = malloc(sizeof(char) * err_msg_len);\n\t\t\tsnprintf(*error_msg, err_msg_len,\n\t\t\t\t \"pe_rm_connect: unknown host for ip %s\",\n\t\t\t\t connect_param->machine_name[i]);\n\t\t\terror(\"%s\", *error_msg);\n\t\t\treturn -1;\n\t\t}\n\n\t\tif (!hl)\n\t\t\thl = hostlist_create(name);\n\t\telse\n\t\t\thostlist_push_host(hl, name);\n\n\t\tif (!total_hl)\n\t\t\ttotal_hl = hostlist_create(name);\n\t\telse\n\t\t\thostlist_push_host(total_hl, name);\n\t}\n\n\tif (!hl) {\n\t\t*error_msg = malloc(sizeof(char) * err_msg_len);\n\t\tsnprintf(*error_msg, err_msg_len,\n\t\t\t \"pe_rm_connect: machine_count 0? it came in as \"\n\t\t\t \"%d but we didn't get a hostlist\",\n\t\t\t connect_param->machine_count);\n\t\terror(\"%s\", *error_msg);\n\t\treturn -1;\n\t}\n\n\t/* Can't sort the list here because the ordering matters when\n\t * launching tasks.\n\t */\n\t//hostlist_sort(hl);\n\txfree(job->nodelist);\n\tjob->nodelist = hostlist_ranged_string_xmalloc(hl);\n\thostlist_destroy(hl);\n\n\t//hostlist_sort(total_hl);\n\ttotal_node_list = hostlist_ranged_string_xmalloc(total_hl);\n\tnode_cnt = hostlist_count(total_hl);\n\n\tsropt.argc = my_argc;\n\tsropt.argv = my_argv;\n\tsropt.user_managed_io = true;\n\t/* Disable binding of the pvmd12 task so it has access to all resources\n\t * allocated to the job step and can use them for spawned tasks. */\n\tsropt.cpu_bind_type = CPU_BIND_NONE;\n\torig_task_num = task_num;\n\tif (slurm_step_ctx_daemon_per_node_hack(job->step_ctx,\n\t\t\t\t\t\ttotal_node_list,\n\t\t\t\t\t\tnode_cnt, &task_num)\n\t    != SLURM_SUCCESS) {\n\t\txfree(total_node_list);\n\t\t*error_msg = malloc(sizeof(char) * err_msg_len);\n\t\tsnprintf(*error_msg, err_msg_len,\n\t\t\t \"pe_rm_connect: problem with hack: %s\",\n\t\t\t slurm_strerror(errno));\n\t\terror(\"%s\", *error_msg);\n\t\treturn -1;\n\t}\n\txfree(total_node_list);\n\tjob->fir_nodeid = orig_task_num;\n\n\tmemset(&step_callbacks, 0, sizeof(step_callbacks));\n\tstep_callbacks.step_complete = _self_complete;\n\tstep_callbacks.step_signal   = _self_signal;\n\tstep_callbacks.step_timeout  = _self_timeout;\n\n\tif (launch_g_step_launch(job, &cio_fds, &global_rc,\n\t\t\t\t &step_callbacks, &opt)) {\n\t\t*error_msg = malloc(sizeof(char) * err_msg_len);\n\t\tsnprintf(*error_msg, err_msg_len,\n\t\t\t \"pe_rm_connect: problem with launch: %s\",\n\t\t\t slurm_strerror(errno));\n\t\terror(\"%s\", *error_msg);\n\t\treturn -1;\n\t}\n\n\trc = slurm_step_ctx_get(job->step_ctx,\n\t\t\t\tSLURM_STEP_CTX_USER_MANAGED_SOCKETS,\n\t\t\t\t&fd_cnt, &ctx_sockfds);\n\tif (ctx_sockfds == NULL) {\n\t\t*error_msg = malloc(sizeof(char) * err_msg_len);\n\t\tsnprintf(*error_msg, err_msg_len,\n\t\t\t \"pe_rm_connect: Unable to get pmd IO socket array %d\",\n\t\t\t rc);\n\t\terror(\"%s\", *error_msg);\n\t\treturn -1;\n\t}\n\tif (fd_cnt != task_num) {\n\t\t*error_msg = malloc(sizeof(char) * err_msg_len);\n\t\tsnprintf(*error_msg, err_msg_len,\n\t\t\t \"pe_rm_connect: looking for %d sockets but \"\n\t\t\t \"got back %d\",\n\t\t\t connect_param->machine_count, fd_cnt);\n\t\terror(\"%s\", *error_msg);\n\t\treturn -1;\n\t}\n\tii = 0;\n\tfor (i=orig_task_num; i<fd_cnt; i++)\n\t\trm_sockfds[ii++] = ctx_sockfds[i];\n\t/* Since opt is a global variable we need to remove the\n\t   dangling reference set here.  This shouldn't matter, but\n\t   Clang reported it so we are making things quite here.\n\t*/\n\tsropt.argv = NULL;\n\treturn 0;\n}\n\n/* Releases the resource manager handle, closes the socket that is\n * created by the pe_rm_init function, and releases memory\n * allocated. When called, pe_rm_free implies the job has completed\n * and resources are freed and available for subsequent jobs.\n * IN/OUT resource_mgr\n *\n * As of PE 1207 pe_rm_free does not always complete.  The parent\n * process seems to finish before we do.  So you might be erronious errors.\n */\nextern void pe_rm_free(rmhandle_t *resource_mgr)\n{\n\tuint32_t rc = 0;\n\n\tif (job && job->step_ctx) {\n\t\tdebug(\"got pe_rm_free called %p %p\", job, job->step_ctx);\n\t\t/* Since we can't relaunch the step here don't worry about the\n\t\t   return code.\n\t\t*/\n\t\tlaunch_g_step_wait(job, got_alloc, &opt);\n\t\t/* We are at the end so don't worry about freeing the\n\t\t   srun_job_t pointer */\n\t\tfini_srun(job, got_alloc, &rc, slurm_started);\n\t}\n\n\tif (total_hl) {\n\t\thostlist_destroy(total_hl);\n\t\ttotal_hl = NULL;\n\t}\n\t*resource_mgr = NULL;\n\tdlclose(my_handle);\n\tif (poe_cmd_fname)\n\t\t(void) unlink(poe_cmd_fname);\n\t/* remove the hostfile if needed */\n\tif ((poe_cmd_fname = getenv(\"SRUN_DESTROY_HOSTFILE\")))\n\t\t(void) unlink(poe_cmd_fname);\n}\n\n/* The memory that is allocated to events generated by the resource\n * manager is released. pe_rm_free_event must be called for every\n * event that is received from the resource manager by calling the\n * pe_rm_get_event function.\n * IN resource_mgr\n * IN job_event - The pointer to a job event. The event must have been\n *        built by calling the pe_rm_get_event function.\n * RET 0 - SUCCESS, nonzero on failure.\n */\nextern int pe_rm_free_event(rmhandle_t resource_mgr, job_event_t ** job_event)\n{\n\tif (pm_type == PM_PMD) {\n\t\tdebug(\"pe_rm_free_event called\");\n\t\treturn 0;\n\t} else if (pm_type != PM_POE) {\n\t\terror(\"pe_rm_free_event: unknown caller\");\n\t\treturn -1;\n\t}\n\n\tdebug(\"got pe_rm_free_event called\");\n\tif (job_event) {\n\t\tfree(*job_event);\n\t}\n\treturn 0;\n}\n\n/* This resource management interface is called to return job event\n * information. The pe_rm_get_event function is only called in\n * interactive mode.\n *\n * With interactive jobs, this function reads or selects on the listen\n * socket created by the pe_rm_init call. If the listen socket is not\n * ready to read, this function selects and waits. POE processes\n * should monitor this socket at all times for event notification from\n * the resource manager after the job has started running.\n *\n * This function returns a pointer to the event that was updated by\n * the transaction.\n * The valid events are:\n * JOB_ERROR_EVENT\n *        Job error messages occurred. In this case, POE displays the\n *        error and terminates.\n * JOB_STATE_EVENT\n *        A job status change occurred, which results in one of the\n *        following job states. In this case, the caller may need to take\n *        appropriate action.\n *     JOB_STATE_RUNNING\n *        Indicates that the job has started. POE uses the\n *        pe_rm_get_job_info function to return the job\n *        information. When a job state of JOB_STATE_RUNNING has been\n *        returned, the job has started running and POE can obtain the\n *        job information by way of the pe_rm_get_job_info function call.\n *     JOB_STATE_NOTRUN\n *        Indicates that the job was not run, and POE will terminate.\n *     JOB_STATE_PREEMPTED\n *        Indicates that the job was preempted.\n *     JOB_STATE_RESUMED\n *        Indicates that the job has resumed.\n * JOB_TIMER_EVENT\n *        Indicates that no events occurred during the period\n *        specified by pe_rm_timeout.\n *\n * IN resource_mgr\n * OUT job_event - The address of the pointer to the job_event_t\n *        type. If an event is generated successfully by the resource\n *        manager, that event is saved at the location specified, and\n *        pe_rm_get_event returns 0 (or a nonzero value, if the event\n *        is not generated successfully). Based on the event type that is\n *        returned, the appropriate event of the type job_event_t can\n *        be accessed. After the event is processed, it should be\n *        freed by calling pe_rm_free_event.\n * OUT error_msg - The address of a character string at which the\n *        error message that is generated by pe_rm_get_event is\n *        stored. The memory for this error message is allocated by\n *        the malloc API call. After the error message is processed,\n *        the memory allocated should be freed by a calling free function.\n * IN rm_timeout - The integer value that defines a connection timeout\n *        value. This value is defined by the MP_RETRY environment\n *        variable. A value less than zero indicates there is no\n *        timeout. A value equal to zero means to immediately return\n *        with no wait or retry. A value greater than zero means to\n *        wait the specified amount of time (in seconds).\n * RET 0 - SUCCESS, nonzero on failure.\n */\nextern int pe_rm_get_event(rmhandle_t resource_mgr, job_event_t **job_event,\n\t\t\t   int rm_timeout, char ** error_msg)\n{\n\tjob_event_t *ret_event = NULL;\n\tint *state;\n\tif (pm_type == PM_PMD) {\n\t\tdebug(\"pe_rm_get_event called\");\n\t\treturn 0;\n\t} else if (pm_type != PM_POE) {\n\t\t*error_msg = malloc(sizeof(char) * err_msg_len);\n\t\tsnprintf(*error_msg, err_msg_len,\n\t\t\t \"pe_rm_get_event: unknown caller\");\n\t\terror(\"%s\", *error_msg);\n\t\treturn -1;\n\t}\n\n\tdebug(\"got pe_rm_get_event called %d %p %p\",\n\t      rm_timeout, job_event, *job_event);\n\n\tret_event = malloc(sizeof(job_event_t));\n\tmemset(ret_event, 0, sizeof(job_event_t));\n\t*job_event = ret_event;\n\tret_event->event = JOB_STATE_EVENT;\n\tstate = malloc(sizeof(int));\n\t*state = JOB_STATE_RUNNING;\n\tret_event->event_data = (void *)state;\n\n\treturn 0;\n}\n\n/* The pe_rm_get_job_info function is called to return job\n * information, after a job has been started. It can be called in\n * either batch or interactive mode. For interactive jobs, it should\n * be called when pe_rm_get_event returns with the JOB_STATE_EVENT\n * event type, indicating the JOB_STATE_RUNNING\n * state. pe_rm_get_job_info provides the job information data values,\n * as defined by the job_info_t structure. It returns with an error if\n * the job is not in a running state. For batch jobs, POE calls\n * pe_rm_get_job_info immediately because, in batch mode, POE is\n * started only after the job has been started. The pe_rm_get_job_info\n * function must be capable of being called multiple times from the\n * same process or a different process, and the same job data must be\n * returned each time. When called from a different process, the\n * environment of that process is guaranteed to be the same as the\n * environment of the process that originally called the function.\n *\n * IN resource_mgr\n * OUT job_info - The address of the pointer to the job_info_t\n *        type. The job_info_t type contains the job information\n *        returned by the resource manager for the handle that is\n *        specified. The caller itself must free the data areas that\n *        are returned.\n * OUT error_msg - The address of a character string at which the\n *        error message that is generated by pe_rm_get_job_info is\n *        stored. The memory for this error message is allocated by the\n *        malloc API call. After the error message is processed, the memory\n *        allocated should be freed by a calling free function.\n * RET 0 - SUCCESS, nonzero on failure.\n */\nextern int pe_rm_get_job_info(rmhandle_t resource_mgr, job_info_t **job_info,\n\t\t\t      char ** error_msg)\n{\n\tjob_info_t *ret_info = malloc(sizeof(job_info_t));\n\tint i, j;\n\tslurm_step_layout_t *step_layout;\n\thostlist_t hl;\n\tchar *host;\n\tchar *mode = \"IP\";\n\thost_usage_t *host_ptr;\n\tint table_cnt;\n\tnrt_tableinfo_t *tables, *table_ptr;\n\tnrt_job_key_t job_key;\n\tjob_step_create_response_msg_t *resp;\n\tint network_id_cnt = 0, size = 0;\n\tnrt_network_id_t *network_id_list;\n\tchar value[32];\n\n\tmemset(ret_info, 0, sizeof(job_info_t));\n\n\tif (pm_type == PM_PMD) {\n\t\tdebug(\"pe_rm_get_job_info called\");\n\t\treturn 0;\n\t} else if (pm_type != PM_POE) {\n\t\t*error_msg = malloc(sizeof(char) * err_msg_len);\n\t\tsnprintf(*error_msg, err_msg_len,\n\t\t\t \"pe_rm_get_job_info: unknown caller\");\n\t\terror(\"%s\", *error_msg);\n\t\treturn -1;\n\t}\n\n\tdebug(\"got pe_rm_get_job_info called\");\n\tif (!job || !job->step_ctx) {\n\t\terror(\"pe_rm_get_job_info: It doesn't appear \"\n\t\t      \"pe_rm_submit_job was called.  I am guessing \"\n\t\t      \"PE_RM_BATCH is set somehow.  It things don't work well \"\n\t\t      \"using this mode unset the env var and retry.\");\n\t\tcreate_srun_job((void **)&job, &got_alloc, slurm_started, 0);\n\t\t/* make sure we set up a signal handler */\n\t\tpre_launch_srun_job(job, slurm_started, 0, &opt);\n\t}\n\n\t*job_info = ret_info;\n\tif (opt.job_name)\n\t\tret_info->job_name = strdup(opt.job_name);\n\tret_info->rm_id = NULL;\n\tret_info->procs = job->ntasks;\n\tret_info->max_instances = 0;\n\tret_info->check_pointable = 0;\n\tret_info->rset_name = \"RSET_NONE\";\n\tret_info->endpoints = 1;\n\n\tslurm_step_ctx_get(job->step_ctx, SLURM_STEP_CTX_RESP, &resp);\n\tif (!resp) {\n\t\t*error_msg = malloc(sizeof(char) * err_msg_len);\n\t\tsnprintf(*error_msg, err_msg_len,\n\t\t\t \"pe_rm_get_job_info: no step response in step ctx\");\n\t\terror(\"%s\", *error_msg);\n\t\treturn -1;\n\t}\n\tslurm_jobinfo_ctx_get(resp->switch_job, NRT_JOBINFO_KEY, &job_key);\n\tret_info->job_key = job_key;\n\n\tif (opt.network) {\n\t\tchar *network_str = xstrdup(opt.network);\n\t\tchar *save_ptr = NULL,\n\t\t\t*token = strtok_r(network_str, \",\", &save_ptr);\n\t\twhile (token) {\n\t\t\t/* network options */\n\t\t\tif (!xstrcasecmp(token, \"ip\")   ||\n\t\t\t    !xstrcasecmp(token, \"ipv4\")  ||\n\t\t\t    !xstrcasecmp(token, \"ipv6\")) {\n\t\t\t\tmode = \"IP\";\n\t\t\t} else if (!xstrcasecmp(token, \"us\")) {\n\t\t\t\tmode = \"US\";\n\t\t\t}\n\t\t\t/* Currently ignoring all other options */\n\t\t\ttoken = strtok_r(NULL, \",\", &save_ptr);\n\t\t}\n\t\txfree(network_str);\n\t}\n\n\tslurm_jobinfo_ctx_get(\n\t\tresp->switch_job, NRT_JOBINFO_TABLESPERTASK, &table_cnt);\n\tsize = sizeof(char *)*(table_cnt+1);\n\tret_info->protocol = malloc(size);\n\tmemset(ret_info->protocol, 0, size);\n\tret_info->mode = malloc(size);\n\tmemset(ret_info->mode, 0, size);\n\tret_info->devicename = malloc(size);\n\tmemset(ret_info->devicename, 0, size);\n\tsize = sizeof(char *)*(table_cnt+2);\n\tret_info->instance = malloc(size);\n\tmemset(ret_info->instance, 0, size);\n\n\tslurm_jobinfo_ctx_get(resp->switch_job, NRT_JOBINFO_TABLEINFO, &tables);\n\tdebug2(\"got count of %d\", table_cnt);\n\tnetwork_id_list = xmalloc(sizeof(nrt_network_id_t) * table_cnt);\n\tfor (i=0, table_ptr=tables; i<table_cnt; i++, table_ptr++) {\n\t\tfor (j = 0; j < network_id_cnt; j++) {\n\t\t\tif (table_ptr->network_id == network_id_list[j])\n\t\t\t\tbreak;\n\t\t}\n\t\tif (j >= network_id_cnt) {\n\t\t\t/* add this new network ID to our table */\n\t\t\tnetwork_id_list[network_id_cnt++] =\n\t\t\t\ttable_ptr->network_id;\n\t\t}\n/* FIXME: Format of these data structure contents not well defined */\n\t\tif (table_ptr->protocol_name)\n\t\t\tret_info->protocol[i] =\n\t\t\t\tstrdup(table_ptr->protocol_name);\n\t\tif (mode)\n\t\t\tret_info->mode[i] = strdup(mode);\n\t\tif (table_ptr->adapter_name)\n\t\t\tret_info->devicename[i] =\n\t\t\t\tstrdup(table_ptr->adapter_name);\n\t\tret_info->instance[i] = table_ptr->instance;\n\t\tret_info->max_instances = MAX(ret_info->max_instances,\n\t\t\t\t\t      ret_info->instance[i]);\n\t\tdebug(\"%d: %s %s %s %d\", i, ret_info->protocol[i],\n\t\t      ret_info->mode[i], ret_info->devicename[i],\n\t\t      ret_info->instance[i]);\n\t}\n\txfree(network_id_list);\n\tret_info->instance[i] = -1;\n\tret_info->num_network = network_id_cnt;\n\tret_info->host_count = job->nhosts;\n\n\tstep_layout = launch_common_get_slurm_step_layout(job);\n\n\tsize = sizeof(host_usage_t) * (ret_info->host_count+1);\n\tret_info->hosts = malloc(size);\n\tmemset(ret_info->hosts, 0, size);\n\n\thost_ptr = ret_info->hosts;\n\ti=0;\n\thl = hostlist_create(step_layout->node_list);\n\twhile ((host = hostlist_shift(hl))) {\n\t\tslurm_addr_t addr;\n\t\thost_ptr->host_name = host;\n\t\tslurm_conf_get_addr(host, &addr);\n\t\thost_ptr->host_address = strdup(inet_ntoa(addr.sin_addr));\n\t\thost_ptr->task_count = step_layout->tasks[i];\n\t\tsize = sizeof(int) * host_ptr->task_count;\n\t\thost_ptr->task_ids = malloc(size);\n\t\tmemset(host_ptr->task_ids, 0, size);\n\n\t\t/* Task ids are already set up in the layout, so just\n\t\t   use them.\n\t\t*/\n\t\tdebug2(\"%s = %s %d tasks\",\n\t\t       host_ptr->host_name, host_ptr->host_address,\n\t\t       host_ptr->task_count);\n\t\tfor (j=0; j<host_ptr->task_count; j++) {\n\t\t\thost_ptr->task_ids[j] = step_layout->tids[i][j];\n\t\t\tdebug2(\"taskid %d\", host_ptr->task_ids[j]);\n\t\t}\n\t\ti++;\n\t\tif (i > ret_info->host_count) {\n\t\t\terror(\"we have more nodes that we bargined for.\");\n\t\t\tbreak;\n\t\t}\n\t\thost_ptr++;\n\t}\n\thostlist_destroy(hl);\n\thost_usage = ret_info->hosts;\n\n\tif (!got_alloc || !slurm_started) {\n\t\tsnprintf(value, sizeof(value), \"%u\", job->jobid);\n\t\tsetenv(\"SLURM_JOB_ID\", value, 1);\n\t\tsetenv(\"SLURM_JOBID\", value, 1);\n\t\tsetenv(\"SLURM_JOB_NODELIST\", job->nodelist, 1);\n\t}\n\n\tif (!sropt.preserve_env) {\n\t\tsnprintf(value, sizeof(value), \"%u\", job->ntasks);\n\t\tsetenv(\"SLURM_NTASKS\", value, 1);\n\t\tsnprintf(value, sizeof(value), \"%u\", job->nhosts);\n\t\tsetenv(\"SLURM_NNODES\", value, 1);\n\t\tsetenv(\"SLURM_NODELIST\", job->nodelist, 1);\n\t}\n\n\tsnprintf(value, sizeof(value), \"%u\", job->stepid);\n\tsetenv(\"SLURM_STEP_ID\", value, 1);\n\tsetenv(\"SLURM_STEPID\", value, 1);\n\tsetenv(\"SLURM_STEP_NODELIST\", step_layout->node_list, 1);\n\tsnprintf(value, sizeof(value), \"%u\", job->nhosts);\n\tsetenv(\"SLURM_STEP_NUM_NODES\", value, 1);\n\tsnprintf(value, sizeof(value), \"%u\", job->ntasks);\n\tsetenv(\"SLURM_STEP_NUM_TASKS\", value, 1);\n\thost = _uint16_array_to_str(step_layout->node_cnt,\n\t\t\t\t    step_layout->tasks);\n\tsetenv(\"SLURM_STEP_TASKS_PER_NODE\", host, 1);\n\txfree(host);\n\treturn 0;\n}\n\n/* The handle to the resource manager is returned to the calling\n * function. The calling process needs to use the resource manager\n * handle in subsequent resource manager API calls.\n *\n * A version will be returned as output in the rmapi_version\n * parameter, after POE supplies it as input. The resource manager\n * returns the version value that is installed and running as output.\n *\n * A resource manager ID can be specified that defines a job that is\n * currently running, and for which POE is initializing the resource\n * manager. When the resource manager ID is null, a value for the\n * resource manager ID is included with the job information that is\n * returned by the pe_rm_get_job_info function. When pe_rm_init is\n * called more than once with a null resource manager ID value, it\n * returns the same ID value on the subsequent pe_rm_get_job_info\n * function call.\n *\n * The resource manager can be initialized in either\n * batch or interactive mode. The resource manager must export the\n * environment variable PE_RM_BATCH=yes when in batch mode.\n *\n * By default, the resource manager error messages and any debugging\n * messages that are generated by this function, or any subsequent\n * resource manager API calls, should be written to STDERR. Errors are\n * returned by way of the error message string parameter.\n *\n * When the resource manager is successfully instantiated and\n * initialized, it returns with a file descriptor for a listen socket,\n * which is used by the resource manager daemon to communicate with\n * the calling process. If a resource manager wants to send\n * information to the calling process, it builds an appropriate event\n * that corresponds to the information and sends that event over the\n * socket to the calling process. The calling process could monitor\n * the socket using the select API and read the event when it is ready.\n *\n * IN/OUT rmapi_version - The resource manager API version level. The\n *        value of RM_API_VERSION is defined in permapi.h. Initially,\n *        POE provides this as input, and the resource manager will\n *        return its version level as output.\n * OUT resource_mgr - Pointer to the rmhandle_t handle returned by the\n *        pe_rm_init function. This handle should be used by all other\n *        resource manager API calls.\n * IN rm_id - Pointer to a character string that defines a\n *        resource manager ID, for checkpoint and restart cases. This\n *        pointer can be set to NULL, which means there is no previous\n *        resource manager session or job running. When it is set to a\n *        value, the resource manager uses the specified ID for\n *        returning the proper job information to a subsequent\n *        pe_rm_get_job_info function call.\n * OUT error_msg - The address of a character string at which the\n *        error messages generated by this function are stored. The\n *        memory for this error message is allocated by the malloc API\n *        call. After the error message is processed, the memory\n *        allocated should be freed by a calling free function.\n * RET - Non-negative integer representing a valid file descriptor\n *        number for the socket that will be used by the resource\n *        manager to communicate with the calling process. - SUCCESS\n *        integer less than 0 - FAILURE\n */\nextern int pe_rm_init(int *rmapi_version, rmhandle_t *resource_mgr, char *rm_id,\n\t\t      char** error_msg)\n{\n\tchar *srun_debug = NULL, *tmp_char = NULL;\n\tchar *myargv[3] = { \"poe\", NULL, NULL };\n\tint debug_level = log_opts.logfile_level;\n\n\tif (geteuid() == 0)\n\t\terror(\"POE will not run as user root\");\n\n\t/* SLURM was originally written against 1300, so we will\n\t * return that, no matter what comes in so we always work.\n\t */\n\t*rmapi_version = 1300;\n\t*resource_mgr = (void *)&job;\n\n#ifdef MYSELF_SO\n\t/* Since POE opens this lib without\n\t   RTLD_LAZY | RTLD_GLOBAL | RTLD_DEEPBIND\n\t   we just open ourself again with those options and bada bing\n\t   bada boom we are good to go with the symbols we need.\n\t*/\n\tmy_handle = dlopen(MYSELF_SO, RTLD_LAZY | RTLD_GLOBAL | RTLD_DEEPBIND);\n\tif (!my_handle) {\n\t\tdebug(\"%s\", dlerror());\n\t\treturn 1;\n\t}\n#else\n\tfatal(\"I haven't been told where I am.  This should never happen.\");\n#endif\n\n\tif (slurm_select_init(1) != SLURM_SUCCESS )\n\t\tfatal( \"failed to initialize node selection plugin\" );\n\n\tslurm_set_launch_type(\"launch/slurm\");\n\n\tif (getenv(\"SLURM_STARTED_STEP\"))\n\t\tslurm_started = true;\n\tif ((srun_debug = getenv(\"SRUN_DEBUG\")))\n\t\tdebug_level = atoi(srun_debug);\n\tif (debug_level) {\n\t\tlog_opts.stderr_level = log_opts.logfile_level =\n\t\t\tlog_opts.syslog_level = debug_level;\n\t}\n\n\t/* This will be used later in the code to set the\n\t * _verbose level. */\n\tif (debug_level >= LOG_LEVEL_INFO)\n\t\tdebug_level -= LOG_LEVEL_INFO;\n\n\tif (pm_type == PM_PMD) {\n\t\tlog_alter_with_fp(log_opts, LOG_DAEMON, pmd_lfp);\n\t\tmyargv[0] = myargv[1] = \"pmd\";\n\t} else {\n\t\tchar *poe_argv = getenv(\"MP_I_SAVED_ARGV\");\n\t\tlog_alter(log_opts, LOG_DAEMON, \"/dev/null\");\n\n\t\tmyargv[1] = getenv(\"SLURM_JOB_NAME\");\n\n\t\tif (poe_argv) {\n\t\t\tchar *adapter_use = NULL;\n\t\t\tchar *bulk_xfer = NULL;\n\t\t\tchar *collectives = NULL;\n\t\t\tchar *euidevice = NULL;\n\t\t\tchar *euilib = NULL;\n\t\t\tchar *immediate = NULL;\n\t\t\tchar *instances = NULL;\n\t\t\tchar *tmp_argv = xstrdup(poe_argv);\n\t\t\tchar *tok, *save_ptr = NULL;\n\t\t\tint tok_inx = 0;\n\n\t\t\t/* Parse the command line\n\t\t\t * Map the following options to their srun equivalent\n\t\t\t * -adapter_use shared | dedicated\n\t\t\t * -collective_groups #\n\t\t\t * -euidevice sn_all | sn_single\n\t\t\t * -euilib ip | us\n\t\t\t * -imm_send_buffers #\n\t\t\t * -instances #\n\t\t\t * -use_bulk_xfer yes | no\n\t\t\t */\n\t\t\ttok = strtok_r(tmp_argv, \" \", &save_ptr);\n\t\t\twhile (tok) {\n\t\t\t\tif ((tok_inx == 1) && !myargv[1]) {\n\t\t\t\t\tmyargv[1] = xstrdup(tok);\n\t\t\t\t} else if (!xstrcmp(tok, \"-adapter_use\")) {\n\t\t\t\t\ttok = strtok_r(NULL, \" \", &save_ptr);\n\t\t\t\t\tif (!tok)\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tadapter_use = xstrdup(tok);\n\t\t\t\t} else if (!xstrcmp(tok, \"-collective_groups\")){\n\t\t\t\t\ttok = strtok_r(NULL, \" \", &save_ptr);\n\t\t\t\t\tif (!tok)\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcollectives = xstrdup(tok);\n\t\t\t\t} else if (!xstrcmp(tok, \"-euidevice\")) {\n\t\t\t\t\ttok = strtok_r(NULL, \" \", &save_ptr);\n\t\t\t\t\tif (!tok)\n\t\t\t\t\t\tbreak;\n\t\t\t\t\teuidevice = xstrdup(tok);\n\t\t\t\t} else if (!xstrcmp(tok, \"-euilib\")) {\n\t\t\t\t\ttok = strtok_r(NULL, \" \", &save_ptr);\n\t\t\t\t\tif (!tok)\n\t\t\t\t\t\tbreak;\n\t\t\t\t\teuilib = xstrdup(tok);\n\t\t\t\t} else if (!xstrcmp(tok, \"-imm_send_buffers\")) {\n\t\t\t\t\ttok = strtok_r(NULL, \" \", &save_ptr);\n\t\t\t\t\tif (!tok)\n\t\t\t\t\t\tbreak;\n\t\t\t\t\timmediate = xstrdup(tok);\n\t\t\t\t} else if (!xstrcmp(tok, \"-instances\")) {\n\t\t\t\t\ttok = strtok_r(NULL, \" \", &save_ptr);\n\t\t\t\t\tif (!tok)\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tinstances = xstrdup(tok);\n\t\t\t\t} else if (!xstrcmp(tok, \"-use_bulk_xfer\")) {\n\t\t\t\t\ttok = strtok_r(NULL, \" \", &save_ptr);\n\t\t\t\t\tif (!tok)\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tbulk_xfer = xstrdup(tok);\n\t\t\t\t}\n\n\t\t\t\ttok = strtok_r(NULL, \" \", &save_ptr);\n\t\t\t\ttok_inx++;\n\t\t\t}\n\t\t\txfree(tmp_argv);\n\n\t\t\t/* Parse the environment variables */\n\t\t\tif (!adapter_use) {\n\t\t\t\tchar *tmp = getenv(\"MP_ADAPTER_USE\");\n\t\t\t\tif (tmp)\n\t\t\t\t\tadapter_use = xstrdup(tmp);\n\t\t\t}\n\t\t\tif (!collectives) {\n\t\t\t\tchar *tmp = getenv(\"MP_COLLECTIVE_GROUPS\");\n\t\t\t\tif (tmp)\n\t\t\t\t\tcollectives = xstrdup(tmp);\n\t\t\t}\n\t\t\tif (!euidevice) {\n\t\t\t\tchar *tmp = getenv(\"MP_EUIDEVICE\");\n\t\t\t\tif (tmp)\n\t\t\t\t\teuidevice = xstrdup(tmp);\n\t\t\t}\n\t\t\tif (!euilib) {\n\t\t\t\tchar *tmp = getenv(\"MP_EUILIB\");\n\t\t\t\tif (tmp)\n\t\t\t\t\teuilib = xstrdup(tmp);\n\t\t\t}\n\t\t\tif (!immediate) {\n\t\t\t\tchar *tmp = getenv(\"MP_IMM_SEND_BUFFERS\");\n\t\t\t\tif (tmp)\n\t\t\t\t\timmediate = xstrdup(tmp);\n\t\t\t}\n\t\t\tif (!instances) {\n\t\t\t\tchar *tmp = getenv(\"MP_INSTANCES\");\n\t\t\t\tif (tmp)\n\t\t\t\t\tinstances = xstrdup(tmp);\n\t\t\t}\n\t\t\tif (!bulk_xfer) {\n\t\t\t\tchar *tmp = getenv(\"MP_USE_BULK_XFER\");\n\t\t\t\tif (tmp)\n\t\t\t\t\tbulk_xfer = xstrdup(tmp);\n\t\t\t}\n\t\t\txfree(opt.network);\n\t\t\tif (adapter_use) {\n\t\t\t\tif (!xstrcmp(adapter_use, \"dedicated\"))\n\t\t\t\t\tsropt.exclusive = true;\n\t\t\t\txfree(adapter_use);\n\t\t\t}\n\t\t\tif (collectives) {\n\t\t\t\tif (opt.network)\n\t\t\t\t\txstrcat(opt.network, \",\");\n\t\t\t\txstrcat(opt.network, \"cau=\");\n\t\t\t\txstrcat(opt.network, collectives);\n\t\t\t}\n\t\t\tif (euidevice) {\n\t\t\t\tif (opt.network)\n\t\t\t\t\txstrcat(opt.network, \",\");\n\t\t\t\txstrcat(opt.network, \"devname=\");\n\t\t\t\txstrcat(opt.network, euidevice);\n\t\t\t}\n\t\t\tif (euilib) {\n\t\t\t\tif (opt.network)\n\t\t\t\t\txstrcat(opt.network, \",\");\n\t\t\t\txstrcat(opt.network, euilib);\n\t\t\t}\n\t\t\tif (immediate) {\n\t\t\t\tif (opt.network)\n\t\t\t\t\txstrcat(opt.network, \",\");\n\t\t\t\txstrcat(opt.network, \"immed=\");\n\t\t\t\txstrcat(opt.network, immediate);\n\t\t\t}\n\t\t\tif (instances) {\n\t\t\t\tif (opt.network)\n\t\t\t\t\txstrcat(opt.network, \",\");\n\t\t\t\txstrcat(opt.network, \"instances=\");\n\t\t\t\txstrcat(opt.network, instances);\n\t\t\t}\n\t\t\tif (bulk_xfer && !xstrcmp(bulk_xfer, \"yes\")) {\n\t\t\t\tif (opt.network)\n\t\t\t\t\txstrcat(opt.network, \",\");\n\t\t\t\txstrcat(opt.network, \"bulk_xfer\");\n\t\t\t}\n\t\t\txfree(bulk_xfer);\n\t\t\txfree(collectives);\n\t\t\txfree(euidevice);\n\t\t\txfree(euilib);\n\t\t\txfree(immediate);\n\t\t\txfree(instances);\n\t\t}\n\t\tif (!myargv[1])\n\t\t\tmyargv[1] = \"poe\";\n\t}\n\n\tdebug(\"got pe_rm_init called\");\n\t/* This needs to happen before any other threads so we can\n\t   catch the signals correctly.  Send in NULL for logopts\n\t   because we just set it up.\n\t*/\n\tinit_srun(2, myargv, NULL, debug_level, 0);\n\t/* This has to be done after init_srun so as to not get over\n\t   written. */\n\tif (getenv(\"SLURM_PRESERVE_ENV\"))\n\t\tsropt.preserve_env = true;\n\tif ((tmp_char = getenv(\"SRUN_EXC_NODES\")))\n\t\topt.exc_nodes = xstrdup(tmp_char);\n\tif ((tmp_char = getenv(\"SRUN_WITH_NODES\")))\n\t\topt.nodelist = xstrdup(tmp_char);\n\tif ((tmp_char = getenv(\"SRUN_RELATIVE\"))) {\n\t\tsropt.relative = atoi(tmp_char);\n\t\tsropt.relative_set = 1;\n\t}\n\n\tif (pm_type == PM_PMD) {\n\t\tuint32_t job_id = -1, step_id = -1;\n\n\t\tif ((srun_debug = getenv(\"SLURM_JOB_ID\")))\n\t\t\tjob_id = atoi(srun_debug);\n\t\tif ((srun_debug = getenv(\"SLURM_STEP_ID\")))\n\t\t\tstep_id = atoi(srun_debug);\n\t\tif (job_id == -1 || step_id == -1) {\n\t\t\t*error_msg = malloc(sizeof(char) * err_msg_len);\n\t\t\tsnprintf(*error_msg, err_msg_len,\n\t\t\t\t \"pe_rm_init: SLURM_JOB_ID or SLURM_STEP_ID \"\n\t\t\t\t \"not found %d.%d\", job_id, step_id);\n\t\t\terror(\"%s\", *error_msg);\n\t\t\treturn -1;\n\t\t}\n\n\t\tjob = _read_job_srun_agent();\n\t\tif (!job) {\n\t\t\t*error_msg = malloc(sizeof(char) * err_msg_len);\n\t\t\tsnprintf(*error_msg, err_msg_len,\n\t\t\t\t \"pe_rm_init: no job created\");\n\t\t\terror(\"%s\", *error_msg);\n\t\t\treturn -1;\n\t\t}\n\n\t\tjob->jobid = job_id;\n\t\tjob->stepid = step_id;\n\n\t\tsropt.ifname = sropt.ofname = sropt.efname = \"/dev/null\";\n\t\tjob_update_io_fnames(job, &opt);\n\t} else if (pm_type == PM_POE) {\n\t\t/* Create agent thread to forward job credential needed for\n\t\t * PMD to fanout child processes on other nodes */\n\t\t_spawn_fe_agent();\n\t} else {\n\t\t*error_msg = malloc(sizeof(char) * err_msg_len);\n\t\tsnprintf(*error_msg, err_msg_len,\n\t\t\t \"pe_rm_init: unknown caller\");\n\t\terror(\"%s\", *error_msg);\n\t\treturn -1;\n\t}\n\n\treturn 0;\n}\n\n/* Used to inform the resource manager that a checkpoint is in\n * progress or has completed. POE calls pe_rm_send_event to provide\n * the resource manager with information about the checkpointed job.\n *\n * IN resource_mgr\n * IN job_event - The address of the pointer to the job_info_t type\n *        that indicates if a checkpoint is in progress (with a type\n *        of JOB_CKPT_IN_PROGRESS) or has completed (with a type of\n *        JOB_CKPT_COMPLETE).\n * OUT error_msg - The address of a character string at which the\n *        error message that is generated by pe_rm_send_event is\n *        stored. The memory for this error message is allocated by the\n *        malloc API call. After the error message is processed, the\n *        memory allocated should be freed by a calling free function.\n * RET 0 - SUCCESS, nonzero on failure.\n */\nextern int pe_rm_send_event(rmhandle_t resource_mgr, job_event_t *job_event,\n\t\t\t    char ** error_msg)\n{\n\tint rc;\n\n\tdebug(\"got pe_rm_send_event called with event type %d\",\n\t      job_event->event);\n\n\tif ((job_event->event == JOB_CKPT_COMPLETE) && job) {\n\t\tstruct ckpt_end_data *ckpt_end_ptr = (struct ckpt_end_data *)\n\t\t\tjob_event->event_data;\n\t\trc = slurm_checkpoint_complete(job->jobid, job->stepid,\n\t\t\t\t\t       ckpt_end_ptr->ckpt_start_time,\n\t\t\t\t\t       ckpt_end_ptr->ckpt_rc,\n\t\t\t\t\t       ckpt_end_ptr->ckpt_msg);\n\t\tif (rc != SLURM_SUCCESS) {\n\t\t\terror(\"pe_rm_send_event: Unable to process checkpoint \"\n\t\t\t      \"complete event for %u.%u\",\n\t\t\t      job->jobid, job->stepid);\n\t\t} else {\n\t\t\tdebug(\"pe_rm_send_event: Checkpoint complete for %u.%u\",\n\t\t\t      job->jobid, job->stepid);\n\t\t}\n\t} else if ((job_event->event == JOB_CKPT_IN_PROGRESS) && job) {\n\t\t/* FIXME: This may need to trigger switch/nrt call on each node\n\t\t * to preempt the job. Not sure how this works yet... */\n\t\tdebug(\"pe_rm_send_event: Checkpoint in progress for %u.%u\",\n\t\t      job->jobid, job->stepid);\n\t}\n\n\treturn 0;\n}\n\n/* This function is used to submit an interactive job to the resource\n * manager. The job request is either an object or a file (JCL format)\n * that contains information needed by a job to run by way of the\n * resource manager.\n *\n * IN resource_mgr\n * IN job_cmd - The job request (JCL format), either as an object or a file.\n * OUT error_msg - The address of a character string at which the\n *        error messages generated by this function are stored. The\n *        memory for this error message is allocated by the malloc API\n *        call. After the error message is processed, the memory\n *        allocated should be freed by a calling free function.\n * RET 0 - SUCCESS, nonzero on failure.\n */\nint pe_rm_submit_job(rmhandle_t resource_mgr, job_command_t job_cmd,\n\t\t     char** error_msg)\n{\n\tchar *slurm_cmd_fname = NULL;\n\tjob_request_t *pe_job_req = NULL;\n\n\tif (pm_type == PM_PMD) {\n\t\tdebug(\"pe_rm_submit_job called from PMD\");\n\t\treturn 0;\n\t} else if (pm_type == PM_POE) {\n\t\tslurm_cmd_fname = getenv(\"SLURM_CMDFILE\");\n\t\tif (slurm_cmd_fname)\n\t\t\tpoe_cmd_fname = getenv(\"MP_CMDFILE\");\n\t} else {\n\t\t*error_msg = malloc(sizeof(char) * err_msg_len);\n\t\tsnprintf(*error_msg, err_msg_len,\n\t\t\t \"pe_rm_submit_job: unknown caller\");\n\t\terror(\"%s\", *error_msg);\n\t\treturn -1;\n\t}\n\n\tdebug(\"got pe_rm_submit_job called %d\", job_cmd.job_format);\n\tif (job_cmd.job_format != 1) {\n\t\t/* We don't handle files */\n\t\t*error_msg = malloc(sizeof(char) * err_msg_len);\n\t\tsnprintf(*error_msg, err_msg_len,\n\t\t\t \"pe_rm_submit_job: SLURM doesn't handle files \"\n\t\t\t \"to submit_job\");\n\t\terror(\"%s\", *error_msg);\n\t\treturn -1;\n\t}\n\n\tpe_job_req = (job_request_t *)job_cmd.job_command;\n\tdebug2(\"num_nodes\\t= %d\", pe_job_req->num_nodes);\n\tdebug2(\"tasks_per_node\\t= %d\", pe_job_req->tasks_per_node);\n\tdebug2(\"total_tasks\\t= %d\", pe_job_req->total_tasks);\n\tdebug2(\"usage_mode\\t= %d\", pe_job_req->node_usage);\n\tdebug2(\"network_usage protocols\\t= %s\",\n\t       pe_job_req->network_usage.protocols);\n\tif (!opt.network)\n\t\txstrcat(opt.network, pe_job_req->network_usage.protocols);\n\telse if (!strstr(opt.network, pe_job_req->network_usage.protocols)) {\n\t\txstrcat(opt.network, \",\");\n\t\txstrcat(opt.network, pe_job_req->network_usage.protocols);\n\t}\n\tdebug2(\"network_usage adapter_usage\\t= %s\",\n\t       pe_job_req->network_usage.adapter_usage);\n\tdebug2(\"network_usage adapter_type\\t= %s\",\n\t       pe_job_req->network_usage.adapter_type);\n\tdebug2(\"network_usage mode\\t= %s\", pe_job_req->network_usage.mode);\n\tdebug2(\"network_usage instance\\t= %s\",\n\t       pe_job_req->network_usage.instances);\n\tdebug2(\"network_usage dev_type\\t= %s\",\n\t       pe_job_req->network_usage.dev_type);\n\tdebug2(\"check_pointable\\t= %d\", pe_job_req->check_pointable);\n\tdebug2(\"check_dir\\t= %s\", pe_job_req->check_dir);\n\tdebug2(\"task_affinity\\t= %s\", pe_job_req->task_affinity);\n\tdebug2(\"pthreads\\t= %d\", pe_job_req->parallel_threads);\n\tdebug2(\"save_job\\t= %s\", pe_job_req->save_job_file);\n\tdebug2(\"require\\t= %s\", pe_job_req->requirements);\n\tdebug2(\"node_topology\\t= %s\", pe_job_req->node_topology);\n\tdebug2(\"pool\\t= %s\", pe_job_req->pool);\n\n\tif (!opt.nodelist\n\t    && pe_job_req->host_names && *pe_job_req->host_names) {\n\t\t/* This means there was a hostfile used for this job.\n\t\t * So we need to set up the arbitrary distribution of it. */\n\t\tint hostfile_count = 0;\n\t\tchar **names = pe_job_req->host_names;\n\t\topt.distribution &= SLURM_DIST_STATE_FLAGS;\n\t\topt.distribution |= SLURM_DIST_ARBITRARY;\n\t\twhile (names && *names) {\n\t\t\tif (opt.nodelist)\n\t\t\t\txstrfmtcat(opt.nodelist, \",%s\",\n\t\t\t\t\t   strtok(*names, \".\"));\n\t\t\telse\n\t\t\t\topt.nodelist = xstrdup(strtok(*names, \".\"));\n\t\t\tnames++;\n\t\t\thostfile_count++;\n\t\t}\n\t\tif (pe_job_req->total_tasks == -1)\n\t\t\tpe_job_req->total_tasks = hostfile_count;\n\t}\n\n\tif (pe_job_req->num_nodes != -1)\n\t\topt.max_nodes = opt.min_nodes = pe_job_req->num_nodes;\n\n\tif (pe_job_req->tasks_per_node != -1)\n\t\topt.ntasks_per_node = pe_job_req->tasks_per_node;\n\n\tif (pe_job_req->total_tasks != -1) {\n\t\topt.ntasks_set = true;\n\t\topt.ntasks = pe_job_req->total_tasks;\n\t}\n\n\tcreate_srun_job((void **)&job, &got_alloc, slurm_started, 0);\n\t_re_write_cmdfile(slurm_cmd_fname, poe_cmd_fname, job->stepid,\n\t\t\t  pe_job_req->total_tasks);\n\n\t/* make sure we set up a signal handler */\n\tpre_launch_srun_job(job, slurm_started, 0, &opt);\n\n\treturn 0;\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/src/plugins/mpi/pmi2/setup.c": "/*****************************************************************************\\\n **  setup.c - PMI2 server setup\n *****************************************************************************\n *  Copyright (C) 2011-2012 National University of Defense Technology.\n *  Written by Hongjia Cao <hjcao@nudt.edu.cn>.\n *  All rights reserved.\n *  Portions copyright (C) 2015 Mellanox Technologies Inc.\n *  Written by Artem Y. Polyakov <artemp@mellanox.com>.\n *  All rights reserved.\n *  Portions copyright (C) 2017 SchedMD LLC.\n *\n *  This file is part of SLURM, a resource management program.\n *  For details, see <https://slurm.schedmd.com/>.\n *  Please also read the included file: DISCLAIMER.\n *\n *  SLURM is free software; you can redistribute it and/or modify it under\n *  the terms of the GNU General Public License as published by the Free\n *  Software Foundation; either version 2 of the License, or (at your option)\n *  any later version.\n *\n *  In addition, as a special exception, the copyright holders give permission\n *  to link the code of portions of this program with the OpenSSL library under\n *  certain conditions as described in each individual source file, and\n *  distribute linked combinations including the two. You must obey the GNU\n *  General Public License in all respects for all of the code used other than\n *  OpenSSL. If you modify file(s) with this exception, you may extend this\n *  exception to your version of the file(s), but you are not obligated to do\n *  so. If you do not wish to do so, delete this exception statement from your\n *  version.  If you delete this exception statement from all source files in\n *  the program, then also delete it here.\n *\n *  SLURM is distributed in the hope that it will be useful, but WITHOUT ANY\n *  WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n *  FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more\n *  details.\n *\n *  You should have received a copy of the GNU General Public License along\n *  with SLURM; if not, write to the Free Software Foundation, Inc.,\n *  51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA.\n\\*****************************************************************************/\n\n#if defined(__FreeBSD__)\n#include <sys/socket.h>\t/* AF_INET */\n#endif\n\n#include <dlfcn.h>\n#include <fcntl.h>\n#include <poll.h>\n#include <signal.h>\n#include <stdlib.h>\n#include <string.h>\n#include <sys/types.h>\n#include <sys/un.h>\n#include <unistd.h>\n\n#include \"src/common/slurm_xlator.h\"\n#include \"src/common/net.h\"\n#include \"src/common/proc_args.h\"\n#include \"src/common/slurm_mpi.h\"\n#include \"src/common/xstring.h\"\n#include \"src/slurmd/slurmstepd/slurmstepd_job.h\"\n#include \"src/slurmd/common/reverse_tree_math.h\"\n\n#include \"setup.h\"\n#include \"tree.h\"\n#include \"pmi.h\"\n#include \"spawn.h\"\n#include \"kvs.h\"\n#include \"ring.h\"\n\n#define PMI2_SOCK_ADDR_FMT \"%s/sock.pmi2.%u.%u\"\n\n\nextern char **environ;\n\nstatic bool run_in_stepd = 0;\n\nint  tree_sock;\nint *task_socks;\nchar tree_sock_addr[128];\npmi2_job_info_t job_info;\npmi2_tree_info_t tree_info;\n\nextern bool\nin_stepd(void)\n{\n\treturn run_in_stepd;\n}\n\nstatic void\n_remove_tree_sock(void)\n{\n\tunlink(tree_sock_addr);\n}\n\nstatic int\n_setup_stepd_job_info(const stepd_step_rec_t *job, char ***env)\n{\n\tchar *p;\n\tint i;\n\n\tmemset(&job_info, 0, sizeof(job_info));\n\n\tif (job->pack_jobid && (job->pack_jobid != NO_VAL)) {\n\t\tjob_info.jobid  = job->pack_jobid;\n\t\tjob_info.stepid = job->stepid;\n\t\tjob_info.nnodes = job->pack_nnodes;\n\t\tjob_info.nodeid = job->nodeid + job->node_offset;\n\t\tjob_info.ntasks = job->pack_ntasks;\n\t\tjob_info.ltasks = job->node_tasks;\n\t\tjob_info.gtids = xmalloc(job_info.ltasks * sizeof(uint32_t));\n\t\tfor (i = 0; i < job_info.ltasks; i ++) {\n\t\t\tjob_info.gtids[i] = job->task[i]->gtid;\n\t\t}\n\t} else {\n\t\tjob_info.jobid  = job->jobid;\n\t\tjob_info.stepid = job->stepid;\n\t\tjob_info.nnodes = job->nnodes;\n\t\tjob_info.nodeid = job->nodeid;\n\t\tjob_info.ntasks = job->ntasks;\n\t\tjob_info.ltasks = job->node_tasks;\n\t\tjob_info.gtids = xmalloc(job_info.ltasks * sizeof(uint32_t));\n\t\tfor (i = 0; i < job_info.ltasks; i ++) {\n\t\t\tjob_info.gtids[i] = job->task[i]->gtid;\n\t\t}\n\t}\n\n\tp = getenvp(*env, PMI2_PMI_DEBUGGED_ENV);\n\tif (p) {\n\t\tjob_info.pmi_debugged = atoi(p);\n\t} else {\n\t\tjob_info.pmi_debugged = 0;\n\t}\n\tp = getenvp(*env, PMI2_SPAWN_SEQ_ENV);\n\tif (p) { \t\t/* spawned */\n\t\tjob_info.spawn_seq = atoi(p);\n\t\tunsetenvp(*env, PMI2_SPAWN_SEQ_ENV);\n\t\tp = getenvp(*env, PMI2_SPAWNER_JOBID_ENV);\n\t\tjob_info.spawner_jobid = xstrdup(p);\n\t\tunsetenvp(*env, PMI2_SPAWNER_JOBID_ENV);\n\t} else {\n\t\tjob_info.spawn_seq = 0;\n\t\tjob_info.spawner_jobid = NULL;\n\t}\n\tp = getenvp(*env, PMI2_PMI_JOBID_ENV);\n\tif (p) {\n\t\tjob_info.pmi_jobid = xstrdup(p);\n\t\tunsetenvp(*env, PMI2_PMI_JOBID_ENV);\n\t} else {\n\t\txstrfmtcat(job_info.pmi_jobid, \"%u.%u\", job->jobid,\n\t\t\t   job->stepid);\n\t}\n\tp = getenvp(*env, PMI2_STEP_NODES_ENV);\n\tif (!p) {\n\t\terror(\"mpi/pmi2: unable to find nodes in job environment\");\n\t\treturn SLURM_ERROR;\n\t} else {\n\t\tjob_info.step_nodelist = xstrdup(p);\n\t\tunsetenvp(*env, PMI2_STEP_NODES_ENV);\n\t}\n\t/*\n\t * how to get the mapping info from stepd directly?\n\t * there is the task distribution info in the launch_tasks_request_msg_t,\n\t * but it is not stored in the stepd_step_rec_t.\n\t */\n\tp = getenvp(*env, PMI2_PROC_MAPPING_ENV);\n\tif (!p) {\n\t\terror(\"PMI2_PROC_MAPPING_ENV not found\");\n\t\treturn SLURM_ERROR;\n\t} else {\n\t\tjob_info.proc_mapping = xstrdup(p);\n\t\tunsetenvp(*env, PMI2_PROC_MAPPING_ENV);\n\t}\n\n\tjob_info.job_env = env_array_copy((const char **)*env);\n\n\tjob_info.MPIR_proctable = NULL;\n\tjob_info.srun_opt = NULL;\n\n\t/* get the SLURM_STEP_RESV_PORTS\n\t */\n\tp = getenvp(*env, SLURM_STEP_RESV_PORTS);\n\tif (!p) {\n\t\tdebug(\"%s: %s not found in env\", __func__, SLURM_STEP_RESV_PORTS);\n\t} else {\n\t\tjob_info.resv_ports = xstrdup(p);\n\t\tinfo(\"%s: SLURM_STEP_RESV_PORTS found %s\", __func__, p);\n\t}\n\treturn SLURM_SUCCESS;\n}\n\nstatic int\n_setup_stepd_tree_info(const stepd_step_rec_t *job, char ***env)\n{\n\thostlist_t hl;\n\tchar *srun_host;\n\tuint16_t port;\n\tchar *p;\n\tint tree_width;\n\n\t/* job info available */\n\n\tmemset(&tree_info, 0, sizeof(tree_info));\n\n\thl = hostlist_create(job_info.step_nodelist);\n\tp = hostlist_nth(hl, job_info.nodeid); /* strdup-ed */\n\ttree_info.this_node = xstrdup(p);\n\tfree(p);\n\n\t/* this only controls the upward communication tree width */\n\tp = getenvp(*env, PMI2_TREE_WIDTH_ENV);\n\tif (p) {\n\t\ttree_width = atoi(p);\n\t\tif (tree_width < 2) {\n\t\t\tinfo(\"invalid PMI2 tree width value (%d) detected. \"\n\t\t\t     \"fallback to default value.\", tree_width);\n\t\t\ttree_width = slurm_get_tree_width();\n\t\t}\n\t} else {\n\t\ttree_width = slurm_get_tree_width();\n\t}\n\n\t/* TODO: cannot launch 0 tasks on node */\n\n\t/*\n\t * In tree position calculation, root of the tree is srun with id 0.\n\t * Stepd's id will be its nodeid plus 1.\n\t */\n\treverse_tree_info(job_info.nodeid + 1, job_info.nnodes + 1,\n\t\t\t  tree_width, &tree_info.parent_id,\n\t\t\t  &tree_info.num_children, &tree_info.depth,\n\t\t\t  &tree_info.max_depth);\n\ttree_info.parent_id --;\t       /* restore real nodeid */\n\tif (tree_info.parent_id < 0) {\t/* parent is srun */\n\t\ttree_info.parent_node = NULL;\n\t} else {\n\t\tp = hostlist_nth(hl, tree_info.parent_id);\n\t\ttree_info.parent_node = xstrdup(p);\n\t\tfree(p);\n\t}\n\thostlist_destroy(hl);\n\n\ttree_info.pmi_port = 0;\t/* not used */\n\n\tsrun_host = getenvp(*env, \"SLURM_SRUN_COMM_HOST\");\n\tif (!srun_host) {\n\t\terror(\"mpi/pmi2: unable to find srun comm ifhn in env\");\n\t\treturn SLURM_ERROR;\n\t}\n\tp = getenvp(*env, PMI2_SRUN_PORT_ENV);\n\tif (!p) {\n\t\terror(\"mpi/pmi2: unable to find srun pmi2 port in env\");\n\t\treturn SLURM_ERROR;\n\t}\n\tport = atoi(p);\n\n\ttree_info.srun_addr = xmalloc(sizeof(slurm_addr_t));\n\tslurm_set_addr(tree_info.srun_addr, port, srun_host);\n\n\tunsetenvp(*env, PMI2_SRUN_PORT_ENV);\n\n\t/* init kvs seq to 0. TODO: reduce array size */\n\ttree_info.children_kvs_seq = xmalloc(sizeof(uint32_t) *\n\t\t\t\t\t     job_info.nnodes);\n\n\treturn SLURM_SUCCESS;\n}\n\n/*\n * setup sockets for slurmstepd\n */\nstatic int\n_setup_stepd_sockets(const stepd_step_rec_t *job, char ***env)\n{\n\tstruct sockaddr_un sa;\n\tint i;\n\tchar *spool;\n\n\tdebug(\"mpi/pmi2: setup sockets\");\n\n\ttree_sock = socket(AF_UNIX, SOCK_STREAM, 0);\n\tif (tree_sock < 0) {\n\t\terror(\"mpi/pmi2: failed to create tree socket: %m\");\n\t\treturn SLURM_ERROR;\n\t}\n\tsa.sun_family = PF_UNIX;\n\n\t/* tree_sock_addr has to remain unformatted since the formatting\n\t * happens on the slurmd side */\n\tspool = slurm_get_slurmd_spooldir(NULL);\n\tsnprintf(tree_sock_addr, sizeof(tree_sock_addr), PMI2_SOCK_ADDR_FMT,\n\t\t spool, job->jobid, job->stepid);\n\t/* Make sure we adjust for the spool dir coming in on the address to\n\t * point to the right spot.\n\t */\n\txstrsubstitute(spool, \"%n\", job->node_name);\n\txstrsubstitute(spool, \"%h\", job->node_name);\n\tsnprintf(sa.sun_path, sizeof(sa.sun_path), PMI2_SOCK_ADDR_FMT,\n\t\t spool, job->jobid, job->stepid);\n\tunlink(sa.sun_path);    /* remove possible old socket */\n\txfree(spool);\n\n\tif (bind(tree_sock, (struct sockaddr *)&sa, SUN_LEN(&sa)) < 0) {\n\t\terror(\"mpi/pmi2: failed to bind tree socket: %m\");\n\t\tunlink(sa.sun_path);\n\t\treturn SLURM_ERROR;\n\t}\n\tif (listen(tree_sock, 64) < 0) {\n\t\terror(\"mpi/pmi2: failed to listen tree socket: %m\");\n\t\tunlink(sa.sun_path);\n\t\treturn SLURM_ERROR;\n\t}\n\n\ttask_socks = xmalloc(2 * job->node_tasks * sizeof(int));\n\tfor (i = 0; i < job->node_tasks; i ++) {\n\t\tsocketpair(AF_UNIX, SOCK_STREAM, 0, &task_socks[i * 2]);\n\t\t/* this must be delayed after the tasks have been forked */\n/* \t\tclose(TASK_PMI_SOCK(i)); */\n\t}\n\treturn SLURM_SUCCESS;\n}\n\nstatic int\n_setup_stepd_kvs(const stepd_step_rec_t *job, char ***env)\n{\n\tint rc = SLURM_SUCCESS, i = 0, pp_cnt = 0;\n\tchar *p, env_key[32], *ppkey, *ppval;\n\n\tkvs_seq = 1;\n\trc = temp_kvs_init();\n\tif (rc != SLURM_SUCCESS)\n\t\treturn rc;\n\n\trc = kvs_init();\n\tif (rc != SLURM_SUCCESS)\n\t\treturn rc;\n\n\t/* preput */\n\tp = getenvp(*env, PMI2_PREPUT_CNT_ENV);\n\tif (p) {\n\t\tpp_cnt = atoi(p);\n\t}\n\n\tfor (i = 0; i < pp_cnt; i ++) {\n\t\tsnprintf(env_key, 32, PMI2_PPKEY_ENV\"%d\", i);\n\t\tp = getenvp(*env, env_key);\n\t\tppkey = p; /* getenvp will not modify p */\n\t\tsnprintf(env_key, 32, PMI2_PPVAL_ENV\"%d\", i);\n\t\tp = getenvp(*env, env_key);\n\t\tppval = p;\n\t\tkvs_put(ppkey, ppval);\n\t}\n\n\t/*\n\t * For PMI11.\n\t * A better logic would be to put PMI_process_mapping in KVS only if\n\t * the task distribution method is not \"arbitrary\", because in\n\t * \"arbitrary\" distribution the process mapping varible is not correct.\n\t * MPICH2 may deduce the clique info from the hostnames. But that\n\t * is rather costly.\n\t */\n\tkvs_put(\"PMI_process_mapping\", job_info.proc_mapping);\n\n\treturn SLURM_SUCCESS;\n}\n\nextern int\npmi2_setup_stepd(const stepd_step_rec_t *job, char ***env)\n{\n\tint rc;\n\n\trun_in_stepd = true;\n\n\t/* job info */\n\trc = _setup_stepd_job_info(job, env);\n\tif (rc != SLURM_SUCCESS)\n\t\treturn rc;\n\n\t/* tree info */\n\trc = _setup_stepd_tree_info(job, env);\n\tif (rc != SLURM_SUCCESS)\n\t\treturn rc;\n\n\t/* sockets */\n\trc = _setup_stepd_sockets(job, env);\n\tif (rc != SLURM_SUCCESS)\n\t\treturn rc;\n\n\t/* kvs */\n\trc = _setup_stepd_kvs(job, env);\n\tif (rc != SLURM_SUCCESS)\n\t\treturn rc;\n\n\t/* TODO: finalize pmix_ring state somewhere */\n\t/* initialize pmix_ring state */\n\trc = pmix_ring_init(&job_info, env);\n\tif (rc != SLURM_SUCCESS)\n\t\treturn rc;\n\n\treturn SLURM_SUCCESS;\n}\n\nextern void\npmi2_cleanup_stepd()\n{\n\tclose(tree_sock);\n\t_remove_tree_sock();\n}\n/**************************************************************/\n\n/* returned string should be xfree-ed by caller */\nstatic char *\n_get_proc_mapping(const mpi_plugin_client_info_t *job)\n{\n\tuint32_t node_cnt, task_cnt, task_mapped, node_task_cnt, **tids;\n\tuint32_t task_dist, block;\n\tuint16_t *tasks, *rounds;\n\tint i, start_id, end_id;\n\tchar *mapping = NULL;\n\n\tnode_cnt = job->step_layout->node_cnt;\n\ttask_cnt = job->step_layout->task_cnt;\n\ttask_dist = job->step_layout->task_dist & SLURM_DIST_STATE_BASE;\n\ttasks = job->step_layout->tasks;\n\ttids = job->step_layout->tids;\n\n\t/* for now, PMI2 only supports vector processor mapping */\n\n\tif ((task_dist & SLURM_DIST_NODEMASK) == SLURM_DIST_NODECYCLIC) {\n\t\tmapping = xstrdup(\"(vector\");\n\n\t\trounds = xmalloc (node_cnt * sizeof(uint16_t));\n\t\ttask_mapped = 0;\n\t\twhile (task_mapped < task_cnt) {\n\t\t\tstart_id = 0;\n\t\t\t/* find start_id */\n\t\t\twhile (start_id < node_cnt) {\n\t\t\t\twhile (start_id < node_cnt &&\n\t\t\t\t       ( rounds[start_id] >= tasks[start_id] ||\n\t\t\t\t\t (task_mapped !=\n\t\t\t\t\t  tids[start_id][rounds[start_id]]) )) {\n\t\t\t\t\tstart_id ++;\n\t\t\t\t}\n\t\t\t\tif (start_id >= node_cnt)\n\t\t\t\t\tbreak;\n\t\t\t\t/* block is always 1 */\n\t\t\t\t/* find end_id */\n\t\t\t\tend_id = start_id;\n\t\t\t\twhile (end_id < node_cnt &&\n\t\t\t\t       ( rounds[end_id] < tasks[end_id] &&\n\t\t\t\t\t (task_mapped ==\n\t\t\t\t\t  tids[end_id][rounds[end_id]]) )) {\n\t\t\t\t\trounds[end_id] ++;\n\t\t\t\t\ttask_mapped ++;\n\t\t\t\t\tend_id ++;\n\t\t\t\t}\n\t\t\t\txstrfmtcat(mapping, \",(%u,%u,1)\", start_id,\n\t\t\t\t\t   end_id - start_id);\n\t\t\t\tstart_id = end_id;\n\t\t\t}\n\t\t}\n\t\txfree(rounds);\n\t\txstrcat(mapping, \")\");\n\t} else if (task_dist == SLURM_DIST_ARBITRARY) {\n\t\t/*\n\t\t * MPICH2 will think that each task runs on a seperate node.\n\t\t * The program will run, but no SHM will be used for\n\t\t * communication.\n\t\t */\n\t\tmapping = xstrdup(\"(vector\");\n\t\txstrfmtcat(mapping, \",(0,%u,1)\", job->step_layout->task_cnt);\n\t\txstrcat(mapping, \")\");\n\n\t} else if (task_dist == SLURM_DIST_PLANE) {\n\t\tmapping = xstrdup(\"(vector\");\n\n\t\trounds = xmalloc (node_cnt * sizeof(uint16_t));\n\t\ttask_mapped = 0;\n\t\twhile (task_mapped < task_cnt) {\n\t\t\tstart_id = 0;\n\t\t\t/* find start_id */\n\t\t\twhile (start_id < node_cnt) {\n\t\t\t\twhile (start_id < node_cnt &&\n\t\t\t\t       ( rounds[start_id] >= tasks[start_id] ||\n\t\t\t\t\t (task_mapped !=\n\t\t\t\t\t  tids[start_id][rounds[start_id]]) )) {\n\t\t\t\t\tstart_id ++;\n\t\t\t\t}\n\t\t\t\tif (start_id >= node_cnt)\n\t\t\t\t\tbreak;\n\t\t\t\t/* find start block. block may be less\n\t\t\t\t * than plane size */\n\t\t\t\tblock = 0;\n\t\t\t\twhile (rounds[start_id] < tasks[start_id] &&\n\t\t\t\t       (task_mapped ==\n\t\t\t\t\ttids[start_id][rounds[start_id]])) {\n\t\t\t\t\tblock ++;\n\t\t\t\t\trounds[start_id] ++;\n\t\t\t\t\ttask_mapped ++;\n\t\t\t\t}\n\t\t\t\t/* find end_id */\n\t\t\t\tend_id = start_id + 1;\n\t\t\t\twhile (end_id < node_cnt &&\n\t\t\t\t       (rounds[end_id] + block - 1 <\n\t\t\t\t\ttasks[end_id])) {\n\t\t\t\t\tfor (i = 0;\n\t\t\t\t\t     i < tasks[end_id] - rounds[end_id];\n\t\t\t\t\t     i ++) {\n\t\t\t\t\t\tif (task_mapped + i !=\n\t\t\t\t\t\t    tids[end_id][rounds[end_id]\n\t\t\t\t\t\t\t\t + i]) {\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif (i != block)\n\t\t\t\t\t\tbreak;\n\t\t\t\t\trounds[end_id] += block;\n\t\t\t\t\ttask_mapped += block;\n\t\t\t\t\tend_id ++;\n\t\t\t\t}\n\t\t\t\txstrfmtcat(mapping, \",(%u,%u,%u)\", start_id,\n\t\t\t\t\t   end_id - start_id, block);\n\t\t\t\tstart_id = end_id;\n\t\t\t}\n\t\t}\n\t\txfree(rounds);\n\t\txstrcat(mapping, \")\");\n\n\t} else {\t\t/* BLOCK mode */\n\t\tmapping = xstrdup(\"(vector\");\n\t\tstart_id = 0;\n\t\tnode_task_cnt = tasks[start_id];\n\t\tfor (i = start_id + 1; i < node_cnt; i ++) {\n\t\t\tif (node_task_cnt == tasks[i])\n\t\t\t\tcontinue;\n\t\t\txstrfmtcat(mapping, \",(%u,%u,%u)\", start_id,\n\t\t\t\t   i - start_id, node_task_cnt);\n\t\t\tstart_id = i;\n\t\t\tnode_task_cnt = tasks[i];\n\t\t}\n\t\txstrfmtcat(mapping, \",(%u,%u,%u))\", start_id, i - start_id,\n\t\t\t   node_task_cnt);\n\t}\n\n\tdebug(\"mpi/pmi2: processor mapping: %s\", mapping);\n\treturn mapping;\n}\n\nstatic int\n_setup_srun_job_info(const mpi_plugin_client_info_t *job)\n{\n\tchar *p;\n\tvoid *handle = NULL, *sym = NULL;\n\n\tmemset(&job_info, 0, sizeof(job_info));\n\n\tjob_info.jobid  = job->jobid;\n\tjob_info.stepid = job->stepid;\n\tjob_info.nnodes = job->step_layout->node_cnt;\n\tjob_info.nodeid = -1;\t/* id in tree. not used. */\n\tjob_info.ntasks = job->step_layout->task_cnt;\n\tjob_info.ltasks = 0;\t/* not used */\n\tjob_info.gtids = NULL;\t/* not used */\n\n\tp = getenv(PMI2_PMI_DEBUGGED_ENV);\n\tif (p) {\n\t\tjob_info.pmi_debugged = atoi(p);\n\t} else {\n\t\tjob_info.pmi_debugged = 0;\n\t}\n\tp = getenv(PMI2_SPAWN_SEQ_ENV);\n\tif (p) { \t\t/* spawned */\n\t\tjob_info.spawn_seq = atoi(p);\n\t\tp = getenv(PMI2_SPAWNER_JOBID_ENV);\n\t\tjob_info.spawner_jobid = xstrdup(p);\n\t\t/* env unset in stepd */\n\t} else {\n\t\tjob_info.spawn_seq = 0;\n\t\tjob_info.spawner_jobid = NULL;\n\t}\n\n\tjob_info.step_nodelist = xstrdup(job->step_layout->node_list);\n\tjob_info.proc_mapping = _get_proc_mapping(job);\n\tif (job_info.proc_mapping == NULL) {\n\t\treturn SLURM_ERROR;\n\t}\n\tp = getenv(PMI2_PMI_JOBID_ENV);\n\tif (p) {\t\t/* spawned */\n\t\tjob_info.pmi_jobid = xstrdup(p);\n\t} else {\n\t\txstrfmtcat(job_info.pmi_jobid, \"%u.%u\", job->jobid,\n\t\t\t   job->stepid);\n\t}\n\tjob_info.job_env = env_array_copy((const char **)environ);\n\n\t/* hjcao: this is really dirty.\n\t   But writing a new launcher is not desirable. */\n\thandle = dlopen(NULL, RTLD_LAZY);\n\tif (handle == NULL) {\n\t\terror(\"mpi/pmi2: failed to dlopen()\");\n\t\treturn SLURM_ERROR;\n\t}\n\tsym = dlsym(handle, \"MPIR_proctable\");\n\tif (sym == NULL) {\n\t\t/* if called directly in API, there may be no symbol available */\n\t\tverbose (\"mpi/pmi2: failed to find symbol 'MPIR_proctable'\");\n\t\tjob_info.MPIR_proctable = NULL;\n\t} else {\n\t\tjob_info.MPIR_proctable = *(MPIR_PROCDESC **)sym;\n\t}\n\tsym = dlsym(handle, \"opt\");\n\tif (sym == NULL) {\n\t\tverbose(\"mpi/pmi2: failed to find symbol 'opt'\");\n\t\tjob_info.srun_opt = NULL;\n\t} else {\n\t\tjob_info.srun_opt = (slurm_opt_t *)sym;\n\t}\n\tdlclose(handle);\n\n\treturn SLURM_SUCCESS;\n}\n\nstatic int\n_setup_srun_tree_info(const mpi_plugin_client_info_t *job)\n{\n\tchar *p;\n\tuint16_t p_port;\n\tchar *spool;\n\n\tmemset(&tree_info, 0, sizeof(tree_info));\n\n\ttree_info.this_node = \"launcher\"; /* not used */\n\ttree_info.parent_id = -2;   /* not used */\n\ttree_info.parent_node = NULL; /* not used */\n\ttree_info.num_children = job_info.nnodes;\n\ttree_info.depth = 0;\t /* not used */\n\ttree_info.max_depth = 0; /* not used */\n\t/* pmi_port set in _setup_srun_sockets */\n\tp = getenv(PMI2_SPAWNER_PORT_ENV);\n\tif (p) {\t\t/* spawned */\n\t\tp_port = atoi(p);\n\t\ttree_info.srun_addr = xmalloc(sizeof(slurm_addr_t));\n\t\t/* assume there is always a lo interface */\n\t\tslurm_set_addr(tree_info.srun_addr, p_port, \"127.0.0.1\");\n\t} else\n\t\ttree_info.srun_addr = NULL;\n\n\t/* FIXME: We need to handle %n and %h in the spool dir, but don't have\n\t * the node name here */\n\tspool = slurm_get_slurmd_spooldir(NULL);\n\tsnprintf(tree_sock_addr, 128, PMI2_SOCK_ADDR_FMT,\n\t\t spool, job->jobid, job->stepid);\n\txfree(spool);\n\n\t/* init kvs seq to 0. TODO: reduce array size */\n\ttree_info.children_kvs_seq = xmalloc(sizeof(uint32_t) *\n\t\t\t\t\t     job_info.nnodes);\n\n\treturn SLURM_SUCCESS;\n}\n\nstatic int\n_setup_srun_socket(const mpi_plugin_client_info_t *job)\n{\n\tif (net_stream_listen(&tree_sock,\n\t\t\t      &tree_info.pmi_port) < 0) {\n\t\terror(\"mpi/pmi2: Failed to create tree socket\");\n\t\treturn SLURM_ERROR;\n\t}\n\tdebug(\"mpi/pmi2: srun pmi port: %hu\", tree_info.pmi_port);\n\n\treturn SLURM_SUCCESS;\n}\n\nstatic int\n_setup_srun_kvs(const mpi_plugin_client_info_t *job)\n{\n\tint rc;\n\n\tkvs_seq = 1;\n\trc = temp_kvs_init();\n\treturn rc;\n}\n\nstatic int\n_setup_srun_environ(const mpi_plugin_client_info_t *job, char ***env)\n{\n\t/* ifhn will be set in SLURM_SRUN_COMM_HOST by slurmd */\n\tenv_array_overwrite_fmt(env, PMI2_SRUN_PORT_ENV, \"%hu\",\n\t\t\t\ttree_info.pmi_port);\n\tenv_array_overwrite_fmt(env, PMI2_STEP_NODES_ENV, \"%s\",\n\t\t\t\tjob_info.step_nodelist);\n\tenv_array_overwrite_fmt(env, PMI2_PROC_MAPPING_ENV, \"%s\",\n\t\t\t\tjob_info.proc_mapping);\n\treturn SLURM_SUCCESS;\n}\n\ninline static int\n_tasks_launched (void)\n{\n\tint i, all_launched = 1;\n\tif (job_info.MPIR_proctable == NULL)\n\t\treturn 1;\n\n\tfor (i = 0; i < job_info.ntasks; i ++) {\n\t\tif (job_info.MPIR_proctable[i].pid == 0) {\n\t\t\tall_launched = 0;\n\t\t\tbreak;\n\t\t}\n\t}\n\treturn all_launched;\n}\n\nstatic void *\n_task_launch_detection(void *unused)\n{\n\tspawn_resp_t *resp;\n\ttime_t start;\n\tint rc = 0;\n\n\t/*\n\t * mpir_init() is called in plugins/launch/slurm/launch_slurm.c before\n\t * mpi_hook_client_prelaunch() is called in api/step_launch.c\n\t */\n\tstart = time(NULL);\n\twhile (_tasks_launched() == 0) {\n\t\tusleep(1000*50);\n\t\tif (time(NULL) - start > 600) {\n\t\t\trc = 1;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t/* send a resp to spawner srun */\n\tresp = spawn_resp_new();\n\tresp->seq = job_info.spawn_seq;\n\tresp->jobid = xstrdup(job_info.pmi_jobid);\n\tresp->error_cnt = 0;\t/* TODO */\n\tresp->rc = rc;\n\tresp->pmi_port = tree_info.pmi_port;\n\n\tspawn_resp_send_to_srun(resp);\n\tspawn_resp_free(resp);\n\treturn NULL;\n}\n\nextern int\npmi2_setup_srun(const mpi_plugin_client_info_t *job, char ***env)\n{\n\tstatic pthread_mutex_t setup_mutex = PTHREAD_MUTEX_INITIALIZER;\n\tstatic pthread_cond_t setup_cond  = PTHREAD_COND_INITIALIZER;\n\tstatic int global_rc = NO_VAL16;\n\tint rc = SLURM_SUCCESS;\n\n\trun_in_stepd = false;\n\tif ((job->pack_jobid == NO_VAL) || (job->pack_jobid == job->jobid)) {\n\t\trc = _setup_srun_job_info(job);\n\t\tif (rc == SLURM_SUCCESS)\n\t\t\trc = _setup_srun_tree_info(job);\n\t\tif (rc == SLURM_SUCCESS)\n\t\t\trc = _setup_srun_socket(job);\n\t\tif (rc == SLURM_SUCCESS)\n\t\t\trc = _setup_srun_kvs(job);\n\t\tif (rc == SLURM_SUCCESS)\n\t\t\trc = _setup_srun_environ(job, env);\n\t\tif ((rc == SLURM_SUCCESS) && job_info.spawn_seq) {\n\t\t\tslurm_thread_create_detached(NULL,\n\t\t\t\t\t\t     _task_launch_detection,\n\t\t\t\t\t\t     NULL);\n\t\t}\n\t\tslurm_mutex_lock(&setup_mutex);\n\t\tglobal_rc = rc;\n\t\tslurm_cond_broadcast(&setup_cond);\n\t\tslurm_mutex_unlock(&setup_mutex);\n\t} else {\n\t\tslurm_mutex_lock(&setup_mutex);\n\t\twhile (global_rc == NO_VAL16)\n\t\t\tslurm_cond_wait(&setup_cond, &setup_mutex);\n\t\trc = global_rc;\n\t\tslurm_mutex_unlock(&setup_mutex);\n\t\tif (rc == SLURM_SUCCESS)\n\t\t\trc = _setup_srun_environ(job, env);\n \t}\n\n\treturn rc;\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/src/plugins/mpi/pmix/mpi_pmix.c": "/*****************************************************************************\\\n **  mpi_pmix.c - Main plugin callbacks for PMIx support in SLURM\n *****************************************************************************\n *  Copyright (C) 2014-2015 Artem Polyakov. All rights reserved.\n *  Copyright (C) 2015-2017 Mellanox Technologies. All rights reserved.\n *  Written by Artem Y. Polyakov <artpol84@gmail.com, artemp@mellanox.com>.\n *\n *  This file is part of SLURM, a resource management program.\n *  For details, see <https://slurm.schedmd.com/>.\n *  Please also read the included file: DISCLAIMER.\n *\n *  SLURM is free software; you can redistribute it and/or modify it under\n *  the terms of the GNU General Public License as published by the Free\n *  Software Foundation; either version 2 of the License, or (at your option)\n *  any later version.\n *\n *  In addition, as a special exception, the copyright holders give permission\n *  to link the code of portions of this program with the OpenSSL library under\n *  certain conditions as described in each individual source file, and\n *  distribute linked combinations including the two. You must obey the GNU\n *  General Public License in all respects for all of the code used other than\n *  OpenSSL. If you modify file(s) with this exception, you may extend this\n *  exception to your version of the file(s), but you are not obligated to do\n *  so. If you do not wish to do so, delete this exception statement from your\n *  version.  If you delete this exception statement from all source files in\n *  the program, then also delete it here.\n *\n *  SLURM is distributed in the hope that it will be useful, but WITHOUT ANY\n *  WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n *  FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more\n *  details.\n *\n *  You should have received a copy of the GNU General Public License along\n *  with SLURM; if not, write to the Free Software Foundation, Inc.,\n *  51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA.\n \\*****************************************************************************/\n\n#include <fcntl.h>\n#include <signal.h>\n#include <sys/types.h>\n#include <dlfcn.h>\n\n#include \"pmixp_common.h\"\n#include \"pmixp_server.h\"\n#include \"pmixp_debug.h\"\n#include \"pmixp_agent.h\"\n#include \"pmixp_info.h\"\n#include \"pmixp_dconn_ucx.h\"\n#include \"pmixp_client.h\"\n\n/*\n * These variables are required by the generic plugin interface.  If they\n * are not found in the plugin, the plugin loader will ignore it.\n *\n * plugin_name - a string giving a human-readable description of the\n * plugin.  There is no maximum length, but the symbol must refer to\n * a valid string.\n *\n * plugin_type - a string suggesting the type of the plugin or its\n * applicability to a particular form of data or method of data handling.\n * If the low-level plugin API is used, the contents of this string are\n * unimportant and may be anything.  SLURM uses the higher-level plugin\n * interface which requires this string to be of the form\n *\n *      <application>/<method>\n *\n * where <application> is a description of the intended application of\n * the plugin (e.g., \"switch\" for SLURM switch) and <method> is a description\n * of how this plugin satisfies that application.  SLURM will only load\n * a switch plugin if the plugin_type string has a prefix of \"switch/\".\n *\n * plugin_version - an unsigned 32-bit integer giving the version number\n * of the plugin.  If major and minor revisions are desired, the major\n * version number may be multiplied by a suitable magnitude constant such\n * as 100 or 1000.  Various SLURM versions will likely require a certain\n * minimum version for their plugins as this API matures.\n */\nconst char plugin_name[] = \"PMIx plugin\";\n\n#if (HAVE_PMIX_VER == 1)\nconst char plugin_type[] = \"mpi/pmix_v1\";\n#elif (HAVE_PMIX_VER == 2)\nconst char plugin_type[] = \"mpi/pmix_v2\";\n#endif\n\nconst uint32_t plugin_version = SLURM_VERSION_NUMBER;\n\nvoid *libpmix_plug = NULL;\n\nstatic void _libpmix_close(void *lib_plug)\n{\n\txassert(lib_plug);\n\tdlclose(lib_plug);\n}\n\nstatic void *_libpmix_open(void)\n{\n\tvoid *lib_plug = NULL;\n\tchar *full_path = NULL;\n\n#ifdef PMIXP_V1_LIBPATH\n\txstrfmtcat(full_path, \"%s/\", PMIXP_V1_LIBPATH);\n#elif defined PMIXP_V2_LIBPATH\n\txstrfmtcat(full_path, \"%s/\", PMIXP_V2_LIBPATH);\n#endif\n\txstrfmtcat(full_path, \"libpmix.so\");\n\tlib_plug = dlopen(full_path, RTLD_LAZY | RTLD_GLOBAL);\n\txfree(full_path);\n\n\tif (lib_plug && (HAVE_PMIX_VER != pmixp_lib_get_version())) {\n\t\tPMIXP_ERROR(\"pmi/pmix: incorrect PMIx library version loaded %d was loaded, required %d version\",\n\t\t\t    pmixp_lib_get_version(), (int)HAVE_PMIX_VER);\n\t\t_libpmix_close(lib_plug);\n\t\tlib_plug = NULL;\n\t}\n\n\treturn lib_plug;\n}\n\n/*\n * init() is called when the plugin is loaded, before any other functions\n * are called.  Put global initialization here.\n */\nextern int init(void)\n{\n\tlibpmix_plug = _libpmix_open();\n\tif (!libpmix_plug) {\n\t\tPMIXP_ERROR(\"pmi/pmix: can not load PMIx library\");\n\t\treturn SLURM_FAILURE;\n\t}\n\treturn SLURM_SUCCESS;\n}\n\nextern int fini(void)\n{\n\tPMIXP_DEBUG(\"%s: call fini()\", pmixp_info_hostname());\n\tpmixp_agent_stop();\n\tpmixp_stepd_finalize();\n\t_libpmix_close(libpmix_plug);\n\treturn SLURM_SUCCESS;\n}\n\nextern int p_mpi_hook_slurmstepd_prefork(\n\tconst stepd_step_rec_t *job, char ***env)\n{\n\tint ret;\n\tpmixp_debug_hang(0);\n\tPMIXP_DEBUG(\"start\");\n\n\tif (job->batch)\n\t\treturn SLURM_SUCCESS;\n\n\tif (SLURM_SUCCESS != (ret = pmixp_stepd_init(job, env))) {\n\t\tPMIXP_ERROR(\"pmixp_stepd_init() failed\");\n\t\tgoto err_ext;\n\t}\n\tif (SLURM_SUCCESS != (ret = pmixp_agent_start())) {\n\t\tPMIXP_ERROR(\"pmixp_agent_start() failed\");\n\t\tgoto err_ext;\n\t}\n\treturn SLURM_SUCCESS;\n\nerr_ext:\n\t/* Abort the whole job if error! */\n\tslurm_kill_job_step(job->jobid, job->stepid, SIGKILL);\n\treturn ret;\n}\n\nextern int p_mpi_hook_slurmstepd_task(\n\tconst mpi_plugin_task_info_t *job, char ***env)\n{\n\tchar **tmp_env = NULL;\n\tpmixp_debug_hang(0);\n\n\tPMIXP_DEBUG(\"Patch environment for task %d\", job->gtaskid);\n\n\tpmixp_lib_setup_fork(job->gtaskid, pmixp_info_namespace(), &tmp_env);\n\tif (NULL != tmp_env) {\n\t\tint i;\n\t\tfor (i = 0; NULL != tmp_env[i]; i++) {\n\t\t\tchar *value = strchr(tmp_env[i], '=');\n\t\t\tif (NULL != value) {\n\t\t\t\t*value = '\\0';\n\t\t\t\tvalue++;\n\t\t\t\tenv_array_overwrite(env,\n\t\t\t\t\t\t    (const char *)tmp_env[i],\n\t\t\t\t\t\t    value);\n\t\t\t}\n\t\t\tfree(tmp_env[i]);\n\t\t}\n\t\tfree(tmp_env);\n\t\ttmp_env = NULL;\n\t}\n\treturn SLURM_SUCCESS;\n}\n\nextern mpi_plugin_client_state_t *p_mpi_hook_client_prelaunch(\n\tconst mpi_plugin_client_info_t *job, char ***env)\n{\n\tstatic pthread_mutex_t setup_mutex = PTHREAD_MUTEX_INITIALIZER;\n\tstatic pthread_cond_t setup_cond  = PTHREAD_COND_INITIALIZER;\n\tstatic char *mapping = NULL;\n\tstatic bool setup_done = false;\n\tuint32_t nnodes, ntasks, **tids;\n\tuint16_t *task_cnt;\n\n\tPMIXP_DEBUG(\"setup process mapping in srun\");\n\tif ((job->pack_jobid == NO_VAL) || (job->pack_jobid == job->jobid)) {\n\t\tnnodes = job->step_layout->node_cnt;\n\t\tntasks = job->step_layout->task_cnt;\n\t\ttask_cnt = job->step_layout->tasks;\n\t\ttids = job->step_layout->tids;\n\t\tmapping = pack_process_mapping(nnodes, ntasks, task_cnt, tids);\n\t\tslurm_mutex_lock(&setup_mutex);\n\t\tsetup_done = true;\n\t\tslurm_cond_broadcast(&setup_cond);\n\t\tslurm_mutex_unlock(&setup_mutex);\n\t} else {\n\t\tslurm_mutex_lock(&setup_mutex);\n\t\twhile (!setup_done)\n\t\t\tslurm_cond_wait(&setup_cond, &setup_mutex);\n\t\tslurm_mutex_unlock(&setup_mutex);\n\t}\n\n\tif (NULL == mapping) {\n\t\tPMIXP_ERROR(\"Cannot create process mapping\");\n\t\treturn NULL;\n\t}\n\tsetenvf(env, PMIXP_SLURM_MAPPING_ENV, \"%s\", mapping);\n\n\t/* only return NULL on error */\n\treturn (void *)0xdeadbeef;\n}\n\nextern int p_mpi_hook_client_fini(void)\n{\n\treturn SLURM_SUCCESS;\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/src/plugins/mpi/pmix/pmixp_dconn_ucx.c": "/*****************************************************************************\\\n **  pmix_dconn_ucx.c - PMIx direct UCX connection\n *****************************************************************************\n *  Copyright (C) 2017      Mellanox Technologies. All rights reserved.\n *  Written by Artem Polyakov <artpol84@gmail.com, artemp@mellanox.com>.\n *\n *  This file is part of SLURM, a resource management program.\n *  For details, see <https://slurm.schedmd.com/>.\n *  Please also read the included file: DISCLAIMER.\n *\n *  SLURM is free software; you can redistribute it and/or modify it under\n *  the terms of the GNU General Public License as published by the Free\n *  Software Foundation; either version 2 of the License, or (at your option)\n *  any later version.\n *\n *  In addition, as a special exception, the copyright holders give permission\n *  to link the code of portions of this program with the OpenSSL library under\n *  certain conditions as described in each individual source file, and\n *  distribute linked combinations including the two. You must obey the GNU\n *  General Public License in all respects for all of the code used other than\n *  OpenSSL. If you modify file(s) with this exception, you may extend this\n *  exception to your version of the file(s), but you are not obligated to do\n *  so. If you do not wish to do so, delete this exception statement from your\n *  version.  If you delete this exception statement from all source files in\n *  the program, then also delete it here.\n *\n *  SLURM is distributed in the hope that it will be useful, but WITHOUT ANY\n *  WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n *  FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more\n *  details.\n *\n *  You should have received a copy of the GNU General Public License along\n *  with SLURM; if not, write to the Free Software Foundation, Inc.,\n *  51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA.\n \\*****************************************************************************/\n\n#include \"pmixp_dconn.h\"\n#include \"pmixp_dconn_ucx.h\"\n#include <unistd.h>\n#include <dlfcn.h>\n#include <ucp/api/ucp.h>\n\n/* local variables */\nstatic int _service_pipe[2];\n#define PMIXP_UCX_LIST_PREALLOC 16\nstatic pmixp_list_t _free_list;\nstatic pmixp_rlist_t _rcv_pending, _snd_pending;\nstatic pmixp_rlist_t _rcv_complete, _snd_complete;\nstatic int _server_fd = -1;\nstatic bool _direct_hdr_set = false;\nstatic pmixp_p2p_data_t _direct_hdr;\nstatic void *_host_hdr = NULL;\npthread_mutex_t _ucx_worker_lock;\n\n\n\n/* UCX objects */\nucp_context_h ucp_context;\nucp_worker_h ucp_worker;\nstatic ucp_address_t *_ucx_addr;\nstatic size_t _ucx_alen;\n\ntypedef enum {\n\tPMIXP_UCX_ACTIVE = 0,\n\tPMIXP_UCX_COMPLETE,\n\tPMIXP_UCX_FAILED\n} pmixp_ucx_status_t;\n\ntypedef struct {\n\tvolatile pmixp_ucx_status_t status;\n\tvoid *buffer;\n\tsize_t len;\n\tvoid *msg;\n} pmixp_ucx_req_t;\n\ntypedef struct {\n\tint nodeid;\n\tbool connected;\n\tucp_ep_h server_ep;\n\tvoid *ucx_addr;\n\tsize_t ucx_alen;\n\tpmixp_p2p_data_t eng_hdr;\n\tpmixp_rlist_t pending;\n} pmixp_dconn_ucx_t;\n\nstatic inline void _recv_req_release(pmixp_ucx_req_t *req)\n{\n\tif (req->buffer) {\n\t\txfree(req->buffer);\n\t}\n\tmemset(req, 0, sizeof(*req));\n\tucp_request_release(req);\n}\n\nstatic void request_init(void *request)\n{\n\tpmixp_ucx_req_t *req = (pmixp_ucx_req_t *) request;\n\treq->status = PMIXP_UCX_ACTIVE;\n\tmemset(req, 0, sizeof(*req));\n}\n\nstatic void send_handle(void *request, ucs_status_t status)\n{\n\tpmixp_ucx_req_t *req = (pmixp_ucx_req_t *) request;\n\tif (UCS_OK == status){\n\t\treq->status = PMIXP_UCX_COMPLETE;\n\t} else {\n\t\tPMIXP_ERROR(\"UCX send request failed: %s\",\n\t\t\t    ucs_status_string(status));\n\t\treq->status = PMIXP_UCX_FAILED;\n\t}\n}\n\nstatic void recv_handle(void *request, ucs_status_t status,\n\t\t\tucp_tag_recv_info_t *info)\n{\n\tpmixp_ucx_req_t *req = (pmixp_ucx_req_t *) request;\n\tif (UCS_OK == status){\n\t\treq->status = PMIXP_UCX_COMPLETE;\n\t} else {\n\t\tPMIXP_ERROR(\"UCX send request failed: %s\",\n\t\t\t    ucs_status_string(status));\n\t\treq->status = PMIXP_UCX_FAILED;\n\t}\n}\n\nstatic bool _epoll_readable(eio_obj_t *obj);\nstatic int _epoll_read(eio_obj_t *obj, List objs);\n\nstatic struct io_operations _epoll_ops = {\n\t.readable = _epoll_readable,\n\t.handle_read = _epoll_read\n};\n\nstatic bool _progress_readable(eio_obj_t *obj);\nstatic int _progress_read(eio_obj_t *obj, List objs);\n\nstatic struct io_operations _progress_ops = {\n\t.readable = _progress_readable,\n\t.handle_read = _progress_read\n};\n\nstatic void *_ucx_init(int nodeid, pmixp_p2p_data_t direct_hdr);\nstatic void _ucx_fini(void *_priv);\nstatic int _ucx_connect(void *_priv, void *ep_data, size_t ep_len,\n\t\t\tvoid *init_msg);\nstatic int _ucx_send(void *_priv, void *msg);\nstatic void _ucx_regio(eio_handle_t *h);\nstatic void *_ucx_lib_handler = NULL;\n\nstatic int _load_ucx_lib()\n{\n\t/* At the time of writing this UCX doesn't support\n\t * fork() and it's memory hooks are causing memory\n\t * corruptions in the forked processes.\n\t * To avoid that we need to disable memory hooks before\n\t * loading UCX library.\n\t */\n\tsetenv(\"UCX_MEM_MMAP_RELOC\", \"no\", 1);\n\tsetenv(\"UCX_MEM_MALLOC_HOOKS\", \"no\", 1);\n\tsetenv(\"UCX_MEM_MALLOC_RELOC\", \"no\", 1);\n\tsetenv(\"UCX_MEM_EVENTS\", \"no\", 1);\n\n#ifdef PMIXP_UCX_LIBPATH\n\t/* If this SLURM build doesn't allow RPATH's\n\t * try to open library by it's full path that\n\t * we have from autoconf\n\t */\n\tchar *full_path = NULL;\n\txstrfmtcat(full_path, \"%s/libucp.so\", PMIXP_UCX_LIBPATH);\n\t_ucx_lib_handler = dlopen(full_path, RTLD_LAZY | RTLD_GLOBAL);\n\txfree(full_path);\n\tif (_ucx_lib_handler) {\n\t\t/* successful, exit now */\n\t\treturn SLURM_SUCCESS;\n\t}\n\t/* fall-thru to see if libucp.so is located in the location\n\t * known by dynamic linker.\n\t */\n#endif\n\t_ucx_lib_handler = dlopen(\"libucp.so\", RTLD_LAZY | RTLD_GLOBAL);\n\tif (!_ucx_lib_handler) {\n\t\tchar *err = dlerror();\n\t\tPMIXP_ERROR(\"Cannot open UCX lib: %s\", (err) ? err : \"unknown\");\n\t\treturn SLURM_ERROR;\n\t}\n\treturn SLURM_SUCCESS;\n}\n\nstatic void _unload_ucx_lib()\n{\n\txassert(_ucx_lib_handler);\n\tif (_ucx_lib_handler) {\n\t\tdlclose(_ucx_lib_handler);\n\t}\n}\n\nint pmixp_dconn_ucx_prepare(pmixp_dconn_handlers_t *handlers,\n\t\t\t    char **ep_data, size_t *ep_len)\n{\n\tucp_config_t *config;\n\tucs_status_t status;\n\tucp_params_t ucp_params;\n\tucp_worker_params_t worker_params;\n\n\t/* By default UCX is not loaded until we explicitly\n\t * asked for that\n\t */\n\t_load_ucx_lib();\n\n\tslurm_mutex_init(&_ucx_worker_lock);\n\n\t/* container of the free elements */\n\tpmixp_list_init(&_free_list);\n\n\t/* Containers for the non-completed requests */\n\tpmixp_rlist_init(&_rcv_pending, &_free_list, PMIXP_UCX_LIST_PREALLOC);\n\tpmixp_rlist_init(&_snd_pending, &_free_list, PMIXP_UCX_LIST_PREALLOC);\n\n\t/* Temp lists to hold completed requests for _ucx_progress */\n\tpmixp_rlist_init(&_snd_complete, &_free_list, PMIXP_UCX_LIST_PREALLOC);\n\tpmixp_rlist_init(&_rcv_complete, &_free_list, PMIXP_UCX_LIST_PREALLOC);\n\n\n\tstatus = ucp_config_read(NULL, NULL, &config);\n\tif (status != UCS_OK) {\n\t\tPMIXP_ERROR(\"Fail to read UCX config: %s\",\n\t\t\t    ucs_status_string(status));\n\t\treturn SLURM_ERROR;\n\t}\n\n\tucp_params.features = UCP_FEATURE_TAG | UCP_FEATURE_WAKEUP;\n\tucp_params.request_size    = sizeof(pmixp_ucx_req_t);\n\tucp_params.request_init    = request_init;\n\tucp_params.request_cleanup = NULL;\n\tucp_params.field_mask      = UCP_PARAM_FIELD_FEATURES |\n\t\t\tUCP_PARAM_FIELD_REQUEST_SIZE |\n\t\t\tUCP_PARAM_FIELD_REQUEST_INIT |\n\t\t\tUCP_PARAM_FIELD_REQUEST_CLEANUP;\n\n\tstatus = ucp_init(&ucp_params, config, &ucp_context);\n\n\tucp_config_release(config);\n\tif (status != UCS_OK) {\n\t\tPMIXP_ERROR(\"Fail to init UCX: %s\",\n\t\t\t    ucs_status_string(status));\n\t\treturn SLURM_ERROR;\n\t}\n\n\tworker_params.field_mask  = UCP_WORKER_PARAM_FIELD_THREAD_MODE;\n\tworker_params.thread_mode = UCS_THREAD_MODE_MULTI;\n\n\tstatus = ucp_worker_create(ucp_context, &worker_params, &ucp_worker);\n\tif (status != UCS_OK) {\n\t\tPMIXP_ERROR(\"Fail to create UCX worker: %s\",\n\t\t\t    ucs_status_string(status));\n\t\tgoto err_worker;\n\t}\n\n\tstatus = ucp_worker_get_address(ucp_worker, &_ucx_addr, &_ucx_alen);\n\tif (status != UCS_OK) {\n\t\tPMIXP_ERROR(\"Fail to get UCX address: %s\",\n\t\t\t    ucs_status_string(status));\n\t\tgoto err_addr;\n\t}\n\n\tstatus = ucp_worker_get_efd(ucp_worker, &_server_fd);\n\tif (status != UCS_OK) {\n\t\tPMIXP_ERROR(\"Fail to get UCX epoll fd: %s\",\n\t\t\t    ucs_status_string(status));\n\t\tgoto err_efd;\n\t}\n\n\tmemset(handlers, 0, sizeof(*handlers));\n\thandlers->connect = _ucx_connect;\n\thandlers->init = _ucx_init;\n\thandlers->fini = _ucx_fini;\n\thandlers->send = _ucx_send;\n\thandlers->getio = NULL;\n\thandlers->regio = _ucx_regio;\n\n\t*ep_data = (void*)_ucx_addr;\n\t*ep_len  = (uint16_t)_ucx_alen;\n\n\treturn SLURM_SUCCESS;\n\nerr_efd:\n\tucp_worker_release_address(ucp_worker, _ucx_addr);\nerr_addr:\n\tucp_worker_destroy(ucp_worker);\nerr_worker:\n\tucp_cleanup(ucp_context);\n\treturn SLURM_ERROR;\n\n}\n\nstatic void _release_send_requests(pmixp_rlist_t *l)\n{\n\tsize_t count = pmixp_rlist_count(l);\n\tsize_t i;\n\tfor (i=0; i<count; i++) {\n\t\tpmixp_ucx_req_t *req;\n\t\treq = (pmixp_ucx_req_t*)pmixp_rlist_deq(l);\n\t\txassert(req);\n\n\t\tucp_request_cancel(ucp_worker, req);\n\t\tif (req->buffer) {\n\t\t\t/* NOTE: since we are finalizing, we don't really care\n\t\t\t * about the status */\n\t\t\t_direct_hdr.send_complete(req->msg, PMIXP_P2P_REGULAR,\n\t\t\t\t\t\t  SLURM_SUCCESS);\n\t\t}\n\t\tucp_request_release(req);\n\t}\n}\n\nstatic void _release_recv_requests(pmixp_rlist_t *l)\n{\n\tsize_t count = pmixp_rlist_count(l);\n\tsize_t i;\n\n\tfor (i=0; i < count; i++) {\n\t\tpmixp_ucx_req_t *req;\n\t\treq = (pmixp_ucx_req_t*)pmixp_rlist_deq(l);\n\t\txassert(req);\n\t\tucp_request_cancel(ucp_worker, req);\n\t\t_recv_req_release(req);\n\t}\n}\n\nvoid pmixp_dconn_ucx_stop()\n{\n\tslurm_mutex_lock(&_ucx_worker_lock);\n\t_release_send_requests(&_snd_pending);\n\t_release_send_requests(&_snd_complete);\n\n\t_release_recv_requests(&_rcv_pending);\n\t_release_recv_requests(&_rcv_complete);\n\tslurm_mutex_unlock(&_ucx_worker_lock);\n}\n\nvoid pmixp_dconn_ucx_finalize()\n{\n\tpmixp_list_elem_t *elem;\n\tsize_t count, i;\n\txassert(_direct_hdr_set);\n\n\tpmixp_rlist_fini(&_snd_pending);\n\tpmixp_rlist_fini(&_snd_complete);\n\tpmixp_rlist_fini(&_rcv_pending);\n\tpmixp_rlist_fini(&_rcv_complete);\n\n\t/* All elements from the previous lists should settle\n\t * down in this free list now. Release it!\n\t */\n\tcount = pmixp_list_count(&_free_list);\n\tfor (i=0; i < count; i++) {\n\t\telem = pmixp_list_deq(&_free_list);\n\t\tpmixp_list_elem_free(elem);\n\t}\n\n\t/* cleanup UCX */\n\tucp_worker_destroy(ucp_worker);\n\tucp_cleanup(ucp_context);\n\n\t/* unload UCX lib */\n\t_unload_ucx_lib();\n\tslurm_mutex_destroy(&_ucx_worker_lock);\n}\n\nstatic int _activate_progress()\n{\n\tchar buf = 'c';\n\tint rc = write(_service_pipe[1], &buf, sizeof(buf));\n\tif (sizeof(buf) != rc) {\n\t\tPMIXP_ERROR(\"Unable to activate UCX progress\");\n\t\tif (0 > rc) {\n\t\t\treturn rc;\n\t\t} else {\n\t\t\treturn SLURM_ERROR;\n\t\t}\n\t}\n\treturn SLURM_SUCCESS;\n}\n\nvoid _ucx_process_msg(char *buffer, size_t len)\n{\n\txassert(_direct_hdr_set);\n\t_direct_hdr.hdr_unpack_cb(buffer, _host_hdr);\n\n\tBuf buf = create_buf(buffer, len);\n\tset_buf_offset(buf, _direct_hdr.rhdr_net_size);\n\t_direct_hdr.new_msg(_host_hdr, buf);\n}\n\nstatic bool _ucx_progress()\n{\n\tpmixp_ucx_req_t *req = NULL;\n\tucp_tag_message_h msg_tag;\n\tucp_tag_recv_info_t info_tag;\n\tpmixp_list_elem_t *elem;\n\tbool new_msg = false;\n\tsize_t count, i;\n\tint events_observed = 0;\n\n\t/* protected progress of UCX */\n\tslurm_mutex_lock(&_ucx_worker_lock);\n\tucp_worker_progress(ucp_worker);\n\n\t/* check for new messages */\n\twhile (1) {\n\t\tmsg_tag = ucp_tag_probe_nb(ucp_worker, 1, 0,\n\t\t\t\t\t   1, &info_tag);\n\t\tif (NULL == msg_tag) {\n\t\t\tbreak;\n\t\t}\n\t\tevents_observed++;\n\n\t\tchar *msg = xmalloc(info_tag.length);\n\t\tpmixp_ucx_req_t *req = (pmixp_ucx_req_t*)\n\t\t\t\tucp_tag_msg_recv_nb(ucp_worker, (void*)msg,\n\t\t\t\t\t\t    info_tag.length,\n\t\t\t\t\t\t    ucp_dt_make_contig(1),\n\t\t\t\t\t\t    msg_tag, recv_handle);\n\t\tif (UCS_PTR_IS_ERR(req)) {\n\t\t\tPMIXP_ERROR(\"ucp_tag_msg_recv_nb failed: %s\",\n\t\t\t\t    ucs_status_string(UCS_PTR_STATUS(req)));\n\t\t\tcontinue;\n\t\t}\n\t\tnew_msg = true;\n\t\treq->buffer = msg;\n\t\treq->len = info_tag.length;\n\t\tif (PMIXP_UCX_ACTIVE == req->status) {\n\t\t\t/* this message is long enough, so it makes\n\t\t\t * sense to do the progres one more timer */\n\t\t\tpmixp_rlist_enq(&_rcv_pending, req);\n\t\t} else {\n\t\t\tpmixp_rlist_enq(&_rcv_complete, req);\n\t\t}\n\t}\n\n\tif (!new_msg && pmixp_rlist_empty(&_rcv_pending) &&\n\t\t\t\tpmixp_rlist_empty(&_snd_pending)) {\n\t\tgoto exit;\n\t}\n\n\t/* Check pending requests */\n\telem = pmixp_rlist_begin(&_rcv_pending);\n\twhile (pmixp_rlist_end(&_rcv_pending) != elem) {\n\t\treq = PMIXP_LIST_VAL(elem);\n\t\tif (PMIXP_UCX_ACTIVE == req->status){\n\t\t\t/* go to the next element */\n\t\t\telem = pmixp_rlist_next(&_rcv_pending, elem);\n\t\t} else {\n\t\t\t/* grab this element for processing */\n\t\t\telem = pmixp_rlist_rem(&_rcv_pending, elem);\n\t\t\tpmixp_rlist_enq(&_rcv_complete, req);\n\t\t\tevents_observed++;\n\t\t}\n\t}\n\n\telem = pmixp_rlist_begin(&_snd_pending);\n\twhile (pmixp_rlist_end(&_snd_pending) != elem) {\n\t\treq = PMIXP_LIST_VAL(elem);\n\t\tif (PMIXP_UCX_ACTIVE == req->status){\n\t\t\t/* go to the next element */\n\t\t\telem = pmixp_rlist_next(&_snd_pending, elem);\n\t\t} else {\n\t\t\t/* grab this element for processing */\n\t\t\telem = pmixp_rlist_rem(&_snd_pending, elem);\n\t\t\tpmixp_rlist_enq(&_snd_complete, req);\n\t\t\tevents_observed++;\n\t\t}\n\t}\n\tslurm_mutex_unlock(&_ucx_worker_lock);\n\n\t/* process sends and receives unlocked */\n\telem = pmixp_rlist_begin(&_rcv_complete);\n\twhile (pmixp_rlist_end(&_rcv_complete) != elem) {\n\t\treq = PMIXP_LIST_VAL(elem);\n\t\t/* Skip failed receives\n\t\t * TODO: what more can we do? */\n\t\tif (PMIXP_UCX_FAILED != req->status){\n\t\t\t_ucx_process_msg(req->buffer, req->len);\n\t\t}\n\t\telem = pmixp_rlist_next(&_rcv_complete, elem);\n\t}\n\n\telem = pmixp_rlist_begin(&_snd_complete);\n\twhile (pmixp_rlist_end(&_snd_complete) != elem) {\n\t\treq = PMIXP_LIST_VAL(elem);\n\t\tint rc = SLURM_SUCCESS;\n\t\tif (PMIXP_UCX_FAILED == req->status){\n\t\t\trc = SLURM_ERROR;\n\t\t}\n\t\txassert(_direct_hdr_set);\n\t\tif (req->buffer) {\n\t\t\t_direct_hdr.send_complete(req->msg,\n\t\t\t\t\t\t  PMIXP_P2P_REGULAR, rc);\n\t\t}\n\t\telem = pmixp_rlist_next(&_snd_complete, elem);\n\t}\n\n\tslurm_mutex_lock(&_ucx_worker_lock);\n\n\tcount = pmixp_rlist_count(&_rcv_complete);\n\tfor (i=0; i < count; i++){\n\t\treq = (pmixp_ucx_req_t *)pmixp_rlist_deq(&_rcv_complete);\n\t\t/* release request to UCX */\n\t\tmemset(req, 0, sizeof(*req));\n\t\tucp_request_release(req);\n\t}\n\n\tcount = pmixp_rlist_count(&_snd_complete);\n\tfor (i=0; i < count; i++) {\n\t\treq = (pmixp_ucx_req_t *)pmixp_rlist_deq(&_snd_complete);\n\t\t/* release request to UCX */\n\t\tmemset(req, 0, sizeof(*req));\n\t\tucp_request_release(req);\n\t}\n\nexit:\n\tslurm_mutex_unlock(&_ucx_worker_lock);\n\treturn !!(events_observed);\n}\n\nstatic bool _epoll_readable(eio_obj_t *obj)\n{\n\tucs_status_t status = UCS_ERR_BUSY;\n\n\t/* sanity check */\n\txassert(NULL != obj );\n\tif (obj->shutdown) {\n\t\t/* corresponding connection will be\n\t\t * cleaned up during plugin finalize\n\t\t */\n\t\treturn false;\n\t}\n\n\tdo {\n\t\t/* process all outstanding events */\n\t\twhile (_ucx_progress());\n\n\t\tif (pmixp_rlist_count(&_rcv_pending) ||\n\t\t    pmixp_rlist_count(&_snd_pending)){\n\t\t\t/* If we got pending requests don't wait\n\t\t\t * on epoll, activate poll interuprtion through\n\t\t\t * the service pipe\n\t\t\t */\n\t\t\t_activate_progress();\n\t\t\treturn false;\n\t\t}\n\n\t\t/* arm the poll fd */\n\t\tslurm_mutex_lock(&_ucx_worker_lock);\n\t\tstatus = ucp_worker_arm(ucp_worker);\n\t\tslurm_mutex_unlock(&_ucx_worker_lock);\n\t} while (UCS_ERR_BUSY == status);\n\n\treturn true;\n}\n\nstatic int _epoll_read(eio_obj_t *obj, List objs)\n{\n\tif (obj->shutdown) {\n\t\t/* corresponding connection will be\n\t\t * cleaned up during plugin finalize\n\t\t */\n\t\treturn 0;\n\t}\n\t/* process all outstanding events */\n\twhile (_ucx_progress());\n\treturn 0;\n}\n\nstatic bool _progress_readable(eio_obj_t *obj)\n{\n\t/* sanity check */\n\txassert(NULL != obj );\n\tif (obj->shutdown) {\n\t\t/* corresponding connection will be\n\t\t\t * cleaned up during plugin finalize\n\t\t\t */\n\t\treturn false;\n\t}\n\t/* all the control is located in epoll_readable\n\t * here we only say that we are readable\n\t */\n\treturn true;\n}\n\nstatic int _progress_read(eio_obj_t *obj, List objs)\n{\n\tchar buf;\n\n\t/* sanity check */\n\txassert(NULL != obj );\n\tif( obj->shutdown ){\n\t\t/* corresponding connection will be\n\t\t * cleaned up during plugin finalize\n\t\t */\n\t\treturn 0;\n\t}\n\n\t/* empty the pipe */\n\twhile (sizeof(buf) == read(_service_pipe[0], &buf, sizeof(buf)));\n\n\t/* process all outstanding events */\n\twhile (_ucx_progress());\n\n\treturn 0;\n}\n\nstatic void *_ucx_init(int nodeid, pmixp_p2p_data_t direct_hdr)\n{\n\tpmixp_dconn_ucx_t *priv = xmalloc(sizeof(pmixp_dconn_ucx_t));\n\tpriv->nodeid = nodeid;\n\tpriv->connected = false;\n\tif (!_direct_hdr_set) {\n\t\t_direct_hdr = direct_hdr;\n\t\t_direct_hdr_set = true;\n\t\t_host_hdr = xmalloc(_direct_hdr.rhdr_host_size);\n\t}\n\n\tslurm_mutex_lock(&_ucx_worker_lock);\n\tpmixp_rlist_init(&priv->pending, &_free_list, PMIXP_UCX_LIST_PREALLOC);\n\tslurm_mutex_unlock(&_ucx_worker_lock);\n\n\treturn (void*)priv;\n}\n\nstatic void _ucx_fini(void *_priv)\n{\n\tpmixp_dconn_ucx_t *priv = (pmixp_dconn_ucx_t *)_priv;\n\n\tif (priv->connected) {\n\t\txfree(priv->ucx_addr);\n\t\tslurm_mutex_lock(&_ucx_worker_lock);\n\t\tucp_ep_destroy(priv->server_ep);\n\t\tslurm_mutex_unlock(&_ucx_worker_lock);\n\t} else {\n\t\tslurm_mutex_lock(&_ucx_worker_lock);\n\t\tpmixp_rlist_fini(&priv->pending);\n\t\tslurm_mutex_unlock(&_ucx_worker_lock);\n\t}\n\txfree(priv);\n}\n\nstatic int _ucx_connect(void *_priv, void *ep_data, size_t ep_len,\n\t\t\tvoid *init_msg)\n{\n\tpmixp_dconn_ucx_t *priv = (pmixp_dconn_ucx_t *)_priv;\n\tucp_ep_params_t ep_params;\n\tucs_status_t status;\n\tint rc = SLURM_SUCCESS;\n\tsize_t i, count;\n\n\tpriv->ucx_addr = ep_data;\n\tpriv->ucx_alen = ep_len;\n\t/* Connect to the server */\n\tep_params.field_mask = UCP_EP_PARAM_FIELD_REMOTE_ADDRESS;\n\tep_params.address    = priv->ucx_addr;\n\n\tslurm_mutex_lock(&_ucx_worker_lock);\n\tstatus = ucp_ep_create(ucp_worker, &ep_params, &priv->server_ep);\n\tif (status != UCS_OK) {\n\t\tPMIXP_ERROR(\"ucp_ep_create failed: %s\",\n\t\t\t    ucs_status_string(status));\n\t\txfree(priv->ucx_addr);\n\t\tslurm_mutex_unlock(&_ucx_worker_lock);\n\t\treturn SLURM_ERROR;\n\t}\n\tpriv->connected = true;\n\n\t/* Enqueue initialization message if requested */\n\tif (init_msg) {\n\t\tpmixp_rlist_push(&priv->pending, init_msg);\n\t}\n\tslurm_mutex_unlock(&_ucx_worker_lock);\n\n\t/* we need to send data while being unlocked */\n\tif (SLURM_SUCCESS == rc){\n\t\tpmixp_list_elem_t *elem = NULL;\n\t\t/* Send all pending messages */\n\t\telem = pmixp_rlist_begin(&priv->pending);\n\t\twhile (pmixp_rlist_end(&priv->pending) != elem) {\n\t\t\t_ucx_send(_priv, PMIXP_LIST_VAL(elem));\n\t\t\telem = pmixp_rlist_next(&priv->pending, elem);\n\t\t}\n\t}\n\n\tslurm_mutex_lock(&_ucx_worker_lock);\n\n\tcount = pmixp_rlist_count(&priv->pending);\n\tfor (i=0; i < count; i++) {\n\t\t/* message is already processed, the value is\n\t\t * not valid anymore.\n\t\t * just dequeue from the list to ensure service\n\t\t * structures cleanup\n\t\t */\n\t\t(void)pmixp_rlist_deq(&priv->pending);\n\t}\n\t/* there will be no more pending messages, we can\n\t * safely release pending list now\n\t */\n\tpmixp_rlist_fini(&priv->pending);\n\tslurm_mutex_unlock(&_ucx_worker_lock);\n\n\treturn rc;\n}\n\n\nstatic int _ucx_send(void *_priv, void *msg)\n{\n\tpmixp_dconn_ucx_t *priv = (pmixp_dconn_ucx_t *)_priv;\n\tint rc = SLURM_SUCCESS;\n\tbool release = false;\n\n\tslurm_mutex_lock(&_ucx_worker_lock);\n\tif (!priv->connected) {\n\t\tpmixp_rlist_enq(&priv->pending, msg);\n\t} else {\n\t\tpmixp_ucx_req_t *req = NULL;\n\t\txassert(_direct_hdr_set);\n\t\tchar *mptr = _direct_hdr.buf_ptr(msg);\n\t\tsize_t msize = _direct_hdr.buf_size(msg);\n\t\treq = (pmixp_ucx_req_t*)\n\t\t\tucp_tag_send_nb(priv->server_ep,\n\t\t\t\t\t(void*)mptr, msize,\n\t\t\t\t\tucp_dt_make_contig(1),\n\t\t\t\t\tpmixp_info_nodeid(), send_handle);\n\t\tif (UCS_PTR_IS_ERR(req)) {\n\t\t\tPMIXP_ERROR(\"Unable to send UCX message: %s\\n\",\n\t\t\t\t    ucs_status_string(UCS_PTR_STATUS(req)));\n\t\t\tgoto exit;\n\t\t} else if (UCS_OK == UCS_PTR_STATUS(req)) {\n\t\t\t/* defer release until we unlock ucp worker */\n\t\t\trelease = true;\n\t\t} else {\n\t\t\treq->msg = msg;\n\t\t\treq->buffer = mptr;\n\t\t\treq->len = msize;\n\t\t\tpmixp_rlist_enq(&_snd_pending, (void*)req);\n\t\t\t_activate_progress();\n\n\t\t}\n\t}\nexit:\n\tslurm_mutex_unlock(&_ucx_worker_lock);\n\n\tif (release){\n\t\t_direct_hdr.send_complete(msg, PMIXP_P2P_INLINE,\n\t\t\t\t\t  SLURM_SUCCESS);\n\t}\n\treturn rc;\n}\n\nstatic void _ucx_regio(eio_handle_t *h)\n{\n\teio_obj_t *obj;\n\n\tpipe(_service_pipe);\n\tfd_set_nonblocking(_service_pipe[0]);\n\tfd_set_nonblocking(_service_pipe[1]);\n\tfd_set_close_on_exec(_service_pipe[0]);\n\tfd_set_close_on_exec(_service_pipe[1]);\n\n\tobj = eio_obj_create(_service_pipe[0], &_progress_ops, (void *)(-1));\n\teio_new_initial_obj(h, obj);\n\n\tobj = eio_obj_create(_server_fd, &_epoll_ops, (void *)(-1));\n\teio_new_initial_obj(h, obj);\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/src/plugins/proctrack/sgi_job/proctrack_sgi_job.c": "/*****************************************************************************\\\n *  proctrack_sgi_job.c - process tracking via SGI's \"job\" module.\n *****************************************************************************\n *  Copyright (C) 2005 The Regents of the University of California.\n *  Produced at Lawrence Livermore National Laboratory (cf, DISCLAIMER).\n *  Written by Mark Grondona <mgrondona@llnl.gov>\n *  CODE-OCEC-09-009. All rights reserved.\n *\n *  This file is part of SLURM, a resource management program.\n *  For details, see <https://slurm.schedmd.com/>.\n *  Please also read the included file: DISCLAIMER.\n *\n *  SLURM is free software; you can redistribute it and/or modify it under\n *  the terms of the GNU General Public License as published by the Free\n *  Software Foundation; either version 2 of the License, or (at your option)\n *  any later version.\n *\n *  In addition, as a special exception, the copyright holders give permission\n *  to link the code of portions of this program with the OpenSSL library under\n *  certain conditions as described in each individual source file, and\n *  distribute linked combinations including the two. You must obey the GNU\n *  General Public License in all respects for all of the code used other than\n *  OpenSSL. If you modify file(s) with this exception, you may extend this\n *  exception to your version of the file(s), but you are not obligated to do\n *  so. If you do not wish to do so, delete this exception statement from your\n *  version.  If you delete this exception statement from all source files in\n *  the program, then also delete it here.\n *\n *  SLURM is distributed in the hope that it will be useful, but WITHOUT ANY\n *  WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n *  FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more\n *  details.\n *\n *  You should have received a copy of the GNU General Public License along\n *  with SLURM; if not, write to the Free Software Foundation, Inc.,\n *  51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA.\n\\*****************************************************************************/\n\n#include <dlfcn.h>\n#include <inttypes.h>\n#include <signal.h>\n#include <stdlib.h>\n#include <sys/types.h>\n#include <unistd.h>\n\n#include \"slurm/slurm.h\"\n#include \"slurm/slurm_errno.h\"\n#include \"src/common/log.h\"\n\n#include \"src/slurmd/slurmstepd/slurmstepd_job.h\"\n\nconst char plugin_name[]      = \"Process tracking via SGI job module\";\nconst char plugin_type[]      = \"proctrack/sgi_job\";\nconst uint32_t plugin_version = SLURM_VERSION_NUMBER;\n\n/*\n * We can't include <job.h> since its prototypes conflict with some\n *  of SLURM's. Instead, put important function protypes and\n *  the jid_t typedef here:\n */\ntypedef uint64_t jid_t;\n\ntypedef jid_t (*create_f)    (jid_t jid_requested, uid_t uid, int options);\ntypedef jid_t (*getjid_f)    (pid_t pid);\ntypedef jid_t (*waitjid_f)   (jid_t jid, int *status, int options);\ntypedef int   (*killjid_f)   (jid_t jid, int sig);\ntypedef jid_t (*detachpid_f) (pid_t pid);\ntypedef jid_t (*attachpid_f) (pid_t pid, jid_t jid_requested);\ntypedef int   (*getpidlist_f)(jid_t jid, pid_t *pid, int bufsize);\ntypedef int   (*getpidcnt_f) (jid_t jid);\n\n/*\n *  Handle to libjob.so\n */\nstatic void *libjob_handle = NULL;\n\n/*\n *  libjob operations we'll need in this plugin\n */\nstatic struct job_operations {\n\tcreate_f     create;\n\tgetjid_f     getjid;\n\twaitjid_f    waitjid;\n\tkilljid_f    killjid;\n\tdetachpid_f  detachpid;\n\tattachpid_f  attachpid;\n\tgetpidlist_f getpidlist;\n\tgetpidcnt_f  getpidcnt;\n} job_ops;\n\n\n/*\n * init() is called when the plugin is loaded, before any other functions\n * are called.  Put global initialization here.\n */\nint init (void)\n{\n\t/*  We dlopen() libjob.so instead of directly linking to it\n\t *   because of symbols like \"job_create\" in libjob which\n\t *   conflict with symbols in slurmd. dlopening the library\n\t *   prevents these symbols from going into the global namespace.\n\t */\n\tif ((libjob_handle = dlopen (\"libjob.so\", RTLD_LAZY)) == NULL) {\n\t\terror (\"Unable to open libjob.so: %m\");\n\t\treturn SLURM_ERROR;\n\t}\n\n\tjob_ops.create    = dlsym (libjob_handle, \"job_create\");\n\tjob_ops.getjid    = dlsym (libjob_handle, \"job_getjid\");\n\tjob_ops.waitjid   = dlsym (libjob_handle, \"job_waitjid\");\n\tjob_ops.killjid   = dlsym (libjob_handle, \"job_killjid\");\n\tjob_ops.detachpid = dlsym (libjob_handle, \"job_detachpid\");\n\tjob_ops.attachpid = dlsym (libjob_handle, \"job_attachpid\");\n\tjob_ops.getpidlist= dlsym (libjob_handle, \"job_getpidlist\");\n\tjob_ops.getpidcnt = dlsym (libjob_handle, \"job_getpidcnt\");\n\n\tif (!job_ops.create)\n\t\terror (\"Unable to resolve job_create in libjob.so\");\n\tif (!job_ops.getjid)\n\t\terror (\"Unable to resolve job_getjid in libjob.so\");\n\tif (!job_ops.waitjid)\n\t\terror (\"Unable to resolve job_waitjid in libjob.so\");\n\tif (!job_ops.killjid)\n\t\terror (\"Unable to resolve job_killjid in libjob.so\");\n\tif (!job_ops.detachpid)\n\t\terror (\"Unable to resolve job_detachpid in libjob.so\");\n\tif (!job_ops.attachpid)\n\t\terror (\"Unable to resolve job_attachpid in libjob.so\");\n\tif (!job_ops.getpidlist)\n\t\terror (\"Unable to resolve job_getpidlist in libjob.so\");\n\tif (!job_ops.getpidcnt)\n\t\terror (\"Unable to resolve job_getpidcnt in libjob.so\");\n\n\tdebug (\"successfully loaded libjob.so\");\n\treturn SLURM_SUCCESS;\n}\n\nint fini (void)\n{\n\tdlclose (libjob_handle);\n\treturn SLURM_SUCCESS;\n}\n\njid_t _job_create (jid_t jid, uid_t uid, int options)\n{\n\treturn ((*job_ops.create) (jid, uid, options));\n}\n\njid_t _job_getjid (pid_t pid)\n{\n\treturn ((*job_ops.getjid) (pid));\n}\n\njid_t _job_waitjid (jid_t jid, int *status, int options)\n{\n\treturn ((*job_ops.waitjid) (jid, status, options));\n}\n\nint _job_killjid (jid_t jid, int sig)\n{\n\treturn ((*job_ops.killjid) (jid, sig));\n}\n\nint _job_detachpid (pid_t pid)\n{\n\treturn ((*job_ops.detachpid) (pid));\n}\n\nint _job_attachpid (pid_t pid, jid_t jid)\n{\n\treturn ((*job_ops.attachpid) (pid, jid));\n}\n\nint _job_getpidlist (jid_t jid, pid_t *pid, int bufsize)\n{\n\treturn ((*job_ops.getpidlist) (jid, pid, bufsize));\n}\n\nint _job_getpidcnt (jid_t jid)\n{\n\treturn ((*job_ops.getpidcnt) (jid));\n}\n\nint proctrack_p_create (stepd_step_rec_t *job)\n{\n\tif (!libjob_handle)\n\t\tinit();\n\n\tif ((job->cont_id = _job_create (0, job->uid, 0)) == (jid_t) -1) {\n\t\terror (\"Failed to create job container: %m\");\n\t\treturn SLURM_ERROR;\n\t}\n\n\tdebug (\"created jid 0x%08lx\", job->cont_id);\n\n\treturn SLURM_SUCCESS;\n}\n\n/* NOTE: This function is called after slurmstepd spawns all user tasks.\n * Since the slurmstepd was placed in the job container when the container\n * was created and all of it's spawned tasks are placed into the container\n * when forked, all we need to do is remove the slurmstepd from the container\n * (once) at this time. */\nint proctrack_p_add (stepd_step_rec_t *job, pid_t pid)\n{\n\tstatic bool first = 1;\n\n\tif (!first)\n\t\treturn SLURM_SUCCESS;\n\n\tfirst = 0;\n\n\t/*\n\t *  Detach ourselves from the job container now that there\n\t *   is at least one other process in it.\n\t */\n\tif (_job_detachpid(getpid()) == (jid_t) -1) {\n\t\terror(\"Failed to detach from job container: %m\");\n\t\treturn SLURM_ERROR;\n\t}\n\n\treturn SLURM_SUCCESS;\n}\n\nint proctrack_p_signal (uint64_t id, int sig)\n{\n\tif ( (_job_killjid ((jid_t) id, sig) < 0)\n\t   && (errno != ENODATA) && (errno != EBADF) )\n\t\treturn (SLURM_ERROR);\n\treturn (SLURM_SUCCESS);\n}\n\nint proctrack_p_destroy (uint64_t id)\n{\n\tint status;\n\t_job_waitjid ((jid_t) id, &status, 0);\n\t/*  Assume any error means job doesn't exist. Therefore,\n\t *   return SUCCESS to slurmd so it doesn't retry continuously\n\t */\n\treturn SLURM_SUCCESS;\n}\n\nuint64_t proctrack_p_find (pid_t pid)\n{\n\tjid_t jid;\n\n\tif ((jid = _job_getjid (pid)) == (jid_t) -1)\n\t\treturn ((uint64_t) 0);\n\n\treturn ((uint64_t) jid);\n}\n\nbool proctrack_p_has_pid (uint64_t cont_id, pid_t pid)\n{\n\tjid_t jid;\n\n\tif ((jid = _job_getjid (pid)) == (jid_t) -1)\n\t\treturn false;\n\tif ((uint64_t)jid != cont_id)\n\t\treturn false;\n\n\treturn true;\n}\n\nint proctrack_p_wait (uint64_t id)\n{\n\tint status;\n\tif (_job_waitjid ((jid_t) id, &status, 0) == (jid_t)-1)\n\t\treturn SLURM_ERROR;\n\n\treturn SLURM_SUCCESS;\n}\n\nint proctrack_p_get_pids(uint64_t cont_id, pid_t **pids, int *npids)\n{\n\tint pidcnt, bufsize;\n\tpid_t *p;\n\n\tpidcnt = _job_getpidcnt((jid_t)cont_id);\n\tif (pidcnt > 0) {\n\t\t/*\n\t\t * FIXME - The \"+ 128\" is a rough attempt to allow for\n\t\t * the fact that _job_getpidcnt() followed by _job_get_pidlist\n\t\t * is not atomic.\n\t\t */\n\t\tbufsize = sizeof(pid_t) * (pidcnt + 128);\n\t\tp = (pid_t *)xmalloc(bufsize);\n\t\tpidcnt = _job_getpidlist((jid_t)cont_id, p, bufsize);\n\t\tif (pidcnt == -1) {\n\t\t\terror(\"job_getpidlist() failed: %m\");\n\t\t\t*pids = NULL;\n\t\t\t*npids = 0;\n\t\t\txfree(p);\n\t\t\treturn SLURM_ERROR;\n\t\t}\n\t\t*pids = p;\n\t\t*npids = pidcnt;\n\t} else {\n\t\t*pids = NULL;\n\t\t*npids = 0;\n\t}\n\n\treturn SLURM_SUCCESS;\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/src/plugins/proctrack/sgi_job/Makefile.am": "# Makefile for proctrack/sgi_job plugin\n\nAUTOMAKE_OPTIONS = foreign\n\nPLUGIN_FLAGS = - -module -avoid-version --export-dynamic\n\nAM_CPPFLAGS = -I$(top_srcdir) -I$(top_srcdir)/src/common\n\npkglib_LTLIBRARIES = proctrack_sgi_job.la\n\nproctrack_sgi_job_la_SOURCES = proctrack_sgi_job.c\nproctrack_sgi_job_la_LDFLAGS = $(PLUGIN_FLAGS) $(OTHER_FLAGS)\n# Don't need to add -ljob because we dlopen the .so to avoid\n#  symbol collisions with slurm functions\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/src/plugins/proctrack/sgi_job/Makefile.in": "# Makefile.in generated by automake 1.15.1 from Makefile.am.\n# @configure_input@\n\n# Copyright (C) 1994-2017 Free Software Foundation, Inc.\n\n# This Makefile.in is free software; the Free Software Foundation\n# gives unlimited permission to copy and/or distribute it,\n# with or without modifications, as long as this notice is preserved.\n\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY, to the extent permitted by law; without\n# even the implied warranty of MERCHANTABILITY or FITNESS FOR A\n# PARTICULAR PURPOSE.\n\n@SET_MAKE@\n\n# Makefile for proctrack/sgi_job plugin\n\nVPATH = @srcdir@\nam__is_gnu_make = { \\\n  if test -z '$(MAKELEVEL)'; then \\\n    false; \\\n  elif test -n '$(MAKE_HOST)'; then \\\n    true; \\\n  elif test -n '$(MAKE_VERSION)' && test -n '$(CURDIR)'; then \\\n    true; \\\n  else \\\n    false; \\\n  fi; \\\n}\nam__make_running_with_option = \\\n  case $${target_option-} in \\\n      ?) ;; \\\n      *) echo \"am__make_running_with_option: internal error: invalid\" \\\n              \"target option '$${target_option-}' specified\" >&2; \\\n         exit 1;; \\\n  esac; \\\n  has_opt=no; \\\n  sane_makeflags=$$MAKEFLAGS; \\\n  if $(am__is_gnu_make); then \\\n    sane_makeflags=$$MFLAGS; \\\n  else \\\n    case $$MAKEFLAGS in \\\n      *\\\\[\\ \\\t]*) \\\n        bs=\\\\; \\\n        sane_makeflags=`printf '%s\\n' \"$$MAKEFLAGS\" \\\n          | sed \"s/$$bs$$bs[$$bs $$bs\t]*//g\"`;; \\\n    esac; \\\n  fi; \\\n  skip_next=no; \\\n  strip_trailopt () \\\n  { \\\n    flg=`printf '%s\\n' \"$$flg\" | sed \"s/$$1.*$$//\"`; \\\n  }; \\\n  for flg in $$sane_makeflags; do \\\n    test $$skip_next = yes && { skip_next=no; continue; }; \\\n    case $$flg in \\\n      *=*|--*) continue;; \\\n        -*I) strip_trailopt 'I'; skip_next=yes;; \\\n      -*I?*) strip_trailopt 'I';; \\\n        -*O) strip_trailopt 'O'; skip_next=yes;; \\\n      -*O?*) strip_trailopt 'O';; \\\n        -*l) strip_trailopt 'l'; skip_next=yes;; \\\n      -*l?*) strip_trailopt 'l';; \\\n      -[dEDm]) skip_next=yes;; \\\n      -[JT]) skip_next=yes;; \\\n    esac; \\\n    case $$flg in \\\n      *$$target_option*) has_opt=yes; break;; \\\n    esac; \\\n  done; \\\n  test $$has_opt = yes\nam__make_dryrun = (target_option=n; $(am__make_running_with_option))\nam__make_keepgoing = (target_option=k; $(am__make_running_with_option))\npkgdatadir = $(datadir)/@PACKAGE@\npkgincludedir = $(includedir)/@PACKAGE@\npkglibdir = $(libdir)/@PACKAGE@\npkglibexecdir = $(libexecdir)/@PACKAGE@\nam__cd = CDPATH=\"$${ZSH_VERSION+.}$(PATH_SEPARATOR)\" && cd\ninstall_sh_DATA = $(install_sh) -c -m 644\ninstall_sh_PROGRAM = $(install_sh) -c\ninstall_sh_SCRIPT = $(install_sh) -c\nINSTALL_HEADER = $(INSTALL_DATA)\ntransform = $(program_transform_name)\nNORMAL_INSTALL = :\nPRE_INSTALL = :\nPOST_INSTALL = :\nNORMAL_UNINSTALL = :\nPRE_UNINSTALL = :\nPOST_UNINSTALL = :\nbuild_triplet = @build@\nhost_triplet = @host@\ntarget_triplet = @target@\nsubdir = src/plugins/proctrack/sgi_job\nACLOCAL_M4 = $(top_srcdir)/aclocal.m4\nam__aclocal_m4_deps = $(top_srcdir)/auxdir/ax_check_compile_flag.m4 \\\n\t$(top_srcdir)/auxdir/ax_check_zlib.m4 \\\n\t$(top_srcdir)/auxdir/ax_gcc_builtin.m4 \\\n\t$(top_srcdir)/auxdir/ax_lib_hdf5.m4 \\\n\t$(top_srcdir)/auxdir/ax_pthread.m4 \\\n\t$(top_srcdir)/auxdir/libtool.m4 \\\n\t$(top_srcdir)/auxdir/ltoptions.m4 \\\n\t$(top_srcdir)/auxdir/ltsugar.m4 \\\n\t$(top_srcdir)/auxdir/ltversion.m4 \\\n\t$(top_srcdir)/auxdir/lt~obsolete.m4 \\\n\t$(top_srcdir)/auxdir/slurm.m4 \\\n\t$(top_srcdir)/auxdir/x_ac__system_configuration.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_affinity.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_blcr.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_bluegene.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_cray.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_curl.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_databases.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_debug.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_deprecated.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_dlfcn.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_env.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_freeipmi.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_hwloc.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_iso.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_json.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_lua.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_lz4.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_man2html.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_munge.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_ncurses.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_netloc.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_nrt.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_ofed.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_pam.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_pmix.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_printf_null.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_ptrace.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_readline.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_rrdtool.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_setproctitle.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_sgi_job.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_slurm_ssl.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_ssh2.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_systemd.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_ucx.m4 \\\n\t$(top_srcdir)/auxdir/x_ac_uid_gid_size.m4 \\\n\t$(top_srcdir)/configure.ac\nam__configure_deps = $(am__aclocal_m4_deps) $(CONFIGURE_DEPENDENCIES) \\\n\t$(ACLOCAL_M4)\nDIST_COMMON = $(srcdir)/Makefile.am $(am__DIST_COMMON)\nmkinstalldirs = $(install_sh) -d\nCONFIG_HEADER = $(top_builddir)/config.h $(top_builddir)/slurm/slurm.h\nCONFIG_CLEAN_FILES =\nCONFIG_CLEAN_VPATH_FILES =\nam__vpath_adj_setup = srcdirstrip=`echo \"$(srcdir)\" | sed 's|.|.|g'`;\nam__vpath_adj = case $$p in \\\n    $(srcdir)/*) f=`echo \"$$p\" | sed \"s|^$$srcdirstrip/||\"`;; \\\n    *) f=$$p;; \\\n  esac;\nam__strip_dir = f=`echo $$p | sed -e 's|^.*/||'`;\nam__install_max = 40\nam__nobase_strip_setup = \\\n  srcdirstrip=`echo \"$(srcdir)\" | sed 's/[].[^$$\\\\*|]/\\\\\\\\&/g'`\nam__nobase_strip = \\\n  for p in $$list; do echo \"$$p\"; done | sed -e \"s|$$srcdirstrip/||\"\nam__nobase_list = $(am__nobase_strip_setup); \\\n  for p in $$list; do echo \"$$p $$p\"; done | \\\n  sed \"s| $$srcdirstrip/| |;\"' / .*\\//!s/ .*/ ./; s,\\( .*\\)/[^/]*$$,\\1,' | \\\n  $(AWK) 'BEGIN { files[\".\"] = \"\" } { files[$$2] = files[$$2] \" \" $$1; \\\n    if (++n[$$2] == $(am__install_max)) \\\n      { print $$2, files[$$2]; n[$$2] = 0; files[$$2] = \"\" } } \\\n    END { for (dir in files) print dir, files[dir] }'\nam__base_list = \\\n  sed '$$!N;$$!N;$$!N;$$!N;$$!N;$$!N;$$!N;s/\\n/ /g' | \\\n  sed '$$!N;$$!N;$$!N;$$!N;s/\\n/ /g'\nam__uninstall_files_from_dir = { \\\n  test -z \"$$files\" \\\n    || { test ! -d \"$$dir\" && test ! -f \"$$dir\" && test ! -r \"$$dir\"; } \\\n    || { echo \" ( cd '$$dir' && rm -f\" $$files \")\"; \\\n         $(am__cd) \"$$dir\" && rm -f $$files; }; \\\n  }\nam__installdirs = \"$(DESTDIR)$(pkglibdir)\"\nLTLIBRARIES = $(pkglib_LTLIBRARIES)\nproctrack_sgi_job_la_LIBADD =\nam_proctrack_sgi_job_la_OBJECTS = proctrack_sgi_job.lo\nproctrack_sgi_job_la_OBJECTS = $(am_proctrack_sgi_job_la_OBJECTS)\nAM_V_lt = $(am__v_lt_@AM_V@)\nam__v_lt_ = $(am__v_lt_@AM_DEFAULT_V@)\nam__v_lt_0 = --silent\nam__v_lt_1 = \nproctrack_sgi_job_la_LINK = $(LIBTOOL) $(AM_V_lt) --tag=CC \\\n\t$(AM_LIBTOOLFLAGS) $(LIBTOOLFLAGS) --mode=link $(CCLD) \\\n\t$(AM_CFLAGS) $(CFLAGS) $(proctrack_sgi_job_la_LDFLAGS) \\\n\t$(LDFLAGS) -o $@\nAM_V_P = $(am__v_P_@AM_V@)\nam__v_P_ = $(am__v_P_@AM_DEFAULT_V@)\nam__v_P_0 = false\nam__v_P_1 = :\nAM_V_GEN = $(am__v_GEN_@AM_V@)\nam__v_GEN_ = $(am__v_GEN_@AM_DEFAULT_V@)\nam__v_GEN_0 = @echo \"  GEN     \" $@;\nam__v_GEN_1 = \nAM_V_at = $(am__v_at_@AM_V@)\nam__v_at_ = $(am__v_at_@AM_DEFAULT_V@)\nam__v_at_0 = @\nam__v_at_1 = \nDEFAULT_INCLUDES = -I.@am__isrc@ -I$(top_builddir) -I$(top_builddir)/slurm\ndepcomp = $(SHELL) $(top_srcdir)/auxdir/depcomp\nam__depfiles_maybe = depfiles\nam__mv = mv -f\nCOMPILE = $(CC) $(DEFS) $(DEFAULT_INCLUDES) $(INCLUDES) $(AM_CPPFLAGS) \\\n\t$(CPPFLAGS) $(AM_CFLAGS) $(CFLAGS)\nLTCOMPILE = $(LIBTOOL) $(AM_V_lt) --tag=CC $(AM_LIBTOOLFLAGS) \\\n\t$(LIBTOOLFLAGS) --mode=compile $(CC) $(DEFS) \\\n\t$(DEFAULT_INCLUDES) $(INCLUDES) $(AM_CPPFLAGS) $(CPPFLAGS) \\\n\t$(AM_CFLAGS) $(CFLAGS)\nAM_V_CC = $(am__v_CC_@AM_V@)\nam__v_CC_ = $(am__v_CC_@AM_DEFAULT_V@)\nam__v_CC_0 = @echo \"  CC      \" $@;\nam__v_CC_1 = \nCCLD = $(CC)\nLINK = $(LIBTOOL) $(AM_V_lt) --tag=CC $(AM_LIBTOOLFLAGS) \\\n\t$(LIBTOOLFLAGS) --mode=link $(CCLD) $(AM_CFLAGS) $(CFLAGS) \\\n\t$(AM_LDFLAGS) $(LDFLAGS) -o $@\nAM_V_CCLD = $(am__v_CCLD_@AM_V@)\nam__v_CCLD_ = $(am__v_CCLD_@AM_DEFAULT_V@)\nam__v_CCLD_0 = @echo \"  CCLD    \" $@;\nam__v_CCLD_1 = \nSOURCES = $(proctrack_sgi_job_la_SOURCES)\nDIST_SOURCES = $(proctrack_sgi_job_la_SOURCES)\nam__can_run_installinfo = \\\n  case $$AM_UPDATE_INFO_DIR in \\\n    n|no|NO) false;; \\\n    *) (install-info --version) >/dev/null 2>&1;; \\\n  esac\nam__tagged_files = $(HEADERS) $(SOURCES) $(TAGS_FILES) $(LISP)\n# Read a list of newline-separated strings from the standard input,\n# and print each of them once, without duplicates.  Input order is\n# *not* preserved.\nam__uniquify_input = $(AWK) '\\\n  BEGIN { nonempty = 0; } \\\n  { items[$$0] = 1; nonempty = 1; } \\\n  END { if (nonempty) { for (i in items) print i; }; } \\\n'\n# Make sure the list of sources is unique.  This is necessary because,\n# e.g., the same source file might be shared among _SOURCES variables\n# for different programs/libraries.\nam__define_uniq_tagged_files = \\\n  list='$(am__tagged_files)'; \\\n  unique=`for i in $$list; do \\\n    if test -f \"$$i\"; then echo $$i; else echo $(srcdir)/$$i; fi; \\\n  done | $(am__uniquify_input)`\nETAGS = etags\nCTAGS = ctags\nam__DIST_COMMON = $(srcdir)/Makefile.in $(top_srcdir)/auxdir/depcomp\nDISTFILES = $(DIST_COMMON) $(DIST_SOURCES) $(TEXINFOS) $(EXTRA_DIST)\nACLOCAL = @ACLOCAL@\nAMTAR = @AMTAR@\nAM_DEFAULT_VERBOSITY = @AM_DEFAULT_VERBOSITY@\nAR = @AR@\nAUTOCONF = @AUTOCONF@\nAUTOHEADER = @AUTOHEADER@\nAUTOMAKE = @AUTOMAKE@\nAWK = @AWK@\nBGQ_LOADED = @BGQ_LOADED@\nBG_INCLUDES = @BG_INCLUDES@\nBG_LDFLAGS = @BG_LDFLAGS@\nBLCR_CPPFLAGS = @BLCR_CPPFLAGS@\nBLCR_HOME = @BLCR_HOME@\nBLCR_LDFLAGS = @BLCR_LDFLAGS@\nBLCR_LIBS = @BLCR_LIBS@\nBLUEGENE_LOADED = @BLUEGENE_LOADED@\nCC = @CC@\nCCDEPMODE = @CCDEPMODE@\nCFLAGS = @CFLAGS@\nCHECK_CFLAGS = @CHECK_CFLAGS@\nCHECK_LIBS = @CHECK_LIBS@\nCPP = @CPP@\nCPPFLAGS = @CPPFLAGS@\nCRAY_JOB_CPPFLAGS = @CRAY_JOB_CPPFLAGS@\nCRAY_JOB_LDFLAGS = @CRAY_JOB_LDFLAGS@\nCRAY_SELECT_CPPFLAGS = @CRAY_SELECT_CPPFLAGS@\nCRAY_SELECT_LDFLAGS = @CRAY_SELECT_LDFLAGS@\nCRAY_SWITCH_CPPFLAGS = @CRAY_SWITCH_CPPFLAGS@\nCRAY_SWITCH_LDFLAGS = @CRAY_SWITCH_LDFLAGS@\nCRAY_TASK_CPPFLAGS = @CRAY_TASK_CPPFLAGS@\nCRAY_TASK_LDFLAGS = @CRAY_TASK_LDFLAGS@\nCXX = @CXX@\nCXXCPP = @CXXCPP@\nCXXDEPMODE = @CXXDEPMODE@\nCXXFLAGS = @CXXFLAGS@\nCYGPATH_W = @CYGPATH_W@\nDATAWARP_CPPFLAGS = @DATAWARP_CPPFLAGS@\nDATAWARP_LDFLAGS = @DATAWARP_LDFLAGS@\nDEFS = @DEFS@\nDEPDIR = @DEPDIR@\nDLLTOOL = @DLLTOOL@\nDL_LIBS = @DL_LIBS@\nDSYMUTIL = @DSYMUTIL@\nDUMPBIN = @DUMPBIN@\nECHO_C = @ECHO_C@\nECHO_N = @ECHO_N@\nECHO_T = @ECHO_T@\nEGREP = @EGREP@\nEXEEXT = @EXEEXT@\nFGREP = @FGREP@\nFREEIPMI_CPPFLAGS = @FREEIPMI_CPPFLAGS@\nFREEIPMI_LDFLAGS = @FREEIPMI_LDFLAGS@\nFREEIPMI_LIBS = @FREEIPMI_LIBS@\nGLIB_CFLAGS = @GLIB_CFLAGS@\nGLIB_COMPILE_RESOURCES = @GLIB_COMPILE_RESOURCES@\nGLIB_GENMARSHAL = @GLIB_GENMARSHAL@\nGLIB_LIBS = @GLIB_LIBS@\nGLIB_MKENUMS = @GLIB_MKENUMS@\nGOBJECT_QUERY = @GOBJECT_QUERY@\nGREP = @GREP@\nGTK_CFLAGS = @GTK_CFLAGS@\nGTK_LIBS = @GTK_LIBS@\nH5CC = @H5CC@\nH5FC = @H5FC@\nHAVEMYSQLCONFIG = @HAVEMYSQLCONFIG@\nHAVE_MAN2HTML = @HAVE_MAN2HTML@\nHAVE_NRT = @HAVE_NRT@\nHAVE_OPENSSL = @HAVE_OPENSSL@\nHAVE_SOME_CURSES = @HAVE_SOME_CURSES@\nHDF5_CC = @HDF5_CC@\nHDF5_CFLAGS = @HDF5_CFLAGS@\nHDF5_CPPFLAGS = @HDF5_CPPFLAGS@\nHDF5_FC = @HDF5_FC@\nHDF5_FFLAGS = @HDF5_FFLAGS@\nHDF5_FLIBS = @HDF5_FLIBS@\nHDF5_LDFLAGS = @HDF5_LDFLAGS@\nHDF5_LIBS = @HDF5_LIBS@\nHDF5_TYPE = @HDF5_TYPE@\nHDF5_VERSION = @HDF5_VERSION@\nHWLOC_CPPFLAGS = @HWLOC_CPPFLAGS@\nHWLOC_LDFLAGS = @HWLOC_LDFLAGS@\nHWLOC_LIBS = @HWLOC_LIBS@\nINSTALL = @INSTALL@\nINSTALL_DATA = @INSTALL_DATA@\nINSTALL_PROGRAM = @INSTALL_PROGRAM@\nINSTALL_SCRIPT = @INSTALL_SCRIPT@\nINSTALL_STRIP_PROGRAM = @INSTALL_STRIP_PROGRAM@\nJSON_CPPFLAGS = @JSON_CPPFLAGS@\nJSON_LDFLAGS = @JSON_LDFLAGS@\nLD = @LD@\nLDFLAGS = @LDFLAGS@\nLIBCURL = @LIBCURL@\nLIBCURL_CPPFLAGS = @LIBCURL_CPPFLAGS@\nLIBOBJS = @LIBOBJS@\nLIBS = @LIBS@\nLIBTOOL = @LIBTOOL@\nLIB_SLURM = @LIB_SLURM@\nLIB_SLURMDB = @LIB_SLURMDB@\nLIB_SLURMDB_BUILD = @LIB_SLURMDB_BUILD@\nLIB_SLURM_BUILD = @LIB_SLURM_BUILD@\nLIPO = @LIPO@\nLN_S = @LN_S@\nLTLIBOBJS = @LTLIBOBJS@\nLT_SYS_LIBRARY_PATH = @LT_SYS_LIBRARY_PATH@\nLZ4_CPPFLAGS = @LZ4_CPPFLAGS@\nLZ4_LDFLAGS = @LZ4_LDFLAGS@\nLZ4_LIBS = @LZ4_LIBS@\nMAINT = @MAINT@\nMAKEINFO = @MAKEINFO@\nMANIFEST_TOOL = @MANIFEST_TOOL@\nMKDIR_P = @MKDIR_P@\nMUNGE_CPPFLAGS = @MUNGE_CPPFLAGS@\nMUNGE_DIR = @MUNGE_DIR@\nMUNGE_LDFLAGS = @MUNGE_LDFLAGS@\nMUNGE_LIBS = @MUNGE_LIBS@\nMYSQL_CFLAGS = @MYSQL_CFLAGS@\nMYSQL_LIBS = @MYSQL_LIBS@\nNCURSES = @NCURSES@\nNETLOC_CPPFLAGS = @NETLOC_CPPFLAGS@\nNETLOC_LDFLAGS = @NETLOC_LDFLAGS@\nNETLOC_LIBS = @NETLOC_LIBS@\nNM = @NM@\nNMEDIT = @NMEDIT@\nNRT_CPPFLAGS = @NRT_CPPFLAGS@\nNUMA_LIBS = @NUMA_LIBS@\nOBJDUMP = @OBJDUMP@\nOBJEXT = @OBJEXT@\nOFED_CPPFLAGS = @OFED_CPPFLAGS@\nOFED_LDFLAGS = @OFED_LDFLAGS@\nOFED_LIBS = @OFED_LIBS@\nOTOOL = @OTOOL@\nOTOOL64 = @OTOOL64@\nPACKAGE = @PACKAGE@\nPACKAGE_BUGREPORT = @PACKAGE_BUGREPORT@\nPACKAGE_NAME = @PACKAGE_NAME@\nPACKAGE_STRING = @PACKAGE_STRING@\nPACKAGE_TARNAME = @PACKAGE_TARNAME@\nPACKAGE_URL = @PACKAGE_URL@\nPACKAGE_VERSION = @PACKAGE_VERSION@\nPAM_DIR = @PAM_DIR@\nPAM_LIBS = @PAM_LIBS@\nPATH_SEPARATOR = @PATH_SEPARATOR@\nPKG_CONFIG = @PKG_CONFIG@\nPKG_CONFIG_LIBDIR = @PKG_CONFIG_LIBDIR@\nPKG_CONFIG_PATH = @PKG_CONFIG_PATH@\nPMIX_V1_CPPFLAGS = @PMIX_V1_CPPFLAGS@\nPMIX_V1_LDFLAGS = @PMIX_V1_LDFLAGS@\nPMIX_V2_CPPFLAGS = @PMIX_V2_CPPFLAGS@\nPMIX_V2_LDFLAGS = @PMIX_V2_LDFLAGS@\nPROJECT = @PROJECT@\nPTHREAD_CC = @PTHREAD_CC@\nPTHREAD_CFLAGS = @PTHREAD_CFLAGS@\nPTHREAD_LIBS = @PTHREAD_LIBS@\nRANLIB = @RANLIB@\nREADLINE_LIBS = @READLINE_LIBS@\nREAL_BGQ_LOADED = @REAL_BGQ_LOADED@\nRELEASE = @RELEASE@\nRRDTOOL_CPPFLAGS = @RRDTOOL_CPPFLAGS@\nRRDTOOL_LDFLAGS = @RRDTOOL_LDFLAGS@\nRRDTOOL_LIBS = @RRDTOOL_LIBS@\nRUNJOB_LDFLAGS = @RUNJOB_LDFLAGS@\nSED = @SED@\nSET_MAKE = @SET_MAKE@\nSHELL = @SHELL@\nSLEEP_CMD = @SLEEP_CMD@\nSLURMCTLD_PORT = @SLURMCTLD_PORT@\nSLURMCTLD_PORT_COUNT = @SLURMCTLD_PORT_COUNT@\nSLURMDBD_PORT = @SLURMDBD_PORT@\nSLURMD_PORT = @SLURMD_PORT@\nSLURM_API_AGE = @SLURM_API_AGE@\nSLURM_API_CURRENT = @SLURM_API_CURRENT@\nSLURM_API_MAJOR = @SLURM_API_MAJOR@\nSLURM_API_REVISION = @SLURM_API_REVISION@\nSLURM_API_VERSION = @SLURM_API_VERSION@\nSLURM_MAJOR = @SLURM_MAJOR@\nSLURM_MICRO = @SLURM_MICRO@\nSLURM_MINOR = @SLURM_MINOR@\nSLURM_PREFIX = @SLURM_PREFIX@\nSLURM_VERSION_NUMBER = @SLURM_VERSION_NUMBER@\nSLURM_VERSION_STRING = @SLURM_VERSION_STRING@\nSSH2_CPPFLAGS = @SSH2_CPPFLAGS@\nSSH2_LDFLAGS = @SSH2_LDFLAGS@\nSSH2_LIBS = @SSH2_LIBS@\nSSL_CPPFLAGS = @SSL_CPPFLAGS@\nSSL_LDFLAGS = @SSL_LDFLAGS@\nSSL_LIBS = @SSL_LIBS@\nSTRIP = @STRIP@\nSUCMD = @SUCMD@\nSYSTEMD_TASKSMAX_OPTION = @SYSTEMD_TASKSMAX_OPTION@\nUCX_CPPFLAGS = @UCX_CPPFLAGS@\nUCX_LDFLAGS = @UCX_LDFLAGS@\nUCX_LIBS = @UCX_LIBS@\nUTIL_LIBS = @UTIL_LIBS@\nVERSION = @VERSION@\nZLIB_CPPFLAGS = @ZLIB_CPPFLAGS@\nZLIB_LDFLAGS = @ZLIB_LDFLAGS@\nZLIB_LIBS = @ZLIB_LIBS@\n_libcurl_config = @_libcurl_config@\nabs_builddir = @abs_builddir@\nabs_srcdir = @abs_srcdir@\nabs_top_builddir = @abs_top_builddir@\nabs_top_srcdir = @abs_top_srcdir@\nac_ct_AR = @ac_ct_AR@\nac_ct_CC = @ac_ct_CC@\nac_ct_CXX = @ac_ct_CXX@\nac_ct_DUMPBIN = @ac_ct_DUMPBIN@\nac_have_man2html = @ac_have_man2html@\nam__include = @am__include@\nam__leading_dot = @am__leading_dot@\nam__quote = @am__quote@\nam__tar = @am__tar@\nam__untar = @am__untar@\nax_pthread_config = @ax_pthread_config@\nbindir = @bindir@\nbuild = @build@\nbuild_alias = @build_alias@\nbuild_cpu = @build_cpu@\nbuild_os = @build_os@\nbuild_vendor = @build_vendor@\nbuilddir = @builddir@\ndatadir = @datadir@\ndatarootdir = @datarootdir@\ndocdir = @docdir@\ndvidir = @dvidir@\nexec_prefix = @exec_prefix@\nhost = @host@\nhost_alias = @host_alias@\nhost_cpu = @host_cpu@\nhost_os = @host_os@\nhost_vendor = @host_vendor@\nhtmldir = @htmldir@\nincludedir = @includedir@\ninfodir = @infodir@\ninstall_sh = @install_sh@\nlibdir = @libdir@\nlibexecdir = @libexecdir@\nlocaledir = @localedir@\nlocalstatedir = @localstatedir@\nlua_CFLAGS = @lua_CFLAGS@\nlua_LIBS = @lua_LIBS@\nmandir = @mandir@\nmkdir_p = @mkdir_p@\noldincludedir = @oldincludedir@\npdfdir = @pdfdir@\nprefix = @prefix@\nprogram_transform_name = @program_transform_name@\npsdir = @psdir@\nrunstatedir = @runstatedir@\nsbindir = @sbindir@\nsharedstatedir = @sharedstatedir@\nsrcdir = @srcdir@\nsysconfdir = @sysconfdir@\ntarget = @target@\ntarget_alias = @target_alias@\ntarget_cpu = @target_cpu@\ntarget_os = @target_os@\ntarget_vendor = @target_vendor@\ntop_build_prefix = @top_build_prefix@\ntop_builddir = @top_builddir@\ntop_srcdir = @top_srcdir@\nAUTOMAKE_OPTIONS = foreign\nPLUGIN_FLAGS = - -module -avoid-version --export-dynamic\nAM_CPPFLAGS = -I$(top_srcdir) -I$(top_srcdir)/src/common\npkglib_LTLIBRARIES = proctrack_sgi_job.la\nproctrack_sgi_job_la_SOURCES = proctrack_sgi_job.c\nproctrack_sgi_job_la_LDFLAGS = $(PLUGIN_FLAGS) $(OTHER_FLAGS)\nall: all-am\n\n.SUFFIXES:\n.SUFFIXES: .c .lo .o .obj\n$(srcdir)/Makefile.in: @MAINTAINER_MODE_TRUE@ $(srcdir)/Makefile.am  $(am__configure_deps)\n\t@for dep in $?; do \\\n\t  case '$(am__configure_deps)' in \\\n\t    *$$dep*) \\\n\t      ( cd $(top_builddir) && $(MAKE) $(AM_MAKEFLAGS) am--refresh ) \\\n\t        && { if test -f $@; then exit 0; else break; fi; }; \\\n\t      exit 1;; \\\n\t  esac; \\\n\tdone; \\\n\techo ' cd $(top_srcdir) && $(AUTOMAKE) --foreign src/plugins/proctrack/sgi_job/Makefile'; \\\n\t$(am__cd) $(top_srcdir) && \\\n\t  $(AUTOMAKE) --foreign src/plugins/proctrack/sgi_job/Makefile\nMakefile: $(srcdir)/Makefile.in $(top_builddir)/config.status\n\t@case '$?' in \\\n\t  *config.status*) \\\n\t    cd $(top_builddir) && $(MAKE) $(AM_MAKEFLAGS) am--refresh;; \\\n\t  *) \\\n\t    echo ' cd $(top_builddir) && $(SHELL) ./config.status $(subdir)/$@ $(am__depfiles_maybe)'; \\\n\t    cd $(top_builddir) && $(SHELL) ./config.status $(subdir)/$@ $(am__depfiles_maybe);; \\\n\tesac;\n\n$(top_builddir)/config.status: $(top_srcdir)/configure $(CONFIG_STATUS_DEPENDENCIES)\n\tcd $(top_builddir) && $(MAKE) $(AM_MAKEFLAGS) am--refresh\n\n$(top_srcdir)/configure: @MAINTAINER_MODE_TRUE@ $(am__configure_deps)\n\tcd $(top_builddir) && $(MAKE) $(AM_MAKEFLAGS) am--refresh\n$(ACLOCAL_M4): @MAINTAINER_MODE_TRUE@ $(am__aclocal_m4_deps)\n\tcd $(top_builddir) && $(MAKE) $(AM_MAKEFLAGS) am--refresh\n$(am__aclocal_m4_deps):\n\ninstall-pkglibLTLIBRARIES: $(pkglib_LTLIBRARIES)\n\t@$(NORMAL_INSTALL)\n\t@list='$(pkglib_LTLIBRARIES)'; test -n \"$(pkglibdir)\" || list=; \\\n\tlist2=; for p in $$list; do \\\n\t  if test -f $$p; then \\\n\t    list2=\"$$list2 $$p\"; \\\n\t  else :; fi; \\\n\tdone; \\\n\ttest -z \"$$list2\" || { \\\n\t  echo \" $(MKDIR_P) '$(DESTDIR)$(pkglibdir)'\"; \\\n\t  $(MKDIR_P) \"$(DESTDIR)$(pkglibdir)\" || exit 1; \\\n\t  echo \" $(LIBTOOL) $(AM_LIBTOOLFLAGS) $(LIBTOOLFLAGS) --mode=install $(INSTALL) $(INSTALL_STRIP_FLAG) $$list2 '$(DESTDIR)$(pkglibdir)'\"; \\\n\t  $(LIBTOOL) $(AM_LIBTOOLFLAGS) $(LIBTOOLFLAGS) --mode=install $(INSTALL) $(INSTALL_STRIP_FLAG) $$list2 \"$(DESTDIR)$(pkglibdir)\"; \\\n\t}\n\nuninstall-pkglibLTLIBRARIES:\n\t@$(NORMAL_UNINSTALL)\n\t@list='$(pkglib_LTLIBRARIES)'; test -n \"$(pkglibdir)\" || list=; \\\n\tfor p in $$list; do \\\n\t  $(am__strip_dir) \\\n\t  echo \" $(LIBTOOL) $(AM_LIBTOOLFLAGS) $(LIBTOOLFLAGS) --mode=uninstall rm -f '$(DESTDIR)$(pkglibdir)/$$f'\"; \\\n\t  $(LIBTOOL) $(AM_LIBTOOLFLAGS) $(LIBTOOLFLAGS) --mode=uninstall rm -f \"$(DESTDIR)$(pkglibdir)/$$f\"; \\\n\tdone\n\nclean-pkglibLTLIBRARIES:\n\t-test -z \"$(pkglib_LTLIBRARIES)\" || rm -f $(pkglib_LTLIBRARIES)\n\t@list='$(pkglib_LTLIBRARIES)'; \\\n\tlocs=`for p in $$list; do echo $$p; done | \\\n\t      sed 's|^[^/]*$$|.|; s|/[^/]*$$||; s|$$|/so_locations|' | \\\n\t      sort -u`; \\\n\ttest -z \"$$locs\" || { \\\n\t  echo rm -f $${locs}; \\\n\t  rm -f $${locs}; \\\n\t}\n\nproctrack_sgi_job.la: $(proctrack_sgi_job_la_OBJECTS) $(proctrack_sgi_job_la_DEPENDENCIES) $(EXTRA_proctrack_sgi_job_la_DEPENDENCIES) \n\t$(AM_V_CCLD)$(proctrack_sgi_job_la_LINK) -rpath $(pkglibdir) $(proctrack_sgi_job_la_OBJECTS) $(proctrack_sgi_job_la_LIBADD) $(LIBS)\n\nmostlyclean-compile:\n\t-rm -f *.$(OBJEXT)\n\ndistclean-compile:\n\t-rm -f *.tab.c\n\n@AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/proctrack_sgi_job.Plo@am__quote@\n\n.c.o:\n@am__fastdepCC_TRUE@\t$(AM_V_CC)$(COMPILE) -MT $@ -MD -MP -MF $(DEPDIR)/$*.Tpo -c -o $@ $<\n@am__fastdepCC_TRUE@\t$(AM_V_at)$(am__mv) $(DEPDIR)/$*.Tpo $(DEPDIR)/$*.Po\n@AMDEP_TRUE@@am__fastdepCC_FALSE@\t$(AM_V_CC)source='$<' object='$@' libtool=no @AMDEPBACKSLASH@\n@AMDEP_TRUE@@am__fastdepCC_FALSE@\tDEPDIR=$(DEPDIR) $(CCDEPMODE) $(depcomp) @AMDEPBACKSLASH@\n@am__fastdepCC_FALSE@\t$(AM_V_CC@am__nodep@)$(COMPILE) -c -o $@ $<\n\n.c.obj:\n@am__fastdepCC_TRUE@\t$(AM_V_CC)$(COMPILE) -MT $@ -MD -MP -MF $(DEPDIR)/$*.Tpo -c -o $@ `$(CYGPATH_W) '$<'`\n@am__fastdepCC_TRUE@\t$(AM_V_at)$(am__mv) $(DEPDIR)/$*.Tpo $(DEPDIR)/$*.Po\n@AMDEP_TRUE@@am__fastdepCC_FALSE@\t$(AM_V_CC)source='$<' object='$@' libtool=no @AMDEPBACKSLASH@\n@AMDEP_TRUE@@am__fastdepCC_FALSE@\tDEPDIR=$(DEPDIR) $(CCDEPMODE) $(depcomp) @AMDEPBACKSLASH@\n@am__fastdepCC_FALSE@\t$(AM_V_CC@am__nodep@)$(COMPILE) -c -o $@ `$(CYGPATH_W) '$<'`\n\n.c.lo:\n@am__fastdepCC_TRUE@\t$(AM_V_CC)$(LTCOMPILE) -MT $@ -MD -MP -MF $(DEPDIR)/$*.Tpo -c -o $@ $<\n@am__fastdepCC_TRUE@\t$(AM_V_at)$(am__mv) $(DEPDIR)/$*.Tpo $(DEPDIR)/$*.Plo\n@AMDEP_TRUE@@am__fastdepCC_FALSE@\t$(AM_V_CC)source='$<' object='$@' libtool=yes @AMDEPBACKSLASH@\n@AMDEP_TRUE@@am__fastdepCC_FALSE@\tDEPDIR=$(DEPDIR) $(CCDEPMODE) $(depcomp) @AMDEPBACKSLASH@\n@am__fastdepCC_FALSE@\t$(AM_V_CC@am__nodep@)$(LTCOMPILE) -c -o $@ $<\n\nmostlyclean-libtool:\n\t-rm -f *.lo\n\nclean-libtool:\n\t-rm -rf .libs _libs\n\nID: $(am__tagged_files)\n\t$(am__define_uniq_tagged_files); mkid -fID $$unique\ntags: tags-am\nTAGS: tags\n\ntags-am: $(TAGS_DEPENDENCIES) $(am__tagged_files)\n\tset x; \\\n\there=`pwd`; \\\n\t$(am__define_uniq_tagged_files); \\\n\tshift; \\\n\tif test -z \"$(ETAGS_ARGS)$$*$$unique\"; then :; else \\\n\t  test -n \"$$unique\" || unique=$$empty_fix; \\\n\t  if test $$# -gt 0; then \\\n\t    $(ETAGS) $(ETAGSFLAGS) $(AM_ETAGSFLAGS) $(ETAGS_ARGS) \\\n\t      \"$$@\" $$unique; \\\n\t  else \\\n\t    $(ETAGS) $(ETAGSFLAGS) $(AM_ETAGSFLAGS) $(ETAGS_ARGS) \\\n\t      $$unique; \\\n\t  fi; \\\n\tfi\nctags: ctags-am\n\nCTAGS: ctags\nctags-am: $(TAGS_DEPENDENCIES) $(am__tagged_files)\n\t$(am__define_uniq_tagged_files); \\\n\ttest -z \"$(CTAGS_ARGS)$$unique\" \\\n\t  || $(CTAGS) $(CTAGSFLAGS) $(AM_CTAGSFLAGS) $(CTAGS_ARGS) \\\n\t     $$unique\n\nGTAGS:\n\there=`$(am__cd) $(top_builddir) && pwd` \\\n\t  && $(am__cd) $(top_srcdir) \\\n\t  && gtags -i $(GTAGS_ARGS) \"$$here\"\ncscopelist: cscopelist-am\n\ncscopelist-am: $(am__tagged_files)\n\tlist='$(am__tagged_files)'; \\\n\tcase \"$(srcdir)\" in \\\n\t  [\\\\/]* | ?:[\\\\/]*) sdir=\"$(srcdir)\" ;; \\\n\t  *) sdir=$(subdir)/$(srcdir) ;; \\\n\tesac; \\\n\tfor i in $$list; do \\\n\t  if test -f \"$$i\"; then \\\n\t    echo \"$(subdir)/$$i\"; \\\n\t  else \\\n\t    echo \"$$sdir/$$i\"; \\\n\t  fi; \\\n\tdone >> $(top_builddir)/cscope.files\n\ndistclean-tags:\n\t-rm -f TAGS ID GTAGS GRTAGS GSYMS GPATH tags\n\ndistdir: $(DISTFILES)\n\t@srcdirstrip=`echo \"$(srcdir)\" | sed 's/[].[^$$\\\\*]/\\\\\\\\&/g'`; \\\n\ttopsrcdirstrip=`echo \"$(top_srcdir)\" | sed 's/[].[^$$\\\\*]/\\\\\\\\&/g'`; \\\n\tlist='$(DISTFILES)'; \\\n\t  dist_files=`for file in $$list; do echo $$file; done | \\\n\t  sed -e \"s|^$$srcdirstrip/||;t\" \\\n\t      -e \"s|^$$topsrcdirstrip/|$(top_builddir)/|;t\"`; \\\n\tcase $$dist_files in \\\n\t  */*) $(MKDIR_P) `echo \"$$dist_files\" | \\\n\t\t\t   sed '/\\//!d;s|^|$(distdir)/|;s,/[^/]*$$,,' | \\\n\t\t\t   sort -u` ;; \\\n\tesac; \\\n\tfor file in $$dist_files; do \\\n\t  if test -f $$file || test -d $$file; then d=.; else d=$(srcdir); fi; \\\n\t  if test -d $$d/$$file; then \\\n\t    dir=`echo \"/$$file\" | sed -e 's,/[^/]*$$,,'`; \\\n\t    if test -d \"$(distdir)/$$file\"; then \\\n\t      find \"$(distdir)/$$file\" -type d ! -perm -700 -exec chmod u+rwx {} \\;; \\\n\t    fi; \\\n\t    if test -d $(srcdir)/$$file && test $$d != $(srcdir); then \\\n\t      cp -fpR $(srcdir)/$$file \"$(distdir)$$dir\" || exit 1; \\\n\t      find \"$(distdir)/$$file\" -type d ! -perm -700 -exec chmod u+rwx {} \\;; \\\n\t    fi; \\\n\t    cp -fpR $$d/$$file \"$(distdir)$$dir\" || exit 1; \\\n\t  else \\\n\t    test -f \"$(distdir)/$$file\" \\\n\t    || cp -p $$d/$$file \"$(distdir)/$$file\" \\\n\t    || exit 1; \\\n\t  fi; \\\n\tdone\ncheck-am: all-am\ncheck: check-am\nall-am: Makefile $(LTLIBRARIES)\ninstalldirs:\n\tfor dir in \"$(DESTDIR)$(pkglibdir)\"; do \\\n\t  test -z \"$$dir\" || $(MKDIR_P) \"$$dir\"; \\\n\tdone\ninstall: install-am\ninstall-exec: install-exec-am\ninstall-data: install-data-am\nuninstall: uninstall-am\n\ninstall-am: all-am\n\t@$(MAKE) $(AM_MAKEFLAGS) install-exec-am install-data-am\n\ninstallcheck: installcheck-am\ninstall-strip:\n\tif test -z '$(STRIP)'; then \\\n\t  $(MAKE) $(AM_MAKEFLAGS) INSTALL_PROGRAM=\"$(INSTALL_STRIP_PROGRAM)\" \\\n\t    install_sh_PROGRAM=\"$(INSTALL_STRIP_PROGRAM)\" INSTALL_STRIP_FLAG=-s \\\n\t      install; \\\n\telse \\\n\t  $(MAKE) $(AM_MAKEFLAGS) INSTALL_PROGRAM=\"$(INSTALL_STRIP_PROGRAM)\" \\\n\t    install_sh_PROGRAM=\"$(INSTALL_STRIP_PROGRAM)\" INSTALL_STRIP_FLAG=-s \\\n\t    \"INSTALL_PROGRAM_ENV=STRIPPROG='$(STRIP)'\" install; \\\n\tfi\nmostlyclean-generic:\n\nclean-generic:\n\ndistclean-generic:\n\t-test -z \"$(CONFIG_CLEAN_FILES)\" || rm -f $(CONFIG_CLEAN_FILES)\n\t-test . = \"$(srcdir)\" || test -z \"$(CONFIG_CLEAN_VPATH_FILES)\" || rm -f $(CONFIG_CLEAN_VPATH_FILES)\n\nmaintainer-clean-generic:\n\t@echo \"This command is intended for maintainers to use\"\n\t@echo \"it deletes files that may require special tools to rebuild.\"\nclean: clean-am\n\nclean-am: clean-generic clean-libtool clean-pkglibLTLIBRARIES \\\n\tmostlyclean-am\n\ndistclean: distclean-am\n\t-rm -rf ./$(DEPDIR)\n\t-rm -f Makefile\ndistclean-am: clean-am distclean-compile distclean-generic \\\n\tdistclean-tags\n\ndvi: dvi-am\n\ndvi-am:\n\nhtml: html-am\n\nhtml-am:\n\ninfo: info-am\n\ninfo-am:\n\ninstall-data-am:\n\ninstall-dvi: install-dvi-am\n\ninstall-dvi-am:\n\ninstall-exec-am: install-pkglibLTLIBRARIES\n\ninstall-html: install-html-am\n\ninstall-html-am:\n\ninstall-info: install-info-am\n\ninstall-info-am:\n\ninstall-man:\n\ninstall-pdf: install-pdf-am\n\ninstall-pdf-am:\n\ninstall-ps: install-ps-am\n\ninstall-ps-am:\n\ninstallcheck-am:\n\nmaintainer-clean: maintainer-clean-am\n\t-rm -rf ./$(DEPDIR)\n\t-rm -f Makefile\nmaintainer-clean-am: distclean-am maintainer-clean-generic\n\nmostlyclean: mostlyclean-am\n\nmostlyclean-am: mostlyclean-compile mostlyclean-generic \\\n\tmostlyclean-libtool\n\npdf: pdf-am\n\npdf-am:\n\nps: ps-am\n\nps-am:\n\nuninstall-am: uninstall-pkglibLTLIBRARIES\n\n.MAKE: install-am install-strip\n\n.PHONY: CTAGS GTAGS TAGS all all-am check check-am clean clean-generic \\\n\tclean-libtool clean-pkglibLTLIBRARIES cscopelist-am ctags \\\n\tctags-am distclean distclean-compile distclean-generic \\\n\tdistclean-libtool distclean-tags distdir dvi dvi-am html \\\n\thtml-am info info-am install install-am install-data \\\n\tinstall-data-am install-dvi install-dvi-am install-exec \\\n\tinstall-exec-am install-html install-html-am install-info \\\n\tinstall-info-am install-man install-pdf install-pdf-am \\\n\tinstall-pkglibLTLIBRARIES install-ps install-ps-am \\\n\tinstall-strip installcheck installcheck-am installdirs \\\n\tmaintainer-clean maintainer-clean-generic mostlyclean \\\n\tmostlyclean-compile mostlyclean-generic mostlyclean-libtool \\\n\tpdf pdf-am ps ps-am tags tags-am uninstall uninstall-am \\\n\tuninstall-pkglibLTLIBRARIES\n\n.PRECIOUS: Makefile\n\n# Don't need to add -ljob because we dlopen the .so to avoid\n#  symbol collisions with slurm functions\n\n# Tell versions [3.59,3.63) of GNU make to not export all variables.\n# Otherwise a system limit (for SysV at least) may be exceeded.\n.NOEXPORT:\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/src/plugins/proctrack/lua/proctrack_lua.c": "/*****************************************************************************\\\n *  proctrack_lua.c\n *****************************************************************************\n *  Copyright (C) 2009 The Regents of the University of California.\n *  Produced at Lawrence Livermore National Laboratory (cf, DISCLAIMER).\n *  Written by Mark Grondona <mgrondona@llnl.gov>\n *  CODE-OCEC-09-009. All rights reserved.\n *\n *  This file is part of SLURM, a resource management program.\n *  For details, see <https://slurm.schedmd.com/>.\n *  Please also read the included file: DISCLAIMER.\n *\n *  SLURM is free software; you can redistribute it and/or modify it under\n *  the terms of the GNU General Public License as published by the Free\n *  Software Foundation; either version 2 of the License, or (at your option)\n *  any later version.\n *\n *  In addition, as a special exception, the copyright holders give permission\n *  to link the code of portions of this program with the OpenSSL library under\n *  certain conditions as described in each individual source file, and\n *  distribute linked combinations including the two. You must obey the GNU\n *  General Public License in all respects for all of the code used other than\n *  OpenSSL. If you modify file(s) with this exception, you may extend this\n *  exception to your version of the file(s), but you are not obligated to do\n *  so. If you do not wish to do so, delete this exception statement from your\n *  version.  If you delete this exception statement from all source files in\n *  the program, then also delete it here.\n *\n *  SLURM is distributed in the hope that it will be useful, but WITHOUT ANY\n *  WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n *  FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more\n *  details.\n *\n *  You should have received a copy of the GNU General Public License along\n *  with SLURM; if not, write to the Free Software Foundation, Inc.,\n *  51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA.\n\\*****************************************************************************/\n\n#include <dlfcn.h>\n#include <inttypes.h>\n#include <pthread.h>\n#include <signal.h>\n#include <stdlib.h>\n#include <sys/types.h>\n#include <unistd.h>\n\n#include <lua.h>\n#include <lauxlib.h>\n#include <lualib.h>\n\n#include \"slurm/slurm.h\"\n#include \"slurm/slurm_errno.h\"\n\n#include \"src/common/log.h\"\n#include \"src/common/macros.h\"\n#include \"src/common/xlua.h\"\n#include \"src/slurmd/slurmstepd/slurmstepd_job.h\"\n\nconst char plugin_name[]            = \"LUA proctrack module\";\nconst char plugin_type[]            = \"proctrack/lua\";\nconst uint32_t plugin_version       = SLURM_VERSION_NUMBER;\n\nstatic const char lua_script_path[] = DEFAULT_SCRIPT_DIR \"/proctrack.lua\";\nstatic lua_State *L = NULL;\n\n/*\n *  Mutex for protecting multi-threaded access to this plugin.\n *   (Only 1 thread at a time should be in here)\n */\nstatic pthread_mutex_t lua_lock = PTHREAD_MUTEX_INITIALIZER;\n\n/*\n *  Lua interface to SLURM log facility:\n */\nstatic int l_log_msg (lua_State *L)\n{\n\tconst char *prefix  = \"proctrack.lua\";\n\tint        level    = 0;\n\tconst char *msg;\n\n\t/*\n\t *  Optional numeric prefix indicating the log level\n\t *   of the message.\n\t */\n\n\t/*\n\t *  Pop message off the lua stack\n\t */\n\tmsg = lua_tostring (L, -1);\n\tlua_pop (L, 1);\n\t/*\n\t *  Pop level off stack:\n\t */\n\tlevel = (int) lua_tonumber (L, -1);\n\tlua_pop (L, 1);\n\n\t/*\n\t *  Call appropriate slurm log function based on log-level argument\n\t */\n\tif (level > 3)\n\t\tdebug3 (\"%s: %s\", prefix, msg);\n\telse if (level == 3)\n\t\tdebug2 (\"%s: %s\", prefix, msg);\n\telse if (level == 2)\n\t\tdebug (\"%s: %s\", prefix, msg);\n\telse if (level == 1)\n\t\tverbose (\"%s: %s\", prefix, msg);\n\telse if (level == 0)\n\t\tinfo (\"%s: %s\", prefix, msg);\n\treturn (0);\n}\n\nstatic int l_log_error (lua_State *L)\n{\n\tconst char *prefix  = \"proctrack.lua\";\n\tconst char *msg     = lua_tostring (L, -1);\n\terror (\"%s: %s\", prefix, msg);\n\treturn (0);\n}\n\nstatic const struct luaL_Reg slurm_functions [] = {\n\t{ \"log\",   l_log_msg   },\n\t{ \"error\", l_log_error },\n\t{ NULL,    NULL        }\n};\n\nstatic void _lua_table_register(lua_State *L, const char *libname,\n\t\t\t\tconst luaL_Reg *l)\n{\n#if LUA_VERSION_NUM == 501\n\tluaL_register(L, NULL, l);\n#else\n\tluaL_setfuncs(L, l, 0);\n\tif (libname)\n\t\tlua_setglobal(L, libname);\n#endif\n}\n\nstatic int lua_register_slurm_output_functions (void)\n{\n\tchar *unpack_str;\n\tchar tmp_string[100];\n\n#if LUA_VERSION_NUM == 501\n\tunpack_str = \"unpack\";\n#else\n\tunpack_str = \"table.unpack\";\n#endif\n\t/*\n\t *  Register slurm output functions in a global \"slurm\" table\n\t */\n\tlua_newtable (L);\n\t_lua_table_register(L, NULL, slurm_functions);\n\n\t/*\n\t *  Create more user-friendly lua versions of SLURM log functions.\n\t */\n\tsnprintf(tmp_string, sizeof(tmp_string),\n\t\t \"slurm.error (string.format(%s({...})))\",\n\t\t unpack_str);\n\tluaL_loadstring (L, tmp_string);\n\tlua_setfield (L, -2, \"log_error\");\n\tsnprintf(tmp_string, sizeof(tmp_string),\n\t\t \"slurm.log (0, string.format(%s({...})))\",\n\t\t unpack_str);\n\tluaL_loadstring (L, tmp_string);\n\tlua_setfield (L, -2, \"log_info\");\n\tsnprintf(tmp_string, sizeof(tmp_string),\n\t\t \"slurm.log (1, string.format(%s({...})))\",\n\t\t unpack_str);\n\tluaL_loadstring (L, tmp_string);\n\tlua_setfield (L, -2, \"log_verbose\");\n\tsnprintf(tmp_string, sizeof(tmp_string),\n\t\t \"slurm.log (2, string.format(%s({...})))\",\n\t\t unpack_str);\n\tluaL_loadstring (L, tmp_string);\n\tlua_setfield (L, -2, \"log_debug\");\n\tsnprintf(tmp_string, sizeof(tmp_string),\n\t\t \"slurm.log (3, string.format(%s({...})))\",\n\t\t unpack_str);\n\tluaL_loadstring (L, tmp_string);\n\tlua_setfield (L, -2, \"log_debug2\");\n\tsnprintf(tmp_string, sizeof(tmp_string),\n\t\t \"slurm.log (4, string.format(%s({...})))\",\n\t\t unpack_str);\n\n\t/*\n\t * slurm.SUCCESS, slurm.FAILURE and slurm.ERROR\n\t */\n\tlua_pushnumber (L, SLURM_FAILURE);\n\tlua_setfield (L, -2, \"FAILURE\");\n\tlua_pushnumber (L, SLURM_ERROR);\n\tlua_setfield (L, -2, \"ERROR\");\n\tlua_pushnumber (L, SLURM_SUCCESS);\n\tlua_setfield (L, -2, \"SUCCESS\");\n\n\tlua_setglobal (L, \"slurm\");\n\treturn 0;\n}\n\n/*\n *  check that global symbol [name] in lua script is a function\n */\nstatic int check_lua_script_function (const char *name)\n{\n\tint rc = 0;\n\tlua_getglobal (L, name);\n\tif (!lua_isfunction (L, -1))\n\t\trc = -1;\n\tlua_pop (L, -1);\n\treturn (rc);\n}\n\n/*\n *   Verify all required fuctions are defined in the proctrack/lua script\n */\nstatic int check_lua_script_functions (void)\n{\n\tint rc = 0;\n\tint i;\n\tconst char *fns[] = {\n\t\t\"proctrack_g_create\",\n\t\t\"proctrack_g_add\",\n\t\t\"proctrack_g_signal\",\n\t\t\"proctrack_g_destroy\",\n\t\t\"proctrack_g_find\",\n\t\t\"proctrack_g_has_pid\",\n\t\t\"proctrack_g_wait\",\n\t\t\"proctrack_g_get_pids\",\n\t\tNULL\n\t};\n\n\ti = 0;\n\tdo {\n\t\tif (check_lua_script_function (fns[i]) < 0) {\n\t\t\terror (\"proctrack/lua: %s: missing required function %s\",\n\t\t\t       lua_script_path, fns[i]);\n\t\t\trc = -1;\n\t\t}\n\t} while (fns[++i]);\n\n\treturn (rc);\n}\n\n/*\n *  NOTE: The init callback should never be called multiple times,\n *   let alone called from multiple threads. Therefore, locking\n *   is unecessary here.\n */\nint init (void)\n{\n\tint rc = SLURM_SUCCESS;\n\n\t/*\n\t * Need to dlopen() the Lua library to ensure plugins see\n\t * appropriate symptoms\n\t */\n\tif ((rc = xlua_dlopen()) != SLURM_SUCCESS)\n\t\treturn rc;\n\n\t/*\n\t *  Initilize lua\n\t */\n\tL = luaL_newstate ();\n\tluaL_openlibs (L);\n\tif (luaL_loadfile (L, lua_script_path))\n\t\treturn error (\"lua: %s: %s\", lua_script_path,\n\t\t\t      lua_tostring (L, -1));\n\n\t/*\n\t *  Register slurm.log and slurm.error functions in lua state:\n\t */\n\tlua_register_slurm_output_functions ();\n\n\t/*\n\t *  Run the user script:\n\t */\n\tif (lua_pcall (L, 0, 1, 0) != 0)\n\t\treturn error (\"proctrack/lua: %s: %s\",\n\t\t\t      lua_script_path, lua_tostring (L, -1));\n\n\t/*\n\t *  Get any return code from the lua script\n\t */\n\trc = (int) lua_tonumber (L, -1);\n\tlua_pop (L, 1);\n\tif (rc != SLURM_SUCCESS)\n\t\treturn rc;\n\n\t/*\n\t *  Check for required lua script functions:\n\t */\n\treturn (check_lua_script_functions ());\n}\n\nint fini (void)\n{\n\tlua_close (L);\n\treturn SLURM_SUCCESS;\n}\n\n\n/*\n *  Create lua 'job' table and leave it on the (lua) stack.\n */\nstatic int lua_job_table_create (stepd_step_rec_t *job)\n{\n\tlua_newtable (L);\n\n\tlua_pushnumber (L, job->jobid);\n\tlua_setfield (L, -2, \"jobid\");\n\tlua_pushnumber (L, job->stepid);\n\tlua_setfield (L, -2, \"stepid\");\n\tlua_pushnumber (L, job->nodeid);\n\tlua_setfield (L, -2, \"nodeid\");\n\tlua_pushnumber (L, job->node_tasks);\n\tlua_setfield (L, -2, \"node_tasks\");\n\tlua_pushnumber (L, job->ntasks);\n\tlua_setfield (L, -2, \"ntasks\");\n\tlua_pushnumber (L, job->cpus_per_task);\n\tlua_setfield (L, -2, \"cpus_per_task\");\n\tlua_pushnumber (L, job->nnodes);\n\tlua_setfield (L, -2, \"nnodes\");\n\tlua_pushnumber (L, job->uid);\n\tlua_setfield (L, -2, \"uid\");\n\tlua_pushnumber (L, job->gid);\n\tlua_setfield (L, -2, \"gid\");\n\tlua_pushnumber (L, job->pgid);\n\tlua_setfield (L, -2, \"pgid\");\n\tlua_pushnumber (L, job->jmgr_pid);\n\tlua_setfield (L, -2, \"jmgr_pid\");\n\tlua_pushnumber (L, job->job_mem);\n\tlua_setfield (L, -2, \"mem\");\n\n\tlua_pushstring (L, job->job_alloc_cores ? job->job_alloc_cores : \"\");\n\tlua_setfield (L, -2, \"JobCPUs\");\n\tlua_pushstring (L, job->step_alloc_cores ? job->step_alloc_cores : \"\");\n\tlua_setfield (L, -2, \"StepCPUs\");\n\tlua_pushstring (L, job->cwd ? job->cwd : \"\");\n\tlua_setfield (L, -2, \"cwd\");\n\n\treturn (0);\n}\n\nint proctrack_p_create (stepd_step_rec_t *job)\n{\n\tint rc = SLURM_ERROR;\n\tdouble id;\n\n\tslurm_mutex_lock (&lua_lock);\n\n\t/*\n\t *  All lua script functions should have been verified during\n\t *   initialization:\n\t */\n\tlua_getglobal (L, \"proctrack_g_create\");\n\tif (lua_isnil (L, -1))\n\t\tgoto out;\n\n\tlua_job_table_create (job);\n\tif (lua_pcall (L, 1, 1, 0) != 0) {\n\t\terror (\"proctrack/lua: %s: proctrack_p_create: %s\",\n\t\t       lua_script_path, lua_tostring (L, -1));\n\t\tgoto out;\n\t}\n\n\t/*\n\t *  Get the container id off the stack:\n\t */\n\tif (lua_isnil (L, -1)) {\n\t\terror (\"proctrack/lua: \"\n\t\t       \"proctrack_p_create did not return id\");\n\t\tlua_pop (L, -1);\n\t\tgoto out;\n\t}\n\n\tid = lua_tonumber (L, -1);\n\tjob->cont_id = (uint64_t) id;\n\tinfo (\"job->cont_id = %\"PRIu64\" (%.0f)\", job->cont_id, id);\n\tlua_pop (L, -1);\n\n\trc = SLURM_SUCCESS;\nout:\n\tslurm_mutex_unlock (&lua_lock);\n\treturn rc;\n}\n\nint proctrack_p_add (stepd_step_rec_t *job, pid_t pid)\n{\n\tint rc = SLURM_ERROR;\n\n\tslurm_mutex_lock (&lua_lock);\n\n\tlua_getglobal (L, \"proctrack_g_add\");\n\tif (lua_isnil (L, -1))\n\t\tgoto out;\n\n\tlua_job_table_create (job);\n\tlua_pushnumber (L, job->cont_id);\n\tlua_pushnumber (L, pid);\n\n\tif (lua_pcall (L, 3, 1, 0) != 0) {\n\t\terror (\"running lua function \"\n\t\t       \"'proctrack_p_add': %s\",\n\t\t       lua_tostring (L, -1));\n\t\tgoto out;\n\t}\n\n\trc = lua_tonumber (L, -1);\n\tlua_pop (L, -1);\nout:\n\tslurm_mutex_unlock (&lua_lock);\n\treturn (rc);\n}\n\nint proctrack_p_signal (uint64_t id, int sig)\n{\n\tint rc = SLURM_ERROR;\n\n\tslurm_mutex_lock (&lua_lock);\n\n\tlua_getglobal (L, \"proctrack_g_signal\");\n\tif (lua_isnil (L, -1))\n\t\tgoto out;\n\n\tlua_pushnumber (L, id);\n\tlua_pushnumber (L, sig);\n\n\tif (lua_pcall (L, 2, 1, 0) != 0) {\n\t\terror (\"running lua function \"\n\t\t       \"'proctrack_p_signal': %s\",\n\t\t       lua_tostring (L, -1));\n\t\tgoto out;\n\t}\n\n\trc = lua_tonumber (L, -1);\n\tlua_pop (L, -1);\nout:\n\tslurm_mutex_unlock (&lua_lock);\n\treturn (rc);\n}\n\nint proctrack_p_destroy (uint64_t id)\n{\n\tint rc = SLURM_ERROR;\n\n\tslurm_mutex_lock (&lua_lock);\n\n\tlua_getglobal (L, \"proctrack_g_destroy\");\n\tif (lua_isnil (L, -1))\n\t\tgoto out;\n\n\tlua_pushnumber (L, id);\n\n\tif (lua_pcall (L, 1, 1, 0) != 0) {\n\t\terror (\"running lua function \"\n\t\t       \"'proctrack_p_destroy': %s\",\n\t\t       lua_tostring (L, -1));\n\t\tgoto out;\n\t}\n\n\trc = lua_tonumber (L, -1);\n\tlua_pop (L, -1);\n\nout:\n\tslurm_mutex_unlock (&lua_lock);\n\treturn (rc);\n}\n\nuint64_t proctrack_p_find (pid_t pid)\n{\n\tuint64_t id = (uint64_t) SLURM_ERROR;\n\n\tslurm_mutex_lock (&lua_lock);\n\n\tlua_getglobal (L, \"proctrack_g_find\");\n\tif (lua_isnil (L, -1))\n\t\tgoto out;\n\n\tlua_pushnumber (L, pid);\n\n\tif (lua_pcall (L, 1, 1, 0) != 0) {\n\t\terror (\"running lua function 'proctrack_p_find': %s\",\n\t\t       lua_tostring (L, -1));\n\t\tgoto out;\n\t}\n\n\tid = (uint64_t) lua_tonumber (L, -1);\n\tlua_pop (L, -1);\n\nout:\n\tslurm_mutex_unlock (&lua_lock);\n\treturn (id);\n}\n\nbool proctrack_p_has_pid (uint64_t id, pid_t pid)\n{\n\tint rc = 0;\n\n\tslurm_mutex_lock (&lua_lock);\n\n\tlua_getglobal (L, \"proctrack_g_has_pid\");\n\tif (lua_isnil (L, -1))\n\t\tgoto out;\n\n\tlua_pushnumber (L, id);\n\tlua_pushnumber (L, pid);\n\n\tif (lua_pcall (L, 2, 1, 0) != 0) {\n\t\terror (\"running lua function \"\n\t\t       \"'proctrack_p_has_pid': %s\",\n\t\t       lua_tostring (L, -1));\n\t\tgoto out;\n\t}\n\n\trc = lua_toboolean (L, -1);\n\tlua_pop (L, -1);\n\nout:\n\tslurm_mutex_unlock (&lua_lock);\n\treturn (rc == 1);\n}\n\nint proctrack_p_wait (uint64_t id)\n{\n\tint rc = SLURM_ERROR;\n\n\tslurm_mutex_lock (&lua_lock);\n\n\tlua_getglobal (L, \"proctrack_g_wait\");\n\tif (lua_isnil (L, -1))\n\t\tgoto out;\n\n\tlua_pushnumber (L, id);\n\n\tif (lua_pcall (L, 1, 1, 0) != 0) {\n\t\terror (\"running lua function 'proctrack_p_wait': %s\",\n\t\t       lua_tostring (L, -1));\n\t\tgoto out;\n\t}\n\n\trc = lua_tonumber (L, -1);\n\tlua_pop (L, -1);\nout:\n\tslurm_mutex_unlock (&lua_lock);\n\treturn (rc);\n}\n\nint proctrack_p_get_pids (uint64_t cont_id, pid_t **pids, int *npids)\n{\n\tint rc = SLURM_ERROR;\n\tint i = 0;\n\tint t = 0;\n\tpid_t *p;\n\n\t*npids = 0;\n\n\tslurm_mutex_lock (&lua_lock);\n\n\tlua_getglobal (L, \"proctrack_g_get_pids\");\n\tif (lua_isnil (L, -1))\n\t\tgoto out;\n\n\tlua_pushnumber (L, cont_id);\n\n\tif (lua_pcall (L, 1, 1, 0) != 0) {\n\t\terror (\"%s: %s: %s\",\n\t\t       \"proctrack/lua\",\n\t\t       __func__,\n\t\t       lua_tostring (L, -1));\n\t\tgoto out;\n\t}\n\n\t/*\n\t *   list of PIDs should be returned in a table from the lua\n\t *    script. If a table wasn't returned then generate an error:\n\t */\n\tif (!lua_istable(L, -1)) {\n\t\terror (\"%s: %s: function should return a table\",\n\t\t       \"proctrack/lua\",\n\t\t       __func__);\n\t\tgoto out;\n\t}\n\n\t/*\n\t *  Save absolute position of table in lua stack\n\t */\n\tt = lua_gettop (L);\n\n\t/*\n\t *  Get table size and create array for slurm\n\t */\n#if LUA_VERSION_NUM == 501\n\t*npids = lua_objlen (L, t);\n#else\n\t*npids = lua_rawlen(L, t);\n#endif\n\n\tp = (pid_t *) xmalloc (*npids * sizeof (pid_t));\n\n\t/*\n\t *  Traverse table/array at position t on the stack:\n\t */\n\tlua_pushnil (L);\n\twhile (lua_next (L, t)) {\n\t\tp [i++] = lua_tonumber (L, -1);\n\t\t/*\n\t\t *  pop value off stack, leave key for lua_next()\n\t\t */\n\t\tlua_pop (L, 1);\n\t}\n\tlua_pop (L, 1);\n\n\t*pids = p;\n\n\trc = SLURM_SUCCESS;\nout:\n\tslurm_mutex_unlock (&lua_lock);\n\treturn rc;\n}\n\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/src/slurmctld/controller.c": "/*****************************************************************************\\\n *  controller.c - main control machine daemon for slurm\n *****************************************************************************\n *  Copyright (C) 2002-2007 The Regents of the University of California.\n *  Copyright (C) 2008-2010 Lawrence Livermore National Security.\n *  Portions Copyright (C) 2010-2016 SchedMD LLC.\n *  Produced at Lawrence Livermore National Laboratory (cf, DISCLAIMER).\n *  Written by Morris Jette <jette1@llnl.gov>, Kevin Tew <tew1@llnl.gov>\n *  CODE-OCEC-09-009. All rights reserved.\n *\n *  This file is part of SLURM, a resource management program.\n *  For details, see <https://slurm.schedmd.com/>.\n *  Please also read the included file: DISCLAIMER.\n *\n *  SLURM is free software; you can redistribute it and/or modify it under\n *  the terms of the GNU General Public License as published by the Free\n *  Software Foundation; either version 2 of the License, or (at your option)\n *  any later version.\n *\n *  In addition, as a special exception, the copyright holders give permission\n *  to link the code of portions of this program with the OpenSSL library under\n *  certain conditions as described in each individual source file, and\n *  distribute linked combinations including the two. You must obey the GNU\n *  General Public License in all respects for all of the code used other than\n *  OpenSSL. If you modify file(s) with this exception, you may extend this\n *  exception to your version of the file(s), but you are not obligated to do\n *  so. If you do not wish to do so, delete this exception statement from your\n *  version.  If you delete this exception statement from all source files in\n *  the program, then also delete it here.\n *\n *  SLURM is distributed in the hope that it will be useful, but WITHOUT ANY\n *  WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n *  FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more\n *  details.\n *\n *  You should have received a copy of the GNU General Public License along\n *  with SLURM; if not, write to the Free Software Foundation, Inc.,\n *  51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA.\n\\*****************************************************************************/\n\n#include \"config.h\"\n\n#if HAVE_SYS_PRCTL_H\n#  include <sys/prctl.h>\n#endif\n\n#include <errno.h>\n#include <grp.h>\n#include <pthread.h>\n#include <signal.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <sys/resource.h>\n#include <sys/stat.h>\n#include <unistd.h>\n\n#include \"slurm/slurm_errno.h\"\n\n#include \"src/common/assoc_mgr.h\"\n#include \"src/common/checkpoint.h\"\n#include \"src/common/daemonize.h\"\n#include \"src/common/fd.h\"\n#include \"src/common/gres.h\"\n#include \"src/common/group_cache.h\"\n#include \"src/common/hostlist.h\"\n#include \"src/common/layouts_mgr.h\"\n#include \"src/common/log.h\"\n#include \"src/common/macros.h\"\n#include \"src/common/node_features.h\"\n#include \"src/common/node_select.h\"\n#include \"src/common/pack.h\"\n#include \"src/common/power.h\"\n#include \"src/common/proc_args.h\"\n#include \"src/common/read_config.h\"\n#include \"src/common/slurm_acct_gather_profile.h\"\n#include \"src/common/slurm_accounting_storage.h\"\n#include \"src/common/slurm_auth.h\"\n#include \"src/common/slurm_ext_sensors.h\"\n#include \"src/common/slurm_jobacct_gather.h\"\n#include \"src/common/slurm_jobcomp.h\"\n#include \"src/common/slurm_mcs.h\"\n#include \"src/common/slurm_priority.h\"\n#include \"src/common/slurm_protocol_api.h\"\n#include \"src/common/slurm_protocol_interface.h\"\n#include \"src/common/slurm_route.h\"\n#include \"src/common/slurm_topology.h\"\n#include \"src/common/switch.h\"\n#include \"src/common/timers.h\"\n#include \"src/common/uid.h\"\n#include \"src/common/xsignal.h\"\n#include \"src/common/xstring.h\"\n\n#include \"src/slurmctld/acct_policy.h\"\n#include \"src/slurmctld/agent.h\"\n#include \"src/slurmctld/burst_buffer.h\"\n#include \"src/slurmctld/fed_mgr.h\"\n#include \"src/slurmctld/front_end.h\"\n#include \"src/slurmctld/gang.h\"\n#include \"src/slurmctld/heartbeat.h\"\n#include \"src/slurmctld/job_scheduler.h\"\n#include \"src/slurmctld/job_submit.h\"\n#include \"src/slurmctld/licenses.h\"\n#include \"src/slurmctld/locks.h\"\n#include \"src/slurmctld/ping_nodes.h\"\n#include \"src/slurmctld/port_mgr.h\"\n#include \"src/slurmctld/power_save.h\"\n#include \"src/slurmctld/powercapping.h\"\n#include \"src/slurmctld/preempt.h\"\n#include \"src/slurmctld/proc_req.h\"\n#include \"src/slurmctld/read_config.h\"\n#include \"src/slurmctld/reservation.h\"\n#include \"src/slurmctld/sched_plugin.h\"\n#include \"src/slurmctld/slurmctld.h\"\n#include \"src/slurmctld/slurmctld_plugstack.h\"\n#include \"src/slurmctld/srun_comm.h\"\n#include \"src/slurmctld/state_save.h\"\n#include \"src/slurmctld/trigger_mgr.h\"\n\n\n#define DEFAULT_DAEMONIZE 1\t/* Run as daemon by default if set */\n#define DEFAULT_RECOVER   1\t/* Default state recovery on restart\n\t\t\t\t * 0 = use no saved state information\n\t\t\t\t * 1 = recover saved job state,\n\t\t\t\t *     node DOWN/DRAIN state & reason information\n\t\t\t\t * 2 = recover state saved from last shutdown */\n#define MIN_CHECKIN_TIME  3\t/* Nodes have this number of seconds to\n\t\t\t\t * check-in before we ping them */\n#define SHUTDOWN_WAIT     2\t/* Time to wait for backup server shutdown */\n#define JOB_COUNT_INTERVAL 30   /* Time to update running job count */\n\n/**************************************************************************\\\n * To test for memory leaks, set MEMORY_LEAK_DEBUG to 1 using\n * \"configure --enable-memory-leak-debug\" then execute\n *\n * $ valgrind --tool=memcheck --leak-check=yes --num-callers=40 \\\n *   --leak-resolution=high ./slurmctld -Dc >valg.ctld.out 2>&1\n *\n * Then exercise the slurmctld functionality before executing\n * > scontrol shutdown\n *\n * Note that --enable-memory-leak-debug will cause the daemon to\n * unload the shared objects at exit thus preventing valgrind\n * to display the stack where the eventual leaks may be.\n * It is always best to test with and without --enable-memory-leak-debug.\n *\n * The OpenSSL code produces a bunch of errors related to use of\n *    non-initialized memory use.\n * The _keyvalue_regex_init() function will generate two blocks \"definitely\n *    lost\", both of size zero. We haven't bothered to address this.\n * On some systems dlopen() will generate a small number of \"definitely\n *    lost\" blocks that are not cleared by dlclose().\n * On some systems, pthread_create() will generated a small number of\n *    \"possibly lost\" blocks.\n * Otherwise the report should be free of errors. Remember to reset\n *    MEMORY_LEAK_DEBUG to 0 for production use (non-seamless backup\n *    controller use).\n\\**************************************************************************/\n\n/* Log to stderr and syslog until becomes a daemon */\nlog_options_t log_opts = LOG_OPTS_INITIALIZER;\n/* Scheduler Log options */\nlog_options_t sched_log_opts = SCHEDLOG_OPTS_INITIALIZER;\n\n/* Global variables */\nint\taccounting_enforce = 0;\nint\tassociation_based_accounting = 0;\nvoid *\tacct_db_conn = NULL;\nint\tbatch_sched_delay = 3;\nint\tbg_recover = DEFAULT_RECOVER;\nuint32_t cluster_cpus = 0;\ntime_t\tlast_proc_req_start = 0;\nbool\tping_nodes_now = false;\npthread_cond_t purge_thread_cond = PTHREAD_COND_INITIALIZER;\nint\tsched_interval = 60;\nslurmctld_config_t slurmctld_config;\ndiag_stats_t slurmctld_diag_stats;\nint\tslurmctld_primary = 1;\nbool\twant_nodes_reboot = true;\nint   slurmctld_tres_cnt = 0;\nslurmdb_cluster_rec_t *response_cluster_rec = NULL;\nint     slurmctld_running_job_count    = 0;\ntime_t  slurmctld_running_job_count_ts = 0;\n\n/* Local variables */\nstatic pthread_t assoc_cache_thread = (pthread_t) 0;\nstatic int\tdaemonize = DEFAULT_DAEMONIZE;\nstatic int\tdebug_level = 0;\nstatic char *\tdebug_logfile = NULL;\nstatic bool\tdump_core = false;\nstatic int      job_sched_cnt = 0;\nstatic uint32_t max_server_threads = MAX_SERVER_THREADS;\nstatic time_t\tnext_stats_reset = 0;\nstatic int\tnew_nice = 0;\nstatic char\tnode_name_short[MAX_SLURM_NAME];\nstatic char\tnode_name_long[MAX_SLURM_NAME];\nstatic pthread_mutex_t purge_thread_lock = PTHREAD_MUTEX_INITIALIZER;\nstatic int\trecover   = DEFAULT_RECOVER;\nstatic pthread_mutex_t sched_cnt_mutex = PTHREAD_MUTEX_INITIALIZER;\nstatic pthread_cond_t server_thread_cond = PTHREAD_COND_INITIALIZER;\nstatic pid_t\tslurmctld_pid;\nstatic char *\tslurm_conf_filename;\n\n/*\n * Static list of signals to block in this process\n * *Must be zero-terminated*\n */\nstatic int controller_sigarray[] = {\n\tSIGINT,  SIGTERM, SIGCHLD, SIGUSR1,\n\tSIGUSR2, SIGTSTP, SIGXCPU, SIGQUIT,\n\tSIGPIPE, SIGALRM, SIGABRT, SIGHUP, 0\n};\n\nstatic int          _accounting_cluster_ready();\nstatic int          _accounting_mark_all_nodes_down(char *reason);\nstatic void *       _assoc_cache_mgr(void *no_data);\nstatic void         _become_slurm_user(void);\nstatic void         _default_sigaction(int sig);\nstatic void         _get_fed_updates();\nstatic void         _init_config(void);\nstatic void         _init_pidfile(void);\nstatic void         _kill_old_slurmctld(void);\nstatic void         _parse_commandline(int argc, char **argv);\ninline static int   _ping_backup_controller(void);\nstatic void         _remove_assoc(slurmdb_assoc_rec_t *rec);\nstatic void         _remove_qos(slurmdb_qos_rec_t *rec);\nstatic void         _update_assoc(slurmdb_assoc_rec_t *rec);\nstatic void         _update_qos(slurmdb_qos_rec_t *rec);\nstatic int          _init_tres(void);\nstatic void         _update_cluster_tres(void);\n\ninline static int   _report_locks_set(void);\nstatic int          _running_jobs_count();\nstatic void *       _service_connection(void *arg);\nstatic void         _set_work_dir(void);\nstatic int          _shutdown_backup_controller(int wait_time);\nstatic void *       _slurmctld_background(void *no_data);\nstatic void *       _slurmctld_rpc_mgr(void *no_data);\nstatic void *       _slurmctld_signal_hand(void *no_data);\nstatic void         _test_thread_limit(void);\ninline static void  _update_cred_key(void);\nstatic bool\t    _verify_clustername(void);\nstatic void\t    _create_clustername_file(void);\nstatic void *       _purge_files_thread(void *no_data);\nstatic void         _update_nice(void);\ninline static void  _usage(char *prog_name);\nstatic bool         _valid_controller(void);\nstatic bool         _wait_for_server_thread(void);\n\n/* main - slurmctld main function, start various threads and process RPCs */\nint main(int argc, char **argv)\n{\n\tint cnt, error_code, i;\n\tstruct stat stat_buf;\n\tstruct rlimit rlim;\n\t/* Locks: Write configuration, job, node, and partition */\n\tslurmctld_lock_t config_write_lock = {\n\t\tWRITE_LOCK, WRITE_LOCK, WRITE_LOCK, WRITE_LOCK, NO_LOCK };\n\t/* Locks: Write node and partition */\n\tslurmctld_lock_t node_part_write_lock = {\n\t\tNO_LOCK, NO_LOCK, WRITE_LOCK, WRITE_LOCK, NO_LOCK };\n\n\tslurm_trigger_callbacks_t callbacks;\n\tbool create_clustername_file;\n\t/*\n\t * Make sure we have no extra open files which\n\t * would be propagated to spawned tasks.\n\t */\n\tcnt = sysconf(_SC_OPEN_MAX);\n\tfor (i = 3; i < cnt; i++)\n\t\tclose(i);\n\n\t/*\n\t * Establish initial configuration\n\t */\n\t_init_config();\n\tslurm_conf_init(NULL);\n\tlog_init(argv[0], log_opts, LOG_DAEMON, NULL);\n\tsched_log_init(argv[0], sched_log_opts, LOG_DAEMON, NULL);\n\tslurmctld_pid = getpid();\n\t_parse_commandline(argc, argv);\n\tinit_locks();\n\tslurm_conf_reinit(slurm_conf_filename);\n\n\tupdate_logging();\n\n\t/* Verify clustername from conf matches value in spool dir\n\t * exit if inconsistent to protect state files from corruption.\n\t * This needs to be done before we kill the old one just in case we\n\t * fail. */\n\tcreate_clustername_file = _verify_clustername();\n\n\t_update_nice();\n\t_kill_old_slurmctld();\n\n\tfor (i = 0; i < 3; i++)\n\t\tfd_set_close_on_exec(i);\n\n\tif (daemonize) {\n\t\tslurmctld_config.daemonize = 1;\n\t\tif (xdaemon())\n\t\t\terror(\"daemon(): %m\");\n\t\tlog_set_timefmt(slurmctld_conf.log_fmt);\n\t\tlog_alter(log_opts, LOG_DAEMON,\n\t\t\t  slurmctld_conf.slurmctld_logfile);\n\t\tsched_log_alter(sched_log_opts, LOG_DAEMON,\n\t\t\t\tslurmctld_conf.sched_logfile);\n\t\tdebug(\"sched: slurmctld starting\");\n\t} else {\n\t\tslurmctld_config.daemonize = 0;\n\t}\n\n\t/*\n\t * Need to create pidfile here in case we setuid() below\n\t * (init_pidfile() exits if it can't initialize pid file).\n\t * On Linux we also need to make this setuid job explicitly\n\t * able to write a core dump.\n\t */\n\t_init_pidfile();\n\t_become_slurm_user();\n\n\t/*\n\t * Create StateSaveLocation directory if necessary.\n\t */\n\tset_slurmctld_state_loc();\n\n\tif (create_clustername_file)\n\t\t_create_clustername_file();\n\n\tif (daemonize)\n\t\t_set_work_dir();\n\n\tif (stat(slurmctld_conf.mail_prog, &stat_buf) != 0)\n\t\terror(\"Configured MailProg is invalid\");\n\n\tif (!xstrcmp(slurmctld_conf.accounting_storage_type,\n\t\t     \"accounting_storage/none\")) {\n\t\tif (xstrcmp(slurmctld_conf.job_acct_gather_type,\n\t\t\t    \"jobacct_gather/none\"))\n\t\t\terror(\"Job accounting information gathered, \"\n\t\t\t      \"but not stored\");\n\t} else {\n\t\tif (!xstrcmp(slurmctld_conf.job_acct_gather_type,\n\t\t\t     \"jobacct_gather/none\"))\n\t\t\tinfo(\"Job accounting information stored, \"\n\t\t\t     \"but details not gathered\");\n\t}\n\n\tif (slurmctld_conf.chos_loc)\n\t\terror(\"Support for the ChosLoc configuration parameter will end in Slurm version 18.08\");\n\n\tif (license_init(slurmctld_conf.licenses) != SLURM_SUCCESS)\n\t\tfatal(\"Invalid Licenses value: %s\", slurmctld_conf.licenses);\n\n#ifdef PR_SET_DUMPABLE\n\tif (prctl(PR_SET_DUMPABLE, 1) < 0)\n\t\tdebug (\"Unable to set dumpable to 1\");\n#endif /* PR_SET_DUMPABLE */\n\n\t/* Warn if the stack size is not unlimited */\n\tif ((getrlimit(RLIMIT_STACK, &rlim) == 0) &&\n\t    (rlim.rlim_cur != RLIM_INFINITY))\n\t\tinfo(\"Stack size set to %ld\", rlim.rlim_max);\n\n\ttest_core_limit();\n\t_test_thread_limit();\n\n\t/* This must happen before we spawn any threads\n\t * which are not designed to handle them */\n\tif (xsignal_block(controller_sigarray) < 0)\n\t\terror(\"Unable to block signals\");\n\n\tassociation_based_accounting =\n\t\tslurm_get_is_association_based_accounting();\n\taccounting_enforce = slurmctld_conf.accounting_storage_enforce;\n\tif (!xstrcasecmp(slurmctld_conf.accounting_storage_type,\n\t\t\t \"accounting_storage/slurmdbd\")) {\n\t\twith_slurmdbd = 1;\n\t\t/* we need job_list not to be NULL */\n\t\tinit_job_conf();\n\t}\n\n\tif (accounting_enforce && !association_based_accounting) {\n\t\taccounting_enforce = 0;\n\t\tslurmctld_conf.track_wckey = false;\n\t\tslurmctld_conf.accounting_storage_enforce = 0;\n\n\t\terror(\"You can not have AccountingStorageEnforce \"\n\t\t      \"set for AccountingStorageType='%s'\",\n\t\t      slurmctld_conf.accounting_storage_type);\n\t}\n\n\tmemset(&callbacks, 0, sizeof(slurm_trigger_callbacks_t));\n\tcallbacks.acct_full   = trigger_primary_ctld_acct_full;\n\tcallbacks.dbd_fail    = trigger_primary_dbd_fail;\n\tcallbacks.dbd_resumed = trigger_primary_dbd_res_op;\n\tcallbacks.db_fail     = trigger_primary_db_fail;\n\tcallbacks.db_resumed  = trigger_primary_db_res_op;\n\n\tinfo(\"%s version %s started on cluster %s\", slurm_prog_name,\n\t     SLURM_VERSION_STRING, slurmctld_conf.cluster_name);\n\n\tif ((error_code = gethostname_short(node_name_short, MAX_SLURM_NAME)))\n\t\tfatal(\"getnodename_short error %s\", slurm_strerror(error_code));\n\tif ((error_code = gethostname(node_name_long, MAX_SLURM_NAME)))\n\t\tfatal(\"getnodename error %s\", slurm_strerror(error_code));\n\n\t/* init job credential stuff */\n\tslurmctld_config.cred_ctx = slurm_cred_creator_ctx_create(\n\t\t\tslurmctld_conf.job_credential_private_key);\n\tif (!slurmctld_config.cred_ctx) {\n\t\tfatal(\"slurm_cred_creator_ctx_create(%s): %m\",\n\t\t\tslurmctld_conf.job_credential_private_key);\n\t}\n\n\t/*\n\t * Avoid constant xstrcasestr calls as part of step launch.\n\t * This could live elsewhere if someone finds a better home for it.\n\t */\n\tif (xstrcasestr(slurmctld_conf.launch_params, \"send_gids\"))\n\t\tslurmctld_config.send_groups_in_cred = true;\n\telse\n\t\tslurmctld_config.send_groups_in_cred = false;\n\n\t/* Must set before plugins are loaded. */\n\tif (slurmctld_conf.backup_controller &&\n\t    ((xstrcmp(node_name_short,slurmctld_conf.backup_controller) == 0) ||\n\t     (xstrcmp(node_name_long, slurmctld_conf.backup_controller) == 0))) {\n\t\tslurmctld_primary = 0;\n\n#ifdef HAVE_ALPS_CRAY\n\t\tslurmctld_config.scheduling_disabled = true;\n#else\n\t\tif (xstrcasestr(slurmctld_conf.sched_params,\n\t\t\t\t\"no_backup_scheduling\"))\n\t\t\tslurmctld_config.scheduling_disabled = true;\n#endif\n\t}\n\n\t/*\n\t * Initialize plugins.\n\t */\n\tif (gres_plugin_init() != SLURM_SUCCESS )\n\t\tfatal( \"failed to initialize gres plugin\" );\n\tif (slurm_select_init(1) != SLURM_SUCCESS )\n\t\tfatal( \"failed to initialize node selection plugin\" );\n\tif (slurm_preempt_init() != SLURM_SUCCESS )\n\t\tfatal( \"failed to initialize preempt plugin\" );\n\tif (checkpoint_init(slurmctld_conf.checkpoint_type) != SLURM_SUCCESS )\n\t\tfatal( \"failed to initialize checkpoint plugin\" );\n\tif (acct_gather_conf_init() != SLURM_SUCCESS )\n\t\tfatal( \"failed to initialize acct_gather plugins\" );\n\tif (jobacct_gather_init() != SLURM_SUCCESS )\n\t\tfatal( \"failed to initialize jobacct_gather plugin\");\n\tif (job_submit_plugin_init() != SLURM_SUCCESS )\n\t\tfatal( \"failed to initialize job_submit plugin\");\n\tif (ext_sensors_init() != SLURM_SUCCESS )\n\t\tfatal( \"failed to initialize ext_sensors plugin\");\n\tif (node_features_g_init() != SLURM_SUCCESS )\n\t\tfatal( \"failed to initialize node_features plugin\");\t\n\tif (switch_g_slurmctld_init() != SLURM_SUCCESS )\n\t\tfatal( \"failed to initialize switch plugin\");\n\tconfig_power_mgr();\n\tagent_init();\n\tif (node_features_g_node_power() && !power_save_test()) {\n\t\tfatal(\"PowerSave required with NodeFeatures plugin, \"\n\t\t      \"but not fully configured (SuspendProgram, \"\n\t\t      \"ResumeProgram and SuspendTime all required)\");\n\t}\n\n\twhile (1) {\n\t\t/* initialization for each primary<->backup switch */\n\t\txfree(slurmctld_config.auth_info);\n\t\tslurmctld_config.auth_info = slurm_get_auth_info();\n\t\tslurmctld_config.shutdown_time = (time_t) 0;\n\t\tslurmctld_config.resume_backup = false;\n\n\t\t/* start in primary or backup mode */\n\t\tif (!slurmctld_primary) {\n\t\t\tslurm_sched_fini();\t/* make sure shutdown */\n\t\t\trun_backup(&callbacks);\n\t\t\tif (slurm_acct_storage_init(NULL) != SLURM_SUCCESS )\n\t\t\t\tfatal(\"failed to initialize \"\n\t\t\t\t      \"accounting_storage plugin\");\n\t\t} else if (_valid_controller()) {\n\t\t\t(void) _shutdown_backup_controller(SHUTDOWN_WAIT);\n\t\t\ttrigger_primary_ctld_res_ctrl();\n\t\t\tctld_assoc_mgr_init(&callbacks);\n\t\t\tif (slurm_acct_storage_init(NULL) != SLURM_SUCCESS )\n\t\t\t\tfatal(\"failed to initialize \"\n\t\t\t\t      \"accounting_storage plugin\");\n\t\t\t/* Now recover the remaining state information */\n\t\t\tlock_slurmctld(config_write_lock);\n\t\t\tif (switch_g_restore(slurmctld_conf.state_save_location,\n\t\t\t\t\t   recover ? true : false))\n\t\t\t\tfatal(\" failed to initialize switch plugin\" );\n\t\t\tif ((error_code = read_slurm_conf(recover, false))) {\n\t\t\t\tfatal(\"read_slurm_conf reading %s: %s\",\n\t\t\t\t\tslurmctld_conf.slurm_conf,\n\t\t\t\t\tslurm_strerror(error_code));\n\t\t\t}\n\t\t\tunlock_slurmctld(config_write_lock);\n\t\t\tselect_g_select_nodeinfo_set_all();\n\n\t\t\tif (recover == 0) {\n\t\t\t\tslurmctld_init_db = 1;\n\t\t\t\t/* This needs to be set up the nodes\n\t\t\t\t   going down and this happens before it is\n\t\t\t\t   normally set up so do it now.\n\t\t\t\t*/\n\t\t\t\tlock_slurmctld(node_part_write_lock);\n\t\t\t\tset_cluster_tres(false);\n\t\t\t\tunlock_slurmctld(node_part_write_lock);\n\t\t\t\t_accounting_mark_all_nodes_down(\"cold-start\");\n\t\t\t}\n\t\t} else {\n\t\t\terror(\"this host (%s/%s) not a valid controller \"\n\t\t\t      \"(%s or %s)\", node_name_short, node_name_long,\n\t\t\t      slurmctld_conf.control_machine,\n\t\t\t      slurmctld_conf.backup_controller);\n\t\t\texit(0);\n\t\t}\n\n\t\tif (!acct_db_conn) {\n\t\t\tacct_db_conn = acct_storage_g_get_connection(\n\t\t\t\t\t\t&callbacks, 0, false,\n\t\t\t\t\t\tslurmctld_conf.cluster_name);\n\t\t\t/* We only send in a variable the first time\n\t\t\t * we call this since we are setting up static\n\t\t\t * variables inside the function sending a\n\t\t\t * NULL will just use those set before. */\n\t\t\tif (assoc_mgr_init(acct_db_conn, NULL, errno) &&\n\t\t\t    (accounting_enforce & ACCOUNTING_ENFORCE_ASSOCS) &&\n\t\t\t    !running_cache) {\n\t\t\t\ttrigger_primary_dbd_fail();\n\t\t\t\terror(\"assoc_mgr_init failure\");\n\t\t\t\tfatal(\"slurmdbd and/or database must be up at \"\n\t\t\t\t      \"slurmctld start time\");\n\t\t\t}\n\t\t}\n\n\t\tinfo(\"Running as primary controller\");\n\t\theartbeat_start();\n\t\tif ((slurmctld_config.resume_backup == false) &&\n\t\t    (slurmctld_primary == 1)) {\n\t\t\ttrigger_primary_ctld_res_op();\n\t\t}\n\n\t\tclusteracct_storage_g_register_ctld(\n\t\t\tacct_db_conn,\n\t\t\tslurmctld_conf.slurmctld_port);\n\t\t_accounting_cluster_ready();\n\n\t\t/* call after registering so that the current cluster's\n\t\t * control_host and control_port will be filled in. */\n\t\tfed_mgr_init(acct_db_conn);\n\n\t\tif (slurm_priority_init() != SLURM_SUCCESS)\n\t\t\tfatal(\"failed to initialize priority plugin\");\n\t\tif (slurm_sched_init() != SLURM_SUCCESS)\n\t\t\tfatal(\"failed to initialize scheduling plugin\");\n\t\tif (slurmctld_plugstack_init())\n\t\t\tfatal(\"failed to initialize slurmctld_plugstack\");\n\t\tif (bb_g_init() != SLURM_SUCCESS )\n\t\t\tfatal( \"failed to initialize burst buffer plugin\");\n\t\tif (power_g_init() != SLURM_SUCCESS )\n\t\t\tfatal( \"failed to initialize power management plugin\");\n\t\tif (slurm_mcs_init() != SLURM_SUCCESS)\n\t\t\tfatal(\"failed to initialize mcs plugin\");\n\n\t\t/*\n\t\t * create attached thread to process RPCs\n\t\t */\n\t\tserver_thread_incr();\n\t\tslurm_thread_create(&slurmctld_config.thread_id_rpc,\n\t\t\t\t    _slurmctld_rpc_mgr, NULL);\n\n\t\t/*\n\t\t * create attached thread for signal handling\n\t\t */\n\t\tslurm_thread_create(&slurmctld_config.thread_id_sig,\n\t\t\t\t    _slurmctld_signal_hand, NULL);\n\n\t\t/*\n\t\t * create attached thread for state save\n\t\t */\n\t\tslurm_thread_create(&slurmctld_config.thread_id_save,\n\t\t\t\t    slurmctld_state_save, NULL);\n\n\t\t/*\n\t\t * create attached thread for node power management\n  \t\t */\n\t\tstart_power_mgr(&slurmctld_config.thread_id_power);\n\n\t\t/*\n\t\t * create attached thread for purging completed job files\n\t\t */\n\t\tslurm_thread_create(&slurmctld_config.thread_id_purge_files,\n\t\t\t\t    _purge_files_thread, NULL);\n\n\t\t/*\n\t\t * process slurm background activities, could run as pthread\n\t\t */\n\t\t_slurmctld_background(NULL);\n\n\t\t/* termination of controller */\n\t\tswitch_g_save(slurmctld_conf.state_save_location);\n\t\tslurm_priority_fini();\n\t\tslurmctld_plugstack_fini();\n\t\tshutdown_state_save();\n\t\tslurm_cond_signal(&purge_thread_cond); /* wake up last time */\n\t\tpthread_join(slurmctld_config.thread_id_purge_files, NULL);\n\t\tpthread_join(slurmctld_config.thread_id_sig,  NULL);\n\t\tpthread_join(slurmctld_config.thread_id_rpc,  NULL);\n\t\tpthread_join(slurmctld_config.thread_id_save, NULL);\n\t\tslurmctld_config.thread_id_purge_files = (pthread_t) 0;\n\t\tslurmctld_config.thread_id_sig  = (pthread_t) 0;\n\t\tslurmctld_config.thread_id_rpc  = (pthread_t) 0;\n\t\tslurmctld_config.thread_id_save = (pthread_t) 0;\n\t\tbb_g_fini();\n\t\tpower_g_fini();\n\t\tslurm_mcs_fini();\n\n\t\tif (running_cache) {\n\t\t\t/* break out and end the association cache\n\t\t\t * thread since we are shutting down, no reason\n\t\t\t * to wait for current info from the database */\n\t\t\tslurm_mutex_lock(&assoc_cache_mutex);\n\t\t\trunning_cache = NO_VAL16;\n\t\t\tslurm_cond_signal(&assoc_cache_cond);\n\t\t\tslurm_mutex_unlock(&assoc_cache_mutex);\n\t\t\tpthread_join(assoc_cache_thread, NULL);\n\t\t}\n\n\t\t/* Save any pending state save RPCs */\n\t\tacct_storage_g_close_connection(&acct_db_conn);\n\t\tslurm_acct_storage_fini();\n\n\t\t/* join the power save thread after saving all state\n\t\t * since it could wait a while waiting for spawned\n\t\t * processes to exit */\n\t\tpthread_join(slurmctld_config.thread_id_power, NULL);\n\n\t\t/* stop the heartbeat last */\n\t\theartbeat_stop();\n\n\t\tif (slurmctld_config.resume_backup == false)\n\t\t\tbreak;\n\n\t\t/* primary controller doesn't resume backup mode */\n\t\tif ((slurmctld_config.resume_backup == true) &&\n\t\t    (slurmctld_primary == 1))\n\t\t\tbreak;\n\n\t\trecover = 2;\n\t}\n\n\tlayouts_fini();\n\tg_slurm_jobcomp_fini();\n\n\t/* Since pidfile is created as user root (its owner is\n\t *   changed to SlurmUser) SlurmUser may not be able to\n\t *   remove it, so this is not necessarily an error. */\n\tif (unlink(slurmctld_conf.slurmctld_pidfile) < 0) {\n\t\tverbose(\"Unable to remove pidfile '%s': %m\",\n\t\t\tslurmctld_conf.slurmctld_pidfile);\n\t}\n\n\n#ifdef MEMORY_LEAK_DEBUG\n{\n\t/* This should purge all allocated memory,   *\\\n\t\\*   Anything left over represents a leak.   */\n\n\n\t/* Give running agents a chance to complete and free memory.\n\t * Wait up to 60 seconds. */\n\tfor (i=0; i<60; i++) {\n\t\tagent_purge();\n\t\tusleep(100000);\n\t\tcnt = get_agent_count();\n\t\tif (cnt == 0)\n\t\t\tbreak;\n\t}\n\tif (cnt)\n\t\terror(\"Left %d agent threads active\", cnt);\n\n\tslurm_sched_fini();\t/* Stop all scheduling */\n\n\t/* Purge our local data structures */\n\tjob_fini();\n\tpart_fini();\t/* part_fini() must precede node_fini() */\n\tnode_fini();\n\tnode_features_g_fini();\n\tpurge_front_end_state();\n\tresv_fini();\n\ttrigger_fini();\n\tfed_mgr_fini();\n\tassoc_mgr_fini(slurmctld_conf.state_save_location);\n\treserve_port_config(NULL);\n\tfree_rpc_stats();\n\n\t/* Some plugins are needed to purge job/node data structures,\n\t * unplug after other data structures are purged */\n\text_sensors_fini();\n\tgres_plugin_fini();\n\tjob_submit_plugin_fini();\n\tslurm_preempt_fini();\n\tjobacct_gather_fini();\n\tacct_gather_conf_destroy();\n\tslurm_select_fini();\n\tslurm_topo_fini();\n\tcheckpoint_fini();\n\tslurm_auth_fini();\n\tswitch_fini();\n\troute_fini();\n\n\t/* purge remaining data structures */\n\tgroup_cache_purge();\n\tlicense_free();\n\tslurm_cred_ctx_destroy(slurmctld_config.cred_ctx);\n\tslurm_crypto_fini();\t/* must be after ctx_destroy */\n\tslurm_conf_destroy();\n\tslurm_api_clear_config();\n\tusleep(500000);\n}\n#else\n\t/*\n\t * Give REQUEST_SHUTDOWN a chance to get propagated, up to 3 seconds.\n\t */\n\tfor (i = 0; i < 30; i++) {\n\t\tagent_purge();\n\t\tcnt = get_agent_count();\n\t\tif (cnt == 0)\n\t\t\tbreak;\n\t\tusleep(100000);\n\t}\n\tif (i >= 30)\n\t\tinfo(\"Dropped %d hung communications to shutdown\", cnt);\n\n\t/*\n\t * do this outside of MEMORY_LEAK_DEBUG so that remote connections get\n\t * closed.\n\t */\n\n#ifdef HAVE_BG\n\t/*\n\t * Always call slurm_select_fini() on some systems like\n\t * BlueGene we need to make sure other processes are ended\n\t * or we could get a random core from within it's\n\t * underlying infrastructure.\n\t */\n        slurm_select_fini();\n#endif\n\n#endif\n\n\txfree(slurmctld_config.auth_info);\n\tif (cnt) {\n\t\tinfo(\"Slurmctld shutdown completing with %d active agent thread\",\n\t\t     cnt);\n\t}\n\tlog_fini();\n\tsched_log_fini();\n\n\tif (dump_core)\n\t\tabort();\n\telse\n\t\texit(0);\n}\n\n/* initialization of common slurmctld configuration */\nstatic void  _init_config(void)\n{\n\tstruct rlimit rlim;\n\n\tif (getrlimit(RLIMIT_NOFILE, &rlim) == 0) {\n\t\trlim.rlim_cur = rlim.rlim_max;\n\t\t(void) setrlimit(RLIMIT_NOFILE, &rlim);\n\t}\n\tif (getrlimit(RLIMIT_CORE, &rlim) == 0) {\n\t\trlim.rlim_cur = rlim.rlim_max;\n\t\t(void) setrlimit(RLIMIT_CORE, &rlim);\n\t}\n\tif (getrlimit(RLIMIT_STACK, &rlim) == 0) {\n\t\t/* slurmctld can spawn lots of pthreads.\n\t\t * Set the (per thread) stack size to a\n\t\t * more \"reasonable\" value to avoid running\n\t\t * out of virtual memory and dying */\n\t\trlim.rlim_cur = rlim.rlim_max;\n\t\t(void) setrlimit(RLIMIT_STACK, &rlim);\n\t}\n\tif (getrlimit(RLIMIT_DATA, &rlim) == 0) {\n\t\trlim.rlim_cur = rlim.rlim_max;\n\t\t(void) setrlimit(RLIMIT_DATA, &rlim);\n\t}\n\n\tmemset(&slurmctld_config, 0, sizeof(slurmctld_config_t));\n\tslurmctld_config.boot_time      = time(NULL);\n\tslurmctld_config.daemonize      = DEFAULT_DAEMONIZE;\n\tslurmctld_config.resume_backup  = false;\n\tslurmctld_config.server_thread_count = 0;\n\tslurmctld_config.shutdown_time  = (time_t) 0;\n\tslurmctld_config.thread_id_main = pthread_self();\n\tslurmctld_config.scheduling_disabled  = false;\n\tslurmctld_config.submissions_disabled = false;\n\tslurm_mutex_init(&slurmctld_config.thread_count_lock);\n\tslurmctld_config.thread_id_main    = (pthread_t) 0;\n\tslurmctld_config.thread_id_sig     = (pthread_t) 0;\n\tslurmctld_config.thread_id_rpc     = (pthread_t) 0;\n}\n\n/* Read configuration file.\n * Same name as API function for use in accounting_storage plugin.\n * Anything you add to this function must be added to the\n * _slurm_rpc_reconfigure_controller function inside proc_req.c try\n * to keep these in sync.\n */\nstatic void _reconfigure_slurm(void)\n{\n\t/* Locks: Write configuration, job, node, and partition */\n\tslurmctld_lock_t config_write_lock = {\n\t\tWRITE_LOCK, WRITE_LOCK, WRITE_LOCK, WRITE_LOCK, NO_LOCK };\n\tint rc;\n\n\tif (slurmctld_config.shutdown_time)\n\t\treturn;\n\n\t/*\n\t * XXX - need to shut down the scheduler\n\t * plugin, re-read the configuration, and then\n\t * restart the (possibly new) plugin.\n\t */\n\tlock_slurmctld(config_write_lock);\n\trc = read_slurm_conf(2, true);\n\tif (rc)\n\t\terror(\"read_slurm_conf: %s\", slurm_strerror(rc));\n\telse {\n\t\t_update_cred_key();\n\t\tset_slurmctld_state_loc();\n\t}\n\t/*\n\t * Avoid constant xstrcasestr calls as part of step launch.\n\t * This could live elsewhere if someone finds a better home for it.\n\t */\n\tif (xstrcasestr(slurmctld_conf.launch_params, \"send_gids\"))\n\t\tslurmctld_config.send_groups_in_cred = true;\n\telse\n\t\tslurmctld_config.send_groups_in_cred = false;\n\n\tgs_reconfig();\n\tunlock_slurmctld(config_write_lock);\n\tassoc_mgr_set_missing_uids();\n\tacct_storage_g_reconfig(acct_db_conn, 0);\n\tstart_power_mgr(&slurmctld_config.thread_id_power);\n\ttrigger_reconfig();\n\tpriority_g_reconfig(true);\t/* notify priority plugin too */\n\tsave_all_state();\t\t/* Has own locking */\n\tqueue_job_scheduler();\n}\n\n/* Request that the job scheduler execute soon (typically within seconds) */\nextern void queue_job_scheduler(void)\n{\n\tslurm_mutex_lock(&sched_cnt_mutex);\n\tjob_sched_cnt++;\n\tslurm_mutex_unlock(&sched_cnt_mutex);\n}\n\n/* _slurmctld_signal_hand - Process daemon-wide signals */\nstatic void *_slurmctld_signal_hand(void *no_data)\n{\n\tint sig;\n\tint i, rc;\n\tint sig_array[] = {SIGINT, SIGTERM, SIGHUP, SIGABRT, SIGUSR2, 0};\n\tsigset_t set;\n\n#if HAVE_SYS_PRCTL_H\n\tif (prctl(PR_SET_NAME, \"sigmgr\", NULL, NULL, NULL) < 0) {\n\t\terror(\"%s: cannot set my name to %s %m\", __func__, \"sigmgr\");\n\t}\n#endif\n\t(void) pthread_setcancelstate(PTHREAD_CANCEL_ENABLE, NULL);\n\t(void) pthread_setcanceltype(PTHREAD_CANCEL_ASYNCHRONOUS, NULL);\n\n\t/* Make sure no required signals are ignored (possibly inherited) */\n\tfor (i = 0; sig_array[i]; i++)\n\t\t_default_sigaction(sig_array[i]);\n\twhile (1) {\n\t\txsignal_sigset_create(sig_array, &set);\n\t\trc = sigwait(&set, &sig);\n\t\tif (rc == EINTR)\n\t\t\tcontinue;\n\t\tswitch (sig) {\n\t\tcase SIGINT:\t/* kill -2  or <CTRL-C> */\n\t\tcase SIGTERM:\t/* kill -15 */\n\t\t\tinfo(\"Terminate signal (SIGINT or SIGTERM) received\");\n\t\t\tslurmctld_config.shutdown_time = time(NULL);\n\t\t\tslurmctld_shutdown();\n\t\t\treturn NULL;\t/* Normal termination */\n\t\t\tbreak;\n\t\tcase SIGHUP:\t/* kill -1 */\n\t\t\tinfo(\"Reconfigure signal (SIGHUP) received\");\n\t\t\t_reconfigure_slurm();\n\t\t\tbreak;\n\t\tcase SIGABRT:\t/* abort */\n\t\t\tinfo(\"SIGABRT received\");\n\t\t\tslurmctld_config.shutdown_time = time(NULL);\n\t\t\tslurmctld_shutdown();\n\t\t\tdump_core = true;\n\t\t\treturn NULL;\n\t\tcase SIGUSR2:\n\t\t\tinfo(\"Logrotate signal (SIGUSR2) received\");\n\t\t\tupdate_logging();\n\t\t\tbreak;\n\t\tdefault:\n\t\t\terror(\"Invalid signal (%d) received\", sig);\n\t\t}\n\t}\n}\n\nstatic void _default_sigaction(int sig)\n{\n\tstruct sigaction act;\n\tif (sigaction(sig, NULL, &act)) {\n\t\terror(\"sigaction(%d): %m\", sig);\n\t\treturn;\n\t}\n\tif (act.sa_handler != SIG_IGN)\n\t\treturn;\n\n\tact.sa_handler = SIG_DFL;\n\tif (sigaction(sig, &act, NULL))\n\t\terror(\"sigaction(%d): %m\", sig);\n}\n\nstatic void _sig_handler(int signal)\n{\n}\n\n/* _slurmctld_rpc_mgr - Read incoming RPCs and create pthread for each */\nstatic void *_slurmctld_rpc_mgr(void *no_data)\n{\n\tint newsockfd;\n\tint *sockfd;\t/* our set of socket file descriptors */\n\tslurm_addr_t cli_addr, srv_addr;\n\tuint16_t port;\n\tchar ip[32];\n\tint fd_next = 0, i, nports;\n\tfd_set rfds;\n\tconnection_arg_t *conn_arg = NULL;\n\t/* Locks: Read config */\n\tslurmctld_lock_t config_read_lock = {\n\t\tREAD_LOCK, NO_LOCK, NO_LOCK, NO_LOCK, NO_LOCK };\n\tint sigarray[] = {SIGUSR1, 0};\n\tchar* node_addr = NULL;\n\n#if HAVE_SYS_PRCTL_H\n\tif (prctl(PR_SET_NAME, \"rpcmgr\", NULL, NULL, NULL) < 0) {\n\t\terror(\"%s: cannot set my name to %s %m\", __func__, \"rpcmgr\");\n\t}\n#endif\n\n\t(void) pthread_setcancelstate(PTHREAD_CANCEL_ENABLE, NULL);\n\t(void) pthread_setcanceltype(PTHREAD_CANCEL_ASYNCHRONOUS, NULL);\n\tdebug3(\"_slurmctld_rpc_mgr pid = %u\", getpid());\n\n\t/* set node_addr to bind to (NULL means any) */\n\tif (slurmctld_conf.backup_controller && slurmctld_conf.backup_addr &&\n\t    ((xstrcmp(node_name_short,slurmctld_conf.backup_controller) == 0) ||\n\t     (xstrcmp(node_name_long, slurmctld_conf.backup_controller) == 0))&&\n\t    (xstrcmp(slurmctld_conf.backup_controller,\n\t\t     slurmctld_conf.backup_addr) != 0)) {\n\t\tnode_addr = slurmctld_conf.backup_addr ;\n\t}\n\telse if (_valid_controller() &&\n\t\t xstrcmp(slurmctld_conf.control_machine,\n\t\t\t slurmctld_conf.control_addr)) {\n\t\tnode_addr = slurmctld_conf.control_addr ;\n\t}\n\n\t/* initialize ports for RPCs */\n\tlock_slurmctld(config_read_lock);\n\tnports = slurmctld_conf.slurmctld_port_count;\n\tif (nports == 0) {\n\t\tfatal(\"slurmctld port count is zero\");\n\t\treturn NULL;\t/* Fix CLANG false positive */\n\t}\n\tsockfd = xmalloc(sizeof(int) * nports);\n\tfor (i=0; i<nports; i++) {\n\t\tsockfd[i] = slurm_init_msg_engine_addrname_port(\n\t\t\t\t\tnode_addr,\n\t\t\t\t\tslurmctld_conf.slurmctld_port+i);\n\t\tif (sockfd[i] == SLURM_SOCKET_ERROR) {\n\t\t\tfatal(\"slurm_init_msg_engine_addrname_port error %m\");\n\t\t\treturn NULL;\t/* Fix CLANG false positive */\n\t\t}\n\t\tfd_set_close_on_exec(sockfd[i]);\n\t\tif (slurm_get_stream_addr(sockfd[i], &srv_addr)) {\n\t\t\terror(\"slurm_get_stream_addr error %m\");\n\t\t} else {\n\t\t\tslurm_get_ip_str(&srv_addr, &port, ip, sizeof(ip));\n\t\t\tdebug2(\"slurmctld listening on %s:%d\", ip, ntohs(port));\n\t\t}\n\t}\n\tunlock_slurmctld(config_read_lock);\n\n\t/* Prepare to catch SIGUSR1 to interrupt accept().\n\t * This signal is generated by the slurmctld signal\n\t * handler thread upon receipt of SIGABRT, SIGINT,\n\t * or SIGTERM. That thread does all processing of\n\t * all signals. */\n\txsignal(SIGUSR1, _sig_handler);\n\txsignal_unblock(sigarray);\n\n\t/*\n\t * Process incoming RPCs until told to shutdown\n\t */\n\twhile (_wait_for_server_thread()) {\n\t\tint max_fd = -1;\n\t\tFD_ZERO(&rfds);\n\t\tfor (i=0; i<nports; i++) {\n\t\t\tFD_SET(sockfd[i], &rfds);\n\t\t\tmax_fd = MAX(sockfd[i], max_fd);\n\t\t}\n\t\tif (select(max_fd+1, &rfds, NULL, NULL, NULL) == -1) {\n\t\t\tif (errno != EINTR)\n\t\t\t\terror(\"slurm_accept_msg_conn select: %m\");\n\t\t\tserver_thread_decr();\n\t\t\tcontinue;\n\t\t}\n\t\t/* find one to process */\n\t\tfor (i=0; i<nports; i++) {\n\t\t\tif (FD_ISSET(sockfd[(fd_next+i) % nports], &rfds)) {\n\t\t\t\ti = (fd_next + i) % nports;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tfd_next = (i + 1) % nports;\n\n\t\t/*\n\t\t * accept needed for stream implementation is a no-op in\n\t\t * message implementation that just passes sockfd to newsockfd\n\t\t */\n\t\tif ((newsockfd = slurm_accept_msg_conn(sockfd[i],\n\t\t\t\t\t\t       &cli_addr)) ==\n\t\t    SLURM_SOCKET_ERROR) {\n\t\t\tif (errno != EINTR)\n\t\t\t\terror(\"slurm_accept_msg_conn: %m\");\n\t\t\tserver_thread_decr();\n\t\t\tcontinue;\n\t\t}\n\t\tfd_set_close_on_exec(newsockfd);\n\t\tconn_arg = xmalloc(sizeof(connection_arg_t));\n\t\tconn_arg->newsockfd = newsockfd;\n\t\tmemcpy(&conn_arg->cli_addr, &cli_addr, sizeof(slurm_addr_t));\n\n\t\tif (slurmctld_conf.debug_flags & DEBUG_FLAG_PROTOCOL) {\n\t\t\tchar inetbuf[64];\n\n\t\t\tslurm_print_slurm_addr(&cli_addr,\n\t\t\t\t\t\tinetbuf,\n\t\t\t\t\t\tsizeof(inetbuf));\n\t\t\tinfo(\"%s: accept() connection from %s\", __func__, inetbuf);\n\t\t}\n\n\t\tif (slurmctld_config.shutdown_time) {\n\t\t\tslurmctld_diag_stats.proc_req_raw++;\n\t\t\t_service_connection(conn_arg);\n\t\t} else {\n\t\t\tslurm_thread_create_detached(NULL, _service_connection,\n\t\t\t\t\t\t     conn_arg);\n\t\t}\n\t}\n\n\tdebug3(\"_slurmctld_rpc_mgr shutting down\");\n\tfor (i=0; i<nports; i++)\n\t\t(void) slurm_shutdown_msg_engine(sockfd[i]);\n\txfree(sockfd);\n\tserver_thread_decr();\n\tpthread_exit((void *) 0);\n\treturn NULL;\n}\n\n/*\n * _service_connection - service the RPC\n * IN/OUT arg - really just the connection's file descriptor, freed\n *\tupon completion\n * RET - NULL\n */\nstatic void *_service_connection(void *arg)\n{\n\tconnection_arg_t *conn = (connection_arg_t *) arg;\n\tvoid *return_code = NULL;\n\tslurm_msg_t msg;\n\n#if HAVE_SYS_PRCTL_H\n\tif (prctl(PR_SET_NAME, \"srvcn\", NULL, NULL, NULL) < 0) {\n\t\terror(\"%s: cannot set my name to %s %m\", __func__, \"srvcn\");\n\t}\n#endif\n\tslurm_msg_t_init(&msg);\n\tmsg.flags |= SLURM_MSG_KEEP_BUFFER;\n\t/*\n\t * slurm_receive_msg sets msg connection fd to accepted fd. This allows\n\t * possibility for slurmctld_req() to close accepted connection.\n\t */\n\tif (slurm_receive_msg(conn->newsockfd, &msg, 0) != 0) {\n\t\tchar addr_buf[32];\n\t\tslurm_print_slurm_addr(&conn->cli_addr, addr_buf,\n\t\t\t\t       sizeof(addr_buf));\n\t\terror(\"slurm_receive_msg [%s]: %m\", addr_buf);\n\t\t/* close the new socket */\n\t\tclose(conn->newsockfd);\n\t\tgoto cleanup;\n\t}\n\n\tif (errno != SLURM_SUCCESS) {\n\t\tif (errno == SLURM_PROTOCOL_VERSION_ERROR) {\n\t\t\tslurm_send_rc_msg(&msg, SLURM_PROTOCOL_VERSION_ERROR);\n\t\t} else\n\t\t\tinfo(\"_service_connection/slurm_receive_msg %m\");\n\t} else {\n\t\t/* process the request */\n\t\tslurmctld_req(&msg, conn);\n\t}\n\n\tif ((conn->newsockfd >= 0) && (close(conn->newsockfd) < 0))\n\t\terror (\"close(%d): %m\",  conn->newsockfd);\n\ncleanup:\n\tslurm_free_msg_members(&msg);\n\txfree(arg);\n\tserver_thread_decr();\n\n\treturn return_code;\n}\n\n/* Increment slurmctld_config.server_thread_count and don't return\n * until its value is no larger than MAX_SERVER_THREADS,\n * RET true unless shutdown in progress */\nstatic bool _wait_for_server_thread(void)\n{\n\tbool print_it = true;\n\tbool rc = true;\n\n\tslurm_mutex_lock(&slurmctld_config.thread_count_lock);\n\twhile (1) {\n\t\tif (slurmctld_config.shutdown_time) {\n\t\t\trc = false;\n\t\t\tbreak;\n\t\t}\n\t\tif (slurmctld_config.server_thread_count < max_server_threads) {\n\t\t\tslurmctld_config.server_thread_count++;\n\t\t\tbreak;\n\t\t} else {\n\t\t\t/* wait for state change and retry,\n\t\t\t * just a delay and not an error.\n\t\t\t * This can happen when the epilog completes\n\t\t\t * on a bunch of nodes at the same time, which\n\t\t\t * can easily happen for highly parallel jobs. */\n\t\t\tif (print_it) {\n\t\t\t\tstatic time_t last_print_time = 0;\n\t\t\t\ttime_t now = time(NULL);\n\t\t\t\tif (difftime(now, last_print_time) > 2) {\n\t\t\t\t\tverbose(\"server_thread_count over \"\n\t\t\t\t\t\t\"limit (%d), waiting\",\n\t\t\t\t\t\tslurmctld_config.\n\t\t\t\t\t\tserver_thread_count);\n\t\t\t\t\tlast_print_time = now;\n\t\t\t\t}\n\t\t\t\tprint_it = false;\n\t\t\t}\n\t\t\tslurm_cond_wait(&server_thread_cond,\n\t\t\t\t\t&slurmctld_config.thread_count_lock);\n\t\t}\n\t}\n\tslurm_mutex_unlock(&slurmctld_config.thread_count_lock);\n\treturn rc;\n}\n\n/* Decrement slurmctld thread count (as applies to thread limit) */\nextern void server_thread_decr(void)\n{\n\tslurm_mutex_lock(&slurmctld_config.thread_count_lock);\n\tif (slurmctld_config.server_thread_count > 0)\n\t\tslurmctld_config.server_thread_count--;\n\telse\n\t\terror(\"slurmctld_config.server_thread_count underflow\");\n\tslurm_cond_broadcast(&server_thread_cond);\n\tslurm_mutex_unlock(&slurmctld_config.thread_count_lock);\n}\n\n/* Increment slurmctld thread count (as applies to thread limit) */\nextern void server_thread_incr(void)\n{\n\tslurm_mutex_lock(&slurmctld_config.thread_count_lock);\n\tslurmctld_config.server_thread_count++;\n\tslurm_mutex_unlock(&slurmctld_config.thread_count_lock);\n}\n\nstatic int _accounting_cluster_ready(void)\n{\n\tint rc = SLURM_ERROR;\n\ttime_t event_time = time(NULL);\n\tbitstr_t *total_node_bitmap = NULL;\n\tchar *cluster_nodes = NULL, *cluster_tres_str;\n\tslurmctld_lock_t node_write_lock = {\n\t\tNO_LOCK, NO_LOCK, WRITE_LOCK, WRITE_LOCK, NO_LOCK };\n\tassoc_mgr_lock_t locks = { NO_LOCK, NO_LOCK, NO_LOCK, NO_LOCK,\n\t\t\t\t   WRITE_LOCK, NO_LOCK, NO_LOCK };\n\n\tlock_slurmctld(node_write_lock);\n\t/* Now get the names of all the nodes on the cluster at this\n\t   time and send it also.\n\t*/\n\ttotal_node_bitmap = bit_alloc(node_record_count);\n\tbit_nset(total_node_bitmap, 0, node_record_count-1);\n\tcluster_nodes = bitmap2node_name_sortable(total_node_bitmap, 0);\n\tFREE_NULL_BITMAP(total_node_bitmap);\n\n\tassoc_mgr_lock(&locks);\n\n\tset_cluster_tres(true);\n\n\tcluster_tres_str = slurmdb_make_tres_string(\n\t\tassoc_mgr_tres_list, TRES_STR_FLAG_SIMPLE);\n\tassoc_mgr_unlock(&locks);\n\n\tunlock_slurmctld(node_write_lock);\n\n\trc = clusteracct_storage_g_cluster_tres(acct_db_conn,\n\t\t\t\t\t\tcluster_nodes,\n\t\t\t\t\t\tcluster_tres_str, event_time,\n\t\t\t\t\t\tSLURM_PROTOCOL_VERSION);\n\n\txfree(cluster_nodes);\n\txfree(cluster_tres_str);\n\n\t/*\n\t * FIXME: We should do things differently here depending on the return\n\t *        value.  If NODES_CHANGE or FIRST_REQ we probably want to send\n\t *        most everything to accounting, but if just the TRES changed it\n\t *        means the nodes didn't change and we might not need to send\n\t *        anything.\n\t */\n\tif ((rc == ACCOUNTING_FIRST_REG) ||\n\t    (rc == ACCOUNTING_NODES_CHANGE_DB) ||\n\t    (rc == ACCOUNTING_TRES_CHANGE_DB)) {\n\t\t/* see if we are running directly to a database\n\t\t * instead of a slurmdbd.\n\t\t */\n\t\tsend_all_to_accounting(event_time, rc);\n\t\trc = SLURM_SUCCESS;\n\t}\n\n\treturn rc;\n}\n\nstatic int _accounting_mark_all_nodes_down(char *reason)\n{\n\tchar *state_file;\n\tstruct stat stat_buf;\n\tstruct node_record *node_ptr;\n\tint i;\n\ttime_t event_time;\n\tint rc = SLURM_ERROR;\n\n\tstate_file = xstrdup_printf(\"%s/node_state\",\n\t\t\t\t    slurmctld_conf.state_save_location);\n\tif (stat(state_file, &stat_buf)) {\n\t\tdebug(\"_accounting_mark_all_nodes_down: could not stat(%s) \"\n\t\t      \"to record node down time\", state_file);\n\t\tevent_time = time(NULL);\n\t} else {\n\t\tevent_time = stat_buf.st_mtime;\n\t}\n\txfree(state_file);\n\n\tif ((rc = acct_storage_g_flush_jobs_on_cluster(acct_db_conn,\n\t\t\t\t\t\t      event_time))\n\t   == SLURM_ERROR)\n\t\treturn rc;\n\n\tnode_ptr = node_record_table_ptr;\n\tfor (i = 0; i < node_record_count; i++, node_ptr++) {\n\t\tif (!node_ptr->name)\n\t\t\tcontinue;\n\t\tif ((rc = clusteracct_storage_g_node_down(\n\t\t\t    acct_db_conn,\n\t\t\t    node_ptr, event_time,\n\t\t\t    reason, slurmctld_conf.slurm_user_id))\n\t\t   == SLURM_ERROR)\n\t\t\tbreak;\n\t}\n\treturn rc;\n}\n\nstatic void _remove_assoc(slurmdb_assoc_rec_t *rec)\n{\n\tint cnt = 0;\n\n\tcnt = job_hold_by_assoc_id(rec->id);\n\n\tif (cnt) {\n\t\tinfo(\"Removed association id:%u user:%s, held %u jobs\",\n\t\t     rec->id, rec->user, cnt);\n\t} else\n\t\tdebug(\"Removed association id:%u user:%s\", rec->id, rec->user);\n}\n\nstatic void _remove_qos(slurmdb_qos_rec_t *rec)\n{\n\tint cnt = 0;\n\tListIterator itr;\n\tstruct part_record *part_ptr;\n\tslurmctld_lock_t part_write_lock =\n\t\t{ NO_LOCK, NO_LOCK, NO_LOCK, WRITE_LOCK, NO_LOCK };\n\n\tlock_slurmctld(part_write_lock);\n\tif (part_list) {\n\t\titr = list_iterator_create(part_list);\n\t\twhile ((part_ptr = list_next(itr))) {\n\t\t\tif (part_ptr->qos_ptr != rec)\n\t\t\t\tcontinue;\n\t\t\tinfo(\"Partition %s's QOS %s was just removed, \"\n\t\t\t     \"you probably didn't mean for this to happen \"\n\t\t\t     \"unless you are also removing the partition.\",\n\t\t\t     part_ptr->name, rec->name);\n\t\t\tpart_ptr->qos_ptr = NULL;\n\t\t}\n\t\tlist_iterator_destroy(itr);\n\t}\n\tunlock_slurmctld(part_write_lock);\n\n\tcnt = job_hold_by_qos_id(rec->id);\n\n\tif (cnt) {\n\t\tinfo(\"Removed QOS:%s held %u jobs\", rec->name, cnt);\n\t} else\n\t\tdebug(\"Removed QOS:%s\", rec->name);\n}\n\nstatic void _update_assoc(slurmdb_assoc_rec_t *rec)\n{\n\tListIterator job_iterator;\n\tstruct job_record *job_ptr;\n\t/* Write lock on jobs */\n\tslurmctld_lock_t job_write_lock =\n\t\t{ NO_LOCK, WRITE_LOCK, NO_LOCK, NO_LOCK, NO_LOCK };\n\n\tif (!job_list || !accounting_enforce\n\t    || !(accounting_enforce & ACCOUNTING_ENFORCE_LIMITS))\n\t\treturn;\n\n\tlock_slurmctld(job_write_lock);\n\tjob_iterator = list_iterator_create(job_list);\n\twhile ((job_ptr = list_next(job_iterator))) {\n\t\tif ((rec != job_ptr->assoc_ptr) || (!IS_JOB_PENDING(job_ptr)))\n\t\t\tcontinue;\n\n\t\tacct_policy_update_pending_job(job_ptr);\n\t}\n\tlist_iterator_destroy(job_iterator);\n\tunlock_slurmctld(job_write_lock);\n}\n\nstatic void _resize_qos(void)\n{\n\tListIterator itr;\n\tstruct part_record *part_ptr;\n\tslurmctld_lock_t part_write_lock =\n\t\t{ NO_LOCK, NO_LOCK, NO_LOCK, WRITE_LOCK, NO_LOCK };\n\n\tlock_slurmctld(part_write_lock);\n\tif (part_list) {\n\t\titr = list_iterator_create(part_list);\n\t\twhile ((part_ptr = list_next(itr))) {\n\t\t\tif (part_ptr->allow_qos) {\n\t\t\t\tinfo(\"got count for %s of %\"BITSTR_FMT, part_ptr->name,\n\t\t\t\t     bit_size(part_ptr->allow_qos_bitstr));\n\t\t\t\tqos_list_build(part_ptr->allow_qos,\n\t\t\t\t\t       &part_ptr->allow_qos_bitstr);\n\t\t\t\tinfo(\"now count for %s of %\"BITSTR_FMT, part_ptr->name,\n\t\t\t\t     bit_size(part_ptr->allow_qos_bitstr));\n\t\t\t}\n\t\t\tif (part_ptr->deny_qos)\n\t\t\t\tqos_list_build(part_ptr->deny_qos,\n\t\t\t\t\t       &part_ptr->deny_qos_bitstr);\n\t\t}\n\t\tlist_iterator_destroy(itr);\n\t}\n\tunlock_slurmctld(part_write_lock);\n}\n\nstatic void _update_qos(slurmdb_qos_rec_t *rec)\n{\n\tListIterator job_iterator;\n\tstruct job_record *job_ptr;\n\t/* Write lock on jobs */\n\tslurmctld_lock_t job_write_lock =\n\t\t{ NO_LOCK, WRITE_LOCK, NO_LOCK, NO_LOCK, NO_LOCK };\n\n\tif (!job_list || !accounting_enforce\n\t    || !(accounting_enforce & ACCOUNTING_ENFORCE_LIMITS))\n\t\treturn;\n\n\tlock_slurmctld(job_write_lock);\n\tjob_iterator = list_iterator_create(job_list);\n\twhile ((job_ptr = list_next(job_iterator))) {\n\t\tif ((rec != job_ptr->qos_ptr) || (!IS_JOB_PENDING(job_ptr)))\n\t\t\tcontinue;\n\n\t\tacct_policy_update_pending_job(job_ptr);\n\t}\n\tlist_iterator_destroy(job_iterator);\n\tunlock_slurmctld(job_write_lock);\n}\n\nstatic int _init_tres(void)\n{\n\tchar *temp_char = slurm_get_accounting_storage_tres();\n\tList char_list;\n\tList add_list = NULL;\n\tslurmdb_tres_rec_t *tres_rec;\n\tslurmdb_update_object_t update_object;\n\tassoc_mgr_lock_t locks = { NO_LOCK, NO_LOCK, NO_LOCK, NO_LOCK,\n\t\t\t\t   READ_LOCK, NO_LOCK, NO_LOCK };\n\n\tif (!temp_char) {\n\t\terror(\"No tres defined, this should never happen\");\n\t\treturn SLURM_ERROR;\n\t}\n\n\tchar_list = list_create(slurm_destroy_char);\n\tslurm_addto_char_list(char_list, temp_char);\n\txfree(temp_char);\n\n\tmemset(&update_object, 0, sizeof(slurmdb_update_object_t));\n\tif (!association_based_accounting) {\n\t\tupdate_object.type = SLURMDB_ADD_TRES;\n\t\tupdate_object.objects = list_create(slurmdb_destroy_tres_rec);\n\t} else if (!g_tres_count)\n\t\tfatal(\"You are running with a database but for some reason \"\n\t\t      \"we have no TRES from it.  This should only happen if \"\n\t\t      \"the database is down and you don't have \"\n\t\t      \"any state files.\");\n\telse if ((g_tres_count < TRES_ARRAY_TOTAL_CNT) ||\n\t\t (xstrcmp(assoc_mgr_tres_array[TRES_ARRAY_BILLING]->type,\n\t\t\t  \"billing\")))\n\t\tfatal(\"You are running with a database but for some reason we have less TRES than should be here (%d < %d) and/or the \\\"billing\\\" TRES is missing. This should only happen if the database is down after an upgrade.\",\n\t\t      g_tres_count, TRES_ARRAY_TOTAL_CNT);\n\n\twhile ((temp_char = list_pop(char_list))) {\n\t\ttres_rec = xmalloc(sizeof(slurmdb_tres_rec_t));\n\n\t\ttres_rec->type = temp_char;\n\n\t\tif (!xstrcasecmp(temp_char, \"cpu\"))\n\t\t\ttres_rec->id = TRES_CPU;\n\t\telse if (!xstrcasecmp(temp_char, \"mem\"))\n\t\t\ttres_rec->id = TRES_MEM;\n\t\telse if (!xstrcasecmp(temp_char, \"energy\"))\n\t\t\ttres_rec->id = TRES_ENERGY;\n\t\telse if (!xstrcasecmp(temp_char, \"node\"))\n\t\t\ttres_rec->id = TRES_NODE;\n\t\telse if (!xstrcasecmp(temp_char, \"billing\"))\n\t\t\ttres_rec->id = TRES_BILLING;\n\t\telse if (!xstrncasecmp(temp_char, \"bb/\", 3)) {\n\t\t\ttres_rec->type[2] = '\\0';\n\t\t\ttres_rec->name = xstrdup(temp_char+3);\n\t\t\tif (!tres_rec->name)\n\t\t\t\tfatal(\"Burst Buffer type tres need to have a \"\n\t\t\t\t      \"name, (i.e. bb/cray).  You gave %s\",\n\t\t\t\t      temp_char);\n\t\t} else if (!xstrncasecmp(temp_char, \"gres/\", 5)) {\n\t\t\ttres_rec->type[4] = '\\0';\n\t\t\ttres_rec->name = xstrdup(temp_char+5);\n\t\t\tif (!tres_rec->name)\n\t\t\t\tfatal(\"Gres type tres need to have a name, \"\n\t\t\t\t      \"(i.e. Gres/GPU).  You gave %s\",\n\t\t\t\t      temp_char);\n\t\t} else if (!xstrncasecmp(temp_char, \"license/\", 8)) {\n\t\t\ttres_rec->type[7] = '\\0';\n\t\t\ttres_rec->name = xstrdup(temp_char+8);\n\t\t\tif (!tres_rec->name)\n\t\t\t\tfatal(\"License type tres need to \"\n\t\t\t\t      \"have a name, (i.e. License/Foo).  \"\n\t\t\t\t      \"You gave %s\",\n\t\t\t\t      temp_char);\n\t\t} else {\n\t\t\tfatal(\"%s: Unknown tres type '%s', acceptable \"\n\t\t\t      \"types are CPU,Gres/,License/,Mem\",\n\t\t\t      __func__, temp_char);\n\t\t\txfree(tres_rec->type);\n\t\t\txfree(tres_rec);\n\t\t}\n\n\t\tif (!association_based_accounting) {\n\t\t\tif (!tres_rec->id)\n\t\t\t\tfatal(\"Unless running with a database you \"\n\t\t\t\t      \"can only run with certain TRES, \"\n\t\t\t\t      \"%s%s%s is not one of them.  \"\n\t\t\t\t      \"Either set up \"\n\t\t\t\t      \"a database preferably with a slurmdbd \"\n\t\t\t\t      \"or remove this TRES from your \"\n\t\t\t\t      \"configuration.\",\n\t\t\t\t      tres_rec->type, tres_rec->name ? \"/\" : \"\",\n\t\t\t\t      tres_rec->name ? tres_rec->name : \"\");\n\t\t\tlist_append(update_object.objects, tres_rec);\n\t\t} else if (!tres_rec->id &&\n\t\t\t   assoc_mgr_fill_in_tres(\n\t\t\t\t   acct_db_conn, tres_rec,\n\t\t\t\t   ACCOUNTING_ENFORCE_TRES, NULL, 0)\n\t\t\t   != SLURM_SUCCESS) {\n\t\t\tif (!add_list)\n\t\t\t\tadd_list = list_create(\n\t\t\t\t\tslurmdb_destroy_tres_rec);\n\t\t\tinfo(\"Couldn't find tres %s%s%s in the database, \"\n\t\t\t     \"creating.\",\n\t\t\t     tres_rec->type, tres_rec->name ? \"/\" : \"\",\n\t\t\t     tres_rec->name ? tres_rec->name : \"\");\n\t\t\tlist_append(add_list, tres_rec);\n\t\t} else\n\t\t\tslurmdb_destroy_tres_rec(tres_rec);\n\t}\n\tFREE_NULL_LIST(char_list);\n\n\tif (add_list) {\n\t\tif (acct_storage_g_add_tres(acct_db_conn,\n\t\t\t\t\t    slurmctld_conf.slurm_user_id,\n\t\t\t\t\t    add_list) != SLURM_SUCCESS)\n\t\t\tfatal(\"Problem adding tres to the database, \"\n\t\t\t      \"can't continue until database is able to \"\n\t\t\t      \"make new tres\");\n\t\t/* refresh list here since the updates are not\n\t\t   sent dynamically */\n\t\tassoc_mgr_refresh_lists(acct_db_conn, ASSOC_MGR_CACHE_TRES);\n\t\tFREE_NULL_LIST(add_list);\n\t}\n\n\tif (!association_based_accounting) {\n\t\tassoc_mgr_update_tres(&update_object, false);\n\t\tlist_destroy(update_object.objects);\n\t}\n\n\t/* Set up the slurmctld_tres_cnt here (Current code is set to\n\t * not have this ever change).\n\t*/\n\tassoc_mgr_lock(&locks);\n\tslurmctld_tres_cnt = g_tres_count;\n\tassoc_mgr_unlock(&locks);\n\n\treturn SLURM_SUCCESS;\n}\n\n/*\n * NOTE: the job_write_lock as well as the assoc_mgr TRES Read lock should be\n * locked before coming in here.\n */\nstatic void _update_job_tres(struct job_record *job_ptr)\n{\n\txassert(verify_lock(JOB_LOCK, WRITE_LOCK));\n\n\t/* If this returns 1 it means the positions were\n\t   altered so just rebuild it.\n\t*/\n\tif (assoc_mgr_set_tres_cnt_array(&job_ptr->tres_req_cnt,\n\t\t\t\t\t job_ptr->tres_req_str,\n\t\t\t\t\t 0, true))\n\t\tjob_set_req_tres(job_ptr, true);\n\tif (assoc_mgr_set_tres_cnt_array(&job_ptr->tres_alloc_cnt,\n\t\t\t\t\t job_ptr->tres_alloc_str,\n\t\t\t\t\t 0, true))\n\t\tjob_set_alloc_tres(job_ptr, true);\n}\n\n/* any association manager locks should be unlocked before hand */\nstatic void _update_cluster_tres(void)\n{\n\tListIterator job_iterator;\n\tstruct job_record *job_ptr;\n\t/* Write lock on jobs */\n\tslurmctld_lock_t job_write_lock =\n\t\t{ NO_LOCK, WRITE_LOCK, NO_LOCK, NO_LOCK, NO_LOCK };\n\tassoc_mgr_lock_t locks = { NO_LOCK, NO_LOCK, NO_LOCK, NO_LOCK,\n\t\t\t\t   READ_LOCK, NO_LOCK, NO_LOCK };\n\n\tif (!job_list)\n\t\treturn;\n\n\tlock_slurmctld(job_write_lock);\n\tassoc_mgr_lock(&locks);\n\tjob_iterator = list_iterator_create(job_list);\n\twhile ((job_ptr = list_next(job_iterator))) {\n\t\t_update_job_tres(job_ptr);\n\t}\n\tlist_iterator_destroy(job_iterator);\n\n\tassoc_mgr_unlock(&locks);\n\tunlock_slurmctld(job_write_lock);\n}\n\n\nstatic void _queue_reboot_msg(void)\n{\n\tagent_arg_t *reboot_agent_args = NULL;\n\tstruct node_record *node_ptr;\n\tchar *host_str;\n\ttime_t now = time(NULL);\n\tint i;\n\tbool want_reboot;\n\n\twant_nodes_reboot = false;\n\tfor (i = 0, node_ptr = node_record_table_ptr;\n\t     i < node_record_count; i++, node_ptr++) {\n\t\t/* Allow nodes in maintenance reservations to reboot\n\t\t * (they previously could not).\n\t\t */\n\t\tif (!IS_NODE_REBOOT(node_ptr))\n\t\t\tcontinue;\t/* No reboot needed */\n\t\tif (IS_NODE_COMPLETING(node_ptr)) {\n\t\t\twant_nodes_reboot = true;\n\t\t\tcontinue;\n\t\t}\n                /* only active idle nodes, don't reboot\n                 * nodes that are idle but have suspended\n                 * jobs on them\n                 */\n\t\tif (IS_NODE_IDLE(node_ptr)\n                    && !IS_NODE_NO_RESPOND(node_ptr)\n                    && !IS_NODE_POWER_UP(node_ptr)\n                    && node_ptr->sus_job_cnt == 0)\n\t\t\twant_reboot = true;\n\t\telse if (IS_NODE_FUTURE(node_ptr) &&\n\t\t\t (node_ptr->last_response == (time_t) 0))\n\t\t\twant_reboot = true; /* system just restarted */\n\t\telse\n\t\t\twant_reboot = false;\n\t\tif (!want_reboot) {\n\t\t\twant_nodes_reboot = true;\t/* defer reboot */\n\t\t\tcontinue;\n\t\t}\n\t\tif (reboot_agent_args == NULL) {\n\t\t\treboot_agent_args = xmalloc(sizeof(agent_arg_t));\n\t\t\treboot_agent_args->msg_type = REQUEST_REBOOT_NODES;\n\t\t\treboot_agent_args->retry = 0;\n\t\t\treboot_agent_args->hostlist = hostlist_create(NULL);\n\t\t\treboot_agent_args->protocol_version =\n\t\t\t\tSLURM_PROTOCOL_VERSION;\n\t\t}\n\t\tif (reboot_agent_args->protocol_version\n\t\t    > node_ptr->protocol_version)\n\t\t\treboot_agent_args->protocol_version =\n\t\t\t\tnode_ptr->protocol_version;\n\t\thostlist_push_host(reboot_agent_args->hostlist, node_ptr->name);\n\t\treboot_agent_args->node_count++;\n\t\t/*\n\t\t * node_ptr->node_state &= ~NODE_STATE_MAINT;\n\t\t * The NODE_STATE_MAINT bit will just get set again as long\n\t\t * as the node remains in the maintenance reservation, so\n\t\t * don't clear it here because it won't do anything.\n\t\t */\n\t\tnode_ptr->node_state &=  NODE_STATE_FLAGS;\n\t\tnode_ptr->node_state |=  NODE_STATE_DOWN;\n\t\tbit_clear(avail_node_bitmap, i);\n\t\tbit_clear(idle_node_bitmap, i);\n\t\tnode_ptr->boot_req_time = now;\n\t\tnode_ptr->last_response = now + slurm_get_resume_timeout();\n\t}\n\tif (reboot_agent_args != NULL) {\n\t\thostlist_uniq(reboot_agent_args->hostlist);\n\t\thost_str = hostlist_ranged_string_xmalloc(\n\t\t\t\treboot_agent_args->hostlist);\n\t\tdebug(\"Queuing reboot request for nodes %s\", host_str);\n\t\txfree(host_str);\n\t\tagent_queue_request(reboot_agent_args);\n\t\tlast_node_update = now;\n\t\tschedule_node_save();\n\t}\n}\n\n/*\n * _slurmctld_background - process slurmctld background activities\n *\tpurge defunct job records, save state, schedule jobs, and\n *\tping other nodes\n */\nstatic void *_slurmctld_background(void *no_data)\n{\n\tstatic time_t last_sched_time;\n\tstatic time_t last_full_sched_time;\n\tstatic time_t last_checkpoint_time;\n\tstatic time_t last_group_time;\n\tstatic time_t last_health_check_time;\n\tstatic time_t last_acct_gather_node_time;\n\tstatic time_t last_ext_sensors_time;\n\tstatic time_t last_no_resp_msg_time;\n\tstatic time_t last_ping_node_time;\n\tstatic time_t last_ping_srun_time;\n\tstatic time_t last_purge_job_time;\n\tstatic time_t last_resv_time;\n\tstatic time_t last_timelimit_time;\n\tstatic time_t last_assert_primary_time;\n\tstatic time_t last_trigger;\n\tstatic time_t last_node_acct;\n\tstatic time_t last_ctld_bu_ping;\n\tstatic time_t last_uid_update;\n\tstatic time_t last_reboot_msg_time;\n\ttime_t now;\n\tint no_resp_msg_interval, ping_interval, purge_job_interval;\n\tint i;\n\tuint32_t job_limit;\n\tDEF_TIMERS;\n\n\t/* Locks: Read config */\n\tslurmctld_lock_t config_read_lock = {\n\t\tREAD_LOCK, NO_LOCK, NO_LOCK, NO_LOCK, NO_LOCK };\n\t/* Locks: Read config, read job */\n\tslurmctld_lock_t job_read_lock = {\n\t\tREAD_LOCK, READ_LOCK, NO_LOCK, NO_LOCK, NO_LOCK };\n\t/* Locks: Read config, write job, write node, read partition */\n\tslurmctld_lock_t job_write_lock = {\n\t\tREAD_LOCK, WRITE_LOCK, WRITE_LOCK, READ_LOCK, READ_LOCK };\n\t/* Locks: Write job */\n\tslurmctld_lock_t job_write_lock2 = {\n\t\tNO_LOCK, WRITE_LOCK, NO_LOCK, NO_LOCK, NO_LOCK };\n\t/* Locks: Read config, write job, write node\n\t * (Might kill jobs on nodes set DOWN) */\n\tslurmctld_lock_t node_write_lock = {\n\t\tREAD_LOCK, WRITE_LOCK, WRITE_LOCK, NO_LOCK, NO_LOCK };\n\t/* Locks: Write node */\n\tslurmctld_lock_t node_write_lock2 = {\n\t\tNO_LOCK, NO_LOCK, WRITE_LOCK, NO_LOCK, NO_LOCK };\n\t/* Locks: Write partition */\n\tslurmctld_lock_t part_write_lock = {\n\t\tNO_LOCK, NO_LOCK, NO_LOCK, WRITE_LOCK, NO_LOCK };\n\t/* Locks: Read job and node */\n\tslurmctld_lock_t job_node_read_lock = {\n\t\tNO_LOCK, READ_LOCK, READ_LOCK, NO_LOCK, NO_LOCK };\n\n\t/* Let the dust settle before doing work */\n\tnow = time(NULL);\n\tlast_sched_time = last_full_sched_time = now;\n\tlast_checkpoint_time = last_group_time = now;\n\tlast_purge_job_time = last_trigger = last_health_check_time = now;\n\tlast_timelimit_time = last_assert_primary_time = now;\n\tlast_no_resp_msg_time = last_resv_time = last_ctld_bu_ping = now;\n\tlast_uid_update = last_reboot_msg_time = now;\n\tlast_acct_gather_node_time = last_ext_sensors_time = now;\n\n\tif ((slurmctld_conf.min_job_age > 0) &&\n\t    (slurmctld_conf.min_job_age < PURGE_JOB_INTERVAL)) {\n\t\t/* Purge jobs more quickly, especially for high job flow */\n\t\tpurge_job_interval = MAX(10, slurmctld_conf.min_job_age);\n\t} else\n\t\tpurge_job_interval = PURGE_JOB_INTERVAL;\n\n\tif (slurmctld_conf.slurmd_timeout) {\n\t\t/* We ping nodes that haven't responded in SlurmdTimeout/3,\n\t\t * but need to do the test at a higher frequency or we might\n\t\t * DOWN nodes with times that fall in the gap. */\n\t\tping_interval = slurmctld_conf.slurmd_timeout / 3;\n\t} else {\n\t\t/* This will just ping non-responding nodes\n\t\t * and restore them to service */\n\t\tping_interval = 100;\t/* 100 seconds */\n\t}\n\tlast_ping_node_time = now + (time_t)MIN_CHECKIN_TIME - ping_interval;\n\tlast_ping_srun_time = now;\n\tlast_node_acct = now;\n\t(void) pthread_setcancelstate(PTHREAD_CANCEL_ENABLE, NULL);\n\t(void) pthread_setcanceltype(PTHREAD_CANCEL_ASYNCHRONOUS, NULL);\n\tdebug3(\"_slurmctld_background pid = %u\", getpid());\n\n\twhile (1) {\n\t\tfor (i = 0; ((i < 10) && (slurmctld_config.shutdown_time == 0));\n\t\t     i++) {\n\t\t\tusleep(100000);\n\t\t}\n\n\t\tnow = time(NULL);\n\t\tSTART_TIMER;\n\n\t\tif (slurmctld_conf.slurmctld_debug <= 3)\n\t\t\tno_resp_msg_interval = 300;\n\t\telse if (slurmctld_conf.slurmctld_debug == 4)\n\t\t\tno_resp_msg_interval = 60;\n\t\telse\n\t\t\tno_resp_msg_interval = 1;\n\n\t\tif (slurmctld_config.shutdown_time) {\n\t\t\tstruct timespec ts = {0, 0};\n\t\t\tstruct timeval now;\n\t\t\t/* wait for RPC's to complete */\n\t\t\tgettimeofday(&now, NULL);\n\t\t\tts.tv_sec = now.tv_sec + CONTROL_TIMEOUT;\n\t\t\tts.tv_nsec = now.tv_usec * 1000;\n\t\t\tslurm_mutex_lock(&slurmctld_config.thread_count_lock);\n\t\t\twhile (slurmctld_config.server_thread_count > 0) {\n\t\t\t\tslurm_cond_timedwait(&server_thread_cond,\n\t\t\t\t\t&slurmctld_config.thread_count_lock,\n\t\t\t\t\t&ts);\n\t\t\t}\n\t\t\tif (slurmctld_config.server_thread_count) {\n\t\t\t\tinfo(\"shutdown server_thread_count=%d\",\n\t\t\t\t\tslurmctld_config.server_thread_count);\n\t\t\t}\n\t\t\tslurm_mutex_unlock(&slurmctld_config.thread_count_lock);\n\n\t\t\tif (_report_locks_set() == 0) {\n\t\t\t\tinfo(\"Saving all slurm state\");\n\t\t\t\tsave_all_state();\n\t\t\t} else {\n\t\t\t\terror(\"Semaphores still set after %d seconds, \"\n\t\t\t\t      \"can not save state\", CONTROL_TIMEOUT);\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\n\t\tif (difftime(now, last_resv_time) >= 5) {\n\t\t\tnow = time(NULL);\n\t\t\tlast_resv_time = now;\n\t\t\tlock_slurmctld(node_write_lock);\n\t\t\tif (set_node_maint_mode(false) > 0)\n\t\t\t\tqueue_job_scheduler();\n\t\t\tunlock_slurmctld(node_write_lock);\n\t\t}\n\n\t\tif (difftime(now, last_no_resp_msg_time) >=\n\t\t    no_resp_msg_interval) {\n\t\t\tnow = time(NULL);\n\t\t\tlast_no_resp_msg_time = now;\n\t\t\tlock_slurmctld(node_write_lock2);\n\t\t\tnode_no_resp_msg();\n\t\t\tunlock_slurmctld(node_write_lock2);\n\t\t}\n\n\t\tif (difftime(now, last_timelimit_time) >= PERIODIC_TIMEOUT) {\n\t\t\tnow = time(NULL);\n\t\t\tlast_timelimit_time = now;\n\t\t\tdebug2(\"Testing job time limits and checkpoints\");\n\t\t\tlock_slurmctld(job_write_lock);\n\t\t\tjob_time_limit();\n\t\t\tjob_resv_check();\n\t\t\tstep_checkpoint();\n\t\t\tunlock_slurmctld(job_write_lock);\n\t\t}\n\n\t\tif (slurmctld_conf.health_check_interval &&\n\t\t    (difftime(now, last_health_check_time) >=\n\t\t     slurmctld_conf.health_check_interval) &&\n\t\t    is_ping_done()) {\n\t\t\tif (slurmctld_conf.health_check_node_state &\n\t\t\t     HEALTH_CHECK_CYCLE) {\n\t\t\t\t/* Call run_health_check() on each cycle */\n\t\t\t} else {\n\t\t\t\tnow = time(NULL);\n\t\t\t\tlast_health_check_time = now;\n\t\t\t}\n\t\t\tlock_slurmctld(node_write_lock);\n\t\t\trun_health_check();\n\t\t\tunlock_slurmctld(node_write_lock);\n\t\t}\n\n\t\tif (slurmctld_conf.acct_gather_node_freq &&\n\t\t    (difftime(now, last_acct_gather_node_time) >=\n\t\t     slurmctld_conf.acct_gather_node_freq) &&\n\t\t    is_ping_done()) {\n\t\t\tnow = time(NULL);\n\t\t\tlast_acct_gather_node_time = now;\n\t\t\tlock_slurmctld(node_write_lock);\n\t\t\tupdate_nodes_acct_gather_data();\n\t\t\tunlock_slurmctld(node_write_lock);\n\t\t}\n\n\t\tif (slurmctld_conf.ext_sensors_freq &&\n\t\t    (difftime(now, last_ext_sensors_time) >=\n\t\t     slurmctld_conf.ext_sensors_freq) &&\n\t\t    is_ping_done()) {\n\t\t\tnow = time(NULL);\n\t\t\tlast_ext_sensors_time = now;\n\t\t\tlock_slurmctld(node_write_lock);\n\t\t\text_sensors_g_update_component_data();\n\t\t\tunlock_slurmctld(node_write_lock);\n\t\t}\n\n\t\tif (((difftime(now, last_ping_node_time) >= ping_interval) ||\n\t\t     ping_nodes_now) && is_ping_done()) {\n\t\t\tnow = time(NULL);\n\t\t\tlast_ping_node_time = now;\n\t\t\tping_nodes_now = false;\n\t\t\tlock_slurmctld(node_write_lock);\n\t\t\tping_nodes();\n\t\t\tunlock_slurmctld(node_write_lock);\n\t\t}\n\n\t\tif (slurmctld_conf.inactive_limit &&\n\t\t    ((now - last_ping_srun_time) >=\n\t\t     (slurmctld_conf.inactive_limit / 3))) {\n\t\t\tnow = time(NULL);\n\t\t\tlast_ping_srun_time = now;\n\t\t\tdebug2(\"Performing srun ping\");\n\t\t\tlock_slurmctld(job_read_lock);\n\t\t\tsrun_ping();\n\t\t\tunlock_slurmctld(job_read_lock);\n\t\t}\n\n\t\tif (want_nodes_reboot && (now > last_reboot_msg_time)) {\n\t\t\tnow = time(NULL);\n\t\t\tlast_reboot_msg_time = now;\n\t\t\tlock_slurmctld(node_write_lock);\n\t\t\t_queue_reboot_msg();\n\t\t\tunlock_slurmctld(node_write_lock);\n\t\t}\n\n\t\t/* Process any pending agent work */\n\t\tagent_trigger(RPC_RETRY_INTERVAL, true);\n\n\t\tif (slurmctld_conf.group_time &&\n\t\t    (difftime(now, last_group_time)\n\t\t     >= slurmctld_conf.group_time)) {\n\t\t\tnow = time(NULL);\n\t\t\tlast_group_time = now;\n\t\t\tlock_slurmctld(part_write_lock);\n\t\t\tload_part_uid_allow_list(slurmctld_conf.group_force);\n\t\t\tunlock_slurmctld(part_write_lock);\n\t\t\tgroup_cache_cleanup();\n\t\t}\n\n\t\tif (difftime(now, last_purge_job_time) >= purge_job_interval) {\n\t\t\tnow = time(NULL);\n\t\t\tlast_purge_job_time = now;\n\t\t\tdebug2(\"Performing purge of old job records\");\n\t\t\tlock_slurmctld(job_write_lock);\n\t\t\tpurge_old_job();\n\t\t\tunlock_slurmctld(job_write_lock);\n\t\t}\n\n\t\tjob_limit = NO_VAL;\n\t\tif (difftime(now, last_full_sched_time) >= sched_interval) {\n\t\t\tslurm_mutex_lock(&sched_cnt_mutex);\n\t\t\t/* job_limit = job_sched_cnt;\tIgnored */\n\t\t\tjob_limit = INFINITE;\n\t\t\tjob_sched_cnt = 0;\n\t\t\tslurm_mutex_unlock(&sched_cnt_mutex);\n\t\t\tlast_full_sched_time = now;\n\t\t} else {\n\t\t\tslurm_mutex_lock(&sched_cnt_mutex);\n\t\t\tif (job_sched_cnt &&\n\t\t\t    (difftime(now, last_sched_time) >=\n\t\t\t     batch_sched_delay)) {\n\t\t\t\tjob_limit = 0;\t/* Default depth */\n\t\t\t\tjob_sched_cnt = 0;\n\t\t\t}\n\t\t\tslurm_mutex_unlock(&sched_cnt_mutex);\n\t\t}\n\t\tif (job_limit != NO_VAL) {\n\t\t\tnow = time(NULL);\n\t\t\tlast_sched_time = now;\n\t\t\tlock_slurmctld(job_write_lock2);\n\t\t\tbb_g_load_state(false);\t/* May alter job nice/prio */\n\t\t\tunlock_slurmctld(job_write_lock2);\n\t\t\tif (schedule(job_limit))\n\t\t\t\tlast_checkpoint_time = 0; /* force state save */\n\t\t\tset_job_elig_time();\n\t\t}\n\n\t\tif (slurmctld_conf.slurmctld_timeout &&\n\t\t    (difftime(now, last_ctld_bu_ping) >\n\t\t     slurmctld_conf.slurmctld_timeout)) {\n\t\t\tif (_ping_backup_controller() != SLURM_SUCCESS)\n\t\t\t\ttrigger_backup_ctld_fail();\n\t\t\tlast_ctld_bu_ping = now;\n\t\t}\n\n\t\tif (difftime(now, last_trigger) > TRIGGER_INTERVAL) {\n\t\t\tnow = time(NULL);\n\t\t\tlast_trigger = now;\n\t\t\tlock_slurmctld(job_node_read_lock);\n\t\t\ttrigger_process();\n\t\t\tunlock_slurmctld(job_node_read_lock);\n\t\t}\n\n\t\tif (difftime(now, last_checkpoint_time) >=\n\t\t    PERIODIC_CHECKPOINT) {\n\t\t\tnow = time(NULL);\n\t\t\tlast_checkpoint_time = now;\n\t\t\tdebug2(\"Performing full system state save\");\n\t\t\tsave_all_state();\n\t\t}\n\n\t\tif (difftime(now, last_node_acct) >= PERIODIC_NODE_ACCT) {\n\t\t\t/* Report current node state to account for added\n\t\t\t * or reconfigured nodes.  Locks are done\n\t\t\t * inside _accounting_cluster_ready, don't\n\t\t\t * lock here. */\n\t\t\tnow = time(NULL);\n\t\t\tlast_node_acct = now;\n\t\t\t_accounting_cluster_ready();\n\t\t}\n\n\t\tif (difftime(now, slurmctld_running_job_count_ts) >=\n\t\t    JOB_COUNT_INTERVAL) {\n\t\t\tnow = time(NULL);\n\t\t\tlock_slurmctld(job_read_lock);\n\t\t\tslurmctld_running_job_count_ts = now;\n\t\t\tslurmctld_running_job_count    = _running_jobs_count();\n\t\t\tunlock_slurmctld(job_read_lock);\n\t\t}\n\n\t\t/* Stats will reset at midnight (approx) local time. */\n\t\tif (last_proc_req_start == 0) {\n\t\t\tlast_proc_req_start = now;\n\t\t\tnext_stats_reset = now - (now % 86400) + 86400;\n\t\t} else if (now >= next_stats_reset) {\n\t\t\tnext_stats_reset = now - (now % 86400) + 86400;\n\t\t\treset_stats(0);\n\t\t}\n\n\t\t/* Reassert this machine as the primary controller.\n\t\t * A network or security problem could result in\n\t\t * the backup controller assuming control even\n\t\t * while the real primary controller is running */\n\t\tlock_slurmctld(config_read_lock);\n\t\tif (slurmctld_conf.slurmctld_timeout   &&\n\t\t    slurmctld_conf.backup_addr         &&\n\t\t    slurmctld_conf.backup_addr[0]      &&\n\t\t    (difftime(now, last_assert_primary_time) >=\n\t\t     slurmctld_conf.slurmctld_timeout) &&\n\t\t    slurmctld_conf.backup_controller &&\n\t\t    xstrcmp(node_name_short,slurmctld_conf.backup_controller) &&\n\t\t    xstrcmp(node_name_long, slurmctld_conf.backup_controller)) {\n\t\t\tnow = time(NULL);\n\t\t\tlast_assert_primary_time = now;\n\t\t\t(void) _shutdown_backup_controller(0);\n\t\t}\n\t\tunlock_slurmctld(config_read_lock);\n\n\t\tif (difftime(now, last_uid_update) >= 3600) {\n\t\t\t/* Make sure we update the uids in the\n\t\t\t * assoc_mgr if there were any users\n\t\t\t * with unknown uids at the time of startup.\n\t\t\t */\n\t\t\tnow = time(NULL);\n\t\t\tlast_uid_update = now;\n\t\t\tassoc_mgr_set_missing_uids();\n\t\t}\n\n\t\tEND_TIMER2(\"_slurmctld_background\");\n\t}\n\n\tdebug3(\"_slurmctld_background shutting down\");\n\n\treturn NULL;\n}\n\n/* save_all_state - save entire slurmctld state for later recovery */\nextern void save_all_state(void)\n{\n\t/* Each of these functions lock their own databases */\n\tschedule_front_end_save();\n\tschedule_job_save();\n\tschedule_node_save();\n\tschedule_part_save();\n\tschedule_resv_save();\n\tschedule_trigger_save();\n\n\tselect_g_state_save(slurmctld_conf.state_save_location);\n\tdump_assoc_mgr_state(slurmctld_conf.state_save_location);\n\tfed_mgr_state_save(slurmctld_conf.state_save_location);\n}\n\n/* make sure the assoc_mgr is up and running with the most current state */\nextern void ctld_assoc_mgr_init(slurm_trigger_callbacks_t *callbacks)\n{\n\tassoc_init_args_t assoc_init_arg;\n\tint num_jobs = 0;\n\tslurmctld_lock_t job_read_lock =\n\t\t{ NO_LOCK, READ_LOCK, NO_LOCK, NO_LOCK, NO_LOCK };\n\n\tmemset(&assoc_init_arg, 0, sizeof(assoc_init_args_t));\n\tassoc_init_arg.enforce = accounting_enforce;\n\tassoc_init_arg.add_license_notify = license_add_remote;\n\tassoc_init_arg.resize_qos_notify = _resize_qos;\n\tassoc_init_arg.remove_assoc_notify = _remove_assoc;\n\tassoc_init_arg.remove_license_notify = license_remove_remote;\n\tassoc_init_arg.remove_qos_notify = _remove_qos;\n\tassoc_init_arg.sync_license_notify = license_sync_remote;\n\tassoc_init_arg.update_assoc_notify = _update_assoc;\n\tassoc_init_arg.update_license_notify = license_update_remote;\n\tassoc_init_arg.update_qos_notify = _update_qos;\n\tassoc_init_arg.update_cluster_tres = _update_cluster_tres;\n\tassoc_init_arg.update_resvs = update_assocs_in_resvs;\n\tassoc_init_arg.cache_level = ASSOC_MGR_CACHE_ASSOC |\n\t\t\t\t     ASSOC_MGR_CACHE_USER  |\n\t\t\t\t     ASSOC_MGR_CACHE_QOS   |\n\t\t\t\t     ASSOC_MGR_CACHE_RES   |\n                         \t     ASSOC_MGR_CACHE_TRES;\n\tif (slurmctld_conf.track_wckey)\n\t\tassoc_init_arg.cache_level |= ASSOC_MGR_CACHE_WCKEY;\n\n\t/* Don't save state but blow away old lists if they exist. */\n\tassoc_mgr_fini(NULL);\n\n\tif (acct_db_conn)\n\t\tacct_storage_g_close_connection(&acct_db_conn);\n\n\tacct_db_conn = acct_storage_g_get_connection(callbacks, 0, false,\n\t\t\t\t\t\t     slurmctld_conf.cluster_name);\n\n\tif (assoc_mgr_init(acct_db_conn, &assoc_init_arg, errno)) {\n\t\tif (accounting_enforce & ACCOUNTING_ENFORCE_ASSOCS)\n\t\t\terror(\"Association database appears down, \"\n\t\t\t      \"reading from state file.\");\n\t\telse\n\t\t\tdebug(\"Association database appears down, \"\n\t\t\t      \"reading from state file.\");\n\n\t\tif ((load_assoc_mgr_state(slurmctld_conf.state_save_location)\n\t\t     != SLURM_SUCCESS)\n\t\t    && (accounting_enforce & ACCOUNTING_ENFORCE_ASSOCS)) {\n\t\t\terror(\"Unable to get any information from \"\n\t\t\t      \"the state file\");\n\t\t\tfatal(\"slurmdbd and/or database must be up at \"\n\t\t\t      \"slurmctld start time\");\n\t\t}\n\t}\n\n\t/* Now load the usage from a flat file since it isn't kept in\n\t   the database\n\t*/\n\tload_assoc_usage(slurmctld_conf.state_save_location);\n\tload_qos_usage(slurmctld_conf.state_save_location);\n\n\tlock_slurmctld(job_read_lock);\n\tif (job_list)\n\t\tnum_jobs = list_count(job_list);\n\tunlock_slurmctld(job_read_lock);\n\n\t_init_tres();\n\n\t/* This thread is looking for when we get correct data from\n\t   the database so we can update the assoc_ptr's in the jobs\n\t*/\n\tif (running_cache || num_jobs) {\n\t\tslurm_thread_create(&assoc_cache_thread,\n\t\t\t\t    _assoc_cache_mgr, NULL);\n\t}\n\n}\n\n/* send all info for the controller to accounting */\nextern void send_all_to_accounting(time_t event_time, int db_rc)\n{\n\t/* ignore the rcs here because if there was an error we will\n\t   push the requests on the queue and process them when the\n\t   database server comes back up.\n\t*/\n\tdebug2(\"send_all_to_accounting: called %s\", rpc_num2string(db_rc));\n\tswitch (db_rc) {\n\tcase ACCOUNTING_FIRST_REG:\n\tcase ACCOUNTING_NODES_CHANGE_DB:\n\t\tsend_jobs_to_accounting();\n\t\tsend_resvs_to_accounting(db_rc);\n\t\t/* fall through */\n\tcase ACCOUNTING_TRES_CHANGE_DB:\n\t\t/* No need to do jobs or resvs when only the TRES change. */\n\t\tsend_nodes_to_accounting(event_time);\n\t\tbreak;\n\tdefault:\n\t\terror(\"unknown rc of %d given\", db_rc);\n\t}\n}\n\nstatic int _add_node_gres_tres(void *x, void *arg)\n{\n\tuint64_t gres_cnt;\n\tint tres_pos;\n\tslurmdb_tres_rec_t *tres_rec_in = (slurmdb_tres_rec_t *)x;\n\tstruct node_record *node_ptr = (struct node_record *)arg;\n\n\txassert(tres_rec_in);\n\n\tif (xstrcmp(tres_rec_in->type, \"gres\"))\n\t\treturn 0;\n\n\tgres_cnt = gres_plugin_node_config_cnt(node_ptr->gres_list,\n\t\t\t\t\t       tres_rec_in->name);\n\tif ((tres_pos = assoc_mgr_find_tres_pos(tres_rec_in, true)) != -1)\n\t\tnode_ptr->tres_cnt[tres_pos] = gres_cnt;\n\n\treturn 0;\n}\n\n/*\n * Set the node's billing tres to the highest billing of all partitions that the\n * node is a part of.\n */\nstatic void _set_node_billing_tres(struct node_record *node_ptr,\n\t\t\t\t   uint64_t cpu_count,\n\t\t\t\t   bool assoc_mgr_locked)\n{\n\tint i;\n\tstruct part_record *part_ptr = NULL;\n\tdouble max_billing = 0;\n\txassert(node_ptr);\n\n\tfor (i = 0; i < node_ptr->part_cnt; i++) {\n\t\tdouble tmp_billing;\n\t\tpart_ptr = node_ptr->part_pptr[i];\n\t\tif (!part_ptr->billing_weights)\n\t\t\tcontinue;\n\n\t\ttmp_billing = assoc_mgr_tres_weighted(node_ptr->tres_cnt,\n\t\t\t\t\t\tpart_ptr->billing_weights,\n\t\t\t\t\t\tslurmctld_conf.priority_flags,\n\t\t\t\t\t\tassoc_mgr_locked);\n\t\tmax_billing = MAX(max_billing, tmp_billing);\n\t}\n\n\t/* Set to the configured cpu_count if no partition has\n\t * tresbillingweights set because the job will be allocated the job's\n\t * cpu count if there are no tresbillingweights defined. */\n\tif (!max_billing)\n\t\tmax_billing = cpu_count;\n\tnode_ptr->tres_cnt[TRES_ARRAY_BILLING] = max_billing;\n}\n\n/*\n * A slurmctld lock needs to at least have a node and partition write lock set\n * before this is called\n */\nextern void set_cluster_tres(bool assoc_mgr_locked)\n{\n\tstruct node_record *node_ptr;\n\tslurmdb_tres_rec_t *tres_rec, *cpu_tres = NULL, *mem_tres = NULL;\n\tint i;\n\tuint64_t cluster_billing = 0;\n\tchar *unique_tres = NULL;\n\tassoc_mgr_lock_t locks = { NO_LOCK, NO_LOCK, NO_LOCK, NO_LOCK,\n\t\t\t\t   WRITE_LOCK, NO_LOCK, NO_LOCK };\n\n\tif (!assoc_mgr_locked)\n\t\tassoc_mgr_lock(&locks);\n\n\txassert(assoc_mgr_tres_array);\n\n\tfor (i=0; i < g_tres_count; i++) {\n\t\ttres_rec = assoc_mgr_tres_array[i];\n\n\t\tif (!tres_rec->type) {\n\t\t\terror(\"TRES %d doesn't have a type given, \"\n\t\t\t      \"this should never happen\",\n\t\t\t      tres_rec->id);\n\t\t\tcontinue; /* this should never happen */\n\t\t}\n\n\t\tif (unique_tres)\n\t\t\txstrfmtcat(unique_tres, \",%s\",\n\t\t\t\t   assoc_mgr_tres_name_array[i]);\n\t\telse\n\t\t\tunique_tres = xstrdup(assoc_mgr_tres_name_array[i]);\n\n\n\t\t/* reset them now since we are about to add to them */\n\t\ttres_rec->count = 0;\n\t\tif (tres_rec->id == TRES_CPU) {\n\t\t\tcpu_tres = tres_rec;\n\t\t\tcontinue;\n\t\t} else if (tres_rec->id == TRES_MEM) {\n\t\t\tmem_tres = tres_rec;\n\t\t\tcontinue;\n\t\t} else if (!xstrcmp(tres_rec->type, \"bb\")) {\n\t\t\ttres_rec->count = bb_g_get_system_size(tres_rec->name);\n\t\t\tcontinue;\n\t\t} else if (!xstrcmp(tres_rec->type, \"gres\")) {\n\t\t\ttres_rec->count = gres_get_system_cnt(tres_rec->name);\n\t\t\tcontinue;\n\t\t} else if (!xstrcmp(tres_rec->type, \"license\")) {\n\t\t\ttres_rec->count = get_total_license_cnt(\n\t\t\t\ttres_rec->name);\n\t\t\tcontinue;\n\t\t}\n\t\t/* FIXME: set up the other tres here that aren't specific */\n\t}\n\n\tslurm_set_accounting_storage_tres(unique_tres);\n\txfree(unique_tres);\n\n\tcluster_cpus = 0;\n\n\tnode_ptr = node_record_table_ptr;\n\tfor (i = 0; i < node_record_count; i++, node_ptr++) {\n\t\tuint64_t cpu_count = 0, mem_count = 0;\n\t\tif (!node_ptr->name)\n\t\t\tcontinue;\n\n\t\tif (slurmctld_conf.fast_schedule) {\n\t\t\tcpu_count += node_ptr->config_ptr->cpus;\n\t\t\tmem_count += node_ptr->config_ptr->real_memory;\n\t\t} else {\n\t\t\tcpu_count += node_ptr->cpus;\n\t\t\tmem_count += node_ptr->real_memory;\n\t\t}\n\n\t\tcluster_cpus += cpu_count;\n\t\tif (mem_tres)\n\t\t\tmem_tres->count += mem_count;\n\n\t\tif (!node_ptr->tres_cnt)\n\t\t\tnode_ptr->tres_cnt = xmalloc(sizeof(uint64_t) *\n\t\t\t\t\t\t     slurmctld_tres_cnt);\n\t\tnode_ptr->tres_cnt[TRES_ARRAY_CPU] = cpu_count;\n\t\tnode_ptr->tres_cnt[TRES_ARRAY_MEM] = mem_count;\n\n\t\tlist_for_each(assoc_mgr_tres_list,\n\t\t\t      _add_node_gres_tres, node_ptr);\n\n\t\t_set_node_billing_tres(node_ptr, cpu_count, true);\n\t\tcluster_billing += node_ptr->tres_cnt[TRES_ARRAY_BILLING];\n\n\t\txfree(node_ptr->tres_str);\n\t\tnode_ptr->tres_str =\n\t\t\tassoc_mgr_make_tres_str_from_array(node_ptr->tres_cnt,\n\t\t\t\t\t\t\t   TRES_STR_FLAG_SIMPLE,\n\t\t\t\t\t\t\t   true);\n\t\txfree(node_ptr->tres_fmt_str);\n\t\tnode_ptr->tres_fmt_str =\n\t\t\tassoc_mgr_make_tres_str_from_array(\n\t\t\t\tnode_ptr->tres_cnt,\n\t\t\t\tTRES_STR_CONVERT_UNITS,\n\t\t\t\ttrue);\n\t}\n\n\t/* FIXME: cluster_cpus probably needs to be removed and handled\n\t * differently in the spots this is used.\n\t */\n\tif (cpu_tres)\n\t\tcpu_tres->count = cluster_cpus;\n\n\tassoc_mgr_tres_array[TRES_ARRAY_NODE]->count = node_record_count;\n\tassoc_mgr_tres_array[TRES_ARRAY_BILLING]->count = cluster_billing;\n\n\tset_partition_tres();\n\n\tif (!assoc_mgr_locked)\n\t\tassoc_mgr_unlock(&locks);\n}\n\n/*\n * _report_locks_set - report any slurmctld locks left set\n * RET count of locks currently set\n */\nstatic int _report_locks_set(void)\n{\n\tslurmctld_lock_flags_t lock_flags;\n\tchar config[4] = \"\", job[4] = \"\", node[4] = \"\", partition[4] = \"\";\n\tint lock_count;\n\n\tget_lock_values(&lock_flags);\n\n\tif (lock_flags.entity[read_lock(CONFIG_LOCK)])\n\t\tstrcat(config, \"R\");\n\tif (lock_flags.entity[write_lock(CONFIG_LOCK)])\n\t\tstrcat(config, \"W\");\n\tif (lock_flags.entity[write_wait_lock(CONFIG_LOCK)])\n\t\tstrcat(config, \"P\");\n\n\tif (lock_flags.entity[read_lock(JOB_LOCK)])\n\t\tstrcat(job, \"R\");\n\tif (lock_flags.entity[write_lock(JOB_LOCK)])\n\t\tstrcat(job, \"W\");\n\tif (lock_flags.entity[write_wait_lock(JOB_LOCK)])\n\t\tstrcat(job, \"P\");\n\n\tif (lock_flags.entity[read_lock(NODE_LOCK)])\n\t\tstrcat(node, \"R\");\n\tif (lock_flags.entity[write_lock(NODE_LOCK)])\n\t\tstrcat(node, \"W\");\n\tif (lock_flags.entity[write_wait_lock(NODE_LOCK)])\n\t\tstrcat(node, \"P\");\n\n\tif (lock_flags.entity[read_lock(PART_LOCK)])\n\t\tstrcat(partition, \"R\");\n\tif (lock_flags.entity[write_lock(PART_LOCK)])\n\t\tstrcat(partition, \"W\");\n\tif (lock_flags.entity[write_wait_lock(PART_LOCK)])\n\t\tstrcat(partition, \"P\");\n\n\tlock_count = strlen(config) + strlen(job) +\n\t    strlen(node) + strlen(partition);\n\tif (lock_count > 0) {\n\t\terror(\"Locks left set \"\n\t\t      \"config:%s, job:%s, node:%s, partition:%s\",\n\t\t      config, job, node, partition);\n\t}\n\treturn lock_count;\n}\n\n/*\n * slurmctld_shutdown - wake up slurm_rpc_mgr thread via signal\n * RET 0 or error code\n */\nint slurmctld_shutdown(void)\n{\n\tdebug(\"sched: slurmctld terminating\");\n\tif (slurmctld_config.thread_id_rpc) {\n\t\tpthread_kill(slurmctld_config.thread_id_rpc, SIGUSR1);\n\t\treturn SLURM_SUCCESS;\n\t} else {\n\t\terror(\"thread_id_rpc not set\");\n\t\treturn SLURM_ERROR;\n\t}\n}\n\n/* Variables for commandline passing using getopt */\nextern char *optarg;\nextern int optind, opterr, optopt;\n\n/*\n * _parse_commandline - parse and process any command line arguments\n * IN argc - number of command line arguments\n * IN argv - the command line arguments\n * IN/OUT conf_ptr - pointer to current configuration, update as needed\n */\nstatic void _parse_commandline(int argc, char **argv)\n{\n\tint c = 0;\n\tchar *tmp_char;\n\tbool bg_recover_override = 0;\n\n\topterr = 0;\n\twhile ((c = getopt(argc, argv, \"BcdDf:hiL:n:rRvV\")) != -1)\n\t\tswitch (c) {\n\t\tcase 'B':\n\t\t\tbg_recover = 0;\n\t\t\tbg_recover_override = 1;\n\t\t\tbreak;\n\t\tcase 'c':\n\t\t\trecover = 0;\n\t\t\tbg_recover = 0;\n\t\t\tbreak;\n\t\tcase 'd':\n\t\t\tdaemonize = 1;\n\t\t\tbreak;\n\t\tcase 'D':\n\t\t\tdaemonize = 0;\n\t\t\tbreak;\n\t\tcase 'f':\n\t\t\txfree(slurm_conf_filename);\n\t\t\tslurm_conf_filename = xstrdup(optarg);\n\t\t\tbreak;\n\t\tcase 'h':\n\t\t\t_usage(argv[0]);\n\t\t\texit(0);\n\t\t\tbreak;\n\t\tcase 'i':\n\t\t\tignore_state_errors = true;\n\t\t\tbreak;\n\t\tcase 'L':\n\t\t\txfree(debug_logfile);\n\t\t\tdebug_logfile = xstrdup(optarg);\n\t\t\tbreak;\n\t\tcase 'n':\n\t\t\tnew_nice = strtol(optarg, &tmp_char, 10);\n\t\t\tif (tmp_char[0] != '\\0') {\n\t\t\t\terror(\"Invalid option for -n option (nice \"\n\t\t\t\t      \"value), ignored\");\n\t\t\t\tnew_nice = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 'r':\n\t\t\trecover = 1;\n\t\t\tif (!bg_recover_override)\n\t\t\t\tbg_recover = 1;\n\t\t\tbreak;\n\t\tcase 'R':\n\t\t\trecover = 2;\n\t\t\tif (!bg_recover_override)\n\t\t\t\tbg_recover = 1;\n\t\t\tbreak;\n\t\tcase 'v':\n\t\t\tdebug_level++;\n\t\t\tbreak;\n\t\tcase 'V':\n\t\t\tprint_slurm_version();\n\t\t\texit(0);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\t_usage(argv[0]);\n\t\t\texit(1);\n\t\t}\n}\n\n/* _usage - print a message describing the command line arguments of\n *\tslurmctld */\nstatic void _usage(char *prog_name)\n{\n\tfprintf(stderr, \"Usage: %s [OPTIONS]\\n\", prog_name);\n#ifdef HAVE_BG\n\tfprintf(stderr, \"  -B      \"\n\t\t\t\"\\tDo not recover state of bluegene blocks.\\n\");\n#endif\n#if (DEFAULT_RECOVER != 0)\n\tfprintf(stderr, \"  -c      \"\n\t\t\t\"\\tDo not recover state from last checkpoint.\\n\");\n#endif\n#if (DEFAULT_DAEMONIZE == 0)\n\tfprintf(stderr, \"  -d      \"\n\t\t\t\"\\tRun daemon in background.\\n\");\n#endif\n#if (DEFAULT_DAEMONIZE != 0)\n\tfprintf(stderr, \"  -D      \"\n\t\t\t\"\\tRun daemon in foreground.\\n\");\n#endif\n\tfprintf(stderr, \"  -f file \"\n\t\t\t\"\\tUse specified file for slurmctld configuration.\\n\");\n\tfprintf(stderr, \"  -h      \"\n\t\t\t\"\\tPrint this help message.\\n\");\n\tfprintf(stderr, \"  -L logfile \"\n\t\t\t\"\\tLog messages to the specified file.\\n\");\n\tfprintf(stderr, \"  -n value \"\n\t\t\t\"\\tRun the daemon at the specified nice value.\\n\");\n#if (DEFAULT_RECOVER == 0)\n\tfprintf(stderr, \"  -r      \"\n\t\t\t\"\\tRecover state from last checkpoint.\\n\");\n#else\n\tfprintf(stderr, \"  -R      \"\n\t\t\t\"\\tRecover full state from last checkpoint.\\n\");\n#endif\n\tfprintf(stderr, \"  -v      \"\n\t\t\t\"\\tVerbose mode. Multiple -v's increase verbosity.\\n\");\n\tfprintf(stderr, \"  -V      \"\n\t\t\t\"\\tPrint version information and exit.\\n\");\n}\n\n/*\n * Tell the backup_controller to relinquish control, primary control_machine\n *\thas resumed operation\n * wait_time - How long to wait for backup controller to write state, seconds.\n *             Must be zero when called from _slurmctld_background() loop.\n * RET 0 or an error code\n * NOTE: READ lock_slurmctld config before entry (or be single-threaded)\n */\nstatic int _shutdown_backup_controller(int wait_time)\n{\n\tint rc;\n\tslurm_msg_t req;\n\n\tslurm_msg_t_init(&req);\n\tif ((slurmctld_conf.backup_addr == NULL) ||\n\t    (slurmctld_conf.backup_addr[0] == '\\0')) {\n\t\tdebug(\"No backup controller to shutdown\");\n\t\treturn SLURM_SUCCESS;\n\t}\n\n\tslurm_set_addr(&req.address, slurmctld_conf.slurmctld_port,\n\t\t       slurmctld_conf.backup_addr);\n\n\t/* send request message */\n\treq.msg_type = REQUEST_CONTROL;\n\n\tif (slurm_send_recv_rc_msg_only_one(&req, &rc,\n\t\t\t\t(CONTROL_TIMEOUT * 1000)) < 0) {\n\t\terror(\"_shutdown_backup_controller:send/recv: %m\");\n\t\treturn SLURM_ERROR;\n\t}\n\tif (rc == ESLURM_DISABLED)\n\t\tdebug(\"backup controller responding\");\n\telse if (rc == 0) {\n\t\tdebug(\"backup controller has relinquished control\");\n\t\tif (wait_time == 0) {\n\t\t\t/* In case primary controller really did not terminate,\n\t\t\t * but just temporarily became non-responsive */\n\t\t\tclusteracct_storage_g_register_ctld(\n\t\t\t\tacct_db_conn,\n\t\t\t\tslurmctld_conf.slurmctld_port);\n\t\t}\n\t} else {\n\t\terror(\"_shutdown_backup_controller: %s\", slurm_strerror(rc));\n\t\treturn SLURM_ERROR;\n\t}\n\n\t/* FIXME: Ideally the REQUEST_CONTROL RPC does not return until all\n\t * other activity has ceased and the state has been saved. That is\n\t * not presently the case (it returns when no other work is pending,\n\t * so the state save should occur right away). We sleep for a while\n\t * here and give the backup controller time to shutdown */\n\tif (wait_time)\n\t\tsleep(wait_time);\n\n\treturn SLURM_SUCCESS;\n}\n\n/* Reset the job credential key based upon configuration parameters\n * NOTE: READ lock_slurmctld config before entry */\nstatic void _update_cred_key(void)\n{\n\tslurm_cred_ctx_key_update(slurmctld_config.cred_ctx,\n\t\t\t\t  slurmctld_conf.job_credential_private_key);\n}\n\n/* Reset slurmctld logging based upon configuration parameters\n *   uses common slurmctld_conf data structure\n * NOTE: READ lock_slurmctld config before entry */\nvoid update_logging(void)\n{\n\tint rc;\n\tuid_t slurm_user_id  = slurmctld_conf.slurm_user_id;\n\tgid_t slurm_user_gid = gid_from_uid(slurm_user_id);\n\n\t/* Preserve execute line arguments (if any) */\n\tif (debug_level) {\n\t\tslurmctld_conf.slurmctld_debug = MIN(\n\t\t\t(LOG_LEVEL_INFO + debug_level),\n\t\t\t(LOG_LEVEL_END - 1));\n\t}\n\tif (slurmctld_conf.slurmctld_debug != NO_VAL16) {\n\t\tlog_opts.stderr_level  = slurmctld_conf.slurmctld_debug;\n\t\tlog_opts.logfile_level = slurmctld_conf.slurmctld_debug;\n\t\tlog_opts.syslog_level  = slurmctld_conf.slurmctld_debug;\n\t}\n\tif (debug_logfile) {\n\t\txfree(slurmctld_conf.slurmctld_logfile);\n\t\tslurmctld_conf.slurmctld_logfile = xstrdup(debug_logfile);\n\t}\n\n\tif (daemonize) {\n\t\tlog_opts.stderr_level = LOG_LEVEL_QUIET;\n\t\tif (!slurmctld_conf.slurmctld_logfile &&\n\t\t    (slurmctld_conf.slurmctld_syslog_debug == LOG_LEVEL_QUIET)){\n\t\t\t/* Ensure fatal errors get logged somewhere */\n\t\t\tlog_opts.syslog_level = LOG_LEVEL_FATAL;\n\t\t} else {\n\t\t\tlog_opts.syslog_level =\n\t\t\t\tslurmctld_conf.slurmctld_syslog_debug;\n\t\t}\n\t} else\n\t\tlog_opts.syslog_level = LOG_LEVEL_QUIET;\n\n\tlog_alter(log_opts, SYSLOG_FACILITY_DAEMON,\n\t\t  slurmctld_conf.slurmctld_logfile);\n\n\tlog_set_timefmt(slurmctld_conf.log_fmt);\n\n\tdebug(\"Log file re-opened\");\n\n\t/*\n\t * SchedLogLevel restore\n\t */\n\tif (slurmctld_conf.sched_log_level != NO_VAL16)\n\t\tsched_log_opts.logfile_level = slurmctld_conf.sched_log_level;\n\n\tsched_log_alter(sched_log_opts, LOG_DAEMON,\n\t\t\tslurmctld_conf.sched_logfile);\n\n\tif (slurmctld_conf.slurmctld_logfile) {\n\t\trc = chown(slurmctld_conf.slurmctld_logfile,\n\t\t\t   slurm_user_id, slurm_user_gid);\n\t\tif (rc && daemonize) {\n\t\t\terror(\"chown(%s, %d, %d): %m\",\n\t\t\t      slurmctld_conf.slurmctld_logfile,\n\t\t\t      (int) slurm_user_id, (int) slurm_user_gid);\n\t\t}\n\t}\n\tif (slurmctld_conf.sched_logfile) {\n\t\trc = chown(slurmctld_conf.sched_logfile,\n\t\t\t   slurm_user_id, slurm_user_gid);\n\t\tif (rc && daemonize) {\n\t\t\terror(\"chown(%s, %d, %d): %m\",\n\t\t\t      slurmctld_conf.sched_logfile,\n\t\t\t      (int) slurm_user_id, (int) slurm_user_gid);\n\t\t}\n\t}\n}\n\n/* Reset slurmd nice value */\nstatic void _update_nice(void)\n{\n\tint cur_nice;\n\tid_t pid;\n\n\tif (new_nice == 0)\t/* No change */\n\t\treturn;\n\n\tpid = getpid();\n\tcur_nice = getpriority(PRIO_PROCESS, pid);\n\tif (cur_nice == new_nice)\n\t\treturn;\n\tif (setpriority(PRIO_PROCESS, pid, new_nice))\n\t\terror(\"Unable to reset nice value to %d: %m\", new_nice);\n}\n\n/* Verify that ClusterName from slurm.conf matches the state directory.\n * If mismatched exit to protect state files from corruption.\n * If the clustername file does not exist, return true so we can create it later\n * after dropping privileges. */\nstatic bool _verify_clustername(void)\n{\n\tFILE *fp;\n\tchar *filename = NULL;\n\tchar name[512] = {0};\n\tbool create_file = false;\n\n\txstrfmtcat(filename, \"%s/clustername\",\n\t\t   slurmctld_conf.state_save_location);\n\n\tif ((fp = fopen(filename, \"r\"))) {\n\t\t/* read value and compare */\n\t\tif (!fgets(name, sizeof(name), fp)) {\n\t\t\terror(\"%s: reading cluster name from clustername file\",\n\t\t\t      __func__);\n\t\t}\n\t\tfclose(fp);\n\t\tif (xstrcmp(name, slurmctld_conf.cluster_name)) {\n\t\t\tfatal(\"CLUSTER NAME MISMATCH.\\n\"\n\t\t\t      \"slurmctld has been started with \\\"\"\n\t\t\t      \"ClusterName=%s\\\", but read \\\"%s\\\" from \"\n\t\t\t      \"the state files in StateSaveLocation.\\n\"\n\t\t\t      \"Running multiple clusters from a shared \"\n\t\t\t      \"StateSaveLocation WILL CAUSE CORRUPTION.\\n\"\n\t\t\t      \"Remove %s to override this safety check if \"\n\t\t\t      \"this is intentional (e.g., the ClusterName \"\n\t\t\t      \"has changed).\", slurmctld_conf.cluster_name,\n\t\t\t      name, filename);\n\t\t\texit(1);\n\t\t}\n\t} else if (slurmctld_conf.cluster_name)\n\t\tcreate_file = true;\n\n\txfree(filename);\n\n\treturn create_file;\n}\n\nstatic void _create_clustername_file(void)\n{\n\tFILE *fp;\n\tchar *filename = NULL;\n\n\tif (!slurmctld_conf.cluster_name)\n\t\treturn;\n\n\tfilename = xstrdup_printf(\"%s/clustername\",\n\t\t\t\t  slurmctld_conf.state_save_location);\n\n\tdebug(\"creating clustername file: %s\", filename);\n\tif (!(fp = fopen(filename, \"w\"))) {\n\t\tfatal(\"%s: failed to create file %s\", __func__, filename);\n\t\texit(1);\n\t}\n\n\tif (fputs(slurmctld_conf.cluster_name, fp) < 0) {\n\t\tfatal(\"%s: failed to write to file %s\", __func__, filename);\n\t\texit(1);\n\t}\n\tfclose(fp);\n\n\txfree(filename);\n}\n\n/* Kill the currently running slurmctld\n * NOTE: No need to lock the config data since we are still single-threaded */\nstatic void _kill_old_slurmctld(void)\n{\n\tint fd;\n\tpid_t oldpid = read_pidfile(slurmctld_conf.slurmctld_pidfile, &fd);\n\tif (oldpid != (pid_t) 0) {\n\t\tinfo (\"killing old slurmctld[%ld]\", (long) oldpid);\n\t\tkill(oldpid, SIGTERM);\n\n\t\t/*\n\t\t * Wait for previous daemon to terminate\n\t\t */\n\t\tif (fd_get_readw_lock(fd) < 0)\n\t\t\tfatal (\"unable to wait for readw lock: %m\");\n\t\t(void) close(fd); /* Ignore errors */\n\t}\n}\n\n/* NOTE: No need to lock the config data since we are still single-threaded */\nstatic void _init_pidfile(void)\n{\n\tif (xstrcmp(slurmctld_conf.slurmctld_pidfile,\n\t\t   slurmctld_conf.slurmd_pidfile) == 0)\n\t\terror(\"SlurmctldPid == SlurmdPid, use different names\");\n\n\t/* Don't close the fd returned here since we need to keep the\n\t * fd open to maintain the write lock */\n\t(void) create_pidfile(slurmctld_conf.slurmctld_pidfile,\n\t\t\t      slurmctld_conf.slurm_user_id);\n}\n\n/*\n * set_slurmctld_state_loc - create state directory as needed and \"cd\" to it\n * NOTE: config read lock must be set on entry\n */\nextern void set_slurmctld_state_loc(void)\n{\n\tint rc;\n\tstruct stat st;\n\tconst char *path = slurmctld_conf.state_save_location;\n\n\t/*\n\t * If state save location does not exist, try to create it.\n\t *  Otherwise, ensure path is a directory as expected, and that\n\t *  we have permission to write to it.\n\t */\n\tif (((rc = stat(path, &st)) < 0) && (errno == ENOENT)) {\n\t\tif (mkdir(path, 0755) < 0)\n\t\t\tfatal(\"mkdir(%s): %m\", path);\n\t}\n\telse if (rc < 0)\n\t\tfatal(\"Unable to stat state save loc: %s: %m\", path);\n\telse if (!S_ISDIR(st.st_mode))\n\t\tfatal(\"State save loc: %s: Not a directory!\", path);\n\telse if (access(path, R_OK|W_OK|X_OK) < 0)\n\t\tfatal(\"Incorrect permissions on state save loc: %s\", path);\n}\n\n/* _assoc_cache_mgr - hold out until we have real data from the\n * database so we can reset the job ptr's assoc ptr's */\nstatic void *_assoc_cache_mgr(void *no_data)\n{\n\tListIterator itr = NULL;\n\tstruct job_record *job_ptr = NULL;\n\tstruct part_record *part_ptr = NULL;\n\tslurmdb_qos_rec_t qos_rec;\n\tslurmdb_assoc_rec_t assoc_rec;\n\t/* Write lock on jobs, read lock on nodes and partitions */\n\tslurmctld_lock_t job_write_lock =\n\t\t{ NO_LOCK, WRITE_LOCK, READ_LOCK, WRITE_LOCK, NO_LOCK };\n\tassoc_mgr_lock_t locks = { READ_LOCK, NO_LOCK, READ_LOCK, NO_LOCK,\n\t\t\t\t   READ_LOCK, NO_LOCK, NO_LOCK };\n\n\twhile (running_cache == 1) {\n\t\tslurm_mutex_lock(&assoc_cache_mutex);\n\t\tslurm_cond_wait(&assoc_cache_cond, &assoc_cache_mutex);\n\t\t/* This is here to see if we are exiting.  If we get\n\t\t   NO_VAL then just return since we are closing down.\n\t\t*/\n\t\tif (running_cache == NO_VAL16) {\n\t\t\tslurm_mutex_unlock(&assoc_cache_mutex);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tlock_slurmctld(job_write_lock);\n\t\t/*\n\t\t * Make sure not to have the job_write_lock, assoc_mgr or the\n\t\t * slurmdbd_lock locked when refresh_lists is called or you may\n\t\t * get deadlock.\n\t\t */\n\t\tassoc_mgr_refresh_lists(acct_db_conn, 0);\n\t\tif (g_tres_count != slurmctld_tres_cnt) {\n\t\t\tinfo(\"TRES in database does not match cache \"\n\t\t\t     \"(%u != %u).  Updating...\",\n\t\t\t     g_tres_count, slurmctld_tres_cnt);\n\t\t\t_init_tres();\n\t\t}\n\t\tif (running_cache == 1)\n\t\t\tunlock_slurmctld(job_write_lock);\n\n\t\tslurm_mutex_unlock(&assoc_cache_mutex);\n\t}\n\n\tif (!job_list) {\n\t\t/* This could happen in rare occations, it doesn't\n\t\t * matter since when the job_list is populated things\n\t\t * will be in sync.\n\t\t */\n\t\tdebug2(\"No job list yet\");\n\t\tunlock_slurmctld(job_write_lock);\n\t\tgoto handle_parts;\n\t}\n\n\tdebug2(\"got real data from the database \"\n\t       \"refreshing the association ptr's for %d jobs\",\n\t       list_count(job_list));\n\tassoc_mgr_lock(&locks);\n\titr = list_iterator_create(job_list);\n\twhile ((job_ptr = list_next(itr))) {\n\t\t_update_job_tres(job_ptr);\n\n\t\tif (job_ptr->assoc_id) {\n\t\t\tmemset(&assoc_rec, 0,\n\t\t\t       sizeof(slurmdb_assoc_rec_t));\n\t\t\tassoc_rec.id = job_ptr->assoc_id;\n\n\t\t\tdebug(\"assoc is %zx (%d) for job %u\",\n\t\t\t      (size_t)job_ptr->assoc_ptr, job_ptr->assoc_id,\n\t\t\t      job_ptr->job_id);\n\n\t\t\tif (assoc_mgr_fill_in_assoc(\n\t\t\t\t    acct_db_conn, &assoc_rec,\n\t\t\t\t    accounting_enforce,\n\t\t\t\t    (slurmdb_assoc_rec_t **)\n\t\t\t\t    &job_ptr->assoc_ptr, true)) {\n\t\t\t\tverbose(\"Invalid association id %u \"\n\t\t\t\t\t\"for job id %u\",\n\t\t\t\t\tjob_ptr->assoc_id, job_ptr->job_id);\n\t\t\t\t/* not a fatal error, association could have\n\t\t\t\t * been removed */\n\t\t\t}\n\n\t\t\tdebug(\"now assoc is %zx (%d) for job %u\",\n\t\t\t      (size_t)job_ptr->assoc_ptr, job_ptr->assoc_id,\n\t\t\t      job_ptr->job_id);\n\t\t}\n\t\tif (job_ptr->qos_id) {\n\t\t\tmemset(&qos_rec, 0, sizeof(slurmdb_qos_rec_t));\n\t\t\tqos_rec.id = job_ptr->qos_id;\n\t\t\tif ((assoc_mgr_fill_in_qos(\n\t\t\t\t    acct_db_conn, &qos_rec,\n\t\t\t\t    accounting_enforce,\n\t\t\t\t    (slurmdb_qos_rec_t **)&job_ptr->qos_ptr,\n\t\t\t\t    true))\n\t\t\t   != SLURM_SUCCESS) {\n\t\t\t\tverbose(\"Invalid qos (%u) for job_id %u\",\n\t\t\t\t\tjob_ptr->qos_id, job_ptr->job_id);\n\t\t\t\t/* not a fatal error, qos could have\n\t\t\t\t * been removed */\n\t\t\t}\n\t\t}\n\t}\n\tlist_iterator_destroy(itr);\n\nhandle_parts:\n\tif (!part_list) {\n\t\t/* This could happen in rare occations, it doesn't\n\t\t * matter since when the job_list is populated things\n\t\t * will be in sync.\n\t\t */\n\t\tdebug2(\"No part list yet\");\n\t\tgoto end_it;\n\t}\n\n\titr = list_iterator_create(part_list);\n\twhile ((part_ptr = list_next(itr))) {\n\t\tif (part_ptr->allow_qos)\n\t\t\tqos_list_build(part_ptr->allow_qos,\n\t\t\t\t       &part_ptr->allow_qos_bitstr);\n\n\t\tif (part_ptr->deny_qos)\n\t\t\tqos_list_build(part_ptr->deny_qos,\n\t\t\t\t       &part_ptr->deny_qos_bitstr);\n\n\t\tif (part_ptr->qos_char) {\n\t\t\tslurmdb_qos_rec_t qos_rec;\n\n\t\t\tmemset(&qos_rec, 0, sizeof(slurmdb_qos_rec_t));\n\t\t\tqos_rec.name = part_ptr->qos_char;\n\t\t\tpart_ptr->qos_ptr = NULL;\n\t\t\tif (assoc_mgr_fill_in_qos(\n\t\t\t\t    acct_db_conn, &qos_rec, accounting_enforce,\n\t\t\t\t    (slurmdb_qos_rec_t **)&part_ptr->qos_ptr,\n\t\t\t\t    true)\n\t\t\t    != SLURM_SUCCESS) {\n\t\t\t\tfatal(\"Partition %s has an invalid qos (%s), \"\n\t\t\t\t      \"please check your configuration\",\n\t\t\t\t      part_ptr->name, qos_rec.name);\n\t\t\t}\n\t\t}\n\t}\n\tlist_iterator_destroy(itr);\n\nend_it:\n\tassoc_mgr_unlock(&locks);\n\t/* issuing a reconfig will reset the pointers on the burst\n\t   buffers */\n\tbb_g_reconfig();\n\n\tunlock_slurmctld(job_write_lock);\n\t/* This needs to be after the lock and after we update the\n\t   jobs so if we need to send them we are set. */\n\t_accounting_cluster_ready();\n\t_get_fed_updates();\n\n\treturn NULL;\n}\n\nstatic void _become_slurm_user(void)\n{\n\tgid_t slurm_user_gid;\n\n\t/* Determine SlurmUser gid */\n\tslurm_user_gid = gid_from_uid(slurmctld_conf.slurm_user_id);\n\tif (slurm_user_gid == (gid_t) -1) {\n\t\tfatal(\"Failed to determine gid of SlurmUser(%u)\",\n\t\t      slurmctld_conf.slurm_user_id);\n\t}\n\n\t/* Initialize supplementary groups ID list for SlurmUser */\n\tif (getuid() == 0) {\n\t\t/* root does not need supplementary groups */\n\t\tif ((slurmctld_conf.slurm_user_id == 0) &&\n\t\t    (setgroups(0, NULL) != 0)) {\n\t\t\tfatal(\"Failed to drop supplementary groups, \"\n\t\t\t      \"setgroups: %m\");\n\t\t} else if ((slurmctld_conf.slurm_user_id != 0) &&\n\t\t\t   initgroups(slurmctld_conf.slurm_user_name,\n\t\t\t\t      slurm_user_gid)) {\n\t\t\tfatal(\"Failed to set supplementary groups, \"\n\t\t\t      \"initgroups: %m\");\n\t\t}\n\t} else {\n\t\tinfo(\"Not running as root. Can't drop supplementary groups\");\n\t}\n\n\t/* Set GID to GID of SlurmUser */\n\tif ((slurm_user_gid != getegid()) &&\n\t    (setgid(slurm_user_gid))) {\n\t\tfatal(\"Failed to set GID to %d\", slurm_user_gid);\n\t}\n\n\t/* Set UID to UID of SlurmUser */\n\tif ((slurmctld_conf.slurm_user_id != getuid()) &&\n\t    (setuid(slurmctld_conf.slurm_user_id))) {\n\t\tfatal(\"Can not set uid to SlurmUser(%u): %m\",\n\t\t      slurmctld_conf.slurm_user_id);\n\t}\n}\n\n/* Return true if node_name (a global) is a valid controller host name */\nstatic bool  _valid_controller(void)\n{\n\tbool match = false;\n\n\tif (slurmctld_conf.control_machine == NULL)\n\t\treturn match;\n\n\tif ((xstrcmp(node_name_short,slurmctld_conf.control_machine) == 0) ||\n\t    (xstrcmp(node_name_long, slurmctld_conf.control_machine) == 0))\n\t\tmatch = true;\n\telse if (strchr(slurmctld_conf.control_machine, ',')) {\n\t\tchar *token, *last = NULL;\n\t\tchar *tmp_name = xstrdup(slurmctld_conf.control_machine);\n\n\t\ttoken = strtok_r(tmp_name, \",\", &last);\n\t\twhile (token) {\n\t\t\tif ((xstrcmp(node_name_short, token) == 0) ||\n\t\t\t    (xstrcmp(node_name_long, token) == 0)) {\n\t\t\t\tmatch = true;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\ttoken = strtok_r(NULL, \",\", &last);\n\t\t}\n\t\txfree(tmp_name);\n\t}\n\n\treturn match;\n}\n\nstatic void _test_thread_limit(void)\n{\n#ifdef RLIMIT_NOFILE\n{\n\tstruct rlimit rlim[1];\n\tif (getrlimit(RLIMIT_NOFILE, rlim) < 0)\n\t\terror(\"Unable to get file count limit\");\n\telse if ((rlim->rlim_cur != RLIM_INFINITY) &&\n\t\t (max_server_threads > rlim->rlim_cur)) {\n\t\tmax_server_threads = rlim->rlim_cur;\n\t\tinfo(\"Reducing max_server_thread to %u due to file count limit \"\n\t\t     \"of %u\", max_server_threads, max_server_threads);\n\t}\n}\n#endif\n\treturn;\n}\n\n/* Ping BackupController\n * RET SLURM_SUCCESS or error code */\nstatic int _ping_backup_controller(void)\n{\n\tint rc = SLURM_SUCCESS;\n\tslurm_msg_t req;\n\t/* Locks: Read configuration */\n\tslurmctld_lock_t config_read_lock = {\n\t\tREAD_LOCK, NO_LOCK, NO_LOCK, NO_LOCK, NO_LOCK };\n\n\tlock_slurmctld(config_read_lock);\n\tif (!slurmctld_conf.backup_addr) {\n\t\tdebug4(\"No backup slurmctld to ping\");\n\t\tunlock_slurmctld(config_read_lock);\n\t\treturn SLURM_SUCCESS;\n\t}\n\n\t/*\n\t *  Set address of controller to ping\n\t */\n\tdebug3(\"pinging backup slurmctld at %s\", slurmctld_conf.backup_addr);\n\tslurm_msg_t_init(&req);\n\tslurm_set_addr(&req.address, slurmctld_conf.slurmctld_port,\n\t\t       slurmctld_conf.backup_addr);\n\tunlock_slurmctld(config_read_lock);\n\n\treq.msg_type = REQUEST_PING;\n\n\tif (slurm_send_recv_rc_msg_only_one(&req, &rc, 0) < 0) {\n\t\tdebug2(\"_ping_backup_controller/slurm_send_node_msg error: %m\");\n\t\treturn SLURM_ERROR;\n\t}\n\n\tif (rc)\n\t\tdebug2(\"_ping_backup_controller/response error %d\", rc);\n\n\treturn rc;\n}\n\nstatic void  _set_work_dir(void)\n{\n\tbool success = false;\n\n\tif (slurmctld_conf.slurmctld_logfile &&\n\t    (slurmctld_conf.slurmctld_logfile[0] == '/')) {\n\t\tchar *slash_ptr, *work_dir;\n\t\twork_dir = xstrdup(slurmctld_conf.slurmctld_logfile);\n\t\tslash_ptr = strrchr(work_dir, '/');\n\t\tif (slash_ptr == work_dir)\n\t\t\twork_dir[1] = '\\0';\n\t\telse\n\t\t\tslash_ptr[0] = '\\0';\n\t\tif ((access(work_dir, W_OK) != 0) || (chdir(work_dir) < 0))\n\t\t\terror(\"chdir(%s): %m\", work_dir);\n\t\telse\n\t\t\tsuccess = true;\n\t\txfree(work_dir);\n\t}\n\n\tif (!success) {\n\t\tif ((access(slurmctld_conf.state_save_location, W_OK) != 0) ||\n\t\t    (chdir(slurmctld_conf.state_save_location) < 0)) {\n\t\t\terror(\"chdir(%s): %m\",\n\t\t\t      slurmctld_conf.state_save_location);\n\t\t} else\n\t\t\tsuccess = true;\n\t}\n\n\tif (!success) {\n\t\tif ((access(\"/var/tmp\", W_OK) != 0) ||\n\t\t    (chdir(\"/var/tmp\") < 0)) {\n\t\t\terror(\"chdir(/var/tmp): %m\");\n\t\t} else\n\t\t\tinfo(\"chdir to /var/tmp\");\n\t}\n}\n\n/*\n * _purge_files_thread - separate thread to remove job batch/environ files\n * from the state directory. Runs async from purge_old_jobs to avoid\n * holding locks while the files are removed, which can cause performance\n * problems under high throughput conditions.\n *\n * Uses the purge_cond to wakeup on demand, then works through the global\n * purge_files_list of job_ids and removes their files.\n */\nstatic void *_purge_files_thread(void *no_data)\n{\n\tint *job_id;\n\n\t/*\n\t * Use the purge_files_list as a queue. _delete_job_details()\n\t * in job_mgr.c always enqueues (at the end), while\n\t *_purge_files_thread consumes off the front.\n\t *\n\t * There is a potential race condition if the job numbers have\n\t * wrapped between _purge_thread removing the state files and\n\t * get_next_job_id trying to re-assign it. This is mitigated\n\t * the the call to _dup_job_file_test() in job_mgr.c ensuring\n\t * there is no existing directory for an id before assigning it.\n\t */\n\n\t/*\n\t * pthread_cond_wait requires a lock to release and reclaim.\n\t * the List structure is already handling locking for itself,\n\t * so this lock isn't actually useful, and the thread calling\n\t * pthread_cond_signal isn't required to have the lock. So\n\t * lock it once and hold it until slurmctld shuts down.\n\t */\n\tslurm_mutex_lock(&purge_thread_lock);\n\twhile (!slurmctld_config.shutdown_time) {\n\t\tslurm_cond_wait(&purge_thread_cond, &purge_thread_lock);\n\t\tdebug2(\"%s: starting, %d jobs to purge\", __func__,\n\t\t       list_count(purge_files_list));\n\n\t\t/*\n\t\t * Use list_dequeue here (instead of list_flush) as it will not\n\t\t * hold up the list lock when we try to enqueue jobs that need\n\t\t * to be freed.\n\t\t */\n\t\twhile ((job_id = list_dequeue(purge_files_list))) {\n\t\t\tdebug2(\"%s: purging files from job %d\",\n\t\t\t       __func__, *job_id);\n\t\t\tdelete_job_desc_files(*job_id);\n\t\t\txfree(job_id);\n\t\t}\n\t}\n\tslurm_mutex_unlock(&purge_thread_lock);\n\treturn NULL;\n}\n\nstatic void _get_fed_updates()\n{\n\tList fed_list = NULL;\n\tslurmdb_update_object_t update = {0};\n\tslurmdb_federation_cond_t fed_cond;\n\n\tslurmdb_init_federation_cond(&fed_cond, 0);\n\tfed_cond.cluster_list = list_create(NULL);\n\tlist_append(fed_cond.cluster_list, slurmctld_conf.cluster_name);\n\n\tfed_list = acct_storage_g_get_federations(acct_db_conn,\n\t\t\t\t\t\t  slurmctld_conf.slurm_user_id,\n\t\t\t\t\t\t  &fed_cond);\n\tFREE_NULL_LIST(fed_cond.cluster_list);\n\n\tif (fed_list) {\n\t\tupdate.objects = fed_list;\n\t\tfed_mgr_update_feds(&update);\n\t}\n\n\tFREE_NULL_LIST(fed_list);\n}\n\nstatic int _foreach_job_running(void *object, void *arg)\n{\n\tstruct job_record *job_ptr = (struct job_record *)object;\n\tint *count = (int *)arg;\n\n\tif (IS_JOB_RUNNING(job_ptr))\n\t\t(*count)++;\n\n\treturn SLURM_SUCCESS;\n}\n\nstatic int _running_jobs_count()\n{\n\tint count = 0;\n\n\tlist_for_each(job_list, _foreach_job_running, &count);\n\n\treturn count;\n}\n\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/auxdir/libtool.m4": "# libtool.m4 - Configure libtool for the host system. -*-Autoconf-*-\n#\n#   Copyright (C) 1996-2001, 2003-2015 Free Software Foundation, Inc.\n#   Written by Gordon Matzigkeit, 1996\n#\n# This file is free software; the Free Software Foundation gives\n# unlimited permission to copy and/or distribute it, with or without\n# modifications, as long as this notice is preserved.\n\nm4_define([_LT_COPYING], [dnl\n# Copyright (C) 2014 Free Software Foundation, Inc.\n# This is free software; see the source for copying conditions.  There is NO\n# warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\n# GNU Libtool is free software; you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation; either version 2 of of the License, or\n# (at your option) any later version.\n#\n# As a special exception to the GNU General Public License, if you\n# distribute this file as part of a program or library that is built\n# using GNU Libtool, you may include this file under the  same\n# distribution terms that you use for the rest of that program.\n#\n# GNU Libtool is distributed in the hope that it will be useful, but\n# WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program.  If not, see <http://www.gnu.org/licenses/>.\n])\n\n# serial 58 LT_INIT\n\n\n# LT_PREREQ(VERSION)\n# ------------------\n# Complain and exit if this libtool version is less that VERSION.\nm4_defun([LT_PREREQ],\n[m4_if(m4_version_compare(m4_defn([LT_PACKAGE_VERSION]), [$1]), -1,\n       [m4_default([$3],\n\t\t   [m4_fatal([Libtool version $1 or higher is required],\n\t\t             63)])],\n       [$2])])\n\n\n# _LT_CHECK_BUILDDIR\n# ------------------\n# Complain if the absolute build directory name contains unusual characters\nm4_defun([_LT_CHECK_BUILDDIR],\n[case `pwd` in\n  *\\ * | *\\\t*)\n    AC_MSG_WARN([Libtool does not cope well with whitespace in `pwd`]) ;;\nesac\n])\n\n\n# LT_INIT([OPTIONS])\n# ------------------\nAC_DEFUN([LT_INIT],\n[AC_PREREQ([2.62])dnl We use AC_PATH_PROGS_FEATURE_CHECK\nAC_REQUIRE([AC_CONFIG_AUX_DIR_DEFAULT])dnl\nAC_BEFORE([$0], [LT_LANG])dnl\nAC_BEFORE([$0], [LT_OUTPUT])dnl\nAC_BEFORE([$0], [LTDL_INIT])dnl\nm4_require([_LT_CHECK_BUILDDIR])dnl\n\ndnl Autoconf doesn't catch unexpanded LT_ macros by default:\nm4_pattern_forbid([^_?LT_[A-Z_]+$])dnl\nm4_pattern_allow([^(_LT_EOF|LT_DLGLOBAL|LT_DLLAZY_OR_NOW|LT_MULTI_MODULE)$])dnl\ndnl aclocal doesn't pull ltoptions.m4, ltsugar.m4, or ltversion.m4\ndnl unless we require an AC_DEFUNed macro:\nAC_REQUIRE([LTOPTIONS_VERSION])dnl\nAC_REQUIRE([LTSUGAR_VERSION])dnl\nAC_REQUIRE([LTVERSION_VERSION])dnl\nAC_REQUIRE([LTOBSOLETE_VERSION])dnl\nm4_require([_LT_PROG_LTMAIN])dnl\n\n_LT_SHELL_INIT([SHELL=${CONFIG_SHELL-/bin/sh}])\n\ndnl Parse OPTIONS\n_LT_SET_OPTIONS([$0], [$1])\n\n# This can be used to rebuild libtool when needed\nLIBTOOL_DEPS=$ltmain\n\n# Always use our own libtool.\nLIBTOOL='$(SHELL) $(top_builddir)/libtool'\nAC_SUBST(LIBTOOL)dnl\n\n_LT_SETUP\n\n# Only expand once:\nm4_define([LT_INIT])\n])# LT_INIT\n\n# Old names:\nAU_ALIAS([AC_PROG_LIBTOOL], [LT_INIT])\nAU_ALIAS([AM_PROG_LIBTOOL], [LT_INIT])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_PROG_LIBTOOL], [])\ndnl AC_DEFUN([AM_PROG_LIBTOOL], [])\n\n\n# _LT_PREPARE_CC_BASENAME\n# -----------------------\nm4_defun([_LT_PREPARE_CC_BASENAME], [\n# Calculate cc_basename.  Skip known compiler wrappers and cross-prefix.\nfunc_cc_basename ()\n{\n    for cc_temp in @S|@*\"\"; do\n      case $cc_temp in\n        compile | *[[\\\\/]]compile | ccache | *[[\\\\/]]ccache ) ;;\n        distcc | *[[\\\\/]]distcc | purify | *[[\\\\/]]purify ) ;;\n        \\-*) ;;\n        *) break;;\n      esac\n    done\n    func_cc_basename_result=`$ECHO \"$cc_temp\" | $SED \"s%.*/%%; s%^$host_alias-%%\"`\n}\n])# _LT_PREPARE_CC_BASENAME\n\n\n# _LT_CC_BASENAME(CC)\n# -------------------\n# It would be clearer to call AC_REQUIREs from _LT_PREPARE_CC_BASENAME,\n# but that macro is also expanded into generated libtool script, which\n# arranges for $SED and $ECHO to be set by different means.\nm4_defun([_LT_CC_BASENAME],\n[m4_require([_LT_PREPARE_CC_BASENAME])dnl\nAC_REQUIRE([_LT_DECL_SED])dnl\nAC_REQUIRE([_LT_PROG_ECHO_BACKSLASH])dnl\nfunc_cc_basename $1\ncc_basename=$func_cc_basename_result\n])\n\n\n# _LT_FILEUTILS_DEFAULTS\n# ----------------------\n# It is okay to use these file commands and assume they have been set\n# sensibly after 'm4_require([_LT_FILEUTILS_DEFAULTS])'.\nm4_defun([_LT_FILEUTILS_DEFAULTS],\n[: ${CP=\"cp -f\"}\n: ${MV=\"mv -f\"}\n: ${RM=\"rm -f\"}\n])# _LT_FILEUTILS_DEFAULTS\n\n\n# _LT_SETUP\n# ---------\nm4_defun([_LT_SETUP],\n[AC_REQUIRE([AC_CANONICAL_HOST])dnl\nAC_REQUIRE([AC_CANONICAL_BUILD])dnl\nAC_REQUIRE([_LT_PREPARE_SED_QUOTE_VARS])dnl\nAC_REQUIRE([_LT_PROG_ECHO_BACKSLASH])dnl\n\n_LT_DECL([], [PATH_SEPARATOR], [1], [The PATH separator for the build system])dnl\ndnl\n_LT_DECL([], [host_alias], [0], [The host system])dnl\n_LT_DECL([], [host], [0])dnl\n_LT_DECL([], [host_os], [0])dnl\ndnl\n_LT_DECL([], [build_alias], [0], [The build system])dnl\n_LT_DECL([], [build], [0])dnl\n_LT_DECL([], [build_os], [0])dnl\ndnl\nAC_REQUIRE([AC_PROG_CC])dnl\nAC_REQUIRE([LT_PATH_LD])dnl\nAC_REQUIRE([LT_PATH_NM])dnl\ndnl\nAC_REQUIRE([AC_PROG_LN_S])dnl\ntest -z \"$LN_S\" && LN_S=\"ln -s\"\n_LT_DECL([], [LN_S], [1], [Whether we need soft or hard links])dnl\ndnl\nAC_REQUIRE([LT_CMD_MAX_LEN])dnl\n_LT_DECL([objext], [ac_objext], [0], [Object file suffix (normally \"o\")])dnl\n_LT_DECL([], [exeext], [0], [Executable file suffix (normally \"\")])dnl\ndnl\nm4_require([_LT_FILEUTILS_DEFAULTS])dnl\nm4_require([_LT_CHECK_SHELL_FEATURES])dnl\nm4_require([_LT_PATH_CONVERSION_FUNCTIONS])dnl\nm4_require([_LT_CMD_RELOAD])dnl\nm4_require([_LT_CHECK_MAGIC_METHOD])dnl\nm4_require([_LT_CHECK_SHAREDLIB_FROM_LINKLIB])dnl\nm4_require([_LT_CMD_OLD_ARCHIVE])dnl\nm4_require([_LT_CMD_GLOBAL_SYMBOLS])dnl\nm4_require([_LT_WITH_SYSROOT])dnl\nm4_require([_LT_CMD_TRUNCATE])dnl\n\n_LT_CONFIG_LIBTOOL_INIT([\n# See if we are running on zsh, and set the options that allow our\n# commands through without removal of \\ escapes INIT.\nif test -n \"\\${ZSH_VERSION+set}\"; then\n   setopt NO_GLOB_SUBST\nfi\n])\nif test -n \"${ZSH_VERSION+set}\"; then\n   setopt NO_GLOB_SUBST\nfi\n\n_LT_CHECK_OBJDIR\n\nm4_require([_LT_TAG_COMPILER])dnl\n\ncase $host_os in\naix3*)\n  # AIX sometimes has problems with the GCC collect2 program.  For some\n  # reason, if we set the COLLECT_NAMES environment variable, the problems\n  # vanish in a puff of smoke.\n  if test set != \"${COLLECT_NAMES+set}\"; then\n    COLLECT_NAMES=\n    export COLLECT_NAMES\n  fi\n  ;;\nesac\n\n# Global variables:\nofile=libtool\ncan_build_shared=yes\n\n# All known linkers require a '.a' archive for static linking (except MSVC,\n# which needs '.lib').\nlibext=a\n\nwith_gnu_ld=$lt_cv_prog_gnu_ld\n\nold_CC=$CC\nold_CFLAGS=$CFLAGS\n\n# Set sane defaults for various variables\ntest -z \"$CC\" && CC=cc\ntest -z \"$LTCC\" && LTCC=$CC\ntest -z \"$LTCFLAGS\" && LTCFLAGS=$CFLAGS\ntest -z \"$LD\" && LD=ld\ntest -z \"$ac_objext\" && ac_objext=o\n\n_LT_CC_BASENAME([$compiler])\n\n# Only perform the check for file, if the check method requires it\ntest -z \"$MAGIC_CMD\" && MAGIC_CMD=file\ncase $deplibs_check_method in\nfile_magic*)\n  if test \"$file_magic_cmd\" = '$MAGIC_CMD'; then\n    _LT_PATH_MAGIC\n  fi\n  ;;\nesac\n\n# Use C for the default configuration in the libtool script\nLT_SUPPORTED_TAG([CC])\n_LT_LANG_C_CONFIG\n_LT_LANG_DEFAULT_CONFIG\n_LT_CONFIG_COMMANDS\n])# _LT_SETUP\n\n\n# _LT_PREPARE_SED_QUOTE_VARS\n# --------------------------\n# Define a few sed substitution that help us do robust quoting.\nm4_defun([_LT_PREPARE_SED_QUOTE_VARS],\n[# Backslashify metacharacters that are still active within\n# double-quoted strings.\nsed_quote_subst='s/\\([[\"`$\\\\]]\\)/\\\\\\1/g'\n\n# Same as above, but do not quote variable references.\ndouble_quote_subst='s/\\([[\"`\\\\]]\\)/\\\\\\1/g'\n\n# Sed substitution to delay expansion of an escaped shell variable in a\n# double_quote_subst'ed string.\ndelay_variable_subst='s/\\\\\\\\\\\\\\\\\\\\\\$/\\\\\\\\\\\\$/g'\n\n# Sed substitution to delay expansion of an escaped single quote.\ndelay_single_quote_subst='s/'\\''/'\\'\\\\\\\\\\\\\\'\\''/g'\n\n# Sed substitution to avoid accidental globbing in evaled expressions\nno_glob_subst='s/\\*/\\\\\\*/g'\n])\n\n# _LT_PROG_LTMAIN\n# ---------------\n# Note that this code is called both from 'configure', and 'config.status'\n# now that we use AC_CONFIG_COMMANDS to generate libtool.  Notably,\n# 'config.status' has no value for ac_aux_dir unless we are using Automake,\n# so we pass a copy along to make sure it has a sensible value anyway.\nm4_defun([_LT_PROG_LTMAIN],\n[m4_ifdef([AC_REQUIRE_AUX_FILE], [AC_REQUIRE_AUX_FILE([ltmain.sh])])dnl\n_LT_CONFIG_LIBTOOL_INIT([ac_aux_dir='$ac_aux_dir'])\nltmain=$ac_aux_dir/ltmain.sh\n])# _LT_PROG_LTMAIN\n\n\n## ------------------------------------- ##\n## Accumulate code for creating libtool. ##\n## ------------------------------------- ##\n\n# So that we can recreate a full libtool script including additional\n# tags, we accumulate the chunks of code to send to AC_CONFIG_COMMANDS\n# in macros and then make a single call at the end using the 'libtool'\n# label.\n\n\n# _LT_CONFIG_LIBTOOL_INIT([INIT-COMMANDS])\n# ----------------------------------------\n# Register INIT-COMMANDS to be passed to AC_CONFIG_COMMANDS later.\nm4_define([_LT_CONFIG_LIBTOOL_INIT],\n[m4_ifval([$1],\n          [m4_append([_LT_OUTPUT_LIBTOOL_INIT],\n                     [$1\n])])])\n\n# Initialize.\nm4_define([_LT_OUTPUT_LIBTOOL_INIT])\n\n\n# _LT_CONFIG_LIBTOOL([COMMANDS])\n# ------------------------------\n# Register COMMANDS to be passed to AC_CONFIG_COMMANDS later.\nm4_define([_LT_CONFIG_LIBTOOL],\n[m4_ifval([$1],\n          [m4_append([_LT_OUTPUT_LIBTOOL_COMMANDS],\n                     [$1\n])])])\n\n# Initialize.\nm4_define([_LT_OUTPUT_LIBTOOL_COMMANDS])\n\n\n# _LT_CONFIG_SAVE_COMMANDS([COMMANDS], [INIT_COMMANDS])\n# -----------------------------------------------------\nm4_defun([_LT_CONFIG_SAVE_COMMANDS],\n[_LT_CONFIG_LIBTOOL([$1])\n_LT_CONFIG_LIBTOOL_INIT([$2])\n])\n\n\n# _LT_FORMAT_COMMENT([COMMENT])\n# -----------------------------\n# Add leading comment marks to the start of each line, and a trailing\n# full-stop to the whole comment if one is not present already.\nm4_define([_LT_FORMAT_COMMENT],\n[m4_ifval([$1], [\nm4_bpatsubst([m4_bpatsubst([$1], [^ *], [# ])],\n              [['`$\\]], [\\\\\\&])]m4_bmatch([$1], [[!?.]$], [], [.])\n)])\n\n\n\n## ------------------------ ##\n## FIXME: Eliminate VARNAME ##\n## ------------------------ ##\n\n\n# _LT_DECL([CONFIGNAME], VARNAME, VALUE, [DESCRIPTION], [IS-TAGGED?])\n# -------------------------------------------------------------------\n# CONFIGNAME is the name given to the value in the libtool script.\n# VARNAME is the (base) name used in the configure script.\n# VALUE may be 0, 1 or 2 for a computed quote escaped value based on\n# VARNAME.  Any other value will be used directly.\nm4_define([_LT_DECL],\n[lt_if_append_uniq([lt_decl_varnames], [$2], [, ],\n    [lt_dict_add_subkey([lt_decl_dict], [$2], [libtool_name],\n\t[m4_ifval([$1], [$1], [$2])])\n    lt_dict_add_subkey([lt_decl_dict], [$2], [value], [$3])\n    m4_ifval([$4],\n\t[lt_dict_add_subkey([lt_decl_dict], [$2], [description], [$4])])\n    lt_dict_add_subkey([lt_decl_dict], [$2],\n\t[tagged?], [m4_ifval([$5], [yes], [no])])])\n])\n\n\n# _LT_TAGDECL([CONFIGNAME], VARNAME, VALUE, [DESCRIPTION])\n# --------------------------------------------------------\nm4_define([_LT_TAGDECL], [_LT_DECL([$1], [$2], [$3], [$4], [yes])])\n\n\n# lt_decl_tag_varnames([SEPARATOR], [VARNAME1...])\n# ------------------------------------------------\nm4_define([lt_decl_tag_varnames],\n[_lt_decl_filter([tagged?], [yes], $@)])\n\n\n# _lt_decl_filter(SUBKEY, VALUE, [SEPARATOR], [VARNAME1..])\n# ---------------------------------------------------------\nm4_define([_lt_decl_filter],\n[m4_case([$#],\n  [0], [m4_fatal([$0: too few arguments: $#])],\n  [1], [m4_fatal([$0: too few arguments: $#: $1])],\n  [2], [lt_dict_filter([lt_decl_dict], [$1], [$2], [], lt_decl_varnames)],\n  [3], [lt_dict_filter([lt_decl_dict], [$1], [$2], [$3], lt_decl_varnames)],\n  [lt_dict_filter([lt_decl_dict], $@)])[]dnl\n])\n\n\n# lt_decl_quote_varnames([SEPARATOR], [VARNAME1...])\n# --------------------------------------------------\nm4_define([lt_decl_quote_varnames],\n[_lt_decl_filter([value], [1], $@)])\n\n\n# lt_decl_dquote_varnames([SEPARATOR], [VARNAME1...])\n# ---------------------------------------------------\nm4_define([lt_decl_dquote_varnames],\n[_lt_decl_filter([value], [2], $@)])\n\n\n# lt_decl_varnames_tagged([SEPARATOR], [VARNAME1...])\n# ---------------------------------------------------\nm4_define([lt_decl_varnames_tagged],\n[m4_assert([$# <= 2])dnl\n_$0(m4_quote(m4_default([$1], [[, ]])),\n    m4_ifval([$2], [[$2]], [m4_dquote(lt_decl_tag_varnames)]),\n    m4_split(m4_normalize(m4_quote(_LT_TAGS)), [ ]))])\nm4_define([_lt_decl_varnames_tagged],\n[m4_ifval([$3], [lt_combine([$1], [$2], [_], $3)])])\n\n\n# lt_decl_all_varnames([SEPARATOR], [VARNAME1...])\n# ------------------------------------------------\nm4_define([lt_decl_all_varnames],\n[_$0(m4_quote(m4_default([$1], [[, ]])),\n     m4_if([$2], [],\n\t   m4_quote(lt_decl_varnames),\n\tm4_quote(m4_shift($@))))[]dnl\n])\nm4_define([_lt_decl_all_varnames],\n[lt_join($@, lt_decl_varnames_tagged([$1],\n\t\t\tlt_decl_tag_varnames([[, ]], m4_shift($@))))dnl\n])\n\n\n# _LT_CONFIG_STATUS_DECLARE([VARNAME])\n# ------------------------------------\n# Quote a variable value, and forward it to 'config.status' so that its\n# declaration there will have the same value as in 'configure'.  VARNAME\n# must have a single quote delimited value for this to work.\nm4_define([_LT_CONFIG_STATUS_DECLARE],\n[$1='`$ECHO \"$][$1\" | $SED \"$delay_single_quote_subst\"`'])\n\n\n# _LT_CONFIG_STATUS_DECLARATIONS\n# ------------------------------\n# We delimit libtool config variables with single quotes, so when\n# we write them to config.status, we have to be sure to quote all\n# embedded single quotes properly.  In configure, this macro expands\n# each variable declared with _LT_DECL (and _LT_TAGDECL) into:\n#\n#    <var>='`$ECHO \"$<var>\" | $SED \"$delay_single_quote_subst\"`'\nm4_defun([_LT_CONFIG_STATUS_DECLARATIONS],\n[m4_foreach([_lt_var], m4_quote(lt_decl_all_varnames),\n    [m4_n([_LT_CONFIG_STATUS_DECLARE(_lt_var)])])])\n\n\n# _LT_LIBTOOL_TAGS\n# ----------------\n# Output comment and list of tags supported by the script\nm4_defun([_LT_LIBTOOL_TAGS],\n[_LT_FORMAT_COMMENT([The names of the tagged configurations supported by this script])dnl\navailable_tags='_LT_TAGS'dnl\n])\n\n\n# _LT_LIBTOOL_DECLARE(VARNAME, [TAG])\n# -----------------------------------\n# Extract the dictionary values for VARNAME (optionally with TAG) and\n# expand to a commented shell variable setting:\n#\n#    # Some comment about what VAR is for.\n#    visible_name=$lt_internal_name\nm4_define([_LT_LIBTOOL_DECLARE],\n[_LT_FORMAT_COMMENT(m4_quote(lt_dict_fetch([lt_decl_dict], [$1],\n\t\t\t\t\t   [description])))[]dnl\nm4_pushdef([_libtool_name],\n    m4_quote(lt_dict_fetch([lt_decl_dict], [$1], [libtool_name])))[]dnl\nm4_case(m4_quote(lt_dict_fetch([lt_decl_dict], [$1], [value])),\n    [0], [_libtool_name=[$]$1],\n    [1], [_libtool_name=$lt_[]$1],\n    [2], [_libtool_name=$lt_[]$1],\n    [_libtool_name=lt_dict_fetch([lt_decl_dict], [$1], [value])])[]dnl\nm4_ifval([$2], [_$2])[]m4_popdef([_libtool_name])[]dnl\n])\n\n\n# _LT_LIBTOOL_CONFIG_VARS\n# -----------------------\n# Produce commented declarations of non-tagged libtool config variables\n# suitable for insertion in the LIBTOOL CONFIG section of the 'libtool'\n# script.  Tagged libtool config variables (even for the LIBTOOL CONFIG\n# section) are produced by _LT_LIBTOOL_TAG_VARS.\nm4_defun([_LT_LIBTOOL_CONFIG_VARS],\n[m4_foreach([_lt_var],\n    m4_quote(_lt_decl_filter([tagged?], [no], [], lt_decl_varnames)),\n    [m4_n([_LT_LIBTOOL_DECLARE(_lt_var)])])])\n\n\n# _LT_LIBTOOL_TAG_VARS(TAG)\n# -------------------------\nm4_define([_LT_LIBTOOL_TAG_VARS],\n[m4_foreach([_lt_var], m4_quote(lt_decl_tag_varnames),\n    [m4_n([_LT_LIBTOOL_DECLARE(_lt_var, [$1])])])])\n\n\n# _LT_TAGVAR(VARNAME, [TAGNAME])\n# ------------------------------\nm4_define([_LT_TAGVAR], [m4_ifval([$2], [$1_$2], [$1])])\n\n\n# _LT_CONFIG_COMMANDS\n# -------------------\n# Send accumulated output to $CONFIG_STATUS.  Thanks to the lists of\n# variables for single and double quote escaping we saved from calls\n# to _LT_DECL, we can put quote escaped variables declarations\n# into 'config.status', and then the shell code to quote escape them in\n# for loops in 'config.status'.  Finally, any additional code accumulated\n# from calls to _LT_CONFIG_LIBTOOL_INIT is expanded.\nm4_defun([_LT_CONFIG_COMMANDS],\n[AC_PROVIDE_IFELSE([LT_OUTPUT],\n\tdnl If the libtool generation code has been placed in $CONFIG_LT,\n\tdnl instead of duplicating it all over again into config.status,\n\tdnl then we will have config.status run $CONFIG_LT later, so it\n\tdnl needs to know what name is stored there:\n        [AC_CONFIG_COMMANDS([libtool],\n            [$SHELL $CONFIG_LT || AS_EXIT(1)], [CONFIG_LT='$CONFIG_LT'])],\n    dnl If the libtool generation code is destined for config.status,\n    dnl expand the accumulated commands and init code now:\n    [AC_CONFIG_COMMANDS([libtool],\n        [_LT_OUTPUT_LIBTOOL_COMMANDS], [_LT_OUTPUT_LIBTOOL_COMMANDS_INIT])])\n])#_LT_CONFIG_COMMANDS\n\n\n# Initialize.\nm4_define([_LT_OUTPUT_LIBTOOL_COMMANDS_INIT],\n[\n\n# The HP-UX ksh and POSIX shell print the target directory to stdout\n# if CDPATH is set.\n(unset CDPATH) >/dev/null 2>&1 && unset CDPATH\n\nsed_quote_subst='$sed_quote_subst'\ndouble_quote_subst='$double_quote_subst'\ndelay_variable_subst='$delay_variable_subst'\n_LT_CONFIG_STATUS_DECLARATIONS\nLTCC='$LTCC'\nLTCFLAGS='$LTCFLAGS'\ncompiler='$compiler_DEFAULT'\n\n# A function that is used when there is no print builtin or printf.\nfunc_fallback_echo ()\n{\n  eval 'cat <<_LTECHO_EOF\n\\$[]1\n_LTECHO_EOF'\n}\n\n# Quote evaled strings.\nfor var in lt_decl_all_varnames([[ \\\n]], lt_decl_quote_varnames); do\n    case \\`eval \\\\\\\\\\$ECHO \\\\\\\\\"\"\\\\\\\\\\$\\$var\"\\\\\\\\\"\\` in\n    *[[\\\\\\\\\\\\\\`\\\\\"\\\\\\$]]*)\n      eval \"lt_\\$var=\\\\\\\\\\\\\"\\\\\\`\\\\\\$ECHO \\\\\"\\\\\\$\\$var\\\\\" | \\\\\\$SED \\\\\"\\\\\\$sed_quote_subst\\\\\"\\\\\\`\\\\\\\\\\\\\"\" ## exclude from sc_prohibit_nested_quotes\n      ;;\n    *)\n      eval \"lt_\\$var=\\\\\\\\\\\\\"\\\\\\$\\$var\\\\\\\\\\\\\"\"\n      ;;\n    esac\ndone\n\n# Double-quote double-evaled strings.\nfor var in lt_decl_all_varnames([[ \\\n]], lt_decl_dquote_varnames); do\n    case \\`eval \\\\\\\\\\$ECHO \\\\\\\\\"\"\\\\\\\\\\$\\$var\"\\\\\\\\\"\\` in\n    *[[\\\\\\\\\\\\\\`\\\\\"\\\\\\$]]*)\n      eval \"lt_\\$var=\\\\\\\\\\\\\"\\\\\\`\\\\\\$ECHO \\\\\"\\\\\\$\\$var\\\\\" | \\\\\\$SED -e \\\\\"\\\\\\$double_quote_subst\\\\\" -e \\\\\"\\\\\\$sed_quote_subst\\\\\" -e \\\\\"\\\\\\$delay_variable_subst\\\\\"\\\\\\`\\\\\\\\\\\\\"\" ## exclude from sc_prohibit_nested_quotes\n      ;;\n    *)\n      eval \"lt_\\$var=\\\\\\\\\\\\\"\\\\\\$\\$var\\\\\\\\\\\\\"\"\n      ;;\n    esac\ndone\n\n_LT_OUTPUT_LIBTOOL_INIT\n])\n\n# _LT_GENERATED_FILE_INIT(FILE, [COMMENT])\n# ------------------------------------\n# Generate a child script FILE with all initialization necessary to\n# reuse the environment learned by the parent script, and make the\n# file executable.  If COMMENT is supplied, it is inserted after the\n# '#!' sequence but before initialization text begins.  After this\n# macro, additional text can be appended to FILE to form the body of\n# the child script.  The macro ends with non-zero status if the\n# file could not be fully written (such as if the disk is full).\nm4_ifdef([AS_INIT_GENERATED],\n[m4_defun([_LT_GENERATED_FILE_INIT],[AS_INIT_GENERATED($@)])],\n[m4_defun([_LT_GENERATED_FILE_INIT],\n[m4_require([AS_PREPARE])]dnl\n[m4_pushdef([AS_MESSAGE_LOG_FD])]dnl\n[lt_write_fail=0\ncat >$1 <<_ASEOF || lt_write_fail=1\n#! $SHELL\n# Generated by $as_me.\n$2\nSHELL=\\${CONFIG_SHELL-$SHELL}\nexport SHELL\n_ASEOF\ncat >>$1 <<\\_ASEOF || lt_write_fail=1\nAS_SHELL_SANITIZE\n_AS_PREPARE\nexec AS_MESSAGE_FD>&1\n_ASEOF\ntest 0 = \"$lt_write_fail\" && chmod +x $1[]dnl\nm4_popdef([AS_MESSAGE_LOG_FD])])])# _LT_GENERATED_FILE_INIT\n\n# LT_OUTPUT\n# ---------\n# This macro allows early generation of the libtool script (before\n# AC_OUTPUT is called), incase it is used in configure for compilation\n# tests.\nAC_DEFUN([LT_OUTPUT],\n[: ${CONFIG_LT=./config.lt}\nAC_MSG_NOTICE([creating $CONFIG_LT])\n_LT_GENERATED_FILE_INIT([\"$CONFIG_LT\"],\n[# Run this file to recreate a libtool stub with the current configuration.])\n\ncat >>\"$CONFIG_LT\" <<\\_LTEOF\nlt_cl_silent=false\nexec AS_MESSAGE_LOG_FD>>config.log\n{\n  echo\n  AS_BOX([Running $as_me.])\n} >&AS_MESSAGE_LOG_FD\n\nlt_cl_help=\"\\\n'$as_me' creates a local libtool stub from the current configuration,\nfor use in further configure time tests before the real libtool is\ngenerated.\n\nUsage: $[0] [[OPTIONS]]\n\n  -h, --help      print this help, then exit\n  -V, --version   print version number, then exit\n  -q, --quiet     do not print progress messages\n  -d, --debug     don't remove temporary files\n\nReport bugs to <bug-libtool@gnu.org>.\"\n\nlt_cl_version=\"\\\nm4_ifset([AC_PACKAGE_NAME], [AC_PACKAGE_NAME ])config.lt[]dnl\nm4_ifset([AC_PACKAGE_VERSION], [ AC_PACKAGE_VERSION])\nconfigured by $[0], generated by m4_PACKAGE_STRING.\n\nCopyright (C) 2011 Free Software Foundation, Inc.\nThis config.lt script is free software; the Free Software Foundation\ngives unlimited permision to copy, distribute and modify it.\"\n\nwhile test 0 != $[#]\ndo\n  case $[1] in\n    --version | --v* | -V )\n      echo \"$lt_cl_version\"; exit 0 ;;\n    --help | --h* | -h )\n      echo \"$lt_cl_help\"; exit 0 ;;\n    --debug | --d* | -d )\n      debug=: ;;\n    --quiet | --q* | --silent | --s* | -q )\n      lt_cl_silent=: ;;\n\n    -*) AC_MSG_ERROR([unrecognized option: $[1]\nTry '$[0] --help' for more information.]) ;;\n\n    *) AC_MSG_ERROR([unrecognized argument: $[1]\nTry '$[0] --help' for more information.]) ;;\n  esac\n  shift\ndone\n\nif $lt_cl_silent; then\n  exec AS_MESSAGE_FD>/dev/null\nfi\n_LTEOF\n\ncat >>\"$CONFIG_LT\" <<_LTEOF\n_LT_OUTPUT_LIBTOOL_COMMANDS_INIT\n_LTEOF\n\ncat >>\"$CONFIG_LT\" <<\\_LTEOF\nAC_MSG_NOTICE([creating $ofile])\n_LT_OUTPUT_LIBTOOL_COMMANDS\nAS_EXIT(0)\n_LTEOF\nchmod +x \"$CONFIG_LT\"\n\n# configure is writing to config.log, but config.lt does its own redirection,\n# appending to config.log, which fails on DOS, as config.log is still kept\n# open by configure.  Here we exec the FD to /dev/null, effectively closing\n# config.log, so it can be properly (re)opened and appended to by config.lt.\nlt_cl_success=:\ntest yes = \"$silent\" &&\n  lt_config_lt_args=\"$lt_config_lt_args --quiet\"\nexec AS_MESSAGE_LOG_FD>/dev/null\n$SHELL \"$CONFIG_LT\" $lt_config_lt_args || lt_cl_success=false\nexec AS_MESSAGE_LOG_FD>>config.log\n$lt_cl_success || AS_EXIT(1)\n])# LT_OUTPUT\n\n\n# _LT_CONFIG(TAG)\n# ---------------\n# If TAG is the built-in tag, create an initial libtool script with a\n# default configuration from the untagged config vars.  Otherwise add code\n# to config.status for appending the configuration named by TAG from the\n# matching tagged config vars.\nm4_defun([_LT_CONFIG],\n[m4_require([_LT_FILEUTILS_DEFAULTS])dnl\n_LT_CONFIG_SAVE_COMMANDS([\n  m4_define([_LT_TAG], m4_if([$1], [], [C], [$1]))dnl\n  m4_if(_LT_TAG, [C], [\n    # See if we are running on zsh, and set the options that allow our\n    # commands through without removal of \\ escapes.\n    if test -n \"${ZSH_VERSION+set}\"; then\n      setopt NO_GLOB_SUBST\n    fi\n\n    cfgfile=${ofile}T\n    trap \"$RM \\\"$cfgfile\\\"; exit 1\" 1 2 15\n    $RM \"$cfgfile\"\n\n    cat <<_LT_EOF >> \"$cfgfile\"\n#! $SHELL\n# Generated automatically by $as_me ($PACKAGE) $VERSION\n# NOTE: Changes made to this file will be lost: look at ltmain.sh.\n\n# Provide generalized library-building support services.\n# Written by Gordon Matzigkeit, 1996\n\n_LT_COPYING\n_LT_LIBTOOL_TAGS\n\n# Configured defaults for sys_lib_dlsearch_path munging.\n: \\${LT_SYS_LIBRARY_PATH=\"$configure_time_lt_sys_library_path\"}\n\n# ### BEGIN LIBTOOL CONFIG\n_LT_LIBTOOL_CONFIG_VARS\n_LT_LIBTOOL_TAG_VARS\n# ### END LIBTOOL CONFIG\n\n_LT_EOF\n\n    cat <<'_LT_EOF' >> \"$cfgfile\"\n\n# ### BEGIN FUNCTIONS SHARED WITH CONFIGURE\n\n_LT_PREPARE_MUNGE_PATH_LIST\n_LT_PREPARE_CC_BASENAME\n\n# ### END FUNCTIONS SHARED WITH CONFIGURE\n\n_LT_EOF\n\n  case $host_os in\n  aix3*)\n    cat <<\\_LT_EOF >> \"$cfgfile\"\n# AIX sometimes has problems with the GCC collect2 program.  For some\n# reason, if we set the COLLECT_NAMES environment variable, the problems\n# vanish in a puff of smoke.\nif test set != \"${COLLECT_NAMES+set}\"; then\n  COLLECT_NAMES=\n  export COLLECT_NAMES\nfi\n_LT_EOF\n    ;;\n  esac\n\n  _LT_PROG_LTMAIN\n\n  # We use sed instead of cat because bash on DJGPP gets confused if\n  # if finds mixed CR/LF and LF-only lines.  Since sed operates in\n  # text mode, it properly converts lines to CR/LF.  This bash problem\n  # is reportedly fixed, but why not run on old versions too?\n  sed '$q' \"$ltmain\" >> \"$cfgfile\" \\\n     || (rm -f \"$cfgfile\"; exit 1)\n\n   mv -f \"$cfgfile\" \"$ofile\" ||\n    (rm -f \"$ofile\" && cp \"$cfgfile\" \"$ofile\" && rm -f \"$cfgfile\")\n  chmod +x \"$ofile\"\n],\n[cat <<_LT_EOF >> \"$ofile\"\n\ndnl Unfortunately we have to use $1 here, since _LT_TAG is not expanded\ndnl in a comment (ie after a #).\n# ### BEGIN LIBTOOL TAG CONFIG: $1\n_LT_LIBTOOL_TAG_VARS(_LT_TAG)\n# ### END LIBTOOL TAG CONFIG: $1\n_LT_EOF\n])dnl /m4_if\n],\n[m4_if([$1], [], [\n    PACKAGE='$PACKAGE'\n    VERSION='$VERSION'\n    RM='$RM'\n    ofile='$ofile'], [])\n])dnl /_LT_CONFIG_SAVE_COMMANDS\n])# _LT_CONFIG\n\n\n# LT_SUPPORTED_TAG(TAG)\n# ---------------------\n# Trace this macro to discover what tags are supported by the libtool\n# --tag option, using:\n#    autoconf --trace 'LT_SUPPORTED_TAG:$1'\nAC_DEFUN([LT_SUPPORTED_TAG], [])\n\n\n# C support is built-in for now\nm4_define([_LT_LANG_C_enabled], [])\nm4_define([_LT_TAGS], [])\n\n\n# LT_LANG(LANG)\n# -------------\n# Enable libtool support for the given language if not already enabled.\nAC_DEFUN([LT_LANG],\n[AC_BEFORE([$0], [LT_OUTPUT])dnl\nm4_case([$1],\n  [C],\t\t\t[_LT_LANG(C)],\n  [C++],\t\t[_LT_LANG(CXX)],\n  [Go],\t\t\t[_LT_LANG(GO)],\n  [Java],\t\t[_LT_LANG(GCJ)],\n  [Fortran 77],\t\t[_LT_LANG(F77)],\n  [Fortran],\t\t[_LT_LANG(FC)],\n  [Windows Resource],\t[_LT_LANG(RC)],\n  [m4_ifdef([_LT_LANG_]$1[_CONFIG],\n    [_LT_LANG($1)],\n    [m4_fatal([$0: unsupported language: \"$1\"])])])dnl\n])# LT_LANG\n\n\n# _LT_LANG(LANGNAME)\n# ------------------\nm4_defun([_LT_LANG],\n[m4_ifdef([_LT_LANG_]$1[_enabled], [],\n  [LT_SUPPORTED_TAG([$1])dnl\n  m4_append([_LT_TAGS], [$1 ])dnl\n  m4_define([_LT_LANG_]$1[_enabled], [])dnl\n  _LT_LANG_$1_CONFIG($1)])dnl\n])# _LT_LANG\n\n\nm4_ifndef([AC_PROG_GO], [\n############################################################\n# NOTE: This macro has been submitted for inclusion into   #\n#  GNU Autoconf as AC_PROG_GO.  When it is available in    #\n#  a released version of Autoconf we should remove this    #\n#  macro and use it instead.                               #\n############################################################\nm4_defun([AC_PROG_GO],\n[AC_LANG_PUSH(Go)dnl\nAC_ARG_VAR([GOC],     [Go compiler command])dnl\nAC_ARG_VAR([GOFLAGS], [Go compiler flags])dnl\n_AC_ARG_VAR_LDFLAGS()dnl\nAC_CHECK_TOOL(GOC, gccgo)\nif test -z \"$GOC\"; then\n  if test -n \"$ac_tool_prefix\"; then\n    AC_CHECK_PROG(GOC, [${ac_tool_prefix}gccgo], [${ac_tool_prefix}gccgo])\n  fi\nfi\nif test -z \"$GOC\"; then\n  AC_CHECK_PROG(GOC, gccgo, gccgo, false)\nfi\n])#m4_defun\n])#m4_ifndef\n\n\n# _LT_LANG_DEFAULT_CONFIG\n# -----------------------\nm4_defun([_LT_LANG_DEFAULT_CONFIG],\n[AC_PROVIDE_IFELSE([AC_PROG_CXX],\n  [LT_LANG(CXX)],\n  [m4_define([AC_PROG_CXX], defn([AC_PROG_CXX])[LT_LANG(CXX)])])\n\nAC_PROVIDE_IFELSE([AC_PROG_F77],\n  [LT_LANG(F77)],\n  [m4_define([AC_PROG_F77], defn([AC_PROG_F77])[LT_LANG(F77)])])\n\nAC_PROVIDE_IFELSE([AC_PROG_FC],\n  [LT_LANG(FC)],\n  [m4_define([AC_PROG_FC], defn([AC_PROG_FC])[LT_LANG(FC)])])\n\ndnl The call to [A][M_PROG_GCJ] is quoted like that to stop aclocal\ndnl pulling things in needlessly.\nAC_PROVIDE_IFELSE([AC_PROG_GCJ],\n  [LT_LANG(GCJ)],\n  [AC_PROVIDE_IFELSE([A][M_PROG_GCJ],\n    [LT_LANG(GCJ)],\n    [AC_PROVIDE_IFELSE([LT_PROG_GCJ],\n      [LT_LANG(GCJ)],\n      [m4_ifdef([AC_PROG_GCJ],\n\t[m4_define([AC_PROG_GCJ], defn([AC_PROG_GCJ])[LT_LANG(GCJ)])])\n       m4_ifdef([A][M_PROG_GCJ],\n\t[m4_define([A][M_PROG_GCJ], defn([A][M_PROG_GCJ])[LT_LANG(GCJ)])])\n       m4_ifdef([LT_PROG_GCJ],\n\t[m4_define([LT_PROG_GCJ], defn([LT_PROG_GCJ])[LT_LANG(GCJ)])])])])])\n\nAC_PROVIDE_IFELSE([AC_PROG_GO],\n  [LT_LANG(GO)],\n  [m4_define([AC_PROG_GO], defn([AC_PROG_GO])[LT_LANG(GO)])])\n\nAC_PROVIDE_IFELSE([LT_PROG_RC],\n  [LT_LANG(RC)],\n  [m4_define([LT_PROG_RC], defn([LT_PROG_RC])[LT_LANG(RC)])])\n])# _LT_LANG_DEFAULT_CONFIG\n\n# Obsolete macros:\nAU_DEFUN([AC_LIBTOOL_CXX], [LT_LANG(C++)])\nAU_DEFUN([AC_LIBTOOL_F77], [LT_LANG(Fortran 77)])\nAU_DEFUN([AC_LIBTOOL_FC], [LT_LANG(Fortran)])\nAU_DEFUN([AC_LIBTOOL_GCJ], [LT_LANG(Java)])\nAU_DEFUN([AC_LIBTOOL_RC], [LT_LANG(Windows Resource)])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_LIBTOOL_CXX], [])\ndnl AC_DEFUN([AC_LIBTOOL_F77], [])\ndnl AC_DEFUN([AC_LIBTOOL_FC], [])\ndnl AC_DEFUN([AC_LIBTOOL_GCJ], [])\ndnl AC_DEFUN([AC_LIBTOOL_RC], [])\n\n\n# _LT_TAG_COMPILER\n# ----------------\nm4_defun([_LT_TAG_COMPILER],\n[AC_REQUIRE([AC_PROG_CC])dnl\n\n_LT_DECL([LTCC], [CC], [1], [A C compiler])dnl\n_LT_DECL([LTCFLAGS], [CFLAGS], [1], [LTCC compiler flags])dnl\n_LT_TAGDECL([CC], [compiler], [1], [A language specific compiler])dnl\n_LT_TAGDECL([with_gcc], [GCC], [0], [Is the compiler the GNU compiler?])dnl\n\n# If no C compiler was specified, use CC.\nLTCC=${LTCC-\"$CC\"}\n\n# If no C compiler flags were specified, use CFLAGS.\nLTCFLAGS=${LTCFLAGS-\"$CFLAGS\"}\n\n# Allow CC to be a program name with arguments.\ncompiler=$CC\n])# _LT_TAG_COMPILER\n\n\n# _LT_COMPILER_BOILERPLATE\n# ------------------------\n# Check for compiler boilerplate output or warnings with\n# the simple compiler test code.\nm4_defun([_LT_COMPILER_BOILERPLATE],\n[m4_require([_LT_DECL_SED])dnl\nac_outfile=conftest.$ac_objext\necho \"$lt_simple_compile_test_code\" >conftest.$ac_ext\neval \"$ac_compile\" 2>&1 >/dev/null | $SED '/^$/d; /^ *+/d' >conftest.err\n_lt_compiler_boilerplate=`cat conftest.err`\n$RM conftest*\n])# _LT_COMPILER_BOILERPLATE\n\n\n# _LT_LINKER_BOILERPLATE\n# ----------------------\n# Check for linker boilerplate output or warnings with\n# the simple link test code.\nm4_defun([_LT_LINKER_BOILERPLATE],\n[m4_require([_LT_DECL_SED])dnl\nac_outfile=conftest.$ac_objext\necho \"$lt_simple_link_test_code\" >conftest.$ac_ext\neval \"$ac_link\" 2>&1 >/dev/null | $SED '/^$/d; /^ *+/d' >conftest.err\n_lt_linker_boilerplate=`cat conftest.err`\n$RM -r conftest*\n])# _LT_LINKER_BOILERPLATE\n\n# _LT_REQUIRED_DARWIN_CHECKS\n# -------------------------\nm4_defun_once([_LT_REQUIRED_DARWIN_CHECKS],[\n  case $host_os in\n    rhapsody* | darwin*)\n    AC_CHECK_TOOL([DSYMUTIL], [dsymutil], [:])\n    AC_CHECK_TOOL([NMEDIT], [nmedit], [:])\n    AC_CHECK_TOOL([LIPO], [lipo], [:])\n    AC_CHECK_TOOL([OTOOL], [otool], [:])\n    AC_CHECK_TOOL([OTOOL64], [otool64], [:])\n    _LT_DECL([], [DSYMUTIL], [1],\n      [Tool to manipulate archived DWARF debug symbol files on Mac OS X])\n    _LT_DECL([], [NMEDIT], [1],\n      [Tool to change global to local symbols on Mac OS X])\n    _LT_DECL([], [LIPO], [1],\n      [Tool to manipulate fat objects and archives on Mac OS X])\n    _LT_DECL([], [OTOOL], [1],\n      [ldd/readelf like tool for Mach-O binaries on Mac OS X])\n    _LT_DECL([], [OTOOL64], [1],\n      [ldd/readelf like tool for 64 bit Mach-O binaries on Mac OS X 10.4])\n\n    AC_CACHE_CHECK([for -single_module linker flag],[lt_cv_apple_cc_single_mod],\n      [lt_cv_apple_cc_single_mod=no\n      if test -z \"$LT_MULTI_MODULE\"; then\n\t# By default we will add the -single_module flag. You can override\n\t# by either setting the environment variable LT_MULTI_MODULE\n\t# non-empty at configure time, or by adding -multi_module to the\n\t# link flags.\n\trm -rf libconftest.dylib*\n\techo \"int foo(void){return 1;}\" > conftest.c\n\techo \"$LTCC $LTCFLAGS $LDFLAGS -o libconftest.dylib \\\n-dynamiclib -Wl,-single_module conftest.c\" >&AS_MESSAGE_LOG_FD\n\t$LTCC $LTCFLAGS $LDFLAGS -o libconftest.dylib \\\n\t  -dynamiclib -Wl,-single_module conftest.c 2>conftest.err\n        _lt_result=$?\n\t# If there is a non-empty error log, and \"single_module\"\n\t# appears in it, assume the flag caused a linker warning\n        if test -s conftest.err && $GREP single_module conftest.err; then\n\t  cat conftest.err >&AS_MESSAGE_LOG_FD\n\t# Otherwise, if the output was created with a 0 exit code from\n\t# the compiler, it worked.\n\telif test -f libconftest.dylib && test 0 = \"$_lt_result\"; then\n\t  lt_cv_apple_cc_single_mod=yes\n\telse\n\t  cat conftest.err >&AS_MESSAGE_LOG_FD\n\tfi\n\trm -rf libconftest.dylib*\n\trm -f conftest.*\n      fi])\n\n    AC_CACHE_CHECK([for -exported_symbols_list linker flag],\n      [lt_cv_ld_exported_symbols_list],\n      [lt_cv_ld_exported_symbols_list=no\n      save_LDFLAGS=$LDFLAGS\n      echo \"_main\" > conftest.sym\n      LDFLAGS=\"$LDFLAGS -Wl,-exported_symbols_list,conftest.sym\"\n      AC_LINK_IFELSE([AC_LANG_PROGRAM([],[])],\n\t[lt_cv_ld_exported_symbols_list=yes],\n\t[lt_cv_ld_exported_symbols_list=no])\n\tLDFLAGS=$save_LDFLAGS\n    ])\n\n    AC_CACHE_CHECK([for -force_load linker flag],[lt_cv_ld_force_load],\n      [lt_cv_ld_force_load=no\n      cat > conftest.c << _LT_EOF\nint forced_loaded() { return 2;}\n_LT_EOF\n      echo \"$LTCC $LTCFLAGS -c -o conftest.o conftest.c\" >&AS_MESSAGE_LOG_FD\n      $LTCC $LTCFLAGS -c -o conftest.o conftest.c 2>&AS_MESSAGE_LOG_FD\n      echo \"$AR cru libconftest.a conftest.o\" >&AS_MESSAGE_LOG_FD\n      $AR cru libconftest.a conftest.o 2>&AS_MESSAGE_LOG_FD\n      echo \"$RANLIB libconftest.a\" >&AS_MESSAGE_LOG_FD\n      $RANLIB libconftest.a 2>&AS_MESSAGE_LOG_FD\n      cat > conftest.c << _LT_EOF\nint main() { return 0;}\n_LT_EOF\n      echo \"$LTCC $LTCFLAGS $LDFLAGS -o conftest conftest.c -Wl,-force_load,./libconftest.a\" >&AS_MESSAGE_LOG_FD\n      $LTCC $LTCFLAGS $LDFLAGS -o conftest conftest.c -Wl,-force_load,./libconftest.a 2>conftest.err\n      _lt_result=$?\n      if test -s conftest.err && $GREP force_load conftest.err; then\n\tcat conftest.err >&AS_MESSAGE_LOG_FD\n      elif test -f conftest && test 0 = \"$_lt_result\" && $GREP forced_load conftest >/dev/null 2>&1; then\n\tlt_cv_ld_force_load=yes\n      else\n\tcat conftest.err >&AS_MESSAGE_LOG_FD\n      fi\n        rm -f conftest.err libconftest.a conftest conftest.c\n        rm -rf conftest.dSYM\n    ])\n    case $host_os in\n    rhapsody* | darwin1.[[012]])\n      _lt_dar_allow_undefined='$wl-undefined ${wl}suppress' ;;\n    darwin1.*)\n      _lt_dar_allow_undefined='$wl-flat_namespace $wl-undefined ${wl}suppress' ;;\n    darwin*) # darwin 5.x on\n      # if running on 10.5 or later, the deployment target defaults\n      # to the OS version, if on x86, and 10.4, the deployment\n      # target defaults to 10.4. Don't you love it?\n      case ${MACOSX_DEPLOYMENT_TARGET-10.0},$host in\n\t10.0,*86*-darwin8*|10.0,*-darwin[[91]]*)\n\t  _lt_dar_allow_undefined='$wl-undefined ${wl}dynamic_lookup' ;;\n\t10.[[012]][[,.]]*)\n\t  _lt_dar_allow_undefined='$wl-flat_namespace $wl-undefined ${wl}suppress' ;;\n\t10.*)\n\t  _lt_dar_allow_undefined='$wl-undefined ${wl}dynamic_lookup' ;;\n      esac\n    ;;\n  esac\n    if test yes = \"$lt_cv_apple_cc_single_mod\"; then\n      _lt_dar_single_mod='$single_module'\n    fi\n    if test yes = \"$lt_cv_ld_exported_symbols_list\"; then\n      _lt_dar_export_syms=' $wl-exported_symbols_list,$output_objdir/$libname-symbols.expsym'\n    else\n      _lt_dar_export_syms='~$NMEDIT -s $output_objdir/$libname-symbols.expsym $lib'\n    fi\n    if test : != \"$DSYMUTIL\" && test no = \"$lt_cv_ld_force_load\"; then\n      _lt_dsymutil='~$DSYMUTIL $lib || :'\n    else\n      _lt_dsymutil=\n    fi\n    ;;\n  esac\n])\n\n\n# _LT_DARWIN_LINKER_FEATURES([TAG])\n# ---------------------------------\n# Checks for linker and compiler features on darwin\nm4_defun([_LT_DARWIN_LINKER_FEATURES],\n[\n  m4_require([_LT_REQUIRED_DARWIN_CHECKS])\n  _LT_TAGVAR(archive_cmds_need_lc, $1)=no\n  _LT_TAGVAR(hardcode_direct, $1)=no\n  _LT_TAGVAR(hardcode_automatic, $1)=yes\n  _LT_TAGVAR(hardcode_shlibpath_var, $1)=unsupported\n  if test yes = \"$lt_cv_ld_force_load\"; then\n    _LT_TAGVAR(whole_archive_flag_spec, $1)='`for conv in $convenience\\\"\\\"; do test  -n \\\"$conv\\\" && new_convenience=\\\"$new_convenience $wl-force_load,$conv\\\"; done; func_echo_all \\\"$new_convenience\\\"`'\n    m4_case([$1], [F77], [_LT_TAGVAR(compiler_needs_object, $1)=yes],\n                  [FC],  [_LT_TAGVAR(compiler_needs_object, $1)=yes])\n  else\n    _LT_TAGVAR(whole_archive_flag_spec, $1)=''\n  fi\n  _LT_TAGVAR(link_all_deplibs, $1)=yes\n  _LT_TAGVAR(allow_undefined_flag, $1)=$_lt_dar_allow_undefined\n  case $cc_basename in\n     ifort*|nagfor*) _lt_dar_can_shared=yes ;;\n     *) _lt_dar_can_shared=$GCC ;;\n  esac\n  if test yes = \"$_lt_dar_can_shared\"; then\n    output_verbose_link_cmd=func_echo_all\n    _LT_TAGVAR(archive_cmds, $1)=\"\\$CC -dynamiclib \\$allow_undefined_flag -o \\$lib \\$libobjs \\$deplibs \\$compiler_flags -install_name \\$rpath/\\$soname \\$verstring $_lt_dar_single_mod$_lt_dsymutil\"\n    _LT_TAGVAR(module_cmds, $1)=\"\\$CC \\$allow_undefined_flag -o \\$lib -bundle \\$libobjs \\$deplibs \\$compiler_flags$_lt_dsymutil\"\n    _LT_TAGVAR(archive_expsym_cmds, $1)=\"sed 's|^|_|' < \\$export_symbols > \\$output_objdir/\\$libname-symbols.expsym~\\$CC -dynamiclib \\$allow_undefined_flag -o \\$lib \\$libobjs \\$deplibs \\$compiler_flags -install_name \\$rpath/\\$soname \\$verstring $_lt_dar_single_mod$_lt_dar_export_syms$_lt_dsymutil\"\n    _LT_TAGVAR(module_expsym_cmds, $1)=\"sed -e 's|^|_|' < \\$export_symbols > \\$output_objdir/\\$libname-symbols.expsym~\\$CC \\$allow_undefined_flag -o \\$lib -bundle \\$libobjs \\$deplibs \\$compiler_flags$_lt_dar_export_syms$_lt_dsymutil\"\n    m4_if([$1], [CXX],\n[   if test yes != \"$lt_cv_apple_cc_single_mod\"; then\n      _LT_TAGVAR(archive_cmds, $1)=\"\\$CC -r -keep_private_externs -nostdlib -o \\$lib-master.o \\$libobjs~\\$CC -dynamiclib \\$allow_undefined_flag -o \\$lib \\$lib-master.o \\$deplibs \\$compiler_flags -install_name \\$rpath/\\$soname \\$verstring$_lt_dsymutil\"\n      _LT_TAGVAR(archive_expsym_cmds, $1)=\"sed 's|^|_|' < \\$export_symbols > \\$output_objdir/\\$libname-symbols.expsym~\\$CC -r -keep_private_externs -nostdlib -o \\$lib-master.o \\$libobjs~\\$CC -dynamiclib \\$allow_undefined_flag -o \\$lib \\$lib-master.o \\$deplibs \\$compiler_flags -install_name \\$rpath/\\$soname \\$verstring$_lt_dar_export_syms$_lt_dsymutil\"\n    fi\n],[])\n  else\n  _LT_TAGVAR(ld_shlibs, $1)=no\n  fi\n])\n\n# _LT_SYS_MODULE_PATH_AIX([TAGNAME])\n# ----------------------------------\n# Links a minimal program and checks the executable\n# for the system default hardcoded library path. In most cases,\n# this is /usr/lib:/lib, but when the MPI compilers are used\n# the location of the communication and MPI libs are included too.\n# If we don't find anything, use the default library path according\n# to the aix ld manual.\n# Store the results from the different compilers for each TAGNAME.\n# Allow to override them for all tags through lt_cv_aix_libpath.\nm4_defun([_LT_SYS_MODULE_PATH_AIX],\n[m4_require([_LT_DECL_SED])dnl\nif test set = \"${lt_cv_aix_libpath+set}\"; then\n  aix_libpath=$lt_cv_aix_libpath\nelse\n  AC_CACHE_VAL([_LT_TAGVAR([lt_cv_aix_libpath_], [$1])],\n  [AC_LINK_IFELSE([AC_LANG_PROGRAM],[\n  lt_aix_libpath_sed='[\n      /Import File Strings/,/^$/ {\n\t  /^0/ {\n\t      s/^0  *\\([^ ]*\\) *$/\\1/\n\t      p\n\t  }\n      }]'\n  _LT_TAGVAR([lt_cv_aix_libpath_], [$1])=`dump -H conftest$ac_exeext 2>/dev/null | $SED -n -e \"$lt_aix_libpath_sed\"`\n  # Check for a 64-bit object if we didn't find anything.\n  if test -z \"$_LT_TAGVAR([lt_cv_aix_libpath_], [$1])\"; then\n    _LT_TAGVAR([lt_cv_aix_libpath_], [$1])=`dump -HX64 conftest$ac_exeext 2>/dev/null | $SED -n -e \"$lt_aix_libpath_sed\"`\n  fi],[])\n  if test -z \"$_LT_TAGVAR([lt_cv_aix_libpath_], [$1])\"; then\n    _LT_TAGVAR([lt_cv_aix_libpath_], [$1])=/usr/lib:/lib\n  fi\n  ])\n  aix_libpath=$_LT_TAGVAR([lt_cv_aix_libpath_], [$1])\nfi\n])# _LT_SYS_MODULE_PATH_AIX\n\n\n# _LT_SHELL_INIT(ARG)\n# -------------------\nm4_define([_LT_SHELL_INIT],\n[m4_divert_text([M4SH-INIT], [$1\n])])# _LT_SHELL_INIT\n\n\n\n# _LT_PROG_ECHO_BACKSLASH\n# -----------------------\n# Find how we can fake an echo command that does not interpret backslash.\n# In particular, with Autoconf 2.60 or later we add some code to the start\n# of the generated configure script that will find a shell with a builtin\n# printf (that we can use as an echo command).\nm4_defun([_LT_PROG_ECHO_BACKSLASH],\n[ECHO='\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'\nECHO=$ECHO$ECHO$ECHO$ECHO$ECHO\nECHO=$ECHO$ECHO$ECHO$ECHO$ECHO$ECHO\n\nAC_MSG_CHECKING([how to print strings])\n# Test print first, because it will be a builtin if present.\nif test \"X`( print -r -- -n ) 2>/dev/null`\" = X-n && \\\n   test \"X`print -r -- $ECHO 2>/dev/null`\" = \"X$ECHO\"; then\n  ECHO='print -r --'\nelif test \"X`printf %s $ECHO 2>/dev/null`\" = \"X$ECHO\"; then\n  ECHO='printf %s\\n'\nelse\n  # Use this function as a fallback that always works.\n  func_fallback_echo ()\n  {\n    eval 'cat <<_LTECHO_EOF\n$[]1\n_LTECHO_EOF'\n  }\n  ECHO='func_fallback_echo'\nfi\n\n# func_echo_all arg...\n# Invoke $ECHO with all args, space-separated.\nfunc_echo_all ()\n{\n    $ECHO \"$*\"\n}\n\ncase $ECHO in\n  printf*) AC_MSG_RESULT([printf]) ;;\n  print*) AC_MSG_RESULT([print -r]) ;;\n  *) AC_MSG_RESULT([cat]) ;;\nesac\n\nm4_ifdef([_AS_DETECT_SUGGESTED],\n[_AS_DETECT_SUGGESTED([\n  test -n \"${ZSH_VERSION+set}${BASH_VERSION+set}\" || (\n    ECHO='\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'\n    ECHO=$ECHO$ECHO$ECHO$ECHO$ECHO\n    ECHO=$ECHO$ECHO$ECHO$ECHO$ECHO$ECHO\n    PATH=/empty FPATH=/empty; export PATH FPATH\n    test \"X`printf %s $ECHO`\" = \"X$ECHO\" \\\n      || test \"X`print -r -- $ECHO`\" = \"X$ECHO\" )])])\n\n_LT_DECL([], [SHELL], [1], [Shell to use when invoking shell scripts])\n_LT_DECL([], [ECHO], [1], [An echo program that protects backslashes])\n])# _LT_PROG_ECHO_BACKSLASH\n\n\n# _LT_WITH_SYSROOT\n# ----------------\nAC_DEFUN([_LT_WITH_SYSROOT],\n[AC_MSG_CHECKING([for sysroot])\nAC_ARG_WITH([sysroot],\n[AS_HELP_STRING([--with-sysroot@<:@=DIR@:>@],\n  [Search for dependent libraries within DIR (or the compiler's sysroot\n   if not specified).])],\n[], [with_sysroot=no])\n\ndnl lt_sysroot will always be passed unquoted.  We quote it here\ndnl in case the user passed a directory name.\nlt_sysroot=\ncase $with_sysroot in #(\n yes)\n   if test yes = \"$GCC\"; then\n     lt_sysroot=`$CC --print-sysroot 2>/dev/null`\n   fi\n   ;; #(\n /*)\n   lt_sysroot=`echo \"$with_sysroot\" | sed -e \"$sed_quote_subst\"`\n   ;; #(\n no|'')\n   ;; #(\n *)\n   AC_MSG_RESULT([$with_sysroot])\n   AC_MSG_ERROR([The sysroot must be an absolute path.])\n   ;;\nesac\n\n AC_MSG_RESULT([${lt_sysroot:-no}])\n_LT_DECL([], [lt_sysroot], [0], [The root where to search for ]dnl\n[dependent libraries, and where our libraries should be installed.])])\n\n# _LT_ENABLE_LOCK\n# ---------------\nm4_defun([_LT_ENABLE_LOCK],\n[AC_ARG_ENABLE([libtool-lock],\n  [AS_HELP_STRING([--disable-libtool-lock],\n    [avoid locking (might break parallel builds)])])\ntest no = \"$enable_libtool_lock\" || enable_libtool_lock=yes\n\n# Some flags need to be propagated to the compiler or linker for good\n# libtool support.\ncase $host in\nia64-*-hpux*)\n  # Find out what ABI is being produced by ac_compile, and set mode\n  # options accordingly.\n  echo 'int i;' > conftest.$ac_ext\n  if AC_TRY_EVAL(ac_compile); then\n    case `/usr/bin/file conftest.$ac_objext` in\n      *ELF-32*)\n\tHPUX_IA64_MODE=32\n\t;;\n      *ELF-64*)\n\tHPUX_IA64_MODE=64\n\t;;\n    esac\n  fi\n  rm -rf conftest*\n  ;;\n*-*-irix6*)\n  # Find out what ABI is being produced by ac_compile, and set linker\n  # options accordingly.\n  echo '[#]line '$LINENO' \"configure\"' > conftest.$ac_ext\n  if AC_TRY_EVAL(ac_compile); then\n    if test yes = \"$lt_cv_prog_gnu_ld\"; then\n      case `/usr/bin/file conftest.$ac_objext` in\n\t*32-bit*)\n\t  LD=\"${LD-ld} -melf32bsmip\"\n\t  ;;\n\t*N32*)\n\t  LD=\"${LD-ld} -melf32bmipn32\"\n\t  ;;\n\t*64-bit*)\n\t  LD=\"${LD-ld} -melf64bmip\"\n\t;;\n      esac\n    else\n      case `/usr/bin/file conftest.$ac_objext` in\n\t*32-bit*)\n\t  LD=\"${LD-ld} -32\"\n\t  ;;\n\t*N32*)\n\t  LD=\"${LD-ld} -n32\"\n\t  ;;\n\t*64-bit*)\n\t  LD=\"${LD-ld} -64\"\n\t  ;;\n      esac\n    fi\n  fi\n  rm -rf conftest*\n  ;;\n\nmips64*-*linux*)\n  # Find out what ABI is being produced by ac_compile, and set linker\n  # options accordingly.\n  echo '[#]line '$LINENO' \"configure\"' > conftest.$ac_ext\n  if AC_TRY_EVAL(ac_compile); then\n    emul=elf\n    case `/usr/bin/file conftest.$ac_objext` in\n      *32-bit*)\n\temul=\"${emul}32\"\n\t;;\n      *64-bit*)\n\temul=\"${emul}64\"\n\t;;\n    esac\n    case `/usr/bin/file conftest.$ac_objext` in\n      *MSB*)\n\temul=\"${emul}btsmip\"\n\t;;\n      *LSB*)\n\temul=\"${emul}ltsmip\"\n\t;;\n    esac\n    case `/usr/bin/file conftest.$ac_objext` in\n      *N32*)\n\temul=\"${emul}n32\"\n\t;;\n    esac\n    LD=\"${LD-ld} -m $emul\"\n  fi\n  rm -rf conftest*\n  ;;\n\nx86_64-*kfreebsd*-gnu|x86_64-*linux*|powerpc*-*linux*| \\\ns390*-*linux*|s390*-*tpf*|sparc*-*linux*)\n  # Find out what ABI is being produced by ac_compile, and set linker\n  # options accordingly.  Note that the listed cases only cover the\n  # situations where additional linker options are needed (such as when\n  # doing 32-bit compilation for a host where ld defaults to 64-bit, or\n  # vice versa); the common cases where no linker options are needed do\n  # not appear in the list.\n  echo 'int i;' > conftest.$ac_ext\n  if AC_TRY_EVAL(ac_compile); then\n    case `/usr/bin/file conftest.o` in\n      *32-bit*)\n\tcase $host in\n\t  x86_64-*kfreebsd*-gnu)\n\t    LD=\"${LD-ld} -m elf_i386_fbsd\"\n\t    ;;\n\t  x86_64-*linux*)\n\t    case `/usr/bin/file conftest.o` in\n\t      *x86-64*)\n\t\tLD=\"${LD-ld} -m elf32_x86_64\"\n\t\t;;\n\t      *)\n\t\tLD=\"${LD-ld} -m elf_i386\"\n\t\t;;\n\t    esac\n\t    ;;\n\t  powerpc64le-*linux*)\n\t    LD=\"${LD-ld} -m elf32lppclinux\"\n\t    ;;\n\t  powerpc64-*linux*)\n\t    LD=\"${LD-ld} -m elf32ppclinux\"\n\t    ;;\n\t  s390x-*linux*)\n\t    LD=\"${LD-ld} -m elf_s390\"\n\t    ;;\n\t  sparc64-*linux*)\n\t    LD=\"${LD-ld} -m elf32_sparc\"\n\t    ;;\n\tesac\n\t;;\n      *64-bit*)\n\tcase $host in\n\t  x86_64-*kfreebsd*-gnu)\n\t    LD=\"${LD-ld} -m elf_x86_64_fbsd\"\n\t    ;;\n\t  x86_64-*linux*)\n\t    LD=\"${LD-ld} -m elf_x86_64\"\n\t    ;;\n\t  powerpcle-*linux*)\n\t    LD=\"${LD-ld} -m elf64lppc\"\n\t    ;;\n\t  powerpc-*linux*)\n\t    LD=\"${LD-ld} -m elf64ppc\"\n\t    ;;\n\t  s390*-*linux*|s390*-*tpf*)\n\t    LD=\"${LD-ld} -m elf64_s390\"\n\t    ;;\n\t  sparc*-*linux*)\n\t    LD=\"${LD-ld} -m elf64_sparc\"\n\t    ;;\n\tesac\n\t;;\n    esac\n  fi\n  rm -rf conftest*\n  ;;\n\n*-*-sco3.2v5*)\n  # On SCO OpenServer 5, we need -belf to get full-featured binaries.\n  SAVE_CFLAGS=$CFLAGS\n  CFLAGS=\"$CFLAGS -belf\"\n  AC_CACHE_CHECK([whether the C compiler needs -belf], lt_cv_cc_needs_belf,\n    [AC_LANG_PUSH(C)\n     AC_LINK_IFELSE([AC_LANG_PROGRAM([[]],[[]])],[lt_cv_cc_needs_belf=yes],[lt_cv_cc_needs_belf=no])\n     AC_LANG_POP])\n  if test yes != \"$lt_cv_cc_needs_belf\"; then\n    # this is probably gcc 2.8.0, egcs 1.0 or newer; no need for -belf\n    CFLAGS=$SAVE_CFLAGS\n  fi\n  ;;\n*-*solaris*)\n  # Find out what ABI is being produced by ac_compile, and set linker\n  # options accordingly.\n  echo 'int i;' > conftest.$ac_ext\n  if AC_TRY_EVAL(ac_compile); then\n    case `/usr/bin/file conftest.o` in\n    *64-bit*)\n      case $lt_cv_prog_gnu_ld in\n      yes*)\n        case $host in\n        i?86-*-solaris*|x86_64-*-solaris*)\n          LD=\"${LD-ld} -m elf_x86_64\"\n          ;;\n        sparc*-*-solaris*)\n          LD=\"${LD-ld} -m elf64_sparc\"\n          ;;\n        esac\n        # GNU ld 2.21 introduced _sol2 emulations.  Use them if available.\n        if ${LD-ld} -V | grep _sol2 >/dev/null 2>&1; then\n          LD=${LD-ld}_sol2\n        fi\n        ;;\n      *)\n\tif ${LD-ld} -64 -r -o conftest2.o conftest.o >/dev/null 2>&1; then\n\t  LD=\"${LD-ld} -64\"\n\tfi\n\t;;\n      esac\n      ;;\n    esac\n  fi\n  rm -rf conftest*\n  ;;\nesac\n\nneed_locks=$enable_libtool_lock\n])# _LT_ENABLE_LOCK\n\n\n# _LT_PROG_AR\n# -----------\nm4_defun([_LT_PROG_AR],\n[AC_CHECK_TOOLS(AR, [ar], false)\n: ${AR=ar}\n: ${AR_FLAGS=cru}\n_LT_DECL([], [AR], [1], [The archiver])\n_LT_DECL([], [AR_FLAGS], [1], [Flags to create an archive])\n\nAC_CACHE_CHECK([for archiver @FILE support], [lt_cv_ar_at_file],\n  [lt_cv_ar_at_file=no\n   AC_COMPILE_IFELSE([AC_LANG_PROGRAM],\n     [echo conftest.$ac_objext > conftest.lst\n      lt_ar_try='$AR $AR_FLAGS libconftest.a @conftest.lst >&AS_MESSAGE_LOG_FD'\n      AC_TRY_EVAL([lt_ar_try])\n      if test 0 -eq \"$ac_status\"; then\n\t# Ensure the archiver fails upon bogus file names.\n\trm -f conftest.$ac_objext libconftest.a\n\tAC_TRY_EVAL([lt_ar_try])\n\tif test 0 -ne \"$ac_status\"; then\n          lt_cv_ar_at_file=@\n        fi\n      fi\n      rm -f conftest.* libconftest.a\n     ])\n  ])\n\nif test no = \"$lt_cv_ar_at_file\"; then\n  archiver_list_spec=\nelse\n  archiver_list_spec=$lt_cv_ar_at_file\nfi\n_LT_DECL([], [archiver_list_spec], [1],\n  [How to feed a file listing to the archiver])\n])# _LT_PROG_AR\n\n\n# _LT_CMD_OLD_ARCHIVE\n# -------------------\nm4_defun([_LT_CMD_OLD_ARCHIVE],\n[_LT_PROG_AR\n\nAC_CHECK_TOOL(STRIP, strip, :)\ntest -z \"$STRIP\" && STRIP=:\n_LT_DECL([], [STRIP], [1], [A symbol stripping program])\n\nAC_CHECK_TOOL(RANLIB, ranlib, :)\ntest -z \"$RANLIB\" && RANLIB=:\n_LT_DECL([], [RANLIB], [1],\n    [Commands used to install an old-style archive])\n\n# Determine commands to create old-style static archives.\nold_archive_cmds='$AR $AR_FLAGS $oldlib$oldobjs'\nold_postinstall_cmds='chmod 644 $oldlib'\nold_postuninstall_cmds=\n\nif test -n \"$RANLIB\"; then\n  case $host_os in\n  bitrig* | openbsd*)\n    old_postinstall_cmds=\"$old_postinstall_cmds~\\$RANLIB -t \\$tool_oldlib\"\n    ;;\n  *)\n    old_postinstall_cmds=\"$old_postinstall_cmds~\\$RANLIB \\$tool_oldlib\"\n    ;;\n  esac\n  old_archive_cmds=\"$old_archive_cmds~\\$RANLIB \\$tool_oldlib\"\nfi\n\ncase $host_os in\n  darwin*)\n    lock_old_archive_extraction=yes ;;\n  *)\n    lock_old_archive_extraction=no ;;\nesac\n_LT_DECL([], [old_postinstall_cmds], [2])\n_LT_DECL([], [old_postuninstall_cmds], [2])\n_LT_TAGDECL([], [old_archive_cmds], [2],\n    [Commands used to build an old-style archive])\n_LT_DECL([], [lock_old_archive_extraction], [0],\n    [Whether to use a lock for old archive extraction])\n])# _LT_CMD_OLD_ARCHIVE\n\n\n# _LT_COMPILER_OPTION(MESSAGE, VARIABLE-NAME, FLAGS,\n#\t\t[OUTPUT-FILE], [ACTION-SUCCESS], [ACTION-FAILURE])\n# ----------------------------------------------------------------\n# Check whether the given compiler option works\nAC_DEFUN([_LT_COMPILER_OPTION],\n[m4_require([_LT_FILEUTILS_DEFAULTS])dnl\nm4_require([_LT_DECL_SED])dnl\nAC_CACHE_CHECK([$1], [$2],\n  [$2=no\n   m4_if([$4], , [ac_outfile=conftest.$ac_objext], [ac_outfile=$4])\n   echo \"$lt_simple_compile_test_code\" > conftest.$ac_ext\n   lt_compiler_flag=\"$3\"  ## exclude from sc_useless_quotes_in_assignment\n   # Insert the option either (1) after the last *FLAGS variable, or\n   # (2) before a word containing \"conftest.\", or (3) at the end.\n   # Note that $ac_compile itself does not contain backslashes and begins\n   # with a dollar sign (not a hyphen), so the echo should work correctly.\n   # The option is referenced via a variable to avoid confusing sed.\n   lt_compile=`echo \"$ac_compile\" | $SED \\\n   -e 's:.*FLAGS}\\{0,1\\} :&$lt_compiler_flag :; t' \\\n   -e 's: [[^ ]]*conftest\\.: $lt_compiler_flag&:; t' \\\n   -e 's:$: $lt_compiler_flag:'`\n   (eval echo \"\\\"\\$as_me:$LINENO: $lt_compile\\\"\" >&AS_MESSAGE_LOG_FD)\n   (eval \"$lt_compile\" 2>conftest.err)\n   ac_status=$?\n   cat conftest.err >&AS_MESSAGE_LOG_FD\n   echo \"$as_me:$LINENO: \\$? = $ac_status\" >&AS_MESSAGE_LOG_FD\n   if (exit $ac_status) && test -s \"$ac_outfile\"; then\n     # The compiler can only warn and ignore the option if not recognized\n     # So say no if there are warnings other than the usual output.\n     $ECHO \"$_lt_compiler_boilerplate\" | $SED '/^$/d' >conftest.exp\n     $SED '/^$/d; /^ *+/d' conftest.err >conftest.er2\n     if test ! -s conftest.er2 || diff conftest.exp conftest.er2 >/dev/null; then\n       $2=yes\n     fi\n   fi\n   $RM conftest*\n])\n\nif test yes = \"[$]$2\"; then\n    m4_if([$5], , :, [$5])\nelse\n    m4_if([$6], , :, [$6])\nfi\n])# _LT_COMPILER_OPTION\n\n# Old name:\nAU_ALIAS([AC_LIBTOOL_COMPILER_OPTION], [_LT_COMPILER_OPTION])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_LIBTOOL_COMPILER_OPTION], [])\n\n\n# _LT_LINKER_OPTION(MESSAGE, VARIABLE-NAME, FLAGS,\n#                  [ACTION-SUCCESS], [ACTION-FAILURE])\n# ----------------------------------------------------\n# Check whether the given linker option works\nAC_DEFUN([_LT_LINKER_OPTION],\n[m4_require([_LT_FILEUTILS_DEFAULTS])dnl\nm4_require([_LT_DECL_SED])dnl\nAC_CACHE_CHECK([$1], [$2],\n  [$2=no\n   save_LDFLAGS=$LDFLAGS\n   LDFLAGS=\"$LDFLAGS $3\"\n   echo \"$lt_simple_link_test_code\" > conftest.$ac_ext\n   if (eval $ac_link 2>conftest.err) && test -s conftest$ac_exeext; then\n     # The linker can only warn and ignore the option if not recognized\n     # So say no if there are warnings\n     if test -s conftest.err; then\n       # Append any errors to the config.log.\n       cat conftest.err 1>&AS_MESSAGE_LOG_FD\n       $ECHO \"$_lt_linker_boilerplate\" | $SED '/^$/d' > conftest.exp\n       $SED '/^$/d; /^ *+/d' conftest.err >conftest.er2\n       if diff conftest.exp conftest.er2 >/dev/null; then\n         $2=yes\n       fi\n     else\n       $2=yes\n     fi\n   fi\n   $RM -r conftest*\n   LDFLAGS=$save_LDFLAGS\n])\n\nif test yes = \"[$]$2\"; then\n    m4_if([$4], , :, [$4])\nelse\n    m4_if([$5], , :, [$5])\nfi\n])# _LT_LINKER_OPTION\n\n# Old name:\nAU_ALIAS([AC_LIBTOOL_LINKER_OPTION], [_LT_LINKER_OPTION])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_LIBTOOL_LINKER_OPTION], [])\n\n\n# LT_CMD_MAX_LEN\n#---------------\nAC_DEFUN([LT_CMD_MAX_LEN],\n[AC_REQUIRE([AC_CANONICAL_HOST])dnl\n# find the maximum length of command line arguments\nAC_MSG_CHECKING([the maximum length of command line arguments])\nAC_CACHE_VAL([lt_cv_sys_max_cmd_len], [dnl\n  i=0\n  teststring=ABCD\n\n  case $build_os in\n  msdosdjgpp*)\n    # On DJGPP, this test can blow up pretty badly due to problems in libc\n    # (any single argument exceeding 2000 bytes causes a buffer overrun\n    # during glob expansion).  Even if it were fixed, the result of this\n    # check would be larger than it should be.\n    lt_cv_sys_max_cmd_len=12288;    # 12K is about right\n    ;;\n\n  gnu*)\n    # Under GNU Hurd, this test is not required because there is\n    # no limit to the length of command line arguments.\n    # Libtool will interpret -1 as no limit whatsoever\n    lt_cv_sys_max_cmd_len=-1;\n    ;;\n\n  cygwin* | mingw* | cegcc*)\n    # On Win9x/ME, this test blows up -- it succeeds, but takes\n    # about 5 minutes as the teststring grows exponentially.\n    # Worse, since 9x/ME are not pre-emptively multitasking,\n    # you end up with a \"frozen\" computer, even though with patience\n    # the test eventually succeeds (with a max line length of 256k).\n    # Instead, let's just punt: use the minimum linelength reported by\n    # all of the supported platforms: 8192 (on NT/2K/XP).\n    lt_cv_sys_max_cmd_len=8192;\n    ;;\n\n  mint*)\n    # On MiNT this can take a long time and run out of memory.\n    lt_cv_sys_max_cmd_len=8192;\n    ;;\n\n  amigaos*)\n    # On AmigaOS with pdksh, this test takes hours, literally.\n    # So we just punt and use a minimum line length of 8192.\n    lt_cv_sys_max_cmd_len=8192;\n    ;;\n\n  bitrig* | darwin* | dragonfly* | freebsd* | netbsd* | openbsd*)\n    # This has been around since 386BSD, at least.  Likely further.\n    if test -x /sbin/sysctl; then\n      lt_cv_sys_max_cmd_len=`/sbin/sysctl -n kern.argmax`\n    elif test -x /usr/sbin/sysctl; then\n      lt_cv_sys_max_cmd_len=`/usr/sbin/sysctl -n kern.argmax`\n    else\n      lt_cv_sys_max_cmd_len=65536\t# usable default for all BSDs\n    fi\n    # And add a safety zone\n    lt_cv_sys_max_cmd_len=`expr $lt_cv_sys_max_cmd_len \\/ 4`\n    lt_cv_sys_max_cmd_len=`expr $lt_cv_sys_max_cmd_len \\* 3`\n    ;;\n\n  interix*)\n    # We know the value 262144 and hardcode it with a safety zone (like BSD)\n    lt_cv_sys_max_cmd_len=196608\n    ;;\n\n  os2*)\n    # The test takes a long time on OS/2.\n    lt_cv_sys_max_cmd_len=8192\n    ;;\n\n  osf*)\n    # Dr. Hans Ekkehard Plesser reports seeing a kernel panic running configure\n    # due to this test when exec_disable_arg_limit is 1 on Tru64. It is not\n    # nice to cause kernel panics so lets avoid the loop below.\n    # First set a reasonable default.\n    lt_cv_sys_max_cmd_len=16384\n    #\n    if test -x /sbin/sysconfig; then\n      case `/sbin/sysconfig -q proc exec_disable_arg_limit` in\n        *1*) lt_cv_sys_max_cmd_len=-1 ;;\n      esac\n    fi\n    ;;\n  sco3.2v5*)\n    lt_cv_sys_max_cmd_len=102400\n    ;;\n  sysv5* | sco5v6* | sysv4.2uw2*)\n    kargmax=`grep ARG_MAX /etc/conf/cf.d/stune 2>/dev/null`\n    if test -n \"$kargmax\"; then\n      lt_cv_sys_max_cmd_len=`echo $kargmax | sed 's/.*[[\t ]]//'`\n    else\n      lt_cv_sys_max_cmd_len=32768\n    fi\n    ;;\n  *)\n    lt_cv_sys_max_cmd_len=`(getconf ARG_MAX) 2> /dev/null`\n    if test -n \"$lt_cv_sys_max_cmd_len\" && \\\n       test undefined != \"$lt_cv_sys_max_cmd_len\"; then\n      lt_cv_sys_max_cmd_len=`expr $lt_cv_sys_max_cmd_len \\/ 4`\n      lt_cv_sys_max_cmd_len=`expr $lt_cv_sys_max_cmd_len \\* 3`\n    else\n      # Make teststring a little bigger before we do anything with it.\n      # a 1K string should be a reasonable start.\n      for i in 1 2 3 4 5 6 7 8; do\n        teststring=$teststring$teststring\n      done\n      SHELL=${SHELL-${CONFIG_SHELL-/bin/sh}}\n      # If test is not a shell built-in, we'll probably end up computing a\n      # maximum length that is only half of the actual maximum length, but\n      # we can't tell.\n      while { test X`env echo \"$teststring$teststring\" 2>/dev/null` \\\n\t         = \"X$teststring$teststring\"; } >/dev/null 2>&1 &&\n\t      test 17 != \"$i\" # 1/2 MB should be enough\n      do\n        i=`expr $i + 1`\n        teststring=$teststring$teststring\n      done\n      # Only check the string length outside the loop.\n      lt_cv_sys_max_cmd_len=`expr \"X$teststring\" : \".*\" 2>&1`\n      teststring=\n      # Add a significant safety factor because C++ compilers can tack on\n      # massive amounts of additional arguments before passing them to the\n      # linker.  It appears as though 1/2 is a usable value.\n      lt_cv_sys_max_cmd_len=`expr $lt_cv_sys_max_cmd_len \\/ 2`\n    fi\n    ;;\n  esac\n])\nif test -n \"$lt_cv_sys_max_cmd_len\"; then\n  AC_MSG_RESULT($lt_cv_sys_max_cmd_len)\nelse\n  AC_MSG_RESULT(none)\nfi\nmax_cmd_len=$lt_cv_sys_max_cmd_len\n_LT_DECL([], [max_cmd_len], [0],\n    [What is the maximum length of a command?])\n])# LT_CMD_MAX_LEN\n\n# Old name:\nAU_ALIAS([AC_LIBTOOL_SYS_MAX_CMD_LEN], [LT_CMD_MAX_LEN])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_LIBTOOL_SYS_MAX_CMD_LEN], [])\n\n\n# _LT_HEADER_DLFCN\n# ----------------\nm4_defun([_LT_HEADER_DLFCN],\n[AC_CHECK_HEADERS([dlfcn.h], [], [], [AC_INCLUDES_DEFAULT])dnl\n])# _LT_HEADER_DLFCN\n\n\n# _LT_TRY_DLOPEN_SELF (ACTION-IF-TRUE, ACTION-IF-TRUE-W-USCORE,\n#                      ACTION-IF-FALSE, ACTION-IF-CROSS-COMPILING)\n# ----------------------------------------------------------------\nm4_defun([_LT_TRY_DLOPEN_SELF],\n[m4_require([_LT_HEADER_DLFCN])dnl\nif test yes = \"$cross_compiling\"; then :\n  [$4]\nelse\n  lt_dlunknown=0; lt_dlno_uscore=1; lt_dlneed_uscore=2\n  lt_status=$lt_dlunknown\n  cat > conftest.$ac_ext <<_LT_EOF\n[#line $LINENO \"configure\"\n#include \"confdefs.h\"\n\n#if HAVE_DLFCN_H\n#include <dlfcn.h>\n#endif\n\n#include <stdio.h>\n\n#ifdef RTLD_GLOBAL\n#  define LT_DLGLOBAL\t\tRTLD_GLOBAL\n#else\n#  ifdef DL_GLOBAL\n#    define LT_DLGLOBAL\t\tDL_GLOBAL\n#  else\n#    define LT_DLGLOBAL\t\t0\n#  endif\n#endif\n\n/* We may have to define LT_DLLAZY_OR_NOW in the command line if we\n   find out it does not work in some platform. */\n#ifndef LT_DLLAZY_OR_NOW\n#  ifdef RTLD_LAZY\n#    define LT_DLLAZY_OR_NOW\t\tRTLD_LAZY\n#  else\n#    ifdef DL_LAZY\n#      define LT_DLLAZY_OR_NOW\t\tDL_LAZY\n#    else\n#      ifdef RTLD_NOW\n#        define LT_DLLAZY_OR_NOW\tRTLD_NOW\n#      else\n#        ifdef DL_NOW\n#          define LT_DLLAZY_OR_NOW\tDL_NOW\n#        else\n#          define LT_DLLAZY_OR_NOW\t0\n#        endif\n#      endif\n#    endif\n#  endif\n#endif\n\n/* When -fvisibility=hidden is used, assume the code has been annotated\n   correspondingly for the symbols needed.  */\n#if defined __GNUC__ && (((__GNUC__ == 3) && (__GNUC_MINOR__ >= 3)) || (__GNUC__ > 3))\nint fnord () __attribute__((visibility(\"default\")));\n#endif\n\nint fnord () { return 42; }\nint main ()\n{\n  void *self = dlopen (0, LT_DLGLOBAL|LT_DLLAZY_OR_NOW);\n  int status = $lt_dlunknown;\n\n  if (self)\n    {\n      if (dlsym (self,\"fnord\"))       status = $lt_dlno_uscore;\n      else\n        {\n\t  if (dlsym( self,\"_fnord\"))  status = $lt_dlneed_uscore;\n          else puts (dlerror ());\n\t}\n      /* dlclose (self); */\n    }\n  else\n    puts (dlerror ());\n\n  return status;\n}]\n_LT_EOF\n  if AC_TRY_EVAL(ac_link) && test -s \"conftest$ac_exeext\" 2>/dev/null; then\n    (./conftest; exit; ) >&AS_MESSAGE_LOG_FD 2>/dev/null\n    lt_status=$?\n    case x$lt_status in\n      x$lt_dlno_uscore) $1 ;;\n      x$lt_dlneed_uscore) $2 ;;\n      x$lt_dlunknown|x*) $3 ;;\n    esac\n  else :\n    # compilation failed\n    $3\n  fi\nfi\nrm -fr conftest*\n])# _LT_TRY_DLOPEN_SELF\n\n\n# LT_SYS_DLOPEN_SELF\n# ------------------\nAC_DEFUN([LT_SYS_DLOPEN_SELF],\n[m4_require([_LT_HEADER_DLFCN])dnl\nif test yes != \"$enable_dlopen\"; then\n  enable_dlopen=unknown\n  enable_dlopen_self=unknown\n  enable_dlopen_self_static=unknown\nelse\n  lt_cv_dlopen=no\n  lt_cv_dlopen_libs=\n\n  case $host_os in\n  beos*)\n    lt_cv_dlopen=load_add_on\n    lt_cv_dlopen_libs=\n    lt_cv_dlopen_self=yes\n    ;;\n\n  mingw* | pw32* | cegcc*)\n    lt_cv_dlopen=LoadLibrary\n    lt_cv_dlopen_libs=\n    ;;\n\n  cygwin*)\n    lt_cv_dlopen=dlopen\n    lt_cv_dlopen_libs=\n    ;;\n\n  darwin*)\n    # if libdl is installed we need to link against it\n    AC_CHECK_LIB([dl], [dlopen],\n\t\t[lt_cv_dlopen=dlopen lt_cv_dlopen_libs=-ldl],[\n    lt_cv_dlopen=dyld\n    lt_cv_dlopen_libs=\n    lt_cv_dlopen_self=yes\n    ])\n    ;;\n\n  tpf*)\n    # Don't try to run any link tests for TPF.  We know it's impossible\n    # because TPF is a cross-compiler, and we know how we open DSOs.\n    lt_cv_dlopen=dlopen\n    lt_cv_dlopen_libs=\n    lt_cv_dlopen_self=no\n    ;;\n\n  *)\n    AC_CHECK_FUNC([shl_load],\n\t  [lt_cv_dlopen=shl_load],\n      [AC_CHECK_LIB([dld], [shl_load],\n\t    [lt_cv_dlopen=shl_load lt_cv_dlopen_libs=-ldld],\n\t[AC_CHECK_FUNC([dlopen],\n\t      [lt_cv_dlopen=dlopen],\n\t  [AC_CHECK_LIB([dl], [dlopen],\n\t\t[lt_cv_dlopen=dlopen lt_cv_dlopen_libs=-ldl],\n\t    [AC_CHECK_LIB([svld], [dlopen],\n\t\t  [lt_cv_dlopen=dlopen lt_cv_dlopen_libs=-lsvld],\n\t      [AC_CHECK_LIB([dld], [dld_link],\n\t\t    [lt_cv_dlopen=dld_link lt_cv_dlopen_libs=-ldld])\n\t      ])\n\t    ])\n\t  ])\n\t])\n      ])\n    ;;\n  esac\n\n  if test no = \"$lt_cv_dlopen\"; then\n    enable_dlopen=no\n  else\n    enable_dlopen=yes\n  fi\n\n  case $lt_cv_dlopen in\n  dlopen)\n    save_CPPFLAGS=$CPPFLAGS\n    test yes = \"$ac_cv_header_dlfcn_h\" && CPPFLAGS=\"$CPPFLAGS -DHAVE_DLFCN_H\"\n\n    save_LDFLAGS=$LDFLAGS\n    wl=$lt_prog_compiler_wl eval LDFLAGS=\\\"\\$LDFLAGS $export_dynamic_flag_spec\\\"\n\n    save_LIBS=$LIBS\n    LIBS=\"$lt_cv_dlopen_libs $LIBS\"\n\n    AC_CACHE_CHECK([whether a program can dlopen itself],\n\t  lt_cv_dlopen_self, [dnl\n\t  _LT_TRY_DLOPEN_SELF(\n\t    lt_cv_dlopen_self=yes, lt_cv_dlopen_self=yes,\n\t    lt_cv_dlopen_self=no, lt_cv_dlopen_self=cross)\n    ])\n\n    if test yes = \"$lt_cv_dlopen_self\"; then\n      wl=$lt_prog_compiler_wl eval LDFLAGS=\\\"\\$LDFLAGS $lt_prog_compiler_static\\\"\n      AC_CACHE_CHECK([whether a statically linked program can dlopen itself],\n\t  lt_cv_dlopen_self_static, [dnl\n\t  _LT_TRY_DLOPEN_SELF(\n\t    lt_cv_dlopen_self_static=yes, lt_cv_dlopen_self_static=yes,\n\t    lt_cv_dlopen_self_static=no,  lt_cv_dlopen_self_static=cross)\n      ])\n    fi\n\n    CPPFLAGS=$save_CPPFLAGS\n    LDFLAGS=$save_LDFLAGS\n    LIBS=$save_LIBS\n    ;;\n  esac\n\n  case $lt_cv_dlopen_self in\n  yes|no) enable_dlopen_self=$lt_cv_dlopen_self ;;\n  *) enable_dlopen_self=unknown ;;\n  esac\n\n  case $lt_cv_dlopen_self_static in\n  yes|no) enable_dlopen_self_static=$lt_cv_dlopen_self_static ;;\n  *) enable_dlopen_self_static=unknown ;;\n  esac\nfi\n_LT_DECL([dlopen_support], [enable_dlopen], [0],\n\t [Whether dlopen is supported])\n_LT_DECL([dlopen_self], [enable_dlopen_self], [0],\n\t [Whether dlopen of programs is supported])\n_LT_DECL([dlopen_self_static], [enable_dlopen_self_static], [0],\n\t [Whether dlopen of statically linked programs is supported])\n])# LT_SYS_DLOPEN_SELF\n\n# Old name:\nAU_ALIAS([AC_LIBTOOL_DLOPEN_SELF], [LT_SYS_DLOPEN_SELF])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_LIBTOOL_DLOPEN_SELF], [])\n\n\n# _LT_COMPILER_C_O([TAGNAME])\n# ---------------------------\n# Check to see if options -c and -o are simultaneously supported by compiler.\n# This macro does not hard code the compiler like AC_PROG_CC_C_O.\nm4_defun([_LT_COMPILER_C_O],\n[m4_require([_LT_DECL_SED])dnl\nm4_require([_LT_FILEUTILS_DEFAULTS])dnl\nm4_require([_LT_TAG_COMPILER])dnl\nAC_CACHE_CHECK([if $compiler supports -c -o file.$ac_objext],\n  [_LT_TAGVAR(lt_cv_prog_compiler_c_o, $1)],\n  [_LT_TAGVAR(lt_cv_prog_compiler_c_o, $1)=no\n   $RM -r conftest 2>/dev/null\n   mkdir conftest\n   cd conftest\n   mkdir out\n   echo \"$lt_simple_compile_test_code\" > conftest.$ac_ext\n\n   lt_compiler_flag=\"-o out/conftest2.$ac_objext\"\n   # Insert the option either (1) after the last *FLAGS variable, or\n   # (2) before a word containing \"conftest.\", or (3) at the end.\n   # Note that $ac_compile itself does not contain backslashes and begins\n   # with a dollar sign (not a hyphen), so the echo should work correctly.\n   lt_compile=`echo \"$ac_compile\" | $SED \\\n   -e 's:.*FLAGS}\\{0,1\\} :&$lt_compiler_flag :; t' \\\n   -e 's: [[^ ]]*conftest\\.: $lt_compiler_flag&:; t' \\\n   -e 's:$: $lt_compiler_flag:'`\n   (eval echo \"\\\"\\$as_me:$LINENO: $lt_compile\\\"\" >&AS_MESSAGE_LOG_FD)\n   (eval \"$lt_compile\" 2>out/conftest.err)\n   ac_status=$?\n   cat out/conftest.err >&AS_MESSAGE_LOG_FD\n   echo \"$as_me:$LINENO: \\$? = $ac_status\" >&AS_MESSAGE_LOG_FD\n   if (exit $ac_status) && test -s out/conftest2.$ac_objext\n   then\n     # The compiler can only warn and ignore the option if not recognized\n     # So say no if there are warnings\n     $ECHO \"$_lt_compiler_boilerplate\" | $SED '/^$/d' > out/conftest.exp\n     $SED '/^$/d; /^ *+/d' out/conftest.err >out/conftest.er2\n     if test ! -s out/conftest.er2 || diff out/conftest.exp out/conftest.er2 >/dev/null; then\n       _LT_TAGVAR(lt_cv_prog_compiler_c_o, $1)=yes\n     fi\n   fi\n   chmod u+w . 2>&AS_MESSAGE_LOG_FD\n   $RM conftest*\n   # SGI C++ compiler will create directory out/ii_files/ for\n   # template instantiation\n   test -d out/ii_files && $RM out/ii_files/* && rmdir out/ii_files\n   $RM out/* && rmdir out\n   cd ..\n   $RM -r conftest\n   $RM conftest*\n])\n_LT_TAGDECL([compiler_c_o], [lt_cv_prog_compiler_c_o], [1],\n\t[Does compiler simultaneously support -c and -o options?])\n])# _LT_COMPILER_C_O\n\n\n# _LT_COMPILER_FILE_LOCKS([TAGNAME])\n# ----------------------------------\n# Check to see if we can do hard links to lock some files if needed\nm4_defun([_LT_COMPILER_FILE_LOCKS],\n[m4_require([_LT_ENABLE_LOCK])dnl\nm4_require([_LT_FILEUTILS_DEFAULTS])dnl\n_LT_COMPILER_C_O([$1])\n\nhard_links=nottested\nif test no = \"$_LT_TAGVAR(lt_cv_prog_compiler_c_o, $1)\" && test no != \"$need_locks\"; then\n  # do not overwrite the value of need_locks provided by the user\n  AC_MSG_CHECKING([if we can lock with hard links])\n  hard_links=yes\n  $RM conftest*\n  ln conftest.a conftest.b 2>/dev/null && hard_links=no\n  touch conftest.a\n  ln conftest.a conftest.b 2>&5 || hard_links=no\n  ln conftest.a conftest.b 2>/dev/null && hard_links=no\n  AC_MSG_RESULT([$hard_links])\n  if test no = \"$hard_links\"; then\n    AC_MSG_WARN(['$CC' does not support '-c -o', so 'make -j' may be unsafe])\n    need_locks=warn\n  fi\nelse\n  need_locks=no\nfi\n_LT_DECL([], [need_locks], [1], [Must we lock files when doing compilation?])\n])# _LT_COMPILER_FILE_LOCKS\n\n\n# _LT_CHECK_OBJDIR\n# ----------------\nm4_defun([_LT_CHECK_OBJDIR],\n[AC_CACHE_CHECK([for objdir], [lt_cv_objdir],\n[rm -f .libs 2>/dev/null\nmkdir .libs 2>/dev/null\nif test -d .libs; then\n  lt_cv_objdir=.libs\nelse\n  # MS-DOS does not allow filenames that begin with a dot.\n  lt_cv_objdir=_libs\nfi\nrmdir .libs 2>/dev/null])\nobjdir=$lt_cv_objdir\n_LT_DECL([], [objdir], [0],\n         [The name of the directory that contains temporary libtool files])dnl\nm4_pattern_allow([LT_OBJDIR])dnl\nAC_DEFINE_UNQUOTED([LT_OBJDIR], \"$lt_cv_objdir/\",\n  [Define to the sub-directory where libtool stores uninstalled libraries.])\n])# _LT_CHECK_OBJDIR\n\n\n# _LT_LINKER_HARDCODE_LIBPATH([TAGNAME])\n# --------------------------------------\n# Check hardcoding attributes.\nm4_defun([_LT_LINKER_HARDCODE_LIBPATH],\n[AC_MSG_CHECKING([how to hardcode library paths into programs])\n_LT_TAGVAR(hardcode_action, $1)=\nif test -n \"$_LT_TAGVAR(hardcode_libdir_flag_spec, $1)\" ||\n   test -n \"$_LT_TAGVAR(runpath_var, $1)\" ||\n   test yes = \"$_LT_TAGVAR(hardcode_automatic, $1)\"; then\n\n  # We can hardcode non-existent directories.\n  if test no != \"$_LT_TAGVAR(hardcode_direct, $1)\" &&\n     # If the only mechanism to avoid hardcoding is shlibpath_var, we\n     # have to relink, otherwise we might link with an installed library\n     # when we should be linking with a yet-to-be-installed one\n     ## test no != \"$_LT_TAGVAR(hardcode_shlibpath_var, $1)\" &&\n     test no != \"$_LT_TAGVAR(hardcode_minus_L, $1)\"; then\n    # Linking always hardcodes the temporary library directory.\n    _LT_TAGVAR(hardcode_action, $1)=relink\n  else\n    # We can link without hardcoding, and we can hardcode nonexisting dirs.\n    _LT_TAGVAR(hardcode_action, $1)=immediate\n  fi\nelse\n  # We cannot hardcode anything, or else we can only hardcode existing\n  # directories.\n  _LT_TAGVAR(hardcode_action, $1)=unsupported\nfi\nAC_MSG_RESULT([$_LT_TAGVAR(hardcode_action, $1)])\n\nif test relink = \"$_LT_TAGVAR(hardcode_action, $1)\" ||\n   test yes = \"$_LT_TAGVAR(inherit_rpath, $1)\"; then\n  # Fast installation is not supported\n  enable_fast_install=no\nelif test yes = \"$shlibpath_overrides_runpath\" ||\n     test no = \"$enable_shared\"; then\n  # Fast installation is not necessary\n  enable_fast_install=needless\nfi\n_LT_TAGDECL([], [hardcode_action], [0],\n    [How to hardcode a shared library path into an executable])\n])# _LT_LINKER_HARDCODE_LIBPATH\n\n\n# _LT_CMD_STRIPLIB\n# ----------------\nm4_defun([_LT_CMD_STRIPLIB],\n[m4_require([_LT_DECL_EGREP])\nstriplib=\nold_striplib=\nAC_MSG_CHECKING([whether stripping libraries is possible])\nif test -n \"$STRIP\" && $STRIP -V 2>&1 | $GREP \"GNU strip\" >/dev/null; then\n  test -z \"$old_striplib\" && old_striplib=\"$STRIP --strip-debug\"\n  test -z \"$striplib\" && striplib=\"$STRIP --strip-unneeded\"\n  AC_MSG_RESULT([yes])\nelse\n# FIXME - insert some real tests, host_os isn't really good enough\n  case $host_os in\n  darwin*)\n    if test -n \"$STRIP\"; then\n      striplib=\"$STRIP -x\"\n      old_striplib=\"$STRIP -S\"\n      AC_MSG_RESULT([yes])\n    else\n      AC_MSG_RESULT([no])\n    fi\n    ;;\n  *)\n    AC_MSG_RESULT([no])\n    ;;\n  esac\nfi\n_LT_DECL([], [old_striplib], [1], [Commands to strip libraries])\n_LT_DECL([], [striplib], [1])\n])# _LT_CMD_STRIPLIB\n\n\n# _LT_PREPARE_MUNGE_PATH_LIST\n# ---------------------------\n# Make sure func_munge_path_list() is defined correctly.\nm4_defun([_LT_PREPARE_MUNGE_PATH_LIST],\n[[# func_munge_path_list VARIABLE PATH\n# -----------------------------------\n# VARIABLE is name of variable containing _space_ separated list of\n# directories to be munged by the contents of PATH, which is string\n# having a format:\n# \"DIR[:DIR]:\"\n#       string \"DIR[ DIR]\" will be prepended to VARIABLE\n# \":DIR[:DIR]\"\n#       string \"DIR[ DIR]\" will be appended to VARIABLE\n# \"DIRP[:DIRP]::[DIRA:]DIRA\"\n#       string \"DIRP[ DIRP]\" will be prepended to VARIABLE and string\n#       \"DIRA[ DIRA]\" will be appended to VARIABLE\n# \"DIR[:DIR]\"\n#       VARIABLE will be replaced by \"DIR[ DIR]\"\nfunc_munge_path_list ()\n{\n    case x@S|@2 in\n    x)\n        ;;\n    *:)\n        eval @S|@1=\\\"`$ECHO @S|@2 | $SED 's/:/ /g'` \\@S|@@S|@1\\\"\n        ;;\n    x:*)\n        eval @S|@1=\\\"\\@S|@@S|@1 `$ECHO @S|@2 | $SED 's/:/ /g'`\\\"\n        ;;\n    *::*)\n        eval @S|@1=\\\"\\@S|@@S|@1\\ `$ECHO @S|@2 | $SED -e 's/.*:://' -e 's/:/ /g'`\\\"\n        eval @S|@1=\\\"`$ECHO @S|@2 | $SED -e 's/::.*//' -e 's/:/ /g'`\\ \\@S|@@S|@1\\\"\n        ;;\n    *)\n        eval @S|@1=\\\"`$ECHO @S|@2 | $SED 's/:/ /g'`\\\"\n        ;;\n    esac\n}\n]])# _LT_PREPARE_PATH_LIST\n\n\n# _LT_SYS_DYNAMIC_LINKER([TAG])\n# -----------------------------\n# PORTME Fill in your ld.so characteristics\nm4_defun([_LT_SYS_DYNAMIC_LINKER],\n[AC_REQUIRE([AC_CANONICAL_HOST])dnl\nm4_require([_LT_DECL_EGREP])dnl\nm4_require([_LT_FILEUTILS_DEFAULTS])dnl\nm4_require([_LT_DECL_OBJDUMP])dnl\nm4_require([_LT_DECL_SED])dnl\nm4_require([_LT_CHECK_SHELL_FEATURES])dnl\nm4_require([_LT_PREPARE_MUNGE_PATH_LIST])dnl\nAC_MSG_CHECKING([dynamic linker characteristics])\nm4_if([$1],\n\t[], [\nif test yes = \"$GCC\"; then\n  case $host_os in\n    darwin*) lt_awk_arg='/^libraries:/,/LR/' ;;\n    *) lt_awk_arg='/^libraries:/' ;;\n  esac\n  case $host_os in\n    mingw* | cegcc*) lt_sed_strip_eq='s|=\\([[A-Za-z]]:\\)|\\1|g' ;;\n    *) lt_sed_strip_eq='s|=/|/|g' ;;\n  esac\n  lt_search_path_spec=`$CC -print-search-dirs | awk $lt_awk_arg | $SED -e \"s/^libraries://\" -e $lt_sed_strip_eq`\n  case $lt_search_path_spec in\n  *\\;*)\n    # if the path contains \";\" then we assume it to be the separator\n    # otherwise default to the standard path separator (i.e. \":\") - it is\n    # assumed that no part of a normal pathname contains \";\" but that should\n    # okay in the real world where \";\" in dirpaths is itself problematic.\n    lt_search_path_spec=`$ECHO \"$lt_search_path_spec\" | $SED 's/;/ /g'`\n    ;;\n  *)\n    lt_search_path_spec=`$ECHO \"$lt_search_path_spec\" | $SED \"s/$PATH_SEPARATOR/ /g\"`\n    ;;\n  esac\n  # Ok, now we have the path, separated by spaces, we can step through it\n  # and add multilib dir if necessary...\n  lt_tmp_lt_search_path_spec=\n  lt_multi_os_dir=/`$CC $CPPFLAGS $CFLAGS $LDFLAGS -print-multi-os-directory 2>/dev/null`\n  # ...but if some path component already ends with the multilib dir we assume\n  # that all is fine and trust -print-search-dirs as is (GCC 4.2? or newer).\n  case \"$lt_multi_os_dir; $lt_search_path_spec \" in\n  \"/; \"* | \"/.; \"* | \"/./; \"* | *\"$lt_multi_os_dir \"* | *\"$lt_multi_os_dir/ \"*)\n    lt_multi_os_dir=\n    ;;\n  esac\n  for lt_sys_path in $lt_search_path_spec; do\n    if test -d \"$lt_sys_path$lt_multi_os_dir\"; then\n      lt_tmp_lt_search_path_spec=\"$lt_tmp_lt_search_path_spec $lt_sys_path$lt_multi_os_dir\"\n    elif test -n \"$lt_multi_os_dir\"; then\n      test -d \"$lt_sys_path\" && \\\n\tlt_tmp_lt_search_path_spec=\"$lt_tmp_lt_search_path_spec $lt_sys_path\"\n    fi\n  done\n  lt_search_path_spec=`$ECHO \"$lt_tmp_lt_search_path_spec\" | awk '\nBEGIN {RS = \" \"; FS = \"/|\\n\";} {\n  lt_foo = \"\";\n  lt_count = 0;\n  for (lt_i = NF; lt_i > 0; lt_i--) {\n    if ($lt_i != \"\" && $lt_i != \".\") {\n      if ($lt_i == \"..\") {\n        lt_count++;\n      } else {\n        if (lt_count == 0) {\n          lt_foo = \"/\" $lt_i lt_foo;\n        } else {\n          lt_count--;\n        }\n      }\n    }\n  }\n  if (lt_foo != \"\") { lt_freq[[lt_foo]]++; }\n  if (lt_freq[[lt_foo]] == 1) { print lt_foo; }\n}'`\n  # AWK program above erroneously prepends '/' to C:/dos/paths\n  # for these hosts.\n  case $host_os in\n    mingw* | cegcc*) lt_search_path_spec=`$ECHO \"$lt_search_path_spec\" |\\\n      $SED 's|/\\([[A-Za-z]]:\\)|\\1|g'` ;;\n  esac\n  sys_lib_search_path_spec=`$ECHO \"$lt_search_path_spec\" | $lt_NL2SP`\nelse\n  sys_lib_search_path_spec=\"/lib /usr/lib /usr/local/lib\"\nfi])\nlibrary_names_spec=\nlibname_spec='lib$name'\nsoname_spec=\nshrext_cmds=.so\npostinstall_cmds=\npostuninstall_cmds=\nfinish_cmds=\nfinish_eval=\nshlibpath_var=\nshlibpath_overrides_runpath=unknown\nversion_type=none\ndynamic_linker=\"$host_os ld.so\"\nsys_lib_dlsearch_path_spec=\"/lib /usr/lib\"\nneed_lib_prefix=unknown\nhardcode_into_libs=no\n\n# when you set need_version to no, make sure it does not cause -set_version\n# flags to be left without arguments\nneed_version=unknown\n\nAC_ARG_VAR([LT_SYS_LIBRARY_PATH],\n[User-defined run-time library search path.])\n\ncase $host_os in\naix3*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  library_names_spec='$libname$release$shared_ext$versuffix $libname.a'\n  shlibpath_var=LIBPATH\n\n  # AIX 3 has no versioning support, so we append a major version to the name.\n  soname_spec='$libname$release$shared_ext$major'\n  ;;\n\naix[[4-9]]*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  need_lib_prefix=no\n  need_version=no\n  hardcode_into_libs=yes\n  if test ia64 = \"$host_cpu\"; then\n    # AIX 5 supports IA64\n    library_names_spec='$libname$release$shared_ext$major $libname$release$shared_ext$versuffix $libname$shared_ext'\n    shlibpath_var=LD_LIBRARY_PATH\n  else\n    # With GCC up to 2.95.x, collect2 would create an import file\n    # for dependence libraries.  The import file would start with\n    # the line '#! .'.  This would cause the generated library to\n    # depend on '.', always an invalid library.  This was fixed in\n    # development snapshots of GCC prior to 3.0.\n    case $host_os in\n      aix4 | aix4.[[01]] | aix4.[[01]].*)\n      if { echo '#if __GNUC__ > 2 || (__GNUC__ == 2 && __GNUC_MINOR__ >= 97)'\n\t   echo ' yes '\n\t   echo '#endif'; } | $CC -E - | $GREP yes > /dev/null; then\n\t:\n      else\n\tcan_build_shared=no\n      fi\n      ;;\n    esac\n    # Using Import Files as archive members, it is possible to support\n    # filename-based versioning of shared library archives on AIX. While\n    # this would work for both with and without runtime linking, it will\n    # prevent static linking of such archives. So we do filename-based\n    # shared library versioning with .so extension only, which is used\n    # when both runtime linking and shared linking is enabled.\n    # Unfortunately, runtime linking may impact performance, so we do\n    # not want this to be the default eventually. Also, we use the\n    # versioned .so libs for executables only if there is the -brtl\n    # linker flag in LDFLAGS as well, or --with-aix-soname=svr4 only.\n    # To allow for filename-based versioning support, we need to create\n    # libNAME.so.V as an archive file, containing:\n    # *) an Import File, referring to the versioned filename of the\n    #    archive as well as the shared archive member, telling the\n    #    bitwidth (32 or 64) of that shared object, and providing the\n    #    list of exported symbols of that shared object, eventually\n    #    decorated with the 'weak' keyword\n    # *) the shared object with the F_LOADONLY flag set, to really avoid\n    #    it being seen by the linker.\n    # At run time we better use the real file rather than another symlink,\n    # but for link time we create the symlink libNAME.so -> libNAME.so.V\n\n    case $with_aix_soname,$aix_use_runtimelinking in\n    # AIX (on Power*) has no versioning support, so currently we cannot hardcode correct\n    # soname into executable. Probably we can add versioning support to\n    # collect2, so additional links can be useful in future.\n    aix,yes) # traditional libtool\n      dynamic_linker='AIX unversionable lib.so'\n      # If using run time linking (on AIX 4.2 or later) use lib<name>.so\n      # instead of lib<name>.a to let people know that these are not\n      # typical AIX shared libraries.\n      library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n      ;;\n    aix,no) # traditional AIX only\n      dynamic_linker='AIX lib.a[(]lib.so.V[)]'\n      # We preserve .a as extension for shared libraries through AIX4.2\n      # and later when we are not doing run time linking.\n      library_names_spec='$libname$release.a $libname.a'\n      soname_spec='$libname$release$shared_ext$major'\n      ;;\n    svr4,*) # full svr4 only\n      dynamic_linker=\"AIX lib.so.V[(]$shared_archive_member_spec.o[)]\"\n      library_names_spec='$libname$release$shared_ext$major $libname$shared_ext'\n      # We do not specify a path in Import Files, so LIBPATH fires.\n      shlibpath_overrides_runpath=yes\n      ;;\n    *,yes) # both, prefer svr4\n      dynamic_linker=\"AIX lib.so.V[(]$shared_archive_member_spec.o[)], lib.a[(]lib.so.V[)]\"\n      library_names_spec='$libname$release$shared_ext$major $libname$shared_ext'\n      # unpreferred sharedlib libNAME.a needs extra handling\n      postinstall_cmds='test -n \"$linkname\" || linkname=\"$realname\"~func_stripname \"\" \".so\" \"$linkname\"~$install_shared_prog \"$dir/$func_stripname_result.$libext\" \"$destdir/$func_stripname_result.$libext\"~test -z \"$tstripme\" || test -z \"$striplib\" || $striplib \"$destdir/$func_stripname_result.$libext\"'\n      postuninstall_cmds='for n in $library_names $old_library; do :; done~func_stripname \"\" \".so\" \"$n\"~test \"$func_stripname_result\" = \"$n\" || func_append rmfiles \" $odir/$func_stripname_result.$libext\"'\n      # We do not specify a path in Import Files, so LIBPATH fires.\n      shlibpath_overrides_runpath=yes\n      ;;\n    *,no) # both, prefer aix\n      dynamic_linker=\"AIX lib.a[(]lib.so.V[)], lib.so.V[(]$shared_archive_member_spec.o[)]\"\n      library_names_spec='$libname$release.a $libname.a'\n      soname_spec='$libname$release$shared_ext$major'\n      # unpreferred sharedlib libNAME.so.V and symlink libNAME.so need extra handling\n      postinstall_cmds='test -z \"$dlname\" || $install_shared_prog $dir/$dlname $destdir/$dlname~test -z \"$tstripme\" || test -z \"$striplib\" || $striplib $destdir/$dlname~test -n \"$linkname\" || linkname=$realname~func_stripname \"\" \".a\" \"$linkname\"~(cd \"$destdir\" && $LN_S -f $dlname $func_stripname_result.so)'\n      postuninstall_cmds='test -z \"$dlname\" || func_append rmfiles \" $odir/$dlname\"~for n in $old_library $library_names; do :; done~func_stripname \"\" \".a\" \"$n\"~func_append rmfiles \" $odir/$func_stripname_result.so\"'\n      ;;\n    esac\n    shlibpath_var=LIBPATH\n  fi\n  ;;\n\namigaos*)\n  case $host_cpu in\n  powerpc)\n    # Since July 2007 AmigaOS4 officially supports .so libraries.\n    # When compiling the executable, add -use-dynld -Lsobjs: to the compileline.\n    library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n    ;;\n  m68k)\n    library_names_spec='$libname.ixlibrary $libname.a'\n    # Create ${libname}_ixlibrary.a entries in /sys/libs.\n    finish_eval='for lib in `ls $libdir/*.ixlibrary 2>/dev/null`; do libname=`func_echo_all \"$lib\" | $SED '\\''s%^.*/\\([[^/]]*\\)\\.ixlibrary$%\\1%'\\''`; $RM /sys/libs/${libname}_ixlibrary.a; $show \"cd /sys/libs && $LN_S $lib ${libname}_ixlibrary.a\"; cd /sys/libs && $LN_S $lib ${libname}_ixlibrary.a || exit 1; done'\n    ;;\n  esac\n  ;;\n\nbeos*)\n  library_names_spec='$libname$shared_ext'\n  dynamic_linker=\"$host_os ld.so\"\n  shlibpath_var=LIBRARY_PATH\n  ;;\n\nbsdi[[45]]*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  need_version=no\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  finish_cmds='PATH=\"\\$PATH:/sbin\" ldconfig $libdir'\n  shlibpath_var=LD_LIBRARY_PATH\n  sys_lib_search_path_spec=\"/shlib /usr/lib /usr/X11/lib /usr/contrib/lib /lib /usr/local/lib\"\n  sys_lib_dlsearch_path_spec=\"/shlib /usr/lib /usr/local/lib\"\n  # the default ld.so.conf also contains /usr/contrib/lib and\n  # /usr/X11R6/lib (/usr/X11 is a link to /usr/X11R6), but let us allow\n  # libtool to hard-code these into programs\n  ;;\n\ncygwin* | mingw* | pw32* | cegcc*)\n  version_type=windows\n  shrext_cmds=.dll\n  need_version=no\n  need_lib_prefix=no\n\n  case $GCC,$cc_basename in\n  yes,*)\n    # gcc\n    library_names_spec='$libname.dll.a'\n    # DLL is installed to $(libdir)/../bin by postinstall_cmds\n    postinstall_cmds='base_file=`basename \\$file`~\n      dlpath=`$SHELL 2>&1 -c '\\''. $dir/'\\''\\$base_file'\\''i; echo \\$dlname'\\''`~\n      dldir=$destdir/`dirname \\$dlpath`~\n      test -d \\$dldir || mkdir -p \\$dldir~\n      $install_prog $dir/$dlname \\$dldir/$dlname~\n      chmod a+x \\$dldir/$dlname~\n      if test -n '\\''$stripme'\\'' && test -n '\\''$striplib'\\''; then\n        eval '\\''$striplib \\$dldir/$dlname'\\'' || exit \\$?;\n      fi'\n    postuninstall_cmds='dldll=`$SHELL 2>&1 -c '\\''. $file; echo \\$dlname'\\''`~\n      dlpath=$dir/\\$dldll~\n       $RM \\$dlpath'\n    shlibpath_overrides_runpath=yes\n\n    case $host_os in\n    cygwin*)\n      # Cygwin DLLs use 'cyg' prefix rather than 'lib'\n      soname_spec='`echo $libname | sed -e 's/^lib/cyg/'``echo $release | $SED -e 's/[[.]]/-/g'`$versuffix$shared_ext'\nm4_if([$1], [],[\n      sys_lib_search_path_spec=\"$sys_lib_search_path_spec /usr/lib/w32api\"])\n      ;;\n    mingw* | cegcc*)\n      # MinGW DLLs use traditional 'lib' prefix\n      soname_spec='$libname`echo $release | $SED -e 's/[[.]]/-/g'`$versuffix$shared_ext'\n      ;;\n    pw32*)\n      # pw32 DLLs use 'pw' prefix rather than 'lib'\n      library_names_spec='`echo $libname | sed -e 's/^lib/pw/'``echo $release | $SED -e 's/[[.]]/-/g'`$versuffix$shared_ext'\n      ;;\n    esac\n    dynamic_linker='Win32 ld.exe'\n    ;;\n\n  *,cl*)\n    # Native MSVC\n    libname_spec='$name'\n    soname_spec='$libname`echo $release | $SED -e 's/[[.]]/-/g'`$versuffix$shared_ext'\n    library_names_spec='$libname.dll.lib'\n\n    case $build_os in\n    mingw*)\n      sys_lib_search_path_spec=\n      lt_save_ifs=$IFS\n      IFS=';'\n      for lt_path in $LIB\n      do\n        IFS=$lt_save_ifs\n        # Let DOS variable expansion print the short 8.3 style file name.\n        lt_path=`cd \"$lt_path\" 2>/dev/null && cmd //C \"for %i in (\".\") do @echo %~si\"`\n        sys_lib_search_path_spec=\"$sys_lib_search_path_spec $lt_path\"\n      done\n      IFS=$lt_save_ifs\n      # Convert to MSYS style.\n      sys_lib_search_path_spec=`$ECHO \"$sys_lib_search_path_spec\" | sed -e 's|\\\\\\\\|/|g' -e 's| \\\\([[a-zA-Z]]\\\\):| /\\\\1|g' -e 's|^ ||'`\n      ;;\n    cygwin*)\n      # Convert to unix form, then to dos form, then back to unix form\n      # but this time dos style (no spaces!) so that the unix form looks\n      # like /cygdrive/c/PROGRA~1:/cygdr...\n      sys_lib_search_path_spec=`cygpath --path --unix \"$LIB\"`\n      sys_lib_search_path_spec=`cygpath --path --dos \"$sys_lib_search_path_spec\" 2>/dev/null`\n      sys_lib_search_path_spec=`cygpath --path --unix \"$sys_lib_search_path_spec\" | $SED -e \"s/$PATH_SEPARATOR/ /g\"`\n      ;;\n    *)\n      sys_lib_search_path_spec=$LIB\n      if $ECHO \"$sys_lib_search_path_spec\" | [$GREP ';[c-zC-Z]:/' >/dev/null]; then\n        # It is most probably a Windows format PATH.\n        sys_lib_search_path_spec=`$ECHO \"$sys_lib_search_path_spec\" | $SED -e 's/;/ /g'`\n      else\n        sys_lib_search_path_spec=`$ECHO \"$sys_lib_search_path_spec\" | $SED -e \"s/$PATH_SEPARATOR/ /g\"`\n      fi\n      # FIXME: find the short name or the path components, as spaces are\n      # common. (e.g. \"Program Files\" -> \"PROGRA~1\")\n      ;;\n    esac\n\n    # DLL is installed to $(libdir)/../bin by postinstall_cmds\n    postinstall_cmds='base_file=`basename \\$file`~\n      dlpath=`$SHELL 2>&1 -c '\\''. $dir/'\\''\\$base_file'\\''i; echo \\$dlname'\\''`~\n      dldir=$destdir/`dirname \\$dlpath`~\n      test -d \\$dldir || mkdir -p \\$dldir~\n      $install_prog $dir/$dlname \\$dldir/$dlname'\n    postuninstall_cmds='dldll=`$SHELL 2>&1 -c '\\''. $file; echo \\$dlname'\\''`~\n      dlpath=$dir/\\$dldll~\n       $RM \\$dlpath'\n    shlibpath_overrides_runpath=yes\n    dynamic_linker='Win32 link.exe'\n    ;;\n\n  *)\n    # Assume MSVC wrapper\n    library_names_spec='$libname`echo $release | $SED -e 's/[[.]]/-/g'`$versuffix$shared_ext $libname.lib'\n    dynamic_linker='Win32 ld.exe'\n    ;;\n  esac\n  # FIXME: first we should search . and the directory the executable is in\n  shlibpath_var=PATH\n  ;;\n\ndarwin* | rhapsody*)\n  dynamic_linker=\"$host_os dyld\"\n  version_type=darwin\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='$libname$release$major$shared_ext $libname$shared_ext'\n  soname_spec='$libname$release$major$shared_ext'\n  shlibpath_overrides_runpath=yes\n  shlibpath_var=DYLD_LIBRARY_PATH\n  shrext_cmds='`test .$module = .yes && echo .so || echo .dylib`'\nm4_if([$1], [],[\n  sys_lib_search_path_spec=\"$sys_lib_search_path_spec /usr/local/lib\"])\n  sys_lib_dlsearch_path_spec='/usr/local/lib /lib /usr/lib'\n  ;;\n\ndgux*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  shlibpath_var=LD_LIBRARY_PATH\n  ;;\n\nfreebsd* | dragonfly*)\n  # DragonFly does not have aout.  When/if they implement a new\n  # versioning mechanism, adjust this.\n  if test -x /usr/bin/objformat; then\n    objformat=`/usr/bin/objformat`\n  else\n    case $host_os in\n    freebsd[[23]].*) objformat=aout ;;\n    *) objformat=elf ;;\n    esac\n  fi\n  version_type=freebsd-$objformat\n  case $version_type in\n    freebsd-elf*)\n      library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n      soname_spec='$libname$release$shared_ext$major'\n      need_version=no\n      need_lib_prefix=no\n      ;;\n    freebsd-*)\n      library_names_spec='$libname$release$shared_ext$versuffix $libname$shared_ext$versuffix'\n      need_version=yes\n      ;;\n  esac\n  shlibpath_var=LD_LIBRARY_PATH\n  case $host_os in\n  freebsd2.*)\n    shlibpath_overrides_runpath=yes\n    ;;\n  freebsd3.[[01]]* | freebsdelf3.[[01]]*)\n    shlibpath_overrides_runpath=yes\n    hardcode_into_libs=yes\n    ;;\n  freebsd3.[[2-9]]* | freebsdelf3.[[2-9]]* | \\\n  freebsd4.[[0-5]] | freebsdelf4.[[0-5]] | freebsd4.1.1 | freebsdelf4.1.1)\n    shlibpath_overrides_runpath=no\n    hardcode_into_libs=yes\n    ;;\n  *) # from 4.6 on, and DragonFly\n    shlibpath_overrides_runpath=yes\n    hardcode_into_libs=yes\n    ;;\n  esac\n  ;;\n\nhaiku*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  need_lib_prefix=no\n  need_version=no\n  dynamic_linker=\"$host_os runtime_loader\"\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  shlibpath_var=LIBRARY_PATH\n  shlibpath_overrides_runpath=no\n  sys_lib_dlsearch_path_spec='/boot/home/config/lib /boot/common/lib /boot/system/lib'\n  hardcode_into_libs=yes\n  ;;\n\nhpux9* | hpux10* | hpux11*)\n  # Give a soname corresponding to the major version so that dld.sl refuses to\n  # link against other versions.\n  version_type=sunos\n  need_lib_prefix=no\n  need_version=no\n  case $host_cpu in\n  ia64*)\n    shrext_cmds='.so'\n    hardcode_into_libs=yes\n    dynamic_linker=\"$host_os dld.so\"\n    shlibpath_var=LD_LIBRARY_PATH\n    shlibpath_overrides_runpath=yes # Unless +noenvvar is specified.\n    library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n    soname_spec='$libname$release$shared_ext$major'\n    if test 32 = \"$HPUX_IA64_MODE\"; then\n      sys_lib_search_path_spec=\"/usr/lib/hpux32 /usr/local/lib/hpux32 /usr/local/lib\"\n      sys_lib_dlsearch_path_spec=/usr/lib/hpux32\n    else\n      sys_lib_search_path_spec=\"/usr/lib/hpux64 /usr/local/lib/hpux64\"\n      sys_lib_dlsearch_path_spec=/usr/lib/hpux64\n    fi\n    ;;\n  hppa*64*)\n    shrext_cmds='.sl'\n    hardcode_into_libs=yes\n    dynamic_linker=\"$host_os dld.sl\"\n    shlibpath_var=LD_LIBRARY_PATH # How should we handle SHLIB_PATH\n    shlibpath_overrides_runpath=yes # Unless +noenvvar is specified.\n    library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n    soname_spec='$libname$release$shared_ext$major'\n    sys_lib_search_path_spec=\"/usr/lib/pa20_64 /usr/ccs/lib/pa20_64\"\n    sys_lib_dlsearch_path_spec=$sys_lib_search_path_spec\n    ;;\n  *)\n    shrext_cmds='.sl'\n    dynamic_linker=\"$host_os dld.sl\"\n    shlibpath_var=SHLIB_PATH\n    shlibpath_overrides_runpath=no # +s is required to enable SHLIB_PATH\n    library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n    soname_spec='$libname$release$shared_ext$major'\n    ;;\n  esac\n  # HP-UX runs *really* slowly unless shared libraries are mode 555, ...\n  postinstall_cmds='chmod 555 $lib'\n  # or fails outright, so override atomically:\n  install_override_mode=555\n  ;;\n\ninterix[[3-9]]*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  dynamic_linker='Interix 3.x ld.so.1 (PE, like ELF)'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=no\n  hardcode_into_libs=yes\n  ;;\n\nirix5* | irix6* | nonstopux*)\n  case $host_os in\n    nonstopux*) version_type=nonstopux ;;\n    *)\n\tif test yes = \"$lt_cv_prog_gnu_ld\"; then\n\t\tversion_type=linux # correct to gnu/linux during the next big refactor\n\telse\n\t\tversion_type=irix\n\tfi ;;\n  esac\n  need_lib_prefix=no\n  need_version=no\n  soname_spec='$libname$release$shared_ext$major'\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$release$shared_ext $libname$shared_ext'\n  case $host_os in\n  irix5* | nonstopux*)\n    libsuff= shlibsuff=\n    ;;\n  *)\n    case $LD in # libtool.m4 will add one of these switches to LD\n    *-32|*\"-32 \"|*-melf32bsmip|*\"-melf32bsmip \")\n      libsuff= shlibsuff= libmagic=32-bit;;\n    *-n32|*\"-n32 \"|*-melf32bmipn32|*\"-melf32bmipn32 \")\n      libsuff=32 shlibsuff=N32 libmagic=N32;;\n    *-64|*\"-64 \"|*-melf64bmip|*\"-melf64bmip \")\n      libsuff=64 shlibsuff=64 libmagic=64-bit;;\n    *) libsuff= shlibsuff= libmagic=never-match;;\n    esac\n    ;;\n  esac\n  shlibpath_var=LD_LIBRARY${shlibsuff}_PATH\n  shlibpath_overrides_runpath=no\n  sys_lib_search_path_spec=\"/usr/lib$libsuff /lib$libsuff /usr/local/lib$libsuff\"\n  sys_lib_dlsearch_path_spec=\"/usr/lib$libsuff /lib$libsuff\"\n  hardcode_into_libs=yes\n  ;;\n\n# No shared lib support for Linux oldld, aout, or coff.\nlinux*oldld* | linux*aout* | linux*coff*)\n  dynamic_linker=no\n  ;;\n\nlinux*android*)\n  version_type=none # Android doesn't support versioned libraries.\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='$libname$release$shared_ext'\n  soname_spec='$libname$release$shared_ext'\n  finish_cmds=\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=yes\n\n  # This implies no fast_install, which is unacceptable.\n  # Some rework will be needed to allow for fast_install\n  # before this can be enabled.\n  hardcode_into_libs=yes\n\n  dynamic_linker='Android linker'\n  # Don't embed -rpath directories since the linker doesn't support them.\n  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n  ;;\n\n# This must be glibc/ELF.\nlinux* | k*bsd*-gnu | kopensolaris*-gnu | gnu*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  finish_cmds='PATH=\"\\$PATH:/sbin\" ldconfig -n $libdir'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=no\n\n  # Some binutils ld are patched to set DT_RUNPATH\n  AC_CACHE_VAL([lt_cv_shlibpath_overrides_runpath],\n    [lt_cv_shlibpath_overrides_runpath=no\n    save_LDFLAGS=$LDFLAGS\n    save_libdir=$libdir\n    eval \"libdir=/foo; wl=\\\"$_LT_TAGVAR(lt_prog_compiler_wl, $1)\\\"; \\\n\t LDFLAGS=\\\"\\$LDFLAGS $_LT_TAGVAR(hardcode_libdir_flag_spec, $1)\\\"\"\n    AC_LINK_IFELSE([AC_LANG_PROGRAM([],[])],\n      [AS_IF([ ($OBJDUMP -p conftest$ac_exeext) 2>/dev/null | grep \"RUNPATH.*$libdir\" >/dev/null],\n\t [lt_cv_shlibpath_overrides_runpath=yes])])\n    LDFLAGS=$save_LDFLAGS\n    libdir=$save_libdir\n    ])\n  shlibpath_overrides_runpath=$lt_cv_shlibpath_overrides_runpath\n\n  # This implies no fast_install, which is unacceptable.\n  # Some rework will be needed to allow for fast_install\n  # before this can be enabled.\n  hardcode_into_libs=yes\n\n  # Ideally, we could use ldconfig to report *all* directores which are\n  # searched for libraries, however this is still not possible.  Aside from not\n  # being certain /sbin/ldconfig is available, command\n  # 'ldconfig -N -X -v | grep ^/' on 64bit Fedora does not report /usr/lib64,\n  # even though it is searched at run-time.  Try to do the best guess by\n  # appending ld.so.conf contents (and includes) to the search path.\n  if test -f /etc/ld.so.conf; then\n    lt_ld_extra=`awk '/^include / { system(sprintf(\"cd /etc; cat %s 2>/dev/null\", \\[$]2)); skip = 1; } { if (!skip) print \\[$]0; skip = 0; }' < /etc/ld.so.conf | $SED -e 's/#.*//;/^[\t ]*hwcap[\t ]/d;s/[:,\t]/ /g;s/=[^=]*$//;s/=[^= ]* / /g;s/\"//g;/^$/d' | tr '\\n' ' '`\n    sys_lib_dlsearch_path_spec=\"/lib /usr/lib $lt_ld_extra\"\n  fi\n\n  # We used to test for /lib/ld.so.1 and disable shared libraries on\n  # powerpc, because MkLinux only supported shared libraries with the\n  # GNU dynamic linker.  Since this was broken with cross compilers,\n  # most powerpc-linux boxes support dynamic linking these days and\n  # people can always --disable-shared, the test was removed, and we\n  # assume the GNU/Linux dynamic linker is in use.\n  dynamic_linker='GNU/Linux ld.so'\n  ;;\n\nnetbsdelf*-gnu)\n  version_type=linux\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='${libname}${release}${shared_ext}$versuffix ${libname}${release}${shared_ext}$major ${libname}${shared_ext}'\n  soname_spec='${libname}${release}${shared_ext}$major'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=no\n  hardcode_into_libs=yes\n  dynamic_linker='NetBSD ld.elf_so'\n  ;;\n\nnetbsd*)\n  version_type=sunos\n  need_lib_prefix=no\n  need_version=no\n  if echo __ELF__ | $CC -E - | $GREP __ELF__ >/dev/null; then\n    library_names_spec='$libname$release$shared_ext$versuffix $libname$shared_ext$versuffix'\n    finish_cmds='PATH=\"\\$PATH:/sbin\" ldconfig -m $libdir'\n    dynamic_linker='NetBSD (a.out) ld.so'\n  else\n    library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n    soname_spec='$libname$release$shared_ext$major'\n    dynamic_linker='NetBSD ld.elf_so'\n  fi\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=yes\n  hardcode_into_libs=yes\n  ;;\n\nnewsos6)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=yes\n  ;;\n\n*nto* | *qnx*)\n  version_type=qnx\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=no\n  hardcode_into_libs=yes\n  dynamic_linker='ldqnx.so'\n  ;;\n\nopenbsd* | bitrig*)\n  version_type=sunos\n  sys_lib_dlsearch_path_spec=/usr/lib\n  need_lib_prefix=no\n  if test -z \"`echo __ELF__ | $CC -E - | $GREP __ELF__`\"; then\n    need_version=no\n  else\n    need_version=yes\n  fi\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$shared_ext$versuffix'\n  finish_cmds='PATH=\"\\$PATH:/sbin\" ldconfig -m $libdir'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=yes\n  ;;\n\nos2*)\n  libname_spec='$name'\n  version_type=windows\n  shrext_cmds=.dll\n  need_version=no\n  need_lib_prefix=no\n  # OS/2 can only load a DLL with a base name of 8 characters or less.\n  soname_spec='`test -n \"$os2dllname\" && libname=\"$os2dllname\";\n    v=$($ECHO $release$versuffix | tr -d .-);\n    n=$($ECHO $libname | cut -b -$((8 - ${#v})) | tr . _);\n    $ECHO $n$v`$shared_ext'\n  library_names_spec='${libname}_dll.$libext'\n  dynamic_linker='OS/2 ld.exe'\n  shlibpath_var=BEGINLIBPATH\n  sys_lib_search_path_spec=\"/lib /usr/lib /usr/local/lib\"\n  sys_lib_dlsearch_path_spec=$sys_lib_search_path_spec\n  postinstall_cmds='base_file=`basename \\$file`~\n    dlpath=`$SHELL 2>&1 -c '\\''. $dir/'\\''\\$base_file'\\''i; $ECHO \\$dlname'\\''`~\n    dldir=$destdir/`dirname \\$dlpath`~\n    test -d \\$dldir || mkdir -p \\$dldir~\n    $install_prog $dir/$dlname \\$dldir/$dlname~\n    chmod a+x \\$dldir/$dlname~\n    if test -n '\\''$stripme'\\'' && test -n '\\''$striplib'\\''; then\n      eval '\\''$striplib \\$dldir/$dlname'\\'' || exit \\$?;\n    fi'\n  postuninstall_cmds='dldll=`$SHELL 2>&1 -c '\\''. $file; $ECHO \\$dlname'\\''`~\n    dlpath=$dir/\\$dldll~\n    $RM \\$dlpath'\n  ;;\n\nosf3* | osf4* | osf5*)\n  version_type=osf\n  need_lib_prefix=no\n  need_version=no\n  soname_spec='$libname$release$shared_ext$major'\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  shlibpath_var=LD_LIBRARY_PATH\n  sys_lib_search_path_spec=\"/usr/shlib /usr/ccs/lib /usr/lib/cmplrs/cc /usr/lib /usr/local/lib /var/shlib\"\n  sys_lib_dlsearch_path_spec=$sys_lib_search_path_spec\n  ;;\n\nrdos*)\n  dynamic_linker=no\n  ;;\n\nsolaris*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=yes\n  hardcode_into_libs=yes\n  # ldd complains unless libraries are executable\n  postinstall_cmds='chmod +x $lib'\n  ;;\n\nsunos4*)\n  version_type=sunos\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$shared_ext$versuffix'\n  finish_cmds='PATH=\"\\$PATH:/usr/etc\" ldconfig $libdir'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=yes\n  if test yes = \"$with_gnu_ld\"; then\n    need_lib_prefix=no\n  fi\n  need_version=yes\n  ;;\n\nsysv4 | sysv4.3*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  shlibpath_var=LD_LIBRARY_PATH\n  case $host_vendor in\n    sni)\n      shlibpath_overrides_runpath=no\n      need_lib_prefix=no\n      runpath_var=LD_RUN_PATH\n      ;;\n    siemens)\n      need_lib_prefix=no\n      ;;\n    motorola)\n      need_lib_prefix=no\n      need_version=no\n      shlibpath_overrides_runpath=no\n      sys_lib_search_path_spec='/lib /usr/lib /usr/ccs/lib'\n      ;;\n  esac\n  ;;\n\nsysv4*MP*)\n  if test -d /usr/nec; then\n    version_type=linux # correct to gnu/linux during the next big refactor\n    library_names_spec='$libname$shared_ext.$versuffix $libname$shared_ext.$major $libname$shared_ext'\n    soname_spec='$libname$shared_ext.$major'\n    shlibpath_var=LD_LIBRARY_PATH\n  fi\n  ;;\n\nsysv5* | sco3.2v5* | sco5v6* | unixware* | OpenUNIX* | sysv4*uw2*)\n  version_type=sco\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=yes\n  hardcode_into_libs=yes\n  if test yes = \"$with_gnu_ld\"; then\n    sys_lib_search_path_spec='/usr/local/lib /usr/gnu/lib /usr/ccs/lib /usr/lib /lib'\n  else\n    sys_lib_search_path_spec='/usr/ccs/lib /usr/lib'\n    case $host_os in\n      sco3.2v5*)\n        sys_lib_search_path_spec=\"$sys_lib_search_path_spec /lib\"\n\t;;\n    esac\n  fi\n  sys_lib_dlsearch_path_spec='/usr/lib'\n  ;;\n\ntpf*)\n  # TPF is a cross-target only.  Preferred cross-host = GNU/Linux.\n  version_type=linux # correct to gnu/linux during the next big refactor\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=no\n  hardcode_into_libs=yes\n  ;;\n\nuts4*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  shlibpath_var=LD_LIBRARY_PATH\n  ;;\n\n*)\n  dynamic_linker=no\n  ;;\nesac\nAC_MSG_RESULT([$dynamic_linker])\ntest no = \"$dynamic_linker\" && can_build_shared=no\n\nvariables_saved_for_relink=\"PATH $shlibpath_var $runpath_var\"\nif test yes = \"$GCC\"; then\n  variables_saved_for_relink=\"$variables_saved_for_relink GCC_EXEC_PREFIX COMPILER_PATH LIBRARY_PATH\"\nfi\n\nif test set = \"${lt_cv_sys_lib_search_path_spec+set}\"; then\n  sys_lib_search_path_spec=$lt_cv_sys_lib_search_path_spec\nfi\n\nif test set = \"${lt_cv_sys_lib_dlsearch_path_spec+set}\"; then\n  sys_lib_dlsearch_path_spec=$lt_cv_sys_lib_dlsearch_path_spec\nfi\n\n# remember unaugmented sys_lib_dlsearch_path content for libtool script decls...\nconfigure_time_dlsearch_path=$sys_lib_dlsearch_path_spec\n\n# ... but it needs LT_SYS_LIBRARY_PATH munging for other configure-time code\nfunc_munge_path_list sys_lib_dlsearch_path_spec \"$LT_SYS_LIBRARY_PATH\"\n\n# to be used as default LT_SYS_LIBRARY_PATH value in generated libtool\nconfigure_time_lt_sys_library_path=$LT_SYS_LIBRARY_PATH\n\n_LT_DECL([], [variables_saved_for_relink], [1],\n    [Variables whose values should be saved in libtool wrapper scripts and\n    restored at link time])\n_LT_DECL([], [need_lib_prefix], [0],\n    [Do we need the \"lib\" prefix for modules?])\n_LT_DECL([], [need_version], [0], [Do we need a version for libraries?])\n_LT_DECL([], [version_type], [0], [Library versioning type])\n_LT_DECL([], [runpath_var], [0],  [Shared library runtime path variable])\n_LT_DECL([], [shlibpath_var], [0],[Shared library path variable])\n_LT_DECL([], [shlibpath_overrides_runpath], [0],\n    [Is shlibpath searched before the hard-coded library search path?])\n_LT_DECL([], [libname_spec], [1], [Format of library name prefix])\n_LT_DECL([], [library_names_spec], [1],\n    [[List of archive names.  First name is the real one, the rest are links.\n    The last name is the one that the linker finds with -lNAME]])\n_LT_DECL([], [soname_spec], [1],\n    [[The coded name of the library, if different from the real name]])\n_LT_DECL([], [install_override_mode], [1],\n    [Permission mode override for installation of shared libraries])\n_LT_DECL([], [postinstall_cmds], [2],\n    [Command to use after installation of a shared archive])\n_LT_DECL([], [postuninstall_cmds], [2],\n    [Command to use after uninstallation of a shared archive])\n_LT_DECL([], [finish_cmds], [2],\n    [Commands used to finish a libtool library installation in a directory])\n_LT_DECL([], [finish_eval], [1],\n    [[As \"finish_cmds\", except a single script fragment to be evaled but\n    not shown]])\n_LT_DECL([], [hardcode_into_libs], [0],\n    [Whether we should hardcode library paths into libraries])\n_LT_DECL([], [sys_lib_search_path_spec], [2],\n    [Compile-time system search path for libraries])\n_LT_DECL([sys_lib_dlsearch_path_spec], [configure_time_dlsearch_path], [2],\n    [Detected run-time system search path for libraries])\n_LT_DECL([], [configure_time_lt_sys_library_path], [2],\n    [Explicit LT_SYS_LIBRARY_PATH set during ./configure time])\n])# _LT_SYS_DYNAMIC_LINKER\n\n\n# _LT_PATH_TOOL_PREFIX(TOOL)\n# --------------------------\n# find a file program that can recognize shared library\nAC_DEFUN([_LT_PATH_TOOL_PREFIX],\n[m4_require([_LT_DECL_EGREP])dnl\nAC_MSG_CHECKING([for $1])\nAC_CACHE_VAL(lt_cv_path_MAGIC_CMD,\n[case $MAGIC_CMD in\n[[\\\\/*] |  ?:[\\\\/]*])\n  lt_cv_path_MAGIC_CMD=$MAGIC_CMD # Let the user override the test with a path.\n  ;;\n*)\n  lt_save_MAGIC_CMD=$MAGIC_CMD\n  lt_save_ifs=$IFS; IFS=$PATH_SEPARATOR\ndnl $ac_dummy forces splitting on constant user-supplied paths.\ndnl POSIX.2 word splitting is done only on the output of word expansions,\ndnl not every word.  This closes a longstanding sh security hole.\n  ac_dummy=\"m4_if([$2], , $PATH, [$2])\"\n  for ac_dir in $ac_dummy; do\n    IFS=$lt_save_ifs\n    test -z \"$ac_dir\" && ac_dir=.\n    if test -f \"$ac_dir/$1\"; then\n      lt_cv_path_MAGIC_CMD=$ac_dir/\"$1\"\n      if test -n \"$file_magic_test_file\"; then\n\tcase $deplibs_check_method in\n\t\"file_magic \"*)\n\t  file_magic_regex=`expr \"$deplibs_check_method\" : \"file_magic \\(.*\\)\"`\n\t  MAGIC_CMD=$lt_cv_path_MAGIC_CMD\n\t  if eval $file_magic_cmd \\$file_magic_test_file 2> /dev/null |\n\t    $EGREP \"$file_magic_regex\" > /dev/null; then\n\t    :\n\t  else\n\t    cat <<_LT_EOF 1>&2\n\n*** Warning: the command libtool uses to detect shared libraries,\n*** $file_magic_cmd, produces output that libtool cannot recognize.\n*** The result is that libtool may fail to recognize shared libraries\n*** as such.  This will affect the creation of libtool libraries that\n*** depend on shared libraries, but programs linked with such libtool\n*** libraries will work regardless of this problem.  Nevertheless, you\n*** may want to report the problem to your system manager and/or to\n*** bug-libtool@gnu.org\n\n_LT_EOF\n\t  fi ;;\n\tesac\n      fi\n      break\n    fi\n  done\n  IFS=$lt_save_ifs\n  MAGIC_CMD=$lt_save_MAGIC_CMD\n  ;;\nesac])\nMAGIC_CMD=$lt_cv_path_MAGIC_CMD\nif test -n \"$MAGIC_CMD\"; then\n  AC_MSG_RESULT($MAGIC_CMD)\nelse\n  AC_MSG_RESULT(no)\nfi\n_LT_DECL([], [MAGIC_CMD], [0],\n\t [Used to examine libraries when file_magic_cmd begins with \"file\"])dnl\n])# _LT_PATH_TOOL_PREFIX\n\n# Old name:\nAU_ALIAS([AC_PATH_TOOL_PREFIX], [_LT_PATH_TOOL_PREFIX])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_PATH_TOOL_PREFIX], [])\n\n\n# _LT_PATH_MAGIC\n# --------------\n# find a file program that can recognize a shared library\nm4_defun([_LT_PATH_MAGIC],\n[_LT_PATH_TOOL_PREFIX(${ac_tool_prefix}file, /usr/bin$PATH_SEPARATOR$PATH)\nif test -z \"$lt_cv_path_MAGIC_CMD\"; then\n  if test -n \"$ac_tool_prefix\"; then\n    _LT_PATH_TOOL_PREFIX(file, /usr/bin$PATH_SEPARATOR$PATH)\n  else\n    MAGIC_CMD=:\n  fi\nfi\n])# _LT_PATH_MAGIC\n\n\n# LT_PATH_LD\n# ----------\n# find the pathname to the GNU or non-GNU linker\nAC_DEFUN([LT_PATH_LD],\n[AC_REQUIRE([AC_PROG_CC])dnl\nAC_REQUIRE([AC_CANONICAL_HOST])dnl\nAC_REQUIRE([AC_CANONICAL_BUILD])dnl\nm4_require([_LT_DECL_SED])dnl\nm4_require([_LT_DECL_EGREP])dnl\nm4_require([_LT_PROG_ECHO_BACKSLASH])dnl\n\nAC_ARG_WITH([gnu-ld],\n    [AS_HELP_STRING([--with-gnu-ld],\n\t[assume the C compiler uses GNU ld @<:@default=no@:>@])],\n    [test no = \"$withval\" || with_gnu_ld=yes],\n    [with_gnu_ld=no])dnl\n\nac_prog=ld\nif test yes = \"$GCC\"; then\n  # Check if gcc -print-prog-name=ld gives a path.\n  AC_MSG_CHECKING([for ld used by $CC])\n  case $host in\n  *-*-mingw*)\n    # gcc leaves a trailing carriage return, which upsets mingw\n    ac_prog=`($CC -print-prog-name=ld) 2>&5 | tr -d '\\015'` ;;\n  *)\n    ac_prog=`($CC -print-prog-name=ld) 2>&5` ;;\n  esac\n  case $ac_prog in\n    # Accept absolute paths.\n    [[\\\\/]]* | ?:[[\\\\/]]*)\n      re_direlt='/[[^/]][[^/]]*/\\.\\./'\n      # Canonicalize the pathname of ld\n      ac_prog=`$ECHO \"$ac_prog\"| $SED 's%\\\\\\\\%/%g'`\n      while $ECHO \"$ac_prog\" | $GREP \"$re_direlt\" > /dev/null 2>&1; do\n\tac_prog=`$ECHO $ac_prog| $SED \"s%$re_direlt%/%\"`\n      done\n      test -z \"$LD\" && LD=$ac_prog\n      ;;\n  \"\")\n    # If it fails, then pretend we aren't using GCC.\n    ac_prog=ld\n    ;;\n  *)\n    # If it is relative, then search for the first ld in PATH.\n    with_gnu_ld=unknown\n    ;;\n  esac\nelif test yes = \"$with_gnu_ld\"; then\n  AC_MSG_CHECKING([for GNU ld])\nelse\n  AC_MSG_CHECKING([for non-GNU ld])\nfi\nAC_CACHE_VAL(lt_cv_path_LD,\n[if test -z \"$LD\"; then\n  lt_save_ifs=$IFS; IFS=$PATH_SEPARATOR\n  for ac_dir in $PATH; do\n    IFS=$lt_save_ifs\n    test -z \"$ac_dir\" && ac_dir=.\n    if test -f \"$ac_dir/$ac_prog\" || test -f \"$ac_dir/$ac_prog$ac_exeext\"; then\n      lt_cv_path_LD=$ac_dir/$ac_prog\n      # Check to see if the program is GNU ld.  I'd rather use --version,\n      # but apparently some variants of GNU ld only accept -v.\n      # Break only if it was the GNU/non-GNU ld that we prefer.\n      case `\"$lt_cv_path_LD\" -v 2>&1 </dev/null` in\n      *GNU* | *'with BFD'*)\n\ttest no != \"$with_gnu_ld\" && break\n\t;;\n      *)\n\ttest yes != \"$with_gnu_ld\" && break\n\t;;\n      esac\n    fi\n  done\n  IFS=$lt_save_ifs\nelse\n  lt_cv_path_LD=$LD # Let the user override the test with a path.\nfi])\nLD=$lt_cv_path_LD\nif test -n \"$LD\"; then\n  AC_MSG_RESULT($LD)\nelse\n  AC_MSG_RESULT(no)\nfi\ntest -z \"$LD\" && AC_MSG_ERROR([no acceptable ld found in \\$PATH])\n_LT_PATH_LD_GNU\nAC_SUBST([LD])\n\n_LT_TAGDECL([], [LD], [1], [The linker used to build libraries])\n])# LT_PATH_LD\n\n# Old names:\nAU_ALIAS([AM_PROG_LD], [LT_PATH_LD])\nAU_ALIAS([AC_PROG_LD], [LT_PATH_LD])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AM_PROG_LD], [])\ndnl AC_DEFUN([AC_PROG_LD], [])\n\n\n# _LT_PATH_LD_GNU\n#- --------------\nm4_defun([_LT_PATH_LD_GNU],\n[AC_CACHE_CHECK([if the linker ($LD) is GNU ld], lt_cv_prog_gnu_ld,\n[# I'd rather use --version here, but apparently some GNU lds only accept -v.\ncase `$LD -v 2>&1 </dev/null` in\n*GNU* | *'with BFD'*)\n  lt_cv_prog_gnu_ld=yes\n  ;;\n*)\n  lt_cv_prog_gnu_ld=no\n  ;;\nesac])\nwith_gnu_ld=$lt_cv_prog_gnu_ld\n])# _LT_PATH_LD_GNU\n\n\n# _LT_CMD_RELOAD\n# --------------\n# find reload flag for linker\n#   -- PORTME Some linkers may need a different reload flag.\nm4_defun([_LT_CMD_RELOAD],\n[AC_CACHE_CHECK([for $LD option to reload object files],\n  lt_cv_ld_reload_flag,\n  [lt_cv_ld_reload_flag='-r'])\nreload_flag=$lt_cv_ld_reload_flag\ncase $reload_flag in\n\"\" | \" \"*) ;;\n*) reload_flag=\" $reload_flag\" ;;\nesac\nreload_cmds='$LD$reload_flag -o $output$reload_objs'\ncase $host_os in\n  cygwin* | mingw* | pw32* | cegcc*)\n    if test yes != \"$GCC\"; then\n      reload_cmds=false\n    fi\n    ;;\n  darwin*)\n    if test yes = \"$GCC\"; then\n      reload_cmds='$LTCC $LTCFLAGS -nostdlib $wl-r -o $output$reload_objs'\n    else\n      reload_cmds='$LD$reload_flag -o $output$reload_objs'\n    fi\n    ;;\nesac\n_LT_TAGDECL([], [reload_flag], [1], [How to create reloadable object files])dnl\n_LT_TAGDECL([], [reload_cmds], [2])dnl\n])# _LT_CMD_RELOAD\n\n\n# _LT_PATH_DD\n# -----------\n# find a working dd\nm4_defun([_LT_PATH_DD],\n[AC_CACHE_CHECK([for a working dd], [ac_cv_path_lt_DD],\n[printf 0123456789abcdef0123456789abcdef >conftest.i\ncat conftest.i conftest.i >conftest2.i\n: ${lt_DD:=$DD}\nAC_PATH_PROGS_FEATURE_CHECK([lt_DD], [dd],\n[if \"$ac_path_lt_DD\" bs=32 count=1 <conftest2.i >conftest.out 2>/dev/null; then\n  cmp -s conftest.i conftest.out \\\n  && ac_cv_path_lt_DD=\"$ac_path_lt_DD\" ac_path_lt_DD_found=:\nfi])\nrm -f conftest.i conftest2.i conftest.out])\n])# _LT_PATH_DD\n\n\n# _LT_CMD_TRUNCATE\n# ----------------\n# find command to truncate a binary pipe\nm4_defun([_LT_CMD_TRUNCATE],\n[m4_require([_LT_PATH_DD])\nAC_CACHE_CHECK([how to truncate binary pipes], [lt_cv_truncate_bin],\n[printf 0123456789abcdef0123456789abcdef >conftest.i\ncat conftest.i conftest.i >conftest2.i\nlt_cv_truncate_bin=\nif \"$ac_cv_path_lt_DD\" bs=32 count=1 <conftest2.i >conftest.out 2>/dev/null; then\n  cmp -s conftest.i conftest.out \\\n  && lt_cv_truncate_bin=\"$ac_cv_path_lt_DD bs=4096 count=1\"\nfi\nrm -f conftest.i conftest2.i conftest.out\ntest -z \"$lt_cv_truncate_bin\" && lt_cv_truncate_bin=\"$SED -e 4q\"])\n_LT_DECL([lt_truncate_bin], [lt_cv_truncate_bin], [1],\n  [Command to truncate a binary pipe])\n])# _LT_CMD_TRUNCATE\n\n\n# _LT_CHECK_MAGIC_METHOD\n# ----------------------\n# how to check for library dependencies\n#  -- PORTME fill in with the dynamic library characteristics\nm4_defun([_LT_CHECK_MAGIC_METHOD],\n[m4_require([_LT_DECL_EGREP])\nm4_require([_LT_DECL_OBJDUMP])\nAC_CACHE_CHECK([how to recognize dependent libraries],\nlt_cv_deplibs_check_method,\n[lt_cv_file_magic_cmd='$MAGIC_CMD'\nlt_cv_file_magic_test_file=\nlt_cv_deplibs_check_method='unknown'\n# Need to set the preceding variable on all platforms that support\n# interlibrary dependencies.\n# 'none' -- dependencies not supported.\n# 'unknown' -- same as none, but documents that we really don't know.\n# 'pass_all' -- all dependencies passed with no checks.\n# 'test_compile' -- check by making test program.\n# 'file_magic [[regex]]' -- check by looking for files in library path\n# that responds to the $file_magic_cmd with a given extended regex.\n# If you have 'file' or equivalent on your system and you're not sure\n# whether 'pass_all' will *always* work, you probably want this one.\n\ncase $host_os in\naix[[4-9]]*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nbeos*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nbsdi[[45]]*)\n  lt_cv_deplibs_check_method='file_magic ELF [[0-9]][[0-9]]*-bit [[ML]]SB (shared object|dynamic lib)'\n  lt_cv_file_magic_cmd='/usr/bin/file -L'\n  lt_cv_file_magic_test_file=/shlib/libc.so\n  ;;\n\ncygwin*)\n  # func_win32_libid is a shell function defined in ltmain.sh\n  lt_cv_deplibs_check_method='file_magic ^x86 archive import|^x86 DLL'\n  lt_cv_file_magic_cmd='func_win32_libid'\n  ;;\n\nmingw* | pw32*)\n  # Base MSYS/MinGW do not provide the 'file' command needed by\n  # func_win32_libid shell function, so use a weaker test based on 'objdump',\n  # unless we find 'file', for example because we are cross-compiling.\n  if ( file / ) >/dev/null 2>&1; then\n    lt_cv_deplibs_check_method='file_magic ^x86 archive import|^x86 DLL'\n    lt_cv_file_magic_cmd='func_win32_libid'\n  else\n    # Keep this pattern in sync with the one in func_win32_libid.\n    lt_cv_deplibs_check_method='file_magic file format (pei*-i386(.*architecture: i386)?|pe-arm-wince|pe-x86-64)'\n    lt_cv_file_magic_cmd='$OBJDUMP -f'\n  fi\n  ;;\n\ncegcc*)\n  # use the weaker test based on 'objdump'. See mingw*.\n  lt_cv_deplibs_check_method='file_magic file format pe-arm-.*little(.*architecture: arm)?'\n  lt_cv_file_magic_cmd='$OBJDUMP -f'\n  ;;\n\ndarwin* | rhapsody*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nfreebsd* | dragonfly*)\n  if echo __ELF__ | $CC -E - | $GREP __ELF__ > /dev/null; then\n    case $host_cpu in\n    i*86 )\n      # Not sure whether the presence of OpenBSD here was a mistake.\n      # Let's accept both of them until this is cleared up.\n      lt_cv_deplibs_check_method='file_magic (FreeBSD|OpenBSD|DragonFly)/i[[3-9]]86 (compact )?demand paged shared library'\n      lt_cv_file_magic_cmd=/usr/bin/file\n      lt_cv_file_magic_test_file=`echo /usr/lib/libc.so.*`\n      ;;\n    esac\n  else\n    lt_cv_deplibs_check_method=pass_all\n  fi\n  ;;\n\nhaiku*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nhpux10.20* | hpux11*)\n  lt_cv_file_magic_cmd=/usr/bin/file\n  case $host_cpu in\n  ia64*)\n    lt_cv_deplibs_check_method='file_magic (s[[0-9]][[0-9]][[0-9]]|ELF-[[0-9]][[0-9]]) shared object file - IA64'\n    lt_cv_file_magic_test_file=/usr/lib/hpux32/libc.so\n    ;;\n  hppa*64*)\n    [lt_cv_deplibs_check_method='file_magic (s[0-9][0-9][0-9]|ELF[ -][0-9][0-9])(-bit)?( [LM]SB)? shared object( file)?[, -]* PA-RISC [0-9]\\.[0-9]']\n    lt_cv_file_magic_test_file=/usr/lib/pa20_64/libc.sl\n    ;;\n  *)\n    lt_cv_deplibs_check_method='file_magic (s[[0-9]][[0-9]][[0-9]]|PA-RISC[[0-9]]\\.[[0-9]]) shared library'\n    lt_cv_file_magic_test_file=/usr/lib/libc.sl\n    ;;\n  esac\n  ;;\n\ninterix[[3-9]]*)\n  # PIC code is broken on Interix 3.x, that's why |\\.a not |_pic\\.a here\n  lt_cv_deplibs_check_method='match_pattern /lib[[^/]]+(\\.so|\\.a)$'\n  ;;\n\nirix5* | irix6* | nonstopux*)\n  case $LD in\n  *-32|*\"-32 \") libmagic=32-bit;;\n  *-n32|*\"-n32 \") libmagic=N32;;\n  *-64|*\"-64 \") libmagic=64-bit;;\n  *) libmagic=never-match;;\n  esac\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\n# This must be glibc/ELF.\nlinux* | k*bsd*-gnu | kopensolaris*-gnu | gnu*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nnetbsd* | netbsdelf*-gnu)\n  if echo __ELF__ | $CC -E - | $GREP __ELF__ > /dev/null; then\n    lt_cv_deplibs_check_method='match_pattern /lib[[^/]]+(\\.so\\.[[0-9]]+\\.[[0-9]]+|_pic\\.a)$'\n  else\n    lt_cv_deplibs_check_method='match_pattern /lib[[^/]]+(\\.so|_pic\\.a)$'\n  fi\n  ;;\n\nnewos6*)\n  lt_cv_deplibs_check_method='file_magic ELF [[0-9]][[0-9]]*-bit [[ML]]SB (executable|dynamic lib)'\n  lt_cv_file_magic_cmd=/usr/bin/file\n  lt_cv_file_magic_test_file=/usr/lib/libnls.so\n  ;;\n\n*nto* | *qnx*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nopenbsd* | bitrig*)\n  if test -z \"`echo __ELF__ | $CC -E - | $GREP __ELF__`\"; then\n    lt_cv_deplibs_check_method='match_pattern /lib[[^/]]+(\\.so\\.[[0-9]]+\\.[[0-9]]+|\\.so|_pic\\.a)$'\n  else\n    lt_cv_deplibs_check_method='match_pattern /lib[[^/]]+(\\.so\\.[[0-9]]+\\.[[0-9]]+|_pic\\.a)$'\n  fi\n  ;;\n\nosf3* | osf4* | osf5*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nrdos*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nsolaris*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nsysv5* | sco3.2v5* | sco5v6* | unixware* | OpenUNIX* | sysv4*uw2*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nsysv4 | sysv4.3*)\n  case $host_vendor in\n  motorola)\n    lt_cv_deplibs_check_method='file_magic ELF [[0-9]][[0-9]]*-bit [[ML]]SB (shared object|dynamic lib) M[[0-9]][[0-9]]* Version [[0-9]]'\n    lt_cv_file_magic_test_file=`echo /usr/lib/libc.so*`\n    ;;\n  ncr)\n    lt_cv_deplibs_check_method=pass_all\n    ;;\n  sequent)\n    lt_cv_file_magic_cmd='/bin/file'\n    lt_cv_deplibs_check_method='file_magic ELF [[0-9]][[0-9]]*-bit [[LM]]SB (shared object|dynamic lib )'\n    ;;\n  sni)\n    lt_cv_file_magic_cmd='/bin/file'\n    lt_cv_deplibs_check_method=\"file_magic ELF [[0-9]][[0-9]]*-bit [[LM]]SB dynamic lib\"\n    lt_cv_file_magic_test_file=/lib/libc.so\n    ;;\n  siemens)\n    lt_cv_deplibs_check_method=pass_all\n    ;;\n  pc)\n    lt_cv_deplibs_check_method=pass_all\n    ;;\n  esac\n  ;;\n\ntpf*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\nos2*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\nesac\n])\n\nfile_magic_glob=\nwant_nocaseglob=no\nif test \"$build\" = \"$host\"; then\n  case $host_os in\n  mingw* | pw32*)\n    if ( shopt | grep nocaseglob ) >/dev/null 2>&1; then\n      want_nocaseglob=yes\n    else\n      file_magic_glob=`echo aAbBcCdDeEfFgGhHiIjJkKlLmMnNoOpPqQrRsStTuUvVwWxXyYzZ | $SED -e \"s/\\(..\\)/s\\/[[\\1]]\\/[[\\1]]\\/g;/g\"`\n    fi\n    ;;\n  esac\nfi\n\nfile_magic_cmd=$lt_cv_file_magic_cmd\ndeplibs_check_method=$lt_cv_deplibs_check_method\ntest -z \"$deplibs_check_method\" && deplibs_check_method=unknown\n\n_LT_DECL([], [deplibs_check_method], [1],\n    [Method to check whether dependent libraries are shared objects])\n_LT_DECL([], [file_magic_cmd], [1],\n    [Command to use when deplibs_check_method = \"file_magic\"])\n_LT_DECL([], [file_magic_glob], [1],\n    [How to find potential files when deplibs_check_method = \"file_magic\"])\n_LT_DECL([], [want_nocaseglob], [1],\n    [Find potential files using nocaseglob when deplibs_check_method = \"file_magic\"])\n])# _LT_CHECK_MAGIC_METHOD\n\n\n# LT_PATH_NM\n# ----------\n# find the pathname to a BSD- or MS-compatible name lister\nAC_DEFUN([LT_PATH_NM],\n[AC_REQUIRE([AC_PROG_CC])dnl\nAC_CACHE_CHECK([for BSD- or MS-compatible name lister (nm)], lt_cv_path_NM,\n[if test -n \"$NM\"; then\n  # Let the user override the test.\n  lt_cv_path_NM=$NM\nelse\n  lt_nm_to_check=${ac_tool_prefix}nm\n  if test -n \"$ac_tool_prefix\" && test \"$build\" = \"$host\"; then\n    lt_nm_to_check=\"$lt_nm_to_check nm\"\n  fi\n  for lt_tmp_nm in $lt_nm_to_check; do\n    lt_save_ifs=$IFS; IFS=$PATH_SEPARATOR\n    for ac_dir in $PATH /usr/ccs/bin/elf /usr/ccs/bin /usr/ucb /bin; do\n      IFS=$lt_save_ifs\n      test -z \"$ac_dir\" && ac_dir=.\n      tmp_nm=$ac_dir/$lt_tmp_nm\n      if test -f \"$tmp_nm\" || test -f \"$tmp_nm$ac_exeext\"; then\n\t# Check to see if the nm accepts a BSD-compat flag.\n\t# Adding the 'sed 1q' prevents false positives on HP-UX, which says:\n\t#   nm: unknown option \"B\" ignored\n\t# Tru64's nm complains that /dev/null is an invalid object file\n\t# MSYS converts /dev/null to NUL, MinGW nm treats NUL as empty\n\tcase $build_os in\n\tmingw*) lt_bad_file=conftest.nm/nofile ;;\n\t*) lt_bad_file=/dev/null ;;\n\tesac\n\tcase `\"$tmp_nm\" -B $lt_bad_file 2>&1 | sed '1q'` in\n\t*$lt_bad_file* | *'Invalid file or object type'*)\n\t  lt_cv_path_NM=\"$tmp_nm -B\"\n\t  break 2\n\t  ;;\n\t*)\n\t  case `\"$tmp_nm\" -p /dev/null 2>&1 | sed '1q'` in\n\t  */dev/null*)\n\t    lt_cv_path_NM=\"$tmp_nm -p\"\n\t    break 2\n\t    ;;\n\t  *)\n\t    lt_cv_path_NM=${lt_cv_path_NM=\"$tmp_nm\"} # keep the first match, but\n\t    continue # so that we can try to find one that supports BSD flags\n\t    ;;\n\t  esac\n\t  ;;\n\tesac\n      fi\n    done\n    IFS=$lt_save_ifs\n  done\n  : ${lt_cv_path_NM=no}\nfi])\nif test no != \"$lt_cv_path_NM\"; then\n  NM=$lt_cv_path_NM\nelse\n  # Didn't find any BSD compatible name lister, look for dumpbin.\n  if test -n \"$DUMPBIN\"; then :\n    # Let the user override the test.\n  else\n    AC_CHECK_TOOLS(DUMPBIN, [dumpbin \"link -dump\"], :)\n    case `$DUMPBIN -symbols -headers /dev/null 2>&1 | sed '1q'` in\n    *COFF*)\n      DUMPBIN=\"$DUMPBIN -symbols -headers\"\n      ;;\n    *)\n      DUMPBIN=:\n      ;;\n    esac\n  fi\n  AC_SUBST([DUMPBIN])\n  if test : != \"$DUMPBIN\"; then\n    NM=$DUMPBIN\n  fi\nfi\ntest -z \"$NM\" && NM=nm\nAC_SUBST([NM])\n_LT_DECL([], [NM], [1], [A BSD- or MS-compatible name lister])dnl\n\nAC_CACHE_CHECK([the name lister ($NM) interface], [lt_cv_nm_interface],\n  [lt_cv_nm_interface=\"BSD nm\"\n  echo \"int some_variable = 0;\" > conftest.$ac_ext\n  (eval echo \"\\\"\\$as_me:$LINENO: $ac_compile\\\"\" >&AS_MESSAGE_LOG_FD)\n  (eval \"$ac_compile\" 2>conftest.err)\n  cat conftest.err >&AS_MESSAGE_LOG_FD\n  (eval echo \"\\\"\\$as_me:$LINENO: $NM \\\\\\\"conftest.$ac_objext\\\\\\\"\\\"\" >&AS_MESSAGE_LOG_FD)\n  (eval \"$NM \\\"conftest.$ac_objext\\\"\" 2>conftest.err > conftest.out)\n  cat conftest.err >&AS_MESSAGE_LOG_FD\n  (eval echo \"\\\"\\$as_me:$LINENO: output\\\"\" >&AS_MESSAGE_LOG_FD)\n  cat conftest.out >&AS_MESSAGE_LOG_FD\n  if $GREP 'External.*some_variable' conftest.out > /dev/null; then\n    lt_cv_nm_interface=\"MS dumpbin\"\n  fi\n  rm -f conftest*])\n])# LT_PATH_NM\n\n# Old names:\nAU_ALIAS([AM_PROG_NM], [LT_PATH_NM])\nAU_ALIAS([AC_PROG_NM], [LT_PATH_NM])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AM_PROG_NM], [])\ndnl AC_DEFUN([AC_PROG_NM], [])\n\n# _LT_CHECK_SHAREDLIB_FROM_LINKLIB\n# --------------------------------\n# how to determine the name of the shared library\n# associated with a specific link library.\n#  -- PORTME fill in with the dynamic library characteristics\nm4_defun([_LT_CHECK_SHAREDLIB_FROM_LINKLIB],\n[m4_require([_LT_DECL_EGREP])\nm4_require([_LT_DECL_OBJDUMP])\nm4_require([_LT_DECL_DLLTOOL])\nAC_CACHE_CHECK([how to associate runtime and link libraries],\nlt_cv_sharedlib_from_linklib_cmd,\n[lt_cv_sharedlib_from_linklib_cmd='unknown'\n\ncase $host_os in\ncygwin* | mingw* | pw32* | cegcc*)\n  # two different shell functions defined in ltmain.sh;\n  # decide which one to use based on capabilities of $DLLTOOL\n  case `$DLLTOOL --help 2>&1` in\n  *--identify-strict*)\n    lt_cv_sharedlib_from_linklib_cmd=func_cygming_dll_for_implib\n    ;;\n  *)\n    lt_cv_sharedlib_from_linklib_cmd=func_cygming_dll_for_implib_fallback\n    ;;\n  esac\n  ;;\n*)\n  # fallback: assume linklib IS sharedlib\n  lt_cv_sharedlib_from_linklib_cmd=$ECHO\n  ;;\nesac\n])\nsharedlib_from_linklib_cmd=$lt_cv_sharedlib_from_linklib_cmd\ntest -z \"$sharedlib_from_linklib_cmd\" && sharedlib_from_linklib_cmd=$ECHO\n\n_LT_DECL([], [sharedlib_from_linklib_cmd], [1],\n    [Command to associate shared and link libraries])\n])# _LT_CHECK_SHAREDLIB_FROM_LINKLIB\n\n\n# _LT_PATH_MANIFEST_TOOL\n# ----------------------\n# locate the manifest tool\nm4_defun([_LT_PATH_MANIFEST_TOOL],\n[AC_CHECK_TOOL(MANIFEST_TOOL, mt, :)\ntest -z \"$MANIFEST_TOOL\" && MANIFEST_TOOL=mt\nAC_CACHE_CHECK([if $MANIFEST_TOOL is a manifest tool], [lt_cv_path_mainfest_tool],\n  [lt_cv_path_mainfest_tool=no\n  echo \"$as_me:$LINENO: $MANIFEST_TOOL '-?'\" >&AS_MESSAGE_LOG_FD\n  $MANIFEST_TOOL '-?' 2>conftest.err > conftest.out\n  cat conftest.err >&AS_MESSAGE_LOG_FD\n  if $GREP 'Manifest Tool' conftest.out > /dev/null; then\n    lt_cv_path_mainfest_tool=yes\n  fi\n  rm -f conftest*])\nif test yes != \"$lt_cv_path_mainfest_tool\"; then\n  MANIFEST_TOOL=:\nfi\n_LT_DECL([], [MANIFEST_TOOL], [1], [Manifest tool])dnl\n])# _LT_PATH_MANIFEST_TOOL\n\n\n# _LT_DLL_DEF_P([FILE])\n# ---------------------\n# True iff FILE is a Windows DLL '.def' file.\n# Keep in sync with func_dll_def_p in the libtool script\nAC_DEFUN([_LT_DLL_DEF_P],\n[dnl\n  test DEF = \"`$SED -n dnl\n    -e '\\''s/^[[\t ]]*//'\\'' dnl Strip leading whitespace\n    -e '\\''/^\\(;.*\\)*$/d'\\'' dnl      Delete empty lines and comments\n    -e '\\''s/^\\(EXPORTS\\|LIBRARY\\)\\([[\t ]].*\\)*$/DEF/p'\\'' dnl\n    -e q dnl                          Only consider the first \"real\" line\n    $1`\" dnl\n])# _LT_DLL_DEF_P\n\n\n# LT_LIB_M\n# --------\n# check for math library\nAC_DEFUN([LT_LIB_M],\n[AC_REQUIRE([AC_CANONICAL_HOST])dnl\nLIBM=\ncase $host in\n*-*-beos* | *-*-cegcc* | *-*-cygwin* | *-*-haiku* | *-*-pw32* | *-*-darwin*)\n  # These system don't have libm, or don't need it\n  ;;\n*-ncr-sysv4.3*)\n  AC_CHECK_LIB(mw, _mwvalidcheckl, LIBM=-lmw)\n  AC_CHECK_LIB(m, cos, LIBM=\"$LIBM -lm\")\n  ;;\n*)\n  AC_CHECK_LIB(m, cos, LIBM=-lm)\n  ;;\nesac\nAC_SUBST([LIBM])\n])# LT_LIB_M\n\n# Old name:\nAU_ALIAS([AC_CHECK_LIBM], [LT_LIB_M])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_CHECK_LIBM], [])\n\n\n# _LT_COMPILER_NO_RTTI([TAGNAME])\n# -------------------------------\nm4_defun([_LT_COMPILER_NO_RTTI],\n[m4_require([_LT_TAG_COMPILER])dnl\n\n_LT_TAGVAR(lt_prog_compiler_no_builtin_flag, $1)=\n\nif test yes = \"$GCC\"; then\n  case $cc_basename in\n  nvcc*)\n    _LT_TAGVAR(lt_prog_compiler_no_builtin_flag, $1)=' -Xcompiler -fno-builtin' ;;\n  *)\n    _LT_TAGVAR(lt_prog_compiler_no_builtin_flag, $1)=' -fno-builtin' ;;\n  esac\n\n  _LT_COMPILER_OPTION([if $compiler supports -fno-rtti -fno-exceptions],\n    lt_cv_prog_compiler_rtti_exceptions,\n    [-fno-rtti -fno-exceptions], [],\n    [_LT_TAGVAR(lt_prog_compiler_no_builtin_flag, $1)=\"$_LT_TAGVAR(lt_prog_compiler_no_builtin_flag, $1) -fno-rtti -fno-exceptions\"])\nfi\n_LT_TAGDECL([no_builtin_flag], [lt_prog_compiler_no_builtin_flag], [1],\n\t[Compiler flag to turn off builtin functions])\n])# _LT_COMPILER_NO_RTTI\n\n\n# _LT_CMD_GLOBAL_SYMBOLS\n# ----------------------\nm4_defun([_LT_CMD_GLOBAL_SYMBOLS],\n[AC_REQUIRE([AC_CANONICAL_HOST])dnl\nAC_REQUIRE([AC_PROG_CC])dnl\nAC_REQUIRE([AC_PROG_AWK])dnl\nAC_REQUIRE([LT_PATH_NM])dnl\nAC_REQUIRE([LT_PATH_LD])dnl\nm4_require([_LT_DECL_SED])dnl\nm4_require([_LT_DECL_EGREP])dnl\nm4_require([_LT_TAG_COMPILER])dnl\n\n# Check for command to grab the raw symbol name followed by C symbol from nm.\nAC_MSG_CHECKING([command to parse $NM output from $compiler object])\nAC_CACHE_VAL([lt_cv_sys_global_symbol_pipe],\n[\n# These are sane defaults that work on at least a few old systems.\n# [They come from Ultrix.  What could be older than Ultrix?!! ;)]\n\n# Character class describing NM global symbol codes.\nsymcode='[[BCDEGRST]]'\n\n# Regexp to match symbols that can be accessed directly from C.\nsympat='\\([[_A-Za-z]][[_A-Za-z0-9]]*\\)'\n\n# Define system-specific variables.\ncase $host_os in\naix*)\n  symcode='[[BCDT]]'\n  ;;\ncygwin* | mingw* | pw32* | cegcc*)\n  symcode='[[ABCDGISTW]]'\n  ;;\nhpux*)\n  if test ia64 = \"$host_cpu\"; then\n    symcode='[[ABCDEGRST]]'\n  fi\n  ;;\nirix* | nonstopux*)\n  symcode='[[BCDEGRST]]'\n  ;;\nosf*)\n  symcode='[[BCDEGQRST]]'\n  ;;\nsolaris*)\n  symcode='[[BDRT]]'\n  ;;\nsco3.2v5*)\n  symcode='[[DT]]'\n  ;;\nsysv4.2uw2*)\n  symcode='[[DT]]'\n  ;;\nsysv5* | sco5v6* | unixware* | OpenUNIX*)\n  symcode='[[ABDT]]'\n  ;;\nsysv4)\n  symcode='[[DFNSTU]]'\n  ;;\nesac\n\n# If we're using GNU nm, then use its standard symbol codes.\ncase `$NM -V 2>&1` in\n*GNU* | *'with BFD'*)\n  symcode='[[ABCDGIRSTW]]' ;;\nesac\n\nif test \"$lt_cv_nm_interface\" = \"MS dumpbin\"; then\n  # Gets list of data symbols to import.\n  lt_cv_sys_global_symbol_to_import=\"sed -n -e 's/^I .* \\(.*\\)$/\\1/p'\"\n  # Adjust the below global symbol transforms to fixup imported variables.\n  lt_cdecl_hook=\" -e 's/^I .* \\(.*\\)$/extern __declspec(dllimport) char \\1;/p'\"\n  lt_c_name_hook=\" -e 's/^I .* \\(.*\\)$/  {\\\"\\1\\\", (void *) 0},/p'\"\n  lt_c_name_lib_hook=\"\\\n  -e 's/^I .* \\(lib.*\\)$/  {\\\"\\1\\\", (void *) 0},/p'\\\n  -e 's/^I .* \\(.*\\)$/  {\\\"lib\\1\\\", (void *) 0},/p'\"\nelse\n  # Disable hooks by default.\n  lt_cv_sys_global_symbol_to_import=\n  lt_cdecl_hook=\n  lt_c_name_hook=\n  lt_c_name_lib_hook=\nfi\n\n# Transform an extracted symbol line into a proper C declaration.\n# Some systems (esp. on ia64) link data and code symbols differently,\n# so use this general approach.\nlt_cv_sys_global_symbol_to_cdecl=\"sed -n\"\\\n$lt_cdecl_hook\\\n\" -e 's/^T .* \\(.*\\)$/extern int \\1();/p'\"\\\n\" -e 's/^$symcode$symcode* .* \\(.*\\)$/extern char \\1;/p'\"\n\n# Transform an extracted symbol line into symbol name and symbol address\nlt_cv_sys_global_symbol_to_c_name_address=\"sed -n\"\\\n$lt_c_name_hook\\\n\" -e 's/^: \\(.*\\) .*$/  {\\\"\\1\\\", (void *) 0},/p'\"\\\n\" -e 's/^$symcode$symcode* .* \\(.*\\)$/  {\\\"\\1\\\", (void *) \\&\\1},/p'\"\n\n# Transform an extracted symbol line into symbol name with lib prefix and\n# symbol address.\nlt_cv_sys_global_symbol_to_c_name_address_lib_prefix=\"sed -n\"\\\n$lt_c_name_lib_hook\\\n\" -e 's/^: \\(.*\\) .*$/  {\\\"\\1\\\", (void *) 0},/p'\"\\\n\" -e 's/^$symcode$symcode* .* \\(lib.*\\)$/  {\\\"\\1\\\", (void *) \\&\\1},/p'\"\\\n\" -e 's/^$symcode$symcode* .* \\(.*\\)$/  {\\\"lib\\1\\\", (void *) \\&\\1},/p'\"\n\n# Handle CRLF in mingw tool chain\nopt_cr=\ncase $build_os in\nmingw*)\n  opt_cr=`$ECHO 'x\\{0,1\\}' | tr x '\\015'` # option cr in regexp\n  ;;\nesac\n\n# Try without a prefix underscore, then with it.\nfor ac_symprfx in \"\" \"_\"; do\n\n  # Transform symcode, sympat, and symprfx into a raw symbol and a C symbol.\n  symxfrm=\"\\\\1 $ac_symprfx\\\\2 \\\\2\"\n\n  # Write the raw and C identifiers.\n  if test \"$lt_cv_nm_interface\" = \"MS dumpbin\"; then\n    # Fake it for dumpbin and say T for any non-static function,\n    # D for any global variable and I for any imported variable.\n    # Also find C++ and __fastcall symbols from MSVC++,\n    # which start with @ or ?.\n    lt_cv_sys_global_symbol_pipe=\"$AWK ['\"\\\n\"     {last_section=section; section=\\$ 3};\"\\\n\"     /^COFF SYMBOL TABLE/{for(i in hide) delete hide[i]};\"\\\n\"     /Section length .*#relocs.*(pick any)/{hide[last_section]=1};\"\\\n\"     /^ *Symbol name *: /{split(\\$ 0,sn,\\\":\\\"); si=substr(sn[2],2)};\"\\\n\"     /^ *Type *: code/{print \\\"T\\\",si,substr(si,length(prfx))};\"\\\n\"     /^ *Type *: data/{print \\\"I\\\",si,substr(si,length(prfx))};\"\\\n\"     \\$ 0!~/External *\\|/{next};\"\\\n\"     / 0+ UNDEF /{next}; / UNDEF \\([^|]\\)*()/{next};\"\\\n\"     {if(hide[section]) next};\"\\\n\"     {f=\\\"D\\\"}; \\$ 0~/\\(\\).*\\|/{f=\\\"T\\\"};\"\\\n\"     {split(\\$ 0,a,/\\||\\r/); split(a[2],s)};\"\\\n\"     s[1]~/^[@?]/{print f,s[1],s[1]; next};\"\\\n\"     s[1]~prfx {split(s[1],t,\\\"@\\\"); print f,t[1],substr(t[1],length(prfx))}\"\\\n\"     ' prfx=^$ac_symprfx]\"\n  else\n    lt_cv_sys_global_symbol_pipe=\"sed -n -e 's/^.*[[\t ]]\\($symcode$symcode*\\)[[\t ]][[\t ]]*$ac_symprfx$sympat$opt_cr$/$symxfrm/p'\"\n  fi\n  lt_cv_sys_global_symbol_pipe=\"$lt_cv_sys_global_symbol_pipe | sed '/ __gnu_lto/d'\"\n\n  # Check to see that the pipe works correctly.\n  pipe_works=no\n\n  rm -f conftest*\n  cat > conftest.$ac_ext <<_LT_EOF\n#ifdef __cplusplus\nextern \"C\" {\n#endif\nchar nm_test_var;\nvoid nm_test_func(void);\nvoid nm_test_func(void){}\n#ifdef __cplusplus\n}\n#endif\nint main(){nm_test_var='a';nm_test_func();return(0);}\n_LT_EOF\n\n  if AC_TRY_EVAL(ac_compile); then\n    # Now try to grab the symbols.\n    nlist=conftest.nm\n    if AC_TRY_EVAL(NM conftest.$ac_objext \\| \"$lt_cv_sys_global_symbol_pipe\" \\> $nlist) && test -s \"$nlist\"; then\n      # Try sorting and uniquifying the output.\n      if sort \"$nlist\" | uniq > \"$nlist\"T; then\n\tmv -f \"$nlist\"T \"$nlist\"\n      else\n\trm -f \"$nlist\"T\n      fi\n\n      # Make sure that we snagged all the symbols we need.\n      if $GREP ' nm_test_var$' \"$nlist\" >/dev/null; then\n\tif $GREP ' nm_test_func$' \"$nlist\" >/dev/null; then\n\t  cat <<_LT_EOF > conftest.$ac_ext\n/* Keep this code in sync between libtool.m4, ltmain, lt_system.h, and tests.  */\n#if defined _WIN32 || defined __CYGWIN__ || defined _WIN32_WCE\n/* DATA imports from DLLs on WIN32 can't be const, because runtime\n   relocations are performed -- see ld's documentation on pseudo-relocs.  */\n# define LT@&t@_DLSYM_CONST\n#elif defined __osf__\n/* This system does not cope well with relocations in const data.  */\n# define LT@&t@_DLSYM_CONST\n#else\n# define LT@&t@_DLSYM_CONST const\n#endif\n\n#ifdef __cplusplus\nextern \"C\" {\n#endif\n\n_LT_EOF\n\t  # Now generate the symbol file.\n\t  eval \"$lt_cv_sys_global_symbol_to_cdecl\"' < \"$nlist\" | $GREP -v main >> conftest.$ac_ext'\n\n\t  cat <<_LT_EOF >> conftest.$ac_ext\n\n/* The mapping between symbol names and symbols.  */\nLT@&t@_DLSYM_CONST struct {\n  const char *name;\n  void       *address;\n}\nlt__PROGRAM__LTX_preloaded_symbols[[]] =\n{\n  { \"@PROGRAM@\", (void *) 0 },\n_LT_EOF\n\t  $SED \"s/^$symcode$symcode* .* \\(.*\\)$/  {\\\"\\1\\\", (void *) \\&\\1},/\" < \"$nlist\" | $GREP -v main >> conftest.$ac_ext\n\t  cat <<\\_LT_EOF >> conftest.$ac_ext\n  {0, (void *) 0}\n};\n\n/* This works around a problem in FreeBSD linker */\n#ifdef FREEBSD_WORKAROUND\nstatic const void *lt_preloaded_setup() {\n  return lt__PROGRAM__LTX_preloaded_symbols;\n}\n#endif\n\n#ifdef __cplusplus\n}\n#endif\n_LT_EOF\n\t  # Now try linking the two files.\n\t  mv conftest.$ac_objext conftstm.$ac_objext\n\t  lt_globsym_save_LIBS=$LIBS\n\t  lt_globsym_save_CFLAGS=$CFLAGS\n\t  LIBS=conftstm.$ac_objext\n\t  CFLAGS=\"$CFLAGS$_LT_TAGVAR(lt_prog_compiler_no_builtin_flag, $1)\"\n\t  if AC_TRY_EVAL(ac_link) && test -s conftest$ac_exeext; then\n\t    pipe_works=yes\n\t  fi\n\t  LIBS=$lt_globsym_save_LIBS\n\t  CFLAGS=$lt_globsym_save_CFLAGS\n\telse\n\t  echo \"cannot find nm_test_func in $nlist\" >&AS_MESSAGE_LOG_FD\n\tfi\n      else\n\techo \"cannot find nm_test_var in $nlist\" >&AS_MESSAGE_LOG_FD\n      fi\n    else\n      echo \"cannot run $lt_cv_sys_global_symbol_pipe\" >&AS_MESSAGE_LOG_FD\n    fi\n  else\n    echo \"$progname: failed program was:\" >&AS_MESSAGE_LOG_FD\n    cat conftest.$ac_ext >&5\n  fi\n  rm -rf conftest* conftst*\n\n  # Do not use the global_symbol_pipe unless it works.\n  if test yes = \"$pipe_works\"; then\n    break\n  else\n    lt_cv_sys_global_symbol_pipe=\n  fi\ndone\n])\nif test -z \"$lt_cv_sys_global_symbol_pipe\"; then\n  lt_cv_sys_global_symbol_to_cdecl=\nfi\nif test -z \"$lt_cv_sys_global_symbol_pipe$lt_cv_sys_global_symbol_to_cdecl\"; then\n  AC_MSG_RESULT(failed)\nelse\n  AC_MSG_RESULT(ok)\nfi\n\n# Response file support.\nif test \"$lt_cv_nm_interface\" = \"MS dumpbin\"; then\n  nm_file_list_spec='@'\nelif $NM --help 2>/dev/null | grep '[[@]]FILE' >/dev/null; then\n  nm_file_list_spec='@'\nfi\n\n_LT_DECL([global_symbol_pipe], [lt_cv_sys_global_symbol_pipe], [1],\n    [Take the output of nm and produce a listing of raw symbols and C names])\n_LT_DECL([global_symbol_to_cdecl], [lt_cv_sys_global_symbol_to_cdecl], [1],\n    [Transform the output of nm in a proper C declaration])\n_LT_DECL([global_symbol_to_import], [lt_cv_sys_global_symbol_to_import], [1],\n    [Transform the output of nm into a list of symbols to manually relocate])\n_LT_DECL([global_symbol_to_c_name_address],\n    [lt_cv_sys_global_symbol_to_c_name_address], [1],\n    [Transform the output of nm in a C name address pair])\n_LT_DECL([global_symbol_to_c_name_address_lib_prefix],\n    [lt_cv_sys_global_symbol_to_c_name_address_lib_prefix], [1],\n    [Transform the output of nm in a C name address pair when lib prefix is needed])\n_LT_DECL([nm_interface], [lt_cv_nm_interface], [1],\n    [The name lister interface])\n_LT_DECL([], [nm_file_list_spec], [1],\n    [Specify filename containing input files for $NM])\n]) # _LT_CMD_GLOBAL_SYMBOLS\n\n\n# _LT_COMPILER_PIC([TAGNAME])\n# ---------------------------\nm4_defun([_LT_COMPILER_PIC],\n[m4_require([_LT_TAG_COMPILER])dnl\n_LT_TAGVAR(lt_prog_compiler_wl, $1)=\n_LT_TAGVAR(lt_prog_compiler_pic, $1)=\n_LT_TAGVAR(lt_prog_compiler_static, $1)=\n\nm4_if([$1], [CXX], [\n  # C++ specific cases for pic, static, wl, etc.\n  if test yes = \"$GXX\"; then\n    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n    _LT_TAGVAR(lt_prog_compiler_static, $1)='-static'\n\n    case $host_os in\n    aix*)\n      # All AIX code is PIC.\n      if test ia64 = \"$host_cpu\"; then\n\t# AIX 5 now supports IA64 processor\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n      fi\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n      ;;\n\n    amigaos*)\n      case $host_cpu in\n      powerpc)\n            # see comment about AmigaOS4 .so support\n            _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n        ;;\n      m68k)\n            # FIXME: we need at least 68020 code to build shared libraries, but\n            # adding the '-m68020' flag to GCC prevents building anything better,\n            # like '-m68040'.\n            _LT_TAGVAR(lt_prog_compiler_pic, $1)='-m68020 -resident32 -malways-restore-a4'\n        ;;\n      esac\n      ;;\n\n    beos* | irix5* | irix6* | nonstopux* | osf3* | osf4* | osf5*)\n      # PIC is the default for these OSes.\n      ;;\n    mingw* | cygwin* | os2* | pw32* | cegcc*)\n      # This hack is so that the source file can tell whether it is being\n      # built for inclusion in a dll (and should export symbols for example).\n      # Although the cygwin gcc ignores -fPIC, still need this for old-style\n      # (--disable-auto-import) libraries\n      m4_if([$1], [GCJ], [],\n\t[_LT_TAGVAR(lt_prog_compiler_pic, $1)='-DDLL_EXPORT'])\n      case $host_os in\n      os2*)\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='$wl-static'\n\t;;\n      esac\n      ;;\n    darwin* | rhapsody*)\n      # PIC is the default on this platform\n      # Common symbols not allowed in MH_DYLIB files\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fno-common'\n      ;;\n    *djgpp*)\n      # DJGPP does not support shared libraries at all\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)=\n      ;;\n    haiku*)\n      # PIC is the default for Haiku.\n      # The \"-static\" flag exists, but is broken.\n      _LT_TAGVAR(lt_prog_compiler_static, $1)=\n      ;;\n    interix[[3-9]]*)\n      # Interix 3.x gcc -fpic/-fPIC options generate broken code.\n      # Instead, we relocate shared libraries at runtime.\n      ;;\n    sysv4*MP*)\n      if test -d /usr/nec; then\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)=-Kconform_pic\n      fi\n      ;;\n    hpux*)\n      # PIC is the default for 64-bit PA HP-UX, but not for 32-bit\n      # PA HP-UX.  On IA64 HP-UX, PIC is the default but the pic flag\n      # sets the default TLS model and affects inlining.\n      case $host_cpu in\n      hppa*64*)\n\t;;\n      *)\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n\t;;\n      esac\n      ;;\n    *qnx* | *nto*)\n      # QNX uses GNU C++, but need to define -shared option too, otherwise\n      # it will coredump.\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC -shared'\n      ;;\n    *)\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n      ;;\n    esac\n  else\n    case $host_os in\n      aix[[4-9]]*)\n\t# All AIX code is PIC.\n\tif test ia64 = \"$host_cpu\"; then\n\t  # AIX 5 now supports IA64 processor\n\t  _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n\telse\n\t  _LT_TAGVAR(lt_prog_compiler_static, $1)='-bnso -bI:/lib/syscalls.exp'\n\tfi\n\t;;\n      chorus*)\n\tcase $cc_basename in\n\tcxch68*)\n\t  # Green Hills C++ Compiler\n\t  # _LT_TAGVAR(lt_prog_compiler_static, $1)=\"--no_auto_instantiation -u __main -u __premain -u _abort -r $COOL_DIR/lib/libOrb.a $MVME_DIR/lib/CC/libC.a $MVME_DIR/lib/classix/libcx.s.a\"\n\t  ;;\n\tesac\n\t;;\n      mingw* | cygwin* | os2* | pw32* | cegcc*)\n\t# This hack is so that the source file can tell whether it is being\n\t# built for inclusion in a dll (and should export symbols for example).\n\tm4_if([$1], [GCJ], [],\n\t  [_LT_TAGVAR(lt_prog_compiler_pic, $1)='-DDLL_EXPORT'])\n\t;;\n      dgux*)\n\tcase $cc_basename in\n\t  ec++*)\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n\t    ;;\n\t  ghcx*)\n\t    # Green Hills C++ Compiler\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-pic'\n\t    ;;\n\t  *)\n\t    ;;\n\tesac\n\t;;\n      freebsd* | dragonfly*)\n\t# FreeBSD uses GNU C++\n\t;;\n      hpux9* | hpux10* | hpux11*)\n\tcase $cc_basename in\n\t  CC*)\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='$wl-a ${wl}archive'\n\t    if test ia64 != \"$host_cpu\"; then\n\t      _LT_TAGVAR(lt_prog_compiler_pic, $1)='+Z'\n\t    fi\n\t    ;;\n\t  aCC*)\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='$wl-a ${wl}archive'\n\t    case $host_cpu in\n\t    hppa*64*|ia64*)\n\t      # +Z the default\n\t      ;;\n\t    *)\n\t      _LT_TAGVAR(lt_prog_compiler_pic, $1)='+Z'\n\t      ;;\n\t    esac\n\t    ;;\n\t  *)\n\t    ;;\n\tesac\n\t;;\n      interix*)\n\t# This is c89, which is MS Visual C++ (no shared libs)\n\t# Anyone wants to do a port?\n\t;;\n      irix5* | irix6* | nonstopux*)\n\tcase $cc_basename in\n\t  CC*)\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='-non_shared'\n\t    # CC pic flag -KPIC is the default.\n\t    ;;\n\t  *)\n\t    ;;\n\tesac\n\t;;\n      linux* | k*bsd*-gnu | kopensolaris*-gnu | gnu*)\n\tcase $cc_basename in\n\t  KCC*)\n\t    # KAI C++ Compiler\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='--backend -Wl,'\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n\t    ;;\n\t  ecpc* )\n\t    # old Intel C++ for x86_64, which still supported -KPIC.\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='-static'\n\t    ;;\n\t  icpc* )\n\t    # Intel C++, used to be incompatible with GCC.\n\t    # ICC 10 doesn't accept -KPIC any more.\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='-static'\n\t    ;;\n\t  pgCC* | pgcpp*)\n\t    # Portland Group C++ compiler\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fpic'\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n\t    ;;\n\t  cxx*)\n\t    # Compaq C++\n\t    # Make sure the PIC flag is empty.  It appears that all Alpha\n\t    # Linux and Compaq Tru64 Unix objects are PIC.\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)=\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='-non_shared'\n\t    ;;\n\t  xlc* | xlC* | bgxl[[cC]]* | mpixl[[cC]]*)\n\t    # IBM XL 8.0, 9.0 on PPC and BlueGene\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-qpic'\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='-qstaticlink'\n\t    ;;\n\t  *)\n\t    case `$CC -V 2>&1 | sed 5q` in\n\t    *Sun\\ C*)\n\t      # Sun C++ 5.9\n\t      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n\t      _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n\t      _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Qoption ld '\n\t      ;;\n\t    esac\n\t    ;;\n\tesac\n\t;;\n      lynxos*)\n\t;;\n      m88k*)\n\t;;\n      mvs*)\n\tcase $cc_basename in\n\t  cxx*)\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-W c,exportall'\n\t    ;;\n\t  *)\n\t    ;;\n\tesac\n\t;;\n      netbsd* | netbsdelf*-gnu)\n\t;;\n      *qnx* | *nto*)\n        # QNX uses GNU C++, but need to define -shared option too, otherwise\n        # it will coredump.\n        _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC -shared'\n        ;;\n      osf3* | osf4* | osf5*)\n\tcase $cc_basename in\n\t  KCC*)\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='--backend -Wl,'\n\t    ;;\n\t  RCC*)\n\t    # Rational C++ 2.4.1\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-pic'\n\t    ;;\n\t  cxx*)\n\t    # Digital/Compaq C++\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t    # Make sure the PIC flag is empty.  It appears that all Alpha\n\t    # Linux and Compaq Tru64 Unix objects are PIC.\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)=\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='-non_shared'\n\t    ;;\n\t  *)\n\t    ;;\n\tesac\n\t;;\n      psos*)\n\t;;\n      solaris*)\n\tcase $cc_basename in\n\t  CC* | sunCC*)\n\t    # Sun C++ 4.2, 5.x and Centerline C++\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Qoption ld '\n\t    ;;\n\t  gcx*)\n\t    # Green Hills C++ Compiler\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-PIC'\n\t    ;;\n\t  *)\n\t    ;;\n\tesac\n\t;;\n      sunos4*)\n\tcase $cc_basename in\n\t  CC*)\n\t    # Sun C++ 4.x\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-pic'\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n\t    ;;\n\t  lcc*)\n\t    # Lucid\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-pic'\n\t    ;;\n\t  *)\n\t    ;;\n\tesac\n\t;;\n      sysv5* | unixware* | sco3.2v5* | sco5v6* | OpenUNIX*)\n\tcase $cc_basename in\n\t  CC*)\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n\t    ;;\n\tesac\n\t;;\n      tandem*)\n\tcase $cc_basename in\n\t  NCC*)\n\t    # NonStop-UX NCC 3.20\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n\t    ;;\n\t  *)\n\t    ;;\n\tesac\n\t;;\n      vxworks*)\n\t;;\n      *)\n\t_LT_TAGVAR(lt_prog_compiler_can_build_shared, $1)=no\n\t;;\n    esac\n  fi\n],\n[\n  if test yes = \"$GCC\"; then\n    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n    _LT_TAGVAR(lt_prog_compiler_static, $1)='-static'\n\n    case $host_os in\n      aix*)\n      # All AIX code is PIC.\n      if test ia64 = \"$host_cpu\"; then\n\t# AIX 5 now supports IA64 processor\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n      fi\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n      ;;\n\n    amigaos*)\n      case $host_cpu in\n      powerpc)\n            # see comment about AmigaOS4 .so support\n            _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n        ;;\n      m68k)\n            # FIXME: we need at least 68020 code to build shared libraries, but\n            # adding the '-m68020' flag to GCC prevents building anything better,\n            # like '-m68040'.\n            _LT_TAGVAR(lt_prog_compiler_pic, $1)='-m68020 -resident32 -malways-restore-a4'\n        ;;\n      esac\n      ;;\n\n    beos* | irix5* | irix6* | nonstopux* | osf3* | osf4* | osf5*)\n      # PIC is the default for these OSes.\n      ;;\n\n    mingw* | cygwin* | pw32* | os2* | cegcc*)\n      # This hack is so that the source file can tell whether it is being\n      # built for inclusion in a dll (and should export symbols for example).\n      # Although the cygwin gcc ignores -fPIC, still need this for old-style\n      # (--disable-auto-import) libraries\n      m4_if([$1], [GCJ], [],\n\t[_LT_TAGVAR(lt_prog_compiler_pic, $1)='-DDLL_EXPORT'])\n      case $host_os in\n      os2*)\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='$wl-static'\n\t;;\n      esac\n      ;;\n\n    darwin* | rhapsody*)\n      # PIC is the default on this platform\n      # Common symbols not allowed in MH_DYLIB files\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fno-common'\n      ;;\n\n    haiku*)\n      # PIC is the default for Haiku.\n      # The \"-static\" flag exists, but is broken.\n      _LT_TAGVAR(lt_prog_compiler_static, $1)=\n      ;;\n\n    hpux*)\n      # PIC is the default for 64-bit PA HP-UX, but not for 32-bit\n      # PA HP-UX.  On IA64 HP-UX, PIC is the default but the pic flag\n      # sets the default TLS model and affects inlining.\n      case $host_cpu in\n      hppa*64*)\n\t# +Z the default\n\t;;\n      *)\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n\t;;\n      esac\n      ;;\n\n    interix[[3-9]]*)\n      # Interix 3.x gcc -fpic/-fPIC options generate broken code.\n      # Instead, we relocate shared libraries at runtime.\n      ;;\n\n    msdosdjgpp*)\n      # Just because we use GCC doesn't mean we suddenly get shared libraries\n      # on systems that don't support them.\n      _LT_TAGVAR(lt_prog_compiler_can_build_shared, $1)=no\n      enable_shared=no\n      ;;\n\n    *nto* | *qnx*)\n      # QNX uses GNU C++, but need to define -shared option too, otherwise\n      # it will coredump.\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC -shared'\n      ;;\n\n    sysv4*MP*)\n      if test -d /usr/nec; then\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)=-Kconform_pic\n      fi\n      ;;\n\n    *)\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n      ;;\n    esac\n\n    case $cc_basename in\n    nvcc*) # Cuda Compiler Driver 2.2\n      _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Xlinker '\n      if test -n \"$_LT_TAGVAR(lt_prog_compiler_pic, $1)\"; then\n        _LT_TAGVAR(lt_prog_compiler_pic, $1)=\"-Xcompiler $_LT_TAGVAR(lt_prog_compiler_pic, $1)\"\n      fi\n      ;;\n    esac\n  else\n    # PORTME Check for flag to pass linker flags through the system compiler.\n    case $host_os in\n    aix*)\n      _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n      if test ia64 = \"$host_cpu\"; then\n\t# AIX 5 now supports IA64 processor\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n      else\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='-bnso -bI:/lib/syscalls.exp'\n      fi\n      ;;\n\n    darwin* | rhapsody*)\n      # PIC is the default on this platform\n      # Common symbols not allowed in MH_DYLIB files\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fno-common'\n      case $cc_basename in\n      nagfor*)\n        # NAG Fortran compiler\n        _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,-Wl,,'\n        _LT_TAGVAR(lt_prog_compiler_pic, $1)='-PIC'\n        _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n        ;;\n      esac\n      ;;\n\n    mingw* | cygwin* | pw32* | os2* | cegcc*)\n      # This hack is so that the source file can tell whether it is being\n      # built for inclusion in a dll (and should export symbols for example).\n      m4_if([$1], [GCJ], [],\n\t[_LT_TAGVAR(lt_prog_compiler_pic, $1)='-DDLL_EXPORT'])\n      case $host_os in\n      os2*)\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='$wl-static'\n\t;;\n      esac\n      ;;\n\n    hpux9* | hpux10* | hpux11*)\n      _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n      # PIC is the default for IA64 HP-UX and 64-bit HP-UX, but\n      # not for PA HP-UX.\n      case $host_cpu in\n      hppa*64*|ia64*)\n\t# +Z the default\n\t;;\n      *)\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)='+Z'\n\t;;\n      esac\n      # Is there a better lt_prog_compiler_static that works with the bundled CC?\n      _LT_TAGVAR(lt_prog_compiler_static, $1)='$wl-a ${wl}archive'\n      ;;\n\n    irix5* | irix6* | nonstopux*)\n      _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n      # PIC (with -KPIC) is the default.\n      _LT_TAGVAR(lt_prog_compiler_static, $1)='-non_shared'\n      ;;\n\n    linux* | k*bsd*-gnu | kopensolaris*-gnu | gnu*)\n      case $cc_basename in\n      # old Intel for x86_64, which still supported -KPIC.\n      ecc*)\n\t_LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='-static'\n        ;;\n      # icc used to be incompatible with GCC.\n      # ICC 10 doesn't accept -KPIC any more.\n      icc* | ifort*)\n\t_LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='-static'\n        ;;\n      # Lahey Fortran 8.1.\n      lf95*)\n\t_LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)='--shared'\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='--static'\n\t;;\n      nagfor*)\n\t# NAG Fortran compiler\n\t_LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,-Wl,,'\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)='-PIC'\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n\t;;\n      tcc*)\n\t# Fabrice Bellard et al's Tiny C Compiler\n\t_LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='-static'\n\t;;\n      pgcc* | pgf77* | pgf90* | pgf95* | pgfortran*)\n        # Portland Group compilers (*not* the Pentium gcc compiler,\n\t# which looks to be a dead project)\n\t_LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)='-fpic'\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n        ;;\n      ccc*)\n        _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n        # All Alpha code is PIC.\n        _LT_TAGVAR(lt_prog_compiler_static, $1)='-non_shared'\n        ;;\n      xl* | bgxl* | bgf* | mpixl*)\n\t# IBM XL C 8.0/Fortran 10.1, 11.1 on PPC and BlueGene\n\t_LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)='-qpic'\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='-qstaticlink'\n\t;;\n      *)\n\tcase `$CC -V 2>&1 | sed 5q` in\n\t*Sun\\ Ceres\\ Fortran* | *Sun*Fortran*\\ [[1-7]].* | *Sun*Fortran*\\ 8.[[0-3]]*)\n\t  # Sun Fortran 8.3 passes all unrecognized flags to the linker\n\t  _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n\t  _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n\t  _LT_TAGVAR(lt_prog_compiler_wl, $1)=''\n\t  ;;\n\t*Sun\\ F* | *Sun*Fortran*)\n\t  _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n\t  _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n\t  _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Qoption ld '\n\t  ;;\n\t*Sun\\ C*)\n\t  # Sun C 5.9\n\t  _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n\t  _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n\t  _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t  ;;\n        *Intel*\\ [[CF]]*Compiler*)\n\t  _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t  _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n\t  _LT_TAGVAR(lt_prog_compiler_static, $1)='-static'\n\t  ;;\n\t*Portland\\ Group*)\n\t  _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t  _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fpic'\n\t  _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n\t  ;;\n\tesac\n\t;;\n      esac\n      ;;\n\n    newsos6)\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n      _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n      ;;\n\n    *nto* | *qnx*)\n      # QNX uses GNU C++, but need to define -shared option too, otherwise\n      # it will coredump.\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC -shared'\n      ;;\n\n    osf3* | osf4* | osf5*)\n      _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n      # All OSF/1 code is PIC.\n      _LT_TAGVAR(lt_prog_compiler_static, $1)='-non_shared'\n      ;;\n\n    rdos*)\n      _LT_TAGVAR(lt_prog_compiler_static, $1)='-non_shared'\n      ;;\n\n    solaris*)\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n      _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n      case $cc_basename in\n      f77* | f90* | f95* | sunf77* | sunf90* | sunf95*)\n\t_LT_TAGVAR(lt_prog_compiler_wl, $1)='-Qoption ld ';;\n      *)\n\t_LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,';;\n      esac\n      ;;\n\n    sunos4*)\n      _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Qoption ld '\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-PIC'\n      _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n      ;;\n\n    sysv4 | sysv4.2uw2* | sysv4.3*)\n      _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n      _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n      ;;\n\n    sysv4*MP*)\n      if test -d /usr/nec; then\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)='-Kconform_pic'\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n      fi\n      ;;\n\n    sysv5* | unixware* | sco3.2v5* | sco5v6* | OpenUNIX*)\n      _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n      _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n      ;;\n\n    unicos*)\n      _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n      _LT_TAGVAR(lt_prog_compiler_can_build_shared, $1)=no\n      ;;\n\n    uts4*)\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-pic'\n      _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n      ;;\n\n    *)\n      _LT_TAGVAR(lt_prog_compiler_can_build_shared, $1)=no\n      ;;\n    esac\n  fi\n])\ncase $host_os in\n  # For platforms that do not support PIC, -DPIC is meaningless:\n  *djgpp*)\n    _LT_TAGVAR(lt_prog_compiler_pic, $1)=\n    ;;\n  *)\n    _LT_TAGVAR(lt_prog_compiler_pic, $1)=\"$_LT_TAGVAR(lt_prog_compiler_pic, $1)@&t@m4_if([$1],[],[ -DPIC],[m4_if([$1],[CXX],[ -DPIC],[])])\"\n    ;;\nesac\n\nAC_CACHE_CHECK([for $compiler option to produce PIC],\n  [_LT_TAGVAR(lt_cv_prog_compiler_pic, $1)],\n  [_LT_TAGVAR(lt_cv_prog_compiler_pic, $1)=$_LT_TAGVAR(lt_prog_compiler_pic, $1)])\n_LT_TAGVAR(lt_prog_compiler_pic, $1)=$_LT_TAGVAR(lt_cv_prog_compiler_pic, $1)\n\n#\n# Check to make sure the PIC flag actually works.\n#\nif test -n \"$_LT_TAGVAR(lt_prog_compiler_pic, $1)\"; then\n  _LT_COMPILER_OPTION([if $compiler PIC flag $_LT_TAGVAR(lt_prog_compiler_pic, $1) works],\n    [_LT_TAGVAR(lt_cv_prog_compiler_pic_works, $1)],\n    [$_LT_TAGVAR(lt_prog_compiler_pic, $1)@&t@m4_if([$1],[],[ -DPIC],[m4_if([$1],[CXX],[ -DPIC],[])])], [],\n    [case $_LT_TAGVAR(lt_prog_compiler_pic, $1) in\n     \"\" | \" \"*) ;;\n     *) _LT_TAGVAR(lt_prog_compiler_pic, $1)=\" $_LT_TAGVAR(lt_prog_compiler_pic, $1)\" ;;\n     esac],\n    [_LT_TAGVAR(lt_prog_compiler_pic, $1)=\n     _LT_TAGVAR(lt_prog_compiler_can_build_shared, $1)=no])\nfi\n_LT_TAGDECL([pic_flag], [lt_prog_compiler_pic], [1],\n\t[Additional compiler flags for building library objects])\n\n_LT_TAGDECL([wl], [lt_prog_compiler_wl], [1],\n\t[How to pass a linker flag through the compiler])\n#\n# Check to make sure the static flag actually works.\n#\nwl=$_LT_TAGVAR(lt_prog_compiler_wl, $1) eval lt_tmp_static_flag=\\\"$_LT_TAGVAR(lt_prog_compiler_static, $1)\\\"\n_LT_LINKER_OPTION([if $compiler static flag $lt_tmp_static_flag works],\n  _LT_TAGVAR(lt_cv_prog_compiler_static_works, $1),\n  $lt_tmp_static_flag,\n  [],\n  [_LT_TAGVAR(lt_prog_compiler_static, $1)=])\n_LT_TAGDECL([link_static_flag], [lt_prog_compiler_static], [1],\n\t[Compiler flag to prevent dynamic linking])\n])# _LT_COMPILER_PIC\n\n\n# _LT_LINKER_SHLIBS([TAGNAME])\n# ----------------------------\n# See if the linker supports building shared libraries.\nm4_defun([_LT_LINKER_SHLIBS],\n[AC_REQUIRE([LT_PATH_LD])dnl\nAC_REQUIRE([LT_PATH_NM])dnl\nm4_require([_LT_PATH_MANIFEST_TOOL])dnl\nm4_require([_LT_FILEUTILS_DEFAULTS])dnl\nm4_require([_LT_DECL_EGREP])dnl\nm4_require([_LT_DECL_SED])dnl\nm4_require([_LT_CMD_GLOBAL_SYMBOLS])dnl\nm4_require([_LT_TAG_COMPILER])dnl\nAC_MSG_CHECKING([whether the $compiler linker ($LD) supports shared libraries])\nm4_if([$1], [CXX], [\n  _LT_TAGVAR(export_symbols_cmds, $1)='$NM $libobjs $convenience | $global_symbol_pipe | $SED '\\''s/.* //'\\'' | sort | uniq > $export_symbols'\n  _LT_TAGVAR(exclude_expsyms, $1)=['_GLOBAL_OFFSET_TABLE_|_GLOBAL__F[ID]_.*']\n  case $host_os in\n  aix[[4-9]]*)\n    # If we're using GNU nm, then we don't want the \"-C\" option.\n    # -C means demangle to GNU nm, but means don't demangle to AIX nm.\n    # Without the \"-l\" option, or with the \"-B\" option, AIX nm treats\n    # weak defined symbols like other global defined symbols, whereas\n    # GNU nm marks them as \"W\".\n    # While the 'weak' keyword is ignored in the Export File, we need\n    # it in the Import File for the 'aix-soname' feature, so we have\n    # to replace the \"-B\" option with \"-P\" for AIX nm.\n    if $NM -V 2>&1 | $GREP 'GNU' > /dev/null; then\n      _LT_TAGVAR(export_symbols_cmds, $1)='$NM -Bpg $libobjs $convenience | awk '\\''{ if (((\\$ 2 == \"T\") || (\\$ 2 == \"D\") || (\\$ 2 == \"B\") || (\\$ 2 == \"W\")) && ([substr](\\$ 3,1,1) != \".\")) { if (\\$ 2 == \"W\") { print \\$ 3 \" weak\" } else { print \\$ 3 } } }'\\'' | sort -u > $export_symbols'\n    else\n      _LT_TAGVAR(export_symbols_cmds, $1)='`func_echo_all $NM | $SED -e '\\''s/B\\([[^B]]*\\)$/P\\1/'\\''` -PCpgl $libobjs $convenience | awk '\\''{ if (((\\$ 2 == \"T\") || (\\$ 2 == \"D\") || (\\$ 2 == \"B\") || (\\$ 2 == \"W\") || (\\$ 2 == \"V\") || (\\$ 2 == \"Z\")) && ([substr](\\$ 1,1,1) != \".\")) { if ((\\$ 2 == \"W\") || (\\$ 2 == \"V\") || (\\$ 2 == \"Z\")) { print \\$ 1 \" weak\" } else { print \\$ 1 } } }'\\'' | sort -u > $export_symbols'\n    fi\n    ;;\n  pw32*)\n    _LT_TAGVAR(export_symbols_cmds, $1)=$ltdll_cmds\n    ;;\n  cygwin* | mingw* | cegcc*)\n    case $cc_basename in\n    cl*)\n      _LT_TAGVAR(exclude_expsyms, $1)='_NULL_IMPORT_DESCRIPTOR|_IMPORT_DESCRIPTOR_.*'\n      ;;\n    *)\n      _LT_TAGVAR(export_symbols_cmds, $1)='$NM $libobjs $convenience | $global_symbol_pipe | $SED -e '\\''/^[[BCDGRS]][[ ]]/s/.*[[ ]]\\([[^ ]]*\\)/\\1 DATA/;s/^.*[[ ]]__nm__\\([[^ ]]*\\)[[ ]][[^ ]]*/\\1 DATA/;/^I[[ ]]/d;/^[[AITW]][[ ]]/s/.* //'\\'' | sort | uniq > $export_symbols'\n      _LT_TAGVAR(exclude_expsyms, $1)=['[_]+GLOBAL_OFFSET_TABLE_|[_]+GLOBAL__[FID]_.*|[_]+head_[A-Za-z0-9_]+_dll|[A-Za-z0-9_]+_dll_iname']\n      ;;\n    esac\n    ;;\n  linux* | k*bsd*-gnu | gnu*)\n    _LT_TAGVAR(link_all_deplibs, $1)=no\n    ;;\n  *)\n    _LT_TAGVAR(export_symbols_cmds, $1)='$NM $libobjs $convenience | $global_symbol_pipe | $SED '\\''s/.* //'\\'' | sort | uniq > $export_symbols'\n    ;;\n  esac\n], [\n  runpath_var=\n  _LT_TAGVAR(allow_undefined_flag, $1)=\n  _LT_TAGVAR(always_export_symbols, $1)=no\n  _LT_TAGVAR(archive_cmds, $1)=\n  _LT_TAGVAR(archive_expsym_cmds, $1)=\n  _LT_TAGVAR(compiler_needs_object, $1)=no\n  _LT_TAGVAR(enable_shared_with_static_runtimes, $1)=no\n  _LT_TAGVAR(export_dynamic_flag_spec, $1)=\n  _LT_TAGVAR(export_symbols_cmds, $1)='$NM $libobjs $convenience | $global_symbol_pipe | $SED '\\''s/.* //'\\'' | sort | uniq > $export_symbols'\n  _LT_TAGVAR(hardcode_automatic, $1)=no\n  _LT_TAGVAR(hardcode_direct, $1)=no\n  _LT_TAGVAR(hardcode_direct_absolute, $1)=no\n  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)=\n  _LT_TAGVAR(hardcode_libdir_separator, $1)=\n  _LT_TAGVAR(hardcode_minus_L, $1)=no\n  _LT_TAGVAR(hardcode_shlibpath_var, $1)=unsupported\n  _LT_TAGVAR(inherit_rpath, $1)=no\n  _LT_TAGVAR(link_all_deplibs, $1)=unknown\n  _LT_TAGVAR(module_cmds, $1)=\n  _LT_TAGVAR(module_expsym_cmds, $1)=\n  _LT_TAGVAR(old_archive_from_new_cmds, $1)=\n  _LT_TAGVAR(old_archive_from_expsyms_cmds, $1)=\n  _LT_TAGVAR(thread_safe_flag_spec, $1)=\n  _LT_TAGVAR(whole_archive_flag_spec, $1)=\n  # include_expsyms should be a list of space-separated symbols to be *always*\n  # included in the symbol list\n  _LT_TAGVAR(include_expsyms, $1)=\n  # exclude_expsyms can be an extended regexp of symbols to exclude\n  # it will be wrapped by ' (' and ')$', so one must not match beginning or\n  # end of line.  Example: 'a|bc|.*d.*' will exclude the symbols 'a' and 'bc',\n  # as well as any symbol that contains 'd'.\n  _LT_TAGVAR(exclude_expsyms, $1)=['_GLOBAL_OFFSET_TABLE_|_GLOBAL__F[ID]_.*']\n  # Although _GLOBAL_OFFSET_TABLE_ is a valid symbol C name, most a.out\n  # platforms (ab)use it in PIC code, but their linkers get confused if\n  # the symbol is explicitly referenced.  Since portable code cannot\n  # rely on this symbol name, it's probably fine to never include it in\n  # preloaded symbol tables.\n  # Exclude shared library initialization/finalization symbols.\ndnl Note also adjust exclude_expsyms for C++ above.\n  extract_expsyms_cmds=\n\n  case $host_os in\n  cygwin* | mingw* | pw32* | cegcc*)\n    # FIXME: the MSVC++ port hasn't been tested in a loooong time\n    # When not using gcc, we currently assume that we are using\n    # Microsoft Visual C++.\n    if test yes != \"$GCC\"; then\n      with_gnu_ld=no\n    fi\n    ;;\n  interix*)\n    # we just hope/assume this is gcc and not c89 (= MSVC++)\n    with_gnu_ld=yes\n    ;;\n  openbsd* | bitrig*)\n    with_gnu_ld=no\n    ;;\n  linux* | k*bsd*-gnu | gnu*)\n    _LT_TAGVAR(link_all_deplibs, $1)=no\n    ;;\n  esac\n\n  _LT_TAGVAR(ld_shlibs, $1)=yes\n\n  # On some targets, GNU ld is compatible enough with the native linker\n  # that we're better off using the native interface for both.\n  lt_use_gnu_ld_interface=no\n  if test yes = \"$with_gnu_ld\"; then\n    case $host_os in\n      aix*)\n\t# The AIX port of GNU ld has always aspired to compatibility\n\t# with the native linker.  However, as the warning in the GNU ld\n\t# block says, versions before 2.19.5* couldn't really create working\n\t# shared libraries, regardless of the interface used.\n\tcase `$LD -v 2>&1` in\n\t  *\\ \\(GNU\\ Binutils\\)\\ 2.19.5*) ;;\n\t  *\\ \\(GNU\\ Binutils\\)\\ 2.[[2-9]]*) ;;\n\t  *\\ \\(GNU\\ Binutils\\)\\ [[3-9]]*) ;;\n\t  *)\n\t    lt_use_gnu_ld_interface=yes\n\t    ;;\n\tesac\n\t;;\n      *)\n\tlt_use_gnu_ld_interface=yes\n\t;;\n    esac\n  fi\n\n  if test yes = \"$lt_use_gnu_ld_interface\"; then\n    # If archive_cmds runs LD, not CC, wlarc should be empty\n    wlarc='$wl'\n\n    # Set some defaults for GNU ld with shared library support. These\n    # are reset later if shared libraries are not supported. Putting them\n    # here allows them to be overridden if necessary.\n    runpath_var=LD_RUN_PATH\n    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n    _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl--export-dynamic'\n    # ancient GNU ld didn't support --whole-archive et. al.\n    if $LD --help 2>&1 | $GREP 'no-whole-archive' > /dev/null; then\n      _LT_TAGVAR(whole_archive_flag_spec, $1)=$wlarc'--whole-archive$convenience '$wlarc'--no-whole-archive'\n    else\n      _LT_TAGVAR(whole_archive_flag_spec, $1)=\n    fi\n    supports_anon_versioning=no\n    case `$LD -v | $SED -e 's/([^)]\\+)\\s\\+//' 2>&1` in\n      *GNU\\ gold*) supports_anon_versioning=yes ;;\n      *\\ [[01]].* | *\\ 2.[[0-9]].* | *\\ 2.10.*) ;; # catch versions < 2.11\n      *\\ 2.11.93.0.2\\ *) supports_anon_versioning=yes ;; # RH7.3 ...\n      *\\ 2.11.92.0.12\\ *) supports_anon_versioning=yes ;; # Mandrake 8.2 ...\n      *\\ 2.11.*) ;; # other 2.11 versions\n      *) supports_anon_versioning=yes ;;\n    esac\n\n    # See if GNU ld supports shared libraries.\n    case $host_os in\n    aix[[3-9]]*)\n      # On AIX/PPC, the GNU linker is very broken\n      if test ia64 != \"$host_cpu\"; then\n\t_LT_TAGVAR(ld_shlibs, $1)=no\n\tcat <<_LT_EOF 1>&2\n\n*** Warning: the GNU linker, at least up to release 2.19, is reported\n*** to be unable to reliably create shared libraries on AIX.\n*** Therefore, libtool is disabling shared libraries support.  If you\n*** really care for shared libraries, you may want to install binutils\n*** 2.20 or above, or modify your PATH so that a non-GNU linker is found.\n*** You will then need to restart the configuration process.\n\n_LT_EOF\n      fi\n      ;;\n\n    amigaos*)\n      case $host_cpu in\n      powerpc)\n            # see comment about AmigaOS4 .so support\n            _LT_TAGVAR(archive_cmds, $1)='$CC -shared $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n            _LT_TAGVAR(archive_expsym_cmds, $1)=''\n        ;;\n      m68k)\n            _LT_TAGVAR(archive_cmds, $1)='$RM $output_objdir/a2ixlibrary.data~$ECHO \"#define NAME $libname\" > $output_objdir/a2ixlibrary.data~$ECHO \"#define LIBRARY_ID 1\" >> $output_objdir/a2ixlibrary.data~$ECHO \"#define VERSION $major\" >> $output_objdir/a2ixlibrary.data~$ECHO \"#define REVISION $revision\" >> $output_objdir/a2ixlibrary.data~$AR $AR_FLAGS $lib $libobjs~$RANLIB $lib~(cd $output_objdir && a2ixlibrary -32)'\n            _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n            _LT_TAGVAR(hardcode_minus_L, $1)=yes\n        ;;\n      esac\n      ;;\n\n    beos*)\n      if $LD --help 2>&1 | $GREP ': supported targets:.* elf' > /dev/null; then\n\t_LT_TAGVAR(allow_undefined_flag, $1)=unsupported\n\t# Joseph Beckenbach <jrb3@best.com> says some releases of gcc\n\t# support --undefined.  This deserves some investigation.  FIXME\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -nostart $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n      else\n\t_LT_TAGVAR(ld_shlibs, $1)=no\n      fi\n      ;;\n\n    cygwin* | mingw* | pw32* | cegcc*)\n      # _LT_TAGVAR(hardcode_libdir_flag_spec, $1) is actually meaningless,\n      # as there is no search path for DLLs.\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n      _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl--export-all-symbols'\n      _LT_TAGVAR(allow_undefined_flag, $1)=unsupported\n      _LT_TAGVAR(always_export_symbols, $1)=no\n      _LT_TAGVAR(enable_shared_with_static_runtimes, $1)=yes\n      _LT_TAGVAR(export_symbols_cmds, $1)='$NM $libobjs $convenience | $global_symbol_pipe | $SED -e '\\''/^[[BCDGRS]][[ ]]/s/.*[[ ]]\\([[^ ]]*\\)/\\1 DATA/;s/^.*[[ ]]__nm__\\([[^ ]]*\\)[[ ]][[^ ]]*/\\1 DATA/;/^I[[ ]]/d;/^[[AITW]][[ ]]/s/.* //'\\'' | sort | uniq > $export_symbols'\n      _LT_TAGVAR(exclude_expsyms, $1)=['[_]+GLOBAL_OFFSET_TABLE_|[_]+GLOBAL__[FID]_.*|[_]+head_[A-Za-z0-9_]+_dll|[A-Za-z0-9_]+_dll_iname']\n\n      if $LD --help 2>&1 | $GREP 'auto-import' > /dev/null; then\n        _LT_TAGVAR(archive_cmds, $1)='$CC -shared $libobjs $deplibs $compiler_flags -o $output_objdir/$soname $wl--enable-auto-image-base -Xlinker --out-implib -Xlinker $lib'\n\t# If the export-symbols file already is a .def file, use it as\n\t# is; otherwise, prepend EXPORTS...\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='if _LT_DLL_DEF_P([$export_symbols]); then\n          cp $export_symbols $output_objdir/$soname.def;\n        else\n          echo EXPORTS > $output_objdir/$soname.def;\n          cat $export_symbols >> $output_objdir/$soname.def;\n        fi~\n        $CC -shared $output_objdir/$soname.def $libobjs $deplibs $compiler_flags -o $output_objdir/$soname $wl--enable-auto-image-base -Xlinker --out-implib -Xlinker $lib'\n      else\n\t_LT_TAGVAR(ld_shlibs, $1)=no\n      fi\n      ;;\n\n    haiku*)\n      _LT_TAGVAR(archive_cmds, $1)='$CC -shared $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n      _LT_TAGVAR(link_all_deplibs, $1)=yes\n      ;;\n\n    os2*)\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n      _LT_TAGVAR(hardcode_minus_L, $1)=yes\n      _LT_TAGVAR(allow_undefined_flag, $1)=unsupported\n      shrext_cmds=.dll\n      _LT_TAGVAR(archive_cmds, $1)='$ECHO \"LIBRARY ${soname%$shared_ext} INITINSTANCE TERMINSTANCE\" > $output_objdir/$libname.def~\n\t$ECHO \"DESCRIPTION \\\"$libname\\\"\" >> $output_objdir/$libname.def~\n\t$ECHO \"DATA MULTIPLE NONSHARED\" >> $output_objdir/$libname.def~\n\t$ECHO EXPORTS >> $output_objdir/$libname.def~\n\temxexp $libobjs | $SED /\"_DLL_InitTerm\"/d >> $output_objdir/$libname.def~\n\t$CC -Zdll -Zcrtdll -o $output_objdir/$soname $libobjs $deplibs $compiler_flags $output_objdir/$libname.def~\n\temximp -o $lib $output_objdir/$libname.def'\n      _LT_TAGVAR(archive_expsym_cmds, $1)='$ECHO \"LIBRARY ${soname%$shared_ext} INITINSTANCE TERMINSTANCE\" > $output_objdir/$libname.def~\n\t$ECHO \"DESCRIPTION \\\"$libname\\\"\" >> $output_objdir/$libname.def~\n\t$ECHO \"DATA MULTIPLE NONSHARED\" >> $output_objdir/$libname.def~\n\t$ECHO EXPORTS >> $output_objdir/$libname.def~\n\tprefix_cmds=\"$SED\"~\n\tif test EXPORTS = \"`$SED 1q $export_symbols`\"; then\n\t  prefix_cmds=\"$prefix_cmds -e 1d\";\n\tfi~\n\tprefix_cmds=\"$prefix_cmds -e \\\"s/^\\(.*\\)$/_\\1/g\\\"\"~\n\tcat $export_symbols | $prefix_cmds >> $output_objdir/$libname.def~\n\t$CC -Zdll -Zcrtdll -o $output_objdir/$soname $libobjs $deplibs $compiler_flags $output_objdir/$libname.def~\n\temximp -o $lib $output_objdir/$libname.def'\n      _LT_TAGVAR(old_archive_From_new_cmds, $1)='emximp -o $output_objdir/${libname}_dll.a $output_objdir/$libname.def'\n      _LT_TAGVAR(enable_shared_with_static_runtimes, $1)=yes\n      ;;\n\n    interix[[3-9]]*)\n      _LT_TAGVAR(hardcode_direct, $1)=no\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath,$libdir'\n      _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-E'\n      # Hack: On Interix 3.x, we cannot compile PIC because of a broken gcc.\n      # Instead, shared libraries are loaded at an image base (0x10000000 by\n      # default) and relocated if they conflict, which is a slow very memory\n      # consuming and fragmenting process.  To avoid this, we pick a random,\n      # 256 KiB-aligned image base between 0x50000000 and 0x6FFC0000 at link\n      # time.  Moving up from 0x10000000 also allows more sbrk(2) space.\n      _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-h,$soname $wl--image-base,`expr ${RANDOM-$$} % 4096 / 2 \\* 262144 + 1342177280` -o $lib'\n      _LT_TAGVAR(archive_expsym_cmds, $1)='sed \"s|^|_|\" $export_symbols >$output_objdir/$soname.expsym~$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-h,$soname $wl--retain-symbols-file,$output_objdir/$soname.expsym $wl--image-base,`expr ${RANDOM-$$} % 4096 / 2 \\* 262144 + 1342177280` -o $lib'\n      ;;\n\n    gnu* | linux* | tpf* | k*bsd*-gnu | kopensolaris*-gnu)\n      tmp_diet=no\n      if test linux-dietlibc = \"$host_os\"; then\n\tcase $cc_basename in\n\t  diet\\ *) tmp_diet=yes;;\t# linux-dietlibc with static linking (!diet-dyn)\n\tesac\n      fi\n      if $LD --help 2>&1 | $EGREP ': supported targets:.* elf' > /dev/null \\\n\t && test no = \"$tmp_diet\"\n      then\n\ttmp_addflag=' $pic_flag'\n\ttmp_sharedflag='-shared'\n\tcase $cc_basename,$host_cpu in\n        pgcc*)\t\t\t\t# Portland Group C compiler\n\t  _LT_TAGVAR(whole_archive_flag_spec, $1)='$wl--whole-archive`for conv in $convenience\\\"\\\"; do test  -n \\\"$conv\\\" && new_convenience=\\\"$new_convenience,$conv\\\"; done; func_echo_all \\\"$new_convenience\\\"` $wl--no-whole-archive'\n\t  tmp_addflag=' $pic_flag'\n\t  ;;\n\tpgf77* | pgf90* | pgf95* | pgfortran*)\n\t\t\t\t\t# Portland Group f77 and f90 compilers\n\t  _LT_TAGVAR(whole_archive_flag_spec, $1)='$wl--whole-archive`for conv in $convenience\\\"\\\"; do test  -n \\\"$conv\\\" && new_convenience=\\\"$new_convenience,$conv\\\"; done; func_echo_all \\\"$new_convenience\\\"` $wl--no-whole-archive'\n\t  tmp_addflag=' $pic_flag -Mnomain' ;;\n\tecc*,ia64* | icc*,ia64*)\t# Intel C compiler on ia64\n\t  tmp_addflag=' -i_dynamic' ;;\n\tefc*,ia64* | ifort*,ia64*)\t# Intel Fortran compiler on ia64\n\t  tmp_addflag=' -i_dynamic -nofor_main' ;;\n\tifc* | ifort*)\t\t\t# Intel Fortran compiler\n\t  tmp_addflag=' -nofor_main' ;;\n\tlf95*)\t\t\t\t# Lahey Fortran 8.1\n\t  _LT_TAGVAR(whole_archive_flag_spec, $1)=\n\t  tmp_sharedflag='--shared' ;;\n        nagfor*)                        # NAGFOR 5.3\n          tmp_sharedflag='-Wl,-shared' ;;\n\txl[[cC]]* | bgxl[[cC]]* | mpixl[[cC]]*) # IBM XL C 8.0 on PPC (deal with xlf below)\n\t  tmp_sharedflag='-qmkshrobj'\n\t  tmp_addflag= ;;\n\tnvcc*)\t# Cuda Compiler Driver 2.2\n\t  _LT_TAGVAR(whole_archive_flag_spec, $1)='$wl--whole-archive`for conv in $convenience\\\"\\\"; do test  -n \\\"$conv\\\" && new_convenience=\\\"$new_convenience,$conv\\\"; done; func_echo_all \\\"$new_convenience\\\"` $wl--no-whole-archive'\n\t  _LT_TAGVAR(compiler_needs_object, $1)=yes\n\t  ;;\n\tesac\n\tcase `$CC -V 2>&1 | sed 5q` in\n\t*Sun\\ C*)\t\t\t# Sun C 5.9\n\t  _LT_TAGVAR(whole_archive_flag_spec, $1)='$wl--whole-archive`new_convenience=; for conv in $convenience\\\"\\\"; do test -z \\\"$conv\\\" || new_convenience=\\\"$new_convenience,$conv\\\"; done; func_echo_all \\\"$new_convenience\\\"` $wl--no-whole-archive'\n\t  _LT_TAGVAR(compiler_needs_object, $1)=yes\n\t  tmp_sharedflag='-G' ;;\n\t*Sun\\ F*)\t\t\t# Sun Fortran 8.3\n\t  tmp_sharedflag='-G' ;;\n\tesac\n\t_LT_TAGVAR(archive_cmds, $1)='$CC '\"$tmp_sharedflag\"\"$tmp_addflag\"' $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n\n        if test yes = \"$supports_anon_versioning\"; then\n          _LT_TAGVAR(archive_expsym_cmds, $1)='echo \"{ global:\" > $output_objdir/$libname.ver~\n            cat $export_symbols | sed -e \"s/\\(.*\\)/\\1;/\" >> $output_objdir/$libname.ver~\n            echo \"local: *; };\" >> $output_objdir/$libname.ver~\n            $CC '\"$tmp_sharedflag\"\"$tmp_addflag\"' $libobjs $deplibs $compiler_flags $wl-soname $wl$soname $wl-version-script $wl$output_objdir/$libname.ver -o $lib'\n        fi\n\n\tcase $cc_basename in\n\ttcc*)\n\t  _LT_TAGVAR(export_dynamic_flag_spec, $1)='-rdynamic'\n\t  ;;\n\txlf* | bgf* | bgxlf* | mpixlf*)\n\t  # IBM XL Fortran 10.1 on PPC cannot create shared libs itself\n\t  _LT_TAGVAR(whole_archive_flag_spec, $1)='--whole-archive$convenience --no-whole-archive'\n\t  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n\t  _LT_TAGVAR(archive_cmds, $1)='$LD -shared $libobjs $deplibs $linker_flags -soname $soname -o $lib'\n\t  if test yes = \"$supports_anon_versioning\"; then\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)='echo \"{ global:\" > $output_objdir/$libname.ver~\n              cat $export_symbols | sed -e \"s/\\(.*\\)/\\1;/\" >> $output_objdir/$libname.ver~\n              echo \"local: *; };\" >> $output_objdir/$libname.ver~\n              $LD -shared $libobjs $deplibs $linker_flags -soname $soname -version-script $output_objdir/$libname.ver -o $lib'\n\t  fi\n\t  ;;\n\tesac\n      else\n        _LT_TAGVAR(ld_shlibs, $1)=no\n      fi\n      ;;\n\n    netbsd* | netbsdelf*-gnu)\n      if echo __ELF__ | $CC -E - | $GREP __ELF__ >/dev/null; then\n\t_LT_TAGVAR(archive_cmds, $1)='$LD -Bshareable $libobjs $deplibs $linker_flags -o $lib'\n\twlarc=\n      else\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-soname $wl$soname $wl-retain-symbols-file $wl$export_symbols -o $lib'\n      fi\n      ;;\n\n    solaris*)\n      if $LD -v 2>&1 | $GREP 'BFD 2\\.8' > /dev/null; then\n\t_LT_TAGVAR(ld_shlibs, $1)=no\n\tcat <<_LT_EOF 1>&2\n\n*** Warning: The releases 2.8.* of the GNU linker cannot reliably\n*** create shared libraries on Solaris systems.  Therefore, libtool\n*** is disabling shared libraries support.  We urge you to upgrade GNU\n*** binutils to release 2.9.1 or newer.  Another option is to modify\n*** your PATH or compiler configuration so that the native linker is\n*** used, and then restart.\n\n_LT_EOF\n      elif $LD --help 2>&1 | $GREP ': supported targets:.* elf' > /dev/null; then\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-soname $wl$soname $wl-retain-symbols-file $wl$export_symbols -o $lib'\n      else\n\t_LT_TAGVAR(ld_shlibs, $1)=no\n      fi\n      ;;\n\n    sysv5* | sco3.2v5* | sco5v6* | unixware* | OpenUNIX*)\n      case `$LD -v 2>&1` in\n        *\\ [[01]].* | *\\ 2.[[0-9]].* | *\\ 2.1[[0-5]].*)\n\t_LT_TAGVAR(ld_shlibs, $1)=no\n\tcat <<_LT_EOF 1>&2\n\n*** Warning: Releases of the GNU linker prior to 2.16.91.0.3 cannot\n*** reliably create shared libraries on SCO systems.  Therefore, libtool\n*** is disabling shared libraries support.  We urge you to upgrade GNU\n*** binutils to release 2.16.91.0.3 or newer.  Another option is to modify\n*** your PATH or compiler configuration so that the native linker is\n*** used, and then restart.\n\n_LT_EOF\n\t;;\n\t*)\n\t  # For security reasons, it is highly recommended that you always\n\t  # use absolute paths for naming shared libraries, and exclude the\n\t  # DT_RUNPATH tag from executables and libraries.  But doing so\n\t  # requires that you compile everything twice, which is a pain.\n\t  if $LD --help 2>&1 | $GREP ': supported targets:.* elf' > /dev/null; then\n\t    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n\t    _LT_TAGVAR(archive_cmds, $1)='$CC -shared $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $libobjs $deplibs $compiler_flags $wl-soname $wl$soname $wl-retain-symbols-file $wl$export_symbols -o $lib'\n\t  else\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t  fi\n\t;;\n      esac\n      ;;\n\n    sunos4*)\n      _LT_TAGVAR(archive_cmds, $1)='$LD -assert pure-text -Bshareable -o $lib $libobjs $deplibs $linker_flags'\n      wlarc=\n      _LT_TAGVAR(hardcode_direct, $1)=yes\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      ;;\n\n    *)\n      if $LD --help 2>&1 | $GREP ': supported targets:.* elf' > /dev/null; then\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-soname $wl$soname $wl-retain-symbols-file $wl$export_symbols -o $lib'\n      else\n\t_LT_TAGVAR(ld_shlibs, $1)=no\n      fi\n      ;;\n    esac\n\n    if test no = \"$_LT_TAGVAR(ld_shlibs, $1)\"; then\n      runpath_var=\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)=\n      _LT_TAGVAR(export_dynamic_flag_spec, $1)=\n      _LT_TAGVAR(whole_archive_flag_spec, $1)=\n    fi\n  else\n    # PORTME fill in a description of your system's linker (not GNU ld)\n    case $host_os in\n    aix3*)\n      _LT_TAGVAR(allow_undefined_flag, $1)=unsupported\n      _LT_TAGVAR(always_export_symbols, $1)=yes\n      _LT_TAGVAR(archive_expsym_cmds, $1)='$LD -o $output_objdir/$soname $libobjs $deplibs $linker_flags -bE:$export_symbols -T512 -H512 -bM:SRE~$AR $AR_FLAGS $lib $output_objdir/$soname'\n      # Note: this linker hardcodes the directories in LIBPATH if there\n      # are no directories specified by -L.\n      _LT_TAGVAR(hardcode_minus_L, $1)=yes\n      if test yes = \"$GCC\" && test -z \"$lt_prog_compiler_static\"; then\n\t# Neither direct hardcoding nor static linking is supported with a\n\t# broken collect2.\n\t_LT_TAGVAR(hardcode_direct, $1)=unsupported\n      fi\n      ;;\n\n    aix[[4-9]]*)\n      if test ia64 = \"$host_cpu\"; then\n\t# On IA64, the linker does run time linking by default, so we don't\n\t# have to do anything special.\n\taix_use_runtimelinking=no\n\texp_sym_flag='-Bexport'\n\tno_entry_flag=\n      else\n\t# If we're using GNU nm, then we don't want the \"-C\" option.\n\t# -C means demangle to GNU nm, but means don't demangle to AIX nm.\n\t# Without the \"-l\" option, or with the \"-B\" option, AIX nm treats\n\t# weak defined symbols like other global defined symbols, whereas\n\t# GNU nm marks them as \"W\".\n\t# While the 'weak' keyword is ignored in the Export File, we need\n\t# it in the Import File for the 'aix-soname' feature, so we have\n\t# to replace the \"-B\" option with \"-P\" for AIX nm.\n\tif $NM -V 2>&1 | $GREP 'GNU' > /dev/null; then\n\t  _LT_TAGVAR(export_symbols_cmds, $1)='$NM -Bpg $libobjs $convenience | awk '\\''{ if (((\\$ 2 == \"T\") || (\\$ 2 == \"D\") || (\\$ 2 == \"B\") || (\\$ 2 == \"W\")) && ([substr](\\$ 3,1,1) != \".\")) { if (\\$ 2 == \"W\") { print \\$ 3 \" weak\" } else { print \\$ 3 } } }'\\'' | sort -u > $export_symbols'\n\telse\n\t  _LT_TAGVAR(export_symbols_cmds, $1)='`func_echo_all $NM | $SED -e '\\''s/B\\([[^B]]*\\)$/P\\1/'\\''` -PCpgl $libobjs $convenience | awk '\\''{ if (((\\$ 2 == \"T\") || (\\$ 2 == \"D\") || (\\$ 2 == \"B\") || (\\$ 2 == \"W\") || (\\$ 2 == \"V\") || (\\$ 2 == \"Z\")) && ([substr](\\$ 1,1,1) != \".\")) { if ((\\$ 2 == \"W\") || (\\$ 2 == \"V\") || (\\$ 2 == \"Z\")) { print \\$ 1 \" weak\" } else { print \\$ 1 } } }'\\'' | sort -u > $export_symbols'\n\tfi\n\taix_use_runtimelinking=no\n\n\t# Test if we are trying to use run time linking or normal\n\t# AIX style linking. If -brtl is somewhere in LDFLAGS, we\n\t# have runtime linking enabled, and use it for executables.\n\t# For shared libraries, we enable/disable runtime linking\n\t# depending on the kind of the shared library created -\n\t# when \"with_aix_soname,aix_use_runtimelinking\" is:\n\t# \"aix,no\"   lib.a(lib.so.V) shared, rtl:no,  for executables\n\t# \"aix,yes\"  lib.so          shared, rtl:yes, for executables\n\t#            lib.a           static archive\n\t# \"both,no\"  lib.so.V(shr.o) shared, rtl:yes\n\t#            lib.a(lib.so.V) shared, rtl:no,  for executables\n\t# \"both,yes\" lib.so.V(shr.o) shared, rtl:yes, for executables\n\t#            lib.a(lib.so.V) shared, rtl:no\n\t# \"svr4,*\"   lib.so.V(shr.o) shared, rtl:yes, for executables\n\t#            lib.a           static archive\n\tcase $host_os in aix4.[[23]]|aix4.[[23]].*|aix[[5-9]]*)\n\t  for ld_flag in $LDFLAGS; do\n\t  if (test x-brtl = \"x$ld_flag\" || test x-Wl,-brtl = \"x$ld_flag\"); then\n\t    aix_use_runtimelinking=yes\n\t    break\n\t  fi\n\t  done\n\t  if test svr4,no = \"$with_aix_soname,$aix_use_runtimelinking\"; then\n\t    # With aix-soname=svr4, we create the lib.so.V shared archives only,\n\t    # so we don't have lib.a shared libs to link our executables.\n\t    # We have to force runtime linking in this case.\n\t    aix_use_runtimelinking=yes\n\t    LDFLAGS=\"$LDFLAGS -Wl,-brtl\"\n\t  fi\n\t  ;;\n\tesac\n\n\texp_sym_flag='-bexport'\n\tno_entry_flag='-bnoentry'\n      fi\n\n      # When large executables or shared objects are built, AIX ld can\n      # have problems creating the table of contents.  If linking a library\n      # or program results in \"error TOC overflow\" add -mminimal-toc to\n      # CXXFLAGS/CFLAGS for g++/gcc.  In the cases where that is not\n      # enough to fix the problem, add -Wl,-bbigtoc to LDFLAGS.\n\n      _LT_TAGVAR(archive_cmds, $1)=''\n      _LT_TAGVAR(hardcode_direct, $1)=yes\n      _LT_TAGVAR(hardcode_direct_absolute, $1)=yes\n      _LT_TAGVAR(hardcode_libdir_separator, $1)=':'\n      _LT_TAGVAR(link_all_deplibs, $1)=yes\n      _LT_TAGVAR(file_list_spec, $1)='$wl-f,'\n      case $with_aix_soname,$aix_use_runtimelinking in\n      aix,*) ;; # traditional, no import file\n      svr4,* | *,yes) # use import file\n\t# The Import File defines what to hardcode.\n\t_LT_TAGVAR(hardcode_direct, $1)=no\n\t_LT_TAGVAR(hardcode_direct_absolute, $1)=no\n\t;;\n      esac\n\n      if test yes = \"$GCC\"; then\n\tcase $host_os in aix4.[[012]]|aix4.[[012]].*)\n\t# We only want to do this on AIX 4.2 and lower, the check\n\t# below for broken collect2 doesn't work under 4.3+\n\t  collect2name=`$CC -print-prog-name=collect2`\n\t  if test -f \"$collect2name\" &&\n\t   strings \"$collect2name\" | $GREP resolve_lib_name >/dev/null\n\t  then\n\t  # We have reworked collect2\n\t  :\n\t  else\n\t  # We have old collect2\n\t  _LT_TAGVAR(hardcode_direct, $1)=unsupported\n\t  # It fails to find uninstalled libraries when the uninstalled\n\t  # path is not listed in the libpath.  Setting hardcode_minus_L\n\t  # to unsupported forces relinking\n\t  _LT_TAGVAR(hardcode_minus_L, $1)=yes\n\t  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n\t  _LT_TAGVAR(hardcode_libdir_separator, $1)=\n\t  fi\n\t  ;;\n\tesac\n\tshared_flag='-shared'\n\tif test yes = \"$aix_use_runtimelinking\"; then\n\t  shared_flag=\"$shared_flag \"'$wl-G'\n\tfi\n\t# Need to ensure runtime linking is disabled for the traditional\n\t# shared library, or the linker may eventually find shared libraries\n\t# /with/ Import File - we do not want to mix them.\n\tshared_flag_aix='-shared'\n\tshared_flag_svr4='-shared $wl-G'\n      else\n\t# not using gcc\n\tif test ia64 = \"$host_cpu\"; then\n\t# VisualAge C++, Version 5.5 for AIX 5L for IA-64, Beta 3 Release\n\t# chokes on -Wl,-G. The following line is correct:\n\t  shared_flag='-G'\n\telse\n\t  if test yes = \"$aix_use_runtimelinking\"; then\n\t    shared_flag='$wl-G'\n\t  else\n\t    shared_flag='$wl-bM:SRE'\n\t  fi\n\t  shared_flag_aix='$wl-bM:SRE'\n\t  shared_flag_svr4='$wl-G'\n\tfi\n      fi\n\n      _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-bexpall'\n      # It seems that -bexpall does not export symbols beginning with\n      # underscore (_), so it is better to generate a list of symbols to export.\n      _LT_TAGVAR(always_export_symbols, $1)=yes\n      if test aix,yes = \"$with_aix_soname,$aix_use_runtimelinking\"; then\n\t# Warning - without using the other runtime loading flags (-brtl),\n\t# -berok will link without error, but may produce a broken library.\n\t_LT_TAGVAR(allow_undefined_flag, $1)='-berok'\n        # Determine the default libpath from the value encoded in an\n        # empty executable.\n        _LT_SYS_MODULE_PATH_AIX([$1])\n        _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-blibpath:$libdir:'\"$aix_libpath\"\n        _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -o $output_objdir/$soname $libobjs $deplibs $wl'$no_entry_flag' $compiler_flags `if test -n \"$allow_undefined_flag\"; then func_echo_all \"$wl$allow_undefined_flag\"; else :; fi` $wl'$exp_sym_flag:\\$export_symbols' '$shared_flag\n      else\n\tif test ia64 = \"$host_cpu\"; then\n\t  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-R $libdir:/usr/lib:/lib'\n\t  _LT_TAGVAR(allow_undefined_flag, $1)=\"-z nodefs\"\n\t  _LT_TAGVAR(archive_expsym_cmds, $1)=\"\\$CC $shared_flag\"' -o $output_objdir/$soname $libobjs $deplibs '\"\\$wl$no_entry_flag\"' $compiler_flags $wl$allow_undefined_flag '\"\\$wl$exp_sym_flag:\\$export_symbols\"\n\telse\n\t # Determine the default libpath from the value encoded in an\n\t # empty executable.\n\t _LT_SYS_MODULE_PATH_AIX([$1])\n\t _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-blibpath:$libdir:'\"$aix_libpath\"\n\t  # Warning - without using the other run time loading flags,\n\t  # -berok will link without error, but may produce a broken library.\n\t  _LT_TAGVAR(no_undefined_flag, $1)=' $wl-bernotok'\n\t  _LT_TAGVAR(allow_undefined_flag, $1)=' $wl-berok'\n\t  if test yes = \"$with_gnu_ld\"; then\n\t    # We only use this code for GNU lds that support --whole-archive.\n\t    _LT_TAGVAR(whole_archive_flag_spec, $1)='$wl--whole-archive$convenience $wl--no-whole-archive'\n\t  else\n\t    # Exported symbols can be pulled into shared objects from archives\n\t    _LT_TAGVAR(whole_archive_flag_spec, $1)='$convenience'\n\t  fi\n\t  _LT_TAGVAR(archive_cmds_need_lc, $1)=yes\n\t  _LT_TAGVAR(archive_expsym_cmds, $1)='$RM -r $output_objdir/$realname.d~$MKDIR $output_objdir/$realname.d'\n\t  # -brtl affects multiple linker settings, -berok does not and is overridden later\n\t  compiler_flags_filtered='`func_echo_all \"$compiler_flags \" | $SED -e \"s%-brtl\\\\([[, ]]\\\\)%-berok\\\\1%g\"`'\n\t  if test svr4 != \"$with_aix_soname\"; then\n\t    # This is similar to how AIX traditionally builds its shared libraries.\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)=\"$_LT_TAGVAR(archive_expsym_cmds, $1)\"'~$CC '$shared_flag_aix' -o $output_objdir/$realname.d/$soname $libobjs $deplibs $wl-bnoentry '$compiler_flags_filtered'$wl-bE:$export_symbols$allow_undefined_flag~$AR $AR_FLAGS $output_objdir/$libname$release.a $output_objdir/$realname.d/$soname'\n\t  fi\n\t  if test aix != \"$with_aix_soname\"; then\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)=\"$_LT_TAGVAR(archive_expsym_cmds, $1)\"'~$CC '$shared_flag_svr4' -o $output_objdir/$realname.d/$shared_archive_member_spec.o $libobjs $deplibs $wl-bnoentry '$compiler_flags_filtered'$wl-bE:$export_symbols$allow_undefined_flag~$STRIP -e $output_objdir/$realname.d/$shared_archive_member_spec.o~( func_echo_all \"#! $soname($shared_archive_member_spec.o)\"; if test shr_64 = \"$shared_archive_member_spec\"; then func_echo_all \"# 64\"; else func_echo_all \"# 32\"; fi; cat $export_symbols ) > $output_objdir/$realname.d/$shared_archive_member_spec.imp~$AR $AR_FLAGS $output_objdir/$soname $output_objdir/$realname.d/$shared_archive_member_spec.o $output_objdir/$realname.d/$shared_archive_member_spec.imp'\n\t  else\n\t    # used by -dlpreopen to get the symbols\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)=\"$_LT_TAGVAR(archive_expsym_cmds, $1)\"'~$MV  $output_objdir/$realname.d/$soname $output_objdir'\n\t  fi\n\t  _LT_TAGVAR(archive_expsym_cmds, $1)=\"$_LT_TAGVAR(archive_expsym_cmds, $1)\"'~$RM -r $output_objdir/$realname.d'\n\tfi\n      fi\n      ;;\n\n    amigaos*)\n      case $host_cpu in\n      powerpc)\n            # see comment about AmigaOS4 .so support\n            _LT_TAGVAR(archive_cmds, $1)='$CC -shared $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n            _LT_TAGVAR(archive_expsym_cmds, $1)=''\n        ;;\n      m68k)\n            _LT_TAGVAR(archive_cmds, $1)='$RM $output_objdir/a2ixlibrary.data~$ECHO \"#define NAME $libname\" > $output_objdir/a2ixlibrary.data~$ECHO \"#define LIBRARY_ID 1\" >> $output_objdir/a2ixlibrary.data~$ECHO \"#define VERSION $major\" >> $output_objdir/a2ixlibrary.data~$ECHO \"#define REVISION $revision\" >> $output_objdir/a2ixlibrary.data~$AR $AR_FLAGS $lib $libobjs~$RANLIB $lib~(cd $output_objdir && a2ixlibrary -32)'\n            _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n            _LT_TAGVAR(hardcode_minus_L, $1)=yes\n        ;;\n      esac\n      ;;\n\n    bsdi[[45]]*)\n      _LT_TAGVAR(export_dynamic_flag_spec, $1)=-rdynamic\n      ;;\n\n    cygwin* | mingw* | pw32* | cegcc*)\n      # When not using gcc, we currently assume that we are using\n      # Microsoft Visual C++.\n      # hardcode_libdir_flag_spec is actually meaningless, as there is\n      # no search path for DLLs.\n      case $cc_basename in\n      cl*)\n\t# Native MSVC\n\t_LT_TAGVAR(hardcode_libdir_flag_spec, $1)=' '\n\t_LT_TAGVAR(allow_undefined_flag, $1)=unsupported\n\t_LT_TAGVAR(always_export_symbols, $1)=yes\n\t_LT_TAGVAR(file_list_spec, $1)='@'\n\t# Tell ltmain to make .lib files, not .a files.\n\tlibext=lib\n\t# Tell ltmain to make .dll files, not .so files.\n\tshrext_cmds=.dll\n\t# FIXME: Setting linknames here is a bad hack.\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -o $output_objdir/$soname $libobjs $compiler_flags $deplibs -Wl,-DLL,-IMPLIB:\"$tool_output_objdir$libname.dll.lib\"~linknames='\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='if _LT_DLL_DEF_P([$export_symbols]); then\n            cp \"$export_symbols\" \"$output_objdir/$soname.def\";\n            echo \"$tool_output_objdir$soname.def\" > \"$output_objdir/$soname.exp\";\n          else\n            $SED -e '\\''s/^/-link -EXPORT:/'\\'' < $export_symbols > $output_objdir/$soname.exp;\n          fi~\n          $CC -o $tool_output_objdir$soname $libobjs $compiler_flags $deplibs \"@$tool_output_objdir$soname.exp\" -Wl,-DLL,-IMPLIB:\"$tool_output_objdir$libname.dll.lib\"~\n          linknames='\n\t# The linker will not automatically build a static lib if we build a DLL.\n\t# _LT_TAGVAR(old_archive_from_new_cmds, $1)='true'\n\t_LT_TAGVAR(enable_shared_with_static_runtimes, $1)=yes\n\t_LT_TAGVAR(exclude_expsyms, $1)='_NULL_IMPORT_DESCRIPTOR|_IMPORT_DESCRIPTOR_.*'\n\t_LT_TAGVAR(export_symbols_cmds, $1)='$NM $libobjs $convenience | $global_symbol_pipe | $SED -e '\\''/^[[BCDGRS]][[ ]]/s/.*[[ ]]\\([[^ ]]*\\)/\\1,DATA/'\\'' | $SED -e '\\''/^[[AITW]][[ ]]/s/.*[[ ]]//'\\'' | sort | uniq > $export_symbols'\n\t# Don't use ranlib\n\t_LT_TAGVAR(old_postinstall_cmds, $1)='chmod 644 $oldlib'\n\t_LT_TAGVAR(postlink_cmds, $1)='lt_outputfile=\"@OUTPUT@\"~\n          lt_tool_outputfile=\"@TOOL_OUTPUT@\"~\n          case $lt_outputfile in\n            *.exe|*.EXE) ;;\n            *)\n              lt_outputfile=$lt_outputfile.exe\n              lt_tool_outputfile=$lt_tool_outputfile.exe\n              ;;\n          esac~\n          if test : != \"$MANIFEST_TOOL\" && test -f \"$lt_outputfile.manifest\"; then\n            $MANIFEST_TOOL -manifest \"$lt_tool_outputfile.manifest\" -outputresource:\"$lt_tool_outputfile\" || exit 1;\n            $RM \"$lt_outputfile.manifest\";\n          fi'\n\t;;\n      *)\n\t# Assume MSVC wrapper\n\t_LT_TAGVAR(hardcode_libdir_flag_spec, $1)=' '\n\t_LT_TAGVAR(allow_undefined_flag, $1)=unsupported\n\t# Tell ltmain to make .lib files, not .a files.\n\tlibext=lib\n\t# Tell ltmain to make .dll files, not .so files.\n\tshrext_cmds=.dll\n\t# FIXME: Setting linknames here is a bad hack.\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -o $lib $libobjs $compiler_flags `func_echo_all \"$deplibs\" | $SED '\\''s/ -lc$//'\\''` -link -dll~linknames='\n\t# The linker will automatically build a .lib file if we build a DLL.\n\t_LT_TAGVAR(old_archive_from_new_cmds, $1)='true'\n\t# FIXME: Should let the user specify the lib program.\n\t_LT_TAGVAR(old_archive_cmds, $1)='lib -OUT:$oldlib$oldobjs$old_deplibs'\n\t_LT_TAGVAR(enable_shared_with_static_runtimes, $1)=yes\n\t;;\n      esac\n      ;;\n\n    darwin* | rhapsody*)\n      _LT_DARWIN_LINKER_FEATURES($1)\n      ;;\n\n    dgux*)\n      _LT_TAGVAR(archive_cmds, $1)='$LD -G -h $soname -o $lib $libobjs $deplibs $linker_flags'\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      ;;\n\n    # FreeBSD 2.2.[012] allows us to include c++rt0.o to get C++ constructor\n    # support.  Future versions do this automatically, but an explicit c++rt0.o\n    # does not break anything, and helps significantly (at the cost of a little\n    # extra space).\n    freebsd2.2*)\n      _LT_TAGVAR(archive_cmds, $1)='$LD -Bshareable -o $lib $libobjs $deplibs $linker_flags /usr/lib/c++rt0.o'\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-R$libdir'\n      _LT_TAGVAR(hardcode_direct, $1)=yes\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      ;;\n\n    # Unfortunately, older versions of FreeBSD 2 do not have this feature.\n    freebsd2.*)\n      _LT_TAGVAR(archive_cmds, $1)='$LD -Bshareable -o $lib $libobjs $deplibs $linker_flags'\n      _LT_TAGVAR(hardcode_direct, $1)=yes\n      _LT_TAGVAR(hardcode_minus_L, $1)=yes\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      ;;\n\n    # FreeBSD 3 and greater uses gcc -shared to do shared libraries.\n    freebsd* | dragonfly*)\n      _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag -o $lib $libobjs $deplibs $compiler_flags'\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-R$libdir'\n      _LT_TAGVAR(hardcode_direct, $1)=yes\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      ;;\n\n    hpux9*)\n      if test yes = \"$GCC\"; then\n\t_LT_TAGVAR(archive_cmds, $1)='$RM $output_objdir/$soname~$CC -shared $pic_flag $wl+b $wl$install_libdir -o $output_objdir/$soname $libobjs $deplibs $compiler_flags~test \"x$output_objdir/$soname\" = \"x$lib\" || mv $output_objdir/$soname $lib'\n      else\n\t_LT_TAGVAR(archive_cmds, $1)='$RM $output_objdir/$soname~$LD -b +b $install_libdir -o $output_objdir/$soname $libobjs $deplibs $linker_flags~test \"x$output_objdir/$soname\" = \"x$lib\" || mv $output_objdir/$soname $lib'\n      fi\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl+b $wl$libdir'\n      _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n      _LT_TAGVAR(hardcode_direct, $1)=yes\n\n      # hardcode_minus_L: Not really in the search PATH,\n      # but as the default location of the library.\n      _LT_TAGVAR(hardcode_minus_L, $1)=yes\n      _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-E'\n      ;;\n\n    hpux10*)\n      if test yes,no = \"$GCC,$with_gnu_ld\"; then\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $wl+h $wl$soname $wl+b $wl$install_libdir -o $lib $libobjs $deplibs $compiler_flags'\n      else\n\t_LT_TAGVAR(archive_cmds, $1)='$LD -b +h $soname +b $install_libdir -o $lib $libobjs $deplibs $linker_flags'\n      fi\n      if test no = \"$with_gnu_ld\"; then\n\t_LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl+b $wl$libdir'\n\t_LT_TAGVAR(hardcode_libdir_separator, $1)=:\n\t_LT_TAGVAR(hardcode_direct, $1)=yes\n\t_LT_TAGVAR(hardcode_direct_absolute, $1)=yes\n\t_LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-E'\n\t# hardcode_minus_L: Not really in the search PATH,\n\t# but as the default location of the library.\n\t_LT_TAGVAR(hardcode_minus_L, $1)=yes\n      fi\n      ;;\n\n    hpux11*)\n      if test yes,no = \"$GCC,$with_gnu_ld\"; then\n\tcase $host_cpu in\n\thppa*64*)\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -shared $wl+h $wl$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t  ;;\n\tia64*)\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $wl+h $wl$soname $wl+nodefaultrpath -o $lib $libobjs $deplibs $compiler_flags'\n\t  ;;\n\t*)\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $wl+h $wl$soname $wl+b $wl$install_libdir -o $lib $libobjs $deplibs $compiler_flags'\n\t  ;;\n\tesac\n      else\n\tcase $host_cpu in\n\thppa*64*)\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -b $wl+h $wl$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t  ;;\n\tia64*)\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -b $wl+h $wl$soname $wl+nodefaultrpath -o $lib $libobjs $deplibs $compiler_flags'\n\t  ;;\n\t*)\n\tm4_if($1, [], [\n\t  # Older versions of the 11.00 compiler do not understand -b yet\n\t  # (HP92453-01 A.11.01.20 doesn't, HP92453-01 B.11.X.35175-35176.GP does)\n\t  _LT_LINKER_OPTION([if $CC understands -b],\n\t    _LT_TAGVAR(lt_cv_prog_compiler__b, $1), [-b],\n\t    [_LT_TAGVAR(archive_cmds, $1)='$CC -b $wl+h $wl$soname $wl+b $wl$install_libdir -o $lib $libobjs $deplibs $compiler_flags'],\n\t    [_LT_TAGVAR(archive_cmds, $1)='$LD -b +h $soname +b $install_libdir -o $lib $libobjs $deplibs $linker_flags'])],\n\t  [_LT_TAGVAR(archive_cmds, $1)='$CC -b $wl+h $wl$soname $wl+b $wl$install_libdir -o $lib $libobjs $deplibs $compiler_flags'])\n\t  ;;\n\tesac\n      fi\n      if test no = \"$with_gnu_ld\"; then\n\t_LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl+b $wl$libdir'\n\t_LT_TAGVAR(hardcode_libdir_separator, $1)=:\n\n\tcase $host_cpu in\n\thppa*64*|ia64*)\n\t  _LT_TAGVAR(hardcode_direct, $1)=no\n\t  _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n\t  ;;\n\t*)\n\t  _LT_TAGVAR(hardcode_direct, $1)=yes\n\t  _LT_TAGVAR(hardcode_direct_absolute, $1)=yes\n\t  _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-E'\n\n\t  # hardcode_minus_L: Not really in the search PATH,\n\t  # but as the default location of the library.\n\t  _LT_TAGVAR(hardcode_minus_L, $1)=yes\n\t  ;;\n\tesac\n      fi\n      ;;\n\n    irix5* | irix6* | nonstopux*)\n      if test yes = \"$GCC\"; then\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-soname $wl$soname `test -n \"$verstring\" && func_echo_all \"$wl-set_version $wl$verstring\"` $wl-update_registry $wl$output_objdir/so_locations -o $lib'\n\t# Try to use the -exported_symbol ld option, if it does not\n\t# work, assume that -exports_file does not work either and\n\t# implicitly export all symbols.\n\t# This should be the same for all languages, so no per-tag cache variable.\n\tAC_CACHE_CHECK([whether the $host_os linker accepts -exported_symbol],\n\t  [lt_cv_irix_exported_symbol],\n\t  [save_LDFLAGS=$LDFLAGS\n\t   LDFLAGS=\"$LDFLAGS -shared $wl-exported_symbol ${wl}foo $wl-update_registry $wl/dev/null\"\n\t   AC_LINK_IFELSE(\n\t     [AC_LANG_SOURCE(\n\t        [AC_LANG_CASE([C], [[int foo (void) { return 0; }]],\n\t\t\t      [C++], [[int foo (void) { return 0; }]],\n\t\t\t      [Fortran 77], [[\n      subroutine foo\n      end]],\n\t\t\t      [Fortran], [[\n      subroutine foo\n      end]])])],\n\t      [lt_cv_irix_exported_symbol=yes],\n\t      [lt_cv_irix_exported_symbol=no])\n           LDFLAGS=$save_LDFLAGS])\n\tif test yes = \"$lt_cv_irix_exported_symbol\"; then\n          _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-soname $wl$soname `test -n \"$verstring\" && func_echo_all \"$wl-set_version $wl$verstring\"` $wl-update_registry $wl$output_objdir/so_locations $wl-exports_file $wl$export_symbols -o $lib'\n\tfi\n\t_LT_TAGVAR(link_all_deplibs, $1)=no\n      else\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared $libobjs $deplibs $compiler_flags -soname $soname `test -n \"$verstring\" && func_echo_all \"-set_version $verstring\"` -update_registry $output_objdir/so_locations -o $lib'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $libobjs $deplibs $compiler_flags -soname $soname `test -n \"$verstring\" && func_echo_all \"-set_version $verstring\"` -update_registry $output_objdir/so_locations -exports_file $export_symbols -o $lib'\n      fi\n      _LT_TAGVAR(archive_cmds_need_lc, $1)='no'\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n      _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n      _LT_TAGVAR(inherit_rpath, $1)=yes\n      _LT_TAGVAR(link_all_deplibs, $1)=yes\n      ;;\n\n    linux*)\n      case $cc_basename in\n      tcc*)\n\t# Fabrice Bellard et al's Tiny C Compiler\n\t_LT_TAGVAR(ld_shlibs, $1)=yes\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag -o $lib $libobjs $deplibs $compiler_flags'\n\t;;\n      esac\n      ;;\n\n    netbsd* | netbsdelf*-gnu)\n      if echo __ELF__ | $CC -E - | $GREP __ELF__ >/dev/null; then\n\t_LT_TAGVAR(archive_cmds, $1)='$LD -Bshareable -o $lib $libobjs $deplibs $linker_flags'  # a.out\n      else\n\t_LT_TAGVAR(archive_cmds, $1)='$LD -shared -o $lib $libobjs $deplibs $linker_flags'      # ELF\n      fi\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-R$libdir'\n      _LT_TAGVAR(hardcode_direct, $1)=yes\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      ;;\n\n    newsos6)\n      _LT_TAGVAR(archive_cmds, $1)='$LD -G -h $soname -o $lib $libobjs $deplibs $linker_flags'\n      _LT_TAGVAR(hardcode_direct, $1)=yes\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n      _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      ;;\n\n    *nto* | *qnx*)\n      ;;\n\n    openbsd* | bitrig*)\n      if test -f /usr/libexec/ld.so; then\n\t_LT_TAGVAR(hardcode_direct, $1)=yes\n\t_LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n\t_LT_TAGVAR(hardcode_direct_absolute, $1)=yes\n\tif test -z \"`echo __ELF__ | $CC -E - | $GREP __ELF__`\"; then\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag -o $lib $libobjs $deplibs $compiler_flags'\n\t  _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $pic_flag -o $lib $libobjs $deplibs $compiler_flags $wl-retain-symbols-file,$export_symbols'\n\t  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath,$libdir'\n\t  _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-E'\n\telse\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag -o $lib $libobjs $deplibs $compiler_flags'\n\t  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath,$libdir'\n\tfi\n      else\n\t_LT_TAGVAR(ld_shlibs, $1)=no\n      fi\n      ;;\n\n    os2*)\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n      _LT_TAGVAR(hardcode_minus_L, $1)=yes\n      _LT_TAGVAR(allow_undefined_flag, $1)=unsupported\n      shrext_cmds=.dll\n      _LT_TAGVAR(archive_cmds, $1)='$ECHO \"LIBRARY ${soname%$shared_ext} INITINSTANCE TERMINSTANCE\" > $output_objdir/$libname.def~\n\t$ECHO \"DESCRIPTION \\\"$libname\\\"\" >> $output_objdir/$libname.def~\n\t$ECHO \"DATA MULTIPLE NONSHARED\" >> $output_objdir/$libname.def~\n\t$ECHO EXPORTS >> $output_objdir/$libname.def~\n\temxexp $libobjs | $SED /\"_DLL_InitTerm\"/d >> $output_objdir/$libname.def~\n\t$CC -Zdll -Zcrtdll -o $output_objdir/$soname $libobjs $deplibs $compiler_flags $output_objdir/$libname.def~\n\temximp -o $lib $output_objdir/$libname.def'\n      _LT_TAGVAR(archive_expsym_cmds, $1)='$ECHO \"LIBRARY ${soname%$shared_ext} INITINSTANCE TERMINSTANCE\" > $output_objdir/$libname.def~\n\t$ECHO \"DESCRIPTION \\\"$libname\\\"\" >> $output_objdir/$libname.def~\n\t$ECHO \"DATA MULTIPLE NONSHARED\" >> $output_objdir/$libname.def~\n\t$ECHO EXPORTS >> $output_objdir/$libname.def~\n\tprefix_cmds=\"$SED\"~\n\tif test EXPORTS = \"`$SED 1q $export_symbols`\"; then\n\t  prefix_cmds=\"$prefix_cmds -e 1d\";\n\tfi~\n\tprefix_cmds=\"$prefix_cmds -e \\\"s/^\\(.*\\)$/_\\1/g\\\"\"~\n\tcat $export_symbols | $prefix_cmds >> $output_objdir/$libname.def~\n\t$CC -Zdll -Zcrtdll -o $output_objdir/$soname $libobjs $deplibs $compiler_flags $output_objdir/$libname.def~\n\temximp -o $lib $output_objdir/$libname.def'\n      _LT_TAGVAR(old_archive_From_new_cmds, $1)='emximp -o $output_objdir/${libname}_dll.a $output_objdir/$libname.def'\n      _LT_TAGVAR(enable_shared_with_static_runtimes, $1)=yes\n      ;;\n\n    osf3*)\n      if test yes = \"$GCC\"; then\n\t_LT_TAGVAR(allow_undefined_flag, $1)=' $wl-expect_unresolved $wl\\*'\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared$allow_undefined_flag $libobjs $deplibs $compiler_flags $wl-soname $wl$soname `test -n \"$verstring\" && func_echo_all \"$wl-set_version $wl$verstring\"` $wl-update_registry $wl$output_objdir/so_locations -o $lib'\n      else\n\t_LT_TAGVAR(allow_undefined_flag, $1)=' -expect_unresolved \\*'\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared$allow_undefined_flag $libobjs $deplibs $compiler_flags -soname $soname `test -n \"$verstring\" && func_echo_all \"-set_version $verstring\"` -update_registry $output_objdir/so_locations -o $lib'\n      fi\n      _LT_TAGVAR(archive_cmds_need_lc, $1)='no'\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n      _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n      ;;\n\n    osf4* | osf5*)\t# as osf3* with the addition of -msym flag\n      if test yes = \"$GCC\"; then\n\t_LT_TAGVAR(allow_undefined_flag, $1)=' $wl-expect_unresolved $wl\\*'\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared$allow_undefined_flag $pic_flag $libobjs $deplibs $compiler_flags $wl-msym $wl-soname $wl$soname `test -n \"$verstring\" && func_echo_all \"$wl-set_version $wl$verstring\"` $wl-update_registry $wl$output_objdir/so_locations -o $lib'\n\t_LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n      else\n\t_LT_TAGVAR(allow_undefined_flag, $1)=' -expect_unresolved \\*'\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared$allow_undefined_flag $libobjs $deplibs $compiler_flags -msym -soname $soname `test -n \"$verstring\" && func_echo_all \"-set_version $verstring\"` -update_registry $output_objdir/so_locations -o $lib'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='for i in `cat $export_symbols`; do printf \"%s %s\\\\n\" -exported_symbol \"\\$i\" >> $lib.exp; done; printf \"%s\\\\n\" \"-hidden\">> $lib.exp~\n          $CC -shared$allow_undefined_flag $wl-input $wl$lib.exp $compiler_flags $libobjs $deplibs -soname $soname `test -n \"$verstring\" && $ECHO \"-set_version $verstring\"` -update_registry $output_objdir/so_locations -o $lib~$RM $lib.exp'\n\n\t# Both c and cxx compiler support -rpath directly\n\t_LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-rpath $libdir'\n      fi\n      _LT_TAGVAR(archive_cmds_need_lc, $1)='no'\n      _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n      ;;\n\n    solaris*)\n      _LT_TAGVAR(no_undefined_flag, $1)=' -z defs'\n      if test yes = \"$GCC\"; then\n\twlarc='$wl'\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $wl-z ${wl}text $wl-h $wl$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='echo \"{ global:\" > $lib.exp~cat $export_symbols | $SED -e \"s/\\(.*\\)/\\1;/\" >> $lib.exp~echo \"local: *; };\" >> $lib.exp~\n          $CC -shared $pic_flag $wl-z ${wl}text $wl-M $wl$lib.exp $wl-h $wl$soname -o $lib $libobjs $deplibs $compiler_flags~$RM $lib.exp'\n      else\n\tcase `$CC -V 2>&1` in\n\t*\"Compilers 5.0\"*)\n\t  wlarc=''\n\t  _LT_TAGVAR(archive_cmds, $1)='$LD -G$allow_undefined_flag -h $soname -o $lib $libobjs $deplibs $linker_flags'\n\t  _LT_TAGVAR(archive_expsym_cmds, $1)='echo \"{ global:\" > $lib.exp~cat $export_symbols | $SED -e \"s/\\(.*\\)/\\1;/\" >> $lib.exp~echo \"local: *; };\" >> $lib.exp~\n            $LD -G$allow_undefined_flag -M $lib.exp -h $soname -o $lib $libobjs $deplibs $linker_flags~$RM $lib.exp'\n\t  ;;\n\t*)\n\t  wlarc='$wl'\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -G$allow_undefined_flag -h $soname -o $lib $libobjs $deplibs $compiler_flags'\n\t  _LT_TAGVAR(archive_expsym_cmds, $1)='echo \"{ global:\" > $lib.exp~cat $export_symbols | $SED -e \"s/\\(.*\\)/\\1;/\" >> $lib.exp~echo \"local: *; };\" >> $lib.exp~\n            $CC -G$allow_undefined_flag -M $lib.exp -h $soname -o $lib $libobjs $deplibs $compiler_flags~$RM $lib.exp'\n\t  ;;\n\tesac\n      fi\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-R$libdir'\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      case $host_os in\n      solaris2.[[0-5]] | solaris2.[[0-5]].*) ;;\n      *)\n\t# The compiler driver will combine and reorder linker options,\n\t# but understands '-z linker_flag'.  GCC discards it without '$wl',\n\t# but is careful enough not to reorder.\n\t# Supported since Solaris 2.6 (maybe 2.5.1?)\n\tif test yes = \"$GCC\"; then\n\t  _LT_TAGVAR(whole_archive_flag_spec, $1)='$wl-z ${wl}allextract$convenience $wl-z ${wl}defaultextract'\n\telse\n\t  _LT_TAGVAR(whole_archive_flag_spec, $1)='-z allextract$convenience -z defaultextract'\n\tfi\n\t;;\n      esac\n      _LT_TAGVAR(link_all_deplibs, $1)=yes\n      ;;\n\n    sunos4*)\n      if test sequent = \"$host_vendor\"; then\n\t# Use $CC to link under sequent, because it throws in some extra .o\n\t# files that make .init and .fini sections work.\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -G $wl-h $soname -o $lib $libobjs $deplibs $compiler_flags'\n      else\n\t_LT_TAGVAR(archive_cmds, $1)='$LD -assert pure-text -Bstatic -o $lib $libobjs $deplibs $linker_flags'\n      fi\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n      _LT_TAGVAR(hardcode_direct, $1)=yes\n      _LT_TAGVAR(hardcode_minus_L, $1)=yes\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      ;;\n\n    sysv4)\n      case $host_vendor in\n\tsni)\n\t  _LT_TAGVAR(archive_cmds, $1)='$LD -G -h $soname -o $lib $libobjs $deplibs $linker_flags'\n\t  _LT_TAGVAR(hardcode_direct, $1)=yes # is this really true???\n\t;;\n\tsiemens)\n\t  ## LD is ld it makes a PLAMLIB\n\t  ## CC just makes a GrossModule.\n\t  _LT_TAGVAR(archive_cmds, $1)='$LD -G -o $lib $libobjs $deplibs $linker_flags'\n\t  _LT_TAGVAR(reload_cmds, $1)='$CC -r -o $output$reload_objs'\n\t  _LT_TAGVAR(hardcode_direct, $1)=no\n        ;;\n\tmotorola)\n\t  _LT_TAGVAR(archive_cmds, $1)='$LD -G -h $soname -o $lib $libobjs $deplibs $linker_flags'\n\t  _LT_TAGVAR(hardcode_direct, $1)=no #Motorola manual says yes, but my tests say they lie\n\t;;\n      esac\n      runpath_var='LD_RUN_PATH'\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      ;;\n\n    sysv4.3*)\n      _LT_TAGVAR(archive_cmds, $1)='$LD -G -h $soname -o $lib $libobjs $deplibs $linker_flags'\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      _LT_TAGVAR(export_dynamic_flag_spec, $1)='-Bexport'\n      ;;\n\n    sysv4*MP*)\n      if test -d /usr/nec; then\n\t_LT_TAGVAR(archive_cmds, $1)='$LD -G -h $soname -o $lib $libobjs $deplibs $linker_flags'\n\t_LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n\trunpath_var=LD_RUN_PATH\n\thardcode_runpath_var=yes\n\t_LT_TAGVAR(ld_shlibs, $1)=yes\n      fi\n      ;;\n\n    sysv4*uw2* | sysv5OpenUNIX* | sysv5UnixWare7.[[01]].[[10]]* | unixware7* | sco3.2v5.0.[[024]]*)\n      _LT_TAGVAR(no_undefined_flag, $1)='$wl-z,text'\n      _LT_TAGVAR(archive_cmds_need_lc, $1)=no\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      runpath_var='LD_RUN_PATH'\n\n      if test yes = \"$GCC\"; then\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $wl-Bexport:$export_symbols $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n      else\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -G $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='$CC -G $wl-Bexport:$export_symbols $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n      fi\n      ;;\n\n    sysv5* | sco3.2v5* | sco5v6*)\n      # Note: We CANNOT use -z defs as we might desire, because we do not\n      # link with -lc, and that would cause any symbols used from libc to\n      # always be unresolved, which means just about no library would\n      # ever link correctly.  If we're not using GNU ld we use -z text\n      # though, which does catch some bad symbols but isn't as heavy-handed\n      # as -z defs.\n      _LT_TAGVAR(no_undefined_flag, $1)='$wl-z,text'\n      _LT_TAGVAR(allow_undefined_flag, $1)='$wl-z,nodefs'\n      _LT_TAGVAR(archive_cmds_need_lc, $1)=no\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-R,$libdir'\n      _LT_TAGVAR(hardcode_libdir_separator, $1)=':'\n      _LT_TAGVAR(link_all_deplibs, $1)=yes\n      _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-Bexport'\n      runpath_var='LD_RUN_PATH'\n\n      if test yes = \"$GCC\"; then\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $wl-Bexport:$export_symbols $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n      else\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -G $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='$CC -G $wl-Bexport:$export_symbols $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n      fi\n      ;;\n\n    uts4*)\n      _LT_TAGVAR(archive_cmds, $1)='$LD -G -h $soname -o $lib $libobjs $deplibs $linker_flags'\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      ;;\n\n    *)\n      _LT_TAGVAR(ld_shlibs, $1)=no\n      ;;\n    esac\n\n    if test sni = \"$host_vendor\"; then\n      case $host in\n      sysv4 | sysv4.2uw2* | sysv4.3* | sysv5*)\n\t_LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-Blargedynsym'\n\t;;\n      esac\n    fi\n  fi\n])\nAC_MSG_RESULT([$_LT_TAGVAR(ld_shlibs, $1)])\ntest no = \"$_LT_TAGVAR(ld_shlibs, $1)\" && can_build_shared=no\n\n_LT_TAGVAR(with_gnu_ld, $1)=$with_gnu_ld\n\n_LT_DECL([], [libext], [0], [Old archive suffix (normally \"a\")])dnl\n_LT_DECL([], [shrext_cmds], [1], [Shared library suffix (normally \".so\")])dnl\n_LT_DECL([], [extract_expsyms_cmds], [2],\n    [The commands to extract the exported symbol list from a shared archive])\n\n#\n# Do we need to explicitly link libc?\n#\ncase \"x$_LT_TAGVAR(archive_cmds_need_lc, $1)\" in\nx|xyes)\n  # Assume -lc should be added\n  _LT_TAGVAR(archive_cmds_need_lc, $1)=yes\n\n  if test yes,yes = \"$GCC,$enable_shared\"; then\n    case $_LT_TAGVAR(archive_cmds, $1) in\n    *'~'*)\n      # FIXME: we may have to deal with multi-command sequences.\n      ;;\n    '$CC '*)\n      # Test whether the compiler implicitly links with -lc since on some\n      # systems, -lgcc has to come before -lc. If gcc already passes -lc\n      # to ld, don't add -lc before -lgcc.\n      AC_CACHE_CHECK([whether -lc should be explicitly linked in],\n\t[lt_cv_]_LT_TAGVAR(archive_cmds_need_lc, $1),\n\t[$RM conftest*\n\techo \"$lt_simple_compile_test_code\" > conftest.$ac_ext\n\n\tif AC_TRY_EVAL(ac_compile) 2>conftest.err; then\n\t  soname=conftest\n\t  lib=conftest\n\t  libobjs=conftest.$ac_objext\n\t  deplibs=\n\t  wl=$_LT_TAGVAR(lt_prog_compiler_wl, $1)\n\t  pic_flag=$_LT_TAGVAR(lt_prog_compiler_pic, $1)\n\t  compiler_flags=-v\n\t  linker_flags=-v\n\t  verstring=\n\t  output_objdir=.\n\t  libname=conftest\n\t  lt_save_allow_undefined_flag=$_LT_TAGVAR(allow_undefined_flag, $1)\n\t  _LT_TAGVAR(allow_undefined_flag, $1)=\n\t  if AC_TRY_EVAL(_LT_TAGVAR(archive_cmds, $1) 2\\>\\&1 \\| $GREP \\\" -lc \\\" \\>/dev/null 2\\>\\&1)\n\t  then\n\t    lt_cv_[]_LT_TAGVAR(archive_cmds_need_lc, $1)=no\n\t  else\n\t    lt_cv_[]_LT_TAGVAR(archive_cmds_need_lc, $1)=yes\n\t  fi\n\t  _LT_TAGVAR(allow_undefined_flag, $1)=$lt_save_allow_undefined_flag\n\telse\n\t  cat conftest.err 1>&5\n\tfi\n\t$RM conftest*\n\t])\n      _LT_TAGVAR(archive_cmds_need_lc, $1)=$lt_cv_[]_LT_TAGVAR(archive_cmds_need_lc, $1)\n      ;;\n    esac\n  fi\n  ;;\nesac\n\n_LT_TAGDECL([build_libtool_need_lc], [archive_cmds_need_lc], [0],\n    [Whether or not to add -lc for building shared libraries])\n_LT_TAGDECL([allow_libtool_libs_with_static_runtimes],\n    [enable_shared_with_static_runtimes], [0],\n    [Whether or not to disallow shared libs when runtime libs are static])\n_LT_TAGDECL([], [export_dynamic_flag_spec], [1],\n    [Compiler flag to allow reflexive dlopens])\n_LT_TAGDECL([], [whole_archive_flag_spec], [1],\n    [Compiler flag to generate shared objects directly from archives])\n_LT_TAGDECL([], [compiler_needs_object], [1],\n    [Whether the compiler copes with passing no objects directly])\n_LT_TAGDECL([], [old_archive_from_new_cmds], [2],\n    [Create an old-style archive from a shared archive])\n_LT_TAGDECL([], [old_archive_from_expsyms_cmds], [2],\n    [Create a temporary old-style archive to link instead of a shared archive])\n_LT_TAGDECL([], [archive_cmds], [2], [Commands used to build a shared archive])\n_LT_TAGDECL([], [archive_expsym_cmds], [2])\n_LT_TAGDECL([], [module_cmds], [2],\n    [Commands used to build a loadable module if different from building\n    a shared archive.])\n_LT_TAGDECL([], [module_expsym_cmds], [2])\n_LT_TAGDECL([], [with_gnu_ld], [1],\n    [Whether we are building with GNU ld or not])\n_LT_TAGDECL([], [allow_undefined_flag], [1],\n    [Flag that allows shared libraries with undefined symbols to be built])\n_LT_TAGDECL([], [no_undefined_flag], [1],\n    [Flag that enforces no undefined symbols])\n_LT_TAGDECL([], [hardcode_libdir_flag_spec], [1],\n    [Flag to hardcode $libdir into a binary during linking.\n    This must work even if $libdir does not exist])\n_LT_TAGDECL([], [hardcode_libdir_separator], [1],\n    [Whether we need a single \"-rpath\" flag with a separated argument])\n_LT_TAGDECL([], [hardcode_direct], [0],\n    [Set to \"yes\" if using DIR/libNAME$shared_ext during linking hardcodes\n    DIR into the resulting binary])\n_LT_TAGDECL([], [hardcode_direct_absolute], [0],\n    [Set to \"yes\" if using DIR/libNAME$shared_ext during linking hardcodes\n    DIR into the resulting binary and the resulting library dependency is\n    \"absolute\", i.e impossible to change by setting $shlibpath_var if the\n    library is relocated])\n_LT_TAGDECL([], [hardcode_minus_L], [0],\n    [Set to \"yes\" if using the -LDIR flag during linking hardcodes DIR\n    into the resulting binary])\n_LT_TAGDECL([], [hardcode_shlibpath_var], [0],\n    [Set to \"yes\" if using SHLIBPATH_VAR=DIR during linking hardcodes DIR\n    into the resulting binary])\n_LT_TAGDECL([], [hardcode_automatic], [0],\n    [Set to \"yes\" if building a shared library automatically hardcodes DIR\n    into the library and all subsequent libraries and executables linked\n    against it])\n_LT_TAGDECL([], [inherit_rpath], [0],\n    [Set to yes if linker adds runtime paths of dependent libraries\n    to runtime path list])\n_LT_TAGDECL([], [link_all_deplibs], [0],\n    [Whether libtool must link a program against all its dependency libraries])\n_LT_TAGDECL([], [always_export_symbols], [0],\n    [Set to \"yes\" if exported symbols are required])\n_LT_TAGDECL([], [export_symbols_cmds], [2],\n    [The commands to list exported symbols])\n_LT_TAGDECL([], [exclude_expsyms], [1],\n    [Symbols that should not be listed in the preloaded symbols])\n_LT_TAGDECL([], [include_expsyms], [1],\n    [Symbols that must always be exported])\n_LT_TAGDECL([], [prelink_cmds], [2],\n    [Commands necessary for linking programs (against libraries) with templates])\n_LT_TAGDECL([], [postlink_cmds], [2],\n    [Commands necessary for finishing linking programs])\n_LT_TAGDECL([], [file_list_spec], [1],\n    [Specify filename containing input files])\ndnl FIXME: Not yet implemented\ndnl _LT_TAGDECL([], [thread_safe_flag_spec], [1],\ndnl    [Compiler flag to generate thread safe objects])\n])# _LT_LINKER_SHLIBS\n\n\n# _LT_LANG_C_CONFIG([TAG])\n# ------------------------\n# Ensure that the configuration variables for a C compiler are suitably\n# defined.  These variables are subsequently used by _LT_CONFIG to write\n# the compiler configuration to 'libtool'.\nm4_defun([_LT_LANG_C_CONFIG],\n[m4_require([_LT_DECL_EGREP])dnl\nlt_save_CC=$CC\nAC_LANG_PUSH(C)\n\n# Source file extension for C test sources.\nac_ext=c\n\n# Object file extension for compiled C test sources.\nobjext=o\n_LT_TAGVAR(objext, $1)=$objext\n\n# Code to be used in simple compile tests\nlt_simple_compile_test_code=\"int some_variable = 0;\"\n\n# Code to be used in simple link tests\nlt_simple_link_test_code='int main(){return(0);}'\n\n_LT_TAG_COMPILER\n# Save the default compiler, since it gets overwritten when the other\n# tags are being tested, and _LT_TAGVAR(compiler, []) is a NOP.\ncompiler_DEFAULT=$CC\n\n# save warnings/boilerplate of simple test code\n_LT_COMPILER_BOILERPLATE\n_LT_LINKER_BOILERPLATE\n\n## CAVEAT EMPTOR:\n## There is no encapsulation within the following macros, do not change\n## the running order or otherwise move them around unless you know exactly\n## what you are doing...\nif test -n \"$compiler\"; then\n  _LT_COMPILER_NO_RTTI($1)\n  _LT_COMPILER_PIC($1)\n  _LT_COMPILER_C_O($1)\n  _LT_COMPILER_FILE_LOCKS($1)\n  _LT_LINKER_SHLIBS($1)\n  _LT_SYS_DYNAMIC_LINKER($1)\n  _LT_LINKER_HARDCODE_LIBPATH($1)\n  LT_SYS_DLOPEN_SELF\n  _LT_CMD_STRIPLIB\n\n  # Report what library types will actually be built\n  AC_MSG_CHECKING([if libtool supports shared libraries])\n  AC_MSG_RESULT([$can_build_shared])\n\n  AC_MSG_CHECKING([whether to build shared libraries])\n  test no = \"$can_build_shared\" && enable_shared=no\n\n  # On AIX, shared libraries and static libraries use the same namespace, and\n  # are all built from PIC.\n  case $host_os in\n  aix3*)\n    test yes = \"$enable_shared\" && enable_static=no\n    if test -n \"$RANLIB\"; then\n      archive_cmds=\"$archive_cmds~\\$RANLIB \\$lib\"\n      postinstall_cmds='$RANLIB $lib'\n    fi\n    ;;\n\n  aix[[4-9]]*)\n    if test ia64 != \"$host_cpu\"; then\n      case $enable_shared,$with_aix_soname,$aix_use_runtimelinking in\n      yes,aix,yes) ;;\t\t\t# shared object as lib.so file only\n      yes,svr4,*) ;;\t\t\t# shared object as lib.so archive member only\n      yes,*) enable_static=no ;;\t# shared object in lib.a archive as well\n      esac\n    fi\n    ;;\n  esac\n  AC_MSG_RESULT([$enable_shared])\n\n  AC_MSG_CHECKING([whether to build static libraries])\n  # Make sure either enable_shared or enable_static is yes.\n  test yes = \"$enable_shared\" || enable_static=yes\n  AC_MSG_RESULT([$enable_static])\n\n  _LT_CONFIG($1)\nfi\nAC_LANG_POP\nCC=$lt_save_CC\n])# _LT_LANG_C_CONFIG\n\n\n# _LT_LANG_CXX_CONFIG([TAG])\n# --------------------------\n# Ensure that the configuration variables for a C++ compiler are suitably\n# defined.  These variables are subsequently used by _LT_CONFIG to write\n# the compiler configuration to 'libtool'.\nm4_defun([_LT_LANG_CXX_CONFIG],\n[m4_require([_LT_FILEUTILS_DEFAULTS])dnl\nm4_require([_LT_DECL_EGREP])dnl\nm4_require([_LT_PATH_MANIFEST_TOOL])dnl\nif test -n \"$CXX\" && ( test no != \"$CXX\" &&\n    ( (test g++ = \"$CXX\" && `g++ -v >/dev/null 2>&1` ) ||\n    (test g++ != \"$CXX\"))); then\n  AC_PROG_CXXCPP\nelse\n  _lt_caught_CXX_error=yes\nfi\n\nAC_LANG_PUSH(C++)\n_LT_TAGVAR(archive_cmds_need_lc, $1)=no\n_LT_TAGVAR(allow_undefined_flag, $1)=\n_LT_TAGVAR(always_export_symbols, $1)=no\n_LT_TAGVAR(archive_expsym_cmds, $1)=\n_LT_TAGVAR(compiler_needs_object, $1)=no\n_LT_TAGVAR(export_dynamic_flag_spec, $1)=\n_LT_TAGVAR(hardcode_direct, $1)=no\n_LT_TAGVAR(hardcode_direct_absolute, $1)=no\n_LT_TAGVAR(hardcode_libdir_flag_spec, $1)=\n_LT_TAGVAR(hardcode_libdir_separator, $1)=\n_LT_TAGVAR(hardcode_minus_L, $1)=no\n_LT_TAGVAR(hardcode_shlibpath_var, $1)=unsupported\n_LT_TAGVAR(hardcode_automatic, $1)=no\n_LT_TAGVAR(inherit_rpath, $1)=no\n_LT_TAGVAR(module_cmds, $1)=\n_LT_TAGVAR(module_expsym_cmds, $1)=\n_LT_TAGVAR(link_all_deplibs, $1)=unknown\n_LT_TAGVAR(old_archive_cmds, $1)=$old_archive_cmds\n_LT_TAGVAR(reload_flag, $1)=$reload_flag\n_LT_TAGVAR(reload_cmds, $1)=$reload_cmds\n_LT_TAGVAR(no_undefined_flag, $1)=\n_LT_TAGVAR(whole_archive_flag_spec, $1)=\n_LT_TAGVAR(enable_shared_with_static_runtimes, $1)=no\n\n# Source file extension for C++ test sources.\nac_ext=cpp\n\n# Object file extension for compiled C++ test sources.\nobjext=o\n_LT_TAGVAR(objext, $1)=$objext\n\n# No sense in running all these tests if we already determined that\n# the CXX compiler isn't working.  Some variables (like enable_shared)\n# are currently assumed to apply to all compilers on this platform,\n# and will be corrupted by setting them based on a non-working compiler.\nif test yes != \"$_lt_caught_CXX_error\"; then\n  # Code to be used in simple compile tests\n  lt_simple_compile_test_code=\"int some_variable = 0;\"\n\n  # Code to be used in simple link tests\n  lt_simple_link_test_code='int main(int, char *[[]]) { return(0); }'\n\n  # ltmain only uses $CC for tagged configurations so make sure $CC is set.\n  _LT_TAG_COMPILER\n\n  # save warnings/boilerplate of simple test code\n  _LT_COMPILER_BOILERPLATE\n  _LT_LINKER_BOILERPLATE\n\n  # Allow CC to be a program name with arguments.\n  lt_save_CC=$CC\n  lt_save_CFLAGS=$CFLAGS\n  lt_save_LD=$LD\n  lt_save_GCC=$GCC\n  GCC=$GXX\n  lt_save_with_gnu_ld=$with_gnu_ld\n  lt_save_path_LD=$lt_cv_path_LD\n  if test -n \"${lt_cv_prog_gnu_ldcxx+set}\"; then\n    lt_cv_prog_gnu_ld=$lt_cv_prog_gnu_ldcxx\n  else\n    $as_unset lt_cv_prog_gnu_ld\n  fi\n  if test -n \"${lt_cv_path_LDCXX+set}\"; then\n    lt_cv_path_LD=$lt_cv_path_LDCXX\n  else\n    $as_unset lt_cv_path_LD\n  fi\n  test -z \"${LDCXX+set}\" || LD=$LDCXX\n  CC=${CXX-\"c++\"}\n  CFLAGS=$CXXFLAGS\n  compiler=$CC\n  _LT_TAGVAR(compiler, $1)=$CC\n  _LT_CC_BASENAME([$compiler])\n\n  if test -n \"$compiler\"; then\n    # We don't want -fno-exception when compiling C++ code, so set the\n    # no_builtin_flag separately\n    if test yes = \"$GXX\"; then\n      _LT_TAGVAR(lt_prog_compiler_no_builtin_flag, $1)=' -fno-builtin'\n    else\n      _LT_TAGVAR(lt_prog_compiler_no_builtin_flag, $1)=\n    fi\n\n    if test yes = \"$GXX\"; then\n      # Set up default GNU C++ configuration\n\n      LT_PATH_LD\n\n      # Check if GNU C++ uses GNU ld as the underlying linker, since the\n      # archiving commands below assume that GNU ld is being used.\n      if test yes = \"$with_gnu_ld\"; then\n        _LT_TAGVAR(archive_cmds, $1)='$CC $pic_flag -shared -nostdlib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname -o $lib'\n        _LT_TAGVAR(archive_expsym_cmds, $1)='$CC $pic_flag -shared -nostdlib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname $wl-retain-symbols-file $wl$export_symbols -o $lib'\n\n        _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n        _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl--export-dynamic'\n\n        # If archive_cmds runs LD, not CC, wlarc should be empty\n        # XXX I think wlarc can be eliminated in ltcf-cxx, but I need to\n        #     investigate it a little bit more. (MM)\n        wlarc='$wl'\n\n        # ancient GNU ld didn't support --whole-archive et. al.\n        if eval \"`$CC -print-prog-name=ld` --help 2>&1\" |\n\t  $GREP 'no-whole-archive' > /dev/null; then\n          _LT_TAGVAR(whole_archive_flag_spec, $1)=$wlarc'--whole-archive$convenience '$wlarc'--no-whole-archive'\n        else\n          _LT_TAGVAR(whole_archive_flag_spec, $1)=\n        fi\n      else\n        with_gnu_ld=no\n        wlarc=\n\n        # A generic and very simple default shared library creation\n        # command for GNU C++ for the case where it uses the native\n        # linker, instead of GNU ld.  If possible, this setting should\n        # overridden to take advantage of the native linker features on\n        # the platform it is being used on.\n        _LT_TAGVAR(archive_cmds, $1)='$CC -shared -nostdlib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags -o $lib'\n      fi\n\n      # Commands to make compiler produce verbose output that lists\n      # what \"hidden\" libraries, object files and flags are used when\n      # linking a shared library.\n      output_verbose_link_cmd='$CC -shared $CFLAGS -v conftest.$objext 2>&1 | $GREP -v \"^Configured with:\" | $GREP \"\\-L\"'\n\n    else\n      GXX=no\n      with_gnu_ld=no\n      wlarc=\n    fi\n\n    # PORTME: fill in a description of your system's C++ link characteristics\n    AC_MSG_CHECKING([whether the $compiler linker ($LD) supports shared libraries])\n    _LT_TAGVAR(ld_shlibs, $1)=yes\n    case $host_os in\n      aix3*)\n        # FIXME: insert proper C++ library support\n        _LT_TAGVAR(ld_shlibs, $1)=no\n        ;;\n      aix[[4-9]]*)\n        if test ia64 = \"$host_cpu\"; then\n          # On IA64, the linker does run time linking by default, so we don't\n          # have to do anything special.\n          aix_use_runtimelinking=no\n          exp_sym_flag='-Bexport'\n          no_entry_flag=\n        else\n          aix_use_runtimelinking=no\n\n          # Test if we are trying to use run time linking or normal\n          # AIX style linking. If -brtl is somewhere in LDFLAGS, we\n          # have runtime linking enabled, and use it for executables.\n          # For shared libraries, we enable/disable runtime linking\n          # depending on the kind of the shared library created -\n          # when \"with_aix_soname,aix_use_runtimelinking\" is:\n          # \"aix,no\"   lib.a(lib.so.V) shared, rtl:no,  for executables\n          # \"aix,yes\"  lib.so          shared, rtl:yes, for executables\n          #            lib.a           static archive\n          # \"both,no\"  lib.so.V(shr.o) shared, rtl:yes\n          #            lib.a(lib.so.V) shared, rtl:no,  for executables\n          # \"both,yes\" lib.so.V(shr.o) shared, rtl:yes, for executables\n          #            lib.a(lib.so.V) shared, rtl:no\n          # \"svr4,*\"   lib.so.V(shr.o) shared, rtl:yes, for executables\n          #            lib.a           static archive\n          case $host_os in aix4.[[23]]|aix4.[[23]].*|aix[[5-9]]*)\n\t    for ld_flag in $LDFLAGS; do\n\t      case $ld_flag in\n\t      *-brtl*)\n\t        aix_use_runtimelinking=yes\n\t        break\n\t        ;;\n\t      esac\n\t    done\n\t    if test svr4,no = \"$with_aix_soname,$aix_use_runtimelinking\"; then\n\t      # With aix-soname=svr4, we create the lib.so.V shared archives only,\n\t      # so we don't have lib.a shared libs to link our executables.\n\t      # We have to force runtime linking in this case.\n\t      aix_use_runtimelinking=yes\n\t      LDFLAGS=\"$LDFLAGS -Wl,-brtl\"\n\t    fi\n\t    ;;\n          esac\n\n          exp_sym_flag='-bexport'\n          no_entry_flag='-bnoentry'\n        fi\n\n        # When large executables or shared objects are built, AIX ld can\n        # have problems creating the table of contents.  If linking a library\n        # or program results in \"error TOC overflow\" add -mminimal-toc to\n        # CXXFLAGS/CFLAGS for g++/gcc.  In the cases where that is not\n        # enough to fix the problem, add -Wl,-bbigtoc to LDFLAGS.\n\n        _LT_TAGVAR(archive_cmds, $1)=''\n        _LT_TAGVAR(hardcode_direct, $1)=yes\n        _LT_TAGVAR(hardcode_direct_absolute, $1)=yes\n        _LT_TAGVAR(hardcode_libdir_separator, $1)=':'\n        _LT_TAGVAR(link_all_deplibs, $1)=yes\n        _LT_TAGVAR(file_list_spec, $1)='$wl-f,'\n        case $with_aix_soname,$aix_use_runtimelinking in\n        aix,*) ;;\t# no import file\n        svr4,* | *,yes) # use import file\n          # The Import File defines what to hardcode.\n          _LT_TAGVAR(hardcode_direct, $1)=no\n          _LT_TAGVAR(hardcode_direct_absolute, $1)=no\n          ;;\n        esac\n\n        if test yes = \"$GXX\"; then\n          case $host_os in aix4.[[012]]|aix4.[[012]].*)\n          # We only want to do this on AIX 4.2 and lower, the check\n          # below for broken collect2 doesn't work under 4.3+\n\t  collect2name=`$CC -print-prog-name=collect2`\n\t  if test -f \"$collect2name\" &&\n\t     strings \"$collect2name\" | $GREP resolve_lib_name >/dev/null\n\t  then\n\t    # We have reworked collect2\n\t    :\n\t  else\n\t    # We have old collect2\n\t    _LT_TAGVAR(hardcode_direct, $1)=unsupported\n\t    # It fails to find uninstalled libraries when the uninstalled\n\t    # path is not listed in the libpath.  Setting hardcode_minus_L\n\t    # to unsupported forces relinking\n\t    _LT_TAGVAR(hardcode_minus_L, $1)=yes\n\t    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n\t    _LT_TAGVAR(hardcode_libdir_separator, $1)=\n\t  fi\n          esac\n          shared_flag='-shared'\n\t  if test yes = \"$aix_use_runtimelinking\"; then\n\t    shared_flag=$shared_flag' $wl-G'\n\t  fi\n\t  # Need to ensure runtime linking is disabled for the traditional\n\t  # shared library, or the linker may eventually find shared libraries\n\t  # /with/ Import File - we do not want to mix them.\n\t  shared_flag_aix='-shared'\n\t  shared_flag_svr4='-shared $wl-G'\n        else\n          # not using gcc\n          if test ia64 = \"$host_cpu\"; then\n\t  # VisualAge C++, Version 5.5 for AIX 5L for IA-64, Beta 3 Release\n\t  # chokes on -Wl,-G. The following line is correct:\n\t  shared_flag='-G'\n          else\n\t    if test yes = \"$aix_use_runtimelinking\"; then\n\t      shared_flag='$wl-G'\n\t    else\n\t      shared_flag='$wl-bM:SRE'\n\t    fi\n\t    shared_flag_aix='$wl-bM:SRE'\n\t    shared_flag_svr4='$wl-G'\n          fi\n        fi\n\n        _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-bexpall'\n        # It seems that -bexpall does not export symbols beginning with\n        # underscore (_), so it is better to generate a list of symbols to\n\t# export.\n        _LT_TAGVAR(always_export_symbols, $1)=yes\n\tif test aix,yes = \"$with_aix_soname,$aix_use_runtimelinking\"; then\n          # Warning - without using the other runtime loading flags (-brtl),\n          # -berok will link without error, but may produce a broken library.\n          # The \"-G\" linker flag allows undefined symbols.\n          _LT_TAGVAR(no_undefined_flag, $1)='-bernotok'\n          # Determine the default libpath from the value encoded in an empty\n          # executable.\n          _LT_SYS_MODULE_PATH_AIX([$1])\n          _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-blibpath:$libdir:'\"$aix_libpath\"\n\n          _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -o $output_objdir/$soname $libobjs $deplibs $wl'$no_entry_flag' $compiler_flags `if test -n \"$allow_undefined_flag\"; then func_echo_all \"$wl$allow_undefined_flag\"; else :; fi` $wl'$exp_sym_flag:\\$export_symbols' '$shared_flag\n        else\n          if test ia64 = \"$host_cpu\"; then\n\t    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-R $libdir:/usr/lib:/lib'\n\t    _LT_TAGVAR(allow_undefined_flag, $1)=\"-z nodefs\"\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)=\"\\$CC $shared_flag\"' -o $output_objdir/$soname $libobjs $deplibs '\"\\$wl$no_entry_flag\"' $compiler_flags $wl$allow_undefined_flag '\"\\$wl$exp_sym_flag:\\$export_symbols\"\n          else\n\t    # Determine the default libpath from the value encoded in an\n\t    # empty executable.\n\t    _LT_SYS_MODULE_PATH_AIX([$1])\n\t    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-blibpath:$libdir:'\"$aix_libpath\"\n\t    # Warning - without using the other run time loading flags,\n\t    # -berok will link without error, but may produce a broken library.\n\t    _LT_TAGVAR(no_undefined_flag, $1)=' $wl-bernotok'\n\t    _LT_TAGVAR(allow_undefined_flag, $1)=' $wl-berok'\n\t    if test yes = \"$with_gnu_ld\"; then\n\t      # We only use this code for GNU lds that support --whole-archive.\n\t      _LT_TAGVAR(whole_archive_flag_spec, $1)='$wl--whole-archive$convenience $wl--no-whole-archive'\n\t    else\n\t      # Exported symbols can be pulled into shared objects from archives\n\t      _LT_TAGVAR(whole_archive_flag_spec, $1)='$convenience'\n\t    fi\n\t    _LT_TAGVAR(archive_cmds_need_lc, $1)=yes\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)='$RM -r $output_objdir/$realname.d~$MKDIR $output_objdir/$realname.d'\n\t    # -brtl affects multiple linker settings, -berok does not and is overridden later\n\t    compiler_flags_filtered='`func_echo_all \"$compiler_flags \" | $SED -e \"s%-brtl\\\\([[, ]]\\\\)%-berok\\\\1%g\"`'\n\t    if test svr4 != \"$with_aix_soname\"; then\n\t      # This is similar to how AIX traditionally builds its shared\n\t      # libraries. Need -bnortl late, we may have -brtl in LDFLAGS.\n\t      _LT_TAGVAR(archive_expsym_cmds, $1)=\"$_LT_TAGVAR(archive_expsym_cmds, $1)\"'~$CC '$shared_flag_aix' -o $output_objdir/$realname.d/$soname $libobjs $deplibs $wl-bnoentry '$compiler_flags_filtered'$wl-bE:$export_symbols$allow_undefined_flag~$AR $AR_FLAGS $output_objdir/$libname$release.a $output_objdir/$realname.d/$soname'\n\t    fi\n\t    if test aix != \"$with_aix_soname\"; then\n\t      _LT_TAGVAR(archive_expsym_cmds, $1)=\"$_LT_TAGVAR(archive_expsym_cmds, $1)\"'~$CC '$shared_flag_svr4' -o $output_objdir/$realname.d/$shared_archive_member_spec.o $libobjs $deplibs $wl-bnoentry '$compiler_flags_filtered'$wl-bE:$export_symbols$allow_undefined_flag~$STRIP -e $output_objdir/$realname.d/$shared_archive_member_spec.o~( func_echo_all \"#! $soname($shared_archive_member_spec.o)\"; if test shr_64 = \"$shared_archive_member_spec\"; then func_echo_all \"# 64\"; else func_echo_all \"# 32\"; fi; cat $export_symbols ) > $output_objdir/$realname.d/$shared_archive_member_spec.imp~$AR $AR_FLAGS $output_objdir/$soname $output_objdir/$realname.d/$shared_archive_member_spec.o $output_objdir/$realname.d/$shared_archive_member_spec.imp'\n\t    else\n\t      # used by -dlpreopen to get the symbols\n\t      _LT_TAGVAR(archive_expsym_cmds, $1)=\"$_LT_TAGVAR(archive_expsym_cmds, $1)\"'~$MV  $output_objdir/$realname.d/$soname $output_objdir'\n\t    fi\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)=\"$_LT_TAGVAR(archive_expsym_cmds, $1)\"'~$RM -r $output_objdir/$realname.d'\n          fi\n        fi\n        ;;\n\n      beos*)\n\tif $LD --help 2>&1 | $GREP ': supported targets:.* elf' > /dev/null; then\n\t  _LT_TAGVAR(allow_undefined_flag, $1)=unsupported\n\t  # Joseph Beckenbach <jrb3@best.com> says some releases of gcc\n\t  # support --undefined.  This deserves some investigation.  FIXME\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -nostart $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n\telse\n\t  _LT_TAGVAR(ld_shlibs, $1)=no\n\tfi\n\t;;\n\n      chorus*)\n        case $cc_basename in\n          *)\n\t  # FIXME: insert proper C++ library support\n\t  _LT_TAGVAR(ld_shlibs, $1)=no\n\t  ;;\n        esac\n        ;;\n\n      cygwin* | mingw* | pw32* | cegcc*)\n\tcase $GXX,$cc_basename in\n\t,cl* | no,cl*)\n\t  # Native MSVC\n\t  # hardcode_libdir_flag_spec is actually meaningless, as there is\n\t  # no search path for DLLs.\n\t  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)=' '\n\t  _LT_TAGVAR(allow_undefined_flag, $1)=unsupported\n\t  _LT_TAGVAR(always_export_symbols, $1)=yes\n\t  _LT_TAGVAR(file_list_spec, $1)='@'\n\t  # Tell ltmain to make .lib files, not .a files.\n\t  libext=lib\n\t  # Tell ltmain to make .dll files, not .so files.\n\t  shrext_cmds=.dll\n\t  # FIXME: Setting linknames here is a bad hack.\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -o $output_objdir/$soname $libobjs $compiler_flags $deplibs -Wl,-DLL,-IMPLIB:\"$tool_output_objdir$libname.dll.lib\"~linknames='\n\t  _LT_TAGVAR(archive_expsym_cmds, $1)='if _LT_DLL_DEF_P([$export_symbols]); then\n              cp \"$export_symbols\" \"$output_objdir/$soname.def\";\n              echo \"$tool_output_objdir$soname.def\" > \"$output_objdir/$soname.exp\";\n            else\n              $SED -e '\\''s/^/-link -EXPORT:/'\\'' < $export_symbols > $output_objdir/$soname.exp;\n            fi~\n            $CC -o $tool_output_objdir$soname $libobjs $compiler_flags $deplibs \"@$tool_output_objdir$soname.exp\" -Wl,-DLL,-IMPLIB:\"$tool_output_objdir$libname.dll.lib\"~\n            linknames='\n\t  # The linker will not automatically build a static lib if we build a DLL.\n\t  # _LT_TAGVAR(old_archive_from_new_cmds, $1)='true'\n\t  _LT_TAGVAR(enable_shared_with_static_runtimes, $1)=yes\n\t  # Don't use ranlib\n\t  _LT_TAGVAR(old_postinstall_cmds, $1)='chmod 644 $oldlib'\n\t  _LT_TAGVAR(postlink_cmds, $1)='lt_outputfile=\"@OUTPUT@\"~\n            lt_tool_outputfile=\"@TOOL_OUTPUT@\"~\n            case $lt_outputfile in\n              *.exe|*.EXE) ;;\n              *)\n                lt_outputfile=$lt_outputfile.exe\n                lt_tool_outputfile=$lt_tool_outputfile.exe\n                ;;\n            esac~\n            func_to_tool_file \"$lt_outputfile\"~\n            if test : != \"$MANIFEST_TOOL\" && test -f \"$lt_outputfile.manifest\"; then\n              $MANIFEST_TOOL -manifest \"$lt_tool_outputfile.manifest\" -outputresource:\"$lt_tool_outputfile\" || exit 1;\n              $RM \"$lt_outputfile.manifest\";\n            fi'\n\t  ;;\n\t*)\n\t  # g++\n\t  # _LT_TAGVAR(hardcode_libdir_flag_spec, $1) is actually meaningless,\n\t  # as there is no search path for DLLs.\n\t  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n\t  _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl--export-all-symbols'\n\t  _LT_TAGVAR(allow_undefined_flag, $1)=unsupported\n\t  _LT_TAGVAR(always_export_symbols, $1)=no\n\t  _LT_TAGVAR(enable_shared_with_static_runtimes, $1)=yes\n\n\t  if $LD --help 2>&1 | $GREP 'auto-import' > /dev/null; then\n\t    _LT_TAGVAR(archive_cmds, $1)='$CC -shared -nostdlib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags -o $output_objdir/$soname $wl--enable-auto-image-base -Xlinker --out-implib -Xlinker $lib'\n\t    # If the export-symbols file already is a .def file, use it as\n\t    # is; otherwise, prepend EXPORTS...\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)='if _LT_DLL_DEF_P([$export_symbols]); then\n              cp $export_symbols $output_objdir/$soname.def;\n            else\n              echo EXPORTS > $output_objdir/$soname.def;\n              cat $export_symbols >> $output_objdir/$soname.def;\n            fi~\n            $CC -shared -nostdlib $output_objdir/$soname.def $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags -o $output_objdir/$soname $wl--enable-auto-image-base -Xlinker --out-implib -Xlinker $lib'\n\t  else\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t  fi\n\t  ;;\n\tesac\n\t;;\n      darwin* | rhapsody*)\n        _LT_DARWIN_LINKER_FEATURES($1)\n\t;;\n\n      os2*)\n\t_LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n\t_LT_TAGVAR(hardcode_minus_L, $1)=yes\n\t_LT_TAGVAR(allow_undefined_flag, $1)=unsupported\n\tshrext_cmds=.dll\n\t_LT_TAGVAR(archive_cmds, $1)='$ECHO \"LIBRARY ${soname%$shared_ext} INITINSTANCE TERMINSTANCE\" > $output_objdir/$libname.def~\n\t  $ECHO \"DESCRIPTION \\\"$libname\\\"\" >> $output_objdir/$libname.def~\n\t  $ECHO \"DATA MULTIPLE NONSHARED\" >> $output_objdir/$libname.def~\n\t  $ECHO EXPORTS >> $output_objdir/$libname.def~\n\t  emxexp $libobjs | $SED /\"_DLL_InitTerm\"/d >> $output_objdir/$libname.def~\n\t  $CC -Zdll -Zcrtdll -o $output_objdir/$soname $libobjs $deplibs $compiler_flags $output_objdir/$libname.def~\n\t  emximp -o $lib $output_objdir/$libname.def'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='$ECHO \"LIBRARY ${soname%$shared_ext} INITINSTANCE TERMINSTANCE\" > $output_objdir/$libname.def~\n\t  $ECHO \"DESCRIPTION \\\"$libname\\\"\" >> $output_objdir/$libname.def~\n\t  $ECHO \"DATA MULTIPLE NONSHARED\" >> $output_objdir/$libname.def~\n\t  $ECHO EXPORTS >> $output_objdir/$libname.def~\n\t  prefix_cmds=\"$SED\"~\n\t  if test EXPORTS = \"`$SED 1q $export_symbols`\"; then\n\t    prefix_cmds=\"$prefix_cmds -e 1d\";\n\t  fi~\n\t  prefix_cmds=\"$prefix_cmds -e \\\"s/^\\(.*\\)$/_\\1/g\\\"\"~\n\t  cat $export_symbols | $prefix_cmds >> $output_objdir/$libname.def~\n\t  $CC -Zdll -Zcrtdll -o $output_objdir/$soname $libobjs $deplibs $compiler_flags $output_objdir/$libname.def~\n\t  emximp -o $lib $output_objdir/$libname.def'\n\t_LT_TAGVAR(old_archive_From_new_cmds, $1)='emximp -o $output_objdir/${libname}_dll.a $output_objdir/$libname.def'\n\t_LT_TAGVAR(enable_shared_with_static_runtimes, $1)=yes\n\t;;\n\n      dgux*)\n        case $cc_basename in\n          ec++*)\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n          ghcx*)\n\t    # Green Hills C++ Compiler\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n          *)\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n        esac\n        ;;\n\n      freebsd2.*)\n        # C++ shared libraries reported to be fairly broken before\n\t# switch to ELF\n        _LT_TAGVAR(ld_shlibs, $1)=no\n        ;;\n\n      freebsd-elf*)\n        _LT_TAGVAR(archive_cmds_need_lc, $1)=no\n        ;;\n\n      freebsd* | dragonfly*)\n        # FreeBSD 3 and later use GNU C++ and GNU ld with standard ELF\n        # conventions\n        _LT_TAGVAR(ld_shlibs, $1)=yes\n        ;;\n\n      haiku*)\n        _LT_TAGVAR(archive_cmds, $1)='$CC -shared $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n        _LT_TAGVAR(link_all_deplibs, $1)=yes\n        ;;\n\n      hpux9*)\n        _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl+b $wl$libdir'\n        _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n        _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-E'\n        _LT_TAGVAR(hardcode_direct, $1)=yes\n        _LT_TAGVAR(hardcode_minus_L, $1)=yes # Not in the search PATH,\n\t\t\t\t             # but as the default\n\t\t\t\t             # location of the library.\n\n        case $cc_basename in\n          CC*)\n            # FIXME: insert proper C++ library support\n            _LT_TAGVAR(ld_shlibs, $1)=no\n            ;;\n          aCC*)\n            _LT_TAGVAR(archive_cmds, $1)='$RM $output_objdir/$soname~$CC -b $wl+b $wl$install_libdir -o $output_objdir/$soname $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags~test \"x$output_objdir/$soname\" = \"x$lib\" || mv $output_objdir/$soname $lib'\n            # Commands to make compiler produce verbose output that lists\n            # what \"hidden\" libraries, object files and flags are used when\n            # linking a shared library.\n            #\n            # There doesn't appear to be a way to prevent this compiler from\n            # explicitly linking system object files so we need to strip them\n            # from the output so that they don't get included in the library\n            # dependencies.\n            output_verbose_link_cmd='templist=`($CC -b $CFLAGS -v conftest.$objext 2>&1) | $EGREP \"\\-L\"`; list= ; for z in $templist; do case $z in conftest.$objext) list=\"$list $z\";; *.$objext);; *) list=\"$list $z\";;esac; done; func_echo_all \"$list\"'\n            ;;\n          *)\n            if test yes = \"$GXX\"; then\n              _LT_TAGVAR(archive_cmds, $1)='$RM $output_objdir/$soname~$CC -shared -nostdlib $pic_flag $wl+b $wl$install_libdir -o $output_objdir/$soname $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags~test \"x$output_objdir/$soname\" = \"x$lib\" || mv $output_objdir/$soname $lib'\n            else\n              # FIXME: insert proper C++ library support\n              _LT_TAGVAR(ld_shlibs, $1)=no\n            fi\n            ;;\n        esac\n        ;;\n\n      hpux10*|hpux11*)\n        if test no = \"$with_gnu_ld\"; then\n\t  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl+b $wl$libdir'\n\t  _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n\n          case $host_cpu in\n            hppa*64*|ia64*)\n              ;;\n            *)\n\t      _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-E'\n              ;;\n          esac\n        fi\n        case $host_cpu in\n          hppa*64*|ia64*)\n            _LT_TAGVAR(hardcode_direct, $1)=no\n            _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n            ;;\n          *)\n            _LT_TAGVAR(hardcode_direct, $1)=yes\n            _LT_TAGVAR(hardcode_direct_absolute, $1)=yes\n            _LT_TAGVAR(hardcode_minus_L, $1)=yes # Not in the search PATH,\n\t\t\t\t\t         # but as the default\n\t\t\t\t\t         # location of the library.\n            ;;\n        esac\n\n        case $cc_basename in\n          CC*)\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n          aCC*)\n\t    case $host_cpu in\n\t      hppa*64*)\n\t        _LT_TAGVAR(archive_cmds, $1)='$CC -b $wl+h $wl$soname -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags'\n\t        ;;\n\t      ia64*)\n\t        _LT_TAGVAR(archive_cmds, $1)='$CC -b $wl+h $wl$soname $wl+nodefaultrpath -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags'\n\t        ;;\n\t      *)\n\t        _LT_TAGVAR(archive_cmds, $1)='$CC -b $wl+h $wl$soname $wl+b $wl$install_libdir -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags'\n\t        ;;\n\t    esac\n\t    # Commands to make compiler produce verbose output that lists\n\t    # what \"hidden\" libraries, object files and flags are used when\n\t    # linking a shared library.\n\t    #\n\t    # There doesn't appear to be a way to prevent this compiler from\n\t    # explicitly linking system object files so we need to strip them\n\t    # from the output so that they don't get included in the library\n\t    # dependencies.\n\t    output_verbose_link_cmd='templist=`($CC -b $CFLAGS -v conftest.$objext 2>&1) | $GREP \"\\-L\"`; list= ; for z in $templist; do case $z in conftest.$objext) list=\"$list $z\";; *.$objext);; *) list=\"$list $z\";;esac; done; func_echo_all \"$list\"'\n\t    ;;\n          *)\n\t    if test yes = \"$GXX\"; then\n\t      if test no = \"$with_gnu_ld\"; then\n\t        case $host_cpu in\n\t          hppa*64*)\n\t            _LT_TAGVAR(archive_cmds, $1)='$CC -shared -nostdlib -fPIC $wl+h $wl$soname -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags'\n\t            ;;\n\t          ia64*)\n\t            _LT_TAGVAR(archive_cmds, $1)='$CC -shared -nostdlib $pic_flag $wl+h $wl$soname $wl+nodefaultrpath -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags'\n\t            ;;\n\t          *)\n\t            _LT_TAGVAR(archive_cmds, $1)='$CC -shared -nostdlib $pic_flag $wl+h $wl$soname $wl+b $wl$install_libdir -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags'\n\t            ;;\n\t        esac\n\t      fi\n\t    else\n\t      # FIXME: insert proper C++ library support\n\t      _LT_TAGVAR(ld_shlibs, $1)=no\n\t    fi\n\t    ;;\n        esac\n        ;;\n\n      interix[[3-9]]*)\n\t_LT_TAGVAR(hardcode_direct, $1)=no\n\t_LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n\t_LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath,$libdir'\n\t_LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-E'\n\t# Hack: On Interix 3.x, we cannot compile PIC because of a broken gcc.\n\t# Instead, shared libraries are loaded at an image base (0x10000000 by\n\t# default) and relocated if they conflict, which is a slow very memory\n\t# consuming and fragmenting process.  To avoid this, we pick a random,\n\t# 256 KiB-aligned image base between 0x50000000 and 0x6FFC0000 at link\n\t# time.  Moving up from 0x10000000 also allows more sbrk(2) space.\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-h,$soname $wl--image-base,`expr ${RANDOM-$$} % 4096 / 2 \\* 262144 + 1342177280` -o $lib'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='sed \"s|^|_|\" $export_symbols >$output_objdir/$soname.expsym~$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-h,$soname $wl--retain-symbols-file,$output_objdir/$soname.expsym $wl--image-base,`expr ${RANDOM-$$} % 4096 / 2 \\* 262144 + 1342177280` -o $lib'\n\t;;\n      irix5* | irix6*)\n        case $cc_basename in\n          CC*)\n\t    # SGI C++\n\t    _LT_TAGVAR(archive_cmds, $1)='$CC -shared -all -multigot $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags -soname $soname `test -n \"$verstring\" && func_echo_all \"-set_version $verstring\"` -update_registry $output_objdir/so_locations -o $lib'\n\n\t    # Archives containing C++ object files must be created using\n\t    # \"CC -ar\", where \"CC\" is the IRIX C++ compiler.  This is\n\t    # necessary to make sure instantiated templates are included\n\t    # in the archive.\n\t    _LT_TAGVAR(old_archive_cmds, $1)='$CC -ar -WR,-u -o $oldlib $oldobjs'\n\t    ;;\n          *)\n\t    if test yes = \"$GXX\"; then\n\t      if test no = \"$with_gnu_ld\"; then\n\t        _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag -nostdlib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname `test -n \"$verstring\" && func_echo_all \"$wl-set_version $wl$verstring\"` $wl-update_registry $wl$output_objdir/so_locations -o $lib'\n\t      else\n\t        _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag -nostdlib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname `test -n \"$verstring\" && func_echo_all \"$wl-set_version $wl$verstring\"` -o $lib'\n\t      fi\n\t    fi\n\t    _LT_TAGVAR(link_all_deplibs, $1)=yes\n\t    ;;\n        esac\n        _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n        _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n        _LT_TAGVAR(inherit_rpath, $1)=yes\n        ;;\n\n      linux* | k*bsd*-gnu | kopensolaris*-gnu | gnu*)\n        case $cc_basename in\n          KCC*)\n\t    # Kuck and Associates, Inc. (KAI) C++ Compiler\n\n\t    # KCC will only create a shared library if the output file\n\t    # ends with \".so\" (or \".sl\" for HP-UX), so rename the library\n\t    # to its proper name (with version) after linking.\n\t    _LT_TAGVAR(archive_cmds, $1)='tempext=`echo $shared_ext | $SED -e '\\''s/\\([[^()0-9A-Za-z{}]]\\)/\\\\\\\\\\1/g'\\''`; templib=`echo $lib | $SED -e \"s/\\$tempext\\..*/.so/\"`; $CC $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags --soname $soname -o \\$templib; mv \\$templib $lib'\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)='tempext=`echo $shared_ext | $SED -e '\\''s/\\([[^()0-9A-Za-z{}]]\\)/\\\\\\\\\\1/g'\\''`; templib=`echo $lib | $SED -e \"s/\\$tempext\\..*/.so/\"`; $CC $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags --soname $soname -o \\$templib $wl-retain-symbols-file,$export_symbols; mv \\$templib $lib'\n\t    # Commands to make compiler produce verbose output that lists\n\t    # what \"hidden\" libraries, object files and flags are used when\n\t    # linking a shared library.\n\t    #\n\t    # There doesn't appear to be a way to prevent this compiler from\n\t    # explicitly linking system object files so we need to strip them\n\t    # from the output so that they don't get included in the library\n\t    # dependencies.\n\t    output_verbose_link_cmd='templist=`$CC $CFLAGS -v conftest.$objext -o libconftest$shared_ext 2>&1 | $GREP \"ld\"`; rm -f libconftest$shared_ext; list= ; for z in $templist; do case $z in conftest.$objext) list=\"$list $z\";; *.$objext);; *) list=\"$list $z\";;esac; done; func_echo_all \"$list\"'\n\n\t    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath,$libdir'\n\t    _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl--export-dynamic'\n\n\t    # Archives containing C++ object files must be created using\n\t    # \"CC -Bstatic\", where \"CC\" is the KAI C++ compiler.\n\t    _LT_TAGVAR(old_archive_cmds, $1)='$CC -Bstatic -o $oldlib $oldobjs'\n\t    ;;\n\t  icpc* | ecpc* )\n\t    # Intel C++\n\t    with_gnu_ld=yes\n\t    # version 8.0 and above of icpc choke on multiply defined symbols\n\t    # if we add $predep_objects and $postdep_objects, however 7.1 and\n\t    # earlier do not add the objects themselves.\n\t    case `$CC -V 2>&1` in\n\t      *\"Version 7.\"*)\n\t        _LT_TAGVAR(archive_cmds, $1)='$CC -shared $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname -o $lib'\n\t\t_LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname $wl-retain-symbols-file $wl$export_symbols -o $lib'\n\t\t;;\n\t      *)  # Version 8.0 or newer\n\t        tmp_idyn=\n\t        case $host_cpu in\n\t\t  ia64*) tmp_idyn=' -i_dynamic';;\n\t\tesac\n\t        _LT_TAGVAR(archive_cmds, $1)='$CC -shared'\"$tmp_idyn\"' $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n\t\t_LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared'\"$tmp_idyn\"' $libobjs $deplibs $compiler_flags $wl-soname $wl$soname $wl-retain-symbols-file $wl$export_symbols -o $lib'\n\t\t;;\n\t    esac\n\t    _LT_TAGVAR(archive_cmds_need_lc, $1)=no\n\t    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath,$libdir'\n\t    _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl--export-dynamic'\n\t    _LT_TAGVAR(whole_archive_flag_spec, $1)='$wl--whole-archive$convenience $wl--no-whole-archive'\n\t    ;;\n          pgCC* | pgcpp*)\n            # Portland Group C++ compiler\n\t    case `$CC -V` in\n\t    *pgCC\\ [[1-5]].* | *pgcpp\\ [[1-5]].*)\n\t      _LT_TAGVAR(prelink_cmds, $1)='tpldir=Template.dir~\n               rm -rf $tpldir~\n               $CC --prelink_objects --instantiation_dir $tpldir $objs $libobjs $compile_deplibs~\n               compile_command=\"$compile_command `find $tpldir -name \\*.o | sort | $NL2SP`\"'\n\t      _LT_TAGVAR(old_archive_cmds, $1)='tpldir=Template.dir~\n                rm -rf $tpldir~\n                $CC --prelink_objects --instantiation_dir $tpldir $oldobjs$old_deplibs~\n                $AR $AR_FLAGS $oldlib$oldobjs$old_deplibs `find $tpldir -name \\*.o | sort | $NL2SP`~\n                $RANLIB $oldlib'\n\t      _LT_TAGVAR(archive_cmds, $1)='tpldir=Template.dir~\n                rm -rf $tpldir~\n                $CC --prelink_objects --instantiation_dir $tpldir $predep_objects $libobjs $deplibs $convenience $postdep_objects~\n                $CC -shared $pic_flag $predep_objects $libobjs $deplibs `find $tpldir -name \\*.o | sort | $NL2SP` $postdep_objects $compiler_flags $wl-soname $wl$soname -o $lib'\n\t      _LT_TAGVAR(archive_expsym_cmds, $1)='tpldir=Template.dir~\n                rm -rf $tpldir~\n                $CC --prelink_objects --instantiation_dir $tpldir $predep_objects $libobjs $deplibs $convenience $postdep_objects~\n                $CC -shared $pic_flag $predep_objects $libobjs $deplibs `find $tpldir -name \\*.o | sort | $NL2SP` $postdep_objects $compiler_flags $wl-soname $wl$soname $wl-retain-symbols-file $wl$export_symbols -o $lib'\n\t      ;;\n\t    *) # Version 6 and above use weak symbols\n\t      _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname -o $lib'\n\t      _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $pic_flag $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname $wl-retain-symbols-file $wl$export_symbols -o $lib'\n\t      ;;\n\t    esac\n\n\t    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl--rpath $wl$libdir'\n\t    _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl--export-dynamic'\n\t    _LT_TAGVAR(whole_archive_flag_spec, $1)='$wl--whole-archive`for conv in $convenience\\\"\\\"; do test  -n \\\"$conv\\\" && new_convenience=\\\"$new_convenience,$conv\\\"; done; func_echo_all \\\"$new_convenience\\\"` $wl--no-whole-archive'\n            ;;\n\t  cxx*)\n\t    # Compaq C++\n\t    _LT_TAGVAR(archive_cmds, $1)='$CC -shared $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname -o $lib'\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname  -o $lib $wl-retain-symbols-file $wl$export_symbols'\n\n\t    runpath_var=LD_RUN_PATH\n\t    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-rpath $libdir'\n\t    _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n\n\t    # Commands to make compiler produce verbose output that lists\n\t    # what \"hidden\" libraries, object files and flags are used when\n\t    # linking a shared library.\n\t    #\n\t    # There doesn't appear to be a way to prevent this compiler from\n\t    # explicitly linking system object files so we need to strip them\n\t    # from the output so that they don't get included in the library\n\t    # dependencies.\n\t    output_verbose_link_cmd='templist=`$CC -shared $CFLAGS -v conftest.$objext 2>&1 | $GREP \"ld\"`; templist=`func_echo_all \"$templist\" | $SED \"s/\\(^.*ld.*\\)\\( .*ld .*$\\)/\\1/\"`; list= ; for z in $templist; do case $z in conftest.$objext) list=\"$list $z\";; *.$objext);; *) list=\"$list $z\";;esac; done; func_echo_all \"X$list\" | $Xsed'\n\t    ;;\n\t  xl* | mpixl* | bgxl*)\n\t    # IBM XL 8.0 on PPC, with GNU ld\n\t    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n\t    _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl--export-dynamic'\n\t    _LT_TAGVAR(archive_cmds, $1)='$CC -qmkshrobj $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n\t    if test yes = \"$supports_anon_versioning\"; then\n\t      _LT_TAGVAR(archive_expsym_cmds, $1)='echo \"{ global:\" > $output_objdir/$libname.ver~\n                cat $export_symbols | sed -e \"s/\\(.*\\)/\\1;/\" >> $output_objdir/$libname.ver~\n                echo \"local: *; };\" >> $output_objdir/$libname.ver~\n                $CC -qmkshrobj $libobjs $deplibs $compiler_flags $wl-soname $wl$soname $wl-version-script $wl$output_objdir/$libname.ver -o $lib'\n\t    fi\n\t    ;;\n\t  *)\n\t    case `$CC -V 2>&1 | sed 5q` in\n\t    *Sun\\ C*)\n\t      # Sun C++ 5.9\n\t      _LT_TAGVAR(no_undefined_flag, $1)=' -zdefs'\n\t      _LT_TAGVAR(archive_cmds, $1)='$CC -G$allow_undefined_flag -h$soname -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags'\n\t      _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -G$allow_undefined_flag -h$soname -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-retain-symbols-file $wl$export_symbols'\n\t      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-R$libdir'\n\t      _LT_TAGVAR(whole_archive_flag_spec, $1)='$wl--whole-archive`new_convenience=; for conv in $convenience\\\"\\\"; do test -z \\\"$conv\\\" || new_convenience=\\\"$new_convenience,$conv\\\"; done; func_echo_all \\\"$new_convenience\\\"` $wl--no-whole-archive'\n\t      _LT_TAGVAR(compiler_needs_object, $1)=yes\n\n\t      # Not sure whether something based on\n\t      # $CC $CFLAGS -v conftest.$objext -o libconftest$shared_ext 2>&1\n\t      # would be better.\n\t      output_verbose_link_cmd='func_echo_all'\n\n\t      # Archives containing C++ object files must be created using\n\t      # \"CC -xar\", where \"CC\" is the Sun C++ compiler.  This is\n\t      # necessary to make sure instantiated templates are included\n\t      # in the archive.\n\t      _LT_TAGVAR(old_archive_cmds, $1)='$CC -xar -o $oldlib $oldobjs'\n\t      ;;\n\t    esac\n\t    ;;\n\tesac\n\t;;\n\n      lynxos*)\n        # FIXME: insert proper C++ library support\n\t_LT_TAGVAR(ld_shlibs, $1)=no\n\t;;\n\n      m88k*)\n        # FIXME: insert proper C++ library support\n        _LT_TAGVAR(ld_shlibs, $1)=no\n\t;;\n\n      mvs*)\n        case $cc_basename in\n          cxx*)\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n\t  *)\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n\tesac\n\t;;\n\n      netbsd*)\n        if echo __ELF__ | $CC -E - | $GREP __ELF__ >/dev/null; then\n\t  _LT_TAGVAR(archive_cmds, $1)='$LD -Bshareable  -o $lib $predep_objects $libobjs $deplibs $postdep_objects $linker_flags'\n\t  wlarc=\n\t  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-R$libdir'\n\t  _LT_TAGVAR(hardcode_direct, $1)=yes\n\t  _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n\tfi\n\t# Workaround some broken pre-1.5 toolchains\n\toutput_verbose_link_cmd='$CC -shared $CFLAGS -v conftest.$objext 2>&1 | $GREP conftest.$objext | $SED -e \"s:-lgcc -lc -lgcc::\"'\n\t;;\n\n      *nto* | *qnx*)\n        _LT_TAGVAR(ld_shlibs, $1)=yes\n\t;;\n\n      openbsd* | bitrig*)\n\tif test -f /usr/libexec/ld.so; then\n\t  _LT_TAGVAR(hardcode_direct, $1)=yes\n\t  _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n\t  _LT_TAGVAR(hardcode_direct_absolute, $1)=yes\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags -o $lib'\n\t  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath,$libdir'\n\t  if test -z \"`echo __ELF__ | $CC -E - | grep __ELF__`\"; then\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $pic_flag $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-retain-symbols-file,$export_symbols -o $lib'\n\t    _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-E'\n\t    _LT_TAGVAR(whole_archive_flag_spec, $1)=$wlarc'--whole-archive$convenience '$wlarc'--no-whole-archive'\n\t  fi\n\t  output_verbose_link_cmd=func_echo_all\n\telse\n\t  _LT_TAGVAR(ld_shlibs, $1)=no\n\tfi\n\t;;\n\n      osf3* | osf4* | osf5*)\n        case $cc_basename in\n          KCC*)\n\t    # Kuck and Associates, Inc. (KAI) C++ Compiler\n\n\t    # KCC will only create a shared library if the output file\n\t    # ends with \".so\" (or \".sl\" for HP-UX), so rename the library\n\t    # to its proper name (with version) after linking.\n\t    _LT_TAGVAR(archive_cmds, $1)='tempext=`echo $shared_ext | $SED -e '\\''s/\\([[^()0-9A-Za-z{}]]\\)/\\\\\\\\\\1/g'\\''`; templib=`echo \"$lib\" | $SED -e \"s/\\$tempext\\..*/.so/\"`; $CC $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags --soname $soname -o \\$templib; mv \\$templib $lib'\n\n\t    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath,$libdir'\n\t    _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n\n\t    # Archives containing C++ object files must be created using\n\t    # the KAI C++ compiler.\n\t    case $host in\n\t      osf3*) _LT_TAGVAR(old_archive_cmds, $1)='$CC -Bstatic -o $oldlib $oldobjs' ;;\n\t      *) _LT_TAGVAR(old_archive_cmds, $1)='$CC -o $oldlib $oldobjs' ;;\n\t    esac\n\t    ;;\n          RCC*)\n\t    # Rational C++ 2.4.1\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n          cxx*)\n\t    case $host in\n\t      osf3*)\n\t        _LT_TAGVAR(allow_undefined_flag, $1)=' $wl-expect_unresolved $wl\\*'\n\t        _LT_TAGVAR(archive_cmds, $1)='$CC -shared$allow_undefined_flag $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $soname `test -n \"$verstring\" && func_echo_all \"$wl-set_version $verstring\"` -update_registry $output_objdir/so_locations -o $lib'\n\t        _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n\t\t;;\n\t      *)\n\t        _LT_TAGVAR(allow_undefined_flag, $1)=' -expect_unresolved \\*'\n\t        _LT_TAGVAR(archive_cmds, $1)='$CC -shared$allow_undefined_flag $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags -msym -soname $soname `test -n \"$verstring\" && func_echo_all \"-set_version $verstring\"` -update_registry $output_objdir/so_locations -o $lib'\n\t        _LT_TAGVAR(archive_expsym_cmds, $1)='for i in `cat $export_symbols`; do printf \"%s %s\\\\n\" -exported_symbol \"\\$i\" >> $lib.exp; done~\n                  echo \"-hidden\">> $lib.exp~\n                  $CC -shared$allow_undefined_flag $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags -msym -soname $soname $wl-input $wl$lib.exp  `test -n \"$verstring\" && $ECHO \"-set_version $verstring\"` -update_registry $output_objdir/so_locations -o $lib~\n                  $RM $lib.exp'\n\t        _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-rpath $libdir'\n\t\t;;\n\t    esac\n\n\t    _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n\n\t    # Commands to make compiler produce verbose output that lists\n\t    # what \"hidden\" libraries, object files and flags are used when\n\t    # linking a shared library.\n\t    #\n\t    # There doesn't appear to be a way to prevent this compiler from\n\t    # explicitly linking system object files so we need to strip them\n\t    # from the output so that they don't get included in the library\n\t    # dependencies.\n\t    output_verbose_link_cmd='templist=`$CC -shared $CFLAGS -v conftest.$objext 2>&1 | $GREP \"ld\" | $GREP -v \"ld:\"`; templist=`func_echo_all \"$templist\" | $SED \"s/\\(^.*ld.*\\)\\( .*ld.*$\\)/\\1/\"`; list= ; for z in $templist; do case $z in conftest.$objext) list=\"$list $z\";; *.$objext);; *) list=\"$list $z\";;esac; done; func_echo_all \"$list\"'\n\t    ;;\n\t  *)\n\t    if test yes,no = \"$GXX,$with_gnu_ld\"; then\n\t      _LT_TAGVAR(allow_undefined_flag, $1)=' $wl-expect_unresolved $wl\\*'\n\t      case $host in\n\t        osf3*)\n\t          _LT_TAGVAR(archive_cmds, $1)='$CC -shared -nostdlib $allow_undefined_flag $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname `test -n \"$verstring\" && func_echo_all \"$wl-set_version $wl$verstring\"` $wl-update_registry $wl$output_objdir/so_locations -o $lib'\n\t\t  ;;\n\t        *)\n\t          _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag -nostdlib $allow_undefined_flag $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-msym $wl-soname $wl$soname `test -n \"$verstring\" && func_echo_all \"$wl-set_version $wl$verstring\"` $wl-update_registry $wl$output_objdir/so_locations -o $lib'\n\t\t  ;;\n\t      esac\n\n\t      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n\t      _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n\n\t      # Commands to make compiler produce verbose output that lists\n\t      # what \"hidden\" libraries, object files and flags are used when\n\t      # linking a shared library.\n\t      output_verbose_link_cmd='$CC -shared $CFLAGS -v conftest.$objext 2>&1 | $GREP -v \"^Configured with:\" | $GREP \"\\-L\"'\n\n\t    else\n\t      # FIXME: insert proper C++ library support\n\t      _LT_TAGVAR(ld_shlibs, $1)=no\n\t    fi\n\t    ;;\n        esac\n        ;;\n\n      psos*)\n        # FIXME: insert proper C++ library support\n        _LT_TAGVAR(ld_shlibs, $1)=no\n        ;;\n\n      sunos4*)\n        case $cc_basename in\n          CC*)\n\t    # Sun C++ 4.x\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n          lcc*)\n\t    # Lucid\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n          *)\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n        esac\n        ;;\n\n      solaris*)\n        case $cc_basename in\n          CC* | sunCC*)\n\t    # Sun C++ 4.2, 5.x and Centerline C++\n            _LT_TAGVAR(archive_cmds_need_lc,$1)=yes\n\t    _LT_TAGVAR(no_undefined_flag, $1)=' -zdefs'\n\t    _LT_TAGVAR(archive_cmds, $1)='$CC -G$allow_undefined_flag -h$soname -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags'\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)='echo \"{ global:\" > $lib.exp~cat $export_symbols | $SED -e \"s/\\(.*\\)/\\1;/\" >> $lib.exp~echo \"local: *; };\" >> $lib.exp~\n              $CC -G$allow_undefined_flag $wl-M $wl$lib.exp -h$soname -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags~$RM $lib.exp'\n\n\t    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-R$libdir'\n\t    _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n\t    case $host_os in\n\t      solaris2.[[0-5]] | solaris2.[[0-5]].*) ;;\n\t      *)\n\t\t# The compiler driver will combine and reorder linker options,\n\t\t# but understands '-z linker_flag'.\n\t        # Supported since Solaris 2.6 (maybe 2.5.1?)\n\t\t_LT_TAGVAR(whole_archive_flag_spec, $1)='-z allextract$convenience -z defaultextract'\n\t        ;;\n\t    esac\n\t    _LT_TAGVAR(link_all_deplibs, $1)=yes\n\n\t    output_verbose_link_cmd='func_echo_all'\n\n\t    # Archives containing C++ object files must be created using\n\t    # \"CC -xar\", where \"CC\" is the Sun C++ compiler.  This is\n\t    # necessary to make sure instantiated templates are included\n\t    # in the archive.\n\t    _LT_TAGVAR(old_archive_cmds, $1)='$CC -xar -o $oldlib $oldobjs'\n\t    ;;\n          gcx*)\n\t    # Green Hills C++ Compiler\n\t    _LT_TAGVAR(archive_cmds, $1)='$CC -shared $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-h $wl$soname -o $lib'\n\n\t    # The C++ compiler must be used to create the archive.\n\t    _LT_TAGVAR(old_archive_cmds, $1)='$CC $LDFLAGS -archive -o $oldlib $oldobjs'\n\t    ;;\n          *)\n\t    # GNU C++ compiler with Solaris linker\n\t    if test yes,no = \"$GXX,$with_gnu_ld\"; then\n\t      _LT_TAGVAR(no_undefined_flag, $1)=' $wl-z ${wl}defs'\n\t      if $CC --version | $GREP -v '^2\\.7' > /dev/null; then\n\t        _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag -nostdlib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-h $wl$soname -o $lib'\n\t        _LT_TAGVAR(archive_expsym_cmds, $1)='echo \"{ global:\" > $lib.exp~cat $export_symbols | $SED -e \"s/\\(.*\\)/\\1;/\" >> $lib.exp~echo \"local: *; };\" >> $lib.exp~\n                  $CC -shared $pic_flag -nostdlib $wl-M $wl$lib.exp $wl-h $wl$soname -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags~$RM $lib.exp'\n\n\t        # Commands to make compiler produce verbose output that lists\n\t        # what \"hidden\" libraries, object files and flags are used when\n\t        # linking a shared library.\n\t        output_verbose_link_cmd='$CC -shared $CFLAGS -v conftest.$objext 2>&1 | $GREP -v \"^Configured with:\" | $GREP \"\\-L\"'\n\t      else\n\t        # g++ 2.7 appears to require '-G' NOT '-shared' on this\n\t        # platform.\n\t        _LT_TAGVAR(archive_cmds, $1)='$CC -G -nostdlib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-h $wl$soname -o $lib'\n\t        _LT_TAGVAR(archive_expsym_cmds, $1)='echo \"{ global:\" > $lib.exp~cat $export_symbols | $SED -e \"s/\\(.*\\)/\\1;/\" >> $lib.exp~echo \"local: *; };\" >> $lib.exp~\n                  $CC -G -nostdlib $wl-M $wl$lib.exp $wl-h $wl$soname -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags~$RM $lib.exp'\n\n\t        # Commands to make compiler produce verbose output that lists\n\t        # what \"hidden\" libraries, object files and flags are used when\n\t        # linking a shared library.\n\t        output_verbose_link_cmd='$CC -G $CFLAGS -v conftest.$objext 2>&1 | $GREP -v \"^Configured with:\" | $GREP \"\\-L\"'\n\t      fi\n\n\t      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-R $wl$libdir'\n\t      case $host_os in\n\t\tsolaris2.[[0-5]] | solaris2.[[0-5]].*) ;;\n\t\t*)\n\t\t  _LT_TAGVAR(whole_archive_flag_spec, $1)='$wl-z ${wl}allextract$convenience $wl-z ${wl}defaultextract'\n\t\t  ;;\n\t      esac\n\t    fi\n\t    ;;\n        esac\n        ;;\n\n    sysv4*uw2* | sysv5OpenUNIX* | sysv5UnixWare7.[[01]].[[10]]* | unixware7* | sco3.2v5.0.[[024]]*)\n      _LT_TAGVAR(no_undefined_flag, $1)='$wl-z,text'\n      _LT_TAGVAR(archive_cmds_need_lc, $1)=no\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      runpath_var='LD_RUN_PATH'\n\n      case $cc_basename in\n        CC*)\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -G $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t  _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -G $wl-Bexport:$export_symbols $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t  ;;\n\t*)\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -shared $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t  _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $wl-Bexport:$export_symbols $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t  ;;\n      esac\n      ;;\n\n      sysv5* | sco3.2v5* | sco5v6*)\n\t# Note: We CANNOT use -z defs as we might desire, because we do not\n\t# link with -lc, and that would cause any symbols used from libc to\n\t# always be unresolved, which means just about no library would\n\t# ever link correctly.  If we're not using GNU ld we use -z text\n\t# though, which does catch some bad symbols but isn't as heavy-handed\n\t# as -z defs.\n\t_LT_TAGVAR(no_undefined_flag, $1)='$wl-z,text'\n\t_LT_TAGVAR(allow_undefined_flag, $1)='$wl-z,nodefs'\n\t_LT_TAGVAR(archive_cmds_need_lc, $1)=no\n\t_LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n\t_LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-R,$libdir'\n\t_LT_TAGVAR(hardcode_libdir_separator, $1)=':'\n\t_LT_TAGVAR(link_all_deplibs, $1)=yes\n\t_LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-Bexport'\n\trunpath_var='LD_RUN_PATH'\n\n\tcase $cc_basename in\n          CC*)\n\t    _LT_TAGVAR(archive_cmds, $1)='$CC -G $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -G $wl-Bexport:$export_symbols $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t    _LT_TAGVAR(old_archive_cmds, $1)='$CC -Tprelink_objects $oldobjs~\n              '\"$_LT_TAGVAR(old_archive_cmds, $1)\"\n\t    _LT_TAGVAR(reload_cmds, $1)='$CC -Tprelink_objects $reload_objs~\n              '\"$_LT_TAGVAR(reload_cmds, $1)\"\n\t    ;;\n\t  *)\n\t    _LT_TAGVAR(archive_cmds, $1)='$CC -shared $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $wl-Bexport:$export_symbols $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t    ;;\n\tesac\n      ;;\n\n      tandem*)\n        case $cc_basename in\n          NCC*)\n\t    # NonStop-UX NCC 3.20\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n          *)\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n        esac\n        ;;\n\n      vxworks*)\n        # FIXME: insert proper C++ library support\n        _LT_TAGVAR(ld_shlibs, $1)=no\n        ;;\n\n      *)\n        # FIXME: insert proper C++ library support\n        _LT_TAGVAR(ld_shlibs, $1)=no\n        ;;\n    esac\n\n    AC_MSG_RESULT([$_LT_TAGVAR(ld_shlibs, $1)])\n    test no = \"$_LT_TAGVAR(ld_shlibs, $1)\" && can_build_shared=no\n\n    _LT_TAGVAR(GCC, $1)=$GXX\n    _LT_TAGVAR(LD, $1)=$LD\n\n    ## CAVEAT EMPTOR:\n    ## There is no encapsulation within the following macros, do not change\n    ## the running order or otherwise move them around unless you know exactly\n    ## what you are doing...\n    _LT_SYS_HIDDEN_LIBDEPS($1)\n    _LT_COMPILER_PIC($1)\n    _LT_COMPILER_C_O($1)\n    _LT_COMPILER_FILE_LOCKS($1)\n    _LT_LINKER_SHLIBS($1)\n    _LT_SYS_DYNAMIC_LINKER($1)\n    _LT_LINKER_HARDCODE_LIBPATH($1)\n\n    _LT_CONFIG($1)\n  fi # test -n \"$compiler\"\n\n  CC=$lt_save_CC\n  CFLAGS=$lt_save_CFLAGS\n  LDCXX=$LD\n  LD=$lt_save_LD\n  GCC=$lt_save_GCC\n  with_gnu_ld=$lt_save_with_gnu_ld\n  lt_cv_path_LDCXX=$lt_cv_path_LD\n  lt_cv_path_LD=$lt_save_path_LD\n  lt_cv_prog_gnu_ldcxx=$lt_cv_prog_gnu_ld\n  lt_cv_prog_gnu_ld=$lt_save_with_gnu_ld\nfi # test yes != \"$_lt_caught_CXX_error\"\n\nAC_LANG_POP\n])# _LT_LANG_CXX_CONFIG\n\n\n# _LT_FUNC_STRIPNAME_CNF\n# ----------------------\n# func_stripname_cnf prefix suffix name\n# strip PREFIX and SUFFIX off of NAME.\n# PREFIX and SUFFIX must not contain globbing or regex special\n# characters, hashes, percent signs, but SUFFIX may contain a leading\n# dot (in which case that matches only a dot).\n#\n# This function is identical to the (non-XSI) version of func_stripname,\n# except this one can be used by m4 code that may be executed by configure,\n# rather than the libtool script.\nm4_defun([_LT_FUNC_STRIPNAME_CNF],[dnl\nAC_REQUIRE([_LT_DECL_SED])\nAC_REQUIRE([_LT_PROG_ECHO_BACKSLASH])\nfunc_stripname_cnf ()\n{\n  case @S|@2 in\n  .*) func_stripname_result=`$ECHO \"@S|@3\" | $SED \"s%^@S|@1%%; s%\\\\\\\\@S|@2\\$%%\"`;;\n  *)  func_stripname_result=`$ECHO \"@S|@3\" | $SED \"s%^@S|@1%%; s%@S|@2\\$%%\"`;;\n  esac\n} # func_stripname_cnf\n])# _LT_FUNC_STRIPNAME_CNF\n\n\n# _LT_SYS_HIDDEN_LIBDEPS([TAGNAME])\n# ---------------------------------\n# Figure out \"hidden\" library dependencies from verbose\n# compiler output when linking a shared library.\n# Parse the compiler output and extract the necessary\n# objects, libraries and library flags.\nm4_defun([_LT_SYS_HIDDEN_LIBDEPS],\n[m4_require([_LT_FILEUTILS_DEFAULTS])dnl\nAC_REQUIRE([_LT_FUNC_STRIPNAME_CNF])dnl\n# Dependencies to place before and after the object being linked:\n_LT_TAGVAR(predep_objects, $1)=\n_LT_TAGVAR(postdep_objects, $1)=\n_LT_TAGVAR(predeps, $1)=\n_LT_TAGVAR(postdeps, $1)=\n_LT_TAGVAR(compiler_lib_search_path, $1)=\n\ndnl we can't use the lt_simple_compile_test_code here,\ndnl because it contains code intended for an executable,\ndnl not a library.  It's possible we should let each\ndnl tag define a new lt_????_link_test_code variable,\ndnl but it's only used here...\nm4_if([$1], [], [cat > conftest.$ac_ext <<_LT_EOF\nint a;\nvoid foo (void) { a = 0; }\n_LT_EOF\n], [$1], [CXX], [cat > conftest.$ac_ext <<_LT_EOF\nclass Foo\n{\npublic:\n  Foo (void) { a = 0; }\nprivate:\n  int a;\n};\n_LT_EOF\n], [$1], [F77], [cat > conftest.$ac_ext <<_LT_EOF\n      subroutine foo\n      implicit none\n      integer*4 a\n      a=0\n      return\n      end\n_LT_EOF\n], [$1], [FC], [cat > conftest.$ac_ext <<_LT_EOF\n      subroutine foo\n      implicit none\n      integer a\n      a=0\n      return\n      end\n_LT_EOF\n], [$1], [GCJ], [cat > conftest.$ac_ext <<_LT_EOF\npublic class foo {\n  private int a;\n  public void bar (void) {\n    a = 0;\n  }\n};\n_LT_EOF\n], [$1], [GO], [cat > conftest.$ac_ext <<_LT_EOF\npackage foo\nfunc foo() {\n}\n_LT_EOF\n])\n\n_lt_libdeps_save_CFLAGS=$CFLAGS\ncase \"$CC $CFLAGS \" in #(\n*\\ -flto*\\ *) CFLAGS=\"$CFLAGS -fno-lto\" ;;\n*\\ -fwhopr*\\ *) CFLAGS=\"$CFLAGS -fno-whopr\" ;;\n*\\ -fuse-linker-plugin*\\ *) CFLAGS=\"$CFLAGS -fno-use-linker-plugin\" ;;\nesac\n\ndnl Parse the compiler output and extract the necessary\ndnl objects, libraries and library flags.\nif AC_TRY_EVAL(ac_compile); then\n  # Parse the compiler output and extract the necessary\n  # objects, libraries and library flags.\n\n  # Sentinel used to keep track of whether or not we are before\n  # the conftest object file.\n  pre_test_object_deps_done=no\n\n  for p in `eval \"$output_verbose_link_cmd\"`; do\n    case $prev$p in\n\n    -L* | -R* | -l*)\n       # Some compilers place space between \"-{L,R}\" and the path.\n       # Remove the space.\n       if test x-L = \"$p\" ||\n          test x-R = \"$p\"; then\n\t prev=$p\n\t continue\n       fi\n\n       # Expand the sysroot to ease extracting the directories later.\n       if test -z \"$prev\"; then\n         case $p in\n         -L*) func_stripname_cnf '-L' '' \"$p\"; prev=-L; p=$func_stripname_result ;;\n         -R*) func_stripname_cnf '-R' '' \"$p\"; prev=-R; p=$func_stripname_result ;;\n         -l*) func_stripname_cnf '-l' '' \"$p\"; prev=-l; p=$func_stripname_result ;;\n         esac\n       fi\n       case $p in\n       =*) func_stripname_cnf '=' '' \"$p\"; p=$lt_sysroot$func_stripname_result ;;\n       esac\n       if test no = \"$pre_test_object_deps_done\"; then\n\t case $prev in\n\t -L | -R)\n\t   # Internal compiler library paths should come after those\n\t   # provided the user.  The postdeps already come after the\n\t   # user supplied libs so there is no need to process them.\n\t   if test -z \"$_LT_TAGVAR(compiler_lib_search_path, $1)\"; then\n\t     _LT_TAGVAR(compiler_lib_search_path, $1)=$prev$p\n\t   else\n\t     _LT_TAGVAR(compiler_lib_search_path, $1)=\"${_LT_TAGVAR(compiler_lib_search_path, $1)} $prev$p\"\n\t   fi\n\t   ;;\n\t # The \"-l\" case would never come before the object being\n\t # linked, so don't bother handling this case.\n\t esac\n       else\n\t if test -z \"$_LT_TAGVAR(postdeps, $1)\"; then\n\t   _LT_TAGVAR(postdeps, $1)=$prev$p\n\t else\n\t   _LT_TAGVAR(postdeps, $1)=\"${_LT_TAGVAR(postdeps, $1)} $prev$p\"\n\t fi\n       fi\n       prev=\n       ;;\n\n    *.lto.$objext) ;; # Ignore GCC LTO objects\n    *.$objext)\n       # This assumes that the test object file only shows up\n       # once in the compiler output.\n       if test \"$p\" = \"conftest.$objext\"; then\n\t pre_test_object_deps_done=yes\n\t continue\n       fi\n\n       if test no = \"$pre_test_object_deps_done\"; then\n\t if test -z \"$_LT_TAGVAR(predep_objects, $1)\"; then\n\t   _LT_TAGVAR(predep_objects, $1)=$p\n\t else\n\t   _LT_TAGVAR(predep_objects, $1)=\"$_LT_TAGVAR(predep_objects, $1) $p\"\n\t fi\n       else\n\t if test -z \"$_LT_TAGVAR(postdep_objects, $1)\"; then\n\t   _LT_TAGVAR(postdep_objects, $1)=$p\n\t else\n\t   _LT_TAGVAR(postdep_objects, $1)=\"$_LT_TAGVAR(postdep_objects, $1) $p\"\n\t fi\n       fi\n       ;;\n\n    *) ;; # Ignore the rest.\n\n    esac\n  done\n\n  # Clean up.\n  rm -f a.out a.exe\nelse\n  echo \"libtool.m4: error: problem compiling $1 test program\"\nfi\n\n$RM -f confest.$objext\nCFLAGS=$_lt_libdeps_save_CFLAGS\n\n# PORTME: override above test on systems where it is broken\nm4_if([$1], [CXX],\n[case $host_os in\ninterix[[3-9]]*)\n  # Interix 3.5 installs completely hosed .la files for C++, so rather than\n  # hack all around it, let's just trust \"g++\" to DTRT.\n  _LT_TAGVAR(predep_objects,$1)=\n  _LT_TAGVAR(postdep_objects,$1)=\n  _LT_TAGVAR(postdeps,$1)=\n  ;;\nesac\n])\n\ncase \" $_LT_TAGVAR(postdeps, $1) \" in\n*\" -lc \"*) _LT_TAGVAR(archive_cmds_need_lc, $1)=no ;;\nesac\n _LT_TAGVAR(compiler_lib_search_dirs, $1)=\nif test -n \"${_LT_TAGVAR(compiler_lib_search_path, $1)}\"; then\n _LT_TAGVAR(compiler_lib_search_dirs, $1)=`echo \" ${_LT_TAGVAR(compiler_lib_search_path, $1)}\" | $SED -e 's! -L! !g' -e 's!^ !!'`\nfi\n_LT_TAGDECL([], [compiler_lib_search_dirs], [1],\n    [The directories searched by this compiler when creating a shared library])\n_LT_TAGDECL([], [predep_objects], [1],\n    [Dependencies to place before and after the objects being linked to\n    create a shared library])\n_LT_TAGDECL([], [postdep_objects], [1])\n_LT_TAGDECL([], [predeps], [1])\n_LT_TAGDECL([], [postdeps], [1])\n_LT_TAGDECL([], [compiler_lib_search_path], [1],\n    [The library search path used internally by the compiler when linking\n    a shared library])\n])# _LT_SYS_HIDDEN_LIBDEPS\n\n\n# _LT_LANG_F77_CONFIG([TAG])\n# --------------------------\n# Ensure that the configuration variables for a Fortran 77 compiler are\n# suitably defined.  These variables are subsequently used by _LT_CONFIG\n# to write the compiler configuration to 'libtool'.\nm4_defun([_LT_LANG_F77_CONFIG],\n[AC_LANG_PUSH(Fortran 77)\nif test -z \"$F77\" || test no = \"$F77\"; then\n  _lt_disable_F77=yes\nfi\n\n_LT_TAGVAR(archive_cmds_need_lc, $1)=no\n_LT_TAGVAR(allow_undefined_flag, $1)=\n_LT_TAGVAR(always_export_symbols, $1)=no\n_LT_TAGVAR(archive_expsym_cmds, $1)=\n_LT_TAGVAR(export_dynamic_flag_spec, $1)=\n_LT_TAGVAR(hardcode_direct, $1)=no\n_LT_TAGVAR(hardcode_direct_absolute, $1)=no\n_LT_TAGVAR(hardcode_libdir_flag_spec, $1)=\n_LT_TAGVAR(hardcode_libdir_separator, $1)=\n_LT_TAGVAR(hardcode_minus_L, $1)=no\n_LT_TAGVAR(hardcode_automatic, $1)=no\n_LT_TAGVAR(inherit_rpath, $1)=no\n_LT_TAGVAR(module_cmds, $1)=\n_LT_TAGVAR(module_expsym_cmds, $1)=\n_LT_TAGVAR(link_all_deplibs, $1)=unknown\n_LT_TAGVAR(old_archive_cmds, $1)=$old_archive_cmds\n_LT_TAGVAR(reload_flag, $1)=$reload_flag\n_LT_TAGVAR(reload_cmds, $1)=$reload_cmds\n_LT_TAGVAR(no_undefined_flag, $1)=\n_LT_TAGVAR(whole_archive_flag_spec, $1)=\n_LT_TAGVAR(enable_shared_with_static_runtimes, $1)=no\n\n# Source file extension for f77 test sources.\nac_ext=f\n\n# Object file extension for compiled f77 test sources.\nobjext=o\n_LT_TAGVAR(objext, $1)=$objext\n\n# No sense in running all these tests if we already determined that\n# the F77 compiler isn't working.  Some variables (like enable_shared)\n# are currently assumed to apply to all compilers on this platform,\n# and will be corrupted by setting them based on a non-working compiler.\nif test yes != \"$_lt_disable_F77\"; then\n  # Code to be used in simple compile tests\n  lt_simple_compile_test_code=\"\\\n      subroutine t\n      return\n      end\n\"\n\n  # Code to be used in simple link tests\n  lt_simple_link_test_code=\"\\\n      program t\n      end\n\"\n\n  # ltmain only uses $CC for tagged configurations so make sure $CC is set.\n  _LT_TAG_COMPILER\n\n  # save warnings/boilerplate of simple test code\n  _LT_COMPILER_BOILERPLATE\n  _LT_LINKER_BOILERPLATE\n\n  # Allow CC to be a program name with arguments.\n  lt_save_CC=$CC\n  lt_save_GCC=$GCC\n  lt_save_CFLAGS=$CFLAGS\n  CC=${F77-\"f77\"}\n  CFLAGS=$FFLAGS\n  compiler=$CC\n  _LT_TAGVAR(compiler, $1)=$CC\n  _LT_CC_BASENAME([$compiler])\n  GCC=$G77\n  if test -n \"$compiler\"; then\n    AC_MSG_CHECKING([if libtool supports shared libraries])\n    AC_MSG_RESULT([$can_build_shared])\n\n    AC_MSG_CHECKING([whether to build shared libraries])\n    test no = \"$can_build_shared\" && enable_shared=no\n\n    # On AIX, shared libraries and static libraries use the same namespace, and\n    # are all built from PIC.\n    case $host_os in\n      aix3*)\n        test yes = \"$enable_shared\" && enable_static=no\n        if test -n \"$RANLIB\"; then\n          archive_cmds=\"$archive_cmds~\\$RANLIB \\$lib\"\n          postinstall_cmds='$RANLIB $lib'\n        fi\n        ;;\n      aix[[4-9]]*)\n\tif test ia64 != \"$host_cpu\"; then\n\t  case $enable_shared,$with_aix_soname,$aix_use_runtimelinking in\n\t  yes,aix,yes) ;;\t\t# shared object as lib.so file only\n\t  yes,svr4,*) ;;\t\t# shared object as lib.so archive member only\n\t  yes,*) enable_static=no ;;\t# shared object in lib.a archive as well\n\t  esac\n\tfi\n        ;;\n    esac\n    AC_MSG_RESULT([$enable_shared])\n\n    AC_MSG_CHECKING([whether to build static libraries])\n    # Make sure either enable_shared or enable_static is yes.\n    test yes = \"$enable_shared\" || enable_static=yes\n    AC_MSG_RESULT([$enable_static])\n\n    _LT_TAGVAR(GCC, $1)=$G77\n    _LT_TAGVAR(LD, $1)=$LD\n\n    ## CAVEAT EMPTOR:\n    ## There is no encapsulation within the following macros, do not change\n    ## the running order or otherwise move them around unless you know exactly\n    ## what you are doing...\n    _LT_COMPILER_PIC($1)\n    _LT_COMPILER_C_O($1)\n    _LT_COMPILER_FILE_LOCKS($1)\n    _LT_LINKER_SHLIBS($1)\n    _LT_SYS_DYNAMIC_LINKER($1)\n    _LT_LINKER_HARDCODE_LIBPATH($1)\n\n    _LT_CONFIG($1)\n  fi # test -n \"$compiler\"\n\n  GCC=$lt_save_GCC\n  CC=$lt_save_CC\n  CFLAGS=$lt_save_CFLAGS\nfi # test yes != \"$_lt_disable_F77\"\n\nAC_LANG_POP\n])# _LT_LANG_F77_CONFIG\n\n\n# _LT_LANG_FC_CONFIG([TAG])\n# -------------------------\n# Ensure that the configuration variables for a Fortran compiler are\n# suitably defined.  These variables are subsequently used by _LT_CONFIG\n# to write the compiler configuration to 'libtool'.\nm4_defun([_LT_LANG_FC_CONFIG],\n[AC_LANG_PUSH(Fortran)\n\nif test -z \"$FC\" || test no = \"$FC\"; then\n  _lt_disable_FC=yes\nfi\n\n_LT_TAGVAR(archive_cmds_need_lc, $1)=no\n_LT_TAGVAR(allow_undefined_flag, $1)=\n_LT_TAGVAR(always_export_symbols, $1)=no\n_LT_TAGVAR(archive_expsym_cmds, $1)=\n_LT_TAGVAR(export_dynamic_flag_spec, $1)=\n_LT_TAGVAR(hardcode_direct, $1)=no\n_LT_TAGVAR(hardcode_direct_absolute, $1)=no\n_LT_TAGVAR(hardcode_libdir_flag_spec, $1)=\n_LT_TAGVAR(hardcode_libdir_separator, $1)=\n_LT_TAGVAR(hardcode_minus_L, $1)=no\n_LT_TAGVAR(hardcode_automatic, $1)=no\n_LT_TAGVAR(inherit_rpath, $1)=no\n_LT_TAGVAR(module_cmds, $1)=\n_LT_TAGVAR(module_expsym_cmds, $1)=\n_LT_TAGVAR(link_all_deplibs, $1)=unknown\n_LT_TAGVAR(old_archive_cmds, $1)=$old_archive_cmds\n_LT_TAGVAR(reload_flag, $1)=$reload_flag\n_LT_TAGVAR(reload_cmds, $1)=$reload_cmds\n_LT_TAGVAR(no_undefined_flag, $1)=\n_LT_TAGVAR(whole_archive_flag_spec, $1)=\n_LT_TAGVAR(enable_shared_with_static_runtimes, $1)=no\n\n# Source file extension for fc test sources.\nac_ext=${ac_fc_srcext-f}\n\n# Object file extension for compiled fc test sources.\nobjext=o\n_LT_TAGVAR(objext, $1)=$objext\n\n# No sense in running all these tests if we already determined that\n# the FC compiler isn't working.  Some variables (like enable_shared)\n# are currently assumed to apply to all compilers on this platform,\n# and will be corrupted by setting them based on a non-working compiler.\nif test yes != \"$_lt_disable_FC\"; then\n  # Code to be used in simple compile tests\n  lt_simple_compile_test_code=\"\\\n      subroutine t\n      return\n      end\n\"\n\n  # Code to be used in simple link tests\n  lt_simple_link_test_code=\"\\\n      program t\n      end\n\"\n\n  # ltmain only uses $CC for tagged configurations so make sure $CC is set.\n  _LT_TAG_COMPILER\n\n  # save warnings/boilerplate of simple test code\n  _LT_COMPILER_BOILERPLATE\n  _LT_LINKER_BOILERPLATE\n\n  # Allow CC to be a program name with arguments.\n  lt_save_CC=$CC\n  lt_save_GCC=$GCC\n  lt_save_CFLAGS=$CFLAGS\n  CC=${FC-\"f95\"}\n  CFLAGS=$FCFLAGS\n  compiler=$CC\n  GCC=$ac_cv_fc_compiler_gnu\n\n  _LT_TAGVAR(compiler, $1)=$CC\n  _LT_CC_BASENAME([$compiler])\n\n  if test -n \"$compiler\"; then\n    AC_MSG_CHECKING([if libtool supports shared libraries])\n    AC_MSG_RESULT([$can_build_shared])\n\n    AC_MSG_CHECKING([whether to build shared libraries])\n    test no = \"$can_build_shared\" && enable_shared=no\n\n    # On AIX, shared libraries and static libraries use the same namespace, and\n    # are all built from PIC.\n    case $host_os in\n      aix3*)\n        test yes = \"$enable_shared\" && enable_static=no\n        if test -n \"$RANLIB\"; then\n          archive_cmds=\"$archive_cmds~\\$RANLIB \\$lib\"\n          postinstall_cmds='$RANLIB $lib'\n        fi\n        ;;\n      aix[[4-9]]*)\n\tif test ia64 != \"$host_cpu\"; then\n\t  case $enable_shared,$with_aix_soname,$aix_use_runtimelinking in\n\t  yes,aix,yes) ;;\t\t# shared object as lib.so file only\n\t  yes,svr4,*) ;;\t\t# shared object as lib.so archive member only\n\t  yes,*) enable_static=no ;;\t# shared object in lib.a archive as well\n\t  esac\n\tfi\n        ;;\n    esac\n    AC_MSG_RESULT([$enable_shared])\n\n    AC_MSG_CHECKING([whether to build static libraries])\n    # Make sure either enable_shared or enable_static is yes.\n    test yes = \"$enable_shared\" || enable_static=yes\n    AC_MSG_RESULT([$enable_static])\n\n    _LT_TAGVAR(GCC, $1)=$ac_cv_fc_compiler_gnu\n    _LT_TAGVAR(LD, $1)=$LD\n\n    ## CAVEAT EMPTOR:\n    ## There is no encapsulation within the following macros, do not change\n    ## the running order or otherwise move them around unless you know exactly\n    ## what you are doing...\n    _LT_SYS_HIDDEN_LIBDEPS($1)\n    _LT_COMPILER_PIC($1)\n    _LT_COMPILER_C_O($1)\n    _LT_COMPILER_FILE_LOCKS($1)\n    _LT_LINKER_SHLIBS($1)\n    _LT_SYS_DYNAMIC_LINKER($1)\n    _LT_LINKER_HARDCODE_LIBPATH($1)\n\n    _LT_CONFIG($1)\n  fi # test -n \"$compiler\"\n\n  GCC=$lt_save_GCC\n  CC=$lt_save_CC\n  CFLAGS=$lt_save_CFLAGS\nfi # test yes != \"$_lt_disable_FC\"\n\nAC_LANG_POP\n])# _LT_LANG_FC_CONFIG\n\n\n# _LT_LANG_GCJ_CONFIG([TAG])\n# --------------------------\n# Ensure that the configuration variables for the GNU Java Compiler compiler\n# are suitably defined.  These variables are subsequently used by _LT_CONFIG\n# to write the compiler configuration to 'libtool'.\nm4_defun([_LT_LANG_GCJ_CONFIG],\n[AC_REQUIRE([LT_PROG_GCJ])dnl\nAC_LANG_SAVE\n\n# Source file extension for Java test sources.\nac_ext=java\n\n# Object file extension for compiled Java test sources.\nobjext=o\n_LT_TAGVAR(objext, $1)=$objext\n\n# Code to be used in simple compile tests\nlt_simple_compile_test_code=\"class foo {}\"\n\n# Code to be used in simple link tests\nlt_simple_link_test_code='public class conftest { public static void main(String[[]] argv) {}; }'\n\n# ltmain only uses $CC for tagged configurations so make sure $CC is set.\n_LT_TAG_COMPILER\n\n# save warnings/boilerplate of simple test code\n_LT_COMPILER_BOILERPLATE\n_LT_LINKER_BOILERPLATE\n\n# Allow CC to be a program name with arguments.\nlt_save_CC=$CC\nlt_save_CFLAGS=$CFLAGS\nlt_save_GCC=$GCC\nGCC=yes\nCC=${GCJ-\"gcj\"}\nCFLAGS=$GCJFLAGS\ncompiler=$CC\n_LT_TAGVAR(compiler, $1)=$CC\n_LT_TAGVAR(LD, $1)=$LD\n_LT_CC_BASENAME([$compiler])\n\n# GCJ did not exist at the time GCC didn't implicitly link libc in.\n_LT_TAGVAR(archive_cmds_need_lc, $1)=no\n\n_LT_TAGVAR(old_archive_cmds, $1)=$old_archive_cmds\n_LT_TAGVAR(reload_flag, $1)=$reload_flag\n_LT_TAGVAR(reload_cmds, $1)=$reload_cmds\n\n## CAVEAT EMPTOR:\n## There is no encapsulation within the following macros, do not change\n## the running order or otherwise move them around unless you know exactly\n## what you are doing...\nif test -n \"$compiler\"; then\n  _LT_COMPILER_NO_RTTI($1)\n  _LT_COMPILER_PIC($1)\n  _LT_COMPILER_C_O($1)\n  _LT_COMPILER_FILE_LOCKS($1)\n  _LT_LINKER_SHLIBS($1)\n  _LT_LINKER_HARDCODE_LIBPATH($1)\n\n  _LT_CONFIG($1)\nfi\n\nAC_LANG_RESTORE\n\nGCC=$lt_save_GCC\nCC=$lt_save_CC\nCFLAGS=$lt_save_CFLAGS\n])# _LT_LANG_GCJ_CONFIG\n\n\n# _LT_LANG_GO_CONFIG([TAG])\n# --------------------------\n# Ensure that the configuration variables for the GNU Go compiler\n# are suitably defined.  These variables are subsequently used by _LT_CONFIG\n# to write the compiler configuration to 'libtool'.\nm4_defun([_LT_LANG_GO_CONFIG],\n[AC_REQUIRE([LT_PROG_GO])dnl\nAC_LANG_SAVE\n\n# Source file extension for Go test sources.\nac_ext=go\n\n# Object file extension for compiled Go test sources.\nobjext=o\n_LT_TAGVAR(objext, $1)=$objext\n\n# Code to be used in simple compile tests\nlt_simple_compile_test_code=\"package main; func main() { }\"\n\n# Code to be used in simple link tests\nlt_simple_link_test_code='package main; func main() { }'\n\n# ltmain only uses $CC for tagged configurations so make sure $CC is set.\n_LT_TAG_COMPILER\n\n# save warnings/boilerplate of simple test code\n_LT_COMPILER_BOILERPLATE\n_LT_LINKER_BOILERPLATE\n\n# Allow CC to be a program name with arguments.\nlt_save_CC=$CC\nlt_save_CFLAGS=$CFLAGS\nlt_save_GCC=$GCC\nGCC=yes\nCC=${GOC-\"gccgo\"}\nCFLAGS=$GOFLAGS\ncompiler=$CC\n_LT_TAGVAR(compiler, $1)=$CC\n_LT_TAGVAR(LD, $1)=$LD\n_LT_CC_BASENAME([$compiler])\n\n# Go did not exist at the time GCC didn't implicitly link libc in.\n_LT_TAGVAR(archive_cmds_need_lc, $1)=no\n\n_LT_TAGVAR(old_archive_cmds, $1)=$old_archive_cmds\n_LT_TAGVAR(reload_flag, $1)=$reload_flag\n_LT_TAGVAR(reload_cmds, $1)=$reload_cmds\n\n## CAVEAT EMPTOR:\n## There is no encapsulation within the following macros, do not change\n## the running order or otherwise move them around unless you know exactly\n## what you are doing...\nif test -n \"$compiler\"; then\n  _LT_COMPILER_NO_RTTI($1)\n  _LT_COMPILER_PIC($1)\n  _LT_COMPILER_C_O($1)\n  _LT_COMPILER_FILE_LOCKS($1)\n  _LT_LINKER_SHLIBS($1)\n  _LT_LINKER_HARDCODE_LIBPATH($1)\n\n  _LT_CONFIG($1)\nfi\n\nAC_LANG_RESTORE\n\nGCC=$lt_save_GCC\nCC=$lt_save_CC\nCFLAGS=$lt_save_CFLAGS\n])# _LT_LANG_GO_CONFIG\n\n\n# _LT_LANG_RC_CONFIG([TAG])\n# -------------------------\n# Ensure that the configuration variables for the Windows resource compiler\n# are suitably defined.  These variables are subsequently used by _LT_CONFIG\n# to write the compiler configuration to 'libtool'.\nm4_defun([_LT_LANG_RC_CONFIG],\n[AC_REQUIRE([LT_PROG_RC])dnl\nAC_LANG_SAVE\n\n# Source file extension for RC test sources.\nac_ext=rc\n\n# Object file extension for compiled RC test sources.\nobjext=o\n_LT_TAGVAR(objext, $1)=$objext\n\n# Code to be used in simple compile tests\nlt_simple_compile_test_code='sample MENU { MENUITEM \"&Soup\", 100, CHECKED }'\n\n# Code to be used in simple link tests\nlt_simple_link_test_code=$lt_simple_compile_test_code\n\n# ltmain only uses $CC for tagged configurations so make sure $CC is set.\n_LT_TAG_COMPILER\n\n# save warnings/boilerplate of simple test code\n_LT_COMPILER_BOILERPLATE\n_LT_LINKER_BOILERPLATE\n\n# Allow CC to be a program name with arguments.\nlt_save_CC=$CC\nlt_save_CFLAGS=$CFLAGS\nlt_save_GCC=$GCC\nGCC=\nCC=${RC-\"windres\"}\nCFLAGS=\ncompiler=$CC\n_LT_TAGVAR(compiler, $1)=$CC\n_LT_CC_BASENAME([$compiler])\n_LT_TAGVAR(lt_cv_prog_compiler_c_o, $1)=yes\n\nif test -n \"$compiler\"; then\n  :\n  _LT_CONFIG($1)\nfi\n\nGCC=$lt_save_GCC\nAC_LANG_RESTORE\nCC=$lt_save_CC\nCFLAGS=$lt_save_CFLAGS\n])# _LT_LANG_RC_CONFIG\n\n\n# LT_PROG_GCJ\n# -----------\nAC_DEFUN([LT_PROG_GCJ],\n[m4_ifdef([AC_PROG_GCJ], [AC_PROG_GCJ],\n  [m4_ifdef([A][M_PROG_GCJ], [A][M_PROG_GCJ],\n    [AC_CHECK_TOOL(GCJ, gcj,)\n      test set = \"${GCJFLAGS+set}\" || GCJFLAGS=\"-g -O2\"\n      AC_SUBST(GCJFLAGS)])])[]dnl\n])\n\n# Old name:\nAU_ALIAS([LT_AC_PROG_GCJ], [LT_PROG_GCJ])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([LT_AC_PROG_GCJ], [])\n\n\n# LT_PROG_GO\n# ----------\nAC_DEFUN([LT_PROG_GO],\n[AC_CHECK_TOOL(GOC, gccgo,)\n])\n\n\n# LT_PROG_RC\n# ----------\nAC_DEFUN([LT_PROG_RC],\n[AC_CHECK_TOOL(RC, windres,)\n])\n\n# Old name:\nAU_ALIAS([LT_AC_PROG_RC], [LT_PROG_RC])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([LT_AC_PROG_RC], [])\n\n\n# _LT_DECL_EGREP\n# --------------\n# If we don't have a new enough Autoconf to choose the best grep\n# available, choose the one first in the user's PATH.\nm4_defun([_LT_DECL_EGREP],\n[AC_REQUIRE([AC_PROG_EGREP])dnl\nAC_REQUIRE([AC_PROG_FGREP])dnl\ntest -z \"$GREP\" && GREP=grep\n_LT_DECL([], [GREP], [1], [A grep program that handles long lines])\n_LT_DECL([], [EGREP], [1], [An ERE matcher])\n_LT_DECL([], [FGREP], [1], [A literal string matcher])\ndnl Non-bleeding-edge autoconf doesn't subst GREP, so do it here too\nAC_SUBST([GREP])\n])\n\n\n# _LT_DECL_OBJDUMP\n# --------------\n# If we don't have a new enough Autoconf to choose the best objdump\n# available, choose the one first in the user's PATH.\nm4_defun([_LT_DECL_OBJDUMP],\n[AC_CHECK_TOOL(OBJDUMP, objdump, false)\ntest -z \"$OBJDUMP\" && OBJDUMP=objdump\n_LT_DECL([], [OBJDUMP], [1], [An object symbol dumper])\nAC_SUBST([OBJDUMP])\n])\n\n# _LT_DECL_DLLTOOL\n# ----------------\n# Ensure DLLTOOL variable is set.\nm4_defun([_LT_DECL_DLLTOOL],\n[AC_CHECK_TOOL(DLLTOOL, dlltool, false)\ntest -z \"$DLLTOOL\" && DLLTOOL=dlltool\n_LT_DECL([], [DLLTOOL], [1], [DLL creation program])\nAC_SUBST([DLLTOOL])\n])\n\n# _LT_DECL_SED\n# ------------\n# Check for a fully-functional sed program, that truncates\n# as few characters as possible.  Prefer GNU sed if found.\nm4_defun([_LT_DECL_SED],\n[AC_PROG_SED\ntest -z \"$SED\" && SED=sed\nXsed=\"$SED -e 1s/^X//\"\n_LT_DECL([], [SED], [1], [A sed program that does not truncate output])\n_LT_DECL([], [Xsed], [\"\\$SED -e 1s/^X//\"],\n    [Sed that helps us avoid accidentally triggering echo(1) options like -n])\n])# _LT_DECL_SED\n\nm4_ifndef([AC_PROG_SED], [\n############################################################\n# NOTE: This macro has been submitted for inclusion into   #\n#  GNU Autoconf as AC_PROG_SED.  When it is available in   #\n#  a released version of Autoconf we should remove this    #\n#  macro and use it instead.                               #\n############################################################\n\nm4_defun([AC_PROG_SED],\n[AC_MSG_CHECKING([for a sed that does not truncate output])\nAC_CACHE_VAL(lt_cv_path_SED,\n[# Loop through the user's path and test for sed and gsed.\n# Then use that list of sed's as ones to test for truncation.\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  test -z \"$as_dir\" && as_dir=.\n  for lt_ac_prog in sed gsed; do\n    for ac_exec_ext in '' $ac_executable_extensions; do\n      if $as_executable_p \"$as_dir/$lt_ac_prog$ac_exec_ext\"; then\n        lt_ac_sed_list=\"$lt_ac_sed_list $as_dir/$lt_ac_prog$ac_exec_ext\"\n      fi\n    done\n  done\ndone\nIFS=$as_save_IFS\nlt_ac_max=0\nlt_ac_count=0\n# Add /usr/xpg4/bin/sed as it is typically found on Solaris\n# along with /bin/sed that truncates output.\nfor lt_ac_sed in $lt_ac_sed_list /usr/xpg4/bin/sed; do\n  test ! -f \"$lt_ac_sed\" && continue\n  cat /dev/null > conftest.in\n  lt_ac_count=0\n  echo $ECHO_N \"0123456789$ECHO_C\" >conftest.in\n  # Check for GNU sed and select it if it is found.\n  if \"$lt_ac_sed\" --version 2>&1 < /dev/null | grep 'GNU' > /dev/null; then\n    lt_cv_path_SED=$lt_ac_sed\n    break\n  fi\n  while true; do\n    cat conftest.in conftest.in >conftest.tmp\n    mv conftest.tmp conftest.in\n    cp conftest.in conftest.nl\n    echo >>conftest.nl\n    $lt_ac_sed -e 's/a$//' < conftest.nl >conftest.out || break\n    cmp -s conftest.out conftest.nl || break\n    # 10000 chars as input seems more than enough\n    test 10 -lt \"$lt_ac_count\" && break\n    lt_ac_count=`expr $lt_ac_count + 1`\n    if test \"$lt_ac_count\" -gt \"$lt_ac_max\"; then\n      lt_ac_max=$lt_ac_count\n      lt_cv_path_SED=$lt_ac_sed\n    fi\n  done\ndone\n])\nSED=$lt_cv_path_SED\nAC_SUBST([SED])\nAC_MSG_RESULT([$SED])\n])#AC_PROG_SED\n])#m4_ifndef\n\n# Old name:\nAU_ALIAS([LT_AC_PROG_SED], [AC_PROG_SED])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([LT_AC_PROG_SED], [])\n\n\n# _LT_CHECK_SHELL_FEATURES\n# ------------------------\n# Find out whether the shell is Bourne or XSI compatible,\n# or has some other useful features.\nm4_defun([_LT_CHECK_SHELL_FEATURES],\n[if ( (MAIL=60; unset MAIL) || exit) >/dev/null 2>&1; then\n  lt_unset=unset\nelse\n  lt_unset=false\nfi\n_LT_DECL([], [lt_unset], [0], [whether the shell understands \"unset\"])dnl\n\n# test EBCDIC or ASCII\ncase `echo X|tr X '\\101'` in\n A) # ASCII based system\n    # \\n is not interpreted correctly by Solaris 8 /usr/ucb/tr\n  lt_SP2NL='tr \\040 \\012'\n  lt_NL2SP='tr \\015\\012 \\040\\040'\n  ;;\n *) # EBCDIC based system\n  lt_SP2NL='tr \\100 \\n'\n  lt_NL2SP='tr \\r\\n \\100\\100'\n  ;;\nesac\n_LT_DECL([SP2NL], [lt_SP2NL], [1], [turn spaces into newlines])dnl\n_LT_DECL([NL2SP], [lt_NL2SP], [1], [turn newlines into spaces])dnl\n])# _LT_CHECK_SHELL_FEATURES\n\n\n# _LT_PATH_CONVERSION_FUNCTIONS\n# -----------------------------\n# Determine what file name conversion functions should be used by\n# func_to_host_file (and, implicitly, by func_to_host_path).  These are needed\n# for certain cross-compile configurations and native mingw.\nm4_defun([_LT_PATH_CONVERSION_FUNCTIONS],\n[AC_REQUIRE([AC_CANONICAL_HOST])dnl\nAC_REQUIRE([AC_CANONICAL_BUILD])dnl\nAC_MSG_CHECKING([how to convert $build file names to $host format])\nAC_CACHE_VAL(lt_cv_to_host_file_cmd,\n[case $host in\n  *-*-mingw* )\n    case $build in\n      *-*-mingw* ) # actually msys\n        lt_cv_to_host_file_cmd=func_convert_file_msys_to_w32\n        ;;\n      *-*-cygwin* )\n        lt_cv_to_host_file_cmd=func_convert_file_cygwin_to_w32\n        ;;\n      * ) # otherwise, assume *nix\n        lt_cv_to_host_file_cmd=func_convert_file_nix_to_w32\n        ;;\n    esac\n    ;;\n  *-*-cygwin* )\n    case $build in\n      *-*-mingw* ) # actually msys\n        lt_cv_to_host_file_cmd=func_convert_file_msys_to_cygwin\n        ;;\n      *-*-cygwin* )\n        lt_cv_to_host_file_cmd=func_convert_file_noop\n        ;;\n      * ) # otherwise, assume *nix\n        lt_cv_to_host_file_cmd=func_convert_file_nix_to_cygwin\n        ;;\n    esac\n    ;;\n  * ) # unhandled hosts (and \"normal\" native builds)\n    lt_cv_to_host_file_cmd=func_convert_file_noop\n    ;;\nesac\n])\nto_host_file_cmd=$lt_cv_to_host_file_cmd\nAC_MSG_RESULT([$lt_cv_to_host_file_cmd])\n_LT_DECL([to_host_file_cmd], [lt_cv_to_host_file_cmd],\n         [0], [convert $build file names to $host format])dnl\n\nAC_MSG_CHECKING([how to convert $build file names to toolchain format])\nAC_CACHE_VAL(lt_cv_to_tool_file_cmd,\n[#assume ordinary cross tools, or native build.\nlt_cv_to_tool_file_cmd=func_convert_file_noop\ncase $host in\n  *-*-mingw* )\n    case $build in\n      *-*-mingw* ) # actually msys\n        lt_cv_to_tool_file_cmd=func_convert_file_msys_to_w32\n        ;;\n    esac\n    ;;\nesac\n])\nto_tool_file_cmd=$lt_cv_to_tool_file_cmd\nAC_MSG_RESULT([$lt_cv_to_tool_file_cmd])\n_LT_DECL([to_tool_file_cmd], [lt_cv_to_tool_file_cmd],\n         [0], [convert $build files to toolchain format])dnl\n])# _LT_PATH_CONVERSION_FUNCTIONS\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/auxdir/ltoptions.m4": "# Helper functions for option handling.                    -*- Autoconf -*-\n#\n#   Copyright (C) 2004-2005, 2007-2009, 2011-2015 Free Software\n#   Foundation, Inc.\n#   Written by Gary V. Vaughan, 2004\n#\n# This file is free software; the Free Software Foundation gives\n# unlimited permission to copy and/or distribute it, with or without\n# modifications, as long as this notice is preserved.\n\n# serial 8 ltoptions.m4\n\n# This is to help aclocal find these macros, as it can't see m4_define.\nAC_DEFUN([LTOPTIONS_VERSION], [m4_if([1])])\n\n\n# _LT_MANGLE_OPTION(MACRO-NAME, OPTION-NAME)\n# ------------------------------------------\nm4_define([_LT_MANGLE_OPTION],\n[[_LT_OPTION_]m4_bpatsubst($1__$2, [[^a-zA-Z0-9_]], [_])])\n\n\n# _LT_SET_OPTION(MACRO-NAME, OPTION-NAME)\n# ---------------------------------------\n# Set option OPTION-NAME for macro MACRO-NAME, and if there is a\n# matching handler defined, dispatch to it.  Other OPTION-NAMEs are\n# saved as a flag.\nm4_define([_LT_SET_OPTION],\n[m4_define(_LT_MANGLE_OPTION([$1], [$2]))dnl\nm4_ifdef(_LT_MANGLE_DEFUN([$1], [$2]),\n        _LT_MANGLE_DEFUN([$1], [$2]),\n    [m4_warning([Unknown $1 option '$2'])])[]dnl\n])\n\n\n# _LT_IF_OPTION(MACRO-NAME, OPTION-NAME, IF-SET, [IF-NOT-SET])\n# ------------------------------------------------------------\n# Execute IF-SET if OPTION is set, IF-NOT-SET otherwise.\nm4_define([_LT_IF_OPTION],\n[m4_ifdef(_LT_MANGLE_OPTION([$1], [$2]), [$3], [$4])])\n\n\n# _LT_UNLESS_OPTIONS(MACRO-NAME, OPTION-LIST, IF-NOT-SET)\n# -------------------------------------------------------\n# Execute IF-NOT-SET unless all options in OPTION-LIST for MACRO-NAME\n# are set.\nm4_define([_LT_UNLESS_OPTIONS],\n[m4_foreach([_LT_Option], m4_split(m4_normalize([$2])),\n\t    [m4_ifdef(_LT_MANGLE_OPTION([$1], _LT_Option),\n\t\t      [m4_define([$0_found])])])[]dnl\nm4_ifdef([$0_found], [m4_undefine([$0_found])], [$3\n])[]dnl\n])\n\n\n# _LT_SET_OPTIONS(MACRO-NAME, OPTION-LIST)\n# ----------------------------------------\n# OPTION-LIST is a space-separated list of Libtool options associated\n# with MACRO-NAME.  If any OPTION has a matching handler declared with\n# LT_OPTION_DEFINE, dispatch to that macro; otherwise complain about\n# the unknown option and exit.\nm4_defun([_LT_SET_OPTIONS],\n[# Set options\nm4_foreach([_LT_Option], m4_split(m4_normalize([$2])),\n    [_LT_SET_OPTION([$1], _LT_Option)])\n\nm4_if([$1],[LT_INIT],[\n  dnl\n  dnl Simply set some default values (i.e off) if boolean options were not\n  dnl specified:\n  _LT_UNLESS_OPTIONS([LT_INIT], [dlopen], [enable_dlopen=no\n  ])\n  _LT_UNLESS_OPTIONS([LT_INIT], [win32-dll], [enable_win32_dll=no\n  ])\n  dnl\n  dnl If no reference was made to various pairs of opposing options, then\n  dnl we run the default mode handler for the pair.  For example, if neither\n  dnl 'shared' nor 'disable-shared' was passed, we enable building of shared\n  dnl archives by default:\n  _LT_UNLESS_OPTIONS([LT_INIT], [shared disable-shared], [_LT_ENABLE_SHARED])\n  _LT_UNLESS_OPTIONS([LT_INIT], [static disable-static], [_LT_ENABLE_STATIC])\n  _LT_UNLESS_OPTIONS([LT_INIT], [pic-only no-pic], [_LT_WITH_PIC])\n  _LT_UNLESS_OPTIONS([LT_INIT], [fast-install disable-fast-install],\n\t\t   [_LT_ENABLE_FAST_INSTALL])\n  _LT_UNLESS_OPTIONS([LT_INIT], [aix-soname=aix aix-soname=both aix-soname=svr4],\n\t\t   [_LT_WITH_AIX_SONAME([aix])])\n  ])\n])# _LT_SET_OPTIONS\n\n\n## --------------------------------- ##\n## Macros to handle LT_INIT options. ##\n## --------------------------------- ##\n\n# _LT_MANGLE_DEFUN(MACRO-NAME, OPTION-NAME)\n# -----------------------------------------\nm4_define([_LT_MANGLE_DEFUN],\n[[_LT_OPTION_DEFUN_]m4_bpatsubst(m4_toupper([$1__$2]), [[^A-Z0-9_]], [_])])\n\n\n# LT_OPTION_DEFINE(MACRO-NAME, OPTION-NAME, CODE)\n# -----------------------------------------------\nm4_define([LT_OPTION_DEFINE],\n[m4_define(_LT_MANGLE_DEFUN([$1], [$2]), [$3])[]dnl\n])# LT_OPTION_DEFINE\n\n\n# dlopen\n# ------\nLT_OPTION_DEFINE([LT_INIT], [dlopen], [enable_dlopen=yes\n])\n\nAU_DEFUN([AC_LIBTOOL_DLOPEN],\n[_LT_SET_OPTION([LT_INIT], [dlopen])\nAC_DIAGNOSE([obsolete],\n[$0: Remove this warning and the call to _LT_SET_OPTION when you\nput the 'dlopen' option into LT_INIT's first parameter.])\n])\n\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_LIBTOOL_DLOPEN], [])\n\n\n# win32-dll\n# ---------\n# Declare package support for building win32 dll's.\nLT_OPTION_DEFINE([LT_INIT], [win32-dll],\n[enable_win32_dll=yes\n\ncase $host in\n*-*-cygwin* | *-*-mingw* | *-*-pw32* | *-*-cegcc*)\n  AC_CHECK_TOOL(AS, as, false)\n  AC_CHECK_TOOL(DLLTOOL, dlltool, false)\n  AC_CHECK_TOOL(OBJDUMP, objdump, false)\n  ;;\nesac\n\ntest -z \"$AS\" && AS=as\n_LT_DECL([], [AS],      [1], [Assembler program])dnl\n\ntest -z \"$DLLTOOL\" && DLLTOOL=dlltool\n_LT_DECL([], [DLLTOOL], [1], [DLL creation program])dnl\n\ntest -z \"$OBJDUMP\" && OBJDUMP=objdump\n_LT_DECL([], [OBJDUMP], [1], [Object dumper program])dnl\n])# win32-dll\n\nAU_DEFUN([AC_LIBTOOL_WIN32_DLL],\n[AC_REQUIRE([AC_CANONICAL_HOST])dnl\n_LT_SET_OPTION([LT_INIT], [win32-dll])\nAC_DIAGNOSE([obsolete],\n[$0: Remove this warning and the call to _LT_SET_OPTION when you\nput the 'win32-dll' option into LT_INIT's first parameter.])\n])\n\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_LIBTOOL_WIN32_DLL], [])\n\n\n# _LT_ENABLE_SHARED([DEFAULT])\n# ----------------------------\n# implement the --enable-shared flag, and supports the 'shared' and\n# 'disable-shared' LT_INIT options.\n# DEFAULT is either 'yes' or 'no'.  If omitted, it defaults to 'yes'.\nm4_define([_LT_ENABLE_SHARED],\n[m4_define([_LT_ENABLE_SHARED_DEFAULT], [m4_if($1, no, no, yes)])dnl\nAC_ARG_ENABLE([shared],\n    [AS_HELP_STRING([--enable-shared@<:@=PKGS@:>@],\n\t[build shared libraries @<:@default=]_LT_ENABLE_SHARED_DEFAULT[@:>@])],\n    [p=${PACKAGE-default}\n    case $enableval in\n    yes) enable_shared=yes ;;\n    no) enable_shared=no ;;\n    *)\n      enable_shared=no\n      # Look at the argument we got.  We use all the common list separators.\n      lt_save_ifs=$IFS; IFS=$IFS$PATH_SEPARATOR,\n      for pkg in $enableval; do\n\tIFS=$lt_save_ifs\n\tif test \"X$pkg\" = \"X$p\"; then\n\t  enable_shared=yes\n\tfi\n      done\n      IFS=$lt_save_ifs\n      ;;\n    esac],\n    [enable_shared=]_LT_ENABLE_SHARED_DEFAULT)\n\n    _LT_DECL([build_libtool_libs], [enable_shared], [0],\n\t[Whether or not to build shared libraries])\n])# _LT_ENABLE_SHARED\n\nLT_OPTION_DEFINE([LT_INIT], [shared], [_LT_ENABLE_SHARED([yes])])\nLT_OPTION_DEFINE([LT_INIT], [disable-shared], [_LT_ENABLE_SHARED([no])])\n\n# Old names:\nAC_DEFUN([AC_ENABLE_SHARED],\n[_LT_SET_OPTION([LT_INIT], m4_if([$1], [no], [disable-])[shared])\n])\n\nAC_DEFUN([AC_DISABLE_SHARED],\n[_LT_SET_OPTION([LT_INIT], [disable-shared])\n])\n\nAU_DEFUN([AM_ENABLE_SHARED], [AC_ENABLE_SHARED($@)])\nAU_DEFUN([AM_DISABLE_SHARED], [AC_DISABLE_SHARED($@)])\n\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AM_ENABLE_SHARED], [])\ndnl AC_DEFUN([AM_DISABLE_SHARED], [])\n\n\n\n# _LT_ENABLE_STATIC([DEFAULT])\n# ----------------------------\n# implement the --enable-static flag, and support the 'static' and\n# 'disable-static' LT_INIT options.\n# DEFAULT is either 'yes' or 'no'.  If omitted, it defaults to 'yes'.\nm4_define([_LT_ENABLE_STATIC],\n[m4_define([_LT_ENABLE_STATIC_DEFAULT], [m4_if($1, no, no, yes)])dnl\nAC_ARG_ENABLE([static],\n    [AS_HELP_STRING([--enable-static@<:@=PKGS@:>@],\n\t[build static libraries @<:@default=]_LT_ENABLE_STATIC_DEFAULT[@:>@])],\n    [p=${PACKAGE-default}\n    case $enableval in\n    yes) enable_static=yes ;;\n    no) enable_static=no ;;\n    *)\n     enable_static=no\n      # Look at the argument we got.  We use all the common list separators.\n      lt_save_ifs=$IFS; IFS=$IFS$PATH_SEPARATOR,\n      for pkg in $enableval; do\n\tIFS=$lt_save_ifs\n\tif test \"X$pkg\" = \"X$p\"; then\n\t  enable_static=yes\n\tfi\n      done\n      IFS=$lt_save_ifs\n      ;;\n    esac],\n    [enable_static=]_LT_ENABLE_STATIC_DEFAULT)\n\n    _LT_DECL([build_old_libs], [enable_static], [0],\n\t[Whether or not to build static libraries])\n])# _LT_ENABLE_STATIC\n\nLT_OPTION_DEFINE([LT_INIT], [static], [_LT_ENABLE_STATIC([yes])])\nLT_OPTION_DEFINE([LT_INIT], [disable-static], [_LT_ENABLE_STATIC([no])])\n\n# Old names:\nAC_DEFUN([AC_ENABLE_STATIC],\n[_LT_SET_OPTION([LT_INIT], m4_if([$1], [no], [disable-])[static])\n])\n\nAC_DEFUN([AC_DISABLE_STATIC],\n[_LT_SET_OPTION([LT_INIT], [disable-static])\n])\n\nAU_DEFUN([AM_ENABLE_STATIC], [AC_ENABLE_STATIC($@)])\nAU_DEFUN([AM_DISABLE_STATIC], [AC_DISABLE_STATIC($@)])\n\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AM_ENABLE_STATIC], [])\ndnl AC_DEFUN([AM_DISABLE_STATIC], [])\n\n\n\n# _LT_ENABLE_FAST_INSTALL([DEFAULT])\n# ----------------------------------\n# implement the --enable-fast-install flag, and support the 'fast-install'\n# and 'disable-fast-install' LT_INIT options.\n# DEFAULT is either 'yes' or 'no'.  If omitted, it defaults to 'yes'.\nm4_define([_LT_ENABLE_FAST_INSTALL],\n[m4_define([_LT_ENABLE_FAST_INSTALL_DEFAULT], [m4_if($1, no, no, yes)])dnl\nAC_ARG_ENABLE([fast-install],\n    [AS_HELP_STRING([--enable-fast-install@<:@=PKGS@:>@],\n    [optimize for fast installation @<:@default=]_LT_ENABLE_FAST_INSTALL_DEFAULT[@:>@])],\n    [p=${PACKAGE-default}\n    case $enableval in\n    yes) enable_fast_install=yes ;;\n    no) enable_fast_install=no ;;\n    *)\n      enable_fast_install=no\n      # Look at the argument we got.  We use all the common list separators.\n      lt_save_ifs=$IFS; IFS=$IFS$PATH_SEPARATOR,\n      for pkg in $enableval; do\n\tIFS=$lt_save_ifs\n\tif test \"X$pkg\" = \"X$p\"; then\n\t  enable_fast_install=yes\n\tfi\n      done\n      IFS=$lt_save_ifs\n      ;;\n    esac],\n    [enable_fast_install=]_LT_ENABLE_FAST_INSTALL_DEFAULT)\n\n_LT_DECL([fast_install], [enable_fast_install], [0],\n\t [Whether or not to optimize for fast installation])dnl\n])# _LT_ENABLE_FAST_INSTALL\n\nLT_OPTION_DEFINE([LT_INIT], [fast-install], [_LT_ENABLE_FAST_INSTALL([yes])])\nLT_OPTION_DEFINE([LT_INIT], [disable-fast-install], [_LT_ENABLE_FAST_INSTALL([no])])\n\n# Old names:\nAU_DEFUN([AC_ENABLE_FAST_INSTALL],\n[_LT_SET_OPTION([LT_INIT], m4_if([$1], [no], [disable-])[fast-install])\nAC_DIAGNOSE([obsolete],\n[$0: Remove this warning and the call to _LT_SET_OPTION when you put\nthe 'fast-install' option into LT_INIT's first parameter.])\n])\n\nAU_DEFUN([AC_DISABLE_FAST_INSTALL],\n[_LT_SET_OPTION([LT_INIT], [disable-fast-install])\nAC_DIAGNOSE([obsolete],\n[$0: Remove this warning and the call to _LT_SET_OPTION when you put\nthe 'disable-fast-install' option into LT_INIT's first parameter.])\n])\n\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_ENABLE_FAST_INSTALL], [])\ndnl AC_DEFUN([AM_DISABLE_FAST_INSTALL], [])\n\n\n# _LT_WITH_AIX_SONAME([DEFAULT])\n# ----------------------------------\n# implement the --with-aix-soname flag, and support the `aix-soname=aix'\n# and `aix-soname=both' and `aix-soname=svr4' LT_INIT options. DEFAULT\n# is either `aix', `both' or `svr4'.  If omitted, it defaults to `aix'.\nm4_define([_LT_WITH_AIX_SONAME],\n[m4_define([_LT_WITH_AIX_SONAME_DEFAULT], [m4_if($1, svr4, svr4, m4_if($1, both, both, aix))])dnl\nshared_archive_member_spec=\ncase $host,$enable_shared in\npower*-*-aix[[5-9]]*,yes)\n  AC_MSG_CHECKING([which variant of shared library versioning to provide])\n  AC_ARG_WITH([aix-soname],\n    [AS_HELP_STRING([--with-aix-soname=aix|svr4|both],\n      [shared library versioning (aka \"SONAME\") variant to provide on AIX, @<:@default=]_LT_WITH_AIX_SONAME_DEFAULT[@:>@.])],\n    [case $withval in\n    aix|svr4|both)\n      ;;\n    *)\n      AC_MSG_ERROR([Unknown argument to --with-aix-soname])\n      ;;\n    esac\n    lt_cv_with_aix_soname=$with_aix_soname],\n    [AC_CACHE_VAL([lt_cv_with_aix_soname],\n      [lt_cv_with_aix_soname=]_LT_WITH_AIX_SONAME_DEFAULT)\n    with_aix_soname=$lt_cv_with_aix_soname])\n  AC_MSG_RESULT([$with_aix_soname])\n  if test aix != \"$with_aix_soname\"; then\n    # For the AIX way of multilib, we name the shared archive member\n    # based on the bitwidth used, traditionally 'shr.o' or 'shr_64.o',\n    # and 'shr.imp' or 'shr_64.imp', respectively, for the Import File.\n    # Even when GNU compilers ignore OBJECT_MODE but need '-maix64' flag,\n    # the AIX toolchain works better with OBJECT_MODE set (default 32).\n    if test 64 = \"${OBJECT_MODE-32}\"; then\n      shared_archive_member_spec=shr_64\n    else\n      shared_archive_member_spec=shr\n    fi\n  fi\n  ;;\n*)\n  with_aix_soname=aix\n  ;;\nesac\n\n_LT_DECL([], [shared_archive_member_spec], [0],\n    [Shared archive member basename, for filename based shared library versioning on AIX])dnl\n])# _LT_WITH_AIX_SONAME\n\nLT_OPTION_DEFINE([LT_INIT], [aix-soname=aix], [_LT_WITH_AIX_SONAME([aix])])\nLT_OPTION_DEFINE([LT_INIT], [aix-soname=both], [_LT_WITH_AIX_SONAME([both])])\nLT_OPTION_DEFINE([LT_INIT], [aix-soname=svr4], [_LT_WITH_AIX_SONAME([svr4])])\n\n\n# _LT_WITH_PIC([MODE])\n# --------------------\n# implement the --with-pic flag, and support the 'pic-only' and 'no-pic'\n# LT_INIT options.\n# MODE is either 'yes' or 'no'.  If omitted, it defaults to 'both'.\nm4_define([_LT_WITH_PIC],\n[AC_ARG_WITH([pic],\n    [AS_HELP_STRING([--with-pic@<:@=PKGS@:>@],\n\t[try to use only PIC/non-PIC objects @<:@default=use both@:>@])],\n    [lt_p=${PACKAGE-default}\n    case $withval in\n    yes|no) pic_mode=$withval ;;\n    *)\n      pic_mode=default\n      # Look at the argument we got.  We use all the common list separators.\n      lt_save_ifs=$IFS; IFS=$IFS$PATH_SEPARATOR,\n      for lt_pkg in $withval; do\n\tIFS=$lt_save_ifs\n\tif test \"X$lt_pkg\" = \"X$lt_p\"; then\n\t  pic_mode=yes\n\tfi\n      done\n      IFS=$lt_save_ifs\n      ;;\n    esac],\n    [pic_mode=m4_default([$1], [default])])\n\n_LT_DECL([], [pic_mode], [0], [What type of objects to build])dnl\n])# _LT_WITH_PIC\n\nLT_OPTION_DEFINE([LT_INIT], [pic-only], [_LT_WITH_PIC([yes])])\nLT_OPTION_DEFINE([LT_INIT], [no-pic], [_LT_WITH_PIC([no])])\n\n# Old name:\nAU_DEFUN([AC_LIBTOOL_PICMODE],\n[_LT_SET_OPTION([LT_INIT], [pic-only])\nAC_DIAGNOSE([obsolete],\n[$0: Remove this warning and the call to _LT_SET_OPTION when you\nput the 'pic-only' option into LT_INIT's first parameter.])\n])\n\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_LIBTOOL_PICMODE], [])\n\n## ----------------- ##\n## LTDL_INIT Options ##\n## ----------------- ##\n\nm4_define([_LTDL_MODE], [])\nLT_OPTION_DEFINE([LTDL_INIT], [nonrecursive],\n\t\t [m4_define([_LTDL_MODE], [nonrecursive])])\nLT_OPTION_DEFINE([LTDL_INIT], [recursive],\n\t\t [m4_define([_LTDL_MODE], [recursive])])\nLT_OPTION_DEFINE([LTDL_INIT], [subproject],\n\t\t [m4_define([_LTDL_MODE], [subproject])])\n\nm4_define([_LTDL_TYPE], [])\nLT_OPTION_DEFINE([LTDL_INIT], [installable],\n\t\t [m4_define([_LTDL_TYPE], [installable])])\nLT_OPTION_DEFINE([LTDL_INIT], [convenience],\n\t\t [m4_define([_LTDL_TYPE], [convenience])])\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/auxdir/ltmain.sh": "#! /bin/sh\n## DO NOT EDIT - This file generated from ./build-aux/ltmain.in\n##               by inline-source v2014-01-03.01\n\n# libtool (GNU libtool) 2.4.6\n# Provide generalized library-building support services.\n# Written by Gordon Matzigkeit <gord@gnu.ai.mit.edu>, 1996\n\n# Copyright (C) 1996-2015 Free Software Foundation, Inc.\n# This is free software; see the source for copying conditions.  There is NO\n# warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\n# GNU Libtool is free software; you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation; either version 2 of the License, or\n# (at your option) any later version.\n#\n# As a special exception to the GNU General Public License,\n# if you distribute this file as part of a program or library that\n# is built using GNU Libtool, you may include this file under the\n# same distribution terms that you use for the rest of that program.\n#\n# GNU Libtool is distributed in the hope that it will be useful, but\n# WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\n\nPROGRAM=libtool\nPACKAGE=libtool\nVERSION=\"2.4.6 Debian-2.4.6-2\"\npackage_revision=2.4.6\n\n\n## ------ ##\n## Usage. ##\n## ------ ##\n\n# Run './libtool --help' for help with using this script from the\n# command line.\n\n\n## ------------------------------- ##\n## User overridable command paths. ##\n## ------------------------------- ##\n\n# After configure completes, it has a better idea of some of the\n# shell tools we need than the defaults used by the functions shared\n# with bootstrap, so set those here where they can still be over-\n# ridden by the user, but otherwise take precedence.\n\n: ${AUTOCONF=\"autoconf\"}\n: ${AUTOMAKE=\"automake\"}\n\n\n## -------------------------- ##\n## Source external libraries. ##\n## -------------------------- ##\n\n# Much of our low-level functionality needs to be sourced from external\n# libraries, which are installed to $pkgauxdir.\n\n# Set a version string for this script.\nscriptversion=2015-01-20.17; # UTC\n\n# General shell script boiler plate, and helper functions.\n# Written by Gary V. Vaughan, 2004\n\n# Copyright (C) 2004-2015 Free Software Foundation, Inc.\n# This is free software; see the source for copying conditions.  There is NO\n# warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\n# This program is free software; you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation; either version 3 of the License, or\n# (at your option) any later version.\n\n# As a special exception to the GNU General Public License, if you distribute\n# this file as part of a program or library that is built using GNU Libtool,\n# you may include this file under the same distribution terms that you use\n# for the rest of that program.\n\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNES FOR A PARTICULAR PURPOSE. See the GNU\n# General Public License for more details.\n\n# You should have received a copy of the GNU General Public License\n# along with this program. If not, see <http://www.gnu.org/licenses/>.\n\n# Please report bugs or propose patches to gary@gnu.org.\n\n\n## ------ ##\n## Usage. ##\n## ------ ##\n\n# Evaluate this file near the top of your script to gain access to\n# the functions and variables defined here:\n#\n#   . `echo \"$0\" | ${SED-sed} 's|[^/]*$||'`/build-aux/funclib.sh\n#\n# If you need to override any of the default environment variable\n# settings, do that before evaluating this file.\n\n\n## -------------------- ##\n## Shell normalisation. ##\n## -------------------- ##\n\n# Some shells need a little help to be as Bourne compatible as possible.\n# Before doing anything else, make sure all that help has been provided!\n\nDUALCASE=1; export DUALCASE # for MKS sh\nif test -n \"${ZSH_VERSION+set}\" && (emulate sh) >/dev/null 2>&1; then :\n  emulate sh\n  NULLCMD=:\n  # Pre-4.2 versions of Zsh do word splitting on ${1+\"$@\"}, which\n  # is contrary to our usage.  Disable this feature.\n  alias -g '${1+\"$@\"}'='\"$@\"'\n  setopt NO_GLOB_SUBST\nelse\n  case `(set -o) 2>/dev/null` in *posix*) set -o posix ;; esac\nfi\n\n# NLS nuisances: We save the old values in case they are required later.\n_G_user_locale=\n_G_safe_locale=\nfor _G_var in LANG LANGUAGE LC_ALL LC_CTYPE LC_COLLATE LC_MESSAGES\ndo\n  eval \"if test set = \\\"\\${$_G_var+set}\\\"; then\n          save_$_G_var=\\$$_G_var\n          $_G_var=C\n\t  export $_G_var\n\t  _G_user_locale=\\\"$_G_var=\\\\\\$save_\\$_G_var; \\$_G_user_locale\\\"\n\t  _G_safe_locale=\\\"$_G_var=C; \\$_G_safe_locale\\\"\n\tfi\"\ndone\n\n# CDPATH.\n(unset CDPATH) >/dev/null 2>&1 && unset CDPATH\n\n# Make sure IFS has a sensible default\nsp=' '\nnl='\n'\nIFS=\"$sp\t$nl\"\n\n# There are apparently some retarded systems that use ';' as a PATH separator!\nif test \"${PATH_SEPARATOR+set}\" != set; then\n  PATH_SEPARATOR=:\n  (PATH='/bin;/bin'; FPATH=$PATH; sh -c :) >/dev/null 2>&1 && {\n    (PATH='/bin:/bin'; FPATH=$PATH; sh -c :) >/dev/null 2>&1 ||\n      PATH_SEPARATOR=';'\n  }\nfi\n\n\n\n## ------------------------- ##\n## Locate command utilities. ##\n## ------------------------- ##\n\n\n# func_executable_p FILE\n# ----------------------\n# Check that FILE is an executable regular file.\nfunc_executable_p ()\n{\n    test -f \"$1\" && test -x \"$1\"\n}\n\n\n# func_path_progs PROGS_LIST CHECK_FUNC [PATH]\n# --------------------------------------------\n# Search for either a program that responds to --version with output\n# containing \"GNU\", or else returned by CHECK_FUNC otherwise, by\n# trying all the directories in PATH with each of the elements of\n# PROGS_LIST.\n#\n# CHECK_FUNC should accept the path to a candidate program, and\n# set $func_check_prog_result if it truncates its output less than\n# $_G_path_prog_max characters.\nfunc_path_progs ()\n{\n    _G_progs_list=$1\n    _G_check_func=$2\n    _G_PATH=${3-\"$PATH\"}\n\n    _G_path_prog_max=0\n    _G_path_prog_found=false\n    _G_save_IFS=$IFS; IFS=${PATH_SEPARATOR-:}\n    for _G_dir in $_G_PATH; do\n      IFS=$_G_save_IFS\n      test -z \"$_G_dir\" && _G_dir=.\n      for _G_prog_name in $_G_progs_list; do\n        for _exeext in '' .EXE; do\n          _G_path_prog=$_G_dir/$_G_prog_name$_exeext\n          func_executable_p \"$_G_path_prog\" || continue\n          case `\"$_G_path_prog\" --version 2>&1` in\n            *GNU*) func_path_progs_result=$_G_path_prog _G_path_prog_found=: ;;\n            *)     $_G_check_func $_G_path_prog\n\t\t   func_path_progs_result=$func_check_prog_result\n\t\t   ;;\n          esac\n          $_G_path_prog_found && break 3\n        done\n      done\n    done\n    IFS=$_G_save_IFS\n    test -z \"$func_path_progs_result\" && {\n      echo \"no acceptable sed could be found in \\$PATH\" >&2\n      exit 1\n    }\n}\n\n\n# We want to be able to use the functions in this file before configure\n# has figured out where the best binaries are kept, which means we have\n# to search for them ourselves - except when the results are already set\n# where we skip the searches.\n\n# Unless the user overrides by setting SED, search the path for either GNU\n# sed, or the sed that truncates its output the least.\ntest -z \"$SED\" && {\n  _G_sed_script=s/aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa/bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb/\n  for _G_i in 1 2 3 4 5 6 7; do\n    _G_sed_script=$_G_sed_script$nl$_G_sed_script\n  done\n  echo \"$_G_sed_script\" 2>/dev/null | sed 99q >conftest.sed\n  _G_sed_script=\n\n  func_check_prog_sed ()\n  {\n    _G_path_prog=$1\n\n    _G_count=0\n    printf 0123456789 >conftest.in\n    while :\n    do\n      cat conftest.in conftest.in >conftest.tmp\n      mv conftest.tmp conftest.in\n      cp conftest.in conftest.nl\n      echo '' >> conftest.nl\n      \"$_G_path_prog\" -f conftest.sed <conftest.nl >conftest.out 2>/dev/null || break\n      diff conftest.out conftest.nl >/dev/null 2>&1 || break\n      _G_count=`expr $_G_count + 1`\n      if test \"$_G_count\" -gt \"$_G_path_prog_max\"; then\n        # Best one so far, save it but keep looking for a better one\n        func_check_prog_result=$_G_path_prog\n        _G_path_prog_max=$_G_count\n      fi\n      # 10*(2^10) chars as input seems more than enough\n      test 10 -lt \"$_G_count\" && break\n    done\n    rm -f conftest.in conftest.tmp conftest.nl conftest.out\n  }\n\n  func_path_progs \"sed gsed\" func_check_prog_sed $PATH:/usr/xpg4/bin\n  rm -f conftest.sed\n  SED=$func_path_progs_result\n}\n\n\n# Unless the user overrides by setting GREP, search the path for either GNU\n# grep, or the grep that truncates its output the least.\ntest -z \"$GREP\" && {\n  func_check_prog_grep ()\n  {\n    _G_path_prog=$1\n\n    _G_count=0\n    _G_path_prog_max=0\n    printf 0123456789 >conftest.in\n    while :\n    do\n      cat conftest.in conftest.in >conftest.tmp\n      mv conftest.tmp conftest.in\n      cp conftest.in conftest.nl\n      echo 'GREP' >> conftest.nl\n      \"$_G_path_prog\" -e 'GREP$' -e '-(cannot match)-' <conftest.nl >conftest.out 2>/dev/null || break\n      diff conftest.out conftest.nl >/dev/null 2>&1 || break\n      _G_count=`expr $_G_count + 1`\n      if test \"$_G_count\" -gt \"$_G_path_prog_max\"; then\n        # Best one so far, save it but keep looking for a better one\n        func_check_prog_result=$_G_path_prog\n        _G_path_prog_max=$_G_count\n      fi\n      # 10*(2^10) chars as input seems more than enough\n      test 10 -lt \"$_G_count\" && break\n    done\n    rm -f conftest.in conftest.tmp conftest.nl conftest.out\n  }\n\n  func_path_progs \"grep ggrep\" func_check_prog_grep $PATH:/usr/xpg4/bin\n  GREP=$func_path_progs_result\n}\n\n\n## ------------------------------- ##\n## User overridable command paths. ##\n## ------------------------------- ##\n\n# All uppercase variable names are used for environment variables.  These\n# variables can be overridden by the user before calling a script that\n# uses them if a suitable command of that name is not already available\n# in the command search PATH.\n\n: ${CP=\"cp -f\"}\n: ${ECHO=\"printf %s\\n\"}\n: ${EGREP=\"$GREP -E\"}\n: ${FGREP=\"$GREP -F\"}\n: ${LN_S=\"ln -s\"}\n: ${MAKE=\"make\"}\n: ${MKDIR=\"mkdir\"}\n: ${MV=\"mv -f\"}\n: ${RM=\"rm -f\"}\n: ${SHELL=\"${CONFIG_SHELL-/bin/sh}\"}\n\n\n## -------------------- ##\n## Useful sed snippets. ##\n## -------------------- ##\n\nsed_dirname='s|/[^/]*$||'\nsed_basename='s|^.*/||'\n\n# Sed substitution that helps us do robust quoting.  It backslashifies\n# metacharacters that are still active within double-quoted strings.\nsed_quote_subst='s|\\([`\"$\\\\]\\)|\\\\\\1|g'\n\n# Same as above, but do not quote variable references.\nsed_double_quote_subst='s/\\([\"`\\\\]\\)/\\\\\\1/g'\n\n# Sed substitution that turns a string into a regex matching for the\n# string literally.\nsed_make_literal_regex='s|[].[^$\\\\*\\/]|\\\\&|g'\n\n# Sed substitution that converts a w32 file name or path\n# that contains forward slashes, into one that contains\n# (escaped) backslashes.  A very naive implementation.\nsed_naive_backslashify='s|\\\\\\\\*|\\\\|g;s|/|\\\\|g;s|\\\\|\\\\\\\\|g'\n\n# Re-'\\' parameter expansions in output of sed_double_quote_subst that\n# were '\\'-ed in input to the same.  If an odd number of '\\' preceded a\n# '$' in input to sed_double_quote_subst, that '$' was protected from\n# expansion.  Since each input '\\' is now two '\\'s, look for any number\n# of runs of four '\\'s followed by two '\\'s and then a '$'.  '\\' that '$'.\n_G_bs='\\\\'\n_G_bs2='\\\\\\\\'\n_G_bs4='\\\\\\\\\\\\\\\\'\n_G_dollar='\\$'\nsed_double_backslash=\"\\\n  s/$_G_bs4/&\\\\\n/g\n  s/^$_G_bs2$_G_dollar/$_G_bs&/\n  s/\\\\([^$_G_bs]\\\\)$_G_bs2$_G_dollar/\\\\1$_G_bs2$_G_bs$_G_dollar/g\n  s/\\n//g\"\n\n\n## ----------------- ##\n## Global variables. ##\n## ----------------- ##\n\n# Except for the global variables explicitly listed below, the following\n# functions in the '^func_' namespace, and the '^require_' namespace\n# variables initialised in the 'Resource management' section, sourcing\n# this file will not pollute your global namespace with anything\n# else. There's no portable way to scope variables in Bourne shell\n# though, so actually running these functions will sometimes place\n# results into a variable named after the function, and often use\n# temporary variables in the '^_G_' namespace. If you are careful to\n# avoid using those namespaces casually in your sourcing script, things\n# should continue to work as you expect. And, of course, you can freely\n# overwrite any of the functions or variables defined here before\n# calling anything to customize them.\n\nEXIT_SUCCESS=0\nEXIT_FAILURE=1\nEXIT_MISMATCH=63  # $? = 63 is used to indicate version mismatch to missing.\nEXIT_SKIP=77\t  # $? = 77 is used to indicate a skipped test to automake.\n\n# Allow overriding, eg assuming that you follow the convention of\n# putting '$debug_cmd' at the start of all your functions, you can get\n# bash to show function call trace with:\n#\n#    debug_cmd='eval echo \"${FUNCNAME[0]} $*\" >&2' bash your-script-name\ndebug_cmd=${debug_cmd-\":\"}\nexit_cmd=:\n\n# By convention, finish your script with:\n#\n#    exit $exit_status\n#\n# so that you can set exit_status to non-zero if you want to indicate\n# something went wrong during execution without actually bailing out at\n# the point of failure.\nexit_status=$EXIT_SUCCESS\n\n# Work around backward compatibility issue on IRIX 6.5. On IRIX 6.4+, sh\n# is ksh but when the shell is invoked as \"sh\" and the current value of\n# the _XPG environment variable is not equal to 1 (one), the special\n# positional parameter $0, within a function call, is the name of the\n# function.\nprogpath=$0\n\n# The name of this program.\nprogname=`$ECHO \"$progpath\" |$SED \"$sed_basename\"`\n\n# Make sure we have an absolute progpath for reexecution:\ncase $progpath in\n  [\\\\/]*|[A-Za-z]:\\\\*) ;;\n  *[\\\\/]*)\n     progdir=`$ECHO \"$progpath\" |$SED \"$sed_dirname\"`\n     progdir=`cd \"$progdir\" && pwd`\n     progpath=$progdir/$progname\n     ;;\n  *)\n     _G_IFS=$IFS\n     IFS=${PATH_SEPARATOR-:}\n     for progdir in $PATH; do\n       IFS=$_G_IFS\n       test -x \"$progdir/$progname\" && break\n     done\n     IFS=$_G_IFS\n     test -n \"$progdir\" || progdir=`pwd`\n     progpath=$progdir/$progname\n     ;;\nesac\n\n\n## ----------------- ##\n## Standard options. ##\n## ----------------- ##\n\n# The following options affect the operation of the functions defined\n# below, and should be set appropriately depending on run-time para-\n# meters passed on the command line.\n\nopt_dry_run=false\nopt_quiet=false\nopt_verbose=false\n\n# Categories 'all' and 'none' are always available.  Append any others\n# you will pass as the first argument to func_warning from your own\n# code.\nwarning_categories=\n\n# By default, display warnings according to 'opt_warning_types'.  Set\n# 'warning_func'  to ':' to elide all warnings, or func_fatal_error to\n# treat the next displayed warning as a fatal error.\nwarning_func=func_warn_and_continue\n\n# Set to 'all' to display all warnings, 'none' to suppress all\n# warnings, or a space delimited list of some subset of\n# 'warning_categories' to display only the listed warnings.\nopt_warning_types=all\n\n\n## -------------------- ##\n## Resource management. ##\n## -------------------- ##\n\n# This section contains definitions for functions that each ensure a\n# particular resource (a file, or a non-empty configuration variable for\n# example) is available, and if appropriate to extract default values\n# from pertinent package files. Call them using their associated\n# 'require_*' variable to ensure that they are executed, at most, once.\n#\n# It's entirely deliberate that calling these functions can set\n# variables that don't obey the namespace limitations obeyed by the rest\n# of this file, in order that that they be as useful as possible to\n# callers.\n\n\n# require_term_colors\n# -------------------\n# Allow display of bold text on terminals that support it.\nrequire_term_colors=func_require_term_colors\nfunc_require_term_colors ()\n{\n    $debug_cmd\n\n    test -t 1 && {\n      # COLORTERM and USE_ANSI_COLORS environment variables take\n      # precedence, because most terminfo databases neglect to describe\n      # whether color sequences are supported.\n      test -n \"${COLORTERM+set}\" && : ${USE_ANSI_COLORS=\"1\"}\n\n      if test 1 = \"$USE_ANSI_COLORS\"; then\n        # Standard ANSI escape sequences\n        tc_reset='\u001b[0m'\n        tc_bold='\u001b[1m';   tc_standout='\u001b[7m'\n        tc_red='\u001b[31m';   tc_green='\u001b[32m'\n        tc_blue='\u001b[34m';  tc_cyan='\u001b[36m'\n      else\n        # Otherwise trust the terminfo database after all.\n        test -n \"`tput sgr0 2>/dev/null`\" && {\n          tc_reset=`tput sgr0`\n          test -n \"`tput bold 2>/dev/null`\" && tc_bold=`tput bold`\n          tc_standout=$tc_bold\n          test -n \"`tput smso 2>/dev/null`\" && tc_standout=`tput smso`\n          test -n \"`tput setaf 1 2>/dev/null`\" && tc_red=`tput setaf 1`\n          test -n \"`tput setaf 2 2>/dev/null`\" && tc_green=`tput setaf 2`\n          test -n \"`tput setaf 4 2>/dev/null`\" && tc_blue=`tput setaf 4`\n          test -n \"`tput setaf 5 2>/dev/null`\" && tc_cyan=`tput setaf 5`\n        }\n      fi\n    }\n\n    require_term_colors=:\n}\n\n\n## ----------------- ##\n## Function library. ##\n## ----------------- ##\n\n# This section contains a variety of useful functions to call in your\n# scripts. Take note of the portable wrappers for features provided by\n# some modern shells, which will fall back to slower equivalents on\n# less featureful shells.\n\n\n# func_append VAR VALUE\n# ---------------------\n# Append VALUE onto the existing contents of VAR.\n\n  # We should try to minimise forks, especially on Windows where they are\n  # unreasonably slow, so skip the feature probes when bash or zsh are\n  # being used:\n  if test set = \"${BASH_VERSION+set}${ZSH_VERSION+set}\"; then\n    : ${_G_HAVE_ARITH_OP=\"yes\"}\n    : ${_G_HAVE_XSI_OPS=\"yes\"}\n    # The += operator was introduced in bash 3.1\n    case $BASH_VERSION in\n      [12].* | 3.0 | 3.0*) ;;\n      *)\n        : ${_G_HAVE_PLUSEQ_OP=\"yes\"}\n        ;;\n    esac\n  fi\n\n  # _G_HAVE_PLUSEQ_OP\n  # Can be empty, in which case the shell is probed, \"yes\" if += is\n  # useable or anything else if it does not work.\n  test -z \"$_G_HAVE_PLUSEQ_OP\" \\\n    && (eval 'x=a; x+=\" b\"; test \"a b\" = \"$x\"') 2>/dev/null \\\n    && _G_HAVE_PLUSEQ_OP=yes\n\nif test yes = \"$_G_HAVE_PLUSEQ_OP\"\nthen\n  # This is an XSI compatible shell, allowing a faster implementation...\n  eval 'func_append ()\n  {\n    $debug_cmd\n\n    eval \"$1+=\\$2\"\n  }'\nelse\n  # ...otherwise fall back to using expr, which is often a shell builtin.\n  func_append ()\n  {\n    $debug_cmd\n\n    eval \"$1=\\$$1\\$2\"\n  }\nfi\n\n\n# func_append_quoted VAR VALUE\n# ----------------------------\n# Quote VALUE and append to the end of shell variable VAR, separated\n# by a space.\nif test yes = \"$_G_HAVE_PLUSEQ_OP\"; then\n  eval 'func_append_quoted ()\n  {\n    $debug_cmd\n\n    func_quote_for_eval \"$2\"\n    eval \"$1+=\\\\ \\$func_quote_for_eval_result\"\n  }'\nelse\n  func_append_quoted ()\n  {\n    $debug_cmd\n\n    func_quote_for_eval \"$2\"\n    eval \"$1=\\$$1\\\\ \\$func_quote_for_eval_result\"\n  }\nfi\n\n\n# func_append_uniq VAR VALUE\n# --------------------------\n# Append unique VALUE onto the existing contents of VAR, assuming\n# entries are delimited by the first character of VALUE.  For example:\n#\n#   func_append_uniq options \" --another-option option-argument\"\n#\n# will only append to $options if \" --another-option option-argument \"\n# is not already present somewhere in $options already (note spaces at\n# each end implied by leading space in second argument).\nfunc_append_uniq ()\n{\n    $debug_cmd\n\n    eval _G_current_value='`$ECHO $'$1'`'\n    _G_delim=`expr \"$2\" : '\\(.\\)'`\n\n    case $_G_delim$_G_current_value$_G_delim in\n      *\"$2$_G_delim\"*) ;;\n      *) func_append \"$@\" ;;\n    esac\n}\n\n\n# func_arith TERM...\n# ------------------\n# Set func_arith_result to the result of evaluating TERMs.\n  test -z \"$_G_HAVE_ARITH_OP\" \\\n    && (eval 'test 2 = $(( 1 + 1 ))') 2>/dev/null \\\n    && _G_HAVE_ARITH_OP=yes\n\nif test yes = \"$_G_HAVE_ARITH_OP\"; then\n  eval 'func_arith ()\n  {\n    $debug_cmd\n\n    func_arith_result=$(( $* ))\n  }'\nelse\n  func_arith ()\n  {\n    $debug_cmd\n\n    func_arith_result=`expr \"$@\"`\n  }\nfi\n\n\n# func_basename FILE\n# ------------------\n# Set func_basename_result to FILE with everything up to and including\n# the last / stripped.\nif test yes = \"$_G_HAVE_XSI_OPS\"; then\n  # If this shell supports suffix pattern removal, then use it to avoid\n  # forking. Hide the definitions single quotes in case the shell chokes\n  # on unsupported syntax...\n  _b='func_basename_result=${1##*/}'\n  _d='case $1 in\n        */*) func_dirname_result=${1%/*}$2 ;;\n        *  ) func_dirname_result=$3        ;;\n      esac'\n\nelse\n  # ...otherwise fall back to using sed.\n  _b='func_basename_result=`$ECHO \"$1\" |$SED \"$sed_basename\"`'\n  _d='func_dirname_result=`$ECHO \"$1\"  |$SED \"$sed_dirname\"`\n      if test \"X$func_dirname_result\" = \"X$1\"; then\n        func_dirname_result=$3\n      else\n        func_append func_dirname_result \"$2\"\n      fi'\nfi\n\neval 'func_basename ()\n{\n    $debug_cmd\n\n    '\"$_b\"'\n}'\n\n\n# func_dirname FILE APPEND NONDIR_REPLACEMENT\n# -------------------------------------------\n# Compute the dirname of FILE.  If nonempty, add APPEND to the result,\n# otherwise set result to NONDIR_REPLACEMENT.\neval 'func_dirname ()\n{\n    $debug_cmd\n\n    '\"$_d\"'\n}'\n\n\n# func_dirname_and_basename FILE APPEND NONDIR_REPLACEMENT\n# --------------------------------------------------------\n# Perform func_basename and func_dirname in a single function\n# call:\n#   dirname:  Compute the dirname of FILE.  If nonempty,\n#             add APPEND to the result, otherwise set result\n#             to NONDIR_REPLACEMENT.\n#             value returned in \"$func_dirname_result\"\n#   basename: Compute filename of FILE.\n#             value retuned in \"$func_basename_result\"\n# For efficiency, we do not delegate to the functions above but instead\n# duplicate the functionality here.\neval 'func_dirname_and_basename ()\n{\n    $debug_cmd\n\n    '\"$_b\"'\n    '\"$_d\"'\n}'\n\n\n# func_echo ARG...\n# ----------------\n# Echo program name prefixed message.\nfunc_echo ()\n{\n    $debug_cmd\n\n    _G_message=$*\n\n    func_echo_IFS=$IFS\n    IFS=$nl\n    for _G_line in $_G_message; do\n      IFS=$func_echo_IFS\n      $ECHO \"$progname: $_G_line\"\n    done\n    IFS=$func_echo_IFS\n}\n\n\n# func_echo_all ARG...\n# --------------------\n# Invoke $ECHO with all args, space-separated.\nfunc_echo_all ()\n{\n    $ECHO \"$*\"\n}\n\n\n# func_echo_infix_1 INFIX ARG...\n# ------------------------------\n# Echo program name, followed by INFIX on the first line, with any\n# additional lines not showing INFIX.\nfunc_echo_infix_1 ()\n{\n    $debug_cmd\n\n    $require_term_colors\n\n    _G_infix=$1; shift\n    _G_indent=$_G_infix\n    _G_prefix=\"$progname: $_G_infix: \"\n    _G_message=$*\n\n    # Strip color escape sequences before counting printable length\n    for _G_tc in \"$tc_reset\" \"$tc_bold\" \"$tc_standout\" \"$tc_red\" \"$tc_green\" \"$tc_blue\" \"$tc_cyan\"\n    do\n      test -n \"$_G_tc\" && {\n        _G_esc_tc=`$ECHO \"$_G_tc\" | $SED \"$sed_make_literal_regex\"`\n        _G_indent=`$ECHO \"$_G_indent\" | $SED \"s|$_G_esc_tc||g\"`\n      }\n    done\n    _G_indent=\"$progname: \"`echo \"$_G_indent\" | $SED 's|.| |g'`\"  \" ## exclude from sc_prohibit_nested_quotes\n\n    func_echo_infix_1_IFS=$IFS\n    IFS=$nl\n    for _G_line in $_G_message; do\n      IFS=$func_echo_infix_1_IFS\n      $ECHO \"$_G_prefix$tc_bold$_G_line$tc_reset\" >&2\n      _G_prefix=$_G_indent\n    done\n    IFS=$func_echo_infix_1_IFS\n}\n\n\n# func_error ARG...\n# -----------------\n# Echo program name prefixed message to standard error.\nfunc_error ()\n{\n    $debug_cmd\n\n    $require_term_colors\n\n    func_echo_infix_1 \"  $tc_standout${tc_red}error$tc_reset\" \"$*\" >&2\n}\n\n\n# func_fatal_error ARG...\n# -----------------------\n# Echo program name prefixed message to standard error, and exit.\nfunc_fatal_error ()\n{\n    $debug_cmd\n\n    func_error \"$*\"\n    exit $EXIT_FAILURE\n}\n\n\n# func_grep EXPRESSION FILENAME\n# -----------------------------\n# Check whether EXPRESSION matches any line of FILENAME, without output.\nfunc_grep ()\n{\n    $debug_cmd\n\n    $GREP \"$1\" \"$2\" >/dev/null 2>&1\n}\n\n\n# func_len STRING\n# ---------------\n# Set func_len_result to the length of STRING. STRING may not\n# start with a hyphen.\n  test -z \"$_G_HAVE_XSI_OPS\" \\\n    && (eval 'x=a/b/c;\n      test 5aa/bb/cc = \"${#x}${x%%/*}${x%/*}${x#*/}${x##*/}\"') 2>/dev/null \\\n    && _G_HAVE_XSI_OPS=yes\n\nif test yes = \"$_G_HAVE_XSI_OPS\"; then\n  eval 'func_len ()\n  {\n    $debug_cmd\n\n    func_len_result=${#1}\n  }'\nelse\n  func_len ()\n  {\n    $debug_cmd\n\n    func_len_result=`expr \"$1\" : \".*\" 2>/dev/null || echo $max_cmd_len`\n  }\nfi\n\n\n# func_mkdir_p DIRECTORY-PATH\n# ---------------------------\n# Make sure the entire path to DIRECTORY-PATH is available.\nfunc_mkdir_p ()\n{\n    $debug_cmd\n\n    _G_directory_path=$1\n    _G_dir_list=\n\n    if test -n \"$_G_directory_path\" && test : != \"$opt_dry_run\"; then\n\n      # Protect directory names starting with '-'\n      case $_G_directory_path in\n        -*) _G_directory_path=./$_G_directory_path ;;\n      esac\n\n      # While some portion of DIR does not yet exist...\n      while test ! -d \"$_G_directory_path\"; do\n        # ...make a list in topmost first order.  Use a colon delimited\n\t# list incase some portion of path contains whitespace.\n        _G_dir_list=$_G_directory_path:$_G_dir_list\n\n        # If the last portion added has no slash in it, the list is done\n        case $_G_directory_path in */*) ;; *) break ;; esac\n\n        # ...otherwise throw away the child directory and loop\n        _G_directory_path=`$ECHO \"$_G_directory_path\" | $SED -e \"$sed_dirname\"`\n      done\n      _G_dir_list=`$ECHO \"$_G_dir_list\" | $SED 's|:*$||'`\n\n      func_mkdir_p_IFS=$IFS; IFS=:\n      for _G_dir in $_G_dir_list; do\n\tIFS=$func_mkdir_p_IFS\n        # mkdir can fail with a 'File exist' error if two processes\n        # try to create one of the directories concurrently.  Don't\n        # stop in that case!\n        $MKDIR \"$_G_dir\" 2>/dev/null || :\n      done\n      IFS=$func_mkdir_p_IFS\n\n      # Bail out if we (or some other process) failed to create a directory.\n      test -d \"$_G_directory_path\" || \\\n        func_fatal_error \"Failed to create '$1'\"\n    fi\n}\n\n\n# func_mktempdir [BASENAME]\n# -------------------------\n# Make a temporary directory that won't clash with other running\n# libtool processes, and avoids race conditions if possible.  If\n# given, BASENAME is the basename for that directory.\nfunc_mktempdir ()\n{\n    $debug_cmd\n\n    _G_template=${TMPDIR-/tmp}/${1-$progname}\n\n    if test : = \"$opt_dry_run\"; then\n      # Return a directory name, but don't create it in dry-run mode\n      _G_tmpdir=$_G_template-$$\n    else\n\n      # If mktemp works, use that first and foremost\n      _G_tmpdir=`mktemp -d \"$_G_template-XXXXXXXX\" 2>/dev/null`\n\n      if test ! -d \"$_G_tmpdir\"; then\n        # Failing that, at least try and use $RANDOM to avoid a race\n        _G_tmpdir=$_G_template-${RANDOM-0}$$\n\n        func_mktempdir_umask=`umask`\n        umask 0077\n        $MKDIR \"$_G_tmpdir\"\n        umask $func_mktempdir_umask\n      fi\n\n      # If we're not in dry-run mode, bomb out on failure\n      test -d \"$_G_tmpdir\" || \\\n        func_fatal_error \"cannot create temporary directory '$_G_tmpdir'\"\n    fi\n\n    $ECHO \"$_G_tmpdir\"\n}\n\n\n# func_normal_abspath PATH\n# ------------------------\n# Remove doubled-up and trailing slashes, \".\" path components,\n# and cancel out any \"..\" path components in PATH after making\n# it an absolute path.\nfunc_normal_abspath ()\n{\n    $debug_cmd\n\n    # These SED scripts presuppose an absolute path with a trailing slash.\n    _G_pathcar='s|^/\\([^/]*\\).*$|\\1|'\n    _G_pathcdr='s|^/[^/]*||'\n    _G_removedotparts=':dotsl\n\t\ts|/\\./|/|g\n\t\tt dotsl\n\t\ts|/\\.$|/|'\n    _G_collapseslashes='s|/\\{1,\\}|/|g'\n    _G_finalslash='s|/*$|/|'\n\n    # Start from root dir and reassemble the path.\n    func_normal_abspath_result=\n    func_normal_abspath_tpath=$1\n    func_normal_abspath_altnamespace=\n    case $func_normal_abspath_tpath in\n      \"\")\n        # Empty path, that just means $cwd.\n        func_stripname '' '/' \"`pwd`\"\n        func_normal_abspath_result=$func_stripname_result\n        return\n        ;;\n      # The next three entries are used to spot a run of precisely\n      # two leading slashes without using negated character classes;\n      # we take advantage of case's first-match behaviour.\n      ///*)\n        # Unusual form of absolute path, do nothing.\n        ;;\n      //*)\n        # Not necessarily an ordinary path; POSIX reserves leading '//'\n        # and for example Cygwin uses it to access remote file shares\n        # over CIFS/SMB, so we conserve a leading double slash if found.\n        func_normal_abspath_altnamespace=/\n        ;;\n      /*)\n        # Absolute path, do nothing.\n        ;;\n      *)\n        # Relative path, prepend $cwd.\n        func_normal_abspath_tpath=`pwd`/$func_normal_abspath_tpath\n        ;;\n    esac\n\n    # Cancel out all the simple stuff to save iterations.  We also want\n    # the path to end with a slash for ease of parsing, so make sure\n    # there is one (and only one) here.\n    func_normal_abspath_tpath=`$ECHO \"$func_normal_abspath_tpath\" | $SED \\\n          -e \"$_G_removedotparts\" -e \"$_G_collapseslashes\" -e \"$_G_finalslash\"`\n    while :; do\n      # Processed it all yet?\n      if test / = \"$func_normal_abspath_tpath\"; then\n        # If we ascended to the root using \"..\" the result may be empty now.\n        if test -z \"$func_normal_abspath_result\"; then\n          func_normal_abspath_result=/\n        fi\n        break\n      fi\n      func_normal_abspath_tcomponent=`$ECHO \"$func_normal_abspath_tpath\" | $SED \\\n          -e \"$_G_pathcar\"`\n      func_normal_abspath_tpath=`$ECHO \"$func_normal_abspath_tpath\" | $SED \\\n          -e \"$_G_pathcdr\"`\n      # Figure out what to do with it\n      case $func_normal_abspath_tcomponent in\n        \"\")\n          # Trailing empty path component, ignore it.\n          ;;\n        ..)\n          # Parent dir; strip last assembled component from result.\n          func_dirname \"$func_normal_abspath_result\"\n          func_normal_abspath_result=$func_dirname_result\n          ;;\n        *)\n          # Actual path component, append it.\n          func_append func_normal_abspath_result \"/$func_normal_abspath_tcomponent\"\n          ;;\n      esac\n    done\n    # Restore leading double-slash if one was found on entry.\n    func_normal_abspath_result=$func_normal_abspath_altnamespace$func_normal_abspath_result\n}\n\n\n# func_notquiet ARG...\n# --------------------\n# Echo program name prefixed message only when not in quiet mode.\nfunc_notquiet ()\n{\n    $debug_cmd\n\n    $opt_quiet || func_echo ${1+\"$@\"}\n\n    # A bug in bash halts the script if the last line of a function\n    # fails when set -e is in force, so we need another command to\n    # work around that:\n    :\n}\n\n\n# func_relative_path SRCDIR DSTDIR\n# --------------------------------\n# Set func_relative_path_result to the relative path from SRCDIR to DSTDIR.\nfunc_relative_path ()\n{\n    $debug_cmd\n\n    func_relative_path_result=\n    func_normal_abspath \"$1\"\n    func_relative_path_tlibdir=$func_normal_abspath_result\n    func_normal_abspath \"$2\"\n    func_relative_path_tbindir=$func_normal_abspath_result\n\n    # Ascend the tree starting from libdir\n    while :; do\n      # check if we have found a prefix of bindir\n      case $func_relative_path_tbindir in\n        $func_relative_path_tlibdir)\n          # found an exact match\n          func_relative_path_tcancelled=\n          break\n          ;;\n        $func_relative_path_tlibdir*)\n          # found a matching prefix\n          func_stripname \"$func_relative_path_tlibdir\" '' \"$func_relative_path_tbindir\"\n          func_relative_path_tcancelled=$func_stripname_result\n          if test -z \"$func_relative_path_result\"; then\n            func_relative_path_result=.\n          fi\n          break\n          ;;\n        *)\n          func_dirname $func_relative_path_tlibdir\n          func_relative_path_tlibdir=$func_dirname_result\n          if test -z \"$func_relative_path_tlibdir\"; then\n            # Have to descend all the way to the root!\n            func_relative_path_result=../$func_relative_path_result\n            func_relative_path_tcancelled=$func_relative_path_tbindir\n            break\n          fi\n          func_relative_path_result=../$func_relative_path_result\n          ;;\n      esac\n    done\n\n    # Now calculate path; take care to avoid doubling-up slashes.\n    func_stripname '' '/' \"$func_relative_path_result\"\n    func_relative_path_result=$func_stripname_result\n    func_stripname '/' '/' \"$func_relative_path_tcancelled\"\n    if test -n \"$func_stripname_result\"; then\n      func_append func_relative_path_result \"/$func_stripname_result\"\n    fi\n\n    # Normalisation. If bindir is libdir, return '.' else relative path.\n    if test -n \"$func_relative_path_result\"; then\n      func_stripname './' '' \"$func_relative_path_result\"\n      func_relative_path_result=$func_stripname_result\n    fi\n\n    test -n \"$func_relative_path_result\" || func_relative_path_result=.\n\n    :\n}\n\n\n# func_quote_for_eval ARG...\n# --------------------------\n# Aesthetically quote ARGs to be evaled later.\n# This function returns two values:\n#   i) func_quote_for_eval_result\n#      double-quoted, suitable for a subsequent eval\n#  ii) func_quote_for_eval_unquoted_result\n#      has all characters that are still active within double\n#      quotes backslashified.\nfunc_quote_for_eval ()\n{\n    $debug_cmd\n\n    func_quote_for_eval_unquoted_result=\n    func_quote_for_eval_result=\n    while test 0 -lt $#; do\n      case $1 in\n        *[\\\\\\`\\\"\\$]*)\n\t  _G_unquoted_arg=`printf '%s\\n' \"$1\" |$SED \"$sed_quote_subst\"` ;;\n        *)\n          _G_unquoted_arg=$1 ;;\n      esac\n      if test -n \"$func_quote_for_eval_unquoted_result\"; then\n\tfunc_append func_quote_for_eval_unquoted_result \" $_G_unquoted_arg\"\n      else\n        func_append func_quote_for_eval_unquoted_result \"$_G_unquoted_arg\"\n      fi\n\n      case $_G_unquoted_arg in\n        # Double-quote args containing shell metacharacters to delay\n        # word splitting, command substitution and variable expansion\n        # for a subsequent eval.\n        # Many Bourne shells cannot handle close brackets correctly\n        # in scan sets, so we specify it separately.\n        *[\\[\\~\\#\\^\\&\\*\\(\\)\\{\\}\\|\\;\\<\\>\\?\\'\\ \\\t]*|*]*|\"\")\n          _G_quoted_arg=\\\"$_G_unquoted_arg\\\"\n          ;;\n        *)\n          _G_quoted_arg=$_G_unquoted_arg\n\t  ;;\n      esac\n\n      if test -n \"$func_quote_for_eval_result\"; then\n\tfunc_append func_quote_for_eval_result \" $_G_quoted_arg\"\n      else\n        func_append func_quote_for_eval_result \"$_G_quoted_arg\"\n      fi\n      shift\n    done\n}\n\n\n# func_quote_for_expand ARG\n# -------------------------\n# Aesthetically quote ARG to be evaled later; same as above,\n# but do not quote variable references.\nfunc_quote_for_expand ()\n{\n    $debug_cmd\n\n    case $1 in\n      *[\\\\\\`\\\"]*)\n\t_G_arg=`$ECHO \"$1\" | $SED \\\n\t    -e \"$sed_double_quote_subst\" -e \"$sed_double_backslash\"` ;;\n      *)\n        _G_arg=$1 ;;\n    esac\n\n    case $_G_arg in\n      # Double-quote args containing shell metacharacters to delay\n      # word splitting and command substitution for a subsequent eval.\n      # Many Bourne shells cannot handle close brackets correctly\n      # in scan sets, so we specify it separately.\n      *[\\[\\~\\#\\^\\&\\*\\(\\)\\{\\}\\|\\;\\<\\>\\?\\'\\ \\\t]*|*]*|\"\")\n        _G_arg=\\\"$_G_arg\\\"\n        ;;\n    esac\n\n    func_quote_for_expand_result=$_G_arg\n}\n\n\n# func_stripname PREFIX SUFFIX NAME\n# ---------------------------------\n# strip PREFIX and SUFFIX from NAME, and store in func_stripname_result.\n# PREFIX and SUFFIX must not contain globbing or regex special\n# characters, hashes, percent signs, but SUFFIX may contain a leading\n# dot (in which case that matches only a dot).\nif test yes = \"$_G_HAVE_XSI_OPS\"; then\n  eval 'func_stripname ()\n  {\n    $debug_cmd\n\n    # pdksh 5.2.14 does not do ${X%$Y} correctly if both X and Y are\n    # positional parameters, so assign one to ordinary variable first.\n    func_stripname_result=$3\n    func_stripname_result=${func_stripname_result#\"$1\"}\n    func_stripname_result=${func_stripname_result%\"$2\"}\n  }'\nelse\n  func_stripname ()\n  {\n    $debug_cmd\n\n    case $2 in\n      .*) func_stripname_result=`$ECHO \"$3\" | $SED -e \"s%^$1%%\" -e \"s%\\\\\\\\$2\\$%%\"`;;\n      *)  func_stripname_result=`$ECHO \"$3\" | $SED -e \"s%^$1%%\" -e \"s%$2\\$%%\"`;;\n    esac\n  }\nfi\n\n\n# func_show_eval CMD [FAIL_EXP]\n# -----------------------------\n# Unless opt_quiet is true, then output CMD.  Then, if opt_dryrun is\n# not true, evaluate CMD.  If the evaluation of CMD fails, and FAIL_EXP\n# is given, then evaluate it.\nfunc_show_eval ()\n{\n    $debug_cmd\n\n    _G_cmd=$1\n    _G_fail_exp=${2-':'}\n\n    func_quote_for_expand \"$_G_cmd\"\n    eval \"func_notquiet $func_quote_for_expand_result\"\n\n    $opt_dry_run || {\n      eval \"$_G_cmd\"\n      _G_status=$?\n      if test 0 -ne \"$_G_status\"; then\n\teval \"(exit $_G_status); $_G_fail_exp\"\n      fi\n    }\n}\n\n\n# func_show_eval_locale CMD [FAIL_EXP]\n# ------------------------------------\n# Unless opt_quiet is true, then output CMD.  Then, if opt_dryrun is\n# not true, evaluate CMD.  If the evaluation of CMD fails, and FAIL_EXP\n# is given, then evaluate it.  Use the saved locale for evaluation.\nfunc_show_eval_locale ()\n{\n    $debug_cmd\n\n    _G_cmd=$1\n    _G_fail_exp=${2-':'}\n\n    $opt_quiet || {\n      func_quote_for_expand \"$_G_cmd\"\n      eval \"func_echo $func_quote_for_expand_result\"\n    }\n\n    $opt_dry_run || {\n      eval \"$_G_user_locale\n\t    $_G_cmd\"\n      _G_status=$?\n      eval \"$_G_safe_locale\"\n      if test 0 -ne \"$_G_status\"; then\n\teval \"(exit $_G_status); $_G_fail_exp\"\n      fi\n    }\n}\n\n\n# func_tr_sh\n# ----------\n# Turn $1 into a string suitable for a shell variable name.\n# Result is stored in $func_tr_sh_result.  All characters\n# not in the set a-zA-Z0-9_ are replaced with '_'. Further,\n# if $1 begins with a digit, a '_' is prepended as well.\nfunc_tr_sh ()\n{\n    $debug_cmd\n\n    case $1 in\n    [0-9]* | *[!a-zA-Z0-9_]*)\n      func_tr_sh_result=`$ECHO \"$1\" | $SED -e 's/^\\([0-9]\\)/_\\1/' -e 's/[^a-zA-Z0-9_]/_/g'`\n      ;;\n    * )\n      func_tr_sh_result=$1\n      ;;\n    esac\n}\n\n\n# func_verbose ARG...\n# -------------------\n# Echo program name prefixed message in verbose mode only.\nfunc_verbose ()\n{\n    $debug_cmd\n\n    $opt_verbose && func_echo \"$*\"\n\n    :\n}\n\n\n# func_warn_and_continue ARG...\n# -----------------------------\n# Echo program name prefixed warning message to standard error.\nfunc_warn_and_continue ()\n{\n    $debug_cmd\n\n    $require_term_colors\n\n    func_echo_infix_1 \"${tc_red}warning$tc_reset\" \"$*\" >&2\n}\n\n\n# func_warning CATEGORY ARG...\n# ----------------------------\n# Echo program name prefixed warning message to standard error. Warning\n# messages can be filtered according to CATEGORY, where this function\n# elides messages where CATEGORY is not listed in the global variable\n# 'opt_warning_types'.\nfunc_warning ()\n{\n    $debug_cmd\n\n    # CATEGORY must be in the warning_categories list!\n    case \" $warning_categories \" in\n      *\" $1 \"*) ;;\n      *) func_internal_error \"invalid warning category '$1'\" ;;\n    esac\n\n    _G_category=$1\n    shift\n\n    case \" $opt_warning_types \" in\n      *\" $_G_category \"*) $warning_func ${1+\"$@\"} ;;\n    esac\n}\n\n\n# func_sort_ver VER1 VER2\n# -----------------------\n# 'sort -V' is not generally available.\n# Note this deviates from the version comparison in automake\n# in that it treats 1.5 < 1.5.0, and treats 1.4.4a < 1.4-p3a\n# but this should suffice as we won't be specifying old\n# version formats or redundant trailing .0 in bootstrap.conf.\n# If we did want full compatibility then we should probably\n# use m4_version_compare from autoconf.\nfunc_sort_ver ()\n{\n    $debug_cmd\n\n    printf '%s\\n%s\\n' \"$1\" \"$2\" \\\n      | sort -t. -k 1,1n -k 2,2n -k 3,3n -k 4,4n -k 5,5n -k 6,6n -k 7,7n -k 8,8n -k 9,9n\n}\n\n# func_lt_ver PREV CURR\n# ---------------------\n# Return true if PREV and CURR are in the correct order according to\n# func_sort_ver, otherwise false.  Use it like this:\n#\n#  func_lt_ver \"$prev_ver\" \"$proposed_ver\" || func_fatal_error \"...\"\nfunc_lt_ver ()\n{\n    $debug_cmd\n\n    test \"x$1\" = x`func_sort_ver \"$1\" \"$2\" | $SED 1q`\n}\n\n\n# Local variables:\n# mode: shell-script\n# sh-indentation: 2\n# eval: (add-hook 'before-save-hook 'time-stamp)\n# time-stamp-pattern: \"10/scriptversion=%:y-%02m-%02d.%02H; # UTC\"\n# time-stamp-time-zone: \"UTC\"\n# End:\n#! /bin/sh\n\n# Set a version string for this script.\nscriptversion=2014-01-07.03; # UTC\n\n# A portable, pluggable option parser for Bourne shell.\n# Written by Gary V. Vaughan, 2010\n\n# Copyright (C) 2010-2015 Free Software Foundation, Inc.\n# This is free software; see the source for copying conditions.  There is NO\n# warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n\n# You should have received a copy of the GNU General Public License\n# along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\n# Please report bugs or propose patches to gary@gnu.org.\n\n\n## ------ ##\n## Usage. ##\n## ------ ##\n\n# This file is a library for parsing options in your shell scripts along\n# with assorted other useful supporting features that you can make use\n# of too.\n#\n# For the simplest scripts you might need only:\n#\n#   #!/bin/sh\n#   . relative/path/to/funclib.sh\n#   . relative/path/to/options-parser\n#   scriptversion=1.0\n#   func_options ${1+\"$@\"}\n#   eval set dummy \"$func_options_result\"; shift\n#   ...rest of your script...\n#\n# In order for the '--version' option to work, you will need to have a\n# suitably formatted comment like the one at the top of this file\n# starting with '# Written by ' and ending with '# warranty; '.\n#\n# For '-h' and '--help' to work, you will also need a one line\n# description of your script's purpose in a comment directly above the\n# '# Written by ' line, like the one at the top of this file.\n#\n# The default options also support '--debug', which will turn on shell\n# execution tracing (see the comment above debug_cmd below for another\n# use), and '--verbose' and the func_verbose function to allow your script\n# to display verbose messages only when your user has specified\n# '--verbose'.\n#\n# After sourcing this file, you can plug processing for additional\n# options by amending the variables from the 'Configuration' section\n# below, and following the instructions in the 'Option parsing'\n# section further down.\n\n## -------------- ##\n## Configuration. ##\n## -------------- ##\n\n# You should override these variables in your script after sourcing this\n# file so that they reflect the customisations you have added to the\n# option parser.\n\n# The usage line for option parsing errors and the start of '-h' and\n# '--help' output messages. You can embed shell variables for delayed\n# expansion at the time the message is displayed, but you will need to\n# quote other shell meta-characters carefully to prevent them being\n# expanded when the contents are evaled.\nusage='$progpath [OPTION]...'\n\n# Short help message in response to '-h' and '--help'.  Add to this or\n# override it after sourcing this library to reflect the full set of\n# options your script accepts.\nusage_message=\"\\\n       --debug        enable verbose shell tracing\n   -W, --warnings=CATEGORY\n                      report the warnings falling in CATEGORY [all]\n   -v, --verbose      verbosely report processing\n       --version      print version information and exit\n   -h, --help         print short or long help message and exit\n\"\n\n# Additional text appended to 'usage_message' in response to '--help'.\nlong_help_message=\"\nWarning categories include:\n       'all'          show all warnings\n       'none'         turn off all the warnings\n       'error'        warnings are treated as fatal errors\"\n\n# Help message printed before fatal option parsing errors.\nfatal_help=\"Try '\\$progname --help' for more information.\"\n\n\n\n## ------------------------- ##\n## Hook function management. ##\n## ------------------------- ##\n\n# This section contains functions for adding, removing, and running hooks\n# to the main code.  A hook is just a named list of of function, that can\n# be run in order later on.\n\n# func_hookable FUNC_NAME\n# -----------------------\n# Declare that FUNC_NAME will run hooks added with\n# 'func_add_hook FUNC_NAME ...'.\nfunc_hookable ()\n{\n    $debug_cmd\n\n    func_append hookable_fns \" $1\"\n}\n\n\n# func_add_hook FUNC_NAME HOOK_FUNC\n# ---------------------------------\n# Request that FUNC_NAME call HOOK_FUNC before it returns.  FUNC_NAME must\n# first have been declared \"hookable\" by a call to 'func_hookable'.\nfunc_add_hook ()\n{\n    $debug_cmd\n\n    case \" $hookable_fns \" in\n      *\" $1 \"*) ;;\n      *) func_fatal_error \"'$1' does not accept hook functions.\" ;;\n    esac\n\n    eval func_append ${1}_hooks '\" $2\"'\n}\n\n\n# func_remove_hook FUNC_NAME HOOK_FUNC\n# ------------------------------------\n# Remove HOOK_FUNC from the list of functions called by FUNC_NAME.\nfunc_remove_hook ()\n{\n    $debug_cmd\n\n    eval ${1}_hooks='`$ECHO \"\\$'$1'_hooks\" |$SED \"s| '$2'||\"`'\n}\n\n\n# func_run_hooks FUNC_NAME [ARG]...\n# ---------------------------------\n# Run all hook functions registered to FUNC_NAME.\n# It is assumed that the list of hook functions contains nothing more\n# than a whitespace-delimited list of legal shell function names, and\n# no effort is wasted trying to catch shell meta-characters or preserve\n# whitespace.\nfunc_run_hooks ()\n{\n    $debug_cmd\n\n    case \" $hookable_fns \" in\n      *\" $1 \"*) ;;\n      *) func_fatal_error \"'$1' does not support hook funcions.n\" ;;\n    esac\n\n    eval _G_hook_fns=\\$$1_hooks; shift\n\n    for _G_hook in $_G_hook_fns; do\n      eval $_G_hook '\"$@\"'\n\n      # store returned options list back into positional\n      # parameters for next 'cmd' execution.\n      eval _G_hook_result=\\$${_G_hook}_result\n      eval set dummy \"$_G_hook_result\"; shift\n    done\n\n    func_quote_for_eval ${1+\"$@\"}\n    func_run_hooks_result=$func_quote_for_eval_result\n}\n\n\n\n## --------------- ##\n## Option parsing. ##\n## --------------- ##\n\n# In order to add your own option parsing hooks, you must accept the\n# full positional parameter list in your hook function, remove any\n# options that you action, and then pass back the remaining unprocessed\n# options in '<hooked_function_name>_result', escaped suitably for\n# 'eval'.  Like this:\n#\n#    my_options_prep ()\n#    {\n#        $debug_cmd\n#\n#        # Extend the existing usage message.\n#        usage_message=$usage_message'\n#      -s, --silent       don'\\''t print informational messages\n#    '\n#\n#        func_quote_for_eval ${1+\"$@\"}\n#        my_options_prep_result=$func_quote_for_eval_result\n#    }\n#    func_add_hook func_options_prep my_options_prep\n#\n#\n#    my_silent_option ()\n#    {\n#        $debug_cmd\n#\n#        # Note that for efficiency, we parse as many options as we can\n#        # recognise in a loop before passing the remainder back to the\n#        # caller on the first unrecognised argument we encounter.\n#        while test $# -gt 0; do\n#          opt=$1; shift\n#          case $opt in\n#            --silent|-s) opt_silent=: ;;\n#            # Separate non-argument short options:\n#            -s*)         func_split_short_opt \"$_G_opt\"\n#                         set dummy \"$func_split_short_opt_name\" \\\n#                             \"-$func_split_short_opt_arg\" ${1+\"$@\"}\n#                         shift\n#                         ;;\n#            *)            set dummy \"$_G_opt\" \"$*\"; shift; break ;;\n#          esac\n#        done\n#\n#        func_quote_for_eval ${1+\"$@\"}\n#        my_silent_option_result=$func_quote_for_eval_result\n#    }\n#    func_add_hook func_parse_options my_silent_option\n#\n#\n#    my_option_validation ()\n#    {\n#        $debug_cmd\n#\n#        $opt_silent && $opt_verbose && func_fatal_help \"\\\n#    '--silent' and '--verbose' options are mutually exclusive.\"\n#\n#        func_quote_for_eval ${1+\"$@\"}\n#        my_option_validation_result=$func_quote_for_eval_result\n#    }\n#    func_add_hook func_validate_options my_option_validation\n#\n# You'll alse need to manually amend $usage_message to reflect the extra\n# options you parse.  It's preferable to append if you can, so that\n# multiple option parsing hooks can be added safely.\n\n\n# func_options [ARG]...\n# ---------------------\n# All the functions called inside func_options are hookable. See the\n# individual implementations for details.\nfunc_hookable func_options\nfunc_options ()\n{\n    $debug_cmd\n\n    func_options_prep ${1+\"$@\"}\n    eval func_parse_options \\\n        ${func_options_prep_result+\"$func_options_prep_result\"}\n    eval func_validate_options \\\n        ${func_parse_options_result+\"$func_parse_options_result\"}\n\n    eval func_run_hooks func_options \\\n        ${func_validate_options_result+\"$func_validate_options_result\"}\n\n    # save modified positional parameters for caller\n    func_options_result=$func_run_hooks_result\n}\n\n\n# func_options_prep [ARG]...\n# --------------------------\n# All initialisations required before starting the option parse loop.\n# Note that when calling hook functions, we pass through the list of\n# positional parameters.  If a hook function modifies that list, and\n# needs to propogate that back to rest of this script, then the complete\n# modified list must be put in 'func_run_hooks_result' before\n# returning.\nfunc_hookable func_options_prep\nfunc_options_prep ()\n{\n    $debug_cmd\n\n    # Option defaults:\n    opt_verbose=false\n    opt_warning_types=\n\n    func_run_hooks func_options_prep ${1+\"$@\"}\n\n    # save modified positional parameters for caller\n    func_options_prep_result=$func_run_hooks_result\n}\n\n\n# func_parse_options [ARG]...\n# ---------------------------\n# The main option parsing loop.\nfunc_hookable func_parse_options\nfunc_parse_options ()\n{\n    $debug_cmd\n\n    func_parse_options_result=\n\n    # this just eases exit handling\n    while test $# -gt 0; do\n      # Defer to hook functions for initial option parsing, so they\n      # get priority in the event of reusing an option name.\n      func_run_hooks func_parse_options ${1+\"$@\"}\n\n      # Adjust func_parse_options positional parameters to match\n      eval set dummy \"$func_run_hooks_result\"; shift\n\n      # Break out of the loop if we already parsed every option.\n      test $# -gt 0 || break\n\n      _G_opt=$1\n      shift\n      case $_G_opt in\n        --debug|-x)   debug_cmd='set -x'\n                      func_echo \"enabling shell trace mode\"\n                      $debug_cmd\n                      ;;\n\n        --no-warnings|--no-warning|--no-warn)\n                      set dummy --warnings none ${1+\"$@\"}\n                      shift\n\t\t      ;;\n\n        --warnings|--warning|-W)\n                      test $# = 0 && func_missing_arg $_G_opt && break\n                      case \" $warning_categories $1\" in\n                        *\" $1 \"*)\n                          # trailing space prevents matching last $1 above\n                          func_append_uniq opt_warning_types \" $1\"\n                          ;;\n                        *all)\n                          opt_warning_types=$warning_categories\n                          ;;\n                        *none)\n                          opt_warning_types=none\n                          warning_func=:\n                          ;;\n                        *error)\n                          opt_warning_types=$warning_categories\n                          warning_func=func_fatal_error\n                          ;;\n                        *)\n                          func_fatal_error \\\n                             \"unsupported warning category: '$1'\"\n                          ;;\n                      esac\n                      shift\n                      ;;\n\n        --verbose|-v) opt_verbose=: ;;\n        --version)    func_version ;;\n        -\\?|-h)       func_usage ;;\n        --help)       func_help ;;\n\n\t# Separate optargs to long options (plugins may need this):\n\t--*=*)        func_split_equals \"$_G_opt\"\n\t              set dummy \"$func_split_equals_lhs\" \\\n                          \"$func_split_equals_rhs\" ${1+\"$@\"}\n                      shift\n                      ;;\n\n       # Separate optargs to short options:\n        -W*)\n                      func_split_short_opt \"$_G_opt\"\n                      set dummy \"$func_split_short_opt_name\" \\\n                          \"$func_split_short_opt_arg\" ${1+\"$@\"}\n                      shift\n                      ;;\n\n        # Separate non-argument short options:\n        -\\?*|-h*|-v*|-x*)\n                      func_split_short_opt \"$_G_opt\"\n                      set dummy \"$func_split_short_opt_name\" \\\n                          \"-$func_split_short_opt_arg\" ${1+\"$@\"}\n                      shift\n                      ;;\n\n        --)           break ;;\n        -*)           func_fatal_help \"unrecognised option: '$_G_opt'\" ;;\n        *)            set dummy \"$_G_opt\" ${1+\"$@\"}; shift; break ;;\n      esac\n    done\n\n    # save modified positional parameters for caller\n    func_quote_for_eval ${1+\"$@\"}\n    func_parse_options_result=$func_quote_for_eval_result\n}\n\n\n# func_validate_options [ARG]...\n# ------------------------------\n# Perform any sanity checks on option settings and/or unconsumed\n# arguments.\nfunc_hookable func_validate_options\nfunc_validate_options ()\n{\n    $debug_cmd\n\n    # Display all warnings if -W was not given.\n    test -n \"$opt_warning_types\" || opt_warning_types=\" $warning_categories\"\n\n    func_run_hooks func_validate_options ${1+\"$@\"}\n\n    # Bail if the options were screwed!\n    $exit_cmd $EXIT_FAILURE\n\n    # save modified positional parameters for caller\n    func_validate_options_result=$func_run_hooks_result\n}\n\n\n\n## ----------------- ##\n## Helper functions. ##\n## ----------------- ##\n\n# This section contains the helper functions used by the rest of the\n# hookable option parser framework in ascii-betical order.\n\n\n# func_fatal_help ARG...\n# ----------------------\n# Echo program name prefixed message to standard error, followed by\n# a help hint, and exit.\nfunc_fatal_help ()\n{\n    $debug_cmd\n\n    eval \\$ECHO \\\"\"Usage: $usage\"\\\"\n    eval \\$ECHO \\\"\"$fatal_help\"\\\"\n    func_error ${1+\"$@\"}\n    exit $EXIT_FAILURE\n}\n\n\n# func_help\n# ---------\n# Echo long help message to standard output and exit.\nfunc_help ()\n{\n    $debug_cmd\n\n    func_usage_message\n    $ECHO \"$long_help_message\"\n    exit 0\n}\n\n\n# func_missing_arg ARGNAME\n# ------------------------\n# Echo program name prefixed message to standard error and set global\n# exit_cmd.\nfunc_missing_arg ()\n{\n    $debug_cmd\n\n    func_error \"Missing argument for '$1'.\"\n    exit_cmd=exit\n}\n\n\n# func_split_equals STRING\n# ------------------------\n# Set func_split_equals_lhs and func_split_equals_rhs shell variables after\n# splitting STRING at the '=' sign.\ntest -z \"$_G_HAVE_XSI_OPS\" \\\n    && (eval 'x=a/b/c;\n      test 5aa/bb/cc = \"${#x}${x%%/*}${x%/*}${x#*/}${x##*/}\"') 2>/dev/null \\\n    && _G_HAVE_XSI_OPS=yes\n\nif test yes = \"$_G_HAVE_XSI_OPS\"\nthen\n  # This is an XSI compatible shell, allowing a faster implementation...\n  eval 'func_split_equals ()\n  {\n      $debug_cmd\n\n      func_split_equals_lhs=${1%%=*}\n      func_split_equals_rhs=${1#*=}\n      test \"x$func_split_equals_lhs\" = \"x$1\" \\\n        && func_split_equals_rhs=\n  }'\nelse\n  # ...otherwise fall back to using expr, which is often a shell builtin.\n  func_split_equals ()\n  {\n      $debug_cmd\n\n      func_split_equals_lhs=`expr \"x$1\" : 'x\\([^=]*\\)'`\n      func_split_equals_rhs=\n      test \"x$func_split_equals_lhs\" = \"x$1\" \\\n        || func_split_equals_rhs=`expr \"x$1\" : 'x[^=]*=\\(.*\\)$'`\n  }\nfi #func_split_equals\n\n\n# func_split_short_opt SHORTOPT\n# -----------------------------\n# Set func_split_short_opt_name and func_split_short_opt_arg shell\n# variables after splitting SHORTOPT after the 2nd character.\nif test yes = \"$_G_HAVE_XSI_OPS\"\nthen\n  # This is an XSI compatible shell, allowing a faster implementation...\n  eval 'func_split_short_opt ()\n  {\n      $debug_cmd\n\n      func_split_short_opt_arg=${1#??}\n      func_split_short_opt_name=${1%\"$func_split_short_opt_arg\"}\n  }'\nelse\n  # ...otherwise fall back to using expr, which is often a shell builtin.\n  func_split_short_opt ()\n  {\n      $debug_cmd\n\n      func_split_short_opt_name=`expr \"x$1\" : 'x-\\(.\\)'`\n      func_split_short_opt_arg=`expr \"x$1\" : 'x-.\\(.*\\)$'`\n  }\nfi #func_split_short_opt\n\n\n# func_usage\n# ----------\n# Echo short help message to standard output and exit.\nfunc_usage ()\n{\n    $debug_cmd\n\n    func_usage_message\n    $ECHO \"Run '$progname --help |${PAGER-more}' for full usage\"\n    exit 0\n}\n\n\n# func_usage_message\n# ------------------\n# Echo short help message to standard output.\nfunc_usage_message ()\n{\n    $debug_cmd\n\n    eval \\$ECHO \\\"\"Usage: $usage\"\\\"\n    echo\n    $SED -n 's|^# ||\n        /^Written by/{\n          x;p;x\n        }\n\th\n\t/^Written by/q' < \"$progpath\"\n    echo\n    eval \\$ECHO \\\"\"$usage_message\"\\\"\n}\n\n\n# func_version\n# ------------\n# Echo version message to standard output and exit.\nfunc_version ()\n{\n    $debug_cmd\n\n    printf '%s\\n' \"$progname $scriptversion\"\n    $SED -n '\n        /(C)/!b go\n        :more\n        /\\./!{\n          N\n          s|\\n# | |\n          b more\n        }\n        :go\n        /^# Written by /,/# warranty; / {\n          s|^# ||\n          s|^# *$||\n          s|\\((C)\\)[ 0-9,-]*[ ,-]\\([1-9][0-9]* \\)|\\1 \\2|\n          p\n        }\n        /^# Written by / {\n          s|^# ||\n          p\n        }\n        /^warranty; /q' < \"$progpath\"\n\n    exit $?\n}\n\n\n# Local variables:\n# mode: shell-script\n# sh-indentation: 2\n# eval: (add-hook 'before-save-hook 'time-stamp)\n# time-stamp-pattern: \"10/scriptversion=%:y-%02m-%02d.%02H; # UTC\"\n# time-stamp-time-zone: \"UTC\"\n# End:\n\n# Set a version string.\nscriptversion='(GNU libtool) 2.4.6'\n\n\n# func_echo ARG...\n# ----------------\n# Libtool also displays the current mode in messages, so override\n# funclib.sh func_echo with this custom definition.\nfunc_echo ()\n{\n    $debug_cmd\n\n    _G_message=$*\n\n    func_echo_IFS=$IFS\n    IFS=$nl\n    for _G_line in $_G_message; do\n      IFS=$func_echo_IFS\n      $ECHO \"$progname${opt_mode+: $opt_mode}: $_G_line\"\n    done\n    IFS=$func_echo_IFS\n}\n\n\n# func_warning ARG...\n# -------------------\n# Libtool warnings are not categorized, so override funclib.sh\n# func_warning with this simpler definition.\nfunc_warning ()\n{\n    $debug_cmd\n\n    $warning_func ${1+\"$@\"}\n}\n\n\n## ---------------- ##\n## Options parsing. ##\n## ---------------- ##\n\n# Hook in the functions to make sure our own options are parsed during\n# the option parsing loop.\n\nusage='$progpath [OPTION]... [MODE-ARG]...'\n\n# Short help message in response to '-h'.\nusage_message=\"Options:\n       --config             show all configuration variables\n       --debug              enable verbose shell tracing\n   -n, --dry-run            display commands without modifying any files\n       --features           display basic configuration information and exit\n       --mode=MODE          use operation mode MODE\n       --no-warnings        equivalent to '-Wnone'\n       --preserve-dup-deps  don't remove duplicate dependency libraries\n       --quiet, --silent    don't print informational messages\n       --tag=TAG            use configuration variables from tag TAG\n   -v, --verbose            print more informational messages than default\n       --version            print version information\n   -W, --warnings=CATEGORY  report the warnings falling in CATEGORY [all]\n   -h, --help, --help-all   print short, long, or detailed help message\n\"\n\n# Additional text appended to 'usage_message' in response to '--help'.\nfunc_help ()\n{\n    $debug_cmd\n\n    func_usage_message\n    $ECHO \"$long_help_message\n\nMODE must be one of the following:\n\n       clean           remove files from the build directory\n       compile         compile a source file into a libtool object\n       execute         automatically set library path, then run a program\n       finish          complete the installation of libtool libraries\n       install         install libraries or executables\n       link            create a library or an executable\n       uninstall       remove libraries from an installed directory\n\nMODE-ARGS vary depending on the MODE.  When passed as first option,\n'--mode=MODE' may be abbreviated as 'MODE' or a unique abbreviation of that.\nTry '$progname --help --mode=MODE' for a more detailed description of MODE.\n\nWhen reporting a bug, please describe a test case to reproduce it and\ninclude the following information:\n\n       host-triplet:   $host\n       shell:          $SHELL\n       compiler:       $LTCC\n       compiler flags: $LTCFLAGS\n       linker:         $LD (gnu? $with_gnu_ld)\n       version:        $progname $scriptversion Debian-2.4.6-2\n       automake:       `($AUTOMAKE --version) 2>/dev/null |$SED 1q`\n       autoconf:       `($AUTOCONF --version) 2>/dev/null |$SED 1q`\n\nReport bugs to <bug-libtool@gnu.org>.\nGNU libtool home page: <http://www.gnu.org/s/libtool/>.\nGeneral help using GNU software: <http://www.gnu.org/gethelp/>.\"\n    exit 0\n}\n\n\n# func_lo2o OBJECT-NAME\n# ---------------------\n# Transform OBJECT-NAME from a '.lo' suffix to the platform specific\n# object suffix.\n\nlo2o=s/\\\\.lo\\$/.$objext/\no2lo=s/\\\\.$objext\\$/.lo/\n\nif test yes = \"$_G_HAVE_XSI_OPS\"; then\n  eval 'func_lo2o ()\n  {\n    case $1 in\n      *.lo) func_lo2o_result=${1%.lo}.$objext ;;\n      *   ) func_lo2o_result=$1               ;;\n    esac\n  }'\n\n  # func_xform LIBOBJ-OR-SOURCE\n  # ---------------------------\n  # Transform LIBOBJ-OR-SOURCE from a '.o' or '.c' (or otherwise)\n  # suffix to a '.lo' libtool-object suffix.\n  eval 'func_xform ()\n  {\n    func_xform_result=${1%.*}.lo\n  }'\nelse\n  # ...otherwise fall back to using sed.\n  func_lo2o ()\n  {\n    func_lo2o_result=`$ECHO \"$1\" | $SED \"$lo2o\"`\n  }\n\n  func_xform ()\n  {\n    func_xform_result=`$ECHO \"$1\" | $SED 's|\\.[^.]*$|.lo|'`\n  }\nfi\n\n\n# func_fatal_configuration ARG...\n# -------------------------------\n# Echo program name prefixed message to standard error, followed by\n# a configuration failure hint, and exit.\nfunc_fatal_configuration ()\n{\n    func__fatal_error ${1+\"$@\"} \\\n      \"See the $PACKAGE documentation for more information.\" \\\n      \"Fatal configuration error.\"\n}\n\n\n# func_config\n# -----------\n# Display the configuration for all the tags in this script.\nfunc_config ()\n{\n    re_begincf='^# ### BEGIN LIBTOOL'\n    re_endcf='^# ### END LIBTOOL'\n\n    # Default configuration.\n    $SED \"1,/$re_begincf CONFIG/d;/$re_endcf CONFIG/,\\$d\" < \"$progpath\"\n\n    # Now print the configurations for the tags.\n    for tagname in $taglist; do\n      $SED -n \"/$re_begincf TAG CONFIG: $tagname\\$/,/$re_endcf TAG CONFIG: $tagname\\$/p\" < \"$progpath\"\n    done\n\n    exit $?\n}\n\n\n# func_features\n# -------------\n# Display the features supported by this script.\nfunc_features ()\n{\n    echo \"host: $host\"\n    if test yes = \"$build_libtool_libs\"; then\n      echo \"enable shared libraries\"\n    else\n      echo \"disable shared libraries\"\n    fi\n    if test yes = \"$build_old_libs\"; then\n      echo \"enable static libraries\"\n    else\n      echo \"disable static libraries\"\n    fi\n\n    exit $?\n}\n\n\n# func_enable_tag TAGNAME\n# -----------------------\n# Verify that TAGNAME is valid, and either flag an error and exit, or\n# enable the TAGNAME tag.  We also add TAGNAME to the global $taglist\n# variable here.\nfunc_enable_tag ()\n{\n    # Global variable:\n    tagname=$1\n\n    re_begincf=\"^# ### BEGIN LIBTOOL TAG CONFIG: $tagname\\$\"\n    re_endcf=\"^# ### END LIBTOOL TAG CONFIG: $tagname\\$\"\n    sed_extractcf=/$re_begincf/,/$re_endcf/p\n\n    # Validate tagname.\n    case $tagname in\n      *[!-_A-Za-z0-9,/]*)\n        func_fatal_error \"invalid tag name: $tagname\"\n        ;;\n    esac\n\n    # Don't test for the \"default\" C tag, as we know it's\n    # there but not specially marked.\n    case $tagname in\n        CC) ;;\n    *)\n        if $GREP \"$re_begincf\" \"$progpath\" >/dev/null 2>&1; then\n\t  taglist=\"$taglist $tagname\"\n\n\t  # Evaluate the configuration.  Be careful to quote the path\n\t  # and the sed script, to avoid splitting on whitespace, but\n\t  # also don't use non-portable quotes within backquotes within\n\t  # quotes we have to do it in 2 steps:\n\t  extractedcf=`$SED -n -e \"$sed_extractcf\" < \"$progpath\"`\n\t  eval \"$extractedcf\"\n        else\n\t  func_error \"ignoring unknown tag $tagname\"\n        fi\n        ;;\n    esac\n}\n\n\n# func_check_version_match\n# ------------------------\n# Ensure that we are using m4 macros, and libtool script from the same\n# release of libtool.\nfunc_check_version_match ()\n{\n    if test \"$package_revision\" != \"$macro_revision\"; then\n      if test \"$VERSION\" != \"$macro_version\"; then\n        if test -z \"$macro_version\"; then\n          cat >&2 <<_LT_EOF\n$progname: Version mismatch error.  This is $PACKAGE $VERSION, but the\n$progname: definition of this LT_INIT comes from an older release.\n$progname: You should recreate aclocal.m4 with macros from $PACKAGE $VERSION\n$progname: and run autoconf again.\n_LT_EOF\n        else\n          cat >&2 <<_LT_EOF\n$progname: Version mismatch error.  This is $PACKAGE $VERSION, but the\n$progname: definition of this LT_INIT comes from $PACKAGE $macro_version.\n$progname: You should recreate aclocal.m4 with macros from $PACKAGE $VERSION\n$progname: and run autoconf again.\n_LT_EOF\n        fi\n      else\n        cat >&2 <<_LT_EOF\n$progname: Version mismatch error.  This is $PACKAGE $VERSION, revision $package_revision,\n$progname: but the definition of this LT_INIT comes from revision $macro_revision.\n$progname: You should recreate aclocal.m4 with macros from revision $package_revision\n$progname: of $PACKAGE $VERSION and run autoconf again.\n_LT_EOF\n      fi\n\n      exit $EXIT_MISMATCH\n    fi\n}\n\n\n# libtool_options_prep [ARG]...\n# -----------------------------\n# Preparation for options parsed by libtool.\nlibtool_options_prep ()\n{\n    $debug_mode\n\n    # Option defaults:\n    opt_config=false\n    opt_dlopen=\n    opt_dry_run=false\n    opt_help=false\n    opt_mode=\n    opt_preserve_dup_deps=false\n    opt_quiet=false\n\n    nonopt=\n    preserve_args=\n\n    # Shorthand for --mode=foo, only valid as the first argument\n    case $1 in\n    clean|clea|cle|cl)\n      shift; set dummy --mode clean ${1+\"$@\"}; shift\n      ;;\n    compile|compil|compi|comp|com|co|c)\n      shift; set dummy --mode compile ${1+\"$@\"}; shift\n      ;;\n    execute|execut|execu|exec|exe|ex|e)\n      shift; set dummy --mode execute ${1+\"$@\"}; shift\n      ;;\n    finish|finis|fini|fin|fi|f)\n      shift; set dummy --mode finish ${1+\"$@\"}; shift\n      ;;\n    install|instal|insta|inst|ins|in|i)\n      shift; set dummy --mode install ${1+\"$@\"}; shift\n      ;;\n    link|lin|li|l)\n      shift; set dummy --mode link ${1+\"$@\"}; shift\n      ;;\n    uninstall|uninstal|uninsta|uninst|unins|unin|uni|un|u)\n      shift; set dummy --mode uninstall ${1+\"$@\"}; shift\n      ;;\n    esac\n\n    # Pass back the list of options.\n    func_quote_for_eval ${1+\"$@\"}\n    libtool_options_prep_result=$func_quote_for_eval_result\n}\nfunc_add_hook func_options_prep libtool_options_prep\n\n\n# libtool_parse_options [ARG]...\n# ---------------------------------\n# Provide handling for libtool specific options.\nlibtool_parse_options ()\n{\n    $debug_cmd\n\n    # Perform our own loop to consume as many options as possible in\n    # each iteration.\n    while test $# -gt 0; do\n      _G_opt=$1\n      shift\n      case $_G_opt in\n        --dry-run|--dryrun|-n)\n                        opt_dry_run=:\n                        ;;\n\n        --config)       func_config ;;\n\n        --dlopen|-dlopen)\n                        opt_dlopen=\"${opt_dlopen+$opt_dlopen\n}$1\"\n                        shift\n                        ;;\n\n        --preserve-dup-deps)\n                        opt_preserve_dup_deps=: ;;\n\n        --features)     func_features ;;\n\n        --finish)       set dummy --mode finish ${1+\"$@\"}; shift ;;\n\n        --help)         opt_help=: ;;\n\n        --help-all)     opt_help=': help-all' ;;\n\n        --mode)         test $# = 0 && func_missing_arg $_G_opt && break\n                        opt_mode=$1\n                        case $1 in\n                          # Valid mode arguments:\n                          clean|compile|execute|finish|install|link|relink|uninstall) ;;\n\n                          # Catch anything else as an error\n                          *) func_error \"invalid argument for $_G_opt\"\n                             exit_cmd=exit\n                             break\n                             ;;\n                        esac\n                        shift\n                        ;;\n\n        --no-silent|--no-quiet)\n                        opt_quiet=false\n                        func_append preserve_args \" $_G_opt\"\n                        ;;\n\n        --no-warnings|--no-warning|--no-warn)\n                        opt_warning=false\n                        func_append preserve_args \" $_G_opt\"\n                        ;;\n\n        --no-verbose)\n                        opt_verbose=false\n                        func_append preserve_args \" $_G_opt\"\n                        ;;\n\n        --silent|--quiet)\n                        opt_quiet=:\n                        opt_verbose=false\n                        func_append preserve_args \" $_G_opt\"\n                        ;;\n\n        --tag)          test $# = 0 && func_missing_arg $_G_opt && break\n                        opt_tag=$1\n                        func_append preserve_args \" $_G_opt $1\"\n                        func_enable_tag \"$1\"\n                        shift\n                        ;;\n\n        --verbose|-v)   opt_quiet=false\n                        opt_verbose=:\n                        func_append preserve_args \" $_G_opt\"\n                        ;;\n\n\t# An option not handled by this hook function:\n        *)\t\tset dummy \"$_G_opt\" ${1+\"$@\"};\tshift; break  ;;\n      esac\n    done\n\n\n    # save modified positional parameters for caller\n    func_quote_for_eval ${1+\"$@\"}\n    libtool_parse_options_result=$func_quote_for_eval_result\n}\nfunc_add_hook func_parse_options libtool_parse_options\n\n\n\n# libtool_validate_options [ARG]...\n# ---------------------------------\n# Perform any sanity checks on option settings and/or unconsumed\n# arguments.\nlibtool_validate_options ()\n{\n    # save first non-option argument\n    if test 0 -lt $#; then\n      nonopt=$1\n      shift\n    fi\n\n    # preserve --debug\n    test : = \"$debug_cmd\" || func_append preserve_args \" --debug\"\n\n    case $host in\n      # Solaris2 added to fix http://debbugs.gnu.org/cgi/bugreport.cgi?bug=16452\n      # see also: http://gcc.gnu.org/bugzilla/show_bug.cgi?id=59788\n      *cygwin* | *mingw* | *pw32* | *cegcc* | *solaris2* | *os2*)\n        # don't eliminate duplications in $postdeps and $predeps\n        opt_duplicate_compiler_generated_deps=:\n        ;;\n      *)\n        opt_duplicate_compiler_generated_deps=$opt_preserve_dup_deps\n        ;;\n    esac\n\n    $opt_help || {\n      # Sanity checks first:\n      func_check_version_match\n\n      test yes != \"$build_libtool_libs\" \\\n        && test yes != \"$build_old_libs\" \\\n        && func_fatal_configuration \"not configured to build any kind of library\"\n\n      # Darwin sucks\n      eval std_shrext=\\\"$shrext_cmds\\\"\n\n      # Only execute mode is allowed to have -dlopen flags.\n      if test -n \"$opt_dlopen\" && test execute != \"$opt_mode\"; then\n        func_error \"unrecognized option '-dlopen'\"\n        $ECHO \"$help\" 1>&2\n        exit $EXIT_FAILURE\n      fi\n\n      # Change the help message to a mode-specific one.\n      generic_help=$help\n      help=\"Try '$progname --help --mode=$opt_mode' for more information.\"\n    }\n\n    # Pass back the unparsed argument list\n    func_quote_for_eval ${1+\"$@\"}\n    libtool_validate_options_result=$func_quote_for_eval_result\n}\nfunc_add_hook func_validate_options libtool_validate_options\n\n\n# Process options as early as possible so that --help and --version\n# can return quickly.\nfunc_options ${1+\"$@\"}\neval set dummy \"$func_options_result\"; shift\n\n\n\n## ----------- ##\n##    Main.    ##\n## ----------- ##\n\nmagic='%%%MAGIC variable%%%'\nmagic_exe='%%%MAGIC EXE variable%%%'\n\n# Global variables.\nextracted_archives=\nextracted_serial=0\n\n# If this variable is set in any of the actions, the command in it\n# will be execed at the end.  This prevents here-documents from being\n# left over by shells.\nexec_cmd=\n\n\n# A function that is used when there is no print builtin or printf.\nfunc_fallback_echo ()\n{\n  eval 'cat <<_LTECHO_EOF\n$1\n_LTECHO_EOF'\n}\n\n# func_generated_by_libtool\n# True iff stdin has been generated by Libtool. This function is only\n# a basic sanity check; it will hardly flush out determined imposters.\nfunc_generated_by_libtool_p ()\n{\n  $GREP \"^# Generated by .*$PACKAGE\" > /dev/null 2>&1\n}\n\n# func_lalib_p file\n# True iff FILE is a libtool '.la' library or '.lo' object file.\n# This function is only a basic sanity check; it will hardly flush out\n# determined imposters.\nfunc_lalib_p ()\n{\n    test -f \"$1\" &&\n      $SED -e 4q \"$1\" 2>/dev/null | func_generated_by_libtool_p\n}\n\n# func_lalib_unsafe_p file\n# True iff FILE is a libtool '.la' library or '.lo' object file.\n# This function implements the same check as func_lalib_p without\n# resorting to external programs.  To this end, it redirects stdin and\n# closes it afterwards, without saving the original file descriptor.\n# As a safety measure, use it only where a negative result would be\n# fatal anyway.  Works if 'file' does not exist.\nfunc_lalib_unsafe_p ()\n{\n    lalib_p=no\n    if test -f \"$1\" && test -r \"$1\" && exec 5<&0 <\"$1\"; then\n\tfor lalib_p_l in 1 2 3 4\n\tdo\n\t    read lalib_p_line\n\t    case $lalib_p_line in\n\t\t\\#\\ Generated\\ by\\ *$PACKAGE* ) lalib_p=yes; break;;\n\t    esac\n\tdone\n\texec 0<&5 5<&-\n    fi\n    test yes = \"$lalib_p\"\n}\n\n# func_ltwrapper_script_p file\n# True iff FILE is a libtool wrapper script\n# This function is only a basic sanity check; it will hardly flush out\n# determined imposters.\nfunc_ltwrapper_script_p ()\n{\n    test -f \"$1\" &&\n      $lt_truncate_bin < \"$1\" 2>/dev/null | func_generated_by_libtool_p\n}\n\n# func_ltwrapper_executable_p file\n# True iff FILE is a libtool wrapper executable\n# This function is only a basic sanity check; it will hardly flush out\n# determined imposters.\nfunc_ltwrapper_executable_p ()\n{\n    func_ltwrapper_exec_suffix=\n    case $1 in\n    *.exe) ;;\n    *) func_ltwrapper_exec_suffix=.exe ;;\n    esac\n    $GREP \"$magic_exe\" \"$1$func_ltwrapper_exec_suffix\" >/dev/null 2>&1\n}\n\n# func_ltwrapper_scriptname file\n# Assumes file is an ltwrapper_executable\n# uses $file to determine the appropriate filename for a\n# temporary ltwrapper_script.\nfunc_ltwrapper_scriptname ()\n{\n    func_dirname_and_basename \"$1\" \"\" \".\"\n    func_stripname '' '.exe' \"$func_basename_result\"\n    func_ltwrapper_scriptname_result=$func_dirname_result/$objdir/${func_stripname_result}_ltshwrapper\n}\n\n# func_ltwrapper_p file\n# True iff FILE is a libtool wrapper script or wrapper executable\n# This function is only a basic sanity check; it will hardly flush out\n# determined imposters.\nfunc_ltwrapper_p ()\n{\n    func_ltwrapper_script_p \"$1\" || func_ltwrapper_executable_p \"$1\"\n}\n\n\n# func_execute_cmds commands fail_cmd\n# Execute tilde-delimited COMMANDS.\n# If FAIL_CMD is given, eval that upon failure.\n# FAIL_CMD may read-access the current command in variable CMD!\nfunc_execute_cmds ()\n{\n    $debug_cmd\n\n    save_ifs=$IFS; IFS='~'\n    for cmd in $1; do\n      IFS=$sp$nl\n      eval cmd=\\\"$cmd\\\"\n      IFS=$save_ifs\n      func_show_eval \"$cmd\" \"${2-:}\"\n    done\n    IFS=$save_ifs\n}\n\n\n# func_source file\n# Source FILE, adding directory component if necessary.\n# Note that it is not necessary on cygwin/mingw to append a dot to\n# FILE even if both FILE and FILE.exe exist: automatic-append-.exe\n# behavior happens only for exec(3), not for open(2)!  Also, sourcing\n# 'FILE.' does not work on cygwin managed mounts.\nfunc_source ()\n{\n    $debug_cmd\n\n    case $1 in\n    */* | *\\\\*)\t. \"$1\" ;;\n    *)\t\t. \"./$1\" ;;\n    esac\n}\n\n\n# func_resolve_sysroot PATH\n# Replace a leading = in PATH with a sysroot.  Store the result into\n# func_resolve_sysroot_result\nfunc_resolve_sysroot ()\n{\n  func_resolve_sysroot_result=$1\n  case $func_resolve_sysroot_result in\n  =*)\n    func_stripname '=' '' \"$func_resolve_sysroot_result\"\n    func_resolve_sysroot_result=$lt_sysroot$func_stripname_result\n    ;;\n  esac\n}\n\n# func_replace_sysroot PATH\n# If PATH begins with the sysroot, replace it with = and\n# store the result into func_replace_sysroot_result.\nfunc_replace_sysroot ()\n{\n  case $lt_sysroot:$1 in\n  ?*:\"$lt_sysroot\"*)\n    func_stripname \"$lt_sysroot\" '' \"$1\"\n    func_replace_sysroot_result='='$func_stripname_result\n    ;;\n  *)\n    # Including no sysroot.\n    func_replace_sysroot_result=$1\n    ;;\n  esac\n}\n\n# func_infer_tag arg\n# Infer tagged configuration to use if any are available and\n# if one wasn't chosen via the \"--tag\" command line option.\n# Only attempt this if the compiler in the base compile\n# command doesn't match the default compiler.\n# arg is usually of the form 'gcc ...'\nfunc_infer_tag ()\n{\n    $debug_cmd\n\n    if test -n \"$available_tags\" && test -z \"$tagname\"; then\n      CC_quoted=\n      for arg in $CC; do\n\tfunc_append_quoted CC_quoted \"$arg\"\n      done\n      CC_expanded=`func_echo_all $CC`\n      CC_quoted_expanded=`func_echo_all $CC_quoted`\n      case $@ in\n      # Blanks in the command may have been stripped by the calling shell,\n      # but not from the CC environment variable when configure was run.\n      \" $CC \"* | \"$CC \"* | \" $CC_expanded \"* | \"$CC_expanded \"* | \\\n      \" $CC_quoted\"* | \"$CC_quoted \"* | \" $CC_quoted_expanded \"* | \"$CC_quoted_expanded \"*) ;;\n      # Blanks at the start of $base_compile will cause this to fail\n      # if we don't check for them as well.\n      *)\n\tfor z in $available_tags; do\n\t  if $GREP \"^# ### BEGIN LIBTOOL TAG CONFIG: $z$\" < \"$progpath\" > /dev/null; then\n\t    # Evaluate the configuration.\n\t    eval \"`$SED -n -e '/^# ### BEGIN LIBTOOL TAG CONFIG: '$z'$/,/^# ### END LIBTOOL TAG CONFIG: '$z'$/p' < $progpath`\"\n\t    CC_quoted=\n\t    for arg in $CC; do\n\t      # Double-quote args containing other shell metacharacters.\n\t      func_append_quoted CC_quoted \"$arg\"\n\t    done\n\t    CC_expanded=`func_echo_all $CC`\n\t    CC_quoted_expanded=`func_echo_all $CC_quoted`\n\t    case \"$@ \" in\n\t    \" $CC \"* | \"$CC \"* | \" $CC_expanded \"* | \"$CC_expanded \"* | \\\n\t    \" $CC_quoted\"* | \"$CC_quoted \"* | \" $CC_quoted_expanded \"* | \"$CC_quoted_expanded \"*)\n\t      # The compiler in the base compile command matches\n\t      # the one in the tagged configuration.\n\t      # Assume this is the tagged configuration we want.\n\t      tagname=$z\n\t      break\n\t      ;;\n\t    esac\n\t  fi\n\tdone\n\t# If $tagname still isn't set, then no tagged configuration\n\t# was found and let the user know that the \"--tag\" command\n\t# line option must be used.\n\tif test -z \"$tagname\"; then\n\t  func_echo \"unable to infer tagged configuration\"\n\t  func_fatal_error \"specify a tag with '--tag'\"\n#\telse\n#\t  func_verbose \"using $tagname tagged configuration\"\n\tfi\n\t;;\n      esac\n    fi\n}\n\n\n\n# func_write_libtool_object output_name pic_name nonpic_name\n# Create a libtool object file (analogous to a \".la\" file),\n# but don't create it if we're doing a dry run.\nfunc_write_libtool_object ()\n{\n    write_libobj=$1\n    if test yes = \"$build_libtool_libs\"; then\n      write_lobj=\\'$2\\'\n    else\n      write_lobj=none\n    fi\n\n    if test yes = \"$build_old_libs\"; then\n      write_oldobj=\\'$3\\'\n    else\n      write_oldobj=none\n    fi\n\n    $opt_dry_run || {\n      cat >${write_libobj}T <<EOF\n# $write_libobj - a libtool object file\n# Generated by $PROGRAM (GNU $PACKAGE) $VERSION\n#\n# Please DO NOT delete this file!\n# It is necessary for linking the library.\n\n# Name of the PIC object.\npic_object=$write_lobj\n\n# Name of the non-PIC object\nnon_pic_object=$write_oldobj\n\nEOF\n      $MV \"${write_libobj}T\" \"$write_libobj\"\n    }\n}\n\n\n##################################################\n# FILE NAME AND PATH CONVERSION HELPER FUNCTIONS #\n##################################################\n\n# func_convert_core_file_wine_to_w32 ARG\n# Helper function used by file name conversion functions when $build is *nix,\n# and $host is mingw, cygwin, or some other w32 environment. Relies on a\n# correctly configured wine environment available, with the winepath program\n# in $build's $PATH.\n#\n# ARG is the $build file name to be converted to w32 format.\n# Result is available in $func_convert_core_file_wine_to_w32_result, and will\n# be empty on error (or when ARG is empty)\nfunc_convert_core_file_wine_to_w32 ()\n{\n  $debug_cmd\n\n  func_convert_core_file_wine_to_w32_result=$1\n  if test -n \"$1\"; then\n    # Unfortunately, winepath does not exit with a non-zero error code, so we\n    # are forced to check the contents of stdout. On the other hand, if the\n    # command is not found, the shell will set an exit code of 127 and print\n    # *an error message* to stdout. So we must check for both error code of\n    # zero AND non-empty stdout, which explains the odd construction:\n    func_convert_core_file_wine_to_w32_tmp=`winepath -w \"$1\" 2>/dev/null`\n    if test \"$?\" -eq 0 && test -n \"$func_convert_core_file_wine_to_w32_tmp\"; then\n      func_convert_core_file_wine_to_w32_result=`$ECHO \"$func_convert_core_file_wine_to_w32_tmp\" |\n        $SED -e \"$sed_naive_backslashify\"`\n    else\n      func_convert_core_file_wine_to_w32_result=\n    fi\n  fi\n}\n# end: func_convert_core_file_wine_to_w32\n\n\n# func_convert_core_path_wine_to_w32 ARG\n# Helper function used by path conversion functions when $build is *nix, and\n# $host is mingw, cygwin, or some other w32 environment. Relies on a correctly\n# configured wine environment available, with the winepath program in $build's\n# $PATH. Assumes ARG has no leading or trailing path separator characters.\n#\n# ARG is path to be converted from $build format to win32.\n# Result is available in $func_convert_core_path_wine_to_w32_result.\n# Unconvertible file (directory) names in ARG are skipped; if no directory names\n# are convertible, then the result may be empty.\nfunc_convert_core_path_wine_to_w32 ()\n{\n  $debug_cmd\n\n  # unfortunately, winepath doesn't convert paths, only file names\n  func_convert_core_path_wine_to_w32_result=\n  if test -n \"$1\"; then\n    oldIFS=$IFS\n    IFS=:\n    for func_convert_core_path_wine_to_w32_f in $1; do\n      IFS=$oldIFS\n      func_convert_core_file_wine_to_w32 \"$func_convert_core_path_wine_to_w32_f\"\n      if test -n \"$func_convert_core_file_wine_to_w32_result\"; then\n        if test -z \"$func_convert_core_path_wine_to_w32_result\"; then\n          func_convert_core_path_wine_to_w32_result=$func_convert_core_file_wine_to_w32_result\n        else\n          func_append func_convert_core_path_wine_to_w32_result \";$func_convert_core_file_wine_to_w32_result\"\n        fi\n      fi\n    done\n    IFS=$oldIFS\n  fi\n}\n# end: func_convert_core_path_wine_to_w32\n\n\n# func_cygpath ARGS...\n# Wrapper around calling the cygpath program via LT_CYGPATH. This is used when\n# when (1) $build is *nix and Cygwin is hosted via a wine environment; or (2)\n# $build is MSYS and $host is Cygwin, or (3) $build is Cygwin. In case (1) or\n# (2), returns the Cygwin file name or path in func_cygpath_result (input\n# file name or path is assumed to be in w32 format, as previously converted\n# from $build's *nix or MSYS format). In case (3), returns the w32 file name\n# or path in func_cygpath_result (input file name or path is assumed to be in\n# Cygwin format). Returns an empty string on error.\n#\n# ARGS are passed to cygpath, with the last one being the file name or path to\n# be converted.\n#\n# Specify the absolute *nix (or w32) name to cygpath in the LT_CYGPATH\n# environment variable; do not put it in $PATH.\nfunc_cygpath ()\n{\n  $debug_cmd\n\n  if test -n \"$LT_CYGPATH\" && test -f \"$LT_CYGPATH\"; then\n    func_cygpath_result=`$LT_CYGPATH \"$@\" 2>/dev/null`\n    if test \"$?\" -ne 0; then\n      # on failure, ensure result is empty\n      func_cygpath_result=\n    fi\n  else\n    func_cygpath_result=\n    func_error \"LT_CYGPATH is empty or specifies non-existent file: '$LT_CYGPATH'\"\n  fi\n}\n#end: func_cygpath\n\n\n# func_convert_core_msys_to_w32 ARG\n# Convert file name or path ARG from MSYS format to w32 format.  Return\n# result in func_convert_core_msys_to_w32_result.\nfunc_convert_core_msys_to_w32 ()\n{\n  $debug_cmd\n\n  # awkward: cmd appends spaces to result\n  func_convert_core_msys_to_w32_result=`( cmd //c echo \"$1\" ) 2>/dev/null |\n    $SED -e 's/[ ]*$//' -e \"$sed_naive_backslashify\"`\n}\n#end: func_convert_core_msys_to_w32\n\n\n# func_convert_file_check ARG1 ARG2\n# Verify that ARG1 (a file name in $build format) was converted to $host\n# format in ARG2. Otherwise, emit an error message, but continue (resetting\n# func_to_host_file_result to ARG1).\nfunc_convert_file_check ()\n{\n  $debug_cmd\n\n  if test -z \"$2\" && test -n \"$1\"; then\n    func_error \"Could not determine host file name corresponding to\"\n    func_error \"  '$1'\"\n    func_error \"Continuing, but uninstalled executables may not work.\"\n    # Fallback:\n    func_to_host_file_result=$1\n  fi\n}\n# end func_convert_file_check\n\n\n# func_convert_path_check FROM_PATHSEP TO_PATHSEP FROM_PATH TO_PATH\n# Verify that FROM_PATH (a path in $build format) was converted to $host\n# format in TO_PATH. Otherwise, emit an error message, but continue, resetting\n# func_to_host_file_result to a simplistic fallback value (see below).\nfunc_convert_path_check ()\n{\n  $debug_cmd\n\n  if test -z \"$4\" && test -n \"$3\"; then\n    func_error \"Could not determine the host path corresponding to\"\n    func_error \"  '$3'\"\n    func_error \"Continuing, but uninstalled executables may not work.\"\n    # Fallback.  This is a deliberately simplistic \"conversion\" and\n    # should not be \"improved\".  See libtool.info.\n    if test \"x$1\" != \"x$2\"; then\n      lt_replace_pathsep_chars=\"s|$1|$2|g\"\n      func_to_host_path_result=`echo \"$3\" |\n        $SED -e \"$lt_replace_pathsep_chars\"`\n    else\n      func_to_host_path_result=$3\n    fi\n  fi\n}\n# end func_convert_path_check\n\n\n# func_convert_path_front_back_pathsep FRONTPAT BACKPAT REPL ORIG\n# Modifies func_to_host_path_result by prepending REPL if ORIG matches FRONTPAT\n# and appending REPL if ORIG matches BACKPAT.\nfunc_convert_path_front_back_pathsep ()\n{\n  $debug_cmd\n\n  case $4 in\n  $1 ) func_to_host_path_result=$3$func_to_host_path_result\n    ;;\n  esac\n  case $4 in\n  $2 ) func_append func_to_host_path_result \"$3\"\n    ;;\n  esac\n}\n# end func_convert_path_front_back_pathsep\n\n\n##################################################\n# $build to $host FILE NAME CONVERSION FUNCTIONS #\n##################################################\n# invoked via '$to_host_file_cmd ARG'\n#\n# In each case, ARG is the path to be converted from $build to $host format.\n# Result will be available in $func_to_host_file_result.\n\n\n# func_to_host_file ARG\n# Converts the file name ARG from $build format to $host format. Return result\n# in func_to_host_file_result.\nfunc_to_host_file ()\n{\n  $debug_cmd\n\n  $to_host_file_cmd \"$1\"\n}\n# end func_to_host_file\n\n\n# func_to_tool_file ARG LAZY\n# converts the file name ARG from $build format to toolchain format. Return\n# result in func_to_tool_file_result.  If the conversion in use is listed\n# in (the comma separated) LAZY, no conversion takes place.\nfunc_to_tool_file ()\n{\n  $debug_cmd\n\n  case ,$2, in\n    *,\"$to_tool_file_cmd\",*)\n      func_to_tool_file_result=$1\n      ;;\n    *)\n      $to_tool_file_cmd \"$1\"\n      func_to_tool_file_result=$func_to_host_file_result\n      ;;\n  esac\n}\n# end func_to_tool_file\n\n\n# func_convert_file_noop ARG\n# Copy ARG to func_to_host_file_result.\nfunc_convert_file_noop ()\n{\n  func_to_host_file_result=$1\n}\n# end func_convert_file_noop\n\n\n# func_convert_file_msys_to_w32 ARG\n# Convert file name ARG from (mingw) MSYS to (mingw) w32 format; automatic\n# conversion to w32 is not available inside the cwrapper.  Returns result in\n# func_to_host_file_result.\nfunc_convert_file_msys_to_w32 ()\n{\n  $debug_cmd\n\n  func_to_host_file_result=$1\n  if test -n \"$1\"; then\n    func_convert_core_msys_to_w32 \"$1\"\n    func_to_host_file_result=$func_convert_core_msys_to_w32_result\n  fi\n  func_convert_file_check \"$1\" \"$func_to_host_file_result\"\n}\n# end func_convert_file_msys_to_w32\n\n\n# func_convert_file_cygwin_to_w32 ARG\n# Convert file name ARG from Cygwin to w32 format.  Returns result in\n# func_to_host_file_result.\nfunc_convert_file_cygwin_to_w32 ()\n{\n  $debug_cmd\n\n  func_to_host_file_result=$1\n  if test -n \"$1\"; then\n    # because $build is cygwin, we call \"the\" cygpath in $PATH; no need to use\n    # LT_CYGPATH in this case.\n    func_to_host_file_result=`cygpath -m \"$1\"`\n  fi\n  func_convert_file_check \"$1\" \"$func_to_host_file_result\"\n}\n# end func_convert_file_cygwin_to_w32\n\n\n# func_convert_file_nix_to_w32 ARG\n# Convert file name ARG from *nix to w32 format.  Requires a wine environment\n# and a working winepath. Returns result in func_to_host_file_result.\nfunc_convert_file_nix_to_w32 ()\n{\n  $debug_cmd\n\n  func_to_host_file_result=$1\n  if test -n \"$1\"; then\n    func_convert_core_file_wine_to_w32 \"$1\"\n    func_to_host_file_result=$func_convert_core_file_wine_to_w32_result\n  fi\n  func_convert_file_check \"$1\" \"$func_to_host_file_result\"\n}\n# end func_convert_file_nix_to_w32\n\n\n# func_convert_file_msys_to_cygwin ARG\n# Convert file name ARG from MSYS to Cygwin format.  Requires LT_CYGPATH set.\n# Returns result in func_to_host_file_result.\nfunc_convert_file_msys_to_cygwin ()\n{\n  $debug_cmd\n\n  func_to_host_file_result=$1\n  if test -n \"$1\"; then\n    func_convert_core_msys_to_w32 \"$1\"\n    func_cygpath -u \"$func_convert_core_msys_to_w32_result\"\n    func_to_host_file_result=$func_cygpath_result\n  fi\n  func_convert_file_check \"$1\" \"$func_to_host_file_result\"\n}\n# end func_convert_file_msys_to_cygwin\n\n\n# func_convert_file_nix_to_cygwin ARG\n# Convert file name ARG from *nix to Cygwin format.  Requires Cygwin installed\n# in a wine environment, working winepath, and LT_CYGPATH set.  Returns result\n# in func_to_host_file_result.\nfunc_convert_file_nix_to_cygwin ()\n{\n  $debug_cmd\n\n  func_to_host_file_result=$1\n  if test -n \"$1\"; then\n    # convert from *nix to w32, then use cygpath to convert from w32 to cygwin.\n    func_convert_core_file_wine_to_w32 \"$1\"\n    func_cygpath -u \"$func_convert_core_file_wine_to_w32_result\"\n    func_to_host_file_result=$func_cygpath_result\n  fi\n  func_convert_file_check \"$1\" \"$func_to_host_file_result\"\n}\n# end func_convert_file_nix_to_cygwin\n\n\n#############################################\n# $build to $host PATH CONVERSION FUNCTIONS #\n#############################################\n# invoked via '$to_host_path_cmd ARG'\n#\n# In each case, ARG is the path to be converted from $build to $host format.\n# The result will be available in $func_to_host_path_result.\n#\n# Path separators are also converted from $build format to $host format.  If\n# ARG begins or ends with a path separator character, it is preserved (but\n# converted to $host format) on output.\n#\n# All path conversion functions are named using the following convention:\n#   file name conversion function    : func_convert_file_X_to_Y ()\n#   path conversion function         : func_convert_path_X_to_Y ()\n# where, for any given $build/$host combination the 'X_to_Y' value is the\n# same.  If conversion functions are added for new $build/$host combinations,\n# the two new functions must follow this pattern, or func_init_to_host_path_cmd\n# will break.\n\n\n# func_init_to_host_path_cmd\n# Ensures that function \"pointer\" variable $to_host_path_cmd is set to the\n# appropriate value, based on the value of $to_host_file_cmd.\nto_host_path_cmd=\nfunc_init_to_host_path_cmd ()\n{\n  $debug_cmd\n\n  if test -z \"$to_host_path_cmd\"; then\n    func_stripname 'func_convert_file_' '' \"$to_host_file_cmd\"\n    to_host_path_cmd=func_convert_path_$func_stripname_result\n  fi\n}\n\n\n# func_to_host_path ARG\n# Converts the path ARG from $build format to $host format. Return result\n# in func_to_host_path_result.\nfunc_to_host_path ()\n{\n  $debug_cmd\n\n  func_init_to_host_path_cmd\n  $to_host_path_cmd \"$1\"\n}\n# end func_to_host_path\n\n\n# func_convert_path_noop ARG\n# Copy ARG to func_to_host_path_result.\nfunc_convert_path_noop ()\n{\n  func_to_host_path_result=$1\n}\n# end func_convert_path_noop\n\n\n# func_convert_path_msys_to_w32 ARG\n# Convert path ARG from (mingw) MSYS to (mingw) w32 format; automatic\n# conversion to w32 is not available inside the cwrapper.  Returns result in\n# func_to_host_path_result.\nfunc_convert_path_msys_to_w32 ()\n{\n  $debug_cmd\n\n  func_to_host_path_result=$1\n  if test -n \"$1\"; then\n    # Remove leading and trailing path separator characters from ARG.  MSYS\n    # behavior is inconsistent here; cygpath turns them into '.;' and ';.';\n    # and winepath ignores them completely.\n    func_stripname : : \"$1\"\n    func_to_host_path_tmp1=$func_stripname_result\n    func_convert_core_msys_to_w32 \"$func_to_host_path_tmp1\"\n    func_to_host_path_result=$func_convert_core_msys_to_w32_result\n    func_convert_path_check : \";\" \\\n      \"$func_to_host_path_tmp1\" \"$func_to_host_path_result\"\n    func_convert_path_front_back_pathsep \":*\" \"*:\" \";\" \"$1\"\n  fi\n}\n# end func_convert_path_msys_to_w32\n\n\n# func_convert_path_cygwin_to_w32 ARG\n# Convert path ARG from Cygwin to w32 format.  Returns result in\n# func_to_host_file_result.\nfunc_convert_path_cygwin_to_w32 ()\n{\n  $debug_cmd\n\n  func_to_host_path_result=$1\n  if test -n \"$1\"; then\n    # See func_convert_path_msys_to_w32:\n    func_stripname : : \"$1\"\n    func_to_host_path_tmp1=$func_stripname_result\n    func_to_host_path_result=`cygpath -m -p \"$func_to_host_path_tmp1\"`\n    func_convert_path_check : \";\" \\\n      \"$func_to_host_path_tmp1\" \"$func_to_host_path_result\"\n    func_convert_path_front_back_pathsep \":*\" \"*:\" \";\" \"$1\"\n  fi\n}\n# end func_convert_path_cygwin_to_w32\n\n\n# func_convert_path_nix_to_w32 ARG\n# Convert path ARG from *nix to w32 format.  Requires a wine environment and\n# a working winepath.  Returns result in func_to_host_file_result.\nfunc_convert_path_nix_to_w32 ()\n{\n  $debug_cmd\n\n  func_to_host_path_result=$1\n  if test -n \"$1\"; then\n    # See func_convert_path_msys_to_w32:\n    func_stripname : : \"$1\"\n    func_to_host_path_tmp1=$func_stripname_result\n    func_convert_core_path_wine_to_w32 \"$func_to_host_path_tmp1\"\n    func_to_host_path_result=$func_convert_core_path_wine_to_w32_result\n    func_convert_path_check : \";\" \\\n      \"$func_to_host_path_tmp1\" \"$func_to_host_path_result\"\n    func_convert_path_front_back_pathsep \":*\" \"*:\" \";\" \"$1\"\n  fi\n}\n# end func_convert_path_nix_to_w32\n\n\n# func_convert_path_msys_to_cygwin ARG\n# Convert path ARG from MSYS to Cygwin format.  Requires LT_CYGPATH set.\n# Returns result in func_to_host_file_result.\nfunc_convert_path_msys_to_cygwin ()\n{\n  $debug_cmd\n\n  func_to_host_path_result=$1\n  if test -n \"$1\"; then\n    # See func_convert_path_msys_to_w32:\n    func_stripname : : \"$1\"\n    func_to_host_path_tmp1=$func_stripname_result\n    func_convert_core_msys_to_w32 \"$func_to_host_path_tmp1\"\n    func_cygpath -u -p \"$func_convert_core_msys_to_w32_result\"\n    func_to_host_path_result=$func_cygpath_result\n    func_convert_path_check : : \\\n      \"$func_to_host_path_tmp1\" \"$func_to_host_path_result\"\n    func_convert_path_front_back_pathsep \":*\" \"*:\" : \"$1\"\n  fi\n}\n# end func_convert_path_msys_to_cygwin\n\n\n# func_convert_path_nix_to_cygwin ARG\n# Convert path ARG from *nix to Cygwin format.  Requires Cygwin installed in a\n# a wine environment, working winepath, and LT_CYGPATH set.  Returns result in\n# func_to_host_file_result.\nfunc_convert_path_nix_to_cygwin ()\n{\n  $debug_cmd\n\n  func_to_host_path_result=$1\n  if test -n \"$1\"; then\n    # Remove leading and trailing path separator characters from\n    # ARG. msys behavior is inconsistent here, cygpath turns them\n    # into '.;' and ';.', and winepath ignores them completely.\n    func_stripname : : \"$1\"\n    func_to_host_path_tmp1=$func_stripname_result\n    func_convert_core_path_wine_to_w32 \"$func_to_host_path_tmp1\"\n    func_cygpath -u -p \"$func_convert_core_path_wine_to_w32_result\"\n    func_to_host_path_result=$func_cygpath_result\n    func_convert_path_check : : \\\n      \"$func_to_host_path_tmp1\" \"$func_to_host_path_result\"\n    func_convert_path_front_back_pathsep \":*\" \"*:\" : \"$1\"\n  fi\n}\n# end func_convert_path_nix_to_cygwin\n\n\n# func_dll_def_p FILE\n# True iff FILE is a Windows DLL '.def' file.\n# Keep in sync with _LT_DLL_DEF_P in libtool.m4\nfunc_dll_def_p ()\n{\n  $debug_cmd\n\n  func_dll_def_p_tmp=`$SED -n \\\n    -e 's/^[\t ]*//' \\\n    -e '/^\\(;.*\\)*$/d' \\\n    -e 's/^\\(EXPORTS\\|LIBRARY\\)\\([\t ].*\\)*$/DEF/p' \\\n    -e q \\\n    \"$1\"`\n  test DEF = \"$func_dll_def_p_tmp\"\n}\n\n\n# func_mode_compile arg...\nfunc_mode_compile ()\n{\n    $debug_cmd\n\n    # Get the compilation command and the source file.\n    base_compile=\n    srcfile=$nonopt  #  always keep a non-empty value in \"srcfile\"\n    suppress_opt=yes\n    suppress_output=\n    arg_mode=normal\n    libobj=\n    later=\n    pie_flag=\n\n    for arg\n    do\n      case $arg_mode in\n      arg  )\n\t# do not \"continue\".  Instead, add this to base_compile\n\tlastarg=$arg\n\targ_mode=normal\n\t;;\n\n      target )\n\tlibobj=$arg\n\targ_mode=normal\n\tcontinue\n\t;;\n\n      normal )\n\t# Accept any command-line options.\n\tcase $arg in\n\t-o)\n\t  test -n \"$libobj\" && \\\n\t    func_fatal_error \"you cannot specify '-o' more than once\"\n\t  arg_mode=target\n\t  continue\n\t  ;;\n\n\t-pie | -fpie | -fPIE)\n          func_append pie_flag \" $arg\"\n\t  continue\n\t  ;;\n\n\t-shared | -static | -prefer-pic | -prefer-non-pic)\n\t  func_append later \" $arg\"\n\t  continue\n\t  ;;\n\n\t-no-suppress)\n\t  suppress_opt=no\n\t  continue\n\t  ;;\n\n\t-Xcompiler)\n\t  arg_mode=arg  #  the next one goes into the \"base_compile\" arg list\n\t  continue      #  The current \"srcfile\" will either be retained or\n\t  ;;            #  replaced later.  I would guess that would be a bug.\n\n\t-Wc,*)\n\t  func_stripname '-Wc,' '' \"$arg\"\n\t  args=$func_stripname_result\n\t  lastarg=\n\t  save_ifs=$IFS; IFS=,\n\t  for arg in $args; do\n\t    IFS=$save_ifs\n\t    func_append_quoted lastarg \"$arg\"\n\t  done\n\t  IFS=$save_ifs\n\t  func_stripname ' ' '' \"$lastarg\"\n\t  lastarg=$func_stripname_result\n\n\t  # Add the arguments to base_compile.\n\t  func_append base_compile \" $lastarg\"\n\t  continue\n\t  ;;\n\n\t*)\n\t  # Accept the current argument as the source file.\n\t  # The previous \"srcfile\" becomes the current argument.\n\t  #\n\t  lastarg=$srcfile\n\t  srcfile=$arg\n\t  ;;\n\tesac  #  case $arg\n\t;;\n      esac    #  case $arg_mode\n\n      # Aesthetically quote the previous argument.\n      func_append_quoted base_compile \"$lastarg\"\n    done # for arg\n\n    case $arg_mode in\n    arg)\n      func_fatal_error \"you must specify an argument for -Xcompile\"\n      ;;\n    target)\n      func_fatal_error \"you must specify a target with '-o'\"\n      ;;\n    *)\n      # Get the name of the library object.\n      test -z \"$libobj\" && {\n\tfunc_basename \"$srcfile\"\n\tlibobj=$func_basename_result\n      }\n      ;;\n    esac\n\n    # Recognize several different file suffixes.\n    # If the user specifies -o file.o, it is replaced with file.lo\n    case $libobj in\n    *.[cCFSifmso] | \\\n    *.ada | *.adb | *.ads | *.asm | \\\n    *.c++ | *.cc | *.ii | *.class | *.cpp | *.cxx | \\\n    *.[fF][09]? | *.for | *.java | *.go | *.obj | *.sx | *.cu | *.cup)\n      func_xform \"$libobj\"\n      libobj=$func_xform_result\n      ;;\n    esac\n\n    case $libobj in\n    *.lo) func_lo2o \"$libobj\"; obj=$func_lo2o_result ;;\n    *)\n      func_fatal_error \"cannot determine name of library object from '$libobj'\"\n      ;;\n    esac\n\n    func_infer_tag $base_compile\n\n    for arg in $later; do\n      case $arg in\n      -shared)\n\ttest yes = \"$build_libtool_libs\" \\\n\t  || func_fatal_configuration \"cannot build a shared library\"\n\tbuild_old_libs=no\n\tcontinue\n\t;;\n\n      -static)\n\tbuild_libtool_libs=no\n\tbuild_old_libs=yes\n\tcontinue\n\t;;\n\n      -prefer-pic)\n\tpic_mode=yes\n\tcontinue\n\t;;\n\n      -prefer-non-pic)\n\tpic_mode=no\n\tcontinue\n\t;;\n      esac\n    done\n\n    func_quote_for_eval \"$libobj\"\n    test \"X$libobj\" != \"X$func_quote_for_eval_result\" \\\n      && $ECHO \"X$libobj\" | $GREP '[]~#^*{};<>?\"'\"'\"'\t &()|`$[]' \\\n      && func_warning \"libobj name '$libobj' may not contain shell special characters.\"\n    func_dirname_and_basename \"$obj\" \"/\" \"\"\n    objname=$func_basename_result\n    xdir=$func_dirname_result\n    lobj=$xdir$objdir/$objname\n\n    test -z \"$base_compile\" && \\\n      func_fatal_help \"you must specify a compilation command\"\n\n    # Delete any leftover library objects.\n    if test yes = \"$build_old_libs\"; then\n      removelist=\"$obj $lobj $libobj ${libobj}T\"\n    else\n      removelist=\"$lobj $libobj ${libobj}T\"\n    fi\n\n    # On Cygwin there's no \"real\" PIC flag so we must build both object types\n    case $host_os in\n    cygwin* | mingw* | pw32* | os2* | cegcc*)\n      pic_mode=default\n      ;;\n    esac\n    if test no = \"$pic_mode\" && test pass_all != \"$deplibs_check_method\"; then\n      # non-PIC code in shared libraries is not supported\n      pic_mode=default\n    fi\n\n    # Calculate the filename of the output object if compiler does\n    # not support -o with -c\n    if test no = \"$compiler_c_o\"; then\n      output_obj=`$ECHO \"$srcfile\" | $SED 's%^.*/%%; s%\\.[^.]*$%%'`.$objext\n      lockfile=$output_obj.lock\n    else\n      output_obj=\n      need_locks=no\n      lockfile=\n    fi\n\n    # Lock this critical section if it is needed\n    # We use this script file to make the link, it avoids creating a new file\n    if test yes = \"$need_locks\"; then\n      until $opt_dry_run || ln \"$progpath\" \"$lockfile\" 2>/dev/null; do\n\tfunc_echo \"Waiting for $lockfile to be removed\"\n\tsleep 2\n      done\n    elif test warn = \"$need_locks\"; then\n      if test -f \"$lockfile\"; then\n\t$ECHO \"\\\n*** ERROR, $lockfile exists and contains:\n`cat $lockfile 2>/dev/null`\n\nThis indicates that another process is trying to use the same\ntemporary object file, and libtool could not work around it because\nyour compiler does not support '-c' and '-o' together.  If you\nrepeat this compilation, it may succeed, by chance, but you had better\navoid parallel builds (make -j) in this platform, or get a better\ncompiler.\"\n\n\t$opt_dry_run || $RM $removelist\n\texit $EXIT_FAILURE\n      fi\n      func_append removelist \" $output_obj\"\n      $ECHO \"$srcfile\" > \"$lockfile\"\n    fi\n\n    $opt_dry_run || $RM $removelist\n    func_append removelist \" $lockfile\"\n    trap '$opt_dry_run || $RM $removelist; exit $EXIT_FAILURE' 1 2 15\n\n    func_to_tool_file \"$srcfile\" func_convert_file_msys_to_w32\n    srcfile=$func_to_tool_file_result\n    func_quote_for_eval \"$srcfile\"\n    qsrcfile=$func_quote_for_eval_result\n\n    # Only build a PIC object if we are building libtool libraries.\n    if test yes = \"$build_libtool_libs\"; then\n      # Without this assignment, base_compile gets emptied.\n      fbsd_hideous_sh_bug=$base_compile\n\n      if test no != \"$pic_mode\"; then\n\tcommand=\"$base_compile $qsrcfile $pic_flag\"\n      else\n\t# Don't build PIC code\n\tcommand=\"$base_compile $qsrcfile\"\n      fi\n\n      func_mkdir_p \"$xdir$objdir\"\n\n      if test -z \"$output_obj\"; then\n\t# Place PIC objects in $objdir\n\tfunc_append command \" -o $lobj\"\n      fi\n\n      func_show_eval_locale \"$command\"\t\\\n          'test -n \"$output_obj\" && $RM $removelist; exit $EXIT_FAILURE'\n\n      if test warn = \"$need_locks\" &&\n\t test \"X`cat $lockfile 2>/dev/null`\" != \"X$srcfile\"; then\n\t$ECHO \"\\\n*** ERROR, $lockfile contains:\n`cat $lockfile 2>/dev/null`\n\nbut it should contain:\n$srcfile\n\nThis indicates that another process is trying to use the same\ntemporary object file, and libtool could not work around it because\nyour compiler does not support '-c' and '-o' together.  If you\nrepeat this compilation, it may succeed, by chance, but you had better\navoid parallel builds (make -j) in this platform, or get a better\ncompiler.\"\n\n\t$opt_dry_run || $RM $removelist\n\texit $EXIT_FAILURE\n      fi\n\n      # Just move the object if needed, then go on to compile the next one\n      if test -n \"$output_obj\" && test \"X$output_obj\" != \"X$lobj\"; then\n\tfunc_show_eval '$MV \"$output_obj\" \"$lobj\"' \\\n\t  'error=$?; $opt_dry_run || $RM $removelist; exit $error'\n      fi\n\n      # Allow error messages only from the first compilation.\n      if test yes = \"$suppress_opt\"; then\n\tsuppress_output=' >/dev/null 2>&1'\n      fi\n    fi\n\n    # Only build a position-dependent object if we build old libraries.\n    if test yes = \"$build_old_libs\"; then\n      if test yes != \"$pic_mode\"; then\n\t# Don't build PIC code\n\tcommand=\"$base_compile $qsrcfile$pie_flag\"\n      else\n\tcommand=\"$base_compile $qsrcfile $pic_flag\"\n      fi\n      if test yes = \"$compiler_c_o\"; then\n\tfunc_append command \" -o $obj\"\n      fi\n\n      # Suppress compiler output if we already did a PIC compilation.\n      func_append command \"$suppress_output\"\n      func_show_eval_locale \"$command\" \\\n        '$opt_dry_run || $RM $removelist; exit $EXIT_FAILURE'\n\n      if test warn = \"$need_locks\" &&\n\t test \"X`cat $lockfile 2>/dev/null`\" != \"X$srcfile\"; then\n\t$ECHO \"\\\n*** ERROR, $lockfile contains:\n`cat $lockfile 2>/dev/null`\n\nbut it should contain:\n$srcfile\n\nThis indicates that another process is trying to use the same\ntemporary object file, and libtool could not work around it because\nyour compiler does not support '-c' and '-o' together.  If you\nrepeat this compilation, it may succeed, by chance, but you had better\navoid parallel builds (make -j) in this platform, or get a better\ncompiler.\"\n\n\t$opt_dry_run || $RM $removelist\n\texit $EXIT_FAILURE\n      fi\n\n      # Just move the object if needed\n      if test -n \"$output_obj\" && test \"X$output_obj\" != \"X$obj\"; then\n\tfunc_show_eval '$MV \"$output_obj\" \"$obj\"' \\\n\t  'error=$?; $opt_dry_run || $RM $removelist; exit $error'\n      fi\n    fi\n\n    $opt_dry_run || {\n      func_write_libtool_object \"$libobj\" \"$objdir/$objname\" \"$objname\"\n\n      # Unlock the critical section if it was locked\n      if test no != \"$need_locks\"; then\n\tremovelist=$lockfile\n        $RM \"$lockfile\"\n      fi\n    }\n\n    exit $EXIT_SUCCESS\n}\n\n$opt_help || {\n  test compile = \"$opt_mode\" && func_mode_compile ${1+\"$@\"}\n}\n\nfunc_mode_help ()\n{\n    # We need to display help for each of the modes.\n    case $opt_mode in\n      \"\")\n        # Generic help is extracted from the usage comments\n        # at the start of this file.\n        func_help\n        ;;\n\n      clean)\n        $ECHO \\\n\"Usage: $progname [OPTION]... --mode=clean RM [RM-OPTION]... FILE...\n\nRemove files from the build directory.\n\nRM is the name of the program to use to delete files associated with each FILE\n(typically '/bin/rm').  RM-OPTIONS are options (such as '-f') to be passed\nto RM.\n\nIf FILE is a libtool library, object or program, all the files associated\nwith it are deleted. Otherwise, only FILE itself is deleted using RM.\"\n        ;;\n\n      compile)\n      $ECHO \\\n\"Usage: $progname [OPTION]... --mode=compile COMPILE-COMMAND... SOURCEFILE\n\nCompile a source file into a libtool library object.\n\nThis mode accepts the following additional options:\n\n  -o OUTPUT-FILE    set the output file name to OUTPUT-FILE\n  -no-suppress      do not suppress compiler output for multiple passes\n  -prefer-pic       try to build PIC objects only\n  -prefer-non-pic   try to build non-PIC objects only\n  -shared           do not build a '.o' file suitable for static linking\n  -static           only build a '.o' file suitable for static linking\n  -Wc,FLAG          pass FLAG directly to the compiler\n\nCOMPILE-COMMAND is a command to be used in creating a 'standard' object file\nfrom the given SOURCEFILE.\n\nThe output file name is determined by removing the directory component from\nSOURCEFILE, then substituting the C source code suffix '.c' with the\nlibrary object suffix, '.lo'.\"\n        ;;\n\n      execute)\n        $ECHO \\\n\"Usage: $progname [OPTION]... --mode=execute COMMAND [ARGS]...\n\nAutomatically set library path, then run a program.\n\nThis mode accepts the following additional options:\n\n  -dlopen FILE      add the directory containing FILE to the library path\n\nThis mode sets the library path environment variable according to '-dlopen'\nflags.\n\nIf any of the ARGS are libtool executable wrappers, then they are translated\ninto their corresponding uninstalled binary, and any of their required library\ndirectories are added to the library path.\n\nThen, COMMAND is executed, with ARGS as arguments.\"\n        ;;\n\n      finish)\n        $ECHO \\\n\"Usage: $progname [OPTION]... --mode=finish [LIBDIR]...\n\nComplete the installation of libtool libraries.\n\nEach LIBDIR is a directory that contains libtool libraries.\n\nThe commands that this mode executes may require superuser privileges.  Use\nthe '--dry-run' option if you just want to see what would be executed.\"\n        ;;\n\n      install)\n        $ECHO \\\n\"Usage: $progname [OPTION]... --mode=install INSTALL-COMMAND...\n\nInstall executables or libraries.\n\nINSTALL-COMMAND is the installation command.  The first component should be\neither the 'install' or 'cp' program.\n\nThe following components of INSTALL-COMMAND are treated specially:\n\n  -inst-prefix-dir PREFIX-DIR  Use PREFIX-DIR as a staging area for installation\n\nThe rest of the components are interpreted as arguments to that command (only\nBSD-compatible install options are recognized).\"\n        ;;\n\n      link)\n        $ECHO \\\n\"Usage: $progname [OPTION]... --mode=link LINK-COMMAND...\n\nLink object files or libraries together to form another library, or to\ncreate an executable program.\n\nLINK-COMMAND is a command using the C compiler that you would use to create\na program from several object files.\n\nThe following components of LINK-COMMAND are treated specially:\n\n  -all-static       do not do any dynamic linking at all\n  -avoid-version    do not add a version suffix if possible\n  -bindir BINDIR    specify path to binaries directory (for systems where\n                    libraries must be found in the PATH setting at runtime)\n  -dlopen FILE      '-dlpreopen' FILE if it cannot be dlopened at runtime\n  -dlpreopen FILE   link in FILE and add its symbols to lt_preloaded_symbols\n  -export-dynamic   allow symbols from OUTPUT-FILE to be resolved with dlsym(3)\n  -export-symbols SYMFILE\n                    try to export only the symbols listed in SYMFILE\n  -export-symbols-regex REGEX\n                    try to export only the symbols matching REGEX\n  -LLIBDIR          search LIBDIR for required installed libraries\n  -lNAME            OUTPUT-FILE requires the installed library libNAME\n  -module           build a library that can dlopened\n  -no-fast-install  disable the fast-install mode\n  -no-install       link a not-installable executable\n  -no-undefined     declare that a library does not refer to external symbols\n  -o OUTPUT-FILE    create OUTPUT-FILE from the specified objects\n  -objectlist FILE  use a list of object files found in FILE to specify objects\n  -os2dllname NAME  force a short DLL name on OS/2 (no effect on other OSes)\n  -precious-files-regex REGEX\n                    don't remove output files matching REGEX\n  -release RELEASE  specify package release information\n  -rpath LIBDIR     the created library will eventually be installed in LIBDIR\n  -R[ ]LIBDIR       add LIBDIR to the runtime path of programs and libraries\n  -shared           only do dynamic linking of libtool libraries\n  -shrext SUFFIX    override the standard shared library file extension\n  -static           do not do any dynamic linking of uninstalled libtool libraries\n  -static-libtool-libs\n                    do not do any dynamic linking of libtool libraries\n  -version-info CURRENT[:REVISION[:AGE]]\n                    specify library version info [each variable defaults to 0]\n  -weak LIBNAME     declare that the target provides the LIBNAME interface\n  -Wc,FLAG\n  -Xcompiler FLAG   pass linker-specific FLAG directly to the compiler\n  -Wl,FLAG\n  -Xlinker FLAG     pass linker-specific FLAG directly to the linker\n  -XCClinker FLAG   pass link-specific FLAG to the compiler driver (CC)\n\nAll other options (arguments beginning with '-') are ignored.\n\nEvery other argument is treated as a filename.  Files ending in '.la' are\ntreated as uninstalled libtool libraries, other files are standard or library\nobject files.\n\nIf the OUTPUT-FILE ends in '.la', then a libtool library is created,\nonly library objects ('.lo' files) may be specified, and '-rpath' is\nrequired, except when creating a convenience library.\n\nIf OUTPUT-FILE ends in '.a' or '.lib', then a standard library is created\nusing 'ar' and 'ranlib', or on Windows using 'lib'.\n\nIf OUTPUT-FILE ends in '.lo' or '.$objext', then a reloadable object file\nis created, otherwise an executable program is created.\"\n        ;;\n\n      uninstall)\n        $ECHO \\\n\"Usage: $progname [OPTION]... --mode=uninstall RM [RM-OPTION]... FILE...\n\nRemove libraries from an installation directory.\n\nRM is the name of the program to use to delete files associated with each FILE\n(typically '/bin/rm').  RM-OPTIONS are options (such as '-f') to be passed\nto RM.\n\nIf FILE is a libtool library, all the files associated with it are deleted.\nOtherwise, only FILE itself is deleted using RM.\"\n        ;;\n\n      *)\n        func_fatal_help \"invalid operation mode '$opt_mode'\"\n        ;;\n    esac\n\n    echo\n    $ECHO \"Try '$progname --help' for more information about other modes.\"\n}\n\n# Now that we've collected a possible --mode arg, show help if necessary\nif $opt_help; then\n  if test : = \"$opt_help\"; then\n    func_mode_help\n  else\n    {\n      func_help noexit\n      for opt_mode in compile link execute install finish uninstall clean; do\n\tfunc_mode_help\n      done\n    } | $SED -n '1p; 2,$s/^Usage:/  or: /p'\n    {\n      func_help noexit\n      for opt_mode in compile link execute install finish uninstall clean; do\n\techo\n\tfunc_mode_help\n      done\n    } |\n    $SED '1d\n      /^When reporting/,/^Report/{\n\tH\n\td\n      }\n      $x\n      /information about other modes/d\n      /more detailed .*MODE/d\n      s/^Usage:.*--mode=\\([^ ]*\\) .*/Description of \\1 mode:/'\n  fi\n  exit $?\nfi\n\n\n# func_mode_execute arg...\nfunc_mode_execute ()\n{\n    $debug_cmd\n\n    # The first argument is the command name.\n    cmd=$nonopt\n    test -z \"$cmd\" && \\\n      func_fatal_help \"you must specify a COMMAND\"\n\n    # Handle -dlopen flags immediately.\n    for file in $opt_dlopen; do\n      test -f \"$file\" \\\n\t|| func_fatal_help \"'$file' is not a file\"\n\n      dir=\n      case $file in\n      *.la)\n\tfunc_resolve_sysroot \"$file\"\n\tfile=$func_resolve_sysroot_result\n\n\t# Check to see that this really is a libtool archive.\n\tfunc_lalib_unsafe_p \"$file\" \\\n\t  || func_fatal_help \"'$lib' is not a valid libtool archive\"\n\n\t# Read the libtool library.\n\tdlname=\n\tlibrary_names=\n\tfunc_source \"$file\"\n\n\t# Skip this library if it cannot be dlopened.\n\tif test -z \"$dlname\"; then\n\t  # Warn if it was a shared library.\n\t  test -n \"$library_names\" && \\\n\t    func_warning \"'$file' was not linked with '-export-dynamic'\"\n\t  continue\n\tfi\n\n\tfunc_dirname \"$file\" \"\" \".\"\n\tdir=$func_dirname_result\n\n\tif test -f \"$dir/$objdir/$dlname\"; then\n\t  func_append dir \"/$objdir\"\n\telse\n\t  if test ! -f \"$dir/$dlname\"; then\n\t    func_fatal_error \"cannot find '$dlname' in '$dir' or '$dir/$objdir'\"\n\t  fi\n\tfi\n\t;;\n\n      *.lo)\n\t# Just add the directory containing the .lo file.\n\tfunc_dirname \"$file\" \"\" \".\"\n\tdir=$func_dirname_result\n\t;;\n\n      *)\n\tfunc_warning \"'-dlopen' is ignored for non-libtool libraries and objects\"\n\tcontinue\n\t;;\n      esac\n\n      # Get the absolute pathname.\n      absdir=`cd \"$dir\" && pwd`\n      test -n \"$absdir\" && dir=$absdir\n\n      # Now add the directory to shlibpath_var.\n      if eval \"test -z \\\"\\$$shlibpath_var\\\"\"; then\n\teval \"$shlibpath_var=\\\"\\$dir\\\"\"\n      else\n\teval \"$shlibpath_var=\\\"\\$dir:\\$$shlibpath_var\\\"\"\n      fi\n    done\n\n    # This variable tells wrapper scripts just to set shlibpath_var\n    # rather than running their programs.\n    libtool_execute_magic=$magic\n\n    # Check if any of the arguments is a wrapper script.\n    args=\n    for file\n    do\n      case $file in\n      -* | *.la | *.lo ) ;;\n      *)\n\t# Do a test to see if this is really a libtool program.\n\tif func_ltwrapper_script_p \"$file\"; then\n\t  func_source \"$file\"\n\t  # Transform arg to wrapped name.\n\t  file=$progdir/$program\n\telif func_ltwrapper_executable_p \"$file\"; then\n\t  func_ltwrapper_scriptname \"$file\"\n\t  func_source \"$func_ltwrapper_scriptname_result\"\n\t  # Transform arg to wrapped name.\n\t  file=$progdir/$program\n\tfi\n\t;;\n      esac\n      # Quote arguments (to preserve shell metacharacters).\n      func_append_quoted args \"$file\"\n    done\n\n    if $opt_dry_run; then\n      # Display what would be done.\n      if test -n \"$shlibpath_var\"; then\n\teval \"\\$ECHO \\\"\\$shlibpath_var=\\$$shlibpath_var\\\"\"\n\techo \"export $shlibpath_var\"\n      fi\n      $ECHO \"$cmd$args\"\n      exit $EXIT_SUCCESS\n    else\n      if test -n \"$shlibpath_var\"; then\n\t# Export the shlibpath_var.\n\teval \"export $shlibpath_var\"\n      fi\n\n      # Restore saved environment variables\n      for lt_var in LANG LANGUAGE LC_ALL LC_CTYPE LC_COLLATE LC_MESSAGES\n      do\n\teval \"if test \\\"\\${save_$lt_var+set}\\\" = set; then\n                $lt_var=\\$save_$lt_var; export $lt_var\n\t      else\n\t\t$lt_unset $lt_var\n\t      fi\"\n      done\n\n      # Now prepare to actually exec the command.\n      exec_cmd=\\$cmd$args\n    fi\n}\n\ntest execute = \"$opt_mode\" && func_mode_execute ${1+\"$@\"}\n\n\n# func_mode_finish arg...\nfunc_mode_finish ()\n{\n    $debug_cmd\n\n    libs=\n    libdirs=\n    admincmds=\n\n    for opt in \"$nonopt\" ${1+\"$@\"}\n    do\n      if test -d \"$opt\"; then\n\tfunc_append libdirs \" $opt\"\n\n      elif test -f \"$opt\"; then\n\tif func_lalib_unsafe_p \"$opt\"; then\n\t  func_append libs \" $opt\"\n\telse\n\t  func_warning \"'$opt' is not a valid libtool archive\"\n\tfi\n\n      else\n\tfunc_fatal_error \"invalid argument '$opt'\"\n      fi\n    done\n\n    if test -n \"$libs\"; then\n      if test -n \"$lt_sysroot\"; then\n        sysroot_regex=`$ECHO \"$lt_sysroot\" | $SED \"$sed_make_literal_regex\"`\n        sysroot_cmd=\"s/\\([ ']\\)$sysroot_regex/\\1/g;\"\n      else\n        sysroot_cmd=\n      fi\n\n      # Remove sysroot references\n      if $opt_dry_run; then\n        for lib in $libs; do\n          echo \"removing references to $lt_sysroot and '=' prefixes from $lib\"\n        done\n      else\n        tmpdir=`func_mktempdir`\n        for lib in $libs; do\n\t  $SED -e \"$sysroot_cmd s/\\([ ']-[LR]\\)=/\\1/g; s/\\([ ']\\)=/\\1/g\" $lib \\\n\t    > $tmpdir/tmp-la\n\t  mv -f $tmpdir/tmp-la $lib\n\tdone\n        ${RM}r \"$tmpdir\"\n      fi\n    fi\n\n    if test -n \"$finish_cmds$finish_eval\" && test -n \"$libdirs\"; then\n      for libdir in $libdirs; do\n\tif test -n \"$finish_cmds\"; then\n\t  # Do each command in the finish commands.\n\t  func_execute_cmds \"$finish_cmds\" 'admincmds=\"$admincmds\n'\"$cmd\"'\"'\n\tfi\n\tif test -n \"$finish_eval\"; then\n\t  # Do the single finish_eval.\n\t  eval cmds=\\\"$finish_eval\\\"\n\t  $opt_dry_run || eval \"$cmds\" || func_append admincmds \"\n       $cmds\"\n\tfi\n      done\n    fi\n\n    # Exit here if they wanted silent mode.\n    $opt_quiet && exit $EXIT_SUCCESS\n\n    if test -n \"$finish_cmds$finish_eval\" && test -n \"$libdirs\"; then\n      echo \"----------------------------------------------------------------------\"\n      echo \"Libraries have been installed in:\"\n      for libdir in $libdirs; do\n\t$ECHO \"   $libdir\"\n      done\n      echo\n      echo \"If you ever happen to want to link against installed libraries\"\n      echo \"in a given directory, LIBDIR, you must either use libtool, and\"\n      echo \"specify the full pathname of the library, or use the '-LLIBDIR'\"\n      echo \"flag during linking and do at least one of the following:\"\n      if test -n \"$shlibpath_var\"; then\n\techo \"   - add LIBDIR to the '$shlibpath_var' environment variable\"\n\techo \"     during execution\"\n      fi\n      if test -n \"$runpath_var\"; then\n\techo \"   - add LIBDIR to the '$runpath_var' environment variable\"\n\techo \"     during linking\"\n      fi\n      if test -n \"$hardcode_libdir_flag_spec\"; then\n\tlibdir=LIBDIR\n\teval flag=\\\"$hardcode_libdir_flag_spec\\\"\n\n\t$ECHO \"   - use the '$flag' linker flag\"\n      fi\n      if test -n \"$admincmds\"; then\n\t$ECHO \"   - have your system administrator run these commands:$admincmds\"\n      fi\n      if test -f /etc/ld.so.conf; then\n\techo \"   - have your system administrator add LIBDIR to '/etc/ld.so.conf'\"\n      fi\n      echo\n\n      echo \"See any operating system documentation about shared libraries for\"\n      case $host in\n\tsolaris2.[6789]|solaris2.1[0-9])\n\t  echo \"more information, such as the ld(1), crle(1) and ld.so(8) manual\"\n\t  echo \"pages.\"\n\t  ;;\n\t*)\n\t  echo \"more information, such as the ld(1) and ld.so(8) manual pages.\"\n\t  ;;\n      esac\n      echo \"----------------------------------------------------------------------\"\n    fi\n    exit $EXIT_SUCCESS\n}\n\ntest finish = \"$opt_mode\" && func_mode_finish ${1+\"$@\"}\n\n\n# func_mode_install arg...\nfunc_mode_install ()\n{\n    $debug_cmd\n\n    # There may be an optional sh(1) argument at the beginning of\n    # install_prog (especially on Windows NT).\n    if test \"$SHELL\" = \"$nonopt\" || test /bin/sh = \"$nonopt\" ||\n       # Allow the use of GNU shtool's install command.\n       case $nonopt in *shtool*) :;; *) false;; esac\n    then\n      # Aesthetically quote it.\n      func_quote_for_eval \"$nonopt\"\n      install_prog=\"$func_quote_for_eval_result \"\n      arg=$1\n      shift\n    else\n      install_prog=\n      arg=$nonopt\n    fi\n\n    # The real first argument should be the name of the installation program.\n    # Aesthetically quote it.\n    func_quote_for_eval \"$arg\"\n    func_append install_prog \"$func_quote_for_eval_result\"\n    install_shared_prog=$install_prog\n    case \" $install_prog \" in\n      *[\\\\\\ /]cp\\ *) install_cp=: ;;\n      *) install_cp=false ;;\n    esac\n\n    # We need to accept at least all the BSD install flags.\n    dest=\n    files=\n    opts=\n    prev=\n    install_type=\n    isdir=false\n    stripme=\n    no_mode=:\n    for arg\n    do\n      arg2=\n      if test -n \"$dest\"; then\n\tfunc_append files \" $dest\"\n\tdest=$arg\n\tcontinue\n      fi\n\n      case $arg in\n      -d) isdir=: ;;\n      -f)\n\tif $install_cp; then :; else\n\t  prev=$arg\n\tfi\n\t;;\n      -g | -m | -o)\n\tprev=$arg\n\t;;\n      -s)\n\tstripme=\" -s\"\n\tcontinue\n\t;;\n      -*)\n\t;;\n      *)\n\t# If the previous option needed an argument, then skip it.\n\tif test -n \"$prev\"; then\n\t  if test X-m = \"X$prev\" && test -n \"$install_override_mode\"; then\n\t    arg2=$install_override_mode\n\t    no_mode=false\n\t  fi\n\t  prev=\n\telse\n\t  dest=$arg\n\t  continue\n\tfi\n\t;;\n      esac\n\n      # Aesthetically quote the argument.\n      func_quote_for_eval \"$arg\"\n      func_append install_prog \" $func_quote_for_eval_result\"\n      if test -n \"$arg2\"; then\n\tfunc_quote_for_eval \"$arg2\"\n      fi\n      func_append install_shared_prog \" $func_quote_for_eval_result\"\n    done\n\n    test -z \"$install_prog\" && \\\n      func_fatal_help \"you must specify an install program\"\n\n    test -n \"$prev\" && \\\n      func_fatal_help \"the '$prev' option requires an argument\"\n\n    if test -n \"$install_override_mode\" && $no_mode; then\n      if $install_cp; then :; else\n\tfunc_quote_for_eval \"$install_override_mode\"\n\tfunc_append install_shared_prog \" -m $func_quote_for_eval_result\"\n      fi\n    fi\n\n    if test -z \"$files\"; then\n      if test -z \"$dest\"; then\n\tfunc_fatal_help \"no file or destination specified\"\n      else\n\tfunc_fatal_help \"you must specify a destination\"\n      fi\n    fi\n\n    # Strip any trailing slash from the destination.\n    func_stripname '' '/' \"$dest\"\n    dest=$func_stripname_result\n\n    # Check to see that the destination is a directory.\n    test -d \"$dest\" && isdir=:\n    if $isdir; then\n      destdir=$dest\n      destname=\n    else\n      func_dirname_and_basename \"$dest\" \"\" \".\"\n      destdir=$func_dirname_result\n      destname=$func_basename_result\n\n      # Not a directory, so check to see that there is only one file specified.\n      set dummy $files; shift\n      test \"$#\" -gt 1 && \\\n\tfunc_fatal_help \"'$dest' is not a directory\"\n    fi\n    case $destdir in\n    [\\\\/]* | [A-Za-z]:[\\\\/]*) ;;\n    *)\n      for file in $files; do\n\tcase $file in\n\t*.lo) ;;\n\t*)\n\t  func_fatal_help \"'$destdir' must be an absolute directory name\"\n\t  ;;\n\tesac\n      done\n      ;;\n    esac\n\n    # This variable tells wrapper scripts just to set variables rather\n    # than running their programs.\n    libtool_install_magic=$magic\n\n    staticlibs=\n    future_libdirs=\n    current_libdirs=\n    for file in $files; do\n\n      # Do each installation.\n      case $file in\n      *.$libext)\n\t# Do the static libraries later.\n\tfunc_append staticlibs \" $file\"\n\t;;\n\n      *.la)\n\tfunc_resolve_sysroot \"$file\"\n\tfile=$func_resolve_sysroot_result\n\n\t# Check to see that this really is a libtool archive.\n\tfunc_lalib_unsafe_p \"$file\" \\\n\t  || func_fatal_help \"'$file' is not a valid libtool archive\"\n\n\tlibrary_names=\n\told_library=\n\trelink_command=\n\tfunc_source \"$file\"\n\n\t# Add the libdir to current_libdirs if it is the destination.\n\tif test \"X$destdir\" = \"X$libdir\"; then\n\t  case \"$current_libdirs \" in\n\t  *\" $libdir \"*) ;;\n\t  *) func_append current_libdirs \" $libdir\" ;;\n\t  esac\n\telse\n\t  # Note the libdir as a future libdir.\n\t  case \"$future_libdirs \" in\n\t  *\" $libdir \"*) ;;\n\t  *) func_append future_libdirs \" $libdir\" ;;\n\t  esac\n\tfi\n\n\tfunc_dirname \"$file\" \"/\" \"\"\n\tdir=$func_dirname_result\n\tfunc_append dir \"$objdir\"\n\n\tif test -n \"$relink_command\"; then\n\t  # Determine the prefix the user has applied to our future dir.\n\t  inst_prefix_dir=`$ECHO \"$destdir\" | $SED -e \"s%$libdir\\$%%\"`\n\n\t  # Don't allow the user to place us outside of our expected\n\t  # location b/c this prevents finding dependent libraries that\n\t  # are installed to the same prefix.\n\t  # At present, this check doesn't affect windows .dll's that\n\t  # are installed into $libdir/../bin (currently, that works fine)\n\t  # but it's something to keep an eye on.\n\t  test \"$inst_prefix_dir\" = \"$destdir\" && \\\n\t    func_fatal_error \"error: cannot install '$file' to a directory not ending in $libdir\"\n\n\t  if test -n \"$inst_prefix_dir\"; then\n\t    # Stick the inst_prefix_dir data into the link command.\n\t    relink_command=`$ECHO \"$relink_command\" | $SED \"s%@inst_prefix_dir@%-inst-prefix-dir $inst_prefix_dir%\"`\n\t  else\n\t    relink_command=`$ECHO \"$relink_command\" | $SED \"s%@inst_prefix_dir@%%\"`\n\t  fi\n\n\t  func_warning \"relinking '$file'\"\n\t  func_show_eval \"$relink_command\" \\\n\t    'func_fatal_error \"error: relink '\\''$file'\\'' with the above command before installing it\"'\n\tfi\n\n\t# See the names of the shared library.\n\tset dummy $library_names; shift\n\tif test -n \"$1\"; then\n\t  realname=$1\n\t  shift\n\n\t  srcname=$realname\n\t  test -n \"$relink_command\" && srcname=${realname}T\n\n\t  # Install the shared library and build the symlinks.\n\t  func_show_eval \"$install_shared_prog $dir/$srcname $destdir/$realname\" \\\n\t      'exit $?'\n\t  tstripme=$stripme\n\t  case $host_os in\n\t  cygwin* | mingw* | pw32* | cegcc*)\n\t    case $realname in\n\t    *.dll.a)\n\t      tstripme=\n\t      ;;\n\t    esac\n\t    ;;\n\t  os2*)\n\t    case $realname in\n\t    *_dll.a)\n\t      tstripme=\n\t      ;;\n\t    esac\n\t    ;;\n\t  esac\n\t  if test -n \"$tstripme\" && test -n \"$striplib\"; then\n\t    func_show_eval \"$striplib $destdir/$realname\" 'exit $?'\n\t  fi\n\n\t  if test \"$#\" -gt 0; then\n\t    # Delete the old symlinks, and create new ones.\n\t    # Try 'ln -sf' first, because the 'ln' binary might depend on\n\t    # the symlink we replace!  Solaris /bin/ln does not understand -f,\n\t    # so we also need to try rm && ln -s.\n\t    for linkname\n\t    do\n\t      test \"$linkname\" != \"$realname\" \\\n\t\t&& func_show_eval \"(cd $destdir && { $LN_S -f $realname $linkname || { $RM $linkname && $LN_S $realname $linkname; }; })\"\n\t    done\n\t  fi\n\n\t  # Do each command in the postinstall commands.\n\t  lib=$destdir/$realname\n\t  func_execute_cmds \"$postinstall_cmds\" 'exit $?'\n\tfi\n\n\t# Install the pseudo-library for information purposes.\n\tfunc_basename \"$file\"\n\tname=$func_basename_result\n\tinstname=$dir/${name}i\n\tfunc_show_eval \"$install_prog $instname $destdir/$name\" 'exit $?'\n\n\t# Maybe install the static library, too.\n\ttest -n \"$old_library\" && func_append staticlibs \" $dir/$old_library\"\n\t;;\n\n      *.lo)\n\t# Install (i.e. copy) a libtool object.\n\n\t# Figure out destination file name, if it wasn't already specified.\n\tif test -n \"$destname\"; then\n\t  destfile=$destdir/$destname\n\telse\n\t  func_basename \"$file\"\n\t  destfile=$func_basename_result\n\t  destfile=$destdir/$destfile\n\tfi\n\n\t# Deduce the name of the destination old-style object file.\n\tcase $destfile in\n\t*.lo)\n\t  func_lo2o \"$destfile\"\n\t  staticdest=$func_lo2o_result\n\t  ;;\n\t*.$objext)\n\t  staticdest=$destfile\n\t  destfile=\n\t  ;;\n\t*)\n\t  func_fatal_help \"cannot copy a libtool object to '$destfile'\"\n\t  ;;\n\tesac\n\n\t# Install the libtool object if requested.\n\ttest -n \"$destfile\" && \\\n\t  func_show_eval \"$install_prog $file $destfile\" 'exit $?'\n\n\t# Install the old object if enabled.\n\tif test yes = \"$build_old_libs\"; then\n\t  # Deduce the name of the old-style object file.\n\t  func_lo2o \"$file\"\n\t  staticobj=$func_lo2o_result\n\t  func_show_eval \"$install_prog \\$staticobj \\$staticdest\" 'exit $?'\n\tfi\n\texit $EXIT_SUCCESS\n\t;;\n\n      *)\n\t# Figure out destination file name, if it wasn't already specified.\n\tif test -n \"$destname\"; then\n\t  destfile=$destdir/$destname\n\telse\n\t  func_basename \"$file\"\n\t  destfile=$func_basename_result\n\t  destfile=$destdir/$destfile\n\tfi\n\n\t# If the file is missing, and there is a .exe on the end, strip it\n\t# because it is most likely a libtool script we actually want to\n\t# install\n\tstripped_ext=\n\tcase $file in\n\t  *.exe)\n\t    if test ! -f \"$file\"; then\n\t      func_stripname '' '.exe' \"$file\"\n\t      file=$func_stripname_result\n\t      stripped_ext=.exe\n\t    fi\n\t    ;;\n\tesac\n\n\t# Do a test to see if this is really a libtool program.\n\tcase $host in\n\t*cygwin* | *mingw*)\n\t    if func_ltwrapper_executable_p \"$file\"; then\n\t      func_ltwrapper_scriptname \"$file\"\n\t      wrapper=$func_ltwrapper_scriptname_result\n\t    else\n\t      func_stripname '' '.exe' \"$file\"\n\t      wrapper=$func_stripname_result\n\t    fi\n\t    ;;\n\t*)\n\t    wrapper=$file\n\t    ;;\n\tesac\n\tif func_ltwrapper_script_p \"$wrapper\"; then\n\t  notinst_deplibs=\n\t  relink_command=\n\n\t  func_source \"$wrapper\"\n\n\t  # Check the variables that should have been set.\n\t  test -z \"$generated_by_libtool_version\" && \\\n\t    func_fatal_error \"invalid libtool wrapper script '$wrapper'\"\n\n\t  finalize=:\n\t  for lib in $notinst_deplibs; do\n\t    # Check to see that each library is installed.\n\t    libdir=\n\t    if test -f \"$lib\"; then\n\t      func_source \"$lib\"\n\t    fi\n\t    libfile=$libdir/`$ECHO \"$lib\" | $SED 's%^.*/%%g'`\n\t    if test -n \"$libdir\" && test ! -f \"$libfile\"; then\n\t      func_warning \"'$lib' has not been installed in '$libdir'\"\n\t      finalize=false\n\t    fi\n\t  done\n\n\t  relink_command=\n\t  func_source \"$wrapper\"\n\n\t  outputname=\n\t  if test no = \"$fast_install\" && test -n \"$relink_command\"; then\n\t    $opt_dry_run || {\n\t      if $finalize; then\n\t        tmpdir=`func_mktempdir`\n\t\tfunc_basename \"$file$stripped_ext\"\n\t\tfile=$func_basename_result\n\t        outputname=$tmpdir/$file\n\t        # Replace the output file specification.\n\t        relink_command=`$ECHO \"$relink_command\" | $SED 's%@OUTPUT@%'\"$outputname\"'%g'`\n\n\t        $opt_quiet || {\n\t          func_quote_for_expand \"$relink_command\"\n\t\t  eval \"func_echo $func_quote_for_expand_result\"\n\t        }\n\t        if eval \"$relink_command\"; then :\n\t          else\n\t\t  func_error \"error: relink '$file' with the above command before installing it\"\n\t\t  $opt_dry_run || ${RM}r \"$tmpdir\"\n\t\t  continue\n\t        fi\n\t        file=$outputname\n\t      else\n\t        func_warning \"cannot relink '$file'\"\n\t      fi\n\t    }\n\t  else\n\t    # Install the binary that we compiled earlier.\n\t    file=`$ECHO \"$file$stripped_ext\" | $SED \"s%\\([^/]*\\)$%$objdir/\\1%\"`\n\t  fi\n\tfi\n\n\t# remove .exe since cygwin /usr/bin/install will append another\n\t# one anyway\n\tcase $install_prog,$host in\n\t*/usr/bin/install*,*cygwin*)\n\t  case $file:$destfile in\n\t  *.exe:*.exe)\n\t    # this is ok\n\t    ;;\n\t  *.exe:*)\n\t    destfile=$destfile.exe\n\t    ;;\n\t  *:*.exe)\n\t    func_stripname '' '.exe' \"$destfile\"\n\t    destfile=$func_stripname_result\n\t    ;;\n\t  esac\n\t  ;;\n\tesac\n\tfunc_show_eval \"$install_prog\\$stripme \\$file \\$destfile\" 'exit $?'\n\t$opt_dry_run || if test -n \"$outputname\"; then\n\t  ${RM}r \"$tmpdir\"\n\tfi\n\t;;\n      esac\n    done\n\n    for file in $staticlibs; do\n      func_basename \"$file\"\n      name=$func_basename_result\n\n      # Set up the ranlib parameters.\n      oldlib=$destdir/$name\n      func_to_tool_file \"$oldlib\" func_convert_file_msys_to_w32\n      tool_oldlib=$func_to_tool_file_result\n\n      func_show_eval \"$install_prog \\$file \\$oldlib\" 'exit $?'\n\n      if test -n \"$stripme\" && test -n \"$old_striplib\"; then\n\tfunc_show_eval \"$old_striplib $tool_oldlib\" 'exit $?'\n      fi\n\n      # Do each command in the postinstall commands.\n      func_execute_cmds \"$old_postinstall_cmds\" 'exit $?'\n    done\n\n    test -n \"$future_libdirs\" && \\\n      func_warning \"remember to run '$progname --finish$future_libdirs'\"\n\n    if test -n \"$current_libdirs\"; then\n      # Maybe just do a dry run.\n      $opt_dry_run && current_libdirs=\" -n$current_libdirs\"\n      exec_cmd='$SHELL \"$progpath\" $preserve_args --finish$current_libdirs'\n    else\n      exit $EXIT_SUCCESS\n    fi\n}\n\ntest install = \"$opt_mode\" && func_mode_install ${1+\"$@\"}\n\n\n# func_generate_dlsyms outputname originator pic_p\n# Extract symbols from dlprefiles and create ${outputname}S.o with\n# a dlpreopen symbol table.\nfunc_generate_dlsyms ()\n{\n    $debug_cmd\n\n    my_outputname=$1\n    my_originator=$2\n    my_pic_p=${3-false}\n    my_prefix=`$ECHO \"$my_originator\" | $SED 's%[^a-zA-Z0-9]%_%g'`\n    my_dlsyms=\n\n    if test -n \"$dlfiles$dlprefiles\" || test no != \"$dlself\"; then\n      if test -n \"$NM\" && test -n \"$global_symbol_pipe\"; then\n\tmy_dlsyms=${my_outputname}S.c\n      else\n\tfunc_error \"not configured to extract global symbols from dlpreopened files\"\n      fi\n    fi\n\n    if test -n \"$my_dlsyms\"; then\n      case $my_dlsyms in\n      \"\") ;;\n      *.c)\n\t# Discover the nlist of each of the dlfiles.\n\tnlist=$output_objdir/$my_outputname.nm\n\n\tfunc_show_eval \"$RM $nlist ${nlist}S ${nlist}T\"\n\n\t# Parse the name list into a source file.\n\tfunc_verbose \"creating $output_objdir/$my_dlsyms\"\n\n\t$opt_dry_run || $ECHO > \"$output_objdir/$my_dlsyms\" \"\\\n/* $my_dlsyms - symbol resolution table for '$my_outputname' dlsym emulation. */\n/* Generated by $PROGRAM (GNU $PACKAGE) $VERSION */\n\n#ifdef __cplusplus\nextern \\\"C\\\" {\n#endif\n\n#if defined __GNUC__ && (((__GNUC__ == 4) && (__GNUC_MINOR__ >= 4)) || (__GNUC__ > 4))\n#pragma GCC diagnostic ignored \\\"-Wstrict-prototypes\\\"\n#endif\n\n/* Keep this code in sync between libtool.m4, ltmain, lt_system.h, and tests.  */\n#if defined _WIN32 || defined __CYGWIN__ || defined _WIN32_WCE\n/* DATA imports from DLLs on WIN32 can't be const, because runtime\n   relocations are performed -- see ld's documentation on pseudo-relocs.  */\n# define LT_DLSYM_CONST\n#elif defined __osf__\n/* This system does not cope well with relocations in const data.  */\n# define LT_DLSYM_CONST\n#else\n# define LT_DLSYM_CONST const\n#endif\n\n#define STREQ(s1, s2) (strcmp ((s1), (s2)) == 0)\n\n/* External symbol declarations for the compiler. */\\\n\"\n\n\tif test yes = \"$dlself\"; then\n\t  func_verbose \"generating symbol list for '$output'\"\n\n\t  $opt_dry_run || echo ': @PROGRAM@ ' > \"$nlist\"\n\n\t  # Add our own program objects to the symbol list.\n\t  progfiles=`$ECHO \"$objs$old_deplibs\" | $SP2NL | $SED \"$lo2o\" | $NL2SP`\n\t  for progfile in $progfiles; do\n\t    func_to_tool_file \"$progfile\" func_convert_file_msys_to_w32\n\t    func_verbose \"extracting global C symbols from '$func_to_tool_file_result'\"\n\t    $opt_dry_run || eval \"$NM $func_to_tool_file_result | $global_symbol_pipe >> '$nlist'\"\n\t  done\n\n\t  if test -n \"$exclude_expsyms\"; then\n\t    $opt_dry_run || {\n\t      eval '$EGREP -v \" ($exclude_expsyms)$\" \"$nlist\" > \"$nlist\"T'\n\t      eval '$MV \"$nlist\"T \"$nlist\"'\n\t    }\n\t  fi\n\n\t  if test -n \"$export_symbols_regex\"; then\n\t    $opt_dry_run || {\n\t      eval '$EGREP -e \"$export_symbols_regex\" \"$nlist\" > \"$nlist\"T'\n\t      eval '$MV \"$nlist\"T \"$nlist\"'\n\t    }\n\t  fi\n\n\t  # Prepare the list of exported symbols\n\t  if test -z \"$export_symbols\"; then\n\t    export_symbols=$output_objdir/$outputname.exp\n\t    $opt_dry_run || {\n\t      $RM $export_symbols\n\t      eval \"$SED -n -e '/^: @PROGRAM@ $/d' -e 's/^.* \\(.*\\)$/\\1/p' \"'< \"$nlist\" > \"$export_symbols\"'\n\t      case $host in\n\t      *cygwin* | *mingw* | *cegcc* )\n                eval \"echo EXPORTS \"'> \"$output_objdir/$outputname.def\"'\n                eval 'cat \"$export_symbols\" >> \"$output_objdir/$outputname.def\"'\n\t        ;;\n\t      esac\n\t    }\n\t  else\n\t    $opt_dry_run || {\n\t      eval \"$SED -e 's/\\([].[*^$]\\)/\\\\\\\\\\1/g' -e 's/^/ /' -e 's/$/$/'\"' < \"$export_symbols\" > \"$output_objdir/$outputname.exp\"'\n\t      eval '$GREP -f \"$output_objdir/$outputname.exp\" < \"$nlist\" > \"$nlist\"T'\n\t      eval '$MV \"$nlist\"T \"$nlist\"'\n\t      case $host in\n\t        *cygwin* | *mingw* | *cegcc* )\n\t          eval \"echo EXPORTS \"'> \"$output_objdir/$outputname.def\"'\n\t          eval 'cat \"$nlist\" >> \"$output_objdir/$outputname.def\"'\n\t          ;;\n\t      esac\n\t    }\n\t  fi\n\tfi\n\n\tfor dlprefile in $dlprefiles; do\n\t  func_verbose \"extracting global C symbols from '$dlprefile'\"\n\t  func_basename \"$dlprefile\"\n\t  name=$func_basename_result\n          case $host in\n\t    *cygwin* | *mingw* | *cegcc* )\n\t      # if an import library, we need to obtain dlname\n\t      if func_win32_import_lib_p \"$dlprefile\"; then\n\t        func_tr_sh \"$dlprefile\"\n\t        eval \"curr_lafile=\\$libfile_$func_tr_sh_result\"\n\t        dlprefile_dlbasename=\n\t        if test -n \"$curr_lafile\" && func_lalib_p \"$curr_lafile\"; then\n\t          # Use subshell, to avoid clobbering current variable values\n\t          dlprefile_dlname=`source \"$curr_lafile\" && echo \"$dlname\"`\n\t          if test -n \"$dlprefile_dlname\"; then\n\t            func_basename \"$dlprefile_dlname\"\n\t            dlprefile_dlbasename=$func_basename_result\n\t          else\n\t            # no lafile. user explicitly requested -dlpreopen <import library>.\n\t            $sharedlib_from_linklib_cmd \"$dlprefile\"\n\t            dlprefile_dlbasename=$sharedlib_from_linklib_result\n\t          fi\n\t        fi\n\t        $opt_dry_run || {\n\t          if test -n \"$dlprefile_dlbasename\"; then\n\t            eval '$ECHO \": $dlprefile_dlbasename\" >> \"$nlist\"'\n\t          else\n\t            func_warning \"Could not compute DLL name from $name\"\n\t            eval '$ECHO \": $name \" >> \"$nlist\"'\n\t          fi\n\t          func_to_tool_file \"$dlprefile\" func_convert_file_msys_to_w32\n\t          eval \"$NM \\\"$func_to_tool_file_result\\\" 2>/dev/null | $global_symbol_pipe |\n\t            $SED -e '/I __imp/d' -e 's/I __nm_/D /;s/_nm__//' >> '$nlist'\"\n\t        }\n\t      else # not an import lib\n\t        $opt_dry_run || {\n\t          eval '$ECHO \": $name \" >> \"$nlist\"'\n\t          func_to_tool_file \"$dlprefile\" func_convert_file_msys_to_w32\n\t          eval \"$NM \\\"$func_to_tool_file_result\\\" 2>/dev/null | $global_symbol_pipe >> '$nlist'\"\n\t        }\n\t      fi\n\t    ;;\n\t    *)\n\t      $opt_dry_run || {\n\t        eval '$ECHO \": $name \" >> \"$nlist\"'\n\t        func_to_tool_file \"$dlprefile\" func_convert_file_msys_to_w32\n\t        eval \"$NM \\\"$func_to_tool_file_result\\\" 2>/dev/null | $global_symbol_pipe >> '$nlist'\"\n\t      }\n\t    ;;\n          esac\n\tdone\n\n\t$opt_dry_run || {\n\t  # Make sure we have at least an empty file.\n\t  test -f \"$nlist\" || : > \"$nlist\"\n\n\t  if test -n \"$exclude_expsyms\"; then\n\t    $EGREP -v \" ($exclude_expsyms)$\" \"$nlist\" > \"$nlist\"T\n\t    $MV \"$nlist\"T \"$nlist\"\n\t  fi\n\n\t  # Try sorting and uniquifying the output.\n\t  if $GREP -v \"^: \" < \"$nlist\" |\n\t      if sort -k 3 </dev/null >/dev/null 2>&1; then\n\t\tsort -k 3\n\t      else\n\t\tsort +2\n\t      fi |\n\t      uniq > \"$nlist\"S; then\n\t    :\n\t  else\n\t    $GREP -v \"^: \" < \"$nlist\" > \"$nlist\"S\n\t  fi\n\n\t  if test -f \"$nlist\"S; then\n\t    eval \"$global_symbol_to_cdecl\"' < \"$nlist\"S >> \"$output_objdir/$my_dlsyms\"'\n\t  else\n\t    echo '/* NONE */' >> \"$output_objdir/$my_dlsyms\"\n\t  fi\n\n\t  func_show_eval '$RM \"${nlist}I\"'\n\t  if test -n \"$global_symbol_to_import\"; then\n\t    eval \"$global_symbol_to_import\"' < \"$nlist\"S > \"$nlist\"I'\n\t  fi\n\n\t  echo >> \"$output_objdir/$my_dlsyms\" \"\\\n\n/* The mapping between symbol names and symbols.  */\ntypedef struct {\n  const char *name;\n  void *address;\n} lt_dlsymlist;\nextern LT_DLSYM_CONST lt_dlsymlist\nlt_${my_prefix}_LTX_preloaded_symbols[];\\\n\"\n\n\t  if test -s \"$nlist\"I; then\n\t    echo >> \"$output_objdir/$my_dlsyms\" \"\\\nstatic void lt_syminit(void)\n{\n  LT_DLSYM_CONST lt_dlsymlist *symbol = lt_${my_prefix}_LTX_preloaded_symbols;\n  for (; symbol->name; ++symbol)\n    {\"\n\t    $SED 's/.*/      if (STREQ (symbol->name, \\\"&\\\")) symbol->address = (void *) \\&&;/' < \"$nlist\"I >> \"$output_objdir/$my_dlsyms\"\n\t    echo >> \"$output_objdir/$my_dlsyms\" \"\\\n    }\n}\"\n\t  fi\n\t  echo >> \"$output_objdir/$my_dlsyms\" \"\\\nLT_DLSYM_CONST lt_dlsymlist\nlt_${my_prefix}_LTX_preloaded_symbols[] =\n{ {\\\"$my_originator\\\", (void *) 0},\"\n\n\t  if test -s \"$nlist\"I; then\n\t    echo >> \"$output_objdir/$my_dlsyms\" \"\\\n  {\\\"@INIT@\\\", (void *) &lt_syminit},\"\n\t  fi\n\n\t  case $need_lib_prefix in\n\t  no)\n\t    eval \"$global_symbol_to_c_name_address\" < \"$nlist\" >> \"$output_objdir/$my_dlsyms\"\n\t    ;;\n\t  *)\n\t    eval \"$global_symbol_to_c_name_address_lib_prefix\" < \"$nlist\" >> \"$output_objdir/$my_dlsyms\"\n\t    ;;\n\t  esac\n\t  echo >> \"$output_objdir/$my_dlsyms\" \"\\\n  {0, (void *) 0}\n};\n\n/* This works around a problem in FreeBSD linker */\n#ifdef FREEBSD_WORKAROUND\nstatic const void *lt_preloaded_setup() {\n  return lt_${my_prefix}_LTX_preloaded_symbols;\n}\n#endif\n\n#ifdef __cplusplus\n}\n#endif\\\n\"\n\t} # !$opt_dry_run\n\n\tpic_flag_for_symtable=\n\tcase \"$compile_command \" in\n\t*\" -static \"*) ;;\n\t*)\n\t  case $host in\n\t  # compiling the symbol table file with pic_flag works around\n\t  # a FreeBSD bug that causes programs to crash when -lm is\n\t  # linked before any other PIC object.  But we must not use\n\t  # pic_flag when linking with -static.  The problem exists in\n\t  # FreeBSD 2.2.6 and is fixed in FreeBSD 3.1.\n\t  *-*-freebsd2.*|*-*-freebsd3.0*|*-*-freebsdelf3.0*)\n\t    pic_flag_for_symtable=\" $pic_flag -DFREEBSD_WORKAROUND\" ;;\n\t  *-*-hpux*)\n\t    pic_flag_for_symtable=\" $pic_flag\"  ;;\n\t  *)\n\t    $my_pic_p && pic_flag_for_symtable=\" $pic_flag\"\n\t    ;;\n\t  esac\n\t  ;;\n\tesac\n\tsymtab_cflags=\n\tfor arg in $LTCFLAGS; do\n\t  case $arg in\n\t  -pie | -fpie | -fPIE) ;;\n\t  *) func_append symtab_cflags \" $arg\" ;;\n\t  esac\n\tdone\n\n\t# Now compile the dynamic symbol file.\n\tfunc_show_eval '(cd $output_objdir && $LTCC$symtab_cflags -c$no_builtin_flag$pic_flag_for_symtable \"$my_dlsyms\")' 'exit $?'\n\n\t# Clean up the generated files.\n\tfunc_show_eval '$RM \"$output_objdir/$my_dlsyms\" \"$nlist\" \"${nlist}S\" \"${nlist}T\" \"${nlist}I\"'\n\n\t# Transform the symbol file into the correct name.\n\tsymfileobj=$output_objdir/${my_outputname}S.$objext\n\tcase $host in\n\t*cygwin* | *mingw* | *cegcc* )\n\t  if test -f \"$output_objdir/$my_outputname.def\"; then\n\t    compile_command=`$ECHO \"$compile_command\" | $SED \"s%@SYMFILE@%$output_objdir/$my_outputname.def $symfileobj%\"`\n\t    finalize_command=`$ECHO \"$finalize_command\" | $SED \"s%@SYMFILE@%$output_objdir/$my_outputname.def $symfileobj%\"`\n\t  else\n\t    compile_command=`$ECHO \"$compile_command\" | $SED \"s%@SYMFILE@%$symfileobj%\"`\n\t    finalize_command=`$ECHO \"$finalize_command\" | $SED \"s%@SYMFILE@%$symfileobj%\"`\n\t  fi\n\t  ;;\n\t*)\n\t  compile_command=`$ECHO \"$compile_command\" | $SED \"s%@SYMFILE@%$symfileobj%\"`\n\t  finalize_command=`$ECHO \"$finalize_command\" | $SED \"s%@SYMFILE@%$symfileobj%\"`\n\t  ;;\n\tesac\n\t;;\n      *)\n\tfunc_fatal_error \"unknown suffix for '$my_dlsyms'\"\n\t;;\n      esac\n    else\n      # We keep going just in case the user didn't refer to\n      # lt_preloaded_symbols.  The linker will fail if global_symbol_pipe\n      # really was required.\n\n      # Nullify the symbol file.\n      compile_command=`$ECHO \"$compile_command\" | $SED \"s% @SYMFILE@%%\"`\n      finalize_command=`$ECHO \"$finalize_command\" | $SED \"s% @SYMFILE@%%\"`\n    fi\n}\n\n# func_cygming_gnu_implib_p ARG\n# This predicate returns with zero status (TRUE) if\n# ARG is a GNU/binutils-style import library. Returns\n# with nonzero status (FALSE) otherwise.\nfunc_cygming_gnu_implib_p ()\n{\n  $debug_cmd\n\n  func_to_tool_file \"$1\" func_convert_file_msys_to_w32\n  func_cygming_gnu_implib_tmp=`$NM \"$func_to_tool_file_result\" | eval \"$global_symbol_pipe\" | $EGREP ' (_head_[A-Za-z0-9_]+_[ad]l*|[A-Za-z0-9_]+_[ad]l*_iname)$'`\n  test -n \"$func_cygming_gnu_implib_tmp\"\n}\n\n# func_cygming_ms_implib_p ARG\n# This predicate returns with zero status (TRUE) if\n# ARG is an MS-style import library. Returns\n# with nonzero status (FALSE) otherwise.\nfunc_cygming_ms_implib_p ()\n{\n  $debug_cmd\n\n  func_to_tool_file \"$1\" func_convert_file_msys_to_w32\n  func_cygming_ms_implib_tmp=`$NM \"$func_to_tool_file_result\" | eval \"$global_symbol_pipe\" | $GREP '_NULL_IMPORT_DESCRIPTOR'`\n  test -n \"$func_cygming_ms_implib_tmp\"\n}\n\n# func_win32_libid arg\n# return the library type of file 'arg'\n#\n# Need a lot of goo to handle *both* DLLs and import libs\n# Has to be a shell function in order to 'eat' the argument\n# that is supplied when $file_magic_command is called.\n# Despite the name, also deal with 64 bit binaries.\nfunc_win32_libid ()\n{\n  $debug_cmd\n\n  win32_libid_type=unknown\n  win32_fileres=`file -L $1 2>/dev/null`\n  case $win32_fileres in\n  *ar\\ archive\\ import\\ library*) # definitely import\n    win32_libid_type=\"x86 archive import\"\n    ;;\n  *ar\\ archive*) # could be an import, or static\n    # Keep the egrep pattern in sync with the one in _LT_CHECK_MAGIC_METHOD.\n    if eval $OBJDUMP -f $1 | $SED -e '10q' 2>/dev/null |\n       $EGREP 'file format (pei*-i386(.*architecture: i386)?|pe-arm-wince|pe-x86-64)' >/dev/null; then\n      case $nm_interface in\n      \"MS dumpbin\")\n\tif func_cygming_ms_implib_p \"$1\" ||\n\t   func_cygming_gnu_implib_p \"$1\"\n\tthen\n\t  win32_nmres=import\n\telse\n\t  win32_nmres=\n\tfi\n\t;;\n      *)\n\tfunc_to_tool_file \"$1\" func_convert_file_msys_to_w32\n\twin32_nmres=`eval $NM -f posix -A \\\"$func_to_tool_file_result\\\" |\n\t  $SED -n -e '\n\t    1,100{\n\t\t/ I /{\n\t\t    s|.*|import|\n\t\t    p\n\t\t    q\n\t\t}\n\t    }'`\n\t;;\n      esac\n      case $win32_nmres in\n      import*)  win32_libid_type=\"x86 archive import\";;\n      *)        win32_libid_type=\"x86 archive static\";;\n      esac\n    fi\n    ;;\n  *DLL*)\n    win32_libid_type=\"x86 DLL\"\n    ;;\n  *executable*) # but shell scripts are \"executable\" too...\n    case $win32_fileres in\n    *MS\\ Windows\\ PE\\ Intel*)\n      win32_libid_type=\"x86 DLL\"\n      ;;\n    esac\n    ;;\n  esac\n  $ECHO \"$win32_libid_type\"\n}\n\n# func_cygming_dll_for_implib ARG\n#\n# Platform-specific function to extract the\n# name of the DLL associated with the specified\n# import library ARG.\n# Invoked by eval'ing the libtool variable\n#    $sharedlib_from_linklib_cmd\n# Result is available in the variable\n#    $sharedlib_from_linklib_result\nfunc_cygming_dll_for_implib ()\n{\n  $debug_cmd\n\n  sharedlib_from_linklib_result=`$DLLTOOL --identify-strict --identify \"$1\"`\n}\n\n# func_cygming_dll_for_implib_fallback_core SECTION_NAME LIBNAMEs\n#\n# The is the core of a fallback implementation of a\n# platform-specific function to extract the name of the\n# DLL associated with the specified import library LIBNAME.\n#\n# SECTION_NAME is either .idata$6 or .idata$7, depending\n# on the platform and compiler that created the implib.\n#\n# Echos the name of the DLL associated with the\n# specified import library.\nfunc_cygming_dll_for_implib_fallback_core ()\n{\n  $debug_cmd\n\n  match_literal=`$ECHO \"$1\" | $SED \"$sed_make_literal_regex\"`\n  $OBJDUMP -s --section \"$1\" \"$2\" 2>/dev/null |\n    $SED '/^Contents of section '\"$match_literal\"':/{\n      # Place marker at beginning of archive member dllname section\n      s/.*/====MARK====/\n      p\n      d\n    }\n    # These lines can sometimes be longer than 43 characters, but\n    # are always uninteresting\n    /:[\t ]*file format pe[i]\\{,1\\}-/d\n    /^In archive [^:]*:/d\n    # Ensure marker is printed\n    /^====MARK====/p\n    # Remove all lines with less than 43 characters\n    /^.\\{43\\}/!d\n    # From remaining lines, remove first 43 characters\n    s/^.\\{43\\}//' |\n    $SED -n '\n      # Join marker and all lines until next marker into a single line\n      /^====MARK====/ b para\n      H\n      $ b para\n      b\n      :para\n      x\n      s/\\n//g\n      # Remove the marker\n      s/^====MARK====//\n      # Remove trailing dots and whitespace\n      s/[\\. \\t]*$//\n      # Print\n      /./p' |\n    # we now have a list, one entry per line, of the stringified\n    # contents of the appropriate section of all members of the\n    # archive that possess that section. Heuristic: eliminate\n    # all those that have a first or second character that is\n    # a '.' (that is, objdump's representation of an unprintable\n    # character.) This should work for all archives with less than\n    # 0x302f exports -- but will fail for DLLs whose name actually\n    # begins with a literal '.' or a single character followed by\n    # a '.'.\n    #\n    # Of those that remain, print the first one.\n    $SED -e '/^\\./d;/^.\\./d;q'\n}\n\n# func_cygming_dll_for_implib_fallback ARG\n# Platform-specific function to extract the\n# name of the DLL associated with the specified\n# import library ARG.\n#\n# This fallback implementation is for use when $DLLTOOL\n# does not support the --identify-strict option.\n# Invoked by eval'ing the libtool variable\n#    $sharedlib_from_linklib_cmd\n# Result is available in the variable\n#    $sharedlib_from_linklib_result\nfunc_cygming_dll_for_implib_fallback ()\n{\n  $debug_cmd\n\n  if func_cygming_gnu_implib_p \"$1\"; then\n    # binutils import library\n    sharedlib_from_linklib_result=`func_cygming_dll_for_implib_fallback_core '.idata$7' \"$1\"`\n  elif func_cygming_ms_implib_p \"$1\"; then\n    # ms-generated import library\n    sharedlib_from_linklib_result=`func_cygming_dll_for_implib_fallback_core '.idata$6' \"$1\"`\n  else\n    # unknown\n    sharedlib_from_linklib_result=\n  fi\n}\n\n\n# func_extract_an_archive dir oldlib\nfunc_extract_an_archive ()\n{\n    $debug_cmd\n\n    f_ex_an_ar_dir=$1; shift\n    f_ex_an_ar_oldlib=$1\n    if test yes = \"$lock_old_archive_extraction\"; then\n      lockfile=$f_ex_an_ar_oldlib.lock\n      until $opt_dry_run || ln \"$progpath\" \"$lockfile\" 2>/dev/null; do\n\tfunc_echo \"Waiting for $lockfile to be removed\"\n\tsleep 2\n      done\n    fi\n    func_show_eval \"(cd \\$f_ex_an_ar_dir && $AR x \\\"\\$f_ex_an_ar_oldlib\\\")\" \\\n\t\t   'stat=$?; rm -f \"$lockfile\"; exit $stat'\n    if test yes = \"$lock_old_archive_extraction\"; then\n      $opt_dry_run || rm -f \"$lockfile\"\n    fi\n    if ($AR t \"$f_ex_an_ar_oldlib\" | sort | sort -uc >/dev/null 2>&1); then\n     :\n    else\n      func_fatal_error \"object name conflicts in archive: $f_ex_an_ar_dir/$f_ex_an_ar_oldlib\"\n    fi\n}\n\n\n# func_extract_archives gentop oldlib ...\nfunc_extract_archives ()\n{\n    $debug_cmd\n\n    my_gentop=$1; shift\n    my_oldlibs=${1+\"$@\"}\n    my_oldobjs=\n    my_xlib=\n    my_xabs=\n    my_xdir=\n\n    for my_xlib in $my_oldlibs; do\n      # Extract the objects.\n      case $my_xlib in\n\t[\\\\/]* | [A-Za-z]:[\\\\/]*) my_xabs=$my_xlib ;;\n\t*) my_xabs=`pwd`\"/$my_xlib\" ;;\n      esac\n      func_basename \"$my_xlib\"\n      my_xlib=$func_basename_result\n      my_xlib_u=$my_xlib\n      while :; do\n        case \" $extracted_archives \" in\n\t*\" $my_xlib_u \"*)\n\t  func_arith $extracted_serial + 1\n\t  extracted_serial=$func_arith_result\n\t  my_xlib_u=lt$extracted_serial-$my_xlib ;;\n\t*) break ;;\n\tesac\n      done\n      extracted_archives=\"$extracted_archives $my_xlib_u\"\n      my_xdir=$my_gentop/$my_xlib_u\n\n      func_mkdir_p \"$my_xdir\"\n\n      case $host in\n      *-darwin*)\n\tfunc_verbose \"Extracting $my_xabs\"\n\t# Do not bother doing anything if just a dry run\n\t$opt_dry_run || {\n\t  darwin_orig_dir=`pwd`\n\t  cd $my_xdir || exit $?\n\t  darwin_archive=$my_xabs\n\t  darwin_curdir=`pwd`\n\t  func_basename \"$darwin_archive\"\n\t  darwin_base_archive=$func_basename_result\n\t  darwin_arches=`$LIPO -info \"$darwin_archive\" 2>/dev/null | $GREP Architectures 2>/dev/null || true`\n\t  if test -n \"$darwin_arches\"; then\n\t    darwin_arches=`$ECHO \"$darwin_arches\" | $SED -e 's/.*are://'`\n\t    darwin_arch=\n\t    func_verbose \"$darwin_base_archive has multiple architectures $darwin_arches\"\n\t    for darwin_arch in  $darwin_arches; do\n\t      func_mkdir_p \"unfat-$$/$darwin_base_archive-$darwin_arch\"\n\t      $LIPO -thin $darwin_arch -output \"unfat-$$/$darwin_base_archive-$darwin_arch/$darwin_base_archive\" \"$darwin_archive\"\n\t      cd \"unfat-$$/$darwin_base_archive-$darwin_arch\"\n\t      func_extract_an_archive \"`pwd`\" \"$darwin_base_archive\"\n\t      cd \"$darwin_curdir\"\n\t      $RM \"unfat-$$/$darwin_base_archive-$darwin_arch/$darwin_base_archive\"\n\t    done # $darwin_arches\n            ## Okay now we've a bunch of thin objects, gotta fatten them up :)\n\t    darwin_filelist=`find unfat-$$ -type f -name \\*.o -print -o -name \\*.lo -print | $SED -e \"$sed_basename\" | sort -u`\n\t    darwin_file=\n\t    darwin_files=\n\t    for darwin_file in $darwin_filelist; do\n\t      darwin_files=`find unfat-$$ -name $darwin_file -print | sort | $NL2SP`\n\t      $LIPO -create -output \"$darwin_file\" $darwin_files\n\t    done # $darwin_filelist\n\t    $RM -rf unfat-$$\n\t    cd \"$darwin_orig_dir\"\n\t  else\n\t    cd $darwin_orig_dir\n\t    func_extract_an_archive \"$my_xdir\" \"$my_xabs\"\n\t  fi # $darwin_arches\n\t} # !$opt_dry_run\n\t;;\n      *)\n        func_extract_an_archive \"$my_xdir\" \"$my_xabs\"\n\t;;\n      esac\n      my_oldobjs=\"$my_oldobjs \"`find $my_xdir -name \\*.$objext -print -o -name \\*.lo -print | sort | $NL2SP`\n    done\n\n    func_extract_archives_result=$my_oldobjs\n}\n\n\n# func_emit_wrapper [arg=no]\n#\n# Emit a libtool wrapper script on stdout.\n# Don't directly open a file because we may want to\n# incorporate the script contents within a cygwin/mingw\n# wrapper executable.  Must ONLY be called from within\n# func_mode_link because it depends on a number of variables\n# set therein.\n#\n# ARG is the value that the WRAPPER_SCRIPT_BELONGS_IN_OBJDIR\n# variable will take.  If 'yes', then the emitted script\n# will assume that the directory where it is stored is\n# the $objdir directory.  This is a cygwin/mingw-specific\n# behavior.\nfunc_emit_wrapper ()\n{\n\tfunc_emit_wrapper_arg1=${1-no}\n\n\t$ECHO \"\\\n#! $SHELL\n\n# $output - temporary wrapper script for $objdir/$outputname\n# Generated by $PROGRAM (GNU $PACKAGE) $VERSION\n#\n# The $output program cannot be directly executed until all the libtool\n# libraries that it depends on are installed.\n#\n# This wrapper script should never be moved out of the build directory.\n# If it is, it will not operate correctly.\n\n# Sed substitution that helps us do robust quoting.  It backslashifies\n# metacharacters that are still active within double-quoted strings.\nsed_quote_subst='$sed_quote_subst'\n\n# Be Bourne compatible\nif test -n \\\"\\${ZSH_VERSION+set}\\\" && (emulate sh) >/dev/null 2>&1; then\n  emulate sh\n  NULLCMD=:\n  # Zsh 3.x and 4.x performs word splitting on \\${1+\\\"\\$@\\\"}, which\n  # is contrary to our usage.  Disable this feature.\n  alias -g '\\${1+\\\"\\$@\\\"}'='\\\"\\$@\\\"'\n  setopt NO_GLOB_SUBST\nelse\n  case \\`(set -o) 2>/dev/null\\` in *posix*) set -o posix;; esac\nfi\nBIN_SH=xpg4; export BIN_SH # for Tru64\nDUALCASE=1; export DUALCASE # for MKS sh\n\n# The HP-UX ksh and POSIX shell print the target directory to stdout\n# if CDPATH is set.\n(unset CDPATH) >/dev/null 2>&1 && unset CDPATH\n\nrelink_command=\\\"$relink_command\\\"\n\n# This environment variable determines our operation mode.\nif test \\\"\\$libtool_install_magic\\\" = \\\"$magic\\\"; then\n  # install mode needs the following variables:\n  generated_by_libtool_version='$macro_version'\n  notinst_deplibs='$notinst_deplibs'\nelse\n  # When we are sourced in execute mode, \\$file and \\$ECHO are already set.\n  if test \\\"\\$libtool_execute_magic\\\" != \\\"$magic\\\"; then\n    file=\\\"\\$0\\\"\"\n\n    qECHO=`$ECHO \"$ECHO\" | $SED \"$sed_quote_subst\"`\n    $ECHO \"\\\n\n# A function that is used when there is no print builtin or printf.\nfunc_fallback_echo ()\n{\n  eval 'cat <<_LTECHO_EOF\n\\$1\n_LTECHO_EOF'\n}\n    ECHO=\\\"$qECHO\\\"\n  fi\n\n# Very basic option parsing. These options are (a) specific to\n# the libtool wrapper, (b) are identical between the wrapper\n# /script/ and the wrapper /executable/ that is used only on\n# windows platforms, and (c) all begin with the string \"--lt-\"\n# (application programs are unlikely to have options that match\n# this pattern).\n#\n# There are only two supported options: --lt-debug and\n# --lt-dump-script. There is, deliberately, no --lt-help.\n#\n# The first argument to this parsing function should be the\n# script's $0 value, followed by \"$@\".\nlt_option_debug=\nfunc_parse_lt_options ()\n{\n  lt_script_arg0=\\$0\n  shift\n  for lt_opt\n  do\n    case \\\"\\$lt_opt\\\" in\n    --lt-debug) lt_option_debug=1 ;;\n    --lt-dump-script)\n        lt_dump_D=\\`\\$ECHO \\\"X\\$lt_script_arg0\\\" | $SED -e 's/^X//' -e 's%/[^/]*$%%'\\`\n        test \\\"X\\$lt_dump_D\\\" = \\\"X\\$lt_script_arg0\\\" && lt_dump_D=.\n        lt_dump_F=\\`\\$ECHO \\\"X\\$lt_script_arg0\\\" | $SED -e 's/^X//' -e 's%^.*/%%'\\`\n        cat \\\"\\$lt_dump_D/\\$lt_dump_F\\\"\n        exit 0\n      ;;\n    --lt-*)\n        \\$ECHO \\\"Unrecognized --lt- option: '\\$lt_opt'\\\" 1>&2\n        exit 1\n      ;;\n    esac\n  done\n\n  # Print the debug banner immediately:\n  if test -n \\\"\\$lt_option_debug\\\"; then\n    echo \\\"$outputname:$output:\\$LINENO: libtool wrapper (GNU $PACKAGE) $VERSION\\\" 1>&2\n  fi\n}\n\n# Used when --lt-debug. Prints its arguments to stdout\n# (redirection is the responsibility of the caller)\nfunc_lt_dump_args ()\n{\n  lt_dump_args_N=1;\n  for lt_arg\n  do\n    \\$ECHO \\\"$outputname:$output:\\$LINENO: newargv[\\$lt_dump_args_N]: \\$lt_arg\\\"\n    lt_dump_args_N=\\`expr \\$lt_dump_args_N + 1\\`\n  done\n}\n\n# Core function for launching the target application\nfunc_exec_program_core ()\n{\n\"\n  case $host in\n  # Backslashes separate directories on plain windows\n  *-*-mingw | *-*-os2* | *-cegcc*)\n    $ECHO \"\\\n      if test -n \\\"\\$lt_option_debug\\\"; then\n        \\$ECHO \\\"$outputname:$output:\\$LINENO: newargv[0]: \\$progdir\\\\\\\\\\$program\\\" 1>&2\n        func_lt_dump_args \\${1+\\\"\\$@\\\"} 1>&2\n      fi\n      exec \\\"\\$progdir\\\\\\\\\\$program\\\" \\${1+\\\"\\$@\\\"}\n\"\n    ;;\n\n  *)\n    $ECHO \"\\\n      if test -n \\\"\\$lt_option_debug\\\"; then\n        \\$ECHO \\\"$outputname:$output:\\$LINENO: newargv[0]: \\$progdir/\\$program\\\" 1>&2\n        func_lt_dump_args \\${1+\\\"\\$@\\\"} 1>&2\n      fi\n      exec \\\"\\$progdir/\\$program\\\" \\${1+\\\"\\$@\\\"}\n\"\n    ;;\n  esac\n  $ECHO \"\\\n      \\$ECHO \\\"\\$0: cannot exec \\$program \\$*\\\" 1>&2\n      exit 1\n}\n\n# A function to encapsulate launching the target application\n# Strips options in the --lt-* namespace from \\$@ and\n# launches target application with the remaining arguments.\nfunc_exec_program ()\n{\n  case \\\" \\$* \\\" in\n  *\\\\ --lt-*)\n    for lt_wr_arg\n    do\n      case \\$lt_wr_arg in\n      --lt-*) ;;\n      *) set x \\\"\\$@\\\" \\\"\\$lt_wr_arg\\\"; shift;;\n      esac\n      shift\n    done ;;\n  esac\n  func_exec_program_core \\${1+\\\"\\$@\\\"}\n}\n\n  # Parse options\n  func_parse_lt_options \\\"\\$0\\\" \\${1+\\\"\\$@\\\"}\n\n  # Find the directory that this script lives in.\n  thisdir=\\`\\$ECHO \\\"\\$file\\\" | $SED 's%/[^/]*$%%'\\`\n  test \\\"x\\$thisdir\\\" = \\\"x\\$file\\\" && thisdir=.\n\n  # Follow symbolic links until we get to the real thisdir.\n  file=\\`ls -ld \\\"\\$file\\\" | $SED -n 's/.*-> //p'\\`\n  while test -n \\\"\\$file\\\"; do\n    destdir=\\`\\$ECHO \\\"\\$file\\\" | $SED 's%/[^/]*\\$%%'\\`\n\n    # If there was a directory component, then change thisdir.\n    if test \\\"x\\$destdir\\\" != \\\"x\\$file\\\"; then\n      case \\\"\\$destdir\\\" in\n      [\\\\\\\\/]* | [A-Za-z]:[\\\\\\\\/]*) thisdir=\\\"\\$destdir\\\" ;;\n      *) thisdir=\\\"\\$thisdir/\\$destdir\\\" ;;\n      esac\n    fi\n\n    file=\\`\\$ECHO \\\"\\$file\\\" | $SED 's%^.*/%%'\\`\n    file=\\`ls -ld \\\"\\$thisdir/\\$file\\\" | $SED -n 's/.*-> //p'\\`\n  done\n\n  # Usually 'no', except on cygwin/mingw when embedded into\n  # the cwrapper.\n  WRAPPER_SCRIPT_BELONGS_IN_OBJDIR=$func_emit_wrapper_arg1\n  if test \\\"\\$WRAPPER_SCRIPT_BELONGS_IN_OBJDIR\\\" = \\\"yes\\\"; then\n    # special case for '.'\n    if test \\\"\\$thisdir\\\" = \\\".\\\"; then\n      thisdir=\\`pwd\\`\n    fi\n    # remove .libs from thisdir\n    case \\\"\\$thisdir\\\" in\n    *[\\\\\\\\/]$objdir ) thisdir=\\`\\$ECHO \\\"\\$thisdir\\\" | $SED 's%[\\\\\\\\/][^\\\\\\\\/]*$%%'\\` ;;\n    $objdir )   thisdir=. ;;\n    esac\n  fi\n\n  # Try to get the absolute directory name.\n  absdir=\\`cd \\\"\\$thisdir\\\" && pwd\\`\n  test -n \\\"\\$absdir\\\" && thisdir=\\\"\\$absdir\\\"\n\"\n\n\tif test yes = \"$fast_install\"; then\n\t  $ECHO \"\\\n  program=lt-'$outputname'$exeext\n  progdir=\\\"\\$thisdir/$objdir\\\"\n\n  if test ! -f \\\"\\$progdir/\\$program\\\" ||\n     { file=\\`ls -1dt \\\"\\$progdir/\\$program\\\" \\\"\\$progdir/../\\$program\\\" 2>/dev/null | $SED 1q\\`; \\\\\n       test \\\"X\\$file\\\" != \\\"X\\$progdir/\\$program\\\"; }; then\n\n    file=\\\"\\$\\$-\\$program\\\"\n\n    if test ! -d \\\"\\$progdir\\\"; then\n      $MKDIR \\\"\\$progdir\\\"\n    else\n      $RM \\\"\\$progdir/\\$file\\\"\n    fi\"\n\n\t  $ECHO \"\\\n\n    # relink executable if necessary\n    if test -n \\\"\\$relink_command\\\"; then\n      if relink_command_output=\\`eval \\$relink_command 2>&1\\`; then :\n      else\n\t\\$ECHO \\\"\\$relink_command_output\\\" >&2\n\t$RM \\\"\\$progdir/\\$file\\\"\n\texit 1\n      fi\n    fi\n\n    $MV \\\"\\$progdir/\\$file\\\" \\\"\\$progdir/\\$program\\\" 2>/dev/null ||\n    { $RM \\\"\\$progdir/\\$program\\\";\n      $MV \\\"\\$progdir/\\$file\\\" \\\"\\$progdir/\\$program\\\"; }\n    $RM \\\"\\$progdir/\\$file\\\"\n  fi\"\n\telse\n\t  $ECHO \"\\\n  program='$outputname'\n  progdir=\\\"\\$thisdir/$objdir\\\"\n\"\n\tfi\n\n\t$ECHO \"\\\n\n  if test -f \\\"\\$progdir/\\$program\\\"; then\"\n\n\t# fixup the dll searchpath if we need to.\n\t#\n\t# Fix the DLL searchpath if we need to.  Do this before prepending\n\t# to shlibpath, because on Windows, both are PATH and uninstalled\n\t# libraries must come first.\n\tif test -n \"$dllsearchpath\"; then\n\t  $ECHO \"\\\n    # Add the dll search path components to the executable PATH\n    PATH=$dllsearchpath:\\$PATH\n\"\n\tfi\n\n\t# Export our shlibpath_var if we have one.\n\tif test yes = \"$shlibpath_overrides_runpath\" && test -n \"$shlibpath_var\" && test -n \"$temp_rpath\"; then\n\t  $ECHO \"\\\n    # Add our own library path to $shlibpath_var\n    $shlibpath_var=\\\"$temp_rpath\\$$shlibpath_var\\\"\n\n    # Some systems cannot cope with colon-terminated $shlibpath_var\n    # The second colon is a workaround for a bug in BeOS R4 sed\n    $shlibpath_var=\\`\\$ECHO \\\"\\$$shlibpath_var\\\" | $SED 's/::*\\$//'\\`\n\n    export $shlibpath_var\n\"\n\tfi\n\n\t$ECHO \"\\\n    if test \\\"\\$libtool_execute_magic\\\" != \\\"$magic\\\"; then\n      # Run the actual program with our arguments.\n      func_exec_program \\${1+\\\"\\$@\\\"}\n    fi\n  else\n    # The program doesn't exist.\n    \\$ECHO \\\"\\$0: error: '\\$progdir/\\$program' does not exist\\\" 1>&2\n    \\$ECHO \\\"This script is just a wrapper for \\$program.\\\" 1>&2\n    \\$ECHO \\\"See the $PACKAGE documentation for more information.\\\" 1>&2\n    exit 1\n  fi\nfi\\\n\"\n}\n\n\n# func_emit_cwrapperexe_src\n# emit the source code for a wrapper executable on stdout\n# Must ONLY be called from within func_mode_link because\n# it depends on a number of variable set therein.\nfunc_emit_cwrapperexe_src ()\n{\n\tcat <<EOF\n\n/* $cwrappersource - temporary wrapper executable for $objdir/$outputname\n   Generated by $PROGRAM (GNU $PACKAGE) $VERSION\n\n   The $output program cannot be directly executed until all the libtool\n   libraries that it depends on are installed.\n\n   This wrapper executable should never be moved out of the build directory.\n   If it is, it will not operate correctly.\n*/\nEOF\n\t    cat <<\"EOF\"\n#ifdef _MSC_VER\n# define _CRT_SECURE_NO_DEPRECATE 1\n#endif\n#include <stdio.h>\n#include <stdlib.h>\n#ifdef _MSC_VER\n# include <direct.h>\n# include <process.h>\n# include <io.h>\n#else\n# include <unistd.h>\n# include <stdint.h>\n# ifdef __CYGWIN__\n#  include <io.h>\n# endif\n#endif\n#include <malloc.h>\n#include <stdarg.h>\n#include <assert.h>\n#include <string.h>\n#include <ctype.h>\n#include <errno.h>\n#include <fcntl.h>\n#include <sys/stat.h>\n\n#define STREQ(s1, s2) (strcmp ((s1), (s2)) == 0)\n\n/* declarations of non-ANSI functions */\n#if defined __MINGW32__\n# ifdef __STRICT_ANSI__\nint _putenv (const char *);\n# endif\n#elif defined __CYGWIN__\n# ifdef __STRICT_ANSI__\nchar *realpath (const char *, char *);\nint putenv (char *);\nint setenv (const char *, const char *, int);\n# endif\n/* #elif defined other_platform || defined ... */\n#endif\n\n/* portability defines, excluding path handling macros */\n#if defined _MSC_VER\n# define setmode _setmode\n# define stat    _stat\n# define chmod   _chmod\n# define getcwd  _getcwd\n# define putenv  _putenv\n# define S_IXUSR _S_IEXEC\n#elif defined __MINGW32__\n# define setmode _setmode\n# define stat    _stat\n# define chmod   _chmod\n# define getcwd  _getcwd\n# define putenv  _putenv\n#elif defined __CYGWIN__\n# define HAVE_SETENV\n# define FOPEN_WB \"wb\"\n/* #elif defined other platforms ... */\n#endif\n\n#if defined PATH_MAX\n# define LT_PATHMAX PATH_MAX\n#elif defined MAXPATHLEN\n# define LT_PATHMAX MAXPATHLEN\n#else\n# define LT_PATHMAX 1024\n#endif\n\n#ifndef S_IXOTH\n# define S_IXOTH 0\n#endif\n#ifndef S_IXGRP\n# define S_IXGRP 0\n#endif\n\n/* path handling portability macros */\n#ifndef DIR_SEPARATOR\n# define DIR_SEPARATOR '/'\n# define PATH_SEPARATOR ':'\n#endif\n\n#if defined _WIN32 || defined __MSDOS__ || defined __DJGPP__ || \\\n  defined __OS2__\n# define HAVE_DOS_BASED_FILE_SYSTEM\n# define FOPEN_WB \"wb\"\n# ifndef DIR_SEPARATOR_2\n#  define DIR_SEPARATOR_2 '\\\\'\n# endif\n# ifndef PATH_SEPARATOR_2\n#  define PATH_SEPARATOR_2 ';'\n# endif\n#endif\n\n#ifndef DIR_SEPARATOR_2\n# define IS_DIR_SEPARATOR(ch) ((ch) == DIR_SEPARATOR)\n#else /* DIR_SEPARATOR_2 */\n# define IS_DIR_SEPARATOR(ch) \\\n\t(((ch) == DIR_SEPARATOR) || ((ch) == DIR_SEPARATOR_2))\n#endif /* DIR_SEPARATOR_2 */\n\n#ifndef PATH_SEPARATOR_2\n# define IS_PATH_SEPARATOR(ch) ((ch) == PATH_SEPARATOR)\n#else /* PATH_SEPARATOR_2 */\n# define IS_PATH_SEPARATOR(ch) ((ch) == PATH_SEPARATOR_2)\n#endif /* PATH_SEPARATOR_2 */\n\n#ifndef FOPEN_WB\n# define FOPEN_WB \"w\"\n#endif\n#ifndef _O_BINARY\n# define _O_BINARY 0\n#endif\n\n#define XMALLOC(type, num)      ((type *) xmalloc ((num) * sizeof(type)))\n#define XFREE(stale) do { \\\n  if (stale) { free (stale); stale = 0; } \\\n} while (0)\n\n#if defined LT_DEBUGWRAPPER\nstatic int lt_debug = 1;\n#else\nstatic int lt_debug = 0;\n#endif\n\nconst char *program_name = \"libtool-wrapper\"; /* in case xstrdup fails */\n\nvoid *xmalloc (size_t num);\nchar *xstrdup (const char *string);\nconst char *base_name (const char *name);\nchar *find_executable (const char *wrapper);\nchar *chase_symlinks (const char *pathspec);\nint make_executable (const char *path);\nint check_executable (const char *path);\nchar *strendzap (char *str, const char *pat);\nvoid lt_debugprintf (const char *file, int line, const char *fmt, ...);\nvoid lt_fatal (const char *file, int line, const char *message, ...);\nstatic const char *nonnull (const char *s);\nstatic const char *nonempty (const char *s);\nvoid lt_setenv (const char *name, const char *value);\nchar *lt_extend_str (const char *orig_value, const char *add, int to_end);\nvoid lt_update_exe_path (const char *name, const char *value);\nvoid lt_update_lib_path (const char *name, const char *value);\nchar **prepare_spawn (char **argv);\nvoid lt_dump_script (FILE *f);\nEOF\n\n\t    cat <<EOF\n#if __GNUC__ < 4 || (__GNUC__ == 4 && __GNUC_MINOR__ < 5)\n# define externally_visible volatile\n#else\n# define externally_visible __attribute__((externally_visible)) volatile\n#endif\nexternally_visible const char * MAGIC_EXE = \"$magic_exe\";\nconst char * LIB_PATH_VARNAME = \"$shlibpath_var\";\nEOF\n\n\t    if test yes = \"$shlibpath_overrides_runpath\" && test -n \"$shlibpath_var\" && test -n \"$temp_rpath\"; then\n              func_to_host_path \"$temp_rpath\"\n\t      cat <<EOF\nconst char * LIB_PATH_VALUE   = \"$func_to_host_path_result\";\nEOF\n\t    else\n\t      cat <<\"EOF\"\nconst char * LIB_PATH_VALUE   = \"\";\nEOF\n\t    fi\n\n\t    if test -n \"$dllsearchpath\"; then\n              func_to_host_path \"$dllsearchpath:\"\n\t      cat <<EOF\nconst char * EXE_PATH_VARNAME = \"PATH\";\nconst char * EXE_PATH_VALUE   = \"$func_to_host_path_result\";\nEOF\n\t    else\n\t      cat <<\"EOF\"\nconst char * EXE_PATH_VARNAME = \"\";\nconst char * EXE_PATH_VALUE   = \"\";\nEOF\n\t    fi\n\n\t    if test yes = \"$fast_install\"; then\n\t      cat <<EOF\nconst char * TARGET_PROGRAM_NAME = \"lt-$outputname\"; /* hopefully, no .exe */\nEOF\n\t    else\n\t      cat <<EOF\nconst char * TARGET_PROGRAM_NAME = \"$outputname\"; /* hopefully, no .exe */\nEOF\n\t    fi\n\n\n\t    cat <<\"EOF\"\n\n#define LTWRAPPER_OPTION_PREFIX         \"--lt-\"\n\nstatic const char *ltwrapper_option_prefix = LTWRAPPER_OPTION_PREFIX;\nstatic const char *dumpscript_opt       = LTWRAPPER_OPTION_PREFIX \"dump-script\";\nstatic const char *debug_opt            = LTWRAPPER_OPTION_PREFIX \"debug\";\n\nint\nmain (int argc, char *argv[])\n{\n  char **newargz;\n  int  newargc;\n  char *tmp_pathspec;\n  char *actual_cwrapper_path;\n  char *actual_cwrapper_name;\n  char *target_name;\n  char *lt_argv_zero;\n  int rval = 127;\n\n  int i;\n\n  program_name = (char *) xstrdup (base_name (argv[0]));\n  newargz = XMALLOC (char *, (size_t) argc + 1);\n\n  /* very simple arg parsing; don't want to rely on getopt\n   * also, copy all non cwrapper options to newargz, except\n   * argz[0], which is handled differently\n   */\n  newargc=0;\n  for (i = 1; i < argc; i++)\n    {\n      if (STREQ (argv[i], dumpscript_opt))\n\t{\nEOF\n\t    case $host in\n\t      *mingw* | *cygwin* )\n\t\t# make stdout use \"unix\" line endings\n\t\techo \"          setmode(1,_O_BINARY);\"\n\t\t;;\n\t      esac\n\n\t    cat <<\"EOF\"\n\t  lt_dump_script (stdout);\n\t  return 0;\n\t}\n      if (STREQ (argv[i], debug_opt))\n\t{\n          lt_debug = 1;\n          continue;\n\t}\n      if (STREQ (argv[i], ltwrapper_option_prefix))\n        {\n          /* however, if there is an option in the LTWRAPPER_OPTION_PREFIX\n             namespace, but it is not one of the ones we know about and\n             have already dealt with, above (inluding dump-script), then\n             report an error. Otherwise, targets might begin to believe\n             they are allowed to use options in the LTWRAPPER_OPTION_PREFIX\n             namespace. The first time any user complains about this, we'll\n             need to make LTWRAPPER_OPTION_PREFIX a configure-time option\n             or a configure.ac-settable value.\n           */\n          lt_fatal (__FILE__, __LINE__,\n\t\t    \"unrecognized %s option: '%s'\",\n                    ltwrapper_option_prefix, argv[i]);\n        }\n      /* otherwise ... */\n      newargz[++newargc] = xstrdup (argv[i]);\n    }\n  newargz[++newargc] = NULL;\n\nEOF\n\t    cat <<EOF\n  /* The GNU banner must be the first non-error debug message */\n  lt_debugprintf (__FILE__, __LINE__, \"libtool wrapper (GNU $PACKAGE) $VERSION\\n\");\nEOF\n\t    cat <<\"EOF\"\n  lt_debugprintf (__FILE__, __LINE__, \"(main) argv[0]: %s\\n\", argv[0]);\n  lt_debugprintf (__FILE__, __LINE__, \"(main) program_name: %s\\n\", program_name);\n\n  tmp_pathspec = find_executable (argv[0]);\n  if (tmp_pathspec == NULL)\n    lt_fatal (__FILE__, __LINE__, \"couldn't find %s\", argv[0]);\n  lt_debugprintf (__FILE__, __LINE__,\n                  \"(main) found exe (before symlink chase) at: %s\\n\",\n\t\t  tmp_pathspec);\n\n  actual_cwrapper_path = chase_symlinks (tmp_pathspec);\n  lt_debugprintf (__FILE__, __LINE__,\n                  \"(main) found exe (after symlink chase) at: %s\\n\",\n\t\t  actual_cwrapper_path);\n  XFREE (tmp_pathspec);\n\n  actual_cwrapper_name = xstrdup (base_name (actual_cwrapper_path));\n  strendzap (actual_cwrapper_path, actual_cwrapper_name);\n\n  /* wrapper name transforms */\n  strendzap (actual_cwrapper_name, \".exe\");\n  tmp_pathspec = lt_extend_str (actual_cwrapper_name, \".exe\", 1);\n  XFREE (actual_cwrapper_name);\n  actual_cwrapper_name = tmp_pathspec;\n  tmp_pathspec = 0;\n\n  /* target_name transforms -- use actual target program name; might have lt- prefix */\n  target_name = xstrdup (base_name (TARGET_PROGRAM_NAME));\n  strendzap (target_name, \".exe\");\n  tmp_pathspec = lt_extend_str (target_name, \".exe\", 1);\n  XFREE (target_name);\n  target_name = tmp_pathspec;\n  tmp_pathspec = 0;\n\n  lt_debugprintf (__FILE__, __LINE__,\n\t\t  \"(main) libtool target name: %s\\n\",\n\t\t  target_name);\nEOF\n\n\t    cat <<EOF\n  newargz[0] =\n    XMALLOC (char, (strlen (actual_cwrapper_path) +\n\t\t    strlen (\"$objdir\") + 1 + strlen (actual_cwrapper_name) + 1));\n  strcpy (newargz[0], actual_cwrapper_path);\n  strcat (newargz[0], \"$objdir\");\n  strcat (newargz[0], \"/\");\nEOF\n\n\t    cat <<\"EOF\"\n  /* stop here, and copy so we don't have to do this twice */\n  tmp_pathspec = xstrdup (newargz[0]);\n\n  /* do NOT want the lt- prefix here, so use actual_cwrapper_name */\n  strcat (newargz[0], actual_cwrapper_name);\n\n  /* DO want the lt- prefix here if it exists, so use target_name */\n  lt_argv_zero = lt_extend_str (tmp_pathspec, target_name, 1);\n  XFREE (tmp_pathspec);\n  tmp_pathspec = NULL;\nEOF\n\n\t    case $host_os in\n\t      mingw*)\n\t    cat <<\"EOF\"\n  {\n    char* p;\n    while ((p = strchr (newargz[0], '\\\\')) != NULL)\n      {\n\t*p = '/';\n      }\n    while ((p = strchr (lt_argv_zero, '\\\\')) != NULL)\n      {\n\t*p = '/';\n      }\n  }\nEOF\n\t    ;;\n\t    esac\n\n\t    cat <<\"EOF\"\n  XFREE (target_name);\n  XFREE (actual_cwrapper_path);\n  XFREE (actual_cwrapper_name);\n\n  lt_setenv (\"BIN_SH\", \"xpg4\"); /* for Tru64 */\n  lt_setenv (\"DUALCASE\", \"1\");  /* for MSK sh */\n  /* Update the DLL searchpath.  EXE_PATH_VALUE ($dllsearchpath) must\n     be prepended before (that is, appear after) LIB_PATH_VALUE ($temp_rpath)\n     because on Windows, both *_VARNAMEs are PATH but uninstalled\n     libraries must come first. */\n  lt_update_exe_path (EXE_PATH_VARNAME, EXE_PATH_VALUE);\n  lt_update_lib_path (LIB_PATH_VARNAME, LIB_PATH_VALUE);\n\n  lt_debugprintf (__FILE__, __LINE__, \"(main) lt_argv_zero: %s\\n\",\n\t\t  nonnull (lt_argv_zero));\n  for (i = 0; i < newargc; i++)\n    {\n      lt_debugprintf (__FILE__, __LINE__, \"(main) newargz[%d]: %s\\n\",\n\t\t      i, nonnull (newargz[i]));\n    }\n\nEOF\n\n\t    case $host_os in\n\t      mingw*)\n\t\tcat <<\"EOF\"\n  /* execv doesn't actually work on mingw as expected on unix */\n  newargz = prepare_spawn (newargz);\n  rval = (int) _spawnv (_P_WAIT, lt_argv_zero, (const char * const *) newargz);\n  if (rval == -1)\n    {\n      /* failed to start process */\n      lt_debugprintf (__FILE__, __LINE__,\n\t\t      \"(main) failed to launch target \\\"%s\\\": %s\\n\",\n\t\t      lt_argv_zero, nonnull (strerror (errno)));\n      return 127;\n    }\n  return rval;\nEOF\n\t\t;;\n\t      *)\n\t\tcat <<\"EOF\"\n  execv (lt_argv_zero, newargz);\n  return rval; /* =127, but avoids unused variable warning */\nEOF\n\t\t;;\n\t    esac\n\n\t    cat <<\"EOF\"\n}\n\nvoid *\nxmalloc (size_t num)\n{\n  void *p = (void *) malloc (num);\n  if (!p)\n    lt_fatal (__FILE__, __LINE__, \"memory exhausted\");\n\n  return p;\n}\n\nchar *\nxstrdup (const char *string)\n{\n  return string ? strcpy ((char *) xmalloc (strlen (string) + 1),\n\t\t\t  string) : NULL;\n}\n\nconst char *\nbase_name (const char *name)\n{\n  const char *base;\n\n#if defined HAVE_DOS_BASED_FILE_SYSTEM\n  /* Skip over the disk name in MSDOS pathnames. */\n  if (isalpha ((unsigned char) name[0]) && name[1] == ':')\n    name += 2;\n#endif\n\n  for (base = name; *name; name++)\n    if (IS_DIR_SEPARATOR (*name))\n      base = name + 1;\n  return base;\n}\n\nint\ncheck_executable (const char *path)\n{\n  struct stat st;\n\n  lt_debugprintf (__FILE__, __LINE__, \"(check_executable): %s\\n\",\n                  nonempty (path));\n  if ((!path) || (!*path))\n    return 0;\n\n  if ((stat (path, &st) >= 0)\n      && (st.st_mode & (S_IXUSR | S_IXGRP | S_IXOTH)))\n    return 1;\n  else\n    return 0;\n}\n\nint\nmake_executable (const char *path)\n{\n  int rval = 0;\n  struct stat st;\n\n  lt_debugprintf (__FILE__, __LINE__, \"(make_executable): %s\\n\",\n                  nonempty (path));\n  if ((!path) || (!*path))\n    return 0;\n\n  if (stat (path, &st) >= 0)\n    {\n      rval = chmod (path, st.st_mode | S_IXOTH | S_IXGRP | S_IXUSR);\n    }\n  return rval;\n}\n\n/* Searches for the full path of the wrapper.  Returns\n   newly allocated full path name if found, NULL otherwise\n   Does not chase symlinks, even on platforms that support them.\n*/\nchar *\nfind_executable (const char *wrapper)\n{\n  int has_slash = 0;\n  const char *p;\n  const char *p_next;\n  /* static buffer for getcwd */\n  char tmp[LT_PATHMAX + 1];\n  size_t tmp_len;\n  char *concat_name;\n\n  lt_debugprintf (__FILE__, __LINE__, \"(find_executable): %s\\n\",\n                  nonempty (wrapper));\n\n  if ((wrapper == NULL) || (*wrapper == '\\0'))\n    return NULL;\n\n  /* Absolute path? */\n#if defined HAVE_DOS_BASED_FILE_SYSTEM\n  if (isalpha ((unsigned char) wrapper[0]) && wrapper[1] == ':')\n    {\n      concat_name = xstrdup (wrapper);\n      if (check_executable (concat_name))\n\treturn concat_name;\n      XFREE (concat_name);\n    }\n  else\n    {\n#endif\n      if (IS_DIR_SEPARATOR (wrapper[0]))\n\t{\n\t  concat_name = xstrdup (wrapper);\n\t  if (check_executable (concat_name))\n\t    return concat_name;\n\t  XFREE (concat_name);\n\t}\n#if defined HAVE_DOS_BASED_FILE_SYSTEM\n    }\n#endif\n\n  for (p = wrapper; *p; p++)\n    if (*p == '/')\n      {\n\thas_slash = 1;\n\tbreak;\n      }\n  if (!has_slash)\n    {\n      /* no slashes; search PATH */\n      const char *path = getenv (\"PATH\");\n      if (path != NULL)\n\t{\n\t  for (p = path; *p; p = p_next)\n\t    {\n\t      const char *q;\n\t      size_t p_len;\n\t      for (q = p; *q; q++)\n\t\tif (IS_PATH_SEPARATOR (*q))\n\t\t  break;\n\t      p_len = (size_t) (q - p);\n\t      p_next = (*q == '\\0' ? q : q + 1);\n\t      if (p_len == 0)\n\t\t{\n\t\t  /* empty path: current directory */\n\t\t  if (getcwd (tmp, LT_PATHMAX) == NULL)\n\t\t    lt_fatal (__FILE__, __LINE__, \"getcwd failed: %s\",\n                              nonnull (strerror (errno)));\n\t\t  tmp_len = strlen (tmp);\n\t\t  concat_name =\n\t\t    XMALLOC (char, tmp_len + 1 + strlen (wrapper) + 1);\n\t\t  memcpy (concat_name, tmp, tmp_len);\n\t\t  concat_name[tmp_len] = '/';\n\t\t  strcpy (concat_name + tmp_len + 1, wrapper);\n\t\t}\n\t      else\n\t\t{\n\t\t  concat_name =\n\t\t    XMALLOC (char, p_len + 1 + strlen (wrapper) + 1);\n\t\t  memcpy (concat_name, p, p_len);\n\t\t  concat_name[p_len] = '/';\n\t\t  strcpy (concat_name + p_len + 1, wrapper);\n\t\t}\n\t      if (check_executable (concat_name))\n\t\treturn concat_name;\n\t      XFREE (concat_name);\n\t    }\n\t}\n      /* not found in PATH; assume curdir */\n    }\n  /* Relative path | not found in path: prepend cwd */\n  if (getcwd (tmp, LT_PATHMAX) == NULL)\n    lt_fatal (__FILE__, __LINE__, \"getcwd failed: %s\",\n              nonnull (strerror (errno)));\n  tmp_len = strlen (tmp);\n  concat_name = XMALLOC (char, tmp_len + 1 + strlen (wrapper) + 1);\n  memcpy (concat_name, tmp, tmp_len);\n  concat_name[tmp_len] = '/';\n  strcpy (concat_name + tmp_len + 1, wrapper);\n\n  if (check_executable (concat_name))\n    return concat_name;\n  XFREE (concat_name);\n  return NULL;\n}\n\nchar *\nchase_symlinks (const char *pathspec)\n{\n#ifndef S_ISLNK\n  return xstrdup (pathspec);\n#else\n  char buf[LT_PATHMAX];\n  struct stat s;\n  char *tmp_pathspec = xstrdup (pathspec);\n  char *p;\n  int has_symlinks = 0;\n  while (strlen (tmp_pathspec) && !has_symlinks)\n    {\n      lt_debugprintf (__FILE__, __LINE__,\n\t\t      \"checking path component for symlinks: %s\\n\",\n\t\t      tmp_pathspec);\n      if (lstat (tmp_pathspec, &s) == 0)\n\t{\n\t  if (S_ISLNK (s.st_mode) != 0)\n\t    {\n\t      has_symlinks = 1;\n\t      break;\n\t    }\n\n\t  /* search backwards for last DIR_SEPARATOR */\n\t  p = tmp_pathspec + strlen (tmp_pathspec) - 1;\n\t  while ((p > tmp_pathspec) && (!IS_DIR_SEPARATOR (*p)))\n\t    p--;\n\t  if ((p == tmp_pathspec) && (!IS_DIR_SEPARATOR (*p)))\n\t    {\n\t      /* no more DIR_SEPARATORS left */\n\t      break;\n\t    }\n\t  *p = '\\0';\n\t}\n      else\n\t{\n\t  lt_fatal (__FILE__, __LINE__,\n\t\t    \"error accessing file \\\"%s\\\": %s\",\n\t\t    tmp_pathspec, nonnull (strerror (errno)));\n\t}\n    }\n  XFREE (tmp_pathspec);\n\n  if (!has_symlinks)\n    {\n      return xstrdup (pathspec);\n    }\n\n  tmp_pathspec = realpath (pathspec, buf);\n  if (tmp_pathspec == 0)\n    {\n      lt_fatal (__FILE__, __LINE__,\n\t\t\"could not follow symlinks for %s\", pathspec);\n    }\n  return xstrdup (tmp_pathspec);\n#endif\n}\n\nchar *\nstrendzap (char *str, const char *pat)\n{\n  size_t len, patlen;\n\n  assert (str != NULL);\n  assert (pat != NULL);\n\n  len = strlen (str);\n  patlen = strlen (pat);\n\n  if (patlen <= len)\n    {\n      str += len - patlen;\n      if (STREQ (str, pat))\n\t*str = '\\0';\n    }\n  return str;\n}\n\nvoid\nlt_debugprintf (const char *file, int line, const char *fmt, ...)\n{\n  va_list args;\n  if (lt_debug)\n    {\n      (void) fprintf (stderr, \"%s:%s:%d: \", program_name, file, line);\n      va_start (args, fmt);\n      (void) vfprintf (stderr, fmt, args);\n      va_end (args);\n    }\n}\n\nstatic void\nlt_error_core (int exit_status, const char *file,\n\t       int line, const char *mode,\n\t       const char *message, va_list ap)\n{\n  fprintf (stderr, \"%s:%s:%d: %s: \", program_name, file, line, mode);\n  vfprintf (stderr, message, ap);\n  fprintf (stderr, \".\\n\");\n\n  if (exit_status >= 0)\n    exit (exit_status);\n}\n\nvoid\nlt_fatal (const char *file, int line, const char *message, ...)\n{\n  va_list ap;\n  va_start (ap, message);\n  lt_error_core (EXIT_FAILURE, file, line, \"FATAL\", message, ap);\n  va_end (ap);\n}\n\nstatic const char *\nnonnull (const char *s)\n{\n  return s ? s : \"(null)\";\n}\n\nstatic const char *\nnonempty (const char *s)\n{\n  return (s && !*s) ? \"(empty)\" : nonnull (s);\n}\n\nvoid\nlt_setenv (const char *name, const char *value)\n{\n  lt_debugprintf (__FILE__, __LINE__,\n\t\t  \"(lt_setenv) setting '%s' to '%s'\\n\",\n                  nonnull (name), nonnull (value));\n  {\n#ifdef HAVE_SETENV\n    /* always make a copy, for consistency with !HAVE_SETENV */\n    char *str = xstrdup (value);\n    setenv (name, str, 1);\n#else\n    size_t len = strlen (name) + 1 + strlen (value) + 1;\n    char *str = XMALLOC (char, len);\n    sprintf (str, \"%s=%s\", name, value);\n    if (putenv (str) != EXIT_SUCCESS)\n      {\n        XFREE (str);\n      }\n#endif\n  }\n}\n\nchar *\nlt_extend_str (const char *orig_value, const char *add, int to_end)\n{\n  char *new_value;\n  if (orig_value && *orig_value)\n    {\n      size_t orig_value_len = strlen (orig_value);\n      size_t add_len = strlen (add);\n      new_value = XMALLOC (char, add_len + orig_value_len + 1);\n      if (to_end)\n        {\n          strcpy (new_value, orig_value);\n          strcpy (new_value + orig_value_len, add);\n        }\n      else\n        {\n          strcpy (new_value, add);\n          strcpy (new_value + add_len, orig_value);\n        }\n    }\n  else\n    {\n      new_value = xstrdup (add);\n    }\n  return new_value;\n}\n\nvoid\nlt_update_exe_path (const char *name, const char *value)\n{\n  lt_debugprintf (__FILE__, __LINE__,\n\t\t  \"(lt_update_exe_path) modifying '%s' by prepending '%s'\\n\",\n                  nonnull (name), nonnull (value));\n\n  if (name && *name && value && *value)\n    {\n      char *new_value = lt_extend_str (getenv (name), value, 0);\n      /* some systems can't cope with a ':'-terminated path #' */\n      size_t len = strlen (new_value);\n      while ((len > 0) && IS_PATH_SEPARATOR (new_value[len-1]))\n        {\n          new_value[--len] = '\\0';\n        }\n      lt_setenv (name, new_value);\n      XFREE (new_value);\n    }\n}\n\nvoid\nlt_update_lib_path (const char *name, const char *value)\n{\n  lt_debugprintf (__FILE__, __LINE__,\n\t\t  \"(lt_update_lib_path) modifying '%s' by prepending '%s'\\n\",\n                  nonnull (name), nonnull (value));\n\n  if (name && *name && value && *value)\n    {\n      char *new_value = lt_extend_str (getenv (name), value, 0);\n      lt_setenv (name, new_value);\n      XFREE (new_value);\n    }\n}\n\nEOF\n\t    case $host_os in\n\t      mingw*)\n\t\tcat <<\"EOF\"\n\n/* Prepares an argument vector before calling spawn().\n   Note that spawn() does not by itself call the command interpreter\n     (getenv (\"COMSPEC\") != NULL ? getenv (\"COMSPEC\") :\n      ({ OSVERSIONINFO v; v.dwOSVersionInfoSize = sizeof(OSVERSIONINFO);\n         GetVersionEx(&v);\n         v.dwPlatformId == VER_PLATFORM_WIN32_NT;\n      }) ? \"cmd.exe\" : \"command.com\").\n   Instead it simply concatenates the arguments, separated by ' ', and calls\n   CreateProcess().  We must quote the arguments since Win32 CreateProcess()\n   interprets characters like ' ', '\\t', '\\\\', '\"' (but not '<' and '>') in a\n   special way:\n   - Space and tab are interpreted as delimiters. They are not treated as\n     delimiters if they are surrounded by double quotes: \"...\".\n   - Unescaped double quotes are removed from the input. Their only effect is\n     that within double quotes, space and tab are treated like normal\n     characters.\n   - Backslashes not followed by double quotes are not special.\n   - But 2*n+1 backslashes followed by a double quote become\n     n backslashes followed by a double quote (n >= 0):\n       \\\" -> \"\n       \\\\\\\" -> \\\"\n       \\\\\\\\\\\" -> \\\\\"\n */\n#define SHELL_SPECIAL_CHARS \"\\\"\\\\ \\001\\002\\003\\004\\005\\006\\007\\010\\011\\012\\013\\014\\015\\016\\017\\020\\021\\022\\023\\024\\025\\026\\027\\030\\031\\032\\033\\034\\035\\036\\037\"\n#define SHELL_SPACE_CHARS \" \\001\\002\\003\\004\\005\\006\\007\\010\\011\\012\\013\\014\\015\\016\\017\\020\\021\\022\\023\\024\\025\\026\\027\\030\\031\\032\\033\\034\\035\\036\\037\"\nchar **\nprepare_spawn (char **argv)\n{\n  size_t argc;\n  char **new_argv;\n  size_t i;\n\n  /* Count number of arguments.  */\n  for (argc = 0; argv[argc] != NULL; argc++)\n    ;\n\n  /* Allocate new argument vector.  */\n  new_argv = XMALLOC (char *, argc + 1);\n\n  /* Put quoted arguments into the new argument vector.  */\n  for (i = 0; i < argc; i++)\n    {\n      const char *string = argv[i];\n\n      if (string[0] == '\\0')\n\tnew_argv[i] = xstrdup (\"\\\"\\\"\");\n      else if (strpbrk (string, SHELL_SPECIAL_CHARS) != NULL)\n\t{\n\t  int quote_around = (strpbrk (string, SHELL_SPACE_CHARS) != NULL);\n\t  size_t length;\n\t  unsigned int backslashes;\n\t  const char *s;\n\t  char *quoted_string;\n\t  char *p;\n\n\t  length = 0;\n\t  backslashes = 0;\n\t  if (quote_around)\n\t    length++;\n\t  for (s = string; *s != '\\0'; s++)\n\t    {\n\t      char c = *s;\n\t      if (c == '\"')\n\t\tlength += backslashes + 1;\n\t      length++;\n\t      if (c == '\\\\')\n\t\tbackslashes++;\n\t      else\n\t\tbackslashes = 0;\n\t    }\n\t  if (quote_around)\n\t    length += backslashes + 1;\n\n\t  quoted_string = XMALLOC (char, length + 1);\n\n\t  p = quoted_string;\n\t  backslashes = 0;\n\t  if (quote_around)\n\t    *p++ = '\"';\n\t  for (s = string; *s != '\\0'; s++)\n\t    {\n\t      char c = *s;\n\t      if (c == '\"')\n\t\t{\n\t\t  unsigned int j;\n\t\t  for (j = backslashes + 1; j > 0; j--)\n\t\t    *p++ = '\\\\';\n\t\t}\n\t      *p++ = c;\n\t      if (c == '\\\\')\n\t\tbackslashes++;\n\t      else\n\t\tbackslashes = 0;\n\t    }\n\t  if (quote_around)\n\t    {\n\t      unsigned int j;\n\t      for (j = backslashes; j > 0; j--)\n\t\t*p++ = '\\\\';\n\t      *p++ = '\"';\n\t    }\n\t  *p = '\\0';\n\n\t  new_argv[i] = quoted_string;\n\t}\n      else\n\tnew_argv[i] = (char *) string;\n    }\n  new_argv[argc] = NULL;\n\n  return new_argv;\n}\nEOF\n\t\t;;\n\t    esac\n\n            cat <<\"EOF\"\nvoid lt_dump_script (FILE* f)\n{\nEOF\n\t    func_emit_wrapper yes |\n\t      $SED -n -e '\ns/^\\(.\\{79\\}\\)\\(..*\\)/\\1\\\n\\2/\nh\ns/\\([\\\\\"]\\)/\\\\\\1/g\ns/$/\\\\n/\ns/\\([^\\n]*\\).*/  fputs (\"\\1\", f);/p\ng\nD'\n            cat <<\"EOF\"\n}\nEOF\n}\n# end: func_emit_cwrapperexe_src\n\n# func_win32_import_lib_p ARG\n# True if ARG is an import lib, as indicated by $file_magic_cmd\nfunc_win32_import_lib_p ()\n{\n    $debug_cmd\n\n    case `eval $file_magic_cmd \\\"\\$1\\\" 2>/dev/null | $SED -e 10q` in\n    *import*) : ;;\n    *) false ;;\n    esac\n}\n\n# func_suncc_cstd_abi\n# !!ONLY CALL THIS FOR SUN CC AFTER $compile_command IS FULLY EXPANDED!!\n# Several compiler flags select an ABI that is incompatible with the\n# Cstd library. Avoid specifying it if any are in CXXFLAGS.\nfunc_suncc_cstd_abi ()\n{\n    $debug_cmd\n\n    case \" $compile_command \" in\n    *\" -compat=g \"*|*\\ -std=c++[0-9][0-9]\\ *|*\" -library=stdcxx4 \"*|*\" -library=stlport4 \"*)\n      suncc_use_cstd_abi=no\n      ;;\n    *)\n      suncc_use_cstd_abi=yes\n      ;;\n    esac\n}\n\n# func_mode_link arg...\nfunc_mode_link ()\n{\n    $debug_cmd\n\n    case $host in\n    *-*-cygwin* | *-*-mingw* | *-*-pw32* | *-*-os2* | *-cegcc*)\n      # It is impossible to link a dll without this setting, and\n      # we shouldn't force the makefile maintainer to figure out\n      # what system we are compiling for in order to pass an extra\n      # flag for every libtool invocation.\n      # allow_undefined=no\n\n      # FIXME: Unfortunately, there are problems with the above when trying\n      # to make a dll that has undefined symbols, in which case not\n      # even a static library is built.  For now, we need to specify\n      # -no-undefined on the libtool link line when we can be certain\n      # that all symbols are satisfied, otherwise we get a static library.\n      allow_undefined=yes\n      ;;\n    *)\n      allow_undefined=yes\n      ;;\n    esac\n    libtool_args=$nonopt\n    base_compile=\"$nonopt $@\"\n    compile_command=$nonopt\n    finalize_command=$nonopt\n\n    compile_rpath=\n    finalize_rpath=\n    compile_shlibpath=\n    finalize_shlibpath=\n    convenience=\n    old_convenience=\n    deplibs=\n    old_deplibs=\n    compiler_flags=\n    linker_flags=\n    dllsearchpath=\n    lib_search_path=`pwd`\n    inst_prefix_dir=\n    new_inherited_linker_flags=\n\n    avoid_version=no\n    bindir=\n    dlfiles=\n    dlprefiles=\n    dlself=no\n    export_dynamic=no\n    export_symbols=\n    export_symbols_regex=\n    generated=\n    libobjs=\n    ltlibs=\n    module=no\n    no_install=no\n    objs=\n    os2dllname=\n    non_pic_objects=\n    precious_files_regex=\n    prefer_static_libs=no\n    preload=false\n    prev=\n    prevarg=\n    release=\n    rpath=\n    xrpath=\n    perm_rpath=\n    temp_rpath=\n    thread_safe=no\n    vinfo=\n    vinfo_number=no\n    weak_libs=\n    single_module=$wl-single_module\n    func_infer_tag $base_compile\n\n    # We need to know -static, to get the right output filenames.\n    for arg\n    do\n      case $arg in\n      -shared)\n\ttest yes != \"$build_libtool_libs\" \\\n\t  && func_fatal_configuration \"cannot build a shared library\"\n\tbuild_old_libs=no\n\tbreak\n\t;;\n      -all-static | -static | -static-libtool-libs)\n\tcase $arg in\n\t-all-static)\n\t  if test yes = \"$build_libtool_libs\" && test -z \"$link_static_flag\"; then\n\t    func_warning \"complete static linking is impossible in this configuration\"\n\t  fi\n\t  if test -n \"$link_static_flag\"; then\n\t    dlopen_self=$dlopen_self_static\n\t  fi\n\t  prefer_static_libs=yes\n\t  ;;\n\t-static)\n\t  if test -z \"$pic_flag\" && test -n \"$link_static_flag\"; then\n\t    dlopen_self=$dlopen_self_static\n\t  fi\n\t  prefer_static_libs=built\n\t  ;;\n\t-static-libtool-libs)\n\t  if test -z \"$pic_flag\" && test -n \"$link_static_flag\"; then\n\t    dlopen_self=$dlopen_self_static\n\t  fi\n\t  prefer_static_libs=yes\n\t  ;;\n\tesac\n\tbuild_libtool_libs=no\n\tbuild_old_libs=yes\n\tbreak\n\t;;\n      esac\n    done\n\n    # See if our shared archives depend on static archives.\n    test -n \"$old_archive_from_new_cmds\" && build_old_libs=yes\n\n    # Go through the arguments, transforming them on the way.\n    while test \"$#\" -gt 0; do\n      arg=$1\n      shift\n      func_quote_for_eval \"$arg\"\n      qarg=$func_quote_for_eval_unquoted_result\n      func_append libtool_args \" $func_quote_for_eval_result\"\n\n      # If the previous option needs an argument, assign it.\n      if test -n \"$prev\"; then\n\tcase $prev in\n\toutput)\n\t  func_append compile_command \" @OUTPUT@\"\n\t  func_append finalize_command \" @OUTPUT@\"\n\t  ;;\n\tesac\n\n\tcase $prev in\n\tbindir)\n\t  bindir=$arg\n\t  prev=\n\t  continue\n\t  ;;\n\tdlfiles|dlprefiles)\n\t  $preload || {\n\t    # Add the symbol object into the linking commands.\n\t    func_append compile_command \" @SYMFILE@\"\n\t    func_append finalize_command \" @SYMFILE@\"\n\t    preload=:\n\t  }\n\t  case $arg in\n\t  *.la | *.lo) ;;  # We handle these cases below.\n\t  force)\n\t    if test no = \"$dlself\"; then\n\t      dlself=needless\n\t      export_dynamic=yes\n\t    fi\n\t    prev=\n\t    continue\n\t    ;;\n\t  self)\n\t    if test dlprefiles = \"$prev\"; then\n\t      dlself=yes\n\t    elif test dlfiles = \"$prev\" && test yes != \"$dlopen_self\"; then\n\t      dlself=yes\n\t    else\n\t      dlself=needless\n\t      export_dynamic=yes\n\t    fi\n\t    prev=\n\t    continue\n\t    ;;\n\t  *)\n\t    if test dlfiles = \"$prev\"; then\n\t      func_append dlfiles \" $arg\"\n\t    else\n\t      func_append dlprefiles \" $arg\"\n\t    fi\n\t    prev=\n\t    continue\n\t    ;;\n\t  esac\n\t  ;;\n\texpsyms)\n\t  export_symbols=$arg\n\t  test -f \"$arg\" \\\n\t    || func_fatal_error \"symbol file '$arg' does not exist\"\n\t  prev=\n\t  continue\n\t  ;;\n\texpsyms_regex)\n\t  export_symbols_regex=$arg\n\t  prev=\n\t  continue\n\t  ;;\n\tframework)\n\t  case $host in\n\t    *-*-darwin*)\n\t      case \"$deplibs \" in\n\t\t*\" $qarg.ltframework \"*) ;;\n\t\t*) func_append deplibs \" $qarg.ltframework\" # this is fixed later\n\t\t   ;;\n\t      esac\n\t      ;;\n\t  esac\n\t  prev=\n\t  continue\n\t  ;;\n\tinst_prefix)\n\t  inst_prefix_dir=$arg\n\t  prev=\n\t  continue\n\t  ;;\n\tmllvm)\n\t  # Clang does not use LLVM to link, so we can simply discard any\n\t  # '-mllvm $arg' options when doing the link step.\n\t  prev=\n\t  continue\n\t  ;;\n\tobjectlist)\n\t  if test -f \"$arg\"; then\n\t    save_arg=$arg\n\t    moreargs=\n\t    for fil in `cat \"$save_arg\"`\n\t    do\n#\t      func_append moreargs \" $fil\"\n\t      arg=$fil\n\t      # A libtool-controlled object.\n\n\t      # Check to see that this really is a libtool object.\n\t      if func_lalib_unsafe_p \"$arg\"; then\n\t\tpic_object=\n\t\tnon_pic_object=\n\n\t\t# Read the .lo file\n\t\tfunc_source \"$arg\"\n\n\t\tif test -z \"$pic_object\" ||\n\t\t   test -z \"$non_pic_object\" ||\n\t\t   test none = \"$pic_object\" &&\n\t\t   test none = \"$non_pic_object\"; then\n\t\t  func_fatal_error \"cannot find name of object for '$arg'\"\n\t\tfi\n\n\t\t# Extract subdirectory from the argument.\n\t\tfunc_dirname \"$arg\" \"/\" \"\"\n\t\txdir=$func_dirname_result\n\n\t\tif test none != \"$pic_object\"; then\n\t\t  # Prepend the subdirectory the object is found in.\n\t\t  pic_object=$xdir$pic_object\n\n\t\t  if test dlfiles = \"$prev\"; then\n\t\t    if test yes = \"$build_libtool_libs\" && test yes = \"$dlopen_support\"; then\n\t\t      func_append dlfiles \" $pic_object\"\n\t\t      prev=\n\t\t      continue\n\t\t    else\n\t\t      # If libtool objects are unsupported, then we need to preload.\n\t\t      prev=dlprefiles\n\t\t    fi\n\t\t  fi\n\n\t\t  # CHECK ME:  I think I busted this.  -Ossama\n\t\t  if test dlprefiles = \"$prev\"; then\n\t\t    # Preload the old-style object.\n\t\t    func_append dlprefiles \" $pic_object\"\n\t\t    prev=\n\t\t  fi\n\n\t\t  # A PIC object.\n\t\t  func_append libobjs \" $pic_object\"\n\t\t  arg=$pic_object\n\t\tfi\n\n\t\t# Non-PIC object.\n\t\tif test none != \"$non_pic_object\"; then\n\t\t  # Prepend the subdirectory the object is found in.\n\t\t  non_pic_object=$xdir$non_pic_object\n\n\t\t  # A standard non-PIC object\n\t\t  func_append non_pic_objects \" $non_pic_object\"\n\t\t  if test -z \"$pic_object\" || test none = \"$pic_object\"; then\n\t\t    arg=$non_pic_object\n\t\t  fi\n\t\telse\n\t\t  # If the PIC object exists, use it instead.\n\t\t  # $xdir was prepended to $pic_object above.\n\t\t  non_pic_object=$pic_object\n\t\t  func_append non_pic_objects \" $non_pic_object\"\n\t\tfi\n\t      else\n\t\t# Only an error if not doing a dry-run.\n\t\tif $opt_dry_run; then\n\t\t  # Extract subdirectory from the argument.\n\t\t  func_dirname \"$arg\" \"/\" \"\"\n\t\t  xdir=$func_dirname_result\n\n\t\t  func_lo2o \"$arg\"\n\t\t  pic_object=$xdir$objdir/$func_lo2o_result\n\t\t  non_pic_object=$xdir$func_lo2o_result\n\t\t  func_append libobjs \" $pic_object\"\n\t\t  func_append non_pic_objects \" $non_pic_object\"\n\t        else\n\t\t  func_fatal_error \"'$arg' is not a valid libtool object\"\n\t\tfi\n\t      fi\n\t    done\n\t  else\n\t    func_fatal_error \"link input file '$arg' does not exist\"\n\t  fi\n\t  arg=$save_arg\n\t  prev=\n\t  continue\n\t  ;;\n\tos2dllname)\n\t  os2dllname=$arg\n\t  prev=\n\t  continue\n\t  ;;\n\tprecious_regex)\n\t  precious_files_regex=$arg\n\t  prev=\n\t  continue\n\t  ;;\n\trelease)\n\t  release=-$arg\n\t  prev=\n\t  continue\n\t  ;;\n\trpath | xrpath)\n\t  # We need an absolute path.\n\t  case $arg in\n\t  [\\\\/]* | [A-Za-z]:[\\\\/]*) ;;\n\t  *)\n\t    func_fatal_error \"only absolute run-paths are allowed\"\n\t    ;;\n\t  esac\n\t  if test rpath = \"$prev\"; then\n\t    case \"$rpath \" in\n\t    *\" $arg \"*) ;;\n\t    *) func_append rpath \" $arg\" ;;\n\t    esac\n\t  else\n\t    case \"$xrpath \" in\n\t    *\" $arg \"*) ;;\n\t    *) func_append xrpath \" $arg\" ;;\n\t    esac\n\t  fi\n\t  prev=\n\t  continue\n\t  ;;\n\tshrext)\n\t  shrext_cmds=$arg\n\t  prev=\n\t  continue\n\t  ;;\n\tweak)\n\t  func_append weak_libs \" $arg\"\n\t  prev=\n\t  continue\n\t  ;;\n\txcclinker)\n\t  func_append linker_flags \" $qarg\"\n\t  func_append compiler_flags \" $qarg\"\n\t  prev=\n\t  func_append compile_command \" $qarg\"\n\t  func_append finalize_command \" $qarg\"\n\t  continue\n\t  ;;\n\txcompiler)\n\t  func_append compiler_flags \" $qarg\"\n\t  prev=\n\t  func_append compile_command \" $qarg\"\n\t  func_append finalize_command \" $qarg\"\n\t  continue\n\t  ;;\n\txlinker)\n\t  func_append linker_flags \" $qarg\"\n\t  func_append compiler_flags \" $wl$qarg\"\n\t  prev=\n\t  func_append compile_command \" $wl$qarg\"\n\t  func_append finalize_command \" $wl$qarg\"\n\t  continue\n\t  ;;\n\t*)\n\t  eval \"$prev=\\\"\\$arg\\\"\"\n\t  prev=\n\t  continue\n\t  ;;\n\tesac\n      fi # test -n \"$prev\"\n\n      prevarg=$arg\n\n      case $arg in\n      -all-static)\n\tif test -n \"$link_static_flag\"; then\n\t  # See comment for -static flag below, for more details.\n\t  func_append compile_command \" $link_static_flag\"\n\t  func_append finalize_command \" $link_static_flag\"\n\tfi\n\tcontinue\n\t;;\n\n      -allow-undefined)\n\t# FIXME: remove this flag sometime in the future.\n\tfunc_fatal_error \"'-allow-undefined' must not be used because it is the default\"\n\t;;\n\n      -avoid-version)\n\tavoid_version=yes\n\tcontinue\n\t;;\n\n      -bindir)\n\tprev=bindir\n\tcontinue\n\t;;\n\n      -dlopen)\n\tprev=dlfiles\n\tcontinue\n\t;;\n\n      -dlpreopen)\n\tprev=dlprefiles\n\tcontinue\n\t;;\n\n      -export-dynamic)\n\texport_dynamic=yes\n\tcontinue\n\t;;\n\n      -export-symbols | -export-symbols-regex)\n\tif test -n \"$export_symbols\" || test -n \"$export_symbols_regex\"; then\n\t  func_fatal_error \"more than one -exported-symbols argument is not allowed\"\n\tfi\n\tif test X-export-symbols = \"X$arg\"; then\n\t  prev=expsyms\n\telse\n\t  prev=expsyms_regex\n\tfi\n\tcontinue\n\t;;\n\n      -framework)\n\tprev=framework\n\tcontinue\n\t;;\n\n      -inst-prefix-dir)\n\tprev=inst_prefix\n\tcontinue\n\t;;\n\n      # The native IRIX linker understands -LANG:*, -LIST:* and -LNO:*\n      # so, if we see these flags be careful not to treat them like -L\n      -L[A-Z][A-Z]*:*)\n\tcase $with_gcc/$host in\n\tno/*-*-irix* | /*-*-irix*)\n\t  func_append compile_command \" $arg\"\n\t  func_append finalize_command \" $arg\"\n\t  ;;\n\tesac\n\tcontinue\n\t;;\n\n      -L*)\n\tfunc_stripname \"-L\" '' \"$arg\"\n\tif test -z \"$func_stripname_result\"; then\n\t  if test \"$#\" -gt 0; then\n\t    func_fatal_error \"require no space between '-L' and '$1'\"\n\t  else\n\t    func_fatal_error \"need path for '-L' option\"\n\t  fi\n\tfi\n\tfunc_resolve_sysroot \"$func_stripname_result\"\n\tdir=$func_resolve_sysroot_result\n\t# We need an absolute path.\n\tcase $dir in\n\t[\\\\/]* | [A-Za-z]:[\\\\/]*) ;;\n\t*)\n\t  absdir=`cd \"$dir\" && pwd`\n\t  test -z \"$absdir\" && \\\n\t    func_fatal_error \"cannot determine absolute directory name of '$dir'\"\n\t  dir=$absdir\n\t  ;;\n\tesac\n\tcase \"$deplibs \" in\n\t*\" -L$dir \"* | *\" $arg \"*)\n\t  # Will only happen for absolute or sysroot arguments\n\t  ;;\n\t*)\n\t  # Preserve sysroot, but never include relative directories\n\t  case $dir in\n\t    [\\\\/]* | [A-Za-z]:[\\\\/]* | =*) func_append deplibs \" $arg\" ;;\n\t    *) func_append deplibs \" -L$dir\" ;;\n\t  esac\n\t  func_append lib_search_path \" $dir\"\n\t  ;;\n\tesac\n\tcase $host in\n\t*-*-cygwin* | *-*-mingw* | *-*-pw32* | *-*-os2* | *-cegcc*)\n\t  testbindir=`$ECHO \"$dir\" | $SED 's*/lib$*/bin*'`\n\t  case :$dllsearchpath: in\n\t  *\":$dir:\"*) ;;\n\t  ::) dllsearchpath=$dir;;\n\t  *) func_append dllsearchpath \":$dir\";;\n\t  esac\n\t  case :$dllsearchpath: in\n\t  *\":$testbindir:\"*) ;;\n\t  ::) dllsearchpath=$testbindir;;\n\t  *) func_append dllsearchpath \":$testbindir\";;\n\t  esac\n\t  ;;\n\tesac\n\tcontinue\n\t;;\n\n      -l*)\n\tif test X-lc = \"X$arg\" || test X-lm = \"X$arg\"; then\n\t  case $host in\n\t  *-*-cygwin* | *-*-mingw* | *-*-pw32* | *-*-beos* | *-cegcc* | *-*-haiku*)\n\t    # These systems don't actually have a C or math library (as such)\n\t    continue\n\t    ;;\n\t  *-*-os2*)\n\t    # These systems don't actually have a C library (as such)\n\t    test X-lc = \"X$arg\" && continue\n\t    ;;\n\t  *-*-openbsd* | *-*-freebsd* | *-*-dragonfly* | *-*-bitrig*)\n\t    # Do not include libc due to us having libc/libc_r.\n\t    test X-lc = \"X$arg\" && continue\n\t    ;;\n\t  *-*-rhapsody* | *-*-darwin1.[012])\n\t    # Rhapsody C and math libraries are in the System framework\n\t    func_append deplibs \" System.ltframework\"\n\t    continue\n\t    ;;\n\t  *-*-sco3.2v5* | *-*-sco5v6*)\n\t    # Causes problems with __ctype\n\t    test X-lc = \"X$arg\" && continue\n\t    ;;\n\t  *-*-sysv4.2uw2* | *-*-sysv5* | *-*-unixware* | *-*-OpenUNIX*)\n\t    # Compiler inserts libc in the correct place for threads to work\n\t    test X-lc = \"X$arg\" && continue\n\t    ;;\n\t  esac\n\telif test X-lc_r = \"X$arg\"; then\n\t case $host in\n\t *-*-openbsd* | *-*-freebsd* | *-*-dragonfly* | *-*-bitrig*)\n\t   # Do not include libc_r directly, use -pthread flag.\n\t   continue\n\t   ;;\n\t esac\n\tfi\n\tfunc_append deplibs \" $arg\"\n\tcontinue\n\t;;\n\n      -mllvm)\n\tprev=mllvm\n\tcontinue\n\t;;\n\n      -module)\n\tmodule=yes\n\tcontinue\n\t;;\n\n      # Tru64 UNIX uses -model [arg] to determine the layout of C++\n      # classes, name mangling, and exception handling.\n      # Darwin uses the -arch flag to determine output architecture.\n      -model|-arch|-isysroot|--sysroot)\n\tfunc_append compiler_flags \" $arg\"\n\tfunc_append compile_command \" $arg\"\n\tfunc_append finalize_command \" $arg\"\n\tprev=xcompiler\n\tcontinue\n\t;;\n\n      -mt|-mthreads|-kthread|-Kthread|-pthread|-pthreads|--thread-safe \\\n      |-threads|-fopenmp|-openmp|-mp|-xopenmp|-omp|-qsmp=*)\n\tfunc_append compiler_flags \" $arg\"\n\tfunc_append compile_command \" $arg\"\n\tfunc_append finalize_command \" $arg\"\n\tcase \"$new_inherited_linker_flags \" in\n\t    *\" $arg \"*) ;;\n\t    * ) func_append new_inherited_linker_flags \" $arg\" ;;\n\tesac\n\tcontinue\n\t;;\n\n      -multi_module)\n\tsingle_module=$wl-multi_module\n\tcontinue\n\t;;\n\n      -no-fast-install)\n\tfast_install=no\n\tcontinue\n\t;;\n\n      -no-install)\n\tcase $host in\n\t*-*-cygwin* | *-*-mingw* | *-*-pw32* | *-*-os2* | *-*-darwin* | *-cegcc*)\n\t  # The PATH hackery in wrapper scripts is required on Windows\n\t  # and Darwin in order for the loader to find any dlls it needs.\n\t  func_warning \"'-no-install' is ignored for $host\"\n\t  func_warning \"assuming '-no-fast-install' instead\"\n\t  fast_install=no\n\t  ;;\n\t*) no_install=yes ;;\n\tesac\n\tcontinue\n\t;;\n\n      -no-undefined)\n\tallow_undefined=no\n\tcontinue\n\t;;\n\n      -objectlist)\n\tprev=objectlist\n\tcontinue\n\t;;\n\n      -os2dllname)\n\tprev=os2dllname\n\tcontinue\n\t;;\n\n      -o) prev=output ;;\n\n      -precious-files-regex)\n\tprev=precious_regex\n\tcontinue\n\t;;\n\n      -release)\n\tprev=release\n\tcontinue\n\t;;\n\n      -rpath)\n\tprev=rpath\n\tcontinue\n\t;;\n\n      -R)\n\tprev=xrpath\n\tcontinue\n\t;;\n\n      -R*)\n\tfunc_stripname '-R' '' \"$arg\"\n\tdir=$func_stripname_result\n\t# We need an absolute path.\n\tcase $dir in\n\t[\\\\/]* | [A-Za-z]:[\\\\/]*) ;;\n\t=*)\n\t  func_stripname '=' '' \"$dir\"\n\t  dir=$lt_sysroot$func_stripname_result\n\t  ;;\n\t*)\n\t  func_fatal_error \"only absolute run-paths are allowed\"\n\t  ;;\n\tesac\n\tcase \"$xrpath \" in\n\t*\" $dir \"*) ;;\n\t*) func_append xrpath \" $dir\" ;;\n\tesac\n\tcontinue\n\t;;\n\n      -shared)\n\t# The effects of -shared are defined in a previous loop.\n\tcontinue\n\t;;\n\n      -shrext)\n\tprev=shrext\n\tcontinue\n\t;;\n\n      -static | -static-libtool-libs)\n\t# The effects of -static are defined in a previous loop.\n\t# We used to do the same as -all-static on platforms that\n\t# didn't have a PIC flag, but the assumption that the effects\n\t# would be equivalent was wrong.  It would break on at least\n\t# Digital Unix and AIX.\n\tcontinue\n\t;;\n\n      -thread-safe)\n\tthread_safe=yes\n\tcontinue\n\t;;\n\n      -version-info)\n\tprev=vinfo\n\tcontinue\n\t;;\n\n      -version-number)\n\tprev=vinfo\n\tvinfo_number=yes\n\tcontinue\n\t;;\n\n      -weak)\n        prev=weak\n\tcontinue\n\t;;\n\n      -Wc,*)\n\tfunc_stripname '-Wc,' '' \"$arg\"\n\targs=$func_stripname_result\n\targ=\n\tsave_ifs=$IFS; IFS=,\n\tfor flag in $args; do\n\t  IFS=$save_ifs\n          func_quote_for_eval \"$flag\"\n\t  func_append arg \" $func_quote_for_eval_result\"\n\t  func_append compiler_flags \" $func_quote_for_eval_result\"\n\tdone\n\tIFS=$save_ifs\n\tfunc_stripname ' ' '' \"$arg\"\n\targ=$func_stripname_result\n\t;;\n\n      -Wl,*)\n\tfunc_stripname '-Wl,' '' \"$arg\"\n\targs=$func_stripname_result\n\targ=\n\tsave_ifs=$IFS; IFS=,\n\tfor flag in $args; do\n\t  IFS=$save_ifs\n          func_quote_for_eval \"$flag\"\n\t  func_append arg \" $wl$func_quote_for_eval_result\"\n\t  func_append compiler_flags \" $wl$func_quote_for_eval_result\"\n\t  func_append linker_flags \" $func_quote_for_eval_result\"\n\tdone\n\tIFS=$save_ifs\n\tfunc_stripname ' ' '' \"$arg\"\n\targ=$func_stripname_result\n\t;;\n\n      -Xcompiler)\n\tprev=xcompiler\n\tcontinue\n\t;;\n\n      -Xlinker)\n\tprev=xlinker\n\tcontinue\n\t;;\n\n      -XCClinker)\n\tprev=xcclinker\n\tcontinue\n\t;;\n\n      # -msg_* for osf cc\n      -msg_*)\n\tfunc_quote_for_eval \"$arg\"\n\targ=$func_quote_for_eval_result\n\t;;\n\n      # Flags to be passed through unchanged, with rationale:\n      # -64, -mips[0-9]      enable 64-bit mode for the SGI compiler\n      # -r[0-9][0-9]*        specify processor for the SGI compiler\n      # -xarch=*, -xtarget=* enable 64-bit mode for the Sun compiler\n      # +DA*, +DD*           enable 64-bit mode for the HP compiler\n      # -q*                  compiler args for the IBM compiler\n      # -m*, -t[45]*, -txscale* architecture-specific flags for GCC\n      # -F/path              path to uninstalled frameworks, gcc on darwin\n      # -p, -pg, --coverage, -fprofile-*  profiling flags for GCC\n      # -fstack-protector*   stack protector flags for GCC\n      # @file                GCC response files\n      # -tp=*                Portland pgcc target processor selection\n      # --sysroot=*          for sysroot support\n      # -O*, -g*, -flto*, -fwhopr*, -fuse-linker-plugin GCC link-time optimization\n      # -specs=*             GCC specs files\n      # -stdlib=*            select c++ std lib with clang\n      # -fsanitize=*         Clang/GCC memory and address sanitizer\n      -64|-mips[0-9]|-r[0-9][0-9]*|-xarch=*|-xtarget=*|+DA*|+DD*|-q*|-m*| \\\n      -t[45]*|-txscale*|-p|-pg|--coverage|-fprofile-*|-F*|@*|-tp=*|--sysroot=*| \\\n      -O*|-g*|-flto*|-fwhopr*|-fuse-linker-plugin|-fstack-protector*|-stdlib=*| \\\n      -specs=*|-fsanitize=*)\n        func_quote_for_eval \"$arg\"\n\targ=$func_quote_for_eval_result\n        func_append compile_command \" $arg\"\n        func_append finalize_command \" $arg\"\n        func_append compiler_flags \" $arg\"\n        continue\n        ;;\n\n      -Z*)\n        if test os2 = \"`expr $host : '.*\\(os2\\)'`\"; then\n          # OS/2 uses -Zxxx to specify OS/2-specific options\n\t  compiler_flags=\"$compiler_flags $arg\"\n\t  func_append compile_command \" $arg\"\n\t  func_append finalize_command \" $arg\"\n\t  case $arg in\n\t  -Zlinker | -Zstack)\n\t    prev=xcompiler\n\t    ;;\n\t  esac\n\t  continue\n        else\n\t  # Otherwise treat like 'Some other compiler flag' below\n\t  func_quote_for_eval \"$arg\"\n\t  arg=$func_quote_for_eval_result\n        fi\n\t;;\n\n      # Some other compiler flag.\n      -* | +*)\n        func_quote_for_eval \"$arg\"\n\targ=$func_quote_for_eval_result\n\t;;\n\n      *.$objext)\n\t# A standard object.\n\tfunc_append objs \" $arg\"\n\t;;\n\n      *.lo)\n\t# A libtool-controlled object.\n\n\t# Check to see that this really is a libtool object.\n\tif func_lalib_unsafe_p \"$arg\"; then\n\t  pic_object=\n\t  non_pic_object=\n\n\t  # Read the .lo file\n\t  func_source \"$arg\"\n\n\t  if test -z \"$pic_object\" ||\n\t     test -z \"$non_pic_object\" ||\n\t     test none = \"$pic_object\" &&\n\t     test none = \"$non_pic_object\"; then\n\t    func_fatal_error \"cannot find name of object for '$arg'\"\n\t  fi\n\n\t  # Extract subdirectory from the argument.\n\t  func_dirname \"$arg\" \"/\" \"\"\n\t  xdir=$func_dirname_result\n\n\t  test none = \"$pic_object\" || {\n\t    # Prepend the subdirectory the object is found in.\n\t    pic_object=$xdir$pic_object\n\n\t    if test dlfiles = \"$prev\"; then\n\t      if test yes = \"$build_libtool_libs\" && test yes = \"$dlopen_support\"; then\n\t\tfunc_append dlfiles \" $pic_object\"\n\t\tprev=\n\t\tcontinue\n\t      else\n\t\t# If libtool objects are unsupported, then we need to preload.\n\t\tprev=dlprefiles\n\t      fi\n\t    fi\n\n\t    # CHECK ME:  I think I busted this.  -Ossama\n\t    if test dlprefiles = \"$prev\"; then\n\t      # Preload the old-style object.\n\t      func_append dlprefiles \" $pic_object\"\n\t      prev=\n\t    fi\n\n\t    # A PIC object.\n\t    func_append libobjs \" $pic_object\"\n\t    arg=$pic_object\n\t  }\n\n\t  # Non-PIC object.\n\t  if test none != \"$non_pic_object\"; then\n\t    # Prepend the subdirectory the object is found in.\n\t    non_pic_object=$xdir$non_pic_object\n\n\t    # A standard non-PIC object\n\t    func_append non_pic_objects \" $non_pic_object\"\n\t    if test -z \"$pic_object\" || test none = \"$pic_object\"; then\n\t      arg=$non_pic_object\n\t    fi\n\t  else\n\t    # If the PIC object exists, use it instead.\n\t    # $xdir was prepended to $pic_object above.\n\t    non_pic_object=$pic_object\n\t    func_append non_pic_objects \" $non_pic_object\"\n\t  fi\n\telse\n\t  # Only an error if not doing a dry-run.\n\t  if $opt_dry_run; then\n\t    # Extract subdirectory from the argument.\n\t    func_dirname \"$arg\" \"/\" \"\"\n\t    xdir=$func_dirname_result\n\n\t    func_lo2o \"$arg\"\n\t    pic_object=$xdir$objdir/$func_lo2o_result\n\t    non_pic_object=$xdir$func_lo2o_result\n\t    func_append libobjs \" $pic_object\"\n\t    func_append non_pic_objects \" $non_pic_object\"\n\t  else\n\t    func_fatal_error \"'$arg' is not a valid libtool object\"\n\t  fi\n\tfi\n\t;;\n\n      *.$libext)\n\t# An archive.\n\tfunc_append deplibs \" $arg\"\n\tfunc_append old_deplibs \" $arg\"\n\tcontinue\n\t;;\n\n      *.la)\n\t# A libtool-controlled library.\n\n\tfunc_resolve_sysroot \"$arg\"\n\tif test dlfiles = \"$prev\"; then\n\t  # This library was specified with -dlopen.\n\t  func_append dlfiles \" $func_resolve_sysroot_result\"\n\t  prev=\n\telif test dlprefiles = \"$prev\"; then\n\t  # The library was specified with -dlpreopen.\n\t  func_append dlprefiles \" $func_resolve_sysroot_result\"\n\t  prev=\n\telse\n\t  func_append deplibs \" $func_resolve_sysroot_result\"\n\tfi\n\tcontinue\n\t;;\n\n      # Some other compiler argument.\n      *)\n\t# Unknown arguments in both finalize_command and compile_command need\n\t# to be aesthetically quoted because they are evaled later.\n\tfunc_quote_for_eval \"$arg\"\n\targ=$func_quote_for_eval_result\n\t;;\n      esac # arg\n\n      # Now actually substitute the argument into the commands.\n      if test -n \"$arg\"; then\n\tfunc_append compile_command \" $arg\"\n\tfunc_append finalize_command \" $arg\"\n      fi\n    done # argument parsing loop\n\n    test -n \"$prev\" && \\\n      func_fatal_help \"the '$prevarg' option requires an argument\"\n\n    if test yes = \"$export_dynamic\" && test -n \"$export_dynamic_flag_spec\"; then\n      eval arg=\\\"$export_dynamic_flag_spec\\\"\n      func_append compile_command \" $arg\"\n      func_append finalize_command \" $arg\"\n    fi\n\n    oldlibs=\n    # calculate the name of the file, without its directory\n    func_basename \"$output\"\n    outputname=$func_basename_result\n    libobjs_save=$libobjs\n\n    if test -n \"$shlibpath_var\"; then\n      # get the directories listed in $shlibpath_var\n      eval shlib_search_path=\\`\\$ECHO \\\"\\$$shlibpath_var\\\" \\| \\$SED \\'s/:/ /g\\'\\`\n    else\n      shlib_search_path=\n    fi\n    eval sys_lib_search_path=\\\"$sys_lib_search_path_spec\\\"\n    eval sys_lib_dlsearch_path=\\\"$sys_lib_dlsearch_path_spec\\\"\n\n    # Definition is injected by LT_CONFIG during libtool generation.\n    func_munge_path_list sys_lib_dlsearch_path \"$LT_SYS_LIBRARY_PATH\"\n\n    func_dirname \"$output\" \"/\" \"\"\n    output_objdir=$func_dirname_result$objdir\n    func_to_tool_file \"$output_objdir/\"\n    tool_output_objdir=$func_to_tool_file_result\n    # Create the object directory.\n    func_mkdir_p \"$output_objdir\"\n\n    # Determine the type of output\n    case $output in\n    \"\")\n      func_fatal_help \"you must specify an output file\"\n      ;;\n    *.$libext) linkmode=oldlib ;;\n    *.lo | *.$objext) linkmode=obj ;;\n    *.la) linkmode=lib ;;\n    *) linkmode=prog ;; # Anything else should be a program.\n    esac\n\n    specialdeplibs=\n\n    libs=\n    # Find all interdependent deplibs by searching for libraries\n    # that are linked more than once (e.g. -la -lb -la)\n    for deplib in $deplibs; do\n      if $opt_preserve_dup_deps; then\n\tcase \"$libs \" in\n\t*\" $deplib \"*) func_append specialdeplibs \" $deplib\" ;;\n\tesac\n      fi\n      func_append libs \" $deplib\"\n    done\n\n    if test lib = \"$linkmode\"; then\n      libs=\"$predeps $libs $compiler_lib_search_path $postdeps\"\n\n      # Compute libraries that are listed more than once in $predeps\n      # $postdeps and mark them as special (i.e., whose duplicates are\n      # not to be eliminated).\n      pre_post_deps=\n      if $opt_duplicate_compiler_generated_deps; then\n\tfor pre_post_dep in $predeps $postdeps; do\n\t  case \"$pre_post_deps \" in\n\t  *\" $pre_post_dep \"*) func_append specialdeplibs \" $pre_post_deps\" ;;\n\t  esac\n\t  func_append pre_post_deps \" $pre_post_dep\"\n\tdone\n      fi\n      pre_post_deps=\n    fi\n\n    deplibs=\n    newdependency_libs=\n    newlib_search_path=\n    need_relink=no # whether we're linking any uninstalled libtool libraries\n    notinst_deplibs= # not-installed libtool libraries\n    notinst_path= # paths that contain not-installed libtool libraries\n\n    case $linkmode in\n    lib)\n\tpasses=\"conv dlpreopen link\"\n\tfor file in $dlfiles $dlprefiles; do\n\t  case $file in\n\t  *.la) ;;\n\t  *)\n\t    func_fatal_help \"libraries can '-dlopen' only libtool libraries: $file\"\n\t    ;;\n\t  esac\n\tdone\n\t;;\n    prog)\n\tcompile_deplibs=\n\tfinalize_deplibs=\n\talldeplibs=false\n\tnewdlfiles=\n\tnewdlprefiles=\n\tpasses=\"conv scan dlopen dlpreopen link\"\n\t;;\n    *)  passes=\"conv\"\n\t;;\n    esac\n\n    for pass in $passes; do\n      # The preopen pass in lib mode reverses $deplibs; put it back here\n      # so that -L comes before libs that need it for instance...\n      if test lib,link = \"$linkmode,$pass\"; then\n\t## FIXME: Find the place where the list is rebuilt in the wrong\n\t##        order, and fix it there properly\n        tmp_deplibs=\n\tfor deplib in $deplibs; do\n\t  tmp_deplibs=\"$deplib $tmp_deplibs\"\n\tdone\n\tdeplibs=$tmp_deplibs\n      fi\n\n      if test lib,link = \"$linkmode,$pass\" ||\n\t test prog,scan = \"$linkmode,$pass\"; then\n\tlibs=$deplibs\n\tdeplibs=\n      fi\n      if test prog = \"$linkmode\"; then\n\tcase $pass in\n\tdlopen) libs=$dlfiles ;;\n\tdlpreopen) libs=$dlprefiles ;;\n\tlink)\n\t  libs=\"$deplibs %DEPLIBS%\"\n\t  test \"X$link_all_deplibs\" != Xno && libs=\"$libs $dependency_libs\"\n\t  ;;\n\tesac\n      fi\n      if test lib,dlpreopen = \"$linkmode,$pass\"; then\n\t# Collect and forward deplibs of preopened libtool libs\n\tfor lib in $dlprefiles; do\n\t  # Ignore non-libtool-libs\n\t  dependency_libs=\n\t  func_resolve_sysroot \"$lib\"\n\t  case $lib in\n\t  *.la)\tfunc_source \"$func_resolve_sysroot_result\" ;;\n\t  esac\n\n\t  # Collect preopened libtool deplibs, except any this library\n\t  # has declared as weak libs\n\t  for deplib in $dependency_libs; do\n\t    func_basename \"$deplib\"\n            deplib_base=$func_basename_result\n\t    case \" $weak_libs \" in\n\t    *\" $deplib_base \"*) ;;\n\t    *) func_append deplibs \" $deplib\" ;;\n\t    esac\n\t  done\n\tdone\n\tlibs=$dlprefiles\n      fi\n      if test dlopen = \"$pass\"; then\n\t# Collect dlpreopened libraries\n\tsave_deplibs=$deplibs\n\tdeplibs=\n      fi\n\n      for deplib in $libs; do\n\tlib=\n\tfound=false\n\tcase $deplib in\n\t-mt|-mthreads|-kthread|-Kthread|-pthread|-pthreads|--thread-safe \\\n        |-threads|-fopenmp|-openmp|-mp|-xopenmp|-omp|-qsmp=*)\n\t  if test prog,link = \"$linkmode,$pass\"; then\n\t    compile_deplibs=\"$deplib $compile_deplibs\"\n\t    finalize_deplibs=\"$deplib $finalize_deplibs\"\n\t  else\n\t    func_append compiler_flags \" $deplib\"\n\t    if test lib = \"$linkmode\"; then\n\t\tcase \"$new_inherited_linker_flags \" in\n\t\t    *\" $deplib \"*) ;;\n\t\t    * ) func_append new_inherited_linker_flags \" $deplib\" ;;\n\t\tesac\n\t    fi\n\t  fi\n\t  continue\n\t  ;;\n\t-l*)\n\t  if test lib != \"$linkmode\" && test prog != \"$linkmode\"; then\n\t    func_warning \"'-l' is ignored for archives/objects\"\n\t    continue\n\t  fi\n\t  func_stripname '-l' '' \"$deplib\"\n\t  name=$func_stripname_result\n\t  if test lib = \"$linkmode\"; then\n\t    searchdirs=\"$newlib_search_path $lib_search_path $compiler_lib_search_dirs $sys_lib_search_path $shlib_search_path\"\n\t  else\n\t    searchdirs=\"$newlib_search_path $lib_search_path $sys_lib_search_path $shlib_search_path\"\n\t  fi\n\t  for searchdir in $searchdirs; do\n\t    for search_ext in .la $std_shrext .so .a; do\n\t      # Search the libtool library\n\t      lib=$searchdir/lib$name$search_ext\n\t      if test -f \"$lib\"; then\n\t\tif test .la = \"$search_ext\"; then\n\t\t  found=:\n\t\telse\n\t\t  found=false\n\t\tfi\n\t\tbreak 2\n\t      fi\n\t    done\n\t  done\n\t  if $found; then\n\t    # deplib is a libtool library\n\t    # If $allow_libtool_libs_with_static_runtimes && $deplib is a stdlib,\n\t    # We need to do some special things here, and not later.\n\t    if test yes = \"$allow_libtool_libs_with_static_runtimes\"; then\n\t      case \" $predeps $postdeps \" in\n\t      *\" $deplib \"*)\n\t\tif func_lalib_p \"$lib\"; then\n\t\t  library_names=\n\t\t  old_library=\n\t\t  func_source \"$lib\"\n\t\t  for l in $old_library $library_names; do\n\t\t    ll=$l\n\t\t  done\n\t\t  if test \"X$ll\" = \"X$old_library\"; then # only static version available\n\t\t    found=false\n\t\t    func_dirname \"$lib\" \"\" \".\"\n\t\t    ladir=$func_dirname_result\n\t\t    lib=$ladir/$old_library\n\t\t    if test prog,link = \"$linkmode,$pass\"; then\n\t\t      compile_deplibs=\"$deplib $compile_deplibs\"\n\t\t      finalize_deplibs=\"$deplib $finalize_deplibs\"\n\t\t    else\n\t\t      deplibs=\"$deplib $deplibs\"\n\t\t      test lib = \"$linkmode\" && newdependency_libs=\"$deplib $newdependency_libs\"\n\t\t    fi\n\t\t    continue\n\t\t  fi\n\t\tfi\n\t\t;;\n\t      *) ;;\n\t      esac\n\t    fi\n\t  else\n\t    # deplib doesn't seem to be a libtool library\n\t    if test prog,link = \"$linkmode,$pass\"; then\n\t      compile_deplibs=\"$deplib $compile_deplibs\"\n\t      finalize_deplibs=\"$deplib $finalize_deplibs\"\n\t    else\n\t      deplibs=\"$deplib $deplibs\"\n\t      test lib = \"$linkmode\" && newdependency_libs=\"$deplib $newdependency_libs\"\n\t    fi\n\t    continue\n\t  fi\n\t  ;; # -l\n\t*.ltframework)\n\t  if test prog,link = \"$linkmode,$pass\"; then\n\t    compile_deplibs=\"$deplib $compile_deplibs\"\n\t    finalize_deplibs=\"$deplib $finalize_deplibs\"\n\t  else\n\t    deplibs=\"$deplib $deplibs\"\n\t    if test lib = \"$linkmode\"; then\n\t\tcase \"$new_inherited_linker_flags \" in\n\t\t    *\" $deplib \"*) ;;\n\t\t    * ) func_append new_inherited_linker_flags \" $deplib\" ;;\n\t\tesac\n\t    fi\n\t  fi\n\t  continue\n\t  ;;\n\t-L*)\n\t  case $linkmode in\n\t  lib)\n\t    deplibs=\"$deplib $deplibs\"\n\t    test conv = \"$pass\" && continue\n\t    newdependency_libs=\"$deplib $newdependency_libs\"\n\t    func_stripname '-L' '' \"$deplib\"\n\t    func_resolve_sysroot \"$func_stripname_result\"\n\t    func_append newlib_search_path \" $func_resolve_sysroot_result\"\n\t    ;;\n\t  prog)\n\t    if test conv = \"$pass\"; then\n\t      deplibs=\"$deplib $deplibs\"\n\t      continue\n\t    fi\n\t    if test scan = \"$pass\"; then\n\t      deplibs=\"$deplib $deplibs\"\n\t    else\n\t      compile_deplibs=\"$deplib $compile_deplibs\"\n\t      finalize_deplibs=\"$deplib $finalize_deplibs\"\n\t    fi\n\t    func_stripname '-L' '' \"$deplib\"\n\t    func_resolve_sysroot \"$func_stripname_result\"\n\t    func_append newlib_search_path \" $func_resolve_sysroot_result\"\n\t    ;;\n\t  *)\n\t    func_warning \"'-L' is ignored for archives/objects\"\n\t    ;;\n\t  esac # linkmode\n\t  continue\n\t  ;; # -L\n\t-R*)\n\t  if test link = \"$pass\"; then\n\t    func_stripname '-R' '' \"$deplib\"\n\t    func_resolve_sysroot \"$func_stripname_result\"\n\t    dir=$func_resolve_sysroot_result\n\t    # Make sure the xrpath contains only unique directories.\n\t    case \"$xrpath \" in\n\t    *\" $dir \"*) ;;\n\t    *) func_append xrpath \" $dir\" ;;\n\t    esac\n\t  fi\n\t  deplibs=\"$deplib $deplibs\"\n\t  continue\n\t  ;;\n\t*.la)\n\t  func_resolve_sysroot \"$deplib\"\n\t  lib=$func_resolve_sysroot_result\n\t  ;;\n\t*.$libext)\n\t  if test conv = \"$pass\"; then\n\t    deplibs=\"$deplib $deplibs\"\n\t    continue\n\t  fi\n\t  case $linkmode in\n\t  lib)\n\t    # Linking convenience modules into shared libraries is allowed,\n\t    # but linking other static libraries is non-portable.\n\t    case \" $dlpreconveniencelibs \" in\n\t    *\" $deplib \"*) ;;\n\t    *)\n\t      valid_a_lib=false\n\t      case $deplibs_check_method in\n\t\tmatch_pattern*)\n\t\t  set dummy $deplibs_check_method; shift\n\t\t  match_pattern_regex=`expr \"$deplibs_check_method\" : \"$1 \\(.*\\)\"`\n\t\t  if eval \"\\$ECHO \\\"$deplib\\\"\" 2>/dev/null | $SED 10q \\\n\t\t    | $EGREP \"$match_pattern_regex\" > /dev/null; then\n\t\t    valid_a_lib=:\n\t\t  fi\n\t\t;;\n\t\tpass_all)\n\t\t  valid_a_lib=:\n\t\t;;\n\t      esac\n\t      if $valid_a_lib; then\n\t\techo\n\t\t$ECHO \"*** Warning: Linking the shared library $output against the\"\n\t\t$ECHO \"*** static library $deplib is not portable!\"\n\t\tdeplibs=\"$deplib $deplibs\"\n\t      else\n\t\techo\n\t\t$ECHO \"*** Warning: Trying to link with static lib archive $deplib.\"\n\t\techo \"*** I have the capability to make that library automatically link in when\"\n\t\techo \"*** you link to this library.  But I can only do this if you have a\"\n\t\techo \"*** shared version of the library, which you do not appear to have\"\n\t\techo \"*** because the file extensions .$libext of this argument makes me believe\"\n\t\techo \"*** that it is just a static archive that I should not use here.\"\n\t      fi\n\t      ;;\n\t    esac\n\t    continue\n\t    ;;\n\t  prog)\n\t    if test link != \"$pass\"; then\n\t      deplibs=\"$deplib $deplibs\"\n\t    else\n\t      compile_deplibs=\"$deplib $compile_deplibs\"\n\t      finalize_deplibs=\"$deplib $finalize_deplibs\"\n\t    fi\n\t    continue\n\t    ;;\n\t  esac # linkmode\n\t  ;; # *.$libext\n\t*.lo | *.$objext)\n\t  if test conv = \"$pass\"; then\n\t    deplibs=\"$deplib $deplibs\"\n\t  elif test prog = \"$linkmode\"; then\n\t    if test dlpreopen = \"$pass\" || test yes != \"$dlopen_support\" || test no = \"$build_libtool_libs\"; then\n\t      # If there is no dlopen support or we're linking statically,\n\t      # we need to preload.\n\t      func_append newdlprefiles \" $deplib\"\n\t      compile_deplibs=\"$deplib $compile_deplibs\"\n\t      finalize_deplibs=\"$deplib $finalize_deplibs\"\n\t    else\n\t      func_append newdlfiles \" $deplib\"\n\t    fi\n\t  fi\n\t  continue\n\t  ;;\n\t%DEPLIBS%)\n\t  alldeplibs=:\n\t  continue\n\t  ;;\n\tesac # case $deplib\n\n\t$found || test -f \"$lib\" \\\n\t  || func_fatal_error \"cannot find the library '$lib' or unhandled argument '$deplib'\"\n\n\t# Check to see that this really is a libtool archive.\n\tfunc_lalib_unsafe_p \"$lib\" \\\n\t  || func_fatal_error \"'$lib' is not a valid libtool archive\"\n\n\tfunc_dirname \"$lib\" \"\" \".\"\n\tladir=$func_dirname_result\n\n\tdlname=\n\tdlopen=\n\tdlpreopen=\n\tlibdir=\n\tlibrary_names=\n\told_library=\n\tinherited_linker_flags=\n\t# If the library was installed with an old release of libtool,\n\t# it will not redefine variables installed, or shouldnotlink\n\tinstalled=yes\n\tshouldnotlink=no\n\tavoidtemprpath=\n\n\n\t# Read the .la file\n\tfunc_source \"$lib\"\n\n\t# Convert \"-framework foo\" to \"foo.ltframework\"\n\tif test -n \"$inherited_linker_flags\"; then\n\t  tmp_inherited_linker_flags=`$ECHO \"$inherited_linker_flags\" | $SED 's/-framework \\([^ $]*\\)/\\1.ltframework/g'`\n\t  for tmp_inherited_linker_flag in $tmp_inherited_linker_flags; do\n\t    case \" $new_inherited_linker_flags \" in\n\t      *\" $tmp_inherited_linker_flag \"*) ;;\n\t      *) func_append new_inherited_linker_flags \" $tmp_inherited_linker_flag\";;\n\t    esac\n\t  done\n\tfi\n\tdependency_libs=`$ECHO \" $dependency_libs\" | $SED 's% \\([^ $]*\\).ltframework% -framework \\1%g'`\n\tif test lib,link = \"$linkmode,$pass\" ||\n\t   test prog,scan = \"$linkmode,$pass\" ||\n\t   { test prog != \"$linkmode\" && test lib != \"$linkmode\"; }; then\n\t  test -n \"$dlopen\" && func_append dlfiles \" $dlopen\"\n\t  test -n \"$dlpreopen\" && func_append dlprefiles \" $dlpreopen\"\n\tfi\n\n\tif test conv = \"$pass\"; then\n\t  # Only check for convenience libraries\n\t  deplibs=\"$lib $deplibs\"\n\t  if test -z \"$libdir\"; then\n\t    if test -z \"$old_library\"; then\n\t      func_fatal_error \"cannot find name of link library for '$lib'\"\n\t    fi\n\t    # It is a libtool convenience library, so add in its objects.\n\t    func_append convenience \" $ladir/$objdir/$old_library\"\n\t    func_append old_convenience \" $ladir/$objdir/$old_library\"\n\t    tmp_libs=\n\t    for deplib in $dependency_libs; do\n\t      deplibs=\"$deplib $deplibs\"\n\t      if $opt_preserve_dup_deps; then\n\t\tcase \"$tmp_libs \" in\n\t\t*\" $deplib \"*) func_append specialdeplibs \" $deplib\" ;;\n\t\tesac\n\t      fi\n\t      func_append tmp_libs \" $deplib\"\n\t    done\n\t  elif test prog != \"$linkmode\" && test lib != \"$linkmode\"; then\n\t    func_fatal_error \"'$lib' is not a convenience library\"\n\t  fi\n\t  continue\n\tfi # $pass = conv\n\n\n\t# Get the name of the library we link against.\n\tlinklib=\n\tif test -n \"$old_library\" &&\n\t   { test yes = \"$prefer_static_libs\" ||\n\t     test built,no = \"$prefer_static_libs,$installed\"; }; then\n\t  linklib=$old_library\n\telse\n\t  for l in $old_library $library_names; do\n\t    linklib=$l\n\t  done\n\tfi\n\tif test -z \"$linklib\"; then\n\t  func_fatal_error \"cannot find name of link library for '$lib'\"\n\tfi\n\n\t# This library was specified with -dlopen.\n\tif test dlopen = \"$pass\"; then\n\t  test -z \"$libdir\" \\\n\t    && func_fatal_error \"cannot -dlopen a convenience library: '$lib'\"\n\t  if test -z \"$dlname\" ||\n\t     test yes != \"$dlopen_support\" ||\n\t     test no = \"$build_libtool_libs\"\n\t  then\n\t    # If there is no dlname, no dlopen support or we're linking\n\t    # statically, we need to preload.  We also need to preload any\n\t    # dependent libraries so libltdl's deplib preloader doesn't\n\t    # bomb out in the load deplibs phase.\n\t    func_append dlprefiles \" $lib $dependency_libs\"\n\t  else\n\t    func_append newdlfiles \" $lib\"\n\t  fi\n\t  continue\n\tfi # $pass = dlopen\n\n\t# We need an absolute path.\n\tcase $ladir in\n\t[\\\\/]* | [A-Za-z]:[\\\\/]*) abs_ladir=$ladir ;;\n\t*)\n\t  abs_ladir=`cd \"$ladir\" && pwd`\n\t  if test -z \"$abs_ladir\"; then\n\t    func_warning \"cannot determine absolute directory name of '$ladir'\"\n\t    func_warning \"passing it literally to the linker, although it might fail\"\n\t    abs_ladir=$ladir\n\t  fi\n\t  ;;\n\tesac\n\tfunc_basename \"$lib\"\n\tlaname=$func_basename_result\n\n\t# Find the relevant object directory and library name.\n\tif test yes = \"$installed\"; then\n\t  if test ! -f \"$lt_sysroot$libdir/$linklib\" && test -f \"$abs_ladir/$linklib\"; then\n\t    func_warning \"library '$lib' was moved.\"\n\t    dir=$ladir\n\t    absdir=$abs_ladir\n\t    libdir=$abs_ladir\n\t  else\n\t    dir=$lt_sysroot$libdir\n\t    absdir=$lt_sysroot$libdir\n\t  fi\n\t  test yes = \"$hardcode_automatic\" && avoidtemprpath=yes\n\telse\n\t  if test ! -f \"$ladir/$objdir/$linklib\" && test -f \"$abs_ladir/$linklib\"; then\n\t    dir=$ladir\n\t    absdir=$abs_ladir\n\t    # Remove this search path later\n\t    func_append notinst_path \" $abs_ladir\"\n\t  else\n\t    dir=$ladir/$objdir\n\t    absdir=$abs_ladir/$objdir\n\t    # Remove this search path later\n\t    func_append notinst_path \" $abs_ladir\"\n\t  fi\n\tfi # $installed = yes\n\tfunc_stripname 'lib' '.la' \"$laname\"\n\tname=$func_stripname_result\n\n\t# This library was specified with -dlpreopen.\n\tif test dlpreopen = \"$pass\"; then\n\t  if test -z \"$libdir\" && test prog = \"$linkmode\"; then\n\t    func_fatal_error \"only libraries may -dlpreopen a convenience library: '$lib'\"\n\t  fi\n\t  case $host in\n\t    # special handling for platforms with PE-DLLs.\n\t    *cygwin* | *mingw* | *cegcc* )\n\t      # Linker will automatically link against shared library if both\n\t      # static and shared are present.  Therefore, ensure we extract\n\t      # symbols from the import library if a shared library is present\n\t      # (otherwise, the dlopen module name will be incorrect).  We do\n\t      # this by putting the import library name into $newdlprefiles.\n\t      # We recover the dlopen module name by 'saving' the la file\n\t      # name in a special purpose variable, and (later) extracting the\n\t      # dlname from the la file.\n\t      if test -n \"$dlname\"; then\n\t        func_tr_sh \"$dir/$linklib\"\n\t        eval \"libfile_$func_tr_sh_result=\\$abs_ladir/\\$laname\"\n\t        func_append newdlprefiles \" $dir/$linklib\"\n\t      else\n\t        func_append newdlprefiles \" $dir/$old_library\"\n\t        # Keep a list of preopened convenience libraries to check\n\t        # that they are being used correctly in the link pass.\n\t        test -z \"$libdir\" && \\\n\t          func_append dlpreconveniencelibs \" $dir/$old_library\"\n\t      fi\n\t    ;;\n\t    * )\n\t      # Prefer using a static library (so that no silly _DYNAMIC symbols\n\t      # are required to link).\n\t      if test -n \"$old_library\"; then\n\t        func_append newdlprefiles \" $dir/$old_library\"\n\t        # Keep a list of preopened convenience libraries to check\n\t        # that they are being used correctly in the link pass.\n\t        test -z \"$libdir\" && \\\n\t          func_append dlpreconveniencelibs \" $dir/$old_library\"\n\t      # Otherwise, use the dlname, so that lt_dlopen finds it.\n\t      elif test -n \"$dlname\"; then\n\t        func_append newdlprefiles \" $dir/$dlname\"\n\t      else\n\t        func_append newdlprefiles \" $dir/$linklib\"\n\t      fi\n\t    ;;\n\t  esac\n\tfi # $pass = dlpreopen\n\n\tif test -z \"$libdir\"; then\n\t  # Link the convenience library\n\t  if test lib = \"$linkmode\"; then\n\t    deplibs=\"$dir/$old_library $deplibs\"\n\t  elif test prog,link = \"$linkmode,$pass\"; then\n\t    compile_deplibs=\"$dir/$old_library $compile_deplibs\"\n\t    finalize_deplibs=\"$dir/$old_library $finalize_deplibs\"\n\t  else\n\t    deplibs=\"$lib $deplibs\" # used for prog,scan pass\n\t  fi\n\t  continue\n\tfi\n\n\n\tif test prog = \"$linkmode\" && test link != \"$pass\"; then\n\t  func_append newlib_search_path \" $ladir\"\n\t  deplibs=\"$lib $deplibs\"\n\n\t  linkalldeplibs=false\n\t  if test no != \"$link_all_deplibs\" || test -z \"$library_names\" ||\n\t     test no = \"$build_libtool_libs\"; then\n\t    linkalldeplibs=:\n\t  fi\n\n\t  tmp_libs=\n\t  for deplib in $dependency_libs; do\n\t    case $deplib in\n\t    -L*) func_stripname '-L' '' \"$deplib\"\n\t         func_resolve_sysroot \"$func_stripname_result\"\n\t         func_append newlib_search_path \" $func_resolve_sysroot_result\"\n\t\t ;;\n\t    esac\n\t    # Need to link against all dependency_libs?\n\t    if $linkalldeplibs; then\n\t      deplibs=\"$deplib $deplibs\"\n\t    else\n\t      # Need to hardcode shared library paths\n\t      # or/and link against static libraries\n\t      newdependency_libs=\"$deplib $newdependency_libs\"\n\t    fi\n\t    if $opt_preserve_dup_deps; then\n\t      case \"$tmp_libs \" in\n\t      *\" $deplib \"*) func_append specialdeplibs \" $deplib\" ;;\n\t      esac\n\t    fi\n\t    func_append tmp_libs \" $deplib\"\n\t  done # for deplib\n\t  continue\n\tfi # $linkmode = prog...\n\n\tif test prog,link = \"$linkmode,$pass\"; then\n\t  if test -n \"$library_names\" &&\n\t     { { test no = \"$prefer_static_libs\" ||\n\t         test built,yes = \"$prefer_static_libs,$installed\"; } ||\n\t       test -z \"$old_library\"; }; then\n\t    # We need to hardcode the library path\n\t    if test -n \"$shlibpath_var\" && test -z \"$avoidtemprpath\"; then\n\t      # Make sure the rpath contains only unique directories.\n\t      case $temp_rpath: in\n\t      *\"$absdir:\"*) ;;\n\t      *) func_append temp_rpath \"$absdir:\" ;;\n\t      esac\n\t    fi\n\n\t    # Hardcode the library path.\n\t    # Skip directories that are in the system default run-time\n\t    # search path.\n\t    case \" $sys_lib_dlsearch_path \" in\n\t    *\" $absdir \"*) ;;\n\t    *)\n\t      case \"$compile_rpath \" in\n\t      *\" $absdir \"*) ;;\n\t      *) func_append compile_rpath \" $absdir\" ;;\n\t      esac\n\t      ;;\n\t    esac\n\t    case \" $sys_lib_dlsearch_path \" in\n\t    *\" $libdir \"*) ;;\n\t    *)\n\t      case \"$finalize_rpath \" in\n\t      *\" $libdir \"*) ;;\n\t      *) func_append finalize_rpath \" $libdir\" ;;\n\t      esac\n\t      ;;\n\t    esac\n\t  fi # $linkmode,$pass = prog,link...\n\n\t  if $alldeplibs &&\n\t     { test pass_all = \"$deplibs_check_method\" ||\n\t       { test yes = \"$build_libtool_libs\" &&\n\t\t test -n \"$library_names\"; }; }; then\n\t    # We only need to search for static libraries\n\t    continue\n\t  fi\n\tfi\n\n\tlink_static=no # Whether the deplib will be linked statically\n\tuse_static_libs=$prefer_static_libs\n\tif test built = \"$use_static_libs\" && test yes = \"$installed\"; then\n\t  use_static_libs=no\n\tfi\n\tif test -n \"$library_names\" &&\n\t   { test no = \"$use_static_libs\" || test -z \"$old_library\"; }; then\n\t  case $host in\n\t  *cygwin* | *mingw* | *cegcc* | *os2*)\n\t      # No point in relinking DLLs because paths are not encoded\n\t      func_append notinst_deplibs \" $lib\"\n\t      need_relink=no\n\t    ;;\n\t  *)\n\t    if test no = \"$installed\"; then\n\t      func_append notinst_deplibs \" $lib\"\n\t      need_relink=yes\n\t    fi\n\t    ;;\n\t  esac\n\t  # This is a shared library\n\n\t  # Warn about portability, can't link against -module's on some\n\t  # systems (darwin).  Don't bleat about dlopened modules though!\n\t  dlopenmodule=\n\t  for dlpremoduletest in $dlprefiles; do\n\t    if test \"X$dlpremoduletest\" = \"X$lib\"; then\n\t      dlopenmodule=$dlpremoduletest\n\t      break\n\t    fi\n\t  done\n\t  if test -z \"$dlopenmodule\" && test yes = \"$shouldnotlink\" && test link = \"$pass\"; then\n\t    echo\n\t    if test prog = \"$linkmode\"; then\n\t      $ECHO \"*** Warning: Linking the executable $output against the loadable module\"\n\t    else\n\t      $ECHO \"*** Warning: Linking the shared library $output against the loadable module\"\n\t    fi\n\t    $ECHO \"*** $linklib is not portable!\"\n\t  fi\n\t  if test lib = \"$linkmode\" &&\n\t     test yes = \"$hardcode_into_libs\"; then\n\t    # Hardcode the library path.\n\t    # Skip directories that are in the system default run-time\n\t    # search path.\n\t    case \" $sys_lib_dlsearch_path \" in\n\t    *\" $absdir \"*) ;;\n\t    *)\n\t      case \"$compile_rpath \" in\n\t      *\" $absdir \"*) ;;\n\t      *) func_append compile_rpath \" $absdir\" ;;\n\t      esac\n\t      ;;\n\t    esac\n\t    case \" $sys_lib_dlsearch_path \" in\n\t    *\" $libdir \"*) ;;\n\t    *)\n\t      case \"$finalize_rpath \" in\n\t      *\" $libdir \"*) ;;\n\t      *) func_append finalize_rpath \" $libdir\" ;;\n\t      esac\n\t      ;;\n\t    esac\n\t  fi\n\n\t  if test -n \"$old_archive_from_expsyms_cmds\"; then\n\t    # figure out the soname\n\t    set dummy $library_names\n\t    shift\n\t    realname=$1\n\t    shift\n\t    libname=`eval \"\\\\$ECHO \\\"$libname_spec\\\"\"`\n\t    # use dlname if we got it. it's perfectly good, no?\n\t    if test -n \"$dlname\"; then\n\t      soname=$dlname\n\t    elif test -n \"$soname_spec\"; then\n\t      # bleh windows\n\t      case $host in\n\t      *cygwin* | mingw* | *cegcc* | *os2*)\n\t        func_arith $current - $age\n\t\tmajor=$func_arith_result\n\t\tversuffix=-$major\n\t\t;;\n\t      esac\n\t      eval soname=\\\"$soname_spec\\\"\n\t    else\n\t      soname=$realname\n\t    fi\n\n\t    # Make a new name for the extract_expsyms_cmds to use\n\t    soroot=$soname\n\t    func_basename \"$soroot\"\n\t    soname=$func_basename_result\n\t    func_stripname 'lib' '.dll' \"$soname\"\n\t    newlib=libimp-$func_stripname_result.a\n\n\t    # If the library has no export list, then create one now\n\t    if test -f \"$output_objdir/$soname-def\"; then :\n\t    else\n\t      func_verbose \"extracting exported symbol list from '$soname'\"\n\t      func_execute_cmds \"$extract_expsyms_cmds\" 'exit $?'\n\t    fi\n\n\t    # Create $newlib\n\t    if test -f \"$output_objdir/$newlib\"; then :; else\n\t      func_verbose \"generating import library for '$soname'\"\n\t      func_execute_cmds \"$old_archive_from_expsyms_cmds\" 'exit $?'\n\t    fi\n\t    # make sure the library variables are pointing to the new library\n\t    dir=$output_objdir\n\t    linklib=$newlib\n\t  fi # test -n \"$old_archive_from_expsyms_cmds\"\n\n\t  if test prog = \"$linkmode\" || test relink != \"$opt_mode\"; then\n\t    add_shlibpath=\n\t    add_dir=\n\t    add=\n\t    lib_linked=yes\n\t    case $hardcode_action in\n\t    immediate | unsupported)\n\t      if test no = \"$hardcode_direct\"; then\n\t\tadd=$dir/$linklib\n\t\tcase $host in\n\t\t  *-*-sco3.2v5.0.[024]*) add_dir=-L$dir ;;\n\t\t  *-*-sysv4*uw2*) add_dir=-L$dir ;;\n\t\t  *-*-sysv5OpenUNIX* | *-*-sysv5UnixWare7.[01].[10]* | \\\n\t\t    *-*-unixware7*) add_dir=-L$dir ;;\n\t\t  *-*-darwin* )\n\t\t    # if the lib is a (non-dlopened) module then we cannot\n\t\t    # link against it, someone is ignoring the earlier warnings\n\t\t    if /usr/bin/file -L $add 2> /dev/null |\n\t\t\t $GREP \": [^:]* bundle\" >/dev/null; then\n\t\t      if test \"X$dlopenmodule\" != \"X$lib\"; then\n\t\t\t$ECHO \"*** Warning: lib $linklib is a module, not a shared library\"\n\t\t\tif test -z \"$old_library\"; then\n\t\t\t  echo\n\t\t\t  echo \"*** And there doesn't seem to be a static archive available\"\n\t\t\t  echo \"*** The link will probably fail, sorry\"\n\t\t\telse\n\t\t\t  add=$dir/$old_library\n\t\t\tfi\n\t\t      elif test -n \"$old_library\"; then\n\t\t\tadd=$dir/$old_library\n\t\t      fi\n\t\t    fi\n\t\tesac\n\t      elif test no = \"$hardcode_minus_L\"; then\n\t\tcase $host in\n\t\t*-*-sunos*) add_shlibpath=$dir ;;\n\t\tesac\n\t\tadd_dir=-L$dir\n\t\tadd=-l$name\n\t      elif test no = \"$hardcode_shlibpath_var\"; then\n\t\tadd_shlibpath=$dir\n\t\tadd=-l$name\n\t      else\n\t\tlib_linked=no\n\t      fi\n\t      ;;\n\t    relink)\n\t      if test yes = \"$hardcode_direct\" &&\n\t         test no = \"$hardcode_direct_absolute\"; then\n\t\tadd=$dir/$linklib\n\t      elif test yes = \"$hardcode_minus_L\"; then\n\t\tadd_dir=-L$absdir\n\t\t# Try looking first in the location we're being installed to.\n\t\tif test -n \"$inst_prefix_dir\"; then\n\t\t  case $libdir in\n\t\t    [\\\\/]*)\n\t\t      func_append add_dir \" -L$inst_prefix_dir$libdir\"\n\t\t      ;;\n\t\t  esac\n\t\tfi\n\t\tadd=-l$name\n\t      elif test yes = \"$hardcode_shlibpath_var\"; then\n\t\tadd_shlibpath=$dir\n\t\tadd=-l$name\n\t      else\n\t\tlib_linked=no\n\t      fi\n\t      ;;\n\t    *) lib_linked=no ;;\n\t    esac\n\n\t    if test yes != \"$lib_linked\"; then\n\t      func_fatal_configuration \"unsupported hardcode properties\"\n\t    fi\n\n\t    if test -n \"$add_shlibpath\"; then\n\t      case :$compile_shlibpath: in\n\t      *\":$add_shlibpath:\"*) ;;\n\t      *) func_append compile_shlibpath \"$add_shlibpath:\" ;;\n\t      esac\n\t    fi\n\t    if test prog = \"$linkmode\"; then\n\t      test -n \"$add_dir\" && compile_deplibs=\"$add_dir $compile_deplibs\"\n\t      test -n \"$add\" && compile_deplibs=\"$add $compile_deplibs\"\n\t    else\n\t      test -n \"$add_dir\" && deplibs=\"$add_dir $deplibs\"\n\t      test -n \"$add\" && deplibs=\"$add $deplibs\"\n\t      if test yes != \"$hardcode_direct\" &&\n\t\t test yes != \"$hardcode_minus_L\" &&\n\t\t test yes = \"$hardcode_shlibpath_var\"; then\n\t\tcase :$finalize_shlibpath: in\n\t\t*\":$libdir:\"*) ;;\n\t\t*) func_append finalize_shlibpath \"$libdir:\" ;;\n\t\tesac\n\t      fi\n\t    fi\n\t  fi\n\n\t  if test prog = \"$linkmode\" || test relink = \"$opt_mode\"; then\n\t    add_shlibpath=\n\t    add_dir=\n\t    add=\n\t    # Finalize command for both is simple: just hardcode it.\n\t    if test yes = \"$hardcode_direct\" &&\n\t       test no = \"$hardcode_direct_absolute\"; then\n\t      add=$libdir/$linklib\n\t    elif test yes = \"$hardcode_minus_L\"; then\n\t      add_dir=-L$libdir\n\t      add=-l$name\n\t    elif test yes = \"$hardcode_shlibpath_var\"; then\n\t      case :$finalize_shlibpath: in\n\t      *\":$libdir:\"*) ;;\n\t      *) func_append finalize_shlibpath \"$libdir:\" ;;\n\t      esac\n\t      add=-l$name\n\t    elif test yes = \"$hardcode_automatic\"; then\n\t      if test -n \"$inst_prefix_dir\" &&\n\t\t test -f \"$inst_prefix_dir$libdir/$linklib\"; then\n\t\tadd=$inst_prefix_dir$libdir/$linklib\n\t      else\n\t\tadd=$libdir/$linklib\n\t      fi\n\t    else\n\t      # We cannot seem to hardcode it, guess we'll fake it.\n\t      add_dir=-L$libdir\n\t      # Try looking first in the location we're being installed to.\n\t      if test -n \"$inst_prefix_dir\"; then\n\t\tcase $libdir in\n\t\t  [\\\\/]*)\n\t\t    func_append add_dir \" -L$inst_prefix_dir$libdir\"\n\t\t    ;;\n\t\tesac\n\t      fi\n\t      add=-l$name\n\t    fi\n\n\t    if test prog = \"$linkmode\"; then\n\t      test -n \"$add_dir\" && finalize_deplibs=\"$add_dir $finalize_deplibs\"\n\t      test -n \"$add\" && finalize_deplibs=\"$add $finalize_deplibs\"\n\t    else\n\t      test -n \"$add_dir\" && deplibs=\"$add_dir $deplibs\"\n\t      test -n \"$add\" && deplibs=\"$add $deplibs\"\n\t    fi\n\t  fi\n\telif test prog = \"$linkmode\"; then\n\t  # Here we assume that one of hardcode_direct or hardcode_minus_L\n\t  # is not unsupported.  This is valid on all known static and\n\t  # shared platforms.\n\t  if test unsupported != \"$hardcode_direct\"; then\n\t    test -n \"$old_library\" && linklib=$old_library\n\t    compile_deplibs=\"$dir/$linklib $compile_deplibs\"\n\t    finalize_deplibs=\"$dir/$linklib $finalize_deplibs\"\n\t  else\n\t    compile_deplibs=\"-l$name -L$dir $compile_deplibs\"\n\t    finalize_deplibs=\"-l$name -L$dir $finalize_deplibs\"\n\t  fi\n\telif test yes = \"$build_libtool_libs\"; then\n\t  # Not a shared library\n\t  if test pass_all != \"$deplibs_check_method\"; then\n\t    # We're trying link a shared library against a static one\n\t    # but the system doesn't support it.\n\n\t    # Just print a warning and add the library to dependency_libs so\n\t    # that the program can be linked against the static library.\n\t    echo\n\t    $ECHO \"*** Warning: This system cannot link to static lib archive $lib.\"\n\t    echo \"*** I have the capability to make that library automatically link in when\"\n\t    echo \"*** you link to this library.  But I can only do this if you have a\"\n\t    echo \"*** shared version of the library, which you do not appear to have.\"\n\t    if test yes = \"$module\"; then\n\t      echo \"*** But as you try to build a module library, libtool will still create \"\n\t      echo \"*** a static module, that should work as long as the dlopening application\"\n\t      echo \"*** is linked with the -dlopen flag to resolve symbols at runtime.\"\n\t      if test -z \"$global_symbol_pipe\"; then\n\t\techo\n\t\techo \"*** However, this would only work if libtool was able to extract symbol\"\n\t\techo \"*** lists from a program, using 'nm' or equivalent, but libtool could\"\n\t\techo \"*** not find such a program.  So, this module is probably useless.\"\n\t\techo \"*** 'nm' from GNU binutils and a full rebuild may help.\"\n\t      fi\n\t      if test no = \"$build_old_libs\"; then\n\t\tbuild_libtool_libs=module\n\t\tbuild_old_libs=yes\n\t      else\n\t\tbuild_libtool_libs=no\n\t      fi\n\t    fi\n\t  else\n\t    deplibs=\"$dir/$old_library $deplibs\"\n\t    link_static=yes\n\t  fi\n\tfi # link shared/static library?\n\n\tif test lib = \"$linkmode\"; then\n\t  if test -n \"$dependency_libs\" &&\n\t     { test yes != \"$hardcode_into_libs\" ||\n\t       test yes = \"$build_old_libs\" ||\n\t       test yes = \"$link_static\"; }; then\n\t    # Extract -R from dependency_libs\n\t    temp_deplibs=\n\t    for libdir in $dependency_libs; do\n\t      case $libdir in\n\t      -R*) func_stripname '-R' '' \"$libdir\"\n\t           temp_xrpath=$func_stripname_result\n\t\t   case \" $xrpath \" in\n\t\t   *\" $temp_xrpath \"*) ;;\n\t\t   *) func_append xrpath \" $temp_xrpath\";;\n\t\t   esac;;\n\t      *) func_append temp_deplibs \" $libdir\";;\n\t      esac\n\t    done\n\t    dependency_libs=$temp_deplibs\n\t  fi\n\n\t  func_append newlib_search_path \" $absdir\"\n\t  # Link against this library\n\t  test no = \"$link_static\" && newdependency_libs=\"$abs_ladir/$laname $newdependency_libs\"\n\t  # ... and its dependency_libs\n\t  tmp_libs=\n\t  for deplib in $dependency_libs; do\n\t    newdependency_libs=\"$deplib $newdependency_libs\"\n\t    case $deplib in\n              -L*) func_stripname '-L' '' \"$deplib\"\n                   func_resolve_sysroot \"$func_stripname_result\";;\n              *) func_resolve_sysroot \"$deplib\" ;;\n            esac\n\t    if $opt_preserve_dup_deps; then\n\t      case \"$tmp_libs \" in\n\t      *\" $func_resolve_sysroot_result \"*)\n                func_append specialdeplibs \" $func_resolve_sysroot_result\" ;;\n\t      esac\n\t    fi\n\t    func_append tmp_libs \" $func_resolve_sysroot_result\"\n\t  done\n\n\t  if test no != \"$link_all_deplibs\"; then\n\t    # Add the search paths of all dependency libraries\n\t    for deplib in $dependency_libs; do\n\t      path=\n\t      case $deplib in\n\t      -L*) path=$deplib ;;\n\t      *.la)\n\t        func_resolve_sysroot \"$deplib\"\n\t        deplib=$func_resolve_sysroot_result\n\t        func_dirname \"$deplib\" \"\" \".\"\n\t\tdir=$func_dirname_result\n\t\t# We need an absolute path.\n\t\tcase $dir in\n\t\t[\\\\/]* | [A-Za-z]:[\\\\/]*) absdir=$dir ;;\n\t\t*)\n\t\t  absdir=`cd \"$dir\" && pwd`\n\t\t  if test -z \"$absdir\"; then\n\t\t    func_warning \"cannot determine absolute directory name of '$dir'\"\n\t\t    absdir=$dir\n\t\t  fi\n\t\t  ;;\n\t\tesac\n\t\tif $GREP \"^installed=no\" $deplib > /dev/null; then\n\t\tcase $host in\n\t\t*-*-darwin*)\n\t\t  depdepl=\n\t\t  eval deplibrary_names=`$SED -n -e 's/^library_names=\\(.*\\)$/\\1/p' $deplib`\n\t\t  if test -n \"$deplibrary_names\"; then\n\t\t    for tmp in $deplibrary_names; do\n\t\t      depdepl=$tmp\n\t\t    done\n\t\t    if test -f \"$absdir/$objdir/$depdepl\"; then\n\t\t      depdepl=$absdir/$objdir/$depdepl\n\t\t      darwin_install_name=`$OTOOL -L $depdepl | awk '{if (NR == 2) {print $1;exit}}'`\n                      if test -z \"$darwin_install_name\"; then\n                          darwin_install_name=`$OTOOL64 -L $depdepl  | awk '{if (NR == 2) {print $1;exit}}'`\n                      fi\n\t\t      func_append compiler_flags \" $wl-dylib_file $wl$darwin_install_name:$depdepl\"\n\t\t      func_append linker_flags \" -dylib_file $darwin_install_name:$depdepl\"\n\t\t      path=\n\t\t    fi\n\t\t  fi\n\t\t  ;;\n\t\t*)\n\t\t  path=-L$absdir/$objdir\n\t\t  ;;\n\t\tesac\n\t\telse\n\t\t  eval libdir=`$SED -n -e 's/^libdir=\\(.*\\)$/\\1/p' $deplib`\n\t\t  test -z \"$libdir\" && \\\n\t\t    func_fatal_error \"'$deplib' is not a valid libtool archive\"\n\t\t  test \"$absdir\" != \"$libdir\" && \\\n\t\t    func_warning \"'$deplib' seems to be moved\"\n\n\t\t  path=-L$absdir\n\t\tfi\n\t\t;;\n\t      esac\n\t      case \" $deplibs \" in\n\t      *\" $path \"*) ;;\n\t      *) deplibs=\"$path $deplibs\" ;;\n\t      esac\n\t    done\n\t  fi # link_all_deplibs != no\n\tfi # linkmode = lib\n      done # for deplib in $libs\n      if test link = \"$pass\"; then\n\tif test prog = \"$linkmode\"; then\n\t  compile_deplibs=\"$new_inherited_linker_flags $compile_deplibs\"\n\t  finalize_deplibs=\"$new_inherited_linker_flags $finalize_deplibs\"\n\telse\n\t  compiler_flags=\"$compiler_flags \"`$ECHO \" $new_inherited_linker_flags\" | $SED 's% \\([^ $]*\\).ltframework% -framework \\1%g'`\n\tfi\n      fi\n      dependency_libs=$newdependency_libs\n      if test dlpreopen = \"$pass\"; then\n\t# Link the dlpreopened libraries before other libraries\n\tfor deplib in $save_deplibs; do\n\t  deplibs=\"$deplib $deplibs\"\n\tdone\n      fi\n      if test dlopen != \"$pass\"; then\n\ttest conv = \"$pass\" || {\n\t  # Make sure lib_search_path contains only unique directories.\n\t  lib_search_path=\n\t  for dir in $newlib_search_path; do\n\t    case \"$lib_search_path \" in\n\t    *\" $dir \"*) ;;\n\t    *) func_append lib_search_path \" $dir\" ;;\n\t    esac\n\t  done\n\t  newlib_search_path=\n\t}\n\n\tif test prog,link = \"$linkmode,$pass\"; then\n\t  vars=\"compile_deplibs finalize_deplibs\"\n\telse\n\t  vars=deplibs\n\tfi\n\tfor var in $vars dependency_libs; do\n\t  # Add libraries to $var in reverse order\n\t  eval tmp_libs=\\\"\\$$var\\\"\n\t  new_libs=\n\t  for deplib in $tmp_libs; do\n\t    # FIXME: Pedantically, this is the right thing to do, so\n\t    #        that some nasty dependency loop isn't accidentally\n\t    #        broken:\n\t    #new_libs=\"$deplib $new_libs\"\n\t    # Pragmatically, this seems to cause very few problems in\n\t    # practice:\n\t    case $deplib in\n\t    -L*) new_libs=\"$deplib $new_libs\" ;;\n\t    -R*) ;;\n\t    *)\n\t      # And here is the reason: when a library appears more\n\t      # than once as an explicit dependence of a library, or\n\t      # is implicitly linked in more than once by the\n\t      # compiler, it is considered special, and multiple\n\t      # occurrences thereof are not removed.  Compare this\n\t      # with having the same library being listed as a\n\t      # dependency of multiple other libraries: in this case,\n\t      # we know (pedantically, we assume) the library does not\n\t      # need to be listed more than once, so we keep only the\n\t      # last copy.  This is not always right, but it is rare\n\t      # enough that we require users that really mean to play\n\t      # such unportable linking tricks to link the library\n\t      # using -Wl,-lname, so that libtool does not consider it\n\t      # for duplicate removal.\n\t      case \" $specialdeplibs \" in\n\t      *\" $deplib \"*) new_libs=\"$deplib $new_libs\" ;;\n\t      *)\n\t\tcase \" $new_libs \" in\n\t\t*\" $deplib \"*) ;;\n\t\t*) new_libs=\"$deplib $new_libs\" ;;\n\t\tesac\n\t\t;;\n\t      esac\n\t      ;;\n\t    esac\n\t  done\n\t  tmp_libs=\n\t  for deplib in $new_libs; do\n\t    case $deplib in\n\t    -L*)\n\t      case \" $tmp_libs \" in\n\t      *\" $deplib \"*) ;;\n\t      *) func_append tmp_libs \" $deplib\" ;;\n\t      esac\n\t      ;;\n\t    *) func_append tmp_libs \" $deplib\" ;;\n\t    esac\n\t  done\n\t  eval $var=\\\"$tmp_libs\\\"\n\tdone # for var\n      fi\n\n      # Add Sun CC postdeps if required:\n      test CXX = \"$tagname\" && {\n        case $host_os in\n        linux*)\n          case `$CC -V 2>&1 | sed 5q` in\n          *Sun\\ C*) # Sun C++ 5.9\n            func_suncc_cstd_abi\n\n            if test no != \"$suncc_use_cstd_abi\"; then\n              func_append postdeps ' -library=Cstd -library=Crun'\n            fi\n            ;;\n          esac\n          ;;\n\n        solaris*)\n          func_cc_basename \"$CC\"\n          case $func_cc_basename_result in\n          CC* | sunCC*)\n            func_suncc_cstd_abi\n\n            if test no != \"$suncc_use_cstd_abi\"; then\n              func_append postdeps ' -library=Cstd -library=Crun'\n            fi\n            ;;\n          esac\n          ;;\n        esac\n      }\n\n      # Last step: remove runtime libs from dependency_libs\n      # (they stay in deplibs)\n      tmp_libs=\n      for i in $dependency_libs; do\n\tcase \" $predeps $postdeps $compiler_lib_search_path \" in\n\t*\" $i \"*)\n\t  i=\n\t  ;;\n\tesac\n\tif test -n \"$i\"; then\n\t  func_append tmp_libs \" $i\"\n\tfi\n      done\n      dependency_libs=$tmp_libs\n    done # for pass\n    if test prog = \"$linkmode\"; then\n      dlfiles=$newdlfiles\n    fi\n    if test prog = \"$linkmode\" || test lib = \"$linkmode\"; then\n      dlprefiles=$newdlprefiles\n    fi\n\n    case $linkmode in\n    oldlib)\n      if test -n \"$dlfiles$dlprefiles\" || test no != \"$dlself\"; then\n\tfunc_warning \"'-dlopen' is ignored for archives\"\n      fi\n\n      case \" $deplibs\" in\n      *\\ -l* | *\\ -L*)\n\tfunc_warning \"'-l' and '-L' are ignored for archives\" ;;\n      esac\n\n      test -n \"$rpath\" && \\\n\tfunc_warning \"'-rpath' is ignored for archives\"\n\n      test -n \"$xrpath\" && \\\n\tfunc_warning \"'-R' is ignored for archives\"\n\n      test -n \"$vinfo\" && \\\n\tfunc_warning \"'-version-info/-version-number' is ignored for archives\"\n\n      test -n \"$release\" && \\\n\tfunc_warning \"'-release' is ignored for archives\"\n\n      test -n \"$export_symbols$export_symbols_regex\" && \\\n\tfunc_warning \"'-export-symbols' is ignored for archives\"\n\n      # Now set the variables for building old libraries.\n      build_libtool_libs=no\n      oldlibs=$output\n      func_append objs \"$old_deplibs\"\n      ;;\n\n    lib)\n      # Make sure we only generate libraries of the form 'libNAME.la'.\n      case $outputname in\n      lib*)\n\tfunc_stripname 'lib' '.la' \"$outputname\"\n\tname=$func_stripname_result\n\teval shared_ext=\\\"$shrext_cmds\\\"\n\teval libname=\\\"$libname_spec\\\"\n\t;;\n      *)\n\ttest no = \"$module\" \\\n\t  && func_fatal_help \"libtool library '$output' must begin with 'lib'\"\n\n\tif test no != \"$need_lib_prefix\"; then\n\t  # Add the \"lib\" prefix for modules if required\n\t  func_stripname '' '.la' \"$outputname\"\n\t  name=$func_stripname_result\n\t  eval shared_ext=\\\"$shrext_cmds\\\"\n\t  eval libname=\\\"$libname_spec\\\"\n\telse\n\t  func_stripname '' '.la' \"$outputname\"\n\t  libname=$func_stripname_result\n\tfi\n\t;;\n      esac\n\n      if test -n \"$objs\"; then\n\tif test pass_all != \"$deplibs_check_method\"; then\n\t  func_fatal_error \"cannot build libtool library '$output' from non-libtool objects on this host:$objs\"\n\telse\n\t  echo\n\t  $ECHO \"*** Warning: Linking the shared library $output against the non-libtool\"\n\t  $ECHO \"*** objects $objs is not portable!\"\n\t  func_append libobjs \" $objs\"\n\tfi\n      fi\n\n      test no = \"$dlself\" \\\n\t|| func_warning \"'-dlopen self' is ignored for libtool libraries\"\n\n      set dummy $rpath\n      shift\n      test 1 -lt \"$#\" \\\n\t&& func_warning \"ignoring multiple '-rpath's for a libtool library\"\n\n      install_libdir=$1\n\n      oldlibs=\n      if test -z \"$rpath\"; then\n\tif test yes = \"$build_libtool_libs\"; then\n\t  # Building a libtool convenience library.\n\t  # Some compilers have problems with a '.al' extension so\n\t  # convenience libraries should have the same extension an\n\t  # archive normally would.\n\t  oldlibs=\"$output_objdir/$libname.$libext $oldlibs\"\n\t  build_libtool_libs=convenience\n\t  build_old_libs=yes\n\tfi\n\n\ttest -n \"$vinfo\" && \\\n\t  func_warning \"'-version-info/-version-number' is ignored for convenience libraries\"\n\n\ttest -n \"$release\" && \\\n\t  func_warning \"'-release' is ignored for convenience libraries\"\n      else\n\n\t# Parse the version information argument.\n\tsave_ifs=$IFS; IFS=:\n\tset dummy $vinfo 0 0 0\n\tshift\n\tIFS=$save_ifs\n\n\ttest -n \"$7\" && \\\n\t  func_fatal_help \"too many parameters to '-version-info'\"\n\n\t# convert absolute version numbers to libtool ages\n\t# this retains compatibility with .la files and attempts\n\t# to make the code below a bit more comprehensible\n\n\tcase $vinfo_number in\n\tyes)\n\t  number_major=$1\n\t  number_minor=$2\n\t  number_revision=$3\n\t  #\n\t  # There are really only two kinds -- those that\n\t  # use the current revision as the major version\n\t  # and those that subtract age and use age as\n\t  # a minor version.  But, then there is irix\n\t  # that has an extra 1 added just for fun\n\t  #\n\t  case $version_type in\n\t  # correct linux to gnu/linux during the next big refactor\n\t  darwin|freebsd-elf|linux|osf|windows|none)\n\t    func_arith $number_major + $number_minor\n\t    current=$func_arith_result\n\t    age=$number_minor\n\t    revision=$number_revision\n\t    ;;\n\t  freebsd-aout|qnx|sunos)\n\t    current=$number_major\n\t    revision=$number_minor\n\t    age=0\n\t    ;;\n\t  irix|nonstopux)\n\t    func_arith $number_major + $number_minor\n\t    current=$func_arith_result\n\t    age=$number_minor\n\t    revision=$number_minor\n\t    lt_irix_increment=no\n\t    ;;\n\t  *)\n\t    func_fatal_configuration \"$modename: unknown library version type '$version_type'\"\n\t    ;;\n\t  esac\n\t  ;;\n\tno)\n\t  current=$1\n\t  revision=$2\n\t  age=$3\n\t  ;;\n\tesac\n\n\t# Check that each of the things are valid numbers.\n\tcase $current in\n\t0|[1-9]|[1-9][0-9]|[1-9][0-9][0-9]|[1-9][0-9][0-9][0-9]|[1-9][0-9][0-9][0-9][0-9]) ;;\n\t*)\n\t  func_error \"CURRENT '$current' must be a nonnegative integer\"\n\t  func_fatal_error \"'$vinfo' is not valid version information\"\n\t  ;;\n\tesac\n\n\tcase $revision in\n\t0|[1-9]|[1-9][0-9]|[1-9][0-9][0-9]|[1-9][0-9][0-9][0-9]|[1-9][0-9][0-9][0-9][0-9]) ;;\n\t*)\n\t  func_error \"REVISION '$revision' must be a nonnegative integer\"\n\t  func_fatal_error \"'$vinfo' is not valid version information\"\n\t  ;;\n\tesac\n\n\tcase $age in\n\t0|[1-9]|[1-9][0-9]|[1-9][0-9][0-9]|[1-9][0-9][0-9][0-9]|[1-9][0-9][0-9][0-9][0-9]) ;;\n\t*)\n\t  func_error \"AGE '$age' must be a nonnegative integer\"\n\t  func_fatal_error \"'$vinfo' is not valid version information\"\n\t  ;;\n\tesac\n\n\tif test \"$age\" -gt \"$current\"; then\n\t  func_error \"AGE '$age' is greater than the current interface number '$current'\"\n\t  func_fatal_error \"'$vinfo' is not valid version information\"\n\tfi\n\n\t# Calculate the version variables.\n\tmajor=\n\tversuffix=\n\tverstring=\n\tcase $version_type in\n\tnone) ;;\n\n\tdarwin)\n\t  # Like Linux, but with the current version available in\n\t  # verstring for coding it into the library header\n\t  func_arith $current - $age\n\t  major=.$func_arith_result\n\t  versuffix=$major.$age.$revision\n\t  # Darwin ld doesn't like 0 for these options...\n\t  func_arith $current + 1\n\t  minor_current=$func_arith_result\n\t  xlcverstring=\"$wl-compatibility_version $wl$minor_current $wl-current_version $wl$minor_current.$revision\"\n\t  verstring=\"-compatibility_version $minor_current -current_version $minor_current.$revision\"\n          # On Darwin other compilers\n          case $CC in\n              nagfor*)\n                  verstring=\"$wl-compatibility_version $wl$minor_current $wl-current_version $wl$minor_current.$revision\"\n                  ;;\n              *)\n                  verstring=\"-compatibility_version $minor_current -current_version $minor_current.$revision\"\n                  ;;\n          esac\n\t  ;;\n\n\tfreebsd-aout)\n\t  major=.$current\n\t  versuffix=.$current.$revision\n\t  ;;\n\n\tfreebsd-elf)\n\t  func_arith $current - $age\n\t  major=.$func_arith_result\n\t  versuffix=$major.$age.$revision\n\t  ;;\n\n\tirix | nonstopux)\n\t  if test no = \"$lt_irix_increment\"; then\n\t    func_arith $current - $age\n\t  else\n\t    func_arith $current - $age + 1\n\t  fi\n\t  major=$func_arith_result\n\n\t  case $version_type in\n\t    nonstopux) verstring_prefix=nonstopux ;;\n\t    *)         verstring_prefix=sgi ;;\n\t  esac\n\t  verstring=$verstring_prefix$major.$revision\n\n\t  # Add in all the interfaces that we are compatible with.\n\t  loop=$revision\n\t  while test 0 -ne \"$loop\"; do\n\t    func_arith $revision - $loop\n\t    iface=$func_arith_result\n\t    func_arith $loop - 1\n\t    loop=$func_arith_result\n\t    verstring=$verstring_prefix$major.$iface:$verstring\n\t  done\n\n\t  # Before this point, $major must not contain '.'.\n\t  major=.$major\n\t  versuffix=$major.$revision\n\t  ;;\n\n\tlinux) # correct to gnu/linux during the next big refactor\n\t  func_arith $current - $age\n\t  major=.$func_arith_result\n\t  versuffix=$major.$age.$revision\n\t  ;;\n\n\tosf)\n\t  func_arith $current - $age\n\t  major=.$func_arith_result\n\t  versuffix=.$current.$age.$revision\n\t  verstring=$current.$age.$revision\n\n\t  # Add in all the interfaces that we are compatible with.\n\t  loop=$age\n\t  while test 0 -ne \"$loop\"; do\n\t    func_arith $current - $loop\n\t    iface=$func_arith_result\n\t    func_arith $loop - 1\n\t    loop=$func_arith_result\n\t    verstring=$verstring:$iface.0\n\t  done\n\n\t  # Make executables depend on our current version.\n\t  func_append verstring \":$current.0\"\n\t  ;;\n\n\tqnx)\n\t  major=.$current\n\t  versuffix=.$current\n\t  ;;\n\n\tsco)\n\t  major=.$current\n\t  versuffix=.$current\n\t  ;;\n\n\tsunos)\n\t  major=.$current\n\t  versuffix=.$current.$revision\n\t  ;;\n\n\twindows)\n\t  # Use '-' rather than '.', since we only want one\n\t  # extension on DOS 8.3 file systems.\n\t  func_arith $current - $age\n\t  major=$func_arith_result\n\t  versuffix=-$major\n\t  ;;\n\n\t*)\n\t  func_fatal_configuration \"unknown library version type '$version_type'\"\n\t  ;;\n\tesac\n\n\t# Clear the version info if we defaulted, and they specified a release.\n\tif test -z \"$vinfo\" && test -n \"$release\"; then\n\t  major=\n\t  case $version_type in\n\t  darwin)\n\t    # we can't check for \"0.0\" in archive_cmds due to quoting\n\t    # problems, so we reset it completely\n\t    verstring=\n\t    ;;\n\t  *)\n\t    verstring=0.0\n\t    ;;\n\t  esac\n\t  if test no = \"$need_version\"; then\n\t    versuffix=\n\t  else\n\t    versuffix=.0.0\n\t  fi\n\tfi\n\n\t# Remove version info from name if versioning should be avoided\n\tif test yes,no = \"$avoid_version,$need_version\"; then\n\t  major=\n\t  versuffix=\n\t  verstring=\n\tfi\n\n\t# Check to see if the archive will have undefined symbols.\n\tif test yes = \"$allow_undefined\"; then\n\t  if test unsupported = \"$allow_undefined_flag\"; then\n\t    if test yes = \"$build_old_libs\"; then\n\t      func_warning \"undefined symbols not allowed in $host shared libraries; building static only\"\n\t      build_libtool_libs=no\n\t    else\n\t      func_fatal_error \"can't build $host shared library unless -no-undefined is specified\"\n\t    fi\n\t  fi\n\telse\n\t  # Don't allow undefined symbols.\n\t  allow_undefined_flag=$no_undefined_flag\n\tfi\n\n      fi\n\n      func_generate_dlsyms \"$libname\" \"$libname\" :\n      func_append libobjs \" $symfileobj\"\n      test \" \" = \"$libobjs\" && libobjs=\n\n      if test relink != \"$opt_mode\"; then\n\t# Remove our outputs, but don't remove object files since they\n\t# may have been created when compiling PIC objects.\n\tremovelist=\n\ttempremovelist=`$ECHO \"$output_objdir/*\"`\n\tfor p in $tempremovelist; do\n\t  case $p in\n\t    *.$objext | *.gcno)\n\t       ;;\n\t    $output_objdir/$outputname | $output_objdir/$libname.* | $output_objdir/$libname$release.*)\n\t       if test -n \"$precious_files_regex\"; then\n\t\t if $ECHO \"$p\" | $EGREP -e \"$precious_files_regex\" >/dev/null 2>&1\n\t\t then\n\t\t   continue\n\t\t fi\n\t       fi\n\t       func_append removelist \" $p\"\n\t       ;;\n\t    *) ;;\n\t  esac\n\tdone\n\ttest -n \"$removelist\" && \\\n\t  func_show_eval \"${RM}r \\$removelist\"\n      fi\n\n      # Now set the variables for building old libraries.\n      if test yes = \"$build_old_libs\" && test convenience != \"$build_libtool_libs\"; then\n\tfunc_append oldlibs \" $output_objdir/$libname.$libext\"\n\n\t# Transform .lo files to .o files.\n\toldobjs=\"$objs \"`$ECHO \"$libobjs\" | $SP2NL | $SED \"/\\.$libext$/d; $lo2o\" | $NL2SP`\n      fi\n\n      # Eliminate all temporary directories.\n      #for path in $notinst_path; do\n      #\tlib_search_path=`$ECHO \"$lib_search_path \" | $SED \"s% $path % %g\"`\n      #\tdeplibs=`$ECHO \"$deplibs \" | $SED \"s% -L$path % %g\"`\n      #\tdependency_libs=`$ECHO \"$dependency_libs \" | $SED \"s% -L$path % %g\"`\n      #done\n\n      if test -n \"$xrpath\"; then\n\t# If the user specified any rpath flags, then add them.\n\ttemp_xrpath=\n\tfor libdir in $xrpath; do\n\t  func_replace_sysroot \"$libdir\"\n\t  func_append temp_xrpath \" -R$func_replace_sysroot_result\"\n\t  case \"$finalize_rpath \" in\n\t  *\" $libdir \"*) ;;\n\t  *) func_append finalize_rpath \" $libdir\" ;;\n\t  esac\n\tdone\n\tif test yes != \"$hardcode_into_libs\" || test yes = \"$build_old_libs\"; then\n\t  dependency_libs=\"$temp_xrpath $dependency_libs\"\n\tfi\n      fi\n\n      # Make sure dlfiles contains only unique files that won't be dlpreopened\n      old_dlfiles=$dlfiles\n      dlfiles=\n      for lib in $old_dlfiles; do\n\tcase \" $dlprefiles $dlfiles \" in\n\t*\" $lib \"*) ;;\n\t*) func_append dlfiles \" $lib\" ;;\n\tesac\n      done\n\n      # Make sure dlprefiles contains only unique files\n      old_dlprefiles=$dlprefiles\n      dlprefiles=\n      for lib in $old_dlprefiles; do\n\tcase \"$dlprefiles \" in\n\t*\" $lib \"*) ;;\n\t*) func_append dlprefiles \" $lib\" ;;\n\tesac\n      done\n\n      if test yes = \"$build_libtool_libs\"; then\n\tif test -n \"$rpath\"; then\n\t  case $host in\n\t  *-*-cygwin* | *-*-mingw* | *-*-pw32* | *-*-os2* | *-*-beos* | *-cegcc* | *-*-haiku*)\n\t    # these systems don't actually have a c library (as such)!\n\t    ;;\n\t  *-*-rhapsody* | *-*-darwin1.[012])\n\t    # Rhapsody C library is in the System framework\n\t    func_append deplibs \" System.ltframework\"\n\t    ;;\n\t  *-*-netbsd*)\n\t    # Don't link with libc until the a.out ld.so is fixed.\n\t    ;;\n\t  *-*-openbsd* | *-*-freebsd* | *-*-dragonfly*)\n\t    # Do not include libc due to us having libc/libc_r.\n\t    ;;\n\t  *-*-sco3.2v5* | *-*-sco5v6*)\n\t    # Causes problems with __ctype\n\t    ;;\n\t  *-*-sysv4.2uw2* | *-*-sysv5* | *-*-unixware* | *-*-OpenUNIX*)\n\t    # Compiler inserts libc in the correct place for threads to work\n\t    ;;\n\t  *)\n\t    # Add libc to deplibs on all other systems if necessary.\n\t    if test yes = \"$build_libtool_need_lc\"; then\n\t      func_append deplibs \" -lc\"\n\t    fi\n\t    ;;\n\t  esac\n\tfi\n\n\t# Transform deplibs into only deplibs that can be linked in shared.\n\tname_save=$name\n\tlibname_save=$libname\n\trelease_save=$release\n\tversuffix_save=$versuffix\n\tmajor_save=$major\n\t# I'm not sure if I'm treating the release correctly.  I think\n\t# release should show up in the -l (ie -lgmp5) so we don't want to\n\t# add it in twice.  Is that correct?\n\trelease=\n\tversuffix=\n\tmajor=\n\tnewdeplibs=\n\tdroppeddeps=no\n\tcase $deplibs_check_method in\n\tpass_all)\n\t  # Don't check for shared/static.  Everything works.\n\t  # This might be a little naive.  We might want to check\n\t  # whether the library exists or not.  But this is on\n\t  # osf3 & osf4 and I'm not really sure... Just\n\t  # implementing what was already the behavior.\n\t  newdeplibs=$deplibs\n\t  ;;\n\ttest_compile)\n\t  # This code stresses the \"libraries are programs\" paradigm to its\n\t  # limits. Maybe even breaks it.  We compile a program, linking it\n\t  # against the deplibs as a proxy for the library.  Then we can check\n\t  # whether they linked in statically or dynamically with ldd.\n\t  $opt_dry_run || $RM conftest.c\n\t  cat > conftest.c <<EOF\n\t  int main() { return 0; }\nEOF\n\t  $opt_dry_run || $RM conftest\n\t  if $LTCC $LTCFLAGS -o conftest conftest.c $deplibs; then\n\t    ldd_output=`ldd conftest`\n\t    for i in $deplibs; do\n\t      case $i in\n\t      -l*)\n\t\tfunc_stripname -l '' \"$i\"\n\t\tname=$func_stripname_result\n\t\tif test yes = \"$allow_libtool_libs_with_static_runtimes\"; then\n\t\t  case \" $predeps $postdeps \" in\n\t\t  *\" $i \"*)\n\t\t    func_append newdeplibs \" $i\"\n\t\t    i=\n\t\t    ;;\n\t\t  esac\n\t\tfi\n\t\tif test -n \"$i\"; then\n\t\t  libname=`eval \"\\\\$ECHO \\\"$libname_spec\\\"\"`\n\t\t  deplib_matches=`eval \"\\\\$ECHO \\\"$library_names_spec\\\"\"`\n\t\t  set dummy $deplib_matches; shift\n\t\t  deplib_match=$1\n\t\t  if test `expr \"$ldd_output\" : \".*$deplib_match\"` -ne 0; then\n\t\t    func_append newdeplibs \" $i\"\n\t\t  else\n\t\t    droppeddeps=yes\n\t\t    echo\n\t\t    $ECHO \"*** Warning: dynamic linker does not accept needed library $i.\"\n\t\t    echo \"*** I have the capability to make that library automatically link in when\"\n\t\t    echo \"*** you link to this library.  But I can only do this if you have a\"\n\t\t    echo \"*** shared version of the library, which I believe you do not have\"\n\t\t    echo \"*** because a test_compile did reveal that the linker did not use it for\"\n\t\t    echo \"*** its dynamic dependency list that programs get resolved with at runtime.\"\n\t\t  fi\n\t\tfi\n\t\t;;\n\t      *)\n\t\tfunc_append newdeplibs \" $i\"\n\t\t;;\n\t      esac\n\t    done\n\t  else\n\t    # Error occurred in the first compile.  Let's try to salvage\n\t    # the situation: Compile a separate program for each library.\n\t    for i in $deplibs; do\n\t      case $i in\n\t      -l*)\n\t\tfunc_stripname -l '' \"$i\"\n\t\tname=$func_stripname_result\n\t\t$opt_dry_run || $RM conftest\n\t\tif $LTCC $LTCFLAGS -o conftest conftest.c $i; then\n\t\t  ldd_output=`ldd conftest`\n\t\t  if test yes = \"$allow_libtool_libs_with_static_runtimes\"; then\n\t\t    case \" $predeps $postdeps \" in\n\t\t    *\" $i \"*)\n\t\t      func_append newdeplibs \" $i\"\n\t\t      i=\n\t\t      ;;\n\t\t    esac\n\t\t  fi\n\t\t  if test -n \"$i\"; then\n\t\t    libname=`eval \"\\\\$ECHO \\\"$libname_spec\\\"\"`\n\t\t    deplib_matches=`eval \"\\\\$ECHO \\\"$library_names_spec\\\"\"`\n\t\t    set dummy $deplib_matches; shift\n\t\t    deplib_match=$1\n\t\t    if test `expr \"$ldd_output\" : \".*$deplib_match\"` -ne 0; then\n\t\t      func_append newdeplibs \" $i\"\n\t\t    else\n\t\t      droppeddeps=yes\n\t\t      echo\n\t\t      $ECHO \"*** Warning: dynamic linker does not accept needed library $i.\"\n\t\t      echo \"*** I have the capability to make that library automatically link in when\"\n\t\t      echo \"*** you link to this library.  But I can only do this if you have a\"\n\t\t      echo \"*** shared version of the library, which you do not appear to have\"\n\t\t      echo \"*** because a test_compile did reveal that the linker did not use this one\"\n\t\t      echo \"*** as a dynamic dependency that programs can get resolved with at runtime.\"\n\t\t    fi\n\t\t  fi\n\t\telse\n\t\t  droppeddeps=yes\n\t\t  echo\n\t\t  $ECHO \"*** Warning!  Library $i is needed by this library but I was not able to\"\n\t\t  echo \"*** make it link in!  You will probably need to install it or some\"\n\t\t  echo \"*** library that it depends on before this library will be fully\"\n\t\t  echo \"*** functional.  Installing it before continuing would be even better.\"\n\t\tfi\n\t\t;;\n\t      *)\n\t\tfunc_append newdeplibs \" $i\"\n\t\t;;\n\t      esac\n\t    done\n\t  fi\n\t  ;;\n\tfile_magic*)\n\t  set dummy $deplibs_check_method; shift\n\t  file_magic_regex=`expr \"$deplibs_check_method\" : \"$1 \\(.*\\)\"`\n\t  for a_deplib in $deplibs; do\n\t    case $a_deplib in\n\t    -l*)\n\t      func_stripname -l '' \"$a_deplib\"\n\t      name=$func_stripname_result\n\t      if test yes = \"$allow_libtool_libs_with_static_runtimes\"; then\n\t\tcase \" $predeps $postdeps \" in\n\t\t*\" $a_deplib \"*)\n\t\t  func_append newdeplibs \" $a_deplib\"\n\t\t  a_deplib=\n\t\t  ;;\n\t\tesac\n\t      fi\n\t      if test -n \"$a_deplib\"; then\n\t\tlibname=`eval \"\\\\$ECHO \\\"$libname_spec\\\"\"`\n\t\tif test -n \"$file_magic_glob\"; then\n\t\t  libnameglob=`func_echo_all \"$libname\" | $SED -e $file_magic_glob`\n\t\telse\n\t\t  libnameglob=$libname\n\t\tfi\n\t\ttest yes = \"$want_nocaseglob\" && nocaseglob=`shopt -p nocaseglob`\n\t\tfor i in $lib_search_path $sys_lib_search_path $shlib_search_path; do\n\t\t  if test yes = \"$want_nocaseglob\"; then\n\t\t    shopt -s nocaseglob\n\t\t    potential_libs=`ls $i/$libnameglob[.-]* 2>/dev/null`\n\t\t    $nocaseglob\n\t\t  else\n\t\t    potential_libs=`ls $i/$libnameglob[.-]* 2>/dev/null`\n\t\t  fi\n\t\t  for potent_lib in $potential_libs; do\n\t\t      # Follow soft links.\n\t\t      if ls -lLd \"$potent_lib\" 2>/dev/null |\n\t\t\t $GREP \" -> \" >/dev/null; then\n\t\t\tcontinue\n\t\t      fi\n\t\t      # The statement above tries to avoid entering an\n\t\t      # endless loop below, in case of cyclic links.\n\t\t      # We might still enter an endless loop, since a link\n\t\t      # loop can be closed while we follow links,\n\t\t      # but so what?\n\t\t      potlib=$potent_lib\n\t\t      while test -h \"$potlib\" 2>/dev/null; do\n\t\t\tpotliblink=`ls -ld $potlib | $SED 's/.* -> //'`\n\t\t\tcase $potliblink in\n\t\t\t[\\\\/]* | [A-Za-z]:[\\\\/]*) potlib=$potliblink;;\n\t\t\t*) potlib=`$ECHO \"$potlib\" | $SED 's|[^/]*$||'`\"$potliblink\";;\n\t\t\tesac\n\t\t      done\n\t\t      if eval $file_magic_cmd \\\"\\$potlib\\\" 2>/dev/null |\n\t\t\t $SED -e 10q |\n\t\t\t $EGREP \"$file_magic_regex\" > /dev/null; then\n\t\t\tfunc_append newdeplibs \" $a_deplib\"\n\t\t\ta_deplib=\n\t\t\tbreak 2\n\t\t      fi\n\t\t  done\n\t\tdone\n\t      fi\n\t      if test -n \"$a_deplib\"; then\n\t\tdroppeddeps=yes\n\t\techo\n\t\t$ECHO \"*** Warning: linker path does not have real file for library $a_deplib.\"\n\t\techo \"*** I have the capability to make that library automatically link in when\"\n\t\techo \"*** you link to this library.  But I can only do this if you have a\"\n\t\techo \"*** shared version of the library, which you do not appear to have\"\n\t\techo \"*** because I did check the linker path looking for a file starting\"\n\t\tif test -z \"$potlib\"; then\n\t\t  $ECHO \"*** with $libname but no candidates were found. (...for file magic test)\"\n\t\telse\n\t\t  $ECHO \"*** with $libname and none of the candidates passed a file format test\"\n\t\t  $ECHO \"*** using a file magic. Last file checked: $potlib\"\n\t\tfi\n\t      fi\n\t      ;;\n\t    *)\n\t      # Add a -L argument.\n\t      func_append newdeplibs \" $a_deplib\"\n\t      ;;\n\t    esac\n\t  done # Gone through all deplibs.\n\t  ;;\n\tmatch_pattern*)\n\t  set dummy $deplibs_check_method; shift\n\t  match_pattern_regex=`expr \"$deplibs_check_method\" : \"$1 \\(.*\\)\"`\n\t  for a_deplib in $deplibs; do\n\t    case $a_deplib in\n\t    -l*)\n\t      func_stripname -l '' \"$a_deplib\"\n\t      name=$func_stripname_result\n\t      if test yes = \"$allow_libtool_libs_with_static_runtimes\"; then\n\t\tcase \" $predeps $postdeps \" in\n\t\t*\" $a_deplib \"*)\n\t\t  func_append newdeplibs \" $a_deplib\"\n\t\t  a_deplib=\n\t\t  ;;\n\t\tesac\n\t      fi\n\t      if test -n \"$a_deplib\"; then\n\t\tlibname=`eval \"\\\\$ECHO \\\"$libname_spec\\\"\"`\n\t\tfor i in $lib_search_path $sys_lib_search_path $shlib_search_path; do\n\t\t  potential_libs=`ls $i/$libname[.-]* 2>/dev/null`\n\t\t  for potent_lib in $potential_libs; do\n\t\t    potlib=$potent_lib # see symlink-check above in file_magic test\n\t\t    if eval \"\\$ECHO \\\"$potent_lib\\\"\" 2>/dev/null | $SED 10q | \\\n\t\t       $EGREP \"$match_pattern_regex\" > /dev/null; then\n\t\t      func_append newdeplibs \" $a_deplib\"\n\t\t      a_deplib=\n\t\t      break 2\n\t\t    fi\n\t\t  done\n\t\tdone\n\t      fi\n\t      if test -n \"$a_deplib\"; then\n\t\tdroppeddeps=yes\n\t\techo\n\t\t$ECHO \"*** Warning: linker path does not have real file for library $a_deplib.\"\n\t\techo \"*** I have the capability to make that library automatically link in when\"\n\t\techo \"*** you link to this library.  But I can only do this if you have a\"\n\t\techo \"*** shared version of the library, which you do not appear to have\"\n\t\techo \"*** because I did check the linker path looking for a file starting\"\n\t\tif test -z \"$potlib\"; then\n\t\t  $ECHO \"*** with $libname but no candidates were found. (...for regex pattern test)\"\n\t\telse\n\t\t  $ECHO \"*** with $libname and none of the candidates passed a file format test\"\n\t\t  $ECHO \"*** using a regex pattern. Last file checked: $potlib\"\n\t\tfi\n\t      fi\n\t      ;;\n\t    *)\n\t      # Add a -L argument.\n\t      func_append newdeplibs \" $a_deplib\"\n\t      ;;\n\t    esac\n\t  done # Gone through all deplibs.\n\t  ;;\n\tnone | unknown | *)\n\t  newdeplibs=\n\t  tmp_deplibs=`$ECHO \" $deplibs\" | $SED 's/ -lc$//; s/ -[LR][^ ]*//g'`\n\t  if test yes = \"$allow_libtool_libs_with_static_runtimes\"; then\n\t    for i in $predeps $postdeps; do\n\t      # can't use Xsed below, because $i might contain '/'\n\t      tmp_deplibs=`$ECHO \" $tmp_deplibs\" | $SED \"s|$i||\"`\n\t    done\n\t  fi\n\t  case $tmp_deplibs in\n\t  *[!\\\t\\ ]*)\n\t    echo\n\t    if test none = \"$deplibs_check_method\"; then\n\t      echo \"*** Warning: inter-library dependencies are not supported in this platform.\"\n\t    else\n\t      echo \"*** Warning: inter-library dependencies are not known to be supported.\"\n\t    fi\n\t    echo \"*** All declared inter-library dependencies are being dropped.\"\n\t    droppeddeps=yes\n\t    ;;\n\t  esac\n\t  ;;\n\tesac\n\tversuffix=$versuffix_save\n\tmajor=$major_save\n\trelease=$release_save\n\tlibname=$libname_save\n\tname=$name_save\n\n\tcase $host in\n\t*-*-rhapsody* | *-*-darwin1.[012])\n\t  # On Rhapsody replace the C library with the System framework\n\t  newdeplibs=`$ECHO \" $newdeplibs\" | $SED 's/ -lc / System.ltframework /'`\n\t  ;;\n\tesac\n\n\tif test yes = \"$droppeddeps\"; then\n\t  if test yes = \"$module\"; then\n\t    echo\n\t    echo \"*** Warning: libtool could not satisfy all declared inter-library\"\n\t    $ECHO \"*** dependencies of module $libname.  Therefore, libtool will create\"\n\t    echo \"*** a static module, that should work as long as the dlopening\"\n\t    echo \"*** application is linked with the -dlopen flag.\"\n\t    if test -z \"$global_symbol_pipe\"; then\n\t      echo\n\t      echo \"*** However, this would only work if libtool was able to extract symbol\"\n\t      echo \"*** lists from a program, using 'nm' or equivalent, but libtool could\"\n\t      echo \"*** not find such a program.  So, this module is probably useless.\"\n\t      echo \"*** 'nm' from GNU binutils and a full rebuild may help.\"\n\t    fi\n\t    if test no = \"$build_old_libs\"; then\n\t      oldlibs=$output_objdir/$libname.$libext\n\t      build_libtool_libs=module\n\t      build_old_libs=yes\n\t    else\n\t      build_libtool_libs=no\n\t    fi\n\t  else\n\t    echo \"*** The inter-library dependencies that have been dropped here will be\"\n\t    echo \"*** automatically added whenever a program is linked with this library\"\n\t    echo \"*** or is declared to -dlopen it.\"\n\n\t    if test no = \"$allow_undefined\"; then\n\t      echo\n\t      echo \"*** Since this library must not contain undefined symbols,\"\n\t      echo \"*** because either the platform does not support them or\"\n\t      echo \"*** it was explicitly requested with -no-undefined,\"\n\t      echo \"*** libtool will only create a static version of it.\"\n\t      if test no = \"$build_old_libs\"; then\n\t\toldlibs=$output_objdir/$libname.$libext\n\t\tbuild_libtool_libs=module\n\t\tbuild_old_libs=yes\n\t      else\n\t\tbuild_libtool_libs=no\n\t      fi\n\t    fi\n\t  fi\n\tfi\n\t# Done checking deplibs!\n\tdeplibs=$newdeplibs\n      fi\n      # Time to change all our \"foo.ltframework\" stuff back to \"-framework foo\"\n      case $host in\n\t*-*-darwin*)\n\t  newdeplibs=`$ECHO \" $newdeplibs\" | $SED 's% \\([^ $]*\\).ltframework% -framework \\1%g'`\n\t  new_inherited_linker_flags=`$ECHO \" $new_inherited_linker_flags\" | $SED 's% \\([^ $]*\\).ltframework% -framework \\1%g'`\n\t  deplibs=`$ECHO \" $deplibs\" | $SED 's% \\([^ $]*\\).ltframework% -framework \\1%g'`\n\t  ;;\n      esac\n\n      # move library search paths that coincide with paths to not yet\n      # installed libraries to the beginning of the library search list\n      new_libs=\n      for path in $notinst_path; do\n\tcase \" $new_libs \" in\n\t*\" -L$path/$objdir \"*) ;;\n\t*)\n\t  case \" $deplibs \" in\n\t  *\" -L$path/$objdir \"*)\n\t    func_append new_libs \" -L$path/$objdir\" ;;\n\t  esac\n\t  ;;\n\tesac\n      done\n      for deplib in $deplibs; do\n\tcase $deplib in\n\t-L*)\n\t  case \" $new_libs \" in\n\t  *\" $deplib \"*) ;;\n\t  *) func_append new_libs \" $deplib\" ;;\n\t  esac\n\t  ;;\n\t*) func_append new_libs \" $deplib\" ;;\n\tesac\n      done\n      deplibs=$new_libs\n\n      # All the library-specific variables (install_libdir is set above).\n      library_names=\n      old_library=\n      dlname=\n\n      # Test again, we may have decided not to build it any more\n      if test yes = \"$build_libtool_libs\"; then\n\t# Remove $wl instances when linking with ld.\n\t# FIXME: should test the right _cmds variable.\n\tcase $archive_cmds in\n\t  *\\$LD\\ *) wl= ;;\n        esac\n\tif test yes = \"$hardcode_into_libs\"; then\n\t  # Hardcode the library paths\n\t  hardcode_libdirs=\n\t  dep_rpath=\n\t  rpath=$finalize_rpath\n\t  test relink = \"$opt_mode\" || rpath=$compile_rpath$rpath\n\t  for libdir in $rpath; do\n\t    if test -n \"$hardcode_libdir_flag_spec\"; then\n\t      if test -n \"$hardcode_libdir_separator\"; then\n\t\tfunc_replace_sysroot \"$libdir\"\n\t\tlibdir=$func_replace_sysroot_result\n\t\tif test -z \"$hardcode_libdirs\"; then\n\t\t  hardcode_libdirs=$libdir\n\t\telse\n\t\t  # Just accumulate the unique libdirs.\n\t\t  case $hardcode_libdir_separator$hardcode_libdirs$hardcode_libdir_separator in\n\t\t  *\"$hardcode_libdir_separator$libdir$hardcode_libdir_separator\"*)\n\t\t    ;;\n\t\t  *)\n\t\t    func_append hardcode_libdirs \"$hardcode_libdir_separator$libdir\"\n\t\t    ;;\n\t\t  esac\n\t\tfi\n\t      else\n\t\teval flag=\\\"$hardcode_libdir_flag_spec\\\"\n\t\tfunc_append dep_rpath \" $flag\"\n\t      fi\n\t    elif test -n \"$runpath_var\"; then\n\t      case \"$perm_rpath \" in\n\t      *\" $libdir \"*) ;;\n\t      *) func_append perm_rpath \" $libdir\" ;;\n\t      esac\n\t    fi\n\t  done\n\t  # Substitute the hardcoded libdirs into the rpath.\n\t  if test -n \"$hardcode_libdir_separator\" &&\n\t     test -n \"$hardcode_libdirs\"; then\n\t    libdir=$hardcode_libdirs\n\t    eval \"dep_rpath=\\\"$hardcode_libdir_flag_spec\\\"\"\n\t  fi\n\t  if test -n \"$runpath_var\" && test -n \"$perm_rpath\"; then\n\t    # We should set the runpath_var.\n\t    rpath=\n\t    for dir in $perm_rpath; do\n\t      func_append rpath \"$dir:\"\n\t    done\n\t    eval \"$runpath_var='$rpath\\$$runpath_var'; export $runpath_var\"\n\t  fi\n\t  test -n \"$dep_rpath\" && deplibs=\"$dep_rpath $deplibs\"\n\tfi\n\n\tshlibpath=$finalize_shlibpath\n\ttest relink = \"$opt_mode\" || shlibpath=$compile_shlibpath$shlibpath\n\tif test -n \"$shlibpath\"; then\n\t  eval \"$shlibpath_var='$shlibpath\\$$shlibpath_var'; export $shlibpath_var\"\n\tfi\n\n\t# Get the real and link names of the library.\n\teval shared_ext=\\\"$shrext_cmds\\\"\n\teval library_names=\\\"$library_names_spec\\\"\n\tset dummy $library_names\n\tshift\n\trealname=$1\n\tshift\n\n\tif test -n \"$soname_spec\"; then\n\t  eval soname=\\\"$soname_spec\\\"\n\telse\n\t  soname=$realname\n\tfi\n\tif test -z \"$dlname\"; then\n\t  dlname=$soname\n\tfi\n\n\tlib=$output_objdir/$realname\n\tlinknames=\n\tfor link\n\tdo\n\t  func_append linknames \" $link\"\n\tdone\n\n\t# Use standard objects if they are pic\n\ttest -z \"$pic_flag\" && libobjs=`$ECHO \"$libobjs\" | $SP2NL | $SED \"$lo2o\" | $NL2SP`\n\ttest \"X$libobjs\" = \"X \" && libobjs=\n\n\tdelfiles=\n\tif test -n \"$export_symbols\" && test -n \"$include_expsyms\"; then\n\t  $opt_dry_run || cp \"$export_symbols\" \"$output_objdir/$libname.uexp\"\n\t  export_symbols=$output_objdir/$libname.uexp\n\t  func_append delfiles \" $export_symbols\"\n\tfi\n\n\torig_export_symbols=\n\tcase $host_os in\n\tcygwin* | mingw* | cegcc*)\n\t  if test -n \"$export_symbols\" && test -z \"$export_symbols_regex\"; then\n\t    # exporting using user supplied symfile\n\t    func_dll_def_p \"$export_symbols\" || {\n\t      # and it's NOT already a .def file. Must figure out\n\t      # which of the given symbols are data symbols and tag\n\t      # them as such. So, trigger use of export_symbols_cmds.\n\t      # export_symbols gets reassigned inside the \"prepare\n\t      # the list of exported symbols\" if statement, so the\n\t      # include_expsyms logic still works.\n\t      orig_export_symbols=$export_symbols\n\t      export_symbols=\n\t      always_export_symbols=yes\n\t    }\n\t  fi\n\t  ;;\n\tesac\n\n\t# Prepare the list of exported symbols\n\tif test -z \"$export_symbols\"; then\n\t  if test yes = \"$always_export_symbols\" || test -n \"$export_symbols_regex\"; then\n\t    func_verbose \"generating symbol list for '$libname.la'\"\n\t    export_symbols=$output_objdir/$libname.exp\n\t    $opt_dry_run || $RM $export_symbols\n\t    cmds=$export_symbols_cmds\n\t    save_ifs=$IFS; IFS='~'\n\t    for cmd1 in $cmds; do\n\t      IFS=$save_ifs\n\t      # Take the normal branch if the nm_file_list_spec branch\n\t      # doesn't work or if tool conversion is not needed.\n\t      case $nm_file_list_spec~$to_tool_file_cmd in\n\t\t*~func_convert_file_noop | *~func_convert_file_msys_to_w32 | ~*)\n\t\t  try_normal_branch=yes\n\t\t  eval cmd=\\\"$cmd1\\\"\n\t\t  func_len \" $cmd\"\n\t\t  len=$func_len_result\n\t\t  ;;\n\t\t*)\n\t\t  try_normal_branch=no\n\t\t  ;;\n\t      esac\n\t      if test yes = \"$try_normal_branch\" \\\n\t\t && { test \"$len\" -lt \"$max_cmd_len\" \\\n\t\t      || test \"$max_cmd_len\" -le -1; }\n\t      then\n\t\tfunc_show_eval \"$cmd\" 'exit $?'\n\t\tskipped_export=false\n\t      elif test -n \"$nm_file_list_spec\"; then\n\t\tfunc_basename \"$output\"\n\t\toutput_la=$func_basename_result\n\t\tsave_libobjs=$libobjs\n\t\tsave_output=$output\n\t\toutput=$output_objdir/$output_la.nm\n\t\tfunc_to_tool_file \"$output\"\n\t\tlibobjs=$nm_file_list_spec$func_to_tool_file_result\n\t\tfunc_append delfiles \" $output\"\n\t\tfunc_verbose \"creating $NM input file list: $output\"\n\t\tfor obj in $save_libobjs; do\n\t\t  func_to_tool_file \"$obj\"\n\t\t  $ECHO \"$func_to_tool_file_result\"\n\t\tdone > \"$output\"\n\t\teval cmd=\\\"$cmd1\\\"\n\t\tfunc_show_eval \"$cmd\" 'exit $?'\n\t\toutput=$save_output\n\t\tlibobjs=$save_libobjs\n\t\tskipped_export=false\n\t      else\n\t\t# The command line is too long to execute in one step.\n\t\tfunc_verbose \"using reloadable object file for export list...\"\n\t\tskipped_export=:\n\t\t# Break out early, otherwise skipped_export may be\n\t\t# set to false by a later but shorter cmd.\n\t\tbreak\n\t      fi\n\t    done\n\t    IFS=$save_ifs\n\t    if test -n \"$export_symbols_regex\" && test : != \"$skipped_export\"; then\n\t      func_show_eval '$EGREP -e \"$export_symbols_regex\" \"$export_symbols\" > \"${export_symbols}T\"'\n\t      func_show_eval '$MV \"${export_symbols}T\" \"$export_symbols\"'\n\t    fi\n\t  fi\n\tfi\n\n\tif test -n \"$export_symbols\" && test -n \"$include_expsyms\"; then\n\t  tmp_export_symbols=$export_symbols\n\t  test -n \"$orig_export_symbols\" && tmp_export_symbols=$orig_export_symbols\n\t  $opt_dry_run || eval '$ECHO \"$include_expsyms\" | $SP2NL >> \"$tmp_export_symbols\"'\n\tfi\n\n\tif test : != \"$skipped_export\" && test -n \"$orig_export_symbols\"; then\n\t  # The given exports_symbols file has to be filtered, so filter it.\n\t  func_verbose \"filter symbol list for '$libname.la' to tag DATA exports\"\n\t  # FIXME: $output_objdir/$libname.filter potentially contains lots of\n\t  # 's' commands, which not all seds can handle. GNU sed should be fine\n\t  # though. Also, the filter scales superlinearly with the number of\n\t  # global variables. join(1) would be nice here, but unfortunately\n\t  # isn't a blessed tool.\n\t  $opt_dry_run || $SED -e '/[ ,]DATA/!d;s,\\(.*\\)\\([ \\,].*\\),s|^\\1$|\\1\\2|,' < $export_symbols > $output_objdir/$libname.filter\n\t  func_append delfiles \" $export_symbols $output_objdir/$libname.filter\"\n\t  export_symbols=$output_objdir/$libname.def\n\t  $opt_dry_run || $SED -f $output_objdir/$libname.filter < $orig_export_symbols > $export_symbols\n\tfi\n\n\ttmp_deplibs=\n\tfor test_deplib in $deplibs; do\n\t  case \" $convenience \" in\n\t  *\" $test_deplib \"*) ;;\n\t  *)\n\t    func_append tmp_deplibs \" $test_deplib\"\n\t    ;;\n\t  esac\n\tdone\n\tdeplibs=$tmp_deplibs\n\n\tif test -n \"$convenience\"; then\n\t  if test -n \"$whole_archive_flag_spec\" &&\n\t    test yes = \"$compiler_needs_object\" &&\n\t    test -z \"$libobjs\"; then\n\t    # extract the archives, so we have objects to list.\n\t    # TODO: could optimize this to just extract one archive.\n\t    whole_archive_flag_spec=\n\t  fi\n\t  if test -n \"$whole_archive_flag_spec\"; then\n\t    save_libobjs=$libobjs\n\t    eval libobjs=\\\"\\$libobjs $whole_archive_flag_spec\\\"\n\t    test \"X$libobjs\" = \"X \" && libobjs=\n\t  else\n\t    gentop=$output_objdir/${outputname}x\n\t    func_append generated \" $gentop\"\n\n\t    func_extract_archives $gentop $convenience\n\t    func_append libobjs \" $func_extract_archives_result\"\n\t    test \"X$libobjs\" = \"X \" && libobjs=\n\t  fi\n\tfi\n\n\tif test yes = \"$thread_safe\" && test -n \"$thread_safe_flag_spec\"; then\n\t  eval flag=\\\"$thread_safe_flag_spec\\\"\n\t  func_append linker_flags \" $flag\"\n\tfi\n\n\t# Make a backup of the uninstalled library when relinking\n\tif test relink = \"$opt_mode\"; then\n\t  $opt_dry_run || eval '(cd $output_objdir && $RM ${realname}U && $MV $realname ${realname}U)' || exit $?\n\tfi\n\n\t# Do each of the archive commands.\n\tif test yes = \"$module\" && test -n \"$module_cmds\"; then\n\t  if test -n \"$export_symbols\" && test -n \"$module_expsym_cmds\"; then\n\t    eval test_cmds=\\\"$module_expsym_cmds\\\"\n\t    cmds=$module_expsym_cmds\n\t  else\n\t    eval test_cmds=\\\"$module_cmds\\\"\n\t    cmds=$module_cmds\n\t  fi\n\telse\n\t  if test -n \"$export_symbols\" && test -n \"$archive_expsym_cmds\"; then\n\t    eval test_cmds=\\\"$archive_expsym_cmds\\\"\n\t    cmds=$archive_expsym_cmds\n\t  else\n\t    eval test_cmds=\\\"$archive_cmds\\\"\n\t    cmds=$archive_cmds\n\t  fi\n\tfi\n\n\tif test : != \"$skipped_export\" &&\n\t   func_len \" $test_cmds\" &&\n\t   len=$func_len_result &&\n\t   test \"$len\" -lt \"$max_cmd_len\" || test \"$max_cmd_len\" -le -1; then\n\t  :\n\telse\n\t  # The command line is too long to link in one step, link piecewise\n\t  # or, if using GNU ld and skipped_export is not :, use a linker\n\t  # script.\n\n\t  # Save the value of $output and $libobjs because we want to\n\t  # use them later.  If we have whole_archive_flag_spec, we\n\t  # want to use save_libobjs as it was before\n\t  # whole_archive_flag_spec was expanded, because we can't\n\t  # assume the linker understands whole_archive_flag_spec.\n\t  # This may have to be revisited, in case too many\n\t  # convenience libraries get linked in and end up exceeding\n\t  # the spec.\n\t  if test -z \"$convenience\" || test -z \"$whole_archive_flag_spec\"; then\n\t    save_libobjs=$libobjs\n\t  fi\n\t  save_output=$output\n\t  func_basename \"$output\"\n\t  output_la=$func_basename_result\n\n\t  # Clear the reloadable object creation command queue and\n\t  # initialize k to one.\n\t  test_cmds=\n\t  concat_cmds=\n\t  objlist=\n\t  last_robj=\n\t  k=1\n\n\t  if test -n \"$save_libobjs\" && test : != \"$skipped_export\" && test yes = \"$with_gnu_ld\"; then\n\t    output=$output_objdir/$output_la.lnkscript\n\t    func_verbose \"creating GNU ld script: $output\"\n\t    echo 'INPUT (' > $output\n\t    for obj in $save_libobjs\n\t    do\n\t      func_to_tool_file \"$obj\"\n\t      $ECHO \"$func_to_tool_file_result\" >> $output\n\t    done\n\t    echo ')' >> $output\n\t    func_append delfiles \" $output\"\n\t    func_to_tool_file \"$output\"\n\t    output=$func_to_tool_file_result\n\t  elif test -n \"$save_libobjs\" && test : != \"$skipped_export\" && test -n \"$file_list_spec\"; then\n\t    output=$output_objdir/$output_la.lnk\n\t    func_verbose \"creating linker input file list: $output\"\n\t    : > $output\n\t    set x $save_libobjs\n\t    shift\n\t    firstobj=\n\t    if test yes = \"$compiler_needs_object\"; then\n\t      firstobj=\"$1 \"\n\t      shift\n\t    fi\n\t    for obj\n\t    do\n\t      func_to_tool_file \"$obj\"\n\t      $ECHO \"$func_to_tool_file_result\" >> $output\n\t    done\n\t    func_append delfiles \" $output\"\n\t    func_to_tool_file \"$output\"\n\t    output=$firstobj\\\"$file_list_spec$func_to_tool_file_result\\\"\n\t  else\n\t    if test -n \"$save_libobjs\"; then\n\t      func_verbose \"creating reloadable object files...\"\n\t      output=$output_objdir/$output_la-$k.$objext\n\t      eval test_cmds=\\\"$reload_cmds\\\"\n\t      func_len \" $test_cmds\"\n\t      len0=$func_len_result\n\t      len=$len0\n\n\t      # Loop over the list of objects to be linked.\n\t      for obj in $save_libobjs\n\t      do\n\t\tfunc_len \" $obj\"\n\t\tfunc_arith $len + $func_len_result\n\t\tlen=$func_arith_result\n\t\tif test -z \"$objlist\" ||\n\t\t   test \"$len\" -lt \"$max_cmd_len\"; then\n\t\t  func_append objlist \" $obj\"\n\t\telse\n\t\t  # The command $test_cmds is almost too long, add a\n\t\t  # command to the queue.\n\t\t  if test 1 -eq \"$k\"; then\n\t\t    # The first file doesn't have a previous command to add.\n\t\t    reload_objs=$objlist\n\t\t    eval concat_cmds=\\\"$reload_cmds\\\"\n\t\t  else\n\t\t    # All subsequent reloadable object files will link in\n\t\t    # the last one created.\n\t\t    reload_objs=\"$objlist $last_robj\"\n\t\t    eval concat_cmds=\\\"\\$concat_cmds~$reload_cmds~\\$RM $last_robj\\\"\n\t\t  fi\n\t\t  last_robj=$output_objdir/$output_la-$k.$objext\n\t\t  func_arith $k + 1\n\t\t  k=$func_arith_result\n\t\t  output=$output_objdir/$output_la-$k.$objext\n\t\t  objlist=\" $obj\"\n\t\t  func_len \" $last_robj\"\n\t\t  func_arith $len0 + $func_len_result\n\t\t  len=$func_arith_result\n\t\tfi\n\t      done\n\t      # Handle the remaining objects by creating one last\n\t      # reloadable object file.  All subsequent reloadable object\n\t      # files will link in the last one created.\n\t      test -z \"$concat_cmds\" || concat_cmds=$concat_cmds~\n\t      reload_objs=\"$objlist $last_robj\"\n\t      eval concat_cmds=\\\"\\$concat_cmds$reload_cmds\\\"\n\t      if test -n \"$last_robj\"; then\n\t        eval concat_cmds=\\\"\\$concat_cmds~\\$RM $last_robj\\\"\n\t      fi\n\t      func_append delfiles \" $output\"\n\n\t    else\n\t      output=\n\t    fi\n\n\t    ${skipped_export-false} && {\n\t      func_verbose \"generating symbol list for '$libname.la'\"\n\t      export_symbols=$output_objdir/$libname.exp\n\t      $opt_dry_run || $RM $export_symbols\n\t      libobjs=$output\n\t      # Append the command to create the export file.\n\t      test -z \"$concat_cmds\" || concat_cmds=$concat_cmds~\n\t      eval concat_cmds=\\\"\\$concat_cmds$export_symbols_cmds\\\"\n\t      if test -n \"$last_robj\"; then\n\t\teval concat_cmds=\\\"\\$concat_cmds~\\$RM $last_robj\\\"\n\t      fi\n\t    }\n\n\t    test -n \"$save_libobjs\" &&\n\t      func_verbose \"creating a temporary reloadable object file: $output\"\n\n\t    # Loop through the commands generated above and execute them.\n\t    save_ifs=$IFS; IFS='~'\n\t    for cmd in $concat_cmds; do\n\t      IFS=$save_ifs\n\t      $opt_quiet || {\n\t\t  func_quote_for_expand \"$cmd\"\n\t\t  eval \"func_echo $func_quote_for_expand_result\"\n\t      }\n\t      $opt_dry_run || eval \"$cmd\" || {\n\t\tlt_exit=$?\n\n\t\t# Restore the uninstalled library and exit\n\t\tif test relink = \"$opt_mode\"; then\n\t\t  ( cd \"$output_objdir\" && \\\n\t\t    $RM \"${realname}T\" && \\\n\t\t    $MV \"${realname}U\" \"$realname\" )\n\t\tfi\n\n\t\texit $lt_exit\n\t      }\n\t    done\n\t    IFS=$save_ifs\n\n\t    if test -n \"$export_symbols_regex\" && ${skipped_export-false}; then\n\t      func_show_eval '$EGREP -e \"$export_symbols_regex\" \"$export_symbols\" > \"${export_symbols}T\"'\n\t      func_show_eval '$MV \"${export_symbols}T\" \"$export_symbols\"'\n\t    fi\n\t  fi\n\n          ${skipped_export-false} && {\n\t    if test -n \"$export_symbols\" && test -n \"$include_expsyms\"; then\n\t      tmp_export_symbols=$export_symbols\n\t      test -n \"$orig_export_symbols\" && tmp_export_symbols=$orig_export_symbols\n\t      $opt_dry_run || eval '$ECHO \"$include_expsyms\" | $SP2NL >> \"$tmp_export_symbols\"'\n\t    fi\n\n\t    if test -n \"$orig_export_symbols\"; then\n\t      # The given exports_symbols file has to be filtered, so filter it.\n\t      func_verbose \"filter symbol list for '$libname.la' to tag DATA exports\"\n\t      # FIXME: $output_objdir/$libname.filter potentially contains lots of\n\t      # 's' commands, which not all seds can handle. GNU sed should be fine\n\t      # though. Also, the filter scales superlinearly with the number of\n\t      # global variables. join(1) would be nice here, but unfortunately\n\t      # isn't a blessed tool.\n\t      $opt_dry_run || $SED -e '/[ ,]DATA/!d;s,\\(.*\\)\\([ \\,].*\\),s|^\\1$|\\1\\2|,' < $export_symbols > $output_objdir/$libname.filter\n\t      func_append delfiles \" $export_symbols $output_objdir/$libname.filter\"\n\t      export_symbols=$output_objdir/$libname.def\n\t      $opt_dry_run || $SED -f $output_objdir/$libname.filter < $orig_export_symbols > $export_symbols\n\t    fi\n\t  }\n\n\t  libobjs=$output\n\t  # Restore the value of output.\n\t  output=$save_output\n\n\t  if test -n \"$convenience\" && test -n \"$whole_archive_flag_spec\"; then\n\t    eval libobjs=\\\"\\$libobjs $whole_archive_flag_spec\\\"\n\t    test \"X$libobjs\" = \"X \" && libobjs=\n\t  fi\n\t  # Expand the library linking commands again to reset the\n\t  # value of $libobjs for piecewise linking.\n\n\t  # Do each of the archive commands.\n\t  if test yes = \"$module\" && test -n \"$module_cmds\"; then\n\t    if test -n \"$export_symbols\" && test -n \"$module_expsym_cmds\"; then\n\t      cmds=$module_expsym_cmds\n\t    else\n\t      cmds=$module_cmds\n\t    fi\n\t  else\n\t    if test -n \"$export_symbols\" && test -n \"$archive_expsym_cmds\"; then\n\t      cmds=$archive_expsym_cmds\n\t    else\n\t      cmds=$archive_cmds\n\t    fi\n\t  fi\n\tfi\n\n\tif test -n \"$delfiles\"; then\n\t  # Append the command to remove temporary files to $cmds.\n\t  eval cmds=\\\"\\$cmds~\\$RM $delfiles\\\"\n\tfi\n\n\t# Add any objects from preloaded convenience libraries\n\tif test -n \"$dlprefiles\"; then\n\t  gentop=$output_objdir/${outputname}x\n\t  func_append generated \" $gentop\"\n\n\t  func_extract_archives $gentop $dlprefiles\n\t  func_append libobjs \" $func_extract_archives_result\"\n\t  test \"X$libobjs\" = \"X \" && libobjs=\n\tfi\n\n\tsave_ifs=$IFS; IFS='~'\n\tfor cmd in $cmds; do\n\t  IFS=$sp$nl\n\t  eval cmd=\\\"$cmd\\\"\n\t  IFS=$save_ifs\n\t  $opt_quiet || {\n\t    func_quote_for_expand \"$cmd\"\n\t    eval \"func_echo $func_quote_for_expand_result\"\n\t  }\n\t  $opt_dry_run || eval \"$cmd\" || {\n\t    lt_exit=$?\n\n\t    # Restore the uninstalled library and exit\n\t    if test relink = \"$opt_mode\"; then\n\t      ( cd \"$output_objdir\" && \\\n\t        $RM \"${realname}T\" && \\\n\t\t$MV \"${realname}U\" \"$realname\" )\n\t    fi\n\n\t    exit $lt_exit\n\t  }\n\tdone\n\tIFS=$save_ifs\n\n\t# Restore the uninstalled library and exit\n\tif test relink = \"$opt_mode\"; then\n\t  $opt_dry_run || eval '(cd $output_objdir && $RM ${realname}T && $MV $realname ${realname}T && $MV ${realname}U $realname)' || exit $?\n\n\t  if test -n \"$convenience\"; then\n\t    if test -z \"$whole_archive_flag_spec\"; then\n\t      func_show_eval '${RM}r \"$gentop\"'\n\t    fi\n\t  fi\n\n\t  exit $EXIT_SUCCESS\n\tfi\n\n\t# Create links to the real library.\n\tfor linkname in $linknames; do\n\t  if test \"$realname\" != \"$linkname\"; then\n\t    func_show_eval '(cd \"$output_objdir\" && $RM \"$linkname\" && $LN_S \"$realname\" \"$linkname\")' 'exit $?'\n\t  fi\n\tdone\n\n\t# If -module or -export-dynamic was specified, set the dlname.\n\tif test yes = \"$module\" || test yes = \"$export_dynamic\"; then\n\t  # On all known operating systems, these are identical.\n\t  dlname=$soname\n\tfi\n      fi\n      ;;\n\n    obj)\n      if test -n \"$dlfiles$dlprefiles\" || test no != \"$dlself\"; then\n\tfunc_warning \"'-dlopen' is ignored for objects\"\n      fi\n\n      case \" $deplibs\" in\n      *\\ -l* | *\\ -L*)\n\tfunc_warning \"'-l' and '-L' are ignored for objects\" ;;\n      esac\n\n      test -n \"$rpath\" && \\\n\tfunc_warning \"'-rpath' is ignored for objects\"\n\n      test -n \"$xrpath\" && \\\n\tfunc_warning \"'-R' is ignored for objects\"\n\n      test -n \"$vinfo\" && \\\n\tfunc_warning \"'-version-info' is ignored for objects\"\n\n      test -n \"$release\" && \\\n\tfunc_warning \"'-release' is ignored for objects\"\n\n      case $output in\n      *.lo)\n\ttest -n \"$objs$old_deplibs\" && \\\n\t  func_fatal_error \"cannot build library object '$output' from non-libtool objects\"\n\n\tlibobj=$output\n\tfunc_lo2o \"$libobj\"\n\tobj=$func_lo2o_result\n\t;;\n      *)\n\tlibobj=\n\tobj=$output\n\t;;\n      esac\n\n      # Delete the old objects.\n      $opt_dry_run || $RM $obj $libobj\n\n      # Objects from convenience libraries.  This assumes\n      # single-version convenience libraries.  Whenever we create\n      # different ones for PIC/non-PIC, this we'll have to duplicate\n      # the extraction.\n      reload_conv_objs=\n      gentop=\n      # if reload_cmds runs $LD directly, get rid of -Wl from\n      # whole_archive_flag_spec and hope we can get by with turning comma\n      # into space.\n      case $reload_cmds in\n        *\\$LD[\\ \\$]*) wl= ;;\n      esac\n      if test -n \"$convenience\"; then\n\tif test -n \"$whole_archive_flag_spec\"; then\n\t  eval tmp_whole_archive_flags=\\\"$whole_archive_flag_spec\\\"\n\t  test -n \"$wl\" || tmp_whole_archive_flags=`$ECHO \"$tmp_whole_archive_flags\" | $SED 's|,| |g'`\n\t  reload_conv_objs=$reload_objs\\ $tmp_whole_archive_flags\n\telse\n\t  gentop=$output_objdir/${obj}x\n\t  func_append generated \" $gentop\"\n\n\t  func_extract_archives $gentop $convenience\n\t  reload_conv_objs=\"$reload_objs $func_extract_archives_result\"\n\tfi\n      fi\n\n      # If we're not building shared, we need to use non_pic_objs\n      test yes = \"$build_libtool_libs\" || libobjs=$non_pic_objects\n\n      # Create the old-style object.\n      reload_objs=$objs$old_deplibs' '`$ECHO \"$libobjs\" | $SP2NL | $SED \"/\\.$libext$/d; /\\.lib$/d; $lo2o\" | $NL2SP`' '$reload_conv_objs\n\n      output=$obj\n      func_execute_cmds \"$reload_cmds\" 'exit $?'\n\n      # Exit if we aren't doing a library object file.\n      if test -z \"$libobj\"; then\n\tif test -n \"$gentop\"; then\n\t  func_show_eval '${RM}r \"$gentop\"'\n\tfi\n\n\texit $EXIT_SUCCESS\n      fi\n\n      test yes = \"$build_libtool_libs\" || {\n\tif test -n \"$gentop\"; then\n\t  func_show_eval '${RM}r \"$gentop\"'\n\tfi\n\n\t# Create an invalid libtool object if no PIC, so that we don't\n\t# accidentally link it into a program.\n\t# $show \"echo timestamp > $libobj\"\n\t# $opt_dry_run || eval \"echo timestamp > $libobj\" || exit $?\n\texit $EXIT_SUCCESS\n      }\n\n      if test -n \"$pic_flag\" || test default != \"$pic_mode\"; then\n\t# Only do commands if we really have different PIC objects.\n\treload_objs=\"$libobjs $reload_conv_objs\"\n\toutput=$libobj\n\tfunc_execute_cmds \"$reload_cmds\" 'exit $?'\n      fi\n\n      if test -n \"$gentop\"; then\n\tfunc_show_eval '${RM}r \"$gentop\"'\n      fi\n\n      exit $EXIT_SUCCESS\n      ;;\n\n    prog)\n      case $host in\n\t*cygwin*) func_stripname '' '.exe' \"$output\"\n\t          output=$func_stripname_result.exe;;\n      esac\n      test -n \"$vinfo\" && \\\n\tfunc_warning \"'-version-info' is ignored for programs\"\n\n      test -n \"$release\" && \\\n\tfunc_warning \"'-release' is ignored for programs\"\n\n      $preload \\\n\t&& test unknown,unknown,unknown = \"$dlopen_support,$dlopen_self,$dlopen_self_static\" \\\n\t&& func_warning \"'LT_INIT([dlopen])' not used. Assuming no dlopen support.\"\n\n      case $host in\n      *-*-rhapsody* | *-*-darwin1.[012])\n\t# On Rhapsody replace the C library is the System framework\n\tcompile_deplibs=`$ECHO \" $compile_deplibs\" | $SED 's/ -lc / System.ltframework /'`\n\tfinalize_deplibs=`$ECHO \" $finalize_deplibs\" | $SED 's/ -lc / System.ltframework /'`\n\t;;\n      esac\n\n      case $host in\n      *-*-darwin*)\n\t# Don't allow lazy linking, it breaks C++ global constructors\n\t# But is supposedly fixed on 10.4 or later (yay!).\n\tif test CXX = \"$tagname\"; then\n\t  case ${MACOSX_DEPLOYMENT_TARGET-10.0} in\n\t    10.[0123])\n\t      func_append compile_command \" $wl-bind_at_load\"\n\t      func_append finalize_command \" $wl-bind_at_load\"\n\t    ;;\n\t  esac\n\tfi\n\t# Time to change all our \"foo.ltframework\" stuff back to \"-framework foo\"\n\tcompile_deplibs=`$ECHO \" $compile_deplibs\" | $SED 's% \\([^ $]*\\).ltframework% -framework \\1%g'`\n\tfinalize_deplibs=`$ECHO \" $finalize_deplibs\" | $SED 's% \\([^ $]*\\).ltframework% -framework \\1%g'`\n\t;;\n      esac\n\n\n      # move library search paths that coincide with paths to not yet\n      # installed libraries to the beginning of the library search list\n      new_libs=\n      for path in $notinst_path; do\n\tcase \" $new_libs \" in\n\t*\" -L$path/$objdir \"*) ;;\n\t*)\n\t  case \" $compile_deplibs \" in\n\t  *\" -L$path/$objdir \"*)\n\t    func_append new_libs \" -L$path/$objdir\" ;;\n\t  esac\n\t  ;;\n\tesac\n      done\n      for deplib in $compile_deplibs; do\n\tcase $deplib in\n\t-L*)\n\t  case \" $new_libs \" in\n\t  *\" $deplib \"*) ;;\n\t  *) func_append new_libs \" $deplib\" ;;\n\t  esac\n\t  ;;\n\t*) func_append new_libs \" $deplib\" ;;\n\tesac\n      done\n      compile_deplibs=$new_libs\n\n\n      func_append compile_command \" $compile_deplibs\"\n      func_append finalize_command \" $finalize_deplibs\"\n\n      if test -n \"$rpath$xrpath\"; then\n\t# If the user specified any rpath flags, then add them.\n\tfor libdir in $rpath $xrpath; do\n\t  # This is the magic to use -rpath.\n\t  case \"$finalize_rpath \" in\n\t  *\" $libdir \"*) ;;\n\t  *) func_append finalize_rpath \" $libdir\" ;;\n\t  esac\n\tdone\n      fi\n\n      # Now hardcode the library paths\n      rpath=\n      hardcode_libdirs=\n      for libdir in $compile_rpath $finalize_rpath; do\n\tif test -n \"$hardcode_libdir_flag_spec\"; then\n\t  if test -n \"$hardcode_libdir_separator\"; then\n\t    if test -z \"$hardcode_libdirs\"; then\n\t      hardcode_libdirs=$libdir\n\t    else\n\t      # Just accumulate the unique libdirs.\n\t      case $hardcode_libdir_separator$hardcode_libdirs$hardcode_libdir_separator in\n\t      *\"$hardcode_libdir_separator$libdir$hardcode_libdir_separator\"*)\n\t\t;;\n\t      *)\n\t\tfunc_append hardcode_libdirs \"$hardcode_libdir_separator$libdir\"\n\t\t;;\n\t      esac\n\t    fi\n\t  else\n\t    eval flag=\\\"$hardcode_libdir_flag_spec\\\"\n\t    func_append rpath \" $flag\"\n\t  fi\n\telif test -n \"$runpath_var\"; then\n\t  case \"$perm_rpath \" in\n\t  *\" $libdir \"*) ;;\n\t  *) func_append perm_rpath \" $libdir\" ;;\n\t  esac\n\tfi\n\tcase $host in\n\t*-*-cygwin* | *-*-mingw* | *-*-pw32* | *-*-os2* | *-cegcc*)\n\t  testbindir=`$ECHO \"$libdir\" | $SED -e 's*/lib$*/bin*'`\n\t  case :$dllsearchpath: in\n\t  *\":$libdir:\"*) ;;\n\t  ::) dllsearchpath=$libdir;;\n\t  *) func_append dllsearchpath \":$libdir\";;\n\t  esac\n\t  case :$dllsearchpath: in\n\t  *\":$testbindir:\"*) ;;\n\t  ::) dllsearchpath=$testbindir;;\n\t  *) func_append dllsearchpath \":$testbindir\";;\n\t  esac\n\t  ;;\n\tesac\n      done\n      # Substitute the hardcoded libdirs into the rpath.\n      if test -n \"$hardcode_libdir_separator\" &&\n\t test -n \"$hardcode_libdirs\"; then\n\tlibdir=$hardcode_libdirs\n\teval rpath=\\\" $hardcode_libdir_flag_spec\\\"\n      fi\n      compile_rpath=$rpath\n\n      rpath=\n      hardcode_libdirs=\n      for libdir in $finalize_rpath; do\n\tif test -n \"$hardcode_libdir_flag_spec\"; then\n\t  if test -n \"$hardcode_libdir_separator\"; then\n\t    if test -z \"$hardcode_libdirs\"; then\n\t      hardcode_libdirs=$libdir\n\t    else\n\t      # Just accumulate the unique libdirs.\n\t      case $hardcode_libdir_separator$hardcode_libdirs$hardcode_libdir_separator in\n\t      *\"$hardcode_libdir_separator$libdir$hardcode_libdir_separator\"*)\n\t\t;;\n\t      *)\n\t\tfunc_append hardcode_libdirs \"$hardcode_libdir_separator$libdir\"\n\t\t;;\n\t      esac\n\t    fi\n\t  else\n\t    eval flag=\\\"$hardcode_libdir_flag_spec\\\"\n\t    func_append rpath \" $flag\"\n\t  fi\n\telif test -n \"$runpath_var\"; then\n\t  case \"$finalize_perm_rpath \" in\n\t  *\" $libdir \"*) ;;\n\t  *) func_append finalize_perm_rpath \" $libdir\" ;;\n\t  esac\n\tfi\n      done\n      # Substitute the hardcoded libdirs into the rpath.\n      if test -n \"$hardcode_libdir_separator\" &&\n\t test -n \"$hardcode_libdirs\"; then\n\tlibdir=$hardcode_libdirs\n\teval rpath=\\\" $hardcode_libdir_flag_spec\\\"\n      fi\n      finalize_rpath=$rpath\n\n      if test -n \"$libobjs\" && test yes = \"$build_old_libs\"; then\n\t# Transform all the library objects into standard objects.\n\tcompile_command=`$ECHO \"$compile_command\" | $SP2NL | $SED \"$lo2o\" | $NL2SP`\n\tfinalize_command=`$ECHO \"$finalize_command\" | $SP2NL | $SED \"$lo2o\" | $NL2SP`\n      fi\n\n      func_generate_dlsyms \"$outputname\" \"@PROGRAM@\" false\n\n      # template prelinking step\n      if test -n \"$prelink_cmds\"; then\n\tfunc_execute_cmds \"$prelink_cmds\" 'exit $?'\n      fi\n\n      wrappers_required=:\n      case $host in\n      *cegcc* | *mingw32ce*)\n        # Disable wrappers for cegcc and mingw32ce hosts, we are cross compiling anyway.\n        wrappers_required=false\n        ;;\n      *cygwin* | *mingw* )\n        test yes = \"$build_libtool_libs\" || wrappers_required=false\n        ;;\n      *)\n        if test no = \"$need_relink\" || test yes != \"$build_libtool_libs\"; then\n          wrappers_required=false\n        fi\n        ;;\n      esac\n      $wrappers_required || {\n\t# Replace the output file specification.\n\tcompile_command=`$ECHO \"$compile_command\" | $SED 's%@OUTPUT@%'\"$output\"'%g'`\n\tlink_command=$compile_command$compile_rpath\n\n\t# We have no uninstalled library dependencies, so finalize right now.\n\texit_status=0\n\tfunc_show_eval \"$link_command\" 'exit_status=$?'\n\n\tif test -n \"$postlink_cmds\"; then\n\t  func_to_tool_file \"$output\"\n\t  postlink_cmds=`func_echo_all \"$postlink_cmds\" | $SED -e 's%@OUTPUT@%'\"$output\"'%g' -e 's%@TOOL_OUTPUT@%'\"$func_to_tool_file_result\"'%g'`\n\t  func_execute_cmds \"$postlink_cmds\" 'exit $?'\n\tfi\n\n\t# Delete the generated files.\n\tif test -f \"$output_objdir/${outputname}S.$objext\"; then\n\t  func_show_eval '$RM \"$output_objdir/${outputname}S.$objext\"'\n\tfi\n\n\texit $exit_status\n      }\n\n      if test -n \"$compile_shlibpath$finalize_shlibpath\"; then\n\tcompile_command=\"$shlibpath_var=\\\"$compile_shlibpath$finalize_shlibpath\\$$shlibpath_var\\\" $compile_command\"\n      fi\n      if test -n \"$finalize_shlibpath\"; then\n\tfinalize_command=\"$shlibpath_var=\\\"$finalize_shlibpath\\$$shlibpath_var\\\" $finalize_command\"\n      fi\n\n      compile_var=\n      finalize_var=\n      if test -n \"$runpath_var\"; then\n\tif test -n \"$perm_rpath\"; then\n\t  # We should set the runpath_var.\n\t  rpath=\n\t  for dir in $perm_rpath; do\n\t    func_append rpath \"$dir:\"\n\t  done\n\t  compile_var=\"$runpath_var=\\\"$rpath\\$$runpath_var\\\" \"\n\tfi\n\tif test -n \"$finalize_perm_rpath\"; then\n\t  # We should set the runpath_var.\n\t  rpath=\n\t  for dir in $finalize_perm_rpath; do\n\t    func_append rpath \"$dir:\"\n\t  done\n\t  finalize_var=\"$runpath_var=\\\"$rpath\\$$runpath_var\\\" \"\n\tfi\n      fi\n\n      if test yes = \"$no_install\"; then\n\t# We don't need to create a wrapper script.\n\tlink_command=$compile_var$compile_command$compile_rpath\n\t# Replace the output file specification.\n\tlink_command=`$ECHO \"$link_command\" | $SED 's%@OUTPUT@%'\"$output\"'%g'`\n\t# Delete the old output file.\n\t$opt_dry_run || $RM $output\n\t# Link the executable and exit\n\tfunc_show_eval \"$link_command\" 'exit $?'\n\n\tif test -n \"$postlink_cmds\"; then\n\t  func_to_tool_file \"$output\"\n\t  postlink_cmds=`func_echo_all \"$postlink_cmds\" | $SED -e 's%@OUTPUT@%'\"$output\"'%g' -e 's%@TOOL_OUTPUT@%'\"$func_to_tool_file_result\"'%g'`\n\t  func_execute_cmds \"$postlink_cmds\" 'exit $?'\n\tfi\n\n\texit $EXIT_SUCCESS\n      fi\n\n      case $hardcode_action,$fast_install in\n        relink,*)\n\t  # Fast installation is not supported\n\t  link_command=$compile_var$compile_command$compile_rpath\n\t  relink_command=$finalize_var$finalize_command$finalize_rpath\n\n\t  func_warning \"this platform does not like uninstalled shared libraries\"\n\t  func_warning \"'$output' will be relinked during installation\"\n\t  ;;\n        *,yes)\n\t  link_command=$finalize_var$compile_command$finalize_rpath\n\t  relink_command=`$ECHO \"$compile_var$compile_command$compile_rpath\" | $SED 's%@OUTPUT@%\\$progdir/\\$file%g'`\n          ;;\n\t*,no)\n\t  link_command=$compile_var$compile_command$compile_rpath\n\t  relink_command=$finalize_var$finalize_command$finalize_rpath\n          ;;\n\t*,needless)\n\t  link_command=$finalize_var$compile_command$finalize_rpath\n\t  relink_command=\n          ;;\n      esac\n\n      # Replace the output file specification.\n      link_command=`$ECHO \"$link_command\" | $SED 's%@OUTPUT@%'\"$output_objdir/$outputname\"'%g'`\n\n      # Delete the old output files.\n      $opt_dry_run || $RM $output $output_objdir/$outputname $output_objdir/lt-$outputname\n\n      func_show_eval \"$link_command\" 'exit $?'\n\n      if test -n \"$postlink_cmds\"; then\n\tfunc_to_tool_file \"$output_objdir/$outputname\"\n\tpostlink_cmds=`func_echo_all \"$postlink_cmds\" | $SED -e 's%@OUTPUT@%'\"$output_objdir/$outputname\"'%g' -e 's%@TOOL_OUTPUT@%'\"$func_to_tool_file_result\"'%g'`\n\tfunc_execute_cmds \"$postlink_cmds\" 'exit $?'\n      fi\n\n      # Now create the wrapper script.\n      func_verbose \"creating $output\"\n\n      # Quote the relink command for shipping.\n      if test -n \"$relink_command\"; then\n\t# Preserve any variables that may affect compiler behavior\n\tfor var in $variables_saved_for_relink; do\n\t  if eval test -z \\\"\\${$var+set}\\\"; then\n\t    relink_command=\"{ test -z \\\"\\${$var+set}\\\" || $lt_unset $var || { $var=; export $var; }; }; $relink_command\"\n\t  elif eval var_value=\\$$var; test -z \"$var_value\"; then\n\t    relink_command=\"$var=; export $var; $relink_command\"\n\t  else\n\t    func_quote_for_eval \"$var_value\"\n\t    relink_command=\"$var=$func_quote_for_eval_result; export $var; $relink_command\"\n\t  fi\n\tdone\n\trelink_command=\"(cd `pwd`; $relink_command)\"\n\trelink_command=`$ECHO \"$relink_command\" | $SED \"$sed_quote_subst\"`\n      fi\n\n      # Only actually do things if not in dry run mode.\n      $opt_dry_run || {\n\t# win32 will think the script is a binary if it has\n\t# a .exe suffix, so we strip it off here.\n\tcase $output in\n\t  *.exe) func_stripname '' '.exe' \"$output\"\n\t         output=$func_stripname_result ;;\n\tesac\n\t# test for cygwin because mv fails w/o .exe extensions\n\tcase $host in\n\t  *cygwin*)\n\t    exeext=.exe\n\t    func_stripname '' '.exe' \"$outputname\"\n\t    outputname=$func_stripname_result ;;\n\t  *) exeext= ;;\n\tesac\n\tcase $host in\n\t  *cygwin* | *mingw* )\n\t    func_dirname_and_basename \"$output\" \"\" \".\"\n\t    output_name=$func_basename_result\n\t    output_path=$func_dirname_result\n\t    cwrappersource=$output_path/$objdir/lt-$output_name.c\n\t    cwrapper=$output_path/$output_name.exe\n\t    $RM $cwrappersource $cwrapper\n\t    trap \"$RM $cwrappersource $cwrapper; exit $EXIT_FAILURE\" 1 2 15\n\n\t    func_emit_cwrapperexe_src > $cwrappersource\n\n\t    # The wrapper executable is built using the $host compiler,\n\t    # because it contains $host paths and files. If cross-\n\t    # compiling, it, like the target executable, must be\n\t    # executed on the $host or under an emulation environment.\n\t    $opt_dry_run || {\n\t      $LTCC $LTCFLAGS -o $cwrapper $cwrappersource\n\t      $STRIP $cwrapper\n\t    }\n\n\t    # Now, create the wrapper script for func_source use:\n\t    func_ltwrapper_scriptname $cwrapper\n\t    $RM $func_ltwrapper_scriptname_result\n\t    trap \"$RM $func_ltwrapper_scriptname_result; exit $EXIT_FAILURE\" 1 2 15\n\t    $opt_dry_run || {\n\t      # note: this script will not be executed, so do not chmod.\n\t      if test \"x$build\" = \"x$host\"; then\n\t\t$cwrapper --lt-dump-script > $func_ltwrapper_scriptname_result\n\t      else\n\t\tfunc_emit_wrapper no > $func_ltwrapper_scriptname_result\n\t      fi\n\t    }\n\t  ;;\n\t  * )\n\t    $RM $output\n\t    trap \"$RM $output; exit $EXIT_FAILURE\" 1 2 15\n\n\t    func_emit_wrapper no > $output\n\t    chmod +x $output\n\t  ;;\n\tesac\n      }\n      exit $EXIT_SUCCESS\n      ;;\n    esac\n\n    # See if we need to build an old-fashioned archive.\n    for oldlib in $oldlibs; do\n\n      case $build_libtool_libs in\n        convenience)\n\t  oldobjs=\"$libobjs_save $symfileobj\"\n\t  addlibs=$convenience\n\t  build_libtool_libs=no\n\t  ;;\n\tmodule)\n\t  oldobjs=$libobjs_save\n\t  addlibs=$old_convenience\n\t  build_libtool_libs=no\n          ;;\n\t*)\n\t  oldobjs=\"$old_deplibs $non_pic_objects\"\n\t  $preload && test -f \"$symfileobj\" \\\n\t    && func_append oldobjs \" $symfileobj\"\n\t  addlibs=$old_convenience\n\t  ;;\n      esac\n\n      if test -n \"$addlibs\"; then\n\tgentop=$output_objdir/${outputname}x\n\tfunc_append generated \" $gentop\"\n\n\tfunc_extract_archives $gentop $addlibs\n\tfunc_append oldobjs \" $func_extract_archives_result\"\n      fi\n\n      # Do each command in the archive commands.\n      if test -n \"$old_archive_from_new_cmds\" && test yes = \"$build_libtool_libs\"; then\n\tcmds=$old_archive_from_new_cmds\n      else\n\n\t# Add any objects from preloaded convenience libraries\n\tif test -n \"$dlprefiles\"; then\n\t  gentop=$output_objdir/${outputname}x\n\t  func_append generated \" $gentop\"\n\n\t  func_extract_archives $gentop $dlprefiles\n\t  func_append oldobjs \" $func_extract_archives_result\"\n\tfi\n\n\t# POSIX demands no paths to be encoded in archives.  We have\n\t# to avoid creating archives with duplicate basenames if we\n\t# might have to extract them afterwards, e.g., when creating a\n\t# static archive out of a convenience library, or when linking\n\t# the entirety of a libtool archive into another (currently\n\t# not supported by libtool).\n\tif (for obj in $oldobjs\n\t    do\n\t      func_basename \"$obj\"\n\t      $ECHO \"$func_basename_result\"\n\t    done | sort | sort -uc >/dev/null 2>&1); then\n\t  :\n\telse\n\t  echo \"copying selected object files to avoid basename conflicts...\"\n\t  gentop=$output_objdir/${outputname}x\n\t  func_append generated \" $gentop\"\n\t  func_mkdir_p \"$gentop\"\n\t  save_oldobjs=$oldobjs\n\t  oldobjs=\n\t  counter=1\n\t  for obj in $save_oldobjs\n\t  do\n\t    func_basename \"$obj\"\n\t    objbase=$func_basename_result\n\t    case \" $oldobjs \" in\n\t    \" \") oldobjs=$obj ;;\n\t    *[\\ /]\"$objbase \"*)\n\t      while :; do\n\t\t# Make sure we don't pick an alternate name that also\n\t\t# overlaps.\n\t\tnewobj=lt$counter-$objbase\n\t\tfunc_arith $counter + 1\n\t\tcounter=$func_arith_result\n\t\tcase \" $oldobjs \" in\n\t\t*[\\ /]\"$newobj \"*) ;;\n\t\t*) if test ! -f \"$gentop/$newobj\"; then break; fi ;;\n\t\tesac\n\t      done\n\t      func_show_eval \"ln $obj $gentop/$newobj || cp $obj $gentop/$newobj\"\n\t      func_append oldobjs \" $gentop/$newobj\"\n\t      ;;\n\t    *) func_append oldobjs \" $obj\" ;;\n\t    esac\n\t  done\n\tfi\n\tfunc_to_tool_file \"$oldlib\" func_convert_file_msys_to_w32\n\ttool_oldlib=$func_to_tool_file_result\n\teval cmds=\\\"$old_archive_cmds\\\"\n\n\tfunc_len \" $cmds\"\n\tlen=$func_len_result\n\tif test \"$len\" -lt \"$max_cmd_len\" || test \"$max_cmd_len\" -le -1; then\n\t  cmds=$old_archive_cmds\n\telif test -n \"$archiver_list_spec\"; then\n\t  func_verbose \"using command file archive linking...\"\n\t  for obj in $oldobjs\n\t  do\n\t    func_to_tool_file \"$obj\"\n\t    $ECHO \"$func_to_tool_file_result\"\n\t  done > $output_objdir/$libname.libcmd\n\t  func_to_tool_file \"$output_objdir/$libname.libcmd\"\n\t  oldobjs=\" $archiver_list_spec$func_to_tool_file_result\"\n\t  cmds=$old_archive_cmds\n\telse\n\t  # the command line is too long to link in one step, link in parts\n\t  func_verbose \"using piecewise archive linking...\"\n\t  save_RANLIB=$RANLIB\n\t  RANLIB=:\n\t  objlist=\n\t  concat_cmds=\n\t  save_oldobjs=$oldobjs\n\t  oldobjs=\n\t  # Is there a better way of finding the last object in the list?\n\t  for obj in $save_oldobjs\n\t  do\n\t    last_oldobj=$obj\n\t  done\n\t  eval test_cmds=\\\"$old_archive_cmds\\\"\n\t  func_len \" $test_cmds\"\n\t  len0=$func_len_result\n\t  len=$len0\n\t  for obj in $save_oldobjs\n\t  do\n\t    func_len \" $obj\"\n\t    func_arith $len + $func_len_result\n\t    len=$func_arith_result\n\t    func_append objlist \" $obj\"\n\t    if test \"$len\" -lt \"$max_cmd_len\"; then\n\t      :\n\t    else\n\t      # the above command should be used before it gets too long\n\t      oldobjs=$objlist\n\t      if test \"$obj\" = \"$last_oldobj\"; then\n\t\tRANLIB=$save_RANLIB\n\t      fi\n\t      test -z \"$concat_cmds\" || concat_cmds=$concat_cmds~\n\t      eval concat_cmds=\\\"\\$concat_cmds$old_archive_cmds\\\"\n\t      objlist=\n\t      len=$len0\n\t    fi\n\t  done\n\t  RANLIB=$save_RANLIB\n\t  oldobjs=$objlist\n\t  if test -z \"$oldobjs\"; then\n\t    eval cmds=\\\"\\$concat_cmds\\\"\n\t  else\n\t    eval cmds=\\\"\\$concat_cmds~\\$old_archive_cmds\\\"\n\t  fi\n\tfi\n      fi\n      func_execute_cmds \"$cmds\" 'exit $?'\n    done\n\n    test -n \"$generated\" && \\\n      func_show_eval \"${RM}r$generated\"\n\n    # Now create the libtool archive.\n    case $output in\n    *.la)\n      old_library=\n      test yes = \"$build_old_libs\" && old_library=$libname.$libext\n      func_verbose \"creating $output\"\n\n      # Preserve any variables that may affect compiler behavior\n      for var in $variables_saved_for_relink; do\n\tif eval test -z \\\"\\${$var+set}\\\"; then\n\t  relink_command=\"{ test -z \\\"\\${$var+set}\\\" || $lt_unset $var || { $var=; export $var; }; }; $relink_command\"\n\telif eval var_value=\\$$var; test -z \"$var_value\"; then\n\t  relink_command=\"$var=; export $var; $relink_command\"\n\telse\n\t  func_quote_for_eval \"$var_value\"\n\t  relink_command=\"$var=$func_quote_for_eval_result; export $var; $relink_command\"\n\tfi\n      done\n      # Quote the link command for shipping.\n      relink_command=\"(cd `pwd`; $SHELL \\\"$progpath\\\" $preserve_args --mode=relink $libtool_args @inst_prefix_dir@)\"\n      relink_command=`$ECHO \"$relink_command\" | $SED \"$sed_quote_subst\"`\n      if test yes = \"$hardcode_automatic\"; then\n\trelink_command=\n      fi\n\n      # Only create the output if not a dry run.\n      $opt_dry_run || {\n\tfor installed in no yes; do\n\t  if test yes = \"$installed\"; then\n\t    if test -z \"$install_libdir\"; then\n\t      break\n\t    fi\n\t    output=$output_objdir/${outputname}i\n\t    # Replace all uninstalled libtool libraries with the installed ones\n\t    newdependency_libs=\n\t    for deplib in $dependency_libs; do\n\t      case $deplib in\n\t      *.la)\n\t\tfunc_basename \"$deplib\"\n\t\tname=$func_basename_result\n\t\tfunc_resolve_sysroot \"$deplib\"\n\t\teval libdir=`$SED -n -e 's/^libdir=\\(.*\\)$/\\1/p' $func_resolve_sysroot_result`\n\t\ttest -z \"$libdir\" && \\\n\t\t  func_fatal_error \"'$deplib' is not a valid libtool archive\"\n\t\tfunc_append newdependency_libs \" ${lt_sysroot:+=}$libdir/$name\"\n\t\t;;\n\t      -L*)\n\t\tfunc_stripname -L '' \"$deplib\"\n\t\tfunc_replace_sysroot \"$func_stripname_result\"\n\t\tfunc_append newdependency_libs \" -L$func_replace_sysroot_result\"\n\t\t;;\n\t      -R*)\n\t\tfunc_stripname -R '' \"$deplib\"\n\t\tfunc_replace_sysroot \"$func_stripname_result\"\n\t\tfunc_append newdependency_libs \" -R$func_replace_sysroot_result\"\n\t\t;;\n\t      *) func_append newdependency_libs \" $deplib\" ;;\n\t      esac\n\t    done\n\t    dependency_libs=$newdependency_libs\n\t    newdlfiles=\n\n\t    for lib in $dlfiles; do\n\t      case $lib in\n\t      *.la)\n\t        func_basename \"$lib\"\n\t\tname=$func_basename_result\n\t\teval libdir=`$SED -n -e 's/^libdir=\\(.*\\)$/\\1/p' $lib`\n\t\ttest -z \"$libdir\" && \\\n\t\t  func_fatal_error \"'$lib' is not a valid libtool archive\"\n\t\tfunc_append newdlfiles \" ${lt_sysroot:+=}$libdir/$name\"\n\t\t;;\n\t      *) func_append newdlfiles \" $lib\" ;;\n\t      esac\n\t    done\n\t    dlfiles=$newdlfiles\n\t    newdlprefiles=\n\t    for lib in $dlprefiles; do\n\t      case $lib in\n\t      *.la)\n\t\t# Only pass preopened files to the pseudo-archive (for\n\t\t# eventual linking with the app. that links it) if we\n\t\t# didn't already link the preopened objects directly into\n\t\t# the library:\n\t\tfunc_basename \"$lib\"\n\t\tname=$func_basename_result\n\t\teval libdir=`$SED -n -e 's/^libdir=\\(.*\\)$/\\1/p' $lib`\n\t\ttest -z \"$libdir\" && \\\n\t\t  func_fatal_error \"'$lib' is not a valid libtool archive\"\n\t\tfunc_append newdlprefiles \" ${lt_sysroot:+=}$libdir/$name\"\n\t\t;;\n\t      esac\n\t    done\n\t    dlprefiles=$newdlprefiles\n\t  else\n\t    newdlfiles=\n\t    for lib in $dlfiles; do\n\t      case $lib in\n\t\t[\\\\/]* | [A-Za-z]:[\\\\/]*) abs=$lib ;;\n\t\t*) abs=`pwd`\"/$lib\" ;;\n\t      esac\n\t      func_append newdlfiles \" $abs\"\n\t    done\n\t    dlfiles=$newdlfiles\n\t    newdlprefiles=\n\t    for lib in $dlprefiles; do\n\t      case $lib in\n\t\t[\\\\/]* | [A-Za-z]:[\\\\/]*) abs=$lib ;;\n\t\t*) abs=`pwd`\"/$lib\" ;;\n\t      esac\n\t      func_append newdlprefiles \" $abs\"\n\t    done\n\t    dlprefiles=$newdlprefiles\n\t  fi\n\t  $RM $output\n\t  # place dlname in correct position for cygwin\n\t  # In fact, it would be nice if we could use this code for all target\n\t  # systems that can't hard-code library paths into their executables\n\t  # and that have no shared library path variable independent of PATH,\n\t  # but it turns out we can't easily determine that from inspecting\n\t  # libtool variables, so we have to hard-code the OSs to which it\n\t  # applies here; at the moment, that means platforms that use the PE\n\t  # object format with DLL files.  See the long comment at the top of\n\t  # tests/bindir.at for full details.\n\t  tdlname=$dlname\n\t  case $host,$output,$installed,$module,$dlname in\n\t    *cygwin*,*lai,yes,no,*.dll | *mingw*,*lai,yes,no,*.dll | *cegcc*,*lai,yes,no,*.dll)\n\t      # If a -bindir argument was supplied, place the dll there.\n\t      if test -n \"$bindir\"; then\n\t\tfunc_relative_path \"$install_libdir\" \"$bindir\"\n\t\ttdlname=$func_relative_path_result/$dlname\n\t      else\n\t\t# Otherwise fall back on heuristic.\n\t\ttdlname=../bin/$dlname\n\t      fi\n\t      ;;\n\t  esac\n\t  $ECHO > $output \"\\\n# $outputname - a libtool library file\n# Generated by $PROGRAM (GNU $PACKAGE) $VERSION\n#\n# Please DO NOT delete this file!\n# It is necessary for linking the library.\n\n# The name that we can dlopen(3).\ndlname='$tdlname'\n\n# Names of this library.\nlibrary_names='$library_names'\n\n# The name of the static archive.\nold_library='$old_library'\n\n# Linker flags that cannot go in dependency_libs.\ninherited_linker_flags='$new_inherited_linker_flags'\n\n# Libraries that this one depends upon.\ndependency_libs='$dependency_libs'\n\n# Names of additional weak libraries provided by this library\nweak_library_names='$weak_libs'\n\n# Version information for $libname.\ncurrent=$current\nage=$age\nrevision=$revision\n\n# Is this an already installed library?\ninstalled=$installed\n\n# Should we warn about portability when linking against -modules?\nshouldnotlink=$module\n\n# Files to dlopen/dlpreopen\ndlopen='$dlfiles'\ndlpreopen='$dlprefiles'\n\n# Directory that this library needs to be installed in:\nlibdir='$install_libdir'\"\n\t  if test no,yes = \"$installed,$need_relink\"; then\n\t    $ECHO >> $output \"\\\nrelink_command=\\\"$relink_command\\\"\"\n\t  fi\n\tdone\n      }\n\n      # Do a symbolic link so that the libtool archive can be found in\n      # LD_LIBRARY_PATH before the program is installed.\n      func_show_eval '( cd \"$output_objdir\" && $RM \"$outputname\" && $LN_S \"../$outputname\" \"$outputname\" )' 'exit $?'\n      ;;\n    esac\n    exit $EXIT_SUCCESS\n}\n\nif test link = \"$opt_mode\" || test relink = \"$opt_mode\"; then\n  func_mode_link ${1+\"$@\"}\nfi\n\n\n# func_mode_uninstall arg...\nfunc_mode_uninstall ()\n{\n    $debug_cmd\n\n    RM=$nonopt\n    files=\n    rmforce=false\n    exit_status=0\n\n    # This variable tells wrapper scripts just to set variables rather\n    # than running their programs.\n    libtool_install_magic=$magic\n\n    for arg\n    do\n      case $arg in\n      -f) func_append RM \" $arg\"; rmforce=: ;;\n      -*) func_append RM \" $arg\" ;;\n      *) func_append files \" $arg\" ;;\n      esac\n    done\n\n    test -z \"$RM\" && \\\n      func_fatal_help \"you must specify an RM program\"\n\n    rmdirs=\n\n    for file in $files; do\n      func_dirname \"$file\" \"\" \".\"\n      dir=$func_dirname_result\n      if test . = \"$dir\"; then\n\todir=$objdir\n      else\n\todir=$dir/$objdir\n      fi\n      func_basename \"$file\"\n      name=$func_basename_result\n      test uninstall = \"$opt_mode\" && odir=$dir\n\n      # Remember odir for removal later, being careful to avoid duplicates\n      if test clean = \"$opt_mode\"; then\n\tcase \" $rmdirs \" in\n\t  *\" $odir \"*) ;;\n\t  *) func_append rmdirs \" $odir\" ;;\n\tesac\n      fi\n\n      # Don't error if the file doesn't exist and rm -f was used.\n      if { test -L \"$file\"; } >/dev/null 2>&1 ||\n\t { test -h \"$file\"; } >/dev/null 2>&1 ||\n\t test -f \"$file\"; then\n\t:\n      elif test -d \"$file\"; then\n\texit_status=1\n\tcontinue\n      elif $rmforce; then\n\tcontinue\n      fi\n\n      rmfiles=$file\n\n      case $name in\n      *.la)\n\t# Possibly a libtool archive, so verify it.\n\tif func_lalib_p \"$file\"; then\n\t  func_source $dir/$name\n\n\t  # Delete the libtool libraries and symlinks.\n\t  for n in $library_names; do\n\t    func_append rmfiles \" $odir/$n\"\n\t  done\n\t  test -n \"$old_library\" && func_append rmfiles \" $odir/$old_library\"\n\n\t  case $opt_mode in\n\t  clean)\n\t    case \" $library_names \" in\n\t    *\" $dlname \"*) ;;\n\t    *) test -n \"$dlname\" && func_append rmfiles \" $odir/$dlname\" ;;\n\t    esac\n\t    test -n \"$libdir\" && func_append rmfiles \" $odir/$name $odir/${name}i\"\n\t    ;;\n\t  uninstall)\n\t    if test -n \"$library_names\"; then\n\t      # Do each command in the postuninstall commands.\n\t      func_execute_cmds \"$postuninstall_cmds\" '$rmforce || exit_status=1'\n\t    fi\n\n\t    if test -n \"$old_library\"; then\n\t      # Do each command in the old_postuninstall commands.\n\t      func_execute_cmds \"$old_postuninstall_cmds\" '$rmforce || exit_status=1'\n\t    fi\n\t    # FIXME: should reinstall the best remaining shared library.\n\t    ;;\n\t  esac\n\tfi\n\t;;\n\n      *.lo)\n\t# Possibly a libtool object, so verify it.\n\tif func_lalib_p \"$file\"; then\n\n\t  # Read the .lo file\n\t  func_source $dir/$name\n\n\t  # Add PIC object to the list of files to remove.\n\t  if test -n \"$pic_object\" && test none != \"$pic_object\"; then\n\t    func_append rmfiles \" $dir/$pic_object\"\n\t  fi\n\n\t  # Add non-PIC object to the list of files to remove.\n\t  if test -n \"$non_pic_object\" && test none != \"$non_pic_object\"; then\n\t    func_append rmfiles \" $dir/$non_pic_object\"\n\t  fi\n\tfi\n\t;;\n\n      *)\n\tif test clean = \"$opt_mode\"; then\n\t  noexename=$name\n\t  case $file in\n\t  *.exe)\n\t    func_stripname '' '.exe' \"$file\"\n\t    file=$func_stripname_result\n\t    func_stripname '' '.exe' \"$name\"\n\t    noexename=$func_stripname_result\n\t    # $file with .exe has already been added to rmfiles,\n\t    # add $file without .exe\n\t    func_append rmfiles \" $file\"\n\t    ;;\n\t  esac\n\t  # Do a test to see if this is a libtool program.\n\t  if func_ltwrapper_p \"$file\"; then\n\t    if func_ltwrapper_executable_p \"$file\"; then\n\t      func_ltwrapper_scriptname \"$file\"\n\t      relink_command=\n\t      func_source $func_ltwrapper_scriptname_result\n\t      func_append rmfiles \" $func_ltwrapper_scriptname_result\"\n\t    else\n\t      relink_command=\n\t      func_source $dir/$noexename\n\t    fi\n\n\t    # note $name still contains .exe if it was in $file originally\n\t    # as does the version of $file that was added into $rmfiles\n\t    func_append rmfiles \" $odir/$name $odir/${name}S.$objext\"\n\t    if test yes = \"$fast_install\" && test -n \"$relink_command\"; then\n\t      func_append rmfiles \" $odir/lt-$name\"\n\t    fi\n\t    if test \"X$noexename\" != \"X$name\"; then\n\t      func_append rmfiles \" $odir/lt-$noexename.c\"\n\t    fi\n\t  fi\n\tfi\n\t;;\n      esac\n      func_show_eval \"$RM $rmfiles\" 'exit_status=1'\n    done\n\n    # Try to remove the $objdir's in the directories where we deleted files\n    for dir in $rmdirs; do\n      if test -d \"$dir\"; then\n\tfunc_show_eval \"rmdir $dir >/dev/null 2>&1\"\n      fi\n    done\n\n    exit $exit_status\n}\n\nif test uninstall = \"$opt_mode\" || test clean = \"$opt_mode\"; then\n  func_mode_uninstall ${1+\"$@\"}\nfi\n\ntest -z \"$opt_mode\" && {\n  help=$generic_help\n  func_fatal_help \"you must specify a MODE\"\n}\n\ntest -z \"$exec_cmd\" && \\\n  func_fatal_help \"invalid operation mode '$opt_mode'\"\n\nif test -n \"$exec_cmd\"; then\n  eval exec \"$exec_cmd\"\n  exit $EXIT_FAILURE\nfi\n\nexit $exit_status\n\n\n# The TAGs below are defined such that we never get into a situation\n# where we disable both kinds of libraries.  Given conflicting\n# choices, we go for a static library, that is the most portable,\n# since we can't tell whether shared libraries were disabled because\n# the user asked for that or because the platform doesn't support\n# them.  This is particularly important on AIX, because we don't\n# support having both static and shared libraries enabled at the same\n# time on that platform, so we default to a shared-only configuration.\n# If a disable-shared tag is given, we'll fallback to a static-only\n# configuration.  But we'll never go from static-only to shared-only.\n\n# ### BEGIN LIBTOOL TAG CONFIG: disable-shared\nbuild_libtool_libs=no\nbuild_old_libs=yes\n# ### END LIBTOOL TAG CONFIG: disable-shared\n\n# ### BEGIN LIBTOOL TAG CONFIG: disable-static\nbuild_old_libs=`case $build_libtool_libs in yes) echo no;; *) echo yes;; esac`\n# ### END LIBTOOL TAG CONFIG: disable-static\n\n# Local Variables:\n# mode:shell-script\n# sh-indentation:2\n# End:\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/auxdir/x_ac_dlfcn.m4": "# $NetBSD$\n\nAC_DEFUN([X_AC_DLFCN], [\n  AC_MSG_CHECKING([library containing dlopen])\n  AC_CHECK_LIB([], [dlopen], [ac_have_dlopen=yes; DL_LIBS=\"\"],\n    [AC_CHECK_LIB([dl], [dlopen], [ac_have_dlopen=yes; DL_LIBS=\"-ldl\"],\n      [AC_CHECK_LIB([svdl], [dlopen], [ac_have_dlopen=yes; DL_LIBS=\"-lsvdl\"])])])\n\n  AC_SUBST(DL_LIBS)\n])\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/contribs/pam_slurm_adopt/helper.c": "/*****************************************************************************\\\n *  pam_slurm_adopt/helper.c\n *****************************************************************************\n *  Useful portions extracted from pam_slurm.c by Ryan Cox <ryan_cox@byu.edu>\n *\n *  Copyright (C) 2002-2007 The Regents of the University of California.\n *  Copyright (C) 2008-2009 Lawrence Livermore National Security.\n *  Produced at Lawrence Livermore National Laboratory (cf, DISCLAIMER).\n *  UCRL-CODE-2002-040.\n *\n *  Written by Chris Dunlap <cdunlap@llnl.gov>\n *         and Jim Garlick  <garlick@llnl.gov>\n *         modified for SLURM by Moe Jette <jette@llnl.gov>.\n *\n *  This file is part of pam_slurm, a PAM module for restricting access to\n *  the compute nodes within a cluster based on information obtained from\n *  Simple Linux Utility for Resource Managment (SLURM).  For details, see\n *  <http://www.llnl.gov/linux/slurm/>.\n *\n *  pam_slurm is free software; you can redistribute it and/or modify it\n *  under the terms of the GNU General Public License as published by the\n *  Free Software Foundation; either version 2 of the License, or (at your\n *  option) any later version.\n *\n *  pam_slurm is distributed in the hope that it will be useful, but WITHOUT\n *  ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n *  FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n *  for more details.\n *\n *  You should have received a copy of the GNU General Public License along\n *  with pam_slurm; if not, write to the Free Software Foundation, Inc.,\n *  51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA.\n\\*****************************************************************************/\n\n#ifndef PAM_MODULE_NAME\n#  define PAM_MODULE_NAME \"pam_slurm_adopt\"\n#endif\n\n#if HAVE_CONFIG_H\n#  include \"config.h\"\n#endif\n\n#include <ctype.h>\n#include <errno.h>\n#include <pwd.h>\n#include <stdarg.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <sys/param.h>\n#include <sys/types.h>\n#include <syslog.h>\n#include <unistd.h>\n#include <dlfcn.h>\n\n#include \"slurm/slurm.h\"\n#include \"src/common/slurm_xlator.h\"\n\n/*  Define the externally visible functions in this file.\n */\n#define PAM_SM_ACCOUNT\n#include <security/pam_modules.h>\n#include <security/_pam_macros.h>\n\n\n/* Define the functions to be called before and after load since _init\n * and _fini are obsolete, and their use can lead to unpredicatable\n * results.\n */\nvoid __attribute__ ((constructor)) libpam_slurm_init(void);\nvoid __attribute__ ((destructor)) libpam_slurm_fini(void);\n\n/*\n *  Handle for libslurm.so\n *\n *  We open libslurm.so via dlopen () in order to pass the\n *   flag RTDL_GLOBAL so that subsequently loaded modules have\n *   access to libslurm symbols. This is pretty much only needed\n *   for dynamically loaded modules that would otherwise be\n *   linked against libslurm.\n *\n */\nstatic void * slurm_h = NULL;\n\n/* This function is necessary because libpam_slurm_init is called without access\n * to the pam handle.\n */\nstatic void\n_log_msg(int level, const char *format, ...)\n{\n\tva_list args;\n\n\topenlog(PAM_MODULE_NAME, LOG_CONS | LOG_PID, LOG_AUTHPRIV);\n\tva_start(args, format);\n\tvsyslog(level, format, args);\n\tva_end(args);\n\tcloselog();\n\treturn;\n}\n\n/*\n *  Sends a message to the application informing the user\n *  that access was denied due to SLURM.\n */\nextern void\nsend_user_msg(pam_handle_t *pamh, const char *mesg)\n{\n\tint retval;\n\tstruct pam_conv *conv;\n\tvoid *dummy;    /* needed to eliminate warning:\n\t\t\t * dereferencing type-punned pointer will\n\t\t\t * break strict-aliasing rules */\n\tchar str[PAM_MAX_MSG_SIZE];\n\tstruct pam_message msg[1];\n\tconst struct pam_message *pmsg[1];\n\tstruct pam_response *prsp;\n\n\tinfo(\"send_user_msg: %s\", mesg);\n\t/*  Get conversation function to talk with app.\n\t */\n\tretval = pam_get_item(pamh, PAM_CONV, (const void **) &dummy);\n\tconv = (struct pam_conv *) dummy;\n\tif (retval != PAM_SUCCESS) {\n\t\t_log_msg(LOG_ERR, \"unable to get pam_conv: %s\",\n\t\t\t pam_strerror(pamh, retval));\n\t\treturn;\n\t}\n\n\t/*  Construct msg to send to app.\n\t */\n\tmemcpy(str, mesg, sizeof(str));\n\tmsg[0].msg_style = PAM_ERROR_MSG;\n\tmsg[0].msg = str;\n\tpmsg[0] = &msg[0];\n\tprsp = NULL;\n\n\t/*  Send msg to app and free the (meaningless) rsp.\n\t */\n\tretval = conv->conv(1, pmsg, &prsp, conv->appdata_ptr);\n\tif (retval != PAM_SUCCESS)\n\t\t_log_msg(LOG_ERR, \"unable to converse with app: %s\",\n\t\t\t pam_strerror(pamh, retval));\n\tif (prsp != NULL)\n\t\t_pam_drop_reply(prsp, 1);\n\n\treturn;\n}\n\n/*\n * Dynamically open system's libslurm.so with RTLD_GLOBAL flag.\n * This allows subsequently loaded modules access to libslurm symbols.\n */\nextern void libpam_slurm_init (void)\n{\n\tchar libslurmname[64];\n\n\tif (slurm_h)\n\t\treturn;\n\n\t/* First try to use the same libslurm version (\"libslurm.so.24.0.0\"),\n\t * Second try to match the major version number (\"libslurm.so.24\"),\n\t * Otherwise use \"libslurm.so\" */\n\tif (snprintf(libslurmname, sizeof(libslurmname),\n\t\t\t\"libslurm.so.%d.%d.%d\", SLURM_API_CURRENT,\n\t\t\tSLURM_API_REVISION, SLURM_API_AGE) >=\n\t\t\t(signed) sizeof(libslurmname) ) {\n\t\t_log_msg (LOG_ERR, \"Unable to write libslurmname\\n\");\n\t} else if ((slurm_h = dlopen(libslurmname, RTLD_NOW|RTLD_GLOBAL))) {\n\t\treturn;\n\t} else {\n\t\t_log_msg (LOG_INFO, \"Unable to dlopen %s: %s\\n\",\n\t\t\tlibslurmname, dlerror ());\n\t}\n\n\tif (snprintf(libslurmname, sizeof(libslurmname), \"libslurm.so.%d\",\n\t\t\tSLURM_API_CURRENT) >= (signed) sizeof(libslurmname) ) {\n\t\t_log_msg (LOG_ERR, \"Unable to write libslurmname\\n\");\n\t} else if ((slurm_h = dlopen(libslurmname, RTLD_NOW|RTLD_GLOBAL))) {\n\t\treturn;\n\t} else {\n\t\t_log_msg (LOG_INFO, \"Unable to dlopen %s: %s\\n\",\n\t\t\tlibslurmname, dlerror ());\n\t}\n\n\tif (!(slurm_h = dlopen(\"libslurm.so\", RTLD_NOW|RTLD_GLOBAL))) {\n\t\t_log_msg (LOG_ERR, \"Unable to dlopen libslurm.so: %s\\n\",\n\t\t\t  dlerror ());\n\t}\n\n\treturn;\n}\n\nextern void libpam_slurm_fini (void)\n{\n\tif (slurm_h)\n\t\tdlclose (slurm_h);\n\treturn;\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/contribs/pam/pam_slurm.c": "/*****************************************************************************\\\n *  pam_slurm.c\n *****************************************************************************\n *  Copyright (C) 2002-2007 The Regents of the University of California.\n *  Copyright (C) 2008-2009 Lawrence Livermore National Security.\n *  Produced at Lawrence Livermore National Laboratory (cf, DISCLAIMER).\n *  UCRL-CODE-2002-040.\n *\n *  Written by Chris Dunlap <cdunlap@llnl.gov>\n *         and Jim Garlick  <garlick@llnl.gov>\n *         modified for SLURM by Moe Jette <jette@llnl.gov>.\n *\n *  This file is part of pam_slurm, a PAM module for restricting access to\n *  the compute nodes within a cluster based on information obtained from\n *  Simple Linux Utility for Resource Managment (SLURM).  For details, see\n *  <http://www.llnl.gov/linux/slurm/>.\n *\n *  pam_slurm is free software; you can redistribute it and/or modify it\n *  under the terms of the GNU General Public License as published by the\n *  Free Software Foundation; either version 2 of the License, or (at your\n *  option) any later version.\n *\n *  pam_slurm is distributed in the hope that it will be useful, but WITHOUT\n *  ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n *  FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n *  for more details.\n *\n *  You should have received a copy of the GNU General Public License along\n *  with pam_slurm; if not, write to the Free Software Foundation, Inc.,\n *  51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA.\n\\*****************************************************************************/\n\n#if HAVE_CONFIG_H\n#  include \"config.h\"\n#endif\n\n#include <ctype.h>\n#include <errno.h>\n#include <pwd.h>\n#include <stdarg.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <sys/param.h>\n#include <sys/stat.h>\n#include <sys/types.h>\n#include <syslog.h>\n#include <unistd.h>\n#include <dlfcn.h>\n\n#include \"slurm/slurm.h\"\n#include \"src/common/xmalloc.h\"\n#include \"src/common/read_config.h\"\n\n/*  Define the externally visible functions in this file.\n */\n#define PAM_SM_ACCOUNT\n#include <security/pam_modules.h>\n#include <security/_pam_macros.h>\n\n\nstruct _options {\n\tint disable_sys_info;\n\tint enable_debug;\n\tint enable_silence;\n\tconst char *msg_prefix;\n\tconst char *msg_suffix;\n};\n\n/* Define the functions to be called before and after load since _init\n * and _fini are obsolete, and their use can lead to unpredicatable\n * results.\n */\nvoid __attribute__ ((constructor)) libpam_slurm_init(void);\nvoid __attribute__ ((destructor)) libpam_slurm_fini(void);\n\n/*\n *  Handle for libslurm.so\n *\n *  We open libslurm.so via dlopen () in order to pass the\n *   flag RTDL_GLOBAL so that subsequently loaded modules have\n *   access to libslurm symbols. This is pretty much only needed\n *   for dynamically loaded modules that would otherwise be\n *   linked against libslurm.\n *\n */\nstatic void * slurm_h = NULL;\nstatic int    pam_debug   = 0;\n\nstatic void _log_msg(int level, const char *format, ...);\nstatic void _parse_args(struct _options *opts, int argc, const char **argv);\nstatic int  _hostrange_member(char *hostname, char *str);\nstatic int  _slurm_match_allocation(uid_t uid);\nstatic void _send_denial_msg(pam_handle_t *pamh, struct _options *opts,\n\t\t\t     const char *user, uid_t uid);\n\n#define DBG(msg,args...)\t\t\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\\\n\t\tif (pam_debug)\t\t\t\t\t\\\n\t\t\t_log_msg(LOG_INFO, msg, ##args);\t\\\n\t} while (0);\n\n/**********************************\\\n *  Account Management Functions  *\n\\**********************************/\n\nPAM_EXTERN int\npam_sm_acct_mgmt(pam_handle_t *pamh, int flags, int argc, const char **argv)\n{\n\tstruct _options opts;\n\tint retval;\n\tchar *user;\n\tvoid *dummy;  /* needed to eliminate warning:\n\t\t       * dereferencing type-punned pointer will break\n\t\t       * strict-aliasing rules */\n\tstruct passwd *pw;\n\tuid_t uid;\n\tint auth = PAM_PERM_DENIED;\n\n\t_parse_args(&opts, argc, argv);\n\tif (flags & PAM_SILENT)\n\t\topts.enable_silence = 1;\n\n\tretval = pam_get_item(pamh, PAM_USER, (const void **) &dummy);\n\tuser = (char *) dummy;\n\tif ((retval != PAM_SUCCESS) || (user == NULL) || (*user == '\\0')) {\n\t\t_log_msg(LOG_ERR, \"unable to identify user: %s\",\n\t\t\t pam_strerror(pamh, retval));\n\t\treturn(PAM_USER_UNKNOWN);\n\t}\n\tif (!(pw = getpwnam(user))) {\n\t\t_log_msg(LOG_ERR, \"user %s does not exist\", user);\n\t\treturn(PAM_USER_UNKNOWN);\n\t}\n\tuid = pw->pw_uid;\n\n\tif (uid == 0)\n\t\tauth = PAM_SUCCESS;\n\telse if (_slurm_match_allocation(uid))\n\t\tauth = PAM_SUCCESS;\n\n\tif ((auth != PAM_SUCCESS) && (!opts.enable_silence))\n\t\t_send_denial_msg(pamh, &opts, user, uid);\n\n\t/*\n\t *  Generate an entry to the system log if access was\n\t *   denied (!PAM_SUCCESS) or disable_sys_info is not set\n\t */\n\tif ((auth != PAM_SUCCESS) || (!opts.disable_sys_info)) {\n\t\t_log_msg(LOG_INFO, \"access %s for user %s (uid=%d)\",\n\t\t\t (auth == PAM_SUCCESS) ? \"granted\" : \"denied\",\n\t\t\t user, uid);\n\t}\n\n\treturn(auth);\n}\n\n\n/************************\\\n *  Internal Functions  *\n\\************************/\n\n/*\n *  Writes message described by the 'format' string to syslog.\n */\nstatic void\n_log_msg(int level, const char *format, ...)\n{\n\tva_list args;\n\n\topenlog(\"pam_slurm\", LOG_CONS | LOG_PID, LOG_AUTHPRIV);\n\tva_start(args, format);\n\tvsyslog(level, format, args);\n\tva_end(args);\n\tcloselog();\n\treturn;\n}\n\n/*\n *  Parses module args passed via PAM's config.\n */\nstatic void\n_parse_args(struct _options *opts, int argc, const char **argv)\n{\n\tint i;\n\n\topts->disable_sys_info = 0;\n\topts->enable_debug = 0;\n\topts->enable_silence = 0;\n\topts->msg_prefix = \"\";\n\topts->msg_suffix = \"\";\n\n\t/*  rsh_kludge:\n\t *  The rsh service under RH71 (rsh-0.17-2.5) truncates the first char\n\t *  of this msg.  The rsh client sends 3 NUL-terminated ASCII strings:\n\t *  client-user-name, server-user-name, and command string.  The server\n\t *  then validates the user.  If the user is valid, it responds with a\n\t *  1-byte zero; o/w, it responds with a 1-byte one followed by an ASCII\n\t *  error message and a newline.  RH's server is using the default PAM\n\t *  conversation function which doesn't prepend the message with a\n\t *  single-byte error code.  As a result, the client receives a string,\n\t *  interprets the first byte as a non-zero status, and treats the\n\t *  remaining string as an error message.  The rsh_kludge prepends a\n\t *  newline which will be interpreted by the rsh client as an\n\t *  error status.\n\t *\n\t *  rlogin_kludge:\n\t *  The rlogin service under RH71 (rsh-0.17-2.5) does not perform a\n\t *  carriage-return after the PAM error message is displayed\n\t *  which results\n\t *  in the \"staircase-effect\" of the next message. The rlogin_kludge\n\t *  appends a carriage-return to prevent this.\n\t */\n\tfor (i=0; i<argc; i++) {\n\t\tif (!strcmp(argv[i], \"debug\"))\n\t\t\topts->enable_debug = pam_debug = 1;\n\t\telse if (!strcmp(argv[i], \"no_sys_info\"))\n\t\t\topts->disable_sys_info = 1;\n\t\telse if (!strcmp(argv[i], \"no_warn\"))\n\t\t\topts->enable_silence = 1;\n\t\telse if (!strcmp(argv[i], \"rsh_kludge\"))\n\t\t\topts->msg_prefix = \"\\n\";\n\t\telse if (!strcmp(argv[i], \"rlogin_kludge\"))\n\t\t\topts->msg_suffix = \"\\r\";\n\t\telse\n\t\t\t_log_msg(LOG_ERR, \"unknown option [%s]\", argv[i]);\n\t}\n\treturn;\n}\n\n/*\n *  Return 1 if 'hostname' is a member of 'str', a SLURM-style host list as\n *  returned by SLURM database queries, else 0.  The 'str' argument is\n *  truncated to the base prefix as a side-effect.\n */\nstatic int\n_hostrange_member(char *hostname, char *str)\n{\n\thostlist_t hl;\n\tint found_host;\n\n\tif (!*hostname || !*str)\n\t\treturn 0;\n\n\tif ((hl = slurm_hostlist_create(str)) == NULL)\n\t\treturn 0;\n\tfound_host = slurm_hostlist_find(hl, hostname);\n\tslurm_hostlist_destroy(hl);\n\n\tif (found_host == -1)\n\t\treturn 0;\n\telse\n\t\treturn 1;\n}\n\n/* _gethostname_short - equivalent to gethostname, but return only the first\n * component of the fully qualified name\n * (e.g. \"linux123.foo.bar\" becomes \"linux123\")\n *\n * Copied from src/common/read_config.c because it is not exported\n * through libslurm.\n *\n * OUT name\n */\nstatic int\n_gethostname_short (char *name, size_t len)\n{\n\tint error_code, name_len;\n\tchar *dot_ptr, path_name[1024];\n\n\terror_code = gethostname(path_name, sizeof(path_name));\n\tif (error_code)\n\t\treturn error_code;\n\n\tdot_ptr = strchr (path_name, '.');\n\tif (dot_ptr == NULL)\n\t\tdot_ptr = path_name + strlen(path_name);\n\telse\n\t\tdot_ptr[0] = '\\0';\n\n\tname_len = (dot_ptr - path_name);\n\tif (name_len > len)\n\t\treturn ENAMETOOLONG;\n\n\tstrcpy(name, path_name);\n\treturn 0;\n}\n\n\n/*\n *  Query the SLURM database to find out if 'uid' has been allocated\n *  this node. If so, return 1 indicating that 'uid' is authorized to\n *  this node else return 0.\n */\nstatic int\n_slurm_match_allocation(uid_t uid)\n{\n\tint authorized = 0, i;\n\tchar hostname[MAXHOSTNAMELEN];\n\tchar *nodename = NULL;\n\tjob_info_msg_t * msg;\n\n\tif (_gethostname_short(hostname, sizeof(hostname)) < 0) {\n\t\t_log_msg(LOG_ERR, \"gethostname: %m\");\n\t\treturn 0;\n\t}\n\n\tif (!(nodename = slurm_conf_get_nodename(hostname))) {\n\t\tif (!(nodename = slurm_conf_get_aliased_nodename())) {\n\t\t\t/* if no match, try localhost (Should only be\n\t\t\t * valid in a test environment) */\n\t\t\tif (!(nodename =\n\t\t\t      slurm_conf_get_nodename(\"localhost\"))) {\n\t\t\t\t_log_msg(LOG_ERR,\n\t\t\t\t\t \"slurm_conf_get_aliased_nodename: \"\n\t\t\t\t\t \"no hostname found\");\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t}\n\t}\n\n\tDBG (\"does uid %ld have \\\"%s\\\" allocated?\", uid, nodename);\n\n\tif (slurm_load_job_user(&msg, uid, SHOW_ALL) < 0) {\n\t\t_log_msg(LOG_ERR, \"slurm_load_job_user: %s\",\n\t\t\t slurm_strerror(errno));\n\t\treturn 0;\n\t}\n\n\tDBG (\"slurm_load_jobs returned %d records\", msg->record_count);\n\n\tfor (i = 0; i < msg->record_count; i++) {\n\t\tjob_info_t *j = &msg->job_array[i];\n\n\t\tif (j->job_state == JOB_RUNNING) {\n\n\t\t\tDBG (\"jobid %ld: nodes=\\\"%s\\\"\", j->job_id, j->nodes);\n\n\t\t\tif (_hostrange_member(nodename, j->nodes) ) {\n\t\t\t\tDBG (\"user %ld allocated node %s in job %ld\",\n\t\t\t\t     uid, nodename, j->job_id);\n\t\t\t\tauthorized = 1;\n\t\t\t\tbreak;\n\t\t\t} else {\n\t\t\t\tchar *nodename;\n\t\t\t\tnodename = slurm_conf_get_nodename(hostname);\n\t\t\t\tif (nodename) {\n\t\t\t\t\tif (_hostrange_member(nodename,\n\t\t\t\t\t\t\t      j->nodes)) {\n\t\t\t\t\t\tDBG (\"user %ld allocated node %s in job %ld\",\n\t\t\t\t\t\t     uid, nodename, j->job_id);\n\t\t\t\t\t\tauthorized = 1;\n\t\t\t\t\t\txfree(nodename);\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\txfree(nodename);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\txfree(nodename);\n\tslurm_free_job_info_msg (msg);\n\n\treturn authorized;\n}\n\n/*\n *  Sends a message to the application informing the user\n *  that access was denied due to SLURM.\n */\nstatic void\n_send_denial_msg(pam_handle_t *pamh, struct _options *opts,\n\t\t const char *user, uid_t uid)\n{\n\tint retval;\n\tstruct pam_conv *conv;\n\tvoid *dummy;    /* needed to eliminate warning:\n\t\t\t * dereferencing type-punned pointer will\n\t\t\t * break strict-aliasing rules */\n\tint n;\n\tchar str[PAM_MAX_MSG_SIZE];\n\tstruct pam_message msg[1];\n\tconst struct pam_message *pmsg[1];\n\tstruct pam_response *prsp;\n\n\t/*  Get conversation function to talk with app.\n\t */\n\tretval = pam_get_item(pamh, PAM_CONV, (const void **) &dummy);\n\tconv = (struct pam_conv *) dummy;\n\tif (retval != PAM_SUCCESS) {\n\t\t_log_msg(LOG_ERR, \"unable to get pam_conv: %s\",\n\t\t\t pam_strerror(pamh, retval));\n\t\treturn;\n\t}\n\n\t/*  Construct msg to send to app.\n\t */\n\tn = snprintf(str, sizeof(str),\n\t\t     \"%sAccess denied: user %s (uid=%d) has no active jobs on this node.%s\",\n\t\t     opts->msg_prefix, user, uid, opts->msg_suffix);\n\tif ((n < 0) || (n >= sizeof(str)))\n\t\t_log_msg(LOG_ERR, \"exceeded buffer for pam_conv message\");\n\tmsg[0].msg_style = PAM_ERROR_MSG;\n\tmsg[0].msg = str;\n\tpmsg[0] = &msg[0];\n\tprsp = NULL;\n\n\t/*  Send msg to app and free the (meaningless) rsp.\n\t */\n\tretval = conv->conv(1, pmsg, &prsp, conv->appdata_ptr);\n\tif (retval != PAM_SUCCESS)\n\t\t_log_msg(LOG_ERR, \"unable to converse with app: %s\",\n\t\t\t pam_strerror(pamh, retval));\n\tif (prsp != NULL)\n\t\t_pam_drop_reply(prsp, 1);\n\n\treturn;\n}\n\n/*\n * Dynamically open system's libslurm.so with RTLD_GLOBAL flag.\n *  This allows subsequently loaded modules access to libslurm symbols.\n */\nextern void libpam_slurm_init (void)\n{\n\tchar libslurmname[64];\n\n\tif (slurm_h)\n\t\treturn;\n\n\t/* First try to use the same libslurm version (\"libslurm.so.24.0.0\"),\n\t * Second try to match the major version number (\"libslurm.so.24\"),\n\t * Otherwise use \"libslurm.so\" */\n\tif (snprintf(libslurmname, sizeof(libslurmname),\n\t\t\t\"libslurm.so.%d.%d.%d\", SLURM_API_CURRENT,\n\t\t\tSLURM_API_REVISION, SLURM_API_AGE) >=\n\t\t\tsizeof(libslurmname) ) {\n\t\t_log_msg (LOG_ERR, \"Unable to write libslurmname\\n\");\n\t} else if ((slurm_h = dlopen(libslurmname, RTLD_NOW|RTLD_GLOBAL))) {\n\t\treturn;\n\t} else {\n\t\t_log_msg (LOG_INFO, \"Unable to dlopen %s: %s\\n\",\n\t\t\tlibslurmname, dlerror ());\n\t}\n\n\tif (snprintf(libslurmname, sizeof(libslurmname), \"libslurm.so.%d\",\n\t\t\tSLURM_API_CURRENT) >= sizeof(libslurmname) ) {\n\t\t_log_msg (LOG_ERR, \"Unable to write libslurmname\\n\");\n\t} else if ((slurm_h = dlopen(libslurmname, RTLD_NOW|RTLD_GLOBAL))) {\n\t\treturn;\n\t} else {\n\t\t_log_msg (LOG_INFO, \"Unable to dlopen %s: %s\\n\",\n\t\t\tlibslurmname, dlerror ());\n\t}\n\n\tif (!(slurm_h = dlopen(\"libslurm.so\", RTLD_NOW|RTLD_GLOBAL))) {\n\t\t_log_msg (LOG_ERR, \"Unable to dlopen libslurm.so: %s\\n\",\n \t\t\t  dlerror ());\n\t}\n\n\treturn;\n}\n\nextern void libpam_slurm_fini (void)\n{\n \tif (slurm_h)\n\t\tdlclose (slurm_h);\n\treturn;\n}\n\n\n/*************************************\\\n *  Statically Loaded Module Struct  *\n\\*************************************/\n\n#ifdef PAM_STATIC\nstruct pam_module _pam_rms_modstruct = {\n\t\"pam_slurm\",\n\tNULL,\n\tNULL,\n\tpam_sm_acct_mgmt,\n\tNULL,\n\tNULL,\n\tNULL,\n};\n#endif /* PAM_STATIC */\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/preemption_plugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Slurm Preemption Plugin API</a></h1>\n\n<h2> Overview</h2>\n<p> This document describes Slurm preemption plugins and the API that defines\nthem. It is intended as a resource to programmers wishing to write their own\nSlurm preemption plugins.</p>\n\n<p>Slurm preemption plugins are Slurm plugins that identify which jobs\ncan be preempted by a pending job. They must conform to the Slurm Plugin\nAPI with the following specifications:</p>\n\n<p><span class=\"commandline\">const char\nplugin_type[]=\"<i>major/minor</i>\"</span><br>\nThe major type must be &quot;preempt.&quot; The minor type can be any\nrecognizable abbreviation for the type of preemption.\nWe recommend, for example:</p>\n\n<ul>\n<li><b>none</b> &mdash; This plugin prevents any job preemption.</li>\n<li><b>partition_prio</b> &mdash; This plugin permit pending jobs from one\npartition to preempt jobs from a lower priority partition.</li>\n<li><b>qos</b> &mdash; This plugin permits jobs to preempt others based\nupon their Quality Of Service values as defined in the Slurm database.</li>\n</ul>\n\n<p><span class=\"commandline\">const char plugin_name[]</span><br>\nSome descriptive name for the plugin.\nThere is no requirement with respect to its format.</p>\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loadeed by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<p>The programmer is urged to study\n<span class=\"commandline\">src/plugins/preempt/partition_prio/preempt_partition_prio.c</span>\nfor an example implementation of a Slurm preemption plugin.</p>\n\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<h2>API Functions</h2>\n<p>The following functions must appear. Functions which are not implemented\nshould be stubbed.</p>\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\">List find_preemptable_jobs(\nstruct job_record *job_ptr)</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Identifies the jobs\nwhich can be preempted by a specific pending job.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\">job_ptr</span> (input) a pointer to the\npending job which is attempting to be started</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: A list of pointers to\njobs which may be preempted.\nThe list should be be released using the <i>list_destroy</i> function when\nno longer required.\nThis list should be sorted in order from most attractive to\npreempt to least attractive to preempt (e.g. lowest to highest priority).\nFor example, even within a given partition or QOS one might want to\nsmaller jobs first.</p>\n\n<p class=\"commandline\">uint16_t job_preempt_mode(\nstruct job_record *job_ptr)</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Identifies the mechanism\nused to preempt the specified job.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\">job_ptr</span> (input) a pointer to the\nrunning job to be preempted</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: PREEMPT_MODE as defined in\nthe slurm/slurm.h file</p>\n\n<p class=\"commandline\">bool preemption_enabled(void)</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Report whether or not job\npreemption is enabled.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: true if running jobs may be\npreempted, otherwise false</p>\n\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<p style=\"text-align:center;\">Last modified 27 March 2015</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/acct_gather_profile_plugins.shtml": "<!--#include virtual=\"header.txt\"-->\n<!--  Copyright (C) 2013 Bull S. A. S.\n      Bull, Rue Jean Jaures, B.P.68, 78340, Les Clayes-sous-Bois. -->\n\n<h1><a name=\"top\">Slurm Profile Accounting Plugin API (AcctGatherProfileType)\n</a></h1>\n\n<h2> Overview</h2>\n<p> This document describes Slurm profile accounting plugins and the API that\ndefines them. It is intended as a resource to programmers wishing to write\ntheir own Slurm profile accounting plugins.\n\n<p>A profiling plugin allows more detailed information on the execution of jobs\nthan can reasonably be kept in the accounting database. (All jobs may also not\nbe profiled.)\n\nA seperate\n<a href=\"hdf5_profile_user_guide.html\">User Guide</a> documents how to use\nthe hdf5 version of the plugin.\n\n<p>The plugin provides an API for making calls to store data at various\npoints in a step's lifecycle. It collects data periodically from potentially\nseveral sources. The periodic samples are eventually\nconsolidated into one <i>time series</i> dataset for each node of a job.\n\n<p>The plugin's primary work is done within slurmstepd on the compute nodes.\nIt assumes a shared file system, presumably on the management network. This\navoids having to transfer files back to the controller at step end. Data is\ntypically gathered at job_acct_gather interval or acct_gather_energy interval\nand the volume is not expected to be burdensome.\n\n<p>The <i>hdf5</i> implementation records I/O counts from the\nnetwork interface (Interconnect), I/O counts from the node from the Lustre\nparallel file system, disk I/O counts, cpu and memory utilization\nfor each task, and a record of energy use.\n\n<p>This implementation stores this data in a HDF5 file for each step\non each node for the jobs. A separate program\n(<a href=\"sh5util.html\">sh5util</a>) is provided to\nconsolidate all the node-step files in one container for the job.\nHDF5 is a well known structured data set that allows different types of\nrelated data to be stored in one file. Its internal structure resembles a\nfile system with <i>groups</i> being similar to <i>directories</i> and\n<i>data sets</i> being similar to <i>files</i>. There are commodity programs,\nnotably <b>HDF5View</b> for viewing and manipulating these files.\n<b>sh5util</b> also provides some capability for extracting subsets of date\nfor import into other analysis tools like spreadsheets.\n\n<p>This plugin is incompatible with --enable-front-end. It you need to\nsimulate a large configuration, please use --enable-multiple-slurmd.\n<p>Slurm profile accounting plugins must conform to the Slurm Plugin API with\nthe following specifications:\n<p><span class=\"commandline\">const char\nplugin_name[]=\"<i>full&nbsp;text&nbsp;name</i>\"</span>\n<p style=\"margin-left:.2in\">\nA free-formatted ASCII text string that identifies the plugin.\n\n<p><span class=\"commandline\">const char\nplugin_type[]=\"<i>major/minor</i>\"</span><br>\n<p style=\"margin-left:.2in\">\nThe major type must be &quot;acct_gather_profile.&quot;\nThe minor type can be any suitable name\nfor the type of profile accounting. We currently use\n<ul>\n<li><b>none</b> &mdash; No profile data is gathered.\n<li><b>hdf5</b> &mdash; Gets profile data about energy use, i/o sources\n(Lustre, network) and task data such as local disk i/o,  CPU and memory usage.\n</ul>\n\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loadeed by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<p>The programmer is urged to study\n<span class=\"commandline\">\nsrc/plugins/acct_gather_profile/acct_gather_profile_hdf5.c</span> and\n<span class=\"commandline\">src/common/slurm_acct_gather_profile.c</span>\nfor a sample implementation of a Slurm profile accounting plugin.\n<p class=\"footer\"><a href=\"#top\">top</a>\n\n<h2>API Functions</h2>\n<p>All of the following functions are required. Functions which are not\nimplemented must be stubbed.\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the SLURM\n<span class=\"commandline\">init()</span>, and the SLURM\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\">\nvoid acct_gather_profile_g_conf_options(void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nCalled from slurmstepd between fork() and exec() of application.\nClose open files<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nvoid acct_gather_profile_g_conf_options(s_p_options_t **full_options,\nint *full_options_cnt)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nDefines configuration options in acct_gather.conf<br>\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">full(out) option definitions.</span>\n<span class=\"commandline\">full_options_cnt(out) number in full.</span>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nvoid acct_gather_profile_g_conf_set(s_p_hashtbl_t *tbl)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nSet configuration options from acct_gather.conf<br>\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">tbl -- hash table of options./span>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nvoid acct_gather_profile_g_conf_get(s_p_hashtbl_t *tbl)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nGets configuration options from acct_gather.conf<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">void* pointer to slurm_acct_gather_conf_t</span>\n on success, or<br> <span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nint acct_gather_profile_p_node_step_start(stepd_step_rec_t* job)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nCalled once per step on each node from slurmstepd, before launching tasks.\n<br />\nProvides an opportunity to create files and other node-step level\ninitialization.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job -- slumd_job_t structure containing information\nabout the step. </span>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint acct_gather_profile_p_node_step_end(stepd_step_rec_t* job)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nCalled once per step on each node from slurmstepd, after all tasks end.\n<br />\nProvides an opportunity to close files, etc.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job -- slumd_job_t structure containing information\nabout the step. </span>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint acct_gather_profile_p_task_start(stepd_step_rec_t* job, uint32_t taskid)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nCalled once per task from slurmstepd, BEFORE node step start is called.\n<br />\nProvides an opportunity to gather beginning values from node counters\n(bytes_read ...)\n<br />\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job -- slumd_job_t structure containing information\nabout the step. </span>\n<br /><span class=\"commandline\">taskid -- Slurm taskid. </span>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint acct_gather_profile_p_task_end(stepd_step_rec_t* job, pid_t taskpid)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nCalled once per task from slurmstepd.\n<br />\nProvides an opportunity to put final data for a task.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job -- slumd_job_t structure containing information\nabout the step. </span>\n<br /><span class=\"commandline\">pid -- task process id (pid_t). </span>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint acct_gather_profile_p_add_sample_data(uint32_t type, void* data);\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nPut data at the Node Samples level. Typically called from something called\nat either job_acct_gather interval or acct_gather_energy interval.\n<br />\nAll samples in the same group will eventually be consolidated in one\ntime series.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<br /><span class=\"commandline\">type -- identifies the type of data. </span>\n<br /><span class=\"commandline\">data -- data structure to be put to the file.\n</span>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<h2>Parameters</h2>\n\n<p>These parameters can be used in the slurm.conf to configure the\nplugin and the frequency at which to gather node profile data.</p>\n<dl>\n<dt><span class=\"commandline\">AcctGatherProfileType</span>\n<dd>Specifies which plugin should be used.\n</dl>\n\n<p>The <a href=\"acct_gather.conf.html\">acct_gather.conf</a> provides profile\nconfiguration options.\n<dl>\n<dt><span class=\"commandline\">ProfileDir</span>\n<dd>Path to location in a shared file system in which to write profile data.\nThere is no default as there is no standard location for a shared file system.\nIt this parameter is not specified, no profiling will occur.\n<dt><span class=\"commandline\">ProfileDefaultProfile</span>\n<dd>Default setting for --profile command line option for srun, salloc, sbatch.\n</dl>\n<p>The default profile value is <b>none</b> which means no profiling will be done\nfor jobs. The hdf5 plugin also includes;</p>\n<ul>\n<li>\n<b>energy</b> sample energy use for the node.\n</li>\n<li>\n<b>lustre</b> sample i/o to the Lustre file system for the node.\n</li>\n<li>\n<b>network</b> sample i/o through the network (interconnect) interface\nfor the node.\n</li>\n<li>\n<b>task</b> sample local disk I/O, cpu  and memory use for each task.\n</li>\n<li>\n<b>all</b> all of the above.\n</li>\n</ul>\n<p>Use caution when setting the default to values other than none as a file for\neach job will be created. This option is provided for test systems.</p>\n\n<p>Most of the sources of profile data are associated with various\nacct_gather plugins. The acct_gather.conf file has setting for various\nsampling mechanisms that can be used to change the frequency at which\nsamples occur.</p>\n\n<h2>Data Types</h2>\n<p>A plugin-like structure is implemented to generalize HDF5 data operations from\nvarious sources. A <i>C</i> <b>typedef</b> is defined for each datatype. These\ndeclarations are in /common/slurm_acct_gather_profile.h so the datatype are\ncommon to all profile plugins.</p>\n\n<p>The operations are defined via structures of function pointers, and they are\ndefined in /plugins/acct_gather_profile/common/profile_hdf5.h and should work\non any HDF5 implementation, not only hdf5.</p>\n\n<p>Functions must be implemented to perform various operations for the datatype.\nThe api for the plugin includes an argument for the datatype so that the\nimplementation of that api can call the specific operation for that datatype.</p>\n\n<p>Groups in the HDF5 file containing a dataset will include an attribute for\nthe datatype so that the program that merges step files into the job can\ndiscover the type of the group and do the right thing.</p>\n\n<p>For example, the typedef for the energy sample datatype;</p>\n<pre>\ntypedef struct profile_energy {\n    char     tod[TOD_LEN];\t// Not used in node-step\n    time_t   time;\n    uint64_t watts;\n    uint64_t cpu_freq;\n} profile_energy_t;\n</pre>\n<p>\nA <i>factory</i> method is implemented for each type to construct a structure\nwith functions implementing various operations for the type.\nThe following structure of functions is required for each type.\n<pre>\n/*\n * Structure of function pointers of common operations on a\n * profile data type. (Some may be stubs, particularly if the data type\n * does not represent a time series.\n *\tdataset_size -- size of one dataset (structure size).\n *      create_memory_datatype -- creates hdf5 memory datatype\n *          corresponding to the datatype structure.\n *      create_file_datatype -- creates hdf5 file datatype\n *          corresponding to the datatype structure.\n *      create_s_memory_datatype -- creates hdf5 memory datatype\n *          corresponding to the summary datatype structure.\n *      create_s_file_datatype -- creates hdf5 file datatype\n *          corresponding to the summary datatype structure.\n *      init_job_series -- allocates a buffer for a complete time\n *          series (in job merge) and initializes each member\n *      merge_step_series -- merges all the individual time samples\n *          into a single data set with one item per sample.\n *          Data items can be scaled (e.g. subtracting beginning time)\n *          differenced (to show counts in interval) or other things\n *          appropriate for the series.\n *      series_total -- accumulate or average members in the entire\n *          series to be added to the file as totals for the node or\n *          task.\n *      extract_series -- format members of a structure for putting\n *          to a file data extracted from a time series to be imported into\n *          another analysis tool. (e.g. format as comma separated value.)\n *      extract_totals -- format members of a structure for putting\n *          to a file data extracted from a time series total to be imported\n *          into another analysis tool. (e.g. format as comma,separated value.)\n */\ntypedef struct profile_hdf5_ops {\n    int   (*dataset_size) ();\n    hid_t (*create_memory_datatype) ();\n    hid_t (*create_file_datatype) ();\n    hid_t (*create_s_memory_datatype) ();\n    hid_t (*create_s_file_datatype) ();\n    void* (*init_job_series) (int, int);\n    void  (*merge_step_series) (hid_t, void*, void*, void*);\n    void* (*series_total) (int, void*);\n    void  (*extract_series) (FILE*, bool, int, int, char*,\n\t\t\t\t       char*, void*);\n    void  (*extract_totals) (FILE*, bool, int, int, char*,\n\t\t\t\t       char*, void*);\n} profile_hdf5_ops_t;\n</pre>\n\n<p>Note there are two different data types for supporting time series.<br>\n1) A primary type is defined for gathering data in the node step file.\nIt is typically named profile_{series_name}_t.<br>\n2) Another type is defined for summarizing series totals.\nIt is typically named profile_{series_name}_s_t. It does not have a 'factory'.\nIt is only used in the functions of the primary data type and the\nprimaries structure has operations to create appropriate hdf5 objects.</p>\n\n<p>When adding a new type, the <b>profile_factory</b> function has to be\nmodified to return an <i>ops</i> for the type.</p>\n\n<p>Interaction between type and hdf5.</p>\n<ul>\n<li>\nThe profile_{type}_t structure is used by callers of the <b>add_sample_data</b>\nfunctions.\n</li>\n<li>\nHDF5 needs a <b>memory</b>_datatype to transform this structure into its\ndataset object in memory. The <i>create_memory_datatype</i> function creates\nthe appropriate object.\n</li>\n<li>\nHDF5 needs a <b>file</b>_datatype to transform the dataset into how it will be\nwritten to the HDF5 file (or to transform what it reads from a file into a\ndataset.) The <i>create_file_datatype</i> function creates\nthe appropriate object.\n</li>\n</ul>\n\n<p class=\"footer\"><a href=\"#top\">top</a>\n\n<p style=\"text-align:center;\">Last modified 27 March 2015</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/mcs_plugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Multi-Category Security (MCS) Plugin Programmer Guide\n</a></h1>\n\n<h2> Overview</h2>\n<p> This document describes Slurm's MCS plugins and the API that\ndefines them. It is intended as a resource to programmers wishing to write\ntheir own Slurm MCS plugins.\n\n<p>Slurm MCS plugins must conform to the\nSlurm Plugin API with the following specifications:\n\n<p><span class=\"commandline\">const char\nplugin_name[]=\"<i>full&nbsp;text&nbsp;name</i>\"</span>\n<p style=\"margin-left:.2in\">\nA free-formatted ASCII text string that identifies the plugin.\n\n<p><span class=\"commandline\">const char\nplugin_type[]=\"<i>major/minor</i>\"</span><br>\n<p style=\"margin-left:.2in\">\nThe major type must be &quot;mcs.&quot;\nThe minor type can be any suitable name\nfor the MCS. We recommend, for example :\n<ul>\n<li><b>account</b> &mdash; Use user account as the category to associate jobs to.\n<li><b>none</b> &mdash; Default. No category associated to jobs.\n<li><b>user</b> &mdash; Use user name as the category to associate jobs to.\n<li><b>group</b> &mdash; Use a user group as the category to associate jobs to.\n</ul>\n\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\n<p style=\"margin-left:.2in\">\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loaded by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<p>The programmer is urged to study\n<span class=\"commandline\">src/plugins/mcs/group</span> and\n<span class=\"commandline\">src/common/slurm_mcs.c</span>\nfor an example implementation of a Slurm MCS plugin.\n<p class=\"footer\"><a href=\"#top\">top</a>\n\n<h2>API Functions</h2>\n<p>All of the following functions are required. Functions which are not\nimplemented must be stubbed.\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the SLURM\n<span class=\"commandline\">init()</span>, and the SLURM\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\">int mcs_p_set_mcs_label(struct job_record *job_ptr, char* label)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nVerify and set or calculate MCS_label for a job.<br>\nCalled by _job_create to get the mcs_label for a job.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\"> job_ptr  </span>  (input/output) pointer to the slurmctld job\nstructure. This can be used to get user_id and group_id.\nAssign MCS_label if possible.<br>\n<span class=\"commandline\"> label </span>    (input) pointer to requested label or NULL if not specified.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS </span> on success, or\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">int mcs_p_check_mcs_label(uint32_t user_id, char *mcs_label)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nFor command squeue/scontrol show nodes in case of option private. Check the compatibility between\nMCS_label of user and MCS_label of jobs/nodes.<br>\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">user_id, mcs_label (input).\n</span>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<h2>Parameters</h2>\n<p>These parameters can be used in the slurm.conf to configure the plugin.</p>\n<dl>\n<dt><span class=\"commandline\">MCSPlugin</span>\n<dd>Specifies which plugin should be used.\n<dt><span class=\"commandline\">MCSParameters</span>\n<dd>If MCSPlugin!=mcs/none, specifies options\n\n<p class=\"footer\"><a href=\"#top\">top</a>\n\n<p style=\"text-align:center;\">Last modified 12 October 2015</p>\n\n<!--#include virtual=\"footer.txt\"-->\n\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/core_spec_plugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Core Specialization Plugin Programmer Guide</a></h1>\n\n<h2> Overview</h2>\n<p> This document describes the Slurm core specialization plugins and the APIs\nthat defines them. It is intended as a resource to programmers wishing to write\ntheir own Slurm core specialization plugin. This is version 100 of the API.\n\n<p>Slurm core specialization plugins must conform to the\nSlurm Plugin API with the following specifications:\n\n<p><span class=\"commandline\">const char\nplugin_name[]=\"<i>full&nbsp;text&nbsp;name</i>\"</span>\n<p style=\"margin-left:.2in\">\nA free-formatted ASCII text string that identifies the plugin.\n\n<p><span class=\"commandline\">const char\nplugin_type[]=\"<i>major/minor</i>\"</span><br>\n<p style=\"margin-left:.2in\">\nThe major type must be &quot;core_spec&quot;.\nThe minor type can be any suitable name for the type of core specialization\npackage.\nThe following core specialization plugins are included in the Slurm distribution\n<ul>\n<li><b>cray</b> &mdash; Use Cray APIs to enforce core specialization.</li>\n<li><b>none</b> &mdash; Can be configured to log calls to its functions, but\notherwise does nothing.</li>\n</ul>\n<p>Slurm can be configured to use multiple core specialization plugins if desired.</p>\n\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loadeed by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<p><b>NOTE:</b> These functions all accept as an argument the job step's\ncontainer ID (as set by the proctrack plugin).\nEach job step will have a different container ID.\nSince a job may execute multiple job steps sequentially and/or in parallel;\nthese functions will be called once for each job step on each compute node.</p>\n\n<p class=\"footer\"><a href=\"#top\">top</a>\n\n<h2>API Functions</h2>\n<p>All of the following functions are required. Functions which are not\nimplemented must be stubbed.\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\">\nint core_spec_p_set(uint64_t cont_id, uint16_t core_count)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nThis function is called by the slurmstepd daemon after the job step's tasks\nhave been forked and exec'ed, and immediately before they are released from\na held state.\nNote that each job step will have a different container ID.\nNote that since a job may execute multiple job steps sequentially and/or in\nparallel; this function will be called once for each job step on each compute\nnode.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">cont_id</span>\n(input) the job step's container ID as set by the proctrack plugin.<br>\n<span class=\"commandline\">core_count</span>\n(input) number of specialized cores to be reserved for the job.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint core_spec_p_clear(uint64_t cont_id)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nThis function is called by the slurmstepd daemon after the job step's tasks\nhave all exited.\nNote that each job step will have a different container ID.\nNote that since a job may execute multiple job steps sequentially and/or in\nparallel; this function will be called once for each job step on each compute\nnode.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">cont_id</span>\n(input) the job step's container ID as set by the proctrack plugin.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint core_spec_p_suspend(uint64_t cont_id, uint16_t core_count)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nThis function is called by the slurmstepd daemon immediately after the job\nstep's tasks have all been sent a SIGSTOP signal.\nNote that each job step will have a different container ID.\nNote that since a job may execute multiple job steps sequentially and/or in\nparallel; this function will be called once for each job step on each compute\nnode.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">cont_id</span>\n(input) the job step's container ID as set by the proctrack plugin.<br>\n<span class=\"commandline\">core_count</span>\n(input) number of specialized cores to be reserved for the job.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint core_spec_p_resume(uint64_t cont_id, uint16_t core_count)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nThis function is called by the slurmstepd daemon immediately before the job\nstep's tasks will all be sent a SIGCONT signal.\nNote that each job step will have a different container ID.\nNote that since a job may execute multiple job steps sequentially and/or in\nparallel; this function will be called once for each job step on each compute\nnode.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">cont_id</span>\n(input) the job step's container ID as set by the proctrack plugin.<br>\n<span class=\"commandline\">core_count</span>\n(input) number of specialized cores to be reserved for the job.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"footer\"><a href=\"#top\">top</a>\n\n<p style=\"text-align:center;\">Last modified 27 March 2015</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/selectplugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Resource Selection Plugin Programmer Guide</a></h1>\n\n<h2>Overview</h2>\n<p>This document describe. Slurm resource selection plugins and the API that defines\nthem. It is intended as a resource to programmers wishing to write their own SLURM\nnode selection plugins.</p>\n\n<p>Slurm node selection plugins are Slurm plugins that implement the Slurm node selection\nAPI described herein. They are intended to provide a mechanism for both selecting\nnodes for pending jobs and performing any system-specific tasks for job launch or\ntermination. The plugins must conform to the Slurm Plugin API with the following\nspecifications:</p>\n<p><span class=\"commandline\">const char plugin_type[]</span><br>\nThe major type must be &quot;select.&quot; The minor type can be any recognizable\nabbreviation for the type of node selection algorithm. We recommend, for example:</p>\n<ul>\n<li><b>bluegene</b> &mdash; <a href=\"http://www.research.ibm.com/bluegene/\">IBM BlueGene/Q</a>\nnode selector. Note that this plugin not only selects the nodes for a job, but performs\nsome initialization and termination functions for the job. Use this plugin for\nBlueGene/Q systems.</li>\n<li><b>cons_res</b> &mdash; A plugin that can allocate individual processors,\nmemory, etc. within nodes. This plugin is recommended for systems with\nmany non-parallel programs sharing nodes. For more information see\n<a href=cons_res.html>Consumable Resources in Slurm</a>.</li>\n<li><b>cray</b> &mdash; Cray XE and XT system node selector. Note that this\nplugin not only selects the nodes for a job, but performs some initialization\nand termination functions for the job. This plugin also serves as a wrapper\nfor the <i>select/linear</i> plugin which enforces various limits and\nprovides support for resource selection optimized for the system topology.</li>\n<li><b>linear</b> &mdash; A plugin that selects nodes assuming a one-dimensional\narray of nodes. The nodes are selected so as to minimize the number of consecutive\nsets of nodes utilizing a best-fit algorithm. While supporting shared nodes,\nthis plugin does not allocate individual processors, but can allocate memory to jobs.\nThis plugin is recommended for systems without shared nodes.</li>\n</ul>\n\n<p><span class=\"commandline\">const char plugin_name[]</span><br>\nSome descriptive name for the plugin.\nThere is no requirement with respect to its format.</p>\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loadeed by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<p>A simplified flow of logic follows:\n<pre>\n/* slurmctld daemon starts, recover state */\nif ((<i>select_p_node_init)</i>()     != SLURM_SUCCESS) ||\n    (<i>select_p_block_init)</i>()    != SLURM_SUCCESS) ||\n    (<i>select_p_state_restore)</i>() != SLURM_SUCCESS) ||\n    (<i>select_p_job_init)</i>()      != SLURM_SUCCESS))\n   abort\n\n/* wait for job arrival */\nif (<i>select_p_job_test</i>(all available nodes) != SLURM_SUCCESS) {\n   if (<i>select_p_job_test</i>(all configured nodes) != SLURM_SUCCESS)\n      /* reject the job and tell the user it can never run */\n   else\n      /* leave the job queued for later execution */\n} else {\n   /* update job's node list and node bitmap */\n   if (<i>select_p_job_begin</i>() != SLURM_SUCCESS)\n      /* leave the job queued for later execution */\n   else {\n      while (!<i>select_p_job_ready</i>())\n\t wait\n      /* execute the job */\n      /* wait for job to end or be terminated */\n      <i>select_p_job_fini</i>()\n    }\n}\n\n/* wait for slurmctld shutdown request */\n<i>select_p_state_save</i>()\n</pre>\n<p>Depending upon failure modes, it is possible that\n<span class=\"commandline\">select_p_state_save()</span>\nwill not be called at slurmctld termination.\nWhen slurmctld is restarted, other function calls may be replayed.\n<span class=\"commandline\">select_p_node_init()</span> may be used\nto synchronize the plugin's state with that of slurmctld.</p>\n\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<h2>Data Objects</h2>\n<p> These functions are expected to read and/or modify data structures directly in\nthe slurmctld daemon's memory. Slurmctld is a multi-threaded program with independent\nread and write locks on each data structure type. Therefore the type of operations\npermitted on various data structures is identified for each function.</p>\n\n<p>These functions make use of bitmaps corresponding to the nodes in a table.\nThe function <span class=\"commandline\">select_p_node_init()</span> should\nbe used to establish the initial mapping of bitmap entries to nodes.\nFunctions defined in <i>src/common/bitmap.h</i> should be used for bitmap\nmanipulations (these functions are directly accessible from the plugin).</p>\n\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<h2>API Functions</h2>\n<p>The following functions must appear. Functions which are not implemented should\nbe stubbed.</p>\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the SLURM\n<span class=\"commandline\">init()</span>, and the SLURM\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<h3>State Save Functions</h3>\n\n<p class=\"commandline\">int select_p_state_save (char *dir_name);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Save any global node selection state\ninformation to a file within the specified directory. The actual file name used is plugin specific.\nIt is recommended that the global switch state contain a magic number for validation purposes.\nThis function is called by the slurmctld daemon on shutdown.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<span class=\"commandline\"> dir_name</span>&nbsp;\n&nbsp;&nbsp;(input) fully-qualified pathname of a directory into which user SlurmUser (as defined\nin slurm.conf) can create a file and write state information into that file. Cannot be NULL.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR.</p>\n\n<p class=\"commandline\">int select_p_state_restore (char *dir_name);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Restore any global node selection state\ninformation from a file within the specified directory. The actual file name used is plugin specific.\nIt is recommended that any magic number associated with the global switch state be verified.\nThis function is called by the slurmctld daemon on startup.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<span class=\"commandline\"> dir_name</span>&nbsp;\n&nbsp;&nbsp;(input) fully-qualified pathname of a directory containing a state information file\nfrom which user SlurmUser (as defined in slurm.conf) can read. Cannot be NULL.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR, causing slurmctld to exit.</p>\n\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<h3>State Initialization Functions</h3>\n\n<p class=\"commandline\">int select_p_node_init (struct node_record *node_ptr, int node_cnt);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Note the initialization of the\nnode record data structure. This function is called by the slurmctld daemon\nwhen the node records are initially established and again when any nodes are\nadded to or removed from the data structure. </p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> node_ptr</span>&nbsp;&nbsp;&nbsp;(input) pointer\nto the node data records. Data in these records can read. Nodes deleted after initialization\nmay have their the <i>name</i> field in the record cleared (zero length) rather than\nrebuilding the node records and bitmaps.<br><br>\n<span class=\"commandline\"> node_cnt</span>&nbsp; &nbsp;&nbsp;(input) number\nof node data records.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR, causing slurmctld to exit.</p>\n\n<p class=\"commandline\">int select_p_block_init (List part_list);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Note the initialization of the\npartition record data structure. This function is called by the slurmctld\ndaemon when the partition records are initially established and again\nwhen any partition configurations change. </p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\"> part_list</span>&nbsp;&nbsp;&nbsp;(input) list of partition\nrecord entries. Note that some of these partitions may have no associated nodes. Also\nconsider that nodes can be removed from one partition and added to a different partition.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR, causing slurmctld to exit.</p>\n\n<p class=\"commandline\">int select_p_job_init(List job_list);<p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Used at slurmctld daemon\nstartup to synchronize plugin (and node) state with that of currently active\njobs.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\"> job_list</span>&nbsp; &nbsp;&nbsp;(input)\nlist of slurm jobs from slurmctld job records.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR.</p>\n\n<p class=\"commandline\">int select_p_reconfigure (void);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Used to notify plugin\nof change in partition configuration or general configuration change.\nThe plugin will test global variables for changes as appropriate.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful, otherwise SLURM_ERROR</p>\n\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n\n<h3>Node-Specific Functions</h3>\n\n<p class=\"commandline\">select_nodeinfo_t *select_p_select_nodeinfo_alloc(void);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Allocate a buffer for select\nplugin specific information about a node. Use select_p_select_nodeinfo_free()\nto free the returned data structure.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: A buffer for select plugin specific\ninformation about a node or NULL on failure. Use select_p_select_nodeinfo_free()\nto free this data structure.</p>\n\n<p class=\"commandline\">int select_p_select_nodeinfo_pack(select_nodeinfo_t *nodeinfo,\nBuf buffer, uint16_t protocol_version);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Pack select plugin specific\ninformation about a node into a buffer for node queries.</p>\n<p style=\"margin-left:.2in\"><b>Argument</b>:<br>\n<span class=\"commandline\"> nodeinfo</span>&nbsp; &nbsp;&nbsp;(input) Node information to be packed.<br>\n<span class=\"commandline\"> buffer</span>&nbsp; &nbsp;&nbsp;(input/output) pointer\nto buffer into which the node information is packed.<br>\n<span class=\"commandline\"> protocol_version</span>&nbsp; &nbsp;&nbsp;(input)\nVersion number of the data packing mechanism (needed for backward compatibility).</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful, otherwise SLURM_ERROR</p>\n\n<p class=\"commandline\">int select_p_select_nodeinfo_unpack(select_nodeinfo_t **nodeinfo,\nBuf buffer, uint16_t protocol_version);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Unpack select plugin specific\ninformation about a node from a buffer for node queries. Use\nselect_p_select_nodeinfo_free() to free the returned data structure.</p>\n<p style=\"margin-left:.2in\"><b>Argument</b>:<br>\n<span class=\"commandline\"> nodeinfo</span>&nbsp; &nbsp;&nbsp;(output) Node\ninformation unpacked from the buffer. Use select_p_select_nodeinfo_free()\nto free the returned data structure.<br>\n<span class=\"commandline\"> buffer</span>&nbsp; &nbsp;&nbsp;(input/output) pointer\nto buffer from which the node information is to be unpacked.<br>\n<span class=\"commandline\"> protocol_version</span>&nbsp; &nbsp;&nbsp;(input)\nVersion number of the data packing mechanism (needed for backward compatibility).</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful, otherwise SLURM_ERROR</p>\n\n<p class=\"commandline\">int select_p_select_nodeinfo_free(select_nodeinfo_t *nodeinfo);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Free a buffer which was\npreviously allocated for select plugin specific information about a node.</p>\n<p style=\"margin-left:.2in\"><b>Argument</b>:\n<span class=\"commandline\"> nodeinfo</span>&nbsp; &nbsp;&nbsp;(input/output) The buffer to be freed.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful, otherwise SLURM_ERROR</p>\n\n<p class=\"commandline\">int int select_p_select_nodeinfo_set(struct job_record *job_ptr);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Reset select plugin specific\ninformation about a job. Called by slurmctld daemon after that job's state has\nbeen restored (at startup) or job has been scheduled.</p>\n<p style=\"margin-left:.2in\"><b>Argument</b>:\n<span class=\"commandline\"> job_ptr</span>&nbsp; &nbsp;&nbsp;(input) Pointer\nto the updated job.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR.</p>\n\n<p class=\"commandline\">int select_p_select_nodeinfo_set_all(void);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Update select plugin specific\ninformation about every node as needed.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR.</p>\n\n<p class=\"commandline\">int select_p_select_nodeinfo_get(select_nodeinfo_t *nodeinfo,\nenum select_nodedata_type dinfo, enum node_states state, void *data);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Get information from a\nselect plugin's node specific data structure.</p>\n<p style=\"margin-left:.2in\"><b>Argument</b>:<br>\n<span class=\"commandline\"> nodeinfo</span>&nbsp; &nbsp;&nbsp;(input) Node information\ndata structure from which information is to get retrieved.<br>\n<span class=\"commandline\"> dinfo</span>&nbsp; &nbsp;&nbsp;(input) Data type to\nbe retrieved.<br>\n<span class=\"commandline\"> state</span>&nbsp; &nbsp;&nbsp;(input) Node state filter\nto be applied (e.g. only get information about ALLOCATED nodes).<br>\n<span class=\"commandline\"> data</span>&nbsp; &nbsp;&nbsp;(output) The retrieved data.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR.</p>\n\n<p class=\"commandline\">int select_p_update_node_config (int index);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: note that a node has\nregistered with a different configuration than previously registered.\nFor example, the node was configured with 1GB of memory in slurm.conf,\nbut actually registered with 2GB of memory.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> index</span>&nbsp;&nbsp;&nbsp;(input) zero origin index\nof the node in reference to the entire system.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful, otherwise SLURM_ERROR</p>\n\n<p class=\"commandline\">bool select_p_node_ranking(struct node_record *node_ptr, int node_cnt)</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: This function is called by the slurmctld\ndaemon at start time to set node rank information for recording the nodes to\noptimize application performance. </p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> node_ptr</span>&nbsp;&nbsp;&nbsp;(input/output) pointer\nto the node data structure. Each node's node rank field may be set.<br>\n<span class=\"commandline\"> node_cnt</span>&nbsp;&nbsp;&nbsp;(input) number\nof nodes configured on the system.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: true if node rank information has\nbeen set.</p>\n\n<p class=\"commandline\">int select_p_update_node_state (struct node_record *node_ptr);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: push a node state change\ninto the plugin. The index should be the index from the slurmctld of\nthe entire system.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> node_ptr</span>&nbsp;&nbsp;&nbsp;(input/output) pointer\nto the node data structure. Each node's node rank field may be set.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful, otherwise SLURM_ERROR</p>\n\n<p class=\"commandline\">int select_p_alter_node_cnt (enum\nselect_node_cnt type, void *data);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Used for systems like an IBM\nBluegene system where one Slurm node is mapped to many compute nodes. In\nBluegene's case one Slurm node/midplane represents 512 compute nodes, but\nsince 512 is typically the smallest allocatable block Slurm treats\nit as one node.  This is a function so the user can issue a 'real'\nnumber and the function will alter it so Slurm can understand what the\nuser really means in Slurm terms.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> type</span>&nbsp;&nbsp;&nbsp;(input) enum\ntelling the plugin how to transform the data.<br>\n<span class=\"commandline\"> data</span>&nbsp;&nbsp;&nbsp;(input/output)\nIs a void * and the actual data type depends upon the first argument to this\nfunction (type).</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful, otherwise SLURM_ERROR</p>\n\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n\n<h3>Block-Specific Functions</h3>\n\n<p class=\"commandline\">int select_p_update_sub_node (update_block_msg_t *block_desc_ptr);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Update the state of a portion of\na Slurm node. Currently used on BlueGene systems to place node cards within a\nmidplane into or out of an error state.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\"> block_desc_ptr</span>&nbsp;&nbsp;&nbsp;(input) pointer\nto the modified block containing the sub-block name and its new state.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful, otherwise SLURM_ERROR</p>\n\n<p class=\"commandline\">int select_p_update_block (update_block_msg_t *block_desc_ptr);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: This function is called when the admin needs\nto manually update the state of a block. </p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\"> block_desc_ptr</span>&nbsp;&nbsp;&nbsp;(input) block\ndescription variable.  Containing the block name and the state to set the block.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR.</p>\n\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n\n<h3>Job-Specific Functions</h3>\n\n<p class=\"commandline\">select_jobinfo_t *select_p_select_jobinfo_alloc(void);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Allocate a buffer for select\nplugin specific information about a job. Use select_p_select_jobinfo_free()\nto free the allocated memory.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: Pointer to a select plugin buffer\nfor a job or NULL on failure. Use select_p_select_jobinfo_free() to free the\nallocated memory.</p>\n\n<p class=\"commandline\">select_jobinfo_t *select_p_select_jobinfo_copy(select_jobinfo_t *jobinfo);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Copy the buffer containing select\nplugin specific information about a job. Use select_p_select_jobinfo_free()\nto free the allocated memory.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\"> jobinfo</span>&nbsp; &nbsp;&nbsp;(input) pointer\nto the select plugin specific information about a job.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: A copy of jobinfo or NULL on\nfailure. Use select_p_select_jobinfo_free() to free the allocated memory.</p>\n\n<p class=\"commandline\">int select_p_select_jobinfo_free(select_jobinfo_t *jobinfo);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Free the buffer containing select\nplugin specific information about a job.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\"> jobinfo</span>&nbsp; &nbsp;&nbsp;(input) pointer\nto the select plugin specific information about a job.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR.</p>\n\n<p class=\"commandline\">int select_p_select_jobinfo_pack(select_jobinfo_t *jobinfo,\nBuf buffer, uint16_t protocol_version);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Pack into a buffer the contents\nof the select plugin specific information about a job.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> jobinfo</span>&nbsp; &nbsp;&nbsp;(input) pointer\nto the select plugin specific information about a job.<br>\n<span class=\"commandline\"> buffer</span>&nbsp; &nbsp;&nbsp;(input/output) pointer\nto buffer into which the job information is packed.<br>\n<span class=\"commandline\"> protocol_version</span>&nbsp; &nbsp;&nbsp;(input)\nVersion number of the data packing mechanism (needed for backward compatibility).</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR.</p>\n\n<p class=\"commandline\">int select_p_select_jobinfo_unpack(select_jobinfo_t **jobinfo_pptr,\nBuf buffer, uint16_t protocol_version);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Unpack from a buffer the contents\nof the select plugin specific information about a job.\nThe returned value must be freed using select_p_select_jobinfo_free().</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> jobinfo</span>&nbsp; &nbsp;&nbsp;(output) pointer\nto the select plugin specific information about a job. The returned value must\nbe freed using select_p_select_jobinfo_free().<br>\n<span class=\"commandline\"> buffer</span>&nbsp; &nbsp;&nbsp;(input/output) pointer\nto buffer from which the job information is unpacked.<br>\n<span class=\"commandline\"> protocol_version</span>&nbsp; &nbsp;&nbsp;(input)\nVersion number of the data packing mechanism (needed for backward compatibility).</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR.</p>\n\n<p class=\"commandline\">int select_p_select_jobinfo_get(select_jobinfo_t *jobinfo,\nenum select_jobdata_type data_type, void *data);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Get the contents of a field\nfrom the select plugin specific information about a job.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> jobinfo</span>&nbsp; &nbsp;&nbsp;(input) pointer\nto the select plugin specific information about a job to be read.<br>\n<span class=\"commandline\"> data_type</span>&nbsp; &nbsp;&nbsp;(input) identification\nof the field to be retrieved.<br>\n<span class=\"commandline\"> data</span>&nbsp; &nbsp;&nbsp;(output) data read\nfrom the job record.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR.</p>\n\n<p class=\"commandline\">int select_p_select_jobinfo_set(select_jobinfo_t *jobinfo,\nenum select_jobdata_type data_type, void *data);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Set a field in the select\nplugin specific information about a job.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> jobinfo</span>&nbsp; &nbsp;&nbsp;(input/output) pointer\nto the select plugin specific information about a job to be modified.<br>\n<span class=\"commandline\"> data_type</span>&nbsp; &nbsp;&nbsp;(input) identification\nof the field to be set.<br>\n<span class=\"commandline\"> data</span>&nbsp; &nbsp;&nbsp;(input) data to be written\ninto the job record.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR.</p>\n\n<p class=\"commandline\">char *select_p_select_jobinfo_sprint(select_jobinfo_t *jobinfo,\nchar *buf, size_t size, int mode);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Print the contents of the select\nplugin specific information about a job.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> jobinfo</span>&nbsp; &nbsp;&nbsp;(input) pointer\nto the select plugin specific information about a job.<br>\n<span class=\"commandline\"> buf</span>&nbsp; &nbsp;&nbsp;(input/output) buffer\ninto which the contents are written.<br>\n<span class=\"commandline\"> size</span>&nbsp; &nbsp;&nbsp;(input) size of buf in bytes.<br>\n<span class=\"commandline\"> mode</span>&nbsp; &nbsp;&nbsp;(input) print mode, see enum select_print_mode.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: Pointer to the buf on success or NULL on failure.</p>\n\n<p class=\"commandline\">char *select_p_select_jobinfo_xstrdup(select_jobinfo_t *jobinfo, int mode);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Print the contents of the select\nplugin specific information about a job. The return value must be released using the xfree() function.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> jobinfo</span>&nbsp; &nbsp;&nbsp;(input) pointer\nto the select plugin specific information about a job.<br>\n<span class=\"commandline\"> mode</span>&nbsp; &nbsp;&nbsp;(input) print mode, see enum select_print_mode.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: Pointer to a string on success or NULL on failure.\nCall xfree() to release the memory allocated for the return value.</p>\n\n<p class=\"commandline\">int select_p_job_test (struct job_record *job_ptr,\nbitstr_t *bitmap, uint32_t min_nodes, uint32_t max_nodes, uint32_t req_nodes, uint32_t mode,\nList preemption_candidates, List *preempted_jobs, bitstr_t *exc_core_bitmap);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Given a job's scheduling requirement\nspecification and a set of nodes which might  be used to satisfy the request, identify\nthe nodes which \"best\" satisfy the request. Note that nodes being considered for allocation\nto the job may include nodes already allocated to other jobs, even if node sharing is\nnot permitted. This is done to ascertain whether or not job may be allocated resources\nat some later time (when the other jobs complete). This permits Slurm to reject\nnon-runnable jobs at submit time rather than after they have spent hours queued.\nInforming users of problems at job submission time permits them to quickly resubmit\nthe job with appropriate constraints.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> job_ptr</span>&nbsp; &nbsp;&nbsp;(input) pointer\nto the job being considered for scheduling. Data in this job record may safely be read.\nData of particular interest include <i>details->contiguous</i> (set if allocated nodes\nshould be contiguous), <i>num_procs</i> (minimum processors in allocation) and\n<i>details->req_node_bitmap</i> (specific required nodes).<br>\n<span class=\"commandline\"> bitmap</span>&nbsp; &nbsp;&nbsp;(input/output)\nbits representing nodes which might be allocated to the job are set on input.\nThis function should clear the bits representing nodes not required to satisfy\njob's scheduling request.\nBits left set will represent nodes to be used for this job. Note that the job's\nrequired nodes (<i>details->req_node_bitmap</i>) will be a superset\n<i>bitmap</i> when the function is called.<br>\n<span class=\"commandline\"> min_nodes</span>&nbsp; &nbsp;&nbsp;(input)\nminimum number of nodes to allocate to this job. Note this reflects both job\nand partition specifications.<br>\n<span class=\"commandline\"> max_nodes</span>&nbsp; &nbsp;&nbsp;(input)\nmaximum number of nodes to allocate to this job. Note this reflects both job\nand partition specifications.<br>\n<span class=\"commandline\"> req_nodes</span>&nbsp; &nbsp;&nbsp;(input)\nthe requested (desired)  of nodes to allocate to this job. This reflects job's\nmaximum node specification (if supplied).<br>\n<span class=\"commandline\"> mode</span>&nbsp; &nbsp;&nbsp;(input)\ncontrols the mode of operation. Valid options are:<br>\n* SELECT_MODE_RUN_NOW: try to schedule job now<br>\n* SELECT_MODE_TEST_ONLY: test if job can ever run<br>\n* SELECT_MODE_WILL_RUN: determine when and where job can run<br>\n<span class=\"commandline\"> preemption_candidates</span>&nbsp; &nbsp;&nbsp;(input)\nlist of pointers to jobs which may be preempted in order to initiate this\npending job. May be NULL if there are no preemption candidates.<br>\n<span class=\"commandline\"> preempted_jobs</span>&nbsp; &nbsp;&nbsp;(input/output)\nlist of jobs which must be preempted in order to initiate the pending job.\nIf the value is NULL, no job list is returned.\nIf the list pointed to has a value of NULL, a new list will be created\notherwise the existing list will be overwritten.\nUse the <i>list_destroy</i> function to destroy the list when no longer\nneeded.<br>\n<span class=\"commandline\"> exc_core_bitmap</span>&nbsp; &nbsp;&nbsp;(input)\nbitmap of cores held for advanced reservations.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR .</p>\n\n<p class=\"commandline\">int select_p_job_begin (struct job_record *job_ptr);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Note the initiation of the specified job\nis about to begin. This function is called immediately after\n<span class=\"commandline\">select_p_job_test()</span> successfully completes for this job.\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\"> job_ptr</span>&nbsp; &nbsp;&nbsp;(input) pointer\nto the job being initialized. Data in this job record may safely be read or written.\nThe <i>nodes</i> and <i>node_bitmap</i> fields of this job record identify the\nnodes which have already been selected for this job to use.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR, which causes the job to be requeued for\nlater execution.</p>\n\n<p class=\"commandline\">int select_p_job_ready (struct job_record *job_ptr);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Test if resources are configured\nand ready for job execution. This function is only used in the job prolog for\nBlueGene systems to determine if the bgblock has been booted and is ready for use.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\"> job_ptr</span>&nbsp; &nbsp;&nbsp;(input) pointer\nto the job being initialized. Data in this job record may safely be read.\nThe <i>nodes</i> and <i>node_bitmap</i> fields of this job record identify the\nnodes which have already been selected for this job to use. </p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: 1 if the job may begin execution,\n0 otherwise.</p>\n\n<p class=\"commandline\">int select_p_job_fini (struct job_record *job_ptr);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Note the termination of the\nspecified job. This function is called as the termination process for the\njob begins (prior to killing the tasks).</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\"> job_ptr</span>&nbsp; &nbsp;&nbsp;(input) pointer\nto the job being terminated. Data in this job record may safely be read or written.\nThe <i>nodes</i> and/or <i>node_bitmap</i> fields of this job record identify the\nnodes which were selected for this job to use.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR.</p>\n\n<p class=\"commandline\">int select_p_job_signal (struct job_record *job_ptr,\nint signal);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Signal the specified job.\nThis is needed for architectures where the job steps are launched by a\nmechanism outside of Slurm, for example when ALPS is used on Cray systems.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> job_ptr</span>&nbsp; &nbsp;&nbsp;(input) pointer\nto the job to be signaled.<br>\n<span class=\"commandline\"> signal</span>&nbsp; &nbsp;&nbsp;(input) signal to\nbe sent to the job.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On\nfailure, the plugin should return a Slurm error code.</p>\n\n\n<p class=\"commandline\">int select_p_job_mem_confirm (struct job_record *job_ptr);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Confirm that a job's memory\nallocation is still valid after a node is restarted. This is an issue if the\njob is allocated all of the memory on a node and that node is restarted with a\ndifferent memory size than at the time it is allocated to the job. This would\nmostly be an issue on an Intel KNL node where the memory size would vary with\nthe MCDRAM cache mode.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> job_ptr</span>&nbsp; &nbsp;&nbsp;(input) pointer\nto the job to be validated.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On\nfailure, the plugin should return a Slurm error code.</p>\n\n<p class=\"commandline\">int select_p_job_suspend (struct job_record *job_ptr,\nbool indf_susp);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Suspend the specified job.\nRelease resources for use by other jobs.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> job_ptr</span>&nbsp; &nbsp;&nbsp;(input) pointer\nto the job being suspended. Data in this job record may safely be read or\nwritten.  The <i>nodes</i> and/or <i>node_bitmap</i> fields of this job record\nidentify the nodes which were selected for this job to use.<br>\n<span class=\"commandline\"> indf_susp</span>&nbsp; &nbsp;&nbsp;(input) flag\nwhich if set indicates the job is being suspended indefinitely by the user or\nadministrator. If not set, the job is being suspended temporarily for gang\nscheduling.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On\nfailure, the plugin should return a Slurm error code.</p>\n\n<p class=\"commandline\">int select_p_job_resume (struct job_record *job_ptr,\nbool indf_susp);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Resume the specified job\nwhich was previously suspended.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> job_ptr</span>&nbsp; &nbsp;&nbsp;(input) pointer\nto the job being resumed. Data in this job record may safely be read or\nwritten.  The <i>nodes</i> and/or <i>node_bitmap</i> fields of this job record\nidentify the nodes which were selected for this job to use.<br>\n<span class=\"commandline\"> indf_susp</span>&nbsp; &nbsp;&nbsp;(input) flag\nwhich if set indicates the job is being resumed after being suspended\nindefinitely by the user or administrator. If not set, the job is being\nresumed after being temporarily suspended for gang scheduling.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On\nfailure, the plugin should return a Slurm error code.</p>\n\n<p class=\"commandline\">int select_p_job_expand_allow (void);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Report the ability of this\nselect plugin to expand jobs.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: True if job expansion is\nsupported, otherwise false.</p>\n\n<p class=\"commandline\">int select_p_job_expand (struct job_record *from_job_ptr,\nstruct job_record *to_job_ptr);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Transfer all resources\ncurrently allocated to one job to another job. One job is left with no\nallocated resources and the other job is left with the resources previously\nallocated to both jobs.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> from_job_ptr</span>&nbsp; &nbsp;&nbsp;(input) pointer\nto the job being to have all of its resources removed.<br>\n<span class=\"commandline\"> to_job_ptr</span>&nbsp; &nbsp;&nbsp;(input) pointer\nto the job getting all of the resources previously either job.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On\nfailure, the plugin should return a Slurm error code.</p>\n\n<p class=\"commandline\">int select_p_job_resized (struct job_record *job_ptr,\nstruct node_record *node_ptr);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Remove the specified node\nfrom the job's allocation.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> job_ptr</span>&nbsp; &nbsp;&nbsp;(input) pointer\nto the job being decreased in size.<br>\n<span class=\"commandline\"> node_ptr</span>&nbsp; &nbsp;&nbsp;(input) pointer\nto the node being removed from a job's allocation.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On\nfailure, the plugin should return a Slurm error code.</p>\n\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n\n<h3>Step-Specific Functions</h3>\n\n<p class=\"commandline\">bitstr_t *select_p_step_pick_nodes(struct job_record *job_ptr,\nselect_jobinfo_t *step_jobinfo, uint32_t node_count)</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: If the select plugin needs to\nselect nodes for a job step, then do so here.<br>\n<b>NOTE:</b> Only select/bluegene selects the job step resources. The logic\nwithin the slurmctld daemon directly selects resources for a job step for all\nother select plugins.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> job_ptr</span>&nbsp; &nbsp;&nbsp;(input)\nPointer to the job which is attempting to allocate a job step.</br>\n<span class=\"commandline\"> step_jobinfo</span>&nbsp; &nbsp;&nbsp;(input/output)\nOn input, this is a pointer to an empty buffer. On output for a successful\njob step allocation, this structure is filled in with detailed information\nabout the job step allocation.</br>\n<span class=\"commandline\"> node_count</span>&nbsp; &nbsp;&nbsp;(input)\nNumber of nodes required by the new job step.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: If successful, then return a\nbitmap of the nodes allocated to the job step, otherwise return NULL and the\nlogic within the slurmctld daemon will select the nodes to be allocated to\nthe job step.</p>\n\n<p class=\"commandline\">int select_p_step_finish(struct step_record *step_ptr, bool killing_step)</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Note that a job step is completing execution</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> step_ptr</span>&nbsp; &nbsp;&nbsp;(input)\nPointer to the step which has completed execution.<br>\n<span class=\"commandline\"> killing_step</span>&nbsp; &nbsp;&nbsp;(input)\nTrue if we are begining the termination of the step (for example, when SIGKILL is being sent);\nFalse if the termination of the step has completed (all processes have exited).</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR.</p>\n\n<p class=\"commandline\">int select_p_fail_cnode(struct step_record *step_ptr);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: This function fails\n  certain cnodes in a blocks midplane.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\">step_ptr</span>&nbsp; &nbsp;&nbsp(input)\ninformation on the step that has failed cnodes.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR.</p>\n\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n\n<h3>Advanced Reservation Functions</h3>\n\n<p class=\"commandline\">bitstr_t * select_p_resv_test(resv_desc_msg_t *resv_desc_ptr, uint32_t node_cnt, bitstr_t *avail_bitmap, bitstr_t **core_bitmap)</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Identify the nodes which best\nsatisfy a reservation request taking system topology into consideration if\napplicable.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> resv_desc_ptr</span>&nbsp; &nbsp;&nbsp;(input/output)\nthe request of the reservation.  The node_list could be changed inside\nof the plugin.<br>\n<span class=\"commandline\"> node_cnt</span>&nbsp; &nbsp;&nbsp;(input)\nnumber of nodes required to satisfy the reservation request.<br>\n<span class=\"commandline\"> avail_bitmap</span>&nbsp; &nbsp;&nbsp;(input/output)\na bitmap of the nodes which are available for use in creating the reservation.<br>\n<span class=\"commandline\"> core_bitmap</span>&nbsp; &nbsp;&nbsp;(input/output)\ncores which can not be used for this reservation IN, and cores to be\nused in the reservation OUT (flush bitstr then apply only used cores).<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: A bitmap of the nodes which should\nbe used for the advanced reservation or NULL if the selected nodes can not\nbe used for an advanced reservation.</p>\n\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<h3>Get Information Functions</h3>\n\n<p class=\"commandline\">int select_p_get_info_from_plugin(enum select_plugindata_info dinfo,\nstruct job_record *job_ptr, void *data);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Get plugin-specific information\nabout a job.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> info</span>&nbsp; &nbsp;&nbsp;(input) identifies\nthe type of data to be updated.<br>\n<span class=\"commandline\"> job_ptr</span>&nbsp; &nbsp;&nbsp;(input) pointer to\nthe job related to the query (if applicable; may be NULL).<br>\n<span class=\"commandline\"> data</span>&nbsp; &nbsp;&nbsp;(output) the requested data.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR.</p>\n\n<p class=\"commandline\">int select_p_pack_select_info(time_t last_query_time,\nuint16_t show_flags, Buf *buffer_ptr, uint16_t protocol_version);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Pack plugin-specific information\nabout its general state into a buffer. Currently only used by select/bluegene\nto pack block state information.<br>\n<b>NOTE:</b> Functions to work with this data may be needed on computers\nwithout the plugin which generated the data, so those functions are in\nsrc/common modules. The unpack function is performed by\nslurm_unpack_block_info_members() in src/common/slurm_protocol_pack.c\nusing BlueGene specific data structures. Use destroy_select_ba_request()\nin src/common/noe_select.c to free the data structure's memory.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> last_query_time</span>&nbsp; &nbsp;&nbsp;(input)\nTime when the data was previously requested (used so only updated information\nneeds to be sent).<br>\n<span class=\"commandline\"> show_flags</span>&nbsp; &nbsp;&nbsp;(input) identifies\nthe type of data requested.<br>\n<span class=\"commandline\"> buffer_ptr</span>&nbsp; &nbsp;&nbsp;(input/output)\nPointer to buffer filled in with select plugin state information.</br>\n<span class=\"commandline\"> protocol_version</span>&nbsp; &nbsp;&nbsp;(input)\nVersion number of the data packing mechanism (needed for backward compatibility).</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR.</p>\n\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<h3>Block Allocator interface</h3>\n\n<p class=\"commandline\">void select_p_ba_init(node_info_msg_t *node_info_ptr, bool sanity_check);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Construct an internal block allocation\ntable containing information about the nodes on a computer. This allocated memory\nshould be released  by calling select_p_ba_fini();</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> node_info_ptr</span>&nbsp; &nbsp;&nbsp;(input)\nInformation about the nodes on a system.<br>\n<span class=\"commandline\"> sanity_check</span>&nbsp; &nbsp;&nbsp;(input) if set\nthen validate that the node name suffix values represent coordinates which are\nwithin the system's dimension size (see function select_p_ba_get_dims).</p>\n\n<p class=\"commandline\">void select_p_ba_fini(void);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Free storage allocated by\nselect_p_ba_init().</p>\n\n<p class=\"commandline\">int *select_p_ba_get_dims(void);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Return an array containing\nthe number of elements in each dimension of the system size. For example, an IBM\nBluegene/P system has a three-dimensional torus topology. If it has eight elements\nin the X dimension, and four in the Y and Z dimensions, the returned array will\ncontain the values 8, 4, 4.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: An array containing the number of\nelements in each dimension of the system size.</p>\n\n<p class=\"commandline\">bitstr_t *select_g_ba_cnodelist2bitmap(char *cnodelist);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Returns a bitmap\nrepresenting the cnodelist input with the bits of the cnodelist in a\nmidplane not set.\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> cnodelist</span>&nbsp; &nbsp;&nbsp;(input)\ncnodelist (e.g. on a BGQ it would look something like '[00000x11331]').</br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: A bitmap the size of the\n  number of cnodes in a midplane with the bits available for use unset.</p>\n\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<p style=\"text-align:center;\">Last modified 11 June 2016</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/accounting_storageplugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Slurm Accounting Storage Plugin API</a></h1>\n\n<h2> Overview</h2>\n<p> This document describes Slurm Accounting Storage plugins and the API that\ndefines them. It is intended as a resource to programmers wishing to write\ntheir own Slurm Job Accounting Storage plugins. This is version 1 of the API.\n\n<p>Slurm Accounting Storage plugins must conform to the\nSlurm Plugin API with the following specifications:\n\n<p><span class=\"commandline\">const char\nplugin_name[]=\"<i>full&nbsp;text&nbsp;name</i>\"</span>\n<p style=\"margin-left:.2in\">\nA free-formatted ASCII text string that identifies the plugin.\n\n<p><span class=\"commandline\">const char\nplugin_type[]=\"<i>major/minor</i>\"</span><br>\n<p style=\"margin-left:.2in\">\nThe major type must be &quot;accounting_storage.&quot;\nThe minor type can be any suitable name\nfor the type of accounting package. We currently use\n<ul>\n<li><b>filetxt</b> &mdash; Information written to a text file.\n<li><b>mysql</b> &mdash; Store information in a mysql database (using\n  the InnoDB storage engine).\n<li><b>slurmdbd</b> &mdash; Send information to the Slurm Database\n  Daemon (SlurmDBD).  Extra configuration is needed and described <a href=\"accounting.html\">here</a>.\n<li><b>none</b> &mdash; Information is not stored anywhere.\n</ul>\n\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loadeed by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<p>The programmer is urged to study\n<span class=\"commandline\">src/plugins/accounting_storage/mysql</span>\nfor a sample implementation of a Slurm Accounting Storage plugin.\n<p>The Accounting Storage plugin was written to be an interface\nto storage data collected by the Job Accounting Gather plugin.  When\nadding a new database you may want to add common functions in a common\nfile in the src/database dir.  Refer to src/database/mysql_common.c|.h for an\nexample so other plugins can also use that database type to write out\ninformation.\n<p class=\"footer\"><a href=\"#top\">top</a>\n\n\n<h2>API Functions</h2>\n\n<p>The Job Accounting Storage API uses hooks in the slurmctld.</p>\n\n<p>All of the following functions are required. Functions which are not\nimplemented must be stubbed.</p>\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<h3>Functions called by the accounting_storage plugin</h3>\n\n<p class=\"commandline\">void *acct_storage_p_get_connection(bool\n  make_agent, int conn_num, bool rollback, char *location)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nacct_storage_p_get_connection() is called to get a connection to the\n  storage medium. acct_storage_p_close_connection() should be used to\n  free the pointer returned by this function.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">make_agent</span> (input) to make an agent\nthread or not.  This is primarily used in the slurmdbd plugin.<br>\n<span class=\"commandline\">conn_num</span> (input) connection number to\nthe plugin.  In many cases you should plan on multiple simultaneous\nconnections to the plugin.  This number is useful since the debug\nmessages can print this out to determine which connection the message\nis from.<br>\n<span class=\"commandline\">rollback</span> (input) Allow rollback to\nhappen or not (in use with databases that support rollback).<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">void *</span> which is an opaque structure\nused inside the plugin to connect to the storage type on success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">int acct_storage_p_close_connection(void **db_conn)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nacct_storage_p_close_connection() is called at the end of the program that has\ncalled acct_storage_p_get_connection(). This function closes the connection to\nthe storage type.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input/output) connection to\nthe storage type; all memory will be freed inside this function and\nset to NULL.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">int acct_storage_p_commit(void *db_conn, bool commit)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nacct_storage_p_commit() is called at a point where you would either\n  want changes to storage to be committed or rolled back.  This function\n  should also send appropriate update messages to the various slurmctlds.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">commit</span> (input) true for commit, false\nto rollback if connection was set up to rollback. <br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint acct_storage_p_add_users(void *db_conn, uint32_t uid, List user_list)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nCalled to add users to the storage type.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the function.<br>\n<span class=\"commandline\">user_list</span> (input) list of\nacct_user_rec_t *'s containing information about the users being added.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint acct_storage_p_add_coord(void *db_conn, uint32_t uid, List acct_list, acct_user_cond_t *user_cond)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nCalled to link specified users to the specified accounts as coordinators.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the function.<br>\n<span class=\"commandline\">acct_list</span> (input) list of\nacct_account_rec_t *'s containing information about the accounts to\nadd the coordinators to. <br>\n<span class=\"commandline\">user_cond</span> (input) contain a list of\nusers to add to be coordinators of the acct_list.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint acct_storage_p_add_accts(void *db_conn, uint32_t uid, List acct_list)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nCalled to add accounts to the storage type.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the function. <br>\n<span class=\"commandline\">acct_list</span> (input) list of\nacct_account_rec_t *'s containing information about the accounts to add. <br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint acct_storage_p_add_clusters(void *db_conn, uint32_t uid, List cluster_list)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nCalled to add clusters to the storage type.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the function.<br>\n<span class=\"commandline\">cluster_list</span> (input) list of\nacct_cluster_rec_t *'s containing information about the clusters to add. <br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint acct_storage_p_add_assocs(void *db_conn, uint32_t uid, List assoc_list)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nCalled to add associations to the storage type.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the function.<br>\n<span class=\"commandline\">assoc_list</span> (input) list of\nacct_assoc_rec_t *'s containing information about the\nassociations to add. <br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint acct_storage_p_add_qos(void *db_conn, uint32_t uid, List qos_list)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nCalled to add QOS's to the storage type.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the function.<br>\n<span class=\"commandline\">qos_list</span> (input) list of\nacct_qos_rec_t *'s containing information about the qos to add. <br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint acct_storage_p_add_wckeys(void *db_conn, uint32_t uid, List wckey_list)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nCalled to add wckeys to the storage type.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the function.<br>\n<span class=\"commandline\">wckey_list</span> (input) list of\nacct_wckey_rec_t *'s containing information about the wckeys to add. <br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint acct_storage_p_add_reservation(void *db_conn,\nacct_reservation_rec_t *resv)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nCalled to add reservations to the storage type.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">resv</span> (input) Reservation to be added. <br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nList acct_storage_p_modify_users(void *db_conn, uint32_t uid,\nacct_user_cond_t *user_cond, acct_user_rec_t *user)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUsed to modify existing users in the storage type.  The condition\n  could include very vague information about the user, so this\n  function should be robust in the ability to give everything the user\n  is asking for.  This is the reason a list of modified users is\n  returned so the caller knows what has been changed, sometimes by mistake.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the function.<br>\n<span class=\"commandline\">user_cond</span> (input) conditional about\nwhich users need to change.  User names or ids should not need to be stated.<br>\n<span class=\"commandline\">user</span> (input) what the changes\nshould be on the users identified by the conditional.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">List</span> containing names of users\nmodified on success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nList acct_storage_p_modify_accounts(void *db_conn, uint32_t uid,\nacct_account_cond_t *acct_cond, acct_account_rec_t *acct)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUsed to modify existing accounts in the storage type.  The condition\n  could include very vague information about the account, so this\n  function should be robust in the ability to give everything the account\n  is asking for.  This is the reason a list of modified accounts is\n  returned so the caller knows what has been changed, sometimes by mistake.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the function.<br>\n<span class=\"commandline\">acct_cond</span> (input) conditional about\nwhich accounts need to change.  Account names should not need to be stated.<br>\n<span class=\"commandline\">acct</span> (input) what the changes\nshould be on the accounts identified by the conditional.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">List</span> containing names of users\nmodified on success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nList acct_storage_p_modify_clusters(void *db_conn, uint32_t uid,\nacct_cluster_cond_t *cluster_cond, acct_cluster_rec_t *cluster)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUsed to modify existing clusters in the storage type.  The condition\n  could include very vague information about the cluster, so this\n  function should be robust in the ability to give everything the cluster\n  is asking for.  This is the reason a list of modified clusters is\n  returned so the caller knows what has been changed, sometimes by mistake.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the function.<br>\n<span class=\"commandline\">cluster_cond</span> (input) conditional about\nwhich clusters need to change.  Cluster names should not need to be stated.<br>\n<span class=\"commandline\">cluster</span> (input) what the changes\nshould be on the clusters identified by the conditional.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">List</span> containing names of clusters\nmodified on success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nList acct_storage_p_modify_assocs(void *db_conn, uint32_t uid,\nacct_assoc_cond_t *assoc_cond, acct_assoc_rec_t *assoc)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUsed to modify existing associations in the storage type.  The condition\n  could include very vague information about the association, so this\n  function should be robust in the ability to give everything the association\n  is asking for.  This is the reason a list of modified associations is\n  returned so the caller knows what has been changed, sometimes by mistake.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the function.<br>\n<span class=\"commandline\">assoc_cond</span> (input) conditional about\nwhich associations need to change.  Association ids should not need to be stated.<br>\n<span class=\"commandline\">assoc</span> (input) what the changes\nshould be on the associations identified by the conditional.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">List</span> containing names of associations\nmodified on success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nList acct_storage_p_modify_job(void *db_conn, uint32_t uid,\nacct_job_modify_cond_t *job_cond, acct_job_rec_t *job)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUsed to modify two fields (the derived exit code and the comment string) of an\nexisting job in the storage type.  Can only modify one job at a time.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type.<br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the function.<br>\n<span class=\"commandline\">job_cond</span> (input) conditional about\nwhich job need to change.<br>\n<span class=\"commandline\">job</span> (input) what the changes\nshould be on the job identified by the conditional.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">List</span> containing ID of job\nmodified on success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nList acct_storage_p_modify_qos(void *db_conn, uint32_t uid,\nacct_qos_cond_t *qos_cond, acct_qos_rec_t *qos)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUsed to modify existing qos in the storage type.  The condition\n  could include very vague information about the qos, so this\n  function should be robust in the ability to give everything the qos\n  is asking for.  This is the reason a list of modified qos is\n  returned so the caller knows what has been changed, sometimes by mistake.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type.<br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the function.<br>\n<span class=\"commandline\">qos_cond</span> (input) conditional about\nwhich qos need to change.  Qos names should not need to be stated.<br>\n<span class=\"commandline\">qos</span> (input) what the changes\nshould be on the qos identified by the conditional.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">List</span> containing names of qos\nmodified on success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nList acct_storage_p_modify_wckeys(void *db_conn, uint32_t uid,\nacct_wckey_cond_t *wckey_cond, acct_wckey_rec_t *wckey)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUsed to modify existing wckeys in the storage type.  The condition\n  could include very vague information about the wckeys, so this\n  function should be robust in the ability to give everything the wckey\n  is asking for.  This is the reason a list of modified wckey is\n  returned so the caller knows what has been changed, sometimes by mistake.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type.<br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the function.<br>\n<span class=\"commandline\">wckey_cond</span> (input) conditional about\nwhich wckeys need to change.  Wckey names should not need to be stated.<br>\n<span class=\"commandline\">wckey</span> (input) what the changes\nshould be on the wckey identified by the conditional.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">List</span> containing names of wckeys\nmodified on success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nint acct_storage_p_modify_reservation(void *db_conn,\nacct_reservation_rec_t *resv)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nCalled to modify reservations in the storage type.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">resv</span> (input) Reservation to be\nmodified (id) must be set in the structure. <br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nList acct_storage_p_remove_users(void *db_conn, uint32_t uid,\nacct_user_cond_t *user_cond)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUsed to remove users from the storage type.  This will remove all\n  associations.  Must check to make sure all running jobs are finished\n  before this is allowed to execute.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the function.<br>\n<span class=\"commandline\">user_cond</span> (input) conditional about\nwhich users to be removed.  User names or ids should not need to be stated.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">List</span> containing names of users\nremoved on success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nList acct_storage_p_remove_coord(void *db_conn, uint32_t uid,\nList acct_list, acct_user_cond_t *user_cond)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUsed to remove coordinators from the storage type.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the function.<br>\n<span class=\"commandline\">acct_list</span> (input) list of accounts\nassociated with the users.<br>\n<span class=\"commandline\">user_cond</span> (input) conditional about\nwhich users to be removed as coordinators.  User names or ids should be stated.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">List</span> containing names of users\nremoved as coordinators on success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nList acct_storage_p_remove_accounts(void *db_conn, uint32_t uid,\nacct_account_cond_t *acct_cond)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUsed to remove accounts from the storage type. This will remove all\n  associations from these accounts.  You need to make sure no jobs are\n  running with any association that is to be removed.  If any of these\n  accounts are default accounts for users that must also change before\n  an account can be removed.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the function.<br>\n<span class=\"commandline\">acct_cond</span> (input) conditional about\nwhich accounts to be removed.  Account names should not need to be stated.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">List</span> containing names of accounts\nremoved on success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nList acct_storage_p_remove_clusters(void *db_conn, uint32_t uid,\nacct_cluster_cond_t *cluster_cond)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUsed to remove clusters from the storage type. This will remove all\n  associations from these clusters.  You need to make sure no jobs are\n  running with any association that is to be removed.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the function.<br>\n<span class=\"commandline\">cluster_cond</span> (input) conditional about\nwhich clusters to be removed.  Cluster names should not need to be stated.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">List</span> containing names of clusters\nremoved on success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nList acct_storage_p_remove_assocs(void *db_conn, uint32_t uid,\nacct_assoc_cond_t *assoc_cond)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUsed to remove associations from the storage type.  You need to make\n  sure no jobs are running with any association that is to be removed.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the function.<br>\n<span class=\"commandline\">assoc_cond</span> (input) conditional about\nwhich associations to be removed.  Association ids should not need to be stated.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">List</span> containing names of associations\nremoved on success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nList acct_storage_p_remove_qos(void *db_conn, uint32_t uid,\nacct_qos_cond_t *qos_cond)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUsed to remove qos from the storage type.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the function.<br>\n<span class=\"commandline\">qos_cond</span> (input) conditional about\nwhich qos to be removed.  Qos names should not need to be stated.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">List</span> containing names of qos\nremoved on success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nList acct_storage_p_remove_wckeys(void *db_conn, uint32_t uid,\nacct_wckey_cond_t *wckey_cond)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUsed to remove wckeys from the storage type.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the function.<br>\n<span class=\"commandline\">wckey_cond</span> (input) conditional about\nwhich wckeys to be removed.  Wckey names should not need to be stated.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">List</span> containing names of wckeys\nremoved on success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nint acct_storage_p_remove_reservation(void *db_conn,\nacct_reservation_rec_t *resv)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nCalled to remove reservations in the storage type.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">resv</span> (input) Reservation to be\nremoved (id) must be set in the structure. <br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nList acct_storage_p_get_users(void *db_conn, uint32_t uid,\nacct_user_cond_t *user_cond)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nGet a list of acct_user_rec_t *'s based on the conditional sent.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the\nfunction.<br>\n<span class=\"commandline\">user_cond</span> (input) conditional about\nwhich users are to be returned.  User names or ids should not need to\nbe stated.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">List</span> containing acct_user_rec_t *'s\non success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nList acct_storage_p_get_accts(void *db_conn, uint32_t uid,\nacct_account_cond_t *acct_cond)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nGet a list of acct_account_rec_t *'s based on the conditional sent.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the\nfunction.<br>\n<span class=\"commandline\">acct_cond</span> (input) conditional about\nwhich accounts are to be returned.  Account names should not need to\nbe stated.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">List</span> containing acct_account_rec_t *'s\non success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nList acct_storage_p_get_clusters(void *db_conn, uint32_t uid,\nacct_cluster_cond_t *cluster_cond)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nGet a list of acct_cluster_rec_t *'s based on the conditional sent.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the\nfunction.<br>\n<span class=\"commandline\">cluster_cond</span> (input) conditional about\nwhich clusters are to be returned.  Cluster names should not need to\nbe stated.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">List</span> containing acct_cluster_rec_t *'s\non success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nList acct_storage_p_get_assocs(void *db_conn, uint32_t uid,\nacct_assoc_cond_t *assoc_cond)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nGet a list of acct_assoc_rec_t *'s based on the conditional sent.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the\nfunction.<br>\n<span class=\"commandline\">assoc_cond</span> (input) conditional about\nwhich associations are to be returned.  Association names should not need to\nbe stated.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">List</span> containing acct_assoc_rec_t *'s\non success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nList acct_storage_p_get_events(void *db_conn, uint32_t uid,\nacct_event_cond_t *event_cond)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nGet a list of acct_event_rec_t *'s based on the conditional sent.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the\nfunction.<br>\n<span class=\"commandline\">event_cond</span> (input) conditional about\nwhich events are to be returned.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">List</span> containing acct_event_rec_t *'s\non success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nList acct_storage_p_get_qos(void *db_conn, uint32_t uid,\nacct_qos_cond_t *qos_cond)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nGet a list of acct_qos_rec_t *'s based on the conditional sent.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the\nfunction.<br>\n<span class=\"commandline\">qos_cond</span> (input) conditional about\nwhich qos are to be returned.  Qos names should not need to\nbe stated.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">List</span> containing acct_qos_rec_t *'s\non success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nList acct_storage_p_get_wckeys(void *db_conn, uint32_t uid,\nacct_wckey_cond_t *wckey_cond)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nGet a list of acct_wckey_rec_t *'s based on the conditional sent.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the\nfunction.<br>\n<span class=\"commandline\">wckey_cond</span> (input) conditional about\nwhich wckeys are to be returned.  Wckey names should not need to\nbe stated.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">List</span> containing acct_wckey_rec_t *'s\non success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nList acct_storage_p_get_txn(void *db_conn, uint32_t uid,\nacct_txn_cond_t *txn_cond)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nGet a list of acct_txn_rec_t *'s (transactions) based on the conditional sent.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the\nfunction.<br>\n<span class=\"commandline\">txn_cond</span> (input) conditional about\nwhich transactions are to be returned.  Transaction ids should not need to\nbe stated.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">List</span> containing acct_txn_rec_t *'s\non success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nint acct_storage_p_get_usage(void *db_conn, uint32_t uid, void *in, int type,\ntime_t start, time_t end)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nGet usage for a specific association or wckey.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type.<br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the\nfunction.<br>\n<span class=\"commandline\">in</span> (input/out) can be anything that\ngathers usage like acct_assoc_rec_t * or acct_wckey_rec_t *.<br>\n<span class=\"commandline\">type</span> (input) really\nslurmdbd_msg_type_t should let the plugin know what the structure is\nthat was sent in some how.<br>\n<span class=\"commandline\">start</span> (input) start time of the usage.<br>\n<span class=\"commandline\">end</span> (input) end time of the usage.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint acct_storage_p_roll_usage(void *db_conn, time_t sent_start, time_t sent_end,\nuint16_t archive_data, rollup_stats_t *rollup_stats)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nroll up association, cluster, and wckey usage in the storage.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type.<br>\n<span class=\"commandline\">sent_start</span> (input) start time of the rollup.<br>\n<span class=\"commandline\">sent_end</span> (input) end time of the rollup.<br>\n<span class=\"commandline\">archive_data</span> (input) archive the results if not zero.<br>\n<span class=\"commandline\">rollup_stats</span> (input/output) performance statistics.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint clusteracct_storage_p_node_down(void *db_conn, char *cluster,\nstruct node_record *node_ptr, time_t event_time, char *reason)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nMark nodes down in the storage type.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type.<br>\n<span class=\"commandline\">cluster</span> (input) name of cluster node\nis on.<br>\n<span class=\"commandline\">node_ptr</span> (input) pointer to the node\nstructure marked down.<br>\n<span class=\"commandline\">event_time</span> (input) time event happened.<br>\n<span class=\"commandline\">reason</span> (input) if different from what\nis set in the node_ptr, the reason the node is down.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint clusteracct_storage_p_node_up(void *db_conn, char *cluster,\nstruct node_record *node_ptr, time_t event_time)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nMark nodes up in the storage type.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type.<br>\n<span class=\"commandline\">cluster</span> (input) name of cluster node\nis on.<br>\n<span class=\"commandline\">node_ptr</span> (input) pointer to the node\nstructure marked up.<br>\n<span class=\"commandline\">event_time</span> (input) time event happened.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint clusteracct_storage_p_cluster_procs(void *db_conn, char *cluster,\nchar *cluster_nodes, uint32_t procs, time_t event_time)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUpdate storage type with the current number of processors on a given cluster.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type. <br>\n<span class=\"commandline\">cluster</span> (input) name of cluster.<br>\n<span class=\"commandline\">cluster_nodes</span> (input) ranged list of\nnodes on system.<br>\n<span class=\"commandline\">procs</span> (input) number of processors on\nsystem.<br>\n<span class=\"commandline\">event_time</span> (input) time event happened.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint clusteracct_storage_p_get_usage(void *db_conn, uint32_t uid, void\n*cluster_rec, int type, time_t start, time_t end)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nGet usage for a specific cluster.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type.<br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the\nfunction.<br>\n<span class=\"commandline\">cluster_rec</span> (input/out)\nacct_cluster_rec_t * already set with the cluster name.  Usage will be\nfilled in.<br>\n<span class=\"commandline\">type</span> (input) really\nslurmdbd_msg_type_t should let the plugin know what the structure is\nthat was sent in some how for this it is just DBD_GET_CLUSTER_USAGE.<br>\n<span class=\"commandline\">start</span> (input) start time of the usage.<br>\n<span class=\"commandline\">end</span> (input) end time of the usage.<br>\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint clusteracct_storage_p_register_ctld(void *db_conn, char *cluster,\nuint16_t port)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUsed when a controller is turned on to tell the storage type where the\n  slurmctld for a given cluster is located at.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type.<br>\n<span class=\"commandline\">cluster</span> (input) name of cluster.<br>\n<span class=\"commandline\">port</span> (input) port on host cluster is\nrunning on the host is grabbed from the connection.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint clusteracct_storage_p_fini_ctld(void *db_conn, char *ip,\nuint16_t port, char *cluster_nodes)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUsed when a controller is turned off to tell the storage type the\n  slurmctld has gone away.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type.<br>\n<span class=\"commandline\">ip</span> (input) ip of connected slurmctld.<br>\n<span class=\"commandline\">port</span> (input) port on host cluster is\nrunning on the host is grabbed from the connection.<br>\n<span class=\"commandline\">cluster_nodes</span> (input) name of all\nnodes currently on the cluster.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint jobacct_storage_p_job_start(void *db_conn, struct job_record *job_ptr)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nNote that a job is about to begin execution or has just changed size.\nThe job's state will include the JOB_RESIZING flag if and only if it has\njust changed size. Otherwise the job is beginning execution for the first time.\nNote the existance of <i>resize_time</i> in the job record if one wishes to\nrecord information about a job at each size (i.e. a history of the job as\nits size changes through time).</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type.<br>\n<span class=\"commandline\">job_ptr</span> (input) information about the job in\nslurmctld.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint jobacct_storage_p_job_complete(void *db_conn, struct job_record *job_ptr)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nNote that a job is about to terminate or change size.\nThe job's state will include the JOB_RESIZING flag if and only if it is about\nto change size. Otherwise the job is terminating.\nNote the existance of <i>resize_time</i> in the job record if one wishes to\nrecord information about a job at each size (i.e. a history of the job as\nits size changes through time).</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type.<br>\n<span class=\"commandline\">job_ptr</span> (input) information about the job in\nslurmctld.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint jobacct_storage_p_step_start(void *db_conn, struct step_record *step_ptr)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\njobacct_storage_p_step_start() is called in the jobacct plugin at the\nallocation of a new step in the slurmctld, this inserts info about the\nbeginning of a step.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type.<br>\n<span class=\"commandline\">step_ptr</span> (input) information about the step in\nslurmctld.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint jobacct_storage_p_step_complete(void *db_conn, struct step_record *step_ptr)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\njobacct_storage_p_step_complete() is called in the jobacct plugin at\nthe end of a step in the slurmctld, this updates the ending\ninformation about a step.\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type.<br>\n<span class=\"commandline\">step_ptr</span> (input) information about the step in\nslurmctld.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint jobacct_storage_p_job_suspend(void *db_conn, struct job_record *job_ptr)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\njobacct_storage_p_suspend() is called in the jobacct plugin when a\njob is suspended or resumed in the slurmctld, this updates the\ndatabase about the suspended time of the job.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type.<br>\n<span class=\"commandline\">job_ptr</span> (input) information about the job in\nslurmctld.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">none</span>\n\n<p class=\"commandline\">\nList jobacct_storage_p_get_jobs_cond(void *db_conn, uint32_t uid,\nacct_job_cond_t *job_cond)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\njobacct_storage_p_get_jobs_cond() is called to get a list of jobs from the\ndatabase given the conditional.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type.<br>\n<span class=\"commandline\">uid</span> (input) uid of user calling the function.<br>\n<span class=\"commandline\">job_cond</span> (input) conditional about\nwhich jobs to get.  Job ids should not need to be stated.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">List of job_rec_t's</span> on success, or<br>\n<span class=\"commandline\">NULL</span> on failure.\n\n<p class=\"commandline\">\nint jobacct_storage_p_archive(void *db_conn, acct_archive_cond_t *arch_cond)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nused to archive old data.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type.<br>\n<span class=\"commandline\">arch_cond</span> (input) conditional about\nwhat to archive.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint jobacct_storage_p_archive_load(void *db_conn, acct_archive_rect *arch_rec)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nused to load old archive data.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type.<br>\n<span class=\"commandline\">arch_rec</span> (input) information about\nwhat to load.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint acct_storage_p_update_shares_used(void *db_conn, List acct_list)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUsed to update shares used in the storage type.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type.<br>\n<span class=\"commandline\">acct_list</span> (input) List of shares_used_object_t.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint acct_storage_p_flush_jobs_on_cluster(void *db_conn, char *cluster, time_t event_time)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nused to mark all jobs in the storage type as finished.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type.<br>\n<span class=\"commandline\">cluster</span> (input) name of cluster to\napply end to.<br>\n<span class=\"commandline\">event_time</span> (input) when the flush happened.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint acct_storage_p_reconfig(void *db_conn)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nReconfigure the plugin.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">db_conn</span> (input) connection to\nthe storage type.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"footer\"><a href=\"#top\">top</a>\n\n\n<h2>Parameters</h2>\n<p>These parameters can be used in the slurm.conf to set up\nconnections to the database all have defaults based on the plugin type\nused.\n<dl>\n<dt><span class=\"commandline\">AccountingStorageType</span>\n<dd>Specifies which plugin should be used.\n<dt><span class=\"commandline\">AccountingStorageLoc</span>\n<dd>Let the plugin the name of the logfile/database name to use.\n<dt><span class=\"commandline\">AccountingStorageHost</span>\n<dd>Let the plugin know the host where the database is.\n<dt><span class=\"commandline\">AccountingStoragePort</span>\n<dd>Let the plugin know the port to connect to.\n<dt><span class=\"commandline\">AccountingStorageUser</span>\n<dd>Let the plugin know the name of the user to connect to the\ndatabase with.\n<dt><span class=\"commandline\">AccountingStoragePass</span>\n<dd>Let the plugin know the password of the user connecting to the database.\n<dt><span class=\"commandline\">AccountingStorageEnforce</span>\n<dd>Specifies if we should enforce certain things be in existence\n  before allowing job submissions and such valid options are\n  \"associations, limits, qos, and wckeys\". You can use any combination\n  of those listed.\n</dl>\n\n<p class=\"footer\"><a href=\"#top\">top</a>\n\n<p style=\"text-align:center;\">Last modified 22 July 2016</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/taskplugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Slurm Task Plugin Programmer Guide</a></h1>\n\n<h2> Overview</h2>\n<p> This document describes Slurm task management plugins and the API\nthat defines them. It is intended as a resource to programmers wishing\nto write their own Slurm scheduler plugins.</p>\n\n<p>Slurm task management plugins are Slurm plugins that implement the\nSlurm task management API described herein. They would typically be\nused to control task affinity (i.e. binding tasks to processors).\nThey must conform to the Slurm Plugin API with the following\nspecifications:</p>\n<p><span class=\"commandline\">const char plugin_type[]</span><br>\nThe major type must be &quot;task.&quot; The minor type can be any recognizable\nabbreviation for the type of task management. We recommend, for example:</p>\n<ul>\n<li><b>affinity</b> &mdash; A plugin that implements task binding to processors.\nThe actual mechanism used to task binding is dependent upon the available\ninfrastructure as determined by the \"configure\" program when Slurm is built\nand the value of the <b>TaskPluginParam</b> as defined in the <b>slurm.conf</b>\n(Slurm configuration file).</li>\n<li><b>cgroup</b> &mdash; Use Linux cgroups for binding tasks to resources.</li>\n<li><b>none</b> &mdash; A plugin that implements the API without providing any\nservices. This is the default behavior and provides no task binding.</li>\n</ul>\n\n<p><span class=\"commandline\">const char plugin_name[]</span><br>\nSome descriptive name for the plugin.\nThere is no requirement with respect to its format.</p>\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loadeed by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<h2>Data Objects</h2>\n<p>The implementation must maintain (though not necessarily directly export) an\nenumerated <span class=\"commandline\">errno</span>  to allow Slurm to discover\nas practically as possible the reason for any failed API call.\nThese values must not be used as return values in integer-valued functions\nin the API. The proper error return value from integer-valued functions is\nSLURM_ERROR.</p>\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<h2>API Functions</h2>\n<p>The following functions must appear. Functions which are not implemented should\nbe stubbed.</p>\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\">int task_p_slurmd_batch_request (uint32_t job_id,\nbatch_job_launch_msg_t *req);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Prepare to launch a batch job.\nEstablish node, socket, and core resource availability for it.\nExecuted by the <b>slurmd</b> daemon as user root.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\">job_id</span>&nbsp;&nbsp;&nbsp;(input)\nID of the job to be started.<br>\n<span class=\"commandline\">req</span>&nbsp;&nbsp;&nbsp;(input/output)\nBatch job launch request specification.\nSee <b>src/common/slurm_protocol_defs.h</b> for the\ndata structure definition.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful.\nOn failure, the plugin should return SLURM_ERROR and set the errno to an\nappropriate value to indicate the reason for failure.</p>\n\n<p class=\"commandline\">int task_p_slurmd_launch_request (uint32_t job_id,\nlaunch_tasks_request_msg_t *req, uint32_t node_id);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Prepare to launch a job.\nEstablish node, socket, and core resource availability for it.\nExecuted by the <b>slurmd</b> daemon as user root.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\">job_id</span>&nbsp;&nbsp;&nbsp;(input)\nID of the job to be started.<br>\n<span class=\"commandline\">req</span>&nbsp;&nbsp;&nbsp;(input/output)\nTask launch request specification including node, socket, and\ncore specifications.\nSee <b>src/common/slurm_protocol_defs.h</b> for the\ndata structure definition.<br>\n<span class=\"commandline\">node_id</span>&nbsp;&nbsp;&nbsp;(input)\nID of the node on which resources are being acquired (zero origin).</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful.\nOn failure, the plugin should return SLURM_ERROR and set the errno to an\nappropriate value to indicate the reason for failure.</p>\n\n<p class=\"commandline\">int task_p_slurmd_reserve_resources (uint32_t job_id,\nlaunch_tasks_request_msg_t *req, uint32_t node_id);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Reserve resources for\nthe initiation of a job. Executed by the <b>slurmd</b> daemon as user root.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\">job_id</span>&nbsp;&nbsp;&nbsp;(input)\nID of the job being started.<br>\n<span class=\"commandline\">req</span>&nbsp;&nbsp;&nbsp;(input)\nTask launch request specification including node, socket, and\ncore specifications.\nSee <b>src/common/slurm_protocol_defs.h</b> for the\ndata structure definition.<br>\n<span class=\"commandline\">node_id</span>&nbsp;&nbsp;&nbsp;(input)\nID of the node on which the resources are being acquired\n(zero origin).</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful.\nOn failure, the plugin should return SLURM_ERROR and set the errno to an\nappropriate value to indicate the reason for failure.</p>\n\n<p class=\"commandline\">int task_p_slurmd_suspend_job (uint32_t job_id);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Temporarily release resources\npreviously reserved for a job.\nExecuted by the <b>slurmd</b> daemon as user root.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\">job_id</span>&nbsp;&nbsp;&nbsp;(input)\nID of the job which is being suspended.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful.\nOn failure, the plugin should return SLURM_ERROR and set the errno to an\nappropriate value to indicate the reason for failure.</p>\n\n<p class=\"commandline\">int task_p_slurmd_resume_job (uint32_t job_id);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Reclaim resources which\nwere previously released using the task_p_slurmd_suspend_job function.\nExecuted by the <b>slurmd</b> daemon as user root.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\">job_id</span>&nbsp;&nbsp;&nbsp;(input)\nID of the job which is being resumed.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful.\nOn failure, the plugin should return SLURM_ERROR and set the errno to an\nappropriate value to indicate the reason for failure.</p>\n\n<p class=\"commandline\">int task_p_slurmd_release_resources (uint32_t job_id);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Release resources previously\nreserved for a job. Executed by the <b>slurmd</b> daemon as user root.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\">job_id</span>&nbsp;&nbsp;&nbsp;(input)\nID of the job which has completed.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful.\nOn failure, the plugin should return SLURM_ERROR and set the errno to an\nappropriate value to indicate the reason for failure.</p>\n\n<p class=\"commandline\">int task_p_pre_setuid (stepd_step_rec_t *job);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: task_p_pre_setuid() is called\nbefore setting the UID for the user to launch his jobs.\nExecuted by the <b>slurmstepd</b> program as user root.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\">job</span>&nbsp;&nbsp;&nbsp;(input)\npointer to the job to be initiated.\nSee <b>src/slurmd/slurmstepd/slurmstepd_job.h</b> for the\ndata structure definition.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful.\nOn failure, the plugin should return SLURM_ERROR and set the errno to an\nappropriate value to indicate the reason for failure.</p>\n\n<p class=\"commandline\">int task_p_pre_launch_priv (stepd_step_rec_t *job);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: task_p_pre_launch_priv() is called\nby each forked task just after the fork. Note that no particular task related\ninformation is available in the job structure at that time.\nExecuted by the <b>slurmstepd</b> program as user root.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\">job</span>&nbsp;&nbsp;&nbsp;(input)\npointer to the job to be initiated.\nSee <b>src/slurmd/slurmstepd/slurmstepd_job.h</b> for the\ndata structure definition.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful.\nOn failure, the plugin should return SLURM_ERROR and set the errno to an\nappropriate value to indicate the reason for failure.</p>\n\n<p class=\"commandline\">int task_p_pre_launch (stepd_step_rec_t *job);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: task_p_pre_launch() is called\nprior to exec of application task.\nExecuted by the <b>slurmstepd</b> program as the job's owner.\nIt is followed by <b>TaskProlog</b> program (as configured in <b>slurm.conf</b>)\nand <b>--task-prolog</b> (from <b>srun</b> command line).</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\">job</span>&nbsp;&nbsp;&nbsp;(input)\npointer to the job to be initiated.\nSee <b>src/slurmd/slurmstepd/slurmstepd_job.h</b> for the\ndata structure definition.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful.\nOn failure, the plugin should return SLURM_ERROR and set the errno to an\nappropriate value to indicate the reason for failure.</p>\n\n<a name=\"get_errno\"><p class=\"commandline\">int task_p_post_term\n(stepd_step_rec_t *job, slurmd_task_p_info_t *task);</p></a>\n<p style=\"margin-left:.2in\"><b>Description</b>: task_p_term() is called\nafter termination of job step.\nExecuted by the <b>slurmstepd</b> program as the job's owner.\nIt is preceded by <b>--task-epilog</b> (from <b>srun</b> command line)\nfollowed by <b>TaskEpilog</b> program (as configured in <b>slurm.conf</b>).</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\">job</span>&nbsp;&nbsp;&nbsp;(input)\npointer to the job which has terminated.\nSee src/slurmd/slurmstepd/slurmstepd_job.h for the\ndata structure definition.<br>\n<span class=\"commandline\">task</span>&nbsp;&nbsp;&nbsp;(input)\npointer to the task which has terminated.\nSee src/slurmd/slurmstepd/slurmstepd_job.h for the\ndata structure definition.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful.\nOn failure, the plugin should return SLURM_ERROR and set the errno to an\nappropriate value to indicate the reason for failure.</p>\n\n<p class=\"commandline\">int task_p_post_step (stepd_step_rec_t *job);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: task_p_post_step() is called\nafter termination of all the tasks of the job step.\nExecuted by the <b>slurmstepd</b> program as user root.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\">job</span>&nbsp;&nbsp;&nbsp;(input)\npointer to the job which has terminated.\nSee <b>src/slurmd/slurmstepd/slurmstepd_job.h</b> for the\ndata structure definition.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful.\nOn failure, the plugin should return SLURM_ERROR and set the errno to an\nappropriate value to indicate the reason for failure.</p>\n\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<p style=\"text-align:center;\">Last modified 27 March 2015</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/node_features_plugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Node Features Plugin Programmer Guide</a></h1>\n\n<h2> Overview</h2>\n<p>This document describes the node features plugin that is responsible for\nmanaging a node's active features. This is typically used for changing a node's\ncharacteristics at boot time. For example, an Intel Knights Landing (KNL)\nprocessor can be booted in various MCDRAM and NUMA modes.\nThis document is intended as a resource to programmers wishing to write their\nown node features plugin.</p>\n\n<p><span class=\"commandline\">const char\nplugin_name[]=\"<i>launch&nbsp;Slurm&nbsp;plugin</i>\"</span>\n<p style=\"margin-left:.2in\">\n\n<p><span class=\"commandline\">const char\nplugin_type[]=\"<i>node_features/[knl_cray]</i>\"</span><br>\n<p style=\"margin-left:.2in\">\n\n<ul>\n<li><b>knl_cray</b> &mdash; Use Cray's capmc command to manage an Intel KNL processor.</li>\n<li><b>knl_generic</b> &mdash; Use Intel commands to manage KNL processor.</li>\n</ul>\n\n<p><span class=\"commandline\">const uint32_t plugin_version=SLURM_VERSION_NUMBER</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loadeed by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<p>The programmer is urged to study\n<span class=\"commandline\">src/plugins/node_features/knl_cray/node_features_knl_cray.c</span>\nfor a sample implementation of a Slurm node features plugin.\n<p class=\"footer\"><a href=\"#top\">top</a>\n\n<h2>API Functions</h2>\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> int fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\"> bool node_features_p_changible_feature(char *feature)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Determine if this (one) specified node feature is under the control of this plugin.\n  The feature must be in a node's available features in order for the node to be\n  reconfigured and the feature become active.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n  <span class=\"commandline\"> feature:</span> One node feature.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">true</span> this feature can be set by this plugin<br>\n  <span class=\"commandline\">false</span> this feature can not be et this plugin.</p>\n\n<p class=\"commandline\"> int node_features_p_reconfig(void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Note that the configuration has changed, read configuration parameters again.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> uint32_t node_features_p_boot_time(void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Return the estimated node reboot time in units of seconds.\n  Used as a basis for optimizing scheduling decisions.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  Estimated boot time in seconds.</p>\n\n<p class=\"commandline\"> int node_features_p_get_node(char *node_list)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Update active and available features on specified nodes.\n  Executed from the slurmctld daemon only and directly updates internal\n  node data structures.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n  <span class=\"commandline\"> node_list:</span> Regular expression identifying\n  the nodes to be updated. Update information about all nodes is value is NULL.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> int node_features_p_job_valid(char *job_features)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Determine of the user's job constraint string is valid.\n  This may be used to limit the type of operators supported (Slurm's active\n  feature logic only supports the AND operator) and prevent illegal\n  combintations of node features (e.g. multiple NUMA modes).\n  Executed from the slurmctld daemon only when either the job submit or\n  modify operation is invoked.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n  <span class=\"commandline\"> job_features:</span> Job constraints specified by\n  the user (-c/--constraint options).<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> char *node_features_p_job_xlate(char *job_features)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Translate a job's feature request to the node features needed at boot time.\n  Job features not required by this plugin (e.g. rack number) will not be\n  returned. For example, a user requested features may be \"cache&quad&knl&rack1\".\n  Since the \"knl\" and \"rack1\" represent physical characteristics of the node\n  and are not used by the node features plugin to boot the node, this function's\n  return value will be \"cache,quad\".\n  Executed from the slurmctld daemon only.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n  <span class=\"commandline\"> job_features:</span> Job constraints specified by\n  the user (-c/--constraint options).<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  Node features used by this plugin when configuring or booting a node.\n  A string with it's memory allocated by xmalloc (i.e. the return value\n  must be released using Slurm's xfree function).</p>\n\n<p class=\"commandline\"> bool node_features_p_node_power(void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Report if the PowerSave mode is required to boot nodes.\n  Executed from the slurmctld daemon only.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  True if the plugin requires PowerSave mode for booting nodes.\n\n<p class=\"commandline\"> void node_features_p_node_state(char **avail_modes, char **current_mode)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Get this node's available and current features (e.g. MCDRAM and NUMA\n  settings from BIOS for a KNL processor, for example\n  avail_modes=\"cache,flat,equal,a2a,quad,hemi,snc2,snc4\" and\n  current_mode=\"cache,quad\").\n  Executed from the slurmd daemon only.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n  <span class=\"commandline\"> avail_modes:</span> Nodes state features which are\n  available. Value is allocated or appended to as appropriate with xmalloc functions.<br>\n  <span class=\"commandline\"> current_modes:</span> Nodes state features which\n  are currently in effect. Value is allocated or appended to as appropriate\n  with xmalloc functions.</p>\n\n<p class=\"commandline\"> bool node_features_g_node_update_valid(void *node_ptr, update_node_msg_t *update_node_msg)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Determine if this node update request is valid. For example, validate that a\n   non-KNL node does not include any MCDRAM or NUMA modes that are KNL specific.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n  <span class=\"commandline\"> node_ptr:</span> Pointer to struct node_record record\n  being updated.<br>\n  <span class=\"commandline\"> update_node_msg:</span> Node update request.</br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  True if the update request is valid, otherwise false.</p>\n\n<p class=\"commandline\"> char *node_features_p_node_xlate(char *new_features, char *orig_features, char *avail_features)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Translate a node's new active feature specification as needed to preserve any\n  original features (i.e. features outside of the domain of this plugin).\n  Also validate that the new features are a subset of available features.\n  For example, a node's new features may be \"cache,quad\", while it's original\n  features may have been \"knl,rack1,flat,hemi\".\n  The original plugin-specific features are \"flat,hemi\", while\n  features configured outside of the domain of this plugin are \"knl,rack1\".\n  In this case, this function's return value will be \"knl,rack1,cache,quad\".\n  This function may also be used to ensure a specific ordering of features\n  (e.g. on a KNL node, always put the MCDRAM mode before the NUMA mode).\n  Executed from the slurmctld daemon only.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n  <span class=\"commandline\"> new_features:</span> Node's new active features.<br>\n  <span class=\"commandline\"> orig_features:</span> Node's previous active feature state.<br>\n  <span class=\"commandline\"> avail_features:</span> Node's available features.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  Node's currently active features, validate and sorted.\n  A string with it's memory allocated by xmalloc (i.e. the return value\n  must be released using Slurm's xfree function).</p>\n\n<p class=\"commandline\"> char *node_features_p_node_xlate2(char *new_features)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Translate a node's newly configured available feature specification as needed\n  to order the entries as desired.\n  For example on a KNL node, always put the MCDRAM mode before the NUMA mode\n  (i.e. an input of \"hemi,flat\" is translated to \"flat,hemi\").\n  Executed from the slurmctld daemon only.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n  <span class=\"commandline\"> new_features:</span> Node's newly configured features.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  Node's currently available features, validate and sorted.\n  A string with it's memory allocated by xmalloc (i.e. the return value\n  must be released using Slurm's xfree function).</p>\n\n<p class=\"commandline\"> void node_features_p_step_config(bool mem_sort, bitstr_t *numa_bitmap)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Perform any desired initialization operations prior to launching a job step.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n  <span class=\"commandline\"> mem_sort:</span> If true, run zonesort before launching a job step.<br>\n  <span class=\"commandline\"> numa_bitmap:</span> Identify NUMA nodes on which to execute zonesort.\n  If NULL, then execute zonesort on all NUMA nodes</p>\n\n<p class=\"commandline\"> char *node_features_p_user_update(uid_t uid)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Determine if the specified user can modify the currently available node\n  features.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n  <span class=\"commandline\"> uid:</span> User ID of user making request.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  True if user can change node active features to other available features.</p>\n\n<p class=\"footer\"><a href=\"#top\">top</a>\n\n<p style=\"text-align:center;\">Last modified 31 October 2017</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/checkpoint_plugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Slurm Job Checkpoint Plugin Programmer Guide</a></h1>\n\n<h2> Overview</h2>\n<p> This document describes Slurm job checkpoint plugins and the API that defines\nthem. It is intended as a resource to programmers wishing to write their own SLURM\njob checkpoint plugins.</p>\n\n<p>Slurm job checkpoint plugins are Slurm plugins that implement the SLURM\nAPI for checkpointing and restarting jobs.\nThe plugins must conform to the Slurm Plugin API with the following specifications:</p>\n\n<p><span class=\"commandline\">const char plugin_type[]</span><br>\nThe major type must be &quot;checkpoint.&quot; The minor type can be any recognizable\nabbreviation for the type of checkpoint mechanism.\nWe recommend, for example:</p>\n<ul>\n<li><b>blcr</b> &mdash;\n<a href=\"https://upc-bugs.lbl.gov/blcr/doc/html/\">\nBerkeley Lab Checkpoint/Restart (BLCR)</a></li>\n<li><b>none</b> &mdash; No job checkpoint.</li>\n<li><b>ompi</b> &mdash; OpenMPI checkpoint (requires OpenMPI version 1.3 or higher).</li>\n</ul></p>\n\n<p><span class=\"commandline\">const char plugin_name[]</span><br>\nSome descriptive name for the plugin.\nThere is no requirement with respect to its format.</p>\n\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loaded by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<p>The programmer is urged to study\n<span class=\"commandline\">src/plugins/checkpoint/blcr/checkpoint_blcr.c</span>\nfor a sample implementation of a Slurm job checkpoint plugin.</p>\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<h2>Data Objects</h2>\n<p>The implementation must maintain (though not necessarily directly export) an\nenumerated <span class=\"commandline\">errno</span> to allow Slurm to discover\nas practically as possible the reason for any failed API call. Plugin-specific enumerated\ninteger values may be used when appropriate.\n\n<p>These values must not be used as return values in integer-valued functions\nin the API. The proper error return value from integer-valued functions is SLURM_ERROR.\nThe implementation should endeavor to provide useful and pertinent information by\nwhatever means is practical.\nSuccessful API calls are not required to reset any errno to a known value. However,\nthe initial value of any errno, prior to any error condition arising, should be\nSLURM_SUCCESS. </p>\n\n<p>There is also a checkpoint-specific error code and message that may be associated\nwith each job step.</p>\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<h2>API Functions</h2>\n<p>The following functions must appear. Functions which are not implemented should\nbe stubbed.</p>\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the SLURM\n<span class=\"commandline\">init()</span>, and the SLURM\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\">int slurm_ckpt_alloc_job (check_jobinfo_t *jobinfo);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Allocate storage for job-step specific\ncheckpoint data.</p>\n<p style=\"margin-left:.2in\"><b>Argument</b>:\n<b>jobinfo</b> (output) returns pointer to the allocated storage.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int slurm_ckpt_free_job (check_jobinfo_t jobinfo);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Release storage for job-step specific\ncheckpoint data that was previously allocated by slurm_ckpt_alloc_job.</p>\n<p style=\"margin-left:.2in\"><b>Argument</b>:\n<b>jobinfo</b> (input) pointer to the previously allocated storage.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int slurm_ckpt_pack_job (check_jobinfo_t jobinfo, Buf buffer, uint16_t protocol_version);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Store job-step specific checkpoint data\ninto a buffer.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<b>jobinfo</b> (input) pointer to the previously allocated storage.<br>\n<b>Buf</b> (input/output) buffer to which jobinfo has been appended.<br>\n<b>protocol_version</b> (input) communication protocol version.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int slurm_ckpt_unpack_job (check_jobinfo_t jobinfo, Buf buffer, uint16_t protocol_version);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Retrieve job-step specific checkpoint data\nfrom a buffer.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:</br>\n<b>jobinfo</b> (output) pointer to the previously allocated storage.<br>\n<b>Buf</b> (input/output) buffer to which jobinfo has been appended.<br>\n<b>protocol_version</b> (input) communication protocol version.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n\n<p class=\"commandline\">check_jobinfo_t slurm_ckpt_copy_job (check_jobinfo_t jobinfo);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Duplicate job-step specific checkpoint data.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:</br>\n<b>jobinfo</b> (input) pointer to the previously allocated storage.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: copy of jobinfo if successful. NULL on failure.</p>\n\n<p class=\"commandline\">int slurm_ckpt_op ( uint32_t job_id, uint32_t step_id,\nstruct step_record *step_ptr, uint16_t op, uint16_t data,\nchar *image_dir, time_t *event_time,\nuint32_t *error_code, char **error_msg );</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Perform some checkpoint operation on a\nspecific job step.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<b>job_id</b> (input) identifies the job to be operated upon.\nMay be SLURM_BATCH_SCRIPT for a batch job or NO_VAL for all steps of the\nspecified job.</br>\n<b>step_id</b> (input) identifies the job step to be operated upon.<br>\n<b>step_ptr</b> (input) pointer to the job step to be operated upon.\nUsed by checkpoint/aix only.<br>\n<b>op</b> (input) specifies the operation to be performed.\nCurrently supported operations include\nCHECK_ABLE (is job step currently able to be checkpointed),\nCHECK_DISABLE (disable checkpoints for this job step),\nCHECK_ENABLE (enable checkpoints for this job step),\nCHECK_CREATE (create a checkpoint for this job step and continue its execution),\nCHECK_VACATE (create a checkpoint for this job step and terminate it),\nCHECK_RESTART (restart this previously checkpointed job step), and\nCHECK_ERROR (return checkpoint-specific error information for this job step).<br>\n<b>data</b> (input) operation-specific data.<br>\n<b>image_dir</b> (input) directory to be used to save or restore state.<br>\n<b>event_time</b> (output) identifies the time of a checkpoint or restart\noperation.</br>\n<b>error_code</b> (output) returns checkpoint-specific error code\nassociated with an operation.</br>\n<b>error_msg</b> (output) identifies checkpoint-specific error message\nassociated with an operation.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\nSLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the error_code and error_msg\nto an appropriate value to indicate the reason for failure.</p>\n\n<p class=\"commandline\">int slurm_ckpt_comp ( struct step_record * step_ptr, time_t event_time,\nuint32_t error_code, char *error_msg );</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Note the completion of a checkpoint operation.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<b>step_ptr</b> (input/output) identifies the job step to be operated upon.</br>\n<b>event_time</b> (input) identifies the time that the checkpoint operation\nbegan.</br>\n<b>error_code</b> (input) checkpoint-specific error code associated\nwith an operation.</br>\n<b>error_msg</b> (input) checkpoint-specific error message associated\nwith an operation.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the error_code and error_msg to an\nappropriate value to indicate the reason for failure.</p>\n\n<p class=\"commandline\">int slurm_ckpt_stepd_prefork ( void *slurmd_job );</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Do preparation work for\nthe checkpoint/restart support. This function is called by <b>slurmstepd</b>\nbefore forking the user tasks.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<b>slurmd_job</b> (input) pointer to job structure internal to slurmstepd.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful.\nOn failure, the plugin should return SLURM_ERROR and set the error_code\nand error_msg to an appropriate value to indicate the reason for failure.</p>\n\n<p class=\"commandline\">int slurm_ckpt_signal_tasks ( void *slurmd_job,\nchar *image_dir );</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Forward the checkpoint\nrequest to tasks managed by <b>slurmstepd</b>.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<b>slurmd_job</b> (input) pointer to job structure internal to slurmstepd.</br>\n<b>image_dir</b> (input) directory to be used to save or restore state.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful.\nOn failure, the plugin should return SLURM_ERROR and set the error_code\nand error_msg to an appropriate value to indicate the reason for failure.</p>\n\n<p class=\"commandline\">int slurm_ckpt_restart_task ( void *slurmd_job,\nchar *image_dir, int gtid);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Restart the execution\nof a tasks from a checkpoint image, called by <b>slurmstepd</b>.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<b>slurmd_job</b> (input) pointer to job structure internal to slurmstepd.<br>\n<b>image_dir</b> (input) directory to be used to save or restore state.<br>\n<b>gtid</b> (input) global task ID to be restarted</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful.\nOn failure, the plugin should return SLURM_ERROR and set the error_code\nand error_msg to an appropriate value to indicate the reason for failure.</p>\n\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<p style=\"text-align:center;\">Last modified 27 March 2015</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/slurmctld_plugstack.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Slurmctld Generic Plugin Programmer Guide</a></h1>\n\n<h2> Overview</h2>\n\n<p> This document describes slurmctld daemon's generic plugins and the API that\ndefines them. It is intended as a resource to programmers wishing to write\ntheir own slurmctld generic plugins. This is version 100 of the API.\n\n<p>The slurmctld generic plugin must conform to the\nSlurm Plugin API with the following specifications:\n\n<p><span class=\"commandline\">const char\nplugin_name[]=\"<i>full&nbsp;text&nbsp;name</i>\"</span>\n<p style=\"margin-left:.2in\">\nA free-formatted ASCII text string that identifies the plugin.\n\n<p><span class=\"commandline\">const char\nplugin_type[]=\"<i>major/minor</i>\"</span><br>\n<p style=\"margin-left:.2in\">\nThe major type must be &quot;slurmctld_plugstack.&quot;\nThe minor type can be any suitable name for the type of slurmctld package.\nSlurm can be configured to use multiple slurmctld_plugstack plugins if desired.</p>\n\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loadeed by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<h2>API Functions</h2>\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the SLURM\n<span class=\"commandline\">init()</span>, and the SLURM\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p>Only the init and fini functions of the plugin will be called.\nThe init function will be called when the slurmctld daemon begins accepting RPCs.\nThe fini function will be called when the slurmctld daemon stops accepting RPCs.\nIn the case of the backup slurmctld daemon, the init and fini functions may\nbe called multiple times (when it assumes control functions and then when it\nreliquishes them to the primary slurmctld daemon).</p>\n\n<p class=\"footer\"><a href=\"#top\">top</a>\n\n<p style=\"text-align:center;\">Last modified 27 March 2015</p>\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/switchplugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Slurm Switch Plugin API</a></h1>\n\n<h2> Overview</h2>\n<p> This document describe. Slurm switch (interconnect) plugins and the API that defines\nthem. It is intended as a resource to programmers wishing to write their own SLURM\nswitch plugins.\nNote that many of the API functions are used only by one of the daemons. For\nexample the slurmctld daemon builds a job step's switch credential\n(<span class=\"commandline\">switch_p_build_jobinfo</span>) while the\nslurmd daemon enables and disables that credential for the job step's\ntasks on a particular node(<span class=\"commandline\">switch_p_job_init</span>,\netc.). </p>\n\n<p>Slurm switch plugins are Slurm plugins that implement the Slurm switch or interconnect\nAPI described herein. They must conform to the Slurm Plugin API with the following\nspecifications:</p>\n<p><span class=\"commandline\">const char plugin_type[]</span><br>\nThe major type must be &quot;switch.&quot; The minor type can be any recognizable\nabbreviation for the type of switch. We recommend, for example:</p>\n<ul>\n<li><b>none</b> &mdash; A plugin that implements the API without providing any actual\nswitch service. This is the case for Ethernet and Myrinet interconnects.</li>\n<li><b>nrt</b> &mdash; IBM Network Resource Table API.</li>\n</ul>\n\n<p><span class=\"commandline\">const char plugin_name[]</span><br>\nSome descriptive name for the plugin.\nThere is no requirement with respect to its format.</p>\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loadeed by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<h2>Data Objects</h2>\n<p> The implementation must support two opaque data classes.\nOne is used as an job step's switch &quot;credential.&quot;\nThis class must encapsulate all job step specific information necessary\nfor the operation of the API specification below.\nThe second is a node's switch state record.\nBoth data classes are referred to in Slurm code using an anonymous\npointer (void *).</p>\n\n<p>The implementation must maintain (though not necessarily directly export) an\nenumerated <span class=\"commandline\">errno</span>  to allow Slurm to discover\nas practically as possible the reason for any failed API call. Plugin-specific enumerated\ninteger values should be used when appropriate. It is desirable that these values\nbe mapped into the range ESLURM_SWITCH_MIN and ESLURM_SWITCH_MAX\nas defined in <span class=\"commandline\">slurm/slurm_errno.h</span>.\nThe error number should be returned by the function\n<a href=\"#get_errno\"><span class=\"commandline\">switch_p_get_errno()</span></a>\nand this error number can be converted to an appropriate string description using the\n<a href=\"#strerror\"><span class=\"commandline\">switch_p_strerror()</span></a>\nfunction described below.</p>\n\n<p>These values must not be used as return values in integer-valued functions\nin the API. The proper error return value from integer-valued functions is SLURM_ERROR.\nThe implementation should endeavor to provide useful and pertinent information by\nwhatever means is practical. In some cases this means an errno for each credential,\nsince plugins must be re-entrant. If a plugin maintains a global errno in place of or in\naddition to a per-credential errno, it is not required to enforce mutual exclusion on it.\nSuccessful API calls are not required to reset any errno to a known value. However,\nthe initial value of any errno, prior to any error condition arising, should be\nSLURM_SUCCESS. </p>\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<h2>API Functions</h2>\n<p>The following functions must appear. Functions which are not implemented should\nbe stubbed.</p>\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the SLURM\n<span class=\"commandline\">init()</span>, and the SLURM\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<h3>Global Switch State Functions</h3>\n<p class=\"commandline\">int switch_p_libstate_save (char *dir_name);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Save any global switch state to a file\nwithin the specified directory. The actual file name used is plugin specific. It is recommended\nthat the global switch state contain a magic number for validation purposes. This function\nis called by the slurmctld daemon on shutdown. Note that if the slurmctld daemon fails,\nthis function will not be called. The plugin may save state independently and/or make\nuse of the switch_p_job_step_allocated function to restore state.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<span class=\"commandline\"> dir_name</span>&nbsp;\n&nbsp;&nbsp;(input) fully-qualified pathname of a directory into which user SlurmUser (as defined\nin slurm.conf) can create a file and write state information into that file. Cannot be NULL.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int switch_p_libstate_restore(char *dir_name, bool recover);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Restore any global switch state from a file\nwithin the specified directory. The actual file name used is plugin specific. It is recommended\nthat any magic number associated with the global switch state be verified. This function\nis called by the slurmctld daemon on startup.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> dir_name</span>&nbsp;\n&nbsp;&nbsp;(input) fully-qualified pathname of a directory containing a state information file\nfrom which user SlurmUser (as defined in slurm.conf) can read. Cannot be NULL.<br>\n<span class=\"commandline\"><span class=\"commandline\"> recover</span>&nbsp;\ntrue of restart with state preserved, false if no state recovery. </p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int switch_p_libstate_clear (void);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Clear switch state information.\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<h3>Node's Switch State Monitoring Functions</h3>\n\n<p>Nodes will register with current switch state information when the slurmd daemon\nis initiated. The slurmctld daemon will also request that slurmd supply current\nswitch state information on a periodic basis.</p>\n\n<p class=\"commandline\">int switch_p_clear_node_state (void);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Initialize node state.\nIf any switch state has previously been established for a job step, it will be cleared.\nThis will be used to establish a \"clean\" state for the switch on the node upon\nwhich it is executed.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int switch_p_alloc_node_info(switch_node_info_t *switch_node);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Allocate storage for a node's switch\nstate record. It is recommended that the record contain a magic number for validation\npurposes.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<span class=\"commandline\"> switch_node</span>&nbsp;\n&nbsp;&nbsp;(output) location for writing location of node's switch state record.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int switch_p_build_node_info(switch_node_info_t switch_node);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Fill in a previously allocated switch state\nrecord for the node on which this function is executed.\nIt is recommended that the magic number be validated.\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int switch_p_pack_node_info (switch_node_info_t switch_node,\nBuf buffer);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Pack the data associated with a\nnode's switch state into a buffer for network transmission.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> switch_node</span>&nbsp; &nbsp;&nbsp;(input) an existing\nnode's switch state record.<br>\n<span class=\"commandline\"> buffer</span>&nbsp; &nbsp;&nbsp;(input/output) buffer onto\nwhich the switch state information is appended.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>:\nThe number of bytes written should be returned if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int switch_p_unpack_node_info (switch_node_info_t **switch_node,\nBuf buffer);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Allocate and unpack\n  the data associated with a node's switch state record from a buffer.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> switch_node</span>&nbsp; &nbsp;&nbsp;(output) a\nnode switch state record will be allocated and filled in with data read from\nthe buffer.<br>\n<span class=\"commandline\"> buffer</span>&nbsp; &nbsp;&nbsp;(input/output) buffer from\nwhich the record's contents are read.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">void switch_p_free_node_info (switch_node_info_t switch_node);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Release the storage associated with\na node's switch state record.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<span class=\"commandline\"> switch_node</span>&nbsp;\n&nbsp;&nbsp;(input/output) a previously allocated node switch state record.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: None</p>\n\n<p class=\"commandline\">char * switch_p_sprintf_node_info (switch_node_info_t switch_node,\nchar *buf, size_t size);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Print the contents of a node's switch state\nrecord to a buffer.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> switch_node</span>&nbsp; &nbsp;&nbsp;(input) a\nnode's switch state record.<br>\n<span class=\"commandline\"> buf</span>&nbsp; &nbsp;&nbsp;(input/output) point to\nbuffer into which the switch state record is to be written.<br>\nof buf in bytes.<br>\n<span class=\"commandline\"> size</span>&nbsp; &nbsp;&nbsp;(input) size\nof buf in bytes.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: Location of buffer, same as <i>buf</i>.</p>\n\n<h3>Job's Switch Credential Management Functions</h3>\n<p class=\"commandline\">int switch_p_alloc_jobinfo(switch_jobinfo_t\n  *switch_job, uint32_t job_id, uint32_t step_id);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Allocate storage for a job step's switch credential.\nIt is recommended that the credential contain a magic number for validation purposes.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> switch_job</span>&nbsp;\n&nbsp;&nbsp;(output) location for writing location of job step's\nswitch credential.\n<span class=\"commandline\"> job_id</span>&nbsp; &nbsp;&nbsp;(input) the\njob id for this job step NO_VAL for not set.<br>\n<span class=\"commandline\"> step_id</span>&nbsp; &nbsp;&nbsp;(input) the\nstep id for this job step NO_VAL for not set.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int switch_p_build_jobinfo (switch_jobinfo_t switch_job,\nslurm_step_layout_t *step_layout, char *network);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Build a job's switch credential.\nIt is recommended that the credential's magic number be validated.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\">switch_job</span>&nbsp; &nbsp;&nbsp;(input/output) Job's\nswitch credential to be updated<br>\n<span class=\"commandline\">step_layout</span>&nbsp;&nbsp;&nbsp; (input) the layout of the step with at least the node_list, tasks and tids set.<br>\n<span class=\"commandline\">network</span>&nbsp;&nbsp;&nbsp; (input) Job step's network\nspecification from srun command. </p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">switch_jobinfo_t switch_p_copy_jobinfo  (switch_jobinfo_t switch_job);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Allocate storage for a job's switch credential\nand copy an existing credential to that location.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<span class=\"commandline\"> switch_job</span>&nbsp;\n&nbsp;&nbsp;(input) an existing job step switch credential.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: A newly allocated job step switch\ncredential containing a copy of the function argument.</p>\n\n<p class=\"commandline\">void switch_p_free_jobinfo (switch_jobinfo_t switch_job);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Release the storage associated with a job's\n switch credential.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<span class=\"commandline\"> switch_job</span>&nbsp;\n&nbsp;&nbsp;(input) an existing job step switch credential.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: None</p>\n\n<p class=\"commandline\">int switch_p_pack_jobinfo (switch_jobinfo_t switch_job, Buf buffer);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Pack the data associated with a job step's\nswitch credential into a buffer for network transmission.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> switch_job</span>&nbsp; &nbsp;&nbsp;(input) an\nexisting job step switch credential.<br>\n<span class=\"commandline\"> buffer</span>&nbsp; &nbsp;&nbsp;(input/output) buffer onto\nwhich the credential's contents are appended.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>:\nThe number of bytes written should be returned if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int switch_p_unpack_jobinfo (switch_jobinfo_t **switch_job, Buf buffer);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Allocate and unpack the data associated with a job's\nswitch credential from a buffer.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> switch_job</span>&nbsp;\n&nbsp;&nbsp;(output) a job step switch credential will be allocated and filled in with data read from the buffer.<br>\n<span class=\"commandline\"> buffer</span>&nbsp; &nbsp;&nbsp;(input/output) buffer from\nwhich the credential's contents are read.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int switch_p_get_jobinfo (switch_jobinfo_t switch_job, int data_type, void *data);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Get some specific data from a job's switch credential.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> switch_job</span>&nbsp; &nbsp;&nbsp;(input) a job's switch credential.<br>\n<span class=\"commandline\"> data_type</span>&nbsp; &nbsp;&nbsp;(input) identification\nas to the type of data requested. The interpretation of this value is plugin dependent.<br>\n<span class=\"commandline\"> data</span>&nbsp; &nbsp;&nbsp;(output) filled in with the desired\ndata. The form of this data is dependent upon the value of data_type and the plugin.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int switch_p_job_step_complete (switch_jobinfo_t switch_job,\nchar *nodelist);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Note that the job step associated\nwith the specified nodelist has completed execution.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> switch_job</span> &nbsp;&nbsp;&nbsp;(input)\nThe completed job step's switch credential.<br>\n<span class=\"commandline\"> nodelist</span>&nbsp; &nbsp;&nbsp;(input) A list of nodes\non which the job step has completed. This may contain expressions to specify\nnode ranges. (e.g. \"linux[1-20]\" or \"linux[2,4,6,8]\").</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int switch_p_job_step_part_comp (switch_jobinfo_t switch_job,\nchar *nodelist);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Note that the job step has completed\nexecution on the specified node list. The job step is not necessarily completed on all\nnodes, but switch resources associated with it on the specified nodes are no longer\nin use.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> switch_job</span> &nbsp;&nbsp;&nbsp;(input)\nThe completed job's switch credential.<br>\n<span class=\"commandline\"> nodelist</span>&nbsp; &nbsp;&nbsp;(input) A list of nodes\non which the job step has completed. This may contain expressions to specify node ranges.\n(e.g. \"linux[1-20]\" or \"linux[2,4,6,8]\").</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">bool switch_p_part_comp (void);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Indicate if the switch plugin should\nprocess partial job step completions (i.e. switch_g_job_step_part_comp). Support\nof partition completions is compute intensive, so it should be avoided unless switch\nresources are in short supply (e.g. former switch/nrt).</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: True if partition step completions are\nto be recorded. False if only full job step completions are to be noted.</p>\n\n<p class=\"commandline\">void switch_p_print_jobinfo(FILE *fp, switch_jobinfo_t switch_job);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Print the contents of a job's\nswitch credential to a file.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> fp</span>&nbsp; &nbsp;&nbsp;(input) pointer to an open file.<br>\n<span class=\"commandline\"> switch_job</span>&nbsp; &nbsp;&nbsp;(input) a job's\nswitch credential.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p class=\"commandline\">char *switch_p_sprint_jobinfo(switch_jobinfo_t switch_job,\nchar *buf, size_t size);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Print the contents of a job's\nswitch credential to a buffer.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> switch_job</span>&nbsp; &nbsp;&nbsp;(input) a job's\nswitch credential.<br>\n<span class=\"commandline\"> buf</span>&nbsp; &nbsp;&nbsp;(input/output) pointer to\nbuffer into which the job credential information is to be written.<br>\n<span class=\"commandline\"> size</span>&nbsp; &nbsp;&nbsp;(input) size of buf in\nbytes</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: location of buffer, same as <i>buf</i>.</p>\n\n<p class=\"commandline\">int switch_p_get_data_jobinfo(switch_jobinfo_t switch_job,\nint key, void *resulting_data);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Get data from a job step's\nswitch credential.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> switch_job</span>&nbsp; &nbsp;&nbsp;(input) a job\nstep's switch credential.<br>\n<span class=\"commandline\"> key</span>&nbsp; &nbsp;&nbsp;(input) identification\nof the type of data to be retrieved from the switch credential. NOTE: The\ninterpretation of this key is dependent upon the switch type. <br>\n<span class=\"commandline\"> resulting_data</span>&nbsp; &nbsp;&nbsp;(input/output)\npointer to where the requested data should be stored. </p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<h3>Node Specific Switch Management Functions</h3>\n<p class=\"commandline\">int switch_p_node_init (void);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: This function is run from the top level slurmd\nonly once per slurmd run. It may be used, for instance, to perform some one-time\ninterconnect setup or spawn an error handling thread.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<span class=\"commandline\"> None</span></p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int switch_p_node_fini (void);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: This function is called once as slurmd exits\n(slurmd will wait for this function to return before continuing the exit process).</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<span class=\"commandline\"> None</span></p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<h3>Job Step Management Functions</h3>\n<pre>\n=========================================================================\nProcess 1 (root)        Process 2 (root, user)  |  Process 3 (user task)\n                                                |\nswitch_p_job_preinit                            |\nfork ------------------ switch_p_job_init       |\nwaitpid                 setuid, chdir, etc.     |\n                        fork N procs -----------+--- switch_p_job_attach\n                        wait all                |    exec mpi process\n                        switch_p_job_fini*      |\nswitch_p_job_postfini                           |\n=========================================================================\n</pre>\n\n<p class=\"commandline\">int switch_p_job_preinit (switch_jobinfo_t jobinfo switch_job);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Preinit is run as root in the first slurmd process,\nthe so called job step manager. This function can be used to perform any initialization\nthat needs to be performed in the same process as switch_p_job_fini().</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\"> switch_job</span>&nbsp; &nbsp;&nbsp;(input) a job's\nswitch credential.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int switch_p_job_init (stepd_step_rec_t *job, uid_t uid);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Initialize interconnect on node for a job.\nThis function is run from the second slurmd process (some interconnect implementations\nmay require the switch_p_job_init functions to be executed from a separate process\nthan the process executing switch_p_job_fini() [e.g. Quadrics Elan]).</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> job</span>&nbsp; &nbsp;&nbsp;(input)\nstructure representing the slurmstepd's view of the job step.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int switch_p_job_attach ( switch_jobinfo_t switch_job, char ***env,\nuint32_t nodeid, uint32_t procid, uint32_t nnodes, uint32_t nprocs, uint32_t rank );</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Attach process to interconnect\n(Called from within the process, so it is appropriate to set interconnect specific\nenvironment variables here).</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> switch_job</span>&nbsp; &nbsp;&nbsp;(input) a job's\nswitch credential.<br>\n<span class=\"commandline\"> env</span>&nbsp; &nbsp;&nbsp;(input/output) the\nenvironment variables to be set upon job step initiation. Switch specific\nenvironment variables are added as needed.<br>\n<span class=\"commandline\"> nodeid</span>&nbsp; &nbsp;&nbsp;(input) zero-origin\nid of this node.<br>\n<span class=\"commandline\"> procid</span>&nbsp; &nbsp;&nbsp;(input) zero-origin\nprocess id local to slurmd and <b>not</b> equivalent to the global task id or MPI rank.<br>\n<span class=\"commandline\"> nnodes</span>&nbsp; &nbsp;&nbsp;(input) count of\nnodes allocated to this job step.<br>\n<span class=\"commandline\"> nprocs</span>&nbsp; &nbsp;&nbsp;(input) total count of\nprocesses or tasks to be initiated for this job step.<br>\n<span class=\"commandline\"> rank</span>&nbsp; &nbsp;&nbsp;(input) zero-origin\nid of this task.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int switch_p_job_fini (switch_jobinfo_t jobinfo switch_job);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: This function is run from the same process\nas switch_p_job_init() after all job tasks have exited. It is *not* run as root, because\nthe process in question has already setuid to the job step owner.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\"> switch_job</span>&nbsp; &nbsp;&nbsp;(input) a job\nstep's switch credential.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int switch_p_job_postfini ( stepd_step_rec_t *job );</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: This function is run from the initial slurmd\nprocess (same process as switch_p_job_preinit()), and is run as root. Any cleanup routines\nthat need to be run with root privileges should be run from this function.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> job</span>&nbsp; &nbsp;&nbsp;(input)\nstructure representing the slurmstepd's view of the job step.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int switch_p_job_step_allocated (switch_jobinfo_t\njobinfo switch_job, char *nodelist);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Note that the identified\njob step is active at restart time. This function can be used to\nrestore global switch state information based upon job steps known to be\nactive at restart time. Use of this function is preferred over switch state\nsaved and restored by the switch plugin. Direct use of job step switch\ninformation eliminates the possibility of inconsistent state information\nbetween the switch and job steps.\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> switch_job</span>&nbsp; &nbsp;&nbsp;(input) a job's\nswitch credential.<br>\n<span class=\"commandline\"> nodelist</span>&nbsp; &nbsp;&nbsp;(input) the nodes\nallocated to a job step.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<h3>Job Management Suspend/Resume Functions</h3>\n\n<p class=\"commandline\">int switch_p_job_suspend_test(switch_jobinfo_t *switch_job);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Determine if a specific job\nstep can be preempted.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> switch_job</span>&nbsp; &nbsp;&nbsp;(input) a job\nstep's switch credential.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if the job step can be\npreempted and SLURM_ERROR otherwise.</p>\n\n<p class=\"commandline\">void switch_p_job_suspend_info_get(switch_jobinfo_t *switch_job,\nvoid **suspend_info);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Pack any information needed\nfor a job step to be preempted into an opaque data structure.<br>\n<b>NOTE</b>: Use switch_p_job_suspend_info_free() to free the opaque data structure.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> switch_job</span>&nbsp; &nbsp;&nbsp;(input) a job\nstep's switch credential.<br>\n<span class=\"commandline\"> suspend_info</span>&nbsp; &nbsp;&nbsp;(input/output)\ninformation needed for a job to be preempted. This should be NULL for the\nfirst call and data about job steps will be added to the opaque data structure\nfor addition function call (i.e. for each addition job step).</p>\n\n<p class=\"commandline\">void switch_p_job_suspend_info_pack(void *suspend_info, Buf buffer);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Pack the information needed\nfor a job to be preempted into a buffer</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> suspend_info</span>&nbsp; &nbsp;&nbsp;(input)\ninformation needed for a job to be preempted, including information for all\nsteps in that job.<br>\n<span class=\"commandline\"> buffer</span>&nbsp; &nbsp;&nbsp;(input/output)\nthe buffer that has suspend_info added to it.</p>\n\n<p class=\"commandline\">int switch_p_job_suspend_info_unpack(void **suspend_info, Buf buffer);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Unpack the information needed\nfor a job to be preempted from a buffer.<br>\n<b>NOTE</b>: Use switch_p_job_suspend_info_free() to free the opaque data structure.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> suspend_info</span>&nbsp; &nbsp;&nbsp;(output)\ninformation needed for a job to be preempted, including information for all\nsteps in that job.<br>\n<span class=\"commandline\"> buffer</span>&nbsp; &nbsp;&nbsp;(input/output)\nthe buffer that has suspend_info extracted from it.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if the suspend_info\ndata was successfully read from buffer and SLURM_ERROR otherwise.</p>\n\n<p class=\"commandline\">int switch_p_job_suspend(void *suspend_info, int max_wait);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Suspend a job's use of switch\nresources. This may reset MPI timeout values and/or release switch resources.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> suspend_info</span>&nbsp; &nbsp;&nbsp;(input)\ninformation needed for a job to be preempted, including information for all\nsteps in that job.<br>\n<span class=\"commandline\"> max_wait</span>&nbsp; &nbsp;&nbsp;(input) maximum\ntime interval to wait for the operation to complete, in seconds</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if job's switch\nresources suspended and SLURM_ERROR otherwise.</p>\n\n<p class=\"commandline\">int switch_p_job_resume(void *suspend_info, int max_wait);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Resume a job's use of switch\nresources. This may reset MPI timeout values and/or release switch resources.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> suspend_info</span>&nbsp; &nbsp;&nbsp;(input)\ninformation needed for a job to be resumed, including information for all\nsteps in that job.<br>\n<span class=\"commandline\"> max_wait</span>&nbsp; &nbsp;&nbsp;(input) maximum\ntime interval to wait for the operation to complete, in seconds</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if job's switch\nresources resumed and SLURM_ERROR otherwise.</p>\n\n<p class=\"commandline\">void switch_p_job_suspend_info_free(void *suspend_info);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Free the resources allocated\nto store job suspend/resume information as generated by the\nswitch_p_job_suspend_info_get() and switch_p_job_suspend_info_unpack() functions.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> suspend_info</span>&nbsp; &nbsp;&nbsp;(input)\ninformation needed for a job to be preempted, including information for all\nsteps in that job.</p>\n\n<h3>Job Step Management Suspend/Resume Functions</h3>\n\n<p class=\"commandline\">int switch_p_job_step_pre_suspend (stepd_step_rec_t *jobstep);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Perform any job step pre-suspend functionality (done before the application PIDs are stopped).</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> job</span>&nbsp; &nbsp;&nbsp;(input)\nstructure representing the slurmstepd's view of the job step.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if the job step can be\nsuspended and SLURM_ERROR otherwise.</p>\n\n<p class=\"commandline\">int switch_p_job_step_post_suspend (stepd_step_rec_t *jobstep);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Perform any job step post-suspend functionality (done after the application PIDs are stopped).</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> job</span>&nbsp; &nbsp;&nbsp;(input)\nstructure representing the slurmstepd's view of the job step.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if the job step has been suspended and SLURM_ERROR otherwise.</p>\n\n<p class=\"commandline\">int switch_p_job_step_pre_resume (stepd_step_rec_t *jobstep);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Perform any job step pre-resume functionality (done before the application PIDs are re-started).</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> job</span>&nbsp; &nbsp;&nbsp;(input)\nstructure representing the slurmstepd's view of the job step.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if the job step can be\nresumed and SLURM_ERROR otherwise.</p>\n\n<p class=\"commandline\">int switch_p_job_step_post_resume (stepd_step_rec_t *jobstep);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Perform any job step post-resume functionality (done after the application PIDs are re-started).</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> job</span>&nbsp; &nbsp;&nbsp;(input)\nstructure representing the slurmstepd's view of the job step.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if the job step has been resumed and SLURM_ERROR otherwise.</p>\n\n<h3>Error Handling Functions</h3>\n<a name=\"get_errno\"><p class=\"commandline\">int switch_p_get_errno (void);</p></a>\n<p style=\"margin-left:.2in\"><b>Description</b>: Return the number of a switch\nspecific error.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>: None</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: Error number for the last failure encountered by\nthe switch plugin.</p>\n\n<p class=\"commandline\"><a name=\"strerror\">char *switch_p_strerror(int errnum);</a></p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Return a string description of a switch\nspecific error code.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\"> errnum</span>&nbsp; &nbsp;&nbsp;(input) a switch\nspecific error code.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: Pointer to string describing the error\nor NULL if no description found in this plugin.</p>\n\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<p style=\"text-align:center;\">Last modified 27 March 2015</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/acct_gather_energy_plugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Slurm Energy Accounting Plugin API (AcctGatherEnergyType)\n</a></h1>\n\n<h2> Overview</h2>\n<p> This document describe. Slurm energy accounting plugins and the API that\ndefines them. It is intended as a resource to programmers wishing to write\ntheir own Slurm energy accounting plugins.\n\n<p>Slurm energy accounting plugins must conform to the\nSlurm Plugin API with the following specifications:\n\n<p><span class=\"commandline\">const char\nplugin_name[]=\"<i>full&nbsp;text&nbsp;name</i>\"</span>\n<p style=\"margin-left:.2in\">\nA free-formatted ASCII text string that identifies the plugin.\n\n<p><span class=\"commandline\">const char\nplugin_type[]=\"<i>major/minor</i>\"</span><br>\n<p style=\"margin-left:.2in\">\nThe major type must be &quot;acct_gather_energy.&quot;\nThe minor type can be any suitable name\nfor the type of energy accounting. We currently use\n<ul>\n<li><b>none</b> &mdash; No energy consumption data is provided.\n<li><b>ipmi</b> &mdash; Gets energy consumption data from the\nBMC (Baseboard Management Controller) using the\nIPMI (Intelligent Platform Management Interface) tool.\n<li><b>rapl</b> &mdash; Gets energy consumption data from hardware sensors on each\ncore/socket, using RAPL (Running Average Power Limit) sensors. Note that\nenabling RAPL may require the execution of the command \"sudo modprobe msr\".\n</ul>\n\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loadeed by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<p>The programmer is urged to study\n<span class=\"commandline\">src/plugins/acct_gather_energy/rapl</span> and \n<span class=\"commandline\">src/common/slurm_acct_gather_energy.c</span>\nfor a sample implementation of a Slurm energy accounting plugin.\n<p class=\"footer\"><a href=\"#top\">top</a>\n\n<h2>API Functions</h2>\n<p>All of the following functions are required. Functions which are not\nimplemented must be stubbed.\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\">int acct_gather_energy_p_update_node_energy(void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUpdates energy accounting data for a node.\nSets/updates the energy and power accounting values in the acct_gather_energy_t\nstructure for the node on which it is called.\nCalled by the slurmd daemon.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\"> None</span>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">int acct_gather_energy_p_get_data(enum acct_energy_type data_type, acct_gather_energy_t *energy)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUpdates and returns energy consumption of a task, or returns current energy and \npower consumption of a node, according to specified data_type.\nCalled by jobacct_gather plugin to update and return energy consumption of a \ntask.\nCalled by slurmd to return energy and power consumption of a node.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\"> data_type</span> (input) type of energy/power data \nto be returned.<br>\n<span class=\"commandline\"> energy</span> (input) pointer to acct_gather_energy_t \nstruct in which energy/power data is to be returned.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">int acct_gather_energy_p_set_data(enum acct_energy_type data_type, acct_gather_energy_t *energy)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nSets the energy consumption data for a node. Not currently used.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\"> data_type</span> (input) type of energy/power data \nto be set.<br>\n<span class=\"commandline\"> energy</span> (input) pointer to acct_gather_energy_t \nstruct from which energy/power data is to be taken.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<h2>Parameters</h2>\n<p>These parameters can be used in the slurm.conf to configure the\nplugin and the frequency at which to gather node energy data.</p>\n<dl>\n<dt><span class=\"commandline\">AcctGatherEnergyType</span>\n<dd>Specifies which plugin should be used.\n<dt><span class=\"commandline\">AcctGatherNodeFreq</span>\n<dd>Time interval between pollings in seconds.\n</dl>\n\n<p class=\"footer\"><a href=\"#top\">top</a>\n\n<p style=\"text-align:center;\">Last modified 27 March 2015</p>\n\n<!--#include virtual=\"footer.txt\"-->\n\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/proctrack_plugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Slurm Process Tracking Plugin API</a></h1>\n\n<h2> Overview</h2>\n<p> This document describes Slurm process tracking plugins and the API\nthat defines them.\nIt is intended as a resource to programmers wishing to write their\nown Slurm process tracking plugins.\nNote that process tracking plugin is designed for use with Slurm job steps.\nThere is a <a href=\"job_container_plugins.html\">job_container plugin</a>\ndesigned for use with Slurm jobs.</p>\n\n<p>Slurm process tracking plugins are Slurm plugins that implement\nthe Slurm process tracking API described herein.\nThey must conform to the Slurm Plugin API with the following\nspecifications:</p>\n\n<p><span class=\"commandline\">const char plugin_type[]</span><br>\nThe major type must be &quot;proctrack.&quot;\nThe minor type can be any recognizable abbreviation for the type\nof proctrack. We recommend, for example:</p>\n<ul>\n<li><b>cray</b> &mdash; Use Cray job containers.</li>\n<li><b>cgroup</b> &mdash; Use Linux cgroups for process tracking. This is the\nrecommended mechanism for non CRAY systems. </li>\n<li><b>linuxproc</b> &mdash; Perform process tracking based upon a scan\nof the Linux process table and use the parent process ID to determine\nwhat processes are members of a Slurm job. NOTE: This mechanism is\nnot entirely reliable for process tracking.</li>\n<li><b>lua</b> &mdash; Use site-defined <a href=\"http://www.lua.org\">Lua</a>\nscript for process tracking. Sample Lua scripts can be found with the\nSlurm distribution in the directory <i>contribs/lua</i>. The default\ninstallation location of the Lua scripts is the same location as the Slurm\nconfiguration file, <i>slurm.conf</i>.</li>\n<li><b>pgid</b> &mdash; Use process group ID to determine\nwhat processes are members of a Slurm job. NOTE: This mechanism is\nnot entirely reliable for process tracking.</li>\n</ul>\n\n<p><span class=\"commandline\">const char plugin_name[]</span><br>\nSome descriptive name for the plugin.\nThere is no requirement with respect to its format.</p>\n\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loadeed by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<p>The programmer is urged to study\n<span class=\"commandline\">src/plugins/proctrack/pgid/proctrack_pgid.c</span>\nfor an example implementation of a Slurm proctrack plugin.</p>\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<h2>Data Objects</h2>\n<p> The implementation must support a container id of type uint64_t.\nThis container ID is maintained by the plugin directly in the slurmd\njob structure using the field named <i>cont_id</i>.</p>\n\n<p>The implementation must maintain (though not necessarily directly export) an\nenumerated <b>errno</b> to allow Slurm to discover as practically as possible\nthe reason for any failed API call.\nThese values must not be used as return values in integer-valued functions\nin the API.\nThe proper error return value from integer-valued functions is SLURM_ERROR.\nThe implementation should endeavor to provide useful and pertinent information\nby whatever means is practical.\nSuccessful API calls are not required to reset errno to a known value.</p>\n\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<h2>API Functions</h2>\n<p>The following functions must appear. Functions which are not implemented should\nbe stubbed.</p>\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the SLURM\n<span class=\"commandline\">init()</span>, and the SLURM\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\">int proctrack_p_create (stepd_step_rec_t *job);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Create a container.\nThe caller should ensure that be valid\n<span class=\"commandline\">proctrack_p_destroy()</span> is called.\nThis function must put the container ID directory in the job structure's\nvariable <i>cont_id</i>.</p>\n<p style=\"margin-left:.2in\"><b>Argument</b>:\n<span class=\"commandline\"> job</span>&nbsp; &nbsp;&nbsp;(input/output)\nPointer to a slurmd job structure.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int proctrack_p_add (stepd_step_rec_t *job, pid_t pid);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Add a specific process ID\nto a given job step's container.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> job</span>&nbsp; &nbsp;&nbsp;(input)\nPointer to a slurmd job structure.<br>\n<span class=\"commandline\"> pid</span>&nbsp; &nbsp;&nbsp;(input)\nThe ID of the process to add to this job's container.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int proctrack_p_signal (uint64_t id, int signal);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Signal all processes in a given\njob step container.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> id</span> &nbsp;&nbsp;(input)\nJob step container's ID.<br>\n<span class=\"commandline\"> signal</span> &nbsp;&nbsp;(input)\nSignal to be sent to processes. Note that a signal of zero\njust tests for the existence of processes in a given job step container.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if the signal\nwas sent.\nIf the signal can not be sent, the function should return SLURM_ERROR and set\nits errno to an appropriate value to indicate the reason for failure.</p>\n\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<p class=\"commandline\">int proctrack_p_destroy (uint64_t id);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Destroy or otherwise\ninvalidate a job step container.\nThis does not imply the container is empty, just that it is no longer\nneeded.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\"> id</span> &nbsp;&nbsp; (input)\nJob step container's ID.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">uint64_t proctrack_p_find (pid_t pid);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>:\nGiven a process ID, return its job step container ID.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\"> pid</span>&nbsp; &nbsp;&nbsp;(input)\nA process ID.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: The job step container ID\nwith this process or zero if none is found.</p>\n\n<p class=\"commandline\">uint32_t proctrack_p_get_pids (uint64_t cont_id, pid_t **pids, int *npids);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>:\nGiven a process container ID, fill in all the process IDs in the container.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\"> cont_id</span>&nbsp; &nbsp;&nbsp;(input)\nA job step container ID.<br>\n<span class=\"commandline\"> pids</span>&nbsp; &nbsp;&nbsp;(output)\nArray of process IDs in the container.<br>\n<span class=\"commandline\"> npids</span>&nbsp; &nbsp;&nbsp;(output)\nCount of process IDs in the container.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if\n  successful, SLURM_ERROR else.</p>\n\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<p style=\"text-align:center;\">Last modified 27 March 2015</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/jobacct_gatherplugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Slurm Job Accounting Gather Plugin API</a></h1>\n\n<h2> Overview</h2>\n<p> This document describes Slurm job accounting gather plugins and the API that\ndefines them. It is intended as a resource to programmers wishing to write\ntheir own Slurm job accounting gather plugins.\n\n<p>Slurm job accounting gather plugins must conform to the\nSlurm Plugin API with the following specifications:\n\n<p><span class=\"commandline\">const char\nplugin_name[]=\"<i>full&nbsp;text&nbsp;name</i>\"</span>\n<p style=\"margin-left:.2in\">\nA free-formatted ASCII text string that identifies the plugin.\n\n<p><span class=\"commandline\">const char\nplugin_type[]=\"<i>major/minor</i>\"</span><br>\n<p style=\"margin-left:.2in\">\nThe major type must be &quot;jobacct_gather.&quot;\nThe minor type can be any suitable name\nfor the type of accounting package. We currently use\n<ul>\n<li><b>cgroup</b> &mdash; Gathers information from Linux cgroup\ninfrastructure and adds this information to the standard rusage\ninformation also gathered for each job. (Experimental, not to be used\n  in production.)\n<li><b>linux</b> &mdash; Gathers information from Linux /proc table and adds this\ninformation to the standard rusage information also gathered for each job.\n<li><b>none</b> &mdash; No information gathered.\n</ul>\n\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loadeed by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<p>The <b>sacct</b> program can be used to display gathered data from regular\naccounting and from these plugins.</p>\n<p>The programmer is urged to study\n<span class=\"commandline\">src/plugins/jobacct_gather/linux</span> and\n<span class=\"commandline\">src/common/slurm_jobacct_gather.[c|h]</span>\nfor a sample implementation of a Slurm job accounting gather plugin.\n<p class=\"footer\"><a href=\"#top\">top</a>\n\n\n<h2>API Functions</h2>\n<p>All of the following functions are required. Functions which are not\nimplemented must be stubbed.\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\">int jobacct_gather_p_poll_data(List task_list, bool pgid_plugin, uint64_t cont_id)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nBuild a table of all current processes.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\"> task_list</span> (in/out) List containing\ncurrent processes <br>\n<span class=\"commandline\"> pgid_plugin</span> (input) if we are\nrunning with the pgid plugin<br>\n<span class=\"commandline\"> cont_id</span> (input) container id of processes if not running with pgid\n\n<p class=\"commandline\">int jobacct_gather_p_endpoll(void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nCalled when the process is finished to stop the\npolling thread.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">none</span>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">int jobacct_gather_p_add_task(pid_t pid, uint16_t tid)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUsed to add a task to the poller.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\"> pid</span> (input) Process id <br>\n<span class=\"commandline\"> tid</span> (input) slurm global task id\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n\n\n<h2>Job Account Gathering</h2>\n<p>All of the following functions are not required but may be used.\n\n<p class=\"commandline\">int jobacct_gather_init(void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nLoads the job account gather plugin.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">int jobacct_gather_fini(void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUnloads the job account gathering plugin.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">int jobacct_gather_startpoll(uin16_t frequency)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nCreates and starts the polling thread.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\"> frequency </span> (input) frequency of the polling.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">void jobacct_gather_change_poll(uint16_t frequency)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nChanges the polling thread to a new frequency.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\"> frequency </span> (input) frequency of the polling\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">void jobacct_gather_suspend_poll(void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nTemporarily stops the polling thread.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">void jobacct_gather_resume_poll(void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nResumes the polling thread that was stopped.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandine\">jobacctinfo_t *jobacct_gather_stat_task(pid_t\n  pid)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nGets the basis of the information of the task.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">pid</span> (input) process id.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">jobacctinfo_t *jobacct_gather_remove_task(pid_t pid)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nRemoves the task.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">pid</span> (input) process id.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">int\n  jobacct_gather_set_proctrack_container_id(uint64_t id)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n Sets the proctrack container to a given id.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">id</span> (input) id to set.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">int jobacct_gather_set_mem_limit(uint32_t job_id,\n  uint32_t step_id, uint64_t mem_limit)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nSets the memory limit  of the job account.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job_id</span> (input) id of the job.<br>\n<span class=\"commandline\">sted_id</span> (input) id of the step.<br>\n<span class=\"commandline\">mem_limit</span> (input) memory limit in megabytes.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">void jobacct_gather_handle_mem_limit(uint64_t total_job_mem, uint64_t total_job_vsize)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nCalled to find out how much memory is used.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\"> total_job_mem</span> (input) total\namount of memory for jobs.<br>\n<span class=\"commandline\"> total_job_vsize</span> (input) the\ntotal job size.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<h2>Job Account Info</h2>\n<p>All of the following functions are not required but may be used.\n\n<p class=\"commandline\">jobacctinfo_t *jobacctinfo_create(jobacct_id_t *jobacct_id)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nCreates the job account info.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\"> jobacct_id</span> (input) the job\naccount id.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">void jobacctinfo_destroy(void *object)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nDestroys the job account info.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\"> object</span> (input) the job that needs to be destroyed\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">int jobacctinfo_setinfo(jobacctinfo_t *jobacct, enum jobacct_data_type type, void *data)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nSet the information for the job.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\"> jobacct</span> (input) job account<br>\n<span class=\"commandline\"> type</span>(input) enum telling the plugin how to transform the data.<br>\n<span class=\"commandline\"> data</span> (input/output) Is a void * and\nthe actual data type depends upon the first argument to this function (type).\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">int jobacctinfo_getinfo(jobacctinfo_t *jobacct, enum jobacct_data_type type, void *data)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nGets the information about the job.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\"> jobacct</span> (input) job account.<br>\n<span class=\"commandline\">type</span> (input) the\ndata type of the job account.\n<span class=\"commandline\">data</span>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\"> void jobacctinfo_pack(jobacctinfo_t *jobacct,\nuint16_t rpc_version, Buf buffer)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nPacks the job account information.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">jobacct</span> (input) the job account.<br>\n<span class=\"commandline\">rpc_version</span> (input) the\nrpc version.<br>\n<span class=\"commandline\">buffer</span> (input) the buffer.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">int jobacctinfo_unpack(jobacctinfo_t **jobacct,\nuint16_t rpc_version, Buf buffer)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUnpacks the job account information.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">jobacct</span> (input) the job account.<br>\n<span class=\"commandline\">rpc_version</span> (input) the rpc\nversion.<br>\n<span class=\"commandline\">buffer</span> (input) the buffer.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">void jobacctinfo_aggregate(jobacctinfo_t *dest, jobacctinfo_t *from)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nAggregates the jobs.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">dest</span> (input) New destination of the job.<br>\n<span class=\"commandline\">from</span> (input) Original location of job.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">void jobacctinfo_2_stats(slurmdb_stats_t *stats, jobacctinfo_t *jobacct)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nGets the stats of the job in accounting.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">stats</span> (input) slurm data base stat.<br>\n<span class=\"commandline\">jobacct</span> (input) the job account.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"footer\"><a href=\"#top\">top</a>\n\n<h2>Parameters</h2>\n<p>These parameters can be used in the slurm.conf to configure the\nplugin and the frequency at which to gather information about running jobs.</p>\n<dl>\n<dt><span class=\"commandline\">JobAcctGatherType</span>\n<dd>Specifies which plugin should be used.\n<dt><span class=\"commandline\">JobAcctGatherFrequency</span>\n<dd>Time interval between pollings in seconds.\n</dl>\n\n<p class=\"footer\"><a href=\"#top\">top</a>\n\n<p style=\"text-align:center;\">Last modified 27 March 2015</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/topology_plugin.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Topology Plugin Programmer Guide</a></h1>\n\n<h2> Overview</h2>\n<p> This document describes Slurm topology plugin and the API that\ndefines them.\nIt is intended as a resource to programmers wishing to write their own\nSlurm topology plugin.</p>\n\n<p>Slurm topology plugins are Slurm plugins that implement\nconvey system topology information so that Slurm is able to\noptimize resource allocations and minimize communication overhead.\nThe plugins must conform to the Slurm Plugin API with the following\nspecifications:</p>\n\n<p><span class=\"commandline\">const char plugin_type[]</span><br>\nThe major type must be &quot;topology.&quot;\nThe minor type specifies the type of topology mechanism.\nWe recommend, for example:</p>\n<ul>\n<li><b>3d_torus</b> &mdash; Optimize placement for a three dimensional torus.</li>\n<li><b>none</b> &mdash; No topology information.</li>\n<li><b>tree</b> &mdash; Optimize placement based upon a hierarchy of network\nswitches.</li>\n</ul></p>\n\n<p><span class=\"commandline\">const char plugin_name[]</span><br>\nSome descriptive name for the plugin.\nThere is no requirement with respect to its format.</p>\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loadeed by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<p>The actions performed by these plugins vary widely.\nIn the case of <b>3d_torus</b>, the nodes in configuration file\nare re-ordered so that nodes which are nearby in the one-dimensional\ntable are also nearby in logical three-dimensional space.\nIn the case of <b>tree</b>, a tabled is built to reflect network\ntopology and that table is later used by the <b>select</b> plugin\nto optimize placement.\nNote carefully, however, the versioning discussion below.</p>\n\n<h2>Data Objects</h2>\n<p>The implementation must maintain (though not necessarily directly export) an\nenumerated <span class=\"commandline\">errno</span> to allow Slurm to discover\nas practically as possible the reason for any failed API call.\nPlugin-specific enumerated integer values may be used when appropriate.\n\n<p>These values must not be used as return values in integer-valued\nfunctions in the API.\nThe proper error return value from integer-valued functions is SLURM_ERROR.\nThe implementation should endeavor to provide useful and pertinent\ninformation by whatever means is practical.\nSuccessful API calls are not required to reset any errno to a known value.\nHowever, the initial value of any errno, prior to any error condition\narising, should be SLURM_SUCCESS. </p>\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<h2>API Functions</h2>\n<p>The following functions must appear.\nFunctions which are not implemented should be stubbed.</p>\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\">int topo_build_config(void);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Generate topology information.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS or\nSLURM_ERROR on failure.</p>\n\n<p class=\"commandline\">bool topo_generate_node_ranking(void)</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Determine if this plugin will\nreorder the node records based upon each job's node rank field.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: true if node reording is supported,\nfalse otherwise.</p>\n\n<p class=\"commandline\">int topo_get_node_addr(char* node_name, char** paddr, char** ppatt);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Get Topology address of a given node.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<b>node_name</b> (input) name of the targeted node<br>\n<b>paddr</b> (output) returns the topology address of the node and connected\nswitches. If there are multiple switches at some level in the hierarchy, they\nwill be represented using Slurm's hostlist expression (e.g. \"s0\" and \"s1\" are\nreported as \"s[0-1]\").  Each level in the hierarchy is separated by a period.\nThe last element will always be the node's name (i.e. \"s0.s10.nodename\")<br>\n<b>ppatt</b> (output) returns the pattern of the topology address. Each level\nin the hierarchy is separated by a period. The final element will always be\n\"node\" (i.e. \"switch.switch.node\")<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS or\nSLURM_ERROR on failure.</p>\n\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<p style=\"text-align:center;\">Last modified 27 March 2015</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/launch_plugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Launch Plugin API</a></h1>\n\n<h2> Overview</h2>\n<p> This document describes the launch plugin that is responsible for\n  launching a parallel task in Slurm and the API that defines them. It\n  is intended as a resource to programmers wishing to write their own\n  launch plugin.\n\n<p><span class=\"commandline\">const char\nplugin_name[]=\"<i>launch&nbsp;Slurm&nbsp;plugin</i>\"</span>\n<p style=\"margin-left:.2in\">\n\n<p><span class=\"commandline\">const char\nplugin_type[]=\"<i>launch/[aprun|poe|runjob|slurm</i>\"</span><br>\n<p style=\"margin-left:.2in\">\n\n<ul>\n<li><b>aprun</b> &mdash; Use Cray's aprun command to launch tasks - used on Cray\nsystems with ALPS installed.</li>\n<li><b>poe</b> &mdash; Use IBM's poe command to launch tasks - used on systems\n  IBM's parallel environment (PE) installed.</li>\n<li><b>runjob</b> &mdash; Use IBM's runjob command to launch tasks - used on\n  BlueGene/Q systems.</li>\n<li><b>slurm</b> &mdash; Use Slurm's default launching infrastructure</li>\n</ul>\n\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loadeed by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<p>The programmer is urged to study\n<span class=\"commandline\">src/plugins/launch/slurm/launch_slurm.c</span>\nfor a sample implementation of a Slurm launch plugin.\n<p class=\"footer\"><a href=\"#top\">top</a>\n\n<h2>API Functions</h2>\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\"> int launch_p_setup_srun_opt(char **rest, opt_t *opt_local)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Sets up the srun operation.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n  <span class=\"commandline\"> rest:</span> extra parameters on the\n  command line not processed by srun<br>\n  <span class=\"commandline\"> opt_local:</span> task launch options from srun command\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\"> int launch_p_handle_multi_prog_verify(int command_pos, opt_t *opt_local)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Is called to verify a multi-prog file if verifying needs to be done.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n  <span class=\"commandline\"> command_pos:</span> to be used with\n  global opt variable to tell which spot the command is in opt.argv.<br>\n  <span class=\"commandline\"> opt_local:</span> task launch options from srun command\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">1</span> if handled, or<br>\n  <span class=\"commandline\">0</span> if not.\n\n<p class=\"commandline\"> int launch_p_create_job_step(srun_job_t *job,\n  bool use_all_cpus, void (*signal_function)(int), sig_atomic_t\n  *destroy_job, opt_t *opt_local, int pack_offset)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Creates the job step.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n  <span class=\"commandline\"> job:</span> the job to run.<br>\n  <span class=\"commandline\"> use_all_cpus:</span> choice whether to use\n  all cpus.<br>\n  <span class=\"commandline\"> signal_function:</span> function that\n  handles the signals coming in.<br>\n  <span class=\"commandline\"> destroy_job:</span> pointer to a global\n  flag signifying if the job was canceled while allocating.\n  <span class=\"commandline\"> opt_local:</span> task launch options from srun command<br>\n  <span class=\"commandline\"> pack_offset:</span> zero-origin index into a\n  heterogeneous job allocation, -1 if not heterogeneous job\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\"> launch_p_step_launch(srun_job_t *job,\n  slurm_step_io_fds_t *cio_fds, uint32_t *global_rc, opt_t *opt_local)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Launches the job step.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n  <span class=\"commandline\"> job:</span> the job to launch.<br>\n  <span class=\"commandline\"> cio_fds:</span> filled in io descriptors<br>\n  <span class=\"commandline\"> global_rc:</span> srun global return code.<br>\n  <span class=\"commandline\"> opt_local:</span> task launch options from srun command\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\"> int launch_p_step_wait(srun_job_t *job, bool\n  got_alloc, opt_t *opt_local, int pack_offset)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Waits for the job to be finished.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n  <span class=\"commandline\"> job:</span> the job to wait for.<br>\n  <span class=\"commandline\"> got_alloc:</span> if the resource\n  allocation was created inside srun.<br>\n  <span class=\"commandline\"> opt_local:</span> task launch options from srun command<br>\n  <span class=\"commandline\"> pack_offset:</span> zero-origin index into a\n  heterogeneous job allocation, -1 if not heterogeneous job\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\"> int launch_p_step_terminate(void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Terminates the job step.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\"> void launch_p_print_status(void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Gets the status of the job.\n\n<p class=\"commandline\"> void launch_p_fwd_signal(int signal)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Sends a forward signal to any underlying tasks.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n  <span class=\"commandline\"> signal:</span> the signal that needs to be sent.\n\n<p class=\"footer\"><a href=\"#top\">top</a>\n\n<p style=\"text-align:center;\">Last modified 20 December 2017</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/schedplugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Slurm Scheduler Plugin API</a></h1>\n\n<h2> Overview</h2>\n<p> This document describe. Slurm scheduler plugins and the API that defines\nthem. It is intended as a resource to programmers wishing to write their own SLURM\nscheduler plugins.</p>\n\n<p>It is noteworthy that two different models are used for job scheduling.\nThe <b>backfill</b> scheduler let. Slurm establishes the initial job priority\nand can periodically alter job priorities to change their order within the queue.\nDevelopers may use the model that best fits their needs.\nNote that a separate <a href=\"selectplugins.html\">node selection plugin</a>\nis available for controlling that aspect of scheduling.</p>\n\n<p>Slurm scheduler plugins are Slurm plugins that implement the Slurm scheduler\nAPI described herein. They must conform to the Slurm Plugin API with the following\nspecifications:</p>\n<p><span class=\"commandline\">const char plugin_type[]</span><br>\nThe major type must be &quot;sched.&quot; The minor type can be any recognizable\nabbreviation for the type of scheduler. We recommend, for example:</p>\n<ul>\n<li><b>builtin</b> &mdash; A plugin that implements the API without providing any actual\nscheduling services. This is the default behavior and implements first-in-first-out scheduling.</li>\n<li><b>backfill</b> &mdash; Raise the priority of jobs if doing so results in their starting earlier\nwithout any delay in the expected initiation time of any higher priority job.</li>\n</ul>\n\n<p><span class=\"commandline\">const char plugin_name[]</span><br>\nSome descriptive name for the plugin.\nThere is no requirement with respect to its format.</p>\n\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loadeed by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<h2>Data Objects</h2>\n<p>The implementation must maintain (though not necessarily directly export) an\nenumerated <span class=\"commandline\">errno</span>  to allow Slurm to discover\nas practically as possible the reason for any failed API call. Plugin-specific enumerated\ninteger values should be used when appropriate. It is desirable that these values\nbe mapped into the range ESLURM_SCHED_MIN and ESLURM_SCHED_MAX\nas defined in <span class=\"commandline\">slurm/slurm_errno.h</span>.\nThe error number should be returned by the function\n<a href=\"#get_errno\"><span class=\"commandline\">slurm_sched_get_errno()</span></a>\nand  string describing the error's meaning should be returned by the function\n<a href=\"#strerror\"><span class=\"commandline\">slurm_sched_strerror()</span></a>\ndescribed below.</p>\n\n<p>These values must not be used as return values in integer-valued functions\nin the API. The proper error return value from integer-valued functions is SLURM_ERROR.\nThe implementation should endeavor to provide useful and pertinent information by\nwhatever means is practical. In some cases this means an errno for each credential,\nsince plugins must be re-entrant. If a plugin maintains a global errno in place of or in\naddition to a per-credential errno, it is not required to enforce mutual exclusion on it.\nSuccessful API calls are not required to reset any errno to a known value. However,\nthe initial value of any errno, prior to any error condition arising, should be\nSLURM_SUCCESS. </p>\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<h2>API Functions</h2>\n<p>The following functions must appear. Functions which are not implemented should\nbe stubbed.</p>\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the SLURM\n<span class=\"commandline\">init()</span>, and the SLURM\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\">int slurm_sched_p_reconfig (void);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Reread any configuration files.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>: None</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On fail\nure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int slurm_sched_p_schedule (void);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: For passive schedulers, invoke a scheduling pass.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>: None</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int slurm_sched_p_newalloc (struct job_record *job_ptr);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Note the successful allocation of resources to a job.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>: Pointer to the slurmctld job structure. This can be used to\nget partition, allocated resources, time limit, etc.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int slurm_sched_p_freealloc (struct job_record *job_ptr);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Note the successful release of resources for a job.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>: Pointer to the slurmctld job structure. This can be used to\nget partition, allocated resources, time limit, etc.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">uint32_t slurm_sched_p_initial_priority (\nuint32_t last_prio, struct job_record *job_ptr);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Establish the initial priority of a new job.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<b>last_prio</b> (input) default priority of the previously submitted job.\nThis can be used to provide First-In-First-Out scheduling by assigning the\nnew job a priority lower than this value.\nThis could also be used to establish an initial priority of zero for all jobs,\nrepresenting a \"held\" state.\nThe scheduler plugin can then decide where and when to initiate pending jobs\nby altering their priority and (optionally) list of required nodes.<br>\n<b>job_ptr</b> (input)\nPointer to the slurmctld job structure. This can be used to get partition,\nresource requirements, time limit, etc.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: The priority to be assigned to this job.</p>\n\n<p class=\"commandline\">void slurm_sched_p_job_is_pending (void);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Note that some job is pending execution.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>: None</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: Nothing.</p>\n\n<p class=\"commandline\">void slurm_sched_p_partition_change (void);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Note that some partition state change\nhappened such as time or size limits.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>: None</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: Nothing.</p>\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<p class=\"commandline\">char *slurm_sched_p_get_conf (void);</p></a>\n<p style=\"margin-left:.2in\"><b>Description</b>: Return scheduler specific\nconfiguration information to be reported for the <i>scontrol show configuration</i>\ncommand.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>: None</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: A string containing configuration\ninformation. The return value is released using the <i>xfree()</i> function.</p>\n\n<a name=\"get_errno\"><p class=\"commandline\">int slurm_sched_p_get_errno (void);</p></a>\n<p style=\"margin-left:.2in\"><b>Description</b>: Return the number of a scheduler\nspecific error.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>: None</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: Error number for the last failure encountered by the scheduler plugin.</p>\n\n<p class=\"commandline\"><a name=\"strerror\">const char *slurm_sched_p_strerror(int errnum);</a></p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Return a string description of a scheduler\nspecific error code.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<b>errnum</b> (input) a scheduler\nspecific error code.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: Pointer to string describing the error\nor NULL if no description found in this plugin.</p>\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<p style=\"text-align:center;\">Last modified 15 December 2016</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/route_plugin.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Slurm Route Plugin Programmer Guide</a></h1>\n\n<h2> Overview</h2>\n<p> This document describes Slurm Route plugin and the API that\ndefines them.\nIt is intended as a resource to programmers wishing to write their own\nSlurm Route plugin.</p>\n\n<p>Slurm Route plugins are Slurm plugins that redirect RPCs through\nintermediate forwarding nodes. The routing mechanism is similar\nto message forwarding which was designed to move message processing overhead\noff the controller. The main difference is that the routine table is\ndefined in the configuration. For example,\nthe topology implementation uses the topology.conf file.</p>\n\n<p>The plugins must conform to the Slurm Plugin API with the following\nspecifications:</p>\n\n<p><span class=\"commandline\">const char plugin_type[]</span><br>\nThe major type must be &quot;rout&quot;\nThe minor type specifies the type of route mechanism.\n</p>\n<ul>\n<li><b>default</b> &mdash; No routing information.</li>\n<li><b>topology</b> &mdash; Route messages using topology.conf information.</li>\n</ul></p>\n\n<p><span class=\"commandline\">const char plugin_name[]</span><br>\nSome descriptive name for the plugin.\nThere is no requirement with respect to its format.</p>\n<p><span class=\"commandline\">uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loadeed by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<h2>Data Objects</h2>\n<p>The implementation must maintain (though not necessarily directly export) an\nenumerated <span class=\"commandline\">errno</span> to allow Slurm to discover\nas practically as possible the reason for any failed API call.\nPlugin-specific enumerated integer values may be used when appropriate.\n\n<p>These values must not be used as return values in integer-valued\nfunctions in the API.\nThe proper error return value from integer-valued functions is SLURM_ERROR.\nThe implementation should endeavor to provide useful and pertinent\ninformation by whatever means is practical.\nSuccessful API calls are not required to reset any errno to a known value.\nHowever, the initial value of any errno, prior to any error condition\narising, should be SLURM_SUCCESS. </p>\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<h2>API Functions</h2>\n<p>The following functions must appear.\nFunctions which are not implemented should be stubbed.</p>\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the SLURM\n<span class=\"commandline\">init()</span>, and the SLURM\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n\n<p class=\"commandline\">\nextern int route_g_split_hostlist(hostlist_t hl,\n\t\t\t\t     hostlist_t** sp_hl,\n\t\t\t\t     int* count);\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nSplit an input hostlist into a set of hostlists to forward to.\n\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">hl (in) hostlist to split</span>\n<span class=\"commandline\">sp_hl (out) the array of hostlist that will be\nmalloced</span>\n<span class=\"commandline\">count (out) the count of created hostlist</span>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nextern int route_g_reconfigure ( void );\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nReset internal state during reconfigure.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nextern slurm_addr_t* route_g_next_collector ( bool *is_collector );\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nget address of parent in message tree.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">is_collector (out) flag indication this node\nis a collector.\n</span>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">slurm_addr_t*</span>\naddress of node to send messages to be aggregated <br>\n<span class=\"commandline\">NULL</span> if not set.\n\n<p class=\"commandline\">\nextern slurm_addr_t* route_g_next_collector_backup ( void );\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nget address of parent's backup in message tree.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">slurm_addr_t*</span>\naddress of node to send messages to be aggregated when primary collector\nis down. <br>\n<span class=\"commandline\">NULL</span> if not set.\n\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<p style=\"text-align:center;\">Last modified 27 March 2015</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/job_submit_plugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Job Submit Plugin API</a></h1>\n\n<h2> Overview</h2>\n<p> This document describes Slurm job submit plugins and the API that\ndefines them. It is intended as a resource to programmers wishing to write\ntheir own Slurm job submit plugins. This is version 100 of the API.</p>\n\n<p>Slurm job submit plugins must conform to the\nSlurm Plugin API with the following specifications:</p>\n\n<p><span class=\"commandline\">const char\nplugin_name[]=\"<i>full&nbsp;text&nbsp;name</i>\"</span>\n<p style=\"margin-left:.2in\">\nA free-formatted ASCII text string that identifies the plugin.\n\n<p><span class=\"commandline\">const char\nplugin_type[]=\"<i>major/minor</i>\"</span><br>\n<p style=\"margin-left:.2in\">\nThe major type must be &quot;job_submit.&quot;\nThe minor type can be any suitable name for the type of job submission package.\nWe include samples in the Slurm distribution for\n<ul>\n<li><b>all_partitions</b> &mdash; Set default partition to all partitions on\nthe cluster.</li>\n<li><b>defaults</b> &mdash; Set default values for job submission or modify\nrequests.</li>\n<li><b>logging</b> &mdash; Log select job submission and modification\nparameters.</li>\n<li><b>lua</b> &mdash; Interface to <a href=\"http://www.lua.org\">Lua</a> scripts\nimplementing these functions (actually a slight variation of them). Sample Lua\nscripts can be found with the Slurm distribution in the directory\n<i>contribs/lua</i>. The default installation location of the Lua scripts is\nthe same location as the Slurm configuration file, <i>slurm.conf</i>.</li>\n<li><b>partition</b> &mdash; Sets a job's default partition based upon job\nsubmission parameters and available partitions.</li>\n</ul>\n\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loadeed by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<p>Slurm can be configured to use multiple job_submit plugins if desired,\nhowever the lua plugin will only execute one lua script named \"job_submit.lua\"\nlocated in the default script directory (typically the subdirectory \"etc\" of\nthe installation directory).</p>\n\n<p class=\"footer\"><a href=\"#top\">top</a>\n\n<h2>API Functions</h2>\n<p>All of the following functions are required. Functions which are not\nimplemented must be stubbed.\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\">\nint job_submit(struct job_descriptor *job_desc, uint32_t submit_uid, char **error_msg)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nThis function is called by the slurmctld daemon with job submission parameters\nsupplied by the salloc, sbatch or srun command. It can be used to log and/or\nmodify the job parameters supplied by the user as desired. Note that this\nfunction has access to the slurmctld's global data structures, for example\nto examine the available partitions, reservations, etc.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job_desc</span>\n(input/output) the job allocation request specifications.<br>\n<span class=\"commandline\">submit_uid</span>\n(input) user ID initiating the request.<br>\n<span class=\"commandline\">error_msg</span>\n(output) If the argument is not null, then a plugin generated error message\ncan be stored here. The error message is expected to have allocated memory\nwhich Slurm will release using the xfree function. The error message is always\npropagated to the caller, no matter the return code.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nint job_modify(struct job_descriptor *job_desc, struct job_record *job_ptr,\nuint32_t modify_uid)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nThis function is called by the slurmctld daemon with job modification parameters\nsupplied by the scontrol or sview command. It can be used to log and/or\nmodify the job parameters supplied by the user as desired. Note that this\nfunction has access to the slurmctld's global data structures, for example to\nexamine the available partitions, reservations, etc.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job_desc</span>\n(input/output) the job allocation request specifications.<br>\n<span class=\"commandline\">job_ptr</span>\n(input/output) slurmctld daemon's current data structure for the job to\nbe modified.<br>\n<span class=\"commandline\">modify_uid</span>\n(input) user ID initiating the request.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<h2>Lua Functions</h2>\n<p>The Lua functions differ slightly from those implemented in C for\nbetter ease of use. Sample Lua scripts can be found with the Slurm distribution\nin the directory <i>contribs/lua</i>. The default installation location of\nthe Lua scripts is the same location as the Slurm configuration file,\n<i>slurm.conf</i>.\nReading and writing of job environment variables using Lua is possible\nby referencing the environment variables as a data structure containing\nnamed elements. For example:<br>\nif (job_desc.environment.LANGUAGE == \"en_US\") then<br>\n....</p>\n\n\n<p class=\"commandline\">\nint job_submit(struct job_descriptor *job_desc, List part_list, uint32_t submit_uid)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nThis function is called by the slurmctld daemon with job submission parameters\nsupplied by the salloc, sbatch or srun command. It can be used to log and/or\nmodify the job parameters supplied by the user as desired. Note that this\nfunction has access to the slurmctld's global data structures, for example\nto examine the available partitions, reservations, etc.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job_desc</span>\n(input/output) the job allocation request specifications.<br>\n<span class=\"commandline\">part_list</span>\n(input) List of pointer to partitions which this user is authorized to use.<br>\n<span class=\"commandline\">submit_uid</span>\n(input) user ID initiating the request.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">0</span> on success, or an\nerrno on failure. Slurm specific error numbers from <i>slurm/slurm_errno.h</i>\nmay be used. On failure, the request will be rejected and the user will have an\nappropriate error message printed for that errno. \n\n<p class=\"commandline\">\nint job_modify(struct job_descriptor *job_desc, struct job_record *job_ptr,\nList part_list, int modify_uid)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nThis function is called by the slurmctld daemon with job modification parameters\nsupplied by the scontrol or sview command. It can be used to log and/or\nmodify the job parameters supplied by the user as desired. Note that this\nfunction has access to the slurmctld's global data structures, for example to\nexamine the available partitions, reservations, etc.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job_desc</span>\n(input/output) the job allocation request specifications.<br>\n<span class=\"commandline\">job_ptr</span>\n(input/output) slurmctld daemon's current data structure for the job to\nbe modified.<br>\n<span class=\"commandline\">part_list</span>\n(input) List of pointer to partitions which this user is authorized to use.<br>\n<span class=\"commandline\">modify_uid</span>\n(input) user ID initiating the request.<br>\n<span class=\"commandline\">0</span> on success, or an\nerrno on failure. Slurm specific error numbers from <i>slurm/slurm_errno.h</i>\nmay be used. On failure, the request will be rejected and the user will have an\nappropriate error message printed for that errno. \n\n<p class=\"footer\"><a href=\"#top\">top</a>\n\n<h2>Building</h2>\n<p>Generally using a LUA interface for a job submit plugin is best:\nIt is simple to write and maintain with minimal dependencies upon the Slurm\ndata structures.\nHowever using C does provide a mechanism to get more information than available\nusing LUA including full access to all of the data structures and functions\nin the slurmctld daemon.\nThe simplest way to build a C program would be to just replace one of the\njob submit plugins included in the Slurm distribution with your own code\n(i.e. use a patch with your own code).\nThen just build and install Slurm with that new code.\nBuilding a new plugin outside of the Slurm distribution is possible, but\nfar more complex.\nIt also requires access to a multitude of Slurm header files as shown in the\nproceedure below.</p>\n\n<ol>\n<li>You will need to at least partly build Slurm first. The \"configure\" command\nmust be executed in order to build the \"config.h\" file in the build directory.</li>\n\n<li>Create a local directory somewhere for your files to build with.\nAlso create subdirectories named \".libs\" and \".deps\".</li>\n\n<li>Copy a \".deps/job_submit_*Plo\" file from another job_submit plugin's \".deps\"\ndirectory (made as part of the build process) into your local \".deps\" subdirectory.\nRename the file as appropriate to reflect your plugins name (e.g. rename\n\"job_submit_partition.Plo\" to be something like \"job_submit_mine.Plo\").</li>\n\n<li>Compile and link your plugin. Those options might differ depending\nupon your build environment. Check the options used for building the\nother job_submit plugins and modify the example below as required.</li>\n\n<li>Install the plugin.</li>\n</ol>\n\n<pre>\n# Example:\n# The Slurm source is in ~/SLURM/slurm.git\n# The Slurm build directory is ~/SLURM/slurm.build\n# The plugin build is to take place in the directory\n#   \"~/SLURM/my_submit\"\n# The installation locaiton is \"/usr/local\"\n\n# Build Slurm from ~/SLURM/slurm.build\n# (or at least run \"~/SLURM/slurm.git/configure\")\n\n# Set up your plugin files\ncd ~/SLURM\nmkdir my_submit\ncd my_submit\nmkdir .libs\nmkdir .deps\n# Create your plugin code\nvi job_submit_mine.c\n\n# Copy up a dependency file\ncp ~/SLURM/slurm.build/src/plugins/job_submit/partition/.deps/job_submit_partition.Plo \\\n   .deps/job_submit_mine.Plo\n\n# Compile\ngcc -DHAVE_CONFIG_H -I~/SLURM/slurm.build -I~/slurm.git \\\n   -g -O2 -pthread -fno-gcse -Werror -Wall -g -O0       \\\n   -fno-strict-aliasing -MT job_submit_mine.lo          \\\n   -MD -MP -MF .deps/job_submit_mine.Tpo                \\\n   -c job_submit_mine.c -o .libs/job_submit_mine.o\n\n# Some clean up\nmv -f .deps/job_submit_mine.Tpo .deps/job_submit_mine.Plo\nrm -fr .libs/job_submit_mine.a .libs/job_submit_mine.la \\\n   .libs/job_submit_mine.lai job_submit_mine.so\n\n# Link\ngcc -shared -fPIC -DPIC .libs/job_submit_mine.o -O2         \\\n   -pthread -O0 -pthread -Wl,-soname -Wl,job_submit_mine.so \\\n   -o job_submit_mine.so\n\n# Install\ncp job_submit_mine.so file \\\n   /usr/local/lib/slurm/job_submit_mine.so\n</pre>\n\n<p style=\"text-align:center;\">Last modified 29 September 2017</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/faq.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Frequently Asked Questions</a></h1>\n\n<h2>For Management</h2>\n<ol>\n<li><a href=\"#foss\">Why should I use Slurm or other Free Open Source Software (FOSS)</a></li>\n</ol>\n\n<h2>For Users</h2>\n<ol>\n<li><a href=\"#comp\">Why is my job/node in COMPLETING state?</a></li>\n<li><a href=\"#rlimit\">Why are my resource limits not propagated?</a></li>\n<li><a href=\"#pending\">Why is my job not running?</a></li>\n<li><a href=\"#sharing\">Why does the srun --overcommit option not permit\n  multiple jobs to run on nodes?</a></li>\n<li><a href=\"#purge\">Why is my job killed prematurely?</a></li>\n<li><a href=\"#opts\">Why are my srun options ignored?</a></li>\n<li><a href=\"#backfill\">Why is the Slurm backfill scheduler not starting my\n  job?</a></li>\n<li><a href=\"#steps\">How can I run multiple jobs from within a single\n  script?</a></li>\n<li><a href=\"#orphan\">Why do I have job steps when my job has already\n  COMPLETED?</a></li>\n<li><a href=\"#multi_batch\">How can I run a job within an existing job\n  allocation?</a></li>\n<li><a href=\"#user_env\">How does Slurm establish the environment for my\n  job?</a></li>\n<li><a href=\"#prompt\">How can I get shell prompts in interactive mode?</a></li>\n<li><a href=\"#batch_out\">How can I get the task ID in the output or error file\n  name for a batch job?</a></li>\n<li><a href=\"#parallel_make\">Can the <i>make</i> command utilize the resources\n  allocated to a Slurm job?</a></li>\n<li><a href=\"#terminal\">Can tasks be launched with a remote (pseudo)\n  terminal?</a></li>\n<li><a href=\"#force\">What does &quot;srun: Force Terminated job&quot;\n  indicate?</a></li>\n<li><a href=\"#early_exit\">What does this mean: &quot;srun: First task exited\n  30s ago&quot; followed by &quot;srun Job Failed&quot;?</a></li>\n<li><a href=\"#memlock\">Why is my MPI job  failing due to the locked memory\n  (memlock) limit being too low?</a></li>\n<li><a href=\"#inactive\">Why is my batch job that launches no job steps being\n  killed?</a></li>\n<li><a href=\"#arbitrary\">How do I run specific tasks on certain nodes\n  in my allocation?</a></li>\n<li><a href=\"#hold\">How can I temporarily prevent a job from running\n  (e.g. place it into a <i>hold</i> state)?</a></li>\n<li><a href=\"#mem_limit\">Why are jobs not getting the appropriate\n  memory limit?</a></li>\n<li><a href=\"#mailing_list\">Is an archive available of messages posted to\n  the <i>slurm-users</i> mailing list?</a></li>\n<li><a href=\"#job_size\">Can I change my job's size after it has started\n  running?</a></li>\n<li><a href=\"#mpi_symbols\">Why is my MPICH2 or MVAPICH2 job not running with\n  Slurm? Why does the DAKOTA program not run with Slurm?</a></li>\n<li><a href=\"#estimated_start_time\">Why does squeue (and \"scontrol show\n  jobid\") sometimes not display a job's estimated start time?</a></li>\n<li><a href=\"#ansys\">How can I run an Ansys program with Slurm?</a></li>\n<li><a href=\"#mic\">How can I run programs with on an Intel Phi (MIC) processor?</a></li>\n<li><a href=\"#req\">How can a job in complete or failed state be requeued?</a></li>\n<li><a href=\"#cpu_count\">Slurm documentation refers to CPUs, cores and threads.\n  What exactly is considered a CPU?</a></li>\n<li><a href=\"#sbatch_srun\">What is the difference between the sbatch\n  and srun commands?</a></li>\n<li><a href=\"#squeue_color\">Can squeue output be color coded?</a></li>\n<li><a href=\"#x11\">Can Slurm export an X11 display on an allocated compute node?</a></li>\n<li><a href=\"#unbuffered_cr\">Why is the srun --u/--unbuffered option adding\n   a carriage return to my output?</a></li>\n<li><a href=\"#sview_colors\">Why is sview not coloring/highlighting nodes\n    properly?</a></li>\n</ol>\n\n<h2>For Administrators</h2>\n<ol>\n<li><a href=\"#suspend\">How is job suspend/resume useful?</a></li>\n<li><a href=\"#fast_schedule\">How can I configure Slurm to use the resources\n  actually found on a node rather than what is defined in\n  <i>slurm.conf</i>?</a></li>\n<li><a href=\"#return_to_service\">Why is a node shown in state DOWN when the node\n  has registered for service?</a></li>\n<li><a href=\"#down_node\">What happens when a node crashes?</a></li>\n<li><a href=\"#multi_job\">How can I control the execution of multiple\n  jobs per node?</a></li>\n<li><a href=\"#inc_plugin\">When the Slurm daemon starts, it prints\n  &quot;cannot resolve X plugin operations&quot; and exits. What does this mean?</a></li>\n<li><a href=\"#pam_exclude\">How can I exclude some users from pam_slurm?</a></li>\n<li><a href=\"#maint_time\">How can I dry up the workload for a maintenance\n  period?</a></li>\n<li><a href=\"#pam\">How can PAM be used to control a user's limits on or\n  access to compute nodes?</a></li>\n<li><a href=\"#time\">Why are jobs allocated nodes and then unable to initiate\n  programs on some nodes?</a></li>\n<li><a href=\"#ping\"> Why does <i>slurmctld</i> log that some nodes\n  are not responding even if they are not in any partition?</a></li>\n<li><a href=\"#controller\"> How should I relocate the primary or backup\n  controller?</a></li>\n<li><a href=\"#multi_slurm\">Can multiple Slurm systems be run in\n  parallel for testing purposes?</a></li>\n<li><a href=\"#multi_slurmd\">Can Slurm emulate a larger cluster?</a></li>\n<li><a href=\"#extra_procs\">Can Slurm emulate nodes with more\n  resources than physically exist on the node?</a></li>\n<li><a href=\"#credential_replayed\">What does a\n  &quot;credential replayed&quot; error in the <i>SlurmdLogFile</i>\n  indicate?</a></li>\n<li><a href=\"#large_time\">What does\n  &quot;Warning: Note very large processing time&quot;\n  in the <i>SlurmctldLogFile</i> indicate?</a></li>\n<li><a href=\"#limit_propagation\">Is resource limit propagation\n  useful on a homogeneous cluster?</a></li>\n<li><a href=\"#clock\">Do I need to maintain synchronized clocks\n  on the cluster?</a></li>\n<li><a href=\"#cred_invalid\">Why are &quot;Invalid job credential&quot; errors\n  generated?</a></li>\n<li><a href=\"#cred_replay\">Why are\n  &quot;Task launch failed on node ... Job credential replayed&quot;\n  errors generated?</a></li>\n<li><a href=\"#globus\">Can Slurm be used with Globus?</a></li>\n<li><a href=\"#file_limit\">What causes the error\n  &quot;Unable to accept new connection: Too many open files&quot;?</a></li>\n<li><a href=\"#slurmd_log\">Why does the setting of <i>SlurmdDebug</i> fail\n  to log job step information at the appropriate level?</a></li>\n<li><a href=\"#rpm\">Why isn't the auth_none.so (or other file) in a\n  Slurm RPM?</a></li>\n<li><a href=\"#slurmdbd\">Why should I use the slurmdbd instead of the\n  regular database plugins?</a></li>\n<li><a href=\"#debug\">How can I build Slurm with debugging symbols?</a></li>\n<li><a href=\"#state_preserve\">How can I easily preserve drained node\n  information between major Slurm updates?</a></li>\n<li><a href=\"#health_check\">Why doesn't the <i>HealthCheckProgram</i>\n  execute on DOWN nodes?</a></li>\n<li><a href=\"#batch_lost\">What is the meaning of the error\n  &quot;Batch JobId=# missing from master node, killing it&quot;?</a></li>\n<li><a href=\"#accept_again\">What does the message\n  &quot;srun: error: Unable to accept connection: Resources temporarily unavailable&quot;\n  indicate?</a></li>\n<li><a href=\"#task_prolog\">How could I automatically print a job's\n  Slurm job ID to its standard output?</a></li>\n<li><a href=\"#orphan_procs\">Why are user processes and <i>srun</i>\n  running even though the job is supposed to be completed?</a></li>\n<li><a href=\"#slurmd_oom\">How can I prevent the <i>slurmd</i> and\n  <i>slurmstepd</i> daemons from being killed when a node's memory\n  is exhausted?</a></li>\n<li><a href=\"#ubuntu\">I see my host of my calling node as 127.0.1.1\n  instead of the correct IP address.  Why is that?</a></li>\n<li><a href=\"#stop_sched\">How can I stop Slurm from scheduling jobs?</a></li>\n<li><a href=\"#scontrol_multi_jobs\">Can I update multiple jobs with a single\n<i>scontrol</i> command?</a></li>\n<li><a href=\"#amazon_ec2\">Can Slurm be used to run jobs on Amazon's EC2?</a></li>\n<li><a href=\"#core_dump\">If a Slurm daemon core dumps, where can I find the\n  core file?</a></li>\n<li><a href=\"#totalview\">How can TotalView be configured to operate with\n  Slurm?</a></li>\n<li><a href=\"#git_patch\">How can a patch file be generated from a Slurm commit\n  in github?</a></li>\n<li><a href=\"#enforce_limits\">Why are the resource limits set in the database\n  not being enforced?</a></li>\n<li><a href=\"#restore_priority\">After manually setting a job priority value,\n  how can it's priority value be returned to being managed by the\n  priority/multifactor plugin?</a></li>\n<li><a href=\"#health_check_example\">Does any one have an example node health check\nscript for Slurm?</a></li>\n<li><a href=\"#add_nodes\">What process should I follow to add nodes to Slurm?</a></li>\n<li><a href=\"#licenses\">Can Slurm be configured to manage licenses?</a></li>\n<li><a href=\"#salloc_default_command\">Can the salloc command be configured to\n  launch a shell on a node in the job's allocation?</a></li>\n<li><a href=\"#upgrade\">What should I be aware of when upgrading Slurm?</a></li>\n<li><a href=\"#torque\">How easy is it to switch from PBS or Torque to Slurm?</a></li>\n<li><a href=\"#sssd\">I am having trouble using SSSD with Slurm.</a></li>\n<li><a href=\"#ha_db\">How critical is configuring high availability for my\n  database?</a></li>\n<li><a href=\"#sql\">How can I use double quotes in MySQL queries?</a></li>\n<li><a href=\"#reboot\">Why is a compute node down with the reason set to\n\"Node unexpectedly rebooted\"?</a></li>\n<li><a href=\"#reqspec\">How can a job which has exited with a specific exit code\n   be requeued?</a></li>\n<li><a href=\"#user_account\">Can a user's account be changed in the database?</a></li>\n<li><a href=\"#mpi_perf\">What might account for MPI performance being below the\n   expected level?</a></li>\n<li><a href=\"#state_info\">How could some jobs submitted immediately before the\n   slurmctld daemon crashed be lost?</a></li>\n<li><a href=\"#delete_partition\">How do I safely remove partitions?</a></li>\n<li><a href=\"#cpu_freq\">Why is Slurm unable to set the CPU frequency for jobs?</a></li>\n<li><a href=\"#mic_config\">How can Slurm be configured to support Intel Phi (MIC)?</a></li>\n<li><a href=\"#cluster_acct\">When adding a new cluster, how can the Slurm cluster\n    configuration be copied from an existing cluster to the new cluster?</a></li>\n<li><a href=\"#cray_dvs\">How can I update Slurm on a Cray DVS file system without\n    rebooting the nodes?</a></li>\n<li><a href=\"#dbd_rebuild\">How can I rebuild the database hierarchy?</a></li>\n<li><a href=\"#routing queue\">How can a routing queue be configured?</a></li>\n<li><a href=\"#squeue_script\">How can I suspend, resume, hold or release all\n    of the jobs belonging to a speciic user, partition, etc?</a></li>\n<li><a href=\"#changed_uid\">I had to change a user's UID and now they cannot submit\n    jobs. How do I get the new UID to take effect?</a></li>\n<li><a href=\"#mysql_duplicate\">Slurmdbd is failing to start with a 'Duplicate entry'\n    error in the database. How do I fix that?</a></li>\n<li><a href=\"#cray_sigbus\">Why are applications on my Cray system failing\n    with SIGBUS (bus error)?</a></li>\n</ol>\n\n<h2>For Management</h2>\n<p><a name=\"foss\"><b>1. Why should I use Slurm or other Free Open Source Software (FOSS)?</b></a><br>\nFree Open Source Software (FOSS) does not mean that it is without cost.\nIt does mean that the you have access to the code so that you are free to\nuse it, study it, and/or enhance it.\nThese reasons contribute to Slurm (and FOSS in general) being subject to\nactive research and development worldwide, displacing proprietary software\nin many environments.\nIf the software is large and complex, like Slurm or the Linux kernel,\nthen while there is no license fee, its use is not without cost.</p>\n<p>If your work is important, you'll want the leading Slurm experts at your\ndisposal to keep your systems operating at peak efficiency.\nWhile Slurm has a global development community incorporating leading edge\ntechnology, <a href=\"https://www.schedmd.com\">SchedMD</a> personnel have developed\nmost of the code and can provide competitively priced commercial support.\nSchedMD works with various organizations to provide a range of support\noptions ranging from remote level-3 support to 24x7 on-site personnel.\nCustomers switching from commercial workload mangers to Slurm typically\nreport higher scalability, better performance and lower costs.</p>\n\n<h2>For Users</h2>\n<p><a name=\"comp\"><b>1. Why is my job/node in COMPLETING state?</b></a><br>\nWhen a job is terminating, both the job and its nodes enter the COMPLETING state.\nAs the Slurm daemon on each node determines that all processes associated with\nthe job have terminated, that node changes state to IDLE or some other appropriate\nstate for use by other jobs.\nWhen every node allocated to a job has determined that all processes associated\nwith it have terminated, the job changes state to COMPLETED or some other\nappropriate state (e.g. FAILED).\nNormally, this happens within a second.\nHowever, if the job has processes that cannot be terminated with a SIGKILL\nsignal, the job and one or more nodes can remain in the COMPLETING state\nfor an extended period of time.\nThis may be indicative of processes hung waiting for a core file\nto complete I/O or operating system failure.\nIf this state persists, the system administrator should check for processes\nassociated with the job that cannot be terminated then use the\n<span class=\"commandline\">scontrol</span> command to change the node's\nstate to DOWN (e.g. &quot;scontrol update NodeName=<i>name</i> State=DOWN Reason=hung_completing&quot;),\nreboot the node, then reset the node's state to IDLE\n(e.g. &quot;scontrol update NodeName=<i>name</i> State=RESUME&quot;).\nNote that setting the node DOWN will terminate all running or suspended\njobs associated with that node.\nAn alternative is to set the node's state to DRAIN until all jobs\nassociated with it terminate before setting it DOWN and re-booting.</p>\n<p>Note that Slurm has two configuration parameters that may be used to\nautomate some of this process.\n<i>UnkillableStepProgram</i> specifies a program to execute when\nnon-killable processes are identified.\n<i>UnkillableStepTimeout</i> specifies how long to wait for processes\nto terminate.\nSee the \"man slurm.conf\" for more information about these parameters.</p>\n\n<p><a name=\"rlimit\"><b>2. Why are my resource limits not propagated?</b></a><br>\nWhen the <span class=\"commandline\">srun</span> command executes, it captures the\nresource limits in effect at submit time on the node where srun executes.\nThese limits are propagated to the allocated nodes before initiating the\nuser's job.\nThe Slurm daemons running on the allocated nodes then try to establish\nidentical resource limits for the job being initiated.\nThere are several possible reasons for not being able to establish those\nresource limits.\n<ul>\n<li>The hard resource limits applied to Slurm's slurmd daemon are lower\nthan the user's soft resources limits on the submit host. Typically\nthe slurmd daemon is initiated by the init daemon with the operating\nsystem default limits. This may be addressed either through use of the\nulimit command in the /etc/sysconfig/slurm file or enabling\n<a href=\"#pam\">PAM in Slurm</a>.</li>\n<li>The user's hard resource limits on the allocated node are lower than\nthe same user's soft hard resource limits on the node from which the\njob was submitted. It is recommended that the system administrator\nestablish uniform hard resource limits for users on all nodes\nwithin a cluster to prevent this from occurring.</li>\n<li>PropagateResourceLimits or PropagateResourceLimitsExcept parameters are\nconfigured in slurm.conf and avoid propagation of specified limits.</li>\n</ul>\n</p>\n<p>NOTE: This may produce the error message &quot;Can't propagate RLIMIT_...&quot;.\nThe error message is printed only if the user explicitly specifies that\nthe resource limit should be propagated or the srun command is running\nwith verbose logging of actions from the slurmd daemon (e.g. \"srun -d6 ...\").</p>\n\n<p><a name=\"pending\"><b>3. Why is my job not running?</b></a><br>\nThe answer to this question depends on a lot of factors. Main one relies upon\nthe scheduler used by Slurm. Executing the command</p>\n<blockquote>\n<p> <span class=\"commandline\">scontrol show config | grep SchedulerType</span></p>\n</blockquote>\n<p> will supply this information. If the scheduler type is <b>builtin</b>, then\njobs will be executed in the order of submission for a given partition. Even if\nresources are available to initiate your job immediately, it will be deferred\nuntil no previously submitted job is pending. If the scheduler type is <b>backfill</b>,\nthen jobs will generally be executed in the order of submission for a given partition\nwith one exception: later submitted jobs will be initiated early if doing so does\nnot delay the expected execution time of an earlier submitted job. In order for\nbackfill scheduling to be effective, users' jobs should specify reasonable time\nlimits. If jobs do not specify time limits, then all jobs will receive the same\ntime limit (that associated with the partition), and the ability to backfill schedule\njobs will be limited. The backfill scheduler does not alter job specifications\nof required or excluded nodes, so jobs which specify nodes will substantially\nreduce the effectiveness of backfill scheduling. See the <a href=\"#backfill\">\nbackfill</a> section for more details. For any scheduler, you can check priorities\nof jobs using the command <span class=\"commandline\">scontrol show job</span>.\nOther reasons can include waiting for resources, memory, qos, reservations, etc.\nAs a guide line, issue an <span class=\"commandline\">scontrol show job &lt;jobid&gt;</span>\nand look at the field <i>State</i> and <i>Reason</i> to investigate the cause.</p></p>\n\n<p><a name=\"sharing\"><b>4. Why does the srun --overcommit option not permit multiple jobs\nto run on nodes?</b></a><br>\nThe <b>--overcommit</b> option is a means of indicating that a job or job step is willing\nto execute more than one task per processor in the job's allocation. For example,\nconsider a cluster of two processor nodes. The srun execute line may be something\nof this sort</p>\n<blockquote>\n<p><span class=\"commandline\">srun --ntasks=4 --nodes=1 a.out</span></p>\n</blockquote>\n<p>This will result in not one, but two nodes being allocated so that each of the four\ntasks is given its own processor. Note that the srun <b>--nodes</b> option specifies\na minimum node count and optionally a maximum node count. A command line of</p>\n<blockquote>\n<p><span class=\"commandline\">srun --ntasks=4 --nodes=1-1 a.out</span></p>\n</blockquote>\n<p>would result in the request being rejected. If the <b>--overcommit</b> option\nis added to either command line, then only one node will be allocated for all\nfour tasks to use.</p>\n<p>More than one job can execute simultaneously on the same compute resource\n(e.g. CPU) through the use of srun's <b>--oversubscribe</b> option in\nconjunction with the <b>OverSubscribe</b> parameter in Slurm's partition\nconfiguration. See the man pages for srun and slurm.conf for more information.</p>\n\n<p><a name=\"purge\"><b>5. Why is my job killed prematurely?</b></a><br>\nSlurm has a job purging mechanism to remove inactive jobs (resource allocations)\nbefore reaching its time limit, which could be infinite.\nThis inactivity time limit is configurable by the system administrator.\nYou can check its value with the command</p>\n<blockquote>\n<p><span class=\"commandline\">scontrol show config | grep InactiveLimit</span></p>\n</blockquote>\n<p>The value of InactiveLimit is in seconds.\nA zero value indicates that job purging is disabled.\nA job is considered inactive if it has no active job steps or if the srun\ncommand creating the job is not responding.\nIn the case of a batch job, the srun command terminates after the job script\nis submitted.\nTherefore batch job pre- and post-processing is limited to the InactiveLimit.\nContact your system administrator if you believe the InactiveLimit value\nshould be changed.\n\n<p><a name=\"opts\"><b>6. Why are my srun options ignored?</b></a><br>\nEverything after the command <span class=\"commandline\">srun</span> is\nexamined to determine if it is a valid option for srun. The first\ntoken that is not a valid option for srun is considered the command\nto execute and everything after that is treated as an option to\nthe command. For example:</p>\n<blockquote>\n<p><span class=\"commandline\">srun -N2 hostname -pdebug</span></p>\n</blockquote>\n<p>srun processes \"-N2\" as an option to itself. \"hostname\" is the\ncommand to execute and \"-pdebug\" is treated as an option to the\nhostname command. This will change the name of the computer\non which Slurm executes the command - Very bad, <b>Don't run\nthis command as user root!</b></p>\n\n<p><a name=\"backfill\"><b>7. Why is the Slurm backfill scheduler not starting my job?\n</b></a><br>\nThe most common problem is failing to set job time limits. If all jobs have\nthe same time limit (for example the partition's time limit), then backfill\nwill not be effective. Note that partitions can have both default and maximum\ntime limits, which can be helpful in configuring a system for effective\nbackfill scheduling.</p>\n\n<p>In addition, there are a multitude of backfill scheduling parameters\nwhich can impact which jobs are considered for backfill scheduling, such\nas the maximum number of jobs tested per user. For more information see\nthe slurm.conf man page and check the configuration of SchedulingParameters\non your system.</p>\n\n<p><a name=\"steps\"><b>8. How can I run multiple jobs from within a\nsingle script?</b></a><br>\nA Slurm job is just a resource allocation. You can execute many\njob steps within that allocation, either in parallel or sequentially.\nSome jobs actually launch thousands of job steps this way. The job\nsteps will be allocated nodes that are not already allocated to\nother job steps. This essential provides a second level of resource\nmanagement within the job for the job steps.</p>\n\n<p><a name=\"orphan\"><b>9. Why do I have job steps when my job has\nalready COMPLETED?</b></a><br>\nNOTE: This only applies to systems configured with\n<i>SwitchType=switch/nrt</i>.\nAll other systems will purge all job steps on job completion.</p>\n<p>Slurm maintains switch (network interconnect) information within\nthe job step for IBM NRT switches.\nThis information must be maintained until we are absolutely certain\nthat the processes associated with the switch have been terminated\nto avoid the possibility of re-using switch resources for other\njobs (even on different nodes).\nSlurm considers jobs COMPLETED when all nodes allocated to the\njob are either DOWN or confirm termination of all its processes.\nThis enables Slurm to purge job information in a timely fashion\neven when there are many failing nodes.\nUnfortunately the job step information may persist longer.</p>\n\n<p><a name=\"multi_batch\"><b>10. How can I run a job within an existing\njob allocation?</b></a><br>\nThere is a srun option <i>--jobid</i> that can be used to specify\na job's ID.\nFor a batch job or within an existing resource allocation, the\nenvironment variable <i>SLURM_JOB_ID</i> has already been defined,\nso all job steps will run within that job allocation unless\notherwise specified.\nThe one exception to this is when submitting batch jobs.\nWhen a batch job is submitted from within an existing batch job,\nit is treated as a new job allocation request and will get a\nnew job ID unless explicitly set with the <i>--jobid</i> option.\nIf you specify that a batch job should use an existing allocation,\nthat job allocation will be released upon the termination of\nthat batch job.</p>\n\n<p><a name=\"user_env\"><b>11. How does Slurm establish the environment\nfor my job?</b></a><br>\nSlurm processes are not run under a shell, but directly exec'ed\nby the <i>slurmd</i> daemon (assuming <i>srun</i> is used to launch\nthe processes).\nThe environment variables in effect at the time the <i>srun</i> command\nis executed are propagated to the spawned processes.\nThe <i>~/.profile</i> and <i>~/.bashrc</i> scripts are not executed\nas part of the process launch. You can also look at <i>--export</i> option of\nsrun and sbatch. See man pages for details.</p>\n\n<p><a name=\"prompt\"><b>12. How can I get shell prompts in interactive\nmode?</b></a><br>\n<i>srun --pty bash -i</i><br/>\nSrun's <i>--pty</i> option runs task zero in pseudo terminal mode.\nBash's <i>-i</i> option tells it to run in interactive mode (with prompts).\n<br/>You can also configure <i>SallocDefaultCommand</i> in <i>slurm.conf</i>\nto automatically launch a shell, e.g.:\n<pre>\nSallocDefaultCommand=\"srun -n1 -N1 --mem-per-cpu=0 --pty --preserve-env --cpu_bind=no --mpi=none $SHELL\"\n</pre>\nAnd then run <i>salloc</i> directly which will provide you an allocation with\nan interactive shell console.\n<p><a name=\"batch_out\"><b>13. How can I get the task ID in the output\nor error file name for a batch job?</b></a><br>\n<p>If you want separate output by task, you will need to build a script\ncontaining this specification. For example:</p>\n<pre>\n$ cat test\n#!/bin/sh\necho begin_test\nsrun -o out_%j_%t hostname\n\n$ sbatch -n7 -o out_%j test\nsbatch: Submitted batch job 65541\n\n$ ls -l out*\n-rw-rw-r--  1 jette jette 11 Jun 15 09:15 out_65541\n-rw-rw-r--  1 jette jette  6 Jun 15 09:15 out_65541_0\n-rw-rw-r--  1 jette jette  6 Jun 15 09:15 out_65541_1\n-rw-rw-r--  1 jette jette  6 Jun 15 09:15 out_65541_2\n-rw-rw-r--  1 jette jette  6 Jun 15 09:15 out_65541_3\n-rw-rw-r--  1 jette jette  6 Jun 15 09:15 out_65541_4\n-rw-rw-r--  1 jette jette  6 Jun 15 09:15 out_65541_5\n-rw-rw-r--  1 jette jette  6 Jun 15 09:15 out_65541_6\n\n$ cat out_65541\nbegin_test\n\n$ cat out_65541_2\ntdev2\n</pre>\n\n<p><a name=\"parallel_make\"><b>14. Can the <i>make</i> command\nutilize the resources allocated to a Slurm job?</b></a><br>\nYes. There is a patch available for GNU make version 3.81\navailable as part of the Slurm distribution in the file\n<i>contribs/make-3.81.slurm.patch</i>.  For GNU make version 4.0 you\ncan use the patch in the file <i>contribs/make-4.0.slurm.patch</i>.\nThis patch will use Slurm to launch tasks across a job's current resource\nallocation. Depending upon the size of modules to be compiled, this may\nor may not improve performance. If most modules are thousands of lines\nlong, the use of additional resources should more than compensate for the\noverhead of Slurm's task launch. Use with make's <i>-j</i> option within an\nexisting Slurm allocation. Outside of a Slurm allocation, make's behavior\nwill be unchanged.</p>\n\n<p><a name=\"terminal\"><b>15. Can tasks be launched with a remote (pseudo)\nterminal?</b></a><br>\nYou have several ways to do so, the recommended ones are the following:<br>\nThe simplest method is to make use of srun's <i>--pty</i> option,\n(e.g. <i>srun --pty bash -i</i>).\nSrun's <i>--pty</i> option runs task zero in pseudo terminal mode. Bash's\n<i>-i</i> option instructs it to run in interactive mode (with prompts).<br>\nIn addition to that method you have the option to define the\n<i>SallocDefaultCommand</i> to run a task in pseudo terminal mode directly,\nso you get the prompt just invoking salloc:\n<pre>SallocDefaultCommand=\"srun -n1 -N1 --mem-per-cpu=0 --pty --preserve-env --cpu_bind=no --mpi=none $SHELL\"</pre>\nFinally you can make use of X11 feature and run a graphical terminal.\n(e.g. <i>srun xterm</i>).<br>\n<p><a name=\"force\"><b>16. What does &quot;srun: Force Terminated job&quot;\nindicate?</b></a><br>\nThe srun command normally terminates when the standard output and\nerror I/O from the spawned tasks end. This does not necessarily\nhappen at the same time that a job step is terminated. For example,\na file system problem could render a spawned task non-killable\nat the same time that I/O to srun is pending. Alternately a network\nproblem could prevent the I/O from being transmitted to srun.\nIn any event, the srun command is notified when a job step is\nterminated, either upon reaching its time limit or being explicitly\nkilled. If the srun has not already terminated, the message\n&quot;srun: Force Terminated job&quot; is printed.\nIf the job step's I/O does not terminate in a timely fashion\nthereafter, pending I/O is abandoned and the srun command\nexits.</p>\n\n<p><a name=\"early_exit\"><b>17. What does this mean:\n&quot;srun: First task exited 30s ago&quot;\nfollowed by &quot;srun Job Failed&quot;?</b></a><br>\nThe srun command monitors when tasks exit. By default, 30 seconds\nafter the first task exists, the job is killed.\nThis typically indicates some type of job failure and continuing\nto execute a parallel job when one of the tasks has exited is\nnot normally productive. This behavior can be changed using srun's\n<i>--wait=&lt;time&gt;</i> option to either change the timeout\nperiod or disable the timeout altogether. See srun's man page\nfor details.</p>\n\n<p><a name=\"memlock\"><b>18. Why is my MPI job  failing due to the\nlocked memory (memlock) limit being too low?</b></a><br>\nBy default, Slurm propagates all of your resource limits at the\ntime of job submission to the spawned tasks.\nThis can be disabled by specifically excluding the propagation of\nspecific limits in the <i>slurm.conf</i> file. For example\n<i>PropagateResourceLimitsExcept=MEMLOCK</i> might be used to\nprevent the propagation of a user's locked memory limit from a\nlogin node to a dedicated node used for his parallel job.\nIf the user's resource limit is not propagated, the limit in\neffect for the <i>slurmd</i> daemon will be used for the spawned job.\nA simple way to control this is to ensure that user <i>root</i> has a\nsufficiently large resource limit and ensuring that <i>slurmd</i> takes\nfull advantage of this limit. For example, you can set user root's\nlocked memory limit ulimit to be unlimited on the compute nodes (see\n<i>\"man limits.conf\"</i>) and ensuring that <i>slurmd</i> takes\nfull advantage of this limit (e.g. by adding something like\n<i>\"ulimit -l unlimited\"</i> to the <i>/etc/init.d/slurm</i>\nscript used to initiate <i>slurmd</i>). It may also be desirable to lock\nthe slurmd daemon's memory to help ensure that it keeps responding if memory\nswapping begins. A sample <i>/etc/sysconfig/slurm</i> file is shown below.\nRelated information about <a href=\"#pam\">PAM</a> is also available.</p>\n<pre>\n#\n# Example /etc/sysconfig/slurm\n#\n# Increase the memlock limit so that user tasks can get\n# unlimited memlock\nulimit -l unlimited\n#\n# Increase the open file limit\nulimit -n 8192\n#\n# Memlocks the slurmd process's memory so that if a node\n# starts swapping, the slurmd will continue to respond\nSLURMD_OPTIONS=\"-M\"\n</pre>\n\n<p><a name=\"inactive\"><b>19. Why is my batch job that launches no\njob steps being killed?</b></a><br>\nSlurm has a configuration parameter <i>InactiveLimit</i> intended\nto kill jobs that do not spawn any job steps for a configurable\nperiod of time. Your system administrator may modify the <i>InactiveLimit</i>\nto satisfy your needs. Alternately, you can just spawn a job step\nat the beginning of your script to execute in the background. It\nwill be purged when your script exits or your job otherwise terminates.\nA line of this sort near the beginning of your script should suffice:<br>\n<i>srun -N1 -n1 sleep 999999 &</i></p>\n\n<p><a name=\"arbitrary\"><b>20. How do I run specific tasks on certain nodes\nin my allocation?</b></a><br>\nOne of the distribution methods for srun '<b>-m</b>\nor <b>--distribution</b>' is 'arbitrary'.  This means you can tell Slurm to\nlayout your tasks in any fashion you want.  For instance if I had an\nallocation of 2 nodes and wanted to run 4 tasks on the first node and\n1 task on the second and my nodes allocated from SLURM_JOB_NODELIST\nwhere tux[0-1] my srun line would look like this:<br><br>\n<i>srun -n5 -m arbitrary -w tux[0,0,0,0,1] hostname</i><br><br>\nIf I wanted something similar but wanted the third task to be on tux 1\nI could run this:<br><br>\n<i>srun -n5 -m arbitrary -w tux[0,0,1,0,0] hostname</i><br><br>\nHere is a simple perl script named arbitrary.pl that can be ran to easily lay\nout tasks on nodes as they are in SLURM_JOB_NODELIST.</p>\n<pre>\n#!/usr/bin/perl\nmy @tasks = split(',', $ARGV[0]);\nmy @nodes = `scontrol show hostnames $SLURM_JOB_NODELIST`;\nmy $node_cnt = $#nodes + 1;\nmy $task_cnt = $#tasks + 1;\n\nif ($node_cnt < $task_cnt) {\n\tprint STDERR \"ERROR: You only have $node_cnt nodes, but requested layout on $task_cnt nodes.\\n\";\n\t$task_cnt = $node_cnt;\n}\n\nmy $cnt = 0;\nmy $layout;\nforeach my $task (@tasks) {\n\tmy $node = $nodes[$cnt];\n\tlast if !$node;\n\tchomp($node);\n\tfor(my $i=0; $i < $task; $i++) {\n\t\t$layout .= \",\" if $layout;\n\t\t$layout .= \"$node\";\n\t}\n\t$cnt++;\n}\nprint $layout;\n</pre>\n\n<p>We can now use this script in our srun line in this fashion.<br><br>\n<i>srun -m arbitrary -n5 -w `arbitrary.pl 4,1` -l hostname</i><br><br>\n<p>This will layout 4 tasks on the first node in the allocation and 1\ntask on the second node.</p>\n\n<p><a name=\"hold\"><b>21. How can I temporarily prevent a job from running\n(e.g. place it into a <i>hold</i> state)?</b></a><br>\nThe easiest way to do this is to change a job's earliest begin time\n(optionally set at job submit time using the <i>--begin</i> option).\nThe example below places a job into hold state (preventing its initiation\nfor 30 days) and later permitting it to start now.</p>\n<pre>\n$ scontrol update JobId=1234 StartTime=now+30days\n... later ...\n$ scontrol update JobId=1234 StartTime=now\n</pre>\n\n<p><a name=\"mem_limit\"><b>22. Why are jobs not getting the appropriate\nmemory limit?</b></a><br>\nThis is probably a variation on the <a href=\"#memlock\">locked memory limit</a>\nproblem described above.\nUse the same solution for the AS (Address Space), RSS (Resident Set Size),\nor other limits as needed.</p>\n\n<p><a name=\"mailing_list\"><b>23. Is an archive available of messages posted to\nthe <i>slurm-users</i> mailing list?</b></a><br>\nYes, it is at <a href=\"http://groups.google.com/group/slurm-users\">\nhttp://groups.google.com/group/slurm-users</a></p>\n\n<p><a name=\"job_size\"><b>24. Can I change my job's size after it has started\nrunning?</b></a><br>\nSlurm supports the ability to both increase and decrease the size of running jobs.\nWhile the size of a pending job may be changed with few restrictions, several\nsignificant restrictions apply to changing the size of a running job as noted\nbelow:\n<ol>\n<li>Support is not available on BlueGene or Cray ALPS system due to limitations\nin the software underlying Slurm.</li>\n<li>Job(s) changing size must not be in a suspended state, including jobs\nsuspended for gang scheduling. The jobs must be in a state of pending or\nrunning. We plan to modify the gang scheduling logic in the future to\nconcurrently schedule a job to be used for expanding another job and the\njob to be expanded.</li>\n</ol></p>\n\n<p>Use the <i>scontrol</i> command to change a job's size either by specifying\na new node count (<i>NumNodes=</i>) for the job or identify the specific nodes\n(<i>NodeList=</i>) that you want the job to retain.\nAny job steps running on the nodes which are relinquished by the job will be\nkilled unless initiated with the <i>--no-kill</i> option.\nAfter the job size is changed, some environment variables created by Slurm\ncontaining information about the job's environment will no longer be valid and\nshould either be removed or altered (e.g. SLURM_JOB_NODES, SLURM_JOB_NODELIST and\nSLURM_NTASKS).\nThe <i>scontrol</i> command will generate a script that can be executed to\nreset local environment variables.\nYou must retain the SLURM_JOB_ID environment variable in order for the\n<i>srun</i> command to gather information about the job's current state and\nspecify the desired node and/or task count in subsequent <i>srun</i> invocations.\nA new accounting record is generated when a job is resized showing the to have\nbeen resubmitted and restarted at the new size.\nAn example is shown below.</p>\n<pre>\n#!/bin/bash\nsrun my_big_job\nscontrol update JobId=$SLURM_JOB_ID NumNodes=2\n. slurm_job_${SLURM_JOB_ID}_resize.sh\nsrun -N2 my_small_job\nrm slurm_job_${SLURM_JOB_ID}_resize.*\n</pre>\n\n<p><b>Increasing a job's size</b><br>\nDirectly increasing the size of a running job would adversely effect the\nscheduling of pending jobs.\nFor the sake of fairness in job scheduling, expanding a running job requires\nthe user to submit a new job, but specify the option\n<i>--dependency=expand:&lt;jobid&gt;</i>.\nThis option tells Slurm that the job, when scheduled, can be used to expand\nthe specified jobid.\nOther job options would be used to identify the required resources\n(e.g. task count, node count, node features, etc.).\nThis new job's time limit will be automatically set to reflect the end time of\nthe job being expanded.\nThis new job's generic resources specification will be automatically set\nequal to that of the job being merged to. This is due to the current Slurm\nrestriction of all nodes associated with a job needing to have the same\ngeneric resource specification (i.e. a job can not have one GPU on one\nnode and two GPUs on another node), although this restriction may be removed\nin the future. This restriction can pose some problems when both jobs can be\nallocated resources on the same node, in which case the generic resources\nallocated to the new job will be released. If the jobs are allocated resources\non different nodes, the generic resources associated with the resulting job\nallocation after the merge will be consistent as expected.\nAny licenses associated with the new job will be added to those available in\nthe job being merged to.\nNote that partition and Quality Of Service (QOS) limits will be applied\nindependently to the new job allocation so the expanded job may exceed size\nlimits configured for an individual job.</p>\n\n<p>After the new job is allocated resources, merge that job's allocation\ninto that of the original job by executing:<br>\n<i>scontrol update jobid=&lt;jobid&gt; NumNodes=0</i><br>\nThe <i>jobid</i> above is that of the job to relinquish it's resources.\nTo provides more control over when the job expansion occurs, the resources are\nnot merged into the original job until explicitly requested.\nThese resources will be transferred to the original job and the scontrol\ncommand will generate a script to reset variables in the second\njob's environment to reflect it's modified resource allocation (which would\nbe no resources).\nOne would normally exit this second job at this point, since it has no\nassociated resources.\nIn order to generate a script to modify the environment variables for the\nexpanded job, execute:<br>\n<i>scontrol update jobid=&lt;jobid&gt; NumNodes=ALL</i><br>\nThen execute the script generated.\nNote that this command does not change the original job's size, but only\ngenerates the script to change its environment variables.\nUntil the environment variables are modified (e.g. the job's node count,\nCPU count, hostlist, etc.), any srun command will only consider the resources\nin the original resource allocation.\nNote that the original job may have active job steps at the time of it's\nexpansion, but they will not be effected by the change.\nAn example of the procedure is shown below in which the original job\nallocation waits until the second resource allocation request can be\nsatisfied. The job requesting additional resources could also use the sbatch\ncommand and permit the original job to continue execution at its initial size.\nNote that the development of additional user tools to manage Slurm resource\nallocations is planned in the future to make this process both simpler and\nmore flexible.</p>\n\n<pre>\n$ salloc -N4 -C haswell bash\nsalloc: Granted job allocation 65542\n$ srun hostname\nicrm1\nicrm2\nicrm3\nicrm4\n\n$ salloc -N4 -C knl,snc4,flat --dependency=expand:$SLURM_JOB_ID bash\nsalloc: Granted job allocation 65543\n$ scontrol update jobid=$SLURM_JOB_ID NumNodes=0\nTo reset Slurm environment variables, execute\n  For bash or sh shells:  . ./slurm_job_65543_resize.sh\n  For csh shells:         source ./slurm_job_65543_resize.csh\n$ exit\nexit\nsalloc: Relinquishing job allocation 65543\n\n$ scontrol update jobid=$SLURM_JOB_ID NumNodes=ALL\nTo reset Slurm environment variables, execute\n  For bash or sh shells:  . ./slurm_job_65542_resize.sh\n  For csh shells:         source ./slurm_job_65542_resize.csh\n$ . ./slurm_job_${SLURM_JOB_ID}_resize.sh\n\n$ srun hostname\nicrm1\nicrm2\nicrm3\nicrm4\nicrm5\nicrm6\nicrm7\nicrm8\n$ exit\nexit\nsalloc: Relinquishing job allocation 65542\n</pre>\n\n<p><a name=\"mpi_symbols\"><b>25. Why is my MPICH2 or MVAPICH2 job not running with\nSlurm? Why does the DAKOTA program not run with Slurm?</b></a><br>\nThe Slurm library used to support MPICH2 or MVAPICH2 references a variety of\nsymbols. If those symbols resolve to functions or variables in your program\nrather than the appropriate library, the application will fail. For example\n<a href=\"http://dakota.sandia.gov\">DAKOTA</a>, versions 5.1 and\nolder, contains a function named regcomp, which will get used rather\nthan the POSIX regex functions. Rename DAKOTA's function and\nreferences from regcomp to something else to make it work properly.</p>\n\n<p><a name=\"estimated_start_time\"><b>26. Why does squeue (and \"scontrol show\njobid\") sometimes not display a job's  estimated start time?</b></a><br>\nWhen the backfill scheduler is configured, it provides an estimated start time\nfor jobs that are candidates for backfill. Pending jobs with dependencies\nwill not have an estimate as it is difficult to predict what resources will\nbe available when the jobs they are dependent on terminate. Also note that\nthe estimate is better for jobs expected to start soon, as most running jobs\nend before their estimated time. There are other restrictions on backfill that\nmay apply. See the <a href=\"#backfill\">backfill</a> section for more details.\n</p>\n\n<p><a name=\"ansys\"><b>27. How can I run an Ansys program with Slurm?</b></a><br>\nIf you are talking about an interactive run of the Ansys app, then you can use\nthis simple script (it is for Ansys Fluent):</p>\n<pre>\n$ cat ./fluent-srun.sh\n#!/usr/bin/env bash\nHOSTSFILE=.hostlist-job$SLURM_JOB_ID\nif [ \"$SLURM_PROCID\" == \"0\" ]; then\n   srun hostname -f > $HOSTSFILE\n   fluent -t $SLURM_NTASKS -cnf=$HOSTSFILE -ssh 3d\n   rm -f $HOSTSFILE\nfi\nexit 0\n</pre>\n\n<p>To run an interactive session, use srun like this:</p>\n<pre>\n$ srun -n <tasks> ./fluent-srun.sh\n</pre>\n\n<p><a name=\"mic\"><b>28. How can I run programs with on an Intel Phi (MIC)\nprocessor?</b></a><br>\nTwo programming models are supported, offloading and native mode.\nSystem administrators should see the <a href=\"#mic_config\">Intel Phi\nconfiguration</a> information below.\nSlurm configuration details for Intel Phi offload support are available\nin Slurm's <a href=\"gres.html\">Generic Resource Guide</a>.\nFor a good description of how to build and run applications, please see\n<a href=\"https://confluence.csc.fi/display/HPCproto/HPC+Prototypes#HPCPrototypes-Nativeprogrammingmodel\">CSC MIC documentation</a>.\nNote that some of the information presented in this document is configuration\ndependent. The <i>mpirun-mic</i> is included in the Slurm distribution in the\n<i>contribs/mic</i> directory. Excerpts of the CSC documentation follow.</p>\n\n<p><b>Executable Auto-Offloading</b><br>\nThe Phi nodes have Executable Auto-Offloading (EAO) enabled by default.\nThis feature is developed at CSC and is not currently in the standard Xeon Phi\ndistribution.\nWith this feature, any executable in the K1OM (MIC) binary format that the user\ntries to run on the host, will transparently be executed on the Xeon Phi\ncoprocessor card instead. The execution is performed using the /usr/bin/micrun\nscript.</p>\n<p>By default all environment variables with the MIC_ prefix will be passed to\nthe binary, with the prefix stripped away. For example\n(MIC_LD_LIBRARY_PATH -> LD_LIBRARY_PATH).</p>\n<p>EAO can be disabled by setting the environment variable MICRUN_DISABLE\n(i.e. export MICRUN_DISABLE=1).</p>\n\n<p><b>Offload programming model</b><br>\nThe Intel compilers support offload compilation automatically. This means\neither offloading a code section using offload pragmas or calling an\noffload-enabled library. (e.g. MKL).</p>\n<p>In order to run offload jobs, one needs to set the GRES (Generic Resource\nScheduling) parameter '--gres=mic:1'. For example:</p>\n<pre>\n$ srun --gres=mic:1 ./hello\n</pre>\n<p>If this is not set, the user will the following warning:</p>\n<pre>\noffload warning: OFFLOAD_DEVICES device number -1 does not correspond to a physical device\n</pre>\n\n<p><b>Native OpenMP code</b><br>\nTo compile OpenMP code natively, you can use the -mmicflag.</p>\n<pre>\n$ module load intel\n$ icc -mmic -openmp hello.c -o hello.mic\n</pre>\n<p>To run, use the srun command. You may need to explicitly specify a Slurm partition containing MIC processors, for example:</p>\n<pre>\n$ srun -p mic ./hello.mic\n</pre>\n\n<p><a name=\"req\"><b>29. How can a job in complete or failed state be requeued?</b></a>\n<br>\n<p>\nSlurm supports requeue jobs in done or failed state. Use the\ncommand:</p>\n<p align=left><b>scontrol requeue job_id</b></p>\n</head>\n<p>The job will be requeued back in PENDING state and scheduled again.\nSee man(1) scontrol.\n</p>\n<p>Consider a simple job like this:</p>\n<pre>\n$cat zoppo\n#!/bin/sh\necho \"hello, world\"\nexit 10\n\n$sbatch -o here ./zoppo\nSubmitted batch job 10\n</pre>\n<p>\nThe job finishes in FAILED state because it exits with\na non zero value. We can requeue the job back to\nthe PENDING state and the job will be dispatched again.\n</p>\n<pre>\n$->scontrol requeue 10\n$->squeue\n     JOBID PARTITION  NAME     USER   ST   TIME  NODES NODELIST(REASON)\n      10      mira    zoppo    david  PD   0:00    1   (NonZeroExitCode)\n$->squeue\n    JOBID PARTITION   NAME     USER ST     TIME  NODES NODELIST(REASON)\n      10      mira    zoppo    david  R    0:03    1      alanz1\n</pre>\n<p>Slurm supports requeuing jobs in hold state with the command:</p>\n<p align=left><b>'scontrol requeuehold job_id'</b></p>\n<p>The job can be in state RUNNING, SUSPENDED, COMPLETED or FAILED\nbefore being requeued.</p>\n<pre>\n$->scontrol requeuehold 10\n$->squeue\n    JOBID PARTITION  NAME     USER ST       TIME  NODES NODELIST(REASON)\n    10      mira    zoppo    david PD       0:00      1 (JobHeldUser)\n</pre>\n\n</p>\n\n<p><a name=\"cpu_count\"><b>30. Slurm documentation refers to CPUs, cores and threads.\nWhat exactly is considered a CPU?</b></a><br>\nIf your nodes are configured with hyperthreading, then a CPU is equivalent\nto a hyperthread.\nOtherwise a CPU is equivalent to a core.\nYou can determine if your nodes have more than one thread per core\nusing the command \"scontrol show node\" and looking at the values of\n\"ThreadsPerCore\".</p>\n<p>Note that even on systems with hyperthreading enabled, the resources will\ngenerally be allocated to jobs at the level of a core (see NOTE below).\nTwo different jobs will not share a core except through the use of a partition\nOverSubscribe configuration parameter.\nFor example, a job requesting resources for three tasks on a node with\nThreadsPerCore=2 will be allocated two full cores.\nNote that Slurm commands contain a multitude of options to control\nresource allocation with respect to base boards, sockets, cores and threads.</p>\n<p>(<b>NOTE:</b> An exception to this would be if the system administrator\nconfigured SelectTypeParameters=CR_CPU and each node's CPU count without its\nsocket/core/thread specification. In that case, each thread would be\nindependently scheduled as a CPU. This is not a typical configuration.)</p>\n\n<p><a name=\"sbatch_srun\"><b>31. What is the difference between the sbatch\n  and srun commands?</b></a><br>\nThe srun command has two different modes of operation. First, if not run within\nan existing job (i.e. not within a Slurm job allocation created by salloc or\nsbatch), then it will create a job allocation and spawn an application.\nIf run within an existing allocation, the srun command only spawns the\napplication.\nFor this question, we will only address the first mode of operation and compare\ncreating a job allocation using the sbatch and srun commands.</p>\n\n<p>The srun command is designed for interactive use, with someone monitoring\nthe output.\nThe output of the application is seen as output of the srun command,\ntypically at the user's terminal.\nThe sbatch command is designed to submit a script for later execution and its\noutput is written to a file.\nCommand options used in the job allocation are almost identical.\nThe most noticable difference in options is that the sbatch command supports\nthe concept of <a href=\"job_array.html\">job arrays</a>, while srun does not.\nAnother significant difference is in fault tolerance.\nFailures involving sbatch jobs typically result in the job being requeued\nand executed again, while failures involving srun typically result in an\nerror message being generated with the expectation that the user will respond\nin an appropriate fashion.</p> \n\n<p><a name=\"squeue_color\"><b>32. Can squeue output be color coded?</b></a><br>\nThe squeue command output is not color coded, but other tools can be used to\nadd color. One such tool is ColorWrapper\n(<a href=\"https://github.com/rrthomas/cw\">https://github.com/rrthomas/cw</a>).\nA sample ColorWrapper configuration file and output are shown below.</p>\n<pre>\npath /bin:/usr/bin:/sbin:/usr/sbin:<env>\nusepty\nbase green+\nmatch red:default (Resources)\nmatch black:default (null)\nmatch black:cyan N/A\nregex cyan:default  PD .*$\nregex red:default ^\\d*\\s*C .*$\nregex red:default ^\\d*\\s*CG .*$\nregex red:default ^\\d*\\s*NF .*$\nregex white:default ^JOBID.*\n</pre>\n<img src=\"squeue_color.png\" width=600>\n\n<p><a name=\"x11\"><b>33. Can Slurm export an X11 display on an allocated compute node?</b></a><br/>\nYou can use the X11 builtin feature starting at version 17.11. This plugin is\nbased on libssh2 and it supports <i>hostbased</i> and <i>pubkey</i>\nauthentication.<br/>You just need to have <i>libssh2</i> installed on compute\nnodes, <i>libssh2</i> development package installed in the build host at build\ntime and <i>PrologFlags=x11</i> set in <i>slurm.conf</i>. You will need also\nuser public/private keys available on compute nodes or otherwise a\n<i>hostbased</i> authentication setup in your ssh servers.\nOther X11 plugins must be deactivated.\n<br/>\nRun it as shown:\n</p>\n<pre>\n$ ssh -X user@login1\n$ srun -n1 --pty --x11 xclock\n</pre>\n<p>\nAn alternative for older versions is to build and install an optional SPANK\nplugin for that functionality. Instructions to build and install the plugin\nfollow. This SPANK plugin will not work if used in combination with native X11\nsupport so you must disable it compiling Slurm with <i>--disable-x11</i>. This\nplugin relies on openssh library and it provides features such as GSSAPI\nsupport.<br/> Update the Slurm installation path as needed:</p>\n<pre>\n# Maybe obvious, but don't forget the -X on ssh\n$ ssh -X alex@testserver.com\n\n# Get the plugin\n$ mkdir git\n$ cd git\n$ git clone https://github.com/hautreux/slurm-spank-x11.git\n$ cd slurm-spank-x11\n\n# Manually edit the X11_LIBEXEC_PROG macro definition\n$ vi slurm-spank-x11.c\n$ vi slurm-spank-x11-plug.c\n$ grep \"define X11_\" slurm-spank-x11.c\n#define X11_LIBEXEC_PROG \"/opt/slurm/17.02/libexec/slurm-spank-x11\"\n$ grep \"define X11_LIBEXEC_PROG\" slurm-spank-x11-plug.c\n#define X11_LIBEXEC_PROG \"/opt/slurm/17.02/libexec/slurm-spank-x11\"\n\n\n# Compile\n$ gcc -g -o slurm-spank-x11 slurm-spank-x11.c\n$ gcc -g -I/opt/slurm/17.02/include -shared -fPIC -o x11.so slurm-spank-x11-plug.c\n\n# Install\n$ mkdir -p /opt/slurm/17.02/libexec\n$ install -m 755 slurm-spank-x11 /opt/slurm/17.02/libexec\n$ install -m 755 x11.so /opt/slurm/17.02/lib/slurm\n\n# Configure\n$ echo -e \"optional x11.so\" >> /opt/slurm/17.02/etc/plugstack.conf\n$ cd ~/tests\n\n# Run\n$ srun -n1 --pty --x11 xclock\nadam@node1's password:\n</pre>\n\n<p><a name=\"unbuffered_cr\"><b>34. Why is the srun --u/--unbuffered option adding\n   a carriage character return to my output?</b></a><br>\nThe libc library used by many programs internally buffers output rather than\nwriting it immediately. This is done for performance reasons.\nThe only way to disable this internal buffering is to configure the program to\nwrite to a pseudo terminal (PTY) rather than to a regular file.\nThis configuration causes <u>some</u> implementations of libc to prepend the\ncarriage return character before all line feed characters.\nRemoving the carriage return character would result in desired formatting\nin some instances, while causing bad formatting in other cases.\nIn any case, Slurm is not adding the carriage return character, but displaying\nthe actual program's output.</p>\n\n<p><a name=\"sview_colors\"<b>35. Why is sview not coloring/highlighting nodes\n    properly?</b></a><br>\nsview color-coding is affected by the GTK theme. The node status grid\nis made up of button widgets and certain GTK themes don't show the color\nsetting as desired. Changing GTK themes can restore proper color-coding.</p>\n\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n\n<h2>For Administrators</h2>\n\n<p><a name=\"suspend\"><b>1. How is job suspend/resume useful?</b></a><br>\nJob suspend/resume is most useful to get particularly large jobs initiated\nin a timely fashion with minimal overhead. Say you want to get a full-system\njob initiated. Normally you would need to either cancel all running jobs\nor wait for them to terminate. Canceling jobs results in the loss of\ntheir work to that point from either their beginning or last checkpoint.\nWaiting for the jobs to terminate can take hours, depending upon your\nsystem configuration. A more attractive alternative is to suspend the\nrunning jobs, run the full-system job, then resume the suspended jobs.\nThis can easily be accomplished by configuring a special queue for\nfull-system jobs and using a script to control the process.\nThe script would stop the other partitions, suspend running jobs in those\npartitions, and start the full-system partition.\nThe process can be reversed when desired.\nOne can effectively gang schedule (time-slice) multiple jobs\nusing this mechanism, although the algorithms to do so can get quite\ncomplex.\nSuspending and resuming a job makes use of the SIGSTOP and SIGCONT\nsignals respectively, so swap and disk space should be sufficient to\naccommodate all jobs allocated to a node, either running or suspended.\n\n<p><a name=\"fast_schedule\"><b>2. How can I configure Slurm to use\nthe resources actually found on a node rather than what is defined\nin <i>slurm.conf</i>?</b></a><br>\nSlurm can either base its scheduling decisions upon the node\nconfiguration defined in <i>slurm.conf</i> or what each node\nactually returns as available resources.\nThis is controlled using the configuration parameter <i>FastSchedule</i>.\nSet its value to zero in order to use the resources actually\nfound on each node, but with a higher overhead for scheduling.\nA value of one is the default and results in the node configuration\ndefined in <i>slurm.conf</i> being used. See &quot;man slurm.conf&quot;\nfor more details.</p>\n\n<p><a name=\"return_to_service\"><b>3. Why is a node shown in state\nDOWN when the node has registered for service?</b></a><br>\nThe configuration parameter <i>ReturnToService</i> in <i>slurm.conf</i>\ncontrols how DOWN nodes are handled.\nSet its value to one in order for DOWN nodes to automatically be\nreturned to service once the <i>slurmd</i> daemon registers\nwith a valid node configuration.\nA value of zero is the default and results in a node staying DOWN\nuntil an administrator explicitly returns it to service using\nthe command &quot;scontrol update NodeName=whatever State=RESUME&quot;.\nSee &quot;man slurm.conf&quot; and &quot;man scontrol&quot; for more\ndetails.</p>\n\n<p><a name=\"down_node\"><b>4. What happens when a node crashes?</b></a><br>\nA node is set DOWN when the slurmd daemon on it stops responding\nfor <i>SlurmdTimeout</i> as defined in <i>slurm.conf</i>.\nThe node can also be set DOWN when certain errors occur or the\nnode's configuration is inconsistent with that defined in <i>slurm.conf</i>.\nAny active job on that node will be killed unless it was submitted\nwith the srun option <i>--no-kill</i>.\nAny active job step on that node will be killed.\nSee the slurm.conf and srun man pages for more information.</p>\n\n<p><a name=\"multi_job\"><b>5. How can I control the execution of multiple\njobs per node?</b></a><br>\nThere are two mechanisms to control this.\nIf you want to allocate individual processors on a node to jobs,\nconfigure <i>SelectType=select/cons_res</i>.\nSee <a href=\"cons_res.html\">Consumable Resources in Slurm</a>\nfor details about this configuration.\nIf you want to allocate whole nodes to jobs, configure\nconfigure <i>SelectType=select/linear</i>.\nEach partition also has a configuration parameter <i>OverSubscribe</i>\nthat enables more than one job to execute on each node.\nSee <i>man slurm.conf</i> for more information about these\nconfiguration parameters.</p>\n\n<p><a name=\"inc_plugin\"><b>6. When the Slurm daemon starts, it\nprints &quot;cannot resolve X plugin operations&quot; and exits.\nWhat does this mean?</b></a><br>\nThis means that symbols expected in the plugin were\nnot found by the daemon. This typically happens when the\nplugin was built or installed improperly or the configuration\nfile is telling the plugin to use an old plugin (say from the\nprevious version of Slurm). Restart the daemon in verbose mode\nfor more information (e.g. &quot;slurmctld -Dvvvvv&quot;).\n\n<p><a name=\"pam_exclude\"><b>7.How can I exclude some users from pam_slurm?</b></a><br>\n<b>CAUTION:</b> Please test this on a test machine/VM before you actually do\nthis on your Slurm computers.</p>\n\n<p><b>Step 1.</b> Make sure pam_listfile.so exists on your system.\nThe following command is an example on Redhat 6:</p>\n<pre>\nls -la /lib64/security/pam_listfile.so\n</pre>\n\n<p><b>Step 2.</b> Create user list (e.g. /etc/ssh/allowed_users):</p>\n<pre>\n# /etc/ssh/allowed_users\nroot\nmyadmin\n</pre>\n<p>And, change file mode to keep it secret from regular users(Optional):</p>\n<pre>\nchmod 600 /etc/ssh/allowed_users\n</pre>\n<p><b>NOTE:</b> root is not necessarily listed on the allowed_users, but I\nfeel somewhat safe if it's on the list.</p>\n\n<p><b>Step 3.</b> On /etc/pam.d/sshd, add pam_listfile.so with sufficient flag\nbefore pam_slurm.so (e.g. my /etc/pam.d/sshd looks like this):</p>\n<pre>\n#%PAM-1.0\nauth       required     pam_sepermit.so\nauth       include      password-auth\naccount    sufficient   pam_listfile.so item=user sense=allow file=/etc/ssh/allowed_users onerr=fail\naccount    required     pam_slurm.so\naccount    required     pam_nologin.so\naccount    include      password-auth\npassword   include      password-auth\n# pam_selinux.so close should be the first session rule\nsession    required     pam_selinux.so close\nsession    required     pam_loginuid.so\n# pam_selinux.so open should only be followed by sessions to be executed in the user context\nsession    required     pam_selinux.so open env_params\nsession    optional     pam_keyinit.so force revoke\nsession    include      password-auth\n</pre>\n<p>(Information courtesy of Koji Tanaka, Indiana University)</p>\n\n<p><a name=\"maint_time\"><b>8. How can I dry up the workload for a\nmaintenance period?</b></a><br>\nCreate a resource reservation as described b. Slurm's\n<a href=\"reservations.html\">Resource Reservation Guide</a>.\n\n<p><a name=\"pam\"><b>9. How can PAM be used to control a user's limits on\nor access to compute nodes?</b></a><br>\nTo control a user's limits on a compute node:<br>\n<p>First, enable Slurm's use of PAM by setting <i>UsePAM=1</i> in\n<i>slurm.conf</i>.</p>\n<p>Second, establish PAM configuration file(s) for Slurm in <i>/etc/pam.conf</i>\nor the appropriate files in the <i>/etc/pam.d</i> directory (e.g.\n<i>/etc/pam.d/sshd</i> by adding the line \"account required pam_slurm.so\".\nA basic configuration you might use is:</p>\n<pre>\naccount  required  pam_unix.so\naccount  required  pam_slurm.so\nauth     required  pam_localuser.so\nsession  required  pam_limits.so\n</pre>\n<p>Third, set the desired limits in <i>/etc/security/limits.conf</i>.\nFor example, to set the locked memory limit to unlimited for all users:</p>\n<pre>\n*   hard   memlock   unlimited\n*   soft   memlock   unlimited\n</pre>\n<p>Finally, you need to disable Slurm's forwarding of the limits from the\nsession from which the <i>srun</i> initiating the job ran. By default\nall resource limits are propagated from that session. For example, adding\nthe following line to <i>slurm.conf</i> will prevent the locked memory\nlimit from being propagated:<i>PropagateResourceLimitsExcept=MEMLOCK</i>.</p>\n\n<p>To control a user's access to a compute node:</p>\n<p>The pam_slurm_adopt and pam_slurm modules prevent users from\nlogging into nodes that they have not been allocated (except for user\nroot, which can always login).\nThey are both included with the Slurm distribution.\n<p>The pam_slurm_adopt module is highly recommended for most installations,\nand is documented in its <a href=\"pam_slurm_adopt.shtml\">own guide</a>.</p>\n<p>pam_slurm is older and less functional.\nThese modules are built by default for RPM packages, but can be disabled using\nthe .rpmmacros option \"%_without_pam 1\" or by entering the command line\noption \"--without pam\" when the configure program is executed.\nTheir source code is in the \"contribs/pam\" and \"contribs/pam_slurm_adopt\"\ndirectories respectively.</p>\n<p>The use of either pam_slurm_adopt or pam_slurm does not require\n<i>UsePAM</i> being set. The two uses of PAM are independent.</p>\n\n<p><a name=\"time\"><b>10. Why are jobs allocated nodes and then unable\nto initiate programs on some nodes?</b></a><br>\nThis typically indicates that the time on some nodes is not consistent\nwith the node on which the <i>slurmctld</i> daemon executes. In order to\ninitiate a job step (or batch job), the <i>slurmctld</i> daemon generates\na credential containing a time stamp. If the <i>slurmd</i> daemon\nreceives a credential containing a time stamp later than the current\ntime or more than a few minutes in the past, it will be rejected.\nIf you check in the <i>SlurmdLog</i> on the nodes of interest, you\nwill likely see messages of this sort: \"<i>Invalid job credential from\n&lt;some IP address&gt;: Job credential expired</i>.\" Make the times\nconsistent across all of the nodes and all should be well.\n\n<p><a name=\"ping\"><b>11. Why does <i>slurmctld</i> log that some nodes\nare not responding even if they are not in any partition?</b></a><br>\nThe <i>slurmctld</i> daemon periodically pings the <i>slurmd</i>\ndaemon on every configured node, even if not associated with any\npartition. You can control the frequency of this ping with the\n<i>SlurmdTimeout</i> configuration parameter in <i>slurm.conf</i>.\n\n<p><a name=\"controller\"><b>12. How should I relocate the primary or\nbackup controller?</b></a><br>\nIf the cluster's computers used for the primary or backup controller\nwill be out of service for an extended period of time, it may be desirable\nto relocate them. In order to do so, follow this procedure:</p>\n<ol>\n<li>Stop all Slurm daemons</li>\n<li>Modify the <i>ControlMachine</i>, <i>ControlAddr</i>,\n<i>BackupController</i>, and/or <i>BackupAddr</i> in the <i>slurm.conf</i> file</li>\n<li>Distribute the updated <i>slurm.conf</i> file to all nodes</li>\n<li>Copy the <i>StateSaveLocation</i> directory to the new host and\nmake sure the permissions allow the <i>SlurmUser</i> to read and write it.\n<li>Restart all Slurm daemons</li>\n</ol>\n<p>There should be no loss of any running or pending jobs. Ensure that\nany nodes added to the cluster have a current <i>slurm.conf</i> file\ninstalled.\n<b>CAUTION:</b> If two nodes are simultaneously configured as the primary\ncontroller (two nodes on which <i>ControlMachine</i> specify the local host\nand the <i>slurmctld</i> daemon is executing on each), system behavior will be\ndestructive. If a compute node has an incorrect <i>ControlMachine</i> or\n<i>BackupController</i> parameter, that node may be rendered unusable, but no\nother harm will result.\n\n<p><a name=\"multi_slurm\"><b>13. Can multiple Slurm systems be run in\nparallel for testing purposes?</b></a><br>\nYes, this is a great way to test new versions of Slurm.\nJust install the test version in a different location with a different\n<i>slurm.conf</i>.\nThe test system's <i>slurm.conf</i> should specify different\npathnames and port numbers to avoid conflicts.\nThe only problem is if more than one version of Slurm is configured\nwith <i>switch/nrt</i> or <i>burst_buffer/*</i> plugins.\nIn that case, there can be conflicting API requests from\nthe different Slurm systems.\nThis can be avoided by configuring the test system with <i>switch/none</i>\nand <i>burst_buffer/none</i>.\nMPI jobs started on an NRT switch system without the\nswitch windows configured will not execute properly, but other jobs\nwill run fine.\n\n<p><a name=\"multi_slurmd\"><b>14. Can Slurm emulate a larger cluster?</b></a><br>\nYes, this can be useful for testing purposes.\nIt has also been used to partition \"fat\" nodes into multiple Slurm nodes.\nThere are two ways to do this.\nThe best method for most conditions is to run one <i>slurmd</i>\ndaemon per emulated node in the cluster as follows.\n<ol>\n<li>When executing the <i>configure</i> program, use the option\n<i>--enable-multiple-slurmd</i> (or add that option to your <i>~/.rpmmacros</i>\nfile).</li>\n<li>Build and install Slurm in the usual manner.</li>\n<li>In <i>slurm.conf</i> define the desired node names (arbitrary\nnames used only by Slurm. as <i>NodeName</i> along with the actual\naddress of the physical node in <i>NodeHostname</i>. Multiple\n<i>NodeName</i> values can be mapped to a single\n<i>NodeHostname</i>.  Note that each <i>NodeName</i> on a single\nphysical node needs to be configured to use a different port number\n(set <i>Port</i> to a unique value on each line for each node).  You\nwill also want to use the \"%n\" symbol in slurmd related path options in\nslurm.conf (<i>SlurmdLogFile</i> and <i>SlurmdPidFile</i>). </li>\n<li>When starting the <i>slurmd</i> daemon, include the <i>NodeName</i>\nof the node that it is supposed to serve on the execute line (e.g.\n\"slurmd -N hostname\").</li>\n<li> This is an example of the <i>slurm.conf</i> file with the  emulated nodes\nand ports configuration. Any valid value for the CPUs, memory or other\nvalid node resources can be specified.</li>\n</ol>\n\n<pre>\nNodeName=dummy26[1-100] NodeHostName=achille Port=[6001-6100] NodeAddr=127.0.0.1 CPUs=4 RealMemory=6000\nPartitionName=mira Default=yes Nodes=dummy26[1-100]\n</pre>\n\n<p>See the\n<a href=\"programmer_guide.html#multiple_slurmd_support\">Programmers Guide</a>\nfor more details about configuring multiple slurmd support.</p>\n\n<p>In order to emulate a really large cluster, it can be more\nconvenient to use a single <i>slurmd</i> daemon.\nThat daemon will not be able to launch many tasks, but can\nsuffice for developing or testing scheduling software.\nDo not run job steps with more than a couple of tasks each\nor execute more than a few jobs at any given time.\nDoing so may result in the <i>slurmd</i> daemon exhausting its\nmemory and failing.\n<b>Use this method with caution.</b>\n<ol>\n<li>Execute the <i>configure</i> program with your normal options\nplus <i>--enable-front-end</i> (this will define HAVE_FRONT_END in\nthe resulting <i>config.h</i> file.</li>\n<li>Build and install Slurm in the usual manner.</li>\n<li>In <i>slurm.conf</i> define the desired node names (arbitrary\nnames used only by Slurm. as <i>NodeName</i> along with the actual\nname and address of the <b>one</b> physical node in <i>NodeHostName</i>\nand <i>NodeAddr</i>.\nUp to 64k nodes can be configured in this virtual cluster.</li>\n<li>Start your <i>slurmctld</i> and one <i>slurmd</i> daemon.\nIt is advisable to use the \"-c\" option to start the daemons without\ntrying to preserve any state files from previous executions.\nBe sure to use the \"-c\" option when switch from this mode too.</li>\n<li>Create job allocations as desired, but do not run job steps\nwith more than a couple of tasks.</li>\n</ol>\n\n<pre>\n$ ./configure --enable-debug --enable-front-end --prefix=... --sysconfdir=...\n$ make install\n$ grep NodeHostName slurm.conf\n<i>NodeName=dummy[1-1200] NodeHostName=localhost NodeAddr=127.0.0.1</i>\n$ slurmctld -c\n$ slurmd -c\n$ sinfo\n<i>PARTITION AVAIL  TIMELIMIT NODES  STATE NODELIST</i>\n<i>pdebug*      up      30:00  1200   idle dummy[1-1200]</i>\n$ cat tmp\n<i>#!/bin/bash</i>\n<i>sleep 30</i>\n$ srun -N200 -b tmp\n<i>srun: jobid 65537 submitted</i>\n$ srun -N200 -b tmp\n<i>srun: jobid 65538 submitted</i>\n$ srun -N800 -b tmp\n<i>srun: jobid 65539 submitted</i>\n$ squeue\n<i>JOBID PARTITION  NAME   USER  ST  TIME  NODES NODELIST(REASON)</i>\n<i>65537    pdebug   tmp  jette   R  0:03    200 dummy[1-200]</i>\n<i>65538    pdebug   tmp  jette   R  0:03    200 dummy[201-400]</i>\n<i>65539    pdebug   tmp  jette   R  0:02    800 dummy[401-1200]</i>\n</pre>\n\n<p><a name=\"extra_procs\"><b>15. Can Slurm emulate nodes with more\nresources than physically exist on the node?</b></a><br>\nYes. In the slurm.conf file, configure <i>FastSchedule=2</i> and specify\nany desired node resource specifications (<i>CPUs</i>, <i>Sockets</i>,\n<i>CoresPerSocket</i>, <i>ThreadsPerCore</i>, and/or <i>TmpDisk</i>).\nSlurm will use the resource specification for each node that is\ngiven in <i>slurm.conf</i> and will not check these specifications\nagainst those actually found on the node. The system would best be configured\nwith <i>TaskPlugin=task/none</i>, so that launched tasks can run on any\navailable CPU under operating system control.\n\n<p><a name=\"credential_replayed\"><b>16. What does a\n&quot;credential replayed&quot;\nerror in the <i>SlurmdLogFile</i> indicate?</b></a><br>\nThis error is indicative of the <i>slurmd</i> daemon not being able\nto respond to job initiation requests from the <i>srun</i> command\nin a timely fashion (a few seconds).\n<i>Srun</i> responds by resending the job initiation request.\nWhen the <i>slurmd</i> daemon finally starts to respond, it\nprocesses both requests.\nThe second request is rejected and the event is logged with\nthe \"credential replayed\" error.\nIf you check the <i>SlurmdLogFile</i> and <i>SlurmctldLogFile</i>,\nyou should see signs of the <i>slurmd</i> daemon's non-responsiveness.\nA variety of factors can be responsible for this problem\nincluding\n<ul>\n<li>Diskless nodes encountering network problems</li>\n<li>Very slow Network Information Service (NIS)</li>\n<li>The <i>Prolog</i> script taking a long time to complete</li>\n</ul>\n<p>Configure <i>MessageTimeout</i> in slurm.conf to a value higher than the\ndefault 5 seconds.</p>\n\n<p><a name=\"large_time\"><b>17. What does\n&quot;Warning: Note very large processing time&quot;\nin the <i>SlurmctldLogFile</i> indicate?</b></a><br>\nThis error is indicative of some operation taking an unexpectedly\nlong time to complete, over one second to be specific.\nSetting the value of <i>SlurmctldDebug</i> configuration parameter\na value of six or higher should identify which operation(s) are\nexperiencing long delays.\nThis message typically indicates long delays in file system access\n(writing state information or getting user information).\nAnother possibility is that the node on which the slurmctld\ndaemon executes has exhausted memory and is paging.\nTry running the program <i>top</i> to check for this possibility.\n\n<p><a name=\"limit_propagation\"><b>18. Is resource limit propagation\nuseful on a homogeneous cluster?</b></a><br>\nResource limit propagation permits a user to modify resource limits\nand submit a job with those limits.\nBy default, Slurm automatically propagates all resource limits in\neffect at the time of job submission to the tasks spawned as part\nof that job.\nSystem administrators can utilize the <i>PropagateResourceLimits</i>\nand <i>PropagateResourceLimitsExcept</i> configuration parameters to\nchange this behavior.\nUsers can override defaults using the <i>srun --propagate</i>\noption.\nSee <i>\"man slurm.conf\"</i> and <i>\"man srun\"</i> for more information\nabout these options.\n\n<p><a name=\"clock\"><b>19. Do I need to maintain synchronized\nclocks on the cluster?</b></a><br>\nIn general, yes. Having inconsistent clocks may cause nodes to\nbe unusable. Slurm log files should contain references to\nexpired credentials. For example:\n<pre>\nerror: Munge decode failed: Expired credential\nENCODED: Wed May 12 12:34:56 2008\nDECODED: Wed May 12 12:01:12 2008\n</pre>\n\n<p><a name=\"cred_invalid\"><b>20. Why are &quot;Invalid job credential&quot;\nerrors generated?</b></a><br>\nThis error is indicative of Slurm's job credential files being inconsistent across\nthe cluster. All nodes in the cluster must have the matching public and private\nkeys as defined by <b>JobCredPrivateKey</b> and <b>JobCredPublicKey</b> in the\nslurm configuration file <b>slurm.conf</b>.\n\n<p><a name=\"cred_replay\"><b>21. Why are\n&quot;Task launch failed on node ... Job credential replayed&quot;\nerrors generated?</b></a><br>\nThis error indicates that a job credential generated by the slurmctld daemon\ncorresponds to a job that the slurmd daemon has already revoked.\nThe slurmctld daemon selects job ID values based upon the configured\nvalue of <b>FirstJobId</b> (the default value is 1) and each job gets\na value one larger than the previous job.\nOn job termination, the slurmctld daemon notifies the slurmd on each\nallocated node that all processes associated with that job should be\nterminated.\nThe slurmd daemon maintains a list of the jobs which have already been\nterminated to avoid replay of task launch requests.\nIf the slurmctld daemon is cold-started (with the &quot;-c&quot; option\nor &quot;/etc/init.d/slurm startclean&quot;), it starts job ID values\nover based upon <b>FirstJobId</b>.\nIf the slurmd is not also cold-started, it will reject job launch requests\nfor jobs that it considers terminated.\nThis solution to this problem is to cold-start all slurmd daemons whenever\nthe slurmctld daemon is cold-started.\n\n<p><a name=\"globus\"><b>22. Can Slurm be used with Globus?</b></a><br>\nYes. Build and install Slurm's Torque/PBS command wrappers along with\nthe Perl APIs from Slurm's <i>contribs</i> directory and configure\n<a href=\"http://www-unix.globus.org/\">Globus</a> to use those PBS commands.\nNote there are RPMs available for both of these packages, named\n<i>torque</i> and <i>perlapi</i> respectively.\n\n<p><a name=\"file_limit\"><b>23. What causes the error\n&quot;Unable to accept new connection: Too many open files&quot;?</b></a><br>\nThe srun command automatically increases its open file limit to\nthe hard limit in order to process all of the standard input and output\nconnections to the launched tasks. It is recommended that you set the\nopen file hard limit to 8192 across the cluster.\n\n<p><a name=\"slurmd_log\"><b>24. Why does the setting of <i>SlurmdDebug</i>\nfail to log job step information at the appropriate level?</b></a><br>\nThere are two programs involved here. One is <b>slurmd</b>, which is\na persistent daemon running at the desired debug level. The second\nprogram is <b>slurmstep</b>, which executed the user job and its\ndebug level is controlled by the user. Submitting the job with\nan option of <i>--debug=#</i> will result in the desired level of\ndetail being logged in the <i>SlurmdLogFile</i> plus the output\nof the program.\n\n<p><a name=\"rpm\"><b>26. Why isn't the pam_slurm.so (or other component) in a\nSlurm RPM?</b></a><br>\nIt is possible that at build time the required dependencies for building the\nlibrary are missing. If you want to build the library then install pam-devel\nand compile again. See the file slurm.spec in the Slurm distribution for a list\nof other options that you can specify at compile time with rpmbuild flags\nand your <i>rpmmacros</i> file.\n\nThe auth_none plugin is in a separate RPM and not built by default.\nUsing the auth_none plugin means that Slurm communications are not\nauthenticated, so you probably do not want to run in this mode of operation\nexcept for testing purposes. If you want to build the auth_none RPM then\nadd <i>--with auth_none</i> on the rpmbuild command line or add\n<i>%_with_auth_none</i> to your ~/rpmmacros file. See the file slurm.spec\nin the Slurm distribution for a list of other options.\n\n<p><a name=\"slurmdbd\"><b>26. Why should I use the slurmdbd instead of the\nregular database plugins?</b></a><br>\nWhile the normal storage plugins will work fine without the added\nlayer of the slurmdbd there are some great benefits to using the\nslurmdbd.\n<ol>\n<li>Added security.  Using the slurmdbd you can have an authenticated\nconnection to the database.</li>\n<li>Off loading processing from the controller.  With the slurmdbd there is no\nslow down to the controller due to a slow or overloaded database.</li>\n<li>Keeping enterprise wide accounting from all Slurm clusters in one database.\nThe slurmdbd is multi-threaded and designed to handle all the\naccounting for the entire enterprise.</li>\n<li>With the database plugins you can query with sacct accounting stats from\nany node Slurm is installed on. With the slurmdbd you can also query any\ncluster using the slurmdbd from any other cluster's nodes. Other tools like\nsreport are also available.</li>\n</ol>\n\n<p><a name=\"debug\"><b>27. How can I build Slurm with debugging symbols?</b></a></br>\nWhen configuring, run the configure script with <i>--enable-developer</i> option.\nThat will provide asserts, debug messages and the <i>-Werror</i> flag, that\nwill in turn activate <i>--enable-debug</i>.\n<br/>With the <i>--enable-debug</i> flag, the code will be compiled with\n<i>-ggdb3</i> and <i>-g -O1 -fno-strict-aliasing</i> flags that will produce\nextra debugging information. Another possible option to use is\n<i>--disable-optimizations</i> that will set <i>-O0</i>.\nSee also <i>auxdir/x_ac_debug.m4</i> for more detail.\n\n<p><a name=\"state_preserve\"><b>28. How can I easily preserve drained node\ninformation between major Slurm updates?</b></a><br>\nMajor Slurm updates generally have changes in the state save files and\ncommunication protocols, so a cold-start (without state) is generally\nrequired. If you have nodes in a DRAIN state and want to preserve that\ninformation, you can easily build a script to preserve that information\nusing the <i>sinfo</i> command. The following command line will report the\n<i>Reason</i> field for every node in a DRAIN state and write the output\nin a form that can be executed later to restore state.\n<pre>\nsinfo -t drain -h -o \"scontrol update nodename='%N' state=drain reason='%E'\"\n</pre>\n\n<p><a name=\"health_check\"><b>29. Why doesn't the <i>HealthCheckProgram</i>\nexecute on DOWN nodes?</a></b><br>\nHierarchical communications are used for sending this message. If there\nare DOWN nodes in the communications hierarchy, messages will need to\nbe re-routed. This limit. Slurm's ability to tightly synchronize the\nexecution of the <i>HealthCheckProgram</i> across the cluster, which\ncould adversely impact performance of parallel applications.\nThe use of CRON or node startup scripts may be better suited to ensure\nthat <i>HealthCheckProgram</i> gets executed on nodes that are DOWN\nin Slurm. If you still want to have Slurm try to execute\n<i>HealthCheckProgram</i> on DOWN nodes, apply the following patch:\n<pre>\nIndex: src/slurmctld/ping_nodes.c\n===================================================================\n--- src/slurmctld/ping_nodes.c  (revision 15166)\n+++ src/slurmctld/ping_nodes.c  (working copy)\n@@ -283,9 +283,6 @@\n\t\tnode_ptr   = &node_record_table_ptr[i];\n\t\tbase_state = node_ptr->node_state & NODE_STATE_BASE;\n\n-               if (base_state == NODE_STATE_DOWN)\n-                       continue;\n-\n #ifdef HAVE_FRONT_END          /* Operate only on front-end */\n\t\tif (i > 0)\n\t\t\tcontinue;\n</pre>\n\n<p><a name=\"batch_lost\"><b>30. What is the meaning of the error\n&quot;Batch JobId=# missing from master node, killing it&quot;?</b></a><br>\nA shell is launched on node zero of a job's allocation to execute\nthe submitted program. The <i>slurmd</i> daemon executing on each compute\nnode will periodically report to the <i>slurmctld</i> what programs it\nis executing. If a batch program is expected to be running on some\nnode (i.e. node zero of the job's allocation) and is not found, the\nmessage above will be logged and the job canceled. This typically is\nassociated with exhausting memory on the node or some other critical\nfailure that cannot be recovered from. The equivalent message in\nearlier releases of Slurm is\n&quot;Master node lost JobId=#, killing it&quot;.\n\n<p><a name=\"accept_again\"><b>31. What does the message\n&quot;srun: error: Unable to accept connection: Resources temporarily unavailable&quot;\nindicate?</b></a><br>\nThis has been reported on some larger clusters running SUSE Linux when\na user's resource limits are reached. You may need to increase limits\nfor locked memory and stack size to resolve this problem.\n\n<p><a name=\"task_prolog\"><b>32. How could I automatically print a job's\nSlurm job ID to its standard output?</b></a></br>\nThe configured <i>TaskProlog</i> is the only thing that can write to\nthe job's standard output or set extra environment variables for a job\nor job step. To write to the job's standard output, precede the message\nwith \"print \". To export environment variables, output a line of this\nform \"export name=value\". The example below will print a job's Slurm\njob ID and allocated hosts for a batch job only.\n\n<pre>\n#!/bin/sh\n#\n# Sample TaskProlog script that will print a batch job's\n# job ID and node list to the job's stdout\n#\n\nif [ X\"$SLURM_STEP_ID\" = \"X\" -a X\"$SLURM_PROCID\" = \"X\"0 ]\nthen\n  echo \"print ==========================================\"\n  echo \"print SLURM_JOB_ID = $SLURM_JOB_ID\"\n  echo \"print SLURM_JOB_NODELIST = $SLURM_JOB_NODELIST\"\n  echo \"print ==========================================\"\nfi\n</pre>\n\n<p><a name=\"orphan_procs\"><b>33. Why are user processes and <i>srun</i>\nrunning even though the job is supposed to be completed?</b></a></br>\nSlurm relies upon a configurable process tracking plugin to determine\nwhen all of the processes associated with a job or job step have completed.\nThose plugins relying upon a kernel patch can reliably identify every process.\nThose plugins dependent upon process group IDs or parent process IDs are not\nreliable. See the <i>ProctrackType</i> description in the <i>slurm.conf</i>\nman page for details. We rely upon the sgi_job for most systems.</p>\n\n<p><a name=\"slurmd_oom\"><b>34. How can I prevent the <i>slurmd</i> and\n<i>slurmstepd</i> daemons from being killed when a node's memory\nis exhausted?</b></a></br>\nYou can set the value in the <i>/proc/self/oom_adj</i> for\n<i>slurmd</i> and <i>slurmstepd</i> by initiating the <i>slurmd</i>\ndaemon with the <i>SLURMD_OOM_ADJ</i> and/or <i>SLURMSTEPD_OOM_ADJ</i>\nenvironment variables set to the desired values.\nA value of -17 typically will disable killing.</p>\n\n<p><a name=\"ubuntu\"><b>35. I see my host of my calling node as 127.0.1.1\n    instead of the correct IB address.  Why is that?</b></a></br>\nSome systems by default will put your host in the /etc/hosts file as\nsomething like</p>\n<pre>\n127.0.1.1\tsnowflake.llnl.gov\tsnowflake\n</pre>\n<p>This will cause srun and Slurm commands to use the 127.0.1.1 address\ninstead of the correct address and prevent communications between nodes.\nThe solution is to either remove this line or configure a different NodeAddr\nthat is known by your other nodes.</p>\n\n<p>The TopologyParam=NoInAddrAny configuration parameter is subject to this\nsame problem, which can also be addressed by removing actual node\nname from the \"127.0.1.1\" as well as the \"127.0.0.1\"\naddresses in the /etc/hosts file.  It is ok if they point to\nlocalhost, but not the actual name of the node.</p>\n\n<p><a name=\"stop_sched\"><b>36. How can I stop Slurm from scheduling jobs?</b></a></br>\nYou can stop Slurm from scheduling jobs on a per partition basis by setting\nthat partition's state to DOWN. Set its state UP to resume scheduling.\nFor example:\n<pre>\n$ scontrol update PartitionName=foo State=DOWN\n$ scontrol update PartitionName=bar State=UP\n</pre></p>\n\n<p><a name=\"scontrol_multi_jobs\"><b>37. Can I update multiple jobs with a\nsingle <i>scontrol</i> command?</b></a></br>\nNo, but you can probably use <i>squeue</i> to build the script taking\nadvantage of its filtering and formatting options. For example:\n<pre>\n$ squeue -tpd -h -o \"scontrol update jobid=%i priority=1000\" >my.script\n</pre></p>\n\n<p><a name=\"amazon_ec2\"><b>38. Can Slurm be used to run jobs on\nAmazon's EC2?</b></a></br>\n<p>Yes, here is a description of use Slurm use with\n<a href=\"http://aws.amazon.com/ec2/\">Amazon's EC2</a> courtesy of\nAshley Pittman:</p>\n<p>I do this regularly and have no problem with it, the approach I take is to\nstart as many instances as I want and have a wrapper around\nec2-describe-instances that builds a /etc/hosts file with fixed hostnames\nand the actual IP addresses that have been allocated.  The only other step\nthen is to generate a slurm.conf based on how many node you've chosen to boot\nthat day.  I run this wrapper script on my laptop and it generates the files\nand they rsyncs them to all the instances automatically.</p>\n<p>One thing I found is tha. Slurm refuses to start if any nodes specified in\nthe slurm.conf file aren't resolvable, I initially tried to specify cloud[0-15]\nin slurm.conf, but then if I configure less than 16 nodes in /etc/hosts this\ndoesn't work so I dynamically generate the slurm.conf as well as the hosts\nfile.</p>\n<p>As a comment about EC2 I run just run generic AMIs and have a persistent EBS\nstorage device which I attach to the first instance when I start up.  This\ncontains a /usr/local which has my software like Slurm, pdsh and MPI installed\nwhich I then copy over the /usr/local on the first instance and NFS export to\nall other instances.  This way I have persistent home directories and a very\nsimple first-login script that configures the virtual cluster for me.</p>\n\n<p><a name=\"core_dump\"><b>39. If a Slurm daemon core dumps, where can I find the\ncore file?</b></a></br>\n<p>For <i>slurmctld</i>, the core file will be in the same directory as its\nlog files (<i>SlurmctldLogFile</i>) if configured using an fully qualified\npathname (starting with \"/\").\nOtherwise it will be found in directory used for saving state\n(<i>StateSaveLocation</i>).</p>\n<p>For <i>slurmd</i>, the core file will be in the same directory as its\nlog files (<i>SlurmdLogFile</i>) if configured using an fully qualified\npathname (starting with \"/\").\nOtherwise it will be found in directory used for saving state\n(<i>SlurmdSpoolDir</i>).</p>\n<p>For <i>slurmstepd</i>, the core file will depend upon when the failure\noccurs. It will either be in spawned job's working directory on the same\nlocation as that described above for the <i>slurmd</i> daemon.</p>\n<p><b>NOTE:</b> On some systems, the slurmstepd's will not generate core files\nwithout some system configuration changes due to its use of the setuid\n(set user ID) function.<br>\nSet /proc/sys/fs/suid_dumpable to 2.<br>\nThis could be set in permently in sysctl.conf with:<br>\nfs.suid_dumpable = 2<br>\nor temporarily with:<br>\nsysctl fs.suid_dumpable=2<br>\nOn Centos 6, also set \"ProcessUnpackaged = yes\" in the file\n/etc/abrt/abrt-action-save-package-data.conf.\nOn Red Hat EL6, also set \"DAEMON_COREFILE_LIMIT=unlimited\" in the file\nrc.d/init.d/functions.</p>\n<p>Once these configuration changes have been made and the slurmstepd aborts,\nyou should see message of this type in the file /var/log/messages:</p>\n<pre>Oct 15 11:31:20 knc abrt[21489]: Saved core dump of pid 21477 (/localhome/adam/slurm/16.05/knc/sbin/slurmstepd) to /var/spool/abrt/ccpp-2015-10-15-11:31:20-21477 (6639616 bytes)\nOct 15 11:31:20 knc abrtd: Directory 'ccpp-2015-10-15-11:31:20-21477' creation detected</pre>\n\n<p>There should be a core file inside the specified directory.</p>\n\n<p>On a 3.6 kernel (Ubuntu), fs.suid_dumpable requires a fully qualified path\nin the core_pattern. For example:<br>\nsysctl kernel.core_pattern=/tmp/core.%e.%p</p>\n\n<p><a name=\"totalview\"><b>40. How can TotalView be configured to operate with\n  Slurm?</b></a></br>\n<p>The following lines should also be added to the global <i>.tvdrc</i> file\nfor TotalView to operate with Slurm:\n<pre>\n# Enable debug server bulk launch: Checked\ndset -set_as_default TV::bulk_launch_enabled true\n\n# Command:\n# Beginning with TV 7X.1, TV supports Slurm and %J.\n# Specify --mem-per-cpu=0 in case Slurm configured with default memory\n# value and we want TotalView to share the job's memory limit without\n# consuming any of the job's memory so as to block other job steps.\ndset -set_as_default TV::bulk_launch_string {srun --mem-per-cpu=0 -N%N -n%N -w`awk -F. 'BEGIN {ORS=\",\"} {if (NR==%N) ORS=\"\"; print $1}' %t1` -l --input=none %B/tvdsvr%K -callback_host %H -callback_ports %L -set_pws %P -verbosity %V -working_directory %D %F}\n\n# Temp File 1 Prototype:\n# Host Lines:\n# Slurm NodeNames need to be unadorned hostnames. In case %R returns\n# fully qualified hostnames, list the hostnames in %t1 here, and use\n# awk in the launch string above to strip away domain name suffixes.\ndset -set_as_default TV::bulk_launch_tmpfile1_host_lines {%R}\n</pre></p>\n<!-- OLD FORMAT\ndset TV::parallel_configs {\n\tname: Slurm;\n\tdescription: Slurm;\n\tstarter: srun %s %p %a;\n\tstyle: manager_process;\n\ttasks_option: -n;\n\tnodes_option: -N;\n\tenv: ;\n\tforce_env: false;\n}\n!-->\n\n<p><a name=\"git_patch\"><b>41. How can a patch file be generated from a Slurm\ncommit in github?</b></a></br>\n<p>Find and open the commit in github then append \".patch\" to the URL and save\nthe resulting file. For an example, see:\n<a href=\"https://github.com/SchedMD/slurm/commit/91e543d433bed11e0df13ce0499be641774c99a3.patch\">\nhttps://github.com/SchedMD/slurm/commit/91e543d433bed11e0df13ce0499be641774c99a3.patch</a>\n</p>\n\n<p><a name=\"enforce_limits\"><b>42. Why are the resource limits set in the\ndatabase not being enforced?</b></a></br>\nIn order to enforce resource limits, set the value of\n<b>AccountingStorageEnforce</b> in each cluster's slurm.conf configuration\nfile appropriately. If <b>AccountingStorageEnforce</b> does not contains\nan option of \"limits\", then resource limits will not be enforced on that cluster.\nSee <a href=\"resource_limits.html\">Resource Limits</a> for more information.</p>\n\n<p><a name=\"restore_priority\"><b>43. After manually setting a job priority\nvalue, how can it's priority value be returned to being managed by the\npriority/multifactor plugin?</b></a></br>\nHold and then release the job as shown below.</p>\n<pre>\n$ scontrol hold &lt;jobid&gt;\n$ scontrol release &lt;jobid&gt;\n</pre>\n\n<p><a name=\"health_check_example\"><b>44. Does any one have an example node\nhealth check script for Slurm?</b></a></br>\nProbably the most comprehensive and lightweight health check tool out\nthere is\n<a href=\"https://github.com/mej/nhc\">Node Health Check</a>.\nIt has integration with Slurm as well as Torque resource managers.</p>\n\n<p><a name=\"add_nodes\"><b>45. What process should I follow to add nodes to Slurm?</b></a></br>\nThe slurmctld daemon has a multitude of bitmaps to track state of nodes and cores\nin the system. Adding nodes to a running system would require the slurmctld daemon\nto rebuild all of those bitmaps, which the developers feel would be safer to do by\nrestarting the daemon. Communications from the slurmd daemons on the compute\nnodes to the slurmctld daemon include a configuration file checksum, so you\nprobably also want to maintain a common slurm.conf file on all nodes. The\nfollowing procedure is recommended:\n<ol>\n<li>Stop the slurmctld daemon (e.g. \"systemctl stop slurmctld\" on the head node)</li>\n<li>Update the slurm.conf file on all nodes in the cluster</li>\n<li>Restart the slurmctld daemon (e.g. \"systemctl start slurmctld\" on the head node)</li>\n<li>Start the slurmd daemons on the new nodes (e.g. \"systemctl start slurmd\" on those nodes)</li>\n<li>Have all slurmd daemons read the new configuration file (e.g.\n\"scontrol reconfig\", no need to restart the daemons)</li>\n</ol>\n\nNOTE: Jobs submitted with srun, and that are waiting for an allocation,\nprior to new nodes being added to the slurm.conf can fail if the job is\nallocated one of the new nodes.\n\n<p><a name=\"licenses\"><b>46. Can Slurm be configured to manage licenses?</b></a></br>\nSlurm is not currently integrated with FlexLM, but it does provide for the\nallocation of global resources called licenses. Use the Licenses configuration\nparameter in your slurm.conf file (e.g. \"Licenses=foo:10,bar:20\").\nJobs can request licenses and be granted exclusive use of those resources\n(e.g. \"sbatch --licenses=foo:2,bar:1 ...\").\nIt is not currently possible to change the total number of licenses on a system\nwithout restarting the slurmctld daemon, but it is possible to dynamically\nreserve licenses and remove them from being available to jobs on the system\n(e.g. \"scontrol update reservation=licenses_held licenses=foo:5,bar:2\").</p>\n\n<p><a name=\"salloc_default_command\"><b>47. Can the salloc command be configured to\nlaunch a shell on a node in the job's allocation?</b></a></br>\nYes, just use the SallocDefaultCommand configuration parameter in your\nslurm.conf file as shown below.</p>\n<pre>\nSallocDefaultCommand=\"srun -n1 -N1 --mem-per-cpu=0 --pty --preserve-env --cpu_bind=no --mpi=none $SHELL\"\n</pre>\n\n<p>\nFor cray systems, add --gres=craynetwork:0 to the options.\n<pre>\nSallocDefaultCommand=\"srun -n1 -N1 --mem-per-cpu=0 --gres=craynetwork:0 --pty --preserve-env --mpi=none $SHELL\"\n</pre>\n</p>\n\n<p><a name=\"upgrade\"><b>48. What should I be aware of when upgrading Slurm?</b></a></br>\nSee the Quick Start Administrator Guide <a href=\"quickstart_admin.html#upgrade\">Upgrade</a>\nsection for details.</p>\n\n<p><a name=\"torque\"><b>49. How easy is it to switch from PBS or Torque to Slurm?</b></a></br>\nA lot of users don't even notice the difference.\nSlurm has wrappers available for the mpiexec, pbsnodes, qdel, qhold, qrls,\nqstat, and qsub commands (see contribs/torque in the distribution and the\n\"slurm-torque\" RPM).\nThere is also a wrapper for the showq command at\n<a href=\"https://github.com/pedmon/slurm_showq\">\nhttps://github.com/pedmon/slurm_showq</a>.</p>\n\n<p>Slurm recognizes and translates the \"#PBS\" options in batch scripts.\nMost, but not all options are supported.</p>\n\n<p>Slurm also includes a SPANK plugin that will set all of the PBS environment\nvariables based upon the Slurm environment (e.g. PBS_JOBID, PBS_JOBNAME,\nPBS_WORKDIR, etc.).\nOne environment not set by PBS_ENVIRONMENT, which if set would result in the\nfailure of some MPI implementations.\nThe plugin will be installed in<br>\n&lt;install_directory&gt;/lib/slurm/spank_pbs.so<br>\nSee the SPANK man page for configuration details.</p>\n\n<p><a name=\"sssd\"><b>50. I am having trouble using SSSD with Slurm.</b></a></br>\nSSSD or System Security Services Deamon does not allow enumeration of\ngroup members by default. Note that enabling enumeration in large\nenvironments might not be feasible. However, Slurm does not need enumeration\nexcept for some specific quirky configurations (multiple groups with the same\nGID), so probably it's perfectly safe to leave enumeration disabled.\nSSSD is also case sensitive by default for some configurations, which could\npossibly raise other issues. Add the following lines\nto <i>/etc/sssd/sssd.conf</i> on your head node to address these issues:</p>\n<pre>\nenumerate = True\ncase_sensitive = False\n</pre>\n\n<p><a name=\"ha_db\"><b>51. How critical is configuring high availability for my\ndatabase?</b></a></br>\n<ul>\n<li>Consider if you really need mysql failover. Short outage of slurmdbd is not\na problem, because slurmctld will store all data in memory and send it to\nslurmdbd when it's back operating. The slurmctld daemon will also cache all\nuser limits and fair share information.</li>\n<li>You cannot use ndb, since slurmdbd/mysql uses a keys on BLOB values (and\nmaybe something more from the incompatibility list).</li>\n<li>You can set up \"classical\" Linux HA, with heartbeat/corosync to migrate\nIP between master/backup mysql servers and:</li>\n<ul>\n  <li>Configure one way replication of mysql, and change master/backup roles on\n    failure</li>\n  <li>Use shared storage for master/slave mysql servers database, and start\n    backup on master mysql failure.</li>\n</ul>\n</ul>\n\n<p><a name=\"sql\"><b>52.How can I use double quotes in MySQL queries?</b></a></br>\nExecute:\n<pre>\nSET session sql_mode='ANSI_QUOTES';\n</pre>\n<p>This will allow double quotes in queries like this:</p>\n<pre>\nshow columns from \"tux_assoc_table\" where Field='is_def';\n</pre>\n\n<p><a name=\"reboot\"><b>53. Why is a compute node down with the reason set to\n\"Node unexpectedly rebooted\"?</b></a></br>\nThis is indicative of the slurmctld daemon running on the cluster's head node\nas well as the slurmd daemon on the compute node when the compute node reboots.\nIf you want to prevent this condition from setting the node into a DOWN state\nthen configure ReturnToService to 2. See the slurm.conf man page for details.\nOtherwise use the scontrol or sview to manually return the node to service.</p>\n\n<p><a name=\"reqspec\"><b>54. How can a job which has exited with a specific exit\n  code be requeued?</b></a></br>\nSlurm supports requeue in hold with a <b>SPECIAL_EXIT</b> state using the\ncommand:</p>\n\n<pre>scontrol requeuehold State=SpecialExit job_id</pre>\n\n<p>This is useful when users want to requeue and flag a job which has exited\nwith a specific error case. See man scontrol(1) for more details.</p>\n\n<pre>\n$->scontrol requeuehold State=SpecialExit 10\n$->squeue\n   JOBID PARTITION  NAME     USER  ST       TIME  NODES NODELIST(REASON)\n    10      mira    zoppo    david SE       0:00      1 (JobHeldUser)\n</pre>\n<p>\nThe job can be later released and run again.\n</p>\n<p>\nThe requeueing of jobs which exit with a specific exit code can be\nautomated using an <b>EpilogSlurmctld</b>, see man(5) slurm.conf.\nThis is an example of a script which exit code depends on the existence\nof a file.\n</p>\n\n<pre>\n$->cat exitme\n#!/bin/sh\n#\necho \"hi! `date`\"\nif [ ! -e \"/tmp/myfile\" ]; then\n  echo \"going out with 8\"\n  exit 8\nfi\nrm /tmp/myfile\necho \"going out with 0\"\nexit 0\n</pre>\n<p>\nThis is an example of an EpilogSlurmctld that checks the job exit value\nlooking at the <b>SLURM_JOB_EXIT2</b> environment variable and requeues a job if\nit exited with value 8. The SLURM_JOB_EXIT2 has the format \"exit:sig\", the first\nnumber is the exit code, typically as set by the exit() function.\nThe second number of the signal that caused the process to terminate if\nit was terminated by a signal.\n</p>\n\n<pre>\n$->cat slurmctldepilog\n#!/bin/sh\n\nexport PATH=/bin:/home/slurm/linux/bin\nLOG=/home/slurm/linux/log/logslurmepilog\n\necho \"Start `date`\" >> $LOG 2>&1\necho \"Job $SLURM_JOB_ID exitcode $SLURM_JOB_EXIT_CODE2\" >> $LOG 2>&1\nexitcode=`echo $SLURM_JOB_EXIT_CODE2|awk '{split($0, a, \":\"); print a[1]}'` >> $LOG 2>&1\nif [ \"$exitcode\" == \"8\" ]; then\n   echo \"Found REQUEUE_EXIT_CODE: $REQUEUE_EXIT_CODE\" >> $LOG 2>&1\n   scontrol requeuehold state=SpecialExit $SLURM_JOB_ID >> $LOG 2>&1\n   echo $? >> $LOG 2>&1\nelse\n   echo \"Job $SLURM_JOB_ID exit all right\" >> $LOG 2>&1\nfi\necho \"Done `date`\" >> $LOG 2>&1\n\nexit 0\n</pre>\n<p>\nUsing the exitme script as an example we have it to exit with value 8 at\nthe first run, then when it gets requeued in hold with SpecialExit state\nwe touch the file /tmp/myfile, then release the job which will finish\nin COMPLETE state.\n</p>\n\n<p><a name=\"user_account\"><b>55. Can a user's account be changed in the database?</b></a></br>\nA user's account can not be changed directly. A new association needs to be\ncreated for the user with the new account. Then the association with the old\naccount can be deleted.</p>\n<pre>\n# Assume user \"adam\" is initially in account \"physics\"\nsacctmgr create user name=adam cluster=tux account=physics\nsacctmgr delete user name=adam cluster=tux account=chemistry\n</pre>\n\n<p><a name=\"mpi_perf\"><b>56. What might account for MPI performance being below\n  the expected level?</b></a><br>\nStarting the slurmd daemons with limited locked memory can account for this.\nAdding the line \"ulimit -l unlimited\" to <i>/etc/sysconfig/slurm</i> file can\nfix this.</p>\n\n<p><a name=\"state_info\"><b>57. How could some jobs submitted immediately before\n   the slurmctld daemon crashed be lost?</b></a><br>\nAny time the slurmctld daemon or hardware fails before state information reaches\ndisk can result in lost state.\nSlurmctld writes state frequently (every five seconds by default), but with\nlarge numbers of jobs, the formatting and writing of records can take seconds\nand recent changes might not be written to disk.\nAnother example is if the state information written to file, but that\ninformation is cached in memory rather than written to disk when the node fails.\nThe interval between state saves being written to disk can be configured at\nbuild time by defining SAVE_MAX_WAIT to a different value than five.</p>\n\n<p><a name=\"delete_partition\"><b>58. How do I safely remove partitions?\n</b></a><br>\nPartitions should be removed using the\n\"scontrol delete PartitionName=&lt;partition&gt;\" command. This is because\nscontrol will prevent any partitions from being removed that are in use.\nPartitions need to be removed from the slurm.conf after being removed using\nscontrol or they will return after a restart.\nAn existing job's partition(s) can be updated with the \"scontrol update\nJobId=&lt;jobid&gt; Partition=&lt;partition(s)&gt;\" command.\nRemoving a partition from the slurm.conf and restarting will cancel any existing\njobs that reference the removed partitions.\n</p>\n\n<p><a name=\"cpu_freq\"><b>59. Why is Slurm unable to set the CPU frequency for\n   jobs?</b></a><br>\nFirst check that Slurm is configured to bind jobs to specific CPUs by\nmaking sure that TaskPlugin is configured to either affinity or cgroup.\nNext check that that your processor is configured to permit frequency\ncontrol by examining the values in the file\n<i>/sys/devices/system/cpu/cpu0/cpufreq</i> where \"cpu0\" represents a CPU ID 0.\nOf particular interest is the file <i>scaling_available_governors</i>,\nwhich identifies the CPU governors available.\nIf \"userspace\" is not an available CPU governor, this may well be due to the\n<i>intel_pstate</i> driver being installed.\nInformation about disabling the <i>intel_pstate</i> driver is available\nfrom<br>\n<a href=\"https://bugzilla.kernel.org/show_bug.cgi?id=57141\">\nhttps://bugzilla.kernel.org/show_bug.cgi?id=57141</a> and<br>\n<a href=\"http://unix.stackexchange.com/questions/121410/setting-cpu-governor-to-on-demand-or-conservative\">\nhttp://unix.stackexchange.com/questions/121410/setting-cpu-governor-to-on-demand-or-conservative</a>.</p>\n\n<p><a name=\"mic_config\"><b>60. How can Slurm be configured to support Intel\n   Xeon Phi (MIC)?</b></a><br>\nUsers should see the <a href=\"#mic\">Xeon Phi use information</a> above.\nSlurm configuration details for Xeon Phi offload support are available\nin Slurm's <a href=\"gres.html\">Generic Resource Guide</a>.</p>\n\n<p>For native mode, slurmd (built for k1om) is started inside the card when the\ncard is booted.\nThe Slurm configuration file, slurm.conf, is the same as on regular compute\nnodes (by default it is mounted on all regular nodes and all Xeon Phi \"nodes\"\nfrom the same place).\nUse the \"slurmd -C\" command to determine the Xeon Phi node configuration\nwith respect to cores, threads per core, memory, etc.\nThe Xeon Phi is by default placed on host's network and connected via the\nbridge to the rest of the cluster, therefore from a Slurm user's perspective\nthe Xeon Phi can look like one more compute node with a lot of CPUs.</p>\n\n<p>Therefore an administrator can use configure the Xeon Phi as a regular node\n(with the slurmd daemon running on it), as a generic resources (for offload\nmode), or both.\nAlthough, Slurm cannot handle the last case nicely since it does not recognize\nthe Xeon Phi compute node and generic resource represent the same resources.\nSo from administrator prospective, the process of MICs configuration can be:\ninstall the latest MPSS and Slurm packages from yum/zypper,\nadd new MICs (via console utility or GUI),\nadd MICs to Slurm queues if necessary, restart the host, use MICs via Slurm.</p>\n\n<p><a name=\"cluster_acct\"><b>61. When adding a new cluster, how can the Slurm cluster\n    configuration be copied from an existing cluster to the new cluster?</b></a><br>\nAccounts need to be configured the cluster. An easy way to copy information from\nan existing cluster is to use the sacctmgr command to dump that cluster's information,\nmodify it using some editor, the load the new information using the sacctmgr\ncommand. See the sacctmgr man page for details, including an example.</p>\n\n<p><a name=\"cray_dvs\"><b>62. How can I update Slurm on a Cray DVS file system\n   without rebooting the nodes?</b></a><br>\nThe problem with DVS caching is related to the fact that the dereferenced value\nof /opt/slurm/default symlink is cached in the DVS attribute cache, and that\ncache is not dropped when the rest of the VM caches are.</p>\n\n<p>The Cray Native Slurm installation manual indicates that slurm should\nhave a \"default\" symlink run through /etc/alternatives.\nAs an alternative to that:\n<ol>\n<li>Institute a policy that all changes to files which could be open\npersistently (i.e., .so files) are always modified by creating a new access\npath.  I.e., installations go to a new directory.</li>\n<li>Dump the /etc/alternatives stuff, just use a regular symlink, e.g., default\npoints to 15.8.0-1.</li>\n<li>Add a new mountpoint on all the compute nodes for /dsl/opt/slurm where the\nattrcache_timeout attribute is reduced from 14440s to 60s (or 15s -- whatever):<br>\nmount -t dvs /opt/slurm /dsl/opt/slurm -o<br>\npath=/dsl/opt/slurm,nodename=c0-0c0s0n0,loadbalance,cache,ro,attrcache_timeout=15<br>\nIn the example above, c0-0c0s0n0 is the single DVS server for the system.</li>\n</ol>\n<p>Using this strategy avoids the caching problems, making upgrades simple.\nOne just has to wait for about 20 seconds after changing the default symlinks\nbefore starting the slurmds again.</p>\n<p>(Information courtesy of Douglas Jacobsen, NERSC,\nLawrence Berkeley National Laboratory)</p>\n\n<p><a name=\"dbd_rebuild\"><b>63. How can I rebuild the database hierarchy?</b></a><br>\nIf you see errors of this sort:</p>\n<pre>\nerror: Can't find parent id 3358 for assoc 1504, this should never happen.\n</pre>\n<p>in the slurmctld log file, this is indicative that the database hierarchy\ninformation has been corrupted, typically due to a hardware failure of\nadministrator error in directly modifying the database. In order to rebuild\nthe database information, start the slurmdbd daemon with the \"-R\" option\nfollowed by an optional comma separated list of cluster names to operate on.</p>\n\n<p><a name=\"routing queue\"><b>64. How can a routing queue be configured?</b></a><br>\nA job submit plugin is designed to have access to a job request from a user,\nplus information about all of the available system partitions/queue.\nAn administrator can write a C plugin or LUA script to set an incoming job's\npartition based upon its size, time limit, etc.\nSee the <a href=\"https://slurm.schedmd.com/job_submit_plugins.html\"> Job Submit Plugin API<a>\nguide for more information.\nAlso see the available job submit plugins distributed with Slurm for examples\n(look in the \"src/plugins/job_submit\" directory).</p>\n\n<p><a name=\"squeue_script\"><b>65. How can I suspend, resume, hold or release all\n    of the jobs belonging to a speciic user, partition, etc?</b></a><br>\nThere isn't any filtering by user, partition, etc. available in the scontrol\ncommand; however the squeue command can be used to perform the filtering and\nbuild a script which you can then execute. For example:\n<pre>\n$ squeue -u adam -h -o \"scontrol hold %i\" &gt;hold_script\n</pre>\n\n<p><a name=\"changed_uid\"><b>66. I had to change a user's UID and now they cannot submit\n    jobs. How do I get the new UID to take effect?</b></a><br>\nWhen changing UIDs, you will also need to restart the slurmctld for the changes to\ntake effect. Normally, when adding a new user to the system, the UID is filled in\nautomatically and immediately. If the user isn't known on the system yet, there is a\nthread that runs every hour that fills in those UIDs when they become known, but it\ndoesn't recognize UID changes of preexisting users. But you can simply restart the\nslurmctld for those changes to be recognized.</p>\n\n<p><a name=\"mysql_duplicate\"><b>67. Slurmdbd is failing to start with a 'Duplicate entry'\n    error in the database. How do I fix that?</b></a><br>\nThis problem has been rarely observed with MySQL, but not MariaDB.\nThe root cause of the failure seems to be reaching the upper limit on the auto increment field.\nUpgrading to MariaDB is recommended.\nIf that is not possible then: backup the database, remove the duplicate record(s),\nand restart the slurmdbd daemon as shown below.</p>\n<pre>\n$ slurmdbd -Dvv\n...\nslurmdbd: debug:  Table \"cray_job_table\" has changed.  Updating...\nslurmdbd: error: mysql_query failed: 1062 Duplicate entry '2711-1478734628' for key 'id_job'\n...\n\n$ mysqldump -u&lt;user&gt; -p&lt;user&gt; slurm_acct_db &gt;/tmp/slurm_db_backup.sql\n\n$ mysql\nmysql> use slurm_acct_db;\nmysql> delete from cray_job_table where id_job='2711-1478734628';\nmysql> quit;\nBye\n</pre>\n\n<p>If necessary, you can edit the database dump and recreate the database as\nshown below.</p>\n<pre>\n$ mysql\nmysql> drop database slurm_acct_db;\nmysql> create database slurm_acct_db;\nmysql> quit;\nBye\n\n$ mysql -u&lt;user&gt; -p&lt;user&gt; &lt;/tmp/slurm_db_backup.sql\n</pre>\n\n<p><a name=\"cray_sigbus\"<b>68. Why are applications on my Cray system failing\n    with SIGBUS (bus error)?</b></a><br>\nBy default, Slurm flushes Lustre file system and kernel caches upon completion\nof each job step. If multiple applications are run simultaneously on compute\nnodes (either multiple applications from a single Slurm job or multiple jobs)\nthe result can be significant performance degredation and even bus errors.\nFailures occur more requently when more applications are executed at the same\ntime on individual compute nodes.\nFailures are also more common when Lustre file systems are used.</p>\n\n<p>Two approaches exist to address this issue.\nOne is to disable the flushing of caches, which can be accomplished by adding\n\"LaunchParameters=lustre_no_flush\" to your Slurm configuration file\n\"slurm.conf\".\nA second approach is to modify Cray file system as described below in order to\nprevent Slurm specific files needing to be re-resolved over DFS.\nThis second approach does not address files used by applications, only those\nused directly by Slurm.</p>\n\n<p>On Cray CLE6.0, by default, nodes get the operating system, including the\nSlurm installation and all of its plugin, via a DVS mount of \"/\".\nReally \"/\" is an overlay filesystem where the lower portion is a loop-mounted\nsquashfs layer and the upper layer is tmpfs.\nWhen buffer caches are flushed during a dlopen (used by Slurm to load its\nplugins), a timeout may result from waiting to re-resolve a Slurm plugin over\nDVS.</p>\n\n<p>The NERSC solution is to localize all files related to Slurm or involved in\nslurmstepd launch into that tmpfs layer at boot time.\nThis is possible by creating a new netroot preload file:</p>\n\n<pre>\n# cat compute-preload.nersc\n/usr/lib64/libslurm*so*\n/usr/lib64/slurm/*.so\n/usr/sbin/slurmd\n/usr/sbin/slurmstepd\n/usr/bin/sbatch\n/usr/bin/srun\n/usr/bin/sbcast\n/usr/bin/numactl\n/usr/lib64/libnuma*so*\n/lib64/ast/libast.so*\n/lib64/ast/libcmd.so*\n/lib64/ast/libdll.so*\n/lib64/ast/libshell.so*\n/lib64/libacl.so*\n/lib64/libattr.so*\n/lib64/libc.so*\n/lib64/libcap.so*\n/lib64/libdl.so*\n/lib64/libgcc_s.so*\n...\n</pre>\n\n<p>NERSC generates its preload file by including everything installed by Slurm\nRPMs plus files identified as being used by Slurm's slurmd daemon on the compute\nnode by running the \"strace -f\" command while the slurmd daemon is launching\na job step.</p>\n\n<p>Once the netroot preload file is generated, it needs to then be included in the\ncray_netroot_preload_worksheet CLE configuration. For example:</p>\n\n<pre>\ncray_netroot_preload.settings.load.data.label.compute: null\ncray_netroot_preload.settings.load.data.compute.targets: []\ncray_netroot_preload.settings.load.data.compute.content_lists:\n- dist/compute-preload.cray\n- dist/compute-preload.nersc\ncray_netroot_preload.settings.load.data.compute.size_limit: 0\n</pre>\n\n<p>This is a generally useful technique for preventing remote lookups of commonly\naccessed files within jobs.</p>\n\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<p style=\"text-align:center;\">Last modified 04 July 2018</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/job_container_plugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Job Container Plugin API</a></h1>\n\n<h2> Overview</h2>\n<p> This document describes Slurm job container plugins and the API\nthat defines them.\nIt is intended as a resource to programmers wishing to write their\nown Slurm job container plugins.\nNote that job container plugin is designed for use with Slurm jobs.\nIt also applies to the sbcast server process on compute nodes.\nThere is a <a href=\"proctrack_plugins.html\">proctrack plugin</a>\ndesigned for use with Slurm job steps.</p>\n\n<p>Slurm job container plugins are Slurm plugins that implement\nthe Slurm job container API described herein.\nThey must conform to the Slurm Plugin API with the following\nspecifications:</p>\n\n<p><span class=\"commandline\">const char plugin_type[]</span><br>\nThe major type must be &quot;job_container.&quot;\nThe minor type can be any recognizable abbreviation for the type\nof proctrack. We recommend, for example:</p>\n<ul>\n<li><b>cncu</b> &mdash; Designed for use on Cray systems only and interface with\nCompute Node Clean Up (CNCU) the Cray infrastructure.</li>\n<li><b>none</b> &mdash; Designed for all other systems.</li>\n</ul>\n\n<p><span class=\"commandline\">const char plugin_name[]</span><br>\nSome descriptive name for the plugin.\nThere is no requirement with respect to its format.</p>\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loadeed by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<p>The programmer is urged to study\n<span class=\"commandline\">src/plugins/proctrack/job_container/job_container_cncu.c</span>\nfor an example implementation of a Slurm proctrack plugin.</p>\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<h2>Data Objects</h2>\n<p> The implementation must support a container ID of type uint64_t.\nThis container ID is generated by the\n<a href=\"proctrack_plugins.html\">proctrack plugin</a>.</p>\n\n<p>The implementation must maintain (though not necessarily directly export) an\nenumerated <b>errno</b> to allow Slurm to discover as practically as possible\nthe reason for any failed API call.\nThese values must not be used as return values in integer-valued functions\nin the API.\nThe proper error return value from integer-valued functions is Slurm_ERROR.\nThe implementation should endeavor to provide useful and pertinent information\nby whatever means is practical.\nSuccessful API calls are not required to reset errno to a known value.</p>\n\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<h2>API Functions</h2>\n<p>The following functions must appear. Functions which are not implemented should\nbe stubbed.</p>\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the SLURM\n<span class=\"commandline\">init()</span>, and the SLURM\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\">int container_p_create (uint32_t job_id);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Create a container.\nThe caller should ensure that the valid\n<span class=\"commandline\">container_p_delete()</span> is called.</p>\n<p style=\"margin-left:.2in\"><b>Argument</b>:\n<span class=\"commandline\"> job_id</span>&nbsp; &nbsp;&nbsp;(input)\nJob ID.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: Slurm_SUCCESS if successful. On failure,\nthe plugin should return Slurm_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int container_p_add_cont (uint32_t job_id, uint64_t cont_id);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Add a specific process tracking\ncontainer (PAGG) to a given job's container.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> job_id</span>&nbsp; &nbsp;&nbsp;(input)\nJob ID.<br>\n<span class=\"commandline\"> cont_id</span>&nbsp; &nbsp;&nbsp;(input)\nProcess tracking container value as set by the proctrack plugin.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: Slurm_SUCCESS if successful. On failure,\nthe plugin should return Slurm_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int container_p_add_pid (uint32_t job_id, pid_t pid, uid_t uid);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Add a specific process ID\nto a given job's container. The process is first placed into a process tracking\ncontainer (PAGG).</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> job_id</span>&nbsp; &nbsp;&nbsp;(input)\nJob ID.<br>\n<span class=\"commandline\"> pid</span>&nbsp; &nbsp;&nbsp;(input)\nProcess ID.<br>\n<span class=\"commandline\"> uid</span>&nbsp; &nbsp;&nbsp;(input)\nOwning user ID.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: Slurm_SUCCESS if successful. On failure,\nthe plugin should return Slurm_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">int container_p_delete (uint32_t job_id);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Destroy or otherwise\ninvalidate a job container.\nThis does not imply the container is empty, just that it is no longer\nneeded.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\"> job_id</span> &nbsp;&nbsp; (input)\nJob ID.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: Slurm_SUCCESS if successful. On failure,\nthe plugin should return Slurm_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n\n<p class=\"commandline\">void container_p_reconfig (void);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Note change in configuration,\nespecially the value of the DebugFlags with respect to JobContainer.</p>\n\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<p style=\"text-align:center;\">Last modified 27 March 2015</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/jobcompplugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Slurm Job Completion Logging Plugin API</a></h1>\n\n<h2> Overview</h2>\n<p>This document describes Slurm job completion logging plugins and the API that defines\nthem. It is intended as a resource to programmers wishing to write their own SLURM\njob completion logging plugins.</p>\n<p>Slurm job completion logging plugins are Slurm plugins that implement the SLURM\nAPI for logging job information upon their completion. This may be used to log job information\nto a text file, database, etc. The plugins must conform to the Slurm Plugin API with the following\nspecifications:</p>\n<p><span class=\"commandline\">const char plugin_type[]</span><br>\nThe major type must be &quot;jobcomp.&quot; The minor type can be any recognizable\nabbreviation for the type of scheduler. We recommend, for example:</p>\n<ul>\n<li><b>none</b> &mdash; No job logging.</li>\n<li><b>elasticsearch</b> &mdash; Log job information to an Elasticsearch server.</li>\n<li><b>filetxt</b> &mdash; Log job information to a text file.</li>\n<li><b>mysql</b> &mdash; Job completion is written to a mysql database.</li>\n<li><b>script</b> &mdash; Execute a script passing in job information in environment variables.</li>\n</ul>\n\n<p><span class=\"commandline\">const char plugin_name[]</span><br>\nSome descriptive name for the plugin.\nThere is no requirement with respect to its format.</p>\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loadeed by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<p>The programmer is urged to study\n<span class=\"commandline\">src/plugins/jobcomp/filetxt/jobcomp_filetxt.c</span> and\n<span class=\"commandline\">src/plugins/jobcomp/none/jobcomp_none.c</span>\nfor sample implementations of a Slurm job completion logging plugin.</p>\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<h2>Data Objects</h2>\n<p>The implementation must maintain (though not necessarily directly export) an\nenumerated <span class=\"commandline\">errno</span>  to allow Slurm to discover\nas practically as possible the reason for any failed API call. Plugin-specific enumerated\ninteger values should be used when appropriate. It is desirable that these values\nbe mapped into the range ESLURM_JOBCOMP_MIN and ESLURM_JOBCOMP_MAX\nas defined in <span class=\"commandline\">slurm/slurm_errno.h</span>.\nThe error number should be returned by the function\n<a href=\"#get_errno\"><span class=\"commandline\">slurm_jobcomp_get_errno()</span></a>\nand this error number can be converted to an appropriate string description using the\n<a href=\"#strerror\"><span class=\"commandline\">slurm_jobcomp_strerror()</span></a>\nfunction described below.</p>\n\n<p>These values must not be used as return values in integer-valued functions\nin the API. The proper error return value from integer-valued functions is SLURM_ERROR.\nThe implementation should endeavor to provide useful and pertinent information by\nwhatever means is practical.\nSuccessful API calls are not required to reset any errno to a known value. However,\nthe initial value of any errno, prior to any error condition arising, should be\nSLURM_SUCCESS. </p>\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<h2>API Functions</h2>\n<p>The following functions must appear. Functions which are not implemented should be stubbed.</p>\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the SLURM\n<span class=\"commandline\">init()</span>, and the SLURM\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\">int slurm_jobcomp_set_location (char * location);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Specify the location to be used for job logging.</p>\n<p style=\"margin-left:.2in\"><b>Argument</b>:<span class=\"commandline\"> location</span>&nbsp;\n&nbsp;&nbsp;(input) specification of where logging should be done. The interpretation of\nthis string is at the discretion of the plugin implementation.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<p class=\"commandline\">int slurm_jobcomp_log_record (struct job_record *job_ptr);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Note that a job is about to\nterminate or change size. The job's state will include the JOB_RESIZING flag\nif and only if it is about to change size. Otherwise the job is terminating.\nNote the existence of <i>resize_time</i> in the job record if one wishes to\nrecord information about a job at each size (i.e. a history of the job as\nits size changes through time).</p>\n<p style=\"margin-left:.2in\"><b>Argument</b>: <br>\n<span class=\"commandline\"> job_ptr</span>&nbsp;&nbsp;&nbsp;(input) Pointer to\njob record as defined in <i>src/slurmctld/slurmctld.h</i></p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<a name=\"get_errno\"><p class=\"commandline\">int slurm_jobcomp_get_errno (void);</p></a>\n<p style=\"margin-left:.2in\"><b>Description</b>: Return the number of a\njob completion logger specific error.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>: None</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: Error number for the last failure encountered by the job completion logging plugin.</p>\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<p class=\"commandline\"><a name=\"strerror\">const char *slurm_jobcomp_strerror(int errnum);</a></p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Return a string description of a job completion logger specific error code.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\"> errnum</span>&nbsp; &nbsp;&nbsp;(input) a job completion logger\nspecific error code.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: Pointer to string describing the error\nor NULL if no description found in this plugin.</p>\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<p class=\"commandline\">\nList slurm_jobcomp_get_jobs(acct_job_cond_t *job_cond);</a></p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Get completed job info from\nstorage.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> job_cond</span>&nbsp; &nbsp;&nbsp;\n(input) specification of filters to identify the jobs we wish information about\n(start time, end time, cluster name, user id, etc).\nacct_job_cond_t is defined in common/slurm_accounting_storage.h.\n<p style=\"margin-left:.2in\"><b>Returns</b>: A list of job records or NULL on \nerror. Elements on the list are of type jobcomp_job_rec_t, which is\ndefined in common/slurm_jobcomp.h.\nAny returned list must be destroyed to avoid memory leaks.\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<p class=\"commandline\">\nvoid slurm_jobcomp_archive(List selected_parts, void *params)\n<p style=\"margin-left:.2in\"><b>Description</b>: used to archive old data.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">List selected_parts </span>\n(input) list containing char *'s of names of partitions to query against.<br>\n<span class=\"commandline\">void *params </span>\n(input) to be cast as sacct_parameters_t in the plugin.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None</p>\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<p style=\"text-align:center;\">Last modified 6 June 2018</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/mpiplugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Slurm MPI Plugin API</a></h1>\n\n<h2> Overview</h2>\n<p> This document describes Slurm MPI selection plugins and the API that defines\nthem. It is intended as a resource to programmers wishing to write their own SLURM\nnode selection plugins.</p>\n\n<p>Slurm MPI selection plugins are Slurm plugins that implement the which version of\nmpi is used during execution of the new Slurm job. API described herein. They are\nintended to provide a mechanism for both selecting MPI versions for pending jobs and\nperforming any mpi-specific tasks for job launch or termination. The plugins must\nconform to the Slurm Plugin API with the following specifications:</p>\n<p><span class=\"commandline\">const char plugin_type[]</span><br>\nThe major type must be &quot;mpi.&quot; The minor type can be any recognizable\nabbreviation for the type of node selection algorithm. We recommend, for example:</p>\n<ul>\n<li><b>openmpi</b> &mdash; For use with older versions of OpenMPI.</li>\n<li><b>pmi2</b> &mdash; For use with MPI2 and MVAPICH2.</li>\n<li><b>pmix</b> &mdash; Exascale PMI implementation (currently supported by OpenMPI starting from version 2.0)</li>\n<li><b>none</b> &mdash; For use with most other versions of MPI.</li>\n</ul>\n<p><span class=\"commandline\">const char plugin_name[]</span><br>\nSome descriptive name for the plugin.\nThere is no requirement with respect to its format.</p>\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loadeed by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<p>A simplified flow of logic follows:\n<br>\nsrun is able to specify the correct mpi to use. with --mpi=MPITYPE\n<br>\nsrun calls\n<br>\n<i>mpi_p_thr_create((srun_job_t *)job);</i>\n<br>\nwhich will set up the correct environment for the specified mpi.\n<br>\nslurmd daemon runs\n<br>\n<i>mpi_p_init((stepd_step_rec_t *)job, (int)rank);</i>\n<br>\nwhich will set configure the slurmd to use the correct mpi as well to interact with the srun.\n<br>\nslurmstepd process runs\n<br>\n<i>p_mpi_hook_slurmstepd_prefork(const stepd_step_rec_t *job, char ***env);</i>\n<br>\nwhich executes immediately before fork/exec of tasks.\n<br>\n\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<h2>Data Objects</h2>\n<p> These functions are expected to read and/or modify data structures directly in\nthe slurmd daemon's and srun memory. Slurmd is a multi-threaded program with independent\nread and write locks on each data structure type. Therefore the type of operations\npermitted on various data structures is identified for each function.</p>\n\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<h2>API Functions</h2>\n<p>The following functions must appear. Functions which are not implemented should\nbe stubbed.</p>\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the SLURM\n<span class=\"commandline\">init()</span>, and the SLURM\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\">int mpi_p_init (stepd_step_rec_t *job, int rank);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Used by slurmd to configure the slurmd's environment\nto that of the correct mpi.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br><span class=\"commandline\"> job</span>&nbsp;\n&nbsp;&nbsp;(input) Pointer to the slurmd_job that is running.  Cannot be NULL.<br>\n<span class=\"commandline\"> rank</span>&nbsp;\n&nbsp;&nbsp;(input) Primarily there for MVAPICH.  Used to send the rank fo the mpirun job.\nThis can be 0 if no rank information is needed for the mpi type.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR.</p>\n\n<p class=\"commandline\">int mpi_p_thr_create (srun_job_t *job);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Used by srun to spawn the thread for the mpi processes.\nMost all the real processing happens here.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<span class=\"commandline\"> job</span>&nbsp;\n&nbsp;&nbsp;(input) Pointer to the srun_job that is running.  Cannot be NULL.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return -1.</p>\n\n<p class=\"commandline\">int mpi_p_single_task ();</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Tells the system whether or not multiple tasks\ncan run at the same time </p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\"> none</span></p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: false if multiple tasks can run and true if only\na single task can run at one time.</p>\n\n<p class=\"commandline\">int p_mpi_hook_slurmstepd_prefork(const stepd_step_rec_t *job, char ***env);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Used by slurmstepd process immediately prior\nto fork and exec of user tasks.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\"> job</span>&nbsp;&nbsp;&nbsp;(input)\nPointer to the slurmd structure for the job that is running.<br>\n<span class=\"commandline\"> env</span>&nbsp;&nbsp;&nbsp;(input)\nEnvironment variables for tasks to be spawned.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return -1.</p>\n\n<p class=\"commandline\">int mpi_p_exit();</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Cleans up anything that needs cleaning up after\nexecution.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\"> none</span></p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR, causing slurmctld to exit.</p>\n\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<p style=\"text-align:center;\">Last modified 15 September 2017</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/plugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Slurm Plugin API</a></h1>\n<h2>Overview</h2>\n<p>A Slurm plugin is a dynamically linked code object which is loaded explicitly\nat run time by the Slurm libraries. A plugin provides a customized implementation\nof a well-defined API connected to tasks such as authentication, interconnect\nfabric, and task scheduling.</p>\n<h2>Identification</h2>\n<p>A Slurm plugin identifies itself by a short character string formatted similarly\nto a MIME type: <i>&lt;major&gt;/&lt;minor&gt;</i>. The major type identifies\nwhich API the plugin implements. The minor type uniquely distinguishes a plugin\nfrom other plugins that implement that same API, by such means as the intended\nplatform or the internal algorithm. For example, a plugin to interface to the\nMaui scheduler would give its type as &quot;sched/maui.&quot; It would implement\nthe Slurm Scheduler API.</p>\n\n<h2>Versioning</h2>\n<p>Slurm plugin version numbers comprise a major, minor and micro revision number.\nIf the major and/or minor revision number changes, this indicates major changes\nto the Slurm functionality including changes to APIs, command options, and\nplugins.\nThese plugin changes may include new functions and/or function arguments.\nIf only the micro revision number changes, this is indicative of bug fixes\nand possibly minor enhancements which should not adversely impact users.\nIn all cases, rebuilding and installing all Slurm plugins is recommended\nat upgrade time.\nNot all compute nodes in a cluster need be updated at the same time, but\nall Slurm APIs, commands, plugins, etc. on a compute node should represent\nthe same version of Slurm.</p>\n\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<h2>Data Objects</h2>\n\n<p>A plugin must define and export the following symbols:</p>\n<ul>\n<li><span class=\"commandline\">char plugin_type[]<br>\n</span> a unique, short, formatted string to identify the plugin's purpose as\ndescribed above. A &quot;null&quot; plugin (i.e., one that implements the desired\nAPI as stubs) should have a minor type of &quot;none.&quot;</li>\n<li><span class=\"commandline\">char plugin_name[]<br>\n</span> a free-form string that identifies the plugin in human-readable terms,\nsuch as &quot;Kerberos authentication.&quot; Slurm will use this string to identify\nthe plugin to end users.</li>\n</ul>\n<p>A plugin may optionally define and export the following symbols:</p>\n<ul>\n<li>const uint32_t plugin_version<br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loadeed by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n</ul>\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<h2>API Functions in All Plugins</h2>\n<p class=\"commandline\">int init (void);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: If present, this function is called\njust after the plugin is loaded. This allows the plugin to perform any global\ninitialization prior to any actual API calls.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>: None.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if the plugin's initialization\nwas successful. Any other return value indicates to Slurm that the plugin should\nbe unloaded and not used.</p>\n<p class=\"commandline\">void fini (void);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: If present, this function is called\njust before the plugin is unloaded. This allows the plugin to do any finalization\nafter the last plugin-specific API call is made.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>: None.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n<p>The functions need not appear. The plugin may provide either\n<span class=\"commandline\">init()</span> or <span class=\"commandline\">fini()</span> or both.</p>\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n<h2>Thread Safety</h2>\n\n<p>Slurm is a multithreaded application. The Slurm plugin library may exercise\nthe plugin functions in a re-entrant fashion. It is the responsibility of the\nplugin author to provide the necessarily mutual exclusion and synchronization\nin order to avoid the pitfalls of re-entrant code.</p>\n<h2>Run-time Support</h2>\n<p>The standard system libraries are available to the plugin. The Slurm libraries\nare also available and plugin authors are encouraged to make use of them rather\nthan develop their own substitutes. Plugins should use the Slurm log to print\nerror messages.</p>\n<p>The plugin author is responsible for specifying any specific non-standard libraries\nneeded for correct operation. Plugins will not load if their dependent libraries\nare not available, so it is the installer's job to make sure the specified libraries\nare available.</p>\n<h2>Performance</h2>\n<p>All plugin functions are expected to execute very quickly. If any function\nentails delays (e.g. transactions with other systems), it should be written to\nutilize a thread for that functionality. This thread may be created by the\n<span class=\"commandline\">init()</span> function and deleted by the\n<span class=\"commandline\">fini()</span> functions. See <b>plugins/sched/backfill</b>\nfor an example of how to do this.</p>\n\n<h2>Data Structure Consistency</h2>\n\n<p>\n  In certain situations Slurm iterates over different data structures elements\n  using counters. For example, with environment variable arrays.\n  In order to avoid buffer overflows and other undesired situations, when a\n  plugin modifies certain elements it must also update these counters accordingly.\n  Other situations may require other types of changes.\n</p>\n<p>\n  The following advice indicates which structures have arrays with associated\n  counters that must be maintained when modifying data, plus other possible\n  important information to take in consideration when manipulating these\n  structures.\n  This list is not fully exhaustive due to constant modifications in code,\n  but it is a first start point and basic guideline for most common situations.\n  Complete structure information can be seen in the <i>slurm/slurm.h.in</i>\n  file.\n</p>\n\n<h3>slurm_job_info_t (job_info_t) Data Structure</h3>\n<pre>\n  uint32_t env_size;\n  char **environment;\n\n  uint32_t spank_job_env_size;\n  char **spank_job_env;\n\n  uint32_t gres_detail_cnt;\n  char **gres_detail_str;\n</pre>\n<p>\n  These pairs of array pointers and element counters must kept updated in order\n  to avoid subsequent buffer overflows, so if you update the array you must\n  also update the related counter.\n</p>\n<pre>\n  char *nodes;\n  int32_t *node_inx;\n\n  int32_t *req_node_inx;\n  char *req_nodes;\n</pre>\n<p>\n  <i>node_inx</i> and <i>req_node_inx</i> represents a list of index pairs for\n  ranges of nodes defined in the <i>nodes</i> and <i>req_nodes</i> fields\n  respectively. In each case, both array variables must match the count.\n</p>\n<pre>\n  uint32_t pack_job_id;\n  char *pack_job_id_set;\n</pre>\n<p>\n  The <i>pack_job_id</i> field should be the first element of the\n  <i>pack_job_id_set</i> array.\n</p>\n\n<h3>job_step_info_t Data Structure</h3>\n<pre>\n  char *nodes;\n  int32_t *node_inx;\n</pre>\n<p>\n  <i>node_inx</i> represents a list of index pairs for range of nodes defined in\n  <i>nodes</i>. Both variables must match the node count.\n</p>\n\n<h3>priority_factors_object_t Data Structure</h3>\n<pre>\n  uint32_t tres_cnt;\n  char **tres_names;\n  double *tres_weights;\n</pre>\n<p>\n  This value must match the configured TRES on the system, otherwise\n  iteration over the <i>tres_names</i> or <i>tres_weights</i> arrays can cause\n  buffer overflows.\n</p>\n\n<h3>job_step_pids_t Data Structure</h3>\n<pre>\n  uint32_t pid_cnt;\n  uint32_t *pid;\n</pre>\n<p>\n  Array <i>pid</i> represents the list of Process IDs for the job step, and\n  <i>pid_cnt</i> is the counter that must match the size of the array.\n</p>\n\n<h3>slurm_step_layout_t Data Structure</h3>\n<pre>\n  uint32_t node_cnt;\n  char *node_list;\n</pre>\n<p>\n  The <i>node_list</i> array size must match <i>node_cnt</i>.\n</p>\n<pre>\n  uint16_t *tasks;\n  uint32_t node_cnt;\n  uint32_t task_cnt;\n</pre>\n<p>\n  In the <i>tasks</i> array, each element is the number of tasks assigned\n  to the corresponding node, to its size must match <i>node_cnt</i>. Moreover\n  <i>task_cnt</i> represents the sum of tasks registered in <i>tasks</i>.\n</p>\n<pre>\n  uint32_t **tids;\n</pre>\n<p>\n  <i>tids</i> is an array of length <i>node_cnt</i> of task ID arrays. Each\n  subarray is designated by the corresponding value in the <i>tasks</i> array,\n  so <i>tasks</i>, <i>tids</i> and <i>task_cnt</i> must be set to match this\n  layout.\n</p>\n\n<h3>slurm_step_launch_params_t Data Structure</h3>\n<pre>\n  uint32_t envc;\n  char **env;\n</pre>\n<p>\n  When modifying the environment variables in the <i>env</i> array, you must\n  also modify the <i>envc</i> counter accordingly to prevent buffer overflows\n  in subsequent loops over that array.\n</p>\n<pre>\n  uint32_t pack_nnodes;\n  uint32_t pack_ntasks;\n\n  uint16_t *pack_task_cnts;\n  uint32_t **pack_tids;\n  uint32_t *pack_node_list;\n</pre>\n<p>\n  This <i>pack_*</i> related variables must match the current heterogeneous job\n  configuration.\n  <br>\n  For example, if for whatever reason you are reducing the number of tasks for\n  a node in a heterogeneous job, you should at least remove that task ID from\n  <i>pack_tids</i>, decrement <i>pack_ntasks</i> and <i>pack_task_cnts</i>, and\n  possibly decrement the number of nodes of the heterogeneous job in\n  <i>pack_nnodes</i> and <i>pack_node_list</i>.\n</p>\n<pre>\n  char **spank_job_env;\n  uint32_t spank_job_env_size;\n</pre>\n<p>\n  When modifying the <i>spank_job_env</i> structure, the\n  <i>spank_job_env_size</i> field must be updated to prevent buffer overflows\n  in subsequent loops over that array.\n</p>\n\n<h3>node_info_t Data Structure</h3>\n<pre>\n  char *features;\n  char *features_act;\n</pre>\n<p>\n  In a system containing Intel KNL processors the <i>features_act</i> field is\n  set by the plugin to match the currently running modes on the node. On other\n  systems the <i>features_act</i> is not usually used.\n  If you program such a plugin you must ensure that <i>features_act</i> contains\n  a subset of <i>features</i>.\n</p>\n<pre>\nchar *reason;\ntime_t reason_time;\nuint32_t reason_uid;\n</pre>\n<p>\n  If <i>reason</i> is modified then <i>reason_time</i> and <i>reason_uid</i>\n  should be updated.\n</p>\n\n<h3>reserve_info_t Data Structure</h3>\n<pre>\n  int32_t *node_inx;\n  uint32_t node_cnt;\n</pre>\n<p>\n  <i>node_inx</i> represents a list of index pairs for range of nodes associated\n  with the reservation and its count must equal <i>node_cnt</i>.\n</p>\n\n<h3>partition_info_t Data Structure</h3>\n<p>\n  No special advice.\n</p>\n\n<h3>slurm_step_layout_req_t Data Structure</h3>\n<p>\n  No special advice.\n</p>\n\n<h3>slurm_step_ctx_params_t</h3>\n<p>\n  No special advice.\n</p>\n\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<p style=\"text-align:center;\">Last modified 20 December 2017</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/bb_plugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Burst Buffer Plugin Programmer Guide</a></h1>\n\n<h2> Overview</h2>\n<p> This document describes the Slurm burst buffer plugins and the\nAPIs that defines them. It is intended as a resource to programmers\nwishing to write their own Slurm burst buffer plugin.\n\n<p>Slurm burst buffer plugins must conform to the\nSlurm Plugin API with the following specifications:\n\n<p><span class=\"commandline\">const char\nplugin_name[]=\"<i>full&nbsp;text&nbsp;name</i>\"</span>\n<p style=\"margin-left:.2in\">\nA free-formatted ASCII text string that identifies the plugin.\n\n<p><span class=\"commandline\">const char\nplugin_type[]=\"<i>major/minor</i>\"</span><br>\n<p style=\"margin-left:.2in\">\n\nThe major type must be &quot;burst_buffer&quot;.\nThe minor type can be any suitable name for the type of burst buffer\npackage.\nThe following burst buffer plugins are included in the Slurm distribution\n<ul>\n<li><b>cray</b> &mdash; Use Cray APIs to provide burst buffer.</li>\n<li><b>generic</b> &mdash; Use generic burst buffer plugin.</li>\n</ul>\n\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loaded by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<h2>API Functions</h2>\n<p>All of the following functions are required. Functions which are not\nimplemented must be stubbed.\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nCalled when the plugin is loaded, before any other functions are\ncalled. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nCalled when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\">\nint bb_p_load_state(bool init_config)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nThis function loads the current state of the burst buffer.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">init_config</span>\n(input) true if called as part of slurmctld initialization.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\nA Slurm errno\n\n<p class=\"commandline\">\nint bb_p_state_pack(uid_t uid, Buf buffer, uint16_t protocol_version)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nPack current burst buffer state information for network transmission.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">uid</span>\n(input) Owning user ID.<br>\n<span class=\"commandline\">buffer</span>\n(input) buffer that will be packed.<br>\n<span class=\"commandline\">protocol_version</span>\n(input) Version number of the data packing mechanism.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\nA Slurm errno\n\n<p class=\"commandline\">\nint bb_p_reconfig(void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nReread the burst buffer config file when it is updated.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\nA Slurm errno\n\n<p class=\"commandline\">\nuint64_t bb_p_get_system_size(char *name)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nGet the total burst buffer size in MB of a given plugin name.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">name</span>\n(input) Plugin name of the burst buffer. If name is NULL, return the total\nspace of all burst buffer plugins.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\nThe size of the burst buffer in MB.\n\n<p class=\"commandline\">\nint bb_p_job_validate(struct job_descriptor *job_desc, uid_t submit_uid)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nValidation of a job submit request with respect to burst buffer option.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job_desc</span>\n(input) Job submission request.<br>\n<span class=\"commandline\">submit_uid</span>\n(input) ID of the user submitting the job.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\nA Slurm errno.\n\n<p class=\"commandline\">\nint bb_p_job_validate2(struct job_record *job_ptr, char **err_msg)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nValidation of a job submit request with respect to burst buffer option.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job_ptr</span>\n(input) Job record for the job request with respect to burst buffer.<br>\n<span class=\"commandline\">err_msg</span>\n(output) Error message, sent directlt to job submission command<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\nA Slurm errno.\n\n<p class=\"commandline\">\nvoid bb_p_job_set_tres_cnt(struct job_record *job_ptr,\nuint64_t *tres_cnt, bool locked);\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nSet the tres count in the job recored.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job_ptr</span>\n(input) Job record to be set.<br>\n<span class=\"commandline\">tres_cnt</span>\n(input/output) Fill in this already allocated array with tres_cnts<br>\n<span class=\"commandline\">locked</span>\n(input) If tres read lock is locked or not.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\nNone\n\n<p class=\"commandline\">\ntime_t bb_p_job_get_est_start(struct job_record *job_ptr)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nGet an estimation of when a job can start.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job_ptr</span>\n(input) Start time of this job.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\nEstimated start time of job_ptr.\n\n<p class=\"commandline\">\nint bb_p_job_try_stage_in(void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nAllocate burst buffers to jobs expected to start soonest.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\nA Slurm errno\n\n<p class=\"commandline\">\nint bb_p_job_test_stage_in(struct job_record *job_ptr, bool test_only)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nDetermine if a job's burst buffer stage-in is complete.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job_ptr</span>\n(input) Job record to test.<br>\n<span class=\"commandline\">test_only</span>\n(input) If false, then attempt to load burst buffer if possible.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n0 stage-in is underway<br>\n1 stage-in complete<br>\n-1 state-in not started or burst buffer in some unexpeced state.\n\n<p class=\"commandline\">\nint bb_p_job_begin(struct job_record *job_ptr)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nAttempt to claim burst buffer resources.<br>\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job_ptr</span>\n(input) Job record to test.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\nA Slurm errno\n\n<p class=\"commandline\">\nint bb_p_job_revoke_alloc(struct job_record *job_ptr)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nRevoke allocation, but do not release resources.\nExecuted after bb_g_job_begin if there was an allocation failure.\nDoes not release previously allocated resources.<br>\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job_ptr</span>\n(input) Job record to test.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\nA Slurm errno\n\n<p class=\"commandline\">\nint bb_p_job_start_stage_out(struct job_record *job_ptr)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nTrigger a job's burst buffer stage out to begin.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job_ptr</span>\n(input) Job to stage out.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\nA Slurm errno\n\n<p class=\"commandline\">\nint bb_p_job_test_post_run(struct job_record *job_ptr)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nDetermine of jobs's post run operation is complete.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job_ptr</span>\n(input) Job to check if post run operation is complete.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n0 - post run operation is underway<br>\n1 - post run operation complete<br>\n-1 - fatal error\n\n<p class=\"commandline\">\nint bb_p_job_test_stage_out(struct job_record *job_ptr)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nDetermine of jobs's stage out is complete.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job_ptr</span>\n(input) Job to check if stage out is complete.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n0 - stage-out is underway<br>\n1 - stage-out complete<br>\n-1 - fatal error\n\n<p class=\"commandline\">\nint bb_p_job_cancel(struct job_record *job_ptr)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nTerminate any file staging and release burst buffer resources.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job_ptr</span>\n(input) Job to cancel.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\nA Slurm errno\n\n<p class=\"commandline\">\nchar *bb_p_xlate_bb_2_tres_str(char *burst_buffer)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nTranslate burst buffer string to TRES string.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">burst_buffer</span>\n(input) Burst buffer to translate to TRES string<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\nThe TRES string of the given burst buffer (Note: User must xfree the\nreturn value).\n\n<p class=\"footer\"><a href=\"#top\">top</a>\n\n<p style=\"text-align:center;\">Last modified 15 May 2017</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/gres_plugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Slurm Generic Resource (GRES) Plugin API</a></h1>\n\n<h2> Overview</h2>\n<p> This document describes Slurm generic resource plugins and the API that\ndefines them. It is intended as a resource to programmers wishing to write\ntheir own Slurm job submit plugins.\n<p>Slurm generic resource plugins must conform to the\nSlurm Plugin API with the following specifications:\n\n<p><span class=\"commandline\">const char\ngres_name[]=\"<i>gres_name</i>\"</span><br>\n<p style=\"margin-left:.2in\">\nThe <i>gres_name</i> should match <i>minor</i> in <i>plugin_type</i>\ndescribed below.</p>\n\n<p><span class=\"commandline\">const char\nplugin_type[]=\"<i>major/minor</i>\"</span><br>\n<p style=\"margin-left:.2in\">\nThe major type must be &quot;gres.&quot;\nThe minor type can be any suitable name\nfor the type of accounting package.</p>\n\n<p><span class=\"commandline\">const char plugin_name[]</span><br>\nSome descriptive name for the plugin.\nThere is no requirement with respect to its format.</p>\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loadeed by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<p>We include samples in the Slurm distribution for\n<ul>\n<li><b>gpu</b> &mdash; Manage GPUs (Graphics Processing Units).\n<li><b>nic</b> &mdash; Manage NICs (Network Interface Cards, this plugin does\nnothing today).\n</ul>\n\n<p class=\"footer\"><a href=\"#top\">top</a>\n\n<h2>API Functions</h2>\n<p>All of the following functions are required. Functions which are not\nimplemented must be stubbed.\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\">\nint node_config_load(List gres_conf_list)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nThis function is called by the <i>slurmd</i> daemon after the <i>slurm.conf</i>\nand <i>gres.conf</i> files have been read.\nIt can be used to validate the configuration by testing the\nactual hardware resources available or just confirm that an entry for the\nresource was included in the <i>gres.conf</i> file.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">gres_conf_list</span>\n(input/output) a list of configuration records generated by reading the\n<i>slurm.conf</i> and <i>gres.conf</i> files<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nvoid job_set_env(char ***job_env_ptr, void *gres_ptr, int node_inx)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nThis function is called by the <i>slurmd</i> daemon after the getting a job\ncredential and can be used to set environment variables for the job based\nupon GRES state information in that credential.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job_env_ptr</span>\n(input/output) pointer to the job's environment variable structure.<br>\n<span class=\"commandline\">gres_ptr</span>\n(input) pointer to the job's GRES allocation information.<br>\n<span class=\"commandline\">node_inx</span>\n(input) zero origin node index, used to interpret node specific GRES data.<br>\n\n<p class=\"commandline\">\nvoid step_set_env(char ***job_env_ptr, void *gres_ptr)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nThis function is called by the <i>slurmd</i> daemon after the getting a job\nstep credential and can be used to set environment variables for the job step\nbased upon GRES state information in that credential.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job_env_ptr</span>\n(input/output) pointer to the job step's environment variable structure.<br>\n<span class=\"commandline\">gres_ptr</span>\n(input) pointer to the step's GRES allocation information.<br>\n\n<p class=\"commandline\">\nextern void send_stepd(int fd)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nThis function is called by the <i>slurmd</i> daemon to send any needed\ninformation to the <i>slurmstepd</i> step shepherd.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">fd</span>\n(input) file descriptor to write information to.<br>\n\n<p class=\"commandline\">\nextern void recv_stepd(int fd)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nThis function is called by the <i>slurmstepd</i> step shepherd to read any\nneeded information from the <i>slurmd</i> daemon.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">fd</span>\n(input) file descriptor to read information from.<br>\n\n<p class=\"commandline\">\nextern int job_info(gres_job_state_t *job_gres_data, uint32_t node_inx,\nenum gres_job_data_type data_type, void *data)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nThis function is used to extract plugin specific data from the job's GRES\ndata structure. Note that data types GRES_JOB_DATA_COUNT and\nGRES_JOB_DATA_BITMAP are processed in common code rather than within the\nplugin and return data types of uint32_t* and bitstr_t** respectively.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job_gres_data</span>\n(input) Information about the job's GRES resources.<br>\n(input) Zero origin index within the job's resource allocation for which\ndata is desired.<br>\n<span class=\"commandline\">gres_job_data_type data_type</span>\n(input) Type of information to be gathered from the data structure.<br>\n<span class=\"commandline\">data</span>\n(output) Pointer to data within job_gres_data.\nNo data is copied or needs to be freed.\nData type depends upon the value of gres_job_data_type data_type.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">\nextern int step_info(gres_step_state_t *step_gres_data, uint32_t node_inx,\nenum gres_step_data_type data_type, void *data)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nThis function is used to extract plugin specific data from the step's GRES\ndata structure. Note that data types GRES_STEP_DATA_COUNT and\nGRES_STEP_DATA_BITMAP are processed in common code rather than within the\nplugin and return data types of uint32_t* and bitstr_t** respectively.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">step_gres_data</span>\n(input) Information about the step's GRES resources.<br>\n<span class=\"commandline\">node_inx</span>\n(input) Zero origin index within the job's resource allocation for which\ndata is desired.<br>\n<span class=\"commandline\">gres_step_data_type data_type</span>\n(input) Type of information to be gathered from the data structure.<br>\n<span class=\"commandline\">data</span>\n(output) Pointer to data within step_gres_data.\nNo data is copied or needs to be freed.\nData type depends upon the value of gres_step_data_type data_type.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"footer\"><a href=\"#top\">top</a>\n\n<p style=\"text-align:center;\">Last modified 27 March 2015</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/crypto_plugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Slurm Cryptographic Plugin Programmer Guide</a></h1>\n\n<h2> Overview</h2>\n<p> This document describe. Slurm cryptographic plugins and the API that\ndefines them.\nIt is intended as a resource to programmers wishing to write their own\nSlurm cryptographic plugins.</p>\n\n<p>Slurm cryptographic plugins are Slurm plugins that implement\na digital signature mechanism.\nThe slurmctld daemon generates a job step credential, signs it,\nand transmits it to an srun program.\nThe srun program then transmits it to the slurmd daemons directly.\nThe slurmctld daemon does not communicate directly with the slurmd\ndaemons at this time for performance reasons, but the job step\ncredential must be validated by the slurmd daemon as being\ngenerated by the slurmctld daemon.\nDigital signatures provide this validation mechanism.\nThe plugins must conform to the Slurm Plugin API with the following\nspecifications:</p>\n\n<p><span class=\"commandline\">const char plugin_type[]</span><br>\nThe major type must be &quot;crypto.&quot;\nThe minor type can be any recognizable abbreviation for the type of\ncryptographic mechanism.\nWe recommend, for example:</p>\n<ul>\n<li><b>munge</b> &mdash; LLNL's Munge system.</li>\n<li><b>openssl</b> &mdash; Open SSL.</li>\n</ul></p>\n\n<p><span class=\"commandline\">const char plugin_name[]</span><br>\nSome descriptive name for the plugin.\nThere is no requirement with respect to its format.</p>\n\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loadeed by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<h2>Data Objects</h2>\n<p>The implementation must maintain (though not necessarily directly export) an\nenumerated <span class=\"commandline\">errno</span> to allow Slurm to discover\nas practically as possible the reason for any failed API call.\nPlugin-specific enumerated integer values may be used when appropriate.\n\n<p>These values must not be used as return values in integer-valued\nfunctions in the API.\nThe proper error return value from integer-valued functions is SLURM_ERROR.\nThe implementation should endeavor to provide useful and pertinent\ninformation by whatever means is practical.\nSuccessful API calls are not required to reset any errno to a known value.\nHowever, the initial value of any errno, prior to any error condition\narising, should be SLURM_SUCCESS. </p>\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<h2>API Functions</h2>\n<p>The following functions must appear.\nFunctions which are not implemented should be stubbed.</p>\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\">void * crypto_read_private_key (const char *path);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Generate a private key\nbased upon the contents of the supplied file.</p>\n<p style=\"margin-left:.2in\"><b>Argument</b>:<span class=\"commandline\">path</span>&nbsp;\n&nbsp;&nbsp;(input) fully-qualified pathname to the private key\nas specified by the <b>JobCredentialPrivateKey</b> configuration parameter.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: The pointer to a key on\nsuccess or NULL on failure.\nCall crypto_destroy_key() to release memory associated with this key.</p>\n\n\n<p class=\"commandline\">void * crypto_read_public_key (const char *path);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Generate a public key\nbased upon the contents of the supplied file.</p>\n<p style=\"margin-left:.2in\"><b>Argument</b>:<span class=\"commandline\">path</span>&nbsp;\n&nbsp;&nbsp;(input) fully-qualified pathname to the public key\nas specified by the <b>JobCredentialPublicCertificate</b> configuration\nparameter.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: The pointer to a key on\nsuccess or NULL on failure.\nCall crypto_destroy_key() to release memory associated with this key.</p>\n\n\n<p class=\"commandline\">void crypto_destroy_key (void *key);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Release storage for\na public or private key.</p>\n<p style=\"margin-left:.2in\"><b>Argument</b>:<span class=\"commandline\"> key</span>&nbsp;\n&nbsp;&nbsp;(input/output) pointer to the key previously allocated\nby crypto_read_private_key() or crypto_read_public_key().</p>\n\n\n<p class=\"commandline\">char *crypto_str_error(void);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Return a string\ndescribing the last error generated by the cryptographic software.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: A pointer to a string.</p>\n\n<p class=\"commandline\">int crypto_sign (void *key, char *buffer, int buf_size,\nchar **sig_pp, unsigned int *sig_size_p);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Generate a signature for\nthe supplied buffer.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:</br>\n<span class=\"commandline\"> key</span>&nbsp;\n&nbsp;&nbsp;(input) pointer to the key previously generated by\ncrypto_read_private_key() or crypto_read_public_key().<br>\n<span class=\"commandline\"> buffer</span>&nbsp; &nbsp;&nbsp;(input) data to\nbe signed.<br>\n<span class=\"commandline\"> buf_size</span>&nbsp; &nbsp;&nbsp;(input)\nsize of buffer, in bytes.<br>\n<span class=\"commandline\"> sig_pp</span>&nbsp; &nbsp;&nbsp;(input/output)\nLocation in which to store the signature. NOTE: The storage for\nsig_pp should be allocated using xmalloc() and will be freed by\nthe caller using xfree().<br>\n<span class=\"commandline\"> sig_size_p</span>&nbsp; &nbsp;&nbsp;(input/output)\nLocation in which to store the size of the signature (sig_pp).</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful.\nOn failure, the plugin should return SLURM_ERROR and set the errno to an\nappropriate value to indicate the reason for failure.</p>\n\n<p class=\"commandline\">int crypto_verify_sign (void *key, char *buffer,\nint buf_size, char *signature, unsigned int sig_size);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Generate a signature for\nthe supplied buffer.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:</br>\n<span class=\"commandline\"> key</span>&nbsp;\n&nbsp;&nbsp;(input) pointer to the key previously generated by\ncrypto_read_private_key() or crypto_read_public_key().<br>\n<span class=\"commandline\"> buffer</span>&nbsp; &nbsp;&nbsp;(input) data\npreviously signed by crypto_sign().<br>\n<span class=\"commandline\"> buf_size</span>&nbsp; &nbsp;&nbsp;(input)\nsize of buffer, in bytes.<br>\n<span class=\"commandline\"> signature</span>&nbsp; &nbsp;&nbsp;(input)\nSignature as returned in sig_pp by the crypto_sign() function and\nto be confirmed.</br>\n<span class=\"commandline\"> sig_size</span>&nbsp; &nbsp;&nbsp;(input)\nSize of the signature as returned in sig_size_p by crypto_sign().</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful.\nOn failure, the plugin should return SLURM_ERROR and set the errno to an\nappropriate value to indicate the reason for failure.</p>\n\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<p style=\"text-align:center;\">Last modified 27 March 2015</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/power_plugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Power Management Plugin Programmer Guide</a></h1>\n\n<h2> Overview</h2>\n<p> This document describes the Slurm power management plugins and the APIs that\ndefines them. It is intended as a resource to programmers wishing to write\ntheir own Slurm power management plugin. This is version 100 of the API.\n\n<p>Slurm power management plugins must conform to the\nSlurm Plugin API with the following specifications:\n\n<p><span class=\"commandline\">const char\nplugin_name[]=\"<i>full&nbsp;text&nbsp;name</i>\"</span>\n<p style=\"margin-left:.2in\">\nA free-formatted ASCII text string that identifies the plugin.\n\n<p><span class=\"commandline\">const char\nplugin_type[]=\"<i>major/minor</i>\"</span><br>\n<p style=\"margin-left:.2in\">\nThe major type must be &quot;power&quot;.\nThe minor type can be any suitable name for the type of power management\npackage.\nThe following power management plugins are included in the Slurm distribution\n<ul>\n<li><b>cray</b> &mdash; Use Cray APIs to provide power management.</li>\n<li><b>none</b> &mdash; Can be configured to log calls to its functions, but\notherwise does nothing.</li>\n</ul>\n\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loadeed by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<p>Slurm can be configured to use multiple power management plugins if desired.</p>\n\n<p class=\"footer\"><a href=\"#top\">top</a>\n\n<h2>API Functions</h2>\n<p>All of the following functions are required. Functions which are not\nimplemented must be stubbed.\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\">\nvoid power_p_reconfig(void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nThis function is called when updated configuration information should be read.\n\n<p class=\"commandline\">\nvoid power_p_job_resume(struct job_record *job_ptr)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nNote that a previously suspended job is being resumed.\nCalled by the slurmctld daemon.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job_ptr</span>\n(input) pointer to the job record being resumed.\n\n<p class=\"commandline\">\nvoid power_p_job_start(struct job_record *job_ptr)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nNote that a job has been allocated resources and is about to begin execution.\nCalled by the slurmctld daemon.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">job_ptr</span>\n(input) pointer to the job record being started.\n\n<p class=\"footer\"><a href=\"#top\">top</a>\n\n<p style=\"text-align:center;\">Last modified 27 March 2015</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/priority_plugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Slurm Priority Plugin API</a></h1>\n\n<h2> Overview</h2>\n<p> This document describes Slurm priority plugins and the API that defines\nthem. It is intended as a resource to programmers wishing to write their own\nSlurm priority plugins.</p>\n\n<p>Slurm priority plugins are Slurm plugins that implement the Slurm priority\nAPI described herein. They must conform to the Slurm Plugin API with the\nfollowing specifications:</p>\n\n<p><span class=\"commandline\">const char\nplugin_type[]=\"<i>major/minor</i>\"</span><br>\nThe major type must be &quot;priority.&quot; The minor type can be any\nrecognizable abbreviation for the type of priority.\nWe recommend, for example:</p>\n\n<ul>\n<li><b>basic</b> &mdash; A plugin that implements the API and provides basic FIFO\njob priority.</li>\n<li><b>multifactor</b> &mdash; The multi-factor job priority plugin.</li>\n</ul>\n\n<p><span class=\"commandline\">const char plugin_name[]</span><br>\nSome descriptive name for the plugin.\nThere is no requirement with respect to its format.</p>\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loadeed by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<p>The programmer is urged to study\n<span class=\"commandline\">src/plugins/priority/basic/priority_basic.c</span>\nfor an example implementation of a Slurm priority plugin.</p>\n\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<h2>Data Objects</h2>\n<p>The implementation must maintain (though not necessarily directly export) an\nenumerated <b>errno</b> to allow Slurm to discover as practically as possible\nthe reason for any failed API call.  Plugin-specific enumerated integer values\nmay be used when appropriate.</p>\n\n<p>These values must not be used as return values in integer-valued functions\nin the API. The proper error return value from integer-valued functions is\nSLURM_ERROR. The implementation should endeavor to provide useful and pertinent\ninformation by whatever means is practical. Successful API calls are not\nrequired to reset any errno to a known value. However, the initial value of any\nerrno, prior to any error condition arising, should be SLURM_SUCCESS. </p>\n\n<p class=\"commandline\"> job_record</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: A slurmctld structure that\ncontains details about a job.</p>\n\n<p class=\"commandline\"> acct_assoc_rec_t</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: A slurm_accounting_storage\nstructure that contains details about an association.</p>\n\n<p class=\"commandline\"> priority_factors_object_t</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: A structure that contains a\njob's priority factors.</p>\n\n<p class=\"commandline\"> priority_factors_request_msg_t</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Used to request job priority\nfactors.  Contains a list of specific job and user ids of the jobs the user\nwants to see.</p>\n\n<p class=\"commandline\"> priority_factors_response_msg_t</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Used to return the list of\npriority_factors_object_t's containing the job priority factors the user has\nasked to see.</p>\n\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<h2>API Functions</h2>\n<p>The following functions must appear. Functions which are not implemented should\nbe stubbed.</p>\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\">uint32_t priority_p_set(uint32_t last_prio, struct job_record *job_ptr)</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Sets the priority of the job.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\">last_prio</span> (input) the priority assigned to the\nlast job<br>\n<span class=\"commandline\">job_ptr</span> (input) pointer to the job record.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: the priority assigned to the job</p>\n\n<p class=\"commandline\">void priority_p_reconfig(bool assoc_clear)</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Refresh the plugin's\nconfiguration. Called whenever slurmctld is reconfigured.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\">assoc_clear</span> (input) true if association\nand QOS used_cpu_run_secs field has been reset. This should be set to true\nwhen Slurm is reconfigured, but false if an RPC is used to change only the\ndebug level of debug flags.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: void</p>\n\n<p class=\"commandline\">void priority_p_set_assoc_usage(acct_assoc_rec_t *assoc)</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Set the normalized and\neffective usage for an association.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\">assoc</span> (input/output) pointer to the association.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: void</p>\n\n<p class=\"commandline\">List priority_p_get_priority_factors_list(priority_factors_request_msg_t *req_msg)</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Retrieves the priority factors\nfor all or specified jobs.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\">req_msg</span> (input) pointer to the message request\nthat contains the specific jobs or users of interest (of any).</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: a list of priority_factors_object_t's\ncontaining the requested job priority factors</p>\n\n<p class=\"commandline\">void priority_p_job_end(struct job_record *job_ptr)</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Handle ending of job\n  with decayable limits.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:\n<span class=\"commandline\">job_ptr</span> (input) pointer to the job record.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: void</p>\n\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<p style=\"text-align:center;\">Last modified 27 March 2015</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/authplugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">Slurm Authentication Plugin API</a></h1>\n\n<h2> Overview</h2>\n<p> This document describes Slurm authentication plugins and the API that defines\nthem. It is intended as a resource to programmers wishing to write their own SLURM\nauthentication plugins.</p>\n<p>Slurm authentication plugins are Slurm plugins that implement the Slurm authentication\nAPI described herein. They must conform to the Slurm Plugin API with the following\nspecifications:</p>\n<p><span class=\"commandline\">const char plugin_type[]</span><br>\nThe major type must be &quot;auth.&quot; The minor type can be any recognizable\nabbreviation for the type of authentication. We recommend, for example:</p>\n<ul>\n<li><b>none</b> &mdash; A plugin that implements the API without providing any actual\nauthentication service. This may be used for testing purposes, but is not suitable for\nproduction use due to lack of effective security.</li>\n<li><b>munge</b> &mdash; LLNL's Munge protocol (recommended plugin for production use).</li>\n</ul>\n\n<p><span class=\"commandline\">const char plugin_name[]</span><br>\nSome descriptive name for the plugin.\nThere is no requirement with respect to its format.</p>\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loadeed by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<p>The programmer is urged to study <span class=\"commandline\">src/plugins/auth/none/auth_none.c</span>\nfor an example implementation of a Slurm authentication plugin.</p>\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n<h2>Data Objects</h2>\n<p> The implementation must support an opaque class, which it defines, to be used\nas an authentication &quot;credential.&quot; This class must encapsulate all user-specific\ninformation necessary for the operation of the API specification below. The credential\nis referred to in Slurm code by an anonymous pointer (void *).</p>\n<p>The implementation must maintain (though not necessarily directly export) an\nenumerated <b>errno</b> to allow Slurm to discover as practically as possible\nthe reason for any failed API call. The following enumerated integer values (declared\nin <span class=\"commandline\">src/common/slurm_auth.h</span>) must be used when\nappropriate.</p>\n<p style=\"margin-left:.2in\">SLURM_AUTH_BADARG> &mdash;an argument to an API function\nwas invalid or malformed.<br>\nSLURM_AUTH_MEMORY> &mdash;a request could not be satisfied because memory for it\ncould not be allocated.<br>\nSLURM_AUTH_NOUSER> &mdash;a credential is improper because it refers to an unknown\nuser.<br>\nSLURM_AUTH_INVALID> &mdash;a credential is improper because the validation of it\nhas failed. This is specifically distinct from the expiration of a credential.<br>\nSLURM_AUTH_MISMATCH> &mdash;a credential could not be properly unpacked because it\nis of an incompatible type or version.</p>\n<p>These values must not be used as return values in integer-valued functions\nin the API. The proper error return value from integer-valued functions is SLURM_ERROR.\nWhile it is most practical to associate a different errno with each instance of\na credential, this is not necessarily enforced by the API. The implementation\nshould endeavor to provide useful and pertinent information by whatever means\nis practical. In most cases, this means an errno for each credential, since plugins\nmust be re-entrant. If a plugin maintains a global errno in place of or in addition\nto a per-credential errno, it is not required to enforce mutual exclusion on it.\nSuccessful API calls are not required to reset any errno to a known value. However,\nthe initial value of any errno, prior to any error condition arising, should be\nSLURM_SUCCESS. </p>\n<p>Plugins may assign implementation-specific values to errno so long as they\ndo not conflict with the values assigned above. This is done programmatically\nby assigning plugin-specific errno values which are arithmetically greater than\nor equal to the symbol SLURM_AUTH_FIRST_LOCAL_ERROR.</p>\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<h2>API Functions</h2>\n<p>The following functions must appear. Functions which are not implemented should\nbe stubbed.</p>\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the SLURM\n<span class=\"commandline\">init()</span>, and the SLURM\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\">void *slurm_auth_create(char *auth_info);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Allocates from the free store\nan anonymous credential object and returns a pointer to it. The pointer should\nbe valid until passed to <span class=\"commandline\">slurm_auth_destroy()</span> for\ndisposal. Slurm will not pass\ncredentials to the API which have not been allocated by this function.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\">argv</span> &nbsp;&nbsp;(input) plugin specific\ninformation.\n<span class=\"commandline\">auth_info</span> &nbsp;&nbsp;(input) plugin specific\nidentification of the server.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: A pointer to a newly allocated credential\nif successful. On failure, the plugin should return NULL and set its errno to\nan appropriate value to indicate the reason for failure.</p>\n<p class=\"commandline\">int slurm_auth_destroy (void *cr);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Deallocates a credential that\nwas allocated with <span class=\"commandline\">slurm_auth_alloc()</span> and any\nassociated storage that has been allocated for it during its use.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<span class=\"commandline\"> cr</span>&nbsp;\n&nbsp;&nbsp;(input) pointer to the credential that is to be deallocated. Cannot\nbe NULL.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure,\nthe plugin should return SLURM_ERROR and set the errno to an appropriate value\nto indicate the reason for failure.</p>\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<p class=\"commandline\">int slurm_auth_verify (void *cr, char *auth_info );</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Verifies that a credential is\nin order and correctly identifies the associated user. It also verifies that the\ncredential has not expired. If verification is successful, the return values of\n<span class=\"commandline\">slurm_auth_get_uid()</span> and\n<span class=\"commandline\">slurm_auth_get_gid()</span>\nin subsequent calls must correspond to the actual verified system UID and GID\nof the user associated with the credential. Verification must fail if the credential\nhas not previously been activated, even if a credential implementation cannot\nexist in an unactivated state. A credential's valid term is defined at activation\nand verification must fail if the credential has expired, even if it would otherwise\nbe valid.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\">cr</span> &nbsp;&nbsp;(input) pointer to the credential\nwhich is to be verified. Cannot be NULL.<br>\n<span class=\"commandline\">auth_info</span> &nbsp;&nbsp;(input) plugin specific\nidentification of the server.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if the credential is\nverified to be in order and has not expired. If the credential cannot be verified,\nor if the credential has expired, the function should return SLURM_ERROR and set\nits errno to an appropriate value to indicate the reason for failure.</p>\n\n<p class=\"commandline\">uid_t slurm_auth_get_uid (void *cr, char *auth_info);<br>\ngid_t slurm_auth_get_gid (void *cr, char *auth_info);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Extracts the numerical UID (GID)\nof the user corresponding to the given credential. Slurm considers this value\ntrustworthy only if the credential has been successfully verified using\n<span class=\"commandline\">slurm_auth_verify()</span>.\nAn unverified credential does not immediately give rise to an error condition\nin these functions, since this would require a plugin to distinguish between a\nverified and an unverified credential, which may be computationally expensive.\nA plugin may consider the lack of verification as an error.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n <span class=\"commandline\">cr</span> &nbsp;&nbsp; (input) pointer to the credential\ncontaining the desired identification.  Cannot be NULL.<br>\n<span class=\"commandline\">auth_info</span> &nbsp;&nbsp;(input) plugin specific\nidentification of the server.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: If successful, the Linux UID (GID)\nassociated with the credential. In case of error, SLURM_AUTH_NOBODY should be\nreturned and errno set appropriately to indicate the cause of the failure.</p>\n\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<p class=\"commandline\">int slurm_auth_pack (void *cr, Buf buf);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Marshals a credential into a buffer\nfor transmission according to the Slurm packing protocol. All authentication plugins\nmust first pack the plugin_type and then the plugin_version data before any plugin-specific\ndata elements are packed. slurm_auth_pack() and slurm_auth_pack() are strictly\nreciprocal. The esult of a packing followed by an unpacking must be a functionally\nequivalent credential. A credential is deemed appropriate for marshalling at any\ntime after its allocation and before its destruction.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\">cr</span>&nbsp; &nbsp;&nbsp;(input) pointer to the credential\nto pack.<br>\n<span class=\"commandline\">buf</span>&nbsp;&nbsp;&nbsp; (input/output) the buffer\ninto which the credential should be packed.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure\nthe plugin should return SLURM_ERROR and set the errno to indicate the reason\nfor the failure.</p>\n<p class=\"commandline\">int slurm_auth_unpack (void *cr, Buf buf);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Unmarshals a credential from a\nbuffer according to the Slurm packing protocol into a supplied (and presumed empty)\ncredential object. The unmarshalled credential is not assumed to be activated\nor verified. The <span class=\"commandline\">plugin_type</span> and <span class=\"commandline\">plugin_version</span>\ndata should first be unpacked from the buffer and verified for applicability.\nThe API does not enforce that they must be equivalent, merely compatible. Compatibility\nis implementation-dependent.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>:<br>\n<span class=\"commandline\">cr</span> &nbsp;&nbsp;&nbsp;(output) pointer to the\ncredential to pack.<br>\n<span class=\"commandline\">buf</span> &nbsp;&nbsp;&nbsp;(input/output) the buffer\nfrom which the credential should be unpacked.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if the credential was\nsuccessfully unpacked. In case of failure, the function should return SLURM_ERROR\nand set errno appropriately to indicate the cause of the failure. If the function\nfails, no assumptions are made about the state of the credential except its suitability\nfor destruction via <span class=\"commandline\">slurm_auth_destroy()</span>.</p>\n<p class=\"commandline\">int slurm_auth_print (void *cr, FILE *fp);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Writes a human-readable representation\nof the credential to a standard I/O stream. There are no strict API constraints\non the behavior of this function, however it is recommended that the information\nbe as complete and as concise as possible. For example, lengthy digital &quot;signatures&quot;\nneed not be printed bitwise, but may be represented by their checksum. The intent\nis to provide a depiction of the credential for debugging purposes.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>: None.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: SLURM_SUCCESS if successful. On failure\nthe plugin should return SLURM_ERROR and set the errno appropriately to indicate\nthe cause of failure.</p>\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n<p class=\"commandline\">int slurm_auth_errno (void *cr);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Returns the current value of errno.\nWhether the value is associated with the given credential or with the plugin as\na whole is implementation-dependent. Because this function can be used to discover\nthe reason why a credential allocation has failed, the argument is advisory. </p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <span class=\"commandline\">cr</span>&nbsp;&nbsp;&nbsp;&nbsp;\n(input) pointer to the credential, the status of whose most recently executed\nAPI function is to be returned. This value may be NULL, indicating that the most\nrecent errno value applicable to the plugin as a whole is to be returned.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: The current value of errno or SLURM_SUCCESS\nif there is no error to report.</p>\n<p class=\"commandline\">const char *slurm_auth_errstr (int errno);</p>\n<p style=\"margin-left:.2in\"><b>Description</b>: Provides a human-readable string\nassociated with the given errno. The plugin need only supply error strings for\nthe errno values it defines and not for errno values listed above that are required\nby the API.</p>\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <span class=\"commandline\">errno</span>&nbsp;&nbsp;&nbsp;\n(input) the plugin-specific errno for which a corresponding error message is desired.</p>\n<p style=\"margin-left:.2in\"><b>Returns</b>: A pointer to a static error message.\nThis function must always return a pointer to a string, even if the string is\nempty or ambiguous such as &quot;unknown error.&quot;</p>\n<p class=\"footer\"><a href=\"#top\">top</a></p>\n\n<p style=\"text-align:center;\">Last modified 27 March 2015</p>\n\n<!--#include virtual=\"footer.txt\"-->\n",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/ext_sensorsplugins.shtml": "<!--#include virtual=\"header.txt\"-->\n\n<h1><a name=\"top\">External Sensors Plugin API (ExtSensorsType)\n</a></h1>\n\n<h2> Overview</h2>\n<p> This document describe. Slurm external sensors plugins and the API that\ndefines them. It is intended as a resource to programmers wishing to write\ntheir own Slurm external sensors plugins.\n\n<p>Slurm external sensors plugins must conform to the\nSlurm Plugin API with the following specifications:\n\n<p><span class=\"commandline\">const char\nplugin_name[]=\"<i>full&nbsp;text&nbsp;name</i>\"</span>\n<p style=\"margin-left:.2in\">\nA free-formatted ASCII text string that identifies the plugin.\n\n<p><span class=\"commandline\">const char\nplugin_type[]=\"<i>major/minor</i>\"</span><br>\n<p style=\"margin-left:.2in\">\nThe major type must be &quot;ext_sensors.&quot;\nThe minor type can be any suitable name\nfor the type of external sensors. We currently use\n<ul>\n<li><b>none</b> &mdash; No external sensors data is collected.\n<li><b>rrd</b> &mdash; Gets external sensors data from the\nRRD database.\n</ul>\n\n<p><span class=\"commandline\">const uint32_t plugin_version</span><br>\nIf specified, identifies the version of Slurm used to build this plugin and\nany attempt to load the plugin from a different version of Slurm will result\nin an error.\nIf not specified, then the plugin may be loadeed by Slurm commands and\ndaemons from any version, however this may result in difficult to diagnose\nfailures due to changes in the arguments to plugin functions or changes\nin other Slurm functions used by the plugin.</p>\n\n<p>The programmer is urged to study\n<span class=\"commandline\">src/plugins/ext_sensors/rrd</span> and\n<span class=\"commandline\">src/common/slurm_ext_sensors.c</span>\nfor a sample implementation of a Slurm external sensors plugin.\n<p class=\"footer\"><a href=\"#top\">top</a>\n\n<h2>API Functions</h2>\n<p>All of the following functions are required. Functions which are not\nimplemented must be stubbed.\n\n<p class=\"commandline\"> int init (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is loaded, before any other functions are\n  called. Put global initialization here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n  <span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n  <span class=\"commandline\">SLURM_ERROR</span> on failure.</p>\n\n<p class=\"commandline\"> void fini (void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\n  Called when the plugin is removed. Clear any allocated storage here.\n<p style=\"margin-left:.2in\"><b>Returns</b>: None.</p>\n\n<p><b>Note</b>: These init and fini functions are not the same as those\ndescribed in the <span class=\"commandline\">dlopen (3)</span> system library.\nThe C run-time system co-opts those symbols for its own initialization.\nThe system <span class=\"commandline\">_init()</span> is called before the Slurm\n<span class=\"commandline\">init()</span>, and the Slurm\n<span class=\"commandline\">fini()</span> is called before the system's\n<span class=\"commandline\">_fini()</span>.</p>\n\n<p class=\"commandline\">extern int ext_sensors_read_conf(void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nReads the external sensors plugin configuration file (ext_sensors.conf)\nand populates the configuration structure.\nCalled by the slurmctld daemon.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\"> None</span>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">extern int ext_sensors_free_conf(void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nFrees the memory allocated for the external sensors configuration.\nCalled by the slurmctld daemon.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\"> None</span>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">extern int ext_sensors_p_update_component_data(void)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nUpdates external sensors data for data types and component types as configured\nin ext_sensors.conf.\nCalled by the slurmctld daemon.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\"> None</span>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">extern int ext_sensors_p_get_stepstartdata(struct step_record *step_rec)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nSets external sensors data in the step record when a job step starts.\nCalled by slurmctld.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\"> step_rec</span> (input) pointer to step record.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<p class=\"commandline\">extern int ext_sensors_p_get_stependdata(struct step_record *step_rec)\n<p style=\"margin-left:.2in\"><b>Description</b>:<br>\nSets external sensors data in the step record when a job step ends.\nCalled by slurmctld.\n<p style=\"margin-left:.2in\"><b>Arguments</b>: <br>\n<span class=\"commandline\"> step_rec</span> (input) pointer to step record.<br>\n<p style=\"margin-left:.2in\"><b>Returns</b>: <br>\n<span class=\"commandline\">SLURM_SUCCESS</span> on success, or<br>\n<span class=\"commandline\">SLURM_ERROR</span> on failure.\n\n<h2>Parameters</h2>\n<p>These parameters can be used in the slurm.conf to configure the\nplugin and the frequency at which to gather external sensors data.</p>\n<dl>\n<dt><span class=\"commandline\">ExtSensorsType</span>\n<dd>Specifies which external sensors plugin should be used.\n<dt><span class=\"commandline\">ExtSensorsFreq</span>\n<dd>Time interval between pollings in seconds.\n</dl>>\n\n<p class=\"footer\"><a href=\"#top\">top</a>\n\n<p style=\"text-align:center;\">Last modified 27 March 2015</p>\n\n<!--#include virtual=\"footer.txt\"-->\n"
    },
    "skipped": [
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/contribs/slurm_completion_help/slurm.vim",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/contribs/cray/libalps_test_programs.tar.gz",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/plane_ex1.gif",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/plane_ex7.gif",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/k_function.gif",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/Slurm_Individual.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/hdf5_job_outline.png",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/arch.gif",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/schedmd.png",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/ibm_pe_fig2.png",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/ibm_pe_fig1.png",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/squeue_color.png",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/plane_ex6.gif",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/plane_ex4.gif",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/allocation_pies.gif",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/plane_ex3.gif",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/plane_ex5.gif",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/coding_style.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/rosetta.gif",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/mc_support.gif",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/plane_ex2.gif",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/topo_ex1.gif",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/slurm_logo.png",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/entities.gif",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/Slurm_Entity.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/hdf5_task_attr.png",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/fonts.ttf",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/example_usage.gif",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/topo_ex2.gif",
        "/tmp/vanessa/spack-stage/spack-stage-slurm-17-11-9-2-oad4arrpt4gky46u5g3srq5ekg32jzny/spack-src/doc/html/usage_pies.gif"
    ],
    "total_files": 2557
}