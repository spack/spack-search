{
    "matches": {
        "/tmp/vanessa/spack-stage/spack-stage-arbor-0.4-ovxhu67m2j3bdrprc7jdkgwxxkag3y2b/spack-src/doc/install/build_install.rst": ".. _in_build_install:\n\nBuild and install from source\n#############################\n\nThis guide covers building and installing Arbor using CMake, which is the recommended method for configuring Arbor for HPC applications and developers.\n\nWe start with an overview of the building process, and the various options available to customize the build.\nThen we cover installing and running on `HPC clusters <cluster_>`_, followed by a `troubleshooting guide <troubleshooting_>`_ for common build problems.\n\n.. note::\n    To get help in case of problems installing Arbor, please make an issue on the Arbor `Github issues <https://github.com/arbor-sim/arbor/issues>`_ page.\n\n.. _install_requirements:\n\nRequirements\n============\n\nMinimum requirements\n--------------------\n\nThe non distributed (i.e. no MPI) version of Arbor can be compiled on Linux or OS X systems\nwith very few tools.\n\n.. table:: Required Tools\n\n    =========== ============================================\n    Tool        Notes\n    =========== ============================================\n    Git         To check out the code, minimum version 2.0.\n    CMake       To set up the build, minimum version 3.12.\n    compiler    A C++17 compiler. See `compilers <install-compilers_>`_.\n    =========== ============================================\n\n.. _install-compilers:\n\nCompilers\n~~~~~~~~~\n\nArbor requires a C++ compiler that fully supports C++17.\nWe recommend using GCC or Clang, for which Arbor has been tested and optimised.\n\n.. table:: Supported Compilers\n\n    =========== ============ ============================================\n    Compiler    Min version  Notes\n    =========== ============ ============================================\n    GCC         8.4.0\n    Clang       8.0          Needs GCC 8 or later for standard library.\n    Apple Clang 9            Apple LLVM version 9.0.0 (clang-900.0.39.2)\n    Hip Clang   Rocm 3.6     HIP support is currently experimental.\n    =========== ============ ============================================\n\n.. _note_CC:\n\n.. Note::\n    The ``CC`` and ``CXX`` environment variables specify which compiler executable\n    CMake should use. If these are not set, CMake will attempt to automatically choose a compiler,\n    which may be too old to compile Arbor.\n    For example, the default compiler chosen below by CMake was GCC 4.8.5 at ``/usr/bin/c++``,\n    so the ``CC`` and ``CXX`` variables were used to specify GCC 10.2.0 before calling ``cmake``.\n\n    .. code-block:: bash\n\n        # on this system CMake chooses the following compiler by default\n        $ c++ --version\n        c++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-16)\n\n        # check which version of GCC is available\n        $ g++ --version\n        g++ (GCC) 10.2.0\n        Copyright (C) 2020 Free Software Foundation, Inc.\n\n        # set environment variables for compilers\n        $ export CC=`which gcc`; export CXX=`which g++`;\n\n        # launch CMake\n        # the compiler version and path is given in the CMake output\n        $ cmake ..\n        -- The C compiler identification is GNU 10.2.0\n        -- The CXX compiler identification is GNU 10.2.0\n        -- Check for working C compiler: /cm/local/apps/gcc/10.2.0/bin/gcc\n        -- Check for working C compiler: /cm/local/apps/gcc/10.2.0/bin/gcc -- works\n        ...\n\n.. Note::\n    Is is commonly assumed that to get the best performance one should use a vendor-specific\n    compiler (e.g. the Intel, Cray or IBM compilers). These compilers are often better at\n    auto-vectorizing loops, however for everything else GCC and Clang nearly always generate\n    more efficient code.\n\n    The main computational loops in Arbor are generated from\n    `NMODL <https://www.neuron.yale.edu/neuron/static/docs/help/neuron/nmodl/nmodl.html>`_.\n    The generated code is explicitly vectorised, obviating the need for vendor compilers,\n    and we can take advantage of their benefits of GCC and Clang:\n    faster compilation times; fewer compiler bugs; and better support for C++ standards.\n\n.. Note::\n    The IBM XL C++ compiler and Intel C++ compiler are not supported, owing to unresolved\n    compiler issues. We strongly recommend building with GCC or Clang instead on PowerPC\n    and Intel platforms.\n\nOptional requirements\n---------------------\n\nGPU support\n~~~~~~~~~~~\n\nArbor has full support for NVIDIA GPUs, for which the NVIDIA CUDA toolkit version 10 is required.\nAnd experimental support for AMD GPUs when compiled with hip-clang (non-release compiler).\n\nDistributed\n~~~~~~~~~~~\n\nArbor uses MPI to run on HPC cluster systems.\nArbor has been tested on MVAPICH2, OpenMPI, Cray MPI, and IBM MPI.\nMore information on building with MPI is in the `HPC cluster section <cluster_>`_.\n\nPython\n~~~~~~\n\nArbor has a Python frontend, for which a minimum of Python 3.6 is required.\nIn order to use MPI in combination with the python frontend the\n`mpi4py <https://mpi4py.readthedocs.io/en/stable/install.html#>`_\nPython package is recommended. See :ref:`install-python` for more information.\n\nNeuroML\n~~~~~~~\n\nArbor supports reading cell morphologies defined in NeuroML version 2 through\nan additional NeuroML support library ``arbornml``. This library requires\n`libxml2 <http://xmlsoft.org>`_ for the parsing of NeuroML2 XML. See :ref:`install-neuroml` for\nmore information.\n\n\nDocumentation\n~~~~~~~~~~~~~~\n\nTo build a local copy of the html documentation that you are reading now, you will need to\ninstall `Sphinx <http://www.sphinx-doc.org/en/master/>`_.\n\n.. _install-downloading:\n\nGetting the code\n================\n\nThe easiest way to acquire the latest version of Arbor is to check the code out from\nthe `Github repository <https://github.com/arbor-sim/arbor>`_:\n\n.. code-block:: bash\n\n    git clone https://github.com/arbor-sim/arbor.git --recurse-submodules\n\nWe recommend using a recursive checkout, because Arbor uses Git submodules for some\nof its library dependencies.\nThe CMake configuration attempts to detect if a required submodule is available, and\nwill print a helpful warning\nor error message if not, but it is up to the user to ensure that all required\nsubmodules are downloaded.\n\nThe Git submodules can be updated, or initialized in a project that didn't use a\nrecursive checkout:\n\n.. code-block:: bash\n\n    git submodule update --init --recursive\n\nYou can also point your browser to Arbor's\n`Github page <https://github.com/arbor-sim/arbor>`_ and download a zip file.\nIf you use the zip file, then don't forget to run Git submodule update manually.\n\n.. _building:\n\nBuilding and installing Arbor\n=============================\n\nOnce the Arbor code has been checked out, first run CMake to configure the build, then run make.\n\nBelow is a simple workflow for: **1)** getting the source; **2)** configuring the build;\n**3)** building; **4)** running tests; **5)** install.\n\nFor more detailed build configuration options, see the `quick start <quickstart_>`_ guide.\n\n.. code-block:: bash\n\n    # 1) Clone.\n    git clone https://github.com/arbor-sim/arbor.git --recurse-submodules\n    cd arbor\n\n    # Make a path for building\n    mkdir build\n    cd build\n\n    # 2) Use CMake to configure the build.\n    # By default Arbor builds in release mode, i.e. with optimizations on.\n    # Release mode should be used for installing and benchmarking Arbor.\n    cmake ..\n\n    # 3.1) Build Arbor library.\n    make -j 4\n    # 3.2) Build Arbor unit tests.\n    make -j 4 tests\n\n    # 4) Run tests.\n    ./bin/unit\n\n    # 5) Install (by default, to /usr/local).\n    make install\n\nThis will build Arbor in release mode with the `default C++ compiler <note_CC_>`_.\n\n.. _quickstart:\n\nQuick start: examples\n---------------------\n\nBelow are some example of CMake configurations for Arbor. For more detail on individual\nCMake parameters and flags, follow links to the more detailed descriptions below.\n\n.. topic:: `Debug <buildtarget_>`_ mode with `assertions <debugging_>`_ enabled.\n\n    If you encounter problems building or running Arbor, compile with these options\n    for testing and debugging.\n\n    .. code-block:: bash\n\n        cmake -DARB_WITH_ASSERTIONS=ON -DCMAKE_BUILD_TYPE=debug\n\n.. topic:: `Release <buildtarget_>`_ mode with `Clang <install-compilers_>`_.\n\n    .. code-block:: bash\n\n        export CC=`which clang`\n        export CXX=`which clang++`\n        cmake\n\n.. topic:: `Release <buildtarget_>`_ mode for the `Haswell architecture <install-architecture_>`_ and `explicit vectorization <install-vectorize_>`_ of kernels.\n\n    .. code-block:: bash\n\n        cmake -DARB_VECTORIZE=ON -DARB_ARCH=haswell\n\n.. topic:: `Release <buildtarget_>`_ mode with `explicit vectorization <install-vectorize_>`_, targeting the `Broadwell architecture <install-vectorize_>`_, with support for `Nvidia GPUs <install-gpu_>`_, and building with `GCC 9 <install-compilers_>`_.\n\n    .. code-block:: bash\n\n        export CC=gcc-9\n        export CXX=g++-9\n        cmake -DARB_VECTORIZE=ON -DARB_ARCH=broadwell -DARB_GPU=cuda\n\n.. topic:: `Release <buildtarget_>`_ mode with `explicit vectorization <install-vectorize_>`_, targeting the `Broadwell architecture <install-vectorize_>`_, with support for `AMD GPUs <install-gpu_>`_, and building with `hipcc <install-compilers_>`_.\n\n    .. code-block:: bash\n\n        export CC=clang\n        export CXX=hipcc\n        cmake -DARB_VECTORIZE=ON -DARB_ARCH=broadwell -DARB_GPU=hip\n\n\n.. topic:: `Release <buildtarget_>`_ mode with `explicit vectorization <install-vectorize_>`_, optimized for the local system architecture and `install <install_>`_ in ``/opt/arbor``\n\n    .. code-block:: bash\n\n        cmake -DARB_VECTORIZE=ON -DCMAKE_INSTALL_PREFIX=/opt/arbor\n\n.. _buildtarget:\n\nBuild target\n------------\n\nBy default, Arbor is built in release mode, which should be used when installing\nor benchmarking Arbor. To compile in debug mode (which in practical terms means\nwith ``-g -O0`` flags), use the ``CMAKE_BUILD_TYPE`` CMake parameter.\n\n.. code-block:: bash\n\n    cmake -DCMAKE_BUILD_TYPE={debug,release}\n\n..  _install-architecture:\n\nArchitecture\n------------\n\nBy default, Arbor is built to target whichever architecture is the compiler default,\nwhich often involves a sacrifice of performance for binary portability. The target\narchitecture can be explicitly set with the ``ARB_ARCH`` configuration option. This\nwill be used to direct the compiler to use the corresponding instruction sets and\nto optimize for that architecture.\n\nWhen building and installing on the same machine, a good choice for many environments\nis to set ``ARB_ARCH`` to ``native``:\n\n.. code-block:: bash\n\n    cmake -DARB_ARCH=native\n\nWhen deploying on a different machine (cross-compiling) specify\nthe specific architecture of the target machine. The valid values correspond to those given\nto the ``-mcpu`` or ``-march`` options for GCC and Clang; the build system will translate\nthese names to corresponding values for other supported compilers.\n\nSpecific recent x86-family Intel CPU architectures include ``broadwell``, ``skylake`` and\n``knl``. Complete lists of architecture names can be found in the compiler documentation:\nfor example GCC `x86 options <https://gcc.gnu.org/onlinedocs/gcc/x86-Options.html>`_,\n`PowerPC options <https://gcc.gnu.org/onlinedocs/gcc/RS_002f6000-and-PowerPC-Options.html#RS_002f6000-and-PowerPC-Options>`_,\nand `ARM options <https://gcc.gnu.org/onlinedocs/gcc/ARM-Options.html>`_.\n\n.. code-block:: bash\n\n     # Intel architectures\n     cmake -DARB_ARCH=broadwell        # broadwell with avx2\n     cmake -DARB_ARCH=skylake-avx512   # skylake with avx512 (Xeon server)\n     cmake -DARB_ARCH=knl              # Xeon Phi KNL\n\n     # ARM Arm8a\n     cmake -DARB_ARCH=armv8-a\n\n     # IBM Power8\n     cmake -DARB_ARCH=power8\n\n..  _install-vectorize:\n\nVectorization\n-------------\n\nExplicit vectorization of computational kernels can be enabled in Arbor by setting the\n``ARB_VECTORIZE`` CMake flag. This option is typically used in conjunction with the\n``ARB_ARCH`` option to specify the target architecture: without SIMD support in Arbor\nfor the architecture, enabling ``ARB_VECTORIZE`` will lead to a compilation error.\n\n.. code-block:: bash\n\n    cmake -DARB_VECTORIZE=ON -DARB_ARCH=native\n\nWith this flag set, the library will use architecture-specific vectorization intrinsics\nto implement these kernels. Arbor currently has vectorization support for x86 architectures\nwith AVX, AVX2 or AVX512 ISA extensions, and for ARM architectures with support for AArch64 NEON intrinsics (first available on ARMv8-A).\n\n.. _install-gpu:\n\nGPU backend\n-----------\n\nCompiling for the GPU backend is controlled by the ``ARB_GPU`` CMake option which is used to select between NVIDIA and AMD GPUs\nas well as specify the chosen GPU compiler.\n\n* ``none``: The default option. Disables the GPU backend.\n* ``cuda``: Enables the GPU backend for NVIDIA GPUs and compiles Arbor with nvcc (CUDA files), and the default C++ compiler (C++ files).\n* ``cuda-clang``: Enables the GPU backend for NVIDIA GPUs and compiles Arbor with clang.\n* ``hip``: Enables the experimental GPU backend for AMD GPUs and compiles Arbor with hipcc.\n\n**NVIDIA GPUs**:\n\nArbor supports NVIDIA GPUs using CUDA. Compiling Arbor for NVIDIA GPUs requires the CUDA Toolkit.\n\n.. code-block:: bash\n\n    cmake -DARB_GPU=cuda\n\n.. code-block:: bash\n\n    cmake -DARB_GPU=cuda-clang\n\nArbor is built for all supported NVIDIA GPUs and the available GPU will be used at runtime.\n\nDepending on the configuration of the system where Arbor is being built, the\nC++ compiler may not be able to find the ``cuda.h`` header when building for NIDIA GPUs.\nThe easiest workaround is to add the path to the include directory containing the header to the\n``CPATH`` environment variable before configuring and building Arbor, for\nexample:\n\n.. code-block:: bash\n\n    export CPATH=\"/opt/cuda/include:$CPATH\"\n    cmake -DARB_GPU=cuda\n\n\n**HIP GPUs**:\n\nArbor has experimental support for AMD GPUs using HIP. The only compiler currently supported is the non-release hip-clang (``hipcc``) compiler.\n(For instructions on how to build hipcc, refer to the\n`HIP documentation <https://github.com/ROCm-Developer-Tools/HIP/blob/master/INSTALL.md#hip-clang>`_).\n\n*CMake configuration for compiling Arbor with hipcc (CUDA and C++ files):*\n\n.. code-block:: bash\n\n    export CC=clang\n    export CXX=hipcc\n    cmake -DARB_GPU=hip\n\nArbor is built for all supported AMD GPUs and the available GPU will be used at runtime.\n\n.. Note::\n    Arbor supports and has been tested on Pascal (P100) and Volta (V100) NVIDIA GPUs,\n    as well as Mi50 and Mi60 AMD GPUs.\n\n\n.. _install-python:\n\nPython frontend\n----------------\n\nArbor can be used with a python frontend which is enabled by toggling the\nCMake ``ARB_WITH_PYTHON`` option:\n\n.. code-block:: bash\n\n    cmake -DARB_WITH_PYTHON=ON\n\nBy default ``ARB_WITH_PYTHON=OFF``. When this option is turned on, a Python module called :py:mod:`arbor` is built.\n\nA specific version of Python can be set when configuring with CMake using the\n``PYTHON_EXECUTABLE`` variable. For example, to use Python 3.8 installed on a Linux\nsystem with the executable in ``/usr/bin/python3.8``:\n\n.. code-block:: bash\n\n    cmake .. -DARB_WITH_PYTHON=ON -DPYTHON_EXECUTABLE=/usr/bin/python3.8\n\nBy default the Python module will be installed in the standard ``CMAKE_INSTALL_PREFIX``\nlocation. To install the module in a different location, for example as a\nuser module or in a virtual environment, set ``ARB_PYTHON_PREFIX``.\nFor example, the CMake configuration for targetting Python 3.8 and install as a\nuser site package might look like the following:\n\n.. code-block:: bash\n\n    cmake .. -DARB_WITH_PYTHON=ON                   \\\n             -DARB_PYTHON_PREFIX=${HOME}/.local     \\\n             -DPYTHON_EXECUTABLE=/user/bin/python3.8\n\nOn the target LINUX system, the Arbor package was installed in\n``/home/$USER/.local/lib/python3.8/site-packages``.\n\n.. Note::\n    By default CMake sets ``CMAKE_INSTALL_PREFIX`` to ``/usr/local`` on Linux and OS X.\n    The compiled libraries are installed in ``/usr/local/lib``, headers are installed in\n    ``/usr/local/include``, and the Python module will be installed in a path like\n    ``/usr/local/lib/python3.8/site-packages``.\n    Because ``/usr/local`` is a system path, the installation phase needs to be run as root,\n    i.e. ``sudo make install``, even if ``ARB_PYTHON_PREFIX`` is set to a user path\n    that does not require root to install.\n\nThe Arbor Python wrapper has optional support for the mpi4py, though\nit is not required to use Arbor with Python and MPI.\nCMake will attempt to automatically detect ``mpi4py`` if configured\nwith both ``-DARB_WITH_PYTHON=ON`` and MPI ``-DARB_WITH_MPI=ON``.\nIf CMake fails to find ``mpi4py`` when it should, the easiest workaround is to\nadd the path to the include directory for ``mpi4py`` to the ``CPATH`` environment\nvariable before configuring and building Arbor:\n\n.. code-block:: bash\n\n    # search for path tp python's site-package mpi4py\n    for p in `python3 -c 'import sys; print(\"\\n\".join(sys.path))'`; do echo ===== $p; ls $p | grep mpi4py; done\n\n    ===== /path/to/python3/site-packages\n    mpi4py\n\n    # set CPATH and run cmake\n    export CPATH=\"/path/to/python3/site-packages/mpi4py/include/:$CPATH\"\n\n    cmake -DARB_WITH_PYTHON=ON -DARB_WITH_MPI=ON\n\n.. _install-neuroml:\n\nNeuroML support\n---------------\n\nArbor has limited support for NeuroML version 2 through an additional library\n``arbornml``. This library will be built if the option ``-DARB_WITH_NEUROML=ON``\nis passed to CMake at configuration time. ``arbornml`` depends upon the\nthe ``libxml2`` library for XML parsing.\n\nWith NeuroML support enabled, Arbor will additionally install the static library\n``libarbornml.a``. Applications using this functionality will need to link\nagainst this library in addition to the main Arbor library and ``libxml2``.\nFor example:\n\n.. code-block:: bash\n\n    g++ -std=c++17 -pthread mycode.cpp -larbornml -larbor -lxml2\n\nFor projects using CMake, Arbor NeuroML support can be required with the\ncomponent ``neuroml``. The corresponding CMake library target is ``arbor::arbornml``.\n\n.. code-block:: cmake\n\n   find_package(arbor COMPONENTS neuroml)\n   # ...\n   target_link_libraries(myapp arbor::arbornml)\n\n\n.. _install:\n\nInstallation\n------------\n\nArbor can be installed with ``make install`` after configuration. The\ninstallation comprises:\n\n- The static libraries ``libarbor.a`` and ``libarborenv.a``.\n- Public header files.\n- The ``lmorpho`` l-system morphology generation utility\n- The ``modcc`` NMODL compiler if built.\n- The python module if built.\n- The HTML documentation if built.\n\nThe default install path (``/usr/local``) can be overridden with the\n``CMAKE_INSTALL_PREFIX`` configuration option.\n\nProvided that Sphinx is available, HTML documentation for Arbor can be built\nwith ``make html``. Note that documentation is not built by default \u2014 if\nbuilt, it too will be included in the installation.\n\nNote that the ``modcc`` compiler will not be built by default if the ``ARB_MODCC``\nconfiguration setting is used to specify a different executable for ``modcc``.\nWhile ``modcc`` can be used to translate user-supplied NMODL mechanism\ndescriptions into C++ and CUDA code for use with Arbor, this generated code\ncurrently relies upon private headers that are not installed.\n\n.. _cluster:\n\nHPC clusters\n============\n\nHPC clusters offer their own unique challenges when compiling and running\nsoftware, so we cover some common issues in this section. If you have problems\non your target system that are not covered here, please make an issue on the\nArbor `Github issues <https://github.com/arbor-sim/arbor/issues>`_ page.\nWe will do our best to help you directly, and update this guide to help other users.\n\n.. _install-mpi:\n\nMPI\n---\n\nArbor uses MPI for distributed systems. By default it is built without MPI support, which\ncan enabled by setting the ``ARB_WITH_MPI`` configuration flag.\nAn example of building a 'release' (optimized) version of Arbor with MPI is:\n\n.. code-block:: bash\n\n    # set the compiler wrappers\n    export CC=`which mpicc`\n    export CXX=`which mpicxx`\n\n    # configure with mpi\n    cmake -DARB_WITH_MPI=ON\n\n    # run MPI-specific unit tests on 2 MPI ranks\n    mpirun -n 2 ./bin/unit-mpi\n\nThe example above sets the ``CC`` and ``CXX`` environment variables to use compiler\nwrappers provided by the MPI implementation. While the configuration process\nwill attempt to find MPI libraries and build options automatically, we recommend\nusing the supplied MPI compiler wrappers in preference.\n\n.. Note::\n    MPI distributions provide **compiler wrappers** for compiling MPI applications.\n\n    In the example above the compiler wrappers for C and C++ called\n    ``mpicc`` and ``mpicxx`` respectively. The name of the compiler wrapper\n    is dependent on the MPI distribution.\n\n    The wrapper forwards the compilation to a compiler, like GCC, and\n    you have to ensure that this compiler is able to compile Arbor. For wrappers\n    that call GCC or Clang compilers, pass the ``--version`` flag\n    to the wrapper. For example, on a Cray system, where the C++ wrapper is called ``CC``:\n\n    .. code-block:: bash\n\n        $ CC --version\n        g++ (GCC) 6.2.0 20160822 (Cray Inc.)\n\nCray systems\n------------\n\nThe compiler used by the MPI wrappers is set using a \"programming environment\" module.\nThe first thing to do is change this module, which by default is set to the Cray\nprogramming environment, to a compiler that can compile Arbor.\nFor example, to use the GCC compilers, select the GNU programming environment:\n\n.. code-block:: bash\n\n    module swap PrgEnv-cray PrgEnv-gnu\n\nThe version of GCC can then be set by choosing an appropriate gcc module.\nIn the example below we use ``module avail`` to see which versions of GCC are available,\nthen choose GCC 7.1.0\n\n.. code-block:: bash\n\n    $ module avail gcc      # see all available gcc versions\n\n    ------------------------- /opt/modulefiles ---------------------------\n    gcc/4.9.3    gcc/6.1.0    gcc/7.1.0    gcc/5.3.0(default)    gcc/6.2.0\n\n    $ module swap gcc/7.1.0 # swap gcc 5.3.0 for 7.1.0\n\n    $ CC --version          # test that the wrapper uses gcc 7.1.0\n    g++ (GCC) 7.1.0 20170502 (Cray Inc.)\n\n    # set compiler wrappers\n    $ export CC=`which cc`\n    $ export CXX=`which CC`\n\nNote that the C and C++ compiler wrappers are called ``cc`` and ``CC``\nrespectively on Cray systems.\n\nCMake detects that it is being run in the Cray programming environment, which makes\nour lives a little bit more difficult (CMake sometimes tries a bit too hard to help).\nTo get CMake to correctly link our code, we need to set the ``CRAYPE_LINK_TYPE``\nenvironment variable to ``dynamic``.\n\n.. code-block:: bash\n\n    export CRAYPE_LINK_TYPE=dynamic\n\nPutting it all together, a typical workflow to build Arbor on a Cray system is:\n\n.. code-block:: bash\n\n    export CRAYPE_LINK_TYPE=dynamic\n    module swap PrgEnv-cray PrgEnv-gnu\n    module swap gcc/7.1.0\n    export CC=`which cc`; export CXX=`which CC`;\n    cmake -DARB_WITH_MPI=ON    # MPI support\n\n.. Note::\n    If ``CRAYPE_LINK_TYPE`` isn't set, there will be warnings like the following when linking:\n\n    .. code-block:: none\n\n        warning: Using 'dlopen' in statically linked applications requires at runtime\n                 the shared libraries from the glibc version used for linking\n\n    Often the library or executable will work, however if a different glibc is loaded,\n    Arbor will crash at runtime with obscure errors that are very difficult to debug.\n\n\n.. _troubleshooting:\n\nTroubleshooting\n===============\n\n.. _crosscompiling:\n\nCross compiling NMODL\n---------------------\n\nCare must be taken when Arbor is compiled on a system with a different\narchitecture to the target system where Arbor will run. This occurs quite\nfrequently on HPC systems, for example when building on a login/service node\nthat has a different architecture to the compute nodes.\n\n.. Note::\n    If building Arbor on a laptop or desktop system, i.e. on the same computer that\n    you will run Arbor on, cross compilation is not an issue.\n\n.. Note::\n    The ``ARB_ARCH`` setting is not applied to the building of ``modcc``.\n    On systems where the build node and compute node have different architectures\n    within the same family, this may mean that separate compilation of ``modcc``\n    is not necessary.\n\n.. Warning::\n    ``Illegal instruction`` errors are a sure sign that\n    Arbor is running on a system that does not support the architecture it was compiled for.\n\nWhen cross compiling, we have to take care that the *modcc* compiler, which is\nused to convert NMODL to C++/CUDA code, is able to run on the compilation node.\n\nBy default, building Arbor will build the ``modcc`` executable from source,\nand then use that to build the built-in mechanisms specified in NMODL. This\nbehaviour can be overridden with the ``ARB_MODCC`` configuration option, for\nexample:\n\n.. code-block:: bash\n\n   cmake -DARB_MODCC=path-to-local-modcc\n\nHere we will use the example of compiling for Intel KNL on a Cray system, which\nhas Intel Sandy Bridge CPUs on login nodes that don't support the AVX512\ninstructions used by KNL.\n\n.. code-block:: bash\n\n    #\n    #   Step 1: Build modcc.\n    #\n\n    module swap PrgEnv-cray PrgEnv-gnu\n    # Important: use GNU compilers directly, not the compiler wrappers,\n    # which generate code for KNL, not the login nodes.\n    export CC=`which gcc`; export CXX=`which g++`;\n    export CRAYPE_LINK_TYPE=dynamic\n\n    # make a path for the modcc build\n    mkdir build_modcc\n    cd build_modcc\n\n    # configure and make modcc\n    cmake ..\n    make -j modcc\n\n    #\n    #   Step 2: Build Arbor.\n    #\n\n    cd ..\n    mkdir build; cd build;\n    # use the compiler wrappers to build Arbor\n    export CC=`which cc`; export CXX=`which CC`;\n    cmake .. -DCMAKE_BUILD_TYPE=release           \\\n             -DARB_WITH_MPI=ON                    \\\n             -DARB_ARCH=knl                       \\\n             -DARB_VECTORIZE=ON                   \\\n             -DARB_MODCC=../build_modcc/bin/modcc\n\n\n.. Note::\n    Cross compilation issues can occur when there are minor differences between login and compute nodes, e.g.\n    when the login node has Intel Haswell, and the compute nodes have Intel Broadwell.\n\n    Other systems, such as IBM BGQ, have very different architectures for login and compute nodes.\n\n    If the *modcc* compiler was not compiled for the login node, illegal instruction errors will\n    occur when building, e.g.\n\n    .. code-block:: none\n\n        $ make\n        ...\n        [ 40%] modcc generating: /users/bcumming/arbor_knl/mechanisms/multicore/pas_cpu.hpp\n        /bin/sh: line 1: 12735 Illegal instruction     (core dumped) /users/bcumming/arbor_knl/build_modcc/modcc/modcc -t cpu -s\\ avx512 -o /users/bcumming/arbor_knl/mechanisms/multicore/pas /users/bcumming/arbor_knl/mechanisms/mod/pas.mod\n        mechanisms/CMakeFiles/build_all_mods.dir/build.make:69: recipe for target '../mechanisms/multicore/pas_cpu.hpp' failed\n\n    If you have errors when running the tests or a miniapp, then either the wrong\n    ``ARB_ARCH`` target architecture was selected; or you might have forgot to launch on the\n    compute node. e.g.:\n\n    .. code-block:: none\n\n        $ ./bin/unit\n        Illegal instruction (core dumped)\n\n    On the Cray KNL system, ``srun`` is used to launch (it might be ``mpirun``\n    or similar on your system):\n\n    .. code-block:: none\n\n        $ srun -n1 -c1 ./bin/unit\n        [==========] Running 609 tests from 108 test cases.\n        [----------] Global test environment set-up.\n        [----------] 15 tests from algorithms\n        [ RUN      ] algorithms.parallel_sort\n        [       OK ] algorithms.parallel_sort (15 ms)\n        [ RUN      ] algorithms.sum\n        [       OK ] algorithms.sum (0 ms)\n        ...\n\n\n.. _debugging:\n\nDebugging\n---------\n\nSometimes things go wrong: tests fail, simulations give strange results, segmentation\nfaults occur and exceptions are thrown.\n\nA good first step when things to wrong is to turn on additional assertions that can\ncatch errors. These are turned off by default (because they slow things down a lot),\nand have to be turned on by setting the ``ARB_WITH_ASSERTIONS`` CMake option:\n\n.. code-block:: bash\n\n    cmake -DARB_WITH_ASSERTIONS=ON\n\n.. Note::\n    These assertions are in the form of ``arb_assert`` macros inside the code,\n    for example:\n\n    .. code-block:: cpp\n\n        void decrement_min_remaining() {\n            arb_assert(min_remaining_steps_>0);\n            if (!--min_remaining_steps_) {\n                compute_min_remaining();\n            }\n        }\n\n    A failing ``arb_assert`` indicates that an error inside the Arbor\n    library, caused either by a logic error in Arbor, or incorrectly checked user input.\n\n    If this occurs, it is highly recommended that you attach the output to the\n    `bug report <https://github.com/arbor-sim/arbor/issues>`_ you send to the Arbor developers!\n\n\nCMake Git submodule warnings\n----------------------------\n\nWhen running CMake, warnings like the following indicate that the Git submodules\nneed to be `updated <install-downloading_>`_.\n\n.. code-block:: none\n\n    The Git submodule for rtdtheme is not available.\n    To check out all submodules use the following commands:\n        git submodule init\n        git submodule update\n    Or download submodules recursively when checking out:\n        git clone --recurse-submodules https://github.com/arbor-sim/arbor.git\n\n"
    },
    "skipped": [
        "/tmp/vanessa/spack-stage/spack-stage-arbor-0.4-ovxhu67m2j3bdrprc7jdkgwxxkag3y2b/spack-src/example/lfp/example_nrn_EP.png"
    ],
    "total_files": 840
}