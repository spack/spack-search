{
    "matches": {
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/configure.ac": "dnl \ndnl   This file is part of SST/macroscale: \ndnl                The macroscale architecture simulator from the SST suite.\ndnl   Copyright (c) 2009-2020, NTESS.\ndnl   This software is distributed under the BSD License.\ndnl   Under the terms of Contract DE-NA0003525 with NTESS,\ndnl   the U.S. Government retains certain rights in this software.\ndnl   For more information, see the LICENSE file in the top \ndnl   SST/macroscale directory.\ndnl\n\n#-------------------------------------------------\n  launch/launch_info.h  \\\n# Basic setup\n#-------------------------------------------------\n\n# Version info, used both in library versioning and inside sstmacro.\nm4_define([SSTMAC_VERSION_TAG], 10)\nm4_define([SSTMAC_SUBVERSION_TAG], 1)\nm4_define([SSTMAC_SUBSUBVERSION_TAG], 0)\n\ndnl Enable this for releases\ndnl m4_define([SSTMAC_SNAPSHOT_TAG])\ndnl Enable this for beta releases\ndnl m4_define([SSTMAC_SNAPSHOT_TAG],-beta1)\n# Enable this for development snapshots (should generally be enabled)\n#m4_define([SSTMAC_SNAPSHOT_TAG],-snapshot)\n\n# Construct the sstmacro version\nm4_define([SSTMAC_ACVERSION_TAG],\n          [SSTMAC_VERSION_TAG.SSTMAC_SUBVERSION_TAG.SSTMAC_SUBSUBVERSION_TAG])\n\ndnl AC_PREREQ([2.68]) avoid this if possible\nAC_INIT([sstmacro], [SSTMAC_ACVERSION_TAG], [sst-macro-help@sandia.gov])\nAC_CONFIG_MACRO_DIR([acinclude])\nAC_CONFIG_AUX_DIR(bin)\nAC_CONFIG_HEADERS(sstmac/common/config.h)\nAX_PREFIX_CONFIG_H(sstmac/common/sstmac_config.h, SSTMAC)\nAC_CANONICAL_TARGET\n\nif test \"X$prefix\" == \"XNONE\"; then\n  MY_PREFIX=$ac_default_prefix\nelse\n  MY_PREFIX=`cd $prefix ; pwd`\nfi\nMY_ABS_SRCPATH=`cd $srcdir ; pwd`\n\nAC_DEFINE_UNQUOTED([CONFIG_INSTALL_INCLUDE_PATH], \"$MY_PREFIX/include/sstmac/configurations\",\n                    [The include path for .ini configurations])\n\nAC_DEFINE_UNQUOTED([CONFIG_SRC_INCLUDE_PATH], \"$MY_ABS_SRCPATH/configurations\",\n                    [The include path for .ini configurations])\n\n# Construct the libtool version\ndnl Libtool library versioning is used to determine compatible libraries. A libtool version\ndnl consists of three numbers CURRENT:REVISION:AGE. These have the following meanings:\ndnl CURRENT:  The most recent interface number that this library implements.\ndnl REVISION: The implementation number of the current interface.\ndnl AGE:      The difference between the newest and oldest interfaces\ndnl           that this library implements. In other words, the\ndnl           library implements all the interface numbers in the\ndnl           range from number current - age to current.\ndnl For new releases the following procedure is used to determine the new version:\ndnl If incompatible changes are made: CURRENT++, REVISION=0, AGE=0\ndnl else if interfaces are added: CURRENT++, REVISION=0, AGE++\ndnl else (no interface changes): REVISION++\nm4_define([SSTMAC_CURRENT_LIBVERS],  10)\nm4_define([SSTMAC_REVISION_LIBVERS], 1)\nm4_define([SSTMAC_AGE_LIBVERS],      0)\nm4_define([SSTMAC_LIBVERSION_TAG],\n          [SSTMAC_CURRENT_LIBVERS:SSTMAC_REVISION_LIBVERS:SSTMAC_AGE_LIBVERS])\n\n# More version info.\nAH_TEMPLATE([VERSION], [Major version number])\nAH_TEMPLATE([SUBVERSION], [Major version number])\nAH_TEMPLATE([SUBSUBVERSION], [Major version number])\nAC_DEFINE_UNQUOTED(VERSION, [SSTMAC_VERSION_TAG])\nAC_DEFINE_UNQUOTED(SUBVERSION, [SSTMAC_SUBVERSION_TAG])\nAC_DEFINE_UNQUOTED(SUBSUBVERSION, [SSTMAC_SUBSUBVERSION_TAG])\nAC_SUBST(SSTMAC_LIBVERSION, [SSTMAC_LIBVERSION_TAG])\n\n# Init automake\nAM_INIT_AUTOMAKE([tar-pax -Wall -Werror foreign -Wno-portability subdir-objects])\nAM_PROG_AS\nm4_ifdef([AM_PROG_AR], [AM_PROG_AR])\nm4_ifdef([AM_SILENT_RULES], [AM_SILENT_RULES([yes])])\n\n#-------------------------------------------------\n# Environment \n#-------------------------------------------------\n\n# Find out if this is running Mac OS X.\ndarwin=false\ncase $target_os in\n  darwin*)  darwin=true ;;\nesac\nAM_CONDITIONAL([DARWIN],[test \"$darwin\" = true])\n\n# Before detecting compilers, we must see if a non-native DES core\n# will be used. If so, we try to use its compiler and flags.\n# Currently only supporting native DES.\nnat_des=yes # native DES\nsst_des=no  # SST/core DES\n\n\n\n# Check compilers and environment\ndnl AC_PROG_RANLIB\nAC_PROG_CC\nAC_PROG_CXX\nAC_PROG_FC\nAC_LANG_CPLUSPLUS\nAC_PROG_LIBTOOL\n\nLT_INIT([shared disable-static dlopen])\n\n#LT_INIT()\nLT_PREREQ([2.2.6])\nAC_PROG_LN_S\n\nCHECK_SDK()\n\nos=`$srcdir/bin/config_tools/get_os`\n\nif test \"X$os\" = \"Xubuntu\"; then\nLDFLAGS=\"$LDFLAGS -Wl,--no-as-needed\"\nAM_CONDITIONAL([HAVE_UBUNTU], [true])\nelse\nAM_CONDITIONAL([HAVE_UBUNTU], [false])\nfi\n\nCHECK_SST_CORE()\n\nCHECK_PYTHON()\n\nCHECK_DLOPEN()\n\nCHECK_SST_ELEMENTS()\n\nCHECK_CLANG()\n\nCHECK_GCC()\n\nCHECK_DEFAULT_INCLUDES()\n\nAC_CHECK_HEADERS([mpi.h],\n  have_mpi_header=yes,\n  have_mpi_header=no\n)\n\nCHECK_CXX_STD()\nif test \"X$have_integrated_core\" != \"Xyes\"; then\nCHECK_MPI_PARALLEL()\nfi\n\nCHECK_SPACK()\n\nAM_CONDITIONAL(HAVE_REGEXP, false)\n\n# Check what's available and what's requested for\n# thread context switching of applications\nCHECK_THREADING()\n\nCHECK_CUSTOM_NEW()\n\n# Check for whether to support event calendar optimizations\nCHECK_EVENT_CALENDAR()\n\n# MiniMD uses atomic builtins that may not be there.  We fake it if needed.  \nCHECK_ATOMICS()\n\n# Check what debugging features to enable\n# and what debugging features to disable for performance\nCHECK_DEBUG()\n\n# Define the default environment (serial,thread parallel,mpi parallel,etc)\nAH_TEMPLATE([DISTRIBUTED_MEMORY], [Define to indicate distributed memory])\nAH_TEMPLATE([DEFAULT_ENV_STRING], [Define to indicate default environment type (mpi/serial)])\nAH_TEMPLATE([DEFAULT_RUNTIME_STRING], [Define to indicate default runtime type (mpi/serial)])\nAH_TEMPLATE([DEFAULT_EVENT_MANAGER_STRING], [Define to indicate default event manager (event map/clock cycler)])\nAH_TEMPLATE([DEFAULT_PARTITION_STRING], [Define to indicate default partitioning strategy])\n\nCHECK_REPO_BUILD([sstmac])\n\nCHECK_OTF2()\n\nCHECK_VTK()\n\nCHECK_THREAD_PARALLEL()\n\n#CHECK_FORTRAN()\n\nCHECK_CALL_GRAPH_VIZ()\n\nCHECK_DOT()\n\nCHECK_INTEGER_TYPES()\n\nCHECK_STL_REPLACEMENT_HEADERS()\n\nCHECK_COMM_SYNC_STATS()\n\nCHECK_COMM_DELAY_STATS()\n\nCHECK_CLANG_LLVM()\n\nCHECK_WERROR()\n\nCHECK_WARNINGS()\n\n\n#-------------------------------------------------\n# Configure subdirs\n#-------------------------------------------------\n\n# Configure dumpi.\nAC_CONFIG_SUBDIRS([sst-dumpi])\n\n\n#-------------------------------------------------\n# Finalize \n#-------------------------------------------------\n\ndnl Don't reorder options.\ndnl AC_PRESERVE_HELP_ORDER\n\nAC_CONFIG_FILES([\n Makefile\n sstmac/Makefile\n sstmac/install/Makefile\n sstmac/dumpi_util/Makefile\n sstmac/libraries/blas/Makefile\n sstmac/libraries/pthread/Makefile\n sstmac/libraries/omp/Makefile\n sstmac/libraries/machines/Makefile\n sstmac/libraries/Makefile\n sstmac/skeletons/Makefile\n sstmac/test_skeletons/Makefile\n sstmac/software/Makefile\n sstmac/hardware/Makefile\n sstmac/sst_core/Makefile\n sstmac/backends/Makefile\n sstmac/backends/common/Makefile\n sstmac/backends/native/Makefile\n sstmac/backends/mpi/Makefile\n sstmac/main/Makefile\n sstmac/common/Makefile\n sstmac/replacements/Makefile\n sstmac/clang_replacements/Makefile\n sprockit/Makefile\n sprockit/sprockit/Makefile\n sprockit/test/Makefile\n bin/Makefile\n include/Makefile\n python/Makefile\n configurations/Makefile\n tests/Makefile\n tests/external/Makefile\n tests/sumi/Makefile\n tests/api/mpi/Makefile\n tests/api/globals/Makefile\n docs/doxygen.cfg\n share/Makefile\n share/SSTMacroConfig.cmake\n sumi-mpi/Makefile\n sumi/Makefile\n])\n\nAC_CONFIG_FILES([bin/sstmacro-config], [chmod +x bin/sstmacro-config])\nAC_CONFIG_FILES([bin/sst++], [chmod +x bin/sst++])\nAC_CONFIG_FILES([bin/sstcc], [chmod +x bin/sstcc])\nAC_CONFIG_FILES([bin/sstccvars.py])\nAC_CONFIG_FILES([tests/runtest], [chmod +x tests/runtest])\nAC_CONFIG_FILES([tests/noop], [chmod +x tests/noop])\nAC_CONFIG_FILES([tests/checktest], [chmod +x tests/checktest])\nAC_CONFIG_FILES([tests/checkdiff], [chmod +x tests/checkdiff])\n\nAC_OUTPUT\n\nif test \"X$with_mpiparallel\" = \"Xtrue\"; then\n  yesno_mpiparallel=\"yes\"\nelse\n  yesno_mpiparallel=\"no\"\nfi\n\n# --------- Print out a configuration summary. ---------\necho\necho \"SST Macroscale Configuration Summary:\"\necho \"---------------------------------------------------------------\"\necho \"Install prefix     $prefix\"\necho \"OS                 $os\"\necho \"C compiler         $CC\"\necho \"C++ compiler       $CXX\"\necho \"CFLAGS             $CFLAGS\"\necho \"CXXFLAGS           $CXXFLAGS $SST_CXXFLAGS $STD_CXXFLAGS\"\necho \"CPPFLAGS           $CPPFLAGS\"\necho \"LDFLAGS            $LDFLAGS\"\necho \"C++ Standard       $cxxstd\"\necho\n\necho \"User Space Threading:\"\necho \"  GNU Pth          $enable_pth\"\necho \"  Pthread          $enable_pthread\"\necho \"  Ucontext         $enable_ucontext\"\necho \"  Fcontext         Auto-included\"\necho\n\necho \"Parallel Discrete Event Simulation:\"\necho \"  MPI PDES         $yesno_mpiparallel\"\necho \"  Multithreaded    $with_multithread\"\necho \"  Spinlock         $with_spinlock\"\necho \"  Thread Affinity  $with_cpu_affinity\"\necho\n\necho \"MAC SDK            $enable_sdk\"\necho \"SST Core           $have_integrated_core\"\necho \"Python             $pyexe\"\necho \"Clang Autoskeleton $found_clang\"\necho \"OTF2 Replay        $build_otf2\"\necho \"MPI Sync Stats     $with_comm_sync_stats\"\necho \"Call Graph Viz     $enable_call_graph\"\necho \"Sanity Checking    $enable_sanity_check\"\nif test -z \"$vtk_path\"; then\necho \"VTK                no\"\nelse\necho \"VTK                $vtk_version @ $vtk_path\"\nfi\n\necho \"---------------------------------------------------------------\"\n\n",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/tests/test_autotools/m4/libtool.m4": "# libtool.m4 - Configure libtool for the host system. -*-Autoconf-*-\n#\n#   Copyright (C) 1996-2001, 2003-2015 Free Software Foundation, Inc.\n#   Written by Gordon Matzigkeit, 1996\n#\n# This file is free software; the Free Software Foundation gives\n# unlimited permission to copy and/or distribute it, with or without\n# modifications, as long as this notice is preserved.\n\nm4_define([_LT_COPYING], [dnl\n# Copyright (C) 2014 Free Software Foundation, Inc.\n# This is free software; see the source for copying conditions.  There is NO\n# warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\n# GNU Libtool is free software; you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation; either version 2 of of the License, or\n# (at your option) any later version.\n#\n# As a special exception to the GNU General Public License, if you\n# distribute this file as part of a program or library that is built\n# using GNU Libtool, you may include this file under the  same\n# distribution terms that you use for the rest of that program.\n#\n# GNU Libtool is distributed in the hope that it will be useful, but\n# WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program.  If not, see <http://www.gnu.org/licenses/>.\n])\n\n# serial 58 LT_INIT\n\n\n# LT_PREREQ(VERSION)\n# ------------------\n# Complain and exit if this libtool version is less that VERSION.\nm4_defun([LT_PREREQ],\n[m4_if(m4_version_compare(m4_defn([LT_PACKAGE_VERSION]), [$1]), -1,\n       [m4_default([$3],\n\t\t   [m4_fatal([Libtool version $1 or higher is required],\n\t\t             63)])],\n       [$2])])\n\n\n# _LT_CHECK_BUILDDIR\n# ------------------\n# Complain if the absolute build directory name contains unusual characters\nm4_defun([_LT_CHECK_BUILDDIR],\n[case `pwd` in\n  *\\ * | *\\\t*)\n    AC_MSG_WARN([Libtool does not cope well with whitespace in `pwd`]) ;;\nesac\n])\n\n\n# LT_INIT([OPTIONS])\n# ------------------\nAC_DEFUN([LT_INIT],\n[AC_PREREQ([2.62])dnl We use AC_PATH_PROGS_FEATURE_CHECK\nAC_REQUIRE([AC_CONFIG_AUX_DIR_DEFAULT])dnl\nAC_BEFORE([$0], [LT_LANG])dnl\nAC_BEFORE([$0], [LT_OUTPUT])dnl\nAC_BEFORE([$0], [LTDL_INIT])dnl\nm4_require([_LT_CHECK_BUILDDIR])dnl\n\ndnl Autoconf doesn't catch unexpanded LT_ macros by default:\nm4_pattern_forbid([^_?LT_[A-Z_]+$])dnl\nm4_pattern_allow([^(_LT_EOF|LT_DLGLOBAL|LT_DLLAZY_OR_NOW|LT_MULTI_MODULE)$])dnl\ndnl aclocal doesn't pull ltoptions.m4, ltsugar.m4, or ltversion.m4\ndnl unless we require an AC_DEFUNed macro:\nAC_REQUIRE([LTOPTIONS_VERSION])dnl\nAC_REQUIRE([LTSUGAR_VERSION])dnl\nAC_REQUIRE([LTVERSION_VERSION])dnl\nAC_REQUIRE([LTOBSOLETE_VERSION])dnl\nm4_require([_LT_PROG_LTMAIN])dnl\n\n_LT_SHELL_INIT([SHELL=${CONFIG_SHELL-/bin/sh}])\n\ndnl Parse OPTIONS\n_LT_SET_OPTIONS([$0], [$1])\n\n# This can be used to rebuild libtool when needed\nLIBTOOL_DEPS=$ltmain\n\n# Always use our own libtool.\nLIBTOOL='$(SHELL) $(top_builddir)/libtool'\nAC_SUBST(LIBTOOL)dnl\n\n_LT_SETUP\n\n# Only expand once:\nm4_define([LT_INIT])\n])# LT_INIT\n\n# Old names:\nAU_ALIAS([AC_PROG_LIBTOOL], [LT_INIT])\nAU_ALIAS([AM_PROG_LIBTOOL], [LT_INIT])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_PROG_LIBTOOL], [])\ndnl AC_DEFUN([AM_PROG_LIBTOOL], [])\n\n\n# _LT_PREPARE_CC_BASENAME\n# -----------------------\nm4_defun([_LT_PREPARE_CC_BASENAME], [\n# Calculate cc_basename.  Skip known compiler wrappers and cross-prefix.\nfunc_cc_basename ()\n{\n    for cc_temp in @S|@*\"\"; do\n      case $cc_temp in\n        compile | *[[\\\\/]]compile | ccache | *[[\\\\/]]ccache ) ;;\n        distcc | *[[\\\\/]]distcc | purify | *[[\\\\/]]purify ) ;;\n        \\-*) ;;\n        *) break;;\n      esac\n    done\n    func_cc_basename_result=`$ECHO \"$cc_temp\" | $SED \"s%.*/%%; s%^$host_alias-%%\"`\n}\n])# _LT_PREPARE_CC_BASENAME\n\n\n# _LT_CC_BASENAME(CC)\n# -------------------\n# It would be clearer to call AC_REQUIREs from _LT_PREPARE_CC_BASENAME,\n# but that macro is also expanded into generated libtool script, which\n# arranges for $SED and $ECHO to be set by different means.\nm4_defun([_LT_CC_BASENAME],\n[m4_require([_LT_PREPARE_CC_BASENAME])dnl\nAC_REQUIRE([_LT_DECL_SED])dnl\nAC_REQUIRE([_LT_PROG_ECHO_BACKSLASH])dnl\nfunc_cc_basename $1\ncc_basename=$func_cc_basename_result\n])\n\n\n# _LT_FILEUTILS_DEFAULTS\n# ----------------------\n# It is okay to use these file commands and assume they have been set\n# sensibly after 'm4_require([_LT_FILEUTILS_DEFAULTS])'.\nm4_defun([_LT_FILEUTILS_DEFAULTS],\n[: ${CP=\"cp -f\"}\n: ${MV=\"mv -f\"}\n: ${RM=\"rm -f\"}\n])# _LT_FILEUTILS_DEFAULTS\n\n\n# _LT_SETUP\n# ---------\nm4_defun([_LT_SETUP],\n[AC_REQUIRE([AC_CANONICAL_HOST])dnl\nAC_REQUIRE([AC_CANONICAL_BUILD])dnl\nAC_REQUIRE([_LT_PREPARE_SED_QUOTE_VARS])dnl\nAC_REQUIRE([_LT_PROG_ECHO_BACKSLASH])dnl\n\n_LT_DECL([], [PATH_SEPARATOR], [1], [The PATH separator for the build system])dnl\ndnl\n_LT_DECL([], [host_alias], [0], [The host system])dnl\n_LT_DECL([], [host], [0])dnl\n_LT_DECL([], [host_os], [0])dnl\ndnl\n_LT_DECL([], [build_alias], [0], [The build system])dnl\n_LT_DECL([], [build], [0])dnl\n_LT_DECL([], [build_os], [0])dnl\ndnl\nAC_REQUIRE([AC_PROG_CC])dnl\nAC_REQUIRE([LT_PATH_LD])dnl\nAC_REQUIRE([LT_PATH_NM])dnl\ndnl\nAC_REQUIRE([AC_PROG_LN_S])dnl\ntest -z \"$LN_S\" && LN_S=\"ln -s\"\n_LT_DECL([], [LN_S], [1], [Whether we need soft or hard links])dnl\ndnl\nAC_REQUIRE([LT_CMD_MAX_LEN])dnl\n_LT_DECL([objext], [ac_objext], [0], [Object file suffix (normally \"o\")])dnl\n_LT_DECL([], [exeext], [0], [Executable file suffix (normally \"\")])dnl\ndnl\nm4_require([_LT_FILEUTILS_DEFAULTS])dnl\nm4_require([_LT_CHECK_SHELL_FEATURES])dnl\nm4_require([_LT_PATH_CONVERSION_FUNCTIONS])dnl\nm4_require([_LT_CMD_RELOAD])dnl\nm4_require([_LT_CHECK_MAGIC_METHOD])dnl\nm4_require([_LT_CHECK_SHAREDLIB_FROM_LINKLIB])dnl\nm4_require([_LT_CMD_OLD_ARCHIVE])dnl\nm4_require([_LT_CMD_GLOBAL_SYMBOLS])dnl\nm4_require([_LT_WITH_SYSROOT])dnl\nm4_require([_LT_CMD_TRUNCATE])dnl\n\n_LT_CONFIG_LIBTOOL_INIT([\n# See if we are running on zsh, and set the options that allow our\n# commands through without removal of \\ escapes INIT.\nif test -n \"\\${ZSH_VERSION+set}\"; then\n   setopt NO_GLOB_SUBST\nfi\n])\nif test -n \"${ZSH_VERSION+set}\"; then\n   setopt NO_GLOB_SUBST\nfi\n\n_LT_CHECK_OBJDIR\n\nm4_require([_LT_TAG_COMPILER])dnl\n\ncase $host_os in\naix3*)\n  # AIX sometimes has problems with the GCC collect2 program.  For some\n  # reason, if we set the COLLECT_NAMES environment variable, the problems\n  # vanish in a puff of smoke.\n  if test set != \"${COLLECT_NAMES+set}\"; then\n    COLLECT_NAMES=\n    export COLLECT_NAMES\n  fi\n  ;;\nesac\n\n# Global variables:\nofile=libtool\ncan_build_shared=yes\n\n# All known linkers require a '.a' archive for static linking (except MSVC,\n# which needs '.lib').\nlibext=a\n\nwith_gnu_ld=$lt_cv_prog_gnu_ld\n\nold_CC=$CC\nold_CFLAGS=$CFLAGS\n\n# Set sane defaults for various variables\ntest -z \"$CC\" && CC=cc\ntest -z \"$LTCC\" && LTCC=$CC\ntest -z \"$LTCFLAGS\" && LTCFLAGS=$CFLAGS\ntest -z \"$LD\" && LD=ld\ntest -z \"$ac_objext\" && ac_objext=o\n\n_LT_CC_BASENAME([$compiler])\n\n# Only perform the check for file, if the check method requires it\ntest -z \"$MAGIC_CMD\" && MAGIC_CMD=file\ncase $deplibs_check_method in\nfile_magic*)\n  if test \"$file_magic_cmd\" = '$MAGIC_CMD'; then\n    _LT_PATH_MAGIC\n  fi\n  ;;\nesac\n\n# Use C for the default configuration in the libtool script\nLT_SUPPORTED_TAG([CC])\n_LT_LANG_C_CONFIG\n_LT_LANG_DEFAULT_CONFIG\n_LT_CONFIG_COMMANDS\n])# _LT_SETUP\n\n\n# _LT_PREPARE_SED_QUOTE_VARS\n# --------------------------\n# Define a few sed substitution that help us do robust quoting.\nm4_defun([_LT_PREPARE_SED_QUOTE_VARS],\n[# Backslashify metacharacters that are still active within\n# double-quoted strings.\nsed_quote_subst='s/\\([[\"`$\\\\]]\\)/\\\\\\1/g'\n\n# Same as above, but do not quote variable references.\ndouble_quote_subst='s/\\([[\"`\\\\]]\\)/\\\\\\1/g'\n\n# Sed substitution to delay expansion of an escaped shell variable in a\n# double_quote_subst'ed string.\ndelay_variable_subst='s/\\\\\\\\\\\\\\\\\\\\\\$/\\\\\\\\\\\\$/g'\n\n# Sed substitution to delay expansion of an escaped single quote.\ndelay_single_quote_subst='s/'\\''/'\\'\\\\\\\\\\\\\\'\\''/g'\n\n# Sed substitution to avoid accidental globbing in evaled expressions\nno_glob_subst='s/\\*/\\\\\\*/g'\n])\n\n# _LT_PROG_LTMAIN\n# ---------------\n# Note that this code is called both from 'configure', and 'config.status'\n# now that we use AC_CONFIG_COMMANDS to generate libtool.  Notably,\n# 'config.status' has no value for ac_aux_dir unless we are using Automake,\n# so we pass a copy along to make sure it has a sensible value anyway.\nm4_defun([_LT_PROG_LTMAIN],\n[m4_ifdef([AC_REQUIRE_AUX_FILE], [AC_REQUIRE_AUX_FILE([ltmain.sh])])dnl\n_LT_CONFIG_LIBTOOL_INIT([ac_aux_dir='$ac_aux_dir'])\nltmain=$ac_aux_dir/ltmain.sh\n])# _LT_PROG_LTMAIN\n\n\n## ------------------------------------- ##\n## Accumulate code for creating libtool. ##\n## ------------------------------------- ##\n\n# So that we can recreate a full libtool script including additional\n# tags, we accumulate the chunks of code to send to AC_CONFIG_COMMANDS\n# in macros and then make a single call at the end using the 'libtool'\n# label.\n\n\n# _LT_CONFIG_LIBTOOL_INIT([INIT-COMMANDS])\n# ----------------------------------------\n# Register INIT-COMMANDS to be passed to AC_CONFIG_COMMANDS later.\nm4_define([_LT_CONFIG_LIBTOOL_INIT],\n[m4_ifval([$1],\n          [m4_append([_LT_OUTPUT_LIBTOOL_INIT],\n                     [$1\n])])])\n\n# Initialize.\nm4_define([_LT_OUTPUT_LIBTOOL_INIT])\n\n\n# _LT_CONFIG_LIBTOOL([COMMANDS])\n# ------------------------------\n# Register COMMANDS to be passed to AC_CONFIG_COMMANDS later.\nm4_define([_LT_CONFIG_LIBTOOL],\n[m4_ifval([$1],\n          [m4_append([_LT_OUTPUT_LIBTOOL_COMMANDS],\n                     [$1\n])])])\n\n# Initialize.\nm4_define([_LT_OUTPUT_LIBTOOL_COMMANDS])\n\n\n# _LT_CONFIG_SAVE_COMMANDS([COMMANDS], [INIT_COMMANDS])\n# -----------------------------------------------------\nm4_defun([_LT_CONFIG_SAVE_COMMANDS],\n[_LT_CONFIG_LIBTOOL([$1])\n_LT_CONFIG_LIBTOOL_INIT([$2])\n])\n\n\n# _LT_FORMAT_COMMENT([COMMENT])\n# -----------------------------\n# Add leading comment marks to the start of each line, and a trailing\n# full-stop to the whole comment if one is not present already.\nm4_define([_LT_FORMAT_COMMENT],\n[m4_ifval([$1], [\nm4_bpatsubst([m4_bpatsubst([$1], [^ *], [# ])],\n              [['`$\\]], [\\\\\\&])]m4_bmatch([$1], [[!?.]$], [], [.])\n)])\n\n\n\n## ------------------------ ##\n## FIXME: Eliminate VARNAME ##\n## ------------------------ ##\n\n\n# _LT_DECL([CONFIGNAME], VARNAME, VALUE, [DESCRIPTION], [IS-TAGGED?])\n# -------------------------------------------------------------------\n# CONFIGNAME is the name given to the value in the libtool script.\n# VARNAME is the (base) name used in the configure script.\n# VALUE may be 0, 1 or 2 for a computed quote escaped value based on\n# VARNAME.  Any other value will be used directly.\nm4_define([_LT_DECL],\n[lt_if_append_uniq([lt_decl_varnames], [$2], [, ],\n    [lt_dict_add_subkey([lt_decl_dict], [$2], [libtool_name],\n\t[m4_ifval([$1], [$1], [$2])])\n    lt_dict_add_subkey([lt_decl_dict], [$2], [value], [$3])\n    m4_ifval([$4],\n\t[lt_dict_add_subkey([lt_decl_dict], [$2], [description], [$4])])\n    lt_dict_add_subkey([lt_decl_dict], [$2],\n\t[tagged?], [m4_ifval([$5], [yes], [no])])])\n])\n\n\n# _LT_TAGDECL([CONFIGNAME], VARNAME, VALUE, [DESCRIPTION])\n# --------------------------------------------------------\nm4_define([_LT_TAGDECL], [_LT_DECL([$1], [$2], [$3], [$4], [yes])])\n\n\n# lt_decl_tag_varnames([SEPARATOR], [VARNAME1...])\n# ------------------------------------------------\nm4_define([lt_decl_tag_varnames],\n[_lt_decl_filter([tagged?], [yes], $@)])\n\n\n# _lt_decl_filter(SUBKEY, VALUE, [SEPARATOR], [VARNAME1..])\n# ---------------------------------------------------------\nm4_define([_lt_decl_filter],\n[m4_case([$#],\n  [0], [m4_fatal([$0: too few arguments: $#])],\n  [1], [m4_fatal([$0: too few arguments: $#: $1])],\n  [2], [lt_dict_filter([lt_decl_dict], [$1], [$2], [], lt_decl_varnames)],\n  [3], [lt_dict_filter([lt_decl_dict], [$1], [$2], [$3], lt_decl_varnames)],\n  [lt_dict_filter([lt_decl_dict], $@)])[]dnl\n])\n\n\n# lt_decl_quote_varnames([SEPARATOR], [VARNAME1...])\n# --------------------------------------------------\nm4_define([lt_decl_quote_varnames],\n[_lt_decl_filter([value], [1], $@)])\n\n\n# lt_decl_dquote_varnames([SEPARATOR], [VARNAME1...])\n# ---------------------------------------------------\nm4_define([lt_decl_dquote_varnames],\n[_lt_decl_filter([value], [2], $@)])\n\n\n# lt_decl_varnames_tagged([SEPARATOR], [VARNAME1...])\n# ---------------------------------------------------\nm4_define([lt_decl_varnames_tagged],\n[m4_assert([$# <= 2])dnl\n_$0(m4_quote(m4_default([$1], [[, ]])),\n    m4_ifval([$2], [[$2]], [m4_dquote(lt_decl_tag_varnames)]),\n    m4_split(m4_normalize(m4_quote(_LT_TAGS)), [ ]))])\nm4_define([_lt_decl_varnames_tagged],\n[m4_ifval([$3], [lt_combine([$1], [$2], [_], $3)])])\n\n\n# lt_decl_all_varnames([SEPARATOR], [VARNAME1...])\n# ------------------------------------------------\nm4_define([lt_decl_all_varnames],\n[_$0(m4_quote(m4_default([$1], [[, ]])),\n     m4_if([$2], [],\n\t   m4_quote(lt_decl_varnames),\n\tm4_quote(m4_shift($@))))[]dnl\n])\nm4_define([_lt_decl_all_varnames],\n[lt_join($@, lt_decl_varnames_tagged([$1],\n\t\t\tlt_decl_tag_varnames([[, ]], m4_shift($@))))dnl\n])\n\n\n# _LT_CONFIG_STATUS_DECLARE([VARNAME])\n# ------------------------------------\n# Quote a variable value, and forward it to 'config.status' so that its\n# declaration there will have the same value as in 'configure'.  VARNAME\n# must have a single quote delimited value for this to work.\nm4_define([_LT_CONFIG_STATUS_DECLARE],\n[$1='`$ECHO \"$][$1\" | $SED \"$delay_single_quote_subst\"`'])\n\n\n# _LT_CONFIG_STATUS_DECLARATIONS\n# ------------------------------\n# We delimit libtool config variables with single quotes, so when\n# we write them to config.status, we have to be sure to quote all\n# embedded single quotes properly.  In configure, this macro expands\n# each variable declared with _LT_DECL (and _LT_TAGDECL) into:\n#\n#    <var>='`$ECHO \"$<var>\" | $SED \"$delay_single_quote_subst\"`'\nm4_defun([_LT_CONFIG_STATUS_DECLARATIONS],\n[m4_foreach([_lt_var], m4_quote(lt_decl_all_varnames),\n    [m4_n([_LT_CONFIG_STATUS_DECLARE(_lt_var)])])])\n\n\n# _LT_LIBTOOL_TAGS\n# ----------------\n# Output comment and list of tags supported by the script\nm4_defun([_LT_LIBTOOL_TAGS],\n[_LT_FORMAT_COMMENT([The names of the tagged configurations supported by this script])dnl\navailable_tags='_LT_TAGS'dnl\n])\n\n\n# _LT_LIBTOOL_DECLARE(VARNAME, [TAG])\n# -----------------------------------\n# Extract the dictionary values for VARNAME (optionally with TAG) and\n# expand to a commented shell variable setting:\n#\n#    # Some comment about what VAR is for.\n#    visible_name=$lt_internal_name\nm4_define([_LT_LIBTOOL_DECLARE],\n[_LT_FORMAT_COMMENT(m4_quote(lt_dict_fetch([lt_decl_dict], [$1],\n\t\t\t\t\t   [description])))[]dnl\nm4_pushdef([_libtool_name],\n    m4_quote(lt_dict_fetch([lt_decl_dict], [$1], [libtool_name])))[]dnl\nm4_case(m4_quote(lt_dict_fetch([lt_decl_dict], [$1], [value])),\n    [0], [_libtool_name=[$]$1],\n    [1], [_libtool_name=$lt_[]$1],\n    [2], [_libtool_name=$lt_[]$1],\n    [_libtool_name=lt_dict_fetch([lt_decl_dict], [$1], [value])])[]dnl\nm4_ifval([$2], [_$2])[]m4_popdef([_libtool_name])[]dnl\n])\n\n\n# _LT_LIBTOOL_CONFIG_VARS\n# -----------------------\n# Produce commented declarations of non-tagged libtool config variables\n# suitable for insertion in the LIBTOOL CONFIG section of the 'libtool'\n# script.  Tagged libtool config variables (even for the LIBTOOL CONFIG\n# section) are produced by _LT_LIBTOOL_TAG_VARS.\nm4_defun([_LT_LIBTOOL_CONFIG_VARS],\n[m4_foreach([_lt_var],\n    m4_quote(_lt_decl_filter([tagged?], [no], [], lt_decl_varnames)),\n    [m4_n([_LT_LIBTOOL_DECLARE(_lt_var)])])])\n\n\n# _LT_LIBTOOL_TAG_VARS(TAG)\n# -------------------------\nm4_define([_LT_LIBTOOL_TAG_VARS],\n[m4_foreach([_lt_var], m4_quote(lt_decl_tag_varnames),\n    [m4_n([_LT_LIBTOOL_DECLARE(_lt_var, [$1])])])])\n\n\n# _LT_TAGVAR(VARNAME, [TAGNAME])\n# ------------------------------\nm4_define([_LT_TAGVAR], [m4_ifval([$2], [$1_$2], [$1])])\n\n\n# _LT_CONFIG_COMMANDS\n# -------------------\n# Send accumulated output to $CONFIG_STATUS.  Thanks to the lists of\n# variables for single and double quote escaping we saved from calls\n# to _LT_DECL, we can put quote escaped variables declarations\n# into 'config.status', and then the shell code to quote escape them in\n# for loops in 'config.status'.  Finally, any additional code accumulated\n# from calls to _LT_CONFIG_LIBTOOL_INIT is expanded.\nm4_defun([_LT_CONFIG_COMMANDS],\n[AC_PROVIDE_IFELSE([LT_OUTPUT],\n\tdnl If the libtool generation code has been placed in $CONFIG_LT,\n\tdnl instead of duplicating it all over again into config.status,\n\tdnl then we will have config.status run $CONFIG_LT later, so it\n\tdnl needs to know what name is stored there:\n        [AC_CONFIG_COMMANDS([libtool],\n            [$SHELL $CONFIG_LT || AS_EXIT(1)], [CONFIG_LT='$CONFIG_LT'])],\n    dnl If the libtool generation code is destined for config.status,\n    dnl expand the accumulated commands and init code now:\n    [AC_CONFIG_COMMANDS([libtool],\n        [_LT_OUTPUT_LIBTOOL_COMMANDS], [_LT_OUTPUT_LIBTOOL_COMMANDS_INIT])])\n])#_LT_CONFIG_COMMANDS\n\n\n# Initialize.\nm4_define([_LT_OUTPUT_LIBTOOL_COMMANDS_INIT],\n[\n\n# The HP-UX ksh and POSIX shell print the target directory to stdout\n# if CDPATH is set.\n(unset CDPATH) >/dev/null 2>&1 && unset CDPATH\n\nsed_quote_subst='$sed_quote_subst'\ndouble_quote_subst='$double_quote_subst'\ndelay_variable_subst='$delay_variable_subst'\n_LT_CONFIG_STATUS_DECLARATIONS\nLTCC='$LTCC'\nLTCFLAGS='$LTCFLAGS'\ncompiler='$compiler_DEFAULT'\n\n# A function that is used when there is no print builtin or printf.\nfunc_fallback_echo ()\n{\n  eval 'cat <<_LTECHO_EOF\n\\$[]1\n_LTECHO_EOF'\n}\n\n# Quote evaled strings.\nfor var in lt_decl_all_varnames([[ \\\n]], lt_decl_quote_varnames); do\n    case \\`eval \\\\\\\\\\$ECHO \\\\\\\\\"\"\\\\\\\\\\$\\$var\"\\\\\\\\\"\\` in\n    *[[\\\\\\\\\\\\\\`\\\\\"\\\\\\$]]*)\n      eval \"lt_\\$var=\\\\\\\\\\\\\"\\\\\\`\\\\\\$ECHO \\\\\"\\\\\\$\\$var\\\\\" | \\\\\\$SED \\\\\"\\\\\\$sed_quote_subst\\\\\"\\\\\\`\\\\\\\\\\\\\"\" ## exclude from sc_prohibit_nested_quotes\n      ;;\n    *)\n      eval \"lt_\\$var=\\\\\\\\\\\\\"\\\\\\$\\$var\\\\\\\\\\\\\"\"\n      ;;\n    esac\ndone\n\n# Double-quote double-evaled strings.\nfor var in lt_decl_all_varnames([[ \\\n]], lt_decl_dquote_varnames); do\n    case \\`eval \\\\\\\\\\$ECHO \\\\\\\\\"\"\\\\\\\\\\$\\$var\"\\\\\\\\\"\\` in\n    *[[\\\\\\\\\\\\\\`\\\\\"\\\\\\$]]*)\n      eval \"lt_\\$var=\\\\\\\\\\\\\"\\\\\\`\\\\\\$ECHO \\\\\"\\\\\\$\\$var\\\\\" | \\\\\\$SED -e \\\\\"\\\\\\$double_quote_subst\\\\\" -e \\\\\"\\\\\\$sed_quote_subst\\\\\" -e \\\\\"\\\\\\$delay_variable_subst\\\\\"\\\\\\`\\\\\\\\\\\\\"\" ## exclude from sc_prohibit_nested_quotes\n      ;;\n    *)\n      eval \"lt_\\$var=\\\\\\\\\\\\\"\\\\\\$\\$var\\\\\\\\\\\\\"\"\n      ;;\n    esac\ndone\n\n_LT_OUTPUT_LIBTOOL_INIT\n])\n\n# _LT_GENERATED_FILE_INIT(FILE, [COMMENT])\n# ------------------------------------\n# Generate a child script FILE with all initialization necessary to\n# reuse the environment learned by the parent script, and make the\n# file executable.  If COMMENT is supplied, it is inserted after the\n# '#!' sequence but before initialization text begins.  After this\n# macro, additional text can be appended to FILE to form the body of\n# the child script.  The macro ends with non-zero status if the\n# file could not be fully written (such as if the disk is full).\nm4_ifdef([AS_INIT_GENERATED],\n[m4_defun([_LT_GENERATED_FILE_INIT],[AS_INIT_GENERATED($@)])],\n[m4_defun([_LT_GENERATED_FILE_INIT],\n[m4_require([AS_PREPARE])]dnl\n[m4_pushdef([AS_MESSAGE_LOG_FD])]dnl\n[lt_write_fail=0\ncat >$1 <<_ASEOF || lt_write_fail=1\n#! $SHELL\n# Generated by $as_me.\n$2\nSHELL=\\${CONFIG_SHELL-$SHELL}\nexport SHELL\n_ASEOF\ncat >>$1 <<\\_ASEOF || lt_write_fail=1\nAS_SHELL_SANITIZE\n_AS_PREPARE\nexec AS_MESSAGE_FD>&1\n_ASEOF\ntest 0 = \"$lt_write_fail\" && chmod +x $1[]dnl\nm4_popdef([AS_MESSAGE_LOG_FD])])])# _LT_GENERATED_FILE_INIT\n\n# LT_OUTPUT\n# ---------\n# This macro allows early generation of the libtool script (before\n# AC_OUTPUT is called), incase it is used in configure for compilation\n# tests.\nAC_DEFUN([LT_OUTPUT],\n[: ${CONFIG_LT=./config.lt}\nAC_MSG_NOTICE([creating $CONFIG_LT])\n_LT_GENERATED_FILE_INIT([\"$CONFIG_LT\"],\n[# Run this file to recreate a libtool stub with the current configuration.])\n\ncat >>\"$CONFIG_LT\" <<\\_LTEOF\nlt_cl_silent=false\nexec AS_MESSAGE_LOG_FD>>config.log\n{\n  echo\n  AS_BOX([Running $as_me.])\n} >&AS_MESSAGE_LOG_FD\n\nlt_cl_help=\"\\\n'$as_me' creates a local libtool stub from the current configuration,\nfor use in further configure time tests before the real libtool is\ngenerated.\n\nUsage: $[0] [[OPTIONS]]\n\n  -h, --help      print this help, then exit\n  -V, --version   print version number, then exit\n  -q, --quiet     do not print progress messages\n  -d, --debug     don't remove temporary files\n\nReport bugs to <bug-libtool@gnu.org>.\"\n\nlt_cl_version=\"\\\nm4_ifset([AC_PACKAGE_NAME], [AC_PACKAGE_NAME ])config.lt[]dnl\nm4_ifset([AC_PACKAGE_VERSION], [ AC_PACKAGE_VERSION])\nconfigured by $[0], generated by m4_PACKAGE_STRING.\n\nCopyright (C) 2011 Free Software Foundation, Inc.\nThis config.lt script is free software; the Free Software Foundation\ngives unlimited permision to copy, distribute and modify it.\"\n\nwhile test 0 != $[#]\ndo\n  case $[1] in\n    --version | --v* | -V )\n      echo \"$lt_cl_version\"; exit 0 ;;\n    --help | --h* | -h )\n      echo \"$lt_cl_help\"; exit 0 ;;\n    --debug | --d* | -d )\n      debug=: ;;\n    --quiet | --q* | --silent | --s* | -q )\n      lt_cl_silent=: ;;\n\n    -*) AC_MSG_ERROR([unrecognized option: $[1]\nTry '$[0] --help' for more information.]) ;;\n\n    *) AC_MSG_ERROR([unrecognized argument: $[1]\nTry '$[0] --help' for more information.]) ;;\n  esac\n  shift\ndone\n\nif $lt_cl_silent; then\n  exec AS_MESSAGE_FD>/dev/null\nfi\n_LTEOF\n\ncat >>\"$CONFIG_LT\" <<_LTEOF\n_LT_OUTPUT_LIBTOOL_COMMANDS_INIT\n_LTEOF\n\ncat >>\"$CONFIG_LT\" <<\\_LTEOF\nAC_MSG_NOTICE([creating $ofile])\n_LT_OUTPUT_LIBTOOL_COMMANDS\nAS_EXIT(0)\n_LTEOF\nchmod +x \"$CONFIG_LT\"\n\n# configure is writing to config.log, but config.lt does its own redirection,\n# appending to config.log, which fails on DOS, as config.log is still kept\n# open by configure.  Here we exec the FD to /dev/null, effectively closing\n# config.log, so it can be properly (re)opened and appended to by config.lt.\nlt_cl_success=:\ntest yes = \"$silent\" &&\n  lt_config_lt_args=\"$lt_config_lt_args --quiet\"\nexec AS_MESSAGE_LOG_FD>/dev/null\n$SHELL \"$CONFIG_LT\" $lt_config_lt_args || lt_cl_success=false\nexec AS_MESSAGE_LOG_FD>>config.log\n$lt_cl_success || AS_EXIT(1)\n])# LT_OUTPUT\n\n\n# _LT_CONFIG(TAG)\n# ---------------\n# If TAG is the built-in tag, create an initial libtool script with a\n# default configuration from the untagged config vars.  Otherwise add code\n# to config.status for appending the configuration named by TAG from the\n# matching tagged config vars.\nm4_defun([_LT_CONFIG],\n[m4_require([_LT_FILEUTILS_DEFAULTS])dnl\n_LT_CONFIG_SAVE_COMMANDS([\n  m4_define([_LT_TAG], m4_if([$1], [], [C], [$1]))dnl\n  m4_if(_LT_TAG, [C], [\n    # See if we are running on zsh, and set the options that allow our\n    # commands through without removal of \\ escapes.\n    if test -n \"${ZSH_VERSION+set}\"; then\n      setopt NO_GLOB_SUBST\n    fi\n\n    cfgfile=${ofile}T\n    trap \"$RM \\\"$cfgfile\\\"; exit 1\" 1 2 15\n    $RM \"$cfgfile\"\n\n    cat <<_LT_EOF >> \"$cfgfile\"\n#! $SHELL\n# Generated automatically by $as_me ($PACKAGE) $VERSION\n# Libtool was configured on host `(hostname || uname -n) 2>/dev/null | sed 1q`:\n# NOTE: Changes made to this file will be lost: look at ltmain.sh.\n\n# Provide generalized library-building support services.\n# Written by Gordon Matzigkeit, 1996\n\n_LT_COPYING\n_LT_LIBTOOL_TAGS\n\n# Configured defaults for sys_lib_dlsearch_path munging.\n: \\${LT_SYS_LIBRARY_PATH=\"$configure_time_lt_sys_library_path\"}\n\n# ### BEGIN LIBTOOL CONFIG\n_LT_LIBTOOL_CONFIG_VARS\n_LT_LIBTOOL_TAG_VARS\n# ### END LIBTOOL CONFIG\n\n_LT_EOF\n\n    cat <<'_LT_EOF' >> \"$cfgfile\"\n\n# ### BEGIN FUNCTIONS SHARED WITH CONFIGURE\n\n_LT_PREPARE_MUNGE_PATH_LIST\n_LT_PREPARE_CC_BASENAME\n\n# ### END FUNCTIONS SHARED WITH CONFIGURE\n\n_LT_EOF\n\n  case $host_os in\n  aix3*)\n    cat <<\\_LT_EOF >> \"$cfgfile\"\n# AIX sometimes has problems with the GCC collect2 program.  For some\n# reason, if we set the COLLECT_NAMES environment variable, the problems\n# vanish in a puff of smoke.\nif test set != \"${COLLECT_NAMES+set}\"; then\n  COLLECT_NAMES=\n  export COLLECT_NAMES\nfi\n_LT_EOF\n    ;;\n  esac\n\n  _LT_PROG_LTMAIN\n\n  # We use sed instead of cat because bash on DJGPP gets confused if\n  # if finds mixed CR/LF and LF-only lines.  Since sed operates in\n  # text mode, it properly converts lines to CR/LF.  This bash problem\n  # is reportedly fixed, but why not run on old versions too?\n  sed '$q' \"$ltmain\" >> \"$cfgfile\" \\\n     || (rm -f \"$cfgfile\"; exit 1)\n\n   mv -f \"$cfgfile\" \"$ofile\" ||\n    (rm -f \"$ofile\" && cp \"$cfgfile\" \"$ofile\" && rm -f \"$cfgfile\")\n  chmod +x \"$ofile\"\n],\n[cat <<_LT_EOF >> \"$ofile\"\n\ndnl Unfortunately we have to use $1 here, since _LT_TAG is not expanded\ndnl in a comment (ie after a #).\n# ### BEGIN LIBTOOL TAG CONFIG: $1\n_LT_LIBTOOL_TAG_VARS(_LT_TAG)\n# ### END LIBTOOL TAG CONFIG: $1\n_LT_EOF\n])dnl /m4_if\n],\n[m4_if([$1], [], [\n    PACKAGE='$PACKAGE'\n    VERSION='$VERSION'\n    RM='$RM'\n    ofile='$ofile'], [])\n])dnl /_LT_CONFIG_SAVE_COMMANDS\n])# _LT_CONFIG\n\n\n# LT_SUPPORTED_TAG(TAG)\n# ---------------------\n# Trace this macro to discover what tags are supported by the libtool\n# --tag option, using:\n#    autoconf --trace 'LT_SUPPORTED_TAG:$1'\nAC_DEFUN([LT_SUPPORTED_TAG], [])\n\n\n# C support is built-in for now\nm4_define([_LT_LANG_C_enabled], [])\nm4_define([_LT_TAGS], [])\n\n\n# LT_LANG(LANG)\n# -------------\n# Enable libtool support for the given language if not already enabled.\nAC_DEFUN([LT_LANG],\n[AC_BEFORE([$0], [LT_OUTPUT])dnl\nm4_case([$1],\n  [C],\t\t\t[_LT_LANG(C)],\n  [C++],\t\t[_LT_LANG(CXX)],\n  [Go],\t\t\t[_LT_LANG(GO)],\n  [Java],\t\t[_LT_LANG(GCJ)],\n  [Fortran 77],\t\t[_LT_LANG(F77)],\n  [Fortran],\t\t[_LT_LANG(FC)],\n  [Windows Resource],\t[_LT_LANG(RC)],\n  [m4_ifdef([_LT_LANG_]$1[_CONFIG],\n    [_LT_LANG($1)],\n    [m4_fatal([$0: unsupported language: \"$1\"])])])dnl\n])# LT_LANG\n\n\n# _LT_LANG(LANGNAME)\n# ------------------\nm4_defun([_LT_LANG],\n[m4_ifdef([_LT_LANG_]$1[_enabled], [],\n  [LT_SUPPORTED_TAG([$1])dnl\n  m4_append([_LT_TAGS], [$1 ])dnl\n  m4_define([_LT_LANG_]$1[_enabled], [])dnl\n  _LT_LANG_$1_CONFIG($1)])dnl\n])# _LT_LANG\n\n\nm4_ifndef([AC_PROG_GO], [\n############################################################\n# NOTE: This macro has been submitted for inclusion into   #\n#  GNU Autoconf as AC_PROG_GO.  When it is available in    #\n#  a released version of Autoconf we should remove this    #\n#  macro and use it instead.                               #\n############################################################\nm4_defun([AC_PROG_GO],\n[AC_LANG_PUSH(Go)dnl\nAC_ARG_VAR([GOC],     [Go compiler command])dnl\nAC_ARG_VAR([GOFLAGS], [Go compiler flags])dnl\n_AC_ARG_VAR_LDFLAGS()dnl\nAC_CHECK_TOOL(GOC, gccgo)\nif test -z \"$GOC\"; then\n  if test -n \"$ac_tool_prefix\"; then\n    AC_CHECK_PROG(GOC, [${ac_tool_prefix}gccgo], [${ac_tool_prefix}gccgo])\n  fi\nfi\nif test -z \"$GOC\"; then\n  AC_CHECK_PROG(GOC, gccgo, gccgo, false)\nfi\n])#m4_defun\n])#m4_ifndef\n\n\n# _LT_LANG_DEFAULT_CONFIG\n# -----------------------\nm4_defun([_LT_LANG_DEFAULT_CONFIG],\n[AC_PROVIDE_IFELSE([AC_PROG_CXX],\n  [LT_LANG(CXX)],\n  [m4_define([AC_PROG_CXX], defn([AC_PROG_CXX])[LT_LANG(CXX)])])\n\nAC_PROVIDE_IFELSE([AC_PROG_F77],\n  [LT_LANG(F77)],\n  [m4_define([AC_PROG_F77], defn([AC_PROG_F77])[LT_LANG(F77)])])\n\nAC_PROVIDE_IFELSE([AC_PROG_FC],\n  [LT_LANG(FC)],\n  [m4_define([AC_PROG_FC], defn([AC_PROG_FC])[LT_LANG(FC)])])\n\ndnl The call to [A][M_PROG_GCJ] is quoted like that to stop aclocal\ndnl pulling things in needlessly.\nAC_PROVIDE_IFELSE([AC_PROG_GCJ],\n  [LT_LANG(GCJ)],\n  [AC_PROVIDE_IFELSE([A][M_PROG_GCJ],\n    [LT_LANG(GCJ)],\n    [AC_PROVIDE_IFELSE([LT_PROG_GCJ],\n      [LT_LANG(GCJ)],\n      [m4_ifdef([AC_PROG_GCJ],\n\t[m4_define([AC_PROG_GCJ], defn([AC_PROG_GCJ])[LT_LANG(GCJ)])])\n       m4_ifdef([A][M_PROG_GCJ],\n\t[m4_define([A][M_PROG_GCJ], defn([A][M_PROG_GCJ])[LT_LANG(GCJ)])])\n       m4_ifdef([LT_PROG_GCJ],\n\t[m4_define([LT_PROG_GCJ], defn([LT_PROG_GCJ])[LT_LANG(GCJ)])])])])])\n\nAC_PROVIDE_IFELSE([AC_PROG_GO],\n  [LT_LANG(GO)],\n  [m4_define([AC_PROG_GO], defn([AC_PROG_GO])[LT_LANG(GO)])])\n\nAC_PROVIDE_IFELSE([LT_PROG_RC],\n  [LT_LANG(RC)],\n  [m4_define([LT_PROG_RC], defn([LT_PROG_RC])[LT_LANG(RC)])])\n])# _LT_LANG_DEFAULT_CONFIG\n\n# Obsolete macros:\nAU_DEFUN([AC_LIBTOOL_CXX], [LT_LANG(C++)])\nAU_DEFUN([AC_LIBTOOL_F77], [LT_LANG(Fortran 77)])\nAU_DEFUN([AC_LIBTOOL_FC], [LT_LANG(Fortran)])\nAU_DEFUN([AC_LIBTOOL_GCJ], [LT_LANG(Java)])\nAU_DEFUN([AC_LIBTOOL_RC], [LT_LANG(Windows Resource)])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_LIBTOOL_CXX], [])\ndnl AC_DEFUN([AC_LIBTOOL_F77], [])\ndnl AC_DEFUN([AC_LIBTOOL_FC], [])\ndnl AC_DEFUN([AC_LIBTOOL_GCJ], [])\ndnl AC_DEFUN([AC_LIBTOOL_RC], [])\n\n\n# _LT_TAG_COMPILER\n# ----------------\nm4_defun([_LT_TAG_COMPILER],\n[AC_REQUIRE([AC_PROG_CC])dnl\n\n_LT_DECL([LTCC], [CC], [1], [A C compiler])dnl\n_LT_DECL([LTCFLAGS], [CFLAGS], [1], [LTCC compiler flags])dnl\n_LT_TAGDECL([CC], [compiler], [1], [A language specific compiler])dnl\n_LT_TAGDECL([with_gcc], [GCC], [0], [Is the compiler the GNU compiler?])dnl\n\n# If no C compiler was specified, use CC.\nLTCC=${LTCC-\"$CC\"}\n\n# If no C compiler flags were specified, use CFLAGS.\nLTCFLAGS=${LTCFLAGS-\"$CFLAGS\"}\n\n# Allow CC to be a program name with arguments.\ncompiler=$CC\n])# _LT_TAG_COMPILER\n\n\n# _LT_COMPILER_BOILERPLATE\n# ------------------------\n# Check for compiler boilerplate output or warnings with\n# the simple compiler test code.\nm4_defun([_LT_COMPILER_BOILERPLATE],\n[m4_require([_LT_DECL_SED])dnl\nac_outfile=conftest.$ac_objext\necho \"$lt_simple_compile_test_code\" >conftest.$ac_ext\neval \"$ac_compile\" 2>&1 >/dev/null | $SED '/^$/d; /^ *+/d' >conftest.err\n_lt_compiler_boilerplate=`cat conftest.err`\n$RM conftest*\n])# _LT_COMPILER_BOILERPLATE\n\n\n# _LT_LINKER_BOILERPLATE\n# ----------------------\n# Check for linker boilerplate output or warnings with\n# the simple link test code.\nm4_defun([_LT_LINKER_BOILERPLATE],\n[m4_require([_LT_DECL_SED])dnl\nac_outfile=conftest.$ac_objext\necho \"$lt_simple_link_test_code\" >conftest.$ac_ext\neval \"$ac_link\" 2>&1 >/dev/null | $SED '/^$/d; /^ *+/d' >conftest.err\n_lt_linker_boilerplate=`cat conftest.err`\n$RM -r conftest*\n])# _LT_LINKER_BOILERPLATE\n\n# _LT_REQUIRED_DARWIN_CHECKS\n# -------------------------\nm4_defun_once([_LT_REQUIRED_DARWIN_CHECKS],[\n  case $host_os in\n    rhapsody* | darwin*)\n    AC_CHECK_TOOL([DSYMUTIL], [dsymutil], [:])\n    AC_CHECK_TOOL([NMEDIT], [nmedit], [:])\n    AC_CHECK_TOOL([LIPO], [lipo], [:])\n    AC_CHECK_TOOL([OTOOL], [otool], [:])\n    AC_CHECK_TOOL([OTOOL64], [otool64], [:])\n    _LT_DECL([], [DSYMUTIL], [1],\n      [Tool to manipulate archived DWARF debug symbol files on Mac OS X])\n    _LT_DECL([], [NMEDIT], [1],\n      [Tool to change global to local symbols on Mac OS X])\n    _LT_DECL([], [LIPO], [1],\n      [Tool to manipulate fat objects and archives on Mac OS X])\n    _LT_DECL([], [OTOOL], [1],\n      [ldd/readelf like tool for Mach-O binaries on Mac OS X])\n    _LT_DECL([], [OTOOL64], [1],\n      [ldd/readelf like tool for 64 bit Mach-O binaries on Mac OS X 10.4])\n\n    AC_CACHE_CHECK([for -single_module linker flag],[lt_cv_apple_cc_single_mod],\n      [lt_cv_apple_cc_single_mod=no\n      if test -z \"$LT_MULTI_MODULE\"; then\n\t# By default we will add the -single_module flag. You can override\n\t# by either setting the environment variable LT_MULTI_MODULE\n\t# non-empty at configure time, or by adding -multi_module to the\n\t# link flags.\n\trm -rf libconftest.dylib*\n\techo \"int foo(void){return 1;}\" > conftest.c\n\techo \"$LTCC $LTCFLAGS $LDFLAGS -o libconftest.dylib \\\n-dynamiclib -Wl,-single_module conftest.c\" >&AS_MESSAGE_LOG_FD\n\t$LTCC $LTCFLAGS $LDFLAGS -o libconftest.dylib \\\n\t  -dynamiclib -Wl,-single_module conftest.c 2>conftest.err\n        _lt_result=$?\n\t# If there is a non-empty error log, and \"single_module\"\n\t# appears in it, assume the flag caused a linker warning\n        if test -s conftest.err && $GREP single_module conftest.err; then\n\t  cat conftest.err >&AS_MESSAGE_LOG_FD\n\t# Otherwise, if the output was created with a 0 exit code from\n\t# the compiler, it worked.\n\telif test -f libconftest.dylib && test 0 = \"$_lt_result\"; then\n\t  lt_cv_apple_cc_single_mod=yes\n\telse\n\t  cat conftest.err >&AS_MESSAGE_LOG_FD\n\tfi\n\trm -rf libconftest.dylib*\n\trm -f conftest.*\n      fi])\n\n    AC_CACHE_CHECK([for -exported_symbols_list linker flag],\n      [lt_cv_ld_exported_symbols_list],\n      [lt_cv_ld_exported_symbols_list=no\n      save_LDFLAGS=$LDFLAGS\n      echo \"_main\" > conftest.sym\n      LDFLAGS=\"$LDFLAGS -Wl,-exported_symbols_list,conftest.sym\"\n      AC_LINK_IFELSE([AC_LANG_PROGRAM([],[])],\n\t[lt_cv_ld_exported_symbols_list=yes],\n\t[lt_cv_ld_exported_symbols_list=no])\n\tLDFLAGS=$save_LDFLAGS\n    ])\n\n    AC_CACHE_CHECK([for -force_load linker flag],[lt_cv_ld_force_load],\n      [lt_cv_ld_force_load=no\n      cat > conftest.c << _LT_EOF\nint forced_loaded() { return 2;}\n_LT_EOF\n      echo \"$LTCC $LTCFLAGS -c -o conftest.o conftest.c\" >&AS_MESSAGE_LOG_FD\n      $LTCC $LTCFLAGS -c -o conftest.o conftest.c 2>&AS_MESSAGE_LOG_FD\n      echo \"$AR cru libconftest.a conftest.o\" >&AS_MESSAGE_LOG_FD\n      $AR cru libconftest.a conftest.o 2>&AS_MESSAGE_LOG_FD\n      echo \"$RANLIB libconftest.a\" >&AS_MESSAGE_LOG_FD\n      $RANLIB libconftest.a 2>&AS_MESSAGE_LOG_FD\n      cat > conftest.c << _LT_EOF\nint main() { return 0;}\n_LT_EOF\n      echo \"$LTCC $LTCFLAGS $LDFLAGS -o conftest conftest.c -Wl,-force_load,./libconftest.a\" >&AS_MESSAGE_LOG_FD\n      $LTCC $LTCFLAGS $LDFLAGS -o conftest conftest.c -Wl,-force_load,./libconftest.a 2>conftest.err\n      _lt_result=$?\n      if test -s conftest.err && $GREP force_load conftest.err; then\n\tcat conftest.err >&AS_MESSAGE_LOG_FD\n      elif test -f conftest && test 0 = \"$_lt_result\" && $GREP forced_load conftest >/dev/null 2>&1; then\n\tlt_cv_ld_force_load=yes\n      else\n\tcat conftest.err >&AS_MESSAGE_LOG_FD\n      fi\n        rm -f conftest.err libconftest.a conftest conftest.c\n        rm -rf conftest.dSYM\n    ])\n    case $host_os in\n    rhapsody* | darwin1.[[012]])\n      _lt_dar_allow_undefined='$wl-undefined ${wl}suppress' ;;\n    darwin1.*)\n      _lt_dar_allow_undefined='$wl-flat_namespace $wl-undefined ${wl}suppress' ;;\n    darwin*) # darwin 5.x on\n      # if running on 10.5 or later, the deployment target defaults\n      # to the OS version, if on x86, and 10.4, the deployment\n      # target defaults to 10.4. Don't you love it?\n      case ${MACOSX_DEPLOYMENT_TARGET-10.0},$host in\n\t10.0,*86*-darwin8*|10.0,*-darwin[[91]]*)\n\t  _lt_dar_allow_undefined='$wl-undefined ${wl}dynamic_lookup' ;;\n\t10.[[012]][[,.]]*)\n\t  _lt_dar_allow_undefined='$wl-flat_namespace $wl-undefined ${wl}suppress' ;;\n\t10.*)\n\t  _lt_dar_allow_undefined='$wl-undefined ${wl}dynamic_lookup' ;;\n      esac\n    ;;\n  esac\n    if test yes = \"$lt_cv_apple_cc_single_mod\"; then\n      _lt_dar_single_mod='$single_module'\n    fi\n    if test yes = \"$lt_cv_ld_exported_symbols_list\"; then\n      _lt_dar_export_syms=' $wl-exported_symbols_list,$output_objdir/$libname-symbols.expsym'\n    else\n      _lt_dar_export_syms='~$NMEDIT -s $output_objdir/$libname-symbols.expsym $lib'\n    fi\n    if test : != \"$DSYMUTIL\" && test no = \"$lt_cv_ld_force_load\"; then\n      _lt_dsymutil='~$DSYMUTIL $lib || :'\n    else\n      _lt_dsymutil=\n    fi\n    ;;\n  esac\n])\n\n\n# _LT_DARWIN_LINKER_FEATURES([TAG])\n# ---------------------------------\n# Checks for linker and compiler features on darwin\nm4_defun([_LT_DARWIN_LINKER_FEATURES],\n[\n  m4_require([_LT_REQUIRED_DARWIN_CHECKS])\n  _LT_TAGVAR(archive_cmds_need_lc, $1)=no\n  _LT_TAGVAR(hardcode_direct, $1)=no\n  _LT_TAGVAR(hardcode_automatic, $1)=yes\n  _LT_TAGVAR(hardcode_shlibpath_var, $1)=unsupported\n  if test yes = \"$lt_cv_ld_force_load\"; then\n    _LT_TAGVAR(whole_archive_flag_spec, $1)='`for conv in $convenience\\\"\\\"; do test  -n \\\"$conv\\\" && new_convenience=\\\"$new_convenience $wl-force_load,$conv\\\"; done; func_echo_all \\\"$new_convenience\\\"`'\n    m4_case([$1], [F77], [_LT_TAGVAR(compiler_needs_object, $1)=yes],\n                  [FC],  [_LT_TAGVAR(compiler_needs_object, $1)=yes])\n  else\n    _LT_TAGVAR(whole_archive_flag_spec, $1)=''\n  fi\n  _LT_TAGVAR(link_all_deplibs, $1)=yes\n  _LT_TAGVAR(allow_undefined_flag, $1)=$_lt_dar_allow_undefined\n  case $cc_basename in\n     ifort*|nagfor*) _lt_dar_can_shared=yes ;;\n     *) _lt_dar_can_shared=$GCC ;;\n  esac\n  if test yes = \"$_lt_dar_can_shared\"; then\n    output_verbose_link_cmd=func_echo_all\n    _LT_TAGVAR(archive_cmds, $1)=\"\\$CC -dynamiclib \\$allow_undefined_flag -o \\$lib \\$libobjs \\$deplibs \\$compiler_flags -install_name \\$rpath/\\$soname \\$verstring $_lt_dar_single_mod$_lt_dsymutil\"\n    _LT_TAGVAR(module_cmds, $1)=\"\\$CC \\$allow_undefined_flag -o \\$lib -bundle \\$libobjs \\$deplibs \\$compiler_flags$_lt_dsymutil\"\n    _LT_TAGVAR(archive_expsym_cmds, $1)=\"sed 's|^|_|' < \\$export_symbols > \\$output_objdir/\\$libname-symbols.expsym~\\$CC -dynamiclib \\$allow_undefined_flag -o \\$lib \\$libobjs \\$deplibs \\$compiler_flags -install_name \\$rpath/\\$soname \\$verstring $_lt_dar_single_mod$_lt_dar_export_syms$_lt_dsymutil\"\n    _LT_TAGVAR(module_expsym_cmds, $1)=\"sed -e 's|^|_|' < \\$export_symbols > \\$output_objdir/\\$libname-symbols.expsym~\\$CC \\$allow_undefined_flag -o \\$lib -bundle \\$libobjs \\$deplibs \\$compiler_flags$_lt_dar_export_syms$_lt_dsymutil\"\n    m4_if([$1], [CXX],\n[   if test yes != \"$lt_cv_apple_cc_single_mod\"; then\n      _LT_TAGVAR(archive_cmds, $1)=\"\\$CC -r -keep_private_externs -nostdlib -o \\$lib-master.o \\$libobjs~\\$CC -dynamiclib \\$allow_undefined_flag -o \\$lib \\$lib-master.o \\$deplibs \\$compiler_flags -install_name \\$rpath/\\$soname \\$verstring$_lt_dsymutil\"\n      _LT_TAGVAR(archive_expsym_cmds, $1)=\"sed 's|^|_|' < \\$export_symbols > \\$output_objdir/\\$libname-symbols.expsym~\\$CC -r -keep_private_externs -nostdlib -o \\$lib-master.o \\$libobjs~\\$CC -dynamiclib \\$allow_undefined_flag -o \\$lib \\$lib-master.o \\$deplibs \\$compiler_flags -install_name \\$rpath/\\$soname \\$verstring$_lt_dar_export_syms$_lt_dsymutil\"\n    fi\n],[])\n  else\n  _LT_TAGVAR(ld_shlibs, $1)=no\n  fi\n])\n\n# _LT_SYS_MODULE_PATH_AIX([TAGNAME])\n# ----------------------------------\n# Links a minimal program and checks the executable\n# for the system default hardcoded library path. In most cases,\n# this is /usr/lib:/lib, but when the MPI compilers are used\n# the location of the communication and MPI libs are included too.\n# If we don't find anything, use the default library path according\n# to the aix ld manual.\n# Store the results from the different compilers for each TAGNAME.\n# Allow to override them for all tags through lt_cv_aix_libpath.\nm4_defun([_LT_SYS_MODULE_PATH_AIX],\n[m4_require([_LT_DECL_SED])dnl\nif test set = \"${lt_cv_aix_libpath+set}\"; then\n  aix_libpath=$lt_cv_aix_libpath\nelse\n  AC_CACHE_VAL([_LT_TAGVAR([lt_cv_aix_libpath_], [$1])],\n  [AC_LINK_IFELSE([AC_LANG_PROGRAM],[\n  lt_aix_libpath_sed='[\n      /Import File Strings/,/^$/ {\n\t  /^0/ {\n\t      s/^0  *\\([^ ]*\\) *$/\\1/\n\t      p\n\t  }\n      }]'\n  _LT_TAGVAR([lt_cv_aix_libpath_], [$1])=`dump -H conftest$ac_exeext 2>/dev/null | $SED -n -e \"$lt_aix_libpath_sed\"`\n  # Check for a 64-bit object if we didn't find anything.\n  if test -z \"$_LT_TAGVAR([lt_cv_aix_libpath_], [$1])\"; then\n    _LT_TAGVAR([lt_cv_aix_libpath_], [$1])=`dump -HX64 conftest$ac_exeext 2>/dev/null | $SED -n -e \"$lt_aix_libpath_sed\"`\n  fi],[])\n  if test -z \"$_LT_TAGVAR([lt_cv_aix_libpath_], [$1])\"; then\n    _LT_TAGVAR([lt_cv_aix_libpath_], [$1])=/usr/lib:/lib\n  fi\n  ])\n  aix_libpath=$_LT_TAGVAR([lt_cv_aix_libpath_], [$1])\nfi\n])# _LT_SYS_MODULE_PATH_AIX\n\n\n# _LT_SHELL_INIT(ARG)\n# -------------------\nm4_define([_LT_SHELL_INIT],\n[m4_divert_text([M4SH-INIT], [$1\n])])# _LT_SHELL_INIT\n\n\n\n# _LT_PROG_ECHO_BACKSLASH\n# -----------------------\n# Find how we can fake an echo command that does not interpret backslash.\n# In particular, with Autoconf 2.60 or later we add some code to the start\n# of the generated configure script that will find a shell with a builtin\n# printf (that we can use as an echo command).\nm4_defun([_LT_PROG_ECHO_BACKSLASH],\n[ECHO='\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'\nECHO=$ECHO$ECHO$ECHO$ECHO$ECHO\nECHO=$ECHO$ECHO$ECHO$ECHO$ECHO$ECHO\n\nAC_MSG_CHECKING([how to print strings])\n# Test print first, because it will be a builtin if present.\nif test \"X`( print -r -- -n ) 2>/dev/null`\" = X-n && \\\n   test \"X`print -r -- $ECHO 2>/dev/null`\" = \"X$ECHO\"; then\n  ECHO='print -r --'\nelif test \"X`printf %s $ECHO 2>/dev/null`\" = \"X$ECHO\"; then\n  ECHO='printf %s\\n'\nelse\n  # Use this function as a fallback that always works.\n  func_fallback_echo ()\n  {\n    eval 'cat <<_LTECHO_EOF\n$[]1\n_LTECHO_EOF'\n  }\n  ECHO='func_fallback_echo'\nfi\n\n# func_echo_all arg...\n# Invoke $ECHO with all args, space-separated.\nfunc_echo_all ()\n{\n    $ECHO \"$*\"\n}\n\ncase $ECHO in\n  printf*) AC_MSG_RESULT([printf]) ;;\n  print*) AC_MSG_RESULT([print -r]) ;;\n  *) AC_MSG_RESULT([cat]) ;;\nesac\n\nm4_ifdef([_AS_DETECT_SUGGESTED],\n[_AS_DETECT_SUGGESTED([\n  test -n \"${ZSH_VERSION+set}${BASH_VERSION+set}\" || (\n    ECHO='\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'\n    ECHO=$ECHO$ECHO$ECHO$ECHO$ECHO\n    ECHO=$ECHO$ECHO$ECHO$ECHO$ECHO$ECHO\n    PATH=/empty FPATH=/empty; export PATH FPATH\n    test \"X`printf %s $ECHO`\" = \"X$ECHO\" \\\n      || test \"X`print -r -- $ECHO`\" = \"X$ECHO\" )])])\n\n_LT_DECL([], [SHELL], [1], [Shell to use when invoking shell scripts])\n_LT_DECL([], [ECHO], [1], [An echo program that protects backslashes])\n])# _LT_PROG_ECHO_BACKSLASH\n\n\n# _LT_WITH_SYSROOT\n# ----------------\nAC_DEFUN([_LT_WITH_SYSROOT],\n[AC_MSG_CHECKING([for sysroot])\nAC_ARG_WITH([sysroot],\n[AS_HELP_STRING([--with-sysroot@<:@=DIR@:>@],\n  [Search for dependent libraries within DIR (or the compiler's sysroot\n   if not specified).])],\n[], [with_sysroot=no])\n\ndnl lt_sysroot will always be passed unquoted.  We quote it here\ndnl in case the user passed a directory name.\nlt_sysroot=\ncase $with_sysroot in #(\n yes)\n   if test yes = \"$GCC\"; then\n     lt_sysroot=`$CC --print-sysroot 2>/dev/null`\n   fi\n   ;; #(\n /*)\n   lt_sysroot=`echo \"$with_sysroot\" | sed -e \"$sed_quote_subst\"`\n   ;; #(\n no|'')\n   ;; #(\n *)\n   AC_MSG_RESULT([$with_sysroot])\n   AC_MSG_ERROR([The sysroot must be an absolute path.])\n   ;;\nesac\n\n AC_MSG_RESULT([${lt_sysroot:-no}])\n_LT_DECL([], [lt_sysroot], [0], [The root where to search for ]dnl\n[dependent libraries, and where our libraries should be installed.])])\n\n# _LT_ENABLE_LOCK\n# ---------------\nm4_defun([_LT_ENABLE_LOCK],\n[AC_ARG_ENABLE([libtool-lock],\n  [AS_HELP_STRING([--disable-libtool-lock],\n    [avoid locking (might break parallel builds)])])\ntest no = \"$enable_libtool_lock\" || enable_libtool_lock=yes\n\n# Some flags need to be propagated to the compiler or linker for good\n# libtool support.\ncase $host in\nia64-*-hpux*)\n  # Find out what ABI is being produced by ac_compile, and set mode\n  # options accordingly.\n  echo 'int i;' > conftest.$ac_ext\n  if AC_TRY_EVAL(ac_compile); then\n    case `/usr/bin/file conftest.$ac_objext` in\n      *ELF-32*)\n\tHPUX_IA64_MODE=32\n\t;;\n      *ELF-64*)\n\tHPUX_IA64_MODE=64\n\t;;\n    esac\n  fi\n  rm -rf conftest*\n  ;;\n*-*-irix6*)\n  # Find out what ABI is being produced by ac_compile, and set linker\n  # options accordingly.\n  echo '[#]line '$LINENO' \"configure\"' > conftest.$ac_ext\n  if AC_TRY_EVAL(ac_compile); then\n    if test yes = \"$lt_cv_prog_gnu_ld\"; then\n      case `/usr/bin/file conftest.$ac_objext` in\n\t*32-bit*)\n\t  LD=\"${LD-ld} -melf32bsmip\"\n\t  ;;\n\t*N32*)\n\t  LD=\"${LD-ld} -melf32bmipn32\"\n\t  ;;\n\t*64-bit*)\n\t  LD=\"${LD-ld} -melf64bmip\"\n\t;;\n      esac\n    else\n      case `/usr/bin/file conftest.$ac_objext` in\n\t*32-bit*)\n\t  LD=\"${LD-ld} -32\"\n\t  ;;\n\t*N32*)\n\t  LD=\"${LD-ld} -n32\"\n\t  ;;\n\t*64-bit*)\n\t  LD=\"${LD-ld} -64\"\n\t  ;;\n      esac\n    fi\n  fi\n  rm -rf conftest*\n  ;;\n\nmips64*-*linux*)\n  # Find out what ABI is being produced by ac_compile, and set linker\n  # options accordingly.\n  echo '[#]line '$LINENO' \"configure\"' > conftest.$ac_ext\n  if AC_TRY_EVAL(ac_compile); then\n    emul=elf\n    case `/usr/bin/file conftest.$ac_objext` in\n      *32-bit*)\n\temul=\"${emul}32\"\n\t;;\n      *64-bit*)\n\temul=\"${emul}64\"\n\t;;\n    esac\n    case `/usr/bin/file conftest.$ac_objext` in\n      *MSB*)\n\temul=\"${emul}btsmip\"\n\t;;\n      *LSB*)\n\temul=\"${emul}ltsmip\"\n\t;;\n    esac\n    case `/usr/bin/file conftest.$ac_objext` in\n      *N32*)\n\temul=\"${emul}n32\"\n\t;;\n    esac\n    LD=\"${LD-ld} -m $emul\"\n  fi\n  rm -rf conftest*\n  ;;\n\nx86_64-*kfreebsd*-gnu|x86_64-*linux*|powerpc*-*linux*| \\\ns390*-*linux*|s390*-*tpf*|sparc*-*linux*)\n  # Find out what ABI is being produced by ac_compile, and set linker\n  # options accordingly.  Note that the listed cases only cover the\n  # situations where additional linker options are needed (such as when\n  # doing 32-bit compilation for a host where ld defaults to 64-bit, or\n  # vice versa); the common cases where no linker options are needed do\n  # not appear in the list.\n  echo 'int i;' > conftest.$ac_ext\n  if AC_TRY_EVAL(ac_compile); then\n    case `/usr/bin/file conftest.o` in\n      *32-bit*)\n\tcase $host in\n\t  x86_64-*kfreebsd*-gnu)\n\t    LD=\"${LD-ld} -m elf_i386_fbsd\"\n\t    ;;\n\t  x86_64-*linux*)\n\t    case `/usr/bin/file conftest.o` in\n\t      *x86-64*)\n\t\tLD=\"${LD-ld} -m elf32_x86_64\"\n\t\t;;\n\t      *)\n\t\tLD=\"${LD-ld} -m elf_i386\"\n\t\t;;\n\t    esac\n\t    ;;\n\t  powerpc64le-*linux*)\n\t    LD=\"${LD-ld} -m elf32lppclinux\"\n\t    ;;\n\t  powerpc64-*linux*)\n\t    LD=\"${LD-ld} -m elf32ppclinux\"\n\t    ;;\n\t  s390x-*linux*)\n\t    LD=\"${LD-ld} -m elf_s390\"\n\t    ;;\n\t  sparc64-*linux*)\n\t    LD=\"${LD-ld} -m elf32_sparc\"\n\t    ;;\n\tesac\n\t;;\n      *64-bit*)\n\tcase $host in\n\t  x86_64-*kfreebsd*-gnu)\n\t    LD=\"${LD-ld} -m elf_x86_64_fbsd\"\n\t    ;;\n\t  x86_64-*linux*)\n\t    LD=\"${LD-ld} -m elf_x86_64\"\n\t    ;;\n\t  powerpcle-*linux*)\n\t    LD=\"${LD-ld} -m elf64lppc\"\n\t    ;;\n\t  powerpc-*linux*)\n\t    LD=\"${LD-ld} -m elf64ppc\"\n\t    ;;\n\t  s390*-*linux*|s390*-*tpf*)\n\t    LD=\"${LD-ld} -m elf64_s390\"\n\t    ;;\n\t  sparc*-*linux*)\n\t    LD=\"${LD-ld} -m elf64_sparc\"\n\t    ;;\n\tesac\n\t;;\n    esac\n  fi\n  rm -rf conftest*\n  ;;\n\n*-*-sco3.2v5*)\n  # On SCO OpenServer 5, we need -belf to get full-featured binaries.\n  SAVE_CFLAGS=$CFLAGS\n  CFLAGS=\"$CFLAGS -belf\"\n  AC_CACHE_CHECK([whether the C compiler needs -belf], lt_cv_cc_needs_belf,\n    [AC_LANG_PUSH(C)\n     AC_LINK_IFELSE([AC_LANG_PROGRAM([[]],[[]])],[lt_cv_cc_needs_belf=yes],[lt_cv_cc_needs_belf=no])\n     AC_LANG_POP])\n  if test yes != \"$lt_cv_cc_needs_belf\"; then\n    # this is probably gcc 2.8.0, egcs 1.0 or newer; no need for -belf\n    CFLAGS=$SAVE_CFLAGS\n  fi\n  ;;\n*-*solaris*)\n  # Find out what ABI is being produced by ac_compile, and set linker\n  # options accordingly.\n  echo 'int i;' > conftest.$ac_ext\n  if AC_TRY_EVAL(ac_compile); then\n    case `/usr/bin/file conftest.o` in\n    *64-bit*)\n      case $lt_cv_prog_gnu_ld in\n      yes*)\n        case $host in\n        i?86-*-solaris*|x86_64-*-solaris*)\n          LD=\"${LD-ld} -m elf_x86_64\"\n          ;;\n        sparc*-*-solaris*)\n          LD=\"${LD-ld} -m elf64_sparc\"\n          ;;\n        esac\n        # GNU ld 2.21 introduced _sol2 emulations.  Use them if available.\n        if ${LD-ld} -V | grep _sol2 >/dev/null 2>&1; then\n          LD=${LD-ld}_sol2\n        fi\n        ;;\n      *)\n\tif ${LD-ld} -64 -r -o conftest2.o conftest.o >/dev/null 2>&1; then\n\t  LD=\"${LD-ld} -64\"\n\tfi\n\t;;\n      esac\n      ;;\n    esac\n  fi\n  rm -rf conftest*\n  ;;\nesac\n\nneed_locks=$enable_libtool_lock\n])# _LT_ENABLE_LOCK\n\n\n# _LT_PROG_AR\n# -----------\nm4_defun([_LT_PROG_AR],\n[AC_CHECK_TOOLS(AR, [ar], false)\n: ${AR=ar}\n: ${AR_FLAGS=cru}\n_LT_DECL([], [AR], [1], [The archiver])\n_LT_DECL([], [AR_FLAGS], [1], [Flags to create an archive])\n\nAC_CACHE_CHECK([for archiver @FILE support], [lt_cv_ar_at_file],\n  [lt_cv_ar_at_file=no\n   AC_COMPILE_IFELSE([AC_LANG_PROGRAM],\n     [echo conftest.$ac_objext > conftest.lst\n      lt_ar_try='$AR $AR_FLAGS libconftest.a @conftest.lst >&AS_MESSAGE_LOG_FD'\n      AC_TRY_EVAL([lt_ar_try])\n      if test 0 -eq \"$ac_status\"; then\n\t# Ensure the archiver fails upon bogus file names.\n\trm -f conftest.$ac_objext libconftest.a\n\tAC_TRY_EVAL([lt_ar_try])\n\tif test 0 -ne \"$ac_status\"; then\n          lt_cv_ar_at_file=@\n        fi\n      fi\n      rm -f conftest.* libconftest.a\n     ])\n  ])\n\nif test no = \"$lt_cv_ar_at_file\"; then\n  archiver_list_spec=\nelse\n  archiver_list_spec=$lt_cv_ar_at_file\nfi\n_LT_DECL([], [archiver_list_spec], [1],\n  [How to feed a file listing to the archiver])\n])# _LT_PROG_AR\n\n\n# _LT_CMD_OLD_ARCHIVE\n# -------------------\nm4_defun([_LT_CMD_OLD_ARCHIVE],\n[_LT_PROG_AR\n\nAC_CHECK_TOOL(STRIP, strip, :)\ntest -z \"$STRIP\" && STRIP=:\n_LT_DECL([], [STRIP], [1], [A symbol stripping program])\n\nAC_CHECK_TOOL(RANLIB, ranlib, :)\ntest -z \"$RANLIB\" && RANLIB=:\n_LT_DECL([], [RANLIB], [1],\n    [Commands used to install an old-style archive])\n\n# Determine commands to create old-style static archives.\nold_archive_cmds='$AR $AR_FLAGS $oldlib$oldobjs'\nold_postinstall_cmds='chmod 644 $oldlib'\nold_postuninstall_cmds=\n\nif test -n \"$RANLIB\"; then\n  case $host_os in\n  bitrig* | openbsd*)\n    old_postinstall_cmds=\"$old_postinstall_cmds~\\$RANLIB -t \\$tool_oldlib\"\n    ;;\n  *)\n    old_postinstall_cmds=\"$old_postinstall_cmds~\\$RANLIB \\$tool_oldlib\"\n    ;;\n  esac\n  old_archive_cmds=\"$old_archive_cmds~\\$RANLIB \\$tool_oldlib\"\nfi\n\ncase $host_os in\n  darwin*)\n    lock_old_archive_extraction=yes ;;\n  *)\n    lock_old_archive_extraction=no ;;\nesac\n_LT_DECL([], [old_postinstall_cmds], [2])\n_LT_DECL([], [old_postuninstall_cmds], [2])\n_LT_TAGDECL([], [old_archive_cmds], [2],\n    [Commands used to build an old-style archive])\n_LT_DECL([], [lock_old_archive_extraction], [0],\n    [Whether to use a lock for old archive extraction])\n])# _LT_CMD_OLD_ARCHIVE\n\n\n# _LT_COMPILER_OPTION(MESSAGE, VARIABLE-NAME, FLAGS,\n#\t\t[OUTPUT-FILE], [ACTION-SUCCESS], [ACTION-FAILURE])\n# ----------------------------------------------------------------\n# Check whether the given compiler option works\nAC_DEFUN([_LT_COMPILER_OPTION],\n[m4_require([_LT_FILEUTILS_DEFAULTS])dnl\nm4_require([_LT_DECL_SED])dnl\nAC_CACHE_CHECK([$1], [$2],\n  [$2=no\n   m4_if([$4], , [ac_outfile=conftest.$ac_objext], [ac_outfile=$4])\n   echo \"$lt_simple_compile_test_code\" > conftest.$ac_ext\n   lt_compiler_flag=\"$3\"  ## exclude from sc_useless_quotes_in_assignment\n   # Insert the option either (1) after the last *FLAGS variable, or\n   # (2) before a word containing \"conftest.\", or (3) at the end.\n   # Note that $ac_compile itself does not contain backslashes and begins\n   # with a dollar sign (not a hyphen), so the echo should work correctly.\n   # The option is referenced via a variable to avoid confusing sed.\n   lt_compile=`echo \"$ac_compile\" | $SED \\\n   -e 's:.*FLAGS}\\{0,1\\} :&$lt_compiler_flag :; t' \\\n   -e 's: [[^ ]]*conftest\\.: $lt_compiler_flag&:; t' \\\n   -e 's:$: $lt_compiler_flag:'`\n   (eval echo \"\\\"\\$as_me:$LINENO: $lt_compile\\\"\" >&AS_MESSAGE_LOG_FD)\n   (eval \"$lt_compile\" 2>conftest.err)\n   ac_status=$?\n   cat conftest.err >&AS_MESSAGE_LOG_FD\n   echo \"$as_me:$LINENO: \\$? = $ac_status\" >&AS_MESSAGE_LOG_FD\n   if (exit $ac_status) && test -s \"$ac_outfile\"; then\n     # The compiler can only warn and ignore the option if not recognized\n     # So say no if there are warnings other than the usual output.\n     $ECHO \"$_lt_compiler_boilerplate\" | $SED '/^$/d' >conftest.exp\n     $SED '/^$/d; /^ *+/d' conftest.err >conftest.er2\n     if test ! -s conftest.er2 || diff conftest.exp conftest.er2 >/dev/null; then\n       $2=yes\n     fi\n   fi\n   $RM conftest*\n])\n\nif test yes = \"[$]$2\"; then\n    m4_if([$5], , :, [$5])\nelse\n    m4_if([$6], , :, [$6])\nfi\n])# _LT_COMPILER_OPTION\n\n# Old name:\nAU_ALIAS([AC_LIBTOOL_COMPILER_OPTION], [_LT_COMPILER_OPTION])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_LIBTOOL_COMPILER_OPTION], [])\n\n\n# _LT_LINKER_OPTION(MESSAGE, VARIABLE-NAME, FLAGS,\n#                  [ACTION-SUCCESS], [ACTION-FAILURE])\n# ----------------------------------------------------\n# Check whether the given linker option works\nAC_DEFUN([_LT_LINKER_OPTION],\n[m4_require([_LT_FILEUTILS_DEFAULTS])dnl\nm4_require([_LT_DECL_SED])dnl\nAC_CACHE_CHECK([$1], [$2],\n  [$2=no\n   save_LDFLAGS=$LDFLAGS\n   LDFLAGS=\"$LDFLAGS $3\"\n   echo \"$lt_simple_link_test_code\" > conftest.$ac_ext\n   if (eval $ac_link 2>conftest.err) && test -s conftest$ac_exeext; then\n     # The linker can only warn and ignore the option if not recognized\n     # So say no if there are warnings\n     if test -s conftest.err; then\n       # Append any errors to the config.log.\n       cat conftest.err 1>&AS_MESSAGE_LOG_FD\n       $ECHO \"$_lt_linker_boilerplate\" | $SED '/^$/d' > conftest.exp\n       $SED '/^$/d; /^ *+/d' conftest.err >conftest.er2\n       if diff conftest.exp conftest.er2 >/dev/null; then\n         $2=yes\n       fi\n     else\n       $2=yes\n     fi\n   fi\n   $RM -r conftest*\n   LDFLAGS=$save_LDFLAGS\n])\n\nif test yes = \"[$]$2\"; then\n    m4_if([$4], , :, [$4])\nelse\n    m4_if([$5], , :, [$5])\nfi\n])# _LT_LINKER_OPTION\n\n# Old name:\nAU_ALIAS([AC_LIBTOOL_LINKER_OPTION], [_LT_LINKER_OPTION])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_LIBTOOL_LINKER_OPTION], [])\n\n\n# LT_CMD_MAX_LEN\n#---------------\nAC_DEFUN([LT_CMD_MAX_LEN],\n[AC_REQUIRE([AC_CANONICAL_HOST])dnl\n# find the maximum length of command line arguments\nAC_MSG_CHECKING([the maximum length of command line arguments])\nAC_CACHE_VAL([lt_cv_sys_max_cmd_len], [dnl\n  i=0\n  teststring=ABCD\n\n  case $build_os in\n  msdosdjgpp*)\n    # On DJGPP, this test can blow up pretty badly due to problems in libc\n    # (any single argument exceeding 2000 bytes causes a buffer overrun\n    # during glob expansion).  Even if it were fixed, the result of this\n    # check would be larger than it should be.\n    lt_cv_sys_max_cmd_len=12288;    # 12K is about right\n    ;;\n\n  gnu*)\n    # Under GNU Hurd, this test is not required because there is\n    # no limit to the length of command line arguments.\n    # Libtool will interpret -1 as no limit whatsoever\n    lt_cv_sys_max_cmd_len=-1;\n    ;;\n\n  cygwin* | mingw* | cegcc*)\n    # On Win9x/ME, this test blows up -- it succeeds, but takes\n    # about 5 minutes as the teststring grows exponentially.\n    # Worse, since 9x/ME are not pre-emptively multitasking,\n    # you end up with a \"frozen\" computer, even though with patience\n    # the test eventually succeeds (with a max line length of 256k).\n    # Instead, let's just punt: use the minimum linelength reported by\n    # all of the supported platforms: 8192 (on NT/2K/XP).\n    lt_cv_sys_max_cmd_len=8192;\n    ;;\n\n  mint*)\n    # On MiNT this can take a long time and run out of memory.\n    lt_cv_sys_max_cmd_len=8192;\n    ;;\n\n  amigaos*)\n    # On AmigaOS with pdksh, this test takes hours, literally.\n    # So we just punt and use a minimum line length of 8192.\n    lt_cv_sys_max_cmd_len=8192;\n    ;;\n\n  bitrig* | darwin* | dragonfly* | freebsd* | netbsd* | openbsd*)\n    # This has been around since 386BSD, at least.  Likely further.\n    if test -x /sbin/sysctl; then\n      lt_cv_sys_max_cmd_len=`/sbin/sysctl -n kern.argmax`\n    elif test -x /usr/sbin/sysctl; then\n      lt_cv_sys_max_cmd_len=`/usr/sbin/sysctl -n kern.argmax`\n    else\n      lt_cv_sys_max_cmd_len=65536\t# usable default for all BSDs\n    fi\n    # And add a safety zone\n    lt_cv_sys_max_cmd_len=`expr $lt_cv_sys_max_cmd_len \\/ 4`\n    lt_cv_sys_max_cmd_len=`expr $lt_cv_sys_max_cmd_len \\* 3`\n    ;;\n\n  interix*)\n    # We know the value 262144 and hardcode it with a safety zone (like BSD)\n    lt_cv_sys_max_cmd_len=196608\n    ;;\n\n  os2*)\n    # The test takes a long time on OS/2.\n    lt_cv_sys_max_cmd_len=8192\n    ;;\n\n  osf*)\n    # Dr. Hans Ekkehard Plesser reports seeing a kernel panic running configure\n    # due to this test when exec_disable_arg_limit is 1 on Tru64. It is not\n    # nice to cause kernel panics so lets avoid the loop below.\n    # First set a reasonable default.\n    lt_cv_sys_max_cmd_len=16384\n    #\n    if test -x /sbin/sysconfig; then\n      case `/sbin/sysconfig -q proc exec_disable_arg_limit` in\n        *1*) lt_cv_sys_max_cmd_len=-1 ;;\n      esac\n    fi\n    ;;\n  sco3.2v5*)\n    lt_cv_sys_max_cmd_len=102400\n    ;;\n  sysv5* | sco5v6* | sysv4.2uw2*)\n    kargmax=`grep ARG_MAX /etc/conf/cf.d/stune 2>/dev/null`\n    if test -n \"$kargmax\"; then\n      lt_cv_sys_max_cmd_len=`echo $kargmax | sed 's/.*[[\t ]]//'`\n    else\n      lt_cv_sys_max_cmd_len=32768\n    fi\n    ;;\n  *)\n    lt_cv_sys_max_cmd_len=`(getconf ARG_MAX) 2> /dev/null`\n    if test -n \"$lt_cv_sys_max_cmd_len\" && \\\n       test undefined != \"$lt_cv_sys_max_cmd_len\"; then\n      lt_cv_sys_max_cmd_len=`expr $lt_cv_sys_max_cmd_len \\/ 4`\n      lt_cv_sys_max_cmd_len=`expr $lt_cv_sys_max_cmd_len \\* 3`\n    else\n      # Make teststring a little bigger before we do anything with it.\n      # a 1K string should be a reasonable start.\n      for i in 1 2 3 4 5 6 7 8; do\n        teststring=$teststring$teststring\n      done\n      SHELL=${SHELL-${CONFIG_SHELL-/bin/sh}}\n      # If test is not a shell built-in, we'll probably end up computing a\n      # maximum length that is only half of the actual maximum length, but\n      # we can't tell.\n      while { test X`env echo \"$teststring$teststring\" 2>/dev/null` \\\n\t         = \"X$teststring$teststring\"; } >/dev/null 2>&1 &&\n\t      test 17 != \"$i\" # 1/2 MB should be enough\n      do\n        i=`expr $i + 1`\n        teststring=$teststring$teststring\n      done\n      # Only check the string length outside the loop.\n      lt_cv_sys_max_cmd_len=`expr \"X$teststring\" : \".*\" 2>&1`\n      teststring=\n      # Add a significant safety factor because C++ compilers can tack on\n      # massive amounts of additional arguments before passing them to the\n      # linker.  It appears as though 1/2 is a usable value.\n      lt_cv_sys_max_cmd_len=`expr $lt_cv_sys_max_cmd_len \\/ 2`\n    fi\n    ;;\n  esac\n])\nif test -n \"$lt_cv_sys_max_cmd_len\"; then\n  AC_MSG_RESULT($lt_cv_sys_max_cmd_len)\nelse\n  AC_MSG_RESULT(none)\nfi\nmax_cmd_len=$lt_cv_sys_max_cmd_len\n_LT_DECL([], [max_cmd_len], [0],\n    [What is the maximum length of a command?])\n])# LT_CMD_MAX_LEN\n\n# Old name:\nAU_ALIAS([AC_LIBTOOL_SYS_MAX_CMD_LEN], [LT_CMD_MAX_LEN])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_LIBTOOL_SYS_MAX_CMD_LEN], [])\n\n\n# _LT_HEADER_DLFCN\n# ----------------\nm4_defun([_LT_HEADER_DLFCN],\n[AC_CHECK_HEADERS([dlfcn.h], [], [], [AC_INCLUDES_DEFAULT])dnl\n])# _LT_HEADER_DLFCN\n\n\n# _LT_TRY_DLOPEN_SELF (ACTION-IF-TRUE, ACTION-IF-TRUE-W-USCORE,\n#                      ACTION-IF-FALSE, ACTION-IF-CROSS-COMPILING)\n# ----------------------------------------------------------------\nm4_defun([_LT_TRY_DLOPEN_SELF],\n[m4_require([_LT_HEADER_DLFCN])dnl\nif test yes = \"$cross_compiling\"; then :\n  [$4]\nelse\n  lt_dlunknown=0; lt_dlno_uscore=1; lt_dlneed_uscore=2\n  lt_status=$lt_dlunknown\n  cat > conftest.$ac_ext <<_LT_EOF\n[#line $LINENO \"configure\"\n#include \"confdefs.h\"\n\n#if HAVE_DLFCN_H\n#include <dlfcn.h>\n#endif\n\n#include <stdio.h>\n\n#ifdef RTLD_GLOBAL\n#  define LT_DLGLOBAL\t\tRTLD_GLOBAL\n#else\n#  ifdef DL_GLOBAL\n#    define LT_DLGLOBAL\t\tDL_GLOBAL\n#  else\n#    define LT_DLGLOBAL\t\t0\n#  endif\n#endif\n\n/* We may have to define LT_DLLAZY_OR_NOW in the command line if we\n   find out it does not work in some platform. */\n#ifndef LT_DLLAZY_OR_NOW\n#  ifdef RTLD_LAZY\n#    define LT_DLLAZY_OR_NOW\t\tRTLD_LAZY\n#  else\n#    ifdef DL_LAZY\n#      define LT_DLLAZY_OR_NOW\t\tDL_LAZY\n#    else\n#      ifdef RTLD_NOW\n#        define LT_DLLAZY_OR_NOW\tRTLD_NOW\n#      else\n#        ifdef DL_NOW\n#          define LT_DLLAZY_OR_NOW\tDL_NOW\n#        else\n#          define LT_DLLAZY_OR_NOW\t0\n#        endif\n#      endif\n#    endif\n#  endif\n#endif\n\n/* When -fvisibility=hidden is used, assume the code has been annotated\n   correspondingly for the symbols needed.  */\n#if defined __GNUC__ && (((__GNUC__ == 3) && (__GNUC_MINOR__ >= 3)) || (__GNUC__ > 3))\nint fnord () __attribute__((visibility(\"default\")));\n#endif\n\nint fnord () { return 42; }\nint main ()\n{\n  void *self = dlopen (0, LT_DLGLOBAL|LT_DLLAZY_OR_NOW);\n  int status = $lt_dlunknown;\n\n  if (self)\n    {\n      if (dlsym (self,\"fnord\"))       status = $lt_dlno_uscore;\n      else\n        {\n\t  if (dlsym( self,\"_fnord\"))  status = $lt_dlneed_uscore;\n          else puts (dlerror ());\n\t}\n      /* dlclose (self); */\n    }\n  else\n    puts (dlerror ());\n\n  return status;\n}]\n_LT_EOF\n  if AC_TRY_EVAL(ac_link) && test -s \"conftest$ac_exeext\" 2>/dev/null; then\n    (./conftest; exit; ) >&AS_MESSAGE_LOG_FD 2>/dev/null\n    lt_status=$?\n    case x$lt_status in\n      x$lt_dlno_uscore) $1 ;;\n      x$lt_dlneed_uscore) $2 ;;\n      x$lt_dlunknown|x*) $3 ;;\n    esac\n  else :\n    # compilation failed\n    $3\n  fi\nfi\nrm -fr conftest*\n])# _LT_TRY_DLOPEN_SELF\n\n\n# LT_SYS_DLOPEN_SELF\n# ------------------\nAC_DEFUN([LT_SYS_DLOPEN_SELF],\n[m4_require([_LT_HEADER_DLFCN])dnl\nif test yes != \"$enable_dlopen\"; then\n  enable_dlopen=unknown\n  enable_dlopen_self=unknown\n  enable_dlopen_self_static=unknown\nelse\n  lt_cv_dlopen=no\n  lt_cv_dlopen_libs=\n\n  case $host_os in\n  beos*)\n    lt_cv_dlopen=load_add_on\n    lt_cv_dlopen_libs=\n    lt_cv_dlopen_self=yes\n    ;;\n\n  mingw* | pw32* | cegcc*)\n    lt_cv_dlopen=LoadLibrary\n    lt_cv_dlopen_libs=\n    ;;\n\n  cygwin*)\n    lt_cv_dlopen=dlopen\n    lt_cv_dlopen_libs=\n    ;;\n\n  darwin*)\n    # if libdl is installed we need to link against it\n    AC_CHECK_LIB([dl], [dlopen],\n\t\t[lt_cv_dlopen=dlopen lt_cv_dlopen_libs=-ldl],[\n    lt_cv_dlopen=dyld\n    lt_cv_dlopen_libs=\n    lt_cv_dlopen_self=yes\n    ])\n    ;;\n\n  tpf*)\n    # Don't try to run any link tests for TPF.  We know it's impossible\n    # because TPF is a cross-compiler, and we know how we open DSOs.\n    lt_cv_dlopen=dlopen\n    lt_cv_dlopen_libs=\n    lt_cv_dlopen_self=no\n    ;;\n\n  *)\n    AC_CHECK_FUNC([shl_load],\n\t  [lt_cv_dlopen=shl_load],\n      [AC_CHECK_LIB([dld], [shl_load],\n\t    [lt_cv_dlopen=shl_load lt_cv_dlopen_libs=-ldld],\n\t[AC_CHECK_FUNC([dlopen],\n\t      [lt_cv_dlopen=dlopen],\n\t  [AC_CHECK_LIB([dl], [dlopen],\n\t\t[lt_cv_dlopen=dlopen lt_cv_dlopen_libs=-ldl],\n\t    [AC_CHECK_LIB([svld], [dlopen],\n\t\t  [lt_cv_dlopen=dlopen lt_cv_dlopen_libs=-lsvld],\n\t      [AC_CHECK_LIB([dld], [dld_link],\n\t\t    [lt_cv_dlopen=dld_link lt_cv_dlopen_libs=-ldld])\n\t      ])\n\t    ])\n\t  ])\n\t])\n      ])\n    ;;\n  esac\n\n  if test no = \"$lt_cv_dlopen\"; then\n    enable_dlopen=no\n  else\n    enable_dlopen=yes\n  fi\n\n  case $lt_cv_dlopen in\n  dlopen)\n    save_CPPFLAGS=$CPPFLAGS\n    test yes = \"$ac_cv_header_dlfcn_h\" && CPPFLAGS=\"$CPPFLAGS -DHAVE_DLFCN_H\"\n\n    save_LDFLAGS=$LDFLAGS\n    wl=$lt_prog_compiler_wl eval LDFLAGS=\\\"\\$LDFLAGS $export_dynamic_flag_spec\\\"\n\n    save_LIBS=$LIBS\n    LIBS=\"$lt_cv_dlopen_libs $LIBS\"\n\n    AC_CACHE_CHECK([whether a program can dlopen itself],\n\t  lt_cv_dlopen_self, [dnl\n\t  _LT_TRY_DLOPEN_SELF(\n\t    lt_cv_dlopen_self=yes, lt_cv_dlopen_self=yes,\n\t    lt_cv_dlopen_self=no, lt_cv_dlopen_self=cross)\n    ])\n\n    if test yes = \"$lt_cv_dlopen_self\"; then\n      wl=$lt_prog_compiler_wl eval LDFLAGS=\\\"\\$LDFLAGS $lt_prog_compiler_static\\\"\n      AC_CACHE_CHECK([whether a statically linked program can dlopen itself],\n\t  lt_cv_dlopen_self_static, [dnl\n\t  _LT_TRY_DLOPEN_SELF(\n\t    lt_cv_dlopen_self_static=yes, lt_cv_dlopen_self_static=yes,\n\t    lt_cv_dlopen_self_static=no,  lt_cv_dlopen_self_static=cross)\n      ])\n    fi\n\n    CPPFLAGS=$save_CPPFLAGS\n    LDFLAGS=$save_LDFLAGS\n    LIBS=$save_LIBS\n    ;;\n  esac\n\n  case $lt_cv_dlopen_self in\n  yes|no) enable_dlopen_self=$lt_cv_dlopen_self ;;\n  *) enable_dlopen_self=unknown ;;\n  esac\n\n  case $lt_cv_dlopen_self_static in\n  yes|no) enable_dlopen_self_static=$lt_cv_dlopen_self_static ;;\n  *) enable_dlopen_self_static=unknown ;;\n  esac\nfi\n_LT_DECL([dlopen_support], [enable_dlopen], [0],\n\t [Whether dlopen is supported])\n_LT_DECL([dlopen_self], [enable_dlopen_self], [0],\n\t [Whether dlopen of programs is supported])\n_LT_DECL([dlopen_self_static], [enable_dlopen_self_static], [0],\n\t [Whether dlopen of statically linked programs is supported])\n])# LT_SYS_DLOPEN_SELF\n\n# Old name:\nAU_ALIAS([AC_LIBTOOL_DLOPEN_SELF], [LT_SYS_DLOPEN_SELF])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_LIBTOOL_DLOPEN_SELF], [])\n\n\n# _LT_COMPILER_C_O([TAGNAME])\n# ---------------------------\n# Check to see if options -c and -o are simultaneously supported by compiler.\n# This macro does not hard code the compiler like AC_PROG_CC_C_O.\nm4_defun([_LT_COMPILER_C_O],\n[m4_require([_LT_DECL_SED])dnl\nm4_require([_LT_FILEUTILS_DEFAULTS])dnl\nm4_require([_LT_TAG_COMPILER])dnl\nAC_CACHE_CHECK([if $compiler supports -c -o file.$ac_objext],\n  [_LT_TAGVAR(lt_cv_prog_compiler_c_o, $1)],\n  [_LT_TAGVAR(lt_cv_prog_compiler_c_o, $1)=no\n   $RM -r conftest 2>/dev/null\n   mkdir conftest\n   cd conftest\n   mkdir out\n   echo \"$lt_simple_compile_test_code\" > conftest.$ac_ext\n\n   lt_compiler_flag=\"-o out/conftest2.$ac_objext\"\n   # Insert the option either (1) after the last *FLAGS variable, or\n   # (2) before a word containing \"conftest.\", or (3) at the end.\n   # Note that $ac_compile itself does not contain backslashes and begins\n   # with a dollar sign (not a hyphen), so the echo should work correctly.\n   lt_compile=`echo \"$ac_compile\" | $SED \\\n   -e 's:.*FLAGS}\\{0,1\\} :&$lt_compiler_flag :; t' \\\n   -e 's: [[^ ]]*conftest\\.: $lt_compiler_flag&:; t' \\\n   -e 's:$: $lt_compiler_flag:'`\n   (eval echo \"\\\"\\$as_me:$LINENO: $lt_compile\\\"\" >&AS_MESSAGE_LOG_FD)\n   (eval \"$lt_compile\" 2>out/conftest.err)\n   ac_status=$?\n   cat out/conftest.err >&AS_MESSAGE_LOG_FD\n   echo \"$as_me:$LINENO: \\$? = $ac_status\" >&AS_MESSAGE_LOG_FD\n   if (exit $ac_status) && test -s out/conftest2.$ac_objext\n   then\n     # The compiler can only warn and ignore the option if not recognized\n     # So say no if there are warnings\n     $ECHO \"$_lt_compiler_boilerplate\" | $SED '/^$/d' > out/conftest.exp\n     $SED '/^$/d; /^ *+/d' out/conftest.err >out/conftest.er2\n     if test ! -s out/conftest.er2 || diff out/conftest.exp out/conftest.er2 >/dev/null; then\n       _LT_TAGVAR(lt_cv_prog_compiler_c_o, $1)=yes\n     fi\n   fi\n   chmod u+w . 2>&AS_MESSAGE_LOG_FD\n   $RM conftest*\n   # SGI C++ compiler will create directory out/ii_files/ for\n   # template instantiation\n   test -d out/ii_files && $RM out/ii_files/* && rmdir out/ii_files\n   $RM out/* && rmdir out\n   cd ..\n   $RM -r conftest\n   $RM conftest*\n])\n_LT_TAGDECL([compiler_c_o], [lt_cv_prog_compiler_c_o], [1],\n\t[Does compiler simultaneously support -c and -o options?])\n])# _LT_COMPILER_C_O\n\n\n# _LT_COMPILER_FILE_LOCKS([TAGNAME])\n# ----------------------------------\n# Check to see if we can do hard links to lock some files if needed\nm4_defun([_LT_COMPILER_FILE_LOCKS],\n[m4_require([_LT_ENABLE_LOCK])dnl\nm4_require([_LT_FILEUTILS_DEFAULTS])dnl\n_LT_COMPILER_C_O([$1])\n\nhard_links=nottested\nif test no = \"$_LT_TAGVAR(lt_cv_prog_compiler_c_o, $1)\" && test no != \"$need_locks\"; then\n  # do not overwrite the value of need_locks provided by the user\n  AC_MSG_CHECKING([if we can lock with hard links])\n  hard_links=yes\n  $RM conftest*\n  ln conftest.a conftest.b 2>/dev/null && hard_links=no\n  touch conftest.a\n  ln conftest.a conftest.b 2>&5 || hard_links=no\n  ln conftest.a conftest.b 2>/dev/null && hard_links=no\n  AC_MSG_RESULT([$hard_links])\n  if test no = \"$hard_links\"; then\n    AC_MSG_WARN(['$CC' does not support '-c -o', so 'make -j' may be unsafe])\n    need_locks=warn\n  fi\nelse\n  need_locks=no\nfi\n_LT_DECL([], [need_locks], [1], [Must we lock files when doing compilation?])\n])# _LT_COMPILER_FILE_LOCKS\n\n\n# _LT_CHECK_OBJDIR\n# ----------------\nm4_defun([_LT_CHECK_OBJDIR],\n[AC_CACHE_CHECK([for objdir], [lt_cv_objdir],\n[rm -f .libs 2>/dev/null\nmkdir .libs 2>/dev/null\nif test -d .libs; then\n  lt_cv_objdir=.libs\nelse\n  # MS-DOS does not allow filenames that begin with a dot.\n  lt_cv_objdir=_libs\nfi\nrmdir .libs 2>/dev/null])\nobjdir=$lt_cv_objdir\n_LT_DECL([], [objdir], [0],\n         [The name of the directory that contains temporary libtool files])dnl\nm4_pattern_allow([LT_OBJDIR])dnl\nAC_DEFINE_UNQUOTED([LT_OBJDIR], \"$lt_cv_objdir/\",\n  [Define to the sub-directory where libtool stores uninstalled libraries.])\n])# _LT_CHECK_OBJDIR\n\n\n# _LT_LINKER_HARDCODE_LIBPATH([TAGNAME])\n# --------------------------------------\n# Check hardcoding attributes.\nm4_defun([_LT_LINKER_HARDCODE_LIBPATH],\n[AC_MSG_CHECKING([how to hardcode library paths into programs])\n_LT_TAGVAR(hardcode_action, $1)=\nif test -n \"$_LT_TAGVAR(hardcode_libdir_flag_spec, $1)\" ||\n   test -n \"$_LT_TAGVAR(runpath_var, $1)\" ||\n   test yes = \"$_LT_TAGVAR(hardcode_automatic, $1)\"; then\n\n  # We can hardcode non-existent directories.\n  if test no != \"$_LT_TAGVAR(hardcode_direct, $1)\" &&\n     # If the only mechanism to avoid hardcoding is shlibpath_var, we\n     # have to relink, otherwise we might link with an installed library\n     # when we should be linking with a yet-to-be-installed one\n     ## test no != \"$_LT_TAGVAR(hardcode_shlibpath_var, $1)\" &&\n     test no != \"$_LT_TAGVAR(hardcode_minus_L, $1)\"; then\n    # Linking always hardcodes the temporary library directory.\n    _LT_TAGVAR(hardcode_action, $1)=relink\n  else\n    # We can link without hardcoding, and we can hardcode nonexisting dirs.\n    _LT_TAGVAR(hardcode_action, $1)=immediate\n  fi\nelse\n  # We cannot hardcode anything, or else we can only hardcode existing\n  # directories.\n  _LT_TAGVAR(hardcode_action, $1)=unsupported\nfi\nAC_MSG_RESULT([$_LT_TAGVAR(hardcode_action, $1)])\n\nif test relink = \"$_LT_TAGVAR(hardcode_action, $1)\" ||\n   test yes = \"$_LT_TAGVAR(inherit_rpath, $1)\"; then\n  # Fast installation is not supported\n  enable_fast_install=no\nelif test yes = \"$shlibpath_overrides_runpath\" ||\n     test no = \"$enable_shared\"; then\n  # Fast installation is not necessary\n  enable_fast_install=needless\nfi\n_LT_TAGDECL([], [hardcode_action], [0],\n    [How to hardcode a shared library path into an executable])\n])# _LT_LINKER_HARDCODE_LIBPATH\n\n\n# _LT_CMD_STRIPLIB\n# ----------------\nm4_defun([_LT_CMD_STRIPLIB],\n[m4_require([_LT_DECL_EGREP])\nstriplib=\nold_striplib=\nAC_MSG_CHECKING([whether stripping libraries is possible])\nif test -n \"$STRIP\" && $STRIP -V 2>&1 | $GREP \"GNU strip\" >/dev/null; then\n  test -z \"$old_striplib\" && old_striplib=\"$STRIP --strip-debug\"\n  test -z \"$striplib\" && striplib=\"$STRIP --strip-unneeded\"\n  AC_MSG_RESULT([yes])\nelse\n# FIXME - insert some real tests, host_os isn't really good enough\n  case $host_os in\n  darwin*)\n    if test -n \"$STRIP\"; then\n      striplib=\"$STRIP -x\"\n      old_striplib=\"$STRIP -S\"\n      AC_MSG_RESULT([yes])\n    else\n      AC_MSG_RESULT([no])\n    fi\n    ;;\n  *)\n    AC_MSG_RESULT([no])\n    ;;\n  esac\nfi\n_LT_DECL([], [old_striplib], [1], [Commands to strip libraries])\n_LT_DECL([], [striplib], [1])\n])# _LT_CMD_STRIPLIB\n\n\n# _LT_PREPARE_MUNGE_PATH_LIST\n# ---------------------------\n# Make sure func_munge_path_list() is defined correctly.\nm4_defun([_LT_PREPARE_MUNGE_PATH_LIST],\n[[# func_munge_path_list VARIABLE PATH\n# -----------------------------------\n# VARIABLE is name of variable containing _space_ separated list of\n# directories to be munged by the contents of PATH, which is string\n# having a format:\n# \"DIR[:DIR]:\"\n#       string \"DIR[ DIR]\" will be prepended to VARIABLE\n# \":DIR[:DIR]\"\n#       string \"DIR[ DIR]\" will be appended to VARIABLE\n# \"DIRP[:DIRP]::[DIRA:]DIRA\"\n#       string \"DIRP[ DIRP]\" will be prepended to VARIABLE and string\n#       \"DIRA[ DIRA]\" will be appended to VARIABLE\n# \"DIR[:DIR]\"\n#       VARIABLE will be replaced by \"DIR[ DIR]\"\nfunc_munge_path_list ()\n{\n    case x@S|@2 in\n    x)\n        ;;\n    *:)\n        eval @S|@1=\\\"`$ECHO @S|@2 | $SED 's/:/ /g'` \\@S|@@S|@1\\\"\n        ;;\n    x:*)\n        eval @S|@1=\\\"\\@S|@@S|@1 `$ECHO @S|@2 | $SED 's/:/ /g'`\\\"\n        ;;\n    *::*)\n        eval @S|@1=\\\"\\@S|@@S|@1\\ `$ECHO @S|@2 | $SED -e 's/.*:://' -e 's/:/ /g'`\\\"\n        eval @S|@1=\\\"`$ECHO @S|@2 | $SED -e 's/::.*//' -e 's/:/ /g'`\\ \\@S|@@S|@1\\\"\n        ;;\n    *)\n        eval @S|@1=\\\"`$ECHO @S|@2 | $SED 's/:/ /g'`\\\"\n        ;;\n    esac\n}\n]])# _LT_PREPARE_PATH_LIST\n\n\n# _LT_SYS_DYNAMIC_LINKER([TAG])\n# -----------------------------\n# PORTME Fill in your ld.so characteristics\nm4_defun([_LT_SYS_DYNAMIC_LINKER],\n[AC_REQUIRE([AC_CANONICAL_HOST])dnl\nm4_require([_LT_DECL_EGREP])dnl\nm4_require([_LT_FILEUTILS_DEFAULTS])dnl\nm4_require([_LT_DECL_OBJDUMP])dnl\nm4_require([_LT_DECL_SED])dnl\nm4_require([_LT_CHECK_SHELL_FEATURES])dnl\nm4_require([_LT_PREPARE_MUNGE_PATH_LIST])dnl\nAC_MSG_CHECKING([dynamic linker characteristics])\nm4_if([$1],\n\t[], [\nif test yes = \"$GCC\"; then\n  case $host_os in\n    darwin*) lt_awk_arg='/^libraries:/,/LR/' ;;\n    *) lt_awk_arg='/^libraries:/' ;;\n  esac\n  case $host_os in\n    mingw* | cegcc*) lt_sed_strip_eq='s|=\\([[A-Za-z]]:\\)|\\1|g' ;;\n    *) lt_sed_strip_eq='s|=/|/|g' ;;\n  esac\n  lt_search_path_spec=`$CC -print-search-dirs | awk $lt_awk_arg | $SED -e \"s/^libraries://\" -e $lt_sed_strip_eq`\n  case $lt_search_path_spec in\n  *\\;*)\n    # if the path contains \";\" then we assume it to be the separator\n    # otherwise default to the standard path separator (i.e. \":\") - it is\n    # assumed that no part of a normal pathname contains \";\" but that should\n    # okay in the real world where \";\" in dirpaths is itself problematic.\n    lt_search_path_spec=`$ECHO \"$lt_search_path_spec\" | $SED 's/;/ /g'`\n    ;;\n  *)\n    lt_search_path_spec=`$ECHO \"$lt_search_path_spec\" | $SED \"s/$PATH_SEPARATOR/ /g\"`\n    ;;\n  esac\n  # Ok, now we have the path, separated by spaces, we can step through it\n  # and add multilib dir if necessary...\n  lt_tmp_lt_search_path_spec=\n  lt_multi_os_dir=/`$CC $CPPFLAGS $CFLAGS $LDFLAGS -print-multi-os-directory 2>/dev/null`\n  # ...but if some path component already ends with the multilib dir we assume\n  # that all is fine and trust -print-search-dirs as is (GCC 4.2? or newer).\n  case \"$lt_multi_os_dir; $lt_search_path_spec \" in\n  \"/; \"* | \"/.; \"* | \"/./; \"* | *\"$lt_multi_os_dir \"* | *\"$lt_multi_os_dir/ \"*)\n    lt_multi_os_dir=\n    ;;\n  esac\n  for lt_sys_path in $lt_search_path_spec; do\n    if test -d \"$lt_sys_path$lt_multi_os_dir\"; then\n      lt_tmp_lt_search_path_spec=\"$lt_tmp_lt_search_path_spec $lt_sys_path$lt_multi_os_dir\"\n    elif test -n \"$lt_multi_os_dir\"; then\n      test -d \"$lt_sys_path\" && \\\n\tlt_tmp_lt_search_path_spec=\"$lt_tmp_lt_search_path_spec $lt_sys_path\"\n    fi\n  done\n  lt_search_path_spec=`$ECHO \"$lt_tmp_lt_search_path_spec\" | awk '\nBEGIN {RS = \" \"; FS = \"/|\\n\";} {\n  lt_foo = \"\";\n  lt_count = 0;\n  for (lt_i = NF; lt_i > 0; lt_i--) {\n    if ($lt_i != \"\" && $lt_i != \".\") {\n      if ($lt_i == \"..\") {\n        lt_count++;\n      } else {\n        if (lt_count == 0) {\n          lt_foo = \"/\" $lt_i lt_foo;\n        } else {\n          lt_count--;\n        }\n      }\n    }\n  }\n  if (lt_foo != \"\") { lt_freq[[lt_foo]]++; }\n  if (lt_freq[[lt_foo]] == 1) { print lt_foo; }\n}'`\n  # AWK program above erroneously prepends '/' to C:/dos/paths\n  # for these hosts.\n  case $host_os in\n    mingw* | cegcc*) lt_search_path_spec=`$ECHO \"$lt_search_path_spec\" |\\\n      $SED 's|/\\([[A-Za-z]]:\\)|\\1|g'` ;;\n  esac\n  sys_lib_search_path_spec=`$ECHO \"$lt_search_path_spec\" | $lt_NL2SP`\nelse\n  sys_lib_search_path_spec=\"/lib /usr/lib /usr/local/lib\"\nfi])\nlibrary_names_spec=\nlibname_spec='lib$name'\nsoname_spec=\nshrext_cmds=.so\npostinstall_cmds=\npostuninstall_cmds=\nfinish_cmds=\nfinish_eval=\nshlibpath_var=\nshlibpath_overrides_runpath=unknown\nversion_type=none\ndynamic_linker=\"$host_os ld.so\"\nsys_lib_dlsearch_path_spec=\"/lib /usr/lib\"\nneed_lib_prefix=unknown\nhardcode_into_libs=no\n\n# when you set need_version to no, make sure it does not cause -set_version\n# flags to be left without arguments\nneed_version=unknown\n\nAC_ARG_VAR([LT_SYS_LIBRARY_PATH],\n[User-defined run-time library search path.])\n\ncase $host_os in\naix3*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  library_names_spec='$libname$release$shared_ext$versuffix $libname.a'\n  shlibpath_var=LIBPATH\n\n  # AIX 3 has no versioning support, so we append a major version to the name.\n  soname_spec='$libname$release$shared_ext$major'\n  ;;\n\naix[[4-9]]*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  need_lib_prefix=no\n  need_version=no\n  hardcode_into_libs=yes\n  if test ia64 = \"$host_cpu\"; then\n    # AIX 5 supports IA64\n    library_names_spec='$libname$release$shared_ext$major $libname$release$shared_ext$versuffix $libname$shared_ext'\n    shlibpath_var=LD_LIBRARY_PATH\n  else\n    # With GCC up to 2.95.x, collect2 would create an import file\n    # for dependence libraries.  The import file would start with\n    # the line '#! .'.  This would cause the generated library to\n    # depend on '.', always an invalid library.  This was fixed in\n    # development snapshots of GCC prior to 3.0.\n    case $host_os in\n      aix4 | aix4.[[01]] | aix4.[[01]].*)\n      if { echo '#if __GNUC__ > 2 || (__GNUC__ == 2 && __GNUC_MINOR__ >= 97)'\n\t   echo ' yes '\n\t   echo '#endif'; } | $CC -E - | $GREP yes > /dev/null; then\n\t:\n      else\n\tcan_build_shared=no\n      fi\n      ;;\n    esac\n    # Using Import Files as archive members, it is possible to support\n    # filename-based versioning of shared library archives on AIX. While\n    # this would work for both with and without runtime linking, it will\n    # prevent static linking of such archives. So we do filename-based\n    # shared library versioning with .so extension only, which is used\n    # when both runtime linking and shared linking is enabled.\n    # Unfortunately, runtime linking may impact performance, so we do\n    # not want this to be the default eventually. Also, we use the\n    # versioned .so libs for executables only if there is the -brtl\n    # linker flag in LDFLAGS as well, or --with-aix-soname=svr4 only.\n    # To allow for filename-based versioning support, we need to create\n    # libNAME.so.V as an archive file, containing:\n    # *) an Import File, referring to the versioned filename of the\n    #    archive as well as the shared archive member, telling the\n    #    bitwidth (32 or 64) of that shared object, and providing the\n    #    list of exported symbols of that shared object, eventually\n    #    decorated with the 'weak' keyword\n    # *) the shared object with the F_LOADONLY flag set, to really avoid\n    #    it being seen by the linker.\n    # At run time we better use the real file rather than another symlink,\n    # but for link time we create the symlink libNAME.so -> libNAME.so.V\n\n    case $with_aix_soname,$aix_use_runtimelinking in\n    # AIX (on Power*) has no versioning support, so currently we cannot hardcode correct\n    # soname into executable. Probably we can add versioning support to\n    # collect2, so additional links can be useful in future.\n    aix,yes) # traditional libtool\n      dynamic_linker='AIX unversionable lib.so'\n      # If using run time linking (on AIX 4.2 or later) use lib<name>.so\n      # instead of lib<name>.a to let people know that these are not\n      # typical AIX shared libraries.\n      library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n      ;;\n    aix,no) # traditional AIX only\n      dynamic_linker='AIX lib.a[(]lib.so.V[)]'\n      # We preserve .a as extension for shared libraries through AIX4.2\n      # and later when we are not doing run time linking.\n      library_names_spec='$libname$release.a $libname.a'\n      soname_spec='$libname$release$shared_ext$major'\n      ;;\n    svr4,*) # full svr4 only\n      dynamic_linker=\"AIX lib.so.V[(]$shared_archive_member_spec.o[)]\"\n      library_names_spec='$libname$release$shared_ext$major $libname$shared_ext'\n      # We do not specify a path in Import Files, so LIBPATH fires.\n      shlibpath_overrides_runpath=yes\n      ;;\n    *,yes) # both, prefer svr4\n      dynamic_linker=\"AIX lib.so.V[(]$shared_archive_member_spec.o[)], lib.a[(]lib.so.V[)]\"\n      library_names_spec='$libname$release$shared_ext$major $libname$shared_ext'\n      # unpreferred sharedlib libNAME.a needs extra handling\n      postinstall_cmds='test -n \"$linkname\" || linkname=\"$realname\"~func_stripname \"\" \".so\" \"$linkname\"~$install_shared_prog \"$dir/$func_stripname_result.$libext\" \"$destdir/$func_stripname_result.$libext\"~test -z \"$tstripme\" || test -z \"$striplib\" || $striplib \"$destdir/$func_stripname_result.$libext\"'\n      postuninstall_cmds='for n in $library_names $old_library; do :; done~func_stripname \"\" \".so\" \"$n\"~test \"$func_stripname_result\" = \"$n\" || func_append rmfiles \" $odir/$func_stripname_result.$libext\"'\n      # We do not specify a path in Import Files, so LIBPATH fires.\n      shlibpath_overrides_runpath=yes\n      ;;\n    *,no) # both, prefer aix\n      dynamic_linker=\"AIX lib.a[(]lib.so.V[)], lib.so.V[(]$shared_archive_member_spec.o[)]\"\n      library_names_spec='$libname$release.a $libname.a'\n      soname_spec='$libname$release$shared_ext$major'\n      # unpreferred sharedlib libNAME.so.V and symlink libNAME.so need extra handling\n      postinstall_cmds='test -z \"$dlname\" || $install_shared_prog $dir/$dlname $destdir/$dlname~test -z \"$tstripme\" || test -z \"$striplib\" || $striplib $destdir/$dlname~test -n \"$linkname\" || linkname=$realname~func_stripname \"\" \".a\" \"$linkname\"~(cd \"$destdir\" && $LN_S -f $dlname $func_stripname_result.so)'\n      postuninstall_cmds='test -z \"$dlname\" || func_append rmfiles \" $odir/$dlname\"~for n in $old_library $library_names; do :; done~func_stripname \"\" \".a\" \"$n\"~func_append rmfiles \" $odir/$func_stripname_result.so\"'\n      ;;\n    esac\n    shlibpath_var=LIBPATH\n  fi\n  ;;\n\namigaos*)\n  case $host_cpu in\n  powerpc)\n    # Since July 2007 AmigaOS4 officially supports .so libraries.\n    # When compiling the executable, add -use-dynld -Lsobjs: to the compileline.\n    library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n    ;;\n  m68k)\n    library_names_spec='$libname.ixlibrary $libname.a'\n    # Create ${libname}_ixlibrary.a entries in /sys/libs.\n    finish_eval='for lib in `ls $libdir/*.ixlibrary 2>/dev/null`; do libname=`func_echo_all \"$lib\" | $SED '\\''s%^.*/\\([[^/]]*\\)\\.ixlibrary$%\\1%'\\''`; $RM /sys/libs/${libname}_ixlibrary.a; $show \"cd /sys/libs && $LN_S $lib ${libname}_ixlibrary.a\"; cd /sys/libs && $LN_S $lib ${libname}_ixlibrary.a || exit 1; done'\n    ;;\n  esac\n  ;;\n\nbeos*)\n  library_names_spec='$libname$shared_ext'\n  dynamic_linker=\"$host_os ld.so\"\n  shlibpath_var=LIBRARY_PATH\n  ;;\n\nbsdi[[45]]*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  need_version=no\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  finish_cmds='PATH=\"\\$PATH:/sbin\" ldconfig $libdir'\n  shlibpath_var=LD_LIBRARY_PATH\n  sys_lib_search_path_spec=\"/shlib /usr/lib /usr/X11/lib /usr/contrib/lib /lib /usr/local/lib\"\n  sys_lib_dlsearch_path_spec=\"/shlib /usr/lib /usr/local/lib\"\n  # the default ld.so.conf also contains /usr/contrib/lib and\n  # /usr/X11R6/lib (/usr/X11 is a link to /usr/X11R6), but let us allow\n  # libtool to hard-code these into programs\n  ;;\n\ncygwin* | mingw* | pw32* | cegcc*)\n  version_type=windows\n  shrext_cmds=.dll\n  need_version=no\n  need_lib_prefix=no\n\n  case $GCC,$cc_basename in\n  yes,*)\n    # gcc\n    library_names_spec='$libname.dll.a'\n    # DLL is installed to $(libdir)/../bin by postinstall_cmds\n    postinstall_cmds='base_file=`basename \\$file`~\n      dlpath=`$SHELL 2>&1 -c '\\''. $dir/'\\''\\$base_file'\\''i; echo \\$dlname'\\''`~\n      dldir=$destdir/`dirname \\$dlpath`~\n      test -d \\$dldir || mkdir -p \\$dldir~\n      $install_prog $dir/$dlname \\$dldir/$dlname~\n      chmod a+x \\$dldir/$dlname~\n      if test -n '\\''$stripme'\\'' && test -n '\\''$striplib'\\''; then\n        eval '\\''$striplib \\$dldir/$dlname'\\'' || exit \\$?;\n      fi'\n    postuninstall_cmds='dldll=`$SHELL 2>&1 -c '\\''. $file; echo \\$dlname'\\''`~\n      dlpath=$dir/\\$dldll~\n       $RM \\$dlpath'\n    shlibpath_overrides_runpath=yes\n\n    case $host_os in\n    cygwin*)\n      # Cygwin DLLs use 'cyg' prefix rather than 'lib'\n      soname_spec='`echo $libname | sed -e 's/^lib/cyg/'``echo $release | $SED -e 's/[[.]]/-/g'`$versuffix$shared_ext'\nm4_if([$1], [],[\n      sys_lib_search_path_spec=\"$sys_lib_search_path_spec /usr/lib/w32api\"])\n      ;;\n    mingw* | cegcc*)\n      # MinGW DLLs use traditional 'lib' prefix\n      soname_spec='$libname`echo $release | $SED -e 's/[[.]]/-/g'`$versuffix$shared_ext'\n      ;;\n    pw32*)\n      # pw32 DLLs use 'pw' prefix rather than 'lib'\n      library_names_spec='`echo $libname | sed -e 's/^lib/pw/'``echo $release | $SED -e 's/[[.]]/-/g'`$versuffix$shared_ext'\n      ;;\n    esac\n    dynamic_linker='Win32 ld.exe'\n    ;;\n\n  *,cl*)\n    # Native MSVC\n    libname_spec='$name'\n    soname_spec='$libname`echo $release | $SED -e 's/[[.]]/-/g'`$versuffix$shared_ext'\n    library_names_spec='$libname.dll.lib'\n\n    case $build_os in\n    mingw*)\n      sys_lib_search_path_spec=\n      lt_save_ifs=$IFS\n      IFS=';'\n      for lt_path in $LIB\n      do\n        IFS=$lt_save_ifs\n        # Let DOS variable expansion print the short 8.3 style file name.\n        lt_path=`cd \"$lt_path\" 2>/dev/null && cmd //C \"for %i in (\".\") do @echo %~si\"`\n        sys_lib_search_path_spec=\"$sys_lib_search_path_spec $lt_path\"\n      done\n      IFS=$lt_save_ifs\n      # Convert to MSYS style.\n      sys_lib_search_path_spec=`$ECHO \"$sys_lib_search_path_spec\" | sed -e 's|\\\\\\\\|/|g' -e 's| \\\\([[a-zA-Z]]\\\\):| /\\\\1|g' -e 's|^ ||'`\n      ;;\n    cygwin*)\n      # Convert to unix form, then to dos form, then back to unix form\n      # but this time dos style (no spaces!) so that the unix form looks\n      # like /cygdrive/c/PROGRA~1:/cygdr...\n      sys_lib_search_path_spec=`cygpath --path --unix \"$LIB\"`\n      sys_lib_search_path_spec=`cygpath --path --dos \"$sys_lib_search_path_spec\" 2>/dev/null`\n      sys_lib_search_path_spec=`cygpath --path --unix \"$sys_lib_search_path_spec\" | $SED -e \"s/$PATH_SEPARATOR/ /g\"`\n      ;;\n    *)\n      sys_lib_search_path_spec=$LIB\n      if $ECHO \"$sys_lib_search_path_spec\" | [$GREP ';[c-zC-Z]:/' >/dev/null]; then\n        # It is most probably a Windows format PATH.\n        sys_lib_search_path_spec=`$ECHO \"$sys_lib_search_path_spec\" | $SED -e 's/;/ /g'`\n      else\n        sys_lib_search_path_spec=`$ECHO \"$sys_lib_search_path_spec\" | $SED -e \"s/$PATH_SEPARATOR/ /g\"`\n      fi\n      # FIXME: find the short name or the path components, as spaces are\n      # common. (e.g. \"Program Files\" -> \"PROGRA~1\")\n      ;;\n    esac\n\n    # DLL is installed to $(libdir)/../bin by postinstall_cmds\n    postinstall_cmds='base_file=`basename \\$file`~\n      dlpath=`$SHELL 2>&1 -c '\\''. $dir/'\\''\\$base_file'\\''i; echo \\$dlname'\\''`~\n      dldir=$destdir/`dirname \\$dlpath`~\n      test -d \\$dldir || mkdir -p \\$dldir~\n      $install_prog $dir/$dlname \\$dldir/$dlname'\n    postuninstall_cmds='dldll=`$SHELL 2>&1 -c '\\''. $file; echo \\$dlname'\\''`~\n      dlpath=$dir/\\$dldll~\n       $RM \\$dlpath'\n    shlibpath_overrides_runpath=yes\n    dynamic_linker='Win32 link.exe'\n    ;;\n\n  *)\n    # Assume MSVC wrapper\n    library_names_spec='$libname`echo $release | $SED -e 's/[[.]]/-/g'`$versuffix$shared_ext $libname.lib'\n    dynamic_linker='Win32 ld.exe'\n    ;;\n  esac\n  # FIXME: first we should search . and the directory the executable is in\n  shlibpath_var=PATH\n  ;;\n\ndarwin* | rhapsody*)\n  dynamic_linker=\"$host_os dyld\"\n  version_type=darwin\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='$libname$release$major$shared_ext $libname$shared_ext'\n  soname_spec='$libname$release$major$shared_ext'\n  shlibpath_overrides_runpath=yes\n  shlibpath_var=DYLD_LIBRARY_PATH\n  shrext_cmds='`test .$module = .yes && echo .so || echo .dylib`'\nm4_if([$1], [],[\n  sys_lib_search_path_spec=\"$sys_lib_search_path_spec /usr/local/lib\"])\n  sys_lib_dlsearch_path_spec='/usr/local/lib /lib /usr/lib'\n  ;;\n\ndgux*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  shlibpath_var=LD_LIBRARY_PATH\n  ;;\n\nfreebsd* | dragonfly*)\n  # DragonFly does not have aout.  When/if they implement a new\n  # versioning mechanism, adjust this.\n  if test -x /usr/bin/objformat; then\n    objformat=`/usr/bin/objformat`\n  else\n    case $host_os in\n    freebsd[[23]].*) objformat=aout ;;\n    *) objformat=elf ;;\n    esac\n  fi\n  version_type=freebsd-$objformat\n  case $version_type in\n    freebsd-elf*)\n      library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n      soname_spec='$libname$release$shared_ext$major'\n      need_version=no\n      need_lib_prefix=no\n      ;;\n    freebsd-*)\n      library_names_spec='$libname$release$shared_ext$versuffix $libname$shared_ext$versuffix'\n      need_version=yes\n      ;;\n  esac\n  shlibpath_var=LD_LIBRARY_PATH\n  case $host_os in\n  freebsd2.*)\n    shlibpath_overrides_runpath=yes\n    ;;\n  freebsd3.[[01]]* | freebsdelf3.[[01]]*)\n    shlibpath_overrides_runpath=yes\n    hardcode_into_libs=yes\n    ;;\n  freebsd3.[[2-9]]* | freebsdelf3.[[2-9]]* | \\\n  freebsd4.[[0-5]] | freebsdelf4.[[0-5]] | freebsd4.1.1 | freebsdelf4.1.1)\n    shlibpath_overrides_runpath=no\n    hardcode_into_libs=yes\n    ;;\n  *) # from 4.6 on, and DragonFly\n    shlibpath_overrides_runpath=yes\n    hardcode_into_libs=yes\n    ;;\n  esac\n  ;;\n\nhaiku*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  need_lib_prefix=no\n  need_version=no\n  dynamic_linker=\"$host_os runtime_loader\"\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  shlibpath_var=LIBRARY_PATH\n  shlibpath_overrides_runpath=no\n  sys_lib_dlsearch_path_spec='/boot/home/config/lib /boot/common/lib /boot/system/lib'\n  hardcode_into_libs=yes\n  ;;\n\nhpux9* | hpux10* | hpux11*)\n  # Give a soname corresponding to the major version so that dld.sl refuses to\n  # link against other versions.\n  version_type=sunos\n  need_lib_prefix=no\n  need_version=no\n  case $host_cpu in\n  ia64*)\n    shrext_cmds='.so'\n    hardcode_into_libs=yes\n    dynamic_linker=\"$host_os dld.so\"\n    shlibpath_var=LD_LIBRARY_PATH\n    shlibpath_overrides_runpath=yes # Unless +noenvvar is specified.\n    library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n    soname_spec='$libname$release$shared_ext$major'\n    if test 32 = \"$HPUX_IA64_MODE\"; then\n      sys_lib_search_path_spec=\"/usr/lib/hpux32 /usr/local/lib/hpux32 /usr/local/lib\"\n      sys_lib_dlsearch_path_spec=/usr/lib/hpux32\n    else\n      sys_lib_search_path_spec=\"/usr/lib/hpux64 /usr/local/lib/hpux64\"\n      sys_lib_dlsearch_path_spec=/usr/lib/hpux64\n    fi\n    ;;\n  hppa*64*)\n    shrext_cmds='.sl'\n    hardcode_into_libs=yes\n    dynamic_linker=\"$host_os dld.sl\"\n    shlibpath_var=LD_LIBRARY_PATH # How should we handle SHLIB_PATH\n    shlibpath_overrides_runpath=yes # Unless +noenvvar is specified.\n    library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n    soname_spec='$libname$release$shared_ext$major'\n    sys_lib_search_path_spec=\"/usr/lib/pa20_64 /usr/ccs/lib/pa20_64\"\n    sys_lib_dlsearch_path_spec=$sys_lib_search_path_spec\n    ;;\n  *)\n    shrext_cmds='.sl'\n    dynamic_linker=\"$host_os dld.sl\"\n    shlibpath_var=SHLIB_PATH\n    shlibpath_overrides_runpath=no # +s is required to enable SHLIB_PATH\n    library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n    soname_spec='$libname$release$shared_ext$major'\n    ;;\n  esac\n  # HP-UX runs *really* slowly unless shared libraries are mode 555, ...\n  postinstall_cmds='chmod 555 $lib'\n  # or fails outright, so override atomically:\n  install_override_mode=555\n  ;;\n\ninterix[[3-9]]*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  dynamic_linker='Interix 3.x ld.so.1 (PE, like ELF)'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=no\n  hardcode_into_libs=yes\n  ;;\n\nirix5* | irix6* | nonstopux*)\n  case $host_os in\n    nonstopux*) version_type=nonstopux ;;\n    *)\n\tif test yes = \"$lt_cv_prog_gnu_ld\"; then\n\t\tversion_type=linux # correct to gnu/linux during the next big refactor\n\telse\n\t\tversion_type=irix\n\tfi ;;\n  esac\n  need_lib_prefix=no\n  need_version=no\n  soname_spec='$libname$release$shared_ext$major'\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$release$shared_ext $libname$shared_ext'\n  case $host_os in\n  irix5* | nonstopux*)\n    libsuff= shlibsuff=\n    ;;\n  *)\n    case $LD in # libtool.m4 will add one of these switches to LD\n    *-32|*\"-32 \"|*-melf32bsmip|*\"-melf32bsmip \")\n      libsuff= shlibsuff= libmagic=32-bit;;\n    *-n32|*\"-n32 \"|*-melf32bmipn32|*\"-melf32bmipn32 \")\n      libsuff=32 shlibsuff=N32 libmagic=N32;;\n    *-64|*\"-64 \"|*-melf64bmip|*\"-melf64bmip \")\n      libsuff=64 shlibsuff=64 libmagic=64-bit;;\n    *) libsuff= shlibsuff= libmagic=never-match;;\n    esac\n    ;;\n  esac\n  shlibpath_var=LD_LIBRARY${shlibsuff}_PATH\n  shlibpath_overrides_runpath=no\n  sys_lib_search_path_spec=\"/usr/lib$libsuff /lib$libsuff /usr/local/lib$libsuff\"\n  sys_lib_dlsearch_path_spec=\"/usr/lib$libsuff /lib$libsuff\"\n  hardcode_into_libs=yes\n  ;;\n\n# No shared lib support for Linux oldld, aout, or coff.\nlinux*oldld* | linux*aout* | linux*coff*)\n  dynamic_linker=no\n  ;;\n\nlinux*android*)\n  version_type=none # Android doesn't support versioned libraries.\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='$libname$release$shared_ext'\n  soname_spec='$libname$release$shared_ext'\n  finish_cmds=\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=yes\n\n  # This implies no fast_install, which is unacceptable.\n  # Some rework will be needed to allow for fast_install\n  # before this can be enabled.\n  hardcode_into_libs=yes\n\n  dynamic_linker='Android linker'\n  # Don't embed -rpath directories since the linker doesn't support them.\n  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n  ;;\n\n# This must be glibc/ELF.\nlinux* | k*bsd*-gnu | kopensolaris*-gnu | gnu*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  finish_cmds='PATH=\"\\$PATH:/sbin\" ldconfig -n $libdir'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=no\n\n  # Some binutils ld are patched to set DT_RUNPATH\n  AC_CACHE_VAL([lt_cv_shlibpath_overrides_runpath],\n    [lt_cv_shlibpath_overrides_runpath=no\n    save_LDFLAGS=$LDFLAGS\n    save_libdir=$libdir\n    eval \"libdir=/foo; wl=\\\"$_LT_TAGVAR(lt_prog_compiler_wl, $1)\\\"; \\\n\t LDFLAGS=\\\"\\$LDFLAGS $_LT_TAGVAR(hardcode_libdir_flag_spec, $1)\\\"\"\n    AC_LINK_IFELSE([AC_LANG_PROGRAM([],[])],\n      [AS_IF([ ($OBJDUMP -p conftest$ac_exeext) 2>/dev/null | grep \"RUNPATH.*$libdir\" >/dev/null],\n\t [lt_cv_shlibpath_overrides_runpath=yes])])\n    LDFLAGS=$save_LDFLAGS\n    libdir=$save_libdir\n    ])\n  shlibpath_overrides_runpath=$lt_cv_shlibpath_overrides_runpath\n\n  # This implies no fast_install, which is unacceptable.\n  # Some rework will be needed to allow for fast_install\n  # before this can be enabled.\n  hardcode_into_libs=yes\n\n  # Ideally, we could use ldconfig to report *all* directores which are\n  # searched for libraries, however this is still not possible.  Aside from not\n  # being certain /sbin/ldconfig is available, command\n  # 'ldconfig -N -X -v | grep ^/' on 64bit Fedora does not report /usr/lib64,\n  # even though it is searched at run-time.  Try to do the best guess by\n  # appending ld.so.conf contents (and includes) to the search path.\n  if test -f /etc/ld.so.conf; then\n    lt_ld_extra=`awk '/^include / { system(sprintf(\"cd /etc; cat %s 2>/dev/null\", \\[$]2)); skip = 1; } { if (!skip) print \\[$]0; skip = 0; }' < /etc/ld.so.conf | $SED -e 's/#.*//;/^[\t ]*hwcap[\t ]/d;s/[:,\t]/ /g;s/=[^=]*$//;s/=[^= ]* / /g;s/\"//g;/^$/d' | tr '\\n' ' '`\n    sys_lib_dlsearch_path_spec=\"/lib /usr/lib $lt_ld_extra\"\n  fi\n\n  # We used to test for /lib/ld.so.1 and disable shared libraries on\n  # powerpc, because MkLinux only supported shared libraries with the\n  # GNU dynamic linker.  Since this was broken with cross compilers,\n  # most powerpc-linux boxes support dynamic linking these days and\n  # people can always --disable-shared, the test was removed, and we\n  # assume the GNU/Linux dynamic linker is in use.\n  dynamic_linker='GNU/Linux ld.so'\n  ;;\n\nnetbsd*)\n  version_type=sunos\n  need_lib_prefix=no\n  need_version=no\n  if echo __ELF__ | $CC -E - | $GREP __ELF__ >/dev/null; then\n    library_names_spec='$libname$release$shared_ext$versuffix $libname$shared_ext$versuffix'\n    finish_cmds='PATH=\"\\$PATH:/sbin\" ldconfig -m $libdir'\n    dynamic_linker='NetBSD (a.out) ld.so'\n  else\n    library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n    soname_spec='$libname$release$shared_ext$major'\n    dynamic_linker='NetBSD ld.elf_so'\n  fi\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=yes\n  hardcode_into_libs=yes\n  ;;\n\nnewsos6)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=yes\n  ;;\n\n*nto* | *qnx*)\n  version_type=qnx\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=no\n  hardcode_into_libs=yes\n  dynamic_linker='ldqnx.so'\n  ;;\n\nopenbsd* | bitrig*)\n  version_type=sunos\n  sys_lib_dlsearch_path_spec=/usr/lib\n  need_lib_prefix=no\n  if test -z \"`echo __ELF__ | $CC -E - | $GREP __ELF__`\"; then\n    need_version=no\n  else\n    need_version=yes\n  fi\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$shared_ext$versuffix'\n  finish_cmds='PATH=\"\\$PATH:/sbin\" ldconfig -m $libdir'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=yes\n  ;;\n\nos2*)\n  libname_spec='$name'\n  version_type=windows\n  shrext_cmds=.dll\n  need_version=no\n  need_lib_prefix=no\n  # OS/2 can only load a DLL with a base name of 8 characters or less.\n  soname_spec='`test -n \"$os2dllname\" && libname=\"$os2dllname\";\n    v=$($ECHO $release$versuffix | tr -d .-);\n    n=$($ECHO $libname | cut -b -$((8 - ${#v})) | tr . _);\n    $ECHO $n$v`$shared_ext'\n  library_names_spec='${libname}_dll.$libext'\n  dynamic_linker='OS/2 ld.exe'\n  shlibpath_var=BEGINLIBPATH\n  sys_lib_search_path_spec=\"/lib /usr/lib /usr/local/lib\"\n  sys_lib_dlsearch_path_spec=$sys_lib_search_path_spec\n  postinstall_cmds='base_file=`basename \\$file`~\n    dlpath=`$SHELL 2>&1 -c '\\''. $dir/'\\''\\$base_file'\\''i; $ECHO \\$dlname'\\''`~\n    dldir=$destdir/`dirname \\$dlpath`~\n    test -d \\$dldir || mkdir -p \\$dldir~\n    $install_prog $dir/$dlname \\$dldir/$dlname~\n    chmod a+x \\$dldir/$dlname~\n    if test -n '\\''$stripme'\\'' && test -n '\\''$striplib'\\''; then\n      eval '\\''$striplib \\$dldir/$dlname'\\'' || exit \\$?;\n    fi'\n  postuninstall_cmds='dldll=`$SHELL 2>&1 -c '\\''. $file; $ECHO \\$dlname'\\''`~\n    dlpath=$dir/\\$dldll~\n    $RM \\$dlpath'\n  ;;\n\nosf3* | osf4* | osf5*)\n  version_type=osf\n  need_lib_prefix=no\n  need_version=no\n  soname_spec='$libname$release$shared_ext$major'\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  shlibpath_var=LD_LIBRARY_PATH\n  sys_lib_search_path_spec=\"/usr/shlib /usr/ccs/lib /usr/lib/cmplrs/cc /usr/lib /usr/local/lib /var/shlib\"\n  sys_lib_dlsearch_path_spec=$sys_lib_search_path_spec\n  ;;\n\nrdos*)\n  dynamic_linker=no\n  ;;\n\nsolaris*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=yes\n  hardcode_into_libs=yes\n  # ldd complains unless libraries are executable\n  postinstall_cmds='chmod +x $lib'\n  ;;\n\nsunos4*)\n  version_type=sunos\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$shared_ext$versuffix'\n  finish_cmds='PATH=\"\\$PATH:/usr/etc\" ldconfig $libdir'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=yes\n  if test yes = \"$with_gnu_ld\"; then\n    need_lib_prefix=no\n  fi\n  need_version=yes\n  ;;\n\nsysv4 | sysv4.3*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  shlibpath_var=LD_LIBRARY_PATH\n  case $host_vendor in\n    sni)\n      shlibpath_overrides_runpath=no\n      need_lib_prefix=no\n      runpath_var=LD_RUN_PATH\n      ;;\n    siemens)\n      need_lib_prefix=no\n      ;;\n    motorola)\n      need_lib_prefix=no\n      need_version=no\n      shlibpath_overrides_runpath=no\n      sys_lib_search_path_spec='/lib /usr/lib /usr/ccs/lib'\n      ;;\n  esac\n  ;;\n\nsysv4*MP*)\n  if test -d /usr/nec; then\n    version_type=linux # correct to gnu/linux during the next big refactor\n    library_names_spec='$libname$shared_ext.$versuffix $libname$shared_ext.$major $libname$shared_ext'\n    soname_spec='$libname$shared_ext.$major'\n    shlibpath_var=LD_LIBRARY_PATH\n  fi\n  ;;\n\nsysv5* | sco3.2v5* | sco5v6* | unixware* | OpenUNIX* | sysv4*uw2*)\n  version_type=sco\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=yes\n  hardcode_into_libs=yes\n  if test yes = \"$with_gnu_ld\"; then\n    sys_lib_search_path_spec='/usr/local/lib /usr/gnu/lib /usr/ccs/lib /usr/lib /lib'\n  else\n    sys_lib_search_path_spec='/usr/ccs/lib /usr/lib'\n    case $host_os in\n      sco3.2v5*)\n        sys_lib_search_path_spec=\"$sys_lib_search_path_spec /lib\"\n\t;;\n    esac\n  fi\n  sys_lib_dlsearch_path_spec='/usr/lib'\n  ;;\n\ntpf*)\n  # TPF is a cross-target only.  Preferred cross-host = GNU/Linux.\n  version_type=linux # correct to gnu/linux during the next big refactor\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=no\n  hardcode_into_libs=yes\n  ;;\n\nuts4*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  shlibpath_var=LD_LIBRARY_PATH\n  ;;\n\n*)\n  dynamic_linker=no\n  ;;\nesac\nAC_MSG_RESULT([$dynamic_linker])\ntest no = \"$dynamic_linker\" && can_build_shared=no\n\nvariables_saved_for_relink=\"PATH $shlibpath_var $runpath_var\"\nif test yes = \"$GCC\"; then\n  variables_saved_for_relink=\"$variables_saved_for_relink GCC_EXEC_PREFIX COMPILER_PATH LIBRARY_PATH\"\nfi\n\nif test set = \"${lt_cv_sys_lib_search_path_spec+set}\"; then\n  sys_lib_search_path_spec=$lt_cv_sys_lib_search_path_spec\nfi\n\nif test set = \"${lt_cv_sys_lib_dlsearch_path_spec+set}\"; then\n  sys_lib_dlsearch_path_spec=$lt_cv_sys_lib_dlsearch_path_spec\nfi\n\n# remember unaugmented sys_lib_dlsearch_path content for libtool script decls...\nconfigure_time_dlsearch_path=$sys_lib_dlsearch_path_spec\n\n# ... but it needs LT_SYS_LIBRARY_PATH munging for other configure-time code\nfunc_munge_path_list sys_lib_dlsearch_path_spec \"$LT_SYS_LIBRARY_PATH\"\n\n# to be used as default LT_SYS_LIBRARY_PATH value in generated libtool\nconfigure_time_lt_sys_library_path=$LT_SYS_LIBRARY_PATH\n\n_LT_DECL([], [variables_saved_for_relink], [1],\n    [Variables whose values should be saved in libtool wrapper scripts and\n    restored at link time])\n_LT_DECL([], [need_lib_prefix], [0],\n    [Do we need the \"lib\" prefix for modules?])\n_LT_DECL([], [need_version], [0], [Do we need a version for libraries?])\n_LT_DECL([], [version_type], [0], [Library versioning type])\n_LT_DECL([], [runpath_var], [0],  [Shared library runtime path variable])\n_LT_DECL([], [shlibpath_var], [0],[Shared library path variable])\n_LT_DECL([], [shlibpath_overrides_runpath], [0],\n    [Is shlibpath searched before the hard-coded library search path?])\n_LT_DECL([], [libname_spec], [1], [Format of library name prefix])\n_LT_DECL([], [library_names_spec], [1],\n    [[List of archive names.  First name is the real one, the rest are links.\n    The last name is the one that the linker finds with -lNAME]])\n_LT_DECL([], [soname_spec], [1],\n    [[The coded name of the library, if different from the real name]])\n_LT_DECL([], [install_override_mode], [1],\n    [Permission mode override for installation of shared libraries])\n_LT_DECL([], [postinstall_cmds], [2],\n    [Command to use after installation of a shared archive])\n_LT_DECL([], [postuninstall_cmds], [2],\n    [Command to use after uninstallation of a shared archive])\n_LT_DECL([], [finish_cmds], [2],\n    [Commands used to finish a libtool library installation in a directory])\n_LT_DECL([], [finish_eval], [1],\n    [[As \"finish_cmds\", except a single script fragment to be evaled but\n    not shown]])\n_LT_DECL([], [hardcode_into_libs], [0],\n    [Whether we should hardcode library paths into libraries])\n_LT_DECL([], [sys_lib_search_path_spec], [2],\n    [Compile-time system search path for libraries])\n_LT_DECL([sys_lib_dlsearch_path_spec], [configure_time_dlsearch_path], [2],\n    [Detected run-time system search path for libraries])\n_LT_DECL([], [configure_time_lt_sys_library_path], [2],\n    [Explicit LT_SYS_LIBRARY_PATH set during ./configure time])\n])# _LT_SYS_DYNAMIC_LINKER\n\n\n# _LT_PATH_TOOL_PREFIX(TOOL)\n# --------------------------\n# find a file program that can recognize shared library\nAC_DEFUN([_LT_PATH_TOOL_PREFIX],\n[m4_require([_LT_DECL_EGREP])dnl\nAC_MSG_CHECKING([for $1])\nAC_CACHE_VAL(lt_cv_path_MAGIC_CMD,\n[case $MAGIC_CMD in\n[[\\\\/*] |  ?:[\\\\/]*])\n  lt_cv_path_MAGIC_CMD=$MAGIC_CMD # Let the user override the test with a path.\n  ;;\n*)\n  lt_save_MAGIC_CMD=$MAGIC_CMD\n  lt_save_ifs=$IFS; IFS=$PATH_SEPARATOR\ndnl $ac_dummy forces splitting on constant user-supplied paths.\ndnl POSIX.2 word splitting is done only on the output of word expansions,\ndnl not every word.  This closes a longstanding sh security hole.\n  ac_dummy=\"m4_if([$2], , $PATH, [$2])\"\n  for ac_dir in $ac_dummy; do\n    IFS=$lt_save_ifs\n    test -z \"$ac_dir\" && ac_dir=.\n    if test -f \"$ac_dir/$1\"; then\n      lt_cv_path_MAGIC_CMD=$ac_dir/\"$1\"\n      if test -n \"$file_magic_test_file\"; then\n\tcase $deplibs_check_method in\n\t\"file_magic \"*)\n\t  file_magic_regex=`expr \"$deplibs_check_method\" : \"file_magic \\(.*\\)\"`\n\t  MAGIC_CMD=$lt_cv_path_MAGIC_CMD\n\t  if eval $file_magic_cmd \\$file_magic_test_file 2> /dev/null |\n\t    $EGREP \"$file_magic_regex\" > /dev/null; then\n\t    :\n\t  else\n\t    cat <<_LT_EOF 1>&2\n\n*** Warning: the command libtool uses to detect shared libraries,\n*** $file_magic_cmd, produces output that libtool cannot recognize.\n*** The result is that libtool may fail to recognize shared libraries\n*** as such.  This will affect the creation of libtool libraries that\n*** depend on shared libraries, but programs linked with such libtool\n*** libraries will work regardless of this problem.  Nevertheless, you\n*** may want to report the problem to your system manager and/or to\n*** bug-libtool@gnu.org\n\n_LT_EOF\n\t  fi ;;\n\tesac\n      fi\n      break\n    fi\n  done\n  IFS=$lt_save_ifs\n  MAGIC_CMD=$lt_save_MAGIC_CMD\n  ;;\nesac])\nMAGIC_CMD=$lt_cv_path_MAGIC_CMD\nif test -n \"$MAGIC_CMD\"; then\n  AC_MSG_RESULT($MAGIC_CMD)\nelse\n  AC_MSG_RESULT(no)\nfi\n_LT_DECL([], [MAGIC_CMD], [0],\n\t [Used to examine libraries when file_magic_cmd begins with \"file\"])dnl\n])# _LT_PATH_TOOL_PREFIX\n\n# Old name:\nAU_ALIAS([AC_PATH_TOOL_PREFIX], [_LT_PATH_TOOL_PREFIX])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_PATH_TOOL_PREFIX], [])\n\n\n# _LT_PATH_MAGIC\n# --------------\n# find a file program that can recognize a shared library\nm4_defun([_LT_PATH_MAGIC],\n[_LT_PATH_TOOL_PREFIX(${ac_tool_prefix}file, /usr/bin$PATH_SEPARATOR$PATH)\nif test -z \"$lt_cv_path_MAGIC_CMD\"; then\n  if test -n \"$ac_tool_prefix\"; then\n    _LT_PATH_TOOL_PREFIX(file, /usr/bin$PATH_SEPARATOR$PATH)\n  else\n    MAGIC_CMD=:\n  fi\nfi\n])# _LT_PATH_MAGIC\n\n\n# LT_PATH_LD\n# ----------\n# find the pathname to the GNU or non-GNU linker\nAC_DEFUN([LT_PATH_LD],\n[AC_REQUIRE([AC_PROG_CC])dnl\nAC_REQUIRE([AC_CANONICAL_HOST])dnl\nAC_REQUIRE([AC_CANONICAL_BUILD])dnl\nm4_require([_LT_DECL_SED])dnl\nm4_require([_LT_DECL_EGREP])dnl\nm4_require([_LT_PROG_ECHO_BACKSLASH])dnl\n\nAC_ARG_WITH([gnu-ld],\n    [AS_HELP_STRING([--with-gnu-ld],\n\t[assume the C compiler uses GNU ld @<:@default=no@:>@])],\n    [test no = \"$withval\" || with_gnu_ld=yes],\n    [with_gnu_ld=no])dnl\n\nac_prog=ld\nif test yes = \"$GCC\"; then\n  # Check if gcc -print-prog-name=ld gives a path.\n  AC_MSG_CHECKING([for ld used by $CC])\n  case $host in\n  *-*-mingw*)\n    # gcc leaves a trailing carriage return, which upsets mingw\n    ac_prog=`($CC -print-prog-name=ld) 2>&5 | tr -d '\\015'` ;;\n  *)\n    ac_prog=`($CC -print-prog-name=ld) 2>&5` ;;\n  esac\n  case $ac_prog in\n    # Accept absolute paths.\n    [[\\\\/]]* | ?:[[\\\\/]]*)\n      re_direlt='/[[^/]][[^/]]*/\\.\\./'\n      # Canonicalize the pathname of ld\n      ac_prog=`$ECHO \"$ac_prog\"| $SED 's%\\\\\\\\%/%g'`\n      while $ECHO \"$ac_prog\" | $GREP \"$re_direlt\" > /dev/null 2>&1; do\n\tac_prog=`$ECHO $ac_prog| $SED \"s%$re_direlt%/%\"`\n      done\n      test -z \"$LD\" && LD=$ac_prog\n      ;;\n  \"\")\n    # If it fails, then pretend we aren't using GCC.\n    ac_prog=ld\n    ;;\n  *)\n    # If it is relative, then search for the first ld in PATH.\n    with_gnu_ld=unknown\n    ;;\n  esac\nelif test yes = \"$with_gnu_ld\"; then\n  AC_MSG_CHECKING([for GNU ld])\nelse\n  AC_MSG_CHECKING([for non-GNU ld])\nfi\nAC_CACHE_VAL(lt_cv_path_LD,\n[if test -z \"$LD\"; then\n  lt_save_ifs=$IFS; IFS=$PATH_SEPARATOR\n  for ac_dir in $PATH; do\n    IFS=$lt_save_ifs\n    test -z \"$ac_dir\" && ac_dir=.\n    if test -f \"$ac_dir/$ac_prog\" || test -f \"$ac_dir/$ac_prog$ac_exeext\"; then\n      lt_cv_path_LD=$ac_dir/$ac_prog\n      # Check to see if the program is GNU ld.  I'd rather use --version,\n      # but apparently some variants of GNU ld only accept -v.\n      # Break only if it was the GNU/non-GNU ld that we prefer.\n      case `\"$lt_cv_path_LD\" -v 2>&1 </dev/null` in\n      *GNU* | *'with BFD'*)\n\ttest no != \"$with_gnu_ld\" && break\n\t;;\n      *)\n\ttest yes != \"$with_gnu_ld\" && break\n\t;;\n      esac\n    fi\n  done\n  IFS=$lt_save_ifs\nelse\n  lt_cv_path_LD=$LD # Let the user override the test with a path.\nfi])\nLD=$lt_cv_path_LD\nif test -n \"$LD\"; then\n  AC_MSG_RESULT($LD)\nelse\n  AC_MSG_RESULT(no)\nfi\ntest -z \"$LD\" && AC_MSG_ERROR([no acceptable ld found in \\$PATH])\n_LT_PATH_LD_GNU\nAC_SUBST([LD])\n\n_LT_TAGDECL([], [LD], [1], [The linker used to build libraries])\n])# LT_PATH_LD\n\n# Old names:\nAU_ALIAS([AM_PROG_LD], [LT_PATH_LD])\nAU_ALIAS([AC_PROG_LD], [LT_PATH_LD])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AM_PROG_LD], [])\ndnl AC_DEFUN([AC_PROG_LD], [])\n\n\n# _LT_PATH_LD_GNU\n#- --------------\nm4_defun([_LT_PATH_LD_GNU],\n[AC_CACHE_CHECK([if the linker ($LD) is GNU ld], lt_cv_prog_gnu_ld,\n[# I'd rather use --version here, but apparently some GNU lds only accept -v.\ncase `$LD -v 2>&1 </dev/null` in\n*GNU* | *'with BFD'*)\n  lt_cv_prog_gnu_ld=yes\n  ;;\n*)\n  lt_cv_prog_gnu_ld=no\n  ;;\nesac])\nwith_gnu_ld=$lt_cv_prog_gnu_ld\n])# _LT_PATH_LD_GNU\n\n\n# _LT_CMD_RELOAD\n# --------------\n# find reload flag for linker\n#   -- PORTME Some linkers may need a different reload flag.\nm4_defun([_LT_CMD_RELOAD],\n[AC_CACHE_CHECK([for $LD option to reload object files],\n  lt_cv_ld_reload_flag,\n  [lt_cv_ld_reload_flag='-r'])\nreload_flag=$lt_cv_ld_reload_flag\ncase $reload_flag in\n\"\" | \" \"*) ;;\n*) reload_flag=\" $reload_flag\" ;;\nesac\nreload_cmds='$LD$reload_flag -o $output$reload_objs'\ncase $host_os in\n  cygwin* | mingw* | pw32* | cegcc*)\n    if test yes != \"$GCC\"; then\n      reload_cmds=false\n    fi\n    ;;\n  darwin*)\n    if test yes = \"$GCC\"; then\n      reload_cmds='$LTCC $LTCFLAGS -nostdlib $wl-r -o $output$reload_objs'\n    else\n      reload_cmds='$LD$reload_flag -o $output$reload_objs'\n    fi\n    ;;\nesac\n_LT_TAGDECL([], [reload_flag], [1], [How to create reloadable object files])dnl\n_LT_TAGDECL([], [reload_cmds], [2])dnl\n])# _LT_CMD_RELOAD\n\n\n# _LT_PATH_DD\n# -----------\n# find a working dd\nm4_defun([_LT_PATH_DD],\n[AC_CACHE_CHECK([for a working dd], [ac_cv_path_lt_DD],\n[printf 0123456789abcdef0123456789abcdef >conftest.i\ncat conftest.i conftest.i >conftest2.i\n: ${lt_DD:=$DD}\nAC_PATH_PROGS_FEATURE_CHECK([lt_DD], [dd],\n[if \"$ac_path_lt_DD\" bs=32 count=1 <conftest2.i >conftest.out 2>/dev/null; then\n  cmp -s conftest.i conftest.out \\\n  && ac_cv_path_lt_DD=\"$ac_path_lt_DD\" ac_path_lt_DD_found=:\nfi])\nrm -f conftest.i conftest2.i conftest.out])\n])# _LT_PATH_DD\n\n\n# _LT_CMD_TRUNCATE\n# ----------------\n# find command to truncate a binary pipe\nm4_defun([_LT_CMD_TRUNCATE],\n[m4_require([_LT_PATH_DD])\nAC_CACHE_CHECK([how to truncate binary pipes], [lt_cv_truncate_bin],\n[printf 0123456789abcdef0123456789abcdef >conftest.i\ncat conftest.i conftest.i >conftest2.i\nlt_cv_truncate_bin=\nif \"$ac_cv_path_lt_DD\" bs=32 count=1 <conftest2.i >conftest.out 2>/dev/null; then\n  cmp -s conftest.i conftest.out \\\n  && lt_cv_truncate_bin=\"$ac_cv_path_lt_DD bs=4096 count=1\"\nfi\nrm -f conftest.i conftest2.i conftest.out\ntest -z \"$lt_cv_truncate_bin\" && lt_cv_truncate_bin=\"$SED -e 4q\"])\n_LT_DECL([lt_truncate_bin], [lt_cv_truncate_bin], [1],\n  [Command to truncate a binary pipe])\n])# _LT_CMD_TRUNCATE\n\n\n# _LT_CHECK_MAGIC_METHOD\n# ----------------------\n# how to check for library dependencies\n#  -- PORTME fill in with the dynamic library characteristics\nm4_defun([_LT_CHECK_MAGIC_METHOD],\n[m4_require([_LT_DECL_EGREP])\nm4_require([_LT_DECL_OBJDUMP])\nAC_CACHE_CHECK([how to recognize dependent libraries],\nlt_cv_deplibs_check_method,\n[lt_cv_file_magic_cmd='$MAGIC_CMD'\nlt_cv_file_magic_test_file=\nlt_cv_deplibs_check_method='unknown'\n# Need to set the preceding variable on all platforms that support\n# interlibrary dependencies.\n# 'none' -- dependencies not supported.\n# 'unknown' -- same as none, but documents that we really don't know.\n# 'pass_all' -- all dependencies passed with no checks.\n# 'test_compile' -- check by making test program.\n# 'file_magic [[regex]]' -- check by looking for files in library path\n# that responds to the $file_magic_cmd with a given extended regex.\n# If you have 'file' or equivalent on your system and you're not sure\n# whether 'pass_all' will *always* work, you probably want this one.\n\ncase $host_os in\naix[[4-9]]*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nbeos*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nbsdi[[45]]*)\n  lt_cv_deplibs_check_method='file_magic ELF [[0-9]][[0-9]]*-bit [[ML]]SB (shared object|dynamic lib)'\n  lt_cv_file_magic_cmd='/usr/bin/file -L'\n  lt_cv_file_magic_test_file=/shlib/libc.so\n  ;;\n\ncygwin*)\n  # func_win32_libid is a shell function defined in ltmain.sh\n  lt_cv_deplibs_check_method='file_magic ^x86 archive import|^x86 DLL'\n  lt_cv_file_magic_cmd='func_win32_libid'\n  ;;\n\nmingw* | pw32*)\n  # Base MSYS/MinGW do not provide the 'file' command needed by\n  # func_win32_libid shell function, so use a weaker test based on 'objdump',\n  # unless we find 'file', for example because we are cross-compiling.\n  if ( file / ) >/dev/null 2>&1; then\n    lt_cv_deplibs_check_method='file_magic ^x86 archive import|^x86 DLL'\n    lt_cv_file_magic_cmd='func_win32_libid'\n  else\n    # Keep this pattern in sync with the one in func_win32_libid.\n    lt_cv_deplibs_check_method='file_magic file format (pei*-i386(.*architecture: i386)?|pe-arm-wince|pe-x86-64)'\n    lt_cv_file_magic_cmd='$OBJDUMP -f'\n  fi\n  ;;\n\ncegcc*)\n  # use the weaker test based on 'objdump'. See mingw*.\n  lt_cv_deplibs_check_method='file_magic file format pe-arm-.*little(.*architecture: arm)?'\n  lt_cv_file_magic_cmd='$OBJDUMP -f'\n  ;;\n\ndarwin* | rhapsody*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nfreebsd* | dragonfly*)\n  if echo __ELF__ | $CC -E - | $GREP __ELF__ > /dev/null; then\n    case $host_cpu in\n    i*86 )\n      # Not sure whether the presence of OpenBSD here was a mistake.\n      # Let's accept both of them until this is cleared up.\n      lt_cv_deplibs_check_method='file_magic (FreeBSD|OpenBSD|DragonFly)/i[[3-9]]86 (compact )?demand paged shared library'\n      lt_cv_file_magic_cmd=/usr/bin/file\n      lt_cv_file_magic_test_file=`echo /usr/lib/libc.so.*`\n      ;;\n    esac\n  else\n    lt_cv_deplibs_check_method=pass_all\n  fi\n  ;;\n\nhaiku*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nhpux10.20* | hpux11*)\n  lt_cv_file_magic_cmd=/usr/bin/file\n  case $host_cpu in\n  ia64*)\n    lt_cv_deplibs_check_method='file_magic (s[[0-9]][[0-9]][[0-9]]|ELF-[[0-9]][[0-9]]) shared object file - IA64'\n    lt_cv_file_magic_test_file=/usr/lib/hpux32/libc.so\n    ;;\n  hppa*64*)\n    [lt_cv_deplibs_check_method='file_magic (s[0-9][0-9][0-9]|ELF[ -][0-9][0-9])(-bit)?( [LM]SB)? shared object( file)?[, -]* PA-RISC [0-9]\\.[0-9]']\n    lt_cv_file_magic_test_file=/usr/lib/pa20_64/libc.sl\n    ;;\n  *)\n    lt_cv_deplibs_check_method='file_magic (s[[0-9]][[0-9]][[0-9]]|PA-RISC[[0-9]]\\.[[0-9]]) shared library'\n    lt_cv_file_magic_test_file=/usr/lib/libc.sl\n    ;;\n  esac\n  ;;\n\ninterix[[3-9]]*)\n  # PIC code is broken on Interix 3.x, that's why |\\.a not |_pic\\.a here\n  lt_cv_deplibs_check_method='match_pattern /lib[[^/]]+(\\.so|\\.a)$'\n  ;;\n\nirix5* | irix6* | nonstopux*)\n  case $LD in\n  *-32|*\"-32 \") libmagic=32-bit;;\n  *-n32|*\"-n32 \") libmagic=N32;;\n  *-64|*\"-64 \") libmagic=64-bit;;\n  *) libmagic=never-match;;\n  esac\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\n# This must be glibc/ELF.\nlinux* | k*bsd*-gnu | kopensolaris*-gnu | gnu*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nnetbsd*)\n  if echo __ELF__ | $CC -E - | $GREP __ELF__ > /dev/null; then\n    lt_cv_deplibs_check_method='match_pattern /lib[[^/]]+(\\.so\\.[[0-9]]+\\.[[0-9]]+|_pic\\.a)$'\n  else\n    lt_cv_deplibs_check_method='match_pattern /lib[[^/]]+(\\.so|_pic\\.a)$'\n  fi\n  ;;\n\nnewos6*)\n  lt_cv_deplibs_check_method='file_magic ELF [[0-9]][[0-9]]*-bit [[ML]]SB (executable|dynamic lib)'\n  lt_cv_file_magic_cmd=/usr/bin/file\n  lt_cv_file_magic_test_file=/usr/lib/libnls.so\n  ;;\n\n*nto* | *qnx*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nopenbsd* | bitrig*)\n  if test -z \"`echo __ELF__ | $CC -E - | $GREP __ELF__`\"; then\n    lt_cv_deplibs_check_method='match_pattern /lib[[^/]]+(\\.so\\.[[0-9]]+\\.[[0-9]]+|\\.so|_pic\\.a)$'\n  else\n    lt_cv_deplibs_check_method='match_pattern /lib[[^/]]+(\\.so\\.[[0-9]]+\\.[[0-9]]+|_pic\\.a)$'\n  fi\n  ;;\n\nosf3* | osf4* | osf5*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nrdos*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nsolaris*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nsysv5* | sco3.2v5* | sco5v6* | unixware* | OpenUNIX* | sysv4*uw2*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nsysv4 | sysv4.3*)\n  case $host_vendor in\n  motorola)\n    lt_cv_deplibs_check_method='file_magic ELF [[0-9]][[0-9]]*-bit [[ML]]SB (shared object|dynamic lib) M[[0-9]][[0-9]]* Version [[0-9]]'\n    lt_cv_file_magic_test_file=`echo /usr/lib/libc.so*`\n    ;;\n  ncr)\n    lt_cv_deplibs_check_method=pass_all\n    ;;\n  sequent)\n    lt_cv_file_magic_cmd='/bin/file'\n    lt_cv_deplibs_check_method='file_magic ELF [[0-9]][[0-9]]*-bit [[LM]]SB (shared object|dynamic lib )'\n    ;;\n  sni)\n    lt_cv_file_magic_cmd='/bin/file'\n    lt_cv_deplibs_check_method=\"file_magic ELF [[0-9]][[0-9]]*-bit [[LM]]SB dynamic lib\"\n    lt_cv_file_magic_test_file=/lib/libc.so\n    ;;\n  siemens)\n    lt_cv_deplibs_check_method=pass_all\n    ;;\n  pc)\n    lt_cv_deplibs_check_method=pass_all\n    ;;\n  esac\n  ;;\n\ntpf*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\nos2*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\nesac\n])\n\nfile_magic_glob=\nwant_nocaseglob=no\nif test \"$build\" = \"$host\"; then\n  case $host_os in\n  mingw* | pw32*)\n    if ( shopt | grep nocaseglob ) >/dev/null 2>&1; then\n      want_nocaseglob=yes\n    else\n      file_magic_glob=`echo aAbBcCdDeEfFgGhHiIjJkKlLmMnNoOpPqQrRsStTuUvVwWxXyYzZ | $SED -e \"s/\\(..\\)/s\\/[[\\1]]\\/[[\\1]]\\/g;/g\"`\n    fi\n    ;;\n  esac\nfi\n\nfile_magic_cmd=$lt_cv_file_magic_cmd\ndeplibs_check_method=$lt_cv_deplibs_check_method\ntest -z \"$deplibs_check_method\" && deplibs_check_method=unknown\n\n_LT_DECL([], [deplibs_check_method], [1],\n    [Method to check whether dependent libraries are shared objects])\n_LT_DECL([], [file_magic_cmd], [1],\n    [Command to use when deplibs_check_method = \"file_magic\"])\n_LT_DECL([], [file_magic_glob], [1],\n    [How to find potential files when deplibs_check_method = \"file_magic\"])\n_LT_DECL([], [want_nocaseglob], [1],\n    [Find potential files using nocaseglob when deplibs_check_method = \"file_magic\"])\n])# _LT_CHECK_MAGIC_METHOD\n\n\n# LT_PATH_NM\n# ----------\n# find the pathname to a BSD- or MS-compatible name lister\nAC_DEFUN([LT_PATH_NM],\n[AC_REQUIRE([AC_PROG_CC])dnl\nAC_CACHE_CHECK([for BSD- or MS-compatible name lister (nm)], lt_cv_path_NM,\n[if test -n \"$NM\"; then\n  # Let the user override the test.\n  lt_cv_path_NM=$NM\nelse\n  lt_nm_to_check=${ac_tool_prefix}nm\n  if test -n \"$ac_tool_prefix\" && test \"$build\" = \"$host\"; then\n    lt_nm_to_check=\"$lt_nm_to_check nm\"\n  fi\n  for lt_tmp_nm in $lt_nm_to_check; do\n    lt_save_ifs=$IFS; IFS=$PATH_SEPARATOR\n    for ac_dir in $PATH /usr/ccs/bin/elf /usr/ccs/bin /usr/ucb /bin; do\n      IFS=$lt_save_ifs\n      test -z \"$ac_dir\" && ac_dir=.\n      tmp_nm=$ac_dir/$lt_tmp_nm\n      if test -f \"$tmp_nm\" || test -f \"$tmp_nm$ac_exeext\"; then\n\t# Check to see if the nm accepts a BSD-compat flag.\n\t# Adding the 'sed 1q' prevents false positives on HP-UX, which says:\n\t#   nm: unknown option \"B\" ignored\n\t# Tru64's nm complains that /dev/null is an invalid object file\n\t# MSYS converts /dev/null to NUL, MinGW nm treats NUL as empty\n\tcase $build_os in\n\tmingw*) lt_bad_file=conftest.nm/nofile ;;\n\t*) lt_bad_file=/dev/null ;;\n\tesac\n\tcase `\"$tmp_nm\" -B $lt_bad_file 2>&1 | sed '1q'` in\n\t*$lt_bad_file* | *'Invalid file or object type'*)\n\t  lt_cv_path_NM=\"$tmp_nm -B\"\n\t  break 2\n\t  ;;\n\t*)\n\t  case `\"$tmp_nm\" -p /dev/null 2>&1 | sed '1q'` in\n\t  */dev/null*)\n\t    lt_cv_path_NM=\"$tmp_nm -p\"\n\t    break 2\n\t    ;;\n\t  *)\n\t    lt_cv_path_NM=${lt_cv_path_NM=\"$tmp_nm\"} # keep the first match, but\n\t    continue # so that we can try to find one that supports BSD flags\n\t    ;;\n\t  esac\n\t  ;;\n\tesac\n      fi\n    done\n    IFS=$lt_save_ifs\n  done\n  : ${lt_cv_path_NM=no}\nfi])\nif test no != \"$lt_cv_path_NM\"; then\n  NM=$lt_cv_path_NM\nelse\n  # Didn't find any BSD compatible name lister, look for dumpbin.\n  if test -n \"$DUMPBIN\"; then :\n    # Let the user override the test.\n  else\n    AC_CHECK_TOOLS(DUMPBIN, [dumpbin \"link -dump\"], :)\n    case `$DUMPBIN -symbols -headers /dev/null 2>&1 | sed '1q'` in\n    *COFF*)\n      DUMPBIN=\"$DUMPBIN -symbols -headers\"\n      ;;\n    *)\n      DUMPBIN=:\n      ;;\n    esac\n  fi\n  AC_SUBST([DUMPBIN])\n  if test : != \"$DUMPBIN\"; then\n    NM=$DUMPBIN\n  fi\nfi\ntest -z \"$NM\" && NM=nm\nAC_SUBST([NM])\n_LT_DECL([], [NM], [1], [A BSD- or MS-compatible name lister])dnl\n\nAC_CACHE_CHECK([the name lister ($NM) interface], [lt_cv_nm_interface],\n  [lt_cv_nm_interface=\"BSD nm\"\n  echo \"int some_variable = 0;\" > conftest.$ac_ext\n  (eval echo \"\\\"\\$as_me:$LINENO: $ac_compile\\\"\" >&AS_MESSAGE_LOG_FD)\n  (eval \"$ac_compile\" 2>conftest.err)\n  cat conftest.err >&AS_MESSAGE_LOG_FD\n  (eval echo \"\\\"\\$as_me:$LINENO: $NM \\\\\\\"conftest.$ac_objext\\\\\\\"\\\"\" >&AS_MESSAGE_LOG_FD)\n  (eval \"$NM \\\"conftest.$ac_objext\\\"\" 2>conftest.err > conftest.out)\n  cat conftest.err >&AS_MESSAGE_LOG_FD\n  (eval echo \"\\\"\\$as_me:$LINENO: output\\\"\" >&AS_MESSAGE_LOG_FD)\n  cat conftest.out >&AS_MESSAGE_LOG_FD\n  if $GREP 'External.*some_variable' conftest.out > /dev/null; then\n    lt_cv_nm_interface=\"MS dumpbin\"\n  fi\n  rm -f conftest*])\n])# LT_PATH_NM\n\n# Old names:\nAU_ALIAS([AM_PROG_NM], [LT_PATH_NM])\nAU_ALIAS([AC_PROG_NM], [LT_PATH_NM])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AM_PROG_NM], [])\ndnl AC_DEFUN([AC_PROG_NM], [])\n\n# _LT_CHECK_SHAREDLIB_FROM_LINKLIB\n# --------------------------------\n# how to determine the name of the shared library\n# associated with a specific link library.\n#  -- PORTME fill in with the dynamic library characteristics\nm4_defun([_LT_CHECK_SHAREDLIB_FROM_LINKLIB],\n[m4_require([_LT_DECL_EGREP])\nm4_require([_LT_DECL_OBJDUMP])\nm4_require([_LT_DECL_DLLTOOL])\nAC_CACHE_CHECK([how to associate runtime and link libraries],\nlt_cv_sharedlib_from_linklib_cmd,\n[lt_cv_sharedlib_from_linklib_cmd='unknown'\n\ncase $host_os in\ncygwin* | mingw* | pw32* | cegcc*)\n  # two different shell functions defined in ltmain.sh;\n  # decide which one to use based on capabilities of $DLLTOOL\n  case `$DLLTOOL --help 2>&1` in\n  *--identify-strict*)\n    lt_cv_sharedlib_from_linklib_cmd=func_cygming_dll_for_implib\n    ;;\n  *)\n    lt_cv_sharedlib_from_linklib_cmd=func_cygming_dll_for_implib_fallback\n    ;;\n  esac\n  ;;\n*)\n  # fallback: assume linklib IS sharedlib\n  lt_cv_sharedlib_from_linklib_cmd=$ECHO\n  ;;\nesac\n])\nsharedlib_from_linklib_cmd=$lt_cv_sharedlib_from_linklib_cmd\ntest -z \"$sharedlib_from_linklib_cmd\" && sharedlib_from_linklib_cmd=$ECHO\n\n_LT_DECL([], [sharedlib_from_linklib_cmd], [1],\n    [Command to associate shared and link libraries])\n])# _LT_CHECK_SHAREDLIB_FROM_LINKLIB\n\n\n# _LT_PATH_MANIFEST_TOOL\n# ----------------------\n# locate the manifest tool\nm4_defun([_LT_PATH_MANIFEST_TOOL],\n[AC_CHECK_TOOL(MANIFEST_TOOL, mt, :)\ntest -z \"$MANIFEST_TOOL\" && MANIFEST_TOOL=mt\nAC_CACHE_CHECK([if $MANIFEST_TOOL is a manifest tool], [lt_cv_path_mainfest_tool],\n  [lt_cv_path_mainfest_tool=no\n  echo \"$as_me:$LINENO: $MANIFEST_TOOL '-?'\" >&AS_MESSAGE_LOG_FD\n  $MANIFEST_TOOL '-?' 2>conftest.err > conftest.out\n  cat conftest.err >&AS_MESSAGE_LOG_FD\n  if $GREP 'Manifest Tool' conftest.out > /dev/null; then\n    lt_cv_path_mainfest_tool=yes\n  fi\n  rm -f conftest*])\nif test yes != \"$lt_cv_path_mainfest_tool\"; then\n  MANIFEST_TOOL=:\nfi\n_LT_DECL([], [MANIFEST_TOOL], [1], [Manifest tool])dnl\n])# _LT_PATH_MANIFEST_TOOL\n\n\n# _LT_DLL_DEF_P([FILE])\n# ---------------------\n# True iff FILE is a Windows DLL '.def' file.\n# Keep in sync with func_dll_def_p in the libtool script\nAC_DEFUN([_LT_DLL_DEF_P],\n[dnl\n  test DEF = \"`$SED -n dnl\n    -e '\\''s/^[[\t ]]*//'\\'' dnl Strip leading whitespace\n    -e '\\''/^\\(;.*\\)*$/d'\\'' dnl      Delete empty lines and comments\n    -e '\\''s/^\\(EXPORTS\\|LIBRARY\\)\\([[\t ]].*\\)*$/DEF/p'\\'' dnl\n    -e q dnl                          Only consider the first \"real\" line\n    $1`\" dnl\n])# _LT_DLL_DEF_P\n\n\n# LT_LIB_M\n# --------\n# check for math library\nAC_DEFUN([LT_LIB_M],\n[AC_REQUIRE([AC_CANONICAL_HOST])dnl\nLIBM=\ncase $host in\n*-*-beos* | *-*-cegcc* | *-*-cygwin* | *-*-haiku* | *-*-pw32* | *-*-darwin*)\n  # These system don't have libm, or don't need it\n  ;;\n*-ncr-sysv4.3*)\n  AC_CHECK_LIB(mw, _mwvalidcheckl, LIBM=-lmw)\n  AC_CHECK_LIB(m, cos, LIBM=\"$LIBM -lm\")\n  ;;\n*)\n  AC_CHECK_LIB(m, cos, LIBM=-lm)\n  ;;\nesac\nAC_SUBST([LIBM])\n])# LT_LIB_M\n\n# Old name:\nAU_ALIAS([AC_CHECK_LIBM], [LT_LIB_M])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_CHECK_LIBM], [])\n\n\n# _LT_COMPILER_NO_RTTI([TAGNAME])\n# -------------------------------\nm4_defun([_LT_COMPILER_NO_RTTI],\n[m4_require([_LT_TAG_COMPILER])dnl\n\n_LT_TAGVAR(lt_prog_compiler_no_builtin_flag, $1)=\n\nif test yes = \"$GCC\"; then\n  case $cc_basename in\n  nvcc*)\n    _LT_TAGVAR(lt_prog_compiler_no_builtin_flag, $1)=' -Xcompiler -fno-builtin' ;;\n  *)\n    _LT_TAGVAR(lt_prog_compiler_no_builtin_flag, $1)=' -fno-builtin' ;;\n  esac\n\n  _LT_COMPILER_OPTION([if $compiler supports -fno-rtti -fno-exceptions],\n    lt_cv_prog_compiler_rtti_exceptions,\n    [-fno-rtti -fno-exceptions], [],\n    [_LT_TAGVAR(lt_prog_compiler_no_builtin_flag, $1)=\"$_LT_TAGVAR(lt_prog_compiler_no_builtin_flag, $1) -fno-rtti -fno-exceptions\"])\nfi\n_LT_TAGDECL([no_builtin_flag], [lt_prog_compiler_no_builtin_flag], [1],\n\t[Compiler flag to turn off builtin functions])\n])# _LT_COMPILER_NO_RTTI\n\n\n# _LT_CMD_GLOBAL_SYMBOLS\n# ----------------------\nm4_defun([_LT_CMD_GLOBAL_SYMBOLS],\n[AC_REQUIRE([AC_CANONICAL_HOST])dnl\nAC_REQUIRE([AC_PROG_CC])dnl\nAC_REQUIRE([AC_PROG_AWK])dnl\nAC_REQUIRE([LT_PATH_NM])dnl\nAC_REQUIRE([LT_PATH_LD])dnl\nm4_require([_LT_DECL_SED])dnl\nm4_require([_LT_DECL_EGREP])dnl\nm4_require([_LT_TAG_COMPILER])dnl\n\n# Check for command to grab the raw symbol name followed by C symbol from nm.\nAC_MSG_CHECKING([command to parse $NM output from $compiler object])\nAC_CACHE_VAL([lt_cv_sys_global_symbol_pipe],\n[\n# These are sane defaults that work on at least a few old systems.\n# [They come from Ultrix.  What could be older than Ultrix?!! ;)]\n\n# Character class describing NM global symbol codes.\nsymcode='[[BCDEGRST]]'\n\n# Regexp to match symbols that can be accessed directly from C.\nsympat='\\([[_A-Za-z]][[_A-Za-z0-9]]*\\)'\n\n# Define system-specific variables.\ncase $host_os in\naix*)\n  symcode='[[BCDT]]'\n  ;;\ncygwin* | mingw* | pw32* | cegcc*)\n  symcode='[[ABCDGISTW]]'\n  ;;\nhpux*)\n  if test ia64 = \"$host_cpu\"; then\n    symcode='[[ABCDEGRST]]'\n  fi\n  ;;\nirix* | nonstopux*)\n  symcode='[[BCDEGRST]]'\n  ;;\nosf*)\n  symcode='[[BCDEGQRST]]'\n  ;;\nsolaris*)\n  symcode='[[BDRT]]'\n  ;;\nsco3.2v5*)\n  symcode='[[DT]]'\n  ;;\nsysv4.2uw2*)\n  symcode='[[DT]]'\n  ;;\nsysv5* | sco5v6* | unixware* | OpenUNIX*)\n  symcode='[[ABDT]]'\n  ;;\nsysv4)\n  symcode='[[DFNSTU]]'\n  ;;\nesac\n\n# If we're using GNU nm, then use its standard symbol codes.\ncase `$NM -V 2>&1` in\n*GNU* | *'with BFD'*)\n  symcode='[[ABCDGIRSTW]]' ;;\nesac\n\nif test \"$lt_cv_nm_interface\" = \"MS dumpbin\"; then\n  # Gets list of data symbols to import.\n  lt_cv_sys_global_symbol_to_import=\"sed -n -e 's/^I .* \\(.*\\)$/\\1/p'\"\n  # Adjust the below global symbol transforms to fixup imported variables.\n  lt_cdecl_hook=\" -e 's/^I .* \\(.*\\)$/extern __declspec(dllimport) char \\1;/p'\"\n  lt_c_name_hook=\" -e 's/^I .* \\(.*\\)$/  {\\\"\\1\\\", (void *) 0},/p'\"\n  lt_c_name_lib_hook=\"\\\n  -e 's/^I .* \\(lib.*\\)$/  {\\\"\\1\\\", (void *) 0},/p'\\\n  -e 's/^I .* \\(.*\\)$/  {\\\"lib\\1\\\", (void *) 0},/p'\"\nelse\n  # Disable hooks by default.\n  lt_cv_sys_global_symbol_to_import=\n  lt_cdecl_hook=\n  lt_c_name_hook=\n  lt_c_name_lib_hook=\nfi\n\n# Transform an extracted symbol line into a proper C declaration.\n# Some systems (esp. on ia64) link data and code symbols differently,\n# so use this general approach.\nlt_cv_sys_global_symbol_to_cdecl=\"sed -n\"\\\n$lt_cdecl_hook\\\n\" -e 's/^T .* \\(.*\\)$/extern int \\1();/p'\"\\\n\" -e 's/^$symcode$symcode* .* \\(.*\\)$/extern char \\1;/p'\"\n\n# Transform an extracted symbol line into symbol name and symbol address\nlt_cv_sys_global_symbol_to_c_name_address=\"sed -n\"\\\n$lt_c_name_hook\\\n\" -e 's/^: \\(.*\\) .*$/  {\\\"\\1\\\", (void *) 0},/p'\"\\\n\" -e 's/^$symcode$symcode* .* \\(.*\\)$/  {\\\"\\1\\\", (void *) \\&\\1},/p'\"\n\n# Transform an extracted symbol line into symbol name with lib prefix and\n# symbol address.\nlt_cv_sys_global_symbol_to_c_name_address_lib_prefix=\"sed -n\"\\\n$lt_c_name_lib_hook\\\n\" -e 's/^: \\(.*\\) .*$/  {\\\"\\1\\\", (void *) 0},/p'\"\\\n\" -e 's/^$symcode$symcode* .* \\(lib.*\\)$/  {\\\"\\1\\\", (void *) \\&\\1},/p'\"\\\n\" -e 's/^$symcode$symcode* .* \\(.*\\)$/  {\\\"lib\\1\\\", (void *) \\&\\1},/p'\"\n\n# Handle CRLF in mingw tool chain\nopt_cr=\ncase $build_os in\nmingw*)\n  opt_cr=`$ECHO 'x\\{0,1\\}' | tr x '\\015'` # option cr in regexp\n  ;;\nesac\n\n# Try without a prefix underscore, then with it.\nfor ac_symprfx in \"\" \"_\"; do\n\n  # Transform symcode, sympat, and symprfx into a raw symbol and a C symbol.\n  symxfrm=\"\\\\1 $ac_symprfx\\\\2 \\\\2\"\n\n  # Write the raw and C identifiers.\n  if test \"$lt_cv_nm_interface\" = \"MS dumpbin\"; then\n    # Fake it for dumpbin and say T for any non-static function,\n    # D for any global variable and I for any imported variable.\n    # Also find C++ and __fastcall symbols from MSVC++,\n    # which start with @ or ?.\n    lt_cv_sys_global_symbol_pipe=\"$AWK ['\"\\\n\"     {last_section=section; section=\\$ 3};\"\\\n\"     /^COFF SYMBOL TABLE/{for(i in hide) delete hide[i]};\"\\\n\"     /Section length .*#relocs.*(pick any)/{hide[last_section]=1};\"\\\n\"     /^ *Symbol name *: /{split(\\$ 0,sn,\\\":\\\"); si=substr(sn[2],2)};\"\\\n\"     /^ *Type *: code/{print \\\"T\\\",si,substr(si,length(prfx))};\"\\\n\"     /^ *Type *: data/{print \\\"I\\\",si,substr(si,length(prfx))};\"\\\n\"     \\$ 0!~/External *\\|/{next};\"\\\n\"     / 0+ UNDEF /{next}; / UNDEF \\([^|]\\)*()/{next};\"\\\n\"     {if(hide[section]) next};\"\\\n\"     {f=\\\"D\\\"}; \\$ 0~/\\(\\).*\\|/{f=\\\"T\\\"};\"\\\n\"     {split(\\$ 0,a,/\\||\\r/); split(a[2],s)};\"\\\n\"     s[1]~/^[@?]/{print f,s[1],s[1]; next};\"\\\n\"     s[1]~prfx {split(s[1],t,\\\"@\\\"); print f,t[1],substr(t[1],length(prfx))}\"\\\n\"     ' prfx=^$ac_symprfx]\"\n  else\n    lt_cv_sys_global_symbol_pipe=\"sed -n -e 's/^.*[[\t ]]\\($symcode$symcode*\\)[[\t ]][[\t ]]*$ac_symprfx$sympat$opt_cr$/$symxfrm/p'\"\n  fi\n  lt_cv_sys_global_symbol_pipe=\"$lt_cv_sys_global_symbol_pipe | sed '/ __gnu_lto/d'\"\n\n  # Check to see that the pipe works correctly.\n  pipe_works=no\n\n  rm -f conftest*\n  cat > conftest.$ac_ext <<_LT_EOF\n#ifdef __cplusplus\nextern \"C\" {\n#endif\nchar nm_test_var;\nvoid nm_test_func(void);\nvoid nm_test_func(void){}\n#ifdef __cplusplus\n}\n#endif\nint main(){nm_test_var='a';nm_test_func();return(0);}\n_LT_EOF\n\n  if AC_TRY_EVAL(ac_compile); then\n    # Now try to grab the symbols.\n    nlist=conftest.nm\n    if AC_TRY_EVAL(NM conftest.$ac_objext \\| \"$lt_cv_sys_global_symbol_pipe\" \\> $nlist) && test -s \"$nlist\"; then\n      # Try sorting and uniquifying the output.\n      if sort \"$nlist\" | uniq > \"$nlist\"T; then\n\tmv -f \"$nlist\"T \"$nlist\"\n      else\n\trm -f \"$nlist\"T\n      fi\n\n      # Make sure that we snagged all the symbols we need.\n      if $GREP ' nm_test_var$' \"$nlist\" >/dev/null; then\n\tif $GREP ' nm_test_func$' \"$nlist\" >/dev/null; then\n\t  cat <<_LT_EOF > conftest.$ac_ext\n/* Keep this code in sync between libtool.m4, ltmain, lt_system.h, and tests.  */\n#if defined _WIN32 || defined __CYGWIN__ || defined _WIN32_WCE\n/* DATA imports from DLLs on WIN32 can't be const, because runtime\n   relocations are performed -- see ld's documentation on pseudo-relocs.  */\n# define LT@&t@_DLSYM_CONST\n#elif defined __osf__\n/* This system does not cope well with relocations in const data.  */\n# define LT@&t@_DLSYM_CONST\n#else\n# define LT@&t@_DLSYM_CONST const\n#endif\n\n#ifdef __cplusplus\nextern \"C\" {\n#endif\n\n_LT_EOF\n\t  # Now generate the symbol file.\n\t  eval \"$lt_cv_sys_global_symbol_to_cdecl\"' < \"$nlist\" | $GREP -v main >> conftest.$ac_ext'\n\n\t  cat <<_LT_EOF >> conftest.$ac_ext\n\n/* The mapping between symbol names and symbols.  */\nLT@&t@_DLSYM_CONST struct {\n  const char *name;\n  void       *address;\n}\nlt__PROGRAM__LTX_preloaded_symbols[[]] =\n{\n  { \"@PROGRAM@\", (void *) 0 },\n_LT_EOF\n\t  $SED \"s/^$symcode$symcode* .* \\(.*\\)$/  {\\\"\\1\\\", (void *) \\&\\1},/\" < \"$nlist\" | $GREP -v main >> conftest.$ac_ext\n\t  cat <<\\_LT_EOF >> conftest.$ac_ext\n  {0, (void *) 0}\n};\n\n/* This works around a problem in FreeBSD linker */\n#ifdef FREEBSD_WORKAROUND\nstatic const void *lt_preloaded_setup() {\n  return lt__PROGRAM__LTX_preloaded_symbols;\n}\n#endif\n\n#ifdef __cplusplus\n}\n#endif\n_LT_EOF\n\t  # Now try linking the two files.\n\t  mv conftest.$ac_objext conftstm.$ac_objext\n\t  lt_globsym_save_LIBS=$LIBS\n\t  lt_globsym_save_CFLAGS=$CFLAGS\n\t  LIBS=conftstm.$ac_objext\n\t  CFLAGS=\"$CFLAGS$_LT_TAGVAR(lt_prog_compiler_no_builtin_flag, $1)\"\n\t  if AC_TRY_EVAL(ac_link) && test -s conftest$ac_exeext; then\n\t    pipe_works=yes\n\t  fi\n\t  LIBS=$lt_globsym_save_LIBS\n\t  CFLAGS=$lt_globsym_save_CFLAGS\n\telse\n\t  echo \"cannot find nm_test_func in $nlist\" >&AS_MESSAGE_LOG_FD\n\tfi\n      else\n\techo \"cannot find nm_test_var in $nlist\" >&AS_MESSAGE_LOG_FD\n      fi\n    else\n      echo \"cannot run $lt_cv_sys_global_symbol_pipe\" >&AS_MESSAGE_LOG_FD\n    fi\n  else\n    echo \"$progname: failed program was:\" >&AS_MESSAGE_LOG_FD\n    cat conftest.$ac_ext >&5\n  fi\n  rm -rf conftest* conftst*\n\n  # Do not use the global_symbol_pipe unless it works.\n  if test yes = \"$pipe_works\"; then\n    break\n  else\n    lt_cv_sys_global_symbol_pipe=\n  fi\ndone\n])\nif test -z \"$lt_cv_sys_global_symbol_pipe\"; then\n  lt_cv_sys_global_symbol_to_cdecl=\nfi\nif test -z \"$lt_cv_sys_global_symbol_pipe$lt_cv_sys_global_symbol_to_cdecl\"; then\n  AC_MSG_RESULT(failed)\nelse\n  AC_MSG_RESULT(ok)\nfi\n\n# Response file support.\nif test \"$lt_cv_nm_interface\" = \"MS dumpbin\"; then\n  nm_file_list_spec='@'\nelif $NM --help 2>/dev/null | grep '[[@]]FILE' >/dev/null; then\n  nm_file_list_spec='@'\nfi\n\n_LT_DECL([global_symbol_pipe], [lt_cv_sys_global_symbol_pipe], [1],\n    [Take the output of nm and produce a listing of raw symbols and C names])\n_LT_DECL([global_symbol_to_cdecl], [lt_cv_sys_global_symbol_to_cdecl], [1],\n    [Transform the output of nm in a proper C declaration])\n_LT_DECL([global_symbol_to_import], [lt_cv_sys_global_symbol_to_import], [1],\n    [Transform the output of nm into a list of symbols to manually relocate])\n_LT_DECL([global_symbol_to_c_name_address],\n    [lt_cv_sys_global_symbol_to_c_name_address], [1],\n    [Transform the output of nm in a C name address pair])\n_LT_DECL([global_symbol_to_c_name_address_lib_prefix],\n    [lt_cv_sys_global_symbol_to_c_name_address_lib_prefix], [1],\n    [Transform the output of nm in a C name address pair when lib prefix is needed])\n_LT_DECL([nm_interface], [lt_cv_nm_interface], [1],\n    [The name lister interface])\n_LT_DECL([], [nm_file_list_spec], [1],\n    [Specify filename containing input files for $NM])\n]) # _LT_CMD_GLOBAL_SYMBOLS\n\n\n# _LT_COMPILER_PIC([TAGNAME])\n# ---------------------------\nm4_defun([_LT_COMPILER_PIC],\n[m4_require([_LT_TAG_COMPILER])dnl\n_LT_TAGVAR(lt_prog_compiler_wl, $1)=\n_LT_TAGVAR(lt_prog_compiler_pic, $1)=\n_LT_TAGVAR(lt_prog_compiler_static, $1)=\n\nm4_if([$1], [CXX], [\n  # C++ specific cases for pic, static, wl, etc.\n  if test yes = \"$GXX\"; then\n    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n    _LT_TAGVAR(lt_prog_compiler_static, $1)='-static'\n\n    case $host_os in\n    aix*)\n      # All AIX code is PIC.\n      if test ia64 = \"$host_cpu\"; then\n\t# AIX 5 now supports IA64 processor\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n      fi\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n      ;;\n\n    amigaos*)\n      case $host_cpu in\n      powerpc)\n            # see comment about AmigaOS4 .so support\n            _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n        ;;\n      m68k)\n            # FIXME: we need at least 68020 code to build shared libraries, but\n            # adding the '-m68020' flag to GCC prevents building anything better,\n            # like '-m68040'.\n            _LT_TAGVAR(lt_prog_compiler_pic, $1)='-m68020 -resident32 -malways-restore-a4'\n        ;;\n      esac\n      ;;\n\n    beos* | irix5* | irix6* | nonstopux* | osf3* | osf4* | osf5*)\n      # PIC is the default for these OSes.\n      ;;\n    mingw* | cygwin* | os2* | pw32* | cegcc*)\n      # This hack is so that the source file can tell whether it is being\n      # built for inclusion in a dll (and should export symbols for example).\n      # Although the cygwin gcc ignores -fPIC, still need this for old-style\n      # (--disable-auto-import) libraries\n      m4_if([$1], [GCJ], [],\n\t[_LT_TAGVAR(lt_prog_compiler_pic, $1)='-DDLL_EXPORT'])\n      case $host_os in\n      os2*)\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='$wl-static'\n\t;;\n      esac\n      ;;\n    darwin* | rhapsody*)\n      # PIC is the default on this platform\n      # Common symbols not allowed in MH_DYLIB files\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fno-common'\n      ;;\n    *djgpp*)\n      # DJGPP does not support shared libraries at all\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)=\n      ;;\n    haiku*)\n      # PIC is the default for Haiku.\n      # The \"-static\" flag exists, but is broken.\n      _LT_TAGVAR(lt_prog_compiler_static, $1)=\n      ;;\n    interix[[3-9]]*)\n      # Interix 3.x gcc -fpic/-fPIC options generate broken code.\n      # Instead, we relocate shared libraries at runtime.\n      ;;\n    sysv4*MP*)\n      if test -d /usr/nec; then\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)=-Kconform_pic\n      fi\n      ;;\n    hpux*)\n      # PIC is the default for 64-bit PA HP-UX, but not for 32-bit\n      # PA HP-UX.  On IA64 HP-UX, PIC is the default but the pic flag\n      # sets the default TLS model and affects inlining.\n      case $host_cpu in\n      hppa*64*)\n\t;;\n      *)\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n\t;;\n      esac\n      ;;\n    *qnx* | *nto*)\n      # QNX uses GNU C++, but need to define -shared option too, otherwise\n      # it will coredump.\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC -shared'\n      ;;\n    *)\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n      ;;\n    esac\n  else\n    case $host_os in\n      aix[[4-9]]*)\n\t# All AIX code is PIC.\n\tif test ia64 = \"$host_cpu\"; then\n\t  # AIX 5 now supports IA64 processor\n\t  _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n\telse\n\t  _LT_TAGVAR(lt_prog_compiler_static, $1)='-bnso -bI:/lib/syscalls.exp'\n\tfi\n\t;;\n      chorus*)\n\tcase $cc_basename in\n\tcxch68*)\n\t  # Green Hills C++ Compiler\n\t  # _LT_TAGVAR(lt_prog_compiler_static, $1)=\"--no_auto_instantiation -u __main -u __premain -u _abort -r $COOL_DIR/lib/libOrb.a $MVME_DIR/lib/CC/libC.a $MVME_DIR/lib/classix/libcx.s.a\"\n\t  ;;\n\tesac\n\t;;\n      mingw* | cygwin* | os2* | pw32* | cegcc*)\n\t# This hack is so that the source file can tell whether it is being\n\t# built for inclusion in a dll (and should export symbols for example).\n\tm4_if([$1], [GCJ], [],\n\t  [_LT_TAGVAR(lt_prog_compiler_pic, $1)='-DDLL_EXPORT'])\n\t;;\n      dgux*)\n\tcase $cc_basename in\n\t  ec++*)\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n\t    ;;\n\t  ghcx*)\n\t    # Green Hills C++ Compiler\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-pic'\n\t    ;;\n\t  *)\n\t    ;;\n\tesac\n\t;;\n      freebsd* | dragonfly*)\n\t# FreeBSD uses GNU C++\n\t;;\n      hpux9* | hpux10* | hpux11*)\n\tcase $cc_basename in\n\t  CC*)\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='$wl-a ${wl}archive'\n\t    if test ia64 != \"$host_cpu\"; then\n\t      _LT_TAGVAR(lt_prog_compiler_pic, $1)='+Z'\n\t    fi\n\t    ;;\n\t  aCC*)\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='$wl-a ${wl}archive'\n\t    case $host_cpu in\n\t    hppa*64*|ia64*)\n\t      # +Z the default\n\t      ;;\n\t    *)\n\t      _LT_TAGVAR(lt_prog_compiler_pic, $1)='+Z'\n\t      ;;\n\t    esac\n\t    ;;\n\t  *)\n\t    ;;\n\tesac\n\t;;\n      interix*)\n\t# This is c89, which is MS Visual C++ (no shared libs)\n\t# Anyone wants to do a port?\n\t;;\n      irix5* | irix6* | nonstopux*)\n\tcase $cc_basename in\n\t  CC*)\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='-non_shared'\n\t    # CC pic flag -KPIC is the default.\n\t    ;;\n\t  *)\n\t    ;;\n\tesac\n\t;;\n      linux* | k*bsd*-gnu | kopensolaris*-gnu | gnu*)\n\tcase $cc_basename in\n\t  KCC*)\n\t    # KAI C++ Compiler\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='--backend -Wl,'\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n\t    ;;\n\t  ecpc* )\n\t    # old Intel C++ for x86_64, which still supported -KPIC.\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='-static'\n\t    ;;\n\t  icpc* )\n\t    # Intel C++, used to be incompatible with GCC.\n\t    # ICC 10 doesn't accept -KPIC any more.\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='-static'\n\t    ;;\n\t  pgCC* | pgcpp*)\n\t    # Portland Group C++ compiler\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fpic'\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n\t    ;;\n\t  cxx*)\n\t    # Compaq C++\n\t    # Make sure the PIC flag is empty.  It appears that all Alpha\n\t    # Linux and Compaq Tru64 Unix objects are PIC.\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)=\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='-non_shared'\n\t    ;;\n\t  xlc* | xlC* | bgxl[[cC]]* | mpixl[[cC]]*)\n\t    # IBM XL 8.0, 9.0 on PPC and BlueGene\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-qpic'\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='-qstaticlink'\n\t    ;;\n\t  *)\n\t    case `$CC -V 2>&1 | sed 5q` in\n\t    *Sun\\ C*)\n\t      # Sun C++ 5.9\n\t      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n\t      _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n\t      _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Qoption ld '\n\t      ;;\n\t    esac\n\t    ;;\n\tesac\n\t;;\n      lynxos*)\n\t;;\n      m88k*)\n\t;;\n      mvs*)\n\tcase $cc_basename in\n\t  cxx*)\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-W c,exportall'\n\t    ;;\n\t  *)\n\t    ;;\n\tesac\n\t;;\n      netbsd*)\n\t;;\n      *qnx* | *nto*)\n        # QNX uses GNU C++, but need to define -shared option too, otherwise\n        # it will coredump.\n        _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC -shared'\n        ;;\n      osf3* | osf4* | osf5*)\n\tcase $cc_basename in\n\t  KCC*)\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='--backend -Wl,'\n\t    ;;\n\t  RCC*)\n\t    # Rational C++ 2.4.1\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-pic'\n\t    ;;\n\t  cxx*)\n\t    # Digital/Compaq C++\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t    # Make sure the PIC flag is empty.  It appears that all Alpha\n\t    # Linux and Compaq Tru64 Unix objects are PIC.\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)=\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='-non_shared'\n\t    ;;\n\t  *)\n\t    ;;\n\tesac\n\t;;\n      psos*)\n\t;;\n      solaris*)\n\tcase $cc_basename in\n\t  CC* | sunCC*)\n\t    # Sun C++ 4.2, 5.x and Centerline C++\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Qoption ld '\n\t    ;;\n\t  gcx*)\n\t    # Green Hills C++ Compiler\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-PIC'\n\t    ;;\n\t  *)\n\t    ;;\n\tesac\n\t;;\n      sunos4*)\n\tcase $cc_basename in\n\t  CC*)\n\t    # Sun C++ 4.x\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-pic'\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n\t    ;;\n\t  lcc*)\n\t    # Lucid\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-pic'\n\t    ;;\n\t  *)\n\t    ;;\n\tesac\n\t;;\n      sysv5* | unixware* | sco3.2v5* | sco5v6* | OpenUNIX*)\n\tcase $cc_basename in\n\t  CC*)\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n\t    ;;\n\tesac\n\t;;\n      tandem*)\n\tcase $cc_basename in\n\t  NCC*)\n\t    # NonStop-UX NCC 3.20\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n\t    ;;\n\t  *)\n\t    ;;\n\tesac\n\t;;\n      vxworks*)\n\t;;\n      *)\n\t_LT_TAGVAR(lt_prog_compiler_can_build_shared, $1)=no\n\t;;\n    esac\n  fi\n],\n[\n  if test yes = \"$GCC\"; then\n    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n    _LT_TAGVAR(lt_prog_compiler_static, $1)='-static'\n\n    case $host_os in\n      aix*)\n      # All AIX code is PIC.\n      if test ia64 = \"$host_cpu\"; then\n\t# AIX 5 now supports IA64 processor\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n      fi\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n      ;;\n\n    amigaos*)\n      case $host_cpu in\n      powerpc)\n            # see comment about AmigaOS4 .so support\n            _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n        ;;\n      m68k)\n            # FIXME: we need at least 68020 code to build shared libraries, but\n            # adding the '-m68020' flag to GCC prevents building anything better,\n            # like '-m68040'.\n            _LT_TAGVAR(lt_prog_compiler_pic, $1)='-m68020 -resident32 -malways-restore-a4'\n        ;;\n      esac\n      ;;\n\n    beos* | irix5* | irix6* | nonstopux* | osf3* | osf4* | osf5*)\n      # PIC is the default for these OSes.\n      ;;\n\n    mingw* | cygwin* | pw32* | os2* | cegcc*)\n      # This hack is so that the source file can tell whether it is being\n      # built for inclusion in a dll (and should export symbols for example).\n      # Although the cygwin gcc ignores -fPIC, still need this for old-style\n      # (--disable-auto-import) libraries\n      m4_if([$1], [GCJ], [],\n\t[_LT_TAGVAR(lt_prog_compiler_pic, $1)='-DDLL_EXPORT'])\n      case $host_os in\n      os2*)\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='$wl-static'\n\t;;\n      esac\n      ;;\n\n    darwin* | rhapsody*)\n      # PIC is the default on this platform\n      # Common symbols not allowed in MH_DYLIB files\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fno-common'\n      ;;\n\n    haiku*)\n      # PIC is the default for Haiku.\n      # The \"-static\" flag exists, but is broken.\n      _LT_TAGVAR(lt_prog_compiler_static, $1)=\n      ;;\n\n    hpux*)\n      # PIC is the default for 64-bit PA HP-UX, but not for 32-bit\n      # PA HP-UX.  On IA64 HP-UX, PIC is the default but the pic flag\n      # sets the default TLS model and affects inlining.\n      case $host_cpu in\n      hppa*64*)\n\t# +Z the default\n\t;;\n      *)\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n\t;;\n      esac\n      ;;\n\n    interix[[3-9]]*)\n      # Interix 3.x gcc -fpic/-fPIC options generate broken code.\n      # Instead, we relocate shared libraries at runtime.\n      ;;\n\n    msdosdjgpp*)\n      # Just because we use GCC doesn't mean we suddenly get shared libraries\n      # on systems that don't support them.\n      _LT_TAGVAR(lt_prog_compiler_can_build_shared, $1)=no\n      enable_shared=no\n      ;;\n\n    *nto* | *qnx*)\n      # QNX uses GNU C++, but need to define -shared option too, otherwise\n      # it will coredump.\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC -shared'\n      ;;\n\n    sysv4*MP*)\n      if test -d /usr/nec; then\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)=-Kconform_pic\n      fi\n      ;;\n\n    *)\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n      ;;\n    esac\n\n    case $cc_basename in\n    nvcc*) # Cuda Compiler Driver 2.2\n      _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Xlinker '\n      if test -n \"$_LT_TAGVAR(lt_prog_compiler_pic, $1)\"; then\n        _LT_TAGVAR(lt_prog_compiler_pic, $1)=\"-Xcompiler $_LT_TAGVAR(lt_prog_compiler_pic, $1)\"\n      fi\n      ;;\n    esac\n  else\n    # PORTME Check for flag to pass linker flags through the system compiler.\n    case $host_os in\n    aix*)\n      _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n      if test ia64 = \"$host_cpu\"; then\n\t# AIX 5 now supports IA64 processor\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n      else\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='-bnso -bI:/lib/syscalls.exp'\n      fi\n      ;;\n\n    darwin* | rhapsody*)\n      # PIC is the default on this platform\n      # Common symbols not allowed in MH_DYLIB files\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fno-common'\n      case $cc_basename in\n      nagfor*)\n        # NAG Fortran compiler\n        _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,-Wl,,'\n        _LT_TAGVAR(lt_prog_compiler_pic, $1)='-PIC'\n        _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n        ;;\n      esac\n      ;;\n\n    mingw* | cygwin* | pw32* | os2* | cegcc*)\n      # This hack is so that the source file can tell whether it is being\n      # built for inclusion in a dll (and should export symbols for example).\n      m4_if([$1], [GCJ], [],\n\t[_LT_TAGVAR(lt_prog_compiler_pic, $1)='-DDLL_EXPORT'])\n      case $host_os in\n      os2*)\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='$wl-static'\n\t;;\n      esac\n      ;;\n\n    hpux9* | hpux10* | hpux11*)\n      _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n      # PIC is the default for IA64 HP-UX and 64-bit HP-UX, but\n      # not for PA HP-UX.\n      case $host_cpu in\n      hppa*64*|ia64*)\n\t# +Z the default\n\t;;\n      *)\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)='+Z'\n\t;;\n      esac\n      # Is there a better lt_prog_compiler_static that works with the bundled CC?\n      _LT_TAGVAR(lt_prog_compiler_static, $1)='$wl-a ${wl}archive'\n      ;;\n\n    irix5* | irix6* | nonstopux*)\n      _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n      # PIC (with -KPIC) is the default.\n      _LT_TAGVAR(lt_prog_compiler_static, $1)='-non_shared'\n      ;;\n\n    linux* | k*bsd*-gnu | kopensolaris*-gnu | gnu*)\n      case $cc_basename in\n      # old Intel for x86_64, which still supported -KPIC.\n      ecc*)\n\t_LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='-static'\n        ;;\n      # icc used to be incompatible with GCC.\n      # ICC 10 doesn't accept -KPIC any more.\n      icc* | ifort*)\n\t_LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='-static'\n        ;;\n      # Lahey Fortran 8.1.\n      lf95*)\n\t_LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)='--shared'\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='--static'\n\t;;\n      nagfor*)\n\t# NAG Fortran compiler\n\t_LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,-Wl,,'\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)='-PIC'\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n\t;;\n      tcc*)\n\t# Fabrice Bellard et al's Tiny C Compiler\n\t_LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='-static'\n\t;;\n      pgcc* | pgf77* | pgf90* | pgf95* | pgfortran*)\n        # Portland Group compilers (*not* the Pentium gcc compiler,\n\t# which looks to be a dead project)\n\t_LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)='-fpic'\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n        ;;\n      ccc*)\n        _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n        # All Alpha code is PIC.\n        _LT_TAGVAR(lt_prog_compiler_static, $1)='-non_shared'\n        ;;\n      xl* | bgxl* | bgf* | mpixl*)\n\t# IBM XL C 8.0/Fortran 10.1, 11.1 on PPC and BlueGene\n\t_LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)='-qpic'\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='-qstaticlink'\n\t;;\n      *)\n\tcase `$CC -V 2>&1 | sed 5q` in\n\t*Sun\\ Ceres\\ Fortran* | *Sun*Fortran*\\ [[1-7]].* | *Sun*Fortran*\\ 8.[[0-3]]*)\n\t  # Sun Fortran 8.3 passes all unrecognized flags to the linker\n\t  _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n\t  _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n\t  _LT_TAGVAR(lt_prog_compiler_wl, $1)=''\n\t  ;;\n\t*Sun\\ F* | *Sun*Fortran*)\n\t  _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n\t  _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n\t  _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Qoption ld '\n\t  ;;\n\t*Sun\\ C*)\n\t  # Sun C 5.9\n\t  _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n\t  _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n\t  _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t  ;;\n        *Intel*\\ [[CF]]*Compiler*)\n\t  _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t  _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n\t  _LT_TAGVAR(lt_prog_compiler_static, $1)='-static'\n\t  ;;\n\t*Portland\\ Group*)\n\t  _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t  _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fpic'\n\t  _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n\t  ;;\n\tesac\n\t;;\n      esac\n      ;;\n\n    newsos6)\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n      _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n      ;;\n\n    *nto* | *qnx*)\n      # QNX uses GNU C++, but need to define -shared option too, otherwise\n      # it will coredump.\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC -shared'\n      ;;\n\n    osf3* | osf4* | osf5*)\n      _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n      # All OSF/1 code is PIC.\n      _LT_TAGVAR(lt_prog_compiler_static, $1)='-non_shared'\n      ;;\n\n    rdos*)\n      _LT_TAGVAR(lt_prog_compiler_static, $1)='-non_shared'\n      ;;\n\n    solaris*)\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n      _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n      case $cc_basename in\n      f77* | f90* | f95* | sunf77* | sunf90* | sunf95*)\n\t_LT_TAGVAR(lt_prog_compiler_wl, $1)='-Qoption ld ';;\n      *)\n\t_LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,';;\n      esac\n      ;;\n\n    sunos4*)\n      _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Qoption ld '\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-PIC'\n      _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n      ;;\n\n    sysv4 | sysv4.2uw2* | sysv4.3*)\n      _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n      _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n      ;;\n\n    sysv4*MP*)\n      if test -d /usr/nec; then\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)='-Kconform_pic'\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n      fi\n      ;;\n\n    sysv5* | unixware* | sco3.2v5* | sco5v6* | OpenUNIX*)\n      _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n      _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n      ;;\n\n    unicos*)\n      _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n      _LT_TAGVAR(lt_prog_compiler_can_build_shared, $1)=no\n      ;;\n\n    uts4*)\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-pic'\n      _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n      ;;\n\n    *)\n      _LT_TAGVAR(lt_prog_compiler_can_build_shared, $1)=no\n      ;;\n    esac\n  fi\n])\ncase $host_os in\n  # For platforms that do not support PIC, -DPIC is meaningless:\n  *djgpp*)\n    _LT_TAGVAR(lt_prog_compiler_pic, $1)=\n    ;;\n  *)\n    _LT_TAGVAR(lt_prog_compiler_pic, $1)=\"$_LT_TAGVAR(lt_prog_compiler_pic, $1)@&t@m4_if([$1],[],[ -DPIC],[m4_if([$1],[CXX],[ -DPIC],[])])\"\n    ;;\nesac\n\nAC_CACHE_CHECK([for $compiler option to produce PIC],\n  [_LT_TAGVAR(lt_cv_prog_compiler_pic, $1)],\n  [_LT_TAGVAR(lt_cv_prog_compiler_pic, $1)=$_LT_TAGVAR(lt_prog_compiler_pic, $1)])\n_LT_TAGVAR(lt_prog_compiler_pic, $1)=$_LT_TAGVAR(lt_cv_prog_compiler_pic, $1)\n\n#\n# Check to make sure the PIC flag actually works.\n#\nif test -n \"$_LT_TAGVAR(lt_prog_compiler_pic, $1)\"; then\n  _LT_COMPILER_OPTION([if $compiler PIC flag $_LT_TAGVAR(lt_prog_compiler_pic, $1) works],\n    [_LT_TAGVAR(lt_cv_prog_compiler_pic_works, $1)],\n    [$_LT_TAGVAR(lt_prog_compiler_pic, $1)@&t@m4_if([$1],[],[ -DPIC],[m4_if([$1],[CXX],[ -DPIC],[])])], [],\n    [case $_LT_TAGVAR(lt_prog_compiler_pic, $1) in\n     \"\" | \" \"*) ;;\n     *) _LT_TAGVAR(lt_prog_compiler_pic, $1)=\" $_LT_TAGVAR(lt_prog_compiler_pic, $1)\" ;;\n     esac],\n    [_LT_TAGVAR(lt_prog_compiler_pic, $1)=\n     _LT_TAGVAR(lt_prog_compiler_can_build_shared, $1)=no])\nfi\n_LT_TAGDECL([pic_flag], [lt_prog_compiler_pic], [1],\n\t[Additional compiler flags for building library objects])\n\n_LT_TAGDECL([wl], [lt_prog_compiler_wl], [1],\n\t[How to pass a linker flag through the compiler])\n#\n# Check to make sure the static flag actually works.\n#\nwl=$_LT_TAGVAR(lt_prog_compiler_wl, $1) eval lt_tmp_static_flag=\\\"$_LT_TAGVAR(lt_prog_compiler_static, $1)\\\"\n_LT_LINKER_OPTION([if $compiler static flag $lt_tmp_static_flag works],\n  _LT_TAGVAR(lt_cv_prog_compiler_static_works, $1),\n  $lt_tmp_static_flag,\n  [],\n  [_LT_TAGVAR(lt_prog_compiler_static, $1)=])\n_LT_TAGDECL([link_static_flag], [lt_prog_compiler_static], [1],\n\t[Compiler flag to prevent dynamic linking])\n])# _LT_COMPILER_PIC\n\n\n# _LT_LINKER_SHLIBS([TAGNAME])\n# ----------------------------\n# See if the linker supports building shared libraries.\nm4_defun([_LT_LINKER_SHLIBS],\n[AC_REQUIRE([LT_PATH_LD])dnl\nAC_REQUIRE([LT_PATH_NM])dnl\nm4_require([_LT_PATH_MANIFEST_TOOL])dnl\nm4_require([_LT_FILEUTILS_DEFAULTS])dnl\nm4_require([_LT_DECL_EGREP])dnl\nm4_require([_LT_DECL_SED])dnl\nm4_require([_LT_CMD_GLOBAL_SYMBOLS])dnl\nm4_require([_LT_TAG_COMPILER])dnl\nAC_MSG_CHECKING([whether the $compiler linker ($LD) supports shared libraries])\nm4_if([$1], [CXX], [\n  _LT_TAGVAR(export_symbols_cmds, $1)='$NM $libobjs $convenience | $global_symbol_pipe | $SED '\\''s/.* //'\\'' | sort | uniq > $export_symbols'\n  _LT_TAGVAR(exclude_expsyms, $1)=['_GLOBAL_OFFSET_TABLE_|_GLOBAL__F[ID]_.*']\n  case $host_os in\n  aix[[4-9]]*)\n    # If we're using GNU nm, then we don't want the \"-C\" option.\n    # -C means demangle to GNU nm, but means don't demangle to AIX nm.\n    # Without the \"-l\" option, or with the \"-B\" option, AIX nm treats\n    # weak defined symbols like other global defined symbols, whereas\n    # GNU nm marks them as \"W\".\n    # While the 'weak' keyword is ignored in the Export File, we need\n    # it in the Import File for the 'aix-soname' feature, so we have\n    # to replace the \"-B\" option with \"-P\" for AIX nm.\n    if $NM -V 2>&1 | $GREP 'GNU' > /dev/null; then\n      _LT_TAGVAR(export_symbols_cmds, $1)='$NM -Bpg $libobjs $convenience | awk '\\''{ if (((\\$ 2 == \"T\") || (\\$ 2 == \"D\") || (\\$ 2 == \"B\") || (\\$ 2 == \"W\")) && ([substr](\\$ 3,1,1) != \".\")) { if (\\$ 2 == \"W\") { print \\$ 3 \" weak\" } else { print \\$ 3 } } }'\\'' | sort -u > $export_symbols'\n    else\n      _LT_TAGVAR(export_symbols_cmds, $1)='`func_echo_all $NM | $SED -e '\\''s/B\\([[^B]]*\\)$/P\\1/'\\''` -PCpgl $libobjs $convenience | awk '\\''{ if (((\\$ 2 == \"T\") || (\\$ 2 == \"D\") || (\\$ 2 == \"B\") || (\\$ 2 == \"W\") || (\\$ 2 == \"V\") || (\\$ 2 == \"Z\")) && ([substr](\\$ 1,1,1) != \".\")) { if ((\\$ 2 == \"W\") || (\\$ 2 == \"V\") || (\\$ 2 == \"Z\")) { print \\$ 1 \" weak\" } else { print \\$ 1 } } }'\\'' | sort -u > $export_symbols'\n    fi\n    ;;\n  pw32*)\n    _LT_TAGVAR(export_symbols_cmds, $1)=$ltdll_cmds\n    ;;\n  cygwin* | mingw* | cegcc*)\n    case $cc_basename in\n    cl*)\n      _LT_TAGVAR(exclude_expsyms, $1)='_NULL_IMPORT_DESCRIPTOR|_IMPORT_DESCRIPTOR_.*'\n      ;;\n    *)\n      _LT_TAGVAR(export_symbols_cmds, $1)='$NM $libobjs $convenience | $global_symbol_pipe | $SED -e '\\''/^[[BCDGRS]][[ ]]/s/.*[[ ]]\\([[^ ]]*\\)/\\1 DATA/;s/^.*[[ ]]__nm__\\([[^ ]]*\\)[[ ]][[^ ]]*/\\1 DATA/;/^I[[ ]]/d;/^[[AITW]][[ ]]/s/.* //'\\'' | sort | uniq > $export_symbols'\n      _LT_TAGVAR(exclude_expsyms, $1)=['[_]+GLOBAL_OFFSET_TABLE_|[_]+GLOBAL__[FID]_.*|[_]+head_[A-Za-z0-9_]+_dll|[A-Za-z0-9_]+_dll_iname']\n      ;;\n    esac\n    ;;\n  *)\n    _LT_TAGVAR(export_symbols_cmds, $1)='$NM $libobjs $convenience | $global_symbol_pipe | $SED '\\''s/.* //'\\'' | sort | uniq > $export_symbols'\n    ;;\n  esac\n], [\n  runpath_var=\n  _LT_TAGVAR(allow_undefined_flag, $1)=\n  _LT_TAGVAR(always_export_symbols, $1)=no\n  _LT_TAGVAR(archive_cmds, $1)=\n  _LT_TAGVAR(archive_expsym_cmds, $1)=\n  _LT_TAGVAR(compiler_needs_object, $1)=no\n  _LT_TAGVAR(enable_shared_with_static_runtimes, $1)=no\n  _LT_TAGVAR(export_dynamic_flag_spec, $1)=\n  _LT_TAGVAR(export_symbols_cmds, $1)='$NM $libobjs $convenience | $global_symbol_pipe | $SED '\\''s/.* //'\\'' | sort | uniq > $export_symbols'\n  _LT_TAGVAR(hardcode_automatic, $1)=no\n  _LT_TAGVAR(hardcode_direct, $1)=no\n  _LT_TAGVAR(hardcode_direct_absolute, $1)=no\n  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)=\n  _LT_TAGVAR(hardcode_libdir_separator, $1)=\n  _LT_TAGVAR(hardcode_minus_L, $1)=no\n  _LT_TAGVAR(hardcode_shlibpath_var, $1)=unsupported\n  _LT_TAGVAR(inherit_rpath, $1)=no\n  _LT_TAGVAR(link_all_deplibs, $1)=unknown\n  _LT_TAGVAR(module_cmds, $1)=\n  _LT_TAGVAR(module_expsym_cmds, $1)=\n  _LT_TAGVAR(old_archive_from_new_cmds, $1)=\n  _LT_TAGVAR(old_archive_from_expsyms_cmds, $1)=\n  _LT_TAGVAR(thread_safe_flag_spec, $1)=\n  _LT_TAGVAR(whole_archive_flag_spec, $1)=\n  # include_expsyms should be a list of space-separated symbols to be *always*\n  # included in the symbol list\n  _LT_TAGVAR(include_expsyms, $1)=\n  # exclude_expsyms can be an extended regexp of symbols to exclude\n  # it will be wrapped by ' (' and ')$', so one must not match beginning or\n  # end of line.  Example: 'a|bc|.*d.*' will exclude the symbols 'a' and 'bc',\n  # as well as any symbol that contains 'd'.\n  _LT_TAGVAR(exclude_expsyms, $1)=['_GLOBAL_OFFSET_TABLE_|_GLOBAL__F[ID]_.*']\n  # Although _GLOBAL_OFFSET_TABLE_ is a valid symbol C name, most a.out\n  # platforms (ab)use it in PIC code, but their linkers get confused if\n  # the symbol is explicitly referenced.  Since portable code cannot\n  # rely on this symbol name, it's probably fine to never include it in\n  # preloaded symbol tables.\n  # Exclude shared library initialization/finalization symbols.\ndnl Note also adjust exclude_expsyms for C++ above.\n  extract_expsyms_cmds=\n\n  case $host_os in\n  cygwin* | mingw* | pw32* | cegcc*)\n    # FIXME: the MSVC++ port hasn't been tested in a loooong time\n    # When not using gcc, we currently assume that we are using\n    # Microsoft Visual C++.\n    if test yes != \"$GCC\"; then\n      with_gnu_ld=no\n    fi\n    ;;\n  interix*)\n    # we just hope/assume this is gcc and not c89 (= MSVC++)\n    with_gnu_ld=yes\n    ;;\n  openbsd* | bitrig*)\n    with_gnu_ld=no\n    ;;\n  esac\n\n  _LT_TAGVAR(ld_shlibs, $1)=yes\n\n  # On some targets, GNU ld is compatible enough with the native linker\n  # that we're better off using the native interface for both.\n  lt_use_gnu_ld_interface=no\n  if test yes = \"$with_gnu_ld\"; then\n    case $host_os in\n      aix*)\n\t# The AIX port of GNU ld has always aspired to compatibility\n\t# with the native linker.  However, as the warning in the GNU ld\n\t# block says, versions before 2.19.5* couldn't really create working\n\t# shared libraries, regardless of the interface used.\n\tcase `$LD -v 2>&1` in\n\t  *\\ \\(GNU\\ Binutils\\)\\ 2.19.5*) ;;\n\t  *\\ \\(GNU\\ Binutils\\)\\ 2.[[2-9]]*) ;;\n\t  *\\ \\(GNU\\ Binutils\\)\\ [[3-9]]*) ;;\n\t  *)\n\t    lt_use_gnu_ld_interface=yes\n\t    ;;\n\tesac\n\t;;\n      *)\n\tlt_use_gnu_ld_interface=yes\n\t;;\n    esac\n  fi\n\n  if test yes = \"$lt_use_gnu_ld_interface\"; then\n    # If archive_cmds runs LD, not CC, wlarc should be empty\n    wlarc='$wl'\n\n    # Set some defaults for GNU ld with shared library support. These\n    # are reset later if shared libraries are not supported. Putting them\n    # here allows them to be overridden if necessary.\n    runpath_var=LD_RUN_PATH\n    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n    _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl--export-dynamic'\n    # ancient GNU ld didn't support --whole-archive et. al.\n    if $LD --help 2>&1 | $GREP 'no-whole-archive' > /dev/null; then\n      _LT_TAGVAR(whole_archive_flag_spec, $1)=$wlarc'--whole-archive$convenience '$wlarc'--no-whole-archive'\n    else\n      _LT_TAGVAR(whole_archive_flag_spec, $1)=\n    fi\n    supports_anon_versioning=no\n    case `$LD -v | $SED -e 's/([^)]\\+)\\s\\+//' 2>&1` in\n      *GNU\\ gold*) supports_anon_versioning=yes ;;\n      *\\ [[01]].* | *\\ 2.[[0-9]].* | *\\ 2.10.*) ;; # catch versions < 2.11\n      *\\ 2.11.93.0.2\\ *) supports_anon_versioning=yes ;; # RH7.3 ...\n      *\\ 2.11.92.0.12\\ *) supports_anon_versioning=yes ;; # Mandrake 8.2 ...\n      *\\ 2.11.*) ;; # other 2.11 versions\n      *) supports_anon_versioning=yes ;;\n    esac\n\n    # See if GNU ld supports shared libraries.\n    case $host_os in\n    aix[[3-9]]*)\n      # On AIX/PPC, the GNU linker is very broken\n      if test ia64 != \"$host_cpu\"; then\n\t_LT_TAGVAR(ld_shlibs, $1)=no\n\tcat <<_LT_EOF 1>&2\n\n*** Warning: the GNU linker, at least up to release 2.19, is reported\n*** to be unable to reliably create shared libraries on AIX.\n*** Therefore, libtool is disabling shared libraries support.  If you\n*** really care for shared libraries, you may want to install binutils\n*** 2.20 or above, or modify your PATH so that a non-GNU linker is found.\n*** You will then need to restart the configuration process.\n\n_LT_EOF\n      fi\n      ;;\n\n    amigaos*)\n      case $host_cpu in\n      powerpc)\n            # see comment about AmigaOS4 .so support\n            _LT_TAGVAR(archive_cmds, $1)='$CC -shared $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n            _LT_TAGVAR(archive_expsym_cmds, $1)=''\n        ;;\n      m68k)\n            _LT_TAGVAR(archive_cmds, $1)='$RM $output_objdir/a2ixlibrary.data~$ECHO \"#define NAME $libname\" > $output_objdir/a2ixlibrary.data~$ECHO \"#define LIBRARY_ID 1\" >> $output_objdir/a2ixlibrary.data~$ECHO \"#define VERSION $major\" >> $output_objdir/a2ixlibrary.data~$ECHO \"#define REVISION $revision\" >> $output_objdir/a2ixlibrary.data~$AR $AR_FLAGS $lib $libobjs~$RANLIB $lib~(cd $output_objdir && a2ixlibrary -32)'\n            _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n            _LT_TAGVAR(hardcode_minus_L, $1)=yes\n        ;;\n      esac\n      ;;\n\n    beos*)\n      if $LD --help 2>&1 | $GREP ': supported targets:.* elf' > /dev/null; then\n\t_LT_TAGVAR(allow_undefined_flag, $1)=unsupported\n\t# Joseph Beckenbach <jrb3@best.com> says some releases of gcc\n\t# support --undefined.  This deserves some investigation.  FIXME\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -nostart $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n      else\n\t_LT_TAGVAR(ld_shlibs, $1)=no\n      fi\n      ;;\n\n    cygwin* | mingw* | pw32* | cegcc*)\n      # _LT_TAGVAR(hardcode_libdir_flag_spec, $1) is actually meaningless,\n      # as there is no search path for DLLs.\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n      _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl--export-all-symbols'\n      _LT_TAGVAR(allow_undefined_flag, $1)=unsupported\n      _LT_TAGVAR(always_export_symbols, $1)=no\n      _LT_TAGVAR(enable_shared_with_static_runtimes, $1)=yes\n      _LT_TAGVAR(export_symbols_cmds, $1)='$NM $libobjs $convenience | $global_symbol_pipe | $SED -e '\\''/^[[BCDGRS]][[ ]]/s/.*[[ ]]\\([[^ ]]*\\)/\\1 DATA/;s/^.*[[ ]]__nm__\\([[^ ]]*\\)[[ ]][[^ ]]*/\\1 DATA/;/^I[[ ]]/d;/^[[AITW]][[ ]]/s/.* //'\\'' | sort | uniq > $export_symbols'\n      _LT_TAGVAR(exclude_expsyms, $1)=['[_]+GLOBAL_OFFSET_TABLE_|[_]+GLOBAL__[FID]_.*|[_]+head_[A-Za-z0-9_]+_dll|[A-Za-z0-9_]+_dll_iname']\n\n      if $LD --help 2>&1 | $GREP 'auto-import' > /dev/null; then\n        _LT_TAGVAR(archive_cmds, $1)='$CC -shared $libobjs $deplibs $compiler_flags -o $output_objdir/$soname $wl--enable-auto-image-base -Xlinker --out-implib -Xlinker $lib'\n\t# If the export-symbols file already is a .def file, use it as\n\t# is; otherwise, prepend EXPORTS...\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='if _LT_DLL_DEF_P([$export_symbols]); then\n          cp $export_symbols $output_objdir/$soname.def;\n        else\n          echo EXPORTS > $output_objdir/$soname.def;\n          cat $export_symbols >> $output_objdir/$soname.def;\n        fi~\n        $CC -shared $output_objdir/$soname.def $libobjs $deplibs $compiler_flags -o $output_objdir/$soname $wl--enable-auto-image-base -Xlinker --out-implib -Xlinker $lib'\n      else\n\t_LT_TAGVAR(ld_shlibs, $1)=no\n      fi\n      ;;\n\n    haiku*)\n      _LT_TAGVAR(archive_cmds, $1)='$CC -shared $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n      _LT_TAGVAR(link_all_deplibs, $1)=yes\n      ;;\n\n    os2*)\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n      _LT_TAGVAR(hardcode_minus_L, $1)=yes\n      _LT_TAGVAR(allow_undefined_flag, $1)=unsupported\n      shrext_cmds=.dll\n      _LT_TAGVAR(archive_cmds, $1)='$ECHO \"LIBRARY ${soname%$shared_ext} INITINSTANCE TERMINSTANCE\" > $output_objdir/$libname.def~\n\t$ECHO \"DESCRIPTION \\\"$libname\\\"\" >> $output_objdir/$libname.def~\n\t$ECHO \"DATA MULTIPLE NONSHARED\" >> $output_objdir/$libname.def~\n\t$ECHO EXPORTS >> $output_objdir/$libname.def~\n\temxexp $libobjs | $SED /\"_DLL_InitTerm\"/d >> $output_objdir/$libname.def~\n\t$CC -Zdll -Zcrtdll -o $output_objdir/$soname $libobjs $deplibs $compiler_flags $output_objdir/$libname.def~\n\temximp -o $lib $output_objdir/$libname.def'\n      _LT_TAGVAR(archive_expsym_cmds, $1)='$ECHO \"LIBRARY ${soname%$shared_ext} INITINSTANCE TERMINSTANCE\" > $output_objdir/$libname.def~\n\t$ECHO \"DESCRIPTION \\\"$libname\\\"\" >> $output_objdir/$libname.def~\n\t$ECHO \"DATA MULTIPLE NONSHARED\" >> $output_objdir/$libname.def~\n\t$ECHO EXPORTS >> $output_objdir/$libname.def~\n\tprefix_cmds=\"$SED\"~\n\tif test EXPORTS = \"`$SED 1q $export_symbols`\"; then\n\t  prefix_cmds=\"$prefix_cmds -e 1d\";\n\tfi~\n\tprefix_cmds=\"$prefix_cmds -e \\\"s/^\\(.*\\)$/_\\1/g\\\"\"~\n\tcat $export_symbols | $prefix_cmds >> $output_objdir/$libname.def~\n\t$CC -Zdll -Zcrtdll -o $output_objdir/$soname $libobjs $deplibs $compiler_flags $output_objdir/$libname.def~\n\temximp -o $lib $output_objdir/$libname.def'\n      _LT_TAGVAR(old_archive_From_new_cmds, $1)='emximp -o $output_objdir/${libname}_dll.a $output_objdir/$libname.def'\n      _LT_TAGVAR(enable_shared_with_static_runtimes, $1)=yes\n      ;;\n\n    interix[[3-9]]*)\n      _LT_TAGVAR(hardcode_direct, $1)=no\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath,$libdir'\n      _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-E'\n      # Hack: On Interix 3.x, we cannot compile PIC because of a broken gcc.\n      # Instead, shared libraries are loaded at an image base (0x10000000 by\n      # default) and relocated if they conflict, which is a slow very memory\n      # consuming and fragmenting process.  To avoid this, we pick a random,\n      # 256 KiB-aligned image base between 0x50000000 and 0x6FFC0000 at link\n      # time.  Moving up from 0x10000000 also allows more sbrk(2) space.\n      _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-h,$soname $wl--image-base,`expr ${RANDOM-$$} % 4096 / 2 \\* 262144 + 1342177280` -o $lib'\n      _LT_TAGVAR(archive_expsym_cmds, $1)='sed \"s|^|_|\" $export_symbols >$output_objdir/$soname.expsym~$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-h,$soname $wl--retain-symbols-file,$output_objdir/$soname.expsym $wl--image-base,`expr ${RANDOM-$$} % 4096 / 2 \\* 262144 + 1342177280` -o $lib'\n      ;;\n\n    gnu* | linux* | tpf* | k*bsd*-gnu | kopensolaris*-gnu)\n      tmp_diet=no\n      if test linux-dietlibc = \"$host_os\"; then\n\tcase $cc_basename in\n\t  diet\\ *) tmp_diet=yes;;\t# linux-dietlibc with static linking (!diet-dyn)\n\tesac\n      fi\n      if $LD --help 2>&1 | $EGREP ': supported targets:.* elf' > /dev/null \\\n\t && test no = \"$tmp_diet\"\n      then\n\ttmp_addflag=' $pic_flag'\n\ttmp_sharedflag='-shared'\n\tcase $cc_basename,$host_cpu in\n        pgcc*)\t\t\t\t# Portland Group C compiler\n\t  _LT_TAGVAR(whole_archive_flag_spec, $1)='$wl--whole-archive`for conv in $convenience\\\"\\\"; do test  -n \\\"$conv\\\" && new_convenience=\\\"$new_convenience,$conv\\\"; done; func_echo_all \\\"$new_convenience\\\"` $wl--no-whole-archive'\n\t  tmp_addflag=' $pic_flag'\n\t  ;;\n\tpgf77* | pgf90* | pgf95* | pgfortran*)\n\t\t\t\t\t# Portland Group f77 and f90 compilers\n\t  _LT_TAGVAR(whole_archive_flag_spec, $1)='$wl--whole-archive`for conv in $convenience\\\"\\\"; do test  -n \\\"$conv\\\" && new_convenience=\\\"$new_convenience,$conv\\\"; done; func_echo_all \\\"$new_convenience\\\"` $wl--no-whole-archive'\n\t  tmp_addflag=' $pic_flag -Mnomain' ;;\n\tecc*,ia64* | icc*,ia64*)\t# Intel C compiler on ia64\n\t  tmp_addflag=' -i_dynamic' ;;\n\tefc*,ia64* | ifort*,ia64*)\t# Intel Fortran compiler on ia64\n\t  tmp_addflag=' -i_dynamic -nofor_main' ;;\n\tifc* | ifort*)\t\t\t# Intel Fortran compiler\n\t  tmp_addflag=' -nofor_main' ;;\n\tlf95*)\t\t\t\t# Lahey Fortran 8.1\n\t  _LT_TAGVAR(whole_archive_flag_spec, $1)=\n\t  tmp_sharedflag='--shared' ;;\n        nagfor*)                        # NAGFOR 5.3\n          tmp_sharedflag='-Wl,-shared' ;;\n\txl[[cC]]* | bgxl[[cC]]* | mpixl[[cC]]*) # IBM XL C 8.0 on PPC (deal with xlf below)\n\t  tmp_sharedflag='-qmkshrobj'\n\t  tmp_addflag= ;;\n\tnvcc*)\t# Cuda Compiler Driver 2.2\n\t  _LT_TAGVAR(whole_archive_flag_spec, $1)='$wl--whole-archive`for conv in $convenience\\\"\\\"; do test  -n \\\"$conv\\\" && new_convenience=\\\"$new_convenience,$conv\\\"; done; func_echo_all \\\"$new_convenience\\\"` $wl--no-whole-archive'\n\t  _LT_TAGVAR(compiler_needs_object, $1)=yes\n\t  ;;\n\tesac\n\tcase `$CC -V 2>&1 | sed 5q` in\n\t*Sun\\ C*)\t\t\t# Sun C 5.9\n\t  _LT_TAGVAR(whole_archive_flag_spec, $1)='$wl--whole-archive`new_convenience=; for conv in $convenience\\\"\\\"; do test -z \\\"$conv\\\" || new_convenience=\\\"$new_convenience,$conv\\\"; done; func_echo_all \\\"$new_convenience\\\"` $wl--no-whole-archive'\n\t  _LT_TAGVAR(compiler_needs_object, $1)=yes\n\t  tmp_sharedflag='-G' ;;\n\t*Sun\\ F*)\t\t\t# Sun Fortran 8.3\n\t  tmp_sharedflag='-G' ;;\n\tesac\n\t_LT_TAGVAR(archive_cmds, $1)='$CC '\"$tmp_sharedflag\"\"$tmp_addflag\"' $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n\n        if test yes = \"$supports_anon_versioning\"; then\n          _LT_TAGVAR(archive_expsym_cmds, $1)='echo \"{ global:\" > $output_objdir/$libname.ver~\n            cat $export_symbols | sed -e \"s/\\(.*\\)/\\1;/\" >> $output_objdir/$libname.ver~\n            echo \"local: *; };\" >> $output_objdir/$libname.ver~\n            $CC '\"$tmp_sharedflag\"\"$tmp_addflag\"' $libobjs $deplibs $compiler_flags $wl-soname $wl$soname $wl-version-script $wl$output_objdir/$libname.ver -o $lib'\n        fi\n\n\tcase $cc_basename in\n\ttcc*)\n\t  _LT_TAGVAR(export_dynamic_flag_spec, $1)='-rdynamic'\n\t  ;;\n\txlf* | bgf* | bgxlf* | mpixlf*)\n\t  # IBM XL Fortran 10.1 on PPC cannot create shared libs itself\n\t  _LT_TAGVAR(whole_archive_flag_spec, $1)='--whole-archive$convenience --no-whole-archive'\n\t  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n\t  _LT_TAGVAR(archive_cmds, $1)='$LD -shared $libobjs $deplibs $linker_flags -soname $soname -o $lib'\n\t  if test yes = \"$supports_anon_versioning\"; then\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)='echo \"{ global:\" > $output_objdir/$libname.ver~\n              cat $export_symbols | sed -e \"s/\\(.*\\)/\\1;/\" >> $output_objdir/$libname.ver~\n              echo \"local: *; };\" >> $output_objdir/$libname.ver~\n              $LD -shared $libobjs $deplibs $linker_flags -soname $soname -version-script $output_objdir/$libname.ver -o $lib'\n\t  fi\n\t  ;;\n\tesac\n      else\n        _LT_TAGVAR(ld_shlibs, $1)=no\n      fi\n      ;;\n\n    netbsd*)\n      if echo __ELF__ | $CC -E - | $GREP __ELF__ >/dev/null; then\n\t_LT_TAGVAR(archive_cmds, $1)='$LD -Bshareable $libobjs $deplibs $linker_flags -o $lib'\n\twlarc=\n      else\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-soname $wl$soname $wl-retain-symbols-file $wl$export_symbols -o $lib'\n      fi\n      ;;\n\n    solaris*)\n      if $LD -v 2>&1 | $GREP 'BFD 2\\.8' > /dev/null; then\n\t_LT_TAGVAR(ld_shlibs, $1)=no\n\tcat <<_LT_EOF 1>&2\n\n*** Warning: The releases 2.8.* of the GNU linker cannot reliably\n*** create shared libraries on Solaris systems.  Therefore, libtool\n*** is disabling shared libraries support.  We urge you to upgrade GNU\n*** binutils to release 2.9.1 or newer.  Another option is to modify\n*** your PATH or compiler configuration so that the native linker is\n*** used, and then restart.\n\n_LT_EOF\n      elif $LD --help 2>&1 | $GREP ': supported targets:.* elf' > /dev/null; then\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-soname $wl$soname $wl-retain-symbols-file $wl$export_symbols -o $lib'\n      else\n\t_LT_TAGVAR(ld_shlibs, $1)=no\n      fi\n      ;;\n\n    sysv5* | sco3.2v5* | sco5v6* | unixware* | OpenUNIX*)\n      case `$LD -v 2>&1` in\n        *\\ [[01]].* | *\\ 2.[[0-9]].* | *\\ 2.1[[0-5]].*)\n\t_LT_TAGVAR(ld_shlibs, $1)=no\n\tcat <<_LT_EOF 1>&2\n\n*** Warning: Releases of the GNU linker prior to 2.16.91.0.3 cannot\n*** reliably create shared libraries on SCO systems.  Therefore, libtool\n*** is disabling shared libraries support.  We urge you to upgrade GNU\n*** binutils to release 2.16.91.0.3 or newer.  Another option is to modify\n*** your PATH or compiler configuration so that the native linker is\n*** used, and then restart.\n\n_LT_EOF\n\t;;\n\t*)\n\t  # For security reasons, it is highly recommended that you always\n\t  # use absolute paths for naming shared libraries, and exclude the\n\t  # DT_RUNPATH tag from executables and libraries.  But doing so\n\t  # requires that you compile everything twice, which is a pain.\n\t  if $LD --help 2>&1 | $GREP ': supported targets:.* elf' > /dev/null; then\n\t    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n\t    _LT_TAGVAR(archive_cmds, $1)='$CC -shared $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $libobjs $deplibs $compiler_flags $wl-soname $wl$soname $wl-retain-symbols-file $wl$export_symbols -o $lib'\n\t  else\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t  fi\n\t;;\n      esac\n      ;;\n\n    sunos4*)\n      _LT_TAGVAR(archive_cmds, $1)='$LD -assert pure-text -Bshareable -o $lib $libobjs $deplibs $linker_flags'\n      wlarc=\n      _LT_TAGVAR(hardcode_direct, $1)=yes\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      ;;\n\n    *)\n      if $LD --help 2>&1 | $GREP ': supported targets:.* elf' > /dev/null; then\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-soname $wl$soname $wl-retain-symbols-file $wl$export_symbols -o $lib'\n      else\n\t_LT_TAGVAR(ld_shlibs, $1)=no\n      fi\n      ;;\n    esac\n\n    if test no = \"$_LT_TAGVAR(ld_shlibs, $1)\"; then\n      runpath_var=\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)=\n      _LT_TAGVAR(export_dynamic_flag_spec, $1)=\n      _LT_TAGVAR(whole_archive_flag_spec, $1)=\n    fi\n  else\n    # PORTME fill in a description of your system's linker (not GNU ld)\n    case $host_os in\n    aix3*)\n      _LT_TAGVAR(allow_undefined_flag, $1)=unsupported\n      _LT_TAGVAR(always_export_symbols, $1)=yes\n      _LT_TAGVAR(archive_expsym_cmds, $1)='$LD -o $output_objdir/$soname $libobjs $deplibs $linker_flags -bE:$export_symbols -T512 -H512 -bM:SRE~$AR $AR_FLAGS $lib $output_objdir/$soname'\n      # Note: this linker hardcodes the directories in LIBPATH if there\n      # are no directories specified by -L.\n      _LT_TAGVAR(hardcode_minus_L, $1)=yes\n      if test yes = \"$GCC\" && test -z \"$lt_prog_compiler_static\"; then\n\t# Neither direct hardcoding nor static linking is supported with a\n\t# broken collect2.\n\t_LT_TAGVAR(hardcode_direct, $1)=unsupported\n      fi\n      ;;\n\n    aix[[4-9]]*)\n      if test ia64 = \"$host_cpu\"; then\n\t# On IA64, the linker does run time linking by default, so we don't\n\t# have to do anything special.\n\taix_use_runtimelinking=no\n\texp_sym_flag='-Bexport'\n\tno_entry_flag=\n      else\n\t# If we're using GNU nm, then we don't want the \"-C\" option.\n\t# -C means demangle to GNU nm, but means don't demangle to AIX nm.\n\t# Without the \"-l\" option, or with the \"-B\" option, AIX nm treats\n\t# weak defined symbols like other global defined symbols, whereas\n\t# GNU nm marks them as \"W\".\n\t# While the 'weak' keyword is ignored in the Export File, we need\n\t# it in the Import File for the 'aix-soname' feature, so we have\n\t# to replace the \"-B\" option with \"-P\" for AIX nm.\n\tif $NM -V 2>&1 | $GREP 'GNU' > /dev/null; then\n\t  _LT_TAGVAR(export_symbols_cmds, $1)='$NM -Bpg $libobjs $convenience | awk '\\''{ if (((\\$ 2 == \"T\") || (\\$ 2 == \"D\") || (\\$ 2 == \"B\") || (\\$ 2 == \"W\")) && ([substr](\\$ 3,1,1) != \".\")) { if (\\$ 2 == \"W\") { print \\$ 3 \" weak\" } else { print \\$ 3 } } }'\\'' | sort -u > $export_symbols'\n\telse\n\t  _LT_TAGVAR(export_symbols_cmds, $1)='`func_echo_all $NM | $SED -e '\\''s/B\\([[^B]]*\\)$/P\\1/'\\''` -PCpgl $libobjs $convenience | awk '\\''{ if (((\\$ 2 == \"T\") || (\\$ 2 == \"D\") || (\\$ 2 == \"B\") || (\\$ 2 == \"W\") || (\\$ 2 == \"V\") || (\\$ 2 == \"Z\")) && ([substr](\\$ 1,1,1) != \".\")) { if ((\\$ 2 == \"W\") || (\\$ 2 == \"V\") || (\\$ 2 == \"Z\")) { print \\$ 1 \" weak\" } else { print \\$ 1 } } }'\\'' | sort -u > $export_symbols'\n\tfi\n\taix_use_runtimelinking=no\n\n\t# Test if we are trying to use run time linking or normal\n\t# AIX style linking. If -brtl is somewhere in LDFLAGS, we\n\t# have runtime linking enabled, and use it for executables.\n\t# For shared libraries, we enable/disable runtime linking\n\t# depending on the kind of the shared library created -\n\t# when \"with_aix_soname,aix_use_runtimelinking\" is:\n\t# \"aix,no\"   lib.a(lib.so.V) shared, rtl:no,  for executables\n\t# \"aix,yes\"  lib.so          shared, rtl:yes, for executables\n\t#            lib.a           static archive\n\t# \"both,no\"  lib.so.V(shr.o) shared, rtl:yes\n\t#            lib.a(lib.so.V) shared, rtl:no,  for executables\n\t# \"both,yes\" lib.so.V(shr.o) shared, rtl:yes, for executables\n\t#            lib.a(lib.so.V) shared, rtl:no\n\t# \"svr4,*\"   lib.so.V(shr.o) shared, rtl:yes, for executables\n\t#            lib.a           static archive\n\tcase $host_os in aix4.[[23]]|aix4.[[23]].*|aix[[5-9]]*)\n\t  for ld_flag in $LDFLAGS; do\n\t  if (test x-brtl = \"x$ld_flag\" || test x-Wl,-brtl = \"x$ld_flag\"); then\n\t    aix_use_runtimelinking=yes\n\t    break\n\t  fi\n\t  done\n\t  if test svr4,no = \"$with_aix_soname,$aix_use_runtimelinking\"; then\n\t    # With aix-soname=svr4, we create the lib.so.V shared archives only,\n\t    # so we don't have lib.a shared libs to link our executables.\n\t    # We have to force runtime linking in this case.\n\t    aix_use_runtimelinking=yes\n\t    LDFLAGS=\"$LDFLAGS -Wl,-brtl\"\n\t  fi\n\t  ;;\n\tesac\n\n\texp_sym_flag='-bexport'\n\tno_entry_flag='-bnoentry'\n      fi\n\n      # When large executables or shared objects are built, AIX ld can\n      # have problems creating the table of contents.  If linking a library\n      # or program results in \"error TOC overflow\" add -mminimal-toc to\n      # CXXFLAGS/CFLAGS for g++/gcc.  In the cases where that is not\n      # enough to fix the problem, add -Wl,-bbigtoc to LDFLAGS.\n\n      _LT_TAGVAR(archive_cmds, $1)=''\n      _LT_TAGVAR(hardcode_direct, $1)=yes\n      _LT_TAGVAR(hardcode_direct_absolute, $1)=yes\n      _LT_TAGVAR(hardcode_libdir_separator, $1)=':'\n      _LT_TAGVAR(link_all_deplibs, $1)=yes\n      _LT_TAGVAR(file_list_spec, $1)='$wl-f,'\n      case $with_aix_soname,$aix_use_runtimelinking in\n      aix,*) ;; # traditional, no import file\n      svr4,* | *,yes) # use import file\n\t# The Import File defines what to hardcode.\n\t_LT_TAGVAR(hardcode_direct, $1)=no\n\t_LT_TAGVAR(hardcode_direct_absolute, $1)=no\n\t;;\n      esac\n\n      if test yes = \"$GCC\"; then\n\tcase $host_os in aix4.[[012]]|aix4.[[012]].*)\n\t# We only want to do this on AIX 4.2 and lower, the check\n\t# below for broken collect2 doesn't work under 4.3+\n\t  collect2name=`$CC -print-prog-name=collect2`\n\t  if test -f \"$collect2name\" &&\n\t   strings \"$collect2name\" | $GREP resolve_lib_name >/dev/null\n\t  then\n\t  # We have reworked collect2\n\t  :\n\t  else\n\t  # We have old collect2\n\t  _LT_TAGVAR(hardcode_direct, $1)=unsupported\n\t  # It fails to find uninstalled libraries when the uninstalled\n\t  # path is not listed in the libpath.  Setting hardcode_minus_L\n\t  # to unsupported forces relinking\n\t  _LT_TAGVAR(hardcode_minus_L, $1)=yes\n\t  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n\t  _LT_TAGVAR(hardcode_libdir_separator, $1)=\n\t  fi\n\t  ;;\n\tesac\n\tshared_flag='-shared'\n\tif test yes = \"$aix_use_runtimelinking\"; then\n\t  shared_flag=\"$shared_flag \"'$wl-G'\n\tfi\n\t# Need to ensure runtime linking is disabled for the traditional\n\t# shared library, or the linker may eventually find shared libraries\n\t# /with/ Import File - we do not want to mix them.\n\tshared_flag_aix='-shared'\n\tshared_flag_svr4='-shared $wl-G'\n      else\n\t# not using gcc\n\tif test ia64 = \"$host_cpu\"; then\n\t# VisualAge C++, Version 5.5 for AIX 5L for IA-64, Beta 3 Release\n\t# chokes on -Wl,-G. The following line is correct:\n\t  shared_flag='-G'\n\telse\n\t  if test yes = \"$aix_use_runtimelinking\"; then\n\t    shared_flag='$wl-G'\n\t  else\n\t    shared_flag='$wl-bM:SRE'\n\t  fi\n\t  shared_flag_aix='$wl-bM:SRE'\n\t  shared_flag_svr4='$wl-G'\n\tfi\n      fi\n\n      _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-bexpall'\n      # It seems that -bexpall does not export symbols beginning with\n      # underscore (_), so it is better to generate a list of symbols to export.\n      _LT_TAGVAR(always_export_symbols, $1)=yes\n      if test aix,yes = \"$with_aix_soname,$aix_use_runtimelinking\"; then\n\t# Warning - without using the other runtime loading flags (-brtl),\n\t# -berok will link without error, but may produce a broken library.\n\t_LT_TAGVAR(allow_undefined_flag, $1)='-berok'\n        # Determine the default libpath from the value encoded in an\n        # empty executable.\n        _LT_SYS_MODULE_PATH_AIX([$1])\n        _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-blibpath:$libdir:'\"$aix_libpath\"\n        _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -o $output_objdir/$soname $libobjs $deplibs $wl'$no_entry_flag' $compiler_flags `if test -n \"$allow_undefined_flag\"; then func_echo_all \"$wl$allow_undefined_flag\"; else :; fi` $wl'$exp_sym_flag:\\$export_symbols' '$shared_flag\n      else\n\tif test ia64 = \"$host_cpu\"; then\n\t  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-R $libdir:/usr/lib:/lib'\n\t  _LT_TAGVAR(allow_undefined_flag, $1)=\"-z nodefs\"\n\t  _LT_TAGVAR(archive_expsym_cmds, $1)=\"\\$CC $shared_flag\"' -o $output_objdir/$soname $libobjs $deplibs '\"\\$wl$no_entry_flag\"' $compiler_flags $wl$allow_undefined_flag '\"\\$wl$exp_sym_flag:\\$export_symbols\"\n\telse\n\t # Determine the default libpath from the value encoded in an\n\t # empty executable.\n\t _LT_SYS_MODULE_PATH_AIX([$1])\n\t _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-blibpath:$libdir:'\"$aix_libpath\"\n\t  # Warning - without using the other run time loading flags,\n\t  # -berok will link without error, but may produce a broken library.\n\t  _LT_TAGVAR(no_undefined_flag, $1)=' $wl-bernotok'\n\t  _LT_TAGVAR(allow_undefined_flag, $1)=' $wl-berok'\n\t  if test yes = \"$with_gnu_ld\"; then\n\t    # We only use this code for GNU lds that support --whole-archive.\n\t    _LT_TAGVAR(whole_archive_flag_spec, $1)='$wl--whole-archive$convenience $wl--no-whole-archive'\n\t  else\n\t    # Exported symbols can be pulled into shared objects from archives\n\t    _LT_TAGVAR(whole_archive_flag_spec, $1)='$convenience'\n\t  fi\n\t  _LT_TAGVAR(archive_cmds_need_lc, $1)=yes\n\t  _LT_TAGVAR(archive_expsym_cmds, $1)='$RM -r $output_objdir/$realname.d~$MKDIR $output_objdir/$realname.d'\n\t  # -brtl affects multiple linker settings, -berok does not and is overridden later\n\t  compiler_flags_filtered='`func_echo_all \"$compiler_flags \" | $SED -e \"s%-brtl\\\\([[, ]]\\\\)%-berok\\\\1%g\"`'\n\t  if test svr4 != \"$with_aix_soname\"; then\n\t    # This is similar to how AIX traditionally builds its shared libraries.\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)=\"$_LT_TAGVAR(archive_expsym_cmds, $1)\"'~$CC '$shared_flag_aix' -o $output_objdir/$realname.d/$soname $libobjs $deplibs $wl-bnoentry '$compiler_flags_filtered'$wl-bE:$export_symbols$allow_undefined_flag~$AR $AR_FLAGS $output_objdir/$libname$release.a $output_objdir/$realname.d/$soname'\n\t  fi\n\t  if test aix != \"$with_aix_soname\"; then\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)=\"$_LT_TAGVAR(archive_expsym_cmds, $1)\"'~$CC '$shared_flag_svr4' -o $output_objdir/$realname.d/$shared_archive_member_spec.o $libobjs $deplibs $wl-bnoentry '$compiler_flags_filtered'$wl-bE:$export_symbols$allow_undefined_flag~$STRIP -e $output_objdir/$realname.d/$shared_archive_member_spec.o~( func_echo_all \"#! $soname($shared_archive_member_spec.o)\"; if test shr_64 = \"$shared_archive_member_spec\"; then func_echo_all \"# 64\"; else func_echo_all \"# 32\"; fi; cat $export_symbols ) > $output_objdir/$realname.d/$shared_archive_member_spec.imp~$AR $AR_FLAGS $output_objdir/$soname $output_objdir/$realname.d/$shared_archive_member_spec.o $output_objdir/$realname.d/$shared_archive_member_spec.imp'\n\t  else\n\t    # used by -dlpreopen to get the symbols\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)=\"$_LT_TAGVAR(archive_expsym_cmds, $1)\"'~$MV  $output_objdir/$realname.d/$soname $output_objdir'\n\t  fi\n\t  _LT_TAGVAR(archive_expsym_cmds, $1)=\"$_LT_TAGVAR(archive_expsym_cmds, $1)\"'~$RM -r $output_objdir/$realname.d'\n\tfi\n      fi\n      ;;\n\n    amigaos*)\n      case $host_cpu in\n      powerpc)\n            # see comment about AmigaOS4 .so support\n            _LT_TAGVAR(archive_cmds, $1)='$CC -shared $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n            _LT_TAGVAR(archive_expsym_cmds, $1)=''\n        ;;\n      m68k)\n            _LT_TAGVAR(archive_cmds, $1)='$RM $output_objdir/a2ixlibrary.data~$ECHO \"#define NAME $libname\" > $output_objdir/a2ixlibrary.data~$ECHO \"#define LIBRARY_ID 1\" >> $output_objdir/a2ixlibrary.data~$ECHO \"#define VERSION $major\" >> $output_objdir/a2ixlibrary.data~$ECHO \"#define REVISION $revision\" >> $output_objdir/a2ixlibrary.data~$AR $AR_FLAGS $lib $libobjs~$RANLIB $lib~(cd $output_objdir && a2ixlibrary -32)'\n            _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n            _LT_TAGVAR(hardcode_minus_L, $1)=yes\n        ;;\n      esac\n      ;;\n\n    bsdi[[45]]*)\n      _LT_TAGVAR(export_dynamic_flag_spec, $1)=-rdynamic\n      ;;\n\n    cygwin* | mingw* | pw32* | cegcc*)\n      # When not using gcc, we currently assume that we are using\n      # Microsoft Visual C++.\n      # hardcode_libdir_flag_spec is actually meaningless, as there is\n      # no search path for DLLs.\n      case $cc_basename in\n      cl*)\n\t# Native MSVC\n\t_LT_TAGVAR(hardcode_libdir_flag_spec, $1)=' '\n\t_LT_TAGVAR(allow_undefined_flag, $1)=unsupported\n\t_LT_TAGVAR(always_export_symbols, $1)=yes\n\t_LT_TAGVAR(file_list_spec, $1)='@'\n\t# Tell ltmain to make .lib files, not .a files.\n\tlibext=lib\n\t# Tell ltmain to make .dll files, not .so files.\n\tshrext_cmds=.dll\n\t# FIXME: Setting linknames here is a bad hack.\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -o $output_objdir/$soname $libobjs $compiler_flags $deplibs -Wl,-DLL,-IMPLIB:\"$tool_output_objdir$libname.dll.lib\"~linknames='\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='if _LT_DLL_DEF_P([$export_symbols]); then\n            cp \"$export_symbols\" \"$output_objdir/$soname.def\";\n            echo \"$tool_output_objdir$soname.def\" > \"$output_objdir/$soname.exp\";\n          else\n            $SED -e '\\''s/^/-link -EXPORT:/'\\'' < $export_symbols > $output_objdir/$soname.exp;\n          fi~\n          $CC -o $tool_output_objdir$soname $libobjs $compiler_flags $deplibs \"@$tool_output_objdir$soname.exp\" -Wl,-DLL,-IMPLIB:\"$tool_output_objdir$libname.dll.lib\"~\n          linknames='\n\t# The linker will not automatically build a static lib if we build a DLL.\n\t# _LT_TAGVAR(old_archive_from_new_cmds, $1)='true'\n\t_LT_TAGVAR(enable_shared_with_static_runtimes, $1)=yes\n\t_LT_TAGVAR(exclude_expsyms, $1)='_NULL_IMPORT_DESCRIPTOR|_IMPORT_DESCRIPTOR_.*'\n\t_LT_TAGVAR(export_symbols_cmds, $1)='$NM $libobjs $convenience | $global_symbol_pipe | $SED -e '\\''/^[[BCDGRS]][[ ]]/s/.*[[ ]]\\([[^ ]]*\\)/\\1,DATA/'\\'' | $SED -e '\\''/^[[AITW]][[ ]]/s/.*[[ ]]//'\\'' | sort | uniq > $export_symbols'\n\t# Don't use ranlib\n\t_LT_TAGVAR(old_postinstall_cmds, $1)='chmod 644 $oldlib'\n\t_LT_TAGVAR(postlink_cmds, $1)='lt_outputfile=\"@OUTPUT@\"~\n          lt_tool_outputfile=\"@TOOL_OUTPUT@\"~\n          case $lt_outputfile in\n            *.exe|*.EXE) ;;\n            *)\n              lt_outputfile=$lt_outputfile.exe\n              lt_tool_outputfile=$lt_tool_outputfile.exe\n              ;;\n          esac~\n          if test : != \"$MANIFEST_TOOL\" && test -f \"$lt_outputfile.manifest\"; then\n            $MANIFEST_TOOL -manifest \"$lt_tool_outputfile.manifest\" -outputresource:\"$lt_tool_outputfile\" || exit 1;\n            $RM \"$lt_outputfile.manifest\";\n          fi'\n\t;;\n      *)\n\t# Assume MSVC wrapper\n\t_LT_TAGVAR(hardcode_libdir_flag_spec, $1)=' '\n\t_LT_TAGVAR(allow_undefined_flag, $1)=unsupported\n\t# Tell ltmain to make .lib files, not .a files.\n\tlibext=lib\n\t# Tell ltmain to make .dll files, not .so files.\n\tshrext_cmds=.dll\n\t# FIXME: Setting linknames here is a bad hack.\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -o $lib $libobjs $compiler_flags `func_echo_all \"$deplibs\" | $SED '\\''s/ -lc$//'\\''` -link -dll~linknames='\n\t# The linker will automatically build a .lib file if we build a DLL.\n\t_LT_TAGVAR(old_archive_from_new_cmds, $1)='true'\n\t# FIXME: Should let the user specify the lib program.\n\t_LT_TAGVAR(old_archive_cmds, $1)='lib -OUT:$oldlib$oldobjs$old_deplibs'\n\t_LT_TAGVAR(enable_shared_with_static_runtimes, $1)=yes\n\t;;\n      esac\n      ;;\n\n    darwin* | rhapsody*)\n      _LT_DARWIN_LINKER_FEATURES($1)\n      ;;\n\n    dgux*)\n      _LT_TAGVAR(archive_cmds, $1)='$LD -G -h $soname -o $lib $libobjs $deplibs $linker_flags'\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      ;;\n\n    # FreeBSD 2.2.[012] allows us to include c++rt0.o to get C++ constructor\n    # support.  Future versions do this automatically, but an explicit c++rt0.o\n    # does not break anything, and helps significantly (at the cost of a little\n    # extra space).\n    freebsd2.2*)\n      _LT_TAGVAR(archive_cmds, $1)='$LD -Bshareable -o $lib $libobjs $deplibs $linker_flags /usr/lib/c++rt0.o'\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-R$libdir'\n      _LT_TAGVAR(hardcode_direct, $1)=yes\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      ;;\n\n    # Unfortunately, older versions of FreeBSD 2 do not have this feature.\n    freebsd2.*)\n      _LT_TAGVAR(archive_cmds, $1)='$LD -Bshareable -o $lib $libobjs $deplibs $linker_flags'\n      _LT_TAGVAR(hardcode_direct, $1)=yes\n      _LT_TAGVAR(hardcode_minus_L, $1)=yes\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      ;;\n\n    # FreeBSD 3 and greater uses gcc -shared to do shared libraries.\n    freebsd* | dragonfly*)\n      _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag -o $lib $libobjs $deplibs $compiler_flags'\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-R$libdir'\n      _LT_TAGVAR(hardcode_direct, $1)=yes\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      ;;\n\n    hpux9*)\n      if test yes = \"$GCC\"; then\n\t_LT_TAGVAR(archive_cmds, $1)='$RM $output_objdir/$soname~$CC -shared $pic_flag $wl+b $wl$install_libdir -o $output_objdir/$soname $libobjs $deplibs $compiler_flags~test \"x$output_objdir/$soname\" = \"x$lib\" || mv $output_objdir/$soname $lib'\n      else\n\t_LT_TAGVAR(archive_cmds, $1)='$RM $output_objdir/$soname~$LD -b +b $install_libdir -o $output_objdir/$soname $libobjs $deplibs $linker_flags~test \"x$output_objdir/$soname\" = \"x$lib\" || mv $output_objdir/$soname $lib'\n      fi\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl+b $wl$libdir'\n      _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n      _LT_TAGVAR(hardcode_direct, $1)=yes\n\n      # hardcode_minus_L: Not really in the search PATH,\n      # but as the default location of the library.\n      _LT_TAGVAR(hardcode_minus_L, $1)=yes\n      _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-E'\n      ;;\n\n    hpux10*)\n      if test yes,no = \"$GCC,$with_gnu_ld\"; then\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $wl+h $wl$soname $wl+b $wl$install_libdir -o $lib $libobjs $deplibs $compiler_flags'\n      else\n\t_LT_TAGVAR(archive_cmds, $1)='$LD -b +h $soname +b $install_libdir -o $lib $libobjs $deplibs $linker_flags'\n      fi\n      if test no = \"$with_gnu_ld\"; then\n\t_LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl+b $wl$libdir'\n\t_LT_TAGVAR(hardcode_libdir_separator, $1)=:\n\t_LT_TAGVAR(hardcode_direct, $1)=yes\n\t_LT_TAGVAR(hardcode_direct_absolute, $1)=yes\n\t_LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-E'\n\t# hardcode_minus_L: Not really in the search PATH,\n\t# but as the default location of the library.\n\t_LT_TAGVAR(hardcode_minus_L, $1)=yes\n      fi\n      ;;\n\n    hpux11*)\n      if test yes,no = \"$GCC,$with_gnu_ld\"; then\n\tcase $host_cpu in\n\thppa*64*)\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -shared $wl+h $wl$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t  ;;\n\tia64*)\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $wl+h $wl$soname $wl+nodefaultrpath -o $lib $libobjs $deplibs $compiler_flags'\n\t  ;;\n\t*)\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $wl+h $wl$soname $wl+b $wl$install_libdir -o $lib $libobjs $deplibs $compiler_flags'\n\t  ;;\n\tesac\n      else\n\tcase $host_cpu in\n\thppa*64*)\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -b $wl+h $wl$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t  ;;\n\tia64*)\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -b $wl+h $wl$soname $wl+nodefaultrpath -o $lib $libobjs $deplibs $compiler_flags'\n\t  ;;\n\t*)\n\tm4_if($1, [], [\n\t  # Older versions of the 11.00 compiler do not understand -b yet\n\t  # (HP92453-01 A.11.01.20 doesn't, HP92453-01 B.11.X.35175-35176.GP does)\n\t  _LT_LINKER_OPTION([if $CC understands -b],\n\t    _LT_TAGVAR(lt_cv_prog_compiler__b, $1), [-b],\n\t    [_LT_TAGVAR(archive_cmds, $1)='$CC -b $wl+h $wl$soname $wl+b $wl$install_libdir -o $lib $libobjs $deplibs $compiler_flags'],\n\t    [_LT_TAGVAR(archive_cmds, $1)='$LD -b +h $soname +b $install_libdir -o $lib $libobjs $deplibs $linker_flags'])],\n\t  [_LT_TAGVAR(archive_cmds, $1)='$CC -b $wl+h $wl$soname $wl+b $wl$install_libdir -o $lib $libobjs $deplibs $compiler_flags'])\n\t  ;;\n\tesac\n      fi\n      if test no = \"$with_gnu_ld\"; then\n\t_LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl+b $wl$libdir'\n\t_LT_TAGVAR(hardcode_libdir_separator, $1)=:\n\n\tcase $host_cpu in\n\thppa*64*|ia64*)\n\t  _LT_TAGVAR(hardcode_direct, $1)=no\n\t  _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n\t  ;;\n\t*)\n\t  _LT_TAGVAR(hardcode_direct, $1)=yes\n\t  _LT_TAGVAR(hardcode_direct_absolute, $1)=yes\n\t  _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-E'\n\n\t  # hardcode_minus_L: Not really in the search PATH,\n\t  # but as the default location of the library.\n\t  _LT_TAGVAR(hardcode_minus_L, $1)=yes\n\t  ;;\n\tesac\n      fi\n      ;;\n\n    irix5* | irix6* | nonstopux*)\n      if test yes = \"$GCC\"; then\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-soname $wl$soname `test -n \"$verstring\" && func_echo_all \"$wl-set_version $wl$verstring\"` $wl-update_registry $wl$output_objdir/so_locations -o $lib'\n\t# Try to use the -exported_symbol ld option, if it does not\n\t# work, assume that -exports_file does not work either and\n\t# implicitly export all symbols.\n\t# This should be the same for all languages, so no per-tag cache variable.\n\tAC_CACHE_CHECK([whether the $host_os linker accepts -exported_symbol],\n\t  [lt_cv_irix_exported_symbol],\n\t  [save_LDFLAGS=$LDFLAGS\n\t   LDFLAGS=\"$LDFLAGS -shared $wl-exported_symbol ${wl}foo $wl-update_registry $wl/dev/null\"\n\t   AC_LINK_IFELSE(\n\t     [AC_LANG_SOURCE(\n\t        [AC_LANG_CASE([C], [[int foo (void) { return 0; }]],\n\t\t\t      [C++], [[int foo (void) { return 0; }]],\n\t\t\t      [Fortran 77], [[\n      subroutine foo\n      end]],\n\t\t\t      [Fortran], [[\n      subroutine foo\n      end]])])],\n\t      [lt_cv_irix_exported_symbol=yes],\n\t      [lt_cv_irix_exported_symbol=no])\n           LDFLAGS=$save_LDFLAGS])\n\tif test yes = \"$lt_cv_irix_exported_symbol\"; then\n          _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-soname $wl$soname `test -n \"$verstring\" && func_echo_all \"$wl-set_version $wl$verstring\"` $wl-update_registry $wl$output_objdir/so_locations $wl-exports_file $wl$export_symbols -o $lib'\n\tfi\n      else\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared $libobjs $deplibs $compiler_flags -soname $soname `test -n \"$verstring\" && func_echo_all \"-set_version $verstring\"` -update_registry $output_objdir/so_locations -o $lib'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $libobjs $deplibs $compiler_flags -soname $soname `test -n \"$verstring\" && func_echo_all \"-set_version $verstring\"` -update_registry $output_objdir/so_locations -exports_file $export_symbols -o $lib'\n      fi\n      _LT_TAGVAR(archive_cmds_need_lc, $1)='no'\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n      _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n      _LT_TAGVAR(inherit_rpath, $1)=yes\n      _LT_TAGVAR(link_all_deplibs, $1)=yes\n      ;;\n\n    linux*)\n      case $cc_basename in\n      tcc*)\n\t# Fabrice Bellard et al's Tiny C Compiler\n\t_LT_TAGVAR(ld_shlibs, $1)=yes\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag -o $lib $libobjs $deplibs $compiler_flags'\n\t;;\n      esac\n      ;;\n\n    netbsd*)\n      if echo __ELF__ | $CC -E - | $GREP __ELF__ >/dev/null; then\n\t_LT_TAGVAR(archive_cmds, $1)='$LD -Bshareable -o $lib $libobjs $deplibs $linker_flags'  # a.out\n      else\n\t_LT_TAGVAR(archive_cmds, $1)='$LD -shared -o $lib $libobjs $deplibs $linker_flags'      # ELF\n      fi\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-R$libdir'\n      _LT_TAGVAR(hardcode_direct, $1)=yes\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      ;;\n\n    newsos6)\n      _LT_TAGVAR(archive_cmds, $1)='$LD -G -h $soname -o $lib $libobjs $deplibs $linker_flags'\n      _LT_TAGVAR(hardcode_direct, $1)=yes\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n      _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      ;;\n\n    *nto* | *qnx*)\n      ;;\n\n    openbsd* | bitrig*)\n      if test -f /usr/libexec/ld.so; then\n\t_LT_TAGVAR(hardcode_direct, $1)=yes\n\t_LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n\t_LT_TAGVAR(hardcode_direct_absolute, $1)=yes\n\tif test -z \"`echo __ELF__ | $CC -E - | $GREP __ELF__`\"; then\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag -o $lib $libobjs $deplibs $compiler_flags'\n\t  _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $pic_flag -o $lib $libobjs $deplibs $compiler_flags $wl-retain-symbols-file,$export_symbols'\n\t  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath,$libdir'\n\t  _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-E'\n\telse\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag -o $lib $libobjs $deplibs $compiler_flags'\n\t  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath,$libdir'\n\tfi\n      else\n\t_LT_TAGVAR(ld_shlibs, $1)=no\n      fi\n      ;;\n\n    os2*)\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n      _LT_TAGVAR(hardcode_minus_L, $1)=yes\n      _LT_TAGVAR(allow_undefined_flag, $1)=unsupported\n      shrext_cmds=.dll\n      _LT_TAGVAR(archive_cmds, $1)='$ECHO \"LIBRARY ${soname%$shared_ext} INITINSTANCE TERMINSTANCE\" > $output_objdir/$libname.def~\n\t$ECHO \"DESCRIPTION \\\"$libname\\\"\" >> $output_objdir/$libname.def~\n\t$ECHO \"DATA MULTIPLE NONSHARED\" >> $output_objdir/$libname.def~\n\t$ECHO EXPORTS >> $output_objdir/$libname.def~\n\temxexp $libobjs | $SED /\"_DLL_InitTerm\"/d >> $output_objdir/$libname.def~\n\t$CC -Zdll -Zcrtdll -o $output_objdir/$soname $libobjs $deplibs $compiler_flags $output_objdir/$libname.def~\n\temximp -o $lib $output_objdir/$libname.def'\n      _LT_TAGVAR(archive_expsym_cmds, $1)='$ECHO \"LIBRARY ${soname%$shared_ext} INITINSTANCE TERMINSTANCE\" > $output_objdir/$libname.def~\n\t$ECHO \"DESCRIPTION \\\"$libname\\\"\" >> $output_objdir/$libname.def~\n\t$ECHO \"DATA MULTIPLE NONSHARED\" >> $output_objdir/$libname.def~\n\t$ECHO EXPORTS >> $output_objdir/$libname.def~\n\tprefix_cmds=\"$SED\"~\n\tif test EXPORTS = \"`$SED 1q $export_symbols`\"; then\n\t  prefix_cmds=\"$prefix_cmds -e 1d\";\n\tfi~\n\tprefix_cmds=\"$prefix_cmds -e \\\"s/^\\(.*\\)$/_\\1/g\\\"\"~\n\tcat $export_symbols | $prefix_cmds >> $output_objdir/$libname.def~\n\t$CC -Zdll -Zcrtdll -o $output_objdir/$soname $libobjs $deplibs $compiler_flags $output_objdir/$libname.def~\n\temximp -o $lib $output_objdir/$libname.def'\n      _LT_TAGVAR(old_archive_From_new_cmds, $1)='emximp -o $output_objdir/${libname}_dll.a $output_objdir/$libname.def'\n      _LT_TAGVAR(enable_shared_with_static_runtimes, $1)=yes\n      ;;\n\n    osf3*)\n      if test yes = \"$GCC\"; then\n\t_LT_TAGVAR(allow_undefined_flag, $1)=' $wl-expect_unresolved $wl\\*'\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared$allow_undefined_flag $libobjs $deplibs $compiler_flags $wl-soname $wl$soname `test -n \"$verstring\" && func_echo_all \"$wl-set_version $wl$verstring\"` $wl-update_registry $wl$output_objdir/so_locations -o $lib'\n      else\n\t_LT_TAGVAR(allow_undefined_flag, $1)=' -expect_unresolved \\*'\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared$allow_undefined_flag $libobjs $deplibs $compiler_flags -soname $soname `test -n \"$verstring\" && func_echo_all \"-set_version $verstring\"` -update_registry $output_objdir/so_locations -o $lib'\n      fi\n      _LT_TAGVAR(archive_cmds_need_lc, $1)='no'\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n      _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n      ;;\n\n    osf4* | osf5*)\t# as osf3* with the addition of -msym flag\n      if test yes = \"$GCC\"; then\n\t_LT_TAGVAR(allow_undefined_flag, $1)=' $wl-expect_unresolved $wl\\*'\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared$allow_undefined_flag $pic_flag $libobjs $deplibs $compiler_flags $wl-msym $wl-soname $wl$soname `test -n \"$verstring\" && func_echo_all \"$wl-set_version $wl$verstring\"` $wl-update_registry $wl$output_objdir/so_locations -o $lib'\n\t_LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n      else\n\t_LT_TAGVAR(allow_undefined_flag, $1)=' -expect_unresolved \\*'\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared$allow_undefined_flag $libobjs $deplibs $compiler_flags -msym -soname $soname `test -n \"$verstring\" && func_echo_all \"-set_version $verstring\"` -update_registry $output_objdir/so_locations -o $lib'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='for i in `cat $export_symbols`; do printf \"%s %s\\\\n\" -exported_symbol \"\\$i\" >> $lib.exp; done; printf \"%s\\\\n\" \"-hidden\">> $lib.exp~\n          $CC -shared$allow_undefined_flag $wl-input $wl$lib.exp $compiler_flags $libobjs $deplibs -soname $soname `test -n \"$verstring\" && $ECHO \"-set_version $verstring\"` -update_registry $output_objdir/so_locations -o $lib~$RM $lib.exp'\n\n\t# Both c and cxx compiler support -rpath directly\n\t_LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-rpath $libdir'\n      fi\n      _LT_TAGVAR(archive_cmds_need_lc, $1)='no'\n      _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n      ;;\n\n    solaris*)\n      _LT_TAGVAR(no_undefined_flag, $1)=' -z defs'\n      if test yes = \"$GCC\"; then\n\twlarc='$wl'\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $wl-z ${wl}text $wl-h $wl$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='echo \"{ global:\" > $lib.exp~cat $export_symbols | $SED -e \"s/\\(.*\\)/\\1;/\" >> $lib.exp~echo \"local: *; };\" >> $lib.exp~\n          $CC -shared $pic_flag $wl-z ${wl}text $wl-M $wl$lib.exp $wl-h $wl$soname -o $lib $libobjs $deplibs $compiler_flags~$RM $lib.exp'\n      else\n\tcase `$CC -V 2>&1` in\n\t*\"Compilers 5.0\"*)\n\t  wlarc=''\n\t  _LT_TAGVAR(archive_cmds, $1)='$LD -G$allow_undefined_flag -h $soname -o $lib $libobjs $deplibs $linker_flags'\n\t  _LT_TAGVAR(archive_expsym_cmds, $1)='echo \"{ global:\" > $lib.exp~cat $export_symbols | $SED -e \"s/\\(.*\\)/\\1;/\" >> $lib.exp~echo \"local: *; };\" >> $lib.exp~\n            $LD -G$allow_undefined_flag -M $lib.exp -h $soname -o $lib $libobjs $deplibs $linker_flags~$RM $lib.exp'\n\t  ;;\n\t*)\n\t  wlarc='$wl'\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -G$allow_undefined_flag -h $soname -o $lib $libobjs $deplibs $compiler_flags'\n\t  _LT_TAGVAR(archive_expsym_cmds, $1)='echo \"{ global:\" > $lib.exp~cat $export_symbols | $SED -e \"s/\\(.*\\)/\\1;/\" >> $lib.exp~echo \"local: *; };\" >> $lib.exp~\n            $CC -G$allow_undefined_flag -M $lib.exp -h $soname -o $lib $libobjs $deplibs $compiler_flags~$RM $lib.exp'\n\t  ;;\n\tesac\n      fi\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-R$libdir'\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      case $host_os in\n      solaris2.[[0-5]] | solaris2.[[0-5]].*) ;;\n      *)\n\t# The compiler driver will combine and reorder linker options,\n\t# but understands '-z linker_flag'.  GCC discards it without '$wl',\n\t# but is careful enough not to reorder.\n\t# Supported since Solaris 2.6 (maybe 2.5.1?)\n\tif test yes = \"$GCC\"; then\n\t  _LT_TAGVAR(whole_archive_flag_spec, $1)='$wl-z ${wl}allextract$convenience $wl-z ${wl}defaultextract'\n\telse\n\t  _LT_TAGVAR(whole_archive_flag_spec, $1)='-z allextract$convenience -z defaultextract'\n\tfi\n\t;;\n      esac\n      _LT_TAGVAR(link_all_deplibs, $1)=yes\n      ;;\n\n    sunos4*)\n      if test sequent = \"$host_vendor\"; then\n\t# Use $CC to link under sequent, because it throws in some extra .o\n\t# files that make .init and .fini sections work.\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -G $wl-h $soname -o $lib $libobjs $deplibs $compiler_flags'\n      else\n\t_LT_TAGVAR(archive_cmds, $1)='$LD -assert pure-text -Bstatic -o $lib $libobjs $deplibs $linker_flags'\n      fi\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n      _LT_TAGVAR(hardcode_direct, $1)=yes\n      _LT_TAGVAR(hardcode_minus_L, $1)=yes\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      ;;\n\n    sysv4)\n      case $host_vendor in\n\tsni)\n\t  _LT_TAGVAR(archive_cmds, $1)='$LD -G -h $soname -o $lib $libobjs $deplibs $linker_flags'\n\t  _LT_TAGVAR(hardcode_direct, $1)=yes # is this really true???\n\t;;\n\tsiemens)\n\t  ## LD is ld it makes a PLAMLIB\n\t  ## CC just makes a GrossModule.\n\t  _LT_TAGVAR(archive_cmds, $1)='$LD -G -o $lib $libobjs $deplibs $linker_flags'\n\t  _LT_TAGVAR(reload_cmds, $1)='$CC -r -o $output$reload_objs'\n\t  _LT_TAGVAR(hardcode_direct, $1)=no\n        ;;\n\tmotorola)\n\t  _LT_TAGVAR(archive_cmds, $1)='$LD -G -h $soname -o $lib $libobjs $deplibs $linker_flags'\n\t  _LT_TAGVAR(hardcode_direct, $1)=no #Motorola manual says yes, but my tests say they lie\n\t;;\n      esac\n      runpath_var='LD_RUN_PATH'\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      ;;\n\n    sysv4.3*)\n      _LT_TAGVAR(archive_cmds, $1)='$LD -G -h $soname -o $lib $libobjs $deplibs $linker_flags'\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      _LT_TAGVAR(export_dynamic_flag_spec, $1)='-Bexport'\n      ;;\n\n    sysv4*MP*)\n      if test -d /usr/nec; then\n\t_LT_TAGVAR(archive_cmds, $1)='$LD -G -h $soname -o $lib $libobjs $deplibs $linker_flags'\n\t_LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n\trunpath_var=LD_RUN_PATH\n\thardcode_runpath_var=yes\n\t_LT_TAGVAR(ld_shlibs, $1)=yes\n      fi\n      ;;\n\n    sysv4*uw2* | sysv5OpenUNIX* | sysv5UnixWare7.[[01]].[[10]]* | unixware7* | sco3.2v5.0.[[024]]*)\n      _LT_TAGVAR(no_undefined_flag, $1)='$wl-z,text'\n      _LT_TAGVAR(archive_cmds_need_lc, $1)=no\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      runpath_var='LD_RUN_PATH'\n\n      if test yes = \"$GCC\"; then\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $wl-Bexport:$export_symbols $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n      else\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -G $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='$CC -G $wl-Bexport:$export_symbols $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n      fi\n      ;;\n\n    sysv5* | sco3.2v5* | sco5v6*)\n      # Note: We CANNOT use -z defs as we might desire, because we do not\n      # link with -lc, and that would cause any symbols used from libc to\n      # always be unresolved, which means just about no library would\n      # ever link correctly.  If we're not using GNU ld we use -z text\n      # though, which does catch some bad symbols but isn't as heavy-handed\n      # as -z defs.\n      _LT_TAGVAR(no_undefined_flag, $1)='$wl-z,text'\n      _LT_TAGVAR(allow_undefined_flag, $1)='$wl-z,nodefs'\n      _LT_TAGVAR(archive_cmds_need_lc, $1)=no\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-R,$libdir'\n      _LT_TAGVAR(hardcode_libdir_separator, $1)=':'\n      _LT_TAGVAR(link_all_deplibs, $1)=yes\n      _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-Bexport'\n      runpath_var='LD_RUN_PATH'\n\n      if test yes = \"$GCC\"; then\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $wl-Bexport:$export_symbols $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n      else\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -G $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='$CC -G $wl-Bexport:$export_symbols $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n      fi\n      ;;\n\n    uts4*)\n      _LT_TAGVAR(archive_cmds, $1)='$LD -G -h $soname -o $lib $libobjs $deplibs $linker_flags'\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      ;;\n\n    *)\n      _LT_TAGVAR(ld_shlibs, $1)=no\n      ;;\n    esac\n\n    if test sni = \"$host_vendor\"; then\n      case $host in\n      sysv4 | sysv4.2uw2* | sysv4.3* | sysv5*)\n\t_LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-Blargedynsym'\n\t;;\n      esac\n    fi\n  fi\n])\nAC_MSG_RESULT([$_LT_TAGVAR(ld_shlibs, $1)])\ntest no = \"$_LT_TAGVAR(ld_shlibs, $1)\" && can_build_shared=no\n\n_LT_TAGVAR(with_gnu_ld, $1)=$with_gnu_ld\n\n_LT_DECL([], [libext], [0], [Old archive suffix (normally \"a\")])dnl\n_LT_DECL([], [shrext_cmds], [1], [Shared library suffix (normally \".so\")])dnl\n_LT_DECL([], [extract_expsyms_cmds], [2],\n    [The commands to extract the exported symbol list from a shared archive])\n\n#\n# Do we need to explicitly link libc?\n#\ncase \"x$_LT_TAGVAR(archive_cmds_need_lc, $1)\" in\nx|xyes)\n  # Assume -lc should be added\n  _LT_TAGVAR(archive_cmds_need_lc, $1)=yes\n\n  if test yes,yes = \"$GCC,$enable_shared\"; then\n    case $_LT_TAGVAR(archive_cmds, $1) in\n    *'~'*)\n      # FIXME: we may have to deal with multi-command sequences.\n      ;;\n    '$CC '*)\n      # Test whether the compiler implicitly links with -lc since on some\n      # systems, -lgcc has to come before -lc. If gcc already passes -lc\n      # to ld, don't add -lc before -lgcc.\n      AC_CACHE_CHECK([whether -lc should be explicitly linked in],\n\t[lt_cv_]_LT_TAGVAR(archive_cmds_need_lc, $1),\n\t[$RM conftest*\n\techo \"$lt_simple_compile_test_code\" > conftest.$ac_ext\n\n\tif AC_TRY_EVAL(ac_compile) 2>conftest.err; then\n\t  soname=conftest\n\t  lib=conftest\n\t  libobjs=conftest.$ac_objext\n\t  deplibs=\n\t  wl=$_LT_TAGVAR(lt_prog_compiler_wl, $1)\n\t  pic_flag=$_LT_TAGVAR(lt_prog_compiler_pic, $1)\n\t  compiler_flags=-v\n\t  linker_flags=-v\n\t  verstring=\n\t  output_objdir=.\n\t  libname=conftest\n\t  lt_save_allow_undefined_flag=$_LT_TAGVAR(allow_undefined_flag, $1)\n\t  _LT_TAGVAR(allow_undefined_flag, $1)=\n\t  if AC_TRY_EVAL(_LT_TAGVAR(archive_cmds, $1) 2\\>\\&1 \\| $GREP \\\" -lc \\\" \\>/dev/null 2\\>\\&1)\n\t  then\n\t    lt_cv_[]_LT_TAGVAR(archive_cmds_need_lc, $1)=no\n\t  else\n\t    lt_cv_[]_LT_TAGVAR(archive_cmds_need_lc, $1)=yes\n\t  fi\n\t  _LT_TAGVAR(allow_undefined_flag, $1)=$lt_save_allow_undefined_flag\n\telse\n\t  cat conftest.err 1>&5\n\tfi\n\t$RM conftest*\n\t])\n      _LT_TAGVAR(archive_cmds_need_lc, $1)=$lt_cv_[]_LT_TAGVAR(archive_cmds_need_lc, $1)\n      ;;\n    esac\n  fi\n  ;;\nesac\n\n_LT_TAGDECL([build_libtool_need_lc], [archive_cmds_need_lc], [0],\n    [Whether or not to add -lc for building shared libraries])\n_LT_TAGDECL([allow_libtool_libs_with_static_runtimes],\n    [enable_shared_with_static_runtimes], [0],\n    [Whether or not to disallow shared libs when runtime libs are static])\n_LT_TAGDECL([], [export_dynamic_flag_spec], [1],\n    [Compiler flag to allow reflexive dlopens])\n_LT_TAGDECL([], [whole_archive_flag_spec], [1],\n    [Compiler flag to generate shared objects directly from archives])\n_LT_TAGDECL([], [compiler_needs_object], [1],\n    [Whether the compiler copes with passing no objects directly])\n_LT_TAGDECL([], [old_archive_from_new_cmds], [2],\n    [Create an old-style archive from a shared archive])\n_LT_TAGDECL([], [old_archive_from_expsyms_cmds], [2],\n    [Create a temporary old-style archive to link instead of a shared archive])\n_LT_TAGDECL([], [archive_cmds], [2], [Commands used to build a shared archive])\n_LT_TAGDECL([], [archive_expsym_cmds], [2])\n_LT_TAGDECL([], [module_cmds], [2],\n    [Commands used to build a loadable module if different from building\n    a shared archive.])\n_LT_TAGDECL([], [module_expsym_cmds], [2])\n_LT_TAGDECL([], [with_gnu_ld], [1],\n    [Whether we are building with GNU ld or not])\n_LT_TAGDECL([], [allow_undefined_flag], [1],\n    [Flag that allows shared libraries with undefined symbols to be built])\n_LT_TAGDECL([], [no_undefined_flag], [1],\n    [Flag that enforces no undefined symbols])\n_LT_TAGDECL([], [hardcode_libdir_flag_spec], [1],\n    [Flag to hardcode $libdir into a binary during linking.\n    This must work even if $libdir does not exist])\n_LT_TAGDECL([], [hardcode_libdir_separator], [1],\n    [Whether we need a single \"-rpath\" flag with a separated argument])\n_LT_TAGDECL([], [hardcode_direct], [0],\n    [Set to \"yes\" if using DIR/libNAME$shared_ext during linking hardcodes\n    DIR into the resulting binary])\n_LT_TAGDECL([], [hardcode_direct_absolute], [0],\n    [Set to \"yes\" if using DIR/libNAME$shared_ext during linking hardcodes\n    DIR into the resulting binary and the resulting library dependency is\n    \"absolute\", i.e impossible to change by setting $shlibpath_var if the\n    library is relocated])\n_LT_TAGDECL([], [hardcode_minus_L], [0],\n    [Set to \"yes\" if using the -LDIR flag during linking hardcodes DIR\n    into the resulting binary])\n_LT_TAGDECL([], [hardcode_shlibpath_var], [0],\n    [Set to \"yes\" if using SHLIBPATH_VAR=DIR during linking hardcodes DIR\n    into the resulting binary])\n_LT_TAGDECL([], [hardcode_automatic], [0],\n    [Set to \"yes\" if building a shared library automatically hardcodes DIR\n    into the library and all subsequent libraries and executables linked\n    against it])\n_LT_TAGDECL([], [inherit_rpath], [0],\n    [Set to yes if linker adds runtime paths of dependent libraries\n    to runtime path list])\n_LT_TAGDECL([], [link_all_deplibs], [0],\n    [Whether libtool must link a program against all its dependency libraries])\n_LT_TAGDECL([], [always_export_symbols], [0],\n    [Set to \"yes\" if exported symbols are required])\n_LT_TAGDECL([], [export_symbols_cmds], [2],\n    [The commands to list exported symbols])\n_LT_TAGDECL([], [exclude_expsyms], [1],\n    [Symbols that should not be listed in the preloaded symbols])\n_LT_TAGDECL([], [include_expsyms], [1],\n    [Symbols that must always be exported])\n_LT_TAGDECL([], [prelink_cmds], [2],\n    [Commands necessary for linking programs (against libraries) with templates])\n_LT_TAGDECL([], [postlink_cmds], [2],\n    [Commands necessary for finishing linking programs])\n_LT_TAGDECL([], [file_list_spec], [1],\n    [Specify filename containing input files])\ndnl FIXME: Not yet implemented\ndnl _LT_TAGDECL([], [thread_safe_flag_spec], [1],\ndnl    [Compiler flag to generate thread safe objects])\n])# _LT_LINKER_SHLIBS\n\n\n# _LT_LANG_C_CONFIG([TAG])\n# ------------------------\n# Ensure that the configuration variables for a C compiler are suitably\n# defined.  These variables are subsequently used by _LT_CONFIG to write\n# the compiler configuration to 'libtool'.\nm4_defun([_LT_LANG_C_CONFIG],\n[m4_require([_LT_DECL_EGREP])dnl\nlt_save_CC=$CC\nAC_LANG_PUSH(C)\n\n# Source file extension for C test sources.\nac_ext=c\n\n# Object file extension for compiled C test sources.\nobjext=o\n_LT_TAGVAR(objext, $1)=$objext\n\n# Code to be used in simple compile tests\nlt_simple_compile_test_code=\"int some_variable = 0;\"\n\n# Code to be used in simple link tests\nlt_simple_link_test_code='int main(){return(0);}'\n\n_LT_TAG_COMPILER\n# Save the default compiler, since it gets overwritten when the other\n# tags are being tested, and _LT_TAGVAR(compiler, []) is a NOP.\ncompiler_DEFAULT=$CC\n\n# save warnings/boilerplate of simple test code\n_LT_COMPILER_BOILERPLATE\n_LT_LINKER_BOILERPLATE\n\n## CAVEAT EMPTOR:\n## There is no encapsulation within the following macros, do not change\n## the running order or otherwise move them around unless you know exactly\n## what you are doing...\nif test -n \"$compiler\"; then\n  _LT_COMPILER_NO_RTTI($1)\n  _LT_COMPILER_PIC($1)\n  _LT_COMPILER_C_O($1)\n  _LT_COMPILER_FILE_LOCKS($1)\n  _LT_LINKER_SHLIBS($1)\n  _LT_SYS_DYNAMIC_LINKER($1)\n  _LT_LINKER_HARDCODE_LIBPATH($1)\n  LT_SYS_DLOPEN_SELF\n  _LT_CMD_STRIPLIB\n\n  # Report what library types will actually be built\n  AC_MSG_CHECKING([if libtool supports shared libraries])\n  AC_MSG_RESULT([$can_build_shared])\n\n  AC_MSG_CHECKING([whether to build shared libraries])\n  test no = \"$can_build_shared\" && enable_shared=no\n\n  # On AIX, shared libraries and static libraries use the same namespace, and\n  # are all built from PIC.\n  case $host_os in\n  aix3*)\n    test yes = \"$enable_shared\" && enable_static=no\n    if test -n \"$RANLIB\"; then\n      archive_cmds=\"$archive_cmds~\\$RANLIB \\$lib\"\n      postinstall_cmds='$RANLIB $lib'\n    fi\n    ;;\n\n  aix[[4-9]]*)\n    if test ia64 != \"$host_cpu\"; then\n      case $enable_shared,$with_aix_soname,$aix_use_runtimelinking in\n      yes,aix,yes) ;;\t\t\t# shared object as lib.so file only\n      yes,svr4,*) ;;\t\t\t# shared object as lib.so archive member only\n      yes,*) enable_static=no ;;\t# shared object in lib.a archive as well\n      esac\n    fi\n    ;;\n  esac\n  AC_MSG_RESULT([$enable_shared])\n\n  AC_MSG_CHECKING([whether to build static libraries])\n  # Make sure either enable_shared or enable_static is yes.\n  test yes = \"$enable_shared\" || enable_static=yes\n  AC_MSG_RESULT([$enable_static])\n\n  _LT_CONFIG($1)\nfi\nAC_LANG_POP\nCC=$lt_save_CC\n])# _LT_LANG_C_CONFIG\n\n\n# _LT_LANG_CXX_CONFIG([TAG])\n# --------------------------\n# Ensure that the configuration variables for a C++ compiler are suitably\n# defined.  These variables are subsequently used by _LT_CONFIG to write\n# the compiler configuration to 'libtool'.\nm4_defun([_LT_LANG_CXX_CONFIG],\n[m4_require([_LT_FILEUTILS_DEFAULTS])dnl\nm4_require([_LT_DECL_EGREP])dnl\nm4_require([_LT_PATH_MANIFEST_TOOL])dnl\nif test -n \"$CXX\" && ( test no != \"$CXX\" &&\n    ( (test g++ = \"$CXX\" && `g++ -v >/dev/null 2>&1` ) ||\n    (test g++ != \"$CXX\"))); then\n  AC_PROG_CXXCPP\nelse\n  _lt_caught_CXX_error=yes\nfi\n\nAC_LANG_PUSH(C++)\n_LT_TAGVAR(archive_cmds_need_lc, $1)=no\n_LT_TAGVAR(allow_undefined_flag, $1)=\n_LT_TAGVAR(always_export_symbols, $1)=no\n_LT_TAGVAR(archive_expsym_cmds, $1)=\n_LT_TAGVAR(compiler_needs_object, $1)=no\n_LT_TAGVAR(export_dynamic_flag_spec, $1)=\n_LT_TAGVAR(hardcode_direct, $1)=no\n_LT_TAGVAR(hardcode_direct_absolute, $1)=no\n_LT_TAGVAR(hardcode_libdir_flag_spec, $1)=\n_LT_TAGVAR(hardcode_libdir_separator, $1)=\n_LT_TAGVAR(hardcode_minus_L, $1)=no\n_LT_TAGVAR(hardcode_shlibpath_var, $1)=unsupported\n_LT_TAGVAR(hardcode_automatic, $1)=no\n_LT_TAGVAR(inherit_rpath, $1)=no\n_LT_TAGVAR(module_cmds, $1)=\n_LT_TAGVAR(module_expsym_cmds, $1)=\n_LT_TAGVAR(link_all_deplibs, $1)=unknown\n_LT_TAGVAR(old_archive_cmds, $1)=$old_archive_cmds\n_LT_TAGVAR(reload_flag, $1)=$reload_flag\n_LT_TAGVAR(reload_cmds, $1)=$reload_cmds\n_LT_TAGVAR(no_undefined_flag, $1)=\n_LT_TAGVAR(whole_archive_flag_spec, $1)=\n_LT_TAGVAR(enable_shared_with_static_runtimes, $1)=no\n\n# Source file extension for C++ test sources.\nac_ext=cpp\n\n# Object file extension for compiled C++ test sources.\nobjext=o\n_LT_TAGVAR(objext, $1)=$objext\n\n# No sense in running all these tests if we already determined that\n# the CXX compiler isn't working.  Some variables (like enable_shared)\n# are currently assumed to apply to all compilers on this platform,\n# and will be corrupted by setting them based on a non-working compiler.\nif test yes != \"$_lt_caught_CXX_error\"; then\n  # Code to be used in simple compile tests\n  lt_simple_compile_test_code=\"int some_variable = 0;\"\n\n  # Code to be used in simple link tests\n  lt_simple_link_test_code='int main(int, char *[[]]) { return(0); }'\n\n  # ltmain only uses $CC for tagged configurations so make sure $CC is set.\n  _LT_TAG_COMPILER\n\n  # save warnings/boilerplate of simple test code\n  _LT_COMPILER_BOILERPLATE\n  _LT_LINKER_BOILERPLATE\n\n  # Allow CC to be a program name with arguments.\n  lt_save_CC=$CC\n  lt_save_CFLAGS=$CFLAGS\n  lt_save_LD=$LD\n  lt_save_GCC=$GCC\n  GCC=$GXX\n  lt_save_with_gnu_ld=$with_gnu_ld\n  lt_save_path_LD=$lt_cv_path_LD\n  if test -n \"${lt_cv_prog_gnu_ldcxx+set}\"; then\n    lt_cv_prog_gnu_ld=$lt_cv_prog_gnu_ldcxx\n  else\n    $as_unset lt_cv_prog_gnu_ld\n  fi\n  if test -n \"${lt_cv_path_LDCXX+set}\"; then\n    lt_cv_path_LD=$lt_cv_path_LDCXX\n  else\n    $as_unset lt_cv_path_LD\n  fi\n  test -z \"${LDCXX+set}\" || LD=$LDCXX\n  CC=${CXX-\"c++\"}\n  CFLAGS=$CXXFLAGS\n  compiler=$CC\n  _LT_TAGVAR(compiler, $1)=$CC\n  _LT_CC_BASENAME([$compiler])\n\n  if test -n \"$compiler\"; then\n    # We don't want -fno-exception when compiling C++ code, so set the\n    # no_builtin_flag separately\n    if test yes = \"$GXX\"; then\n      _LT_TAGVAR(lt_prog_compiler_no_builtin_flag, $1)=' -fno-builtin'\n    else\n      _LT_TAGVAR(lt_prog_compiler_no_builtin_flag, $1)=\n    fi\n\n    if test yes = \"$GXX\"; then\n      # Set up default GNU C++ configuration\n\n      LT_PATH_LD\n\n      # Check if GNU C++ uses GNU ld as the underlying linker, since the\n      # archiving commands below assume that GNU ld is being used.\n      if test yes = \"$with_gnu_ld\"; then\n        _LT_TAGVAR(archive_cmds, $1)='$CC $pic_flag -shared -nostdlib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname -o $lib'\n        _LT_TAGVAR(archive_expsym_cmds, $1)='$CC $pic_flag -shared -nostdlib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname $wl-retain-symbols-file $wl$export_symbols -o $lib'\n\n        _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n        _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl--export-dynamic'\n\n        # If archive_cmds runs LD, not CC, wlarc should be empty\n        # XXX I think wlarc can be eliminated in ltcf-cxx, but I need to\n        #     investigate it a little bit more. (MM)\n        wlarc='$wl'\n\n        # ancient GNU ld didn't support --whole-archive et. al.\n        if eval \"`$CC -print-prog-name=ld` --help 2>&1\" |\n\t  $GREP 'no-whole-archive' > /dev/null; then\n          _LT_TAGVAR(whole_archive_flag_spec, $1)=$wlarc'--whole-archive$convenience '$wlarc'--no-whole-archive'\n        else\n          _LT_TAGVAR(whole_archive_flag_spec, $1)=\n        fi\n      else\n        with_gnu_ld=no\n        wlarc=\n\n        # A generic and very simple default shared library creation\n        # command for GNU C++ for the case where it uses the native\n        # linker, instead of GNU ld.  If possible, this setting should\n        # overridden to take advantage of the native linker features on\n        # the platform it is being used on.\n        _LT_TAGVAR(archive_cmds, $1)='$CC -shared -nostdlib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags -o $lib'\n      fi\n\n      # Commands to make compiler produce verbose output that lists\n      # what \"hidden\" libraries, object files and flags are used when\n      # linking a shared library.\n      output_verbose_link_cmd='$CC -shared $CFLAGS -v conftest.$objext 2>&1 | $GREP -v \"^Configured with:\" | $GREP \"\\-L\"'\n\n    else\n      GXX=no\n      with_gnu_ld=no\n      wlarc=\n    fi\n\n    # PORTME: fill in a description of your system's C++ link characteristics\n    AC_MSG_CHECKING([whether the $compiler linker ($LD) supports shared libraries])\n    _LT_TAGVAR(ld_shlibs, $1)=yes\n    case $host_os in\n      aix3*)\n        # FIXME: insert proper C++ library support\n        _LT_TAGVAR(ld_shlibs, $1)=no\n        ;;\n      aix[[4-9]]*)\n        if test ia64 = \"$host_cpu\"; then\n          # On IA64, the linker does run time linking by default, so we don't\n          # have to do anything special.\n          aix_use_runtimelinking=no\n          exp_sym_flag='-Bexport'\n          no_entry_flag=\n        else\n          aix_use_runtimelinking=no\n\n          # Test if we are trying to use run time linking or normal\n          # AIX style linking. If -brtl is somewhere in LDFLAGS, we\n          # have runtime linking enabled, and use it for executables.\n          # For shared libraries, we enable/disable runtime linking\n          # depending on the kind of the shared library created -\n          # when \"with_aix_soname,aix_use_runtimelinking\" is:\n          # \"aix,no\"   lib.a(lib.so.V) shared, rtl:no,  for executables\n          # \"aix,yes\"  lib.so          shared, rtl:yes, for executables\n          #            lib.a           static archive\n          # \"both,no\"  lib.so.V(shr.o) shared, rtl:yes\n          #            lib.a(lib.so.V) shared, rtl:no,  for executables\n          # \"both,yes\" lib.so.V(shr.o) shared, rtl:yes, for executables\n          #            lib.a(lib.so.V) shared, rtl:no\n          # \"svr4,*\"   lib.so.V(shr.o) shared, rtl:yes, for executables\n          #            lib.a           static archive\n          case $host_os in aix4.[[23]]|aix4.[[23]].*|aix[[5-9]]*)\n\t    for ld_flag in $LDFLAGS; do\n\t      case $ld_flag in\n\t      *-brtl*)\n\t        aix_use_runtimelinking=yes\n\t        break\n\t        ;;\n\t      esac\n\t    done\n\t    if test svr4,no = \"$with_aix_soname,$aix_use_runtimelinking\"; then\n\t      # With aix-soname=svr4, we create the lib.so.V shared archives only,\n\t      # so we don't have lib.a shared libs to link our executables.\n\t      # We have to force runtime linking in this case.\n\t      aix_use_runtimelinking=yes\n\t      LDFLAGS=\"$LDFLAGS -Wl,-brtl\"\n\t    fi\n\t    ;;\n          esac\n\n          exp_sym_flag='-bexport'\n          no_entry_flag='-bnoentry'\n        fi\n\n        # When large executables or shared objects are built, AIX ld can\n        # have problems creating the table of contents.  If linking a library\n        # or program results in \"error TOC overflow\" add -mminimal-toc to\n        # CXXFLAGS/CFLAGS for g++/gcc.  In the cases where that is not\n        # enough to fix the problem, add -Wl,-bbigtoc to LDFLAGS.\n\n        _LT_TAGVAR(archive_cmds, $1)=''\n        _LT_TAGVAR(hardcode_direct, $1)=yes\n        _LT_TAGVAR(hardcode_direct_absolute, $1)=yes\n        _LT_TAGVAR(hardcode_libdir_separator, $1)=':'\n        _LT_TAGVAR(link_all_deplibs, $1)=yes\n        _LT_TAGVAR(file_list_spec, $1)='$wl-f,'\n        case $with_aix_soname,$aix_use_runtimelinking in\n        aix,*) ;;\t# no import file\n        svr4,* | *,yes) # use import file\n          # The Import File defines what to hardcode.\n          _LT_TAGVAR(hardcode_direct, $1)=no\n          _LT_TAGVAR(hardcode_direct_absolute, $1)=no\n          ;;\n        esac\n\n        if test yes = \"$GXX\"; then\n          case $host_os in aix4.[[012]]|aix4.[[012]].*)\n          # We only want to do this on AIX 4.2 and lower, the check\n          # below for broken collect2 doesn't work under 4.3+\n\t  collect2name=`$CC -print-prog-name=collect2`\n\t  if test -f \"$collect2name\" &&\n\t     strings \"$collect2name\" | $GREP resolve_lib_name >/dev/null\n\t  then\n\t    # We have reworked collect2\n\t    :\n\t  else\n\t    # We have old collect2\n\t    _LT_TAGVAR(hardcode_direct, $1)=unsupported\n\t    # It fails to find uninstalled libraries when the uninstalled\n\t    # path is not listed in the libpath.  Setting hardcode_minus_L\n\t    # to unsupported forces relinking\n\t    _LT_TAGVAR(hardcode_minus_L, $1)=yes\n\t    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n\t    _LT_TAGVAR(hardcode_libdir_separator, $1)=\n\t  fi\n          esac\n          shared_flag='-shared'\n\t  if test yes = \"$aix_use_runtimelinking\"; then\n\t    shared_flag=$shared_flag' $wl-G'\n\t  fi\n\t  # Need to ensure runtime linking is disabled for the traditional\n\t  # shared library, or the linker may eventually find shared libraries\n\t  # /with/ Import File - we do not want to mix them.\n\t  shared_flag_aix='-shared'\n\t  shared_flag_svr4='-shared $wl-G'\n        else\n          # not using gcc\n          if test ia64 = \"$host_cpu\"; then\n\t  # VisualAge C++, Version 5.5 for AIX 5L for IA-64, Beta 3 Release\n\t  # chokes on -Wl,-G. The following line is correct:\n\t  shared_flag='-G'\n          else\n\t    if test yes = \"$aix_use_runtimelinking\"; then\n\t      shared_flag='$wl-G'\n\t    else\n\t      shared_flag='$wl-bM:SRE'\n\t    fi\n\t    shared_flag_aix='$wl-bM:SRE'\n\t    shared_flag_svr4='$wl-G'\n          fi\n        fi\n\n        _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-bexpall'\n        # It seems that -bexpall does not export symbols beginning with\n        # underscore (_), so it is better to generate a list of symbols to\n\t# export.\n        _LT_TAGVAR(always_export_symbols, $1)=yes\n\tif test aix,yes = \"$with_aix_soname,$aix_use_runtimelinking\"; then\n          # Warning - without using the other runtime loading flags (-brtl),\n          # -berok will link without error, but may produce a broken library.\n          # The \"-G\" linker flag allows undefined symbols.\n          _LT_TAGVAR(no_undefined_flag, $1)='-bernotok'\n          # Determine the default libpath from the value encoded in an empty\n          # executable.\n          _LT_SYS_MODULE_PATH_AIX([$1])\n          _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-blibpath:$libdir:'\"$aix_libpath\"\n\n          _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -o $output_objdir/$soname $libobjs $deplibs $wl'$no_entry_flag' $compiler_flags `if test -n \"$allow_undefined_flag\"; then func_echo_all \"$wl$allow_undefined_flag\"; else :; fi` $wl'$exp_sym_flag:\\$export_symbols' '$shared_flag\n        else\n          if test ia64 = \"$host_cpu\"; then\n\t    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-R $libdir:/usr/lib:/lib'\n\t    _LT_TAGVAR(allow_undefined_flag, $1)=\"-z nodefs\"\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)=\"\\$CC $shared_flag\"' -o $output_objdir/$soname $libobjs $deplibs '\"\\$wl$no_entry_flag\"' $compiler_flags $wl$allow_undefined_flag '\"\\$wl$exp_sym_flag:\\$export_symbols\"\n          else\n\t    # Determine the default libpath from the value encoded in an\n\t    # empty executable.\n\t    _LT_SYS_MODULE_PATH_AIX([$1])\n\t    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-blibpath:$libdir:'\"$aix_libpath\"\n\t    # Warning - without using the other run time loading flags,\n\t    # -berok will link without error, but may produce a broken library.\n\t    _LT_TAGVAR(no_undefined_flag, $1)=' $wl-bernotok'\n\t    _LT_TAGVAR(allow_undefined_flag, $1)=' $wl-berok'\n\t    if test yes = \"$with_gnu_ld\"; then\n\t      # We only use this code for GNU lds that support --whole-archive.\n\t      _LT_TAGVAR(whole_archive_flag_spec, $1)='$wl--whole-archive$convenience $wl--no-whole-archive'\n\t    else\n\t      # Exported symbols can be pulled into shared objects from archives\n\t      _LT_TAGVAR(whole_archive_flag_spec, $1)='$convenience'\n\t    fi\n\t    _LT_TAGVAR(archive_cmds_need_lc, $1)=yes\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)='$RM -r $output_objdir/$realname.d~$MKDIR $output_objdir/$realname.d'\n\t    # -brtl affects multiple linker settings, -berok does not and is overridden later\n\t    compiler_flags_filtered='`func_echo_all \"$compiler_flags \" | $SED -e \"s%-brtl\\\\([[, ]]\\\\)%-berok\\\\1%g\"`'\n\t    if test svr4 != \"$with_aix_soname\"; then\n\t      # This is similar to how AIX traditionally builds its shared\n\t      # libraries. Need -bnortl late, we may have -brtl in LDFLAGS.\n\t      _LT_TAGVAR(archive_expsym_cmds, $1)=\"$_LT_TAGVAR(archive_expsym_cmds, $1)\"'~$CC '$shared_flag_aix' -o $output_objdir/$realname.d/$soname $libobjs $deplibs $wl-bnoentry '$compiler_flags_filtered'$wl-bE:$export_symbols$allow_undefined_flag~$AR $AR_FLAGS $output_objdir/$libname$release.a $output_objdir/$realname.d/$soname'\n\t    fi\n\t    if test aix != \"$with_aix_soname\"; then\n\t      _LT_TAGVAR(archive_expsym_cmds, $1)=\"$_LT_TAGVAR(archive_expsym_cmds, $1)\"'~$CC '$shared_flag_svr4' -o $output_objdir/$realname.d/$shared_archive_member_spec.o $libobjs $deplibs $wl-bnoentry '$compiler_flags_filtered'$wl-bE:$export_symbols$allow_undefined_flag~$STRIP -e $output_objdir/$realname.d/$shared_archive_member_spec.o~( func_echo_all \"#! $soname($shared_archive_member_spec.o)\"; if test shr_64 = \"$shared_archive_member_spec\"; then func_echo_all \"# 64\"; else func_echo_all \"# 32\"; fi; cat $export_symbols ) > $output_objdir/$realname.d/$shared_archive_member_spec.imp~$AR $AR_FLAGS $output_objdir/$soname $output_objdir/$realname.d/$shared_archive_member_spec.o $output_objdir/$realname.d/$shared_archive_member_spec.imp'\n\t    else\n\t      # used by -dlpreopen to get the symbols\n\t      _LT_TAGVAR(archive_expsym_cmds, $1)=\"$_LT_TAGVAR(archive_expsym_cmds, $1)\"'~$MV  $output_objdir/$realname.d/$soname $output_objdir'\n\t    fi\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)=\"$_LT_TAGVAR(archive_expsym_cmds, $1)\"'~$RM -r $output_objdir/$realname.d'\n          fi\n        fi\n        ;;\n\n      beos*)\n\tif $LD --help 2>&1 | $GREP ': supported targets:.* elf' > /dev/null; then\n\t  _LT_TAGVAR(allow_undefined_flag, $1)=unsupported\n\t  # Joseph Beckenbach <jrb3@best.com> says some releases of gcc\n\t  # support --undefined.  This deserves some investigation.  FIXME\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -nostart $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n\telse\n\t  _LT_TAGVAR(ld_shlibs, $1)=no\n\tfi\n\t;;\n\n      chorus*)\n        case $cc_basename in\n          *)\n\t  # FIXME: insert proper C++ library support\n\t  _LT_TAGVAR(ld_shlibs, $1)=no\n\t  ;;\n        esac\n        ;;\n\n      cygwin* | mingw* | pw32* | cegcc*)\n\tcase $GXX,$cc_basename in\n\t,cl* | no,cl*)\n\t  # Native MSVC\n\t  # hardcode_libdir_flag_spec is actually meaningless, as there is\n\t  # no search path for DLLs.\n\t  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)=' '\n\t  _LT_TAGVAR(allow_undefined_flag, $1)=unsupported\n\t  _LT_TAGVAR(always_export_symbols, $1)=yes\n\t  _LT_TAGVAR(file_list_spec, $1)='@'\n\t  # Tell ltmain to make .lib files, not .a files.\n\t  libext=lib\n\t  # Tell ltmain to make .dll files, not .so files.\n\t  shrext_cmds=.dll\n\t  # FIXME: Setting linknames here is a bad hack.\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -o $output_objdir/$soname $libobjs $compiler_flags $deplibs -Wl,-DLL,-IMPLIB:\"$tool_output_objdir$libname.dll.lib\"~linknames='\n\t  _LT_TAGVAR(archive_expsym_cmds, $1)='if _LT_DLL_DEF_P([$export_symbols]); then\n              cp \"$export_symbols\" \"$output_objdir/$soname.def\";\n              echo \"$tool_output_objdir$soname.def\" > \"$output_objdir/$soname.exp\";\n            else\n              $SED -e '\\''s/^/-link -EXPORT:/'\\'' < $export_symbols > $output_objdir/$soname.exp;\n            fi~\n            $CC -o $tool_output_objdir$soname $libobjs $compiler_flags $deplibs \"@$tool_output_objdir$soname.exp\" -Wl,-DLL,-IMPLIB:\"$tool_output_objdir$libname.dll.lib\"~\n            linknames='\n\t  # The linker will not automatically build a static lib if we build a DLL.\n\t  # _LT_TAGVAR(old_archive_from_new_cmds, $1)='true'\n\t  _LT_TAGVAR(enable_shared_with_static_runtimes, $1)=yes\n\t  # Don't use ranlib\n\t  _LT_TAGVAR(old_postinstall_cmds, $1)='chmod 644 $oldlib'\n\t  _LT_TAGVAR(postlink_cmds, $1)='lt_outputfile=\"@OUTPUT@\"~\n            lt_tool_outputfile=\"@TOOL_OUTPUT@\"~\n            case $lt_outputfile in\n              *.exe|*.EXE) ;;\n              *)\n                lt_outputfile=$lt_outputfile.exe\n                lt_tool_outputfile=$lt_tool_outputfile.exe\n                ;;\n            esac~\n            func_to_tool_file \"$lt_outputfile\"~\n            if test : != \"$MANIFEST_TOOL\" && test -f \"$lt_outputfile.manifest\"; then\n              $MANIFEST_TOOL -manifest \"$lt_tool_outputfile.manifest\" -outputresource:\"$lt_tool_outputfile\" || exit 1;\n              $RM \"$lt_outputfile.manifest\";\n            fi'\n\t  ;;\n\t*)\n\t  # g++\n\t  # _LT_TAGVAR(hardcode_libdir_flag_spec, $1) is actually meaningless,\n\t  # as there is no search path for DLLs.\n\t  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n\t  _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl--export-all-symbols'\n\t  _LT_TAGVAR(allow_undefined_flag, $1)=unsupported\n\t  _LT_TAGVAR(always_export_symbols, $1)=no\n\t  _LT_TAGVAR(enable_shared_with_static_runtimes, $1)=yes\n\n\t  if $LD --help 2>&1 | $GREP 'auto-import' > /dev/null; then\n\t    _LT_TAGVAR(archive_cmds, $1)='$CC -shared -nostdlib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags -o $output_objdir/$soname $wl--enable-auto-image-base -Xlinker --out-implib -Xlinker $lib'\n\t    # If the export-symbols file already is a .def file, use it as\n\t    # is; otherwise, prepend EXPORTS...\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)='if _LT_DLL_DEF_P([$export_symbols]); then\n              cp $export_symbols $output_objdir/$soname.def;\n            else\n              echo EXPORTS > $output_objdir/$soname.def;\n              cat $export_symbols >> $output_objdir/$soname.def;\n            fi~\n            $CC -shared -nostdlib $output_objdir/$soname.def $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags -o $output_objdir/$soname $wl--enable-auto-image-base -Xlinker --out-implib -Xlinker $lib'\n\t  else\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t  fi\n\t  ;;\n\tesac\n\t;;\n      darwin* | rhapsody*)\n        _LT_DARWIN_LINKER_FEATURES($1)\n\t;;\n\n      os2*)\n\t_LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n\t_LT_TAGVAR(hardcode_minus_L, $1)=yes\n\t_LT_TAGVAR(allow_undefined_flag, $1)=unsupported\n\tshrext_cmds=.dll\n\t_LT_TAGVAR(archive_cmds, $1)='$ECHO \"LIBRARY ${soname%$shared_ext} INITINSTANCE TERMINSTANCE\" > $output_objdir/$libname.def~\n\t  $ECHO \"DESCRIPTION \\\"$libname\\\"\" >> $output_objdir/$libname.def~\n\t  $ECHO \"DATA MULTIPLE NONSHARED\" >> $output_objdir/$libname.def~\n\t  $ECHO EXPORTS >> $output_objdir/$libname.def~\n\t  emxexp $libobjs | $SED /\"_DLL_InitTerm\"/d >> $output_objdir/$libname.def~\n\t  $CC -Zdll -Zcrtdll -o $output_objdir/$soname $libobjs $deplibs $compiler_flags $output_objdir/$libname.def~\n\t  emximp -o $lib $output_objdir/$libname.def'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='$ECHO \"LIBRARY ${soname%$shared_ext} INITINSTANCE TERMINSTANCE\" > $output_objdir/$libname.def~\n\t  $ECHO \"DESCRIPTION \\\"$libname\\\"\" >> $output_objdir/$libname.def~\n\t  $ECHO \"DATA MULTIPLE NONSHARED\" >> $output_objdir/$libname.def~\n\t  $ECHO EXPORTS >> $output_objdir/$libname.def~\n\t  prefix_cmds=\"$SED\"~\n\t  if test EXPORTS = \"`$SED 1q $export_symbols`\"; then\n\t    prefix_cmds=\"$prefix_cmds -e 1d\";\n\t  fi~\n\t  prefix_cmds=\"$prefix_cmds -e \\\"s/^\\(.*\\)$/_\\1/g\\\"\"~\n\t  cat $export_symbols | $prefix_cmds >> $output_objdir/$libname.def~\n\t  $CC -Zdll -Zcrtdll -o $output_objdir/$soname $libobjs $deplibs $compiler_flags $output_objdir/$libname.def~\n\t  emximp -o $lib $output_objdir/$libname.def'\n\t_LT_TAGVAR(old_archive_From_new_cmds, $1)='emximp -o $output_objdir/${libname}_dll.a $output_objdir/$libname.def'\n\t_LT_TAGVAR(enable_shared_with_static_runtimes, $1)=yes\n\t;;\n\n      dgux*)\n        case $cc_basename in\n          ec++*)\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n          ghcx*)\n\t    # Green Hills C++ Compiler\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n          *)\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n        esac\n        ;;\n\n      freebsd2.*)\n        # C++ shared libraries reported to be fairly broken before\n\t# switch to ELF\n        _LT_TAGVAR(ld_shlibs, $1)=no\n        ;;\n\n      freebsd-elf*)\n        _LT_TAGVAR(archive_cmds_need_lc, $1)=no\n        ;;\n\n      freebsd* | dragonfly*)\n        # FreeBSD 3 and later use GNU C++ and GNU ld with standard ELF\n        # conventions\n        _LT_TAGVAR(ld_shlibs, $1)=yes\n        ;;\n\n      haiku*)\n        _LT_TAGVAR(archive_cmds, $1)='$CC -shared $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n        _LT_TAGVAR(link_all_deplibs, $1)=yes\n        ;;\n\n      hpux9*)\n        _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl+b $wl$libdir'\n        _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n        _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-E'\n        _LT_TAGVAR(hardcode_direct, $1)=yes\n        _LT_TAGVAR(hardcode_minus_L, $1)=yes # Not in the search PATH,\n\t\t\t\t             # but as the default\n\t\t\t\t             # location of the library.\n\n        case $cc_basename in\n          CC*)\n            # FIXME: insert proper C++ library support\n            _LT_TAGVAR(ld_shlibs, $1)=no\n            ;;\n          aCC*)\n            _LT_TAGVAR(archive_cmds, $1)='$RM $output_objdir/$soname~$CC -b $wl+b $wl$install_libdir -o $output_objdir/$soname $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags~test \"x$output_objdir/$soname\" = \"x$lib\" || mv $output_objdir/$soname $lib'\n            # Commands to make compiler produce verbose output that lists\n            # what \"hidden\" libraries, object files and flags are used when\n            # linking a shared library.\n            #\n            # There doesn't appear to be a way to prevent this compiler from\n            # explicitly linking system object files so we need to strip them\n            # from the output so that they don't get included in the library\n            # dependencies.\n            output_verbose_link_cmd='templist=`($CC -b $CFLAGS -v conftest.$objext 2>&1) | $EGREP \"\\-L\"`; list= ; for z in $templist; do case $z in conftest.$objext) list=\"$list $z\";; *.$objext);; *) list=\"$list $z\";;esac; done; func_echo_all \"$list\"'\n            ;;\n          *)\n            if test yes = \"$GXX\"; then\n              _LT_TAGVAR(archive_cmds, $1)='$RM $output_objdir/$soname~$CC -shared -nostdlib $pic_flag $wl+b $wl$install_libdir -o $output_objdir/$soname $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags~test \"x$output_objdir/$soname\" = \"x$lib\" || mv $output_objdir/$soname $lib'\n            else\n              # FIXME: insert proper C++ library support\n              _LT_TAGVAR(ld_shlibs, $1)=no\n            fi\n            ;;\n        esac\n        ;;\n\n      hpux10*|hpux11*)\n        if test no = \"$with_gnu_ld\"; then\n\t  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl+b $wl$libdir'\n\t  _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n\n          case $host_cpu in\n            hppa*64*|ia64*)\n              ;;\n            *)\n\t      _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-E'\n              ;;\n          esac\n        fi\n        case $host_cpu in\n          hppa*64*|ia64*)\n            _LT_TAGVAR(hardcode_direct, $1)=no\n            _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n            ;;\n          *)\n            _LT_TAGVAR(hardcode_direct, $1)=yes\n            _LT_TAGVAR(hardcode_direct_absolute, $1)=yes\n            _LT_TAGVAR(hardcode_minus_L, $1)=yes # Not in the search PATH,\n\t\t\t\t\t         # but as the default\n\t\t\t\t\t         # location of the library.\n            ;;\n        esac\n\n        case $cc_basename in\n          CC*)\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n          aCC*)\n\t    case $host_cpu in\n\t      hppa*64*)\n\t        _LT_TAGVAR(archive_cmds, $1)='$CC -b $wl+h $wl$soname -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags'\n\t        ;;\n\t      ia64*)\n\t        _LT_TAGVAR(archive_cmds, $1)='$CC -b $wl+h $wl$soname $wl+nodefaultrpath -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags'\n\t        ;;\n\t      *)\n\t        _LT_TAGVAR(archive_cmds, $1)='$CC -b $wl+h $wl$soname $wl+b $wl$install_libdir -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags'\n\t        ;;\n\t    esac\n\t    # Commands to make compiler produce verbose output that lists\n\t    # what \"hidden\" libraries, object files and flags are used when\n\t    # linking a shared library.\n\t    #\n\t    # There doesn't appear to be a way to prevent this compiler from\n\t    # explicitly linking system object files so we need to strip them\n\t    # from the output so that they don't get included in the library\n\t    # dependencies.\n\t    output_verbose_link_cmd='templist=`($CC -b $CFLAGS -v conftest.$objext 2>&1) | $GREP \"\\-L\"`; list= ; for z in $templist; do case $z in conftest.$objext) list=\"$list $z\";; *.$objext);; *) list=\"$list $z\";;esac; done; func_echo_all \"$list\"'\n\t    ;;\n          *)\n\t    if test yes = \"$GXX\"; then\n\t      if test no = \"$with_gnu_ld\"; then\n\t        case $host_cpu in\n\t          hppa*64*)\n\t            _LT_TAGVAR(archive_cmds, $1)='$CC -shared -nostdlib -fPIC $wl+h $wl$soname -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags'\n\t            ;;\n\t          ia64*)\n\t            _LT_TAGVAR(archive_cmds, $1)='$CC -shared -nostdlib $pic_flag $wl+h $wl$soname $wl+nodefaultrpath -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags'\n\t            ;;\n\t          *)\n\t            _LT_TAGVAR(archive_cmds, $1)='$CC -shared -nostdlib $pic_flag $wl+h $wl$soname $wl+b $wl$install_libdir -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags'\n\t            ;;\n\t        esac\n\t      fi\n\t    else\n\t      # FIXME: insert proper C++ library support\n\t      _LT_TAGVAR(ld_shlibs, $1)=no\n\t    fi\n\t    ;;\n        esac\n        ;;\n\n      interix[[3-9]]*)\n\t_LT_TAGVAR(hardcode_direct, $1)=no\n\t_LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n\t_LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath,$libdir'\n\t_LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-E'\n\t# Hack: On Interix 3.x, we cannot compile PIC because of a broken gcc.\n\t# Instead, shared libraries are loaded at an image base (0x10000000 by\n\t# default) and relocated if they conflict, which is a slow very memory\n\t# consuming and fragmenting process.  To avoid this, we pick a random,\n\t# 256 KiB-aligned image base between 0x50000000 and 0x6FFC0000 at link\n\t# time.  Moving up from 0x10000000 also allows more sbrk(2) space.\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-h,$soname $wl--image-base,`expr ${RANDOM-$$} % 4096 / 2 \\* 262144 + 1342177280` -o $lib'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='sed \"s|^|_|\" $export_symbols >$output_objdir/$soname.expsym~$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-h,$soname $wl--retain-symbols-file,$output_objdir/$soname.expsym $wl--image-base,`expr ${RANDOM-$$} % 4096 / 2 \\* 262144 + 1342177280` -o $lib'\n\t;;\n      irix5* | irix6*)\n        case $cc_basename in\n          CC*)\n\t    # SGI C++\n\t    _LT_TAGVAR(archive_cmds, $1)='$CC -shared -all -multigot $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags -soname $soname `test -n \"$verstring\" && func_echo_all \"-set_version $verstring\"` -update_registry $output_objdir/so_locations -o $lib'\n\n\t    # Archives containing C++ object files must be created using\n\t    # \"CC -ar\", where \"CC\" is the IRIX C++ compiler.  This is\n\t    # necessary to make sure instantiated templates are included\n\t    # in the archive.\n\t    _LT_TAGVAR(old_archive_cmds, $1)='$CC -ar -WR,-u -o $oldlib $oldobjs'\n\t    ;;\n          *)\n\t    if test yes = \"$GXX\"; then\n\t      if test no = \"$with_gnu_ld\"; then\n\t        _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag -nostdlib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname `test -n \"$verstring\" && func_echo_all \"$wl-set_version $wl$verstring\"` $wl-update_registry $wl$output_objdir/so_locations -o $lib'\n\t      else\n\t        _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag -nostdlib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname `test -n \"$verstring\" && func_echo_all \"$wl-set_version $wl$verstring\"` -o $lib'\n\t      fi\n\t    fi\n\t    _LT_TAGVAR(link_all_deplibs, $1)=yes\n\t    ;;\n        esac\n        _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n        _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n        _LT_TAGVAR(inherit_rpath, $1)=yes\n        ;;\n\n      linux* | k*bsd*-gnu | kopensolaris*-gnu | gnu*)\n        case $cc_basename in\n          KCC*)\n\t    # Kuck and Associates, Inc. (KAI) C++ Compiler\n\n\t    # KCC will only create a shared library if the output file\n\t    # ends with \".so\" (or \".sl\" for HP-UX), so rename the library\n\t    # to its proper name (with version) after linking.\n\t    _LT_TAGVAR(archive_cmds, $1)='tempext=`echo $shared_ext | $SED -e '\\''s/\\([[^()0-9A-Za-z{}]]\\)/\\\\\\\\\\1/g'\\''`; templib=`echo $lib | $SED -e \"s/\\$tempext\\..*/.so/\"`; $CC $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags --soname $soname -o \\$templib; mv \\$templib $lib'\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)='tempext=`echo $shared_ext | $SED -e '\\''s/\\([[^()0-9A-Za-z{}]]\\)/\\\\\\\\\\1/g'\\''`; templib=`echo $lib | $SED -e \"s/\\$tempext\\..*/.so/\"`; $CC $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags --soname $soname -o \\$templib $wl-retain-symbols-file,$export_symbols; mv \\$templib $lib'\n\t    # Commands to make compiler produce verbose output that lists\n\t    # what \"hidden\" libraries, object files and flags are used when\n\t    # linking a shared library.\n\t    #\n\t    # There doesn't appear to be a way to prevent this compiler from\n\t    # explicitly linking system object files so we need to strip them\n\t    # from the output so that they don't get included in the library\n\t    # dependencies.\n\t    output_verbose_link_cmd='templist=`$CC $CFLAGS -v conftest.$objext -o libconftest$shared_ext 2>&1 | $GREP \"ld\"`; rm -f libconftest$shared_ext; list= ; for z in $templist; do case $z in conftest.$objext) list=\"$list $z\";; *.$objext);; *) list=\"$list $z\";;esac; done; func_echo_all \"$list\"'\n\n\t    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath,$libdir'\n\t    _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl--export-dynamic'\n\n\t    # Archives containing C++ object files must be created using\n\t    # \"CC -Bstatic\", where \"CC\" is the KAI C++ compiler.\n\t    _LT_TAGVAR(old_archive_cmds, $1)='$CC -Bstatic -o $oldlib $oldobjs'\n\t    ;;\n\t  icpc* | ecpc* )\n\t    # Intel C++\n\t    with_gnu_ld=yes\n\t    # version 8.0 and above of icpc choke on multiply defined symbols\n\t    # if we add $predep_objects and $postdep_objects, however 7.1 and\n\t    # earlier do not add the objects themselves.\n\t    case `$CC -V 2>&1` in\n\t      *\"Version 7.\"*)\n\t        _LT_TAGVAR(archive_cmds, $1)='$CC -shared $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname -o $lib'\n\t\t_LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname $wl-retain-symbols-file $wl$export_symbols -o $lib'\n\t\t;;\n\t      *)  # Version 8.0 or newer\n\t        tmp_idyn=\n\t        case $host_cpu in\n\t\t  ia64*) tmp_idyn=' -i_dynamic';;\n\t\tesac\n\t        _LT_TAGVAR(archive_cmds, $1)='$CC -shared'\"$tmp_idyn\"' $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n\t\t_LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared'\"$tmp_idyn\"' $libobjs $deplibs $compiler_flags $wl-soname $wl$soname $wl-retain-symbols-file $wl$export_symbols -o $lib'\n\t\t;;\n\t    esac\n\t    _LT_TAGVAR(archive_cmds_need_lc, $1)=no\n\t    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath,$libdir'\n\t    _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl--export-dynamic'\n\t    _LT_TAGVAR(whole_archive_flag_spec, $1)='$wl--whole-archive$convenience $wl--no-whole-archive'\n\t    ;;\n          pgCC* | pgcpp*)\n            # Portland Group C++ compiler\n\t    case `$CC -V` in\n\t    *pgCC\\ [[1-5]].* | *pgcpp\\ [[1-5]].*)\n\t      _LT_TAGVAR(prelink_cmds, $1)='tpldir=Template.dir~\n               rm -rf $tpldir~\n               $CC --prelink_objects --instantiation_dir $tpldir $objs $libobjs $compile_deplibs~\n               compile_command=\"$compile_command `find $tpldir -name \\*.o | sort | $NL2SP`\"'\n\t      _LT_TAGVAR(old_archive_cmds, $1)='tpldir=Template.dir~\n                rm -rf $tpldir~\n                $CC --prelink_objects --instantiation_dir $tpldir $oldobjs$old_deplibs~\n                $AR $AR_FLAGS $oldlib$oldobjs$old_deplibs `find $tpldir -name \\*.o | sort | $NL2SP`~\n                $RANLIB $oldlib'\n\t      _LT_TAGVAR(archive_cmds, $1)='tpldir=Template.dir~\n                rm -rf $tpldir~\n                $CC --prelink_objects --instantiation_dir $tpldir $predep_objects $libobjs $deplibs $convenience $postdep_objects~\n                $CC -shared $pic_flag $predep_objects $libobjs $deplibs `find $tpldir -name \\*.o | sort | $NL2SP` $postdep_objects $compiler_flags $wl-soname $wl$soname -o $lib'\n\t      _LT_TAGVAR(archive_expsym_cmds, $1)='tpldir=Template.dir~\n                rm -rf $tpldir~\n                $CC --prelink_objects --instantiation_dir $tpldir $predep_objects $libobjs $deplibs $convenience $postdep_objects~\n                $CC -shared $pic_flag $predep_objects $libobjs $deplibs `find $tpldir -name \\*.o | sort | $NL2SP` $postdep_objects $compiler_flags $wl-soname $wl$soname $wl-retain-symbols-file $wl$export_symbols -o $lib'\n\t      ;;\n\t    *) # Version 6 and above use weak symbols\n\t      _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname -o $lib'\n\t      _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $pic_flag $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname $wl-retain-symbols-file $wl$export_symbols -o $lib'\n\t      ;;\n\t    esac\n\n\t    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl--rpath $wl$libdir'\n\t    _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl--export-dynamic'\n\t    _LT_TAGVAR(whole_archive_flag_spec, $1)='$wl--whole-archive`for conv in $convenience\\\"\\\"; do test  -n \\\"$conv\\\" && new_convenience=\\\"$new_convenience,$conv\\\"; done; func_echo_all \\\"$new_convenience\\\"` $wl--no-whole-archive'\n            ;;\n\t  cxx*)\n\t    # Compaq C++\n\t    _LT_TAGVAR(archive_cmds, $1)='$CC -shared $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname -o $lib'\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname  -o $lib $wl-retain-symbols-file $wl$export_symbols'\n\n\t    runpath_var=LD_RUN_PATH\n\t    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-rpath $libdir'\n\t    _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n\n\t    # Commands to make compiler produce verbose output that lists\n\t    # what \"hidden\" libraries, object files and flags are used when\n\t    # linking a shared library.\n\t    #\n\t    # There doesn't appear to be a way to prevent this compiler from\n\t    # explicitly linking system object files so we need to strip them\n\t    # from the output so that they don't get included in the library\n\t    # dependencies.\n\t    output_verbose_link_cmd='templist=`$CC -shared $CFLAGS -v conftest.$objext 2>&1 | $GREP \"ld\"`; templist=`func_echo_all \"$templist\" | $SED \"s/\\(^.*ld.*\\)\\( .*ld .*$\\)/\\1/\"`; list= ; for z in $templist; do case $z in conftest.$objext) list=\"$list $z\";; *.$objext);; *) list=\"$list $z\";;esac; done; func_echo_all \"X$list\" | $Xsed'\n\t    ;;\n\t  xl* | mpixl* | bgxl*)\n\t    # IBM XL 8.0 on PPC, with GNU ld\n\t    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n\t    _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl--export-dynamic'\n\t    _LT_TAGVAR(archive_cmds, $1)='$CC -qmkshrobj $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n\t    if test yes = \"$supports_anon_versioning\"; then\n\t      _LT_TAGVAR(archive_expsym_cmds, $1)='echo \"{ global:\" > $output_objdir/$libname.ver~\n                cat $export_symbols | sed -e \"s/\\(.*\\)/\\1;/\" >> $output_objdir/$libname.ver~\n                echo \"local: *; };\" >> $output_objdir/$libname.ver~\n                $CC -qmkshrobj $libobjs $deplibs $compiler_flags $wl-soname $wl$soname $wl-version-script $wl$output_objdir/$libname.ver -o $lib'\n\t    fi\n\t    ;;\n\t  *)\n\t    case `$CC -V 2>&1 | sed 5q` in\n\t    *Sun\\ C*)\n\t      # Sun C++ 5.9\n\t      _LT_TAGVAR(no_undefined_flag, $1)=' -zdefs'\n\t      _LT_TAGVAR(archive_cmds, $1)='$CC -G$allow_undefined_flag -h$soname -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags'\n\t      _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -G$allow_undefined_flag -h$soname -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-retain-symbols-file $wl$export_symbols'\n\t      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-R$libdir'\n\t      _LT_TAGVAR(whole_archive_flag_spec, $1)='$wl--whole-archive`new_convenience=; for conv in $convenience\\\"\\\"; do test -z \\\"$conv\\\" || new_convenience=\\\"$new_convenience,$conv\\\"; done; func_echo_all \\\"$new_convenience\\\"` $wl--no-whole-archive'\n\t      _LT_TAGVAR(compiler_needs_object, $1)=yes\n\n\t      # Not sure whether something based on\n\t      # $CC $CFLAGS -v conftest.$objext -o libconftest$shared_ext 2>&1\n\t      # would be better.\n\t      output_verbose_link_cmd='func_echo_all'\n\n\t      # Archives containing C++ object files must be created using\n\t      # \"CC -xar\", where \"CC\" is the Sun C++ compiler.  This is\n\t      # necessary to make sure instantiated templates are included\n\t      # in the archive.\n\t      _LT_TAGVAR(old_archive_cmds, $1)='$CC -xar -o $oldlib $oldobjs'\n\t      ;;\n\t    esac\n\t    ;;\n\tesac\n\t;;\n\n      lynxos*)\n        # FIXME: insert proper C++ library support\n\t_LT_TAGVAR(ld_shlibs, $1)=no\n\t;;\n\n      m88k*)\n        # FIXME: insert proper C++ library support\n        _LT_TAGVAR(ld_shlibs, $1)=no\n\t;;\n\n      mvs*)\n        case $cc_basename in\n          cxx*)\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n\t  *)\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n\tesac\n\t;;\n\n      netbsd*)\n        if echo __ELF__ | $CC -E - | $GREP __ELF__ >/dev/null; then\n\t  _LT_TAGVAR(archive_cmds, $1)='$LD -Bshareable  -o $lib $predep_objects $libobjs $deplibs $postdep_objects $linker_flags'\n\t  wlarc=\n\t  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-R$libdir'\n\t  _LT_TAGVAR(hardcode_direct, $1)=yes\n\t  _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n\tfi\n\t# Workaround some broken pre-1.5 toolchains\n\toutput_verbose_link_cmd='$CC -shared $CFLAGS -v conftest.$objext 2>&1 | $GREP conftest.$objext | $SED -e \"s:-lgcc -lc -lgcc::\"'\n\t;;\n\n      *nto* | *qnx*)\n        _LT_TAGVAR(ld_shlibs, $1)=yes\n\t;;\n\n      openbsd* | bitrig*)\n\tif test -f /usr/libexec/ld.so; then\n\t  _LT_TAGVAR(hardcode_direct, $1)=yes\n\t  _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n\t  _LT_TAGVAR(hardcode_direct_absolute, $1)=yes\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags -o $lib'\n\t  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath,$libdir'\n\t  if test -z \"`echo __ELF__ | $CC -E - | grep __ELF__`\"; then\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $pic_flag $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-retain-symbols-file,$export_symbols -o $lib'\n\t    _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-E'\n\t    _LT_TAGVAR(whole_archive_flag_spec, $1)=$wlarc'--whole-archive$convenience '$wlarc'--no-whole-archive'\n\t  fi\n\t  output_verbose_link_cmd=func_echo_all\n\telse\n\t  _LT_TAGVAR(ld_shlibs, $1)=no\n\tfi\n\t;;\n\n      osf3* | osf4* | osf5*)\n        case $cc_basename in\n          KCC*)\n\t    # Kuck and Associates, Inc. (KAI) C++ Compiler\n\n\t    # KCC will only create a shared library if the output file\n\t    # ends with \".so\" (or \".sl\" for HP-UX), so rename the library\n\t    # to its proper name (with version) after linking.\n\t    _LT_TAGVAR(archive_cmds, $1)='tempext=`echo $shared_ext | $SED -e '\\''s/\\([[^()0-9A-Za-z{}]]\\)/\\\\\\\\\\1/g'\\''`; templib=`echo \"$lib\" | $SED -e \"s/\\$tempext\\..*/.so/\"`; $CC $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags --soname $soname -o \\$templib; mv \\$templib $lib'\n\n\t    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath,$libdir'\n\t    _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n\n\t    # Archives containing C++ object files must be created using\n\t    # the KAI C++ compiler.\n\t    case $host in\n\t      osf3*) _LT_TAGVAR(old_archive_cmds, $1)='$CC -Bstatic -o $oldlib $oldobjs' ;;\n\t      *) _LT_TAGVAR(old_archive_cmds, $1)='$CC -o $oldlib $oldobjs' ;;\n\t    esac\n\t    ;;\n          RCC*)\n\t    # Rational C++ 2.4.1\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n          cxx*)\n\t    case $host in\n\t      osf3*)\n\t        _LT_TAGVAR(allow_undefined_flag, $1)=' $wl-expect_unresolved $wl\\*'\n\t        _LT_TAGVAR(archive_cmds, $1)='$CC -shared$allow_undefined_flag $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $soname `test -n \"$verstring\" && func_echo_all \"$wl-set_version $verstring\"` -update_registry $output_objdir/so_locations -o $lib'\n\t        _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n\t\t;;\n\t      *)\n\t        _LT_TAGVAR(allow_undefined_flag, $1)=' -expect_unresolved \\*'\n\t        _LT_TAGVAR(archive_cmds, $1)='$CC -shared$allow_undefined_flag $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags -msym -soname $soname `test -n \"$verstring\" && func_echo_all \"-set_version $verstring\"` -update_registry $output_objdir/so_locations -o $lib'\n\t        _LT_TAGVAR(archive_expsym_cmds, $1)='for i in `cat $export_symbols`; do printf \"%s %s\\\\n\" -exported_symbol \"\\$i\" >> $lib.exp; done~\n                  echo \"-hidden\">> $lib.exp~\n                  $CC -shared$allow_undefined_flag $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags -msym -soname $soname $wl-input $wl$lib.exp  `test -n \"$verstring\" && $ECHO \"-set_version $verstring\"` -update_registry $output_objdir/so_locations -o $lib~\n                  $RM $lib.exp'\n\t        _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-rpath $libdir'\n\t\t;;\n\t    esac\n\n\t    _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n\n\t    # Commands to make compiler produce verbose output that lists\n\t    # what \"hidden\" libraries, object files and flags are used when\n\t    # linking a shared library.\n\t    #\n\t    # There doesn't appear to be a way to prevent this compiler from\n\t    # explicitly linking system object files so we need to strip them\n\t    # from the output so that they don't get included in the library\n\t    # dependencies.\n\t    output_verbose_link_cmd='templist=`$CC -shared $CFLAGS -v conftest.$objext 2>&1 | $GREP \"ld\" | $GREP -v \"ld:\"`; templist=`func_echo_all \"$templist\" | $SED \"s/\\(^.*ld.*\\)\\( .*ld.*$\\)/\\1/\"`; list= ; for z in $templist; do case $z in conftest.$objext) list=\"$list $z\";; *.$objext);; *) list=\"$list $z\";;esac; done; func_echo_all \"$list\"'\n\t    ;;\n\t  *)\n\t    if test yes,no = \"$GXX,$with_gnu_ld\"; then\n\t      _LT_TAGVAR(allow_undefined_flag, $1)=' $wl-expect_unresolved $wl\\*'\n\t      case $host in\n\t        osf3*)\n\t          _LT_TAGVAR(archive_cmds, $1)='$CC -shared -nostdlib $allow_undefined_flag $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname `test -n \"$verstring\" && func_echo_all \"$wl-set_version $wl$verstring\"` $wl-update_registry $wl$output_objdir/so_locations -o $lib'\n\t\t  ;;\n\t        *)\n\t          _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag -nostdlib $allow_undefined_flag $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-msym $wl-soname $wl$soname `test -n \"$verstring\" && func_echo_all \"$wl-set_version $wl$verstring\"` $wl-update_registry $wl$output_objdir/so_locations -o $lib'\n\t\t  ;;\n\t      esac\n\n\t      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n\t      _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n\n\t      # Commands to make compiler produce verbose output that lists\n\t      # what \"hidden\" libraries, object files and flags are used when\n\t      # linking a shared library.\n\t      output_verbose_link_cmd='$CC -shared $CFLAGS -v conftest.$objext 2>&1 | $GREP -v \"^Configured with:\" | $GREP \"\\-L\"'\n\n\t    else\n\t      # FIXME: insert proper C++ library support\n\t      _LT_TAGVAR(ld_shlibs, $1)=no\n\t    fi\n\t    ;;\n        esac\n        ;;\n\n      psos*)\n        # FIXME: insert proper C++ library support\n        _LT_TAGVAR(ld_shlibs, $1)=no\n        ;;\n\n      sunos4*)\n        case $cc_basename in\n          CC*)\n\t    # Sun C++ 4.x\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n          lcc*)\n\t    # Lucid\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n          *)\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n        esac\n        ;;\n\n      solaris*)\n        case $cc_basename in\n          CC* | sunCC*)\n\t    # Sun C++ 4.2, 5.x and Centerline C++\n            _LT_TAGVAR(archive_cmds_need_lc,$1)=yes\n\t    _LT_TAGVAR(no_undefined_flag, $1)=' -zdefs'\n\t    _LT_TAGVAR(archive_cmds, $1)='$CC -G$allow_undefined_flag -h$soname -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags'\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)='echo \"{ global:\" > $lib.exp~cat $export_symbols | $SED -e \"s/\\(.*\\)/\\1;/\" >> $lib.exp~echo \"local: *; };\" >> $lib.exp~\n              $CC -G$allow_undefined_flag $wl-M $wl$lib.exp -h$soname -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags~$RM $lib.exp'\n\n\t    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-R$libdir'\n\t    _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n\t    case $host_os in\n\t      solaris2.[[0-5]] | solaris2.[[0-5]].*) ;;\n\t      *)\n\t\t# The compiler driver will combine and reorder linker options,\n\t\t# but understands '-z linker_flag'.\n\t        # Supported since Solaris 2.6 (maybe 2.5.1?)\n\t\t_LT_TAGVAR(whole_archive_flag_spec, $1)='-z allextract$convenience -z defaultextract'\n\t        ;;\n\t    esac\n\t    _LT_TAGVAR(link_all_deplibs, $1)=yes\n\n\t    output_verbose_link_cmd='func_echo_all'\n\n\t    # Archives containing C++ object files must be created using\n\t    # \"CC -xar\", where \"CC\" is the Sun C++ compiler.  This is\n\t    # necessary to make sure instantiated templates are included\n\t    # in the archive.\n\t    _LT_TAGVAR(old_archive_cmds, $1)='$CC -xar -o $oldlib $oldobjs'\n\t    ;;\n          gcx*)\n\t    # Green Hills C++ Compiler\n\t    _LT_TAGVAR(archive_cmds, $1)='$CC -shared $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-h $wl$soname -o $lib'\n\n\t    # The C++ compiler must be used to create the archive.\n\t    _LT_TAGVAR(old_archive_cmds, $1)='$CC $LDFLAGS -archive -o $oldlib $oldobjs'\n\t    ;;\n          *)\n\t    # GNU C++ compiler with Solaris linker\n\t    if test yes,no = \"$GXX,$with_gnu_ld\"; then\n\t      _LT_TAGVAR(no_undefined_flag, $1)=' $wl-z ${wl}defs'\n\t      if $CC --version | $GREP -v '^2\\.7' > /dev/null; then\n\t        _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag -nostdlib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-h $wl$soname -o $lib'\n\t        _LT_TAGVAR(archive_expsym_cmds, $1)='echo \"{ global:\" > $lib.exp~cat $export_symbols | $SED -e \"s/\\(.*\\)/\\1;/\" >> $lib.exp~echo \"local: *; };\" >> $lib.exp~\n                  $CC -shared $pic_flag -nostdlib $wl-M $wl$lib.exp $wl-h $wl$soname -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags~$RM $lib.exp'\n\n\t        # Commands to make compiler produce verbose output that lists\n\t        # what \"hidden\" libraries, object files and flags are used when\n\t        # linking a shared library.\n\t        output_verbose_link_cmd='$CC -shared $CFLAGS -v conftest.$objext 2>&1 | $GREP -v \"^Configured with:\" | $GREP \"\\-L\"'\n\t      else\n\t        # g++ 2.7 appears to require '-G' NOT '-shared' on this\n\t        # platform.\n\t        _LT_TAGVAR(archive_cmds, $1)='$CC -G -nostdlib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-h $wl$soname -o $lib'\n\t        _LT_TAGVAR(archive_expsym_cmds, $1)='echo \"{ global:\" > $lib.exp~cat $export_symbols | $SED -e \"s/\\(.*\\)/\\1;/\" >> $lib.exp~echo \"local: *; };\" >> $lib.exp~\n                  $CC -G -nostdlib $wl-M $wl$lib.exp $wl-h $wl$soname -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags~$RM $lib.exp'\n\n\t        # Commands to make compiler produce verbose output that lists\n\t        # what \"hidden\" libraries, object files and flags are used when\n\t        # linking a shared library.\n\t        output_verbose_link_cmd='$CC -G $CFLAGS -v conftest.$objext 2>&1 | $GREP -v \"^Configured with:\" | $GREP \"\\-L\"'\n\t      fi\n\n\t      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-R $wl$libdir'\n\t      case $host_os in\n\t\tsolaris2.[[0-5]] | solaris2.[[0-5]].*) ;;\n\t\t*)\n\t\t  _LT_TAGVAR(whole_archive_flag_spec, $1)='$wl-z ${wl}allextract$convenience $wl-z ${wl}defaultextract'\n\t\t  ;;\n\t      esac\n\t    fi\n\t    ;;\n        esac\n        ;;\n\n    sysv4*uw2* | sysv5OpenUNIX* | sysv5UnixWare7.[[01]].[[10]]* | unixware7* | sco3.2v5.0.[[024]]*)\n      _LT_TAGVAR(no_undefined_flag, $1)='$wl-z,text'\n      _LT_TAGVAR(archive_cmds_need_lc, $1)=no\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      runpath_var='LD_RUN_PATH'\n\n      case $cc_basename in\n        CC*)\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -G $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t  _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -G $wl-Bexport:$export_symbols $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t  ;;\n\t*)\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -shared $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t  _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $wl-Bexport:$export_symbols $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t  ;;\n      esac\n      ;;\n\n      sysv5* | sco3.2v5* | sco5v6*)\n\t# Note: We CANNOT use -z defs as we might desire, because we do not\n\t# link with -lc, and that would cause any symbols used from libc to\n\t# always be unresolved, which means just about no library would\n\t# ever link correctly.  If we're not using GNU ld we use -z text\n\t# though, which does catch some bad symbols but isn't as heavy-handed\n\t# as -z defs.\n\t_LT_TAGVAR(no_undefined_flag, $1)='$wl-z,text'\n\t_LT_TAGVAR(allow_undefined_flag, $1)='$wl-z,nodefs'\n\t_LT_TAGVAR(archive_cmds_need_lc, $1)=no\n\t_LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n\t_LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-R,$libdir'\n\t_LT_TAGVAR(hardcode_libdir_separator, $1)=':'\n\t_LT_TAGVAR(link_all_deplibs, $1)=yes\n\t_LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-Bexport'\n\trunpath_var='LD_RUN_PATH'\n\n\tcase $cc_basename in\n          CC*)\n\t    _LT_TAGVAR(archive_cmds, $1)='$CC -G $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -G $wl-Bexport:$export_symbols $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t    _LT_TAGVAR(old_archive_cmds, $1)='$CC -Tprelink_objects $oldobjs~\n              '\"$_LT_TAGVAR(old_archive_cmds, $1)\"\n\t    _LT_TAGVAR(reload_cmds, $1)='$CC -Tprelink_objects $reload_objs~\n              '\"$_LT_TAGVAR(reload_cmds, $1)\"\n\t    ;;\n\t  *)\n\t    _LT_TAGVAR(archive_cmds, $1)='$CC -shared $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $wl-Bexport:$export_symbols $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t    ;;\n\tesac\n      ;;\n\n      tandem*)\n        case $cc_basename in\n          NCC*)\n\t    # NonStop-UX NCC 3.20\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n          *)\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n        esac\n        ;;\n\n      vxworks*)\n        # FIXME: insert proper C++ library support\n        _LT_TAGVAR(ld_shlibs, $1)=no\n        ;;\n\n      *)\n        # FIXME: insert proper C++ library support\n        _LT_TAGVAR(ld_shlibs, $1)=no\n        ;;\n    esac\n\n    AC_MSG_RESULT([$_LT_TAGVAR(ld_shlibs, $1)])\n    test no = \"$_LT_TAGVAR(ld_shlibs, $1)\" && can_build_shared=no\n\n    _LT_TAGVAR(GCC, $1)=$GXX\n    _LT_TAGVAR(LD, $1)=$LD\n\n    ## CAVEAT EMPTOR:\n    ## There is no encapsulation within the following macros, do not change\n    ## the running order or otherwise move them around unless you know exactly\n    ## what you are doing...\n    _LT_SYS_HIDDEN_LIBDEPS($1)\n    _LT_COMPILER_PIC($1)\n    _LT_COMPILER_C_O($1)\n    _LT_COMPILER_FILE_LOCKS($1)\n    _LT_LINKER_SHLIBS($1)\n    _LT_SYS_DYNAMIC_LINKER($1)\n    _LT_LINKER_HARDCODE_LIBPATH($1)\n\n    _LT_CONFIG($1)\n  fi # test -n \"$compiler\"\n\n  CC=$lt_save_CC\n  CFLAGS=$lt_save_CFLAGS\n  LDCXX=$LD\n  LD=$lt_save_LD\n  GCC=$lt_save_GCC\n  with_gnu_ld=$lt_save_with_gnu_ld\n  lt_cv_path_LDCXX=$lt_cv_path_LD\n  lt_cv_path_LD=$lt_save_path_LD\n  lt_cv_prog_gnu_ldcxx=$lt_cv_prog_gnu_ld\n  lt_cv_prog_gnu_ld=$lt_save_with_gnu_ld\nfi # test yes != \"$_lt_caught_CXX_error\"\n\nAC_LANG_POP\n])# _LT_LANG_CXX_CONFIG\n\n\n# _LT_FUNC_STRIPNAME_CNF\n# ----------------------\n# func_stripname_cnf prefix suffix name\n# strip PREFIX and SUFFIX off of NAME.\n# PREFIX and SUFFIX must not contain globbing or regex special\n# characters, hashes, percent signs, but SUFFIX may contain a leading\n# dot (in which case that matches only a dot).\n#\n# This function is identical to the (non-XSI) version of func_stripname,\n# except this one can be used by m4 code that may be executed by configure,\n# rather than the libtool script.\nm4_defun([_LT_FUNC_STRIPNAME_CNF],[dnl\nAC_REQUIRE([_LT_DECL_SED])\nAC_REQUIRE([_LT_PROG_ECHO_BACKSLASH])\nfunc_stripname_cnf ()\n{\n  case @S|@2 in\n  .*) func_stripname_result=`$ECHO \"@S|@3\" | $SED \"s%^@S|@1%%; s%\\\\\\\\@S|@2\\$%%\"`;;\n  *)  func_stripname_result=`$ECHO \"@S|@3\" | $SED \"s%^@S|@1%%; s%@S|@2\\$%%\"`;;\n  esac\n} # func_stripname_cnf\n])# _LT_FUNC_STRIPNAME_CNF\n\n\n# _LT_SYS_HIDDEN_LIBDEPS([TAGNAME])\n# ---------------------------------\n# Figure out \"hidden\" library dependencies from verbose\n# compiler output when linking a shared library.\n# Parse the compiler output and extract the necessary\n# objects, libraries and library flags.\nm4_defun([_LT_SYS_HIDDEN_LIBDEPS],\n[m4_require([_LT_FILEUTILS_DEFAULTS])dnl\nAC_REQUIRE([_LT_FUNC_STRIPNAME_CNF])dnl\n# Dependencies to place before and after the object being linked:\n_LT_TAGVAR(predep_objects, $1)=\n_LT_TAGVAR(postdep_objects, $1)=\n_LT_TAGVAR(predeps, $1)=\n_LT_TAGVAR(postdeps, $1)=\n_LT_TAGVAR(compiler_lib_search_path, $1)=\n\ndnl we can't use the lt_simple_compile_test_code here,\ndnl because it contains code intended for an executable,\ndnl not a library.  It's possible we should let each\ndnl tag define a new lt_????_link_test_code variable,\ndnl but it's only used here...\nm4_if([$1], [], [cat > conftest.$ac_ext <<_LT_EOF\nint a;\nvoid foo (void) { a = 0; }\n_LT_EOF\n], [$1], [CXX], [cat > conftest.$ac_ext <<_LT_EOF\nclass Foo\n{\npublic:\n  Foo (void) { a = 0; }\nprivate:\n  int a;\n};\n_LT_EOF\n], [$1], [F77], [cat > conftest.$ac_ext <<_LT_EOF\n      subroutine foo\n      implicit none\n      integer*4 a\n      a=0\n      return\n      end\n_LT_EOF\n], [$1], [FC], [cat > conftest.$ac_ext <<_LT_EOF\n      subroutine foo\n      implicit none\n      integer a\n      a=0\n      return\n      end\n_LT_EOF\n], [$1], [GCJ], [cat > conftest.$ac_ext <<_LT_EOF\npublic class foo {\n  private int a;\n  public void bar (void) {\n    a = 0;\n  }\n};\n_LT_EOF\n], [$1], [GO], [cat > conftest.$ac_ext <<_LT_EOF\npackage foo\nfunc foo() {\n}\n_LT_EOF\n])\n\n_lt_libdeps_save_CFLAGS=$CFLAGS\ncase \"$CC $CFLAGS \" in #(\n*\\ -flto*\\ *) CFLAGS=\"$CFLAGS -fno-lto\" ;;\n*\\ -fwhopr*\\ *) CFLAGS=\"$CFLAGS -fno-whopr\" ;;\n*\\ -fuse-linker-plugin*\\ *) CFLAGS=\"$CFLAGS -fno-use-linker-plugin\" ;;\nesac\n\ndnl Parse the compiler output and extract the necessary\ndnl objects, libraries and library flags.\nif AC_TRY_EVAL(ac_compile); then\n  # Parse the compiler output and extract the necessary\n  # objects, libraries and library flags.\n\n  # Sentinel used to keep track of whether or not we are before\n  # the conftest object file.\n  pre_test_object_deps_done=no\n\n  for p in `eval \"$output_verbose_link_cmd\"`; do\n    case $prev$p in\n\n    -L* | -R* | -l*)\n       # Some compilers place space between \"-{L,R}\" and the path.\n       # Remove the space.\n       if test x-L = \"$p\" ||\n          test x-R = \"$p\"; then\n\t prev=$p\n\t continue\n       fi\n\n       # Expand the sysroot to ease extracting the directories later.\n       if test -z \"$prev\"; then\n         case $p in\n         -L*) func_stripname_cnf '-L' '' \"$p\"; prev=-L; p=$func_stripname_result ;;\n         -R*) func_stripname_cnf '-R' '' \"$p\"; prev=-R; p=$func_stripname_result ;;\n         -l*) func_stripname_cnf '-l' '' \"$p\"; prev=-l; p=$func_stripname_result ;;\n         esac\n       fi\n       case $p in\n       =*) func_stripname_cnf '=' '' \"$p\"; p=$lt_sysroot$func_stripname_result ;;\n       esac\n       if test no = \"$pre_test_object_deps_done\"; then\n\t case $prev in\n\t -L | -R)\n\t   # Internal compiler library paths should come after those\n\t   # provided the user.  The postdeps already come after the\n\t   # user supplied libs so there is no need to process them.\n\t   if test -z \"$_LT_TAGVAR(compiler_lib_search_path, $1)\"; then\n\t     _LT_TAGVAR(compiler_lib_search_path, $1)=$prev$p\n\t   else\n\t     _LT_TAGVAR(compiler_lib_search_path, $1)=\"${_LT_TAGVAR(compiler_lib_search_path, $1)} $prev$p\"\n\t   fi\n\t   ;;\n\t # The \"-l\" case would never come before the object being\n\t # linked, so don't bother handling this case.\n\t esac\n       else\n\t if test -z \"$_LT_TAGVAR(postdeps, $1)\"; then\n\t   _LT_TAGVAR(postdeps, $1)=$prev$p\n\t else\n\t   _LT_TAGVAR(postdeps, $1)=\"${_LT_TAGVAR(postdeps, $1)} $prev$p\"\n\t fi\n       fi\n       prev=\n       ;;\n\n    *.lto.$objext) ;; # Ignore GCC LTO objects\n    *.$objext)\n       # This assumes that the test object file only shows up\n       # once in the compiler output.\n       if test \"$p\" = \"conftest.$objext\"; then\n\t pre_test_object_deps_done=yes\n\t continue\n       fi\n\n       if test no = \"$pre_test_object_deps_done\"; then\n\t if test -z \"$_LT_TAGVAR(predep_objects, $1)\"; then\n\t   _LT_TAGVAR(predep_objects, $1)=$p\n\t else\n\t   _LT_TAGVAR(predep_objects, $1)=\"$_LT_TAGVAR(predep_objects, $1) $p\"\n\t fi\n       else\n\t if test -z \"$_LT_TAGVAR(postdep_objects, $1)\"; then\n\t   _LT_TAGVAR(postdep_objects, $1)=$p\n\t else\n\t   _LT_TAGVAR(postdep_objects, $1)=\"$_LT_TAGVAR(postdep_objects, $1) $p\"\n\t fi\n       fi\n       ;;\n\n    *) ;; # Ignore the rest.\n\n    esac\n  done\n\n  # Clean up.\n  rm -f a.out a.exe\nelse\n  echo \"libtool.m4: error: problem compiling $1 test program\"\nfi\n\n$RM -f confest.$objext\nCFLAGS=$_lt_libdeps_save_CFLAGS\n\n# PORTME: override above test on systems where it is broken\nm4_if([$1], [CXX],\n[case $host_os in\ninterix[[3-9]]*)\n  # Interix 3.5 installs completely hosed .la files for C++, so rather than\n  # hack all around it, let's just trust \"g++\" to DTRT.\n  _LT_TAGVAR(predep_objects,$1)=\n  _LT_TAGVAR(postdep_objects,$1)=\n  _LT_TAGVAR(postdeps,$1)=\n  ;;\nesac\n])\n\ncase \" $_LT_TAGVAR(postdeps, $1) \" in\n*\" -lc \"*) _LT_TAGVAR(archive_cmds_need_lc, $1)=no ;;\nesac\n _LT_TAGVAR(compiler_lib_search_dirs, $1)=\nif test -n \"${_LT_TAGVAR(compiler_lib_search_path, $1)}\"; then\n _LT_TAGVAR(compiler_lib_search_dirs, $1)=`echo \" ${_LT_TAGVAR(compiler_lib_search_path, $1)}\" | $SED -e 's! -L! !g' -e 's!^ !!'`\nfi\n_LT_TAGDECL([], [compiler_lib_search_dirs], [1],\n    [The directories searched by this compiler when creating a shared library])\n_LT_TAGDECL([], [predep_objects], [1],\n    [Dependencies to place before and after the objects being linked to\n    create a shared library])\n_LT_TAGDECL([], [postdep_objects], [1])\n_LT_TAGDECL([], [predeps], [1])\n_LT_TAGDECL([], [postdeps], [1])\n_LT_TAGDECL([], [compiler_lib_search_path], [1],\n    [The library search path used internally by the compiler when linking\n    a shared library])\n])# _LT_SYS_HIDDEN_LIBDEPS\n\n\n# _LT_LANG_F77_CONFIG([TAG])\n# --------------------------\n# Ensure that the configuration variables for a Fortran 77 compiler are\n# suitably defined.  These variables are subsequently used by _LT_CONFIG\n# to write the compiler configuration to 'libtool'.\nm4_defun([_LT_LANG_F77_CONFIG],\n[AC_LANG_PUSH(Fortran 77)\nif test -z \"$F77\" || test no = \"$F77\"; then\n  _lt_disable_F77=yes\nfi\n\n_LT_TAGVAR(archive_cmds_need_lc, $1)=no\n_LT_TAGVAR(allow_undefined_flag, $1)=\n_LT_TAGVAR(always_export_symbols, $1)=no\n_LT_TAGVAR(archive_expsym_cmds, $1)=\n_LT_TAGVAR(export_dynamic_flag_spec, $1)=\n_LT_TAGVAR(hardcode_direct, $1)=no\n_LT_TAGVAR(hardcode_direct_absolute, $1)=no\n_LT_TAGVAR(hardcode_libdir_flag_spec, $1)=\n_LT_TAGVAR(hardcode_libdir_separator, $1)=\n_LT_TAGVAR(hardcode_minus_L, $1)=no\n_LT_TAGVAR(hardcode_automatic, $1)=no\n_LT_TAGVAR(inherit_rpath, $1)=no\n_LT_TAGVAR(module_cmds, $1)=\n_LT_TAGVAR(module_expsym_cmds, $1)=\n_LT_TAGVAR(link_all_deplibs, $1)=unknown\n_LT_TAGVAR(old_archive_cmds, $1)=$old_archive_cmds\n_LT_TAGVAR(reload_flag, $1)=$reload_flag\n_LT_TAGVAR(reload_cmds, $1)=$reload_cmds\n_LT_TAGVAR(no_undefined_flag, $1)=\n_LT_TAGVAR(whole_archive_flag_spec, $1)=\n_LT_TAGVAR(enable_shared_with_static_runtimes, $1)=no\n\n# Source file extension for f77 test sources.\nac_ext=f\n\n# Object file extension for compiled f77 test sources.\nobjext=o\n_LT_TAGVAR(objext, $1)=$objext\n\n# No sense in running all these tests if we already determined that\n# the F77 compiler isn't working.  Some variables (like enable_shared)\n# are currently assumed to apply to all compilers on this platform,\n# and will be corrupted by setting them based on a non-working compiler.\nif test yes != \"$_lt_disable_F77\"; then\n  # Code to be used in simple compile tests\n  lt_simple_compile_test_code=\"\\\n      subroutine t\n      return\n      end\n\"\n\n  # Code to be used in simple link tests\n  lt_simple_link_test_code=\"\\\n      program t\n      end\n\"\n\n  # ltmain only uses $CC for tagged configurations so make sure $CC is set.\n  _LT_TAG_COMPILER\n\n  # save warnings/boilerplate of simple test code\n  _LT_COMPILER_BOILERPLATE\n  _LT_LINKER_BOILERPLATE\n\n  # Allow CC to be a program name with arguments.\n  lt_save_CC=$CC\n  lt_save_GCC=$GCC\n  lt_save_CFLAGS=$CFLAGS\n  CC=${F77-\"f77\"}\n  CFLAGS=$FFLAGS\n  compiler=$CC\n  _LT_TAGVAR(compiler, $1)=$CC\n  _LT_CC_BASENAME([$compiler])\n  GCC=$G77\n  if test -n \"$compiler\"; then\n    AC_MSG_CHECKING([if libtool supports shared libraries])\n    AC_MSG_RESULT([$can_build_shared])\n\n    AC_MSG_CHECKING([whether to build shared libraries])\n    test no = \"$can_build_shared\" && enable_shared=no\n\n    # On AIX, shared libraries and static libraries use the same namespace, and\n    # are all built from PIC.\n    case $host_os in\n      aix3*)\n        test yes = \"$enable_shared\" && enable_static=no\n        if test -n \"$RANLIB\"; then\n          archive_cmds=\"$archive_cmds~\\$RANLIB \\$lib\"\n          postinstall_cmds='$RANLIB $lib'\n        fi\n        ;;\n      aix[[4-9]]*)\n\tif test ia64 != \"$host_cpu\"; then\n\t  case $enable_shared,$with_aix_soname,$aix_use_runtimelinking in\n\t  yes,aix,yes) ;;\t\t# shared object as lib.so file only\n\t  yes,svr4,*) ;;\t\t# shared object as lib.so archive member only\n\t  yes,*) enable_static=no ;;\t# shared object in lib.a archive as well\n\t  esac\n\tfi\n        ;;\n    esac\n    AC_MSG_RESULT([$enable_shared])\n\n    AC_MSG_CHECKING([whether to build static libraries])\n    # Make sure either enable_shared or enable_static is yes.\n    test yes = \"$enable_shared\" || enable_static=yes\n    AC_MSG_RESULT([$enable_static])\n\n    _LT_TAGVAR(GCC, $1)=$G77\n    _LT_TAGVAR(LD, $1)=$LD\n\n    ## CAVEAT EMPTOR:\n    ## There is no encapsulation within the following macros, do not change\n    ## the running order or otherwise move them around unless you know exactly\n    ## what you are doing...\n    _LT_COMPILER_PIC($1)\n    _LT_COMPILER_C_O($1)\n    _LT_COMPILER_FILE_LOCKS($1)\n    _LT_LINKER_SHLIBS($1)\n    _LT_SYS_DYNAMIC_LINKER($1)\n    _LT_LINKER_HARDCODE_LIBPATH($1)\n\n    _LT_CONFIG($1)\n  fi # test -n \"$compiler\"\n\n  GCC=$lt_save_GCC\n  CC=$lt_save_CC\n  CFLAGS=$lt_save_CFLAGS\nfi # test yes != \"$_lt_disable_F77\"\n\nAC_LANG_POP\n])# _LT_LANG_F77_CONFIG\n\n\n# _LT_LANG_FC_CONFIG([TAG])\n# -------------------------\n# Ensure that the configuration variables for a Fortran compiler are\n# suitably defined.  These variables are subsequently used by _LT_CONFIG\n# to write the compiler configuration to 'libtool'.\nm4_defun([_LT_LANG_FC_CONFIG],\n[AC_LANG_PUSH(Fortran)\n\nif test -z \"$FC\" || test no = \"$FC\"; then\n  _lt_disable_FC=yes\nfi\n\n_LT_TAGVAR(archive_cmds_need_lc, $1)=no\n_LT_TAGVAR(allow_undefined_flag, $1)=\n_LT_TAGVAR(always_export_symbols, $1)=no\n_LT_TAGVAR(archive_expsym_cmds, $1)=\n_LT_TAGVAR(export_dynamic_flag_spec, $1)=\n_LT_TAGVAR(hardcode_direct, $1)=no\n_LT_TAGVAR(hardcode_direct_absolute, $1)=no\n_LT_TAGVAR(hardcode_libdir_flag_spec, $1)=\n_LT_TAGVAR(hardcode_libdir_separator, $1)=\n_LT_TAGVAR(hardcode_minus_L, $1)=no\n_LT_TAGVAR(hardcode_automatic, $1)=no\n_LT_TAGVAR(inherit_rpath, $1)=no\n_LT_TAGVAR(module_cmds, $1)=\n_LT_TAGVAR(module_expsym_cmds, $1)=\n_LT_TAGVAR(link_all_deplibs, $1)=unknown\n_LT_TAGVAR(old_archive_cmds, $1)=$old_archive_cmds\n_LT_TAGVAR(reload_flag, $1)=$reload_flag\n_LT_TAGVAR(reload_cmds, $1)=$reload_cmds\n_LT_TAGVAR(no_undefined_flag, $1)=\n_LT_TAGVAR(whole_archive_flag_spec, $1)=\n_LT_TAGVAR(enable_shared_with_static_runtimes, $1)=no\n\n# Source file extension for fc test sources.\nac_ext=${ac_fc_srcext-f}\n\n# Object file extension for compiled fc test sources.\nobjext=o\n_LT_TAGVAR(objext, $1)=$objext\n\n# No sense in running all these tests if we already determined that\n# the FC compiler isn't working.  Some variables (like enable_shared)\n# are currently assumed to apply to all compilers on this platform,\n# and will be corrupted by setting them based on a non-working compiler.\nif test yes != \"$_lt_disable_FC\"; then\n  # Code to be used in simple compile tests\n  lt_simple_compile_test_code=\"\\\n      subroutine t\n      return\n      end\n\"\n\n  # Code to be used in simple link tests\n  lt_simple_link_test_code=\"\\\n      program t\n      end\n\"\n\n  # ltmain only uses $CC for tagged configurations so make sure $CC is set.\n  _LT_TAG_COMPILER\n\n  # save warnings/boilerplate of simple test code\n  _LT_COMPILER_BOILERPLATE\n  _LT_LINKER_BOILERPLATE\n\n  # Allow CC to be a program name with arguments.\n  lt_save_CC=$CC\n  lt_save_GCC=$GCC\n  lt_save_CFLAGS=$CFLAGS\n  CC=${FC-\"f95\"}\n  CFLAGS=$FCFLAGS\n  compiler=$CC\n  GCC=$ac_cv_fc_compiler_gnu\n\n  _LT_TAGVAR(compiler, $1)=$CC\n  _LT_CC_BASENAME([$compiler])\n\n  if test -n \"$compiler\"; then\n    AC_MSG_CHECKING([if libtool supports shared libraries])\n    AC_MSG_RESULT([$can_build_shared])\n\n    AC_MSG_CHECKING([whether to build shared libraries])\n    test no = \"$can_build_shared\" && enable_shared=no\n\n    # On AIX, shared libraries and static libraries use the same namespace, and\n    # are all built from PIC.\n    case $host_os in\n      aix3*)\n        test yes = \"$enable_shared\" && enable_static=no\n        if test -n \"$RANLIB\"; then\n          archive_cmds=\"$archive_cmds~\\$RANLIB \\$lib\"\n          postinstall_cmds='$RANLIB $lib'\n        fi\n        ;;\n      aix[[4-9]]*)\n\tif test ia64 != \"$host_cpu\"; then\n\t  case $enable_shared,$with_aix_soname,$aix_use_runtimelinking in\n\t  yes,aix,yes) ;;\t\t# shared object as lib.so file only\n\t  yes,svr4,*) ;;\t\t# shared object as lib.so archive member only\n\t  yes,*) enable_static=no ;;\t# shared object in lib.a archive as well\n\t  esac\n\tfi\n        ;;\n    esac\n    AC_MSG_RESULT([$enable_shared])\n\n    AC_MSG_CHECKING([whether to build static libraries])\n    # Make sure either enable_shared or enable_static is yes.\n    test yes = \"$enable_shared\" || enable_static=yes\n    AC_MSG_RESULT([$enable_static])\n\n    _LT_TAGVAR(GCC, $1)=$ac_cv_fc_compiler_gnu\n    _LT_TAGVAR(LD, $1)=$LD\n\n    ## CAVEAT EMPTOR:\n    ## There is no encapsulation within the following macros, do not change\n    ## the running order or otherwise move them around unless you know exactly\n    ## what you are doing...\n    _LT_SYS_HIDDEN_LIBDEPS($1)\n    _LT_COMPILER_PIC($1)\n    _LT_COMPILER_C_O($1)\n    _LT_COMPILER_FILE_LOCKS($1)\n    _LT_LINKER_SHLIBS($1)\n    _LT_SYS_DYNAMIC_LINKER($1)\n    _LT_LINKER_HARDCODE_LIBPATH($1)\n\n    _LT_CONFIG($1)\n  fi # test -n \"$compiler\"\n\n  GCC=$lt_save_GCC\n  CC=$lt_save_CC\n  CFLAGS=$lt_save_CFLAGS\nfi # test yes != \"$_lt_disable_FC\"\n\nAC_LANG_POP\n])# _LT_LANG_FC_CONFIG\n\n\n# _LT_LANG_GCJ_CONFIG([TAG])\n# --------------------------\n# Ensure that the configuration variables for the GNU Java Compiler compiler\n# are suitably defined.  These variables are subsequently used by _LT_CONFIG\n# to write the compiler configuration to 'libtool'.\nm4_defun([_LT_LANG_GCJ_CONFIG],\n[AC_REQUIRE([LT_PROG_GCJ])dnl\nAC_LANG_SAVE\n\n# Source file extension for Java test sources.\nac_ext=java\n\n# Object file extension for compiled Java test sources.\nobjext=o\n_LT_TAGVAR(objext, $1)=$objext\n\n# Code to be used in simple compile tests\nlt_simple_compile_test_code=\"class foo {}\"\n\n# Code to be used in simple link tests\nlt_simple_link_test_code='public class conftest { public static void main(String[[]] argv) {}; }'\n\n# ltmain only uses $CC for tagged configurations so make sure $CC is set.\n_LT_TAG_COMPILER\n\n# save warnings/boilerplate of simple test code\n_LT_COMPILER_BOILERPLATE\n_LT_LINKER_BOILERPLATE\n\n# Allow CC to be a program name with arguments.\nlt_save_CC=$CC\nlt_save_CFLAGS=$CFLAGS\nlt_save_GCC=$GCC\nGCC=yes\nCC=${GCJ-\"gcj\"}\nCFLAGS=$GCJFLAGS\ncompiler=$CC\n_LT_TAGVAR(compiler, $1)=$CC\n_LT_TAGVAR(LD, $1)=$LD\n_LT_CC_BASENAME([$compiler])\n\n# GCJ did not exist at the time GCC didn't implicitly link libc in.\n_LT_TAGVAR(archive_cmds_need_lc, $1)=no\n\n_LT_TAGVAR(old_archive_cmds, $1)=$old_archive_cmds\n_LT_TAGVAR(reload_flag, $1)=$reload_flag\n_LT_TAGVAR(reload_cmds, $1)=$reload_cmds\n\n## CAVEAT EMPTOR:\n## There is no encapsulation within the following macros, do not change\n## the running order or otherwise move them around unless you know exactly\n## what you are doing...\nif test -n \"$compiler\"; then\n  _LT_COMPILER_NO_RTTI($1)\n  _LT_COMPILER_PIC($1)\n  _LT_COMPILER_C_O($1)\n  _LT_COMPILER_FILE_LOCKS($1)\n  _LT_LINKER_SHLIBS($1)\n  _LT_LINKER_HARDCODE_LIBPATH($1)\n\n  _LT_CONFIG($1)\nfi\n\nAC_LANG_RESTORE\n\nGCC=$lt_save_GCC\nCC=$lt_save_CC\nCFLAGS=$lt_save_CFLAGS\n])# _LT_LANG_GCJ_CONFIG\n\n\n# _LT_LANG_GO_CONFIG([TAG])\n# --------------------------\n# Ensure that the configuration variables for the GNU Go compiler\n# are suitably defined.  These variables are subsequently used by _LT_CONFIG\n# to write the compiler configuration to 'libtool'.\nm4_defun([_LT_LANG_GO_CONFIG],\n[AC_REQUIRE([LT_PROG_GO])dnl\nAC_LANG_SAVE\n\n# Source file extension for Go test sources.\nac_ext=go\n\n# Object file extension for compiled Go test sources.\nobjext=o\n_LT_TAGVAR(objext, $1)=$objext\n\n# Code to be used in simple compile tests\nlt_simple_compile_test_code=\"package main; func main() { }\"\n\n# Code to be used in simple link tests\nlt_simple_link_test_code='package main; func main() { }'\n\n# ltmain only uses $CC for tagged configurations so make sure $CC is set.\n_LT_TAG_COMPILER\n\n# save warnings/boilerplate of simple test code\n_LT_COMPILER_BOILERPLATE\n_LT_LINKER_BOILERPLATE\n\n# Allow CC to be a program name with arguments.\nlt_save_CC=$CC\nlt_save_CFLAGS=$CFLAGS\nlt_save_GCC=$GCC\nGCC=yes\nCC=${GOC-\"gccgo\"}\nCFLAGS=$GOFLAGS\ncompiler=$CC\n_LT_TAGVAR(compiler, $1)=$CC\n_LT_TAGVAR(LD, $1)=$LD\n_LT_CC_BASENAME([$compiler])\n\n# Go did not exist at the time GCC didn't implicitly link libc in.\n_LT_TAGVAR(archive_cmds_need_lc, $1)=no\n\n_LT_TAGVAR(old_archive_cmds, $1)=$old_archive_cmds\n_LT_TAGVAR(reload_flag, $1)=$reload_flag\n_LT_TAGVAR(reload_cmds, $1)=$reload_cmds\n\n## CAVEAT EMPTOR:\n## There is no encapsulation within the following macros, do not change\n## the running order or otherwise move them around unless you know exactly\n## what you are doing...\nif test -n \"$compiler\"; then\n  _LT_COMPILER_NO_RTTI($1)\n  _LT_COMPILER_PIC($1)\n  _LT_COMPILER_C_O($1)\n  _LT_COMPILER_FILE_LOCKS($1)\n  _LT_LINKER_SHLIBS($1)\n  _LT_LINKER_HARDCODE_LIBPATH($1)\n\n  _LT_CONFIG($1)\nfi\n\nAC_LANG_RESTORE\n\nGCC=$lt_save_GCC\nCC=$lt_save_CC\nCFLAGS=$lt_save_CFLAGS\n])# _LT_LANG_GO_CONFIG\n\n\n# _LT_LANG_RC_CONFIG([TAG])\n# -------------------------\n# Ensure that the configuration variables for the Windows resource compiler\n# are suitably defined.  These variables are subsequently used by _LT_CONFIG\n# to write the compiler configuration to 'libtool'.\nm4_defun([_LT_LANG_RC_CONFIG],\n[AC_REQUIRE([LT_PROG_RC])dnl\nAC_LANG_SAVE\n\n# Source file extension for RC test sources.\nac_ext=rc\n\n# Object file extension for compiled RC test sources.\nobjext=o\n_LT_TAGVAR(objext, $1)=$objext\n\n# Code to be used in simple compile tests\nlt_simple_compile_test_code='sample MENU { MENUITEM \"&Soup\", 100, CHECKED }'\n\n# Code to be used in simple link tests\nlt_simple_link_test_code=$lt_simple_compile_test_code\n\n# ltmain only uses $CC for tagged configurations so make sure $CC is set.\n_LT_TAG_COMPILER\n\n# save warnings/boilerplate of simple test code\n_LT_COMPILER_BOILERPLATE\n_LT_LINKER_BOILERPLATE\n\n# Allow CC to be a program name with arguments.\nlt_save_CC=$CC\nlt_save_CFLAGS=$CFLAGS\nlt_save_GCC=$GCC\nGCC=\nCC=${RC-\"windres\"}\nCFLAGS=\ncompiler=$CC\n_LT_TAGVAR(compiler, $1)=$CC\n_LT_CC_BASENAME([$compiler])\n_LT_TAGVAR(lt_cv_prog_compiler_c_o, $1)=yes\n\nif test -n \"$compiler\"; then\n  :\n  _LT_CONFIG($1)\nfi\n\nGCC=$lt_save_GCC\nAC_LANG_RESTORE\nCC=$lt_save_CC\nCFLAGS=$lt_save_CFLAGS\n])# _LT_LANG_RC_CONFIG\n\n\n# LT_PROG_GCJ\n# -----------\nAC_DEFUN([LT_PROG_GCJ],\n[m4_ifdef([AC_PROG_GCJ], [AC_PROG_GCJ],\n  [m4_ifdef([A][M_PROG_GCJ], [A][M_PROG_GCJ],\n    [AC_CHECK_TOOL(GCJ, gcj,)\n      test set = \"${GCJFLAGS+set}\" || GCJFLAGS=\"-g -O2\"\n      AC_SUBST(GCJFLAGS)])])[]dnl\n])\n\n# Old name:\nAU_ALIAS([LT_AC_PROG_GCJ], [LT_PROG_GCJ])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([LT_AC_PROG_GCJ], [])\n\n\n# LT_PROG_GO\n# ----------\nAC_DEFUN([LT_PROG_GO],\n[AC_CHECK_TOOL(GOC, gccgo,)\n])\n\n\n# LT_PROG_RC\n# ----------\nAC_DEFUN([LT_PROG_RC],\n[AC_CHECK_TOOL(RC, windres,)\n])\n\n# Old name:\nAU_ALIAS([LT_AC_PROG_RC], [LT_PROG_RC])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([LT_AC_PROG_RC], [])\n\n\n# _LT_DECL_EGREP\n# --------------\n# If we don't have a new enough Autoconf to choose the best grep\n# available, choose the one first in the user's PATH.\nm4_defun([_LT_DECL_EGREP],\n[AC_REQUIRE([AC_PROG_EGREP])dnl\nAC_REQUIRE([AC_PROG_FGREP])dnl\ntest -z \"$GREP\" && GREP=grep\n_LT_DECL([], [GREP], [1], [A grep program that handles long lines])\n_LT_DECL([], [EGREP], [1], [An ERE matcher])\n_LT_DECL([], [FGREP], [1], [A literal string matcher])\ndnl Non-bleeding-edge autoconf doesn't subst GREP, so do it here too\nAC_SUBST([GREP])\n])\n\n\n# _LT_DECL_OBJDUMP\n# --------------\n# If we don't have a new enough Autoconf to choose the best objdump\n# available, choose the one first in the user's PATH.\nm4_defun([_LT_DECL_OBJDUMP],\n[AC_CHECK_TOOL(OBJDUMP, objdump, false)\ntest -z \"$OBJDUMP\" && OBJDUMP=objdump\n_LT_DECL([], [OBJDUMP], [1], [An object symbol dumper])\nAC_SUBST([OBJDUMP])\n])\n\n# _LT_DECL_DLLTOOL\n# ----------------\n# Ensure DLLTOOL variable is set.\nm4_defun([_LT_DECL_DLLTOOL],\n[AC_CHECK_TOOL(DLLTOOL, dlltool, false)\ntest -z \"$DLLTOOL\" && DLLTOOL=dlltool\n_LT_DECL([], [DLLTOOL], [1], [DLL creation program])\nAC_SUBST([DLLTOOL])\n])\n\n# _LT_DECL_SED\n# ------------\n# Check for a fully-functional sed program, that truncates\n# as few characters as possible.  Prefer GNU sed if found.\nm4_defun([_LT_DECL_SED],\n[AC_PROG_SED\ntest -z \"$SED\" && SED=sed\nXsed=\"$SED -e 1s/^X//\"\n_LT_DECL([], [SED], [1], [A sed program that does not truncate output])\n_LT_DECL([], [Xsed], [\"\\$SED -e 1s/^X//\"],\n    [Sed that helps us avoid accidentally triggering echo(1) options like -n])\n])# _LT_DECL_SED\n\nm4_ifndef([AC_PROG_SED], [\n############################################################\n# NOTE: This macro has been submitted for inclusion into   #\n#  GNU Autoconf as AC_PROG_SED.  When it is available in   #\n#  a released version of Autoconf we should remove this    #\n#  macro and use it instead.                               #\n############################################################\n\nm4_defun([AC_PROG_SED],\n[AC_MSG_CHECKING([for a sed that does not truncate output])\nAC_CACHE_VAL(lt_cv_path_SED,\n[# Loop through the user's path and test for sed and gsed.\n# Then use that list of sed's as ones to test for truncation.\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  test -z \"$as_dir\" && as_dir=.\n  for lt_ac_prog in sed gsed; do\n    for ac_exec_ext in '' $ac_executable_extensions; do\n      if $as_executable_p \"$as_dir/$lt_ac_prog$ac_exec_ext\"; then\n        lt_ac_sed_list=\"$lt_ac_sed_list $as_dir/$lt_ac_prog$ac_exec_ext\"\n      fi\n    done\n  done\ndone\nIFS=$as_save_IFS\nlt_ac_max=0\nlt_ac_count=0\n# Add /usr/xpg4/bin/sed as it is typically found on Solaris\n# along with /bin/sed that truncates output.\nfor lt_ac_sed in $lt_ac_sed_list /usr/xpg4/bin/sed; do\n  test ! -f \"$lt_ac_sed\" && continue\n  cat /dev/null > conftest.in\n  lt_ac_count=0\n  echo $ECHO_N \"0123456789$ECHO_C\" >conftest.in\n  # Check for GNU sed and select it if it is found.\n  if \"$lt_ac_sed\" --version 2>&1 < /dev/null | grep 'GNU' > /dev/null; then\n    lt_cv_path_SED=$lt_ac_sed\n    break\n  fi\n  while true; do\n    cat conftest.in conftest.in >conftest.tmp\n    mv conftest.tmp conftest.in\n    cp conftest.in conftest.nl\n    echo >>conftest.nl\n    $lt_ac_sed -e 's/a$//' < conftest.nl >conftest.out || break\n    cmp -s conftest.out conftest.nl || break\n    # 10000 chars as input seems more than enough\n    test 10 -lt \"$lt_ac_count\" && break\n    lt_ac_count=`expr $lt_ac_count + 1`\n    if test \"$lt_ac_count\" -gt \"$lt_ac_max\"; then\n      lt_ac_max=$lt_ac_count\n      lt_cv_path_SED=$lt_ac_sed\n    fi\n  done\ndone\n])\nSED=$lt_cv_path_SED\nAC_SUBST([SED])\nAC_MSG_RESULT([$SED])\n])#AC_PROG_SED\n])#m4_ifndef\n\n# Old name:\nAU_ALIAS([LT_AC_PROG_SED], [AC_PROG_SED])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([LT_AC_PROG_SED], [])\n\n\n# _LT_CHECK_SHELL_FEATURES\n# ------------------------\n# Find out whether the shell is Bourne or XSI compatible,\n# or has some other useful features.\nm4_defun([_LT_CHECK_SHELL_FEATURES],\n[if ( (MAIL=60; unset MAIL) || exit) >/dev/null 2>&1; then\n  lt_unset=unset\nelse\n  lt_unset=false\nfi\n_LT_DECL([], [lt_unset], [0], [whether the shell understands \"unset\"])dnl\n\n# test EBCDIC or ASCII\ncase `echo X|tr X '\\101'` in\n A) # ASCII based system\n    # \\n is not interpreted correctly by Solaris 8 /usr/ucb/tr\n  lt_SP2NL='tr \\040 \\012'\n  lt_NL2SP='tr \\015\\012 \\040\\040'\n  ;;\n *) # EBCDIC based system\n  lt_SP2NL='tr \\100 \\n'\n  lt_NL2SP='tr \\r\\n \\100\\100'\n  ;;\nesac\n_LT_DECL([SP2NL], [lt_SP2NL], [1], [turn spaces into newlines])dnl\n_LT_DECL([NL2SP], [lt_NL2SP], [1], [turn newlines into spaces])dnl\n])# _LT_CHECK_SHELL_FEATURES\n\n\n# _LT_PATH_CONVERSION_FUNCTIONS\n# -----------------------------\n# Determine what file name conversion functions should be used by\n# func_to_host_file (and, implicitly, by func_to_host_path).  These are needed\n# for certain cross-compile configurations and native mingw.\nm4_defun([_LT_PATH_CONVERSION_FUNCTIONS],\n[AC_REQUIRE([AC_CANONICAL_HOST])dnl\nAC_REQUIRE([AC_CANONICAL_BUILD])dnl\nAC_MSG_CHECKING([how to convert $build file names to $host format])\nAC_CACHE_VAL(lt_cv_to_host_file_cmd,\n[case $host in\n  *-*-mingw* )\n    case $build in\n      *-*-mingw* ) # actually msys\n        lt_cv_to_host_file_cmd=func_convert_file_msys_to_w32\n        ;;\n      *-*-cygwin* )\n        lt_cv_to_host_file_cmd=func_convert_file_cygwin_to_w32\n        ;;\n      * ) # otherwise, assume *nix\n        lt_cv_to_host_file_cmd=func_convert_file_nix_to_w32\n        ;;\n    esac\n    ;;\n  *-*-cygwin* )\n    case $build in\n      *-*-mingw* ) # actually msys\n        lt_cv_to_host_file_cmd=func_convert_file_msys_to_cygwin\n        ;;\n      *-*-cygwin* )\n        lt_cv_to_host_file_cmd=func_convert_file_noop\n        ;;\n      * ) # otherwise, assume *nix\n        lt_cv_to_host_file_cmd=func_convert_file_nix_to_cygwin\n        ;;\n    esac\n    ;;\n  * ) # unhandled hosts (and \"normal\" native builds)\n    lt_cv_to_host_file_cmd=func_convert_file_noop\n    ;;\nesac\n])\nto_host_file_cmd=$lt_cv_to_host_file_cmd\nAC_MSG_RESULT([$lt_cv_to_host_file_cmd])\n_LT_DECL([to_host_file_cmd], [lt_cv_to_host_file_cmd],\n         [0], [convert $build file names to $host format])dnl\n\nAC_MSG_CHECKING([how to convert $build file names to toolchain format])\nAC_CACHE_VAL(lt_cv_to_tool_file_cmd,\n[#assume ordinary cross tools, or native build.\nlt_cv_to_tool_file_cmd=func_convert_file_noop\ncase $host in\n  *-*-mingw* )\n    case $build in\n      *-*-mingw* ) # actually msys\n        lt_cv_to_tool_file_cmd=func_convert_file_msys_to_w32\n        ;;\n    esac\n    ;;\nesac\n])\nto_tool_file_cmd=$lt_cv_to_tool_file_cmd\nAC_MSG_RESULT([$lt_cv_to_tool_file_cmd])\n_LT_DECL([to_tool_file_cmd], [lt_cv_to_tool_file_cmd],\n         [0], [convert $build files to toolchain format])dnl\n])# _LT_PATH_CONVERSION_FUNCTIONS\n",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/tests/test_autotools/m4/ltoptions.m4": "# Helper functions for option handling.                    -*- Autoconf -*-\n#\n#   Copyright (C) 2004-2005, 2007-2009, 2011-2015 Free Software\n#   Foundation, Inc.\n#   Written by Gary V. Vaughan, 2004\n#\n# This file is free software; the Free Software Foundation gives\n# unlimited permission to copy and/or distribute it, with or without\n# modifications, as long as this notice is preserved.\n\n# serial 8 ltoptions.m4\n\n# This is to help aclocal find these macros, as it can't see m4_define.\nAC_DEFUN([LTOPTIONS_VERSION], [m4_if([1])])\n\n\n# _LT_MANGLE_OPTION(MACRO-NAME, OPTION-NAME)\n# ------------------------------------------\nm4_define([_LT_MANGLE_OPTION],\n[[_LT_OPTION_]m4_bpatsubst($1__$2, [[^a-zA-Z0-9_]], [_])])\n\n\n# _LT_SET_OPTION(MACRO-NAME, OPTION-NAME)\n# ---------------------------------------\n# Set option OPTION-NAME for macro MACRO-NAME, and if there is a\n# matching handler defined, dispatch to it.  Other OPTION-NAMEs are\n# saved as a flag.\nm4_define([_LT_SET_OPTION],\n[m4_define(_LT_MANGLE_OPTION([$1], [$2]))dnl\nm4_ifdef(_LT_MANGLE_DEFUN([$1], [$2]),\n        _LT_MANGLE_DEFUN([$1], [$2]),\n    [m4_warning([Unknown $1 option '$2'])])[]dnl\n])\n\n\n# _LT_IF_OPTION(MACRO-NAME, OPTION-NAME, IF-SET, [IF-NOT-SET])\n# ------------------------------------------------------------\n# Execute IF-SET if OPTION is set, IF-NOT-SET otherwise.\nm4_define([_LT_IF_OPTION],\n[m4_ifdef(_LT_MANGLE_OPTION([$1], [$2]), [$3], [$4])])\n\n\n# _LT_UNLESS_OPTIONS(MACRO-NAME, OPTION-LIST, IF-NOT-SET)\n# -------------------------------------------------------\n# Execute IF-NOT-SET unless all options in OPTION-LIST for MACRO-NAME\n# are set.\nm4_define([_LT_UNLESS_OPTIONS],\n[m4_foreach([_LT_Option], m4_split(m4_normalize([$2])),\n\t    [m4_ifdef(_LT_MANGLE_OPTION([$1], _LT_Option),\n\t\t      [m4_define([$0_found])])])[]dnl\nm4_ifdef([$0_found], [m4_undefine([$0_found])], [$3\n])[]dnl\n])\n\n\n# _LT_SET_OPTIONS(MACRO-NAME, OPTION-LIST)\n# ----------------------------------------\n# OPTION-LIST is a space-separated list of Libtool options associated\n# with MACRO-NAME.  If any OPTION has a matching handler declared with\n# LT_OPTION_DEFINE, dispatch to that macro; otherwise complain about\n# the unknown option and exit.\nm4_defun([_LT_SET_OPTIONS],\n[# Set options\nm4_foreach([_LT_Option], m4_split(m4_normalize([$2])),\n    [_LT_SET_OPTION([$1], _LT_Option)])\n\nm4_if([$1],[LT_INIT],[\n  dnl\n  dnl Simply set some default values (i.e off) if boolean options were not\n  dnl specified:\n  _LT_UNLESS_OPTIONS([LT_INIT], [dlopen], [enable_dlopen=no\n  ])\n  _LT_UNLESS_OPTIONS([LT_INIT], [win32-dll], [enable_win32_dll=no\n  ])\n  dnl\n  dnl If no reference was made to various pairs of opposing options, then\n  dnl we run the default mode handler for the pair.  For example, if neither\n  dnl 'shared' nor 'disable-shared' was passed, we enable building of shared\n  dnl archives by default:\n  _LT_UNLESS_OPTIONS([LT_INIT], [shared disable-shared], [_LT_ENABLE_SHARED])\n  _LT_UNLESS_OPTIONS([LT_INIT], [static disable-static], [_LT_ENABLE_STATIC])\n  _LT_UNLESS_OPTIONS([LT_INIT], [pic-only no-pic], [_LT_WITH_PIC])\n  _LT_UNLESS_OPTIONS([LT_INIT], [fast-install disable-fast-install],\n\t\t   [_LT_ENABLE_FAST_INSTALL])\n  _LT_UNLESS_OPTIONS([LT_INIT], [aix-soname=aix aix-soname=both aix-soname=svr4],\n\t\t   [_LT_WITH_AIX_SONAME([aix])])\n  ])\n])# _LT_SET_OPTIONS\n\n\n## --------------------------------- ##\n## Macros to handle LT_INIT options. ##\n## --------------------------------- ##\n\n# _LT_MANGLE_DEFUN(MACRO-NAME, OPTION-NAME)\n# -----------------------------------------\nm4_define([_LT_MANGLE_DEFUN],\n[[_LT_OPTION_DEFUN_]m4_bpatsubst(m4_toupper([$1__$2]), [[^A-Z0-9_]], [_])])\n\n\n# LT_OPTION_DEFINE(MACRO-NAME, OPTION-NAME, CODE)\n# -----------------------------------------------\nm4_define([LT_OPTION_DEFINE],\n[m4_define(_LT_MANGLE_DEFUN([$1], [$2]), [$3])[]dnl\n])# LT_OPTION_DEFINE\n\n\n# dlopen\n# ------\nLT_OPTION_DEFINE([LT_INIT], [dlopen], [enable_dlopen=yes\n])\n\nAU_DEFUN([AC_LIBTOOL_DLOPEN],\n[_LT_SET_OPTION([LT_INIT], [dlopen])\nAC_DIAGNOSE([obsolete],\n[$0: Remove this warning and the call to _LT_SET_OPTION when you\nput the 'dlopen' option into LT_INIT's first parameter.])\n])\n\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_LIBTOOL_DLOPEN], [])\n\n\n# win32-dll\n# ---------\n# Declare package support for building win32 dll's.\nLT_OPTION_DEFINE([LT_INIT], [win32-dll],\n[enable_win32_dll=yes\n\ncase $host in\n*-*-cygwin* | *-*-mingw* | *-*-pw32* | *-*-cegcc*)\n  AC_CHECK_TOOL(AS, as, false)\n  AC_CHECK_TOOL(DLLTOOL, dlltool, false)\n  AC_CHECK_TOOL(OBJDUMP, objdump, false)\n  ;;\nesac\n\ntest -z \"$AS\" && AS=as\n_LT_DECL([], [AS],      [1], [Assembler program])dnl\n\ntest -z \"$DLLTOOL\" && DLLTOOL=dlltool\n_LT_DECL([], [DLLTOOL], [1], [DLL creation program])dnl\n\ntest -z \"$OBJDUMP\" && OBJDUMP=objdump\n_LT_DECL([], [OBJDUMP], [1], [Object dumper program])dnl\n])# win32-dll\n\nAU_DEFUN([AC_LIBTOOL_WIN32_DLL],\n[AC_REQUIRE([AC_CANONICAL_HOST])dnl\n_LT_SET_OPTION([LT_INIT], [win32-dll])\nAC_DIAGNOSE([obsolete],\n[$0: Remove this warning and the call to _LT_SET_OPTION when you\nput the 'win32-dll' option into LT_INIT's first parameter.])\n])\n\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_LIBTOOL_WIN32_DLL], [])\n\n\n# _LT_ENABLE_SHARED([DEFAULT])\n# ----------------------------\n# implement the --enable-shared flag, and supports the 'shared' and\n# 'disable-shared' LT_INIT options.\n# DEFAULT is either 'yes' or 'no'.  If omitted, it defaults to 'yes'.\nm4_define([_LT_ENABLE_SHARED],\n[m4_define([_LT_ENABLE_SHARED_DEFAULT], [m4_if($1, no, no, yes)])dnl\nAC_ARG_ENABLE([shared],\n    [AS_HELP_STRING([--enable-shared@<:@=PKGS@:>@],\n\t[build shared libraries @<:@default=]_LT_ENABLE_SHARED_DEFAULT[@:>@])],\n    [p=${PACKAGE-default}\n    case $enableval in\n    yes) enable_shared=yes ;;\n    no) enable_shared=no ;;\n    *)\n      enable_shared=no\n      # Look at the argument we got.  We use all the common list separators.\n      lt_save_ifs=$IFS; IFS=$IFS$PATH_SEPARATOR,\n      for pkg in $enableval; do\n\tIFS=$lt_save_ifs\n\tif test \"X$pkg\" = \"X$p\"; then\n\t  enable_shared=yes\n\tfi\n      done\n      IFS=$lt_save_ifs\n      ;;\n    esac],\n    [enable_shared=]_LT_ENABLE_SHARED_DEFAULT)\n\n    _LT_DECL([build_libtool_libs], [enable_shared], [0],\n\t[Whether or not to build shared libraries])\n])# _LT_ENABLE_SHARED\n\nLT_OPTION_DEFINE([LT_INIT], [shared], [_LT_ENABLE_SHARED([yes])])\nLT_OPTION_DEFINE([LT_INIT], [disable-shared], [_LT_ENABLE_SHARED([no])])\n\n# Old names:\nAC_DEFUN([AC_ENABLE_SHARED],\n[_LT_SET_OPTION([LT_INIT], m4_if([$1], [no], [disable-])[shared])\n])\n\nAC_DEFUN([AC_DISABLE_SHARED],\n[_LT_SET_OPTION([LT_INIT], [disable-shared])\n])\n\nAU_DEFUN([AM_ENABLE_SHARED], [AC_ENABLE_SHARED($@)])\nAU_DEFUN([AM_DISABLE_SHARED], [AC_DISABLE_SHARED($@)])\n\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AM_ENABLE_SHARED], [])\ndnl AC_DEFUN([AM_DISABLE_SHARED], [])\n\n\n\n# _LT_ENABLE_STATIC([DEFAULT])\n# ----------------------------\n# implement the --enable-static flag, and support the 'static' and\n# 'disable-static' LT_INIT options.\n# DEFAULT is either 'yes' or 'no'.  If omitted, it defaults to 'yes'.\nm4_define([_LT_ENABLE_STATIC],\n[m4_define([_LT_ENABLE_STATIC_DEFAULT], [m4_if($1, no, no, yes)])dnl\nAC_ARG_ENABLE([static],\n    [AS_HELP_STRING([--enable-static@<:@=PKGS@:>@],\n\t[build static libraries @<:@default=]_LT_ENABLE_STATIC_DEFAULT[@:>@])],\n    [p=${PACKAGE-default}\n    case $enableval in\n    yes) enable_static=yes ;;\n    no) enable_static=no ;;\n    *)\n     enable_static=no\n      # Look at the argument we got.  We use all the common list separators.\n      lt_save_ifs=$IFS; IFS=$IFS$PATH_SEPARATOR,\n      for pkg in $enableval; do\n\tIFS=$lt_save_ifs\n\tif test \"X$pkg\" = \"X$p\"; then\n\t  enable_static=yes\n\tfi\n      done\n      IFS=$lt_save_ifs\n      ;;\n    esac],\n    [enable_static=]_LT_ENABLE_STATIC_DEFAULT)\n\n    _LT_DECL([build_old_libs], [enable_static], [0],\n\t[Whether or not to build static libraries])\n])# _LT_ENABLE_STATIC\n\nLT_OPTION_DEFINE([LT_INIT], [static], [_LT_ENABLE_STATIC([yes])])\nLT_OPTION_DEFINE([LT_INIT], [disable-static], [_LT_ENABLE_STATIC([no])])\n\n# Old names:\nAC_DEFUN([AC_ENABLE_STATIC],\n[_LT_SET_OPTION([LT_INIT], m4_if([$1], [no], [disable-])[static])\n])\n\nAC_DEFUN([AC_DISABLE_STATIC],\n[_LT_SET_OPTION([LT_INIT], [disable-static])\n])\n\nAU_DEFUN([AM_ENABLE_STATIC], [AC_ENABLE_STATIC($@)])\nAU_DEFUN([AM_DISABLE_STATIC], [AC_DISABLE_STATIC($@)])\n\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AM_ENABLE_STATIC], [])\ndnl AC_DEFUN([AM_DISABLE_STATIC], [])\n\n\n\n# _LT_ENABLE_FAST_INSTALL([DEFAULT])\n# ----------------------------------\n# implement the --enable-fast-install flag, and support the 'fast-install'\n# and 'disable-fast-install' LT_INIT options.\n# DEFAULT is either 'yes' or 'no'.  If omitted, it defaults to 'yes'.\nm4_define([_LT_ENABLE_FAST_INSTALL],\n[m4_define([_LT_ENABLE_FAST_INSTALL_DEFAULT], [m4_if($1, no, no, yes)])dnl\nAC_ARG_ENABLE([fast-install],\n    [AS_HELP_STRING([--enable-fast-install@<:@=PKGS@:>@],\n    [optimize for fast installation @<:@default=]_LT_ENABLE_FAST_INSTALL_DEFAULT[@:>@])],\n    [p=${PACKAGE-default}\n    case $enableval in\n    yes) enable_fast_install=yes ;;\n    no) enable_fast_install=no ;;\n    *)\n      enable_fast_install=no\n      # Look at the argument we got.  We use all the common list separators.\n      lt_save_ifs=$IFS; IFS=$IFS$PATH_SEPARATOR,\n      for pkg in $enableval; do\n\tIFS=$lt_save_ifs\n\tif test \"X$pkg\" = \"X$p\"; then\n\t  enable_fast_install=yes\n\tfi\n      done\n      IFS=$lt_save_ifs\n      ;;\n    esac],\n    [enable_fast_install=]_LT_ENABLE_FAST_INSTALL_DEFAULT)\n\n_LT_DECL([fast_install], [enable_fast_install], [0],\n\t [Whether or not to optimize for fast installation])dnl\n])# _LT_ENABLE_FAST_INSTALL\n\nLT_OPTION_DEFINE([LT_INIT], [fast-install], [_LT_ENABLE_FAST_INSTALL([yes])])\nLT_OPTION_DEFINE([LT_INIT], [disable-fast-install], [_LT_ENABLE_FAST_INSTALL([no])])\n\n# Old names:\nAU_DEFUN([AC_ENABLE_FAST_INSTALL],\n[_LT_SET_OPTION([LT_INIT], m4_if([$1], [no], [disable-])[fast-install])\nAC_DIAGNOSE([obsolete],\n[$0: Remove this warning and the call to _LT_SET_OPTION when you put\nthe 'fast-install' option into LT_INIT's first parameter.])\n])\n\nAU_DEFUN([AC_DISABLE_FAST_INSTALL],\n[_LT_SET_OPTION([LT_INIT], [disable-fast-install])\nAC_DIAGNOSE([obsolete],\n[$0: Remove this warning and the call to _LT_SET_OPTION when you put\nthe 'disable-fast-install' option into LT_INIT's first parameter.])\n])\n\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_ENABLE_FAST_INSTALL], [])\ndnl AC_DEFUN([AM_DISABLE_FAST_INSTALL], [])\n\n\n# _LT_WITH_AIX_SONAME([DEFAULT])\n# ----------------------------------\n# implement the --with-aix-soname flag, and support the `aix-soname=aix'\n# and `aix-soname=both' and `aix-soname=svr4' LT_INIT options. DEFAULT\n# is either `aix', `both' or `svr4'.  If omitted, it defaults to `aix'.\nm4_define([_LT_WITH_AIX_SONAME],\n[m4_define([_LT_WITH_AIX_SONAME_DEFAULT], [m4_if($1, svr4, svr4, m4_if($1, both, both, aix))])dnl\nshared_archive_member_spec=\ncase $host,$enable_shared in\npower*-*-aix[[5-9]]*,yes)\n  AC_MSG_CHECKING([which variant of shared library versioning to provide])\n  AC_ARG_WITH([aix-soname],\n    [AS_HELP_STRING([--with-aix-soname=aix|svr4|both],\n      [shared library versioning (aka \"SONAME\") variant to provide on AIX, @<:@default=]_LT_WITH_AIX_SONAME_DEFAULT[@:>@.])],\n    [case $withval in\n    aix|svr4|both)\n      ;;\n    *)\n      AC_MSG_ERROR([Unknown argument to --with-aix-soname])\n      ;;\n    esac\n    lt_cv_with_aix_soname=$with_aix_soname],\n    [AC_CACHE_VAL([lt_cv_with_aix_soname],\n      [lt_cv_with_aix_soname=]_LT_WITH_AIX_SONAME_DEFAULT)\n    with_aix_soname=$lt_cv_with_aix_soname])\n  AC_MSG_RESULT([$with_aix_soname])\n  if test aix != \"$with_aix_soname\"; then\n    # For the AIX way of multilib, we name the shared archive member\n    # based on the bitwidth used, traditionally 'shr.o' or 'shr_64.o',\n    # and 'shr.imp' or 'shr_64.imp', respectively, for the Import File.\n    # Even when GNU compilers ignore OBJECT_MODE but need '-maix64' flag,\n    # the AIX toolchain works better with OBJECT_MODE set (default 32).\n    if test 64 = \"${OBJECT_MODE-32}\"; then\n      shared_archive_member_spec=shr_64\n    else\n      shared_archive_member_spec=shr\n    fi\n  fi\n  ;;\n*)\n  with_aix_soname=aix\n  ;;\nesac\n\n_LT_DECL([], [shared_archive_member_spec], [0],\n    [Shared archive member basename, for filename based shared library versioning on AIX])dnl\n])# _LT_WITH_AIX_SONAME\n\nLT_OPTION_DEFINE([LT_INIT], [aix-soname=aix], [_LT_WITH_AIX_SONAME([aix])])\nLT_OPTION_DEFINE([LT_INIT], [aix-soname=both], [_LT_WITH_AIX_SONAME([both])])\nLT_OPTION_DEFINE([LT_INIT], [aix-soname=svr4], [_LT_WITH_AIX_SONAME([svr4])])\n\n\n# _LT_WITH_PIC([MODE])\n# --------------------\n# implement the --with-pic flag, and support the 'pic-only' and 'no-pic'\n# LT_INIT options.\n# MODE is either 'yes' or 'no'.  If omitted, it defaults to 'both'.\nm4_define([_LT_WITH_PIC],\n[AC_ARG_WITH([pic],\n    [AS_HELP_STRING([--with-pic@<:@=PKGS@:>@],\n\t[try to use only PIC/non-PIC objects @<:@default=use both@:>@])],\n    [lt_p=${PACKAGE-default}\n    case $withval in\n    yes|no) pic_mode=$withval ;;\n    *)\n      pic_mode=default\n      # Look at the argument we got.  We use all the common list separators.\n      lt_save_ifs=$IFS; IFS=$IFS$PATH_SEPARATOR,\n      for lt_pkg in $withval; do\n\tIFS=$lt_save_ifs\n\tif test \"X$lt_pkg\" = \"X$lt_p\"; then\n\t  pic_mode=yes\n\tfi\n      done\n      IFS=$lt_save_ifs\n      ;;\n    esac],\n    [pic_mode=m4_default([$1], [default])])\n\n_LT_DECL([], [pic_mode], [0], [What type of objects to build])dnl\n])# _LT_WITH_PIC\n\nLT_OPTION_DEFINE([LT_INIT], [pic-only], [_LT_WITH_PIC([yes])])\nLT_OPTION_DEFINE([LT_INIT], [no-pic], [_LT_WITH_PIC([no])])\n\n# Old name:\nAU_DEFUN([AC_LIBTOOL_PICMODE],\n[_LT_SET_OPTION([LT_INIT], [pic-only])\nAC_DIAGNOSE([obsolete],\n[$0: Remove this warning and the call to _LT_SET_OPTION when you\nput the 'pic-only' option into LT_INIT's first parameter.])\n])\n\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_LIBTOOL_PICMODE], [])\n\n## ----------------- ##\n## LTDL_INIT Options ##\n## ----------------- ##\n\nm4_define([_LTDL_MODE], [])\nLT_OPTION_DEFINE([LTDL_INIT], [nonrecursive],\n\t\t [m4_define([_LTDL_MODE], [nonrecursive])])\nLT_OPTION_DEFINE([LTDL_INIT], [recursive],\n\t\t [m4_define([_LTDL_MODE], [recursive])])\nLT_OPTION_DEFINE([LTDL_INIT], [subproject],\n\t\t [m4_define([_LTDL_MODE], [subproject])])\n\nm4_define([_LTDL_TYPE], [])\nLT_OPTION_DEFINE([LTDL_INIT], [installable],\n\t\t [m4_define([_LTDL_TYPE], [installable])])\nLT_OPTION_DEFINE([LTDL_INIT], [convenience],\n\t\t [m4_define([_LTDL_TYPE], [convenience])])\n",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/acinclude/check_dlopen.m4": "\nAC_DEFUN([CHECK_DLOPEN], [\n\nAC_LANG_PUSH([C])\n\nAC_CHECK_LIB([dl], [dlopen], [],\n  [AC_MSG_ERROR([Could not locate libdl for dynamic library loading])])\n\nAC_CHECK_HEADERS([dlfcn.h], [],\n      [AC_MSG_ERROR([Could not locate dlfcn.h for dynaimc library loading])])\n\nAC_LANG_POP([C])\n\n])\n\n",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/skeletons/sst_component_example/component.cc": "/**\nCopyright 2009-2020 National Technology and Engineering Solutions of Sandia,\nLLC (NTESS).  Under the terms of Contract DE-NA-0003525, the U.S.  Government \nretains certain rights in this software.\n\nSandia National Laboratories is a multimission laboratory managed and operated\nby National Technology and Engineering Solutions of Sandia, LLC., a wholly \nowned subsidiary of Honeywell International, Inc., for the U.S. Department of \nEnergy's National Nuclear Security Administration under contract DE-NA0003525.\n\nCopyright (c) 2009-2020, NTESS\n\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without modification, \nare permitted provided that the following conditions are met:\n\n    * Redistributions of source code must retain the above copyright\n      notice, this list of conditions and the following disclaimer.\n\n    * Redistributions in binary form must reproduce the above\n      copyright notice, this list of conditions and the following\n      disclaimer in the documentation and/or other materials provided\n      with the distribution.\n\n    * Neither the name of the copyright holder nor the names of its\n      contributors may be used to endorse or promote products derived\n      from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n\"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\nLIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\nA PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\nOWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\nSPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\nLIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\nDATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\nTHEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\nQuestions? Contact sst-macro-help@sandia.gov\n*/\n#include <sstmac/hardware/common/connection.h>\n#include <sstmac/common/sstmac_config.h>\n#include <sstmac/common/sst_event.h>\n#include <sprockit/sim_parameters.h>\n\n\nusing namespace sstmac;\nusing namespace sstmac::hw;\n\n/**\nFor creating custom hardware components inside of SST/macro, it follows\nessentially the same steps as a regular SST component. However, SST/macro\nprovides an extra wrapper layer and present a slightly different interface\nfor connecting objects together in the simulated network. This 'Connectable'\ninterface is presented below.\n*/\n\n\n#if SSTMAC_INTEGRATED_SST_CORE\nusing namespace SST;\n/**\nNo special Python actions are needed so this is null.\n*/\nchar py[] = {0x00};\n\n/**\n * @brief The TestModule class\n * SST will look for this module information after loading libtest.so using dlopen\n * dlopen of libtest.so is triggered by running 'import sst.test'\n * inside the Python configuration script\n */\nclass TestModule : public SSTElementPythonModule {\n public:\n  TestModule(std::string library) :\n    SSTElementPythonModule(library)\n  {\n    addPrimaryModule(py);\n  }\n\n  SST_ELI_REGISTER_PYTHON_MODULE(\n   TestModule,\n   \"test\",\n   SST_ELI_ELEMENT_VERSION(1,0,0)\n  )\n};\n#include <sst/core/model/element_python.h>\n#include <sst/core/element.h>\n#endif\n\n/**\n * @brief The test_component class\n * For sst-macro, all the componennts must correspond to a parent factory type\n * in this case, we create a factory type test_component from which all\n * test components will inherit\n */\nclass TestComponent : public ConnectableComponent {\n public:\n  SST_ELI_DECLARE_BASE(TestComponent)\n  SST_ELI_DECLARE_DEFAULT_INFO()\n  SST_ELI_DECLARE_CTOR(uint32_t,SST::Params&)\n  /**\n   * @brief test_component Standard constructor for all components\n   *  with 3 basic parameters\n   * @param params  All of the parameters scoped for this component\n   * @param id      A unique ID for this component\n   * @param mgr     The event manager that will schedule events for this component\n   */\n  TestComponent(uint32_t id, SST::Params& params) :\n    ConnectableComponent(id, params)\n {\n }\n};\n\nclass TestEvent : public Event {\n public:\n  //Make sure to satisfy the serializable interface\n  ImplementSerializable(TestEvent)\n};\n\n/**\n * @brief The dummy_switch class\n * This is a basic instance of a test component that will generate events\n */\nclass DummySwitch : public TestComponent {\n public:\n  SST_ELI_REGISTER_DERIVED_COMPONENT(\n    TestComponent,\n    DummySwitch,\n    \"macro\",\n    \"dummy\",\n    SST_ELI_ELEMENT_VERSION(1,0,0),\n    \"A dummy switch\",\n    COMPONENT_CATEGORY_NETWORK)\n\n  /**\n   * @brief dummy_switch Standard constructor for all components\n   *  with 3 basic parameters\n   * @param params  All of the parameters scoped for this component\n   * @param id      A unique ID for this component\n   * @param mgr     The event manager that will schedule events for this component\n   */\n  DummySwitch(uint32_t id, SST::Params& params) :\n   TestComponent(id,params), id_(id)\n  {\n    //make sure this function gets called\n    //unfortunately, due to virtual function initialization order\n    //this has to be called in the base child class\n    initLinks(params);\n    //init params\n    num_ping_pongs_ = params.find<int>(\"num_ping_pongs\", 2);\n    latency_ = TimeDelta(params.find<SST::UnitAlgebra>(\"latency\").getValue().toDouble());\n  }\n\n  std::string toString() const override { return \"dummy\";}\n\n  void recvPayload(Event* ev){\n    std::cout << \"Oh, hey, component \" << id_ << \" got a payload!\" << std::endl;\n    TestEvent* tev = dynamic_cast<TestEvent*>(ev);\n    if (tev == nullptr){\n      std::cerr << \"received wrong event type\" << std::endl;\n      abort();\n    }\n    if (num_ping_pongs_ > 0){\n      sendPingMessage();\n    }\n  }\n\n  void recvCredit(Event* ev){\n    //ignore for now, we won't do anything with credits\n  }\n\n  void connectOutput(int src_outport, int dst_inport, EventLink::ptr&& link) override {\n    //register handler on port\n    partner_ = std::move(link);\n    std::cout << \"Connecting output \"\n              << src_outport << \"-> \" << dst_inport\n              << \" on component \" << id_ << std::endl;\n  }\n\n  void connectInput(int src_outport, int dst_inport, EventLink::ptr&& link) override {\n    //we won't do anything with credits, but print for tutorial\n    std::cout << \"Connecting input \"\n              << src_outport << \"-> \" << dst_inport\n              << \" on component \" << id_ << std::endl;\n  }\n\n  void setup() override {\n    std::cout << \"Setting up \" << id_ << std::endl;\n    //make sure to call parent setup method\n    TestComponent::setup();\n    //send an initial test message\n    sendPingMessage();\n  }\n\n  void init(unsigned int phase) override {\n    std::cout << \"Initializing \" << id_\n              << \" on phase \" << phase << std::endl;\n    //make sure to call parent init method\n    TestComponent::init(phase);\n  }\n\n  LinkHandler* creditHandler(int port) override {\n    return newLinkHandler(this, &DummySwitch::recvCredit);\n  }\n\n  LinkHandler* payloadHandler(int port) override {\n    return newLinkHandler(this, &DummySwitch::recvPayload);\n  }\n\n private:\n  void sendPingMessage(){\n    partner_->send(new TestEvent);\n    --num_ping_pongs_;\n  }\n\n private:\n  EventLink::ptr partner_;\n  TimeDelta latency_;\n  int num_ping_pongs_;\n  uint32_t id_;\n\n};\n\n",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/manual.md": "---\ntitle: Manual for SST-Macro 10.1.x\npublished: true\ncategory: SSTDocumentation\n---\n\n\n# SST/macro 10.1 User's Manual\n\n![](https://github.com/sstsimulator/sst-macro/blob/devel/docs/manual/figures/sstlogo.png) \n\n\n\n\n\n\n\n \n\n# Table of Contents\n   - [Chapter 1: Introduction](#sec_intro)\n      - [Section 1.1: Overview](#sec_intro_overview)\n      - [Section 1.2: Preview of Things to Come](#sec_preview)\n      - [Section 1.3: What To Expect In The User's Manual](#sec_whatToExpect)\n   - [Chapter 2: Building and Running SST/macro](#chapter_building)\n      - [Section 2.1: Build and Installation of SST-macro](#sec_buildinstall)\n         - [2.1.1: Downloading](#subsec_build_downloading)\n         - [2.1.2: Dependencies](#subsec_build_dependencies)\n         - [2.1.3: Configuration and Building](#subsec_build_configure)\n            - [Build SST core](#subsec_buildSSTCore)\n            - [Build SST/macro element library](#subsec_buildElementLib)\n         - [2.1.4: Post-Build](#subsec_postbuild)\n         - [2.1.5: GNU pth for user-space threading: DEPRECATED](#subsubsec_pth)\n         - [2.1.6: fcontext](#subsubsec_fcontext)\n         - [2.1.7: Known Issues](#subsec_build_issues)\n      - [Section 2.2: Building DUMPI](#sec_building_dumpi)\n         - [2.2.1: Known Issues](#subsubsec_building_dumpi_issues)\n      - [Section 2.3: Building Clang source-to-source support](#sec_buildingClang)\n         - [2.3.1: Building Clang libTooling](#subsec_buildingClanglibTooling)\n            - [The Easy Way: Mac OS X](#subsubsec_libToolingOSX)\n            - [The Hard Way](#subsubsec_libTooling)\n         - [2.3.2: Building SST/macro with Clang](#subsec_buildingWithClang)\n      - [Section 2.4: Building with OTF2](#sec_buildingOtf2)\n      - [Section 2.5: Running an Application](#sec_building_running)\n         - [2.5.1: SST Python Scripts](#subsec_SSTPythonScripts)\n         - [2.5.2: Building Skeleton Applications](#sec_tutorial_runapp)\n         - [2.5.3: Makefiles](#subsec_tutorial_makefiles)\n         - [2.5.4: Command-line arguments](#subsec_tutorial_cmdline)\n      - [Section 2.6: Parallel Simulations in Standalone Mode](#sec_PDES)\n         - [2.6.1: Distributed Memory Parallel](#subsec_mpiparallel)\n         - [2.6.2: Shared Memory Parallel](#subsec_parallelopt)\n         - [2.6.3: Warnings for Parallel Simulation](#subsec_parallelwarn)\n      - [Section 2.7: Debug Output](#sec_dbgoutput)\n   - [Chapter 3: Basic Tutorials](#chapter_tutorials)\n      - [Section 3.1: SST/macro Parameter files](#sec_parameters)\n         - [3.1.1: Parameter Namespace Rules](#subsec_parameterNamespace)\n         - [3.1.2: Initial Example](#subsec_initialExample)\n      - [Section 3.2: SST Python Files](#sec_pythonFiles)\n      - [Section 3.3: Network Topologies and Routing](#sec_tutorial_topology)\n         - [3.3.1: Topology](#subsec_tutorial_topology)\n         - [3.3.2: Routing](#subsec_tutorial_routing)\n      - [Section 3.4: Network Model](#sec_tutorial_networkmodel)\n         - [3.4.1: Analytic Models: MACRELS](#subsec_tutorial_macrels)\n         - [3.4.2: Packet Models: PISCES](#subsec_tutorial_pisces)\n            - [PISCES simple model](#subsubsec_tutorial_simplePisces)\n            - [PISCES cut-through model](#subsubsec_tutorial_cutThroughPisces)\n         - [3.4.3: SCULPIN](#subsec_sculpin)\n         - [3.4.4: SNAPPR](#subsec_snappr)\n         - [3.4.5: Flow](#subsec_tutorial_flow)\n      - [Section 3.5: Basic MPI Program](#sec_tutorial_basicmpi)\n      - [Section 3.6: Launching, Allocation, and Indexing](#sec_tutorial_launchetc)\n         - [3.6.1: Launch Commands](#subsec_tutorial_launch)\n         - [3.6.2: Allocation Schemes](#subsec_tutorial_allocation)\n            - [Indexing Schemes](#subsec_tutorial_indexing)\n      - [Section 3.7: Discrete Event Simulation](#sec_tutorial_des)\n      - [Section 3.8: Using DUMPI](#sec_tutorial_dumpi)\n         - [3.8.1: Building DUMPI](#subset_dump_build)\n         - [3.8.2: Trace Collection](#subsec_dumpi_tracecollection)\n         - [3.8.3: Trace Replay](#subsec_dumpi_tracereplay)\n      - [Section 3.9: Using Score-P and OTF2](#sec_tutorial_otf)\n         - [3.9.1: Trace Collection](#subsec_otf_traceCollection)\n         - [3.9.2: Trace Replay](#subsec_otf_traceReplay)\n      - [Section 3.10: Statistics](#sec_Statistics)\n         - [3.10.1: Collectors](#subsec_collectors)\n         - [3.10.2: Outputs](#subsec_outputs)\n         - [3.10.3: Groups](#subsec_groups)\n         - [3.10.4: SST/macro Standalone Input](#subsec_standaloneInput)\n         - [3.10.5: Custom Statistics](#subsec_customStats)\n      - [Section 3.11: OTF2 Trace Creation](#sec_otf_traceEmission)\n      - [Section 3.12: Call Graph Visualization](#sec_tutorials_callgraph)\n      - [Section 3.13: Spyplot Diagrams](#sec_tutorials_spyplot)\n      - [Section 3.14: Fixed-Time Quanta Charts](#sec_tutorials_ftq)\n      - [Section 3.15: Network Statistics](#sec_tutorials_packetStats)\n         - [3.15.1: XmitBytes](#subsec_xmitbytes)\n         - [3.15.2: XmitWait](#subsec_xmitwait)\n         - [3.15.3: XmitFlows](#subsec_xmitflows)\n   - [Chapter 4: Topologies](#chapter_topologies)\n      - [Section 4.1: Torus](#subsec_tutorial_hypercube)\n      - [Section 4.2: Hypercube](#subsec_tutorial_hypercube)\n         - [4.2.1: Allocation and indexing](#subsec_hypercube_allocation)\n         - [4.2.2: Routing](#subsec_hypercube_routing)\n      - [Section 4.3: Fat Tree](#sec_tutorial_fattree)\n         - [4.3.1: Switch Crossbar Bandwidth Scaling](#subsec_fattree_xbarbw)\n         - [4.3.2: Routing](#subsec_fattree_routing)\n      - [Section 4.4: Cascade](#sec_tutorial_cascade)\n         - [4.4.1: Allocation and indexing](#subsec_cascade_allocatoin)\n         - [4.4.2: Routing](#subsec_cascade_routing)\n   - [Chapter 5: External Applications and Skeletonization](#chap_appsAndSkeletonization)\n      - [Section 5.1: Basic Application porting](#sec_skel_basic)\n         - [5.1.1: Loading external skeletons with the standalone core](#subsec_externalAppStandalone)\n      - [Section 5.2: Auto-skeletonization with Clang](#sec_autoSkeletonization)\n         - [5.2.1: Redirecting Main](#subsec_redirectMain)\n         - [5.2.2: Memory Allocations](#subsec_memoryAllocations)\n         - [5.2.3: Computation](#subsec_computation)\n         - [5.2.4: Special Pragmas](#subsec_specialPragams)\n         - [5.2.5: Skeletonization Issues](#subsec_skeletonIssues)\n      - [Section 5.3: Process Encapsulation](#sec_processEncapsulation)\n   - [Chapter 6: Clang Source-to-Source Auto-Skeletonization via Pragmas](#clangTutorial)\n      - [Section 6.1: Pragma Overview](#sec_pragmaOverview)\n         - [6.1.1: Compiler workflow](#subsec_compilerWorkflow)\n         - [6.1.2: Compiler Environment Variables](#subsec_compilerEnv)\n            - [SSTMAC\\_SRC2SRC: Default 1](#subsubsec_env_src2src)\n            - [SSTMAC\\_SKELETONIZE: Default 0](#subsubsec_env_skeletonize)\n            - [SSTMAC\\_HEADERS: No default](#subsubsec_env_headers)\n            - [SSTMAC\\_DELETE\\_TEMP\\_SOURCES: Default 1](#subsubsec_env_delete_temp_objects)\n            - [SSTMAC\\_DELETE\\_TEMP\\_OBJECTS: Default 1](#subsubsec_env_delete_temp_sources)\n      - [Section 6.2: Basic Replacement Pragmas](#sec_basicReplacementPragmas)\n         - [6.2.1: pragma sst delete: no arguments](#subsec_pragma_sst_delete)\n         - [6.2.2: pragma sst replace [to\\_replace:string] [new\\_text:C++ expression]](#subsec_pragma_sst_replace)\n         - [6.2.3: pragma sst init [new\\_value:string]](#subsec_pragma_sst_init)\n         - [6.2.4: pragma sst return [new\\_value:C++ expression]](#subsec_pragma_sst_return)\n         - [6.2.5: pragma sst keep](#subsec_pragma_sst_keep)\n         - [6.2.6: pragma sst keep\\_if [condition:C++ bool expression]](#subsec_pragma_sst_keep_if)\n         - [6.2.7: pragma sst empty](#subsec_pragma_sst_empty)\n         - [6.2.8: pragma sst branch\\_predict [condition:C++ expression]](#subsec_pragma_sst_branch_predict)\n      - [Section 6.3: Memory Allocation Pragmas](#sec_memAllocPragmas)\n         - [6.3.1: pragma sst malloc](#subsec_pragma_sst_malloc)\n         - [6.3.2: pragma sst new](#subsec_pragma_sst_new)\n      - [Section 6.4: Data-Driven Type Pragmas](#ddtPragmas)\n         - [6.4.1: pragma sst null\\_ptr](#subsec_pragma_sst_null_ptr)\n         - [6.4.2: pragma sst null\\_type [type alias] [list allowed functions]](#subsec_pragma_sst_null_type)\n      - [Section 6.5: Compute Pragmas](#sec_computePragmas)\n         - [6.5.1: pragma sst compute and pragma omp parallel](#subsec_pragma_sst_compute)\n         - [6.5.2: pragma sst loop\\_count [integer: C++ expression]](#subsec_pragma_sst_loop_count)\n         - [6.5.3: pragma sst branch\\_predict [float: C++ expression]](#subsec_pragma_sst_branch_predict)\n         - [6.5.4: pragma sst advance\\_time [units] [time to advance by]](#subsec_pragma_sst_advance_time)\n   - [Chapter 7: Issues and Limitations](#ch_issues)\n      - [Section 7.1: Polling in applications](#sec_polling)\n      - [Section 7.2: Fortran](#subsec_issues_fortran)\n   - [Chapter 8: Detailed Parameter Listings](#chapter_parameters)\n      - [Section 8.1: Global namespace](#sec_globalParams)\n      - [Section 8.2: Namespace \"topology\"](#sec_topologyParams)\n      - [Section 8.3: Namespace \"node\"](#sec_nodeParams)\n         - [8.3.1: Namespace \"node.nic\"](#subsec_node_nic_Params)\n            - [Namespace \"node.nic.ejection\"](#subsubsec_node_nic_ejection_Params)\n            - [Namespace ``node.nic.injection\"](#subsubsec_node_nic_injection_Params)\n         - [8.3.2: Namespace ``node.memory\"](#subsec_node_memory_Params)\n         - [8.3.3: Namespace \"node.os\"](#subsec_node_os_Params)\n         - [8.3.4: Namespace ``node.proc\"](#subsec_node_proc_Params)\n      - [Section 8.4: Namespace \"mpi\"](#sec_mpi_Params)\n         - [8.4.1: Namespace ``mpi.queue\"](#subsec_mpi_queue_Params)\n      - [Section 8.5: Namespace \"switch\"](#subsec_switch_Params)\n         - [8.5.1: Namespace \"switch.router\"](#subsec_switch_router_Params)\n         - [8.5.2: Namespace \"switch.xbar\"](#subsec_switch_xbar_Params)\n         - [8.5.3: Namespace ``switch.link\"](#subsec_switch_link_Params)\n      - [Section 8.6: Namespace \"appN\"](#sec_appN_Params)\n\n\n\n## Chapter 1: Introduction<a name=\"sec_intro\"></a>\n\n\n\n### Section 1.1: Overview<a name=\"sec_intro_overview\"></a>\n\n\n\nThe SST-macro software package provides a simulator for large-scale parallel computer architectures. \nIt permits the coarse-grained study of distributed-memory applications. \nThe simulator is driven from either a trace file or skeleton application. \nThe simulator architecture is modular, allowing it to easily be extended with additional network models, \ntrace file formats, software services, and processor models.\n\nSimulation can be broadly categorized as either off-line or on-line.\nOff-line simulators typically first run a full parallel application on a real machine,\nrecording certain communication and computation events to a simulation trace.\nThis event trace can then be replayed post-mortem in the simulator.\nMost common are MPI traces which record all MPI events, and\nSST-macro provides the DUMPI utility ([3.8](#sec_tutorial_dumpi)) for collecting and replaying MPI traces. \nTrace extrapolation can extend the usefulness of off-line simulation by estimating large or untraceable system scales without having to collect a trace, but it is limited.\n\nWe turn to on-line simulation when the hardware or applications parameters need to change.\nOn-line simulators instead run real application code, allowing native C/C++ to be compiled directly into the simulator.\nSST-macro intercepts certain function calls, estimating how much time passes rather than actually executing the function.\nIn MPI programs, for example, calls to MPI\\_Send are linked to the simulator instead of passing to the real MPI library.\nIf desired, SST-macro can actually be a full MPI emulator, delivering messages between ranks and replicating the behavior of a full MPI implementation.\n\nAlthough SST-macro supports both on-line and off-line modes, on-line simulation is encouraged because\nevent traces are much less flexible, containing a fixed sequence of events.\nApplication inputs and number of nodes cannot be changed. \nWithout a flexible control flow, it also cannot simulate dynamic behavior like load balancing or faults.\nOn-line simulation can explore a much broader problem space since they evolve directly in the simulator.\n\nFor large, system-level experiments with thousands of network endpoints, high-accuracy cycle-accurate simulation is not possible,\nor at least not convenient.\nSimulation requires coarse-grained approximations to be practical.\nSST-macro is therefore designed for specific cost/accuracy tradeoffs.\nIt should still capture complex cause/effect behavior in applications and hardware, but be efficient enough to simulate at the system-level. \nFor speeding up simulator execution, we encourage skeletonization, discussed further in Chapter [5](#chap_appsAndSkeletonization). \nA high-quality skeleton is an application model that reproduces certain characteristics with only limited computation.  \nWe also encourage uncertainty quantification (UQ) for validating simulator results.\nSkeletonization and UQ are the two main elements in the \"canonical\" SST-macro workflow (Figure [1](#fig_workflow)).\n\n\n![Figure 1: SST/macro workflow.](https://github.com/sstsimulator/sst-macro/blob/devel/docs/manual/figures/workflow.png) \n\n*Figure 1: SST/macro workflow.*\n\n\n\nBecause of its popularity, MPI is one of our main priorities in providing programming model support.  \nSome MPI-3 functions and MPI one-sided functions are not implemented.\nThis will lead to compile errors with an obvious \"not implement\" compiler message.\n\n### Section 1.2: Preview of Things to Come<a name=\"sec_preview\"></a>\n\n\n\nSuppose you have the basic MPI application below that executes a simple send/recv operation.\nOne could use `mpicc` or `mpic++` to compile and run as an actual MPI program.\nThis requires spawning all the processes and running them in parallel.\nSuppose, however, you wanted to simulate an entire MPI job launch within a single simulator process.\nThis might prove very useful for debugging since you could just run GDB or Valgrind on a single process.\nIt might take a while, but for small runs (16 ranks or so) you could debug right on your laptop just as you do for a serial program.\n\n````\nint size = atoi(argv[1]);\nif (rank == 0){\n int partner = 1;\n  MPI_Send(buffer, size, MPI_INT, partner, tag, MPI_COMM_WORLD);\n} else {\n  int partner = 0;\n  MPI_Recv(buffer, size, MPI_INT, partner, tag, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n}\nMPI_Barrier(MPI_COMM_WORLD);\n\nif (rank == 0){\n  printf(\"Rank 0 finished at t=%8.4f ms\\n\", MPI_Wtime()*1e3);\n}\n````\n\nThis is exactly the functionality that SST/macro provides.\nInstead of using `mpic++`, you compile the code with `sst++`.\nThis modifies your code and intercepts MPI calls, running them through the simulator instead of an actual MPI implementation.\nYour code will execute and run exactly the same, and your application won't even know the difference.\nYou now need a parameter file with information like:\n\n````\nnode {\n app1 {\n  name = send_recv\n  launch_cmd = aprun -n 2\n  argv = 20\n }\n}\n````\nRather than launching your code using `mpirun` or similar, you put all your command line parameters into a `parameters.ini` file.\nThe simulator then executes your application exactly as if you had been a real system and run:\n\n````\nshell> aprun -n 2 ./send_recv 20\n````\nThings get more complicated when you bring skeletonization into play.\nThe use case above is emulation, exactly reproducing MPI functionality.\nIn skeletonization or simulation, SST/macro will mimic as closely as possible the original application,\nbut avoids as much computation and as much memory allocation as possible.\nThis allows packing in as many simulated (virtual) MPI ranks as possible into your single `sstmac` process.\n\n### Section 1.3: What To Expect In The User's Manual<a name=\"sec_whatToExpect\"></a>\n\n\n\nThis user's manual is mainly designed for those who wish to perform experiments with new applications using existing hardware models.\nThis has been the dominant use case and we therefore classify those doing application experiments as \"users\" and those making new hardware models \"developers.\"\nGetting applications to run in SST/macro should be very straightforward and requires no knowledge of simulator internal code.\nMaking new hardware models is much more in depth and requires learning some basics of core simulator code.\nThose interested in making new hardware models should consult the developer's manual in the top-level source directory.\n\n\n\n## Chapter 2: Building and Running SST/macro<a name=\"chapter_building\"></a>\n\n\n\n### Section 2.1: Build and Installation of SST-macro<a name=\"sec_buildinstall\"></a>\n\n\n\n\n#### 2.1.1: Downloading<a name=\"subsec_build_downloading\"></a>\n\n\n\nSST-macro is available at https://github.com/sstsimulator/sst-macro.\nYou can download the git repository directly:\n\n````\nshell> git clone https://github.com/sstsimulator/sst-macro.git\n````\nor for ssh\n\n````\nshell> git clone ssh://git@github.com/sstsimulator/sst-macro.git\n````\nor you can download a release tarball from https://github.com/sstsimulator/sst-macro/releases.\n\n#### 2.1.2: Dependencies<a name=\"subsec_build_dependencies\"></a>\n\n\nThe most critical change is that C++11 is now a strict prerequisite. \nWorkarounds had previously existed for older compilers. \nThese are no longer supported.\nThe following are dependencies for SST-macro.\n\n\n-   (optional) Git is needed in order to clone the source code repository, but you can also download a tar (Section [2.1.1](#subsec_build_downloading)).\n-   Autoconf: 2.68 or later\n-   Automake: 1.11.1 or later\n-   Libtool: 2.4 or later\n-   A C/C++ compiler is required with C++11 support.  gcc >=4.8.5 and clang >= 3.7 are known to work.\n-   (optional) OTF2: 2.0 or later for OTF2 trace replay.\n-   (optional) VTK 8.1 or later for creating Exodus files for traffic visualization\n-   (optional) Paraview 5.0 or greater for visualizing Exodus files\n-   (optional) Doxygen and Graphviz are needed to build the source code documentation.\n-   (optional) KCacheGrind or QCacheGrind to display call graphs\n-   (optional) Clang development libraries to enable SST source-to-source compiler\n\n#### 2.1.3: Configuration and Building<a name=\"subsec_build_configure\"></a>\n\n\n\nSST/macro is an SST element library, proving a set of simulation components that run on the main SST core.  \nThe SST core provides the parallel discrete event simulation manager that manages time synchronization and sending events in serial, MPI parallel, multi-threaded, or MPI + threaded mode.  \nThe core does not provide any simulation components like node models, interconnect models, MPI trace readers, etc.  \nThe actual simulation models are contained in the element library.  \n\nThe SST core is a standalone executable that dynamically loads shared object files containing the element libraries.  \nFor many element libraries, a Python input file is created that builds and connects the various simulation components.  \nFor maximum flexibility, this will become the preferred mode.  \nHowever, SST/macro has historically had a text-file input `parameters.ini` that configures the simulation.  \nTo preserve that mode for existing users, a wrapper Python script is provided that processes SST/macro input files.  \nSST/macro can also be compiled in standalone mode that uses its own simulation core.\n\nThe workflow for installing and running on the main SST core is:\n\n-   Build and install SST core\n-   Build and install the SST/macro element library `libmacro.so`\n-   Make sure paths are properly configured for `libmacro.so` to be visible to the SST core (`SST_LIB_PATH`)\n-   Run the `pysstmac` wrapper Python script that runs SST/macro-specific parameters OR\n-   Write a custom Python script\n\nThe workflow for installing and running on the standalone SST/macro core:\n\n-   Build and install SST/macro standalone to generate `sstmac` executable\n-   Run `sstmac` with `*.ini` parameter files\n\n##### Build SST core<a name=\"subsec_buildSSTCore\"></a>\n\n\nThe recommended mode for maximum flexibility is to run using the SST core downloadable from http://sst-simulator.org/SSTPages/SSTMainDownloads.\nBuilding and installing sets up the discrete event simulation core required for all SST elements.\n\n##### Build SST/macro element library<a name=\"subsec_buildElementLib\"></a>\n\n\nIf using the repo (not a release tarball), go to the top-level source directory and run:\n````\ntop-level-src> ./bootstrap.sh\n````\nThis sets up the configure script. For builds, we recommend building outside the source tree:\n\n````\nsst-macro> mkdir build\nsst-macro> cd build\nsst-macro/build> ../configure --prefix=$PATH_TO_INSTALL\n````\n\nIf wanting to use SST core instead of the macro standalone build, run:\n\n````\nsst-macro/build> ../configure --prefix=$PATH_TO_INSTALL --with-sst-core=$PATH_TO_SST_CORE CC=MPICC CXX=MPICXX\n````\n\n`PATH_TO_SST_CORE` should be the prefix install directory used when installing the core.  \nThe MPI compilers should be the same compilers used for building SST core.\n\nSST/macro can still be built in standalone mode for features that have not been fully migrated to the SST core. \nThis includes numerous statistics which are not yet supported by SST core.\nThe installation and running are the same for both modes - simply remove the `--with--sst-core` parameter.  \nA complete list of options for building can be seen by running `../configure --help`.   \nFor autoconf, options are generally divided into flags for 3rd party dependencies (`-with-X=`)\nand flags enabling or disabling features (`--enable-X`).\nSome common options are:\n\n\n-   --with-otf2[=location]: Enable OTF2 trace replay, requires a path to OTF2 installation.\n-   --with-clang[=location]: Enable Clang source-to-source tools by pointing to Clang development libraries\n-   --(dis|en)able-call-graph: Enables the collection of simulated call graphs, which can be viewed with KCacheGrind\n-   --(dis|en)able-multithread: Enables a multi-threaded backend\n\nOnce configuration has completed, printing a summary of the things it found, simply type `make`.  \n\n#### 2.1.4: Post-Build<a name=\"subsec_postbuild\"></a>\n\n\n\nIf the build did not succeed open an issue on the github page at https://github.com/sstsimulator/sst-macro/issues or contact SST-macro support for help (sst-macro-help@sandia.gov).\n\nIf the build was successful, it is recommended to run the range of tests to make sure nothing went wrong.  \nTo do this, and also install SST-macro  to the install path specified during installation, run the following commands:\n\n````\nsst-macro/build> make check\nsst-macro/build> make install\nsst-macro/build> make installcheck\n````\nMake check runs all the tests we use for development, which checks all functionality of the simulator.  \nMake installcheck compiles some of the skeletons that come with SST-macro, linking against the installation.  \n\n\nImportant:  Applications and other code linking to SST-macro use Makefiles that use the `sst++ or \\inlineshell{sstcc` compiler wrappers\nthat are installed there for convenience to figure out where headers and libraries are.  When making your skeletons and components, make sure your path is properly configured.\n}\n\n#### 2.1.5: GNU pth for user-space threading: DEPRECATED<a name=\"subsubsec_pth\"></a>\n\n\nBy default, Linux usually ships with `ucontext` which enables user-space threading.\nMac OS X previously required an extra library be installed (GNU pth).\nThese are no longer required and are deprecated in favor of fcontext,\nwhich is now integrated with the SST/macro distribution (see below).\n\nFor those still wishing to use pth, GNU pth is easy to download and install from source.\nEven easier is MacPorts. \n\n````\nshell> sudo port install pth\n````\n\nMacPorts installed all libraries to `/opt/local`. \nWhen configuring, simply add `--with-pth=\\$PATH_TO_PTH` as an argument.\nFor MacPorts installation, this means configuring SST/macro with:\n\n````\n../configure --with-pth=/opt/local\n````\n\n#### 2.1.6: fcontext<a name=\"subsubsec_fcontext\"></a>\n\n\nThe fcontext library for user-space threading is now integrated directly with the SST/macro distribution.\nThis provides much greater performance than GNU pth or standard Linux ucontext.\nUsers may see as much as a 20\\\nfcontext is be activated by default. \n\n\n#### 2.1.7: Known Issues<a name=\"subsec_build_issues\"></a>\n\n\n\n\n\n-   Any build or runtime problems should be reported to sst-macro-help@sandia.gov.  We try to respond as quickly as possible.\n-   make -j: When doing a parallel compile dependency problems can occur.  \nThere are a lot of inter-related libraries and files.  \nSometimes the Makefile dependency tracker gets ahead of itself and you will get errors about missing libraries and header files.\nIf this occurs, restart the compilation.  If the error vanishes, it was a parallel dependency problem.\nIf the error persists, then it's a real bug.\n-   Ubuntu: The Ubuntu linker performs too much optimization on dynamically linked executables.\nSome call it a feature.  I call it a bug.\nIn the process it throws away symbols it actually needs later. The build system should automatically fix Ubuntu flags.\nIf still having issues, make sure that '-Wl,--no-as-needed' is given in LDFLAGS.\n\nThe problem occurs when the executable depends on libA which depends on libB.\nThe executable has no direct dependence on any symbols in libB.\nEven if you add `-lB` to the `LDFLAGS` or `LDADD` variables,\nthe linker ignores them and throws the library out.\nIt takes a dirty hack to force the linkage.\nIf there are issues, contact the developers at sst-macro-help@sandia.gov and report the problem.\n\n### Section 2.2: Building DUMPI<a name=\"sec_building_dumpi\"></a>\n\n\n\nBy default, DUMPI is configured and built along with SST/macro with support for reading and parsing DUMPI traces, known as libundumpi.  \nDUMPI binaries and libraries are also installed along with everything for SST-macro during make install.   \nDUMPI can be used as its own library within the SST-macro source tree by changing to `sst-macro/sst-dumpi`, \nwhere you can change its configuration options.  \n\nDUMPI can also be used as stand-alone tool (\\eg~for simplicity if you're only tracing). \nTo get DUMPI by itself, either copy the `sstmacro/dumpi` directory somewhere else or visit https://github.com/sstsimulator/sst-dumpi and follow similar instructions for obtaining SST-macro.\n\nTo see a list of configuration options for DUMPI, run `./configure --help`.  \nIf you're trying to configure DUMPI for trace collection, use `--enable-libdumpi`.\nYour build process might look like this (if you're building in a separate directory from the dumpi source tree) :\n\n````\nsst-dumpi/build> ../configure --prefix=/path-to-install --enable-libdumpi\nsst-dumpi/build> make\nsst-dumpi/build> sudo make install\n````\n\n#### 2.2.1: Known Issues<a name=\"subsubsec_building_dumpi_issues\"></a>\n\n\n\n\n-   When compiling on platforms with compiler/linker wrappers, e.g. ftn (Fortran) and CC (C++) compilers \nat NERSC, the libtool configuration can get corrupted.  The linker flags automatically added by the \nwrapper produce bad values for the predeps/postdeps variable in the libtool script in the top \nlevel source folder.  When this occurs, the (unfortunately) easiest way to fix this is to manually modify\nthe libtool script.  Search for predeps/postdeps and set the values to empty.\nThis will clear all the erroneous linker flags.  The compilation/linkage should still work since \nall necessary flags are set by the wrappers.\n\n\n### Section 2.3: Building Clang source-to-source support<a name=\"sec_buildingClang\"></a>\n\n\n\nTo enable Clang source-to-source support it is not sufficient to have a Clang compiler.  You have to install a special libTooling library for Clang.\n\n#### 2.3.1: Building Clang libTooling<a name=\"subsec_buildingClanglibTooling\"></a>\n\n\n\n##### The Easy Way: Mac OS X<a name=\"subsubsec_libToolingOSX\"></a>\n\n\nUsing MacPorts on OS X, it is trivial to obtain a Clang installation that includes libTooling:\n\n````\nport install clang-devel\n````\n\nMacPorts will place the Clang compilers in `/opt/local/bin`.  Enable the devel version of Clang with:\n\n````\nport select --set clang mp-clang-devel\n````\n\nThe Clang libraries will be placed into `/opt/local/libexec/llvm-devel/lib`, so the appropriate option to the sst-macro configure script is `--with-clang=/opt/local/libexec/llvm-devel`.\n\n##### The Hard Way<a name=\"subsubsec_libTooling\"></a>\n\n\nFor operating systems other than OS X, building Clang support has a few steps (and takes quite a while to build), but is straightforward.\nInstead of having an all-in-one tarball, you will have to download several different components. You can install more if you want build libc++, but these are not required.\nObtain the following from http://releases.llvm.org/download.html.\n\n\n-   LLVM source code\n-   Clang source code\n-   libc++ source code\n-   libc++abi source code\n-   compiler-rt source code\n-   (optional, not recommended) OpenMP source code\n\nSetting up the folders can be done automatically using the `setup-clang` script in `bin/tools` folder in sst-macro. Put all of downloaded tarballs in a folder, e.g. `clang-llvm`. Then run `setup-clang` in the directory. \nIt will automatically place files where LLVM needs them.\nLLVM is the \"driver\" for the entire build. Everything else is a subcomponent. \nThe setup script places each tarball in the following subfolders of the main LLVM folder\n\n\n-   tools/clang\n-   projects/compiler-rt\n-   projects/libcxx\n-   projects/libcxxabi\n-   projects/openmp\n\nUsing CMake (assuming you are in a build subdirectory of the LLVM tree), you would run the script below to configure.\nYou no longer need to use Clang to build Clang. \nFor the most stable results, though, you should a pre-existing Clang compiler to build the Clang development libraries.\n\n````\ncmake ../llvm \\\n  -DCMAKE_CXX_COMPILER=clang++ \\\n  -DCMAKE_C_COMPILER=clang \\\n  -DCMAKE_CXX_FLAGS=\"-O3\" \\\n  -DCMAKE_C_FLAGS=\"-O3\" \\\n  -DCMAKE_INSTALL_PREFIX=$install\n````\n\nTo build a complete LLVM/Clang run:\n\n````\ncmake ../llvm \\\n  -DCMAKE_CXX_COMPILER=clang++ \\\n  -DCMAKE_C_COMPILER=clang \\\n  -DCMAKE_CXX_FLAGS=\"-O3\" \\\n  -DCMAKE_C_FLAGS=\"-O3\" \\\n  -DLLVM_ENABLE_LIBCXX=ON \\\n  -DLLVM_TOOL_COMPILER_RT_BUILD=ON \\\n  -DLLVM_TOOL_LIBCXXABI_BUILD=ON \\\n  -DLLVM_TOOL_LIBCXX_BUILD=ON \\\n  -DCMAKE_INSTALL_PREFIX=$install\n````\n\nOn some systems, linking Clang might blow out your memory. If that is the case, you have to set `LD=ld.gold` for the linker.\nRun `make install`. The libTooling library will now be available at the `\\$install` location.\n\nAny compiler used for SST (g++, icpc, clang++) can generally be mixed with most versions of the libtooling source-to-source library.\nNOTE: The same compiler used to build SST must have been used to build the libtooling library.\nHowever, the table below contains versions that are recommended or approved and which combinations are untested (but may work).\n\n\n| Compiler to build SST | Libtooling version |\n|-----------------------|--------------------|\n| Clang 4,5,6 | 4,5,6 |\n| Clang 7,8 | 7,8 |\n| GCC 4.8-6 | 4-7 |\n| GCC 7- | ? |\n| ? | 8 |\n\n#### 2.3.2: Building SST/macro with Clang<a name=\"subsec_buildingWithClang\"></a>\n\n\n\nNow that clang is installed, you only need to add the configure flag `--with-clang` pointing it to the install location from above.\nYou must use the same Clang compiler to build SST that you used to build libTooling.\n\n````\n../configure CXX=clang++ CC=clang --with-clang=$install\n````\n\nClang source-to-source support will now be built into the `sst++` compiler. \nIf Clang development libraries are available in the default system path (as is often the case with LLVM models, e..g `module load llvm`),\nthen you can just put `--with-clang`.\n\n### Section 2.4: Building with OTF2<a name=\"sec_buildingOtf2\"></a>\n\n\nOTF2 is a general purpose trace format with specialized callbacks for the MPI API. OTF2 traces are generated by programs compiled with Score-P compiler wrappers. SST/macro 8.1 supports OTF2 trace replay and OTF2 trace generation when configured with \n\n````\n./configure --with-otf2=<OTF2-root>\n````\nwhere the OTF2 root is the installation prefix for a valid OTF2 build. OTF2 can be obtained from the Score-P project at {http://www.vi-hps.org/projects/score-p}.\nDetailed build and usage instructions can be found on the website.\n\n\n\n\n### Section 2.5: Running an Application<a name=\"sec_building_running\"></a>\n\n\n#### 2.5.1: SST Python Scripts<a name=\"subsec_SSTPythonScripts\"></a>\n\n\n\nFull details on building SST Python scripts can be found at http://sst-simulator.org.  To preserve the old parameter format in the near-term, SST/macro provides the `pysstmac` script:\n\n````\nexport SST_LIB_PATH=$SST_LIB_PATH:$SSTMAC_PREFIX/lib\n\noptions=\"$@\"\n$SST_PREFIX/bin/sst$SSTMAC_PREFIX/include/python/default.py --model-options=\"$options\"\n````\n\nThe script configures the necessary paths and then launches with a Python script `default.py`.  Interested users can look at the details of the Python file to understand how SST/macro converts parameter files into a Python config graph compatible with SST core.\nAssuming the path is configured properly, users can run\n\n````\nshell>pysstmac -f parameters.ini\n````\nwith a properly formatted parameter file. If running in standalone mode, the command would be similar (but different).\n\n````\nshell>sstmac -f parameters.ini\n````\nsince there is no Python setup involved.\n\n\n#### 2.5.2: Building Skeleton Applications<a name=\"sec_tutorial_runapp\"></a>\n\n\n\nTo demonstrate how an external skeleton application is run in SST-macro, we'll use a very simple send-recv program located in `skeletons/sendrecv`.\nWe will take a closer look at the actual code in Section [3.5](#sec_tutorial_basicmpi).\nAfter SST-macro has been installed and your PATH variable set correctly, for standalone core users can run:\n\n````\nsst-macro> cd skeletons/sendrecv\nsst-macro/skeletons/sendrecv> make\nsst-macro/skeleton/sendrecv> sstmac -f parameters.ini --exe=./runsstmac\n````\n\nYou should see some output that tells you 1) the estimated total (simulated) runtime of the simulation, and \n2) the wall-time that it took for the simulation to run.  \nBoth of these numbers should be small since it's a trivial program. \nThis is how simulations generally work in SST-macro: you build skeleton code and link it with the simulator to produce an importable library.  \nThe importable library contains hooks for loading a skeleton app into the simulator.\nNOTE: `runsstmac` appears to be an executable, but is actually built as a shared library. \nIf using a regular compiler (e.g. gcc), the Makefile would produce an executable `runsstmac`.\nTo ensure that building apps for SST require no modification to an existing build system,\nSST simple builds a shared library `runsstmac` rather than requiring renaming to the standard convention\n`librunsstmac.so`.\n\n#### 2.5.3: Makefiles<a name=\"subsec_tutorial_makefiles\"></a>\n\n\nWe recommend structuring the Makefile for your project like the one seen in `skeletons/sendrecv/Makefile` :\n\n````\nTARGET := runsstmac\nSRC := $(shell ls *.c) \n\nCXX :=      $(PATH_TO_SST)/bin/sst++\nCC :=        $(PATH_TO_SST)/bin/sstcc\nCXXFLAGS := ...\nCPPFLAGS := ...\nLIBDIR :=  ...\nPREFIX :=   ...\nLDFLAGS :=  -Wl,-rpath,$(PREFIX)/lib\n...\n````\nThe SST compiler wrappers `sst++` and `sstcc` automagically configure and map the code for simulation. \n\n#### 2.5.4: Command-line arguments<a name=\"subsec_tutorial_cmdline\"></a>\n\n\n\nThere are few common command-line arguments with SST-macro, listed below\n\n\n-   -h/--help: Print some typical help info\n-   -f [parameter file]: The parameter file to use for the simulation.  \nThis can be relative to the current directory, an absolute path, or the name of a pre-set file that is in sstmacro/configurations \n(which installs to /path-to-install/include/configurations, and gets searched along with current directory).\n-   --dumpi: If you are in a folder with all the DUMPI traces, you can invoke the main `sstmac` executable with this option.  This replays the trace in a special debug mode for quickly validating the correctness of a trace.\n-   --otf2: If you are in a folder with all the OTF2 traces, you can invoke the main `sstmac` executable with this option.  This replays the trace in a special debug mode for quickly validating the correctness of a trace.\n-   -d [debug flags]: A list of debug flags to activate as a comma-separated list (no spaces) - see Section [2.7](#sec_dbgoutput)\n-   -p [parameter]=[value]: Setting a parameter value (overrides what is in the parameter file)\n-   -c: If multithreaded, give a comma-separated list (no spaces) of the core affinities to use - see Section [2.6.2](#subsec_parallelopt)\n\n### Section 2.6: Parallel Simulations in Standalone Mode<a name=\"sec_PDES\"></a>\n\n\n\nSST-macro supports running parallel discrete event simulation (PDES) in distributed memory (MPI), threaded shared memory (pthreads) and hybrid (MPI+pthreads) modes.  Running these in standalone mode will be discouraged as parallel simulations should use the unified SST core. However, near-term, hybrid modes and other optimizations are not fully supported in the unified SST core. The standalone core may still be required for certain cases.\n\n#### 2.6.1: Distributed Memory Parallel<a name=\"subsec_mpiparallel\"></a>\n\n\nConfigure will automatically check for MPI.\nYour configure should look something like:\n\n````\nsst-macro/build> ../configure CXX=mpicxx CC=mpicc ...\n````\nWith the above options, you can just compile and go.\nSST-macro is run exactly like the serial version, but is spawned like any other MPI parallel program.\nUse your favorite MPI launcher to run, e.g. for OpenMPI\n\n````\nmysim> mpirun -n 4 sstmac -f parameters.ini\n````\nor for MPICH\n\n````\nmysim> mpiexec -n 4 sstmac -f parameters.ini\n````\n\nEven if you compile for MPI parallelism, the code can still be run in serial with the same configuration options.\nSST-macro will notice the total number of ranks is 1 and ignore any parallel options.\nWhen launched with multiple MPI ranks, SST-macro will automatically figure out how many partitions (MPI processes) \nyou are using, partition the network topology into contiguous blocks, and start running in parallel.   \n\n#### 2.6.2: Shared Memory Parallel<a name=\"subsec_parallelopt\"></a>\n\n\nIn order to run shared memory parallel, you must configure the simulator with the `--enable-multithread` flag.\nPartitioning for threads is currently always done using block partitioning and there is no need to set an input parameter.\nIncluding the integer parameter `sst_nthread` specifies the number of threads to be used (per rank in MPI+pthreads mode) in the simulation.\nThe following configuration options may provide better threaded performance.\n\n-   `--enable-spinlock` replaces pthread mutexes with spinlocks.  Higher performance and recommended when supported.\n-   `--enable-cpu-affinity` causes SST-macro to pin threads to specific cpu cores.  When enabled, SST-macro will require the\n`cpu_affinity` parameter, which is a comma separated list of cpu affinities for each MPI task on a node.  SST-macro will sequentially\npin each thread spawned by a task to the next next higher core number.  For example, with two MPI tasks per node and four threads per MPI task,\n`cpu_affinity = 0,4` will result in MPI tasks pinned to cores 0 and 4, with pthreads pinned to cores 1-3 and 5-7.\nFor a threaded only simulation `cpu_affinity = 4` would pin the main process to core 4 and any threads to cores 5 and up.\nThe affinities can also be specified on the command line using the `-c` option.\nJob launchers may in some cases provide duplicate functionality and either method can be used.\n\n#### 2.6.3: Warnings for Parallel Simulation<a name=\"subsec_parallelwarn\"></a>\n\n\n\n-   If the number of simulated processes specified by e.g. `aprun -n 100` does not match the number of nodes in the topology (i.e. you are not space-filling the whole simulated machine), parallel performance will suffer. SST-macro partitions nodes, not MPI ranks.\n\n\nParallel simulation speedups are likely to be modest for small runs.\nSpeeds are best with serious congestion or heavy interconnect traffic.\nWeak scaling is usually achievable with 100-500 simulated MPI ranks per logical process.\nEven without speedup, parallel simulation can certainly be useful in overcoming memory constraints.\n\n\n### Section 2.7: Debug Output<a name=\"sec_dbgoutput\"></a>\n\n\nSST-macro defines a set of debug flags that can be specified in the parameter file to control debug output printed by the simulator.\nTo list the set of all valid flags with documentation, the user can run\n\n````\nbin> ./sstmac --debug-flags\n````\n\nwhich will output something like\n\n````\nmpi\n        print all the basic operations that occur on each rank - only API calls are\n        logged, not any implementation details\n    router\n        print all operations occurring in the router\n     ....\n````\n\n\nTo turn on debug output, add the following to the input file\n\n````\ndebug = mpi\n````\nlisting all flags you want separated by spaces.\n\n\n\n\n## Chapter 3: Basic Tutorials<a name=\"chapter_tutorials\"></a>\n\n\n\n\n\n### Section 3.1: SST/macro Parameter files<a name=\"sec_parameters\"></a>\n\n\n\nThere are parameter files for the main network models (MACRELS, PISCES, SCULPIN, SNAPPR) in the top-level examples directory.\nA minimal parameter file setting up a 2D-torus topology is shown below. \nAn equivalent Python input file that reads an ini file is also shown.\nA detailed listing of parameter namespaces and keywords is given in Section [8](#chapter_parameters).\nBoth the `ini` files and Python files make careful use of namespaces.\n\n````\namm_model = amm1\ncongestion_model = LogP\nnode {\n #run a single mpi test\n app1 {\n  indexing = block\n  allocation = first_available\n  launch_cmd = aprun -n8 -N1\n  name = sstmac_mpi_testall\n  argv =\n  sendrecvMessage_size = 128\n }\n ncores = 1\n memory {\n  model = simple\n  bandwidth = 1GB/s\n  latency = 10ns\n }\n proc {\n  frequency = 1GHz\n }\n nic {\n  injection {\n   bandwidth = 1GB/s\n   latency = 1us\n  }\n  model = simple\n }\n}\nswitch {\n link {\n  bandwidth = 1.0GB/s\n   latency = 100ns\n }\n logp {\n   bandwidth = 1GB/s\n   out_in_latency = 1us\n }\n}\n\ntopology {\n name = torus\n geometry = 4,4\n}\n````\nThe input file follows a basic syntax of `parameter = value`.\nParameter names follow C++ variable rules (letters, numbers, underscore) while parameter values can contain spaces.  Trailing and leading whitespaces are stripped from parameters.\nComments can be included on lines starting with \\#.\n\n#### 3.1.1: Parameter Namespace Rules<a name=\"subsec_parameterNamespace\"></a>\n\n\nPeriods denote nesting of parameter namespaces.\nThe parameter `node.memory.model` will be nested in namespace `memory` inside namespace `node`.\nIf inside a given namespace, SST-macro looks only within that namespace.\n\nThe preferred syntax more closely resembles C++ namespace declarations. \nNamespaces are scoped using brackets \\{\\}:\n\n````\nnode {\n model = simple\n memory {\n   model = simple\n   bandwidth = 1GB/s\n   latency = 10ns\n }\n}\n````\nAny line containing a single string with an opening \\{ starts a new namespace.\nA line containing only a closing \\} ends the innermost namespace.\nThe syntax is not as flexible as C++ since the opening \\{ must appear on the same line as the namespace and the closing \\} must be on a line of its own.\nA detailed listing of parameter namespaces and keywords is given in Section [8](#chapter_parameters).\n\n#### 3.1.2: Initial Example<a name=\"subsec_initialExample\"></a>\n\n\nContinuing with the example above, we see the input file is broken into namespace sections. \nFirst, application launch parameters for each node must be chosen determining what application will launch, \nhow nodes will be allocated, how ranks will be indexed, and finally what application will be run.\nAdditionally, you must specify how many processes to launch and how many to spawn per node.\nWe currently recommend using aprun syntax (the launcher for Cray machines),\nalthough support is being added for other process management systems.\nSST-macro can simulate command line parameters by giving a value for `node.app1.argv`.\n\nA network must also be chosen.\nIn the simplest possible case, the network is modeled via a simple latency/bandwidth formula.\nFor more complicated network models, many more than two parameters will be required.\nSee [3.4](#sec_tutorial_networkmodel) for a brief explanation of SST-macro network congestion models.\nA topology is also needed for constructing the network.\nIn this case we choose a 2-D 4X4 torus (16 switches).  The `topology.geometry`\nparameter takes an arbitrarily long list of numbers as the dimensions to the torus.\n\nFinally, we must construct a node model.\nIn this case, again, we use the simplest possible models for the node,\nnetwork interface controller (NIC), and memory.\n\nParameter files can be constructed in a more modular way through the `include` statement.\nAn alternative parameter file would be:\n\n````\ninclude machine.ini\n# Launch parameters\nnode {\n app1 {\n  indexing = block\n  allocation = first_available\n  launch_cmd = aprun -n2 -N1\n  name = user_mpiapp_cxx\n  argv = \n  # Application parameters\n  sendrecvMessage_size = 128\n }\n}\n````\nwhere in the first line we include the file `machine.ini`.\nAll network, topology, and node parameters would be placed into a `machine.ini` file.\nIn this way, multiple experiments can be linked to a common machine.\nAlternatively, multiple machines could be linked to the same application by creating and including an `application.ini`.\n\n\n\n### Section 3.2: SST Python Files<a name=\"sec_pythonFiles\"></a>\n\n\nFor SST core, SST/macro provides a Python translator for the ini files to a Python input deck.\nFor those wishing to directly use Python inputs (or understand better SST core files),\nan example Python file is included here to illustrate using Macro.\nAdditionally, you can look at `sstmac/sst_core/sstmacro.py` to see more details of building and linking SST components.\n\nSST/macro provides a particular idiom for setting up systems.\nRather than directly instantiate components, `sstmacro.py` provides an interconnect object.\nParameter namespaces are created through nested dictionaries.\nOne all parameters are created in the dictionaries, all the components are build and run through the `ic.build()` command.\n\n````\nimport sst\nimport sst.macro\nfrom sst.macro import Interconnect\n\nlink_bw=\"12.5GB/s\"\nlink_lat=\"100ns\"\nlogpParams = {\n  \"bandwidth\" : \"12.5GB/s\",\n  \"hop_latency\" : \"100ns\",\n  \"out_in_latency\" : \"1.2us\",\n}\n\nswParams = {\n  \"name\" : \"pisces\",\n  \"mtu\" : \"4KB\",\n  \"arbitrator\" : \"cut_through\",\n  \"router\" : {\n    \"name\"     :     \"torus_minimal\",\n  },\n  \"link\" : {\n    \"bandwidth\" : link_bw,\n    \"latency\" : link_lat,\n    \"credits\" : \"128KB\",\n  },\n  \"xbar\" : {\n    \"bandwidth\" : \"1000GB/s\",\n    \"latency\" : \"10ns\",\n  },\n  \"logp\" : logpParams,\n}\n\nmpiParams = {\n \"max_vshort_msg_size\" : 4096,\n \"max_eager_msg_size\" : 64000,\n \"post_header_delay\" : \"0.35906660us\",\n \"post_rdma_delay\" : \"0.88178612us\",\n \"rdma_pin_latency\" : \"5.42639881us\",\n \"rdma_page_delay\" : \"50.50000000ns\",\n}\n\nappParams = {\n  \"allocation\" : \"hostname\",\n  \"indexing\" : \"hostname\",\n  \"exe\" : \"halo3d-26\",\n  \"argv\" : \"-pex 4 -pey 4 -pez 4 -nx 128 -ny 128 -nz 128 -sleep 0 -iterations 10\",\n  \"launch_cmd\" : \"aprun -n 64 -N 1\",\n  \"allocation\" : \"first_available\",\n  \"indexing\" : \"block\",\n  \"mpi\" : mpiParams,\n}\n\nmemParams = {\n \"name\" : \"pisces\",\n \"latency\" : \"10ns\",\n \"total_bandwidth\" : \"100GB/s\",\n \"max_single_bandwidth\" : \"11.20GB/s\",\n}\n\nnicParams = {\n  \"name\" : \"pisces\",\n  \"injection\" : {\n    \"mtu\" : \"4KB\",\n    \"redundant\" : 8,\n    \"bandwidth\" : \"13.04GB/s\",\n    \"arbitrator\" : \"cut_through\",\n    \"latency\" : \"0.6us\",\n    \"credits\" : \"128KB\",\n  },\n  \"ejection\" : {\n    \"latency\" : link_lat,\n  },  \n}\n\nnodeParams = {\n  \"memory\" : memParams,\n  \"nic\" : nicParams,\n  \"app1\" : appParams,\n  \"name\" : \"simple\",\n  \"proc\" : {\n    \"frequency\" : \"2GHz\",\n    \"ncores\" : \"4\",\n  }\n}\n\ntopoParams = {\n \"name\" : \"torus,\n \"geometry\" : \"[4,4,4]\",\n}\n\nparams = {\n  \"node\" : nodeParams,\n  \"switch\" : swParams,\n  \"topology\" : topoParams,\n}\n\nic = Interconnect(params)\nic.build()\n````\n\nAgain, to see all the details of creating and linking components, refer to the `sstmac/sst_core/sstmacro.py` file.\n\n\n\n\n\n\n\n\n### Section 3.3: Network Topologies and Routing<a name=\"sec_tutorial_topology\"></a>\n\n\nWe here give a brief introduction to specifying different topologies and routing strategies.\nWe will only discuss one basic example (torus).\nA more thorough introduction covering all topologies is planned for future releases.\nExcellent resources are \"Principles and Practices of Interconnection Networks\" by Brian Towles and William Dally published by Morgan Kaufman and \"High Performance Datacenter Networks\" by Dennis Abts and John Kim published by Morgan and Claypool.\n\n#### 3.3.1: Topology<a name=\"subsec_tutorial_topology\"></a>\n\n\n\nTopologies are determined by two mandatory parameters.\n\n````\ntopology.name = torus\ntopology.geometry = 4 4\n````\nHere we choose a 2D-torus topology with extent 4 in both the X and Y dimensions for a total of 16 nodes (Figure [2](#fig_torus_basic))\nThe topology is laid out in a regular grid with network links connecting nearest neighbors.\nAdditionally, wrap-around links connect the nodes on each boundary.\n\n![Figure 2: 4 x 4 2D Torus](https://github.com/sstsimulator/sst-macro/blob/devel/docs/manual/figures/tikz/torus/torus.png) \n\n*Figure 2: 4 x 4 2D Torus*\n\n\n\n\nThe figure is actually an oversimplification.\nThe `topology.geometry` parameter actually specifies the topology of the network switches, not the compute nodes. \nA torus is an example of a direct network in which each switch has one or more nodes \"directly\" connected to it.\nA more accurate picture of the network is given in Figure [3](#fig_torus_withnodes).\n\n![Figure 3: 4 x 4 2D Torus of Network Switches with Compute Nodes](https://github.com/sstsimulator/sst-macro/blob/devel/docs/manual/figures/tikz/torus/withnodes.png) \n\n*Figure 3: 4 x 4 2D Torus of Network Switches with Compute Nodes*\n\n\nWhile in many previous architectures there was generally a one-to-one correspondence between compute nodes and switches, more recent architectures have multiple compute nodes per switch (e.g. Cray Gemini with two nodes, Cray Aries with four nodes).\nMultiple nodes per switch can be specified via a concentration parameter:\n\n````\ntopology {\n name = torus\n geometry = 4 4\n concentration = 2\n}\n````\nwhich would now generate a torus topology with 16 switches and 32 compute nodes.\n\nAnother subtle modification of torus (and other networks) can be controlled by giving the X, Y, and Z directions different bandwidth.\nThe above network could be modified as\n\n````\ntopology {\n name = torus\n geometry = 4 4\n redundant = 2 1\n}\n````\ngiving the the X-dimension twice the bandwidth of the Y-dimension.\nThis pattern DOES exist in some interconnects as a load-balancing strategy.\nA very subtle point arises here. Consider two different networks:\n\n````\ntopology {\n name = torus\n geometry = 4 4\n redundant = 1 1\n}\nswitch.link.bandwidth = 2GB/s\n````\n````\ntopology {\n name = torus\n geometry = 4 4\n redundant = 2 2\n}\nswitch.link.bandwidth = 1GB/s\n````\nFor some coarse-grained models, these two networks are exactly equivalent.\nIn more fine-grained models, however, these are actually two different networks.\nThe first network has ONE link carrying 2 GB/s. The second network has TWO links each carrying 1 GB/s.\n\n#### 3.3.2: Routing<a name=\"subsec_tutorial_routing\"></a>\n\n\nBy default, SST-macro uses the simplest possible routing algorithm: dimension-order minimal routing (Figure [4](#fig_torus_basicrouting)).\n\n![Figure 4: Dimension-Order Minimal Routing on a 2D Torus](https://github.com/sstsimulator/sst-macro/blob/devel/docs/manual/figures/tikz/torus/minroutetorus.png) \n\n*Figure 4: Dimension-Order Minimal Routing on a 2D Torus*\n\n\nIn going from source to destination, the message first travels along the X-dimension and then travels along the Y-dimension.\nThe above scheme is entirely static, making no adjustments to avoid congestion in the network.\nSST-macro supports a variety of adaptive routing algorithms.  This can be specified:\n\n````\nswitch {\n router {\n  name = min_ad\n }\n}\n````\nwhich specifies minimal adaptive routing. \nThere are now multiple valid paths between network endpoints, one of which is illustrated in Figure [5](#fig_torus_minadrouting).\n\n![Figure 5: Adaptive Minimal Routing on a 2D Torus](https://github.com/sstsimulator/sst-macro/blob/devel/docs/manual/figures/tikz/torus/minadroutetorus.png) \n\n*Figure 5: Adaptive Minimal Routing on a 2D Torus*\n\n\nAt each network hop, the router chooses the productive path with least congestion.\nIn some cases, however, there is only one minimal path (node (0,0) sending to (2,0) with only X different).\nFor these messages, minimal adaptive is exactly equivalent to dimension-order routing.\nOther supported routing schemes are valiant and UGAL.  More routing schemes are scheduled to be added in future versions.  \nA full description of more complicated routing schemes will be given in its own chapter in future versions. \nFor now, we direct users to existing resources such as \"High Performance Datacenter Networks\" by Dennis Abts and John Kim.\n\n\n\n### Section 3.4: Network Model<a name=\"sec_tutorial_networkmodel\"></a>\n\n\n\nNetwork models can be divided into several categories.  SST/macro supports analytic models, which estimate network delays via basic latency/bandwidth formulas, and packet models, which model step-by-step the transit of individuals through the interconnect.\nA third class of models (flow models), was previously supported but are now discontinued due to the much better scalability of packet models.\n\n#### 3.4.1: Analytic Models: MACRELS<a name=\"subsec_tutorial_macrels\"></a>\n\n\n\nThe analytic models in SST/macro are colloqiually referred to as MACRELS (MTL for AnalytiC REally Lightweight Simulation).\nAn example file running a simple application can be found in the top-level examples folder.\nThe MTL (message transfer layer) moves entire network flows from point-to-point without packetizing them into smaller chunks.\nThus an entire 1 MB MPI message is transported as a single chunk of data.\nThe majority of MACRELS models are based on the LogP set of approximations:\n\n\n&Delta; t = &alpha; + &beta; N\n\nwhere &Delta; t is the time delay, &alpha; is the minimum latency of the communication, &beta; is the inverse bandwidth (s/B), and N is the number of bytes.\nIn abstract machine models, these methods are selected as:\n\n````\ncongestion_model = logP\n````\nDetails are shown for traffic moving from source to destination in Figure [6](#fig_macrelsOverview).\nModeling occurs on entire flows, rather than individual packets. \n\n\n-   Flows queue waiting for NIC injection link to become available. Flow is forwarded to destination NIC based after computed delay.\n-   Flows queue waiting for NIC ejection link to become available. Flow finishes after ejection link becomes available.\n\n\n![Figure 6: MACRELS (Messages with AnalytiC REally Lightweight Simulation) skips congestion modeling and approximates send delays using a simple latency/bandwidth estimate, similar to the LogGOP model. Modeling occurs on entire flows, rather than individual packets. For details on numbered steps, see text.](https://github.com/sstsimulator/sst-macro/blob/devel/docs/manual/figures/macrels.png) \n\n*Figure 6: MACRELS (Messages with AnalytiC REally Lightweight Simulation) skips congestion modeling and approximates send delays using a simple latency/bandwidth estimate, similar to the LogGOP model. Modeling occurs on entire flows, rather than individual packets. For details on numbered steps, see text.*\n\n\n\n\n#### 3.4.2: Packet Models: PISCES<a name=\"subsec_tutorial_pisces\"></a>\n\n\n\nPISCES (Packet-flow Interconnect Simulation for Congestion at Extreme Scale) breaks network flows (MPI messages) into individual packets and models each packet individually.\nAn example file running a simple application can be found in the top-level examples folder.\nIn reality, packets are further subdivided into flits (flow-control units).\nFlit-level detail would be way too computationally intense for large-scale simulation.\nAll routing decisions are made on packets as a while. \nTwo flits in the same packet cannot take different paths through the network.\nHowever, they may not travel together.\n\nPISCES (Packet-flow Interconnect Simulation for Congestion at Extreme-Scale) models individual packets moving through the network. Flits (flow-control units) are approximately modeled using flow-like approximations. Packets can have partial occupancies in several different buffers, approximating wormhole routing. However, arbitration is modeled on whole packets, not individual flits (see Figure [7](#fig_piscesOverview))\n\n-   A message (flow) is broken up into packets. Depending on available space in the Tx buffer, a limited number of packets may be able to queue up in the buffer. If credits are available in the Rx buffer for the link and the link is idle, the packet moves into the next Rx buffer after a computed delay.\n-   The router selects a path for the packet and the packet requests to the crossbar to transmit to the corresponding output port. If credits are available for the Rx buffer, the crossbar may select the packet in arbitration and move it to the output buffer. After moving, the Rx buffer returns credits to the previous Tx buffer for that packet.\n-   Step 1 is repeated for the next Rx buffer, waiting for credits and link availability.\n-   Repeat Step 2\n-   Repeat Step 3\n-   Packet arrives in NIC Rx queue and queues waiting to inject into local memory. After injection, the Rx buffer returns credits to the corresponding Tx buffer.\n\n\n![Figure 7](https://github.com/sstsimulator/sst-macro/blob/devel/docs/manual/figures/pisces_overview.png) \n\n*Figure 7*\n\n\n\n\nPISCES provides two mechanisms for treating flit-level flow control discussed next.\n\n##### PISCES simple model<a name=\"subsubsec_tutorial_simplePisces\"></a>\n\n\nIn the simple model, each router uses a basic store-and-forward mechanism.\nFlits are not allowed to \"separate\" and always travel as a single unit.\nThe entire packet has to be stored within a router before it can be forwarded to the next router.\nThe simple model affects the arbitrator that decided when and how to transmit flits.\nTo select a simple model:\n\n````\narbitrator = simple\n````\nThe simple model is the least computationally expensive. \nHowever, for large packet sizes, it can produce erroneously high latencies.\nTo tune the packet size for abstract machine models, set:\n\n````\nswitch.mtu = 1024B\nnode.nic.mtu = 1024B\n````\nwhich sets the packet size to 1024B. \nFor the simple model, packet sizes larger than 256-512B are not recommended.\nPacket sizes on production supercomputers are often small (96-128B).\nSmall packet sizes with the simple model can be a good compromise for having more fine-grained routing but cheaper congestion modeling in the arbitrator.\nMore details are given in Figure [7](#fig_piscesOverview).\n\n##### PISCES cut-through model<a name=\"subsubsec_tutorial_cutThroughPisces\"></a>\n\n\n\n\n![Figure 8: Timeline of four different packets passing through a PISCES cut-through bandwidth arbitrator. The incoming bandwidth (I) and outgoing bandwidth (O) are shown for each packet.  Time is the horizontal axis. Bandwidth consumed by a packet is shown by the vertical extent of each packet. The individual events are 1) First packet arrives 2) Second packet arrives with reduced bandwidth but no available bandwidth 3) First packet finishes. Second packet can begin sending. 4) Third packet arrives and begins sending with remaining bandwidth. 5) Fourth packet arrives, but no available bandwidth. 6) Second packet finishes. Third packet increases bandwidth. Fourth packet can begin sending. 7) Third packet finishes. Fourth packet increases bandwidth. 8) Fourth packet finishes.\nFull details are given in the text.](https://github.com/sstsimulator/sst-macro/blob/devel/docs/manual/figures/Pisces.png) \n\n*Figure 8: Timeline of four different packets passing through a PISCES cut-through bandwidth arbitrator. The incoming bandwidth (I) and outgoing bandwidth (O) are shown for each packet.  Time is the horizontal axis. Bandwidth consumed by a packet is shown by the vertical extent of each packet. The individual events are 1) First packet arrives 2) Second packet arrives with reduced bandwidth but no available bandwidth 3) First packet finishes. Second packet can begin sending. 4) Third packet arrives and begins sending with remaining bandwidth. 5) Fourth packet arrives, but no available bandwidth. 6) Second packet finishes. Third packet increases bandwidth. Fourth packet can begin sending. 7) Third packet finishes. Fourth packet increases bandwidth. 8) Fourth packet finishes.\nFull details are given in the text.*\n\n\n\nIn the cut-through model, routing decisions still occur at the packet-level.\nHowever, some attempt is made to account for pipelining of flits across different router stages.\nSomewhat similar to the LogP models used above, latency/bandwidth formulas are used to estimate packet delays.\nHowever, the cut-through model adds more details.\nIt's requested as:\n\n````\narbitrator = cut_through\n````\nFigure [8](#fig_pisces) shows a timeline for the data being transmitted through a crossbar, SerDes, or other network component with a \"fixed bandwidth.\" \nEach component is essentially a pipe with some flow bandwidth.\nThe arbitrator divides its limited bandwidth amongst incoming packets.\nPackets fill the pipeline, consuming bandwidth.\nIn contrast to the completely discrete simple model, packets can \"multiplex\" in the component sharing an arbitrary bandwidth partition.\nModeling a packet delay starts with two input parameters and computes three output parameters.\n\n\n-   A: Packet head arrival (input)\n-   I: Packet incoming bandwidth (input)\n-   H: Packet head departure (output)\n-   T: Packet tail departure (output)\n-   O: Packet outgoing bandwidth (output)\n\nIn the simple model, a packet either consumes all the bandwidth or none of the bandwidth.\nTo account for flit-level pipelining, the cut-through model allows packets to consume partial bandwidths.\nConsider an aribitrator that has a maximum bandwidth of 1.0.\nThe first packet (purple, Figure [8](#fig_pisces)) arrives with a full incoming bandwidth of 1.0 and head arrival of t=0.0.\nIt therefore consumes all the available bandwidth. \nThe head of the packet can actually leave immediately (as it must to properly pipeline or cut-through).\nThe tail leaves after all bytes have sent at t=1.0.\nThus for the first packet we have H=0.0, T=1.0, and O=1.0.\n\nThe second packet (orange) arrives at t=0.5. \nUpon arrival there is no bandwidth available as the first packet is consuming the maximum.\nOnly after the first packet finishes can the second packet begin.\nThe second packet arrives and leaves with a reduced bandwidth of 0.5. \nThus we have H=1.0, T=3.0, and O=0.5.\n\nThe third packet (green) arrives at t=1.75.\nUpon arrival there is some bandwidth, but not enough to match the incoming bandwidth of 0.57.\nThus the third packet is slowed initially.\nAfter the second packet finished, the third packet can send at increased bandwidth.\nThe computation here is a bit more complicated.\nPacket 3 can actually consume MORE than 0.6 bandwidth units.\nBetween steps 4 and 6, packet 3 has accumulated in a local buffer in the router.\nThus even though the incoming bandwidth is only 0.6, there are several flits that are available to send immediately at full bandwidth waiting in the buffer.\nThus results in an effective bandwidth of 0.75 for the remainder of the packet's time in the arbitrator.\nThus we end up with H=1.75, T=3.5, and O=0.57.\nEven though the packet is initially delayed, the buffers compensate for the delay and allow the outgoing bandwidth to \"catch up\" with the incoming bandwidth.\n\nFinally, the fourth packet (blue) arrives at t=3.0. \nThere is some available bandwidth. After the third packet finishes, the fourth packet can now send at maximum.\nBecause of the initial delay, the outgoing bandwidth is somewhat reduced.\nWe have H=3.0, T=4.38, and O=0.73.\n\n#### 3.4.3: SCULPIN<a name=\"subsec_sculpin\"></a>\n\n\n\nUnder current architectural trends, switches have ample buffer space and crossbar bandwidth, making the mostly likely bottleneck edge bandwidth through the output ports.\nAn example file running a simple application can be found in the top-level examples folder.\nSCULPIN (Simple Congestion Unbuffered Latency Packet Interconnection Network) models the main source of contention in today's networks occurring on the output port ser/des. Unlike PISCES, individual flits are not able to wormhole route across links interspersed with flits from other packets.\n\n-   A message (flow) is broken up into packets. Each packet waits in the queue to send based on link availability and QoS.\n-   After being selected, the packets are forwarded to the switch. Packets are immediately routed to the correct output port, skipping crossbar arbitration. Packets wait in unbounded queues, thereby assuming sufficient buffer space is always available.\n-   Repeat Step 1. Packet waits in queue until link becomes available based on QoS. Packet is immediately forwarded to next output port, skipping arbitration\n-   Repeat Step 1.\n-   Packet arrives in NIC Rx queue (no credits, buffer assumed to always have space). Packets queue waiting to inject into local memory.\n\n\n![Figure 9](https://github.com/sstsimulator/sst-macro/blob/devel/docs/manual/figures/sculpin.png) \n\n*Figure 9*\n\n\n\n#### 3.4.4: SNAPPR<a name=\"subsec_snappr\"></a>\n\n\n\nBecause of the coarse-grained mechanisms used in PISCES and SCULPIN, it can be difficult to model more advanced mechanisms like QoS or congestion control. \nSNAPPR (Simulator Network for Adaptive Priority Packet Routing) uses a coarse-grained cycle-based simulation that allows priority queues based on QoS or restricting injection rate for congestion control. The model is configured in much the same way as the other models.  SNAPPR is slightly more expensive than the other models, but provides by far the most flexibility and most detailed statistics.\nAn example file running a simple application can be found in the top-level examples folder.\n\n#### 3.4.5: Flow<a name=\"subsec_tutorial_flow\"></a>\n\n\nThe flow model, in simple cases, corrects the most severe problems of the packet model.\nInstead of discrete chunks, messages are modeled as fluid flows moving through the network.\nCongestion is treated as a fluid dynamics problem, sharing bandwidth between competing flows.\nIn contrast to LogP models, flow models can account fairly well for congestion.\nWithout congestion, a flow only requires a FLOW START and FLOW STOP event to be modeled (see tutorial on discrete event simulation in [3.7](#sec_tutorial_des)).\nWhile the packet model would require many, many events to simulate a 1 MB message, the flow model might only require two.\nWith congestion, flow update events must be scheduled whenever congestion changes on a network link.\nFor limited congestion, only a few update events must occur.\nThe flow model also corrects the latency and multiplexing problems in the PISCES simple model, providing higher-accuracy for coarse-grained simulation.\n\nThe flow model starts to break down for large systems or under heavy congestion.\nIn the packet model, all congestion events are \"local\" to a given router.\nThe number of events is also constant in packet models regardless of congestion since we are modeling a fixed number of discrete units.\nIn flow models, flow update events can be \"non-local,\" propagating across the system and causing flow update events on other routers.\nWhen congestion occurs, this \"ripple effect\" can cause the number of events to explode, overwhelming the simulator.\nFor large systems or heavy congestion, the flow model is actually much slower than the packet model. Support for this model has been completely removed.\n\n\n\n### Section 3.5: Basic MPI Program<a name=\"sec_tutorial_basicmpi\"></a>\n\n\n\nLet us go back to the simple send/recv skeleton and actually look at the code.\nThis code should be compiled with SST compiler wrappers installed in the `bin` folder.\n\n````\n#include <stdlib.h>\n#include <stdio.h>\n#include <mpi.h>\n\nint main(int argc, char **argv) \n{\n  int message_size = 128;\n  int me, nproc;\n  int tag = 0;\n  int dst = 1;\n  int src = 0;\n  MPI_Status stat;\n\n  MPI_Init(&argc,&argv);\n  MPI_Comm world = MPI_COMM_WORLD;\n  MPI_Comm_rank(world,&me);\n  MPI_Comm_size(world,&nproc);\n````\nThe starting point is creating a main routine for the application.\nThe simulator itself already provides a `main` routine.\nThe SST compiler automatically changes the function name to `userSkeletonMain`,\nwhich provides an entry point for the application to actually begin.\nWhen SST-macro launches, it will invoke this routine and pass in any command line arguments specified via the `app1.argv` parameter.  Upon entering the main routine, \nthe code is now indistinguishable from regular MPI C++ code.  \nIn the parameter file to be used with the simulation, you must set\n\n````\nnode {\n app1 {\n  exe = <PATH_TO_EXE>\n````\n\nWhile MPI would have produced an executable, SST works by loading shared object files using `dlopen`.\nTo get SST to load the skeleton, you must specify the path of the \"executable\" in the input file.\nUsing `dlopen` tricks, SST finds the main function in the .so file and calls it to spawn the skeleton app.\nJust as an executable can only have one main, SST shared object files can only have a single executable in them at a time.\n\nAt the very top of the file, the `mpi.h` header is actually mapped by the SST compiler to an SST-macro header file.\nThis header provides the MPI API and configures MPI function calls to link to SST-macro instead of the real MPI library.\nThe code now proceeds:\n\n````\nif (nproc != 2) {\n    fprintf(stderr, \"sendrecv only runs with two processors\\n\");\n      abort();\n  }\n  if (me == 0) {\n    MPI_Send(NULL, message_size, MPI_INT, dst, tag, world);\n    printf(\"rank %i sending a message\\n\", me);\n  }\n  else {\n    MPI_Recv(NULL, message_size, MPI_INT, src, tag, world, &stat);\n    printf(\"rank %i receiving a message\\n\", me);\n  }\n  MPI_Finalize();\n  return 0;\n}\n````\nHere the code just checks the MPI rank and sends (rank 0) or receives (rank 1) a message.\n\nFor more details on what exactly the SST compiler wrapper is doing, you can specify `SSTMAC_VERBOSE=1` as an environment variable to have SST print out detailed commands. Additionally, you can specify `SSTMAC_DELETE_TEMPS=0` to examine any temporary source-to-source files.\n\n\n\n### Section 3.6: Launching, Allocation, and Indexing<a name=\"sec_tutorial_launchetc\"></a>\n\n\n\n#### 3.6.1: Launch Commands<a name=\"subsec_tutorial_launch\"></a>\n\n\nJust as jobs must be launched on a shared supercomputer using Slurm or aprun,\nSST/macro requires the user to specify a launch command for the application.\nCurrently, we encourage the user to use aprun from Cray, for which documentation can easily be found online.\nIn the parameter file you specify, e.g.\n\n````\nnode {\n app1 {\n  name = user_mpiapp_cxx\n  launch_cmd = aprun -n 8 -N 2\n }\n}\n````\nwhich launches an external user C++ application with eight ranks and two ranks per node.\nThe aprun command has many command line options (see online documentation), some of which may be supported in future versions of SST/macro.  In particular, we are in the process of adding support for thread affinity, OpenMP thread allocation, and NUMA containment flags.  Most flags, if included, will simply be ignored.\n\n#### 3.6.2: Allocation Schemes<a name=\"subsec_tutorial_allocation\"></a>\n\n\nIn order for a job to launch, it must first allocate nodes to run on. Here we choose a simple 2D torus\n\n````\ntopology.name = torus\ntopology.geometry = 3 3\ntopology.concentration = 1\n````\nwhich has 9 nodes arranged in a 3x3 mesh.\nFor the launch command `aprun -n 8 -N 2`, we must allocate 4 compute nodes from the pool of 9.\nOur first option is to specify the first available allocation scheme (Figure [10](#fig_allocation_first_available))\n\n````\nnode.app1.allocation = first_available\n````\n\n![Figure 10: First available Allocation of 4 Compute Codes on a 3x3 2D Torus](https://github.com/sstsimulator/sst-macro/blob/devel/docs/manual/figures/tikz/allocation/firstavailable.png) \n\n*Figure 10: First available Allocation of 4 Compute Codes on a 3x3 2D Torus*\n\n\nIn first available, the allocator simply loops through the list of available nodes as they are numbered by the topology object.\nIn the case of a 2D torus, the topology numbers by looping through columns in a row.\nIn general, first available will give a contiguous allocation, but it won't necessarily be ideally structured.\n\nTo give more structure to the allocation, a Cartesian allocator can be used (Figure [11](#fig_allocation_cartesian)).\n\n````\napp1 {\n allocation = cartesian\n cart_sizes = [2,2]\n cart_offsets = [0,0]\n}\n````\n\n![Figure 11: Cartesian Allocation of 4 Compute Codes on a 3x3 2D Torus](https://github.com/sstsimulator/sst-macro/blob/devel/docs/manual/figures/tikz/allocation/cartesian.png) \n\n*Figure 11: Cartesian Allocation of 4 Compute Codes on a 3x3 2D Torus*\n\n\nRather than just looping through the list of available nodes, we explicitly allocate a 2x2 block from the torus.\nIf testing how ``topology agnostic\" your application is, you can also choose a random allocation.\n\n````\nnode.app1.allocation = random\n````\n\n![Figure 12: Random Allocation of 4 Compute Codes on a 3x3 2D Torus](https://github.com/sstsimulator/sst-macro/blob/devel/docs/manual/figures/tikz/allocation/random.png) \n\n*Figure 12: Random Allocation of 4 Compute Codes on a 3x3 2D Torus*\n\n\n\nIn many use cases, the number of allocated nodes equals the total number of nodes in the machine.\nIn this case, all allocation strategies allocate the same set of nodes, i.e. the whole machine.\nHowever, results may still differ slightly since the allocation strategies still assign an initial numbering of the node,\nwhich means a random allocation will give different results from Cartesian and first available.\n\n\n##### Indexing Schemes<a name=\"subsec_tutorial_indexing\"></a>\n\n\nOnce nodes are allocated, the MPI ranks (or equivalent) must be assigned to physical nodes, i.e. indexed.\nThe simplest strategies are block and round-robin.  If only running one MPI rank per node, the two strategies are equivalent,\nindexing MPI ranks in the order received from the allocation list.\nIf running multiple MPI ranks per node, block indexing tries to keep consecutive MPI ranks on the same node (Figure [13](#fig_indexing_block)).\n\n````\nnode.app1.indexing = block\n````\n\n![Figure 13: Block Indexing of 8 MPI Ranks on 4 Compute Nodes](https://github.com/sstsimulator/sst-macro/blob/devel/docs/manual/figures/tikz/indexing/block.png) \n\n*Figure 13: Block Indexing of 8 MPI Ranks on 4 Compute Nodes*\n\n\nIn contrast, round-robin spreads out MPI ranks by assigning consecutive MPI ranks on different nodes (Figure [14](#fig_indexing_round_robin)).\n\n````\nnode.app1.indexing = round_robin\n````\n\n![Figure 14: Round-Robin Indexing of 8 MPI Ranks on 4 Compute Nodes](https://github.com/sstsimulator/sst-macro/blob/devel/docs/manual/figures/tikz/indexing/roundrobin.png) \n\n*Figure 14: Round-Robin Indexing of 8 MPI Ranks on 4 Compute Nodes*\n\n\nFinally, one may also choose\n\n````\nnode.app1.indexing = random\n````\nRandom allocation with random indexing is somewhat redundant.  \nRandom allocation with block indexing is not similar to Cartesian allocation with random indexing.\nRandom indexing on a Cartesian allocation still gives a contiguous block of nodes,\neven if consecutive MPI ranks are scattered around.\nA random allocation (unless allocating the whole machine) will not give a contiguous set of nodes.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n### Section 3.7: Discrete Event Simulation<a name=\"sec_tutorial_des\"></a>\n\n\nAlthough not necessary for using the simulator, a basic understanding of discrete event simulation can be helpful in giving users an intuition for network models and parameters.\nHere we walk through a basic program that executes a single send/recv pair.\nSST-macro simulates many parallel processes, but itself runs as a single process with only one address space (SST-macro can actually run in parallel mode, but we ignore that complication here).\nSST-macro manages each parallel process as a user-space thread (application thread), allocating a thread stack and frame of execution.\nUser-space threading is necessary for large simulations since otherwise the kernel would be overwhelmed scheduling thousands of threads.\n\nSST-macro is driven by a simulation thread which manages the user-space thread scheduling (Figure [15](#fig_des)).\nIn the most common (and simplest) use case, all user-space threads are serialized, running one at a time.\nThe main simulation thread must manage all synchronizations, yielding execution to process threads at the appropriate times.\nThe main simulation thread is usually abbreviated as the DES (discrete event simulation) thread.\nThe simulation progresses by scheduling future events.\nFor example, if a message is estimated to take 5 &mu;s to arrive,\nthe simulator will schedule a MESSAGE ARRIVED event 5 &mu;s ahead of the current time stamp.\nEvery simulation starts by scheduling the same set of events: launch process 0, launch process 1, etc.\n\n\n![Figure 15: Progression of Discrete Event Simulation for Simple Send/Recv Example](https://github.com/sstsimulator/sst-macro/blob/devel/docs/manual/figures/tikz/des/events.png) \n\n*Figure 15: Progression of Discrete Event Simulation for Simple Send/Recv Example*\n\n\n\nThe simulation begins at time t=0&mu; s.\nThe simulation thread runs the first event, launching process 0.\nThe context of process 0 is switched in, and SST-macro proceeds running code as if it were actually process 0.\nProcess 0 starts a blocking send in Event 1.\nFor process 0 to perform a send in the simulator, it must schedule the necessary events to simulate the send.\nMost users of SST-macro will never need to explicitly schedule events.\nDiscrete event details are always hidden by the API and executed inside library functions.\nIn this simple case, the simulator estimates the blocking send will take 1 &mu;s.\nIt therefore schedules a SEND DONE (Event 4) 1 &mu;s into the future before blocking.\nWhen process 0 blocks, it yields execution back to the main simulation.\n\nAt this point, no time has yet progressed in the simulator.\nThe DES thread runs the next event, launching process 1, which executes a blocking receive (Event 3).\nUnlike the blocking send case, the blocking receive does not schedule any events.\nIt cannot know when the message will arrive and therefore blocks without scheduling a RECV DONE event.\nProcess 1 just registers the receive and yields back to the DES thread.\n\nAt this point, the simulator has no events left at t=0 &mu;s and so it must progress its time stamp.\nThe next event (Event 4) is SEND DONE at t=1 &mu;s. The event does two things.\nFirst, now that the message has been injected into the network, the simulator estimates when it will arrive at the NIC of process 1.\nIn this case, it estimates 1 &mu;s and therefore schedules a MESSAGE ARRIVED event in the future at t=2 &mu;s (Event 7).\nSecond, the DES thread unblocks process 0, resuming execution of its thread context.\nProcess 0 now posts a blocking receive, waiting for process 1 to acknowledge receipt of its message.\n\nThe simulator is now out of events at t=1 &mu;s and therefore progresses its time stamp to t=2 &mu;s.\nThe message arrives (Event 7), allowing process 1 to complete its receive and unblock.\nThe DES thread yields execution back to process 1, which now executes a blocking send to ack receipt of the message.\nIt therefore schedules a SEND DONE event 1 &mu;s in the future (Event 10) and blocks, yielding back to the DES thread.\nThis flow of events continues until all the application threads have terminated.\nThe DES thread will run out of events, bringing the simulation to an end. \n\n\n\n\n\n### Section 3.8: Using DUMPI<a name=\"sec_tutorial_dumpi\"></a>\n\n\n\n#### 3.8.1: Building DUMPI<a name=\"subset_dump_build\"></a>\n\n\nAs noted in the introduction, SST-macro is primarily intended to be an on-line simulator. Real application code runs, but SST-macro  intercepts calls to communication (MPI) and computation functions to simulate time passing.  However, SST-macro can also run off-line, replaying application traces collected from real production runs.  This trace collection and trace replay library is called DUMPI.\n\nAlthough DUMPI is automatically included as a subproject in the SST-macro download, trace collection can be easier if DUMPI is built independently from SST-macro.  The code can be downloaded from https://bitbucket.org/sst-ca/dumpi. If downloaded through Mercurial, one must initialize the build system and create the configure script.\n\n````\ndumpi> ./bootstrap.sh\n````\n\nDUMPI must be built with an MPI compiler.\n\n````\ndumpi/build> ../configure CC=mpicc CXX=mpicxx \\ \n\t              --enable-libdumpi --prefix=$DUMPI_PATH\n````\nThe `--enable-libdumpi` flag is needed to configure the trace collection library.\nAfter compiling and installing, a `libdumpi` will be added to `\\$DUMPI_PATH/lib`.\n\nCollecting application traces requires only a trivial modification to the standard MPI build.\nUsing the same compiler, simply add the DUMPI library path and library name to your project's `LDFLAGS`.\n\n````\nyour_project/build> ../configure CC=mpicc CXX=mpicxx \\\n                                  LDFLAGS=\"-L$DUMPI_PATH/lib -ldumpi\"\n````\n\n#### 3.8.2: Trace Collection<a name=\"subsec_dumpi_tracecollection\"></a>\n\n\nDUMPI works by overriding weak symbols in the MPI library.\nIn all MPI libraries, functions such as `MPI_Send` are only weak symbol wrappers to the actual function `PMPI_Send`.\nDUMPI overrides the weak symbols by implementing functions with the symbol `MPI_Send`. \nIf a linker encounters a weak symbol and regular symbol with the same name, it ignores the weak symbol.\nDUMPI functions look like\n\n````\nint MPI_Send(...)\n{\n  /** Start profiling work */\n  ...\n  int rc = PMPI_Send(...);\n  /** Finish profiling work */\n  ...\n  return rc;\n}\n````\ncollecting profile information and then directly calling the PMPI functions.\n\nWe examine DUMPI using a very basic example program.\n\n````\n#include <mpi.h>\nint main(int argc, char** argv)\n{\n  MPI_Init(&argc, &argv);\n  MPI_Finalize();\n  return 0;\n}\n````\nAfter compiling the program named `test` with DUMPI, we run MPI in the standard way.\n\n````\nexample> mpiexec -n 2 ./test\n````\nAfter running, there are now three new files in the directory.\n\n````\nexample> ls dumpi*\ndumpi-2013.09.26.10.55.53-0000.bin\t\ndumpi-2013.09.26.10.55.53-0001.bin\t\ndumpi-2013.09.26.10.55.53.meta\n````\nDUMPI automatically assigns a unique name to the files from a timestamp.\nThe first two files are the DUMPI binary files storing separate traces for MPI rank 0 and rank 1.\nThe contents of the binary files can be displayed in human-readable form by running the `dumpi2ascii`\nprogram, which should have been installed in `\\$DUMPI_PATH/bin`.\n\n````\nexample> dumpi2ascii dumpi-2013.09.26.10.55.53-0000.bin\n````\nThis produces the output\n\n````\nMPI_Init entering at walltime 8153.0493, cputime 0.0044 seconds in thread 0.\nMPI_Init returning at walltime 8153.0493, cputime 0.0044 seconds in thread 0.\nMPI_Finalize entering at walltime 8153.0493, cputime 0.0045 seconds in thread 0.\nMPI_Finalize returning at walltime 8153.0498, cputime 0.0049 seconds in thread 0.\n````\nThe third file is just a small metadata file DUMPI used to configure trace replay.\n\n````\nhostname=deepthought.magrathea.gov\nnumprocs=2\nusername=slartibartfast\nstartime=1380218153\nfileprefix=dumpi-2013.09.26.10.55.53\nversion=1\nsubversion=1\nsubsubversion=0\n````\n\n#### 3.8.3: Trace Replay<a name=\"subsec_dumpi_tracereplay\"></a>\n\n\nIt is often useful to validate the correctness of a trace.  Sometimes there can be problems with trace collection. \nThere are also a few nooks and crannies of the MPI standard left unimplemented.\nTo validate the trace, you can run in a special debug mode that runs the simulation with a very coarse-grained model\nto ensure as quickly as possible that all functions execute correctly.\nThis can be done straightforwardly by running the executable with the dumpi flag: `sstmac --dumpi`.\n\nTo replay a trace in the simulator, a small modification is required to the example input file in [3.1](#sec_parameters).\nWe have two choices for the trace replay.  First, we can attempt to exactly replay the trace as it ran on the host machine.\nSecond, we could replay the trace on a new machine or different layout.\n\nFor exact replay, the key issue is specifying the machine topology.\nFor some architectures, topology information can be directly encoded into the trace.\nThis is generally true on Blue Gene, but not Cray.\nWhen topology information is recorded, trace replay is much easier.\nThe parameter file then becomes, e.g.\n\n````\nnode {\n app1 {\n  indexing = dumpi\n  allocation = dumpi\n  name = parsedumpi\n  dumpi_metaname = testbgp.meta\n }\n}\n````\nWe set indexing and allocation parameters to read from the DUMPI trace.\nThe application name is a special app that parses the DUMPI trace.\nFinally, we direct SST-macro to the DUMPI metafile produced when the trace was collected.\nTo extract the topology information, locate the `.bin` file corresponding to MPI rank 0.\nTo print topology info, run\n\n````\ntraces> dumpi2ascii -H testbgp-0000.bin\n````\nwhich produces the output\n\n````\nversion=1.1.0\nstarttime=Fri Nov 22 13:53:58 2013\nhostname=R00-M1-N01-J01.challenger\nusername=<none>\nmeshdim=3\nmeshsize=[4, 2, 2]\nmeshcrd=[0, 0, 0]\n````\nHere we see that the topology is 3D with extent 4,2,2 in the X,Y,Z directions.\nAt present, the user must still specify the topology in the parameter file.\nEven though SST-macro can read the topology dimensions from the trace file,\nit cannot read the topology type.  It could be a torus, dragonfly, or fat tree.\nThe parameter file therefore needs\n\n````\ntopology {\n name = torus\n geometry = 4 2 2\n}\n````\nBeyond the topology, the user must also specify the machine model with bandwidth and latency parameters.\nAgain, this is information that cannot be automatically encoded in the trace.\nIt must be determined via small benchmarks like ping-pong.\nAn example file can be found in the test suite in `tests/test_configs/testdumpibgp.ini`.\n\nIf no topology info could be recorded in the trace, more work is needed.\nThe only information recorded in the trace is the hostname of each MPI rank.\nThe parameters are almost the same, but with allocation now set to `hostname`.\nSince no topology info is contained in the trace, \na hostname map must be put into a text file that maps a hostname to the topology coordinates.\nThe new parameter file, for a fictional machine called deep thought\n\n````\n# Launch parameters\nnode {\n app1 {\n  indexing = dumpi\n  allocation = hostname\n  name = parsedumpi\n  dumpi_metaname = dumpi-2013.09.26.10.55.53.meta\n  dumpi_mapname = deepthought.map\n }\n}\n# Machine parameters\ntopology {\n name = torus\n geometry = 2 2\n}\n````\n\n\nIn this case, we assume a 2D torus with four nodes.\nAgain, DUMPI records the hostname of each MPI rank during trace collection.\nIn order to replay the trace, the mapping of hostname to coordinates must be given in a node map file,\nspecified by the parameter `launch_dumpi_mapname`.\nThe node map file has the format\n\n````\n4 2\nnid0 0 0\nnid1 0 1\nnid2 1 0\nnid3 1 1\n````\nwhere the first line gives the number of nodes and number of coordinates, respectively.\nEach hostname and its topology coordinates must then be specified.\nMore details on building hostname maps are given below.\n\nWe can also use the trace to experiment with new topologies to see performance changes.\nSuppose we want to test a crossbar topology.\n\n````\n# Launch parameters\nnode {\n app1 {\n  indexing = block\n  allocation = first_available\n  dumpi_metaname = dumpi-2013.09.26.10.55.53.meta\n  name = parsedumpi\n  size = 2\n }\n}\n# Machine parameters\ntopology {\n name = crossbar\n geometry = 4\n}\n````\nWe no longer use the DUMPI allocation and indexing. \nWe also no longer require a hostname map.\nThe trace is only used to generate MPI events and no topology or hostname data is used.\nThe MPI ranks are mapped to physical nodes entirely independent of the trace.\n\n\n\n\n### Section 3.9: Using Score-P and OTF2<a name=\"sec_tutorial_otf\"></a>\n\n\n\nOTF2 is part of Score-P. Sources for both can be found here \n````\nhttp://www.vi-hps.org/projects/score-p\n````\n\n\nTrace collection requires both Score-P and OTF2 installations. Trace replay with SST/macro requires only OTF2.\n\n\n#### 3.9.1: Trace Collection<a name=\"subsec_otf_traceCollection\"></a>\n\n\n\nScore-P's default collection strategy will include every function call in the trace, making even small programs produce untenably large traces. Score-P supports collection filters, which can restrict collection at a minimum to MPI and OMP function calls. At the end of the program's runtime, traces from each rank are put in a common directory.  An MPI program must be compiled with Score-P to produce traces:\n\n````\nscorep-mpicxx -o test.exe test.cc\n````\n\n\n\nTo limit the size of the traces, run the program with:\n\n````\n# these environment variables are picked up by Score-P at runtime\nexport SCOREP_ENABLE_TRACING=true\nexport SCOREP_TOTAL_MEMORY=1G\nexport SCOREP_FILTERING_FILE='scorep.filter'\n\nmpirun -n 2 test.exe\n````\n\nThe file `scorep.filter` should contain:\n````\nSCOREP_REGION_NAMES_BEGIN EXCLUDE *\n````\n\n\nTo view a plain-text representation of the trace after running, use the otf2-print tool.\n\n````\notf2-print scorep-*/traces.otf2\n````\n\n#### 3.9.2: Trace Replay<a name=\"subsec_otf_traceReplay\"></a>\n\n\nSST/macro will use a trace replay skeleton for OTF2 in much the same way as it does for dumpi. SST/macro trace replays configured using *.ini files. \n\n````\n...\n\nnode {\n app1 {\n  otf2_timescale = 1.0\n  name = otf2_trace_replay_app\n  size = N\n  otf2_metafile = <trace-root>/scorep-20170309_1421_27095992608015568/traces.otf2\n # debugging output\n  otf2_print_mpi_calls=false\n  otf2_print_trace_events=false\n  otf2_print_time_deltas=false\n  otf2_print_unknown_callback=false\n }\n}\n````\n\n\n\n### Section 3.10: Statistics<a name=\"sec_Statistics\"></a>\n\n\n\nSST/macro statistics current only work in standalone mode due to the rigid structure of statistics in SST core.\nFixes are planned for SST core for the 10.0 release in 2020.\nUntil then, most of the statistics will require the standalone core.\nBoth standalone and SST core do follow the same basic structure, however, and the tutorial below covers concepts important to both.\nThe three abstractions for understanding statistics are collectors, groups, and outputs.\nWe will use the running example of a bytes sent statistic.\n\n#### 3.10.1: Collectors<a name=\"subsec_collectors\"></a>\n\n\n\nStatistic collectors inherit from `Statistic<T>` and are used by components to collect individual statistics.\nStatistics are collected through the `addData` function:\n\n````\nxmit_bytes_->addData(pkt->byteLength());\n````\nThe statistic only specifies the type of data collected, not the manner of collection (histogram, accumulate).\nIn this case, e.g., we would have:\n\n````\nStatistic<uint64_t>* xmit_bytes_;\n````\nStatistic objects generally do three things, with the exception of special custom statistics.\n\n\n-   Collect data through an addData function.\n-   Register output fields before collecting data through the `registerField` function.\n-   Pass along fields to output when done collecting data through the `outputField` function.\n\nThe data collected and the data output are not the same - and may not even be of the same type.\nFor an accumulator, data collected and data output are the same (sum of collected values).\nFor a histogram, data collected is, e.g., a single integer, while the data output is the counts in a series of bins.\nIf there are ten bins, the histogram will register ten output fields at the beginning and output ten fields at the end.\n\n#### 3.10.2: Outputs<a name=\"subsec_outputs\"></a>\n\n\n\nStatistic outputs provide an abstract interface for outputting fields.\nIn SQL or Pandas terminology, each statistic defines a row in a table. Each field will be a column.\nOutputs therefore map naturally to a CSV file.\nSST core also provides an HDF5 output, for those statistics that work with SST core.\n\n#### 3.10.3: Groups<a name=\"subsec_groups\"></a>\n\n\n\nStatistics can be grouped together when appropriate, for example bytes sent statistics for switches may want to be grouped together.\nEach group is associated with a given output.\nMost commonly, a group is only used to link statistics to the same output.\nHowever, aggregation of statistics can potentially be performed as well for certain cases.\n\n#### 3.10.4: SST/macro Standalone Input<a name=\"subsec_standaloneInput\"></a>\n\n\n\nEach statistic has a name, which specifies a parameter namespace in the parameter file.\nIn the case above, we activate an ``xmit\\_bytes\" statistic.\n\n````\nnic {\n  injection {\n   xmit_bytes {\n     type = accumulator\n     output = csv\n     group = test\n   }\n  }\n}\n````\nAs discussed above, we must specify the type of collection, the type of output, and the group name.\nThe output file name (test.csv) is generated from the group name. The CSV output looks like:\n\n````\nname,component,total\nxmit_bytes,nid0,16952064\nxmit_bytes,nid1,6635264\nxmit_bytes,nid2,7542016\n````\nFor a histogram with 5 bins, we could specify an input:\n\n````\nxmit_bytes {\n  type = histogram\n  output = csv\n  group = all\n  num_bins = 5\n  min_value = 0\n  max_value = 5KB\n}\n````\nwhich then generates columns for the bins, e.g.\n\n````\nname,component,numBins,binSize,bin0,bin1,bin2,bin3,bin4\nxmit_bytes,nid0,5,1000,1235,559,396,31,3746\nxmit_bytes,nid1,5,1000,870,439,322,11,1292\nxmit_bytes,nid2,5,1000,838,396,279,11,1551\n````\n\n#### 3.10.5: Custom Statistics<a name=\"subsec_customStats\"></a>\n\n\nCertain statistics (examples below) do not fit into the model of row/column tables and require special `addData` functions.\nRather than declare themselves as `Statistic<T>` for some numeric type T, they declare themselves as `Statistic<void>` and have a completely custom collection and output mechanism.\nThey also generally do not rely an abstract interfaces. \nFor example, a bytes sent statistic output can choose a CSV histogram or an HDF5 accumulator or a text list.\nHere, the statistic can only have a single type and works with a specific output.\n\n\n\n### Section 3.11: OTF2 Trace Creation<a name=\"sec_otf_traceEmission\"></a>\n\n\nSST/macro can emit OTF2 traces from MPI simulations, if compiled with:\n\n````\nbuild> ../configure --enable-otf2=$PATH_TO_OTF2\n````\n\nThis is an example of a custom statistic, discussed in [3.10.5](#subsec_customStats).\nThis gets activated by:\n\n````\n...\n\nnode {\n app1 {\n  mpi {\n    otf2 {\n      type = otf2writer\n      group = app1\n      output = otf2\n    }\n  }\n }\n}\n````\n\nThe statistic is given to the MPI namespace.\nGood practice is generally to name the group after the app.\n\n\n\n\n\n### Section 3.12: Call Graph Visualization<a name=\"sec_tutorials_callgraph\"></a>\n\n\nGenerating call graphs requires a special build of SST-macro.\n\n````\nbuild> ../configure --prefix=$INSTALL_PATH --enable-call-graph\n````\nThe extra flag enables special instrumentation.\nIn the default build, the instrumentation is not added to avoid overheads.\nHowever, SST-macro only instruments a select group of the most important functions so the overhead should only be 10-50\\\nAfter installing the instrumented version of SST-macro, a call graph must be activated for a given application.\n\n````\nnode {\n  app1 {\n    call_graph {\n      type = call_graph\n      output = cachegrind\n      group = test\n    }\n  }\n}\n````\nAfter running the above, a `test.callgrind.out` file should appear in the folder based on the group name.\nAdditionally, a summary CSV file - `test.csv` or other group name - is generated with various aggregate statistics.\n\nTo visualize the call graph, you must download KCachegrind: http://kcachegrind.sourceforge.net/html/Download.html.\nKCachegrind is built on the KDE environment, which is simple to build for Linux but can be very tedious for Mac.\nThe download also includes a QCachegrind subfolder, providing the same functionality built on top of Qt.  \nThis is highly recommended for Mac users.\n\n\n![Figure 16: QCachegrind GUI](https://github.com/sstsimulator/sst-macro/blob/devel/docs/manual/figures/graphviz/gui.png) \n\n*Figure 16: QCachegrind GUI*\n\n\n\nThe basic QCachegrind GUI is shown in Figure [16](#fig_qcgui).\nOn the left, a sidebar contains the list of all functions instrumented with the percent of total execution time spent in the function.\nIn the center pane, the call graph is shown.\nTo navigate the call graph, a small window in the bottom right corner can be used to change the view pane.\nZooming into one region (Figure [17](#fig_qcgraphone)), we see a set of MPI functions (Barrier, Scan, Allgatherv).\nEach of the functions enters a polling loop, which dominates the total execution time.\nA small portion of the polling loop calls the ``Handle Socket Header\" function.\nDouble-clicking this node unrolls more details in the call graph (Figure [18](#fig_qcgraphtwo)).\nHere we see the function splits execution time between buffering messages (memcpy) and posting headers (Compute Time).\n\n\n![Figure 17: QCachegrind Call Graph of MPI Functions](https://github.com/sstsimulator/sst-macro/blob/devel/docs/manual/figures/graphviz/callgraph1.png) \n\n*Figure 17: QCachegrind Call Graph of MPI Functions*\n\n\n\n\n![Figure 18: QCachegrind Expanded Call Graph of Eager 0 Function](https://github.com/sstsimulator/sst-macro/blob/devel/docs/manual/figures/graphviz/callgraph2.png) \n\n*Figure 18: QCachegrind Expanded Call Graph of Eager 0 Function*\n\n\n\nIn the summary file, each function is broken down into \"self\" time (time spent directly in the function itself)\nand time spent in various subroutines.\n\n````\napp1.rank0.thread0,main,self,40000000000000\napp1.rank0.thread0,main,sleep,20000000000000000\napp1.rank0.thread0,main,MPI_Init,101362856608\napp1.rank0.thread0,main,MPI_Finalize,40013333328\napp1.rank0.thread0,main,MPI_Allgather,344587523048\napp1.rank0.thread0,main,MPI_Alltoall,80969809408\napp1.rank0.thread0,main,MPI_Allreduce,180006666664\napp1.rank0.thread0,main,MPI_Barrier,320740095096\napp1.rank0.thread0,main,MPI_Gather,160234285648\napp1.rank0.thread0,main,MPI_Reduce,161223333064\n....\n````\nHere is a breakdown of a benchmark for the `main` routine.\nA small amount of self-time is shown, along with the time spent in other routines.\nEach of these subroutines themselves can also have subroutines:\n\n````\napp1.rank0.thread0,MPI_Allgather,self,121499999400\napp1.rank0.thread0,MPI_Allgather,memcopy,3034190336\n````\n\n\n\n\n\n### Section 3.13: Spyplot Diagrams<a name=\"sec_tutorials_spyplot\"></a>\n\n\n\nSpyplots visualize communication matrices, showing either the number of messages or number of bytes sent between two network endpoints.\nThey are essentially contour diagrams, where instead of a continuous function F(x,y) we are plotting the communication matrix M(i,j).\nAn example spyplot is shown for a simple application that only executes an MPI\\_Allreduce (Figure [19](#fig_spyplot)).\nLarger amounts of data (red) are sent to nearest neighbors while decreasing amounts (blue) are sent to MPI ranks further away.\n\n\n![Figure 19: Spyplot of Bytes Transferred Between MPI Ranks for MPI\\_Allreduce](https://github.com/sstsimulator/sst-macro/blob/devel/docs/manual/figures/spyplot/mpi_spyplot.png) \n\n*Figure 19: Spyplot of Bytes Transferred Between MPI Ranks for MPI\\_Allreduce*\n\n\n\nVarious spyplots can be activated.\nThe most commonly used are the MPI spyplots, for which you activate the spyplot as part of the MPI subcomponent.\n\n````\nnode {\n  app1 {\n    mpi {\n      spy_bytes {\n        type = spyplot\n        output = csv\n        group = app1\n      }\n    }\n  }\n}\n````\nAfter running, there will be a CSV containing the data sent by each component to another component.\nThe same statistic can be activated in both the `node.app1.mpi` namespaces and the `node.nic` namespaces.\nThe type of the statistic must be spyplot, but the output can be other formats (but just use csv).\n\n\n\n\n\n### Section 3.14: Fixed-Time Quanta Charts<a name=\"sec_tutorials_ftq\"></a>\n\n\n\n\n![Figure 20: Application Activity (Fixed-Time Quanta; FTQ) histogram](https://github.com/sstsimulator/sst-macro/blob/devel/docs/manual/figures/matplotlib/ftq/pic1024.png) \n\n*Figure 20: Application Activity (Fixed-Time Quanta; FTQ) histogram*\n\n\n\nAnother way of visualizing application activity is a fixed-time quanta (FTQ) chart.\nWhile the call graph gives a very detailed profile of what critical code regions, they lack temporal information. \nFigure [20](#fig_ftq) displays the proportion of time spent by ranks in MPI communication and computation in a PIC trace replay with respect to simulation time.\nAfter running, two new files appear in the folder: `<fileroot>_app1.py` and `<fileroot>_app1.dat` that can use Python's matplotlib to generate plots.\nPreviously, plots were generated using Gnuplot, but this has been deprecated in favor of much more aesthetically pleasing maplotlib output.\n\n````\nyour_project # python output_app1.py --help\nusage: output_app1.py [-h] [--show] [--title TITLE] [--eps] [--pdf] [--png]\n                      [--svg]\n\noptional arguments:\n  -h, --help     show this help message and exit\n  --show         display the plot on screen\n  --title TITLE  set the title\n  --eps          output .eps file\n  --pdf          output .pdf file\n  --png          output .png file\n  --svg          output .svg file\n````\n\nGenerating the histogram requires matplotlib, and visualizing the histogram interactively with `--show` requires a screen or X11 forwarding.\nFTQ aggregates tags into tunable time \"epochs\".\nAn epoch states the ratio of each tag represented at a point in time.\nLarger epochs will smooth the graph and decrease the quantity of data required to render a plot; while a smaller epoc will add more detail, at the risk of making the plot excessively volatile.\n\n\nSST/macro activates FTQ for a given application as:\n\n````\nnode {\n app1 {\n  name = sstmac_mpi_testall\n  launch_cmd = aprun -n 8 -N 2\n  ftq {\n   type = ftq_calendar\n   epoch_length = 1ms\n   output = ftq\n   group = app1\n  }\n  print_times = false\n  message_size = 400B\n }\n}\n````\nwhere the `fileroot` a path and a file name prefix.\n\n\n\n\n### Section 3.15: Network Statistics<a name=\"sec_tutorials_packetStats\"></a>\n\n\n\nHere we describe a few of the network statistics that can be collected and the basic mechanism for activating them.\nThese statistics are usually collected on either the NIC, switch crossbar, or switch output buffers.\nThese are based on the XmitWait and XmitBytes performance counters from OmniPath,\nand aim to provide similar statistics as those from production systems.\n\n#### 3.15.1: XmitBytes<a name=\"subsec_xmitbytes\"></a>\n\n\nTo active a message size histogram on the NIC or the switches to determine the data sent by individual packets, the parameter file should include, for example:\n\n````\nnode {\n nic {\n  injection {\n   xmit_bytes {\n     output = csv\n     type = accumulator\n     group = test\n   }\n  }\n } \n}\n````\nIn contrast the custom statistics above, this is a row-table statistic that can have different types and outputs.\nThe same stat can be activated in both the `node.nic.injection` and `switch` namespaces.\n\n#### 3.15.2: XmitWait<a name=\"subsec_xmitwait\"></a>\n\n\nTo estimate congestion, SST/macro provides an `xmit_wait` statistic.\nThis counts the total amount of time spent in stalls due to lack of credits.\nThe time is accumulated and reported in seconds.\n\n````\nnode {\n nic {\n  injection {\n   xmit_wait {\n     output = csv\n     type = accumulator\n     group = test\n   }\n  }\n }\n}\n````\nThe same stat can be activated in both the `node.nic.injection` and `switch` namespaces.\n\n#### 3.15.3: XmitFlows<a name=\"subsec_xmitflows\"></a>\n\n\nThe previous statistics track the bytes sent by packets and as such are agnostic to the messages (or flows) sending them.\nIf interested in the flow-level statistics, it can be activated as:\n\n````\nnode {\n app1 {\n  mpi {\n    xmit_flows {\n\n    }\n  }\n }\n}\n````\n\n\n\n\n\n\n\n\n## Chapter 4: Topologies<a name=\"chapter_topologies\"></a>\n\n\n\nThe torus topology is straightforward and easy to understand.\nHere we introduce the basics of other topologies within SST that are more complex and require extra documentation to configure properly.\nThese are generally higher-radix or path-diverse topologies like fat tree, dragonfly, and flattened butterfly.\nAs noted in [3.3](#sec_tutorial_topology), a more thorough and excellent discussions of these topologies is given in \"High Performance Datacenter Networks\" by Dennis Abts and John Kim.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n### Section 4.1: Torus<a name=\"subsec_tutorial_hypercube\"></a>\n\n\n\nThe torus is the simplest topology and fairly easy to understand.\nWe have already discussed basic indexing and allocation as well as routing.\nMore complicated allocation schemes with greater fine-grained control can be used such as the\ncoordinate allocation scheme (see hypercube below for examples) and the node ID allocation scheme (see fat tree below for examples).\nMore complicated Valiant and UGAL routing schemes are shown below for hypercube and Cascade,\nbut apply equally well to torus.\n\nFor torus we illustrate here the Cartesian allocation for generating regular Cartesian subsets.\nFor this, the input file would look like \n\n````\ntopology {\n name = torus\n geometry = 4 4 4\n}\nnode {\n app1 {\n  launch_cmd = aprun -n 8\n  indexing = block\n  allocation = cartesian\n  cart_sizes = [2,2,2]\n  cart_offsets = [0,0,0]\n }\n}\n````\n\nThis allocates a 3D torus of size 4x4x4.\nSuppose we want to allocate all 8 MPI ranks in a single octant?\nWe can place them all in a 2x2x2 3D sub-torus by specifying the size of the sublock \n(`cart_sizes`) and which octant (`cart_offsets`).\nThis applies equally well to higher dimensional analogs.\nThis is particularly useful for allocation on Blue Gene machines\nwhich always maintain contiguous allocations on a subset of nodes.\n\nThis allocation is slightly more complicated if we have multiple nodes per switch.\nEven though we have a 3D torus, \nwe treat the geometry as a 4D coordinate space with the 4th dimension referring to nodes connected to the same switch, \ni.e. if two nodes have the 4D coordinates [1 2 3 0] and [1 2 3 1] they are both connected to the same switch.\nConsider the example below:\n\n````\ntopology {\n name = torus\n geometry = 4 4 4\n concentration = 2\n}\napp1 {\n launch_cmd = aprun -n 8\n indexing = block\n allocation = cartesian\n cart_sizes = [2,2,1,2]\n cart_offsets = [0,0,0,0]\n}\n````\n\nWe allocate a set of switches across an XY plane (2 in X, 2 in Y, 1 in Z for a single plane).\nThe last entry in `cart_sizes` indicates that both nodes on each switch should be used.\n\n\n\n\n### Section 4.2: Hypercube<a name=\"subsec_tutorial_hypercube\"></a>\n\n\n\nAlthough never used at scale in a production system, the generalized hypercube is an important topology to understand, particularly for flattened butterfly and Cascade.\nThe (k,n) generalized hypercube is geometrically an N-dimensional torus with each dimension having size k (although dimension sizes need not be equal).\nHere we show a (4,2) generalized hypercube (Figure [21](#fig_topologies_hypercubeConnected)).  This would be specified in SST as:\n\n````\ntopology.name = hypercube\ntopology.geometry = 4 4\n````\nindicating size 4 in two dimensions. \n\nWhile a torus only has nearest-neighbor connections, a hypercube has full connectivity within a row and column (Figure [21](#fig_topologies_hypercubeConnected)).\nAny switches in the same row or same column can send packets with only a single hop.\n\n\n![Figure 21: Hypercube with links and connections within a row/column](https://github.com/sstsimulator/sst-macro/blob/devel/docs/manual/figures/tikz/hypercube/hypercube_connected.png) \n\n*Figure 21: Hypercube with links and connections within a row/column*\n\n\n\nThis extra connectivity leads to greater path diversity and higher radix switches.\nThe cost tradeoff is that each link has lower bandwidth than a torus. \nWhereas a torus has a few fat links connecting switches, a hypercube has many thin links.\nA hypercube can have more dimensions and be asymmetric, e.g.\n\n````\ntopology.name = hypercube\ntopology.geometry = 4 5 6\n````\n\nwhere now we have full connections within horizontal rows, horizontal columns, and vertical columns.\nHere each switch has radix 12 (3 connections in X, 4 connections in Y, 5 connections in Z). \n\n#### 4.2.1: Allocation and indexing<a name=\"subsec_hypercube_allocation\"></a>\n\n\n\nA hypercube has the same coordinate system as a torus. For example, to create a very specific, irregular allocation on a hyerpcube:\n\n````\nnode {\n app1 {\n  launch_cmd = aprun -n 5\n  indexing = coordinate\n  allocation = coordinate\n  coordinate_file = coords.txt\n }\n}\n````\nand then a coordinate file named `coords.txt`\n\n````\n5 2\n0 0\n0 1\n1 1\n2 0\n3 3\n````\nThe first line indicates 5 entries each with 2 coordinates.\nEach line then defines where MPI ranks 0-4 will be placed\n\n\n![Figure 22: Hypercube allocation for given set of coordinates](https://github.com/sstsimulator/sst-macro/blob/devel/docs/manual/figures/tikz/hypercube/hypercube_allocation.png) \n\n*Figure 22: Hypercube allocation for given set of coordinates*\n\n\n\n#### 4.2.2: Routing<a name=\"subsec_hypercube_routing\"></a>\n\n\n\nHypercubes allow very path-diverse routing because of its extra connections.\nIn the case of minimal routing (Figure [23](#fig_topologies_hypercubePath)), two different minimal paths from blue to red are shown.\nWhile dimension order routing would rigorously go X then Y, you can still route minimally over two paths either randomly selecting to balance load or routing based on congestion.\n\n\n![Figure 23: Minimal routing within a hypercube showing path diversity. Packet travels from blue to red, passing through green intermediate switches.](https://github.com/sstsimulator/sst-macro/blob/devel/docs/manual/figures/tikz/hypercube/hypercube_path.png) \n\n*Figure 23: Minimal routing within a hypercube showing path diversity. Packet travels from blue to red, passing through green intermediate switches.*\n\n\n\nTo fully maximize path diversity on adversarial traffic patterns, though, path-diverse topologies can benefit from Valiant routing.\nHere, rather than directly routing to the final destination, packets first route to random intermediate switches on a minimal path.\nThen they route again from the intermediate switch to the final destination also on a minimal path (Figure [24](#fig_topologies_hypercubeValiant)).\nAlthough it increases the hop count and therefore the point-to-point latency, it utilizes more paths and therefore increases the effective point-to-point bandwidth.\n\n\n![Figure 24: Valiant routing within a hypercube.  Packet travels from blue to red via a random intermediate destination shown in gray. Additional intermediate switches are shown in green.](https://github.com/sstsimulator/sst-macro/blob/devel/docs/manual/figures/tikz/hypercube/hypercube_valiant.png) \n\n*Figure 24: Valiant routing within a hypercube.  Packet travels from blue to red via a random intermediate destination shown in gray. Additional intermediate switches are shown in green.*\n\n\n\n\n\n### Section 4.3: Fat Tree<a name=\"sec_tutorial_fattree\"></a>\n\n\n\nSST provides a very flexible fat-tree topology which allows both full bandwidth and tapered bandwidth configurations using either uniform or non-uniform switches.\nThis flexibility requires a farily complicated set of input parameters which are best introduced by examining a couple of example configurations.  Consider the full-bandwidth topology in Figure~[25](#fig_topologies_fullfattree) which uses uniform 8-port switches throughout.\n\n\n![Figure 25: Full-bandwidth fat-tree topology using uniform 8-port switches.](https://github.com/sstsimulator/sst-macro/blob/devel/docs/manual/figures/topologies/fattree4.png) \n\n*Figure 25: Full-bandwidth fat-tree topology using uniform 8-port switches.*\n\n\n\nThe SST fat-tree is strictly a 3-level topology, with the switch levels refered to as leaf (bottom), aggregation (middle), and core (top).\nInterconnected leaf and aggregation switches form an aggregation subtree, which forms the basic unit of a fat-tree topology.\nThe structure of the aggregation subtree is, itself, flexible and places few constraints on the number of subtrees or the way they are connected to the core level.\nIn Figure~[25](#fig_topologies_fullfattree), there are 4 leaf switches and 4 aggregation switches per subtree, and each leaf switch has a concentration of four nodes per switch.\nBalancing bandwidth, there are 4 ports going up from each leaf switch and 4 ports going down from each aggregation switch.\nThis subtree can be specified as follows:\n\n````\ntopology.leaf_switches_per_subtree = 4\ntopology.agg_switches_per_subtree = 4\ntopology.concentration = 4\ntopology.up_ports_per_leaf_switch = 4\ntopology.down_ports_per_agg_switch = 4\n````\n\nIn this example we have 2 aggregation subtrees.\nThere are four ports going up from each aggregation switch.\nAll of the ports on the core switches go down, so the number of core switches required (4) is only half the number of total aggregation switches (8).\nThis core configuration can be specified as follows:\n\n````\ntopologies.num_agg_subtrees = 2\ntopologies.num_core_switches = 4\ntopologies.up_ports_per_agg_switch = 4\ntopologies.down_ports_per_core_switch = 8\n````\n\nPutting it all together with the topology name results in:\n\n````\ntopology.name = fat_tree\nlogy.leaf_switches_per_subtree = 4\ntopology.agg_switches_per_subtree = 4\ntopology.concentration = 4\ntopology.up_ports_per_leaf_switch = 4\ntopology.down_ports_per_agg_switch = 4\ntopologies.num_agg_subtrees = 2\ntopologies.num_core_switches = 4\ntopologies.up_ports_per_agg_switch = 4\ntopologies.down_ports_per_core_switch = 8\n````\n\nThe next example, though somewhat contrived, better demonstrates the fat-tree input flexibility.\nSuppose that one wanted to use the same 8-port switches to construct a 3-level fat-tree that was both cheaper and had more endpoints (nodes), at the cost of interswitch bandwidth.\nOne possible configuration is shown in Figure~[26](#fig_topologies_taperedfattree).\n\n\n![Figure 26: A tapered fat-tree topology using uniform 8-port switches.](https://github.com/sstsimulator/sst-macro/blob/devel/docs/manual/figures/topologies/fattree4-tapered.png) \n\n*Figure 26: A tapered fat-tree topology using uniform 8-port switches.*\n\n\n\nHere the concentration has been increased to 6 nodes per leaf switch, leaving only two up ports per leaf switch.\nThus an aggregation subtree has a total of only 8 leaf up ports, which requires at least two aggregation switches (in order to have any ports left to connect into the core).\nEach aggregation switch is then required to have 4 ports heading down.\nThe subtree can be configured as follows:\n\n````\ntopology.leaf_switches_per_subtree = 4\ntopology.agg_switches_per_subtree = 2\ntopology.concentration = 6\ntopology.up_ports_per_leaf_switch = 2\ntopology.down_ports_per_agg_switch = 4\n````\n\nThere are a total of four aggregation switches.\nIf the bandwidth is allowed to taper again, a single 8-port core switch can accomodate 2 ports coming up from each aggregation switch.\nThis core configuration can be specified as follows:\n\n````\ntopologies.num_agg_subtrees = 2\ntopologies.num_core_switches = 1\ntopologies.up_ports_per_agg_switch = 2\ntopologies.down_ports_per_core_switch = 8\n````\n\nThis is a heavily tapered tree and also has the downside of using only 6 ports per switch in the aggregation level.\nThis example was chosen more for its illustrative rather than practical value, though there are certainly applications where it would be perfectly adequate. \nMore practical tapering becomes an option when you increase the number of ports per switch, but visualizations become more difficult to grasp.\n\nThe following constraints must be met for a valid configuration.\n\n-   Down ports must equal up ports: leaf up ports (`leaf_switches_per_subtree` &times; `up_ports_per_leaf_switch`) must equal aggregation down ports (`agg_switches_per_subtree` &times; `down_ports_per_agg_switch`), and total aggregation up ports (`up_ports_per_agg_switch` &times; `agg_switches_per_subtree` &times; `num_agg_subtrees`) must equal total core down ports (`num_core_switches` &times; `down_ports_per_core_switch`).\n-   Need enough down ports -- each switch must have at least one link into each \"unit\" (subtree or switch, depending on level) below it:  `down_ports_per_core_switch` must be &gt;= `num_agg_subtrees`, and `down_ports_per_agg_switch` must be &gt;= `leaf_switches_per_subtree`.\n-   Need enough up ports -- each \"unit\" (subtree or switch) must have at least one link into each switch above it: `up_ports_per_agg_switch` &times; `agg_switches_per_subtree` must be &gt;= `num_core_switches`, and `up_ports_per_leaf_switch` must be &gt;= `agg_switches_per_subtree`.\n-   Connections need to be regular: 1) `down_ports_per_core_switch` mod `num_agg_subtrees` must equal zero, 2) `down_ports_per_agg_switch` mod `leaf_switches_per_subtree` must equal zero, 3) `up_ports_per_leaf_switch` mod `agg_switches_per_subtree` must equal zero\n\n#### 4.3.1: Switch Crossbar Bandwidth Scaling<a name=\"subsec_fattree_xbarbw\"></a>\n\n\n\nAllowing non-uniform switches in the topology implies that switch crossbar bandwidth should be non-uniform as well.\nBy default, SST assumes `switch.xbar.bandwidth` specifies the bandwidth for the switch type with the lowest port count.\nThe crossbar bandwidth is scaled by the total number of ports for all other switch types. \nInput keywords are provided to override this default behavior.\nFor the tapered-bandwidth example above, uniform switch bandwidth can be maintained by setting all bandwidth scaling to 1.0:\n\n````\ntopology.leaf_bandwidth_multiplier = 1.0\ntopology.agg_bandwidth_multiplier = 1.0\ntopology.core_bandwidth_multiplier = 1.0\n````\n\n#### 4.3.2: Routing<a name=\"subsec_fattree_routing\"></a>\n\n\n\nThe fat-tree topology should be used in conjunction with `router = fat_tree`, which will maximize the utilization of path diversity.\nThere is a `fat_tree_minimal` router which will use the lowest numbered valid port for any destination; this will result in poor network performance and is primarily useful for testing and perhaps experiments where network contention is desired.\n\n\n\n### Section 4.4: Cascade<a name=\"sec_tutorial_cascade\"></a>\n\n\n\n\n![Figure 27: Schematic of cascade with three groups showing hypercube intragroup links and high bandwidth intergroup global links](https://github.com/sstsimulator/sst-macro/blob/devel/docs/manual/figures/tikz/cascade/cascade.png) \n\n*Figure 27: Schematic of cascade with three groups showing hypercube intragroup links and high bandwidth intergroup global links*\n\n\n\nAs bandwidth per pin increases, arguments can be made that optimal topologies should be higher radix.\nA 3D torus is on the low-radix extreme while a hypercube is a high-radix extreme.\nA variation on the dragonfly is the cascade topology implemented by Cray on their Aries interconnects.\nA cascade is sometimes viewed as a generalization of flattened butterfly and hypercube topologies with \"virtual\" switches of very high radix,\nnot dissimilar from the fat-tree implementation with many physical commodity switches composing a single virtual switch.\nThe cascade topology (Figure [27](#fig_topologies_cascade)) is actually quite simple.\nSmall groups are connected as a generalized hypercube with full connectivity within a row or column.\nIntergroup connections (global links) provide pathways for hopping between groups.\nA cascade is usually understood through three parameters:\n\n-   p: number of nodes connected to each router\n-   a: number of routers in a group\n-   h: number of global links that each switch has\n\nFor simplicity, only three example global links are show for clarity in the picture.\nFor the Cray X630, a = 96, h=10, and p=4 so that each router is connected to many other (h=10) groups.\nThe caveat is that in many implementations global links are grouped together for h=2 or 3 fat global links.\nThese demonstrate well-balanced ratios.\nIn general, scaling out a cascade should not increase the size of a group, only the number of groups.\n\n#### 4.4.1: Allocation and indexing<a name=\"subsec_cascade_allocatoin\"></a>\n\n\n\nThe cascade coordinate system is essentially the same as a 3D torus.\nThe group 2D hypercube layout defines X and Y coordinates.\nThe group number defines a Z or G coordinate.\nThus the topology in Figure [27](#fig_topologies_cascade) would be specified as\n\n````\ntopology.name = cascade\ntopology.geometry = 3 3 3\n````\nfor groups of size 3 X 3 with a total of 3 groups.\nTo complete the specification, the number of global links (h) for each router must be given\n\n````\ntopology.group_connections = 10\n````\n\n#### 4.4.2: Routing<a name=\"subsec_cascade_routing\"></a>\n\n\n\nIt is important to understand the distinction between link bandwidth, channel bandwidth, and pin bandwidth.\nAll topologies have the same pin bandwidth and channel bandwidth (assuming they use the same technology).\nEach router in a topology is constrained to have the same number of channels (called radix, usually about k=64).\nThe number of channels per link changes dramatically from topology to topology.\nLow radix topologies like 3D torus can allocate more channels per link, \ngiving higher bandwidth between adjacent routers.\ncascade is higher radix, having many more connections but having lower bandwidth between adjacent routers.\nWhile minimal routing is often sufficient on torus topologies because of the high link bandwidth,\ncascade will exhibit very poor performance with minimal routing.\nTo effectively utilize all the available bandwidth, packets should have a high amount of path diversity.\nPackets sent between two routers should take as many different paths as possible to maximize the effective bandwidth point-to-point.\n\n\n![Figure 28: Schematic of cascade showing minimal route. Traveling between groups requires routing to the correct global link, hopping the global link, then routing within a group to the correct final node.](https://github.com/sstsimulator/sst-macro/blob/devel/docs/manual/figures/tikz/cascade/cascademinroute.png) \n\n*Figure 28: Schematic of cascade showing minimal route. Traveling between groups requires routing to the correct global link, hopping the global link, then routing within a group to the correct final node.*\n\n\n\nMinimal routing itself has a few complications (Figure [28](#fig_topologies_cascademinroute)).\nEach router only has a few global links.\nThus, traveling from e.g. the blue router at X=3,Y=2,G=0 to the red router at X=1,Y=2,G=2, there is no direct link between the routers.\nFurthermore, there is no direct link between Groups 0 and 2.\nThus packets must route through the purple intermediate nodes.\nFirst, the packet hops to X=3,Y=3, G=0.\nThis router has a global link to Group 2, allowing the packet to hop to the next intermediate router at X=1, Y=3, G=2.\nFinally, the minimal route completes by hopping within Group 2 to the final destination.\n\n\n![Figure 29: Schematic of cascade showing Valiant route. Traveling between groups requires routing to a random intermediate node, then routing minimally to the final destination.](https://github.com/sstsimulator/sst-macro/blob/devel/docs/manual/figures/tikz/cascade/cascadevaliant.png) \n\n*Figure 29: Schematic of cascade showing Valiant route. Traveling between groups requires routing to a random intermediate node, then routing minimally to the final destination.*\n\n\n\nTo improve on minimal routing, global routing strategies are required (global routing is distinguished here from adaptive routing).  \nGlobal essentially means \"not minimal\" and spreads packets along many different paths.\nThe simplest global routing strategy is Valiant routing, which falls in the global, oblivious category (Figure ).\nOblivious simply means packets are scattered randomly without measuring congestion.\nIn Valiant routing, each packet does the following:\n\n-   Pick a random intermediate node\n-   Route minimally to random node\n-   Route minimally from random node to destination node\nThis is somewhat counterintuitive at first.\nRather than go directly to the destination node, packets go out of their way to a random node, shown in Figure  as the yellow router.\nThus, routing from the blue router in Group 0 to the red router in Group 2 first follows the minimal path (green routers) to the randomly selected yellow router in Group 1. \nFrom there, a second minimal path is taken through the orange routers to the final destination.\nIn cases with high congestion or even for large messages on a quiet network, this actually improves performance.\nIf a point-to-point message is composed of ten packets,\nall ten packets will follow different paths to the final destination.\nThis essentially multiplies the maximum bandwidth by a factor of ten.\nValiant routing can be specified as\n\n````\nrouter = valiant\n````\n\nIn contrast, UGAL routing is a global, adaptive strategy, making decisions based on congestion.\nBecause Valiant is oblivious, it often sends too many packets to far away random nodes.\nFollowing a Valiant path is only relevant when enough packets fill up router queues, creating congestion.\nUGAL does the following steps:\n\n-   Start routing minimally\n-   On each step, check congestion (buffer queue depth)\n-   If congestion is too heavy, switch to Valiant and re-route to random intermediate node. Otherwise stay on minimal path.\nUGAL packets stay on a minimal path until congestion forces them to use a Valiant strategy.\nThis routing can be specified as:\n\n````\nrouter = ugal\n````\n\n\n\n\n\n\n\n## Chapter 5: External Applications and Skeletonization<a name=\"chap_appsAndSkeletonization\"></a>\n\n\n\n### Section 5.1: Basic Application porting<a name=\"sec_skel_basic\"></a>\n\n\n\nThere are three parts to successfully taking a C++ code and turning it into a scalable simulation.\n\n-   Symbol Interception: Rather than linking to MPI, pThreads, or other parallel libraries (or even calling `hostname`), these functions must be redirected to SST-macro rather than calling the native libraries on the machine running the simulator.\nYou get all redirected linkage for free by using\nthe SST compiler wrappers `sst++` and `sstcc` installed in the `bin` folder.\n-   Skeletonization: While SST-macro can run in emulation mode, executing your entire application exactly, this is not scalable.  To simulate at scale (i.e. 1K or more MPI ranks) you must strip down or \"skeletonize\" the application to the minimal amount of computation.  The energy and time cost of expensive compute kernels are then simulated via models rather than explicitly executed.\n-   Process encapsulation: Each virtual process being simulated is not an actual physical process. It is instead modeled as a lightweight user-space thread.  This means each virtual process has its own stack and register variables, but not its own data segment (global variables).\nVirtual processes share the same address space and the same global variables.  A Beta version of the auto-skeletonizing clang-based SST compiler is available with the 7.X releases. If the Beta is not stable with your application, manual refactoring may be necessary if you have global variables.\n\nNow in Beta, another possible feature is available:\n\n-   Memoization hooks: Rather than building an app for simulation, build an app with special profiling hooks. There is no skeletonization or redirected linkage, but the runtime or performance counters obtained by running should be used to build models for simulation.\n\nThere are generally 3 modes of using an application common with SST/macro:\n\n-   Simulation: As lightweight as possible without sacrificing accuracy. Intended to be used for performance estimation at large scales.\n-   Emulation/Virtualization: Run a parallel or distributed application within a single simulator thread/process - primarily useful for debugging.\n-   Memoization: Run a full application within the simulator, collecting performance counters or timers on critical sections\n\n\n\n|  | Simulator hooks | Symbol interception | Skeletonization | Process encapsulation |\n|--|-----------------|---------------------|-----------------|-----------------------|\n| Simulation | Yes | Yes | Yes | Yes |\n| Virtualization | Yes | Yes | No | Yes |\n| Memoization | Yes | No | No | No |\n\n\n#### 5.1.1: Loading external skeletons with the standalone core<a name=\"subsec_externalAppStandalone\"></a>\n\n\n\nYou should always write your own skeleton applications in an external folder rather then integrating directly into the `sstmac` executable.\nExisting make systems can be used unmodified. Rather than producing an executable, though, SST/macro produces a shared library.\nThese shared libraries are then imported into the main `sstmac` executable.\n\nIf you follow the example in the `skeletons/sendrecv` folder,\nthe Makefile shows how to generate an importable skeleton.\nIf you are using `sst++`, it will automatically convert executables into loadable libraries.\nIf your application is named `runapp`, you would run it with `sstmac`:\n\n````\n./runapp -f parameters.ini --exe=./runapp\n````\ndirecting to load the library as a skeleton executable.\n\n### Section 5.2: Auto-skeletonization with Clang<a name=\"sec_autoSkeletonization\"></a>\n\n\n\nThe build of the Clang toolchain is described in Section [2.3](#sec_buildingClang). \nThis enables a source-to-source translation capability in the `sst++` compiler that can auto-skeletonize computation and fix global variable references.\nSome of this can be accomplished automatically (global variables), but most of it (removing computation and memory allocations) must occur through pragmas.\nA good example of skeletonization can be found in the lulesh2.0.3 example in the skeletons folder. Most of the available SST pragmas are used there.\nPragmas are preferred since they allow switching easily back and forth between skeleton and full applications.\nThis allows much easier validation of the simulation. The section here briefly introduces the SST pragma language.\nA complete tutorial on all available pragmas is given in Chapter [6](#clangTutorial).\n\n#### 5.2.1: Redirecting Main<a name=\"subsec_redirectMain\"></a>\n\n\n\nYour application's `main` has to have its symbols changed.\nThe simulator itself takes over `main`.\nSST-macro therefore has to capture the function pointer in your code and associate it with a string name for the input file.\nThis is automatically accomplished by defining the macro `sstmac_app_name` either in your code or through a `-D=` build flag to the name of your application (unquoted!). The value of the macro will become the string name used for launching the application via `node.app1.name=X`.\nEven without Clang, this works for C++. For C, Clang source-to-source is required.\n\n#### 5.2.2: Memory Allocations<a name=\"subsec_memoryAllocations\"></a>\n\n\n\nTo deactivate memory allocations in C code that uses `malloc`, use:\n````\n#pragma sst malloc\n  void* ptr = malloc(...)\n````\nprior to any memory allocations that should be deactivated during skeleton runs, but active during real runs.\n\nSimilarly, for C++ we have\n````\n#pragma sst new\n  int* ptr = new int[...]\n````\n\n#### 5.2.3: Computation<a name=\"subsec_computation\"></a>\n\n\n\nIn general, the SST compiler captures all `#pragma omp parallel` statements.\nIt then analyzes the for-loop or code block and attempts to derive a computational model for it.\nThe computational models are quite simple (skeleton apps!), \nbased simply on the number of flops executed and the number of bytes read (written) from memory.\nConsider the example:\n\n````\ndouble A[N], B[N];\n#pragma omp parallel for\nfor (int i=0; i < N; ++i){\n  A[i] = alpha*A[i] + B[i];\n}\n````\nThe SST compiler deduces 16N bytes read, 8N bytes written, and 16N flops (or 8N if fused-multiplies are enabled).\nBased on processor speed and memory speed, it then estimates how long the kernel will take without actually executing the loop.\nIf not wanting to use OpenMP in the code, `#pragma sst compute` can be used instead of `#pragma omp parallel`.\n\n#### 5.2.4: Special Pragmas<a name=\"subsec_specialPragams\"></a>\n\n\n\nMany special cases can arise that break skeletonization.\nThis is often not a limit of the SST compiler, but rather a fundemental limitation in the static analysis of the code.\nThis most often arises due to nested loops. Consider the example:\n\n````\n#pragma omp parallel for\nfor (int i=0; i < N; ++i){\n  int nElems = nElemLookup[i];\n  for (int e=0; e < nElems; ++e){\n  }\n}\n````\nAuto-skeletonization will fail. The skeletonization converts the outer loop into a single call to an SST compute model.\nHowever, the inner loop can vary depending on the index.\nThis data-dependency breaks the static analysis.\nTo fix this, a hint must be given to SST as to what the \"average\" inner loop size is.\nFor example, it may loops nodes in a mesh. In this case, it may almost always be 8.\n\n````\n#pragma omp parallel for\nfor (int i=0; i < N; ++i){\n  int nElems = nElemLookup[i];\n  #sst replace nElems 8\n  for (int e=0; e < nElems; ++e){\n  }\n}\n````\nThis hint allows SST to skeletonize the inner loop and \"guess\" at the data dependency.\n\n\n\n#### 5.2.5: Skeletonization Issues<a name=\"subsec_skeletonIssues\"></a>\n\n\n\nSkeletonization challenges fall into three main categories:\n\n\n-   Data structures - Memory is a precious commodity when running large simulations, so get rid of every memory allocation you can.\n-   Loops - Usually the main brunt of CPU time, so get rid of any loops that don't contain MPI calls or calculate variables needed in MPI calls.\n-   Communication buffers - While you can pass in real buffers with data to SST-macro MPI calls and they will work like normal, it is relatively expensive. If they're not needed, get rid of them.\n\n\n\n\n\nThe main issue that arises during skeletonization is data-dependent communication.  \nIn many cases, it will seem like you can't remove computation or memory allocation because MPI calls depend somehow on that data.  \nThe following are some examples of how we deal with those:\n\n\n-   Loop convergence - In some algorithms, the number of times you iterate through the main loop depends on an error converging to near zero, or some other converging mechanism.  This basically means you can't take out anything at all, because the final result of the computation dictates the number of loops.  In this case, we usually set the number of main loop iterations to a fixed number.\n-   Particle migration - Some codes have a particle-in-cell structure, where the spatial domain is decomposed among processes, and particles or elements are distributed among them, and forces between particles are calculated.  When a particle moves to another domain/process, how many particles migrate and how far depends on the actual computed forces. However, in the skeleton, we are not actually computing the forces - only estimated how long the force computation took.  If all we need to know is that this migration/communication happens sometimes, then we can just make it happen every so many iterations, or even sample from a probability distribution.\n-   AMR - Some applications, like adaptive mesh refinement (AMR), exhibit communication that is entirely dependent on the computation.  In this case, skeletonization again depends on making approximations or probability estimates of where and when box refinement occurs without actually computing everything.\n\nFor applications with heavy dynamic data dependence, we have the following strategies:\n\n-   Traces  - revert to DUMPI traces, where you will be limited by existing machine size.  Trace extrapolation is also an option here.\n-   Synthetic - It may be possible to replace communication with randomly-generated data and decisions, which emulate how the original application worked. This occurs in the CoMD skeleton.\n-   Hybrid - It is possible to construct meta-traces that describe the problem from a real run, and read them into SST-macro to reconstruct the communication that happens.  This occurs in the `boxml` aplications.\n\n### Section 5.3: Process Encapsulation<a name=\"sec_processEncapsulation\"></a>\n\n\n\nAs mentioned above, virtual processes are not real, physical processes inside the OS.\nThey are explicitly managed user-space threads with a private stack, but without a private set of global variables.\nWhen porting an application to SST/macro, global variables used in C programs will not be mapped to separate memory addresses causing incorrect execution or even segmentation faults.\nIf you have avoided global variables, there is no major issue.  \nIf you have read-only global variables with the same value on each machine, there is still no issue.\nIf you have mutable global variables, you should use the `sst++` clang-based compiler wrappers to auto-refactor your code (Section [5.2](#sec_autoSkeletonization)).\nThis feature is current labeled Beta, but is stable for numerous tests and will be fully supported for release 7.1.\n\n\n\n\n## Chapter 6: Clang Source-to-Source Auto-Skeletonization via Pragmas<a name=\"clangTutorial\"></a>\n\n\n\nThere are three main examples of auto-skeletonization with pragmas in the SST-macro source code in the `skeletons` directory.\nThese applications are Lulesh, HPCG, and CoMD.\nThe auto-skeletonizing compiler is designed to do three main things:\n\n\n-   Redirect global variable accesses to thread-specific values\n-   Turn off large memory allocations that would prevent scalable simulation\n-   Estimate time of compute-intensive kernels instead of executing them\n\n### Section 6.1: Pragma Overview<a name=\"sec_pragmaOverview\"></a>\n\n\n\n\n![Figure 30: Source-to-source transformation workflow for SST compiler. For C source files, g++ can be swapped with gcc. The choice of underlying compiler is actually arbitrary and can be clang, gcc, icc, etc.](https://github.com/sstsimulator/sst-macro/blob/devel/docs/manual/figures/compilerWorkflow.png) \n\n*Figure 30: Source-to-source transformation workflow for SST compiler. For C source files, g++ can be swapped with gcc. The choice of underlying compiler is actually arbitrary and can be clang, gcc, icc, etc.*\n\n\n\n#### 6.1.1: Compiler workflow<a name=\"subsec_compilerWorkflow\"></a>\n\n\n\nThe source-to-source compiler operates on a pre-processed source file.\nThe source code transformation generates a temporary source file.\nThis temporary source file is then compiled into the target object file.\nGlobal variables require static registration of C++ variables.\nHere another temporary C++ source file (even if the original file is C)\nis generated that has all static global variable registrations.\nThe corresponding object file is merged with the original object file,\ncreating a complete SST-macro object file with the transformed code and C++ static registrations.\nThis workflow is shown in Figure [30](#fig_compilerWorkflow).\n\n#### 6.1.2: Compiler Environment Variables<a name=\"subsec_compilerEnv\"></a>\n\n\n\n##### SSTMAC\\_SRC2SRC: Default 1<a name=\"subsubsec_env_src2src\"></a>\n\n\n\nIf set to zero, deactivates the source-to-source transformation. \nThe compiler wrapper will then compile the code into the simulator, but will not redirect any global variable accesses or perform any skeletonization.\n\n##### SSTMAC\\_SKELETONIZE: Default 0<a name=\"subsubsec_env_skeletonize\"></a>\n\n\n\nIf set to zero, deactivates skeletonization. \nThis does not deactivate global variable redirection.\nThus, with `SSTMAC_SRC2SRC=1` and `SSTMAC_SKELETONIZE=0`,\nSST-macro will act as an MPI emulator executing a full code but with global variables refactored to maintain correctness.\n\n\n\n\n\n##### SSTMAC\\_HEADERS: No default<a name=\"subsubsec_env_headers\"></a>\n\n\n\nThe compiler wrapper will only redirect global variables that it knows should definitely be modified.\nAll global variables found in source files will be redirected.\n`extern` global variables found in header files are more difficult.\nCertain system global variables like `stderr` should not be modified and so are left as global variable constants.\nBy default, global variables in a header file are NOT redirected unless explicitly specified in a header configuration file.\nThe variable `SSTMAC_HEADERS` should give the full path of a file containing the list of header files.\nHeader file paths in the file should be one per line and should be the full path, not a relative path.\n\n##### SSTMAC\\_DELETE\\_TEMP\\_SOURCES: Default 1<a name=\"subsubsec_env_delete_temp_objects\"></a>\n\n\n\nIf non-zero, the compiler cleans up all temporary source files.\nIf you wish to keep temporary files to view them for debugging, set to 0.\nAll temporary, intermediate source files will otherwise be deleted at the end of compilation.\nThe source files are re-formatted using clang-format to make them more readable.\nThe actual source files given to the compiler are very mess (with very long lines) since the source-to-source tries to preserve the original line numbers for debugging.\n\n##### SSTMAC\\_DELETE\\_TEMP\\_OBJECTS: Default 1<a name=\"subsubsec_env_delete_temp_sources\"></a>\n\n\n\nIf non-zero, the compiler cleans up all temporary object files.\nIf you wish to keep temporary files for debugging, set to 0.\nDue to issues with some linkers, debug symbols do not appear correctly in gdb or lldb unless the original object files are kept.\nIf you wish to get sensible output from the debugger, make sure this is set to 0.\n\n### Section 6.2: Basic Replacement Pragmas<a name=\"sec_basicReplacementPragmas\"></a>\n\n\n\nWhen skeletonization is active (see `SSTMAC_SKELETONIZE`), these pragmas will cause replacements in the original source code.\nPragmas apply to the next statement in the source code.\nFor compound statements such as a for-loop with a multi-statement body, the pragma applies to the entire for-loop.\n\n#### 6.2.1: pragma sst delete: no arguments<a name=\"subsec_pragma_sst_delete\"></a>\n\n\n\nThis deletes the next statement from the source code.\nIf the statement declares a variable that is used later in the code, this will cause a compile error.\nConsider an example from the Lulesh source code.\n\n````\n#pragma sst delete\n    testnorms_data.values[i] = normr/normr0;\n````\nIn the skeleton, the residual is not actually computed and the `testnorms_data` array is not actually allocated.\nThus this statement should be deleted and not actually executed in the skeleton.\n\n#### 6.2.2: pragma sst replace [to\\_replace:string] [new\\_text:C++ expression]<a name=\"subsec_pragma_sst_replace\"></a>\n\n\n\nThis applies a string replace to a variable or function call in the next statement.\nConsider an example from Lulesh.\n\n````\n#pragma sst replace volo 1\n   deltatime() = (Real_t(.5)*cbrt(volo(0)))/sqrt(Real_t(2.0)*einit);\n````\nThe function call `volo(0)` is not valid in the skeleton since volumes are not actually computed.\nHere we simply estimate that all cells have unit volume replacing `volo(0)` with `1`.\n\n#### 6.2.3: pragma sst init [new\\_value:string]<a name=\"subsec_pragma_sst_init\"></a>\n\n\n\nThis pragma can only apply to a binary equals operator assigning a value.\nThe pragma changes the right-hand side to use the given new value.\nFor example, in Lulesh:\n\n````\n#pragma sst init nullptr\n  destAddr = &domain.commDataSend[pmsg * maxPlaneComm] ;\n````\nThe send buffer `domain.commDataSend` is not allocated in the skeleton and thus is not valid to use.\nThe pragma causes the skeleton to simply set `destAddr` to `nullptr`.\n\n#### 6.2.4: pragma sst return [new\\_value:C++ expression]<a name=\"subsec_pragma_sst_return\"></a>\n\n\n\nPragma is equivalent to `pragma sst init`. This replaces the target of a return statement with the given expression.\nThis produces a compiler error if applied to anything but a return statement.\n\n#### 6.2.5: pragma sst keep<a name=\"subsec_pragma_sst_keep\"></a>\n\n\n\nDuring the skeletonization process, some transformations occur automatically even without pragmas. \nFor example, all MPI calls have input buffers converted to null pointers to indicate a simulated MPI call.\nIf the MPI call should be emulated with real payloads, the MPI call must be explicitly marked with `pragma keep`.\nAn example can be found in the HPCG skeleton:\n\n````\n#pragma sst keep\n  MPI_Allreduce(&localNumberOfNonzeros, &totalNumberOfNonzeros, ...)\n````\nThe actual allreduce operation is carried out, summing the the local number into the total number of nonzeroes.\n\n#### 6.2.6: pragma sst keep\\_if [condition:C++ bool expression]<a name=\"subsec_pragma_sst_keep_if\"></a>\n\n\n\nMore control over whether transformations are skipped is provided by `keep_if`.\nAn example is found in CoMD.\n\n````\n#pragma sst keep_if count < 16\n   MPI_Allreduce(sendBuf, recvBuf, count, MPI_DOUBLE, MPI_SUM, MPI_COMM_WORLD);\n````\nAny small allreduce operations are kept. \nAny allreduce operations larger than a given cutoff are simulated without emulating the actual buffer operations.\n\n#### 6.2.7: pragma sst empty<a name=\"subsec_pragma_sst_empty\"></a>\n\n\n\nThis pragma is applied to functions. The function prototype is kept, but an empty body is inserted instead of the actual code.\nThis can be useful for deleting large blocks of computation inside a function.\n\n#### 6.2.8: pragma sst branch\\_predict [condition:C++ expression]<a name=\"subsec_pragma_sst_branch_predict\"></a>\n\n\n\nThe branch prediction pragma can be applied in two different contexts.\nWe will revisit the pragma in the context of compute skeletonization below.\nThe branch prediction pragma should only be applied to an if-statement.\nMuch like the replace pragmas, it swaps out the given if condition with a new expression.\n\nThe branch prediction pragmas become necessary when skeletonizing.\nCertain values may not be computed or certain variables marked null.\nIf these values are then used in an if predicate,\nthe skeletonizing compiler cannot deduce the correct behavior for the application.\nWhen an ambiguous predicate is found, the compiler will usually print a warning and just assume the predicate is false.\nPredicates are often almost always true or almost always false. \nThus most uses of this pragma will simply supply `true` or `false` as the replacement.\nHowever, any arbitrary C++ boolean expression can be given as the replacement.\nThe new predicate expression (like the original), must not involve any null variables.\n\n### Section 6.3: Memory Allocation Pragmas<a name=\"sec_memAllocPragmas\"></a>\n\n\n\n#### 6.3.1: pragma sst malloc<a name=\"subsec_pragma_sst_malloc\"></a>\n\n\n\nApplied to any statement in which the right-hand side is a malloc. This sets the left-hand side to `NULL`.\nThis is critical for turning off large memory allocations on data structures not required for control-flow.\n\n\n#### 6.3.2: pragma sst new<a name=\"subsec_pragma_sst_new\"></a>\n\n\n\nApplied to any statement in which the right-hand side a C++ operator new. This sets the left-hand side to `nullptr`.\nThis is critical for turning off large memory allocations on data structures not required for control-flow.\n\n### Section 6.4: Data-Driven Type Pragmas<a name=\"ddtPragmas\"></a>\n\n\n\n#### 6.4.1: pragma sst null\\_ptr<a name=\"subsec_pragma_sst_null_ptr\"></a>\n\n\n\nThis applies to variable declarations. If pragma is not applied to a declaration, a compiler error is given.\nA null variable is one in which all operations involving the variable should be deleted.\nThis usually applies to large data arrays that should never be allocated and therefore never dereferenced.\nAn example can be seen in CoMD:\n\n````\n#pragma sst null_ptr\n   int* nAtoms;         //!< total number of atoms in each box\n````\nThe array is not allocated and all statements operating on the array are deleted.\n\nThis pragma is much more powerful than simply using `pragma sst new`.\n`pragma sst new` simply turns off a given memory allocation setting it to a null value.\nIf the array is dereferenced later in code, this causes a segmentation fault.\nBy marking a declaration as null, the compiler can flag where segmentation faults would occur when running the skeleton.\n\nIn most cases, all operations involving the null variable are deleted.\nHowever, there may be cases where the compiler may decide deleting an operation cannot be done automatically since\nit may affect control flow, e.g., if the variable is used inside an if-statement.\nWhen this occurs, a compiler error is thrown flagging where the ambiguity occurs.\nAnother pragma must then be applied to that statement to tell the compiler how to proceed.\n\n#### 6.4.2: pragma sst null\\_type [type alias] [list allowed functions]<a name=\"subsec_pragma_sst_null_type\"></a>\n\n\n\nThis applies to C++ class variable declarations. If pragma is not applied to a declaration, a compiler error is given.\nThis essentially works the same way as `null_ptr`, but allows certain member functions to be kept instead of deleted.\nConsider an example from Lulesh:\n\n````\n#pragma sst null_type sstmac::vector size resize empty\n   std::vector<Real_t> m_x ;  /* coordinates */\n```` \nHere we wish to indicate the vector is \"null\" and should not actually allocate memory or allow array accesses.\nHowever, we still wish to track the vector size and whether it is empty.\nThe first argument to the pragma is a new type name that implements the \"alias\" functionality.\nFor `std::vector`, SST-macro automatically provides the alias.\nFor illustration, that code is reproduced here:\n\n````\nnamespace sstmac {\nclass vector {\n public:\n  void resize(unsigned long sz){\n    size_ = sz;\n  }\n\n  unsigned long size() const {\n    return size_;\n  }\n\n  template <class... Args>\n  void push_back(Args... args){\n    ++size_;\n  }\n\n  template <class... Args>\n  void emplace_back(Args... args){\n    ++size_;\n  }\n\n  bool empty() const {\n    return size_ == 0;\n  }\n\n private:\n  unsigned long  size_;\n};\n}\n````\nThis empty vector class allows the type to track its size, but not actually hold any data.\nAll places in the Lulesh code that an `std::vector` is used are substituted with the new type.\nThe remaining arguments to the pragma are the list of functions we wish to mark as valid.\nIn this case, even though the alias vector class provides more functions, we only allow `size`, `resize`, and `empty` to be called.\n\n\n### Section 6.5: Compute Pragmas<a name=\"sec_computePragmas\"></a>\n\n\n\n#### 6.5.1: pragma sst compute and pragma omp parallel<a name=\"subsec_pragma_sst_compute\"></a>\n\n\n\nCompute-intensive should not be executed natively.\nInstead, a compute model should be used to estimate the elapsed time.\nCompute model replacements are automatically triggered by any OpenMP parallel pragmas.\nThe corresponding block or for-loop is not executed, instead calling out to a compute model to estimate time.\nCurrently, compute modeling is done via a very basic static analysis.\nThe static analysis attempts to count the number of integer and floating point operations.\nIt also estimates the number of memory reads and writes.\nThese four counters are passed to a coarse-grained processor model for time estimates.\nFor more details, see `sstmac_compute_detailed` in the source code.\nNumerous examples can be found in the Lulesh, HPCG, and CoMD skeleton applications.\n\n#### 6.5.2: pragma sst loop\\_count [integer: C++ expression]<a name=\"subsec_pragma_sst_loop_count\"></a>\n\n\n\nIf the `sst compute` or `omp parallel` pragma are applied to an outer loop with one or more inner loops,\nthe compute model static analysis might fail.\nThis occurs when the inner loop control flow depends on the actual execution.\nAny variables declared inside the compute block are not valid to use in the compute estimate since they will be skeletonized and deleted.\nOnly variables in scope at the beginning of the outer loop are safe to use in compute modeling.\n\nWhen the static analysis fails, a corresponding compiler error is thrown.\nThis usually requires giving a loop count hint.\nConsider the example from HPCG:\n\n````\n#pragma omp parallel for\n  for (local_int_t i=0; i< localNumberOfRows; i++) {\n    int cur_nnz = nonzerosInRow[i];\n   #pragma sst loop_count 27\n    for (int j=0; j<cur_nnz; j++) mtxIndL[i][j] = mtxIndG[i][j];\n  }\n````\nThe static analysis fails on `cur_nnz`.\nHowever, that value is almost always 27.\nThus we can safely tell the compiler to just assume the loop count is 27.\n\n#### 6.5.3: pragma sst branch\\_predict [float: C++ expression]<a name=\"subsec_pragma_sst_branch_predict\"></a>\n\n\n\nSimilar to the way that loop counts can break the static analysis, if statements inside a loop skeletonized with `omp parallel` or `sst compute` can also be problematic.\nIf the predicate depends on a variable declared inside the skeletonzied block,\nthe static analysis will break since it cannot predict when and how often to assume true or false.\nIn contrast to the branch prediction pragma previously used, branch prediction pragmas inside a compute block must give a number between 0 and 1.\nThis can either be a literal float or expression that computes a float value.\nConsider an example from CoMD:\n\n````\n#pragma sst branch_predict 0.2\n  if(r2 <= rCut2 && r2 > 0.0){\n````\nInside the compute block, a compute may or may not occur depending on whether a particle distance is less than a cutoff.\nBased on the way CoMD constructs unit cells and halo regions, running CoMD shows that about 1 in 5 neighbor interactions are actually below the cutoff.\nThus we given the branch prediction the hint 0.2.\n\n#### 6.5.4: pragma sst advance\\_time [units] [time to advance by]<a name=\"subsec_pragma_sst_advance_time\"></a>\n\n\n\nThis pragma advances the simulator time by the specified amounts of time. It can be placed before any statement. The units can be the following: sec, msec, usec or nsec for Seconds, milliseconds, microseconds and nanoseconds respectively. \n\n\n\n\n## Chapter 7: Issues and Limitations<a name=\"ch_issues\"></a>\n\n\n\n### Section 7.1: Polling in applications<a name=\"sec_polling\"></a>\n\n\n\nUse of probe non-blocking functions in a loop, such as:\n\n\n````\nwhile(!flag){\n MPI_Iprobe( 0, 0, MPI_COMM_WORLD, &flag, &status );\n}\n````\ncreates problems for the simulation. Virtual time never advances in the MPI\\_Iprobe call. \nThis causes an infinite loop that never returns to the discrete event manager. \nEven if configured so that time progresses, the code will work but will take a very long time to run.\n\n### Section 7.2: Fortran<a name=\"subsec_issues_fortran\"></a>\n\n\n\nSST-macro previously provided some experimental support for Fortran90 applications. \nThis has been discontinued for the foreseeable future.\nFor profiling existing apps written with Fortran, DUMPI traces can still be generated. \n\n\n\n\n\n\n\n## Chapter 8: Detailed Parameter Listings<a name=\"chapter_parameters\"></a>\n\n\nThe following chapter is organized by parameter namespaces. Tables in each namespace are organized as\n\n\n\n| Name (type) | Default if not given | Allowed  Values | Description |\n|-------------|----------------------|-----------------|-------------|\n|             |                      |                 |             |\n\nwhich lists the possible parameter names, allowed values, and brief descriptions.\nMore detailed descriptions of particular parameter values are found in the documentation in previous chapters.\n\nThe allowed parameter types are:\n\n\n| int | Any integer |\n|-----|-------------|\n| long | Any integer value, but guaranteed not to overflow for long integers |\n| bool | Either \"true\" or \"false\" as lowercase string |\n| time | Any valid float value followed by time units (s,ms,us,ns,ps) |\n| freq | Any valid float value followed by frequency units (Hz, MHz, GHz) |\n| bandwidth | Any valid float value followed by bandwidth units (b/s, B/s, Mb/s, MB/s, etc) |\n| byte length | Any positive integer followed by length units (B, KB, MB, GB,TB) |\n| string | An arbitrary string |\n| vector of X | A vector of type X with entries separated by spaces |\n| filepath | A valid filepath to an existing file, either absolute or relative |\n| quantiy | A catch-all for a quantity with units. Any of frequency, bandwidth, byte length, or time can be given |\n\n### Section 8.1: Global namespace<a name=\"sec_globalParams\"></a>\n\n\n\n\n| Name (type) | Default | Allowed | Description |\n|-------------|---------|---------|-------------|\n| sst\\_nthread (int) | 1 | Positive int | Only relevant for multi-threading. Specifying more threads than cores can lead to deadlock. |\n| serialization\\_buffer\\_size (byte length) | 16 KB |  | Size to allocate for buffering point-to-point sends in parallel. This should set be large enough to handle serialization of all messages in a given time window, but not so large that significant space is wasted. |\n| backup\\_buffer\\_size (byte length) | 1 MB |  | Size to allocate for special overflow buffers when the standard buffer is overrun. This is the base size and continues to grow if buffers overflow again in a time window. This should be large enough so that buffers do not continuously overflow, but not so large that memory gets filled up. |\n| cpu\\_affinity (vector of int) | No default | Invalid cpu IDs give undefined behavior | When in multi-threading, specifies the list of core IDs that threads will be pinned to. |\n\n### Section 8.2: Namespace \"topology\"<a name=\"sec_topologyParams\"></a>\n\n\n\n\n| Name (type) | Default | Allowed | Description |\n|-------------|---------|---------|-------------|\n| geometry (vector of int) | No default | See Topology section | Geometry configuration of the topology. For details of the keyword, users should refer to Section [4](#chapter_topologies) |\n| auto (bool) | false | Whether to auto-generate the topology based on the application size. |\n| name (string) | No default | torus, cascade, dragonfly, fat\\_tree, crossbar, tapered\\_fat\\_tree | The name of the topology to build. For details, see Section [4](#chapter_topologies) |\n| seed (long) | System time |  | If no value given, random numbers for topology will be generated from system time |\n| concentration (int) | 1 | Positive int | The number of nodes per network switch. For indirect networks, this is the number of nodes per leaf switch. |\n| num\\_leaf\\_switches (int) | No default | Positive int | Only relevant for fat trees. This is the number of switches at the lowest level of the tree that are connected to compute nodes. Depending on how the fat tree is specified, this number may not be required. |\n| k (int) | No default | int >= 2 | The branching fraction of a fat tree. k=2 is a binary tree. k=4 is a quad-tree. |\n| l (int) | No default | Positive int | The number of levels in a fat tree. |\n| num\\_inj\\_switches\\_per\\_subtree | No default | Positive int | For a tapered tree, the number of injection switches, N(inj), within an aggregation tree that connect directly toc ompute nodes. |\n| num\\_agg\\_switches\\_per\\_subtree | No default | Positive int | For a tapered tree, the number of aggregations witches per aggregation tree linking injection switches to the core. |\n| num\\_agg\\_subtrees | No default | Positive int | For a tapered fat tree with 3 levels (injection, aggregation, core), this gives the number, N(agg), of aggregation subtrees. To find the total number, N(tot) of injection (leaf) switches, we have N(tot) = N(agg) X N(inj). |\n| num\\_core\\_switches | No default | Positive int | The total number of core switches in a tapered tree linking the individual aggregation trees. |\n| group\\_connections (int) | No default | Positive int | For cascase ir dragonfly, the number of intergroup connections on each switch in a Dragonfly group |\n| redundant (vector of int) | vector of 1's | Positive ints | For Cartesian topologies (hypercube, cascadem, dragonfly, torus) this specifies a bandwidth (redundancy) multiplier for network links in each dimension. |\n\n### Section 8.3: Namespace \"node\"<a name=\"sec_nodeParams\"></a>\n\n\n\n\n| Name (type) | Default | Allowed | Description |\n|-------------|---------|---------|-------------|\n| name (string) | simple | simple | The type of node model (level of detail) for node-level operations |\n\n#### 8.3.1: Namespace \"node.nic\"<a name=\"subsec_node_nic_Params\"></a>\n\n\n\n\n| Name (type) | Default | Allowed | Description |\n|-------------|---------|---------|-------------|\n| name (string) | No default | pisces, logp, sculpin | The type of NIC model (level of detail) for modeling injection of messages (flows) to/from the network. |\n| negligible\\_size (byte length) | 256B |  | Messages (flows) smaller than size will not go through detailed congestion modeling. They will go through a simple analytic model to compute the delay. |\n\n##### Namespace \"node.nic.ejection\"<a name=\"subsubsec_node_nic_ejection_Params\"></a>\n\n\nThese parameters do not need to be specified, but can be given.\nGenerally, the simulation assumes an infinite buffer size (unlimited memory) and no latency.\nAll other parameters can be filled in from `node.nic.injection`.\n\n##### Namespace ``node.nic.injection\"<a name=\"subsubsec_node_nic_injection_Params\"></a>\n\n\n\n\n#### 8.3.2: Namespace ``node.memory\"<a name=\"subsec_node_memory_Params\"></a>\n\n\n\n\n| Name (type) | Default | Allowed | Description |\n|-------------|---------|---------|-------------|\n| model (string) | No default | logP, pisces | The type of memory model (level of detail) for modeling memory transactions. |\n| arbitrator (string) | cut\\_through | null, simple, cut\\_through | The type of arbitrator. See arbitrator descriptions above. |\n| latency (time) | No default |  | The latency of single memory operation |\n| total\\_bandwidth | No default |  | The total memory bandwidth possible across all memory controllers. |\n| max\\_single\\_bandwidth | Computed |  | The maximum memory bandwidth of a single stream of requests. Essentially the bandwidth of a single memory controller. If not given, this defaults the value of total\\_bandwidth. |\n\n#### 8.3.3: Namespace \"node.os\"<a name=\"subsec_node_os_Params\"></a>\n\n\n\n\n| Name (type) | Default | Allowed | Description |\n|-------------|---------|---------|-------------|\n| compute\\_scheduler (string) | simple | simple, cpuset | The level of detail for scheduling compute tasks to cores. Simple looks for any empty core. cpuset allows bitmasks to be set for defining core affinities. |\n| stack\\_size (byte length) | 64 KB |  | The size of user-space thread stack to allocate for each virtual application |\n| stack\\_chunk\\_size (byte length) | 1 MB |  | The size of memory to allocate at a time when allocating new thread stacks. Rather than allocating one thread stack at a time, multiple stacks are allocated and added to a pool as needed. |\n\n#### 8.3.4: Namespace ``node.proc\"<a name=\"subsec_node_proc_Params\"></a>\n\n\n\n| Name (type) | Default | Allowed | Description |\n|-------------|---------|---------|-------------|\n| ncores (int) | No default | Positive int | The number of cores contained in a processor (socket). Total number of cores for a node is ncores X nsockets. |\n| frequency | No default |  | The baseline frequency of the node |\n| parallelism (double) | 1.0 | Positive number | Fudge factor to account for superscalar processor. Number of flops per cycle performed by processor. |\n\n### Section 8.4: Namespace \"mpi\"<a name=\"sec_mpi_Params\"></a>\n\n\n\n\n| Name (type) | Default | Allowed | Description |\n|-------------|---------|---------|-------------|\n| test\\_delay (time) | 0 |  | The minimum time spent by MPI on each MPI\\_Test call |\n| iprobe\\_delay (time) | 0 |  | The minimum time spent by MPI on each MPI\\_Iprobe call |\n| otf2\\_dir\\_basename (time) | empty string |  | Enables OTF2 and combines this parameter with a timestamp to name the archive |\n\n#### 8.4.1: Namespace ``mpi.queue\"<a name=\"subsec_mpi_queue_Params\"></a>\n\n\n\n\n| Name (type) | Default | Allowed | Description |\n|-------------|---------|---------|-------------|\n| max\\_vshort\\_msg\\_size (byte length) | 512B |  | The maximum size to use the very short message protocol. Small messages are sent eagerly using special pre-allocated mailbox buffers. Sends complete immediately. |\n| max\\_eager\\_msg\\_size (byte length) | 8KB |  | The maximum size to use the RDMA eager protocol. This also uses buffers to send message, but instead of using pre-allocated mailboxes, it coordinates an RDMA get. Sends complete immediately. |\n| post\\_rdma\\_delay (time) | 0 |  | The minimum time spent by MPI posting each RDMA operation |\n| post\\_header\\_delay (time) | 0 |  | The mimimum time spent by MPI sending headers into pre-allocated mailboxes |\n| poll\\_delay (time) | 0 |  | The minimum time spent by MPI each time it polls for incoming messages |\n\n### Section 8.5: Namespace \"switch\"<a name=\"subsec_switch_Params\"></a>\n\n\n\n\n| Name (type) | Default | Allowed | Description |\n|-------------|---------|---------|-------------|\n| name (string) | No default | logp, pisces, sculpin | The type of switch model (level of detail) for modeling network traffic. |\n| mtu (byte length) | 1024B |  | The packet size. All messages (flows) will be broken into units of this size. |\n\n#### 8.5.1: Namespace \"switch.router\"<a name=\"subsec_switch_router_Params\"></a>\n\n\n\n\n| Name (type) | Default | Allowed | Description |\n|-------------|---------|---------|-------------|\n| name (string) | No default | minimal, valiant, ugal, dragonfly\\_minimal, fat\\_tree | The name of the routing algorithm to use for routing packets. |\n| ugal\\_threshold (int) | 0 |  | The minimum number of network hops required before UGAL is considered. All path lengths less than value automatically use minimal. |\n\n\n#### 8.5.2: Namespace \"switch.xbar\"<a name=\"subsec_switch_xbar_Params\"></a>\n\n\n\n\n| Name (type) | Default | Allowed | Description |\n|-------------|---------|---------|-------------|\n| arbitrator (string) | cut\\_through | null, simple, cut\\_through | Bandwidth arbitrator for PISCES congestion modeling. Null uses simple delays with no congestion. Simple uses store-and-forward that is cheap to compute, but can have severe latency errors for large packets. Cut-through approximates pipelining of flits across stages. |\n| latency (time) | No default |  | The latency to traverse the component |\n| bandwidth | No default |  | The bandwidth of the arbitrator |\n| credits (byte length) | No default |  | The number of initial credits for the component. Corresponds to an input buffer on another component. In many cases, SST/macro can compute this from other parameters and fill in the value. In some cases, it will be required. |\n\n\n#### 8.5.3: Namespace ``switch.link\"<a name=\"subsec_switch_link_Params\"></a>\n\n\n\n| Name (type) | Default | Allowed | Description |\n|-------------|---------|---------|-------------|\n| arbitrator (string) | cut\\_through | null, simple, cut\\_through | Bandwidth arbitrator for PISCES congestion modeling. Null uses simple delays with no congestion. Simple uses store-and-forward that is cheap to compute, but can have severe latency errors for large packets. Cut-through approximates pipelining of flits across stages. |\n| latency (time) | No default |  | The latency to traverse the component |\n| bandwidth | No default |  | The bandwidth of the arbitrator |\n| credits (byte length) | No default |  | The number of initial credits for the component. Corresponds to an input buffer on another component. In many cases, SST/macro can compute this from other parameters and fill in the value. In some cases, it will be required. |\n\n\n\n### Section 8.6: Namespace \"appN\"<a name=\"sec_appN_Params\"></a>\n\n\nThis is a series of namespaces `app1`, `app2`, and so on for each of the launched applications. These should be contained within the `node` namespace.\n\n\n| Name (type) | Default | Allowed | Description |\n|-------------|---------|---------|-------------|\n| name (string) | No default | parsedumpi, cxx\\_full\\_main, cxx\\_empty\\_main | The name of the application to launch. Very few applications are built-in. Registration of external apps is shown starting in Section [3.5](#sec_tutorial_basicmpi). |\n| size (int) | No default | Positive int | The number of procs (MPI ranks) to launch. If launch\\_cmd given, this parameter is not required. |\n| start (int) | 0 |  | The time at which a launch request for the application will be made |\n| concentration (int) | 1 | Positive int | The number of procs (MPI ranks) per compute node |\n| core\\_affinities (vector of int) | Empty |  |  |\n| launch\\_cmd (string) | No default | Valid aprun or srun | This uses a launch command as would be found with ALPS or SLURM launchers on real systems, e.g. aprun -n 4 -N 1 |\n| indexing (string) | block | block, random, cart, node\\_id, coordinate | The indexing scheme for assign proc ID (MPI rank number) to compute nodes |\n| node\\_id\\_mapper\\_file (filepath) | No default |  | If using Node ID indexing, the file containing the node ID index list |\n| random\\_indexer\\_seed (long) | System time |  | The seed to use for a random allocation. If not specified, system time is used. |\n| allocation (string) | first\\_available | first\\_available, random, cart, node\\_id, coordinate | The scheme to use for allocating compute nodes to a given job. |\n| random\\_allocation\\_seed (long) | System time |  | For random allocation policy. If unspecified, system time is used as the seed. |\n| node\\_id\\_allocation\\_file (filepath) | No default |  | If using Node ID allocation, the file containing the list of node IDs to allocate for the job |\n| dumpi\\_metaname (filepath) | No default |  | If running DUMPI trace, the location of the metafile for configuring trace replay |\n| coordinate\\_file (filepath) | No default |  | If running using coordinate allocation or indexing, the path to the file containing the node coordinates of each proc (MPI rank) |\n| cart\\_sizes (vector of int) | No default |  | Launch a contiguous block of nodes in a Cartesian topology. This gives the size of each dimension in the block. |\n| cart\\_offsets (vector of int) | No default |  | Launch a contiguous block nodes in a Cartesian topology. This gives the offset in each dimension where the block begins. |\n| parsedumpi\\_timescale (double) | 1.0 | Positive float | If running DUMPI traces, scale compute times by the given value. Values less than 1.0 speed up computation. Values greater than 1.0 slow down computation. |\n| parsedumpi\\_terminate\\_percent (int) | 100 | 1-100 | Percent of trace. Can be used to terminate large traces early |\n| host\\_compute\\_timer (bool) | False |  | Use the compute time on the host to estimate compute delays |\n\n\n| Name (type) | Default | Allowed | Description |\n|-------------|---------|---------|-------------|\n| otf2\\_metafile (string) | No default | string | The root file of an OTF2 trace. |\n| otf2\\_timescale (double) | 1.0 | Positive float | If running OTF2 traces, scale compute times by the given value. Values less than 1.0 speed up computation. Values greater than 1.0 slow down computation. |\n| otf2\\_print\\_mpi\\_calls (bool) | false |  | Print MPI calls found in the OTF2 trace |\n| otf2\\_print\\_trace\\_events (bool) | false |  | Debugging flag that printsindividual trace events (which includes details such as when an MPI call begins, ends, and when a collective begins and ends |\n| otf2\\_print\\_time\\_deltas (bool) | false |  | Debugging flag that prints compute delays injected by the simulator |\n| otf2\\_warn\\_unknown\\_callback (bool) | false |  | Debugging flag the prints unknown callbacks |\n\n\n\n\n\n\n\n",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/BasicMPITutorial.tex": "%% !TEX root = manual.tex\n\n\\section{Basic MPI Program}\n\\label{sec:tutorial:basicmpi}\n\nLet us go back to the simple send/recv skeleton and actually look at the code.\nThis code should be compiled with SST compiler wrappers installed in the \\inlineshell{bin} folder.\n\n\\begin{CppCode}\n#include <stdlib.h>\n#include <stdio.h>\n#include <mpi.h>\n\nint main(int argc, char **argv) \n{\n  int message_size = 128;\n  int me, nproc;\n  int tag = 0;\n  int dst = 1;\n  int src = 0;\n  MPI_Status stat;\n\n  MPI_Init(&argc,&argv);\n  MPI_Comm world = MPI_COMM_WORLD;\n  MPI_Comm_rank(world,&me);\n  MPI_Comm_size(world,&nproc);\n\\end{CppCode}\nThe starting point is creating a main routine for the application.\nThe simulator itself already provides a \\inlinecode{main} routine.\nThe SST compiler automatically changes the function name to \\inlinecode{userSkeletonMain},\nwhich provides an entry point for the application to actually begin.\nWhen \\sstmacro launches, it will invoke this routine and pass in any command line arguments specified via the \\inlinefile{app1.argv} parameter.  Upon entering the main routine, \nthe code is now indistinguishable from regular MPI C++ code.  \nIn the parameter file to be used with the simulation, you must set\n\n\\begin{ViFile}\nnode {\n app1 {\n  exe = <PATH_TO_EXE>\n\\end{ViFile}\n\nWhile MPI would have produced an executable, SST works by loading shared object files using \\inlinecode{dlopen}.\nTo get SST to load the skeleton, you must specify the path of the ``executable\" in the input file.\nUsing \\inlinecode{dlopen} tricks, SST finds the main function in the .so file and calls it to spawn the skeleton app.\nJust as an executable can only have one main, SST shared object files can only have a single executable in them at a time.\n\nAt the very top of the file, the \\inlineshell{mpi.h} header is actually mapped by the SST compiler to an \\sstmacro header file.\nThis header provides the MPI API and configures MPI function calls to link to \\sstmacro instead of the real MPI library.\nThe code now proceeds:\n\n\\begin{CppCode}\n  if (nproc != 2) {\n    fprintf(stderr, \"sendrecv only runs with two processors\\n\");\n      abort();\n  }\n  if (me == 0) {\n    MPI_Send(NULL, message_size, MPI_INT, dst, tag, world);\n    printf(\"rank %i sending a message\\n\", me);\n  }\n  else {\n    MPI_Recv(NULL, message_size, MPI_INT, src, tag, world, &stat);\n    printf(\"rank %i receiving a message\\n\", me);\n  }\n  MPI_Finalize();\n  return 0;\n}\n\\end{CppCode}\nHere the code just checks the MPI rank and sends (rank 0) or receives (rank 1) a message.\n\nFor more details on what exactly the SST compiler wrapper is doing, you can specify \\inlineshell{SSTMAC_VERBOSE=1} as an environment variable to have SST print out detailed commands. Additionally, you can specify \\inlineshell{SSTMAC_DELETE_TEMPS=0} to examine any temporary source-to-source files.\n",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/sstmac/main/loadlib.cc": "/**\nCopyright 2009-2020 National Technology and Engineering Solutions of Sandia,\nLLC (NTESS).  Under the terms of Contract DE-NA-0003525, the U.S.  Government \nretains certain rights in this software.\n\nSandia National Laboratories is a multimission laboratory managed and operated\nby National Technology and Engineering Solutions of Sandia, LLC., a wholly \nowned subsidiary of Honeywell International, Inc., for the U.S. Department of \nEnergy's National Nuclear Security Administration under contract DE-NA0003525.\n\nCopyright (c) 2009-2020, NTESS\n\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without modification, \nare permitted provided that the following conditions are met:\n\n    * Redistributions of source code must retain the above copyright\n      notice, this list of conditions and the following disclaimer.\n\n    * Redistributions in binary form must reproduce the above\n      copyright notice, this list of conditions and the following\n      disclaimer in the documentation and/or other materials provided\n      with the distribution.\n\n    * Neither the name of the copyright holder nor the names of its\n      contributors may be used to endorse or promote products derived\n      from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n\"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\nLIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\nA PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\nOWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\nSPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\nLIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\nDATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\nTHEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\nQuestions? Contact sst-macro-help@sandia.gov\n*/\n#include <dlfcn.h>\n#include <vector>\n#include <string>\n#include <cstring>\n#include <sys/stat.h>\n#include <sprockit/errors.h>\n\nnamespace sstmac {\n\nstatic std::vector<std::string> split_path(const std::string& searchPath)\n{\n  std::vector<std::string> paths;\n  char * pathCopy = new char [searchPath.length() + 1];\n  std::strcpy(pathCopy, searchPath.c_str());\n  char *brkb = NULL;\n  char *p = NULL;\n  for ( p = strtok_r(pathCopy, \":\", &brkb); p ; p = strtok_r(NULL, \":\", &brkb) ) {\n    paths.push_back(p);\n  }\n\n  delete [] pathCopy;\n  return paths;\n}\n\nstd::string loadExternPathStr(){\n  const char* libpath_str = getenv(\"SST_LIB_PATH\");\n  if (libpath_str){\n    return libpath_str;\n  } else {\n    return \"\";\n  }\n}\n\nvoid* loadExternLibrary(const std::string& libname, const std::string& searchPath)\n{\n  struct stat sbuf;\n  int ret = stat(libname.c_str(), &sbuf);\n  std::string fullpath;\n  if (ret != 0){\n    std::vector<std::string> paths = split_path(searchPath);\n    //always include current directory\n    paths.push_back(\".\");\n\n    for (auto&& path : paths) {\n      fullpath = path + \"/\" + libname;\n      ret = stat(fullpath.c_str(), &sbuf);\n      if (ret == 0) break;\n    }\n  } else {\n    fullpath = libname;\n  }\n\n  if (ret != 0){\n    //didn't find it\n    spkt_abort_printf(\"%s not found in current directory or in path=%s\",\n                      libname.c_str(), searchPath.c_str());\n  }\n\n  //std::cerr << \"Loading external library \" << fullpath << std::endl;\n\n  // This is a little weird, but always try the last path - if we\n  // didn't succeed in the stat, we'll get a file not found error\n  // from dlopen, which is a useful error message for the user.\n  void* handle = dlopen(fullpath.c_str(), RTLD_NOW|RTLD_LOCAL);\n  if (NULL == handle) {\n    spkt_abort_printf(\"Opening library %s failed\\n:%s\", libname.c_str(), dlerror());\n  }\n  return handle;\n}\n\nvoid* loadExternLibrary(const std::string& libname)\n{\n  return loadExternLibrary(libname, loadExternPathStr());\n}\n\nvoid unloadExternLibrary(void* handle)\n{\n  dlclose(handle);\n}\n\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/sstmac/software/launch/app_launcher.cc": "/**\nCopyright 2009-2020 National Technology and Engineering Solutions of Sandia, \nLLC (NTESS).  Under the terms of Contract DE-NA-0003525, the U.S.  Government \nretains certain rights in this software.\n\nSandia National Laboratories is a multimission laboratory managed and operated\nby National Technology and Engineering Solutions of Sandia, LLC., a wholly \nowned subsidiary of Honeywell International, Inc., for the U.S. Department of \nEnergy's National Nuclear Security Administration under contract DE-NA0003525.\n\nCopyright (c) 2009-2020, NTESS\n\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without modification, \nare permitted provided that the following conditions are met:\n\n    * Redistributions of source code must retain the above copyright\n      notice, this list of conditions and the following disclaimer.\n\n    * Redistributions in binary form must reproduce the above\n      copyright notice, this list of conditions and the following\n      disclaimer in the documentation and/or other materials provided\n      with the distribution.\n\n    * Neither the name of the copyright holder nor the names of its\n      contributors may be used to endorse or promote products derived\n      from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n\"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\nLIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\nA PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\nOWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\nSPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\nLIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\nDATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\nTHEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\nQuestions? Contact sst-macro-help@sandia.gov\n*/\n\n#include <sstmac/software/launch/app_launcher.h>\n#include <sstmac/software/launch/launch_event.h>\n#include <sstmac/software/launch/job_launcher.h>\n#include <sstmac/software/process/operating_system.h>\n#include <sstmac/software/process/app.h>\n#include <sstmac/common/thread_lock.h>\n#include <sprockit/sim_parameters.h>\n#include <sprockit/util.h>\n#include <unistd.h>\n#include <getopt.h>\n\nnamespace sstmac {\nnamespace sw {\n\nAppLauncher::AppLauncher(OperatingSystem* os) :\n  Service(std::string(\"launcher\"), SoftwareId(0,0), os),\n  is_completed_(false)\n{\n}\n\nAppLauncher::~AppLauncher() throw()\n{\n}\n\nvoid\nAppLauncher::incomingRequest(Request* req)\n{\n  StartAppRequest* lreq = safe_cast(StartAppRequest, req);\n  if (lreq->type() == LaunchRequest::Start){\n    TaskMapping::addGlobalMapping(lreq->aid(), lreq->uniqueName(), lreq->mapping());\n\n    //if necessary, bcast this to whomever else needs it\n    os_->outcastAppStart(lreq->tid(), lreq->aid(), lreq->uniqueName(),\n                         lreq->mapping(), lreq->appParams());\n\n    SoftwareId sid(lreq->aid(), lreq->tid());\n    SST::Params app_params = lreq->appParams();\n    App::dlopenCheck(lreq->aid(), app_params);\n    auto app_name = app_params.find<std::string>(\"name\");\n    App* theapp = sprockit::create<App>(\"macro\", app_name, app_params, sid, os_);\n    theapp->setUniqueName(lreq->uniqueName());\n    int intranode_rank = num_apps_launched_[lreq->aid()]++;\n    int core_affinity = lreq->coreAffinity(intranode_rank);\n    if (core_affinity != Thread::no_core_affinity){\n      theapp->setAffinity(core_affinity);\n    }\n\n    os_->startApp(theapp, lreq->uniqueName());\n  }\n  delete lreq;\n}\n\nvoid\nAppLauncher::start()\n{\n  Service::start();\n  if (!os_) {\n    spkt_throw_printf(sprockit::ValueError,\n                     \"AppLauncher::start: OS hasn't been registered yet\");\n  }\n}\n\nhw::NetworkMessage*\nLaunchRequest::cloneInjectionAck() const\n{\n  spkt_abort_printf(\"launch event should never be cloned for injection\");\n  return nullptr;\n}\n\nint\nStartAppRequest::coreAffinity(int  /*intranode_rank*/) const\n{\n  return Thread::no_core_affinity;\n}\n\nvoid\nStartAppRequest::serialize_order(serializer &ser)\n{\n  LaunchRequest::serialize_order(ser);\n  ser & unique_name_;\n  ser & app_params_;\n  mapping_ = TaskMapping::serialize_order(aid(), ser);\n}\n\nstd::string\nStartAppRequest::toString() const\n{\n  return sprockit::sprintf(\"start_app_event: app=%d task=%d node=%d\", aid(), tid(), toaddr());\n}\n\nstd::string\nJobStopRequest::toString() const\n{\n  return sprockit::sprintf(\"job_stop_event: app=%d task=%d node=%d\", aid(), tid(), fromaddr());\n}\n\n\n}\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/sstmac/software/process/global.cc": "/**\nCopyright 2009-2020 National Technology and Engineering Solutions of Sandia, \nLLC (NTESS).  Under the terms of Contract DE-NA-0003525, the U.S.  Government \nretains certain rights in this software.\n\nSandia National Laboratories is a multimission laboratory managed and operated\nby National Technology and Engineering Solutions of Sandia, LLC., a wholly \nowned subsidiary of Honeywell International, Inc., for the U.S. Department of \nEnergy's National Nuclear Security Administration under contract DE-NA0003525.\n\nCopyright (c) 2009-2020, NTESS\n\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without modification, \nare permitted provided that the following conditions are met:\n\n    * Redistributions of source code must retain the above copyright\n      notice, this list of conditions and the following disclaimer.\n\n    * Redistributions in binary form must reproduce the above\n      copyright notice, this list of conditions and the following\n      disclaimer in the documentation and/or other materials provided\n      with the distribution.\n\n    * Neither the name of the copyright holder nor the names of its\n      contributors may be used to endorse or promote products derived\n      from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n\"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\nLIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\nA PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\nOWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\nSPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\nLIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\nDATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\nTHEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\nQuestions? Contact sst-macro-help@sandia.gov\n*/\n\n#include <sstmac/software/process/global.h>\n#include <sstmac/software/process/operating_system.h>\n#include <sstmac/software/process/thread.h>\n#include <sstmac/software/process/cppglobal.h>\n\nextern \"C\" {\n\nint sstmac_global_stacksize = 0;\nchar* static_init_glbls_segment = nullptr;\nchar* static_init_tls_segment = nullptr;\nvoid allocate_static_init_tls_segment(){\n  static_init_tls_segment = new char[int(1e6)];\n}\nvoid allocate_static_init_glbls_segment(){\n  static_init_glbls_segment = new char[int(1e6)];\n}\n\n}\n\nnamespace sstmac {\n\nGlobalVariableContext GlobalVariable::glblCtx;\nGlobalVariableContext GlobalVariable::tlsCtx;\nbool GlobalVariable::inited = false;\n\nint\nGlobalVariable::init(const int size, const char* name, bool tls)\n{\n  if (!inited){\n    tlsCtx.init();\n    glblCtx.init();\n    inited = true;\n  }\n  if (tls) return tlsCtx.append(size, name);\n  else return glblCtx.append(size, name);\n}\n\nvoid\nGlobalVariableContext::init()\n{\n  stackOffset = 0;\n  allocSize_ = 4096;\n  globalInits = nullptr;\n}\n\nvoid\nGlobalVariableContext::registerInitFxn(int offset, std::function<void (void *)> &&fxn)\n{\n  initFxns[offset] = std::move(fxn);\n}\n\nint\nGlobalVariableContext::append(const int size, const char*  /*name*/)\n{\n  int offset = stackOffset;\n\n  int rem = size % 4;\n  int offsetIncrement = rem ? (size + (4-rem)) : size; //align on 32-bits\n\n  bool realloc = false;\n  while ((offsetIncrement + stackOffset) > allocSize_){\n    realloc = true;\n    allocSize_ *= 2; //grow until big enough\n  }\n\n  if (realloc && !activeGlobalMaps_.empty()){\n    spkt_abort_printf(\"dynamically loaded global variable overran storage space\\n\"\n                      \"to fix, explicitly set globals_size = %d in app params\",\n                      allocSize_);\n  }\n\n  if (realloc || globalInits == nullptr){\n    char* old = globalInits;\n    globalInits = new char[allocSize_];\n    if (old){\n      //move everything in that was already there\n      ::memcpy(globalInits, old, stackOffset);\n      delete[] old;\n    }\n  }\n\n  //printf(\"Allocated global variable %s of size %d at offset %d - %s\\n\",\n  //       name, size, offset, (realloc ? \"reallocated to fit\" : \"already fits\"));\n  //fflush(stdout);\n\n  stackOffset += offsetIncrement;\n\n  return offset;\n}\n\nCppGlobalRegisterGuard::CppGlobalRegisterGuard(int& offset, int size, bool tls, const char* name,\n                                               std::function<void(void*)>&& fxn) :\n  tls_(tls), offset_(offset)\n{\n  offset_ = offset = GlobalVariable::init(size, name, tls);\n  if (tls){\n    GlobalVariable::tlsCtx.registerInitFxn(offset, std::move(fxn));\n  } else {\n    GlobalVariable::glblCtx.registerInitFxn(offset, std::move(fxn));\n  }\n}\n\nCppGlobalRegisterGuard::~CppGlobalRegisterGuard()\n{\n  if (tls_){\n    GlobalVariable::tlsCtx.unregisterInitFxn(offset_);\n  } else {\n    GlobalVariable::glblCtx.unregisterInitFxn(offset_);\n  }\n}\n\nvoid\nGlobalVariableContext::callInitFxns(void *globals)\n{\n  for (auto& pair : initFxns){\n    int offset = pair.first;\n    char* ptr = ((char*)globals) + offset;\n    (pair.second)(ptr);\n  }\n}\n\nGlobalVariableContext::~GlobalVariableContext()\n{\n  if (globalInits){\n    delete[] globalInits;\n    globalInits = nullptr;\n  }\n}\n\nvoid\nGlobalVariableContext::initGlobalSpace(void* ptr, int size, int offset)\n{\n  for (void* globals : activeGlobalMaps_){\n    char* dst = ((char*)globals) + offset;\n    ::memcpy(dst, ptr, size);\n  }\n\n  //also do the global init for any new threads spawned\n  char* dst = ((char*)globalInits) + offset;\n  ::memcpy(dst, ptr, size);\n}\n\n}\n\n#include <dlfcn.h>\n\nextern \"C\" void *sstmac_dlopen(const char* filename, int flag)\n{\n  void* ret = dlopen(filename, flag);\n  return ret;\n}\n\nextern \"C\" void sstmac_init_global_space(void* ptr, int size, int offset, bool tls)\n{\n  if (tls) sstmac::GlobalVariable::tlsCtx.initGlobalSpace(ptr, size, offset);\n  else sstmac::GlobalVariable::glblCtx.initGlobalSpace(ptr, size, offset);\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/sstmac/software/process/app.h": "/**\nCopyright 2009-2020 National Technology and Engineering Solutions of Sandia, \nLLC (NTESS).  Under the terms of Contract DE-NA-0003525, the U.S.  Government \nretains certain rights in this software.\n\nSandia National Laboratories is a multimission laboratory managed and operated\nby National Technology and Engineering Solutions of Sandia, LLC., a wholly \nowned subsidiary of Honeywell International, Inc., for the U.S. Department of \nEnergy's National Nuclear Security Administration under contract DE-NA0003525.\n\nCopyright (c) 2009-2020, NTESS\n\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without modification, \nare permitted provided that the following conditions are met:\n\n    * Redistributions of source code must retain the above copyright\n      notice, this list of conditions and the following disclaimer.\n\n    * Redistributions in binary form must reproduce the above\n      copyright notice, this list of conditions and the following\n      disclaimer in the documentation and/or other materials provided\n      with the distribution.\n\n    * Neither the name of the copyright holder nor the names of its\n      contributors may be used to endorse or promote products derived\n      from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n\"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\nLIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\nA PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\nOWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\nSPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\nLIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\nDATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\nTHEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\nQuestions? Contact sst-macro-help@sandia.gov\n*/\n\n#ifndef SSTMAC_SOFTWARE_PROCESS_APP_H_INCLUDED\n#define SSTMAC_SOFTWARE_PROCESS_APP_H_INCLUDED\n\n#include <sstmac/software/libraries/compute/lib_compute_fwd.h>\n#include <sstmac/software/libraries/compute/compute_event_fwd.h>\n#include <sstmac/software/process/thread.h>\n#include <sstmac/software/api/api_fwd.h>\n#include <sstmac/software/process/operating_system_fwd.h>\n\n#include <sstmac/sst_core/integrated_component.h>\n\n#include <sprockit/factory.h>\n#include <sprockit/sim_parameters.h>\n\n#ifdef sleep\n#if sleep == sstmac_sleep\n#define refactor_sleep_macro\n#undef sleep\n#endif\n#endif\n\nnamespace sstmac {\nnamespace sw {\n\nclass mutex_t  {\n public:\n  /** Blocking keys for those threads waiting on the mutex */\n  std::list<Thread*> waiters;\n  std::list<Thread*> conditionals;\n  bool locked;\n\n  mutex_t() : locked(false)\n  {\n  }\n};\n\ntypedef std::map<long, mutex_t*> condition_t;\n\n/**\n * The app derived class adds to the thread base class by providing\n * facilities to allow applications to simulate computation.\n * Messaging models are supported through an api class,\n * which are stored by the app\n */\nclass App : public Thread\n{\n public:\n  SST_ELI_DECLARE_BASE(App)\n  SST_ELI_DECLARE_DEFAULT_INFO()\n  SST_ELI_DECLARE_CTOR(SST::Params&,SoftwareId,OperatingSystem*)\n\n  typedef void (*destructor_fxn)(void*);\n\n  typedef int (*main_fxn)(int argc, char** argv);\n  typedef int (*empty_main_fxn)();\n\n  int allocateTlsKey(destructor_fxn fnx);\n\n  static SST::Params getParams();\n\n  App* parentApp() const override {\n    return const_cast<App*>(this);\n  }\n\n  bool isMainThread() const override {\n    return true;\n  }\n\n  static void deleteStatics();\n\n  void sleep(TimeDelta time);\n\n  void compute(TimeDelta time);\n\n  void computeInst(ComputeEvent* cmsg);\n\n  void computeLoop(uint64_t num_loops,\n    int nflops_per_loop,\n    int nintops_per_loop,\n    int bytes_per_loop);\n\n  void computeBlockRead(uint64_t bytes);\n\n  void computeBlockWrite(uint64_t bytes);\n\n  void computeBlockMemcpy(uint64_t bytes);\n\n  LibComputeMemmove* computeLib();\n\n  ~App() override;\n\n  void cleanup() override;\n\n  /**\n   * @brief skeleton_main\n   * @return The return code that would be returned by a main\n   */\n  virtual int skeletonMain() = 0;\n\n  void run() override;\n\n  int rc() const {\n    return rc_;\n  }\n\n  SST::Params& params() {\n    return params_;\n  }\n\n  char* getenv(const std::string& name) const;\n\n  int putenv(char* input);\n\n  int setenv(const std::string& name, const std::string& value, int overwrite);\n\n  /**\n   * Let a parent application know about the existence of a subthread\n   * If thread does not have an initialized ID, a unique ID is allocated for the thread\n   * Can be called from a constructor. This method does NOT throw.\n   * @param thr\n   */\n  void addSubthread(Thread* thr);\n\n  /**\n   * Let a parent application know a subthread has finished.\n   * This completely erases the thread. There will be no record of this thread after calling this function.\n   * @param thr A thread with initialized ID\n   */\n  void removeSubthread(Thread* thr);\n\n  void removeSubthread(uint32_t thr_id);\n\n  /**\n   * @brief get_subthread\n   * @param id\n   * @return\n   */\n  Thread* getSubthread(uint32_t id);\n\n  /**\n   * Allocate a unique ID for a mutex variable\n   * @return The unique ID\n   */\n  int allocateMutex();\n\n  /**\n   * Allocate a unique ID for a condition variable\n   * @return The unique ID\n   */\n  int allocateCondition();\n\n  /**\n   * Fetch a mutex object corresponding to their ID\n   * @param id\n   * @return The mutex object corresponding to the ID. Return NULL if no mutex is found.\n   */\n  mutex_t* getMutex(int id);\n\n  /**\n   * Fetch a condition object corresponding to the ID\n   * @param id\n   * @return The condition object corresponding to the ID. Return NULL if not condition is found.\n   */\n  condition_t* getCondition(int id);\n\n  bool eraseCondition(int id);\n\n  bool eraseMutex(int id);\n\n  void* globalsStorage() const {\n    return globals_storage_;\n  }\n\n  void* newTlsStorage() {\n    return allocateDataSegment(true);\n  }\n\n  const std::string& uniqueName() const {\n    return unique_name_;\n  }\n\n  void setUniqueName(const std::string& name) {\n    unique_name_ = name;\n  }\n\n  static void dlopenCheck(int aid, SST::Params& params, bool check_name = true);\n\n  static void dlcloseCheck(int aid);\n\n  static void lockDlopen(int aid);\n\n  static void unlockDlopen(int aid);\n\n  static int appRC(){\n    return app_rc_;\n  }\n\n  FILE* stdOutFile(){\n    return stdout_;\n  }\n\n  FILE* stdErrFile(){\n    return stderr_;\n  }\n\n  std::ostream& coutStream();\n  std::ostream& cerrStream();\n\n protected:\n  friend class Thread;\n\n  App(SST::Params& params, SoftwareId sid,\n      OperatingSystem* os);\n\n  SST::Params params_;\n\n private:\n  API* getPrebuiltApi(const std::string& name);\n\n  void dlcloseCheck(){\n    dlcloseCheck(aid());\n  }\n\n  char* allocateDataSegment(bool tls);\n\n  void computeDetailed(uint64_t flops, uint64_t intops, uint64_t bytes, int nthread);\n\n  LibComputeMemmove* compute_lib_;\n  std::string unique_name_;\n\n  int next_tls_key_;\n  int next_condition_;\n  int next_mutex_;\n  uint64_t min_op_cutoff_;\n\n  std::map<long, Thread*> subthreads_;\n  std::map<int, mutex_t> mutexes_;\n  std::map<int, condition_t> conditions_;\n  std::map<int, destructor_fxn> tls_key_fxns_;\n  //these can alias - so I can't use unique_ptr\n  std::map<std::string, API*> apis_;\n  std::map<std::string,std::string> env_;\n\n  char env_string_[64];\n\n  char* globals_storage_;\n\n  bool notify_;\n\n  int rc_;\n\n  struct dlopen_entry {\n    void* handle;\n    int refcount;\n    bool loaded;\n    std::string name;\n    dlopen_entry() : handle(nullptr), refcount(0), loaded(false) {}\n  };\n\n  static std::map<int, dlopen_entry> dlopens_;\n\n  static int app_rc_;\n\n  std::ofstream cout_;\n  std::ofstream cerr_;\n  FILE* stdout_;\n  FILE* stderr_;\n\n};\n\n\nclass UserAppCxxFullMain : public App\n{\n public:\n  SST_ELI_REGISTER_DERIVED(App,\n    UserAppCxxFullMain,\n    \"macro\",\n    \"UserAppCxxFullMain\",\n    SST_ELI_ELEMENT_VERSION(1,0,0),\n    \"an app that runs main(argc,argv)\")\n\n  UserAppCxxFullMain(SST::Params& params, SoftwareId sid,\n                     OperatingSystem* os);\n\n  static void registerMainFxn(const char* name, App::main_fxn fxn);\n\n  int skeletonMain() override;\n\n  static void deleteStatics();\n\n  static void aliasMains();\n\n  struct argv_entry {\n    char** argv;\n    int argc;\n    argv_entry() : argv(0), argc(0) {}\n  };\n\n private:\n  void initArgv(argv_entry& entry);\n\n  static std::unique_ptr<std::map<std::string, App::main_fxn>> main_fxns_;\n  static std::map<std::string, App::main_fxn>* main_fxns_init_;\n  static std::map<AppId, argv_entry> argv_map_;\n  App::main_fxn fxn_;\n\n};\n\nclass UserAppCxxEmptyMain : public App\n{\n public:\n  SST_ELI_REGISTER_DERIVED(App,\n    UserAppCxxFullMain,\n    \"macro\",\n    \"UserAppCxxFullMain\",\n    SST_ELI_ELEMENT_VERSION(1,0,0),\n    \"an app that runs main()\")\n\n  UserAppCxxEmptyMain(SST::Params& params, SoftwareId sid,\n                          OperatingSystem* os);\n\n  static void registerMainFxn(const char* name, App::empty_main_fxn fxn);\n\n  static void aliasMains();\n\n  int skeletonMain() override;\n\n private:\n  //to work around static init bugs for older compilers\n  //I have to init with a raw pointer - then transfer ownershipt to a unique_ptr\n  //that cleans up at the end\n  static std::unique_ptr<std::map<std::string, App::empty_main_fxn>> empty_main_fxns_;\n  static std::map<std::string, App::empty_main_fxn>* empty_main_fxns_init_;\n  App::empty_main_fxn fxn_;\n\n};\n\n/** utility function for computing stuff */\nvoid computeTime(double tsec);\n\n}\n} // end of namespace sstmac.\n\n#ifdef refactor_sleep_macro\n#define sleep sstmac_sleep\n#undef refactor_sleep_macro\n#endif\n\n#endif\n",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/sstmac/software/process/app.cc": "/**\nCopyright 2009-2020 National Technology and Engineering Solutions of Sandia, \nLLC (NTESS).  Under the terms of Contract DE-NA-0003525, the U.S.  Government \nretains certain rights in this software.\n\nSandia National Laboratories is a multimission laboratory managed and operated\nby National Technology and Engineering Solutions of Sandia, LLC., a wholly \nowned subsidiary of Honeywell International, Inc., for the U.S. Department of \nEnergy's National Nuclear Security Administration under contract DE-NA0003525.\n\nCopyright (c) 2009-2020, NTESS\n\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without modification, \nare permitted provided that the following conditions are met:\n\n    * Redistributions of source code must retain the above copyright\n      notice, this list of conditions and the following disclaimer.\n\n    * Redistributions in binary form must reproduce the above\n      copyright notice, this list of conditions and the following\n      disclaimer in the documentation and/or other materials provided\n      with the distribution.\n\n    * Neither the name of the copyright holder nor the names of its\n      contributors may be used to endorse or promote products derived\n      from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n\"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\nLIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\nA PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\nOWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\nSPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\nLIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\nDATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\nTHEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\nQuestions? Contact sst-macro-help@sandia.gov\n*/\n\n#ifndef __STDC_FORMAT_MACROS\n#define __STDC_FORMAT_MACROS\n#endif\n#include <inttypes.h>\n\n#include <sstmac/software/libraries/compute/lib_compute_inst.h>\n#include <sstmac/software/libraries/compute/lib_compute_time.h>\n#include <sstmac/software/libraries/compute/lib_compute_memmove.h>\n#include <sstmac/software/process/app.h>\n#include <sstmac/software/api/api.h>\n#include <sstmac/software/process/operating_system.h>\n#include <sstmac/software/process/backtrace.h>\n#include <sstmac/common/sstmac_env.h>\n#include <sstmac/dumpi_util/dumpi_meta.h>\n#include <sstmac/software/launch/job_launcher.h>\n#include <sstmac/software/launch/launch_event.h>\n#include <sstmac/common/thread_lock.h>\n#include <dlfcn.h>\n#include <sstmac/common/sstmac_env.h>\n#include <sstmac/dumpi_util/dumpi_meta.h>\n#include <sstmac/hardware/node/node.h>\n#include <sprockit/statics.h>\n#include <sprockit/output.h>\n#include <sprockit/util.h>\n#include <sprockit/sim_parameters.h>\n#include <sstmac/software/api/api.h>\n#include <sstmac/main/sstmac.h>\n\nstatic sprockit::NeedDeletestatics<sstmac::sw::UserAppCxxFullMain> del_app_statics;\n\nRegisterKeywords(\n { \"host_compute_timer\", \"whether to use the time elapsed on the host machine in compute modeling\" },\n { \"min_op_cutoff\", \"the minimum number of operations in a compute before detailed modeling is perfromed\" },\n { \"notify\", \"whether the app should send completion notifications to job root\" },\n { \"globals_size\", \"the size of the global variable segment to allocate\" },\n { \"OMP_NUM_THREADS\", \"environment variable for configuring openmp\" },\n { \"exe\", \"an optional exe .so file to load for this app\" },\n);\n\nMakeDebugSlot(app_compute);\n\nvoid sstmac_app_loaded(int /*aid*/){}\n\nextern \"C\" FILE* sstmac_stdout(){\n  return sstmac::sw::Thread::current()->parentApp()->stdOutFile();\n}\n\nextern \"C\" FILE* sstmac_stderr(){\n  return sstmac::sw::Thread::current()->parentApp()->stdErrFile();\n}\n\nnamespace sstmac {\n\nstd::ostream& cout_wrapper(){\n  return sw::Thread::current()->parentApp()->coutStream();\n}\n\nstd::ostream& cerr_wrapper(){\n  return sw::Thread::current()->parentApp()->cerrStream();\n}\n\nnamespace sw {\n\nstd::unique_ptr<std::map<std::string, App::main_fxn>> UserAppCxxFullMain::main_fxns_;\nstd::unique_ptr<std::map<std::string, App::empty_main_fxn>> UserAppCxxEmptyMain::empty_main_fxns_;\nstd::map<std::string, App::main_fxn>* UserAppCxxFullMain::main_fxns_init_ = nullptr;\nstd::map<std::string, App::empty_main_fxn>* UserAppCxxEmptyMain::empty_main_fxns_init_ = nullptr;\nstd::map<AppId, UserAppCxxFullMain::argv_entry> UserAppCxxFullMain::argv_map_;\n\nstd::map<int, App::dlopen_entry> App::dlopens_;\nint App::app_rc_ = 0;\n\nint\nApp::allocateTlsKey(destructor_fxn fxn)\n{\n  int next = next_tls_key_;\n  tls_key_fxns_[next] = fxn;\n  ++next_tls_key_;\n  return next;\n}\n\nstatic char* get_data_segment(SST::Params& params,\n                              const char* param_name, GlobalVariableContext& ctx)\n{\n  int allocSize = ctx.allocSize();\n  if (params.contains(param_name)){\n    allocSize = params.find<int>(param_name);\n    if (ctx.allocSize() != allocSize){\n      ctx.setAllocSize(allocSize);\n    }\n  }\n  if (allocSize != 0){\n    char* segment = new char[allocSize];\n    ::memcpy(segment, ctx.globalInit(), ctx.globalsSize());\n    return segment;\n  } else {\n    return nullptr;\n  }\n}\n\n\nstatic thread_lock dlopen_lock;\n\nvoid\nApp::lockDlopen(int aid)\n{\n  dlopen_entry& entry = dlopens_[aid];\n  entry.refcount++;\n}\n\nvoid\nApp::unlockDlopen(int aid)\n{\n  dlcloseCheck(aid);\n}\n\nvoid\nApp::dlopenCheck(int aid, SST::Params& params, bool check_name)\n{\n  if (params.contains(\"exe\")){\n    dlopen_lock.lock();\n    std::string libname = params.find<std::string>(\"exe\");\n    dlopen_entry& entry = dlopens_[aid];\n    entry.name = libname;\n    if (entry.refcount == 0 || !entry.loaded){\n      entry.handle = loadExternLibrary(libname, loadExternPathStr());\n      entry.loaded = true;\n    }\n\n    if (check_name){\n      void* name = dlsym(entry.handle, \"exe_main_name\");\n      if (name){\n        const char* str_name = (const char*) name;\n        if (params.contains(\"name\")){\n          std::string given_name = params.find<std::string>(\"name\");\n          /**\n          if (given_name != std::string(str_name)){\n            std::cout << sprockit::sprintf(\"App %d loaded from exe %s. \"\n               \"User-specified name '%s' overriding default name\",\n               aid, libname.c_str(), given_name.c_str()) << std::endl;\n          }\n          */\n          params.insert(\"label\", given_name);\n        }\n        params.insert(\"name\", str_name);\n      }\n    }\n\n    ++entry.refcount;\n    sstmac_app_loaded(aid);\n    dlopen_lock.unlock();\n  }\n  UserAppCxxEmptyMain::aliasMains();\n  UserAppCxxFullMain::aliasMains();\n}\n\nvoid\nApp::dlcloseCheck(int aid)\n{\n  dlopen_lock.lock();\n  auto iter = dlopens_.find(aid);\n  if (iter != dlopens_.end()){\n    dlopen_entry& entry = iter->second;\n    --entry.refcount;\n    if (entry.refcount == 0 && entry.loaded){\n      unloadExternLibrary(entry.handle);\n      dlopens_.erase(iter);\n    }\n  }\n  dlopen_lock.unlock();\n}\n\nchar*\nApp::allocateDataSegment(bool tls)\n{\n  if (tls){\n    return get_data_segment(params_, \"tls_size\", GlobalVariable::tlsCtx);\n  } else {\n    return get_data_segment(params_, \"globals_size\", GlobalVariable::glblCtx);\n  }\n}\n\nApp::App(SST::Params& params, SoftwareId sid,\n         OperatingSystem* os) :\n  Thread(params, sid, os),\n  params_(params),\n  compute_lib_(nullptr),\n  next_tls_key_(0),\n  next_condition_(0),\n  next_mutex_(0),\n  min_op_cutoff_(0),\n  globals_storage_(nullptr),\n  notify_(true),\n  rc_(0)\n{\n  globals_storage_ = allocateDataSegment(false); //not tls\n  min_op_cutoff_ = params.find<long>(\"min_op_cutoff\", 1000);\n  bool host_compute = params.find<bool>(\"host_compute_timer\", false);\n  if (host_compute){\n    host_timer_ = new HostTimer;\n  }\n\n  notify_ = params.find<bool>(\"notify\", true);\n\n  SST::Params env_params = params.find_scoped_params(\"env\");\n  omp_contexts_.emplace_back();\n  omp_context& active = omp_contexts_.back();\n  active.max_num_subthreads = active.requested_num_subthreads =\n    env_params.find<int>(\"OMP_NUM_THREADS\", 1);\n  active.level = 0;\n  active.num_threads = 1;\n\n  std::set<std::string> keys = env_params.getKeys();\n  for (auto& key : keys){\n    env_[key] = env_params.find<std::string>(key);\n  }\n\n  for (auto iter=os->env_begin(); iter != os->env_end(); ++iter){\n    auto my_iter = env_.find(iter->first);\n    if (my_iter == env_.end()){\n      //don't overwrite - app env taks precedence\n      env_[iter->first] = iter->second;\n    }\n  }\n\n  std::vector<std::string> apis;\n  if (params.contains(\"apis\")){\n    params.find_array(\"apis\", apis);\n  } else {\n    apis.push_back(\"mpi\");\n    apis.push_back(\"sumi:mpi\");\n  }\n\n  for (auto& str : apis){\n    std::string alias;\n    std::string name;\n    auto pos = str.find(\":\");\n    if (pos == std::string::npos){\n      name = str;\n      alias = str;\n    } else {\n      alias = str.substr(0, pos);\n      name = str.substr(pos + 1);\n    }\n\n    auto iter = apis_.find(name);\n    if (iter == apis_.end()){\n      SST::Params api_params = params.find_scoped_params(name);\n      API* api = sprockit::create<API>(\n          \"macro\", name, api_params, this, os->node());\n      apis_[name] = api;\n    }\n    apis_[alias] = apis_[name];\n  }\n\n  std::string stdout_str = params.find<std::string>(\"stdout\", \"stdout\");\n  std::string stderr_str = params.find<std::string>(\"stderr\", \"stderr\");\n  std::string cout_str = params.find<std::string>(\"cout\", \"cout\");\n  std::string cerr_str = params.find<std::string>(\"cerr\", \"cerr\");\n\n  if (stdout_str == \"stdout\"){\n    stdout_ = stdout;\n  } else if (stdout_str == \"app\"){\n    std::string name = sprockit::sprintf(\"stdout.app%d\", sid.app_);\n    stdout_ = fopen(name.c_str(), \"a\");\n  } else if (stdout_str == \"rank\"){\n    std::string name = sprockit::sprintf(\"stdout.app%d.%d\", sid.app_, sid.task_);\n    stdout_ = fopen(name.c_str(), \"w\");\n  } else {\n    //this must be a filename\n    stdout_ = fopen(stdout_str.c_str(), \"a\");\n  }\n\n  if (stderr_str == \"stderr\"){\n    stderr_ = stderr;\n  } else if (stdout_str == \"app\"){\n    std::string name = sprockit::sprintf(\"stderr.app%d\", sid.app_);\n    stderr_ = fopen(name.c_str(), \"a\");\n  } else if (stdout_str == \"rank\"){\n    std::string name = sprockit::sprintf(\"stderr.app%d.%d\", sid.app_, sid.task_);\n    stderr_ = fopen(name.c_str(), \"w\");\n  } else {\n    //this must be a filename\n    stderr_ = fopen(stderr_str.c_str(), \"a\");\n  }\n\n  if (cout_str == \"cout\"){\n    //do nothing - by doing nothing we will return cout later\n  } else if (cout_str == \"app\") {\n    std::string name = sprockit::sprintf(\"cout.app%d\", sid.app_);\n    cout_.open(name);\n  } else if (cout_str == \"rank\") {\n    std::string name = sprockit::sprintf(\"cout.app%d.%d\", sid.app_, sid.task_);\n    cout_.open(name);\n  } else {\n    //this must be a filename\n    cout_.open(cout_str);\n  }\n\n  if (cerr_str == \"cerr\"){\n    //do nothing - by doing nothing we will return cout later\n  } else if (cerr_str == \"app\") {\n    std::string name = sprockit::sprintf(\"cerr.app%d\", sid.app_);\n    cerr_.open(name);\n  } else if (cerr_str == \"rank\") {\n    std::string name = sprockit::sprintf(\"cerr.app%d.%d\", sid.app_, sid.task_);\n    cerr_.open(cerr_str);\n  } else {\n    //this must be a filename\n    cerr_.open(cerr_str);\n  }\n}\n\nApp::~App()\n{\n  /** These get deleted by unregister */\n  //sprockit::delete_vals(apis_);\n  if (compute_lib_) delete compute_lib_;\n  if (globals_storage_) delete[] globals_storage_;\n}\n\nstd::ostream&\nApp::coutStream(){\n  if (cout_.is_open()){\n    return cout_;\n  } else {\n    return std::cout;\n  }\n}\n\nstd::ostream&\nApp::cerrStream(){\n  if (cerr_.is_open()){\n    return cerr_;\n  } else {\n    return std::cerr;\n  }\n}\n\n\nint\nApp::putenv(char* input)\n{\n  spkt_abort_printf(\"app::putenv: not implemented - cannot put %d\",\n                    input);\n  return 0;\n}\n\nint\nApp::setenv(const std::string &name, const std::string &value, int overwrite)\n{\n  if (overwrite){\n    env_[name] = value;\n  } else {\n    auto iter = env_.find(name);\n    if (iter == env_.end()){\n      env_[name] = value;\n    }\n  }\n  return 0;\n}\n\nchar*\nApp::getenv(const std::string &name) const\n{\n  char* my_buf = const_cast<char*>(env_string_);\n  auto iter = env_.find(name);\n  if (iter == env_.end()){\n    return nullptr;\n  } else {\n    auto& val = iter->second;\n    if (val.size() >= sizeof(env_string_)){\n      spkt_abort_printf(\"Environment variable %s=%s is too long - need less than %d\",\n                        name.c_str(), val.c_str(), int(val.size()));\n    }\n    ::strcpy(my_buf, val.data());\n  }\n  //ugly but necessary\n  return my_buf;\n}\n\nLibComputeMemmove*\nApp::computeLib()\n{\n  if(!compute_lib_) {\n    compute_lib_ = new LibComputeMemmove(params_, sid_, os_);\n  }\n  return compute_lib_;\n}\n\nvoid\nApp::deleteStatics()\n{\n}\n\nvoid\nApp::cleanup()\n{\n  //okay, the app is dying\n  //it may be that we have subthreads that are still active\n  //all of these subthreads must be cancelled and never start again\n  for (auto& pair : subthreads_){\n    pair.second->cancel();\n  }\n  subthreads_.clear();\n\n  Thread::cleanup();\n}\n\nvoid\nApp::sleep(TimeDelta time)\n{\n  computeLib()->sleep(time);\n}\n\nvoid\nApp::compute(TimeDelta time)\n{\n  computeLib()->compute(time);\n}\n\nvoid\nApp::computeInst(ComputeEvent* cmsg)\n{\n  computeLib()->computeInst(cmsg);\n}\n\nvoid\nApp::computeLoop(uint64_t num_loops,\n  int nflops_per_loop,\n  int nintops_per_loop,\n  int bytes_per_loop)\n{\n  computeLib()->LibComputeInst::computeLoop(\n          num_loops, nflops_per_loop, nintops_per_loop, bytes_per_loop);\n}\n\nvoid\nApp::computeDetailed(uint64_t flops, uint64_t nintops, uint64_t bytes, int nthread)\n{\n  static const uint64_t overflow = 18006744072479883520ull;\n  if (flops > overflow || bytes > overflow){\n    spkt_abort_printf(\"flops/byte counts for compute overflowed\");\n  }\n  if ((flops+nintops) < min_op_cutoff_){\n    return;\n  }\n\n  debug_printf(sprockit::dbg::app_compute,\n               \"Rank %d for app %d: detailed compute for flops=%\" PRIu64 \" intops=%\" PRIu64 \" bytes=%\" PRIu64,\n               sid_.task_, sid_.app_, flops, nintops, bytes);\n\n  computeLib()->computeDetailed(flops, nintops, bytes, nthread);\n}\n\nvoid\nApp::computeBlockRead(uint64_t bytes)\n{\n  computeLib()->read(bytes);\n}\n\nvoid\nApp::computeBlockWrite(uint64_t bytes)\n{\n  computeLib()->write(bytes);\n}\n\nSST::Params\nApp::getParams()\n{\n  return OperatingSystem::currentThread()->parentApp()->params();\n}\n\nvoid\nApp::computeBlockMemcpy(uint64_t bytes)\n{\n  computeLib()->copy(bytes);\n}\n\nAPI*\nApp::getPrebuiltApi(const std::string &name)\n{\n  auto iter = apis_.find(name);\n  if (iter == apis_.end()){\n    spkt_abort_printf(\"API %s was not included in launch params for app %d\",\n                name.c_str(), aid());\n  }\n  return iter->second;\n}\n\nvoid\nApp::run()\n{\n  CallGraphAppend(main);\n  os_->incrementAppRefcount();\n  endAPICall(); //this initializes things, \"fake\" api call at beginning\n  rc_ = skeletonMain();\n  //we are ending but perform the equivalent\n  //to a start api call to flush any compute\n  startAPICall();\n\n  std::set<API*> unique;\n  //because of aliasing...\n  for (auto& pair : apis_){\n    unique.insert(pair.second);\n  }\n  apis_.clear();\n  for (API* api : unique) delete api;\n\n  //now we have to send a message to the job launcher to let it know we are done\n  os_->decrementAppRefcount();\n  //for now assume that the application has finished with a barrier - which is true of like everything\n  if (sid_.task_ == 0 && notify_){\n    int launchRoot = os_->node()->launchRoot();\n    JobStopRequest* lev = new JobStopRequest(os_->node()->allocateUniqueId(),\n                                             sid_.app_, unique_name_, launchRoot, os_->addr());\n    os_->nicCtrlIoctl()(lev);\n  }\n  TaskMapping::removeGlobalMapping(sid_.app_, unique_name_);\n  ThreadInfo::deregisterUserSpaceVirtualThread(stack_);\n  dlcloseCheck();\n\n  app_rc_ = rc_;\n}\n\nvoid\nApp::addSubthread(Thread *thr)\n{\n  if (thr->threadId() == Thread::main_thread){\n    thr->initId();\n  }\n  subthreads_[thr->threadId()] = thr;\n}\n\nThread*\nApp::getSubthread(uint32_t id)\n{\n  auto it = subthreads_.find(id);\n  if (it==subthreads_.end()){\n    spkt_throw_printf(sprockit::ValueError,\n      \"unknown thread id %u\",\n      id);\n  }\n  return it->second;\n}\n\nvoid\nApp::removeSubthread(uint32_t id)\n{\n  subthreads_.erase(id);\n}\n\nvoid\nApp::removeSubthread(Thread *thr)\n{\n  subthreads_.erase(thr->threadId());\n}\n\nbool\nApp::eraseMutex(int id)\n{\n  std::map<int,mutex_t>::iterator it = mutexes_.find(id);\n  if (it == mutexes_.end()){\n    return false;\n  } else {\n    mutexes_.erase(id);\n    return true;\n  }\n}\n\nbool\nApp::eraseCondition(int id)\n{\n  std::map<int,condition_t>::iterator it = conditions_.find(id);\n  if (it == conditions_.end()){\n    return false;\n  } else {\n    conditions_.erase(id);\n    return true;\n  }\n}\n\nmutex_t*\nApp::getMutex(int id)\n{\n  std::map<int,mutex_t>::iterator it = mutexes_.find(id);\n  if (it==mutexes_.end()){\n    return 0;\n  } else {\n    return &it->second;\n  }\n}\n\nint\nApp::allocateMutex()\n{\n  int id = next_mutex_++;\n  mutexes_[id]; //implicit make\n  return id;\n}\n\nint\nApp::allocateCondition()\n{\n  int id = next_condition_++;\n  conditions_[id]; //implicit make\n  return id;\n}\n\ncondition_t*\nApp::getCondition(int id)\n{\n  std::map<int,condition_t>::iterator it = conditions_.find(id);\n  if (it==conditions_.end()){\n    return 0;\n  } else {\n    return &it->second;\n  }\n}\n\nvoid\nUserAppCxxFullMain::deleteStatics()\n{\n  for (auto& pair : argv_map_){\n    argv_entry& entry = pair.second;\n    char* main_buffer = entry.argv[0];\n    delete[] main_buffer;\n    delete[] entry.argv;\n  }\n  argv_map_.clear();\n  main_fxns_ = nullptr;\n}\n\nUserAppCxxFullMain::UserAppCxxFullMain(SST::Params& params, SoftwareId sid,\n                                       OperatingSystem* os) :\n  App(params, sid, os)\n{\n  if (!main_fxns_){\n    //because of the awful XC8 bug\n    main_fxns_ = std::unique_ptr<std::map<std::string,main_fxn>>(main_fxns_init_);\n    main_fxns_init_ = nullptr;\n  }\n\n  std::string name = params.find<std::string>(\"name\");\n  std::map<std::string, main_fxn>::iterator it = main_fxns_->find(name);\n  if (it == main_fxns_->end()){\n    spkt_throw_printf(sprockit::ValueError,\n                     \"no user app with the name %s registered\",\n                     name.c_str());\n  }\n  fxn_ = it->second;\n}\n\nvoid\nUserAppCxxFullMain::aliasMains()\n{\n  static thread_lock lock;\n  lock.lock();\n  if (!main_fxns_){\n    main_fxns_ = std::unique_ptr<std::map<std::string, App::main_fxn>>(main_fxns_init_);\n    main_fxns_init_ = nullptr;\n  }\n  auto* lib = App::getBuilderLibrary(\"macro\");\n  if (main_fxns_){\n    for (auto& pair : *main_fxns_){\n#if SSTMAC_INTEGRATED_SST_CORE\n    auto* builder = lib->getBuilder(\"UserAppCxxFullMain\");\n    lib->addBuilder(pair.first, builder);\n#else\n    using builder_t = sprockit::DerivedBuilder<App,UserAppCxxFullMain,SST::Params&,SoftwareId,OperatingSystem*>;\n    lib->addBuilder(pair.first, std::unique_ptr<builder_t>(new builder_t));\n#endif\n    }\n  }\n  lock.unlock();\n}\n\nvoid\nUserAppCxxFullMain::registerMainFxn(const char *name, App::main_fxn fxn)\n{\n  if (main_fxns_){  //already passed static init\n    (*main_fxns_)[name] = fxn; \n  } else {\n    if (!main_fxns_init_){\n      main_fxns_init_ = new std::map<std::string, main_fxn>;\n    }\n    (*main_fxns_init_)[name] = fxn;\n  }\n}\n\nvoid\nUserAppCxxEmptyMain::aliasMains()\n{\n  static thread_lock lock;\n  lock.lock();\n  if (!empty_main_fxns_){\n    empty_main_fxns_ = std::unique_ptr<std::map<std::string, App::empty_main_fxn>>(empty_main_fxns_init_);\n    empty_main_fxns_init_ = nullptr;\n  }\n  auto* lib = App::getBuilderLibrary(\"macro\");\n  if (empty_main_fxns_){\n    for (auto& pair : *empty_main_fxns_){\n#if SSTMAC_INTEGRATED_SST_CORE\n      auto* builder = lib->getBuilder(\"UserAppCxxEmptyMain\");\n      lib->addBuilder(pair.first, builder);\n#else\n      using builder_t = sprockit::DerivedBuilder<App,UserAppCxxFullMain,SST::Params&,SoftwareId,OperatingSystem*>;\n      lib->addBuilder(pair.first, std::unique_ptr<builder_t>(new builder_t));\n#endif\n    }\n  }\n  lock.unlock();\n}\n\nvoid\nUserAppCxxFullMain::initArgv(argv_entry& entry)\n{\n  std::string appname = params_.find<std::string>(\"name\");\n  std::string argv_str = params_.find<std::string>(\"argv\", \"\");\n  std::deque<std::string> argv_param_dq;\n  pst::BasicStringTokenizer::tokenize(argv_str, argv_param_dq, std::string(\" \"));\n  int argc = argv_param_dq.size() + 1;\n  char* argv_buffer = new char[256 * argc];\n  char* argv_buffer_ptr = argv_buffer;\n  char** argv = new char*[argc+1];\n  argv[0] = argv_buffer;\n  ::strcpy(argv_buffer, appname.c_str());\n  int i=1;\n  argv_buffer_ptr += appname.size() + 1;\n  for (auto& src_str : argv_param_dq){\n    ::strcpy(argv_buffer_ptr, src_str.c_str());\n    argv[i] = argv_buffer_ptr;\n    //increment pointer for next strcpy\n    argv_buffer_ptr += src_str.size() + 1; //+1 for null terminator\n    ++i;\n  }\n  argv[argc] = nullptr; //missing nullptr - Issue #269\n  entry.argc = argc;\n  entry.argv = argv;\n}\n\nint\nUserAppCxxFullMain::skeletonMain()\n{\n  static thread_lock argv_lock;\n  argv_lock.lock();\n  argv_entry& entry = argv_map_[sid_.app_];\n  if (entry.argv == 0){\n    initArgv(entry);\n  }\n  argv_lock.unlock();\n  int rc = (*fxn_)(entry.argc, entry.argv);\n  return rc;\n}\n\nUserAppCxxEmptyMain::UserAppCxxEmptyMain(SST::Params& params, SoftwareId sid,\n                                         OperatingSystem* os) :\n  App(params, sid, os)\n{\n  if (!empty_main_fxns_){\n    empty_main_fxns_ = std::unique_ptr<std::map<std::string, App::empty_main_fxn>>(empty_main_fxns_init_);\n    empty_main_fxns_init_ = nullptr;\n  }\n\n  std::string name = params.find<std::string>(\"name\");\n  std::map<std::string, empty_main_fxn>::iterator it = empty_main_fxns_->find(name);\n  if (it == empty_main_fxns_->end()){\n    spkt_throw_printf(sprockit::ValueError,\n                     \"no user app with the name %s registered\",\n                     name.c_str());\n  }\n  fxn_ = it->second;\n}\n\nvoid\nUserAppCxxEmptyMain::registerMainFxn(const char *name, App::empty_main_fxn fxn)\n{\n  if (empty_main_fxns_){ //already cleared static init\n    (*empty_main_fxns_)[name] = fxn;\n  } else { \n    if (!empty_main_fxns_init_){\n      empty_main_fxns_init_ = new std::map<std::string, empty_main_fxn>;\n    }\n\n    (*empty_main_fxns_init_)[name] = fxn;\n  }\n\n#if 0\n  auto* lib = App::getBuilderLibrary(\"macro\");\n#if SSTMAC_INTEGRATED_SST_CORE\n  using builder_t = SST::ELI::DerivedBuilder<App,UserAppCxxFullMain,SST::Params&,SoftwareId,OperatingSystem*>;\n  lib->addBuilder(name, new builder_t);\n#else\n  using builder_t = sprockit::DerivedBuilder<App,UserAppCxxFullMain,SST::Params&,SoftwareId,OperatingSystem*>;\n  lib->addBuilder(name, std::unique_ptr<builder_t>(new builder_t));\n#endif\n#endif\n}\n\nint\nUserAppCxxEmptyMain::skeletonMain()\n{\n  return (*fxn_)();\n}\n\nvoid computeTime(double tsec)\n{\n  Thread* t = OperatingSystem::currentThread();\n  App* a = safe_cast(App, t,\n     \"cannot cast current thread to app in compute_time function\");\n  a->compute(TimeDelta(tsec));\n}\n\n}\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/sstmac/replacements/dlfcn.h": "/**\nCopyright 2009-2020 National Technology and Engineering Solutions of Sandia,\nLLC (NTESS).  Under the terms of Contract DE-NA-0003525, the U.S.  Government \nretains certain rights in this software.\n\nSandia National Laboratories is a multimission laboratory managed and operated\nby National Technology and Engineering Solutions of Sandia, LLC., a wholly \nowned subsidiary of Honeywell International, Inc., for the U.S. Department of \nEnergy's National Nuclear Security Administration under contract DE-NA0003525.\n\nCopyright (c) 2009-2020, NTESS\n\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without modification, \nare permitted provided that the following conditions are met:\n\n    * Redistributions of source code must retain the above copyright\n      notice, this list of conditions and the following disclaimer.\n\n    * Redistributions in binary form must reproduce the above\n      copyright notice, this list of conditions and the following\n      disclaimer in the documentation and/or other materials provided\n      with the distribution.\n\n    * Neither the name of the copyright holder nor the names of its\n      contributors may be used to endorse or promote products derived\n      from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n\"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\nLIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\nA PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\nOWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\nSPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\nLIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\nDATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\nTHEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\nQuestions? Contact sst-macro-help@sandia.gov\n*/\n#ifndef sstmac_dlfcn_h_included\n#define sstmac_dlfcn_h_included\n\n\n#include_next <dlfcn.h>\n\n#define dlopen sstmac_dlopen\n\n#ifdef __cplusplus\nextern \"C\" {\n#endif\n\nvoid *sstmac_dlopen(const char *filename, int flag);\n\n#ifdef __cplusplus\n}\n#endif\n\n#ifdef SIGNAL_H_OWNS_STL\n#undef SIGNAL_H_OWNS_STL\n#undef SSTMAC_INSIDE_STL\n#include <sstmac/replacements/sstmac_pthread_return.h>\n#endif\n\n#endif\n\n"
    },
    "skipped": [
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/pdes-report.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/developer-sstmacro-10.1.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/manual-sstmacro-10.1.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/.git/objects/pack/pack-665ee05465acd8b3f974f1a3cd720a83ddd00af9.idx",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/.git/objects/pack/pack-665ee05465acd8b3f974f1a3cd720a83ddd00af9.pack",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/tests/test_traces/testbgp-0000.bin",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/tests/test_traces/testbgp-0005.bin",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/tests/test_traces/testbgp-0004.bin",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/tests/test_traces/testtrace-0001.bin",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/tests/test_traces/testtrace-0000.bin",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/tests/test_traces/testbgp-0006.bin",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/tests/test_traces/testtrace-0002.bin",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/tests/test_traces/testbgp-0002.bin",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/tests/test_traces/testtrace-0003.bin",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/tests/test_traces/testbgp-0001.bin",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/tests/test_traces/testbgp-0003.bin",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/tests/reference/spyplot.num_messages.png.ref-out",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/tests/reference/spyplot.bytes.png.ref-out",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/tests/otf2_test_traces/profile.cubex",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/tests/otf2_test_traces/traces.otf2",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/tests/otf2_test_traces/traces.def",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/tests/otf2_test_traces/traces/1.def",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/tests/otf2_test_traces/traces/4.evt",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/tests/otf2_test_traces/traces/7.evt",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/tests/otf2_test_traces/traces/7.def",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/tests/otf2_test_traces/traces/9.evt",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/tests/otf2_test_traces/traces/2.def",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/tests/otf2_test_traces/traces/8.def",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/tests/otf2_test_traces/traces/8.evt",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/tests/otf2_test_traces/traces/3.evt",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/tests/otf2_test_traces/traces/5.evt",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/tests/otf2_test_traces/traces/6.evt",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/tests/otf2_test_traces/traces/2.evt",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/tests/otf2_test_traces/traces/9.def",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/tests/otf2_test_traces/traces/0.def",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/tests/otf2_test_traces/traces/4.def",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/tests/otf2_test_traces/traces/1.evt",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/tests/otf2_test_traces/traces/5.def",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/tests/otf2_test_traces/traces/3.def",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/tests/otf2_test_traces/traces/6.def",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/tests/otf2_test_traces/traces/0.evt",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/skeletons/traffic/TrafficFigure.jpg",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/skeletons/traffic/TrafficFigure.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/skeletons/traffic/TrafficFigure.graffle",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/developer/figures/desCore.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/developer/figures/pdesCore.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/developer/figures/pdesCore.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/developer/figures/DecisionFlow.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/developer/figures/DecisionFlow.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/developer/figures/DES.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/developer/figures/DES.graffle",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/developer/figures/RoutingFlow.graffle",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/developer/figures/sstlogo.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/developer/figures/components.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/developer/figures/components.graffle",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/developer/figures/EventHandler.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/developer/figures/components.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/developer/figures/desCore.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/developer/figures/DecisionFlow.graffle",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/developer/figures/RoutingFlow.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/developer/figures/DES.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/developer/figures/EventHandler.graffle",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/developer/figures/RoutingFlow.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/pisces_overview.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/messageSizeHistogramNekbone.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/Pisces.graffle",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/Pisces.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/macrels.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/sculpin.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/compilerWorkflow.graffle",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/Pisces.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/compilerWorkflow.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/pisces_overview.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/macrels.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/workflow.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/sculpin.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/macrels.graffle",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/workflow.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/sstlogo.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/uqSanity.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/compilerWorkflow.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/delayHistogramNekbone.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/pisces_overview.graffle",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/sculpin.graffle",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/congestionSpyplotNekbone.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/tikz/fattree/abstract_fattree.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/tikz/fattree/fattree_ids.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/tikz/fattree/abstract_fattree.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/tikz/fattree/fattree_coords.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/tikz/fattree/fattree_ids.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/tikz/fattree/fattree_coords.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/tikz/torus/minroutetorus.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/tikz/torus/minadroutetorus.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/tikz/torus/minroutetorus.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/tikz/torus/minadroutetorus.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/tikz/torus/torus.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/tikz/torus/torus.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/tikz/torus/withnodes.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/tikz/torus/withnodes.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/tikz/allocation/random.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/tikz/allocation/cartesian.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/tikz/allocation/firstavailable.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/tikz/allocation/random.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/tikz/allocation/firstavailable.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/tikz/allocation/cartesian.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/tikz/hypercube/hypercube_connected.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/tikz/hypercube/hypercube_allocation.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/tikz/hypercube/hypercube_path.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/tikz/hypercube/hypercube.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/tikz/hypercube/hypercube_valiant.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/tikz/hypercube/hypercube_connected.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/tikz/hypercube/hypercube_path.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/tikz/hypercube/hypercube_valiant.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/tikz/hypercube/hypercube_allocation.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/tikz/des/events.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/tikz/des/events.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/tikz/cascade/cascadevaliant.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/tikz/cascade/cascade.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/tikz/cascade/cascademinroute.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/tikz/cascade/cascademinroute.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/tikz/cascade/cascade.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/tikz/cascade/cascadevaliant.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/tikz/indexing/block.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/tikz/indexing/block.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/tikz/indexing/roundrobin.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/tikz/indexing/random.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/tikz/indexing/roundrobin.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/gnuplot/ftq/ftq.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/gnuplot/ftq/ftq.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/vtk/hopper.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/topologies/fattree4.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/topologies/compilerWorkflow.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/topologies/fattree4-tapered.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/topologies/fattree4.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/topologies/fattree4-tapered.graffle",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/topologies/fattree4.graffle",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/topologies/fattree4-tapered.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/network/congestion.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/network/congestion.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/matplotlib/ftq/pic1024.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/amm/AMM1.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/amm/amm2_membus.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/amm/AMM1.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/amm/amm3_switch.ccd",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/amm/amm2_membus.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/amm/amm3_switch.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/amm/amm2_membus.ccd",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/amm/amm3_switch.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/spyplot/mpi_spyplot.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/spyplot/mpi_spyplot.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/graphviz/gui.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/graphviz/navwindow.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/graphviz/gui.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/graphviz/sidebar.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/graphviz/callgraph2.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/graphviz/navwindow.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/graphviz/callgraph1.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/graphviz/callgraph2.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/graphviz/callgraph1.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/graphviz/sidebar.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/gui/networkswitchtooltip.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/gui/network.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/gui/manager.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/gui/network.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/gui/manager.png",
        "/tmp/vanessa/spack-stage/spack-stage-sst-macro-master-62mwva7waqj7rngdiq3c4io6vcssvra5/spack-src/docs/manual/figures/gui/networkswitchtooltip.pdf"
    ],
    "total_files": 2362
}