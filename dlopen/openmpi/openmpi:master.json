{
    "matches": {
        "/tmp/vanessa/spack-stage/spack-stage-openmpi-master-qcrm7qmgqutvsby2zcmdb57s22lzfq65/spack-src/.gitignore": ".libs\n.deps\n.libs\n.dirstamp\n.DS_Store\n.cdt*\n.project\n.gdb*\n.idea\n\n.hgrc\n.hgignore\n.hg\n.hgignore_local\n\n*.la\n*.lo\n*.o\n*.so\n*.a\n*.dwarf\n*.dSYM\n*.S\n*.loT\n*.orig\n*.rej\n*.bak\n*.class\n*.xcscheme\n*.out\n*.plist\n*.orig\n*.obj\n*.mod\n*.i90\n*.ii\n*.ti\n*.exe\n*.log\n*.trs\n*.sapp\n*~\n*\\\\#\n\nMakefile\nMakefile.in\n\n# hwloc and pmix have been de-modularized, but still uses parts of the\n# MCA system due to the amount of glue code that ended up in the\n# framework base.  Until that is cleaned up, do not ignore the\n# hard-coded static-components.h file.\nstatic-components.h\n!opal/mca/hwloc/base/static-components.h\n!opal/mca/pmix/base/static-components.h\n\n*\\\\#\nconfig.cache\naclocal.m4\nautom4te.cache\nconfig.log\nconfig.status\nconfigure\nlibtool\ndoxygen\nbin\nlib\ncscope.*\netags\nGRTAGS\nGSYMS\nGTAGS\nGPATH\nvc70.pdb\n.hgrc\n.hgignore\n.hg\n.hgignore_local\nstamp-h?\nAUTHORS\n\nar-lib\nylwrap\nconfig.lt\nconfig.guess\nconfig.sub\ndepcomp\ncompile\ninstall-sh\nltmain.sh\nmissing\nmkinstalldirs\nlibtool.m4\nlt~obsolete.m4\nltdl.m4\nargz.m4\nltargz.m4\nltsugar.m4\nltversion.m4\nltoptions.m4\n\n# Libevent and hwloc are included as a tarball.  Ignore any expanded\n# tarballs, since they are not included in git.  Do not ignore the\n# tarballs themselves, and those are artifacts we will store in git.\n3rd-party/libevent-*\n!3rd-party/libevent-*.tar.*\n3rd-party/hwloc-*\n!3rd-party/hwloc-*.tar.*\n\nconfig/project_list.m4\nconfig/autogen_found_items.m4\nconfig/opal_get_version.sh\nconfig/test-driver\nconfig/mca_no_configure_components.m4\nconfig/mca_m4_config_include.m4\nconfig/ext_no_configure_components.m4\nconfig/ext_m4_config_include.m4\n\ncontrib/build-mca-comps-outside-of-tree/btl_tcp2_config.h\ncontrib/build-mca-comps-outside-of-tree/btl_tcp2_config.h.in\ncontrib/build-mca-comps-outside-of-tree/config\ncontrib/build-mca-comps-outside-of-tree/aclocal.m4\ncontrib/dist/linux/compile_debian_mlnx_example\ncontrib/dist/mofed/compile_debian_mlnx_example\ncontrib/dist/mofed/debian/changelog\ncontrib/dist/mofed/debian/control\ncontrib/dist/mofed/debian/copyright\ncontrib/dist/mofed/debian/rules\ncontrib/platform/intel/bend/*orcm*\ncontrib/scaling/orte_no_op\ncontrib/scaling/mpi_no_op\ncontrib/scaling/mpi_barrier\ncontrib/scaling/mpi_memprobe\n\nexamples/hello_c\nexamples/hello_cxx\nexamples/hello_mpifh\nexamples/hello_usempi\nexamples/hello_usempif08\nexamples/ring_c\nexamples/ring_cxx\nexamples/ring_mpifh\nexamples/ring_usempi\nexamples/ring_usempif08\nexamples/connectivity_c\nexamples/ring_oshmem\nexamples/hello_oshmem\nexamples/ring_oshmemfh\nexamples/hello_oshmemfh\nexamples/hello_oshmemcxx\nexamples/oshmem_circular_shift\nexamples/oshmem_max_reduction\nexamples/oshmem_shmalloc\nexamples/oshmem_strided_puts\nexamples/oshmem_symmetric_data\nexamples/spc_example\n\nompi/debuggers/*.in\nompi/debuggers/dlopen_test\nompi/debuggers/predefined_gap_test\nompi/debuggers/predefined_pad_test\n\nompi/include/mpi.h\nompi/include/mpif-config.h\nompi/include/mpif.h\nompi/include/mpif-c-constants-decl.h\nompi/include/mpif-c-constants.h\nompi/include/mpif-common.h\nompi/include/mpi-ext.h\nompi/include/mpif-ext.h\nompi/include/mpif-f08-types.h\nompi/include/mpif-handles.h\nompi/include/mpif-io-constants.h\nompi/include/mpif-constants.h\nompi/include/mpif-io-handles.h\nompi/include/mpif-sizeof.h\nompi/include/mpi_portable_platform.h\nompi/include/ompi/version.h\nompi/include/ompi/frameworks.h\n\nompi/mca/coll/basic/coll-basic-version.h*\nompi/mca/coll/demo/config\nompi/mca/coll/demo/coll_demo_config.h*\nompi/mca/coll/demo/coll-demo-version.h*\nompi/mca/coll/ml/coll_ml_lex.c\nompi/mca/coll/self/coll-self-version.h*\nompi/mca/coll/sm/coll-sm-version.h*\n\nompi/mca/crcp/ompi_crcp.7\n\nompi/mca/io/romio321/romio/adio/include/romioconf.h\nompi/mca/io/romio321/romio/include/mpio.h\nompi/mca/io/romio321/romio/localdefs\nompi/mca/io/romio321/romio/test/fcoll_test.f\nompi/mca/io/romio321/romio/test/fmisc.f\nompi/mca/io/romio321/romio/test/fperf.f\nompi/mca/io/romio321/romio/test/large_file.c\nompi/mca/io/romio321/romio/test/misc.c\nompi/mca/io/romio321/romio/test/pfcoll_test.f\nompi/mca/io/romio321/romio/test/runtests\nompi/mca/io/romio321/romio/util/romioinstall\nompi/mca/io/romio321/romio/test/syshints.c\n\nompi/mca/osc/monitoring/osc_monitoring_template_gen.h\n\nompi/mca/pml/v/autogen.vprotocols\nompi/mca/pml/v/mca_vprotocol_config_output\n\nompi/mca/rte/orte/ompi-ps.1\nompi/mca/rte/orte/ompi-clean.1\nompi/mca/rte/orte/mpiexec.1\nompi/mca/rte/orte/ompi-top.1\nompi/mca/rte/orte/ompi-server.1\nompi/mca/rte/orte/ompi-restart.1\nompi/mca/rte/orte/ompi-checkpoint.1\nompi/mca/rte/orte/mpirun.1\n\nompi/mca/sharedfp/addproc/mca_sharedfp_addproc_control\n\nompi/mca/topo/treematch/config.h\n\nompi/mpi/c/profile/p*.c\n\nompi/mpi/fortran/configure-fortran-output.h\nompi/mpi/fortran/mpiext/mpi-ext-module.F90\nompi/mpi/fortran/mpiext/mpi-f08-ext-module.F90\nompi/mpi/fortran/mpiext-use-mpi/mpi-ext-module.F90\nompi/mpi/fortran/mpiext-use-mpi-f08/mpi-f08-ext-module.F90\n\nompi/mpi/fortran/mpif-h/sizeof_f.f90\nompi/mpi/fortran/mpif-h/profile/p*.c\nompi/mpi/fortran/mpif-h/profile/psizeof_f.f90\n\nompi/mpi/fortran/use-mpi/mpi-types.F90\n\nompi/mpi/fortran/use-mpi-f08/mod/mpi-f08-constants.h\nompi/mpi/fortran/use-mpi-f08/mod/mpi-f08-interfaces.h\nompi/mpi/fortran/use-mpi-f08/sizeof_f08.f90\nompi/mpi/fortran/use-mpi-f08/sizeof_f08.h\nompi/mpi/fortran/use-mpi-f08/profile/psizeof_f08.f90\nompi/mpi/fortran/use-mpi-f08/profile/*.F90\n\nompi/mpi/fortran/use-mpi-ignore-tkr/mpi-ignore-tkr-interfaces.h\nompi/mpi/fortran/use-mpi-ignore-tkr/mpi-ignore-tkr-file-interfaces.h\nompi/mpi/fortran/use-mpi-ignore-tkr/mpi-ignore-tkr-sizeof.f90\nompi/mpi/fortran/use-mpi-ignore-tkr/mpi-ignore-tkr-sizeof.h\nompi/mpi/fortran/use-mpi-ignore-tkr/mpi-ignore-tkr-removed-interfaces.h\n\nompi/mpi/fortran/use-mpi-tkr/fortran_kinds.sh\nompi/mpi/fortran/use-mpi-tkr/fortran_sizes.h\nompi/mpi/fortran/use-mpi-tkr/mpi_kinds.ompi_module\nompi/mpi/fortran/use-mpi-tkr/mpi-tkr-sizeof.f90\nompi/mpi/fortran/use-mpi-tkr/mpi-tkr-sizeof.h\n\nompi/mpi/java/java/mpi\nompi/mpi/java/java/*.jar\nompi/mpi/java/java/*.h\nompi/mpi/java/java/doc\n\nompi/mpi/man/man3/MPI*.3\nompi/mpi/man/man3/OpenMPI.3\nompi/mpi/man/man3/.dir-stamp\n\nompi/mpi/tool/profile/*.c\n\nompi/mpiext/affinity/c/OMPI_Affinity_str.3\nompi/mpiext/affinity/c/example\n\nompi/mpiext/example/tests/progress_c\nompi/mpiext/example/tests/progress_mpifh\nompi/mpiext/example/tests/progress_usempi\nompi/mpiext/example/tests/progress_usempif08\n\nompi/mpiext/cuda/c/MPIX_Query_cuda_support.3\nompi/mpiext/cuda/c/mpiext_cuda_c.h\nompi/mpiext/cuda/c/cuda_c.h\n\nompi/mpiext/pcollreq/c/MPIX_*.3\nompi/mpiext/pcollreq/c/profile/pallgather_init.c\nompi/mpiext/pcollreq/c/profile/pallgatherv_init.c\nompi/mpiext/pcollreq/c/profile/pallreduce_init.c\nompi/mpiext/pcollreq/c/profile/palltoall_init.c\nompi/mpiext/pcollreq/c/profile/palltoallv_init.c\nompi/mpiext/pcollreq/c/profile/palltoallw_init.c\nompi/mpiext/pcollreq/c/profile/pbarrier_init.c\nompi/mpiext/pcollreq/c/profile/pbcast_init.c\nompi/mpiext/pcollreq/c/profile/pexscan_init.c\nompi/mpiext/pcollreq/c/profile/pgather_init.c\nompi/mpiext/pcollreq/c/profile/pgatherv_init.c\nompi/mpiext/pcollreq/c/profile/pmpiext_pcollreq_c.h\nompi/mpiext/pcollreq/c/profile/pneighbor_allgather_init.c\nompi/mpiext/pcollreq/c/profile/pneighbor_allgatherv_init.c\nompi/mpiext/pcollreq/c/profile/pneighbor_alltoall_init.c\nompi/mpiext/pcollreq/c/profile/pneighbor_alltoallv_init.c\nompi/mpiext/pcollreq/c/profile/pneighbor_alltoallw_init.c\nompi/mpiext/pcollreq/c/profile/preduce_init.c\nompi/mpiext/pcollreq/c/profile/preduce_scatter_block_init.c\nompi/mpiext/pcollreq/c/profile/preduce_scatter_init.c\nompi/mpiext/pcollreq/c/profile/pscan_init.c\nompi/mpiext/pcollreq/c/profile/pscatter_init.c\nompi/mpiext/pcollreq/c/profile/pscatterv_init.c\nompi/mpiext/pcollreq/c/profile/ppcollreq_c.h\n\nompi/mpiext/pcollreq/mpif-h/profile/pallgather_init_f.c\nompi/mpiext/pcollreq/mpif-h/profile/pallgatherv_init_f.c\nompi/mpiext/pcollreq/mpif-h/profile/pallreduce_init_f.c\nompi/mpiext/pcollreq/mpif-h/profile/palltoall_init_f.c\nompi/mpiext/pcollreq/mpif-h/profile/palltoallv_init_f.c\nompi/mpiext/pcollreq/mpif-h/profile/palltoallw_init_f.c\nompi/mpiext/pcollreq/mpif-h/profile/pbarrier_init_f.c\nompi/mpiext/pcollreq/mpif-h/profile/pbcast_init_f.c\nompi/mpiext/pcollreq/mpif-h/profile/pexscan_init_f.c\nompi/mpiext/pcollreq/mpif-h/profile/pgather_init_f.c\nompi/mpiext/pcollreq/mpif-h/profile/pgatherv_init_f.c\nompi/mpiext/pcollreq/mpif-h/profile/pneighbor_allgather_init_f.c\nompi/mpiext/pcollreq/mpif-h/profile/pneighbor_allgatherv_init_f.c\nompi/mpiext/pcollreq/mpif-h/profile/pneighbor_alltoall_init_f.c\nompi/mpiext/pcollreq/mpif-h/profile/pneighbor_alltoallv_init_f.c\nompi/mpiext/pcollreq/mpif-h/profile/pneighbor_alltoallw_init_f.c\nompi/mpiext/pcollreq/mpif-h/profile/preduce_init_f.c\nompi/mpiext/pcollreq/mpif-h/profile/preduce_scatter_block_init_f.c\nompi/mpiext/pcollreq/mpif-h/profile/preduce_scatter_init_f.c\nompi/mpiext/pcollreq/mpif-h/profile/pscan_init_f.c\nompi/mpiext/pcollreq/mpif-h/profile/pscatter_init_f.c\nompi/mpiext/pcollreq/mpif-h/profile/pscatterv_init_f.c\n\nompi/mpiext/shortfloat/c/mpiext_shortfloat_c.h\nompi/mpiext/shortfloat/mpif-h/mpiext_shortfloat_mpifh.h\nompi/mpiext/shortfloat/use-mpi-f08/mpiext_shortfloat_usempif08.h\n\nompi/tools/mpisync/mpisync\nompi/tools/mpisync/mpirun_prof\nompi/tools/mpisync/ompi_timing_post\nompi/tools/mpisync/mpisync.1\n\nompi/tools/ompi_info/ompi_info\nompi/tools/ompi_info/ompi_info.1\n\nompi/tools/wrappers/mpic++-wrapper-data.txt\nompi/tools/wrappers/mpicc-wrapper-data.txt\nompi/tools/wrappers/mpifort-wrapper-data.txt\nompi/tools/wrappers/mpicc.1\nompi/tools/wrappers/mpic++.1\nompi/tools/wrappers/mpicxx.1\nompi/tools/wrappers/mpifort.1\nompi/tools/wrappers/mpijavac.1\nompi/tools/wrappers/ompi_wrapper_script\nompi/tools/wrappers/ompi.pc\nompi/tools/wrappers/ompi-c.pc\nompi/tools/wrappers/ompi-cxx.pc\nompi/tools/wrappers/ompi-fort.pc\nompi/tools/wrappers/mpijavac.pl\nompi/tools/wrappers/mpif90.1\nompi/tools/wrappers/mpif77.1\nompi/tools/wrappers/mpicxx-wrapper-data.txt\nompi/tools/wrappers/mpif77-wrapper-data.txt\nompi/tools/wrappers/mpif90-wrapper-data.txt\n\nopal/libltdl\n\nopal/asm/atomic-asm.S\nopal/asm/atomic-test\nopal/asm/generated/atomic-*.s\n\nopal/include/opal_config.h\nopal/include/opal_config.h.in\nopal/include/opal/install_dirs.h\nopal/include/opal/version.h\nopal/include/opal/frameworks.h\nopal/include/opal/sys/powerpc/atomic-32.s\nopal/include/opal/sys/powerpc/atomic-64.s\nopal/include/opal/sys/powerpc/atomic-32-64.s\n\nopal/mca/base/mca_base_parse_paramfile_lex.c\n\nopal/mca/common/libfabric/libfabric/config.h\n\nopal/mca/btl/openib/btl_openib_lex.c\n\nopal/mca/btl/usnic/usnic_btl_run_tests\n\nopal/mca/crs/opal_crs.7\n\nopal/mca/event/libevent*/libevent/config.h.in\nopal/mca/event/libevent*/libevent/config.h\nopal/mca/event/libevent*/libevent/libevent.pc\nopal/mca/event/libevent*/libevent/libevent_openssl.pc\nopal/mca/event/libevent*/libevent/libevent_pthreads.pc\nopal/mca/event/libevent*/libevent/include/event2/event-config.h\n\nopal/mca/installdirs/config/install_dirs.h\n\n!opal/mca/pmix/pmix*/openpmix/AUTHORS\n!opal/mca/pmix/pmix*/openpmix/contrib/perf_tools/Makefile\nopal/mca/pmix/pmix*/openpmix/include/pmix/autogen/config.h\nopal/mca/pmix/pmix*/openpmix/include/pmix/autogen/config.h.in\nopal/mca/pmix/pmix*/openpmix/src/include/private/autogen/config.h.in\nopal/mca/pmix/pmix*/openpmix/src/include/private/autogen/config.h\nopal/mca/pmix/pmix*/openpmix/src/include/frameworks.h\nopal/mca/pmix/pmix*/openpmix/src/mca/pinstalldirs/config/pinstall_dirs.h\nopal/mca/pmix/pmix*/openpmix/config/autogen_found_items.m4\nopal/mca/pmix/pmix*/openpmix/config/mca_library_paths.txt\nopal/mca/pmix/pmix*/openpmix/config/test-driver\nopal/mca/pmix/pmix*/openpmix/src/include/pmix_config.h\nopal/mca/pmix/pmix*/openpmix/src/include/pmix_config.h.in\nopal/mca/pmix/pmix*/openpmix/include/pmix_common.h\nopal/mca/pmix/pmix*/openpmix/include/pmix_rename.h\nopal/mca/pmix/pmix*/openpmix/include/pmix_version.h\nopal/mca/pmix/pmix*/openpmix/src/util/keyval/keyval_lex.c\nopal/mca/pmix/pmix*/openpmix/src/util/show_help_lex.c\nopal/mca/pmix/pmix*/openpmix/examples/alloc\nopal/mca/pmix/pmix*/openpmix/examples/client\nopal/mca/pmix/pmix*/openpmix/examples/debugger\nopal/mca/pmix/pmix*/openpmix/examples/debuggerd\nopal/mca/pmix/pmix*/openpmix/examples/dmodex\nopal/mca/pmix/pmix*/openpmix/examples/dynamic\nopal/mca/pmix/pmix*/openpmix/examples/fault\nopal/mca/pmix/pmix*/openpmix/examples/jctrl\nopal/mca/pmix/pmix*/openpmix/examples/pub\nopal/mca/pmix/pmix*/openpmix/examples/server\nopal/mca/pmix/pmix*/openpmix/examples/tool\nopal/mca/pmix/pmix*/openpmix/test/run_tests00.pl\nopal/mca/pmix/pmix*/openpmix/test/run_tests01.pl\nopal/mca/pmix/pmix*/openpmix/test/run_tests02.pl\nopal/mca/pmix/pmix*/openpmix/test/run_tests03.pl\nopal/mca/pmix/pmix*/openpmix/test/run_tests04.pl\nopal/mca/pmix/pmix*/openpmix/test/run_tests05.pl\nopal/mca/pmix/pmix*/openpmix/test/run_tests06.pl\nopal/mca/pmix/pmix*/openpmix/test/run_tests07.pl\nopal/mca/pmix/pmix*/openpmix/test/run_tests08.pl\nopal/mca/pmix/pmix*/openpmix/test/run_tests09.pl\nopal/mca/pmix/pmix*/openpmix/test/run_tests10.pl\nopal/mca/pmix/pmix*/openpmix/test/run_tests11.pl\nopal/mca/pmix/pmix*/openpmix/test/run_tests12.pl\nopal/mca/pmix/pmix*/openpmix/test/run_tests13.pl\nopal/mca/pmix/pmix*/openpmix/test/run_tests14.pl\nopal/mca/pmix/pmix*/openpmix/test/run_tests15.pl\nopal/mca/pmix/pmix*/openpmix/src/tools/wrapper/pmix.pc\nopal/mca/pmix/pmix*/openpmix/src/tools/wrapper/pmixcc-wrapper-data.txt\n\n\nopal/mca/pmix/ext4x/ext4x.c\nopal/mca/pmix/ext4x/ext4x.h\nopal/mca/pmix/ext4x/ext4x_client.c\nopal/mca/pmix/ext4x/ext4x_component.c\nopal/mca/pmix/ext4x/ext4x_server_north.c\nopal/mca/pmix/ext4x/ext4x_server_south.c\n\nopal/tools/opal-checkpoint/opal-checkpoint\nopal/tools/opal-checkpoint/opal-checkpoint.1\nopal/tools/opal-restart/opal-restart\nopal/tools/opal-restart/opal-restart.1\n\nopal/tools/wrappers/opalcc-wrapper-data.txt\nopal/tools/wrappers/opalc++-wrapper-data.txt\nopal/tools/wrappers/opalCC-wrapper-data.txt\nopal/tools/wrappers/opal_wrapper\nopal/tools/wrappers/opalcc.1\nopal/tools/wrappers/opalc++.1\nopal/tools/wrappers/generic_wrapper.1\nopal/tools/wrappers/opal_wrapper.1\nopal/tools/wrappers/opal.pc\n\nopal/util/show_help_lex.c\nopal/util/keyval/keyval_lex.c\n\ntest/simple/abort\ntest/simple/accept\ntest/simple/attach\ntest/simple/bad_exit\ntest/simple/bcast_loop\ntest/simple/binding\ntest/simple/concurrent_spawn\ntest/simple/connect\ntest/simple/crisscross\ntest/simple/delayed_abort\ntest/simple/hello_barrier\ntest/simple/hello_nodename\ntest/simple/hello_output\ntest/simple/hello_show_help\ntest/simple/hello\ntest/simple/hello++\ntest/simple/intercomm1\ntest/simple/interlib\ntest/simple/loop_child\ntest/simple/loop_spawn\ntest/simple/mpi_barrier\ntest/simple/mpi_no_op\ntest/simple/mpi_spin\ntest/simple/multi_abort\ntest/simple/parallel_r8\ntest/simple/parallel_r64\ntest/simple/parallel_w8\ntest/simple/parallel_w64\ntest/simple/pinterlib\ntest/simple/pmix\ntest/simple/pubsub\ntest/simple/read_write\ntest/simple/reduce-hang\ntest/simple/ring\ntest/simple/segv\ntest/simple/simple_spawn\ntest/simple/slave\ntest/simple/spawn_multiple\ntest/simple/xlib\ntest/simple/ziaprobe\ntest/simple/ziatest\ntest/simple/*.dwarf\ntest/simple/junk*\ntest/simple/sio\ntest/simple/sendrecv_blaster\ntest/simple/early_abort\ntest/simple/spawn_problem/ch_rec\ntest/simple/spawn_problem/output\ntest/simple/spawn_problem/start\ntest/simple/debugger\ntest/simple/server_port_name.txt\ntest/simple/singleton_client_server\ntest/simple/intercomm_create\ntest/simple/spawn_tree\ntest/simple/init-exit77\ntest/simple/mpi_info\ntest/simple/info_spawn\ntest/simple/client\ntest/simple/server\ntest/simple/paccept\ntest/simple/pconnect\ntest/simple/thread_init\ntest/simple/memcached-dummy\ntest/simple/coll_test\ntest/simple/badcoll\ntest/simple/iof\ntest/simple/no-disconnect\ntest/simple/nonzero\ntest/simple/add_host\n\noshmem/include/shmem.h\noshmem/include/shmem_portable_platform.h\noshmem/include/oshmem/frameworks.h\noshmem/include/oshmem/version.h\n\noshmem/mca/sshmem/base/static-components.h\n\noshmem/shmem/c/profile/p*.c\noshmem/shmem/c/profile/*.c\n\noshmem/shmem/fortran/libshmem_fortran.la\noshmem/shmem/fortran/profile/pshmem_*_f.c\noshmem/shmem/fortran/profile/pshpdeallc_f.c\noshmem/shmem/fortran/profile/pshpclmove_f.c\noshmem/shmem/fortran/profile/pmy_pe_f.c\noshmem/shmem/fortran/profile/pshpalloc_f.c\noshmem/shmem/fortran/profile/pnum_pes_f.c\noshmem/shmem/fortran/profile/pstart_pes_f.c\n\noshmem/shmem/java/java/shmem.jar\noshmem/shmem/java/java/doc\noshmem/shmem/java/java/shmem_Constant.h\noshmem/shmem/java/java/shmem_ShMem.h\noshmem/shmem/java/java/shmem\noshmem/shmem/java/java/shmem_Addr.h\noshmem/shmem/java/java/shmem_PSync.h\n\noshmem/shmem/man/man3/shmem_*.3\noshmem/shmem/man/man3/OpenSHMEM.3\noshmem/shmem/man/man3/intro_shmem.3\noshmem/shmem/man/man3/_my_pe.3\noshmem/shmem/man/man3/_num_pes.3\noshmem/shmem/man/man3/shfree.3\noshmem/shmem/man/man3/shmalloc.3\noshmem/shmem/man/man3/shmemalign.3\noshmem/shmem/man/man3/shrealloc.3\noshmem/shmem/man/man3/start_pes.3\noshmem/shmem/man/man3/.dir-stamp\n\noshmem/tools/oshmem_info/oshmem_info\noshmem/tools/oshmem_info/oshmem_info.1\n\noshmem/tools/wrappers/oshcc.1\noshmem/tools/wrappers/oshfort.1\noshmem/tools/wrappers/oshrun.1\noshmem/tools/wrappers/shmemcc.1\noshmem/tools/wrappers/shmemfort.1\noshmem/tools/wrappers/shmemrun.1\noshmem/tools/wrappers/shmemcc-wrapper-data.txt\noshmem/tools/wrappers/shmemfort-wrapper-data.txt\noshmem/tools/wrappers/oshCC.1\noshmem/tools/wrappers/oshc++.1\noshmem/tools/wrappers/oshcxx.1\noshmem/tools/wrappers/shmemCC.1\noshmem/tools/wrappers/shmemc++-wrapper-data.txt\noshmem/tools/wrappers/shmemc++.1\noshmem/tools/wrappers/shmemcxx.1\n\ntest/asm/atomic_math_noinline\ntest/asm/atomic_barrier\ntest/asm/atomic_cmpset_noinline\ntest/asm/atomic_math\ntest/asm/atomic_cmpset\ntest/asm/atomic_spinlock_noinline.c\ntest/asm/atomic_barrier_noinline.c\ntest/asm/atomic_math_noinline.c\ntest/asm/atomic_cmpset_noinline.c\ntest/asm/atomic_spinlock_noinline\ntest/asm/atomic_barrier_noinline\ntest/asm/atomic_spinlock\n\ntest/class/*.txt\ntest/class/ompi_bitmap_test_out.txt\ntest/class/ompi_circular_buffer_fifo\ntest/class/ompi_fifo\ntest/class/ompi_rb_tree\ntest/class/ompi_bitmap\ntest/class/opal_bitmap\ntest/class/opal_fifo\ntest/class/opal_hash_table\ntest/class/opal_lifo\ntest/class/opal_list\ntest/class/opal_pointer_array\ntest/class/opal_proc_table\ntest/class/opal_tree\ntest/class/opal_value_array\n\ntest/datatype/ddt_test\ntest/datatype/ddt_pack\ntest/datatype/external32\ntest/datatype/to_self\ntest/datatype/checksum\ntest/datatype/position\ntest/datatype/ddt_raw\ntest/datatype/opal_datatype_test\ntest/datatype/position_noncontig\ntest/datatype/unpack_ooo\ntest/datatype/unpack_hetero\n\ntest/dss/dss_buffer\ntest/dss/dss_copy\ntest/dss/dss_size\ntest/dss/dss_cmp\ntest/dss/dss_release\ntest/dss/dss_payload\ntest/dss/dss_set_get\ntest/dss/dss_print\n\ntest/event/signal-test\ntest/event/event-test\ntest/event/time-test\n\ntest/monitoring/monitoring_test\ntest/monitoring/check_monitoring\ntest/monitoring/example_reduce_count\ntest/monitoring/test_overhead\ntest/monitoring/test_pvar_access\n\n\ntest/mpi/environment/chello\n\ntest/runtime/parse_context\ntest/runtime/sigchld\ntest/runtime/start_shut\ntest/runtime/opal_init_finalize\ntest/runtime/orte_init_finalize\n\ntest/spc/spc_test\n\ntest/threads/opal_condition\ntest/threads/opal_thread\n\ntest/util/aaa\ntest/util/test_session_dir_out\ntest/util/opal_os_path\ntest/util/opal_argv\ntest/util/opal_os_create_dirpath\ntest/util/opal_if\ntest/util/opal_error\ntest/util/opal_timer\ntest/util/orte_sys_info\ntest/util/orte_session_dir\ntest/util/orte_sys_info\ntest/util/orte_universe_setup_file_io\ntest/util/opal_basename\ntest/util/ompi_numtostr\ntest/util/ompi_pack\ntest/util/test-file\ntest/util/opal_sos\ntest/util/opal_path_nfs\ntest/util/opal_path_nfs.out\ntest/util/opal_bit_ops\ntest/util/bipartite_graph\n\nopal/test/reachable/reachable_netlink\nopal/test/reachable/reachable_weighted\nopal/mca/threads/argobots/threads_argobots.h\nopal/mca/threads/qthreads/threads_qthreads.h\n",
        "/tmp/vanessa/spack-stage/spack-stage-openmpi-master-qcrm7qmgqutvsby2zcmdb57s22lzfq65/spack-src/README.md": "# Open MPI\n\nThe Open MPI Project is an open source Message Passing Interface (MPI)\nimplementation that is developed and maintained by a consortium of\nacademic, research, and industry partners.  Open MPI is therefore able\nto combine the expertise, technologies, and resources from all across\nthe High Performance Computing community in order to build the best\nMPI library available.  Open MPI offers advantages for system and\nsoftware vendors, application developers and computer science\nresearchers.\n\nSee [the MPI Forum web site](https://mpi-forum.org/) for information\nabout the MPI API specification.\n\n## Quick start\n\nIn many cases, Open MPI can be built and installed by simply\nindicating the installation directory on the command line:\n\n```\n$ tar xf openmpi-<version>.tar.bz2\n$ cd openmpi-<version>\n$ ./configure --prefix=<path> |& tee config.out\n...lots of output...\n$ make -j 8 |& tee make.out\n...lots of output...\n$ make install |& tee install.out\n...lots of output...\n```\n\nNote that there are many, many configuration options to the\n`./configure` step.  Some of them may be needed for your particular\nenvironmnet; see below for desciptions of the options available.\n\nIf your installation prefix path is not writable by a regular user,\nyou may need to use sudo or su to run the `make install` step.  For\nexample:\n\n```\n$ sudo make install |& tee install.out\n[sudo] password for jsquyres: <enter your password here>\n...lots of output...\n```\n\nFinally, note that VPATH builds are fully supported.  For example:\n\n```\n$ tar xf openmpi-<version>.tar.bz2\n$ cd openmpi-<version>\n$ mkdir build\n$ cd build\n$ ../configure --prefix=<path> |& tee config.out\n...etc.\n```\n\n## Table of contents\n\nThe rest of this file contains:\n\n* [General release notes about Open MPI](#general-notes)\n  * [Platform-specific notes](#platform-notes)\n  * [Compiler-specific notes](#compiler-notes)\n  * [Run-time support notes](#general-run-time-support-notes)\n  * [MPI functionality and features](#mpi-functionality-and-features)\n  * [OpenSHMEM functionality and\n    features](#openshmem-functionality-and-features)\n  * [MPI collectives](#mpi-collectives)\n  * [OpenSHMEM collectives](#openshmem-collectives)\n  * [Network support](#network-support)\n  * [Open MPI extensions](#open-mpi-extensions)\n* [Detailed information on building Open MPI](#building-open-mpi)\n  * [Installation options](#installation-options)\n  * [Networking support and options](#networking-support--options)\n  * [Run-time system support and options](#run-time-system-support)\n  * [Miscellaneous support\n    libraries](#miscellaneous-support-libraries)\n  * [MPI functionality options](#mpi-functionality)\n  * [OpenSHMEM functionality options](#openshmem-functionality)\n  * [Miscellaneous functionality\n    options](#miscellaneous-functionality)\n* [Open MPI version and library numbering\n  policies](#open-mpi-version-numbers-and-binary-compatibility)\n  * [Backwards compatibility polices](#backwards-compatibility)\n  * [Software version numbering](#software-version-number)\n  * [Shared library version numbering](#shared-library-version-number)\n* [Information on how to both query and validate your Open MPI\n  installation](#checking-your-open-mpi-installation)\n* [Description of Open MPI extensions](#open-mpi-api-extensions)\n  * [Compiling the extensions](#compiling-the-extensions)\n  * [Using the extensions](#using-the-extensions)\n* [Examples showing how to compile Open MPI applications](#compiling-open-mpi-applications)\n* [Examples showing how to run Open MPI applications](#running-open-mpi-applications)\n* [Summary information on the various plugin\n frameworks](#the-modular-component-architecture-mca)\n  * [MPI layer frameworks](#mpi-layer-frameworks)\n  * [OpenSHMEM component frameworks](#openshmem-component-frameworks)\n  * [Run-time environment\n    frameworks](#back-end-run-time-environment-rte-component-frameworks)\n  * [Miscellaneous frameworks](#miscellaneous-frameworks)\n  * [Other notes about frameworks](#framework-notes)\n* [How to get more help](#questions--problems)\n\nAlso, note that much, much more information is also available [in the\nOpen MPI FAQ](https://www.open-mpi.org/faq/).\n\n\n## General notes\n\nThe following abbreviated list of release notes applies to this code\nbase as of this writing (April 2020):\n\n* Open MPI now includes two public software layers: MPI and OpenSHMEM.\n  Throughout this document, references to Open MPI implicitly include\n  both of these layers. When distinction between these two layers is\n  necessary, we will reference them as the \"MPI\" and \"OpenSHMEM\"\n  layers respectively.\n\n* OpenSHMEM is a collaborative effort between academia, industry, and\n  the U.S. Government to create a specification for a standardized API\n  for parallel programming in the Partitioned Global Address Space\n  (PGAS).  For more information about the OpenSHMEM project, including\n  access to the current OpenSHMEM specification, please visit\n  http://openshmem.org/.\n\n  This OpenSHMEM implementation will only work in Linux environments\n  with a restricted set of supported networks.\n\n* Open MPI includes support for a wide variety of supplemental\n  hardware and software package.  When configuring Open MPI, you may\n  need to supply additional flags to the `configure` script in order\n  to tell Open MPI where the header files, libraries, and any other\n  required files are located.  As such, running `configure` by itself\n  may not include support for all the devices (etc.) that you expect,\n  especially if their support headers / libraries are installed in\n  non-standard locations.  Network interconnects are an easy example\n  to discuss -- Libfabric and OpenFabrics networks, for example, both\n  have supplemental headers and libraries that must be found before\n  Open MPI can build support for them.  You must specify where these\n  files are with the appropriate options to configure.  See the\n  listing of configure command-line switches, below, for more details.\n\n* The majority of Open MPI's documentation is here in this file, the\n  included man pages, and on [the web site\n  FAQ](https://www.open-mpi.org/).\n\n* Note that Open MPI documentation uses the word \"component\"\n  frequently; the word \"plugin\" is probably more familiar to most\n  users.  As such, end users can probably completely substitute the\n  word \"plugin\" wherever you see \"component\" in our documentation.\n  For what it's worth, we use the word \"component\" for historical\n  reasons, mainly because it is part of our acronyms and internal API\n  function calls.\n\n* The run-time systems that are currently supported are:\n  * rsh / ssh\n  * PBS Pro, Torque\n  * Platform LSF (tested with v9.1.1 and later)\n  * SLURM\n  * Cray XE, XC, and XK\n  * Oracle Grid Engine (OGE) 6.1, 6.2 and open source Grid Engine\n\n* Systems that have been tested are:\n  * Linux (various flavors/distros), 64 bit (x86, ppc, aarch64),\n    with gcc (>=4.8.x+), clang (>=3.6.0), Absoft (fortran), Intel,\n    and Portland (*)\n  * macOS (10.14-10.15), 64 bit (x86_64) with XCode compilers\n\n  (*) Be sure to read the Compiler Notes, below.\n\n* Other systems have been lightly (but not fully) tested:\n  * Linux (various flavors/distros), 32 bit, with gcc\n  * Cygwin 32 & 64 bit with gcc\n  * ARMv6, ARMv7\n  * Other 64 bit platforms.\n  * OpenBSD.  Requires configure options `--enable-mca-no-build=patcher`\n    and `--disable-dlopen` with this release.\n  * Problems have been reported when building Open MPI on FreeBSD 11.1\n    using the clang-4.0 system compiler. A workaround is to build\n    Open MPI using the GNU compiler.\n\n* Open MPI has taken some steps towards [Reproducible\n  Builds](https://reproducible-builds.org/).  Specifically, Open MPI's\n  `configure` and `make` process, by default, records the build date\n  and some system-specific information such as the hostname where Open\n  MPI was built and the username who built it.  If you desire a\n  Reproducible Build, set the `$SOURCE_DATE_EPOCH`, `$USER` and\n  `$HOSTNAME` environment variables before invoking `configure` and\n  `make`, and Open MPI will use those values instead of invoking\n  `whoami` and/or `hostname`, respectively.  See\n  https://reproducible-builds.org/docs/source-date-epoch/ for\n  information on the expected format and content of the\n  `$SOURCE_DATE_EPOCH` variable.\n\n\n### Platform Notes\n\n- N/A\n\n\n### Compiler Notes\n\n* Open MPI requires a C99-capable compiler to build.\n\n* On platforms other than x86-64, ARM, and PPC, Open MPI requires a\n  compiler that either supports C11 atomics or the GCC `__atomic`\n  atomics (e.g., GCC >= v4.7.2).\n\n* Mixing compilers from different vendors when building Open MPI\n  (e.g., using the C/C++ compiler from one vendor and the Fortran\n  compiler from a different vendor) has been successfully employed by\n  some Open MPI users (discussed on the Open MPI user's mailing list),\n  but such configurations are not tested and not documented.  For\n  example, such configurations may require additional compiler /\n  linker flags to make Open MPI build properly.\n\n  A not-uncommon case for this is when building on MacOS with the\n  system-default GCC compiler (i.e., `/usr/bin/gcc`), but a 3rd party\n  gfortran (e.g., provided by Homebrew, in `/usr/local/bin/gfortran`).\n  Since these compilers are provided by different organizations, they\n  have different default search paths.  For example, if Homebrew has\n  also installed a local copy of Libevent (a 3rd party package that\n  Open MPI requires), the MacOS-default `gcc` linker will find it\n  without any additional command line flags, but the Homebrew-provided\n  gfortran linker will not.  In this case, it may be necessary to\n  provide the following on the configure command line:\n\n  ```\n  $ ./configure FCFLAGS=-L/usr/local/lib ...\n  ```\n\n  This `-L` flag will then be passed to the Fortran linker when\n  creating Open MPI's Fortran libraries, and it will therefore be able\n  to find the installed Libevent.\n\n* In general, the latest versions of compilers of a given vendor's\n  series have the least bugs.  We have seen cases where Vendor XYZ's\n  compiler version A.B fails to compile Open MPI, but version A.C\n  (where C>B) works just fine.  If you run into a compile failure, you\n  might want to double check that you have the latest bug fixes and\n  patches for your compiler.\n\n* Users have reported issues with older versions of the Fortran PGI\n  compiler suite when using Open MPI's (non-default) `--enable-debug`\n  configure option.  Per the above advice of using the most recent\n  version of a compiler series, the Open MPI team recommends using the\n  latest version of the PGI suite, and/or not using the `--enable-debug`\n  configure option.  If it helps, here's what we have found with some\n  (not comprehensive) testing of various versions of the PGI compiler\n  suite:\n\n  * pgi-8 : NO known good version with `--enable-debug`\n  * pgi-9 : 9.0-4 known GOOD\n  * pgi-10: 10.0-0 known GOOD\n  * pgi-11: NO known good version with `--enable-debug`\n  * pgi-12: 12.10 known BAD with `-m32`, but known GOOD without `-m32`\n            (and 12.8 and 12.9 both known BAD with `--enable-debug`)\n  * pgi-13: 13.9 known BAD with `-m32`, 13.10 known GOOD without `-m32`\n  * pgi-15: 15.10 known BAD with `-m32`\n\n* Similarly, there is a known Fortran PGI compiler issue with long\n  source directory path names that was resolved in 9.0-4 (9.0-3 is\n  known to be broken in this regard).\n\n* Open MPI does not support the PGI compiler suite on OS X or MacOS.\n  See issues below for more details:\n  * https://github.com/open-mpi/ompi/issues/2604\n  * https://github.com/open-mpi/ompi/issues/2605\n\n* OpenSHMEM Fortran bindings do not support the \"no underscore\"\n  Fortran symbol convention. IBM's `xlf` compilers build in that mode\n  by default.  As such, IBM's `xlf` compilers cannot build/link the\n  OpenSHMEM Fortran bindings by default. A workaround is to pass\n  `FC=\"xlf -qextname\"` at configure time to force a trailing\n  underscore. See [this\n  issue](https://github.com/open-mpi/ompi/issues/3612) for more\n  details.\n\n* MPI applications that use the mpi_f08 module on PowerPC platforms\n  (tested ppc64le) will likely experience runtime failures if:\n   * they are using a GNU linker (ld) version after v2.25.1 and before v2.28,\n     *and*\n   * they compiled with PGI (tested 17.5) or XL (tested v15.1.5) compilers.\n  This was noticed on Ubuntu 16.04 which uses the 2.26.1 version of\n  `ld` by default. However, this issue impacts any OS using a version\n  of `ld` noted above. This GNU linker regression will be fixed in\n  version 2.28.  [Here is a link to the GNU bug on this\n  issue](https://sourceware.org/bugzilla/show_bug.cgi?id=21306).  The\n  XL compiler will include a fix for this issue in a future release.\n\n* On NetBSD-6 (at least AMD64 and i386), and possibly on OpenBSD,\n  Libtool misidentifies properties of f95/g95, leading to obscure\n  compile-time failures if used to build Open MPI.  You can work\n  around this issue by ensuring that libtool will not use f95/g95\n  (e.g., by specifying `FC=<some_other_compiler>`, or otherwise ensuring\n  a different Fortran compiler will be found earlier in the path than\n  `f95`/`g95`), or by disabling the Fortran MPI bindings with\n  `--disable-mpi-fortran`.\n\n* On OpenBSD/i386, if you configure with\n  `--enable-mca-no-build=patcher`, you will also need to add\n  `--disable-dlopen`.  Otherwise, odd crashes can occur\n  nondeterministically.\n\n* Absoft 11.5.2 plus a service pack from September 2012 (which Absoft\n  says is available upon request), or a version later than 11.5.2\n  (e.g., 11.5.3), is required to compile the Fortran `mpi_f08`\n  module.\n\n* Open MPI does not support the Sparc v8 CPU target.  However,\n  as of Solaris Studio 12.1, and later compilers, one should not\n  specify `-xarch=v8plus` or `-xarch=v9`.  The use of the options\n  `-m32` and `-m64` for producing 32 and 64 bit targets, respectively,\n  are now preferred by the Solaris Studio compilers.  GCC may\n  require either `-m32` or `-mcpu=v9 -m32`, depending on GCC version.\n\n* If one tries to build OMPI on Ubuntu with Solaris Studio using the C++\n  compiler and the `-m32` option, you might see a warning:\n\n  ```\n  CC: Warning: failed to detect system linker version, falling back to custom linker usage\n  ```\n\n  And the build will fail.  One can overcome this error by either\n  setting `LD_LIBRARY_PATH` to the location of the 32 bit libraries\n  (most likely /lib32), or giving `LDFLAGS=\"-L/lib32 -R/lib32\"` to the\n  `configure` command.  Officially, Solaris Studio is not supported on\n  Ubuntu Linux distributions, so additional problems might be\n  incurred.\n\n* Open MPI does not support the `gccfss` compiler (GCC For SPARC\n  Systems; a now-defunct compiler project from Sun).\n\n* At least some versions of the Intel 8.1 compiler seg fault while\n  compiling certain Open MPI source code files.  As such, it is not\n  supported.\n\n* It has been reported that the Intel 9.1 and 10.0 compilers fail to\n  compile Open MPI on IA64 platforms.  As of 12 Sep 2012, there is\n  very little (if any) testing performed on IA64 platforms (with any\n  compiler).  Support is \"best effort\" for these platforms, but it is\n  doubtful that any effort will be expended to fix the Intel 9.1 /\n  10.0 compiler issuers on this platform.\n\n* Early versions of the Intel 12.1 Linux compiler suite on x86_64 seem\n  to have a bug that prevents Open MPI from working.  Symptoms\n  including immediate segv of the wrapper compilers (e.g., `mpicc`) and\n  MPI applications.  As of 1 Feb 2012, if you upgrade to the latest\n  version of the Intel 12.1 Linux compiler suite, the problem will go\n  away.\n\n* The Portland Group compilers prior to version 7.0 require the\n  `-Msignextend` compiler flag to extend the sign bit when converting\n  from a shorter to longer integer.  This is is different than other\n  compilers (such as GNU).  When compiling Open MPI with the Portland\n  compiler suite, the following flags should be passed to Open MPI's\n  `configure` script:\n\n  ```\n  shell$ ./configure CFLAGS=-Msignextend CXXFLAGS=-Msignextend \\\n         --with-wrapper-cflags=-Msignextend \\\n         --with-wrapper-cxxflags=-Msignextend ...\n  ```\n\n  This will both compile Open MPI with the proper compile flags and\n  also automatically add \"-Msignextend\" when the C and C++ MPI wrapper\n  compilers are used to compile user MPI applications.\n\n* It has been reported that Pathscale 5.0.5 and 6.0.527 compilers\n  give an internal compiler error when trying to build Open MPI.\n\n* As of July 2017, the Pathscale compiler suite apparently has no\n  further commercial support, and it does not look like there will be\n  further releases.  Any issues discovered regarding building /\n  running Open MPI with the Pathscale compiler suite therefore may not\n  be able to be resolved.\n\n* Using the Absoft compiler to build the MPI Fortran bindings on Suse\n  9.3 is known to fail due to a Libtool compatibility issue.\n\n* MPI Fortran API support has been completely overhauled since the\n  Open MPI v1.5/v1.6 series.\n\n  There is now only a single Fortran MPI wrapper compiler and a\n  single Fortran OpenSHMEM wrapper compiler: `mpifort` and `oshfort`,\n  respectively.  `mpif77` and `mpif90` still exist, but they are\n  symbolic links to `mpifort`.\n\n  Similarly, Open MPI's `configure` script only recognizes the `FC`\n  and `FCFLAGS` environment variables (to specify the Fortran\n  compiler and compiler flags, respectively).  The `F77` and `FFLAGS`\n  environment variables are ***IGNORED***.\n\n  As a direct result, it is ***STRONGLY*** recommended that you\n  specify a Fortran compiler that uses file suffixes to determine\n  Fortran code layout (e.g., free form vs. fixed).  For example, with\n  some versions of the IBM XLF compiler, it is preferable to use\n  `FC=xlf` instead of `FC=xlf90`, because `xlf` will automatically\n  determine the difference between free form and fixed Fortran source\n  code.\n\n  However, many Fortran compilers allow specifying additional\n  command-line arguments to indicate which Fortran dialect to use.\n  For example, if `FC=xlf90`, you may need to use `mpifort --qfixed ...`\n  to compile fixed format Fortran source files.\n\n  You can use either `ompi_info` or `oshmem_info` to see with which\n  Fortran compiler Open MPI was configured and compiled.\n\n  There are up to three sets of Fortran MPI bindings that may be\n  provided (depending on your Fortran compiler):\n\n  1. `mpif.h`: This is the first MPI Fortran interface that was\n     defined in MPI-1.  It is a file that is included in Fortran\n     source code.  Open MPI's `mpif.h` does not declare any MPI\n     subroutines; they are all implicit.\n\n  1. `mpi` module: The `mpi` module file was added in MPI-2.  It\n     provides strong compile-time parameter type checking for MPI\n     subroutines.\n\n  1. `mpi_f08` module: The `mpi_f08` module was added in MPI-3.  It\n     provides many advantages over the `mpif.h` file and `mpi` module.\n     For example, MPI handles have distinct types (vs. all being\n     integers).  See the MPI-3 document for more details.\n\n  ***NOTE:*** The `mpi_f08` module is ***STRONGLY*** recommended for\n  all new MPI Fortran subroutines and applications.  Note that the\n  `mpi_f08` module can be used in conjunction with the other two\n  Fortran MPI bindings in the same application (only one binding can\n  be used per subroutine/function, however).  Full interoperability\n  between `mpif.h`/`mpi` module and `mpi_f08` module MPI handle types\n  is provided, allowing `mpi_f08` to be used in new subroutines in\n  legacy MPI applications.\n\n  Per the OpenSHMEM specification, there is only one Fortran OpenSHMEM\n  binding provided:\n\n  * `shmem.fh`: All Fortran OpenSHMEM programs should include\n    `shmem.f`, and Fortran OpenSHMEM programs that use constants\n    defined by OpenSHMEM ***MUST*** include `shmem.fh`.\n\n  The following notes apply to the above-listed Fortran bindings:\n\n  * All Fortran compilers support the `mpif.h`/`shmem.fh`-based\n    bindings, with one exception: the `MPI_SIZEOF` interfaces will\n    only be present when Open MPI is built with a Fortran compiler\n    that supports the `INTERFACE` keyword and `ISO_FORTRAN_ENV`.  Most\n    notably, this excludes the GNU Fortran compiler suite before\n    version 4.9.\n\n  * The level of support provided by the `mpi` module is based on your\n    Fortran compiler.\n\n    If Open MPI is built with a non-GNU Fortran compiler, or if Open\n    MPI is built with the GNU Fortran compiler >= v4.9, all MPI\n    subroutines will be prototyped in the `mpi` module.  All calls to\n    MPI subroutines will therefore have their parameter types checked\n    at compile time.\n\n    If Open MPI is built with an old `gfortran` (i.e., < v4.9), a\n    limited `mpi` module will be built.  Due to the limitations of\n    these compilers, and per guidance from the MPI-3 specification,\n    all MPI subroutines with \"choice\" buffers are specifically *not*\n    included in the `mpi` module, and their parameters will not be\n    checked at compile time.  Specifically, all MPI subroutines with\n    no \"choice\" buffers are prototyped and will receive strong\n    parameter type checking at run-time (e.g., `MPI_INIT`,\n    `MPI_COMM_RANK`, etc.).\n\n    Similar to the `mpif.h` interface, `MPI_SIZEOF` is only supported\n    on Fortran compilers that support `INTERFACE` and\n    `ISO_FORTRAN_ENV`.\n\n  * The `mpi_f08` module has been tested with the Intel Fortran\n    compiler and gfortran >= 4.9.  Other modern Fortran compilers\n    likely also work.\n\n    Many older Fortran compilers do not provide enough modern Fortran\n    features to support the `mpi_f08` module.  For example, `gfortran`\n    < v4.9 does provide enough support for the `mpi_f08` module.\n\n  You can examine the output of the following command to see all\n  the Fortran features that are/are not enabled in your Open MPI\n  installation:\n\n  ```\n  shell$ ompi_info | grep -i fort\n  ```\n\n\n### General Run-Time Support Notes\n\n* The Open MPI installation must be in your `PATH` on all nodes (and\n  potentially `LD_LIBRARY_PATH` or `DYLD_LIBRARY_PATH`, if\n  `libmpi`/`libshmem` is a shared library), unless using the\n  `--prefix` or `--enable-mpirun-prefix-by-default` functionality (see\n  below).\n\n* Open MPI's run-time behavior can be customized via Modular Component\n  Architecture (MCA) parameters (see below for more information on how\n  to get/set MCA parameter values).  Some MCA parameters can be set in\n  a way that renders Open MPI inoperable (see notes about MCA\n  parameters later in this file).  In particular, some parameters have\n  required options that must be included.\n\n  * If specified, the `btl` parameter must include the `self`\n    component, or Open MPI will not be able to deliver messages to the\n    same rank as the sender.  For example: `mpirun --mca btl tcp,self\n    ...`\n  * If specified, the `btl_tcp_if_exclude` parameter must include the\n    loopback device (`lo` on many Linux platforms), or Open MPI will\n    not be able to route MPI messages using the TCP BTL.  For example:\n    `mpirun --mca btl_tcp_if_exclude lo,eth1 ...`\n\n* Running on nodes with different endian and/or different datatype\n  sizes within a single parallel job is supported in this release.\n  However, Open MPI does not resize data when datatypes differ in size\n  (for example, sending a 4 byte `MPI_DOUBLE` and receiving an 8 byte\n  `MPI_DOUBLE` will fail).\n\n\n### MPI Functionality and Features\n\n* All MPI-3.1 functionality is supported.\n\n* Note that starting with Open MPI v4.0.0, prototypes for several\n  legacy MPI-1 symbols that were deleted in the MPI-3.0 specification\n  (which was published in 2012) are no longer available by default in\n  `mpi.h`.  Specifically, several MPI-1 symbols were deprecated in the\n  1996 publishing of the MPI-2.0 specification.  These deprecated\n  symbols were eventually removed from the MPI-3.0 specification in\n  2012.\n\n  The symbols that now no longer appear by default in Open MPI's\n  `mpi.h` are:\n\n  * `MPI_Address` (replaced by `MPI_Get_address`)\n  * `MPI_Errhandler_create` (replaced by `MPI_Comm_create_errhandler`)\n  * `MPI_Errhandler_get` (replaced by `MPI_Comm_get_errhandler`)\n  * `MPI_Errhandler_set` (replaced by `MPI_Comm_set_errhandler`)\n  * `MPI_Type_extent` (replaced by `MPI_Type_get_extent`)\n  * `MPI_Type_hindexed` (replaced by `MPI_Type_create_hindexed`)\n  * `MPI_Type_hvector` (replaced by `MPI_Type_create_hvector`)\n  * `MPI_Type_lb` (replaced by `MPI_Type_get_extent`)\n  * `MPI_Type_struct` (replaced by `MPI_Type_create_struct`)\n  * `MPI_Type_ub` (replaced by `MPI_Type_get_extent`)\n  * `MPI_LB` (replaced by `MPI_Type_create_resized`)\n  * `MPI_UB` (replaced by `MPI_Type_create_resized`)\n  * `MPI_COMBINER_HINDEXED_INTEGER`\n  * `MPI_COMBINER_HVECTOR_INTEGER`\n  * `MPI_COMBINER_STRUCT_INTEGER`\n  * `MPI_Handler_function` (replaced by `MPI_Comm_errhandler_function`)\n\n  Although these symbols are no longer prototyped in `mpi.h`, they\n  are still present in the MPI library in Open MPI v4.0.x. This\n  enables legacy MPI applications to link and run successfully with\n  Open MPI v4.0.x, even though they will fail to compile.\n\n  ***WARNING:*** Future releases of Open MPI beyond the v4.0.x series\n  may remove these symbols altogether.\n\n  ***WARNING:*** The Open MPI team ***STRONGLY*** encourages all MPI\n  application developers to stop using these constructs that were\n  first deprecated over 20 years ago, and finally removed from the MPI\n  specification in MPI-3.0 (in 2012).\n\n  ***WARNING:*** [The Open MPI\n  FAQ](https://www.open-mpi.org/faq/?category=mpi-removed) contains\n  examples of how to update legacy MPI applications using these\n  deleted symbols to use the \"new\" symbols.\n\n  All that being said, if you are unable to immediately update your\n  application to stop using these legacy MPI-1 symbols, you can\n  re-enable them in `mpi.h` by configuring Open MPI with the\n  `--enable-mpi1-compatibility` flag.\n\n* Rank reordering support is available using the TreeMatch library. It\n  is activated for the graph and `dist_graph` communicator topologies.\n\n* When using MPI deprecated functions, some compilers will emit\n  warnings.  For example:\n\n  ```\n  shell$ cat deprecated_example.c\n  #include <mpi.h>\n  void foo(void) {\n      MPI_Datatype type;\n      MPI_Type_struct(1, NULL, NULL, NULL, &type);\n  }\n  shell$ mpicc -c deprecated_example.c\n  deprecated_example.c: In function 'foo':\n  deprecated_example.c:4: warning: 'MPI_Type_struct' is deprecated (declared at /opt/openmpi/include/mpi.h:1522)\n  shell$\n  ```\n\n* `MPI_THREAD_MULTIPLE` is supported with some exceptions.\n\n  The following PMLs support `MPI_THREAD_MULTIPLE`:\n  1. `cm` (see list (1) of supported MTLs, below)\n  1. `ob1` (see list (2) of supported BTLs, below)\n  1. `ucx`\n\n  (1) The `cm` PML and the following MTLs support `MPI_THREAD_MULTIPLE`:\n     1. `ofi` (Libfabric)\n     1. `portals4`\n\n  (2) The `ob1` PML and the following BTLs support `MPI_THREAD_MULTIPLE`:\n     1. `self`\n     1. `sm`\n     1. `smcuda`\n     1. `tcp`\n     1. `ugni`\n     1. `usnic`\n\n  Currently, MPI File operations are not thread safe even if MPI is\n  initialized for `MPI_THREAD_MULTIPLE` support.\n\n* `MPI_REAL16` and `MPI_COMPLEX32` are only supported on platforms\n  where a portable C datatype can be found that matches the Fortran\n  type `REAL*16`, both in size and bit representation.\n\n* The \"libompitrace\" library is bundled in Open MPI and is installed\n  by default (it can be disabled via the `--disable-libompitrace`\n  flag).  This library provides a simplistic tracing of select MPI\n  function calls via the MPI profiling interface.  Linking it in to\n  your application via (e.g., via `-lompitrace`) will automatically\n  output to stderr when some MPI functions are invoked:\n\n  ```\n  shell$ cd examples/\n  shell$ mpicc hello_c.c -o hello_c -lompitrace\n  shell$ mpirun -np 1 hello_c\n  MPI_INIT: argc 1\n  Hello, world, I am 0 of 1\n  MPI_BARRIER[0]: comm MPI_COMM_WORLD\n  MPI_FINALIZE[0]\n  shell$\n  ```\n\n  Keep in mind that the output from the trace library is going to\n  `stderr`, so it may output in a slightly different order than the\n  `stdout` from your application.\n\n  This library is being offered as a \"proof of concept\" / convenience\n  from Open MPI.  If there is interest, it is trivially easy to extend\n  it to printf for other MPI functions.  Pull requests on github.com\n  would be greatly appreciated.\n\n\n### OpenSHMEM Functionality and Features\n\nAll OpenSHMEM-1.3 functionality is supported.\n\n\n### MPI Collectives\n\n* The `cuda` coll component provides CUDA-aware support for the\n  reduction type collectives with GPU buffers. This component is only\n  compiled into the library when the library has been configured with\n  CUDA-aware support.  It intercepts calls to the reduction\n  collectives, copies the data to staging buffers if GPU buffers, then\n  calls underlying collectives to do the work.\n\n\n### OpenSHMEM Collectives\n\n* The `fca` scoll component: the Mellanox Fabric Collective\n  Accelerator (FCA) is a solution for offloading collective operations\n  from the MPI process onto Mellanox QDR InfiniBand switch CPUs and\n  HCAs.\n\n* The `basic` scoll component: Reference implementation of all\n  OpenSHMEM collective operations.\n\n\n### Network Support\n\n* There are several main MPI network models available: `ob1`, `cm`,\n  and `ucx`.  `ob1` uses BTL (\"Byte Transfer Layer\")\n  components for each supported network.  `cm` uses MTL (\"Matching\n  Transport Layer\") components for each supported network.  `ucx` uses\n  the OpenUCX transport.\n\n  * `ob1` supports a variety of networks that can be used in\n    combination with each other:\n    * OpenFabrics: InfiniBand, iWARP, and RoCE\n    * Loopback (send-to-self)\n    * Shared memory\n    * TCP\n    * SMCUDA\n    * Cisco usNIC\n    * uGNI (Cray Gemini, Aries)\n    * shared memory (XPMEM, Linux CMA, Linux KNEM, and\n      copy-in/copy-out shared memory)\n\n  * `cm` supports a smaller number of networks (and they cannot be\n    used together), but may provide better overall MPI performance:\n    * Intel Omni-Path PSM2 (version 11.2.173 or later)\n    * Intel True Scale PSM (QLogic InfiniPath)\n    * OpenFabrics Interfaces (\"libfabric\" tag matching)\n    * Portals 4\n\n  * UCX is the [Unified Communication X (UCX) communication\n    library](https://www.openucx.org/).  This is an open-source\n    project developed in collaboration between industry, laboratories,\n    and academia to create an open-source production grade\n    communication framework for data centric and high-performance\n    applications.  The UCX library can be downloaded from repositories\n    (e.g., Fedora/RedHat yum repositories).  The UCX library is also\n    part of Mellanox OFED and Mellanox HPC-X binary distributions.\n\n    UCX currently supports:\n\n    * OpenFabrics Verbs (including InfiniBand and RoCE)\n    * Cray's uGNI\n    * TCP\n    * Shared memory\n    * NVIDIA CUDA drivers\n\n  While users can manually select any of the above transports at run\n  time, Open MPI will select a default transport as follows:\n\n  1. If InfiniBand devices are available, use the UCX PML.\n  1. If PSM, PSM2, or other tag-matching-supporting Libfabric\n     transport devices are available (e.g., Cray uGNI), use the `cm`\n     PML and a single appropriate corresponding `mtl` module.\n  1. Otherwise, use the `ob1` PML and one or more appropriate `btl`\n     modules.\n\n  Users can override Open MPI's default selection algorithms and force\n  the use of a specific transport if desired by setting the `pml` MCA\n  parameter (and potentially the `btl` and/or `mtl` MCA parameters) at\n  run-time:\n\n  ```\n  shell$ mpirun --mca pml ob1 --mca btl [comma-delimted-BTLs] ...\n  or\n  shell$ mpirun --mca pml cm --mca mtl [MTL] ...\n  or\n  shell$ mpirun --mca pml ucx ...\n  ```\n\n  There is a known issue when using UCX with very old Mellanox\n  Infiniband HCAs, in particular HCAs preceding the introduction of\n  the ConnectX product line, which can result in Open MPI crashing in\n  MPI_Finalize.  This issue is addressed by UCX release 1.9.0 and\n  newer.\n\n* The main OpenSHMEM network model is `ucx`; it interfaces directly\n  with UCX.\n\n* In prior versions of Open MPI, InfiniBand and RoCE support was\n  provided through the `openib` BTL and `ob1` PML plugins.  Starting\n  with Open MPI 4.0.0, InfiniBand support through the `openib` plugin\n  is both deprecated and superseded by the `ucx` PML component.  The\n  `openib` BTL was removed in Open MPI v5.0.0.\n\n  While the `openib` BTL depended on `libibverbs`, the UCX PML depends\n  on the UCX library.\n\n  Once installed, Open MPI can be built with UCX support by adding\n  `--with-ucx` to the Open MPI configure command. Once Open MPI is\n  configured to use UCX, the runtime will automatically select the\n  `ucx` PML if one of the supported networks is detected (e.g.,\n  InfiniBand).  It's possible to force using UCX in the `mpirun` or\n  `oshrun` command lines by specifying any or all of the following mca\n  parameters: `--mca pml ucx` for MPI point-to-point operations,\n  `--mca spml ucx` for OpenSHMEM support, and `--mca osc ucx` for MPI\n  RMA (one-sided) operations.\n\n* The `usnic` BTL is support for Cisco's usNIC device (\"userspace NIC\")\n  on Cisco UCS servers with the Virtualized Interface Card (VIC).\n  Although the usNIC is accessed via the OpenFabrics Libfabric API\n  stack, this BTL is specific to Cisco usNIC devices.\n\n* uGNI is a Cray library for communicating over the Gemini and Aries\n  interconnects.\n\n* The OpenFabrics Enterprise Distribution (OFED) software package v1.0\n  will not work properly with Open MPI v1.2 (and later) due to how its\n  Mellanox InfiniBand plugin driver is created.  The problem is fixed\n  with OFED v1.1 (and later).\n\n* The use of `fork()` with Libiverbs-based networks (i.e., the UCX\n  PML) is only partially supported, and only on Linux kernels >=\n  v2.6.15 with `libibverbs` v1.1 or later (first released as part of\n  OFED v1.2), per restrictions imposed by the OFED network stack.\n\n* Linux `knem` support is used when the `sm` (shared memory) BTL is\n  compiled with knem support (see the `--with-knem` configure option)\n  and the `knem` Linux module is loaded in the running kernel.  If the\n  `knem` Linux kernel module is not loaded, the `knem` support is (by\n  default) silently deactivated during Open MPI jobs.\n\n  See https://knem.gforge.inria.fr/ for details on Knem.\n\n* Linux Cross-Memory Attach (CMA) or XPMEM is used by the `sm` shared\n  memory BTL when the CMA/XPMEM libraries are installed,\n  respectively.  Linux CMA and XPMEM are similar (but different)\n  mechanisms for Open MPI to utilize single-copy semantics for shared\n  memory.\n\n\n### Open MPI Extensions\n\nAn MPI \"extensions\" framework is included in Open MPI, but is not\nenabled by default.  See the \"Open MPI API Extensions\" section below\nfor more information on compiling and using MPI extensions.\n\nThe following extensions are included in this version of Open MPI:\n\n1. `pcollreq`: Provides routines for persistent collective\n   communication operations and persistent neighborhood collective\n   communication operations, which are planned to be included in\n   MPI-4.0.  The function names are prefixed with `MPIX_` instead of\n   `MPI_`, like `MPIX_Barrier_init`, because they are not\n   standardized yet.  Future versions of Open MPI will switch to the\n   `MPI_` prefix once the MPI Standard which includes this feature is\n   published.  See their man page for more details.\n1. `shortfloat`: Provides MPI datatypes `MPIX_C_FLOAT16`,\n   `MPIX_SHORT_FLOAT`, `MPIX_SHORT_FLOAT`, and\n   `MPIX_CXX_SHORT_FLOAT_COMPLEX` if corresponding language types are\n   available. See `ompi/mpiext/shortfloat/README.txt` for details.\n1. `affinity`: Provides the `OMPI_Affinity_str()` API, which returns\n   a string indicating the resources which a process is bound. For\n   more details, see its man page.\n1. `cuda`: When the library is compiled with CUDA-aware support, it\n   provides two things.  First, a macro\n   `MPIX_CUDA_AWARE_SUPPORT`. Secondly, the function\n   `MPIX_Query_cuda_support()` that can be used to query for support.\n1. `example`: A non-functional extension; its only purpose is to\n   provide an example for how to create other extensions.\n\n\n## Building Open MPI\n\nIf you have checked out a ***developer's copy*** of Open MPI (i.e.,\nyou cloned from Git), you really need to read the `HACKING` file\nbefore attempting to build Open MPI. Really.\n\nIf you have downloaded a tarball, then things are much simpler.\nOpen MPI uses a traditional `configure` script paired with `make` to\nbuild.  Typical installs can be of the pattern:\n\n```\nshell$ ./configure [...options...]\nshell$ make [-j N] all install\n      (use an integer value of N for parallel builds)\n```\n\nThere are many available `configure` options (see `./configure --help`\nfor a full list); a summary of the more commonly used ones is included\nbelow.\n\n***NOTE:*** if you are building Open MPI on a network filesystem, the\nmachine you on which you are building *must* be time-synchronized with\nthe file server.  Specifically: Open MPI's build system *requires*\naccurate filesystem timestamps.  If your `make` output includes\nwarning about timestamps in the future or runs GNU Automake, Autoconf,\nand/or Libtool, this is *not normal*, and you may have an invalid\nbuild.  Ensure that the time on your build machine is synchronized\nwith the time on your file server, or build on a local filesystem.\nThen remove the Open MPI source directory and start over (e.g., by\nre-extracting the Open MPI tarball).\n\nNote that for many of Open MPI's `--with-FOO` options, Open MPI will,\nby default, search for header files and/or libraries for `FOO`.  If\nthe relevant files are found, Open MPI will built support for `FOO`;\nif they are not found, Open MPI will skip building support for `FOO`.\nHowever, if you specify `--with-FOO` on the configure command line and\nOpen MPI is unable to find relevant support for `FOO`, configure will\nassume that it was unable to provide a feature that was specifically\nrequested and will abort so that a human can resolve out the issue.\n\nAdditionally, if a search directory is specified in the form\n`--with-FOO=DIR`, Open MPI will:\n\n1. Search for `FOO`'s header files in `DIR/include`.\n2. Search for `FOO`'s library files:\n   1. If `--with-FOO-libdir=<libdir>` was specified, search in\n      `<libdir>`.\n   1. Otherwise, search in `DIR/lib`, and if they are not found\n      there, search again in `DIR/lib64`.\n3. If both the relevant header files and libraries are found:\n   1. Open MPI will build support for `FOO`.\n   1. If the root path where the FOO libraries are found is neither\n      `/usr` nor `/usr/local`, Open MPI will compile itself with\n      RPATH flags pointing to the directory where FOO's libraries\n      are located.  Open MPI does not RPATH `/usr/lib[64]` and\n      `/usr/local/lib[64]` because many systems already search these\n      directories for run-time libraries by default; adding RPATH for\n      them could have unintended consequences for the search path\n      ordering.\n\n\n### Installation Options\n\n* `--prefix=DIR`:\n  Install Open MPI into the base directory named `DIR`.  Hence, Open\n  MPI will place its executables in `DIR/bin`, its header files in\n  `DIR/include`, its libraries in `DIR/lib`, etc.\n\n* `--disable-shared`:\n  By default, Open MPI and OpenSHMEM build shared libraries, and all\n  components are built as dynamic shared objects (DSOs). This switch\n  disables this default; it is really only useful when used with\n  `--enable-static`.  Specifically, this option does *not* imply\n  `--enable-static`; enabling static libraries and disabling shared\n  libraries are two independent options.\n\n* `--enable-static`:\n  Build MPI and OpenSHMEM as static libraries, and statically link in\n  all components.  Note that this option does *not* imply\n  `--disable-shared`; enabling static libraries and disabling shared\n  libraries are two independent options.\n\n  Be sure to read the description of `--without-memory-manager`,\n  below; it may have some effect on `--enable-static`.\n\n* `--disable-wrapper-rpath`:\n  By default, the wrapper compilers (e.g., `mpicc`) will enable\n  \"rpath\" support in generated executables on systems that support it.\n  That is, they will include a file reference to the location of Open\n  MPI's libraries in the application executable itself.  This means\n  that the user does not have to set `LD_LIBRARY_PATH` to find Open\n  MPI's libraries (e.g., if they are installed in a location that the\n  run-time linker does not search by default).\n\n  On systems that utilize the GNU `ld` linker, recent enough versions\n  will actually utilize \"runpath\" functionality, not \"rpath\".  There\n  is an important difference between the two:\n\n  1. \"rpath\": the location of the Open MPI libraries is hard-coded into\n     the MPI/OpenSHMEM application and cannot be overridden at\n     run-time.\n  1. \"runpath\": the location of the Open MPI libraries is hard-coded into\n     the MPI/OpenSHMEM application, but can be overridden at run-time\n     by setting the `LD_LIBRARY_PATH` environment variable.\n\n  For example, consider that you install Open MPI vA.B.0 and\n  compile/link your MPI/OpenSHMEM application against it.  Later, you\n  install Open MPI vA.B.1 to a different installation prefix (e.g.,\n  `/opt/openmpi/A.B.1` vs. `/opt/openmpi/A.B.0`), and you leave the old\n  installation intact.\n\n  In the rpath case, your MPI application will always use the\n  libraries from your A.B.0 installation.  In the runpath case, you\n  can set the `LD_LIBRARY_PATH` environment variable to point to the\n  A.B.1 installation, and then your MPI application will use those\n  libraries.\n\n  Note that in both cases, however, if you remove the original A.B.0\n  installation and set `LD_LIBRARY_PATH` to point to the A.B.1\n  installation, your application will use the A.B.1 libraries.\n\n  This rpath/runpath behavior can be disabled via\n  `--disable-wrapper-rpath`.\n\n  If you would like to keep the rpath option, but not enable runpath\n  a different configure option is avalabile\n  `--disable-wrapper-runpath`.\n\n* `--enable-dlopen`:\n  Build all of Open MPI's components as standalone Dynamic Shared\n  Objects (DSO's) that are loaded at run-time (this is the default).\n  The opposite of this option, `--disable-dlopen`, causes two things:\n\n  1. All of Open MPI's components will be built as part of Open MPI's\n     normal libraries (e.g., `libmpi`).\n  1. Open MPI will not attempt to open any DSO's at run-time.\n\n  Note that this option does *not* imply that OMPI's libraries will be\n  built as static objects (e.g., `libmpi.a`).  It only specifies the\n  location of OMPI's components: standalone DSOs or folded into the\n  Open MPI libraries.  You can control whether Open MPI's libraries\n  are build as static or dynamic via `--enable|disable-static` and\n  `--enable|disable-shared`.\n\n* `--disable-show-load-errors-by-default`:\n  Set the default value of the `mca_base_component_show_load_errors`\n  MCA variable: the `--enable` form of this option sets the MCA\n  variable to true, the `--disable` form sets the MCA variable to\n  false.  The MCA `mca_base_component_show_load_errors` variable can\n  still be overridden at run time via the usual MCA-variable-setting\n  mechanisms; this configure option simply sets the default value.\n\n  The `--disable` form of this option is intended for Open MPI\n  packagers who tend to enable support for many different types of\n  networks and systems in their packages.  For example, consider a\n  packager who includes support for both the FOO and BAR networks in\n  their Open MPI package, both of which require support libraries\n  (`libFOO.so` and `libBAR.so`).  If an end user only has BAR\n  hardware, they likely only have `libBAR.so` available on their\n  systems -- not `libFOO.so`.  Disabling load errors by default will\n  prevent the user from seeing potentially confusing warnings about\n  the FOO components failing to load because `libFOO.so` is not\n  available on their systems.\n\n  Conversely, system administrators tend to build an Open MPI that is\n  targeted at their specific environment, and contains few (if any)\n  components that are not needed.  In such cases, they might want\n  their users to be warned that the FOO network components failed to\n  load (e.g., if `libFOO.so` was mistakenly unavailable), because Open\n  MPI may otherwise silently failover to a slower network path for MPI\n  traffic.\n\n* `--with-platform=FILE`:\n  Load configure options for the build from `FILE`.  Options on the\n  command line that are not in `FILE` are also used.  Options on the\n  command line and in `FILE` are replaced by what is in `FILE`.\n\n* `--with-libmpi-name=STRING`:\n  Replace `libmpi.*` and `libmpi_FOO.*` (where `FOO` is one of the\n  fortran supporting libraries installed in lib) with `libSTRING.*`\n  and `libSTRING_FOO.*`. This is provided as a convenience mechanism\n  for third-party packagers of Open MPI that might want to rename\n  these libraries for their own purposes. This option is *not*\n  intended for typical users of Open MPI.\n\n* `--enable-mca-no-build=LIST`:\n  Comma-separated list of `<type>-<component>` pairs that will not be\n  built. For example, `--enable-mca-no-build=btl-portals,oob-ud` will\n  disable building the portals BTL and the ud OOB component.\n\n\n### Networking support / options\n\n* `--with-fca=DIR`:\n  Specify the directory where the Mellanox FCA library and\n  header files are located.\n\n  FCA is the support library for Mellanox switches and HCAs.\n\n* `--with-hcoll=DIR`:\n  Specify the directory where the Mellanox hcoll library and header\n  files are located.  This option is generally only necessary if the\n  hcoll headers and libraries are not in default compiler/linker\n  search paths.\n\n  hcoll is the support library for MPI collective operation offload on\n  Mellanox ConnectX-3 HCAs (and later).\n\n* `--with-knem=DIR`:\n  Specify the directory where the knem libraries and header files are\n  located.  This option is generally only necessary if the knem headers\n  and libraries are not in default compiler/linker search paths.\n\n  knem is a Linux kernel module that allows direct process-to-process\n  memory copies (optionally using hardware offload), potentially\n  increasing bandwidth for large messages sent between messages on the\n  same server.  See [the Knem web site](https://knem.gforge.inria.fr/)\n  for details.\n\n* `--with-libfabric=DIR`:\n  Specify the directory where the OpenFabrics Interfaces `libfabric`\n  library and header files are located.  This option is generally only\n  necessary if the libfabric headers and libraries are not in default\n  compiler/linker search paths.\n\n  Libfabric is the support library for OpenFabrics Interfaces-based\n  network adapters, such as Cisco usNIC, Intel True Scale PSM, Cray\n  uGNI, etc.\n\n* `--with-libfabric-libdir=DIR`:\n  Look in directory for the libfabric libraries.  By default, Open MPI\n  will look in `DIR/lib` and `DIR/lib64`, which covers most cases.\n  This option is only needed for special configurations.\n\n* `--with-portals4=DIR`:\n  Specify the directory where the Portals4 libraries and header files\n  are located.  This option is generally only necessary if the Portals4\n  headers and libraries are not in default compiler/linker search\n  paths.\n\n  Portals is a low-level network API for high-performance networking\n  on high-performance computing systems developed by Sandia National\n  Laboratories, Intel Corporation, and the University of New Mexico.\n  The Portals 4 Reference Implementation is a complete implementation\n  of Portals 4, with transport over InfiniBand verbs and UDP.\n\n* `--with-portals4-libdir=DIR`:\n  Location of libraries to link with for Portals4 support.\n\n* `--with-portals4-max-md-size=SIZE` and\n  `--with-portals4-max-va-size=SIZE`:\n  Set configuration values for Portals 4\n\n* `--with-psm=<directory>`:\n  Specify the directory where the QLogic InfiniPath / Intel True Scale\n  PSM library and header files are located.  This option is generally\n  only necessary if the PSM headers and libraries are not in default\n  compiler/linker search paths.\n\n  PSM is the support library for QLogic InfiniPath and Intel TrueScale\n  network adapters.\n\n* `--with-psm-libdir=DIR`:\n  Look in directory for the PSM libraries.  By default, Open MPI will\n  look in `DIR/lib` and `DIR/lib64`, which covers most cases.  This\n  option is only needed for special configurations.\n\n* `--with-psm2=DIR`:\n  Specify the directory where the Intel Omni-Path PSM2 library and\n  header files are located.  This option is generally only necessary\n  if the PSM2 headers and libraries are not in default compiler/linker\n  search paths.\n\n  PSM is the support library for Intel Omni-Path network adapters.\n\n* `--with-psm2-libdir=DIR`:\n  Look in directory for the PSM2 libraries.  By default, Open MPI will\n  look in `DIR/lib` and `DIR/lib64`, which covers most cases.  This\n  option is only needed for special configurations.\n\n* `--with-ucx=DIR`:\n  Specify the directory where the UCX libraries and header files are\n  located.  This option is generally only necessary if the UCX headers\n  and libraries are not in default compiler/linker search paths.\n\n* `--with-ucx-libdir=DIR`:\n  Look in directory for the UCX libraries.  By default, Open MPI will\n  look in `DIR/lib` and `DIR/lib64`, which covers most cases.  This\n  option is only needed for special configurations.\n\n* `--with-usnic`:\n  Abort configure if Cisco usNIC support cannot be built.\n\n\n### Run-time system support\n\n* `--enable-mpirun-prefix-by-default`:\n  This option forces the `mpirun` command to always behave as if\n  `--prefix $prefix` was present on the command line (where `$prefix`\n  is the value given to the `--prefix` option to configure).  This\n  prevents most `rsh`/`ssh`-based users from needing to modify their\n  shell startup files to set the `PATH` and/or `LD_LIBRARY_PATH` for\n  Open MPI on remote nodes.  Note, however, that such users may still\n  desire to set `PATH` -- perhaps even in their shell startup files --\n  so that executables such as `mpicc` and `mpirun` can be found\n  without needing to type long path names.\n\n* `--enable-orte-static-ports`:\n   Enable ORTE static ports for TCP OOB (default: enabled).\n\n* `--with-alps`:\n  Force the building of for the Cray Alps run-time environment.  If\n  Alps support cannot be found, configure will abort.\n\n* `--with-lsf=DIR`:\n  Specify the directory where the LSF libraries and header files are\n  located.  This option is generally only necessary if the LSF headers\n  and libraries are not in default compiler/linker search paths.\n\n  LSF is a resource manager system, frequently used as a batch\n  scheduler in HPC systems.\n\n* `--with-lsf-libdir=DIR`:\n  Look in directory for the LSF libraries.  By default, Open MPI will\n  look in `DIR/lib` and `DIR/lib64`, which covers most cases.  This\n  option is only needed for special configurations.\n\n* `--with-slurm`:\n  Force the building of SLURM scheduler support.\n\n* `--with-sge`:\n  Specify to build support for the Oracle Grid Engine (OGE) resource\n  manager and/or the Open Grid Engine.  OGE support is disabled by\n  default; this option must be specified to build OMPI's OGE support.\n\n  The Oracle Grid Engine (OGE) and open Grid Engine packages are\n  resource manager systems, frequently used as a batch scheduler in\n  HPC systems.  It used to be called the \"Sun Grid Engine\", which is\n  why the option is still named `--with-sge`.\n\n* `--with-tm=DIR`:\n  Specify the directory where the TM libraries and header files are\n  located.  This option is generally only necessary if the TM headers\n  and libraries are not in default compiler/linker search paths.\n\n  TM is the support library for the Torque and PBS Pro resource\n  manager systems, both of which are frequently used as a batch\n  scheduler in HPC systems.\n\n\n### Miscellaneous support libraries\n\n* `--with-libevent(=VALUE)`\n  This option specifies where to find the libevent support headers and\n  library.  The following `VALUE`s are permitted:\n\n  * `internal`: Use Open MPI's internal copy of libevent.\n  * `external`: Use an external Libevent installation (rely on default\n    compiler and linker paths to find it)\n  * `<no value>`:  Same as `internal`.\n  * `DIR`: Specify the location of a specific libevent\n    installation to use\n\n  By default (or if `--with-libevent` is specified with no `VALUE`),\n  Open MPI will build and use the copy of libevent that it has in its\n  source tree.  However, if the `VALUE` is `external`, Open MPI will\n  look for the relevant libevent header file and library in default\n  compiler / linker locations.  Or, `VALUE` can be a directory tree\n  where the libevent header file and library can be found.  This\n  option allows operating systems to include Open MPI and use their\n  default libevent installation instead of Open MPI's bundled\n  libevent.\n\n  libevent is a support library that provides event-based processing,\n  timers, and signal handlers.  Open MPI requires libevent to build;\n  passing --without-libevent will cause configure to abort.\n\n* `--with-libevent-libdir=DIR`:\n  Look in directory for the libevent libraries.  This option is only\n  usable when building Open MPI against an external libevent\n  installation.  Just like other `--with-FOO-libdir` configure\n  options, this option is only needed for special configurations.\n\n* `--with-hwloc(=VALUE)`:\n  hwloc is a support library that provides processor and memory\n  affinity information for NUMA platforms.  It is required by Open\n  MPI.  Therefore, specifying `--with-hwloc=no` (or `--without-hwloc`)\n  is disallowed.\n\n  By default (i.e., if `--with-hwloc` is not specified, or if\n  `--with-hwloc` is specified without a value), Open MPI will first try\n  to find/use an hwloc installation on the current system.  If Open\n  MPI cannot find one, it will fall back to build and use the internal\n  copy of hwloc included in the Open MPI source tree.\n\n  Alternatively, the `--with-hwloc` option can be used to specify\n  where to find the hwloc support headers and library.  The following\n  `VALUE`s are permitted:\n\n  * `internal`: Only use Open MPI's internal copy of hwloc.\n  * `external`: Only use an external hwloc installation (rely on\n    default compiler and linker paths to find it).\n  * `DIR`: Only use the specific hwloc installation found in\n    the specified directory.\n\n* `--with-hwloc-libdir=DIR`:\n  Look in directory for the hwloc libraries.  This option is only\n  usable when building Open MPI against an external hwloc\n  installation.  Just like other `--with-FOO-libdir` configure options,\n  this option is only needed for special configurations.\n\n* `--disable-hwloc-pci`:\n  Disable building hwloc's PCI device-sensing capabilities.  On some\n  platforms (e.g., SusE 10 SP1, x86-64), the libpci support library is\n  broken.  Open MPI's configure script should usually detect when\n  libpci is not usable due to such brokenness and turn off PCI\n  support, but there may be cases when configure mistakenly enables\n  PCI support in the presence of a broken libpci.  These cases may\n  result in `make` failing with warnings about relocation symbols in\n  libpci.  The `--disable-hwloc-pci` switch can be used to force Open\n  MPI to not build hwloc's PCI device-sensing capabilities in these\n  cases.\n\n  Similarly, if Open MPI incorrectly decides that libpci is broken,\n  you can force Open MPI to build hwloc's PCI device-sensing\n  capabilities by using `--enable-hwloc-pci`.\n\n  hwloc can discover PCI devices and locality, which can be useful for\n  Open MPI in assigning message passing resources to MPI processes.\n\n* `--with-libltdl=DIR`:\n  Specify the directory where the GNU Libtool libltdl libraries and\n  header files are located.  This option is generally only necessary\n  if the libltdl headers and libraries are not in default\n  compiler/linker search paths.\n\n  Note that this option is ignored if `--disable-dlopen` is specified.\n\n* `--disable-libompitrace`:\n  Disable building the simple `libompitrace` library (see note above\n  about libompitrace)\n\n* `--with-valgrind(=DIR)`:\n  Directory where the valgrind software is installed.  If Open MPI\n  finds Valgrind's header files, it will include additional support\n  for Valgrind's memory-checking debugger.\n\n  Specifically, it will eliminate a lot of false positives from\n  running Valgrind on MPI applications.  There is a minor performance\n  penalty for enabling this option.\n\n\n### MPI Functionality\n\n* `--with-mpi-param-check(=VALUE)`:\n  Whether or not to check MPI function parameters for errors at\n  runtime.  The following `VALUE`s are permitted:\n\n  * `always`: MPI function parameters are always checked for errors\n  * `never`: MPI function parameters are never checked for errors\n  * `runtime`: Whether MPI function parameters are checked depends on\n    the value of the MCA parameter `mpi_param_check` (default: yes).\n  * `yes`: Synonym for \"always\" (same as `--with-mpi-param-check`).\n  * `no`: Synonym for \"never\" (same as `--without-mpi-param-check`).\n\n  If `--with-mpi-param` is not specified, `runtime` is the default.\n\n* `--disable-mpi-thread-multiple`:\n  Disable the MPI thread level `MPI_THREAD_MULTIPLE` (it is enabled by\n  default).\n\n* `--enable-mpi-java`:\n  Enable building of an ***EXPERIMENTAL*** Java MPI interface\n  (disabled by default).  You may also need to specify\n  `--with-jdk-dir`, `--with-jdk-bindir`, and/or `--with-jdk-headers`.\n  See [README.JAVA.md](README.JAVA.md) for details.\n\n  Note that this Java interface is ***INCOMPLETE*** (meaning: it does\n  not support all MPI functionality) and ***LIKELY TO CHANGE***.  The\n  Open MPI developers would very much like to hear your feedback about\n  this interface.  See [README.JAVA.md](README.JAVA.md) for more\n  details.\n\n* `--enable-mpi-fortran(=VALUE)`:\n  By default, Open MPI will attempt to build all 3 Fortran bindings:\n  `mpif.h`, the `mpi` module, and the `mpi_f08` module.  The following\n  `VALUE`s are permitted:\n\n  * `all`: Synonym for `yes`.\n  * `yes`: Attempt to build all 3 Fortran bindings; skip\n    any binding that cannot be built (same as\n    `--enable-mpi-fortran`).\n  * `mpifh`: Only build `mpif.h` support.\n  * `usempi`: Only build `mpif.h` and `mpi` module support.\n  * `usempif08`:  Build `mpif.h`, `mpi` module, and `mpi_f08`\n     module support.\n  * `none`: Synonym for `no`.\n  * `no`: Do not build any MPI Fortran support (same as\n    `--disable-mpi-fortran`).  This is mutually exclusive\n     with building the OpenSHMEM Fortran interface.\n\n* `--enable-mpi-ext(=LIST)`:\n  Enable Open MPI's non-portable API extensions.  `LIST` is a\n  comma-delmited list of extensions.  If no `LIST` is specified, all\n  of the extensions are enabled.\n\n  See the \"Open MPI API Extensions\" section for more details.\n\n* `--disable-mpi-io`:\n  Disable built-in support for MPI-2 I/O, likely because an\n  externally-provided MPI I/O package will be used. Default is to use\n  the internal framework system that uses the ompio component and a\n  specially modified version of ROMIO that fits inside the romio\n  component\n\n* `--disable-io-romio`:\n  Disable the ROMIO MPI-IO component\n\n* `--with-io-romio-flags=FLAGS`:\n  Pass `FLAGS` to the ROMIO distribution configuration script.  This\n  option is usually only necessary to pass\n  parallel-filesystem-specific preprocessor/compiler/linker flags back\n  to the ROMIO system.\n\n* `--disable-io-ompio`:\n  Disable the ompio MPI-IO component\n\n* `--enable-sparse-groups`:\n  Enable the usage of sparse groups. This would save memory\n  significantly especially if you are creating large\n  communicators. (Disabled by default)\n\n\n### OpenSHMEM Functionality\n\n* `--disable-oshmem`:\n  Disable building the OpenSHMEM implementation (by default, it is\n  enabled).\n\n* `--disable-oshmem-fortran`:\n  Disable building only the Fortran OpenSHMEM bindings. Please see\n  the \"Compiler Notes\" section herein which contains further\n  details on known issues with various Fortran compilers.\n\n\n### Miscellaneous Functionality\n\n* `--without-memory-manager`:\n  Disable building Open MPI's memory manager.  Open MPI's memory\n  manager is usually built on Linux based platforms, and is generally\n  only used for optimizations with some OpenFabrics-based networks (it\n  is not *necessary* for OpenFabrics networks, but some performance\n  loss may be observed without it).\n\n  However, it may be necessary to disable the memory manager in order\n  to build Open MPI statically.\n\n* `--with-ft=TYPE`:\n  Specify the type of fault tolerance to enable.  Options: LAM\n  (LAM/MPI-like), cr (Checkpoint/Restart).  Fault tolerance support is\n  disabled unless this option is specified.\n\n* `--enable-peruse`:\n  Enable the PERUSE MPI data analysis interface.\n\n* `--enable-heterogeneous`:\n  Enable support for running on heterogeneous clusters (e.g., machines\n  with different endian representations).  Heterogeneous support is\n  disabled by default because it imposes a minor performance penalty.\n\n  ***THIS FUNCTIONALITY IS CURRENTLY BROKEN - DO NOT USE***\n\n* `--with-wrapper-cflags=CFLAGS`\n* `--with-wrapper-cxxflags=CXXFLAGS`\n* `--with-wrapper-fflags=FFLAGS`\n* `--with-wrapper-fcflags=FCFLAGS`\n* `--with-wrapper-ldflags=LDFLAGS`\n* `--with-wrapper-libs=LIBS`:\n  Add the specified flags to the default flags that are used in Open\n  MPI's \"wrapper\" compilers (e.g., `mpicc` -- see below for more\n  information about Open MPI's wrapper compilers).  By default, Open\n  MPI's wrapper compilers use the same compilers used to build Open\n  MPI and specify a minimum set of additional flags that are necessary\n  to compile/link MPI applications.  These configure options give\n  system administrators the ability to embed additional flags in\n  OMPI's wrapper compilers (which is a local policy decision).  The\n  meanings of the different flags are:\n\n  `CFLAGS`: Flags passed by the `mpicc` wrapper to the C compiler\n  `CXXFLAGS`: Flags passed by the `mpic++` wrapper to the C++ compiler\n  `FCFLAGS`: Flags passed by the `mpifort` wrapper to the Fortran compiler\n  `LDFLAGS`: Flags passed by all the wrappers to the linker\n  `LIBS`: Flags passed by all the wrappers to the linker\n\n  There are other ways to configure Open MPI's wrapper compiler\n  behavior; see [the Open MPI FAQ](https://www.open-mpi.org/faq/) for\n  more information.\n\nThere are many other options available -- see `./configure --help`.\n\nChanging the compilers that Open MPI uses to build itself uses the\nstandard Autoconf mechanism of setting special environment variables\neither before invoking configure or on the configure command line.\nThe following environment variables are recognized by configure:\n\n* `CC`: C compiler to use\n* `CFLAGS`: Compile flags to pass to the C compiler\n* `CPPFLAGS`: Preprocessor flags to pass to the C compiler\n* `CXX`: C++ compiler to use\n* `CXXFLAGS`: Compile flags to pass to the C++ compiler\n* `CXXCPPFLAGS`: Preprocessor flags to pass to the C++ compiler\n* `FC`: Fortran compiler to use\n* `FCFLAGS`: Compile flags to pass to the Fortran compiler\n* `LDFLAGS`: Linker flags to pass to all compilers\n* `LIBS`: Libraries to pass to all compilers (it is rarely\n   necessary for users to need to specify additional `LIBS`)\n* `PKG_CONFIG`: Path to the `pkg-config` utility\n\nFor example:\n\n```\nshell$ ./configure CC=mycc CXX=myc++ FC=myfortran ...\n```\n\n***NOTE:*** We generally suggest using the above command line form for\nsetting different compilers (vs. setting environment variables and\nthen invoking `./configure`).  The above form will save all variables\nand values in the `config.log` file, which makes post-mortem analysis\neasier if problems occur.\n\nNote that if you intend to compile Open MPI with a `make` other than\nthe default one in your `PATH`, then you must either set the `$MAKE`\nenvironment variable before invoking Open MPI's `configure` script, or\npass `MAKE=your_make_prog` to configure.  For example:\n\n```\nshell$ ./configure MAKE=/path/to/my/make ...\n```\n\nThis could be the case, for instance, if you have a shell alias for\n`make`, or you always type `gmake` out of habit.  Failure to tell\n`configure` which non-default `make` you will use to compile Open MPI\ncan result in undefined behavior (meaning: don't do that).\n\nNote that you may also want to ensure that the value of\n`LD_LIBRARY_PATH` is set appropriately (or not at all) for your build\n(or whatever environment variable is relevant for your operating\nsystem).  For example, some users have been tripped up by setting to\nuse a non-default Fortran compiler via the `FC` environment variable,\nbut then failing to set `LD_LIBRARY_PATH` to include the directory\ncontaining that non-default Fortran compiler's support libraries.\nThis causes Open MPI's `configure` script to fail when it tries to\ncompile / link / run simple Fortran programs.\n\nIt is required that the compilers specified be compile and link\ncompatible, meaning that object files created by one compiler must be\nable to be linked with object files from the other compilers and\nproduce correctly functioning executables.\n\nOpen MPI supports all the `make` targets that are provided by GNU\nAutomake, such as:\n\n* `all`: build the entire Open MPI package\n* `install`: install Open MPI\n* `uninstall`: remove all traces of Open MPI from the $prefix\n* `clean`: clean out the build tree\n\nOnce Open MPI has been built and installed, it is safe to run `make\nclean` and/or remove the entire build tree.\n\nVPATH and parallel builds are fully supported.\n\nGenerally speaking, the only thing that users need to do to use Open\nMPI is ensure that `PREFIX/bin` is in their `PATH` and `PREFIX/lib` is\nin their `LD_LIBRARY_PATH`.  Users may need to ensure to set the\n`PATH` and `LD_LIBRARY_PATH` in their shell setup files (e.g.,\n`.bashrc`, `.cshrc`) so that non-interactive `rsh`/`ssh`-based logins\nwill be able to find the Open MPI executables.\n\n\n## Open MPI Version Numbers and Binary Compatibility\n\nOpen MPI has two sets of version numbers that are likely of interest\nto end users / system administrator:\n\n1. Software version number\n1. Shared library version numbers\n\nBoth are predicated on Open MPI's definition of \"backwards\ncompatibility.\"\n\n***NOTE:*** The version numbering conventions were changed with the\nrelease of v1.10.0.  Most notably, Open MPI no longer uses an\n\"odd/even\" release schedule to indicate feature development vs. stable\nreleases.  See the README in releases prior to v1.10.0 for more\ninformation (e.g.,\nhttps://github.com/open-mpi/ompi/blob/v1.8/README#L1392-L1475).\n\n\n### Backwards Compatibility\n\nOpen MPI version Y is backwards compatible with Open MPI version X\n(where Y>X) if users can:\n\n* Compile an MPI/OpenSHMEM application with version X,\n  `mpirun`/`oshrun` it with version Y, and get the same\n  user-observable behavior.\n* Invoke `ompi_info` with the same CLI options in versions X and Y and\n  get the same user-observable behavior.\n\nNote that this definition encompasses several things:\n\n* Application Binary Interface (ABI)\n* MPI / OpenSHMEM run time system\n* `mpirun` / `oshrun` command line options\n* MCA parameter names / values / meanings\n\nHowever, this definition only applies when the same version of Open\nMPI is used with all instances of the runtime and MPI / OpenSHMEM\nprocesses in a single MPI job.  If the versions are not exactly the\nsame everywhere, Open MPI is not guaranteed to work properly in any\nscenario.\n\nBackwards compatibility tends to work best when user applications are\ndynamically linked to one version of the Open MPI / OSHMEM libraries,\nand can be updated at run time to link to a new version of the Open\nMPI / OSHMEM libraries.\n\nFor example, if an MPI / OSHMEM application links statically against\nthe libraries from Open MPI vX, then attempting to launch that\napplication with `mpirun` / `oshrun` from Open MPI vY is not guaranteed to\nwork (because it is mixing vX and vY of Open MPI in a single job).\n\nSimilarly, if using a container technology that internally bundles all\nthe libraries from Open MPI vX, attempting to launch that container\nwith `mpirun` / `oshrun` from Open MPI vY is not guaranteed to work.\n\n### Software Version Number\n\nOfficial Open MPI releases use the common \"A.B.C\" version identifier\nformat.  Each of the three numbers has a specific meaning:\n\n* Major: The major number is the first integer in the version string\n  Changes in the major number typically indicate a significant\n  change in the code base and/or end-user functionality, and also\n  indicate a break from backwards compatibility.  Specifically: Open\n  MPI releases with different major version numbers are not\n  backwards compatibale with each other.\n\n  ***CAVEAT:*** This rule does not extend to versions prior to v1.10.0.\n  Specifically: v1.10.x is not guaranteed to be backwards\n  compatible with other v1.x releases.\n\n* Minor: The minor number is the second integer in the version string.\n  Changes in the minor number indicate a user-observable change in the\n  code base and/or end-user functionality.  Backwards compatibility\n  will still be preserved with prior releases that have the same major\n  version number (e.g., v2.5.3 is backwards compatible with v2.3.1).\n\n* Release: The release number is the third integer in the version\n  string.  Changes in the release number typically indicate a bug fix\n  in the code base and/or end-user functionality.  For example, if\n  there is a release that only contains bug fixes and no other\n  user-observable changes or new features, only the third integer will\n  be increased (e.g., from v4.3.0 to v4.3.1).\n\nThe \"A.B.C\" version number may optionally be followed by a Quantifier:\n\n* Quantifier: Open MPI version numbers sometimes have an arbitrary\n  string affixed to the end of the version number. Common strings\n  include:\n  * aX: Indicates an alpha release. X is an integer indicating the\n    number of the alpha release (e.g., v1.10.3a5 indicates the 5th\n    alpha release of version 1.10.3).\n  * bX: Indicates a beta release. X is an integer indicating the\n    number of the beta release (e.g., v1.10.3b3 indicates the 3rd beta\n    release of version 1.10.3).\n  * rcX: Indicates a release candidate. X is an integer indicating the\n    number of the release candidate (e.g., v1.10.3rc4 indicates the\n    4th release candidate of version 1.10.3).\n\nNightly development snapshot tarballs use a different version number\nscheme; they contain three distinct values:\n\n* The git branch name from which the tarball was created.\n* The date/timestamp, in `YYYYMMDDHHMM` format.\n* The hash of the git commit from which the tarball was created.\n\nFor example, a snapshot tarball filename of\n`openmpi-v2.x-201703070235-e4798fb.tar.gz` indicates that this tarball\nwas created from the v2.x branch, on March 7, 2017, at 2:35am GMT,\nfrom git hash e4798fb.\n\n### Shared Library Version Number\n\nThe GNU Libtool official documentation details how the versioning\nscheme works.  The quick version is that the shared library versions\nare a triple of integers: (current,revision,age), or `c:r:a`.  This\ntriple is not related to the Open MPI software version number.  There\nare six simple rules for updating the values (taken almost verbatim\nfrom the Libtool docs):\n\n1. Start with version information of `0:0:0` for each shared library.\n1. Update the version information only immediately before a public\n  release of your software. More frequent updates are unnecessary,\n  and only guarantee that the current interface number gets larger\n  faster.\n1. If the library source code has changed at all since the last\n   update, then increment revision (`c:r:a` becomes `c:r+1:a`).\n1. If any interfaces have been added, removed, or changed since the\n   last update, increment current, and set revision to 0.\n1. If any interfaces have been added since the last public release,\n   then increment age.\n1. If any interfaces have been removed since the last public release,\n   then set age to 0.\n\nHere's how we apply those rules specifically to Open MPI:\n\n1. The above rules do not apply to MCA components (a.k.a. \"plugins\");\n   MCA component `.so` versions stay unspecified.\n1. The above rules apply exactly as written to the following libraries\n   starting with Open MPI version v1.5 (prior to v1.5, `libopen-pal`\n   and `libopen-rte` were still at `0:0:0` for reasons discussed in bug\n   ticket #2092 https://svn.open-mpi.org/trac/ompi/ticket/2092):\n    * `libopen-rte`\n    * `libopen-pal`\n    * `libmca_common_*`\n1. The following libraries use a slightly modified version of the\n   above rules: rules 4, 5, and 6 only apply to the official MPI and\n   OpenSHMEM interfaces (functions, global variables).  The rationale\n   for this decision is that the vast majority of our users only care\n   about the official/public MPI/OpenSHMEM interfaces; we therefore\n   want the `.so` version number to reflect only changes to the\n   official MPI/OpenSHMEM APIs.  Put simply: non-MPI/OpenSHMEM API /\n   internal changes to the MPI-application-facing libraries are\n   irrelevant to pure MPI/OpenSHMEM applications.\n   * `libmpi`\n   * `libmpi_mpifh`\n   * `libmpi_usempi_tkr`\n   * `libmpi_usempi_ignore_tkr`\n   * `libmpi_usempif08`\n   * `libmpi_cxx`\n   * `libmpi_java`\n   * `liboshmem`\n\n\n## Checking Your Open MPI Installation\n\nThe `ompi_info` command can be used to check the status of your Open\nMPI installation (located in `PREFIX/bin/ompi_info`).  Running it with\nno arguments provides a summary of information about your Open MPI\ninstallation.\n\nNote that the `ompi_info` command is extremely helpful in determining\nwhich components are installed as well as listing all the run-time\nsettable parameters that are available in each component (as well as\ntheir default values).\n\nThe following options may be helpful:\n\n* `--all`: Show a *lot* of information about your Open MPI\n  installation.\n* `--parsable`:  Display all the information in an easily\n  `grep`/`cut`/`awk`/`sed`-able format.\n* `--param FRAMEWORK COMPONENT`:\n  A `FRAMEWORK` value of `all` and a `COMPONENT` value of `all` will\n  show all parameters to all components.  Otherwise, the parameters of\n  all the components in a specific framework, or just the parameters\n  of a specific component can be displayed by using an appropriate\n  FRAMEWORK and/or COMPONENT name.\n* `--level LEVEL`:\n  By default, `ompi_info` only shows \"Level 1\" MCA parameters --\n  parameters that can affect whether MPI processes can run\n  successfully or not (e.g., determining which network interfaces to\n  use).  The `--level` option will display all MCA parameters from\n  level 1 to `LEVEL` (the max `LEVEL` value is 9).  Use `ompi_info\n  --param FRAMEWORK COMPONENT --level 9` to see *all* MCA parameters\n  for a given component.  See \"The Modular Component Architecture\n  (MCA)\" section, below, for a fuller explanation.\n\nChanging the values of these parameters is explained in the \"The\nModular Component Architecture (MCA)\" section, below.\n\nWhen verifying a new Open MPI installation, we recommend running six\ntests:\n\n1. Use `mpirun` to launch a non-MPI program (e.g., `hostname` or\n   `uptime`) across multiple nodes.\n1. Use `mpirun` to launch a trivial MPI program that does no MPI\n   communication (e.g., the `hello_c` program in the `examples/`\n   directory in the Open MPI distribution).\n1. Use `mpirun` to launch a trivial MPI program that sends and\n   receives a few MPI messages (e.g., the `ring_c` program in the\n   `examples/` directory in the Open MPI distribution).\n1. Use `oshrun` to launch a non-OpenSHMEM program across multiple\n   nodes.\n1. Use `oshrun` to launch a trivial MPI program that does no OpenSHMEM\n   communication (e.g., `hello_shmem.c` program in the `examples/`\n   directory in the Open MPI distribution.)\n1. Use `oshrun` to launch a trivial OpenSHMEM program that puts and\n   gets a few messages (e.g., the `ring_shmem.c` in the `examples/`\n   directory in the Open MPI distribution.)\n\nIf you can run all six of these tests successfully, that is a good\nindication that Open MPI built and installed properly.\n\n\n## Open MPI API Extensions\n\nOpen MPI contains a framework for extending the MPI API that is\navailable to applications.  Each extension is usually a standalone set\nof functionality that is distinct from other extensions (similar to\nhow Open MPI's plugins are usually unrelated to each other).  These\nextensions provide new functions and/or constants that are available\nto MPI applications.\n\nWARNING: These extensions are neither standard nor portable to other\nMPI implementations!\n\n### Compiling the extensions\n\nOpen MPI extensions are all enabled by default; they can be disabled\nvia the `--disable-mpi-ext` command line switch.\n\nSince extensions are meant to be used by advanced users only, this\nfile does not document which extensions are available or what they\ndo.  Look in the ompi/mpiext/ directory to see the extensions; each\nsubdirectory of that directory contains an extension.  Each has a\nREADME file that describes what it does.\n\n### Using the extensions\n\nTo reinforce the fact that these extensions are non-standard, you must\ninclude a separate header file after `<mpi.h>` to obtain the function\nprototypes, constant declarations, etc.  For example:\n\n```c\n#include <mpi.h>\n#if defined(OPEN_MPI) && OPEN_MPI\n#include <mpi-ext.h>\n#endif\n\nint main() {\n    MPI_Init(NULL, NULL);\n\n#if defined(OPEN_MPI) && OPEN_MPI\n    {\n        char ompi_bound[OMPI_AFFINITY_STRING_MAX];\n        char current_binding[OMPI_AFFINITY_STRING_MAX];\n        char exists[OMPI_AFFINITY_STRING_MAX];\n        OMPI_Affinity_str(OMPI_AFFINITY_LAYOUT_FMT, ompi_bound,\n                          current_bindings, exists);\n    }\n#endif\n    MPI_Finalize();\n    return 0;\n}\n```\n\nNotice that the Open MPI-specific code is surrounded by the `#if`\nstatement to ensure that it is only ever compiled by Open MPI.\n\nThe Open MPI wrapper compilers (`mpicc` and friends) should\nautomatically insert all relevant compiler and linker flags necessary\nto use the extensions.  No special flags or steps should be necessary\ncompared to \"normal\" MPI applications.\n\n\n## Compiling Open MPI Applications\n\nOpen MPI provides \"wrapper\" compilers that should be used for\ncompiling MPI and OpenSHMEM applications:\n\n* C: `mpicc`, `oshcc`\n* C++: `mpiCC`, `oshCC` (or `mpic++` if your filesystem is case-insensitive)\n* Fortran: `mpifort`, `oshfort`\n\nFor example:\n\n```\nshell$ mpicc hello_world_mpi.c -o hello_world_mpi -g\nshell$\n```\n\nFor OpenSHMEM applications:\n\n```\nshell$ oshcc hello_shmem.c -o hello_shmem -g\nshell$\n```\n\nAll the wrapper compilers do is add a variety of compiler and linker\nflags to the command line and then invoke a back-end compiler.  To be\nspecific: the wrapper compilers do not parse source code at all; they\nare solely command-line manipulators, and have nothing to do with the\nactual compilation or linking of programs.  The end result is an MPI\nexecutable that is properly linked to all the relevant libraries.\n\nCustomizing the behavior of the wrapper compilers is possible (e.g.,\nchanging the compiler [not recommended] or specifying additional\ncompiler/linker flags); see the Open MPI FAQ for more information.\n\nAlternatively, Open MPI also installs `pkg-config(1)` configuration\nfiles under `$libdir/pkgconfig`.  If `pkg-config` is configured to find\nthese files, then compiling / linking Open MPI programs can be\nperformed like this:\n\n```\nshell$ gcc hello_world_mpi.c -o hello_world_mpi -g \\\n            `pkg-config ompi-c --cflags --libs`\nshell$\n```\n\nOpen MPI supplies multiple `pkg-config(1)` configuration files; one\nfor each different wrapper compiler (language):\n\n* `ompi`: Synonym for `ompi-c`; Open MPI applications using the C\n   MPI bindings\n* `ompi-c`: Open MPI applications using the C MPI bindings\n* `ompi-cxx`: Open MPI applications using the C MPI bindings\n* `ompi-fort`: Open MPI applications using the Fortran MPI bindings\n\nThe following `pkg-config(1)` configuration files *may* be installed,\ndepending on which command line options were specified to Open MPI's\nconfigure script.  They are not necessary for MPI applications, but\nmay be used by applications that use Open MPI's lower layer support\nlibraries.\n\n* `opal`: Open Portable Access Layer applications\n\n\n## Running Open MPI Applications\n\nOpen MPI supports both `mpirun` and `mpiexec` (they are exactly\nequivalent) to launch MPI applications.  For example:\n\n```\nshell$ mpirun -np 2 hello_world_mpi\nor\nshell$ mpiexec -np 1 hello_world_mpi : -np 1 hello_world_mpi\n```\n\nare equivalent.\n\nThe `rsh` launcher (which defaults to using `ssh`) accepts a\n`--hostfile` parameter (the option `--machinefile` is equivalent); you\ncan specify a `--hostfile` parameter indicating a standard\n`mpirun`-style hostfile (one hostname per line):\n\n```\nshell$ mpirun --hostfile my_hostfile -np 2 hello_world_mpi\n```\n\nIf you intend to run more than one process on a node, the hostfile can\nuse the \"slots\" attribute.  If \"slots\" is not specified, a count of 1\nis assumed.  For example, using the following hostfile:\n\n```\nshell$ cat my_hostfile\nnode1.example.com\nnode2.example.com\nnode3.example.com slots=2\nnode4.example.com slots=4\n```\n\n```\nshell$ mpirun --hostfile my_hostfile -np 8 hello_world_mpi\n```\n\nwill launch `MPI_COMM_WORLD` rank 0 on node1, rank 1 on node2, ranks 2\nand 3 on node3, and ranks 4 through 7 on node4.\n\nOther starters, such as the resource manager / batch scheduling\nenvironments, do not require hostfiles (and will ignore the hostfile\nif it is supplied).  They will also launch as many processes as slots\nhave been allocated by the scheduler if no \"-np\" argument has been\nprovided.  For example, running a SLURM job with 8 processors:\n\n```\nshell$ salloc -n 8 mpirun a.out\n```\n\nThe above command will reserve 8 processors and run 1 copy of mpirun,\nwhich will, in turn, launch 8 copies of a.out in a single\n`MPI_COMM_WORLD` on the processors that were allocated by SLURM.\n\nNote that the values of component parameters can be changed on the\n`mpirun` / `mpiexec` command line.  This is explained in the section\nbelow, \"The Modular Component Architecture (MCA)\".\n\nOpen MPI supports `oshrun` to launch OpenSHMEM applications. For\nexample:\n\n```\nshell$ oshrun -np 2 hello_world_oshmem\n```\n\nOpenSHMEM applications may also be launched directly by resource\nmanagers such as SLURM. For example, when OMPI is configured\n`--with-pmix` and `--with-slurm`, one may launch OpenSHMEM applications\nvia `srun`:\n\n```\nshell$ srun -N 2 hello_world_oshmem\n```\n\n## The Modular Component Architecture (MCA)\n\nThe MCA is the backbone of Open MPI -- most services and functionality\nare implemented through MCA components.\n\n### MPI layer frameworks\n\nHere is a list of all the component frameworks in the MPI layer of\nOpen MPI:\n\n* `bml`: BTL management layer\n* `coll`: MPI collective algorithms\n* `fbtl`: file byte transfer layer: abstraction for individual\n   read: collective read and write operations for MPI I/O\n* `fs`: file system functions for MPI I/O\n* `io`: MPI I/O\n* `mtl`: Matching transport layer, used for MPI point-to-point\n   messages on some types of networks\n* `op`: Back end computations for intrinsic MPI_Op operators\n* `osc`: MPI one-sided communications\n* `pml`: MPI point-to-point management layer\n* `rte`: Run-time environment operations\n* `sharedfp`: shared file pointer operations for MPI I/O\n* `topo`: MPI topology routines\n* `vprotocol`: Protocols for the \"v\" PML\n\n### OpenSHMEM component frameworks\n\n* `atomic`: OpenSHMEM atomic operations\n* `memheap`: OpenSHMEM memory allocators that support the\n  PGAS memory model\n* `scoll`: OpenSHMEM collective operations\n* `spml`: OpenSHMEM \"pml-like\" layer: supports one-sided,\n  point-to-point operations\n* `sshmem`: OpenSHMEM shared memory backing facility\n\n### Back-end run-time environment (RTE) component frameworks:\n\n* `dfs`: Distributed file system\n* `errmgr`: RTE error manager\n* `ess`: RTE environment-specific services\n* `filem`: Remote file management\n* `grpcomm`: RTE group communications\n* `iof`: I/O forwarding\n* `notifier`: System-level notification support\n* `odls`: OpenRTE daemon local launch subsystem\n* `oob`: Out of band messaging\n* `plm`: Process lifecycle management\n* `ras`: Resource allocation system\n* `rmaps`: Resource mapping system\n* `rml`: RTE message layer\n* `routed`: Routing table for the RML\n* `rtc`: Run-time control framework\n* `schizo`: OpenRTE personality framework\n* `state`: RTE state machine\n\n### Miscellaneous frameworks:\n\n* `allocator`: Memory allocator\n* `backtrace`: Debugging call stack backtrace support\n* `btl`: Point-to-point Byte Transfer Layer\n* `dl`: Dynamic loading library interface\n* `event`: Event library (libevent) versioning support\n* `hwloc`: Hardware locality (hwloc) versioning support\n* `if`: OS IP interface support\n* `installdirs`: Installation directory relocation services\n* `memchecker`: Run-time memory checking\n* `memcpy`: Memory copy support\n* `memory`: Memory management hooks\n* `mpool`: Memory pooling\n* `patcher`: Symbol patcher hooks\n* `pmix`: Process management interface (exascale)\n* `pstat`: Process status\n* `rcache`: Memory registration cache\n* `sec`: Security framework\n* `shmem`: Shared memory support (NOT related to OpenSHMEM)\n* `timer`: High-resolution timers\n\n### Framework notes\n\nEach framework typically has one or more components that are used at\nrun-time.  For example, the `btl` framework is used by the MPI layer\nto send bytes across different types underlying networks.  The `tcp`\n`btl`, for example, sends messages across TCP-based networks; the\n`ucx` `pml` sends messages across InfiniBand-based networks.\n\nEach component typically has some tunable parameters that can be\nchanged at run-time.  Use the `ompi_info` command to check a component\nto see what its tunable parameters are.  For example:\n\n```\nshell$ ompi_info --param btl tcp\n```\n\nshows some of the parameters (and default values) for the `tcp` `btl`\ncomponent (use `--level` to show *all* the parameters; see below).\n\nNote that `ompi_info` only shows a small number a component's MCA\nparameters by default.  Each MCA parameter has a \"level\" value from 1\nto 9, corresponding to the MPI-3 MPI_T tool interface levels.  In Open\nMPI, we have interpreted these nine levels as three groups of three:\n\n1. End user / basic\n1. End user / detailed\n1. End user / all\n1. Application tuner / basic\n1. Application tuner / detailed\n1. Application tuner / all\n1. MPI/OpenSHMEM developer / basic\n1. MPI/OpenSHMEM developer / detailed\n1. MPI/OpenSHMEM developer / all\n\nHere's how the three sub-groups are defined:\n\n1. End user: Generally, these are parameters that are required for\n   correctness, meaning that someone may need to set these just to\n   get their MPI/OpenSHMEM application to run correctly.\n1. Application tuner: Generally, these are parameters that can be\n   used to tweak MPI application performance.\n1. MPI/OpenSHMEM developer: Parameters that either don't fit in the\n   other two, or are specifically intended for debugging /\n   development of Open MPI itself.\n\nEach sub-group is broken down into three classifications:\n\n1. Basic: For parameters that everyone in this category will want to\n   see.\n1. Detailed: Parameters that are useful, but you probably won't need\n   to change them often.\n1. All: All other parameters -- probably including some fairly\n   esoteric parameters.\n\nTo see *all* available parameters for a given component, specify that\nompi_info should use level 9:\n\n```\nshell$ ompi_info --param btl tcp --level 9\n```\n\nThese values can be overridden at run-time in several ways.  At\nrun-time, the following locations are examined (in order) for new\nvalues of parameters:\n\n1. `PREFIX/etc/openmpi-mca-params.conf`:\n   This file is intended to set any system-wide default MCA parameter\n   values -- it will apply, by default, to all users who use this Open\n   MPI installation.  The default file that is installed contains many\n   comments explaining its format.\n\n1. `$HOME/.openmpi/mca-params.conf`:\n   If this file exists, it should be in the same format as\n   `PREFIX/etc/openmpi-mca-params.conf`.  It is intended to provide\n   per-user default parameter values.\n\n1. environment variables of the form `OMPI_MCA_<name>` set equal to a\n   `VALUE`:\n\n   Where `<name>` is the name of the parameter.  For example, set the\n   variable named `OMPI_MCA_btl_tcp_frag_size` to the value 65536\n   (Bourne-style shells):\n\n   ```\n   shell$ OMPI_MCA_btl_tcp_frag_size=65536\n   shell$ export OMPI_MCA_btl_tcp_frag_size\n   ```\n\n4. the `mpirun`/`oshrun` command line: `--mca NAME VALUE`\n\n   Where <name> is the name of the parameter.  For example:\n\n   ```\n   shell$ mpirun --mca btl_tcp_frag_size 65536 -np 2 hello_world_mpi\n   ```\n\nThese locations are checked in order.  For example, a parameter value\npassed on the `mpirun` command line will override an environment\nvariable; an environment variable will override the system-wide\ndefaults.\n\nEach component typically activates itself when relevant.  For example,\nthe usNIC component will detect that usNIC devices are present and\nwill automatically be used for MPI communications.  The SLURM\ncomponent will automatically detect when running inside a SLURM job\nand activate itself.  And so on.\n\nComponents can be manually activated or deactivated if necessary, of\ncourse.  The most common components that are manually activated,\ndeactivated, or tuned are the `btl` components -- components that are\nused for MPI point-to-point communications on many types common\nnetworks.\n\nFor example, to *only* activate the `tcp` and `self` (process loopback)\ncomponents are used for MPI communications, specify them in a\ncomma-delimited list to the `btl` MCA parameter:\n\n```\nshell$ mpirun --mca btl tcp,self hello_world_mpi\n```\n\nTo add shared memory support, add `sm` into the command-delimited list\n(list order does not matter):\n\n```\nshell$ mpirun --mca btl tcp,sm,self hello_world_mpi\n```\n\n(there used to be a `vader` BTL for shared memory support; it was\nrenamed to `sm` in Open MPI v5.0.0, but the alias `vader` still works\nas well)\n\nTo specifically deactivate a specific component, the comma-delimited\nlist can be prepended with a `^` to negate it:\n\n```\nshell$ mpirun --mca btl ^tcp hello_mpi_world\n```\n\nThe above command will use any other `btl` component other than the\n`tcp` component.\n\n\n## Questions?  Problems?\n\nFound a bug?  Got a question?  Want to make a suggestion?  Want to\ncontribute to Open MPI?  Please let us know!\n\nWhen submitting questions and problems, be sure to include as much\nextra information as possible.  [See the community help web\npage](https://www.open-mpi.org/community/help/) for details on all the\ninformation that we request in order to provide assistance:\n\nThe best way to report bugs, send comments, or ask questions is to\nsign up on the user's and/or developer's mailing list (for user-level\nand developer-level questions; when in doubt, send to the user's\nlist):\n\n* users@lists.open-mpi.org\n* devel@lists.open-mpi.org\n\nBecause of spam, only subscribers are allowed to post to these lists\n(ensure that you subscribe with and post from exactly the same e-mail\naddress -- joe@example.com is considered different than\njoe@mycomputer.example.com!).  Visit these pages to subscribe to the\nlists:\n\n* [Subscribe to the users mailing\n  list](https://lists.open-mpi.org/mailman/listinfo/users)\n* [Subscribe to the developers mailing\n  list](https://lists.open-mpi.org/mailman/listinfo/devel)\n\nMake today an Open MPI day!\n",
        "/tmp/vanessa/spack-stage/spack-stage-openmpi-master-qcrm7qmgqutvsby2zcmdb57s22lzfq65/spack-src/config/opal_configure_options.m4": "dnl -*- shell-script -*-\ndnl\ndnl Copyright (c) 2004-2010 The Trustees of Indiana University and Indiana\ndnl                         University Research and Technology\ndnl                         Corporation.  All rights reserved.\ndnl Copyright (c) 2004-2005 The University of Tennessee and The University\ndnl                         of Tennessee Research Foundation.  All rights\ndnl                         reserved.\ndnl Copyright (c) 2004-2005 High Performance Computing Center Stuttgart,\ndnl                         University of Stuttgart.  All rights reserved.\ndnl Copyright (c) 2004-2005 The Regents of the University of California.\ndnl                         All rights reserved.\ndnl Copyright (c) 2006-2020 Cisco Systems, Inc.  All rights reserved\ndnl Copyright (c) 2007      Sun Microsystems, Inc.  All rights reserved.\ndnl Copyright (c) 2009      IBM Corporation.  All rights reserved.\ndnl Copyright (c) 2009      Los Alamos National Security, LLC.  All rights\ndnl                         reserved.\ndnl Copyright (c) 2009-2011 Oak Ridge National Labs.  All rights reserved.\ndnl Copyright (c) 2011-2013 NVIDIA Corporation.  All rights reserved.\ndnl Copyright (c) 2013-2017 Intel, Inc.  All rights reserved.\ndnl Copyright (c) 2015      Research Organization for Information Science\ndnl                         and Technology (RIST). All rights reserved.\ndnl\ndnl $COPYRIGHT$\ndnl\ndnl Additional copyrights may follow\ndnl\ndnl $HEADER$\ndnl\n\nAC_DEFUN([OPAL_CONFIGURE_OPTIONS],[\nopal_show_subtitle \"OPAL Configuration options\"\n\n\n#\n# Is this a developer copy?\n#\n\nif test -d .git; then\n    OPAL_DEVEL=1\nelse\n    OPAL_DEVEL=0\nfi\n\n\n#\n# Code coverage options\n#\n\nAC_MSG_CHECKING([if want to run code coverage])\nAC_ARG_ENABLE(coverage,\n              AC_HELP_STRING([--enable-coverage],\n                             [enable code coverage files to be generated]))\nif test \"$enable_coverage\" = \"yes\"; then\n    if test \"$enable_shared\" = \"yes\"; then\n        AC_MSG_WARN([Code coverage can run only with static libraries. Please\nrun configure with --enable-static --disable-shared if\nyou want code coverage. Also ensure that you execute\nmake clean too ensure removal of all leftover shared\nmpi libraries])\n        AC_MSG_ERROR([Cannot continue processing])\n    fi\n    AC_MSG_RESULT([yes])\n    WANT_COVERAGE=1\nelse\n    AC_MSG_RESULT([no])\n    WANT_COVERAGE=0\nfi\n\n\n#\n# Branch Probabilities options\n#\n\nAC_MSG_CHECKING([if want to compile with branch probabilities])\nAC_ARG_ENABLE(branch-probabilities,\n              AC_HELP_STRING([--enable-branch-probabilities],\n                             [enable profile arcs and branch probability optimization]))\nif test \"$enable_branch_probabilities\" = \"yes\"; then\n    AC_MSG_RESULT([yes])\n    WANT_BRANCH_PROBABILITIES=1\nelse\n    AC_MSG_RESULT([no])\n    WANT_BRANCH_PROBABILITIES=0\nfi\n\n\n#\n# Memory debugging\n#\n\nAC_MSG_CHECKING([if want to debug memory usage])\nAC_ARG_ENABLE(mem-debug,\n    AC_HELP_STRING([--enable-mem-debug],\n                   [enable memory debugging (not for general MPI users!) (default: disabled)]))\nif test \"$enable_mem_debug\" = \"yes\"; then\n    AC_MSG_RESULT([yes])\n    WANT_MEM_DEBUG=1\nelse\n    AC_MSG_RESULT([no])\n    WANT_MEM_DEBUG=0\nfi\nAC_DEFINE_UNQUOTED(OPAL_ENABLE_MEM_DEBUG, $WANT_MEM_DEBUG,\n    [Whether we want the memory profiling or not])\n\n#\n# Memory profiling\n#\n\nAC_MSG_CHECKING([if want to profile memory usage])\nAC_ARG_ENABLE(mem-profile,\n    AC_HELP_STRING([--enable-mem-profile],\n                   [enable memory profiling (not for general MPI users!) (default: disabled)]))\nif test \"$enable_mem_profile\" = \"yes\"; then\n    AC_MSG_RESULT([yes])\n    WANT_MEM_PROFILE=1\nelse\n    AC_MSG_RESULT([no])\n    WANT_MEM_PROFILE=0\nfi\nAC_DEFINE_UNQUOTED(OPAL_ENABLE_MEM_PROFILE, $WANT_MEM_PROFILE,\n    [Whether we want the memory profiling or not])\n\n#\n# Developer picky compiler options\n#\n\nAC_MSG_CHECKING([if want developer-level compiler pickyness])\nAC_ARG_ENABLE(picky,\n    AC_HELP_STRING([--enable-picky],\n                   [enable developer-level compiler pickyness when building Open MPI (default: disabled, unless a .git directory is found in the build tree)]))\nif test \"$enable_picky\" = \"yes\"; then\n    AC_MSG_RESULT([yes])\n    WANT_PICKY_COMPILER=1\nelse\n    AC_MSG_RESULT([no])\n    WANT_PICKY_COMPILER=0\nfi\n#################### Developer default override ####################\nif test \"$WANT_PICKY_COMPILER\" = \"0\" && test -z \"$enable_picky\" && test \"$OPAL_DEVEL\" = 1; then\n    WANT_PICKY_COMPILER=1\n    echo \"--> developer override: enable picky compiler by default\"\nfi\n#################### Developer default override ####################\n\n#\n# Developer debugging\n#\n\nAC_MSG_CHECKING([if want developer-level debugging code])\nAC_ARG_ENABLE(debug,\n    AC_HELP_STRING([--enable-debug],\n                   [enable developer-level debugging code (not for general MPI users!) (default: disabled)]))\nif test \"$enable_debug\" = \"yes\"; then\n    AC_MSG_RESULT([yes])\n    WANT_DEBUG=1\nelse\n    AC_MSG_RESULT([no])\n    WANT_DEBUG=0\nfi\n\n\nAC_MSG_CHECKING([if want to developer-level timing framework])\nAC_ARG_ENABLE(timing,\n    AC_HELP_STRING([--enable-timing],\n                   [enable developer-level timing code (not for general MPI users!) (default: disabled)]))\nif test \"$enable_timing\" = \"yes\"; then\n    AC_MSG_RESULT([yes])\n    WANT_TIMING=1\nelse\n    AC_MSG_RESULT([no])\n    WANT_TIMING=0\nfi\n\nAC_DEFINE_UNQUOTED(OPAL_ENABLE_TIMING, $WANT_TIMING,\n    [Whether we want developer-level timing framework or not])\n\nAM_CONDITIONAL([OPAL_COMPILE_TIMING], [test \"$WANT_TIMING\" = \"1\"])\nAM_CONDITIONAL([OPAL_INSTALL_TIMING_BINARIES], [test \"$WANT_TIMING\" = \"1\" && test \"$enable_binaries\" != \"no\"])\n\nif test \"$WANT_DEBUG\" = \"0\"; then\n    CFLAGS=\"-DNDEBUG $CFLAGS\"\n    CXXFLAGS=\"-DNDEBUG $CXXFLAGS\"\nfi\nAC_DEFINE_UNQUOTED(OPAL_ENABLE_DEBUG, $WANT_DEBUG,\n    [Whether we want developer-level debugging code or not])\n\nAC_ARG_ENABLE(debug-symbols,\n    AC_HELP_STRING([--disable-debug-symbols],\n        [Disable adding compiler flags to enable debugging symbols if --enable-debug is specified.  For non-debugging builds, this flag has no effect.]))\n\n#\n# Do we want to install all of OPAL/ORTE and OMPI's header files?\n#\n\nAC_MSG_CHECKING([if want to install project-internal header files])\nAC_ARG_WITH(devel-headers,\n    AC_HELP_STRING([--with-devel-headers],\n                   [normal MPI users/applications do not need this (mpi.h and mpif.h are ALWAYS installed).  Developer headers are only necessary for MCA module authors (default: disabled).]))\nif test \"$with_devel_headers\" = \"yes\"; then\n    AC_MSG_RESULT([yes])\n    WANT_INSTALL_HEADERS=1\nelse\n    AC_MSG_RESULT([no])\n    WANT_INSTALL_HEADERS=0\nfi\nAM_CONDITIONAL(WANT_INSTALL_HEADERS, test \"$WANT_INSTALL_HEADERS\" = 1)\n\n\n#\n# Do we want the pretty-print stack trace feature?\n#\n\nAC_MSG_CHECKING([if want pretty-print stacktrace])\nAC_ARG_ENABLE([pretty-print-stacktrace],\n    [AC_HELP_STRING([--enable-pretty-print-stacktrace],\n                    [Pretty print stacktrace on process signal (default: enabled)])])\nif test \"$enable_pretty_print_stacktrace\" = \"no\" ; then\n    AC_MSG_RESULT([no])\n    WANT_PRETTY_PRINT_STACKTRACE=0\nelse\n    AC_MSG_RESULT([yes])\n    WANT_PRETTY_PRINT_STACKTRACE=1\nfi\nAC_DEFINE_UNQUOTED([OPAL_WANT_PRETTY_PRINT_STACKTRACE],\n                   [$WANT_PRETTY_PRINT_STACKTRACE],\n                   [if want pretty-print stack trace feature])\n\n\n#\n# Do we want PTY support?\n#\n\nAC_MSG_CHECKING([if want pty support])\nAC_ARG_ENABLE(pty-support,\n    AC_HELP_STRING([--enable-pty-support],\n                   [Enable/disable PTY support for STDIO forwarding.  (default: enabled)]))\nif test \"$enable_pty_support\" = \"no\" ; then\n    AC_MSG_RESULT([no])\n    OPAL_ENABLE_PTY_SUPPORT=0\nelse\n    AC_MSG_RESULT([yes])\n    OPAL_ENABLE_PTY_SUPPORT=1\nfi\nAC_DEFINE_UNQUOTED([OPAL_ENABLE_PTY_SUPPORT], [$OPAL_ENABLE_PTY_SUPPORT],\n                   [Whether user wants PTY support or not])\n\n\n#\n# Do we want to disable weak symbols for some reason?\n#\n\nAC_MSG_CHECKING([if want weak symbol support])\nAC_ARG_ENABLE(weak-symbols,\n    AC_HELP_STRING([--enable-weak-symbols],\n                   [use weak symbols, if available (default: enabled)]))\nif test \"$enable_weak_symbols\" != \"no\"; then\n    AC_MSG_RESULT([yes])\n    WANT_WEAK_SYMBOLS=1\nelse\n    AC_MSG_RESULT([no])\n    WANT_WEAK_SYMBOLS=0\nfi\n\n\n#\n# Do we want to allow DLOPEN?\n#\n\nAC_MSG_CHECKING([if want dlopen support])\nAC_ARG_ENABLE([dlopen],\n    [AC_HELP_STRING([--enable-dlopen],\n                    [Whether build should attempt to use dlopen (or\n                     similar) to dynamically load components.\n                     Disabling dlopen implies --disable-mca-dso.\n                     (default: enabled)])])\nif test \"$enable_dlopen\" = \"no\" ; then\n    enable_mca_dso=no\n    enable_mca_static=yes\n    OPAL_ENABLE_DLOPEN_SUPPORT=0\n    AC_MSG_RESULT([no])\nelse\n    OPAL_ENABLE_DLOPEN_SUPPORT=1\n    AC_MSG_RESULT([yes])\nfi\nAC_DEFINE_UNQUOTED(OPAL_ENABLE_DLOPEN_SUPPORT, $OPAL_ENABLE_DLOPEN_SUPPORT,\n    [Whether we want to enable dlopen support])\n\n\n#\n# Do we want to show component load error messages by default?\n#\n\nAC_MSG_CHECKING([for default value of mca_base_component_show_load_errors])\nAC_ARG_ENABLE([show-load-errors-by-default],\n    [AC_HELP_STRING([--enable-show-load-errors-by-default],\n                    [Set the default value for the MCA parameter\n                     mca_base_component_show_load_errors (but can be\n                     overridden at run time by the usual\n                     MCA-variable-setting mechansism).  This MCA variable\n                     controls whether warnings are displayed when an MCA\n                     component fails to load at run time due to an error.\n                     (default: enabled, meaning that\n                      mca_base_component_show_load_errors is enabled\n                      by default])])\nif test \"$enable_show_load_errors_by_default\" = \"no\" ; then\n    OPAL_SHOW_LOAD_ERRORS_DEFAULT=0\n    AC_MSG_RESULT([disabled by default])\nelse\n    OPAL_SHOW_LOAD_ERRORS_DEFAULT=1\n    AC_MSG_RESULT([enabled by default])\nfi\nAC_DEFINE_UNQUOTED(OPAL_SHOW_LOAD_ERRORS_DEFAULT, $OPAL_SHOW_LOAD_ERRORS_DEFAULT,\n                   [Default value for mca_base_component_show_load_errors MCA variable])\n\n\n#\n# Heterogeneous support\n#\n\nAC_MSG_CHECKING([if want heterogeneous support])\nAC_ARG_ENABLE([heterogeneous],\n    [AC_HELP_STRING([--enable-heterogeneous],\n                    [Enable features required for heterogeneous\n                     platform support (default: disabled)])])\nif test \"$enable_heterogeneous\" = \"yes\" ; then\n     AC_MSG_RESULT([yes])\n     opal_want_heterogeneous=1\nelse\n     AC_MSG_RESULT([no])\n     opal_want_heterogeneous=0\nfi\nAC_DEFINE_UNQUOTED([OPAL_ENABLE_HETEROGENEOUS_SUPPORT],\n                   [$opal_want_heterogeneous],\n                   [Enable features required for heterogeneous support])\n\n\nif test \"$opal_want_heterogeneous\" = 1; then\n    ompi_cv_c_word_size_align=yes\nelse\n    AC_CACHE_CHECK([if word-sized integers must be word-size aligned],\n        [ompi_cv_c_word_size_align],\n        [AC_LANG_PUSH(C)\n         AC_RUN_IFELSE([AC_LANG_PROGRAM([dnl\n#include <stdlib.h>], [[    long data[2] = {0, 0};\n    long *lp;\n    int *ip;\n    ip = (int*) data;\n    ip++;\n    lp = (long*) ip;\n    return lp[0]; ]])],\n            [ompi_cv_c_word_size_align=no],\n            [ompi_cv_c_word_size_align=yes],\n            [ompi_cv_c_word_size_align=yes])])\nfi\nAS_IF([test $ompi_cv_c_word_size_align = yes], [results=1], [results=0])\nAC_DEFINE_UNQUOTED([OPAL_ALIGN_WORD_SIZE_INTEGERS], [$results],\n    [set to 1 if word-size integers must be aligned to word-size padding to prevent bus errors])\n\n\n#\n# Cross-compile data\n#\nAC_ARG_WITH([cross],\n    [AC_HELP_STRING([--with-cross=FILE],\n        [Specify configure values that can not be determined in a cross-compilation environment.  See the Open MPI FAQ.])])\nif test \"$with_cross\" = \"yes\" ; then\n    AC_MSG_ERROR([--with-cross argument must include FILE option])\nelif test \"$with_cross\" = \"no\" ; then\n    AC_MSG_ERROR([--without-cross is not a valid argument])\nelif test \"$with_cross\" != \"\" ; then\n    if test ! -r $with_cross ; then\n        AC_MSG_ERROR([could not find cross-compile data file $with_cross])\n    fi\n\n    # eval into environment\n    OPAL_LOG_MSG([Loading cross-compile file $with_cross, with contents below])\n    OPAL_LOG_FILE([$with_cross])\n    . \"$with_cross\"\nfi\n\n#\n# Do we want to install binaries?\n#\nAC_ARG_ENABLE([binaries],\n    [AC_HELP_STRING([--enable-binaries],\n        [Build and install binaries required for Open MPI, such as the wrapper compilers.   Useful for multi-lib installations.  (default: enabled)])])\nAM_CONDITIONAL([OPAL_INSTALL_BINARIES], [test \"$enable_binaries\" != \"no\"])\n\nAC_ARG_ENABLE([script-wrapper-compilers],\n  [AC_HELP_STRING([--enable-script-wrapper-compilers],\n     [Use less featured script-based wrapper compilers instead of the standard C-based wrapper compilers.  This option ignores the --disable-binaries option and is mainly useful in cross-compile environments])])\n  if test \"$enable_script_wrapper_compilers\" = \"yes\"; then\n      WANT_SCRIPT_WRAPPER_COMPILERS=1\n  else\n      WANT_SCRIPT_WRAPPER_COMPILERS=0\n  fi\nAM_CONDITIONAL([OPAL_WANT_SCRIPT_WRAPPER_COMPILERS], [test \"$enable_script_wrapper_compilers\" = \"yes\"])\n\n#\n# Support per-user config files?\n#\nAC_ARG_ENABLE([per-user-config-files],\n   [AC_HELP_STRING([--enable-per-user-config-files],\n      [Disable per-user configuration files, to save disk accesses during job start-up.  This is likely desirable for large jobs.  Note that this can also be achieved by environment variables at run-time.  (default: enabled)])])\nif test \"$enable_per_user_config_files\" = \"no\" ; then\n  result=0\nelse\n  result=1\nfi\nAC_DEFINE_UNQUOTED([OPAL_WANT_HOME_CONFIG_FILES], [$result],\n     [Enable per-user config files])\n\n#\n# Do we want to enable IPv6 support?\n#\nAC_MSG_CHECKING([if want IPv6 support])\nAC_ARG_ENABLE([ipv6],\n    [AC_HELP_STRING([--enable-ipv6],\n        [Enable IPv6 support, but only if the underlying system supports it (default: disabled)])])\nif test \"$enable_ipv6\" = \"yes\"; then\n    AC_MSG_RESULT([yes])\n    opal_want_ipv6=1\nelse\n    AC_MSG_RESULT([no])\n    opal_want_ipv6=0\nfi\nAC_DEFINE_UNQUOTED([OPAL_ENABLE_IPV6], [$opal_want_ipv6],\n                   [Enable IPv6 support, but only if the underlying system supports it])\n\n\n#\n# Package/brand string\n#\nAC_MSG_CHECKING([if want package/brand string])\nAC_ARG_WITH([package-string],\n     [AC_HELP_STRING([--with-package-string=STRING],\n                     [Use a branding string throughout Open MPI])])\nif test \"$with_package_string\" = \"\" || test \"$with_package_string\" = \"no\"; then\n    with_package_string=\"Open MPI $OPAL_CONFIGURE_USER@$OPAL_CONFIGURE_HOST Distribution\"\nfi\nAC_DEFINE_UNQUOTED([OPAL_PACKAGE_STRING], [\"$with_package_string\"],\n     [package/branding string for Open MPI])\nAC_MSG_RESULT([$with_package_string])\n\n#\n# Ident string\n#\nAC_MSG_CHECKING([if want ident string])\nAC_ARG_WITH([ident-string],\n     [AC_HELP_STRING([--with-ident-string=STRING],\n                     [Embed an ident string into Open MPI object files])])\nif test \"$with_ident_string\" = \"\" || test \"$with_ident_string\" = \"no\"; then\n    with_ident_string=\"%VERSION%\"\nfi\n# This is complicated, because $OPAL_VERSION may have spaces in it.\n# So put the whole sed expr in single quotes -- i.e., directly\n# substitute %VERSION% for (not expanded) $OPAL_VERSION.\nwith_ident_string=\"`echo $with_ident_string | sed -e 's/%VERSION%/$OPAL_VERSION/'`\"\n\n# Now eval an echo of that so that the \"$OPAL_VERSION\" token is\n# replaced with its value.  Enclose the whole thing in \"\" so that it\n# ends up as 1 token.\nwith_ident_string=\"`eval echo $with_ident_string`\"\n\nAC_DEFINE_UNQUOTED([OPAL_IDENT_STRING], [\"$with_ident_string\"],\n     [ident string for Open MPI])\nAC_MSG_RESULT([$with_ident_string])\n\n\n#\n# Use alternative checksum algorithm\n#\nAC_MSG_CHECKING([if want to use an alternative checksum algo for messages])\nAC_ARG_WITH([dst-checksum],\n     [AC_HELP_STRING([--with-dst-checksum],\n                     [Use an alternative checksum algorithm for messages])])\nif test \"$with_dst_checksum\" = \"yes\"; then\n    AC_MSG_RESULT([yes])\n    CFLAGS=\"-DOPAL_CSUM_DST $CFLAGS\"\nelse\n    AC_MSG_RESULT([no])\nfi\n\n\n#\n# User level (mpi.h.in) visible maximum lengths of strings.\n# These may be required in lower-level libraries to set up matching\n# data-structures (e.g. OPAL_MAX_OBJECT_NAME).\n#\n# Default values (as of OMPI-1.3), and some sane minimum and maximum values\n#\n\n# No lower and upper bound required or enforced\nOPAL_WITH_OPTION_MIN_MAX_VALUE(processor_name,  256,  16, 1024)\n\n# Min length according to information passed in ompi/errhandler/errcode.c\nOPAL_WITH_OPTION_MIN_MAX_VALUE(error_string,    256,  64, 1024)\n\n# Min length according to MPI-2.1, p. 236 (information passed in ompi/communicator/comm.c: min only 48)\nOPAL_WITH_OPTION_MIN_MAX_VALUE(object_name,      64,  64,  256)\n\n# Min and Max length according to MPI-2.1, p. 287 is 32; longest key in ROMIO however 33\nOPAL_WITH_OPTION_MIN_MAX_VALUE(info_key,         36,  34,  255)\n\n# No lower and upper bound required or enforced!\nOPAL_WITH_OPTION_MIN_MAX_VALUE(info_val,        256,  32, 1024)\n\n# Min length according to _POSIX_HOST_NAME_MAX=255 (4*HOST_NAME_MAX)\nOPAL_WITH_OPTION_MIN_MAX_VALUE(port_name,      1024, 255, 2048)\n\n# Min length accroding to MPI-2.1, p. 418\nOPAL_WITH_OPTION_MIN_MAX_VALUE(datarep_string,  128,  64,  256)\n\nAC_DEFINE_UNQUOTED([OPAL_ENABLE_CRDEBUG], [0],\n    [Whether we want checkpoint/restart enabled debugging functionality or not])\n\n# some systems don't want/like getpwuid\nAC_MSG_CHECKING([if want getpwuid support])\nAC_ARG_ENABLE([getpwuid],\n    [AC_HELP_STRING([--disable-getpwuid],\n        [Disable getpwuid support (default: enabled)])])\nif test \"$enable_getpwuid\" = \"no\"; then\n    AC_MSG_RESULT([no])\n    opal_want_getpwuid=0\nelse\n    AC_MSG_RESULT([yes])\n    opal_want_getpwuid=1\nfi\nAC_DEFINE_UNQUOTED([OPAL_ENABLE_GETPWUID], [$opal_want_getpwuid],\n                   [Disable getpwuid support (default: enabled)])\n\ndnl We no longer support the old OPAL_ENABLE_PROGRESS_THREADS.  At\ndnl some point, this should die.\nAC_DEFINE([OPAL_ENABLE_PROGRESS_THREADS],\n          [0],\n          [Whether we want BTL progress threads enabled])\n])dnl\n",
        "/tmp/vanessa/spack-stage/spack-stage-openmpi-master-qcrm7qmgqutvsby2zcmdb57s22lzfq65/spack-src/config/opal_mca.m4": "dnl -*- shell-script -*-\ndnl\ndnl Copyright (c) 2004-2005 The Trustees of Indiana University and Indiana\ndnl                         University Research and Technology\ndnl                         Corporation.  All rights reserved.\ndnl Copyright (c) 2004-2005 The University of Tennessee and The University\ndnl                         of Tennessee Research Foundation.  All rights\ndnl                         reserved.\ndnl Copyright (c) 2004-2005 High Performance Computing Center Stuttgart,\ndnl                         University of Stuttgart.  All rights reserved.\ndnl Copyright (c) 2004-2005 The Regents of the University of California.\ndnl                         All rights reserved.\ndnl Copyright (c) 2010-2016 Cisco Systems, Inc.  All rights reserved.\ndnl Copyright (c) 2013-2017 Intel, Inc. All rights reserved.\ndnl Copyright (c) 2018      Amazon.com, Inc. or its affiliates.\ndnl                         All Rights reserved.\ndnl $COPYRIGHT$\ndnl\ndnl Additional copyrights may follow\ndnl\ndnl $HEADER$\ndnl\n\n# OPAL_EVAL_ARG(arg)\n# ------------------\n# evaluates and returns argument\nAC_DEFUN([OPAL_EVAL_ARG], [$1])\n\n######################################################################\n#\n# OPAL_MCA\n#\n# configure the MCA (modular component architecture).  Works hand in hand\n# with Open MPI's autogen.pl, requiring it's specially formatted lists\n# of frameworks, components, etc.\n#\n# USAGE:\n#   OPAL_MCA()\n#\n######################################################################\nAC_DEFUN([OPAL_MCA],[\n    dnl for OPAL_CONFIGURE_USER env variable\n    AC_REQUIRE([OPAL_CONFIGURE_SETUP])\n\n    # Set a special flag so that we can detect if the user calls\n    # OPAL_WRAPPER_FLAGS_ADD and error.\n    m4_define([mca_component_configure_active], [1])\n\n    # Find which components should be built as run-time loadable components\n    # Acceptable combinations:\n    #\n    # [default -- no option given]\n    # --enable-mca-dso\n    # --enable-mca-dso=[.+,]*COMPONENT_TYPE[.+,]*\n    # --enable-mca-dso=[.+,]*COMPONENT_TYPE-COMPONENT_NAME[.+,]*\n    # --disable-mca-dso\n    #\n    AC_ARG_ENABLE([mca-no-build],\n        [AC_HELP_STRING([--enable-mca-no-build=LIST],\n                        [Comma-separated list of <type>-<component> pairs\n                         that will not be built.  Example:\n                         \"--enable-mca-no-build=btl-portals,oob-ud\" will\n                         disable building the \"portals\" btl and the \"ud\"\n                         oob components.])])\n    AC_ARG_ENABLE(mca-dso,\n        AC_HELP_STRING([--enable-mca-dso=LIST],\n                       [Comma-separated list of types and/or\n                        type-component pairs that will be built as\n                        run-time loadable components (as opposed to\n                        statically linked in), if supported on this\n                        platform.  The default is to build all components\n                        as DSOs.]))\n    AC_ARG_ENABLE(mca-static,\n        AC_HELP_STRING([--enable-mca-static=LIST],\n                       [Comma-separated list of types and/or\n                        type-component pairs that will be built statically\n                        linked into the library.  The default (if DSOs are\n                        supported) is to build all components as DSOs.\n                        Enabling a component as static disables it\n                        building as a DSO.]))\n    AC_ARG_ENABLE(mca-direct,\n        AC_HELP_STRING([--enable-mca-direct=LIST],\n                       [Comma-separated list of type-component pairs that\n                        will be hard coded as the one component to use for\n                        a given component type, saving the (small)\n                        overhead of the component architecture.  LIST must\n                        not be empty and implies given component pairs are\n                        build as static components.]))\n\n    AC_MSG_CHECKING([which components should be disabled])\n    if test \"$enable_mca_no_build\" = \"yes\"; then\n        AC_MSG_RESULT([yes])\n        AC_MSG_ERROR([*** The enable-mca-no-build flag requires an explicit list\n*** of type-component pairs.  For example, --enable-mca-no-build=pml-ob1])\n    else\n        ifs_save=\"$IFS\"\n        IFS=\"${IFS}$PATH_SEPARATOR,\"\n        msg=\n        for item in $enable_mca_no_build; do\n            type=\"`echo $item | cut -s -f1 -d-`\"\n            comp=\"`echo $item | cut -s -f2- -d-`\"\n            if test -z $type ; then\n                type=$item\n            fi\n            if test -z $comp ; then\n                str=\"`echo DISABLE_${type}=1 | sed s/-/_/g`\"\n                eval $str\n                msg=\"$item $msg\"\n            else\n                str=\"`echo DISABLE_${type}_${comp}=1 | sed s/-/_/g`\"\n                eval $str\n                msg=\"$item $msg\"\n            fi\n        done\n        IFS=\"$ifs_save\"\n    fi\n    AC_MSG_RESULT([$msg])\n    unset msg\n\n    #\n    # First, add all the mca-direct components / types into the mca-static\n    # lists and create a list of component types that are direct compile,\n    # in the form DIRECT_[type]=[component]\n    #\n    AC_MSG_CHECKING([which components should be direct-linked into the library])\n    if test \"$enable_mca_direct\" = \"yes\" ; then\n        AC_MSG_RESULT([yes])\n        AC_MSG_ERROR([*** The enable-mca-direct flag requires an explicit list of\n*** type-component pairs.  For example, --enable-mca-direct=pml-ob1,coll-basic])\n    elif test ! -z \"$enable_mca_direct\" && test \"$enable_mca_direct\" != \"\" ; then\n        #\n        # we need to add this into the static list, unless the static list\n        # is everything\n        #\n        if test \"$enable_mca_static\" = \"no\" ; then\n            AC_MSG_WARN([*** Re-enabling static component support for direct call])\n            enable_mca_static=\"$enable_mca_direct\"\n        elif test -z \"$enable_mca_static\" ; then\n            enable_mca_static=\"$enable_mca_direct\"\n        elif test \"$enable_mca_static\" != \"yes\" ; then\n            enable_mca_static=\"$enable_mca_direct,$enable_mca_static\"\n        fi\n\n        ifs_save=\"$IFS\"\n        IFS=\"${IFS}$PATH_SEPARATOR,\"\n        msg=\n        for item in $enable_mca_direct; do\n            type=\"`echo $item | cut -f1 -d-`\"\n            comp=\"`echo $item | cut -f2- -d-`\"\n            if test -z $type || test -z $comp ; then\n                AC_MSG_ERROR([*** The enable-mca-direct flag requires a\n*** list of type-component pairs.  Invalid input detected.])\n            else\n                str=\"`echo DIRECT_$type=$comp | sed s/-/_/g`\"\n                eval $str\n                msg=\"$item $msg\"\n            fi\n        done\n        IFS=\"$ifs_save\"\n    fi\n    AC_MSG_RESULT([$msg])\n    unset msg\n\n    #\n    # Second, set the DSO_all and STATIC_all variables.  conflict\n    # resolution (prefer static) is done in the big loop below\n    #\n    AC_MSG_CHECKING([which components should be run-time loadable])\n    if test \"$enable_static\" != \"no\"; then\n        DSO_all=0\n        msg=none\n    elif test -z \"$enable_mca_dso\" || test \"$enable_mca_dso\" = \"yes\"; then\n        DSO_all=1\n        msg=all\n    elif test \"$enable_mca_dso\" = \"no\"; then\n        DSO_all=0\n        msg=none\n        enable_dlopen=no\n    else\n        DSO_all=0\n        ifs_save=\"$IFS\"\n        IFS=\"${IFS}$PATH_SEPARATOR,\"\n        msg=\n        for item in $enable_mca_dso; do\n            str=\"`echo DSO_$item=1 | sed s/-/_/g`\"\n            eval $str\n            msg=\"$item $msg\"\n        done\n        IFS=\"$ifs_save\"\n    fi\n    AC_MSG_RESULT([$msg])\n    unset msg\n    if test \"$enable_static\" != \"no\"; then\n        AC_MSG_WARN([*** Shared libraries have been disabled (--disable-shared)])\n        AC_MSG_WARN([*** Building MCA components as DSOs automatically disabled])\n    fi\n\n    AC_MSG_CHECKING([which components should be static])\n    if test \"$enable_mca_static\" = \"yes\"; then\n        STATIC_all=1\n        msg=all\n    elif test -z \"$enable_mca_static\" || test \"$enable_mca_static\" = \"no\"; then\n        STATIC_all=0\n        msg=none\n    else\n        STATIC_all=0\n        ifs_save=\"$IFS\"\n        IFS=\"${IFS}$PATH_SEPARATOR,\"\n        msg=\n        for item in $enable_mca_static; do\n            str=\"`echo STATIC_$item=1 | sed s/-/_/g`\"\n            eval $str\n            msg=\"$item $msg\"\n        done\n        IFS=\"$ifs_save\"\n    fi\n    AC_MSG_RESULT([$msg])\n    unset msg\n\n    AC_MSG_CHECKING([for projects containing MCA frameworks])\n    AC_MSG_RESULT([mca_project_list])\n\n    # if there isn't a project list, abort\n    m4_ifdef([mca_project_list], [],\n             [m4_fatal([Could not find project list - please rerun autogen.pl!])])\n\n    # now configure all the projects, frameworks, and components.  Most\n    # of the hard stuff is in here\n    MCA_PROJECT_SUBDIRS=\n    MCA_PROJECT_DIST_SUBDIRS=\n    m4_foreach(mca_project, [mca_project_list],\n               [# BWB: Until projects have separate configure scripts\n                # and can skip running all of ORTE, just avoid recursing\n                # into orte sub directory if orte disabled\n                if (test \"mca_project\" = \"ompi\" && test \"$enable_mpi\" != \"no\") || test \"mca_project\" = \"opal\" || test \"mca_project\" = \"orte\" || test \"mca_project\" = \"oshmem\"; then\n                   MCA_PROJECT_SUBDIRS=\"$MCA_PROJECT_SUBDIRS mca_project\"\n                   MCA_PROJECT_DIST_SUBDIRS=\"$MCA_PROJECT_DIST_SUBDIRS mca_project\"\n                fi\n                MCA_CONFIGURE_PROJECT(mca_project)])\n\n    AC_SUBST(MCA_PROJECT_SUBDIRS)\n    AC_SUBST(MCA_PROJECT_DIST_SUBDIRS)\n\n    m4_undefine([mca_component_configure_active])\n])\n\n\n######################################################################\n#\n# MCA_CONFIGURE_PROJECT\n#\n# Configure all frameworks inside the given project name.  Assumes that\n# the frameworks are located in [project_name]/mca/[frameworks] and that\n# there is an m4_defined list named mca_[project]_framework_list with\n# the list of frameworks.\n#\n# USAGE:\n#   MCA_CONFIGURE_PROJECT(project_name)\n#\n######################################################################\nAC_DEFUN([MCA_CONFIGURE_PROJECT],[\n    # can't use a variable rename here because these need to be evaled\n    # at auto* time.\n\n    opal_show_subtitle \"Configuring MCA for $1\"\n\n    AC_MSG_CHECKING([for frameworks for $1])\n    AC_MSG_RESULT([mca_$1_framework_list])\n\n    # iterate through the list of frameworks.  There is something\n    # funky with m4 foreach if the list is defined, but empty.  It\n    # will call the 3rd argument once with an empty value for the\n    # first argument.  Protect against calling MCA_CONFIGURE_FRAMEWORK\n    # with an empty second argument.  Grrr....\n    # if there isn't a project list, abort\n    #\n    # Also setup two variables for Makefiles:\n    #  MCA_project_FRAMEWORKS     - list of frameworks in that project\n    #  MCA_project_FRAMEWORK_LIBS - list of libraries (or variables pointing\n    #                               to more libraries) that must be included\n    #                               in the project's main library\n    m4_ifdef([mca_$1_framework_list], [],\n             [m4_fatal([Could not find mca_$1_framework_list - please rerun autogen.pl])])\n\n    MCA_$1_FRAMEWORKS=\n    MCA_$1_FRAMEWORKS_SUBDIRS=\n    MCA_$1_FRAMEWORK_COMPONENT_ALL_SUBDIRS=\n    MCA_$1_FRAMEWORK_COMPONENT_DSO_SUBDIRS=\n    MCA_$1_FRAMEWORK_COMPONENT_STATIC_SUBDIRS=\n    MCA_$1_FRAMEWORK_LIBS=\n\n    m4_foreach(mca_framework, [mca_$1_framework_list],\n               [m4_ifval(mca_framework,\n                         [dnl common has to go up front\n                          m4_if(mca_framework, [common],\n                                [MCA_$1_FRAMEWORKS=\"mca_framework $MCA_$1_FRAMEWORKS\"\n                                 MCA_$1_FRAMEWORKS_SUBDIRS=\"[mca/]mca_framework $MCA_$1_FRAMEWORKS_SUBDIRS\"\n                                 MCA_$1_FRAMEWORK_COMPONENT_ALL_SUBDIRS=\"[\\$(MCA_]$1[_]mca_framework[_ALL_SUBDIRS)] $MCA_$1_FRAMEWORK_COMPONENT_ALL_SUBDIRS\"\n                                 MCA_$1_FRAMEWORK_COMPONENT_DSO_SUBDIRS=\"[\\$(MCA_]$1[_]mca_framework[_DSO_SUBDIRS)] $MCA_$1_FRAMEWORK_COMPONENT_DSO_SUBDIRS\"\n                                 MCA_$1_FRAMEWORK_COMPONENT_STATIC_SUBDIRS=\"[\\$(MCA_]$1[_]mca_framework[_STATIC_SUBDIRS)] $MCA_$1_FRAMEWORK_COMPONENT_STATIC_SUBDIRS\"\n                                ], [\n                                 MCA_$1_FRAMEWORKS=\"$MCA_$1_FRAMEWORKS mca_framework\"\n                                 MCA_$1_FRAMEWORKS_SUBDIRS=\"$MCA_$1_FRAMEWORKS_SUBDIRS [mca/]mca_framework\"\n                                 MCA_$1_FRAMEWORK_COMPONENT_ALL_SUBDIRS=\"$MCA_$1_FRAMEWORK_COMPONENT_ALL_SUBDIRS [\\$(MCA_]$1[_]mca_framework[_ALL_SUBDIRS)]\"\n                                 MCA_$1_FRAMEWORK_COMPONENT_DSO_SUBDIRS=\"$MCA_$1_FRAMEWORK_COMPONENT_DSO_SUBDIRS [\\$(MCA_]$1[_]mca_framework[_DSO_SUBDIRS)]\"\n                                 MCA_$1_FRAMEWORK_COMPONENT_STATIC_SUBDIRS=\"$MCA_$1_FRAMEWORK_COMPONENT_STATIC_SUBDIRS [\\$(MCA_]$1[_]mca_framework[_STATIC_SUBDIRS)]\"\n                                 MCA_$1_FRAMEWORK_LIBS=\"$MCA_$1_FRAMEWORK_LIBS [mca/]mca_framework[/libmca_]mca_framework[.la]\"])\n                          MCA_$1_FRAMEWORK_LIBS=\"$MCA_$1_FRAMEWORK_LIBS [\\$(MCA_]$1[_]mca_framework[_STATIC_LTLIBS)]\"\n                          m4_ifdef([MCA_]$1[_]mca_framework[_CONFIG],\n                                   [MCA_]$1[_]mca_framework[_CONFIG]($1, mca_framework),\n                                   [MCA_CONFIGURE_FRAMEWORK($1, mca_framework, 1)])])])\n\n    # note that mca_wrapper_extra_* is a running list, and we take checkpoints at the end of our project\n    $1_mca_wrapper_extra_cppflags=\"$mca_wrapper_extra_cppflags\"\n    $1_mca_wrapper_extra_ldflags=\"$mca_wrapper_extra_ldflags\"\n    $1_mca_wrapper_extra_libs=\"$mca_wrapper_extra_libs\"\n\n    AC_SUBST(MCA_$1_FRAMEWORKS)\n    AC_SUBST(MCA_$1_FRAMEWORKS_SUBDIRS)\n    AC_SUBST(MCA_$1_FRAMEWORK_COMPONENT_ALL_SUBDIRS)\n    AC_SUBST(MCA_$1_FRAMEWORK_COMPONENT_DSO_SUBDIRS)\n    AC_SUBST(MCA_$1_FRAMEWORK_COMPONENT_STATIC_SUBDIRS)\n    AC_SUBST(MCA_$1_FRAMEWORK_LIBS)\n])\n\n# MCA_ORDER_COMPONENT_LIST(project_name, framework_name)\nAC_DEFUN([MCA_ORDER_COMPONENT_LIST], [\n    m4_foreach(mca_component, [mca_$1_$2_m4_config_component_list],\n               [m4_ifval(mca_component,\n                    [m4_ifdef([MCA_]$1[_]$2[_]mca_component[_PRIORITY], [],\n                         [m4_fatal([MCA_$1_$2_]mca_component[_PRIORITY not found, but required.])])])])\n    m4_define([component_list],\n              [esyscmd([config/opal_mca_priority_sort.pl] m4_foreach([mca_component], [mca_$1_$2_m4_config_component_list],\n                        [m4_ifval(mca_component, [mca_component ]OPAL_EVAL_ARG([MCA_]$1[_]$2[_]mca_component[_PRIORITY ]))]))])\n])\n\nAC_DEFUN([MCA_CHECK_IGNORED_PRIORITY], [\n    m4_foreach(mca_component, [mca_$1_$2_m4_config_component_list],\n               [m4_ifval(mca_component,\n                    [m4_ifdef([MCA_]$1[_]$2[_]mca_component[_PRIORITY],\n                         [m4_warn([unsupported], [MCA_]$1[_]$2[_]mca_component[_PRIORITY found, but ignored.])])])])\n])\n\n\n######################################################################\n#\n# MCA_CONFIGURE_FRAMEWORK\n#\n# Configure the given framework and all components inside the\n# framework.  Assumes that the framework is located in\n# [project_name]/mca/[framework], and that all components are\n# available under the framework directory.  Will configure all\n# no-configure and builtin components, then search for components with\n# configure scripts.  Assumes that no component is marked as builtin\n# AND has a configure script.\n#\n# USAGE:\n#   MCA_CONFIGURE_PROJECT(project_name, framework_name, allow_succeed)\n#\n######################################################################\nAC_DEFUN([MCA_CONFIGURE_FRAMEWORK],[\n    opal_show_subsubtitle \"Configuring MCA framework $2\"\n\n    m4_ifdef([mca_$1_$2_no_config_component_list], [],\n             [m4_fatal([Could not find mca_$1_$2_no_config_component_list - please rerun autogen.pl])])\n    m4_ifdef([mca_$1_$2_m4_config_component_list], [],\n             [m4_fatal([Could not find mca_$1_$2_m4_config_component_list - please rerun autogen.pl])])\n\n    # setup for framework\n    all_components=\n    static_components=\n    dso_components=\n    static_ltlibs=\n\n    # Ensure that the directory where the #include file is to live\n    # exists.  Need to do this for VPATH builds, because the directory\n    # may not exist yet.  For the \"common\" type, it's not really a\n    # component, so it doesn't have a base.\n    m4_if([$2], [common], [outdir=$1/mca/common], [outdir=$1/mca/$2/base])\n    AS_MKDIR_P([$outdir])\n\n    # emit Makefile rule\n    AC_CONFIG_FILES([$1/mca/$2/Makefile])\n\n    # remove any previously generated #include files\n    outfile_real=$outdir/static-components.h\n    outfile=$outfile_real.new\n    rm -f $outfile $outfile.struct $outfile.extern\n    touch $outfile.struct $outfile.extern\n\n    # print some nice messages about what we're about to do...\n    AC_MSG_CHECKING([for no configure components in framework $2])\n    AC_MSG_RESULT([mca_$1_$2_no_config_component_list])\n    AC_MSG_CHECKING([for m4 configure components in framework $2])\n    AC_MSG_RESULT([mca_$1_$2_m4_config_component_list])\n\n    # If there are components in the no configure list, but we're\n    # doing one of the \"special\" selection logics, abort with a\n    # reasonable message.\n    m4_if(OPAL_EVAL_ARG([MCA_$1_$2_CONFIGURE_MODE]), [STOP_AT_FIRST],\n          [m4_ifval(mca_$1_$2_no_config_component_list,\n                   [m4_fatal([Framework $2 using STOP_AT_FIRST but at least one component has no configure.m4])])])\n    m4_if(OPAL_EVAL_ARG([MCA_$1_$2_CONFIGURE_MODE]), [STOP_AT_FIRST_PRIORITY],\n          [m4_ifval(mca_$1_$2_no_config_component_list,\n                   [m4_fatal([Framework $2 using STOP_AT_FIRST_PRIORITY but at least one component has no configure.m4])])])\n    m4_if(OPAL_EVAL_ARG([MCA_$1_$2_CONFIGURE_MODE]), [PRIORITY],\n          [m4_ifval(mca_$1_$2_no_config_component_list,\n                   [m4_fatal([Framework $2 using PRIORITY but at least one component has no configure.m4])])])\n    # run the configure logic for the no-config components\n    m4_foreach(mca_component, [mca_$1_$2_no_config_component_list],\n               [m4_ifval(mca_component,\n                  [MCA_CONFIGURE_NO_CONFIG_COMPONENT($1, $2, mca_component,\n                                                     [all_components],\n                                                     [static_components],\n                                                     [dso_components],\n                                                     [static_ltlibs],\n                                                     [$3])])])\n\n    # configure components that use built-in configuration scripts\n    m4_ifdef([component_list], [m4_undefine([component_list])])\n    m4_if(OPAL_EVAL_ARG([MCA_$1_$2_CONFIGURE_MODE]), [STOP_AT_FIRST], [MCA_ORDER_COMPONENT_LIST($1, $2)],\n          [m4_if(OPAL_EVAL_ARG([MCA_$1_$2_CONFIGURE_MODE]), [STOP_AT_FIRST_PRIORITY], [MCA_ORDER_COMPONENT_LIST($1, $2)],\n                [m4_if(OPAL_EVAL_ARG([MCA_$1_$2_CONFIGURE_MODE]), [PRIORITY], [MCA_ORDER_COMPONENT_LIST($1, $2)],\n                       [m4_define([component_list], [mca_$1_$2_m4_config_component_list])])])])\n\n    best_mca_component_priority=0\n    components_looking_for_succeed=$3\n    components_last_result=0\n    m4_foreach(mca_component, [component_list],\n               [m4_ifval(mca_component,\n                  [m4_if(OPAL_EVAL_ARG([MCA_$1_$2_CONFIGURE_MODE]), [STOP_AT_FIRST_PRIORITY],\n                         [AS_IF([test $best_mca_component_priority -gt MCA_$1_$2_]mca_component[_PRIORITY], [components_looking_for_succeed=0])])\n                   MCA_CONFIGURE_M4_CONFIG_COMPONENT($1, $2, mca_component,\n                                                     [all_components],\n                                                     [static_components],\n                                                     [dso_components],\n                                                     [static_ltlibs],\n                                                     [$components_looking_for_succeed],\n                                                     [components_last_result=1],\n                                                     [components_last_result=0])\n                   m4_if(OPAL_EVAL_ARG([MCA_$1_$2_CONFIGURE_MODE]), [STOP_AT_FIRST],\n                         [AS_IF([test $components_last_result -eq 1], [components_looking_for_succeed=0])])\n                   m4_if(OPAL_EVAL_ARG([MCA_$1_$2_CONFIGURE_MODE]), [STOP_AT_FIRST_PRIORITY],\n                         [AS_IF([test $components_last_result -eq 1], [best_mca_component_priority=]OPAL_EVAL_ARG([MCA_$1_$2_]mca_component[_PRIORITY]))])\n                   ])])\n\n    # configure components that provide their own configure script.\n    # It would be really hard to run these for \"find first that\n    # works\", so we don't :)\n    m4_if(OPAL_EVAL_ARG([MCA_$1_]$2[_CONFIGURE_MODE]), [STOP_AT_FIRST], [],\n        [m4_if(OPAL_EVAL_ARG([MCA_$1_]$2[_CONFIGURE_MODE]), [STOP_AT_FIRST_PRIORITY], [],\n             [m4_if(OPAL_EVAL_ARG([MCA_$1_]$2[_CONFIGURE_MODE]), [PRIORITY], [],\n                 [MCA_CHECK_IGNORED_PRIORITY($1, $2)\n                  AS_IF([test \"$3\" != \"0\"],\n                        [MCA_CONFIGURE_ALL_CONFIG_COMPONENTS($1, $2, [all_components],\n                                               [static_components], [dso_components],\n                                               [static_ltlibs])])])])])\n\n    MCA_$1_$2_ALL_COMPONENTS=\"$all_components\"\n    MCA_$1_$2_STATIC_COMPONENTS=\"$static_components\"\n    MCA_$1_$2_DSO_COMPONENTS=\"$dso_components\"\n    MCA_$1_$2_STATIC_LTLIBS=\"$static_ltlibs\"\n\n    AC_SUBST(MCA_$1_$2_ALL_COMPONENTS)\n    AC_SUBST(MCA_$1_$2_STATIC_COMPONENTS)\n    AC_SUBST(MCA_$1_$2_DSO_COMPONENTS)\n    AC_SUBST(MCA_$1_$2_STATIC_LTLIBS)\n\n    OPAL_MCA_MAKE_DIR_LIST(MCA_$1_$2_ALL_SUBDIRS, $2, [$all_components])\n    OPAL_MCA_MAKE_DIR_LIST(MCA_$1_$2_STATIC_SUBDIRS, $2, [$static_components])\n    OPAL_MCA_MAKE_DIR_LIST(MCA_$1_$2_DSO_SUBDIRS, $2, [$dso_components])\n\n    # Create the final .h file that will be included in the type's\n    # top-level glue.  This lists all the static components.  We don't\n    # need to do this for \"common\".\n    if test \"$2\" != \"common\"; then\n        cat > $outfile <<EOF\n/*\n * \\$HEADER\\$\n */\n#if defined(c_plusplus) || defined(__cplusplus)\nextern \"C\" {\n#endif\n\n`cat $outfile.extern`\n\nconst mca_base_component_t *mca_$2_base_static_components[[]] = {\n`cat $outfile.struct`\n  NULL\n};\n\n#if defined(c_plusplus) || defined(__cplusplus)\n}\n#endif\n\nEOF\n        # Only replace the header file if a) it doesn't previously\n        # exist, or b) the contents are different.  Do this to not\n        # trigger recompilation of certain .c files just because the\n        # timestamp changed on $outfile_real (similar to the way AC\n        # handles AC_CONFIG_HEADER files).\n        diff $outfile $outfile_real > /dev/null 2>&1\n        if test \"$?\" != \"0\"; then\n            mv $outfile $outfile_real\n        else\n            rm -f $outfile\n        fi\n    fi\n    rm -f $outfile.struct $outfile.extern\n\n    unset all_components static_components dso_components outfile outfile_real\n])\n\n\n######################################################################\n#\n# MCA_CONFIGURE_NO_CONFIG_COMPONENT\n#\n# Configure the given framework and all components inside the framework.\n# Assumes that the framework is located in [project_name]/mca/[framework],\n# and that all components are available under the framework directory.\n# Will configure all builtin components, then search for components with\n# configure scripts.  Assumes that no component is marked as builtin\n# AND has a configure script.\n#\n# USAGE:\n#   MCA_CONFIGURE_PROJECT(project_name, framework_name, component_name\n#                         all_components_variable,\n#                         static_components_variable,\n#                         dso_components_variable,\n#                         static_ltlibs_variable,\n#                         allowed_to_succeed)\n#\n######################################################################\nAC_DEFUN([MCA_CONFIGURE_NO_CONFIG_COMPONENT],[\n    opal_show_subsubsubtitle \"MCA component $2:$3 (no configuration)\"\n\n    opal_show_verbose \"OPAL_MCA_NO_CONFIG_COMPONENT: before, should_build=$8\"\n    MCA_COMPONENT_BUILD_CHECK($1, $2, $3,\n                              [should_build=$8], [should_build=0])\n    MCA_COMPONENT_COMPILE_MODE($1, $2, $3, compile_mode)\n    opal_show_verbose \"OPAL_MCA_NO_CONFIG_COMPONENT: after, should_build=$should_build\"\n\n    if test \"$should_build\" = \"1\" ; then\n        MCA_PROCESS_COMPONENT($1, $2, $3, $4, $5, $6, $7, $compile_mode)\n    else\n        MCA_PROCESS_DEAD_COMPONENT($1, $2, $3)\n        # add component to all component list\n        $4=\"$$4 $3\"\n    fi\n\n    # set the AM_CONDITIONAL on how we should build\n    if test \"$compile_mode\" = \"dso\" ; then\n        BUILD_$1_$2_$3_DSO=1\n    else\n        BUILD_$1_$2_$3_DSO=0\n    fi\n    AM_CONDITIONAL(MCA_BUILD_$1_$2_$3_DSO, test \"$BUILD_$1_$2_$3_DSO\" = \"1\")\n\n    AC_CONFIG_FILES([$1/mca/$2/$3/Makefile])\n\n    unset compile_mode\n])\n\n\n######################################################################\n#\n# MCA_CONFIGURE_M4_CONFIG_COMPONENT\n#\n#\n# USAGE:\n#   MCA_CONFIGURE_PROJECT(project_name, framework_name, component_name\n#                         all_components_variable,\n#                         static_components_variable,\n#                         dso_components_variable,\n#                         static_ltlibs_variable,\n#                         allowed_to_succeed,\n#                         [eval if should build],\n#                         [eval if should not build])\n#\n######################################################################\nAC_DEFUN([MCA_CONFIGURE_M4_CONFIG_COMPONENT],[\n    m4_ifdef([MCA_$1_$2_$3_PRIORITY],\n        [opal_show_subsubsubtitle \"MCA component $2:$3 (m4 configuration macro, priority MCA_$1_$2_$3_PRIORITY)\"],\n        [opal_show_subsubsubtitle \"MCA component $2:$3 (m4 configuration macro)\"])\n\n    opal_show_verbose \"OPAL_MCA_M4_CONFIG_COMPONENT: before, should_build=$8\"\n    MCA_COMPONENT_BUILD_CHECK($1, $2, $3, [should_build=$8], [should_build=0])\n    # Allow the component to override the build mode if it really wants to.\n    # It is, of course, free to end up calling MCA_COMPONENT_COMPILE_MODE\n    m4_ifdef([MCA_$1_$2_$3_COMPILE_MODE],\n             [MCA_$1_$2_$3_COMPILE_MODE($1, $2, $3, compile_mode)],\n             [MCA_COMPONENT_COMPILE_MODE($1, $2, $3, compile_mode)])\n\n    # try to configure the component\n    m4_ifdef([MCA_$1_$2_$3_CONFIG],\n             [MCA_$1_$2_$3_CONFIG([should_build=$should_build],\n                                  [should_build=0])],\n             [m4_fatal([MCA_$1_$2_$3_CONFIG macro not found])])\n    opal_show_verbose \"OPAL_MCA_M4_CONFIG_COMPONENT: after, should_build=$should_build\"\n\n    AS_IF([test \"$should_build\" = \"1\"],\n          [MCA_PROCESS_COMPONENT($1, $2, $3, $4, $5, $6, $7, $compile_mode)],\n          [MCA_PROCESS_DEAD_COMPONENT($1, $2, $3)\n           # add component to all component list\n           $4=\"$$4 $3\"])\n\n    m4_ifdef([MCA_$1_$2_$3_POST_CONFIG],\n             [ MCA_$1_$2_$3_POST_CONFIG($should_build)])\n\n    # set the AM_CONDITIONAL on how we should build\n    AS_IF([test \"$compile_mode\" = \"dso\"],\n          [BUILD_$1_$2_$3_DSO=1],\n          [BUILD_$1_$2_$3_DSO=0])\n    AM_CONDITIONAL(MCA_BUILD_$1_$2_$3_DSO, test \"$BUILD_$1_$2_$3_DSO\" = \"1\")\n\n    AS_IF([test \"$should_build\" = \"1\"], [$9], [$10])\n\n    unset compile_mode\n])\n\n\n######################################################################\n#\n# MCA_CONFIGURE_ALL_CONFIG_COMPONENTS\n#\n# configure all components in the given framework that have configure\n# scripts and should be configured according to the usual rules...\n#\n# USAGE:\n#   MCA_CONFIGURE_ALL_CONFIG_COMPONENTS(project_name,\n#                         framework_name,\n#                         all_components_variable,\n#                         static_components_variable,\n#                         dso_components_variable,\n#                         static_ltlibs_variable)\n#\n######################################################################\nAC_DEFUN([MCA_CONFIGURE_ALL_CONFIG_COMPONENTS],[\n    for component_path in $srcdir/$1/mca/$2/* ; do\n        component=\"`basename $component_path`\"\n        if test -d $component_path && test -x $component_path/configure ; then\n            opal_show_subsubsubtitle \"MCA component $2:$component (need to configure)\"\n\n            opal_show_verbose \"OPAL_MCA_ALL_CONFIG_COMPONENTS: before, should_build=$8\"\n            MCA_COMPONENT_BUILD_CHECK($1, $2, $component,\n                                      [should_build=1], [should_build=0])\n            MCA_COMPONENT_COMPILE_MODE($1, $2, $component, compile_mode)\n            opal_show_verbose \"OPAL_MCA_ALL_CONFIG_COMPONENTS: after, should_build=$should_build\"\n\n            if test \"$should_build\" = \"1\" ; then\n                OPAL_CONFIG_SUBDIR([$1/mca/$2/$component],\n                                   [$opal_subdir_args],\n                                   [should_build=1], [should_build=0])\n                opal_show_verbose \"OPAL_MCA_ALL_CONFIG_COMPONENTS: after subdir, should_build=$should_build\"\n            fi\n\n            if test \"$should_build\" = \"1\" ; then\n                # do some extra work to pass flags back from the\n                # top-level configure, the way a configure.m4\n                # component would.\n                infile=\"$srcdir/$1/mca/$2/$3/post_configure.sh\"\n                if test -f $infile; then\n\n                    # First check for the ABORT tag\n                    line=\"`$GREP ABORT= $infile | cut -d= -f2-`\"\n                    if test -n \"$line\" && test \"$line\" != \"no\"; then\n                        AC_MSG_WARN([MCA component configure script told me to abort])\n                        AC_MSG_ERROR([cannot continue])\n                    fi\n\n                    m4_foreach(flags, [LDFLAGS, LIBS],\n                        [[line=\"`$GREP WRAPPER_EXTRA_]flags[= $infile | cut -d= -f2-`\"]\n                            eval \"line=$line\"\n                            if test -n \"$line\"; then\n                                $2[_]$3[_WRAPPER_EXTRA_]flags[=\"$line\"]\n                            fi\n                        ])dnl\n                fi\n\n                MCA_PROCESS_COMPONENT($1, $2, $component, $3, $4, $5, $6, $compile_mode)\n            else\n                MCA_PROCESS_DEAD_COMPONENT($1, $2, $component)\n            fi\n        fi\n    done\n])\n\n\n# MCA_COMPONENT_COMPILE_MODE(project_name (1), framework_name (2),\n#                            component_name (3), compile_mode_variable (4))\n# -------------------------------------------------------------------------\n# set compile_mode_variable to the compile mode for the given component\n#\n#   NOTE: component_name may not be determined until runtime....\nAC_DEFUN([MCA_COMPONENT_COMPILE_MODE],[\n    SHARED_FRAMEWORK=\"$DSO_$2\"\n    AS_LITERAL_IF([$3],\n        [SHARED_COMPONENT=\"$DSO_$2_$3\"],\n        [str=\"SHARED_COMPONENT=\\$DSO_$2_$3\"\n         eval $str])\n\n    STATIC_FRAMEWORK=\"$STATIC_$2\"\n    AS_LITERAL_IF([$3],\n        [STATIC_COMPONENT=\"$STATIC_$2_$3\"],\n        [str=\"STATIC_COMPONENT=\\$STATIC_$2_$3\"\n         eval $str])\n\n    shared_mode_override=static\n\n    # Setup for either shared or static\n    if test \"$STATIC_FRAMEWORK\" = \"1\" || \\\n       test \"$STATIC_COMPONENT\" = \"1\" || \\\n       test \"$STATIC_all\" = \"1\" ; then\n        $4=\"static\"\n    elif test \"$shared_mode_override\" = \"dso\" || \\\n         test \"$SHARED_FRAMEWORK\" = \"1\" || \\\n         test \"$SHARED_COMPONENT\" = \"1\" || \\\n         test \"$DSO_all\" = \"1\"; then\n        $4=\"dso\"\n    else\n        $4=\"static\"\n    fi\n\n    AC_MSG_CHECKING([for MCA component $2:$3 compile mode])\n    if test \"$DIRECT_$2\" = \"$3\" ; then\n        AC_MSG_RESULT([$$4 - direct])\n    else\n        AC_MSG_RESULT([$$4])\n    fi\n])\n\n\n# MCA_PROCESS_COMPONENT(project_name(1), framework_name (2), component_name (3),\n#                        all_components_variable (4), static_components_variable (5)\n#                        dso_components_variable (6), static_ltlibs_variable (7),\n#                        compile_mode_variable (8))\n#---------------------------------------------------------------------\n# Final setup work for a given component.  It should be known before\n# calling that this component can build properly (and exists)\n#\n#   NOTE: component_name may not be determined until runtime....\nAC_DEFUN([MCA_PROCESS_COMPONENT],[\n    AC_REQUIRE([AC_PROG_GREP])\n\n    # See if it dropped an output file for us to pick up some\n    # shell variables in.\n    infile=\"$srcdir/$1/mca/$2/$3/post_configure.sh\"\n\n    # Add this subdir to the mast list of all MCA component subdirs\n    $4=\"$$4 $3\"\n\n    if test \"$8\" = \"dso\" ; then\n        $6=\"$$6 $3\"\n    else\n        if test \"$2\" = \"common\"; then\n            # Static libraries in \"common\" frameworks are installed, and\n            # therefore must obey the $FRAMEWORK_LIB_PREFIX that was\n            # set.\n            $7=\"mca/$2/$3/lib${m4_translit([$1], [a-z], [A-Z])_LIB_PREFIX}mca_$2_$3.la $$7\"\n        else\n            # Other frameworks do not have to obey the\n            # $FRAMEWORK_LIB_PREFIX prefix.\n            $7=\"mca/$2/$3/libmca_$2_$3.la $$7\"\n        fi\n        echo \"extern const mca_base_component_t mca_$2_$3_component;\" >> $outfile.extern\n        echo \"  &mca_$2_$3_component, \" >> $outfile.struct\n        $5=\"$$5 $3\"\n    fi\n\n    # Output pretty results\n    AC_MSG_CHECKING([if MCA component $2:$3 can compile])\n    AC_MSG_RESULT([yes])\n\n    dnl BWB: FIX ME: We still use the post_configure.sh for frameworks that use the direct call infrastructure.\n    dnl All other uses we can ignore here, because config_components will have read it in and set all the\n    dnl proper environment variables.  At some point, we should handle the direct call stuff the same way we\n    dnl handle the headers for static components like timers in opal, ie, have a framework level configure.m4 that\n    dnl does the right thing\n    if test -f $infile; then\n        # check for direct call header to include.  This will be\n        # AC_SUBSTed later.\n        if test \"$DIRECT_$2\" = \"$3\" ; then\n            if test \"`$GREP DIRECT_CALL_HEADER $infile`\" != \"\" ; then\n                line=\"`$GREP DIRECT_CALL_HEADER $infile | cut -d= -f2-`\"\n                str=\"MCA_$1_$2_DIRECT_CALL_HEADER=$line\"\n                eval $str\n            else\nAC_MSG_ERROR([*** $2 component $3 was supposed to be direct-called, but\n*** does not appear to support direct calling.\n*** Aborting])\n            fi\n        fi\n    else\n        # were we supposed to have found something in the\n        # post_configure.sh, but the file didn't exist?\n        if test \"$DIRECT_$2\" = \"$3\" ; then\nAC_MSG_ERROR([*** $2 component $3 was supposed to be direct-called, but\n*** does not appear to support direct calling.\n*** Aborting])\n        fi\n    fi\n\n    # if the component is building, add it's WRAPPER_EXTRA_LDFLAGS and\n    # WRAPPER_EXTRA_LIBS.  If the component doesn't specify it's\n    # WRAPPER_EXTRA_LIBS and WRAPPER_EXTRA_LDFLAGS, try using LDFLAGS and LIBS if\n    # component didn't have it's own configure script (in which case,\n    # we know it didn't set LDFLAGS and LIBS because it can't) Don't\n    # have to do this if the component is building dynamically,\n    # because it will link against these (without a dependency from\n    # libmpi.so to these flags)\n    if test \"$8\" = \"static\"; then\n        AS_LITERAL_IF([$3],\n            [m4_foreach(flags, [LDFLAGS, LIBS],\n                    [AS_IF([test \"$$2_$3_WRAPPER_EXTRA_]flags[\" = \"\"],\n                           [OPAL_FLAGS_APPEND_UNIQ([mca_wrapper_extra_]m4_tolower(flags), [$$2_$3_]flags)],\n                           [OPAL_FLAGS_APPEND_UNIQ([mca_wrapper_extra_]m4_tolower(flags), [$$2_$3_WRAPPER_EXTRA_]flags)])\n                        ])],\n            [m4_foreach(flags, [LDFLAGS, LIBS],\n                    [[str=\"line=\\$$2_$3_WRAPPER_EXTRA_]flags[\"]\n                      eval \"$str\"\n                      OPAL_FLAGS_APPEND_UNIQ([mca_wrapper_extra_]m4_tolower(flags), [$line])])])\n    fi\n\n    # if needed, copy over WRAPPER_EXTRA_CPPFLAGS.  Since a configure script\n    # component can never be used in a STOP_AT_FIRST framework, we\n    # don't have to implement the else clause in the literal check...\n    AS_LITERAL_IF([$3],\n        [AS_IF([test \"$$2_$3_WRAPPER_EXTRA_CPPFLAGS\" != \"\"],\n           [m4_if(OPAL_EVAL_ARG([MCA_$1_$2_CONFIGURE_MODE]), [STOP_AT_FIRST], [stop_at_first=1], [stop_at_first=0])\n            AS_IF([test \"$8\" = \"static\" && test \"$stop_at_first\" = \"1\"],\n              [AS_IF([test \"$with_devel_headers\" = \"yes\"],\n                     [OPAL_FLAGS_APPEND_UNIQ([mca_wrapper_extra_cppflags], [$$2_$3_WRAPPER_EXTRA_CPPFLAGS])])],\n              [AC_MSG_WARN([ignoring $2_$3_WRAPPER_EXTRA_CPPFLAGS ($$2_$3_WRAPPER_EXTRA_CPPFLAGS): component conditions not met])])])])\n])\n\n\n# MCA_PROCESS_DEAD_COMPONENT(project_name (1), framework_name (2),\n#                            component_name (3))\n# ----------------------------------------------------------------\n# Finall setup work for a component that can not be built.  Do the\n# last minute checks to make sure the user isn't doing something\n# stupid.\n#\n#   NOTE: component_name may not be determined until runtime....\nAC_DEFUN([MCA_PROCESS_DEAD_COMPONENT],[\n    AC_MSG_CHECKING([if MCA component $2:$3 can compile])\n    AC_MSG_RESULT([no])\n\n    # If this component was requested as the default for this\n    # type, then abort.\n    if test \"$with_$2\" = \"$3\" ; then\n        AC_MSG_WARN([MCA component \"$3\" failed to configure properly])\n        AC_MSG_WARN([This component was selected as the default])\n        AC_MSG_ERROR([Cannot continue])\n    fi\n\n    if test ! -z \"$DIRECT_$2\" ; then\n        if test \"$DIRECT_$2\" = \"$3\" ; then\n            AC_MSG_WARN([MCA component \"$3\" failed to configure properly])\n            AC_MSG_WARN([This component was selected as the default (direct call)])\n            AC_MSG_ERROR([Cannot continue])\n        fi\n    fi\n])\n\n\n# MCA_COMPONENT_BUILD_CHECK(project_name (1), framework_name(2),\n#                           component_name (3), action-if-build (4)\n#                           action-if-not-build (5)\n# -----------------------------------------------------------------\n# checks the standard rules of component building to see if the\n# given component should be built.\n#\n# Note: component_name may not be determined until runtime....\nAC_DEFUN([MCA_COMPONENT_BUILD_CHECK],[\n    AC_REQUIRE([AC_PROG_GREP])\n\n    component_path=\"$srcdir/$1/mca/$2/$3\"\n    want_component=0\n\n    # build if:\n    # - the component type is direct and we are that component\n    # - there is no opal_ignore file\n    # - there is an opal_ignore, but there is an empty opal_unignore\n    # - there is an opal_ignore, but username is in opal_unignore\n    if test -d $component_path ; then\n        # decide if we want the component to be built or not.  This\n        # is spread out because some of the logic is a little complex\n        # and test's syntax isn't exactly the greatest.  We want to\n        # build the component by default.\n        want_component=1\n        if test -f $component_path/.opal_ignore ; then\n            # If there is an opal_ignore file, don't build\n            # the component.  Note that this decision can be\n            # overridden by the unignore logic below.\n            want_component=0\n        fi\n        if test -f $component_path/.opal_unignore ; then\n            # if there is an empty opal_unignore, that is\n            # equivalent to having your userid in the unignore file.\n            # If userid is in the file, unignore the ignore file.\n            if test ! -s $component_path/.opal_unignore ; then\n                want_component=1\n            elif test ! -z \"`$GREP $OPAL_CONFIGURE_USER $component_path/.opal_unignore`\" ; then\n                want_component=1\n            fi\n        fi\n        # if this component type is direct and we are not it, we don't want\n        # to be built.  Otherwise, we do want to be built.\n        if test ! -z \"$DIRECT_$2\" ; then\n            if test \"$DIRECT_$2\" = \"$3\" ; then\n                want_component=1\n            else\n                want_component=0\n            fi\n        fi\n    fi\n\n    # if we were explicitly disabled, don't build :)\n    AS_IF([test \"$DISABLE_$2\" = \"1\"], [want_component=0])\n    AS_LITERAL_IF([$3],\n        [AS_IF([test \"$DISABLE_$2_$3\" = \"1\"], [want_component=0])],\n        [str=\"DISABLED_COMPONENT_CHECK=\\$DISABLE_$2_$3\"\n         eval $str\n         if test \"$DISABLED_COMPONENT_CHECK\" = \"1\" ; then\n             want_component=0\n         fi])\n\n    AS_IF([test \"$want_component\" = \"1\"], [$4], [$5])\n])\n\n\n# MCA_SETUP_DIRECT_CALL(project_name (1), framework_name  (2))\n# -------------------------------------------------------------\nAC_DEFUN([MCA_SETUP_DIRECT_CALL],[\n    if test ! -z \"$DIRECT_$2\" ; then\n        MCA_$1_$2_DIRECT_CALL_COMPONENT=$DIRECT_$2\n        MCA_$1_$2_DIRECT_CALL=1\n    else\n        MCA_$1_$2_DIRECT_CALL_COMPONENT=\n        MCA_$1_$2_DIRECT_CALL=0\n    fi\n\n    AC_SUBST(MCA_$1_$2_DIRECT_CALL_HEADER)\n    AC_DEFINE_UNQUOTED([MCA_$1_$2_DIRECT_CALL], [$MCA_$1_$2_DIRECT_CALL],\n            [Defined to 1 if $1:$2 should use direct calls instead of components])\n    AC_DEFINE_UNQUOTED([MCA_$1_$2_DIRECT_CALL_COMPONENT], [$MCA_$1_$2_DIRECT_CALL_COMPONENT],\n            [name of component to use for direct calls, if MCA_$1_$2_DIRECT_CALL is 1])\n    AC_DEFINE_UNQUOTED([MCA_$1_$2_DIRECT_CALL_HEADER],\n                       [\"[$MCA_]$1[_]$2[_DIRECT_CALL_HEADER]\"],\n                       [Header $1:$2 includes to be direct called])\n])\n\n\n# OPAL_MCA_MAKE_DIR_LIST(subst'ed variable, framework, shell list)\n# -------------------------------------------------------------------------\nAC_DEFUN([OPAL_MCA_MAKE_DIR_LIST],[\n    $1=\n    for item in $3 ; do\n       $1=\"$$1 mca/$2/$item\"\n    done\n    AC_SUBST($1)\n])\n",
        "/tmp/vanessa/spack-stage/spack-stage-openmpi-master-qcrm7qmgqutvsby2zcmdb57s22lzfq65/spack-src/config/opal_check_cuda.m4": "dnl -*- shell-script -*-\ndnl\ndnl Copyright (c) 2004-2010 The Trustees of Indiana University and Indiana\ndnl                         University Research and Technology\ndnl                         Corporation.  All rights reserved.\ndnl Copyright (c) 2004-2005 The University of Tennessee and The University\ndnl                         of Tennessee Research Foundation.  All rights\ndnl                         reserved.\ndnl Copyright (c) 2004-2005 High Performance Computing Center Stuttgart,\ndnl                         University of Stuttgart.  All rights reserved.\ndnl Copyright (c) 2004-2005 The Regents of the University of California.\ndnl                         All rights reserved.\ndnl Copyright (c) 2006-2016 Cisco Systems, Inc.  All rights reserved.\ndnl Copyright (c) 2007      Sun Microsystems, Inc.  All rights reserved.\ndnl Copyright (c) 2009      IBM Corporation.  All rights reserved.\ndnl Copyright (c) 2009      Los Alamos National Security, LLC.  All rights\ndnl                         reserved.\ndnl Copyright (c) 2009-2011 Oak Ridge National Labs.  All rights reserved.\ndnl Copyright (c) 2011-2015 NVIDIA Corporation.  All rights reserved.\ndnl Copyright (c) 2015      Research Organization for Information Science\ndnl                         and Technology (RIST). All rights reserved.\ndnl\ndnl $COPYRIGHT$\ndnl\ndnl Additional copyrights may follow\ndnl\ndnl $HEADER$\ndnl\n\nAC_DEFUN([OPAL_CHECK_CUDA],[\n#\n# Check to see if user wants CUDA support\n#\nAC_ARG_WITH([cuda],\n            [AC_HELP_STRING([--with-cuda(=DIR)],\n            [Build cuda support, optionally adding DIR/include])])\nAC_MSG_CHECKING([if --with-cuda is set])\n\n# Note that CUDA support is off by default.  To turn it on, the user has to\n# request it.  The user can just ask for --with-cuda and it that case we\n# look for the cuda.h file in /usr/local/cuda.  Otherwise, they can give\n# us a directory.  If they provide a directory, we will look in that directory\n# as well as the directory with the \"include\" string appended to it.  The fact\n# that we check in two directories precludes us from using the OMPI_CHECK_DIR\n# macro as that would error out after not finding it in the first directory.\n# Note that anywhere CUDA aware code is in the Open MPI repository requires\n# us to make use of AC_REQUIRE to ensure this check has been done.\nAS_IF([test \"$with_cuda\" = \"no\" || test \"x$with_cuda\" = \"x\"],\n      [opal_check_cuda_happy=\"no\"\n       AC_MSG_RESULT([not set (--with-cuda=$with_cuda)])],\n      [AS_IF([test \"$with_cuda\" = \"yes\"],\n             [AS_IF([test \"x`ls /usr/local/cuda/include/cuda.h 2> /dev/null`\" = \"x\"],\n                    [AC_MSG_RESULT([not found in standard location])\n                     AC_MSG_WARN([Expected file /usr/local/cuda/include/cuda.h not found])\n                     AC_MSG_ERROR([Cannot continue])],\n                    [AC_MSG_RESULT([found])\n                     opal_check_cuda_happy=yes\n                     opal_cuda_incdir=/usr/local/cuda/include])],\n             [AS_IF([test ! -d \"$with_cuda\"],\n                    [AC_MSG_RESULT([not found])\n                     AC_MSG_WARN([Directory $with_cuda not found])\n                     AC_MSG_ERROR([Cannot continue])],\n                    [AS_IF([test \"x`ls $with_cuda/include/cuda.h 2> /dev/null`\" = \"x\"],\n                           [AS_IF([test \"x`ls $with_cuda/cuda.h 2> /dev/null`\" = \"x\"],\n                                  [AC_MSG_RESULT([not found])\n                                   AC_MSG_WARN([Could not find cuda.h in $with_cuda/include or $with_cuda])\n                                   AC_MSG_ERROR([Cannot continue])],\n                                  [opal_check_cuda_happy=yes\n                                   opal_cuda_incdir=$with_cuda\n                                   AC_MSG_RESULT([found ($with_cuda/cuda.h)])])],\n                           [opal_check_cuda_happy=yes\n                            opal_cuda_incdir=\"$with_cuda/include\"\n                            AC_MSG_RESULT([found ($opal_cuda_incdir/cuda.h)])])])])])\n\ndnl We cannot have CUDA support without dlopen support.  HOWEVER, at\ndnl this point in configure, we can't know whether the DL framework\ndnl has been configured or not yet (it likely hasn't, since CUDA is a\ndnl common framework, and likely configured first).  So we have to\ndnl defer this check until later (see the OPAL_CHECK_CUDA_AFTER_OPAL_DL m4\ndnl macro, below).  :-(\n\n# We require CUDA IPC support which started in CUDA 4.1. Error\n# out if the support is not there.\nAS_IF([test \"$opal_check_cuda_happy\" = \"yes\"],\n    [AC_CHECK_MEMBER([struct CUipcMemHandle_st.reserved],\n        [],\n        [AC_MSG_ERROR([Cannot continue because CUDA 4.1 or later is required])],\n        [#include <$opal_cuda_incdir/cuda.h>])],\n    [])\n\n# If we have CUDA support, check to see if we have support for SYNC_MEMOPS\n# which was first introduced in CUDA 6.0.\nAS_IF([test \"$opal_check_cuda_happy\"=\"yes\"],\n    [AC_CHECK_DECL([CU_POINTER_ATTRIBUTE_SYNC_MEMOPS], [CUDA_SYNC_MEMOPS=1], [CUDA_SYNC_MEMOPS=0],\n        [#include <$opal_cuda_incdir/cuda.h>])],\n    [])\n\n# If we have CUDA support, check to see if we have CUDA 6.0 or later.\nAC_COMPILE_IFELSE(\n    [AC_LANG_PROGRAM([[#include <$opal_cuda_incdir/cuda.h>]],\n        [[\n#if CUDA_VERSION < 6000\n#error \"CUDA_VERSION is less than 6000\"\n#endif\n        ]])],\n        [CUDA_VERSION_60_OR_GREATER=1],\n        [CUDA_VERSION_60_OR_GREATER=0])\n\n# If we have CUDA support, check to see if we have support for cuPointerGetAttributes\n# which was first introduced in CUDA 7.0.\nAS_IF([test \"$opal_check_cuda_happy\"=\"yes\"],\n    AC_CHECK_DECL([cuPointerGetAttributes], [CUDA_GET_ATTRIBUTES=1], [CUDA_GET_ATTRIBUTES=0],\n        [#include <$opal_cuda_incdir/cuda.h>]),\n    [])\n\nAC_MSG_CHECKING([if have cuda support])\nif test \"$opal_check_cuda_happy\" = \"yes\"; then\n    AC_MSG_RESULT([yes (-I$opal_cuda_incdir)])\n    CUDA_SUPPORT=1\n    opal_datatype_cuda_CPPFLAGS=\"-I$opal_cuda_incdir\"\n    AC_SUBST([opal_datatype_cuda_CPPFLAGS])\nelse\n    AC_MSG_RESULT([no])\n    CUDA_SUPPORT=0\nfi\n\nOPAL_SUMMARY_ADD([[Miscellaneous]],[[CUDA support]],[opal_cuda], [$opal_check_cuda_happy])\n\nAM_CONDITIONAL([OPAL_cuda_support], [test \"x$CUDA_SUPPORT\" = \"x1\"])\nAC_DEFINE_UNQUOTED([OPAL_CUDA_SUPPORT],$CUDA_SUPPORT,\n                   [Whether we want cuda device pointer support])\n\nAM_CONDITIONAL([OPAL_cuda_sync_memops], [test \"x$CUDA_SYNC_MEMOPS\" = \"x1\"])\nAC_DEFINE_UNQUOTED([OPAL_CUDA_SYNC_MEMOPS],$CUDA_SYNC_MEMOPS,\n                   [Whether we have CUDA CU_POINTER_ATTRIBUTE_SYNC_MEMOPS support available])\n\nAM_CONDITIONAL([OPAL_cuda_get_attributes], [test \"x$CUDA_GET_ATTRIBUTES\" = \"x1\"])\nAC_DEFINE_UNQUOTED([OPAL_CUDA_GET_ATTRIBUTES],$CUDA_GET_ATTRIBUTES,\n                   [Whether we have CUDA cuPointerGetAttributes function available])\n\n# There is nothing specific we can check for to see if GPU Direct RDMA is available.\n# Therefore, we check to see whether we have CUDA 6.0 or later.\nAM_CONDITIONAL([OPAL_cuda_gdr_support], [test \"x$CUDA_VERSION_60_OR_GREATER\" = \"x1\"])\nAC_DEFINE_UNQUOTED([OPAL_CUDA_GDR_SUPPORT],$CUDA_VERSION_60_OR_GREATER,\n                   [Whether we have CUDA GDR support available])\n\n])\n\ndnl\ndnl CUDA support requires DL support (it dynamically opens the CUDA\ndnl library at run time).  But we do not check for OPAL DL support\ndnl until lafter the initial OPAL_CHECK_CUDA is called.  So put the\ndnl CUDA+DL check in a separate macro that can be called after the DL MCA\ndnl framework checks in the top-level configure.ac.\ndnl\nAC_DEFUN([OPAL_CHECK_CUDA_AFTER_OPAL_DL],[\n\n    # We cannot have CUDA support without OPAL DL support.  Error out\n    # if the user wants CUDA but we do not have OPAL DL support.\n    AS_IF([test $OPAL_HAVE_DL_SUPPORT -eq 0 && \\\n           test \"$opal_check_cuda_happy\" = \"yes\"],\n          [AC_MSG_WARN([--with-cuda was specified, but dlopen support is disabled.])\n           AC_MSG_WARN([You must reconfigure Open MPI with dlopen (\"dl\") support.])\n           AC_MSG_ERROR([Cannot continue.])])\n])\n",
        "/tmp/vanessa/spack-stage/spack-stage-openmpi-master-qcrm7qmgqutvsby2zcmdb57s22lzfq65/spack-src/ompi/debuggers/mpihandles_interface.h": "/*\n * Copyright (c) 2007      High Performance Computing Center Stuttgart,\n *                         University of Stuttgart.  All rights reserved.\n * Copyright (c) 2007-2008 Cisco Systems, Inc.  All rights reserved.\n * Copyright (c) 2007-2013 The University of Tennessee and The University of\n *                         Tennessee Research Foundation.  All rights reserved.\n * Copyright (c) 2012-2013 Inria.  All rights reserved.\n * $COPYRIGHT$\n *\n * Additional copyrights may follow\n *\n * Some text copied from and references made to mpi_interface.h.\n *\n * Copyright (C) 2000-2004 by Etnus, LLC\n * Copyright (C) 1999 by Etnus, Inc.\n * Copyright (C) 1997-1998 Dolphin Interconnect Solutions Inc.\n *\n * $HEADER$\n */\n\n#ifndef __MPIDBG_INTERFACE_H__\n#define __MPIDBG_INTERFACE_H__ 1\n\n#include \"ompi_config.h\"\n\n/*\n * This file provides interface functions for a debugger to gather\n * additional information about MPI handles.\n */\n#include <sys/types.h>\n\n/* Include the Etnus debugger message queue interface so that we can\n   use much of its infrastructure (e.g., the mqs_basic_callbacks,\n   mqs_image_callbacks, and mqs_process_callbacks). */\n#define FOR_MPI2 0\n#include \"msgq_interface.h\"\n\n/**************************************************************************\n * Types and macros\n **************************************************************************/\n\nenum {\n    MPIDBG_MAX_OBJECT_NAME = MPI_MAX_OBJECT_NAME\n};\nenum {\n    MPIDBG_MAX_FILENAME = 1024\n};\nenum {\n    MPIDBG_INTERFACE_VERSION = 1\n};\n\n\n/*-----------------------------------------------------------------------\n * Global initialization information for the DLL\n *-----------------------------------------------------------------------*/\n\n/* Structure containing types for C and C++ MPI handles */\nstruct mpidbg_handle_info_t {\n    /* C handle types.  They are typically pointers to something or\n       integers. */\n    /* Back-end type for MPI_Aint */\n    mqs_type *hi_c_aint;\n    /* Back-end type for MPI_Comm */\n    mqs_type *hi_c_comm;\n    /* Back-end type for MPI_Datatype */\n    mqs_type *hi_c_datatype;\n    /* Back-end type for MPI_Errhandler */\n    mqs_type *hi_c_errhandler;\n    /* Back-end type for MPI_File */\n    mqs_type *hi_c_file;\n    /* Back-end type for MPI_Group */\n    mqs_type *hi_c_group;\n    /* Back-end type for MPI_Info */\n    mqs_type *hi_c_info;\n    /* Back-end type for MPI_Offset */\n    mqs_type *hi_c_offset;\n    /* Back-end type for MPI_Op */\n    mqs_type *hi_c_op;\n    /* Back-end type for MPI_Request */\n    mqs_type *hi_c_request;\n    /* Back-end type for MPI_Status */\n    mqs_type *hi_c_status;\n    /* Back-end type for MPI_Win */\n    mqs_type *hi_c_win;\n\n    /* C++ handle types.  Note that these will always be *objects*,\n       never pointers. */\n    /* Back-end type for MPI::Aint */\n    mqs_type *hi_cxx_aint;\n    /* Back-end type for MPI::Comm */\n    mqs_type *hi_cxx_comm;\n    /* Back-end type for MPI::Intracomm */\n    mqs_type *hi_cxx_intracomm;\n    /* Back-end type for MPI::Intercomm */\n    mqs_type *hi_cxx_intercomm;\n    /* Back-end type for MPI::Graphcomm */\n    mqs_type *hi_cxx_graphcomm;\n    /* Back-end type for MPI::Cartcomm */\n    mqs_type *hi_cxx_cartcomm;\n    /* Back-end type for MPI::Datatype */\n    mqs_type *hi_cxx_datatype;\n    /* Back-end type for MPI::Errhandler */\n    mqs_type *hi_cxx_errhandler;\n    /* Back-end type for MPI::File */\n    mqs_type *hi_cxx_file;\n    /* Back-end type for MPI::Group */\n    mqs_type *hi_cxx_group;\n    /* Back-end type for MPI::Info */\n    mqs_type *hi_cxx_info;\n    /* Back-end type for MPI::Offset */\n    mqs_type *hi_cxx_offset;\n    /* Back-end type for MPI::Op */\n    mqs_type *hi_cxx_op;\n    /* Back-end type for MPI::Request */\n    mqs_type *hi_cxx_request;\n    /* Back-end type for MPI::Prequest */\n    mqs_type *hi_cxx_prequest;\n    /* Back-end type for MPI::Grequest */\n    mqs_type *hi_cxx_grequest;\n    /* Back-end type for MPI::Status */\n    mqs_type *hi_cxx_status;\n    /* Back-end type for MPI::Win */\n    mqs_type *hi_cxx_win;\n};\n\nenum mpidbg_return_codes_t {\n    /* Success */\n    MPIDBG_SUCCESS,\n    /* Something was not found */\n    MPIDBG_ERR_NOT_FOUND,\n    /* Something is not supported */\n    MPIDBG_ERR_NOT_SUPPORTED,\n    /* Something is out of range */\n    MPIDBG_ERR_OUT_OF_RANGE,\n    /* Something is not available */\n    MPIDBG_ERR_UNAVAILABLE,\n    /* Ran out of memory */\n    MPIDBG_ERR_NO_MEM,\n    /* Sentinel max value */\n    MPIDBG_MAX_RETURN_CODE\n};\n\n/*-----------------------------------------------------------------------\n * General data structures\n *-----------------------------------------------------------------------*/\n\n/* Information about MPI processes */\nstruct mpidbg_process_t {\n    /* JMS: need something to uniquely ID MPI processes in the\n       presence of MPI_COMM_SPAWN */\n\n    /* Global rank in MPI_COMM_WORLD */\n    int mpi_comm_world_rank;\n};\n/* ==> JMS Should we just use mqs_process_location instead?  George\n   thinks that this is unncessary -- perhaps due to the fact that we\n   could use mqs_process_location...?  Need to get some feedback from\n   others on this one.  Need to check Euro PVM/MPI '06 paper... */\n\n/* General name -> handle address mappings.  This is an optional type\n   that is used to describe MPI's predefined handles if the\n   pre-defined names do not appear as symbols in the MPI process.\n   E.g., if MPI_COMM_WORLD is a #define that maps to some other value,\n   this data structure can be used to map the string \"MPI_COMM_WORLD\"\n   to the actual value of the handle that it corresponds to (e.g., 0\n   or a pointer value). */\nstruct mpidbg_name_map_t {\n    /* Name of the handle */\n    char *map_name;\n\n    /* Handle that the name corresponds to.  Will be 0/NULL if there\n       is no corresponding back-end object. */\n    mqs_taddr_t map_handle;\n};\n\n/* MPI attribute / value pairs.  Include both a numeric and string\n   key; pre-defined MPI keyvals (e.g., MPI_TAG_MAX) have a\n   human-readable string name.  The string will be NULL for\n   non-predefined keyvals. */\nstruct mpidbg_attribute_pair_t {\n    /* Keyval */\n    int keyval;\n    /* Keyval name; will be non-NULL for attributes that have a\n       human-readable name (e.g., MPI predefined keyvals) */\n    char *keyval_name;\n    /* Value */\n    char *value;\n};\n\n/*-----------------------------------------------------------------------\n * Communicators\n *-----------------------------------------------------------------------*/\n\n/* Using an enum instead of #define because debuggers can show the\n   *names* of enum values, not just the values. */\nenum mpidbg_comm_capabilities_t {\n    /* Whether this MPI DLL supports returning basic information about\n       communicators */\n    MPIDBG_COMM_CAP_BASIC =                  0x01,\n    /* Whether this MPI DLL supports returning names of\n       communicators */\n    MPIDBG_COMM_CAP_STRING_NAMES =           0x02,\n    /* Whether this MPI DLL supports indicating whether a communicator\n       has been freed by the user application */\n    MPIDBG_COMM_CAP_FREED_HANDLE =           0x04,\n    /* Whether this MPI DLL supports indicating whether a communicator\n       object has been freed by the MPI implementation or not */\n    MPIDBG_COMM_CAP_FREED_OBJECT =           0x08,\n    /* Whether this MPI DLL supports returning the list of MPI request\n       handles that are pending on a communicator */\n    MPIDBG_COMM_CAP_REQUEST_LIST =           0x10,\n    /* Whether this MPI DLL supports returning the list of MPI window\n       handles that were derived from a given communicator */\n    MPIDBG_COMM_CAP_WINDOW_LIST =            0x20,\n    /* Whether this MPI DLL supports returning the list of MPI file\n       handles that were derived from a given communicator */\n    MPIDBG_COMM_CAP_FILE_LIST =              0x40,\n    /* Sentinel max value */\n    MPIDBG_COMM_CAP_MAX\n};\n\nenum mpidbg_comm_info_bitmap_t {\n    /* Predefined communicator if set (user-defined if not set) */\n    MPIDBG_COMM_INFO_PREDEFINED =      0x01,\n    /* Whether this communicator is a cartesian communicator or not\n       (mutually exclusive with _GRAPH and _INTERCOMM) */\n    MPIDBG_COMM_INFO_CARTESIAN =       0x02,\n    /* Whether this communicator is a graph communicator or not\n       (mutually exclusive with _CARTESIAN and _INTERCOMM) */\n    MPIDBG_COMM_INFO_GRAPH =           0x04,\n    /* If a cartesian or graph communicator, whether the processes in\n       this communicator were re-ordered when the topology was\n       assigned. */\n    MPIDBG_COMM_INFO_TOPO_REORDERED =  0x08,\n    /* Whether this is an intercommunicator or not (this communicator\n       is an intracommunicator if this flag is not yet). */\n    MPIDBG_COMM_INFO_INTERCOMM =       0x10,\n    /* This communicator has been marked for freeing by the user\n       application if set */\n    MPIDBG_COMM_INFO_FREED_HANDLE =    0x20,\n    /* This communicator has actually been freed by the MPI\n       implementation if set */\n    MPIDBG_COMM_INFO_FREED_OBJECT =    0x40,\n    /* The queried communicator is MPI_COMM_NULL */\n    MPIDBG_COMM_INFO_COMM_NULL =       0x80,\n    /* The queried communicator has a distributed graph topology attached to it */\n    MPIDBG_COMM_INFO_DIST_GRAPH =      0x00000400,\n    /* Sentinel max value */\n    MPIDBG_COMM_INFO_MAX\n};\n\nstruct mpidbg_comm_info_t {\n    /* Name of the MPI_COMM */\n    char comm_name[MPIDBG_MAX_OBJECT_NAME];\n\n    /* Bit flags describing the communicator */\n    enum mpidbg_comm_info_bitmap_t comm_bitflags;\n\n    /* This process' rank within this communicator */\n    int comm_rank;\n    /* The communicator's size  */\n    int comm_size;\n\n    /* Number of processes in the local group */\n    int comm_num_local_procs;\n    /* Information about each process in the local group (in\n       communicator rank order, length: comm_num_local_procs) */\n    struct mpidbg_process_t *comm_local_procs;\n\n    /* For intercommunicators, the number of processes in the remote\n       group */\n    int comm_num_remote_procs;\n    /* For intercommunicators, information about each process in the\n       remote group (in communicator rank order, length:\n       comm_num_remote_procs) */\n    struct mpidbg_process_t *comm_remote_procs;\n\n    /* For cartesian communicators, the number of dimensions */\n    int comm_cart_num_dims;\n    /* For cartesian communicators, an array of dimension lengths\n       (length: cart_comm_num_dims) */\n    int *comm_cart_dims;\n    /* For cartesian communicators, an array of boolean values\n       indicating whether each dimension is periodic or not (length:\n       cart_comm_num_dims) */\n    int8_t *comm_cart_periods;\n\n    /* For graph communicators, the number of nodes */\n    int comm_graph_num_nodes;\n    /* For graph communicators, an array of the node degrees (length:\n       comm_graph_num_nodes) */\n    int *comm_graph_index;\n    /* For graph communicators, an array of the edges (length:\n       comm_graph_num_nodes) */\n    int *comm_graph_edges;\n\n    /* C handle */\n    mqs_taddr_t comm_c_handle;\n    /* Fortran handle; will be MPIDBG_ERR_UNAVAILABLE if currently\n       unavailable or MPIDBG_ERR_NOT_SUPPORTED if not supported */\n    int comm_fortran_handle;\n\n    /* Number of attributes defined on this communicator */\n    int comm_num_attrs;\n    /* Array of attribute keyval/value pairs defined on this\n       communicator (length: comm_num_attrs) */\n    struct mpidbg_attribute_pair_t *comm_attrs;\n\n    /* Number of ongoing requests within this communicator, or\n       MPIDBG_ERR_NOT_SUPPORTED */\n    int comm_num_pending_requests;\n    /* If comm_num_pending_requests != MPIDBG_ERR_NOT_SUPPORTED, an\n       array of ongoing request handles attached on this\n       communicator (length: comm_num_pending_requests) */\n    mqs_taddr_t *comm_pending_requests;\n\n    /* Number of MPI windows derived from this communicator, or\n       MPIDBG_ERR_NOT_SUPPORTED  */\n    int comm_num_derived_windows;\n    /* If comm_num_derived_windows != MPIDBG_ERR_NOT_SUPPORTED, an\n       array of window handles derived from this communicator (length:\n       com_num_derived_windows) */\n    mqs_taddr_t *comm_derived_windows;\n\n    /* Number of MPI files derived from this communicator, or\n       MPIDBG_ERR_NOT_SUPPORTED  */\n    int comm_num_derived_files;\n    /* If comm_num_derived_files != MPIDBG_ERR_NOT_SUPPORTED, an array\n       of file handles derived from this communicator (length:\n       comm_num_derived_files) */\n    mqs_taddr_t *comm_derived_files;\n};\n\n\n/*-----------------------------------------------------------------------\n * Requests\n *-----------------------------------------------------------------------*/\n\n/* Using an enum instead of #define because debuggers can show the\n   *names* of enum values, not just the values. */\nenum mpidbg_request_capabilities_t {\n    /* Whether this MPI DLL supports returning basic information about\n       requests */\n    MPIDBG_REQUEST_CAP_BASIC =           0x01,\n    /* Sentinel max value */\n    MPIDBG_REQUEST_CAP_MAX\n};\n\nenum mpidbg_request_info_bitmap_t {\n    /* Predefined request if set (user-defined if not set) */\n    MPIDBG_REQUEST_INFO_PREDEFINED =      0x01,\n    /* Sentinel max value */\n    MPIDBG_REQUEST_INFO_MAX\n};\n\nstruct mpidbg_request_info_t {\n    /* Bit flags describing the error handler */\n    enum mpidbg_request_info_bitmap_t req_bitflags;\n\n    /* C handle */\n    mqs_taddr_t req_c_handle;\n    /* Fortran handle; will be MPIDBG_ERR_UNAVAILABLE if currently\n       unavailable or MPIDBG_ERR_NOT_SUPPORTED if not supported */\n    int req_fortran_handle;\n};\n\n/*-----------------------------------------------------------------------\n * Statuses\n *-----------------------------------------------------------------------*/\n\nenum mpidbg_status_capabilities_t {\n    /* Whether this MPI DLL supports returning basic information about\n       statuses */\n    MPIDBG_STATUS_CAP_BASIC =           0x01,\n    /* Sentinel max value */\n    MPIDBG_STATUS_CAP_MAX\n};\n\nenum mpidbg_status_info_bitmap_t {\n    /* Predefined status if set (user-defined if not set) */\n    MPIDBG_STATUS_INFO_PREDEFINED =      0x01,\n    /* Sentinel max value */\n    MPIDBG_STATUS_INFO_MAX\n};\n\nstruct mpidbg_status_info_t {\n    /* Bit flags describing the error handler */\n    enum mpidbg_status_info_bitmap_t status_bitflags;\n};\n\n/*-----------------------------------------------------------------------\n * Error handlers\n *-----------------------------------------------------------------------*/\n\n/* Using an enum instead of #define because debuggers can show the\n   *names* of enum values, not just the values. */\nenum mpidbg_errhandler_capabilities_t {\n    /* Whether this MPI DLL supports returning basic information about\n       error handlers */\n    MPIDBG_ERRH_CAP_BASIC =           0x01,\n    /* Whether this MPI DLL supports returning names of the predefined\n       error handlers */\n    MPIDBG_ERRH_CAP_STRING_NAMES =    0x02,\n    /* Whether this MPI DLL supports indicating whether an error\n       handler has been freed by the user application */\n    MPIDBG_ERRH_CAP_FREED_HANDLE =    0x04,\n    /* Whether this MPI DLL supports indicating whether an error\n       handler object has been freed by the MPI implementation or\n       not */\n    MPIDBG_ERRH_CAP_FREED_OBJECT =    0x08,\n    /* Whether this MPI DLL supports returning the list of MPI handles\n       that an MPI error handler is attached to */\n    MPIDBG_ERRH_CAP_HANDLE_LIST =     0x10,\n    /* Sentinel max value */\n    MPIDBG_ERRH_CAP_MAX\n};\n\nenum mpidbg_errhandler_info_bitmap_t {\n    /* Predefined error handler if set (user-defined if not set) */\n    MPIDBG_ERRH_INFO_PREDEFINED =      0x01,\n    /* Communicator error handler if set */\n    MPIDBG_ERRH_INFO_COMMUNICATOR =    0x02,\n    /* File error handler if set */\n    MPIDBG_ERRH_INFO_FILE =            0x04,\n    /* Window error handler if set */\n    MPIDBG_ERRH_INFO_WINDOW =          0x08,\n    /* Callback is in C if set (Fortran if not set) */\n    MPIDBG_ERRH_INFO_C_CALLBACK =      0x10,\n    /* This errorhandler has been marked for freeing by the user\n       application if set */\n    MPIDBG_ERRH_INFO_FREED_HANDLE =    0x20,\n    /* This errorhandler has actually been freed by the MPI\n       implementation if set */\n    MPIDBG_ERRH_INFO_FREED_OBJECT =    0x40,\n    /* Sentinel max value */\n    MPIDBG_ERRH_INFO_MAX\n};\n\nstruct mpidbg_errhandler_info_t {\n    /* String name; only relevant for predefined errorhandlers.  If\n       not a predefined errorhandler, eh_name[0] will be '\\0'; */\n    char eh_name[MPIDBG_MAX_OBJECT_NAME];\n\n    /* Bit flags describing the error handler */\n    enum mpidbg_errhandler_info_bitmap_t eh_bitflags;\n\n    /* C handle */\n    mqs_taddr_t eh_c_handle;\n    /* Fortran handle; will be MPIDBG_ERR_UNAVAILABLE if currently\n       unavailable or MPIDBG_ERR_NOT_SUPPORTED if not supported */\n    int eh_fortran_handle;\n\n    /* Number of MPI handles that this error handler is attached to.\n       MPIDBG_ERR_NOT_SUPPORTED means that this information is not\n       supported by the DLL. */\n    int16_t eh_refcount;\n    /* If eh_refcount != MPIDBG_ERR_NOT_SUPPORTED, list of handles\n       that are using this error handler (length: eh_refcount). */\n    mqs_taddr_t *eh_handles;\n\n    /* Address of the user-defined error handler (will be 0 for\n       predefined error handlers).  Note that each of the 3 C\n       callbacks contain an MPI handle; the debugger will need to\n       figure out the appropriate size for these types depending on\n       the platform and MPI implementation.  This value will be NULL\n       if MPIDBG_ERRH_INFO_PREDEFINED is set on the flags. */\n    mqs_taddr_t eh_callback_func;\n};\n\n/**************************************************************************\n * Global variables\n *\n * mpidbg_dll_locations is in the MPI application; all others are in\n * the DLL.\n **************************************************************************/\n\n/* Array of filenames instantiated IN THE MPI APPLICATION (*NOT* in\n   the DLL) that provides an set of locations where DLLs may be found.\n   The last pointer in the array will be a NULL sentinel value.  The\n   debugger can scan the entries in the array, find one that matches\n   the debugger (by examining a) whether the dlopen works or not, and\n   b) if the dlopen succeeds, examine mpidbg_dll_is_big_endian and\n   mpidbg_dll_bitness), and try to dynamically open the dl_filename.\n   Notes:\n\n   1. It is not an error if a dl_filename either does not exist or is\n      otherwise un-openable (the debugger can just try the next\n      match).\n   2. This array values are not valid until MPIR_Breakpoint.\n   3. If a filename is absolute, the debugger will attempt to load\n      exactly that.  If the filename is relative, the debugger may try\n      a few prefix variations to find the DLL.\n */\nextern char **mpidbg_dll_locations;\n\n/* Global variable *in the DLL* describing whether this DLL is big or\n   little endian (1 = big endian, 0 = little endian).  This value is\n   valid immediately upon opening of the DLL. */\nextern char mpidbg_dll_is_big_endian;\n\n/* Global variable *in the DLL* describing the bitness of the DLL (8,\n   16, 32, 64, ...).  This value is valid immediately upon opening of\n   the DLL. */\nextern char mpidbg_dll_bitness;\n\n/* Global variable *in the DLL* describing the DLL's capabilties with\n   regards to communicators.  This value is valid after a successfull\n   call to mpidbg_init_per_process(). */\nextern enum mpidbg_comm_capabilities_t mpidbg_comm_capabilities;\n\n/* Global variable *in the DLL* that is an array of MPI communicator\n   handle names -> handle mappings (the last entry in the array is\n   marked by a NULL string value).  For example, MPI_COMM_WORLD may\n   not appear as a symbol in an MPI process, but the debugger needs to\n   be able to map this name to a valid handle.  MPI implementations\n   not requiring this mapping can either have a NULL value for this\n   variable or have a single entry that has a NULL string value.  This\n   variable is not valid until after a successfull call to\n   mpidbg_init_per_process().  */\nextern struct mpidbg_name_map_t *mpidbg_comm_name_map;\n\n/* Global variable *in the DLL* describing the DLL's capabilties with\n   regards to error handlers.  This value is valid after a successfull\n   call to mpidbg_init_per_process(). */\nextern enum mpidbg_errhandler_capabilities_t mpidbg_errhandler_capabilities;\n\n/* Global variable *in the DLL* that is an array of MPI error handler\n   handle names -> handle mappings.  It is analogous to\n   mpidbg_comm_name_map; see above for details. */\nextern struct mpidbg_name_map_t *mpidbg_errhandler_name_map;\n\n/**************************************************************************\n * Functions\n **************************************************************************/\n\n/*-----------------------------------------------------------------------\n * DLL infrastructure functions\n *-----------------------------------------------------------------------*/\n\n/* This function must be called once before any other mpidbg_*()\n   function is called, and before most other global mpidbg_* data is\n   read.  It is only necessary to call this function once for a given\n   debugger instantiation.  This function will initialize all mpidbg\n   global state, to include setting all relevant global capability\n   flags.\n\n   Parameters:\n\n   IN: callbacks: Table of pointers to the debugger functions. The DLL\n                  need only save the pointer, the debugger promises to\n                  maintain the table of functions valid for as long as\n                  needed.  The table remains the property of the\n                  debugger, and should not be altered or deallocated\n                  by the DLL. This applies to all of the callback\n                  tables.\n\n   This function will return:\n\n   MPIDBG_SUCCESS: if all initialization went well\n   MPIDBG_ERR_*: if something went wrong.\n*/\nint mpidbg_init_once(const mqs_basic_callbacks *callbacks);\n\n/*-----------------------------------------------------------------------*/\n\n/* Query the DLL to find out what version of the interface it\n   supports.\n\n   Parameters:\n\n   None.\n\n   This function will return:\n\n   MPIDBG_INTERFACE_VERSION\n*/\n\nint mpidbg_interface_version_compatibility(void);\n\n/*-----------------------------------------------------------------------*/\n\n/* Returns a string describing this DLL.\n\n   Parameters:\n\n   None\n\n   This function will return:\n\n   A null-terminated string describing this DLL.\n*/\nchar *mpidbg_version_string(void);\n\n/*-----------------------------------------------------------------------*/\n\n/* Returns the address width that this DLL was compiled with.\n\n   Parameters:\n\n   None\n\n   This function will return:\n\n   sizeof(mqs_taddr_t)\n*/\n\nint mpidbg_dll_taddr_width(void);\n\n/*-----------------------------------------------------------------------*/\n\n/* Setup debug information for a specific image, this must save the\n   callbacks (probably in the mqs_image_info), and use those functions\n   for accessing this image.\n\n   The DLL should use the mqs_put_image_info and mqs_get_image_info\n   functions to associate whatever information it wants to keep with\n   the image (e.g., all of the type offsets it needs could be kept\n   here).  The debugger will call mqs_destroy_image_info when it no\n   longer wants to keep information about the given executable.\n\n   This will be called once for each executable image in the parallel\n   job.\n\n   Parameters:\n\n   IN: image: the application image.\n   IN: callbacks: Table of pointers to the debugger image-specific\n                  functions. The DLL need only save the pointer, the\n                  debugger promises to maintain the table of functions\n                  valid for as long as needed.  The table remains the\n                  property of the debugger, and should not be altered\n                  or deallocated by the DLL. This applies to all of\n                  the callback tables.\n   IN/OUT: handle_types: a pointer to a pre-allocated struct\n                         containing mqs_types for each of the MPI\n                         handle types.  Must be filled in with results\n                         from mqs_find_type for each MPI handle type.\n\n   This function will return:\n\n   MPIDBG_SUCCESS: if all initialization went well\n   MPIDBG_ERR_NOT_SUPPORTED: if the image does not support the MPIDBG\n                   interface.  In this case, no other mpidbg functions\n                   will be invoked on this image (not even\n                   mpidbg_finalize_per_image()).\n   MPIDBG_ERR_*: if something went wrong.\n*/\nint mpidbg_init_per_image(mqs_image *image,\n                          const mqs_image_callbacks *callbacks,\n                          struct mpidbg_handle_info_t *handle_types);\n\n/* This function will be called once when an application image that\n   previously had mpidbg_init_per_image() successfully invoked that is\n   now ending (e.g., the debugger is exiting, the debugger has\n   unloaded this image, etc.).  This function can be used to clean up\n   any image-specific data.\n\n   Parameters:\n\n   IN: image: the application image.\n   IN: image_info: the info associated with the application image.\n*/\nvoid mpidbg_finalize_per_image(mqs_image *image, mqs_image_info *image_info);\n\n/*-----------------------------------------------------------------------*/\n\n/* This function will only be called if mpidbg_init_per_image()\n   returned successfully, indicating that the image contains\n   information for MPI handle information.  If you cannot tell whether\n   a process will have MPI handle information in it by examining the\n   image, you should return SUCCESS from mpidbg_init_per_image() and\n   use this function to check whether MPI handle information is\n   available in the process.\n\n   Set up whatever process specific information we need.  For instance,\n   addresses of global variables should be handled here rather than in\n   the image information, because if data may be in dynamic libraries\n   which could end up mapped differently in different processes.\n\n   Note that certain global variables are not valid until after this\n   call completes successfully (see above; e.g.,\n   mpidbg_comm_capabilities, mpidbg_comm_name_mapping, etc.).\n\n   Parameters:\n\n   IN: process: the process\n   IN: callbacks: Table of pointers to the debugger process-specific\n                  functions. The DLL need only save the pointer, the\n                  debugger promises to maintain the table of functions\n                  valid for as long as needed.  The table remains the\n                  property of the debugger, and should not be altered\n                  or deallocated by the DLL. This applies to all of\n                  the callback tables.\n   IN/OUT: handle_types: the same handle_types that was passed to\n                         mqs_init_per_image.  It can be left unaltered\n                         if the results from mqs_init_per_image were\n                         sufficient, or modified if necessary to be\n                         specific to this process.\n\n   This function will return:\n\n   MPIDBG_SUCCESS: if all initialization went well\n   MPIDBG_ERR_NOT_SUPPORTED: if the process does not support the MPIDBG\n                   interface.  In this case, no other mpidbg functions\n                   will be invoked on this image (not even\n                   mpidbg_finalize_per_process()).\n   MPIDBG_ERR_*: if something went wrong.\n*/\nint mpidbg_init_per_process(mqs_process *process,\n                            const mqs_process_callbacks *callbacks,\n                            struct mpidbg_handle_info_t *handle_types);\n\n/* This function will be called once when an application image that\n   previously had mpidbg_init_per_process() successfully invoked that\n   is now ending (e.g., the debugger is exiting, the debugger has\n   stopped executing this process, etc.).  This function can be used\n   to clean up any process-specific data.\n\n   Parameters:\n\n   IN: process: the application process.\n   IN: process_info: the info associated with the application process.\n*/\nvoid mpidbg_finalize_per_process(mqs_process *process,\n                                 mqs_process_info *process_info);\n\n/*-----------------------------------------------------------------------\n * MPI handle query functions\n * MPI_Comm\n *-----------------------------------------------------------------------*/\n\n/* Query a specific MPI_Comm handle and, if found and valid, allocate\n   a new instance of the mpidbg_comm_info_t struct and all of its\n   internal data, and fill it in with information about the underlying\n   corresponding MPI communicator object.\n\n   Parameters:\n\n   IN: image: image\n   IN: image_info: image info that was previously \"put\"\n   IN: process: process\n   IN: process_info: process info that was previously \"put\"\n   IN: comm: communicator handle\n   OUT: info: pointer to be filled with a newly-allocated struct\n              mpidbg_comm_info_t\n\n   This function will return:\n\n   MPIDBG_SUCCESS: if the handle is valid, was found, and the info\n                   parameter was filled in successfully.\n   MPIDBG_ERR_NOT_FOUND: if the handle is not valid / found.\n   MPIDBG_ERR_UNSUPPORTED: if this function is unsupported.\n*/\nint mpidbg_comm_query(mqs_image *image, mqs_image_info *image_info,\n                      mqs_process *process, mqs_process_info *process_info,\n                      mqs_taddr_t c_comm, struct mpidbg_comm_info_t **info);\n\n/* Query function to turn a Fortran INTEGER handle into its equivalent\n   C handle (that can then be queried with mpidbg_comm_query()).\n   mqs_taddr_t is used in order to guarantee to be large enough to\n   hold a Fortran INTEGER.\n\n   Parameters:\n\n   IN: image: image\n   IN: image_info: image info that was previously \"put\"\n   IN: process: process\n   IN: process_info: process info that was previously \"put\"\n   IN: f77_comm: a zero-padded Fortran integer containing the Fortran\n                 handle of the communicator.\n   OUT: c_comm: a C handle suitable to pass to mpidbg_comm_query().\n\n   This function returns:\n\n   MPIDBG_SUCCESS: if the handle is valid, was found, and the c_comm\n                   parameter was filled in successfully.\n   MPIDBG_ERR_NOT_FOUND: if the handle is not valid / found.\n   MPIDBG_ERR_UNSUPPORTED: if this function is unsupported.\n*/\nint mpidbg_comm_f2c(mqs_image *image, mqs_image_info *image_info,\n                    mqs_process *process, mqs_process_info *process_info,\n                    mqs_taddr_t f77_comm, mqs_taddr_t *c_comm);\n\n/* Query function to turn a C++ handle into its equivalent C handle\n   (that can then be queried with mpidbg_comm_query()).  Pass the\n   pointer to the object as the cxx_comm (because we can't pass the\n   object itself); we return the C handle.\n\n   --> JMS Need more discussion here -- George has some opinion.  He\n       thinks we don't need this.\n   Parameters:\n\n   IN: image: image\n   IN: image_info: image info that was previously \"put\"\n   IN: process: process\n   IN: process_info: process info that was previously \"put\"\n   IN: cxx_comm: a pointer to the MPI handle object\n   IN: comm_type: one of 0, MPIDBG_COMM_INFO_CARTESION,\n                  MPIDBG_COMM_INFO_GRAPH, or\n                  MPIDBG_COMM_INFO_INTERCOMM indicating whether the\n                  object is an MPI::Comm, MPI::Cartcomm,\n                  MPI::Graphcomm, or MPI::Intercomm.\n   OUT: c_comm: a C handle suitable to pass to mpidbg_comm_query().\n\n   This function returns:\n\n   MPIDBG_SUCCESS: if the handle is valid, was found, and the c_comm\n                   parameter was filled in successfully.\n   MPIDBG_ERR_NOT_FOUND: if the handle is not valid / found.\n   MPIDBG_ERR_UNSUPPORTED: if this function is unsupported.\n*/\nint mpidbg_comm_cxx2c(mqs_image *image, mqs_image_info *image_info,\n                      mqs_process *process, mqs_process_info *process_info,\n                      mqs_taddr_t cxx_comm,\n                      enum mpidbg_comm_info_bitmap_t comm_type,\n                      mqs_taddr_t *c_comm);\n\n/*-----------------------------------------------------------------------\n * MPI handle query functions\n * MPI_Errhandler\n *-----------------------------------------------------------------------*/\n\n/* These functions are analogous to the mpidbg_comm_* functions, but\n   for MPI_Errhandler.  Note that there is no need for a\n   \"errhandler_type\" argument to the cxx2c function because\n   MPI::Errhandler has no derived classes. */\n\nint mpidbg_errhandler_query(mqs_image *image, mqs_image_info *image_info,\n                            mqs_process *process, mqs_process_info *process_info,\n                            mqs_taddr_t errhandler,\n                            struct mpidbg_errhandler_info_t **info);\nint mpidbg_errhandler_f2c(mqs_image *image, mqs_image_info *image_info,\n                          mqs_process *process, mqs_process_info *process_info,\n                          mqs_taddr_t f77_errhandler,\n                          mqs_taddr_t *c_errhandler);\nint mpidbg_errhandler_cxx2c(mqs_image *image, mqs_image_info *image_info,\n                            mqs_process *process, mqs_process_info *process_info,\n                            mqs_taddr_t cxx_errhandler,\n                            mqs_taddr_t *c_errhandler);\n\n/*-----------------------------------------------------------------------\n * MPI handle query functions\n * MPI_Request\n *-----------------------------------------------------------------------*/\n\n/* These functions are analogous to the mpidbg_comm_* functions, but\n   for MPI_Request. */\n\nint mpidbg_request_query(mqs_image *image, mqs_image_info *image_info,\n                         mqs_process *process, mqs_process_info *process_info,\n                         mqs_taddr_t request,\n                         struct mpidbg_request_info_t **info);\nint mpidbg_request_f2c(mqs_image *image, mqs_image_info *image_info,\n                       mqs_process *process, mqs_process_info *process_info,\n                       mqs_taddr_t f77_request, mqs_taddr_t *c_request);\nint mpidbg_request_cxx2c(mqs_image *image, mqs_image_info *image_info,\n                         mqs_process *process, mqs_process_info *process_info,\n                         mqs_taddr_t cxx_request,\n                         enum mpidbg_request_info_bitmap_t request_type,\n                         mqs_taddr_t *c_request);\n\n/*-----------------------------------------------------------------------\n * MPI handle query functions\n * MPI_Status\n *-----------------------------------------------------------------------*/\n\n/* These functions are analogous to the mpidbg_comm_* functions, but\n   for MPI_Status. */\n\nint mpidbg_status_query(mqs_image *image, mqs_image_info *image_info,\n                        mqs_process *process, mqs_process_info *process_info,\n                        mqs_taddr_t status,\n                        struct mpidbg_status_info_t **info);\nint mpidbg_status_f2c(mqs_image *image, mqs_image_info *image_info,\n                      mqs_process *process, mqs_process_info *process_info,\n                      mqs_taddr_t f77_status, mqs_taddr_t *c_status);\nint mpidbg_status_cxx2c(mqs_image *image, mqs_image_info *image_info,\n                        mqs_process *process, mqs_process_info *process_info,\n                        mqs_taddr_t cxx_status,\n                        mqs_taddr_t *c_status);\n\n#endif /* __MPIDBG_INTERFACE_H__ */\n",
        "/tmp/vanessa/spack-stage/spack-stage-openmpi-master-qcrm7qmgqutvsby2zcmdb57s22lzfq65/spack-src/ompi/debuggers/dlopen_test.c": "/*\n * Copyright (c) 2009-2018 Cisco Systems, Inc.  All rights reserved.\n * Copyright (c) 2018      Amazon.com, Inc. or its affiliates.  All Rights reserved.\n * $COPYRIGHT$\n *\n * Additional copyrights may follow\n *\n * $HEADER$\n */\n\n#include \"opal_config.h\"\n\n#include <stdio.h>\n#include <string.h>\n#include <stdlib.h>\n#include <unistd.h>\n\n#include \"opal/runtime/opal.h\"\n#include \"opal/util/printf.h\"\n#include \"opal/mca/dl/base/base.h\"\n\n#if !OPAL_HAVE_DL_SUPPORT\nint main(int argc, char *argv[])\n{\n    /* If OPAL wasn't built with libltdl support, then skip this test */\n    fprintf(stderr, \"OPAL was not built with libltdl support; skipping\\n\");\n    return 77;\n}\n\n#else /* OPAL_HAVE_DL_SUPPORT */\n\nstatic int try_open(const char *filename)\n{\n    char *err_msg;\n    opal_dl_handle_t *handle;\n    int ret;\n\n    ret = opal_dl_open(filename, true, true, &handle, &err_msg);\n    if (OPAL_SUCCESS == ret) {\n        opal_dl_close(handle);\n        printf(\"File opened with private namespace, all passed\\n\");\n        return 0;\n    }\n\n    printf(\"Failed to open with private namespace: %s\\n\", err_msg);\n    printf(\"Retrying with global namespace\\n\");\n\n    ret = opal_dl_open(filename, true, false, &handle, &err_msg);\n    if (OPAL_SUCCESS == ret) {\n        opal_dl_close(handle);\n        printf(\"File opened with global namespace\\n\");\n        return 0;\n    }\n\n    fprintf(stderr, \"File failed to open with global namespace: %s\\n\",\n            err_msg);\n\n    return 2;\n}\n\nstatic int do_test(void)\n{\n    FILE *fp;\n    char filename[] = \"./libompi_dbg_msgq\";\n    char full_filename[] = \"./libompi_dbg_msgq.la\";\n    char line[1024];\n    int happy;\n\n    /* Double check that the .la file is there that we expect; if it's\n       not, skip this test. */\n    fp = fopen(full_filename, \"r\");\n    if (NULL == fp) {\n        fprintf(stderr,\n                \"File %s.la doesn't seem to exist; skipping this test\\n\",\n                full_filename);\n        exit(77);\n    }\n    /* We know the .la file is there, so read it, looking for the\n       dlopen value.  If the dlopen value is '' (i.e., empty), then\n       there's nothing to dlopen (i.e., OMPI was built with\n       --enable-static --disable-shared, so return 77 to skip this\n       test.  This is horrible, but I can't think of a better way to\n       check it (since there is no good way to #define whether we have\n       built statically or not...). */\n    happy = 0;\n    while (1) {\n        if (0 == fgets(line, sizeof(line) - 1, fp)) {\n            break;\n        }\n        if (0 == strncmp(line, \"dlname=\", 7)) {\n            if (0 == strncmp(line + 7, \"''\", 2)) {\n                happy = 0;\n            } else {\n                happy = 1;\n            }\n            break;\n        }\n    }\n    fclose(fp);\n    if (!happy) {\n        fprintf(stderr, \"No test file to dlopen (perhaps --enable-static?); skipping\\n\");\n        exit(77);\n    }\n\n    char cwd[4096];\n    getcwd(cwd, sizeof(cwd) - 1);\n    cwd[sizeof(cwd) - 1] = '\\0';\n    printf(\"Running in CWD: %s\\n\", cwd);\n\n    printf(\"Trying to open file with private namespace: %s\\n\", filename);\n\n    /* If that works, great */\n    if (0 == try_open(filename)) {\n        return 0;\n    }\n\n    /* If we're using libltdl, it will find the .la file and may\n       discover that it needs to open the actual file in the .libs\n       directory.  If we're not using libltdl, then we won't know\n       about the magic .la file / .libs directory.  Hueristic: if we\n       get here, manually prefix the filename with .libs/ and try\n       again. */\n    char *rel_filename;\n    opal_asprintf(&rel_filename, \".libs/%s\", filename);\n    if (NULL == rel_filename) {\n        return 1;\n    }\n    int rc = try_open(rel_filename);\n    free(rel_filename);\n\n    return rc;\n}\n\nint main(int argc, char *argv[])\n{\n    opal_init(&argc, &argv);\n    int ret = do_test();\n    opal_finalize();\n\n    return ret;\n}\n#endif /* OPAL_HAVE_DL_SUPPORT */\n",
        "/tmp/vanessa/spack-stage/spack-stage-openmpi-master-qcrm7qmgqutvsby2zcmdb57s22lzfq65/spack-src/ompi/debuggers/Makefile.am": "#\n# Copyright (c) 2004-2005 The Trustees of Indiana University and Indiana\n#                         University Research and Technology\n#                         Corporation.  All rights reserved.\n# Copyright (c) 2004-2005 The University of Tennessee and The University\n#                         of Tennessee Research Foundation.  All rights\n#                         reserved.\n# Copyright (c) 2004-2005 High Performance Computing Center Stuttgart,\n#                         University of Stuttgart.  All rights reserved.\n# Copyright (c) 2004-2005 The Regents of the University of California.\n#                         All rights reserved.\n# Copyright (c) 2007-2015 Cisco Systems, Inc.  All rights reserved.\n# Copyright (c) 2016      IBM Corporation.  All rights reserved.\n# $COPYRIGHT$\n#\n# Additional copyrights may follow\n#\n# $HEADER$\n#\n\nnoinst_LTLIBRARIES = libdebuggers.la libompi_debugger_canary.la\nompilib_LTLIBRARIES = libompi_dbg_msgq.la\n\ncheck_PROGRAMS = predefined_gap_test predefined_pad_test dlopen_test\n\nTESTS = $(check_PROGRAMS)\n\n# This is not quite in the Automake spirit, but we have to do it.\n# Since the totalview portion of the library must be built with -g, we\n# must eliminate the CFLAGS that are passed in here by default (which\n# may already have debugging and/or optimization flags).  We use\n# post-processed forms of the CFLAGS in the library targets down\n# below.\n\nCFLAGS = $(CFLAGS_WITHOUT_OPTFLAGS) $(DEBUGGER_CFLAGS)\n\n# Source code files\n\nheaders = \\\n        debuggers.h \\\n        ompi_common_dll_defs.h \\\n        msgq_interface.h ompi_msgq_dll_defs.h\n\n# Simple checks to ensure that the DSOs are functional\n\ndlopen_test_SOURCES = dlopen_test.c\ndlopen_test_LDADD = \\\n        $(top_builddir)/ompi/lib@OMPI_LIBMPI_NAME@.la \\\n        $(top_builddir)/opal/lib@OPAL_LIB_PREFIX@open-pal.la\ndlopen_test_DEPENDENCIES = $(ompi_predefined_LDADD)\n\npredefined_gap_test_SOURCES = predefined_gap_test.c\npredefined_gap_test_LDFLAGS = $(WRAPPER_EXTRA_LDFLAGS)\npredefined_gap_test_LDADD = $(top_builddir)/ompi/lib@OMPI_LIBMPI_NAME@.la\npredefined_gap_test_DEPENDENCIES = $(ompi_predefined_LDADD)\n\nlibdebuggers_la_SOURCES = \\\n        $(headers) \\\n        ompi_debuggers.c\nlibdebuggers_la_CPPFLAGS = \\\n        -DOMPI_MSGQ_DLL=\\\"$(ompilibdir)/$(OPAL_DYN_LIB_PREFIX)ompi_dbg_msgq.$(OPAL_DYN_LIB_SUFFIX)\\\" \\\n        -DOMPI_MSGQ_DLL_PREFIX=\\\"$(OPAL_DYN_LIB_PREFIX)ompi_dbg_msgq\\\" \\\n        -DOMPI_MPIHANDLES_DLL_PREFIX=\\\"$(OPAL_DYN_LIB_PREFIX)ompi_dbg_mpihandles\\\"\n\nlibompi_debugger_canary_la_SOURCES = \\\n        ompi_debugger_canary.c\n\ncommon = ompi_common_dll_defs.h ompi_common_dll.c\n\n# MPI message queue DLL\nlibompi_dbg_msgq_la_SOURCES = ompi_msgq_dll.c ompi_msgq_dll_defs.h $(common)\nlibompi_dbg_msgq_la_CFLAGS = -g\nlibompi_dbg_msgq_la_LDFLAGS = -module -avoid-version\n\n# These are checks for the padding on predefined MPI object types.\n# They are here in the debuggers/ directory (vs., for example,\n# runtime/) because a) we already had some canary tests here in this\n# directory, and b) the runtime/ directory is built by subdir objects,\n# and \"make check\" will *build* a test in runtime/, but it won't *run*\n# it.  :-(\npredefined_pad_test_LDFLAGS = $(WRAPPER_EXTRA_LDFLAGS)\npredefined_pad_test_LDADD = $(top_builddir)/ompi/lib@OMPI_LIBMPI_NAME@.la\npredefined_pad_test_DEPENDENCIES = $(ompi_predefined_LDADD)\n\n# Conditionally install the header files\n\nif WANT_INSTALL_HEADERS\nompidir = $(ompiincludedir)/$(subdir)\nompi_HEADERS = $(headers)\nendif\n",
        "/tmp/vanessa/spack-stage/spack-stage-openmpi-master-qcrm7qmgqutvsby2zcmdb57s22lzfq65/spack-src/ompi/debuggers/ompi_msgq_dll.c": "/* -*- Mode: C; c-basic-offset:4 ; indent-tabs-mode:nil -*- */\n/*\n * Copyright (c) 2007-2018 Cisco Systems, Inc.  All rights reserved.\n * Copyright (c) 2004-2010 The University of Tennessee and The University\n *                         of Tennessee Research Foundation.  All rights\n *                         reserved.\n * Copyright (c) 2008-2009 Sun Microsystems, Inc.  All rights reserved.\n * Copyright (c) 2015      Los Alamos National Security, LLC.  All rights\n *                         reserved.\n * Copyright (c) 2016      Intel, Inc. All rights reserved.\n * Copyright (c) 2016      Research Organization for Information Science\n *                         and Technology (RIST). All rights reserved.\n * $COPYRIGHT$\n *\n * Additional copyrights may follow\n *\n * $HEADER$\n */\n\n/**********************************************************************\n * Copyright (C) 2000-2004 by Etnus, LLC.\n * Copyright (C) 1999 by Etnus, Inc.\n * Copyright (C) 1997-1998 Dolphin Interconnect Solutions Inc.\n *\n * Permission is hereby granted to use, reproduce, prepare derivative\n * works, and to redistribute to others.\n *\n *\t\t\t\t  DISCLAIMER\n *\n * Neither Dolphin Interconnect Solutions, Etnus LLC, nor any of their\n * employees, makes any warranty express or implied, or assumes any\n * legal liability or responsibility for the accuracy, completeness,\n * or usefulness of any information, apparatus, product, or process\n * disclosed, or represents that its use would not infringe privately\n * owned rights.\n *\n * This code was written by\n * James Cownie: Dolphin Interconnect Solutions. <jcownie@dolphinics.com>\n *               Etnus LLC <jcownie@etnus.com>\n **********************************************************************/\n\n/* Update log\n *\n * Jul 12 2001 FNW: Add a meaningful ID to the communicator name, and switch\n *                  to using the recv_context as the unique_id field.\n * Mar  6 2001 JHC: Add mqs_get_comm_group to allow a debugger to acquire\n *                  processes less eagerly.\n * Dec 13 2000 JHC: totalview/2514: Modify image_has_queues to return\n *                  a silent FALSE if none of the expected data is\n *                  present. This way you won't get complaints when\n *                  you try this on non MPICH processes.\n * Sep  8 2000 JVD: #include <string.h> to silence Linux Alpha compiler warnings.\n * Mar 21 2000 JHC: Add the new entrypoint mqs_dll_taddr_width\n * Nov 26 1998 JHC: Fix the problem that we weren't handling\n *                  MPIR_Ignore_queues properly.\n * Oct 22 1998 JHC: Fix a zero allocation problem\n * Aug 19 1998 JHC: Fix some problems in our use of target_to_host on\n *                  big endian machines.\n * May 28 1998 JHC: Use the extra information we can return to say\n *                  explicitly that sends are only showing non-blocking ops\n * May 19 1998 JHC: Changed the names of the structs and added casts\n *                  where needed to reflect the change to the way we handle\n *                  type safety across the interface.\n * Oct 27 1997 JHC: Created by exploding db_message_state_mpich.cxx\n */\n\n/*\n   The following was added by William Gropp to improve the portability\n   to systems with non-ANSI C compilers\n */\n\n#include \"ompi_config.h\"\n\n#ifdef HAVE_NO_C_CONST\n#define const\n#endif\n#include <string.h>\n#include <stdlib.h>\n\n/* Notice to developers!!!!\n * The following include files with _dbg.h suffixes contains definitions\n * that are shared between the debuggger plugins and the OMPI code base.\n * This is done instead of including the non-_dbg suffixed files because\n * of the different way compilers may handle extern definitions. The\n * particular case that is causing problems is when there is an extern\n * variable or function that is accessed in a static inline function.\n * For example, here is the code we often see in a header file.\n *\n * extern int request_complete;\n * static inline check_request(void) {\n *    request_complete = 1;\n * }\n *\n * If this code exists in a header file and gets included in a source\n * file, then some compilers expect to have request_complete defined\n * somewhere even if request_complete is never referenced and\n * check_request is never called. Other compilers do not need them defined\n * if they are never referenced in the source file.\n *\n * In the case of extern functions we something like the following:\n *\n * extern int foo();\n * static inline bar(void) {\n *     foo();\n * }\n *\n * If this code exists it actually compiles fine however an undefined symbol\n * is kept for foo() and in the case of some tools that load in plugins with\n * RTLD_NOW this undefined symbol causes the dlopen to fail since we do not\n * have (nor really need) the supporting library containing foo().\n *\n * Therefore, to handle cases like the above with compilers that require the\n * symbols (like Sun Studio) instead of  pulling in all of OMPI into the\n * plugins or defining dummy symbols here we separate the definitions used by\n * both sets of code into the _dbg.h files.\n *\n * This means if one needs to add another definition that the plugins must see\n * one should either move the definition into one of the existing _dbg.h file or\n * create a new _dbg.h file.\n */\n#include \"ompi/group/group_dbg.h\"\n#include \"ompi/request/request_dbg.h\"\n#include \"ompi/mca/pml/base/pml_base_request_dbg.h\"\n#include \"mpi.h\" /* needed for MPI_ANY_TAG */\n\n#include \"msgq_interface.h\"\n#include \"ompi_msgq_dll_defs.h\"\n\n/*\n   End of inclusion\n */\n\n\n/* Essential macros for C */\n#ifndef NULL\n#define NULL ((void *)0)\n#endif\n#ifndef TRUE\n#define TRUE (0==0)\n#endif\n#ifndef FALSE\n#define FALSE (0==1)\n#endif\n\n#ifdef OLD_STYLE_CPP_CONCAT\n#define concat(a,b) a/**/b\n#define stringize(a) \"a\"\n#else\n#define concat(a,b) a##b\n#define stringize(a) #a\n#endif\n\n#define OPAL_ALIGN(x,a,t) (((x)+((t)(a)-1)) & ~(((t)(a)-1)))\n\n/**\n * The internal debugging interface.\n */\n#define VERBOSE_GENERAL  0x00000001\n#define VERBOSE_GROUP    0x00000002\n#define VERBOSE_COMM     0x00000004\n#define VERBOSE_LISTS    0x00000008\n#define VERBOSE_REQ      0x00000010\n#define VERBOSE_REQ_DUMP 0x00000020\n\n#define VERBOSE 0x00000000\n\n#if VERBOSE\n#define DEBUG(LEVEL, WHAT) if(LEVEL & VERBOSE) { printf WHAT; }\n#else\n#define DEBUG(LEVEL,WHAT)\n#endif  /* VERBOSE */\n\n/**********************************************************************/\n/* Set up the basic callbacks into the debugger */\n\nvoid mqs_setup_basic_callbacks (const mqs_basic_callbacks * cb)\n{\n    mqs_basic_entrypoints = cb;\n} /* mqs_setup_callbacks */\n\n\n/**********************************************************************/\n/* Version handling functions.\n * This one should never be changed.\n */\nint mqs_version_compatibility (void)\n{\n    return MQS_INTERFACE_COMPATIBILITY;\n} /* mqs_version_compatibility */\n\nstatic char mqs_version_str[OMPI_MAX_VER_SIZE];\n\n/* This one can say what you like */\nchar *mqs_version_string (void)\n{\n    int offset;\n    offset = snprintf(mqs_version_str, OMPI_MAX_VER_SIZE-1,  \n                      \"Open MPI message queue support for parallel debuggers \");\n    ompi_get_lib_version(mqs_version_str+offset, OMPI_MAX_VER_SIZE-offset);\n    return mqs_version_str;\n} /* mqs_version_string */\n\n/* So the debugger can tell what interface width the library was compiled with */\nint mqs_dll_taddr_width (void)\n{\n    return sizeof (mqs_taddr_t);\n} /* mqs_dll_taddr_width */\n\n/**********************************************************************/\n/* Functions to handle translation groups.\n * We have a list of these on the process info, so that we can\n * share the group between multiple communicators.\n */\n/**********************************************************************/\n/* Translate a process number */\nstatic int translate (group_t *this, int index)\n{\n    if (index == MQS_INVALID_PROCESS ||\n        ((unsigned int)index) >= ((unsigned int) this->entries))\n        return MQS_INVALID_PROCESS;\n    return this->local_to_global[index];\n} /* translate */\n\n/**********************************************************************/\n/* Search the group list for this group, if not found create it.\n */\nstatic group_t * find_or_create_group( mqs_process *proc,\n                                       mqs_taddr_t group_base )\n{\n    mpi_process_info *p_info = (mpi_process_info *)mqs_get_process_info (proc);\n    mpi_process_info_extra *extra = (mpi_process_info_extra*) p_info->extra;\n    mqs_image * image        = mqs_get_image (proc);\n    mpi_image_info *i_info   = (mpi_image_info *)mqs_get_image_info (image);\n    communicator_t *comm     = extra->communicator_list;\n    int *tr;\n    char *trbuffer;\n    int i, np, is_dense;\n    group_t *group;\n    mqs_taddr_t value;\n    mqs_taddr_t tablep;\n\n    np = ompi_fetch_int( proc,\n                         group_base + i_info->ompi_group_t.offset.grp_proc_count,\n                         p_info );\n    if( np < 0 ) {\n        DEBUG(VERBOSE_COMM, (\"Get a size for the communicator = %d\\n\", np));\n        return NULL;  /* Makes no sense ! */\n    }\n    is_dense =\n        ompi_fetch_int( proc,\n                        group_base + i_info->ompi_group_t.offset.grp_flags,\n                        p_info );\n    is_dense = (0 != (is_dense & OMPI_GROUP_DENSE));\n\n    /* Iterate over each communicator seeing if we can find this group */\n    for (;comm; comm = comm->next) {\n        group = comm->group;\n        if( group && (group->group_base == group_base) ) {\n            group->ref_count++;\t\t\t/* Someone else is interested */\n            DEBUG(VERBOSE_GROUP, (\"Increase refcount for group 0x%p to %d\\n\",\n                                  (void*)group, group->ref_count) );\n            return group;\n        }\n    }\n\n    /* Hmm, couldn't find one, so fetch it */\n    group = (group_t *)mqs_malloc (sizeof (group_t));\n    tr = (int *)mqs_malloc (np*sizeof(int));\n    trbuffer = (char *)mqs_malloc (np*sizeof(mqs_taddr_t));\n    group->local_to_global = tr;\n    group->group_base = group_base;\n    DEBUG(VERBOSE_GROUP, (\"Create a new group 0x%p with %d members\\n\",\n                          (void*)group, np) );\n\n    tablep = ompi_fetch_pointer( proc,\n                                 group_base + i_info->ompi_group_t.offset.grp_proc_pointers,\n                                 p_info);\n\n    if( (0 != np) &&\n        (mqs_ok != mqs_fetch_data(proc, tablep, np * p_info->sizes.pointer_size,\n                                  trbuffer)) ) {\n        DEBUG(VERBOSE_GROUP,(\"Failed to read the proc data. Destroy group %p\\n\",\n                             (void*)group));\n        mqs_free (group);\n        mqs_free (tr);\n        mqs_free (trbuffer);\n        return NULL;\n    }\n\n    /**\n     * Now convert the process representation into the local representation.\n     * We will endup with an array of Open MPI internal pointers to proc\n     * structure. By comparing this pointers to the MPI_COMM_WORLD group\n     * we can figure out the global rank in the MPI_COMM_WORLD of the process.\n     *\n     * Note that this only works for dense groups.  Someday we may\n     * support more than dense groups, but that's what we've got for\n     * today.\n     */\n     if( NULL == extra->world_proc_array ) {\n         extra->world_proc_array = mqs_malloc( np * sizeof(mqs_taddr_t) );\n         for( i = 0; i < np; i++ ) {\n             mqs_target_to_host( proc, trbuffer + p_info->sizes.pointer_size*i,\n                                 &value, p_info->sizes.pointer_size );\n             extra->world_proc_array[i] = value;\n             group->local_to_global[i] = is_dense ? i : -1;\n         }\n         extra->world_proc_array_entries = np;\n     } else {\n         int j;\n\n         for( i = 0; i < np; i++ ) {\n             mqs_target_to_host( proc, trbuffer + p_info->sizes.pointer_size*i,\n                                 &value, p_info->sizes.pointer_size );\n             if (is_dense) {\n                 /* get the global rank this MPI process */\n                 for( j = 0; j < extra->world_proc_array_entries; j++ ) {\n                     if( value == extra->world_proc_array[j] ) {\n                         group->local_to_global[i] = j;\n                         break;\n                     }\n                 }\n             } else {\n                 group->local_to_global[i] = -1;\n             }\n         }\n     }\n\n    mqs_free(trbuffer);\n\n    group->entries = np;\n    group->ref_count = 1;\n    return group;\n} /* find_or_create_group */\n\n/***********************************************************************/\nstatic void group_decref (group_t * group)\n{\n    DEBUG(VERBOSE_GROUP, (\"Decrement reference count for group %p to %d\\n\", (void*)group,\n                          (group->ref_count - 1)));\n    if (--(group->ref_count) == 0) {\n        mqs_free (group->local_to_global);\n        DEBUG(VERBOSE_GROUP, (\"Destroy group %p\\n\", (void*)group));\n        mqs_free (group);\n    }\n} /* group_decref */\n\n/***********************************************************************\n * Perform basic setup for the image, we just allocate and clear\n * our info.\n */\nint mqs_setup_image (mqs_image *image, const mqs_image_callbacks *icb)\n{\n    mpi_image_info *i_info = (mpi_image_info *)mqs_malloc (sizeof (mpi_image_info));\n\n    if (!i_info)\n        return err_no_store;\n\n    memset ((void *)i_info, 0, sizeof (mpi_image_info));\n    i_info->image_callbacks = icb;\t\t/* Before we do *ANYTHING* */\n    i_info->extra = NULL;\n\n    mqs_put_image_info (image, (mqs_image_info *)i_info);\n\n    return mqs_ok;\n} /* mqs_setup_image */\n\n\n/***********************************************************************\n * Check for all the information we require to access the Open MPI message queues.\n * Stash it into our structure on the image if we're successful.\n */\n\nint mqs_image_has_queues (mqs_image *image, char **message)\n{\n    mpi_image_info * i_info = (mpi_image_info *)mqs_get_image_info (image);\n\n    i_info->extra = NULL;\n\n    /* Default failure message ! */\n    *message = \"The symbols and types in the Open MPI library used by the debugger\\n\"\n        \"to extract the message queues are not as expected in\\n\"\n        \"the image '%s'\\n\"\n        \"No message queue display is possible.\\n\"\n        \"This is probably an Open MPI version or configuration problem.\";\n\n    /* Force in the file containing our breakpoint function, to ensure\n     * that types have been read from there before we try to look them\n     * up.\n     */\n    mqs_find_function (image, \"ompi_debugger_setup_dlls\", mqs_lang_c, NULL);\n\n    /* Are we supposed to ignore this ? (e.g. it's really an HPF\n     * runtime using the Open MPI process acquisition, but not wanting\n     * queue display)\n     */\n    if (mqs_find_symbol (image, \"MPIR_Ignore_queues\", NULL) == mqs_ok) {\n        *message = NULL;\t\t\t\t/* Fail silently */\n        return err_silent_failure;\n    }\n\n    /* Fill in the type information */\n    return ompi_fill_in_type_info(image, message);\n} /* mqs_image_has_queues */\n\n/***********************************************************************\n * Setup information needed for a specific process.\n * TV assumes that this will hang something onto the process,\n * if nothing is attached to it, then TV will believe that this process\n * has no message queue information.\n */\nint mqs_setup_process (mqs_process *process, const mqs_process_callbacks *pcb)\n{\n    /* Extract the addresses of the global variables we need and save them away */\n    mpi_process_info *p_info = (mpi_process_info *)mqs_malloc (sizeof (mpi_process_info));\n\n    if (p_info) {\n        mqs_image        *image;\n        mpi_image_info   *i_info;\n        mpi_process_info_extra *extra;\n\n        p_info->process_callbacks = pcb;\n\n        p_info->extra = mqs_malloc(sizeof(mpi_process_info_extra));\n        extra = (mpi_process_info_extra*) p_info->extra;\n\n        /* Now we can get the rest of the info ! */\n        image  = mqs_get_image (process);\n        i_info   = (mpi_image_info *)mqs_get_image_info (image);\n\n        /* We have no communicators yet */\n        extra->communicator_list = NULL;\n        /* Enforce the generation of the communicators list */\n        extra->comm_lowest_free  = 0;\n        extra->comm_number_free  = 0;\n        /* By default we don't show our internal requests*/\n        extra->show_internal_requests = 0;\n\n        extra->world_proc_array_entries = 0;\n        extra->world_proc_array = NULL;\n\n        mqs_get_type_sizes (process, &p_info->sizes);\n        /*\n         * Before going any further make sure we know exactly how the\n         * Open MPI library was compiled. This means we know the size\n         * of each of the basic types as stored in the\n         * MPIR_debug_typedefs_sizeof array.\n         */\n        {\n            mqs_taddr_t typedefs_sizeof;\n\n            if (mqs_find_symbol (image, \"MPIR_debug_typedefs_sizeof\", &typedefs_sizeof) != mqs_ok) {\n                return err_no_store;\n            }\n            p_info->sizes.short_size = ompi_fetch_int( process, /* sizeof (short) */\n                                                       typedefs_sizeof,\n                                                       p_info );\n            typedefs_sizeof += p_info->sizes.int_size;\n            p_info->sizes.int_size = ompi_fetch_int( process, /* sizeof (int) */\n                                                     typedefs_sizeof,\n                                                     p_info );\n            typedefs_sizeof += p_info->sizes.int_size;\n             p_info->sizes.long_size = ompi_fetch_int( process, /* sizeof (long) */\n                                                       typedefs_sizeof,\n                                                       p_info );\n            typedefs_sizeof += p_info->sizes.int_size;\n            p_info->sizes.long_long_size = ompi_fetch_int( process, /* sizeof (long long) */\n                                                           typedefs_sizeof,\n                                                           p_info );\n            typedefs_sizeof += p_info->sizes.int_size;\n            p_info->sizes.pointer_size = ompi_fetch_int( process, /* sizeof (void *) */\n                                                         typedefs_sizeof,\n                                                         p_info );\n            typedefs_sizeof += p_info->sizes.int_size;\n            p_info->sizes.bool_size = ompi_fetch_int( process, /* sizeof (bool) */\n                                                      typedefs_sizeof,\n                                                      p_info );\n            typedefs_sizeof += p_info->sizes.int_size;\n            p_info->sizes.size_t_size = ompi_fetch_int( process, /* sizeof (size_t) */\n                                                        typedefs_sizeof,\n                                                        p_info );\n            DEBUG( VERBOSE_GENERAL,\n                   (\"sizes short = %d int = %d long = %d long long = %d \"\n                    \"void* = %d bool = %d size_t = %d\\n\",\n                    p_info->sizes.short_size, p_info->sizes.int_size,\n                    p_info->sizes.long_size, p_info->sizes.long_long_size,\n                    p_info->sizes.pointer_size, p_info->sizes.bool_size,\n                    p_info->sizes.size_t_size) );\n        }\n\n        mqs_put_process_info (process, (mqs_process_info *)p_info);\n\n        return mqs_ok;\n    }\n    return err_no_store;\n} /* mqs_setup_process */\n\n/***********************************************************************\n * Check the process for message queues.\n */\nint mqs_process_has_queues (mqs_process *proc, char **msg)\n{\n    mpi_process_info *p_info = (mpi_process_info *)mqs_get_process_info (proc);\n    mpi_process_info_extra *extra = (mpi_process_info_extra*) p_info->extra;\n    mqs_image * image        = mqs_get_image (proc);\n    mpi_image_info   *i_info = (mpi_image_info *)mqs_get_image_info (image);\n\n    /* Don't bother with a pop up here, it's unlikely to be helpful */\n    *msg = 0;\n    DEBUG(VERBOSE_GENERAL,(\"checking the status of the OMPI dll\\n\"));\n    if (mqs_find_symbol (image, \"ompi_mpi_communicators\", &extra->commlist_base) != mqs_ok)\n        return err_all_communicators;\n\n    if (mqs_find_symbol (image, \"mca_pml_base_send_requests\", &extra->send_queue_base) != mqs_ok)\n        return err_mpid_sends;\n\n    if (mqs_find_symbol (image, \"mca_pml_base_recv_requests\", &extra->recv_queue_base) != mqs_ok)\n        return err_mpid_recvs;\n    DEBUG(VERBOSE_GENERAL,(\"process_has_queues returned success\\n\"));\n    return mqs_ok;\n} /* mqs_process_has_queues */\n\n/***********************************************************************\n * Check if the communicators have changed by looking at the\n * pointer array values for lowest_free and number_free.\n */\nstatic int communicators_changed (mqs_process *proc)\n{\n    mpi_process_info *p_info = (mpi_process_info *)mqs_get_process_info (proc);\n    mpi_process_info_extra *extra = (mpi_process_info_extra*) p_info->extra;\n    mqs_image * image          = mqs_get_image (proc);\n    mpi_image_info *i_info   = (mpi_image_info *)mqs_get_image_info (image);\n    mqs_tword_t number_free;         /* the number of available positions in\n                                      * the communicator array. */\n    mqs_tword_t lowest_free;         /* the lowest free communicator */\n\n    lowest_free = ompi_fetch_int( proc,\n                                  extra->commlist_base + i_info->opal_pointer_array_t.offset.lowest_free,\n                                  p_info );\n    number_free = ompi_fetch_int( proc,\n                                  extra->commlist_base + i_info->opal_pointer_array_t.offset.number_free,\n                                  p_info );\n    if( (lowest_free != extra->comm_lowest_free) ||\n        (number_free != extra->comm_number_free) ) {\n        DEBUG(VERBOSE_COMM, (\"Recreate the communicator list\\n\"\n                             \"    lowest_free [current] %d != [stored] %d\\n\"\n                             \"    number_free [current] %d != [stored] %d\\n\",\n                             (int)lowest_free, (int)extra->comm_lowest_free,\n                             (int)number_free, (int)extra->comm_number_free) );\n        return 1;\n    }\n    DEBUG(VERBOSE_COMM, (\"Communicator list not modified\\n\") );\n    return 0;\n} /* mqs_communicators_changed */\n\n/***********************************************************************\n * Find a matching communicator on our list. We check the recv context\n * as well as the address since the communicator structures may be\n * being re-allocated from a free list, in which case the same\n * address will be re-used a lot, which could confuse us.\n */\nstatic communicator_t * find_communicator( mpi_process_info *p_info,\n                                           int recv_ctx )\n{\n    mpi_process_info_extra *extra = (mpi_process_info_extra*) p_info->extra;\n    communicator_t * comm = extra->communicator_list;\n\n    for( ; comm; comm = comm->next ) {\n        if( comm->comm_info.unique_id == (mqs_taddr_t)recv_ctx )\n            return comm;\n    }\n\n    return NULL;\n} /* find_communicator */\n\n/***********************************************************************\n * Comparison function for sorting communicators.\n */\nstatic int compare_comms (const void *a, const void *b)\n{\n    communicator_t * ca = *(communicator_t **)a;\n    communicator_t * cb = *(communicator_t **)b;\n\n    return cb->comm_info.unique_id - ca->comm_info.unique_id;\n} /* compare_comms */\n\n/***********************************************************************\n * Rebuild our list of communicators because something has changed\n */\nstatic int rebuild_communicator_list (mqs_process *proc)\n{\n    mpi_process_info *p_info = (mpi_process_info *)mqs_get_process_info (proc);\n    mpi_process_info_extra *extra = (mpi_process_info_extra*) p_info->extra;\n    mqs_image * image        = mqs_get_image (proc);\n    mpi_image_info *i_info   = (mpi_image_info *)mqs_get_image_info (image);\n    communicator_t **commp, *old;\n    int i, commcount = 0, context_id;\n    mqs_tword_t comm_size, lowest_free, number_free;\n    mqs_taddr_t comm_addr_base;\n    mqs_taddr_t comm_ptr;\n\n    DEBUG(VERBOSE_COMM,(\"rebuild_communicator_list called \"\n                        \"(commlist_base %llx, array offset %ld array size %d)\\n\",\n                        (long long)extra->commlist_base,\n                        (long)i_info->opal_pointer_array_t.offset.addr,\n                        i_info->opal_pointer_array_t.size));\n    /**\n     * Start by getting the number of registered communicators in the\n     * global communicator array.\n     */\n    comm_size = ompi_fetch_int( proc,\n                                extra->commlist_base + i_info->opal_pointer_array_t.offset.size,\n                                p_info );\n    lowest_free = ompi_fetch_int( proc,\n                                  extra->commlist_base + i_info->opal_pointer_array_t.offset.lowest_free,\n                                  p_info );\n    number_free = ompi_fetch_int( proc,\n                                  extra->commlist_base + i_info->opal_pointer_array_t.offset.number_free,\n                                  p_info );\n    extra->comm_lowest_free = lowest_free;\n    extra->comm_number_free = number_free;\n\n    DEBUG(VERBOSE_COMM,(\"Number of coms %d lowest_free %d number_free %d\\n\",\n                        (int)comm_size, (int)lowest_free, (int)number_free));\n    /* In Open MPI the MPI_COMM_WORLD is always at index 0. By default, the\n     * MPI_COMM_WORLD will never get modified. Except, when the fault tolerance\n     * features are enabled in Open MPI. Therefore, we will regenerate the\n     * list of proc pointers every time we rescan the communicators list.\n     * We can use the fact that MPI_COMM_WORLD is at index 0 to force the\n     * creation of the world_proc_array.\n     */\n    extra->world_proc_array_entries = 0;\n    mqs_free( extra->world_proc_array );\n    extra->world_proc_array = NULL;\n\n    /* Now get the pointer to the array of pointers to communicators */\n    comm_addr_base =\n        ompi_fetch_pointer( proc,\n                            extra->commlist_base + i_info->opal_pointer_array_t.offset.addr,\n                            p_info );\n    DEBUG(VERBOSE_COMM,(\"Array of communicators starting at 0x%llx (sizeof(mqs_taddr_t*) = %d)\\n\",\n                        (long long)comm_addr_base, (int)sizeof(mqs_taddr_t)));\n    for( i = 0; (commcount < (comm_size - number_free)) && (i < comm_size); i++ ) {\n        /* Get the communicator pointer */\n        comm_ptr =\n            ompi_fetch_pointer( proc,\n                                comm_addr_base + i * p_info->sizes.pointer_size,\n                                p_info );\n        DEBUG(VERBOSE_GENERAL,(\"Fetch communicator pointer 0x%llx\\n\", (long long)comm_ptr));\n        if( 0 == comm_ptr ) continue;\n        commcount++;\n        /* Now let's grab the data we want from inside */\n        DEBUG(VERBOSE_GENERAL, (\"Retrieve context_id from 0x%llx and local_rank from 0x%llx\\n\",\n                                (long long)(comm_ptr + i_info->ompi_communicator_t.offset.c_contextid),\n                                (long long)(comm_ptr + i_info->ompi_communicator_t.offset.c_my_rank)));\n        context_id = ompi_fetch_int( proc,\n                                     comm_ptr + i_info->ompi_communicator_t.offset.c_contextid,\n                                     p_info );\n        /* Do we already have this communicator ? */\n        old = find_communicator(p_info, context_id);\n        if( NULL == old ) {\n            mqs_taddr_t group_base;\n\n            old = (communicator_t *)mqs_malloc (sizeof (communicator_t));\n            /* Save the results */\n            old->next                 = extra->communicator_list;\n            extra->communicator_list = old;\n            old->comm_ptr             = comm_ptr;\n            old->comm_info.unique_id  = context_id;\n            old->comm_info.local_rank = ompi_fetch_int(proc,\n                                                       comm_ptr + i_info->ompi_communicator_t.offset.c_my_rank,\n                                                       p_info);\n            old->group = NULL;\n\n            DEBUG(VERBOSE_COMM,(\"Create new communicator 0x%lx with context_id %d and local_rank %d\\n\",\n                                (long)old, context_id, local_rank));\n            /* Now get the information about the group */\n            group_base =\n                ompi_fetch_pointer( proc, comm_ptr + i_info->ompi_communicator_t.offset.c_local_group,\n                                    p_info );\n            old->group = find_or_create_group( proc, group_base );\n        }\n        mqs_fetch_data( proc, comm_ptr + i_info->ompi_communicator_t.offset.c_name,\n                        64, old->comm_info.name );\n\n        if( NULL != old->group ) {\n            old->comm_info.size = old->group->entries;\n        }\n        old->present = TRUE;\n        DEBUG(VERBOSE_COMM,(\"Communicator 0x%llx %d local_rank %d name %s group %p\\n\",\n                            (long long)old->comm_ptr, (int)old->comm_info.unique_id,\n                            (int)old->comm_info.local_rank, old->comm_info.name,\n                            (void*)old->group));\n    }\n\n    /* Now iterate over the list tidying up any communicators which\n     * no longer exist, and cleaning the flags on any which do.\n     */\n    commp = &extra->communicator_list;\n    commcount = 0;\n    for (; *commp; ) {\n        communicator_t *comm = *commp;\n        if (comm->present) {\n            comm->present = FALSE;\n            commcount++;\n            DEBUG(VERBOSE_COMM, (\"Keep communicator 0x%llx name %s\\n\",\n                                 (long long)comm->comm_ptr, comm->comm_info.name));\n            commp = &(*commp)->next;        /* go to the next communicator */\n        } else { /* It needs to be deleted */\n            *commp = comm->next;\t\t\t/* Remove from the list, *commp now points to the next */\n            DEBUG(VERBOSE_COMM, (\"Remove communicator 0x%llx name %s (group %p)\\n\",\n                                 (long long)comm->comm_ptr, comm->comm_info.name,\n                                 (void*)comm->group));\n            group_decref (comm->group);\t\t/* Group is no longer referenced from here */\n            mqs_free (comm);\n        }\n    }\n\n    if (commcount) {\n        /* Sort the list so that it is displayed in some semi-sane order. */\n        communicator_t ** comm_array =\n            (communicator_t **) mqs_malloc(commcount * sizeof (communicator_t *));\n        communicator_t *comm = extra->communicator_list;\n\n        for (i=0; i<commcount; i++, comm=comm->next)\n            comm_array [i] = comm;\n\n        /* Do the sort */\n        qsort (comm_array, commcount, sizeof (communicator_t *), compare_comms);\n\n        /* Rebuild the list */\n        extra->communicator_list = NULL;\n        for (i=0; i<commcount; i++) {\n            comm = comm_array[i];\n            comm->next = extra->communicator_list;\n            extra->communicator_list = comm;\n        }\n\n        mqs_free (comm_array);\n    }\n\n    return mqs_ok;\n} /* rebuild_communicator_list */\n\n/***********************************************************************\n * Update the list of communicators in the process if it has changed.\n */\nint mqs_update_communicator_list (mqs_process *proc)\n{\n    if (communicators_changed (proc))\n        return rebuild_communicator_list (proc);\n    return mqs_ok;\n} /* mqs_update_communicator_list */\n\n/***********************************************************************\n * Setup to iterate over communicators.\n * This is where we check whether our internal communicator list needs\n * updating and if so do it.\n */\nint mqs_setup_communicator_iterator (mqs_process *proc)\n{\n    mpi_process_info *p_info = (mpi_process_info *)mqs_get_process_info (proc);\n    mpi_process_info_extra *extra = (mpi_process_info_extra*) p_info->extra;\n\n    /* Start at the front of the list again */\n    extra->current_communicator = extra->communicator_list;\n    /* Reset the operation iterator too */\n    extra->next_msg.free_list            = 0;\n    extra->next_msg.current_item         = 0;\n    extra->next_msg.opal_list_t_pos.list = 0;\n\n    DEBUG(VERBOSE_COMM,(\"mqs_setup_communicator_iterator called\\n\"));\n    return extra->current_communicator == NULL ? mqs_end_of_list : mqs_ok;\n} /* mqs_setup_communicator_iterator */\n\n/***********************************************************************\n * Fetch information about the current communicator.\n */\nint mqs_get_communicator (mqs_process *proc, mqs_communicator *comm)\n{\n    mpi_process_info *p_info = (mpi_process_info *)mqs_get_process_info (proc);\n    mpi_process_info_extra *extra = (mpi_process_info_extra*) p_info->extra;\n\n    if (extra->current_communicator) {\n        *comm = extra->current_communicator->comm_info;\n        DEBUG(VERBOSE_COMM,(\"mqs_get_communicator %d local_rank %d name %s\\n\",\n                            (int)comm->unique_id, (int)comm->local_rank,\n                            comm->name));\n        return mqs_ok;\n    }\n    DEBUG(VERBOSE_COMM,(\"No more communicators for this iteration\\n\"));\n    return err_no_current_communicator;\n} /* mqs_get_communicator */\n\n/***********************************************************************\n * Get the group information about the current communicator.\n */\nint mqs_get_comm_group (mqs_process *proc, int *group_members)\n{\n    mpi_process_info *p_info = (mpi_process_info *)mqs_get_process_info (proc);\n    mpi_process_info_extra *extra = (mpi_process_info_extra*) p_info->extra;\n    communicator_t     *comm   = extra->current_communicator;\n\n    if (comm && comm->group) {\n        group_t * g = comm->group;\n        int i;\n\n        for (i=0; i<g->entries; i++)\n            group_members[i] = g->local_to_global[i];\n\n        return mqs_ok;\n    }\n    return err_no_current_communicator;\n} /* mqs_get_comm_group */\n\n/***********************************************************************\n * Step to the next communicator.\n */\nint mqs_next_communicator (mqs_process *proc)\n{\n    mpi_process_info *p_info = (mpi_process_info *)mqs_get_process_info (proc);\n    mpi_process_info_extra *extra = (mpi_process_info_extra*) p_info->extra;\n\n    extra->current_communicator = extra->current_communicator->next;\n    return (extra->current_communicator != NULL) ? mqs_ok : mqs_end_of_list;\n} /* mqs_next_communicator */\n\n/**\n * Parsing the opal_list_t.\n */\nstatic int opal_list_t_init_parser( mqs_process *proc, mpi_process_info *p_info,\n                                    mqs_opal_list_t_pos* position, mqs_taddr_t list )\n{\n    mqs_image * image        = mqs_get_image (proc);\n    mpi_image_info *i_info   = (mpi_image_info *)mqs_get_image_info (image);\n\n    position->list = list;\n    position->sentinel = position->list + i_info->opal_list_t.offset.opal_list_sentinel;\n    position->current_item =\n        ompi_fetch_pointer( proc, position->sentinel + i_info->opal_list_item_t.offset.opal_list_next,\n                            p_info );\n    if( position->current_item == position->sentinel )\n        position->current_item = 0;\n    DEBUG(VERBOSE_LISTS,(\"opal_list_t_init_parser list = 0x%llx, sentinel = 0x%llx, \"\n                         \"current_item = 0x%llx\\n\", (long long)position->list,\n                         (long long)position->sentinel, (long long)position->current_item));\n    return mqs_ok;\n}\n\nstatic int next_item_opal_list_t( mqs_process *proc, mpi_process_info *p_info,\n                                  mqs_opal_list_t_pos* position, mqs_taddr_t* active_item )\n{\n    mqs_image * image        = mqs_get_image (proc);\n    mpi_image_info *i_info   = (mpi_image_info *)mqs_get_image_info (image);\n\n    *active_item = position->current_item;\n    if( 0 == position->current_item )\n        return mqs_end_of_list;\n\n    position->current_item =\n        ompi_fetch_pointer( proc,\n                            position->current_item + i_info->opal_list_item_t.offset.opal_list_next,\n                            p_info );\n    if( position->current_item == position->sentinel )\n        position->current_item = 0;\n    return mqs_ok;\n}\n\n#if defined(CODE_NOT_USED)\n/**\n * Parsing the opal_free_list lists.\n */\nstatic void opal_free_list_t_dump_position( mqs_opal_free_list_t_pos* position )\n{\n    printf( \"position->opal_list_t_pos.current_item = 0x%llx\\n\", (long long)position->opal_list_t_pos.current_item );\n    printf( \"position->opal_list_t_pos.list         = 0x%llx\\n\", (long long)position->opal_list_t_pos.list );\n    printf( \"position->opal_list_t_pos.sentinel     = 0x%llx\\n\", (long long)position->opal_list_t_pos.sentinel );\n    printf( \"position->current_item                 = 0x%llx\\n\", (long long)position->current_item );\n    printf( \"position->upper_bound                  = 0x%llx\\n\", (long long)position->upper_bound );\n    printf( \"position->header_space                 = %llx\\n\", (long long)position->header_space );\n    printf( \"position->free_list                    = 0x%llx\\n\", (long long)position->free_list );\n    printf( \"position->fl_frag_class                = 0x%llx\\n\", (long long)position->fl_frag_class );\n    printf( \"position->fl_mpool                     = 0x%llx\\n\", (long long)position->fl_mpool );\n    printf( \"position->fl_frag_size                 = %llx\\n\", (long long)position->fl_frag_size );\n    printf( \"position->fl_frag_alignment            = %llx\\n\", (long long)position->fl_frag_alignment );\n    printf( \"position->fl_num_per_alloc             = %llx\\n\", (long long)position->fl_num_per_alloc );\n    printf( \"position->fl_num_allocated             = %llx\\n\", (long long)position->fl_num_allocated );\n    printf( \"position->fl_num_initial_alloc         = %llx\\n\", (long long)position->fl_num_initial_alloc );\n}\n#endif  /* CODE_NOT_USED */\n\nstatic int opal_free_list_t_init_parser( mqs_process *proc, mpi_process_info *p_info,\n                                         mqs_opal_free_list_t_pos* position, mqs_taddr_t free_list )\n{\n    mqs_image * image          = mqs_get_image (proc);\n    mpi_image_info *i_info   = (mpi_image_info *)mqs_get_image_info (image);\n    mqs_taddr_t active_allocation;\n\n    position->free_list = free_list;\n\n    position->fl_frag_size =\n        ompi_fetch_size_t( proc, position->free_list + i_info->opal_free_list_t.offset.fl_frag_size,\n                           p_info );\n    position->fl_frag_alignment =\n        ompi_fetch_size_t( proc, position->free_list + i_info->opal_free_list_t.offset.fl_frag_alignment,\n                           p_info );\n    position->fl_frag_class =\n        ompi_fetch_pointer( proc, position->free_list + i_info->opal_free_list_t.offset.fl_frag_class,\n                            p_info );\n    position->fl_mpool =\n        ompi_fetch_pointer( proc, position->free_list + i_info->opal_free_list_t.offset.fl_mpool,\n                            p_info );\n    position->fl_num_per_alloc =\n        ompi_fetch_size_t( proc, position->free_list + i_info->opal_free_list_t.offset.fl_num_per_alloc,\n                           p_info );\n    position->fl_num_allocated =\n        ompi_fetch_size_t( proc, position->free_list + i_info->opal_free_list_t.offset.fl_num_allocated,\n                           p_info );\n\n    if( 0 == position->fl_mpool ) {\n        position->header_space = position->fl_frag_size;\n    } else {\n        DEBUG(VERBOSE_GENERAL, (\"BLAH !!! (CORRECT ME)\\n\"));\n        position->header_space = position->fl_frag_size;\n    }\n    position->header_space = OPAL_ALIGN( position->header_space,\n                                         position->fl_frag_alignment, mqs_taddr_t );\n\n    /**\n     * Work around the strange opal_free_list_t way to allocate elements. The first chunk is\n     * not required to have the same size as the others.\n     * A similar work around should be set for the last chunk of allocations too !!! But how\n     * can we solve ONE equation with 2 unknowns ?\n     */\n    if( position->fl_num_allocated <= position->fl_num_per_alloc ) {\n        position->fl_num_initial_alloc = position->fl_num_allocated;\n    } else {\n        position->fl_num_initial_alloc = position->fl_num_allocated % position->fl_num_per_alloc;\n        if( 0 == position->fl_num_initial_alloc )\n            position->fl_num_initial_alloc = position->fl_num_per_alloc;\n    }\n    DEBUG(VERBOSE_LISTS,(\"opal_free_list_t fl_frag_size = %lld fl_header_space = %lld\\n\"\n                         \"                 fl_frag_alignment = %lld fl_num_per_alloc = %lld\\n\"\n                         \"                 fl_num_allocated = %lld fl_num_initial_alloc = %lld\\n\"\n                         \"                 header_space = %lld\\n\",\n                         (long long)position->fl_frag_size, (long long)position->header_space,\n                         (long long)position->fl_frag_alignment, (long long)position->fl_num_per_alloc,\n                         (long long)position->fl_num_allocated, (long long)position->fl_num_initial_alloc,\n                         (long long)position->header_space));\n\n    /**\n     * Initialize the pointer to the opal_list_t.\n     */\n    opal_list_t_init_parser( proc, p_info, &position->opal_list_t_pos,\n                             position->free_list + i_info->opal_free_list_t.offset.fl_allocations );\n    next_item_opal_list_t( proc, p_info, &position->opal_list_t_pos, &active_allocation );\n    DEBUG(VERBOSE_LISTS,(\"active_allocation 0x%llx header_space %d\\n\",\n                         (long long)active_allocation, (int)position->header_space));\n    if( 0 == active_allocation ) {  /* the end of the list */\n        position->upper_bound = 0;\n    } else {\n        /**\n         * Handle alignment issues...\n         */\n        active_allocation += i_info->opal_free_list_item_t.size;\n        active_allocation = OPAL_ALIGN( active_allocation,\n                                        position->fl_frag_alignment, mqs_taddr_t );\n        /**\n         * Now let's try to compute the upper bound ...\n         */\n        position->upper_bound =\n            position->fl_num_initial_alloc * position->header_space + active_allocation;\n        DEBUG(VERBOSE_LISTS,(\"there are some elements in the list \"\n                             \"active_allocation = %llx upper_bound = %llx\\n\",\n                             (long long)active_allocation, (long long)position->upper_bound));\n    }\n    position->current_item = active_allocation;\n\n    /*opal_free_list_t_dump_position( position );*/\n    return mqs_ok;\n}\n\n/**\n * Return the current position and move the internal counter to the next element.\n */\nstatic int opal_free_list_t_next_item( mqs_process *proc, mpi_process_info *p_info,\n                                       mqs_opal_free_list_t_pos* position, mqs_taddr_t* active_item )\n{\n    mqs_image * image          = mqs_get_image (proc);\n    mpi_image_info *i_info   = (mpi_image_info *)mqs_get_image_info (image);\n    mqs_taddr_t active_allocation;\n\n    *active_item = position->current_item;\n    if( 0 == position->current_item )  /* the end ... */\n        return mqs_ok;\n\n    position->current_item += position->header_space;\n    if( position->current_item >= position->upper_bound ) {\n        DEBUG(VERBOSE_LISTS,(\"Reach the end of one of the opal_free_list_t \"\n                             \"allocations. Go to the next one\\n\"));\n        /* we should go to the next allocation */\n        next_item_opal_list_t( proc, p_info,\n                               &position->opal_list_t_pos, &active_allocation );\n        if( 0 == active_allocation ) { /* we're at the end */\n            position->current_item = 0;\n            return mqs_ok;\n        }\n        /**\n         * Handle alignment issues...\n         */\n        active_allocation += i_info->opal_free_list_item_t.size;\n        active_allocation = OPAL_ALIGN( active_allocation,\n                                        position->fl_frag_alignment, mqs_taddr_t );\n        /**\n         * Now let's try to compute the upper bound ...\n         */\n        position->upper_bound =\n            position->fl_num_per_alloc * position->header_space + active_allocation;\n        position->current_item = active_allocation;\n        DEBUG(VERBOSE_LISTS,(\"there are more elements in the list \"\n                             \"active_allocation = %llx upper_bound = %llx\\n\",\n                             (long long)active_allocation, (long long)position->upper_bound));\n        /*opal_free_list_t_dump_position( position );*/\n    }\n    DEBUG(VERBOSE_LISTS,(\"Free list actual position 0x%llx next element at 0x%llx\\n\",\n                         (long long)*active_item, (long long)position->current_item));\n    return mqs_ok;\n}\n\nstatic void dump_request( mqs_taddr_t current_item, mqs_pending_operation *res )\n{\n    if(!(VERBOSE_REQ_DUMP & VERBOSE)) return;\n    printf( \"\\n+===============================================+\\n\"\n            \"|Request 0x%llx contain \\n\"\n            \"|    res->status              = %d\\n\"\n            \"|    res->desired_local_rank  = %ld\\n\"\n            \"|    res->desired_global_rank = %ld\\n\"\n            \"|    res->tag_wild            = %ld\\n\"\n            \"|    res->desired_tag         = %ld\\n\"\n            \"|    res->system_buffer       = %s\\n\"\n            \"|    res->buffer              = 0x%llx\\n\"\n            \"|    res->desired_length      = %ld\\n\",\n        (long long)current_item, res->status, (long)res->desired_local_rank,\n        (long)res->desired_global_rank, (long)res->tag_wild, (long)res->desired_tag,\n        (TRUE == res->system_buffer ? \"TRUE\" : \"FALSE\"), (long long)res->buffer,\n        (long)res->desired_length );\n\n    if( res->status > mqs_st_pending ) {\n        printf( \"|    res->actual_length       = %ld\\n\"\n                \"|    res->actual_tag          = %ld\\n\"\n                \"|    res->actual_local_rank   = %ld\\n\"\n                \"|    res->actual_global_rank  = %ld\\n\",\n                (long)res->actual_length, (long)res->actual_tag,\n                (long)res->actual_local_rank, (long)res->actual_global_rank );\n    }\n    if( '\\0' != res->extra_text[0][0] )\n        printf( \"|    extra[0] = %s\\n\", res->extra_text[0] );\n    if( '\\0' != res->extra_text[1][0] )\n        printf( \"|    extra[1] = %s\\n\", res->extra_text[1] );\n    if( '\\0' != res->extra_text[2][0] )\n        printf( \"|    extra[2] = %s\\n\", res->extra_text[2] );\n    if( '\\0' != res->extra_text[3][0] )\n        printf( \"|    extra[3] = %s\\n\", res->extra_text[3] );\n    if( '\\0' != res->extra_text[4][0] )\n        printf( \"|    extra[4] = %s\\n\", res->extra_text[4] );\n    printf( \"+===============================================+\\n\\n\" );\n}\n\n/**\n * Handle the send queue as well as the receive queue. The unexpected queue\n * is a whole different story ...\n */\nstatic int fetch_request( mqs_process *proc, mpi_process_info *p_info,\n                          mqs_pending_operation *res, int look_for_user_buffer )\n{\n    mqs_image * image        = mqs_get_image (proc);\n    mpi_image_info *i_info   = (mpi_image_info *)mqs_get_image_info (image);\n    mqs_taddr_t current_item;\n    mqs_tword_t req_complete, req_pml_complete, req_valid, req_type;\n    mqs_taddr_t req_buffer, req_comm;\n    mpi_process_info_extra *extra = (mpi_process_info_extra*) p_info->extra;\n\n    /* If we get a PML request with an internal tag we will jump back here */\n  rescan_requests:\n    while( 1 ) {\n        opal_free_list_t_next_item( proc, p_info,\n                                    &extra->next_msg, &current_item );\n        if( 0 == current_item ) {\n            DEBUG(VERBOSE_REQ,(\"no more items in the %s request queue\\n\",\n                               look_for_user_buffer ? \"receive\" : \"send\" ));\n            return mqs_end_of_list;\n        }\n        req_valid = ompi_fetch_int( proc, current_item + i_info->ompi_request_t.offset.req_state, p_info );\n        if( OMPI_REQUEST_INVALID == req_valid ) continue;\n        req_comm = ompi_fetch_pointer( proc, current_item + i_info->mca_pml_base_request_t.offset.req_comm, p_info );\n        if( extra->current_communicator->comm_ptr == req_comm ) break;\n        DEBUG(VERBOSE_REQ,(\"unmatched request (0x%llx) req_comm = %llx current_com = %llx\\n\",\n                           (long long)current_item, (long long)req_comm,\n                           (long long)extra->current_communicator->comm_ptr));\n    }\n\n    res->extra_text[0][0] = 0; res->extra_text[1][0] = 0; res->extra_text[2][0] = 0;\n    res->extra_text[3][0] = 0; res->extra_text[4][0] = 0;\n\n    req_type = ompi_fetch_int( proc, current_item + i_info->ompi_request_t.offset.req_type, p_info );\n    if( OMPI_REQUEST_PML == req_type ) {\n        mqs_taddr_t ompi_datatype;\n        char data_name[64];\n\n        /**\n         * First retrieve the tag. If the tag is negative and the user didn't\n         * request the internal requests information then move along.\n         */\n        res->desired_tag =\n            ompi_fetch_int( proc, current_item + i_info->mca_pml_base_request_t.offset.req_tag, p_info );\n        if( MPI_ANY_TAG == (int)res->desired_tag ) {\n            res->tag_wild = TRUE;\n        } else {\n            /* Don't allow negative tags to show up */\n            if( ((int)res->desired_tag < 0) && (0 == extra->show_internal_requests) )\n                goto rescan_requests;\n            res->tag_wild = FALSE;\n        }\n\n        req_type =\n            ompi_fetch_int( proc, current_item + i_info->mca_pml_base_request_t.offset.req_type,\n                            p_info);\n        req_complete =\n            ompi_fetch_bool( proc,\n                             current_item + i_info->ompi_request_t.offset.req_complete,\n                             p_info );\n        req_pml_complete =\n            ompi_fetch_bool( proc,\n                             current_item + i_info->mca_pml_base_request_t.offset.req_pml_complete,\n                             p_info );\n        res->status = (0 == req_complete ? mqs_st_pending : mqs_st_complete);\n\n        res->desired_local_rank  = ompi_fetch_int( proc, current_item + i_info->mca_pml_base_request_t.offset.req_peer, p_info );\n        res->desired_global_rank = translate( extra->current_communicator->group,\n                                              res->desired_local_rank );\n\n        res->buffer = ompi_fetch_pointer( proc, current_item + i_info->mca_pml_base_request_t.offset.req_addr,\n                                     p_info );\n        /* Set this to true if it's a buffered request */\n        res->system_buffer = FALSE;\n\n        /* The pointer to the request datatype */\n        ompi_datatype =\n            ompi_fetch_pointer( proc,\n                                current_item + i_info->mca_pml_base_request_t.offset.req_datatype, p_info );\n        /* Retrieve the count as specified by the user */\n        res->desired_length =\n            ompi_fetch_size_t( proc,\n                               ompi_datatype + i_info->ompi_datatype_t.offset.size,\n                               p_info );\n        /* Be user friendly, show the datatype name */\n        mqs_fetch_data( proc, ompi_datatype + i_info->ompi_datatype_t.offset.name,\n                        64, data_name );\n        if( '\\0' != data_name[0] ) {\n            // res->extra_text[x] is only 64 chars long -- same as\n            // data_name.  If you try to snprintf it into\n            // res->extra_text with additional text, some compilers\n            // will warn that we might truncate the string (because it\n            // can see the static char array lengths).  So just put\n            // data_name in res->extra_text[2] (vs. extra_text[1]),\n            // where it is guaranteed to fit.\n            data_name[4] = '\\0';\n            snprintf( (char*)res->extra_text[1], 64, \"Data: %d\",\n                      (int)res->desired_length);\n            snprintf( (char*)res->extra_text[2], 64, \"%s\",\n                      data_name );\n        }\n        /* And now compute the real length as specified by the user */\n        res->desired_length *=\n            ompi_fetch_size_t( proc,\n                               current_item + i_info->mca_pml_base_request_t.offset.req_count,\n                               p_info );\n\n        if( MCA_PML_REQUEST_SEND == req_type ) {\n            snprintf( (char *)res->extra_text[0], 64, \"Send: 0x%llx\", (long long)current_item );\n            req_buffer =\n                ompi_fetch_pointer( proc,\n                                    current_item + i_info->mca_pml_base_send_request_t.offset.req_addr,\n                                    p_info );\n            res->system_buffer = ( req_buffer == res->buffer ? FALSE : TRUE );\n            res->actual_length =\n                ompi_fetch_size_t( proc,\n                                   current_item + i_info->mca_pml_base_send_request_t.offset.req_bytes_packed, p_info );\n            res->actual_tag         = res->desired_tag;\n            res->actual_local_rank  = res->desired_local_rank;\n            res->actual_global_rank = res->actual_local_rank;\n        } else if( MCA_PML_REQUEST_RECV == req_type ) {\n            snprintf( (char *)res->extra_text[0], 64, \"Receive: 0x%llx\", (long long)current_item );\n            /**\n             * There is a trick with the MPI_TAG. All receive requests set it to MPI_ANY_TAG\n             * when the request get initialized, and to the real tag once the request\n             * is matched.\n             */\n            res->actual_tag =\n                ompi_fetch_int( proc, current_item + i_info->ompi_request_t.offset.req_status +\n                                i_info->ompi_status_public_t.offset.MPI_TAG, p_info );\n            if( MPI_ANY_TAG != (int)res->actual_tag ) {\n                res->status = mqs_st_matched;\n                res->desired_length =\n                    ompi_fetch_size_t( proc,\n                                       current_item + i_info->mca_pml_base_recv_request_t.offset.req_bytes_packed,\n                                       p_info );\n                res->actual_local_rank =\n                    ompi_fetch_int( proc, current_item + i_info->ompi_request_t.offset.req_status +\n                                    i_info->ompi_status_public_t.offset.MPI_SOURCE, p_info );\n                res->actual_global_rank = translate( extra->current_communicator->group,\n                                                  res->actual_local_rank );\n            }\n        } else {\n            snprintf( (char *)res->extra_text[0], 64, \"Unknown type of request 0x%llx\", (long long)current_item );\n        }\n        if( 0 != req_pml_complete ) {\n\t\t\tsnprintf( (char *)res->extra_text[1], 64, \"Data transfer completed\" );\n        }\n\n        /* If the length we're looking for is the count ... */\n        /*res->desired_length      =\n          ompi_fetch_int( proc, current_item + i_info->mca_pml_base_request_t.offset.req_count, p_info );*/\n\n        if( (mqs_st_pending < res->status) && (MCA_PML_REQUEST_SEND != req_type) ) {  /* The real data from the status */\n            res->actual_length       =\n                ompi_fetch_size_t( proc, current_item + i_info->ompi_request_t.offset.req_status +\n                                   i_info->ompi_status_public_t.offset._ucount, p_info );\n            res->actual_tag          =\n                ompi_fetch_int( proc, current_item + i_info->ompi_request_t.offset.req_status +\n                                i_info->ompi_status_public_t.offset.MPI_TAG, p_info );\n            res->actual_local_rank   =\n                ompi_fetch_int( proc, current_item + i_info->ompi_request_t.offset.req_status +\n                                i_info->ompi_status_public_t.offset.MPI_SOURCE, p_info );\n            res->actual_global_rank  = translate( extra->current_communicator->group,\n                                                  res->actual_local_rank );\n        }\n        dump_request( current_item, res );\n    }\n    return mqs_ok;\n}\n\n/***********************************************************************\n * Setup to iterate over pending operations\n */\nint mqs_setup_operation_iterator (mqs_process *proc, int op)\n{\n    mpi_process_info *p_info = (mpi_process_info *)mqs_get_process_info (proc);\n    mpi_process_info_extra *extra = (mpi_process_info_extra*) p_info->extra;\n\n    extra->what = (mqs_op_class)op;\n\n    switch (op) {\n    case mqs_pending_sends:\n        DEBUG(VERBOSE_REQ,(\"setup the send queue iterator\\n\"));\n        opal_free_list_t_init_parser( proc, p_info, &extra->next_msg, extra->send_queue_base );\n        return mqs_ok;\n\n    case mqs_pending_receives:\n        DEBUG(VERBOSE_REQ,(\"setup the receive queue iterator\\n\"));\n        opal_free_list_t_init_parser( proc, p_info, &extra->next_msg, extra->recv_queue_base );\n        return mqs_ok;\n\n    case mqs_unexpected_messages:  /* TODO */\n        return mqs_no_information;\n\n    default:\n        return err_bad_request;\n    }\n} /* mqs_setup_operation_iterator */\n\n/***********************************************************************\n * Fetch the next valid operation.\n * Since Open MPI only maintains a single queue of each type of operation,\n * we have to run over it and filter out the operations which\n * match the active communicator.\n */\nint mqs_next_operation (mqs_process *proc, mqs_pending_operation *op)\n{\n    mpi_process_info *p_info = (mpi_process_info *)mqs_get_process_info (proc);\n    mpi_process_info_extra *extra = (mpi_process_info_extra*) p_info->extra;\n\n    switch (extra->what) {\n    case mqs_pending_receives:\n        DEBUG(VERBOSE_REQ,(\"digging for the receive queue\\n\"));\n        return fetch_request( proc, p_info, op, TRUE );\n    case mqs_unexpected_messages:\n        /* TODO: not handled yet */\n        return err_bad_request;\n    case mqs_pending_sends:\n        DEBUG(VERBOSE_REQ,(\"digging for the send queue\\n\"));\n        return fetch_request( proc, p_info, op, FALSE );\n    default: return err_bad_request;\n    }\n} /* mqs_next_operation */\n\n/***********************************************************************\n * Destroy the info.\n */\nvoid mqs_destroy_process_info (mqs_process_info *mp_info)\n{\n    mpi_process_info *p_info = (mpi_process_info *)mp_info;\n    mpi_process_info_extra *extra = (mpi_process_info_extra*) p_info->extra;\n    /* Need to handle the communicators and groups too */\n    communicator_t *comm;\n\n    if( NULL != extra) {\n        comm = extra->communicator_list;\n        while (comm) {\n            communicator_t *next = comm->next;\n\n            if( NULL != comm->group )\n                group_decref (comm->group);  /* Group is no longer referenced from here */\n            mqs_free (comm);\n\n            comm = next;\n        }\n        if (NULL != extra) {\n            mqs_free(extra);\n        }\n    }\n    mqs_free (p_info);\n} /* mqs_destroy_process_info */\n\n/***********************************************************************\n * Free off the data we associated with an image. Since we malloced it\n * we just free it.\n */\nvoid mqs_destroy_image_info (mqs_image_info *info)\n{\n    mqs_free (info);\n} /* mqs_destroy_image_info */\n\n/***********************************************************************/\n/* Convert an error code into a printable string */\nchar * mqs_dll_error_string (int errcode)\n{\n    switch (errcode) {\n    case err_silent_failure:\n        return \"\";\n    case err_no_current_communicator:\n        return \"No current communicator in the communicator iterator\";\n    case err_bad_request:\n        return \"Attempting to setup to iterate over an unknown queue of operations\";\n    case err_no_store:\n        return \"Unable to allocate store\";\n    case err_failed_qhdr:\n        return \"Failed to find type MPID_QHDR\";\n    case err_unexpected:\n        return \"Failed to find field 'unexpected' in MPID_QHDR\";\n    case err_posted:\n        return \"Failed to find field 'posted' in MPID_QHDR\";\n    case err_failed_queue:\n        return \"Failed to find type MPID_QUEUE\";\n    case err_first:\n        return \"Failed to find field 'first' in MPID_QUEUE\";\n    case err_context_id:\n        return \"Failed to find field 'context_id' in MPID_QEL\";\n    case err_tag:\n        return \"Failed to find field 'tag' in MPID_QEL\";\n    case err_tagmask:\n        return \"Failed to find field 'tagmask' in MPID_QEL\";\n    case err_lsrc:\n        return \"Failed to find field 'lsrc' in MPID_QEL\";\n    case err_srcmask:\n        return \"Failed to find field 'srcmask' in MPID_QEL\";\n    case err_next:\n        return \"Failed to find field 'next' in MPID_QEL\";\n    case err_ptr:\n        return \"Failed to find field 'ptr' in MPID_QEL\";\n    case err_missing_type:\n        return \"Failed to find some type\";\n    case err_missing_symbol:\n        return \"Failed to find field the global symbol\";\n    case err_db_shandle:\n        return \"Failed to find field 'db_shandle' in MPIR_SQEL\";\n    case err_db_comm:\n        return \"Failed to find field 'db_comm' in MPIR_SQEL\";\n    case err_db_target:\n        return \"Failed to find field 'db_target' in MPIR_SQEL\";\n    case err_db_tag:\n        return \"Failed to find field 'db_tag' in MPIR_SQEL\";\n    case err_db_data:\n        return \"Failed to find field 'db_data' in MPIR_SQEL\";\n    case err_db_byte_length:\n        return \"Failed to find field 'db_byte_length' in MPIR_SQEL\";\n    case err_db_next:\n        return \"Failed to find field 'db_next' in MPIR_SQEL\";\n    case err_failed_rhandle:\n        return \"Failed to find type MPIR_RHANDLE\";\n    case err_is_complete:\n        return \"Failed to find field 'is_complete' in MPIR_RHANDLE\";\n    case err_buf:\n        return \"Failed to find field 'buf' in MPIR_RHANDLE\";\n    case err_len:\n        return \"Failed to find field 'len' in MPIR_RHANDLE\";\n    case err_s:\n        return \"Failed to find field 's' in MPIR_RHANDLE\";\n    case err_failed_status:\n        return \"Failed to find type MPI_Status\";\n    case err_count:\n        return \"Failed to find field 'count' in MPIR_Status\";\n    case err_MPI_SOURCE:\n        return \"Failed to find field 'MPI_SOURCE' in MPIR_Status\";\n    case err_MPI_TAG:\n        return \"Failed to find field 'MPI_TAG' in MPIR_Status\";\n    case err_failed_commlist:\n        return \"Failed to find type MPIR_Comm_list\";\n    case err_sequence_number:\n        return \"Failed to find field 'sequence_number' in MPIR_Comm_list\";\n    case err_comm_first:\n        return \"Failed to find field 'comm_first' in MPIR_Comm_list\";\n    case err_failed_communicator:\n        return \"Failed to find type MPIR_Communicator\";\n    case err_lrank_to_grank:\n        return \"Failed to find field 'lrank_to_grank' in MPIR_Communicator\";\n    case err_send_context:\n        return \"Failed to find field 'send_context' in MPIR_Communicator\";\n    case err_recv_context:\n        return \"Failed to find field 'recv_context' in MPIR_Communicator\";\n    case err_comm_next:\n        return \"Failed to find field 'comm_next' in MPIR_Communicator\";\n    case err_comm_name:\n        return \"Failed to find field 'comm_name' in MPIR_Communicator\";\n    case err_all_communicators:\n        return \"Failed to find the global symbol MPIR_All_communicators\";\n    case err_mpid_sends:\n        return \"Failed to access the global send requests list\";\n    case err_mpid_recvs:\n        return \"Failed to access the global receive requests list\";\n    case err_group_corrupt:\n        return \"Could not read a communicator's group from the process (probably a store corruption)\";\n\n    default: return \"Unknown error code\";\n    }\n} /* mqs_dll_error_string */\n",
        "/tmp/vanessa/spack-stage/spack-stage-openmpi-master-qcrm7qmgqutvsby2zcmdb57s22lzfq65/spack-src/ompi/debuggers/tv-debugger-attach.txt": "(Downloaded from http://www-unix.mcs.anl.gov/mpi/mpi-debug/mpich-attach.txt,\n17 June 2008; cached here in case it ever disappears from the Argonne site)\n\nTV Process Acquisition with MPICH\n---------------------------------\n\nRevised  2 Apr 2001: Added MPIR_partial_attach_ok\nRevised 25 Oct 2000: Added MPIR_acquired_pre_main\n\nThe fundamental model is that TotalView is debugging the process which\nis responsible for starting the parallel MPI application.\n\nThis process can either be a participant in the MPI job once it has\nstarted the other processes (normally it ends up as rank 0 in\nCOMM_WORLD), or it can be a separate process which does not\nparticipate in the job (other than for forwarding I/O, signals and so\non).\n\nTotalView expects this process to communicate with the debugger in the\nfollowing ways :-\n\n1) TV looks for specific external symbols in the image to identify it\n   as an MPI master code.\n\n2) TV places a breakpoint in the routine MPIR_Breakpoint and expects\n   the MPI masted code to call this at appropriate points to tell TV\n   to look at the values of specific external symbols.\n\nThe external symbols and data types expected by TotalView and used for\nprocess pickup are detailed in the file mpid/ch2/attach.h in the MPICH\ncode, appended here...\n\n...............\n/*  $Id: attach.h,v 1.1.1.1 1997/09/17 20:39:24 gropp Exp $\n */\n\n/* This file contains support for bringing processes up stopped, so that\n * a debugger can attach to them     (done for TotalView)\n */\n\n/* Update log\n *\n * Nov 27 1996 jcownie@dolphinics.com: Added the executable_name to MPIR_PROCDESC\n */\n\n#ifndef _ATTACH_INCLUDE\n#define _ATTACH_INCLUDE\n\n#ifndef VOLATILE\n#if defined(__STDC__) || defined(__cplusplus)\n#define VOLATILE volatile\n#else\n#define VOLATILE\n#endif\n#endif\n\n/*****************************************************************************\n*                                DEBUGGING SUPPORT                           *\n*****************************************************************************/\n\n\n/* A little struct to hold the target processor name and pid for\n * each process which forms part of the MPI program.\n * We may need to think more about this once we have dynamic processes...\n *\n * DO NOT change the name of this structure or its fields. The debugger knows\n * them, and will be confused if you change them.\n */\ntypedef struct {\n  char * host_name;           /* Something we can pass to inet_addr */\n  char * executable_name;     /* The name of the image */\n  int    pid;\t\t      /* The pid of the process */\n} MPIR_PROCDESC;\n\n/* Array of procdescs for debugging purposes */\nextern MPIR_PROCDESC *MPIR_proctable;\nextern int MPIR_proctable_size;\n\n/* Various global variables which a debugger can use for\n * 1) finding out what the state of the program is at\n *    the time the magic breakpoint is hit.\n * 2) inform the process that it has been attached to and is\n *    now free to run.\n */\nextern VOLATILE int MPIR_debug_state;\nextern VOLATILE int MPIR_debug_gate;\nextern char * MPIR_debug_abort_string;\nextern int          MPIR_being_debugged; /* Cause extra info on internal state\n\t\t\t\t\t  * to be maintained\n\t\t\t\t\t  */\n\n/* Values for the debug_state, this seems to be all we need at the moment\n * but that may change...\n */\n#define MPIR_DEBUG_SPAWNED   1\n#define MPIR_DEBUG_ABORTING  2\n\n#endif\n..............................\n\nThe named symbols looked for by TotalView are\n\n/* MPICH process startup magic names */\n#define MPICH_breakpoint_name  \t\"MPIR_Breakpoint\"\n#define MPICH_debugstate_name  \t\"MPIR_debug_state\"\n#define MPICH_debuggate_name  \t\"MPIR_debug_gate\"\n#define MPICH_proctable_name  \t\"MPIR_proctable\"\n#define MPICH_proctable_size_name   \"MPIR_proctable_size\"\n#define MPICH_abort_string_name \"MPIR_debug_abort_string\"\n#define MPICH_starter_name      \"MPIR_i_am_starter\"\n#define MPICH_acquired_pre_main_name \"MPIR_acquired_pre_main\"\n#define MPICH_partial_attach_name \"MPIR_partial_attach_ok\"\n#define MPICH_being_debugged_name \"MPIR_being_debugged\"\n#define MPICH_dll_name          \"MPIR_dll_name\"\n\nIf the symbol MPIR_dll_name is present in the image, then it is\nexpected to be\n\nextern char [] MPIR_dll_name;\n\nand to contain a string which is the name of the message queue\ndebugging library to use to debug this code.\n\nThis can be used to override the default DLL name which TotalView\nwould choose.\n\nMPIR_Breakpoint is the routine that the start up process calls at\npoints of interest, after setting the variable MPIR_debug_state to an\nappropriate value.\n\nThe proctable contains the array of processes in the MPI program\nindexed by rank in COMM_World, and MPIR_proctable_size gives the count\nof the number of processes.\n\nMPIR_being_debugged is set by TotalView when it starts (or attaches)\nto an MPI program.\n\nMPIR_debug_gate is the volatile variable that TV will set once it has\nattached to a process to let it run.\n\nTotalview also needs the debug information for the MPIR_PROCDESC type,\nsince it uses that to work out the size and fields in the procedesc\narray.\n\nIf the symbol MPIR_i_am_starter appears in the program then TotalView\ntreats it as a starter process which is not in the MPI world,\notherwise it treats the initial process as index 0 in COMM_World.\n\nTotalview 4.1.0-2 and later only:\nIf the symbol MPIR_acquired_pre_main appears in the program, then\nTotalView forces the display of the main program in its source pane\nafter acquiring the new processes at startup. If the symbol is not\npresent, then a normal display showing the place at which the code was\nexecuting when acquired will be shown. This variable should be present\nin the initial process only if the acquired processes have been\nstopped for acquisition before they enter the user's main program,\neither because they are stopped, \"on the return from exec\", or because\nthey are stopped by code in a library init section.\n\nIf the symbol MPIR_partial_attach_ok is present in the executable,\nthen this informs TotalView that the initial startup barrier is\nimplemented by the MPI system, rather than by having each of the child\nprocesses hang in a loop waiting for the MPIR_debug_gate variable to\nbe set. Therefore TotalView need only release the initial process to\nrelease the whole MPI job, which can therefore be run _without_ having\nto acquire all of the MPI processes which it includes. This is useful\nin versions of TotalView which include the possibility of attaching to\nprocesses later in the run (for instance, by selecting only processes\nin a specific communicator, or a specific rank process in COMM_WORLD).\nTotalView may choose to ignore this and acquire all processes, and its\npresence does not prevent TotalView from using the old protocol to\nacquire all of the processes. (Since setting the MPIR_debug_gate is\nharmless).\n\nAll of the code that MPICH uses can be found in the MPICH source\nrelease, specifically in initutil.c and debugutil.c\n\nHere's a little more description of each of the variables TV\nreferences or sets.\n\nMPIR_debug_state\n  Required.\n  If we don't see this we won't know what the target process\n  is trying to tell us by hitting the breakpoint, and we'll ignore it.\n  Process acquisition will not work without this variable existing and\n  being set correctly.\n\nMPIR_debug_gate\n  Not required.\n  If it's not there we won't complain, however if you don't have this\n  you'd better have some other way of holding all the processes until\n  we have attached to them. TV sets this to (int)1 once it has\n  attached to the process.\n\nMPIR_debug_abort_string\n  Not required.\n  Or rather, only required to get special handling of MPI_Abort.\n\nMPIR_i_am_starter\n  Not required.\n  The presence or absence of this symbol is all that is tested, we\n  never look at the _value_ of the symbol. However, if the first\n  process being debugged should not be included in the user's view of\n  the MPI processes, then this symbol should be in that program.\n\nMPIR_acquired_pre_main\n  Not required.\n  The presence or absence of this symbol is all that is tested, we\n  never look at the _value_ of the symbol. Its existence only matters\n  in the initially debugged process.\n\nMPIR_being_debugged\n  Not required.\n  We try to set this to (int)1 to let the target processes know that they're\n  being debugged. If the symbol doesn't exist we won't write it and\n  won't complain.\n\nMPIR_dll_name\n  Not required.\n  If it's not present we'll _only_ use the default name for the debug\n  dll. (But if you don't have dlopen or message queue dumping, that\n  certainly won't matter !)\n\n",
        "/tmp/vanessa/spack-stage/spack-stage-openmpi-master-qcrm7qmgqutvsby2zcmdb57s22lzfq65/spack-src/ompi/tools/ompi_info/param.c": "/*\n * Copyright (c) 2004-2010 The Trustees of Indiana University and Indiana\n *                         University Research and Technology\n *                         Corporation.  All rights reserved.\n * Copyright (c) 2004-2006 The University of Tennessee and The University\n *                         of Tennessee Research Foundation.  All rights\n *                         reserved.\n * Copyright (c) 2004-2005 High Performance Computing Center Stuttgart,\n *                         University of Stuttgart.  All rights reserved.\n * Copyright (c) 2004-2005 The Regents of the University of California.\n *                         All rights reserved.\n * Copyright (c) 2007-2017 Cisco Systems, Inc.  All rights reserved\n * Copyright (c) 2009      Oak Ridge National Labs.  All rights reserved.\n * Copyright (c) 2014-2019 Research Organization for Information Science\n *                         and Technology (RIST).  All rights reserved.\n * Copyright (c) 2015-2019 Intel, Inc.  All rights reserved.\n * Copyright (c) 2018      Amazon.com, Inc. or its affiliates.  All Rights reserved.\n * Copyright (c) 2018      FUJITSU LIMITED.  All rights reserved.\n * $COPYRIGHT$\n *\n * Additional copyrights may follow\n *\n * $HEADER$\n */\n\n#include \"ompi_config.h\"\n#include \"mpi.h\"\n\n#include <string.h>\n#include <ctype.h>\n#ifdef HAVE_UNISTD_H\n#include <unistd.h>\n#endif\n#ifdef HAVE_SYS_PARAM_H\n#include <sys/param.h>\n#endif\n#ifdef HAVE_NETDB_H\n#include <netdb.h>\n#endif\n\n#include MCA_timer_IMPLEMENTATION_HEADER\n#include \"opal/include/opal/version.h\"\n#include \"opal/class/opal_value_array.h\"\n#include \"opal/class/opal_pointer_array.h\"\n#include \"opal/util/printf.h\"\n#include \"opal/memoryhooks/memory.h\"\n#include \"opal/runtime/opal_info_support.h\"\n\n#include \"ompi/tools/ompi_info/ompi_info.h\"\n#include \"ompi/include/mpi_portable_platform.h\"\n\n\nconst char *ompi_info_deprecated_value = \"deprecated-ompi-info-value\";\n\nstatic void append(char *dest, size_t max, int *first, char *src)\n{\n    size_t len;\n\n    if (NULL == src) {\n        return;\n    }\n\n    len = max - strlen(dest);\n    if (!(*first)) {\n        strncat(dest, \", \", len);\n        len = max - strlen(dest);\n    }\n    strncat(dest, src, len);\n    *first = 0;\n}\n\n\n/*\n * do_config\n * Accepts:\n *\t- want_all: boolean flag; TRUE -> display all options\n *\t\t\t\t  FALSE -> display selected options\n *\n * This function displays all the options with which the current\n * installation of ompi was configured. There are many options here\n * that are carried forward from OMPI-7 and are not mca parameters\n * in OMPI-10. I have to dig through the invalid options and replace\n * them with OMPI-10 options.\n */\nvoid ompi_info_do_config(bool want_all)\n{\n    char *fortran_mpifh;\n    char *fortran_usempi;\n    char *fortran_usempif08;\n    char *fortran_usempif08_compliance;\n    char *fortran_have_ignore_tkr;\n    char *fortran_have_f08_assumed_rank;\n    char *fortran_build_f08_subarrays;\n    char *fortran_have_optional_args;\n    char *fortran_have_interface;\n    char *fortran_have_iso_fortran_env;\n    char *fortran_have_storage_size;\n    char *fortran_have_bind_c;\n    char *fortran_have_iso_c_binding;\n    char *fortran_have_bind_c_sub;\n    char *fortran_have_bind_c_type;\n    char *fortran_have_bind_c_type_name;\n    char *fortran_have_private;\n    char *fortran_have_abstract;\n    char *fortran_have_asynchronous;\n    char *fortran_have_procedure;\n    char *fortran_have_use_only;\n    char *fortran_have_c_funloc;\n    char *fortran_08_using_wrappers_for_choice_buffer_functions;\n    char *fortran_build_sizeof;\n    char *java;\n    char *heterogeneous;\n    char *memprofile;\n    char *memdebug;\n    char *debug;\n    char *mpi_interface_warning;\n    char *cprofiling;\n    char *fortran_mpifh_profiling;\n    char *fortran_usempi_profiling;\n    char *fortran_usempif08_profiling;\n    char *threads;\n    char *have_dl;\n    char *sparse_groups;\n    char *wtime_support;\n    char *symbol_visibility;\n    char *ft_support;\n    char *crdebug_support;\n    char *topology_support;\n    char *ipv6_support;\n\n    /* Do a little preprocessor trickery here to figure opal_info_out the\n     * tri-state of MPI_PARAM_CHECK (which will be either 0, 1, or\n     * ompi_mpi_param_check).  The preprocessor will only allow\n     * comparisons against constants, so you'll get a warning if you\n     * check MPI_PARAM_CHECK against 0 or 1, but its real value is the\n     * char *ompi_mpi_param_check.  So define ompi_mpi_param_check to\n     * be a constant, and then all the preprocessor comparisons work\n     * opal_info_out ok.  Note that we chose the preprocessor\n     * comparison ropal_info_oute because it is not sufficient to\n     * simply set the variable ompi_mpi_param_check to a non-0/non-1\n     * value.  This is because the compiler will generate a warning\n     * that that C variable is unused when MPI_PARAM_CHECK is\n     * hard-coded to 0 or 1.\n     */\n    char *paramcheck;\n#define ompi_mpi_param_check 999\n#if 0 == MPI_PARAM_CHECK\n    paramcheck = \"never\";\n#elif 1 == MPI_PARAM_CHECK\n    paramcheck = \"always\";\n#else\n    paramcheck = \"runtime\";\n#endif\n\n    /* The current mpi_f08 implementation does not support Fortran\n       subarrays.  However, someday it may/will.  Hence, I'm leaving\n       in all the logic that checks to see whether subarrays are\n       supported, but I'm just hard-coding\n       OMPI_BUILD_FORTRAN_F08_SUBARRAYS to 0 (we used to have a\n       prototype mpi_f08 module that implemented a handful of\n       descriptor-based interfaces and supported subarrays, but that\n       has been removed). */\n    const int OMPI_BUILD_FORTRAN_F08_SUBARRAYS = 0;\n\n    /* setup the strings that don't require allocations*/\n    if (OMPI_BUILD_FORTRAN_BINDINGS >= OMPI_FORTRAN_USEMPI_BINDINGS) {\n        if (OMPI_FORTRAN_HAVE_IGNORE_TKR) {\n            fortran_usempi = \"yes (full: ignore TKR)\";\n        } else {\n            fortran_usempi = \"yes (limited: overloading)\";\n        }\n    } else {\n        fortran_usempi = \"no\";\n    }\n    fortran_usempif08 = OMPI_BUILD_FORTRAN_BINDINGS >= OMPI_FORTRAN_USEMPIF08_BINDINGS ? \"yes\" : \"no\";\n    fortran_have_f08_assumed_rank = OMPI_FORTRAN_HAVE_F08_ASSUMED_RANK ?\n        \"yes\" : \"no\";\n    fortran_build_f08_subarrays = OMPI_BUILD_FORTRAN_F08_SUBARRAYS ?\n        \"yes\" : \"no\";\n    fortran_have_optional_args = OMPI_FORTRAN_HAVE_OPTIONAL_ARGS ?\n        \"yes\" : \"no\";\n    fortran_have_interface = OMPI_FORTRAN_HAVE_INTERFACE ? \"yes\" : \"no\";\n    fortran_have_iso_fortran_env = OMPI_FORTRAN_HAVE_ISO_FORTRAN_ENV ?\n        \"yes\" : \"no\";\n    fortran_have_storage_size = OMPI_FORTRAN_HAVE_STORAGE_SIZE ? \"yes\" : \"no\";\n    fortran_have_bind_c = OMPI_FORTRAN_HAVE_BIND_C ? \"yes\" : \"no\";\n    fortran_have_iso_c_binding = OMPI_FORTRAN_HAVE_ISO_C_BINDING ?\n        \"yes\" : \"no\";\n    fortran_have_bind_c_sub = OMPI_FORTRAN_HAVE_BIND_C_SUB ? \"yes\" : \"no\";\n    fortran_have_bind_c_type = OMPI_FORTRAN_HAVE_BIND_C_TYPE ? \"yes\" : \"no\";\n    fortran_have_bind_c_type_name = OMPI_FORTRAN_HAVE_BIND_C_TYPE_NAME ?\n        \"yes\" : \"no\";\n    fortran_have_private = OMPI_FORTRAN_HAVE_PRIVATE ? \"yes\" : \"no\";\n    fortran_have_abstract = OMPI_FORTRAN_HAVE_ABSTRACT ? \"yes\" : \"no\";\n    fortran_have_asynchronous = OMPI_FORTRAN_HAVE_ASYNCHRONOUS ? \"yes\" : \"no\";\n    fortran_have_procedure = OMPI_FORTRAN_HAVE_PROCEDURE ? \"yes\" : \"no\";\n    fortran_have_use_only = OMPI_FORTRAN_HAVE_USE_ONLY ? \"yes\" : \"no\";\n    fortran_have_c_funloc = OMPI_FORTRAN_HAVE_C_FUNLOC ? \"yes\" : \"no\";\n    fortran_08_using_wrappers_for_choice_buffer_functions =\n        OMPI_FORTRAN_NEED_WRAPPER_ROUTINES ? \"yes\" : \"no\";\n    fortran_build_sizeof = OMPI_FORTRAN_BUILD_SIZEOF ?\n        \"yes\" : \"no\";\n\n    /* Build a string describing what level of compliance the mpi_f08\n       module has */\n    char f08_msg[1024];\n    if (OMPI_BUILD_FORTRAN_BINDINGS >= OMPI_FORTRAN_USEMPIF08_BINDINGS) {\n\n        /* Do we have everything? (not including PROTECTED, which\n           isn't *needed* for the mpi_f08 module compliance -- it's\n           just *nice to have*) */\n        if (OMPI_BUILD_FORTRAN_F08_SUBARRAYS &&\n            OMPI_FORTRAN_HAVE_PRIVATE &&\n            OMPI_FORTRAN_HAVE_ABSTRACT &&\n            OMPI_FORTRAN_HAVE_ASYNCHRONOUS &&\n            OMPI_FORTRAN_HAVE_PROCEDURE &&\n            OMPI_FORTRAN_HAVE_USE_ONLY &&\n            OMPI_FORTRAN_HAVE_C_FUNLOC &&\n            OMPI_FORTRAN_NEED_WRAPPER_ROUTINES) {\n            fortran_usempif08_compliance = \"The mpi_f08 module is available, and is fully compliant.  w00t!\";\n        } else {\n            int first = 1;\n            snprintf(f08_msg, sizeof(f08_msg),\n                     \"The mpi_f08 module is available, but due to limitations in the %s compiler and/or Open MPI, does not support the following: \",\n                     OMPI_FC);\n            if (!OMPI_BUILD_FORTRAN_F08_SUBARRAYS) {\n                append(f08_msg, sizeof(f08_msg), &first, \"array subsections\");\n            }\n            if (!OMPI_FORTRAN_HAVE_PRIVATE) {\n                append(f08_msg, sizeof(f08_msg), &first,\n                       \"private MPI_Status members\");\n            }\n            if (!OMPI_FORTRAN_HAVE_ABSTRACT) {\n                append(f08_msg, sizeof(f08_msg), &first,\n                       \"ABSTRACT INTERFACE function pointers\");\n            }\n            if (!OMPI_FORTRAN_HAVE_ASYNCHRONOUS) {\n                append(f08_msg, sizeof(f08_msg), &first,\n                       \"Fortran '08-specified ASYNCHRONOUS behavior\");\n            }\n            if (!OMPI_FORTRAN_HAVE_PROCEDURE) {\n                append(f08_msg, sizeof(f08_msg), &first, \"PROCEDUREs\");\n            }\n            if (!OMPI_FORTRAN_HAVE_USE_ONLY) {\n                append(f08_msg, sizeof(f08_msg), &first, \"USE_ONLY\");\n            }\n            if (!OMPI_FORTRAN_HAVE_C_FUNLOC) {\n                append(f08_msg, sizeof(f08_msg), &first, \"C_FUNLOCs\");\n            }\n            if (OMPI_FORTRAN_NEED_WRAPPER_ROUTINES) {\n                append(f08_msg, sizeof(f08_msg), &first,\n                       \"direct passthru (where possible) to underlying Open MPI's C functionality\");\n            }\n            fortran_usempif08_compliance = f08_msg;\n        }\n    } else {\n        fortran_usempif08_compliance = \"The mpi_f08 module was not built\";\n    }\n\n    java = OMPI_WANT_JAVA_BINDINGS ? \"yes\" : \"no\";\n    heterogeneous = OPAL_ENABLE_HETEROGENEOUS_SUPPORT ? \"yes\" : \"no\";\n    memprofile = OPAL_ENABLE_MEM_PROFILE ? \"yes\" : \"no\";\n    memdebug = OPAL_ENABLE_MEM_DEBUG ? \"yes\" : \"no\";\n    debug = OPAL_ENABLE_DEBUG ? \"yes\" : \"no\";\n    mpi_interface_warning = OMPI_WANT_MPI_INTERFACE_WARNING ? \"yes\" : \"no\";\n    cprofiling = \"yes\";\n    fortran_mpifh_profiling = (OMPI_BUILD_FORTRAN_BINDINGS >= OMPI_FORTRAN_MPIFH_BINDINGS) ? \"yes\" : \"no\";\n    fortran_usempi_profiling = (OMPI_BUILD_FORTRAN_BINDINGS >= OMPI_FORTRAN_USEMPI_BINDINGS) ? \"yes\" : \"no\";\n    fortran_usempif08_profiling = (OMPI_BUILD_FORTRAN_BINDINGS >= OMPI_FORTRAN_USEMPIF08_BINDINGS) ? \"yes\" : \"no\";\n    have_dl = OPAL_HAVE_DL_SUPPORT ? \"yes\" : \"no\";\n    sparse_groups = OMPI_GROUP_SPARSE ? \"yes\" : \"no\";\n    wtime_support = OPAL_TIMER_USEC_NATIVE ? \"native\" : \"gettimeofday\";\n    symbol_visibility = OPAL_C_HAVE_VISIBILITY ? \"yes\" : \"no\";\n    topology_support = \"yes\";\n    ipv6_support = OPAL_ENABLE_IPV6 ? \"yes\" : \"no\";\n\n    /* setup strings that require allocation */\n    if (OMPI_BUILD_FORTRAN_BINDINGS >= OMPI_FORTRAN_MPIFH_BINDINGS) {\n        (void)opal_asprintf(&fortran_mpifh, \"yes (%s)\",\n                       (OPAL_HAVE_WEAK_SYMBOLS ? \"all\" :\n                        (OMPI_FORTRAN_CAPS ? \"caps\" :\n                         (OMPI_FORTRAN_PLAIN ? \"lower case\" :\n                          (OMPI_FORTRAN_SINGLE_UNDERSCORE ? \"single underscore\" : \"double underscore\")))));\n    } else {\n        fortran_mpifh = strdup(\"no\");\n    }\n\n    if (OMPI_FORTRAN_HAVE_IGNORE_TKR) {\n        /* OMPI_FORTRAN_IGNORE_TKR_PREDECL is already in quotes; it\n           didn't work consistently to put it in _STRINGIFY because\n           sometimes the compiler would actually interpret the pragma\n           in there before stringify-ing it. */\n        (void)opal_asprintf(&fortran_have_ignore_tkr, \"yes (%s)\",\n                       OMPI_FORTRAN_IGNORE_TKR_PREDECL);\n    } else {\n        fortran_have_ignore_tkr = strdup(\"no\");\n    }\n\n    (void)opal_asprintf(&threads, \"%s (MPI_THREAD_MULTIPLE: yes, OPAL support: yes, OMPI progress: %s, Event lib: yes)\",\n                   \"posix\", OPAL_ENABLE_PROGRESS_THREADS ? \"yes\" : \"no\");\n\n    (void)opal_asprintf(&ft_support, \"%s (checkpoint thread: %s)\",\n                   OPAL_ENABLE_FT ? \"yes\" : \"no\", OPAL_ENABLE_FT_THREAD ? \"yes\" : \"no\");\n\n    (void)opal_asprintf(&crdebug_support, \"%s\",\n                   OPAL_ENABLE_CRDEBUG ? \"yes\" : \"no\");\n\n    /* output values */\n    opal_info_out(\"Configured by\", \"config:user\", OPAL_CONFIGURE_USER);\n    opal_info_out(\"Configured on\", \"config:timestamp\", OPAL_CONFIGURE_DATE);\n    opal_info_do_hostname();\n    opal_info_out(\"Configure command line\", \"config:cli\", OPAL_CONFIGURE_CLI);\n\n    opal_info_out(\"Built by\", \"build:user\", OMPI_BUILD_USER);\n    opal_info_out(\"Built on\", \"build:timestamp\", OMPI_BUILD_DATE);\n    opal_info_out(\"Built host\", \"build:host\", OMPI_BUILD_HOST);\n\n    opal_info_out(\"C bindings\", \"bindings:c\", \"yes\");\n    opal_info_out(\"Fort mpif.h\", \"bindings:mpif.h\", fortran_mpifh);\n    free(fortran_mpifh);\n    opal_info_out(\"Fort use mpi\", \"bindings:use_mpi\",\n                  fortran_usempi);\n    opal_info_out(\"Fort use mpi size\", \"bindings:use_mpi:size\",\n                  ompi_info_deprecated_value);\n    opal_info_out(\"Fort use mpi_f08\", \"bindings:use_mpi_f08\",\n                  fortran_usempif08);\n    opal_info_out(\"Fort mpi_f08 compliance\", \"bindings:use_mpi_f08:compliance\",\n                  fortran_usempif08_compliance);\n    opal_info_out(\"Fort mpi_f08 subarrays\", \"bindings:use_mpi_f08:subarrays-supported\",\n                  fortran_build_f08_subarrays);\n    opal_info_out(\"Java bindings\", \"bindings:java\", java);\n\n    opal_info_out(\"Wrapper compiler rpath\", \"compiler:all:rpath\",\n                  WRAPPER_RPATH_SUPPORT);\n    opal_info_out(\"C compiler\", \"compiler:c:command\", OPAL_CC);\n    opal_info_out(\"C compiler absolute\", \"compiler:c:absolute\",\n                  OPAL_CC_ABSOLUTE);\n    opal_info_out(\"C compiler family name\", \"compiler:c:familyname\",\n                  _STRINGIFY(OPAL_BUILD_PLATFORM_COMPILER_FAMILYNAME));\n    opal_info_out(\"C compiler version\", \"compiler:c:version\",\n                  _STRINGIFY(OPAL_BUILD_PLATFORM_COMPILER_VERSION_STR));\n\n    if (want_all) {\n        opal_info_out_int(\"C char size\", \"compiler:c:sizeof:char\", sizeof(char));\n        /* JMS: should be fixed in MPI-2.2 to differentiate between C\n           _Bool and C++ bool.  For the moment, the code base assumes\n           that they are the same.  Because of opal_config_bottom.h,\n           we can sizeof(bool) here, so we might as well -- even\n           though this technically isn't right.  This should be fixed\n           when we update to MPI-2.2.  See below for note about C++\n           bool alignment. */\n        opal_info_out_int(\"C bool size\", \"compiler:c:sizeof:bool\", sizeof(bool));\n        opal_info_out_int(\"C short size\", \"compiler:c:sizeof:short\", sizeof(short));\n        opal_info_out_int(\"C int size\", \"compiler:c:sizeof:int\", sizeof(int));\n        opal_info_out_int(\"C long size\", \"compiler:c:sizeof:long\", sizeof(long));\n#if defined(HAVE_SHORT_FLOAT)\n        opal_info_out_int(\"C short float size\", \"compiler:c:sizeof:short_float\", sizeof(short float));\n#elif defined(HAVE_OPAL_SHORT_FLOAT_T)\n        opal_info_out_int(\"C short float size\", \"compiler:c:sizeof:short_float\", sizeof(opal_short_float_t));\n#endif\n        opal_info_out_int(\"C float size\", \"compiler:c:sizeof:float\", sizeof(float));\n        opal_info_out_int(\"C double size\", \"compiler:c:sizeof:double\", sizeof(double));\n        opal_info_out_int(\"C long double size\", \"compiler:c:sizeof:long_double\", sizeof(long double));\n        opal_info_out_int(\"C pointer size\", \"compiler:c:sizeof:pointer\", sizeof(void *));\n        opal_info_out_int(\"C char align\", \"compiler:c:align:char\", OPAL_ALIGNMENT_CHAR);\n        opal_info_out(\"C bool align\", \"compiler:c:align:bool\", \"skipped\");\n        opal_info_out_int(\"C int align\", \"compiler:c:align:int\", OPAL_ALIGNMENT_INT);\n#if defined(HAVE_SHORT_FLOAT)\n        opal_info_out_int(\"C short float align\", \"compiler:c:align:short_float\", OPAL_ALIGNMENT_SHORT_FLOAT);\n#elif defined(HAVE_OPAL_SHORT_FLOAT_T)\n        opal_info_out_int(\"C short float align\", \"compiler:c:align:short_float\", OPAL_ALIGNMENT_OPAL_SHORT_FLOAT_T);\n#endif\n        opal_info_out_int(\"C float align\", \"compiler:c:align:float\", OPAL_ALIGNMENT_FLOAT);\n        opal_info_out_int(\"C double align\", \"compiler:c:align:double\", OPAL_ALIGNMENT_DOUBLE);\n        opal_info_out_int(\"C long double align\", \"compiler:c:align:long_double\", OPAL_ALIGNMENT_LONG_DOUBLE);\n    }\n\n    opal_info_out(\"C++ compiler\", \"compiler:cxx:command\", OMPI_CXX);\n    opal_info_out(\"C++ compiler absolute\", \"compiler:cxx:absolute\", OMPI_CXX_ABSOLUTE);\n    opal_info_out(\"Fort compiler\", \"compiler:fortran:command\", OMPI_FC);\n    opal_info_out(\"Fort compiler abs\", \"compiler:fortran:absolute\",\n                  OMPI_FC_ABSOLUTE);\n    opal_info_out(\"Fort ignore TKR\", \"compiler:fortran:ignore_tkr\",\n                  fortran_have_ignore_tkr);\n    free(fortran_have_ignore_tkr);\n    opal_info_out(\"Fort 08 assumed shape\",\n                  \"compiler:fortran:f08_assumed_rank\",\n                  fortran_have_f08_assumed_rank);\n    opal_info_out(\"Fort optional args\",\n                  \"compiler:fortran:optional_arguments\",\n                  fortran_have_optional_args);\n    opal_info_out(\"Fort INTERFACE\",\n                  \"compiler:fortran:interface\",\n                  fortran_have_interface);\n    opal_info_out(\"Fort ISO_FORTRAN_ENV\",\n                  \"compiler:fortran:iso_fortran_env\",\n                  fortran_have_iso_fortran_env);\n    opal_info_out(\"Fort STORAGE_SIZE\",\n                  \"compiler:fortran:storage_size\",\n                  fortran_have_storage_size);\n    opal_info_out(\"Fort BIND(C) (all)\",\n                  \"compiler:fortran:bind_c\",\n                  fortran_have_bind_c);\n    opal_info_out(\"Fort ISO_C_BINDING\",\n                  \"compiler:fortran:iso_c_binding\",\n                  fortran_have_iso_c_binding);\n    opal_info_out(\"Fort SUBROUTINE BIND(C)\",\n                  \"compiler:fortran:subroutine_bind_c\",\n                  fortran_have_bind_c_sub);\n    opal_info_out(\"Fort TYPE,BIND(C)\",\n                  \"compiler:fortran:type_bind_c\",\n                  fortran_have_bind_c_type);\n    opal_info_out(\"Fort T,BIND(C,name=\\\"a\\\")\",\n                  \"compiler:fortran:type_name_bind_c\",\n                  fortran_have_bind_c_type_name);\n    opal_info_out(\"Fort PRIVATE\",\n                  \"compiler:fortran:private\",\n                  fortran_have_private);\n    opal_info_out(\"Fort ABSTRACT\",\n                  \"compiler:fortran:abstract\",\n                  fortran_have_abstract);\n    opal_info_out(\"Fort ASYNCHRONOUS\",\n                  \"compiler:fortran:asynchronous\",\n                  fortran_have_asynchronous);\n    opal_info_out(\"Fort PROCEDURE\",\n                  \"compiler:fortran:procedure\",\n                  fortran_have_procedure);\n    opal_info_out(\"Fort USE...ONLY\",\n                  \"compiler:fortran:use_only\",\n                  fortran_have_use_only);\n    opal_info_out(\"Fort C_FUNLOC\",\n                  \"compiler:fortran:c_funloc\",\n                  fortran_have_c_funloc);\n    opal_info_out(\"Fort f08 using wrappers\",\n                  \"compiler:fortran:08_wrappers\",\n                  fortran_08_using_wrappers_for_choice_buffer_functions);\n    opal_info_out(\"Fort MPI_SIZEOF\",\n                  \"compiler:fortran:mpi_sizeof\",\n                  fortran_build_sizeof);\n\n    if (want_all) {\n\n        /* Will always have the size of Fortran integer */\n\n        opal_info_out_int(\"Fort integer size\", \"compiler:fortran:sizeof:integer\",\n                      OMPI_SIZEOF_FORTRAN_INTEGER);\n\n        opal_info_out_int(\"Fort logical size\", \"compiler:fortran:sizeof:logical\",\n                      OMPI_SIZEOF_FORTRAN_LOGICAL);\n        opal_info_out_int(\"Fort logical value true\", \"compiler:fortran:value:true\",\n                      OMPI_FORTRAN_VALUE_TRUE);\n\n\n        /* May or may not have the other Fortran sizes */\n\n        if (OMPI_BUILD_FORTRAN_BINDINGS >= OMPI_FORTRAN_MPIFH_BINDINGS) {\n            opal_info_out(\"Fort have integer1\", \"compiler:fortran:have:integer1\",\n                          OMPI_HAVE_FORTRAN_INTEGER1 ? \"yes\" : \"no\");\n            opal_info_out(\"Fort have integer2\", \"compiler:fortran:have:integer2\",\n                          OMPI_HAVE_FORTRAN_INTEGER2 ? \"yes\" : \"no\");\n            opal_info_out(\"Fort have integer4\", \"compiler:fortran:have:integer4\",\n                          OMPI_HAVE_FORTRAN_INTEGER4 ? \"yes\" : \"no\");\n            opal_info_out(\"Fort have integer8\", \"compiler:fortran:have:integer8\",\n                          OMPI_HAVE_FORTRAN_INTEGER8 ? \"yes\" : \"no\");\n            opal_info_out(\"Fort have integer16\", \"compiler:fortran:have:integer16\",\n                          OMPI_HAVE_FORTRAN_INTEGER16 ? \"yes\" : \"no\");\n\n            opal_info_out(\"Fort have real2\", \"compiler:fortran:have:real2\",\n                          OMPI_HAVE_FORTRAN_REAL2 ? \"yes\" : \"no\");\n            opal_info_out(\"Fort have real4\", \"compiler:fortran:have:real4\",\n                          OMPI_HAVE_FORTRAN_REAL4 ? \"yes\" : \"no\");\n            opal_info_out(\"Fort have real8\", \"compiler:fortran:have:real8\",\n                          OMPI_HAVE_FORTRAN_REAL8 ? \"yes\" : \"no\");\n            opal_info_out(\"Fort have real16\", \"compiler:fortran:have:real16\",\n                          OMPI_HAVE_FORTRAN_REAL16 && OMPI_REAL16_MATCHES_C ? \"yes\" : \"no\");\n\n            opal_info_out(\"Fort have complex4\", \"compiler:fortran:have:complex4\",\n                          OMPI_HAVE_FORTRAN_COMPLEX4 ? \"yes\" : \"no\");\n            opal_info_out(\"Fort have complex8\", \"compiler:fortran:have:complex8\",\n                          OMPI_HAVE_FORTRAN_COMPLEX8 ? \"yes\" : \"no\");\n            opal_info_out(\"Fort have complex16\", \"compiler:fortran:have:complex16\",\n                          OMPI_HAVE_FORTRAN_COMPLEX16 ? \"yes\" : \"no\");\n            opal_info_out(\"Fort have complex32\", \"compiler:fortran:have:complex32\",\n                          OMPI_HAVE_FORTRAN_COMPLEX32 && OMPI_REAL16_MATCHES_C ? \"yes\" : \"no\");\n\n            opal_info_out_int(\"Fort integer1 size\", \"compiler:fortran:sizeof:integer1\",\n                          OMPI_HAVE_FORTRAN_INTEGER1 ? OMPI_SIZEOF_FORTRAN_INTEGER1 : -1);\n            opal_info_out_int(\"Fort integer2 size\", \"compiler:fortran:sizeof:integer2\",\n                          OMPI_HAVE_FORTRAN_INTEGER2 ? OMPI_SIZEOF_FORTRAN_INTEGER2 : -1);\n            opal_info_out_int(\"Fort integer4 size\", \"compiler:fortran:sizeof:integer4\",\n                          OMPI_HAVE_FORTRAN_INTEGER4 ? OMPI_SIZEOF_FORTRAN_INTEGER4 : -1);\n            opal_info_out_int(\"Fort integer8 size\", \"compiler:fortran:sizeof:integer8\",\n                          OMPI_HAVE_FORTRAN_INTEGER8 ? OMPI_SIZEOF_FORTRAN_INTEGER8 : -1);\n            opal_info_out_int(\"Fort integer16 size\", \"compiler:fortran:sizeof:integer16\",\n                          OMPI_HAVE_FORTRAN_INTEGER16 ? OMPI_SIZEOF_FORTRAN_INTEGER16 : -1);\n\n            opal_info_out_int(\"Fort real size\", \"compiler:fortran:sizeof:real\",\n                          OMPI_SIZEOF_FORTRAN_REAL);\n            opal_info_out_int(\"Fort real2 size\", \"compiler:fortran:sizeof:real2\",\n                          OMPI_HAVE_FORTRAN_REAL2 ? OMPI_SIZEOF_FORTRAN_REAL2 : -1);\n            opal_info_out_int(\"Fort real4 size\", \"compiler:fortran:sizeof:real4\",\n                          OMPI_HAVE_FORTRAN_REAL4 ? OMPI_SIZEOF_FORTRAN_REAL4 : -1);\n            opal_info_out_int(\"Fort real8 size\", \"compiler:fortran:sizeof:real8\",\n                          OMPI_HAVE_FORTRAN_REAL8 ? OMPI_SIZEOF_FORTRAN_REAL8 : -1);\n            opal_info_out_int(\"Fort real16 size\", \"compiler:fortran:sizeof:real17\",\n                          OMPI_HAVE_FORTRAN_REAL16 ? OMPI_SIZEOF_FORTRAN_REAL16 : -1);\n\n            opal_info_out_int(\"Fort dbl prec size\",\n                          \"compiler:fortran:sizeof:double_precision\",\n                          OMPI_SIZEOF_FORTRAN_DOUBLE_PRECISION);\n\n            opal_info_out_int(\"Fort cplx size\", \"compiler:fortran:sizeof:complex\",\n                          OMPI_SIZEOF_FORTRAN_COMPLEX);\n            opal_info_out_int(\"Fort dbl cplx size\",\n                          \"compiler:fortran:sizeof:double_complex\",\n                          OMPI_HAVE_FORTRAN_DOUBLE_COMPLEX ? OMPI_SIZEOF_FORTRAN_DOUBLE_COMPLEX : -1);\n            opal_info_out_int(\"Fort cplx4 size\", \"compiler:fortran:sizeof:complex4\",\n                          OMPI_HAVE_FORTRAN_COMPLEX4 ? OMPI_SIZEOF_FORTRAN_COMPLEX4 : -1);\n            opal_info_out_int(\"Fort cplx8 size\", \"compiler:fortran:sizeof:complex8\",\n                          OMPI_HAVE_FORTRAN_COMPLEX8 ? OMPI_SIZEOF_FORTRAN_COMPLEX8 : -1);\n            opal_info_out_int(\"Fort cplx16 size\", \"compiler:fortran:sizeof:complex16\",\n                          OMPI_HAVE_FORTRAN_COMPLEX16 ? OMPI_SIZEOF_FORTRAN_COMPLEX16 : -1);\n            opal_info_out_int(\"Fort cplx32 size\", \"compiler:fortran:sizeof:complex32\",\n                          OMPI_HAVE_FORTRAN_COMPLEX32 ? OMPI_SIZEOF_FORTRAN_COMPLEX32 : -1);\n\n            opal_info_out_int(\"Fort integer align\", \"compiler:fortran:align:integer\",\n                          OMPI_ALIGNMENT_FORTRAN_INTEGER);\n            opal_info_out_int(\"Fort integer1 align\", \"compiler:fortran:align:integer1\",\n                          OMPI_HAVE_FORTRAN_INTEGER1 ? OMPI_ALIGNMENT_FORTRAN_INTEGER1 : -1);\n            opal_info_out_int(\"Fort integer2 align\", \"compiler:fortran:align:integer2\",\n                          OMPI_HAVE_FORTRAN_INTEGER2 ? OMPI_ALIGNMENT_FORTRAN_INTEGER2 : -1);\n            opal_info_out_int(\"Fort integer4 align\", \"compiler:fortran:align:integer4\",\n                          OMPI_HAVE_FORTRAN_INTEGER4 ? OMPI_ALIGNMENT_FORTRAN_INTEGER4 : -1);\n            opal_info_out_int(\"Fort integer8 align\", \"compiler:fortran:align:integer8\",\n                          OMPI_HAVE_FORTRAN_INTEGER8 ? OMPI_ALIGNMENT_FORTRAN_INTEGER8 : -1);\n            opal_info_out_int(\"Fort integer16 align\", \"compiler:fortran:align:integer16\",\n                          OMPI_HAVE_FORTRAN_INTEGER16 ? OMPI_ALIGNMENT_FORTRAN_INTEGER16 : -1);\n\n            opal_info_out_int(\"Fort real align\", \"compiler:fortran:align:real\",\n                          OMPI_ALIGNMENT_FORTRAN_REAL);\n            opal_info_out_int(\"Fort real2 align\", \"compiler:fortran:align:real2\",\n                          OMPI_HAVE_FORTRAN_REAL2 ? OMPI_ALIGNMENT_FORTRAN_REAL2 : -1);\n            opal_info_out_int(\"Fort real4 align\", \"compiler:fortran:align:real4\",\n                          OMPI_HAVE_FORTRAN_REAL4 ? OMPI_ALIGNMENT_FORTRAN_REAL4 : -1);\n            opal_info_out_int(\"Fort real8 align\", \"compiler:fortran:align:real8\",\n                          OMPI_HAVE_FORTRAN_REAL8 ? OMPI_ALIGNMENT_FORTRAN_REAL8 : -1);\n            opal_info_out_int(\"Fort real16 align\", \"compiler:fortran:align:real16\",\n                          OMPI_HAVE_FORTRAN_REAL16 ? OMPI_ALIGNMENT_FORTRAN_REAL16 : -1);\n\n            opal_info_out_int(\"Fort dbl prec align\",\n                          \"compiler:fortran:align:double_precision\",\n                          OMPI_ALIGNMENT_FORTRAN_DOUBLE_PRECISION);\n\n            opal_info_out_int(\"Fort cplx align\", \"compiler:fortran:align:complex\",\n                          OMPI_ALIGNMENT_FORTRAN_COMPLEX);\n            opal_info_out_int(\"Fort dbl cplx align\",\n                          \"compiler:fortran:align:double_complex\",\n                          OMPI_HAVE_FORTRAN_DOUBLE_COMPLEX ? OMPI_ALIGNMENT_FORTRAN_DOUBLE_COMPLEX : -1);\n            opal_info_out_int(\"Fort cplx4 align\", \"compiler:fortran:align:complex4\",\n                          OMPI_HAVE_FORTRAN_COMPLEX4 ? OMPI_ALIGNMENT_FORTRAN_COMPLEX4 : -1);\n            opal_info_out_int(\"Fort cplx8 align\", \"compiler:fortran:align:complex8\",\n                          OMPI_HAVE_FORTRAN_COMPLEX8 ? OMPI_ALIGNMENT_FORTRAN_COMPLEX8 : -1);\n            opal_info_out_int(\"Fort cplx16 align\", \"compiler:fortran:align:complex16\",\n                          OMPI_HAVE_FORTRAN_COMPLEX16 ? OMPI_ALIGNMENT_FORTRAN_COMPLEX16 : -1);\n            opal_info_out_int(\"Fort cplx32 align\", \"compiler:fortran:align:complex32\",\n                          OMPI_HAVE_FORTRAN_COMPLEX32 ? OMPI_ALIGNMENT_FORTRAN_COMPLEX32 : -1);\n\n        } else {\n            opal_info_out(\"Fort real size\", \"compiler:fortran:sizeof:real\", \"skipped\");\n            opal_info_out(\"Fort dbl prec size\",\n                          \"compiler:fortran:sizeof:double_precision\", \"skipped\");\n            opal_info_out(\"Fort cplx size\", \"compiler:fortran:sizeof:complex\", \"skipped\");\n            opal_info_out(\"Fort dbl cplx size\",\n                          \"compiler:fortran:sizeof:double_complex\", \"skipped\");\n\n            opal_info_out(\"Fort integer align\", \"compiler:fortran:align:integer\", \"skipped\");\n            opal_info_out(\"Fort real align\", \"compiler:fortran:align:real\", \"skipped\");\n            opal_info_out(\"Fort dbl prec align\",\n                          \"compiler:fortran:align:double_precision\",\"skipped\");\n            opal_info_out(\"Fort cplx align\", \"compiler:fortran:align:complex\", \"skipped\");\n            opal_info_out(\"Fort dbl cplx align\",\n                          \"compiler:fortran:align:double_complex\", \"skipped\");\n        }\n    }\n\n    opal_info_out(\"C profiling\", \"option:profiling:c\", cprofiling);\n    opal_info_out(\"Fort mpif.h profiling\", \"option:profiling:mpif.h\",\n                  fortran_mpifh_profiling);\n    opal_info_out(\"Fort use mpi profiling\", \"option:profiling:use_mpi\",\n                  fortran_usempi_profiling);\n    opal_info_out(\"Fort use mpi_f08 prof\",\n                  \"option:profiling:use_mpi_f08\",\n                  fortran_usempif08_profiling);\n\n    opal_info_out(\"Thread support\", \"option:threads\", threads);\n    free(threads);\n    opal_info_out(\"Sparse Groups\", \"option:sparse:groups\", sparse_groups);\n\n    if (want_all) {\n\n        /* Don't display the build CPPFLAGS or CXXCPPFLAGS because they're\n         * just -I$(top_srcdir)/include, etc.  Hence, they're a) boring,\n         * and c) specific for ompi_info.\n         */\n\n        opal_info_out(\"Build CFLAGS\", \"option:build:cflags\", OMPI_BUILD_CFLAGS);\n        opal_info_out(\"Build FCFLAGS\", \"option:build:fcflags\", OMPI_BUILD_FCFLAGS);\n        opal_info_out(\"Build LDFLAGS\", \"option:build:ldflags\", OMPI_BUILD_LDFLAGS);\n        opal_info_out(\"Build LIBS\", \"option:build:libs\", OMPI_BUILD_LIBS);\n\n        opal_info_out(\"Wrapper extra CFLAGS\", \"option:wrapper:extra_cflags\",\n                      WRAPPER_EXTRA_CFLAGS);\n        opal_info_out(\"Wrapper extra CXXFLAGS\", \"option:wrapper:extra_cxxflags\",\n                      WRAPPER_EXTRA_CXXFLAGS);\n        opal_info_out(\"Wrapper extra FCFLAGS\", \"option:wrapper:extra_fcflags\",\n                      WRAPPER_EXTRA_FCFLAGS);\n        opal_info_out(\"Wrapper extra LDFLAGS\", \"option:wrapper:extra_ldflags\",\n                      WRAPPER_EXTRA_LDFLAGS);\n        opal_info_out(\"Wrapper extra LIBS\", \"option:wrapper:extra_libs\",\n                      WRAPPER_EXTRA_LIBS);\n    }\n\n    opal_info_out(\"Internal debug support\", \"option:debug\", debug);\n    opal_info_out(\"MPI interface warnings\", \"option:mpi-interface-warning\", mpi_interface_warning);\n    opal_info_out(\"MPI parameter check\", \"option:mpi-param-check\", paramcheck);\n    opal_info_out(\"Memory profiling support\", \"option:mem-profile\", memprofile);\n    opal_info_out(\"Memory debugging support\", \"option:mem-debug\", memdebug);\n    opal_info_out(\"dl support\", \"option:dlopen\", have_dl);\n    opal_info_out(\"Heterogeneous support\", \"options:heterogeneous\", heterogeneous);\n    opal_info_out(\"MPI_WTIME support\", \"options:mpi-wtime\", wtime_support);\n    opal_info_out(\"Symbol vis. support\", \"options:visibility\", symbol_visibility);\n    opal_info_out(\"Host topology support\", \"options:host-topology\",\n                  topology_support);\n    opal_info_out(\"IPv6 support\", \"options:ipv6\", ipv6_support);\n\n    opal_info_out(\"MPI extensions\", \"options:mpi_ext\", OMPI_MPIEXT_COMPONENTS);\n\n    opal_info_out(\"FT Checkpoint support\", \"options:ft_support\", ft_support);\n    free(ft_support);\n\n    opal_info_out(\"C/R Enabled Debugging\", \"options:crdebug_support\", crdebug_support);\n    free(crdebug_support);\n\n    opal_info_out_int(\"MPI_MAX_PROCESSOR_NAME\", \"options:mpi-max-processor-name\",\n                  MPI_MAX_PROCESSOR_NAME);\n    opal_info_out_int(\"MPI_MAX_ERROR_STRING\",   \"options:mpi-max-error-string\",\n                  MPI_MAX_ERROR_STRING);\n    opal_info_out_int(\"MPI_MAX_OBJECT_NAME\",    \"options:mpi-max-object-name\",\n                  MPI_MAX_OBJECT_NAME);\n    opal_info_out_int(\"MPI_MAX_INFO_KEY\",       \"options:mpi-max-info-key\",\n                  MPI_MAX_INFO_KEY);\n    opal_info_out_int(\"MPI_MAX_INFO_VAL\",       \"options:mpi-max-info-val\",\n                  MPI_MAX_INFO_VAL);\n    opal_info_out_int(\"MPI_MAX_PORT_NAME\",      \"options:mpi-max-port-name\",\n                  MPI_MAX_PORT_NAME);\n    opal_info_out_int(\"MPI_MAX_DATAREP_STRING\", \"options:mpi-max-datarep-string\",\n                  MPI_MAX_DATAREP_STRING);\n\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-openmpi-master-qcrm7qmgqutvsby2zcmdb57s22lzfq65/spack-src/oshmem/mca/memheap/base/memheap_base_static.c": "/*\n * Copyright (c) 2013      Mellanox Technologies, Inc.\n *                         All rights reserved.\n * Copyright (c) 2016      IBM Corporation.  All rights reserved.\n * $COPYRIGHT$\n *\n * Additional copyrights may follow\n *\n * $HEADER$\n */\n#include \"oshmem_config.h\"\n\n#include \"oshmem/util/oshmem_util.h\"\n#include \"oshmem/proc/proc.h\"\n#include \"oshmem/mca/memheap/memheap.h\"\n#include \"oshmem/mca/memheap/base/base.h\"\n#include \"oshmem/util/oshmem_util.h\"\n\n#include <stdio.h>\n\nstruct map_segment_desc {\n    void* start;\n    void* end;\n    char perms[8];\n    uint64_t offset;\n    char dev[8];\n    uint64_t inode;\n    char pathname[MAXPATHLEN];\n};\n\ntypedef struct memheap_static_context {\n    struct {\n        void* start;\n        void* end;\n    } mem_segs[MCA_MEMHEAP_MAX_SEGMENTS];\n    int n_segments;\n} memheap_static_context_t;\n\nstatic memheap_static_context_t memheap_context;\n\nstatic int _load_segments(void);\nstatic int _check_perms(struct map_segment_desc *seg);\nstatic int _check_address(struct map_segment_desc *seg);\nstatic int _check_pathname(struct map_segment_desc *seg);\n\nint mca_memheap_base_static_init(mca_memheap_map_t *map)\n{\n    /* read and parse segments from /proc/self/maps */\n    int ret = OSHMEM_SUCCESS;\n\n    assert(map);\n    assert(HEAP_SEG_INDEX < map->n_segments);\n\n    ret = _load_segments();\n\n    if (OSHMEM_SUCCESS == ret) {\n        int i;\n        size_t total_mem;\n\n        for (i = 0, total_mem = 0; i < memheap_context.n_segments; i++) {\n            map_segment_t *s = &map->mem_segs[map->n_segments];\n\n            memset(s, 0, sizeof(*s));\n            MAP_SEGMENT_RESET_FLAGS(s);\n            s->seg_id = MAP_SEGMENT_SHM_INVALID;\n            s->super.va_base = memheap_context.mem_segs[i].start;\n            s->super.va_end  = memheap_context.mem_segs[i].end;\n            s->seg_size = ((uintptr_t)s->super.va_end - (uintptr_t)s->super.va_base);\n            s->type = MAP_SEGMENT_STATIC;\n            map->n_segments++;\n\n            total_mem += ((uintptr_t)s->super.va_end - (uintptr_t)s->super.va_base);\n        }\n        MEMHEAP_VERBOSE(1,\n                        \"Memheap static memory: %llu byte(s), %d segments\",\n                        (unsigned long long)total_mem, map->n_segments);\n    }\n\n    return ret;\n}\n\nvoid mca_memheap_base_static_exit(mca_memheap_map_t *map)\n{\n    assert(map);\n}\n\nstatic int _check_perms(struct map_segment_desc *seg)\n{\n    if (!strcmp(seg->perms, \"rw-p\") || !strcmp(seg->perms, \"rwxp\"))\n        return OSHMEM_SUCCESS;\n\n    return OSHMEM_ERROR;\n}\n\nstatic int _check_address(struct map_segment_desc *seg)\n{\n    /* FIXME Linux specific code */\n#ifdef __linux__\n    extern unsigned _end;\n    void* data_end = &_end;\n\n    /**\n     * SGI shmem only supports globals&static in main program.\n     * It does not support them in shared objects or in dlopen()\n     * (Clarified on PGAS 2011 tutorial)\n     *\n     * So ignored any maps that start higher then process _end\n     * FIXME: make sure we do not register symmetric heap twice\n     * if we decide to allow shared objects\n     */\n    if ((uintptr_t)seg->start > (uintptr_t)data_end) {\n        MEMHEAP_VERBOSE(100,\n                        \"skip segment: data _end < segment start (%p < %p)\",\n                        data_end, seg->start);\n        return OSHMEM_ERROR;\n    }\n\n    if ((uintptr_t)seg->end > (uintptr_t)data_end) {\n        MEMHEAP_VERBOSE(100,\n                        \"adjust segment: data _end < segment end (%p < %p\",\n                        data_end, seg->end);\n         seg->end = data_end;\n    }\n#endif\n    return OSHMEM_SUCCESS;\n}\n\nstatic int _check_pathname(struct map_segment_desc *seg)\n{\n    /* Probably we need to check found path but\n     * To press check coverity issue following code is disabled\n     */\n#if 0\n    char *p;\n    if ('\\0' == seg->pathname[0])\n    return OSHMEM_SUCCESS;\n\n    if (0 == strncmp(seg->pathname, \"/lib\", 4))\n    return OSHMEM_ERROR;\n\n    if (0 == strncmp(seg->pathname, \"/usr/lib\", 8))\n    return OSHMEM_ERROR;\n\n    if (0 == strncmp(seg->pathname, \"/dev\", 4))\n    return OSHMEM_ERROR;\n\n    if (0 == strcmp(seg->pathname, \"[stack]\"))\n    return OSHMEM_ERROR;\n\n    if (0 == strcmp(seg->pathname, \"[vdso]\"))\n    return OSHMEM_ERROR;\n\n    if (0 == strcmp(seg->pathname, \"[vsyscall]\"))\n    return OSHMEM_ERROR;\n\n    p = rindex(seg->pathname, '/');\n    if (p) {\n        if (0 == strncmp(p+1, \"libshmem.so\", 11))\n        return OSHMEM_ERROR;\n\n        if (0 == strncmp(p+1, \"lib\" OMPI_LIBMPI_NAME \".so\", 9))\n        return OSHMEM_ERROR;\n\n        if (0 == strncmp(p+1, \"libmca_common_sm.so\", 19))\n        return OSHMEM_ERROR;\n    }\n#endif\n    return OSHMEM_SUCCESS;\n}\n\nstatic int _load_segments(void)\n{\n    FILE *fp;\n    char line[1024];\n    struct map_segment_desc seg;\n\n    memheap_context.n_segments = 0;\n    /* FIXME!!! Linux specific code */\n    fp = fopen(\"/proc/self/maps\", \"r\");\n    if (NULL == fp) {\n        MEMHEAP_ERROR(\"Failed to open /proc/self/maps\");\n        return OSHMEM_ERROR;\n    }\n\n    while (NULL != fgets(line, sizeof(line), fp)) {\n        memset(&seg, 0, sizeof(seg));\n        if (3 > sscanf(line,\n               \"%llx-%llx %s %llx %s %llx %s\",\n               (unsigned long long *) &seg.start,\n               (unsigned long long *) &seg.end,\n               seg.perms,\n               (unsigned long long *) &seg.offset,\n               seg.dev,\n               (unsigned long long *) &seg.inode,\n               seg.pathname)) {\n            MEMHEAP_ERROR(\"Failed to sscanf /proc/self/maps output %s\", line);\n            fclose(fp);\n            return OSHMEM_ERROR;\n        }\n\n        if (OSHMEM_ERROR == _check_address(&seg))\n            continue;\n\n        if (OSHMEM_ERROR == _check_pathname(&seg))\n            continue;\n\n        if (OSHMEM_ERROR == _check_perms(&seg))\n            continue;\n\n        MEMHEAP_VERBOSE(5, \"add: %s\", line);\n        if (MCA_MEMHEAP_MAX_SEGMENTS <= memheap_context.n_segments) {\n            MEMHEAP_ERROR(\"too many segments (max = %d): skip %s\",\n                          MCA_MEMHEAP_MAX_SEGMENTS, line);\n            continue;\n        }\n        if (memheap_context.n_segments > 0\n                && seg.start\n                        == memheap_context.mem_segs[memheap_context.n_segments\n                                - 1].end) {\n            MEMHEAP_VERBOSE(5, \"Coalescing segment\");\n            memheap_context.mem_segs[memheap_context.n_segments - 1].end =\n                    seg.end;\n        } else {\n            memheap_context.mem_segs[memheap_context.n_segments].start =\n                    seg.start;\n            memheap_context.mem_segs[memheap_context.n_segments].end = seg.end;\n            memheap_context.n_segments++;\n        }\n    }\n\n    fclose(fp);\n    return OSHMEM_SUCCESS;\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-openmpi-master-qcrm7qmgqutvsby2zcmdb57s22lzfq65/spack-src/oshmem/tools/oshmem_info/param.c": "/*\n * Copyright (c) 2013      Mellanox Technologies, Inc.\n *                         All rights reserved.\n *\n * Copyright (c) 2014-2018 Cisco Systems, Inc.  All rights reserved\n * Copyright (c) 2014-2019 Research Organization for Information Science\n *                         and Technology (RIST).  All rights reserved.\n * Copyright (c) 2016-2017 IBM Corporation. All rights reserved.\n * Copyright (c) 2018      Amazon.com, Inc. or its affiliates.  All Rights reserved.\n * Copyright (c) 2019      Intel, Inc.  All rights reserved.\n * $COPYRIGHT$\n *\n * Additional copyrights may follow\n *\n * $HEADER$\n */\n\n#include \"oshmem_config.h\"\n#include \"mpi.h\"\n#include \"shmem.h\"\n\n#include <string.h>\n#include <ctype.h>\n#ifdef HAVE_UNISTD_H\n#include <unistd.h>\n#endif\n#ifdef HAVE_SYS_PARAM_H\n#include <sys/param.h>\n#endif\n#ifdef HAVE_NETDB_H\n#include <netdb.h>\n#endif\n\n#include MCA_timer_IMPLEMENTATION_HEADER\n#include \"opal/include/opal/version.h\"\n#include \"opal/class/opal_value_array.h\"\n#include \"opal/class/opal_pointer_array.h\"\n#include \"opal/util/printf.h\"\n#include \"opal/memoryhooks/memory.h\"\n#include \"opal/runtime/opal_info_support.h\"\n\n#include \"ompi/tools/ompi_info/ompi_info.h\"\n#include \"ompi/include/mpi_portable_platform.h\"\n\n#include \"oshmem/tools/oshmem_info/oshmem_info.h\"\n\n\nconst char *opal_info_deprecated_value = \"deprecated-ompi-info-value\";\n\n/*\n * do_config\n * Accepts:\n *  - want_all: boolean flag; TRUE -> display all options\n *                FALSE -> display selected options\n *\n * This function displays all the options with which the current\n * installation of ompi was configured. There are many options here\n * that are carried forward from OMPI-7 and are not mca parameters\n * in OMPI-10. I have to dig through the invalid options and replace\n * them with OMPI-10 options.\n */\nvoid oshmem_info_do_config(bool want_all)\n{\n    char *fortran_binding;\n    char *heterogeneous;\n    char *memprofile;\n    char *memdebug;\n    char *debug;\n    char *mpi_interface_warning;\n    char *cprofiling;\n    char *fortran_profiling;\n    char *threads;\n    char *have_dl;\n    char *sparse_groups;\n    char *wtime_support;\n    char *symbol_visibility;\n    char *ft_support;\n    char *crdebug_support;\n    char *topology_support;\n\n    /* Do a little preprocessor trickery here to figure opal_info_out the\n     * tri-state of MPI_PARAM_CHECK (which will be either 0, 1, or\n     * ompi_mpi_param_check).  The preprocessor will only allow\n     * comparisons against constants, so you'll get a warning if you\n     * check MPI_PARAM_CHECK against 0 or 1, but its real value is the\n     * char *ompi_mpi_param_check.  So define ompi_mpi_param_check to\n     * be a constant, and then all the preprocessor comparisons work\n     * opal_info_out ok.  Note that we chose the preprocessor\n     * comparison ropal_info_oute because it is not sufficient to\n     * simply set the variable ompi_mpi_param_check to a non-0/non-1\n     * value.  This is because the compiler will generate a warning\n     * that that C variable is unused when MPI_PARAM_CHECK is\n     * hard-coded to 0 or 1.\n     */\n    char *paramcheck;\n#define ompi_mpi_param_check 999\n#if 0 == MPI_PARAM_CHECK\n    paramcheck = \"never\";\n#elif 1 == MPI_PARAM_CHECK\n    paramcheck = \"always\";\n#else\n    paramcheck = \"runtime\";\n#endif\n\n    heterogeneous = OPAL_ENABLE_HETEROGENEOUS_SUPPORT ? \"yes\" : \"no\";\n    memprofile = OPAL_ENABLE_MEM_PROFILE ? \"yes\" : \"no\";\n    memdebug = OPAL_ENABLE_MEM_DEBUG ? \"yes\" : \"no\";\n    debug = OPAL_ENABLE_DEBUG ? \"yes\" : \"no\";\n    mpi_interface_warning = OMPI_WANT_MPI_INTERFACE_WARNING ? \"yes\" : \"no\";\n    cprofiling = \"yes\";\n    fortran_profiling = (OMPI_BUILD_FORTRAN_BINDINGS >= OMPI_FORTRAN_MPIFH_BINDINGS) ? \"yes\" : \"no\";\n    have_dl = OPAL_HAVE_DL_SUPPORT ? \"yes\" : \"no\";\n    sparse_groups = OMPI_GROUP_SPARSE ? \"yes\" : \"no\";\n    wtime_support = OPAL_TIMER_USEC_NATIVE ? \"native\" : \"gettimeofday\";\n    symbol_visibility = OPAL_C_HAVE_VISIBILITY ? \"yes\" : \"no\";\n    topology_support = \"yes\";\n\n    /* setup strings that require allocation */\n    if (OMPI_BUILD_FORTRAN_BINDINGS >= OMPI_FORTRAN_MPIFH_BINDINGS) {\n        (void)opal_asprintf(&fortran_binding, \"yes (%s)\",\n                       (OPAL_HAVE_WEAK_SYMBOLS ? \"all\" :\n                        (OMPI_FORTRAN_CAPS ? \"caps\" :\n                         (OMPI_FORTRAN_PLAIN ? \"lower case\" :\n                          (OMPI_FORTRAN_SINGLE_UNDERSCORE ? \"single underscore\" : \"double underscore\")))));\n    } else {\n        fortran_binding = strdup(\"no\");\n    }\n\n    (void)opal_asprintf(&threads, \"%s (MPI_THREAD_MULTIPLE: yes, OPAL support: yes, OMPI progress: %s, Event lib: yes)\",\n                   \"posix\", OPAL_ENABLE_PROGRESS_THREADS ? \"yes\" : \"no\");\n\n    (void)opal_asprintf(&ft_support, \"%s (checkpoint thread: %s)\",\n                   OPAL_ENABLE_FT ? \"yes\" : \"no\", OPAL_ENABLE_FT_THREAD ? \"yes\" : \"no\");\n\n    (void)opal_asprintf(&crdebug_support, \"%s\",\n                   OPAL_ENABLE_CRDEBUG ? \"yes\" : \"no\");\n\n    /* output values */\n    opal_info_out(\"Configured by\", \"config:user\", OPAL_CONFIGURE_USER);\n    opal_info_out(\"Configured on\", \"config:timestamp\", OPAL_CONFIGURE_DATE);\n    opal_info_out(\"Configure host\", \"config:host\", OPAL_CONFIGURE_HOST);\n    opal_info_out(\"Configure command line\", \"config:cli\", OPAL_CONFIGURE_CLI);\n\n    opal_info_out(\"Built by\", \"build:user\", OMPI_BUILD_USER);\n    opal_info_out(\"Built on\", \"build:timestamp\", OMPI_BUILD_DATE);\n    opal_info_out(\"Built host\", \"build:host\", OMPI_BUILD_HOST);\n\n    opal_info_out(\"C bindings\", \"bindings:c\", \"yes\");\n    opal_info_out(\"Fort shmem.fh\", \"bindings:fortran\", fortran_binding);\n    free(fortran_binding);\n\n    opal_info_out(\"Wrapper compiler rpath\", \"compiler:all:rpath\",\n                  WRAPPER_RPATH_SUPPORT);\n    opal_info_out(\"C compiler\", \"compiler:c:command\", OPAL_CC);\n    opal_info_out(\"C compiler absolute\", \"compiler:c:absolute\",\n                  OPAL_CC_ABSOLUTE);\n    opal_info_out(\"C compiler family name\", \"compiler:c:familyname\",\n                  _STRINGIFY(OPAL_BUILD_PLATFORM_COMPILER_FAMILYNAME));\n    opal_info_out(\"C compiler version\", \"compiler:c:version\",\n                  _STRINGIFY(OPAL_BUILD_PLATFORM_COMPILER_VERSION_STR));\n\n    if (want_all) {\n        opal_info_out_int(\"C char size\", \"compiler:c:sizeof:char\", sizeof(char));\n        /* JMS: should be fixed in MPI-2.2 to differentiate between C\n           _Bool and C++ bool.  For the moment, the code base assumes\n           that they are the same.  Because of opal_config_bottom.h,\n           we can sizeof(bool) here, so we might as well -- even\n           though this technically isn't right.  This should be fixed\n           when we update to MPI-2.2.  See below for note about C++\n           bool alignment. */\n        opal_info_out_int(\"C bool size\", \"compiler:c:sizeof:bool\", sizeof(bool));\n        opal_info_out_int(\"C short size\", \"compiler:c:sizeof:short\", sizeof(short));\n        opal_info_out_int(\"C int size\", \"compiler:c:sizeof:int\", sizeof(int));\n        opal_info_out_int(\"C long size\", \"compiler:c:sizeof:long\", sizeof(long));\n        opal_info_out_int(\"C float size\", \"compiler:c:sizeof:float\", sizeof(float));\n        opal_info_out_int(\"C double size\", \"compiler:c:sizeof:double\", sizeof(double));\n        opal_info_out_int(\"C pointer size\", \"compiler:c:sizeof:pointer\", sizeof(void *));\n        opal_info_out_int(\"C char align\", \"compiler:c:align:char\", OPAL_ALIGNMENT_CHAR);\n        opal_info_out(\"C bool align\", \"compiler:c:align:bool\", \"skipped\");\n        opal_info_out_int(\"C int align\", \"compiler:c:align:int\", OPAL_ALIGNMENT_INT);\n        opal_info_out_int(\"C float align\", \"compiler:c:align:float\", OPAL_ALIGNMENT_FLOAT);\n        opal_info_out_int(\"C double align\", \"compiler:c:align:double\", OPAL_ALIGNMENT_DOUBLE);\n    }\n\n    opal_info_out(\"C++ compiler\", \"compiler:cxx:command\", OMPI_CXX);\n    opal_info_out(\"C++ compiler absolute\", \"compiler:cxx:absolute\", OMPI_CXX_ABSOLUTE);\n    opal_info_out(\"Fort compiler\", \"compiler:fortran:command\", OMPI_FC);\n    opal_info_out(\"Fort compiler abs\", \"compiler:fortran:absolute\",\n                  OMPI_FC_ABSOLUTE);\n\n    if (want_all) {\n\n        /* Will always have the size of Fortran integer */\n\n        opal_info_out_int(\"Fort integer size\", \"compiler:fortran:sizeof:integer\",\n                      OMPI_SIZEOF_FORTRAN_INTEGER);\n\n        opal_info_out_int(\"Fort logical size\", \"compiler:fortran:sizeof:logical\",\n                      OMPI_SIZEOF_FORTRAN_LOGICAL);\n        opal_info_out_int(\"Fort logical value true\", \"compiler:fortran:value:true\",\n                      OMPI_FORTRAN_VALUE_TRUE);\n\n\n        /* May or may not have the other Fortran sizes */\n\n        if (OMPI_BUILD_FORTRAN_BINDINGS >= OMPI_FORTRAN_MPIFH_BINDINGS) {\n            opal_info_out(\"Fort have integer1\", \"compiler:fortran:have:integer1\",\n                          OMPI_HAVE_FORTRAN_INTEGER1 ? \"yes\" : \"no\");\n            opal_info_out(\"Fort have integer2\", \"compiler:fortran:have:integer2\",\n                          OMPI_HAVE_FORTRAN_INTEGER2 ? \"yes\" : \"no\");\n            opal_info_out(\"Fort have integer4\", \"compiler:fortran:have:integer4\",\n                          OMPI_HAVE_FORTRAN_INTEGER4 ? \"yes\" : \"no\");\n            opal_info_out(\"Fort have integer8\", \"compiler:fortran:have:integer8\",\n                          OMPI_HAVE_FORTRAN_INTEGER8 ? \"yes\" : \"no\");\n            opal_info_out(\"Fort have integer16\", \"compiler:fortran:have:integer16\",\n                          OMPI_HAVE_FORTRAN_INTEGER16 ? \"yes\" : \"no\");\n\n            opal_info_out(\"Fort have real4\", \"compiler:fortran:have:real4\",\n                          OMPI_HAVE_FORTRAN_REAL4 ? \"yes\" : \"no\");\n            opal_info_out(\"Fort have real8\", \"compiler:fortran:have:real8\",\n                          OMPI_HAVE_FORTRAN_REAL8 ? \"yes\" : \"no\");\n            opal_info_out(\"Fort have real16\", \"compiler:fortran:have:real16\",\n                          OMPI_HAVE_FORTRAN_REAL16 && OMPI_REAL16_MATCHES_C ? \"yes\" : \"no\");\n\n            opal_info_out(\"Fort have complex8\", \"compiler:fortran:have:complex8\",\n                          OMPI_HAVE_FORTRAN_COMPLEX8 ? \"yes\" : \"no\");\n            opal_info_out(\"Fort have complex16\", \"compiler:fortran:have:complex16\",\n                          OMPI_HAVE_FORTRAN_COMPLEX16 ? \"yes\" : \"no\");\n            opal_info_out(\"Fort have complex32\", \"compiler:fortran:have:complex32\",\n                          OMPI_HAVE_FORTRAN_COMPLEX32 && OMPI_REAL16_MATCHES_C ? \"yes\" : \"no\");\n\n            opal_info_out_int(\"Fort integer1 size\", \"compiler:fortran:sizeof:integer1\",\n                          OMPI_HAVE_FORTRAN_INTEGER1 ? OMPI_SIZEOF_FORTRAN_INTEGER1 : -1);\n            opal_info_out_int(\"Fort integer2 size\", \"compiler:fortran:sizeof:integer2\",\n                          OMPI_HAVE_FORTRAN_INTEGER2 ? OMPI_SIZEOF_FORTRAN_INTEGER2 : -1);\n            opal_info_out_int(\"Fort integer4 size\", \"compiler:fortran:sizeof:integer4\",\n                          OMPI_HAVE_FORTRAN_INTEGER4 ? OMPI_SIZEOF_FORTRAN_INTEGER4 : -1);\n            opal_info_out_int(\"Fort integer8 size\", \"compiler:fortran:sizeof:integer8\",\n                          OMPI_HAVE_FORTRAN_INTEGER8 ? OMPI_SIZEOF_FORTRAN_INTEGER8 : -1);\n            opal_info_out_int(\"Fort integer16 size\", \"compiler:fortran:sizeof:integer16\",\n                          OMPI_HAVE_FORTRAN_INTEGER16 ? OMPI_SIZEOF_FORTRAN_INTEGER16 : -1);\n\n            opal_info_out_int(\"Fort real size\", \"compiler:fortran:sizeof:real\",\n                          OMPI_SIZEOF_FORTRAN_REAL);\n            opal_info_out_int(\"Fort real4 size\", \"compiler:fortran:sizeof:real4\",\n                          OMPI_HAVE_FORTRAN_REAL4 ? OMPI_SIZEOF_FORTRAN_REAL4 : -1);\n            opal_info_out_int(\"Fort real8 size\", \"compiler:fortran:sizeof:real8\",\n                          OMPI_HAVE_FORTRAN_REAL8 ? OMPI_SIZEOF_FORTRAN_REAL8 : -1);\n            opal_info_out_int(\"Fort real16 size\", \"compiler:fortran:sizeof:real17\",\n                          OMPI_HAVE_FORTRAN_REAL16 ? OMPI_SIZEOF_FORTRAN_REAL16 : -1);\n\n            opal_info_out_int(\"Fort dbl prec size\",\n                          \"compiler:fortran:sizeof:double_precision\",\n                          OMPI_SIZEOF_FORTRAN_DOUBLE_PRECISION);\n\n            opal_info_out_int(\"Fort cplx size\", \"compiler:fortran:sizeof:complex\",\n                          OMPI_SIZEOF_FORTRAN_COMPLEX);\n            opal_info_out_int(\"Fort dbl cplx size\",\n                          \"compiler:fortran:sizeof:double_complex\",\n                          OMPI_HAVE_FORTRAN_DOUBLE_COMPLEX ? OMPI_SIZEOF_FORTRAN_DOUBLE_COMPLEX : -1);\n            opal_info_out_int(\"Fort cplx8 size\", \"compiler:fortran:sizeof:complex8\",\n                          OMPI_HAVE_FORTRAN_COMPLEX8 ? OMPI_SIZEOF_FORTRAN_COMPLEX8 : -1);\n            opal_info_out_int(\"Fort cplx16 size\", \"compiler:fortran:sizeof:complex16\",\n                          OMPI_HAVE_FORTRAN_COMPLEX16 ? OMPI_SIZEOF_FORTRAN_COMPLEX16 : -1);\n            opal_info_out_int(\"Fort cplx32 size\", \"compiler:fortran:sizeof:complex32\",\n                          OMPI_HAVE_FORTRAN_COMPLEX32 ? OMPI_SIZEOF_FORTRAN_COMPLEX32 : -1);\n\n            opal_info_out_int(\"Fort integer align\", \"compiler:fortran:align:integer\",\n                          OMPI_ALIGNMENT_FORTRAN_INTEGER);\n            opal_info_out_int(\"Fort integer1 align\", \"compiler:fortran:align:integer1\",\n                          OMPI_HAVE_FORTRAN_INTEGER1 ? OMPI_ALIGNMENT_FORTRAN_INTEGER1 : -1);\n            opal_info_out_int(\"Fort integer2 align\", \"compiler:fortran:align:integer2\",\n                          OMPI_HAVE_FORTRAN_INTEGER2 ? OMPI_ALIGNMENT_FORTRAN_INTEGER2 : -1);\n            opal_info_out_int(\"Fort integer4 align\", \"compiler:fortran:align:integer4\",\n                          OMPI_HAVE_FORTRAN_INTEGER4 ? OMPI_ALIGNMENT_FORTRAN_INTEGER4 : -1);\n            opal_info_out_int(\"Fort integer8 align\", \"compiler:fortran:align:integer8\",\n                          OMPI_HAVE_FORTRAN_INTEGER8 ? OMPI_ALIGNMENT_FORTRAN_INTEGER8 : -1);\n            opal_info_out_int(\"Fort integer16 align\", \"compiler:fortran:align:integer16\",\n                          OMPI_HAVE_FORTRAN_INTEGER16 ? OMPI_ALIGNMENT_FORTRAN_INTEGER16 : -1);\n\n            opal_info_out_int(\"Fort real align\", \"compiler:fortran:align:real\",\n                          OMPI_ALIGNMENT_FORTRAN_REAL);\n            opal_info_out_int(\"Fort real4 align\", \"compiler:fortran:align:real4\",\n                          OMPI_HAVE_FORTRAN_REAL4 ? OMPI_ALIGNMENT_FORTRAN_REAL4 : -1);\n            opal_info_out_int(\"Fort real8 align\", \"compiler:fortran:align:real8\",\n                          OMPI_HAVE_FORTRAN_REAL8 ? OMPI_ALIGNMENT_FORTRAN_REAL8 : -1);\n            opal_info_out_int(\"Fort real16 align\", \"compiler:fortran:align:real16\",\n                          OMPI_HAVE_FORTRAN_REAL16 ? OMPI_ALIGNMENT_FORTRAN_REAL16 : -1);\n\n            opal_info_out_int(\"Fort dbl prec align\",\n                          \"compiler:fortran:align:double_precision\",\n                          OMPI_ALIGNMENT_FORTRAN_DOUBLE_PRECISION);\n\n            opal_info_out_int(\"Fort cplx align\", \"compiler:fortran:align:complex\",\n                          OMPI_ALIGNMENT_FORTRAN_COMPLEX);\n            opal_info_out_int(\"Fort dbl cplx align\",\n                          \"compiler:fortran:align:double_complex\",\n                          OMPI_HAVE_FORTRAN_DOUBLE_COMPLEX ? OMPI_ALIGNMENT_FORTRAN_DOUBLE_COMPLEX : -1);\n            opal_info_out_int(\"Fort cplx8 align\", \"compiler:fortran:align:complex8\",\n                          OMPI_HAVE_FORTRAN_COMPLEX8 ? OMPI_ALIGNMENT_FORTRAN_COMPLEX8 : -1);\n            opal_info_out_int(\"Fort cplx16 align\", \"compiler:fortran:align:complex16\",\n                          OMPI_HAVE_FORTRAN_COMPLEX16 ? OMPI_ALIGNMENT_FORTRAN_COMPLEX16 : -1);\n            opal_info_out_int(\"Fort cplx32 align\", \"compiler:fortran:align:complex32\",\n                          OMPI_HAVE_FORTRAN_COMPLEX32 ? OMPI_ALIGNMENT_FORTRAN_COMPLEX32 : -1);\n\n        } else {\n            opal_info_out(\"Fort real size\", \"compiler:fortran:sizeof:real\", \"skipped\");\n            opal_info_out(\"Fort dbl prec size\",\n                          \"compiler:fortran:sizeof:double_precision\", \"skipped\");\n            opal_info_out(\"Fort cplx size\", \"compiler:fortran:sizeof:complex\", \"skipped\");\n            opal_info_out(\"Fort dbl cplx size\",\n                          \"compiler:fortran:sizeof:double_complex\", \"skipped\");\n\n            opal_info_out(\"Fort integer align\", \"compiler:fortran:align:integer\", \"skipped\");\n            opal_info_out(\"Fort real align\", \"compiler:fortran:align:real\", \"skipped\");\n            opal_info_out(\"Fort dbl prec align\",\n                          \"compiler:fortran:align:double_precision\",\"skipped\");\n            opal_info_out(\"Fort cplx align\", \"compiler:fortran:align:complex\", \"skipped\");\n            opal_info_out(\"Fort dbl cplx align\",\n                          \"compiler:fortran:align:double_complex\", \"skipped\");\n        }\n    }\n\n    opal_info_out(\"C profiling\", \"option:profiling:c\", cprofiling);\n    opal_info_out(\"Fort shmem.fh profiling\", \"option:profiling:shmem.fh\",\n                  fortran_profiling);\n\n    opal_info_out(\"Thread support\", \"option:threads\", threads);\n    free(threads);\n    opal_info_out(\"Sparse Groups\", \"option:sparse:groups\", sparse_groups);\n\n    if (want_all) {\n\n        /* Don't display the build CPPFLAGS or CXXCPPFLAGS because they're\n         * just -I$(top_srcdir)/include, etc.  Hence, they're a) boring,\n         * and c) specific for ompi_info.\n         */\n\n        opal_info_out(\"Build CFLAGS\", \"option:build:cflags\", OMPI_BUILD_CFLAGS);\n        opal_info_out(\"Build CXXFLAGS\", \"option:build:cxxflags\", OMPI_BUILD_CXXFLAGS);\n        opal_info_out(\"Build FCFLAGS\", \"option:build:fcflags\", OMPI_BUILD_FCFLAGS);\n        opal_info_out(\"Build LDFLAGS\", \"option:build:ldflags\", OMPI_BUILD_LDFLAGS);\n        opal_info_out(\"Build LIBS\", \"option:build:libs\", OMPI_BUILD_LIBS);\n\n        opal_info_out(\"Wrapper extra CFLAGS\", \"option:wrapper:extra_cflags\",\n                      WRAPPER_EXTRA_CFLAGS);\n        opal_info_out(\"Wrapper extra CXXFLAGS\", \"option:wrapper:extra_cxxflags\",\n                      WRAPPER_EXTRA_CXXFLAGS);\n        opal_info_out(\"Wrapper extra FCFLAGS\", \"option:wrapper:extra_fcflags\",\n                      WRAPPER_EXTRA_FCFLAGS);\n        opal_info_out(\"Wrapper extra LDFLAGS\", \"option:wrapper:extra_ldflags\",\n                      WRAPPER_EXTRA_LDFLAGS);\n        opal_info_out(\"Wrapper extra LIBS\", \"option:wrapper:extra_libs\",\n                      WRAPPER_EXTRA_LIBS);\n    }\n\n    opal_info_out(\"Internal debug support\", \"option:debug\", debug);\n    opal_info_out(\"MPI interface warnings\", \"option:mpi-interface-warning\", mpi_interface_warning);\n    opal_info_out(\"MPI parameter check\", \"option:mpi-param-check\", paramcheck);\n    opal_info_out(\"Memory profiling support\", \"option:mem-profile\", memprofile);\n    opal_info_out(\"Memory debugging support\", \"option:mem-debug\", memdebug);\n    opal_info_out(\"dl support\", \"option:dlopen\", have_dl);\n    opal_info_out(\"Heterogeneous support\", \"options:heterogeneous\", heterogeneous);\n    opal_info_out(\"MPI_WTIME support\", \"options:mpi-wtime\", wtime_support);\n    opal_info_out(\"Symbol vis. support\", \"options:visibility\", symbol_visibility);\n    opal_info_out(\"Host topology support\", \"options:host-topology\",\n                  topology_support);\n\n    opal_info_out(\"MPI extensions\", \"options:mpi_ext\", OMPI_MPIEXT_COMPONENTS);\n\n    opal_info_out(\"FT Checkpoint support\", \"options:ft_support\", ft_support);\n    free(ft_support);\n\n    opal_info_out(\"C/R Enabled Debugging\", \"options:crdebug_support\", crdebug_support);\n    free(crdebug_support);\n\n    opal_info_out_int(\"MPI_MAX_PROCESSOR_NAME\", \"options:mpi-max-processor-name\",\n                  MPI_MAX_PROCESSOR_NAME);\n    opal_info_out_int(\"MPI_MAX_ERROR_STRING\",   \"options:mpi-max-error-string\",\n                  MPI_MAX_ERROR_STRING);\n    opal_info_out_int(\"MPI_MAX_OBJECT_NAME\",    \"options:mpi-max-object-name\",\n                  MPI_MAX_OBJECT_NAME);\n    opal_info_out_int(\"MPI_MAX_INFO_KEY\",       \"options:mpi-max-info-key\",\n                  MPI_MAX_INFO_KEY);\n    opal_info_out_int(\"MPI_MAX_INFO_VAL\",       \"options:mpi-max-info-val\",\n                  MPI_MAX_INFO_VAL);\n    opal_info_out_int(\"MPI_MAX_PORT_NAME\",      \"options:mpi-max-port-name\",\n                  MPI_MAX_PORT_NAME);\n    opal_info_out_int(\"MPI_MAX_DATAREP_STRING\", \"options:mpi-max-datarep-string\",\n                  MPI_MAX_DATAREP_STRING);\n\n    /* This block displays all the options with which the current\n     * installation of oshmem was configured. */\n    {\n        char *oshmem_fortran = OSHMEM_BUILD_FORTRAN_BINDINGS ? \"yes\" : \"no\";\n        char *oshmem_compat = OSHMEM_SPEC_COMPAT ? \"yes\" : \"no\";\n        char *oshmem_param_check = OSHMEM_PARAM_CHECK ? \"yes\" : \"no\";\n        char *oshmem_profiling = OSHMEM_PROFILING ? \"yes\" : \"no\";\n\n        opal_info_out(\"OSHMEM C bindings\", \"oshmem:bindings:c\", \"yes\");\n        opal_info_out(\"OSHMEM Fortran bindings\", \"oshmem:bindings:fort\", oshmem_fortran);\n        opal_info_out(\"OSHMEM SGI/Quadrics mode\", \"oshmem:options:spec_compat\", oshmem_compat);\n        opal_info_out(\"OSHMEM API param check\", \"oshmem:options:param_check\", oshmem_param_check);\n        opal_info_out(\"OSHMEM profiling support\", \"oshmem:options:profiling\", oshmem_profiling);\n    }\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-openmpi-master-qcrm7qmgqutvsby2zcmdb57s22lzfq65/spack-src/opal/Makefile.am": "#\n# Copyright (c) 2004-2005 The Trustees of Indiana University and Indiana\n#                         University Research and Technology\n#                         Corporation.  All rights reserved.\n# Copyright (c) 2004-2009 The University of Tennessee and The University\n#                         of Tennessee Research Foundation.  All rights\n#                         reserved.\n# Copyright (c) 2004-2009 High Performance Computing Center Stuttgart,\n#                         University of Stuttgart.  All rights reserved.\n# Copyright (c) 2004-2005 The Regents of the University of California.\n#                         All rights reserved.\n# Copyright (c) 2009-2015 Cisco Systems, Inc.  All rights reserved.\n# Copyright (c) 2015-2016 Intel, Inc. All rights reserved.\n# Copyright (c) 2016      Research Organization for Information Science\n#                         and Technology (RIST). All rights reserved.\n# Copyright (c) 2020      Amazon.com, Inc. or its affiliates.\n#                         All Rights reserved.\n# $COPYRIGHT$\n#\n# Additional copyrights may follow\n#\n# $HEADER$\n#\n\nSUBDIRS = \\\n\tinclude \\\n        datatype \\\n        etc \\\n        util \\\n\tmca/base \\\n\t$(MCA_opal_FRAMEWORKS_SUBDIRS) \\\n\t$(MCA_opal_FRAMEWORK_COMPONENT_STATIC_SUBDIRS) \\\n        . \\\n\t$(MCA_opal_FRAMEWORK_COMPONENT_DSO_SUBDIRS)\n\n# libltdl is included by variable because if --disable-dlopen was\n# used, there will be no generated Makefile in that directory (and\n# therefore make distclean will fail).\nDIST_SUBDIRS = \\\n\tinclude \\\n        datatype \\\n        etc \\\n\tutil \\\n\tmca/base \\\n\t$(MCA_opal_FRAMEWORKS_SUBDIRS) \\\n\t$(MCA_opal_FRAMEWORK_COMPONENT_ALL_SUBDIRS)\n\n# Build the main OPAL library\n\nlib_LTLIBRARIES = lib@OPAL_LIB_PREFIX@open-pal.la\nlib@OPAL_LIB_PREFIX@open_pal_la_SOURCES =\nlib@OPAL_LIB_PREFIX@open_pal_la_LIBADD = \\\n        datatype/libdatatype.la \\\n        mca/base/libmca_base.la \\\n        util/libopalutil.la \\\n\t$(MCA_opal_FRAMEWORK_LIBS) \\\n\t$(opal_libevent_LIBS) \\\n\t$(opal_hwloc_LIBS) \\\n\t$(opal_pmix_LIBS)\nlib@OPAL_LIB_PREFIX@open_pal_la_DEPENDENCIES = \\\n        datatype/libdatatype.la \\\n        mca/base/libmca_base.la \\\n        util/libopalutil.la \\\n        $(MCA_opal_FRAMEWORK_LIBS)\nlib@OPAL_LIB_PREFIX@open_pal_la_LDFLAGS = -version-info $(libopen_pal_so_version) \\\n\t$(opal_libevent_LDFLAGS) \\\n\t$(opal_hwloc_LDFLAGS) \\\n\t$(opal_pmix_LDFLAGS)\n\n# included subdirectory Makefile.am's and appended-to variables\nheaders =\nnoinst_LTLIBRARIES =\ndist_opaldata_DATA =\nlib@OPAL_LIB_PREFIX@open_pal_la_SOURCES += $(headers)\n\n# Conditionally install the header files\n\nif WANT_INSTALL_HEADERS\nopaldir = $(opalincludedir)/$(subdir)\nnobase_opal_HEADERS = $(headers)\nendif\n\ninclude class/Makefile.am\ninclude memoryhooks/Makefile.am\ninclude runtime/Makefile.am\ninclude mca/Makefile.am\ninclude tools/Makefile.am\ninclude dss/Makefile.am\n",
        "/tmp/vanessa/spack-stage/spack-stage-openmpi-master-qcrm7qmgqutvsby2zcmdb57s22lzfq65/spack-src/opal/mca/btl/usnic/README.test": "usnic BTL Unit Testing Information\n==================================\nThis document briefly describes the scheme put in place for usnic BTL unit\ntesting.  This system was very quickly tossed together and warrants a proper\nrevisiting at some point in the future.  There are lots of ways to solve these\nproblems and this is just one of them.  Future improvement is welcome.\n\nGoals\n-----\n* To enable _unit_ testing of isolated functions or sets of functions.  This\n  has all sorts of benefits, including:\n    - greater confidence that corner cases work as expected\n    - faster, lower-stress refactoring in the future\n    - influencing future interfaces to have less implicit coupling/state (unit\n      testing is harder otherwise)\n* To be able to test *static* functions as well as non-static ones.\n* To avoid cluttering the normal code base with excessive test-related\n  macros/code.\n* The tests should be easy to run under Valgrind and GDB to facilitate:\n    - automated leak/memory checking\n    - easy debugging compared to a parallel MPI environment\n\nAnti-Goals\n----------\n* Testing the low level networking API (e.g., libfabric).\n* Testing inter-process interaction, such as ORTE-related functionality.\n\nConstraints\n-----------\n* our unit tests should never perturb a normal build in terms of performance\n  or correctness\n    - also should not affect other non-usNIC developers in any way (don't\n      break Ralph's `make check`)\n* static functions are difficult to test from outside the same source file\n\nDesign Notes\n------------\n* Source files named `X.c` include a header at the end named `test/X_test.h`\n    - Rationale: gives tests access to the static functions in `X.c`\n    - Rationale: keeps `X.c` clutter-free\n* unit test infrastructure lives in `btl_usnic_test.c` and `btl_usnic_test.h`\n* unit test functionality is built and enabled by passing\n  `--enable-opal-btl-usnic-unit-tests` to configure\n    - Rationale: default state disables all unit test logic, achieving our\n      \"non-interference\" goals\n* The tests are run by a new executable that gets built when unit tests are\n  enabled: `opal_btl_usnic_run_tests`.\n* Tests are registered at dlopen time via an\n  `__attribute__((__constructor__))` function that is generated by invocations\n  of the `USNIC_REGISTER_TEST` macro.\n    - Rationale: add tests in one spot, no need to centralize the list of\n      tests to run separately from the tests themselves.\n* Tests only use a simple `check()` macro right now that has `assert`-like\n  semantics.\n    - this could easily be expanded in the future, using the check docs as\n      inspiration:\n      http://check.sourceforge.net/doc/check_html/check_4.html#Convenience-Test-Functions\n\nWorthy Future Goals/Features\n----------------------------\n* Add some mocking capabilities.\n    - could use the preprocessor to replace regular function/macro calls with\n      calls to functions/macros that dispatch to changeable function pointers\n    - will require some reorganization of some of the existing code...\n* Output test results in a format that Jenkins and other tools can understand.\n    - TAP\n    - jUnit XML\n* Possibly utilize part or all of an existing unit testing framework, e.g.:\n    - check: http://check.sourceforge.net/  (LGPLed)\n    - cUnit: http://cunit.sourceforge.net/  (unfortunately GPLed...)\n* Re-examine test grouping and numbering.  Right now there's no real concept\n  of \"suites\" or multiple cases within a single test function.  Once the\n  number of tests grows to a certain point it will probably make sense to\n  revisit this decision.\n",
        "/tmp/vanessa/spack-stage/spack-stage-openmpi-master-qcrm7qmgqutvsby2zcmdb57s22lzfq65/spack-src/opal/mca/btl/usnic/btl_usnic_test.h": "/*\n * Copyright (c) 2014      Cisco Systems, Inc.  All rights reserved.\n * $COPYRIGHT$\n *\n * Additional copyrights may follow\n *\n * $HEADER$\n */\n\n#ifndef BTL_USNIC_TEST_H\n#define BTL_USNIC_TEST_H\n\n#include \"opal_config.h\"\n\ntypedef int (*opal_btl_usnic_test_fn_t)(void *ctx);\n\n#if OPAL_BTL_USNIC_UNIT_TESTS\n#  define test_out(...) fprintf(stderr, __VA_ARGS__)\n#  define check(a)                                                           \\\n    do {                                                                     \\\n        if (!(a)) {                                                          \\\n            test_out(\"%s:%d: check failed, '%s'\\n\", __func__, __LINE__, #a); \\\n            return TEST_FAILED;                                              \\\n        }                                                                    \\\n    } while (0)\n#  define check_str_eq(a,b)                                     \\\n    do {                                                        \\\n        const char *a_ = (a);                                   \\\n        const char *b_ = (b);                                   \\\n        if (0 != strcmp(a_,b_)) {                               \\\n            test_out(\"%s:%d: check failed, \\\"%s\\\" != \\\"%s\\\"\\n\", \\\n                     __func__, __LINE__, a_, b_);               \\\n            return TEST_FAILED;                                 \\\n        }                                                       \\\n    } while (0)\n#  define check_int_eq(got, expected)                                   \\\n    do {                                                                \\\n        if ((got) != (expected)) {                                      \\\n            test_out(\"%s:%d: check failed, \\\"%s\\\" != \\\"%s\\\", got %d\\n\", \\\n                     __func__, __LINE__, #got, #expected, (got));       \\\n            return TEST_FAILED;                                         \\\n        }                                                               \\\n    } while (0)\n/* just use check_int_eq for now, no public error code to string routine\n * exists (opal_err2str is static) */\n#  define check_err_code(got, expected)                                 \\\n    check_int_eq(got, expected)\n#  define check_msg(a, msg)                                \\\n    do {                                                   \\\n        if (!(a)) {                                        \\\n            test_out(\"%s:%d: check failed, \\\"%s\\\" (%s)\\n\", \\\n                     __func__, __LINE__, #a, (msg));       \\\n            return TEST_FAILED;                            \\\n        }                                                  \\\n    } while (0)\n\nextern int opal_btl_usnic_num_tests_run;\nextern int opal_btl_usnic_num_tests_passed;\nextern int opal_btl_usnic_num_tests_failed;\nextern int opal_btl_usnic_num_tests_skipped;\n\nenum test_result {\n    TEST_PASSED = 0,\n    TEST_FAILED,\n    TEST_SKIPPED\n};\n\n/* let us actually paste __LINE__ with other tokens */\n#  define USNIC_PASTE(a,b) USNIC_PASTE2(a,b)\n#  define USNIC_PASTE2(a,b) a ## b\n/* A helper macro to de-clutter test registration. */\n#  define USNIC_REGISTER_TEST(name, test_fn, ctx)       \\\n__attribute__((__constructor__))                        \\\nstatic void USNIC_PASTE(usnic_reg_ctor_,__LINE__)(void) \\\n{                                                       \\\n    opal_btl_usnic_register_test(name, test_fn, ctx);   \\\n}                                                       \\\n\n#else /* !OPAL_BTL_USNIC_UNIT_TESTS */\n#  define test_out(...) do {} while(0)\n#  define USNIC_REGISTER_TEST(name, test_fn, ctx)\n#endif\n\n/* Run all registered tests.  Typically called by an external utility that\n * dlopens the usnic BTL shared object.  See run_usnic_tests.c. */\nvoid opal_btl_usnic_run_tests(void);\n\nvoid opal_btl_usnic_register_test(const char *name,\n                                  opal_btl_usnic_test_fn_t test_fn,\n                                  void *ctx);\n\n/* should be called once, at component close time */\nvoid opal_btl_usnic_cleanup_tests(void);\n\n#endif /* BTL_USNIC_TEST_H */\n",
        "/tmp/vanessa/spack-stage/spack-stage-openmpi-master-qcrm7qmgqutvsby2zcmdb57s22lzfq65/spack-src/opal/mca/btl/usnic/test/usnic_btl_run_tests.c": "/*\n * Copyright (c) 2014      Cisco Systems, Inc.  All rights reserved.\n * Copyright (c) 2016      IBM Corporation.  All rights reserved.\n * $COPYRIGHT$\n *\n * Additional copyrights may follow\n *\n * $HEADER$\n */\n\n/* A simple test runner program for the usnic BTL unit tests.  See README.test\n * for more information. */\n\n/* for dladdr() */\n#define _GNU_SOURCE\n\n#include <assert.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <libgen.h> /* for dirname() */\n\n#include <dlfcn.h>\n\n#define MCA_BTL_USNIC_SO \"mca_btl_usnic.so\"\n\ntypedef void (*run_tests_fn_t)(void);\n\nint main(int argc, char **argv)\n{\n    void *mpi_handle;\n    void *usnic_handle;\n    void (*run_tests)(void);\n    int (*init)(int *, char ***);\n    int (*finalize)(void);\n    Dl_info info;\n    char *libmpi_path;\n    char *path;\n    char *to;\n    int path_len;\n\n    mpi_handle = dlopen(\"lib\" OMPI_LIBMPI_NAME \".so\", RTLD_NOW|RTLD_GLOBAL);\n    if (mpi_handle == NULL) {\n        fprintf(stderr, \"mpi_handle=NULL dlerror()=%s\\n\", dlerror());\n        abort();\n    }\n\n    /* casting awfulness needed for GCC's \"-pedantic\" option :( */\n    *(void **)(&init) = dlsym(mpi_handle, \"MPI_Init\");\n    if (init == NULL) {\n        fprintf(stderr, \"init=NULL dlerror()=%s\\n\", dlerror());\n        abort();\n    }\n    /* casting awfulness needed for GCC's \"-pedantic\" option :( */\n    *(void **)(&finalize) = dlsym(mpi_handle, \"MPI_Finalize\");\n    if (finalize == NULL) {\n        fprintf(stderr, \"finalize=%p dlerror()=%s\\n\", *(void **)(&finalize), dlerror());\n        abort();\n    }\n\n    /* call MPI_Init this way to avoid build-time dependency issues */\n    init(&argc, &argv);\n\n    /* figure out where the usnic BTL shared object is relative to libmpi.so */\n    if (!dladdr(*(void **)(&init), &info)) {\n        fprintf(stderr, \"ERROR: unable to dladdr(init,...)\\n\");\n        abort();\n    }\n    libmpi_path = strdup(info.dli_fname);\n    assert(libmpi_path != NULL);\n    path_len = strlen(libmpi_path) + strlen(\"/openmpi/\") + strlen(MCA_BTL_USNIC_SO);\n    path = calloc(path_len+1, 1);\n    to = path;\n    to = stpcpy(to, dirname(libmpi_path));\n    to = stpcpy(to, \"/openmpi/\");\n    to = stpcpy(to, MCA_BTL_USNIC_SO);\n\n    usnic_handle = dlopen(path, RTLD_NOW|RTLD_LOCAL);\n    if (usnic_handle == NULL) {\n        fprintf(stderr, \"usnic_handle=%p dlerror()=%s\\n\", (void *)usnic_handle, dlerror());\n        abort();\n    }\n\n    free(libmpi_path);\n    free(path);\n\n    /* casting awfulness needed for GCC's \"-pedantic\" option :( */\n    *(void **)(&run_tests) = dlsym(usnic_handle, BTL_USNIC_RUN_TESTS_SYMBOL);\n    if (run_tests == NULL) {\n        fprintf(stderr, \"run_tests=%p dlerror()=%s\\n\",\n                *(void **)(&run_tests), dlerror());\n        abort();\n    }\n    run_tests();\n\n    finalize();\n\n    /* deliberately do not dlclose() either handle so that any valgrind stack\n     * traces are more useful */\n\n    return 0;\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-openmpi-master-qcrm7qmgqutvsby2zcmdb57s22lzfq65/spack-src/opal/mca/common/cuda/common_cuda.c": "/*\n * Copyright (c) 2004-2006 The Trustees of Indiana University and Indiana\n *                         University Research and Technology\n *                         Corporation.  All rights reserved.\n * Copyright (c) 2004-2014 The University of Tennessee and The University\n *                         of Tennessee Research Foundation.  All rights\n *                         reserved.\n * Copyright (c) 2004-2005 High Performance Computing Center Stuttgart,\n *                         University of Stuttgart.  All rights reserved.\n * Copyright (c) 2004-2006 The Regents of the University of California.\n *                         All rights reserved.\n * Copyright (c) 2011-2015 NVIDIA Corporation.  All rights reserved.\n * Copyright (c) 2015      Cisco Systems, Inc.  All rights reserved.\n * Copyright (c) 2015      Research Organization for Information Science\n *                         and Technology (RIST). All rights reserved.\n * Copyright (c) 2018      Amazon.com, Inc. or its affiliates.  All Rights reserved.\n * $COPYRIGHT$\n *\n * Additional copyrights may follow\n *\n * $HEADER$\n */\n\n/**\n * This file contains various support functions for doing CUDA\n * operations.\n */\n#include \"opal_config.h\"\n\n#include <errno.h>\n#include <unistd.h>\n#include <cuda.h>\n\n#include \"opal/align.h\"\n#include \"opal/datatype/opal_convertor.h\"\n#include \"opal/datatype/opal_datatype_cuda.h\"\n#include \"opal/util/output.h\"\n#include \"opal/util/show_help.h\"\n#include \"opal/util/proc.h\"\n#include \"opal/util/argv.h\"\n#include \"opal/util/printf.h\"\n\n#include \"opal/mca/rcache/base/base.h\"\n#include \"opal/runtime/opal_params.h\"\n#include \"opal/mca/timer/base/base.h\"\n#include \"opal/mca/dl/base/base.h\"\n\n#include \"common_cuda.h\"\n\n/**\n * Since function names can get redefined in cuda.h file, we need to do this\n * stringifying to get the latest function name from the header file.  For\n * example, cuda.h may have something like this:\n * #define cuMemFree cuMemFree_v2\n * We want to make sure we find cuMemFree_v2, not cuMemFree.\n */\n#define STRINGIFY2(x) #x\n#define STRINGIFY(x) STRINGIFY2(x)\n\n#define OPAL_CUDA_DLSYM(libhandle, funcName)                                         \\\ndo {                                                                                 \\\n char *err_msg;                                                                      \\\n void *ptr;                                                                          \\\n if (OPAL_SUCCESS !=                                                                 \\\n     opal_dl_lookup(libhandle, STRINGIFY(funcName), &ptr, &err_msg)) {               \\\n        opal_show_help(\"help-mpi-common-cuda.txt\", \"dlsym failed\", true,             \\\n                       STRINGIFY(funcName), err_msg);                                \\\n        return 1;                                                                    \\\n    } else {                                                                         \\\n        *(void **)(&cuFunc.funcName) = ptr;                                          \\\n        opal_output_verbose(15, mca_common_cuda_output,                              \\\n                            \"CUDA: successful dlsym of %s\",                          \\\n                            STRINGIFY(funcName));                                    \\\n    }                                                                                \\\n} while (0)\n\n/* Structure to hold CUDA function pointers that get dynamically loaded. */\nstruct cudaFunctionTable {\n    int (*cuPointerGetAttribute)(void *, CUpointer_attribute, CUdeviceptr);\n    int (*cuMemcpyAsync)(CUdeviceptr, CUdeviceptr, size_t, CUstream);\n    int (*cuMemcpy)(CUdeviceptr, CUdeviceptr, size_t);\n    int (*cuMemAlloc)(CUdeviceptr *, unsigned int);\n    int (*cuMemFree)(CUdeviceptr buf);\n    int (*cuCtxGetCurrent)(void *cuContext);\n    int (*cuStreamCreate)(CUstream *, int);\n    int (*cuEventCreate)(CUevent *, int);\n    int (*cuEventRecord)(CUevent, CUstream);\n    int (*cuMemHostRegister)(void *, size_t, unsigned int);\n    int (*cuMemHostUnregister)(void *);\n    int (*cuEventQuery)(CUevent);\n    int (*cuEventDestroy)(CUevent);\n    int (*cuStreamWaitEvent)(CUstream, CUevent, unsigned int);\n    int (*cuMemGetAddressRange)(CUdeviceptr*, size_t*, CUdeviceptr);\n    int (*cuIpcGetEventHandle)(CUipcEventHandle*, CUevent);\n    int (*cuIpcOpenEventHandle)(CUevent*, CUipcEventHandle);\n    int (*cuIpcOpenMemHandle)(CUdeviceptr*, CUipcMemHandle, unsigned int);\n    int (*cuIpcCloseMemHandle)(CUdeviceptr);\n    int (*cuIpcGetMemHandle)(CUipcMemHandle*, CUdeviceptr);\n    int (*cuCtxGetDevice)(CUdevice *);\n    int (*cuDeviceCanAccessPeer)(int *, CUdevice, CUdevice);\n    int (*cuDeviceGet)(CUdevice *, int);\n#if OPAL_CUDA_GDR_SUPPORT\n    int (*cuPointerSetAttribute)(const void *, CUpointer_attribute, CUdeviceptr);\n#endif /* OPAL_CUDA_GDR_SUPPORT */\n    int (*cuCtxSetCurrent)(CUcontext);\n    int (*cuEventSynchronize)(CUevent);\n    int (*cuStreamSynchronize)(CUstream);\n    int (*cuStreamDestroy)(CUstream);\n#if OPAL_CUDA_GET_ATTRIBUTES\n    int (*cuPointerGetAttributes)(unsigned int, CUpointer_attribute *, void **, CUdeviceptr);\n#endif /* OPAL_CUDA_GET_ATTRIBUTES */\n};\ntypedef struct cudaFunctionTable cudaFunctionTable_t;\nstatic cudaFunctionTable_t cuFunc;\n\nstatic int stage_one_init_ref_count = 0;\nstatic bool stage_three_init_complete = false;\nstatic bool common_cuda_initialized = false;\nstatic bool common_cuda_mca_parames_registered = false;\nstatic int mca_common_cuda_verbose;\nstatic int mca_common_cuda_output = 0;\nbool mca_common_cuda_enabled = false;\nstatic bool mca_common_cuda_register_memory = true;\nstatic bool mca_common_cuda_warning = false;\nstatic opal_list_t common_cuda_memory_registrations;\nstatic CUstream ipcStream = NULL;\nstatic CUstream dtohStream = NULL;\nstatic CUstream htodStream = NULL;\nstatic CUstream memcpyStream = NULL;\nstatic int mca_common_cuda_gpu_mem_check_workaround = (CUDA_VERSION > 7000) ? 0 : 1;\nstatic opal_mutex_t common_cuda_init_lock;\nstatic opal_mutex_t common_cuda_htod_lock;\nstatic opal_mutex_t common_cuda_dtoh_lock;\nstatic opal_mutex_t common_cuda_ipc_lock;\n\n/* Functions called by opal layer - plugged into opal function table */\nstatic int mca_common_cuda_is_gpu_buffer(const void*, opal_convertor_t*);\nstatic int mca_common_cuda_memmove(void*, void*, size_t);\nstatic int mca_common_cuda_cu_memcpy_async(void*, const void*, size_t, opal_convertor_t*);\nstatic int mca_common_cuda_cu_memcpy(void*, const void*, size_t);\n\n/* Function that gets plugged into opal layer */\nstatic int mca_common_cuda_stage_two_init(opal_common_cuda_function_table_t *);\n\n/* Structure to hold memory registrations that are delayed until first\n * call to send or receive a GPU pointer */\nstruct common_cuda_mem_regs_t {\n    opal_list_item_t super;\n    void *ptr;\n    size_t amount;\n    char *msg;\n};\ntypedef struct common_cuda_mem_regs_t common_cuda_mem_regs_t;\nOBJ_CLASS_DECLARATION(common_cuda_mem_regs_t);\nOBJ_CLASS_INSTANCE(common_cuda_mem_regs_t,\n                   opal_list_item_t,\n                   NULL,\n                   NULL);\n\nstatic int mca_common_cuda_async = 1;\nstatic int mca_common_cuda_cumemcpy_async;\n#if OPAL_ENABLE_DEBUG\nstatic int mca_common_cuda_cumemcpy_timing;\n#endif /* OPAL_ENABLE_DEBUG */\n\n/* Array of CUDA events to be queried for IPC stream, sending side and\n * receiving side. */\nCUevent *cuda_event_ipc_array = NULL;\nCUevent *cuda_event_dtoh_array = NULL;\nCUevent *cuda_event_htod_array = NULL;\n\n/* Array of fragments currently being moved by cuda async non-blocking\n * operations */\nstruct mca_btl_base_descriptor_t **cuda_event_ipc_frag_array = NULL;\nstruct mca_btl_base_descriptor_t **cuda_event_dtoh_frag_array = NULL;\nstruct mca_btl_base_descriptor_t **cuda_event_htod_frag_array = NULL;\n\n/* First free/available location in cuda_event_status_array */\nstatic int cuda_event_ipc_first_avail, cuda_event_dtoh_first_avail, cuda_event_htod_first_avail;\n\n/* First currently-being used location in the cuda_event_status_array */\nstatic int cuda_event_ipc_first_used, cuda_event_dtoh_first_used, cuda_event_htod_first_used;\n\n/* Number of status items currently in use */\nstatic volatile int cuda_event_ipc_num_used, cuda_event_dtoh_num_used, cuda_event_htod_num_used;\n\n/* Size of array holding events */\nint cuda_event_max = 400;\nstatic int cuda_event_ipc_most = 0;\nstatic int cuda_event_dtoh_most = 0;\nstatic int cuda_event_htod_most = 0;\n\n/* Handle to libcuda.so */\nopal_dl_handle_t *libcuda_handle = NULL;\n\n/* Unused variable that we register at init time and unregister at fini time.\n * This is used to detect if user has done a device reset prior to MPI_Finalize.\n * This is a workaround to avoid SEGVs.\n */\nstatic int checkmem;\nstatic int ctx_ok = 1;\n\n#define CUDA_COMMON_TIMING 0\n#if OPAL_ENABLE_DEBUG\n/* Some timing support structures.  Enable this to help analyze\n * internal performance issues. */\nstatic opal_timer_t ts_start;\nstatic opal_timer_t ts_end;\nstatic double accum;\n#define THOUSAND  1000L\n#define MILLION   1000000L\nstatic float mydifftime(opal_timer_t ts_start, opal_timer_t ts_end);\n#endif /* OPAL_ENABLE_DEBUG */\n\n/* These functions are typically unused in the optimized builds. */\nstatic void cuda_dump_evthandle(int, void *, char *) __opal_attribute_unused__ ;\nstatic void cuda_dump_memhandle(int, void *, char *) __opal_attribute_unused__ ;\n#if OPAL_ENABLE_DEBUG\n#define CUDA_DUMP_MEMHANDLE(a) cuda_dump_memhandle a\n#define CUDA_DUMP_EVTHANDLE(a) cuda_dump_evthandle a\n#else\n#define CUDA_DUMP_MEMHANDLE(a)\n#define CUDA_DUMP_EVTHANDLE(a)\n#endif /* OPAL_ENABLE_DEBUG */\n\n/* This is a seperate function so we can see these variables with ompi_info and\n * also set them with the tools interface */\nvoid mca_common_cuda_register_mca_variables(void)\n{\n\n    if (false == common_cuda_mca_parames_registered) {\n        common_cuda_mca_parames_registered = true;\n    }\n    /* Set different levels of verbosity in the cuda related code. */\n    mca_common_cuda_verbose = 0;\n    (void) mca_base_var_register(\"ompi\", \"mpi\", \"common_cuda\", \"verbose\",\n                                 \"Set level of common cuda verbosity\",\n                                 MCA_BASE_VAR_TYPE_INT, NULL, 0, 0,\n                                 OPAL_INFO_LVL_9,\n                                 MCA_BASE_VAR_SCOPE_READONLY,\n                                 &mca_common_cuda_verbose);\n\n    /* Control whether system buffers get CUDA pinned or not.  Allows for\n     * performance analysis. */\n    mca_common_cuda_register_memory = true;\n    (void) mca_base_var_register(\"ompi\", \"mpi\", \"common_cuda\", \"register_memory\",\n                                 \"Whether to cuMemHostRegister preallocated BTL buffers\",\n                                 MCA_BASE_VAR_TYPE_BOOL, NULL, 0, 0,\n                                 OPAL_INFO_LVL_9,\n                                 MCA_BASE_VAR_SCOPE_READONLY,\n                                 &mca_common_cuda_register_memory);\n\n    /* Control whether we see warnings when CUDA memory registration fails.  This is\n     * useful when CUDA support is configured in, but we are running a regular MPI\n     * application without CUDA. */\n    mca_common_cuda_warning = true;\n    (void) mca_base_var_register(\"ompi\", \"mpi\", \"common_cuda\", \"warning\",\n                                 \"Whether to print warnings when CUDA registration fails\",\n                                 MCA_BASE_VAR_TYPE_BOOL, NULL, 0, 0,\n                                 OPAL_INFO_LVL_9,\n                                 MCA_BASE_VAR_SCOPE_READONLY,\n                                 &mca_common_cuda_warning);\n\n    /* Use this flag to test async vs sync copies */\n    mca_common_cuda_async = 1;\n    (void) mca_base_var_register(\"ompi\", \"mpi\", \"common_cuda\", \"memcpy_async\",\n                                 \"Set to 0 to force CUDA sync copy instead of async\",\n                                 MCA_BASE_VAR_TYPE_INT, NULL, 0, 0,\n                                 OPAL_INFO_LVL_9,\n                                 MCA_BASE_VAR_SCOPE_READONLY,\n                                 &mca_common_cuda_async);\n\n    /* Use this parameter to increase the number of outstanding events allows */\n    (void) mca_base_var_register(\"ompi\", \"mpi\", \"common_cuda\", \"event_max\",\n                                 \"Set number of oustanding CUDA events\",\n                                 MCA_BASE_VAR_TYPE_INT, NULL, 0, 0,\n                                 OPAL_INFO_LVL_9,\n                                 MCA_BASE_VAR_SCOPE_READONLY,\n                                 &cuda_event_max);\n\n    /* Use this flag to test cuMemcpyAsync vs cuMemcpy */\n    mca_common_cuda_cumemcpy_async = 1;\n    (void) mca_base_var_register(\"ompi\", \"mpi\", \"common_cuda\", \"cumemcpy_async\",\n                                 \"Set to 0 to force CUDA cuMemcpy instead of cuMemcpyAsync/cuStreamSynchronize\",\n                                 MCA_BASE_VAR_TYPE_INT, NULL, 0, 0,\n                                 OPAL_INFO_LVL_5,\n                                 MCA_BASE_VAR_SCOPE_READONLY,\n                                 &mca_common_cuda_cumemcpy_async);\n\n#if OPAL_ENABLE_DEBUG\n    /* Use this flag to dump out timing of cumempcy sync and async */\n    mca_common_cuda_cumemcpy_timing = 0;\n    (void) mca_base_var_register(\"ompi\", \"mpi\", \"common_cuda\", \"cumemcpy_timing\",\n                                 \"Set to 1 to dump timing of eager copies\",\n                                 MCA_BASE_VAR_TYPE_INT, NULL, 0, 0,\n                                 OPAL_INFO_LVL_5,\n                                 MCA_BASE_VAR_SCOPE_READONLY,\n                                 &mca_common_cuda_cumemcpy_timing);\n#endif /* OPAL_ENABLE_DEBUG */\n\n    (void) mca_base_var_register(\"ompi\", \"mpi\", \"common_cuda\", \"gpu_mem_check_workaround\",\n                                 \"Set to 0 to disable GPU memory check workaround. A user would rarely have to do this.\",\n                                 MCA_BASE_VAR_TYPE_INT, NULL, 0, 0,\n                                 OPAL_INFO_LVL_9,\n                                 MCA_BASE_VAR_SCOPE_READONLY,\n                                 &mca_common_cuda_gpu_mem_check_workaround);\n}\n\n/**\n * This is the first stage of initialization.  This function is called\n * explicitly by any BTLs that can support CUDA-aware. It is called during\n * the component open phase of initialization. This fuction will look for\n * the SONAME of the library which is libcuda.so.1. In most cases, this will\n * result in the library found.  However, there are some setups that require\n * the extra steps for searching. This function will then load the symbols\n * needed from the CUDA driver library. Any failure will result in this\n * initialization failing and status will be set showing that.\n */\nint mca_common_cuda_stage_one_init(void)\n{\n    int retval, i, j;\n    char *cudalibs[] = {\"libcuda.so.1\", \"libcuda.dylib\", NULL};\n    char *searchpaths[] = {\"\", \"/usr/lib64\", NULL};\n    char **errmsgs = NULL;\n    char *errmsg = NULL;\n    int errsize;\n    bool stage_one_init_passed = false;\n\n    stage_one_init_ref_count++;\n    if (stage_one_init_ref_count > 1) {\n        opal_output_verbose(10, mca_common_cuda_output,\n                            \"CUDA: stage_one_init_ref_count is now %d, no need to init\",\n                            stage_one_init_ref_count);\n        return OPAL_SUCCESS;\n    }\n\n    /* This is a no-op in most cases as the parameters were registered earlier */\n    mca_common_cuda_register_mca_variables();\n\n    OBJ_CONSTRUCT(&common_cuda_init_lock, opal_mutex_t);\n    OBJ_CONSTRUCT(&common_cuda_htod_lock, opal_mutex_t);\n    OBJ_CONSTRUCT(&common_cuda_dtoh_lock, opal_mutex_t);\n    OBJ_CONSTRUCT(&common_cuda_ipc_lock, opal_mutex_t);\n\n    mca_common_cuda_output = opal_output_open(NULL);\n    opal_output_set_verbosity(mca_common_cuda_output, mca_common_cuda_verbose);\n\n    opal_output_verbose(10, mca_common_cuda_output,\n                        \"CUDA: stage_one_init_ref_count is now %d, initializing\",\n                        stage_one_init_ref_count);\n\n    /* First check if the support is enabled.  In the case that the user has\n     * turned it off, we do not need to continue with any CUDA specific\n     * initialization.  Do this after MCA parameter registration. */\n    if (!opal_cuda_support) {\n        return 1;\n    }\n\n    if (!OPAL_HAVE_DL_SUPPORT) {\n        opal_show_help(\"help-mpi-common-cuda.txt\", \"dlopen disabled\", true);\n        return 1;\n    }\n\n    /* Now walk through all the potential names libcuda and find one\n     * that works.  If it does, all is good.  If not, print out all\n     * the messages about why things failed.  This code was careful\n     * to try and save away all error messages if the loading ultimately\n     * failed to help with debugging.\n     *\n     * NOTE: On the first loop we just utilize the default loading\n     * paths from the system.  For the second loop, set /usr/lib64 to\n     * the search path and try again.  This is done to handle the case\n     * where we have both 32 and 64 bit libcuda.so libraries\n     * installed.  Even when running in 64-bit mode, the /usr/lib\n     * directory is searched first and we may find a 32-bit\n     * libcuda.so.1 library.  Loading of this library will fail as the\n     * OPAL DL framework does not handle having the wrong ABI in the\n     * search path (unlike ld or ld.so).  Note that we only set this\n     * search path after the original search.  This is so that\n     * LD_LIBRARY_PATH and run path settings are respected.  Setting\n     * this search path overrides them (rather then being\n     * appended). */\n    j = 0;\n    while (searchpaths[j] != NULL) {\n        i = 0;\n        while (cudalibs[i] != NULL) {\n            char *filename = NULL;\n            char *str = NULL;\n\n            /* If there's a non-empty search path, prepend it\n               to the library filename */\n            if (strlen(searchpaths[j]) > 0) {\n                opal_asprintf(&filename, \"%s/%s\", searchpaths[j], cudalibs[i]);\n            } else {\n                filename = strdup(cudalibs[i]);\n            }\n            if (NULL == filename) {\n                opal_show_help(\"help-mpi-common-cuda.txt\", \"No memory\",\n                               true, OPAL_PROC_MY_HOSTNAME);\n                return 1;\n            }\n\n            retval = opal_dl_open(filename, false, false,\n                                  &libcuda_handle, &str);\n            if (OPAL_SUCCESS != retval || NULL == libcuda_handle) {\n                if (NULL != str) {\n                    opal_argv_append(&errsize, &errmsgs, str);\n                } else {\n                    opal_argv_append(&errsize, &errmsgs,\n                                     \"opal_dl_open() returned NULL.\");\n                }\n                opal_output_verbose(10, mca_common_cuda_output,\n                                    \"CUDA: Library open error: %s\",\n                                    errmsgs[errsize-1]);\n            } else {\n                opal_output_verbose(10, mca_common_cuda_output,\n                                    \"CUDA: Library successfully opened %s\",\n                                    cudalibs[i]);\n                stage_one_init_passed = true;\n                break;\n            }\n            i++;\n\n            free(filename);\n        }\n        if (true == stage_one_init_passed) {\n            break; /* Break out of outer loop */\n        }\n        j++;\n    }\n\n    if (true != stage_one_init_passed) {\n        errmsg = opal_argv_join(errmsgs, '\\n');\n        if (opal_warn_on_missing_libcuda) {\n            opal_show_help(\"help-mpi-common-cuda.txt\", \"dlopen failed\", true,\n                           errmsg);\n        }\n        opal_cuda_support = 0;\n    }\n    opal_argv_free(errmsgs);\n    free(errmsg);\n\n    if (true != stage_one_init_passed) {\n        return 1;\n    }\n    opal_cuda_add_initialization_function(&mca_common_cuda_stage_two_init);\n    OBJ_CONSTRUCT(&common_cuda_memory_registrations, opal_list_t);\n\n    /* Map in the functions that we need.  Note that if there is an error\n     * the macro OPAL_CUDA_DLSYM will print an error and call return.  */\n    OPAL_CUDA_DLSYM(libcuda_handle, cuStreamCreate);\n    OPAL_CUDA_DLSYM(libcuda_handle, cuCtxGetCurrent);\n    OPAL_CUDA_DLSYM(libcuda_handle, cuEventCreate);\n    OPAL_CUDA_DLSYM(libcuda_handle, cuEventRecord);\n    OPAL_CUDA_DLSYM(libcuda_handle, cuMemHostRegister);\n    OPAL_CUDA_DLSYM(libcuda_handle, cuMemHostUnregister);\n    OPAL_CUDA_DLSYM(libcuda_handle, cuPointerGetAttribute);\n    OPAL_CUDA_DLSYM(libcuda_handle, cuEventQuery);\n    OPAL_CUDA_DLSYM(libcuda_handle, cuEventDestroy);\n    OPAL_CUDA_DLSYM(libcuda_handle, cuStreamWaitEvent);\n    OPAL_CUDA_DLSYM(libcuda_handle, cuMemcpyAsync);\n    OPAL_CUDA_DLSYM(libcuda_handle, cuMemcpy);\n    OPAL_CUDA_DLSYM(libcuda_handle, cuMemFree);\n    OPAL_CUDA_DLSYM(libcuda_handle, cuMemAlloc);\n    OPAL_CUDA_DLSYM(libcuda_handle, cuMemGetAddressRange);\n    OPAL_CUDA_DLSYM(libcuda_handle, cuIpcGetEventHandle);\n    OPAL_CUDA_DLSYM(libcuda_handle, cuIpcOpenEventHandle);\n    OPAL_CUDA_DLSYM(libcuda_handle, cuIpcOpenMemHandle);\n    OPAL_CUDA_DLSYM(libcuda_handle, cuIpcCloseMemHandle);\n    OPAL_CUDA_DLSYM(libcuda_handle, cuIpcGetMemHandle);\n    OPAL_CUDA_DLSYM(libcuda_handle, cuCtxGetDevice);\n    OPAL_CUDA_DLSYM(libcuda_handle, cuDeviceCanAccessPeer);\n    OPAL_CUDA_DLSYM(libcuda_handle, cuDeviceGet);\n#if OPAL_CUDA_GDR_SUPPORT\n    OPAL_CUDA_DLSYM(libcuda_handle, cuPointerSetAttribute);\n#endif /* OPAL_CUDA_GDR_SUPPORT */\n    OPAL_CUDA_DLSYM(libcuda_handle, cuCtxSetCurrent);\n    OPAL_CUDA_DLSYM(libcuda_handle, cuEventSynchronize);\n    OPAL_CUDA_DLSYM(libcuda_handle, cuStreamSynchronize);\n    OPAL_CUDA_DLSYM(libcuda_handle, cuStreamDestroy);\n#if OPAL_CUDA_GET_ATTRIBUTES\n    OPAL_CUDA_DLSYM(libcuda_handle, cuPointerGetAttributes);\n#endif /* OPAL_CUDA_GET_ATTRIBUTES */\n    return 0;\n}\n\n/**\n * This function is registered with the OPAL CUDA support.  In that way,\n * these function pointers will be loaded into the OPAL CUDA code when\n * the first convertor is initialized.  This does not trigger any CUDA\n * specific initialization as this may just be a host buffer that is\n * triggering this call.\n */\nstatic int mca_common_cuda_stage_two_init(opal_common_cuda_function_table_t *ftable)\n{\n    if (OPAL_UNLIKELY(!opal_cuda_support)) {\n        return OPAL_ERROR;\n    }\n\n    ftable->gpu_is_gpu_buffer = &mca_common_cuda_is_gpu_buffer;\n    ftable->gpu_cu_memcpy_async = &mca_common_cuda_cu_memcpy_async;\n    ftable->gpu_cu_memcpy = &mca_common_cuda_cu_memcpy;\n    ftable->gpu_memmove = &mca_common_cuda_memmove;\n\n    opal_output_verbose(30, mca_common_cuda_output,\n                        \"CUDA: support functions initialized\");\n    return OPAL_SUCCESS;\n}\n\n/**\n * This is the last phase of initialization.  This is triggered when we examine\n * a buffer pointer and determine it is a GPU buffer.  We then assume the user\n * has selected their GPU and we can go ahead with all the CUDA related\n * initializations.  If we get an error, just return.  Cleanup of resources\n * will happen when fini is called.\n */\nstatic int mca_common_cuda_stage_three_init(void)\n{\n    int i, s, rc;\n    CUresult res;\n    CUcontext cuContext;\n    common_cuda_mem_regs_t *mem_reg;\n\n    OPAL_THREAD_LOCK(&common_cuda_init_lock);\n    opal_output_verbose(20, mca_common_cuda_output,\n                        \"CUDA: entering stage three init\");\n\n/* Compiled without support or user disabled support */\n    if (OPAL_UNLIKELY(!opal_cuda_support)) {\n        opal_output_verbose(20, mca_common_cuda_output,\n                            \"CUDA: No mpi cuda support, exiting stage three init\");\n        stage_three_init_complete = true;\n        OPAL_THREAD_UNLOCK(&common_cuda_init_lock);\n        return OPAL_ERROR;\n    }\n\n    /* In case another thread snuck in and completed the initialization */\n    if (true == stage_three_init_complete) {\n        if (common_cuda_initialized) {\n            opal_output_verbose(20, mca_common_cuda_output,\n                                \"CUDA: Stage three already complete, exiting stage three init\");\n            OPAL_THREAD_UNLOCK(&common_cuda_init_lock);\n            return OPAL_SUCCESS;\n        } else {\n            opal_output_verbose(20, mca_common_cuda_output,\n                                \"CUDA: Stage three already complete, failed during the init\");\n            OPAL_THREAD_UNLOCK(&common_cuda_init_lock);\n            return OPAL_ERROR;\n        }\n    }\n\n    /* Check to see if this process is running in a CUDA context.  If\n     * so, all is good.  If not, then disable registration of memory. */\n    res = cuFunc.cuCtxGetCurrent(&cuContext);\n    if (CUDA_SUCCESS != res) {\n        if (mca_common_cuda_warning) {\n            /* Check for the not initialized error since we can make suggestions to\n             * user for this error. */\n            if (CUDA_ERROR_NOT_INITIALIZED == res) {\n                opal_show_help(\"help-mpi-common-cuda.txt\", \"cuCtxGetCurrent failed not initialized\",\n                               true);\n            } else {\n                opal_show_help(\"help-mpi-common-cuda.txt\", \"cuCtxGetCurrent failed\",\n                               true, res);\n            }\n        }\n        mca_common_cuda_enabled = false;\n        mca_common_cuda_register_memory = false;\n    } else if ((CUDA_SUCCESS == res) && (NULL == cuContext)) {\n        if (mca_common_cuda_warning) {\n            opal_show_help(\"help-mpi-common-cuda.txt\", \"cuCtxGetCurrent returned NULL\",\n                           true);\n        }\n        mca_common_cuda_enabled = false;\n        mca_common_cuda_register_memory = false;\n    } else {\n        /* All is good.  mca_common_cuda_register_memory will retain its original\n         * value.  Normally, that is 1, but the user can override it to disable\n         * registration of the internal buffers. */\n        mca_common_cuda_enabled = true;\n        opal_output_verbose(20, mca_common_cuda_output,\n                            \"CUDA: cuCtxGetCurrent succeeded\");\n    }\n\n    /* No need to go on at this point.  If we cannot create a context and we are at\n     * the point where we are making MPI calls, it is time to fully disable\n     * CUDA support.\n     */\n    if (false == mca_common_cuda_enabled) {\n        OPAL_THREAD_UNLOCK(&common_cuda_init_lock);\n        return OPAL_ERROR;\n    }\n\n    if (true == mca_common_cuda_enabled) {\n        /* Set up an array to store outstanding IPC async copy events */\n        cuda_event_ipc_num_used = 0;\n        cuda_event_ipc_first_avail = 0;\n        cuda_event_ipc_first_used = 0;\n\n        cuda_event_ipc_array = (CUevent *) calloc(cuda_event_max, sizeof(CUevent *));\n        if (NULL == cuda_event_ipc_array) {\n            opal_show_help(\"help-mpi-common-cuda.txt\", \"No memory\",\n                           true, OPAL_PROC_MY_HOSTNAME);\n            rc = OPAL_ERROR;\n            goto cleanup_and_error;\n        }\n\n        /* Create the events since they can be reused. */\n        for (i = 0; i < cuda_event_max; i++) {\n            res = cuFunc.cuEventCreate(&cuda_event_ipc_array[i], CU_EVENT_DISABLE_TIMING);\n            if (CUDA_SUCCESS != res) {\n                opal_show_help(\"help-mpi-common-cuda.txt\", \"cuEventCreate failed\",\n                               true, OPAL_PROC_MY_HOSTNAME, res);\n                rc = OPAL_ERROR;\n                goto cleanup_and_error;\n            }\n        }\n\n        /* The first available status index is 0.  Make an empty frag\n           array. */\n        cuda_event_ipc_frag_array = (struct mca_btl_base_descriptor_t **)\n            malloc(sizeof(struct mca_btl_base_descriptor_t *) * cuda_event_max);\n        if (NULL == cuda_event_ipc_frag_array) {\n            opal_show_help(\"help-mpi-common-cuda.txt\", \"No memory\",\n                           true, OPAL_PROC_MY_HOSTNAME);\n            rc = OPAL_ERROR;\n            goto cleanup_and_error;\n        }\n    }\n\n    if (true == mca_common_cuda_enabled) {\n        /* Set up an array to store outstanding async dtoh events.  Used on the\n         * sending side for asynchronous copies. */\n        cuda_event_dtoh_num_used = 0;\n        cuda_event_dtoh_first_avail = 0;\n        cuda_event_dtoh_first_used = 0;\n\n        cuda_event_dtoh_array = (CUevent *) calloc(cuda_event_max, sizeof(CUevent *));\n        if (NULL == cuda_event_dtoh_array) {\n            opal_show_help(\"help-mpi-common-cuda.txt\", \"No memory\",\n                           true, OPAL_PROC_MY_HOSTNAME);\n            rc = OPAL_ERROR;\n            goto cleanup_and_error;\n        }\n\n        /* Create the events since they can be reused. */\n        for (i = 0; i < cuda_event_max; i++) {\n            res = cuFunc.cuEventCreate(&cuda_event_dtoh_array[i], CU_EVENT_DISABLE_TIMING);\n            if (CUDA_SUCCESS != res) {\n                opal_show_help(\"help-mpi-common-cuda.txt\", \"cuEventCreate failed\",\n                               true, OPAL_PROC_MY_HOSTNAME, res);\n                rc = OPAL_ERROR;\n                goto cleanup_and_error;\n            }\n        }\n\n        /* The first available status index is 0.  Make an empty frag\n           array. */\n        cuda_event_dtoh_frag_array = (struct mca_btl_base_descriptor_t **)\n            malloc(sizeof(struct mca_btl_base_descriptor_t *) * cuda_event_max);\n        if (NULL == cuda_event_dtoh_frag_array) {\n            opal_show_help(\"help-mpi-common-cuda.txt\", \"No memory\",\n                           true, OPAL_PROC_MY_HOSTNAME);\n            rc = OPAL_ERROR;\n            goto cleanup_and_error;\n        }\n\n        /* Set up an array to store outstanding async htod events.  Used on the\n         * receiving side for asynchronous copies. */\n        cuda_event_htod_num_used = 0;\n        cuda_event_htod_first_avail = 0;\n        cuda_event_htod_first_used = 0;\n\n        cuda_event_htod_array = (CUevent *) calloc(cuda_event_max, sizeof(CUevent *));\n        if (NULL == cuda_event_htod_array) {\n            opal_show_help(\"help-mpi-common-cuda.txt\", \"No memory\",\n                           true, OPAL_PROC_MY_HOSTNAME);\n           rc = OPAL_ERROR;\n           goto cleanup_and_error;\n        }\n\n        /* Create the events since they can be reused. */\n        for (i = 0; i < cuda_event_max; i++) {\n            res = cuFunc.cuEventCreate(&cuda_event_htod_array[i], CU_EVENT_DISABLE_TIMING);\n            if (CUDA_SUCCESS != res) {\n                opal_show_help(\"help-mpi-common-cuda.txt\", \"cuEventCreate failed\",\n                               true, OPAL_PROC_MY_HOSTNAME, res);\n               rc = OPAL_ERROR;\n               goto cleanup_and_error;\n            }\n        }\n\n        /* The first available status index is 0.  Make an empty frag\n           array. */\n        cuda_event_htod_frag_array = (struct mca_btl_base_descriptor_t **)\n            malloc(sizeof(struct mca_btl_base_descriptor_t *) * cuda_event_max);\n        if (NULL == cuda_event_htod_frag_array) {\n            opal_show_help(\"help-mpi-common-cuda.txt\", \"No memory\",\n                           true, OPAL_PROC_MY_HOSTNAME);\n           rc = OPAL_ERROR;\n           goto cleanup_and_error;\n        }\n    }\n\n    s = opal_list_get_size(&common_cuda_memory_registrations);\n    for(i = 0; i < s; i++) {\n        mem_reg = (common_cuda_mem_regs_t *)\n            opal_list_remove_first(&common_cuda_memory_registrations);\n        if (mca_common_cuda_enabled && mca_common_cuda_register_memory) {\n            res = cuFunc.cuMemHostRegister(mem_reg->ptr, mem_reg->amount, 0);\n            if (res != CUDA_SUCCESS) {\n                /* If registering the memory fails, print a message and continue.\n                 * This is not a fatal error. */\n                opal_show_help(\"help-mpi-common-cuda.txt\", \"cuMemHostRegister during init failed\",\n                               true, mem_reg->ptr, mem_reg->amount,\n                               OPAL_PROC_MY_HOSTNAME, res, mem_reg->msg);\n            } else {\n                opal_output_verbose(20, mca_common_cuda_output,\n                                    \"CUDA: cuMemHostRegister OK on rcache %s: \"\n                                    \"address=%p, bufsize=%d\",\n                                    mem_reg->msg, mem_reg->ptr, (int)mem_reg->amount);\n            }\n        }\n        free(mem_reg->msg);\n        OBJ_RELEASE(mem_reg);\n    }\n\n    /* Create stream for use in ipc asynchronous copies */\n    res = cuFunc.cuStreamCreate(&ipcStream, 0);\n    if (OPAL_UNLIKELY(res != CUDA_SUCCESS)) {\n        opal_show_help(\"help-mpi-common-cuda.txt\", \"cuStreamCreate failed\",\n                       true, OPAL_PROC_MY_HOSTNAME, res);\n        rc = OPAL_ERROR;\n        goto cleanup_and_error;\n    }\n\n    /* Create stream for use in dtoh asynchronous copies */\n    res = cuFunc.cuStreamCreate(&dtohStream, 0);\n    if (OPAL_UNLIKELY(res != CUDA_SUCCESS)) {\n        opal_show_help(\"help-mpi-common-cuda.txt\", \"cuStreamCreate failed\",\n                       true, OPAL_PROC_MY_HOSTNAME, res);\n        rc = OPAL_ERROR;\n        goto cleanup_and_error;\n    }\n\n    /* Create stream for use in htod asynchronous copies */\n    res = cuFunc.cuStreamCreate(&htodStream, 0);\n    if (OPAL_UNLIKELY(res != CUDA_SUCCESS)) {\n        opal_show_help(\"help-mpi-common-cuda.txt\", \"cuStreamCreate failed\",\n                       true, OPAL_PROC_MY_HOSTNAME, res);\n        rc = OPAL_ERROR;\n        goto cleanup_and_error;\n    }\n\n    if (mca_common_cuda_cumemcpy_async) {\n        /* Create stream for use in cuMemcpyAsync synchronous copies */\n        res = cuFunc.cuStreamCreate(&memcpyStream, 0);\n        if (OPAL_UNLIKELY(res != CUDA_SUCCESS)) {\n            opal_show_help(\"help-mpi-common-cuda.txt\", \"cuStreamCreate failed\",\n                           true, OPAL_PROC_MY_HOSTNAME, res);\n            rc = OPAL_ERROR;\n            goto cleanup_and_error;\n        }\n    }\n\n    res = cuFunc.cuMemHostRegister(&checkmem, sizeof(int), 0);\n    if (res != CUDA_SUCCESS) {\n        /* If registering the memory fails, print a message and continue.\n         * This is not a fatal error. */\n        opal_show_help(\"help-mpi-common-cuda.txt\", \"cuMemHostRegister during init failed\",\n                       true, &checkmem, sizeof(int),\n                       OPAL_PROC_MY_HOSTNAME, res, \"checkmem\");\n\n    } else {\n        opal_output_verbose(20, mca_common_cuda_output,\n                            \"CUDA: cuMemHostRegister OK on test region\");\n    }\n\n    opal_output_verbose(20, mca_common_cuda_output,\n                        \"CUDA: the extra gpu memory check is %s\", (mca_common_cuda_gpu_mem_check_workaround == 1) ? \"on\":\"off\");\n\n    opal_output_verbose(30, mca_common_cuda_output,\n                        \"CUDA: initialized\");\n    opal_atomic_mb();  /* Make sure next statement does not get reordered */\n    common_cuda_initialized = true;\n    stage_three_init_complete = true;\n    OPAL_THREAD_UNLOCK(&common_cuda_init_lock);\n    return OPAL_SUCCESS;\n\n    /* If we are here, something went wrong.  Cleanup and return an error. */\n cleanup_and_error:\n    opal_atomic_mb(); /* Make sure next statement does not get reordered */\n    stage_three_init_complete = true;\n    OPAL_THREAD_UNLOCK(&common_cuda_init_lock);\n    return rc;\n}\n\n/**\n * Cleanup all CUDA resources.\n *\n * Note: Still figuring out how to get cuMemHostUnregister called from the smcuda sm\n * rcache.  Looks like with the memory pool from openib (grdma), the unregistering is\n * called as the free list is destructed.  Not true for the sm mpool.  This means we\n * are currently still leaking some host memory we registered with CUDA.\n */\nvoid mca_common_cuda_fini(void)\n{\n    int i;\n    CUresult res;\n\n    if (false == common_cuda_initialized) {\n        stage_one_init_ref_count--;\n        opal_output_verbose(20, mca_common_cuda_output,\n                            \"CUDA: mca_common_cuda_fini, never completed initialization so \"\n                            \"skipping fini, ref_count is now %d\", stage_one_init_ref_count);\n        return;\n    }\n\n    if (0 == stage_one_init_ref_count) {\n        opal_output_verbose(20, mca_common_cuda_output,\n                            \"CUDA: mca_common_cuda_fini, ref_count=%d, fini is already complete\",\n                            stage_one_init_ref_count);\n        return;\n    }\n\n    if (1 == stage_one_init_ref_count) {\n        opal_output_verbose(20, mca_common_cuda_output,\n                            \"CUDA: mca_common_cuda_fini, ref_count=%d, cleaning up started\",\n                            stage_one_init_ref_count);\n\n        /* This call is in here to make sure the context is still valid.\n         * This was the one way of checking which did not cause problems\n         * while calling into the CUDA library.  This check will detect if\n         * a user has called cudaDeviceReset prior to MPI_Finalize. If so,\n         * then this call will fail and we skip cleaning up CUDA resources. */\n        res = cuFunc.cuMemHostUnregister(&checkmem);\n        if (CUDA_SUCCESS != res) {\n            ctx_ok = 0;\n        }\n        opal_output_verbose(20, mca_common_cuda_output,\n                            \"CUDA: mca_common_cuda_fini, cuMemHostUnregister returned %d, ctx_ok=%d\",\n                            res, ctx_ok);\n\n        if (NULL != cuda_event_ipc_array) {\n            if (ctx_ok) {\n                for (i = 0; i < cuda_event_max; i++) {\n                    if (NULL != cuda_event_ipc_array[i]) {\n                        cuFunc.cuEventDestroy(cuda_event_ipc_array[i]);\n                    }\n                }\n            }\n            free(cuda_event_ipc_array);\n        }\n        if (NULL != cuda_event_htod_array) {\n            if (ctx_ok) {\n                for (i = 0; i < cuda_event_max; i++) {\n                    if (NULL != cuda_event_htod_array[i]) {\n                        cuFunc.cuEventDestroy(cuda_event_htod_array[i]);\n                    }\n                }\n            }\n            free(cuda_event_htod_array);\n        }\n\n        if (NULL != cuda_event_dtoh_array) {\n            if (ctx_ok) {\n                for (i = 0; i < cuda_event_max; i++) {\n                    if (NULL != cuda_event_dtoh_array[i]) {\n                        cuFunc.cuEventDestroy(cuda_event_dtoh_array[i]);\n                    }\n                }\n            }\n            free(cuda_event_dtoh_array);\n        }\n\n        if (NULL != cuda_event_ipc_frag_array) {\n            free(cuda_event_ipc_frag_array);\n        }\n        if (NULL != cuda_event_htod_frag_array) {\n            free(cuda_event_htod_frag_array);\n        }\n        if (NULL != cuda_event_dtoh_frag_array) {\n            free(cuda_event_dtoh_frag_array);\n        }\n        if ((NULL != ipcStream) && ctx_ok) {\n            cuFunc.cuStreamDestroy(ipcStream);\n        }\n        if ((NULL != dtohStream) && ctx_ok) {\n            cuFunc.cuStreamDestroy(dtohStream);\n        }\n        if ((NULL != htodStream) && ctx_ok) {\n            cuFunc.cuStreamDestroy(htodStream);\n        }\n        if ((NULL != memcpyStream) && ctx_ok) {\n            cuFunc.cuStreamDestroy(memcpyStream);\n        }\n        OBJ_DESTRUCT(&common_cuda_init_lock);\n        OBJ_DESTRUCT(&common_cuda_htod_lock);\n        OBJ_DESTRUCT(&common_cuda_dtoh_lock);\n        OBJ_DESTRUCT(&common_cuda_ipc_lock);\n        if (NULL != libcuda_handle) {\n            opal_dl_close(libcuda_handle);\n        }\n\n        opal_output_verbose(20, mca_common_cuda_output,\n                            \"CUDA: mca_common_cuda_fini, ref_count=%d, cleaning up all done\",\n                            stage_one_init_ref_count);\n\n        opal_output_close(mca_common_cuda_output);\n\n    } else {\n        opal_output_verbose(20, mca_common_cuda_output,\n                            \"CUDA: mca_common_cuda_fini, ref_count=%d, cuda still in use\",\n                            stage_one_init_ref_count);\n    }\n    stage_one_init_ref_count--;\n}\n\n/**\n * Call the CUDA register function so we pin the memory in the CUDA\n * space.\n */\nvoid mca_common_cuda_register(void *ptr, size_t amount, char *msg) {\n    int res;\n\n    /* Always first check if the support is enabled.  If not, just return */\n    if (!opal_cuda_support)\n        return;\n\n    if (!common_cuda_initialized) {\n        OPAL_THREAD_LOCK(&common_cuda_init_lock);\n        if (!common_cuda_initialized) {\n            common_cuda_mem_regs_t *regptr;\n            regptr = OBJ_NEW(common_cuda_mem_regs_t);\n            regptr->ptr = ptr;\n            regptr->amount = amount;\n            regptr->msg = strdup(msg);\n            opal_list_append(&common_cuda_memory_registrations,\n                             (opal_list_item_t*)regptr);\n            OPAL_THREAD_UNLOCK(&common_cuda_init_lock);\n            return;\n        }\n        OPAL_THREAD_UNLOCK(&common_cuda_init_lock);\n    }\n\n    if (mca_common_cuda_enabled && mca_common_cuda_register_memory) {\n        res = cuFunc.cuMemHostRegister(ptr, amount, 0);\n        if (OPAL_UNLIKELY(res != CUDA_SUCCESS)) {\n            /* If registering the memory fails, print a message and continue.\n             * This is not a fatal error. */\n            opal_show_help(\"help-mpi-common-cuda.txt\", \"cuMemHostRegister failed\",\n                           true, ptr, amount,\n                           OPAL_PROC_MY_HOSTNAME, res, msg);\n        } else {\n            opal_output_verbose(20, mca_common_cuda_output,\n                                \"CUDA: cuMemHostRegister OK on rcache %s: \"\n                                \"address=%p, bufsize=%d\",\n                                msg, ptr, (int)amount);\n        }\n    }\n}\n\n/**\n * Call the CUDA unregister function so we unpin the memory in the CUDA\n * space.\n */\nvoid mca_common_cuda_unregister(void *ptr, char *msg) {\n    int res, i, s;\n    common_cuda_mem_regs_t *mem_reg;\n\n    /* This can happen if memory was queued up to be registered, but\n     * no CUDA operations happened, so it never was registered.\n     * Therefore, just release any of the resources. */\n    if (!common_cuda_initialized) {\n        s = opal_list_get_size(&common_cuda_memory_registrations);\n        for(i = 0; i < s; i++) {\n            mem_reg = (common_cuda_mem_regs_t *)\n                opal_list_remove_first(&common_cuda_memory_registrations);\n            free(mem_reg->msg);\n            OBJ_RELEASE(mem_reg);\n        }\n        return;\n    }\n\n    if (mca_common_cuda_enabled && mca_common_cuda_register_memory) {\n        res = cuFunc.cuMemHostUnregister(ptr);\n        if (OPAL_UNLIKELY(res != CUDA_SUCCESS)) {\n            /* If unregistering the memory fails, just continue.  This is during\n             * shutdown.  Only print when running in verbose mode. */\n            opal_output_verbose(20, mca_common_cuda_output,\n                                \"CUDA: cuMemHostUnregister failed: ptr=%p, res=%d, rcache=%s\",\n                                ptr, res, msg);\n\n        } else {\n            opal_output_verbose(20, mca_common_cuda_output,\n                                \"CUDA: cuMemHostUnregister OK on rcache %s: \"\n                                \"address=%p\",\n                                msg, ptr);\n        }\n    }\n}\n\n/*\n * Get the memory handle of a local section of memory that can be sent\n * to the remote size so it can access the memory.  This is the\n * registration function for the sending side of a message transfer.\n */\nint cuda_getmemhandle(void *base, size_t size, mca_rcache_base_registration_t *newreg,\n                      mca_rcache_base_registration_t *hdrreg)\n\n{\n    CUmemorytype memType;\n    CUresult result;\n    CUipcMemHandle *memHandle;\n    CUdeviceptr pbase;\n    size_t psize;\n\n    mca_rcache_common_cuda_reg_t *cuda_reg = (mca_rcache_common_cuda_reg_t*)newreg;\n    memHandle = (CUipcMemHandle *)cuda_reg->data.memHandle;\n\n    /* We should only be there if this is a CUDA device pointer */\n    result = cuFunc.cuPointerGetAttribute(&memType,\n                                          CU_POINTER_ATTRIBUTE_MEMORY_TYPE, (CUdeviceptr)base);\n    assert(CUDA_SUCCESS == result);\n    assert(CU_MEMORYTYPE_DEVICE == memType);\n\n    /* Get the memory handle so we can send it to the remote process. */\n    result = cuFunc.cuIpcGetMemHandle(memHandle, (CUdeviceptr)base);\n    CUDA_DUMP_MEMHANDLE((100, memHandle, \"GetMemHandle-After\"));\n\n    if (CUDA_SUCCESS != result) {\n        opal_show_help(\"help-mpi-common-cuda.txt\", \"cuIpcGetMemHandle failed\",\n                       true, result, base);\n        return OPAL_ERROR;\n    } else {\n        opal_output_verbose(20, mca_common_cuda_output,\n                            \"CUDA: cuIpcGetMemHandle passed: base=%p size=%d\",\n                            base, (int)size);\n    }\n\n    /* Need to get the real base and size of the memory handle.  This is\n     * how the remote side saves the handles in a cache. */\n    result = cuFunc.cuMemGetAddressRange(&pbase, &psize, (CUdeviceptr)base);\n    if (CUDA_SUCCESS != result) {\n        opal_show_help(\"help-mpi-common-cuda.txt\", \"cuMemGetAddressRange failed\",\n                       true, result, base);\n        return OPAL_ERROR;\n    } else {\n        opal_output_verbose(10, mca_common_cuda_output,\n                            \"CUDA: cuMemGetAddressRange passed: addr=%p, size=%d, pbase=%p, psize=%d \",\n                            base, (int)size, (void *)pbase, (int)psize);\n    }\n\n    /* Store all the information in the registration */\n    cuda_reg->base.base = (void *)pbase;\n    cuda_reg->base.bound = (unsigned char *)pbase + psize - 1;\n    cuda_reg->data.memh_seg_addr.pval = (void *) pbase;\n    cuda_reg->data.memh_seg_len = psize;\n\n#if OPAL_CUDA_SYNC_MEMOPS\n    /* With CUDA 6.0, we can set an attribute on the memory pointer that will\n     * ensure any synchronous copies are completed prior to any other access\n     * of the memory region.  This means we do not need to record an event\n     * and send to the remote side.\n     */\n    memType = 1; /* Just use this variable since we already have it */\n    result = cuFunc.cuPointerSetAttribute(&memType, CU_POINTER_ATTRIBUTE_SYNC_MEMOPS,\n                                          (CUdeviceptr)base);\n    if (OPAL_UNLIKELY(CUDA_SUCCESS != result)) {\n        opal_show_help(\"help-mpi-common-cuda.txt\", \"cuPointerSetAttribute failed\",\n                       true, OPAL_PROC_MY_HOSTNAME, result, base);\n        return OPAL_ERROR;\n    }\n#else\n    /* Need to record the event to ensure that any memcopies into the\n     * device memory have completed.  The event handle associated with\n     * this event is sent to the remote process so that it will wait\n     * on this event prior to copying data out of the device memory.\n     * Note that this needs to be the NULL stream to make since it is\n     * unknown what stream any copies into the device memory were done\n     * with. */\n    result = cuFunc.cuEventRecord((CUevent)cuda_reg->data.event, 0);\n    if (OPAL_UNLIKELY(CUDA_SUCCESS != result)) {\n        opal_show_help(\"help-mpi-common-cuda.txt\", \"cuEventRecord failed\",\n                       true, result, base);\n        return OPAL_ERROR;\n    }\n#endif /* OPAL_CUDA_SYNC_MEMOPS */\n\n    return OPAL_SUCCESS;\n}\n\n/*\n * This function is called by the local side that called the cuda_getmemhandle.\n * There is nothing to be done so just return.\n */\nint cuda_ungetmemhandle(void *reg_data, mca_rcache_base_registration_t *reg)\n{\n    opal_output_verbose(10, mca_common_cuda_output,\n                        \"CUDA: cuda_ungetmemhandle (no-op): base=%p\", reg->base);\n    CUDA_DUMP_MEMHANDLE((100, ((mca_rcache_common_cuda_reg_t *)reg)->data.memHandle, \"cuda_ungetmemhandle\"));\n\n    return OPAL_SUCCESS;\n}\n\n/*\n * Open a memory handle that refers to remote memory so we can get an address\n * that works on the local side.  This is the registration function for the\n * remote side of a transfer.  newreg contains the new handle.  hddrreg contains\n * the memory handle that was received from the remote side.\n */\nint cuda_openmemhandle(void *base, size_t size, mca_rcache_base_registration_t *newreg,\n                       mca_rcache_base_registration_t *hdrreg)\n{\n    CUresult result;\n    CUipcMemHandle *memHandle;\n    mca_rcache_common_cuda_reg_t *cuda_newreg = (mca_rcache_common_cuda_reg_t*)newreg;\n\n    /* Save in local variable to avoid ugly casting */\n    memHandle = (CUipcMemHandle *)cuda_newreg->data.memHandle;\n    CUDA_DUMP_MEMHANDLE((100, memHandle, \"Before call to cuIpcOpenMemHandle\"));\n\n    /* Open the memory handle and store it into the registration structure. */\n    result = cuFunc.cuIpcOpenMemHandle((CUdeviceptr *)&newreg->alloc_base, *memHandle,\n                                       CU_IPC_MEM_LAZY_ENABLE_PEER_ACCESS);\n\n    /* If there are some stale entries in the cache, they can cause other\n     * registrations to fail.  Let the caller know that so that can attempt\n     * to clear them out. */\n    if (CUDA_ERROR_ALREADY_MAPPED == result) {\n        opal_output_verbose(10, mca_common_cuda_output,\n                            \"CUDA: cuIpcOpenMemHandle returned CUDA_ERROR_ALREADY_MAPPED for \"\n                            \"p=%p,size=%d: notify memory pool\\n\", base, (int)size);\n        return OPAL_ERR_WOULD_BLOCK;\n    }\n    if (OPAL_UNLIKELY(CUDA_SUCCESS != result)) {\n        opal_show_help(\"help-mpi-common-cuda.txt\", \"cuIpcOpenMemHandle failed\",\n                       true, OPAL_PROC_MY_HOSTNAME, result, base);\n        /* Currently, this is a non-recoverable error */\n        return OPAL_ERROR;\n    } else {\n        opal_output_verbose(10, mca_common_cuda_output,\n                            \"CUDA: cuIpcOpenMemHandle passed: base=%p (remote base=%p,size=%d)\",\n                            newreg->alloc_base, base, (int)size);\n        CUDA_DUMP_MEMHANDLE((200, memHandle, \"cuIpcOpenMemHandle\"));\n    }\n\n    return OPAL_SUCCESS;\n}\n\n/*\n * Close a memory handle that refers to remote memory.\n */\nint cuda_closememhandle(void *reg_data, mca_rcache_base_registration_t *reg)\n{\n    CUresult result;\n    mca_rcache_common_cuda_reg_t *cuda_reg = (mca_rcache_common_cuda_reg_t*)reg;\n\n    /* Only attempt to close if we have valid context.  This can change if a call\n     * to the fini function is made and we discover context is gone. */\n    if (ctx_ok) {\n        result = cuFunc.cuIpcCloseMemHandle((CUdeviceptr)cuda_reg->base.alloc_base);\n        if (OPAL_UNLIKELY(CUDA_SUCCESS != result)) {\n            if (CUDA_ERROR_DEINITIALIZED != result) {\n                opal_show_help(\"help-mpi-common-cuda.txt\", \"cuIpcCloseMemHandle failed\",\n                true, result, cuda_reg->base.alloc_base);\n            }\n            /* We will just continue on and hope things continue to work. */\n        } else {\n            opal_output_verbose(10, mca_common_cuda_output,\n                                \"CUDA: cuIpcCloseMemHandle passed: base=%p\",\n                                cuda_reg->base.alloc_base);\n            CUDA_DUMP_MEMHANDLE((100, cuda_reg->data.memHandle, \"cuIpcCloseMemHandle\"));\n        }\n    }\n\n    return OPAL_SUCCESS;\n}\n\nvoid mca_common_cuda_construct_event_and_handle(uintptr_t *event, void *handle)\n{\n    CUresult result;\n\n    result = cuFunc.cuEventCreate((CUevent *)event, CU_EVENT_INTERPROCESS | CU_EVENT_DISABLE_TIMING);\n    if (OPAL_UNLIKELY(CUDA_SUCCESS != result)) {\n        opal_show_help(\"help-mpi-common-cuda.txt\", \"cuEventCreate failed\",\n                       true, OPAL_PROC_MY_HOSTNAME, result);\n    }\n\n    result = cuFunc.cuIpcGetEventHandle((CUipcEventHandle *)handle, (CUevent)*event);\n    if (OPAL_UNLIKELY(CUDA_SUCCESS != result)) {\n        opal_show_help(\"help-mpi-common-cuda.txt\", \"cuIpcGetEventHandle failed\",\n                       true, result);\n    }\n\n    CUDA_DUMP_EVTHANDLE((10, handle, \"construct_event_and_handle\"));\n\n}\n\nvoid mca_common_cuda_destruct_event(uintptr_t event)\n{\n    CUresult result;\n\n    /* Only attempt to destroy if we have valid context.  This can change if a call\n     * to the fini function is made and we discover context is gone. */\n    if (ctx_ok) {\n        result = cuFunc.cuEventDestroy((CUevent)event);\n        if (OPAL_UNLIKELY(CUDA_SUCCESS != result)) {\n            opal_show_help(\"help-mpi-common-cuda.txt\", \"cuEventDestroy failed\",\n                           true, result);\n        }\n    }\n}\n\n\n/*\n * Put remote event on stream to ensure that the the start of the\n * copy does not start until the completion of the event.\n */\nvoid mca_common_wait_stream_synchronize(mca_rcache_common_cuda_reg_t *rget_reg)\n{\n#if OPAL_CUDA_SYNC_MEMOPS\n    /* No need for any of this with SYNC_MEMOPS feature */\n    return;\n#else /* OPAL_CUDA_SYNC_MEMOPS */\n    CUipcEventHandle evtHandle;\n    CUevent event;\n    CUresult result;\n\n    memcpy(&evtHandle, rget_reg->data.evtHandle, sizeof(evtHandle));\n    CUDA_DUMP_EVTHANDLE((100, &evtHandle, \"stream_synchronize\"));\n\n    result = cuFunc.cuIpcOpenEventHandle(&event, evtHandle);\n    if (OPAL_UNLIKELY(CUDA_SUCCESS != result)) {\n        opal_show_help(\"help-mpi-common-cuda.txt\", \"cuIpcOpenEventHandle failed\",\n                       true, result);\n    }\n\n    /* BEGIN of Workaround - There is a bug in CUDA 4.1 RC2 and earlier\n     * versions.  Need to record an event on the stream, even though\n     * it is not used, to make sure we do not short circuit our way\n     * out of the cuStreamWaitEvent test.\n     */\n    result = cuFunc.cuEventRecord(event, 0);\n    if (OPAL_UNLIKELY(CUDA_SUCCESS != result)) {\n        opal_show_help(\"help-mpi-common-cuda.txt\", \"cuEventRecord failed\",\n                       true, OPAL_PROC_MY_HOSTNAME, result);\n    }\n    /* END of Workaround */\n\n    result = cuFunc.cuStreamWaitEvent(0, event, 0);\n    if (OPAL_UNLIKELY(CUDA_SUCCESS != result)) {\n        opal_show_help(\"help-mpi-common-cuda.txt\", \"cuStreamWaitEvent failed\",\n                       true, result);\n    }\n\n    /* All done with this event. */\n    result = cuFunc.cuEventDestroy(event);\n    if (OPAL_UNLIKELY(CUDA_SUCCESS != result)) {\n        opal_show_help(\"help-mpi-common-cuda.txt\", \"cuEventDestroy failed\",\n                       true, result);\n    }\n#endif /* OPAL_CUDA_SYNC_MEMOPS */\n}\n\n/*\n * Start the asynchronous copy.  Then record and save away an event that will\n * be queried to indicate the copy has completed.\n */\nint mca_common_cuda_memcpy(void *dst, void *src, size_t amount, char *msg,\n                           struct mca_btl_base_descriptor_t *frag, int *done)\n{\n    CUresult result;\n    int iter;\n\n    OPAL_THREAD_LOCK(&common_cuda_ipc_lock);\n    /* First make sure there is room to store the event.  If not, then\n     * return an error.  The error message will tell the user to try and\n     * run again, but with a larger array for storing events. */\n    if (cuda_event_ipc_num_used == cuda_event_max) {\n        opal_show_help(\"help-mpi-common-cuda.txt\", \"Out of cuEvent handles\",\n                       true, cuda_event_max, cuda_event_max+100, cuda_event_max+100);\n        OPAL_THREAD_UNLOCK(&common_cuda_ipc_lock);\n        return OPAL_ERR_OUT_OF_RESOURCE;\n    }\n\n    if (cuda_event_ipc_num_used > cuda_event_ipc_most) {\n        cuda_event_ipc_most = cuda_event_ipc_num_used;\n        /* Just print multiples of 10 */\n        if (0 == (cuda_event_ipc_most % 10)) {\n            opal_output_verbose(20, mca_common_cuda_output,\n                                \"Maximum ipc events used is now %d\", cuda_event_ipc_most);\n        }\n    }\n\n    /* This is the standard way to run.  Running with synchronous copies is available\n     * to measure the advantages of asynchronous copies. */\n    if (OPAL_LIKELY(mca_common_cuda_async)) {\n        result = cuFunc.cuMemcpyAsync((CUdeviceptr)dst, (CUdeviceptr)src, amount, ipcStream);\n        if (OPAL_UNLIKELY(CUDA_SUCCESS != result)) {\n            opal_show_help(\"help-mpi-common-cuda.txt\", \"cuMemcpyAsync failed\",\n                           true, dst, src, amount, result);\n            OPAL_THREAD_UNLOCK(&common_cuda_ipc_lock);\n            return OPAL_ERROR;\n        } else {\n            opal_output_verbose(20, mca_common_cuda_output,\n                                \"CUDA: cuMemcpyAsync passed: dst=%p, src=%p, size=%d\",\n                                dst, src, (int)amount);\n        }\n        result = cuFunc.cuEventRecord(cuda_event_ipc_array[cuda_event_ipc_first_avail], ipcStream);\n        if (OPAL_UNLIKELY(CUDA_SUCCESS != result)) {\n            opal_show_help(\"help-mpi-common-cuda.txt\", \"cuEventRecord failed\",\n                           true, OPAL_PROC_MY_HOSTNAME, result);\n            OPAL_THREAD_UNLOCK(&common_cuda_ipc_lock);\n            return OPAL_ERROR;\n        }\n        cuda_event_ipc_frag_array[cuda_event_ipc_first_avail] = frag;\n\n        /* Bump up the first available slot and number used by 1 */\n        cuda_event_ipc_first_avail++;\n        if (cuda_event_ipc_first_avail >= cuda_event_max) {\n            cuda_event_ipc_first_avail = 0;\n        }\n        cuda_event_ipc_num_used++;\n\n        *done = 0;\n    } else {\n        /* Mimic the async function so they use the same memcpy call. */\n        result = cuFunc.cuMemcpyAsync((CUdeviceptr)dst, (CUdeviceptr)src, amount, ipcStream);\n        if (OPAL_UNLIKELY(CUDA_SUCCESS != result)) {\n            opal_show_help(\"help-mpi-common-cuda.txt\", \"cuMemcpyAsync failed\",\n                           true, dst, src, amount, result);\n            OPAL_THREAD_UNLOCK(&common_cuda_ipc_lock);\n            return OPAL_ERROR;\n        } else {\n            opal_output_verbose(20, mca_common_cuda_output,\n                                \"CUDA: cuMemcpyAsync passed: dst=%p, src=%p, size=%d\",\n                                dst, src, (int)amount);\n        }\n\n        /* Record an event, then wait for it to complete with calls to cuEventQuery */\n        result = cuFunc.cuEventRecord(cuda_event_ipc_array[cuda_event_ipc_first_avail], ipcStream);\n        if (OPAL_UNLIKELY(CUDA_SUCCESS != result)) {\n            opal_show_help(\"help-mpi-common-cuda.txt\", \"cuEventRecord failed\",\n                           true, OPAL_PROC_MY_HOSTNAME, result);\n            OPAL_THREAD_UNLOCK(&common_cuda_ipc_lock);\n            return OPAL_ERROR;\n        }\n\n        cuda_event_ipc_frag_array[cuda_event_ipc_first_avail] = frag;\n\n        /* Bump up the first available slot and number used by 1 */\n        cuda_event_ipc_first_avail++;\n        if (cuda_event_ipc_first_avail >= cuda_event_max) {\n            cuda_event_ipc_first_avail = 0;\n        }\n        cuda_event_ipc_num_used++;\n\n        result = cuFunc.cuEventQuery(cuda_event_ipc_array[cuda_event_ipc_first_used]);\n        if ((CUDA_SUCCESS != result) && (CUDA_ERROR_NOT_READY != result)) {\n            opal_show_help(\"help-mpi-common-cuda.txt\", \"cuEventQuery failed\",\n                           true, result);\n            OPAL_THREAD_UNLOCK(&common_cuda_ipc_lock);\n            return OPAL_ERROR;\n        }\n\n        iter = 0;\n        while (CUDA_ERROR_NOT_READY == result) {\n            if (0 == (iter % 10)) {\n                opal_output(-1, \"EVENT NOT DONE (iter=%d)\", iter);\n            }\n            result = cuFunc.cuEventQuery(cuda_event_ipc_array[cuda_event_ipc_first_used]);\n            if ((CUDA_SUCCESS != result) && (CUDA_ERROR_NOT_READY != result)) {\n                opal_show_help(\"help-mpi-common-cuda.txt\", \"cuEventQuery failed\",\n                               true, result);\n            OPAL_THREAD_UNLOCK(&common_cuda_ipc_lock);\n                return OPAL_ERROR;\n            }\n            iter++;\n        }\n\n        --cuda_event_ipc_num_used;\n        ++cuda_event_ipc_first_used;\n        if (cuda_event_ipc_first_used >= cuda_event_max) {\n            cuda_event_ipc_first_used = 0;\n        }\n        *done = 1;\n    }\n    OPAL_THREAD_UNLOCK(&common_cuda_ipc_lock);\n    return OPAL_SUCCESS;\n}\n\n/*\n * Record an event and save the frag.  This is called by the sending side and\n * is used to queue an event when a htod copy has been initiated.\n */\nint mca_common_cuda_record_dtoh_event(char *msg, struct mca_btl_base_descriptor_t *frag)\n{\n    CUresult result;\n\n    /* First make sure there is room to store the event.  If not, then\n     * return an error.  The error message will tell the user to try and\n     * run again, but with a larger array for storing events. */\n    OPAL_THREAD_LOCK(&common_cuda_dtoh_lock);\n    if (cuda_event_dtoh_num_used == cuda_event_max) {\n        opal_show_help(\"help-mpi-common-cuda.txt\", \"Out of cuEvent handles\",\n                       true, cuda_event_max, cuda_event_max+100, cuda_event_max+100);\n        return OPAL_ERR_OUT_OF_RESOURCE;\n    }\n\n    if (cuda_event_dtoh_num_used > cuda_event_dtoh_most) {\n        cuda_event_dtoh_most = cuda_event_dtoh_num_used;\n        /* Just print multiples of 10 */\n        if (0 == (cuda_event_dtoh_most % 10)) {\n            opal_output_verbose(20, mca_common_cuda_output,\n                                \"Maximum DtoH events used is now %d\", cuda_event_dtoh_most);\n        }\n    }\n\n    result = cuFunc.cuEventRecord(cuda_event_dtoh_array[cuda_event_dtoh_first_avail], dtohStream);\n    if (OPAL_UNLIKELY(CUDA_SUCCESS != result)) {\n        opal_show_help(\"help-mpi-common-cuda.txt\", \"cuEventRecord failed\",\n                       true, OPAL_PROC_MY_HOSTNAME, result);\n        OPAL_THREAD_UNLOCK(&common_cuda_dtoh_lock);\n        return OPAL_ERROR;\n    }\n    cuda_event_dtoh_frag_array[cuda_event_dtoh_first_avail] = frag;\n\n    /* Bump up the first available slot and number used by 1 */\n    cuda_event_dtoh_first_avail++;\n    if (cuda_event_dtoh_first_avail >= cuda_event_max) {\n        cuda_event_dtoh_first_avail = 0;\n    }\n    cuda_event_dtoh_num_used++;\n\n    OPAL_THREAD_UNLOCK(&common_cuda_dtoh_lock);\n    return OPAL_SUCCESS;\n}\n\n/*\n * Record an event and save the frag.  This is called by the receiving side and\n * is used to queue an event when a dtoh copy has been initiated.\n */\nint mca_common_cuda_record_htod_event(char *msg, struct mca_btl_base_descriptor_t *frag)\n{\n    CUresult result;\n\n    OPAL_THREAD_LOCK(&common_cuda_htod_lock);\n    /* First make sure there is room to store the event.  If not, then\n     * return an error.  The error message will tell the user to try and\n     * run again, but with a larger array for storing events. */\n    if (cuda_event_htod_num_used == cuda_event_max) {\n        opal_show_help(\"help-mpi-common-cuda.txt\", \"Out of cuEvent handles\",\n                       true, cuda_event_max, cuda_event_max+100, cuda_event_max+100);\n        OPAL_THREAD_UNLOCK(&common_cuda_htod_lock);\n        return OPAL_ERR_OUT_OF_RESOURCE;\n    }\n\n    if (cuda_event_htod_num_used > cuda_event_htod_most) {\n        cuda_event_htod_most = cuda_event_htod_num_used;\n        /* Just print multiples of 10 */\n        if (0 == (cuda_event_htod_most % 10)) {\n            opal_output_verbose(20, mca_common_cuda_output,\n                                \"Maximum HtoD events used is now %d\", cuda_event_htod_most);\n        }\n    }\n\n    result = cuFunc.cuEventRecord(cuda_event_htod_array[cuda_event_htod_first_avail], htodStream);\n    if (OPAL_UNLIKELY(CUDA_SUCCESS != result)) {\n        opal_show_help(\"help-mpi-common-cuda.txt\", \"cuEventRecord failed\",\n                       true, OPAL_PROC_MY_HOSTNAME, result);\n        OPAL_THREAD_UNLOCK(&common_cuda_htod_lock);\n        return OPAL_ERROR;\n    }\n    cuda_event_htod_frag_array[cuda_event_htod_first_avail] = frag;\n\n   /* Bump up the first available slot and number used by 1 */\n    cuda_event_htod_first_avail++;\n    if (cuda_event_htod_first_avail >= cuda_event_max) {\n        cuda_event_htod_first_avail = 0;\n    }\n    cuda_event_htod_num_used++;\n\n    OPAL_THREAD_UNLOCK(&common_cuda_htod_lock);\n    return OPAL_SUCCESS;\n}\n\n/**\n * Used to get the dtoh stream for initiating asynchronous copies.\n */\nvoid *mca_common_cuda_get_dtoh_stream(void) {\n    return (void *)dtohStream;\n}\n\n/**\n * Used to get the htod stream for initiating asynchronous copies.\n */\nvoid *mca_common_cuda_get_htod_stream(void) {\n    return (void *)htodStream;\n}\n\n/*\n * Function is called every time progress is called with the sm BTL.  If there\n * are outstanding events, check to see if one has completed.  If so, hand\n * back the fragment for further processing.\n */\nint progress_one_cuda_ipc_event(struct mca_btl_base_descriptor_t **frag) {\n    CUresult result;\n\n    if( OPAL_LIKELY(0 == cuda_event_ipc_num_used) )\n        return 0;\n\n    OPAL_THREAD_LOCK(&common_cuda_ipc_lock);\n    if (cuda_event_ipc_num_used > 0) {\n        opal_output_verbose(20, mca_common_cuda_output,\n                           \"CUDA: progress_one_cuda_ipc_event, outstanding_events=%d\",\n                            cuda_event_ipc_num_used);\n\n        result = cuFunc.cuEventQuery(cuda_event_ipc_array[cuda_event_ipc_first_used]);\n\n        /* We found an event that is not ready, so return. */\n        if (CUDA_ERROR_NOT_READY == result) {\n            opal_output_verbose(20, mca_common_cuda_output,\n                                \"CUDA: cuEventQuery returned CUDA_ERROR_NOT_READY\");\n            *frag = NULL;\n            OPAL_THREAD_UNLOCK(&common_cuda_ipc_lock);\n            return 0;\n        } else if (CUDA_SUCCESS != result) {\n            opal_show_help(\"help-mpi-common-cuda.txt\", \"cuEventQuery failed\",\n                           true, result);\n            *frag = NULL;\n            OPAL_THREAD_UNLOCK(&common_cuda_ipc_lock);\n            return OPAL_ERROR;\n        }\n\n        *frag = cuda_event_ipc_frag_array[cuda_event_ipc_first_used];\n        opal_output_verbose(10, mca_common_cuda_output,\n                            \"CUDA: cuEventQuery returned %d\", result);\n\n        /* Bump counters, loop around the circular buffer if necessary */\n        --cuda_event_ipc_num_used;\n        ++cuda_event_ipc_first_used;\n        if (cuda_event_ipc_first_used >= cuda_event_max) {\n            cuda_event_ipc_first_used = 0;\n        }\n        /* A return value of 1 indicates an event completed and a frag was returned */\n        OPAL_THREAD_UNLOCK(&common_cuda_ipc_lock);\n        return 1;\n    }\n    OPAL_THREAD_UNLOCK(&common_cuda_ipc_lock);\n    return 0;\n}\n\n/**\n * Progress any dtoh event completions.\n */\nint progress_one_cuda_dtoh_event(struct mca_btl_base_descriptor_t **frag) {\n    CUresult result;\n\n    OPAL_THREAD_LOCK(&common_cuda_dtoh_lock);\n    if (cuda_event_dtoh_num_used > 0) {\n        opal_output_verbose(30, mca_common_cuda_output,\n                           \"CUDA: progress_one_cuda_dtoh_event, outstanding_events=%d\",\n                            cuda_event_dtoh_num_used);\n\n        result = cuFunc.cuEventQuery(cuda_event_dtoh_array[cuda_event_dtoh_first_used]);\n\n        /* We found an event that is not ready, so return. */\n        if (CUDA_ERROR_NOT_READY == result) {\n            opal_output_verbose(30, mca_common_cuda_output,\n                                \"CUDA: cuEventQuery returned CUDA_ERROR_NOT_READY\");\n            *frag = NULL;\n            OPAL_THREAD_UNLOCK(&common_cuda_dtoh_lock);\n            return 0;\n        } else if (CUDA_SUCCESS != result) {\n            opal_show_help(\"help-mpi-common-cuda.txt\", \"cuEventQuery failed\",\n                           true, result);\n            *frag = NULL;\n            OPAL_THREAD_UNLOCK(&common_cuda_dtoh_lock);\n            return OPAL_ERROR;\n        }\n\n        *frag = cuda_event_dtoh_frag_array[cuda_event_dtoh_first_used];\n        opal_output_verbose(30, mca_common_cuda_output,\n                            \"CUDA: cuEventQuery returned %d\", result);\n\n        /* Bump counters, loop around the circular buffer if necessary */\n        --cuda_event_dtoh_num_used;\n        ++cuda_event_dtoh_first_used;\n        if (cuda_event_dtoh_first_used >= cuda_event_max) {\n            cuda_event_dtoh_first_used = 0;\n        }\n        /* A return value of 1 indicates an event completed and a frag was returned */\n        OPAL_THREAD_UNLOCK(&common_cuda_dtoh_lock);\n        return 1;\n    }\n    OPAL_THREAD_UNLOCK(&common_cuda_dtoh_lock);\n    return 0;\n}\n\n/**\n * Progress any dtoh event completions.\n */\nint progress_one_cuda_htod_event(struct mca_btl_base_descriptor_t **frag) {\n    CUresult result;\n\n    OPAL_THREAD_LOCK(&common_cuda_htod_lock);\n    if (cuda_event_htod_num_used > 0) {\n        opal_output_verbose(30, mca_common_cuda_output,\n                           \"CUDA: progress_one_cuda_htod_event, outstanding_events=%d\",\n                            cuda_event_htod_num_used);\n\n        result = cuFunc.cuEventQuery(cuda_event_htod_array[cuda_event_htod_first_used]);\n\n        /* We found an event that is not ready, so return. */\n        if (CUDA_ERROR_NOT_READY == result) {\n            opal_output_verbose(30, mca_common_cuda_output,\n                                \"CUDA: cuEventQuery returned CUDA_ERROR_NOT_READY\");\n            *frag = NULL;\n            OPAL_THREAD_UNLOCK(&common_cuda_htod_lock);\n            return 0;\n        } else if (CUDA_SUCCESS != result) {\n            opal_show_help(\"help-mpi-common-cuda.txt\", \"cuEventQuery failed\",\n                           true, result);\n            *frag = NULL;\n            OPAL_THREAD_UNLOCK(&common_cuda_htod_lock);\n            return OPAL_ERROR;\n        }\n\n        *frag = cuda_event_htod_frag_array[cuda_event_htod_first_used];\n        opal_output_verbose(30, mca_common_cuda_output,\n                            \"CUDA: cuEventQuery returned %d\", result);\n\n        /* Bump counters, loop around the circular buffer if necessary */\n        --cuda_event_htod_num_used;\n        ++cuda_event_htod_first_used;\n        if (cuda_event_htod_first_used >= cuda_event_max) {\n            cuda_event_htod_first_used = 0;\n        }\n        /* A return value of 1 indicates an event completed and a frag was returned */\n        OPAL_THREAD_UNLOCK(&common_cuda_htod_lock);\n        return 1;\n    }\n    OPAL_THREAD_UNLOCK(&common_cuda_htod_lock);\n    return OPAL_ERR_RESOURCE_BUSY;\n}\n\n\n/**\n * Need to make sure the handle we are retrieving from the cache is still\n * valid.  Compare the cached handle to the one received.\n */\nint mca_common_cuda_memhandle_matches(mca_rcache_common_cuda_reg_t *new_reg,\n                                      mca_rcache_common_cuda_reg_t *old_reg)\n{\n\n    if (0 == memcmp(new_reg->data.memHandle, old_reg->data.memHandle, sizeof(new_reg->data.memHandle))) {\n        return 1;\n    } else {\n        return 0;\n    }\n\n}\n\n/*\n * Function to dump memory handle information.  This is based on\n * definitions from cuiinterprocess_private.h.\n */\nstatic void cuda_dump_memhandle(int verbose, void *memHandle, char *str) {\n\n    struct InterprocessMemHandleInternal\n    {\n        /* The first two entries are the CUinterprocessCtxHandle */\n        int64_t ctxId; /* unique (within a process) id of the sharing context */\n        int     pid;   /* pid of sharing context */\n\n        int64_t size;\n        int64_t blocksize;\n        int64_t offset;\n        int     gpuId;\n        int     subDeviceIndex;\n        int64_t serial;\n    } memH;\n\n    if (NULL == str) {\n        str = \"CUDA\";\n    }\n    memcpy(&memH, memHandle, sizeof(memH));\n    opal_output_verbose(verbose, mca_common_cuda_output,\n                        \"%s:ctxId=0x%\" PRIx64 \", pid=%d, size=%\" PRIu64 \", blocksize=%\" PRIu64 \", offset=%\"\n                        PRIu64 \", gpuId=%d, subDeviceIndex=%d, serial=%\" PRIu64,\n                        str, memH.ctxId, memH.pid, memH.size, memH.blocksize, memH.offset,\n                        memH.gpuId, memH.subDeviceIndex, memH.serial);\n}\n\n/*\n * Function to dump memory handle information.  This is based on\n * definitions from cuiinterprocess_private.h.\n */\nstatic void cuda_dump_evthandle(int verbose, void *evtHandle, char *str) {\n\n    struct InterprocessEventHandleInternal\n    {\n        unsigned long pid;\n        unsigned long serial;\n        int index;\n    } evtH;\n\n    if (NULL == str) {\n        str = \"CUDA\";\n    }\n    memcpy(&evtH, evtHandle, sizeof(evtH));\n    opal_output_verbose(verbose, mca_common_cuda_output,\n                        \"CUDA: %s:pid=%lu, serial=%lu, index=%d\",\n                        str, evtH.pid, evtH.serial, evtH.index);\n}\n\n\n/* Return microseconds of elapsed time. Microseconds are relevant when\n * trying to understand the fixed overhead of the communication. Used\n * when trying to time various functions.\n *\n * Cut and past the following to get timings where wanted.\n *\n *   clock_gettime(CLOCK_MONOTONIC, &ts_start);\n *   FUNCTION OF INTEREST\n *   clock_gettime(CLOCK_MONOTONIC, &ts_end);\n *   accum = mydifftime(ts_start, ts_end);\n *   opal_output(0, \"Function took   %7.2f usecs\\n\", accum);\n *\n */\n#if OPAL_ENABLE_DEBUG\nstatic float mydifftime(opal_timer_t ts_start, opal_timer_t ts_end) {\n    return (ts_end - ts_start);\n}\n#endif /* OPAL_ENABLE_DEBUG */\n\n/* Routines that get plugged into the opal datatype code */\nstatic int mca_common_cuda_is_gpu_buffer(const void *pUserBuf, opal_convertor_t *convertor)\n{\n    int res;\n    CUmemorytype memType = 0;\n    CUdeviceptr dbuf = (CUdeviceptr)pUserBuf;\n    CUcontext ctx = NULL, memCtx = NULL;\n#if OPAL_CUDA_GET_ATTRIBUTES\n    uint32_t isManaged = 0;\n    /* With CUDA 7.0, we can get multiple attributes with a single call */\n    CUpointer_attribute attributes[3] = {CU_POINTER_ATTRIBUTE_MEMORY_TYPE,\n                                         CU_POINTER_ATTRIBUTE_CONTEXT,\n                                         CU_POINTER_ATTRIBUTE_IS_MANAGED};\n    void *attrdata[] = {(void *)&memType, (void *)&memCtx, (void *)&isManaged};\n\n    res = cuFunc.cuPointerGetAttributes(3, attributes, attrdata, dbuf);\n    OPAL_OUTPUT_VERBOSE((101, mca_common_cuda_output,\n                        \"dbuf=%p, memType=%d, memCtx=%p, isManaged=%d, res=%d\",\n                         (void *)dbuf, (int)memType, (void *)memCtx, isManaged, res));\n\n    /* Mark unified memory buffers with a flag.  This will allow all unified\n     * memory to be forced through host buffers.  Note that this memory can\n     * be either host or device so we need to set this flag prior to that check. */\n    if (1 == isManaged) {\n        if (NULL != convertor) {\n            convertor->flags |= CONVERTOR_CUDA_UNIFIED;\n        }\n    }\n    if (res != CUDA_SUCCESS) {\n        /* If we cannot determine it is device pointer,\n         * just assume it is not. */\n        return 0;\n    } else if (memType == CU_MEMORYTYPE_HOST) {\n        /* Host memory, nothing to do here */\n        return 0;\n    } else if (memType == 0) {\n        /* This can happen when CUDA is initialized but dbuf is not valid CUDA pointer */\n        return 0;\n    }\n    /* Must be a device pointer */\n    assert(memType == CU_MEMORYTYPE_DEVICE);\n#else /* OPAL_CUDA_GET_ATTRIBUTES */\n    res = cuFunc.cuPointerGetAttribute(&memType,\n                                       CU_POINTER_ATTRIBUTE_MEMORY_TYPE, dbuf);\n    if (res != CUDA_SUCCESS) {\n        /* If we cannot determine it is device pointer,\n         * just assume it is not. */\n        return 0;\n    } else if (memType == CU_MEMORYTYPE_HOST) {\n        /* Host memory, nothing to do here */\n        return 0;\n    }\n    /* Must be a device pointer */\n    assert(memType == CU_MEMORYTYPE_DEVICE);\n#endif /* OPAL_CUDA_GET_ATTRIBUTES */\n\n    /* This piece of code was added in to handle in a case involving\n     * OMP threads.  The user had initialized CUDA and then spawned\n     * two threads.  The first thread had the CUDA context, but the\n     * second thread did not.  We therefore had no context to act upon\n     * and future CUDA driver calls would fail.  Therefore, if we have\n     * GPU memory, but no context, get the context from the GPU memory\n     * and set the current context to that.  It is rare that we will not\n     * have a context. */\n    res = cuFunc.cuCtxGetCurrent(&ctx);\n    if (OPAL_UNLIKELY(NULL == ctx)) {\n        if (CUDA_SUCCESS == res) {\n#if !OPAL_CUDA_GET_ATTRIBUTES\n            res = cuFunc.cuPointerGetAttribute(&memCtx,\n                                               CU_POINTER_ATTRIBUTE_CONTEXT, dbuf);\n            if (OPAL_UNLIKELY(res != CUDA_SUCCESS)) {\n                opal_output(0, \"CUDA: error calling cuPointerGetAttribute: \"\n                            \"res=%d, ptr=%p aborting...\", res, pUserBuf);\n                return OPAL_ERROR;\n            }\n#endif /* OPAL_CUDA_GET_ATTRIBUTES */\n            res = cuFunc.cuCtxSetCurrent(memCtx);\n            if (OPAL_UNLIKELY(res != CUDA_SUCCESS)) {\n                opal_output(0, \"CUDA: error calling cuCtxSetCurrent: \"\n                            \"res=%d, ptr=%p aborting...\", res, pUserBuf);\n                return OPAL_ERROR;\n            } else {\n                OPAL_OUTPUT_VERBOSE((10, mca_common_cuda_output,\n                                     \"CUDA: cuCtxSetCurrent passed: ptr=%p\", pUserBuf));\n            }\n        } else {\n            /* Print error and proceed */\n            opal_output(0, \"CUDA: error calling cuCtxGetCurrent: \"\n                        \"res=%d, ptr=%p aborting...\", res, pUserBuf);\n            return OPAL_ERROR;\n        }\n    }\n\n    /* WORKAROUND - They are times when the above code determines a pice of memory\n     * is GPU memory, but it actually is not.  That has been seen on multi-GPU systems\n     * with 6 or 8 GPUs on them. Therefore, we will do this extra check.  Note if we\n     * made it this far, then the assumption at this point is we have GPU memory.\n     * Unfotunately, this extra call is costing us another 100 ns almost doubling\n     * the cost of this entire function. */\n    if (OPAL_LIKELY(mca_common_cuda_gpu_mem_check_workaround)) {\n        CUdeviceptr pbase;\n        size_t psize;\n        res = cuFunc.cuMemGetAddressRange(&pbase, &psize, dbuf);\n        if (CUDA_SUCCESS != res) {\n            opal_output_verbose(5, mca_common_cuda_output,\n                                \"CUDA: cuMemGetAddressRange failed on this pointer: res=%d, buf=%p \"\n                                \"Overriding check and setting to host pointer. \",\n                              res, (void *)dbuf);\n            /* This cannot be GPU memory if the previous call failed */\n            return 0;\n        }\n    }\n\n    /* First access on a device pointer finalizes CUDA support initialization.\n     * If initialization fails, disable support. */\n    if (!stage_three_init_complete) {\n        if (0 != mca_common_cuda_stage_three_init()) {\n            opal_cuda_support = 0;\n        }\n    }\n\n    return 1;\n}\n\nstatic int mca_common_cuda_cu_memcpy_async(void *dest, const void *src, size_t size,\n                                         opal_convertor_t* convertor)\n{\n    return cuFunc.cuMemcpyAsync((CUdeviceptr)dest, (CUdeviceptr)src, size,\n                                (CUstream)convertor->stream);\n}\n\n/**\n * This function is plugged into various areas where a cuMemcpy would be called.\n * This is a synchronous operation that will not return until the copy is complete.\n */\nstatic int mca_common_cuda_cu_memcpy(void *dest, const void *src, size_t size)\n{\n    CUresult result;\n#if OPAL_ENABLE_DEBUG\n    CUmemorytype memTypeSrc, memTypeDst;\n    if (OPAL_UNLIKELY(mca_common_cuda_cumemcpy_timing)) {\n        /* Nice to know type of source and destination for timing output. Do\n         * not care about return code as memory type will just be set to 0 */\n        result = cuFunc.cuPointerGetAttribute(&memTypeDst,\n                                              CU_POINTER_ATTRIBUTE_MEMORY_TYPE, (CUdeviceptr)dest);\n        result = cuFunc.cuPointerGetAttribute(&memTypeSrc,\n                                              CU_POINTER_ATTRIBUTE_MEMORY_TYPE, (CUdeviceptr)src);\n        ts_start = opal_timer_base_get_usec();\n    }\n#endif\n    if (mca_common_cuda_cumemcpy_async) {\n        result = cuFunc.cuMemcpyAsync((CUdeviceptr)dest, (CUdeviceptr)src, size, memcpyStream);\n        if (OPAL_UNLIKELY(CUDA_SUCCESS != result)) {\n            opal_show_help(\"help-mpi-common-cuda.txt\", \"cuMemcpyAsync failed\",\n                           true, dest, src, size, result);\n            return OPAL_ERROR;\n        }\n        result = cuFunc.cuStreamSynchronize(memcpyStream);\n        if (OPAL_UNLIKELY(CUDA_SUCCESS != result)) {\n            opal_show_help(\"help-mpi-common-cuda.txt\", \"cuStreamSynchronize failed\",\n                           true, OPAL_PROC_MY_HOSTNAME, result);\n            return OPAL_ERROR;\n        }\n    } else {\n         result = cuFunc.cuMemcpy((CUdeviceptr)dest, (CUdeviceptr)src, size);\n         if (OPAL_UNLIKELY(CUDA_SUCCESS != result)) {\n             opal_show_help(\"help-mpi-common-cuda.txt\", \"cuMemcpy failed\",\n                            true, OPAL_PROC_MY_HOSTNAME, result);\n             return OPAL_ERROR;\n         }\n    }\n#if OPAL_ENABLE_DEBUG\n    if (OPAL_UNLIKELY(mca_common_cuda_cumemcpy_timing)) {\n        ts_end = opal_timer_base_get_usec();\n        accum = mydifftime(ts_start, ts_end);\n        if (mca_common_cuda_cumemcpy_async) {\n            opal_output(0, \"cuMemcpyAsync took   %7.2f usecs, size=%d, (src=%p (%d), dst=%p (%d))\\n\",\n                        accum, (int)size, src, memTypeSrc, dest, memTypeDst);\n        } else {\n            opal_output(0, \"cuMemcpy took   %7.2f usecs, size=%d,  (src=%p (%d), dst=%p (%d))\\n\",\n                        accum, (int)size, src, memTypeSrc, dest, memTypeDst);\n        }\n    }\n#endif\n    return OPAL_SUCCESS;\n}\n\nstatic int mca_common_cuda_memmove(void *dest, void *src, size_t size)\n{\n    CUdeviceptr tmp;\n    int result;\n\n    result = cuFunc.cuMemAlloc(&tmp,size);\n    if (mca_common_cuda_cumemcpy_async) {\n        result = cuFunc.cuMemcpyAsync(tmp, (CUdeviceptr)src, size, memcpyStream);\n        if (OPAL_UNLIKELY(CUDA_SUCCESS != result)) {\n            opal_show_help(\"help-mpi-common-cuda.txt\", \"cuMemcpyAsync failed\",\n                           true, tmp, src, size, result);\n            return OPAL_ERROR;\n        }\n        result = cuFunc.cuMemcpyAsync((CUdeviceptr)dest, tmp, size, memcpyStream);\n        if (OPAL_UNLIKELY(CUDA_SUCCESS != result)) {\n            opal_show_help(\"help-mpi-common-cuda.txt\", \"cuMemcpyAsync failed\",\n                           true, dest, tmp, size, result);\n            return OPAL_ERROR;\n        }\n        result = cuFunc.cuStreamSynchronize(memcpyStream);\n        if (OPAL_UNLIKELY(CUDA_SUCCESS != result)) {\n            opal_show_help(\"help-mpi-common-cuda.txt\", \"cuStreamSynchronize failed\",\n                           true, OPAL_PROC_MY_HOSTNAME, result);\n            return OPAL_ERROR;\n        }\n    } else {\n        result = cuFunc.cuMemcpy(tmp, (CUdeviceptr)src, size);\n        if (OPAL_UNLIKELY(result != CUDA_SUCCESS)) {\n            opal_output(0, \"CUDA: memmove-Error in cuMemcpy: res=%d, dest=%p, src=%p, size=%d\",\n                        result, (void *)tmp, src, (int)size);\n            return OPAL_ERROR;\n        }\n        result = cuFunc.cuMemcpy((CUdeviceptr)dest, tmp, size);\n        if (OPAL_UNLIKELY(result != CUDA_SUCCESS)) {\n            opal_output(0, \"CUDA: memmove-Error in cuMemcpy: res=%d, dest=%p, src=%p, size=%d\",\n                        result, dest, (void *)tmp, (int)size);\n            return OPAL_ERROR;\n        }\n    }\n    cuFunc.cuMemFree(tmp);\n    return OPAL_SUCCESS;\n}\n\nint mca_common_cuda_get_device(int *devicenum)\n{\n    CUdevice cuDev;\n    int res;\n\n    res = cuFunc.cuCtxGetDevice(&cuDev);\n    if (OPAL_UNLIKELY(res != CUDA_SUCCESS)) {\n        opal_output(0, \"CUDA: cuCtxGetDevice failed: res=%d\",\n                    res);\n        return res;\n    }\n    *devicenum = cuDev;\n    return 0;\n}\n\nint mca_common_cuda_device_can_access_peer(int *access, int dev1, int dev2)\n{\n    int res;\n    res = cuFunc.cuDeviceCanAccessPeer(access, (CUdevice)dev1, (CUdevice)dev2);\n    if (OPAL_UNLIKELY(res != CUDA_SUCCESS)) {\n        opal_output(0, \"CUDA: cuDeviceCanAccessPeer failed: res=%d\",\n                    res);\n        return res;\n    }\n    return 0;\n}\n\nint mca_common_cuda_get_address_range(void *pbase, size_t *psize, void *base)\n{\n    CUresult result;\n    result = cuFunc.cuMemGetAddressRange((CUdeviceptr *)pbase, psize, (CUdeviceptr)base);\n    if (OPAL_UNLIKELY(CUDA_SUCCESS != result)) {\n        opal_show_help(\"help-mpi-common-cuda.txt\", \"cuMemGetAddressRange failed 2\",\n                       true, OPAL_PROC_MY_HOSTNAME, result, base);\n        return OPAL_ERROR;\n    } else {\n        opal_output_verbose(50, mca_common_cuda_output,\n                            \"CUDA: cuMemGetAddressRange passed: addr=%p, pbase=%p, psize=%lu \",\n                            base, *(char **)pbase, *psize);\n    }\n    return 0;\n}\n\n#if OPAL_CUDA_GDR_SUPPORT\n/* Check to see if the memory was freed between the time it was stored in\n * the registration cache and now.  Return true if the memory was previously\n * freed.  This is indicated by the BUFFER_ID value in the registration cache\n * not matching the BUFFER_ID of the buffer we are checking.  Return false\n * if the registration is still good.\n */\nbool mca_common_cuda_previously_freed_memory(mca_rcache_base_registration_t *reg)\n{\n    int res;\n    unsigned long long bufID;\n    unsigned char *dbuf = reg->base;\n\n    res = cuFunc.cuPointerGetAttribute(&bufID, CU_POINTER_ATTRIBUTE_BUFFER_ID,\n                                       (CUdeviceptr)dbuf);\n    /* If we cannot determine the BUFFER_ID, then print a message and default\n     * to forcing the registration to be kicked out. */\n    if (OPAL_UNLIKELY(res != CUDA_SUCCESS)) {\n        opal_show_help(\"help-mpi-common-cuda.txt\", \"bufferID failed\",\n                       true, OPAL_PROC_MY_HOSTNAME, res);\n        return true;\n    }\n    opal_output_verbose(50, mca_common_cuda_output,\n                        \"CUDA: base=%p, bufID=%llu, reg->gpu_bufID=%llu, %s\", dbuf, bufID, reg->gpu_bufID,\n                        (reg->gpu_bufID == bufID ? \"BUFFER_ID match\":\"BUFFER_ID do not match\"));\n    if (bufID != reg->gpu_bufID) {\n        return true;\n    } else {\n        return false;\n    }\n}\n\n/*\n * Get the buffer ID from the memory and store it in the registration.\n * This is needed to ensure the cached registration is not stale.  If\n * we fail to get buffer ID, print an error and set buffer ID to 0.\n * Also set SYNC_MEMOPS on any GPU registration to ensure that\n * synchronous copies complete before the buffer is accessed.\n */\nvoid mca_common_cuda_get_buffer_id(mca_rcache_base_registration_t *reg)\n{\n    int res;\n    unsigned long long bufID = 0;\n    unsigned char *dbuf = reg->base;\n    int enable = 1;\n\n    res = cuFunc.cuPointerGetAttribute(&bufID, CU_POINTER_ATTRIBUTE_BUFFER_ID,\n                                       (CUdeviceptr)dbuf);\n    if (OPAL_UNLIKELY(res != CUDA_SUCCESS)) {\n        opal_show_help(\"help-mpi-common-cuda.txt\", \"bufferID failed\",\n                       true, OPAL_PROC_MY_HOSTNAME, res);\n    }\n    reg->gpu_bufID = bufID;\n\n    res = cuFunc.cuPointerSetAttribute(&enable, CU_POINTER_ATTRIBUTE_SYNC_MEMOPS,\n                                       (CUdeviceptr)dbuf);\n    if (OPAL_UNLIKELY(CUDA_SUCCESS != res)) {\n        opal_show_help(\"help-mpi-common-cuda.txt\", \"cuPointerSetAttribute failed\",\n                       true, OPAL_PROC_MY_HOSTNAME, res, dbuf);\n    }\n}\n#endif /* OPAL_CUDA_GDR_SUPPORT */\n",
        "/tmp/vanessa/spack-stage/spack-stage-openmpi-master-qcrm7qmgqutvsby2zcmdb57s22lzfq65/spack-src/opal/mca/common/cuda/help-mpi-common-cuda.txt": "# -*- text -*-\n#\n# Copyright (c) 2011-2015 NVIDIA.  All rights reserved.\n# Copyright (c) 2015 Cisco Systems, Inc.  All rights reserved.\n# $COPYRIGHT$\n#\n# Additional copyrights may follow\n#\n# $HEADER$\n#\n[cuCtxGetCurrent failed not initialized]\nWARNING: The call to cuCtxGetCurrent() failed while attempting to register\ninternal memory with the CUDA environment.  The program will continue to run,\nbut the performance of GPU memory transfers may be reduced.  This failure\nindicates that the CUDA environment is not yet initialized.  To eliminate\nthis warning, ensure that CUDA is initialized prior to calling MPI_Init.\n\nNOTE: You can turn off this warning by setting the MCA parameter\n      mpi_common_cuda_warning to 0.\n#\n[cuCtxGetCurrent failed]\nWARNING: The call to cuCtxGetCurrent() failed while attempting to register\ninternal memory with the CUDA environment.  The program will continue to run,\nbut the performance of GPU memory transfers may be reduced.\n  cuCtxGetCurrent return value:   %d\n\nNOTE: You can turn off this warning by setting the MCA parameter\n      mpi_common_cuda_warning to 0.\n#\n[cuCtxGetCurrent returned NULL]\nWARNING: The call to cuCtxGetCurrent() failed while attempting to register\ninternal memory with the CUDA environment.  The program will continue to run,\nbut the performance of GPU memory transfers may be reduced.  This failure\nindicates that there is no CUDA context yet.  To eliminate this warning,\nensure that there is a CUDA context prior to calling MPI_Init.\n\nNOTE: You can turn off this warning by setting the MCA parameter\n      mpi_common_cuda_warning to 0.\n#\n[cuMemHostRegister during init failed]\nThe call to cuMemHostRegister(%p, %d, 0) failed.\n  Host:  %s\n  cuMemHostRegister return value:  %d\n  Registration cache:  %s\n#\n[cuMemHostRegister failed]\nThe call to cuMemHostRegister(%p, %d, 0) failed.\n  Host:  %s\n  cuMemHostRegister return value:  %d\n  Registration cache:  %s\n#\n[cuIpcGetMemHandle failed]\nThe call to cuIpcGetMemHandle failed. This means the GPU RDMA protocol\ncannot be used.\n  cuIpcGetMemHandle return value:   %d\n  address: %p\nCheck the cuda.h file for what the return value means. Perhaps a reboot\nof the node will clear the problem.\n#\n[cuMemGetAddressRange failed]\nThe call to cuMemGetAddressRange failed. This means the GPU RDMA protocol\ncannot be used.\n  cuMemGetAddressRange return value:   %d\n  address: %p\nCheck the cuda.h file for what the return value means. Perhaps a reboot\nof the node will clear the problem.\n#\n[cuMemGetAddressRange failed 2]\nThe call to cuMemGetAddressRange failed during the GPU RDMA protocol.\n  Host:  %s\n  cuMemGetAddressRange return value:  %d\n  address:  %p\nCheck the cuda.h file for what the return value means. This is highly\nunusual and should not happen. The program will probably abort.\n#\n[Out of cuEvent handles]\nThe library has exceeded its number of outstanding event handles.\nFor better performance, this number should be increased.\n  Current maximum handles:   %4d\n  Suggested new maximum:     %4d\nRerun with --mca mpi_common_cuda_event_max %d\n#\n[cuIpcOpenMemHandle failed]\nThe call to cuIpcOpenMemHandle failed. This is an unrecoverable error\nand will cause the program to abort.\n  Hostname:                         %s\n  cuIpcOpenMemHandle return value:  %d\n  address:                          %p\nCheck the cuda.h file for what the return value means. A possible cause\nfor this is not enough free device memory.  Try to reduce the device\nmemory footprint of your application.\n#\n[cuIpcCloseMemHandle failed]\nThe call to cuIpcCloseMemHandle failed. This is a warning and the program\nwill continue to run.\n  cuIpcCloseMemHandle return value:   %d\n  address: %p\nCheck the cuda.h file for what the return value means. Perhaps a reboot\nof the node will clear the problem.\n#\n[cuMemcpyAsync failed]\nThe call to cuMemcpyAsync failed. This is a unrecoverable error and will\ncause the program to abort.\n  cuMemcpyAsync(%p, %p, %d) returned value %d\nCheck the cuda.h file for what the return value means.\n#\n[cuEventCreate failed]\nThe call to cuEventCreate failed. This is a unrecoverable error and will\ncause the program to abort.\n  Hostname:                     %s\n  cuEventCreate return value:   %d\nCheck the cuda.h file for what the return value means.\n#\n[cuEventRecord failed]\nThe call to cuEventRecord failed. This is a unrecoverable error and will\ncause the program to abort.\n  Hostname:                     %s\n  cuEventRecord return value:   %d\nCheck the cuda.h file for what the return value means.\n#\n[cuEventQuery failed]\nThe call to cuEventQuery failed. This is a unrecoverable error and will\ncause the program to abort.\n  cuEventQuery return value:   %d\nCheck the cuda.h file for what the return value means.\n#\n[cuIpcGetEventHandle failed]\nThe call to cuIpcGetEventHandle failed. This is a unrecoverable error and will\ncause the program to abort.\n  cuIpcGetEventHandle return value:   %d\nCheck the cuda.h file for what the return value means.\n#\n[cuIpcOpenEventHandle failed]\nThe call to cuIpcOpenEventHandle failed. This is a unrecoverable error and will\ncause the program to abort.\n  cuIpcOpenEventHandle return value:   %d\nCheck the cuda.h file for what the return value means.\n#\n[cuStreamWaitEvent failed]\nThe call to cuStreamWaitEvent failed. This is a unrecoverable error and will\ncause the program to abort.\n  cuStreamWaitEvent return value:   %d\nCheck the cuda.h file for what the return value means.\n#\n[cuEventDestroy failed]\nThe call to cuEventDestory failed. This is a unrecoverable error and will\ncause the program to abort.\n  cuEventDestory return value:   %d\nCheck the cuda.h file for what the return value means.\n#\n[cuStreamCreate failed]\nThe call to cuStreamCreate failed.  This is a unrecoverable error and will\ncause the program to abort.\n  Hostname:                      %s\n  cuStreamCreate return value:   %d\nCheck the cuda.h file for what the return vale means.\n#\n[dlopen disabled]\nOpen MPI was compiled without dynamic library support (e.g., with the\n --disable-dlopen flag), and therefore cannot utilize CUDA support.\n\nIf you need CUDA support, reconfigure Open MPI with dynamic library support enabled.\n#\n[dlopen failed]\nThe library attempted to open the following supporting CUDA libraries,\nbut each of them failed.  CUDA-aware support is disabled.\n%s\nIf you do not require CUDA-aware support, then run with\n--mca opal_warn_on_missing_libcuda 0 to suppress this message.  If you do\nrequire CUDA-aware support, then try setting LD_LIBRARY_PATH to the location\nof libcuda.so.1 to resolve this issue.\n#\n[dlsym failed]\nAn error occurred while trying to map in the address of a function.\n  Function Name: %s\n  Error string:  %s\nCUDA-aware support is disabled.\n#\n[bufferID failed]\nAn error occurred while trying to get the BUFFER_ID of a GPU memory\nregion.  This could cause incorrect results.  Turn of GPU Direct RDMA\nsupport by running with --mca btl_openib_cuda_want_gdr_support 0.\n  Hostname:                             %s\n  cuPointerGetAttribute return value:   %d\nCheck the cuda.h file for what the return value means.\n[cuPointerSetAttribute failed]\nThe call to cuPointerSetAttribute with CU_POINTER_ATTRIBUTE_SYNC_MEMOPS\nfailed. This is highly unusual and should not happen.  The program will\ncontinue, but report this error to the Open MPI developers.\n  Hostname:                             %s\n  cuPointerSetAttribute return value:   %d\n  Address:                              %p\nCheck the cuda.h file for what the return value means.\n#\n[cuStreamSynchronize failed]\nThe call to cuStreamSynchronize failed. This is highly unusual and should\nnot happen.  Please report this error to the Open MPI developers.\n  Hostname:                             %s\n  cuStreamSynchronize return value:     %d\nCheck the cuda.h file for what the return value means.\n#\n[cuMemcpy failed]\nThe call to cuMemcpy failed. This is highly unusual and should\nnot happen.  Please report this error to the Open MPI developers.\n  Hostname:                  %s\n  cuMemcpy return value:     %d\nCheck the cuda.h file for what the return value means.\n#\n[No memory]\nA call to allocate memory within the CUDA support failed.  This is\nan unrecoverable error and will cause the program to abort.\n  Hostname:  %s\n",
        "/tmp/vanessa/spack-stage/spack-stage-openmpi-master-qcrm7qmgqutvsby2zcmdb57s22lzfq65/spack-src/opal/mca/base/base.h": "/* -*- Mode: C; c-basic-offset:4 ; indent-tabs-mode:nil -*- */\n/*\n * Copyright (c) 2004-2008 The Trustees of Indiana University and Indiana\n *                         University Research and Technology\n *                         Corporation.  All rights reserved.\n * Copyright (c) 2004-2007 The University of Tennessee and The University\n *                         of Tennessee Research Foundation.  All rights\n *                         reserved.\n * Copyright (c) 2004-2005 High Performance Computing Center Stuttgart,\n *                         University of Stuttgart.  All rights reserved.\n * Copyright (c) 2004-2005 The Regents of the University of California.\n *                         All rights reserved.\n * Copyright (c) 2009      Cisco Systems, Inc.  All rights reserved.\n * Copyright (c) 2013-2015 Los Alamos National Security, LLC. All rights\n *                         reserved.\n * Copyright (c) 2015      Research Organization for Information Science\n *                         and Technology (RIST). All rights reserved.\n * Copyright (c) 2017 IBM Corporation.  All rights reserved.\n * Copyright (c) 2018      Triad National Security, LLC. All rights\n *                         reserved.\n * $COPYRIGHT$\n *\n * Additional copyrights may follow\n *\n * $HEADER$\n */\n\n#ifndef MCA_BASE_H\n#define MCA_BASE_H\n\n#include \"opal_config.h\"\n\n#include \"opal/class/opal_object.h\"\n#include \"opal/class/opal_list.h\"\n\n/*\n * These units are large enough to warrant their own .h files\n */\n#include \"opal/mca/mca.h\"\n#include \"opal/mca/base/mca_base_var.h\"\n#include \"opal/mca/base/mca_base_framework.h\"\n#include \"opal/util/cmd_line.h\"\n#include \"opal/util/output.h\"\n\nBEGIN_C_DECLS\n\n/*\n * Structure for making plain lists of components\n */\nstruct mca_base_component_list_item_t {\n    opal_list_item_t super;\n    const mca_base_component_t *cli_component;\n};\ntypedef struct mca_base_component_list_item_t mca_base_component_list_item_t;\nOPAL_DECLSPEC OBJ_CLASS_DECLARATION(mca_base_component_list_item_t);\n\n/*\n * Structure for making priority lists of components\n */\nstruct mca_base_component_priority_list_item_t {\n    mca_base_component_list_item_t super;\n    int cpli_priority;\n};\ntypedef struct mca_base_component_priority_list_item_t\n    mca_base_component_priority_list_item_t;\n\nOPAL_DECLSPEC OBJ_CLASS_DECLARATION(mca_base_component_priority_list_item_t);\n\n/*\n * Public variables\n */\nOPAL_DECLSPEC extern char *mca_base_component_path;\nOPAL_DECLSPEC extern bool mca_base_component_show_load_errors;\nOPAL_DECLSPEC extern bool mca_base_component_track_load_errors;\nOPAL_DECLSPEC extern bool mca_base_component_disable_dlopen;\nOPAL_DECLSPEC extern char *mca_base_system_default_path;\nOPAL_DECLSPEC extern char *mca_base_user_default_path;\n\n/*\n * Standard verbosity levels\n */\nenum {\n    /** total silence */\n    MCA_BASE_VERBOSE_NONE  = -1,\n    /** only errors are printed */\n    MCA_BASE_VERBOSE_ERROR = 0,\n    /** emit messages about component selection, open, and unloading */\n    MCA_BASE_VERBOSE_COMPONENT = 10,\n    /** also emit warnings */\n    MCA_BASE_VERBOSE_WARN  = 20,\n    /** also emit general, user-relevant information, such as rationale as to why certain choices\n     * or code paths were taken, information gleaned from probing the local system, etc. */\n    MCA_BASE_VERBOSE_INFO  = 40,\n    /** also emit relevant tracing information (e.g., which functions were invoked /\n     * call stack entry/exit info) */\n    MCA_BASE_VERBOSE_TRACE = 60,\n    /** also emit Open MPI-developer-level (i.e,. highly detailed) information */\n    MCA_BASE_VERBOSE_DEBUG = 80,\n    /** also output anything else that might be useful */\n    MCA_BASE_VERBOSE_MAX   = 100,\n};\n\n/*\n * Public functions\n */\n\n/**\n * First function called in the MCA.\n *\n * @return OPAL_SUCCESS Upon success\n * @return OPAL_ERROR Upon failure\n *\n * This function starts up the entire MCA.  It initializes a bunch\n * of built-in MCA parameters, and initialized the MCA component\n * repository.\n *\n * It must be the first MCA function invoked.  It is normally\n * invoked during the initialization stage and specifically\n * invoked in the special case of the *_info command.\n */\nOPAL_DECLSPEC int mca_base_open(void);\n\n/**\n * Last function called in the MCA\n *\n * @return OPAL_SUCCESS Upon success\n * @return OPAL_ERROR Upon failure\n *\n * This function closes down the entire MCA.  It clears all MCA\n * parameters and closes down the MCA component respository.\n *\n * It must be the last MCA function invoked.  It is normally invoked\n * during the finalize stage.\n */\nOPAL_DECLSPEC void mca_base_close(void);\n\n/**\n * A generic select function\n *\n */\nOPAL_DECLSPEC int mca_base_select(const char *type_name, int output_id,\n                                  opal_list_t *components_available,\n                                  mca_base_module_t **best_module,\n                                  mca_base_component_t **best_component,\n                                  int *priority_out);\n\n/**\n * A function for component query functions to discover if they have\n * been explicitly required to or requested to be selected.\n *\n * exclusive: If the specified component is the only component that is\n *            available for selection.\n *\n */\nOPAL_DECLSPEC int mca_base_is_component_required(opal_list_t *components_available,\n                                                 mca_base_component_t *component,\n                                                 bool exclusive,\n                                                 bool *is_required);\n\n/* mca_base_cmd_line.c */\n\nOPAL_DECLSPEC int mca_base_cmd_line_setup(opal_cmd_line_t *cmd);\nOPAL_DECLSPEC int mca_base_cmd_line_process_args(opal_cmd_line_t *cmd,\n                                                 char ***app_env,\n                                                 char ***global_env);\nOPAL_DECLSPEC void mca_base_cmd_line_wrap_args(char **args);\n\n/* mca_base_component_compare.c */\n\nOPAL_DECLSPEC int mca_base_component_compare_priority(mca_base_component_priority_list_item_t *a,\n                                                      mca_base_component_priority_list_item_t *b);\nOPAL_DECLSPEC int mca_base_component_compare(const mca_base_component_t *a,\n                                             const mca_base_component_t *b);\nOPAL_DECLSPEC int mca_base_component_compatible(const mca_base_component_t *a,\n                                                const mca_base_component_t *b);\nOPAL_DECLSPEC char * mca_base_component_to_string(const mca_base_component_t *a);\n\n/* mca_base_component_find.c */\n\nOPAL_DECLSPEC int mca_base_component_find (const char *directory, mca_base_framework_t *framework,\n                                           bool ignore_requested, bool open_dso_components);\n\n/**\n * Parse the requested component string and return an opal_argv of the requested\n * (or not requested) components.\n */\nint mca_base_component_parse_requested (const char *requested, bool *include_mode,\n                                        char ***requested_component_names);\n\n/**\n * Filter a list of components based on a comma-delimted list of names and/or\n * a set of meta-data flags.\n *\n * @param[in,out] components List of components to filter\n * @param[in] output_id Output id to write to for error/warning/debug messages\n * @param[in] filter_names Comma delimited list of components to use. Negate with ^.\n * May be NULL.\n * @param[in] filter_flags Metadata flags components are required to have set (CR ready)\n *\n * @returns OPAL_SUCCESS On success\n * @returns OPAL_ERR_NOT_FOUND If some component in {filter_names} is not found in\n * {components}. Does not apply to negated filters.\n * @returns opal error code On other error.\n *\n * This function closes and releases any components that do not match the filter_name and\n * filter flags.\n */\nOPAL_DECLSPEC int mca_base_components_filter (mca_base_framework_t *framework, uint32_t filter_flags);\n\n\n\n/* Safely release some memory allocated by mca_base_component_find()\n   (i.e., is safe to call even if you never called\n   mca_base_component_find()). */\nOPAL_DECLSPEC int mca_base_component_find_finalize(void);\n\n/* mca_base_components_register.c */\nOPAL_DECLSPEC int mca_base_framework_components_register (struct mca_base_framework_t *framework,\n                                                          mca_base_register_flag_t flags);\n\n/* mca_base_components_open.c */\nOPAL_DECLSPEC int mca_base_framework_components_open (struct mca_base_framework_t *framework,\n                                                      mca_base_open_flag_t flags);\n\nOPAL_DECLSPEC int mca_base_components_open(const char *type_name, int output_id,\n                                           const mca_base_component_t **static_components,\n                                           opal_list_t *components_available,\n                                           bool open_dso_components);\n\n/* mca_base_components_close.c */\n/**\n * Close and release a component.\n *\n * @param[in] component Component to close\n * @param[in] output_id Output id for debugging output\n *\n * After calling this function the component may no longer be used.\n */\nOPAL_DECLSPEC void mca_base_component_close (const mca_base_component_t *component, int output_id);\n\n/**\n * Release a component without closing it.\n * @param[in] component Component to close\n * @param[in] output_id Output id for debugging output\n *\n * After calling this function the component may no longer be used.\n */\nvoid mca_base_component_unload (const mca_base_component_t *component, int output_id);\n\nOPAL_DECLSPEC int mca_base_components_close(int output_id, opal_list_t *components_available,\n                                            const mca_base_component_t *skip);\n\nOPAL_DECLSPEC int mca_base_framework_components_close (struct mca_base_framework_t *framework,\n\t\t\t\t\t\t       const mca_base_component_t *skip);\n\nEND_C_DECLS\n\n#endif /* MCA_BASE_H */\n",
        "/tmp/vanessa/spack-stage/spack-stage-openmpi-master-qcrm7qmgqutvsby2zcmdb57s22lzfq65/spack-src/opal/mca/base/mca_base_component_repository.c": "/* -*- Mode: C; c-basic-offset:4 ; indent-tabs-mode:nil -*- */\n/*\n * Copyright (c) 2004-2005 The Trustees of Indiana University and Indiana\n *                         University Research and Technology\n *                         Corporation.  All rights reserved.\n * Copyright (c) 2004-2005 The University of Tennessee and The University\n *                         of Tennessee Research Foundation.  All rights\n *                         reserved.\n * Copyright (c) 2004-2005 High Performance Computing Center Stuttgart,\n *                         University of Stuttgart.  All rights reserved.\n * Copyright (c) 2004-2005 The Regents of the University of California.\n *                         All rights reserved.\n * Copyright (c) 2008-2015 Cisco Systems, Inc.  All rights reserved.\n * Copyright (c) 2015      Los Alamos National Security, LLC. All rights\n *                         reserved.\n * Copyright (c) 2015      Research Organization for Information Science\n *                         and Technology (RIST). All rights reserved.\n * Copyright (c) 2017 IBM Corporation.  All rights reserved.\n * Copyright (c) 2018      Amazon.com, Inc. or its affiliates.  All Rights reserved.\n * $COPYRIGHT$\n *\n * Additional copyrights may follow\n *\n * $HEADER$\n */\n\n\n#include \"opal_config.h\"\n#ifdef HAVE_SYS_TYPES_H\n#include <sys/types.h>\n#endif\n#include <string.h>\n#include <stdlib.h>\n#include <stdio.h>\n#ifdef HAVE_UNISTD_H\n#include <unistd.h>\n#endif\n\n#include \"opal/class/opal_list.h\"\n#include \"opal/mca/mca.h\"\n#include \"opal/mca/base/base.h\"\n#include \"opal/mca/base/mca_base_component_repository.h\"\n#include \"opal/mca/dl/base/base.h\"\n#include \"opal/constants.h\"\n#include \"opal/class/opal_hash_table.h\"\n#include \"opal/util/basename.h\"\n#include \"opal/util/string_copy.h\"\n#include \"opal/util/printf.h\"\n\n#if OPAL_HAVE_DL_SUPPORT\n\n/*\n * Private types\n */\nstatic void ri_constructor(mca_base_component_repository_item_t *ri);\nstatic void ri_destructor(mca_base_component_repository_item_t *ri);\nOBJ_CLASS_INSTANCE(mca_base_component_repository_item_t, opal_list_item_t,\n                   ri_constructor, ri_destructor);\n\n#endif /* OPAL_HAVE_DL_SUPPORT */\n\nstatic void clf_constructor(opal_object_t *obj);\nstatic void clf_destructor(opal_object_t *obj);\n\nOBJ_CLASS_INSTANCE(mca_base_failed_component_t, opal_list_item_t,\n                   clf_constructor, clf_destructor);\n\n\nstatic void clf_constructor(opal_object_t *obj)\n{\n    mca_base_failed_component_t *cli = (mca_base_failed_component_t *) obj;\n    cli->comp = NULL;\n    cli->error_msg = NULL;\n}\n\nstatic void clf_destructor(opal_object_t *obj)\n{\n    mca_base_failed_component_t *cli = (mca_base_failed_component_t *) obj;\n    cli->comp = NULL;\n    if( NULL != cli->error_msg ) {\n        free(cli->error_msg);\n        cli->error_msg = NULL;\n    }\n}\n\n/*\n * Private variables\n */\nstatic bool initialized = false;\n\n\n#if OPAL_HAVE_DL_SUPPORT\n\nstatic opal_hash_table_t mca_base_component_repository;\n\n/* two-level macro for stringifying a number */\n#define STRINGIFYX(x) #x\n#define STRINGIFY(x) STRINGIFYX(x)\n\nstatic int process_repository_item (const char *filename, void *data)\n{\n    char name[MCA_BASE_MAX_COMPONENT_NAME_LEN + 1];\n    char type[MCA_BASE_MAX_TYPE_NAME_LEN + 1];\n    mca_base_component_repository_item_t *ri;\n    opal_list_t *component_list;\n    char *base;\n    int ret;\n\n    base = opal_basename (filename);\n    if (NULL == base) {\n        return OPAL_ERROR;\n    }\n\n    /* check if the plugin has the appropriate prefix */\n    if (0 != strncmp (base, \"mca_\", 4)) {\n        free (base);\n        return OPAL_SUCCESS;\n    }\n\n    /* read framework and component names. framework names may not include an _\n     * but component names may */\n    ret = sscanf (base, \"mca_%\" STRINGIFY(MCA_BASE_MAX_TYPE_NAME_LEN) \"[^_]_%\"\n                  STRINGIFY(MCA_BASE_MAX_COMPONENT_NAME_LEN) \"s\", type, name);\n    if (0 > ret) {\n        /* does not patch the expected template. skip */\n        free(base);\n        return OPAL_SUCCESS;\n    }\n\n    /* lookup the associated framework list and create if it doesn't already exist */\n    ret = opal_hash_table_get_value_ptr (&mca_base_component_repository, type,\n                                         strlen (type), (void **) &component_list);\n    if (OPAL_SUCCESS != ret) {\n        component_list = OBJ_NEW(opal_list_t);\n        if (NULL == component_list) {\n            free (base);\n            /* OOM. nothing to do but fail */\n            return OPAL_ERR_OUT_OF_RESOURCE;\n        }\n\n        ret = opal_hash_table_set_value_ptr (&mca_base_component_repository, type,\n                                             strlen (type), (void *) component_list);\n        if (OPAL_SUCCESS != ret) {\n            free (base);\n            OBJ_RELEASE(component_list);\n            return ret;\n        }\n    }\n\n    /* check for duplicate components */\n    OPAL_LIST_FOREACH(ri, component_list, mca_base_component_repository_item_t) {\n        if (0 == strcmp (ri->ri_name, name)) {\n            /* already scanned this component */\n            free (base);\n            return OPAL_SUCCESS;\n        }\n    }\n\n    ri = OBJ_NEW(mca_base_component_repository_item_t);\n    if (NULL == ri) {\n        free (base);\n        return OPAL_ERR_OUT_OF_RESOURCE;\n    }\n\n    ri->ri_base = base;\n\n    ri->ri_path = strdup (filename);\n    if (NULL == ri->ri_path) {\n        OBJ_RELEASE(ri);\n        return OPAL_ERR_OUT_OF_RESOURCE;\n    }\n\n    opal_string_copy (ri->ri_type, type, MCA_BASE_MAX_TYPE_NAME_LEN);\n    opal_string_copy (ri->ri_name, name, MCA_BASE_MAX_COMPONENT_NAME_LEN);\n\n    opal_list_append (component_list, &ri->super);\n\n    return OPAL_SUCCESS;\n}\n\nstatic int file_exists(const char *filename, const char *ext)\n{\n    char *final;\n    int ret;\n\n    if (NULL == ext) {\n        return access (filename, F_OK) == 0;\n    }\n\n    ret = opal_asprintf(&final, \"%s.%s\", filename, ext);\n    if (0 > ret || NULL == final) {\n        return 0;\n    }\n\n    ret = access (final, F_OK);\n    free(final);\n    return (0 == ret);\n}\n\n#endif /* OPAL_HAVE_DL_SUPPORT */\n\nint mca_base_component_repository_add (const char *path)\n{\n#if OPAL_HAVE_DL_SUPPORT\n    char *path_to_use = NULL, *dir, *ctx;\n    const char sep[] = {OPAL_ENV_SEP, '\\0'};\n\n    if (NULL == path) {\n        /* nothing to do */\n        return OPAL_SUCCESS;\n    }\n\n    path_to_use = strdup (path);\n\n    dir = strtok_r (path_to_use, sep, &ctx);\n    do {\n        if ((0 == strcmp(dir, \"USER_DEFAULT\") || 0 == strcmp(dir, \"USR_DEFAULT\"))\n            && NULL != mca_base_user_default_path) {\n            dir = mca_base_user_default_path;\n        } else if (0 == strcmp(dir, \"SYS_DEFAULT\") ||\n                   0 == strcmp(dir, \"SYSTEM_DEFAULT\")) {\n            dir = mca_base_system_default_path;\n        }\n\n        if (0 != opal_dl_foreachfile(dir, process_repository_item, NULL)) {\n            break;\n        }\n    } while (NULL != (dir = strtok_r (NULL, sep, &ctx)));\n\n    free (path_to_use);\n\n#endif /* OPAL_HAVE_DL_SUPPORT */\n\n    return OPAL_SUCCESS;\n}\n\n\n/*\n * Initialize the repository\n */\nint mca_base_component_repository_init(void)\n{\n  /* Setup internal structures */\n\n  if (!initialized) {\n#if OPAL_HAVE_DL_SUPPORT\n\n    /* Initialize the dl framework */\n    int ret = mca_base_framework_open(&opal_dl_base_framework, 0);\n    if (OPAL_SUCCESS != ret) {\n        opal_output(0, \"%s %d:%s failed -- process will likely abort (open the dl framework returned %d instead of OPAL_SUCCESS)\\n\",\n                    __FILE__, __LINE__, __func__, ret);\n        return ret;\n    }\n    opal_dl_base_select();\n\n    OBJ_CONSTRUCT(&mca_base_component_repository, opal_hash_table_t);\n    ret = opal_hash_table_init (&mca_base_component_repository, 128);\n    if (OPAL_SUCCESS != ret) {\n        (void) mca_base_framework_close (&opal_dl_base_framework);\n        return ret;\n    }\n\n    ret = mca_base_component_repository_add (mca_base_component_path);\n    if (OPAL_SUCCESS != ret) {\n        OBJ_DESTRUCT(&mca_base_component_repository);\n        (void) mca_base_framework_close (&opal_dl_base_framework);\n        return ret;\n    }\n#endif\n\n    initialized = true;\n  }\n\n  /* All done */\n\n  return OPAL_SUCCESS;\n}\n\nint mca_base_component_repository_get_components (mca_base_framework_t *framework,\n                                                  opal_list_t **framework_components)\n{\n    *framework_components = NULL;\n#if OPAL_HAVE_DL_SUPPORT\n    return opal_hash_table_get_value_ptr (&mca_base_component_repository, framework->framework_name,\n                                          strlen (framework->framework_name), (void **) framework_components);\n#endif\n    return OPAL_ERR_NOT_FOUND;\n}\n\n#if OPAL_HAVE_DL_SUPPORT\nstatic void mca_base_component_repository_release_internal (mca_base_component_repository_item_t *ri) {\n    int group_id;\n\n    group_id = mca_base_var_group_find (NULL, ri->ri_type, ri->ri_name);\n    if (0 <= group_id) {\n        /* ensure all variables are deregistered before we dlclose the component */\n        mca_base_var_group_deregister (group_id);\n    }\n\n    /* Close the component (and potentially unload it from memory */\n    if (ri->ri_dlhandle) {\n        opal_dl_close(ri->ri_dlhandle);\n        ri->ri_dlhandle = NULL;\n    }\n}\n#endif\n\n#if OPAL_HAVE_DL_SUPPORT\nstatic mca_base_component_repository_item_t *find_component (const char *type, const char *name)\n{\n    mca_base_component_repository_item_t *ri;\n    opal_list_t *component_list;\n    int ret;\n\n    ret = opal_hash_table_get_value_ptr (&mca_base_component_repository, type,\n                                         strlen (type), (void **) &component_list);\n    if (OPAL_SUCCESS != ret) {\n        /* component does not exist in the repository */\n        return NULL;\n    }\n\n    OPAL_LIST_FOREACH(ri, component_list, mca_base_component_repository_item_t) {\n        if (0 == strcmp (ri->ri_name, name)) {\n            return ri;\n        }\n    }\n\n    return NULL;\n}\n#endif\n\nvoid mca_base_component_repository_release(const mca_base_component_t *component)\n{\n#if OPAL_HAVE_DL_SUPPORT\n    mca_base_component_repository_item_t *ri;\n\n    ri = find_component (component->mca_type_name, component->mca_component_name);\n    if (NULL != ri && !(--ri->ri_refcnt)) {\n        mca_base_component_repository_release_internal (ri);\n    }\n#endif\n}\n\nint mca_base_component_repository_retain_component (const char *type, const char *name)\n{\n#if OPAL_HAVE_DL_SUPPORT\n    mca_base_component_repository_item_t *ri = find_component(type, name);\n\n    if (NULL != ri) {\n        ++ri->ri_refcnt;\n        return OPAL_SUCCESS;\n    }\n\n    return OPAL_ERR_NOT_FOUND;\n#else\n    return OPAL_ERR_NOT_SUPPORTED;\n#endif\n}\n\nint mca_base_component_repository_open (mca_base_framework_t *framework,\n                                        mca_base_component_repository_item_t *ri)\n{\n#if OPAL_HAVE_DL_SUPPORT\n    mca_base_component_t *component_struct;\n    mca_base_component_list_item_t *mitem = NULL;\n    char *struct_name = NULL;\n    int vl, ret;\n\n    opal_output_verbose(MCA_BASE_VERBOSE_INFO, 0, \"mca_base_component_repository_open: examining dynamic \"\n                        \"%s MCA component \\\"%s\\\" at path %s\", ri->ri_type, ri->ri_name, ri->ri_path);\n\n    vl = mca_base_component_show_load_errors ? MCA_BASE_VERBOSE_ERROR : MCA_BASE_VERBOSE_INFO;\n\n    /* Ensure that this component is not already loaded (should only happen\n       if it was statically loaded).  It's an error if it's already\n       loaded because we're evaluating this file -- not this component.\n       Hence, returning OPAL_ERR_PARAM indicates that the *file* failed\n       to load, not the component. */\n\n    OPAL_LIST_FOREACH(mitem, &framework->framework_components, mca_base_component_list_item_t) {\n        if (0 == strcmp(mitem->cli_component->mca_component_name, ri->ri_name)) {\n            opal_output_verbose (MCA_BASE_VERBOSE_INFO, 0, \"mca_base_component_repository_open: already loaded (ignored)\");\n            return OPAL_ERR_BAD_PARAM;\n        }\n    }\n\n    /* silence coverity issue (invalid free) */\n    mitem = NULL;\n\n    if (NULL != ri->ri_dlhandle) {\n        opal_output_verbose (MCA_BASE_VERBOSE_INFO, 0, \"mca_base_component_repository_open: already loaded. returning cached component\");\n        mitem = OBJ_NEW(mca_base_component_list_item_t);\n        if (NULL == mitem) {\n            return OPAL_ERR_OUT_OF_RESOURCE;\n        }\n\n        mitem->cli_component = ri->ri_component_struct;\n        opal_list_append (&framework->framework_components, &mitem->super);\n\n        return OPAL_SUCCESS;\n    }\n\n    if (0 != strcmp (ri->ri_type, framework->framework_name)) {\n        /* shouldn't happen. attempting to open a component belonging to\n         * another framework. if this happens it is likely a MCA base\n         * bug so assert */\n        assert (0);\n        return OPAL_ERR_NOT_SUPPORTED;\n    }\n\n    /* Now try to load the component */\n\n    char *err_msg = NULL;\n    if (OPAL_SUCCESS != opal_dl_open(ri->ri_path, true, false, &ri->ri_dlhandle, &err_msg)) {\n        if (NULL == err_msg) {\n            err_msg = \"opal_dl_open() error message was NULL!\";\n        }\n        /* Because libltdl erroneously says \"file not found\" for any\n           type of error -- which is especially misleading when the file\n           is actually there but cannot be opened for some other reason\n           (e.g., missing symbol) -- do some simple huersitics and if\n           the file [probably] does exist, print a slightly better error\n           message. */\n        if (0 == strcasecmp(\"file not found\", err_msg) &&\n            (file_exists(ri->ri_path, \"lo\") ||\n             file_exists(ri->ri_path, \"so\") ||\n             file_exists(ri->ri_path, \"dylib\") ||\n             file_exists(ri->ri_path, \"dll\"))) {\n            err_msg = \"perhaps a missing symbol, or compiled for a different version of Open MPI?\";\n        }\n        opal_output_verbose(vl, 0, \"mca_base_component_repository_open: unable to open %s: %s (ignored)\",\n                            ri->ri_base, err_msg);\n\n        if( mca_base_component_track_load_errors ) {\n            mca_base_failed_component_t *f_comp = OBJ_NEW(mca_base_failed_component_t);\n            f_comp->comp = ri;\n            opal_asprintf(&(f_comp->error_msg), \"%s\", err_msg);\n            opal_list_append(&framework->framework_failed_components, &f_comp->super);\n        }\n\n        return OPAL_ERR_BAD_PARAM;\n    }\n\n    /* Successfully opened the component; now find the public struct.\n       Malloc out enough space for it. */\n\n    do {\n        ret = opal_asprintf (&struct_name, \"mca_%s_%s_component\", ri->ri_type, ri->ri_name);\n        if (0 > ret) {\n            ret = OPAL_ERR_OUT_OF_RESOURCE;\n            break;\n        }\n\n        mitem = OBJ_NEW(mca_base_component_list_item_t);\n        if (NULL == mitem) {\n            ret = OPAL_ERR_OUT_OF_RESOURCE;\n            break;\n        }\n\n        err_msg = NULL;\n        ret = opal_dl_lookup(ri->ri_dlhandle, struct_name, (void**) &component_struct, &err_msg);\n        if (OPAL_SUCCESS != ret || NULL == component_struct) {\n            if (NULL == err_msg) {\n                err_msg = \"opal_dl_loookup() error message was NULL!\";\n            }\n            opal_output_verbose(vl, 0, \"mca_base_component_repository_open: \\\"%s\\\" does not appear to be a valid \"\n                                \"%s MCA dynamic component (ignored): %s. ret %d\", ri->ri_base, ri->ri_type, err_msg, ret);\n\n            ret = OPAL_ERR_BAD_PARAM;\n            break;\n        }\n\n        /* done with the structure name */\n        free (struct_name);\n        struct_name = NULL;\n\n        /* We found the public struct.  Make sure its MCA major.minor\n           version is the same as ours. TODO -- add checks for project version (from framework) */\n        if (!(MCA_BASE_VERSION_MAJOR == component_struct->mca_major_version &&\n              MCA_BASE_VERSION_MINOR == component_struct->mca_minor_version)) {\n            opal_output_verbose(vl, 0, \"mca_base_component_repository_open: %s \\\"%s\\\" uses an MCA interface that is \"\n                                \"not recognized (component MCA v%d.%d.%d != supported MCA v%d.%d.%d) -- ignored\",\n                                ri->ri_type, ri->ri_path, component_struct->mca_major_version,\n                                component_struct->mca_minor_version, component_struct->mca_release_version,\n                                MCA_BASE_VERSION_MAJOR, MCA_BASE_VERSION_MINOR, MCA_BASE_VERSION_RELEASE);\n            ret = OPAL_ERR_BAD_PARAM;\n            break;\n        }\n\n        /* Also check that the component struct framework and component\n           names match the expected names from the filename */\n        if (0 != strcmp(component_struct->mca_type_name, ri->ri_type) ||\n            0 != strcmp(component_struct->mca_component_name, ri->ri_name)) {\n            opal_output_verbose(vl, 0, \"Component file data does not match filename: %s (%s / %s) != %s %s -- ignored\",\n                                ri->ri_path, ri->ri_type, ri->ri_name,\n                                component_struct->mca_type_name,\n                                component_struct->mca_component_name);\n            ret = OPAL_ERR_BAD_PARAM;\n            break;\n        }\n\n        /* Alles gut.  Save the component struct, and register this\n           component to be closed later. */\n\n        ri->ri_component_struct = mitem->cli_component = component_struct;\n        ri->ri_refcnt = 1;\n        opal_list_append(&framework->framework_components, &mitem->super);\n\n        opal_output_verbose (MCA_BASE_VERBOSE_INFO, 0, \"mca_base_component_repository_open: opened dynamic %s MCA \"\n                             \"component \\\"%s\\\"\", ri->ri_type, ri->ri_name);\n\n        return OPAL_SUCCESS;\n    } while (0);\n\n    if (mitem) {\n        OBJ_RELEASE(mitem);\n    }\n\n    if (struct_name) {\n        free (struct_name);\n    }\n\n    opal_dl_close (ri->ri_dlhandle);\n    ri->ri_dlhandle = NULL;\n\n    return ret;\n#else\n\n    /* no dlopen support */\n    return OPAL_ERR_NOT_SUPPORTED;\n#endif\n}\n\n/*\n * Finalize the repository -- close everything that's still open.\n */\nvoid mca_base_component_repository_finalize(void)\n{\n    if (!initialized) {\n        return;\n    }\n\n    initialized = false;\n\n#if OPAL_HAVE_DL_SUPPORT\n    opal_list_t *component_list;\n    void *node, *key;\n    size_t key_size;\n    int ret;\n\n    ret = opal_hash_table_get_first_key_ptr (&mca_base_component_repository, &key, &key_size,\n                                             (void **) &component_list, &node);\n    while (OPAL_SUCCESS == ret) {\n        OPAL_LIST_RELEASE(component_list);\n        ret = opal_hash_table_get_next_key_ptr (&mca_base_component_repository, &key,\n                                                &key_size, (void **) &component_list,\n                                                node, &node);\n    }\n\n    (void) mca_base_framework_close(&opal_dl_base_framework);\n    OBJ_DESTRUCT(&mca_base_component_repository);\n#endif\n}\n\n#if OPAL_HAVE_DL_SUPPORT\n\n/*\n * Basic sentinel values, and construct the inner list\n */\nstatic void ri_constructor (mca_base_component_repository_item_t *ri)\n{\n    memset(ri->ri_type, 0, sizeof(ri->ri_type));\n    ri->ri_dlhandle = NULL;\n    ri->ri_component_struct = NULL;\n    ri->ri_path = NULL;\n}\n\n\n/*\n * Close a component\n */\nstatic void ri_destructor (mca_base_component_repository_item_t *ri)\n{\n    /* dlclose the component if it is still open */\n    mca_base_component_repository_release_internal (ri);\n\n    /* It should be obvious, but I'll state it anyway because it bit me\n       during debugging: after the dlclose(), the mca_base_component_t\n       pointer is no longer valid because it has [potentially] been\n       unloaded from memory.  So don't try to use it.  :-) */\n\n    if (ri->ri_path) {\n        free (ri->ri_path);\n    }\n\n    if (ri->ri_base) {\n        free (ri->ri_base);\n    }\n}\n\n#endif /* OPAL_HAVE_DL_SUPPORT */\n",
        "/tmp/vanessa/spack-stage/spack-stage-openmpi-master-qcrm7qmgqutvsby2zcmdb57s22lzfq65/spack-src/opal/mca/base/mca_base_open.c": "/* -*- Mode: C; c-basic-offset:4 ; indent-tabs-mode:nil -*- */\n/*\n * Copyright (c) 2004-2005 The Trustees of Indiana University and Indiana\n *                         University Research and Technology\n *                         Corporation.  All rights reserved.\n * Copyright (c) 2004-2017 The University of Tennessee and The University\n *                         of Tennessee Research Foundation.  All rights\n *                         reserved.\n * Copyright (c) 2004-2005 High Performance Computing Center Stuttgart,\n *                         University of Stuttgart.  All rights reserved.\n * Copyright (c) 2004-2005 The Regents of the University of California.\n *                         All rights reserved.\n * Copyright (c) 2011-2017 Cisco Systems, Inc.  All rights reserved\n * Copyright (c) 2015      Los Alamos National Security, LLC. All rights\n *                         reserved.\n * Copyright (c) 2017      IBM Corporation.  All rights reserved.\n * Copyright (c) 2018      Amazon.com, Inc. or its affiliates.  All Rights reserved.\n * Copyright (c) 2018-2019 Triad National Security, LLC. All rights\n *                         reserved.\n * $COPYRIGHT$\n *\n * Additional copyrights may follow\n *\n * $HEADER$\n */\n\n#include \"opal_config.h\"\n\n#include <stdio.h>\n#include <string.h>\n#ifdef HAVE_SYSLOG_H\n#include <syslog.h>\n#endif\n#ifdef HAVE_UNISTD_H\n#include <unistd.h>\n#endif\n\n#include \"opal/runtime/opal.h\"\n#include \"opal/mca/installdirs/installdirs.h\"\n#include \"opal/util/output.h\"\n#include \"opal/util/printf.h\"\n#include \"opal/mca/mca.h\"\n#include \"opal/mca/base/base.h\"\n#include \"opal/mca/base/mca_base_component_repository.h\"\n#include \"opal/constants.h\"\n#include \"opal/util/opal_environ.h\"\n\n/*\n * Public variables\n */\nchar *mca_base_component_path = NULL;\nint mca_base_opened = 0;\nchar *mca_base_system_default_path = NULL;\nchar *mca_base_user_default_path = NULL;\nbool mca_base_component_show_load_errors =\n    (bool) OPAL_SHOW_LOAD_ERRORS_DEFAULT;\nbool mca_base_component_track_load_errors = false;\nbool mca_base_component_disable_dlopen = false;\n\nstatic char *mca_base_verbose = NULL;\n\n/*\n * Private functions\n */\nstatic void set_defaults(opal_output_stream_t *lds);\nstatic void parse_verbose(char *e, opal_output_stream_t *lds);\n\n\n/*\n * Main MCA initialization.\n */\nint mca_base_open(void)\n{\n    char *value;\n    opal_output_stream_t lds;\n    const char *hostname;\n    int var_id;\n\n    if (mca_base_opened++) {\n        return OPAL_SUCCESS;\n    }\n\n    /* define the system and user default paths */\n#if OPAL_WANT_HOME_CONFIG_FILES\n    mca_base_system_default_path = strdup(opal_install_dirs.opallibdir);\n    opal_asprintf(&mca_base_user_default_path, \"%s\"OPAL_PATH_SEP\".openmpi\"OPAL_PATH_SEP\"components\", opal_home_directory());\n#else\n    opal_asprintf(&mca_base_system_default_path, \"%s\", opal_install_dirs.opallibdir);\n#endif\n\n    /* see if the user wants to override the defaults */\n    if (NULL == mca_base_user_default_path) {\n        value = strdup(mca_base_system_default_path);\n    } else {\n        opal_asprintf(&value, \"%s%c%s\", mca_base_system_default_path,\n                 OPAL_ENV_SEP, mca_base_user_default_path);\n    }\n\n    mca_base_component_path = value;\n    var_id = mca_base_var_register(\"opal\", \"mca\", \"base\", \"component_path\",\n                                   \"Path where to look for additional components\",\n                                   MCA_BASE_VAR_TYPE_STRING, NULL, 0, 0,\n                                   OPAL_INFO_LVL_9,\n                                   MCA_BASE_VAR_SCOPE_READONLY,\n                                   &mca_base_component_path);\n    (void) mca_base_var_register_synonym(var_id, \"opal\", \"mca\", NULL, \"component_path\",\n                                         MCA_BASE_VAR_SYN_FLAG_DEPRECATED);\n    free(value);\n\n    mca_base_component_show_load_errors =\n        (bool) OPAL_SHOW_LOAD_ERRORS_DEFAULT;\n    var_id = mca_base_var_register(\"opal\", \"mca\", \"base\", \"component_show_load_errors\",\n                                   \"Whether to show errors for components that failed to load or not\",\n                                   MCA_BASE_VAR_TYPE_BOOL, NULL, 0, 0,\n                                   OPAL_INFO_LVL_9,\n                                   MCA_BASE_VAR_SCOPE_READONLY,\n                                   &mca_base_component_show_load_errors);\n    (void) mca_base_var_register_synonym(var_id, \"opal\", \"mca\", NULL, \"component_show_load_errors\",\n                                         MCA_BASE_VAR_SYN_FLAG_DEPRECATED);\n\n    mca_base_component_track_load_errors = false;\n    var_id = mca_base_var_register(\"opal\", \"mca\", \"base\", \"component_track_load_errors\",\n                                   \"Whether to track errors for components that failed to load or not\",\n                                   MCA_BASE_VAR_TYPE_BOOL, NULL, 0, 0,\n                                   OPAL_INFO_LVL_9,\n                                   MCA_BASE_VAR_SCOPE_READONLY,\n                                   &mca_base_component_track_load_errors);\n\n    mca_base_component_disable_dlopen = false;\n    var_id = mca_base_var_register(\"opal\", \"mca\", \"base\", \"component_disable_dlopen\",\n                                   \"Whether to attempt to disable opening dynamic components or not\",\n                                   MCA_BASE_VAR_TYPE_BOOL, NULL, 0, 0,\n                                   OPAL_INFO_LVL_9,\n                                   MCA_BASE_VAR_SCOPE_READONLY,\n                                   &mca_base_component_disable_dlopen);\n    (void) mca_base_var_register_synonym(var_id, \"opal\", \"mca\", NULL, \"component_disable_dlopen\",\n                                         MCA_BASE_VAR_SYN_FLAG_DEPRECATED);\n\n    /* What verbosity level do we want for the default 0 stream? */\n    char *str = getenv(\"OPAL_OUTPUT_INTERNAL_TO_STDOUT\");\n    if (NULL != str && str[0] == '1') {\n        mca_base_verbose = \"stdout\";\n    }\n    else {\n        mca_base_verbose = \"stderr\";\n    }\n    var_id = mca_base_var_register(\"opal\", \"mca\", \"base\", \"verbose\",\n                                   \"Specifies where the default error output stream goes (this is separate from distinct help messages).  Accepts a comma-delimited list of: stderr, stdout, syslog, syslogpri:<notice|info|debug>, syslogid:<str> (where str is the prefix string for all syslog notices), file[:filename] (if filename is not specified, a default filename is used), fileappend (if not specified, the file is opened for truncation), level[:N] (if specified, integer verbose level; otherwise, 0 is implied)\",\n                                   MCA_BASE_VAR_TYPE_STRING, NULL, 0, 0,\n                                   OPAL_INFO_LVL_9,\n                                   MCA_BASE_VAR_SCOPE_READONLY,\n                                   &mca_base_verbose);\n    (void) mca_base_var_register_synonym(var_id, \"opal\", \"mca\", NULL, \"verbose\",\n                                         MCA_BASE_VAR_SYN_FLAG_DEPRECATED);\n\n    memset(&lds, 0, sizeof(lds));\n    if (NULL != mca_base_verbose) {\n        parse_verbose(mca_base_verbose, &lds);\n    } else {\n        set_defaults(&lds);\n    }\n    hostname = opal_gethostname();\n    opal_asprintf(&lds.lds_prefix, \"[%s:%05d] \", hostname, getpid());\n    opal_output_reopen(0, &lds);\n    opal_output_verbose (MCA_BASE_VERBOSE_COMPONENT, 0, \"mca: base: opening components\");\n    free(lds.lds_prefix);\n\n    /* Open up the component repository */\n\n    opal_finalize_register_cleanup (mca_base_close);\n\n    return mca_base_component_repository_init();\n}\n\n\n/*\n * Set sane default values for the lds\n */\nstatic void set_defaults(opal_output_stream_t *lds)\n{\n\n    /* Load up defaults */\n\n    OBJ_CONSTRUCT(lds, opal_output_stream_t);\n#if defined(HAVE_SYSLOG) && defined(HAVE_SYSLOG_H)\n    lds->lds_syslog_priority = LOG_INFO;\n    lds->lds_syslog_ident = \"ompi\";\n#endif\n    lds->lds_want_stderr = true;\n}\n\n\n/*\n * Parse the value of an environment variable describing verbosity\n */\nstatic void parse_verbose(char *e, opal_output_stream_t *lds)\n{\n    char *edup;\n    char *ptr, *next;\n    bool have_output = false;\n\n    if (NULL == e) {\n        return;\n    }\n\n    edup = strdup(e);\n    ptr = edup;\n\n    /* Now parse the environment variable */\n\n    while (NULL != ptr && strlen(ptr) > 0) {\n        next = strchr(ptr, ',');\n        if (NULL != next) {\n            *next = '\\0';\n        }\n\n        if (0 == strcasecmp(ptr, \"syslog\")) {\n#if defined(HAVE_SYSLOG) && defined(HAVE_SYSLOG_H)\n            lds->lds_want_syslog = true;\n            have_output = true;\n#else\n            opal_output(0, \"syslog support requested but not available on this system\");\n#endif  /* defined(HAVE_SYSLOG) && defined(HAVE_SYSLOG_H) */\n        }\n        else if (strncasecmp(ptr, \"syslogpri:\", 10) == 0) {\n#if defined(HAVE_SYSLOG) && defined(HAVE_SYSLOG_H)\n            lds->lds_want_syslog = true;\n            have_output = true;\n            if (strcasecmp(ptr + 10, \"notice\") == 0)\n                lds->lds_syslog_priority = LOG_NOTICE;\n            else if (strcasecmp(ptr + 10, \"INFO\") == 0)\n                lds->lds_syslog_priority = LOG_INFO;\n            else if (strcasecmp(ptr + 10, \"DEBUG\") == 0)\n                lds->lds_syslog_priority = LOG_DEBUG;\n#else\n            opal_output(0, \"syslog support requested but not available on this system\");\n#endif  /* defined(HAVE_SYSLOG) && defined(HAVE_SYSLOG_H) */\n        } else if (strncasecmp(ptr, \"syslogid:\", 9) == 0) {\n#if defined(HAVE_SYSLOG) && defined(HAVE_SYSLOG_H)\n            lds->lds_want_syslog = true;\n            lds->lds_syslog_ident = ptr + 9;\n#else\n            opal_output(0, \"syslog support requested but not available on this system\");\n#endif  /* defined(HAVE_SYSLOG) && defined(HAVE_SYSLOG_H) */\n        }\n\n        else if (strcasecmp(ptr, \"stdout\") == 0) {\n            lds->lds_want_stdout = true;\n            have_output = true;\n        } else if (strcasecmp(ptr, \"stderr\") == 0) {\n            lds->lds_want_stderr = true;\n            have_output = true;\n        }\n\n        else if (strcasecmp(ptr, \"file\") == 0 || strcasecmp(ptr, \"file:\") == 0) {\n            lds->lds_want_file = true;\n            have_output = true;\n        } else if (strncasecmp(ptr, \"file:\", 5) == 0) {\n            lds->lds_want_file = true;\n            lds->lds_file_suffix = strdup(ptr + 5);\n            have_output = true;\n        } else if (strcasecmp(ptr, \"fileappend\") == 0) {\n            lds->lds_want_file = true;\n            lds->lds_want_file_append = 1;\n            have_output = true;\n        }\n\n        else if (strncasecmp(ptr, \"level\", 5) == 0) {\n            lds->lds_verbose_level = 0;\n            if (ptr[5] == OPAL_ENV_SEP)\n                lds->lds_verbose_level = atoi(ptr + 6);\n        }\n\n        if (NULL == next) {\n            break;\n        }\n        ptr = next + 1;\n    }\n\n    /* If we didn't get an output, default to stderr */\n\n    if (!have_output) {\n        lds->lds_want_stderr = true;\n    }\n\n    /* All done */\n\n    free(edup);\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-openmpi-master-qcrm7qmgqutvsby2zcmdb57s22lzfq65/spack-src/opal/mca/base/mca_base_component_find.c": "/* -*- Mode: C; c-basic-offset:4 ; indent-tabs-mode:nil -*- */\n/*\n * Copyright (c) 2004-2005 The Trustees of Indiana University and Indiana\n *                         University Research and Technology\n *                         Corporation.  All rights reserved.\n * Copyright (c) 2004-2007 The University of Tennessee and The University\n *                         of Tennessee Research Foundation.  All rights\n *                         reserved.\n * Copyright (c) 2004-2005 High Performance Computing Center Stuttgart,\n *                         University of Stuttgart.  All rights reserved.\n * Copyright (c) 2004-2005 The Regents of the University of California.\n *                         All rights reserved.\n * Copyright (c) 2008-2015 Cisco Systems, Inc.  All rights reserved.\n * Copyright (c) 2008      Sun Microsystems, Inc.  All rights reserved.\n * Copyright (c) 2015      Research Organization for Information Science\n *                         and Technology (RIST). All rights reserved.\n * Copyright (c) 2014-2015 Los Alamos National Security, LLC. All rights\n *                         reserved.\n * Copyright (c) 2019      Triad National Security, LLC. All rights\n *                         reserved.\n * Copyright (c) 2020      Google, LLC. All rights reserved.\n * $COPYRIGHT$\n *\n * Additional copyrights may follow\n *\n * $HEADER$\n */\n\n#include \"opal_config.h\"\n\n#include <stdio.h>\n#include <string.h>\n#include <ctype.h>\n#include <stdlib.h>\n#ifdef HAVE_SYS_TYPES_H\n#include <sys/types.h>\n#endif\n#ifdef HAVE_SYS_STAT_H\n#include <sys/stat.h>\n#endif\n#ifdef HAVE_UNISTD_H\n#include <unistd.h>\n#endif\n#ifdef HAVE_SYS_PARAM_H\n#include <sys/param.h>\n#endif\n#ifdef HAVE_NETDB_H\n#include <netdb.h>\n#endif\n\n#include \"opal/runtime/opal.h\"\n#include \"opal/mca/installdirs/installdirs.h\"\n#include \"opal/util/opal_environ.h\"\n#include \"opal/util/output.h\"\n#include \"opal/util/argv.h\"\n#include \"opal/util/show_help.h\"\n#include \"opal/class/opal_list.h\"\n#include \"opal/mca/mca.h\"\n#include \"opal/mca/base/base.h\"\n#include \"opal/mca/base/mca_base_alias.h\"\n#include \"opal/mca/base/mca_base_component_repository.h\"\n#include \"opal/constants.h\"\n#include \"opal/mca/dl/base/base.h\"\n\n#if OPAL_HAVE_DL_SUPPORT\n/*\n * Private functions\n */\nstatic void find_dyn_components(const char *path, mca_base_framework_t *framework,\n                                const char **names, bool include_mode);\n\n#endif /* OPAL_HAVE_DL_SUPPORT */\n\nstatic int component_find_check (mca_base_framework_t *framework, char **requested_component_names);\n\n/*\n * Dummy structure for casting for open_only logic\n */\nstruct mca_base_open_only_dummy_component_t {\n    /** MCA base component */\n    mca_base_component_t version;\n    /** MCA base data */\n    mca_base_component_data_t data;\n};\ntypedef struct mca_base_open_only_dummy_component_t mca_base_open_only_dummy_component_t;\n\nstatic char negate[] = \"^\";\n\nstatic bool use_component(const mca_base_framework_t *framework,\n                          const bool include_mode,\n                          const char **requested_component_names,\n                          const char *component_name);\n\n\n/*\n * Function to find as many components of a given type as possible.  This\n * includes statically-linked in components as well as opening up a\n * directory and looking for shared-library MCA components of the\n * appropriate type (load them if available).\n *\n * Return one consolidated array of (mca_base_component_t*) pointing to all\n * available components.\n */\nint mca_base_component_find (const char *directory, mca_base_framework_t *framework,\n                             bool ignore_requested, bool open_dso_components)\n{\n    const mca_base_component_t **static_components = framework->framework_static_components;\n    char **requested_component_names = NULL;\n    mca_base_component_list_item_t *cli;\n    bool include_mode = true;\n    int ret;\n\n    if (!ignore_requested) {\n        ret = mca_base_component_parse_requested (framework->framework_selection, &include_mode,\n                                                  &requested_component_names);\n        if (OPAL_SUCCESS != ret) {\n            return ret;\n        }\n    }\n\n    /* Find all the components that were statically linked in */\n    if (static_components) {\n        for (int i = 0 ; NULL != static_components[i]; ++i) {\n            if ( use_component(framework, include_mode,\n                               (const char**)requested_component_names,\n                               static_components[i]->mca_component_name) ) {\n                cli = OBJ_NEW(mca_base_component_list_item_t);\n                if (NULL == cli) {\n                    ret = OPAL_ERR_OUT_OF_RESOURCE;\n                    goto component_find_out;\n                }\n                cli->cli_component = static_components[i];\n                opal_list_append(&framework->framework_components, (opal_list_item_t *) cli);\n            }\n        }\n    }\n\n#if OPAL_HAVE_DL_SUPPORT\n    /* Find any available dynamic components in the specified directory */\n    if (open_dso_components && !mca_base_component_disable_dlopen) {\n        find_dyn_components(directory, framework, (const char**)requested_component_names,\n                            include_mode);\n    } else {\n        opal_output_verbose (MCA_BASE_VERBOSE_INFO, 0,\n                            \"mca: base: component_find: dso loading for %s MCA components disabled\",\n                            framework->framework_name);\n    }\n#endif\n\n    if (include_mode) {\n        ret = component_find_check (framework, requested_component_names);\n    } else {\n        ret = OPAL_SUCCESS;\n    }\n\ncomponent_find_out:\n\n    if (NULL != requested_component_names) {\n        opal_argv_free(requested_component_names);\n    }\n\n    /* All done */\n\n    return ret;\n}\n\nint mca_base_component_find_finalize(void)\n{\n    return OPAL_SUCCESS;\n}\n\nint mca_base_components_filter (mca_base_framework_t *framework, uint32_t filter_flags)\n{\n    opal_list_t *components = &framework->framework_components;\n    int output_id = framework->framework_output;\n    mca_base_component_list_item_t *cli, *next;\n    char **requested_component_names = NULL;\n    bool include_mode, can_use;\n    int ret;\n\n    assert (NULL != components);\n\n    if (0 == filter_flags && NULL == framework->framework_selection) {\n        return OPAL_SUCCESS;\n    }\n\n    ret = mca_base_component_parse_requested (framework->framework_selection, &include_mode,\n                                              &requested_component_names);\n    if (OPAL_SUCCESS != ret) {\n        return ret;\n    }\n\n    OPAL_LIST_FOREACH_SAFE(cli, next, components, mca_base_component_list_item_t) {\n        const mca_base_component_t *component = cli->cli_component;\n        mca_base_open_only_dummy_component_t *dummy =\n            (mca_base_open_only_dummy_component_t *) cli->cli_component;\n\n        can_use = use_component (framework, include_mode, (const char **) requested_component_names,\n                                 cli->cli_component->mca_component_name);\n\n        if (!can_use || (filter_flags & dummy->data.param_field) != filter_flags) {\n            if (can_use && (filter_flags & MCA_BASE_METADATA_PARAM_CHECKPOINT) &&\n                !(MCA_BASE_METADATA_PARAM_CHECKPOINT & dummy->data.param_field)) {\n                opal_output_verbose (MCA_BASE_VERBOSE_COMPONENT, output_id,\n                                     \"mca: base: components_filter: \"\n                                     \"(%s) Component %s is *NOT* Checkpointable - Disabled\",\n                                     component->reserved,\n                                     component->mca_component_name);\n            }\n\n            opal_list_remove_item (components, &cli->super);\n\n            mca_base_component_unload (component, output_id);\n\n            OBJ_RELEASE(cli);\n        } else if (filter_flags & MCA_BASE_METADATA_PARAM_CHECKPOINT) {\n            opal_output_verbose (MCA_BASE_VERBOSE_COMPONENT, output_id,\n                                 \"mca: base: components_filter: \"\n                                 \"(%s) Component %s is Checkpointable\",\n                                 component->reserved,\n                                 component->mca_component_name);\n        }\n    }\n\n    if (include_mode) {\n        ret = component_find_check (framework, requested_component_names);\n    } else {\n        ret = OPAL_SUCCESS;\n    }\n\n    if (NULL != requested_component_names) {\n        opal_argv_free (requested_component_names);\n    }\n\n    return ret;\n}\n\n#if OPAL_HAVE_DL_SUPPORT\n\n/*\n * Open up all directories in a given path and search for components of\n * the specified type (and possibly of a given name).\n *\n * Note that we use our own path iteration functionality because we\n * need to look at companion .ompi_info files in the same directory as\n * the library to generate dependencies, etc.\n */\nstatic void find_dyn_components(const char *path, mca_base_framework_t *framework,\n                                const char **names, bool include_mode)\n{\n    mca_base_component_repository_item_t *ri;\n    opal_list_t *dy_components;\n    int ret;\n\n    if (NULL != path) {\n        ret = mca_base_component_repository_add (path);\n        if (OPAL_SUCCESS != ret) {\n            return;\n        }\n    }\n\n    ret = mca_base_component_repository_get_components (framework, &dy_components);\n    if (OPAL_SUCCESS != ret) {\n        return;\n    }\n\n    /* Iterate through the repository and find components that can be included */\n    OPAL_LIST_FOREACH(ri, dy_components, mca_base_component_repository_item_t) {\n        if (use_component(framework, include_mode, names, ri->ri_name)) {\n            mca_base_component_repository_open (framework, ri);\n        }\n    }\n}\n\n#endif /* OPAL_HAVE_DL_SUPPORT */\n\nstatic bool component_in_list (const char **requested_component_names,\n                               const char *component_name)\n{\n    for (int i = 0 ; requested_component_names[i] ; ++i) {\n        if (strcmp(component_name, requested_component_names[i]) == 0) {\n            return true;\n        }\n    }\n\n    return false;\n}\n\nstatic bool use_component(const mca_base_framework_t *framework,\n                          const bool include_mode,\n                          const char **requested_component_names,\n                          const char *component_name)\n{\n    /*\n     * If no selection is specified then we use all components\n     * we can find.\n     */\n    if (NULL == requested_component_names) {\n        return true;\n    }\n\n    bool found = component_in_list (requested_component_names, component_name);\n\n    if (!found) {\n        const mca_base_alias_t *alias = mca_base_alias_lookup (framework->framework_project,\n                                                               framework->framework_name, component_name);\n        if (alias) {\n            OPAL_LIST_FOREACH_DECL(alias_item, &alias->component_aliases, mca_base_alias_item_t) {\n                found = component_in_list (requested_component_names, alias_item->component_alias);\n                if (found) {\n                    break;\n                }\n            }\n        }\n    }\n\n    /*\n     * include_mode  found |   use\n     * --------------------+------\n     *            0      0 |  true\n     *            0      1 | false\n     *            1      0 | false\n     *            1      1 |  true\n     *\n     * -> inverted xor\n     * As xor is a binary operator let's implement it manually before\n     * a compiler screws it up.\n     */\n\n    return (include_mode && found) || !(include_mode || found);\n}\n\n/* Ensure that *all* requested components exist.  Print a warning\n   and abort if they do not. */\nstatic int component_find_check (mca_base_framework_t *framework, char **requested_component_names)\n{\n    opal_list_t *components = &framework->framework_components;\n\n    if (NULL == requested_component_names) {\n        return OPAL_SUCCESS;\n    }\n\n    for (int i = 0 ; requested_component_names[i] ; ++i) {\n        bool found = false;\n\n        OPAL_LIST_FOREACH_DECL(cli, components, mca_base_component_list_item_t) {\n            if (0 == strcmp (requested_component_names[i], cli->cli_component->mca_component_name)) {\n                found = true;\n                break;\n            }\n\n            const mca_base_alias_t *alias = mca_base_alias_lookup (framework->framework_project,\n                                                                   framework->framework_name,\n                                                                   cli->cli_component->mca_component_name);\n            if (alias) {\n                OPAL_LIST_FOREACH_DECL(alias_item, &alias->component_aliases, mca_base_alias_item_t) {\n                    if (0 == strcmp (requested_component_names[i], alias_item->component_alias)) {\n                        found = true;\n                        break;\n                    }\n                }\n                if (found) {\n                    break;\n                }\n            }\n        }\n\n        if (!found) {\n            const char *h;\n            h = opal_gethostname();\n            opal_show_help(\"help-mca-base.txt\",\n                           \"find-available:not-valid\", true,\n                           h, framework->framework_name, requested_component_names[i]);\n            return OPAL_ERR_NOT_FOUND;\n        }\n    }\n\n    return OPAL_SUCCESS;\n}\n\nint mca_base_component_parse_requested (const char *requested, bool *include_mode,\n                                        char ***requested_component_names)\n{\n    const char *requested_orig = requested;\n\n    *requested_component_names = NULL;\n    *include_mode = true;\n\n    /* See if the user requested anything */\n    if (NULL == requested || 0 == strlen (requested)) {\n        return OPAL_SUCCESS;\n    }\n\n    /* Are we including or excluding?  We only allow the negate\n       character to be the *first* character of the value (but be nice\n       and allow any number of negate characters in the beginning). */\n    *include_mode = requested[0] != negate[0];\n\n    /* skip over all negate symbols at the beginning */\n    requested += strspn (requested, negate);\n\n    /* Double check to ensure that the user did not specify the negate\n       character anywhere else in the value. */\n    if (NULL != strstr (requested, negate)) {\n        opal_show_help(\"help-mca-base.txt\",\n                       \"framework-param:too-many-negates\",\n                       true, requested_orig);\n        return OPAL_ERROR;\n    }\n\n    /* Split up the value into individual component names */\n    *requested_component_names = opal_argv_split(requested, ',');\n\n    /* All done */\n    return OPAL_SUCCESS;\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-openmpi-master-qcrm7qmgqutvsby2zcmdb57s22lzfq65/spack-src/opal/mca/crs/self/configure.m4": "# -*- shell-script -*-\n#\n# Copyright (c) 2004-2010 The Trustees of Indiana University.\n#                         All rights reserved.\n# Copyright (c) 2004-2005 The Trustees of the University of Tennessee.\n#                         All rights reserved.\n# Copyright (c) 2004-2005 High Performance Computing Center Stuttgart,\n#                         University of Stuttgart.  All rights reserved.\n# Copyright (c) 2004-2005 The Regents of the University of California.\n#                         All rights reserved.\n# Copyright (c) 2010      Cisco Systems, Inc.  All rights reserved.\n# $COPYRIGHT$\n#\n# Additional copyrights may follow\n#\n# $HEADER$\n#\n\n# MCA_crs_self_CONFIG([action-if-found], [action-if-not-found])\n# -----------------------------------------------------------\nAC_DEFUN([MCA_opal_crs_self_CONFIG],[\n    AC_CONFIG_FILES([opal/mca/crs/self/Makefile])\n\n    # If we don't want FT, don't compile this component\n    AS_IF([test \"$opal_want_ft_cr\" = \"1\"],\n        [crs_self_good=\"yes\"],\n        [crs_self_good=\"no\"])\n\n    # We need the dlfcn.h so we can access dlsym and friends\n    AS_IF([test \"$crs_self_good\" = \"yes\"],\n        [AC_CHECK_HEADER([dlfcn.h],\n                         [crs_self_good=\"yes\"],\n                         [crs_self_good=\"no\"])])\n\n    # If they did not ask for dlopen support,\n    # they probably do not want this component either\n    AS_IF([test \"$crs_self_good\" = \"yes\"],\n        [AS_IF([test \"$OPAL_ENABLE_DLOPEN_SUPPORT\" = \"1\"],\n                [crs_self_good=\"yes\"],\n                [crs_self_good=\"no\"])])\n\n    AS_IF([test \"$crs_self_good\" = \"yes\"],\n        [$1],\n        [$2])\n\n])dnl\n",
        "/tmp/vanessa/spack-stage/spack-stage-openmpi-master-qcrm7qmgqutvsby2zcmdb57s22lzfq65/spack-src/opal/mca/crs/self/crs_self_module.c": "/*\n * Copyright (c) 2004-2010 The Trustees of Indiana University.\n *                         All rights reserved.\n * Copyright (c) 2004-2005 The Trustees of the University of Tennessee.\n *                         All rights reserved.\n * Copyright (c) 2004-2005 High Performance Computing Center Stuttgart,\n *                         University of Stuttgart.  All rights reserved.\n * Copyright (c) 2004-2005 The Regents of the University of California.\n *                         All rights reserved.\n * Copyright (c) 2007      Los Alamos National Security, LLC.  All rights\n *                         reserved.\n * Copyright (c) 2007      Evergrid, Inc. All rights reserved.\n *\n * Copyright (c) 2018      Amazon.com, Inc. or its affiliates.  All Rights reserved.\n * $COPYRIGHT$\n *\n * Additional copyrights may follow\n *\n * $HEADER$\n */\n\n#include \"opal_config.h\"\n\n#include <sys/types.h>\n#ifdef HAVE_UNISTD_H\n#include <unistd.h>\n#endif  /* HAVE_UNISTD_H */\n#include <string.h>\n#ifdef HAVE_DLFCN_H\n#include <dlfcn.h>\n#endif\n\n#include \"opal/util/opal_environ.h\"\n#include \"opal/util/output.h\"\n#include \"opal/util/show_help.h\"\n#include \"opal/util/argv.h\"\n#include \"opal/util/opal_environ.h\"\n#include \"opal/util/printf.h\"\n\n#include \"opal/constants.h\"\n#include \"opal/mca/base/mca_base_var.h\"\n\n#include \"opal/mca/crs/crs.h\"\n#include \"opal/mca/crs/base/base.h\"\n#include \"opal/runtime/opal_cr.h\"\n\n#include \"crs_self.h\"\n\n/*\n * Self module\n */\nstatic opal_crs_base_module_t loc_module = {\n    /** Initialization Function */\n    opal_crs_self_module_init,\n    /** Finalization Function */\n    opal_crs_self_module_finalize,\n\n    /** Checkpoint interface */\n    opal_crs_self_checkpoint,\n\n    /** Restart Command Access */\n    opal_crs_self_restart,\n\n    /** Disable checkpoints */\n    opal_crs_self_disable_checkpoint,\n    /** Enable checkpoints */\n    opal_crs_self_enable_checkpoint,\n\n    /** Prelaunch */\n    opal_crs_self_prelaunch,\n\n    /** Register Thread */\n    opal_crs_self_reg_thread\n};\n\n/*\n * Snapshot structure\n */\nOBJ_CLASS_DECLARATION(opal_crs_self_snapshot_t);\n\nstruct opal_crs_self_snapshot_t {\n    /** Base CRS snapshot type */\n    opal_crs_base_snapshot_t super;\n    /** Command Line used to restart the app */\n    char * cmd_line;\n};\ntypedef struct opal_crs_self_snapshot_t opal_crs_self_snapshot_t;\n\nstatic void opal_crs_self_construct(opal_crs_self_snapshot_t *obj);\nstatic void opal_crs_self_destruct( opal_crs_self_snapshot_t *obj);\n\nOBJ_CLASS_INSTANCE(opal_crs_self_snapshot_t,\n                   opal_crs_base_snapshot_t,\n                   opal_crs_self_construct,\n                   opal_crs_self_destruct);\n\n\ntypedef void (*opal_crs_self_dlsym_dummy_fn_t)(void);\n\n/************************************\n * Locally Global vars & functions :)\n ************************************/\nstatic int crs_self_find_function(char *prefix, char *suffix,\n                                  opal_crs_self_dlsym_dummy_fn_t *fn_ptr);\n\nstatic int self_update_snapshot_metadata(opal_crs_self_snapshot_t *snapshot);\n\nstatic int opal_crs_self_restart_cmd(opal_crs_self_snapshot_t *snapshot, char **cmd);\nstatic int self_cold_start(opal_crs_self_snapshot_t *snapshot);\n\nvoid opal_crs_self_construct(opal_crs_self_snapshot_t *snapshot)\n{\n    snapshot->cmd_line = NULL;\n}\n\nvoid opal_crs_self_destruct( opal_crs_self_snapshot_t *snapshot)\n{\n    if(NULL != snapshot->cmd_line)\n        free(snapshot->cmd_line);\n}\n\nstatic int opal_crs_self_extract_callbacks(void);\n\n/*\n * MCA Functions\n */\nint opal_crs_self_component_query(mca_base_module_t **module, int *priority)\n{\n    int ret;\n\n    opal_output_verbose(10, mca_crs_self_component.super.output_handle,\n                        \"crs:self: component_query()\");\n\n    /*\n     * If this is a tool, then return a module with the lowest priority.\n     * This allows 'mpirun' to select the 'none' component since it has\n     * a priority higher than 0.\n     * But also allows 'opal-restart' to select this component if needed\n     * since it only ever requests that a specific component be opened\n     * that is defined in the snapshot metadata file.\n     */\n    if( opal_cr_is_tool ) {\n        *priority = 0;\n        *module = (mca_base_module_t *)&loc_module;\n        return OPAL_SUCCESS;\n    }\n\n    /*\n     * Extract the user level callbacks if they exist\n     */\n    ret = opal_crs_self_extract_callbacks();\n\n    if( OPAL_SUCCESS != ret ||\n        !mca_crs_self_component.can_checkpoint ) {\n        *priority = -1;\n        *module = NULL;\n        return OPAL_ERROR;\n    }\n    else {\n        *priority = mca_crs_self_component.super.priority;\n        *module = (mca_base_module_t *)&loc_module;\n        return OPAL_SUCCESS;\n    }\n}\n\nstatic int opal_crs_self_extract_callbacks(void)\n{\n    opal_crs_self_dlsym_dummy_fn_t loc_fn;\n\n    /*\n     * Find the function names\n     */\n    crs_self_find_function(mca_crs_self_component.prefix,\n                           SUFFIX_CHECKPOINT,\n                           &loc_fn);\n    mca_crs_self_component.ucb_checkpoint_fn = (opal_crs_self_checkpoint_callback_fn_t)loc_fn;\n\n    crs_self_find_function(mca_crs_self_component.prefix,\n                           SUFFIX_CONTINUE,\n                           &loc_fn);\n    mca_crs_self_component.ucb_continue_fn = (opal_crs_self_continue_callback_fn_t)loc_fn;\n\n    crs_self_find_function(mca_crs_self_component.prefix,\n                           SUFFIX_RESTART,\n                           &loc_fn);\n    mca_crs_self_component.ucb_restart_fn = (opal_crs_self_restart_callback_fn_t)loc_fn;\n\n    /*\n     * Sanity check\n     */\n    mca_crs_self_component.can_checkpoint = true;\n\n    if(NULL == mca_crs_self_component.ucb_checkpoint_fn) {\n        mca_crs_self_component.can_checkpoint = false;\n    }\n    if(NULL == mca_crs_self_component.ucb_continue_fn) {\n    }\n    if(NULL == mca_crs_self_component.ucb_restart_fn) {\n    }\n\n    return OPAL_SUCCESS;\n}\n\nint opal_crs_self_module_init(void)\n{\n    bool callback_matched = true;\n\n    opal_output_verbose(10, mca_crs_self_component.super.output_handle,\n                        \"crs:self: module_init()\");\n\n    if( opal_cr_is_tool ) {\n        return OPAL_SUCCESS;\n    }\n\n    /*\n     * Sanity check\n     */\n    if(NULL == mca_crs_self_component.ucb_checkpoint_fn) {\n        callback_matched = false;\n        mca_crs_self_component.can_checkpoint = false;\n    }\n    if(NULL == mca_crs_self_component.ucb_continue_fn) {\n        callback_matched = false;\n    }\n    if(NULL == mca_crs_self_component.ucb_restart_fn) {\n        callback_matched = false;\n    }\n    if( !callback_matched ) {\n        if( 1 <= mca_crs_self_component.super.verbose ) {\n            opal_show_help(\"help-opal-crs-self.txt\", \"self:no_callback\", false,\n                           \"checkpoint\", mca_crs_self_component.prefix, SUFFIX_CHECKPOINT,\n                           \"continue  \", mca_crs_self_component.prefix, SUFFIX_CONTINUE,\n                           \"restart   \", mca_crs_self_component.prefix, SUFFIX_RESTART,\n                           PREFIX_DEFAULT);\n        }\n    }\n\n    /*\n     * If the user requested that we do_restart, then call their callback\n     */\n    if(mca_crs_self_component.do_restart) {\n        opal_output_verbose(10, mca_crs_self_component.super.output_handle,\n                            \"crs:self: module_init: Call their restart function\");\n        if( NULL != mca_crs_self_component.ucb_restart_fn)\n            mca_crs_self_component.ucb_restart_fn();\n    }\n\n    return OPAL_SUCCESS;\n}\n\nint opal_crs_self_module_finalize(void)\n{\n    opal_output_verbose(10, mca_crs_self_component.super.output_handle,\n                        \"crs:self: module_finalize()\");\n\n    return OPAL_SUCCESS;\n}\n\n\nint opal_crs_self_checkpoint(pid_t pid,\n                             opal_crs_base_snapshot_t *base_snapshot,\n                             opal_crs_base_ckpt_options_t *options,\n                             opal_crs_state_type_t *state)\n{\n    opal_crs_self_snapshot_t *snapshot = OBJ_NEW(opal_crs_self_snapshot_t);\n    int ret, exit_status = OPAL_SUCCESS;\n    char * restart_cmd = NULL;\n\n    /*\n     * This function should never be called by a tool\n     */\n    if( opal_cr_is_tool ) {\n        return OPAL_ERR_NOT_SUPPORTED;\n    }\n\n    if( options->stop ) {\n        opal_output(0,\n                    \"crs:self: checkpoint(): Error: SIGSTOP Not currently supported!\");\n    }\n\n    /*\n     * Setup for snapshot directory creation\n     */\n    snapshot->super = *base_snapshot;\n#if 0\n    snapshot->super.snapshot_directory = strdup(base_snapshot->snapshot_directory);\n    snapshot->super.metadata_filename  = strdup(base_snapshot->metadata_filename);\n#endif\n\n    opal_output_verbose(10, mca_crs_self_component.super.output_handle,\n                        \"crs:self: checkpoint(%d, ---)\", pid);\n\n    if(!mca_crs_self_component.can_checkpoint) {\n        opal_show_help(\"help-opal-crs-self.txt\", \"self:ckpt_disabled\", false);\n        exit_status = OPAL_ERROR;\n        goto cleanup;\n    }\n\n    /*\n     * Update the snapshot metadata\n     */\n    snapshot->super.component_name = strdup(mca_crs_self_component.super.base_version.mca_component_name);\n    if( NULL == snapshot->super.metadata ) {\n        if (NULL == (snapshot->super.metadata = fopen(snapshot->super.metadata_filename, \"a\")) ) {\n            opal_output(mca_crs_self_component.super.output_handle,\n                        \"crs:self: checkpoint(): Error: Unable to open the file (%s)\",\n                        snapshot->super.metadata_filename);\n            exit_status = OPAL_ERROR;\n            goto cleanup;\n        }\n    }\n    fprintf(snapshot->super.metadata, \"%s%s\\n\", CRS_METADATA_COMP, snapshot->super.component_name);\n\n    /*\n     * Call the user callback function\n     */\n    if(NULL != mca_crs_self_component.ucb_checkpoint_fn) {\n        mca_crs_self_component.ucb_checkpoint_fn(&restart_cmd);\n    }\n\n    /*\n     * Save the restart command\n     */\n    if( NULL == restart_cmd) {\n        *state = OPAL_CRS_ERROR;\n        opal_show_help(\"help-opal-crs-self.txt\", \"self:no-restart-cmd\",\n                       true);\n        exit_status = OPAL_ERROR;\n        goto cleanup;\n    }\n    else {\n        snapshot->cmd_line = strdup(restart_cmd);\n\n        opal_output_verbose(10, mca_crs_self_component.super.output_handle,\n                            \"crs:self: checkpoint: Restart Command (%s)\", snapshot->cmd_line);\n    }\n\n    /*\n     * The best we can do is update the metadata file with the\n     * application argv and argc we started with.\n     */\n    if( OPAL_SUCCESS != (ret = self_update_snapshot_metadata(snapshot)) ) {\n        *state = OPAL_CRS_ERROR;\n        opal_output(mca_crs_self_component.super.output_handle,\n                    \"crs:self: checkpoint(): Error: Unable to update metadata for snapshot (%s).\",\n                    snapshot->super.metadata_filename);\n        exit_status = ret;\n        goto cleanup;\n    }\n\n\n    *state = OPAL_CRS_CONTINUE;\n\n    /*\n     * Call their continue routine for completeness\n     */\n    if(NULL != mca_crs_self_component.ucb_continue_fn) {\n        mca_crs_self_component.ucb_continue_fn();\n    }\n\n    base_snapshot = &(snapshot->super);\n\n cleanup:\n    if( NULL != restart_cmd) {\n        free(restart_cmd);\n        restart_cmd = NULL;\n    }\n\n    return exit_status;\n}\n\n/*\n * Notice that the user restart callback is not called here, but always from\n *  opal_init for the self module.\n */\nint opal_crs_self_restart(opal_crs_base_snapshot_t *base_snapshot, bool spawn_child, pid_t *child_pid)\n{\n    opal_crs_self_snapshot_t *snapshot = OBJ_NEW(opal_crs_self_snapshot_t);\n    char **cr_argv = NULL;\n    char * cr_cmd = NULL;\n    int ret;\n    int exit_status = OPAL_SUCCESS;\n    int status;\n\n    snapshot->super = *base_snapshot;\n\n    opal_output_verbose(10, mca_crs_self_component.super.output_handle,\n                        \"crs:self: restart(%d)\", spawn_child);\n\n    /*\n     * If we need to reconstruct the snapshot\n     */\n    if(snapshot->super.cold_start) {\n        if( OPAL_SUCCESS != (ret = self_cold_start(snapshot)) ){\n            exit_status = ret;\n            opal_output(mca_crs_self_component.super.output_handle,\n                        \"crs:blcr: blcr_restart: Unable to reconstruct the snapshot.\");\n            goto cleanup;\n        }\n    }\n\n    /*\n     * JJH: Check to make sure the application exists?\n     */\n\n    /*\n     * Get the restart command\n     */\n    if ( OPAL_SUCCESS != (ret = opal_crs_self_restart_cmd(snapshot, &cr_cmd)) ) {\n        exit_status = ret;\n        goto cleanup;\n    }\n    if ( NULL == (cr_argv = opal_argv_split(cr_cmd, ' ')) ) {\n        exit_status = OPAL_ERROR;\n        goto cleanup;\n    }\n\n\n    if (!spawn_child) {\n        opal_output_verbose(10, mca_crs_self_component.super.output_handle,\n                            \"crs:self: self_restart: SELF: exec :(%s, %s):\",\n                            strdup(cr_argv[0]),\n                            opal_argv_join(cr_argv, ' '));\n\n        status = execvp(strdup(cr_argv[0]), cr_argv);\n\n        if(status < 0) {\n            opal_output(mca_crs_self_component.super.output_handle,\n                        \"crs:self: self_restart: SELF: Child failed to execute :(%d):\", status);\n        }\n        opal_output(mca_crs_self_component.super.output_handle,\n                    \"crs:self: self_restart: SELF: execvp returned %d\", status);\n        exit_status = status;\n        goto cleanup;\n    }\n    else {\n        *child_pid = fork();\n        if( *child_pid == 0) {\n            /* Child Process */\n            opal_output_verbose(10, mca_crs_self_component.super.output_handle,\n                                \"crs:self: self_restart: CHILD: exec :(%s, %s):\",\n                                strdup(cr_argv[0]),\n                                opal_argv_join(cr_argv, ' '));\n\n            status = execvp(strdup(cr_argv[0]), cr_argv);\n\n            if(status < 0) {\n                opal_output(mca_crs_self_component.super.output_handle,\n                            \"crs:self: self_restart: CHILD: Child failed to execute :(%d):\", status);\n            }\n            opal_output(mca_crs_self_component.super.output_handle,\n                        \"crs:self: self_restart: CHILD: execvp returned %d\", status);\n            exit_status = status;\n            goto cleanup;\n        }\n        else if(*child_pid > 0) {\n            /* Parent is done once it is started. */\n            ;\n        }\n        else {\n            opal_output(mca_crs_self_component.super.output_handle,\n                        \"crs:self: self_restart: CHILD: fork failed :(%d):\", *child_pid);\n        }\n    }\n\n cleanup:\n    if( NULL != cr_cmd)\n        free(cr_cmd);\n    if( NULL != cr_argv)\n        opal_argv_free(cr_argv);\n\n    return exit_status;\n}\n\nint opal_crs_self_disable_checkpoint(void)\n{\n    /*\n     * This function should never be called by a tool\n     */\n    if( opal_cr_is_tool ) {\n        return OPAL_ERR_NOT_SUPPORTED;\n    }\n\n    opal_output_verbose(10, mca_crs_self_component.super.output_handle,\n                        \"crs:self: disable_checkpoint()\");\n\n    mca_crs_self_component.can_checkpoint = false;\n\n    return OPAL_SUCCESS;\n}\n\nint opal_crs_self_enable_checkpoint(void)\n{\n    /*\n     * This function should never be called by a tool\n     */\n    if( opal_cr_is_tool ) {\n        return OPAL_ERR_NOT_SUPPORTED;\n    }\n\n    opal_output_verbose(10, mca_crs_self_component.super.output_handle,\n                        \"crs:self: enable_checkpoint()\");\n\n    mca_crs_self_component.can_checkpoint = true;\n\n    return OPAL_SUCCESS;\n}\n\nint opal_crs_self_prelaunch(int32_t rank,\n                            char *base_snapshot_dir,\n                            char **app,\n                            char **cwd,\n                            char ***argv,\n                            char ***env)\n{\n    char * tmp_env_var = NULL;\n\n    /*\n     * This function should never be called by a tool\n     */\n    if( opal_cr_is_tool ) {\n        return OPAL_ERR_NOT_SUPPORTED;\n    }\n\n    (void) mca_base_var_env_name(\"opal_cr_is_tool\", &tmp_env_var);\n    opal_setenv(tmp_env_var,\n                \"0\", true, env);\n    free(tmp_env_var);\n    tmp_env_var = NULL;\n\n    return OPAL_SUCCESS;\n}\n\nint opal_crs_self_reg_thread(void)\n{\n    /*\n     * This function should never be called by a tool\n     */\n    if( opal_cr_is_tool ) {\n        return OPAL_ERR_NOT_SUPPORTED;\n    }\n\n    return OPAL_SUCCESS;\n}\n\n/******************\n * Local functions\n ******************/\nstatic int crs_self_find_function(char *prefix, char *suffix,\n                                  opal_crs_self_dlsym_dummy_fn_t *fn_ptr) {\n    char *func_to_find = NULL;\n\n    if( NULL == prefix || 0 >= strlen(prefix) ) {\n        opal_output(mca_crs_self_component.super.output_handle,\n                    \"crs:self: crs_self_find_function: Error: prefix is NULL or empty string!\");\n        *fn_ptr = NULL;\n        return OPAL_ERROR;\n    }\n    if( NULL == suffix || 0 >= strlen(suffix) ) {\n        opal_output(mca_crs_self_component.super.output_handle,\n                    \"crs:self: crs_self_find_function: Error: suffix is NULL or empty string!\");\n        *fn_ptr = NULL;\n        return OPAL_ERROR;\n    }\n\n    opal_output_verbose(10, mca_crs_self_component.super.output_handle,\n                        \"crs:self: crs_self_find_function(--, %s, %s)\",\n                        prefix, suffix);\n\n    opal_asprintf(&func_to_find, \"%s_%s\", prefix, suffix);\n\n    /* The RTLD_DEFAULT is a special handle that searches the default libraries\n     * including the current application for the indicated symbol. This allows\n     * us to not have to dlopen/dlclose the executable. A bit of short hand\n     * really.\n     */\n    *((void**) fn_ptr) = dlsym(RTLD_DEFAULT, func_to_find);\n    if( NULL == fn_ptr) {\n        opal_output_verbose(12, mca_crs_self_component.super.output_handle,\n                            \"crs:self: crs_self_find_function: WARNING: Function \\\"%s\\\" not found\",\n                            func_to_find);\n    }\n    else {\n        opal_output_verbose(10, mca_crs_self_component.super.output_handle,\n                            \"crs:self: crs_self_find_function: Found function \\\"%s\\\"\",\n                            func_to_find);\n    }\n\n    if( NULL == func_to_find) {\n        free(func_to_find);\n    }\n\n    return OPAL_SUCCESS;\n}\n\n/*\n * Self is a special case. The 'fname' here is the command line that the user\n * wishes to execute. This function takes this command line and adds\n *   -mca crs_self_do_restart 1\n * Which will trigger the restart callback once the program has been run.\n *\n * For example, The user starts their program with:\n *   $ my_prog arg1 arg2\n *\n * They checkpoint it:\n *   $ opal_checkpoint -mca crs self 1234\n *\n * They restart it:\n *   $ opal_restart -mca crs self my_prog arg1 arg2\n *\n * fname is then:\n *   fname = \"my_prog arg1 arg2\"\n *\n * This funciton translates that to the command:\n *   cmd = \"my_prog arg1 arg2 -mca crs self -mca crs_self_do_restart 1\"\n *\n * Which will cause the program \"my_prog\" to call their restart function\n * upon opal_init time.\n *\n * Note: The user could bypass the opal_restart routine safely by simply calling\n *   $ my_prog arg1 arg2 -mca crs self -mca crs_self_do_restart 1\n * However, for consistency sake, we should not encourage this as it won't work for\n * all of the other checkpointers.\n */\nstatic int opal_crs_self_restart_cmd(opal_crs_self_snapshot_t *snapshot, char **cmd)\n{\n    char * tmp_env_var = NULL;\n\n    opal_output_verbose(10, mca_crs_self_component.super.output_handle,\n                        \"crs:self: restart_cmd(%s, ---)\", snapshot->cmd_line);\n\n    (void) mca_base_var_env_name(\"crs\", &tmp_env_var);\n    opal_setenv(tmp_env_var,\n                \"self\",\n                true, &environ);\n    free(tmp_env_var);\n    tmp_env_var = NULL;\n\n    (void) mca_base_var_env_name(\"crs_self_do_restart\", &tmp_env_var);\n    opal_setenv(tmp_env_var,\n                \"1\",\n                true, &environ);\n    free(tmp_env_var);\n    tmp_env_var = NULL;\n\n    (void) mca_base_var_env_name(\"crs_self_prefix\", &tmp_env_var);\n    opal_setenv(tmp_env_var,\n                mca_crs_self_component.prefix,\n                true, &environ);\n    free(tmp_env_var);\n    tmp_env_var = NULL;\n\n    /* Instead of adding it to the command line, we should use the environment\n     * to pass the values. This allow sthe OPAL application to be braindead\n     * WRT MCA parameters\n     *   add_args = strdup(\"-mca crs self -mca crs_self_do_restart 1\");\n     */\n\n    opal_asprintf(cmd, \"%s\", snapshot->cmd_line);\n\n    return OPAL_SUCCESS;\n}\n\nstatic int self_cold_start(opal_crs_self_snapshot_t *snapshot) {\n    int ret, exit_status = OPAL_SUCCESS;\n    char **tmp_argv = NULL;\n    char * component_name = NULL;\n    int prev_pid;\n\n    opal_output_verbose(10, mca_crs_self_component.super.output_handle,\n                        \"crs:self: cold_start()\");\n\n    /*\n     * Find the snapshot directory, read the metadata file\n     */\n    if( NULL == snapshot->super.metadata ) {\n        if (NULL == (snapshot->super.metadata = fopen(snapshot->super.metadata_filename, \"a\")) ) {\n            opal_output(mca_crs_self_component.super.output_handle,\n                        \"crs:self: checkpoint(): Error: Unable to open the file (%s)\",\n                        snapshot->super.metadata_filename);\n            exit_status = OPAL_ERROR;\n            goto cleanup;\n        }\n    }\n    if( OPAL_SUCCESS != (ret = opal_crs_base_extract_expected_component(snapshot->super.metadata,\n                                                                        &component_name, &prev_pid) ) ) {\n        opal_output(mca_crs_self_component.super.output_handle,\n                    \"crs:self: self_cold_start: Error: Failed to extract the metadata from the local snapshot (%s). Returned %d.\",\n                    snapshot->super.metadata_filename, ret);\n        exit_status = ret;\n        goto cleanup;\n    }\n\n    snapshot->super.component_name = strdup(component_name);\n\n    /* Compare the strings to make sure this is our snapshot before going further */\n    if ( 0 != strncmp(mca_crs_self_component.super.base_version.mca_component_name,\n                      component_name, strlen(component_name)) ) {\n        exit_status = OPAL_ERROR;\n        opal_output(mca_crs_self_component.super.output_handle,\n                    \"crs:self: self_cold_start: Error: This snapshot (%s) is not intended for us (%s)\\n\",\n                    component_name, mca_crs_self_component.super.base_version.mca_component_name);\n        goto cleanup;\n    }\n\n    /*\n     * Restart command\n     * JJH: Command lines limited to 256 chars.\n     */\n    opal_crs_base_metadata_read_token(snapshot->super.metadata, CRS_METADATA_CONTEXT, &tmp_argv);\n    if( NULL == tmp_argv ) {\n        opal_output(mca_crs_self_component.super.output_handle,\n                    \"crs:self: self_cold_start: Error: Failed to read the %s token from the local checkpoint in %s\",\n                    CRS_METADATA_CONTEXT, snapshot->super.snapshot_directory);\n        exit_status = OPAL_ERROR;\n        goto cleanup;\n    }\n    opal_asprintf(&snapshot->cmd_line, \"%s\", tmp_argv[0]);\n\n    /*\n     * Reset the cold_start flag\n     */\n    snapshot->super.cold_start = false;\n\n cleanup:\n    if(NULL != tmp_argv) {\n        opal_argv_free(tmp_argv);\n        tmp_argv = NULL;\n    }\n\n    return exit_status;\n\n}\n\nstatic int self_update_snapshot_metadata(opal_crs_self_snapshot_t *snapshot) {\n    int exit_status = OPAL_SUCCESS;\n\n    if(NULL == snapshot->cmd_line) {\n        opal_show_help(\"help-opal-crs-self.txt\", \"self:no-restart-cmd\",\n                       true);\n        exit_status = OPAL_ERROR;\n        goto cleanup;\n    }\n\n    opal_output_verbose(10, mca_crs_self_component.super.output_handle,\n                        \"crs:self: update_snapshot_metadata(%s)\",\n                        snapshot->super.metadata_filename);\n\n    /*\n     * Append to the metadata file the command line to restart with\n     *  - How user wants us to restart\n     */\n    fprintf(snapshot->super.metadata, \"%s%s\\n\", CRS_METADATA_CONTEXT, snapshot->cmd_line);\n\n cleanup:\n    return exit_status;\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-openmpi-master-qcrm7qmgqutvsby2zcmdb57s22lzfq65/spack-src/opal/mca/dl/configure.m4": "dnl -*- shell-script -*-\ndnl\ndnl Copyright (c) 2010-2015 Cisco Systems, Inc.  All rights reserved.\ndnl $COPYRIGHT$\ndnl\ndnl Additional copyrights may follow\ndnl\ndnl $HEADER$\ndnl\n\ndnl There will only be one component used in this framework, and it will\ndnl be selected at configure time by priority.  Components must set\ndnl their priorities in their configure.m4 file.\n\ndnl We only want one winning component (vs. STOP_AT_FIRST_PRIORITY,\ndnl which will allow all components of the same priority who succeed to\ndnl win)\nm4_define(MCA_opal_dl_CONFIGURE_MODE, STOP_AT_FIRST)\n\nAC_DEFUN([MCA_opal_dl_CONFIG],[\n    OPAL_HAVE_DL_SUPPORT=0\n\n    # If --disable-dlopen was used, then have all the components fail\n    # (we still need to configure them all so that things like \"make\n    # dist\" work\", but we just want the MCA system to (artificially)\n    # conclude that it can't build any of the components.\n    AS_IF([test \"$enable_dlopen\" = \"no\"],\n          [want_dl=0], [want_dl=1])\n\n    MCA_CONFIGURE_FRAMEWORK([opal], [dl], [$want_dl])\n\n    # If we found no suitable static dl component and dlopen support\n    # was not specifically disabled, this is an error.\n    AS_IF([test \"$MCA_opal_dl_STATIC_COMPONENTS\" = \"\" && \\\n           test \"$enable_dlopen\" != \"no\"],\n          [AC_MSG_WARN([Did not find a suitable static opal dl component])\n           AC_MSG_WARN([You might need to install libltld (and its headers) or])\n           AC_MSG_WARN([specify --disable-dlopen to configure.])\n           AC_MSG_ERROR([Cannot continue])])\n\n    # If we have a winning component (which, per above, will only\n    # happen if --disable-dlopen was *not* specified), do some more\n    # logic.\n    AS_IF([test \"$MCA_opal_dl_STATIC_COMPONENTS\" != \"\"],\n       [ # We had a winner -- w00t!\n\n        OPAL_HAVE_DL_SUPPORT=1\n        # If we added any -L flags to ADD_LDFLAGS, then we (might)\n        # need to add those directories to LD_LIBRARY_PATH.\n        # Otherwise, if we try to AC RUN_IFELSE anything here in\n        # configure, it might die because it can't find the libraries\n        # we just linked against.\n        OPAL_VAR_SCOPE_PUSH([opal_dl_base_found_l opal_dl_base_token opal_dl_base_tmp opal_dl_base_dir])\n        opal_dl_base_found_l=0\n        eval \"opal_dl_base_tmp=\\$opal_dl_${opal_dl_winner}_ADD_LIBS\"\n        for opal_dl_base_token in $opal_dl_base_tmp; do\n            case $opal_dl_base_token in\n            -l*) opal_dl_base_found_l=1 ;;\n            esac\n        done\n        AS_IF([test $opal_dl_base_found_l -eq 1],\n              [eval \"opal_dl_base_tmp=\\$opal_dl_${opal_dl_winner}_ADD_LDFLAGS\"\n               for opal_dl_base_token in $opal_dl_base_tmp; do\n                   case $opal_dl_base_token in\n                   -L*)\n                       opal_dl_base_dir=`echo $opal_dl_base_token | cut -c3-`\n                       export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$opal_dl_base_dir\n                       AC_MSG_WARN([Adding to LD_LIBRARY_PATH: $opal_dl_base_dir])\n                       ;;\n                   esac\n               done])\n        OPAL_VAR_SCOPE_POP\n    ])\n\n    AC_DEFINE_UNQUOTED([OPAL_HAVE_DL_SUPPORT], [$OPAL_HAVE_DL_SUPPORT],\n                       [Whether the OPAL DL framework is functional or not])\n])\n",
        "/tmp/vanessa/spack-stage/spack-stage-openmpi-master-qcrm7qmgqutvsby2zcmdb57s22lzfq65/spack-src/opal/mca/dl/dl.h": "/* -*- Mode: C; c-basic-offset:4 ; indent-tabs-mode:nil -*- */\n/*\n * Copyright (c) 2015 Cisco Systems, Inc.  All rights reserved.\n * Copyright (c) 2015      Los Alamos National Security, LLC. All rights\n *                         reserved.\n * $COPYRIGHT$\n *\n * Additional copyrights may follow\n *\n * $HEADER$\n */\n\n/**\n * @file\n *\n * Dynamic library framework\n *\n * General Description:\n *\n * This framework provides portable access to dlopen- and dlsym-like\n * functionality, very similar to Libtool's libltdl.  Indeed, one of\n * the components in this framework will use libltdl, if it is\n * present/available.  However, on some common types systems where\n * libltdl headers and libraries are *not* available, we can support\n * plugins via this simple framework.\n *\n * This is a compile-time framework: a single component will be\n * selected by the priority that its configure.m4 provides.  All other\n * components will be ignored (i.e., not built/not part of the\n * installation).  Meaning: the static_components of the dl framework\n * will always contain 0 or 1 components.\n *\n * SIDENOTE: Open MPI used to embed libltdl.  However, as of early\n * 2015, this became problematic, for a variety of complex and\n * uninteresting reasons (see the following if you care about the\n * details: https://github.com/open-mpi/ompi/issues/311,\n * http://debbugs.gnu.org/cgi/bugreport.cgi?bug=19370,\n * https://github.com/open-mpi/ompi/pull/366,\n * https://github.com/open-mpi/ompi/pull/390).  That being said, we,\n * as a developer community, still wanted to be able to natively use\n * DSOs by default.  A small/simple framework for DL functionality,\n * along with a simple component that supports dlopen/dlsym on POSIX\n * platforms and another component that natively uses libltdl seemed\n * like a good solution.\n */\n\n#ifndef OPAL_MCA_DL_DL_H\n#define OPAL_MCA_DL_DL_H\n\n#include \"opal_config.h\"\n\n#include \"opal/mca/mca.h\"\n#include \"opal/mca/base/base.h\"\n\nBEGIN_C_DECLS\n\n/**\n * Handle for an opened file\n */\nstruct opal_dl_handle_t;\ntypedef struct opal_dl_handle_t opal_dl_handle_t;\n\n/**\n * Dynamically open the file specified.\n *\n * Arguments:\n *   fname   = Base filename to open.  If NULL, open this process.\n *   use_ext = If true, try various filename suffixes that are\n *       relevant on this platform (e.g., .so, .dll, .dylib).  If\n *       false, just use exactly whatever was passed as fname.\n *   private = If true, open the file in a private namespace.\n *       Otherwise, open the file in a global namespace.\n *   handle = Upon successful open, a handle to the opened file will\n *       be returned.\n *   err_msg= if non-NULL and !=OPAL_SUCCESS is returned, will point to a\n *       string error message\n *\n * Returns:\n *   OPAL_SUCCESS on success, or OPAL_ERROR\n *\n * Space for the handle must be allocated by the module (it can be\n * freed during the call to opal_dl_base_module_dlclose_fn_t).\n *\n * The err_msg points to an internal string and should not be altered\n * or freed by the caller.  The contents of the err_msg string may\n * change after successive calls to opal_dl API calls.\n */\ntypedef int (*opal_dl_base_module_open_fn_t)\n    (const char *fname, bool use_ext, bool private_namespace,\n     opal_dl_handle_t **handle, char **err_msg);\n\n/**\n * Lookup a symbol in an opened file.\n *\n * Arguments:\n *   handle = handle of a previously dynamically opened file\n *   symbol = name of the symbol to lookup\n *   ptr    = if found, a pointer to the symbol.  Otherwise, NULL.\n *   err_msg= if non-NULL and !=OPAL_SUCCESS is returned, will point to a\n *            string error message\n * Returns:\n *   OPAL_SUCCESS on success, or OPAL_ERROR\n *\n *\n * The err_msg points to an internal string and should not be altered\n * or freed by the caller.  The contents of the err_msg string may\n * change after successive calls to opal_dl API calls.\n */\ntypedef int (*opal_dl_base_module_lookup_fn_t)\n    (opal_dl_handle_t *handle, const char *symbol, void **ptr, char **err_msg);\n\n/**\n * Dynamically close a previously dynamically-opened file.\n *\n * Arguments:\n *   handle = handle of a previously dynamically opened file.\n * Returns:\n *   OPAL_SUCCESS on success, or OPAL_ERROR\n *\n * This function should close the file and free and resources\n * associated with it (e.g., whatever is cached on the handle).\n */\ntypedef int (*opal_dl_base_module_close_fn_t)\n    (opal_dl_handle_t *handle);\n\n/**\n * Search through a path of directories, invoking a callback on each\n * unique regular (non-Libtool) file basename found (e.g., will only\n * be invoked once for the files \"foo.la\" and \"foo.so\", with the\n * parameter \"foo\").\n *\n * Arguments:\n *   path   = OPAL_ENV_SEP-delimited list of directories\n *   cb_func= function to invoke on each filename found\n *   data   = context for callback function\n * Returns:\n *   OPAL_SUCESS on success, OPAL_ERR* otherwise\n */\ntypedef int (*opal_dl_base_module_foreachfile_fn_t)\n    (const char *search_path,\n     int (*cb_func)(const char *filename, void *context),\n     void *context);\n\n/**\n * Structure for DL components.\n */\nstruct opal_dl_base_component_1_0_0_t {\n    /** MCA base component */\n    mca_base_component_t base_version;\n    /** MCA base data */\n    mca_base_component_data_t base_data;\n\n    /** Default priority */\n    int priority;\n};\ntypedef struct opal_dl_base_component_1_0_0_t opal_dl_base_component_1_0_0_t;\ntypedef struct opal_dl_base_component_1_0_0_t opal_dl_base_component_t;\n\n/**\n * Structure for DL modules\n */\nstruct opal_dl_base_module_1_0_0_t {\n    mca_base_module_2_0_0_t                 super;\n\n    /** Open / close */\n    opal_dl_base_module_open_fn_t           open;\n    opal_dl_base_module_close_fn_t          close;\n\n    /** Lookup a symbol */\n    opal_dl_base_module_lookup_fn_t         lookup;\n\n    /** Iterate looking for files */\n    opal_dl_base_module_foreachfile_fn_t    foreachfile;\n};\ntypedef struct opal_dl_base_module_1_0_0_t opal_dl_base_module_1_0_0_t;\ntypedef struct opal_dl_base_module_1_0_0_t opal_dl_base_module_t;\n\n/**\n * Macro for use in components that are of type DL\n */\n#define OPAL_DL_BASE_VERSION_1_0_0              \\\n    OPAL_MCA_BASE_VERSION_2_1_0(\"dl\", 1, 0, 0)\n\nEND_C_DECLS\n\n#endif /* OPAL_MCA_DL_DL_H */\n",
        "/tmp/vanessa/spack-stage/spack-stage-openmpi-master-qcrm7qmgqutvsby2zcmdb57s22lzfq65/spack-src/opal/mca/dl/dlopen/dl_dlopen_component.c": "/* -*- Mode: C; c-basic-offset:4 ; indent-tabs-mode:nil -*- */\n/*\n * Copyright (c) 2015 Cisco Systems, Inc.  All rights reserved.\n * Copyright (c) 2015      Los Alamos National Security, LLC. All rights\n *                         reserved.\n * $COPYRIGHT$\n *\n * Additional copyrights may follow\n *\n * $HEADER$\n */\n\n#include \"opal_config.h\"\n\n#include \"opal/constants.h\"\n#include \"opal/mca/dl/dl.h\"\n#include \"opal/util/argv.h\"\n\n#include \"dl_dlopen.h\"\n\n\n/*\n * Public string showing the sysinfo ompi_linux component version number\n */\nconst char *opal_dl_dlopen_component_version_string =\n    \"OPAL dl dlopen MCA component version \" OPAL_VERSION;\n\n\n/*\n * Local functions\n */\nstatic int dlopen_component_register(void);\nstatic int dlopen_component_open(void);\nstatic int dlopen_component_close(void);\nstatic int dlopen_component_query(mca_base_module_t **module, int *priority);\n\n/*\n * Instantiate the public struct with all of our public information\n * and pointers to our public functions in it\n */\n\nopal_dl_dlopen_component_t mca_dl_dlopen_component = {\n\n    /* Fill in the mca_dl_base_component_t */\n    .base = {\n\n        /* First, the mca_component_t struct containing meta information\n           about the component itself */\n        .base_version = {\n            OPAL_DL_BASE_VERSION_1_0_0,\n\n            /* Component name and version */\n            .mca_component_name = \"dlopen\",\n            MCA_BASE_MAKE_VERSION(component, OPAL_MAJOR_VERSION, OPAL_MINOR_VERSION,\n                                  OPAL_RELEASE_VERSION),\n\n            /* Component functions */\n            .mca_register_component_params = dlopen_component_register,\n            .mca_open_component = dlopen_component_open,\n            .mca_close_component = dlopen_component_close,\n            .mca_query_component = dlopen_component_query,\n        },\n\n        .base_data = {\n            /* The component is checkpoint ready */\n            MCA_BASE_METADATA_PARAM_CHECKPOINT\n        },\n\n        /* The dl framework members */\n        .priority = 80\n    },\n};\n\n\nstatic int dlopen_component_register(void)\n{\n    int ret;\n\n    mca_dl_dlopen_component.filename_suffixes_mca_storage = \".so,.dylib,.dll,.sl\";\n    ret =\n        mca_base_component_var_register(&mca_dl_dlopen_component.base.base_version,\n                                        \"filename_suffixes\",\n                                        \"Comma-delimited list of filename suffixes that the dlopen component will try\",\n                                        MCA_BASE_VAR_TYPE_STRING,\n                                        NULL,\n                                        0,\n                                        MCA_BASE_VAR_FLAG_SETTABLE,\n                                        OPAL_INFO_LVL_5,\n                                        MCA_BASE_VAR_SCOPE_LOCAL,\n                                        &mca_dl_dlopen_component.filename_suffixes_mca_storage);\n    if (ret < 0) {\n        return ret;\n    }\n    mca_dl_dlopen_component.filename_suffixes =\n        opal_argv_split(mca_dl_dlopen_component.filename_suffixes_mca_storage,\n                        ',');\n\n    return OPAL_SUCCESS;\n}\n\nstatic int dlopen_component_open(void)\n{\n    return OPAL_SUCCESS;\n}\n\n\nstatic int dlopen_component_close(void)\n{\n    if (NULL != mca_dl_dlopen_component.filename_suffixes) {\n        opal_argv_free(mca_dl_dlopen_component.filename_suffixes);\n        mca_dl_dlopen_component.filename_suffixes = NULL;\n    }\n\n    return OPAL_SUCCESS;\n}\n\n\nstatic int dlopen_component_query(mca_base_module_t **module, int *priority)\n{\n    /* The priority value is somewhat meaningless here; by\n       opal/mca/dl/configure.m4, there's at most one component\n       available. */\n    *priority = mca_dl_dlopen_component.base.priority;\n    *module = &opal_dl_dlopen_module.super;\n\n    return OPAL_SUCCESS;\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-openmpi-master-qcrm7qmgqutvsby2zcmdb57s22lzfq65/spack-src/opal/mca/dl/dlopen/dl_dlopen_module.c": "/* -*- Mode: C; c-basic-offset:4 ; indent-tabs-mode:nil -*- */\n/*\n * Copyright (c) 2015 Cisco Systems, Inc.  All rights reserved.\n * Copyright (c) 2015      Los Alamos National Security, LLC. All rights\n *                         reserved.\n * Copyright (c) 2016      IBM Corporation.  All rights reserved.\n * Copyright (c) 2018      Amazon.com, Inc. or its affiliates.  All Rights reserved.\n * $COPYRIGHT$\n *\n * Additional copyrights may follow\n *\n * $HEADER$\n */\n\n#include \"opal_config.h\"\n\n#include <stdlib.h>\n#include <dlfcn.h>\n#include <sys/types.h>\n#include <dirent.h>\n#include <sys/stat.h>\n#include <unistd.h>\n\n#include \"opal/constants.h\"\n#include \"opal/mca/dl/dl.h\"\n#include \"opal/util/argv.h\"\n#include \"opal/util/printf.h\"\n\n#include \"dl_dlopen.h\"\n\n\n/*\n * Trivial helper function to avoid replicating code\n */\nstatic void do_dlopen(const char *fname, int flags,\n                      void **handle, char **err_msg)\n{\n    assert(handle);\n\n    *handle = dlopen(fname, flags);\n\n    if (NULL != err_msg) {\n        if (NULL != *handle) {\n            *err_msg = NULL;\n        } else {\n            *err_msg = dlerror();\n        }\n    }\n}\n\n\nstatic int dlopen_open(const char *fname, bool use_ext, bool private_namespace,\n                       opal_dl_handle_t **handle, char **err_msg)\n{\n    assert(handle);\n\n    *handle = NULL;\n\n    /* Setup the dlopen flags */\n    int flags = RTLD_LAZY;\n    if (private_namespace) {\n        flags |= RTLD_LOCAL;\n    } else {\n        flags |= RTLD_GLOBAL;\n    }\n\n    /* If the caller wants to use filename extensions, loop through\n       them */\n    void *local_handle = NULL;\n    if (use_ext && NULL != fname) {\n        int i;\n        char *ext;\n\n        for (i = 0, ext = mca_dl_dlopen_component.filename_suffixes[i];\n             NULL != ext;\n             ext = mca_dl_dlopen_component.filename_suffixes[++i]) {\n            char *name;\n\n            opal_asprintf(&name, \"%s%s\", fname, ext);\n            if (NULL == name) {\n                return OPAL_ERR_IN_ERRNO;\n            }\n\n            /* Does the file exist? */\n            struct stat buf;\n            if (stat(name, &buf) < 0) {\n                free(name);\n                if (NULL != err_msg) {\n                    *err_msg = \"File not found\";\n                }\n                continue;\n            }\n\n            /* Yes, the file exists -- try to dlopen it.  If we can't\n               dlopen it, bail. */\n            do_dlopen(name, flags, &local_handle, err_msg);\n            free(name);\n            break;\n        }\n    }\n\n    /* Otherwise, the caller does not want to use filename extensions,\n       so just use the single filename that the caller provided */\n    else {\n        do_dlopen(fname, flags, &local_handle, err_msg);\n    }\n\n    if (NULL != local_handle) {\n        *handle = calloc(1, sizeof(opal_dl_handle_t));\n        (*handle)->dlopen_handle = local_handle;\n\n#if OPAL_ENABLE_DEBUG\n        if( NULL != fname ) {\n            (*handle)->filename = strdup(fname);\n        }\n        else {\n            (*handle)->filename = strdup(\"(null)\");\n        }\n#endif\n    }\n    return (NULL != local_handle) ? OPAL_SUCCESS : OPAL_ERROR;\n}\n\n\nstatic int dlopen_lookup(opal_dl_handle_t *handle, const char *symbol,\n                         void **ptr, char **err_msg)\n{\n    assert(handle);\n    assert(handle->dlopen_handle);\n    assert(symbol);\n    assert(ptr);\n\n    *ptr = dlsym(handle->dlopen_handle, symbol);\n    if (NULL != *ptr) {\n        return OPAL_SUCCESS;\n    }\n\n    if (NULL != err_msg) {\n        *err_msg = dlerror();\n    }\n    return OPAL_ERROR;\n}\n\n\nstatic int dlopen_close(opal_dl_handle_t *handle)\n{\n    assert(handle);\n\n    int ret;\n    ret = dlclose(handle->dlopen_handle);\n\n#if OPAL_ENABLE_DEBUG\n    free(handle->filename);\n#endif\n    free(handle);\n\n    return ret;\n}\n\n/*\n * Scan all the files in a directory (or path) and invoke a callback\n * on each one.\n */\nstatic int dlopen_foreachfile(const char *search_path,\n                              int (*func)(const char *filename, void *data),\n                              void *data)\n{\n    int ret;\n    DIR *dp = NULL;\n    char **dirs = NULL;\n    char **good_files = NULL;\n\n    dirs = opal_argv_split(search_path, OPAL_ENV_SEP);\n    for (int i = 0; NULL != dirs && NULL != dirs[i]; ++i) {\n\n        dp = opendir(dirs[i]);\n        if (NULL == dp) {\n            ret = OPAL_ERR_IN_ERRNO;\n            goto error;\n        }\n\n        struct dirent *de;\n        while (NULL != (de = readdir(dp))) {\n\n            /* Make the absolute path name */\n            char *abs_name = NULL;\n            opal_asprintf(&abs_name, \"%s/%s\", dirs[i], de->d_name);\n            if (NULL == abs_name) {\n                ret = OPAL_ERR_IN_ERRNO;\n                goto error;\n            }\n\n            /* Stat the file */\n            struct stat buf;\n            if (stat(abs_name, &buf) < 0) {\n                free(abs_name);\n                ret = OPAL_ERR_IN_ERRNO;\n                goto error;\n            }\n\n            /* Skip if not a file */\n            if (!S_ISREG(buf.st_mode)) {\n                free(abs_name);\n                continue;\n            }\n\n            /* Find the suffix */\n            char *ptr = strrchr(abs_name, '.');\n            if (NULL != ptr) {\n\n                /* Skip libtool files */\n                if (strcmp(ptr, \".la\") == 0 ||\n                    strcmp(ptr, \".lo\") == 0) {\n                    free (abs_name);\n                    continue;\n                }\n\n                *ptr = '\\0';\n            }\n\n            /* Have we already found this file?  Or already found a\n               file with the same basename (but different suffix)? */\n            bool found = false;\n            for (int j = 0; NULL != good_files &&\n                     NULL != good_files[j]; ++j) {\n                if (strcmp(good_files[j], abs_name) == 0) {\n                    found = true;\n                    break;\n                }\n            }\n\n            if (!found) {\n                opal_argv_append_nosize(&good_files, abs_name);\n            }\n            free(abs_name);\n        }\n        closedir(dp);\n    }\n    dp = NULL;\n\n    /* Invoke the callback on all the found files */\n    if (NULL != good_files) {\n        for (int i = 0; NULL != good_files[i]; ++i) {\n            ret = func(good_files[i], data);\n            if (OPAL_SUCCESS != ret) {\n                goto error;\n            }\n        }\n    }\n\n    ret = OPAL_SUCCESS;\n\n error:\n    if (NULL != dp) {\n        closedir(dp);\n    }\n    if (NULL != dirs) {\n        opal_argv_free(dirs);\n    }\n    if (NULL != good_files) {\n        opal_argv_free(good_files);\n    }\n\n    return ret;\n}\n\n\n/*\n * Module definition\n */\nopal_dl_base_module_t opal_dl_dlopen_module = {\n    .open = dlopen_open,\n    .lookup = dlopen_lookup,\n    .close = dlopen_close,\n    .foreachfile = dlopen_foreachfile\n};\n",
        "/tmp/vanessa/spack-stage/spack-stage-openmpi-master-qcrm7qmgqutvsby2zcmdb57s22lzfq65/spack-src/opal/mca/dl/dlopen/dl_dlopen.h": "/*\n * Copyright (c) 2015 Cisco Systems, Inc.  All rights reserved.\n * $COPYRIGHT$\n *\n * Additional copyrights may follow\n *\n * $HEADER$\n */\n\n#ifndef OPAL_DL_DLOPEN\n#define OPAL_DL_DLOPEN\n\n#include \"opal_config.h\"\n\n#include \"opal/mca/dl/dl.h\"\n\nOPAL_DECLSPEC extern opal_dl_base_module_t opal_dl_dlopen_module;\n\n/*\n * Dynamic library handles generated by this component.\n *\n * If we're debugging, keep a copy of the name of the file we've opened.\n */\nstruct opal_dl_handle_t {\n    void *dlopen_handle;\n#if OPAL_ENABLE_DEBUG\n    void *filename;\n#endif\n};\n\ntypedef struct {\n    opal_dl_base_component_t base;\n\n    char *filename_suffixes_mca_storage;\n    char **filename_suffixes;\n} opal_dl_dlopen_component_t;\n\nOPAL_DECLSPEC extern opal_dl_dlopen_component_t mca_dl_dlopen_component;\n\n#endif /* OPAL_DL_DLOPEN */\n",
        "/tmp/vanessa/spack-stage/spack-stage-openmpi-master-qcrm7qmgqutvsby2zcmdb57s22lzfq65/spack-src/opal/mca/dl/dlopen/configure.m4": "# -*- shell-script -*-\n#\n# Copyright (c) 2009-2017 Cisco Systems, Inc.  All rights reserved\n#\n# $COPYRIGHT$\n#\n# Additional copyrights may follow\n#\n# $HEADER$\n#\n\nAC_DEFUN([MCA_opal_dl_dlopen_PRIORITY], [80])\n\n#\n# Force this component to compile in static-only mode\n#\nAC_DEFUN([MCA_opal_dl_dlopen_COMPILE_MODE], [\n    AC_MSG_CHECKING([for MCA component $2:$3 compile mode])\n    $4=\"static\"\n    AC_MSG_RESULT([$$4])\n])\n\n# MCA_dl_dlopen_CONFIG([action-if-can-compile],\n#                      [action-if-cant-compile])\n# ------------------------------------------------\nAC_DEFUN([MCA_opal_dl_dlopen_CONFIG],[\n    AC_CONFIG_FILES([opal/mca/dl/dlopen/Makefile])\n\n    dnl This is effectively a back-door for Open MPI developers to\n    dnl force the use of the libltdl dl component.\n    AC_ARG_ENABLE([dl-dlopen],\n        [AS_HELP_STRING([--disable-dl-dlopen],\n            [Disable the \"dlopen\" DL component (and probably force the use of the \"libltdl\" DL component).  This option should really only be used by Open MPI developers.  You are probably actually looking for the \"--disable-dlopen\" option, which disables all dlopen-like functionality from Open MPI.])\n        ])\n\n    opal_dl_dlopen_happy=no\n    AS_IF([test \"$enable_dl_dlopen\" != \"no\"],\n          [OPAL_CHECK_PACKAGE([opal_dl_dlopen],\n              [dlfcn.h],\n              [dl],\n              [dlopen],\n              [],\n              [],\n              [],\n              [opal_dl_dlopen_happy=yes],\n              [opal_dl_dlopen_happy=no])\n          ])\n\n    AS_IF([test \"$opal_dl_dlopen_happy\" = \"yes\"],\n          [dl_dlopen_ADD_LIBS=$opal_dl_dlopen_LIBS\n           dl_dlopen_WRAPPER_EXTRA_LIBS=$opal_dl_dlopen_LIBS\n           $1],\n          [$2])\n\n    AC_SUBST(opal_dl_dlopen_LIBS)\n])\n",
        "/tmp/vanessa/spack-stage/spack-stage-openmpi-master-qcrm7qmgqutvsby2zcmdb57s22lzfq65/spack-src/opal/mca/dl/dlopen/Makefile.am": "#\n# Copyright (c) 2004-2010 The Trustees of Indiana University.\n#                         All rights reserved.\n# Copyright (c) 2014-2015 Cisco Systems, Inc.  All rights reserved.\n# $COPYRIGHT$\n#\n# Additional copyrights may follow\n#\n# $HEADER$\n#\n\nsources = \\\n        dl_dlopen.h \\\n        dl_dlopen_component.c \\\n        dl_dlopen_module.c\n\n# This component will only ever be built statically -- never as a DSO.\n\nnoinst_LTLIBRARIES = libmca_dl_dlopen.la\n\nlibmca_dl_dlopen_la_SOURCES = $(sources)\nlibmca_dl_dlopen_la_LDFLAGS = -module -avoid-version\nlibmca_dl_dlopen_la_LIBADD = $(opal_dl_dlopen_LIBS)\n",
        "/tmp/vanessa/spack-stage/spack-stage-openmpi-master-qcrm7qmgqutvsby2zcmdb57s22lzfq65/spack-src/opal/mca/dl/libltdl/dl_libltdl_module.c": "/*\n * Copyright (c) 2015 Cisco Systems, Inc.  All rights reserved.\n * Copyright (c) 2016      IBM Corporation.  All rights reserved.\n * $COPYRIGHT$\n *\n * Additional copyrights may follow\n *\n * $HEADER$\n */\n\n#include \"opal_config.h\"\n\n#include \"opal/constants.h\"\n#include \"opal/mca/dl/dl.h\"\n\n#include \"dl_libltdl.h\"\n\n\nstatic int libltdl_open(const char *fname, bool use_ext, bool private_namespace,\n                       opal_dl_handle_t **handle, char **err_msg)\n{\n    assert(handle);\n\n    *handle = NULL;\n    if (NULL != err_msg) {\n        *err_msg = NULL;\n    }\n\n    lt_dlhandle local_handle;\n\n#if OPAL_DL_LIBLTDL_HAVE_LT_DLADVISE\n    opal_dl_libltdl_component_t *c = &mca_dl_libltdl_component;\n\n    if (use_ext && private_namespace) {\n        local_handle = lt_dlopenadvise(fname, c->advise_private_ext);\n    } else if (use_ext && !private_namespace) {\n        local_handle = lt_dlopenadvise(fname, c->advise_public_ext);\n    } else if (!use_ext && private_namespace) {\n        local_handle = lt_dlopenadvise(fname, c->advise_private_noext);\n    } else if (!use_ext && !private_namespace) {\n        local_handle = lt_dlopenadvise(fname, c->advise_public_noext);\n    }\n#else\n    if (use_ext) {\n        local_handle = lt_dlopenext(fname);\n    } else {\n        local_handle = lt_dlopen(fname);\n    }\n#endif\n\n    if (NULL != local_handle) {\n        *handle = calloc(1, sizeof(opal_dl_handle_t));\n        (*handle)->ltdl_handle = local_handle;\n\n#if OPAL_ENABLE_DEBUG\n        if( NULL != fname ) {\n            (*handle)->filename = strdup(fname);\n        }\n        else {\n            (*handle)->filename = strdup(\"(null)\");\n        }\n#endif\n\n        return OPAL_SUCCESS;\n    }\n\n    if (NULL != err_msg) {\n        *err_msg = (char*) lt_dlerror();\n    }\n    return OPAL_ERROR;\n}\n\n\nstatic int libltdl_lookup(opal_dl_handle_t *handle, const char *symbol,\n                         void **ptr, char **err_msg)\n{\n    assert(handle);\n    assert(handle->ltdl_handle);\n    assert(symbol);\n    assert(ptr);\n\n    if (NULL != err_msg) {\n        *err_msg = NULL;\n    }\n\n    *ptr = lt_dlsym(handle->ltdl_handle, symbol);\n    if (NULL != *ptr) {\n        return OPAL_SUCCESS;\n    }\n\n    if (NULL != err_msg) {\n        *err_msg = (char*) lt_dlerror();\n    }\n    return OPAL_ERROR;\n}\n\n\nstatic int libltdl_close(opal_dl_handle_t *handle)\n{\n    assert(handle);\n\n    int ret;\n    ret = lt_dlclose(handle->ltdl_handle);\n\n#if OPAL_ENABLE_DEBUG\n    free(handle->filename);\n#endif\n    free(handle);\n\n    return ret;\n}\n\nstatic int libltdl_foreachfile(const char *search_path,\n                               int (*func)(const char *filename, void *data),\n                               void *data)\n{\n    assert(search_path);\n    assert(func);\n\n    int ret = lt_dlforeachfile(search_path, func, data);\n    return (0 == ret) ? OPAL_SUCCESS : OPAL_ERROR;\n}\n\n\n/*\n * Module definition\n */\nopal_dl_base_module_t opal_dl_libltdl_module = {\n    .open = libltdl_open,\n    .lookup = libltdl_lookup,\n    .close = libltdl_close,\n    .foreachfile = libltdl_foreachfile\n};\n",
        "/tmp/vanessa/spack-stage/spack-stage-openmpi-master-qcrm7qmgqutvsby2zcmdb57s22lzfq65/spack-src/opal/mca/dl/libltdl/configure.m4": "# -*- shell-script -*-\n#\n# Copyright (c) 2009-2015 Cisco Systems, Inc.  All rights reserved.\n#\n# Copyright (c) 2017      Intel, Inc. All rights reserved.\n# $COPYRIGHT$\n#\n# Additional copyrights may follow\n#\n# $HEADER$\n#\n\nAC_DEFUN([MCA_opal_dl_libltdl_PRIORITY], [50])\n\n#\n# Force this component to compile in static-only mode\n#\nAC_DEFUN([MCA_opal_dl_libltdl_COMPILE_MODE], [\n    AC_MSG_CHECKING([for MCA component $2:$3 compile mode])\n    $4=\"static\"\n    AC_MSG_RESULT([$$4])\n])\n\n# MCA_opal_dl_libltdl_POST_CONFIG()\n# ---------------------------------\nAC_DEFUN([MCA_opal_dl_libltdl_POST_CONFIG],[\n    # If we won, then do all the rest of the setup\n    AS_IF([test \"$1\" = \"1\"],\n          [\n           # Add some stuff to CPPFLAGS so that the rest of the source\n           # tree can be built\n           LDFLAGS=\"$LDFLAGS $opal_dl_libltdl_ADD_LDFLAGS\"\n           LIBS=\"$LIBS $opal_dl_libltdl_ADD_LIBS\"\n          ])\n])dnl\n\n# MCA_dl_libltdl_CONFIG([action-if-can-compile],\n#                       [action-if-cant-compile])\n# ------------------------------------------------\nAC_DEFUN([MCA_opal_dl_libltdl_CONFIG],[\n    OPAL_VAR_SCOPE_PUSH([CPPFLAGS_save LDFLAGS_save LIBS_save])\n    AC_CONFIG_FILES([opal/mca/dl/libltdl/Makefile])\n\n    # Add --with options\n    AC_ARG_WITH([libltdl],\n        [AC_HELP_STRING([--with-libltdl(=DIR)],\n             [Build libltdl support, optionally adding DIR/include, DIR/lib, and DIR/lib64 to the search path for headers and libraries])])\n    AC_ARG_WITH([libltdl-libdir],\n       [AC_HELP_STRING([--with-libltdl-libdir=DIR],\n             [Search for libltdl libraries in DIR])])\n\n    # Sanity check the --with values\n    OPAL_CHECK_WITHDIR([libltdl], [$with_libltdl],\n                       [include/ltdl.h])\n    OPAL_CHECK_WITHDIR([libltdl-libdir], [$with_libltdl_libdir],\n                       [libltdl.*])\n\n    # Defaults\n    opal_check_libltdl_dir_msg=\"compiler default\"\n    opal_check_libltdl_libdir_msg=\"linker default\"\n\n    # Save directory names if supplied\n    AS_IF([test ! -z \"$with_libltdl\" && test \"$with_libltdl\" != \"yes\"],\n          [opal_check_libltdl_dir=$with_libltdl\n           opal_check_libltdl_dir_msg=\"$opal_check_libltdl_dir (from --with-libltdl)\"])\n    AS_IF([test ! -z \"$with_libltdl_libdir\" && test \"$with_libltdl_libdir\" != \"yes\"],\n          [opal_check_libltdl_libdir=$with_libltdl_libdir\n           opal_check_libltdl_libdir_msg=\"$opal_check_libltdl_libdir (from --with-libltdl-libdir)\"])\n\n    opal_dl_libltdl_happy=no\n    AS_IF([test \"$with_libltdl\" != \"no\"],\n          [AC_MSG_CHECKING([for libltdl dir])\n           AC_MSG_RESULT([$opal_check_libltdl_dir_msg])\n           AC_MSG_CHECKING([for libltdl library dir])\n           AC_MSG_RESULT([$opal_check_libltdl_libdir_msg])\n\n           OPAL_CHECK_PACKAGE([opal_dl_libltdl],\n                  [ltdl.h],\n                  [ltdl],\n                  [lt_dlopen],\n                  [],\n                  [$opal_check_libltdl_dir],\n                  [$opal_check_libltdl_libdir],\n                  [opal_dl_libltdl_happy=yes],\n                  [opal_dl_libltdl_happy=no])\n              ])\n\n    # If we have libltdl, do we have lt_dladvise?\n    opal_dl_libltdl_have_lt_dladvise=0\n    AS_IF([test \"$opal_dl_libltdl_happy\" = \"yes\"],\n          [CPPFLAGS_save=$CPPFLAGS\n           LDFLAGS_save=$LDFLAGS\n           LIBS_save=$LIBS\n\n           CPPFLAGS=\"$opal_dl_libltdl_CPPFLAGS $CPPFLAGS\"\n           LDFLAGS=\"$opal_dl_libltdl_LDFLAGS $LDFLAGS\"\n           LIBS=\"$opal_dl_libltdl_LIBS $LIBS\"\n           AC_CHECK_FUNC([lt_dladvise_init],\n                         [opal_dl_libltdl_have_lt_dladvise=1])\n           CPPFLAGS=$CPPFLAGS_save\n           LDFLAGS=$LDFLAGS_save\n           LIBS=$LIBS_save\n          ])\n    AC_DEFINE_UNQUOTED(OPAL_DL_LIBLTDL_HAVE_LT_DLADVISE,\n        [$opal_dl_libltdl_have_lt_dladvise],\n        [Whether we have lt_dladvise or not])\n\n    AS_IF([test \"$opal_dl_libltdl_happy\" = \"yes\"],\n          [opal_dl_libltdl_ADD_CPPFLAGS=$opal_dl_libltdl_CPPFLAGS\n           opal_dl_libltdl_ADD_LDFLAGS=$opal_dl_libltdl_LDFLAGS\n           opal_dl_libltdl_ADD_LIBS=$opal_dl_libltdl_LIBS\n           $1],\n          [AS_IF([test ! -z \"$with_libltdl\" && \\\n                  test \"$with_libltdl\" != \"no\"],\n                 [AC_MSG_WARN([Libltdl support requested (via --with-libltdl) but not found.])\n                  AC_MSG_ERROR([Cannot continue.])])\n           $2])\n\n    AC_SUBST(opal_dl_libltdl_CPPFLAGS)\n    AC_SUBST(opal_dl_libltdl_LDFLAGS)\n    AC_SUBST(opal_dl_libltdl_LIBS)\n\n    OPAL_VAR_SCOPE_POP\n])\n",
        "/tmp/vanessa/spack-stage/spack-stage-openmpi-master-qcrm7qmgqutvsby2zcmdb57s22lzfq65/spack-src/contrib/platform/lanl/toss/README.md": "These platform files were created from platform files shipped with the release\ntarball. Each file has been modified. Here are the details on how they were\ncreated.\n\n- common\n  Copy of contrib/platform/lanl/toss/toss-common. Removed entries in bottom\n  half of file that were specific to TOSS so that it could be used for Cray\n  platforms as well.\n- common-optimized\n  Copy of contrib/platform/lanl/toss/optimized-common. Used the file as-is.\n- toss2-qib-optimized\n  Copy of contrib/platform/lanl/toss/optimized with the following changes:\n  - source common and common-optimzed instead of toss-common and\n    optimized-common\n  - added entries that were removed from common:\n    - enable_mca_no_build\n    - with_slurm\n    - with_tm\n    - with_pmi\n    - NOTE: common had \"with_devel_headers=yes\" in it that was not propagated.\n      This option should not be used in production as per Open MPI developer\n      mailing list guidance.\n  - Changed comment \"Disable components not needed on any TOSS platform\" to\n    \"Disable components not needed on TOSS platforms with high-speed networks\"\n  - Changed \"enable panasas\" to \"enable lustre\"\n- toss2-qib-optimized.conf\n  - copy of contrib/platform/lanl/toss/optimized.conf with the following\n    changes:\n    - changed: orte_no_session_dirs = /lustre,/net,/users,/usr/projects\n    - changed: btl = ^openib\n    - removed: hwloc_base_binding_policy = core (outdated setting)\n    - added: rmaps_base_ranking_policy = core (rank by core)\n    - added: ras_base_launch_orted_on_hn = true (run orted on parent node of\n      allocation)\n- toss2-mlx-optimized\n  - copy of toss2-qib-optimized\n- toss2-mlx-optimized.conf\n  - copy of toss2-qib-optimized.conf with the following changes:\n    - remove: oob_tcp_if_include = ib0,eth0 (identification of general network\n      device names is problematic in RHEL7. Just let Open MPI figure it out)\n    - change: btl = vader,openib,self\n    - change: btl_openib_receive_queues = X,4096,1024:X,12288,512:X,65536,512\n      (change S to X; make sure numbers match those for the same entry in\n      contrib/platform/lanl/toss/optimized-mlx.conf)\n    - addition: pml = ob1 (disable MXM)\n    - addition: coll = ^hcoll (disable MXM)\n- toss3-hfi-optimized\n  - copy of toss2-qib-optimized\n- toss3-hfi-optimized.conf\n  - copy of toss2-qib-optimized.conf with the following changes:\n    - remove: oob_tcp_if_include = ib0,eth0\n    - add: oob_tcp_if_exclude = ib0 (Omnipath is flaky; don't use it for oob)\n- toss3-wc-optimized (platform file for woodchuck which is an ethernet-only\n  connected cluster)\n  - copy of toss3-hfi-optimized with the following changes:\n    - change: remove \"btl-tcp\" from the enable_mca_no_build list\n    - change: comment \"Disable components not needed on TOSS platforms with\n      high-speed networks\" to \"Disable components not needed on TOSS Ethernet-\n      connected clusters\"\n- toss3-wc-optimized.conf\n  - copy of toss3-hfi-optimized.conf with the following changes:\n    - change: comment \"Add the interface for out-of-band communication and set\n      it up\" to \"Set up the interface for out-of-band communication\"\n    - remove: oob_tcp_if_exclude = ib0\n    - remove: btl (let Open MPI figure out what best to use for ethernet-\n      connected hardware)\n    - remove: btl_openib_want_fork_support (no infiniband)\n    - remove: btl_openib_receive_queues (no infiniband)\n- cray-lustre-optimized\n  - copy of contrib/platform/lanl/cray_xc_cle5.2/optimized-lustre with the\n    following changes:\n    - remove: whole if/else clause of 'test \"$enable_debug\" = \"yes\"'\n    - addition: source ./common\n    - addition: source ./common-optimized\n    - change: with_io_romio_flags=\"--with-file-system=ufs+nfs+lustre\"\n    - remove: with_lustre=/opt/cray/lustre-cray_ari_s/default\n    - additions from platform/lanl/cray_xc_cle5.2/optimized-common that don't\n      go in common-optimzed:\n      - enable_mca_no_build=crs,filem,routed-linear,snapc,pml-dr,pml-crcp2,pml-crcpw,pml-v,pml-example,crcp,pml-cm,ess-cnos,grpcomm-cnos,plm-rsh,btl-tcp,oob-ud,ras-simulator,mpool-fake\n      - enable_mca_static=btl:ugni,btl:self,btl:vader,pml:ob1\n      - enable_mca_directpml-ob1\n      - with_tm=no\n      - enable_orte_static_ports=no\n      - enable_pty_support=no\n    - addition: enable_dlopen=yes (change from original platform file as per\n      Nathan Hjelm)\n- cray-lustre-optimized.conf\n  - copy of contrib/platform/lanl/cray_xc_cle5.2/optimized-lustre.conf with\n    the following changes:\n    - change: orte_no_session_dirs = /lustre,/users,/usr/projects\n    - remove: hwloc_base_binding_policy = core (outdated setting)\n    - addition: rmaps_base_ranking_policy = core (rank by core)\n\n# vi: filetype=txt\n"
    },
    "skipped": [
        "/tmp/vanessa/spack-stage/spack-stage-openmpi-master-qcrm7qmgqutvsby2zcmdb57s22lzfq65/spack-src/ompi/mca/io/romio321/romio/adio/common/ad_iwrite_coll.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-openmpi-master-qcrm7qmgqutvsby2zcmdb57s22lzfq65/spack-src/ompi/mca/io/romio321/romio/adio/common/ad_iread_coll.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-openmpi-master-qcrm7qmgqutvsby2zcmdb57s22lzfq65/spack-src/ompi/mca/io/romio321/romio/doc/source-guide.tex",
        "/tmp/vanessa/spack-stage/spack-stage-openmpi-master-qcrm7qmgqutvsby2zcmdb57s22lzfq65/spack-src/ompi/mca/io/romio321/romio/doc/users-guide.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-openmpi-master-qcrm7qmgqutvsby2zcmdb57s22lzfq65/spack-src/ompi/mca/coll/sm/memory-layout.ppt",
        "/tmp/vanessa/spack-stage/spack-stage-openmpi-master-qcrm7qmgqutvsby2zcmdb57s22lzfq65/spack-src/ompi/mpi/fortran/c_to_integer_kind_mapping.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-openmpi-master-qcrm7qmgqutvsby2zcmdb57s22lzfq65/spack-src/.git/objects/pack/pack-e739609ec548c46c3c452f38dac25e0d9f14e3a3.pack",
        "/tmp/vanessa/spack-stage/spack-stage-openmpi-master-qcrm7qmgqutvsby2zcmdb57s22lzfq65/spack-src/.git/objects/pack/pack-e739609ec548c46c3c452f38dac25e0d9f14e3a3.idx",
        "/tmp/vanessa/spack-stage/spack-stage-openmpi-master-qcrm7qmgqutvsby2zcmdb57s22lzfq65/spack-src/3rd-party/hwloc-2.2.0.tar.gz",
        "/tmp/vanessa/spack-stage/spack-stage-openmpi-master-qcrm7qmgqutvsby2zcmdb57s22lzfq65/spack-src/3rd-party/libevent-2.1.12-stable.tar.gz"
    ],
    "total_files": 5662
}