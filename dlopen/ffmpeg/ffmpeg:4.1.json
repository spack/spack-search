{
    "matches": {
        "/tmp/vanessa/spack-stage/spack-stage-ffmpeg-4.1-sdpvlh5k2flacnv4x524fsjycqueu4ji/spack-src/compat/w32dlfcn.h": "/*\n * This file is part of FFmpeg.\n *\n * FFmpeg is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License as published by the Free Software Foundation; either\n * version 2.1 of the License, or (at your option) any later version.\n *\n * FFmpeg is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with FFmpeg; if not, write to the Free Software\n * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n */\n\n#ifndef COMPAT_W32DLFCN_H\n#define COMPAT_W32DLFCN_H\n\n#ifdef _WIN32\n#include <windows.h>\n#include \"config.h\"\n#if (_WIN32_WINNT < 0x0602) || HAVE_WINRT\n#include \"libavutil/wchar_filename.h\"\n#endif\n/**\n * Safe function used to open dynamic libs. This attempts to improve program security\n * by removing the current directory from the dll search path. Only dll's found in the\n * executable or system directory are allowed to be loaded.\n * @param name  The dynamic lib name.\n * @return A handle to the opened lib.\n */\nstatic inline HMODULE win32_dlopen(const char *name)\n{\n#if _WIN32_WINNT < 0x0602\n    // Need to check if KB2533623 is available\n    if (!GetProcAddress(GetModuleHandleW(L\"kernel32.dll\"), \"SetDefaultDllDirectories\")) {\n        HMODULE module = NULL;\n        wchar_t *path = NULL, *name_w = NULL;\n        DWORD pathlen;\n        if (utf8towchar(name, &name_w))\n            goto exit;\n        path = (wchar_t *)av_mallocz_array(MAX_PATH, sizeof(wchar_t));\n        // Try local directory first\n        pathlen = GetModuleFileNameW(NULL, path, MAX_PATH);\n        pathlen = wcsrchr(path, '\\\\') - path;\n        if (pathlen == 0 || pathlen + wcslen(name_w) + 2 > MAX_PATH)\n            goto exit;\n        path[pathlen] = '\\\\';\n        wcscpy(path + pathlen + 1, name_w);\n        module = LoadLibraryExW(path, NULL, LOAD_WITH_ALTERED_SEARCH_PATH);\n        if (module == NULL) {\n            // Next try System32 directory\n            pathlen = GetSystemDirectoryW(path, MAX_PATH);\n            if (pathlen == 0 || pathlen + wcslen(name_w) + 2 > MAX_PATH)\n                goto exit;\n            path[pathlen] = '\\\\';\n            wcscpy(path + pathlen + 1, name_w);\n            module = LoadLibraryExW(path, NULL, LOAD_WITH_ALTERED_SEARCH_PATH);\n        }\nexit:\n        av_free(path);\n        av_free(name_w);\n        return module;\n    }\n#endif\n#ifndef LOAD_LIBRARY_SEARCH_APPLICATION_DIR\n#   define LOAD_LIBRARY_SEARCH_APPLICATION_DIR 0x00000200\n#endif\n#ifndef LOAD_LIBRARY_SEARCH_SYSTEM32\n#   define LOAD_LIBRARY_SEARCH_SYSTEM32        0x00000800\n#endif\n#if HAVE_WINRT\n    wchar_t *name_w = NULL;\n    int ret;\n    if (utf8towchar(name, &name_w))\n        return NULL;\n    ret = LoadPackagedLibrary(name_w, 0);\n    av_free(name_w);\n    return ret;\n#else\n    return LoadLibraryExA(name, NULL, LOAD_LIBRARY_SEARCH_APPLICATION_DIR | LOAD_LIBRARY_SEARCH_SYSTEM32);\n#endif\n}\n#define dlopen(name, flags) win32_dlopen(name)\n#define dlclose FreeLibrary\n#define dlsym GetProcAddress\n#else\n#include <dlfcn.h>\n#endif\n\n#endif /* COMPAT_W32DLFCN_H */\n",
        "/tmp/vanessa/spack-stage/spack-stage-ffmpeg-4.1-sdpvlh5k2flacnv4x524fsjycqueu4ji/spack-src/compat/cuda/dynlink_loader.h": "/*\n * This file is part of FFmpeg.\n *\n * FFmpeg is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License as published by the Free Software Foundation; either\n * version 2.1 of the License, or (at your option) any later version.\n *\n * FFmpeg is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with FFmpeg; if not, write to the Free Software\n * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n */\n\n#ifndef AV_COMPAT_CUDA_DYNLINK_LOADER_H\n#define AV_COMPAT_CUDA_DYNLINK_LOADER_H\n\n#include \"libavutil/log.h\"\n#include \"compat/w32dlfcn.h\"\n\n#define FFNV_LOAD_FUNC(path) dlopen((path), RTLD_LAZY)\n#define FFNV_SYM_FUNC(lib, sym) dlsym((lib), (sym))\n#define FFNV_FREE_FUNC(lib) dlclose(lib)\n#define FFNV_LOG_FUNC(logctx, msg, ...) av_log(logctx, AV_LOG_ERROR, msg,  __VA_ARGS__)\n#define FFNV_DEBUG_LOG_FUNC(logctx, msg, ...) av_log(logctx, AV_LOG_DEBUG, msg,  __VA_ARGS__)\n\n#include <ffnvcodec/dynlink_loader.h>\n\n#endif\n",
        "/tmp/vanessa/spack-stage/spack-stage-ffmpeg-4.1-sdpvlh5k2flacnv4x524fsjycqueu4ji/spack-src/libavformat/avisynth.c": "/*\n * AviSynth/AvxSynth support\n * Copyright (c) 2012 AvxSynth Team\n *\n * This file is part of FFmpeg\n *\n * FFmpeg is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License as published by the Free Software Foundation; either\n * version 2.1 of the License, or (at your option) any later version.\n *\n * FFmpeg is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with FFmpeg; if not, write to the Free Software\n * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n */\n\n#include \"libavutil/attributes.h\"\n#include \"libavutil/internal.h\"\n\n#include \"libavcodec/internal.h\"\n\n#include \"avformat.h\"\n#include \"internal.h\"\n#include \"config.h\"\n\n/* Enable function pointer definitions for runtime loading. */\n#define AVSC_NO_DECLSPEC\n\n/* Platform-specific directives for AviSynth vs AvxSynth. */\n#ifdef _WIN32\n  #include \"compat/w32dlfcn.h\"\n  #undef EXTERN_C\n  #include \"compat/avisynth/avisynth_c.h\"\n  #define AVISYNTH_LIB \"avisynth\"\n  #define USING_AVISYNTH\n#else\n  #include <dlfcn.h>\n  #include \"compat/avisynth/avxsynth_c.h\"\n  #define AVISYNTH_NAME \"libavxsynth\"\n  #define AVISYNTH_LIB AVISYNTH_NAME SLIBSUF\n#endif\n\ntypedef struct AviSynthLibrary {\n    void *library;\n#define AVSC_DECLARE_FUNC(name) name ## _func name\n    AVSC_DECLARE_FUNC(avs_bit_blt);\n    AVSC_DECLARE_FUNC(avs_clip_get_error);\n    AVSC_DECLARE_FUNC(avs_create_script_environment);\n    AVSC_DECLARE_FUNC(avs_delete_script_environment);\n    AVSC_DECLARE_FUNC(avs_get_audio);\n    AVSC_DECLARE_FUNC(avs_get_error);\n    AVSC_DECLARE_FUNC(avs_get_frame);\n    AVSC_DECLARE_FUNC(avs_get_version);\n    AVSC_DECLARE_FUNC(avs_get_video_info);\n    AVSC_DECLARE_FUNC(avs_invoke);\n    AVSC_DECLARE_FUNC(avs_release_clip);\n    AVSC_DECLARE_FUNC(avs_release_value);\n    AVSC_DECLARE_FUNC(avs_release_video_frame);\n    AVSC_DECLARE_FUNC(avs_take_clip);\n#ifdef USING_AVISYNTH\n    AVSC_DECLARE_FUNC(avs_bits_per_pixel);\n    AVSC_DECLARE_FUNC(avs_get_height_p);\n    AVSC_DECLARE_FUNC(avs_get_pitch_p);\n    AVSC_DECLARE_FUNC(avs_get_read_ptr_p);\n    AVSC_DECLARE_FUNC(avs_get_row_size_p);\n    AVSC_DECLARE_FUNC(avs_is_planar_rgb);\n    AVSC_DECLARE_FUNC(avs_is_planar_rgba);\n#endif\n#undef AVSC_DECLARE_FUNC\n} AviSynthLibrary;\n\ntypedef struct AviSynthContext {\n    AVS_ScriptEnvironment *env;\n    AVS_Clip *clip;\n    const AVS_VideoInfo *vi;\n\n    /* avisynth_read_packet_video() iterates over this. */\n    int n_planes;\n    const int *planes;\n\n    int curr_stream;\n    int curr_frame;\n    int64_t curr_sample;\n\n    int error;\n\n    /* Linked list pointers. */\n    struct AviSynthContext *next;\n} AviSynthContext;\n\nstatic const int avs_planes_packed[1] = { 0 };\nstatic const int avs_planes_grey[1]   = { AVS_PLANAR_Y };\nstatic const int avs_planes_yuv[3]    = { AVS_PLANAR_Y, AVS_PLANAR_U,\n                                          AVS_PLANAR_V };\n#ifdef USING_AVISYNTH\nstatic const int avs_planes_rgb[3]    = { AVS_PLANAR_G, AVS_PLANAR_B,\n                                          AVS_PLANAR_R };\nstatic const int avs_planes_yuva[4]   = { AVS_PLANAR_Y, AVS_PLANAR_U,\n                                          AVS_PLANAR_V, AVS_PLANAR_A };\nstatic const int avs_planes_rgba[4]   = { AVS_PLANAR_G, AVS_PLANAR_B,\n                                          AVS_PLANAR_R, AVS_PLANAR_A };\n#endif\n\n/* A conflict between C++ global objects, atexit, and dynamic loading requires\n * us to register our own atexit handler to prevent double freeing. */\nstatic AviSynthLibrary avs_library;\nstatic int avs_atexit_called        = 0;\n\n/* Linked list of AviSynthContexts. An atexit handler destroys this list. */\nstatic AviSynthContext *avs_ctx_list = NULL;\n\nstatic av_cold void avisynth_atexit_handler(void);\n\nstatic av_cold int avisynth_load_library(void)\n{\n    avs_library.library = dlopen(AVISYNTH_LIB, RTLD_NOW | RTLD_LOCAL);\n    if (!avs_library.library)\n        return AVERROR_UNKNOWN;\n\n#define LOAD_AVS_FUNC(name, continue_on_fail)                          \\\n        avs_library.name = dlsym(avs_library.library, #name);          \\\n        if (!continue_on_fail && !avs_library.name)                    \\\n            goto fail;\n\n    LOAD_AVS_FUNC(avs_bit_blt, 0);\n    LOAD_AVS_FUNC(avs_clip_get_error, 0);\n    LOAD_AVS_FUNC(avs_create_script_environment, 0);\n    LOAD_AVS_FUNC(avs_delete_script_environment, 0);\n    LOAD_AVS_FUNC(avs_get_audio, 0);\n    LOAD_AVS_FUNC(avs_get_error, 1); // New to AviSynth 2.6\n    LOAD_AVS_FUNC(avs_get_frame, 0);\n    LOAD_AVS_FUNC(avs_get_version, 0);\n    LOAD_AVS_FUNC(avs_get_video_info, 0);\n    LOAD_AVS_FUNC(avs_invoke, 0);\n    LOAD_AVS_FUNC(avs_release_clip, 0);\n    LOAD_AVS_FUNC(avs_release_value, 0);\n    LOAD_AVS_FUNC(avs_release_video_frame, 0);\n    LOAD_AVS_FUNC(avs_take_clip, 0);\n#ifdef USING_AVISYNTH\n    LOAD_AVS_FUNC(avs_bits_per_pixel, 1);\n    LOAD_AVS_FUNC(avs_get_height_p, 1);\n    LOAD_AVS_FUNC(avs_get_pitch_p, 1);\n    LOAD_AVS_FUNC(avs_get_read_ptr_p, 1);\n    LOAD_AVS_FUNC(avs_get_row_size_p, 1);\n    LOAD_AVS_FUNC(avs_is_planar_rgb, 1);\n    LOAD_AVS_FUNC(avs_is_planar_rgba, 1);\n#endif\n#undef LOAD_AVS_FUNC\n\n    atexit(avisynth_atexit_handler);\n    return 0;\n\nfail:\n    dlclose(avs_library.library);\n    return AVERROR_UNKNOWN;\n}\n\n/* Note that avisynth_context_create and avisynth_context_destroy\n * do not allocate or free the actual context! That is taken care of\n * by libavformat. */\nstatic av_cold int avisynth_context_create(AVFormatContext *s)\n{\n    AviSynthContext *avs = s->priv_data;\n    int ret;\n\n    if (!avs_library.library)\n        if (ret = avisynth_load_library())\n            return ret;\n\n    avs->env = avs_library.avs_create_script_environment(3);\n    if (avs_library.avs_get_error) {\n        const char *error = avs_library.avs_get_error(avs->env);\n        if (error) {\n            av_log(s, AV_LOG_ERROR, \"%s\\n\", error);\n            return AVERROR_UNKNOWN;\n        }\n    }\n\n    if (!avs_ctx_list) {\n        avs_ctx_list = avs;\n    } else {\n        avs->next    = avs_ctx_list;\n        avs_ctx_list = avs;\n    }\n\n    return 0;\n}\n\nstatic av_cold void avisynth_context_destroy(AviSynthContext *avs)\n{\n    if (avs_atexit_called)\n        return;\n\n    if (avs == avs_ctx_list) {\n        avs_ctx_list = avs->next;\n    } else {\n        AviSynthContext *prev = avs_ctx_list;\n        while (prev->next != avs)\n            prev = prev->next;\n        prev->next = avs->next;\n    }\n\n    if (avs->clip) {\n        avs_library.avs_release_clip(avs->clip);\n        avs->clip = NULL;\n    }\n    if (avs->env) {\n        avs_library.avs_delete_script_environment(avs->env);\n        avs->env = NULL;\n    }\n}\n\nstatic av_cold void avisynth_atexit_handler(void)\n{\n    AviSynthContext *avs = avs_ctx_list;\n\n    while (avs) {\n        AviSynthContext *next = avs->next;\n        avisynth_context_destroy(avs);\n        avs = next;\n    }\n    dlclose(avs_library.library);\n\n    avs_atexit_called = 1;\n}\n\n/* Create AVStream from audio and video data. */\nstatic int avisynth_create_stream_video(AVFormatContext *s, AVStream *st)\n{\n    AviSynthContext *avs = s->priv_data;\n    int planar = 0; // 0: packed, 1: YUV, 2: Y8, 3: Planar RGB, 4: YUVA, 5: Planar RGBA\n\n    st->codecpar->codec_type = AVMEDIA_TYPE_VIDEO;\n    st->codecpar->codec_id   = AV_CODEC_ID_RAWVIDEO;\n    st->codecpar->width      = avs->vi->width;\n    st->codecpar->height     = avs->vi->height;\n\n    st->avg_frame_rate    = (AVRational) { avs->vi->fps_numerator,\n                                           avs->vi->fps_denominator };\n    st->start_time        = 0;\n    st->duration          = avs->vi->num_frames;\n    st->nb_frames         = avs->vi->num_frames;\n    avpriv_set_pts_info(st, 32, avs->vi->fps_denominator, avs->vi->fps_numerator);\n\n    switch (avs->vi->pixel_type) {\n#ifdef USING_AVISYNTH\n    /* 10~16-bit YUV pix_fmts (AviSynth+) */\n    case AVS_CS_YUV444P10:\n        st->codecpar->format = AV_PIX_FMT_YUV444P10;\n        planar               = 1;\n        break;\n    case AVS_CS_YUV422P10:\n        st->codecpar->format = AV_PIX_FMT_YUV422P10;\n        planar               = 1;\n        break;\n    case AVS_CS_YUV420P10:\n        st->codecpar->format = AV_PIX_FMT_YUV420P10;\n        planar               = 1;\n        break;\n    case AVS_CS_YUV444P12:\n        st->codecpar->format = AV_PIX_FMT_YUV444P12;\n        planar               = 1;\n        break;\n    case AVS_CS_YUV422P12:\n        st->codecpar->format = AV_PIX_FMT_YUV422P12;\n        planar               = 1;\n        break;\n    case AVS_CS_YUV420P12:\n        st->codecpar->format = AV_PIX_FMT_YUV420P12;\n        planar               = 1;\n        break;\n    case AVS_CS_YUV444P14:\n        st->codecpar->format = AV_PIX_FMT_YUV444P14;\n        planar               = 1;\n        break;\n    case AVS_CS_YUV422P14:\n        st->codecpar->format = AV_PIX_FMT_YUV422P14;\n        planar               = 1;\n        break;\n    case AVS_CS_YUV420P14:\n        st->codecpar->format = AV_PIX_FMT_YUV420P14;\n        planar               = 1;\n        break;\n    case AVS_CS_YUV444P16:\n        st->codecpar->format = AV_PIX_FMT_YUV444P16;\n        planar               = 1;\n        break;\n    case AVS_CS_YUV422P16:\n        st->codecpar->format = AV_PIX_FMT_YUV422P16;\n        planar               = 1;\n        break;\n    case AVS_CS_YUV420P16:\n        st->codecpar->format = AV_PIX_FMT_YUV420P16;\n        planar               = 1;\n        break;\n    /* 8~16-bit YUV pix_fmts with Alpha (AviSynth+) */\n    case AVS_CS_YUVA444:\n        st->codecpar->format = AV_PIX_FMT_YUVA444P;\n        planar               = 4;\n        break;\n    case AVS_CS_YUVA422:\n        st->codecpar->format = AV_PIX_FMT_YUVA422P;\n        planar               = 4;\n        break;\n    case AVS_CS_YUVA420:\n        st->codecpar->format = AV_PIX_FMT_YUVA420P;\n        planar               = 4;\n        break;\n    case AVS_CS_YUVA444P10:\n        st->codecpar->format = AV_PIX_FMT_YUVA444P10;\n        planar               = 4;\n        break;\n    case AVS_CS_YUVA422P10:\n        st->codecpar->format = AV_PIX_FMT_YUVA422P10;\n        planar               = 4;\n        break;\n    case AVS_CS_YUVA420P10:\n        st->codecpar->format = AV_PIX_FMT_YUVA420P10;\n        planar               = 4;\n        break;\n    case AVS_CS_YUVA444P16:\n        st->codecpar->format = AV_PIX_FMT_YUVA444P16;\n        planar               = 4;\n        break;\n    case AVS_CS_YUVA422P16:\n        st->codecpar->format = AV_PIX_FMT_YUVA422P16;\n        planar               = 4;\n        break;\n    case AVS_CS_YUVA420P16:\n        st->codecpar->format = AV_PIX_FMT_YUVA420P16;\n        planar               = 4;\n        break;\n    /* Planar RGB pix_fmts (AviSynth+) */\n    case AVS_CS_RGBP:\n        st->codecpar->format = AV_PIX_FMT_GBRP;\n        planar               = 3;\n        break;\n    case AVS_CS_RGBP10:\n        st->codecpar->format = AV_PIX_FMT_GBRP10;\n        planar               = 3;\n        break;\n    case AVS_CS_RGBP12:\n        st->codecpar->format = AV_PIX_FMT_GBRP12;\n        planar               = 3;\n        break;\n    case AVS_CS_RGBP14:\n        st->codecpar->format = AV_PIX_FMT_GBRP14;\n        planar               = 3;\n        break;\n    case AVS_CS_RGBP16:\n        st->codecpar->format = AV_PIX_FMT_GBRP16;\n        planar               = 3;\n        break;\n    /* Planar RGB pix_fmts with Alpha (AviSynth+) */\n    case AVS_CS_RGBAP:\n        st->codecpar->format = AV_PIX_FMT_GBRAP;\n        planar               = 5;\n        break;\n    case AVS_CS_RGBAP10:\n        st->codecpar->format = AV_PIX_FMT_GBRAP10;\n        planar               = 5;\n        break;\n    case AVS_CS_RGBAP12:\n        st->codecpar->format = AV_PIX_FMT_GBRAP12;\n        planar               = 5;\n        break;\n    case AVS_CS_RGBAP16:\n        st->codecpar->format = AV_PIX_FMT_GBRAP16;\n        planar               = 5;\n        break;\n    /* GRAY16 (AviSynth+) */\n    case AVS_CS_Y16:\n        st->codecpar->format = AV_PIX_FMT_GRAY16;\n        planar               = 2;\n        break;\n    /* pix_fmts added in AviSynth 2.6 */\n    case AVS_CS_YV24:\n        st->codecpar->format = AV_PIX_FMT_YUV444P;\n        planar               = 1;\n        break;\n    case AVS_CS_YV16:\n        st->codecpar->format = AV_PIX_FMT_YUV422P;\n        planar               = 1;\n        break;\n    case AVS_CS_YV411:\n        st->codecpar->format = AV_PIX_FMT_YUV411P;\n        planar               = 1;\n        break;\n    case AVS_CS_Y8:\n        st->codecpar->format = AV_PIX_FMT_GRAY8;\n        planar               = 2;\n        break;\n    /* 16-bit packed RGB pix_fmts (AviSynth+) */\n    case AVS_CS_BGR48:\n        st->codecpar->format = AV_PIX_FMT_BGR48;\n        break;\n    case AVS_CS_BGR64:\n        st->codecpar->format = AV_PIX_FMT_BGRA64;\n        break;\n#endif\n    /* AviSynth 2.5 and AvxSynth pix_fmts */\n    case AVS_CS_BGR24:\n        st->codecpar->format = AV_PIX_FMT_BGR24;\n        break;\n    case AVS_CS_BGR32:\n        st->codecpar->format = AV_PIX_FMT_RGB32;\n        break;\n    case AVS_CS_YUY2:\n        st->codecpar->format = AV_PIX_FMT_YUYV422;\n        break;\n    case AVS_CS_YV12:\n        st->codecpar->format = AV_PIX_FMT_YUV420P;\n        planar               = 1;\n        break;\n    case AVS_CS_I420: // Is this even used anywhere?\n        st->codecpar->format = AV_PIX_FMT_YUV420P;\n        planar               = 1;\n        break;\n    default:\n        av_log(s, AV_LOG_ERROR,\n               \"unknown AviSynth colorspace %d\\n\", avs->vi->pixel_type);\n        avs->error = 1;\n        return AVERROR_UNKNOWN;\n    }\n\n    switch (planar) {\n#ifdef USING_AVISYNTH\n    case 5: // Planar RGB + Alpha\n        avs->n_planes = 4;\n        avs->planes   = avs_planes_rgba;\n        break;\n    case 4: // YUV + Alpha\n        avs->n_planes = 4;\n        avs->planes   = avs_planes_yuva;\n        break;\n    case 3: // Planar RGB\n        avs->n_planes = 3;\n        avs->planes   = avs_planes_rgb;\n        break;\n#endif\n    case 2: // Y8\n        avs->n_planes = 1;\n        avs->planes   = avs_planes_grey;\n        break;\n    case 1: // YUV\n        avs->n_planes = 3;\n        avs->planes   = avs_planes_yuv;\n        break;\n    default:\n        avs->n_planes = 1;\n        avs->planes   = avs_planes_packed;\n    }\n    return 0;\n}\n\nstatic int avisynth_create_stream_audio(AVFormatContext *s, AVStream *st)\n{\n    AviSynthContext *avs = s->priv_data;\n\n    st->codecpar->codec_type  = AVMEDIA_TYPE_AUDIO;\n    st->codecpar->sample_rate = avs->vi->audio_samples_per_second;\n    st->codecpar->channels    = avs->vi->nchannels;\n    st->duration              = avs->vi->num_audio_samples;\n    avpriv_set_pts_info(st, 64, 1, avs->vi->audio_samples_per_second);\n\n    switch (avs->vi->sample_type) {\n    case AVS_SAMPLE_INT8:\n        st->codecpar->codec_id = AV_CODEC_ID_PCM_U8;\n        break;\n    case AVS_SAMPLE_INT16:\n        st->codecpar->codec_id = AV_CODEC_ID_PCM_S16LE;\n        break;\n    case AVS_SAMPLE_INT24:\n        st->codecpar->codec_id = AV_CODEC_ID_PCM_S24LE;\n        break;\n    case AVS_SAMPLE_INT32:\n        st->codecpar->codec_id = AV_CODEC_ID_PCM_S32LE;\n        break;\n    case AVS_SAMPLE_FLOAT:\n        st->codecpar->codec_id = AV_CODEC_ID_PCM_F32LE;\n        break;\n    default:\n        av_log(s, AV_LOG_ERROR,\n               \"unknown AviSynth sample type %d\\n\", avs->vi->sample_type);\n        avs->error = 1;\n        return AVERROR_UNKNOWN;\n    }\n    return 0;\n}\n\nstatic int avisynth_create_stream(AVFormatContext *s)\n{\n    AviSynthContext *avs = s->priv_data;\n    AVStream *st;\n    int ret;\n    int id = 0;\n\n    if (avs_has_video(avs->vi)) {\n        st = avformat_new_stream(s, NULL);\n        if (!st)\n            return AVERROR_UNKNOWN;\n        st->id = id++;\n        if (ret = avisynth_create_stream_video(s, st))\n            return ret;\n    }\n    if (avs_has_audio(avs->vi)) {\n        st = avformat_new_stream(s, NULL);\n        if (!st)\n            return AVERROR_UNKNOWN;\n        st->id = id++;\n        if (ret = avisynth_create_stream_audio(s, st))\n            return ret;\n    }\n    return 0;\n}\n\nstatic int avisynth_open_file(AVFormatContext *s)\n{\n    AviSynthContext *avs = s->priv_data;\n    AVS_Value arg, val;\n    int ret;\n#ifdef USING_AVISYNTH\n    char filename_ansi[MAX_PATH * 4];\n    wchar_t filename_wc[MAX_PATH * 4];\n#endif\n\n    if (ret = avisynth_context_create(s))\n        return ret;\n\n#ifdef USING_AVISYNTH\n    /* Convert UTF-8 to ANSI code page */\n    MultiByteToWideChar(CP_UTF8, 0, s->filename, -1, filename_wc, MAX_PATH * 4);\n    WideCharToMultiByte(CP_THREAD_ACP, 0, filename_wc, -1, filename_ansi,\n                        MAX_PATH * 4, NULL, NULL);\n    arg = avs_new_value_string(filename_ansi);\n#else\n    arg = avs_new_value_string(s->filename);\n#endif\n    val = avs_library.avs_invoke(avs->env, \"Import\", arg, 0);\n    if (avs_is_error(val)) {\n        av_log(s, AV_LOG_ERROR, \"%s\\n\", avs_as_error(val));\n        ret = AVERROR_UNKNOWN;\n        goto fail;\n    }\n    if (!avs_is_clip(val)) {\n        av_log(s, AV_LOG_ERROR, \"AviSynth script did not return a clip\\n\");\n        ret = AVERROR_UNKNOWN;\n        goto fail;\n    }\n\n    avs->clip = avs_library.avs_take_clip(val, avs->env);\n    avs->vi   = avs_library.avs_get_video_info(avs->clip);\n\n#ifdef USING_AVISYNTH\n    /* On Windows, FFmpeg supports AviSynth interface version 6 or higher.\n     * This includes AviSynth 2.6 RC1 or higher, and AviSynth+ r1718 or higher,\n     * and excludes 2.5 and the 2.6 alphas. Since AvxSynth identifies itself\n     * as interface version 3 like 2.5.8, this needs to be special-cased. */\n\n    if (avs_library.avs_get_version(avs->clip) < 6) {\n        av_log(s, AV_LOG_ERROR,\n               \"AviSynth version is too old. Please upgrade to either AviSynth 2.6 >= RC1 or AviSynth+ >= r1718.\\n\");\n        ret = AVERROR_UNKNOWN;\n        goto fail;\n    }\n#endif\n\n    /* Release the AVS_Value as it will go out of scope. */\n    avs_library.avs_release_value(val);\n\n    if (ret = avisynth_create_stream(s))\n        goto fail;\n\n    return 0;\n\nfail:\n    avisynth_context_destroy(avs);\n    return ret;\n}\n\nstatic void avisynth_next_stream(AVFormatContext *s, AVStream **st,\n                                 AVPacket *pkt, int *discard)\n{\n    AviSynthContext *avs = s->priv_data;\n\n    avs->curr_stream++;\n    avs->curr_stream %= s->nb_streams;\n\n    *st = s->streams[avs->curr_stream];\n    if ((*st)->discard == AVDISCARD_ALL)\n        *discard = 1;\n    else\n        *discard = 0;\n\n    return;\n}\n\n/* Copy AviSynth clip data into an AVPacket. */\nstatic int avisynth_read_packet_video(AVFormatContext *s, AVPacket *pkt,\n                                      int discard)\n{\n    AviSynthContext *avs = s->priv_data;\n    AVS_VideoFrame *frame;\n    unsigned char *dst_p;\n    const unsigned char *src_p;\n    int n, i, plane, rowsize, planeheight, pitch, bits;\n    const char *error;\n    int avsplus av_unused;\n\n    if (avs->curr_frame >= avs->vi->num_frames)\n        return AVERROR_EOF;\n\n    /* This must happen even if the stream is discarded to prevent desync. */\n    n = avs->curr_frame++;\n    if (discard)\n        return 0;\n\n#ifdef USING_AVISYNTH\n    /* Detect whether we're using AviSynth 2.6 or AviSynth+ by\n     * looking for whether avs_is_planar_rgb exists. */\n    if (GetProcAddress(avs_library.library, \"avs_is_planar_rgb\") == NULL)\n        avsplus = 0;\n    else\n        avsplus = 1;\n\n    /* avs_bits_per_pixel changed to AVSC_API with AviSynth 2.6, which\n     * requires going through avs_library, while AvxSynth has it under\n     * the older AVSC_INLINE type, so special-case this. */\n\n    bits = avs_library.avs_bits_per_pixel(avs->vi);\n#else\n    bits = avs_bits_per_pixel(avs->vi);\n#endif\n\n    /* Without the cast to int64_t, calculation overflows at about 9k x 9k\n     * resolution. */\n    pkt->size = (((int64_t)avs->vi->width *\n                  (int64_t)avs->vi->height) * bits) / 8;\n    if (!pkt->size)\n        return AVERROR_UNKNOWN;\n\n    if (av_new_packet(pkt, pkt->size) < 0)\n        return AVERROR(ENOMEM);\n\n    pkt->pts      = n;\n    pkt->dts      = n;\n    pkt->duration = 1;\n    pkt->stream_index = avs->curr_stream;\n\n    frame = avs_library.avs_get_frame(avs->clip, n);\n    error = avs_library.avs_clip_get_error(avs->clip);\n    if (error) {\n        av_log(s, AV_LOG_ERROR, \"%s\\n\", error);\n        avs->error = 1;\n        av_packet_unref(pkt);\n        return AVERROR_UNKNOWN;\n    }\n\n    dst_p = pkt->data;\n    for (i = 0; i < avs->n_planes; i++) {\n        plane = avs->planes[i];\n#ifdef USING_AVISYNTH\n        src_p = avs_library.avs_get_read_ptr_p(frame, plane);\n        pitch = avs_library.avs_get_pitch_p(frame, plane);\n\n        rowsize     = avs_library.avs_get_row_size_p(frame, plane);\n        planeheight = avs_library.avs_get_height_p(frame, plane);\n#else\n        src_p = avs_get_read_ptr_p(frame, plane);\n        pitch = avs_get_pitch_p(frame, plane);\n\n        rowsize     = avs_get_row_size_p(frame, plane);\n        planeheight = avs_get_height_p(frame, plane);\n#endif\n\n        /* Flip RGB video. */\n        if (avs_is_rgb24(avs->vi) || avs_is_rgb(avs->vi)) {\n            src_p = src_p + (planeheight - 1) * pitch;\n            pitch = -pitch;\n        }\n\n#ifdef USING_AVISYNTH\n        /* Flip Planar RGB video */\n        if (avsplus && (avs_library.avs_is_planar_rgb(avs->vi) ||\n                        avs_library.avs_is_planar_rgba(avs->vi))) {\n            src_p = src_p + (planeheight - 1) * pitch;\n            pitch = -pitch;\n        }\n#endif\n\n        avs_library.avs_bit_blt(avs->env, dst_p, rowsize, src_p, pitch,\n                                 rowsize, planeheight);\n        dst_p += rowsize * planeheight;\n    }\n\n    avs_library.avs_release_video_frame(frame);\n    return 0;\n}\n\nstatic int avisynth_read_packet_audio(AVFormatContext *s, AVPacket *pkt,\n                                      int discard)\n{\n    AviSynthContext *avs = s->priv_data;\n    AVRational fps, samplerate;\n    int samples;\n    int64_t n;\n    const char *error;\n\n    if (avs->curr_sample >= avs->vi->num_audio_samples)\n        return AVERROR_EOF;\n\n    fps.num        = avs->vi->fps_numerator;\n    fps.den        = avs->vi->fps_denominator;\n    samplerate.num = avs->vi->audio_samples_per_second;\n    samplerate.den = 1;\n\n    if (avs_has_video(avs->vi)) {\n        if (avs->curr_frame < avs->vi->num_frames)\n            samples = av_rescale_q(avs->curr_frame, samplerate, fps) -\n                      avs->curr_sample;\n        else\n            samples = av_rescale_q(1, samplerate, fps);\n    } else {\n        samples = 1000;\n    }\n\n    /* After seeking, audio may catch up with video. */\n    if (samples <= 0) {\n        pkt->size = 0;\n        pkt->data = NULL;\n        return 0;\n    }\n\n    if (avs->curr_sample + samples > avs->vi->num_audio_samples)\n        samples = avs->vi->num_audio_samples - avs->curr_sample;\n\n    /* This must happen even if the stream is discarded to prevent desync. */\n    n                 = avs->curr_sample;\n    avs->curr_sample += samples;\n    if (discard)\n        return 0;\n\n    pkt->size = avs_bytes_per_channel_sample(avs->vi) *\n                samples * avs->vi->nchannels;\n    if (!pkt->size)\n        return AVERROR_UNKNOWN;\n\n    if (av_new_packet(pkt, pkt->size) < 0)\n        return AVERROR(ENOMEM);\n\n    pkt->pts      = n;\n    pkt->dts      = n;\n    pkt->duration = samples;\n    pkt->stream_index = avs->curr_stream;\n\n    avs_library.avs_get_audio(avs->clip, pkt->data, n, samples);\n    error = avs_library.avs_clip_get_error(avs->clip);\n    if (error) {\n        av_log(s, AV_LOG_ERROR, \"%s\\n\", error);\n        avs->error = 1;\n        av_packet_unref(pkt);\n        return AVERROR_UNKNOWN;\n    }\n    return 0;\n}\n\nstatic av_cold int avisynth_read_header(AVFormatContext *s)\n{\n    int ret;\n\n    // Calling library must implement a lock for thread-safe opens.\n    if (ret = ff_lock_avformat())\n        return ret;\n\n    if (ret = avisynth_open_file(s)) {\n        ff_unlock_avformat();\n        return ret;\n    }\n\n    ff_unlock_avformat();\n    return 0;\n}\n\nstatic int avisynth_read_packet(AVFormatContext *s, AVPacket *pkt)\n{\n    AviSynthContext *avs = s->priv_data;\n    AVStream *st;\n    int discard = 0;\n    int ret;\n\n    if (avs->error)\n        return AVERROR_UNKNOWN;\n\n    /* If either stream reaches EOF, try to read the other one before\n     * giving up. */\n    avisynth_next_stream(s, &st, pkt, &discard);\n    if (st->codecpar->codec_type == AVMEDIA_TYPE_VIDEO) {\n        ret = avisynth_read_packet_video(s, pkt, discard);\n        if (ret == AVERROR_EOF && avs_has_audio(avs->vi)) {\n            avisynth_next_stream(s, &st, pkt, &discard);\n            return avisynth_read_packet_audio(s, pkt, discard);\n        }\n    } else {\n        ret = avisynth_read_packet_audio(s, pkt, discard);\n        if (ret == AVERROR_EOF && avs_has_video(avs->vi)) {\n            avisynth_next_stream(s, &st, pkt, &discard);\n            return avisynth_read_packet_video(s, pkt, discard);\n        }\n    }\n\n    return ret;\n}\n\nstatic av_cold int avisynth_read_close(AVFormatContext *s)\n{\n    if (ff_lock_avformat())\n        return AVERROR_UNKNOWN;\n\n    avisynth_context_destroy(s->priv_data);\n    ff_unlock_avformat();\n    return 0;\n}\n\nstatic int avisynth_read_seek(AVFormatContext *s, int stream_index,\n                              int64_t timestamp, int flags)\n{\n    AviSynthContext *avs = s->priv_data;\n    AVStream *st;\n    AVRational fps, samplerate;\n\n    if (avs->error)\n        return AVERROR_UNKNOWN;\n\n    fps        = (AVRational) { avs->vi->fps_numerator,\n                                avs->vi->fps_denominator };\n    samplerate = (AVRational) { avs->vi->audio_samples_per_second, 1 };\n\n    st = s->streams[stream_index];\n    if (st->codecpar->codec_type == AVMEDIA_TYPE_VIDEO) {\n        /* AviSynth frame counts are signed int. */\n        if ((timestamp >= avs->vi->num_frames) ||\n            (timestamp > INT_MAX)              ||\n            (timestamp < 0))\n            return AVERROR_EOF;\n        avs->curr_frame = timestamp;\n        if (avs_has_audio(avs->vi))\n            avs->curr_sample = av_rescale_q(timestamp, samplerate, fps);\n    } else {\n        if ((timestamp >= avs->vi->num_audio_samples) || (timestamp < 0))\n            return AVERROR_EOF;\n        /* Force frame granularity for seeking. */\n        if (avs_has_video(avs->vi)) {\n            avs->curr_frame  = av_rescale_q(timestamp, fps, samplerate);\n            avs->curr_sample = av_rescale_q(avs->curr_frame, samplerate, fps);\n        } else {\n            avs->curr_sample = timestamp;\n        }\n    }\n\n    return 0;\n}\n\nAVInputFormat ff_avisynth_demuxer = {\n    .name           = \"avisynth\",\n    .long_name      = NULL_IF_CONFIG_SMALL(\"AviSynth script\"),\n    .priv_data_size = sizeof(AviSynthContext),\n    .read_header    = avisynth_read_header,\n    .read_packet    = avisynth_read_packet,\n    .read_close     = avisynth_read_close,\n    .read_seek      = avisynth_read_seek,\n    .extensions     = \"avs\",\n};\n",
        "/tmp/vanessa/spack-stage/spack-stage-ffmpeg-4.1-sdpvlh5k2flacnv4x524fsjycqueu4ji/spack-src/libavfilter/vf_frei0r.c": "/*\n * Copyright (c) 2010 Stefano Sabatini\n * This file is part of FFmpeg.\n *\n * FFmpeg is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License as published by the Free Software Foundation; either\n * version 2.1 of the License, or (at your option) any later version.\n *\n * FFmpeg is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with FFmpeg; if not, write to the Free Software\n * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n */\n\n/**\n * @file\n * frei0r wrapper\n */\n\n#include <dlfcn.h>\n#include <frei0r.h>\n#include <stdio.h>\n#include <string.h>\n#include <stdlib.h>\n#include \"config.h\"\n#include \"libavutil/avstring.h\"\n#include \"libavutil/common.h\"\n#include \"libavutil/eval.h\"\n#include \"libavutil/imgutils.h\"\n#include \"libavutil/internal.h\"\n#include \"libavutil/mathematics.h\"\n#include \"libavutil/mem.h\"\n#include \"libavutil/opt.h\"\n#include \"libavutil/parseutils.h\"\n#include \"avfilter.h\"\n#include \"formats.h\"\n#include \"internal.h\"\n#include \"video.h\"\n\ntypedef f0r_instance_t (*f0r_construct_f)(unsigned int width, unsigned int height);\ntypedef void (*f0r_destruct_f)(f0r_instance_t instance);\ntypedef void (*f0r_deinit_f)(void);\ntypedef int (*f0r_init_f)(void);\ntypedef void (*f0r_get_plugin_info_f)(f0r_plugin_info_t *info);\ntypedef void (*f0r_get_param_info_f)(f0r_param_info_t *info, int param_index);\ntypedef void (*f0r_update_f)(f0r_instance_t instance, double time, const uint32_t *inframe, uint32_t *outframe);\ntypedef void (*f0r_update2_f)(f0r_instance_t instance, double time, const uint32_t *inframe1, const uint32_t *inframe2, const uint32_t *inframe3, uint32_t *outframe);\ntypedef void (*f0r_set_param_value_f)(f0r_instance_t instance, f0r_param_t param, int param_index);\ntypedef void (*f0r_get_param_value_f)(f0r_instance_t instance, f0r_param_t param, int param_index);\n\ntypedef struct Frei0rContext {\n    const AVClass *class;\n    f0r_update_f update;\n    void *dl_handle;            /* dynamic library handle   */\n    f0r_instance_t instance;\n    f0r_plugin_info_t plugin_info;\n\n    f0r_get_param_info_f  get_param_info;\n    f0r_get_param_value_f get_param_value;\n    f0r_set_param_value_f set_param_value;\n    f0r_construct_f       construct;\n    f0r_destruct_f        destruct;\n    f0r_deinit_f          deinit;\n\n    char *dl_name;\n    char *params;\n    AVRational framerate;\n\n    /* only used by the source */\n    int w, h;\n    AVRational time_base;\n    uint64_t pts;\n} Frei0rContext;\n\nstatic void *load_sym(AVFilterContext *ctx, const char *sym_name)\n{\n    Frei0rContext *s = ctx->priv;\n    void *sym = dlsym(s->dl_handle, sym_name);\n    if (!sym)\n        av_log(ctx, AV_LOG_ERROR, \"Could not find symbol '%s' in loaded module.\\n\", sym_name);\n    return sym;\n}\n\nstatic int set_param(AVFilterContext *ctx, f0r_param_info_t info, int index, char *param)\n{\n    Frei0rContext *s = ctx->priv;\n    union {\n        double d;\n        f0r_param_color_t col;\n        f0r_param_position_t pos;\n        f0r_param_string *str;\n    } val;\n    char *tail;\n    uint8_t rgba[4];\n\n    switch (info.type) {\n    case F0R_PARAM_BOOL:\n        if      (!strcmp(param, \"y\")) val.d = 1.0;\n        else if (!strcmp(param, \"n\")) val.d = 0.0;\n        else goto fail;\n        break;\n\n    case F0R_PARAM_DOUBLE:\n        val.d = av_strtod(param, &tail);\n        if (*tail || val.d == HUGE_VAL)\n            goto fail;\n        break;\n\n    case F0R_PARAM_COLOR:\n        if (sscanf(param, \"%f/%f/%f\", &val.col.r, &val.col.g, &val.col.b) != 3) {\n            if (av_parse_color(rgba, param, -1, ctx) < 0)\n                goto fail;\n            val.col.r = rgba[0] / 255.0;\n            val.col.g = rgba[1] / 255.0;\n            val.col.b = rgba[2] / 255.0;\n        }\n        break;\n\n    case F0R_PARAM_POSITION:\n        if (sscanf(param, \"%lf/%lf\", &val.pos.x, &val.pos.y) != 2)\n            goto fail;\n        break;\n\n    case F0R_PARAM_STRING:\n        val.str = param;\n        break;\n    }\n\n    s->set_param_value(s->instance, &val, index);\n    return 0;\n\nfail:\n    av_log(ctx, AV_LOG_ERROR, \"Invalid value '%s' for parameter '%s'.\\n\",\n           param, info.name);\n    return AVERROR(EINVAL);\n}\n\nstatic int set_params(AVFilterContext *ctx, const char *params)\n{\n    Frei0rContext *s = ctx->priv;\n    int i;\n\n    if (!params)\n        return 0;\n\n    for (i = 0; i < s->plugin_info.num_params; i++) {\n        f0r_param_info_t info;\n        char *param;\n        int ret;\n\n        s->get_param_info(&info, i);\n\n        if (*params) {\n            if (!(param = av_get_token(&params, \"|\")))\n                return AVERROR(ENOMEM);\n            if (*params)\n                params++;               /* skip ':' */\n            ret = set_param(ctx, info, i, param);\n            av_free(param);\n            if (ret < 0)\n                return ret;\n        }\n    }\n\n    return 0;\n}\n\nstatic int load_path(AVFilterContext *ctx, void **handle_ptr, const char *prefix, const char *name)\n{\n    char *path = av_asprintf(\"%s%s%s\", prefix, name, SLIBSUF);\n    if (!path)\n        return AVERROR(ENOMEM);\n    av_log(ctx, AV_LOG_DEBUG, \"Looking for frei0r effect in '%s'.\\n\", path);\n    *handle_ptr = dlopen(path, RTLD_NOW|RTLD_LOCAL);\n    av_free(path);\n    return 0;\n}\n\nstatic av_cold int frei0r_init(AVFilterContext *ctx,\n                               const char *dl_name, int type)\n{\n    Frei0rContext *s = ctx->priv;\n    f0r_init_f            f0r_init;\n    f0r_get_plugin_info_f f0r_get_plugin_info;\n    f0r_plugin_info_t *pi;\n    char *path;\n    int ret = 0;\n    int i;\n    static const char* const frei0r_pathlist[] = {\n        \"/usr/local/lib/frei0r-1/\",\n        \"/usr/lib/frei0r-1/\",\n        \"/usr/local/lib64/frei0r-1/\",\n        \"/usr/lib64/frei0r-1/\"\n    };\n\n    if (!dl_name) {\n        av_log(ctx, AV_LOG_ERROR, \"No filter name provided.\\n\");\n        return AVERROR(EINVAL);\n    }\n\n    /* see: http://frei0r.dyne.org/codedoc/html/group__pluglocations.html */\n    if ((path = av_strdup(getenv(\"FREI0R_PATH\")))) {\n#ifdef _WIN32\n        const char *separator = \";\";\n#else\n        const char *separator = \":\";\n#endif\n        char *p, *ptr = NULL;\n        for (p = path; p = av_strtok(p, separator, &ptr); p = NULL) {\n            /* add additional trailing slash in case it is missing */\n            char *p1 = av_asprintf(\"%s/\", p);\n            if (!p1) {\n                ret = AVERROR(ENOMEM);\n                goto check_path_end;\n            }\n            ret = load_path(ctx, &s->dl_handle, p1, dl_name);\n            av_free(p1);\n            if (ret < 0)\n                goto check_path_end;\n            if (s->dl_handle)\n                break;\n        }\n\n    check_path_end:\n        av_free(path);\n        if (ret < 0)\n            return ret;\n    }\n    if (!s->dl_handle && (path = getenv(\"HOME\"))) {\n        char *prefix = av_asprintf(\"%s/.frei0r-1/lib/\", path);\n        if (!prefix)\n            return AVERROR(ENOMEM);\n        ret = load_path(ctx, &s->dl_handle, prefix, dl_name);\n        av_free(prefix);\n        if (ret < 0)\n            return ret;\n    }\n    for (i = 0; !s->dl_handle && i < FF_ARRAY_ELEMS(frei0r_pathlist); i++) {\n        ret = load_path(ctx, &s->dl_handle, frei0r_pathlist[i], dl_name);\n        if (ret < 0)\n            return ret;\n    }\n    if (!s->dl_handle) {\n        av_log(ctx, AV_LOG_ERROR, \"Could not find module '%s'.\\n\", dl_name);\n        return AVERROR(EINVAL);\n    }\n\n    if (!(f0r_init                = load_sym(ctx, \"f0r_init\"           )) ||\n        !(f0r_get_plugin_info     = load_sym(ctx, \"f0r_get_plugin_info\")) ||\n        !(s->get_param_info  = load_sym(ctx, \"f0r_get_param_info\" )) ||\n        !(s->get_param_value = load_sym(ctx, \"f0r_get_param_value\")) ||\n        !(s->set_param_value = load_sym(ctx, \"f0r_set_param_value\")) ||\n        !(s->update          = load_sym(ctx, \"f0r_update\"         )) ||\n        !(s->construct       = load_sym(ctx, \"f0r_construct\"      )) ||\n        !(s->destruct        = load_sym(ctx, \"f0r_destruct\"       )) ||\n        !(s->deinit          = load_sym(ctx, \"f0r_deinit\"         )))\n        return AVERROR(EINVAL);\n\n    if (f0r_init() < 0) {\n        av_log(ctx, AV_LOG_ERROR, \"Could not init the frei0r module.\\n\");\n        return AVERROR(EINVAL);\n    }\n\n    f0r_get_plugin_info(&s->plugin_info);\n    pi = &s->plugin_info;\n    if (pi->plugin_type != type) {\n        av_log(ctx, AV_LOG_ERROR,\n               \"Invalid type '%s' for this plugin\\n\",\n               pi->plugin_type == F0R_PLUGIN_TYPE_FILTER ? \"filter\" :\n               pi->plugin_type == F0R_PLUGIN_TYPE_SOURCE ? \"source\" :\n               pi->plugin_type == F0R_PLUGIN_TYPE_MIXER2 ? \"mixer2\" :\n               pi->plugin_type == F0R_PLUGIN_TYPE_MIXER3 ? \"mixer3\" : \"unknown\");\n        return AVERROR(EINVAL);\n    }\n\n    av_log(ctx, AV_LOG_VERBOSE,\n           \"name:%s author:'%s' explanation:'%s' color_model:%s \"\n           \"frei0r_version:%d version:%d.%d num_params:%d\\n\",\n           pi->name, pi->author, pi->explanation,\n           pi->color_model == F0R_COLOR_MODEL_BGRA8888 ? \"bgra8888\" :\n           pi->color_model == F0R_COLOR_MODEL_RGBA8888 ? \"rgba8888\" :\n           pi->color_model == F0R_COLOR_MODEL_PACKED32 ? \"packed32\" : \"unknown\",\n           pi->frei0r_version, pi->major_version, pi->minor_version, pi->num_params);\n\n    return 0;\n}\n\nstatic av_cold int filter_init(AVFilterContext *ctx)\n{\n    Frei0rContext *s = ctx->priv;\n\n    return frei0r_init(ctx, s->dl_name, F0R_PLUGIN_TYPE_FILTER);\n}\n\nstatic av_cold void uninit(AVFilterContext *ctx)\n{\n    Frei0rContext *s = ctx->priv;\n\n    if (s->destruct && s->instance)\n        s->destruct(s->instance);\n    if (s->deinit)\n        s->deinit();\n    if (s->dl_handle)\n        dlclose(s->dl_handle);\n}\n\nstatic int config_input_props(AVFilterLink *inlink)\n{\n    AVFilterContext *ctx = inlink->dst;\n    Frei0rContext *s = ctx->priv;\n\n    if (s->destruct && s->instance)\n        s->destruct(s->instance);\n    if (!(s->instance = s->construct(inlink->w, inlink->h))) {\n        av_log(ctx, AV_LOG_ERROR, \"Impossible to load frei0r instance.\\n\");\n        return AVERROR(EINVAL);\n    }\n\n    return set_params(ctx, s->params);\n}\n\nstatic int query_formats(AVFilterContext *ctx)\n{\n    Frei0rContext *s = ctx->priv;\n    AVFilterFormats *formats = NULL;\n    int ret;\n\n    if        (s->plugin_info.color_model == F0R_COLOR_MODEL_BGRA8888) {\n        if ((ret = ff_add_format(&formats, AV_PIX_FMT_BGRA)) < 0)\n            return ret;\n    } else if (s->plugin_info.color_model == F0R_COLOR_MODEL_RGBA8888) {\n        if ((ret = ff_add_format(&formats, AV_PIX_FMT_RGBA)) < 0)\n            return ret;\n    } else {                                   /* F0R_COLOR_MODEL_PACKED32 */\n        static const enum AVPixelFormat pix_fmts[] = {\n            AV_PIX_FMT_BGRA, AV_PIX_FMT_ARGB, AV_PIX_FMT_ABGR, AV_PIX_FMT_ARGB, AV_PIX_FMT_NONE\n        };\n        formats = ff_make_format_list(pix_fmts);\n    }\n\n    if (!formats)\n        return AVERROR(ENOMEM);\n\n    return ff_set_common_formats(ctx, formats);\n}\n\nstatic int filter_frame(AVFilterLink *inlink, AVFrame *in)\n{\n    Frei0rContext *s = inlink->dst->priv;\n    AVFilterLink *outlink = inlink->dst->outputs[0];\n    AVFrame *out;\n\n    out = ff_get_video_buffer(outlink, outlink->w, outlink->h);\n    if (!out) {\n        av_frame_free(&in);\n        return AVERROR(ENOMEM);\n    }\n    av_frame_copy_props(out, in);\n\n    s->update(s->instance, in->pts * av_q2d(inlink->time_base) * 1000,\n                   (const uint32_t *)in->data[0],\n                   (uint32_t *)out->data[0]);\n\n    av_frame_free(&in);\n\n    return ff_filter_frame(outlink, out);\n}\n\n#define OFFSET(x) offsetof(Frei0rContext, x)\n#define FLAGS AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_FILTERING_PARAM\nstatic const AVOption frei0r_options[] = {\n    { \"filter_name\",   NULL, OFFSET(dl_name), AV_OPT_TYPE_STRING, .flags = FLAGS },\n    { \"filter_params\", NULL, OFFSET(params),  AV_OPT_TYPE_STRING, .flags = FLAGS },\n    { NULL }\n};\n\nAVFILTER_DEFINE_CLASS(frei0r);\n\nstatic const AVFilterPad avfilter_vf_frei0r_inputs[] = {\n    {\n        .name         = \"default\",\n        .type         = AVMEDIA_TYPE_VIDEO,\n        .config_props = config_input_props,\n        .filter_frame = filter_frame,\n    },\n    { NULL }\n};\n\nstatic const AVFilterPad avfilter_vf_frei0r_outputs[] = {\n    {\n        .name = \"default\",\n        .type = AVMEDIA_TYPE_VIDEO,\n    },\n    { NULL }\n};\n\nAVFilter ff_vf_frei0r = {\n    .name          = \"frei0r\",\n    .description   = NULL_IF_CONFIG_SMALL(\"Apply a frei0r effect.\"),\n    .query_formats = query_formats,\n    .init          = filter_init,\n    .uninit        = uninit,\n    .priv_size     = sizeof(Frei0rContext),\n    .priv_class    = &frei0r_class,\n    .inputs        = avfilter_vf_frei0r_inputs,\n    .outputs       = avfilter_vf_frei0r_outputs,\n};\n\nstatic av_cold int source_init(AVFilterContext *ctx)\n{\n    Frei0rContext *s = ctx->priv;\n\n    s->time_base.num = s->framerate.den;\n    s->time_base.den = s->framerate.num;\n\n    return frei0r_init(ctx, s->dl_name, F0R_PLUGIN_TYPE_SOURCE);\n}\n\nstatic int source_config_props(AVFilterLink *outlink)\n{\n    AVFilterContext *ctx = outlink->src;\n    Frei0rContext *s = ctx->priv;\n\n    if (av_image_check_size(s->w, s->h, 0, ctx) < 0)\n        return AVERROR(EINVAL);\n    outlink->w = s->w;\n    outlink->h = s->h;\n    outlink->time_base = s->time_base;\n    outlink->frame_rate = av_inv_q(s->time_base);\n    outlink->sample_aspect_ratio = (AVRational){1,1};\n\n    if (s->destruct && s->instance)\n        s->destruct(s->instance);\n    if (!(s->instance = s->construct(outlink->w, outlink->h))) {\n        av_log(ctx, AV_LOG_ERROR, \"Impossible to load frei0r instance.\\n\");\n        return AVERROR(EINVAL);\n    }\n    if (!s->params) {\n        av_log(ctx, AV_LOG_ERROR, \"frei0r filter parameters not set.\\n\");\n        return AVERROR(EINVAL);\n    }\n\n    return set_params(ctx, s->params);\n}\n\nstatic int source_request_frame(AVFilterLink *outlink)\n{\n    Frei0rContext *s = outlink->src->priv;\n    AVFrame *frame = ff_get_video_buffer(outlink, outlink->w, outlink->h);\n\n    if (!frame)\n        return AVERROR(ENOMEM);\n\n    frame->sample_aspect_ratio = (AVRational) {1, 1};\n    frame->pts = s->pts++;\n\n    s->update(s->instance, av_rescale_q(frame->pts, s->time_base, (AVRational){1,1000}),\n                   NULL, (uint32_t *)frame->data[0]);\n\n    return ff_filter_frame(outlink, frame);\n}\n\nstatic const AVOption frei0r_src_options[] = {\n    { \"size\",          \"Dimensions of the generated video.\", OFFSET(w),         AV_OPT_TYPE_IMAGE_SIZE, { .str = \"320x240\" }, .flags = FLAGS },\n    { \"framerate\",     NULL,                                 OFFSET(framerate), AV_OPT_TYPE_VIDEO_RATE, { .str = \"25\" }, 0, INT_MAX, .flags = FLAGS },\n    { \"filter_name\",   NULL,                                 OFFSET(dl_name),   AV_OPT_TYPE_STRING,                  .flags = FLAGS },\n    { \"filter_params\", NULL,                                 OFFSET(params),    AV_OPT_TYPE_STRING,                  .flags = FLAGS },\n    { NULL },\n};\n\nAVFILTER_DEFINE_CLASS(frei0r_src);\n\nstatic const AVFilterPad avfilter_vsrc_frei0r_src_outputs[] = {\n    {\n        .name          = \"default\",\n        .type          = AVMEDIA_TYPE_VIDEO,\n        .request_frame = source_request_frame,\n        .config_props  = source_config_props\n    },\n    { NULL }\n};\n\nAVFilter ff_vsrc_frei0r_src = {\n    .name          = \"frei0r_src\",\n    .description   = NULL_IF_CONFIG_SMALL(\"Generate a frei0r source.\"),\n    .priv_size     = sizeof(Frei0rContext),\n    .priv_class    = &frei0r_src_class,\n    .init          = source_init,\n    .uninit        = uninit,\n    .query_formats = query_formats,\n    .inputs        = NULL,\n    .outputs       = avfilter_vsrc_frei0r_src_outputs,\n};\n",
        "/tmp/vanessa/spack-stage/spack-stage-ffmpeg-4.1-sdpvlh5k2flacnv4x524fsjycqueu4ji/spack-src/libavfilter/af_ladspa.c": "/*\n * Copyright (c) 2013 Paul B Mahol\n * Copyright (c) 2011 Mina Nagy Zaki\n *\n * This file is part of FFmpeg.\n *\n * FFmpeg is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License as published by the Free Software Foundation; either\n * version 2.1 of the License, or (at your option) any later version.\n *\n * FFmpeg is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with FFmpeg; if not, write to the Free Software\n * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n */\n\n/**\n * @file\n * LADSPA wrapper\n */\n\n#include <dlfcn.h>\n#include <ladspa.h>\n#include \"libavutil/avassert.h\"\n#include \"libavutil/avstring.h\"\n#include \"libavutil/channel_layout.h\"\n#include \"libavutil/opt.h\"\n#include \"audio.h\"\n#include \"avfilter.h\"\n#include \"internal.h\"\n\ntypedef struct LADSPAContext {\n    const AVClass *class;\n    char *dl_name;\n    char *plugin;\n    char *options;\n    void *dl_handle;\n\n    unsigned long nb_inputs;\n    unsigned long *ipmap;      /* map input number to port number */\n\n    unsigned long nb_inputcontrols;\n    unsigned long *icmap;      /* map input control number to port number */\n    LADSPA_Data *ictlv;        /* input controls values */\n\n    unsigned long nb_outputs;\n    unsigned long *opmap;      /* map output number to port number */\n\n    unsigned long nb_outputcontrols;\n    unsigned long *ocmap;      /* map output control number to port number */\n    LADSPA_Data *octlv;        /* output controls values */\n\n    const LADSPA_Descriptor *desc;\n    int *ctl_needs_value;\n    int nb_handles;\n    LADSPA_Handle *handles;\n\n    int sample_rate;\n    int nb_samples;\n    int64_t pts;\n    int64_t duration;\n} LADSPAContext;\n\n#define OFFSET(x) offsetof(LADSPAContext, x)\n#define FLAGS AV_OPT_FLAG_AUDIO_PARAM | AV_OPT_FLAG_FILTERING_PARAM\nstatic const AVOption ladspa_options[] = {\n    { \"file\", \"set library name or full path\", OFFSET(dl_name), AV_OPT_TYPE_STRING, .flags = FLAGS },\n    { \"f\",    \"set library name or full path\", OFFSET(dl_name), AV_OPT_TYPE_STRING, .flags = FLAGS },\n    { \"plugin\", \"set plugin name\", OFFSET(plugin), AV_OPT_TYPE_STRING, .flags = FLAGS },\n    { \"p\",      \"set plugin name\", OFFSET(plugin), AV_OPT_TYPE_STRING, .flags = FLAGS },\n    { \"controls\", \"set plugin options\", OFFSET(options), AV_OPT_TYPE_STRING, .flags = FLAGS },\n    { \"c\",        \"set plugin options\", OFFSET(options), AV_OPT_TYPE_STRING, .flags = FLAGS },\n    { \"sample_rate\", \"set sample rate\", OFFSET(sample_rate), AV_OPT_TYPE_INT, {.i64=44100}, 1, INT32_MAX, FLAGS },\n    { \"s\",           \"set sample rate\", OFFSET(sample_rate), AV_OPT_TYPE_INT, {.i64=44100}, 1, INT32_MAX, FLAGS },\n    { \"nb_samples\", \"set the number of samples per requested frame\", OFFSET(nb_samples), AV_OPT_TYPE_INT, {.i64=1024}, 1, INT_MAX, FLAGS },\n    { \"n\",          \"set the number of samples per requested frame\", OFFSET(nb_samples), AV_OPT_TYPE_INT, {.i64=1024}, 1, INT_MAX, FLAGS },\n    { \"duration\", \"set audio duration\", OFFSET(duration), AV_OPT_TYPE_DURATION, {.i64=-1}, -1, INT64_MAX, FLAGS },\n    { \"d\",        \"set audio duration\", OFFSET(duration), AV_OPT_TYPE_DURATION, {.i64=-1}, -1, INT64_MAX, FLAGS },\n    { NULL }\n};\n\nAVFILTER_DEFINE_CLASS(ladspa);\n\nstatic void print_ctl_info(AVFilterContext *ctx, int level,\n                           LADSPAContext *s, int ctl, unsigned long *map,\n                           LADSPA_Data *values, int print)\n{\n    const LADSPA_PortRangeHint *h = s->desc->PortRangeHints + map[ctl];\n\n    av_log(ctx, level, \"c%i: %s [\", ctl, s->desc->PortNames[map[ctl]]);\n\n    if (LADSPA_IS_HINT_TOGGLED(h->HintDescriptor)) {\n        av_log(ctx, level, \"toggled (1 or 0)\");\n\n        if (LADSPA_IS_HINT_HAS_DEFAULT(h->HintDescriptor))\n            av_log(ctx, level, \" (default %i)\", (int)values[ctl]);\n    } else {\n        if (LADSPA_IS_HINT_INTEGER(h->HintDescriptor)) {\n            av_log(ctx, level, \"<int>\");\n\n            if (LADSPA_IS_HINT_BOUNDED_BELOW(h->HintDescriptor))\n                av_log(ctx, level, \", min: %i\", (int)h->LowerBound);\n\n            if (LADSPA_IS_HINT_BOUNDED_ABOVE(h->HintDescriptor))\n                av_log(ctx, level, \", max: %i\", (int)h->UpperBound);\n\n            if (print)\n                av_log(ctx, level, \" (value %d)\", (int)values[ctl]);\n            else if (LADSPA_IS_HINT_HAS_DEFAULT(h->HintDescriptor))\n                av_log(ctx, level, \" (default %d)\", (int)values[ctl]);\n        } else {\n            av_log(ctx, level, \"<float>\");\n\n            if (LADSPA_IS_HINT_BOUNDED_BELOW(h->HintDescriptor))\n                av_log(ctx, level, \", min: %f\", h->LowerBound);\n\n            if (LADSPA_IS_HINT_BOUNDED_ABOVE(h->HintDescriptor))\n                av_log(ctx, level, \", max: %f\", h->UpperBound);\n\n            if (print)\n                av_log(ctx, level, \" (value %f)\", values[ctl]);\n            else if (LADSPA_IS_HINT_HAS_DEFAULT(h->HintDescriptor))\n                av_log(ctx, level, \" (default %f)\", values[ctl]);\n        }\n\n        if (LADSPA_IS_HINT_SAMPLE_RATE(h->HintDescriptor))\n            av_log(ctx, level, \", multiple of sample rate\");\n\n        if (LADSPA_IS_HINT_LOGARITHMIC(h->HintDescriptor))\n            av_log(ctx, level, \", logarithmic scale\");\n    }\n\n    av_log(ctx, level, \"]\\n\");\n}\n\nstatic int filter_frame(AVFilterLink *inlink, AVFrame *in)\n{\n    AVFilterContext *ctx = inlink->dst;\n    LADSPAContext *s = ctx->priv;\n    AVFrame *out;\n    int i, h, p;\n\n    av_assert0(in->channels == (s->nb_inputs * s->nb_handles));\n\n    if (!s->nb_outputs ||\n        (av_frame_is_writable(in) && s->nb_inputs == s->nb_outputs &&\n        !(s->desc->Properties & LADSPA_PROPERTY_INPLACE_BROKEN))) {\n        out = in;\n    } else {\n        out = ff_get_audio_buffer(ctx->outputs[0], in->nb_samples);\n        if (!out) {\n            av_frame_free(&in);\n            return AVERROR(ENOMEM);\n        }\n        av_frame_copy_props(out, in);\n    }\n\n    av_assert0(!s->nb_outputs || out->channels == (s->nb_outputs * s->nb_handles));\n\n    for (h = 0; h < s->nb_handles; h++) {\n        for (i = 0; i < s->nb_inputs; i++) {\n            p = s->nb_handles > 1 ? h : i;\n            s->desc->connect_port(s->handles[h], s->ipmap[i],\n                                  (LADSPA_Data*)in->extended_data[p]);\n        }\n\n        for (i = 0; i < s->nb_outputs; i++) {\n            p = s->nb_handles > 1 ? h : i;\n            s->desc->connect_port(s->handles[h], s->opmap[i],\n                                  (LADSPA_Data*)out->extended_data[p]);\n        }\n\n        s->desc->run(s->handles[h], in->nb_samples);\n    }\n\n    for (i = 0; i < s->nb_outputcontrols; i++)\n        print_ctl_info(ctx, AV_LOG_VERBOSE, s, i, s->ocmap, s->octlv, 1);\n\n    if (out != in)\n        av_frame_free(&in);\n\n    return ff_filter_frame(ctx->outputs[0], out);\n}\n\nstatic int request_frame(AVFilterLink *outlink)\n{\n    AVFilterContext *ctx = outlink->src;\n    LADSPAContext *s = ctx->priv;\n    AVFrame *out;\n    int64_t t;\n    int i;\n\n    if (ctx->nb_inputs)\n        return ff_request_frame(ctx->inputs[0]);\n\n    t = av_rescale(s->pts, AV_TIME_BASE, s->sample_rate);\n    if (s->duration >= 0 && t >= s->duration)\n        return AVERROR_EOF;\n\n    out = ff_get_audio_buffer(outlink, s->nb_samples);\n    if (!out)\n        return AVERROR(ENOMEM);\n\n    for (i = 0; i < s->nb_outputs; i++)\n        s->desc->connect_port(s->handles[0], s->opmap[i],\n                (LADSPA_Data*)out->extended_data[i]);\n\n    s->desc->run(s->handles[0], s->nb_samples);\n\n    for (i = 0; i < s->nb_outputcontrols; i++)\n        print_ctl_info(ctx, AV_LOG_INFO, s, i, s->ocmap, s->octlv, 1);\n\n    out->sample_rate = s->sample_rate;\n    out->pts         = s->pts;\n    s->pts          += s->nb_samples;\n\n    return ff_filter_frame(outlink, out);\n}\n\nstatic void set_default_ctl_value(LADSPAContext *s, int ctl,\n                                  unsigned long *map, LADSPA_Data *values)\n{\n    const LADSPA_PortRangeHint *h = s->desc->PortRangeHints + map[ctl];\n    const LADSPA_Data lower = h->LowerBound;\n    const LADSPA_Data upper = h->UpperBound;\n\n    if (LADSPA_IS_HINT_DEFAULT_MINIMUM(h->HintDescriptor)) {\n        values[ctl] = lower;\n    } else if (LADSPA_IS_HINT_DEFAULT_MAXIMUM(h->HintDescriptor)) {\n        values[ctl] = upper;\n    } else if (LADSPA_IS_HINT_DEFAULT_0(h->HintDescriptor)) {\n        values[ctl] = 0.0;\n    } else if (LADSPA_IS_HINT_DEFAULT_1(h->HintDescriptor)) {\n        values[ctl] = 1.0;\n    } else if (LADSPA_IS_HINT_DEFAULT_100(h->HintDescriptor)) {\n        values[ctl] = 100.0;\n    } else if (LADSPA_IS_HINT_DEFAULT_440(h->HintDescriptor)) {\n        values[ctl] = 440.0;\n    } else if (LADSPA_IS_HINT_DEFAULT_LOW(h->HintDescriptor)) {\n        if (LADSPA_IS_HINT_LOGARITHMIC(h->HintDescriptor))\n            values[ctl] = exp(log(lower) * 0.75 + log(upper) * 0.25);\n        else\n            values[ctl] = lower * 0.75 + upper * 0.25;\n    } else if (LADSPA_IS_HINT_DEFAULT_MIDDLE(h->HintDescriptor)) {\n        if (LADSPA_IS_HINT_LOGARITHMIC(h->HintDescriptor))\n            values[ctl] = exp(log(lower) * 0.5 + log(upper) * 0.5);\n        else\n            values[ctl] = lower * 0.5 + upper * 0.5;\n    } else if (LADSPA_IS_HINT_DEFAULT_HIGH(h->HintDescriptor)) {\n        if (LADSPA_IS_HINT_LOGARITHMIC(h->HintDescriptor))\n            values[ctl] = exp(log(lower) * 0.25 + log(upper) * 0.75);\n        else\n            values[ctl] = lower * 0.25 + upper * 0.75;\n    }\n}\n\nstatic int connect_ports(AVFilterContext *ctx, AVFilterLink *link)\n{\n    LADSPAContext *s = ctx->priv;\n    int i, j;\n\n    s->nb_handles = s->nb_inputs == 1 && s->nb_outputs == 1 ? link->channels : 1;\n    s->handles    = av_calloc(s->nb_handles, sizeof(*s->handles));\n    if (!s->handles)\n        return AVERROR(ENOMEM);\n\n    for (i = 0; i < s->nb_handles; i++) {\n        s->handles[i] = s->desc->instantiate(s->desc, link->sample_rate);\n        if (!s->handles[i]) {\n            av_log(ctx, AV_LOG_ERROR, \"Could not instantiate plugin.\\n\");\n            return AVERROR_EXTERNAL;\n        }\n\n        // Connect the input control ports\n        for (j = 0; j < s->nb_inputcontrols; j++)\n            s->desc->connect_port(s->handles[i], s->icmap[j], s->ictlv + j);\n\n        // Connect the output control ports\n        for (j = 0; j < s->nb_outputcontrols; j++)\n            s->desc->connect_port(s->handles[i], s->ocmap[j], &s->octlv[j]);\n\n        if (s->desc->activate)\n            s->desc->activate(s->handles[i]);\n    }\n\n    av_log(ctx, AV_LOG_DEBUG, \"handles: %d\\n\", s->nb_handles);\n\n    return 0;\n}\n\nstatic int config_input(AVFilterLink *inlink)\n{\n    AVFilterContext *ctx = inlink->dst;\n\n    return connect_ports(ctx, inlink);\n}\n\nstatic int config_output(AVFilterLink *outlink)\n{\n    AVFilterContext *ctx = outlink->src;\n    LADSPAContext *s = ctx->priv;\n    int ret;\n\n    if (ctx->nb_inputs) {\n        AVFilterLink *inlink = ctx->inputs[0];\n\n        outlink->format      = inlink->format;\n        outlink->sample_rate = inlink->sample_rate;\n        if (s->nb_inputs == s->nb_outputs) {\n            outlink->channel_layout = inlink->channel_layout;\n            outlink->channels = inlink->channels;\n        }\n\n        ret = 0;\n    } else {\n        outlink->sample_rate = s->sample_rate;\n        outlink->time_base   = (AVRational){1, s->sample_rate};\n\n        ret = connect_ports(ctx, outlink);\n    }\n\n    return ret;\n}\n\nstatic void count_ports(const LADSPA_Descriptor *desc,\n                        unsigned long *nb_inputs, unsigned long *nb_outputs)\n{\n    LADSPA_PortDescriptor pd;\n    int i;\n\n    for (i = 0; i < desc->PortCount; i++) {\n        pd = desc->PortDescriptors[i];\n\n        if (LADSPA_IS_PORT_AUDIO(pd)) {\n            if (LADSPA_IS_PORT_INPUT(pd)) {\n                (*nb_inputs)++;\n            } else if (LADSPA_IS_PORT_OUTPUT(pd)) {\n                (*nb_outputs)++;\n            }\n        }\n    }\n}\n\nstatic void *try_load(const char *dir, const char *soname)\n{\n    char *path = av_asprintf(\"%s/%s.so\", dir, soname);\n    void *ret = NULL;\n\n    if (path) {\n        ret = dlopen(path, RTLD_LOCAL|RTLD_NOW);\n        av_free(path);\n    }\n\n    return ret;\n}\n\nstatic int set_control(AVFilterContext *ctx, unsigned long port, LADSPA_Data value)\n{\n    LADSPAContext *s = ctx->priv;\n    const char *label = s->desc->Label;\n    LADSPA_PortRangeHint *h = (LADSPA_PortRangeHint *)s->desc->PortRangeHints +\n                              s->icmap[port];\n\n    if (port >= s->nb_inputcontrols) {\n        av_log(ctx, AV_LOG_ERROR, \"Control c%ld is out of range [0 - %lu].\\n\",\n               port, s->nb_inputcontrols);\n        return AVERROR(EINVAL);\n    }\n\n    if (LADSPA_IS_HINT_BOUNDED_BELOW(h->HintDescriptor) &&\n            value < h->LowerBound) {\n        av_log(ctx, AV_LOG_ERROR,\n                \"%s: input control c%ld is below lower boundary of %0.4f.\\n\",\n                label, port, h->LowerBound);\n        return AVERROR(EINVAL);\n    }\n\n    if (LADSPA_IS_HINT_BOUNDED_ABOVE(h->HintDescriptor) &&\n            value > h->UpperBound) {\n        av_log(ctx, AV_LOG_ERROR,\n                \"%s: input control c%ld is above upper boundary of %0.4f.\\n\",\n                label, port, h->UpperBound);\n        return AVERROR(EINVAL);\n    }\n\n    s->ictlv[port] = value;\n\n    return 0;\n}\n\nstatic av_cold int init(AVFilterContext *ctx)\n{\n    LADSPAContext *s = ctx->priv;\n    LADSPA_Descriptor_Function descriptor_fn;\n    const LADSPA_Descriptor *desc;\n    LADSPA_PortDescriptor pd;\n    AVFilterPad pad = { NULL };\n    char *p, *arg, *saveptr = NULL;\n    unsigned long nb_ports;\n    int i, j = 0;\n\n    if (!s->dl_name) {\n        av_log(ctx, AV_LOG_ERROR, \"No plugin name provided\\n\");\n        return AVERROR(EINVAL);\n    }\n\n    if (s->dl_name[0] == '/' || s->dl_name[0] == '.') {\n        // argument is a path\n        s->dl_handle = dlopen(s->dl_name, RTLD_LOCAL|RTLD_NOW);\n    } else {\n        // argument is a shared object name\n        char *paths = av_strdup(getenv(\"LADSPA_PATH\"));\n        const char *separator = \":\";\n\n        if (paths) {\n            p = paths;\n            while ((arg = av_strtok(p, separator, &saveptr)) && !s->dl_handle) {\n                s->dl_handle = try_load(arg, s->dl_name);\n                p = NULL;\n            }\n        }\n\n        av_free(paths);\n        if (!s->dl_handle && (paths = av_asprintf(\"%s/.ladspa/lib\", getenv(\"HOME\")))) {\n            s->dl_handle = try_load(paths, s->dl_name);\n            av_free(paths);\n        }\n\n        if (!s->dl_handle)\n            s->dl_handle = try_load(\"/usr/local/lib/ladspa\", s->dl_name);\n\n        if (!s->dl_handle)\n            s->dl_handle = try_load(\"/usr/lib/ladspa\", s->dl_name);\n    }\n    if (!s->dl_handle) {\n        av_log(ctx, AV_LOG_ERROR, \"Failed to load '%s'\\n\", s->dl_name);\n        return AVERROR(EINVAL);\n    }\n\n    descriptor_fn = dlsym(s->dl_handle, \"ladspa_descriptor\");\n    if (!descriptor_fn) {\n        av_log(ctx, AV_LOG_ERROR, \"Could not find ladspa_descriptor: %s\\n\", dlerror());\n        return AVERROR(EINVAL);\n    }\n\n    // Find the requested plugin, or list plugins\n    if (!s->plugin) {\n        av_log(ctx, AV_LOG_INFO, \"The '%s' library contains the following plugins:\\n\", s->dl_name);\n        av_log(ctx, AV_LOG_INFO, \"I = Input Channels\\n\");\n        av_log(ctx, AV_LOG_INFO, \"O = Output Channels\\n\");\n        av_log(ctx, AV_LOG_INFO, \"I:O %-25s %s\\n\", \"Plugin\", \"Description\");\n        av_log(ctx, AV_LOG_INFO, \"\\n\");\n        for (i = 0; desc = descriptor_fn(i); i++) {\n            unsigned long inputs = 0, outputs = 0;\n\n            count_ports(desc, &inputs, &outputs);\n            av_log(ctx, AV_LOG_INFO, \"%lu:%lu %-25s %s\\n\", inputs, outputs, desc->Label,\n                   (char *)av_x_if_null(desc->Name, \"?\"));\n            av_log(ctx, AV_LOG_VERBOSE, \"Maker: %s\\n\",\n                   (char *)av_x_if_null(desc->Maker, \"?\"));\n            av_log(ctx, AV_LOG_VERBOSE, \"Copyright: %s\\n\",\n                   (char *)av_x_if_null(desc->Copyright, \"?\"));\n        }\n        return AVERROR_EXIT;\n    } else {\n        for (i = 0;; i++) {\n            desc = descriptor_fn(i);\n            if (!desc) {\n                av_log(ctx, AV_LOG_ERROR, \"Could not find plugin: %s\\n\", s->plugin);\n                return AVERROR(EINVAL);\n            }\n\n            if (desc->Label && !strcmp(desc->Label, s->plugin))\n                break;\n        }\n    }\n\n    s->desc  = desc;\n    nb_ports = desc->PortCount;\n\n    s->ipmap = av_calloc(nb_ports, sizeof(*s->ipmap));\n    s->opmap = av_calloc(nb_ports, sizeof(*s->opmap));\n    s->icmap = av_calloc(nb_ports, sizeof(*s->icmap));\n    s->ocmap = av_calloc(nb_ports, sizeof(*s->ocmap));\n    s->ictlv = av_calloc(nb_ports, sizeof(*s->ictlv));\n    s->octlv = av_calloc(nb_ports, sizeof(*s->octlv));\n    s->ctl_needs_value = av_calloc(nb_ports, sizeof(*s->ctl_needs_value));\n    if (!s->ipmap || !s->opmap || !s->icmap ||\n        !s->ocmap || !s->ictlv || !s->octlv || !s->ctl_needs_value)\n        return AVERROR(ENOMEM);\n\n    for (i = 0; i < nb_ports; i++) {\n        pd = desc->PortDescriptors[i];\n\n        if (LADSPA_IS_PORT_AUDIO(pd)) {\n            if (LADSPA_IS_PORT_INPUT(pd)) {\n                s->ipmap[s->nb_inputs] = i;\n                s->nb_inputs++;\n            } else if (LADSPA_IS_PORT_OUTPUT(pd)) {\n                s->opmap[s->nb_outputs] = i;\n                s->nb_outputs++;\n            }\n        } else if (LADSPA_IS_PORT_CONTROL(pd)) {\n            if (LADSPA_IS_PORT_INPUT(pd)) {\n                s->icmap[s->nb_inputcontrols] = i;\n\n                if (LADSPA_IS_HINT_HAS_DEFAULT(desc->PortRangeHints[i].HintDescriptor))\n                    set_default_ctl_value(s, s->nb_inputcontrols, s->icmap, s->ictlv);\n                else\n                    s->ctl_needs_value[s->nb_inputcontrols] = 1;\n\n                s->nb_inputcontrols++;\n            } else if (LADSPA_IS_PORT_OUTPUT(pd)) {\n                s->ocmap[s->nb_outputcontrols] = i;\n                s->nb_outputcontrols++;\n            }\n        }\n    }\n\n    // List Control Ports if \"help\" is specified\n    if (s->options && !strcmp(s->options, \"help\")) {\n        if (!s->nb_inputcontrols) {\n            av_log(ctx, AV_LOG_INFO,\n                   \"The '%s' plugin does not have any input controls.\\n\",\n                   desc->Label);\n        } else {\n            av_log(ctx, AV_LOG_INFO,\n                   \"The '%s' plugin has the following input controls:\\n\",\n                   desc->Label);\n            for (i = 0; i < s->nb_inputcontrols; i++)\n                print_ctl_info(ctx, AV_LOG_INFO, s, i, s->icmap, s->ictlv, 0);\n        }\n        return AVERROR_EXIT;\n    }\n\n    // Parse control parameters\n    p = s->options;\n    while (s->options) {\n        LADSPA_Data val;\n        int ret;\n\n        if (!(arg = av_strtok(p, \" |\", &saveptr)))\n            break;\n        p = NULL;\n\n        if (sscanf(arg, \"c%d=%f\", &i, &val) != 2) {\n            if (sscanf(arg, \"%f\", &val) != 1) {\n                av_log(ctx, AV_LOG_ERROR, \"Invalid syntax.\\n\");\n                return AVERROR(EINVAL);\n            }\n            i = j++;\n        }\n\n        if ((ret = set_control(ctx, i, val)) < 0)\n            return ret;\n        s->ctl_needs_value[i] = 0;\n    }\n\n    // Check if any controls are not set\n    for (i = 0; i < s->nb_inputcontrols; i++) {\n        if (s->ctl_needs_value[i]) {\n            av_log(ctx, AV_LOG_ERROR, \"Control c%d must be set.\\n\", i);\n            print_ctl_info(ctx, AV_LOG_ERROR, s, i, s->icmap, s->ictlv, 0);\n            return AVERROR(EINVAL);\n        }\n    }\n\n    pad.type = AVMEDIA_TYPE_AUDIO;\n\n    if (s->nb_inputs) {\n        pad.name = av_asprintf(\"in0:%s%lu\", desc->Label, s->nb_inputs);\n        if (!pad.name)\n            return AVERROR(ENOMEM);\n\n        pad.filter_frame = filter_frame;\n        pad.config_props = config_input;\n        if (ff_insert_inpad(ctx, ctx->nb_inputs, &pad) < 0) {\n            av_freep(&pad.name);\n            return AVERROR(ENOMEM);\n        }\n    }\n\n    av_log(ctx, AV_LOG_DEBUG, \"ports: %lu\\n\", nb_ports);\n    av_log(ctx, AV_LOG_DEBUG, \"inputs: %lu outputs: %lu\\n\",\n                              s->nb_inputs, s->nb_outputs);\n    av_log(ctx, AV_LOG_DEBUG, \"input controls: %lu output controls: %lu\\n\",\n                              s->nb_inputcontrols, s->nb_outputcontrols);\n\n    return 0;\n}\n\nstatic int query_formats(AVFilterContext *ctx)\n{\n    LADSPAContext *s = ctx->priv;\n    AVFilterFormats *formats;\n    AVFilterChannelLayouts *layouts;\n    static const enum AVSampleFormat sample_fmts[] = {\n        AV_SAMPLE_FMT_FLTP, AV_SAMPLE_FMT_NONE };\n    int ret;\n\n    formats = ff_make_format_list(sample_fmts);\n    if (!formats)\n        return AVERROR(ENOMEM);\n    ret = ff_set_common_formats(ctx, formats);\n    if (ret < 0)\n        return ret;\n\n    if (s->nb_inputs) {\n        formats = ff_all_samplerates();\n        if (!formats)\n            return AVERROR(ENOMEM);\n\n        ret = ff_set_common_samplerates(ctx, formats);\n        if (ret < 0)\n            return ret;\n    } else {\n        int sample_rates[] = { s->sample_rate, -1 };\n\n        ret = ff_set_common_samplerates(ctx, ff_make_format_list(sample_rates));\n        if (ret < 0)\n            return ret;\n    }\n\n    if (s->nb_inputs == 1 && s->nb_outputs == 1) {\n        // We will instantiate multiple LADSPA_Handle, one over each channel\n        layouts = ff_all_channel_counts();\n        if (!layouts)\n            return AVERROR(ENOMEM);\n\n        ret = ff_set_common_channel_layouts(ctx, layouts);\n        if (ret < 0)\n            return ret;\n    } else if (s->nb_inputs == 2 && s->nb_outputs == 2) {\n        layouts = NULL;\n        ret = ff_add_channel_layout(&layouts, AV_CH_LAYOUT_STEREO);\n        if (ret < 0)\n            return ret;\n        ret = ff_set_common_channel_layouts(ctx, layouts);\n        if (ret < 0)\n            return ret;\n    } else {\n        AVFilterLink *outlink = ctx->outputs[0];\n\n        if (s->nb_inputs >= 1) {\n            AVFilterLink *inlink = ctx->inputs[0];\n            uint64_t inlayout = FF_COUNT2LAYOUT(s->nb_inputs);\n\n            layouts = NULL;\n            ret = ff_add_channel_layout(&layouts, inlayout);\n            if (ret < 0)\n                return ret;\n            ret = ff_channel_layouts_ref(layouts, &inlink->out_channel_layouts);\n            if (ret < 0)\n                return ret;\n\n            if (!s->nb_outputs) {\n                ret = ff_channel_layouts_ref(layouts, &outlink->in_channel_layouts);\n                if (ret < 0)\n                    return ret;\n            }\n        }\n\n        if (s->nb_outputs >= 1) {\n            uint64_t outlayout = FF_COUNT2LAYOUT(s->nb_outputs);\n\n            layouts = NULL;\n            ret = ff_add_channel_layout(&layouts, outlayout);\n            if (ret < 0)\n                return ret;\n            ret = ff_channel_layouts_ref(layouts, &outlink->in_channel_layouts);\n            if (ret < 0)\n                return ret;\n        }\n    }\n\n    return 0;\n}\n\nstatic av_cold void uninit(AVFilterContext *ctx)\n{\n    LADSPAContext *s = ctx->priv;\n    int i;\n\n    for (i = 0; i < s->nb_handles; i++) {\n        if (s->desc->deactivate)\n            s->desc->deactivate(s->handles[i]);\n        if (s->desc->cleanup)\n            s->desc->cleanup(s->handles[i]);\n    }\n\n    if (s->dl_handle)\n        dlclose(s->dl_handle);\n\n    av_freep(&s->ipmap);\n    av_freep(&s->opmap);\n    av_freep(&s->icmap);\n    av_freep(&s->ocmap);\n    av_freep(&s->ictlv);\n    av_freep(&s->octlv);\n    av_freep(&s->handles);\n    av_freep(&s->ctl_needs_value);\n\n    if (ctx->nb_inputs)\n        av_freep(&ctx->input_pads[0].name);\n}\n\nstatic int process_command(AVFilterContext *ctx, const char *cmd, const char *args,\n                           char *res, int res_len, int flags)\n{\n    LADSPA_Data value;\n    unsigned long port;\n\n    if (sscanf(cmd, \"c%ld\", &port) + sscanf(args, \"%f\", &value) != 2)\n        return AVERROR(EINVAL);\n\n    return set_control(ctx, port, value);\n}\n\nstatic const AVFilterPad ladspa_outputs[] = {\n    {\n        .name          = \"default\",\n        .type          = AVMEDIA_TYPE_AUDIO,\n        .config_props  = config_output,\n        .request_frame = request_frame,\n    },\n    { NULL }\n};\n\nAVFilter ff_af_ladspa = {\n    .name          = \"ladspa\",\n    .description   = NULL_IF_CONFIG_SMALL(\"Apply LADSPA effect.\"),\n    .priv_size     = sizeof(LADSPAContext),\n    .priv_class    = &ladspa_class,\n    .init          = init,\n    .uninit        = uninit,\n    .query_formats = query_formats,\n    .process_command = process_command,\n    .inputs        = 0,\n    .outputs       = ladspa_outputs,\n    .flags         = AVFILTER_FLAG_DYNAMIC_INPUTS,\n};\n",
        "/tmp/vanessa/spack-stage/spack-stage-ffmpeg-4.1-sdpvlh5k2flacnv4x524fsjycqueu4ji/spack-src/libavfilter/vf_telecine.c": "/*\n * Copyright (c) 2012 Rudolf Polzer\n * Copyright (c) 2013 Paul B Mahol\n *\n * This file is part of FFmpeg.\n *\n * FFmpeg is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License as published by the Free Software Foundation; either\n * version 2.1 of the License, or (at your option) any later version.\n *\n * FFmpeg is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with FFmpeg; if not, write to the Free Software\n * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n */\n\n/**\n * @file telecine filter, heavily based from mpv-player:TOOLS/vf_dlopen/telecine.c by\n * Rudolf Polzer.\n */\n\n#include \"libavutil/avstring.h\"\n#include \"libavutil/imgutils.h\"\n#include \"libavutil/opt.h\"\n#include \"libavutil/pixdesc.h\"\n#include \"avfilter.h\"\n#include \"formats.h\"\n#include \"internal.h\"\n#include \"video.h\"\n\ntypedef struct TelecineContext {\n    const AVClass *class;\n    int first_field;\n    char *pattern;\n    unsigned int pattern_pos;\n    int64_t start_time;\n\n    AVRational pts;\n    AVRational ts_unit;\n    int out_cnt;\n    int occupied;\n\n    int nb_planes;\n    int planeheight[4];\n    int stride[4];\n\n    AVFrame *frame[5];\n    AVFrame *temp;\n} TelecineContext;\n\n#define OFFSET(x) offsetof(TelecineContext, x)\n#define FLAGS AV_OPT_FLAG_FILTERING_PARAM|AV_OPT_FLAG_VIDEO_PARAM\n\nstatic const AVOption telecine_options[] = {\n    {\"first_field\", \"select first field\", OFFSET(first_field), AV_OPT_TYPE_INT,   {.i64=0}, 0, 1, FLAGS, \"field\"},\n        {\"top\",    \"select top field first\",                0, AV_OPT_TYPE_CONST, {.i64=0}, 0, 0, FLAGS, \"field\"},\n        {\"t\",      \"select top field first\",                0, AV_OPT_TYPE_CONST, {.i64=0}, 0, 0, FLAGS, \"field\"},\n        {\"bottom\", \"select bottom field first\",             0, AV_OPT_TYPE_CONST, {.i64=1}, 0, 0, FLAGS, \"field\"},\n        {\"b\",      \"select bottom field first\",             0, AV_OPT_TYPE_CONST, {.i64=1}, 0, 0, FLAGS, \"field\"},\n    {\"pattern\", \"pattern that describe for how many fields a frame is to be displayed\", OFFSET(pattern), AV_OPT_TYPE_STRING, {.str=\"23\"}, 0, 0, FLAGS},\n    {NULL}\n};\n\nAVFILTER_DEFINE_CLASS(telecine);\n\nstatic av_cold int init(AVFilterContext *ctx)\n{\n    TelecineContext *s = ctx->priv;\n    const char *p;\n    int max = 0;\n\n    if (!strlen(s->pattern)) {\n        av_log(ctx, AV_LOG_ERROR, \"No pattern provided.\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n\n    for (p = s->pattern; *p; p++) {\n        if (!av_isdigit(*p)) {\n            av_log(ctx, AV_LOG_ERROR, \"Provided pattern includes non-numeric characters.\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n\n        max = FFMAX(*p - '0', max);\n        s->pts.num += 2;\n        s->pts.den += *p - '0';\n    }\n\n    s->start_time = AV_NOPTS_VALUE;\n\n    s->out_cnt = (max + 1) / 2;\n    av_log(ctx, AV_LOG_INFO, \"Telecine pattern %s yields up to %d frames per frame, pts advance factor: %d/%d\\n\",\n           s->pattern, s->out_cnt, s->pts.num, s->pts.den);\n\n    return 0;\n}\n\nstatic int query_formats(AVFilterContext *ctx)\n{\n    AVFilterFormats *pix_fmts = NULL;\n    int fmt, ret;\n\n    for (fmt = 0; av_pix_fmt_desc_get(fmt); fmt++) {\n        const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(fmt);\n        if (!(desc->flags & AV_PIX_FMT_FLAG_HWACCEL ||\n              desc->flags & AV_PIX_FMT_FLAG_PAL     ||\n              desc->flags & AV_PIX_FMT_FLAG_BITSTREAM) &&\n            (ret = ff_add_format(&pix_fmts, fmt)) < 0)\n            return ret;\n    }\n\n    return ff_set_common_formats(ctx, pix_fmts);\n}\n\nstatic int config_input(AVFilterLink *inlink)\n{\n    TelecineContext *s = inlink->dst->priv;\n    const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(inlink->format);\n    int i, ret;\n\n    s->temp = ff_get_video_buffer(inlink, inlink->w, inlink->h);\n    if (!s->temp)\n        return AVERROR(ENOMEM);\n    for (i = 0; i < s->out_cnt; i++) {\n        s->frame[i] = ff_get_video_buffer(inlink, inlink->w, inlink->h);\n        if (!s->frame[i])\n            return AVERROR(ENOMEM);\n    }\n\n    if ((ret = av_image_fill_linesizes(s->stride, inlink->format, inlink->w)) < 0)\n        return ret;\n\n    s->planeheight[1] = s->planeheight[2] = AV_CEIL_RSHIFT(inlink->h, desc->log2_chroma_h);\n    s->planeheight[0] = s->planeheight[3] = inlink->h;\n\n    s->nb_planes = av_pix_fmt_count_planes(inlink->format);\n\n    return 0;\n}\n\nstatic int config_output(AVFilterLink *outlink)\n{\n    AVFilterContext *ctx = outlink->src;\n    TelecineContext *s = ctx->priv;\n    const AVFilterLink *inlink = ctx->inputs[0];\n    AVRational fps = inlink->frame_rate;\n\n    if (!fps.num || !fps.den) {\n        av_log(ctx, AV_LOG_ERROR, \"The input needs a constant frame rate; \"\n               \"current rate of %d/%d is invalid\\n\", fps.num, fps.den);\n        return AVERROR(EINVAL);\n    }\n    fps = av_mul_q(fps, av_inv_q(s->pts));\n    av_log(ctx, AV_LOG_VERBOSE, \"FPS: %d/%d -> %d/%d\\n\",\n           inlink->frame_rate.num, inlink->frame_rate.den, fps.num, fps.den);\n\n    outlink->frame_rate = fps;\n    outlink->time_base = av_mul_q(inlink->time_base, s->pts);\n    av_log(ctx, AV_LOG_VERBOSE, \"TB: %d/%d -> %d/%d\\n\",\n           inlink->time_base.num, inlink->time_base.den, outlink->time_base.num, outlink->time_base.den);\n\n    s->ts_unit = av_inv_q(av_mul_q(fps, outlink->time_base));\n\n    return 0;\n}\n\nstatic int filter_frame(AVFilterLink *inlink, AVFrame *inpicref)\n{\n    AVFilterContext *ctx = inlink->dst;\n    AVFilterLink *outlink = ctx->outputs[0];\n    TelecineContext *s = ctx->priv;\n    int i, len, ret = 0, nout = 0;\n\n    if (s->start_time == AV_NOPTS_VALUE)\n        s->start_time = inpicref->pts;\n\n    len = s->pattern[s->pattern_pos] - '0';\n\n    s->pattern_pos++;\n    if (!s->pattern[s->pattern_pos])\n        s->pattern_pos = 0;\n\n    if (!len) { // do not output any field from this frame\n        av_frame_free(&inpicref);\n        return 0;\n    }\n\n    if (s->occupied) {\n        av_frame_make_writable(s->frame[nout]);\n        for (i = 0; i < s->nb_planes; i++) {\n            // fill in the EARLIER field from the buffered pic\n            av_image_copy_plane(s->frame[nout]->data[i] + s->frame[nout]->linesize[i] * s->first_field,\n                                s->frame[nout]->linesize[i] * 2,\n                                s->temp->data[i] + s->temp->linesize[i] * s->first_field,\n                                s->temp->linesize[i] * 2,\n                                s->stride[i],\n                                (s->planeheight[i] - s->first_field + 1) / 2);\n            // fill in the LATER field from the new pic\n            av_image_copy_plane(s->frame[nout]->data[i] + s->frame[nout]->linesize[i] * !s->first_field,\n                                s->frame[nout]->linesize[i] * 2,\n                                inpicref->data[i] + inpicref->linesize[i] * !s->first_field,\n                                inpicref->linesize[i] * 2,\n                                s->stride[i],\n                                (s->planeheight[i] - !s->first_field + 1) / 2);\n        }\n        nout++;\n        len--;\n        s->occupied = 0;\n    }\n\n    while (len >= 2) {\n        // output THIS image as-is\n        av_frame_make_writable(s->frame[nout]);\n        for (i = 0; i < s->nb_planes; i++)\n            av_image_copy_plane(s->frame[nout]->data[i], s->frame[nout]->linesize[i],\n                                inpicref->data[i], inpicref->linesize[i],\n                                s->stride[i],\n                                s->planeheight[i]);\n        nout++;\n        len -= 2;\n    }\n\n    if (len >= 1) {\n        // copy THIS image to the buffer, we need it later\n        for (i = 0; i < s->nb_planes; i++)\n            av_image_copy_plane(s->temp->data[i], s->temp->linesize[i],\n                                inpicref->data[i], inpicref->linesize[i],\n                                s->stride[i],\n                                s->planeheight[i]);\n        s->occupied = 1;\n    }\n\n    for (i = 0; i < nout; i++) {\n        AVFrame *frame = av_frame_clone(s->frame[i]);\n\n        if (!frame) {\n            av_frame_free(&inpicref);\n            return AVERROR(ENOMEM);\n        }\n\n        av_frame_copy_props(frame, inpicref);\n        frame->pts = ((s->start_time == AV_NOPTS_VALUE) ? 0 : s->start_time) +\n                     av_rescale(outlink->frame_count_in, s->ts_unit.num,\n                                s->ts_unit.den);\n        ret = ff_filter_frame(outlink, frame);\n    }\n    av_frame_free(&inpicref);\n\n    return ret;\n}\n\nstatic av_cold void uninit(AVFilterContext *ctx)\n{\n    TelecineContext *s = ctx->priv;\n    int i;\n\n    av_frame_free(&s->temp);\n    for (i = 0; i < s->out_cnt; i++)\n        av_frame_free(&s->frame[i]);\n}\n\nstatic const AVFilterPad telecine_inputs[] = {\n    {\n        .name          = \"default\",\n        .type          = AVMEDIA_TYPE_VIDEO,\n        .filter_frame  = filter_frame,\n        .config_props  = config_input,\n    },\n    { NULL }\n};\n\nstatic const AVFilterPad telecine_outputs[] = {\n    {\n        .name          = \"default\",\n        .type          = AVMEDIA_TYPE_VIDEO,\n        .config_props  = config_output,\n    },\n    { NULL }\n};\n\nAVFilter ff_vf_telecine = {\n    .name          = \"telecine\",\n    .description   = NULL_IF_CONFIG_SMALL(\"Apply a telecine pattern.\"),\n    .priv_size     = sizeof(TelecineContext),\n    .priv_class    = &telecine_class,\n    .init          = init,\n    .uninit        = uninit,\n    .query_formats = query_formats,\n    .inputs        = telecine_inputs,\n    .outputs       = telecine_outputs,\n};\n",
        "/tmp/vanessa/spack-stage/spack-stage-ffmpeg-4.1-sdpvlh5k2flacnv4x524fsjycqueu4ji/spack-src/libavcodec/omx.c": "/*\n * OMX Video encoder\n * Copyright (C) 2011 Martin Storsjo\n *\n * This file is part of FFmpeg.\n *\n * FFmpeg is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License as published by the Free Software Foundation; either\n * version 2.1 of the License, or (at your option) any later version.\n *\n * FFmpeg is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with FFmpeg; if not, write to the Free Software\n * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n */\n\n#include \"config.h\"\n\n#if CONFIG_OMX_RPI\n#define OMX_SKIP64BIT\n#endif\n\n#include <dlfcn.h>\n#include <OMX_Core.h>\n#include <OMX_Component.h>\n#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <sys/time.h>\n\n#include \"libavutil/avstring.h\"\n#include \"libavutil/avutil.h\"\n#include \"libavutil/common.h\"\n#include \"libavutil/imgutils.h\"\n#include \"libavutil/log.h\"\n#include \"libavutil/opt.h\"\n\n#include \"avcodec.h\"\n#include \"h264.h\"\n#include \"internal.h\"\n\n#ifdef OMX_SKIP64BIT\nstatic OMX_TICKS to_omx_ticks(int64_t value)\n{\n    OMX_TICKS s;\n    s.nLowPart  = value & 0xffffffff;\n    s.nHighPart = value >> 32;\n    return s;\n}\nstatic int64_t from_omx_ticks(OMX_TICKS value)\n{\n    return (((int64_t)value.nHighPart) << 32) | value.nLowPart;\n}\n#else\n#define to_omx_ticks(x) (x)\n#define from_omx_ticks(x) (x)\n#endif\n\n#define INIT_STRUCT(x) do {                                               \\\n        x.nSize = sizeof(x);                                              \\\n        x.nVersion = s->version;                                          \\\n    } while (0)\n#define CHECK(x) do {                                                     \\\n        if (x != OMX_ErrorNone) {                                         \\\n            av_log(avctx, AV_LOG_ERROR,                                   \\\n                   \"err %x (%d) on line %d\\n\", x, x, __LINE__);           \\\n            return AVERROR_UNKNOWN;                                       \\\n        }                                                                 \\\n    } while (0)\n\ntypedef struct OMXContext {\n    void *lib;\n    void *lib2;\n    OMX_ERRORTYPE (*ptr_Init)(void);\n    OMX_ERRORTYPE (*ptr_Deinit)(void);\n    OMX_ERRORTYPE (*ptr_ComponentNameEnum)(OMX_STRING, OMX_U32, OMX_U32);\n    OMX_ERRORTYPE (*ptr_GetHandle)(OMX_HANDLETYPE*, OMX_STRING, OMX_PTR, OMX_CALLBACKTYPE*);\n    OMX_ERRORTYPE (*ptr_FreeHandle)(OMX_HANDLETYPE);\n    OMX_ERRORTYPE (*ptr_GetComponentsOfRole)(OMX_STRING, OMX_U32*, OMX_U8**);\n    OMX_ERRORTYPE (*ptr_GetRolesOfComponent)(OMX_STRING, OMX_U32*, OMX_U8**);\n    void (*host_init)(void);\n} OMXContext;\n\nstatic av_cold void *dlsym_prefixed(void *handle, const char *symbol, const char *prefix)\n{\n    char buf[50];\n    snprintf(buf, sizeof(buf), \"%s%s\", prefix ? prefix : \"\", symbol);\n    return dlsym(handle, buf);\n}\n\nstatic av_cold int omx_try_load(OMXContext *s, void *logctx,\n                                const char *libname, const char *prefix,\n                                const char *libname2)\n{\n    if (libname2) {\n        s->lib2 = dlopen(libname2, RTLD_NOW | RTLD_GLOBAL);\n        if (!s->lib2) {\n            av_log(logctx, AV_LOG_WARNING, \"%s not found\\n\", libname);\n            return AVERROR_ENCODER_NOT_FOUND;\n        }\n        s->host_init = dlsym(s->lib2, \"bcm_host_init\");\n        if (!s->host_init) {\n            av_log(logctx, AV_LOG_WARNING, \"bcm_host_init not found\\n\");\n            dlclose(s->lib2);\n            s->lib2 = NULL;\n            return AVERROR_ENCODER_NOT_FOUND;\n        }\n    }\n    s->lib = dlopen(libname, RTLD_NOW | RTLD_GLOBAL);\n    if (!s->lib) {\n        av_log(logctx, AV_LOG_WARNING, \"%s not found\\n\", libname);\n        return AVERROR_ENCODER_NOT_FOUND;\n    }\n    s->ptr_Init                = dlsym_prefixed(s->lib, \"OMX_Init\", prefix);\n    s->ptr_Deinit              = dlsym_prefixed(s->lib, \"OMX_Deinit\", prefix);\n    s->ptr_ComponentNameEnum   = dlsym_prefixed(s->lib, \"OMX_ComponentNameEnum\", prefix);\n    s->ptr_GetHandle           = dlsym_prefixed(s->lib, \"OMX_GetHandle\", prefix);\n    s->ptr_FreeHandle          = dlsym_prefixed(s->lib, \"OMX_FreeHandle\", prefix);\n    s->ptr_GetComponentsOfRole = dlsym_prefixed(s->lib, \"OMX_GetComponentsOfRole\", prefix);\n    s->ptr_GetRolesOfComponent = dlsym_prefixed(s->lib, \"OMX_GetRolesOfComponent\", prefix);\n    if (!s->ptr_Init || !s->ptr_Deinit || !s->ptr_ComponentNameEnum ||\n        !s->ptr_GetHandle || !s->ptr_FreeHandle ||\n        !s->ptr_GetComponentsOfRole || !s->ptr_GetRolesOfComponent) {\n        av_log(logctx, AV_LOG_WARNING, \"Not all functions found in %s\\n\", libname);\n        dlclose(s->lib);\n        s->lib = NULL;\n        if (s->lib2)\n            dlclose(s->lib2);\n        s->lib2 = NULL;\n        return AVERROR_ENCODER_NOT_FOUND;\n    }\n    return 0;\n}\n\nstatic av_cold OMXContext *omx_init(void *logctx, const char *libname, const char *prefix)\n{\n    static const char * const libnames[] = {\n#if CONFIG_OMX_RPI\n        \"/opt/vc/lib/libopenmaxil.so\", \"/opt/vc/lib/libbcm_host.so\",\n#else\n        \"libOMX_Core.so\", NULL,\n        \"libOmxCore.so\", NULL,\n#endif\n        NULL\n    };\n    const char* const* nameptr;\n    int ret = AVERROR_ENCODER_NOT_FOUND;\n    OMXContext *omx_context;\n\n    omx_context = av_mallocz(sizeof(*omx_context));\n    if (!omx_context)\n        return NULL;\n    if (libname) {\n        ret = omx_try_load(omx_context, logctx, libname, prefix, NULL);\n        if (ret < 0) {\n            av_free(omx_context);\n            return NULL;\n        }\n    } else {\n        for (nameptr = libnames; *nameptr; nameptr += 2)\n            if (!(ret = omx_try_load(omx_context, logctx, nameptr[0], prefix, nameptr[1])))\n                break;\n        if (!*nameptr) {\n            av_free(omx_context);\n            return NULL;\n        }\n    }\n\n    if (omx_context->host_init)\n        omx_context->host_init();\n    omx_context->ptr_Init();\n    return omx_context;\n}\n\nstatic av_cold void omx_deinit(OMXContext *omx_context)\n{\n    if (!omx_context)\n        return;\n    omx_context->ptr_Deinit();\n    dlclose(omx_context->lib);\n    av_free(omx_context);\n}\n\ntypedef struct OMXCodecContext {\n    const AVClass *class;\n    char *libname;\n    char *libprefix;\n    OMXContext *omx_context;\n\n    AVCodecContext *avctx;\n\n    char component_name[OMX_MAX_STRINGNAME_SIZE];\n    OMX_VERSIONTYPE version;\n    OMX_HANDLETYPE handle;\n    int in_port, out_port;\n    OMX_COLOR_FORMATTYPE color_format;\n    int stride, plane_size;\n\n    int num_in_buffers, num_out_buffers;\n    OMX_BUFFERHEADERTYPE **in_buffer_headers;\n    OMX_BUFFERHEADERTYPE **out_buffer_headers;\n    int num_free_in_buffers;\n    OMX_BUFFERHEADERTYPE **free_in_buffers;\n    int num_done_out_buffers;\n    OMX_BUFFERHEADERTYPE **done_out_buffers;\n    pthread_mutex_t input_mutex;\n    pthread_cond_t input_cond;\n    pthread_mutex_t output_mutex;\n    pthread_cond_t output_cond;\n\n    pthread_mutex_t state_mutex;\n    pthread_cond_t state_cond;\n    OMX_STATETYPE state;\n    OMX_ERRORTYPE error;\n\n    int mutex_cond_inited;\n\n    int eos_sent, got_eos;\n\n    uint8_t *output_buf;\n    int output_buf_size;\n\n    int input_zerocopy;\n    int profile;\n} OMXCodecContext;\n\nstatic void append_buffer(pthread_mutex_t *mutex, pthread_cond_t *cond,\n                          int* array_size, OMX_BUFFERHEADERTYPE **array,\n                          OMX_BUFFERHEADERTYPE *buffer)\n{\n    pthread_mutex_lock(mutex);\n    array[(*array_size)++] = buffer;\n    pthread_cond_broadcast(cond);\n    pthread_mutex_unlock(mutex);\n}\n\nstatic OMX_BUFFERHEADERTYPE *get_buffer(pthread_mutex_t *mutex, pthread_cond_t *cond,\n                                        int* array_size, OMX_BUFFERHEADERTYPE **array,\n                                        int wait)\n{\n    OMX_BUFFERHEADERTYPE *buffer;\n    pthread_mutex_lock(mutex);\n    if (wait) {\n        while (!*array_size)\n           pthread_cond_wait(cond, mutex);\n    }\n    if (*array_size > 0) {\n        buffer = array[0];\n        (*array_size)--;\n        memmove(&array[0], &array[1], (*array_size) * sizeof(OMX_BUFFERHEADERTYPE*));\n    } else {\n        buffer = NULL;\n    }\n    pthread_mutex_unlock(mutex);\n    return buffer;\n}\n\nstatic OMX_ERRORTYPE event_handler(OMX_HANDLETYPE component, OMX_PTR app_data, OMX_EVENTTYPE event,\n                                   OMX_U32 data1, OMX_U32 data2, OMX_PTR event_data)\n{\n    OMXCodecContext *s = app_data;\n    // This uses casts in the printfs, since OMX_U32 actually is a typedef for\n    // unsigned long in official header versions (but there are also modified\n    // versions where it is something else).\n    switch (event) {\n    case OMX_EventError:\n        pthread_mutex_lock(&s->state_mutex);\n        av_log(s->avctx, AV_LOG_ERROR, \"OMX error %\"PRIx32\"\\n\", (uint32_t) data1);\n        s->error = data1;\n        pthread_cond_broadcast(&s->state_cond);\n        pthread_mutex_unlock(&s->state_mutex);\n        break;\n    case OMX_EventCmdComplete:\n        if (data1 == OMX_CommandStateSet) {\n            pthread_mutex_lock(&s->state_mutex);\n            s->state = data2;\n            av_log(s->avctx, AV_LOG_VERBOSE, \"OMX state changed to %\"PRIu32\"\\n\", (uint32_t) data2);\n            pthread_cond_broadcast(&s->state_cond);\n            pthread_mutex_unlock(&s->state_mutex);\n        } else if (data1 == OMX_CommandPortDisable) {\n            av_log(s->avctx, AV_LOG_VERBOSE, \"OMX port %\"PRIu32\" disabled\\n\", (uint32_t) data2);\n        } else if (data1 == OMX_CommandPortEnable) {\n            av_log(s->avctx, AV_LOG_VERBOSE, \"OMX port %\"PRIu32\" enabled\\n\", (uint32_t) data2);\n        } else {\n            av_log(s->avctx, AV_LOG_VERBOSE, \"OMX command complete, command %\"PRIu32\", value %\"PRIu32\"\\n\",\n                                             (uint32_t) data1, (uint32_t) data2);\n        }\n        break;\n    case OMX_EventPortSettingsChanged:\n        av_log(s->avctx, AV_LOG_VERBOSE, \"OMX port %\"PRIu32\" settings changed\\n\", (uint32_t) data1);\n        break;\n    default:\n        av_log(s->avctx, AV_LOG_VERBOSE, \"OMX event %d %\"PRIx32\" %\"PRIx32\"\\n\",\n                                         event, (uint32_t) data1, (uint32_t) data2);\n        break;\n    }\n    return OMX_ErrorNone;\n}\n\nstatic OMX_ERRORTYPE empty_buffer_done(OMX_HANDLETYPE component, OMX_PTR app_data,\n                                       OMX_BUFFERHEADERTYPE *buffer)\n{\n    OMXCodecContext *s = app_data;\n    if (s->input_zerocopy) {\n        if (buffer->pAppPrivate) {\n            if (buffer->pOutputPortPrivate)\n                av_free(buffer->pAppPrivate);\n            else\n                av_frame_free((AVFrame**)&buffer->pAppPrivate);\n            buffer->pAppPrivate = NULL;\n        }\n    }\n    append_buffer(&s->input_mutex, &s->input_cond,\n                  &s->num_free_in_buffers, s->free_in_buffers, buffer);\n    return OMX_ErrorNone;\n}\n\nstatic OMX_ERRORTYPE fill_buffer_done(OMX_HANDLETYPE component, OMX_PTR app_data,\n                                      OMX_BUFFERHEADERTYPE *buffer)\n{\n    OMXCodecContext *s = app_data;\n    append_buffer(&s->output_mutex, &s->output_cond,\n                  &s->num_done_out_buffers, s->done_out_buffers, buffer);\n    return OMX_ErrorNone;\n}\n\nstatic const OMX_CALLBACKTYPE callbacks = {\n    event_handler,\n    empty_buffer_done,\n    fill_buffer_done\n};\n\nstatic av_cold int find_component(OMXContext *omx_context, void *logctx,\n                                  const char *role, char *str, int str_size)\n{\n    OMX_U32 i, num = 0;\n    char **components;\n    int ret = 0;\n\n#if CONFIG_OMX_RPI\n    if (av_strstart(role, \"video_encoder.\", NULL)) {\n        av_strlcpy(str, \"OMX.broadcom.video_encode\", str_size);\n        return 0;\n    }\n#endif\n    omx_context->ptr_GetComponentsOfRole((OMX_STRING) role, &num, NULL);\n    if (!num) {\n        av_log(logctx, AV_LOG_WARNING, \"No component for role %s found\\n\", role);\n        return AVERROR_ENCODER_NOT_FOUND;\n    }\n    components = av_mallocz_array(num, sizeof(*components));\n    if (!components)\n        return AVERROR(ENOMEM);\n    for (i = 0; i < num; i++) {\n        components[i] = av_mallocz(OMX_MAX_STRINGNAME_SIZE);\n        if (!components[i]) {\n            ret = AVERROR(ENOMEM);\n            goto end;\n        }\n    }\n    omx_context->ptr_GetComponentsOfRole((OMX_STRING) role, &num, (OMX_U8**) components);\n    av_strlcpy(str, components[0], str_size);\nend:\n    for (i = 0; i < num; i++)\n        av_free(components[i]);\n    av_free(components);\n    return ret;\n}\n\nstatic av_cold int wait_for_state(OMXCodecContext *s, OMX_STATETYPE state)\n{\n    int ret = 0;\n    pthread_mutex_lock(&s->state_mutex);\n    while (s->state != state && s->error == OMX_ErrorNone)\n        pthread_cond_wait(&s->state_cond, &s->state_mutex);\n    if (s->error != OMX_ErrorNone)\n        ret = AVERROR_ENCODER_NOT_FOUND;\n    pthread_mutex_unlock(&s->state_mutex);\n    return ret;\n}\n\nstatic av_cold int omx_component_init(AVCodecContext *avctx, const char *role)\n{\n    OMXCodecContext *s = avctx->priv_data;\n    OMX_PARAM_COMPONENTROLETYPE role_params = { 0 };\n    OMX_PORT_PARAM_TYPE video_port_params = { 0 };\n    OMX_PARAM_PORTDEFINITIONTYPE in_port_params = { 0 }, out_port_params = { 0 };\n    OMX_VIDEO_PARAM_PORTFORMATTYPE video_port_format = { 0 };\n    OMX_VIDEO_PARAM_BITRATETYPE vid_param_bitrate = { 0 };\n    OMX_ERRORTYPE err;\n    int i;\n\n    s->version.s.nVersionMajor = 1;\n    s->version.s.nVersionMinor = 1;\n    s->version.s.nRevision     = 2;\n\n    err = s->omx_context->ptr_GetHandle(&s->handle, s->component_name, s, (OMX_CALLBACKTYPE*) &callbacks);\n    if (err != OMX_ErrorNone) {\n        av_log(avctx, AV_LOG_ERROR, \"OMX_GetHandle(%s) failed: %x\\n\", s->component_name, err);\n        return AVERROR_UNKNOWN;\n    }\n\n    // This one crashes the mediaserver on qcom, if used over IOMX\n    INIT_STRUCT(role_params);\n    av_strlcpy(role_params.cRole, role, sizeof(role_params.cRole));\n    // Intentionally ignore errors on this one\n    OMX_SetParameter(s->handle, OMX_IndexParamStandardComponentRole, &role_params);\n\n    INIT_STRUCT(video_port_params);\n    err = OMX_GetParameter(s->handle, OMX_IndexParamVideoInit, &video_port_params);\n    CHECK(err);\n\n    s->in_port = s->out_port = -1;\n    for (i = 0; i < video_port_params.nPorts; i++) {\n        int port = video_port_params.nStartPortNumber + i;\n        OMX_PARAM_PORTDEFINITIONTYPE port_params = { 0 };\n        INIT_STRUCT(port_params);\n        port_params.nPortIndex = port;\n        err = OMX_GetParameter(s->handle, OMX_IndexParamPortDefinition, &port_params);\n        if (err != OMX_ErrorNone) {\n            av_log(avctx, AV_LOG_WARNING, \"port %d error %x\\n\", port, err);\n            break;\n        }\n        if (port_params.eDir == OMX_DirInput && s->in_port < 0) {\n            in_port_params = port_params;\n            s->in_port = port;\n        } else if (port_params.eDir == OMX_DirOutput && s->out_port < 0) {\n            out_port_params = port_params;\n            s->out_port = port;\n        }\n    }\n    if (s->in_port < 0 || s->out_port < 0) {\n        av_log(avctx, AV_LOG_ERROR, \"No in or out port found (in %d out %d)\\n\", s->in_port, s->out_port);\n        return AVERROR_UNKNOWN;\n    }\n\n    s->color_format = 0;\n    for (i = 0; ; i++) {\n        INIT_STRUCT(video_port_format);\n        video_port_format.nIndex = i;\n        video_port_format.nPortIndex = s->in_port;\n        if (OMX_GetParameter(s->handle, OMX_IndexParamVideoPortFormat, &video_port_format) != OMX_ErrorNone)\n            break;\n        if (video_port_format.eColorFormat == OMX_COLOR_FormatYUV420Planar ||\n            video_port_format.eColorFormat == OMX_COLOR_FormatYUV420PackedPlanar) {\n            s->color_format = video_port_format.eColorFormat;\n            break;\n        }\n    }\n    if (s->color_format == 0) {\n        av_log(avctx, AV_LOG_ERROR, \"No supported pixel formats (%d formats available)\\n\", i);\n        return AVERROR_UNKNOWN;\n    }\n\n    in_port_params.bEnabled   = OMX_TRUE;\n    in_port_params.bPopulated = OMX_FALSE;\n    in_port_params.eDomain    = OMX_PortDomainVideo;\n\n    in_port_params.format.video.pNativeRender         = NULL;\n    in_port_params.format.video.bFlagErrorConcealment = OMX_FALSE;\n    in_port_params.format.video.eColorFormat          = s->color_format;\n    s->stride     = avctx->width;\n    s->plane_size = avctx->height;\n    // If specific codecs need to manually override the stride/plane_size,\n    // that can be done here.\n    in_port_params.format.video.nStride      = s->stride;\n    in_port_params.format.video.nSliceHeight = s->plane_size;\n    in_port_params.format.video.nFrameWidth  = avctx->width;\n    in_port_params.format.video.nFrameHeight = avctx->height;\n    if (avctx->framerate.den > 0 && avctx->framerate.num > 0)\n        in_port_params.format.video.xFramerate = (1 << 16) * avctx->framerate.num / avctx->framerate.den;\n    else\n        in_port_params.format.video.xFramerate = (1 << 16) * avctx->time_base.den / avctx->time_base.num;\n\n    err = OMX_SetParameter(s->handle, OMX_IndexParamPortDefinition, &in_port_params);\n    CHECK(err);\n    err = OMX_GetParameter(s->handle, OMX_IndexParamPortDefinition, &in_port_params);\n    CHECK(err);\n    s->stride         = in_port_params.format.video.nStride;\n    s->plane_size     = in_port_params.format.video.nSliceHeight;\n    s->num_in_buffers = in_port_params.nBufferCountActual;\n\n    err = OMX_GetParameter(s->handle, OMX_IndexParamPortDefinition, &out_port_params);\n    out_port_params.bEnabled   = OMX_TRUE;\n    out_port_params.bPopulated = OMX_FALSE;\n    out_port_params.eDomain    = OMX_PortDomainVideo;\n    out_port_params.format.video.pNativeRender = NULL;\n    out_port_params.format.video.nFrameWidth   = avctx->width;\n    out_port_params.format.video.nFrameHeight  = avctx->height;\n    out_port_params.format.video.nStride       = 0;\n    out_port_params.format.video.nSliceHeight  = 0;\n    out_port_params.format.video.nBitrate      = avctx->bit_rate;\n    out_port_params.format.video.xFramerate    = in_port_params.format.video.xFramerate;\n    out_port_params.format.video.bFlagErrorConcealment  = OMX_FALSE;\n    if (avctx->codec->id == AV_CODEC_ID_MPEG4)\n        out_port_params.format.video.eCompressionFormat = OMX_VIDEO_CodingMPEG4;\n    else if (avctx->codec->id == AV_CODEC_ID_H264)\n        out_port_params.format.video.eCompressionFormat = OMX_VIDEO_CodingAVC;\n\n    err = OMX_SetParameter(s->handle, OMX_IndexParamPortDefinition, &out_port_params);\n    CHECK(err);\n    err = OMX_GetParameter(s->handle, OMX_IndexParamPortDefinition, &out_port_params);\n    CHECK(err);\n    s->num_out_buffers = out_port_params.nBufferCountActual;\n\n    INIT_STRUCT(vid_param_bitrate);\n    vid_param_bitrate.nPortIndex     = s->out_port;\n    vid_param_bitrate.eControlRate   = OMX_Video_ControlRateVariable;\n    vid_param_bitrate.nTargetBitrate = avctx->bit_rate;\n    err = OMX_SetParameter(s->handle, OMX_IndexParamVideoBitrate, &vid_param_bitrate);\n    if (err != OMX_ErrorNone)\n        av_log(avctx, AV_LOG_WARNING, \"Unable to set video bitrate parameter\\n\");\n\n    if (avctx->codec->id == AV_CODEC_ID_H264) {\n        OMX_VIDEO_PARAM_AVCTYPE avc = { 0 };\n        INIT_STRUCT(avc);\n        avc.nPortIndex = s->out_port;\n        err = OMX_GetParameter(s->handle, OMX_IndexParamVideoAvc, &avc);\n        CHECK(err);\n        avc.nBFrames = 0;\n        avc.nPFrames = avctx->gop_size - 1;\n        switch (s->profile == FF_PROFILE_UNKNOWN ? avctx->profile : s->profile) {\n        case FF_PROFILE_H264_BASELINE:\n            avc.eProfile = OMX_VIDEO_AVCProfileBaseline;\n            break;\n        case FF_PROFILE_H264_MAIN:\n            avc.eProfile = OMX_VIDEO_AVCProfileMain;\n            break;\n        case FF_PROFILE_H264_HIGH:\n            avc.eProfile = OMX_VIDEO_AVCProfileHigh;\n            break;\n        default:\n            break;\n        }\n        err = OMX_SetParameter(s->handle, OMX_IndexParamVideoAvc, &avc);\n        CHECK(err);\n    }\n\n    err = OMX_SendCommand(s->handle, OMX_CommandStateSet, OMX_StateIdle, NULL);\n    CHECK(err);\n\n    s->in_buffer_headers  = av_mallocz(sizeof(OMX_BUFFERHEADERTYPE*) * s->num_in_buffers);\n    s->free_in_buffers    = av_mallocz(sizeof(OMX_BUFFERHEADERTYPE*) * s->num_in_buffers);\n    s->out_buffer_headers = av_mallocz(sizeof(OMX_BUFFERHEADERTYPE*) * s->num_out_buffers);\n    s->done_out_buffers   = av_mallocz(sizeof(OMX_BUFFERHEADERTYPE*) * s->num_out_buffers);\n    if (!s->in_buffer_headers || !s->free_in_buffers || !s->out_buffer_headers || !s->done_out_buffers)\n        return AVERROR(ENOMEM);\n    for (i = 0; i < s->num_in_buffers && err == OMX_ErrorNone; i++) {\n        if (s->input_zerocopy)\n            err = OMX_UseBuffer(s->handle, &s->in_buffer_headers[i], s->in_port, s, in_port_params.nBufferSize, NULL);\n        else\n            err = OMX_AllocateBuffer(s->handle, &s->in_buffer_headers[i],  s->in_port,  s, in_port_params.nBufferSize);\n        if (err == OMX_ErrorNone)\n            s->in_buffer_headers[i]->pAppPrivate = s->in_buffer_headers[i]->pOutputPortPrivate = NULL;\n    }\n    CHECK(err);\n    s->num_in_buffers = i;\n    for (i = 0; i < s->num_out_buffers && err == OMX_ErrorNone; i++)\n        err = OMX_AllocateBuffer(s->handle, &s->out_buffer_headers[i], s->out_port, s, out_port_params.nBufferSize);\n    CHECK(err);\n    s->num_out_buffers = i;\n\n    if (wait_for_state(s, OMX_StateIdle) < 0) {\n        av_log(avctx, AV_LOG_ERROR, \"Didn't get OMX_StateIdle\\n\");\n        return AVERROR_UNKNOWN;\n    }\n    err = OMX_SendCommand(s->handle, OMX_CommandStateSet, OMX_StateExecuting, NULL);\n    CHECK(err);\n    if (wait_for_state(s, OMX_StateExecuting) < 0) {\n        av_log(avctx, AV_LOG_ERROR, \"Didn't get OMX_StateExecuting\\n\");\n        return AVERROR_UNKNOWN;\n    }\n\n    for (i = 0; i < s->num_out_buffers && err == OMX_ErrorNone; i++)\n        err = OMX_FillThisBuffer(s->handle, s->out_buffer_headers[i]);\n    if (err != OMX_ErrorNone) {\n        for (; i < s->num_out_buffers; i++)\n            s->done_out_buffers[s->num_done_out_buffers++] = s->out_buffer_headers[i];\n    }\n    for (i = 0; i < s->num_in_buffers; i++)\n        s->free_in_buffers[s->num_free_in_buffers++] = s->in_buffer_headers[i];\n    return err != OMX_ErrorNone ? AVERROR_UNKNOWN : 0;\n}\n\nstatic av_cold void cleanup(OMXCodecContext *s)\n{\n    int i, executing;\n\n    pthread_mutex_lock(&s->state_mutex);\n    executing = s->state == OMX_StateExecuting;\n    pthread_mutex_unlock(&s->state_mutex);\n\n    if (executing) {\n        OMX_SendCommand(s->handle, OMX_CommandStateSet, OMX_StateIdle, NULL);\n        wait_for_state(s, OMX_StateIdle);\n        OMX_SendCommand(s->handle, OMX_CommandStateSet, OMX_StateLoaded, NULL);\n        for (i = 0; i < s->num_in_buffers; i++) {\n            OMX_BUFFERHEADERTYPE *buffer = get_buffer(&s->input_mutex, &s->input_cond,\n                                                      &s->num_free_in_buffers, s->free_in_buffers, 1);\n            if (s->input_zerocopy)\n                buffer->pBuffer = NULL;\n            OMX_FreeBuffer(s->handle, s->in_port, buffer);\n        }\n        for (i = 0; i < s->num_out_buffers; i++) {\n            OMX_BUFFERHEADERTYPE *buffer = get_buffer(&s->output_mutex, &s->output_cond,\n                                                      &s->num_done_out_buffers, s->done_out_buffers, 1);\n            OMX_FreeBuffer(s->handle, s->out_port, buffer);\n        }\n        wait_for_state(s, OMX_StateLoaded);\n    }\n    if (s->handle) {\n        s->omx_context->ptr_FreeHandle(s->handle);\n        s->handle = NULL;\n    }\n\n    omx_deinit(s->omx_context);\n    s->omx_context = NULL;\n    if (s->mutex_cond_inited) {\n        pthread_cond_destroy(&s->state_cond);\n        pthread_mutex_destroy(&s->state_mutex);\n        pthread_cond_destroy(&s->input_cond);\n        pthread_mutex_destroy(&s->input_mutex);\n        pthread_cond_destroy(&s->output_cond);\n        pthread_mutex_destroy(&s->output_mutex);\n        s->mutex_cond_inited = 0;\n    }\n    av_freep(&s->in_buffer_headers);\n    av_freep(&s->out_buffer_headers);\n    av_freep(&s->free_in_buffers);\n    av_freep(&s->done_out_buffers);\n    av_freep(&s->output_buf);\n}\n\nstatic av_cold int omx_encode_init(AVCodecContext *avctx)\n{\n    OMXCodecContext *s = avctx->priv_data;\n    int ret = AVERROR_ENCODER_NOT_FOUND;\n    const char *role;\n    OMX_BUFFERHEADERTYPE *buffer;\n    OMX_ERRORTYPE err;\n\n#if CONFIG_OMX_RPI\n    s->input_zerocopy = 1;\n#endif\n\n    s->omx_context = omx_init(avctx, s->libname, s->libprefix);\n    if (!s->omx_context)\n        return AVERROR_ENCODER_NOT_FOUND;\n\n    pthread_mutex_init(&s->state_mutex, NULL);\n    pthread_cond_init(&s->state_cond, NULL);\n    pthread_mutex_init(&s->input_mutex, NULL);\n    pthread_cond_init(&s->input_cond, NULL);\n    pthread_mutex_init(&s->output_mutex, NULL);\n    pthread_cond_init(&s->output_cond, NULL);\n    s->mutex_cond_inited = 1;\n    s->avctx = avctx;\n    s->state = OMX_StateLoaded;\n    s->error = OMX_ErrorNone;\n\n    switch (avctx->codec->id) {\n    case AV_CODEC_ID_MPEG4:\n        role = \"video_encoder.mpeg4\";\n        break;\n    case AV_CODEC_ID_H264:\n        role = \"video_encoder.avc\";\n        break;\n    default:\n        return AVERROR(ENOSYS);\n    }\n\n    if ((ret = find_component(s->omx_context, avctx, role, s->component_name, sizeof(s->component_name))) < 0)\n        goto fail;\n\n    av_log(avctx, AV_LOG_INFO, \"Using %s\\n\", s->component_name);\n\n    if ((ret = omx_component_init(avctx, role)) < 0)\n        goto fail;\n\n    if (avctx->flags & AV_CODEC_FLAG_GLOBAL_HEADER) {\n        while (1) {\n            buffer = get_buffer(&s->output_mutex, &s->output_cond,\n                                &s->num_done_out_buffers, s->done_out_buffers, 1);\n            if (buffer->nFlags & OMX_BUFFERFLAG_CODECCONFIG) {\n                if ((ret = av_reallocp(&avctx->extradata, avctx->extradata_size + buffer->nFilledLen + AV_INPUT_BUFFER_PADDING_SIZE)) < 0) {\n                    avctx->extradata_size = 0;\n                    goto fail;\n                }\n                memcpy(avctx->extradata + avctx->extradata_size, buffer->pBuffer + buffer->nOffset, buffer->nFilledLen);\n                avctx->extradata_size += buffer->nFilledLen;\n                memset(avctx->extradata + avctx->extradata_size, 0, AV_INPUT_BUFFER_PADDING_SIZE);\n            }\n            err = OMX_FillThisBuffer(s->handle, buffer);\n            if (err != OMX_ErrorNone) {\n                append_buffer(&s->output_mutex, &s->output_cond,\n                              &s->num_done_out_buffers, s->done_out_buffers, buffer);\n                av_log(avctx, AV_LOG_ERROR, \"OMX_FillThisBuffer failed: %x\\n\", err);\n                ret = AVERROR_UNKNOWN;\n                goto fail;\n            }\n            if (avctx->codec->id == AV_CODEC_ID_H264) {\n                // For H.264, the extradata can be returned in two separate buffers\n                // (the videocore encoder on raspberry pi does this);\n                // therefore check that we have got both SPS and PPS before continuing.\n                int nals[32] = { 0 };\n                int i;\n                for (i = 0; i + 4 < avctx->extradata_size; i++) {\n                     if (!avctx->extradata[i + 0] &&\n                         !avctx->extradata[i + 1] &&\n                         !avctx->extradata[i + 2] &&\n                         avctx->extradata[i + 3] == 1) {\n                         nals[avctx->extradata[i + 4] & 0x1f]++;\n                     }\n                }\n                if (nals[H264_NAL_SPS] && nals[H264_NAL_PPS])\n                    break;\n            } else {\n                if (avctx->extradata_size > 0)\n                    break;\n            }\n        }\n    }\n\n    return 0;\nfail:\n    return ret;\n}\n\n\nstatic int omx_encode_frame(AVCodecContext *avctx, AVPacket *pkt,\n                            const AVFrame *frame, int *got_packet)\n{\n    OMXCodecContext *s = avctx->priv_data;\n    int ret = 0;\n    OMX_BUFFERHEADERTYPE* buffer;\n    OMX_ERRORTYPE err;\n\n    if (frame) {\n        uint8_t *dst[4];\n        int linesize[4];\n        int need_copy;\n        buffer = get_buffer(&s->input_mutex, &s->input_cond,\n                            &s->num_free_in_buffers, s->free_in_buffers, 1);\n\n        buffer->nFilledLen = av_image_fill_arrays(dst, linesize, buffer->pBuffer, avctx->pix_fmt, s->stride, s->plane_size, 1);\n\n        if (s->input_zerocopy) {\n            uint8_t *src[4] = { NULL };\n            int src_linesize[4];\n            av_image_fill_arrays(src, src_linesize, frame->data[0], avctx->pix_fmt, s->stride, s->plane_size, 1);\n            if (frame->linesize[0] == src_linesize[0] &&\n                frame->linesize[1] == src_linesize[1] &&\n                frame->linesize[2] == src_linesize[2] &&\n                frame->data[1] == src[1] &&\n                frame->data[2] == src[2]) {\n                // If the input frame happens to have all planes stored contiguously,\n                // with the right strides, just clone the frame and set the OMX\n                // buffer header to point to it\n                AVFrame *local = av_frame_clone(frame);\n                if (!local) {\n                    // Return the buffer to the queue so it's not lost\n                    append_buffer(&s->input_mutex, &s->input_cond, &s->num_free_in_buffers, s->free_in_buffers, buffer);\n                    return AVERROR(ENOMEM);\n                } else {\n                    buffer->pAppPrivate = local;\n                    buffer->pOutputPortPrivate = NULL;\n                    buffer->pBuffer = local->data[0];\n                    need_copy = 0;\n                }\n            } else {\n                // If not, we need to allocate a new buffer with the right\n                // size and copy the input frame into it.\n                uint8_t *buf = NULL;\n                int image_buffer_size = av_image_get_buffer_size(avctx->pix_fmt, s->stride, s->plane_size, 1);\n                if (image_buffer_size >= 0)\n                    buf = av_malloc(image_buffer_size);\n                if (!buf) {\n                    // Return the buffer to the queue so it's not lost\n                    append_buffer(&s->input_mutex, &s->input_cond, &s->num_free_in_buffers, s->free_in_buffers, buffer);\n                    return AVERROR(ENOMEM);\n                } else {\n                    buffer->pAppPrivate = buf;\n                    // Mark that pAppPrivate is an av_malloc'ed buffer, not an AVFrame\n                    buffer->pOutputPortPrivate = (void*) 1;\n                    buffer->pBuffer = buf;\n                    need_copy = 1;\n                    buffer->nFilledLen = av_image_fill_arrays(dst, linesize, buffer->pBuffer, avctx->pix_fmt, s->stride, s->plane_size, 1);\n                }\n            }\n        } else {\n            need_copy = 1;\n        }\n        if (need_copy)\n            av_image_copy(dst, linesize, (const uint8_t**) frame->data, frame->linesize, avctx->pix_fmt, avctx->width, avctx->height);\n        buffer->nFlags = OMX_BUFFERFLAG_ENDOFFRAME;\n        buffer->nOffset = 0;\n        // Convert the timestamps to microseconds; some encoders can ignore\n        // the framerate and do VFR bit allocation based on timestamps.\n        buffer->nTimeStamp = to_omx_ticks(av_rescale_q(frame->pts, avctx->time_base, AV_TIME_BASE_Q));\n        err = OMX_EmptyThisBuffer(s->handle, buffer);\n        if (err != OMX_ErrorNone) {\n            append_buffer(&s->input_mutex, &s->input_cond, &s->num_free_in_buffers, s->free_in_buffers, buffer);\n            av_log(avctx, AV_LOG_ERROR, \"OMX_EmptyThisBuffer failed: %x\\n\", err);\n            return AVERROR_UNKNOWN;\n        }\n    } else if (!s->eos_sent) {\n        buffer = get_buffer(&s->input_mutex, &s->input_cond,\n                            &s->num_free_in_buffers, s->free_in_buffers, 1);\n\n        buffer->nFilledLen = 0;\n        buffer->nFlags = OMX_BUFFERFLAG_EOS;\n        buffer->pAppPrivate = buffer->pOutputPortPrivate = NULL;\n        err = OMX_EmptyThisBuffer(s->handle, buffer);\n        if (err != OMX_ErrorNone) {\n            append_buffer(&s->input_mutex, &s->input_cond, &s->num_free_in_buffers, s->free_in_buffers, buffer);\n            av_log(avctx, AV_LOG_ERROR, \"OMX_EmptyThisBuffer failed: %x\\n\", err);\n            return AVERROR_UNKNOWN;\n        }\n        s->eos_sent = 1;\n    }\n\n    while (!*got_packet && ret == 0 && !s->got_eos) {\n        // If not flushing, just poll the queue if there's finished packets.\n        // If flushing, do a blocking wait until we either get a completed\n        // packet, or get EOS.\n        buffer = get_buffer(&s->output_mutex, &s->output_cond,\n                            &s->num_done_out_buffers, s->done_out_buffers,\n                            !frame);\n        if (!buffer)\n            break;\n\n        if (buffer->nFlags & OMX_BUFFERFLAG_EOS)\n            s->got_eos = 1;\n\n        if (buffer->nFlags & OMX_BUFFERFLAG_CODECCONFIG && avctx->flags & AV_CODEC_FLAG_GLOBAL_HEADER) {\n            if ((ret = av_reallocp(&avctx->extradata, avctx->extradata_size + buffer->nFilledLen + AV_INPUT_BUFFER_PADDING_SIZE)) < 0) {\n                avctx->extradata_size = 0;\n                goto end;\n            }\n            memcpy(avctx->extradata + avctx->extradata_size, buffer->pBuffer + buffer->nOffset, buffer->nFilledLen);\n            avctx->extradata_size += buffer->nFilledLen;\n            memset(avctx->extradata + avctx->extradata_size, 0, AV_INPUT_BUFFER_PADDING_SIZE);\n        } else {\n            if (!(buffer->nFlags & OMX_BUFFERFLAG_ENDOFFRAME) || !pkt->data) {\n                // If the output packet isn't preallocated, just concatenate everything in our\n                // own buffer\n                int newsize = s->output_buf_size + buffer->nFilledLen + AV_INPUT_BUFFER_PADDING_SIZE;\n                if ((ret = av_reallocp(&s->output_buf, newsize)) < 0) {\n                    s->output_buf_size = 0;\n                    goto end;\n                }\n                memcpy(s->output_buf + s->output_buf_size, buffer->pBuffer + buffer->nOffset, buffer->nFilledLen);\n                s->output_buf_size += buffer->nFilledLen;\n                if (buffer->nFlags & OMX_BUFFERFLAG_ENDOFFRAME) {\n                    if ((ret = av_packet_from_data(pkt, s->output_buf, s->output_buf_size)) < 0) {\n                        av_freep(&s->output_buf);\n                        s->output_buf_size = 0;\n                        goto end;\n                    }\n                    s->output_buf = NULL;\n                    s->output_buf_size = 0;\n                }\n            } else {\n                // End of frame, and the caller provided a preallocated frame\n                if ((ret = ff_alloc_packet2(avctx, pkt, s->output_buf_size + buffer->nFilledLen, 0)) < 0) {\n                    av_log(avctx, AV_LOG_ERROR, \"Error getting output packet of size %d.\\n\",\n                           (int)(s->output_buf_size + buffer->nFilledLen));\n                    goto end;\n                }\n                memcpy(pkt->data, s->output_buf, s->output_buf_size);\n                memcpy(pkt->data + s->output_buf_size, buffer->pBuffer + buffer->nOffset, buffer->nFilledLen);\n                av_freep(&s->output_buf);\n                s->output_buf_size = 0;\n            }\n            if (buffer->nFlags & OMX_BUFFERFLAG_ENDOFFRAME) {\n                pkt->pts = av_rescale_q(from_omx_ticks(buffer->nTimeStamp), AV_TIME_BASE_Q, avctx->time_base);\n                // We don't currently enable B-frames for the encoders, so set\n                // pkt->dts = pkt->pts. (The calling code behaves worse if the encoder\n                // doesn't set the dts).\n                pkt->dts = pkt->pts;\n                if (buffer->nFlags & OMX_BUFFERFLAG_SYNCFRAME)\n                    pkt->flags |= AV_PKT_FLAG_KEY;\n                *got_packet = 1;\n            }\n        }\nend:\n        err = OMX_FillThisBuffer(s->handle, buffer);\n        if (err != OMX_ErrorNone) {\n            append_buffer(&s->output_mutex, &s->output_cond, &s->num_done_out_buffers, s->done_out_buffers, buffer);\n            av_log(avctx, AV_LOG_ERROR, \"OMX_FillThisBuffer failed: %x\\n\", err);\n            ret = AVERROR_UNKNOWN;\n        }\n    }\n    return ret;\n}\n\nstatic av_cold int omx_encode_end(AVCodecContext *avctx)\n{\n    OMXCodecContext *s = avctx->priv_data;\n\n    cleanup(s);\n    return 0;\n}\n\n#define OFFSET(x) offsetof(OMXCodecContext, x)\n#define VDE AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_DECODING_PARAM | AV_OPT_FLAG_ENCODING_PARAM\n#define VE  AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_ENCODING_PARAM\nstatic const AVOption options[] = {\n    { \"omx_libname\", \"OpenMAX library name\", OFFSET(libname), AV_OPT_TYPE_STRING, { 0 }, 0, 0, VDE },\n    { \"omx_libprefix\", \"OpenMAX library prefix\", OFFSET(libprefix), AV_OPT_TYPE_STRING, { 0 }, 0, 0, VDE },\n    { \"zerocopy\", \"Try to avoid copying input frames if possible\", OFFSET(input_zerocopy), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 1, VE },\n    { \"profile\",  \"Set the encoding profile\", OFFSET(profile), AV_OPT_TYPE_INT,   { .i64 = FF_PROFILE_UNKNOWN },       FF_PROFILE_UNKNOWN, FF_PROFILE_H264_HIGH, VE, \"profile\" },\n    { \"baseline\", \"\",                         0,               AV_OPT_TYPE_CONST, { .i64 = FF_PROFILE_H264_BASELINE }, 0, 0, VE, \"profile\" },\n    { \"main\",     \"\",                         0,               AV_OPT_TYPE_CONST, { .i64 = FF_PROFILE_H264_MAIN },     0, 0, VE, \"profile\" },\n    { \"high\",     \"\",                         0,               AV_OPT_TYPE_CONST, { .i64 = FF_PROFILE_H264_HIGH },     0, 0, VE, \"profile\" },\n    { NULL }\n};\n\nstatic const enum AVPixelFormat omx_encoder_pix_fmts[] = {\n    AV_PIX_FMT_YUV420P, AV_PIX_FMT_NONE\n};\n\nstatic const AVClass omx_mpeg4enc_class = {\n    .class_name = \"mpeg4_omx\",\n    .item_name  = av_default_item_name,\n    .option     = options,\n    .version    = LIBAVUTIL_VERSION_INT,\n};\nAVCodec ff_mpeg4_omx_encoder = {\n    .name             = \"mpeg4_omx\",\n    .long_name        = NULL_IF_CONFIG_SMALL(\"OpenMAX IL MPEG-4 video encoder\"),\n    .type             = AVMEDIA_TYPE_VIDEO,\n    .id               = AV_CODEC_ID_MPEG4,\n    .priv_data_size   = sizeof(OMXCodecContext),\n    .init             = omx_encode_init,\n    .encode2          = omx_encode_frame,\n    .close            = omx_encode_end,\n    .pix_fmts         = omx_encoder_pix_fmts,\n    .capabilities     = AV_CODEC_CAP_DELAY,\n    .caps_internal    = FF_CODEC_CAP_INIT_THREADSAFE | FF_CODEC_CAP_INIT_CLEANUP,\n    .priv_class       = &omx_mpeg4enc_class,\n};\n\nstatic const AVClass omx_h264enc_class = {\n    .class_name = \"h264_omx\",\n    .item_name  = av_default_item_name,\n    .option     = options,\n    .version    = LIBAVUTIL_VERSION_INT,\n};\nAVCodec ff_h264_omx_encoder = {\n    .name             = \"h264_omx\",\n    .long_name        = NULL_IF_CONFIG_SMALL(\"OpenMAX IL H.264 video encoder\"),\n    .type             = AVMEDIA_TYPE_VIDEO,\n    .id               = AV_CODEC_ID_H264,\n    .priv_data_size   = sizeof(OMXCodecContext),\n    .init             = omx_encode_init,\n    .encode2          = omx_encode_frame,\n    .close            = omx_encode_end,\n    .pix_fmts         = omx_encoder_pix_fmts,\n    .capabilities     = AV_CODEC_CAP_DELAY,\n    .caps_internal    = FF_CODEC_CAP_INIT_THREADSAFE | FF_CODEC_CAP_INIT_CLEANUP,\n    .priv_class       = &omx_h264enc_class,\n};\n",
        "/tmp/vanessa/spack-stage/spack-stage-ffmpeg-4.1-sdpvlh5k2flacnv4x524fsjycqueu4ji/spack-src/libavcodec/amfenc.c": "/*\n * This file is part of FFmpeg.\n *\n * FFmpeg is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License as published by the Free Software Foundation; either\n * version 2.1 of the License, or (at your option) any later version.\n *\n * FFmpeg is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with FFmpeg; if not, write to the Free Software\n * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n */\n\n#include \"config.h\"\n\n#include \"libavutil/avassert.h\"\n#include \"libavutil/imgutils.h\"\n#include \"libavutil/hwcontext.h\"\n#if CONFIG_D3D11VA\n#include \"libavutil/hwcontext_d3d11va.h\"\n#endif\n#if CONFIG_DXVA2\n#define COBJMACROS\n#include \"libavutil/hwcontext_dxva2.h\"\n#endif\n#include \"libavutil/mem.h\"\n#include \"libavutil/pixdesc.h\"\n#include \"libavutil/time.h\"\n\n#include \"amfenc.h\"\n#include \"internal.h\"\n\n#if CONFIG_D3D11VA\n#include <d3d11.h>\n#endif\n\n#ifdef _WIN32\n#include \"compat/w32dlfcn.h\"\n#else\n#include <dlfcn.h>\n#endif\n\n#define FFMPEG_AMF_WRITER_ID L\"ffmpeg_amf\"\n\n#define PTS_PROP L\"PtsProp\"\n\nconst enum AVPixelFormat ff_amf_pix_fmts[] = {\n    AV_PIX_FMT_NV12,\n    AV_PIX_FMT_YUV420P,\n#if CONFIG_D3D11VA\n    AV_PIX_FMT_D3D11,\n#endif\n#if CONFIG_DXVA2\n    AV_PIX_FMT_DXVA2_VLD,\n#endif\n    AV_PIX_FMT_NONE\n};\n\ntypedef struct FormatMap {\n    enum AVPixelFormat       av_format;\n    enum AMF_SURFACE_FORMAT  amf_format;\n} FormatMap;\n\nstatic const FormatMap format_map[] =\n{\n    { AV_PIX_FMT_NONE,       AMF_SURFACE_UNKNOWN },\n    { AV_PIX_FMT_NV12,       AMF_SURFACE_NV12 },\n    { AV_PIX_FMT_BGR0,       AMF_SURFACE_BGRA },\n    { AV_PIX_FMT_RGB0,       AMF_SURFACE_RGBA },\n    { AV_PIX_FMT_GRAY8,      AMF_SURFACE_GRAY8 },\n    { AV_PIX_FMT_YUV420P,    AMF_SURFACE_YUV420P },\n    { AV_PIX_FMT_YUYV422,    AMF_SURFACE_YUY2 },\n};\n\nstatic enum AMF_SURFACE_FORMAT amf_av_to_amf_format(enum AVPixelFormat fmt)\n{\n    int i;\n    for (i = 0; i < amf_countof(format_map); i++) {\n        if (format_map[i].av_format == fmt) {\n            return format_map[i].amf_format;\n        }\n    }\n    return AMF_SURFACE_UNKNOWN;\n}\n\nstatic void AMF_CDECL_CALL AMFTraceWriter_Write(AMFTraceWriter *pThis,\n    const wchar_t *scope, const wchar_t *message)\n{\n    AmfTraceWriter *tracer = (AmfTraceWriter*)pThis;\n    av_log(tracer->avctx, AV_LOG_DEBUG, \"%ls: %ls\", scope, message); // \\n is provided from AMF\n}\n\nstatic void AMF_CDECL_CALL AMFTraceWriter_Flush(AMFTraceWriter *pThis)\n{\n}\n\nstatic AMFTraceWriterVtbl tracer_vtbl =\n{\n    .Write = AMFTraceWriter_Write,\n    .Flush = AMFTraceWriter_Flush,\n};\n\nstatic int amf_load_library(AVCodecContext *avctx)\n{\n    AmfContext        *ctx = avctx->priv_data;\n    AMFInit_Fn         init_fun;\n    AMFQueryVersion_Fn version_fun;\n    AMF_RESULT         res;\n\n    ctx->delayed_frame = av_frame_alloc();\n    if (!ctx->delayed_frame) {\n        return AVERROR(ENOMEM);\n    }\n    // hardcoded to current HW queue size - will realloc in timestamp_queue_enqueue() if too small\n    ctx->timestamp_list = av_fifo_alloc((avctx->max_b_frames + 16) * sizeof(int64_t));\n    if (!ctx->timestamp_list) {\n        return AVERROR(ENOMEM);\n    }\n    ctx->dts_delay = 0;\n\n\n    ctx->library = dlopen(AMF_DLL_NAMEA, RTLD_NOW | RTLD_LOCAL);\n    AMF_RETURN_IF_FALSE(ctx, ctx->library != NULL,\n        AVERROR_UNKNOWN, \"DLL %s failed to open\\n\", AMF_DLL_NAMEA);\n\n    init_fun = (AMFInit_Fn)dlsym(ctx->library, AMF_INIT_FUNCTION_NAME);\n    AMF_RETURN_IF_FALSE(ctx, init_fun != NULL, AVERROR_UNKNOWN, \"DLL %s failed to find function %s\\n\", AMF_DLL_NAMEA, AMF_INIT_FUNCTION_NAME);\n\n    version_fun = (AMFQueryVersion_Fn)dlsym(ctx->library, AMF_QUERY_VERSION_FUNCTION_NAME);\n    AMF_RETURN_IF_FALSE(ctx, version_fun != NULL, AVERROR_UNKNOWN, \"DLL %s failed to find function %s\\n\", AMF_DLL_NAMEA, AMF_QUERY_VERSION_FUNCTION_NAME);\n\n    res = version_fun(&ctx->version);\n    AMF_RETURN_IF_FALSE(ctx, res == AMF_OK, AVERROR_UNKNOWN, \"%s failed with error %d\\n\", AMF_QUERY_VERSION_FUNCTION_NAME, res);\n    res = init_fun(AMF_FULL_VERSION, &ctx->factory);\n    AMF_RETURN_IF_FALSE(ctx, res == AMF_OK, AVERROR_UNKNOWN, \"%s failed with error %d\\n\", AMF_INIT_FUNCTION_NAME, res);\n    res = ctx->factory->pVtbl->GetTrace(ctx->factory, &ctx->trace);\n    AMF_RETURN_IF_FALSE(ctx, res == AMF_OK, AVERROR_UNKNOWN, \"GetTrace() failed with error %d\\n\", res);\n    res = ctx->factory->pVtbl->GetDebug(ctx->factory, &ctx->debug);\n    AMF_RETURN_IF_FALSE(ctx, res == AMF_OK, AVERROR_UNKNOWN, \"GetDebug() failed with error %d\\n\", res);\n    return 0;\n}\n\n#if CONFIG_D3D11VA\nstatic int amf_init_from_d3d11_device(AVCodecContext *avctx, AVD3D11VADeviceContext *hwctx)\n{\n    AmfContext *ctx = avctx->priv_data;\n    AMF_RESULT res;\n\n    res = ctx->context->pVtbl->InitDX11(ctx->context, hwctx->device, AMF_DX11_1);\n    if (res != AMF_OK) {\n        if (res == AMF_NOT_SUPPORTED)\n            av_log(avctx, AV_LOG_ERROR, \"AMF via D3D11 is not supported on the given device.\\n\");\n        else\n            av_log(avctx, AV_LOG_ERROR, \"AMF failed to initialise on the given D3D11 device: %d.\\n\", res);\n        return AVERROR(ENODEV);\n    }\n\n    return 0;\n}\n#endif\n\n#if CONFIG_DXVA2\nstatic int amf_init_from_dxva2_device(AVCodecContext *avctx, AVDXVA2DeviceContext *hwctx)\n{\n    AmfContext *ctx = avctx->priv_data;\n    HANDLE device_handle;\n    IDirect3DDevice9 *device;\n    HRESULT hr;\n    AMF_RESULT res;\n    int ret;\n\n    hr = IDirect3DDeviceManager9_OpenDeviceHandle(hwctx->devmgr, &device_handle);\n    if (FAILED(hr)) {\n        av_log(avctx, AV_LOG_ERROR, \"Failed to open device handle for Direct3D9 device: %lx.\\n\", (unsigned long)hr);\n        return AVERROR_EXTERNAL;\n    }\n\n    hr = IDirect3DDeviceManager9_LockDevice(hwctx->devmgr, device_handle, &device, FALSE);\n    if (SUCCEEDED(hr)) {\n        IDirect3DDeviceManager9_UnlockDevice(hwctx->devmgr, device_handle, FALSE);\n        ret = 0;\n    } else {\n        av_log(avctx, AV_LOG_ERROR, \"Failed to lock device handle for Direct3D9 device: %lx.\\n\", (unsigned long)hr);\n        ret = AVERROR_EXTERNAL;\n    }\n\n    IDirect3DDeviceManager9_CloseDeviceHandle(hwctx->devmgr, device_handle);\n\n    if (ret < 0)\n        return ret;\n\n    res = ctx->context->pVtbl->InitDX9(ctx->context, device);\n\n    IDirect3DDevice9_Release(device);\n\n    if (res != AMF_OK) {\n        if (res == AMF_NOT_SUPPORTED)\n            av_log(avctx, AV_LOG_ERROR, \"AMF via D3D9 is not supported on the given device.\\n\");\n        else\n            av_log(avctx, AV_LOG_ERROR, \"AMF failed to initialise on given D3D9 device: %d.\\n\", res);\n        return AVERROR(ENODEV);\n    }\n\n    return 0;\n}\n#endif\n\nstatic int amf_init_context(AVCodecContext *avctx)\n{\n    AmfContext *ctx = avctx->priv_data;\n    AMF_RESULT  res;\n    av_unused int ret;\n\n    ctx->hwsurfaces_in_queue = 0;\n    ctx->hwsurfaces_in_queue_max = 16;\n\n    // configure AMF logger\n    // the return of these functions indicates old state and do not affect behaviour\n    ctx->trace->pVtbl->EnableWriter(ctx->trace, AMF_TRACE_WRITER_DEBUG_OUTPUT, ctx->log_to_dbg != 0 );\n    if (ctx->log_to_dbg)\n        ctx->trace->pVtbl->SetWriterLevel(ctx->trace, AMF_TRACE_WRITER_DEBUG_OUTPUT, AMF_TRACE_TRACE);\n    ctx->trace->pVtbl->EnableWriter(ctx->trace, AMF_TRACE_WRITER_CONSOLE, 0);\n    ctx->trace->pVtbl->SetGlobalLevel(ctx->trace, AMF_TRACE_TRACE);\n\n    // connect AMF logger to av_log\n    ctx->tracer.vtbl = &tracer_vtbl;\n    ctx->tracer.avctx = avctx;\n    ctx->trace->pVtbl->RegisterWriter(ctx->trace, FFMPEG_AMF_WRITER_ID,(AMFTraceWriter*)&ctx->tracer, 1);\n    ctx->trace->pVtbl->SetWriterLevel(ctx->trace, FFMPEG_AMF_WRITER_ID, AMF_TRACE_TRACE);\n\n    res = ctx->factory->pVtbl->CreateContext(ctx->factory, &ctx->context);\n    AMF_RETURN_IF_FALSE(ctx, res == AMF_OK, AVERROR_UNKNOWN, \"CreateContext() failed with error %d\\n\", res);\n\n    // If a device was passed to the encoder, try to initialise from that.\n    if (avctx->hw_frames_ctx) {\n        AVHWFramesContext *frames_ctx = (AVHWFramesContext*)avctx->hw_frames_ctx->data;\n\n        if (amf_av_to_amf_format(frames_ctx->sw_format) == AMF_SURFACE_UNKNOWN) {\n            av_log(avctx, AV_LOG_ERROR, \"Format of input frames context (%s) is not supported by AMF.\\n\",\n                   av_get_pix_fmt_name(frames_ctx->sw_format));\n            return AVERROR(EINVAL);\n        }\n\n        switch (frames_ctx->device_ctx->type) {\n#if CONFIG_D3D11VA\n        case AV_HWDEVICE_TYPE_D3D11VA:\n            ret = amf_init_from_d3d11_device(avctx, frames_ctx->device_ctx->hwctx);\n            if (ret < 0)\n                return ret;\n            break;\n#endif\n#if CONFIG_DXVA2\n        case AV_HWDEVICE_TYPE_DXVA2:\n            ret = amf_init_from_dxva2_device(avctx, frames_ctx->device_ctx->hwctx);\n            if (ret < 0)\n                return ret;\n            break;\n#endif\n        default:\n            av_log(avctx, AV_LOG_ERROR, \"AMF initialisation from a %s frames context is not supported.\\n\",\n                   av_hwdevice_get_type_name(frames_ctx->device_ctx->type));\n            return AVERROR(ENOSYS);\n        }\n\n        ctx->hw_frames_ctx = av_buffer_ref(avctx->hw_frames_ctx);\n        if (!ctx->hw_frames_ctx)\n            return AVERROR(ENOMEM);\n\n        if (frames_ctx->initial_pool_size > 0)\n            ctx->hwsurfaces_in_queue_max = frames_ctx->initial_pool_size - 1;\n\n    } else if (avctx->hw_device_ctx) {\n        AVHWDeviceContext *device_ctx = (AVHWDeviceContext*)avctx->hw_device_ctx->data;\n\n        switch (device_ctx->type) {\n#if CONFIG_D3D11VA\n        case AV_HWDEVICE_TYPE_D3D11VA:\n            ret = amf_init_from_d3d11_device(avctx, device_ctx->hwctx);\n            if (ret < 0)\n                return ret;\n            break;\n#endif\n#if CONFIG_DXVA2\n        case AV_HWDEVICE_TYPE_DXVA2:\n            ret = amf_init_from_dxva2_device(avctx, device_ctx->hwctx);\n            if (ret < 0)\n                return ret;\n            break;\n#endif\n        default:\n            av_log(avctx, AV_LOG_ERROR, \"AMF initialisation from a %s device is not supported.\\n\",\n                   av_hwdevice_get_type_name(device_ctx->type));\n            return AVERROR(ENOSYS);\n        }\n\n        ctx->hw_device_ctx = av_buffer_ref(avctx->hw_device_ctx);\n        if (!ctx->hw_device_ctx)\n            return AVERROR(ENOMEM);\n\n    } else {\n        res = ctx->context->pVtbl->InitDX11(ctx->context, NULL, AMF_DX11_1);\n        if (res == AMF_OK) {\n            av_log(avctx, AV_LOG_VERBOSE, \"AMF initialisation succeeded via D3D11.\\n\");\n        } else {\n            res = ctx->context->pVtbl->InitDX9(ctx->context, NULL);\n            if (res == AMF_OK) {\n                av_log(avctx, AV_LOG_VERBOSE, \"AMF initialisation succeeded via D3D9.\\n\");\n            } else {\n                av_log(avctx, AV_LOG_ERROR, \"AMF initialisation failed via D3D9: error %d.\\n\", res);\n                return AVERROR(ENOSYS);\n            }\n        }\n    }\n    return 0;\n}\n\nstatic int amf_init_encoder(AVCodecContext *avctx)\n{\n    AmfContext        *ctx = avctx->priv_data;\n    const wchar_t     *codec_id = NULL;\n    AMF_RESULT         res;\n    enum AVPixelFormat pix_fmt;\n\n    switch (avctx->codec->id) {\n        case AV_CODEC_ID_H264:\n            codec_id = AMFVideoEncoderVCE_AVC;\n            break;\n        case AV_CODEC_ID_HEVC:\n            codec_id = AMFVideoEncoder_HEVC;\n            break;\n        default:\n            break;\n    }\n    AMF_RETURN_IF_FALSE(ctx, codec_id != NULL, AVERROR(EINVAL), \"Codec %d is not supported\\n\", avctx->codec->id);\n\n    if (ctx->hw_frames_ctx)\n        pix_fmt = ((AVHWFramesContext*)ctx->hw_frames_ctx->data)->sw_format;\n    else\n        pix_fmt = avctx->pix_fmt;\n\n    ctx->format = amf_av_to_amf_format(pix_fmt);\n    AMF_RETURN_IF_FALSE(ctx, ctx->format != AMF_SURFACE_UNKNOWN, AVERROR(EINVAL),\n                        \"Format %s is not supported\\n\", av_get_pix_fmt_name(pix_fmt));\n\n    res = ctx->factory->pVtbl->CreateComponent(ctx->factory, ctx->context, codec_id, &ctx->encoder);\n    AMF_RETURN_IF_FALSE(ctx, res == AMF_OK, AVERROR_ENCODER_NOT_FOUND, \"CreateComponent(%ls) failed with error %d\\n\", codec_id, res);\n\n    return 0;\n}\n\nint av_cold ff_amf_encode_close(AVCodecContext *avctx)\n{\n    AmfContext *ctx = avctx->priv_data;\n\n    if (ctx->delayed_surface) {\n        ctx->delayed_surface->pVtbl->Release(ctx->delayed_surface);\n        ctx->delayed_surface = NULL;\n    }\n\n    if (ctx->encoder) {\n        ctx->encoder->pVtbl->Terminate(ctx->encoder);\n        ctx->encoder->pVtbl->Release(ctx->encoder);\n        ctx->encoder = NULL;\n    }\n\n    if (ctx->context) {\n        ctx->context->pVtbl->Terminate(ctx->context);\n        ctx->context->pVtbl->Release(ctx->context);\n        ctx->context = NULL;\n    }\n    av_buffer_unref(&ctx->hw_device_ctx);\n    av_buffer_unref(&ctx->hw_frames_ctx);\n\n    if (ctx->trace) {\n        ctx->trace->pVtbl->UnregisterWriter(ctx->trace, FFMPEG_AMF_WRITER_ID);\n    }\n    if (ctx->library) {\n        dlclose(ctx->library);\n        ctx->library = NULL;\n    }\n    ctx->trace = NULL;\n    ctx->debug = NULL;\n    ctx->factory = NULL;\n    ctx->version = 0;\n    ctx->delayed_drain = 0;\n    av_frame_free(&ctx->delayed_frame);\n    av_fifo_freep(&ctx->timestamp_list);\n\n    return 0;\n}\n\nstatic int amf_copy_surface(AVCodecContext *avctx, const AVFrame *frame,\n    AMFSurface* surface)\n{\n    AMFPlane *plane;\n    uint8_t  *dst_data[4];\n    int       dst_linesize[4];\n    int       planes;\n    int       i;\n\n    planes = surface->pVtbl->GetPlanesCount(surface);\n    av_assert0(planes < FF_ARRAY_ELEMS(dst_data));\n\n    for (i = 0; i < planes; i++) {\n        plane = surface->pVtbl->GetPlaneAt(surface, i);\n        dst_data[i] = plane->pVtbl->GetNative(plane);\n        dst_linesize[i] = plane->pVtbl->GetHPitch(plane);\n    }\n    av_image_copy(dst_data, dst_linesize,\n        (const uint8_t**)frame->data, frame->linesize, frame->format,\n        avctx->width, avctx->height);\n\n    return 0;\n}\n\nstatic inline int timestamp_queue_enqueue(AVCodecContext *avctx, int64_t timestamp)\n{\n    AmfContext         *ctx = avctx->priv_data;\n    if (av_fifo_space(ctx->timestamp_list) < sizeof(timestamp)) {\n        if (av_fifo_grow(ctx->timestamp_list, sizeof(timestamp)) < 0) {\n            return AVERROR(ENOMEM);\n        }\n    }\n    av_fifo_generic_write(ctx->timestamp_list, &timestamp, sizeof(timestamp), NULL);\n    return 0;\n}\n\nstatic int amf_copy_buffer(AVCodecContext *avctx, AVPacket *pkt, AMFBuffer *buffer)\n{\n    AmfContext      *ctx = avctx->priv_data;\n    int              ret;\n    AMFVariantStruct var = {0};\n    int64_t          timestamp = AV_NOPTS_VALUE;\n    int64_t          size = buffer->pVtbl->GetSize(buffer);\n\n    if ((ret = ff_alloc_packet2(avctx, pkt, size, 0)) < 0) {\n        return ret;\n    }\n    memcpy(pkt->data, buffer->pVtbl->GetNative(buffer), size);\n\n    switch (avctx->codec->id) {\n        case AV_CODEC_ID_H264:\n            buffer->pVtbl->GetProperty(buffer, AMF_VIDEO_ENCODER_OUTPUT_DATA_TYPE, &var);\n            if(var.int64Value == AMF_VIDEO_ENCODER_OUTPUT_DATA_TYPE_IDR) {\n                pkt->flags = AV_PKT_FLAG_KEY;\n            }\n            break;\n        case AV_CODEC_ID_HEVC:\n            buffer->pVtbl->GetProperty(buffer, AMF_VIDEO_ENCODER_HEVC_OUTPUT_DATA_TYPE, &var);\n            if (var.int64Value == AMF_VIDEO_ENCODER_HEVC_OUTPUT_DATA_TYPE_IDR) {\n                pkt->flags = AV_PKT_FLAG_KEY;\n            }\n            break;\n        default:\n            break;\n    }\n\n    buffer->pVtbl->GetProperty(buffer, PTS_PROP, &var);\n\n    pkt->pts = var.int64Value; // original pts\n\n\n    AMF_RETURN_IF_FALSE(ctx, av_fifo_size(ctx->timestamp_list) > 0, AVERROR_UNKNOWN, \"timestamp_list is empty\\n\");\n\n    av_fifo_generic_read(ctx->timestamp_list, &timestamp, sizeof(timestamp), NULL);\n\n    // calc dts shift if max_b_frames > 0\n    if (avctx->max_b_frames > 0 && ctx->dts_delay == 0) {\n        int64_t timestamp_last = AV_NOPTS_VALUE;\n        AMF_RETURN_IF_FALSE(ctx, av_fifo_size(ctx->timestamp_list) > 0, AVERROR_UNKNOWN,\n            \"timestamp_list is empty while max_b_frames = %d\\n\", avctx->max_b_frames);\n        av_fifo_generic_peek_at(\n            ctx->timestamp_list,\n            &timestamp_last,\n            (av_fifo_size(ctx->timestamp_list) / sizeof(timestamp) - 1) * sizeof(timestamp_last),\n            sizeof(timestamp_last),\n            NULL);\n        if (timestamp < 0 || timestamp_last < AV_NOPTS_VALUE) {\n            return AVERROR(ERANGE);\n        }\n        ctx->dts_delay = timestamp_last - timestamp;\n    }\n    pkt->dts = timestamp - ctx->dts_delay;\n    return 0;\n}\n\n// amfenc API implementation\nint ff_amf_encode_init(AVCodecContext *avctx)\n{\n    int ret;\n\n    if ((ret = amf_load_library(avctx)) == 0) {\n        if ((ret = amf_init_context(avctx)) == 0) {\n            if ((ret = amf_init_encoder(avctx)) == 0) {\n                return 0;\n            }\n        }\n    }\n    ff_amf_encode_close(avctx);\n    return ret;\n}\n\nstatic AMF_RESULT amf_set_property_buffer(AMFSurface *object, const wchar_t *name, AMFBuffer *val)\n{\n    AMF_RESULT res;\n    AMFVariantStruct var;\n    res = AMFVariantInit(&var);\n    if (res == AMF_OK) {\n        AMFGuid guid_AMFInterface = IID_AMFInterface();\n        AMFInterface *amf_interface;\n        res = val->pVtbl->QueryInterface(val, &guid_AMFInterface, (void**)&amf_interface);\n\n        if (res == AMF_OK) {\n            res = AMFVariantAssignInterface(&var, amf_interface);\n            amf_interface->pVtbl->Release(amf_interface);\n        }\n        if (res == AMF_OK) {\n            res = object->pVtbl->SetProperty(object, name, var);\n        }\n        AMFVariantClear(&var);\n    }\n    return res;\n}\n\nstatic AMF_RESULT amf_get_property_buffer(AMFData *object, const wchar_t *name, AMFBuffer **val)\n{\n    AMF_RESULT res;\n    AMFVariantStruct var;\n    res = AMFVariantInit(&var);\n    if (res == AMF_OK) {\n        res = object->pVtbl->GetProperty(object, name, &var);\n        if (res == AMF_OK) {\n            if (var.type == AMF_VARIANT_INTERFACE) {\n                AMFGuid guid_AMFBuffer = IID_AMFBuffer();\n                AMFInterface *amf_interface = AMFVariantInterface(&var);\n                res = amf_interface->pVtbl->QueryInterface(amf_interface, &guid_AMFBuffer, (void**)val);\n            } else {\n                res = AMF_INVALID_DATA_TYPE;\n            }\n        }\n        AMFVariantClear(&var);\n    }\n    return res;\n}\n\nstatic AMFBuffer *amf_create_buffer_with_frame_ref(const AVFrame *frame, AMFContext *context)\n{\n    AVFrame *frame_ref;\n    AMFBuffer *frame_ref_storage_buffer = NULL;\n    AMF_RESULT res;\n\n    res = context->pVtbl->AllocBuffer(context, AMF_MEMORY_HOST, sizeof(frame_ref), &frame_ref_storage_buffer);\n    if (res == AMF_OK) {\n        frame_ref = av_frame_clone(frame);\n        if (frame_ref) {\n            memcpy(frame_ref_storage_buffer->pVtbl->GetNative(frame_ref_storage_buffer), &frame_ref, sizeof(frame_ref));\n        } else {\n            frame_ref_storage_buffer->pVtbl->Release(frame_ref_storage_buffer);\n            frame_ref_storage_buffer = NULL;\n        }\n    }\n    return frame_ref_storage_buffer;\n}\n\nstatic void amf_release_buffer_with_frame_ref(AMFBuffer *frame_ref_storage_buffer)\n{\n    AVFrame *frame_ref;\n    memcpy(&frame_ref, frame_ref_storage_buffer->pVtbl->GetNative(frame_ref_storage_buffer), sizeof(frame_ref));\n    av_frame_free(&frame_ref);\n    frame_ref_storage_buffer->pVtbl->Release(frame_ref_storage_buffer);\n}\n\nint ff_amf_send_frame(AVCodecContext *avctx, const AVFrame *frame)\n{\n    AmfContext *ctx = avctx->priv_data;\n    AMFSurface *surface;\n    AMF_RESULT  res;\n    int         ret;\n\n    if (!ctx->encoder)\n        return AVERROR(EINVAL);\n\n    if (!frame) { // submit drain\n        if (!ctx->eof) { // submit drain one time only\n            if (ctx->delayed_surface != NULL) {\n                ctx->delayed_drain = 1; // input queue is full: resubmit Drain() in ff_amf_receive_packet\n            } else if(!ctx->delayed_drain) {\n                res = ctx->encoder->pVtbl->Drain(ctx->encoder);\n                if (res == AMF_INPUT_FULL) {\n                    ctx->delayed_drain = 1; // input queue is full: resubmit Drain() in ff_amf_receive_packet\n                } else {\n                    if (res == AMF_OK) {\n                        ctx->eof = 1; // drain started\n                    }\n                    AMF_RETURN_IF_FALSE(ctx, res == AMF_OK, AVERROR_UNKNOWN, \"Drain() failed with error %d\\n\", res);\n                }\n            }\n        } else{\n            return AVERROR_EOF;\n        }\n    } else { // submit frame\n        int hw_surface = 0;\n\n        if (ctx->delayed_surface != NULL) {\n            return AVERROR(EAGAIN); // should not happen when called from ffmpeg, other clients may resubmit\n        }\n        // prepare surface from frame\n        switch (frame->format) {\n#if CONFIG_D3D11VA\n        case AV_PIX_FMT_D3D11:\n            {\n                static const GUID AMFTextureArrayIndexGUID = { 0x28115527, 0xe7c3, 0x4b66, { 0x99, 0xd3, 0x4f, 0x2a, 0xe6, 0xb4, 0x7f, 0xaf } };\n                ID3D11Texture2D *texture = (ID3D11Texture2D*)frame->data[0]; // actual texture\n                int index = (intptr_t)frame->data[1]; // index is a slice in texture array is - set to tell AMF which slice to use\n\n                av_assert0(frame->hw_frames_ctx       && ctx->hw_frames_ctx &&\n                           frame->hw_frames_ctx->data == ctx->hw_frames_ctx->data);\n\n                texture->lpVtbl->SetPrivateData(texture, &AMFTextureArrayIndexGUID, sizeof(index), &index);\n\n                res = ctx->context->pVtbl->CreateSurfaceFromDX11Native(ctx->context, texture, &surface, NULL); // wrap to AMF surface\n                AMF_RETURN_IF_FALSE(ctx, res == AMF_OK, AVERROR(ENOMEM), \"CreateSurfaceFromDX11Native() failed  with error %d\\n\", res);\n\n                hw_surface = 1;\n            }\n            break;\n#endif\n#if CONFIG_DXVA2\n        case AV_PIX_FMT_DXVA2_VLD:\n            {\n                IDirect3DSurface9 *texture = (IDirect3DSurface9 *)frame->data[3]; // actual texture\n\n                res = ctx->context->pVtbl->CreateSurfaceFromDX9Native(ctx->context, texture, &surface, NULL); // wrap to AMF surface\n                AMF_RETURN_IF_FALSE(ctx, res == AMF_OK, AVERROR(ENOMEM), \"CreateSurfaceFromDX9Native() failed  with error %d\\n\", res);\n\n                hw_surface = 1;\n            }\n            break;\n#endif\n        default:\n            {\n                res = ctx->context->pVtbl->AllocSurface(ctx->context, AMF_MEMORY_HOST, ctx->format, avctx->width, avctx->height, &surface);\n                AMF_RETURN_IF_FALSE(ctx, res == AMF_OK, AVERROR(ENOMEM), \"AllocSurface() failed  with error %d\\n\", res);\n                amf_copy_surface(avctx, frame, surface);\n            }\n            break;\n        }\n\n        if (hw_surface) {\n            AMFBuffer *frame_ref_storage_buffer;\n\n            // input HW surfaces can be vertically aligned by 16; tell AMF the real size\n            surface->pVtbl->SetCrop(surface, 0, 0, frame->width, frame->height);\n\n            frame_ref_storage_buffer = amf_create_buffer_with_frame_ref(frame, ctx->context);\n            AMF_RETURN_IF_FALSE(ctx, frame_ref_storage_buffer != NULL, AVERROR(ENOMEM), \"create_buffer_with_frame_ref() returned NULL\\n\");\n\n            res = amf_set_property_buffer(surface, L\"av_frame_ref\", frame_ref_storage_buffer);\n            AMF_RETURN_IF_FALSE(ctx, res == AMF_OK, AVERROR_UNKNOWN, \"SetProperty failed for \\\"av_frame_ref\\\" with error %d\\n\", res);\n            ctx->hwsurfaces_in_queue++;\n            frame_ref_storage_buffer->pVtbl->Release(frame_ref_storage_buffer);\n        }\n\n        surface->pVtbl->SetPts(surface, frame->pts);\n        AMF_ASSIGN_PROPERTY_INT64(res, surface, PTS_PROP, frame->pts);\n\n        switch (avctx->codec->id) {\n        case AV_CODEC_ID_H264:\n            AMF_ASSIGN_PROPERTY_INT64(res, surface, AMF_VIDEO_ENCODER_INSERT_AUD, !!ctx->aud);\n            break;\n        case AV_CODEC_ID_HEVC:\n            AMF_ASSIGN_PROPERTY_INT64(res, surface, AMF_VIDEO_ENCODER_HEVC_INSERT_AUD, !!ctx->aud);\n            break;\n        default:\n            break;\n        }\n\n\n        // submit surface\n        res = ctx->encoder->pVtbl->SubmitInput(ctx->encoder, (AMFData*)surface);\n        if (res == AMF_INPUT_FULL) { // handle full queue\n            //store surface for later submission\n            ctx->delayed_surface = surface;\n            if (surface->pVtbl->GetMemoryType(surface) == AMF_MEMORY_DX11) {\n                av_frame_ref(ctx->delayed_frame, frame);\n            }\n        } else {\n            surface->pVtbl->Release(surface);\n            AMF_RETURN_IF_FALSE(ctx, res == AMF_OK, AVERROR_UNKNOWN, \"SubmitInput() failed with error %d\\n\", res);\n\n            if ((ret = timestamp_queue_enqueue(avctx, frame->pts)) < 0) {\n                return ret;\n            }\n\n        }\n    }\n    return 0;\n}\nint ff_amf_receive_packet(AVCodecContext *avctx, AVPacket *avpkt)\n{\n    int             ret;\n    AMF_RESULT      res;\n    AMF_RESULT      res_query;\n    AmfContext     *ctx = avctx->priv_data;\n    AMFData        *data = NULL;\n    int             block_and_wait;\n\n    if (!ctx->encoder)\n        return AVERROR(EINVAL);\n\n    do {\n        block_and_wait = 0;\n        // poll data\n        res_query = ctx->encoder->pVtbl->QueryOutput(ctx->encoder, &data);\n        if (data) {\n            // copy data to packet\n            AMFBuffer* buffer;\n            AMFGuid guid = IID_AMFBuffer();\n            data->pVtbl->QueryInterface(data, &guid, (void**)&buffer); // query for buffer interface\n            ret = amf_copy_buffer(avctx, avpkt, buffer);\n\n            buffer->pVtbl->Release(buffer);\n\n            if (data->pVtbl->HasProperty(data, L\"av_frame_ref\")) {\n                AMFBuffer *frame_ref_storage_buffer;\n                res = amf_get_property_buffer(data, L\"av_frame_ref\", &frame_ref_storage_buffer);\n                AMF_RETURN_IF_FALSE(ctx, res == AMF_OK, AVERROR_UNKNOWN, \"GetProperty failed for \\\"av_frame_ref\\\" with error %d\\n\", res);\n                amf_release_buffer_with_frame_ref(frame_ref_storage_buffer);\n                ctx->hwsurfaces_in_queue--;\n            }\n\n            data->pVtbl->Release(data);\n\n            AMF_RETURN_IF_FALSE(ctx, ret >= 0, ret, \"amf_copy_buffer() failed with error %d\\n\", ret);\n\n            if (ctx->delayed_surface != NULL) { // try to resubmit frame\n                res = ctx->encoder->pVtbl->SubmitInput(ctx->encoder, (AMFData*)ctx->delayed_surface);\n                if (res != AMF_INPUT_FULL) {\n                    int64_t pts = ctx->delayed_surface->pVtbl->GetPts(ctx->delayed_surface);\n                    ctx->delayed_surface->pVtbl->Release(ctx->delayed_surface);\n                    ctx->delayed_surface = NULL;\n                    av_frame_unref(ctx->delayed_frame);\n                    AMF_RETURN_IF_FALSE(ctx, res == AMF_OK, AVERROR_UNKNOWN, \"Repeated SubmitInput() failed with error %d\\n\", res);\n\n                    if ((ret = timestamp_queue_enqueue(avctx, pts)) < 0) {\n                        return ret;\n                    }\n                } else {\n                    av_log(avctx, AV_LOG_WARNING, \"Data acquired but delayed frame submission got AMF_INPUT_FULL- should not happen\\n\");\n                }\n            } else if (ctx->delayed_drain) { // try to resubmit drain\n                res = ctx->encoder->pVtbl->Drain(ctx->encoder);\n                if (res != AMF_INPUT_FULL) {\n                    ctx->delayed_drain = 0;\n                    ctx->eof = 1; // drain started\n                    AMF_RETURN_IF_FALSE(ctx, res == AMF_OK, AVERROR_UNKNOWN, \"Repeated Drain() failed with error %d\\n\", res);\n                } else {\n                    av_log(avctx, AV_LOG_WARNING, \"Data acquired but delayed drain submission got AMF_INPUT_FULL- should not happen\\n\");\n                }\n            }\n        } else if (ctx->delayed_surface != NULL || ctx->delayed_drain || (ctx->eof && res_query != AMF_EOF) || (ctx->hwsurfaces_in_queue >= ctx->hwsurfaces_in_queue_max)) {\n            block_and_wait = 1;\n            av_usleep(1000); // wait and poll again\n        }\n    } while (block_and_wait);\n\n    if (res_query == AMF_EOF) {\n        ret = AVERROR_EOF;\n    } else if (data == NULL) {\n        ret = AVERROR(EAGAIN);\n    } else {\n        ret = 0;\n    }\n    return ret;\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-ffmpeg-4.1-sdpvlh5k2flacnv4x524fsjycqueu4ji/spack-src/libavutil/hwcontext_dxva2.c": "/*\n * This file is part of FFmpeg.\n *\n * FFmpeg is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License as published by the Free Software Foundation; either\n * version 2.1 of the License, or (at your option) any later version.\n *\n * FFmpeg is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with FFmpeg; if not, write to the Free Software\n * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n */\n\n#include <windows.h>\n\n#define DXVA2API_USE_BITFIELDS\n#define COBJMACROS\n\n#include <d3d9.h>\n#include <dxva2api.h>\n#include <initguid.h>\n\n#include \"avassert.h\"\n#include \"common.h\"\n#include \"hwcontext.h\"\n#include \"hwcontext_dxva2.h\"\n#include \"hwcontext_internal.h\"\n#include \"imgutils.h\"\n#include \"pixdesc.h\"\n#include \"pixfmt.h\"\n#include \"compat/w32dlfcn.h\"\n\ntypedef IDirect3D9* WINAPI pDirect3DCreate9(UINT);\ntypedef HRESULT WINAPI pDirect3DCreate9Ex(UINT, IDirect3D9Ex **);\ntypedef HRESULT WINAPI pCreateDeviceManager9(UINT *, IDirect3DDeviceManager9 **);\n\n#define FF_D3DCREATE_FLAGS (D3DCREATE_SOFTWARE_VERTEXPROCESSING | \\\n                            D3DCREATE_MULTITHREADED | \\\n                            D3DCREATE_FPU_PRESERVE)\n\nstatic const D3DPRESENT_PARAMETERS dxva2_present_params = {\n    .Windowed         = TRUE,\n    .BackBufferWidth  = 640,\n    .BackBufferHeight = 480,\n    .BackBufferCount  = 0,\n    .SwapEffect       = D3DSWAPEFFECT_DISCARD,\n    .Flags            = D3DPRESENTFLAG_VIDEO,\n};\n\ntypedef struct DXVA2Mapping {\n    uint32_t palette_dummy[256];\n} DXVA2Mapping;\n\ntypedef struct DXVA2FramesContext {\n    IDirect3DSurface9 **surfaces_internal;\n    int              nb_surfaces_used;\n\n    HANDLE  device_handle;\n    IDirectXVideoAccelerationService *service;\n\n    D3DFORMAT format;\n} DXVA2FramesContext;\n\ntypedef struct DXVA2DevicePriv {\n    HMODULE d3dlib;\n    HMODULE dxva2lib;\n\n    HANDLE device_handle;\n\n    IDirect3D9       *d3d9;\n    IDirect3DDevice9 *d3d9device;\n} DXVA2DevicePriv;\n\nstatic const struct {\n    D3DFORMAT d3d_format;\n    enum AVPixelFormat pix_fmt;\n} supported_formats[] = {\n    { MKTAG('N', 'V', '1', '2'), AV_PIX_FMT_NV12 },\n    { MKTAG('P', '0', '1', '0'), AV_PIX_FMT_P010 },\n    { D3DFMT_P8,                 AV_PIX_FMT_PAL8 },\n};\n\nDEFINE_GUID(video_decoder_service,   0xfc51a551, 0xd5e7, 0x11d9, 0xaf, 0x55, 0x00, 0x05, 0x4e, 0x43, 0xff, 0x02);\nDEFINE_GUID(video_processor_service, 0xfc51a552, 0xd5e7, 0x11d9, 0xaf, 0x55, 0x00, 0x05, 0x4e, 0x43, 0xff, 0x02);\n\nstatic void dxva2_frames_uninit(AVHWFramesContext *ctx)\n{\n    AVDXVA2DeviceContext *device_hwctx = ctx->device_ctx->hwctx;\n    AVDXVA2FramesContext *frames_hwctx = ctx->hwctx;\n    DXVA2FramesContext *s = ctx->internal->priv;\n    int i;\n\n    if (frames_hwctx->decoder_to_release)\n        IDirectXVideoDecoder_Release(frames_hwctx->decoder_to_release);\n\n    if (s->surfaces_internal) {\n        for (i = 0; i < frames_hwctx->nb_surfaces; i++) {\n            if (s->surfaces_internal[i])\n                IDirect3DSurface9_Release(s->surfaces_internal[i]);\n        }\n    }\n    av_freep(&s->surfaces_internal);\n\n    if (s->service) {\n        IDirectXVideoAccelerationService_Release(s->service);\n        s->service = NULL;\n    }\n\n    if (s->device_handle != INVALID_HANDLE_VALUE) {\n        IDirect3DDeviceManager9_CloseDeviceHandle(device_hwctx->devmgr, s->device_handle);\n        s->device_handle = INVALID_HANDLE_VALUE;\n    }\n}\n\nstatic void dxva2_pool_release_dummy(void *opaque, uint8_t *data)\n{\n    // important not to free anything here--data is a surface object\n    // associated with the call to CreateSurface(), and these surfaces are\n    // released in dxva2_frames_uninit()\n}\n\nstatic AVBufferRef *dxva2_pool_alloc(void *opaque, int size)\n{\n    AVHWFramesContext      *ctx = (AVHWFramesContext*)opaque;\n    DXVA2FramesContext       *s = ctx->internal->priv;\n    AVDXVA2FramesContext *hwctx = ctx->hwctx;\n\n    if (s->nb_surfaces_used < hwctx->nb_surfaces) {\n        s->nb_surfaces_used++;\n        return av_buffer_create((uint8_t*)s->surfaces_internal[s->nb_surfaces_used - 1],\n                                sizeof(*hwctx->surfaces), dxva2_pool_release_dummy, 0, 0);\n    }\n\n    return NULL;\n}\n\nstatic int dxva2_init_pool(AVHWFramesContext *ctx)\n{\n    AVDXVA2FramesContext *frames_hwctx = ctx->hwctx;\n    AVDXVA2DeviceContext *device_hwctx = ctx->device_ctx->hwctx;\n    DXVA2FramesContext              *s = ctx->internal->priv;\n    int decode = (frames_hwctx->surface_type == DXVA2_VideoDecoderRenderTarget);\n\n    int i;\n    HRESULT hr;\n\n    if (ctx->initial_pool_size <= 0)\n        return 0;\n\n    hr = IDirect3DDeviceManager9_OpenDeviceHandle(device_hwctx->devmgr, &s->device_handle);\n    if (FAILED(hr)) {\n        av_log(ctx, AV_LOG_ERROR, \"Failed to open device handle\\n\");\n        return AVERROR_UNKNOWN;\n    }\n\n    hr = IDirect3DDeviceManager9_GetVideoService(device_hwctx->devmgr,\n                                                 s->device_handle,\n                                                 decode ? &video_decoder_service : &video_processor_service,\n                                                 (void **)&s->service);\n    if (FAILED(hr)) {\n        av_log(ctx, AV_LOG_ERROR, \"Failed to create the video service\\n\");\n        return AVERROR_UNKNOWN;\n    }\n\n    for (i = 0; i < FF_ARRAY_ELEMS(supported_formats); i++) {\n        if (ctx->sw_format == supported_formats[i].pix_fmt) {\n            s->format = supported_formats[i].d3d_format;\n            break;\n        }\n    }\n    if (i == FF_ARRAY_ELEMS(supported_formats)) {\n        av_log(ctx, AV_LOG_ERROR, \"Unsupported pixel format: %s\\n\",\n               av_get_pix_fmt_name(ctx->sw_format));\n        return AVERROR(EINVAL);\n    }\n\n    s->surfaces_internal = av_mallocz_array(ctx->initial_pool_size,\n                                            sizeof(*s->surfaces_internal));\n    if (!s->surfaces_internal)\n        return AVERROR(ENOMEM);\n\n    hr = IDirectXVideoAccelerationService_CreateSurface(s->service,\n                                                        ctx->width, ctx->height,\n                                                        ctx->initial_pool_size - 1,\n                                                        s->format, D3DPOOL_DEFAULT, 0,\n                                                        frames_hwctx->surface_type,\n                                                        s->surfaces_internal, NULL);\n    if (FAILED(hr)) {\n        av_log(ctx, AV_LOG_ERROR, \"Could not create the surfaces\\n\");\n        return AVERROR_UNKNOWN;\n    }\n\n    ctx->internal->pool_internal = av_buffer_pool_init2(sizeof(*s->surfaces_internal),\n                                                        ctx, dxva2_pool_alloc, NULL);\n    if (!ctx->internal->pool_internal)\n        return AVERROR(ENOMEM);\n\n    frames_hwctx->surfaces    = s->surfaces_internal;\n    frames_hwctx->nb_surfaces = ctx->initial_pool_size;\n\n    return 0;\n}\n\nstatic int dxva2_frames_init(AVHWFramesContext *ctx)\n{\n    AVDXVA2FramesContext *hwctx = ctx->hwctx;\n    DXVA2FramesContext       *s = ctx->internal->priv;\n    int ret;\n\n    if (hwctx->surface_type != DXVA2_VideoDecoderRenderTarget &&\n        hwctx->surface_type != DXVA2_VideoProcessorRenderTarget) {\n        av_log(ctx, AV_LOG_ERROR, \"Unknown surface type: %lu\\n\",\n               hwctx->surface_type);\n        return AVERROR(EINVAL);\n    }\n\n    s->device_handle = INVALID_HANDLE_VALUE;\n\n    /* init the frame pool if the caller didn't provide one */\n    if (!ctx->pool) {\n        ret = dxva2_init_pool(ctx);\n        if (ret < 0) {\n            av_log(ctx, AV_LOG_ERROR, \"Error creating an internal frame pool\\n\");\n            return ret;\n        }\n    }\n\n    return 0;\n}\n\nstatic int dxva2_get_buffer(AVHWFramesContext *ctx, AVFrame *frame)\n{\n    frame->buf[0] = av_buffer_pool_get(ctx->pool);\n    if (!frame->buf[0])\n        return AVERROR(ENOMEM);\n\n    frame->data[3] = frame->buf[0]->data;\n    frame->format  = AV_PIX_FMT_DXVA2_VLD;\n    frame->width   = ctx->width;\n    frame->height  = ctx->height;\n\n    return 0;\n}\n\nstatic int dxva2_transfer_get_formats(AVHWFramesContext *ctx,\n                                      enum AVHWFrameTransferDirection dir,\n                                      enum AVPixelFormat **formats)\n{\n    enum AVPixelFormat *fmts;\n\n    fmts = av_malloc_array(2, sizeof(*fmts));\n    if (!fmts)\n        return AVERROR(ENOMEM);\n\n    fmts[0] = ctx->sw_format;\n    fmts[1] = AV_PIX_FMT_NONE;\n\n    *formats = fmts;\n\n    return 0;\n}\n\nstatic void dxva2_unmap_frame(AVHWFramesContext *ctx, HWMapDescriptor *hwmap)\n{\n    IDirect3DSurface9 *surface = (IDirect3DSurface9*)hwmap->source->data[3];\n    IDirect3DSurface9_UnlockRect(surface);\n    av_freep(&hwmap->priv);\n}\n\nstatic int dxva2_map_frame(AVHWFramesContext *ctx, AVFrame *dst, const AVFrame *src,\n                           int flags)\n{\n    IDirect3DSurface9 *surface = (IDirect3DSurface9*)src->data[3];\n    DXVA2Mapping      *map;\n    D3DSURFACE_DESC    surfaceDesc;\n    D3DLOCKED_RECT     LockedRect;\n    HRESULT            hr;\n    int i, err, nb_planes;\n    int lock_flags = 0;\n\n    nb_planes = av_pix_fmt_count_planes(dst->format);\n\n    hr = IDirect3DSurface9_GetDesc(surface, &surfaceDesc);\n    if (FAILED(hr)) {\n        av_log(ctx, AV_LOG_ERROR, \"Error getting a surface description\\n\");\n        return AVERROR_UNKNOWN;\n    }\n\n    if (!(flags & AV_HWFRAME_MAP_WRITE))\n        lock_flags |= D3DLOCK_READONLY;\n    if (flags & AV_HWFRAME_MAP_OVERWRITE)\n        lock_flags |= D3DLOCK_DISCARD;\n\n    hr = IDirect3DSurface9_LockRect(surface, &LockedRect, NULL, lock_flags);\n    if (FAILED(hr)) {\n        av_log(ctx, AV_LOG_ERROR, \"Unable to lock DXVA2 surface\\n\");\n        return AVERROR_UNKNOWN;\n    }\n\n    map = av_mallocz(sizeof(*map));\n    if (!map) {\n        err = AVERROR(ENOMEM);\n        goto fail;\n    }\n\n    err = ff_hwframe_map_create(src->hw_frames_ctx, dst, src,\n                                dxva2_unmap_frame, map);\n    if (err < 0) {\n        av_freep(&map);\n        goto fail;\n    }\n\n    for (i = 0; i < nb_planes; i++)\n        dst->linesize[i] = LockedRect.Pitch;\n\n    av_image_fill_pointers(dst->data, dst->format, surfaceDesc.Height,\n                           (uint8_t*)LockedRect.pBits, dst->linesize);\n\n    if (dst->format == AV_PIX_FMT_PAL8)\n        dst->data[1] = (uint8_t*)map->palette_dummy;\n\n    return 0;\nfail:\n    IDirect3DSurface9_UnlockRect(surface);\n    return err;\n}\n\nstatic int dxva2_transfer_data_to(AVHWFramesContext *ctx, AVFrame *dst,\n                                  const AVFrame *src)\n{\n    AVFrame *map;\n    int ret;\n\n    if (src->format != ctx->sw_format)\n        return AVERROR(ENOSYS);\n\n    map = av_frame_alloc();\n    if (!map)\n        return AVERROR(ENOMEM);\n    map->format = dst->format;\n\n    ret = dxva2_map_frame(ctx, map, dst, AV_HWFRAME_MAP_WRITE | AV_HWFRAME_MAP_OVERWRITE);\n    if (ret < 0)\n        goto fail;\n\n    av_image_copy(map->data, map->linesize, src->data, src->linesize,\n                  ctx->sw_format, src->width, src->height);\n\nfail:\n    av_frame_free(&map);\n    return ret;\n}\n\nstatic int dxva2_transfer_data_from(AVHWFramesContext *ctx, AVFrame *dst,\n                                    const AVFrame *src)\n{\n    AVFrame *map;\n    ptrdiff_t src_linesize[4], dst_linesize[4];\n    int ret, i;\n\n    if (dst->format != ctx->sw_format)\n        return AVERROR(ENOSYS);\n\n    map = av_frame_alloc();\n    if (!map)\n        return AVERROR(ENOMEM);\n    map->format = dst->format;\n\n    ret = dxva2_map_frame(ctx, map, src, AV_HWFRAME_MAP_READ);\n    if (ret < 0)\n        goto fail;\n\n    for (i = 0; i < 4; i++) {\n        dst_linesize[i] = dst->linesize[i];\n        src_linesize[i] = map->linesize[i];\n    }\n    av_image_copy_uc_from(dst->data, dst_linesize, map->data, src_linesize,\n                          ctx->sw_format, src->width, src->height);\nfail:\n    av_frame_free(&map);\n    return ret;\n}\n\nstatic int dxva2_map_from(AVHWFramesContext *ctx,\n                          AVFrame *dst, const AVFrame *src, int flags)\n{\n    int err;\n\n    if (dst->format != AV_PIX_FMT_NONE && dst->format != ctx->sw_format)\n        return AVERROR(ENOSYS);\n    dst->format = ctx->sw_format;\n\n    err = dxva2_map_frame(ctx, dst, src, flags);\n    if (err < 0)\n        return err;\n\n    err = av_frame_copy_props(dst, src);\n    if (err < 0)\n        return err;\n\n    return 0;\n}\n\nstatic void dxva2_device_free(AVHWDeviceContext *ctx)\n{\n    AVDXVA2DeviceContext *hwctx = ctx->hwctx;\n    DXVA2DevicePriv       *priv = ctx->user_opaque;\n\n    if (hwctx->devmgr && priv->device_handle != INVALID_HANDLE_VALUE)\n        IDirect3DDeviceManager9_CloseDeviceHandle(hwctx->devmgr, priv->device_handle);\n\n    if (hwctx->devmgr)\n        IDirect3DDeviceManager9_Release(hwctx->devmgr);\n\n    if (priv->d3d9device)\n        IDirect3DDevice9_Release(priv->d3d9device);\n\n    if (priv->d3d9)\n        IDirect3D9_Release(priv->d3d9);\n\n    if (priv->d3dlib)\n        dlclose(priv->d3dlib);\n\n    if (priv->dxva2lib)\n        dlclose(priv->dxva2lib);\n\n    av_freep(&ctx->user_opaque);\n}\n\nstatic int dxva2_device_create9(AVHWDeviceContext *ctx, UINT adapter)\n{\n    DXVA2DevicePriv *priv = ctx->user_opaque;\n    D3DPRESENT_PARAMETERS d3dpp = dxva2_present_params;\n    D3DDISPLAYMODE d3ddm;\n    HRESULT hr;\n    pDirect3DCreate9 *createD3D = (pDirect3DCreate9 *)dlsym(priv->d3dlib, \"Direct3DCreate9\");\n    if (!createD3D) {\n        av_log(ctx, AV_LOG_ERROR, \"Failed to locate Direct3DCreate9\\n\");\n        return AVERROR_UNKNOWN;\n    }\n\n    priv->d3d9 = createD3D(D3D_SDK_VERSION);\n    if (!priv->d3d9) {\n        av_log(ctx, AV_LOG_ERROR, \"Failed to create IDirect3D object\\n\");\n        return AVERROR_UNKNOWN;\n    }\n\n    IDirect3D9_GetAdapterDisplayMode(priv->d3d9, adapter, &d3ddm);\n\n    d3dpp.BackBufferFormat = d3ddm.Format;\n\n    hr = IDirect3D9_CreateDevice(priv->d3d9, adapter, D3DDEVTYPE_HAL, GetDesktopWindow(),\n                                 FF_D3DCREATE_FLAGS,\n                                 &d3dpp, &priv->d3d9device);\n    if (FAILED(hr)) {\n        av_log(ctx, AV_LOG_ERROR, \"Failed to create Direct3D device\\n\");\n        return AVERROR_UNKNOWN;\n    }\n\n    return 0;\n}\n\nstatic int dxva2_device_create9ex(AVHWDeviceContext *ctx, UINT adapter)\n{\n    DXVA2DevicePriv *priv = ctx->user_opaque;\n    D3DPRESENT_PARAMETERS d3dpp = dxva2_present_params;\n    D3DDISPLAYMODEEX modeex = {0};\n    IDirect3D9Ex *d3d9ex = NULL;\n    IDirect3DDevice9Ex *exdev = NULL;\n    HRESULT hr;\n    pDirect3DCreate9Ex *createD3DEx = (pDirect3DCreate9Ex *)dlsym(priv->d3dlib, \"Direct3DCreate9Ex\");\n    if (!createD3DEx)\n        return AVERROR(ENOSYS);\n\n    hr = createD3DEx(D3D_SDK_VERSION, &d3d9ex);\n    if (FAILED(hr))\n        return AVERROR_UNKNOWN;\n\n    modeex.Size = sizeof(D3DDISPLAYMODEEX);\n    hr = IDirect3D9Ex_GetAdapterDisplayModeEx(d3d9ex, adapter, &modeex, NULL);\n    if (FAILED(hr)) {\n        IDirect3D9Ex_Release(d3d9ex);\n        return AVERROR_UNKNOWN;\n    }\n\n    d3dpp.BackBufferFormat = modeex.Format;\n\n    hr = IDirect3D9Ex_CreateDeviceEx(d3d9ex, adapter, D3DDEVTYPE_HAL, GetDesktopWindow(),\n                                     FF_D3DCREATE_FLAGS,\n                                     &d3dpp, NULL, &exdev);\n    if (FAILED(hr)) {\n        IDirect3D9Ex_Release(d3d9ex);\n        return AVERROR_UNKNOWN;\n    }\n\n    av_log(ctx, AV_LOG_VERBOSE, \"Using D3D9Ex device.\\n\");\n    priv->d3d9 = (IDirect3D9 *)d3d9ex;\n    priv->d3d9device = (IDirect3DDevice9 *)exdev;\n    return 0;\n}\n\nstatic int dxva2_device_create(AVHWDeviceContext *ctx, const char *device,\n                               AVDictionary *opts, int flags)\n{\n    AVDXVA2DeviceContext *hwctx = ctx->hwctx;\n    DXVA2DevicePriv *priv;\n    pCreateDeviceManager9 *createDeviceManager = NULL;\n    unsigned resetToken = 0;\n    UINT adapter = D3DADAPTER_DEFAULT;\n    HRESULT hr;\n    int err;\n\n    if (device)\n        adapter = atoi(device);\n\n    priv = av_mallocz(sizeof(*priv));\n    if (!priv)\n        return AVERROR(ENOMEM);\n\n    ctx->user_opaque = priv;\n    ctx->free        = dxva2_device_free;\n\n    priv->device_handle = INVALID_HANDLE_VALUE;\n\n    priv->d3dlib = dlopen(\"d3d9.dll\", 0);\n    if (!priv->d3dlib) {\n        av_log(ctx, AV_LOG_ERROR, \"Failed to load D3D9 library\\n\");\n        return AVERROR_UNKNOWN;\n    }\n    priv->dxva2lib = dlopen(\"dxva2.dll\", 0);\n    if (!priv->dxva2lib) {\n        av_log(ctx, AV_LOG_ERROR, \"Failed to load DXVA2 library\\n\");\n        return AVERROR_UNKNOWN;\n    }\n\n    createDeviceManager = (pCreateDeviceManager9 *)dlsym(priv->dxva2lib,\n                                                         \"DXVA2CreateDirect3DDeviceManager9\");\n    if (!createDeviceManager) {\n        av_log(ctx, AV_LOG_ERROR, \"Failed to locate DXVA2CreateDirect3DDeviceManager9\\n\");\n        return AVERROR_UNKNOWN;\n    }\n\n    if (dxva2_device_create9ex(ctx, adapter) < 0) {\n        // Retry with \"classic\" d3d9\n        err = dxva2_device_create9(ctx, adapter);\n        if (err < 0)\n            return err;\n    }\n\n    hr = createDeviceManager(&resetToken, &hwctx->devmgr);\n    if (FAILED(hr)) {\n        av_log(ctx, AV_LOG_ERROR, \"Failed to create Direct3D device manager\\n\");\n        return AVERROR_UNKNOWN;\n    }\n\n    hr = IDirect3DDeviceManager9_ResetDevice(hwctx->devmgr, priv->d3d9device, resetToken);\n    if (FAILED(hr)) {\n        av_log(ctx, AV_LOG_ERROR, \"Failed to bind Direct3D device to device manager\\n\");\n        return AVERROR_UNKNOWN;\n    }\n\n    hr = IDirect3DDeviceManager9_OpenDeviceHandle(hwctx->devmgr, &priv->device_handle);\n    if (FAILED(hr)) {\n        av_log(ctx, AV_LOG_ERROR, \"Failed to open device handle\\n\");\n        return AVERROR_UNKNOWN;\n    }\n\n    return 0;\n}\n\nconst HWContextType ff_hwcontext_type_dxva2 = {\n    .type                 = AV_HWDEVICE_TYPE_DXVA2,\n    .name                 = \"DXVA2\",\n\n    .device_hwctx_size    = sizeof(AVDXVA2DeviceContext),\n    .frames_hwctx_size    = sizeof(AVDXVA2FramesContext),\n    .frames_priv_size     = sizeof(DXVA2FramesContext),\n\n    .device_create        = dxva2_device_create,\n    .frames_init          = dxva2_frames_init,\n    .frames_uninit        = dxva2_frames_uninit,\n    .frames_get_buffer    = dxva2_get_buffer,\n    .transfer_get_formats = dxva2_transfer_get_formats,\n    .transfer_data_to     = dxva2_transfer_data_to,\n    .transfer_data_from   = dxva2_transfer_data_from,\n    .map_from             = dxva2_map_from,\n\n    .pix_fmts             = (const enum AVPixelFormat[]){ AV_PIX_FMT_DXVA2_VLD, AV_PIX_FMT_NONE },\n};\n"
    },
    "skipped": [
        "/tmp/vanessa/spack-stage/spack-stage-ffmpeg-4.1-sdpvlh5k2flacnv4x524fsjycqueu4ji/spack-src/tests/reference.pnm"
    ],
    "total_files": 3987
}