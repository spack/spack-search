{
    "matches": {
        "/tmp/vanessa/spack-stage/spack-stage-ffmpeg-3.2.4-tt6o4aq464a72ptcc3rjc7s6iclbxb35/spack-src/libavformat/avisynth.c": "/*\n * AviSynth/AvxSynth support\n * Copyright (c) 2012 AvxSynth Team\n *\n * This file is part of FFmpeg\n * FFmpeg is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License as published by the Free Software Foundation; either\n * version 2.1 of the License, or (at your option) any later version.\n *\n * FFmpeg is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with FFmpeg; if not, write to the Free Software\n * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n */\n\n#include \"libavutil/internal.h\"\n#include \"libavcodec/internal.h\"\n#include \"avformat.h\"\n#include \"internal.h\"\n#include \"config.h\"\n\n/* Enable function pointer definitions for runtime loading. */\n#define AVSC_NO_DECLSPEC\n\n/* Platform-specific directives for AviSynth vs AvxSynth. */\n#ifdef _WIN32\n  #include <windows.h>\n  #undef EXTERN_C\n  #include \"compat/avisynth/avisynth_c.h\"\n  #define AVISYNTH_LIB \"avisynth\"\n  #define USING_AVISYNTH\n#else\n  #include <dlfcn.h>\n  #include \"compat/avisynth/avxsynth_c.h\"\n  #define AVISYNTH_NAME \"libavxsynth\"\n  #define AVISYNTH_LIB AVISYNTH_NAME SLIBSUF\n\n  #define LoadLibrary(x) dlopen(x, RTLD_NOW | RTLD_LOCAL)\n  #define GetProcAddress dlsym\n  #define FreeLibrary dlclose\n#endif\n\ntypedef struct AviSynthLibrary {\n    void *library;\n#define AVSC_DECLARE_FUNC(name) name ## _func name\n    AVSC_DECLARE_FUNC(avs_bit_blt);\n    AVSC_DECLARE_FUNC(avs_clip_get_error);\n    AVSC_DECLARE_FUNC(avs_create_script_environment);\n    AVSC_DECLARE_FUNC(avs_delete_script_environment);\n    AVSC_DECLARE_FUNC(avs_get_audio);\n    AVSC_DECLARE_FUNC(avs_get_error);\n    AVSC_DECLARE_FUNC(avs_get_frame);\n    AVSC_DECLARE_FUNC(avs_get_version);\n    AVSC_DECLARE_FUNC(avs_get_video_info);\n    AVSC_DECLARE_FUNC(avs_invoke);\n    AVSC_DECLARE_FUNC(avs_release_clip);\n    AVSC_DECLARE_FUNC(avs_release_value);\n    AVSC_DECLARE_FUNC(avs_release_video_frame);\n    AVSC_DECLARE_FUNC(avs_take_clip);\n#ifdef USING_AVISYNTH\n    AVSC_DECLARE_FUNC(avs_bits_per_pixel);\n    AVSC_DECLARE_FUNC(avs_get_height_p);\n    AVSC_DECLARE_FUNC(avs_get_pitch_p);\n    AVSC_DECLARE_FUNC(avs_get_read_ptr_p);\n    AVSC_DECLARE_FUNC(avs_get_row_size_p);\n    AVSC_DECLARE_FUNC(avs_is_planar_rgb);\n    AVSC_DECLARE_FUNC(avs_is_planar_rgba);\n#endif\n#undef AVSC_DECLARE_FUNC\n} AviSynthLibrary;\n\ntypedef struct AviSynthContext {\n    AVS_ScriptEnvironment *env;\n    AVS_Clip *clip;\n    const AVS_VideoInfo *vi;\n\n    /* avisynth_read_packet_video() iterates over this. */\n    int n_planes;\n    const int *planes;\n\n    int curr_stream;\n    int curr_frame;\n    int64_t curr_sample;\n\n    int error;\n\n    /* Linked list pointers. */\n    struct AviSynthContext *next;\n} AviSynthContext;\n\nstatic const int avs_planes_packed[1] = { 0 };\nstatic const int avs_planes_grey[1]   = { AVS_PLANAR_Y };\nstatic const int avs_planes_yuv[3]    = { AVS_PLANAR_Y, AVS_PLANAR_U,\n                                          AVS_PLANAR_V };\n#ifdef USING_AVISYNTH\nstatic const int avs_planes_rgb[3]    = { AVS_PLANAR_G, AVS_PLANAR_B,\n                                          AVS_PLANAR_R };\nstatic const int avs_planes_yuva[4]   = { AVS_PLANAR_Y, AVS_PLANAR_U,\n                                          AVS_PLANAR_V, AVS_PLANAR_A };\nstatic const int avs_planes_rgba[4]   = { AVS_PLANAR_G, AVS_PLANAR_B,\n                                          AVS_PLANAR_R, AVS_PLANAR_A };\n#endif\n\n/* A conflict between C++ global objects, atexit, and dynamic loading requires\n * us to register our own atexit handler to prevent double freeing. */\nstatic AviSynthLibrary avs_library;\nstatic int avs_atexit_called        = 0;\n\n/* Linked list of AviSynthContexts. An atexit handler destroys this list. */\nstatic AviSynthContext *avs_ctx_list = NULL;\n\nstatic av_cold void avisynth_atexit_handler(void);\n\nstatic av_cold int avisynth_load_library(void)\n{\n    avs_library.library = LoadLibrary(AVISYNTH_LIB);\n    if (!avs_library.library)\n        return AVERROR_UNKNOWN;\n\n#define LOAD_AVS_FUNC(name, continue_on_fail)                          \\\n        avs_library.name =                                             \\\n            (void *)GetProcAddress(avs_library.library, #name);        \\\n        if (!continue_on_fail && !avs_library.name)                    \\\n            goto fail;\n\n    LOAD_AVS_FUNC(avs_bit_blt, 0);\n    LOAD_AVS_FUNC(avs_clip_get_error, 0);\n    LOAD_AVS_FUNC(avs_create_script_environment, 0);\n    LOAD_AVS_FUNC(avs_delete_script_environment, 0);\n    LOAD_AVS_FUNC(avs_get_audio, 0);\n    LOAD_AVS_FUNC(avs_get_error, 1); // New to AviSynth 2.6\n    LOAD_AVS_FUNC(avs_get_frame, 0);\n    LOAD_AVS_FUNC(avs_get_version, 0);\n    LOAD_AVS_FUNC(avs_get_video_info, 0);\n    LOAD_AVS_FUNC(avs_invoke, 0);\n    LOAD_AVS_FUNC(avs_release_clip, 0);\n    LOAD_AVS_FUNC(avs_release_value, 0);\n    LOAD_AVS_FUNC(avs_release_video_frame, 0);\n    LOAD_AVS_FUNC(avs_take_clip, 0);\n#ifdef USING_AVISYNTH\n    LOAD_AVS_FUNC(avs_bits_per_pixel, 1);\n    LOAD_AVS_FUNC(avs_get_height_p, 1);\n    LOAD_AVS_FUNC(avs_get_pitch_p, 1);\n    LOAD_AVS_FUNC(avs_get_read_ptr_p, 1);\n    LOAD_AVS_FUNC(avs_get_row_size_p, 1);\n    LOAD_AVS_FUNC(avs_is_planar_rgb, 1);\n    LOAD_AVS_FUNC(avs_is_planar_rgba, 1);\n#endif\n#undef LOAD_AVS_FUNC\n\n    atexit(avisynth_atexit_handler);\n    return 0;\n\nfail:\n    FreeLibrary(avs_library.library);\n    return AVERROR_UNKNOWN;\n}\n\n/* Note that avisynth_context_create and avisynth_context_destroy\n * do not allocate or free the actual context! That is taken care of\n * by libavformat. */\nstatic av_cold int avisynth_context_create(AVFormatContext *s)\n{\n    AviSynthContext *avs = s->priv_data;\n    int ret;\n\n    if (!avs_library.library)\n        if (ret = avisynth_load_library())\n            return ret;\n\n    avs->env = avs_library.avs_create_script_environment(3);\n    if (avs_library.avs_get_error) {\n        const char *error = avs_library.avs_get_error(avs->env);\n        if (error) {\n            av_log(s, AV_LOG_ERROR, \"%s\\n\", error);\n            return AVERROR_UNKNOWN;\n        }\n    }\n\n    if (!avs_ctx_list) {\n        avs_ctx_list = avs;\n    } else {\n        avs->next    = avs_ctx_list;\n        avs_ctx_list = avs;\n    }\n\n    return 0;\n}\n\nstatic av_cold void avisynth_context_destroy(AviSynthContext *avs)\n{\n    if (avs_atexit_called)\n        return;\n\n    if (avs == avs_ctx_list) {\n        avs_ctx_list = avs->next;\n    } else {\n        AviSynthContext *prev = avs_ctx_list;\n        while (prev->next != avs)\n            prev = prev->next;\n        prev->next = avs->next;\n    }\n\n    if (avs->clip) {\n        avs_library.avs_release_clip(avs->clip);\n        avs->clip = NULL;\n    }\n    if (avs->env) {\n        avs_library.avs_delete_script_environment(avs->env);\n        avs->env = NULL;\n    }\n}\n\nstatic av_cold void avisynth_atexit_handler(void)\n{\n    AviSynthContext *avs = avs_ctx_list;\n\n    while (avs) {\n        AviSynthContext *next = avs->next;\n        avisynth_context_destroy(avs);\n        avs = next;\n    }\n    FreeLibrary(avs_library.library);\n\n    avs_atexit_called = 1;\n}\n\n/* Create AVStream from audio and video data. */\nstatic int avisynth_create_stream_video(AVFormatContext *s, AVStream *st)\n{\n    AviSynthContext *avs = s->priv_data;\n    int planar = 0; // 0: packed, 1: YUV, 2: Y8, 3: Planar RGB, 4: YUVA, 5: Planar RGBA\n\n    st->codecpar->codec_type = AVMEDIA_TYPE_VIDEO;\n    st->codecpar->codec_id   = AV_CODEC_ID_RAWVIDEO;\n    st->codecpar->width      = avs->vi->width;\n    st->codecpar->height     = avs->vi->height;\n\n    st->avg_frame_rate    = (AVRational) { avs->vi->fps_numerator,\n                                           avs->vi->fps_denominator };\n    st->start_time        = 0;\n    st->duration          = avs->vi->num_frames;\n    st->nb_frames         = avs->vi->num_frames;\n    avpriv_set_pts_info(st, 32, avs->vi->fps_denominator, avs->vi->fps_numerator);\n\n    switch (avs->vi->pixel_type) {\n#ifdef USING_AVISYNTH\n/* 10~16-bit YUV pix_fmts (AviSynth+) */\n    case AVS_CS_YUV444P10:\n        st->codecpar->format = AV_PIX_FMT_YUV444P10;\n        planar               = 1;\n        break;\n    case AVS_CS_YUV422P10:\n        st->codecpar->format = AV_PIX_FMT_YUV422P10;\n        planar               = 1;\n        break;\n    case AVS_CS_YUV420P10:\n        st->codecpar->format = AV_PIX_FMT_YUV420P10;\n        planar               = 1;\n        break;\n    case AVS_CS_YUV444P12:\n        st->codecpar->format = AV_PIX_FMT_YUV444P12;\n        planar               = 1;\n        break;\n    case AVS_CS_YUV422P12:\n        st->codecpar->format = AV_PIX_FMT_YUV422P12;\n        planar               = 1;\n        break;\n    case AVS_CS_YUV420P12:\n        st->codecpar->format = AV_PIX_FMT_YUV420P12;\n        planar               = 1;\n        break;\n    case AVS_CS_YUV444P14:\n        st->codecpar->format = AV_PIX_FMT_YUV444P14;\n        planar               = 1;\n        break;\n    case AVS_CS_YUV422P14:\n        st->codecpar->format = AV_PIX_FMT_YUV422P14;\n        planar               = 1;\n        break;\n    case AVS_CS_YUV420P14:\n        st->codecpar->format = AV_PIX_FMT_YUV420P14;\n        planar               = 1;\n        break;\n    case AVS_CS_YUV444P16:\n        st->codecpar->format = AV_PIX_FMT_YUV444P16;\n        planar               = 1;\n        break;\n    case AVS_CS_YUV422P16:\n        st->codecpar->format = AV_PIX_FMT_YUV422P16;\n        planar               = 1;\n        break;\n    case AVS_CS_YUV420P16:\n        st->codecpar->format = AV_PIX_FMT_YUV420P16;\n        planar               = 1;\n        break;\n/* 8~16-bit YUV pix_fmts with Alpha (AviSynth+) */\n    case AVS_CS_YUVA444:\n        st->codecpar->format = AV_PIX_FMT_YUVA444P;\n        planar               = 4;\n        break;\n    case AVS_CS_YUVA422:\n        st->codecpar->format = AV_PIX_FMT_YUVA422P;\n        planar               = 4;\n        break;\n    case AVS_CS_YUVA420:\n        st->codecpar->format = AV_PIX_FMT_YUVA420P;\n        planar               = 4;\n        break;\n    case AVS_CS_YUVA444P10:\n        st->codecpar->format = AV_PIX_FMT_YUVA444P10;\n        planar               = 4;\n        break;\n    case AVS_CS_YUVA422P10:\n        st->codecpar->format = AV_PIX_FMT_YUVA422P10;\n        planar               = 4;\n        break;\n    case AVS_CS_YUVA420P10:\n        st->codecpar->format = AV_PIX_FMT_YUVA420P10;\n        planar               = 4;\n        break;\n    case AVS_CS_YUVA444P16:\n        st->codecpar->format = AV_PIX_FMT_YUVA444P16;\n        planar               = 4;\n        break;\n    case AVS_CS_YUVA422P16:\n        st->codecpar->format = AV_PIX_FMT_YUVA422P16;\n        planar               = 4;\n        break;\n    case AVS_CS_YUVA420P16:\n        st->codecpar->format = AV_PIX_FMT_YUVA420P16;\n        planar               = 4;\n        break;\n/* Planar RGB pix_fmts (AviSynth+)  */\n    case AVS_CS_RGBP:\n        st->codecpar->format = AV_PIX_FMT_GBRP;\n        planar               = 3;\n        break;\n    case AVS_CS_RGBP10:\n        st->codecpar->format = AV_PIX_FMT_GBRP10;\n        planar               = 3;\n        break;\n    case AVS_CS_RGBP12:\n        st->codecpar->format = AV_PIX_FMT_GBRP12;\n        planar               = 3;\n        break;\n    case AVS_CS_RGBP14:\n        st->codecpar->format = AV_PIX_FMT_GBRP14;\n        planar               = 3;\n        break;\n    case AVS_CS_RGBP16:\n        st->codecpar->format = AV_PIX_FMT_GBRP16;\n        planar               = 3;\n        break;\n/* Planar RGB pix_fmts with Alpha (AviSynth+) */\n    case AVS_CS_RGBAP:\n        st->codecpar->format = AV_PIX_FMT_GBRAP;\n        planar               = 5;\n        break;\n    case AVS_CS_RGBAP10:\n        st->codecpar->format = AV_PIX_FMT_GBRAP10;\n        planar               = 5;\n        break;\n    case AVS_CS_RGBAP12:\n        st->codecpar->format = AV_PIX_FMT_GBRAP12;\n        planar               = 5;\n        break;\n    case AVS_CS_RGBAP16:\n        st->codecpar->format = AV_PIX_FMT_GBRAP16;\n        planar               = 5;\n        break;\n/* GRAY16 (AviSynth+) */\n    case AVS_CS_Y16:\n        st->codecpar->format = AV_PIX_FMT_GRAY16;\n        planar               = 2;\n        break;\n/* pix_fmts added in AviSynth 2.6 */\n    case AVS_CS_YV24:\n        st->codecpar->format = AV_PIX_FMT_YUV444P;\n        planar               = 1;\n        break;\n    case AVS_CS_YV16:\n        st->codecpar->format = AV_PIX_FMT_YUV422P;\n        planar               = 1;\n        break;\n    case AVS_CS_YV411:\n        st->codecpar->format = AV_PIX_FMT_YUV411P;\n        planar               = 1;\n        break;\n    case AVS_CS_Y8:\n        st->codecpar->format = AV_PIX_FMT_GRAY8;\n        planar               = 2;\n        break;\n/* 16-bit packed RGB pix_fmts (AviSynth+) */\n    case AVS_CS_BGR48:\n        st->codecpar->format = AV_PIX_FMT_BGR48;\n        break;\n    case AVS_CS_BGR64:\n        st->codecpar->format = AV_PIX_FMT_BGRA64;\n        break;\n#endif\n/* AviSynth 2.5 and AvxSynth pix_fmts */\n    case AVS_CS_BGR24:\n        st->codecpar->format = AV_PIX_FMT_BGR24;\n        break;\n    case AVS_CS_BGR32:\n        st->codecpar->format = AV_PIX_FMT_RGB32;\n        break;\n    case AVS_CS_YUY2:\n        st->codecpar->format = AV_PIX_FMT_YUYV422;\n        break;\n    case AVS_CS_YV12:\n        st->codecpar->format = AV_PIX_FMT_YUV420P;\n        planar               = 1;\n        break;\n    case AVS_CS_I420: // Is this even used anywhere?\n        st->codecpar->format = AV_PIX_FMT_YUV420P;\n        planar               = 1;\n        break;\n    default:\n        av_log(s, AV_LOG_ERROR,\n               \"unknown AviSynth colorspace %d\\n\", avs->vi->pixel_type);\n        avs->error = 1;\n        return AVERROR_UNKNOWN;\n    }\n\n    switch (planar) {\n#ifdef USING_AVISYNTH\n    case 5: // Planar RGB + Alpha\n        avs->n_planes = 4;\n        avs->planes   = avs_planes_rgba;\n        break;\n    case 4: // YUV + Alpha\n        avs->n_planes = 4;\n        avs->planes   = avs_planes_yuva;\n        break;\n    case 3: // Planar RGB\n        avs->n_planes = 3;\n        avs->planes   = avs_planes_rgb;\n        break;\n#endif\n    case 2: // Y8\n        avs->n_planes = 1;\n        avs->planes   = avs_planes_grey;\n        break;\n    case 1: // YUV\n        avs->n_planes = 3;\n        avs->planes   = avs_planes_yuv;\n        break;\n    default:\n        avs->n_planes = 1;\n        avs->planes   = avs_planes_packed;\n    }\n    return 0;\n}\n\nstatic int avisynth_create_stream_audio(AVFormatContext *s, AVStream *st)\n{\n    AviSynthContext *avs = s->priv_data;\n\n    st->codecpar->codec_type  = AVMEDIA_TYPE_AUDIO;\n    st->codecpar->sample_rate = avs->vi->audio_samples_per_second;\n    st->codecpar->channels    = avs->vi->nchannels;\n    st->duration              = avs->vi->num_audio_samples;\n    avpriv_set_pts_info(st, 64, 1, avs->vi->audio_samples_per_second);\n\n    switch (avs->vi->sample_type) {\n    case AVS_SAMPLE_INT8:\n        st->codecpar->codec_id = AV_CODEC_ID_PCM_U8;\n        break;\n    case AVS_SAMPLE_INT16:\n        st->codecpar->codec_id = AV_CODEC_ID_PCM_S16LE;\n        break;\n    case AVS_SAMPLE_INT24:\n        st->codecpar->codec_id = AV_CODEC_ID_PCM_S24LE;\n        break;\n    case AVS_SAMPLE_INT32:\n        st->codecpar->codec_id = AV_CODEC_ID_PCM_S32LE;\n        break;\n    case AVS_SAMPLE_FLOAT:\n        st->codecpar->codec_id = AV_CODEC_ID_PCM_F32LE;\n        break;\n    default:\n        av_log(s, AV_LOG_ERROR,\n               \"unknown AviSynth sample type %d\\n\", avs->vi->sample_type);\n        avs->error = 1;\n        return AVERROR_UNKNOWN;\n    }\n    return 0;\n}\n\nstatic int avisynth_create_stream(AVFormatContext *s)\n{\n    AviSynthContext *avs = s->priv_data;\n    AVStream *st;\n    int ret;\n    int id = 0;\n\n    if (avs_has_video(avs->vi)) {\n        st = avformat_new_stream(s, NULL);\n        if (!st)\n            return AVERROR_UNKNOWN;\n        st->id = id++;\n        if (ret = avisynth_create_stream_video(s, st))\n            return ret;\n    }\n    if (avs_has_audio(avs->vi)) {\n        st = avformat_new_stream(s, NULL);\n        if (!st)\n            return AVERROR_UNKNOWN;\n        st->id = id++;\n        if (ret = avisynth_create_stream_audio(s, st))\n            return ret;\n    }\n    return 0;\n}\n\nstatic int avisynth_open_file(AVFormatContext *s)\n{\n    AviSynthContext *avs = s->priv_data;\n    AVS_Value arg, val;\n    int ret;\n#ifdef USING_AVISYNTH\n    char filename_ansi[MAX_PATH * 4];\n    wchar_t filename_wc[MAX_PATH * 4];\n#endif\n\n    if (ret = avisynth_context_create(s))\n        return ret;\n\n#ifdef USING_AVISYNTH\n    /* Convert UTF-8 to ANSI code page */\n    MultiByteToWideChar(CP_UTF8, 0, s->filename, -1, filename_wc, MAX_PATH * 4);\n    WideCharToMultiByte(CP_THREAD_ACP, 0, filename_wc, -1, filename_ansi,\n                        MAX_PATH * 4, NULL, NULL);\n    arg = avs_new_value_string(filename_ansi);\n#else\n    arg = avs_new_value_string(s->filename);\n#endif\n    val = avs_library.avs_invoke(avs->env, \"Import\", arg, 0);\n    if (avs_is_error(val)) {\n        av_log(s, AV_LOG_ERROR, \"%s\\n\", avs_as_error(val));\n        ret = AVERROR_UNKNOWN;\n        goto fail;\n    }\n    if (!avs_is_clip(val)) {\n        av_log(s, AV_LOG_ERROR, \"AviSynth script did not return a clip\\n\");\n        ret = AVERROR_UNKNOWN;\n        goto fail;\n    }\n\n    avs->clip = avs_library.avs_take_clip(val, avs->env);\n    avs->vi   = avs_library.avs_get_video_info(avs->clip);\n\n#ifdef USING_AVISYNTH\n    /* On Windows, FFmpeg supports AviSynth interface version 6 or higher.\n     * This includes AviSynth 2.6 RC1 or higher, and AviSynth+ r1718 or higher,\n     * and excludes 2.5 and the 2.6 alphas. Since AvxSynth identifies itself\n     * as interface version 3 like 2.5.8, this needs to be special-cased. */\n\n    if (avs_library.avs_get_version(avs->clip) < 6) {\n        av_log(s, AV_LOG_ERROR,\n               \"AviSynth version is too old. Please upgrade to either AviSynth 2.6 >= RC1 or AviSynth+ >= r1718.\\n\");\n        ret = AVERROR_UNKNOWN;\n        goto fail;\n    }\n#endif\n\n    /* Release the AVS_Value as it will go out of scope. */\n    avs_library.avs_release_value(val);\n\n    if (ret = avisynth_create_stream(s))\n        goto fail;\n\n    return 0;\n\nfail:\n    avisynth_context_destroy(avs);\n    return ret;\n}\n\nstatic void avisynth_next_stream(AVFormatContext *s, AVStream **st,\n                                 AVPacket *pkt, int *discard)\n{\n    AviSynthContext *avs = s->priv_data;\n\n    avs->curr_stream++;\n    avs->curr_stream %= s->nb_streams;\n\n    *st = s->streams[avs->curr_stream];\n    if ((*st)->discard == AVDISCARD_ALL)\n        *discard = 1;\n    else\n        *discard = 0;\n\n    return;\n}\n\n/* Copy AviSynth clip data into an AVPacket. */\nstatic int avisynth_read_packet_video(AVFormatContext *s, AVPacket *pkt,\n                                      int discard)\n{\n    AviSynthContext *avs = s->priv_data;\n    AVS_VideoFrame *frame;\n    unsigned char *dst_p;\n    const unsigned char *src_p;\n    int n, i, plane, rowsize, planeheight, pitch, bits;\n    const char *error;\n\n    if (avs->curr_frame >= avs->vi->num_frames)\n        return AVERROR_EOF;\n\n    /* This must happen even if the stream is discarded to prevent desync. */\n    n = avs->curr_frame++;\n    if (discard)\n        return 0;\n\n#ifdef USING_AVISYNTH\n    /* Detect whether we're using AviSynth 2.6 or AviSynth+ by\n     * looking for whether avs_is_planar_rgb exists. */\n\n    int avsplus;\n\n    if (GetProcAddress(avs_library.library, \"avs_is_planar_rgb\") == NULL)\n        avsplus = 0;\n    else\n        avsplus = 1;\n\n    /* avs_bits_per_pixel changed to AVSC_API with AviSynth 2.6, which\n     * requires going through avs_library, while AvxSynth has it under\n     * the older AVSC_INLINE type, so special-case this. */\n\n    bits = avs_library.avs_bits_per_pixel(avs->vi);\n#else\n    bits = avs_bits_per_pixel(avs->vi);\n#endif\n\n    /* Without the cast to int64_t, calculation overflows at about 9k x 9k\n     * resolution. */\n    pkt->size = (((int64_t)avs->vi->width *\n                  (int64_t)avs->vi->height) * bits) / 8;\n    if (!pkt->size)\n        return AVERROR_UNKNOWN;\n\n    if (av_new_packet(pkt, pkt->size) < 0)\n        return AVERROR(ENOMEM);\n\n    pkt->pts      = n;\n    pkt->dts      = n;\n    pkt->duration = 1;\n    pkt->stream_index = avs->curr_stream;\n\n    frame = avs_library.avs_get_frame(avs->clip, n);\n    error = avs_library.avs_clip_get_error(avs->clip);\n    if (error) {\n        av_log(s, AV_LOG_ERROR, \"%s\\n\", error);\n        avs->error = 1;\n        av_packet_unref(pkt);\n        return AVERROR_UNKNOWN;\n    }\n\n    dst_p = pkt->data;\n    for (i = 0; i < avs->n_planes; i++) {\n        plane = avs->planes[i];\n#ifdef USING_AVISYNTH\n        src_p = avs_library.avs_get_read_ptr_p(frame, plane);\n        pitch = avs_library.avs_get_pitch_p(frame, plane);\n\n        rowsize     = avs_library.avs_get_row_size_p(frame, plane);\n        planeheight = avs_library.avs_get_height_p(frame, plane);\n#else\n        src_p = avs_get_read_ptr_p(frame, plane);\n        pitch = avs_get_pitch_p(frame, plane);\n\n        rowsize     = avs_get_row_size_p(frame, plane);\n        planeheight = avs_get_height_p(frame, plane);\n#endif\n\n        /* Flip RGB video. */\n        if (avs_is_rgb24(avs->vi) || avs_is_rgb(avs->vi)) {\n            src_p = src_p + (planeheight - 1) * pitch;\n            pitch = -pitch;\n        }\n\n#ifdef USING_AVISYNTH\n        /* Flip Planar RGB video. */\n        if (avsplus && (avs_library.avs_is_planar_rgb(avs->vi) ||\n                        avs_library.avs_is_planar_rgba(avs->vi))) {\n            src_p = src_p + (planeheight - 1) * pitch;\n            pitch = -pitch;\n        }\n#endif\n\n        avs_library.avs_bit_blt(avs->env, dst_p, rowsize, src_p, pitch,\n                                 rowsize, planeheight);\n        dst_p += rowsize * planeheight;\n    }\n\n    avs_library.avs_release_video_frame(frame);\n    return 0;\n}\n\nstatic int avisynth_read_packet_audio(AVFormatContext *s, AVPacket *pkt,\n                                      int discard)\n{\n    AviSynthContext *avs = s->priv_data;\n    AVRational fps, samplerate;\n    int samples;\n    int64_t n;\n    const char *error;\n\n    if (avs->curr_sample >= avs->vi->num_audio_samples)\n        return AVERROR_EOF;\n\n    fps.num        = avs->vi->fps_numerator;\n    fps.den        = avs->vi->fps_denominator;\n    samplerate.num = avs->vi->audio_samples_per_second;\n    samplerate.den = 1;\n\n    if (avs_has_video(avs->vi)) {\n        if (avs->curr_frame < avs->vi->num_frames)\n            samples = av_rescale_q(avs->curr_frame, samplerate, fps) -\n                      avs->curr_sample;\n        else\n            samples = av_rescale_q(1, samplerate, fps);\n    } else {\n        samples = 1000;\n    }\n\n    /* After seeking, audio may catch up with video. */\n    if (samples <= 0) {\n        pkt->size = 0;\n        pkt->data = NULL;\n        return 0;\n    }\n\n    if (avs->curr_sample + samples > avs->vi->num_audio_samples)\n        samples = avs->vi->num_audio_samples - avs->curr_sample;\n\n    /* This must happen even if the stream is discarded to prevent desync. */\n    n                 = avs->curr_sample;\n    avs->curr_sample += samples;\n    if (discard)\n        return 0;\n\n    pkt->size = avs_bytes_per_channel_sample(avs->vi) *\n                samples * avs->vi->nchannels;\n    if (!pkt->size)\n        return AVERROR_UNKNOWN;\n\n    if (av_new_packet(pkt, pkt->size) < 0)\n        return AVERROR(ENOMEM);\n\n    pkt->pts      = n;\n    pkt->dts      = n;\n    pkt->duration = samples;\n    pkt->stream_index = avs->curr_stream;\n\n    avs_library.avs_get_audio(avs->clip, pkt->data, n, samples);\n    error = avs_library.avs_clip_get_error(avs->clip);\n    if (error) {\n        av_log(s, AV_LOG_ERROR, \"%s\\n\", error);\n        avs->error = 1;\n        av_packet_unref(pkt);\n        return AVERROR_UNKNOWN;\n    }\n    return 0;\n}\n\nstatic av_cold int avisynth_read_header(AVFormatContext *s)\n{\n    int ret;\n\n    // Calling library must implement a lock for thread-safe opens.\n    if (ret = avpriv_lock_avformat())\n        return ret;\n\n    if (ret = avisynth_open_file(s)) {\n        avpriv_unlock_avformat();\n        return ret;\n    }\n\n    avpriv_unlock_avformat();\n    return 0;\n}\n\nstatic int avisynth_read_packet(AVFormatContext *s, AVPacket *pkt)\n{\n    AviSynthContext *avs = s->priv_data;\n    AVStream *st;\n    int discard = 0;\n    int ret;\n\n    if (avs->error)\n        return AVERROR_UNKNOWN;\n\n    /* If either stream reaches EOF, try to read the other one before\n     * giving up. */\n    avisynth_next_stream(s, &st, pkt, &discard);\n    if (st->codecpar->codec_type == AVMEDIA_TYPE_VIDEO) {\n        ret = avisynth_read_packet_video(s, pkt, discard);\n        if (ret == AVERROR_EOF && avs_has_audio(avs->vi)) {\n            avisynth_next_stream(s, &st, pkt, &discard);\n            return avisynth_read_packet_audio(s, pkt, discard);\n        }\n    } else {\n        ret = avisynth_read_packet_audio(s, pkt, discard);\n        if (ret == AVERROR_EOF && avs_has_video(avs->vi)) {\n            avisynth_next_stream(s, &st, pkt, &discard);\n            return avisynth_read_packet_video(s, pkt, discard);\n        }\n    }\n\n    return ret;\n}\n\nstatic av_cold int avisynth_read_close(AVFormatContext *s)\n{\n    if (avpriv_lock_avformat())\n        return AVERROR_UNKNOWN;\n\n    avisynth_context_destroy(s->priv_data);\n    avpriv_unlock_avformat();\n    return 0;\n}\n\nstatic int avisynth_read_seek(AVFormatContext *s, int stream_index,\n                              int64_t timestamp, int flags)\n{\n    AviSynthContext *avs = s->priv_data;\n    AVStream *st;\n    AVRational fps, samplerate;\n\n    if (avs->error)\n        return AVERROR_UNKNOWN;\n\n    fps        = (AVRational) { avs->vi->fps_numerator,\n                                avs->vi->fps_denominator };\n    samplerate = (AVRational) { avs->vi->audio_samples_per_second, 1 };\n\n    st = s->streams[stream_index];\n    if (st->codecpar->codec_type == AVMEDIA_TYPE_VIDEO) {\n        /* AviSynth frame counts are signed int. */\n        if ((timestamp >= avs->vi->num_frames) ||\n            (timestamp > INT_MAX)              ||\n            (timestamp < 0))\n            return AVERROR_EOF;\n        avs->curr_frame = timestamp;\n        if (avs_has_audio(avs->vi))\n            avs->curr_sample = av_rescale_q(timestamp, samplerate, fps);\n    } else {\n        if ((timestamp >= avs->vi->num_audio_samples) || (timestamp < 0))\n            return AVERROR_EOF;\n        /* Force frame granularity for seeking. */\n        if (avs_has_video(avs->vi)) {\n            avs->curr_frame  = av_rescale_q(timestamp, fps, samplerate);\n            avs->curr_sample = av_rescale_q(avs->curr_frame, samplerate, fps);\n        } else {\n            avs->curr_sample = timestamp;\n        }\n    }\n\n    return 0;\n}\n\nAVInputFormat ff_avisynth_demuxer = {\n    .name           = \"avisynth\",\n    .long_name      = NULL_IF_CONFIG_SMALL(\"AviSynth script\"),\n    .priv_data_size = sizeof(AviSynthContext),\n    .read_header    = avisynth_read_header,\n    .read_packet    = avisynth_read_packet,\n    .read_close     = avisynth_read_close,\n    .read_seek      = avisynth_read_seek,\n    .extensions     = \"avs\",\n};\n",
        "/tmp/vanessa/spack-stage/spack-stage-ffmpeg-3.2.4-tt6o4aq464a72ptcc3rjc7s6iclbxb35/spack-src/libavfilter/vf_frei0r.c": "/*\n * Copyright (c) 2010 Stefano Sabatini\n * This file is part of FFmpeg.\n *\n * FFmpeg is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License as published by the Free Software Foundation; either\n * version 2.1 of the License, or (at your option) any later version.\n *\n * FFmpeg is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with FFmpeg; if not, write to the Free Software\n * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n */\n\n/**\n * @file\n * frei0r wrapper\n */\n\n#include <dlfcn.h>\n#include <frei0r.h>\n#include <stdio.h>\n#include <string.h>\n#include <stdlib.h>\n#include \"config.h\"\n#include \"libavutil/avstring.h\"\n#include \"libavutil/common.h\"\n#include \"libavutil/eval.h\"\n#include \"libavutil/imgutils.h\"\n#include \"libavutil/internal.h\"\n#include \"libavutil/mathematics.h\"\n#include \"libavutil/mem.h\"\n#include \"libavutil/opt.h\"\n#include \"libavutil/parseutils.h\"\n#include \"avfilter.h\"\n#include \"formats.h\"\n#include \"internal.h\"\n#include \"video.h\"\n\ntypedef f0r_instance_t (*f0r_construct_f)(unsigned int width, unsigned int height);\ntypedef void (*f0r_destruct_f)(f0r_instance_t instance);\ntypedef void (*f0r_deinit_f)(void);\ntypedef int (*f0r_init_f)(void);\ntypedef void (*f0r_get_plugin_info_f)(f0r_plugin_info_t *info);\ntypedef void (*f0r_get_param_info_f)(f0r_param_info_t *info, int param_index);\ntypedef void (*f0r_update_f)(f0r_instance_t instance, double time, const uint32_t *inframe, uint32_t *outframe);\ntypedef void (*f0r_update2_f)(f0r_instance_t instance, double time, const uint32_t *inframe1, const uint32_t *inframe2, const uint32_t *inframe3, uint32_t *outframe);\ntypedef void (*f0r_set_param_value_f)(f0r_instance_t instance, f0r_param_t param, int param_index);\ntypedef void (*f0r_get_param_value_f)(f0r_instance_t instance, f0r_param_t param, int param_index);\n\ntypedef struct Frei0rContext {\n    const AVClass *class;\n    f0r_update_f update;\n    void *dl_handle;            /* dynamic library handle   */\n    f0r_instance_t instance;\n    f0r_plugin_info_t plugin_info;\n\n    f0r_get_param_info_f  get_param_info;\n    f0r_get_param_value_f get_param_value;\n    f0r_set_param_value_f set_param_value;\n    f0r_construct_f       construct;\n    f0r_destruct_f        destruct;\n    f0r_deinit_f          deinit;\n\n    char *dl_name;\n    char *params;\n    AVRational framerate;\n\n    /* only used by the source */\n    int w, h;\n    AVRational time_base;\n    uint64_t pts;\n} Frei0rContext;\n\nstatic void *load_sym(AVFilterContext *ctx, const char *sym_name)\n{\n    Frei0rContext *s = ctx->priv;\n    void *sym = dlsym(s->dl_handle, sym_name);\n    if (!sym)\n        av_log(ctx, AV_LOG_ERROR, \"Could not find symbol '%s' in loaded module.\\n\", sym_name);\n    return sym;\n}\n\nstatic int set_param(AVFilterContext *ctx, f0r_param_info_t info, int index, char *param)\n{\n    Frei0rContext *s = ctx->priv;\n    union {\n        double d;\n        f0r_param_color_t col;\n        f0r_param_position_t pos;\n    } val;\n    char *tail;\n    uint8_t rgba[4];\n\n    switch (info.type) {\n    case F0R_PARAM_BOOL:\n        if      (!strcmp(param, \"y\")) val.d = 1.0;\n        else if (!strcmp(param, \"n\")) val.d = 0.0;\n        else goto fail;\n        break;\n\n    case F0R_PARAM_DOUBLE:\n        val.d = av_strtod(param, &tail);\n        if (*tail || val.d == HUGE_VAL)\n            goto fail;\n        break;\n\n    case F0R_PARAM_COLOR:\n        if (sscanf(param, \"%f/%f/%f\", &val.col.r, &val.col.g, &val.col.b) != 3) {\n            if (av_parse_color(rgba, param, -1, ctx) < 0)\n                goto fail;\n            val.col.r = rgba[0] / 255.0;\n            val.col.g = rgba[1] / 255.0;\n            val.col.b = rgba[2] / 255.0;\n        }\n        break;\n\n    case F0R_PARAM_POSITION:\n        if (sscanf(param, \"%lf/%lf\", &val.pos.x, &val.pos.y) != 2)\n            goto fail;\n        break;\n    }\n\n    s->set_param_value(s->instance, &val, index);\n    return 0;\n\nfail:\n    av_log(ctx, AV_LOG_ERROR, \"Invalid value '%s' for parameter '%s'.\\n\",\n           param, info.name);\n    return AVERROR(EINVAL);\n}\n\nstatic int set_params(AVFilterContext *ctx, const char *params)\n{\n    Frei0rContext *s = ctx->priv;\n    int i;\n\n    if (!params)\n        return 0;\n\n    for (i = 0; i < s->plugin_info.num_params; i++) {\n        f0r_param_info_t info;\n        char *param;\n        int ret;\n\n        s->get_param_info(&info, i);\n\n        if (*params) {\n            if (!(param = av_get_token(&params, \"|\")))\n                return AVERROR(ENOMEM);\n            if (*params)\n                params++;               /* skip ':' */\n            ret = set_param(ctx, info, i, param);\n            av_free(param);\n            if (ret < 0)\n                return ret;\n        }\n    }\n\n    return 0;\n}\n\nstatic int load_path(AVFilterContext *ctx, void **handle_ptr, const char *prefix, const char *name)\n{\n    char *path = av_asprintf(\"%s%s%s\", prefix, name, SLIBSUF);\n    if (!path)\n        return AVERROR(ENOMEM);\n    av_log(ctx, AV_LOG_DEBUG, \"Looking for frei0r effect in '%s'.\\n\", path);\n    *handle_ptr = dlopen(path, RTLD_NOW|RTLD_LOCAL);\n    av_free(path);\n    return 0;\n}\n\nstatic av_cold int frei0r_init(AVFilterContext *ctx,\n                               const char *dl_name, int type)\n{\n    Frei0rContext *s = ctx->priv;\n    f0r_init_f            f0r_init;\n    f0r_get_plugin_info_f f0r_get_plugin_info;\n    f0r_plugin_info_t *pi;\n    char *path;\n    int ret = 0;\n    int i;\n    static const char* const frei0r_pathlist[] = {\n        \"/usr/local/lib/frei0r-1/\",\n        \"/usr/lib/frei0r-1/\",\n        \"/usr/local/lib64/frei0r-1/\",\n        \"/usr/lib64/frei0r-1/\"\n    };\n\n    if (!dl_name) {\n        av_log(ctx, AV_LOG_ERROR, \"No filter name provided.\\n\");\n        return AVERROR(EINVAL);\n    }\n\n    /* see: http://frei0r.dyne.org/codedoc/html/group__pluglocations.html */\n    if ((path = av_strdup(getenv(\"FREI0R_PATH\")))) {\n#ifdef _WIN32\n        const char *separator = \";\";\n#else\n        const char *separator = \":\";\n#endif\n        char *p, *ptr = NULL;\n        for (p = path; p = av_strtok(p, separator, &ptr); p = NULL) {\n            /* add additional trailing slash in case it is missing */\n            char *p1 = av_asprintf(\"%s/\", p);\n            if (!p1) {\n                ret = AVERROR(ENOMEM);\n                goto check_path_end;\n            }\n            ret = load_path(ctx, &s->dl_handle, p1, dl_name);\n            av_free(p1);\n            if (ret < 0)\n                goto check_path_end;\n            if (s->dl_handle)\n                break;\n        }\n\n    check_path_end:\n        av_free(path);\n        if (ret < 0)\n            return ret;\n    }\n    if (!s->dl_handle && (path = getenv(\"HOME\"))) {\n        char *prefix = av_asprintf(\"%s/.frei0r-1/lib/\", path);\n        if (!prefix)\n            return AVERROR(ENOMEM);\n        ret = load_path(ctx, &s->dl_handle, prefix, dl_name);\n        av_free(prefix);\n        if (ret < 0)\n            return ret;\n    }\n    for (i = 0; !s->dl_handle && i < FF_ARRAY_ELEMS(frei0r_pathlist); i++) {\n        ret = load_path(ctx, &s->dl_handle, frei0r_pathlist[i], dl_name);\n        if (ret < 0)\n            return ret;\n    }\n    if (!s->dl_handle) {\n        av_log(ctx, AV_LOG_ERROR, \"Could not find module '%s'.\\n\", dl_name);\n        return AVERROR(EINVAL);\n    }\n\n    if (!(f0r_init                = load_sym(ctx, \"f0r_init\"           )) ||\n        !(f0r_get_plugin_info     = load_sym(ctx, \"f0r_get_plugin_info\")) ||\n        !(s->get_param_info  = load_sym(ctx, \"f0r_get_param_info\" )) ||\n        !(s->get_param_value = load_sym(ctx, \"f0r_get_param_value\")) ||\n        !(s->set_param_value = load_sym(ctx, \"f0r_set_param_value\")) ||\n        !(s->update          = load_sym(ctx, \"f0r_update\"         )) ||\n        !(s->construct       = load_sym(ctx, \"f0r_construct\"      )) ||\n        !(s->destruct        = load_sym(ctx, \"f0r_destruct\"       )) ||\n        !(s->deinit          = load_sym(ctx, \"f0r_deinit\"         )))\n        return AVERROR(EINVAL);\n\n    if (f0r_init() < 0) {\n        av_log(ctx, AV_LOG_ERROR, \"Could not init the frei0r module.\\n\");\n        return AVERROR(EINVAL);\n    }\n\n    f0r_get_plugin_info(&s->plugin_info);\n    pi = &s->plugin_info;\n    if (pi->plugin_type != type) {\n        av_log(ctx, AV_LOG_ERROR,\n               \"Invalid type '%s' for this plugin\\n\",\n               pi->plugin_type == F0R_PLUGIN_TYPE_FILTER ? \"filter\" :\n               pi->plugin_type == F0R_PLUGIN_TYPE_SOURCE ? \"source\" :\n               pi->plugin_type == F0R_PLUGIN_TYPE_MIXER2 ? \"mixer2\" :\n               pi->plugin_type == F0R_PLUGIN_TYPE_MIXER3 ? \"mixer3\" : \"unknown\");\n        return AVERROR(EINVAL);\n    }\n\n    av_log(ctx, AV_LOG_VERBOSE,\n           \"name:%s author:'%s' explanation:'%s' color_model:%s \"\n           \"frei0r_version:%d version:%d.%d num_params:%d\\n\",\n           pi->name, pi->author, pi->explanation,\n           pi->color_model == F0R_COLOR_MODEL_BGRA8888 ? \"bgra8888\" :\n           pi->color_model == F0R_COLOR_MODEL_RGBA8888 ? \"rgba8888\" :\n           pi->color_model == F0R_COLOR_MODEL_PACKED32 ? \"packed32\" : \"unknown\",\n           pi->frei0r_version, pi->major_version, pi->minor_version, pi->num_params);\n\n    return 0;\n}\n\nstatic av_cold int filter_init(AVFilterContext *ctx)\n{\n    Frei0rContext *s = ctx->priv;\n\n    return frei0r_init(ctx, s->dl_name, F0R_PLUGIN_TYPE_FILTER);\n}\n\nstatic av_cold void uninit(AVFilterContext *ctx)\n{\n    Frei0rContext *s = ctx->priv;\n\n    if (s->destruct && s->instance)\n        s->destruct(s->instance);\n    if (s->deinit)\n        s->deinit();\n    if (s->dl_handle)\n        dlclose(s->dl_handle);\n}\n\nstatic int config_input_props(AVFilterLink *inlink)\n{\n    AVFilterContext *ctx = inlink->dst;\n    Frei0rContext *s = ctx->priv;\n\n    if (s->destruct && s->instance)\n        s->destruct(s->instance);\n    if (!(s->instance = s->construct(inlink->w, inlink->h))) {\n        av_log(ctx, AV_LOG_ERROR, \"Impossible to load frei0r instance.\\n\");\n        return AVERROR(EINVAL);\n    }\n\n    return set_params(ctx, s->params);\n}\n\nstatic int query_formats(AVFilterContext *ctx)\n{\n    Frei0rContext *s = ctx->priv;\n    AVFilterFormats *formats = NULL;\n    int ret;\n\n    if        (s->plugin_info.color_model == F0R_COLOR_MODEL_BGRA8888) {\n        if ((ret = ff_add_format(&formats, AV_PIX_FMT_BGRA)) < 0)\n            return ret;\n    } else if (s->plugin_info.color_model == F0R_COLOR_MODEL_RGBA8888) {\n        if ((ret = ff_add_format(&formats, AV_PIX_FMT_RGBA)) < 0)\n            return ret;\n    } else {                                   /* F0R_COLOR_MODEL_PACKED32 */\n        static const enum AVPixelFormat pix_fmts[] = {\n            AV_PIX_FMT_BGRA, AV_PIX_FMT_ARGB, AV_PIX_FMT_ABGR, AV_PIX_FMT_ARGB, AV_PIX_FMT_NONE\n        };\n        formats = ff_make_format_list(pix_fmts);\n    }\n\n    if (!formats)\n        return AVERROR(ENOMEM);\n\n    return ff_set_common_formats(ctx, formats);\n}\n\nstatic int filter_frame(AVFilterLink *inlink, AVFrame *in)\n{\n    Frei0rContext *s = inlink->dst->priv;\n    AVFilterLink *outlink = inlink->dst->outputs[0];\n    AVFrame *out;\n\n    out = ff_get_video_buffer(outlink, outlink->w, outlink->h);\n    if (!out) {\n        av_frame_free(&in);\n        return AVERROR(ENOMEM);\n    }\n    av_frame_copy_props(out, in);\n\n    s->update(s->instance, in->pts * av_q2d(inlink->time_base) * 1000,\n                   (const uint32_t *)in->data[0],\n                   (uint32_t *)out->data[0]);\n\n    av_frame_free(&in);\n\n    return ff_filter_frame(outlink, out);\n}\n\n#define OFFSET(x) offsetof(Frei0rContext, x)\n#define FLAGS AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_FILTERING_PARAM\nstatic const AVOption frei0r_options[] = {\n    { \"filter_name\",   NULL, OFFSET(dl_name), AV_OPT_TYPE_STRING, .flags = FLAGS },\n    { \"filter_params\", NULL, OFFSET(params),  AV_OPT_TYPE_STRING, .flags = FLAGS },\n    { NULL }\n};\n\nAVFILTER_DEFINE_CLASS(frei0r);\n\nstatic const AVFilterPad avfilter_vf_frei0r_inputs[] = {\n    {\n        .name         = \"default\",\n        .type         = AVMEDIA_TYPE_VIDEO,\n        .config_props = config_input_props,\n        .filter_frame = filter_frame,\n    },\n    { NULL }\n};\n\nstatic const AVFilterPad avfilter_vf_frei0r_outputs[] = {\n    {\n        .name = \"default\",\n        .type = AVMEDIA_TYPE_VIDEO,\n    },\n    { NULL }\n};\n\nAVFilter ff_vf_frei0r = {\n    .name          = \"frei0r\",\n    .description   = NULL_IF_CONFIG_SMALL(\"Apply a frei0r effect.\"),\n    .query_formats = query_formats,\n    .init          = filter_init,\n    .uninit        = uninit,\n    .priv_size     = sizeof(Frei0rContext),\n    .priv_class    = &frei0r_class,\n    .inputs        = avfilter_vf_frei0r_inputs,\n    .outputs       = avfilter_vf_frei0r_outputs,\n};\n\nstatic av_cold int source_init(AVFilterContext *ctx)\n{\n    Frei0rContext *s = ctx->priv;\n\n    s->time_base.num = s->framerate.den;\n    s->time_base.den = s->framerate.num;\n\n    return frei0r_init(ctx, s->dl_name, F0R_PLUGIN_TYPE_SOURCE);\n}\n\nstatic int source_config_props(AVFilterLink *outlink)\n{\n    AVFilterContext *ctx = outlink->src;\n    Frei0rContext *s = ctx->priv;\n\n    if (av_image_check_size(s->w, s->h, 0, ctx) < 0)\n        return AVERROR(EINVAL);\n    outlink->w = s->w;\n    outlink->h = s->h;\n    outlink->time_base = s->time_base;\n    outlink->frame_rate = av_inv_q(s->time_base);\n    outlink->sample_aspect_ratio = (AVRational){1,1};\n\n    if (s->destruct && s->instance)\n        s->destruct(s->instance);\n    if (!(s->instance = s->construct(outlink->w, outlink->h))) {\n        av_log(ctx, AV_LOG_ERROR, \"Impossible to load frei0r instance.\\n\");\n        return AVERROR(EINVAL);\n    }\n    if (!s->params) {\n        av_log(ctx, AV_LOG_ERROR, \"frei0r filter parameters not set.\\n\");\n        return AVERROR(EINVAL);\n    }\n\n    return set_params(ctx, s->params);\n}\n\nstatic int source_request_frame(AVFilterLink *outlink)\n{\n    Frei0rContext *s = outlink->src->priv;\n    AVFrame *frame = ff_get_video_buffer(outlink, outlink->w, outlink->h);\n\n    if (!frame)\n        return AVERROR(ENOMEM);\n\n    frame->sample_aspect_ratio = (AVRational) {1, 1};\n    frame->pts = s->pts++;\n\n    s->update(s->instance, av_rescale_q(frame->pts, s->time_base, (AVRational){1,1000}),\n                   NULL, (uint32_t *)frame->data[0]);\n\n    return ff_filter_frame(outlink, frame);\n}\n\nstatic const AVOption frei0r_src_options[] = {\n    { \"size\",          \"Dimensions of the generated video.\", OFFSET(w),         AV_OPT_TYPE_IMAGE_SIZE, { .str = \"320x240\" }, .flags = FLAGS },\n    { \"framerate\",     NULL,                                 OFFSET(framerate), AV_OPT_TYPE_VIDEO_RATE, { .str = \"25\" }, 0, INT_MAX, .flags = FLAGS },\n    { \"filter_name\",   NULL,                                 OFFSET(dl_name),   AV_OPT_TYPE_STRING,                  .flags = FLAGS },\n    { \"filter_params\", NULL,                                 OFFSET(params),    AV_OPT_TYPE_STRING,                  .flags = FLAGS },\n    { NULL },\n};\n\nAVFILTER_DEFINE_CLASS(frei0r_src);\n\nstatic const AVFilterPad avfilter_vsrc_frei0r_src_outputs[] = {\n    {\n        .name          = \"default\",\n        .type          = AVMEDIA_TYPE_VIDEO,\n        .request_frame = source_request_frame,\n        .config_props  = source_config_props\n    },\n    { NULL }\n};\n\nAVFilter ff_vsrc_frei0r_src = {\n    .name          = \"frei0r_src\",\n    .description   = NULL_IF_CONFIG_SMALL(\"Generate a frei0r source.\"),\n    .priv_size     = sizeof(Frei0rContext),\n    .priv_class    = &frei0r_src_class,\n    .init          = source_init,\n    .uninit        = uninit,\n    .query_formats = query_formats,\n    .inputs        = NULL,\n    .outputs       = avfilter_vsrc_frei0r_src_outputs,\n};\n",
        "/tmp/vanessa/spack-stage/spack-stage-ffmpeg-3.2.4-tt6o4aq464a72ptcc3rjc7s6iclbxb35/spack-src/libavfilter/af_ladspa.c": "/*\n * Copyright (c) 2013 Paul B Mahol\n * Copyright (c) 2011 Mina Nagy Zaki\n *\n * This file is part of FFmpeg.\n *\n * FFmpeg is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License as published by the Free Software Foundation; either\n * version 2.1 of the License, or (at your option) any later version.\n *\n * FFmpeg is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with FFmpeg; if not, write to the Free Software\n * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n */\n\n/**\n * @file\n * LADSPA wrapper\n */\n\n#include <dlfcn.h>\n#include <ladspa.h>\n#include \"libavutil/avassert.h\"\n#include \"libavutil/avstring.h\"\n#include \"libavutil/channel_layout.h\"\n#include \"libavutil/opt.h\"\n#include \"audio.h\"\n#include \"avfilter.h\"\n#include \"internal.h\"\n\ntypedef struct LADSPAContext {\n    const AVClass *class;\n    char *dl_name;\n    char *plugin;\n    char *options;\n    void *dl_handle;\n\n    unsigned long nb_inputs;\n    unsigned long *ipmap;      /* map input number to port number */\n\n    unsigned long nb_inputcontrols;\n    unsigned long *icmap;      /* map input control number to port number */\n    LADSPA_Data *ictlv;        /* input controls values */\n\n    unsigned long nb_outputs;\n    unsigned long *opmap;      /* map output number to port number */\n\n    unsigned long nb_outputcontrols;\n    unsigned long *ocmap;      /* map output control number to port number */\n    LADSPA_Data *octlv;        /* output controls values */\n\n    const LADSPA_Descriptor *desc;\n    int *ctl_needs_value;\n    int nb_handles;\n    LADSPA_Handle *handles;\n\n    int sample_rate;\n    int nb_samples;\n    int64_t pts;\n    int64_t duration;\n} LADSPAContext;\n\n#define OFFSET(x) offsetof(LADSPAContext, x)\n#define FLAGS AV_OPT_FLAG_AUDIO_PARAM | AV_OPT_FLAG_FILTERING_PARAM\nstatic const AVOption ladspa_options[] = {\n    { \"file\", \"set library name or full path\", OFFSET(dl_name), AV_OPT_TYPE_STRING, .flags = FLAGS },\n    { \"f\",    \"set library name or full path\", OFFSET(dl_name), AV_OPT_TYPE_STRING, .flags = FLAGS },\n    { \"plugin\", \"set plugin name\", OFFSET(plugin), AV_OPT_TYPE_STRING, .flags = FLAGS },\n    { \"p\",      \"set plugin name\", OFFSET(plugin), AV_OPT_TYPE_STRING, .flags = FLAGS },\n    { \"controls\", \"set plugin options\", OFFSET(options), AV_OPT_TYPE_STRING, .flags = FLAGS },\n    { \"c\",        \"set plugin options\", OFFSET(options), AV_OPT_TYPE_STRING, .flags = FLAGS },\n    { \"sample_rate\", \"set sample rate\", OFFSET(sample_rate), AV_OPT_TYPE_INT, {.i64=44100}, 1, INT32_MAX, FLAGS },\n    { \"s\",           \"set sample rate\", OFFSET(sample_rate), AV_OPT_TYPE_INT, {.i64=44100}, 1, INT32_MAX, FLAGS },\n    { \"nb_samples\", \"set the number of samples per requested frame\", OFFSET(nb_samples), AV_OPT_TYPE_INT, {.i64=1024}, 1, INT_MAX, FLAGS },\n    { \"n\",          \"set the number of samples per requested frame\", OFFSET(nb_samples), AV_OPT_TYPE_INT, {.i64=1024}, 1, INT_MAX, FLAGS },\n    { \"duration\", \"set audio duration\", OFFSET(duration), AV_OPT_TYPE_DURATION, {.i64=-1}, -1, INT64_MAX, FLAGS },\n    { \"d\",        \"set audio duration\", OFFSET(duration), AV_OPT_TYPE_DURATION, {.i64=-1}, -1, INT64_MAX, FLAGS },\n    { NULL }\n};\n\nAVFILTER_DEFINE_CLASS(ladspa);\n\nstatic void print_ctl_info(AVFilterContext *ctx, int level,\n                           LADSPAContext *s, int ctl, unsigned long *map,\n                           LADSPA_Data *values, int print)\n{\n    const LADSPA_PortRangeHint *h = s->desc->PortRangeHints + map[ctl];\n\n    av_log(ctx, level, \"c%i: %s [\", ctl, s->desc->PortNames[map[ctl]]);\n\n    if (LADSPA_IS_HINT_TOGGLED(h->HintDescriptor)) {\n        av_log(ctx, level, \"toggled (1 or 0)\");\n\n        if (LADSPA_IS_HINT_HAS_DEFAULT(h->HintDescriptor))\n            av_log(ctx, level, \" (default %i)\", (int)values[ctl]);\n    } else {\n        if (LADSPA_IS_HINT_INTEGER(h->HintDescriptor)) {\n            av_log(ctx, level, \"<int>\");\n\n            if (LADSPA_IS_HINT_BOUNDED_BELOW(h->HintDescriptor))\n                av_log(ctx, level, \", min: %i\", (int)h->LowerBound);\n\n            if (LADSPA_IS_HINT_BOUNDED_ABOVE(h->HintDescriptor))\n                av_log(ctx, level, \", max: %i\", (int)h->UpperBound);\n\n            if (print)\n                av_log(ctx, level, \" (value %d)\", (int)values[ctl]);\n            else if (LADSPA_IS_HINT_HAS_DEFAULT(h->HintDescriptor))\n                av_log(ctx, level, \" (default %d)\", (int)values[ctl]);\n        } else {\n            av_log(ctx, level, \"<float>\");\n\n            if (LADSPA_IS_HINT_BOUNDED_BELOW(h->HintDescriptor))\n                av_log(ctx, level, \", min: %f\", h->LowerBound);\n\n            if (LADSPA_IS_HINT_BOUNDED_ABOVE(h->HintDescriptor))\n                av_log(ctx, level, \", max: %f\", h->UpperBound);\n\n            if (print)\n                av_log(ctx, level, \" (value %f)\", values[ctl]);\n            else if (LADSPA_IS_HINT_HAS_DEFAULT(h->HintDescriptor))\n                av_log(ctx, level, \" (default %f)\", values[ctl]);\n        }\n\n        if (LADSPA_IS_HINT_SAMPLE_RATE(h->HintDescriptor))\n            av_log(ctx, level, \", multiple of sample rate\");\n\n        if (LADSPA_IS_HINT_LOGARITHMIC(h->HintDescriptor))\n            av_log(ctx, level, \", logarithmic scale\");\n    }\n\n    av_log(ctx, level, \"]\\n\");\n}\n\nstatic int filter_frame(AVFilterLink *inlink, AVFrame *in)\n{\n    AVFilterContext *ctx = inlink->dst;\n    LADSPAContext *s = ctx->priv;\n    AVFrame *out;\n    int i, h, p;\n\n    av_assert0(in->channels == (s->nb_inputs * s->nb_handles));\n\n    if (!s->nb_outputs ||\n        (av_frame_is_writable(in) && s->nb_inputs == s->nb_outputs &&\n        !(s->desc->Properties & LADSPA_PROPERTY_INPLACE_BROKEN))) {\n        out = in;\n    } else {\n        out = ff_get_audio_buffer(ctx->outputs[0], in->nb_samples);\n        if (!out) {\n            av_frame_free(&in);\n            return AVERROR(ENOMEM);\n        }\n        av_frame_copy_props(out, in);\n    }\n\n    av_assert0(!s->nb_outputs || out->channels == (s->nb_outputs * s->nb_handles));\n\n    for (h = 0; h < s->nb_handles; h++) {\n        for (i = 0; i < s->nb_inputs; i++) {\n            p = s->nb_handles > 1 ? h : i;\n            s->desc->connect_port(s->handles[h], s->ipmap[i],\n                                  (LADSPA_Data*)in->extended_data[p]);\n        }\n\n        for (i = 0; i < s->nb_outputs; i++) {\n            p = s->nb_handles > 1 ? h : i;\n            s->desc->connect_port(s->handles[h], s->opmap[i],\n                                  (LADSPA_Data*)out->extended_data[p]);\n        }\n\n        s->desc->run(s->handles[h], in->nb_samples);\n    }\n\n    for (i = 0; i < s->nb_outputcontrols; i++)\n        print_ctl_info(ctx, AV_LOG_VERBOSE, s, i, s->ocmap, s->octlv, 1);\n\n    if (out != in)\n        av_frame_free(&in);\n\n    return ff_filter_frame(ctx->outputs[0], out);\n}\n\nstatic int request_frame(AVFilterLink *outlink)\n{\n    AVFilterContext *ctx = outlink->src;\n    LADSPAContext *s = ctx->priv;\n    AVFrame *out;\n    int64_t t;\n    int i;\n\n    if (ctx->nb_inputs)\n        return ff_request_frame(ctx->inputs[0]);\n\n    t = av_rescale(s->pts, AV_TIME_BASE, s->sample_rate);\n    if (s->duration >= 0 && t >= s->duration)\n        return AVERROR_EOF;\n\n    out = ff_get_audio_buffer(outlink, s->nb_samples);\n    if (!out)\n        return AVERROR(ENOMEM);\n\n    for (i = 0; i < s->nb_outputs; i++)\n        s->desc->connect_port(s->handles[0], s->opmap[i],\n                (LADSPA_Data*)out->extended_data[i]);\n\n    s->desc->run(s->handles[0], s->nb_samples);\n\n    for (i = 0; i < s->nb_outputcontrols; i++)\n        print_ctl_info(ctx, AV_LOG_INFO, s, i, s->ocmap, s->octlv, 1);\n\n    out->sample_rate = s->sample_rate;\n    out->pts         = s->pts;\n    s->pts          += s->nb_samples;\n\n    return ff_filter_frame(outlink, out);\n}\n\nstatic void set_default_ctl_value(LADSPAContext *s, int ctl,\n                                  unsigned long *map, LADSPA_Data *values)\n{\n    const LADSPA_PortRangeHint *h = s->desc->PortRangeHints + map[ctl];\n    const LADSPA_Data lower = h->LowerBound;\n    const LADSPA_Data upper = h->UpperBound;\n\n    if (LADSPA_IS_HINT_DEFAULT_MINIMUM(h->HintDescriptor)) {\n        values[ctl] = lower;\n    } else if (LADSPA_IS_HINT_DEFAULT_MAXIMUM(h->HintDescriptor)) {\n        values[ctl] = upper;\n    } else if (LADSPA_IS_HINT_DEFAULT_0(h->HintDescriptor)) {\n        values[ctl] = 0.0;\n    } else if (LADSPA_IS_HINT_DEFAULT_1(h->HintDescriptor)) {\n        values[ctl] = 1.0;\n    } else if (LADSPA_IS_HINT_DEFAULT_100(h->HintDescriptor)) {\n        values[ctl] = 100.0;\n    } else if (LADSPA_IS_HINT_DEFAULT_440(h->HintDescriptor)) {\n        values[ctl] = 440.0;\n    } else if (LADSPA_IS_HINT_DEFAULT_LOW(h->HintDescriptor)) {\n        if (LADSPA_IS_HINT_LOGARITHMIC(h->HintDescriptor))\n            values[ctl] = exp(log(lower) * 0.75 + log(upper) * 0.25);\n        else\n            values[ctl] = lower * 0.75 + upper * 0.25;\n    } else if (LADSPA_IS_HINT_DEFAULT_MIDDLE(h->HintDescriptor)) {\n        if (LADSPA_IS_HINT_LOGARITHMIC(h->HintDescriptor))\n            values[ctl] = exp(log(lower) * 0.5 + log(upper) * 0.5);\n        else\n            values[ctl] = lower * 0.5 + upper * 0.5;\n    } else if (LADSPA_IS_HINT_DEFAULT_HIGH(h->HintDescriptor)) {\n        if (LADSPA_IS_HINT_LOGARITHMIC(h->HintDescriptor))\n            values[ctl] = exp(log(lower) * 0.25 + log(upper) * 0.75);\n        else\n            values[ctl] = lower * 0.25 + upper * 0.75;\n    }\n}\n\nstatic int connect_ports(AVFilterContext *ctx, AVFilterLink *link)\n{\n    LADSPAContext *s = ctx->priv;\n    int i, j;\n\n    s->nb_handles = s->nb_inputs == 1 && s->nb_outputs == 1 ? link->channels : 1;\n    s->handles    = av_calloc(s->nb_handles, sizeof(*s->handles));\n    if (!s->handles)\n        return AVERROR(ENOMEM);\n\n    for (i = 0; i < s->nb_handles; i++) {\n        s->handles[i] = s->desc->instantiate(s->desc, link->sample_rate);\n        if (!s->handles[i]) {\n            av_log(ctx, AV_LOG_ERROR, \"Could not instantiate plugin.\\n\");\n            return AVERROR_EXTERNAL;\n        }\n\n        // Connect the input control ports\n        for (j = 0; j < s->nb_inputcontrols; j++)\n            s->desc->connect_port(s->handles[i], s->icmap[j], s->ictlv + j);\n\n        // Connect the output control ports\n        for (j = 0; j < s->nb_outputcontrols; j++)\n            s->desc->connect_port(s->handles[i], s->ocmap[j], &s->octlv[j]);\n\n        if (s->desc->activate)\n            s->desc->activate(s->handles[i]);\n    }\n\n    av_log(ctx, AV_LOG_DEBUG, \"handles: %d\\n\", s->nb_handles);\n\n    return 0;\n}\n\nstatic int config_input(AVFilterLink *inlink)\n{\n    AVFilterContext *ctx = inlink->dst;\n\n    return connect_ports(ctx, inlink);\n}\n\nstatic int config_output(AVFilterLink *outlink)\n{\n    AVFilterContext *ctx = outlink->src;\n    LADSPAContext *s = ctx->priv;\n    int ret;\n\n    if (ctx->nb_inputs) {\n        AVFilterLink *inlink = ctx->inputs[0];\n\n        outlink->format      = inlink->format;\n        outlink->sample_rate = inlink->sample_rate;\n        if (s->nb_inputs == s->nb_outputs) {\n            outlink->channel_layout = inlink->channel_layout;\n            outlink->channels = inlink->channels;\n        }\n\n        ret = 0;\n    } else {\n        LADSPAContext *s = ctx->priv;\n\n        outlink->sample_rate = s->sample_rate;\n        outlink->time_base   = (AVRational){1, s->sample_rate};\n\n        ret = connect_ports(ctx, outlink);\n    }\n\n    return ret;\n}\n\nstatic void count_ports(const LADSPA_Descriptor *desc,\n                        unsigned long *nb_inputs, unsigned long *nb_outputs)\n{\n    LADSPA_PortDescriptor pd;\n    int i;\n\n    for (i = 0; i < desc->PortCount; i++) {\n        pd = desc->PortDescriptors[i];\n\n        if (LADSPA_IS_PORT_AUDIO(pd)) {\n            if (LADSPA_IS_PORT_INPUT(pd)) {\n                (*nb_inputs)++;\n            } else if (LADSPA_IS_PORT_OUTPUT(pd)) {\n                (*nb_outputs)++;\n            }\n        }\n    }\n}\n\nstatic void *try_load(const char *dir, const char *soname)\n{\n    char *path = av_asprintf(\"%s/%s.so\", dir, soname);\n    void *ret = NULL;\n\n    if (path) {\n        ret = dlopen(path, RTLD_LOCAL|RTLD_NOW);\n        av_free(path);\n    }\n\n    return ret;\n}\n\nstatic int set_control(AVFilterContext *ctx, unsigned long port, LADSPA_Data value)\n{\n    LADSPAContext *s = ctx->priv;\n    const char *label = s->desc->Label;\n    LADSPA_PortRangeHint *h = (LADSPA_PortRangeHint *)s->desc->PortRangeHints +\n                              s->icmap[port];\n\n    if (port >= s->nb_inputcontrols) {\n        av_log(ctx, AV_LOG_ERROR, \"Control c%ld is out of range [0 - %lu].\\n\",\n               port, s->nb_inputcontrols);\n        return AVERROR(EINVAL);\n    }\n\n    if (LADSPA_IS_HINT_BOUNDED_BELOW(h->HintDescriptor) &&\n            value < h->LowerBound) {\n        av_log(ctx, AV_LOG_ERROR,\n                \"%s: input control c%ld is below lower boundary of %0.4f.\\n\",\n                label, port, h->LowerBound);\n        return AVERROR(EINVAL);\n    }\n\n    if (LADSPA_IS_HINT_BOUNDED_ABOVE(h->HintDescriptor) &&\n            value > h->UpperBound) {\n        av_log(ctx, AV_LOG_ERROR,\n                \"%s: input control c%ld is above upper boundary of %0.4f.\\n\",\n                label, port, h->UpperBound);\n        return AVERROR(EINVAL);\n    }\n\n    s->ictlv[port] = value;\n\n    return 0;\n}\n\nstatic av_cold int init(AVFilterContext *ctx)\n{\n    LADSPAContext *s = ctx->priv;\n    LADSPA_Descriptor_Function descriptor_fn;\n    const LADSPA_Descriptor *desc;\n    LADSPA_PortDescriptor pd;\n    AVFilterPad pad = { NULL };\n    char *p, *arg, *saveptr = NULL;\n    unsigned long nb_ports;\n    int i, j = 0;\n\n    if (!s->dl_name) {\n        av_log(ctx, AV_LOG_ERROR, \"No plugin name provided\\n\");\n        return AVERROR(EINVAL);\n    }\n\n    if (s->dl_name[0] == '/' || s->dl_name[0] == '.') {\n        // argument is a path\n        s->dl_handle = dlopen(s->dl_name, RTLD_LOCAL|RTLD_NOW);\n    } else {\n        // argument is a shared object name\n        char *paths = av_strdup(getenv(\"LADSPA_PATH\"));\n        const char *separator = \":\";\n\n        if (paths) {\n            p = paths;\n            while ((arg = av_strtok(p, separator, &saveptr)) && !s->dl_handle) {\n                s->dl_handle = try_load(arg, s->dl_name);\n                p = NULL;\n            }\n        }\n\n        av_free(paths);\n        if (!s->dl_handle && (paths = av_asprintf(\"%s/.ladspa/lib\", getenv(\"HOME\")))) {\n            s->dl_handle = try_load(paths, s->dl_name);\n            av_free(paths);\n        }\n\n        if (!s->dl_handle)\n            s->dl_handle = try_load(\"/usr/local/lib/ladspa\", s->dl_name);\n\n        if (!s->dl_handle)\n            s->dl_handle = try_load(\"/usr/lib/ladspa\", s->dl_name);\n    }\n    if (!s->dl_handle) {\n        av_log(ctx, AV_LOG_ERROR, \"Failed to load '%s'\\n\", s->dl_name);\n        return AVERROR(EINVAL);\n    }\n\n    descriptor_fn = dlsym(s->dl_handle, \"ladspa_descriptor\");\n    if (!descriptor_fn) {\n        av_log(ctx, AV_LOG_ERROR, \"Could not find ladspa_descriptor: %s\\n\", dlerror());\n        return AVERROR(EINVAL);\n    }\n\n    // Find the requested plugin, or list plugins\n    if (!s->plugin) {\n        av_log(ctx, AV_LOG_INFO, \"The '%s' library contains the following plugins:\\n\", s->dl_name);\n        av_log(ctx, AV_LOG_INFO, \"I = Input Channels\\n\");\n        av_log(ctx, AV_LOG_INFO, \"O = Output Channels\\n\");\n        av_log(ctx, AV_LOG_INFO, \"I:O %-25s %s\\n\", \"Plugin\", \"Description\");\n        av_log(ctx, AV_LOG_INFO, \"\\n\");\n        for (i = 0; desc = descriptor_fn(i); i++) {\n            unsigned long inputs = 0, outputs = 0;\n\n            count_ports(desc, &inputs, &outputs);\n            av_log(ctx, AV_LOG_INFO, \"%lu:%lu %-25s %s\\n\", inputs, outputs, desc->Label,\n                   (char *)av_x_if_null(desc->Name, \"?\"));\n            av_log(ctx, AV_LOG_VERBOSE, \"Maker: %s\\n\",\n                   (char *)av_x_if_null(desc->Maker, \"?\"));\n            av_log(ctx, AV_LOG_VERBOSE, \"Copyright: %s\\n\",\n                   (char *)av_x_if_null(desc->Copyright, \"?\"));\n        }\n        return AVERROR_EXIT;\n    } else {\n        for (i = 0;; i++) {\n            desc = descriptor_fn(i);\n            if (!desc) {\n                av_log(ctx, AV_LOG_ERROR, \"Could not find plugin: %s\\n\", s->plugin);\n                return AVERROR(EINVAL);\n            }\n\n            if (desc->Label && !strcmp(desc->Label, s->plugin))\n                break;\n        }\n    }\n\n    s->desc  = desc;\n    nb_ports = desc->PortCount;\n\n    s->ipmap = av_calloc(nb_ports, sizeof(*s->ipmap));\n    s->opmap = av_calloc(nb_ports, sizeof(*s->opmap));\n    s->icmap = av_calloc(nb_ports, sizeof(*s->icmap));\n    s->ocmap = av_calloc(nb_ports, sizeof(*s->ocmap));\n    s->ictlv = av_calloc(nb_ports, sizeof(*s->ictlv));\n    s->octlv = av_calloc(nb_ports, sizeof(*s->octlv));\n    s->ctl_needs_value = av_calloc(nb_ports, sizeof(*s->ctl_needs_value));\n    if (!s->ipmap || !s->opmap || !s->icmap ||\n        !s->ocmap || !s->ictlv || !s->octlv || !s->ctl_needs_value)\n        return AVERROR(ENOMEM);\n\n    for (i = 0; i < nb_ports; i++) {\n        pd = desc->PortDescriptors[i];\n\n        if (LADSPA_IS_PORT_AUDIO(pd)) {\n            if (LADSPA_IS_PORT_INPUT(pd)) {\n                s->ipmap[s->nb_inputs] = i;\n                s->nb_inputs++;\n            } else if (LADSPA_IS_PORT_OUTPUT(pd)) {\n                s->opmap[s->nb_outputs] = i;\n                s->nb_outputs++;\n            }\n        } else if (LADSPA_IS_PORT_CONTROL(pd)) {\n            if (LADSPA_IS_PORT_INPUT(pd)) {\n                s->icmap[s->nb_inputcontrols] = i;\n\n                if (LADSPA_IS_HINT_HAS_DEFAULT(desc->PortRangeHints[i].HintDescriptor))\n                    set_default_ctl_value(s, s->nb_inputcontrols, s->icmap, s->ictlv);\n                else\n                    s->ctl_needs_value[s->nb_inputcontrols] = 1;\n\n                s->nb_inputcontrols++;\n            } else if (LADSPA_IS_PORT_OUTPUT(pd)) {\n                s->ocmap[s->nb_outputcontrols] = i;\n                s->nb_outputcontrols++;\n            }\n        }\n    }\n\n    // List Control Ports if \"help\" is specified\n    if (s->options && !strcmp(s->options, \"help\")) {\n        if (!s->nb_inputcontrols) {\n            av_log(ctx, AV_LOG_INFO,\n                   \"The '%s' plugin does not have any input controls.\\n\",\n                   desc->Label);\n        } else {\n            av_log(ctx, AV_LOG_INFO,\n                   \"The '%s' plugin has the following input controls:\\n\",\n                   desc->Label);\n            for (i = 0; i < s->nb_inputcontrols; i++)\n                print_ctl_info(ctx, AV_LOG_INFO, s, i, s->icmap, s->ictlv, 0);\n        }\n        return AVERROR_EXIT;\n    }\n\n    // Parse control parameters\n    p = s->options;\n    while (s->options) {\n        LADSPA_Data val;\n        int ret;\n\n        if (!(arg = av_strtok(p, \" |\", &saveptr)))\n            break;\n        p = NULL;\n\n        if (sscanf(arg, \"c%d=%f\", &i, &val) != 2) {\n            if (sscanf(arg, \"%f\", &val) != 1) {\n                av_log(ctx, AV_LOG_ERROR, \"Invalid syntax.\\n\");\n                return AVERROR(EINVAL);\n            }\n            i = j++;\n        }\n\n        if ((ret = set_control(ctx, i, val)) < 0)\n            return ret;\n        s->ctl_needs_value[i] = 0;\n    }\n\n    // Check if any controls are not set\n    for (i = 0; i < s->nb_inputcontrols; i++) {\n        if (s->ctl_needs_value[i]) {\n            av_log(ctx, AV_LOG_ERROR, \"Control c%d must be set.\\n\", i);\n            print_ctl_info(ctx, AV_LOG_ERROR, s, i, s->icmap, s->ictlv, 0);\n            return AVERROR(EINVAL);\n        }\n    }\n\n    pad.type = AVMEDIA_TYPE_AUDIO;\n\n    if (s->nb_inputs) {\n        pad.name = av_asprintf(\"in0:%s%lu\", desc->Label, s->nb_inputs);\n        if (!pad.name)\n            return AVERROR(ENOMEM);\n\n        pad.filter_frame = filter_frame;\n        pad.config_props = config_input;\n        if (ff_insert_inpad(ctx, ctx->nb_inputs, &pad) < 0) {\n            av_freep(&pad.name);\n            return AVERROR(ENOMEM);\n        }\n    }\n\n    av_log(ctx, AV_LOG_DEBUG, \"ports: %lu\\n\", nb_ports);\n    av_log(ctx, AV_LOG_DEBUG, \"inputs: %lu outputs: %lu\\n\",\n                              s->nb_inputs, s->nb_outputs);\n    av_log(ctx, AV_LOG_DEBUG, \"input controls: %lu output controls: %lu\\n\",\n                              s->nb_inputcontrols, s->nb_outputcontrols);\n\n    return 0;\n}\n\nstatic int query_formats(AVFilterContext *ctx)\n{\n    LADSPAContext *s = ctx->priv;\n    AVFilterFormats *formats;\n    AVFilterChannelLayouts *layouts;\n    static const enum AVSampleFormat sample_fmts[] = {\n        AV_SAMPLE_FMT_FLTP, AV_SAMPLE_FMT_NONE };\n    int ret;\n\n    formats = ff_make_format_list(sample_fmts);\n    if (!formats)\n        return AVERROR(ENOMEM);\n    ret = ff_set_common_formats(ctx, formats);\n    if (ret < 0)\n        return ret;\n\n    if (s->nb_inputs) {\n        formats = ff_all_samplerates();\n        if (!formats)\n            return AVERROR(ENOMEM);\n\n        ret = ff_set_common_samplerates(ctx, formats);\n        if (ret < 0)\n            return ret;\n    } else {\n        int sample_rates[] = { s->sample_rate, -1 };\n\n        ret = ff_set_common_samplerates(ctx, ff_make_format_list(sample_rates));\n        if (ret < 0)\n            return ret;\n    }\n\n    if (s->nb_inputs == 1 && s->nb_outputs == 1) {\n        // We will instantiate multiple LADSPA_Handle, one over each channel\n        layouts = ff_all_channel_counts();\n        if (!layouts)\n            return AVERROR(ENOMEM);\n\n        ret = ff_set_common_channel_layouts(ctx, layouts);\n        if (ret < 0)\n            return ret;\n    } else if (s->nb_inputs == 2 && s->nb_outputs == 2) {\n        layouts = NULL;\n        ret = ff_add_channel_layout(&layouts, AV_CH_LAYOUT_STEREO);\n        if (ret < 0)\n            return ret;\n        ret = ff_set_common_channel_layouts(ctx, layouts);\n        if (ret < 0)\n            return ret;\n    } else {\n        AVFilterLink *outlink = ctx->outputs[0];\n\n        if (s->nb_inputs >= 1) {\n            AVFilterLink *inlink = ctx->inputs[0];\n            uint64_t inlayout = FF_COUNT2LAYOUT(s->nb_inputs);\n\n            layouts = NULL;\n            ret = ff_add_channel_layout(&layouts, inlayout);\n            if (ret < 0)\n                return ret;\n            ret = ff_channel_layouts_ref(layouts, &inlink->out_channel_layouts);\n            if (ret < 0)\n                return ret;\n\n            if (!s->nb_outputs) {\n                ret = ff_channel_layouts_ref(layouts, &outlink->in_channel_layouts);\n                if (ret < 0)\n                    return ret;\n            }\n        }\n\n        if (s->nb_outputs >= 1) {\n            uint64_t outlayout = FF_COUNT2LAYOUT(s->nb_outputs);\n\n            layouts = NULL;\n            ret = ff_add_channel_layout(&layouts, outlayout);\n            if (ret < 0)\n                return ret;\n            ret = ff_channel_layouts_ref(layouts, &outlink->in_channel_layouts);\n            if (ret < 0)\n                return ret;\n        }\n    }\n\n    return 0;\n}\n\nstatic av_cold void uninit(AVFilterContext *ctx)\n{\n    LADSPAContext *s = ctx->priv;\n    int i;\n\n    for (i = 0; i < s->nb_handles; i++) {\n        if (s->desc->deactivate)\n            s->desc->deactivate(s->handles[i]);\n        if (s->desc->cleanup)\n            s->desc->cleanup(s->handles[i]);\n    }\n\n    if (s->dl_handle)\n        dlclose(s->dl_handle);\n\n    av_freep(&s->ipmap);\n    av_freep(&s->opmap);\n    av_freep(&s->icmap);\n    av_freep(&s->ocmap);\n    av_freep(&s->ictlv);\n    av_freep(&s->octlv);\n    av_freep(&s->handles);\n    av_freep(&s->ctl_needs_value);\n\n    if (ctx->nb_inputs)\n        av_freep(&ctx->input_pads[0].name);\n}\n\nstatic int process_command(AVFilterContext *ctx, const char *cmd, const char *args,\n                           char *res, int res_len, int flags)\n{\n    LADSPA_Data value;\n    unsigned long port;\n\n    if (sscanf(cmd, \"c%ld\", &port) + sscanf(args, \"%f\", &value) != 2)\n        return AVERROR(EINVAL);\n\n    return set_control(ctx, port, value);\n}\n\nstatic const AVFilterPad ladspa_outputs[] = {\n    {\n        .name          = \"default\",\n        .type          = AVMEDIA_TYPE_AUDIO,\n        .config_props  = config_output,\n        .request_frame = request_frame,\n    },\n    { NULL }\n};\n\nAVFilter ff_af_ladspa = {\n    .name          = \"ladspa\",\n    .description   = NULL_IF_CONFIG_SMALL(\"Apply LADSPA effect.\"),\n    .priv_size     = sizeof(LADSPAContext),\n    .priv_class    = &ladspa_class,\n    .init          = init,\n    .uninit        = uninit,\n    .query_formats = query_formats,\n    .process_command = process_command,\n    .inputs        = 0,\n    .outputs       = ladspa_outputs,\n    .flags         = AVFILTER_FLAG_DYNAMIC_INPUTS,\n};\n",
        "/tmp/vanessa/spack-stage/spack-stage-ffmpeg-3.2.4-tt6o4aq464a72ptcc3rjc7s6iclbxb35/spack-src/libavfilter/vf_telecine.c": "/*\n * Copyright (c) 2012 Rudolf Polzer\n * Copyright (c) 2013 Paul B Mahol\n *\n * This file is part of FFmpeg.\n *\n * FFmpeg is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License as published by the Free Software Foundation; either\n * version 2.1 of the License, or (at your option) any later version.\n *\n * FFmpeg is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with FFmpeg; if not, write to the Free Software\n * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n */\n\n/**\n * @file telecine filter, heavily based from mpv-player:TOOLS/vf_dlopen/telecine.c by\n * Rudolf Polzer.\n */\n\n#include \"libavutil/avstring.h\"\n#include \"libavutil/imgutils.h\"\n#include \"libavutil/opt.h\"\n#include \"libavutil/pixdesc.h\"\n#include \"avfilter.h\"\n#include \"formats.h\"\n#include \"internal.h\"\n#include \"video.h\"\n\ntypedef struct {\n    const AVClass *class;\n    int first_field;\n    char *pattern;\n    unsigned int pattern_pos;\n    int64_t start_time;\n\n    AVRational pts;\n    AVRational ts_unit;\n    int out_cnt;\n    int occupied;\n\n    int nb_planes;\n    int planeheight[4];\n    int stride[4];\n\n    AVFrame *frame[5];\n    AVFrame *temp;\n} TelecineContext;\n\n#define OFFSET(x) offsetof(TelecineContext, x)\n#define FLAGS AV_OPT_FLAG_FILTERING_PARAM|AV_OPT_FLAG_VIDEO_PARAM\n\nstatic const AVOption telecine_options[] = {\n    {\"first_field\", \"select first field\", OFFSET(first_field), AV_OPT_TYPE_INT,   {.i64=0}, 0, 1, FLAGS, \"field\"},\n        {\"top\",    \"select top field first\",                0, AV_OPT_TYPE_CONST, {.i64=0}, 0, 0, FLAGS, \"field\"},\n        {\"t\",      \"select top field first\",                0, AV_OPT_TYPE_CONST, {.i64=0}, 0, 0, FLAGS, \"field\"},\n        {\"bottom\", \"select bottom field first\",             0, AV_OPT_TYPE_CONST, {.i64=1}, 0, 0, FLAGS, \"field\"},\n        {\"b\",      \"select bottom field first\",             0, AV_OPT_TYPE_CONST, {.i64=1}, 0, 0, FLAGS, \"field\"},\n    {\"pattern\", \"pattern that describe for how many fields a frame is to be displayed\", OFFSET(pattern), AV_OPT_TYPE_STRING, {.str=\"23\"}, 0, 0, FLAGS},\n    {NULL}\n};\n\nAVFILTER_DEFINE_CLASS(telecine);\n\nstatic av_cold int init(AVFilterContext *ctx)\n{\n    TelecineContext *s = ctx->priv;\n    const char *p;\n    int max = 0;\n\n    if (!strlen(s->pattern)) {\n        av_log(ctx, AV_LOG_ERROR, \"No pattern provided.\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n\n    for (p = s->pattern; *p; p++) {\n        if (!av_isdigit(*p)) {\n            av_log(ctx, AV_LOG_ERROR, \"Provided pattern includes non-numeric characters.\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n\n        max = FFMAX(*p - '0', max);\n        s->pts.num += 2;\n        s->pts.den += *p - '0';\n    }\n\n    s->start_time = AV_NOPTS_VALUE;\n\n    s->out_cnt = (max + 1) / 2;\n    av_log(ctx, AV_LOG_INFO, \"Telecine pattern %s yields up to %d frames per frame, pts advance factor: %d/%d\\n\",\n           s->pattern, s->out_cnt, s->pts.num, s->pts.den);\n\n    return 0;\n}\n\nstatic int query_formats(AVFilterContext *ctx)\n{\n    AVFilterFormats *pix_fmts = NULL;\n    int fmt, ret;\n\n    for (fmt = 0; av_pix_fmt_desc_get(fmt); fmt++) {\n        const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(fmt);\n        if (!(desc->flags & AV_PIX_FMT_FLAG_HWACCEL ||\n              desc->flags & AV_PIX_FMT_FLAG_PAL     ||\n              desc->flags & AV_PIX_FMT_FLAG_BITSTREAM) &&\n            (ret = ff_add_format(&pix_fmts, fmt)) < 0)\n            return ret;\n    }\n\n    return ff_set_common_formats(ctx, pix_fmts);\n}\n\nstatic int config_input(AVFilterLink *inlink)\n{\n    TelecineContext *s = inlink->dst->priv;\n    const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(inlink->format);\n    int i, ret;\n\n    s->temp = ff_get_video_buffer(inlink, inlink->w, inlink->h);\n    if (!s->temp)\n        return AVERROR(ENOMEM);\n    for (i = 0; i < s->out_cnt; i++) {\n        s->frame[i] = ff_get_video_buffer(inlink, inlink->w, inlink->h);\n        if (!s->frame[i])\n            return AVERROR(ENOMEM);\n    }\n\n    if ((ret = av_image_fill_linesizes(s->stride, inlink->format, inlink->w)) < 0)\n        return ret;\n\n    s->planeheight[1] = s->planeheight[2] = AV_CEIL_RSHIFT(inlink->h, desc->log2_chroma_h);\n    s->planeheight[0] = s->planeheight[3] = inlink->h;\n\n    s->nb_planes = av_pix_fmt_count_planes(inlink->format);\n\n    return 0;\n}\n\nstatic int config_output(AVFilterLink *outlink)\n{\n    AVFilterContext *ctx = outlink->src;\n    TelecineContext *s = ctx->priv;\n    const AVFilterLink *inlink = ctx->inputs[0];\n    AVRational fps = inlink->frame_rate;\n\n    if (!fps.num || !fps.den) {\n        av_log(ctx, AV_LOG_ERROR, \"The input needs a constant frame rate; \"\n               \"current rate of %d/%d is invalid\\n\", fps.num, fps.den);\n        return AVERROR(EINVAL);\n    }\n    fps = av_mul_q(fps, av_inv_q(s->pts));\n    av_log(ctx, AV_LOG_VERBOSE, \"FPS: %d/%d -> %d/%d\\n\",\n           inlink->frame_rate.num, inlink->frame_rate.den, fps.num, fps.den);\n\n    outlink->frame_rate = fps;\n    outlink->time_base = av_mul_q(inlink->time_base, s->pts);\n    av_log(ctx, AV_LOG_VERBOSE, \"TB: %d/%d -> %d/%d\\n\",\n           inlink->time_base.num, inlink->time_base.den, outlink->time_base.num, outlink->time_base.den);\n\n    s->ts_unit = av_inv_q(av_mul_q(fps, outlink->time_base));\n\n    return 0;\n}\n\nstatic int filter_frame(AVFilterLink *inlink, AVFrame *inpicref)\n{\n    AVFilterContext *ctx = inlink->dst;\n    AVFilterLink *outlink = ctx->outputs[0];\n    TelecineContext *s = ctx->priv;\n    int i, len, ret = 0, nout = 0;\n\n    if (s->start_time == AV_NOPTS_VALUE)\n        s->start_time = inpicref->pts;\n\n    len = s->pattern[s->pattern_pos] - '0';\n\n    s->pattern_pos++;\n    if (!s->pattern[s->pattern_pos])\n        s->pattern_pos = 0;\n\n    if (!len) { // do not output any field from this frame\n        av_frame_free(&inpicref);\n        return 0;\n    }\n\n    if (s->occupied) {\n        av_frame_make_writable(s->frame[nout]);\n        for (i = 0; i < s->nb_planes; i++) {\n            // fill in the EARLIER field from the buffered pic\n            av_image_copy_plane(s->frame[nout]->data[i] + s->frame[nout]->linesize[i] * s->first_field,\n                                s->frame[nout]->linesize[i] * 2,\n                                s->temp->data[i] + s->temp->linesize[i] * s->first_field,\n                                s->temp->linesize[i] * 2,\n                                s->stride[i],\n                                (s->planeheight[i] - s->first_field + 1) / 2);\n            // fill in the LATER field from the new pic\n            av_image_copy_plane(s->frame[nout]->data[i] + s->frame[nout]->linesize[i] * !s->first_field,\n                                s->frame[nout]->linesize[i] * 2,\n                                inpicref->data[i] + inpicref->linesize[i] * !s->first_field,\n                                inpicref->linesize[i] * 2,\n                                s->stride[i],\n                                (s->planeheight[i] - !s->first_field + 1) / 2);\n        }\n        nout++;\n        len--;\n        s->occupied = 0;\n    }\n\n    while (len >= 2) {\n        // output THIS image as-is\n        av_frame_make_writable(s->frame[nout]);\n        for (i = 0; i < s->nb_planes; i++)\n            av_image_copy_plane(s->frame[nout]->data[i], s->frame[nout]->linesize[i],\n                                inpicref->data[i], inpicref->linesize[i],\n                                s->stride[i],\n                                s->planeheight[i]);\n        nout++;\n        len -= 2;\n    }\n\n    if (len >= 1) {\n        // copy THIS image to the buffer, we need it later\n        for (i = 0; i < s->nb_planes; i++)\n            av_image_copy_plane(s->temp->data[i], s->temp->linesize[i],\n                                inpicref->data[i], inpicref->linesize[i],\n                                s->stride[i],\n                                s->planeheight[i]);\n        s->occupied = 1;\n    }\n\n    for (i = 0; i < nout; i++) {\n        AVFrame *frame = av_frame_clone(s->frame[i]);\n\n        if (!frame) {\n            av_frame_free(&inpicref);\n            return AVERROR(ENOMEM);\n        }\n\n        av_frame_copy_props(frame, inpicref);\n        frame->pts = ((s->start_time == AV_NOPTS_VALUE) ? 0 : s->start_time) +\n                     av_rescale(outlink->frame_count, s->ts_unit.num,\n                                s->ts_unit.den);\n        ret = ff_filter_frame(outlink, frame);\n    }\n    av_frame_free(&inpicref);\n\n    return ret;\n}\n\nstatic av_cold void uninit(AVFilterContext *ctx)\n{\n    TelecineContext *s = ctx->priv;\n    int i;\n\n    av_frame_free(&s->temp);\n    for (i = 0; i < s->out_cnt; i++)\n        av_frame_free(&s->frame[i]);\n}\n\nstatic const AVFilterPad telecine_inputs[] = {\n    {\n        .name          = \"default\",\n        .type          = AVMEDIA_TYPE_VIDEO,\n        .filter_frame  = filter_frame,\n        .config_props  = config_input,\n    },\n    { NULL }\n};\n\nstatic const AVFilterPad telecine_outputs[] = {\n    {\n        .name          = \"default\",\n        .type          = AVMEDIA_TYPE_VIDEO,\n        .config_props  = config_output,\n    },\n    { NULL }\n};\n\nAVFilter ff_vf_telecine = {\n    .name          = \"telecine\",\n    .description   = NULL_IF_CONFIG_SMALL(\"Apply a telecine pattern.\"),\n    .priv_size     = sizeof(TelecineContext),\n    .priv_class    = &telecine_class,\n    .init          = init,\n    .uninit        = uninit,\n    .query_formats = query_formats,\n    .inputs        = telecine_inputs,\n    .outputs       = telecine_outputs,\n};\n",
        "/tmp/vanessa/spack-stage/spack-stage-ffmpeg-3.2.4-tt6o4aq464a72ptcc3rjc7s6iclbxb35/spack-src/libavcodec/omx.c": "/*\n * OMX Video encoder\n * Copyright (C) 2011 Martin Storsjo\n *\n * This file is part of FFmpeg.\n *\n * FFmpeg is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License as published by the Free Software Foundation; either\n * version 2.1 of the License, or (at your option) any later version.\n *\n * FFmpeg is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with FFmpeg; if not, write to the Free Software\n * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n */\n\n#include \"config.h\"\n\n#if CONFIG_OMX_RPI\n#define OMX_SKIP64BIT\n#endif\n\n#include <dlfcn.h>\n#include <OMX_Core.h>\n#include <OMX_Component.h>\n#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <sys/time.h>\n\n#include \"libavutil/avstring.h\"\n#include \"libavutil/avutil.h\"\n#include \"libavutil/common.h\"\n#include \"libavutil/imgutils.h\"\n#include \"libavutil/log.h\"\n#include \"libavutil/opt.h\"\n\n#include \"avcodec.h\"\n#include \"h264.h\"\n#include \"internal.h\"\n\n#ifdef OMX_SKIP64BIT\nstatic OMX_TICKS to_omx_ticks(int64_t value)\n{\n    OMX_TICKS s;\n    s.nLowPart  = value & 0xffffffff;\n    s.nHighPart = value >> 32;\n    return s;\n}\nstatic int64_t from_omx_ticks(OMX_TICKS value)\n{\n    return (((int64_t)value.nHighPart) << 32) | value.nLowPart;\n}\n#else\n#define to_omx_ticks(x) (x)\n#define from_omx_ticks(x) (x)\n#endif\n\n#define INIT_STRUCT(x) do {                                               \\\n        x.nSize = sizeof(x);                                              \\\n        x.nVersion = s->version;                                          \\\n    } while (0)\n#define CHECK(x) do {                                                     \\\n        if (x != OMX_ErrorNone) {                                         \\\n            av_log(avctx, AV_LOG_ERROR,                                   \\\n                   \"err %x (%d) on line %d\\n\", x, x, __LINE__);           \\\n            return AVERROR_UNKNOWN;                                       \\\n        }                                                                 \\\n    } while (0)\n\ntypedef struct OMXContext {\n    void *lib;\n    void *lib2;\n    OMX_ERRORTYPE (*ptr_Init)(void);\n    OMX_ERRORTYPE (*ptr_Deinit)(void);\n    OMX_ERRORTYPE (*ptr_ComponentNameEnum)(OMX_STRING, OMX_U32, OMX_U32);\n    OMX_ERRORTYPE (*ptr_GetHandle)(OMX_HANDLETYPE*, OMX_STRING, OMX_PTR, OMX_CALLBACKTYPE*);\n    OMX_ERRORTYPE (*ptr_FreeHandle)(OMX_HANDLETYPE);\n    OMX_ERRORTYPE (*ptr_GetComponentsOfRole)(OMX_STRING, OMX_U32*, OMX_U8**);\n    OMX_ERRORTYPE (*ptr_GetRolesOfComponent)(OMX_STRING, OMX_U32*, OMX_U8**);\n    void (*host_init)(void);\n} OMXContext;\n\nstatic av_cold void *dlsym_prefixed(void *handle, const char *symbol, const char *prefix)\n{\n    char buf[50];\n    snprintf(buf, sizeof(buf), \"%s%s\", prefix ? prefix : \"\", symbol);\n    return dlsym(handle, buf);\n}\n\nstatic av_cold int omx_try_load(OMXContext *s, void *logctx,\n                                const char *libname, const char *prefix,\n                                const char *libname2)\n{\n    if (libname2) {\n        s->lib2 = dlopen(libname2, RTLD_NOW | RTLD_GLOBAL);\n        if (!s->lib2) {\n            av_log(logctx, AV_LOG_WARNING, \"%s not found\\n\", libname);\n            return AVERROR_ENCODER_NOT_FOUND;\n        }\n        s->host_init = dlsym(s->lib2, \"bcm_host_init\");\n        if (!s->host_init) {\n            av_log(logctx, AV_LOG_WARNING, \"bcm_host_init not found\\n\");\n            dlclose(s->lib2);\n            s->lib2 = NULL;\n            return AVERROR_ENCODER_NOT_FOUND;\n        }\n    }\n    s->lib = dlopen(libname, RTLD_NOW | RTLD_GLOBAL);\n    if (!s->lib) {\n        av_log(logctx, AV_LOG_WARNING, \"%s not found\\n\", libname);\n        return AVERROR_ENCODER_NOT_FOUND;\n    }\n    s->ptr_Init                = dlsym_prefixed(s->lib, \"OMX_Init\", prefix);\n    s->ptr_Deinit              = dlsym_prefixed(s->lib, \"OMX_Deinit\", prefix);\n    s->ptr_ComponentNameEnum   = dlsym_prefixed(s->lib, \"OMX_ComponentNameEnum\", prefix);\n    s->ptr_GetHandle           = dlsym_prefixed(s->lib, \"OMX_GetHandle\", prefix);\n    s->ptr_FreeHandle          = dlsym_prefixed(s->lib, \"OMX_FreeHandle\", prefix);\n    s->ptr_GetComponentsOfRole = dlsym_prefixed(s->lib, \"OMX_GetComponentsOfRole\", prefix);\n    s->ptr_GetRolesOfComponent = dlsym_prefixed(s->lib, \"OMX_GetRolesOfComponent\", prefix);\n    if (!s->ptr_Init || !s->ptr_Deinit || !s->ptr_ComponentNameEnum ||\n        !s->ptr_GetHandle || !s->ptr_FreeHandle ||\n        !s->ptr_GetComponentsOfRole || !s->ptr_GetRolesOfComponent) {\n        av_log(logctx, AV_LOG_WARNING, \"Not all functions found in %s\\n\", libname);\n        dlclose(s->lib);\n        s->lib = NULL;\n        if (s->lib2)\n            dlclose(s->lib2);\n        s->lib2 = NULL;\n        return AVERROR_ENCODER_NOT_FOUND;\n    }\n    return 0;\n}\n\nstatic av_cold OMXContext *omx_init(void *logctx, const char *libname, const char *prefix)\n{\n    static const char * const libnames[] = {\n#if CONFIG_OMX_RPI\n        \"/opt/vc/lib/libopenmaxil.so\", \"/opt/vc/lib/libbcm_host.so\",\n#else\n        \"libOMX_Core.so\", NULL,\n        \"libOmxCore.so\", NULL,\n#endif\n        NULL\n    };\n    const char* const* nameptr;\n    int ret = AVERROR_ENCODER_NOT_FOUND;\n    OMXContext *omx_context;\n\n    omx_context = av_mallocz(sizeof(*omx_context));\n    if (!omx_context)\n        return NULL;\n    if (libname) {\n        ret = omx_try_load(omx_context, logctx, libname, prefix, NULL);\n        if (ret < 0) {\n            av_free(omx_context);\n            return NULL;\n        }\n    } else {\n        for (nameptr = libnames; *nameptr; nameptr += 2)\n            if (!(ret = omx_try_load(omx_context, logctx, nameptr[0], prefix, nameptr[1])))\n                break;\n        if (!*nameptr) {\n            av_free(omx_context);\n            return NULL;\n        }\n    }\n\n    if (omx_context->host_init)\n        omx_context->host_init();\n    omx_context->ptr_Init();\n    return omx_context;\n}\n\nstatic av_cold void omx_deinit(OMXContext *omx_context)\n{\n    if (!omx_context)\n        return;\n    omx_context->ptr_Deinit();\n    dlclose(omx_context->lib);\n    av_free(omx_context);\n}\n\ntypedef struct OMXCodecContext {\n    const AVClass *class;\n    char *libname;\n    char *libprefix;\n    OMXContext *omx_context;\n\n    AVCodecContext *avctx;\n\n    char component_name[OMX_MAX_STRINGNAME_SIZE];\n    OMX_VERSIONTYPE version;\n    OMX_HANDLETYPE handle;\n    int in_port, out_port;\n    OMX_COLOR_FORMATTYPE color_format;\n    int stride, plane_size;\n\n    int num_in_buffers, num_out_buffers;\n    OMX_BUFFERHEADERTYPE **in_buffer_headers;\n    OMX_BUFFERHEADERTYPE **out_buffer_headers;\n    int num_free_in_buffers;\n    OMX_BUFFERHEADERTYPE **free_in_buffers;\n    int num_done_out_buffers;\n    OMX_BUFFERHEADERTYPE **done_out_buffers;\n    pthread_mutex_t input_mutex;\n    pthread_cond_t input_cond;\n    pthread_mutex_t output_mutex;\n    pthread_cond_t output_cond;\n\n    pthread_mutex_t state_mutex;\n    pthread_cond_t state_cond;\n    OMX_STATETYPE state;\n    OMX_ERRORTYPE error;\n\n    int mutex_cond_inited;\n\n    int num_in_frames, num_out_frames;\n\n    uint8_t *output_buf;\n    int output_buf_size;\n\n    int input_zerocopy;\n} OMXCodecContext;\n\nstatic void append_buffer(pthread_mutex_t *mutex, pthread_cond_t *cond,\n                          int* array_size, OMX_BUFFERHEADERTYPE **array,\n                          OMX_BUFFERHEADERTYPE *buffer)\n{\n    pthread_mutex_lock(mutex);\n    array[(*array_size)++] = buffer;\n    pthread_cond_broadcast(cond);\n    pthread_mutex_unlock(mutex);\n}\n\nstatic OMX_BUFFERHEADERTYPE *get_buffer(pthread_mutex_t *mutex, pthread_cond_t *cond,\n                                        int* array_size, OMX_BUFFERHEADERTYPE **array,\n                                        int wait)\n{\n    OMX_BUFFERHEADERTYPE *buffer;\n    pthread_mutex_lock(mutex);\n    if (wait) {\n        while (!*array_size)\n           pthread_cond_wait(cond, mutex);\n    }\n    if (*array_size > 0) {\n        buffer = array[0];\n        (*array_size)--;\n        memmove(&array[0], &array[1], (*array_size) * sizeof(OMX_BUFFERHEADERTYPE*));\n    } else {\n        buffer = NULL;\n    }\n    pthread_mutex_unlock(mutex);\n    return buffer;\n}\n\nstatic OMX_ERRORTYPE event_handler(OMX_HANDLETYPE component, OMX_PTR app_data, OMX_EVENTTYPE event,\n                                   OMX_U32 data1, OMX_U32 data2, OMX_PTR event_data)\n{\n    OMXCodecContext *s = app_data;\n    // This uses casts in the printfs, since OMX_U32 actually is a typedef for\n    // unsigned long in official header versions (but there are also modified\n    // versions where it is something else).\n    switch (event) {\n    case OMX_EventError:\n        pthread_mutex_lock(&s->state_mutex);\n        av_log(s->avctx, AV_LOG_ERROR, \"OMX error %\"PRIx32\"\\n\", (uint32_t) data1);\n        s->error = data1;\n        pthread_cond_broadcast(&s->state_cond);\n        pthread_mutex_unlock(&s->state_mutex);\n        break;\n    case OMX_EventCmdComplete:\n        if (data1 == OMX_CommandStateSet) {\n            pthread_mutex_lock(&s->state_mutex);\n            s->state = data2;\n            av_log(s->avctx, AV_LOG_VERBOSE, \"OMX state changed to %\"PRIu32\"\\n\", (uint32_t) data2);\n            pthread_cond_broadcast(&s->state_cond);\n            pthread_mutex_unlock(&s->state_mutex);\n        } else if (data1 == OMX_CommandPortDisable) {\n            av_log(s->avctx, AV_LOG_VERBOSE, \"OMX port %\"PRIu32\" disabled\\n\", (uint32_t) data2);\n        } else if (data1 == OMX_CommandPortEnable) {\n            av_log(s->avctx, AV_LOG_VERBOSE, \"OMX port %\"PRIu32\" enabled\\n\", (uint32_t) data2);\n        } else {\n            av_log(s->avctx, AV_LOG_VERBOSE, \"OMX command complete, command %\"PRIu32\", value %\"PRIu32\"\\n\",\n                                             (uint32_t) data1, (uint32_t) data2);\n        }\n        break;\n    case OMX_EventPortSettingsChanged:\n        av_log(s->avctx, AV_LOG_VERBOSE, \"OMX port %\"PRIu32\" settings changed\\n\", (uint32_t) data1);\n        break;\n    default:\n        av_log(s->avctx, AV_LOG_VERBOSE, \"OMX event %d %\"PRIx32\" %\"PRIx32\"\\n\",\n                                         event, (uint32_t) data1, (uint32_t) data2);\n        break;\n    }\n    return OMX_ErrorNone;\n}\n\nstatic OMX_ERRORTYPE empty_buffer_done(OMX_HANDLETYPE component, OMX_PTR app_data,\n                                       OMX_BUFFERHEADERTYPE *buffer)\n{\n    OMXCodecContext *s = app_data;\n    if (s->input_zerocopy) {\n        if (buffer->pAppPrivate) {\n            if (buffer->pOutputPortPrivate)\n                av_free(buffer->pAppPrivate);\n            else\n                av_frame_free((AVFrame**)&buffer->pAppPrivate);\n            buffer->pAppPrivate = NULL;\n        }\n    }\n    append_buffer(&s->input_mutex, &s->input_cond,\n                  &s->num_free_in_buffers, s->free_in_buffers, buffer);\n    return OMX_ErrorNone;\n}\n\nstatic OMX_ERRORTYPE fill_buffer_done(OMX_HANDLETYPE component, OMX_PTR app_data,\n                                      OMX_BUFFERHEADERTYPE *buffer)\n{\n    OMXCodecContext *s = app_data;\n    append_buffer(&s->output_mutex, &s->output_cond,\n                  &s->num_done_out_buffers, s->done_out_buffers, buffer);\n    return OMX_ErrorNone;\n}\n\nstatic const OMX_CALLBACKTYPE callbacks = {\n    event_handler,\n    empty_buffer_done,\n    fill_buffer_done\n};\n\nstatic av_cold int find_component(OMXContext *omx_context, void *logctx,\n                                  const char *role, char *str, int str_size)\n{\n    OMX_U32 i, num = 0;\n    char **components;\n    int ret = 0;\n\n#if CONFIG_OMX_RPI\n    if (av_strstart(role, \"video_encoder.\", NULL)) {\n        av_strlcpy(str, \"OMX.broadcom.video_encode\", str_size);\n        return 0;\n    }\n#endif\n    omx_context->ptr_GetComponentsOfRole((OMX_STRING) role, &num, NULL);\n    if (!num) {\n        av_log(logctx, AV_LOG_WARNING, \"No component for role %s found\\n\", role);\n        return AVERROR_ENCODER_NOT_FOUND;\n    }\n    components = av_mallocz(sizeof(char*) * num);\n    if (!components)\n        return AVERROR(ENOMEM);\n    for (i = 0; i < num; i++) {\n        components[i] = av_mallocz(OMX_MAX_STRINGNAME_SIZE);\n        if (!components) {\n            ret = AVERROR(ENOMEM);\n            goto end;\n        }\n    }\n    omx_context->ptr_GetComponentsOfRole((OMX_STRING) role, &num, (OMX_U8**) components);\n    av_strlcpy(str, components[0], str_size);\nend:\n    for (i = 0; i < num; i++)\n        av_free(components[i]);\n    av_free(components);\n    return ret;\n}\n\nstatic av_cold int wait_for_state(OMXCodecContext *s, OMX_STATETYPE state)\n{\n    int ret = 0;\n    pthread_mutex_lock(&s->state_mutex);\n    while (s->state != state && s->error == OMX_ErrorNone)\n        pthread_cond_wait(&s->state_cond, &s->state_mutex);\n    if (s->error != OMX_ErrorNone)\n        ret = AVERROR_ENCODER_NOT_FOUND;\n    pthread_mutex_unlock(&s->state_mutex);\n    return ret;\n}\n\nstatic av_cold int omx_component_init(AVCodecContext *avctx, const char *role)\n{\n    OMXCodecContext *s = avctx->priv_data;\n    OMX_PARAM_COMPONENTROLETYPE role_params = { 0 };\n    OMX_PORT_PARAM_TYPE video_port_params = { 0 };\n    OMX_PARAM_PORTDEFINITIONTYPE in_port_params = { 0 }, out_port_params = { 0 };\n    OMX_VIDEO_PARAM_PORTFORMATTYPE video_port_format = { 0 };\n    OMX_VIDEO_PARAM_BITRATETYPE vid_param_bitrate = { 0 };\n    OMX_ERRORTYPE err;\n    int i;\n\n    s->version.s.nVersionMajor = 1;\n    s->version.s.nVersionMinor = 1;\n    s->version.s.nRevision     = 2;\n\n    err = s->omx_context->ptr_GetHandle(&s->handle, s->component_name, s, (OMX_CALLBACKTYPE*) &callbacks);\n    if (err != OMX_ErrorNone) {\n        av_log(avctx, AV_LOG_ERROR, \"OMX_GetHandle(%s) failed: %x\\n\", s->component_name, err);\n        return AVERROR_UNKNOWN;\n    }\n\n    // This one crashes the mediaserver on qcom, if used over IOMX\n    INIT_STRUCT(role_params);\n    av_strlcpy(role_params.cRole, role, sizeof(role_params.cRole));\n    // Intentionally ignore errors on this one\n    OMX_SetParameter(s->handle, OMX_IndexParamStandardComponentRole, &role_params);\n\n    INIT_STRUCT(video_port_params);\n    err = OMX_GetParameter(s->handle, OMX_IndexParamVideoInit, &video_port_params);\n    CHECK(err);\n\n    s->in_port = s->out_port = -1;\n    for (i = 0; i < video_port_params.nPorts; i++) {\n        int port = video_port_params.nStartPortNumber + i;\n        OMX_PARAM_PORTDEFINITIONTYPE port_params = { 0 };\n        INIT_STRUCT(port_params);\n        port_params.nPortIndex = port;\n        err = OMX_GetParameter(s->handle, OMX_IndexParamPortDefinition, &port_params);\n        if (err != OMX_ErrorNone) {\n            av_log(avctx, AV_LOG_WARNING, \"port %d error %x\\n\", port, err);\n            break;\n        }\n        if (port_params.eDir == OMX_DirInput && s->in_port < 0) {\n            in_port_params = port_params;\n            s->in_port = port;\n        } else if (port_params.eDir == OMX_DirOutput && s->out_port < 0) {\n            out_port_params = port_params;\n            s->out_port = port;\n        }\n    }\n    if (s->in_port < 0 || s->out_port < 0) {\n        av_log(avctx, AV_LOG_ERROR, \"No in or out port found (in %d out %d)\\n\", s->in_port, s->out_port);\n        return AVERROR_UNKNOWN;\n    }\n\n    s->color_format = 0;\n    for (i = 0; ; i++) {\n        INIT_STRUCT(video_port_format);\n        video_port_format.nIndex = i;\n        video_port_format.nPortIndex = s->in_port;\n        if (OMX_GetParameter(s->handle, OMX_IndexParamVideoPortFormat, &video_port_format) != OMX_ErrorNone)\n            break;\n        if (video_port_format.eColorFormat == OMX_COLOR_FormatYUV420Planar ||\n            video_port_format.eColorFormat == OMX_COLOR_FormatYUV420PackedPlanar) {\n            s->color_format = video_port_format.eColorFormat;\n            break;\n        }\n    }\n    if (s->color_format == 0) {\n        av_log(avctx, AV_LOG_ERROR, \"No supported pixel formats (%d formats available)\\n\", i);\n        return AVERROR_UNKNOWN;\n    }\n\n    in_port_params.bEnabled   = OMX_TRUE;\n    in_port_params.bPopulated = OMX_FALSE;\n    in_port_params.eDomain    = OMX_PortDomainVideo;\n\n    in_port_params.format.video.pNativeRender         = NULL;\n    in_port_params.format.video.bFlagErrorConcealment = OMX_FALSE;\n    in_port_params.format.video.eColorFormat          = s->color_format;\n    s->stride     = avctx->width;\n    s->plane_size = avctx->height;\n    // If specific codecs need to manually override the stride/plane_size,\n    // that can be done here.\n    in_port_params.format.video.nStride      = s->stride;\n    in_port_params.format.video.nSliceHeight = s->plane_size;\n    in_port_params.format.video.nFrameWidth  = avctx->width;\n    in_port_params.format.video.nFrameHeight = avctx->height;\n    if (avctx->framerate.den > 0 && avctx->framerate.num > 0)\n        in_port_params.format.video.xFramerate = (1 << 16) * avctx->framerate.num / avctx->framerate.den;\n    else\n        in_port_params.format.video.xFramerate = (1 << 16) * avctx->time_base.den / avctx->time_base.num;\n\n    err = OMX_SetParameter(s->handle, OMX_IndexParamPortDefinition, &in_port_params);\n    CHECK(err);\n    err = OMX_GetParameter(s->handle, OMX_IndexParamPortDefinition, &in_port_params);\n    CHECK(err);\n    s->stride         = in_port_params.format.video.nStride;\n    s->plane_size     = in_port_params.format.video.nSliceHeight;\n    s->num_in_buffers = in_port_params.nBufferCountActual;\n\n    err = OMX_GetParameter(s->handle, OMX_IndexParamPortDefinition, &out_port_params);\n    out_port_params.bEnabled   = OMX_TRUE;\n    out_port_params.bPopulated = OMX_FALSE;\n    out_port_params.eDomain    = OMX_PortDomainVideo;\n    out_port_params.format.video.pNativeRender = NULL;\n    out_port_params.format.video.nFrameWidth   = avctx->width;\n    out_port_params.format.video.nFrameHeight  = avctx->height;\n    out_port_params.format.video.nStride       = 0;\n    out_port_params.format.video.nSliceHeight  = 0;\n    out_port_params.format.video.nBitrate      = avctx->bit_rate;\n    out_port_params.format.video.xFramerate    = in_port_params.format.video.xFramerate;\n    out_port_params.format.video.bFlagErrorConcealment  = OMX_FALSE;\n    if (avctx->codec->id == AV_CODEC_ID_MPEG4)\n        out_port_params.format.video.eCompressionFormat = OMX_VIDEO_CodingMPEG4;\n    else if (avctx->codec->id == AV_CODEC_ID_H264)\n        out_port_params.format.video.eCompressionFormat = OMX_VIDEO_CodingAVC;\n\n    err = OMX_SetParameter(s->handle, OMX_IndexParamPortDefinition, &out_port_params);\n    CHECK(err);\n    err = OMX_GetParameter(s->handle, OMX_IndexParamPortDefinition, &out_port_params);\n    CHECK(err);\n    s->num_out_buffers = out_port_params.nBufferCountActual;\n\n    INIT_STRUCT(vid_param_bitrate);\n    vid_param_bitrate.nPortIndex     = s->out_port;\n    vid_param_bitrate.eControlRate   = OMX_Video_ControlRateVariable;\n    vid_param_bitrate.nTargetBitrate = avctx->bit_rate;\n    err = OMX_SetParameter(s->handle, OMX_IndexParamVideoBitrate, &vid_param_bitrate);\n    if (err != OMX_ErrorNone)\n        av_log(avctx, AV_LOG_WARNING, \"Unable to set video bitrate parameter\\n\");\n\n    if (avctx->codec->id == AV_CODEC_ID_H264) {\n        OMX_VIDEO_PARAM_AVCTYPE avc = { 0 };\n        INIT_STRUCT(avc);\n        avc.nPortIndex = s->out_port;\n        err = OMX_GetParameter(s->handle, OMX_IndexParamVideoAvc, &avc);\n        CHECK(err);\n        avc.nBFrames = 0;\n        avc.nPFrames = avctx->gop_size - 1;\n        err = OMX_SetParameter(s->handle, OMX_IndexParamVideoAvc, &avc);\n        CHECK(err);\n    }\n\n    err = OMX_SendCommand(s->handle, OMX_CommandStateSet, OMX_StateIdle, NULL);\n    CHECK(err);\n\n    s->in_buffer_headers  = av_mallocz(sizeof(OMX_BUFFERHEADERTYPE*) * s->num_in_buffers);\n    s->free_in_buffers    = av_mallocz(sizeof(OMX_BUFFERHEADERTYPE*) * s->num_in_buffers);\n    s->out_buffer_headers = av_mallocz(sizeof(OMX_BUFFERHEADERTYPE*) * s->num_out_buffers);\n    s->done_out_buffers   = av_mallocz(sizeof(OMX_BUFFERHEADERTYPE*) * s->num_out_buffers);\n    if (!s->in_buffer_headers || !s->free_in_buffers || !s->out_buffer_headers || !s->done_out_buffers)\n        return AVERROR(ENOMEM);\n    for (i = 0; i < s->num_in_buffers && err == OMX_ErrorNone; i++) {\n        if (s->input_zerocopy)\n            err = OMX_UseBuffer(s->handle, &s->in_buffer_headers[i], s->in_port, s, in_port_params.nBufferSize, NULL);\n        else\n            err = OMX_AllocateBuffer(s->handle, &s->in_buffer_headers[i],  s->in_port,  s, in_port_params.nBufferSize);\n        if (err == OMX_ErrorNone)\n            s->in_buffer_headers[i]->pAppPrivate = s->in_buffer_headers[i]->pOutputPortPrivate = NULL;\n    }\n    CHECK(err);\n    s->num_in_buffers = i;\n    for (i = 0; i < s->num_out_buffers && err == OMX_ErrorNone; i++)\n        err = OMX_AllocateBuffer(s->handle, &s->out_buffer_headers[i], s->out_port, s, out_port_params.nBufferSize);\n    CHECK(err);\n    s->num_out_buffers = i;\n\n    if (wait_for_state(s, OMX_StateIdle) < 0) {\n        av_log(avctx, AV_LOG_ERROR, \"Didn't get OMX_StateIdle\\n\");\n        return AVERROR_UNKNOWN;\n    }\n    err = OMX_SendCommand(s->handle, OMX_CommandStateSet, OMX_StateExecuting, NULL);\n    CHECK(err);\n    if (wait_for_state(s, OMX_StateExecuting) < 0) {\n        av_log(avctx, AV_LOG_ERROR, \"Didn't get OMX_StateExecuting\\n\");\n        return AVERROR_UNKNOWN;\n    }\n\n    for (i = 0; i < s->num_out_buffers && err == OMX_ErrorNone; i++)\n        err = OMX_FillThisBuffer(s->handle, s->out_buffer_headers[i]);\n    if (err != OMX_ErrorNone) {\n        for (; i < s->num_out_buffers; i++)\n            s->done_out_buffers[s->num_done_out_buffers++] = s->out_buffer_headers[i];\n    }\n    for (i = 0; i < s->num_in_buffers; i++)\n        s->free_in_buffers[s->num_free_in_buffers++] = s->in_buffer_headers[i];\n    return err != OMX_ErrorNone ? AVERROR_UNKNOWN : 0;\n}\n\nstatic av_cold void cleanup(OMXCodecContext *s)\n{\n    int i, executing;\n\n    pthread_mutex_lock(&s->state_mutex);\n    executing = s->state == OMX_StateExecuting;\n    pthread_mutex_unlock(&s->state_mutex);\n\n    if (executing) {\n        OMX_SendCommand(s->handle, OMX_CommandStateSet, OMX_StateIdle, NULL);\n        wait_for_state(s, OMX_StateIdle);\n        OMX_SendCommand(s->handle, OMX_CommandStateSet, OMX_StateLoaded, NULL);\n        for (i = 0; i < s->num_in_buffers; i++) {\n            OMX_BUFFERHEADERTYPE *buffer = get_buffer(&s->input_mutex, &s->input_cond,\n                                                      &s->num_free_in_buffers, s->free_in_buffers, 1);\n            if (s->input_zerocopy)\n                buffer->pBuffer = NULL;\n            OMX_FreeBuffer(s->handle, s->in_port, buffer);\n        }\n        for (i = 0; i < s->num_out_buffers; i++) {\n            OMX_BUFFERHEADERTYPE *buffer = get_buffer(&s->output_mutex, &s->output_cond,\n                                                      &s->num_done_out_buffers, s->done_out_buffers, 1);\n            OMX_FreeBuffer(s->handle, s->out_port, buffer);\n        }\n        wait_for_state(s, OMX_StateLoaded);\n    }\n    if (s->handle) {\n        s->omx_context->ptr_FreeHandle(s->handle);\n        s->handle = NULL;\n    }\n\n    omx_deinit(s->omx_context);\n    s->omx_context = NULL;\n    if (s->mutex_cond_inited) {\n        pthread_cond_destroy(&s->state_cond);\n        pthread_mutex_destroy(&s->state_mutex);\n        pthread_cond_destroy(&s->input_cond);\n        pthread_mutex_destroy(&s->input_mutex);\n        pthread_cond_destroy(&s->output_cond);\n        pthread_mutex_destroy(&s->output_mutex);\n        s->mutex_cond_inited = 0;\n    }\n    av_freep(&s->in_buffer_headers);\n    av_freep(&s->out_buffer_headers);\n    av_freep(&s->free_in_buffers);\n    av_freep(&s->done_out_buffers);\n    av_freep(&s->output_buf);\n}\n\nstatic av_cold int omx_encode_init(AVCodecContext *avctx)\n{\n    OMXCodecContext *s = avctx->priv_data;\n    int ret = AVERROR_ENCODER_NOT_FOUND;\n    const char *role;\n    OMX_BUFFERHEADERTYPE *buffer;\n    OMX_ERRORTYPE err;\n\n#if CONFIG_OMX_RPI\n    s->input_zerocopy = 1;\n#endif\n\n    s->omx_context = omx_init(avctx, s->libname, s->libprefix);\n    if (!s->omx_context)\n        return AVERROR_ENCODER_NOT_FOUND;\n\n    pthread_mutex_init(&s->state_mutex, NULL);\n    pthread_cond_init(&s->state_cond, NULL);\n    pthread_mutex_init(&s->input_mutex, NULL);\n    pthread_cond_init(&s->input_cond, NULL);\n    pthread_mutex_init(&s->output_mutex, NULL);\n    pthread_cond_init(&s->output_cond, NULL);\n    s->mutex_cond_inited = 1;\n    s->avctx = avctx;\n    s->state = OMX_StateLoaded;\n    s->error = OMX_ErrorNone;\n\n    switch (avctx->codec->id) {\n    case AV_CODEC_ID_MPEG4:\n        role = \"video_encoder.mpeg4\";\n        break;\n    case AV_CODEC_ID_H264:\n        role = \"video_encoder.avc\";\n        break;\n    default:\n        return AVERROR(ENOSYS);\n    }\n\n    if ((ret = find_component(s->omx_context, avctx, role, s->component_name, sizeof(s->component_name))) < 0)\n        goto fail;\n\n    av_log(avctx, AV_LOG_INFO, \"Using %s\\n\", s->component_name);\n\n    if ((ret = omx_component_init(avctx, role)) < 0)\n        goto fail;\n\n    if (avctx->flags & AV_CODEC_FLAG_GLOBAL_HEADER) {\n        while (1) {\n            buffer = get_buffer(&s->output_mutex, &s->output_cond,\n                                &s->num_done_out_buffers, s->done_out_buffers, 1);\n            if (buffer->nFlags & OMX_BUFFERFLAG_CODECCONFIG) {\n                if ((ret = av_reallocp(&avctx->extradata, avctx->extradata_size + buffer->nFilledLen + AV_INPUT_BUFFER_PADDING_SIZE)) < 0) {\n                    avctx->extradata_size = 0;\n                    goto fail;\n                }\n                memcpy(avctx->extradata + avctx->extradata_size, buffer->pBuffer + buffer->nOffset, buffer->nFilledLen);\n                avctx->extradata_size += buffer->nFilledLen;\n                memset(avctx->extradata + avctx->extradata_size, 0, AV_INPUT_BUFFER_PADDING_SIZE);\n            }\n            err = OMX_FillThisBuffer(s->handle, buffer);\n            if (err != OMX_ErrorNone) {\n                append_buffer(&s->output_mutex, &s->output_cond,\n                              &s->num_done_out_buffers, s->done_out_buffers, buffer);\n                av_log(avctx, AV_LOG_ERROR, \"OMX_FillThisBuffer failed: %x\\n\", err);\n                ret = AVERROR_UNKNOWN;\n                goto fail;\n            }\n            if (avctx->codec->id == AV_CODEC_ID_H264) {\n                // For H.264, the extradata can be returned in two separate buffers\n                // (the videocore encoder on raspberry pi does this);\n                // therefore check that we have got both SPS and PPS before continuing.\n                int nals[32] = { 0 };\n                int i;\n                for (i = 0; i + 4 < avctx->extradata_size; i++) {\n                     if (!avctx->extradata[i + 0] &&\n                         !avctx->extradata[i + 1] &&\n                         !avctx->extradata[i + 2] &&\n                         avctx->extradata[i + 3] == 1) {\n                         nals[avctx->extradata[i + 4] & 0x1f]++;\n                     }\n                }\n                if (nals[H264_NAL_SPS] && nals[H264_NAL_PPS])\n                    break;\n            } else {\n                if (avctx->extradata_size > 0)\n                    break;\n            }\n        }\n    }\n\n    return 0;\nfail:\n    return ret;\n}\n\n\nstatic int omx_encode_frame(AVCodecContext *avctx, AVPacket *pkt,\n                            const AVFrame *frame, int *got_packet)\n{\n    OMXCodecContext *s = avctx->priv_data;\n    int ret = 0;\n    OMX_BUFFERHEADERTYPE* buffer;\n    OMX_ERRORTYPE err;\n\n    if (frame) {\n        uint8_t *dst[4];\n        int linesize[4];\n        int need_copy;\n        buffer = get_buffer(&s->input_mutex, &s->input_cond,\n                            &s->num_free_in_buffers, s->free_in_buffers, 1);\n\n        buffer->nFilledLen = av_image_fill_arrays(dst, linesize, buffer->pBuffer, avctx->pix_fmt, s->stride, s->plane_size, 1);\n\n        if (s->input_zerocopy) {\n            uint8_t *src[4] = { NULL };\n            int src_linesize[4];\n            av_image_fill_arrays(src, src_linesize, frame->data[0], avctx->pix_fmt, s->stride, s->plane_size, 1);\n            if (frame->linesize[0] == src_linesize[0] &&\n                frame->linesize[1] == src_linesize[1] &&\n                frame->linesize[2] == src_linesize[2] &&\n                frame->data[1] == src[1] &&\n                frame->data[2] == src[2]) {\n                // If the input frame happens to have all planes stored contiguously,\n                // with the right strides, just clone the frame and set the OMX\n                // buffer header to point to it\n                AVFrame *local = av_frame_clone(frame);\n                if (!local) {\n                    // Return the buffer to the queue so it's not lost\n                    append_buffer(&s->input_mutex, &s->input_cond, &s->num_free_in_buffers, s->free_in_buffers, buffer);\n                    return AVERROR(ENOMEM);\n                } else {\n                    buffer->pAppPrivate = local;\n                    buffer->pOutputPortPrivate = NULL;\n                    buffer->pBuffer = local->data[0];\n                    need_copy = 0;\n                }\n            } else {\n                // If not, we need to allocate a new buffer with the right\n                // size and copy the input frame into it.\n                uint8_t *buf = NULL;\n                int image_buffer_size = av_image_get_buffer_size(avctx->pix_fmt, s->stride, s->plane_size, 1);\n                if (image_buffer_size >= 0)\n                    buf = av_malloc(image_buffer_size);\n                if (!buf) {\n                    // Return the buffer to the queue so it's not lost\n                    append_buffer(&s->input_mutex, &s->input_cond, &s->num_free_in_buffers, s->free_in_buffers, buffer);\n                    return AVERROR(ENOMEM);\n                } else {\n                    buffer->pAppPrivate = buf;\n                    // Mark that pAppPrivate is an av_malloc'ed buffer, not an AVFrame\n                    buffer->pOutputPortPrivate = (void*) 1;\n                    buffer->pBuffer = buf;\n                    need_copy = 1;\n                    buffer->nFilledLen = av_image_fill_arrays(dst, linesize, buffer->pBuffer, avctx->pix_fmt, s->stride, s->plane_size, 1);\n                }\n            }\n        } else {\n            need_copy = 1;\n        }\n        if (need_copy)\n            av_image_copy(dst, linesize, (const uint8_t**) frame->data, frame->linesize, avctx->pix_fmt, avctx->width, avctx->height);\n        buffer->nFlags = OMX_BUFFERFLAG_ENDOFFRAME;\n        buffer->nOffset = 0;\n        // Convert the timestamps to microseconds; some encoders can ignore\n        // the framerate and do VFR bit allocation based on timestamps.\n        buffer->nTimeStamp = to_omx_ticks(av_rescale_q(frame->pts, avctx->time_base, AV_TIME_BASE_Q));\n        err = OMX_EmptyThisBuffer(s->handle, buffer);\n        if (err != OMX_ErrorNone) {\n            append_buffer(&s->input_mutex, &s->input_cond, &s->num_free_in_buffers, s->free_in_buffers, buffer);\n            av_log(avctx, AV_LOG_ERROR, \"OMX_EmptyThisBuffer failed: %x\\n\", err);\n            return AVERROR_UNKNOWN;\n        }\n        s->num_in_frames++;\n    }\n\n    while (!*got_packet && ret == 0) {\n        // Only wait for output if flushing and not all frames have been output\n        buffer = get_buffer(&s->output_mutex, &s->output_cond,\n                            &s->num_done_out_buffers, s->done_out_buffers,\n                            !frame && s->num_out_frames < s->num_in_frames);\n        if (!buffer)\n            break;\n\n        if (buffer->nFlags & OMX_BUFFERFLAG_CODECCONFIG && avctx->flags & AV_CODEC_FLAG_GLOBAL_HEADER) {\n            if ((ret = av_reallocp(&avctx->extradata, avctx->extradata_size + buffer->nFilledLen + AV_INPUT_BUFFER_PADDING_SIZE)) < 0) {\n                avctx->extradata_size = 0;\n                goto end;\n            }\n            memcpy(avctx->extradata + avctx->extradata_size, buffer->pBuffer + buffer->nOffset, buffer->nFilledLen);\n            avctx->extradata_size += buffer->nFilledLen;\n            memset(avctx->extradata + avctx->extradata_size, 0, AV_INPUT_BUFFER_PADDING_SIZE);\n        } else {\n            if (buffer->nFlags & OMX_BUFFERFLAG_ENDOFFRAME)\n                s->num_out_frames++;\n            if (!(buffer->nFlags & OMX_BUFFERFLAG_ENDOFFRAME) || !pkt->data) {\n                // If the output packet isn't preallocated, just concatenate everything in our\n                // own buffer\n                int newsize = s->output_buf_size + buffer->nFilledLen + AV_INPUT_BUFFER_PADDING_SIZE;\n                if ((ret = av_reallocp(&s->output_buf, newsize)) < 0) {\n                    s->output_buf_size = 0;\n                    goto end;\n                }\n                memcpy(s->output_buf + s->output_buf_size, buffer->pBuffer + buffer->nOffset, buffer->nFilledLen);\n                s->output_buf_size += buffer->nFilledLen;\n                if (buffer->nFlags & OMX_BUFFERFLAG_ENDOFFRAME) {\n                    if ((ret = av_packet_from_data(pkt, s->output_buf, s->output_buf_size)) < 0) {\n                        av_freep(&s->output_buf);\n                        s->output_buf_size = 0;\n                        goto end;\n                    }\n                    s->output_buf = NULL;\n                    s->output_buf_size = 0;\n                }\n            } else {\n                // End of frame, and the caller provided a preallocated frame\n                if ((ret = ff_alloc_packet2(avctx, pkt, s->output_buf_size + buffer->nFilledLen, 0)) < 0) {\n                    av_log(avctx, AV_LOG_ERROR, \"Error getting output packet of size %d.\\n\",\n                           (int)(s->output_buf_size + buffer->nFilledLen));\n                    goto end;\n                }\n                memcpy(pkt->data, s->output_buf, s->output_buf_size);\n                memcpy(pkt->data + s->output_buf_size, buffer->pBuffer + buffer->nOffset, buffer->nFilledLen);\n                av_freep(&s->output_buf);\n                s->output_buf_size = 0;\n            }\n            if (buffer->nFlags & OMX_BUFFERFLAG_ENDOFFRAME) {\n                pkt->pts = av_rescale_q(from_omx_ticks(buffer->nTimeStamp), AV_TIME_BASE_Q, avctx->time_base);\n                // We don't currently enable B-frames for the encoders, so set\n                // pkt->dts = pkt->pts. (The calling code behaves worse if the encoder\n                // doesn't set the dts).\n                pkt->dts = pkt->pts;\n                if (buffer->nFlags & OMX_BUFFERFLAG_SYNCFRAME)\n                    pkt->flags |= AV_PKT_FLAG_KEY;\n                *got_packet = 1;\n            }\n        }\nend:\n        err = OMX_FillThisBuffer(s->handle, buffer);\n        if (err != OMX_ErrorNone) {\n            append_buffer(&s->output_mutex, &s->output_cond, &s->num_done_out_buffers, s->done_out_buffers, buffer);\n            av_log(avctx, AV_LOG_ERROR, \"OMX_FillThisBuffer failed: %x\\n\", err);\n            ret = AVERROR_UNKNOWN;\n        }\n    }\n    return ret;\n}\n\nstatic av_cold int omx_encode_end(AVCodecContext *avctx)\n{\n    OMXCodecContext *s = avctx->priv_data;\n\n    cleanup(s);\n    return 0;\n}\n\n#define OFFSET(x) offsetof(OMXCodecContext, x)\n#define VDE AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_DECODING_PARAM | AV_OPT_FLAG_ENCODING_PARAM\n#define VE  AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_ENCODING_PARAM\nstatic const AVOption options[] = {\n    { \"omx_libname\", \"OpenMAX library name\", OFFSET(libname), AV_OPT_TYPE_STRING, { 0 }, 0, 0, VDE },\n    { \"omx_libprefix\", \"OpenMAX library prefix\", OFFSET(libprefix), AV_OPT_TYPE_STRING, { 0 }, 0, 0, VDE },\n    { \"zerocopy\", \"Try to avoid copying input frames if possible\", OFFSET(input_zerocopy), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 1, VE },\n    { NULL }\n};\n\nstatic const enum AVPixelFormat omx_encoder_pix_fmts[] = {\n    AV_PIX_FMT_YUV420P, AV_PIX_FMT_NONE\n};\n\nstatic const AVClass omx_mpeg4enc_class = {\n    .class_name = \"mpeg4_omx\",\n    .item_name  = av_default_item_name,\n    .option     = options,\n    .version    = LIBAVUTIL_VERSION_INT,\n};\nAVCodec ff_mpeg4_omx_encoder = {\n    .name             = \"mpeg4_omx\",\n    .long_name        = NULL_IF_CONFIG_SMALL(\"OpenMAX IL MPEG-4 video encoder\"),\n    .type             = AVMEDIA_TYPE_VIDEO,\n    .id               = AV_CODEC_ID_MPEG4,\n    .priv_data_size   = sizeof(OMXCodecContext),\n    .init             = omx_encode_init,\n    .encode2          = omx_encode_frame,\n    .close            = omx_encode_end,\n    .pix_fmts         = omx_encoder_pix_fmts,\n    .capabilities     = AV_CODEC_CAP_DELAY,\n    .caps_internal    = FF_CODEC_CAP_INIT_THREADSAFE | FF_CODEC_CAP_INIT_CLEANUP,\n    .priv_class       = &omx_mpeg4enc_class,\n};\n\nstatic const AVClass omx_h264enc_class = {\n    .class_name = \"h264_omx\",\n    .item_name  = av_default_item_name,\n    .option     = options,\n    .version    = LIBAVUTIL_VERSION_INT,\n};\nAVCodec ff_h264_omx_encoder = {\n    .name             = \"h264_omx\",\n    .long_name        = NULL_IF_CONFIG_SMALL(\"OpenMAX IL H.264 video encoder\"),\n    .type             = AVMEDIA_TYPE_VIDEO,\n    .id               = AV_CODEC_ID_H264,\n    .priv_data_size   = sizeof(OMXCodecContext),\n    .init             = omx_encode_init,\n    .encode2          = omx_encode_frame,\n    .close            = omx_encode_end,\n    .pix_fmts         = omx_encoder_pix_fmts,\n    .capabilities     = AV_CODEC_CAP_DELAY,\n    .caps_internal    = FF_CODEC_CAP_INIT_THREADSAFE | FF_CODEC_CAP_INIT_CLEANUP,\n    .priv_class       = &omx_h264enc_class,\n};\n",
        "/tmp/vanessa/spack-stage/spack-stage-ffmpeg-3.2.4-tt6o4aq464a72ptcc3rjc7s6iclbxb35/spack-src/libavcodec/nvenc.c": "/*\n * H.264/HEVC hardware encoding using nvidia nvenc\n * Copyright (c) 2016 Timo Rothenpieler <timo@rothenpieler.org>\n *\n * This file is part of FFmpeg.\n *\n * FFmpeg is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License as published by the Free Software Foundation; either\n * version 2.1 of the License, or (at your option) any later version.\n *\n * FFmpeg is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with FFmpeg; if not, write to the Free Software\n * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n */\n\n#include \"config.h\"\n\n#if defined(_WIN32) || defined(__CYGWIN__)\n# define CUDA_LIBNAME \"nvcuda.dll\"\n# if ARCH_X86_64\n#  define NVENC_LIBNAME \"nvEncodeAPI64.dll\"\n# else\n#  define NVENC_LIBNAME \"nvEncodeAPI.dll\"\n# endif\n#else\n# define CUDA_LIBNAME \"libcuda.so.1\"\n# define NVENC_LIBNAME \"libnvidia-encode.so.1\"\n#endif\n\n#if defined(_WIN32)\n#include <windows.h>\n\n#define dlopen(filename, flags) LoadLibrary(TEXT(filename))\n#define dlsym(handle, symbol)   GetProcAddress(handle, symbol)\n#define dlclose(handle)         FreeLibrary(handle)\n#else\n#include <dlfcn.h>\n#endif\n\n#include \"libavutil/hwcontext.h\"\n#include \"libavutil/imgutils.h\"\n#include \"libavutil/avassert.h\"\n#include \"libavutil/mem.h\"\n#include \"internal.h\"\n#include \"nvenc.h\"\n\n#define NVENC_CAP 0x30\n#define IS_CBR(rc) (rc == NV_ENC_PARAMS_RC_CBR ||               \\\n                    rc == NV_ENC_PARAMS_RC_2_PASS_QUALITY ||    \\\n                    rc == NV_ENC_PARAMS_RC_2_PASS_FRAMESIZE_CAP)\n\n#define LOAD_LIBRARY(l, path)                   \\\n    do {                                        \\\n        if (!((l) = dlopen(path, RTLD_LAZY))) { \\\n            av_log(avctx, AV_LOG_ERROR,         \\\n                   \"Cannot load %s\\n\",          \\\n                   path);                       \\\n            return AVERROR_UNKNOWN;             \\\n        }                                       \\\n    } while (0)\n\n#define LOAD_SYMBOL(fun, lib, symbol)        \\\n    do {                                     \\\n        if (!((fun) = dlsym(lib, symbol))) { \\\n            av_log(avctx, AV_LOG_ERROR,      \\\n                   \"Cannot load %s\\n\",       \\\n                   symbol);                  \\\n            return AVERROR_UNKNOWN;          \\\n        }                                    \\\n    } while (0)\n\nconst enum AVPixelFormat ff_nvenc_pix_fmts[] = {\n    AV_PIX_FMT_YUV420P,\n    AV_PIX_FMT_NV12,\n    AV_PIX_FMT_P010,\n    AV_PIX_FMT_YUV444P,\n    AV_PIX_FMT_YUV444P16,\n    AV_PIX_FMT_0RGB32,\n    AV_PIX_FMT_0BGR32,\n#if CONFIG_CUDA\n    AV_PIX_FMT_CUDA,\n#endif\n    AV_PIX_FMT_NONE\n};\n\n#define IS_10BIT(pix_fmt) (pix_fmt == AV_PIX_FMT_P010 ||    \\\n                           pix_fmt == AV_PIX_FMT_YUV444P16)\n\n#define IS_YUV444(pix_fmt) (pix_fmt == AV_PIX_FMT_YUV444P || \\\n                            pix_fmt == AV_PIX_FMT_YUV444P16)\n\nstatic const struct {\n    NVENCSTATUS nverr;\n    int         averr;\n    const char *desc;\n} nvenc_errors[] = {\n    { NV_ENC_SUCCESS,                      0,                \"success\"                  },\n    { NV_ENC_ERR_NO_ENCODE_DEVICE,         AVERROR(ENOENT),  \"no encode device\"         },\n    { NV_ENC_ERR_UNSUPPORTED_DEVICE,       AVERROR(ENOSYS),  \"unsupported device\"       },\n    { NV_ENC_ERR_INVALID_ENCODERDEVICE,    AVERROR(EINVAL),  \"invalid encoder device\"   },\n    { NV_ENC_ERR_INVALID_DEVICE,           AVERROR(EINVAL),  \"invalid device\"           },\n    { NV_ENC_ERR_DEVICE_NOT_EXIST,         AVERROR(EIO),     \"device does not exist\"    },\n    { NV_ENC_ERR_INVALID_PTR,              AVERROR(EFAULT),  \"invalid ptr\"              },\n    { NV_ENC_ERR_INVALID_EVENT,            AVERROR(EINVAL),  \"invalid event\"            },\n    { NV_ENC_ERR_INVALID_PARAM,            AVERROR(EINVAL),  \"invalid param\"            },\n    { NV_ENC_ERR_INVALID_CALL,             AVERROR(EINVAL),  \"invalid call\"             },\n    { NV_ENC_ERR_OUT_OF_MEMORY,            AVERROR(ENOMEM),  \"out of memory\"            },\n    { NV_ENC_ERR_ENCODER_NOT_INITIALIZED,  AVERROR(EINVAL),  \"encoder not initialized\"  },\n    { NV_ENC_ERR_UNSUPPORTED_PARAM,        AVERROR(ENOSYS),  \"unsupported param\"        },\n    { NV_ENC_ERR_LOCK_BUSY,                AVERROR(EAGAIN),  \"lock busy\"                },\n    { NV_ENC_ERR_NOT_ENOUGH_BUFFER,        AVERROR_BUFFER_TOO_SMALL, \"not enough buffer\"},\n    { NV_ENC_ERR_INVALID_VERSION,          AVERROR(EINVAL),  \"invalid version\"          },\n    { NV_ENC_ERR_MAP_FAILED,               AVERROR(EIO),     \"map failed\"               },\n    { NV_ENC_ERR_NEED_MORE_INPUT,          AVERROR(EAGAIN),  \"need more input\"          },\n    { NV_ENC_ERR_ENCODER_BUSY,             AVERROR(EAGAIN),  \"encoder busy\"             },\n    { NV_ENC_ERR_EVENT_NOT_REGISTERD,      AVERROR(EBADF),   \"event not registered\"     },\n    { NV_ENC_ERR_GENERIC,                  AVERROR_UNKNOWN,  \"generic error\"            },\n    { NV_ENC_ERR_INCOMPATIBLE_CLIENT_KEY,  AVERROR(EINVAL),  \"incompatible client key\"  },\n    { NV_ENC_ERR_UNIMPLEMENTED,            AVERROR(ENOSYS),  \"unimplemented\"            },\n    { NV_ENC_ERR_RESOURCE_REGISTER_FAILED, AVERROR(EIO),     \"resource register failed\" },\n    { NV_ENC_ERR_RESOURCE_NOT_REGISTERED,  AVERROR(EBADF),   \"resource not registered\"  },\n    { NV_ENC_ERR_RESOURCE_NOT_MAPPED,      AVERROR(EBADF),   \"resource not mapped\"      },\n};\n\nstatic int nvenc_map_error(NVENCSTATUS err, const char **desc)\n{\n    int i;\n    for (i = 0; i < FF_ARRAY_ELEMS(nvenc_errors); i++) {\n        if (nvenc_errors[i].nverr == err) {\n            if (desc)\n                *desc = nvenc_errors[i].desc;\n            return nvenc_errors[i].averr;\n        }\n    }\n    if (desc)\n        *desc = \"unknown error\";\n    return AVERROR_UNKNOWN;\n}\n\nstatic int nvenc_print_error(void *log_ctx, NVENCSTATUS err,\n                                     const char *error_string)\n{\n    const char *desc;\n    int ret;\n    ret = nvenc_map_error(err, &desc);\n    av_log(log_ctx, AV_LOG_ERROR, \"%s: %s (%d)\\n\", error_string, desc, err);\n    return ret;\n}\n\nstatic av_cold int nvenc_load_libraries(AVCodecContext *avctx)\n{\n    NvencContext *ctx = avctx->priv_data;\n    NvencDynLoadFunctions *dl_fn = &ctx->nvenc_dload_funcs;\n    PNVENCODEAPIGETMAXSUPPORTEDVERSION nvenc_get_max_ver;\n    PNVENCODEAPICREATEINSTANCE nvenc_create_instance;\n    NVENCSTATUS err;\n    uint32_t nvenc_max_ver;\n\n#if CONFIG_CUDA\n    dl_fn->cu_init                      = cuInit;\n    dl_fn->cu_device_get_count          = cuDeviceGetCount;\n    dl_fn->cu_device_get                = cuDeviceGet;\n    dl_fn->cu_device_get_name           = cuDeviceGetName;\n    dl_fn->cu_device_compute_capability = cuDeviceComputeCapability;\n    dl_fn->cu_ctx_create                = cuCtxCreate_v2;\n    dl_fn->cu_ctx_pop_current           = cuCtxPopCurrent_v2;\n    dl_fn->cu_ctx_destroy               = cuCtxDestroy_v2;\n#else\n    LOAD_LIBRARY(dl_fn->cuda, CUDA_LIBNAME);\n\n    LOAD_SYMBOL(dl_fn->cu_init, dl_fn->cuda, \"cuInit\");\n    LOAD_SYMBOL(dl_fn->cu_device_get_count, dl_fn->cuda, \"cuDeviceGetCount\");\n    LOAD_SYMBOL(dl_fn->cu_device_get, dl_fn->cuda, \"cuDeviceGet\");\n    LOAD_SYMBOL(dl_fn->cu_device_get_name, dl_fn->cuda, \"cuDeviceGetName\");\n    LOAD_SYMBOL(dl_fn->cu_device_compute_capability, dl_fn->cuda,\n                \"cuDeviceComputeCapability\");\n    LOAD_SYMBOL(dl_fn->cu_ctx_create, dl_fn->cuda, \"cuCtxCreate_v2\");\n    LOAD_SYMBOL(dl_fn->cu_ctx_pop_current, dl_fn->cuda, \"cuCtxPopCurrent_v2\");\n    LOAD_SYMBOL(dl_fn->cu_ctx_destroy, dl_fn->cuda, \"cuCtxDestroy_v2\");\n#endif\n\n    LOAD_LIBRARY(dl_fn->nvenc, NVENC_LIBNAME);\n\n    LOAD_SYMBOL(nvenc_get_max_ver, dl_fn->nvenc,\n                \"NvEncodeAPIGetMaxSupportedVersion\");\n    LOAD_SYMBOL(nvenc_create_instance, dl_fn->nvenc,\n                \"NvEncodeAPICreateInstance\");\n\n    err = nvenc_get_max_ver(&nvenc_max_ver);\n    if (err != NV_ENC_SUCCESS)\n        return nvenc_print_error(avctx, err, \"Failed to query nvenc max version\");\n\n    av_log(avctx, AV_LOG_VERBOSE, \"Loaded Nvenc version %d.%d\\n\", nvenc_max_ver >> 4, nvenc_max_ver & 0xf);\n\n    if ((NVENCAPI_MAJOR_VERSION << 4 | NVENCAPI_MINOR_VERSION) > nvenc_max_ver) {\n        av_log(avctx, AV_LOG_ERROR, \"Driver does not support the required nvenc API version. \"\n               \"Required: %d.%d Found: %d.%d\\n\",\n               NVENCAPI_MAJOR_VERSION, NVENCAPI_MINOR_VERSION,\n               nvenc_max_ver >> 4, nvenc_max_ver & 0xf);\n        return AVERROR(ENOSYS);\n    }\n\n    dl_fn->nvenc_funcs.version = NV_ENCODE_API_FUNCTION_LIST_VER;\n\n    err = nvenc_create_instance(&dl_fn->nvenc_funcs);\n    if (err != NV_ENC_SUCCESS)\n        return nvenc_print_error(avctx, err, \"Failed to create nvenc instance\");\n\n    av_log(avctx, AV_LOG_VERBOSE, \"Nvenc initialized successfully\\n\");\n\n    return 0;\n}\n\nstatic av_cold int nvenc_open_session(AVCodecContext *avctx)\n{\n    NV_ENC_OPEN_ENCODE_SESSION_EX_PARAMS params = { 0 };\n    NvencContext *ctx = avctx->priv_data;\n    NV_ENCODE_API_FUNCTION_LIST *p_nvenc = &ctx->nvenc_dload_funcs.nvenc_funcs;\n    NVENCSTATUS ret;\n\n    params.version    = NV_ENC_OPEN_ENCODE_SESSION_EX_PARAMS_VER;\n    params.apiVersion = NVENCAPI_VERSION;\n    params.device     = ctx->cu_context;\n    params.deviceType = NV_ENC_DEVICE_TYPE_CUDA;\n\n    ret = p_nvenc->nvEncOpenEncodeSessionEx(&params, &ctx->nvencoder);\n    if (ret != NV_ENC_SUCCESS) {\n        ctx->nvencoder = NULL;\n        return nvenc_print_error(avctx, ret, \"OpenEncodeSessionEx failed\");\n    }\n\n    return 0;\n}\n\nstatic int nvenc_check_codec_support(AVCodecContext *avctx)\n{\n    NvencContext *ctx = avctx->priv_data;\n    NV_ENCODE_API_FUNCTION_LIST *p_nvenc = &ctx->nvenc_dload_funcs.nvenc_funcs;\n    int i, ret, count = 0;\n    GUID *guids = NULL;\n\n    ret = p_nvenc->nvEncGetEncodeGUIDCount(ctx->nvencoder, &count);\n\n    if (ret != NV_ENC_SUCCESS || !count)\n        return AVERROR(ENOSYS);\n\n    guids = av_malloc(count * sizeof(GUID));\n    if (!guids)\n        return AVERROR(ENOMEM);\n\n    ret = p_nvenc->nvEncGetEncodeGUIDs(ctx->nvencoder, guids, count, &count);\n    if (ret != NV_ENC_SUCCESS) {\n        ret = AVERROR(ENOSYS);\n        goto fail;\n    }\n\n    ret = AVERROR(ENOSYS);\n    for (i = 0; i < count; i++) {\n        if (!memcmp(&guids[i], &ctx->init_encode_params.encodeGUID, sizeof(*guids))) {\n            ret = 0;\n            break;\n        }\n    }\n\nfail:\n    av_free(guids);\n\n    return ret;\n}\n\nstatic int nvenc_check_cap(AVCodecContext *avctx, NV_ENC_CAPS cap)\n{\n    NvencContext *ctx = avctx->priv_data;\n    NV_ENCODE_API_FUNCTION_LIST *p_nvenc = &ctx->nvenc_dload_funcs.nvenc_funcs;\n    NV_ENC_CAPS_PARAM params        = { 0 };\n    int ret, val = 0;\n\n    params.version     = NV_ENC_CAPS_PARAM_VER;\n    params.capsToQuery = cap;\n\n    ret = p_nvenc->nvEncGetEncodeCaps(ctx->nvencoder, ctx->init_encode_params.encodeGUID, &params, &val);\n\n    if (ret == NV_ENC_SUCCESS)\n        return val;\n    return 0;\n}\n\nstatic int nvenc_check_capabilities(AVCodecContext *avctx)\n{\n    NvencContext *ctx = avctx->priv_data;\n    int ret;\n\n    ret = nvenc_check_codec_support(avctx);\n    if (ret < 0) {\n        av_log(avctx, AV_LOG_VERBOSE, \"Codec not supported\\n\");\n        return ret;\n    }\n\n    ret = nvenc_check_cap(avctx, NV_ENC_CAPS_SUPPORT_YUV444_ENCODE);\n    if (IS_YUV444(ctx->data_pix_fmt) && ret <= 0) {\n        av_log(avctx, AV_LOG_VERBOSE, \"YUV444P not supported\\n\");\n        return AVERROR(ENOSYS);\n    }\n\n    ret = nvenc_check_cap(avctx, NV_ENC_CAPS_SUPPORT_LOSSLESS_ENCODE);\n    if (ctx->preset >= PRESET_LOSSLESS_DEFAULT && ret <= 0) {\n        av_log(avctx, AV_LOG_VERBOSE, \"Lossless encoding not supported\\n\");\n        return AVERROR(ENOSYS);\n    }\n\n    ret = nvenc_check_cap(avctx, NV_ENC_CAPS_WIDTH_MAX);\n    if (ret < avctx->width) {\n        av_log(avctx, AV_LOG_VERBOSE, \"Width %d exceeds %d\\n\",\n               avctx->width, ret);\n        return AVERROR(ENOSYS);\n    }\n\n    ret = nvenc_check_cap(avctx, NV_ENC_CAPS_HEIGHT_MAX);\n    if (ret < avctx->height) {\n        av_log(avctx, AV_LOG_VERBOSE, \"Height %d exceeds %d\\n\",\n               avctx->height, ret);\n        return AVERROR(ENOSYS);\n    }\n\n    ret = nvenc_check_cap(avctx, NV_ENC_CAPS_NUM_MAX_BFRAMES);\n    if (ret < avctx->max_b_frames) {\n        av_log(avctx, AV_LOG_VERBOSE, \"Max B-frames %d exceed %d\\n\",\n               avctx->max_b_frames, ret);\n\n        return AVERROR(ENOSYS);\n    }\n\n    ret = nvenc_check_cap(avctx, NV_ENC_CAPS_SUPPORT_FIELD_ENCODING);\n    if (ret < 1 && avctx->flags & AV_CODEC_FLAG_INTERLACED_DCT) {\n        av_log(avctx, AV_LOG_VERBOSE,\n               \"Interlaced encoding is not supported. Supported level: %d\\n\",\n               ret);\n        return AVERROR(ENOSYS);\n    }\n\n    ret = nvenc_check_cap(avctx, NV_ENC_CAPS_SUPPORT_10BIT_ENCODE);\n    if (IS_10BIT(ctx->data_pix_fmt) && ret <= 0) {\n        av_log(avctx, AV_LOG_VERBOSE, \"10 bit encode not supported\\n\");\n        return AVERROR(ENOSYS);\n    }\n\n    ret = nvenc_check_cap(avctx, NV_ENC_CAPS_SUPPORT_LOOKAHEAD);\n    if (ctx->rc_lookahead > 0 && ret <= 0) {\n        av_log(avctx, AV_LOG_VERBOSE, \"RC lookahead not supported\\n\");\n        return AVERROR(ENOSYS);\n    }\n\n    ret = nvenc_check_cap(avctx, NV_ENC_CAPS_SUPPORT_TEMPORAL_AQ);\n    if (ctx->temporal_aq > 0 && ret <= 0) {\n        av_log(avctx, AV_LOG_VERBOSE, \"Temporal AQ not supported\\n\");\n        return AVERROR(ENOSYS);\n    }\n\n    return 0;\n}\n\nstatic av_cold int nvenc_check_device(AVCodecContext *avctx, int idx)\n{\n    NvencContext *ctx = avctx->priv_data;\n    NvencDynLoadFunctions *dl_fn = &ctx->nvenc_dload_funcs;\n    NV_ENCODE_API_FUNCTION_LIST *p_nvenc = &dl_fn->nvenc_funcs;\n    char name[128] = { 0};\n    int major, minor, ret;\n    CUresult cu_res;\n    CUdevice cu_device;\n    CUcontext dummy;\n    int loglevel = AV_LOG_VERBOSE;\n\n    if (ctx->device == LIST_DEVICES)\n        loglevel = AV_LOG_INFO;\n\n    cu_res = dl_fn->cu_device_get(&cu_device, idx);\n    if (cu_res != CUDA_SUCCESS) {\n        av_log(avctx, AV_LOG_ERROR,\n               \"Cannot access the CUDA device %d\\n\",\n               idx);\n        return -1;\n    }\n\n    cu_res = dl_fn->cu_device_get_name(name, sizeof(name), cu_device);\n    if (cu_res != CUDA_SUCCESS)\n        return -1;\n\n    cu_res = dl_fn->cu_device_compute_capability(&major, &minor, cu_device);\n    if (cu_res != CUDA_SUCCESS)\n        return -1;\n\n    av_log(avctx, loglevel, \"[ GPU #%d - < %s > has Compute SM %d.%d ]\\n\", idx, name, major, minor);\n    if (((major << 4) | minor) < NVENC_CAP) {\n        av_log(avctx, loglevel, \"does not support NVENC\\n\");\n        goto fail;\n    }\n\n    cu_res = dl_fn->cu_ctx_create(&ctx->cu_context_internal, 0, cu_device);\n    if (cu_res != CUDA_SUCCESS) {\n        av_log(avctx, AV_LOG_FATAL, \"Failed creating CUDA context for NVENC: 0x%x\\n\", (int)cu_res);\n        goto fail;\n    }\n\n    ctx->cu_context = ctx->cu_context_internal;\n\n    cu_res = dl_fn->cu_ctx_pop_current(&dummy);\n    if (cu_res != CUDA_SUCCESS) {\n        av_log(avctx, AV_LOG_FATAL, \"Failed popping CUDA context: 0x%x\\n\", (int)cu_res);\n        goto fail2;\n    }\n\n    if ((ret = nvenc_open_session(avctx)) < 0)\n        goto fail2;\n\n    if ((ret = nvenc_check_capabilities(avctx)) < 0)\n        goto fail3;\n\n    av_log(avctx, loglevel, \"supports NVENC\\n\");\n\n    dl_fn->nvenc_device_count++;\n\n    if (ctx->device == dl_fn->nvenc_device_count - 1 || ctx->device == ANY_DEVICE)\n        return 0;\n\nfail3:\n    p_nvenc->nvEncDestroyEncoder(ctx->nvencoder);\n    ctx->nvencoder = NULL;\n\nfail2:\n    dl_fn->cu_ctx_destroy(ctx->cu_context_internal);\n    ctx->cu_context_internal = NULL;\n\nfail:\n    return AVERROR(ENOSYS);\n}\n\nstatic av_cold int nvenc_setup_device(AVCodecContext *avctx)\n{\n    NvencContext *ctx = avctx->priv_data;\n    NvencDynLoadFunctions *dl_fn = &ctx->nvenc_dload_funcs;\n\n    switch (avctx->codec->id) {\n    case AV_CODEC_ID_H264:\n        ctx->init_encode_params.encodeGUID = NV_ENC_CODEC_H264_GUID;\n        break;\n    case AV_CODEC_ID_HEVC:\n        ctx->init_encode_params.encodeGUID = NV_ENC_CODEC_HEVC_GUID;\n        break;\n    default:\n        return AVERROR_BUG;\n    }\n\n    if (avctx->pix_fmt == AV_PIX_FMT_CUDA) {\n#if CONFIG_CUDA\n        AVHWFramesContext   *frames_ctx;\n        AVCUDADeviceContext *device_hwctx;\n        int ret;\n\n        if (!avctx->hw_frames_ctx)\n            return AVERROR(EINVAL);\n\n        frames_ctx   = (AVHWFramesContext*)avctx->hw_frames_ctx->data;\n        device_hwctx = frames_ctx->device_ctx->hwctx;\n\n        ctx->cu_context = device_hwctx->cuda_ctx;\n\n        ret = nvenc_open_session(avctx);\n        if (ret < 0)\n            return ret;\n\n        ret = nvenc_check_capabilities(avctx);\n        if (ret < 0) {\n            av_log(avctx, AV_LOG_FATAL, \"Provided device doesn't support required NVENC features\\n\");\n            return ret;\n        }\n#else\n        return AVERROR_BUG;\n#endif\n    } else {\n        int i, nb_devices = 0;\n\n        if ((dl_fn->cu_init(0)) != CUDA_SUCCESS) {\n            av_log(avctx, AV_LOG_ERROR,\n                   \"Cannot init CUDA\\n\");\n            return AVERROR_UNKNOWN;\n        }\n\n        if ((dl_fn->cu_device_get_count(&nb_devices)) != CUDA_SUCCESS) {\n            av_log(avctx, AV_LOG_ERROR,\n                   \"Cannot enumerate the CUDA devices\\n\");\n            return AVERROR_UNKNOWN;\n        }\n\n        if (!nb_devices) {\n            av_log(avctx, AV_LOG_FATAL, \"No CUDA capable devices found\\n\");\n                return AVERROR_EXTERNAL;\n        }\n\n        av_log(avctx, AV_LOG_VERBOSE, \"%d CUDA capable devices found\\n\", nb_devices);\n\n        dl_fn->nvenc_device_count = 0;\n        for (i = 0; i < nb_devices; ++i) {\n            if ((nvenc_check_device(avctx, i)) >= 0 && ctx->device != LIST_DEVICES)\n                return 0;\n        }\n\n        if (ctx->device == LIST_DEVICES)\n            return AVERROR_EXIT;\n\n        if (!dl_fn->nvenc_device_count) {\n            av_log(avctx, AV_LOG_FATAL, \"No NVENC capable devices found\\n\");\n            return AVERROR_EXTERNAL;\n        }\n\n        av_log(avctx, AV_LOG_FATAL, \"Requested GPU %d, but only %d GPUs are available!\\n\", ctx->device, dl_fn->nvenc_device_count);\n        return AVERROR(EINVAL);\n    }\n\n    return 0;\n}\n\ntypedef struct GUIDTuple {\n    const GUID guid;\n    int flags;\n} GUIDTuple;\n\n#define PRESET_ALIAS(alias, name, ...) \\\n    [PRESET_ ## alias] = { NV_ENC_PRESET_ ## name ## _GUID, __VA_ARGS__ }\n\n#define PRESET(name, ...) PRESET_ALIAS(name, name, __VA_ARGS__)\n\nstatic void nvenc_map_preset(NvencContext *ctx)\n{\n    GUIDTuple presets[] = {\n        PRESET(DEFAULT),\n        PRESET(HP),\n        PRESET(HQ),\n        PRESET(BD),\n        PRESET_ALIAS(SLOW,   HQ,    NVENC_TWO_PASSES),\n        PRESET_ALIAS(MEDIUM, HQ,    NVENC_ONE_PASS),\n        PRESET_ALIAS(FAST,   HP,    NVENC_ONE_PASS),\n        PRESET(LOW_LATENCY_DEFAULT, NVENC_LOWLATENCY),\n        PRESET(LOW_LATENCY_HP,      NVENC_LOWLATENCY),\n        PRESET(LOW_LATENCY_HQ,      NVENC_LOWLATENCY),\n        PRESET(LOSSLESS_DEFAULT,    NVENC_LOSSLESS),\n        PRESET(LOSSLESS_HP,         NVENC_LOSSLESS),\n    };\n\n    GUIDTuple *t = &presets[ctx->preset];\n\n    ctx->init_encode_params.presetGUID = t->guid;\n    ctx->flags = t->flags;\n}\n\n#undef PRESET\n#undef PRESET_ALIAS\n\nstatic av_cold void set_constqp(AVCodecContext *avctx)\n{\n    NvencContext *ctx = avctx->priv_data;\n    NV_ENC_RC_PARAMS *rc = &ctx->encode_config.rcParams;\n\n    rc->rateControlMode = NV_ENC_PARAMS_RC_CONSTQP;\n    rc->constQP.qpInterB = avctx->global_quality;\n    rc->constQP.qpInterP = avctx->global_quality;\n    rc->constQP.qpIntra = avctx->global_quality;\n\n    avctx->qmin = -1;\n    avctx->qmax = -1;\n}\n\nstatic av_cold void set_vbr(AVCodecContext *avctx)\n{\n    NvencContext *ctx = avctx->priv_data;\n    NV_ENC_RC_PARAMS *rc = &ctx->encode_config.rcParams;\n    int qp_inter_p;\n\n    if (avctx->qmin >= 0 && avctx->qmax >= 0) {\n        rc->enableMinQP = 1;\n        rc->enableMaxQP = 1;\n\n        rc->minQP.qpInterB = avctx->qmin;\n        rc->minQP.qpInterP = avctx->qmin;\n        rc->minQP.qpIntra = avctx->qmin;\n\n        rc->maxQP.qpInterB = avctx->qmax;\n        rc->maxQP.qpInterP = avctx->qmax;\n        rc->maxQP.qpIntra = avctx->qmax;\n\n        qp_inter_p = (avctx->qmax + 3 * avctx->qmin) / 4; // biased towards Qmin\n    } else if (avctx->qmin >= 0) {\n        rc->enableMinQP = 1;\n\n        rc->minQP.qpInterB = avctx->qmin;\n        rc->minQP.qpInterP = avctx->qmin;\n        rc->minQP.qpIntra = avctx->qmin;\n\n        qp_inter_p = avctx->qmin;\n    } else {\n        qp_inter_p = 26; // default to 26\n    }\n\n    rc->enableInitialRCQP = 1;\n    rc->initialRCQP.qpInterP  = qp_inter_p;\n\n    if (avctx->i_quant_factor != 0.0 && avctx->b_quant_factor != 0.0) {\n        rc->initialRCQP.qpIntra = av_clip(\n            qp_inter_p * fabs(avctx->i_quant_factor) + avctx->i_quant_offset, 0, 51);\n        rc->initialRCQP.qpInterB = av_clip(\n            qp_inter_p * fabs(avctx->b_quant_factor) + avctx->b_quant_offset, 0, 51);\n    } else {\n        rc->initialRCQP.qpIntra = qp_inter_p;\n        rc->initialRCQP.qpInterB = qp_inter_p;\n    }\n}\n\nstatic av_cold void set_lossless(AVCodecContext *avctx)\n{\n    NvencContext *ctx = avctx->priv_data;\n    NV_ENC_RC_PARAMS *rc = &ctx->encode_config.rcParams;\n\n    rc->rateControlMode = NV_ENC_PARAMS_RC_CONSTQP;\n    rc->constQP.qpInterB = 0;\n    rc->constQP.qpInterP = 0;\n    rc->constQP.qpIntra = 0;\n\n    avctx->qmin = -1;\n    avctx->qmax = -1;\n}\n\nstatic void nvenc_override_rate_control(AVCodecContext *avctx)\n{\n    NvencContext *ctx    = avctx->priv_data;\n    NV_ENC_RC_PARAMS *rc = &ctx->encode_config.rcParams;\n\n    switch (ctx->rc) {\n    case NV_ENC_PARAMS_RC_CONSTQP:\n        if (avctx->global_quality <= 0) {\n            av_log(avctx, AV_LOG_WARNING,\n                   \"The constant quality rate-control requires \"\n                   \"the 'global_quality' option set.\\n\");\n            return;\n        }\n        set_constqp(avctx);\n        return;\n    case NV_ENC_PARAMS_RC_2_PASS_VBR:\n    case NV_ENC_PARAMS_RC_VBR:\n        if (avctx->qmin < 0 && avctx->qmax < 0) {\n            av_log(avctx, AV_LOG_WARNING,\n                   \"The variable bitrate rate-control requires \"\n                   \"the 'qmin' and/or 'qmax' option set.\\n\");\n            set_vbr(avctx);\n            return;\n        }\n    case NV_ENC_PARAMS_RC_VBR_MINQP:\n        if (avctx->qmin < 0) {\n            av_log(avctx, AV_LOG_WARNING,\n                   \"The variable bitrate rate-control requires \"\n                   \"the 'qmin' option set.\\n\");\n            set_vbr(avctx);\n            return;\n        }\n        set_vbr(avctx);\n        break;\n    case NV_ENC_PARAMS_RC_CBR:\n    case NV_ENC_PARAMS_RC_2_PASS_QUALITY:\n    case NV_ENC_PARAMS_RC_2_PASS_FRAMESIZE_CAP:\n        break;\n    }\n\n    rc->rateControlMode = ctx->rc;\n}\n\nstatic av_cold void nvenc_setup_rate_control(AVCodecContext *avctx)\n{\n    NvencContext *ctx = avctx->priv_data;\n\n    if (avctx->bit_rate > 0) {\n        ctx->encode_config.rcParams.averageBitRate = avctx->bit_rate;\n    } else if (ctx->encode_config.rcParams.averageBitRate > 0) {\n        ctx->encode_config.rcParams.maxBitRate = ctx->encode_config.rcParams.averageBitRate;\n    }\n\n    if (avctx->rc_max_rate > 0)\n        ctx->encode_config.rcParams.maxBitRate = avctx->rc_max_rate;\n\n    if (ctx->rc < 0) {\n        if (ctx->flags & NVENC_ONE_PASS)\n            ctx->twopass = 0;\n        if (ctx->flags & NVENC_TWO_PASSES)\n            ctx->twopass = 1;\n\n        if (ctx->twopass < 0)\n            ctx->twopass = (ctx->flags & NVENC_LOWLATENCY) != 0;\n\n        if (ctx->cbr) {\n            if (ctx->twopass) {\n                ctx->rc = NV_ENC_PARAMS_RC_2_PASS_QUALITY;\n            } else {\n                ctx->rc = NV_ENC_PARAMS_RC_CBR;\n            }\n        } else if (avctx->global_quality > 0) {\n            ctx->rc = NV_ENC_PARAMS_RC_CONSTQP;\n        } else if (ctx->twopass) {\n            ctx->rc = NV_ENC_PARAMS_RC_2_PASS_VBR;\n        } else if (avctx->qmin >= 0 && avctx->qmax >= 0) {\n            ctx->rc = NV_ENC_PARAMS_RC_VBR_MINQP;\n        }\n    }\n\n    if (ctx->flags & NVENC_LOSSLESS) {\n        set_lossless(avctx);\n    } else if (ctx->rc >= 0) {\n        nvenc_override_rate_control(avctx);\n    } else {\n        ctx->encode_config.rcParams.rateControlMode = NV_ENC_PARAMS_RC_VBR;\n        set_vbr(avctx);\n    }\n\n    if (avctx->rc_buffer_size > 0) {\n        ctx->encode_config.rcParams.vbvBufferSize = avctx->rc_buffer_size;\n    } else if (ctx->encode_config.rcParams.averageBitRate > 0) {\n        ctx->encode_config.rcParams.vbvBufferSize = 2 * ctx->encode_config.rcParams.averageBitRate;\n    }\n\n    if (ctx->aq) {\n        ctx->encode_config.rcParams.enableAQ   = 1;\n        ctx->encode_config.rcParams.aqStrength = ctx->aq_strength;\n        av_log(avctx, AV_LOG_VERBOSE, \"AQ enabled.\\n\");\n    }\n\n    if (ctx->temporal_aq) {\n        ctx->encode_config.rcParams.enableTemporalAQ = 1;\n        av_log(avctx, AV_LOG_VERBOSE, \"Temporal AQ enabled.\\n\");\n    }\n\n    if (ctx->rc_lookahead) {\n        int lkd_bound = FFMIN(ctx->nb_surfaces, ctx->async_depth) -\n                        ctx->encode_config.frameIntervalP - 4;\n\n        if (lkd_bound < 0) {\n            av_log(avctx, AV_LOG_WARNING,\n                   \"Lookahead not enabled. Increase buffer delay (-delay).\\n\");\n        } else {\n            ctx->encode_config.rcParams.enableLookahead = 1;\n            ctx->encode_config.rcParams.lookaheadDepth  = av_clip(ctx->rc_lookahead, 0, lkd_bound);\n            ctx->encode_config.rcParams.disableIadapt   = ctx->no_scenecut;\n            ctx->encode_config.rcParams.disableBadapt   = !ctx->b_adapt;\n            av_log(avctx, AV_LOG_VERBOSE,\n                   \"Lookahead enabled: depth %d, scenecut %s, B-adapt %s.\\n\",\n                   ctx->encode_config.rcParams.lookaheadDepth,\n                   ctx->encode_config.rcParams.disableIadapt ? \"disabled\" : \"enabled\",\n                   ctx->encode_config.rcParams.disableBadapt ? \"disabled\" : \"enabled\");\n        }\n    }\n\n    if (ctx->strict_gop) {\n        ctx->encode_config.rcParams.strictGOPTarget = 1;\n        av_log(avctx, AV_LOG_VERBOSE, \"Strict GOP target enabled.\\n\");\n    }\n\n    if (ctx->nonref_p)\n        ctx->encode_config.rcParams.enableNonRefP = 1;\n\n    if (ctx->zerolatency)\n        ctx->encode_config.rcParams.zeroReorderDelay = 1;\n\n    if (ctx->quality)\n        ctx->encode_config.rcParams.targetQuality = ctx->quality;\n}\n\nstatic av_cold int nvenc_setup_h264_config(AVCodecContext *avctx)\n{\n    NvencContext *ctx                      = avctx->priv_data;\n    NV_ENC_CONFIG *cc                      = &ctx->encode_config;\n    NV_ENC_CONFIG_H264 *h264               = &cc->encodeCodecConfig.h264Config;\n    NV_ENC_CONFIG_H264_VUI_PARAMETERS *vui = &h264->h264VUIParameters;\n\n    vui->colourMatrix = avctx->colorspace;\n    vui->colourPrimaries = avctx->color_primaries;\n    vui->transferCharacteristics = avctx->color_trc;\n    vui->videoFullRangeFlag = (avctx->color_range == AVCOL_RANGE_JPEG\n        || ctx->data_pix_fmt == AV_PIX_FMT_YUVJ420P || ctx->data_pix_fmt == AV_PIX_FMT_YUVJ422P || ctx->data_pix_fmt == AV_PIX_FMT_YUVJ444P);\n\n    vui->colourDescriptionPresentFlag =\n        (avctx->colorspace != 2 || avctx->color_primaries != 2 || avctx->color_trc != 2);\n\n    vui->videoSignalTypePresentFlag =\n        (vui->colourDescriptionPresentFlag\n        || vui->videoFormat != 5\n        || vui->videoFullRangeFlag != 0);\n\n    h264->sliceMode = 3;\n    h264->sliceModeData = 1;\n\n    h264->disableSPSPPS = (avctx->flags & AV_CODEC_FLAG_GLOBAL_HEADER) ? 1 : 0;\n    h264->repeatSPSPPS  = (avctx->flags & AV_CODEC_FLAG_GLOBAL_HEADER) ? 0 : 1;\n    h264->outputAUD     = 1;\n\n    if (avctx->refs >= 0) {\n        /* 0 means \"let the hardware decide\" */\n        h264->maxNumRefFrames = avctx->refs;\n    }\n    if (avctx->gop_size >= 0) {\n        h264->idrPeriod = cc->gopLength;\n    }\n\n    if (IS_CBR(cc->rcParams.rateControlMode)) {\n        h264->outputBufferingPeriodSEI = 1;\n        h264->outputPictureTimingSEI   = 1;\n    }\n\n    if (cc->rcParams.rateControlMode == NV_ENC_PARAMS_RC_2_PASS_QUALITY ||\n        cc->rcParams.rateControlMode == NV_ENC_PARAMS_RC_2_PASS_FRAMESIZE_CAP ||\n        cc->rcParams.rateControlMode == NV_ENC_PARAMS_RC_2_PASS_VBR) {\n        h264->adaptiveTransformMode = NV_ENC_H264_ADAPTIVE_TRANSFORM_ENABLE;\n        h264->fmoMode = NV_ENC_H264_FMO_DISABLE;\n    }\n\n    if (ctx->flags & NVENC_LOSSLESS) {\n        h264->qpPrimeYZeroTransformBypassFlag = 1;\n    } else {\n        switch(ctx->profile) {\n        case NV_ENC_H264_PROFILE_BASELINE:\n            cc->profileGUID = NV_ENC_H264_PROFILE_BASELINE_GUID;\n            avctx->profile = FF_PROFILE_H264_BASELINE;\n            break;\n        case NV_ENC_H264_PROFILE_MAIN:\n            cc->profileGUID = NV_ENC_H264_PROFILE_MAIN_GUID;\n            avctx->profile = FF_PROFILE_H264_MAIN;\n            break;\n        case NV_ENC_H264_PROFILE_HIGH:\n            cc->profileGUID = NV_ENC_H264_PROFILE_HIGH_GUID;\n            avctx->profile = FF_PROFILE_H264_HIGH;\n            break;\n        case NV_ENC_H264_PROFILE_HIGH_444P:\n            cc->profileGUID = NV_ENC_H264_PROFILE_HIGH_444_GUID;\n            avctx->profile = FF_PROFILE_H264_HIGH_444_PREDICTIVE;\n            break;\n        }\n    }\n\n    // force setting profile as high444p if input is AV_PIX_FMT_YUV444P\n    if (ctx->data_pix_fmt == AV_PIX_FMT_YUV444P) {\n        cc->profileGUID = NV_ENC_H264_PROFILE_HIGH_444_GUID;\n        avctx->profile = FF_PROFILE_H264_HIGH_444_PREDICTIVE;\n    }\n\n    h264->chromaFormatIDC = avctx->profile == FF_PROFILE_H264_HIGH_444_PREDICTIVE ? 3 : 1;\n\n    h264->level = ctx->level;\n\n    return 0;\n}\n\nstatic av_cold int nvenc_setup_hevc_config(AVCodecContext *avctx)\n{\n    NvencContext *ctx                      = avctx->priv_data;\n    NV_ENC_CONFIG *cc                      = &ctx->encode_config;\n    NV_ENC_CONFIG_HEVC *hevc               = &cc->encodeCodecConfig.hevcConfig;\n    NV_ENC_CONFIG_HEVC_VUI_PARAMETERS *vui = &hevc->hevcVUIParameters;\n\n    vui->colourMatrix = avctx->colorspace;\n    vui->colourPrimaries = avctx->color_primaries;\n    vui->transferCharacteristics = avctx->color_trc;\n    vui->videoFullRangeFlag = (avctx->color_range == AVCOL_RANGE_JPEG\n        || ctx->data_pix_fmt == AV_PIX_FMT_YUVJ420P || ctx->data_pix_fmt == AV_PIX_FMT_YUVJ422P || ctx->data_pix_fmt == AV_PIX_FMT_YUVJ444P);\n\n    vui->colourDescriptionPresentFlag =\n        (avctx->colorspace != 2 || avctx->color_primaries != 2 || avctx->color_trc != 2);\n\n    vui->videoSignalTypePresentFlag =\n        (vui->colourDescriptionPresentFlag\n        || vui->videoFormat != 5\n        || vui->videoFullRangeFlag != 0);\n\n    hevc->sliceMode = 3;\n    hevc->sliceModeData = 1;\n\n    hevc->disableSPSPPS = (avctx->flags & AV_CODEC_FLAG_GLOBAL_HEADER) ? 1 : 0;\n    hevc->repeatSPSPPS  = (avctx->flags & AV_CODEC_FLAG_GLOBAL_HEADER) ? 0 : 1;\n    hevc->outputAUD     = 1;\n\n    if (avctx->refs >= 0) {\n        /* 0 means \"let the hardware decide\" */\n        hevc->maxNumRefFramesInDPB = avctx->refs;\n    }\n    if (avctx->gop_size >= 0) {\n        hevc->idrPeriod = cc->gopLength;\n    }\n\n    if (IS_CBR(cc->rcParams.rateControlMode)) {\n        hevc->outputBufferingPeriodSEI = 1;\n        hevc->outputPictureTimingSEI   = 1;\n    }\n\n    switch(ctx->profile) {\n    case NV_ENC_HEVC_PROFILE_MAIN:\n        cc->profileGUID = NV_ENC_HEVC_PROFILE_MAIN_GUID;\n        avctx->profile = FF_PROFILE_HEVC_MAIN;\n        break;\n    case NV_ENC_HEVC_PROFILE_MAIN_10:\n        cc->profileGUID = NV_ENC_HEVC_PROFILE_MAIN10_GUID;\n        avctx->profile = FF_PROFILE_HEVC_MAIN_10;\n        break;\n    case NV_ENC_HEVC_PROFILE_REXT:\n        cc->profileGUID = NV_ENC_HEVC_PROFILE_FREXT_GUID;\n        avctx->profile = FF_PROFILE_HEVC_REXT;\n        break;\n    }\n\n    // force setting profile as main10 if input is 10 bit\n    if (IS_10BIT(ctx->data_pix_fmt)) {\n        cc->profileGUID = NV_ENC_HEVC_PROFILE_MAIN10_GUID;\n        avctx->profile = FF_PROFILE_HEVC_MAIN_10;\n    }\n\n    // force setting profile as rext if input is yuv444\n    if (IS_YUV444(ctx->data_pix_fmt)) {\n        cc->profileGUID = NV_ENC_HEVC_PROFILE_FREXT_GUID;\n        avctx->profile = FF_PROFILE_HEVC_REXT;\n    }\n\n    hevc->chromaFormatIDC = IS_YUV444(ctx->data_pix_fmt) ? 3 : 1;\n\n    hevc->pixelBitDepthMinus8 = IS_10BIT(ctx->data_pix_fmt) ? 2 : 0;\n\n    hevc->level = ctx->level;\n\n    hevc->tier = ctx->tier;\n\n    return 0;\n}\n\nstatic av_cold int nvenc_setup_codec_config(AVCodecContext *avctx)\n{\n    switch (avctx->codec->id) {\n    case AV_CODEC_ID_H264:\n        return nvenc_setup_h264_config(avctx);\n    case AV_CODEC_ID_HEVC:\n        return nvenc_setup_hevc_config(avctx);\n    /* Earlier switch/case will return if unknown codec is passed. */\n    }\n\n    return 0;\n}\n\nstatic av_cold int nvenc_setup_encoder(AVCodecContext *avctx)\n{\n    NvencContext *ctx = avctx->priv_data;\n    NvencDynLoadFunctions *dl_fn = &ctx->nvenc_dload_funcs;\n    NV_ENCODE_API_FUNCTION_LIST *p_nvenc = &dl_fn->nvenc_funcs;\n\n    NV_ENC_PRESET_CONFIG preset_config = { 0 };\n    NVENCSTATUS nv_status = NV_ENC_SUCCESS;\n    AVCPBProperties *cpb_props;\n    int res = 0;\n    int dw, dh;\n\n    ctx->encode_config.version = NV_ENC_CONFIG_VER;\n    ctx->init_encode_params.version = NV_ENC_INITIALIZE_PARAMS_VER;\n\n    ctx->init_encode_params.encodeHeight = avctx->height;\n    ctx->init_encode_params.encodeWidth = avctx->width;\n\n    ctx->init_encode_params.encodeConfig = &ctx->encode_config;\n\n    nvenc_map_preset(ctx);\n\n    preset_config.version = NV_ENC_PRESET_CONFIG_VER;\n    preset_config.presetCfg.version = NV_ENC_CONFIG_VER;\n\n    nv_status = p_nvenc->nvEncGetEncodePresetConfig(ctx->nvencoder,\n                                                    ctx->init_encode_params.encodeGUID,\n                                                    ctx->init_encode_params.presetGUID,\n                                                    &preset_config);\n    if (nv_status != NV_ENC_SUCCESS)\n        return nvenc_print_error(avctx, nv_status, \"Cannot get the preset configuration\");\n\n    memcpy(&ctx->encode_config, &preset_config.presetCfg, sizeof(ctx->encode_config));\n\n    ctx->encode_config.version = NV_ENC_CONFIG_VER;\n\n    if (avctx->sample_aspect_ratio.num && avctx->sample_aspect_ratio.den &&\n        (avctx->sample_aspect_ratio.num != 1 || avctx->sample_aspect_ratio.num != 1)) {\n        av_reduce(&dw, &dh,\n                  avctx->width * avctx->sample_aspect_ratio.num,\n                  avctx->height * avctx->sample_aspect_ratio.den,\n                  1024 * 1024);\n        ctx->init_encode_params.darHeight = dh;\n        ctx->init_encode_params.darWidth = dw;\n    } else {\n        ctx->init_encode_params.darHeight = avctx->height;\n        ctx->init_encode_params.darWidth = avctx->width;\n    }\n\n    // De-compensate for hardware, dubiously, trying to compensate for\n    // playback at 704 pixel width.\n    if (avctx->width == 720 &&\n        (avctx->height == 480 || avctx->height == 576)) {\n        av_reduce(&dw, &dh,\n                  ctx->init_encode_params.darWidth * 44,\n                  ctx->init_encode_params.darHeight * 45,\n                  1024 * 1024);\n        ctx->init_encode_params.darHeight = dh;\n        ctx->init_encode_params.darWidth = dw;\n    }\n\n    ctx->init_encode_params.frameRateNum = avctx->time_base.den;\n    ctx->init_encode_params.frameRateDen = avctx->time_base.num * avctx->ticks_per_frame;\n\n    ctx->init_encode_params.enableEncodeAsync = 0;\n    ctx->init_encode_params.enablePTD = 1;\n\n    if (avctx->gop_size > 0) {\n        if (avctx->max_b_frames >= 0) {\n            /* 0 is intra-only, 1 is I/P only, 2 is one B-Frame, 3 two B-frames, and so on. */\n            ctx->encode_config.frameIntervalP = avctx->max_b_frames + 1;\n        }\n\n        ctx->encode_config.gopLength = avctx->gop_size;\n    } else if (avctx->gop_size == 0) {\n        ctx->encode_config.frameIntervalP = 0;\n        ctx->encode_config.gopLength = 1;\n    }\n\n    ctx->initial_pts[0] = AV_NOPTS_VALUE;\n    ctx->initial_pts[1] = AV_NOPTS_VALUE;\n\n    nvenc_setup_rate_control(avctx);\n\n    if (avctx->flags & AV_CODEC_FLAG_INTERLACED_DCT) {\n        ctx->encode_config.frameFieldMode = NV_ENC_PARAMS_FRAME_FIELD_MODE_FIELD;\n    } else {\n        ctx->encode_config.frameFieldMode = NV_ENC_PARAMS_FRAME_FIELD_MODE_FRAME;\n    }\n\n    res = nvenc_setup_codec_config(avctx);\n    if (res)\n        return res;\n\n    nv_status = p_nvenc->nvEncInitializeEncoder(ctx->nvencoder, &ctx->init_encode_params);\n    if (nv_status != NV_ENC_SUCCESS) {\n        return nvenc_print_error(avctx, nv_status, \"InitializeEncoder failed\");\n    }\n\n    if (ctx->encode_config.frameIntervalP > 1)\n        avctx->has_b_frames = 2;\n\n    if (ctx->encode_config.rcParams.averageBitRate > 0)\n        avctx->bit_rate = ctx->encode_config.rcParams.averageBitRate;\n\n    cpb_props = ff_add_cpb_side_data(avctx);\n    if (!cpb_props)\n        return AVERROR(ENOMEM);\n    cpb_props->max_bitrate = ctx->encode_config.rcParams.maxBitRate;\n    cpb_props->avg_bitrate = avctx->bit_rate;\n    cpb_props->buffer_size = ctx->encode_config.rcParams.vbvBufferSize;\n\n    return 0;\n}\n\nstatic av_cold int nvenc_alloc_surface(AVCodecContext *avctx, int idx)\n{\n    NvencContext *ctx = avctx->priv_data;\n    NvencDynLoadFunctions *dl_fn = &ctx->nvenc_dload_funcs;\n    NV_ENCODE_API_FUNCTION_LIST *p_nvenc = &dl_fn->nvenc_funcs;\n\n    NVENCSTATUS nv_status;\n    NV_ENC_CREATE_BITSTREAM_BUFFER allocOut = { 0 };\n    allocOut.version = NV_ENC_CREATE_BITSTREAM_BUFFER_VER;\n\n    switch (ctx->data_pix_fmt) {\n    case AV_PIX_FMT_YUV420P:\n        ctx->surfaces[idx].format = NV_ENC_BUFFER_FORMAT_YV12_PL;\n        break;\n\n    case AV_PIX_FMT_NV12:\n        ctx->surfaces[idx].format = NV_ENC_BUFFER_FORMAT_NV12_PL;\n        break;\n\n    case AV_PIX_FMT_P010:\n        ctx->surfaces[idx].format = NV_ENC_BUFFER_FORMAT_YUV420_10BIT;\n        break;\n\n    case AV_PIX_FMT_YUV444P:\n        ctx->surfaces[idx].format = NV_ENC_BUFFER_FORMAT_YUV444_PL;\n        break;\n\n    case AV_PIX_FMT_YUV444P16:\n        ctx->surfaces[idx].format = NV_ENC_BUFFER_FORMAT_YUV444_10BIT;\n        break;\n\n    case AV_PIX_FMT_0RGB32:\n        ctx->surfaces[idx].format = NV_ENC_BUFFER_FORMAT_ARGB;\n        break;\n\n    case AV_PIX_FMT_0BGR32:\n        ctx->surfaces[idx].format = NV_ENC_BUFFER_FORMAT_ABGR;\n        break;\n\n    default:\n        av_log(avctx, AV_LOG_FATAL, \"Invalid input pixel format\\n\");\n        return AVERROR(EINVAL);\n    }\n\n    if (avctx->pix_fmt == AV_PIX_FMT_CUDA) {\n        ctx->surfaces[idx].in_ref = av_frame_alloc();\n        if (!ctx->surfaces[idx].in_ref)\n            return AVERROR(ENOMEM);\n    } else {\n        NV_ENC_CREATE_INPUT_BUFFER allocSurf = { 0 };\n        allocSurf.version = NV_ENC_CREATE_INPUT_BUFFER_VER;\n        allocSurf.width = (avctx->width + 31) & ~31;\n        allocSurf.height = (avctx->height + 31) & ~31;\n        allocSurf.memoryHeap = NV_ENC_MEMORY_HEAP_SYSMEM_CACHED;\n        allocSurf.bufferFmt = ctx->surfaces[idx].format;\n\n        nv_status = p_nvenc->nvEncCreateInputBuffer(ctx->nvencoder, &allocSurf);\n        if (nv_status != NV_ENC_SUCCESS) {\n            return nvenc_print_error(avctx, nv_status, \"CreateInputBuffer failed\");\n        }\n\n        ctx->surfaces[idx].input_surface = allocSurf.inputBuffer;\n        ctx->surfaces[idx].width = allocSurf.width;\n        ctx->surfaces[idx].height = allocSurf.height;\n    }\n\n    ctx->surfaces[idx].lockCount = 0;\n\n    /* 1MB is large enough to hold most output frames.\n     * NVENC increases this automaticaly if it is not enough. */\n    allocOut.size = 1024 * 1024;\n\n    allocOut.memoryHeap = NV_ENC_MEMORY_HEAP_SYSMEM_CACHED;\n\n    nv_status = p_nvenc->nvEncCreateBitstreamBuffer(ctx->nvencoder, &allocOut);\n    if (nv_status != NV_ENC_SUCCESS) {\n        int err = nvenc_print_error(avctx, nv_status, \"CreateBitstreamBuffer failed\");\n        if (avctx->pix_fmt != AV_PIX_FMT_CUDA)\n            p_nvenc->nvEncDestroyInputBuffer(ctx->nvencoder, ctx->surfaces[idx].input_surface);\n        av_frame_free(&ctx->surfaces[idx].in_ref);\n        return err;\n    }\n\n    ctx->surfaces[idx].output_surface = allocOut.bitstreamBuffer;\n    ctx->surfaces[idx].size = allocOut.size;\n\n    return 0;\n}\n\nstatic av_cold int nvenc_setup_surfaces(AVCodecContext *avctx)\n{\n    NvencContext *ctx = avctx->priv_data;\n    int i, res;\n    int num_mbs = ((avctx->width + 15) >> 4) * ((avctx->height + 15) >> 4);\n    ctx->nb_surfaces = FFMAX((num_mbs >= 8160) ? 32 : 48,\n                             ctx->nb_surfaces);\n    ctx->async_depth = FFMIN(ctx->async_depth, ctx->nb_surfaces - 1);\n\n\n    ctx->surfaces = av_mallocz_array(ctx->nb_surfaces, sizeof(*ctx->surfaces));\n    if (!ctx->surfaces)\n        return AVERROR(ENOMEM);\n\n    ctx->timestamp_list = av_fifo_alloc(ctx->nb_surfaces * sizeof(int64_t));\n    if (!ctx->timestamp_list)\n        return AVERROR(ENOMEM);\n    ctx->output_surface_queue = av_fifo_alloc(ctx->nb_surfaces * sizeof(NvencSurface*));\n    if (!ctx->output_surface_queue)\n        return AVERROR(ENOMEM);\n    ctx->output_surface_ready_queue = av_fifo_alloc(ctx->nb_surfaces * sizeof(NvencSurface*));\n    if (!ctx->output_surface_ready_queue)\n        return AVERROR(ENOMEM);\n\n    for (i = 0; i < ctx->nb_surfaces; i++) {\n        if ((res = nvenc_alloc_surface(avctx, i)) < 0)\n            return res;\n    }\n\n    return 0;\n}\n\nstatic av_cold int nvenc_setup_extradata(AVCodecContext *avctx)\n{\n    NvencContext *ctx = avctx->priv_data;\n    NvencDynLoadFunctions *dl_fn = &ctx->nvenc_dload_funcs;\n    NV_ENCODE_API_FUNCTION_LIST *p_nvenc = &dl_fn->nvenc_funcs;\n\n    NVENCSTATUS nv_status;\n    uint32_t outSize = 0;\n    char tmpHeader[256];\n    NV_ENC_SEQUENCE_PARAM_PAYLOAD payload = { 0 };\n    payload.version = NV_ENC_SEQUENCE_PARAM_PAYLOAD_VER;\n\n    payload.spsppsBuffer = tmpHeader;\n    payload.inBufferSize = sizeof(tmpHeader);\n    payload.outSPSPPSPayloadSize = &outSize;\n\n    nv_status = p_nvenc->nvEncGetSequenceParams(ctx->nvencoder, &payload);\n    if (nv_status != NV_ENC_SUCCESS) {\n        return nvenc_print_error(avctx, nv_status, \"GetSequenceParams failed\");\n    }\n\n    avctx->extradata_size = outSize;\n    avctx->extradata = av_mallocz(outSize + AV_INPUT_BUFFER_PADDING_SIZE);\n\n    if (!avctx->extradata) {\n        return AVERROR(ENOMEM);\n    }\n\n    memcpy(avctx->extradata, tmpHeader, outSize);\n\n    return 0;\n}\n\nav_cold int ff_nvenc_encode_close(AVCodecContext *avctx)\n{\n    NvencContext *ctx               = avctx->priv_data;\n    NvencDynLoadFunctions *dl_fn = &ctx->nvenc_dload_funcs;\n    NV_ENCODE_API_FUNCTION_LIST *p_nvenc = &dl_fn->nvenc_funcs;\n    int i;\n\n    /* the encoder has to be flushed before it can be closed */\n    if (ctx->nvencoder) {\n        NV_ENC_PIC_PARAMS params        = { .version        = NV_ENC_PIC_PARAMS_VER,\n                                            .encodePicFlags = NV_ENC_PIC_FLAG_EOS };\n\n        p_nvenc->nvEncEncodePicture(ctx->nvencoder, &params);\n    }\n\n    av_fifo_freep(&ctx->timestamp_list);\n    av_fifo_freep(&ctx->output_surface_ready_queue);\n    av_fifo_freep(&ctx->output_surface_queue);\n\n    if (ctx->surfaces && avctx->pix_fmt == AV_PIX_FMT_CUDA) {\n        for (i = 0; i < ctx->nb_surfaces; ++i) {\n            if (ctx->surfaces[i].input_surface) {\n                 p_nvenc->nvEncUnmapInputResource(ctx->nvencoder, ctx->surfaces[i].in_map.mappedResource);\n            }\n        }\n        for (i = 0; i < ctx->nb_registered_frames; i++) {\n            if (ctx->registered_frames[i].regptr)\n                p_nvenc->nvEncUnregisterResource(ctx->nvencoder, ctx->registered_frames[i].regptr);\n        }\n        ctx->nb_registered_frames = 0;\n    }\n\n    if (ctx->surfaces) {\n        for (i = 0; i < ctx->nb_surfaces; ++i) {\n            if (avctx->pix_fmt != AV_PIX_FMT_CUDA)\n                p_nvenc->nvEncDestroyInputBuffer(ctx->nvencoder, ctx->surfaces[i].input_surface);\n            av_frame_free(&ctx->surfaces[i].in_ref);\n            p_nvenc->nvEncDestroyBitstreamBuffer(ctx->nvencoder, ctx->surfaces[i].output_surface);\n        }\n    }\n    av_freep(&ctx->surfaces);\n    ctx->nb_surfaces = 0;\n\n    if (ctx->nvencoder)\n        p_nvenc->nvEncDestroyEncoder(ctx->nvencoder);\n    ctx->nvencoder = NULL;\n\n    if (ctx->cu_context_internal)\n        dl_fn->cu_ctx_destroy(ctx->cu_context_internal);\n    ctx->cu_context = ctx->cu_context_internal = NULL;\n\n    if (dl_fn->nvenc)\n        dlclose(dl_fn->nvenc);\n    dl_fn->nvenc = NULL;\n\n    dl_fn->nvenc_device_count = 0;\n\n#if !CONFIG_CUDA\n    if (dl_fn->cuda)\n        dlclose(dl_fn->cuda);\n    dl_fn->cuda = NULL;\n#endif\n\n    dl_fn->cu_init = NULL;\n    dl_fn->cu_device_get_count = NULL;\n    dl_fn->cu_device_get = NULL;\n    dl_fn->cu_device_get_name = NULL;\n    dl_fn->cu_device_compute_capability = NULL;\n    dl_fn->cu_ctx_create = NULL;\n    dl_fn->cu_ctx_pop_current = NULL;\n    dl_fn->cu_ctx_destroy = NULL;\n\n    av_log(avctx, AV_LOG_VERBOSE, \"Nvenc unloaded\\n\");\n\n    return 0;\n}\n\nav_cold int ff_nvenc_encode_init(AVCodecContext *avctx)\n{\n    NvencContext *ctx = avctx->priv_data;\n    int ret;\n\n    if (avctx->pix_fmt == AV_PIX_FMT_CUDA) {\n        AVHWFramesContext *frames_ctx;\n        if (!avctx->hw_frames_ctx) {\n            av_log(avctx, AV_LOG_ERROR,\n                   \"hw_frames_ctx must be set when using GPU frames as input\\n\");\n            return AVERROR(EINVAL);\n        }\n        frames_ctx = (AVHWFramesContext*)avctx->hw_frames_ctx->data;\n        ctx->data_pix_fmt = frames_ctx->sw_format;\n    } else {\n        ctx->data_pix_fmt = avctx->pix_fmt;\n    }\n\n    if ((ret = nvenc_load_libraries(avctx)) < 0)\n        return ret;\n\n    if ((ret = nvenc_setup_device(avctx)) < 0)\n        return ret;\n\n    if ((ret = nvenc_setup_encoder(avctx)) < 0)\n        return ret;\n\n    if ((ret = nvenc_setup_surfaces(avctx)) < 0)\n        return ret;\n\n    if (avctx->flags & AV_CODEC_FLAG_GLOBAL_HEADER) {\n        if ((ret = nvenc_setup_extradata(avctx)) < 0)\n            return ret;\n    }\n\n    return 0;\n}\n\nstatic NvencSurface *get_free_frame(NvencContext *ctx)\n{\n    int i;\n\n    for (i = 0; i < ctx->nb_surfaces; ++i) {\n        if (!ctx->surfaces[i].lockCount) {\n            ctx->surfaces[i].lockCount = 1;\n            return &ctx->surfaces[i];\n        }\n    }\n\n    return NULL;\n}\n\nstatic int nvenc_copy_frame(AVCodecContext *avctx, NvencSurface *nv_surface,\n            NV_ENC_LOCK_INPUT_BUFFER *lock_buffer_params, const AVFrame *frame)\n{\n    int dst_linesize[4] = {\n        lock_buffer_params->pitch,\n        lock_buffer_params->pitch,\n        lock_buffer_params->pitch,\n        lock_buffer_params->pitch\n    };\n    uint8_t *dst_data[4];\n    int ret;\n\n    if (frame->format == AV_PIX_FMT_YUV420P)\n        dst_linesize[1] = dst_linesize[2] >>= 1;\n\n    ret = av_image_fill_pointers(dst_data, frame->format, nv_surface->height,\n                                 lock_buffer_params->bufferDataPtr, dst_linesize);\n    if (ret < 0)\n        return ret;\n\n    if (frame->format == AV_PIX_FMT_YUV420P)\n        FFSWAP(uint8_t*, dst_data[1], dst_data[2]);\n\n    av_image_copy(dst_data, dst_linesize,\n                  (const uint8_t**)frame->data, frame->linesize, frame->format,\n                  avctx->width, avctx->height);\n\n    return 0;\n}\n\nstatic int nvenc_find_free_reg_resource(AVCodecContext *avctx)\n{\n    NvencContext *ctx = avctx->priv_data;\n    NvencDynLoadFunctions *dl_fn = &ctx->nvenc_dload_funcs;\n    NV_ENCODE_API_FUNCTION_LIST *p_nvenc = &dl_fn->nvenc_funcs;\n\n    int i;\n\n    if (ctx->nb_registered_frames == FF_ARRAY_ELEMS(ctx->registered_frames)) {\n        for (i = 0; i < ctx->nb_registered_frames; i++) {\n            if (!ctx->registered_frames[i].mapped) {\n                if (ctx->registered_frames[i].regptr) {\n                    p_nvenc->nvEncUnregisterResource(ctx->nvencoder,\n                                                ctx->registered_frames[i].regptr);\n                    ctx->registered_frames[i].regptr = NULL;\n                }\n                return i;\n            }\n        }\n    } else {\n        return ctx->nb_registered_frames++;\n    }\n\n    av_log(avctx, AV_LOG_ERROR, \"Too many registered CUDA frames\\n\");\n    return AVERROR(ENOMEM);\n}\n\nstatic int nvenc_register_frame(AVCodecContext *avctx, const AVFrame *frame)\n{\n    NvencContext *ctx = avctx->priv_data;\n    NvencDynLoadFunctions *dl_fn = &ctx->nvenc_dload_funcs;\n    NV_ENCODE_API_FUNCTION_LIST *p_nvenc = &dl_fn->nvenc_funcs;\n\n    AVHWFramesContext *frames_ctx = (AVHWFramesContext*)avctx->hw_frames_ctx->data;\n    NV_ENC_REGISTER_RESOURCE reg;\n    int i, idx, ret;\n\n    for (i = 0; i < ctx->nb_registered_frames; i++) {\n        if (ctx->registered_frames[i].ptr == (CUdeviceptr)frame->data[0])\n            return i;\n    }\n\n    idx = nvenc_find_free_reg_resource(avctx);\n    if (idx < 0)\n        return idx;\n\n    reg.version            = NV_ENC_REGISTER_RESOURCE_VER;\n    reg.resourceType       = NV_ENC_INPUT_RESOURCE_TYPE_CUDADEVICEPTR;\n    reg.width              = frames_ctx->width;\n    reg.height             = frames_ctx->height;\n    reg.bufferFormat       = ctx->surfaces[0].format;\n    reg.pitch              = frame->linesize[0];\n    reg.resourceToRegister = frame->data[0];\n\n    ret = p_nvenc->nvEncRegisterResource(ctx->nvencoder, &reg);\n    if (ret != NV_ENC_SUCCESS) {\n        nvenc_print_error(avctx, ret, \"Error registering an input resource\");\n        return AVERROR_UNKNOWN;\n    }\n\n    ctx->registered_frames[idx].ptr    = (CUdeviceptr)frame->data[0];\n    ctx->registered_frames[idx].regptr = reg.registeredResource;\n    return idx;\n}\n\nstatic int nvenc_upload_frame(AVCodecContext *avctx, const AVFrame *frame,\n                                      NvencSurface *nvenc_frame)\n{\n    NvencContext *ctx = avctx->priv_data;\n    NvencDynLoadFunctions *dl_fn = &ctx->nvenc_dload_funcs;\n    NV_ENCODE_API_FUNCTION_LIST *p_nvenc = &dl_fn->nvenc_funcs;\n\n    int res;\n    NVENCSTATUS nv_status;\n\n    if (avctx->pix_fmt == AV_PIX_FMT_CUDA) {\n        int reg_idx = nvenc_register_frame(avctx, frame);\n        if (reg_idx < 0) {\n            av_log(avctx, AV_LOG_ERROR, \"Could not register an input CUDA frame\\n\");\n            return reg_idx;\n        }\n\n        res = av_frame_ref(nvenc_frame->in_ref, frame);\n        if (res < 0)\n            return res;\n\n        nvenc_frame->in_map.version = NV_ENC_MAP_INPUT_RESOURCE_VER;\n        nvenc_frame->in_map.registeredResource = ctx->registered_frames[reg_idx].regptr;\n        nv_status = p_nvenc->nvEncMapInputResource(ctx->nvencoder, &nvenc_frame->in_map);\n        if (nv_status != NV_ENC_SUCCESS) {\n            av_frame_unref(nvenc_frame->in_ref);\n            return nvenc_print_error(avctx, nv_status, \"Error mapping an input resource\");\n        }\n\n        ctx->registered_frames[reg_idx].mapped = 1;\n        nvenc_frame->reg_idx                   = reg_idx;\n        nvenc_frame->input_surface             = nvenc_frame->in_map.mappedResource;\n        nvenc_frame->pitch                     = frame->linesize[0];\n        return 0;\n    } else {\n        NV_ENC_LOCK_INPUT_BUFFER lockBufferParams = { 0 };\n\n        lockBufferParams.version = NV_ENC_LOCK_INPUT_BUFFER_VER;\n        lockBufferParams.inputBuffer = nvenc_frame->input_surface;\n\n        nv_status = p_nvenc->nvEncLockInputBuffer(ctx->nvencoder, &lockBufferParams);\n        if (nv_status != NV_ENC_SUCCESS) {\n            return nvenc_print_error(avctx, nv_status, \"Failed locking nvenc input buffer\");\n        }\n\n        nvenc_frame->pitch = lockBufferParams.pitch;\n        res = nvenc_copy_frame(avctx, nvenc_frame, &lockBufferParams, frame);\n\n        nv_status = p_nvenc->nvEncUnlockInputBuffer(ctx->nvencoder, nvenc_frame->input_surface);\n        if (nv_status != NV_ENC_SUCCESS) {\n            return nvenc_print_error(avctx, nv_status, \"Failed unlocking input buffer!\");\n        }\n\n        return res;\n    }\n}\n\nstatic void nvenc_codec_specific_pic_params(AVCodecContext *avctx,\n                                            NV_ENC_PIC_PARAMS *params)\n{\n    NvencContext *ctx = avctx->priv_data;\n\n    switch (avctx->codec->id) {\n    case AV_CODEC_ID_H264:\n        params->codecPicParams.h264PicParams.sliceMode =\n            ctx->encode_config.encodeCodecConfig.h264Config.sliceMode;\n        params->codecPicParams.h264PicParams.sliceModeData =\n            ctx->encode_config.encodeCodecConfig.h264Config.sliceModeData;\n      break;\n    case AV_CODEC_ID_HEVC:\n        params->codecPicParams.hevcPicParams.sliceMode =\n            ctx->encode_config.encodeCodecConfig.hevcConfig.sliceMode;\n        params->codecPicParams.hevcPicParams.sliceModeData =\n            ctx->encode_config.encodeCodecConfig.hevcConfig.sliceModeData;\n        break;\n    }\n}\n\nstatic inline void timestamp_queue_enqueue(AVFifoBuffer* queue, int64_t timestamp)\n{\n    av_fifo_generic_write(queue, &timestamp, sizeof(timestamp), NULL);\n}\n\nstatic inline int64_t timestamp_queue_dequeue(AVFifoBuffer* queue)\n{\n    int64_t timestamp = AV_NOPTS_VALUE;\n    if (av_fifo_size(queue) > 0)\n        av_fifo_generic_read(queue, &timestamp, sizeof(timestamp), NULL);\n\n    return timestamp;\n}\n\nstatic int nvenc_set_timestamp(AVCodecContext *avctx,\n                               NV_ENC_LOCK_BITSTREAM *params,\n                               AVPacket *pkt)\n{\n    NvencContext *ctx = avctx->priv_data;\n\n    pkt->pts = params->outputTimeStamp;\n\n    /* generate the first dts by linearly extrapolating the\n     * first two pts values to the past */\n    if (avctx->max_b_frames > 0 && !ctx->first_packet_output &&\n        ctx->initial_pts[1] != AV_NOPTS_VALUE) {\n        int64_t ts0 = ctx->initial_pts[0], ts1 = ctx->initial_pts[1];\n        int64_t delta;\n\n        if ((ts0 < 0 && ts1 > INT64_MAX + ts0) ||\n            (ts0 > 0 && ts1 < INT64_MIN + ts0))\n            return AVERROR(ERANGE);\n        delta = ts1 - ts0;\n\n        if ((delta < 0 && ts0 > INT64_MAX + delta) ||\n            (delta > 0 && ts0 < INT64_MIN + delta))\n            return AVERROR(ERANGE);\n        pkt->dts = ts0 - delta;\n\n        ctx->first_packet_output = 1;\n        return 0;\n    }\n\n    pkt->dts = timestamp_queue_dequeue(ctx->timestamp_list);\n\n    return 0;\n}\n\nstatic int process_output_surface(AVCodecContext *avctx, AVPacket *pkt, NvencSurface *tmpoutsurf)\n{\n    NvencContext *ctx = avctx->priv_data;\n    NvencDynLoadFunctions *dl_fn = &ctx->nvenc_dload_funcs;\n    NV_ENCODE_API_FUNCTION_LIST *p_nvenc = &dl_fn->nvenc_funcs;\n\n    uint32_t slice_mode_data;\n    uint32_t *slice_offsets = NULL;\n    NV_ENC_LOCK_BITSTREAM lock_params = { 0 };\n    NVENCSTATUS nv_status;\n    int res = 0;\n\n    enum AVPictureType pict_type;\n\n    switch (avctx->codec->id) {\n    case AV_CODEC_ID_H264:\n      slice_mode_data = ctx->encode_config.encodeCodecConfig.h264Config.sliceModeData;\n      break;\n    case AV_CODEC_ID_H265:\n      slice_mode_data = ctx->encode_config.encodeCodecConfig.hevcConfig.sliceModeData;\n      break;\n    default:\n      av_log(avctx, AV_LOG_ERROR, \"Unknown codec name\\n\");\n      res = AVERROR(EINVAL);\n      goto error;\n    }\n    slice_offsets = av_mallocz(slice_mode_data * sizeof(*slice_offsets));\n\n    if (!slice_offsets)\n        goto error;\n\n    lock_params.version = NV_ENC_LOCK_BITSTREAM_VER;\n\n    lock_params.doNotWait = 0;\n    lock_params.outputBitstream = tmpoutsurf->output_surface;\n    lock_params.sliceOffsets = slice_offsets;\n\n    nv_status = p_nvenc->nvEncLockBitstream(ctx->nvencoder, &lock_params);\n    if (nv_status != NV_ENC_SUCCESS) {\n        res = nvenc_print_error(avctx, nv_status, \"Failed locking bitstream buffer\");\n        goto error;\n    }\n\n    if (res = ff_alloc_packet2(avctx, pkt, lock_params.bitstreamSizeInBytes,0)) {\n        p_nvenc->nvEncUnlockBitstream(ctx->nvencoder, tmpoutsurf->output_surface);\n        goto error;\n    }\n\n    memcpy(pkt->data, lock_params.bitstreamBufferPtr, lock_params.bitstreamSizeInBytes);\n\n    nv_status = p_nvenc->nvEncUnlockBitstream(ctx->nvencoder, tmpoutsurf->output_surface);\n    if (nv_status != NV_ENC_SUCCESS)\n        nvenc_print_error(avctx, nv_status, \"Failed unlocking bitstream buffer, expect the gates of mordor to open\");\n\n\n    if (avctx->pix_fmt == AV_PIX_FMT_CUDA) {\n        p_nvenc->nvEncUnmapInputResource(ctx->nvencoder, tmpoutsurf->in_map.mappedResource);\n        av_frame_unref(tmpoutsurf->in_ref);\n        ctx->registered_frames[tmpoutsurf->reg_idx].mapped = 0;\n\n        tmpoutsurf->input_surface = NULL;\n    }\n\n    switch (lock_params.pictureType) {\n    case NV_ENC_PIC_TYPE_IDR:\n        pkt->flags |= AV_PKT_FLAG_KEY;\n    case NV_ENC_PIC_TYPE_I:\n        pict_type = AV_PICTURE_TYPE_I;\n        break;\n    case NV_ENC_PIC_TYPE_P:\n        pict_type = AV_PICTURE_TYPE_P;\n        break;\n    case NV_ENC_PIC_TYPE_B:\n        pict_type = AV_PICTURE_TYPE_B;\n        break;\n    case NV_ENC_PIC_TYPE_BI:\n        pict_type = AV_PICTURE_TYPE_BI;\n        break;\n    default:\n        av_log(avctx, AV_LOG_ERROR, \"Unknown picture type encountered, expect the output to be broken.\\n\");\n        av_log(avctx, AV_LOG_ERROR, \"Please report this error and include as much information on how to reproduce it as possible.\\n\");\n        res = AVERROR_EXTERNAL;\n        goto error;\n    }\n\n#if FF_API_CODED_FRAME\nFF_DISABLE_DEPRECATION_WARNINGS\n    avctx->coded_frame->pict_type = pict_type;\nFF_ENABLE_DEPRECATION_WARNINGS\n#endif\n\n    ff_side_data_set_encoder_stats(pkt,\n        (lock_params.frameAvgQP - 1) * FF_QP2LAMBDA, NULL, 0, pict_type);\n\n    res = nvenc_set_timestamp(avctx, &lock_params, pkt);\n    if (res < 0)\n        goto error2;\n\n    av_free(slice_offsets);\n\n    return 0;\n\nerror:\n    timestamp_queue_dequeue(ctx->timestamp_list);\n\nerror2:\n    av_free(slice_offsets);\n\n    return res;\n}\n\nstatic int output_ready(AVCodecContext *avctx, int flush)\n{\n    NvencContext *ctx = avctx->priv_data;\n    int nb_ready, nb_pending;\n\n    /* when B-frames are enabled, we wait for two initial timestamps to\n     * calculate the first dts */\n    if (!flush && avctx->max_b_frames > 0 &&\n        (ctx->initial_pts[0] == AV_NOPTS_VALUE || ctx->initial_pts[1] == AV_NOPTS_VALUE))\n        return 0;\n\n    nb_ready   = av_fifo_size(ctx->output_surface_ready_queue)   / sizeof(NvencSurface*);\n    nb_pending = av_fifo_size(ctx->output_surface_queue)         / sizeof(NvencSurface*);\n    if (flush)\n        return nb_ready > 0;\n    return (nb_ready > 0) && (nb_ready + nb_pending >= ctx->async_depth);\n}\n\nint ff_nvenc_encode_frame(AVCodecContext *avctx, AVPacket *pkt,\n                          const AVFrame *frame, int *got_packet)\n{\n    NVENCSTATUS nv_status;\n    NvencSurface *tmpoutsurf, *inSurf;\n    int res;\n\n    NvencContext *ctx = avctx->priv_data;\n    NvencDynLoadFunctions *dl_fn = &ctx->nvenc_dload_funcs;\n    NV_ENCODE_API_FUNCTION_LIST *p_nvenc = &dl_fn->nvenc_funcs;\n\n    NV_ENC_PIC_PARAMS pic_params = { 0 };\n    pic_params.version = NV_ENC_PIC_PARAMS_VER;\n\n    if (frame) {\n        inSurf = get_free_frame(ctx);\n        if (!inSurf) {\n            av_log(avctx, AV_LOG_ERROR, \"No free surfaces\\n\");\n            return AVERROR_BUG;\n        }\n\n        res = nvenc_upload_frame(avctx, frame, inSurf);\n        if (res) {\n            inSurf->lockCount = 0;\n            return res;\n        }\n\n        pic_params.inputBuffer = inSurf->input_surface;\n        pic_params.bufferFmt = inSurf->format;\n        pic_params.inputWidth = avctx->width;\n        pic_params.inputHeight = avctx->height;\n        pic_params.inputPitch = inSurf->pitch;\n        pic_params.outputBitstream = inSurf->output_surface;\n\n        if (avctx->flags & AV_CODEC_FLAG_INTERLACED_DCT) {\n            if (frame->top_field_first)\n                pic_params.pictureStruct = NV_ENC_PIC_STRUCT_FIELD_TOP_BOTTOM;\n            else\n                pic_params.pictureStruct = NV_ENC_PIC_STRUCT_FIELD_BOTTOM_TOP;\n        } else {\n            pic_params.pictureStruct = NV_ENC_PIC_STRUCT_FRAME;\n        }\n\n        if (ctx->forced_idr >= 0 && frame->pict_type == AV_PICTURE_TYPE_I) {\n            pic_params.encodePicFlags =\n                ctx->forced_idr ? NV_ENC_PIC_FLAG_FORCEIDR : NV_ENC_PIC_FLAG_FORCEINTRA;\n        } else {\n            pic_params.encodePicFlags = 0;\n        }\n\n        pic_params.inputTimeStamp = frame->pts;\n\n        nvenc_codec_specific_pic_params(avctx, &pic_params);\n    } else {\n        pic_params.encodePicFlags = NV_ENC_PIC_FLAG_EOS;\n    }\n\n    nv_status = p_nvenc->nvEncEncodePicture(ctx->nvencoder, &pic_params);\n    if (nv_status != NV_ENC_SUCCESS &&\n        nv_status != NV_ENC_ERR_NEED_MORE_INPUT)\n        return nvenc_print_error(avctx, nv_status, \"EncodePicture failed!\");\n\n    if (frame) {\n        av_fifo_generic_write(ctx->output_surface_queue, &inSurf, sizeof(inSurf), NULL);\n        timestamp_queue_enqueue(ctx->timestamp_list, frame->pts);\n\n        if (ctx->initial_pts[0] == AV_NOPTS_VALUE)\n            ctx->initial_pts[0] = frame->pts;\n        else if (ctx->initial_pts[1] == AV_NOPTS_VALUE)\n            ctx->initial_pts[1] = frame->pts;\n    }\n\n    /* all the pending buffers are now ready for output */\n    if (nv_status == NV_ENC_SUCCESS) {\n        while (av_fifo_size(ctx->output_surface_queue) > 0) {\n            av_fifo_generic_read(ctx->output_surface_queue, &tmpoutsurf, sizeof(tmpoutsurf), NULL);\n            av_fifo_generic_write(ctx->output_surface_ready_queue, &tmpoutsurf, sizeof(tmpoutsurf), NULL);\n        }\n    }\n\n    if (output_ready(avctx, !frame)) {\n        av_fifo_generic_read(ctx->output_surface_ready_queue, &tmpoutsurf, sizeof(tmpoutsurf), NULL);\n\n        res = process_output_surface(avctx, pkt, tmpoutsurf);\n\n        if (res)\n            return res;\n\n        av_assert0(tmpoutsurf->lockCount);\n        tmpoutsurf->lockCount--;\n\n        *got_packet = 1;\n    } else {\n        *got_packet = 0;\n    }\n\n    return 0;\n}\n"
    },
    "skipped": [
        "/tmp/vanessa/spack-stage/spack-stage-ffmpeg-3.2.4-tt6o4aq464a72ptcc3rjc7s6iclbxb35/spack-src/tests/reference.pnm",
        "/tmp/vanessa/spack-stage/spack-stage-ffmpeg-3.2.4-tt6o4aq464a72ptcc3rjc7s6iclbxb35/spack-src/libavcodec/cinepakenc.c"
    ],
    "total_files": 3561
}