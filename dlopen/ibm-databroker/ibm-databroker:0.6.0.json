{
    "matches": {
        "/tmp/vanessa/spack-stage/spack-stage-ibm-databroker-0.6.0-hybe4sfz4fmlvenxranuc2wbbtem4hgc/spack-src/bindings/python/dbr_module/dbr.py": " #\n # Copyright (C) 2018, 2019 IBM Corporation\n #\n # Licensed under the Apache License, Version 2.0 (the \"License\");\n # you may not use this file except in compliance with the License.\n # You may obtain a copy of the License at\n #\n #    http://www.apache.org/licenses/LICENSE-2.0\n #\n # Unless required by applicable law or agreed to in writing, software\n # distributed under the License is distributed on an \"AS IS\" BASIS,\n # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n # See the License for the specific language governing permissions and\n # limitations under the License.\n #\nfrom _dbr_interface import ffi\nlibtransport = ffi.dlopen(\"libdbbe_transport.so\", ffi.RTLD_GLOBAL|ffi.RTLD_NOW)\nlibbackend = ffi.dlopen(\"libdbbe_redis.so\", ffi.RTLD_GLOBAL|ffi.RTLD_NOW)\nlibdatabroker = ffi.dlopen(\"libdatabroker.so\")\nimport _cffi_backend\nfrom dbr_module.dbr_errorcodes import Errors\nimport pickle\n\nERRORTABLE = Errors()\n\n# Copy for direct access\nDBR_SUCCESS = ERRORTABLE.DBR_SUCCESS # no error, clean result, operation successful\nDBR_ERR_GENERIC = ERRORTABLE.DBR_ERR_GENERIC # a general or unknown error has occurred\nDBR_ERR_INVALID = ERRORTABLE.DBR_ERR_INVALID # an invalid parameter was passed into a function or other general error\nDBR_ERR_HANDLE = ERRORTABLE.DBR_ERR_HANDLE # an invalid handle was encountered\nDBR_ERR_INPROGRESS = ERRORTABLE.DBR_ERR_INPROGRESS # a request is still in progress, check again later\nDBR_ERR_TIMEOUT = ERRORTABLE.DBR_ERR_TIMEOUT # a timeout occurred\nDBR_ERR_UBUFFER = ERRORTABLE.DBR_ERR_UBUFFER # provided user buffer problem (too small, not available)\nDBR_ERR_UNAVAIL = ERRORTABLE.DBR_ERR_UNAVAIL # the requested tuple or namespace is not available in the backing storage\nDBR_ERR_EXISTS = ERRORTABLE.DBR_ERR_EXISTS # Entry already exists\nDBR_ERR_NSBUSY = ERRORTABLE.DBR_ERR_NSBUSY # there are still clients attached to a namespace\nDBR_ERR_NSINVAL = ERRORTABLE.DBR_ERR_NSINVAL # invalid name space\nDBR_ERR_NOMEMORY = ERRORTABLE.DBR_ERR_NOMEMORY # the amount of memory or storage was insufficient to\nDBR_ERR_TAGERROR = ERRORTABLE.DBR_ERR_TAGERROR # the returned tag is an error\nDBR_ERR_NOFILE = ERRORTABLE.DBR_ERR_NOFILE # a file was not found\nDBR_ERR_NOAUTH = ERRORTABLE.DBR_ERR_NOAUTH # access authorization required or failed\nDBR_ERR_NOCONNECT = ERRORTABLE.DBR_ERR_NOCONNECT # connection to a storage backend failed\nDBR_ERR_CANCELLED = ERRORTABLE.DBR_ERR_CANCELLED # operation was cancelled\nDBR_ERR_NOTIMPL = ERRORTABLE.DBR_ERR_NOTIMPL # operation not implemented\nDBR_ERR_INVALIDOP = ERRORTABLE.DBR_ERR_INVALIDOP # invalid operation\nDBR_ERR_BE_POST = ERRORTABLE.DBR_ERR_BE_POST #  posting request to back-end failed\nDBR_ERR_BE_GENERAL = ERRORTABLE.DBR_ERR_BE_GENERAL # Unspecified back-end error\nDBR_ERR_MAXERROR = ERRORTABLE.DBR_ERR_MAXERROR\n\n# Tuple persist level\nDBR_PERST_VOLATILE_SIMPLE = libdatabroker.DBR_PERST_VOLATILE_SIMPLE\nDBR_PERST_VOLATILE_FT = libdatabroker.DBR_PERST_VOLATILE_FT\nDBR_PERST_TEMPORARY_SIMPLE = libdatabroker.DBR_PERST_TEMPORARY_SIMPLE\nDBR_PERST_TEMPORARY_FT = libdatabroker.DBR_PERST_TEMPORARY_FT\nDBR_PERST_PERMANENT_SIMPLE = libdatabroker.DBR_PERST_PERMANENT_SIMPLE\nDBR_PERST_PERMANENT_FT = libdatabroker.DBR_PERST_PERMANENT_FT\nDBR_PERST_MAX = libdatabroker.DBR_PERST_MAX\n\nDBR_FLAGS_NONE = libdatabroker.DBR_FLAGS_NONE\nDBR_FLAGS_NOWAIT = libdatabroker.DBR_FLAGS_NOWAIT\nDBR_FLAGS_MAX = libdatabroker.DBR_FLAGS_MAX\n\nDBR_GROUP_LIST_EMPTY = '0' #libdatabroker.DBR_GROUP_LIST_EMPTY\nDBR_GROUP_EMPTY = '0'      #libdatabroker.DBR_GROUP_EMPTY\n\n# Mask\nDBR_STATE_MASK_ALL = libdatabroker.DBR_STATE_MASK_ALL\n\n\n# Utility\ndef getErrorCode(error_code):\n    return ERRORTABLE.getErrorCode(error_code).decode()\n\ndef getErrorMessage(error_code):\n    if error_code < DBR_ERR_MAXERROR:\n        return ERRORTABLE.getErrorMessage(error_code).decode()\n    return \"Unknown Error\"\n\ndef createBuf(buftype, bufsize):\n    retval = ffi.buffer(ffi.new(buftype, bufsize))\n    return retval\n\n# Data Broker\ndef create(dbrname, level, groups):\n    dbr_hdl = libdatabroker.dbrCreate(dbrname.encode(), level, groups)\n    return dbr_hdl\n\ndef attach(dbr_name):\n    dbr_hdl = libdatabroker.dbrAttach(dbr_name.encode())\n    return dbr_hdl\n\ndef delete(dbr_name):\n    retval = libdatabroker.dbrDelete(dbr_name.encode())\n    return retval\n\ndef detach(dbr_handle):\n    retval = libdatabroker.dbrDetach(dbr_handle)\n    return retval\n\ndef query(dbr_handle, dbr_state, state_mask):\n    retval =  libdatabroker.dbrQuery(dbr_handle, dbr_state, state_mask)\n    return retval\n\ndef addUnits(dbr_handle, units):\n    retval = libdatabroker.dbrAddUnits(dbr_handle, units)\n    return retval \n\ndef removeUnits(dbr_handle, units):\n    retval = libdatabroker.dbrRemoveUnits(dbr_handle, units)\n    return retval\n\ndef put(dbr_hdl, tuple_val, tuple_name, group):\n    dumpedtuple = None\n    if type(tuple_val) is str:\n        dumpedtuple = tuple_val.encode()\n    else:\n        dumpedtuple = pickle.dumps(tuple_val)\n    size = len(dumpedtuple)\n    retval = libdatabroker.dbrPut(dbr_hdl, dumpedtuple, size, tuple_name.encode(), group.encode())\n    return retval\n\ndef read(dbr_hdl, tuple_name, match_template, group, flag, buffer_size=None):\n    out_size = ffi.new('int64_t*')\n    if buffer_size is None :\n        buffer_size=[256]\n    out_size[0] = buffer_size[0]\n    out_buffer = createBuf('char[]', out_size[0])\n    retval = libdatabroker.dbrRead(dbr_hdl, ffi.from_buffer(out_buffer), out_size, tuple_name.encode(), match_template.encode(), group.encode(), flag)\n    if retval != 0:\n        return None, retval\n    buffer_size[0] = out_size[0]\n    result = None\n    try:\n        result = pickle.loads(out_buffer[:])\n    except:\n        result = out_buffer[:].decode()\n    return result, retval\n\ndef get(dbr_hdl, tuple_name, match_template, group, flag, buffer_size=None):\n    out_size = ffi.new('int64_t*')\n    if buffer_size is None :\n        buffer_size=[128]\n    out_size[0] = buffer_size[0]\n    out_buffer = createBuf('char[]', out_size[0])\n    retval = libdatabroker.dbrGet(dbr_hdl, ffi.from_buffer(out_buffer), out_size, tuple_name.encode(), match_template.encode(), group.encode(), flag)\n    if retval != 0:\n        return None, retval\n    buffer_size[0] = out_size[0]\n    result = None\n    try:\n        result = pickle.loads(out_buffer[:])\n    except:\n        result = out_buffer[:].decode()\n    return result, retval\n    #return pickle.loads(out_buffer[:]), retval\n\ndef readA(dbr_hdl, tuple_name, match_template, group, buffer_size=None):\n    out_size = ffi.new('int64_t*')\n    if buffer_size is None :\n        buffer_size=[128]\n    out_size[0] = buffer_size[0]\n    out_buffer = createBuf('char[]', out_size[0])\n    tag = libdatabroker.dbrReadA(dbr_hdl, ffi.from_buffer(out_buffer), out_size, tuple_name.encode(), match_template.encode(), group.encode())\n    buffer_size[0] = out_size[0]\n    return tag, out_buffer \n\ndef putA(dbr_hdl, tuple_val, tuple_name, group):\n    #dumpedtuple = pickle.dumps(tuple_val)\n    dumpedtuple = None\n    if type(tuple_val) is str:\n        dumpedtuple = tuple_val.encode()\n    else:\n        dumpedtuple = pickle.dumps(tuple_val)\n    size = len(dumpedtuple)\n    tag = libdatabroker.dbrPutA(dbr_hdl, dumpedtuple, size, tuple_name.encode(), group.encode())\n    return tag\n\ndef getA(dbr_hdl, tuple_name, match_template, group, buffer_size=None):\n    out_size = ffi.new('int64_t*')\n    if buffer_size is None :\n        buffer_size=[128]\n    out_size[0] = buffer_size[0]\n    out_buffer = createBuf('char[]', out_size[0])\n    tag = libdatabroker.dbrGetA(dbr_hdl, ffi.from_buffer(out_buffer), out_size, tuple_name.encode(), match_template.encode(), group.encode())\n    buffer_size[0] = out_size[0]\n    return tag, out_buffer # pickle.loads(out_buffer[:]) \n\ndef decodeTuple(tuple_buffer):\n    result = None\n    try:\n        result = pickle.loads(tuple_buffer[:])\n    except:\n        result = tuple_buffer[:].decode()\n    return result\n    #return pickle.loads(tuple_buffer[:])\n\ndef testKey(dbr_hdl, tuple_name):\n    retval = libdatabroker.dbrTestKey(dbr_hdl, tuple_name)\n    return retval\n\ndef directory(dbr_hdl, match_template, group, count, size):\n    tbuf = createBuf('char[]',size)\n    rsize = ffi.new('int64_t*')\n    retval = libdatabroker.dbrDirectory(dbr_hdl, match_template.encode(), group.encode(), count, ffi.from_buffer(tbuf), ffi.cast('const size_t',size), rsize)\n    result_buffer=(tbuf[0:rsize[0]].decode().split('\\n'))\n    return result_buffer, rsize[0], retval\n\ndef move(src_DBRHandle, src_group, tuple_name, match_template, dest_DBRHandle, dest_group):\n    retval = libdatabroker.dbrMove(src_DBRHandle, src_group.encode(), tuple_name.encode(), match_template.encode(), dest_DBRHandle, dest_group.encode())\n    return retval\n\ndef remove(dbr_hdl, group, tuple_name, match_template):\n    retval = libdatabroker.dbrRemove(dbr_hdl, group.encode(), tuple_name.encode(), match_template.encode())\n    return retval\n\ndef test(tag):\n    retval = libdatabroker.dbrTest(tag)\n    return retval\n\ndef cancel(tag):\n    retval = libdatabroker.dbrCancel(tag)\n    return retval\n\ndef eval(dbr_hdl, tuple_val, tuple_name, size, group, fn_ptr):\n    retval = libdatabroker.dbrEval(dbr_hdl, tuple_val.encode(), size, tuple_name.encode(), group.encode(), fn_ptr)\n    return retval\n"
    },
    "skipped": [
        "/tmp/vanessa/spack-stage/spack-stage-ibm-databroker-0.6.0-hybe4sfz4fmlvenxranuc2wbbtem4hgc/spack-src/doc/fig/architecture.png",
        "/tmp/vanessa/spack-stage/spack-stage-ibm-databroker-0.6.0-hybe4sfz4fmlvenxranuc2wbbtem4hgc/spack-src/doc/fig/dbrworkflow.png"
    ],
    "total_files": 163
}