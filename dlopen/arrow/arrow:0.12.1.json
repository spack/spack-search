{
    "matches": {
        "/tmp/vanessa/spack-stage/spack-stage-arrow-0.12.1-5t3jhpxat63jnyckavh6dij4iyabhfhm/spack-src/python/pyarrow/gandiva.pyx": "# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\n# cython: profile=False\n# distutils: language = c++\n# cython: embedsignature = True\n\nimport os\n\nfrom libcpp cimport bool as c_bool, nullptr\nfrom libcpp.memory cimport shared_ptr, unique_ptr, make_shared\nfrom libcpp.string cimport string as c_string\nfrom libcpp.vector cimport vector as c_vector\nfrom libcpp.unordered_set cimport unordered_set as c_unordered_set\nfrom libc.stdint cimport int64_t, int32_t, uint8_t, uintptr_t\n\nfrom pyarrow.includes.libarrow cimport *\nfrom pyarrow.compat import frombytes\nfrom pyarrow.lib cimport (Array, DataType, Field, MemoryPool, RecordBatch,\n                          Schema, check_status, pyarrow_wrap_array,\n                          pyarrow_wrap_data_type, ensure_type)\n\nfrom pyarrow.includes.libgandiva cimport (\n    CCondition, CExpression,\n    CNode, CProjector, CFilter,\n    CSelectionVector,\n    TreeExprBuilder_MakeExpression,\n    TreeExprBuilder_MakeFunction,\n    TreeExprBuilder_MakeBoolLiteral,\n    TreeExprBuilder_MakeUInt8Literal,\n    TreeExprBuilder_MakeUInt16Literal,\n    TreeExprBuilder_MakeUInt32Literal,\n    TreeExprBuilder_MakeUInt64Literal,\n    TreeExprBuilder_MakeInt8Literal,\n    TreeExprBuilder_MakeInt16Literal,\n    TreeExprBuilder_MakeInt32Literal,\n    TreeExprBuilder_MakeInt64Literal,\n    TreeExprBuilder_MakeFloatLiteral,\n    TreeExprBuilder_MakeDoubleLiteral,\n    TreeExprBuilder_MakeStringLiteral,\n    TreeExprBuilder_MakeBinaryLiteral,\n    TreeExprBuilder_MakeField,\n    TreeExprBuilder_MakeIf,\n    TreeExprBuilder_MakeAnd,\n    TreeExprBuilder_MakeOr,\n    TreeExprBuilder_MakeCondition,\n    TreeExprBuilder_MakeInExpressionInt32,\n    TreeExprBuilder_MakeInExpressionInt64,\n    TreeExprBuilder_MakeInExpressionTime32,\n    TreeExprBuilder_MakeInExpressionTime64,\n    TreeExprBuilder_MakeInExpressionDate32,\n    TreeExprBuilder_MakeInExpressionDate64,\n    TreeExprBuilder_MakeInExpressionTimeStamp,\n    TreeExprBuilder_MakeInExpressionString,\n    TreeExprBuilder_MakeInExpressionBinary,\n    SelectionVector_MakeInt16,\n    SelectionVector_MakeInt32,\n    SelectionVector_MakeInt64,\n    Projector_Make,\n    Filter_Make,\n    CFunctionSignature,\n    GetRegisteredFunctionSignatures)\n\nif os.name == 'posix':\n    # Expose self with RTLD_GLOBAL so that symbols from gandiva.so and child\n    # libs (such as libstdc++) can be reached during JIT code execution.\n    # Another workaround is to use\n    #   sys.setdlopenflags(os.RTLD_GLOBAL | os.RTLD_NOW)\n    # but it would affect all C extensions loaded in the process.\n    import ctypes\n    _dll = ctypes.CDLL(__file__, ctypes.RTLD_GLOBAL)\n\ncdef class Node:\n    cdef:\n        shared_ptr[CNode] node\n\n    def __init__(self):\n        raise TypeError(\"Do not call {}'s constructor directly, use the \"\n                        \"TreeExprBuilder API directly\"\n                        .format(self.__class__.__name__))\n\n    @staticmethod\n    cdef create(shared_ptr[CNode] node):\n        cdef Node self = Node.__new__(Node)\n        self.node = node\n        return self\n\ncdef class Expression:\n    cdef:\n        shared_ptr[CExpression] expression\n\n    cdef void init(self, shared_ptr[CExpression] expression):\n        self.expression = expression\n\ncdef class Condition:\n    cdef:\n        shared_ptr[CCondition] condition\n\n    def __init__(self):\n        raise TypeError(\"Do not call {}'s constructor directly, use the \"\n                        \"TreeExprBuilder API instead\"\n                        .format(self.__class__.__name__))\n\n    @staticmethod\n    cdef create(shared_ptr[CCondition] condition):\n        cdef Condition self = Condition.__new__(Condition)\n        self.condition = condition\n        return self\n\ncdef class SelectionVector:\n    cdef:\n        shared_ptr[CSelectionVector] selection_vector\n\n    def __init__(self):\n        raise TypeError(\"Do not call {}'s constructor directly.\"\n                        .format(self.__class__.__name__))\n\n    @staticmethod\n    cdef create(shared_ptr[CSelectionVector] selection_vector):\n        cdef SelectionVector self = SelectionVector.__new__(SelectionVector)\n        self.selection_vector = selection_vector\n        return self\n\n    def to_array(self):\n        cdef shared_ptr[CArray] result = self.selection_vector.get().ToArray()\n        return pyarrow_wrap_array(result)\n\ncdef class Projector:\n    cdef:\n        shared_ptr[CProjector] projector\n        MemoryPool pool\n\n    def __init__(self):\n        raise TypeError(\"Do not call {}'s constructor directly, use \"\n                        \"make_projector instead\"\n                        .format(self.__class__.__name__))\n\n    @staticmethod\n    cdef create(shared_ptr[CProjector] projector, MemoryPool pool):\n        cdef Projector self = Projector.__new__(Projector)\n        self.projector = projector\n        self.pool = pool\n        return self\n\n    def evaluate(self, RecordBatch batch):\n        cdef vector[shared_ptr[CArray]] results\n        check_status(self.projector.get().Evaluate(\n            batch.sp_batch.get()[0], self.pool.pool, &results))\n        cdef shared_ptr[CArray] result\n        arrays = []\n        for result in results:\n            arrays.append(pyarrow_wrap_array(result))\n        return arrays\n\ncdef class Filter:\n    cdef:\n        shared_ptr[CFilter] filter\n\n    def __init__(self):\n        raise TypeError(\"Do not call {}'s constructor directly, use \"\n                        \"make_filter instead\"\n                        .format(self.__class__.__name__))\n\n    @staticmethod\n    cdef create(shared_ptr[CFilter] filter):\n        cdef Filter self = Filter.__new__(Filter)\n        self.filter = filter\n        return self\n\n    def evaluate(self, RecordBatch batch, MemoryPool pool, dtype='int32'):\n        cdef:\n            DataType type = ensure_type(dtype)\n            shared_ptr[CSelectionVector] selection\n\n        if type.id == _Type_INT16:\n            check_status(SelectionVector_MakeInt16(\n                batch.num_rows, pool.pool, &selection))\n        elif type.id == _Type_INT32:\n            check_status(SelectionVector_MakeInt32(\n                batch.num_rows, pool.pool, &selection))\n        elif type.id == _Type_INT64:\n            check_status(SelectionVector_MakeInt64(\n                batch.num_rows, pool.pool, &selection))\n        else:\n            raise ValueError(\"'dtype' of the selection vector should be \"\n                             \"one of 'int16', 'int32' and 'int64'.\")\n\n        check_status(self.filter.get().Evaluate(\n            batch.sp_batch.get()[0], selection))\n        return SelectionVector.create(selection)\n\n\ncdef class TreeExprBuilder:\n\n    def make_literal(self, value, dtype):\n        cdef:\n            DataType type = ensure_type(dtype)\n            shared_ptr[CNode] r\n\n        if type.id == _Type_BOOL:\n            r = TreeExprBuilder_MakeBoolLiteral(value)\n        elif type.id == _Type_UINT8:\n            r = TreeExprBuilder_MakeUInt8Literal(value)\n        elif type.id == _Type_UINT16:\n            r = TreeExprBuilder_MakeUInt16Literal(value)\n        elif type.id == _Type_UINT32:\n            r = TreeExprBuilder_MakeUInt32Literal(value)\n        elif type.id == _Type_UINT64:\n            r = TreeExprBuilder_MakeUInt64Literal(value)\n        elif type.id == _Type_INT8:\n            r = TreeExprBuilder_MakeInt8Literal(value)\n        elif type.id == _Type_INT16:\n            r = TreeExprBuilder_MakeInt16Literal(value)\n        elif type.id == _Type_INT32:\n            r = TreeExprBuilder_MakeInt32Literal(value)\n        elif type.id == _Type_INT64:\n            r = TreeExprBuilder_MakeInt64Literal(value)\n        elif type.id == _Type_FLOAT:\n            r = TreeExprBuilder_MakeFloatLiteral(value)\n        elif type.id == _Type_DOUBLE:\n            r = TreeExprBuilder_MakeDoubleLiteral(value)\n        elif type.id == _Type_STRING:\n            r = TreeExprBuilder_MakeStringLiteral(value.encode('UTF-8'))\n        elif type.id == _Type_BINARY:\n            r = TreeExprBuilder_MakeBinaryLiteral(value)\n        else:\n            raise TypeError(\"Didn't recognize dtype \" + str(dtype))\n\n        return Node.create(r)\n\n    def make_expression(self, Node root_node, Field return_field):\n        cdef shared_ptr[CExpression] r = TreeExprBuilder_MakeExpression(\n            root_node.node, return_field.sp_field)\n        cdef Expression expression = Expression()\n        expression.init(r)\n        return expression\n\n    def make_function(self, name, children, DataType return_type):\n        cdef c_vector[shared_ptr[CNode]] c_children\n        cdef Node child\n        for child in children:\n            c_children.push_back(child.node)\n        cdef shared_ptr[CNode] r = TreeExprBuilder_MakeFunction(\n            name.encode(), c_children, return_type.sp_type)\n        return Node.create(r)\n\n    def make_field(self, Field field):\n        cdef shared_ptr[CNode] r = TreeExprBuilder_MakeField(field.sp_field)\n        return Node.create(r)\n\n    def make_if(self, Node condition, Node this_node,\n                Node else_node, DataType return_type):\n        cdef shared_ptr[CNode] r = TreeExprBuilder_MakeIf(\n            condition.node, this_node.node, else_node.node,\n            return_type.sp_type)\n        return Node.create(r)\n\n    def make_and(self, children):\n        cdef c_vector[shared_ptr[CNode]] c_children\n        cdef Node child\n        for child in children:\n            c_children.push_back(child.node)\n        cdef shared_ptr[CNode] r = TreeExprBuilder_MakeAnd(c_children)\n        return Node.create(r)\n\n    def make_or(self, children):\n        cdef c_vector[shared_ptr[CNode]] c_children\n        cdef Node child\n        for child in children:\n            c_children.push_back(child.node)\n        cdef shared_ptr[CNode] r = TreeExprBuilder_MakeOr(c_children)\n        return Node.create(r)\n\n    def _make_in_expression_int32(self, Node node, values):\n        cdef shared_ptr[CNode] r\n        cdef c_unordered_set[int32_t] c_values\n        cdef int32_t v\n        for v in values:\n            c_values.insert(v)\n        r = TreeExprBuilder_MakeInExpressionInt32(node.node, c_values)\n        return Node.create(r)\n\n    def _make_in_expression_int64(self, Node node, values):\n        cdef shared_ptr[CNode] r\n        cdef c_unordered_set[int64_t] c_values\n        cdef int64_t v\n        for v in values:\n            c_values.insert(v)\n        r = TreeExprBuilder_MakeInExpressionInt64(node.node, c_values)\n        return Node.create(r)\n\n    def _make_in_expression_time32(self, Node node, values):\n        cdef shared_ptr[CNode] r\n        cdef c_unordered_set[int32_t] c_values\n        cdef int32_t v\n        for v in values:\n            c_values.insert(v)\n        r = TreeExprBuilder_MakeInExpressionTime32(node.node, c_values)\n        return Node.create(r)\n\n    def _make_in_expression_time64(self, Node node, values):\n        cdef shared_ptr[CNode] r\n        cdef c_unordered_set[int64_t] c_values\n        cdef int64_t v\n        for v in values:\n            c_values.insert(v)\n        r = TreeExprBuilder_MakeInExpressionTime64(node.node, c_values)\n        return Node.create(r)\n\n    def _make_in_expression_date32(self, Node node, values):\n        cdef shared_ptr[CNode] r\n        cdef c_unordered_set[int32_t] c_values\n        cdef int32_t v\n        for v in values:\n            c_values.insert(v)\n        r = TreeExprBuilder_MakeInExpressionDate32(node.node, c_values)\n        return Node.create(r)\n\n    def _make_in_expression_date64(self, Node node, values):\n        cdef shared_ptr[CNode] r\n        cdef c_unordered_set[int64_t] c_values\n        cdef int64_t v\n        for v in values:\n            c_values.insert(v)\n        r = TreeExprBuilder_MakeInExpressionDate64(node.node, c_values)\n        return Node.create(r)\n\n    def _make_in_expression_timestamp(self, Node node, values):\n        cdef shared_ptr[CNode] r\n        cdef c_unordered_set[int64_t] c_values\n        cdef int64_t v\n        for v in values:\n            c_values.insert(v)\n        r = TreeExprBuilder_MakeInExpressionTimeStamp(node.node, c_values)\n        return Node.create(r)\n\n    def _make_in_expression_binary(self, Node node, values):\n        cdef shared_ptr[CNode] r\n        cdef c_unordered_set[c_string] c_values\n        cdef c_string v\n        for v in values:\n            c_values.insert(v)\n        r = TreeExprBuilder_MakeInExpressionString(node.node, c_values)\n        return Node.create(r)\n\n    def _make_in_expression_string(self, Node node, values):\n        cdef shared_ptr[CNode] r\n        cdef c_unordered_set[c_string] c_values\n        cdef c_string _v\n        for v in values:\n            _v = v.encode('UTF-8')\n            c_values.insert(_v)\n        r = TreeExprBuilder_MakeInExpressionString(node.node, c_values)\n        return Node.create(r)\n\n    def make_in_expression(self, Node node, values, dtype):\n        cdef DataType type = ensure_type(dtype)\n\n        if type.id == _Type_INT32:\n            return self._make_in_expression_int32(node, values)\n        elif type.id == _Type_INT64:\n            return self._make_in_expression_int64(node, values)\n        elif type.id == _Type_TIME32:\n            return self._make_in_expression_time32(node, values)\n        elif type.id == _Type_TIME64:\n            return self._make_in_expression_time64(node, values)\n        elif type.id == _Type_TIMESTAMP:\n            return self._make_in_expression_timestamp(node, values)\n        elif type.id == _Type_DATE32:\n            return self._make_in_expression_date32(node, values)\n        elif type.id == _Type_DATE64:\n            return self._make_in_expression_date64(node, values)\n        elif type.id == _Type_BINARY:\n            return self._make_in_expression_binary(node, values)\n        elif type.id == _Type_STRING:\n            return self._make_in_expression_string(node, values)\n        else:\n            raise TypeError(\"Data type \" + str(dtype) + \" not supported.\")\n\n    def make_condition(self, Node condition):\n        cdef shared_ptr[CCondition] r = TreeExprBuilder_MakeCondition(\n            condition.node)\n        return Condition.create(r)\n\ncpdef make_projector(Schema schema, children, MemoryPool pool):\n    cdef c_vector[shared_ptr[CExpression]] c_children\n    cdef Expression child\n    for child in children:\n        c_children.push_back(child.expression)\n    cdef shared_ptr[CProjector] result\n    check_status(Projector_Make(schema.sp_schema, c_children,\n                                &result))\n    return Projector.create(result, pool)\n\ncpdef make_filter(Schema schema, Condition condition):\n    cdef shared_ptr[CFilter] result\n    check_status(Filter_Make(schema.sp_schema, condition.condition, &result))\n    return Filter.create(result)\n\ncdef class FunctionSignature:\n    \"\"\"\n    Signature of a Gandiva function including name, parameter types\n    and return type.\n    \"\"\"\n\n    cdef:\n        shared_ptr[CFunctionSignature] signature\n\n    def __init__(self):\n        raise TypeError(\"Do not call {}'s constructor directly.\"\n                        .format(self.__class__.__name__))\n\n    @staticmethod\n    cdef create(shared_ptr[CFunctionSignature] signature):\n        cdef FunctionSignature self = FunctionSignature.__new__(\n            FunctionSignature)\n        self.signature = signature\n        return self\n\n    def return_type(self):\n        return pyarrow_wrap_data_type(self.signature.get().ret_type())\n\n    def param_types(self):\n        result = []\n        cdef vector[shared_ptr[CDataType]] types = \\\n            self.signature.get().param_types()\n        for t in types:\n            result.append(pyarrow_wrap_data_type(t))\n        return result\n\n    def name(self):\n        return self.signature.get().base_name().decode()\n\n    def __repr__(self):\n        signature = self.signature.get().ToString().decode()\n        return \"FunctionSignature(\" + signature + \")\"\n\n\ndef get_registered_function_signatures():\n    \"\"\"\n    Return the function in Gandiva's ExpressionRegistry.\n\n    Returns\n    -------\n    registry: a list of registered function signatures\n    \"\"\"\n    results = []\n\n    cdef vector[shared_ptr[CFunctionSignature]] signatures = \\\n        GetRegisteredFunctionSignatures()\n\n    for signature in signatures:\n        results.append(FunctionSignature.create(signature))\n\n    return results\n",
        "/tmp/vanessa/spack-stage/spack-stage-arrow-0.12.1-5t3jhpxat63jnyckavh6dij4iyabhfhm/spack-src/cpp/src/arrow/io/hdfs-internal.cc": "// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\n\n// This shim interface to libhdfs (for runtime shared library loading) has been\n// adapted from the SFrame project, released under the ASF-compatible 3-clause\n// BSD license\n//\n// Using this required having the $JAVA_HOME and $HADOOP_HOME environment\n// variables set, so that libjvm and libhdfs can be located easily\n\n// Copyright (C) 2015 Dato, Inc.\n// All rights reserved.\n//\n// This software may be modified and distributed under the terms\n// of the BSD license. See the LICENSE file for details.\n\n#include \"arrow/io/hdfs-internal.h\"\n\n#include <cstdint>\n#include <cstdlib>\n#include <mutex>\n#include <sstream>  // IWYU pragma: keep\n#include <string>\n#include <vector>\n\n#ifndef _WIN32\n#include <dlfcn.h>\n#endif\n\n#include <boost/filesystem.hpp>  // NOLINT\n\n#include \"arrow/status.h\"\n#include \"arrow/util/logging.h\"\n\nnamespace fs = boost::filesystem;\n\n#ifndef _WIN32\nstatic void* libjvm_handle = NULL;\n#else\nstatic HINSTANCE libjvm_handle = NULL;\n#endif\n/*\n * All the shim pointers\n */\n\n// Helper functions for dlopens\nstatic std::vector<fs::path> get_potential_libjvm_paths();\nstatic std::vector<fs::path> get_potential_libhdfs_paths();\nstatic std::vector<fs::path> get_potential_libhdfs3_paths();\nstatic arrow::Status try_dlopen(std::vector<fs::path> potential_paths, const char* name,\n#ifndef _WIN32\n                                void*& out_handle);\n#else\n                                HINSTANCE& out_handle);\n#endif\n\nstatic std::vector<fs::path> get_potential_libhdfs_paths() {\n  std::vector<fs::path> libhdfs_potential_paths;\n  std::string file_name;\n\n// OS-specific file name\n#ifdef _WIN32\n  file_name = \"hdfs.dll\";\n#elif __APPLE__\n  file_name = \"libhdfs.dylib\";\n#else\n  file_name = \"libhdfs.so\";\n#endif\n\n  // Common paths\n  std::vector<fs::path> search_paths = {fs::path(\"\"), fs::path(\".\")};\n\n  // Path from environment variable\n  const char* hadoop_home = std::getenv(\"HADOOP_HOME\");\n  if (hadoop_home != nullptr) {\n    auto path = fs::path(hadoop_home) / \"lib/native\";\n    search_paths.push_back(path);\n  }\n\n  const char* libhdfs_dir = std::getenv(\"ARROW_LIBHDFS_DIR\");\n  if (libhdfs_dir != nullptr) {\n    search_paths.push_back(fs::path(libhdfs_dir));\n  }\n\n  // All paths with file name\n  for (auto& path : search_paths) {\n    libhdfs_potential_paths.push_back(path / file_name);\n  }\n\n  return libhdfs_potential_paths;\n}\n\nstatic std::vector<fs::path> get_potential_libhdfs3_paths() {\n  std::vector<fs::path> potential_paths;\n  std::string file_name;\n\n// OS-specific file name\n#ifdef _WIN32\n  file_name = \"hdfs3.dll\";\n#elif __APPLE__\n  file_name = \"libhdfs3.dylib\";\n#else\n  file_name = \"libhdfs3.so\";\n#endif\n\n  // Common paths\n  std::vector<fs::path> search_paths = {fs::path(\"\"), fs::path(\".\")};\n\n  const char* libhdfs3_dir = std::getenv(\"ARROW_LIBHDFS3_DIR\");\n  if (libhdfs3_dir != nullptr) {\n    search_paths.push_back(fs::path(libhdfs3_dir));\n  }\n\n  // All paths with file name\n  for (auto& path : search_paths) {\n    potential_paths.push_back(path / file_name);\n  }\n\n  return potential_paths;\n}\n\nstatic std::vector<fs::path> get_potential_libjvm_paths() {\n  std::vector<fs::path> libjvm_potential_paths;\n\n  std::vector<fs::path> search_prefixes;\n  std::vector<fs::path> search_suffixes;\n  std::string file_name;\n\n// From heuristics\n#ifdef __WIN32\n  search_prefixes = {\"\"};\n  search_suffixes = {\"/jre/bin/server\", \"/bin/server\"};\n  file_name = \"jvm.dll\";\n#elif __APPLE__\n  search_prefixes = {\"\"};\n  search_suffixes = {\"\", \"/jre/lib/server\", \"/lib/server\"};\n  file_name = \"libjvm.dylib\";\n\n// SFrame uses /usr/libexec/java_home to find JAVA_HOME; for now we are\n// expecting users to set an environment variable\n#else\n  search_prefixes = {\n      \"/usr/lib/jvm/default-java\",                // ubuntu / debian distros\n      \"/usr/lib/jvm/java\",                        // rhel6\n      \"/usr/lib/jvm\",                             // centos6\n      \"/usr/lib64/jvm\",                           // opensuse 13\n      \"/usr/local/lib/jvm/default-java\",          // alt ubuntu / debian distros\n      \"/usr/local/lib/jvm/java\",                  // alt rhel6\n      \"/usr/local/lib/jvm\",                       // alt centos6\n      \"/usr/local/lib64/jvm\",                     // alt opensuse 13\n      \"/usr/local/lib/jvm/java-7-openjdk-amd64\",  // alt ubuntu / debian distros\n      \"/usr/lib/jvm/java-7-openjdk-amd64\",        // alt ubuntu / debian distros\n      \"/usr/local/lib/jvm/java-6-openjdk-amd64\",  // alt ubuntu / debian distros\n      \"/usr/lib/jvm/java-6-openjdk-amd64\",        // alt ubuntu / debian distros\n      \"/usr/lib/jvm/java-7-oracle\",               // alt ubuntu\n      \"/usr/lib/jvm/java-8-oracle\",               // alt ubuntu\n      \"/usr/lib/jvm/java-6-oracle\",               // alt ubuntu\n      \"/usr/local/lib/jvm/java-7-oracle\",         // alt ubuntu\n      \"/usr/local/lib/jvm/java-8-oracle\",         // alt ubuntu\n      \"/usr/local/lib/jvm/java-6-oracle\",         // alt ubuntu\n      \"/usr/lib/jvm/default\",                     // alt centos\n      \"/usr/java/latest\",                         // alt centos\n  };\n  search_suffixes = {\"\", \"/jre/lib/amd64/server\", \"/lib/amd64/server\"};\n  file_name = \"libjvm.so\";\n#endif\n  // From direct environment variable\n  char* env_value = NULL;\n  if ((env_value = getenv(\"JAVA_HOME\")) != NULL) {\n    search_prefixes.insert(search_prefixes.begin(), env_value);\n  }\n\n  // Generate cross product between search_prefixes, search_suffixes, and file_name\n  for (auto& prefix : search_prefixes) {\n    for (auto& suffix : search_suffixes) {\n      auto path = (fs::path(prefix) / fs::path(suffix) / fs::path(file_name));\n      libjvm_potential_paths.push_back(path);\n    }\n  }\n\n  return libjvm_potential_paths;\n}\n\n#ifndef _WIN32\nstatic arrow::Status try_dlopen(std::vector<fs::path> potential_paths, const char* name,\n                                void*& out_handle) {\n  std::vector<std::string> error_messages;\n\n  for (auto& i : potential_paths) {\n    i.make_preferred();\n    out_handle = dlopen(i.native().c_str(), RTLD_NOW | RTLD_LOCAL);\n\n    if (out_handle != NULL) {\n      // std::cout << \"Loaded \" << i << std::endl;\n      break;\n    } else {\n      const char* err_msg = dlerror();\n      if (err_msg != NULL) {\n        error_messages.push_back(std::string(err_msg));\n      } else {\n        error_messages.push_back(std::string(\" returned NULL\"));\n      }\n    }\n  }\n\n  if (out_handle == NULL) {\n    return arrow::Status::IOError(\"Unable to load \", name);\n  }\n\n  return arrow::Status::OK();\n}\n\n#else\nstatic arrow::Status try_dlopen(std::vector<fs::path> potential_paths, const char* name,\n                                HINSTANCE& out_handle) {\n  std::vector<std::string> error_messages;\n\n  for (auto& i : potential_paths) {\n    i.make_preferred();\n    out_handle = LoadLibrary(i.string().c_str());\n\n    if (out_handle != NULL) {\n      break;\n    } else {\n      // error_messages.push_back(get_last_err_str(GetLastError()));\n    }\n  }\n\n  if (out_handle == NULL) {\n    return arrow::Status::IOError(\"Unable to load \", name);\n  }\n\n  return arrow::Status::OK();\n}\n#endif  // _WIN32\n\nstatic inline void* GetLibrarySymbol(void* handle, const char* symbol) {\n  if (handle == NULL) return NULL;\n#ifndef _WIN32\n  return dlsym(handle, symbol);\n#else\n\n  void* ret = reinterpret_cast<void*>(\n      GetProcAddress(reinterpret_cast<HINSTANCE>(handle), symbol));\n  if (ret == NULL) {\n    // logstream(LOG_INFO) << \"GetProcAddress error: \"\n    //                     << get_last_err_str(GetLastError()) << std::endl;\n  }\n  return ret;\n#endif\n}\n\n#define GET_SYMBOL_REQUIRED(SHIM, SYMBOL_NAME)                         \\\n  do {                                                                 \\\n    if (!SHIM->SYMBOL_NAME) {                                          \\\n      *reinterpret_cast<void**>(&SHIM->SYMBOL_NAME) =                  \\\n          GetLibrarySymbol(SHIM->handle, \"\" #SYMBOL_NAME);             \\\n    }                                                                  \\\n    if (!SHIM->SYMBOL_NAME)                                            \\\n      return Status::IOError(\"Getting symbol \" #SYMBOL_NAME \"failed\"); \\\n  } while (0)\n\n#define GET_SYMBOL(SHIM, SYMBOL_NAME)                    \\\n  if (!SHIM->SYMBOL_NAME) {                              \\\n    *reinterpret_cast<void**>(&SHIM->SYMBOL_NAME) =      \\\n        GetLibrarySymbol(SHIM->handle, \"\" #SYMBOL_NAME); \\\n  }\n\nnamespace arrow {\nnamespace io {\nnamespace internal {\n\nstatic LibHdfsShim libhdfs_shim;\nstatic LibHdfsShim libhdfs3_shim;\n\nhdfsBuilder* LibHdfsShim::NewBuilder(void) { return this->hdfsNewBuilder(); }\n\nvoid LibHdfsShim::BuilderSetNameNode(hdfsBuilder* bld, const char* nn) {\n  this->hdfsBuilderSetNameNode(bld, nn);\n}\n\nvoid LibHdfsShim::BuilderSetNameNodePort(hdfsBuilder* bld, tPort port) {\n  this->hdfsBuilderSetNameNodePort(bld, port);\n}\n\nvoid LibHdfsShim::BuilderSetUserName(hdfsBuilder* bld, const char* userName) {\n  this->hdfsBuilderSetUserName(bld, userName);\n}\n\nvoid LibHdfsShim::BuilderSetKerbTicketCachePath(hdfsBuilder* bld,\n                                                const char* kerbTicketCachePath) {\n  this->hdfsBuilderSetKerbTicketCachePath(bld, kerbTicketCachePath);\n}\n\nvoid LibHdfsShim::BuilderSetForceNewInstance(hdfsBuilder* bld) {\n  this->hdfsBuilderSetForceNewInstance(bld);\n}\n\nhdfsFS LibHdfsShim::BuilderConnect(hdfsBuilder* bld) {\n  return this->hdfsBuilderConnect(bld);\n}\n\nint LibHdfsShim::BuilderConfSetStr(hdfsBuilder* bld, const char* key, const char* val) {\n  return this->hdfsBuilderConfSetStr(bld, key, val);\n}\n\nint LibHdfsShim::Disconnect(hdfsFS fs) { return this->hdfsDisconnect(fs); }\n\nhdfsFile LibHdfsShim::OpenFile(hdfsFS fs, const char* path, int flags, int bufferSize,\n                               short replication, tSize blocksize) {  // NOLINT\n  return this->hdfsOpenFile(fs, path, flags, bufferSize, replication, blocksize);\n}\n\nint LibHdfsShim::CloseFile(hdfsFS fs, hdfsFile file) {\n  return this->hdfsCloseFile(fs, file);\n}\n\nint LibHdfsShim::Exists(hdfsFS fs, const char* path) {\n  return this->hdfsExists(fs, path);\n}\n\nint LibHdfsShim::Seek(hdfsFS fs, hdfsFile file, tOffset desiredPos) {\n  return this->hdfsSeek(fs, file, desiredPos);\n}\n\ntOffset LibHdfsShim::Tell(hdfsFS fs, hdfsFile file) { return this->hdfsTell(fs, file); }\n\ntSize LibHdfsShim::Read(hdfsFS fs, hdfsFile file, void* buffer, tSize length) {\n  return this->hdfsRead(fs, file, buffer, length);\n}\n\nbool LibHdfsShim::HasPread() {\n  GET_SYMBOL(this, hdfsPread);\n  return this->hdfsPread != nullptr;\n}\n\ntSize LibHdfsShim::Pread(hdfsFS fs, hdfsFile file, tOffset position, void* buffer,\n                         tSize length) {\n  GET_SYMBOL(this, hdfsPread);\n  DCHECK(this->hdfsPread);\n  return this->hdfsPread(fs, file, position, buffer, length);\n}\n\ntSize LibHdfsShim::Write(hdfsFS fs, hdfsFile file, const void* buffer, tSize length) {\n  return this->hdfsWrite(fs, file, buffer, length);\n}\n\nint LibHdfsShim::Flush(hdfsFS fs, hdfsFile file) { return this->hdfsFlush(fs, file); }\n\nint LibHdfsShim::Available(hdfsFS fs, hdfsFile file) {\n  GET_SYMBOL(this, hdfsAvailable);\n  if (this->hdfsAvailable)\n    return this->hdfsAvailable(fs, file);\n  else\n    return 0;\n}\n\nint LibHdfsShim::Copy(hdfsFS srcFS, const char* src, hdfsFS dstFS, const char* dst) {\n  GET_SYMBOL(this, hdfsCopy);\n  if (this->hdfsCopy)\n    return this->hdfsCopy(srcFS, src, dstFS, dst);\n  else\n    return 0;\n}\n\nint LibHdfsShim::Move(hdfsFS srcFS, const char* src, hdfsFS dstFS, const char* dst) {\n  GET_SYMBOL(this, hdfsMove);\n  if (this->hdfsMove)\n    return this->hdfsMove(srcFS, src, dstFS, dst);\n  else\n    return 0;\n}\n\nint LibHdfsShim::Delete(hdfsFS fs, const char* path, int recursive) {\n  return this->hdfsDelete(fs, path, recursive);\n}\n\nint LibHdfsShim::Rename(hdfsFS fs, const char* oldPath, const char* newPath) {\n  GET_SYMBOL(this, hdfsRename);\n  if (this->hdfsRename)\n    return this->hdfsRename(fs, oldPath, newPath);\n  else\n    return 0;\n}\n\nchar* LibHdfsShim::GetWorkingDirectory(hdfsFS fs, char* buffer, size_t bufferSize) {\n  GET_SYMBOL(this, hdfsGetWorkingDirectory);\n  if (this->hdfsGetWorkingDirectory) {\n    return this->hdfsGetWorkingDirectory(fs, buffer, bufferSize);\n  } else {\n    return NULL;\n  }\n}\n\nint LibHdfsShim::SetWorkingDirectory(hdfsFS fs, const char* path) {\n  GET_SYMBOL(this, hdfsSetWorkingDirectory);\n  if (this->hdfsSetWorkingDirectory) {\n    return this->hdfsSetWorkingDirectory(fs, path);\n  } else {\n    return 0;\n  }\n}\n\nint LibHdfsShim::MakeDirectory(hdfsFS fs, const char* path) {\n  return this->hdfsCreateDirectory(fs, path);\n}\n\nint LibHdfsShim::SetReplication(hdfsFS fs, const char* path, int16_t replication) {\n  GET_SYMBOL(this, hdfsSetReplication);\n  if (this->hdfsSetReplication) {\n    return this->hdfsSetReplication(fs, path, replication);\n  } else {\n    return 0;\n  }\n}\n\nhdfsFileInfo* LibHdfsShim::ListDirectory(hdfsFS fs, const char* path, int* numEntries) {\n  return this->hdfsListDirectory(fs, path, numEntries);\n}\n\nhdfsFileInfo* LibHdfsShim::GetPathInfo(hdfsFS fs, const char* path) {\n  return this->hdfsGetPathInfo(fs, path);\n}\n\nvoid LibHdfsShim::FreeFileInfo(hdfsFileInfo* hdfsFileInfo, int numEntries) {\n  this->hdfsFreeFileInfo(hdfsFileInfo, numEntries);\n}\n\nchar*** LibHdfsShim::GetHosts(hdfsFS fs, const char* path, tOffset start,\n                              tOffset length) {\n  GET_SYMBOL(this, hdfsGetHosts);\n  if (this->hdfsGetHosts) {\n    return this->hdfsGetHosts(fs, path, start, length);\n  } else {\n    return NULL;\n  }\n}\n\nvoid LibHdfsShim::FreeHosts(char*** blockHosts) {\n  GET_SYMBOL(this, hdfsFreeHosts);\n  if (this->hdfsFreeHosts) {\n    this->hdfsFreeHosts(blockHosts);\n  }\n}\n\ntOffset LibHdfsShim::GetDefaultBlockSize(hdfsFS fs) {\n  GET_SYMBOL(this, hdfsGetDefaultBlockSize);\n  if (this->hdfsGetDefaultBlockSize) {\n    return this->hdfsGetDefaultBlockSize(fs);\n  } else {\n    return 0;\n  }\n}\n\ntOffset LibHdfsShim::GetCapacity(hdfsFS fs) { return this->hdfsGetCapacity(fs); }\n\ntOffset LibHdfsShim::GetUsed(hdfsFS fs) { return this->hdfsGetUsed(fs); }\n\nint LibHdfsShim::Chown(hdfsFS fs, const char* path, const char* owner,\n                       const char* group) {\n  return this->hdfsChown(fs, path, owner, group);\n}\n\nint LibHdfsShim::Chmod(hdfsFS fs, const char* path, short mode) {  // NOLINT\n  return this->hdfsChmod(fs, path, mode);\n}\n\nint LibHdfsShim::Utime(hdfsFS fs, const char* path, tTime mtime, tTime atime) {\n  GET_SYMBOL(this, hdfsUtime);\n  if (this->hdfsUtime) {\n    return this->hdfsUtime(fs, path, mtime, atime);\n  } else {\n    return 0;\n  }\n}\n\nStatus LibHdfsShim::GetRequiredSymbols() {\n  GET_SYMBOL_REQUIRED(this, hdfsNewBuilder);\n  GET_SYMBOL_REQUIRED(this, hdfsBuilderSetNameNode);\n  GET_SYMBOL_REQUIRED(this, hdfsBuilderSetNameNodePort);\n  GET_SYMBOL_REQUIRED(this, hdfsBuilderSetUserName);\n  GET_SYMBOL_REQUIRED(this, hdfsBuilderSetKerbTicketCachePath);\n  GET_SYMBOL_REQUIRED(this, hdfsBuilderSetForceNewInstance);\n  GET_SYMBOL_REQUIRED(this, hdfsBuilderConfSetStr);\n  GET_SYMBOL_REQUIRED(this, hdfsBuilderConnect);\n  GET_SYMBOL_REQUIRED(this, hdfsCreateDirectory);\n  GET_SYMBOL_REQUIRED(this, hdfsDelete);\n  GET_SYMBOL_REQUIRED(this, hdfsDisconnect);\n  GET_SYMBOL_REQUIRED(this, hdfsExists);\n  GET_SYMBOL_REQUIRED(this, hdfsFreeFileInfo);\n  GET_SYMBOL_REQUIRED(this, hdfsGetCapacity);\n  GET_SYMBOL_REQUIRED(this, hdfsGetUsed);\n  GET_SYMBOL_REQUIRED(this, hdfsGetPathInfo);\n  GET_SYMBOL_REQUIRED(this, hdfsListDirectory);\n  GET_SYMBOL_REQUIRED(this, hdfsChown);\n  GET_SYMBOL_REQUIRED(this, hdfsChmod);\n\n  // File methods\n  GET_SYMBOL_REQUIRED(this, hdfsCloseFile);\n  GET_SYMBOL_REQUIRED(this, hdfsFlush);\n  GET_SYMBOL_REQUIRED(this, hdfsOpenFile);\n  GET_SYMBOL_REQUIRED(this, hdfsRead);\n  GET_SYMBOL_REQUIRED(this, hdfsSeek);\n  GET_SYMBOL_REQUIRED(this, hdfsTell);\n  GET_SYMBOL_REQUIRED(this, hdfsWrite);\n\n  return Status::OK();\n}\n\nStatus ConnectLibHdfs(LibHdfsShim** driver) {\n  static std::mutex lock;\n  std::lock_guard<std::mutex> guard(lock);\n\n  LibHdfsShim* shim = &libhdfs_shim;\n\n  static bool shim_attempted = false;\n  if (!shim_attempted) {\n    shim_attempted = true;\n\n    shim->Initialize();\n\n    std::vector<fs::path> libjvm_potential_paths = get_potential_libjvm_paths();\n    RETURN_NOT_OK(try_dlopen(libjvm_potential_paths, \"libjvm\", libjvm_handle));\n\n    std::vector<fs::path> libhdfs_potential_paths = get_potential_libhdfs_paths();\n    RETURN_NOT_OK(try_dlopen(libhdfs_potential_paths, \"libhdfs\", shim->handle));\n  } else if (shim->handle == nullptr) {\n    return Status::IOError(\"Prior attempt to load libhdfs failed\");\n  }\n\n  *driver = shim;\n  return shim->GetRequiredSymbols();\n}\n\nStatus ConnectLibHdfs3(LibHdfsShim** driver) {\n  static std::mutex lock;\n  std::lock_guard<std::mutex> guard(lock);\n\n  LibHdfsShim* shim = &libhdfs3_shim;\n\n  static bool shim_attempted = false;\n  if (!shim_attempted) {\n    shim_attempted = true;\n\n    shim->Initialize();\n\n    std::vector<fs::path> libhdfs3_potential_paths = get_potential_libhdfs3_paths();\n    RETURN_NOT_OK(try_dlopen(libhdfs3_potential_paths, \"libhdfs3\", shim->handle));\n  } else if (shim->handle == nullptr) {\n    return Status::IOError(\"Prior attempt to load libhdfs3 failed\");\n  }\n\n  *driver = shim;\n  return shim->GetRequiredSymbols();\n}\n\n}  // namespace internal\n}  // namespace io\n}  // namespace arrow\n"
    },
    "skipped": [
        "/tmp/vanessa/spack-stage/spack-stage-arrow-0.12.1-5t3jhpxat63jnyckavh6dij4iyabhfhm/spack-src/ruby/red-arrow/image/red-arrow.png",
        "/tmp/vanessa/spack-stage/spack-stage-arrow-0.12.1-5t3jhpxat63jnyckavh6dij4iyabhfhm/spack-src/ruby/red-arrow/test/fixture/TestOrcFile.test1.orc",
        "/tmp/vanessa/spack-stage/spack-stage-arrow-0.12.1-5t3jhpxat63jnyckavh6dij4iyabhfhm/spack-src/c_glib/test/fixture/TestOrcFile.test1.orc",
        "/tmp/vanessa/spack-stage/spack-stage-arrow-0.12.1-5t3jhpxat63jnyckavh6dij4iyabhfhm/spack-src/python/pyarrow/tests/data/orc/TestOrcFile.testDate1900.jsn.gz",
        "/tmp/vanessa/spack-stage/spack-stage-arrow-0.12.1-5t3jhpxat63jnyckavh6dij4iyabhfhm/spack-src/python/pyarrow/tests/data/orc/TestOrcFile.emptyFile.jsn.gz",
        "/tmp/vanessa/spack-stage/spack-stage-arrow-0.12.1-5t3jhpxat63jnyckavh6dij4iyabhfhm/spack-src/python/pyarrow/tests/data/orc/TestOrcFile.testDate1900.orc",
        "/tmp/vanessa/spack-stage/spack-stage-arrow-0.12.1-5t3jhpxat63jnyckavh6dij4iyabhfhm/spack-src/python/pyarrow/tests/data/orc/TestOrcFile.test1.orc",
        "/tmp/vanessa/spack-stage/spack-stage-arrow-0.12.1-5t3jhpxat63jnyckavh6dij4iyabhfhm/spack-src/python/pyarrow/tests/data/orc/TestOrcFile.emptyFile.orc",
        "/tmp/vanessa/spack-stage/spack-stage-arrow-0.12.1-5t3jhpxat63jnyckavh6dij4iyabhfhm/spack-src/python/pyarrow/tests/data/orc/TestOrcFile.test1.jsn.gz",
        "/tmp/vanessa/spack-stage/spack-stage-arrow-0.12.1-5t3jhpxat63jnyckavh6dij4iyabhfhm/spack-src/python/pyarrow/tests/data/orc/decimal.orc",
        "/tmp/vanessa/spack-stage/spack-stage-arrow-0.12.1-5t3jhpxat63jnyckavh6dij4iyabhfhm/spack-src/python/pyarrow/tests/data/orc/decimal.jsn.gz",
        "/tmp/vanessa/spack-stage/spack-stage-arrow-0.12.1-5t3jhpxat63jnyckavh6dij4iyabhfhm/spack-src/python/pyarrow/tests/data/parquet/v0.7.1.some-named-index.parquet",
        "/tmp/vanessa/spack-stage/spack-stage-arrow-0.12.1-5t3jhpxat63jnyckavh6dij4iyabhfhm/spack-src/python/pyarrow/tests/data/parquet/v0.7.1.column-metadata-handling.parquet",
        "/tmp/vanessa/spack-stage/spack-stage-arrow-0.12.1-5t3jhpxat63jnyckavh6dij4iyabhfhm/spack-src/python/pyarrow/tests/data/parquet/v0.7.1.parquet",
        "/tmp/vanessa/spack-stage/spack-stage-arrow-0.12.1-5t3jhpxat63jnyckavh6dij4iyabhfhm/spack-src/python/pyarrow/tests/data/parquet/v0.7.1.all-named-index.parquet",
        "/tmp/vanessa/spack-stage/spack-stage-arrow-0.12.1-5t3jhpxat63jnyckavh6dij4iyabhfhm/spack-src/site/img/native_go_implementation.png",
        "/tmp/vanessa/spack-stage/spack-stage-arrow-0.12.1-5t3jhpxat63jnyckavh6dij4iyabhfhm/spack-src/site/img/shared.png",
        "/tmp/vanessa/spack-stage/spack-stage-arrow-0.12.1-5t3jhpxat63jnyckavh6dij4iyabhfhm/spack-src/site/img/turbodbc_arrow.png",
        "/tmp/vanessa/spack-stage/spack-stage-arrow-0.12.1-5t3jhpxat63jnyckavh6dij4iyabhfhm/spack-src/site/img/simd.png",
        "/tmp/vanessa/spack-stage/spack-stage-arrow-0.12.1-5t3jhpxat63jnyckavh6dij4iyabhfhm/spack-src/site/img/arrow.png",
        "/tmp/vanessa/spack-stage/spack-stage-arrow-0.12.1-5t3jhpxat63jnyckavh6dij4iyabhfhm/spack-src/site/img/copy.png",
        "/tmp/vanessa/spack-stage/spack-stage-arrow-0.12.1-5t3jhpxat63jnyckavh6dij4iyabhfhm/spack-src/site/assets/fast_python_serialization_with_ray_and_arrow/speedups0.png",
        "/tmp/vanessa/spack-stage/spack-stage-arrow-0.12.1-5t3jhpxat63jnyckavh6dij4iyabhfhm/spack-src/site/assets/fast_python_serialization_with_ray_and_arrow/speedups3.png",
        "/tmp/vanessa/spack-stage/spack-stage-arrow-0.12.1-5t3jhpxat63jnyckavh6dij4iyabhfhm/spack-src/site/assets/fast_python_serialization_with_ray_and_arrow/arrow_object.png",
        "/tmp/vanessa/spack-stage/spack-stage-arrow-0.12.1-5t3jhpxat63jnyckavh6dij4iyabhfhm/spack-src/site/assets/fast_python_serialization_with_ray_and_arrow/speedups2.png",
        "/tmp/vanessa/spack-stage/spack-stage-arrow-0.12.1-5t3jhpxat63jnyckavh6dij4iyabhfhm/spack-src/site/assets/fast_python_serialization_with_ray_and_arrow/speedups1.png",
        "/tmp/vanessa/spack-stage/spack-stage-arrow-0.12.1-5t3jhpxat63jnyckavh6dij4iyabhfhm/spack-src/site/assets/fast_python_serialization_with_ray_and_arrow/python_object.png",
        "/tmp/vanessa/spack-stage/spack-stage-arrow-0.12.1-5t3jhpxat63jnyckavh6dij4iyabhfhm/spack-src/cpp/thirdparty/jemalloc/17c897976c60b0e6e4f4a365c751027244dada7a.tar.gz",
        "/tmp/vanessa/spack-stage/spack-stage-arrow-0.12.1-5t3jhpxat63jnyckavh6dij4iyabhfhm/spack-src/docs/source/format/Arrow.graffle",
        "/tmp/vanessa/spack-stage/spack-stage-arrow-0.12.1-5t3jhpxat63jnyckavh6dij4iyabhfhm/spack-src/docs/source/format/Arrow.png",
        "/tmp/vanessa/spack-stage/spack-stage-arrow-0.12.1-5t3jhpxat63jnyckavh6dij4iyabhfhm/spack-src/matlab/test/numeric_datatypes_with_nan_column.feather",
        "/tmp/vanessa/spack-stage/spack-stage-arrow-0.12.1-5t3jhpxat63jnyckavh6dij4iyabhfhm/spack-src/matlab/test/numeric_datatypes_with_nan_row.feather",
        "/tmp/vanessa/spack-stage/spack-stage-arrow-0.12.1-5t3jhpxat63jnyckavh6dij4iyabhfhm/spack-src/matlab/test/numeric_datatypes_6th_variable_name_is_empty.feather",
        "/tmp/vanessa/spack-stage/spack-stage-arrow-0.12.1-5t3jhpxat63jnyckavh6dij4iyabhfhm/spack-src/matlab/test/corrupted_feather_file.feather",
        "/tmp/vanessa/spack-stage/spack-stage-arrow-0.12.1-5t3jhpxat63jnyckavh6dij4iyabhfhm/spack-src/matlab/test/numeric_datatypes_with_no_nulls.feather"
    ],
    "total_files": 2887
}