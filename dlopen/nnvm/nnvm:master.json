{
    "matches": {
        "/tmp/vanessa/spack-stage/spack-stage-nnvm-master-vj4cbvz7jkgehpi7pikyt6zxukco5p24/spack-src/tests/python/frontend/darknet/test_forward.py": "\"\"\"\nCompile Darknet Models\n=====================\nThis article is a test script to test darknet models with NNVM.\nAll the required models and libraries will be downloaded from the internet\nby the script.\n\"\"\"\nimport os\nimport requests\nimport numpy as np\nfrom nnvm import frontend\nfrom nnvm.testing.darknet import __darknetffi__\nimport nnvm.compiler\nimport tvm\nimport sys\nimport urllib\nif sys.version_info >= (3,):\n    import urllib.request as urllib2\nelse:\n    import urllib2\n\ndef _download(url, path, overwrite=False, sizecompare=False):\n    ''' Download from internet'''\n    if os.path.isfile(path) and not overwrite:\n        if sizecompare:\n            file_size = os.path.getsize(path)\n            res_head = requests.head(url)\n            res_get = requests.get(url, stream=True)\n            if 'Content-Length' not in res_head.headers:\n                res_get = urllib2.urlopen(url)\n            urlfile_size = int(res_get.headers['Content-Length'])\n            if urlfile_size != file_size:\n                print(\"exist file got corrupted, downloading\", path, \" file freshly\")\n                _download(url, path, True, False)\n                return\n        print('File {} exists, skip.'.format(path))\n        return\n    print('Downloading from url {} to {}'.format(url, path))\n    try:\n        urllib.request.urlretrieve(url, path)\n        print('')\n    except:\n        urllib.urlretrieve(url, path)\n\nDARKNET_LIB = 'libdarknet.so'\nDARKNETLIB_URL = 'https://github.com/siju-samuel/darknet/blob/master/lib/' \\\n                                    + DARKNET_LIB + '?raw=true'\n_download(DARKNETLIB_URL, DARKNET_LIB)\nLIB = __darknetffi__.dlopen('./' + DARKNET_LIB)\n\ndef test_forward(net):\n    '''Test network with given input image on both darknet and tvm'''\n    def get_darknet_output(net, img):\n        return LIB.network_predict_image(net, img)\n\n    def get_tvm_output(net, img):\n        '''Compute TVM output'''\n        dtype = 'float32'\n        batch_size = 1\n        sym, params = frontend.darknet.from_darknet(net, dtype)\n        data = np.empty([batch_size, img.c, img.h, img.w], dtype)\n        i = 0\n        for c in range(img.c):\n            for h in range(img.h):\n                for k in range(img.w):\n                    data[0][c][h][k] = img.data[i]\n                    i = i + 1\n\n        target = 'llvm'\n        shape_dict = {'data': data.shape}\n        #with nnvm.compiler.build_config(opt_level=2):\n        graph, library, params = nnvm.compiler.build(sym, target, shape_dict, dtype, params=params)\n        ######################################################################\n        # Execute on TVM\n        # ---------------\n        # The process is no different from other examples.\n        from tvm.contrib import graph_runtime\n        ctx = tvm.cpu(0)\n        m = graph_runtime.create(graph, library, ctx)\n        # set inputs\n        m.set_input('data', tvm.nd.array(data.astype(dtype)))\n        m.set_input(**params)\n        m.run()\n        # get outputs\n        out_shape = (net.outputs,)\n        tvm_out = m.get_output(0, tvm.nd.empty(out_shape, dtype)).asnumpy()\n        return tvm_out\n\n    test_image = 'dog.jpg'\n    img_url = 'https://github.com/siju-samuel/darknet/blob/master/data/' + test_image   +'?raw=true'\n    _download(img_url, test_image)\n    img = LIB.letterbox_image(LIB.load_image_color(test_image.encode('utf-8'), 0, 0), net.w, net.h)\n    darknet_output = get_darknet_output(net, img)\n    darknet_out = np.zeros(net.outputs, dtype='float32')\n    for i in range(net.outputs):\n        darknet_out[i] = darknet_output[i]\n    tvm_out = get_tvm_output(net, img)\n    np.testing.assert_allclose(darknet_out, tvm_out, rtol=1e-3, atol=1e-3)\n\ndef test_forward_extraction():\n    '''test extraction model'''\n    model_name = 'extraction'\n    cfg_name = model_name + '.cfg'\n    weights_name = model_name + '.weights'\n    cfg_url = 'https://github.com/pjreddie/darknet/blob/master/cfg/' + cfg_name + '?raw=true'\n    weights_url = 'http://pjreddie.com/media/files/' + weights_name + '?raw=true'\n    _download(cfg_url, cfg_name)\n    _download(weights_url, weights_name)\n    net = LIB.load_network(cfg_name.encode('utf-8'), weights_name.encode('utf-8'), 0)\n    test_forward(net)\n    LIB.free_network(net)\n\ndef test_forward_alexnet():\n    '''test alexnet model'''\n    model_name = 'alexnet'\n    cfg_name = model_name + '.cfg'\n    weights_name = model_name + '.weights'\n    cfg_url = 'https://github.com/pjreddie/darknet/blob/master/cfg/' + cfg_name + '?raw=true'\n    weights_url = 'http://pjreddie.com/media/files/' + weights_name + '?raw=true'\n    _download(cfg_url, cfg_name)\n    _download(weights_url, weights_name)\n    net = LIB.load_network(cfg_name.encode('utf-8'), weights_name.encode('utf-8'), 0)\n    test_forward(net)\n    LIB.free_network(net)\n\ndef test_forward_resnet50():\n    '''test resnet50 model'''\n    model_name = 'resnet50'\n    cfg_name = model_name + '.cfg'\n    weights_name = model_name + '.weights'\n    cfg_url = 'https://github.com/pjreddie/darknet/blob/master/cfg/' + cfg_name + '?raw=true'\n    weights_url = 'http://pjreddie.com/media/files/' + weights_name + '?raw=true'\n    _download(cfg_url, cfg_name)\n    _download(weights_url, weights_name)\n    net = LIB.load_network(cfg_name.encode('utf-8'), weights_name.encode('utf-8'), 0)\n    test_forward(net)\n    LIB.free_network(net)\n\ndef test_forward_yolo():\n    '''test yolo model'''\n    model_name = 'yolo'\n    cfg_name = model_name + '.cfg'\n    weights_name = model_name + '.weights'\n    cfg_url = 'https://github.com/pjreddie/darknet/blob/master/cfg/' + cfg_name + '?raw=true'\n    weights_url = 'http://pjreddie.com/media/files/' + weights_name + '?raw=true'\n    _download(cfg_url, cfg_name)\n    _download(weights_url, weights_name)\n    net = LIB.load_network(cfg_name.encode('utf-8'), weights_name.encode('utf-8'), 0)\n    test_forward(net)\n    LIB.free_network(net)\n\ndef test_forward_convolutional():\n    '''test convolutional layer'''\n    net = LIB.make_network(1)\n    layer = LIB.make_convolutional_layer(1, 224, 224, 3, 32, 1, 3, 2, 0, 1, 0, 0, 0, 0)\n    net.layers[0] = layer\n    net.w = net.h = 224\n    LIB.resize_network(net, 224, 224)\n    test_forward(net)\n    LIB.free_network(net)\n\ndef test_forward_dense():\n    '''test fully connected layer'''\n    net = LIB.make_network(1)\n    layer = LIB.make_connected_layer(1, 75, 20, 1, 0, 0)\n    net.layers[0] = layer\n    net.w = net.h = 5\n    LIB.resize_network(net, 5, 5)\n    test_forward(net)\n    LIB.free_network(net)\n\ndef test_forward_maxpooling():\n    '''test maxpooling layer'''\n    net = LIB.make_network(1)\n    layer = LIB.make_maxpool_layer(1, 224, 224, 3, 2, 2, 0)\n    net.layers[0] = layer\n    net.w = net.h = 224\n    LIB.resize_network(net, 224, 224)\n    test_forward(net)\n    LIB.free_network(net)\n\ndef test_forward_avgpooling():\n    '''test avgerage pooling layer'''\n    net = LIB.make_network(1)\n    layer = LIB.make_avgpool_layer(1, 224, 224, 3)\n    net.layers[0] = layer\n    net.w = net.h = 224\n    LIB.resize_network(net, 224, 224)\n    test_forward(net)\n    LIB.free_network(net)\n\ndef test_forward_batch_norm():\n    '''test batch normalization layer'''\n    net = LIB.make_network(1)\n    layer = LIB.make_convolutional_layer(1, 224, 224, 3, 32, 1, 3, 2, 0, 1, 1, 0, 0, 0)\n    for i in range(32):\n        layer.rolling_mean[i] = np.random.rand(1)\n        layer.rolling_variance[i] = np.random.rand(1)\n    net.layers[0] = layer\n    net.w = net.h = 224\n    LIB.resize_network(net, 224, 224)\n    test_forward(net)\n    LIB.free_network(net)\n\ndef test_forward_shortcut():\n    '''test shortcut layer'''\n    net = LIB.make_network(3)\n    layer_1 = LIB.make_convolutional_layer(1, 224, 224, 3, 32, 1, 3, 2, 0, 1, 0, 0, 0, 0)\n    layer_2 = LIB.make_convolutional_layer(1, 111, 111, 32, 32, 1, 1, 1, 0, 1, 0, 0, 0, 0)\n    layer_3 = LIB.make_shortcut_layer(1, 0, 111, 111, 32, 111, 111, 32)\n    layer_3.activation = 1\n    net.layers[0] = layer_1\n    net.layers[1] = layer_2\n    net.layers[2] = layer_3\n    net.w = net.h = 224\n    LIB.resize_network(net, 224, 224)\n    test_forward(net)\n    LIB.free_network(net)\n\ndef test_forward_reorg():\n    '''test reorg layer'''\n    net = LIB.make_network(2)\n    layer_1 = LIB.make_convolutional_layer(1, 222, 222, 3, 32, 1, 3, 2, 0, 1, 0, 0, 0, 0)\n    layer_2 = LIB.make_reorg_layer(1, 110, 110, 32, 2, 0, 0, 0)\n    net.layers[0] = layer_1\n    net.layers[1] = layer_2\n    net.w = net.h = 222\n    LIB.resize_network(net, 222, 222)\n    test_forward(net)\n    LIB.free_network(net)\n\ndef test_forward_region():\n    '''test region layer'''\n    net = LIB.make_network(2)\n    layer_1 = LIB.make_convolutional_layer(1, 224, 224, 3, 8, 1, 3, 2, 0, 1, 0, 0, 0, 0)\n    layer_2 = LIB.make_region_layer(1, 111, 111, 2, 2, 1)\n    layer_2.softmax = 1\n    net.layers[0] = layer_1\n    net.layers[1] = layer_2\n    net.w = net.h = 224\n    LIB.resize_network(net, 224, 224)\n    test_forward(net)\n    LIB.free_network(net)\n\nif __name__ == '__main__':\n    test_forward_resnet50()\n    test_forward_alexnet()\n    test_forward_extraction()\n    test_forward_yolo()\n    test_forward_convolutional()\n    test_forward_maxpooling()\n    test_forward_avgpooling()\n    test_forward_batch_norm()\n    test_forward_shortcut()\n    test_forward_dense()\n    test_forward_reorg()\n    test_forward_region()\n",
        "/tmp/vanessa/spack-stage/spack-stage-nnvm-master-vj4cbvz7jkgehpi7pikyt6zxukco5p24/spack-src/tutorials/from_darknet.py": "\"\"\"\nTutorial for running Yolo-V2 in Darknet Models\n=====================\n**Author**: `Siju Samuel <https://siju-samuel.github.io/>`_\n\nThis article is an introductory tutorial to deploy darknet models with NNVM.\n\nAll the required models and libraries will be downloaded from the internet\n\nby the script.\n\nThis script runs the YOLO-V2 Model with the bounding boxes\n\nDarknet parsing have dependancy with CFFI and CV2 library\n\nPlease install CFFI and CV2 before executing this script\n\npip install cffi\n\npip install opencv-python\n\"\"\"\nfrom ctypes import *\nimport math\nimport random\nimport nnvm\nimport nnvm.frontend.darknet\nimport nnvm.testing.darknet\nfrom nnvm.testing.darknet import __darknetffi__\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tvm\nimport os, sys, time, urllib, requests\nif sys.version_info >= (3,):\n    import urllib.request as urllib2\n    import urllib.parse as urlparse\nelse:\n    import urllib2\n    import urlparse\n\n######################################################################\n# Set the parameters here.\n# Supported models alexnet, resnet50, resnet152, extraction, yolo\n######################################################################\nmodel_name = 'yolo'\ntest_image = 'dog.jpg'\ntarget = 'llvm'\nctx = tvm.cpu(0)\n######################################################################\n\ndef dlProgress(count, block_size, total_size):\n    \"\"\"Show the download progress.\"\"\"\n    global start_time\n    if count == 0:\n        start_time = time.time()\n        return\n    duration = time.time() - start_time\n    progress_size = int(count * block_size)\n    speed = int(progress_size / (1024 * duration))\n    percent = int(count * block_size * 100 / total_size)\n    sys.stdout.write(\"\\r...%d%%, %d MB, %d KB/s, %d seconds passed\" %\n          (percent, progress_size / (1024 * 1024), speed, duration))\n    sys.stdout.flush()\n\ndef download(url, path, overwrite=False, sizecompare=False):\n    \"\"\"Downloads the file from the internet.\n    Set the input options correctly to overwrite or do the size comparison\n\n    Parameters\n    ----------\n    url : str\n        Operator name, such as Convolution, Connected, etc\n    path : str\n        List of input symbols.\n    overwrite : dict\n        Dict of operator attributes\n    sizecompare : dict\n        Dict of operator attributes\n\n    Returns\n    -------\n    out_name : converted out name of operation\n    sym : nnvm.Symbol\n        Converted nnvm Symbol\n    \"\"\"\n    if os.path.isfile(path) and not overwrite:\n        if (sizecompare):\n            fileSize = os.path.getsize(path)\n            resHead = requests.head(url)\n            resGet = requests.get(url,stream=True)\n            if 'Content-Length' not in resHead.headers :\n                resGet = urllib2.urlopen(url)\n            urlFileSize = int(resGet.headers['Content-Length'])\n            if urlFileSize != fileSize:\n                print (\"exist file got corrupted, downloading\", path , \" file freshly\")\n                download(url, path, True, False)\n                return\n        print('File {} exists, skip.'.format(path))\n        return\n    print('Downloading from url {} to {}'.format(url, path))\n    try:\n        urllib.request.urlretrieve(url, path, reporthook=dlProgress)\n        print('')\n    except:\n        urllib.urlretrieve(url, path, reporthook=dlProgress)\n\n######################################################################\n# Prepare cfg and weights file\n# Pretrained model available https://pjreddie.com/darknet/imagenet/\n# --------------------------------------------------------------------\n# Download cfg and weights file first time.\n\ncfg_name = model_name + '.cfg'\nweights_name = model_name + '.weights'\ncfg_url = 'https://github.com/siju-samuel/darknet/blob/master/cfg/' + \\\n            cfg_name + '?raw=true'\nweights_url = 'http://pjreddie.com/media/files/' + weights_name + '?raw=true'\n\ndownload(cfg_url, cfg_name)\ndownload(weights_url, weights_name)\n\n######################################################################\n# Download and Load darknet library\n# ---------------------------------\n\ndarknet_lib = 'libdarknet.so'\ndarknetlib_url = 'https://github.com/siju-samuel/darknet/blob/master/lib/' + \\\n                        darknet_lib + '?raw=true'\ndownload(darknetlib_url, darknet_lib)\n\n#if the file doesnt exist, then exit normally.\nif os.path.isfile('./' + darknet_lib) is False:\n    exit(0)\n\ndarknet_lib = __darknetffi__.dlopen('./' + darknet_lib)\ncfg = \"./\" + str(cfg_name)\nweights = \"./\" + str(weights_name)\nnet = darknet_lib.load_network(cfg.encode('utf-8'), weights.encode('utf-8'), 0)\ndtype = 'float32'\nbatch_size = 1\nprint(\"Converting darknet to nnvm symbols...\")\nsym, params = nnvm.frontend.darknet.from_darknet(net, dtype)\n\n######################################################################\n# Compile the model on NNVM\n# --------------------------------------------------------------------\n# compile the model\ndata = np.empty([batch_size, net.c ,net.h, net.w], dtype);\nshape = {'data': data.shape}\nprint(\"Compiling the model...\")\nwith nnvm.compiler.build_config(opt_level=2):\n    graph, lib, params = nnvm.compiler.build(sym, target, shape, dtype, params)\n\n#####################################################################\n# Save the json\n# --------------------------------------------------------------------\ndef save_lib():\n    #Save the graph, params and .so to the current directory\n    print(\"Saving the compiled output...\")\n    path_name = 'nnvm_darknet_' + model_name\n    path_lib = path_name + '_deploy_lib.so'\n    lib.export_library(path_lib)\n    with open(path_name\n+ \"deploy_graph.json\", \"w\") as fo:\n        fo.write(graph.json())\n    with open(path_name\n+ \"deploy_param.params\", \"wb\") as fo:\n        fo.write(nnvm.compiler.save_param_dict(params))\n#save_lib()\n\n######################################################################\n# Load a test image\n# --------------------------------------------------------------------\nprint(\"Loading the test image...\")\nimg_url = 'https://github.com/siju-samuel/darknet/blob/master/data/' + \\\n            test_image   +'?raw=true'\ndownload(img_url, test_image)\n\ndata = nnvm.testing.darknet.load_image(test_image, net.w, net.h)\n\n######################################################################\n# Execute on TVM\n# --------------------------------------------------------------------\n# The process is no different from other examples.\nfrom tvm.contrib import graph_runtime\n\nm = graph_runtime.create(graph, lib, ctx)\n\n# set inputs\nm.set_input('data', tvm.nd.array(data.astype(dtype)))\nm.set_input(**params)\n# execute\nprint(\"Running the test image...\")\n\nm.run()\n# get outputs\nout_shape = (net.outputs,)\ntvm_out = m.get_output(0, tvm.nd.empty(out_shape, dtype)).asnumpy()\n\n#do the detection and bring up the bounding boxes\nthresh = 0.24\nhier_thresh = 0.5\nimg = nnvm.testing.darknet.load_image_color(test_image)\n_, im_h, im_w = img.shape\nprobs= []\nboxes = []\nregion_layer = net.layers[net.n - 1]\nboxes, probs = nnvm.testing.yolo2_detection.get_region_boxes(region_layer, im_w, im_h, net.w, net.h,\n                       thresh, probs, boxes, 1, tvm_out)\n\nboxes, probs = nnvm.testing.yolo2_detection.do_nms_sort(boxes, probs,\n                       region_layer.w*region_layer.h*region_layer.n, region_layer.classes, 0.3)\n\ncoco_name = 'coco.names'\ncoco_url = 'https://github.com/siju-samuel/darknet/blob/master/data/' + coco_name   +'?raw=true'\nfont_name = 'arial.ttf'\nfont_url = 'https://github.com/siju-samuel/darknet/blob/master/data/' + font_name   +'?raw=true'\ndownload(coco_url, coco_name)\ndownload(font_url, font_name)\n\nwith open(coco_name) as f:\n    content = f.readlines()\n\nnames = [x.strip() for x in content]\n\nnnvm.testing.yolo2_detection.draw_detections(img, region_layer.w*region_layer.h*region_layer.n,\n                 thresh, boxes, probs, names, region_layer.classes)\nplt.imshow(img.transpose(1,2,0))\nplt.show()\n"
    },
    "skipped": [
        "/tmp/vanessa/spack-stage/spack-stage-nnvm-master-vj4cbvz7jkgehpi7pikyt6zxukco5p24/spack-src/.git/objects/pack/pack-ab82e8d9cdcc48d8652a0f475289350a28156187.pack",
        "/tmp/vanessa/spack-stage/spack-stage-nnvm-master-vj4cbvz7jkgehpi7pikyt6zxukco5p24/spack-src/.git/objects/pack/pack-ab82e8d9cdcc48d8652a0f475289350a28156187.idx"
    ],
    "total_files": 256
}