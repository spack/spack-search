{
    "matches": {
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.20-xigfpbo5yypiin5odq3dedwvkyxa5sxr/spack-src/CMakeLists.txt": "cmake_minimum_required(VERSION 2.8.8)\nmessage(STATUS \"Cmake version ${CMAKE_MAJOR_VERSION}.${CMAKE_MINOR_VERSION}.${CMAKE_PATCH_VERSION}\")\nset(CMAKE_MODULE_PATH ${CMAKE_MODULE_PATH} ${CMAKE_HOME_DIRECTORY}/tools/cmake/Modules)\n\nproject(SimGrid C CXX)\n\n#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#\n#     Check for the compiler        #\n#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#\n\n### Need to set rc ccompiler before enable language\nif(WIN32)\n  SET(CMAKE_RC_COMPILER \"windres\")\nendif()\n\n## \n## Check the C/C++ standard that we need\n##   See also tools/cmake/GCCFlags.cmake that sets our paranoid warning flags\nINCLUDE(CheckCCompilerFlag)\nCHECK_C_COMPILER_FLAG(-fstack-cleaner HAVE_C_STACK_CLEANER)\n\n## Request full debugging flags\nset(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} -g3\")\nset(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -g3\")\nset(CMAKE_Fortran_FLAGS \"${CMAKE_Fortran_FLAGS} -g\")\n\nif (CMAKE_COMPILER_IS_GNUCC)    \n  if (CMAKE_CXX_COMPILER_VERSION VERSION_LESS \"4.7\")\n    message(FATAL_ERROR\n            \"SimGrid needs at least g++ version 4.7 to compile but you have ${CMAKE_CXX_COMPILER_VERSION}.\"\n            \"You need a sufficient support of c++11 to compile SimGrid.\")\n  endif()\nendif()\n\n## We need a decent support of the c++11 standard\ninclude(CheckCXXCompilerFlag)\nCHECK_CXX_COMPILER_FLAG(\"-std=gnu++11\" COMPILER_SUPPORTS_CXX11)\nif(COMPILER_SUPPORTS_CXX11)\n  set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -std=gnu++11\")\nelse() \n  message(FATAL_ERROR \n          \"The compiler ${CMAKE_CXX_COMPILER} (v${CMAKE_CXX_COMPILER_VERSION}) has no C++11 support. \"\n          \"Please install a decent C++ compiler (remove CMakeCache.txt once it's installed).\")\nendif()\n\n### And we need C11 standard, too\ninclude(CheckCCompilerFlag)\nCHECK_C_COMPILER_FLAG(\"-std=gnu11\" COMPILER_SUPPORTS_C11)\nif(COMPILER_SUPPORTS_C11)\n  set(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} -std=gnu11\")\nelse()\n  message(FATAL_ERROR \n          \"The compiler ${CMAKE_C_COMPILER} (v${CMAKE_C_COMPILER_VERSION}) has no C11 support. \"\n          \"Please use a decent C compiler \"\n          \"(note that c++11 support of ${CMAKE_CXX_COMPILER} seems ok).\")\nendif()\nif(APPLE AND (CMAKE_C_COMPILER_VERSION VERSION_LESS \"4.6\"))\n  ### gcc 4.[1-5] cannot compile ucontext on OSX\n  message(STATUS \"Ucontext can't be used with this version of gcc (must be greater than 4.5)\")\n  set(HAVE_UCONTEXT_H 0)\nendif()\n\n### Check threading support\nset(CMAKE_THREAD_PREFER_PTHREAD TRUE)\nfind_package(Threads)\n\n### Setup Options\ninclude(${CMAKE_HOME_DIRECTORY}/tools/cmake/Option.cmake)\n\n### SMPI vs. Fortran\nif ((NOT DEFINED enable_smpi) OR enable_smpi) \n  # First unset the compiler in case we're re-running cmake over a previous\n  # configuration where it was saved as smpiff\n  unset(CMAKE_Fortran_COMPILER)\n  \n  SET(SMPI_FORTRAN 0)\n  if(enable_fortran)\n    enable_language(Fortran OPTIONAL)\n  endif()\n  \n  if(CMAKE_Fortran_COMPILER)\n\n    # Fortran compiler detected: save it, then replace by smpiff\n    set(SMPI_Fortran_COMPILER \"${CMAKE_Fortran_COMPILER}\" CACHE FILEPATH \"The real Fortran compiler\")\n\n\t# Set flags/libs to be used in smpiff\n    if(CMAKE_Fortran_COMPILER_ID MATCHES \"GNU\")\n      set(SMPI_Fortran_FLAGS \"\\\"-fpic\\\" \\\"-ff2c\\\" \\\"-fno-second-underscore\\\"\")\n      set(SMPI_Fortran_LIBS \"\\\"-lgfortran\\\"\")\n    elseif(CMAKE_Fortran_COMPILER_ID MATCHES \"Intel\")\n      set(SMPI_Fortran_FLAGS \"\\\"-fPIC\\\" \\\"-nofor-main\\\"\")\n      set(SMPI_Fortran_LIBS \"\\\"-lifcore\\\"\")\n    elseif(CMAKE_Fortran_COMPILER_ID MATCHES \"PGI|Flang\") # flang\n      set(SMPI_Fortran_FLAGS \"\\\"-fPIC\\\"\")\n      set(SMPI_Fortran_LIBS \"\")\n    endif()\n\n    set(SMPI_FORTRAN 1)\n  endif(CMAKE_Fortran_COMPILER)\n\nendif()\n\n#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#\n#     Build the version number      #\n#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#\n\nset(SIMGRID_VERSION_MAJOR \"3\")\nset(SIMGRID_VERSION_MINOR \"20\")\nset(SIMGRID_VERSION_PATCH \"0\")\n# set(SIMGRID_VERSION_EXTRA \"-DEVEL\") # Extra words to add to version string (e.g. -rc1)\n\nset(SIMGRID_VERSION_DATE  \"2018\") # Year for copyright information\n\nif(${SIMGRID_VERSION_PATCH} EQUAL \"0\")\n  set(release_version \"${SIMGRID_VERSION_MAJOR}.${SIMGRID_VERSION_MINOR}\")\nelse()\n  set(release_version \"${SIMGRID_VERSION_MAJOR}.${SIMGRID_VERSION_MINOR}.${SIMGRID_VERSION_PATCH}\")\nendif()\n\nset(SIMGRID_VERSION_STRING \"SimGrid version ${release_version}${SIMGRID_VERSION_EXTRA}\")\n\nset(libsimgrid_version \"${release_version}\")\nset(libsimgrid-java_version \"${release_version}\")\n\n### SET THE LIBRARY EXTENSION \nif(APPLE)\n  set(LIB_EXE \"dylib\")\nelseif(WIN32)\n  set(LIB_EXE \"a\")\n  set(BIN_EXE \".exe\")\nelse()\n  set(LIB_EXE \"so\")\nendif()\n\nexecute_process(COMMAND ${CMAKE_LINKER} -version OUTPUT_VARIABLE LINKER_VERSION ERROR_VARIABLE LINKER_VERSION)\nstring(REGEX MATCH \"[0-9].[0-9]*\" LINKER_VERSION \"${LINKER_VERSION}\")\n\n### Set the library providing dlopen\nif(\"${CMAKE_SYSTEM}\" MATCHES \"Linux\")\n  find_library(DL_LIBRARY dl)\nendif(\"${CMAKE_SYSTEM}\" MATCHES \"Linux\")\n\n### Find programs and paths\nFIND_PROGRAM(GCOV_PATH gcov)\ninclude(FindPerl)\nif(NOT PERL_FOUND)\n  message(FATAL_ERROR \"Please install Perl to compile SimGrid.\")\nendif()\n\n# tesh.py needs python 3 (or the module python-subprocess32 on python2.8+)\nset(PythonInterp_FIND_VERSION 3)\nset(PythonInterp_FIND_VERSION_COUNT 1)\nset(PythonInterp_FIND_VERSION_MAJOR 3)\ninclude(FindPythonInterp)\nif(NOT PYTHONINTERP_FOUND)\n  message(FATAL_ERROR \"Please install Python (version 3 or higher).\")\nendif()\n\nSET(LIBRARY_OUTPUT_PATH ${CMAKE_BINARY_DIR}/lib)\n\n### Compute the include paths\n\n# Only include public headers by default\ninclude_directories(\n   ${CMAKE_BINARY_DIR}/include\n   ${CMAKE_HOME_DIRECTORY}/include\n)\n\n# Compute the ones that should be added when compiling the library\nset(INTERNAL_INCLUDES\n  ${CMAKE_BINARY_DIR}\n  ${CMAKE_HOME_DIRECTORY}\n  ${CMAKE_HOME_DIRECTORY}/src/include\n  )\n\nif(enable_smpi)\n  set (INTERNAL_INCLUDES ${INTERNAL_INCLUDES} ${CMAKE_HOME_DIRECTORY}/src/smpi/include)\nendif()\n\nif(NOT CMAKE_CROSSCOMPILING AND EXISTS /usr/include/)\n  set(INTERNAL_INCLUDES ${INTERNAL_INCLUDES} /usr/include/)\nendif()\n\nif(WIN32)\n  set(CMAKE_INCLUDE_WIN \"${CMAKE_C_COMPILER}\")\n  set(CMAKE_LIB_WIN \"${CMAKE_C_COMPILER}\")\n  string(REGEX REPLACE \"/bin/gcc.*\" \"/include\"  CMAKE_INCLUDE_WIN \"${CMAKE_INCLUDE_WIN}\")\n  string(REGEX REPLACE \"/bin/gcc.*\" \"/lib\"  CMAKE_LIB_WIN \"${CMAKE_LIB_WIN}\")\n  set(INTERNAL_INCLUDES ${INTERNAL_INCLUDES} ${CMAKE_INCLUDE_WIN})\n  unset(CMAKE_INCLUDE_WIN)\nendif()\n\n# library dependency cannot start with a space (CMP0004), so initialize it with something that is never desactivated.\nset(SIMGRID_DEP \"-lm\") \n\n### Determine the assembly flavor that we need today\nset(HAVE_RAW_CONTEXTS 0)\ninclude(CMakeDetermineSystem)\nIF(CMAKE_SYSTEM_PROCESSOR MATCHES \".86|AMD64|amd64\")\n  IF(CMAKE_SIZEOF_VOID_P EQUAL 4) # 32 bits\n    message(STATUS \"System processor: i686 (${CMAKE_SYSTEM_PROCESSOR}, 32 bits)\")\n    set(SIMGRID_PROCESSOR_i686 1)\n    set(SIMGRID_PROCESSOR_x86_64 0)\n  ELSE()\n    message(STATUS \"System processor: x86_64 (${CMAKE_SYSTEM_PROCESSOR}, 64 bits)\")\n    set(SIMGRID_PROCESSOR_i686 0)\n    set(SIMGRID_PROCESSOR_x86_64 1)\n  ENDIF()\n  if (WIN32)\n    message(STATUS \"Disable fast raw contexts on Windows.\")\n  else()\n    set(HAVE_RAW_CONTEXTS 1)\n  endif()\nELSE()\n  set(SIMGRID_PROCESSOR_i686 0)\n  set(SIMGRID_PROCESSOR_x86_64 0)\nENDIF()\n\ninclude(CheckFunctionExists)\ninclude(CheckTypeSize)\ninclude(CheckIncludeFile)\ninclude(CheckIncludeFiles)\ninclude(CheckLibraryExists)\ninclude(CheckSymbolExists)\n\nset(HAVE_GRAPHVIZ 0)\ninclude(FindGraphviz)\n\nset(SIMGRID_HAVE_LUA 0)\nif(enable_lua)\n  include(FindLuaSimgrid)\nendif()\n\nset(SIMGRID_HAVE_NS3 0)\nif(enable_ns3)\n  include(FindNS3)\n  if (SIMGRID_HAVE_NS3)\n    set(SIMGRID_HAVE_NS3 1)\n    foreach(lib core csma point-to-point internet network applications)\n      set(SIMGRID_DEP \"${SIMGRID_DEP} -lns${NS3_VERSION}-${lib}${NS3_SUFFIX}\")\n    endforeach()\n  else()\n    message(FATAL_ERROR \"Cannot find NS3. Please install it (apt-get install ns3 libns3-dev) or disable that cmake option\")\n  endif()\nendif()\n\nif(WIN32)\n  set(Boost_USE_STATIC_LIBS 1)\nendif()\n\nset(HAVE_PAPI 0)\nif(enable_smpi_papi)\n  include(FindPAPI)\n  if (NOT HAVE_PAPI)\n    message(FATAL_ERROR \"Cannot find PAPI. Please install it (apt-get install papi-tools libpapi-dev) or disable PAPI bindings.\")\n  endif()\nendif()\n\n# Not finding this is perfectly OK\nfind_package(Boost COMPONENTS unit_test_framework)\nif (Boost_UNIT_TEST_FRAMEWORK_FOUND)\n  message(STATUS \"Enabling the Boost-based unit tests.\")\nelse()\n  message(STATUS \"Disabling the Boost-based unit tests -- please install libboost-test-dev.\")\nendif()\n\n\nfind_package(Boost 1.48)\nif(Boost_FOUND)\n  include_directories(${Boost_INCLUDE_DIRS})\nelse()\n  if(APPLE)\n    message(FATAL_ERROR \"Boost libraries not found. Try to install them with 'sudo fink install boost1.53.nopython' (check the exact name with 'fink list boost') or 'sudo brew install boost'\")\n  else()\n    message(FATAL_ERROR \"Boost libraries not found. Install libboost-dev (>= 1.48.0).\")\n  endif()\nendif()\n\nfind_package(Boost COMPONENTS context)\nset(Boost_FOUND 1) # This component is optional\nif(Boost_CONTEXT_FOUND)\n  message(STATUS \"Found Boost.Context\")\n  set(HAVE_BOOST_CONTEXTS 1)\nelse()\n  message (\"   boost        : found.\")\n  message (\"   boost-context: missing. Install libboost-context-dev for this optional feature.\")\n  set(HAVE_BOOST_CONTEXTS 0)\nendif()\n\n# Checks for header libraries functions.\nCHECK_LIBRARY_EXISTS(rt      clock_gettime           \"\" HAVE_POSIX_GETTIME)\n\nset(HAVE_PTHREAD_SETAFFINITY 0)\nCHECK_LIBRARY_EXISTS(pthread pthread_setaffinity_np  \"\" HAVE_PTHREAD_SETAFFINITY)\n\nif(CMAKE_SYSTEM_NAME MATCHES \"Darwin\")\n  set(CMAKE_REQUIRED_DEFINITIONS \"-D_XOPEN_SOURCE=700 -D_DARWIN_C_SOURCE\")\nelseif(MINGW)\n  # Use the GNU version of unusual modifiers like PRIx64\n  add_definitions(-D__USE_MINGW_ANSI_STDIO=1)\n  set(CMAKE_REQUIRED_DEFINITIONS \"-D__USE_MINGW_ANSI_STDIO=1\")\nelse()\n  set(CMAKE_REQUIRED_DEFINITIONS \"-D_GNU_SOURCE\")\nendif()\n\nCHECK_INCLUDE_FILE(\"valgrind/valgrind.h\" HAVE_VALGRIND_H)\nCHECK_INCLUDE_FILE(\"unistd.h\" HAVE_UNISTD_H)\nCHECK_INCLUDE_FILE(\"execinfo.h\" HAVE_EXECINFO_H)\nCHECK_INCLUDE_FILE(\"signal.h\" HAVE_SIGNAL_H)\nCHECK_INCLUDE_FILE(\"sys/param.h\" HAVE_SYS_PARAM_H)\nCHECK_INCLUDE_FILE(\"sys/sysctl.h\" HAVE_SYS_SYSCTL_H)\nCHECK_INCLUDE_FILE(\"ucontext.h\" HAVE_UCONTEXT_H)\nCHECK_INCLUDE_FILE(\"linux/futex.h\" HAVE_FUTEX_H)\n\nCHECK_FUNCTION_EXISTS(backtrace HAVE_BACKTRACE)\nCHECK_FUNCTION_EXISTS(dlfunc HAVE_DLFUNC)\nCHECK_FUNCTION_EXISTS(gettimeofday HAVE_GETTIMEOFDAY)\nCHECK_FUNCTION_EXISTS(nanosleep HAVE_NANOSLEEP)\nCHECK_FUNCTION_EXISTS(getdtablesize HAVE_GETDTABLESIZE)\nCHECK_FUNCTION_EXISTS(sysconf HAVE_SYSCONF)\nCHECK_FUNCTION_EXISTS(popen HAVE_POPEN)\nCHECK_FUNCTION_EXISTS(process_vm_readv HAVE_PROCESS_VM_READV)\nCHECK_FUNCTION_EXISTS(mmap HAVE_MMAP)\nCHECK_FUNCTION_EXISTS(mremap HAVE_MREMAP)\n\nCHECK_SYMBOL_EXISTS(vasprintf stdio.h HAVE_VASPRINTF)\nif(MINGW)\n  # The detection of vasprintf fails on MinGW, assumingly because it's\n  # defined as an inline function in stdio.h instead of a regular\n  # function. So force the result to be 1 despite of the test.\n  set(HAVE_VASPRINTF 1)\nendif()\n\n#Check if __thread is defined\nexecute_process(\n  COMMAND \"${CMAKE_C_COMPILER} ${CMAKE_HOME_DIRECTORY}/tools/cmake/test_prog/prog_thread_storage.c -o testprog\"\n  WORKING_DIRECTORY ${CMAKE_BINARY_DIR}\n  RESULT_VARIABLE HAVE_thread_storage_run)\nfile(REMOVE testprog)\nif(HAVE_thread_storage_run)\n  set(HAVE_THREAD_LOCAL_STORAGE 1)\nelse()\n  set(HAVE_THREAD_LOCAL_STORAGE 0)\nendif()\n\nCHECK_INCLUDE_FILE(\"sys/sendfile.h\" HAVE_SENDFILE_H)\nCHECK_FUNCTION_EXISTS(sendfile HAVE_SENDFILE)\nif(HAVE_SENDFILE_H AND HAVE_SENDFILE)\n  set(HAVE_SENDFILE 1)\nelse()\n  set(HAVE_SENDFILE 0)\nendif()\n\nif(enable_model-checking AND NOT \"${CMAKE_SYSTEM}\" MATCHES \"Linux|FreeBSD\")\n  message(WARNING \"Support for model-checking has not been enabled on ${CMAKE_SYSTEM}: disabling it\")\n  set(enable_model-checking FALSE)\nendif()\n\nif(HAVE_MMAP AND HAVE_THREAD_LOCAL_STORAGE)\n  SET(HAVE_MMALLOC 1)\nelse()\n  SET(HAVE_MMALLOC 0)\n  if(enable_model-checking)\n    message(STATUS \"Warning: support for model-checking has been disabled because you are missing either mmap or __thread.\")\n  endif()\n  SET(enable_model-checking 0)\nendif()\n\nif(enable_jedule)\n  set(SIMGRID_HAVE_JEDULE 1)\nelse()\n  set(SIMGRID_HAVE_JEDULE 0)\nendif()\n\nif(enable_mallocators)\n  SET(SIMGRID_HAVE_MALLOCATOR 1)\nelse()\n  SET(SIMGRID_HAVE_MALLOCATOR 0)\nendif()\n\ninclude(FindLibunwind)\nif(HAVE_LIBUNWIND)\n  SET(SIMGRID_DEP \"${SIMGRID_DEP} ${LIBUNWIND_LIBRARIES}\")\nelse()\n  if(enable_model-checking)\n    message(FATAL_ERROR \"Please install libunwind-dev libdw-dev libelf-dev libevent-dev if you want to compile the SimGrid model checker.\")\n  endif()\nendif()\n\nif(enable_model-checking)\n  find_package(Libdw REQUIRED)\n  find_package(Libelf REQUIRED)\n  find_package(Libevent REQUIRED)\n  include_directories(${LIBDW_INCLUDE_DIR} ${LIBELF_INCLUDE_DIR} ${LIBEVENT_INCLUDE_DIR})\n  set(SIMGRID_DEP \"${SIMGRID_DEP} ${LIBEVENT_LIBRARIES} ${LIBELF_LIBRARIES} ${LIBDW_LIBRARIES}\")\n  set(SIMGRID_HAVE_MC 1)\n  if(\"${CMAKE_SYSTEM}\" MATCHES \"FreeBSD\" AND enable_java)\n    message(WARNING \"FreeBSD + Model-Checking + Java = too much for now. Disabling java\")\n    set(enable_java FALSE)\n  endif()\nelse()\n  SET(SIMGRID_HAVE_MC 0)  \n  set(HAVE_MMALLOC 0)\nendif()\nmark_as_advanced(PATH_LIBDW_H)\nmark_as_advanced(PATH_LIBDW_LIB)\n\nif (enable_model-checking AND enable_ns3)\n  message(FATAL_ERROR \"Cannot activate both model-checking and NS3 bindings: NS3 pull too much dependencies for the MC to work\")\nendif()\n\nif(enable_smpi)\n  SET(HAVE_SMPI 1)\n  if(\"${CMAKE_SYSTEM}\" MATCHES \"Darwin|FreeBSD|Linux\")\n    SET(USE_LIBUTIL 0)\n    SET(HAVE_PRIVATIZATION 1)\n  else()\n    message (STATUS \"Warning:  no support for SMPI automatic privatization on this platform\")\n    SET(HAVE_PRIVATIZATION 0)\n  endif()\nelse()\n  SET(HAVE_SMPI 0)\nendif()\n\n#--------------------------------------------------------------------------------------------------\n### Initialize of CONTEXT THREADS\n\nset(HAVE_THREAD_CONTEXTS 0)\nif(CMAKE_USE_PTHREADS_INIT)\n  ### Test that we have a way to create semaphores\n\n  set(HAVE_SEM_OPEN 0)\n  CHECK_LIBRARY_EXISTS(pthread sem_open \"\" HAVE_SEM_OPEN_LIB)\n  if(HAVE_SEM_OPEN_LIB)\n    try_run(semopen_retval semopen_compilable\n            ${CMAKE_BINARY_DIR}\n            ${CMAKE_HOME_DIRECTORY}/tools/cmake/test_prog/prog_sem_open.c\n\t    LINK_LIBRARIES pthread\n\t    COMPILE_OUTPUT_VARIABLE semopen_compilmsg\n            RUN_OUTPUT_VARIABLE semopen_runmsg)\n    \n    if(semopen_compilable)\n      if(NOT semopen_retval) #\u00a0error if not 0\n        message(STATUS \"sem_open is compilable and executable\")\n\tset(HAVE_SEM_OPEN 1)\n      else()\n        message(STATUS \"Warning: sem_open seems compilable but not executable\")\n        message(STATUS \"Compilation output: ${semopen_compilmsg}\")\n        message(STATUS \"Execution output: ${semopen_runmsg}\")\n        message(STATUS \"Exit value: ${semopen_retval}\")\n      endif()\n    else()\n      message(STATUS \"Warning: sem_open not compilable\")\n      message(STATUS \"Compilation output: ${semopen_compilmsg}\")\n    endif()\n    unset(semopen_compilable)\n    unset(semopen_retval)\n    unset(semopen_runmsg)\n    unset(semopen_compilmsg)\n  endif()\n\n  set(HAVE_SEM_INIT 0)  \n  if(NOT APPLE) # OS X El Capitan deprecates this function\n    CHECK_LIBRARY_EXISTS(pthread sem_init \"\" HAVE_SEM_INIT_LIB)\n  endif()\n  if(HAVE_SEM_INIT_LIB)\n    try_run(seminit_retval seminit_compilable\n            ${CMAKE_BINARY_DIR}\n            ${CMAKE_HOME_DIRECTORY}/tools/cmake/test_prog/prog_sem_init.c\n\t    LINK_LIBRARIES pthread\n\t    COMPILE_OUTPUT_VARIABLE seminit_compilmsg\n            RUN_OUTPUT_VARIABLE seminit_runmsg)\n    \n    if(seminit_compilable)\n      if(NOT seminit_retval) #\u00a0error if not 0\n        message(STATUS \"sem_init is compilable and executable\")\n\tset(HAVE_SEM_INIT 1)\n      else()\n        message(STATUS \"Warning: sem_init seems compilable but not executable\")\n        message(STATUS \"Compilation output: ${seminit_compilmsg}\")\n        message(STATUS \"Execution output: ${seminit_runmsg}\")\n        message(STATUS \"Exit value: ${seminit_retval}\")\n      endif()\n    else()\n      message(STATUS \"Warning: sem_init not compilable\")\n      message(STATUS \"Compilation output: ${seminit_compilmsg}\")\n    endif()\n    unset(seminit_compilable)\n    unset(seminit_retval)\n    unset(seminit_runmsg)\n    unset(seminit_compilmsg)\n  endif()\n\n  if(NOT HAVE_SEM_OPEN AND NOT HAVE_SEM_INIT)\n    message(FATAL_ERROR \"Semaphores are not usable (failed to use both sem_open and sem_init), but they are mandatory to threads (you may need to mount /dev).\")\n  endif()\n\n  set(HAVE_THREAD_CONTEXTS 1)\n  message(STATUS \"Support for thread context factory ok.\")\nendif()\n\nset(HAVE_UCONTEXT_CONTEXTS 0)\nif(NOT HAVE_UCONTEXT_H)\n  message(STATUS \"No ucontext factory: <ucontext.h> not found.\")\nelseif(APPLE)\n  message(STATUS \"No ucontext factory: Apple don't want us to use them.\")\n  set(HAVE_UCONTEXT_H 0)\nelse()\n  try_compile(compile_makecontext ${CMAKE_BINARY_DIR} ${CMAKE_HOME_DIRECTORY}/tools/cmake/test_prog/prog_makecontext.c\n    OUTPUT_VARIABLE compile_makecontext_output)\n\n  #If can have both context\n  if(compile_makecontext)\n    set(HAVE_UCONTEXT_CONTEXTS 1)\n    message(STATUS \"Support for ucontext factory ok.\")\n  else()\n    message(STATUS \"Error: <ucontext.h> exists, but makecontext is not compilable. Compilation output:\\n ${compile_makecontext_output}\")\n    message(STATUS \"No ucontext factory: makecontext() is not compilable.\")\n  endif()\n\n  # Stack setup (size and address)\n  try_run(RUN_makecontext_VAR COMPILE_makecontext_VAR\n    ${CMAKE_BINARY_DIR} ${CMAKE_HOME_DIRECTORY}/tools/cmake/test_prog/prog_stacksetup.c\n    RUN_OUTPUT_VARIABLE stack_setup)\n\n  LIST(LENGTH stack_setup stack_setup_len)\n  if(\"${stack_setup_len}\" STREQUAL \"2\")\n    LIST(GET stack_setup 0 makecontext_addr)\n    LIST(GET stack_setup 1 makecontext_size)\n    set(sg_makecontext_stack_addr \"#define sg_makecontext_stack_addr(skaddr) (${makecontext_addr})\")\n    set(sg_makecontext_stack_size \"#define sg_makecontext_stack_size(sksize) (${makecontext_size})\")\n  else()\n    message(FATAL_ERROR \"Could not figure out the stack setup. Compil: ${RUN_makecontext_VAR}. Exec: ${COMPILE_makecontext_VAR}. Output: ${stack_setup}\")\n  endif()\nendif()\n\n# Stack growth direction (upward or downward). Used for the following contexts: SysV, raw, Boost\ntry_run(RUN_stackgrowth_VAR COMPILE_stackgrowth_VAR\n  ${CMAKE_BINARY_DIR}\n  ${CMAKE_HOME_DIRECTORY}/tools/cmake/test_prog/prog_stackgrowth.c\n  RUN_OUTPUT_VARIABLE stack\n  COPY_FILE test_stackgrowth)\n\nif(\"${stack}\" STREQUAL \"down\")\n  set(PTH_STACKGROWTH \"-1\")\nelseif(\"${stack}\" STREQUAL \"up\")\n  set(PTH_STACKGROWTH \"1\")\nelse()\n  if(\"${CMAKE_SYSTEM_PROCESSOR}\" STREQUAL \"x86_64\")\n    set(PTH_STACKGROWTH \"-1\")\n  elseif(\"${CMAKE_SYSTEM_PROCESSOR}\" STREQUAL \"i686\")\n    set(PTH_STACKGROWTH \"-1\")\n  else()\n    message(FATAL_ERROR \"Could not figure out the stack direction. Test prog returned: ${stack}; CMAKE_SYSTEM_PROCESSOR: ${CMAKE_SYSTEM_PROCESSOR}.\")\n  endif()\nendif()\n# If the test ran well, remove the test binary\nfile(REMOVE test_stackgrowth)\n#--------------------------------------------------------------------------------------------------\n\n### check for addr2line\nfind_path(ADDR2LINE NAMES addr2line\tPATHS NO_DEFAULT_PATHS)\nif(ADDR2LINE)\n  set(ADDR2LINE \"${ADDR2LINE}/addr2line\")\nendif()\n\n###############\n## GIT version check\n##\nif(EXISTS ${CMAKE_HOME_DIRECTORY}/.git/)\n  execute_process(\n     COMMAND git remote\n     COMMAND head -n 1\n     WORKING_DIRECTORY ${CMAKE_HOME_DIRECTORY}/.git/\n     OUTPUT_VARIABLE remote\n     OUTPUT_STRIP_TRAILING_WHITESPACE)\n  #message(STATUS \"Git remote: ${remote}\")\n  execute_process(COMMAND git config --get remote.${remote}.url\n     WORKING_DIRECTORY ${CMAKE_HOME_DIRECTORY}/.git/\n     OUTPUT_VARIABLE url\n     OUTPUT_STRIP_TRAILING_WHITESPACE)\n  #message(STATUS \"Git url: ${url}\")\n  if(url)\n    execute_process(COMMAND git --git-dir=${CMAKE_HOME_DIRECTORY}/.git log --pretty=oneline --abbrev-commit -1\n       WORKING_DIRECTORY ${CMAKE_HOME_DIRECTORY}/.git/\n       OUTPUT_VARIABLE GIT_VERSION\n       OUTPUT_STRIP_TRAILING_WHITESPACE)\n    message(STATUS \"Git version: ${GIT_VERSION}\")\n\n    execute_process(COMMAND git --git-dir=${CMAKE_HOME_DIRECTORY}/.git log -n 1 --pretty=format:%ai .\n       WORKING_DIRECTORY ${CMAKE_HOME_DIRECTORY}/.git/\n       OUTPUT_VARIABLE GIT_DATE \n       OUTPUT_STRIP_TRAILING_WHITESPACE)\n    message(STATUS \"Git date: ${GIT_DATE}\")\n    string(REGEX REPLACE \" .*\" \"\" GIT_VERSION \"${GIT_VERSION}\")\n\n    execute_process(COMMAND git --git-dir=${CMAKE_HOME_DIRECTORY}/.git log --pretty=format:%H -1\n       WORKING_DIRECTORY ${CMAKE_HOME_DIRECTORY}/.git/\n       OUTPUT_VARIABLE SIMGRID_GITHASH\n       OUTPUT_STRIP_TRAILING_WHITESPACE)\n  endif()\nelseif(EXISTS ${CMAKE_HOME_DIRECTORY}/.gitversion)\n  FILE(STRINGS ${CMAKE_HOME_DIRECTORY}/.gitversion GIT_VERSION)\nelse()\n  set(GIT_VERSION \"none, release version\")\nendif()\n\n### Setup gcc & clang flags\nif (NOT MSVC)\n  include(${CMAKE_HOME_DIRECTORY}/tools/cmake/GCCFlags.cmake)\nendif()\n\n### Generate the required headers and scripts\n#############################################\n\n# Avoid triggering a (full) rebuild by touching the files if they did not really change\nconfigure_file(\"${CMAKE_HOME_DIRECTORY}/tools/cmake/src/internal_config.h.in\" \"${CMAKE_BINARY_DIR}/src/internal_config.h.generated\"    @ONLY IMMEDIATE)\nconfigure_file(\"${CMAKE_HOME_DIRECTORY}/include/simgrid/config.h.in\"          \"${CMAKE_BINARY_DIR}/include/simgrid/config.h.generated\" @ONLY IMMEDIATE)\nexecute_process(COMMAND ${CMAKE_COMMAND} -E copy_if_different ${CMAKE_BINARY_DIR}/src/internal_config.h.generated ${CMAKE_BINARY_DIR}/src/internal_config.h)\nexecute_process(COMMAND ${CMAKE_COMMAND} -E copy_if_different ${CMAKE_BINARY_DIR}/include/simgrid/config.h.generated ${CMAKE_BINARY_DIR}/include/simgrid/config.h)\nfile(REMOVE ${CMAKE_BINARY_DIR}/src/internal_config.h.generated)\nfile(REMOVE ${CMAKE_BINARY_DIR}/include/simgrid/config.h.generated)\n\n# We need two versions of the SMPI scripts because they contain the path to the library\n# so, it depends of whether SimGrid is installed, or run from the sources (during the build)\n\nfile(READ ${CMAKE_HOME_DIRECTORY}/src/smpi/smpitools.sh SMPITOOLS_SH) # Definitions shared amongst all SMPI scripts, inlined in each of them\n\n### SMPI script used when simgrid is installed\nset(exec_prefix ${CMAKE_INSTALL_PREFIX})\nset(includeflag \"-I${CMAKE_INSTALL_PREFIX}/include -I${CMAKE_INSTALL_PREFIX}/include/smpi\")\nset(includedir \"${CMAKE_INSTALL_PREFIX}/include\")\nset(libdir ${exec_prefix}/lib)\nset(CMAKE_SMPI_COMMAND \"export LD_LIBRARY_PATH=\\\"${CMAKE_INSTALL_PREFIX}/lib\")\nif(NS3_LIBRARY_PATH)\n  set(CMAKE_SMPI_COMMAND \"${CMAKE_SMPI_COMMAND}:${NS3_LIBRARY_PATH}\")\nendif()\nset(CMAKE_SMPI_COMMAND \"${CMAKE_SMPI_COMMAND}:\\${LD_LIBRARY_PATH:+:$LD_LIBRARY_PATH}\\\"\")\nset(SMPIMAIN smpimain)\n\nconfigure_file(${CMAKE_HOME_DIRECTORY}/include/smpi/mpif.h.in ${CMAKE_BINARY_DIR}/include/smpi/mpif.h @ONLY)\n#configure mpif.f90 to build mpi.mod\nif(SMPI_FORTRAN)\n  set(MODULE_MPIF_IN \"module mpi\")\n  set(MODULE_MPIF_OUT \"end module mpi\")\n  configure_file(${CMAKE_HOME_DIRECTORY}/include/smpi/mpif.h.in ${CMAKE_BINARY_DIR}/src/smpi/mpif.f90.generated @ONLY)\n  execute_process(COMMAND ${CMAKE_COMMAND} -E copy_if_different ${CMAKE_BINARY_DIR}/src/smpi/mpif.f90.generated ${CMAKE_BINARY_DIR}/src/smpi/mpif.f90)\n  set(CMAKE_Fortran_MODULE_DIRECTORY ${CMAKE_BINARY_DIR}/include/smpi)\n  add_library(mpi SHARED ${CMAKE_BINARY_DIR}/src/smpi/mpif.f90)\nendif()\n\nforeach(script cc cxx ff f90 run)\n  configure_file(${CMAKE_HOME_DIRECTORY}/src/smpi/smpi${script}.in ${CMAKE_BINARY_DIR}/bin/smpi${script} @ONLY)\nendforeach()\n\n### SMPI scripts used when compiling simgrid \nset(exec_prefix \"${CMAKE_BINARY_DIR}/smpi_script/\")\nset(includeflag \"-I${CMAKE_HOME_DIRECTORY}/include -I${CMAKE_HOME_DIRECTORY}/include/smpi\")\nset(includeflag \"${includeflag} -I${CMAKE_BINARY_DIR}/include -I${CMAKE_BINARY_DIR}/include/smpi\")\nset(includedir \"${CMAKE_HOME_DIRECTORY}/include\")\nset(libdir \"${CMAKE_BINARY_DIR}/lib\")\nset(CMAKE_SMPI_COMMAND \"export LD_LIBRARY_PATH=\\\"${CMAKE_BINARY_DIR}/lib\")\nif(NS3_LIBRARY_PATH)\n  set(CMAKE_SMPI_COMMAND \"${CMAKE_SMPI_COMMAND}:${NS3_LIBRARY_PATH}\")\nendif()\nset(CMAKE_SMPI_COMMAND \"${CMAKE_SMPI_COMMAND}:\\${LD_LIBRARY_PATH:+:$LD_LIBRARY_PATH}\\\"\")\nset(SMPIMAIN ${CMAKE_BINARY_DIR}/bin/smpimain)\n\nforeach(script cc cxx ff f90 run)\n  configure_file(${CMAKE_HOME_DIRECTORY}/src/smpi/smpi${script}.in ${CMAKE_BINARY_DIR}/smpi_script/bin/smpi${script} @ONLY)\nendforeach()\n\nif(NOT WIN32)\n  foreach(script cc cxx ff f90 run)\n    execute_process(COMMAND chmod a=rwx ${CMAKE_BINARY_DIR}/bin/smpi${script})\n    execute_process(COMMAND chmod a=rwx ${CMAKE_BINARY_DIR}/smpi_script/bin/smpi${script})\n  endforeach()\nendif()\n\nset(generated_headers_to_install\n  ${CMAKE_CURRENT_BINARY_DIR}/include/smpi/mpif.h\n  ${CMAKE_CURRENT_BINARY_DIR}/include/simgrid/config.h\n  )\n\nset(generated_headers  ${CMAKE_CURRENT_BINARY_DIR}/src/internal_config.h )\n\nset(generated_files_to_clean\n  ${generated_headers}\n  ${generated_headers_to_install}\n  ${CMAKE_BINARY_DIR}/bin/smpicc\n  ${CMAKE_BINARY_DIR}/bin/smpicxx\n  ${CMAKE_BINARY_DIR}/bin/smpiff\n  ${CMAKE_BINARY_DIR}/bin/smpif90\n  ${CMAKE_BINARY_DIR}/bin/smpirun\n  ${CMAKE_BINARY_DIR}/bin/colorize\n  ${CMAKE_BINARY_DIR}/bin/simgrid_update_xml\n  ${CMAKE_BINARY_DIR}/examples/smpi/tracing/smpi_traced.trace\n  )\n\nif(NOT \"${CMAKE_BINARY_DIR}\" STREQUAL \"${CMAKE_HOME_DIRECTORY}\")\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay/actions0.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions0.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay/actions1.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions1.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay/actions_allreduce.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions_allreduce.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay/actions_barrier.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions_barrier.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay/actions_bcast.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions_bcast.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay/actions_with_isend.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions_with_isend.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay/actions_alltoall.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions_alltoall.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay/actions_alltoallv.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions_alltoallv.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay/actions_waitall.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions_waitall.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay/actions_reducescatter.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions_reducescatter.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay/actions_gather.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions_gather.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay/actions_allgatherv.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions_allgatherv.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/hostfile ${CMAKE_BINARY_DIR}/teshsuite/smpi/hostfile COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/hostfile_cluster ${CMAKE_BINARY_DIR}/teshsuite/smpi/hostfile_cluster COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/hostfile_coll ${CMAKE_BINARY_DIR}/teshsuite/smpi/hostfile_coll COPYONLY)\n\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/description_file ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/description_file COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/README ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/README COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/smpi_replay.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/smpi_replay.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace0.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace0.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace1.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace1.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace2.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace2.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace3.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace3.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace4.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace4.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace5.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace5.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace6.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace6.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace7.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace7.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace8.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace8.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace9.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace9.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace10.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace10.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace11.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace11.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace12.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace12.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace13.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace13.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace14.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace14.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace15.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace15.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace16.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace16.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace17.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace17.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace18.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace18.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace19.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace19.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace20.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace20.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace21.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace21.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace22.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace22.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace23.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace23.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace24.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace24.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace25.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace25.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace26.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace26.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace27.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace27.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace28.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace28.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace29.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace29.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace30.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace30.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace31.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace31.txt COPYONLY)\n\n  set(generated_files_to_clean\n    ${generated_files_to_clean}\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions0.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions1.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions_allreduce.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions_barrier.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions_bcast.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions_with_isend.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions_alltoall.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions_alltoallv.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions_waitall.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions_gather.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions_allgatherv.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions_reducescatter.txt\n    ${CMAKE_BINARY_DIR}/teshsuite/smpi/hostfile\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/description_file\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/README\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/smpi_replay.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace0.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace1.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace2.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace3.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace4.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace5.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace6.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace7.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace8.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace9.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace10.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace11.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace12.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace13.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace14.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace15.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace16.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace17.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace18.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace19.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace20.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace21.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace22.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace23.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace24.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace25.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace26.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace27.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace28.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace29.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace30.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace31.txt\n    )\nendif()\n\nSET_DIRECTORY_PROPERTIES(PROPERTIES ADDITIONAL_MAKE_CLEAN_FILES\n  \"${generated_files_to_clean}\")\n\n### Define source packages for Libs\ninclude(${CMAKE_HOME_DIRECTORY}/tools/cmake/DefinePackages.cmake)\n\n### Build some Maintainer files\ninclude(${CMAKE_HOME_DIRECTORY}/tools/cmake/MaintainerMode.cmake)\ninclude(${CMAKE_HOME_DIRECTORY}/tools/cmake/UnitTesting.cmake)\n\n### Make Libs\nif(NOT WIN32)\n  include(${CMAKE_HOME_DIRECTORY}/tools/cmake/MakeLib.cmake)\nelse()\n  include(${CMAKE_HOME_DIRECTORY}/tools/cmake/MakeLibWin.cmake)\nendif()\n\nif(enable_java)\n  include(${CMAKE_HOME_DIRECTORY}/tools/cmake/Java.cmake)\nendif()\n\n### Make tests\nif(enable_memcheck_xml)\n  set(enable_memcheck true)\nendif()\n\nINCLUDE(CTest)\nENABLE_TESTING()\ninclude(${CMAKE_HOME_DIRECTORY}/tools/cmake/Tests.cmake)\ninclude(${CMAKE_HOME_DIRECTORY}/tools/cmake/CTestConfig.cmake)\n\n### Define subdirectories\nforeach(cmakefile ${CMAKEFILES_TXT})\n  string(REPLACE \"/CMakeLists.txt\" \"\" repository ${cmakefile})\n  add_subdirectory(\"${CMAKE_HOME_DIRECTORY}/${repository}\")\nendforeach()\n\n### Setup the distrib\ninclude(${CMAKE_HOME_DIRECTORY}/tools/cmake/Distrib.cmake)\n\n### Build the docs if asked to\ninclude(${CMAKE_HOME_DIRECTORY}/tools/cmake/Documentation.cmake)\n\n### Print the result of configuration\nmessage(\"\")\nmessage(\"##########################################\")\nmessage(\"#### Content of src/internal_config.h ####\")\nmessage(\"##########################################\")\nfile(STRINGS ${CMAKE_CURRENT_BINARY_DIR}/src/internal_config.h config_output)\nLIST(REMOVE_AT config_output 0 1 2 3 4 5 6 7 8 9 10) # Pass the file header\nforeach(line ${config_output})\n  message(\"   ${line}\")\nendforeach()\nmessage(\"##########################################\")\nmessage(\"####   Content of simgrid/config.h    ####\")\nmessage(\"##########################################\")\nfile(STRINGS ${CMAKE_CURRENT_BINARY_DIR}/include/simgrid/config.h config_output)\nLIST(REMOVE_AT config_output 0 1 2 3 4 5 6 7 8 9 -1) # Pass the file header\nforeach(line ${config_output})\n  message(\"   ${line}\")\nendforeach()\nmessage(\"##########################################\")\nmessage(\"####   End of configuration headers   ####\")\nmessage(\"##########################################\")\n\nmessage(\"\\nConfiguration of package `simgrid':\")\nmessage(\"        Home directory ..............: ${CMAKE_HOME_DIRECTORY}\")\nmessage(\"        Build Name ..................: ${BUILDNAME}\")\nmessage(\"        Cmake Generator .............: ${CMAKE_GENERATOR}\")\nmessage(\"        Site ........................: ${SITE}\")\nmessage(\"        Install prefix ..............: ${CMAKE_INSTALL_PREFIX}\")\nif(release)\n  message(\"        Release .....................: simgrid-${release_version}${SIMGRID_VERSION_EXTRA} (release build)\")\nelse()\n  message(\"        Release .....................: simgrid-${release_version}${SIMGRID_VERSION_EXTRA} (development build)\")\nendif()\nmessage(\"\")\nmessage(\"        Compiler: C .................: ${CMAKE_C_COMPILER} (id: ${CMAKE_C_COMPILER_ID})\")\nmessage(\"                version .............: ${CMAKE_C_COMPILER_VERSION}\")\nmessage(\"                is gnu ..............: ${CMAKE_COMPILER_IS_GNUCC}\")\nmessage(\"        Compiler: C++ ...............: ${CMAKE_CXX_COMPILER} (id: ${CMAKE_CXX_COMPILER_ID})\")\nmessage(\"                version .............: ${CMAKE_CXX_COMPILER_VERSION}\")\nif(${Java_FOUND})\n  message(\"        Compiler: Javac .............: ${Java_JAVAC_EXECUTABLE}\")\n  message(\"                version .............: ${Java_VERSION_STRING}\")\nendif()\nif(CMAKE_Fortran_COMPILER)\n  message(\"        Compiler: Fortran ...........: ${SMPI_Fortran_COMPILER} (id: ${CMAKE_Fortran_COMPILER_ID})\")\n  message(\"                version .............: ${CMAKE_Fortran_COMPILER_VERSION}\")\nendif()\nmessage(\"        Linker: .....................: ${CMAKE_LINKER}\")\nmessage(\"                version .............: ${LINKER_VERSION}\")\nmessage(\"        Make program: ...............: ${CMAKE_MAKE_PROGRAM}\")\nmessage(\"\")\nmessage(\"        CFlags ......................: ${CMAKE_C_FLAGS}\")\nmessage(\"        CXXFlags ....................: ${CMAKE_CXX_FLAGS}\")\nmessage(\"        LDFlags .....................: ${CMAKE_C_LINK_FLAGS}\")\nmessage(\"        with LTO ....................: ${enable_lto}\")\nmessage(\"\")\n\nif (SIMGRID_HAVE_NS3)\n  message(\"        Compile NS-3 ................: yes (path: ${NS3_PATH})\")\nelse()\n  message(\"        Compile NS-3 ................: NO  (hint: ${NS3_HINT})\")\nendif()\n\nif (${Java_FOUND})\n  message(\"        Compile Java ................: yes\")\n  message(\"          Native lib in jar .........: ${enable_lib_in_jar}\")\nelse()\n  message(\"        Compile Java ................: NO\")\nendif()\nmessage(\"        Compile Lua .................: ${SIMGRID_HAVE_LUA}\")\nmessage(\"        Compile Smpi ................: ${HAVE_SMPI}\")\nmessage(\"          Smpi fortran ..............: ${SMPI_FORTRAN}\")\nmessage(\"          MPICH3 testsuite ..........: ${enable_smpi_MPICH3_testsuite}\")\nmessage(\"          Privatization .............: ${HAVE_PRIVATIZATION}\")\nmessage(\"          PAPI support...............: ${HAVE_PAPI}\")\nmessage(\"        Compile Boost.Context support: ${HAVE_BOOST_CONTEXTS}\")\nmessage(\"\")\nmessage(\"        Maintainer mode .............: ${enable_maintainer_mode}\")\nmessage(\"        Documentation................: ${enable_documentation}\")\nmessage(\"        Model checking ..............: ${SIMGRID_HAVE_MC}\")\nmessage(\"        Jedule  mode ................: ${SIMGRID_HAVE_JEDULE}\")\nmessage(\"        Graphviz mode ...............: ${HAVE_GRAPHVIZ}\")\nmessage(\"        Mallocators .................: ${enable_mallocators}\")\nmessage(\"\")\nmessage(\"        Simgrid dependencies ........: ${SIMGRID_DEP}\")\nmessage(\"\")\n\nexecute_process(COMMAND ${CMAKE_COMMAND} -E make_directory ${PROJECT_BINARY_DIR}/Testing/Notes/)\nfile(WRITE ${PROJECT_BINARY_DIR}/Testing/Notes/Build  \"GIT version : ${GIT_VERSION}\\n\")\nfile(APPEND ${PROJECT_BINARY_DIR}/Testing/Notes/Build \"Release     : simgrid-${release_version}\\n\")\n\nINCLUDE(Dart)\n",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.20-xigfpbo5yypiin5odq3dedwvkyxa5sxr/spack-src/src/simgrid/sg_config.cpp": "/* Copyright (c) 2009-2018. The SimGrid Team. All rights reserved.          */\n\n/* This program is free software; you can redistribute it and/or modify it\n * under the terms of the license (GNU LGPL) which comes with this package. */\n\n/* sg_config: configuration infrastructure for the simulation world         */\n\n#include \"simgrid/sg_config.hpp\"\n#include \"simgrid/instr.h\"\n#include \"src/instr/instr_private.hpp\"\n#include \"src/internal_config.h\"\n#include \"src/kernel/lmm/maxmin.hpp\"\n#include \"src/mc/mc_config.hpp\"\n#include \"src/mc/mc_replay.hpp\"\n#include \"src/surf/surf_interface.hpp\"\n#include \"surf/surf.hpp\"\n#include \"xbt/config.hpp\"\n\nXBT_LOG_NEW_DEFAULT_SUBCATEGORY(surf_config, surf, \"About the configuration of SimGrid\");\n\n/* 0: beginning of time (config cannot be changed yet)\n * 1: initialized: cfg_set created (config can now be changed)\n * 2: configured: command line parsed and config part of platform file was\n *    integrated also, platform construction ongoing or done.\n *    (Config cannot be changed anymore!)\n */\nint _sg_cfg_init_status = 0;\n\n/* instruct the upper layer (simix or simdag) to exit as soon as possible */\nbool _sg_cfg_exit_asap = false;\n\n#define sg_cfg_exit_early()                                                                                            \\\n  do {                                                                                                                 \\\n    _sg_cfg_exit_asap = true;                                                                                          \\\n    return;                                                                                                            \\\n  } while (0)\n\n/* Parse the command line, looking for options */\nstatic void sg_config_cmd_line(int *argc, char **argv)\n{\n  int shall_exit = 0;\n  int i;\n  int j;\n\n  for (j = i = 1; i < *argc; i++) {\n    if (not strncmp(argv[i], \"--cfg=\", strlen(\"--cfg=\"))) {\n      char *opt = strchr(argv[i], '=');\n      opt++;\n\n      simgrid::config::set_parse(opt);\n      XBT_DEBUG(\"Did apply '%s' as config setting\", opt);\n    } else if (not strcmp(argv[i], \"--version\")) {\n      printf(\"%s\\n\", SIMGRID_VERSION_STRING);\n      shall_exit = 1;\n    } else if (not strcmp(argv[i], \"--cfg-help\") || not strcmp(argv[i], \"--help\")) {\n      printf(\"Description of the configuration accepted by this simulator:\\n\");\n      simgrid::config::help();\n      printf(\n          \"\\n\"\n          \"Each of these configurations can be used by adding\\n\"\n          \"    --cfg=<option name>:<option value>\\n\"\n          \"to the command line.\\n\"\n          \"\\n\"\n          \"For more information, please refer to:\\n\"\n          \"   --help-aliases for the list of all option aliases.\\n\"\n          \"   --help-logs and --help-log-categories for the details of logging output.\\n\"\n          \"   --help-models for a list of all models known by this simulator.\\n\"\n          \"   --help-tracing for the details of all tracing options known by this simulator.\\n\"\n          \"   --version to get SimGrid version information.\\n\"\n          \"\\n\"\n        );\n      shall_exit = 1;\n    } else if (not strcmp(argv[i], \"--help-aliases\")) {\n      printf(\"Here is a list of all deprecated option names, with their replacement.\\n\");\n      simgrid::config::show_aliases();\n      printf(\"Please consider using the recent names\\n\");\n      shall_exit = 1;\n    } else if (not strcmp(argv[i], \"--help-models\")) {\n      model_help(\"host\", surf_host_model_description);\n      printf(\"\\n\");\n      model_help(\"CPU\", surf_cpu_model_description);\n      printf(\"\\n\");\n      model_help(\"network\", surf_network_model_description);\n      printf(\"\\nLong description of all optimization levels accepted by the models of this simulator:\\n\");\n      for (int k = 0; surf_optimization_mode_description[k].name; k++)\n        printf(\"  %s: %s\\n\",\n               surf_optimization_mode_description[k].name,\n               surf_optimization_mode_description[k].description);\n      printf(\"Both network and CPU models have 'Lazy' as default optimization level\\n\\n\");\n      shall_exit = 1;\n    } else if (not strcmp(argv[i], \"--help-tracing\")) {\n      TRACE_help();\n      shall_exit = 1;\n    } else {\n      argv[j++] = argv[i];\n    }\n  }\n  if (j < *argc) {\n    argv[j] = nullptr;\n    *argc = j;\n  }\n  if (shall_exit)\n    sg_cfg_exit_early();\n}\n\n/* callback of the plugin variable */\nstatic void _sg_cfg_cb__plugin(const std::string& value)\n{\n  xbt_assert(_sg_cfg_init_status < 2, \"Cannot load a plugin after the initialization\");\n\n  if (value.empty())\n    return;\n\n  if (value == \"help\") {\n    model_help(\"plugin\", surf_plugin_description);\n    sg_cfg_exit_early();\n  }\n\n  int plugin_id = find_model_description(surf_plugin_description, value);\n  surf_plugin_description[plugin_id].model_init_preparse();\n}\n\n/* callback of the host/model variable */\nstatic void _sg_cfg_cb__host_model(const std::string& value)\n{\n  xbt_assert(_sg_cfg_init_status < 2, \"Cannot change the model after the initialization\");\n\n  if (value == \"help\") {\n    model_help(\"host\", surf_host_model_description);\n    sg_cfg_exit_early();\n  }\n\n  /* Make sure that the model exists */\n  find_model_description(surf_host_model_description, value);\n}\n\n/* callback of the cpu/model variable */\nstatic void _sg_cfg_cb__cpu_model(const std::string& value)\n{\n  xbt_assert(_sg_cfg_init_status < 2, \"Cannot change the model after the initialization\");\n\n  if (value == \"help\") {\n    model_help(\"CPU\", surf_cpu_model_description);\n    sg_cfg_exit_early();\n  }\n\n  /* New Module missing */\n  find_model_description(surf_cpu_model_description, value);\n}\n\n/* callback of the cpu/model variable */\nstatic void _sg_cfg_cb__optimization_mode(const std::string& value)\n{\n  xbt_assert(_sg_cfg_init_status < 2, \"Cannot change the model after the initialization\");\n\n  if (value == \"help\") {\n    model_help(\"optimization\", surf_optimization_mode_description);\n    sg_cfg_exit_early();\n  }\n\n  /* New Module missing */\n  find_model_description(surf_optimization_mode_description, value);\n}\n\n/* callback of the cpu/model variable */\nstatic void _sg_cfg_cb__storage_mode(const std::string& value)\n{\n  xbt_assert(_sg_cfg_init_status < 2, \"Cannot change the model after the initialization\");\n\n  if (value == \"help\") {\n    model_help(\"storage\", surf_storage_model_description);\n    sg_cfg_exit_early();\n  }\n\n  find_model_description(surf_storage_model_description, value);\n}\n\n/* callback of the network_model variable */\nstatic void _sg_cfg_cb__network_model(const std::string& value)\n{\n  xbt_assert(_sg_cfg_init_status < 2, \"Cannot change the model after the initialization\");\n\n  if (value == \"help\") {\n    model_help(\"network\", surf_network_model_description);\n    sg_cfg_exit_early();\n  }\n\n  /* New Module missing */\n  find_model_description(surf_network_model_description, value);\n}\n\nstatic void _sg_cfg_cb_contexts_parallel_mode(const std::string& mode_name)\n{\n  if (mode_name == \"posix\") {\n    SIMIX_context_set_parallel_mode(XBT_PARMAP_POSIX);\n  } else if (mode_name == \"futex\") {\n    SIMIX_context_set_parallel_mode(XBT_PARMAP_FUTEX);\n  } else if (mode_name == \"busy_wait\") {\n    SIMIX_context_set_parallel_mode(XBT_PARMAP_BUSY_WAIT);\n  } else {\n    xbt_die(\"Command line setting of the parallel synchronization mode should \"\n            \"be one of \\\"posix\\\", \\\"futex\\\" or \\\"busy_wait\\\"\");\n  }\n}\n\n/* build description line with possible values */\nstatic void describe_model(char *result,int resultsize,\n                           const s_surf_model_description_t model_description[],\n                           const char *name,\n                           const char *description)\n{\n  result[0] = '\\0';\n  char *p = result;\n  p += snprintf(result,resultsize-1, \"%s. Possible values: %s\", description,\n            model_description[0].name ? model_description[0].name : \"n/a\");\n  for (int i = 1; model_description[i].name; i++)\n    p += snprintf(p,resultsize-(p-result)-1, \", %s\", model_description[i].name);\n  p += snprintf(p,resultsize-(p-result)-1, \".\\n       (use 'help' as a value to see the long description of each %s)\", name);\n\n  xbt_assert(p<result+resultsize-1,\"Buffer too small to display the model description of %s\",name);\n}\n\n/* create the config set, register what should be and parse the command line*/\nvoid sg_config_init(int *argc, char **argv)\n{\n  const int descsize = 1024;\n  char description[descsize];\n\n  /* Create the configuration support */\n  if (_sg_cfg_init_status != 0) { /* Only create stuff if not already inited */\n    XBT_WARN(\"Call to sg_config_init() after initialization ignored\");\n    return;\n  }\n\n  /* Plugins configuration */\n  describe_model(description, descsize, surf_plugin_description, \"plugin\", \"The plugins\");\n  simgrid::config::declare_flag<std::string>(\"plugin\", description, \"\", &_sg_cfg_cb__plugin);\n\n  describe_model(description, descsize, surf_cpu_model_description, \"model\", \"The model to use for the CPU\");\n  simgrid::config::declare_flag<std::string>(\"cpu/model\", description, \"Cas01\", &_sg_cfg_cb__cpu_model);\n\n  describe_model(description, descsize, surf_storage_model_description, \"model\", \"The model to use for the storage\");\n  simgrid::config::declare_flag<std::string>(\"storage/model\", description, \"default\", &_sg_cfg_cb__storage_mode);\n\n  describe_model(description, descsize, surf_network_model_description, \"model\", \"The model to use for the network\");\n  simgrid::config::declare_flag<std::string>(\"network/model\", description, \"LV08\", &_sg_cfg_cb__network_model);\n\n  describe_model(description, descsize, surf_optimization_mode_description, \"optimization mode\",\n                 \"The optimization modes to use for the network\");\n  simgrid::config::declare_flag<std::string>(\"network/optim\", description, \"Lazy\", &_sg_cfg_cb__optimization_mode);\n\n  describe_model(description, descsize, surf_host_model_description, \"model\", \"The model to use for the host\");\n  simgrid::config::declare_flag<std::string>(\"host/model\", description, \"default\", &_sg_cfg_cb__host_model);\n\n  simgrid::config::bind_flag(sg_surf_precision, \"surf/precision\",\n                             \"Numerical precision used when updating simulation times (in seconds)\");\n\n  simgrid::config::bind_flag(sg_maxmin_precision, \"maxmin/precision\",\n                             \"Numerical precision used when computing resource sharing (in flops/sec or bytes/sec)\");\n\n  simgrid::config::bind_flag(sg_concurrency_limit, \"maxmin/concurrency-limit\", {\"maxmin/concurrency_limit\"},\n                             \"Maximum number of concurrent variables in the maxmim system. Also limits the number of \"\n                             \"processes on each host, at higher level. (default: -1 means no such limitation)\");\n\n  /* The parameters of network models */\n\n  sg_latency_factor = 13.01; // comes from the default LV08 network model\n  simgrid::config::bind_flag(sg_latency_factor, \"network/latency-factor\", {\"network/latency_factor\"},\n                             \"Correction factor to apply to the provided latency (default value set by network model)\");\n\n  sg_bandwidth_factor = 0.97; // comes from the default LV08 network model\n  simgrid::config::bind_flag(\n      sg_bandwidth_factor, \"network/bandwidth-factor\", {\"network/bandwidth_factor\"},\n      \"Correction factor to apply to the provided bandwidth (default value set by network model)\");\n\n  sg_weight_S_parameter = 20537; // comes from the default LV08 network model\n  simgrid::config::bind_flag(\n      sg_weight_S_parameter, \"network/weight-S\", {\"network/weight_S\"},\n      \"Correction factor to apply to the weight of competing streams (default value set by network model)\");\n\n  /* Inclusion path */\n  simgrid::config::declare_flag<std::string>(\"path\", \"Lookup path for inclusions in platform and deployment XML files\",\n                                             \"\", [](std::string const& path) {\n                                               if (not path.empty())\n                                                 surf_path.push_back(path);\n                                             });\n\n  simgrid::config::declare_flag<bool>(\"cpu/maxmin-selective-update\",\n                                      \"Update the constraint set propagating recursively to others constraints \"\n                                      \"(off by default unless optim is set to lazy)\",\n                                      \"no\");\n  simgrid::config::alias(\"cpu/maxmin-selective-update\", {\"cpu/maxmin_selective_update\"});\n  simgrid::config::declare_flag<bool>(\"network/maxmin-selective-update\", \"Update the constraint set propagating \"\n                                                                         \"recursively to others constraints (off by \"\n                                                                         \"default unless optim is set to lazy)\",\n                                      \"no\");\n  simgrid::config::alias(\"network/maxmin-selective-update\", {\"network/maxmin_selective_update\"});\n\n  extern bool _sg_do_verbose_exit;\n  simgrid::config::bind_flag(_sg_do_verbose_exit, \"verbose-exit\", \"Activate the \\\"do nothing\\\" mode in Ctrl-C\");\n\n  simgrid::config::declare_flag<int>(\"contexts/stack-size\", \"Stack size of contexts in KiB\", 8 * 1024,\n                                     [](int value) { smx_context_stack_size = value * 1024; });\n  simgrid::config::alias(\"contexts/stack-size\", {\"contexts/stack_size\"});\n\n  /* guard size for contexts stacks in memory pages */\n#if defined(_WIN32) || (PTH_STACKGROWTH != -1)\n  int default_guard_size = 0;\n#else\n  int default_guard_size = 1;\n#endif\n  simgrid::config::declare_flag<int>(\"contexts/guard-size\", \"Guard size for contexts stacks in memory pages\",\n                                     default_guard_size,\n                                     [](int value) { smx_context_guard_size = value * xbt_pagesize; });\n  simgrid::config::alias(\"contexts/guard-size\", {\"contexts/guard_size\"});\n  simgrid::config::declare_flag<int>(\"contexts/nthreads\", \"Number of parallel threads used to execute user contexts\", 1,\n                                     &SIMIX_context_set_nthreads);\n\n  simgrid::config::declare_flag<int>(\"contexts/parallel-threshold\",\n                                     \"Minimal number of user contexts to be run in parallel (raw contexts only)\", 2,\n                                     &SIMIX_context_set_parallel_threshold);\n  simgrid::config::alias(\"contexts/parallel-threshold\", {\"contexts/parallel_threshold\"});\n\n  /* synchronization mode for parallel user contexts */\n#if HAVE_FUTEX_H\n  std::string default_synchro_mode = \"futex\";\n#else //No futex on mac and posix is unimplememted yet\n  std::string default_synchro_mode = \"busy_wait\";\n#endif\n  simgrid::config::declare_flag<std::string>(\"contexts/synchro\", \"Synchronization mode to use when running contexts in \"\n                                                                 \"parallel (either futex, posix or busy_wait)\",\n                                             default_synchro_mode, &_sg_cfg_cb_contexts_parallel_mode);\n\n  // For smpi/bw-factor and smpi/lat-factor\n  // SMPI model can be used without enable_smpi, so keep this out of the ifdef.\n  simgrid::config::declare_flag<std::string>(\"smpi/bw-factor\",\n                                             \"Bandwidth factors for smpi. Format: \"\n                                             \"'threshold0:value0;threshold1:value1;...;thresholdN:valueN', \"\n                                             \"meaning if(size >=thresholdN ) return valueN.\",\n                                             \"65472:0.940694;15424:0.697866;9376:0.58729;5776:1.08739;3484:0.77493;\"\n                                             \"1426:0.608902;732:0.341987;257:0.338112;0:0.812084\");\n  simgrid::config::alias(\"smpi/bw-factor\", {\"smpi/bw_factor\"});\n\n  simgrid::config::declare_flag<std::string>(\"smpi/lat-factor\", \"Latency factors for smpi.\",\n                                             \"65472:11.6436;15424:3.48845;9376:2.59299;5776:2.18796;3484:1.88101;\"\n                                             \"1426:1.61075;732:1.9503;257:1.95341;0:2.01467\");\n  simgrid::config::alias(\"smpi/lat-factor\", {\"smpi/lat_factor\"});\n  simgrid::config::declare_flag<std::string>(\"smpi/IB-penalty-factors\",\n                                             \"Correction factor to communications using Infiniband model with \"\n                                             \"contention (default value based on Stampede cluster profiling)\",\n                                             \"0.965;0.925;1.35\");\n  simgrid::config::alias(\"smpi/IB-penalty-factors\", {\"smpi/IB_penalty_factors\"});\n\n#if HAVE_SMPI\n  simgrid::config::declare_flag<double>(\"smpi/host-speed\", \"Speed of the host running the simulation (in flop/s). \"\n                                                           \"Used to bench the operations.\",\n                                        20000.0);\n  simgrid::config::alias(\"smpi/host-speed\", {\"smpi/running_power\", \"smpi/running-power\"});\n\n  simgrid::config::declare_flag<bool>(\"smpi/keep-temps\", \"Whether we should keep the generated temporary files.\",\n                                      false);\n\n  simgrid::config::declare_flag<bool>(\"smpi/display-timing\", \"Whether we should display the timing after simulation.\",\n                                      false);\n  simgrid::config::alias(\"smpi/display-timing\", {\"smpi/display_timing\"});\n\n  simgrid::config::declare_flag<bool>(\n      \"smpi/simulate-computation\", \"Whether the computational part of the simulated application should be simulated.\",\n      true);\n  simgrid::config::alias(\"smpi/simulate-computation\", {\"smpi/simulate_computation\"});\n\n  simgrid::config::declare_flag<std::string>(\n      \"smpi/shared-malloc\", \"Whether SMPI_SHARED_MALLOC is enabled. Disable it for debugging purposes.\", \"global\");\n  simgrid::config::alias(\"smpi/shared-malloc\", {\"smpi/use_shared_malloc\", \"smpi/use-shared-malloc\"});\n  simgrid::config::declare_flag<double>(\"smpi/shared-malloc-blocksize\",\n                                        \"Size of the bogus file which will be created for global shared allocations\",\n                                        1UL << 20);\n  simgrid::config::declare_flag<std::string>(\"smpi/shared-malloc-hugepage\",\n                                             \"Path to a mounted hugetlbfs, to use huge pages with shared malloc.\", \"\");\n\n  simgrid::config::declare_flag<double>(\n      \"smpi/cpu-threshold\", \"Minimal computation time (in seconds) not discarded, or -1 for infinity.\", 1e-6);\n  simgrid::config::alias(\"smpi/cpu-threshold\", {\"smpi/cpu_threshold\"});\n\n  simgrid::config::declare_flag<int>(\n      \"smpi/async-small-thresh\",\n      \"Maximal size of messages that are to be sent asynchronously, without waiting for the receiver\", 0);\n  simgrid::config::alias(\"smpi/async-small-thresh\", {\"smpi/async_small_thres\", \"smpi/async_small_thresh\"});\n\n  simgrid::config::declare_flag<bool>(\"smpi/trace-call-location\",\n                                      \"Should filename and linenumber of MPI calls be traced?\", false);\n\n  simgrid::config::declare_flag<int>(\n      \"smpi/send-is-detached-thresh\",\n      \"Threshold of message size where MPI_Send stops behaving like MPI_Isend and becomes MPI_Ssend\", 65536);\n  simgrid::config::alias(\"smpi/send-is-detached-thresh\",\n                         {\"smpi/send_is_detached_thres\", \"smpi/send_is_detached_thresh\"});\n\n  const char* default_privatization = std::getenv(\"SMPI_PRIVATIZATION\");\n  if (default_privatization == nullptr)\n    default_privatization = \"no\";\n\n  simgrid::config::declare_flag<std::string>(\n      \"smpi/privatization\", \"How we should privatize global variable at runtime (no, yes, mmap, dlopen).\",\n      default_privatization);\n  simgrid::config::alias(\"smpi/privatization\", {\"smpi/privatize_global_variables\", \"smpi/privatize-global-variables\"});\n\n  simgrid::config::declare_flag<std::string>(\n      \"smpi/privatize-libs\", \"Add libraries (; separated) to privatize (libgfortran for example). You need to provide the full names of the files (libgfortran.so.4), or its full path\", \"\");\n\n  simgrid::config::declare_flag<bool>(\"smpi/grow-injected-times\",\n                                      \"Whether we want to make the injected time in MPI_Iprobe and MPI_Test grow, to \"\n                                      \"allow faster simulation. This can make simulation less precise, though.\",\n                                      true);\n\n#if HAVE_PAPI\n  simgrid::config::declare_flag<std::string>(\"smpi/papi-events\",\n                                             \"This switch enables tracking the specified counters with PAPI\", \"\");\n#endif\n  simgrid::config::declare_flag<std::string>(\"smpi/comp-adjustment-file\",\n                                             \"A file containing speedups or slowdowns for some parts of the code.\", \"\");\n  simgrid::config::declare_flag<std::string>(\n      \"smpi/os\", \"Small messages timings (MPI_Send minimum time for small messages)\", \"0:0:0:0:0\");\n  simgrid::config::declare_flag<std::string>(\n      \"smpi/ois\", \"Small messages timings (MPI_Isend minimum time for small messages)\", \"0:0:0:0:0\");\n  simgrid::config::declare_flag<std::string>(\n      \"smpi/or\", \"Small messages timings (MPI_Recv minimum time for small messages)\", \"0:0:0:0:0\");\n\n  simgrid::config::declare_flag<double>(\"smpi/iprobe-cpu-usage\",\n                                        \"Maximum usage of CPUs by MPI_Iprobe() calls. We've observed that MPI_Iprobes \"\n                                        \"consume significantly less power than the maximum of a specific application. \"\n                                        \"This value is then (Iprobe_Usage/Max_Application_Usage).\",\n                                        1.0);\n\n  simgrid::config::declare_flag<std::string>(\"smpi/coll-selector\", \"Which collective selector to use\", \"default\");\n  simgrid::config::alias(\"smpi/coll-selector\", {\"smpi/coll_selector\"});\n  simgrid::config::declare_flag<std::string>(\"smpi/gather\", \"Which collective to use for gather\", \"\");\n  simgrid::config::declare_flag<std::string>(\"smpi/allgather\", \"Which collective to use for allgather\", \"\");\n  simgrid::config::declare_flag<std::string>(\"smpi/barrier\", \"Which collective to use for barrier\", \"\");\n  simgrid::config::declare_flag<std::string>(\"smpi/reduce_scatter\", \"Which collective to use for reduce_scatter\", \"\");\n  simgrid::config::alias(\"smpi/reduce_scatter\", {\"smpi/reduce-scatter\"});\n  simgrid::config::declare_flag<std::string>(\"smpi/scatter\", \"Which collective to use for scatter\", \"\");\n  simgrid::config::declare_flag<std::string>(\"smpi/allgatherv\", \"Which collective to use for allgatherv\", \"\");\n  simgrid::config::declare_flag<std::string>(\"smpi/allreduce\", \"Which collective to use for allreduce\", \"\");\n  simgrid::config::declare_flag<std::string>(\"smpi/alltoall\", \"Which collective to use for alltoall\", \"\");\n  simgrid::config::declare_flag<std::string>(\"smpi/alltoallv\", \"Which collective to use for alltoallv\", \"\");\n  simgrid::config::declare_flag<std::string>(\"smpi/bcast\", \"Which collective to use for bcast\", \"\");\n  simgrid::config::declare_flag<std::string>(\"smpi/reduce\", \"Which collective to use for reduce\", \"\");\n#endif // HAVE_SMPI\n\n  /* Others */\n\n  simgrid::config::declare_flag<bool>(\n      \"exception/cutpath\", \"Whether to cut all path information from call traces, used e.g. in exceptions.\", false);\n\n  extern bool _sg_do_clean_atexit;\n  simgrid::config::bind_flag(_sg_do_clean_atexit, \"clean-atexit\", {\"clean_atexit\"},\n                             \"Whether to cleanup SimGrid at exit. Disable it if your code segfaults after its end.\");\n\n  if (surf_path.empty())\n    simgrid::config::set_default<std::string>(\"path\", \"./\");\n\n  _sg_cfg_init_status = 1;\n\n  sg_config_cmd_line(argc, argv);\n\n  xbt_mallocator_initialization_is_done(SIMIX_context_is_parallel());\n}\n\nvoid sg_config_finalize()\n{\n  if (not _sg_cfg_init_status)\n    return;                     /* Not initialized yet. Nothing to do */\n\n  simgrid::config::finalize();\n  _sg_cfg_init_status = 0;\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.20-xigfpbo5yypiin5odq3dedwvkyxa5sxr/spack-src/src/smpi/smpi_main.c": "/* Copyright (c) 2007-2018. The SimGrid Team. All rights reserved.          */\n\n/* This program is free software; you can redistribute it and/or modify it\n * under the terms of the license (GNU LGPL) which comes with this package. */\n\n#include <stdio.h>\n#include <stdlib.h>\n\n#include <smpi/smpi.h>\n\nint main(int argc, char **argv)\n{\n  if (getenv(\"SMPI_PRETEND_CC\") != NULL) {\n    /* Hack to ensure that smpicc can pretend to be a simple compiler. Particularly handy to pass it to the\n     * configuration tools. This one is used with dlopen privatization. */\n    return 0;\n  }\n\n  if (argc < 2) {\n    fprintf(stderr, \"Usage: smpimain <program to launch>\\n\");\n    exit(1);\n  }\n  return smpi_main(argv[1], argc - 1, argv + 1);\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.20-xigfpbo5yypiin5odq3dedwvkyxa5sxr/spack-src/src/smpi/internals/smpi_global.cpp": "/* Copyright (c) 2007-2018. The SimGrid Team. All rights reserved.          */\n\n/* This program is free software; you can redistribute it and/or modify it\n * under the terms of the license (GNU LGPL) which comes with this package. */\n\n#include \"smpi_host.hpp\"\n#include \"mc/mc.h\"\n#include \"simgrid/s4u/Engine.hpp\"\n#include \"smpi_coll.hpp\"\n#include \"smpi_process.hpp\"\n#include \"src/msg/msg_private.hpp\"\n#include \"src/simix/smx_private.hpp\"\n#include \"xbt/config.hpp\"\n\n#include <cfloat> /* DBL_MAX */\n#include <dlfcn.h>\n#include <fcntl.h>\n#if not defined(__APPLE__)\n#include <link.h>\n#endif\n#include <fstream>\n\n#if HAVE_SENDFILE\n#include <sys/sendfile.h>\n#endif\n\nXBT_LOG_NEW_DEFAULT_SUBCATEGORY(smpi_kernel, smpi, \"Logging specific to SMPI (kernel)\");\n#include <boost/tokenizer.hpp>\n#include <boost/algorithm/string.hpp> /* trim_right / trim_left */\n\n#ifndef RTLD_DEEPBIND\n/* RTLD_DEEPBIND is a bad idea of GNU ld that obviously does not exist on other platforms\n * See https://www.akkadia.org/drepper/dsohowto.pdf\n * and https://lists.freebsd.org/pipermail/freebsd-current/2016-March/060284.html\n*/\n#define RTLD_DEEPBIND 0\n#endif\n\n#if HAVE_PAPI\n#include \"papi.h\"\nconst char* papi_default_config_name = \"default\";\n\nstruct papi_process_data {\n  papi_counter_t counter_data;\n  int event_set;\n};\n#endif\n\nusing simgrid::s4u::Actor;\nusing simgrid::s4u::ActorPtr;\nstd::unordered_map<std::string, double> location2speedup;\n\nstatic std::map</*process_id*/ ActorPtr, simgrid::smpi::Process*> process_data;\nint process_count = 0;\nstatic int smpi_exit_status = 0;\nint smpi_universe_size = 0;\nextern double smpi_total_benched_time;\nxbt_os_timer_t global_timer;\nstatic std::vector<std::string> privatize_libs_paths;\n/**\n * Setting MPI_COMM_WORLD to MPI_COMM_UNINITIALIZED (it's a variable)\n * is important because the implementation of MPI_Comm checks\n * \"this == MPI_COMM_UNINITIALIZED\"? If yes, it uses smpi_process()->comm_world()\n * instead of \"this\".\n * This is basically how we only have one global variable but all processes have\n * different communicators (the one their SMPI instance uses).\n *\n * See smpi_comm.cpp and the functions therein for details.\n */\nMPI_Comm MPI_COMM_WORLD = MPI_COMM_UNINITIALIZED;\nMPI_Errhandler *MPI_ERRORS_RETURN = nullptr;\nMPI_Errhandler *MPI_ERRORS_ARE_FATAL = nullptr;\nMPI_Errhandler *MPI_ERRHANDLER_NULL = nullptr;\n// No instance gets manually created; check also the smpirun.in script as\n// this default name is used there as well (when the <actor> tag is generated).\nstatic const std::string smpi_default_instance_name(\"smpirun\");\nstatic simgrid::config::Flag<double> smpi_wtime_sleep(\n  \"smpi/wtime\", \"Minimum time to inject inside a call to MPI_Wtime\", 0.0);\nstatic simgrid::config::Flag<double> smpi_init_sleep(\n  \"smpi/init\", \"Time to inject inside a call to MPI_Init\", 0.0);\n\nvoid (*smpi_comm_copy_data_callback) (smx_activity_t, void*, size_t) = &smpi_comm_copy_buffer_callback;\n\nint smpi_process_count()\n{\n  return process_count;\n}\n\nsimgrid::smpi::Process* smpi_process()\n{\n  ActorPtr me = Actor::self();\n  if (me == nullptr) // This happens sometimes (eg, when linking against NS3 because it pulls openMPI...)\n    return nullptr;\n  simgrid::msg::ActorExt* msgExt = static_cast<simgrid::msg::ActorExt*>(me->get_impl()->getUserData());\n  return static_cast<simgrid::smpi::Process*>(msgExt->data);\n}\n\nsimgrid::smpi::Process* smpi_process_remote(ActorPtr actor)\n{\n  return process_data.at(actor);\n}\n\nMPI_Comm smpi_process_comm_self(){\n  return smpi_process()->comm_self();\n}\n\nvoid smpi_process_init(int *argc, char ***argv){\n  simgrid::smpi::Process::init(argc, argv);\n}\n\nint smpi_process_index(){\n  return simgrid::s4u::this_actor::get_pid();\n}\n\nvoid * smpi_process_get_user_data(){\n  return smpi_process()->get_user_data();\n}\n\nvoid smpi_process_set_user_data(void *data){\n  return smpi_process()->set_user_data(data);\n}\n\n\nint smpi_global_size()\n{\n  char *value = getenv(\"SMPI_GLOBAL_SIZE\");\n  xbt_assert(value,\"Please set env var SMPI_GLOBAL_SIZE to the expected number of processes.\");\n\n  return xbt_str_parse_int(value, \"SMPI_GLOBAL_SIZE contains a non-numerical value: %s\");\n}\n\nvoid smpi_comm_set_copy_data_callback(void (*callback) (smx_activity_t, void*, size_t))\n{\n  smpi_comm_copy_data_callback = callback;\n}\n\nstatic void memcpy_private(void* dest, const void* src, std::vector<std::pair<size_t, size_t>>& private_blocks)\n{\n  for (auto const& block : private_blocks)\n    memcpy((uint8_t*)dest+block.first, (uint8_t*)src+block.first, block.second-block.first);\n}\n\nstatic void check_blocks(std::vector<std::pair<size_t, size_t>> &private_blocks, size_t buff_size) {\n  for (auto const& block : private_blocks)\n    xbt_assert(block.first <= block.second && block.second <= buff_size, \"Oops, bug in shared malloc.\");\n}\n\nvoid smpi_comm_copy_buffer_callback(smx_activity_t synchro, void *buff, size_t buff_size)\n{\n  simgrid::kernel::activity::CommImplPtr comm =\n      boost::dynamic_pointer_cast<simgrid::kernel::activity::CommImpl>(synchro);\n  int src_shared                        = 0;\n  int dst_shared                        = 0;\n  size_t src_offset                     = 0;\n  size_t dst_offset                     = 0;\n  std::vector<std::pair<size_t, size_t>> src_private_blocks;\n  std::vector<std::pair<size_t, size_t>> dst_private_blocks;\n  XBT_DEBUG(\"Copy the data over\");\n  if((src_shared=smpi_is_shared(buff, src_private_blocks, &src_offset))) {\n    XBT_DEBUG(\"Sender %p is shared. Let's ignore it.\", buff);\n    src_private_blocks = shift_and_frame_private_blocks(src_private_blocks, src_offset, buff_size);\n  }\n  else {\n    src_private_blocks.clear();\n    src_private_blocks.push_back(std::make_pair(0, buff_size));\n  }\n  if((dst_shared=smpi_is_shared((char*)comm->dst_buff, dst_private_blocks, &dst_offset))) {\n    XBT_DEBUG(\"Receiver %p is shared. Let's ignore it.\", (char*)comm->dst_buff);\n    dst_private_blocks = shift_and_frame_private_blocks(dst_private_blocks, dst_offset, buff_size);\n  }\n  else {\n    dst_private_blocks.clear();\n    dst_private_blocks.push_back(std::make_pair(0, buff_size));\n  }\n  check_blocks(src_private_blocks, buff_size);\n  check_blocks(dst_private_blocks, buff_size);\n  auto private_blocks = merge_private_blocks(src_private_blocks, dst_private_blocks);\n  check_blocks(private_blocks, buff_size);\n  void* tmpbuff=buff;\n  if ((smpi_privatize_global_variables == SmpiPrivStrategies::MMAP) &&\n      (static_cast<char*>(buff) >= smpi_data_exe_start) &&\n      (static_cast<char*>(buff) < smpi_data_exe_start + smpi_data_exe_size)) {\n    XBT_DEBUG(\"Privatization : We are copying from a zone inside global memory... Saving data to temp buffer !\");\n    smpi_switch_data_segment(comm->src_proc->iface());\n    tmpbuff = static_cast<void*>(xbt_malloc(buff_size));\n    memcpy_private(tmpbuff, buff, private_blocks);\n  }\n\n  if ((smpi_privatize_global_variables == SmpiPrivStrategies::MMAP) && ((char*)comm->dst_buff >= smpi_data_exe_start) &&\n      ((char*)comm->dst_buff < smpi_data_exe_start + smpi_data_exe_size)) {\n    XBT_DEBUG(\"Privatization : We are copying to a zone inside global memory - Switch data segment\");\n    smpi_switch_data_segment(comm->dst_proc->iface());\n  }\n  XBT_DEBUG(\"Copying %zu bytes from %p to %p\", buff_size, tmpbuff,comm->dst_buff);\n  memcpy_private(comm->dst_buff, tmpbuff, private_blocks);\n\n  if (comm->detached) {\n    // if this is a detached send, the source buffer was duplicated by SMPI\n    // sender to make the original buffer available to the application ASAP\n    xbt_free(buff);\n    //It seems that the request is used after the call there this should be free somewhere else but where???\n    //xbt_free(comm->comm.src_data);// inside SMPI the request is kept inside the user data and should be free\n    comm->src_buff = nullptr;\n  }\n  if (tmpbuff != buff)\n    xbt_free(tmpbuff);\n}\n\nvoid smpi_comm_null_copy_buffer_callback(smx_activity_t comm, void *buff, size_t buff_size)\n{\n  /* nothing done in this version */\n}\n\nstatic void smpi_check_options()\n{\n  //check correctness of MPI parameters\n\n  xbt_assert(simgrid::config::get_value<int>(\"smpi/async-small-thresh\") <=\n             simgrid::config::get_value<int>(\"smpi/send-is-detached-thresh\"));\n\n  if (simgrid::config::is_default(\"smpi/host-speed\")) {\n    XBT_INFO(\"You did not set the power of the host running the simulation.  \"\n             \"The timings will certainly not be accurate.  \"\n             \"Use the option \\\"--cfg=smpi/host-speed:<flops>\\\" to set its value.\"\n             \"Check http://simgrid.org/simgrid/latest/doc/options.html#options_smpi_bench for more information.\");\n  }\n\n  xbt_assert(simgrid::config::get_value<double>(\"smpi/cpu-threshold\") >= 0,\n             \"The 'smpi/cpu-threshold' option cannot have negative values [anymore]. If you want to discard \"\n             \"the simulation of any computation, please use 'smpi/simulate-computation:no' instead.\");\n}\n\nint smpi_enabled() {\n  return not process_data.empty();\n}\n\nvoid smpi_global_init()\n{\n  if (not MC_is_active()) {\n    global_timer = xbt_os_timer_new();\n    xbt_os_walltimer_start(global_timer);\n  }\n\n  std::string filename = simgrid::config::get_value<std::string>(\"smpi/comp-adjustment-file\");\n  if (not filename.empty()) {\n    std::ifstream fstream(filename);\n    if (not fstream.is_open()) {\n      xbt_die(\"Could not open file %s. Does it exist?\", filename.c_str());\n    }\n\n    std::string line;\n    typedef boost::tokenizer< boost::escaped_list_separator<char>> Tokenizer;\n    std::getline(fstream, line); // Skip the header line\n    while (std::getline(fstream, line)) {\n      Tokenizer tok(line);\n      Tokenizer::iterator it  = tok.begin();\n      Tokenizer::iterator end = std::next(tok.begin());\n\n      std::string location = *it;\n      boost::trim(location);\n      location2speedup.insert(std::pair<std::string, double>(location, std::stod(*end)));\n    }\n  }\n\n#if HAVE_PAPI\n  // This map holds for each computation unit (such as \"default\" or \"process1\" etc.)\n  // the configuration as given by the user (counter data as a pair of (counter_name, counter_counter))\n  // and the (computed) event_set.\n  std::map</* computation unit name */ std::string, papi_process_data> units2papi_setup;\n\n  if (not simgrid::config::get_value<std::string>(\"smpi/papi-events\").empty()) {\n    if (PAPI_library_init(PAPI_VER_CURRENT) != PAPI_VER_CURRENT)\n      XBT_ERROR(\"Could not initialize PAPI library; is it correctly installed and linked?\"\n                \" Expected version is %i\",\n                PAPI_VER_CURRENT);\n\n    typedef boost::tokenizer<boost::char_separator<char>> Tokenizer;\n    boost::char_separator<char> separator_units(\";\");\n    std::string str = simgrid::config::get_value<std::string>(\"smpi/papi-events\");\n    Tokenizer tokens(str, separator_units);\n\n    // Iterate over all the computational units. This could be processes, hosts, threads, ranks... You name it.\n    // I'm not exactly sure what we will support eventually, so I'll leave it at the general term \"units\".\n    for (auto const& unit_it : tokens) {\n      boost::char_separator<char> separator_events(\":\");\n      Tokenizer event_tokens(unit_it, separator_events);\n\n      int event_set = PAPI_NULL;\n      if (PAPI_create_eventset(&event_set) != PAPI_OK) {\n        // TODO: Should this let the whole simulation die?\n        XBT_CRITICAL(\"Could not create PAPI event set during init.\");\n      }\n\n      // NOTE: We cannot use a map here, as we must obey the order of the counters\n      // This is important for PAPI: We need to map the values of counters back\n      // to the event_names (so, when PAPI_read() has finished)!\n      papi_counter_t counters2values;\n\n      // Iterate over all counters that were specified for this specific\n      // unit.\n      // Note that we need to remove the name of the unit\n      // (that could also be the \"default\" value), which always comes first.\n      // Hence, we start at ++(events.begin())!\n      for (Tokenizer::iterator events_it = ++(event_tokens.begin()); events_it != event_tokens.end(); ++events_it) {\n\n        int event_code   = PAPI_NULL;\n        char* event_name = const_cast<char*>((*events_it).c_str());\n        if (PAPI_event_name_to_code(event_name, &event_code) == PAPI_OK) {\n          if (PAPI_add_event(event_set, event_code) != PAPI_OK) {\n            XBT_ERROR(\"Could not add PAPI event '%s'. Skipping.\", event_name);\n            continue;\n          } else {\n            XBT_DEBUG(\"Successfully added PAPI event '%s' to the event set.\", event_name);\n          }\n        } else {\n          XBT_CRITICAL(\"Could not find PAPI event '%s'. Skipping.\", event_name);\n          continue;\n        }\n\n        counters2values.push_back(\n            // We cannot just pass *events_it, as this is of type const basic_string\n            std::make_pair<std::string, long long>(std::string(*events_it), 0));\n      }\n\n      std::string unit_name    = *(event_tokens.begin());\n      papi_process_data config = {.counter_data = std::move(counters2values), .event_set = event_set};\n\n      units2papi_setup.insert(std::make_pair(unit_name, std::move(config)));\n    }\n  }\n#endif\n}\n\nvoid smpi_global_destroy()\n{\n  smpi_bench_destroy();\n  smpi_shared_destroy();\n  smpi_deployment_cleanup_instances();\n\n  if (simgrid::smpi::Colls::smpi_coll_cleanup_callback != nullptr)\n    simgrid::smpi::Colls::smpi_coll_cleanup_callback();\n\n  MPI_COMM_WORLD = MPI_COMM_NULL;\n\n  if (not MC_is_active()) {\n    xbt_os_timer_free(global_timer);\n  }\n\n  if (smpi_privatize_global_variables == SmpiPrivStrategies::MMAP)\n    smpi_destroy_global_memory_segments();\n  smpi_free_static();\n}\n\nstatic void smpi_init_options(){\n  // return if already called\n  if (smpi_cpu_threshold > -1)\n    return;\n  simgrid::smpi::Colls::set_collectives();\n  simgrid::smpi::Colls::smpi_coll_cleanup_callback = nullptr;\n  smpi_cpu_threshold                               = simgrid::config::get_value<double>(\"smpi/cpu-threshold\");\n  smpi_host_speed                                  = simgrid::config::get_value<double>(\"smpi/host-speed\");\n  xbt_assert(smpi_host_speed >= 0, \"You're trying to set the host_speed to a negative value (%f)\", smpi_host_speed);\n  std::string smpi_privatize_option = simgrid::config::get_value<std::string>(\"smpi/privatization\");\n  if (smpi_privatize_option == \"no\" || smpi_privatize_option == \"0\")\n    smpi_privatize_global_variables = SmpiPrivStrategies::NONE;\n  else if (smpi_privatize_option == \"yes\" || smpi_privatize_option == \"1\")\n    smpi_privatize_global_variables = SmpiPrivStrategies::DEFAULT;\n  else if (smpi_privatize_option == \"mmap\")\n    smpi_privatize_global_variables = SmpiPrivStrategies::MMAP;\n  else if (smpi_privatize_option == \"dlopen\")\n    smpi_privatize_global_variables = SmpiPrivStrategies::DLOPEN;\n  else\n    xbt_die(\"Invalid value for smpi/privatization: '%s'\", smpi_privatize_option.c_str());\n\n  if (not SMPI_switch_data_segment) {\n    XBT_DEBUG(\"Running without smpi_main(); disable smpi/privatization.\");\n    smpi_privatize_global_variables = SmpiPrivStrategies::NONE;\n  }\n#if defined(__FreeBSD__)\n  if (smpi_privatize_global_variables == SmpiPrivStrategies::MMAP) {\n    XBT_INFO(\"mmap privatization is broken on FreeBSD, switching to dlopen privatization instead.\");\n    smpi_privatize_global_variables = SmpiPrivStrategies::DLOPEN;\n  }\n#endif\n\n  if (smpi_cpu_threshold < 0)\n    smpi_cpu_threshold = DBL_MAX;\n\n  std::string val = simgrid::config::get_value<std::string>(\"smpi/shared-malloc\");\n  if ((val == \"yes\") || (val == \"1\") || (val == \"on\") || (val == \"global\")) {\n    smpi_cfg_shared_malloc = SharedMallocType::GLOBAL;\n  } else if (val == \"local\") {\n    smpi_cfg_shared_malloc = SharedMallocType::LOCAL;\n  } else if ((val == \"no\") || (val == \"0\") || (val == \"off\")) {\n    smpi_cfg_shared_malloc = SharedMallocType::NONE;\n  } else {\n    xbt_die(\"Invalid value '%s' for option smpi/shared-malloc. Possible values: 'on' or 'global', 'local', 'off'\",\n            val.c_str());\n  }\n}\n\ntypedef std::function<int(int argc, char *argv[])> smpi_entry_point_type;\ntypedef int (* smpi_c_entry_point_type)(int argc, char **argv);\ntypedef void (*smpi_fortran_entry_point_type)();\n\nstatic int smpi_run_entry_point(smpi_entry_point_type entry_point, std::vector<std::string> args)\n{\n  char noarg[]   = {'\\0'};\n  const int argc = args.size();\n  std::unique_ptr<char*[]> argv(new char*[argc + 1]);\n  for (int i = 0; i != argc; ++i)\n    argv[i] = args[i].empty() ? noarg : &args[i].front();\n  argv[argc] = nullptr;\n\n  int res = entry_point(argc, argv.get());\n  if (res != 0){\n    XBT_WARN(\"SMPI process did not return 0. Return value : %d\", res);\n    if (smpi_exit_status == 0)\n      smpi_exit_status = res;\n  }\n  return 0;\n}\n\n\n// TODO, remove the number of functions involved here\nstatic smpi_entry_point_type smpi_resolve_function(void* handle)\n{\n  smpi_fortran_entry_point_type entry_point_fortran = (smpi_fortran_entry_point_type)dlsym(handle, \"user_main_\");\n  if (entry_point_fortran != nullptr) {\n    return [entry_point_fortran](int argc, char** argv) {\n      smpi_process_init(&argc, &argv);\n      entry_point_fortran();\n      return 0;\n    };\n  }\n\n  smpi_c_entry_point_type entry_point = (smpi_c_entry_point_type)dlsym(handle, \"main\");\n  if (entry_point != nullptr) {\n    return entry_point;\n  }\n\n  return smpi_entry_point_type();\n}\n\nstatic void smpi_copy_file(std::string src, std::string target, off_t fdin_size)\n{\n  int fdin = open(src.c_str(), O_RDONLY);\n  xbt_assert(fdin >= 0, \"Cannot read from %s. Please make sure that the file exists and is executable.\", src.c_str());\n  int fdout = open(target.c_str(), O_CREAT | O_RDWR, S_IRWXU);\n  xbt_assert(fdout >= 0, \"Cannot write into %s\", target.c_str());\n\n  XBT_DEBUG(\"Copy %ld bytes into %s\", static_cast<long>(fdin_size), target.c_str());\n#if HAVE_SENDFILE\n  ssize_t sent_size = sendfile(fdout, fdin, NULL, fdin_size);\n  xbt_assert(sent_size == fdin_size, \"Error while copying %s: only %zd bytes copied instead of %ld (errno: %d -- %s)\",\n             target.c_str(), sent_size, fdin_size, errno, strerror(errno));\n#else\n  const int bufsize = 1024 * 1024 * 4;\n  char buf[bufsize];\n  while (int got = read(fdin, buf, bufsize)) {\n    if (got == -1) {\n      xbt_assert(errno == EINTR, \"Cannot read from %s\", src.c_str());\n    } else {\n      char* p  = buf;\n      int todo = got;\n      while (int done = write(fdout, p, todo)) {\n        if (done == -1) {\n          xbt_assert(errno == EINTR, \"Cannot write into %s\", target.c_str());\n        } else {\n          p += done;\n          todo -= done;\n        }\n      }\n    }\n  }\n#endif\n  close(fdin);\n  close(fdout);\n}\n\n#if not defined(__APPLE__)\nstatic int visit_libs(struct dl_phdr_info* info, size_t, void* data)\n{\n  char* libname = (char*)(data);\n  const char *path = info->dlpi_name;\n  if(strstr(path, libname)){\n    strncpy(libname, path, 512);\n    return 1;\n  }\n  \n  return 0;\n}\n#endif\n\nint smpi_main(const char* executable, int argc, char *argv[])\n{\n  srand(SMPI_RAND_SEED);\n\n  if (getenv(\"SMPI_PRETEND_CC\") != nullptr) {\n    /* Hack to ensure that smpicc can pretend to be a simple compiler. Particularly handy to pass it to the\n     * configuration tools */\n    return 0;\n  }\n\n  TRACE_global_init();\n\n  SIMIX_global_init(&argc, argv);\n  MSG_init(&argc,argv);\n\n  SMPI_switch_data_segment = &smpi_switch_data_segment;\n\n  // TODO This will not be executed in the case where smpi_main is not called,\n  // e.g., not for smpi_msg_masterslave. This should be moved to another location\n  // that is always called -- maybe close to Actor::onCreation?\n  simgrid::s4u::Host::on_creation.connect(\n      [](simgrid::s4u::Host& host) { host.extension_set(new simgrid::smpi::Host(&host)); });\n\n  // parse the platform file: get the host list\n  SIMIX_create_environment(argv[1]);\n  SIMIX_comm_set_copy_data_callback(smpi_comm_copy_buffer_callback);\n\n  smpi_init_options();\n  if (smpi_privatize_global_variables == SmpiPrivStrategies::DLOPEN) {\n\n    std::string executable_copy = executable;\n\n    // Prepare the copy of the binary (get its size)\n    struct stat fdin_stat;\n    stat(executable_copy.c_str(), &fdin_stat);\n    off_t fdin_size = fdin_stat.st_size;\n    static std::size_t rank = 0;\n    \n    \n    std::string libnames = simgrid::config::get_value<std::string>(\"smpi/privatize-libs\");\n    if(not libnames.empty()){\n      //split option\n      std::vector<std::string> privatize_libs;\n      boost::split(privatize_libs,libnames, boost::is_any_of(\";\"));\n\n      for (auto const& libname : privatize_libs) {\n        //load the library once to add it to the local libs, to get the absolute path\n        void* libhandle = dlopen(libname.c_str(), RTLD_LAZY);\n        //get library name from path\n        char fullpath[512]={'\\0'};\n        strcpy(fullpath, libname.c_str());\n#if not defined(__APPLE__)\n        int ret = dl_iterate_phdr(visit_libs, fullpath);\n        if(ret==0)\n          xbt_die(\"Can't find a linked %s - check the setting you gave to smpi/privatize-libs\", fullpath);\n        else\n          XBT_DEBUG(\"Extra lib to privatize found : %s\", fullpath);\n#else\n          xbt_die(\"smpi/privatize-libs is not (yet) compatible with OSX\");\n#endif\n        privatize_libs_paths.push_back(fullpath);\n        dlclose(libhandle);\n      }\n    }\n    \n    simix_global->default_function = [executable_copy, fdin_size](std::vector<std::string> args) {\n      return std::function<void()>([executable_copy, fdin_size, args] {\n\n        // Copy the dynamic library:\n        std::string target_executable = executable_copy\n          + \"_\" + std::to_string(getpid())\n          + \"_\" + std::to_string(rank) + \".so\";\n\n        smpi_copy_file(executable_copy, target_executable, fdin_size);\n        //if smpi/privatize-libs is set, duplicate pointed lib and link each executable copy to a different one.\n          std::string target_lib;\n          for (auto const& libpath : privatize_libs_paths){\n          //if we were given a full path, strip it\n          size_t index = libpath.find_last_of(\"/\\\\\");\n          std::string libname;\n          if(index!=std::string::npos)\n            libname=libpath.substr(index+1);\n\n          if(not libname.empty()){\n            //load the library to add it to the local libs, to get the absolute path\n            struct stat fdin_stat2;\n            stat(libpath.c_str(), &fdin_stat2);\n            off_t fdin_size2 = fdin_stat2.st_size;\n            \n            // Copy the dynamic library, the new name must be the same length as the old one\n            // just replace the name with 7 digits for the rank and the rest of the name.\n            unsigned int pad=7;\n            if(libname.length()<pad)\n              pad=libname.length();\n            target_lib = std::string(pad - std::to_string(rank).length(), '0')\n                        +std::to_string(rank)+libname.substr(pad);\n            XBT_DEBUG(\"copy lib %s to %s, with size %lld\", libpath.c_str(), target_lib.c_str(), (long long)fdin_size2);\n            smpi_copy_file(libpath, target_lib, fdin_size2);\n\n            std::string sedcommand = \"sed -i -e 's/\"+libname+\"/\"+target_lib+\"/g' \"+target_executable;\n            int ret = system(sedcommand.c_str());\n            if(ret!=0) xbt_die (\"error while applying sed command %s \\n\", sedcommand.c_str());\n          }\n        }\n\n        rank++;\n        // Load the copy and resolve the entry point:\n        void* handle = dlopen(target_executable.c_str(), RTLD_LAZY | RTLD_LOCAL | RTLD_DEEPBIND);\n        int saved_errno = errno;\n        if (simgrid::config::get_value<bool>(\"smpi/keep-temps\") == false){\n          unlink(target_executable.c_str());\n          if(not target_lib.empty())\n            unlink(target_lib.c_str());\n        }\n        if (handle == nullptr)\n          xbt_die(\"dlopen failed: %s (errno: %d -- %s)\", dlerror(), saved_errno, strerror(saved_errno));\n        smpi_entry_point_type entry_point = smpi_resolve_function(handle);\n        if (not entry_point)\n          xbt_die(\"Could not resolve entry point\");\n        smpi_run_entry_point(entry_point, args);\n      });\n    };\n  }\n  else {\n    if (smpi_privatize_global_variables == SmpiPrivStrategies::MMAP)\n      smpi_prepare_global_memory_segment();\n    // Load the dynamic library and resolve the entry point:\n    void* handle = dlopen(executable, RTLD_LAZY | RTLD_LOCAL);\n    if (handle == nullptr)\n      xbt_die(\"dlopen failed for %s: %s (errno: %d -- %s)\", executable, dlerror(), errno, strerror(errno));\n    smpi_entry_point_type entry_point = smpi_resolve_function(handle);\n    if (not entry_point)\n      xbt_die(\"main not found in %s\", executable);\n    if (smpi_privatize_global_variables == SmpiPrivStrategies::MMAP)\n      smpi_backup_global_memory_segment();\n\n    // Execute the same entry point for each simulated process:\n    simix_global->default_function = [entry_point](std::vector<std::string> args) {\n      return std::function<void()>([entry_point, args] {\n        smpi_run_entry_point(entry_point, args);\n      });\n    };\n  }\n\n  SMPI_init();\n  SIMIX_launch_application(argv[2]);\n  SMPI_app_instance_register(smpi_default_instance_name.c_str(), nullptr,\n                             process_data.size()); // This call has a side effect on process_count...\n  MPI_COMM_WORLD = *smpi_deployment_comm_world(smpi_default_instance_name);\n  smpi_universe_size = process_count;\n\n\n  /* Clean IO before the run */\n  fflush(stdout);\n  fflush(stderr);\n\n  if (MC_is_active()) {\n    MC_run();\n  } else {\n\n    SIMIX_run();\n\n    xbt_os_walltimer_stop(global_timer);\n    if (simgrid::config::get_value<bool>(\"smpi/display-timing\")) {\n      double global_time = xbt_os_timer_elapsed(global_timer);\n      XBT_INFO(\"Simulated time: %g seconds. \\n\\n\"\n          \"The simulation took %g seconds (after parsing and platform setup)\\n\"\n          \"%g seconds were actual computation of the application\",\n          SIMIX_get_clock(), global_time , smpi_total_benched_time);\n\n      if (smpi_total_benched_time/global_time>=0.75)\n      XBT_INFO(\"More than 75%% of the time was spent inside the application code.\\n\"\n      \"You may want to use sampling functions or trace replay to reduce this.\");\n    }\n  }\n  smpi_global_destroy();\n\n  return smpi_exit_status;\n}\n\n// Called either directly from the user code, or from the code called by smpirun\nvoid SMPI_init(){\n  simgrid::s4u::Actor::on_creation.connect([](simgrid::s4u::ActorPtr actor) {\n    if (not actor->is_daemon()) {\n      process_data.insert({actor, new simgrid::smpi::Process(actor, nullptr)});\n    }\n  });\n  simgrid::s4u::Actor::on_destruction.connect([](simgrid::s4u::ActorPtr actor) {\n    auto it = process_data.find(actor);\n    if (it != process_data.end()) {\n      delete it->second;\n      process_data.erase(it);\n    }\n  });\n\n  smpi_init_options();\n  smpi_global_init();\n  smpi_check_options();\n  simgrid::s4u::on_simulation_end.connect(TRACE_smpi_release);\n}\n\nvoid SMPI_finalize(){\n  smpi_global_destroy();\n}\n\nvoid smpi_mpi_init() {\n  if(smpi_init_sleep > 0)\n    simcall_process_sleep(smpi_init_sleep);\n}\n\ndouble smpi_mpi_wtime(){\n  double time;\n  if (smpi_process()->initialized() != 0 && smpi_process()->finalized() == 0 && smpi_process()->sampling() == 0) {\n    smpi_bench_end();\n    time = SIMIX_get_clock();\n    // to avoid deadlocks if used as a break condition, such as\n    //     while (MPI_Wtime(...) < time_limit) {\n    //       ....\n    //     }\n    // because the time will not normally advance when only calls to MPI_Wtime\n    // are made -> deadlock (MPI_Wtime never reaches the time limit)\n    if(smpi_wtime_sleep > 0)\n      simcall_process_sleep(smpi_wtime_sleep);\n    smpi_bench_begin();\n  } else {\n    time = SIMIX_get_clock();\n  }\n  return time;\n}\n\n",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.20-xigfpbo5yypiin5odq3dedwvkyxa5sxr/spack-src/src/simix/smx_context.cpp": "/* a fast and simple context switching library                              */\n\n/* Copyright (c) 2009-2018. The SimGrid Team. All rights reserved.          */\n\n/* This program is free software; you can redistribute it and/or modify it\n * under the terms of the license (GNU LGPL) which comes with this package. */\n\n#include <cerrno>\n#include <cstring>\n\n#include <utility>\n#include <string>\n\n#include <xbt/config.hpp>\n#include <xbt/log.h>\n#include <xbt/range.hpp>\n#include <xbt/sysdep.h>\n\n#include \"simgrid/modelchecker.h\"\n#include \"simgrid/sg_config.hpp\"\n#include \"smx_private.hpp\"\n#include \"src/internal_config.h\"\n#include \"xbt/log.h\"\n#include \"xbt/xbt_os_thread.h\"\n\n#ifdef _WIN32\n#include <windows.h>\n#include <malloc.h>\n#else\n#include <sys/mman.h>\n#endif\n\n#ifdef __MINGW32__\n#define _aligned_malloc __mingw_aligned_malloc\n#define _aligned_free  __mingw_aligned_free\n#endif /*MINGW*/\n\n#if HAVE_VALGRIND_H\n# include <valgrind/valgrind.h>\n#endif\n\nXBT_LOG_NEW_DEFAULT_SUBCATEGORY(simix_context, simix, \"Context switching mechanism\");\n\nstatic std::pair<const char*, simgrid::kernel::context::ContextFactoryInitializer> context_factories[] = {\n#if HAVE_RAW_CONTEXTS\n  { \"raw\", &simgrid::kernel::context::raw_factory },\n#endif\n#if HAVE_UCONTEXT_CONTEXTS\n  { \"ucontext\", &simgrid::kernel::context::sysv_factory },\n#endif\n#if HAVE_BOOST_CONTEXTS\n  { \"boost\", &simgrid::kernel::context::boost_factory },\n#endif\n#if HAVE_THREAD_CONTEXTS\n  { \"thread\", &simgrid::kernel::context::thread_factory },\n#endif\n};\n\nstatic_assert(sizeof(context_factories) != 0, \"No context factories are enabled for this build\");\n\n// Create the list of possible contexts:\nstatic inline\nstd::string contexts_list()\n{\n  std::string res;\n  const std::size_t n = sizeof(context_factories) / sizeof(context_factories[0]);\n  for (std::size_t i = 1; i != n; ++i) {\n    res += \", \";\n    res += context_factories[i].first;\n  }\n  return res;\n}\n\nstatic simgrid::config::Flag<std::string> context_factory_name(\n  \"contexts/factory\",\n  (std::string(\"Possible values: \")+contexts_list()).c_str(),\n  context_factories[0].first);\n\nunsigned smx_context_stack_size;\nint smx_context_stack_size_was_set = 0;\nunsigned smx_context_guard_size;\nint smx_context_guard_size_was_set = 0;\n#if HAVE_THREAD_LOCAL_STORAGE\nstatic XBT_THREAD_LOCAL smx_context_t smx_current_context_parallel;\n#else\nstatic xbt_os_thread_key_t smx_current_context_key = 0;\n#endif\nstatic smx_context_t smx_current_context_serial;\nstatic int smx_parallel_contexts = 1;\nstatic int smx_parallel_threshold = 2;\nstatic e_xbt_parmap_mode_t smx_parallel_synchronization_mode = XBT_PARMAP_DEFAULT;\n\n/**\n * This function is called by SIMIX_global_init() to initialize the context module.\n */\nvoid SIMIX_context_mod_init()\n{\n  xbt_assert(simix_global->context_factory == nullptr);\n\n  smx_context_stack_size_was_set = not simgrid::config::is_default(\"contexts/stack-size\");\n  smx_context_guard_size_was_set = not simgrid::config::is_default(\"contexts/guard-size\");\n\n#if HAVE_THREAD_CONTEXTS && not HAVE_THREAD_LOCAL_STORAGE\n  /* the __thread storage class is not available on this platform:\n   * use getspecific/setspecific instead to store the current context in each thread */\n  xbt_os_thread_key_create(&smx_current_context_key);\n#endif\n\n#if HAVE_SMPI && (defined(__APPLE__) || defined(__NetBSD__))\n  std::string priv = simgrid::config::get_value<std::string>(\"smpi/privatization\");\n  if (context_factory_name == \"thread\" && (priv == \"dlopen\" || priv == \"yes\" || priv == \"default\" || priv == \"1\")) {\n    XBT_WARN(\"dlopen+thread broken on Apple and BSD. Switching to raw contexts.\");\n    context_factory_name = \"raw\";\n  }\n#endif\n\n#if HAVE_SMPI && defined(__FreeBSD__)\n  if (context_factory_name == \"thread\" && simgrid::config::get_value<std::string>(\"smpi/privatization\") != \"no\") {\n    XBT_WARN(\"mmap broken on FreeBSD, but dlopen+thread broken too. Switching to dlopen+raw contexts.\");\n    context_factory_name = \"raw\";\n  }\n#endif\n\n  /* select the context factory to use to create the contexts */\n  if (simgrid::kernel::context::factory_initializer) { // Give Java a chance to hijack the factory mechanism\n    simix_global->context_factory = simgrid::kernel::context::factory_initializer();\n    return;\n  }\n  /* use the factory specified by --cfg=contexts/factory:value */\n  for (auto const& factory : context_factories)\n    if (context_factory_name == factory.first) {\n      simix_global->context_factory = factory.second();\n      break;\n    }\n\n  if (simix_global->context_factory == nullptr) {\n    XBT_ERROR(\"Invalid context factory specified. Valid factories on this machine:\");\n#if HAVE_RAW_CONTEXTS\n    XBT_ERROR(\"  raw: high performance context factory implemented specifically for SimGrid\");\n#else\n    XBT_ERROR(\"  (raw contexts were disabled at compilation time on this machine -- check configure logs for details)\");\n#endif\n#if HAVE_UCONTEXT_CONTEXTS\n    XBT_ERROR(\"  ucontext: classical system V contexts (implemented with makecontext, swapcontext and friends)\");\n#else\n    XBT_ERROR(\"  (ucontext was disabled at compilation time on this machine -- check configure logs for details)\");\n#endif\n#if HAVE_BOOST_CONTEXTS\n    XBT_ERROR(\"  boost: this uses the boost libraries context implementation\");\n#else\n    XBT_ERROR(\"  (boost was disabled at compilation time on this machine -- check configure logs for details. Did you install the libboost-context-dev package?)\");\n#endif\n    XBT_ERROR(\"  thread: slow portability layer using pthreads as provided by gcc\");\n    xbt_die(\"Please use a valid factory.\");\n  }\n}\n\n/**\n * This function is called by SIMIX_clean() to finalize the context module.\n */\nvoid SIMIX_context_mod_exit()\n{\n  delete simix_global->context_factory;\n  simix_global->context_factory = nullptr;\n}\n\nvoid *SIMIX_context_stack_new()\n{\n  void *stack;\n\n  if (smx_context_guard_size > 0 && not MC_is_active()) {\n\n#if !defined(PTH_STACKGROWTH) || (PTH_STACKGROWTH != -1)\n    xbt_die(\"Stack overflow protection is known to be broken on your system: you stacks grow upwards (or detection is \"\n            \"broken). \"\n            \"Please disable stack guards with --cfg=contexts:guard-size:0\");\n    /* Current code for stack overflow protection assumes that stacks are growing downward (PTH_STACKGROWTH == -1).\n     * Protected pages need to be put after the stack when PTH_STACKGROWTH == 1. */\n#endif\n\n    size_t size = smx_context_stack_size + smx_context_guard_size;\n#if SIMGRID_HAVE_MC\n    /* Cannot use posix_memalign when SIMGRID_HAVE_MC. Align stack by hand, and save the\n     * pointer returned by xbt_malloc0. */\n    char *alloc = (char*)xbt_malloc0(size + xbt_pagesize);\n    stack = alloc - ((uintptr_t)alloc & (xbt_pagesize - 1)) + xbt_pagesize;\n    *((void **)stack - 1) = alloc;\n#elif !defined(_WIN32)\n    if (posix_memalign(&stack, xbt_pagesize, size) != 0)\n      xbt_die(\"Failed to allocate stack.\");\n#else\n    stack = _aligned_malloc(size, xbt_pagesize);\n#endif\n\n#ifndef _WIN32\n    if (mprotect(stack, smx_context_guard_size, PROT_NONE) == -1) {\n      xbt_die(\n          \"Failed to protect stack: %s.\\n\"\n          \"If you are running a lot of actors, you may be exceeding the amount of mappings allowed per process.\\n\"\n          \"On Linux systems, change this value with sudo sysctl -w vm.max_map_count=newvalue (default value: 65536)\\n\"\n          \"Please see http://simgrid.gforge.inria.fr/simgrid/latest/doc/html/options.html#options_virt for more info.\",\n          strerror(errno));\n      /* This is fatal. We are going to fail at some point when we try reusing this. */\n    }\n#endif\n    stack = (char *)stack + smx_context_guard_size;\n  } else {\n    stack = xbt_malloc0(smx_context_stack_size);\n  }\n\n#if HAVE_VALGRIND_H\n  unsigned int valgrind_stack_id = VALGRIND_STACK_REGISTER(stack, (char *)stack + smx_context_stack_size);\n  memcpy((char *)stack + smx_context_usable_stack_size, &valgrind_stack_id, sizeof valgrind_stack_id);\n#endif\n\n  return stack;\n}\n\nvoid SIMIX_context_stack_delete(void *stack)\n{\n  if (not stack)\n    return;\n\n#if HAVE_VALGRIND_H\n  unsigned int valgrind_stack_id;\n  memcpy(&valgrind_stack_id, (char *)stack + smx_context_usable_stack_size, sizeof valgrind_stack_id);\n  VALGRIND_STACK_DEREGISTER(valgrind_stack_id);\n#endif\n\n#ifndef _WIN32\n  if (smx_context_guard_size > 0 && not MC_is_active()) {\n    stack = (char *)stack - smx_context_guard_size;\n    if (mprotect(stack, smx_context_guard_size, PROT_READ | PROT_WRITE) == -1) {\n      XBT_WARN(\"Failed to remove page protection: %s\", strerror(errno));\n      /* try to pursue anyway */\n    }\n#if SIMGRID_HAVE_MC\n    /* Retrieve the saved pointer.  See SIMIX_context_stack_new above. */\n    stack = *((void **)stack - 1);\n#endif\n  }\n#endif /* not windows */\n\n  xbt_free(stack);\n}\n\n/** @brief Returns whether some parallel threads are used for the user contexts. */\nint SIMIX_context_is_parallel() {\n  return smx_parallel_contexts > 1;\n}\n\n/**\n * @brief Returns the number of parallel threads used for the user contexts.\n * \\return the number of threads (1 means no parallelism)\n */\nint SIMIX_context_get_nthreads() {\n  return smx_parallel_contexts;\n}\n\n/**\n * \\brief Sets the number of parallel threads to use\n * for the user contexts.\n *\n * This function should be called before initializing SIMIX.\n * A value of 1 means no parallelism (1 thread only).\n * If the value is greater than 1, the thread support must be enabled.\n *\n * \\param nb_threads the number of threads to use\n */\nvoid SIMIX_context_set_nthreads(int nb_threads) {\n  if (nb_threads<=0) {\n     nb_threads = xbt_os_get_numcores();\n     XBT_INFO(\"Auto-setting contexts/nthreads to %d\",nb_threads);\n  }\n#if !HAVE_THREAD_CONTEXTS\n  xbt_assert(nb_threads == 1, \"Parallel runs are impossible when the pthreads are missing.\");\n#endif\n  smx_parallel_contexts = nb_threads;\n}\n\n/**\n * \\brief Returns the threshold above which user processes are run in parallel.\n *\n * If the number of threads is set to 1, there is no parallelism and this\n * threshold has no effect.\n *\n * \\return when the number of user processes ready to run is above\n * this threshold, they are run in parallel\n */\nint SIMIX_context_get_parallel_threshold() {\n  return smx_parallel_threshold;\n}\n\n/**\n * \\brief Sets the threshold above which user processes are run in parallel.\n *\n * If the number of threads is set to 1, there is no parallelism and this\n * threshold has no effect.\n *\n * \\param threshold when the number of user processes ready to run is above\n * this threshold, they are run in parallel\n */\nvoid SIMIX_context_set_parallel_threshold(int threshold) {\n  smx_parallel_threshold = threshold;\n}\n\n/**\n * \\brief Returns the synchronization mode used when processes are run in\n * parallel.\n * \\return how threads are synchronized if processes are run in parallel\n */\ne_xbt_parmap_mode_t SIMIX_context_get_parallel_mode() {\n  return smx_parallel_synchronization_mode;\n}\n\n/**\n * \\brief Sets the synchronization mode to use when processes are run in\n * parallel.\n * \\param mode how to synchronize threads if processes are run in parallel\n */\nvoid SIMIX_context_set_parallel_mode(e_xbt_parmap_mode_t mode) {\n  smx_parallel_synchronization_mode = mode;\n}\n\n/**\n * \\brief Returns the current context of this thread.\n * \\return the current context of this thread\n */\nsmx_context_t SIMIX_context_get_current()\n{\n  if (SIMIX_context_is_parallel()) {\n#if HAVE_THREAD_LOCAL_STORAGE\n    return smx_current_context_parallel;\n#else\n    return xbt_os_thread_get_specific(smx_current_context_key);\n#endif\n  }\n  else {\n    return smx_current_context_serial;\n  }\n}\n\n/**\n * \\brief Sets the current context of this thread.\n * \\param context the context to set\n */\nvoid SIMIX_context_set_current(smx_context_t context)\n{\n  if (SIMIX_context_is_parallel()) {\n#if HAVE_THREAD_LOCAL_STORAGE\n    smx_current_context_parallel = context;\n#else\n    xbt_os_thread_set_specific(smx_current_context_key, context);\n#endif\n  }\n  else {\n    smx_current_context_serial = context;\n  }\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.20-xigfpbo5yypiin5odq3dedwvkyxa5sxr/spack-src/teshsuite/smpi/CMakeLists.txt": "if(enable_smpi)\n  if(WIN32)\n    set(CMAKE_C_FLAGS \"-include ${CMAKE_HOME_DIRECTORY}/include/smpi/smpi_main.h\")\n  else()\n    set(CMAKE_C_COMPILER \"${CMAKE_BINARY_DIR}/smpi_script/bin/smpicc\")\n  endif()\n\n  include_directories(BEFORE \"${CMAKE_HOME_DIRECTORY}/include/smpi\")\n  foreach(x coll-allgather coll-allgatherv coll-allreduce coll-alltoall coll-alltoallv coll-barrier coll-bcast\n            coll-gather coll-reduce coll-reduce-scatter coll-scatter macro-sample pt2pt-dsend pt2pt-pingpong\n            type-hvector type-indexed type-struct type-vector bug-17132 timers privatization )\n    add_executable       (${x}  ${x}/${x}.c)\n    target_link_libraries(${x}  simgrid)\n    set_target_properties(${x}  PROPERTIES RUNTIME_OUTPUT_DIRECTORY ${CMAKE_CURRENT_BINARY_DIR}/${x})\n  endforeach()\n\n  if(NOT WIN32)\n    foreach(x macro-shared macro-partial-shared macro-partial-shared-communication )\n      add_executable       (${x}  ${x}/${x}.c)\n      target_link_libraries(${x}  simgrid)\n      set_target_properties(${x}  PROPERTIES RUNTIME_OUTPUT_DIRECTORY ${CMAKE_CURRENT_BINARY_DIR}/${x})\n    endforeach()\n  endif()\nendif()\n\nforeach(x coll-allgather coll-allgatherv coll-allreduce coll-alltoall coll-alltoallv coll-barrier coll-bcast\n    coll-gather coll-reduce coll-reduce-scatter coll-scatter macro-sample pt2pt-dsend pt2pt-pingpong\n    type-hvector type-indexed type-struct type-vector bug-17132 timers privatization\n    macro-shared macro-partial-shared macro-partial-shared-communication)\n  set(tesh_files    ${tesh_files}    ${CMAKE_CURRENT_SOURCE_DIR}/${x}/${x}.tesh)\n  set(teshsuite_src ${teshsuite_src} ${CMAKE_CURRENT_SOURCE_DIR}/${x}/${x}.c)\nendforeach()\n\nset (teshsuite_src ${teshsuite_src} PARENT_SCOPE)\nset(tesh_files    ${tesh_files}     ${CMAKE_CURRENT_SOURCE_DIR}/coll-allreduce/coll-allreduce-large.tesh\n                                    ${CMAKE_CURRENT_SOURCE_DIR}/coll-allreduce/coll-allreduce-automatic.tesh\n                                    ${CMAKE_CURRENT_SOURCE_DIR}/coll-alltoall/clusters.tesh\n                                    ${CMAKE_CURRENT_SOURCE_DIR}/pt2pt-pingpong/broken_hostfiles.tesh\n                                    ${CMAKE_CURRENT_SOURCE_DIR}/pt2pt-pingpong/TI_output.tesh                                       PARENT_SCOPE)\nset(bin_files       ${bin_files}    ${CMAKE_CURRENT_SOURCE_DIR}/hostfile\n                                    ${CMAKE_CURRENT_SOURCE_DIR}/hostfile_cluster\n                                    ${CMAKE_CURRENT_SOURCE_DIR}/hostfile_coll\n                                    ${CMAKE_CURRENT_SOURCE_DIR}/hostfile_empty                             PARENT_SCOPE)\n\nif(enable_smpi)\n  if(NOT WIN32)\n    ADD_TESH_FACTORIES(tesh-smpi-macro-shared \"thread;ucontext;raw;boost\" --setenv platfdir=${CMAKE_HOME_DIRECTORY}/examples/platforms --setenv bindir=${CMAKE_BINARY_DIR}/teshsuite/smpi/macro-shared --cd ${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/macro-shared macro-shared.tesh)\n    ADD_TESH_FACTORIES(tesh-smpi-macro-partial-shared \"thread;ucontext;raw;boost\" --setenv platfdir=${CMAKE_HOME_DIRECTORY}/examples/platforms --setenv bindir=${CMAKE_BINARY_DIR}/teshsuite/smpi/macro-partial-shared --cd ${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/macro-partial-shared macro-partial-shared.tesh)\n    ADD_TESH_FACTORIES(tesh-smpi-macro-partial-shared-communication \"thread;ucontext;raw;boost\" --setenv platfdir=${CMAKE_HOME_DIRECTORY}/examples/platforms --setenv bindir=${CMAKE_BINARY_DIR}/teshsuite/smpi/macro-partial-shared-communication --cd ${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/macro-partial-shared-communication macro-partial-shared-communication.tesh)\n  endif()\n\n  foreach(x coll-allgather coll-allgatherv coll-allreduce coll-alltoall coll-alltoallv coll-barrier coll-bcast\n            coll-gather coll-reduce coll-reduce-scatter coll-scatter macro-sample pt2pt-dsend pt2pt-pingpong\n            type-hvector type-indexed type-struct type-vector bug-17132 timers)\n    ADD_TESH_FACTORIES(tesh-smpi-${x} \"thread;ucontext;raw;boost\" --setenv platfdir=${CMAKE_HOME_DIRECTORY}/examples/platforms --setenv srcdir=${CMAKE_HOME_DIRECTORY}/examples/platforms --setenv bindir=${CMAKE_BINARY_DIR}/teshsuite/smpi/${x} --cd ${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/${x} ${x}.tesh)\n  endforeach()\n\n  foreach (ALLGATHER 2dmesh 3dmesh bruck GB loosely_lr NTSLR NTSLR_NB pair rdb  rhv ring SMP_NTS smp_simple spreading_simple\n                     ompi mpich ompi_neighborexchange mvapich2 mvapich2_smp impi)\n    ADD_TESH(tesh-smpi-coll-allgather-${ALLGATHER} --cfg smpi/allgather:${ALLGATHER} --setenv platfdir=${CMAKE_HOME_DIRECTORY}/examples/platforms --setenv bindir=${CMAKE_BINARY_DIR}/teshsuite/smpi/coll-allgather --cd ${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/coll-allgather coll-allgather.tesh)\n  endforeach()\n\n  foreach (ALLGATHERV GB pair ring ompi mpich ompi_neighborexchange ompi_bruck mpich_rdb mpich_ring mvapich2 impi)\n    ADD_TESH(tesh-smpi-coll-allgatherv-${ALLGATHERV} --cfg smpi/allgatherv:${ALLGATHERV} --setenv platfdir=${CMAKE_HOME_DIRECTORY}/examples/platforms --setenv bindir=${CMAKE_BINARY_DIR}/teshsuite/smpi/coll-allgatherv --cd ${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/coll-allgatherv coll-allgatherv.tesh)\n  endforeach()\n\n  foreach (ALLREDUCE lr rab1 rab2 rab_rdb rdb smp_binomial smp_binomial_pipeline smp_rdb smp_rsag smp_rsag_lr impi\n                     smp_rsag_rab redbcast ompi mpich ompi_ring_segmented mvapich2 mvapich2_rs mvapich2_two_level)\n    ADD_TESH(tesh-smpi-coll-allreduce-${ALLREDUCE} --cfg smpi/allreduce:${ALLREDUCE} --setenv platfdir=${CMAKE_HOME_DIRECTORY}/examples/platforms --setenv bindir=${CMAKE_BINARY_DIR}/teshsuite/smpi/coll-allreduce --cd ${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/coll-allreduce coll-allreduce.tesh)\n  endforeach()\n\n  foreach (ALLTOALL 2dmesh 3dmesh pair pair_rma pair_one_barrier pair_light_barrier pair_mpi_barrier rdb ring\n                    ring_light_barrier ring_mpi_barrier ring_one_barrier bruck basic_linear ompi mpich mvapich2\n                    mvapich2_scatter_dest impi)\n    ADD_TESH(tesh-smpi-coll-alltoall-${ALLTOALL} --cfg smpi/alltoall:${ALLTOALL} --setenv platfdir=${CMAKE_HOME_DIRECTORY}/examples/platforms --setenv bindir=${CMAKE_BINARY_DIR}/teshsuite/smpi/coll-alltoall --cd ${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/coll-alltoall coll-alltoall.tesh)\n  endforeach()\n\n  foreach (ALLTOALLV pair pair_light_barrier pair_mpi_barrier pair_one_barrier  ring ring_light_barrier ring_mpi_barrier\n                     ring_one_barrier bruck ompi mpich mvapich2 ompi_basic_linear impi)\n    ADD_TESH(tesh-smpi-coll-alltoallv-${ALLTOALLV} --cfg smpi/alltoallv:${ALLTOALLV} --setenv platfdir=${CMAKE_HOME_DIRECTORY}/examples/platforms --setenv bindir=${CMAKE_BINARY_DIR}/teshsuite/smpi/coll-alltoallv --cd ${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/coll-alltoallv coll-alltoallv.tesh)\n  endforeach()\n\n  foreach (BARRIER ompi mpich ompi_basic_linear ompi_tree ompi_bruck ompi_recursivedoubling ompi_doublering mvapich2_pair mvapich2 impi)\n      ADD_TESH(tesh-smpi-coll-barrier-${BARRIER} --cfg smpi/barrier:${BARRIER} --setenv platfdir=${CMAKE_HOME_DIRECTORY}/examples/platforms --setenv bindir=${CMAKE_BINARY_DIR}/teshsuite/smpi/coll-barrier --cd ${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/coll-barrier coll-barrier.tesh)\n  endforeach()\n\n  foreach (BCAST arrival_pattern_aware arrival_pattern_aware_wait arrival_scatter binomial_tree flattree\n                 flattree_pipeline NTSB NTSL NTSL_Isend scatter_LR_allgather scatter_rdb_allgather SMP_binary\n                 SMP_binomial SMP_linear ompi mpich ompi_split_bintree ompi_pipeline mvapich2 mvapich2_intra_node\n                 mvapich2_knomial_intra_node impi)\n    ADD_TESH(tesh-smpi-coll-bcast-${BCAST} --cfg smpi/bcast:${BCAST} --setenv platfdir=${CMAKE_HOME_DIRECTORY}/examples/platforms --setenv bindir=${CMAKE_BINARY_DIR}/teshsuite/smpi/coll-bcast --cd ${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/coll-bcast coll-bcast.tesh)\n  endforeach()\n\n  foreach (GATHER ompi mpich ompi_basic_linear ompi_linear_sync ompi_binomial mvapich2 mvapich2_two_level impi)\n    ADD_TESH(tesh-smpi-coll-gather-${GATHER} --cfg smpi/gather:${GATHER} --setenv platfdir=${CMAKE_HOME_DIRECTORY}/examples/platforms --setenv bindir=${CMAKE_BINARY_DIR}/teshsuite/smpi/coll-gather --cd ${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/coll-gather coll-gather.tesh)\n  endforeach()\n\n  foreach (REDUCE arrival_pattern_aware binomial flat_tree NTSL scatter_gather ompi mpich ompi_chain ompi_binary impi\n                  ompi_basic_linear ompi_binomial ompi_in_order_binary mvapich2 mvapich2_knomial mvapich2_two_level rab)\n    ADD_TESH(tesh-smpi-coll-reduce-${REDUCE} --cfg smpi/reduce:${REDUCE} --setenv platfdir=${CMAKE_HOME_DIRECTORY}/examples/platforms --setenv bindir=${CMAKE_BINARY_DIR}/teshsuite/smpi/coll-reduce --cd ${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/coll-reduce coll-reduce.tesh)\n  endforeach()\n\n  foreach (REDUCE_SCATTER ompi mpich ompi_basic_recursivehalving ompi_ring mpich_noncomm mpich_pair mvapich2 mpich_rdb impi)\n    ADD_TESH(tesh-smpi-coll-reduce-scatter-${REDUCE_SCATTER} --cfg smpi/reduce_scatter:${REDUCE_SCATTER} --setenv platfdir=${CMAKE_HOME_DIRECTORY}/examples/platforms --setenv bindir=${CMAKE_BINARY_DIR}/teshsuite/smpi/coll-reduce-scatter --cd ${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/coll-reduce-scatter coll-reduce-scatter.tesh)\n  endforeach()\n\n  foreach (SCATTER ompi mpich ompi_basic_linear ompi_binomial mvapich2 mvapich2_two_level_binomial mvapich2_two_level_direct impi)\n    ADD_TESH(tesh-smpi-coll-scatter-${SCATTER} --cfg smpi/scatter:${SCATTER} --setenv platfdir=${CMAKE_HOME_DIRECTORY}/examples/platforms --setenv bindir=${CMAKE_BINARY_DIR}/teshsuite/smpi/coll-scatter --cd ${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/coll-scatter coll-scatter.tesh)\n  endforeach()\n\n  # Extra allreduce test: large automatic\n  ADD_TESH(tesh-smpi-coll-allreduce-large --cfg smpi/allreduce:ompi_ring_segmented --setenv platfdir=${CMAKE_HOME_DIRECTORY}/examples/platforms --setenv bindir=${CMAKE_BINARY_DIR}/teshsuite/smpi/coll-allreduce --cd ${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/coll-allreduce coll-allreduce-large.tesh)\n  ADD_TESH(tesh-smpi-coll-allreduce-automatic --setenv platfdir=${CMAKE_HOME_DIRECTORY}/examples/platforms --setenv bindir=${CMAKE_BINARY_DIR}/teshsuite/smpi/coll-allreduce --cd ${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/coll-allreduce coll-allreduce-automatic.tesh)\n\n  # Extra allreduce test: cluster-types\n  ADD_TESH(tesh-smpi-cluster-types --cfg smpi/alltoall:mvapich2 --setenv platfdir=${CMAKE_HOME_DIRECTORY}/examples/platforms --setenv bindir=${CMAKE_BINARY_DIR}/teshsuite/smpi/coll-alltoall --cd ${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/coll-alltoall clusters.tesh)\n\n  # Extra pt2pt pingpong test: broken usage ti-tracing\n  ADD_TESH_FACTORIES(tesh-smpi-broken  \"thread\"   --setenv platfdir=${CMAKE_HOME_DIRECTORY}/examples/platforms --setenv bindir=${CMAKE_BINARY_DIR}/teshsuite/smpi/pt2pt-pingpong --cd ${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/pt2pt-pingpong broken_hostfiles.tesh)\n  ADD_TESH(tesh-smpi-replay-ti-tracing            --setenv platfdir=${CMAKE_HOME_DIRECTORY}/examples/platforms --setenv srcdir=${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/pt2pt-pingpong --cd ${CMAKE_BINARY_DIR}/teshsuite/smpi/pt2pt-pingpong ${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/pt2pt-pingpong/TI_output.tesh)\n\n  # Simple privatization tests\n  if(HAVE_PRIVATIZATION)\n    foreach(PRIVATIZATION dlopen mmap)\n      ADD_TESH_FACTORIES(tesh-smpi-privatization-${PRIVATIZATION}  \"thread;ucontext;raw;boost\" --setenv privatization=${PRIVATIZATION} --setenv platfdir=${CMAKE_HOME_DIRECTORY}/examples/platforms --setenv bindir=${CMAKE_BINARY_DIR}/teshsuite/smpi/privatization --cd ${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/privatization privatization.tesh)\n    endforeach()\n  endif()\nendif()\n",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.20-xigfpbo5yypiin5odq3dedwvkyxa5sxr/spack-src/teshsuite/smpi/mpich3-test/coll/CMakeLists.txt": "if(enable_smpi AND enable_smpi_MPICH3_testsuite)\n  if(WIN32)\n    set(CMAKE_C_FLAGS \"-include ${CMAKE_HOME_DIRECTORY}/include/smpi/smpi_main.h\")\n  else()\n    set(CMAKE_C_COMPILER \"${CMAKE_BINARY_DIR}/smpi_script/bin/smpicc\")\n    set(CMAKE_Fortran_COMPILER \"${CMAKE_BINARY_DIR}/smpi_script/bin/smpiff\")\n  endif()\n\n  include_directories(BEFORE \"${CMAKE_HOME_DIRECTORY}/include/smpi\")\n  include_directories(\"${CMAKE_CURRENT_SOURCE_DIR}/../include/\")\n\n  add_executable(allgather2 allgather2.c)\n  add_executable(allgather3 allgather3.c)\n  add_executable(allgather_struct allgather_struct.c)\n  add_executable(allgatherv2 allgatherv2.c)\n  add_executable(allgatherv3 allgatherv3.c)\n  if(HAVE_PRIVATIZATION)\n    add_executable(allgatherv4 allgatherv4.c)\n  else()\n    add_executable(allgatherv4 allgatherv4_manual.c)\n  endif()\n  add_executable(allred2 allred2.c)\n  add_executable(allred3 allred3.c)\n  add_executable(allred4 allred4.c)\n  add_executable(allred5 allred5.c)\n  add_executable(allred6 allred6.c)\n  if(HAVE_PRIVATIZATION)\n    add_executable(allred allred.c)\n  else()\n    add_executable(allred allred_manual.c)\n  endif()\n  add_executable(allredmany allredmany.c)\n  add_executable(alltoall1 alltoall1.c)\n  add_executable(alltoallv0 alltoallv0.c)\n  add_executable(alltoallv alltoallv.c)\n#  add_executable(alltoallw1 alltoallw1.c)\n#  add_executable(alltoallw2 alltoallw2.c)\n#  add_executable(alltoallw_zeros alltoallw_zeros.c)\n  add_executable(bcast_full bcast.c)\n  add_executable(bcast_min_datatypes bcast.c)\n  add_executable(bcast_comm_world bcast.c)\n  add_executable(bcasttest bcasttest.c)\n  add_executable(bcastzerotype bcastzerotype.c)\n  add_executable(coll10 coll10.c)\n  add_executable(coll11 coll11.c)\n  add_executable(coll12 coll12.c)\n  add_executable(coll13 coll13.c)\n  add_executable(coll2 coll2.c)\n  add_executable(coll3 coll3.c)\n  add_executable(coll4 coll4.c)\n  add_executable(coll5 coll5.c)\n  add_executable(coll6 coll6.c)\n  add_executable(coll7 coll7.c)\n  add_executable(coll8 coll8.c)\n  add_executable(coll9 coll9.c)\n  add_executable(exscan2 exscan2.c)\n  add_executable(exscan exscan.c)\n  add_executable(gather2 gather2.c)\n  add_executable(gather_big gather_big.c)\n  add_executable(gather gather.c)\n#  add_executable(iallred iallred.c)\n#  add_executable(ibarrier ibarrier.c)\n#  add_executable(icallgather icallgather.c)\n#  add_executable(icallgatherv icallgatherv.c)\n#  add_executable(icallreduce icallreduce.c)\n#  add_executable(icalltoall icalltoall.c)\n#  add_executable(icalltoallv icalltoallv.c)\n#  add_executable(icalltoallw icalltoallw.c)\n#  add_executable(icbarrier icbarrier.c)\n#  add_executable(icbcast icbcast.c)\n#  add_executable(icgather icgather.c)\n#  add_executable(icgatherv icgatherv.c)\n#  add_executable(icreduce icreduce.c)\n#  add_executable(icscatter icscatter.c)\n#  add_executable(icscatterv icscatterv.c)\n  add_executable(longuser longuser.c)\n#  add_executable(nonblocking2 nonblocking2.c)\n#  add_executable(nonblocking3 nonblocking3.c)\n#  add_executable(nonblocking nonblocking.c)\n#  add_executable(opband opband.c)\n#  add_executable(opbor opbor.c)\n#  add_executable(opbxor opbxor.c)\n  add_executable(op_commutative op_commutative.c)\n#  add_executable(opland opland.c)\n#  add_executable(oplor oplor.c)\n#  add_executable(oplxor oplxor.c)\n#  add_executable(opmax opmax.c)\n#  add_executable(opmaxloc opmaxloc.c)\n#  add_executable(opmin opmin.c)\n#  add_executable(opminloc opminloc.c)\n#  add_executable(opprod opprod.c)\n#  add_executable(opsum opsum.c)\n  add_executable(red3 red3.c)\n  add_executable(red4 red4.c)\n  add_executable(redscat2 redscat2.c)\n  add_executable(redscat3 redscat3.c)\n  add_executable(redscatbkinter redscatbkinter.c)\n  add_executable(redscatblk3 redscatblk3.c)\n  add_executable(red_scat_block2 red_scat_block2.c)\n  add_executable(red_scat_block red_scat_block.c)\n  add_executable(redscat redscat.c)\n#  add_executable(redscatinter redscatinter.c)\n  add_executable(reduce_mpich reduce.c)\n  add_executable(reduce_local reduce_local.c)\n  add_executable(scantst scantst.c)\n  add_executable(scatter2 scatter2.c)\n  add_executable(scatter3 scatter3.c)\n  add_executable(scattern scattern.c)\n  add_executable(scatterv scatterv.c)\n#  add_executable(uoplong uoplong.c)\n\n  target_link_libraries(allgather2  simgrid mtest_c)\n  target_link_libraries(allgather3  simgrid mtest_c)\n  target_link_libraries(allgather_struct  simgrid mtest_c)\n  target_link_libraries(allgatherv2  simgrid mtest_c)\n  target_link_libraries(allgatherv3  simgrid mtest_c)\n  target_link_libraries(allgatherv4  simgrid mtest_c)\n  target_link_libraries(allred2  simgrid mtest_c)\n  target_link_libraries(allred3  simgrid mtest_c)\n  target_link_libraries(allred4  simgrid mtest_c)\n  target_link_libraries(allred5  simgrid mtest_c)\n  target_link_libraries(allred6  simgrid mtest_c)\n  target_link_libraries(allred  simgrid mtest_c)\n  target_link_libraries(allredmany  simgrid mtest_c)\n  target_link_libraries(alltoall1  simgrid mtest_c)\n  target_link_libraries(alltoallv0  simgrid mtest_c)\n  target_link_libraries(alltoallv  simgrid mtest_c)\n#  target_link_libraries(alltoallw1  simgrid mtest_c)\n#  target_link_libraries(alltoallw2  simgrid mtest_c)\n#  target_link_libraries(alltoallw_zeros  simgrid mtest_c)\n  target_link_libraries(bcast_full  simgrid mtest_c)\n  target_link_libraries(bcast_min_datatypes  simgrid mtest_c)\n  target_link_libraries(bcast_comm_world  simgrid mtest_c)\n  target_link_libraries(bcasttest  simgrid mtest_c)\n  target_link_libraries(bcastzerotype  simgrid mtest_c)\n  target_link_libraries(coll10  simgrid mtest_c)\n  target_link_libraries(coll11  simgrid mtest_c)\n  target_link_libraries(coll12  simgrid mtest_c)\n  target_link_libraries(coll13  simgrid mtest_c)\n  target_link_libraries(coll2  simgrid mtest_c)\n  target_link_libraries(coll3  simgrid mtest_c)\n  target_link_libraries(coll4  simgrid mtest_c)\n  target_link_libraries(coll5  simgrid mtest_c)\n  target_link_libraries(coll6  simgrid mtest_c)\n  target_link_libraries(coll7  simgrid mtest_c)\n  target_link_libraries(coll8  simgrid mtest_c)\n  target_link_libraries(coll9  simgrid mtest_c)\n  target_link_libraries(exscan2  simgrid mtest_c)\n  target_link_libraries(exscan  simgrid mtest_c)\n  target_link_libraries(gather2  simgrid mtest_c)\n  target_link_libraries(gather_big  simgrid mtest_c)\n  target_link_libraries(gather  simgrid mtest_c)\n#  target_link_libraries(iallred  simgrid mtest_c)\n#  target_link_libraries(ibarrier  simgrid mtest_c)\n#  target_link_libraries(icallgather  simgrid mtest_c)\n#  target_link_libraries(icallgatherv  simgrid mtest_c)\n#  target_link_libraries(icallreduce  simgrid mtest_c)\n#  target_link_libraries(icalltoall  simgrid mtest_c)\n#  target_link_libraries(icalltoallv  simgrid mtest_c)\n#  target_link_libraries(icalltoallw  simgrid mtest_c)\n#  target_link_libraries(icbarrier  simgrid mtest_c)\n#  target_link_libraries(icbcast  simgrid mtest_c)\n#  target_link_libraries(icgather  simgrid mtest_c)\n#  target_link_libraries(icgatherv  simgrid mtest_c)\n#  target_link_libraries(icreduce  simgrid mtest_c)\n#  target_link_libraries(icscatter  simgrid mtest_c)\n#  target_link_libraries(icscatterv  simgrid mtest_c)\n  target_link_libraries(longuser  simgrid mtest_c)\n#  target_link_libraries(nonblocking2  simgrid mtest_c)\n#  target_link_libraries(nonblocking3  simgrid mtest_c)\n#  target_link_libraries(nonblocking  simgrid mtest_c)\n#  target_link_libraries(opband  simgrid mtest_c)\n#  target_link_libraries(opbor  simgrid mtest_c)\n#  target_link_libraries(opbxor  simgrid mtest_c)\n  target_link_libraries(op_commutative  simgrid mtest_c)\n#  target_link_libraries(opland  simgrid mtest_c)\n#  target_link_libraries(oplor  simgrid mtest_c)\n#  target_link_libraries(oplxor  simgrid mtest_c)\n#  target_link_libraries(opmax  simgrid mtest_c)\n#  target_link_libraries(opmaxloc  simgrid mtest_c)\n#  target_link_libraries(opmin  simgrid mtest_c)\n#  target_link_libraries(opminloc  simgrid mtest_c)\n#  target_link_libraries(opprod  simgrid mtest_c)\n#  target_link_libraries(opsum  simgrid mtest_c)\n  target_link_libraries(red3  simgrid mtest_c)\n  target_link_libraries(red4  simgrid mtest_c)\n  target_link_libraries(redscat2  simgrid mtest_c)\n  target_link_libraries(redscat3  simgrid mtest_c)\n  target_link_libraries(redscatbkinter  simgrid mtest_c)\n  target_link_libraries(redscatblk3  simgrid mtest_c)\n  target_link_libraries(red_scat_block2  simgrid mtest_c)\n  target_link_libraries(red_scat_block  simgrid mtest_c)\n  target_link_libraries(redscat  simgrid mtest_c)\n#  target_link_libraries(redscatinter  simgrid mtest_c)\n  target_link_libraries(reduce_mpich  simgrid mtest_c)\n  target_link_libraries(reduce_local  simgrid mtest_c)\n  target_link_libraries(scantst  simgrid mtest_c)\n  target_link_libraries(scatter2  simgrid mtest_c)\n  target_link_libraries(scatter3  simgrid mtest_c)\n  target_link_libraries(scattern  simgrid mtest_c)\n  target_link_libraries(scatterv  simgrid mtest_c)\n#  target_link_libraries(uoplong  simgrid mtest_c)\n\n  set_target_properties(allred PROPERTIES COMPILE_FLAGS \"-O0\" LINK_FLAGS \"-O0\")\n  set_target_properties(bcast_min_datatypes PROPERTIES COMPILE_FLAGS \"-DBCAST_MIN_DATATYPES_ONLY\" LINK_FLAGS \"-DBCAST_MIN_DATATYPES_ONLY\")\n  set_target_properties(bcast_comm_world PROPERTIES COMPILE_FLAGS \"-DBCAST_COMM_WORLD_ONLY\" LINK_FLAGS \"-DBCAST_COMM_WORLD_ONLY\")\n\n  # These tests take 5 to 15 seconds to run, so we don't want to run them several times.\n  # But at the same time, we'd like to check if they work for all factories and all privatization algorithm\n  # Thus the current matrix\n\n  MACRO(ADD_MPICH3_COLL SELECTOR FACTORY PRIVATIZATION)\n    set(NAME \"test-smpi-mpich3-coll-${SELECTOR}\")\n    set(ARGS \"-execarg=--cfg=smpi/coll-selector:${SELECTOR}\" ${ARGN})\n    if(NOT \"${PRIVATIZATION}\" STREQUAL \"\" AND HAVE_PRIVATIZATION)\n      set(NAME \"${NAME}-${PRIVATIZATION}\")\n      set(ARGS ${ARGS} \"-execarg=--cfg=smpi/privatization:${PRIVATIZATION}\")\n    endif()\n    string(TOUPPER \"HAVE_${FACTORY}_CONTEXTS\" HAVE_FACTORY)\n    if(NOT \"${FACTORY}\" STREQUAL \"\" AND ${HAVE_FACTORY})\n      set(NAME \"${NAME}-${FACTORY}\")\n      set(ARGS ${ARGS} \"-execarg=--cfg=contexts/factory:${FACTORY}\")\n    endif()\n    ADD_TEST(${NAME} ${CMAKE_COMMAND} -E chdir ${CMAKE_BINARY_DIR}/teshsuite/smpi/mpich3-test/coll ${PERL_EXECUTABLE} ${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/mpich3-test/runtests ${TESH_OPTION} -mpiexec=${CMAKE_BINARY_DIR}/smpi_script/bin/smpirun -srcdir=${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/mpich3-test/coll -tests=testlist ${ARGS})\n    SET_TESTS_PROPERTIES(${NAME} PROPERTIES PASS_REGULAR_EXPRESSION \"tests passed!\")\n  ENDMACRO()\n\n  # Test default selector; default factory; default privatization\n  ADD_MPICH3_COLL(default \"\" \"\")\n\n  # Test OMPI selector: thread factory, dlopen privatization\n  ADD_MPICH3_COLL(ompi \"thread\" \"dlopen\" -execarg=--cfg=smpi/bcast:binomial_tree)\n\n  # Test MPICH selector: boost factory, dlopen privatization\n  ADD_MPICH3_COLL(mpich \"boost\" \"dlopen\")\n\n  # Test MVAPICH2 selector: ucontext factory, mmap privatization\n  ADD_MPICH3_COLL(mvapich2 \"ucontext\" \"mmap\")\n\n  # Test IMPI selector: raw factory, mmap privatization\n  ADD_MPICH3_COLL(impi \"raw\" \"mmap\")\n\nendif()\n\nset(examples_src  ${examples_src}\n ${CMAKE_CURRENT_SOURCE_DIR}/allgather2.c \n ${CMAKE_CURRENT_SOURCE_DIR}/allgather_struct.c \n ${CMAKE_CURRENT_SOURCE_DIR}/allgather3.c \n ${CMAKE_CURRENT_SOURCE_DIR}/allgatherv2.c \n ${CMAKE_CURRENT_SOURCE_DIR}/allgatherv3.c \n ${CMAKE_CURRENT_SOURCE_DIR}/allgatherv4.c \n ${CMAKE_CURRENT_SOURCE_DIR}/allgatherv4_manual.c \n ${CMAKE_CURRENT_SOURCE_DIR}/allred2.c \n ${CMAKE_CURRENT_SOURCE_DIR}/allred3.c \n ${CMAKE_CURRENT_SOURCE_DIR}/allred4.c \n ${CMAKE_CURRENT_SOURCE_DIR}/allred5.c \n ${CMAKE_CURRENT_SOURCE_DIR}/allred6.c \n ${CMAKE_CURRENT_SOURCE_DIR}/allred.c \n ${CMAKE_CURRENT_SOURCE_DIR}/allred_manual.c \n ${CMAKE_CURRENT_SOURCE_DIR}/allredmany.c \n ${CMAKE_CURRENT_SOURCE_DIR}/alltoall1.c \n ${CMAKE_CURRENT_SOURCE_DIR}/alltoallv0.c \n ${CMAKE_CURRENT_SOURCE_DIR}/alltoallv.c \n ${CMAKE_CURRENT_SOURCE_DIR}/alltoallw1.c \n ${CMAKE_CURRENT_SOURCE_DIR}/alltoallw2.c \n ${CMAKE_CURRENT_SOURCE_DIR}/alltoallw_zeros.c \n ${CMAKE_CURRENT_SOURCE_DIR}/bcast.c \n ${CMAKE_CURRENT_SOURCE_DIR}/bcasttest.c \n ${CMAKE_CURRENT_SOURCE_DIR}/bcastzerotype.c \n ${CMAKE_CURRENT_SOURCE_DIR}/coll10.c \n ${CMAKE_CURRENT_SOURCE_DIR}/coll11.c \n ${CMAKE_CURRENT_SOURCE_DIR}/coll12.c \n ${CMAKE_CURRENT_SOURCE_DIR}/coll13.c \n ${CMAKE_CURRENT_SOURCE_DIR}/coll2.c \n ${CMAKE_CURRENT_SOURCE_DIR}/coll3.c \n ${CMAKE_CURRENT_SOURCE_DIR}/coll4.c \n ${CMAKE_CURRENT_SOURCE_DIR}/coll5.c \n ${CMAKE_CURRENT_SOURCE_DIR}/coll6.c \n ${CMAKE_CURRENT_SOURCE_DIR}/coll7.c \n ${CMAKE_CURRENT_SOURCE_DIR}/coll8.c \n ${CMAKE_CURRENT_SOURCE_DIR}/coll9.c \n ${CMAKE_CURRENT_SOURCE_DIR}/exscan2.c \n ${CMAKE_CURRENT_SOURCE_DIR}/exscan.c \n ${CMAKE_CURRENT_SOURCE_DIR}/gather2.c \n ${CMAKE_CURRENT_SOURCE_DIR}/gather_big.c \n ${CMAKE_CURRENT_SOURCE_DIR}/gather.c \n ${CMAKE_CURRENT_SOURCE_DIR}/iallred.c \n ${CMAKE_CURRENT_SOURCE_DIR}/ibarrier.c \n ${CMAKE_CURRENT_SOURCE_DIR}/icallgather.c \n ${CMAKE_CURRENT_SOURCE_DIR}/icallgatherv.c \n ${CMAKE_CURRENT_SOURCE_DIR}/icallreduce.c \n ${CMAKE_CURRENT_SOURCE_DIR}/icalltoall.c \n ${CMAKE_CURRENT_SOURCE_DIR}/icalltoallv.c \n ${CMAKE_CURRENT_SOURCE_DIR}/icalltoallw.c \n ${CMAKE_CURRENT_SOURCE_DIR}/icbarrier.c \n ${CMAKE_CURRENT_SOURCE_DIR}/icbcast.c \n ${CMAKE_CURRENT_SOURCE_DIR}/icgather.c \n ${CMAKE_CURRENT_SOURCE_DIR}/icgatherv.c \n ${CMAKE_CURRENT_SOURCE_DIR}/icreduce.c \n ${CMAKE_CURRENT_SOURCE_DIR}/icscatter.c \n ${CMAKE_CURRENT_SOURCE_DIR}/icscatterv.c \n ${CMAKE_CURRENT_SOURCE_DIR}/longuser.c \n ${CMAKE_CURRENT_SOURCE_DIR}/nonblocking2.c \n ${CMAKE_CURRENT_SOURCE_DIR}/nonblocking3.c \n ${CMAKE_CURRENT_SOURCE_DIR}/nonblocking.c \n ${CMAKE_CURRENT_SOURCE_DIR}/opband.c \n ${CMAKE_CURRENT_SOURCE_DIR}/opbor.c \n ${CMAKE_CURRENT_SOURCE_DIR}/opbxor.c \n ${CMAKE_CURRENT_SOURCE_DIR}/op_commutative.c \n ${CMAKE_CURRENT_SOURCE_DIR}/opland.c \n ${CMAKE_CURRENT_SOURCE_DIR}/oplor.c \n ${CMAKE_CURRENT_SOURCE_DIR}/oplxor.c \n ${CMAKE_CURRENT_SOURCE_DIR}/opmax.c \n ${CMAKE_CURRENT_SOURCE_DIR}/opmaxloc.c \n ${CMAKE_CURRENT_SOURCE_DIR}/opmin.c \n ${CMAKE_CURRENT_SOURCE_DIR}/opminloc.c \n ${CMAKE_CURRENT_SOURCE_DIR}/opprod.c \n ${CMAKE_CURRENT_SOURCE_DIR}/opsum.c \n ${CMAKE_CURRENT_SOURCE_DIR}/red3.c \n ${CMAKE_CURRENT_SOURCE_DIR}/red4.c \n ${CMAKE_CURRENT_SOURCE_DIR}/redscat2.c \n ${CMAKE_CURRENT_SOURCE_DIR}/redscat3.c \n ${CMAKE_CURRENT_SOURCE_DIR}/redscatbkinter.c \n ${CMAKE_CURRENT_SOURCE_DIR}/redscatblk3.c \n ${CMAKE_CURRENT_SOURCE_DIR}/red_scat_block2.c \n ${CMAKE_CURRENT_SOURCE_DIR}/red_scat_block.c \n ${CMAKE_CURRENT_SOURCE_DIR}/redscat.c \n ${CMAKE_CURRENT_SOURCE_DIR}/redscatinter.c \n ${CMAKE_CURRENT_SOURCE_DIR}/reduce.c \n ${CMAKE_CURRENT_SOURCE_DIR}/reduce_local.c \n ${CMAKE_CURRENT_SOURCE_DIR}/scantst.c \n ${CMAKE_CURRENT_SOURCE_DIR}/scatter2.c \n ${CMAKE_CURRENT_SOURCE_DIR}/scatter3.c \n ${CMAKE_CURRENT_SOURCE_DIR}/scattern.c \n ${CMAKE_CURRENT_SOURCE_DIR}/scatterv.c \n ${CMAKE_CURRENT_SOURCE_DIR}/uoplong.c \n  PARENT_SCOPE)\nset(txt_files  ${txt_files}  ${CMAKE_CURRENT_SOURCE_DIR}/testlist  PARENT_SCOPE)\n",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.20-xigfpbo5yypiin5odq3dedwvkyxa5sxr/spack-src/tools/simgrid.supp": "# Valgrind suppressions for stuff that we cannot control\n\n# Memory leaks in standard tools (e.g. dash, tail, or sort)\n{\n   Memory leak in /bin tools\n   Memcheck:Leak\n   ...\n   obj:/bin/*\n}\n\n{\n   Memory leak in /usr/bin tools\n   Memcheck:Leak\n   ...\n   obj:/usr/bin/*\n}\n\n{\n   Memory leak in cmake\n   Memcheck:Leak\n   match-leak-kinds:reachable\n   ...\n   fun:_Znwm\n   fun:_ZN4Json5Value13nullSingletonEv\n   obj:*/libjsoncpp.so*\n   ...\n   fun:_dl_init\n}\n\n# There's a constant leak of 56 bytes in the depths of libc which\n# manifests, for example, when using backtrace()\n{\n   Memory leak in libc/dlopen with -pthread\n   Memcheck:Leak\n   fun:malloc\n   fun:_dl_map_object_deps\n   fun:dl_open_worker\n   fun:_dl_catch_error\n   fun:_dl_open\n   fun:do_dlopen\n   fun:_dl_catch_error\n   fun:dlerror_run\n   fun:__libc_dlopen_mode\n}\n\n# Another problem in glibc, where makecontext does not reset the EBP register,\n# and backtrace goes too far when walking up the stack frames\n{\n   Invalid read in backtrace, called after makecontext\n   Memcheck:Addr4\n   fun:backtrace\n   ...\n   fun:makecontext\n}\n\n#There seems to be an issue with libc using an uninitialized value somewhere in dlopen\n{\n   Invalid read in dl_start\n   Memcheck:Cond\n   fun:index\n   fun:expand_dynamic_string_token\n   ...\n   fun:_dl_start\n}\n\n# 72704 bytes leak from GCC >5.1 https://gcc.gnu.org/bugzilla/show_bug.cgi?id=64535\n{\n   Memory leak in dl_init\n   Memcheck:Leak\n   match-leak-kinds:reachable\n   fun:malloc\n   obj:/usr/lib/*/libstdc++.so.*\n   fun:call_init.part.0\n   ...\n   fun:_dl_init\n}\n\n#Ignore leaks in SMPI sample codes\n{\n   Leaks in SMPI sample codes\n   Memcheck:Leak\n   match-leak-kinds: all\n   fun:malloc\n   fun:smpi_simulated_main_\n}\n\n#SMPI leaks the dlopen handle used to load the program\n{\n   dlopen handle leaks (1/3)\n   Memcheck:Leak\n   match-leak-kinds:reachable\n   fun:malloc\n   ...\n   fun:dlopen@@GLIBC_*\n}\n\n{\n   dlopen handle leaks (2/3)\n   Memcheck:Leak\n   match-leak-kinds:reachable\n   fun:calloc\n   ...\n   fun:dlopen@@GLIBC_*\n}\n\n{\n   dlopen handle leaks (3/3)\n   Memcheck:Leak\n   match-leak-kinds:reachable\n   fun:realloc\n   ...\n   fun:dlopen@@GLIBC_*\n}\n\n# Memory leaks appearing to be in libcgraph.  They can be seen with the\n# following simple program:\n# ,----\n# | #include <stdio.h>\n# | #include <graphviz/cgraph.h>\n# | int main(int argc, char *argv[])\n# | {\n# |     if (argc == 1) {\n# |         printf(\"Usage: %s <dotfile>\\n\", argv[0]);\n# |         return 1;\n# |     }\n# |     Agraph_t *g;\n# |     FILE *inf = fopen(argv[1], \"r\");\n# |     g = agread(inf, 0);\n# |     fclose(inf);\n# |     agclose(g);\n# |     return 0;\n# | }\n# `----\n{\n   Memory leak in libcgraph (1/2)\n   Memcheck:Leak\n   fun:malloc\n   ...\n   obj:/usr/lib/libcgraph.so*\n   fun:aaglex\n   fun:aagparse\n   fun:agconcat\n}\n{\n   Memory leak in libcgraph (1/2)\n   Memcheck:Leak\n   fun:calloc\n   ...\n   obj:/usr/lib/libcgraph.so*\n   fun:aagparse\n   fun:agconcat\n}\n{\n   Memory leak in libcgraph (2/2)\n   Memcheck:Leak\n   fun:malloc\n   ...\n   fun:agnode\n   obj:/usr/lib/libcgraph.so*\n   fun:aagparse\n   fun:agconcat\n}\n\n# We're not interested by memory leaks in the Lua interpreter\n{\n   Memory leak in lua\n   Memcheck:Leak\n   ...\n   fun:luaD_precall\n}\n\n# libunwind seems to be using msync poorly, thus triggering these\n# https://github.com/JuliaLang/julia/issues/4533\n{\n   msync unwind\n   Memcheck:Param\n   msync(start)\n   ...\n   obj:*/libpthread*.so\n   ...\n}\n\n{\n   ignore unwind cruft\n   Memcheck:Param\n   rt_sigprocmask(set)\n   ...\n   obj:/usr/lib/x86_64-linux-gnu/libunwind.so.*\n   ...\n}\n{\n   ignore unwind cruft\n   Memcheck:Param\n   msync(start)\n   ...\n   obj:/usr/lib/x86_64-linux-gnu/libunwind.so.*\n   ...\n}\n\n{\n   ignore unwind invalid reads\n   Memcheck:Addr8\n   fun:_Ux86_64_setcontext\n}\n\n# Java cruft\n{\n  JavaCruft 1\n  Memcheck:Addr4\n  ...\n  fun:_ZN9JavaCalls11call_helperEP9JavaValueP12methodHandleP17JavaCallArgumentsP6Thread\n  fun:JVM_DoPrivileged\n  ...\n}\n{\n   JavaCruft 2\n   Memcheck:Cond\n   ...\n   fun:_ZN13CompileBroker25invoke_compiler_on_methodEP11CompileTask\n   ...\n}\n\n{\n   Somewhere within the Java conditions and monitors\n   Memcheck:Cond\n   fun:MarsagliaXORV\n   ...\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.20-xigfpbo5yypiin5odq3dedwvkyxa5sxr/spack-src/tools/tesh/tesh.py": "#! @PYTHON_EXECUTABLE@\n# -*- coding: utf-8 -*-\n\"\"\"\n\ntesh -- testing shell\n========================\n\nCopyright (c) 2012-2018. The SimGrid Team. All rights reserved.\n\nThis program is free software; you can redistribute it and/or modify it\nunder the terms of the license (GNU LGPL) which comes with this package.\n\n\n#TODO: child of child of child that printfs. Does it work?\n#TODO: a child dies after its parent. What happen?\n\n#TODO: regular expression in output\n#ex: >> Time taken: [0-9]+s\n#TODO: linked regular expression in output\n#ex:\n# >> Bytes sent: ([0-9]+)\n# >> Bytes recv: \\1\n# then, even better:\n# ! expect (\\1 > 500)\n\n\"\"\"\n\n\nimport sys, os\nimport shlex\nimport re\nimport difflib\nimport signal\nimport argparse\n\nif sys.version_info[0] == 3:\n    import subprocess\n    import _thread\nelse:\n    raise \"This program is expected to run with Python3 only\"\n\n##############\n#\n# Utilities\n#\n#\n\ndef isWindows():\n    return sys.platform.startswith('win')\n\n# Singleton metaclass that works in Python 2 & 3\n# http://stackoverflow.com/questions/6760685/creating-a-singleton-in-python\nclass _Singleton(type):\n    \"\"\" A metaclass that creates a Singleton base class when called. \"\"\"\n    _instances = {}\n    def __call__(cls, *args, **kwargs):\n        if cls not in cls._instances:\n            cls._instances[cls] = super(_Singleton, cls).__call__(*args, **kwargs)\n        return cls._instances[cls]\nclass Singleton(_Singleton('SingletonMeta', (object,), {})): pass\n\nSIGNALS_TO_NAMES_DICT = dict((getattr(signal, n), n) \\\n    for n in dir(signal) if n.startswith('SIG') and '_' not in n )\n\n\n\n#exit correctly\ndef tesh_exit(errcode):\n    #If you do not flush some prints are skipped\n    sys.stdout.flush()\n    #os._exit exit even when executed within a thread\n    os._exit(errcode)\n\n\ndef fatal_error(msg):\n    print(\"[Tesh/CRITICAL] \"+str(msg))\n    tesh_exit(1)\n\n\n#Set an environment variable.\n# arg must be a string with the format \"variable=value\"\ndef setenv(arg):\n    print(\"[Tesh/INFO] setenv \"+arg)\n    t = arg.split(\"=\")\n    os.environ[t[0]] = t[1]\n    #os.putenv(t[0], t[1]) does not work\n    #see http://stackoverflow.com/questions/17705419/python-os-environ-os-putenv-usr-bin-env\n\n\n#http://stackoverflow.com/questions/30734967/how-to-expand-environment-variables-in-python-as-bash-does\ndef expandvars2(path):\n    return re.sub(r'(?<!\\\\)\\$[A-Za-z_][A-Za-z0-9_]*', '', os.path.expandvars(path))\n\n# https://github.com/Cadair/jupyter_environment_kernels/issues/10\ntry:\n    FileNotFoundError\nexcept NameError:\n    #py2\n    FileNotFoundError = OSError\n\n##############\n#\n# Cleanup on signal\n#\n#\n\n# Global variable. Stores which process group should be killed (or None otherwise)\npgtokill = None\n\ndef kill_process_group(pgid):\n    if pgid is None: # Nobody to kill. We don't know who to kill on windows, or we don't have anyone to kill on signal handler\n        return\n\n    # print(\"Kill process group {}\".format(pgid))\n    try:\n        os.killpg(pgid, signal.SIGTERM)\n    except OSError:\n        # os.killpg failed. OK. Some subprocesses may still be running.\n        pass\n\ndef signal_handler(signal, frame):\n    print(\"Caught signal {}\".format(SIGNALS_TO_NAMES_DICT[signal]))\n    if pgtokill is not None:\n        kill_process_group(pgtokill)\n    tesh_exit(5)\n\n\n\n##############\n#\n# Classes\n#\n#\n\n\n\n# read file line per line (and concat line that ends with \"\\\")\nclass FileReader(Singleton):\n    def __init__(self, filename=None):\n        if filename is None:\n            self.filename = \"(stdin)\"\n            self.f = sys.stdin\n        else:\n            self.filename_raw = filename\n            self.filename = os.path.basename(filename)\n            self.abspath = os.path.abspath(filename)\n            self.f = open(self.filename_raw)\n\n        self.linenumber = 0\n\n    def __repr__(self):\n        return self.filename+\":\"+str(self.linenumber)\n\n    def readfullline(self):\n        try:\n            line = next(self.f)\n            self.linenumber += 1\n        except StopIteration:\n            return None\n        if line[-1] == \"\\n\":\n            txt = line[0:-1]\n        else:\n            txt = line\n        while len(line) > 1 and line[-2] == \"\\\\\":\n            txt = txt[0:-1]\n            line = next(self.f)\n            self.linenumber += 1\n            txt += line[0:-1]\n        return txt\n\n\n#keep the state of tesh (mostly configuration values)\nclass TeshState(Singleton):\n    def __init__(self):\n        self.threads = []\n        self.args_suffix = \"\"\n        self.ignore_regexps_common = []\n        self.jenkins = False # not a Jenkins run by default\n        self.timeout = 10 # default value: 10 sec\n        self.wrapper = None\n        self.keep = False\n\n    def add_thread(self, thread):\n        self.threads.append(thread)\n\n    def join_all_threads(self):\n        for t in self.threads:\n            t.acquire()\n            t.release()\n\n#Command line object\nclass Cmd(object):\n    def __init__(self):\n        self.input_pipe = []\n        self.output_pipe_stdout = []\n        self.output_pipe_stderr = []\n        self.timeout = TeshState().timeout\n        self.args = None\n        self.linenumber = -1\n\n        self.background = False\n        self.cwd = None\n\n        self.ignore_output = False\n        self.expect_return = 0\n\n        self.output_display = False\n\n        self.sort = -1\n\n        self.ignore_regexps = TeshState().ignore_regexps_common\n\n    def add_input_pipe(self, l):\n        self.input_pipe.append(l)\n\n    def add_output_pipe_stdout(self, l):\n        self.output_pipe_stdout.append(l)\n\n    def add_output_pipe_stderr(self, l):\n        self.output_pipe_stderr.append(l)\n\n    def set_cmd(self, args, linenumber):\n        self.args = args\n        self.linenumber = linenumber\n\n    def add_ignore(self, txt):\n        self.ignore_regexps.append(re.compile(txt))\n\n    def remove_ignored_lines(self, lines):\n        for ign in self.ignore_regexps:\n                lines = [l for l in lines if not ign.match(l)]\n        return lines\n\n\n    def _cmd_mkfile(self, argline):\n        filename = argline[len(\"mkfile \"):]\n        file = open(filename, \"w\")\n        if file is None:\n            fatal_error(\"Unable to create file \"+filename)\n        file.write(\"\\n\".join(self.input_pipe))\n        file.write(\"\\n\")\n        file.close()\n\n    def _cmd_cd(self, argline):\n        args = shlex.split(argline)\n        if len(args) != 2:\n            fatal_error(\"Too many arguments to cd\")\n        try:\n            os.chdir(args[1])\n            print(\"[Tesh/INFO] change directory to \"+args[1])\n        except FileNotFoundError:\n            print(\"Chdir to \"+args[1]+\" failed: No such file or directory\")\n            print(\"Test suite `\"+FileReader().filename+\"': NOK (system error)\")\n            tesh_exit(4)\n\n\n    #Run the Cmd if possible.\n    # Return False if nothing has been ran.\n    def run_if_possible(self):\n        if self.can_run():\n            if self.background:\n                #Python threads loose the cwd\n                self.cwd = os.getcwd()\n                lock = _thread.allocate_lock()\n                lock.acquire()\n                TeshState().add_thread(lock)\n                _thread.start_new_thread( Cmd._run, (self, lock) )\n            else:\n                self._run()\n            return True\n        else:\n            return False\n\n\n    def _run(self, lock=None):\n        #Python threads loose the cwd\n        if self.cwd is not None:\n            os.chdir(self.cwd)\n            self.cwd = None\n\n        #retrocompatibility: support ${aaa:=.} variable format\n        def replace_perl_variables(m):\n            vname = m.group(1)\n            vdefault = m.group(2)\n            if vname in os.environ:\n                return \"$\"+vname\n            else:\n                return vdefault\n        self.args = re.sub(r\"\\${(\\w+):=([^}]*)}\", replace_perl_variables, self.args)\n\n        #replace bash environment variables ($THINGS) to their values\n        self.args = expandvars2(self.args)\n\n        if re.match(\"^mkfile \", self.args) is not None:\n            self._cmd_mkfile(self.args)\n            if lock is not None: lock.release()\n            return\n\n        if re.match(\"^cd \", self.args) is not None:\n            self._cmd_cd(self.args)\n            if lock is not None: lock.release()\n            return\n\n        if TeshState().wrapper is not None:\n            self.timeout *= 20\n            self.args = TeshState().wrapper + self.args\n        elif re.match(\".*smpirun.*\", self.args) is not None:\n            self.args = \"sh \" + self.args\n        if TeshState().jenkins and self.timeout != None:\n            self.timeout *= 10\n\n        self.args += TeshState().args_suffix\n\n        print(\"[\"+FileReader().filename+\":\"+str(self.linenumber)+\"] \"+self.args)\n\n        args = shlex.split(self.args)\n        #print (args)\n\n        global pgtokill\n\n        try:\n            proc = subprocess.Popen(args, bufsize=1, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, universal_newlines=True, start_new_session=True)\n            try:\n                if not isWindows():\n                    pgtokill = os.getpgid(proc.pid)\n            except OSError:\n                # os.getpgid failed. OK. No cleanup.\n                pass\n        except FileNotFoundError:\n            print(\"[\"+FileReader().filename+\":\"+str(self.linenumber)+\"] Cannot start '\"+args[0]+\"': File not found\")\n            tesh_exit(3)\n        except OSError as osE:\n            if osE.errno == 8:\n                osE.strerror += \"\\nOSError: [Errno 8] Executed scripts should start with shebang line (like #!/usr/bin/env sh)\"\n            raise osE\n\n        cmdName = FileReader().filename+\":\"+str(self.linenumber)\n        try:\n            (stdout_data, stderr_data) = proc.communicate(\"\\n\".join(self.input_pipe), self.timeout)\n            pgtokill = None\n        except subprocess.TimeoutExpired:\n            print(\"Test suite `\"+FileReader().filename+\"': NOK (<\"+cmdName+\"> timeout after \"+str(self.timeout)+\" sec)\")\n            kill_process_group(pgtokill)\n            tesh_exit(3)\n\n        if self.output_display:\n            print(stdout_data)\n\n        #remove text colors\n        ansi_escape = re.compile(r'\\x1b[^m]*m')\n        stdout_data = ansi_escape.sub('', stdout_data)\n\n        #print ((stdout_data, stderr_data))\n\n        if self.ignore_output:\n            print(\"(ignoring the output of <\"+cmdName+\"> as requested)\")\n        else:\n            stdouta = stdout_data.split(\"\\n\")\n            while len(stdouta) > 0 and stdouta[-1] == \"\":\n                del stdouta[-1]\n            stdouta = self.remove_ignored_lines(stdouta)\n            stdcpy = stdouta[:]\n\n            # Mimic the \"sort\" bash command, which is case unsensitive.\n            if self.sort == 0:\n                stdouta.sort(key=lambda x: x.lower())\n                self.output_pipe_stdout.sort(key=lambda x: x.lower())\n            elif self.sort > 0:\n                stdouta.sort(key=lambda x: x[:self.sort].lower())\n                self.output_pipe_stdout.sort(key=lambda x: x[:self.sort].lower())\n\n            diff = list(difflib.unified_diff(self.output_pipe_stdout, stdouta,lineterm=\"\",fromfile='expected', tofile='obtained'))\n            if len(diff) > 0:\n                print(\"Output of <\"+cmdName+\"> mismatch:\")\n                if self.sort >= 0: # If sorted, truncate the diff output and show the unsorted version\n                    difflen = 0;\n                    for line in diff:\n                        if difflen<50:\n                            print(line)\n                        difflen += 1\n                    if difflen > 50:\n                        print(\"(diff truncated after 50 lines)\")\n                    print(\"Unsorted observed output:\\n\")\n                    for line in stdcpy:\n                        print(line)\n                else: # If not sorted, just display the diff\n                    for line in diff:\n                        print(line)\n\n                print(\"Test suite `\"+FileReader().filename+\"': NOK (<\"+cmdName+\"> output mismatch)\")\n                if lock is not None: lock.release()\n                if TeshState().keep:\n                    f = open('obtained','w')\n                    obtained = stdout_data.split(\"\\n\")\n                    while len(obtained) > 0 and obtained[-1] == \"\":\n                        del obtained[-1]\n                    obtained = self.remove_ignored_lines(obtained)\n                    for line in obtained:\n                        f.write(\"> \"+line+\"\\n\")\n                    f.close()\n                    print(\"Obtained output kept as requested: \"+os.path.abspath(\"obtained\"))\n                tesh_exit(2)\n\n        #print ((proc.returncode, self.expect_return))\n\n        if proc.returncode != self.expect_return:\n            if proc.returncode >= 0:\n                print(\"Test suite `\"+FileReader().filename+\"': NOK (<\"+cmdName+\"> returned code \"+str(proc.returncode)+\")\")\n                if lock is not None: lock.release()\n                tesh_exit(2)\n            else:\n                print(\"Test suite `\"+FileReader().filename+\"': NOK (<\"+cmdName+\"> got signal \"+SIGNALS_TO_NAMES_DICT[-proc.returncode]+\")\")\n                if lock is not None: lock.release()\n                tesh_exit(-proc.returncode)\n\n        if lock is not None: lock.release()\n\n\n\n    def can_run(self):\n        return self.args is not None\n\n\n\n\n##############\n#\n# Main\n#\n#\n\n\n\nif __name__ == '__main__':\n    signal.signal(signal.SIGINT, signal_handler)\n    signal.signal(signal.SIGTERM, signal_handler)\n\n    parser = argparse.ArgumentParser(description='tesh -- testing shell', add_help=True)\n    group1 = parser.add_argument_group('Options')\n    group1.add_argument('teshfile', nargs='?', help='Name of teshfile, stdin if omitted')\n    group1.add_argument('--cd', metavar='some/directory', help='ask tesh to switch the working directory before launching the tests')\n    group1.add_argument('--setenv', metavar='var=value', action='append', help='set a specific environment variable')\n    group1.add_argument('--cfg', metavar='arg', action='append', help='add parameter --cfg=arg to each command line')\n    group1.add_argument('--log', metavar='arg', action='append', help='add parameter --log=arg to each command line')\n    group1.add_argument('--ignore-jenkins', action='store_true', help='ignore all cruft generated on SimGrid continous integration servers')\n    group1.add_argument('--wrapper', metavar='arg', help='Run each command in the provided wrapper (eg valgrind)')\n    group1.add_argument('--keep', action='store_true', help='Keep the obtained output when it does not match the expected one')\n\n    try:\n        options = parser.parse_args()\n    except SystemExit:\n        tesh_exit(1)\n\n    if options.cd is not None:\n        print(\"[Tesh/INFO] change directory to \" + options.cd)\n        os.chdir(options.cd)\n\n    if options.ignore_jenkins:\n        print(\"Ignore all cruft seen on SimGrid's continous integration servers\")\n        # Note: regexps should match at the beginning of lines\n        TeshState().ignore_regexps_common = [\n           re.compile(r\"profiling:\"),\n           re.compile(r\"Unable to clean temporary file C:\"),\n           re.compile(r\".*Configuration change: Set 'contexts/\"),\n           re.compile(r\"Picked up JAVA_TOOL_OPTIONS: \"),\n           re.compile(r\"Picked up _JAVA_OPTIONS: \"),\n           re.compile(r\"==[0-9]+== ?WARNING: ASan doesn't fully support\"),\n           re.compile(r\"==[0-9]+== ?WARNING: ASan is ignoring requested __asan_handle_no_return: stack top:\"),\n           re.compile(r\"False positive error reports may follow\"),\n           re.compile(r\"For details see http://code.google.com/p/address-sanitizer/issues/detail\\?id=189\"),\n           re.compile(r\"For details see https://github.com/google/sanitizers/issues/189\"),\n           re.compile(r\"Python runtime initialized with LC_CTYPE=C .*\"),\n           re.compile(r\"cmake: /usr/local/lib/libcurl\\.so\\.4: no version information available \\(required by cmake\\)\"), # Seen on CircleCI\n           re.compile(r\".*mmap broken on FreeBSD, but dlopen\\+thread broken too. Switching to dlopen\\+raw contexts\\.\"),\n           re.compile(r\".*dlopen\\+thread broken on Apple and BSD\\. Switching to raw contexts\\.\"),\n           ]\n        TeshState().jenkins = True # This is a Jenkins build\n\n    if options.teshfile is None:\n        f = FileReader(None)\n        print(\"Test suite from stdin\")\n    else:\n        if not os.path.isfile(options.teshfile):\n            print(\"Cannot open teshfile '\"+options.teshfile+\"': File not found\")\n            tesh_exit(3)\n        f = FileReader(options.teshfile)\n        print(\"Test suite '\"+f.abspath+\"'\")\n\n    if options.setenv is not None:\n        for e in options.setenv:\n            setenv(e)\n\n    if options.cfg is not None:\n        for c in options.cfg:\n            TeshState().args_suffix += \" --cfg=\" + c\n    if options.log is not None:\n        for l in options.log:\n            TeshState().args_suffix += \" --log=\" + l\n\n    if options.wrapper is not None:\n        TeshState().wrapper = options.wrapper\n\n    if options.keep:\n        TeshState().keep = True\n\n    #cmd holds the current command line\n    # tech commands will add some parameters to it\n    # when ready, we execute it.\n    cmd = Cmd()\n\n    line = f.readfullline()\n    while line is not None:\n        #print(\">>=============\"+line+\"==<<\")\n        if len(line) == 0:\n            #print (\"END CMD block\")\n            if cmd.run_if_possible():\n                cmd = Cmd()\n\n        elif line[0] == \"#\":\n            pass\n\n        elif line[0:2] == \"p \":\n            print(\"[\"+str(FileReader())+\"] \"+line[2:])\n\n        elif line[0:2] == \"< \":\n            cmd.add_input_pipe(line[2:])\n        elif line[0:1] == \"<\":\n            cmd.add_input_pipe(line[1:])\n\n        elif line[0:2] == \"> \":\n            cmd.add_output_pipe_stdout(line[2:])\n        elif line[0:1] == \">\":\n            cmd.add_output_pipe_stdout(line[1:])\n\n        elif line[0:2] == \"$ \":\n            if cmd.run_if_possible():\n                cmd = Cmd()\n            cmd.set_cmd(line[2:], f.linenumber)\n\n        elif line[0:2] == \"& \":\n            if cmd.run_if_possible():\n                cmd = Cmd()\n            cmd.set_cmd(line[2:], f.linenumber)\n            cmd.background = True\n\n        elif line[0:15] == \"! output ignore\":\n            cmd.ignore_output = True\n            #print(\"cmd.ignore_output = True\")\n        elif line[0:16] == \"! output display\":\n            cmd.output_display = True\n            cmd.ignore_output = True\n        elif line[0:15] == \"! expect return\":\n            cmd.expect_return = int(line[16:])\n            #print(\"expect return \"+str(int(line[16:])))\n        elif line[0:15] == \"! expect signal\":\n            sig = line[16:]\n            #get the signal integer value from the signal module\n            if sig not in signal.__dict__:\n                fatal_error(\"unrecognized signal '\"+sig+\"'\")\n            sig = int(signal.__dict__[sig])\n            #popen return -signal when a process ends with a signal\n            cmd.expect_return = -sig\n        elif line[0:len(\"! timeout \")] == \"! timeout \":\n            if \"no\" in line[len(\"! timeout \"):]:\n                cmd.timeout = None\n            else:\n                cmd.timeout = int(line[len(\"! timeout \"):])\n\n        elif line[0:len(\"! output sort\")] == \"! output sort\":\n            if len(line) >= len(\"! output sort \"):\n                sort = int(line[len(\"! output sort \"):])\n            else:\n                sort = 0\n            cmd.sort = sort\n        elif line[0:len(\"! setenv \")] == \"! setenv \":\n            setenv(line[len(\"! setenv \"):])\n\n        elif line[0:len(\"! ignore \")] == \"! ignore \":\n            cmd.add_ignore(line[len(\"! ignore \"):])\n\n        else:\n            fatal_error(\"UNRECOGNIZED OPTION\")\n\n\n        line = f.readfullline()\n\n    cmd.run_if_possible()\n\n    TeshState().join_all_threads()\n\n    if f.filename == \"(stdin)\":\n        print(\"Test suite from stdin OK\")\n    else:\n        print(\"Test suite `\"+f.filename+\"' OK\")\n",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.20-xigfpbo5yypiin5odq3dedwvkyxa5sxr/spack-src/doc/doxygen/FAQ.doc": "/*! \\page FAQ MSG Frequently Asked Questions\n\n@tableofcontents\n\nThis document is the FAQ of the MSG interface. Some entries are a bit aging and it should be refreshed at some point.\n\n\\section faq_simgrid I'm new to SimGrid. I have some questions. Where should I start?\n\nYou are at the right place... To understand what you can do or\ncannot do with SimGrid, you should read the\n<a href=\"http://simgrid.gforge.inria.fr/tutorials.php\">tutorial\nslides</a> from the SimGrid's website. You may find more uptodate\nmaterial on the\n<a href=\"http://people.irisa.fr/Martin.Quinson/blog/SimGrid/\">blog of\nMartin Quinson</a>. \n\nAnother great source of inspiration can be found in the \\ref s4u_examples.\n\nIf you are stuck at any point and if this FAQ cannot help you, please drop us a\nmail to the user mailing list: <simgrid-user@lists.gforge.inria.fr>.\n\n\\subsection faq_interfaces What is the difference between MSG and SimDag? Do they serve the same purpose?\n\nIt depend on how you define \"purpose\", I guess ;)\n\nThey all allow you to build a prototype of application which you can run\nwithin the simulator afterward. They all share the same simulation kernel,\nwhich is the core of the SimGrid project. They differ by the way you express\nyour application.\n\nWith SimDag, you express your code as a collection of interdependent\nparallel tasks. So, in this model, applications can be seen as a DAG of\ntasks. This is the interface of choice for people wanting to port old\ncode designed for SimGrid v1 or v2 to the framework current version.\n\nWith MSG, your application is seen as a set of communicating\nprocesses, exchanging data by the way of messages and performing\ncomputation on their own.\n\n\\subsection faq_visualization Visualizing and analyzing the results\n\nIt is sometime convenient to \"see\" how the agents are behaving. If you\nlike colors, you can use <tt>tools/MSG_visualization/colorize.pl </tt>\nas a filter to your MSG outputs. It works directly with INFO. Beware,\nINFO() prints on stderr. Do not forget to redirect if you want to\nfilter (e.g. with bash):\n\\verbatim\n./msg_test small_platform.xml small_deployment.xml 2>&1 | ../../tools/MSG_visualization/colorize.pl\n\\endverbatim\n\nWe also have a more graphical output. Have a look at section \\ref options_tracing.\n\n\\subsection faq_C Argh! Do I really have to code in C?\n\nWe provide Java bindings of the MSG interface, which is the main\nSimGrid user API.\n\nMoreover If you use C++, you should be able to use the SimGrid library\nas a standard C library and everything should work fine (simply\n<i>link</i> against this library; recompiling SimGrid with a C++\ncompiler won't work and it wouldn't help if you could).\n\nFor now, we do not feel a real demand for any other language. But if\nyou think there is one, please speak up!\n\n\\section faq_howto Feature related questions\n\n\\subsection faq_MIA \"Could you please add (your favorite feature here) to SimGrid?\"\n\nHere is the deal. The whole SimGrid project (MSG, SURF, ...) is\nmeant to be kept as simple and generic as possible. We cannot add\nfunctions for everybody's needs when these functions can easily be\nbuilt from the ones already in the API. Most of the time, it is\npossible and when it was not possible we always have upgraded the API\naccordingly. When somebody asks us a question like \"How to do that?\nIs there a function in the API to simply do this?\", we're always glad\nto answer and help. However if we don't need this code for our own\nneed, there is no chance we're going to write it... it's your job! :)\nThe counterpart to our answers is that once you come up with a neat\nimplementation of this feature (task duplication, RPC, thread\nsynchronization, ...), you should send it to us and we will be glad to\nadd it to the distribution. Thus, other people will take advantage of\nit (and we don't have to answer this question again and again ;).\n\nYou'll find in this section a few \"Missing In Action\" features. Many\npeople have asked about it and we have given hints on how to simply do\nit with MSG. Feel free to contribute...\n\n\\subsection faq_MIA_MSG MSG features\n\n\\subsubsection faq_MIA_examples I want some more complex MSG examples!\n\nMany people have come to ask me a more complex example and each time,\nthey have realized afterward that the basics were in the previous three\nexamples.\n\nOf course they have often been needing more complex functions like\nMSG_process_suspend(), MSG_process_resume() and\nMSG_process_isSuspended() (to perform synchronization), or\nMSG_task_Iprobe() and MSG_process_sleep() (to avoid blocking\nreceptions), or even MSG_process_create() (to design asynchronous\ncommunications or computations). But the examples are sufficient to\nstart.\n\nWe know. We should add some more examples, but not really some more\ncomplex ones... We should add some examples that illustrate some other\nfunctionalists (like how to simply encode asynchronous\ncommunications, RPC, process migrations, thread synchronization, ...)\nand we will do it when we will have a little bit more time. We have\ntried to document the examples so that they are understandable. Tell\nus if something is not clear and once again feel free to participate!\n:)\n\n\\subsubsection faq_MIA_taskdup Missing in action: MSG Task duplication/replication\n\nThere is no task duplication in MSG. When you create a task, you can\nprocess it or send it somewhere else. As soon as a process has sent\nthis task, he doesn't have this task anymore. It's gone. The receiver\nprocess has got the task. However, you could decide upon receiving to\ncreate a \"copy\" of a task but you have to handle by yourself the\nsemantic associated to this \"duplication\".\n\nAs we already told, we prefer keeping the API as simple as\npossible. This kind of feature is rather easy to implement by users\nand the semantic you associate really depends on people. Having a\n*generic* task duplication mechanism is not that trivial (in\nparticular because of the data field). That is why I would recommend\nthat you write it by yourself even if I can give you advice on how to\ndo it.\n\nYou have the following functions to get information about a task:\nMSG_task_get_name(), MSG_task_get_compute_duration(),\nMSG_task_get_remaining_computation(), MSG_task_get_data_size(),\nand MSG_task_get_data().\n\nYou could use a dictionary (#xbt_dict_t) of dynars (#xbt_dynar_t). If\nyou still don't see how to do it, please come back to us...\n\n\\subsubsection faq_MIA_thread_synchronization How to synchronize my user processes?\n\nIt depends on why you want to synchronize them.  If you just want to\nhave a shared state between your processes, then you probably don't\nneed to do anything. User processes never get forcefully interrupted\nin SimGrid (unless you explicitly request the parallel execution of\nuser processes -- see @ref options_virt_parallel).\n\nEven if several processes are executed at the exact same time within\nthe simulation, they are linearized in reality by default: one process\nalways run in an exclusive manner, atomic, uninterrupted until it does\na simcall (until it ask a service from the simulation kernel). This is\nsurprising at first, but things are much easier this way, both for the\nuser (who don't have to protect her shared data) and for the kernel\n(that avoid many synchronization issues too). Processes are executed\nconcurrently in the simulated realm, but you don't need to bother with\nthis in the real realm.\n\nIf you really need to synchronize your processes (because it's what\nyou are studying or to create an atomic section that spans over\nseveral simcalls), you obviously cannot use regular synchronization\nmechanisms (pthread_mutexes in C or the synchronized keyword in Java).\nThis is because the SimGrid kernel locks all processes and unlock them\none after the other when they are supposed to run, until they give the\ncontrol back in their simcall. If one of them gets locked by the OS \nbefore returning the control to the kernel, that's definitively a\ndeadlock.\n\nInstead, you should use the synchronization mechanism provided by the\nsimulation kernel. This could with a SimGrid mutex, a SimGrid\ncondition variables or a SimGrid semaphore, as described in @ref\nmsg_synchro (in Java, only semaphores are available). But actually,\nmany synchronization patterns can be encoded with communication on\nmailboxes. Typically, if you need one process to notify another one,\nyou could use a condition variable or a semphore, but sending a\nmessage to a specific mailbox does the trick in most cases.\n\n\\subsubsection faq_MIA_host_load Where is the get_host_load function hidden in MSG?\n\nThere is no such thing because its semantic wouldn't be really\nclear. Of course, it is something about the amount of host throughput,\nbut there is as many definition of \"host load\" as people asking for\nthis function. First, you have to remember that resource availability\nmay vary over time, which make any load notion harder to define.\n\nIt may be instantaneous value or an average one. Moreover it may be only the\npower of the computer, or may take the background load into account, or may\neven take the currently running tasks into account. In some SURF models,\ncommunications have an influence on computational power. Should it be taken\ninto account too?\n\nFirst of all, it's near to impossible to predict the load beforehand in the\nsimulator since it depends on too much parameters (background load\nvariation, bandwidth sharing algorithmic complexity) some of them even being\nnot known beforehand (other task starting at the same time). So, getting\nthis information is really hard (just like in real life). It's not just that\nwe want MSG to be as painful as real life. But as it is in some way\nrealistic, we face some of the same problems as we would face in real life.\n\nHow would you do it for real? The most common option is to use something\nlike NWS that performs active probes. The best solution is probably to do\nthe same within MSG, as in next code snippet. It is very close from what you\nwould have to do out of the simulator, and thus gives you information that\nyou could also get in real settings to not hinder the realism of your\nsimulation.\n\n\\code\ndouble get_host_load() {\n   m_task_t task = MSG_task_create(\"test\", 0.001, 0, NULL);\n   double date = MSG_get_clock();\n\n   MSG_task_execute(task);\n   date = MSG_get_clock() - date;\n   MSG_task_destroy(task);\n   return (0.001/date);\n}\n\\endcode\n\nOf course, it may not match your personal definition of \"host load\". In this\ncase, please detail what you mean on the mailing list, and we will extend\nthis FAQ section to fit your taste if possible.\n\n\\subsubsection faq_MIA_communication_time How can I get the *real* communication time?\n\nCommunications are synchronous and thus if you simply get the time\nbefore and after a communication, you'll only get the transmission\ntime and the time spent to really communicate (it will also take into\naccount the time spent waiting for the other party to be\nready). However, getting the *real* communication time is not really\nhard either. The following solution is a good starting point.\n\n\\code\nint sender()\n{\n  m_task_t task = MSG_task_create(\"Task\", task_comp_size, task_comm_size,\n                                  calloc(1,sizeof(double)));\n  *((double*) task->data) = MSG_get_clock();\n  MSG_task_put(task, slaves[i % slaves_count], PORT_22);\n  XBT_INFO(\"Send completed\");\n  return 0;\n}\nint receiver()\n{\n  m_task_t task = NULL;\n  double time1,time2;\n\n  time1 = MSG_get_clock();\n  a = MSG_task_get(&(task), PORT_22);\n  time2 = MSG_get_clock();\n  if(time1<*((double *)task->data))\n     time1 = *((double *) task->data);\n  XBT_INFO(\"Communication time :  \\\"%f\\\" \", time2-time1);\n  free(task->data);\n  MSG_task_destroy(task);\n  return 0;\n}\n\\endcode\n\n\\subsection faq_MIA_SimDag SimDag related questions\n\n\\subsubsection faq_SG_comm Implementing communication delays between tasks.\n\nA classic question of SimDag newcomers is about how to express a\ncommunication delay between tasks. The thing is that in SimDag, both\ncomputation and communication are seen as tasks.  So, if you want to\nmodel a data dependency between two DAG tasks t1 and t2, you have to\ncreate 3 SD_tasks: t1, t2 and c and add dependencies in the following\nway:\n\n\\code\nSD_task_dependency_add(t1, c);\nSD_task_dependency_add(c, t2);\n\\endcode\n\nThis way task t2 cannot start before the termination of communication c\nwhich in turn cannot start before t1 ends.\n\nWhen creating task c, you have to associate an amount of data (in bytes)\ncorresponding to what has to be sent by t1 to t2.\n\nFinally to schedule the communication task c, you have to build a list\ncomprising the workstations on which t1 and t2 are scheduled (w1 and w2\nfor example) and build a communication matrix that should look like\n[0;amount ; 0; 0].\n\n\\subsubsection faq_SG_DAG How to implement a distributed dynamic scheduler of DAGs.\n\nDistributed is somehow \"contagious\". If you start making distributed\ndecisions, there is no way to handle DAGs directly anymore (unless I\nam missing something). You have to encode your DAGs in term of\ncommunicating process to make the whole scheduling process\ndistributed. Here is an example of how you could do that. Assume T1\nhas to be done before T2.\n\n\\code\n int your_agent(int argc, char *argv[] {\n   ...\n   T1 = MSG_task_create(...);\n   T2 = MSG_task_create(...);\n   ...\n   while(1) {\n     ...\n     if(cond) MSG_task_execute(T1);\n     ...\n     if((MSG_task_get_remaining_computation(T1)=0.0) && (you_re_in_a_good_mood))\n        MSG_task_execute(T2)\n     else {\n        /* do something else */\n     }\n   }\n }\n\\endcode\n\nIf you decide that the distributed part is not that much important and that\nDAG is really the level of abstraction you want to work with, then you should\ngive a try to \\ref SD_API.\n\n\\subsection faq_MIA_generic Generic features\n\n\\subsubsection faq_MIA_batch_scheduler Is there a native support for batch schedulers in SimGrid?\n\nNo, there is no native support for batch schedulers and none is\nplanned because this is a very specific need (and doing it in a\ngeneric way is thus very hard). However some people have implemented\ntheir own batch schedulers. Vincent Garonne wrote one during his PhD\nand put his code in the contrib directory of our SVN so that other can\nkeep working on it. You may find inspiring ideas in it.\n\n\\subsubsection faq_MIA_checkpointing I need a checkpointing thing\n\nActually, it depends on whether you want to checkpoint the simulation, or to\nsimulate checkpoints.\n\nThe first one could help if your simulation is a long standing process you\nwant to keep running even on hardware issues. It could also help to\n<i>rewind</i> the simulation by jumping sometimes on an old checkpoint to\ncancel recent calculations.\\n\nUnfortunately, such thing will probably never exist in SG. One would have to\nduplicate all data structures because doing a rewind at the simulator level\nis very very hard (not talking about the malloc free operations that might\nhave been done in between). Instead, you may be interested in the Libckpt\nlibrary (http://www.cs.utk.edu/~plank/plank/www/libckpt.html). This is the\ncheckpointing solution used in the condor project, for example. It makes it\neasy to create checkpoints (at the OS level, creating something like core\nfiles), and rerunning them on need.\n\nIf you want to simulate checkpoints instead, it means that you want the\nstate of an executing task (in particular, the progress made towards\ncompletion) to be saved somewhere.  So if a host (and the task executing on\nit) fails (cf. #MSG_HOST_FAILURE), then the task can be restarted\nfrom the last checkpoint.\\n\n\nActually, such a thing does not exist in SimGrid either, but it's just\nbecause we don't think it is fundamental and it may be done in the user code\nat relatively low cost. You could for example use a watcher that\nperiodically get the remaining amount of things to do (using\nMSG_task_get_remaining_computation()), or fragment the task in smaller\nsubtasks.\n\n\\subsection faq_platform Platform building and Dynamic resources\n\n\\subsubsection faq_platform_example Where can I find SimGrid platform files?\n\nThere are several little examples in the archive, in the examples/msg\ndirectory. From time to time, we are asked for other files, but we\ndon't have much at hand right now.\n\nYou should refer to the Platform Description Archive\n(http://pda.gforge.inria.fr) project to see the other platform file we\nhave available, as well as the Simulacrum simulator, meant to generate\nSimGrid platforms using all classical generation algorithms.\n\n\\subsubsection faq_platform_alnem How can I automatically map an existing platform?\n\nWe are working on a project called ALNeM (Application-Level Network\nMapper) which goal is to automatically discover the topology of an\nexisting network. Its output will be a platform description file\nfollowing the SimGrid syntax, so everybody will get the ability to map\ntheir own lab network (and contribute them to the catalog project).\nThis tool is not ready yet, but it move quite fast forward. Just stay\ntuned.\n\n\\subsubsection faq_platform_synthetic Generating synthetic but realistic platforms\n\nThe third possibility to get a platform file (after manual or\nautomatic mapping of real platforms) is to generate synthetic\nplatforms. Getting a realistic result is not a trivial task, and\nmoreover, nobody is really able to define what \"realistic\" means when\nspeaking of topology files. You can find some more thoughts on this\ntopic in these\n<a href=\"http://graal.ens-lyon.fr/~alegrand/articles/Simgrid-Introduction.pdf\">slides</a>.\n\nIf you are looking for an actual tool, there we have a little tool to\nannotate Tiers-generated topologies. This perl-script is in\n<tt>tools/platform_generation/</tt> directory of the SVN. Dinda et Al.\nreleased a very comparable tool, and called it GridG.\n\n\nThe specified computing power will be available to up to 6 sequential\ntasks without sharing. If more tasks are placed on this host, the\nresource will be shared accordingly. For example, if you schedule 12\ntasks on the host, each will get half of the computing power. Please\nnote that although sound, this model were never scientifically\nassessed. Please keep this fact in mind when using it.\n\n\n\\subsubsection faq_platform_random Using random variable for the resource power or availability\n\nThe best way to model the resouce power using a random variable is to\nuse an availability trace that is directed by a probability\ndistribution. This can be done using the function\ntmgr_trace_generator_value() below. The date and value generators is\ncreated with one of tmgr_event_generator_new_uniform(),\ntmgr_event_generator_new_exponential() or\ntmgr_event_generator_new_weibull() (if you need other generators,\nadding them to src/surf/trace_mgr.c should be quite trivial and your\npatch will be welcomed). Once your trace is created, you have to\nconnect it to the resource with the function\nsg_platf_new_trace_connect().\n\nThat the process is very similar if you want to model the\nresource availability with a random variable (deciding whether it's\non/off instead of deciding its speed) using the function\ntmgr_trace_generator_state() or tmgr_trace_generator_avail_unavail()\ninstead of tmgr_trace_generator_value().\n\nUnfortunately, all this is currently lacking a proper documentation,\nand there is even no proper example of use. You'll thus have to check\nthe header file include/simgrid/platf.h and experiment a bit by\nyourself. The following code should be a good starting point, and\ncontributing a little clean example would be a good way to help the\nSimGrid project.\n\n@code\ntmgr_trace_generator_value(\"mytrace\",tmgr_event_generator_new_exponential(.5)\n                                     tmgr_event_generator_new_uniform(100000,9999999));\n\t\t\t\t     \nsg_platf_trace_connect_cbarg_t myconnect = SG_PLATF_TRACE_CONNECT_INITIALIZER;\nmyconnect.kind = SURF_TRACE_CONNECT_KIND_BANDWIDTH;\nmyconnect.trace = \"mytrace\";\nmyconnect.element = \"mylink\";\n\nsg_platf_trace_connect(myconnect);\n@endcode\n\n\\section faq_troubleshooting Troubleshooting\n\n\\subsection faq_trouble_changelog The feature X stopped to work after my last update \n\nI guess that you want to read the ChangeLog file, that always contains\nall the information that could be important to the users during the\nupgrade. Actually, you may want to read it (alongside with the NEWS\nfile that highlights the most important changes) even before you\nupgrade your copy of SimGrid, too.\n\nWe do our best to maintain the backward compatibility, but we\nsometimes have to fix the things that are too broken. If we happen to\nkill a feature that you were using, we are sorry. We think that you\nshould update to the new way of doing things, but if you can't afford\nit, that's ok. Just stick to the last version that were working for\nyou, and have a pleasant day.\n\n\\subsection faq_trouble_lib_compil SimGrid compilation and installation problems\n\n\\subsubsection faq_trouble_lib_config cmake fails!\n\nWe know only one reason for the configure to fail:\n\n - <b>You are using a broken build environment</b>\\n\n   Try updating your cmake version. If symptom is that the configury\n   magic complains about gcc not being able to build executables, you\n   are probably missing the libc6-dev package. Damn Ubuntu. \n\nIf you experience other kind of issue, please get in touch with us. We are\nalways interested in improving our portability to new systems.\n\n\\subsubsection faq_trouble_distcheck Dude! \"ctest\" fails on my machine!\n\nDon't assume we never run this target, because we do. Check\nhttp://cdash.inria.fr/CDash/index.php?project=Simgrid (click on\nprevious if there is no result for today: results are produced only by\n11am, French time) and\nhttps://buildd.debian.org/status/logs.php?pkg=simgrid if you don't believe us.\n\nIf it's failing on your machine in a way not experienced by the\nautobuilders above, please drop us a mail on the mailing list so that\nwe can check it out. Make sure to read \\ref faq_bugrepport before you\ndo so.\n\n\\subsection faq_trouble_compil User code compilation problems\n\n\\subsubsection faq_trouble_err_logcat \"gcc: _simgrid_this_log_category_does_not_exist__??? undeclared (first use in this function)\"\n\nThis is because you are using the log mechanism, but you didn't created\nany default category in this file. You should refer to \\ref XBT_log\nfor all the details, but you simply forgot to call one of\nXBT_LOG_NEW_DEFAULT_CATEGORY() or XBT_LOG_NEW_DEFAULT_SUBCATEGORY().\n\n\\subsubsection faq_trouble_pthreadstatic \"gcc: undefined reference to pthread_key_create\"\n\nThis indicates that one of the library SimGrid depends on (libpthread\nhere) was missing on the linking command line. Dependencies of\nlibsimgrid are expressed directly in the dynamic library, so it's\nquite impossible that you see this message when doing dynamic linking.\n\nIf you compile your code statically (and if you use a pthread version\nof SimGrid), you must absolutely\nspecify <tt>-lpthread</tt> on the linker command line. As usual, this should\ncome after <tt>-lsimgrid</tt> on this command line.\n\n\\subsection faq_trouble_errors Runtime error messages\n\n\\subsubsection faq_trouble_errors_big_fat_warning I'm told that my XML files are too old.\n\nThe format of the XML platform description files is sometimes\nimproved. For example, we decided to change the units used in SimGrid\nfrom MBytes, MFlops and seconds to Bytes, Flops and seconds to ease\npeople exchanging small messages. We also reworked the route\ndescriptions to allow more compact descriptions.\n\nThat is why the XML files are versionned using the 'version' attribute\nof the root tag. Currently, it should read:\n@verbatim\n  <platform version=\"4\">\n@endverbatim\n\nIf your files are too old, you can use the simgrid_update_xml.pl\nscript which can be found in the tools directory of the archive.\n\n\\subsection faq_trouble_debug Debugging SMPI applications\n\nIn order to debug SMPI programs, you can use the following options:\n\n- <b>-wrapper 'gdb --args'</b>: this option is used to use a wrapper\n  in order to call the SMPI process. Good candidates for this options\n  are \"gdb --args\", \"valgrind\", \"rr record\", \"strace\", etc;\n\n- <b>-foreground</b>: this options gives the debugger access to the terminal\n  which is needed in order to use an interactive debugger.\n\nBoth options are needed in order to run the SMPI process under GDB.\n\n\\subsection faq_trouble_valgrind Valgrind-related and other debugger issues\n\nIf you don't, you really should use valgrind to debug your code, it's\nalmost magic.\n\n\\subsubsection faq_trouble_vg_libc Valgrind spits tons of errors about backtraces!\n\nIt may happen that valgrind, the memory debugger beloved by any decent C\nprogrammer, spits tons of warnings like the following :\n\\verbatim ==8414== Conditional jump or move depends on uninitialised value(s)\n==8414==    at 0x400882D: (within /lib/ld-2.3.6.so)\n==8414==    by 0x414EDE9: (within /lib/tls/i686/cmov/libc-2.3.6.so)\n==8414==    by 0x400B105: (within /lib/ld-2.3.6.so)\n==8414==    by 0x414F937: _dl_open (in /lib/tls/i686/cmov/libc-2.3.6.so)\n==8414==    by 0x4150F4C: (within /lib/tls/i686/cmov/libc-2.3.6.so)\n==8414==    by 0x400B105: (within /lib/ld-2.3.6.so)\n==8414==    by 0x415102D: __libc_dlopen_mode (in /lib/tls/i686/cmov/libc-2.3.6.so)\n==8414==    by 0x412D6B9: backtrace (in /lib/tls/i686/cmov/libc-2.3.6.so)\n==8414==    by 0x8076446: xbt_dictelm_get_ext (dict_elm.c:714)\n==8414==    by 0x80764C1: xbt_dictelm_get (dict_elm.c:732)\n==8414==    by 0x8079010: xbt_cfg_register (config.c:208)\n==8414==    by 0x806821B: MSG_config (msg_config.c:42)\n\\endverbatim\n\nThis problem is somewhere in the libc when using the backtraces and there is\nvery few things we can do ourselves to fix it. Instead, here is how to tell\nvalgrind to ignore the error. Add the following to your ~/.valgrind.supp (or\ncreate this file on need). Make sure to change the obj line according to\nyour personnal mileage (change 2.3.6 to the actual version you are using,\nwhich you can retrieve with a simple \"ls /lib/ld*.so\").\n\n\\verbatim {\n   name: Backtrace madness\n   Memcheck:Cond\n   obj:/lib/ld-2.3.6.so\n   fun:dl_open_worker\n   fun:_dl_open\n   fun:do_dlopen\n   fun:dlerror_run\n   fun:__libc_dlopen_mode\n}\\endverbatim\n\nThen, you have to specify valgrind to use this suppression file by passing\nthe <tt>--suppressions=$HOME/.valgrind.supp</tt> option on the command line.\nYou can also add the following to your ~/.bashrc so that it gets passed\nautomatically. Actually, it passes a bit more options to valgrind, and this\nhappen to be my personnal settings. Check the valgrind documentation for\nmore information.\n\n\\verbatim export VALGRIND_OPTS=\"--leak-check=yes --leak-resolution=high --num-callers=40 --tool=memcheck --suppressions=$HOME/.valgrind.supp\" \\endverbatim\n\n\\subsubsection faq_trouble_backtraces Truncated backtraces\n\nWhen debugging SimGrid, it's easier to pass the\n--disable-compiler-optimization flag to the configure if valgrind or\ngdb get fooled by the optimization done by the compiler. But you\nshould remove these flag when everything works before going in\nproduction (before launching your 1252135 experiments), or everything\nwill run only one half of the true SimGrid potential.\n\n\\subsection faq_deadlock There is a deadlock in my code!!!\n\nUnfortunately, we cannot debug every code written in SimGrid.  We\nfurthermore believe that the framework provides ways enough\ninformation to debug such information yourself. If the textual output\nis not enough, Make sure to check the \\ref faq_visualization FAQ entry to see\nhow to get a graphical one.\n\nNow, if you come up with a really simple example that deadlocks and\nyou're absolutely convinced that it should not, you can ask on the\nlist. Just be aware that you'll be severely punished if the mistake is\non your side... We have plenty of FAQ entries to redact and new\nfeatures to implement for the impenitents! ;)\n\n\\subsection faq_surf_network_latency I get weird timings when I play with the latencies.\n\nOK, first of all, remember that units should be Bytes, Flops and\nSeconds. If you don't use such units, some SimGrid constants (e.g. the\nSG_TCP_CTE_GAMMA constant used in most network models) won't have the\nright unit and you'll end up with weird results.\n\nHere is what happens with a single transfer of size L on a link\n(bw,lat) when nothing else happens.\n\n\\verbatim\n0-----lat--------------------------------------------------t\n|-----|**** real_bw =min(bw,SG_TCP_CTE_GAMMA/(2*lat)) *****|\n\\endverbatim\n\nIn more complex situations, this min is the solution of a complex\nmax-min linear system.  Have a look\n<a href=\"http://lists.gforge.inria.fr/pipermail/simgrid-devel/2006-April/thread.html\">here</a>\nand read the two threads \"Bug in SURF?\" and \"Surf bug not\nfixed?\". You'll have a few other examples of such computations. You\ncan also read \"A Network Model for Simulation of Grid Application\" by\nHenri Casanova and Loris Marchal to have all the details. The fact\nthat the real_bw is smaller than bw is easy to understand. The fact\nthat real_bw is smaller than SG_TCP_CTE_GAMMA/(2*lat) is due to the\nwindow-based congestion mechanism of TCP. With TCP, you can't exploit\nyour huge network capacity if you don't have a good round-trip-time\nbecause of the acks...\n\nAnyway, what you get is t=lat + L/min(bw,SG_TCP_CTE_GAMMA/(2*lat)).\n\n  * if I you set (bw,lat)=(100 000 000, 0.00001), you get t =  1.00001 (you fully\nuse your link)\n  * if I you set (bw,lat)=(100 000 000, 0.0001),  you get t =  1.0001 (you're on the\nlimit)\n  * if I you set (bw,lat)=(100 000 000, 0.001),   you get t = 10.001  (ouch!)\n\nThis bound on the effective bandwidth of a flow is not the only thing\nthat may make your result be unexpected. For example, two flows\ncompeting on a saturated link receive an amount of bandwidth inversely\nproportional to their round trip time.\n\n\\subsection faq_bugrepport So I've found a bug in SimGrid. How to report it?\n\nWe do our best to make sure to hammer away any bugs of SimGrid, but this is\nstill an academic project so please be patient if/when you find bugs in it.\nIf you do, the best solution is to drop an email either on the simgrid-user\nor the simgrid-devel mailing list and explain us about the issue.  You can\nalso decide to open a formal bug report using the\n<a href=\"https://gforge.inria.fr/tracker/?atid=165&group_id=12&func=browse\">relevant\ninterface</a>. You need to login on the server to get the ability to submit\nbugs.\n\nWe will do our best to solve any problem repported, but you need to help us\nfinding the issue. Just telling \"it segfault\" isn't enough. Telling \"It\nsegfaults when running the attached simulator\" doesn't really help either.\nYou may find the following article interesting to see how to repport\ninformative bug repports:\nhttp://www.chiark.greenend.org.uk/~sgtatham/bugs.html (it is not SimGrid\nspecific at all, but it's full of good advices).\n\n\\author Da SimGrid team <simgrid-devel@lists.gforge.inria.fr>\n\n*/\n",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.20-xigfpbo5yypiin5odq3dedwvkyxa5sxr/spack-src/doc/doxygen/module-smpi.doc": "/** \n@defgroup SMPI_API      SMPI: Simulate real MPI applications\n@brief Programming environment for the simulation of MPI applications\n\n@tableofcontents\n\nSMPI enables the study of MPI application by emulating them on top of\nthe SimGrid simulator. This is particularly interesting to study\nexisting MPI applications within the comfort of the simulator. The\nSMPI reference article is available at\nhttps://hal.inria.fr/hal-01415484. You should also read the \n<a href=\"http://simgrid.org/tutorials/simgrid-smpi-101.pdf\">SMPI\nintroductory slides</a>.\n\nOur goal is to enable the study of **unmodified MPI applications**.\nSome constructs and features are still missing, but we can probably\nadd them on demand.  If you already used MPI before, SMPI should sound\nvery familiar to you: Use smpicc instead of mpicc, and smpirun instead\nof mpirun. The main difference is that smpirun takes a virtual\nplatform as extra parameter (see @ref platform).\n\nIf you are new to MPI, you should first take our online [SMPI\nCourseWare](https://simgrid.github.io/SMPI_CourseWare/). It consists\nin several projects that progressively introduce the MPI concepts. It\nproposes to use SimGrid and SMPI to run the experiments, but the\nlearning objectives are centered on MPI itself. \n\nFor **further scalability**, you may modify your code to speed up your\nstudies or save memory space.  Maximal **simulation accuracy**\nrequires some specific care from you.\n\n - @ref SMPI_use\n   - @ref SMPI_use_compile\n   - @ref SMPI_use_exec\n   - @ref SMPI_use_debug\n   - @ref SMPI_use_colls\n     - @ref SMPI_use_colls_algos\n     - @ref SMPI_use_colls_tracing\n - @ref SMPI_what\n   - @ref SMPI_what_coverage\n   - @ref SMPI_what_globals\n - @ref SMPI_adapting\n   - @ref SMPI_adapting_size\n   - @ref SMPI_adapting_speed\n - @ref SMPI_accuracy\n - @ref SMPI_troubleshooting\n   - @ref SMPI_trouble_configure_refuses_smpicc\n   - @ref SMPI_trouble_configure_dont_find_smpicc\n   - @ref SMPI_trouble_useconds_t\n\n\n@section SMPI_use Using SMPI\n\n@subsection SMPI_use_compile Compiling your code\n\nIf your application is in C, then simply use <tt>smpicc</tt> as a\ncompiler just like you use mpicc with other MPI implementations. This\nscript still calls your default compiler (gcc, clang, ...) and adds\nthe right compilation flags along the way. If your application is in\nC++, Fortran 77 or Fortran 90, use respectively <tt>smpicxx</tt>,\n<tt>smpiff</tt> or <tt>smpif90</tt>.\n\n@subsection SMPI_use_exec Executing your code on the simulator\n\nUse the <tt>smpirun</tt> script as follows for that:\n\n@verbatim\nsmpirun -hostfile my_hostfile.txt -platform my_platform.xml ./program -blah\n@endverbatim\n\n - <tt>my_hostfile.txt</tt> is a classical MPI hostfile (that is, this\n   file lists the machines on which the processes must be dispatched, one\n   per line)\n - <tt>my_platform.xml</tt> is a classical SimGrid platform file. Of\n   course, the hosts of the hostfile must exist in the provided\n   platform.\n - <tt>./program</tt> is the MPI program to simulate, that you\n   compiled with <tt>smpicc</tt>\n - <tt>-blah</tt> is a command-line parameter passed to this program.\n\n<tt>smpirun</tt> accepts other parameters, such as <tt>-np</tt> if you\ndon't want to use all the hosts defined in the hostfile, <tt>-map</tt>\nto display on which host each rank gets mapped of <tt>-trace</tt> to\nactivate the tracing during the simulation. You can get the full list\nby running\n\n@verbatim\nsmpirun -help\n@endverbatim\n\n@subsection SMPI_use_debug Debugging your code on top of SMPI\n\nIf you want to explore the automatic platform and deployment files\nthat are generated by @c smpirun, add @c -keep-temps to the command\nline.\n\nYou can also run your simulation within valgrind or gdb using the\nfollowing commands. Once in GDB, each MPI ranks will be represented as\na regular thread, and you can explore the state of each of them as\nusual.\n@verbatim\nsmpirun -wrapper valgrind ...other args...\nsmpirun -wrapper \"gdb --args\" --cfg=contexts/factory:thread ...other args...\n@endverbatim\n\n@subsection SMPI_use_colls Simulating collective operations\n\nMPI collective operations are crucial to the performance of MPI\napplications and must be carefully optimized according to many\nparameters. Every existing implementation provides several algorithms\nfor each collective operation, and selects by default the best suited\none, depending on the sizes sent, the number of nodes, the\ncommunicator, or the communication library being used.  These\ndecisions are based on empirical results and theoretical complexity\nestimation, and are very different between MPI implementations. In\nmost cases, the users can also manually tune the algorithm used for\neach collective operation.\n\nSMPI can simulate the behavior of several MPI implementations:\nOpenMPI, MPICH,\n<a href=\"http://star-mpi.sourceforge.net/\">STAR-MPI</a>, and\nMVAPICH2. For that, it provides 115 collective algorithms and several\nselector algorithms, that were collected directly in the source code\nof the targeted MPI implementations.\n\nYou can switch the automatic selector through the\n\\c smpi/coll-selector configuration item. Possible values:\n\n - <b>ompi</b>: default selection logic of OpenMPI (version 1.7)\n - <b>mpich</b>: default selection logic of MPICH (version 3.0.4)\n - <b>mvapich2</b>: selection logic of MVAPICH2 (version 1.9) tuned\n   on the Stampede cluster   \n - <b>impi</b>: preliminary version of an Intel MPI selector (version\n   4.1.3, also tuned for the Stampede cluster). Due the closed source\n   nature of Intel MPI, some of the algorithms described in the\n   documentation are not available, and are replaced by mvapich ones.   \n - <b>default</b>: legacy algorithms used in the earlier days of\n   SimGrid. Do not use for serious perform performance studies.\n\n\n@subsubsection SMPI_use_colls_algos Available algorithms\n\nYou can also pick the algorithm used for each collective with the\ncorresponding configuration item. For example, to use the pairwise\nalltoall algorithm, one should add \\c --cfg=smpi/alltoall:pair to the\nline. This will override the selector (if any) for this algorithm.\nIt means that the selected algorithm will be used \n\nWarning: Some collective may require specific conditions to be\nexecuted correctly (for instance having a communicator with a power of\ntwo number of nodes only), which are currently not enforced by\nSimgrid. Some crashes can be expected while trying these algorithms\nwith unusual sizes/parameters\n\n#### MPI_Alltoall\n\nMost of these are best described in <a href=\"http://www.cs.arizona.edu/~dkl/research/papers/ics06.pdf\">STAR-MPI</a>\n\n - default: naive one, by default\n - ompi: use openmpi selector for the alltoall operations\n - mpich: use mpich selector for the alltoall operations\n - mvapich2: use mvapich2 selector for the alltoall operations\n - impi: use intel mpi selector for the alltoall operations\n - automatic (experimental): use an automatic self-benchmarking algorithm \n - bruck: Described by Bruck et.al. in <a href=\"http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=642949\">this paper</a>\n - 2dmesh: organizes the nodes as a two dimensional mesh, and perform allgather \n   along the dimensions\n - 3dmesh: adds a third dimension to the previous algorithm\n - rdb: recursive doubling: extends the mesh to a nth dimension, each one \n   containing two nodes\n - pair: pairwise exchange, only works for power of 2 procs, size-1 steps,\n   each process sends and receives from the same process at each step\n - pair_light_barrier: same, with small barriers between steps to avoid\n   contention\n - pair_mpi_barrier: same, with MPI_Barrier used\n - pair_one_barrier: only one barrier at the beginning\n - ring: size-1 steps, at each step a process send to process (n+i)%size, and receives from (n-i)%size\n - ring_light_barrier: same, with small barriers between some phases to avoid contention\n - ring_mpi_barrier: same, with MPI_Barrier used\n - ring_one_barrier: only one barrier at the beginning\n - basic_linear: posts all receives and all sends,\nstarts the communications, and waits for all communication to finish\n - mvapich2_scatter_dest: isend/irecv with scattered destinations, posting only a few messages at the same time\n\n#### MPI_Alltoallv\n\n - default: naive one, by default\n - ompi: use openmpi selector for the alltoallv operations\n - mpich: use mpich selector for the alltoallv operations\n - mvapich2: use mvapich2 selector for the alltoallv operations\n - impi: use intel mpi selector for the alltoallv operations\n - automatic (experimental): use an automatic self-benchmarking algorithm \n - bruck: same as alltoall\n - pair: same as alltoall\n - pair_light_barrier: same as alltoall\n - pair_mpi_barrier: same as alltoall\n - pair_one_barrier: same as alltoall\n - ring: same as alltoall\n - ring_light_barrier: same as alltoall\n - ring_mpi_barrier: same as alltoall\n - ring_one_barrier: same as alltoall\n - ompi_basic_linear: same as alltoall\n\n#### MPI_Gather\n\n - default: naive one, by default\n - ompi: use openmpi selector for the gather operations\n - mpich: use mpich selector for the gather operations\n - mvapich2: use mvapich2 selector for the gather operations\n - impi: use intel mpi selector for the gather operations\n - automatic (experimental): use an automatic self-benchmarking algorithm \nwhich will iterate over all implemented versions and output the best\n - ompi_basic_linear: basic linear algorithm from openmpi, each process sends to the root\n - ompi_binomial: binomial tree algorithm\n - ompi_linear_sync: same as basic linear, but with a synchronization at the\n beginning and message cut into two segments.\n - mvapich2_two_level: SMP-aware version from MVAPICH. Gather first intra-node (defaults to mpich's gather), and then exchange with only one process/node. Use mvapich2 selector to change these to tuned algorithms for Stampede cluster.\n\n#### MPI_Barrier\n\n - default: naive one, by default\n - ompi: use openmpi selector for the barrier operations\n - mpich: use mpich selector for the barrier operations\n - mvapich2: use mvapich2 selector for the barrier operations\n - impi: use intel mpi selector for the barrier operations\n - automatic (experimental): use an automatic self-benchmarking algorithm \n - ompi_basic_linear: all processes send to root\n - ompi_two_procs: special case for two processes\n - ompi_bruck: nsteps = sqrt(size), at each step, exchange data with rank-2^k and rank+2^k\n - ompi_recursivedoubling: recursive doubling algorithm\n - ompi_tree: recursive doubling type algorithm, with tree structure\n - ompi_doublering: double ring algorithm\n - mvapich2_pair: pairwise algorithm\n\n#### MPI_Scatter\n\n - default: naive one, by default\n - ompi: use openmpi selector for the scatter operations\n - mpich: use mpich selector for the scatter operations\n - mvapich2: use mvapich2 selector for the scatter operations\n - impi: use intel mpi selector for the scatter operations\n - automatic (experimental): use an automatic self-benchmarking algorithm \n - ompi_basic_linear: basic linear scatter \n - ompi_binomial: binomial tree scatter\n - mvapich2_two_level_direct: SMP aware algorithm, with an intra-node stage (default set to mpich selector), and then a basic linear inter node stage. Use mvapich2 selector to change these to tuned algorithms for Stampede cluster. \n - mvapich2_two_level_binomial: SMP aware algorithm, with an intra-node stage (default set to mpich selector), and then a binomial phase. Use mvapich2 selector to change these to tuned algorithms for Stampede cluster.\n\n#### MPI_Reduce\n\n - default: naive one, by default\n - ompi: use openmpi selector for the reduce operations\n - mpich: use mpich selector for the reduce operations\n - mvapich2: use mvapich2 selector for the reduce operations\n - impi: use intel mpi selector for the reduce operations\n - automatic (experimental): use an automatic self-benchmarking algorithm \n - arrival_pattern_aware: root exchanges with the first process to arrive\n - binomial: uses a binomial tree\n - flat_tree: uses a flat tree\n - NTSL: Non-topology-specific pipelined linear-bcast function \n   0->1, 1->2 ,2->3, ....., ->last node: in a pipeline fashion, with segments\n of 8192 bytes\n - scatter_gather: scatter then gather\n - ompi_chain: openmpi reduce algorithms are built on the same basis, but the\n topology is generated differently for each flavor\nchain = chain with spacing of size/2, and segment size of 64KB \n - ompi_pipeline: same with pipeline (chain with spacing of 1), segment size \ndepends on the communicator size and the message size\n - ompi_binary: same with binary tree, segment size of 32KB\n - ompi_in_order_binary: same with binary tree, enforcing order on the \noperations\n - ompi_binomial: same with binomial algo (redundant with default binomial \none in most cases)\n - ompi_basic_linear: basic algorithm, each process sends to root\n - mvapich2_knomial: k-nomial algorithm. Default factor is 4 (mvapich2 selector adapts it through tuning)\n - mvapich2_two_level: SMP-aware reduce, with default set to mpich both for intra and inter communicators. Use mvapich2 selector to change these to tuned algorithms for Stampede cluster.\n - rab: <a href=\"https://fs.hlrs.de/projects/par/mpi//myreduce.html\">Rabenseifner</a>'s reduce algorithm \n\n#### MPI_Allreduce\n\n - default: naive one, by default\n - ompi: use openmpi selector for the allreduce operations\n - mpich: use mpich selector for the allreduce operations\n - mvapich2: use mvapich2 selector for the allreduce operations\n - impi: use intel mpi selector for the allreduce operations\n - automatic (experimental): use an automatic self-benchmarking algorithm \n - lr: logical ring reduce-scatter then logical ring allgather\n - rab1: variations of the  <a href=\"https://fs.hlrs.de/projects/par/mpi//myreduce.html\">Rabenseifner</a> algorithm: reduce_scatter then allgather\n - rab2: variations of the  <a href=\"https://fs.hlrs.de/projects/par/mpi//myreduce.html\">Rabenseifner</a> algorithm: alltoall then allgather\n - rab_rsag: variation of the  <a href=\"https://fs.hlrs.de/projects/par/mpi//myreduce.html\">Rabenseifner</a> algorithm: recursive doubling \nreduce_scatter then recursive doubling allgather \n - rdb: recursive doubling\n - smp_binomial: binomial tree with smp: binomial intra \nSMP reduce, inter reduce, inter broadcast then intra broadcast\n - smp_binomial_pipeline: same with segment size = 4096 bytes\n - smp_rdb: intra: binomial allreduce, inter: Recursive \ndoubling allreduce, intra: binomial broadcast\n - smp_rsag: intra: binomial allreduce, inter: reduce-scatter, \ninter:allgather, intra: binomial broadcast\n - smp_rsag_lr: intra: binomial allreduce, inter: logical ring \nreduce-scatter, logical ring inter:allgather, intra: binomial broadcast\n - smp_rsag_rab: intra: binomial allreduce, inter: rab\nreduce-scatter, rab inter:allgather, intra: binomial broadcast\n - redbcast: reduce then broadcast, using default or tuned algorithms if specified\n - ompi_ring_segmented: ring algorithm used by OpenMPI\n - mvapich2_rs: rdb for small messages, reduce-scatter then allgather else\n - mvapich2_two_level: SMP-aware algorithm, with mpich as intra algoritm, and rdb as inter (Change this behavior by using mvapich2 selector to use tuned values)\n - rab: default <a href=\"https://fs.hlrs.de/projects/par/mpi//myreduce.html\">Rabenseifner</a> implementation\n\n#### MPI_Reduce_scatter\n\n - default: naive one, by default\n - ompi: use openmpi selector for the reduce_scatter operations\n - mpich: use mpich selector for the reduce_scatter operations\n - mvapich2: use mvapich2 selector for the reduce_scatter operations\n - impi: use intel mpi selector for the reduce_scatter operations\n - automatic (experimental): use an automatic self-benchmarking algorithm \n - ompi_basic_recursivehalving: recursive halving version from OpenMPI\n - ompi_ring: ring version from OpenMPI\n - mpich_pair: pairwise exchange version from MPICH\n - mpich_rdb: recursive doubling version from MPICH\n - mpich_noncomm: only works for power of 2 procs, recursive doubling for noncommutative ops\n\n\n#### MPI_Allgather\n\n - default: naive one, by default\n - ompi: use openmpi selector for the allgather operations\n - mpich: use mpich selector for the allgather operations\n - mvapich2: use mvapich2 selector for the allgather operations\n - impi: use intel mpi selector for the allgather operations\n - automatic (experimental): use an automatic self-benchmarking algorithm \n - 2dmesh: see alltoall\n - 3dmesh: see alltoall\n - bruck: Described by Bruck et.al. in <a href=\"http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=642949\">\nEfficient algorithms for all-to-all communications in multiport message-passing systems</a> \n - GB: Gather - Broadcast (uses tuned version if specified)\n - loosely_lr: Logical Ring with grouping by core (hardcoded, default \nprocesses/node: 4)\n - NTSLR: Non Topology Specific Logical Ring\n - NTSLR_NB: Non Topology Specific Logical Ring, Non Blocking operations\n - pair: see alltoall\n - rdb: see alltoall\n - rhv: only power of 2 number of processes\n - ring: see alltoall\n - SMP_NTS: gather to root of each SMP, then every root of each SMP node \npost INTER-SMP Sendrecv, then do INTRA-SMP Bcast for each receiving message, \nusing logical ring algorithm (hardcoded, default processes/SMP: 8)\n - smp_simple: gather to root of each SMP, then every root of each SMP node \npost INTER-SMP Sendrecv, then do INTRA-SMP Bcast for each receiving message, \nusing simple algorithm (hardcoded, default processes/SMP: 8)\n - spreading_simple: from node i, order of communications is i -> i + 1, i ->\n i + 2, ..., i -> (i + p -1) % P\n - ompi_neighborexchange: Neighbor Exchange algorithm for allgather. \nDescribed by Chen et.al. in  <a href=\"http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1592302\">Performance Evaluation of Allgather Algorithms on Terascale Linux Cluster with Fast Ethernet</a>\n - mvapich2_smp: SMP aware algorithm, performing intra-node gather, inter-node allgather with one process/node, and bcast intra-node\n\n\n#### MPI_Allgatherv\n\n - default: naive one, by default\n - ompi: use openmpi selector for the allgatherv operations\n - mpich: use mpich selector for the allgatherv operations\n - mvapich2: use mvapich2 selector for the allgatherv operations\n - impi: use intel mpi selector for the allgatherv operations\n - automatic (experimental): use an automatic self-benchmarking algorithm \n - GB: Gatherv - Broadcast (uses tuned version if specified, but only for \nBcast, gatherv is not tuned)\n - pair: see alltoall\n - ring: see alltoall\n - ompi_neighborexchange: see allgather\n - ompi_bruck: see allgather\n - mpich_rdb: recursive doubling algorithm from MPICH\n - mpich_ring: ring algorithm from MPICh - performs differently from the  one from STAR-MPI\n\n#### MPI_Bcast\n\n - default: naive one, by default\n - ompi: use openmpi selector for the bcast operations\n - mpich: use mpich selector for the bcast operations\n - mvapich2: use mvapich2 selector for the bcast operations\n - impi: use intel mpi selector for the bcast operations\n - automatic (experimental): use an automatic self-benchmarking algorithm \n - arrival_pattern_aware: root exchanges with the first process to arrive\n - arrival_pattern_aware_wait: same with slight variation\n - binomial_tree: binomial tree exchange\n - flattree: flat tree exchange\n - flattree_pipeline: flat tree exchange, message split into 8192 bytes pieces\n - NTSB: Non-topology-specific pipelined binary tree with 8192 bytes pieces\n - NTSL: Non-topology-specific pipelined linear with 8192 bytes pieces\n - NTSL_Isend: Non-topology-specific pipelined linear with 8192 bytes pieces, asynchronous communications\n - scatter_LR_allgather: scatter followed by logical ring allgather\n - scatter_rdb_allgather: scatter followed by recursive doubling allgather\n - arrival_scatter: arrival pattern aware scatter-allgather\n - SMP_binary: binary tree algorithm with 8 cores/SMP\n - SMP_binomial: binomial tree algorithm with 8 cores/SMP\n - SMP_linear: linear algorithm with 8 cores/SMP\n - ompi_split_bintree: binary tree algorithm from OpenMPI, with message split in 8192 bytes pieces\n - ompi_pipeline: pipeline algorithm from OpenMPI, with message split in 128KB pieces\n - mvapich2_inter_node: Inter node default mvapich worker \n - mvapich2_intra_node: Intra node default mvapich worker\n - mvapich2_knomial_intra_node:  k-nomial intra node default mvapich worker. default factor is 4.\n\n#### Automatic evaluation \n\n(Warning: This is still very experimental)\n\nAn automatic version is available for each collective (or even as a selector). This specific \nversion will loop over all other implemented algorithm for this particular collective, and apply \nthem while benchmarking the time taken for each process. It will then output the quickest for \neach process, and the global quickest. This is still unstable, and a few algorithms which need \nspecific number of nodes may crash.\n\n#### Adding an algorithm\n\nTo add a new algorithm, one should check in the src/smpi/colls folder how other algorithms \nare coded. Using plain MPI code inside Simgrid can't be done, so algorithms have to be \nchanged to use smpi version of the calls instead (MPI_Send will become smpi_mpi_send). Some functions may have different signatures than their MPI counterpart, please check the other algorithms or contact us using <a href=\"http://lists.gforge.inria.fr/mailman/listinfo/simgrid-devel\">SimGrid developers mailing list</a>.\n\nExample: adding a \"pair\" version of the Alltoall collective.\n\n - Implement it in a file called alltoall-pair.c in the src/smpi/colls folder. This file should include colls_private.hpp.\n\n - The name of the new algorithm function should be smpi_coll_tuned_alltoall_pair, with the same signature as MPI_Alltoall.\n\n - Once the adaptation to SMPI code is done, add a reference to the file (\"src/smpi/colls/alltoall-pair.c\") in the SMPI_SRC part of the DefinePackages.cmake file inside buildtools/cmake, to allow the file to be built and distributed.\n\n - To register the new version of the algorithm, simply add a line to the corresponding macro in src/smpi/colls/cools.h ( add a \"COLL_APPLY(action, COLL_ALLTOALL_SIG, pair)\" to the COLL_ALLTOALLS macro ). The algorithm should now be compiled and be selected when using --cfg=smpi/alltoall:pair at runtime.\n\n - To add a test for the algorithm inside Simgrid's test suite, juste add the new algorithm name in the ALLTOALL_COLL list found inside teshsuite/smpi/CMakeLists.txt . When running ctest, a test for the new algorithm should be generated and executed. If it does not pass, please check your code or contact us.\n\n - Please submit your patch for inclusion in SMPI, for example through a pull request on GitHub or directly per email.\n\n@subsubsection SMPI_use_colls_tracing Tracing of internal communications\n\nBy default, the collective operations are traced as a unique operation\nbecause tracing all point-to-point communications composing them could\nresult in overloaded, hard to interpret traces. If you want to debug\nand compare collective algorithms, you should set the\n\\c tracing/smpi/internals configuration item to 1 instead of 0.\n\nHere are examples of two alltoall collective algorithms runs on 16 nodes, \nthe first one with a ring algorithm, the second with a pairwise one:\n\n@htmlonly\n<a href=\"smpi_simgrid_alltoall_ring_16.png\" border=0><img src=\"smpi_simgrid_alltoall_ring_16.png\" width=\"30%\" border=0 align=\"center\"></a>\n<a href=\"smpi_simgrid_alltoall_pair_16.png\" border=0><img src=\"smpi_simgrid_alltoall_pair_16.png\" width=\"30%\" border=0 align=\"center\"></a>\n<br/>\n@endhtmlonly\n\n@section SMPI_what What can run within SMPI?\n\nYou can run unmodified MPI applications (both C/C++ and Fortran) within\nSMPI, provided that you only use MPI calls that we implemented. Global\nvariables should be handled correctly on Linux systems.\n\n@subsection SMPI_what_coverage MPI coverage of SMPI\n\nOur coverage of the interface is very decent, but still incomplete;\nGiven the size of the MPI standard, we may well never manage to \nimplement absolutely all existing primitives. Currently, we have\nalmost no support for I/O primitives, but we still pass a very large\namount of the MPICH coverage tests.\n\nThe full list of not yet implemented functions is documented in the\nfile @ref include/smpi/smpi.h, between two lines containing the\n<tt>FIXME</tt> marker. If you really miss a feature, please get in\ntouch with us: we can guide you though the SimGrid code to help you\nimplementing it, and we'd glad to integrate your contribution to the\nmain project afterward.\n\n@subsection SMPI_what_globals Privatization of global variables\n\nConcerning the globals, the problem comes from the fact that usually,\nMPI processes run as real UNIX processes while they are all folded\ninto threads of a unique system process in SMPI. Global variables are\nusually private to each MPI process while they become shared between\nthe processes in SMPI.  The problem and some potential solutions are\ndiscussed in this article: \"Automatic Handling of Global Variables for\nMulti-threaded MPI Programs\", available at\nhttp://charm.cs.illinois.edu/newPapers/11-23/paper.pdf (note that this\narticle does not deal with SMPI but with a competing solution called\nAMPI that suffers of the same issue).  This point used to be\nproblematic in SimGrid, but the problem should now be handled\nautomatically on Linux.\n\nOlder versions of SimGrid came with a script that automatically\nprivatized the globals through static analysis of the source code. But\nour implementation was not robust enough to be used in production, so\nit was removed at some point. Currently, SMPI comes with two\nprivatization mechanisms that you can @ref options_smpi_privatization\n\"select at runtime\". At the time of writing (v3.18), the dlopen\napproach is considered to be very fast (it's used by default) while\nthe mmap approach is considered to be rather slow but very robust.\n\nWith the <b>mmap approach</b>, SMPI duplicates and dynamically switch\nthe \\c .data and \\c .bss segments of the ELF process when switching\nthe MPI ranks. This allows each ranks to have its own copy of the\nglobal variables.  No copy actually occures as this mechanism uses \\c\nmmap for efficiency. This mechanism is considered to be very robust on\nall systems supporting \\c mmap (Linux and most BSDs). Its performance\nis questionable since each context switch between MPI ranks induces\nseveral syscalls to change the \\c mmap that redirects the \\c .data and\n\\c .bss segments to the copies of the new rank. The code will also be\ncopied several times in memory, inducing a slight increase of memory\noccupation.\n\nAnother limitation is that SMPI only accounts for global variables\ndefined in the executable. If the processes use external global\nvariables from dynamic libraries, they won't be switched\ncorrectly. The easiest way to solve this is to statically link against\nthe library with these globals. This way, each MPI rank will get its\nown copy of these libraries. Of course you should never statically\nlink against the SimGrid library itself.\n\nWith the <b>dlopen approach</b>, SMPI loads several copies of the same\nexecutable in memory as if it were a library, so that the global\nvariables get naturally duplicated. It first requires the executable\nto be compiled as a relocatable binary, which is less common for\nprograms than for libraries. But most distributions are now compiled\nthis way for security reason as it allows to randomize the address\nspace layout. It should thus be safe to compile most (any?) program\nthis way.  The second trick is that the dynamic linker refuses to link\nthe exact same file several times, be it a library or a relocatable\nexecutable. It makes perfectly sense in the general case, but we need\nto circumvent this rule of thumb in our case. To that extend, the\nbinary is copied in a temporary file before being re-linked against.\n`dlmopen()` cannot be used as it only allows 256 contextes, and as it\nwould also dupplicate simgrid itself.\n\nThis approach greatly speeds up the context switching, down to about\n40 CPU cycles with our raw contextes, instead of requesting several\nsyscalls with the \\c mmap approach. Another advantage is that it\npermits to run the SMPI contexts in parallel, which is obviously not\npossible with the \\c mmap approach. It was tricky to implement, but we\nare not aware of any flaws, so smpirun activates it by default.\n\nIn the future, it may be possible to further reduce the memory and\ndisk consumption. It seems that we could <a\nhref=\"https://lwn.net/Articles/415889/\">punch holes</a> in the files\nbefore dl-loading them to remove the code and constants, and mmap\nthese area onto a unique copy. If done correctly, this would reduce\nthe disk- and memory- usage to the bare minimum, and would also reduce\nthe pressure on the CPU instruction cache. See \n<a href=\"https://github.com/simgrid/simgrid/issues/137\">the relevant\nbug</a> on github for implementation leads.\\n\n\nAlso, currently, only the binary is copied and dlopen-ed for each MPI\nrank. We could probably extend this to external dependencies, but for\nnow, any external dependencies must be statically linked into your\napplication. As usual, simgrid itself shall never be statically linked\nin your app. You don't want to give a copy of SimGrid to each MPI rank:\nthat's ways too much for them to deal with.\n\n@section SMPI_adapting Adapting your MPI code for further scalability\n\nAs detailed in the reference article (available at\nhttp://hal.inria.fr/hal-01415484), you may want to adapt your code\nto improve the simulation performance. But these tricks may seriously\nhinder the result quality (or even prevent the app to run) if used\nwrongly. We assume that if you want to simulate an HPC application,\nyou know what you are doing. Don't prove us wrong!\n\n@subsection SMPI_adapting_size Reducing your memory footprint\n\nIf you get short on memory (the whole app is executed on a single node when\nsimulated), you should have a look at the SMPI_SHARED_MALLOC and\nSMPI_SHARED_FREE macros. It allows to share memory areas between processes: The\npurpose of these macro is that the same line malloc on each process will point\nto the exact same memory area. So if you have a malloc of 2M and you have 16\nprocesses, this macro will change your memory consumption from 2M*16 to 2M\nonly. Only one block for all processes.\n\nIf your program is ok with a block containing garbage value because all\nprocesses write and read to the same place without any kind of coordination,\nthen this macro can dramatically shrink your memory consumption. For example,\nthat will be very beneficial to a matrix multiplication code, as all blocks will\nbe stored on the same area. Of course, the resulting computations will useless,\nbut you can still study the application behavior this way. \n\nNaturally, this won't work if your code is data-dependent. For example, a Jacobi\niterative computation depends on the result computed by the code to detect\nconvergence conditions, so turning them into garbage by sharing the same memory\narea between processes does not seem very wise. You cannot use the\nSMPI_SHARED_MALLOC macro in this case, sorry.\n\nThis feature is demoed by the example file\n<tt>examples/smpi/NAS/dt.c</tt>\n\n@subsection SMPI_adapting_speed Toward faster simulations\n\nIf your application is too slow, try using SMPI_SAMPLE_LOCAL,\nSMPI_SAMPLE_GLOBAL and friends to indicate which computation loops can\nbe sampled. Some of the loop iterations will be executed to measure\ntheir duration, and this duration will be used for the subsequent\niterations. These samples are done per processor with\nSMPI_SAMPLE_LOCAL, and shared between all processors with\nSMPI_SAMPLE_GLOBAL. Of course, none of this will work if the execution\ntime of your loop iteration are not stable.\n\nThis feature is demoed by the example file \n<tt>examples/smpi/NAS/ep.c</tt>\n\n@section SMPI_accuracy Ensuring accurate simulations\n\nOut of the box, SimGrid may give you fairly accurate results, but\nthere is a plenty of factors that could go wrong and make your results\ninaccurate or even plainly wrong. Actually, you can only get accurate\nresults of a nicely built model, including both the system hardware\nand your application. Such models are hard to pass over and reuse in\nother settings, because elements that are not relevant to an\napplication (say, the latency of point-to-point communications,\ncollective operation implementation details or CPU-network\ninteraction) may be irrelevant to another application. The dream of\nthe perfect model, encompassing every aspects is only a chimera, as\nthe only perfect model of the reality is the reality. If you go for\nsimulation, then you have to ignore some irrelevant aspects of the\nreality, but which aspects are irrelevant is actually\napplication-dependent...\n\nThe only way to assess whether your settings provide accurate results\nis to double-check these results. If possible, you should first run\nthe same experiment in simulation and in real life, gathering as much\ninformation as you can. Try to understand the discrepancies in the\nresults that you observe between both settings (visualization can be\nprecious for that). Then, try to modify your model (of the platform,\nof the collective operations) to reduce the most preeminent differences.\n\nIf the discrepancies come from the computing time, try adapting the \\c\nsmpi/host-speed: reduce it if your simulation runs faster than in\nreality. If the error come from the communication, then you need to\nfiddle with your platform file.\n\nBe inventive in your modeling. Don't be afraid if the names given by\nSimGrid does not match the real names: we got very good results by\nmodeling multicore/GPU machines with a set of separate hosts\ninterconnected with very fast networks (but don't trust your model\nbecause it has the right names in the right place either).\n\nFinally, you may want to check [this\narticle](https://hal.inria.fr/hal-00907887) on the classical pitfalls\nin modeling distributed systems.\n\n@section SMPI_troubleshooting Troubleshooting with SMPI\n\n@subsection SMPI_trouble_configure_refuses_smpicc ./configure refuses to use smpicc\n\nIf your <tt>./configure</tt> reports that the compiler is not\nfunctional or that you are cross-compiling, try to define the\n<tt>SMPI_PRETEND_CC</tt> environment variable before running the\nconfiguration.\n\n@verbatim\nSMPI_PRETEND_CC=1 ./configure # here come the configure parameters\nmake\n@endverbatim\n\nIndeed, the programs compiled with <tt>smpicc</tt> cannot be executed\nwithout <tt>smpirun</tt> (they are shared libraries, and they do weird\nthings on startup), while configure wants to test them directly.\nWith <tt>SMPI_PRETEND_CC</tt> smpicc does not compile as shared,\nand the SMPI initialization stops and returns 0 before doing anything\nthat would fail without <tt>smpirun</tt>.\n\n\\warning \n\n  Make sure that SMPI_PRETEND_CC is only set when calling ./configure,\n  not during the actual execution, or any program compiled with smpicc\n  will stop before starting.\n\n@subsection SMPI_trouble_configure_dont_find_smpicc ./configure does not pick smpicc as a compiler\n\nIn addition to the previous answers, some projects also need to be\nexplicitely told what compiler to use, as follows:\n\n@verbatim\nSMPI_PRETEND_CC=1 ./configure CC=smpicc # here come the other configure parameters\nmake\n@endverbatim\n\nMaybe your configure is using another variable, such as <tt>cc</tt> or\nsimilar. Just check the logs.\n\n@subsection SMPI_trouble_useconds_t  error: unknown type name 'useconds_t'\n\nTry to add <tt>-D_GNU_SOURCE</tt> to your compilation line to get ride\nof that error.\n\nThe reason is that SMPI provides its own version of <tt>usleep(3)</tt>\nto override it and to block in the simulation world, not in the real\none. It needs the <tt>useconds_t</tt> type for that, which is declared\nonly if you declare <tt>_GNU_SOURCE</tt> before including\n<tt>unistd.h</tt>. If your project includes that header file before\nSMPI, then you need to ensure that you pass the right configuration\ndefines as advised above.\n\n\n*/\n\n\n/** @example include/smpi/smpi.h */\n",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.20-xigfpbo5yypiin5odq3dedwvkyxa5sxr/spack-src/doc/doxygen/options.doc": "/*! \\page options Configure SimGrid\n\n\\htmlonly\n<div align=\"center\">\n\\endhtmlonly\n\\htmlinclude graphical-toc.svg\n\\htmlonly\n</div>\n<script>\ndocument.getElementById(\"Config\").style=\"opacity:0.93999999;fill:#ff0000;fill-opacity:0.1;stroke:#000000;stroke-width:0.35277778;stroke-linecap:round;stroke-linejoin:round;stroke-miterlimit:4;stroke-dasharray:none;stroke-dashoffset:0;stroke-opacity:1\";\n</script>\n\\endhtmlonly\n\nA number of options can be given at runtime to change the default\nSimGrid behavior. For a complete list of all configuration options\naccepted by the SimGrid version used in your simulator, simply pass\nthe --help configuration flag to your program. If some of the options\nare not documented on this page, this is a bug that you should please\nreport so that we can fix it. Note that some of the options presented\nhere may not be available in your simulators, depending on the\n@ref install_src_config \"compile-time options\" that you used.\n\n\\tableofcontents\n\n\\section options_using Passing configuration options to the simulators\n\nThere is several way to pass configuration options to the simulators.\nThe most common way is to use the \\c --cfg command line argument. For\nexample, to set the item \\c Item to the value \\c Value, simply\ntype the following: \\verbatim\nmy_simulator --cfg=Item:Value (other arguments)\n\\endverbatim\n\nSeveral \\c `--cfg` command line arguments can naturally be used. If you\nneed to include spaces in the argument, don't forget to quote the\nargument. You can even escape the included quotes (write \\' for ' if\nyou have your argument between ').\n\nAnother solution is to use the \\c \\<config\\> tag in the platform file. The\nonly restriction is that this tag must occure before the first\nplatform element (be it \\c \\<AS\\>, \\c \\<cluster\\>, \\c \\<peer\\> or whatever).\nThe \\c \\<config\\> tag takes an \\c id attribute, but it is currently\nignored so you don't really need to pass it. The important par is that\nwithin that tag, you can pass one or several \\c \\<prop\\> tags to specify\nthe configuration to use. For example, setting \\c Item to \\c Value\ncan be done by adding the following to the beginning of your platform\nfile:\n\\verbatim\n<config>\n  <prop id=\"Item\" value=\"Value\"/>\n</config>\n\\endverbatim\n\nA last solution is to pass your configuration directly using the C\ninterface. If you happen to use the MSG interface, this is very easy\nwith the simgrid::s4u::Engine::setConfig() or MSG_config() functions. If you do not use MSG, that's a bit\nmore complex, as you have to mess with the internal configuration set\ndirectly as follows. Check the \\ref XBT_config \"relevant page\" for\ndetails on all the functions you can use in this context, \\c\n_sg_cfg_set being the only configuration set currently used in\nSimGrid.\n\n@code\n#include <xbt/config.h>\n\nint main(int argc, char *argv[]) {\n     SD_init(&argc, argv);\n\n     /* Prefer MSG_config() if you use MSG!! */\n     xbt_cfg_set_parse(\"Item:Value\");\n\n     // Rest of your code\n}\n@endcode\n\n\\section options_index Index of all existing configuration options\n\n\\note\n  The full list can be retrieved by passing \"--help\" and\n     \"--help-cfg\" to an executable that uses SimGrid.\n\n- \\c clean-atexit: \\ref options_generic_clean_atexit\n\n- \\c contexts/factory: \\ref options_virt_factory\n- \\c contexts/guard-size: \\ref options_virt_guard_size\n- \\c contexts/nthreads: \\ref options_virt_parallel\n- \\c contexts/parallel-threshold: \\ref options_virt_parallel\n- \\c contexts/stack-size: \\ref options_virt_stacksize\n- \\c contexts/synchro: \\ref options_virt_parallel\n\n- \\c cpu/maxmin-selective-update: \\ref options_model_optim\n- \\c cpu/model: \\ref options_model_select\n- \\c cpu/optim: \\ref options_model_optim\n\n- \\c exception/cutpath: \\ref options_exception_cutpath\n\n- \\c host/model: \\ref options_model_select\n\n- \\c maxmin/precision: \\ref options_model_precision\n- \\c maxmin/concurrency-limit: \\ref options_concurrency_limit\n\n- \\c msg/debug-multiple-use: \\ref options_msg_debug_multiple_use\n\n- \\c model-check: \\ref options_modelchecking\n- \\c model-check/checkpoint: \\ref options_modelchecking_steps\n- \\c model-check/communications-determinism: \\ref options_modelchecking_comm_determinism\n- \\c model-check/dot-output: \\ref options_modelchecking_dot_output\n- \\c model-check/hash: \\ref options_modelchecking_hash\n- \\c model-check/property: \\ref options_modelchecking_liveness\n- \\c model-check/max-depth: \\ref options_modelchecking_max_depth\n- \\c model-check/record: \\ref options_modelchecking_recordreplay\n- \\c model-check/reduction: \\ref options_modelchecking_reduction\n- \\c model-check/replay: \\ref options_modelchecking_recordreplay\n- \\c model-check/send-determinism: \\ref options_modelchecking_comm_determinism\n- \\c model-check/sparse-checkpoint: \\ref options_modelchecking_sparse_checkpoint\n- \\c model-check/termination: \\ref options_modelchecking_termination\n- \\c model-check/timeout: \\ref options_modelchecking_timeout\n- \\c model-check/visited: \\ref options_modelchecking_visited\n\n- \\c network/bandwidth-factor: \\ref options_model_network_coefs\n- \\c network/crosstraffic: \\ref options_model_network_crosstraffic\n- \\c network/latency-factor: \\ref options_model_network_coefs\n- \\c network/maxmin-selective-update: \\ref options_model_optim\n- \\c network/model: \\ref options_model_select\n- \\c network/optim: \\ref options_model_optim\n- \\c network/TCP-gamma: \\ref options_model_network_gamma\n- \\c network/weight-S: \\ref options_model_network_coefs\n\n- \\c ns3/TcpModel: \\ref options_pls\n- \\c path: \\ref options_generic_path\n- \\c plugin: \\ref options_generic_plugin\n\n- \\c simix/breakpoint: \\ref options_generic_breakpoint\n\n- \\c storage/max_file_descriptors: \\ref option_model_storage_maxfd\n\n- \\c surf/precision: \\ref options_model_precision\n\n- \\c <b>For collective operations of SMPI, please refer to Section \\ref options_index_smpi_coll</b>\n- \\c smpi/async-small-thresh: \\ref options_model_network_asyncsend\n- \\c smpi/bw-factor: \\ref options_model_smpi_bw_factor\n- \\c smpi/coll-selector: \\ref options_model_smpi_collectives\n- \\c smpi/comp-adjustment-file: \\ref options_model_smpi_adj_file\n- \\c smpi/cpu-threshold: \\ref options_smpi_bench\n- \\c smpi/display-timing: \\ref options_smpi_timing\n- \\c smpi/grow-injected-times: \\ref options_model_smpi_test\n- \\c smpi/host-speed: \\ref options_smpi_bench\n- \\c smpi/IB-penalty-factors: \\ref options_model_network_coefs\n- \\c smpi/iprobe: \\ref options_model_smpi_iprobe\n- \\c smpi/iprobe-cpu-usage: \\ref options_model_smpi_iprobe_cpu_usage\n- \\c smpi/init: \\ref options_model_smpi_init\n- \\c smpi/keep-temps: \\ref options_smpi_temps\n- \\c smpi/lat-factor: \\ref options_model_smpi_lat_factor\n- \\c smpi/ois: \\ref options_model_smpi_ois\n- \\c smpi/or: \\ref options_model_smpi_or\n- \\c smpi/os: \\ref options_model_smpi_os\n- \\c smpi/papi-events: \\ref options_smpi_papi_events\n- \\c smpi/privatization: \\ref options_smpi_privatization\n- \\c smpi/privatize-libs: \\ref options_smpi_privatize_libs\n- \\c smpi/send-is-detached-thresh: \\ref options_model_smpi_detached\n- \\c smpi/shared-malloc: \\ref options_model_smpi_shared_malloc\n- \\c smpi/shared-malloc-hugepage: \\ref options_model_smpi_shared_malloc\n- \\c smpi/simulate-computation: \\ref options_smpi_bench\n- \\c smpi/test: \\ref options_model_smpi_test\n- \\c smpi/wtime: \\ref options_model_smpi_wtime\n\n- \\c <b>Tracing configuration options can be found in Section \\ref tracing_tracing_options</b>.\n\n- \\c storage/model: \\ref options_storage_model\n- \\c verbose-exit: \\ref options_generic_exit\n\n- \\c vm/model: \\ref options_vm_model\n\n\\subsection options_index_smpi_coll Index of SMPI collective algorithms options\n\nTODO: All available collective algorithms will be made available via the ``smpirun --help-coll`` command.\n\n\\section options_model Configuring the platform models\n\n\\anchor options_storage_model\n\\anchor options_vm_model\n\\subsection options_model_select Selecting the platform models\n\nSimGrid comes with several network, CPU and storage models built in, and you\ncan change the used model at runtime by changing the passed\nconfiguration. The three main configuration items are given below.\nFor each of these items, passing the special \\c help value gives\nyou a short description of all possible values. Also, \\c --help-models\nshould provide information about all models for all existing resources.\n   - \\b network/model: specify the used network model\n   - \\b cpu/model: specify the used CPU model\n   - \\b host/model: specify the used host model\n   - \\b storage/model: specify the used storage model (there is currently only one such model - this option is hence only useful for future releases)\n   - \\b vm/model: specify the model for virtual machines (there is currently only one such model - this option is hence only useful for future releases)\n\nAs of writing, the following network models are accepted. Over\nthe time new models can be added, and some experimental models can be\nremoved; check the values on your simulators for an uptodate\ninformation. Note that the CM02 model is described in the research report\n<a href=\"ftp://ftp.ens-lyon.fr/pub/LIP/Rapports/RR/RR2002/RR2002-40.ps.gz\">A\nNetwork Model for Simulation of Grid Application</a> while LV08 is\ndescribed in\n<a href=\"http://mescal.imag.fr/membres/arnaud.legrand/articles/simutools09.pdf\">Accuracy Study and Improvement of Network Simulation in the SimGrid Framework</a>.\n\n  - \\b LV08 (default one): Realistic network analytic model\n    (slow-start modeled by multiplying latency by 13.01, bandwidth by\n    .97; bottleneck sharing uses a payload of S=20537 for evaluating RTT)\n  - \\anchor options_model_select_network_constant \\b Constant: Simplistic network model where all communication\n    take a constant time (one second). This model provides the lowest\n    realism, but is (marginally) faster.\n  - \\b SMPI: Realistic network model specifically tailored for HPC\n    settings (accurate modeling of slow start with correction factors on\n    three intervals: < 1KiB, < 64 KiB, >= 64 KiB). See also \\ref\n    options_model_network_coefs \"this section\" for more info.\n  - \\b IB: Realistic network model specifically tailored for HPC\n    settings with InfiniBand networks (accurate modeling contention\n    behavior, based on the model explained in\n    http://mescal.imag.fr/membres/jean-marc.vincent/index.html/PhD/Vienne.pdf).\n    See also \\ref options_model_network_coefs \"this section\" for more info.\n  - \\b CM02: Legacy network analytic model (Very similar to LV08, but\n    without corrective factors. The timings of small messages are thus\n    poorly modeled)\n  - \\b Reno: Model from Steven H. Low using lagrange_solve instead of\n    lmm_solve (experts only; check the code for more info).\n  - \\b Reno2: Model from Steven H. Low using lagrange_solve instead of\n    lmm_solve (experts only; check the code for more info).\n  - \\b Vegas: Model from Steven H. Low using lagrange_solve instead of\n    lmm_solve (experts only; check the code for more info).\n\nIf you compiled SimGrid accordingly, you can use packet-level network\nsimulators as network models (see \\ref pls_ns3). In that case, you have\ntwo extra models, described below, and some \n\\ref options_pls \"specific additional configuration flags\".\n  - \\b NS3: Network pseudo-model using the NS3 tcp model\n\nConcerning the CPU, we have only one model for now:\n  - \\b Cas01: Simplistic CPU model (time=size/power)\n\nThe host concept is the aggregation of a CPU with a network\ncard. Three models exists, but actually, only 2 of them are\ninteresting. The \"compound\" one is simply due to the way our internal\ncode is organized, and can easily be ignored. So at the end, you have\ntwo host models: The default one allows to aggregate an\nexisting CPU model with an existing network model, but does not allow\nparallel tasks because these beasts need some collaboration between\nthe network and CPU model. That is why, ptask_07 is used by default\nwhen using SimDag.\n  - \\b default: Default host model. Currently, CPU:Cas01 and\n    network:LV08 (with cross traffic enabled)\n  - \\b compound: Host model that is automatically chosen if\n    you change the network and CPU models\n  - \\b ptask_L07: Host model somehow similar to Cas01+CM02 but\n    allowing \"parallel tasks\", that are intended to model the moldable\n    tasks of the grid scheduling literature.\n\n\\subsection options_generic_plugin Plugins\n\nSimGrid plugins allow to extend the framework without changing its\nsource code directly. Read the source code of the existing plugins to\nlearn how to do so (in ``src/plugins``), and ask your questions to the\nusual channels (Stack Overflow, Mailing list, IRC). The basic idea is\nthat plugins usually register callbacks to some signals of interest.\nIf they need to store some information about a given object (Link, CPU\nor Actor), they do so through the use of a dedicated object extension.\n\nSome of the existing plugins can be activated from the command line,\nmeaning that you can activate them from the command line without any\nmodification to your simulation code. For example, you can activate\nthe host energy plugin by adding the following to your command line:\n\n\\verbatim\n    --cfg=plugin:host_energy\n\\endverbatim\n\nHere is the full list of plugins that can be activated this way:\n\n - \\b host_energy: keeps track of the energy dissipated by\n   computations. More details in @ref plugin_energy.\n - \\b link_energy: keeps track of the energy dissipated by\n   communications. More details in @ref SURF_plugin_energy.\n - \\b host_load: keeps track of the computational load. \n   More details in @ref plugin_load.\n\n\\subsection options_model_optim Optimization level of the platform models\n\nThe network and CPU models that are based on lmm_solve (that\nis, all our analytical models) accept specific optimization\nconfigurations.\n  - items \\b network/optim and \\b cpu/optim (both default to 'Lazy'):\n    - \\b Lazy: Lazy action management (partial invalidation in lmm +\n      heap in action remaining).\n    - \\b TI: Trace integration. Highly optimized mode when using\n      availability traces (only available for the Cas01 CPU model for\n      now).\n    - \\b Full: Full update of remaining and variables. Slow but may be\n      useful when debugging.\n  - items \\b network/maxmin-selective-update and\n    \\b cpu/maxmin-selective-update: configure whether the underlying\n    should be lazily updated or not. It should have no impact on the\n    computed timings, but should speed up the computation.\n\nIt is still possible to disable the \\c maxmin-selective-update feature\nbecause it can reveal counter-productive in very specific scenarios\nwhere the interaction level is high. In particular, if all your\ncommunication share a given backbone link, you should disable it:\nwithout \\c maxmin-selective-update, every communications are updated\nat each step through a simple loop over them. With that feature\nenabled, every communications will still get updated in this case\n(because of the dependency induced by the backbone), but through a\ncomplicated pattern aiming at following the actual dependencies.\n\n\\subsection options_model_precision Numerical precision of the platform models\n\nThe analytical models handle a lot of floating point values. It is\npossible to change the epsilon used to update and compare them through\nthe \\b maxmin/precision item (default value: 0.00001). Changing it\nmay speedup the simulation by discarding very small actions, at the\nprice of a reduced numerical precision.\n\n\\subsection options_concurrency_limit Concurrency limit\n\nThe maximum number of variables per resource can be tuned through\nthe \\b maxmin/concurrency-limit item. The default value is -1, meaning that\nthere is no such limitation. You can have as many simultaneous actions per\nresources as you want. If your simulation presents a very high level of\nconcurrency, it may help to use e.g. 100 as a value here. It means that at\nmost 100 actions can consume a resource at a given time. The extraneous actions\nare queued and wait until the amount of concurrency of the considered resource\nlowers under the given boundary.\n\nSuch limitations help both to the simulation speed and simulation accuracy\non highly constrained scenarios, but the simulation speed suffers of this\nsetting on regular (less constrained) scenarios so it is off by default.\n\n\\subsection options_model_network Configuring the Network model\n\n\\subsubsection options_model_network_gamma Maximal TCP window size\n\nThe analytical models need to know the maximal TCP window size to take\nthe TCP congestion mechanism into account. This is set to 4194304 by\ndefault, but can be changed using the \\b network/TCP-gamma item.\n\nOn linux, this value can be retrieved using the following\ncommands. Both give a set of values, and you should use the last one,\nwhich is the maximal size.\\verbatim\ncat /proc/sys/net/ipv4/tcp_rmem # gives the sender window\ncat /proc/sys/net/ipv4/tcp_wmem # gives the receiver window\n\\endverbatim\n\n\\subsubsection options_model_network_coefs Correcting important network parameters\n\nSimGrid can take network irregularities such as a slow startup or\nchanging behavior depending on the message size into account.\nYou should not change these values unless you really know what you're doing.\n\nThe corresponding values were computed through data fitting one the\ntimings of packet-level simulators.\n\nSee\n<a href=\"http://mescal.imag.fr/membres/arnaud.legrand/articles/simutools09.pdf\">Accuracy Study and Improvement of Network Simulation in the SimGrid Framework</a>\nfor more information about these parameters.\n\nIf you are using the SMPI model, these correction coefficients are\nthemselves corrected by constant values depending on the size of the\nexchange. Again, only hardcore experts should bother about this fact.\n\nInfiniBand network behavior can be modeled through 3 parameters, as explained in\n<a href=\"http://mescal.imag.fr/membres/jean-marc.vincent/index.html/PhD/Vienne.pdf\">this PhD thesis</a>.\nThese factors can be changed through the following option:\n\n\\verbatim\nsmpi/IB-penalty-factors:\"\u03b2e;\u03b2s;\u03b3s\"\n\\endverbatim\n\nBy default SMPI uses factors computed on the Stampede Supercomputer at TACC, with optimal\ndeployment of processes on nodes.\n\n\\subsubsection options_model_network_crosstraffic Simulating cross-traffic\n\nAs of SimGrid v3.7, cross-traffic effects can be taken into account in\nanalytical simulations. It means that ongoing and incoming\ncommunication flows are treated independently. In addition, the LV08\nmodel adds 0.05 of usage on the opposite direction for each new\ncreated flow. This can be useful to simulate some important TCP\nphenomena such as ack compression.\n\nFor that to work, your platform must have two links for each\npair of interconnected hosts. An example of usable platform is\navailable in <tt>examples/platforms/crosstraffic.xml</tt>.\n\nThis is activated through the \\b network/crosstraffic item, that\ncan be set to 0 (disable this feature) or 1 (enable it).\n\nNote that with the default host model this option is activated by default.\n\n\\subsubsection options_model_network_asyncsend Simulating asyncronous send\n\n(this configuration item is experimental and may change or disapear)\n\nIt is possible to specify that messages below a certain size will be sent\nas soon as the call to MPI_Send is issued, without waiting for the\ncorrespondant receive. This threshold can be configured through the\n\\b smpi/async-small-thresh item. The default value is 0. This behavior can also be\nmanually set for MSG mailboxes, by setting the receiving mode of the mailbox\nwith a call to \\ref MSG_mailbox_set_async . For MSG, all messages sent to this\nmailbox will have this behavior, so consider using two mailboxes if needed.\n\nThis value needs to be smaller than or equals to the threshold set at\n\\ref options_model_smpi_detached , because asynchronous messages are\nmeant to be detached as well.\n\n\\subsubsection options_pls Configuring packet-level pseudo-models\n\nWhen using the packet-level pseudo-models, several specific\nconfiguration flags are provided to configure the associated tools.\nThere is by far not enough such SimGrid flags to cover every aspects\nof the associated tools, since we only added the items that we\nneeded ourselves. Feel free to request more items (or even better:\nprovide patches adding more items).\n\nWhen using NS3, the only existing item is \\b ns3/TcpModel,\ncorresponding to the ns3::TcpL4Protocol::SocketType configuration item\nin NS3. The only valid values (enforced on the SimGrid side) are\n'NewReno' or 'Reno' or 'Tahoe'.\n\n\\subsection options_model_storage Configuring the Storage model\n\n\\subsubsection option_model_storage_maxfd Maximum amount of file descriptors per host\n\nEach host maintains a fixed-size array of its file descriptors. You\ncan change its size (1024 by default) through the \\b\nstorage/max_file_descriptors item to either enlarge it if your\napplication requires it or to reduce it to save memory space.\n\n\\section options_modelchecking Configuring the Model-Checking\n\nTo enable the SimGrid model-checking support the program should\nbe executed using the simgrid-mc wrapper:\n\\verbatim\nsimgrid-mc ./my_program\n\\endverbatim\n\nSafety properties are expressed as assertions using the function\n\\verbatim\nvoid MC_assert(int prop);\n\\endverbatim\n\n\\subsection options_modelchecking_liveness Specifying a liveness property\n\nIf you want to specify liveness properties (beware, that's\nexperimental), you have to pass them on the command line, specifying\nthe name of the file containing the property, as formatted by the\nltl2ba program.\n\n\\verbatim\n--cfg=model-check/property:<filename>\n\\endverbatim\n\n\\subsection options_modelchecking_steps Going for stateful verification\n\nBy default, the system is backtracked to its initial state to explore\nanother path instead of backtracking to the exact step before the fork\nthat we want to explore (this is called stateless verification). This\nis done this way because saving intermediate states can rapidly\nexhaust the available memory. If you want, you can change the value of\nthe <tt>model-check/checkpoint</tt> variable. For example, the\nfollowing configuration will ask to take a checkpoint every step.\nBeware, this will certainly explode your memory. Larger values are\nprobably better, make sure to experiment a bit to find the right\nsetting for your specific system.\n\n\\verbatim\n--cfg=model-check/checkpoint:1\n\\endverbatim\n\n\\subsection options_modelchecking_reduction Specifying the kind of reduction\n\nThe main issue when using the model-checking is the state space\nexplosion. To counter that problem, several exploration reduction\ntechniques can be used. There is unfortunately no silver bullet here,\nand the most efficient reduction techniques cannot be applied to any\nproperties. In particular, the DPOR method cannot be applied on\nliveness properties since it may break some cycles in the exploration\nthat are important to the property validity.\n\n\\verbatim\n--cfg=model-check/reduction:<technique>\n\\endverbatim\n\nFor now, this configuration variable can take 2 values:\n * none: Do not apply any kind of reduction (mandatory for now for\n   liveness properties)\n * dpor: Apply Dynamic Partial Ordering Reduction. Only valid if you\n   verify local safety properties (default value for safety checks).\n\n\\subsection options_modelchecking_visited model-check/visited, Cycle detection\n\nIn order to detect cycles, the model-checker needs to check if a new explored\nstate is in fact the same state than a previous one. For that,\nthe model-checker can take a snapshot of each visited state: this snapshot is\nthen used to compare it with subsequent states in the exploration graph.\n\nThe \\b model-check/visited option is the maximum number of states which are stored in\nmemory. If the maximum number of snapshotted state is reached, some states will\nbe removed from the memory and some cycles might be missed. Small\nvalues can lead to incorrect verifications, but large value can\nexhaust your memory, so choose carefully.\n\nBy default, no state is snapshotted and cycles cannot be detected.\n\n\\subsection options_modelchecking_termination model-check/termination, Non termination detection\n\nThe \\b model-check/termination configuration item can be used to report if a\nnon-termination execution path has been found. This is a path with a cycle\nwhich means that the program might never terminate.\n\nThis only works in safety mode.\n\nThis options is disabled by default.\n\n\\subsection options_modelchecking_dot_output model-check/dot-output, Dot output\n\nIf set, the \\b model-check/dot-output configuration item is the name of a file\nin which to write a dot file of the path leading the found property (safety or\nliveness violation) as well as the cycle for liveness properties. This dot file\ncan then fed to the graphviz dot tool to generate an corresponding graphical\nrepresentation.\n\n\\subsection options_modelchecking_max_depth model-check/max-depth, Depth limit\n\nThe \\b model-checker/max-depth can set the maximum depth of the exploration\ngraph of the model-checker. If this limit is reached, a logging message is\nsent and the results might not be exact.\n\nBy default, there is not depth limit.\n\n\\subsection options_modelchecking_timeout Handling of timeout\n\nBy default, the model-checker does not handle timeout conditions: the `wait`\noperations never time out. With the \\b model-check/timeout configuration item\nset to \\b yes, the model-checker will explore timeouts of `wait` operations.\n\n\\subsection options_modelchecking_comm_determinism Communication determinism\n\nThe \\b model-check/communications-determinism and\n\\b model-check/send-determinism items can be used to select the communication\ndeterminism mode of the model-checker which checks determinism properties of\nthe communications of an application.\n\n\\subsection options_modelchecking_sparse_checkpoint Per page checkpoints\n\nWhen the model-checker is configured to take a snapshot of each explored state\n(with the \\b model-checker/visited item), the memory consumption can rapidly\nreach GiB ou Tib of memory. However, for many workloads, the memory does not\nchange much between different snapshots and taking a complete copy of each\nsnapshot is a waste of memory.\n\nThe \\b model-check/sparse-checkpoint option item can be set to \\b yes in order\nto avoid making a complete copy of each snapshot: instead, each snapshot will be\ndecomposed in blocks which will be stored separately.\nIf multiple snapshots share the same block (or if the same block\nis used in the same snapshot), the same copy of the block will be shared leading\nto a reduction of the memory footprint.\n\nFor many applications, this option considerably reduces the memory consumption.\nIn somes cases, the model-checker might be slightly slower because of the time\ntaken to manage the metadata about the blocks. In other cases however, this\nsnapshotting strategy will be much faster by reducing the cache consumption.\nWhen the memory consumption is important, by avoiding to hit the swap or\nreducing the swap usage, this option might be much faster than the basic\nsnapshotting strategy.\n\nThis option is currently disabled by default.\n\n\\subsection options_mc_perf Performance considerations for the model checker\n\nThe size of the stacks can have a huge impact on the memory\nconsumption when using model-checking. By default, each snapshot will\nsave a copy of the whole stacks and not only of the part which is\nreally meaningful: you should expect the contribution of the memory\nconsumption of the snapshots to be \\f$ \\mbox{number of processes}\n\\times \\mbox{stack size} \\times \\mbox{number of states} \\f$.\n\nThe \\b model-check/sparse-checkpoint can be used to reduce the memory\nconsumption by trying to share memory between the different snapshots.\n\nWhen compiled against the model checker, the stacks are not\nprotected with guards: if the stack size is too small for your\napplication, the stack will silently overflow on other parts of the\nmemory (see \\ref options_virt_guard_size).\n\n\\subsection options_modelchecking_hash Hashing of the state (experimental)\n\nUsually most of the time of the model-checker is spent comparing states. This\nprocess is complicated and consumes a lot of bandwidth and cache.\nIn order to speedup the state comparison, the experimental \\b model-checker/hash\nconfiguration item enables the computation of a hash summarizing as much\ninformation of the state as possible into a single value. This hash can be used\nto avoid most of the comparisons: the costly comparison is then only used when\nthe hashes are identical.\n\nCurrently most of the state is not included in the hash because the\nimplementation was found to be buggy and this options is not as useful as\nit could be. For this reason, it is currently disabled by default.\n\n\\subsection options_modelchecking_recordreplay Record/replay (experimental)\n\nAs the model-checker keeps jumping at different places in the execution graph,\nit is difficult to understand what happens when trying to debug an application\nunder the model-checker. Event the output of the program is difficult to\ninterpret. Moreover, the model-checker does not behave nicely with advanced\ndebugging tools such as valgrind. For those reason, to identify a trajectory\nin the execution graph with the model-checker and replay this trajcetory and\nwithout the model-checker black-magic but with more standard tools\n(such as a debugger, valgrind, etc.). For this reason, Simgrid implements an\nexperimental record/replay functionnality in order to record a trajectory with\nthe model-checker and replay it without the model-checker.\n\nWhen the model-checker finds an interesting path in the application execution\ngraph (where a safety or liveness property is violated), it can generate an\nidentifier for this path. In order to enable this behavious the\n\\b model-check/record must be set to \\b yes. By default, this behaviour is not\nenabled.\n\nThis is an example of output:\n\n<pre>\n[  0.000000] (0:@) Check a safety property\n[  0.000000] (0:@) **************************\n[  0.000000] (0:@) *** PROPERTY NOT VALID ***\n[  0.000000] (0:@) **************************\n[  0.000000] (0:@) Counter-example execution trace:\n[  0.000000] (0:@) Path = 1/3;1/4\n[  0.000000] (0:@) [(1)Tremblay (app)] MC_RANDOM(3)\n[  0.000000] (0:@) [(1)Tremblay (app)] MC_RANDOM(4)\n[  0.000000] (0:@) Expanded states = 27\n[  0.000000] (0:@) Visited states = 68\n[  0.000000] (0:@) Executed transitions = 46\n</pre>\n\nThis path can then be replayed outside of the model-checker (and even in\nnon-MC build of simgrid) by setting the \\b model-check/replay item to the given\npath. The other options should be the same (but the model-checker should\nbe disabled).\n\nThe format and meaning of the path may change between different releases so\nthe same release of Simgrid should be used for the record phase and the replay\nphase.\n\n\\section options_virt Configuring the User Process Virtualization\n\n\\subsection options_virt_factory Selecting the virtualization factory\n\nIn SimGrid, the user code is virtualized in a specific mechanism\nthat allows the simulation kernel to control its execution: when a user\nprocess requires a blocking action (such as sending a message), it is\ninterrupted, and only gets released when the simulated clock reaches\nthe point where the blocking operation is done. This is explained\ngraphically in the [relevant tutorial, available online](http://simgrid.gforge.inria.fr/tutorials/simgrid-simix-101.pdf).\n\nIn SimGrid, the containers in which user processes are virtualized are\ncalled contexts. Several context factory are provided, and you can\nselect the one you want to use with the \\b contexts/factory\nconfiguration item. Some of the following may not exist on your\nmachine because of portability issues. In any case, the default one\nshould be the most effcient one (please report bugs if the\nauto-detection fails for you). They are approximately sorted here from\nthe slowest to the most efficient:\n\n - \\b thread: very slow factory using full featured threads (either\n   pthreads or windows native threads). They are slow but very\n   standard. Some debuggers or profilers only work with this factory.\n - \\b java: Java applications are virtualized onto java threads (that\n   are regular pthreads registered to the JVM)\n - \\b ucontext: fast factory using System V contexts (Linux and FreeBSD only)\n - \\b boost: This uses the [context implementation](http://www.boost.org/doc/libs/1_59_0/libs/context/doc/html/index.html)\n   of the boost library for a performance that is comparable to our\n   raw implementation.\\n Install the relevant library (e.g. with the\n   libboost-contexts-dev package on Debian/Ubuntu) and recompile\n   SimGrid. Note that our implementation is not compatible with recent\n   implementations of the library, and it will be hard to fix this since\n   the library's author decided to hide an API that we were using.\n - \\b raw: amazingly fast factory using a context switching mechanism\n   of our own, directly implemented in assembly (only available for x86\n   and amd64 platforms for now) and without any unneeded system call.\n\nThe main reason to change this setting is when the debugging tools get\nfooled by the optimized context factories. Threads are the most\ndebugging-friendly contextes, as they allow to set breakpoints\nanywhere with gdb and visualize backtraces for all processes, in order\nto debug concurrency issues. Valgrind is also more comfortable with\nthreads, but it should be usable with all factories (but the callgrind\ntool that really don't like raw and ucontext factories).\n\n\\subsection options_virt_stacksize Adapting the used stack size\n\nEach virtualized used process is executed using a specific system\nstack. The size of this stack has a huge impact on the simulation\nscalability, but its default value is rather large. This is because\nthe error messages that you get when the stack size is too small are\nrather disturbing: this leads to stack overflow (overwriting other\nstacks), leading to segfaults with corrupted stack traces.\n\nIf you want to push the scalability limits of your code, you might\nwant to reduce the \\b contexts/stack-size item. Its default value\nis 8192 (in KiB), while our Chord simulation works with stacks as small\nas 16 KiB, for example. For the thread factory, the default value\nis the one of the system but you can still change it with this parameter.\n\nThe operating system should only allocate memory for the pages of the\nstack which are actually used and you might not need to use this in\nmost cases. However, this setting is very important when using the\nmodel checker (see \\ref options_mc_perf).\n\n\\subsection options_virt_guard_size Disabling stack guard pages\n\nA stack guard page is usually used which prevents the stack of a given\nactor from overflowing on another stack. But the performance impact\nmay become prohibitive when the amount of actors increases.  The\noption \\b contexts:guard-size is the number of stack guard pages used.\nBy setting it to 0, no guard pages will be used: in this case, you\nshould avoid using small stacks (\\b stack-size) as the stack will\nsilently overflow on other parts of the memory.\n\nWhen no stack guard page is created, stacks may then silently overflow\non other parts of the memory if their size is too small for the\napplication. This happens:\n\n- on Windows systems;\n- when the model checker is enabled;\n- and of course when guard pages are explicitely disabled (with \\b contexts:guard-size=0).\n\n\\subsection options_virt_parallel Running user code in parallel\n\nParallel execution of the user code is only considered stable in\nSimGrid v3.7 and higher, and mostly for MSG simulations. SMPI\nsimulations may well fail in parallel mode. It is described in\n<a href=\"http://hal.inria.fr/inria-00602216/\">INRIA RR-7653</a>.\n\nIf you are using the \\c ucontext or \\c raw context factories, you can\nrequest to execute the user code in parallel. Several threads are\nlaunched, each of them handling as much user contexts at each run. To\nactiave this, set the \\b contexts/nthreads item to the amount of\ncores that you have in your computer (or lower than 1 to have\nthe amount of cores auto-detected).\n\nEven if you asked several worker threads using the previous option,\nyou can request to start the parallel execution (and pay the\nassociated synchronization costs) only if the potential parallelism is\nlarge enough. For that, set the \\b contexts/parallel-threshold\nitem to the minimal amount of user contexts needed to start the\nparallel execution. In any given simulation round, if that amount is\nnot reached, the contexts will be run sequentially directly by the\nmain thread (thus saving the synchronization costs). Note that this\noption is mainly useful when the grain of the user code is very fine,\nbecause our synchronization is now very efficient.\n\nWhen parallel execution is activated, you can choose the\nsynchronization schema used with the \\b contexts/synchro item,\nwhich value is either:\n - \\b futex: ultra optimized synchronisation schema, based on futexes\n   (fast user-mode mutexes), and thus only available on Linux systems.\n   This is the default mode when available.\n - \\b posix: slow but portable synchronisation using only POSIX\n   primitives.\n - \\b busy_wait: not really a synchronisation: the worker threads\n   constantly request new contexts to execute. It should be the most\n   efficient synchronisation schema, but it loads all the cores of your\n   machine for no good reason. You probably prefer the other less\n   eager schemas.\n\n\\section options_tracing Configuring the tracing subsystem\n\nThe \\ref outcomes_vizu \"tracing subsystem\" can be configured in several\ndifferent ways depending on the nature of the simulator (MSG, SimDag,\nSMPI) and the kind of traces that need to be obtained. See the \\ref\ntracing_tracing_options \"Tracing Configuration Options subsection\" to\nget a detailed description of each configuration option.\n\nWe detail here a simple way to get the traces working for you, even if\nyou never used the tracing API.\n\n\n- Any SimGrid-based simulator (MSG, SimDag, SMPI, ...) and raw traces:\n\\verbatim\n--cfg=tracing:yes --cfg=tracing/uncategorized:yes --cfg=triva/uncategorized:uncat.plist\n\\endverbatim\n    The first parameter activates the tracing subsystem, the second\n    tells it to trace host and link utilization (without any\n    categorization) and the third creates a graph configuration file\n    to configure Triva when analysing the resulting trace file.\n\n- MSG or SimDag-based simulator and categorized traces (you need to declare categories and classify your tasks according to them)\n\\verbatim\n--cfg=tracing:yes --cfg=tracing/categorized:yes --cfg=triva/categorized:cat.plist\n\\endverbatim\n    The first parameter activates the tracing subsystem, the second\n    tells it to trace host and link categorized utilization and the\n    third creates a graph configuration file to configure Triva when\n    analysing the resulting trace file.\n\n- SMPI simulator and traces for a space/time view:\n\\verbatim\nsmpirun -trace ...\n\\endverbatim\n    The <i>-trace</i> parameter for the smpirun script runs the\nsimulation with --cfg=tracing:yes and --cfg=tracing/smpi:yes. Check the\nsmpirun's <i>-help</i> parameter for additional tracing options.\n\nSometimes you might want to put additional information on the trace to\ncorrectly identify them later, or to provide data that can be used to\nreproduce an experiment. You have two ways to do that:\n\n- Add a string on top of the trace file as comment:\n\\verbatim\n--cfg=tracing/comment:my_simulation_identifier\n\\endverbatim\n\n- Add the contents of a textual file on top of the trace file as comment:\n\\verbatim\n--cfg=tracing/comment-file:my_file_with_additional_information.txt\n\\endverbatim\n\nPlease, use these two parameters (for comments) to make reproducible\nsimulations. For additional details about this and all tracing\noptions, check See the \\ref tracing_tracing_options.\n\n\\section options_msg Configuring MSG\n\n\\subsection options_msg_debug_multiple_use Debugging MSG\n\nSometimes your application may try to send a task that is still being\nexecuted somewhere else, making it impossible to send this task. However,\nfor debugging purposes, one may want to know what the other host is/was\ndoing. This option shows a backtrace of the other process.\n\nEnable this option by adding\n\n\\verbatim\n--cfg=msg/debug-multiple-use:on\n\\endverbatim\n\n\\section options_smpi Configuring SMPI\n\nThe SMPI interface provides several specific configuration items.\nThese are uneasy to see since the code is usually launched through the\n\\c smiprun script directly.\n\n\\subsection options_smpi_bench smpi/bench: Automatic benchmarking of SMPI code\n\nIn SMPI, the sequential code is automatically benchmarked, and these\ncomputations are automatically reported to the simulator. That is to\nsay that if you have a large computation between a \\c MPI_Recv() and a\n\\c MPI_Send(), SMPI will automatically benchmark the duration of this\ncode, and create an execution task within the simulator to take this\ninto account. For that, the actual duration is measured on the host\nmachine and then scaled to the power of the corresponding simulated\nmachine. The variable \\b smpi/host-speed allows to specify the\ncomputational speed of the host machine (in flop/s) to use when\nscaling the execution times. It defaults to 20000, but you really want\nto update it to get accurate simulation results.\n\nWhen the code is constituted of numerous consecutive MPI calls, the\nprevious mechanism feeds the simulation kernel with numerous tiny\ncomputations. The \\b smpi/cpu-threshold item becomes handy when this\nimpacts badly the simulation performance. It specifies a threshold (in\nseconds) below which the execution chunks are not reported to the\nsimulation kernel (default value: 1e-6).\n\n\\note\n    The option smpi/cpu-threshold ignores any computation time spent\n    below this threshold. SMPI does not consider the \\a amount of these\n    computations; there is no offset for this. Hence, by using a\n    value that is too low, you may end up with unreliable simulation\n    results.\n\nIn some cases, however, one may wish to disable simulation of\napplication computation. This is the case when SMPI is used not to\nsimulate an MPI applications, but instead an MPI code that performs\n\"live replay\" of another MPI app (e.g., ScalaTrace's replay tool,\nvarious on-line simulators that run an app at scale). In this case the\ncomputation of the replay/simulation logic should not be simulated by\nSMPI. Instead, the replay tool or on-line simulator will issue\n\"computation events\", which correspond to the actual MPI simulation\nbeing replayed/simulated. At the moment, these computation events can\nbe simulated using SMPI by calling internal smpi_execute*() functions.\n\nTo disable the benchmarking/simulation of computation in the simulated\napplication, the variable \\b smpi/simulate-computation should be set to no.\n\n\\note\n    This option just ignores the timings in your simulation; it still executes\n    the computations itself. If you want to stop SMPI from doing that,\n    you should check the SMPI_SAMPLE macros, documented in the section\n    \\ref SMPI_adapting_speed.\n\nSolution                           | Computations actually executed? | Computations simulated ?\n---------------------------------- | ------------------------------- | ------------------------\n--cfg=smpi/simulate-computation:no | Yes                             | No, never\n--cfg=smpi/cpu-threshold:42        | Yes, in all cases               | Only if it lasts more than 42 seconds\nSMPI_SAMPLE() macro                | Only once per loop nest (see @ref SMPI_adapting_speed \"documentation\") | Always\n\n\\subsection options_model_smpi_adj_file smpi/comp-adjustment-file: Slow-down or speed-up parts of your code.\n\nThis option allows you to pass a file that contains two columns: The first column\ndefines the section that will be subject to a speedup; the second column is the speedup.\n\nFor instance:\n\n\\verbatim\n\"start:stop\",\"ratio\"\n\"exchange_1.f:30:exchange_1.f:130\",1.18244559422142\n\\endverbatim\n\nThe first line is the header - you must include it.\nThe following line means that the code between two consecutive MPI calls on\nline 30 in exchange_1.f and line 130 in exchange_1.f should receive a speedup\nof 1.18244559422142. The value for the second column is therefore a speedup, if it is\nlarger than 1 and a slow-down if it is smaller than 1. Nothing will be changed if it is\nequal to 1.\n\nOf course, you can set any arbitrary filenames you want (so the start and end don't have to be\nin the same file), but be aware that this mechanism only supports @em consecutive calls!\n\n\\note\n    Please note that you must pass the \\b -trace-call-location flag to smpicc\n    or smpiff, respectively! This flag activates some macro definitions in our\n    mpi.h / mpi.f files that help with obtaining the call location.\n\n\\subsection options_model_smpi_bw_factor smpi/bw-factor: Bandwidth factors\n\nThe possible throughput of network links is often dependent on the\nmessage sizes, as protocols may adapt to different message sizes. With\nthis option, a series of message sizes and factors are given, helping\nthe simulation to be more realistic. For instance, the current\ndefault value is\n\n\\verbatim\n65472:0.940694;15424:0.697866;9376:0.58729;5776:1.08739;3484:0.77493;1426:0.608902;732:0.341987;257:0.338112;0:0.812084\n\\endverbatim\n\nSo, messages with size 65472 and more will get a total of MAX_BANDWIDTH*0.940694,\nmessages of size 15424 to 65471 will get MAX_BANDWIDTH*0.697866 and so on.\nHere, MAX_BANDWIDTH denotes the bandwidth of the link.\n\n\\note\n    The SimGrid-Team has developed a script to help you determine these\n    values. You can find more information and the download here:\n    1. http://simgrid.gforge.inria.fr/contrib/smpi-calibration-doc.html\n    2. http://simgrid.gforge.inria.fr/contrib/smpi-saturation-doc.html\n\n\\subsection options_smpi_timing smpi/display-timing: Reporting simulation time\n\n\\b Default: 0 (false)\n\nMost of the time, you run MPI code with SMPI to compute the time it\nwould take to run it on a platform. But since the\ncode is run through the \\c smpirun script, you don't have any control\non the launcher code, making it difficult to report the simulated time\nwhen the simulation ends. If you set the \\b smpi/display-timing item\nto 1, \\c smpirun will display this information when the simulation ends. \\verbatim\nSimulation time: 1e3 seconds.\n\\endverbatim\n\n\\subsection options_smpi_temps smpi/keep-temps: not cleaning up after simulation\n\n\\b Default: 0 (false)\n\nUnder some conditions, SMPI generates a lot of temporary files.  They\nusually get cleaned, but you may use this option to not erase these\nfiles. This is for example useful when debugging or profiling\nexecutions using the dlopen privatization schema, as missing binary\nfiles tend to fool the debuggers.\n\n\\subsection options_model_smpi_lat_factor smpi/lat-factor: Latency factors\n\nThe motivation and syntax for this option is identical to the motivation/syntax\nof smpi/bw-factor, see \\ref options_model_smpi_bw_factor for details.\n\nThere is an important difference, though: While smpi/bw-factor \\a reduces the\nactual bandwidth (i.e., values between 0 and 1 are valid), latency factors\nincrease the latency, i.e., values larger than or equal to 1 are valid here.\n\nThis is the default value:\n\n\\verbatim\n65472:11.6436;15424:3.48845;9376:2.59299;5776:2.18796;3484:1.88101;1426:1.61075;732:1.9503;257:1.95341;0:2.01467\n\\endverbatim\n\n\\note\n    The SimGrid-Team has developed a script to help you determine these\n    values. You can find more information and the download here:\n    1. http://simgrid.gforge.inria.fr/contrib/smpi-calibration-doc.html\n    2. http://simgrid.gforge.inria.fr/contrib/smpi-saturation-doc.html\n\n\\subsection options_smpi_papi_events smpi/papi-events: Trace hardware counters with PAPI\n\n\\warning \n    This option is experimental and will be subject to change.\n    This feature currently requires superuser privileges, as registers are queried.\n    Only use this feature with code you trust! Call smpirun for instance via\n        smpirun -wrapper \"sudo \" <your-parameters>\n    or run sudo sh -c \"echo 0 > /proc/sys/kernel/perf_event_paranoid\"\n    In the later case, sudo will not be required.\n\n\\note\n    This option is only available when SimGrid was compiled with PAPI support.\n\nThis option takes the names of PAPI counters and adds their respective values\nto the trace files. (See Section \\ref tracing_tracing_options.)\n\nIt is planned to make this feature available on a per-process (or per-thread?) basis.\nThe first draft, however, just implements a \"global\" (i.e., for all processes) set\nof counters, the \"default\" set.\n\n\\verbatim\n--cfg=smpi/papi-events:\"default:PAPI_L3_LDM:PAPI_L2_LDM\"\n\\endverbatim\n\n\\subsection options_smpi_privatization smpi/privatization: Automatic privatization of global variables\n\nMPI executables are usually meant to be executed in separated\nprocesses, but SMPI is executed in only one process. Global variables\nfrom executables will be placed in the same memory zone and shared\nbetween processes, causing intricate bugs.  Several options are\npossible to avoid this, as described in the main\n<a href=\"https://hal.inria.fr/hal-01415484\">SMPI publication</a> and in\nthe @ref SMPI_what_globals \"SMPI documentation\". SimGrid provides two\nways of automatically privatizing the globals, and this option allows\nto choose between them.\n\n  - <b>no</b> (default when not using smpirun): Do not automatically privatize variables.\n    Pass \\c -no-privatize to smpirun to disable this feature.\n  - <b>dlopen</b> or <b>yes</b> (default when using smpirun): Link multiple times against the binary.\n  - <b>mmap</b> (slower, but maybe somewhat more stable):\n    Runtime automatic switching of the data segments.\n\n\\warning\n  This configuration option cannot be set in your platform file. You can only\n  pass it as an argument to smpirun.\n  \n\\subsection options_smpi_privatize_libs smpi/privatize-libs: Automatic privatization of\n global variables inside external libraries\n\nLinux/BSD only: When using dlopen (default) privatization, privatize specific \nshared libraries with internal global variables, if they can't be linked statically. \nFor example libgfortran is usually used for Fortran I/O and indexes in files \ncan be mixed up.\n\n\\warning\n  This configuration option can only use either full paths to libraries, or full names.\n  Check with ldd the name of the library you want to use.\n  Example:\n  ldd allpairf90 \n    libgfortran.so.3 => /usr/lib/x86_64-linux-gnu/libgfortran.so.3 (0x00007fbb4d91b000)\n  Then you can use --cfg=smpi/privatize-libs:\"libgfortran.so.3\" or --cfg=smpi/privatize-libs:\"/usr/lib/x86_64-linux-gnu/libgfortran.so.3\", but not \"libgfortran\" or \"libgfortran.so\".\n  Multiple libraries can be given, semicolon separated.\n\n\n\\subsection options_model_smpi_detached Simulating MPI detached send\n\nThis threshold specifies the size in bytes under which the send will return\nimmediately. This is different from the threshold detailed in  \\ref options_model_network_asyncsend\nbecause the message is not effectively sent when the send is posted. SMPI still waits for the\ncorrespondant receive to be posted to perform the communication operation. This threshold can be set\nby changing the \\b smpi/send-is-detached-thresh item. The default value is 65536.\n\n\\subsection options_model_smpi_collectives Simulating MPI collective algorithms\n\nSMPI implements more than 100 different algorithms for MPI collective communication, to accurately\nsimulate the behavior of most of the existing MPI libraries. The \\b smpi/coll-selector item can be used\n to use the decision logic of either OpenMPI or MPICH libraries (values: ompi or mpich, by default SMPI\nuses naive version of collective operations). Each collective operation can be manually selected with a\n\\b smpi/collective_name:algo_name. Available algorithms are listed in \\ref SMPI_use_colls .\n\n\\subsection options_model_smpi_iprobe smpi/iprobe: Inject constant times for calls to MPI_Iprobe\n\n\\b Default value: 0.0001\n\nThe behavior and motivation for this configuration option is identical with \\a smpi/test, see\nSection \\ref options_model_smpi_test for details.\n\n\\subsection options_model_smpi_iprobe_cpu_usage smpi/iprobe-cpu-usage: Reduce speed for iprobe calls\n\n\\b Default value: 1 (no change from default behavior)\n\nMPI_Iprobe calls can be heavily used in applications. To account correctly for the energy\ncores spend probing, it is necessary to reduce the load that these calls cause inside\nSimGrid.\n\nFor instance, we measured a max power consumption of 220 W for a particular application but \nonly 180 W while this application was probing. Hence, the correct factor that should\nbe passed to this option would be 180/220 = 0.81.\n\n\\subsection options_model_smpi_init smpi/init: Inject constant times for calls to MPI_Init\n\n\\b Default value: 0\n\nThe behavior for this configuration option is identical with \\a smpi/test, see\nSection \\ref options_model_smpi_test for details.\n\n\\subsection options_model_smpi_ois smpi/ois: Inject constant times for asynchronous send operations\n\nThis configuration option works exactly as \\a smpi/os, see Section \\ref options_model_smpi_os.\nOf course, \\a smpi/ois is used to account for MPI_Isend instead of MPI_Send.\n\n\\subsection options_model_smpi_os smpi/os: Inject constant times for send operations\n\nIn several network models such as LogP, send (MPI_Send, MPI_Isend) and receive (MPI_Recv)\noperations incur costs (i.e., they consume CPU time). SMPI can factor these costs in as well, but the\nuser has to configure SMPI accordingly as these values may vary by machine.\nThis can be done by using smpi/os for MPI_Send operations; for MPI_Isend and\nMPI_Recv, use \\a smpi/ois and \\a smpi/or, respectively. These work exactly as\n\\a smpi/ois.\n\n\\a smpi/os can consist of multiple sections; each section takes three values, for example:\n\n\\verbatim\n    1:3:2;10:5:1\n\\endverbatim\n\nHere, the sections are divided by \";\" (that is, this example contains two sections).\nFurthermore, each section consists of three values.\n\n1. The first value denotes the minimum size for this section to take effect;\n   read it as \"if message size is greater than this value (and other section has a larger\n   first value that is also smaller than the message size), use this\".\n   In the first section above, this value is \"1\".\n\n2. The second value is the startup time; this is a constant value that will always\n   be charged, no matter what the size of the message. In the first section above,\n   this value is \"3\".\n\n3. The third value is the \\a per-byte cost. That is, it is charged for every\n   byte of the message (incurring cost messageSize*cost_per_byte)\n   and hence accounts also for larger messages. In the first\n   section of the example above, this value is \"2\".\n\nNow, SMPI always checks which section it should take for a given message; that is,\nif a message of size 11 is sent with the configuration of the example above, only\nthe second section will be used, not the first, as the first value of the second\nsection is closer to the message size. Hence, a message of size 11 incurs the\nfollowing cost inside MPI_Send:\n\n\\verbatim\n    5+11*1\n\\endverbatim\n\nAs 5 is the startup cost and 1 is the cost per byte.\n\n\\note\n    The order of sections can be arbitrary; they will be ordered internally.\n\n\\subsection options_model_smpi_or smpi/or: Inject constant times for receive operations\n\nThis configuration option works exactly as \\a smpi/os, see Section \\ref options_model_smpi_os.\nOf course, \\a smpi/or is used to account for MPI_Recv instead of MPI_Send.\n\n\\subsection options_model_smpi_test smpi/test: Inject constant times for calls to MPI_Test\n\n\\b Default value: 0.0001\n\nBy setting this option, you can control the amount of time a process sleeps\nwhen MPI_Test() is called; this is important, because SimGrid normally only\nadvances the time while communication is happening and thus,\nMPI_Test will not add to the time, resulting in a deadlock if used as a\nbreak-condition.\n\nHere is an example:\n\n\\code{.unparsed}\n    while(!flag) {\n        MPI_Test(request, flag, status);\n        ...\n    }\n\\endcode\n\n\\note\n    Internally, in order to speed up execution, we use a counter to keep track\n    on how often we already checked if the handle is now valid or not. Hence, we\n    actually use counter*SLEEP_TIME, that is, the time MPI_Test() causes the process\n    to sleep increases linearly with the number of previously failed tests. This \n    behavior can be disabled by setting smpi/grow-injected-times to no. This will\n    also disable this behavior for MPI_Iprobe.\n\n\n\\subsection options_model_smpi_shared_malloc smpi/shared-malloc: Factorize malloc()s\n\n\\b Default: global\n\nIf your simulation consumes too much memory, you may want to modify\nyour code so that the working areas are shared by all MPI ranks. For\nexample, in a bloc-cyclic matrix multiplication, you will only\nallocate one set of blocs, and every processes will share them.\nNaturally, this will lead to very wrong results, but this will save a\nlot of memory so this is still desirable for some studies. For more on\nthe motivation for that feature, please refer to the \n<a href=\"https://simgrid.github.io/SMPI_CourseWare/topic_understanding_performance/matrixmultiplication/\">relevant\nsection</a> of the SMPI CourseWare (see Activity #2.2 of the pointed\nassignment). In practice, change the call to malloc() and free() into\nSMPI_SHARED_MALLOC() and SMPI_SHARED_FREE().\n\nSMPI provides 2 algorithms for this feature. The first one, called \\c\nlocal, allocates one bloc per call to SMPI_SHARED_MALLOC() in your\ncode (each call location gets its own bloc) and this bloc is shared\namongst all MPI ranks.  This is implemented with the shm_* functions\nto create a new POSIX shared memory object (kept in RAM, in /dev/shm)\nfor each shared bloc.\n\nWith the \\c global algorithm, each call to SMPI_SHARED_MALLOC()\nreturns a new adress, but it only points to a shadow bloc: its memory\narea is mapped on a 1MiB file on disk. If the returned bloc is of size\nN MiB, then the same file is mapped N times to cover the whole bloc. \nAt the end, no matter how many SMPI_SHARED_MALLOC you do, this will\nonly consume 1 MiB in memory. \n\nYou can disable this behavior and come back to regular mallocs (for\nexample for debugging purposes) using \\c \"no\" as a value.\n\nIf you want to keep private some parts of the buffer, for instance if these\nparts are used by the application logic and should not be corrupted, you\ncan use SMPI_PARTIAL_SHARED_MALLOC(size, offsets, offsets_count).\n\nAs an example,\n\n\\code{.C}\n    mem = SMPI_PARTIAL_SHARED_MALLOC(500, {27,42 , 100,200}, 2);\n\\endcode\n\nwill allocate 500 bytes to mem, such that mem[27..41] and mem[100..199]\nare shared and other area remain private.\n\nThen, it can be deallocated by calling SMPI_SHARED_FREE(mem).\n\nWhen smpi/shared-malloc:global is used, the memory consumption problem\nis solved, but it may induce too much load on the kernel's pages table. \nIn this case, you should use huge pages so that we create only one\nentry per Mb of malloced data instead of one entry per 4k.\nTo activate this, you must mount a hugetlbfs on your system and allocate\nat least one huge page:\n\n\\code{.sh}\n    mkdir /home/huge\n    sudo mount none /home/huge -t hugetlbfs -o rw,mode=0777\n    sudo sh -c 'echo 1 > /proc/sys/vm/nr_hugepages' # echo more if you need more\n\\endcode\n\nThen, you can pass the option --cfg=smpi/shared-malloc-hugepage:/home/huge\nto smpirun to actually activate the huge page support in shared mallocs.\n\n\\subsection options_model_smpi_wtime smpi/wtime: Inject constant times for calls to MPI_Wtime\n\n\\b Default value: 0\n\nBy setting this option, you can control the amount of time a process sleeps\nwhen MPI_Wtime() is called; this is important, because SimGrid normally only\nadvances the time while communication is happening and thus,\nMPI_Wtime will not add to the time, resulting in a deadlock if used as a\nbreak-condition.\n\nHere is an example:\n\n\\code{.unparsed}\n    while(MPI_Wtime() < some_time_bound) {\n        ...\n    }\n\\endcode\n\nIf the time is never advanced, this loop will clearly never end as MPI_Wtime()\nalways returns the same value. Hence, pass a (small) value to the smpi/wtime\noption to force a call to MPI_Wtime to advance the time as well.\n\n\n\\section options_generic Configuring other aspects of SimGrid\n\n\\subsection options_generic_clean_atexit Cleanup before termination\n\nThe C / C++ standard contains a function called \\b [atexit](http://www.cplusplus.com/reference/cstdlib/atexit/).\natexit registers callbacks, which are called just before the program terminates.\n\nBy setting the configuration option clean-atexit to 1 (true), a callback\nis registered and will clean up some variables and terminate/cleanup the tracing.\n\nTODO: Add when this should be used.\n\n\\subsection options_generic_path Profile files' search path\n\nIt is possible to specify a list of directories to search into for the\ntrace files (see @ref pf_trace) by using the \\b path configuration\nitem. To add several directory to the path, set the configuration\nitem several times, as in \\verbatim\n--cfg=path:toto --cfg=path:tutu\n\\endverbatim\n\n\\subsection options_generic_breakpoint Set a breakpoint\n\n\\verbatim\n--cfg=simix/breakpoint:3.1416\n\\endverbatim\n\nThis configuration option sets a breakpoint: when the simulated clock reaches\nthe given time, a SIGTRAP is raised.  This can be used to stop the execution and\nget a backtrace with a debugger.\n\nIt is also possible to set the breakpoint from inside the debugger, by writing\nin global variable simgrid::simix::breakpoint. For example, with gdb:\n\n\\verbatim\nset variable simgrid::simix::breakpoint = 3.1416\n\\endverbatim\n\n\\subsection options_generic_exit Behavior on Ctrl-C\n\nBy default, when Ctrl-C is pressed, the status of all existing\nsimulated processes is displayed before exiting the simulation. This is very useful to debug your\ncode, but it can reveal troublesome in some cases (such as when the\namount of processes becomes really big). This behavior is disabled\nwhen \\b verbose-exit is set to 0 (it is to 1 by default).\n\n\\subsection options_exception_cutpath Truncate local path from exception backtrace\n\n\\verbatim\n--cfg=exception/cutpath:1\n\\endverbatim\n\nThis configuration option is used to remove the path from the\nbacktrace shown when an exception is thrown. This is mainly useful for\nthe tests: the full file path makes the tests not reproducible, and\nthus failing as we are currently comparing output. Clearly, the path\nused on different machines are almost guaranteed to be different and\nhence, the output would mismatch, causing the test to fail.\n\n\\section options_log Logging Configuration\n\nIt can be done by using XBT. Go to \\ref XBT_log for more details.\n\n*/\n"
    },
    "skipped": [
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.20-xigfpbo5yypiin5odq3dedwvkyxa5sxr/spack-src/doc/surf++.png",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.20-xigfpbo5yypiin5odq3dedwvkyxa5sxr/spack-src/doc/triva-time_interval.png",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.20-xigfpbo5yypiin5odq3dedwvkyxa5sxr/spack-src/doc/triva-graph_visualization.png",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.20-xigfpbo5yypiin5odq3dedwvkyxa5sxr/spack-src/doc/surf++.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.20-xigfpbo5yypiin5odq3dedwvkyxa5sxr/spack-src/doc/triva-graph_configuration.png",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.20-xigfpbo5yypiin5odq3dedwvkyxa5sxr/spack-src/doc/sc3-description.png",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.20-xigfpbo5yypiin5odq3dedwvkyxa5sxr/spack-src/doc/webcruft/Paje_MSG_screenshot_thn.jpg",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.20-xigfpbo5yypiin5odq3dedwvkyxa5sxr/spack-src/doc/webcruft/smpi_simgrid_alltoall_pair_16.png",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.20-xigfpbo5yypiin5odq3dedwvkyxa5sxr/spack-src/doc/webcruft/storage_sample_scenario.png",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.20-xigfpbo5yypiin5odq3dedwvkyxa5sxr/spack-src/doc/webcruft/output.goal.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.20-xigfpbo5yypiin5odq3dedwvkyxa5sxr/spack-src/doc/webcruft/smpi_simgrid_alltoall_ring_16.png",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.20-xigfpbo5yypiin5odq3dedwvkyxa5sxr/spack-src/doc/webcruft/Paje_MSG_screenshot.jpg",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.20-xigfpbo5yypiin5odq3dedwvkyxa5sxr/spack-src/doc/webcruft/AS_hierarchy.png",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.20-xigfpbo5yypiin5odq3dedwvkyxa5sxr/spack-src/doc/webcruft/SGicon.gif",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.20-xigfpbo5yypiin5odq3dedwvkyxa5sxr/spack-src/doc/webcruft/eclipseScreenShot.png",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.20-xigfpbo5yypiin5odq3dedwvkyxa5sxr/spack-src/doc/webcruft/SGicon.icns",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.20-xigfpbo5yypiin5odq3dedwvkyxa5sxr/spack-src/doc/webcruft/SGicon.ico",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.20-xigfpbo5yypiin5odq3dedwvkyxa5sxr/spack-src/doc/webcruft/awstats_logo3.png",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.20-xigfpbo5yypiin5odq3dedwvkyxa5sxr/spack-src/doc/webcruft/simgrid_logo_2011.png",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.20-xigfpbo5yypiin5odq3dedwvkyxa5sxr/spack-src/doc/webcruft/simgrid_logo_2011.gif",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.20-xigfpbo5yypiin5odq3dedwvkyxa5sxr/spack-src/doc/webcruft/poster_thumbnail.png",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.20-xigfpbo5yypiin5odq3dedwvkyxa5sxr/spack-src/doc/webcruft/simgrid_logo_2011_small.png",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.20-xigfpbo5yypiin5odq3dedwvkyxa5sxr/spack-src/doc/webcruft/simgrid_logo_win.bmp",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.20-xigfpbo5yypiin5odq3dedwvkyxa5sxr/spack-src/doc/webcruft/simgrid_logo_win_2011.bmp"
    ],
    "total_files": 2455
}