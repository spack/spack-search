{
    "matches": {
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.21-2jw7hfw3ki7yfy6d52vbzhst6fypdxym/spack-src/CMakeLists.txt": "cmake_minimum_required(VERSION 2.8.8)\nmessage(STATUS \"Cmake version ${CMAKE_MAJOR_VERSION}.${CMAKE_MINOR_VERSION}.${CMAKE_PATCH_VERSION}\")\nset(CMAKE_MODULE_PATH ${CMAKE_MODULE_PATH} ${CMAKE_HOME_DIRECTORY}/tools/cmake/Modules)\n\nproject(SimGrid C CXX)\n\n#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#\n#     Check for the compiler        #\n#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#\n\n### Need to set rc ccompiler before enable language\nif(WIN32)\n  SET(CMAKE_RC_COMPILER \"windres\")\nendif()\n\n## \n## Check the C/C++ standard that we need\n##   See also tools/cmake/GCCFlags.cmake that sets our paranoid warning flags\nINCLUDE(CheckCCompilerFlag)\nCHECK_C_COMPILER_FLAG(-fstack-cleaner HAVE_C_STACK_CLEANER)\n\n## Request full debugging flags\nset(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} -g3\")\nset(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -g3\")\nset(CMAKE_Fortran_FLAGS \"${CMAKE_Fortran_FLAGS} -g\")\n\nif (CMAKE_COMPILER_IS_GNUCC)    \n  if (CMAKE_CXX_COMPILER_VERSION VERSION_LESS \"4.7\")\n    message(FATAL_ERROR\n            \"SimGrid needs at least g++ version 4.7 to compile but you have ${CMAKE_CXX_COMPILER_VERSION}.\"\n            \"You need a sufficient support of c++11 to compile SimGrid.\")\n  endif()\nendif()\n\n## We need a decent support of the c++11 standard\ninclude(CheckCXXCompilerFlag)\nCHECK_CXX_COMPILER_FLAG(\"-std=gnu++11\" COMPILER_SUPPORTS_CXX11)\nif(COMPILER_SUPPORTS_CXX11)\n  set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -std=gnu++11\")\nelse() \n  message(FATAL_ERROR \n          \"The compiler ${CMAKE_CXX_COMPILER} (v${CMAKE_CXX_COMPILER_VERSION}) has no C++11 support. \"\n          \"Please install a decent C++ compiler (remove CMakeCache.txt once it's installed).\")\nendif()\n\n### And we need C11 standard, too\ninclude(CheckCCompilerFlag)\nCHECK_C_COMPILER_FLAG(\"-std=gnu11\" COMPILER_SUPPORTS_C11)\nif(COMPILER_SUPPORTS_C11)\n  set(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} -std=gnu11\")\nelse()\n  message(FATAL_ERROR \n          \"The compiler ${CMAKE_C_COMPILER} (v${CMAKE_C_COMPILER_VERSION}) has no C11 support. \"\n          \"Please use a decent C compiler \"\n          \"(note that c++11 support of ${CMAKE_CXX_COMPILER} seems ok).\")\nendif()\nif(APPLE AND (CMAKE_C_COMPILER_VERSION VERSION_LESS \"4.6\"))\n  ### gcc 4.[1-5] cannot compile ucontext on OSX\n  message(STATUS \"Ucontext can't be used with this version of gcc (must be greater than 4.5)\")\n  set(HAVE_UCONTEXT_H 0)\nendif()\n\n### Check threading support\nset(CMAKE_THREAD_PREFER_PTHREAD TRUE)\nfind_package(Threads)\n\n### Setup Options\ninclude(${CMAKE_HOME_DIRECTORY}/tools/cmake/Option.cmake)\n\n### SMPI vs. Fortran\nif ((NOT DEFINED enable_smpi) OR enable_smpi) \n  # First unset the compiler in case we're re-running cmake over a previous\n  # configuration where it was saved as smpiff\n  unset(CMAKE_Fortran_COMPILER)\n  \n  SET(SMPI_FORTRAN 0)\n  if(enable_fortran)\n    enable_language(Fortran OPTIONAL)\n  endif()\n  \n  if(CMAKE_Fortran_COMPILER)\n\n    # Fortran compiler detected: save it, then replace by smpiff\n    set(SMPI_Fortran_COMPILER \"${CMAKE_Fortran_COMPILER}\" CACHE FILEPATH \"The real Fortran compiler\")\n\n\t# Set flags/libs to be used in smpiff\n    if(CMAKE_Fortran_COMPILER_ID MATCHES \"GNU\")\n      set(SMPI_Fortran_FLAGS \"\\\"-fpic\\\" \\\"-ff2c\\\" \\\"-fno-second-underscore\\\"\")\n      set(SMPI_Fortran_LIBS \"\\\"-lgfortran\\\"\")\n      set(SMPI_GFORTRAN 1)\n    elseif(CMAKE_Fortran_COMPILER_ID MATCHES \"Intel\")\n      set(SMPI_Fortran_FLAGS \"\\\"-fPIC\\\" \\\"-nofor-main\\\"\")\n      set(SMPI_Fortran_LIBS \"\\\"-lifcore\\\"\")\n      set(SMPI_IFORT 1)\n    elseif(CMAKE_Fortran_COMPILER_ID MATCHES \"PGI|Flang\") # flang\n      set(SMPI_Fortran_FLAGS \"\\\"-fPIC\\\"\")\n      set(SMPI_Fortran_LIBS \"\")\n      set(SMPI_FLANG 1)\n    endif()\n\n    set(SMPI_FORTRAN 1)\n  endif(CMAKE_Fortran_COMPILER)\n\nendif()\n\n#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#\n#     Build the version number      #\n#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#\n\nset(SIMGRID_VERSION_MAJOR \"3\")\nset(SIMGRID_VERSION_MINOR \"21\")\nset(SIMGRID_VERSION_PATCH \"0\")\n#set(SIMGRID_VERSION_EXTRA \"-DEVEL\") # Extra words to add to version string (e.g. -rc1)\n\nset(SIMGRID_VERSION_DATE  \"2018\") # Year for copyright information\n\nif(${SIMGRID_VERSION_PATCH} EQUAL \"0\")\n  set(release_version \"${SIMGRID_VERSION_MAJOR}.${SIMGRID_VERSION_MINOR}\")\nelse()\n  set(release_version \"${SIMGRID_VERSION_MAJOR}.${SIMGRID_VERSION_MINOR}.${SIMGRID_VERSION_PATCH}\")\nendif()\n\nset(SIMGRID_VERSION_STRING \"SimGrid version ${release_version}${SIMGRID_VERSION_EXTRA}\")\n\nset(libsimgrid_version \"${release_version}\")\nset(libsimgrid-java_version \"${release_version}\")\n\n### SET THE LIBRARY EXTENSION \nif(APPLE)\n  set(LIB_EXE \"dylib\")\nelseif(WIN32)\n  set(LIB_EXE \"a\")\n  set(BIN_EXE \".exe\")\nelse()\n  set(LIB_EXE \"so\")\nendif()\n\nexecute_process(COMMAND ${CMAKE_LINKER} -version OUTPUT_VARIABLE LINKER_VERSION ERROR_VARIABLE LINKER_VERSION)\nstring(REGEX MATCH \"[0-9].[0-9]*\" LINKER_VERSION \"${LINKER_VERSION}\")\n\n### Set the library providing dlopen\nif(\"${CMAKE_SYSTEM}\" MATCHES \"Linux\")\n  find_library(DL_LIBRARY dl)\nendif(\"${CMAKE_SYSTEM}\" MATCHES \"Linux\")\n\n### Find programs and paths\nFIND_PROGRAM(GCOV_PATH gcov)\ninclude(FindPerl)\nif(NOT PERL_FOUND)\n  message(FATAL_ERROR \"Please install Perl to compile SimGrid.\")\nendif()\n\n# tesh.py needs python 3 (or the module python-subprocess32 on python2.8+)\nset(PythonInterp_FIND_VERSION 3)\nset(PythonInterp_FIND_VERSION_COUNT 1)\nset(PythonInterp_FIND_VERSION_MAJOR 3)\ninclude(FindPythonInterp)\nif(NOT PYTHONINTERP_FOUND)\n  message(FATAL_ERROR \"Please install Python (version 3 or higher).\")\nendif()\n\nSET(LIBRARY_OUTPUT_PATH ${CMAKE_BINARY_DIR}/lib)\n\n### Compute the include paths\n\n# Only include public headers by default\ninclude_directories(\n   ${CMAKE_BINARY_DIR}/include\n   ${CMAKE_HOME_DIRECTORY}/include\n)\n\n# Compute the ones that should be added when compiling the library\nset(INTERNAL_INCLUDES\n  ${CMAKE_BINARY_DIR}\n  ${CMAKE_HOME_DIRECTORY}\n  ${CMAKE_HOME_DIRECTORY}/src/include\n  )\n\nif(enable_smpi)\n  set (INTERNAL_INCLUDES ${INTERNAL_INCLUDES} ${CMAKE_HOME_DIRECTORY}/src/smpi/include)\nendif()\n\nif(NOT CMAKE_CROSSCOMPILING AND EXISTS /usr/include/)\n  set(INTERNAL_INCLUDES ${INTERNAL_INCLUDES} /usr/include/)\nendif()\n\nif(WIN32)\n  set(CMAKE_INCLUDE_WIN \"${CMAKE_C_COMPILER}\")\n  set(CMAKE_LIB_WIN \"${CMAKE_C_COMPILER}\")\n  string(REGEX REPLACE \"/bin/gcc.*\" \"/include\"  CMAKE_INCLUDE_WIN \"${CMAKE_INCLUDE_WIN}\")\n  string(REGEX REPLACE \"/bin/gcc.*\" \"/lib\"  CMAKE_LIB_WIN \"${CMAKE_LIB_WIN}\")\n  set(INTERNAL_INCLUDES ${INTERNAL_INCLUDES} ${CMAKE_INCLUDE_WIN})\n  unset(CMAKE_INCLUDE_WIN)\nendif()\n\n# library dependency cannot start with a space (CMP0004), so initialize it with something that is never desactivated.\nset(SIMGRID_DEP \"-lm\") \n\n### Determine the assembly flavor that we need today\nset(HAVE_RAW_CONTEXTS 0)\ninclude(CMakeDetermineSystem)\nIF(CMAKE_SYSTEM_PROCESSOR MATCHES \".86|AMD64|amd64\")\n  IF(CMAKE_SIZEOF_VOID_P EQUAL 4) # 32 bits\n    message(STATUS \"System processor: i686 (${CMAKE_SYSTEM_PROCESSOR}, 32 bits)\")\n    set(SIMGRID_PROCESSOR_i686 1)\n    set(SIMGRID_PROCESSOR_x86_64 0)\n  ELSE()\n    message(STATUS \"System processor: x86_64 (${CMAKE_SYSTEM_PROCESSOR}, 64 bits)\")\n    set(SIMGRID_PROCESSOR_i686 0)\n    set(SIMGRID_PROCESSOR_x86_64 1)\n  ENDIF()\n  if (WIN32)\n    message(STATUS \"Disable fast raw contexts on Windows.\")\n  else()\n    set(HAVE_RAW_CONTEXTS 1)\n  endif()\nELSE()\n  set(SIMGRID_PROCESSOR_i686 0)\n  set(SIMGRID_PROCESSOR_x86_64 0)\nENDIF()\n\ninclude(CheckFunctionExists)\ninclude(CheckTypeSize)\ninclude(CheckIncludeFile)\ninclude(CheckIncludeFiles)\ninclude(CheckLibraryExists)\ninclude(CheckSymbolExists)\n\nset(HAVE_GRAPHVIZ 0)\ninclude(FindGraphviz)\n\nset(SIMGRID_HAVE_LUA 0)\nif(enable_lua)\n  include(FindLuaSimgrid)\nendif()\n\nset(SIMGRID_HAVE_NS3 0)\nif(enable_ns3)\n  include(FindNS3)\n  if (SIMGRID_HAVE_NS3)\n    set(SIMGRID_HAVE_NS3 1)\n    foreach(lib core csma point-to-point internet network applications)\n      set(SIMGRID_DEP \"${SIMGRID_DEP} -lns${NS3_VERSION}-${lib}${NS3_SUFFIX}\")\n    endforeach()\n  else()\n    message(FATAL_ERROR \"Cannot find NS3. Please install it (apt-get install ns3 libns3-dev) or disable that cmake option\")\n  endif()\nendif()\n\nif(WIN32)\n  set(Boost_USE_STATIC_LIBS 1)\nendif()\n\nset(HAVE_PAPI 0)\nif(enable_smpi_papi)\n  include(FindPAPI)\n  if (NOT HAVE_PAPI)\n    message(FATAL_ERROR \"Cannot find PAPI. Please install it (apt-get install papi-tools libpapi-dev) or disable PAPI bindings.\")\n  endif()\nendif()\n\n# Not finding this is perfectly OK\nfind_package(Boost 1.59 COMPONENTS unit_test_framework)\nif (Boost_UNIT_TEST_FRAMEWORK_FOUND)\n  message(STATUS \"Enabling the Boost-based unit tests.\")\nelse()\n  message(STATUS \"Disabling the Boost-based unit tests -- please install libboost-test-dev (>= v1.59).\")\nendif()\n\n\nfind_package(Boost 1.48)\nif(Boost_FOUND)\n  include_directories(${Boost_INCLUDE_DIRS})\nelse()\n  if(APPLE)\n    message(FATAL_ERROR \"Boost libraries not found. Try to install them with 'sudo fink install boost1.53.nopython' (check the exact name with 'fink list boost') or 'sudo brew install boost'\")\n  else()\n    message(FATAL_ERROR \"Boost libraries not found. Install libboost-dev (>= 1.48.0).\")\n  endif()\nendif()\n\nfind_package(Boost COMPONENTS context)\nset(Boost_FOUND 1) # This component is optional\nif(Boost_CONTEXT_FOUND)\n  message(STATUS \"Found Boost.Context\")\n  set(HAVE_BOOST_CONTEXTS 1)\nelse()\n  message (\"   boost        : found.\")\n  message (\"   boost-context: missing. Install libboost-context-dev for this optional feature.\")\n  set(HAVE_BOOST_CONTEXTS 0)\nendif()\n\n# Checks for header libraries functions.\nCHECK_LIBRARY_EXISTS(rt      clock_gettime           \"\" HAVE_POSIX_GETTIME)\n\nset(HAVE_PTHREAD_SETAFFINITY 0)\nCHECK_LIBRARY_EXISTS(pthread pthread_setaffinity_np  \"\" HAVE_PTHREAD_SETAFFINITY)\n\nif(CMAKE_SYSTEM_NAME MATCHES \"Darwin\")\n  set(CMAKE_REQUIRED_DEFINITIONS \"-D_XOPEN_SOURCE=700 -D_DARWIN_C_SOURCE\")\nelseif(MINGW)\n  # Use the GNU version of unusual modifiers like PRIx64\n  add_definitions(-D__USE_MINGW_ANSI_STDIO=1)\n  set(CMAKE_REQUIRED_DEFINITIONS \"-D__USE_MINGW_ANSI_STDIO=1\")\nelse()\n  set(CMAKE_REQUIRED_DEFINITIONS \"-D_GNU_SOURCE\")\nendif()\n\nCHECK_INCLUDE_FILE(\"valgrind/valgrind.h\" HAVE_VALGRIND_H)\nCHECK_INCLUDE_FILE(\"unistd.h\" HAVE_UNISTD_H)\nCHECK_INCLUDE_FILE(\"execinfo.h\" HAVE_EXECINFO_H)\nCHECK_INCLUDE_FILE(\"signal.h\" HAVE_SIGNAL_H)\nCHECK_INCLUDE_FILE(\"sys/param.h\" HAVE_SYS_PARAM_H)\nCHECK_INCLUDE_FILE(\"sys/sysctl.h\" HAVE_SYS_SYSCTL_H)\nCHECK_INCLUDE_FILE(\"ucontext.h\" HAVE_UCONTEXT_H)\nCHECK_INCLUDE_FILE(\"linux/futex.h\" HAVE_FUTEX_H)\n\nCHECK_FUNCTION_EXISTS(backtrace HAVE_BACKTRACE)\nCHECK_FUNCTION_EXISTS(dlfunc HAVE_DLFUNC)\nCHECK_FUNCTION_EXISTS(gettimeofday HAVE_GETTIMEOFDAY)\nCHECK_FUNCTION_EXISTS(nanosleep HAVE_NANOSLEEP)\nCHECK_FUNCTION_EXISTS(getdtablesize HAVE_GETDTABLESIZE)\nCHECK_FUNCTION_EXISTS(sysconf HAVE_SYSCONF)\nCHECK_FUNCTION_EXISTS(popen HAVE_POPEN)\nCHECK_FUNCTION_EXISTS(process_vm_readv HAVE_PROCESS_VM_READV)\nCHECK_FUNCTION_EXISTS(mmap HAVE_MMAP)\nCHECK_FUNCTION_EXISTS(mremap HAVE_MREMAP)\n\nCHECK_SYMBOL_EXISTS(vasprintf stdio.h HAVE_VASPRINTF)\nif(MINGW)\n  # The detection of vasprintf fails on MinGW, assumingly because it's\n  # defined as an inline function in stdio.h instead of a regular\n  # function. So force the result to be 1 despite of the test.\n  set(HAVE_VASPRINTF 1)\nendif()\n\nCHECK_INCLUDE_FILE(\"sys/sendfile.h\" HAVE_SENDFILE_H)\nCHECK_FUNCTION_EXISTS(sendfile HAVE_SENDFILE)\nif(HAVE_SENDFILE_H AND HAVE_SENDFILE)\n  set(HAVE_SENDFILE 1)\nelse()\n  set(HAVE_SENDFILE 0)\nendif()\n\nif(enable_model-checking AND NOT \"${CMAKE_SYSTEM}\" MATCHES \"Linux|FreeBSD\")\n  message(WARNING \"Support for model-checking has not been enabled on ${CMAKE_SYSTEM}: disabling it\")\n  set(enable_model-checking FALSE)\nendif()\n\nif(HAVE_MMAP)\n  SET(HAVE_MMALLOC 1)\nelse()\n  SET(HAVE_MMALLOC 0)\n  if(enable_model-checking)\n    message(STATUS \"Warning: support for model-checking has been disabled because you are missing either mmap or __thread.\")\n  endif()\n  SET(enable_model-checking 0)\nendif()\n\nif(enable_jedule)\n  set(SIMGRID_HAVE_JEDULE 1)\nelse()\n  set(SIMGRID_HAVE_JEDULE 0)\nendif()\n\nif(enable_mallocators)\n  SET(SIMGRID_HAVE_MALLOCATOR 1)\nelse()\n  SET(SIMGRID_HAVE_MALLOCATOR 0)\nendif()\n\ninclude(FindLibunwind)\nif(HAVE_LIBUNWIND)\n  SET(SIMGRID_DEP \"${SIMGRID_DEP} ${LIBUNWIND_LIBRARIES}\")\nelse()\n  if(enable_model-checking)\n    message(FATAL_ERROR \"Please install libunwind-dev libdw-dev libelf-dev libevent-dev if you want to compile the SimGrid model checker.\")\n  endif()\nendif()\n\nif(enable_model-checking)\n  find_package(Libdw REQUIRED)\n  find_package(Libelf REQUIRED)\n  find_package(Libevent REQUIRED)\n  include_directories(${LIBDW_INCLUDE_DIR} ${LIBELF_INCLUDE_DIR} ${LIBEVENT_INCLUDE_DIR})\n  set(SIMGRID_DEP \"${SIMGRID_DEP} ${LIBEVENT_LIBRARIES} ${LIBELF_LIBRARIES} ${LIBDW_LIBRARIES}\")\n  set(SIMGRID_HAVE_MC 1)\n  if(\"${CMAKE_SYSTEM}\" MATCHES \"FreeBSD\" AND enable_java)\n    message(WARNING \"FreeBSD + Model-Checking + Java = too much for now. Disabling java\")\n    set(enable_java FALSE)\n  endif()\nelse()\n  SET(SIMGRID_HAVE_MC 0)  \n  set(HAVE_MMALLOC 0)\nendif()\nmark_as_advanced(PATH_LIBDW_H)\nmark_as_advanced(PATH_LIBDW_LIB)\n\nif (enable_model-checking AND enable_ns3)\n  message(FATAL_ERROR \"Cannot activate both model-checking and NS3 bindings: NS3 pull too much dependencies for the MC to work\")\nendif()\n\nif(enable_smpi)\n  SET(HAVE_SMPI 1)\n  if(\"${CMAKE_SYSTEM}\" MATCHES \"Darwin|FreeBSD|Linux\")\n    SET(USE_LIBUTIL 0)\n    SET(HAVE_PRIVATIZATION 1)\n  else()\n    message (STATUS \"Warning:  no support for SMPI automatic privatization on this platform\")\n    SET(HAVE_PRIVATIZATION 0)\n  endif()\nelse()\n  SET(HAVE_SMPI 0)\nendif()\n\n#--------------------------------------------------------------------------------------------------\n### Initialize of CONTEXT THREADS\n\nset(HAVE_THREAD_CONTEXTS 0)\nif(CMAKE_USE_PTHREADS_INIT)\n  ### Test that we have a way to create semaphores\n\n  set(HAVE_SEM_OPEN 0)\n  CHECK_LIBRARY_EXISTS(pthread sem_open \"\" HAVE_SEM_OPEN_LIB)\n  if(HAVE_SEM_OPEN_LIB)\n    try_run(semopen_retval semopen_compilable\n            ${CMAKE_BINARY_DIR}\n            ${CMAKE_HOME_DIRECTORY}/tools/cmake/test_prog/prog_sem_open.c\n\t    LINK_LIBRARIES pthread\n\t    COMPILE_OUTPUT_VARIABLE semopen_compilmsg\n            RUN_OUTPUT_VARIABLE semopen_runmsg)\n    \n    if(semopen_compilable)\n      if(NOT semopen_retval) #\u00a0error if not 0\n        message(STATUS \"sem_open is compilable and executable\")\n\tset(HAVE_SEM_OPEN 1)\n      else()\n        message(STATUS \"Warning: sem_open seems compilable but not executable\")\n        message(STATUS \"Compilation output: ${semopen_compilmsg}\")\n        message(STATUS \"Execution output: ${semopen_runmsg}\")\n        message(STATUS \"Exit value: ${semopen_retval}\")\n      endif()\n    else()\n      message(STATUS \"Warning: sem_open not compilable\")\n      message(STATUS \"Compilation output: ${semopen_compilmsg}\")\n    endif()\n    unset(semopen_compilable)\n    unset(semopen_retval)\n    unset(semopen_runmsg)\n    unset(semopen_compilmsg)\n  endif()\n\n  set(HAVE_SEM_INIT 0)  \n  if(NOT APPLE) # OS X El Capitan deprecates this function\n    CHECK_LIBRARY_EXISTS(pthread sem_init \"\" HAVE_SEM_INIT_LIB)\n  endif()\n  if(HAVE_SEM_INIT_LIB)\n    try_run(seminit_retval seminit_compilable\n            ${CMAKE_BINARY_DIR}\n            ${CMAKE_HOME_DIRECTORY}/tools/cmake/test_prog/prog_sem_init.c\n\t    LINK_LIBRARIES pthread\n\t    COMPILE_OUTPUT_VARIABLE seminit_compilmsg\n            RUN_OUTPUT_VARIABLE seminit_runmsg)\n    \n    if(seminit_compilable)\n      if(NOT seminit_retval) #\u00a0error if not 0\n        message(STATUS \"sem_init is compilable and executable\")\n\tset(HAVE_SEM_INIT 1)\n      else()\n        message(STATUS \"Warning: sem_init seems compilable but not executable\")\n        message(STATUS \"Compilation output: ${seminit_compilmsg}\")\n        message(STATUS \"Execution output: ${seminit_runmsg}\")\n        message(STATUS \"Exit value: ${seminit_retval}\")\n      endif()\n    else()\n      message(STATUS \"Warning: sem_init not compilable\")\n      message(STATUS \"Compilation output: ${seminit_compilmsg}\")\n    endif()\n    unset(seminit_compilable)\n    unset(seminit_retval)\n    unset(seminit_runmsg)\n    unset(seminit_compilmsg)\n  endif()\n\n  if(NOT HAVE_SEM_OPEN AND NOT HAVE_SEM_INIT)\n    message(FATAL_ERROR \"Semaphores are not usable (failed to use both sem_open and sem_init), but they are mandatory to threads (you may need to mount /dev).\")\n  endif()\n\n  set(HAVE_THREAD_CONTEXTS 1)\n  message(STATUS \"Support for thread context factory ok.\")\nendif()\n\nset(HAVE_UCONTEXT_CONTEXTS 0)\nif(NOT HAVE_UCONTEXT_H)\n  message(STATUS \"No ucontext factory: <ucontext.h> not found.\")\nelseif(APPLE)\n  message(STATUS \"No ucontext factory: Apple don't want us to use them.\")\n  set(HAVE_UCONTEXT_H 0)\nelse()\n  try_compile(compile_makecontext ${CMAKE_BINARY_DIR} ${CMAKE_HOME_DIRECTORY}/tools/cmake/test_prog/prog_makecontext.c\n    OUTPUT_VARIABLE compile_makecontext_output)\n\n  #If can have both context\n  if(compile_makecontext)\n    set(HAVE_UCONTEXT_CONTEXTS 1)\n    message(STATUS \"Support for ucontext factory ok.\")\n  else()\n    message(STATUS \"Error: <ucontext.h> exists, but makecontext is not compilable. Compilation output:\\n ${compile_makecontext_output}\")\n    message(STATUS \"No ucontext factory: makecontext() is not compilable.\")\n  endif()\n\n  # Stack setup (size and address)\n  try_run(RUN_makecontext_VAR COMPILE_makecontext_VAR\n    ${CMAKE_BINARY_DIR} ${CMAKE_HOME_DIRECTORY}/tools/cmake/test_prog/prog_stacksetup.c\n    RUN_OUTPUT_VARIABLE stack_setup)\n\n  LIST(LENGTH stack_setup stack_setup_len)\n  if(\"${stack_setup_len}\" STREQUAL \"2\")\n    LIST(GET stack_setup 0 makecontext_addr)\n    LIST(GET stack_setup 1 makecontext_size)\n    set(sg_makecontext_stack_addr \"#define sg_makecontext_stack_addr(skaddr) (${makecontext_addr})\")\n    set(sg_makecontext_stack_size \"#define sg_makecontext_stack_size(sksize) (${makecontext_size})\")\n  else()\n    message(FATAL_ERROR \"Could not figure out the stack setup. Compil: ${RUN_makecontext_VAR}. Exec: ${COMPILE_makecontext_VAR}. Output: ${stack_setup}\")\n  endif()\nendif()\n\n# Stack growth direction (upward or downward). Used for the following contexts: SysV, raw, Boost\ntry_run(RUN_stackgrowth_VAR COMPILE_stackgrowth_VAR\n  ${CMAKE_BINARY_DIR}\n  ${CMAKE_HOME_DIRECTORY}/tools/cmake/test_prog/prog_stackgrowth.c\n  RUN_OUTPUT_VARIABLE stack\n  COPY_FILE test_stackgrowth)\n\nif(\"${stack}\" STREQUAL \"down\")\n  set(PTH_STACKGROWTH \"-1\")\nelseif(\"${stack}\" STREQUAL \"up\")\n  set(PTH_STACKGROWTH \"1\")\nelse()\n  if(\"${CMAKE_SYSTEM_PROCESSOR}\" STREQUAL \"x86_64\")\n    set(PTH_STACKGROWTH \"-1\")\n  elseif(\"${CMAKE_SYSTEM_PROCESSOR}\" STREQUAL \"i686\")\n    set(PTH_STACKGROWTH \"-1\")\n  else()\n    message(FATAL_ERROR \"Could not figure out the stack direction. Test prog returned: ${stack}; CMAKE_SYSTEM_PROCESSOR: ${CMAKE_SYSTEM_PROCESSOR}.\")\n  endif()\nendif()\n# If the test ran well, remove the test binary\nfile(REMOVE test_stackgrowth)\n#--------------------------------------------------------------------------------------------------\n\n### check for addr2line\nfind_path(ADDR2LINE NAMES addr2line\tPATHS NO_DEFAULT_PATHS)\nif(ADDR2LINE)\n  set(ADDR2LINE \"${ADDR2LINE}/addr2line\")\nendif()\n\n###############\n## GIT version check\n##\nif(EXISTS ${CMAKE_HOME_DIRECTORY}/.git/)\n  execute_process(\n     COMMAND git remote\n     COMMAND head -n 1\n     WORKING_DIRECTORY ${CMAKE_HOME_DIRECTORY}/.git/\n     OUTPUT_VARIABLE remote\n     OUTPUT_STRIP_TRAILING_WHITESPACE)\n  #message(STATUS \"Git remote: ${remote}\")\n  execute_process(COMMAND git config --get remote.${remote}.url\n     WORKING_DIRECTORY ${CMAKE_HOME_DIRECTORY}/.git/\n     OUTPUT_VARIABLE url\n     OUTPUT_STRIP_TRAILING_WHITESPACE)\n  #message(STATUS \"Git url: ${url}\")\n  if(url)\n    execute_process(COMMAND git --git-dir=${CMAKE_HOME_DIRECTORY}/.git log --pretty=oneline --abbrev-commit -1\n       WORKING_DIRECTORY ${CMAKE_HOME_DIRECTORY}/.git/\n       OUTPUT_VARIABLE GIT_VERSION\n       OUTPUT_STRIP_TRAILING_WHITESPACE)\n    message(STATUS \"Git version: ${GIT_VERSION}\")\n\n    execute_process(COMMAND git --git-dir=${CMAKE_HOME_DIRECTORY}/.git log -n 1 --pretty=format:%ai .\n       WORKING_DIRECTORY ${CMAKE_HOME_DIRECTORY}/.git/\n       OUTPUT_VARIABLE GIT_DATE \n       OUTPUT_STRIP_TRAILING_WHITESPACE)\n    message(STATUS \"Git date: ${GIT_DATE}\")\n    string(REGEX REPLACE \" .*\" \"\" GIT_VERSION \"${GIT_VERSION}\")\n\n    execute_process(COMMAND git --git-dir=${CMAKE_HOME_DIRECTORY}/.git log --pretty=format:%H -1\n       WORKING_DIRECTORY ${CMAKE_HOME_DIRECTORY}/.git/\n       OUTPUT_VARIABLE SIMGRID_GITHASH\n       OUTPUT_STRIP_TRAILING_WHITESPACE)\n  endif()\nelseif(EXISTS ${CMAKE_HOME_DIRECTORY}/.gitversion)\n  FILE(STRINGS ${CMAKE_HOME_DIRECTORY}/.gitversion GIT_VERSION)\nelse()\n  set(GIT_VERSION \"none, release version\")\nendif()\n\n### Setup gcc & clang flags\nif (NOT MSVC)\n  include(${CMAKE_HOME_DIRECTORY}/tools/cmake/GCCFlags.cmake)\nendif()\n\n### Generate the required headers and scripts\n#############################################\n\n# Avoid triggering a (full) rebuild by touching the files if they did not really change\nconfigure_file(\"${CMAKE_HOME_DIRECTORY}/tools/cmake/src/internal_config.h.in\" \"${CMAKE_BINARY_DIR}/src/internal_config.h.generated\"    @ONLY IMMEDIATE)\nconfigure_file(\"${CMAKE_HOME_DIRECTORY}/include/simgrid/config.h.in\"          \"${CMAKE_BINARY_DIR}/include/simgrid/config.h.generated\" @ONLY IMMEDIATE)\nexecute_process(COMMAND ${CMAKE_COMMAND} -E copy_if_different ${CMAKE_BINARY_DIR}/src/internal_config.h.generated ${CMAKE_BINARY_DIR}/src/internal_config.h)\nexecute_process(COMMAND ${CMAKE_COMMAND} -E copy_if_different ${CMAKE_BINARY_DIR}/include/simgrid/config.h.generated ${CMAKE_BINARY_DIR}/include/simgrid/config.h)\nfile(REMOVE ${CMAKE_BINARY_DIR}/src/internal_config.h.generated)\nfile(REMOVE ${CMAKE_BINARY_DIR}/include/simgrid/config.h.generated)\n\n# We need two versions of the SMPI scripts because they contain the path to the library\n# so, it depends of whether SimGrid is installed, or run from the sources (during the build)\n\nfile(READ ${CMAKE_HOME_DIRECTORY}/src/smpi/smpitools.sh SMPITOOLS_SH) # Definitions shared amongst all SMPI scripts, inlined in each of them\n\n### SMPI script used when simgrid is installed\nset(exec_prefix ${CMAKE_INSTALL_PREFIX})\nset(includeflag \"-I${CMAKE_INSTALL_PREFIX}/include -I${CMAKE_INSTALL_PREFIX}/include/smpi\")\nset(includedir \"${CMAKE_INSTALL_PREFIX}/include\")\nset(libdir ${exec_prefix}/lib)\nset(CMAKE_SMPI_COMMAND \"export LD_LIBRARY_PATH=\\\"${CMAKE_INSTALL_PREFIX}/lib\")\nif(NS3_LIBRARY_PATH)\n  set(CMAKE_SMPI_COMMAND \"${CMAKE_SMPI_COMMAND}:${NS3_LIBRARY_PATH}\")\nendif()\nset(CMAKE_SMPI_COMMAND \"${CMAKE_SMPI_COMMAND}:\\${LD_LIBRARY_PATH:+:$LD_LIBRARY_PATH}\\\"\")\nset(SMPIMAIN ${libdir}/simgrid/smpimain)\n\nconfigure_file(${CMAKE_HOME_DIRECTORY}/include/smpi/mpif.h.in ${CMAKE_BINARY_DIR}/include/smpi/mpif.h @ONLY)\n#configure mpif.f90 to build mpi.mod\nif(SMPI_FORTRAN)\n  set(MODULE_MPIF_IN \"module mpi\")\n  set(MODULE_MPIF_OUT \"end module mpi\")\n  configure_file(${CMAKE_HOME_DIRECTORY}/include/smpi/mpif.h.in ${CMAKE_BINARY_DIR}/src/smpi/mpif.f90.generated @ONLY)\n  execute_process(COMMAND ${CMAKE_COMMAND} -E copy_if_different ${CMAKE_BINARY_DIR}/src/smpi/mpif.f90.generated ${CMAKE_BINARY_DIR}/src/smpi/mpif.f90)\n  set(CMAKE_Fortran_MODULE_DIRECTORY ${CMAKE_BINARY_DIR}/include/smpi)\n  add_library(mpi SHARED ${CMAKE_BINARY_DIR}/src/smpi/mpif.f90)\nendif()\n\nforeach(script cc cxx ff f90 run)\n  configure_file(${CMAKE_HOME_DIRECTORY}/src/smpi/smpi${script}.in ${CMAKE_BINARY_DIR}/bin/smpi${script} @ONLY)\nendforeach()\n\n### SMPI scripts used when compiling simgrid \nset(exec_prefix \"${CMAKE_BINARY_DIR}/smpi_script/\")\nset(includeflag \"-I${CMAKE_HOME_DIRECTORY}/include -I${CMAKE_HOME_DIRECTORY}/include/smpi\")\nset(includeflag \"${includeflag} -I${CMAKE_BINARY_DIR}/include -I${CMAKE_BINARY_DIR}/include/smpi\")\nset(includedir \"${CMAKE_HOME_DIRECTORY}/include\")\nset(libdir \"${CMAKE_BINARY_DIR}/lib\")\nset(CMAKE_SMPI_COMMAND \"export LD_LIBRARY_PATH=\\\"${CMAKE_BINARY_DIR}/lib\")\nif(NS3_LIBRARY_PATH)\n  set(CMAKE_SMPI_COMMAND \"${CMAKE_SMPI_COMMAND}:${NS3_LIBRARY_PATH}\")\nendif()\nset(CMAKE_SMPI_COMMAND \"${CMAKE_SMPI_COMMAND}:\\${LD_LIBRARY_PATH:+:$LD_LIBRARY_PATH}\\\"\")\nset(SMPIMAIN ${CMAKE_BINARY_DIR}/lib/simgrid/smpimain)\n\nforeach(script cc cxx ff f90 run)\n  configure_file(${CMAKE_HOME_DIRECTORY}/src/smpi/smpi${script}.in ${CMAKE_BINARY_DIR}/smpi_script/bin/smpi${script} @ONLY)\nendforeach()\n\nif(NOT WIN32)\n  foreach(script cc cxx ff f90 run)\n    execute_process(COMMAND chmod a=rwx ${CMAKE_BINARY_DIR}/bin/smpi${script})\n    execute_process(COMMAND chmod a=rwx ${CMAKE_BINARY_DIR}/smpi_script/bin/smpi${script})\n  endforeach()\nendif()\n\nset(generated_headers_to_install\n  ${CMAKE_CURRENT_BINARY_DIR}/include/smpi/mpif.h\n  ${CMAKE_CURRENT_BINARY_DIR}/include/simgrid/config.h\n  )\n\nset(generated_headers  ${CMAKE_CURRENT_BINARY_DIR}/src/internal_config.h )\n\nset(generated_files_to_clean\n  ${generated_headers}\n  ${generated_headers_to_install}\n  ${CMAKE_BINARY_DIR}/bin/smpicc\n  ${CMAKE_BINARY_DIR}/bin/smpicxx\n  ${CMAKE_BINARY_DIR}/bin/smpiff\n  ${CMAKE_BINARY_DIR}/bin/smpif90\n  ${CMAKE_BINARY_DIR}/bin/smpirun\n  ${CMAKE_BINARY_DIR}/bin/colorize\n  ${CMAKE_BINARY_DIR}/bin/simgrid_update_xml\n  ${CMAKE_BINARY_DIR}/examples/smpi/tracing/smpi_traced.trace\n  )\n\nif(NOT \"${CMAKE_BINARY_DIR}\" STREQUAL \"${CMAKE_HOME_DIRECTORY}\")\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay/actions0.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions0.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay/actions1.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions1.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay/actions_allreduce.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions_allreduce.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay/actions_barrier.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions_barrier.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay/actions_bcast.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions_bcast.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay/actions_with_isend.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions_with_isend.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay/actions_alltoall.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions_alltoall.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay/actions_alltoallv.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions_alltoallv.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay/actions_waitall.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions_waitall.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay/actions_reducescatter.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions_reducescatter.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay/actions_gather.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions_gather.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay/actions_allgatherv.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions_allgatherv.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/hostfile ${CMAKE_BINARY_DIR}/teshsuite/smpi/hostfile COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/hostfile_cluster ${CMAKE_BINARY_DIR}/teshsuite/smpi/hostfile_cluster COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/hostfile_coll ${CMAKE_BINARY_DIR}/teshsuite/smpi/hostfile_coll COPYONLY)\n\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/description_file ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/description_file COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/README ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/README COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/smpi_replay.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/smpi_replay.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace0.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace0.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace1.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace1.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace2.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace2.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace3.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace3.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace4.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace4.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace5.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace5.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace6.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace6.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace7.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace7.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace8.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace8.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace9.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace9.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace10.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace10.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace11.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace11.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace12.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace12.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace13.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace13.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace14.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace14.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace15.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace15.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace16.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace16.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace17.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace17.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace18.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace18.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace19.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace19.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace20.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace20.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace21.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace21.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace22.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace22.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace23.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace23.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace24.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace24.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace25.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace25.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace26.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace26.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace27.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace27.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace28.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace28.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace29.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace29.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace30.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace30.txt COPYONLY)\n  configure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace31.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace31.txt COPYONLY)\n\nconfigure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple_manual_deploy/compute_only.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple_manual_deploy/compute_only.txt COPYONLY)\nconfigure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple_manual_deploy/compute_only/actions0.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple_manual_deploy/compute_only/actions0.txt COPYONLY)\nconfigure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple_manual_deploy/compute_only/actions1.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple_manual_deploy/compute_only/actions1.txt COPYONLY)\nconfigure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple_manual_deploy/empty.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple_manual_deploy/empty.txt COPYONLY)\nconfigure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple_manual_deploy/empty/actions0.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple_manual_deploy/empty/actions0.txt COPYONLY)\nconfigure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple_manual_deploy/empty/actions1.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple_manual_deploy/empty/actions1.txt COPYONLY)\nconfigure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple_manual_deploy/mixed.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple_manual_deploy/mixed.txt COPYONLY)\nconfigure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple_manual_deploy/mixed/actions0.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple_manual_deploy/mixed/actions0.txt COPYONLY)\nconfigure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple_manual_deploy/mixed/actions1.txt ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple_manual_deploy/mixed/actions1.txt COPYONLY)\nconfigure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple_manual_deploy/workload_compute ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple_manual_deploy/workload_compute COPYONLY)\nconfigure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple_manual_deploy/workload_compute_consecutive ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple_manual_deploy/workload_compute_consecutive COPYONLY)\nconfigure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple_manual_deploy/workload_compute_consecutive2 ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple_manual_deploy/workload_compute_consecutive2 COPYONLY)\nconfigure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple_manual_deploy/workload_compute_simple ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple_manual_deploy/workload_compute_simple COPYONLY)\nconfigure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple_manual_deploy/workload_mixed2_same_time ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple_manual_deploy/workload_mixed2_same_time COPYONLY)\nconfigure_file(${CMAKE_HOME_DIRECTORY}/examples/smpi/replay_multiple_manual_deploy/workload_mixed2_same_time_and_resources ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple_manual_deploy/workload_mixed2_same_time_and_resources COPYONLY)\n\n  set(generated_files_to_clean\n    ${generated_files_to_clean}\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions0.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions1.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions_allreduce.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions_barrier.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions_bcast.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions_with_isend.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions_alltoall.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions_alltoallv.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions_waitall.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions_gather.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions_allgatherv.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay/actions_reducescatter.txt\n    ${CMAKE_BINARY_DIR}/teshsuite/smpi/hostfile\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/description_file\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/README\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/smpi_replay.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace0.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace1.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace2.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace3.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace4.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace5.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace6.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace7.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace8.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace9.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace10.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace11.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace12.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace13.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace14.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace15.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace16.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace17.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace18.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace19.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace20.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace21.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace22.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace23.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace24.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace25.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace26.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace27.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace28.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace29.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace30.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple/ti_traces_32_1/ti_trace31.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple_manual_deploy/compute_only.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple_manual_deploy/compute_only/actions0.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple_manual_deploy/compute_only/actions1.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple_manual_deploy/empty.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple_manual_deploy/empty/actions0.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple_manual_deploy/empty/actions1.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple_manual_deploy/mixed.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple_manual_deploy/mixed/actions0.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple_manual_deploy/mixed/actions1.txt\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple_manual_deploy/replay_multiple_manual.tesh\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple_manual_deploy/workload_compute\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple_manual_deploy/workload_compute_consecutive\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple_manual_deploy/workload_compute_consecutive2\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple_manual_deploy/workload_compute_simple\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple_manual_deploy/workload_empty1\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple_manual_deploy/workload_empty2\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple_manual_deploy/workload_empty2_same_resources\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple_manual_deploy/workload_empty2_same_time\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple_manual_deploy/workload_empty2_same_time_and_resources\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple_manual_deploy/workload_mixed1\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple_manual_deploy/workload_mixed2\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple_manual_deploy/workload_mixed2_same_resources\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple_manual_deploy/workload_mixed2_same_time\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple_manual_deploy/workload_mixed2_same_time_and_resources\n    ${CMAKE_BINARY_DIR}/examples/smpi/replay_multiple_manual_deploy/workload_nojob\n    )\nendif()\n\nSET_DIRECTORY_PROPERTIES(PROPERTIES ADDITIONAL_MAKE_CLEAN_FILES\n  \"${generated_files_to_clean}\")\n\n### Define source packages for Libs\ninclude(${CMAKE_HOME_DIRECTORY}/tools/cmake/DefinePackages.cmake)\n\n### Build some Maintainer files\ninclude(${CMAKE_HOME_DIRECTORY}/tools/cmake/MaintainerMode.cmake)\ninclude(${CMAKE_HOME_DIRECTORY}/tools/cmake/UnitTesting.cmake)\n\n### Make Libs\nif(NOT WIN32)\n  include(${CMAKE_HOME_DIRECTORY}/tools/cmake/MakeLib.cmake)\nelse()\n  include(${CMAKE_HOME_DIRECTORY}/tools/cmake/MakeLibWin.cmake)\nendif()\n\nif(enable_java)\n  include(${CMAKE_HOME_DIRECTORY}/tools/cmake/Java.cmake)\nendif()\n\n### Make tests\nif(enable_memcheck_xml)\n  set(enable_memcheck true)\nendif()\n\nINCLUDE(CTest)\nENABLE_TESTING()\ninclude(${CMAKE_HOME_DIRECTORY}/tools/cmake/Tests.cmake)\ninclude(${CMAKE_HOME_DIRECTORY}/tools/cmake/CTestConfig.cmake)\n\n### Define subdirectories\nforeach(cmakefile ${CMAKEFILES_TXT})\n  string(REPLACE \"/CMakeLists.txt\" \"\" repository ${cmakefile})\n  add_subdirectory(\"${CMAKE_HOME_DIRECTORY}/${repository}\")\nendforeach()\n\n### Setup the distrib\ninclude(${CMAKE_HOME_DIRECTORY}/tools/cmake/Distrib.cmake)\n\n### Build the docs if asked to\ninclude(${CMAKE_HOME_DIRECTORY}/tools/cmake/Documentation.cmake)\n\n### Print the result of configuration\nmessage(\"\")\nmessage(\"##########################################\")\nmessage(\"#### Content of src/internal_config.h ####\")\nmessage(\"##########################################\")\nfile(STRINGS ${CMAKE_CURRENT_BINARY_DIR}/src/internal_config.h config_output)\nLIST(REMOVE_AT config_output 0 1 2 3 4 5 6 7 8 9 10) # Pass the file header\nforeach(line ${config_output})\n  message(\"   ${line}\")\nendforeach()\nmessage(\"##########################################\")\nmessage(\"####   Content of simgrid/config.h    ####\")\nmessage(\"##########################################\")\nfile(STRINGS ${CMAKE_CURRENT_BINARY_DIR}/include/simgrid/config.h config_output)\nLIST(REMOVE_AT config_output 0 1 2 3 4 5 6 7 8 9 -1) # Pass the file header\nforeach(line ${config_output})\n  message(\"   ${line}\")\nendforeach()\nmessage(\"##########################################\")\nmessage(\"####   End of configuration headers   ####\")\nmessage(\"##########################################\")\n\nmessage(\"\\nConfiguration of package `simgrid':\")\nmessage(\"        Home directory ..............: ${CMAKE_HOME_DIRECTORY}\")\nmessage(\"        Build Name ..................: ${BUILDNAME}\")\nmessage(\"        Cmake Generator .............: ${CMAKE_GENERATOR}\")\nmessage(\"        Site ........................: ${SITE}\")\nmessage(\"        Install prefix ..............: ${CMAKE_INSTALL_PREFIX}\")\nif(release)\n  message(\"        Release .....................: simgrid-${release_version}${SIMGRID_VERSION_EXTRA} (release build)\")\nelse()\n  message(\"        Release .....................: simgrid-${release_version}${SIMGRID_VERSION_EXTRA} (development build)\")\nendif()\nmessage(\"\")\nmessage(\"        Compiler: C .................: ${CMAKE_C_COMPILER} (id: ${CMAKE_C_COMPILER_ID})\")\nmessage(\"                version .............: ${CMAKE_C_COMPILER_VERSION}\")\nmessage(\"                is gnu ..............: ${CMAKE_COMPILER_IS_GNUCC}\")\nmessage(\"        Compiler: C++ ...............: ${CMAKE_CXX_COMPILER} (id: ${CMAKE_CXX_COMPILER_ID})\")\nmessage(\"                version .............: ${CMAKE_CXX_COMPILER_VERSION}\")\nif(${Java_FOUND})\n  message(\"        Compiler: Javac .............: ${Java_JAVAC_EXECUTABLE}\")\n  message(\"                version .............: ${Java_VERSION_STRING}\")\nendif()\nif(CMAKE_Fortran_COMPILER)\n  message(\"        Compiler: Fortran ...........: ${SMPI_Fortran_COMPILER} (id: ${CMAKE_Fortran_COMPILER_ID})\")\n  message(\"                version .............: ${CMAKE_Fortran_COMPILER_VERSION}\")\nendif()\nmessage(\"        Linker: .....................: ${CMAKE_LINKER}\")\nmessage(\"                version .............: ${LINKER_VERSION}\")\nmessage(\"        Make program: ...............: ${CMAKE_MAKE_PROGRAM}\")\nmessage(\"\")\nmessage(\"        CFlags ......................: ${CMAKE_C_FLAGS}\")\nmessage(\"        CXXFlags ....................: ${CMAKE_CXX_FLAGS}\")\nmessage(\"        LDFlags .....................: ${CMAKE_C_LINK_FLAGS}\")\nmessage(\"        with LTO ....................: ${enable_lto}\")\nmessage(\"\")\n\nif (SIMGRID_HAVE_NS3)\n  message(\"        Compile NS-3 ................: yes (path: ${NS3_PATH})\")\nelse()\n  message(\"        Compile NS-3 ................: NO  (hint: ${NS3_HINT})\")\nendif()\n\nif (${Java_FOUND})\n  message(\"        Compile Java ................: yes\")\n  message(\"          Native lib in jar .........: ${enable_lib_in_jar}\")\nelse()\n  message(\"        Compile Java ................: NO\")\nendif()\nmessage(\"        Compile Lua .................: ${SIMGRID_HAVE_LUA}\")\nmessage(\"        Compile Smpi ................: ${HAVE_SMPI}\")\nmessage(\"          Smpi fortran ..............: ${SMPI_FORTRAN}\")\nmessage(\"          MPICH3 testsuite ..........: ${enable_smpi_MPICH3_testsuite}\")\nmessage(\"          Privatization .............: ${HAVE_PRIVATIZATION}\")\nmessage(\"          PAPI support...............: ${HAVE_PAPI}\")\nmessage(\"        Compile Boost.Context support: ${HAVE_BOOST_CONTEXTS}\")\nmessage(\"\")\nmessage(\"        Maintainer mode .............: ${enable_maintainer_mode}\")\nmessage(\"        Documentation................: ${enable_documentation}\")\nmessage(\"        Model checking ..............: ${SIMGRID_HAVE_MC}\")\nmessage(\"        Jedule  mode ................: ${SIMGRID_HAVE_JEDULE}\")\nmessage(\"        Graphviz mode ...............: ${HAVE_GRAPHVIZ}\")\nmessage(\"        Mallocators .................: ${enable_mallocators}\")\nmessage(\"\")\nmessage(\"        Simgrid dependencies ........: ${SIMGRID_DEP}\")\nmessage(\"\")\n\nexecute_process(COMMAND ${CMAKE_COMMAND} -E make_directory ${PROJECT_BINARY_DIR}/Testing/Notes/)\nfile(WRITE ${PROJECT_BINARY_DIR}/Testing/Notes/Build  \"GIT version : ${GIT_VERSION}\\n\")\nfile(APPEND ${PROJECT_BINARY_DIR}/Testing/Notes/Build \"Release     : simgrid-${release_version}\\n\")\n\nINCLUDE(Dart)\n",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.21-2jw7hfw3ki7yfy6d52vbzhst6fypdxym/spack-src/src/simgrid/sg_config.cpp": "/* Copyright (c) 2009-2018. The SimGrid Team. All rights reserved.          */\n\n/* This program is free software; you can redistribute it and/or modify it\n * under the terms of the license (GNU LGPL) which comes with this package. */\n\n/* sg_config: configuration infrastructure for the simulation world         */\n\n#include \"simgrid/sg_config.hpp\"\n#include \"simgrid/instr.h\"\n#include \"src/instr/instr_private.hpp\"\n#include \"src/internal_config.h\"\n#include \"src/kernel/lmm/maxmin.hpp\"\n#include \"src/mc/mc_config.hpp\"\n#include \"src/mc/mc_replay.hpp\"\n#include \"src/surf/surf_interface.hpp\"\n#include \"surf/surf.hpp\"\n#include \"xbt/config.hpp\"\n\nXBT_LOG_NEW_DEFAULT_SUBCATEGORY(surf_config, surf, \"About the configuration of SimGrid\");\n\nstatic simgrid::config::Flag<bool> cfg_continue_after_help\n  {\"help-nostop\", \"Do not stop the execution when --help is found\", false};\n\n/** @brief Allow other libraries to react to the --help flag, too\n *\n * When finding --help on the command line, simgrid usually stops right after displaying its help message.\n * If you are writing a library using simgrid, you may want to display your own help message before everything stops.\n * If so, just call this function before having simgrid parsing the command line, and you will be given the control\n * even if the user is asking for help.\n */\nvoid sg_config_continue_after_help()\n{\n  cfg_continue_after_help = true;\n}\n\n/* 0: beginning of time (config cannot be changed yet)\n * 1: initialized: cfg_set created (config can now be changed)\n * 2: configured: command line parsed and config part of platform file was\n *    integrated also, platform construction ongoing or done.\n *    (Config cannot be changed anymore!)\n */\nint _sg_cfg_init_status = 0;\n\n/* instruct the upper layer (simix or simdag) to exit as soon as possible */\nbool _sg_cfg_exit_asap = false;\n\n#define sg_cfg_exit_early()                                                                                            \\\n  do {                                                                                                                 \\\n    _sg_cfg_exit_asap = true;                                                                                          \\\n    return;                                                                                                            \\\n  } while (0)\n\n/* Parse the command line, looking for options */\nstatic void sg_config_cmd_line(int *argc, char **argv)\n{\n  bool shall_exit = false;\n  int i;\n  int j;\n  bool parse_args = true; // Stop parsing the parameters once we found '--'\n\n  for (j = i = 1; i < *argc; i++) {\n    if (not strcmp(\"--\", argv[i])) {\n      parse_args = false;\n      // Remove that '--' from the arguments\n    } else if (parse_args && not strncmp(argv[i], \"--cfg=\", strlen(\"--cfg=\"))) {\n      char *opt = strchr(argv[i], '=');\n      opt++;\n\n      simgrid::config::set_parse(opt);\n      XBT_DEBUG(\"Did apply '%s' as config setting\", opt);\n    } else if (parse_args && not strcmp(argv[i], \"--version\")) {\n      printf(\"%s\\n\", SIMGRID_VERSION_STRING);\n      shall_exit = true;\n    } else if (parse_args && (not strcmp(argv[i], \"--cfg-help\") || not strcmp(argv[i], \"--help\"))) {\n      printf(\"Description of the configuration accepted by this simulator:\\n\");\n      simgrid::config::help();\n      printf(\n          \"\\n\"\n          \"Each of these configurations can be used by adding\\n\"\n          \"    --cfg=<option name>:<option value>\\n\"\n          \"to the command line.\\n\"\n          \"\\n\"\n          \"For more information, please refer to:\\n\"\n          \"   --help-aliases for the list of all option aliases.\\n\"\n          \"   --help-logs and --help-log-categories for the details of logging output.\\n\"\n          \"   --help-models for a list of all models known by this simulator.\\n\"\n          \"   --help-tracing for the details of all tracing options known by this simulator.\\n\"\n          \"   --version to get SimGrid version information.\\n\"\n          \"\\n\"\n        );\n      shall_exit = not cfg_continue_after_help;\n      argv[j++]  = argv[i]; // Preserve the --help in argv just in case someone else wants to see it\n    } else if (parse_args && not strcmp(argv[i], \"--help-aliases\")) {\n      printf(\"Here is a list of all deprecated option names, with their replacement.\\n\");\n      simgrid::config::show_aliases();\n      printf(\"Please consider using the recent names\\n\");\n      shall_exit = true;\n    } else if (parse_args && not strcmp(argv[i], \"--help-models\")) {\n      model_help(\"host\", surf_host_model_description);\n      printf(\"\\n\");\n      model_help(\"CPU\", surf_cpu_model_description);\n      printf(\"\\n\");\n      model_help(\"network\", surf_network_model_description);\n      printf(\"\\nLong description of all optimization levels accepted by the models of this simulator:\\n\");\n      for (int k = 0; surf_optimization_mode_description[k].name; k++)\n        printf(\"  %s: %s\\n\",\n               surf_optimization_mode_description[k].name,\n               surf_optimization_mode_description[k].description);\n      printf(\"Both network and CPU models have 'Lazy' as default optimization level\\n\\n\");\n      shall_exit = true;\n    } else if (parse_args && not strcmp(argv[i], \"--help-tracing\")) {\n      TRACE_help();\n      shall_exit = true;\n    } else {\n      argv[j++] = argv[i];\n    }\n  }\n  if (j < *argc) {\n    argv[j] = nullptr;\n    *argc = j;\n  }\n  if (shall_exit)\n    sg_cfg_exit_early();\n}\n\n/* callback of the plugin variable */\nstatic void _sg_cfg_cb__plugin(const std::string& value)\n{\n  xbt_assert(_sg_cfg_init_status < 2, \"Cannot load a plugin after the initialization\");\n\n  if (value.empty())\n    return;\n\n  if (value == \"help\") {\n    model_help(\"plugin\", surf_plugin_description);\n    sg_cfg_exit_early();\n  }\n\n  int plugin_id = find_model_description(surf_plugin_description, value);\n  surf_plugin_description[plugin_id].model_init_preparse();\n}\n\n/* callback of the host/model variable */\nstatic void _sg_cfg_cb__host_model(const std::string& value)\n{\n  xbt_assert(_sg_cfg_init_status < 2, \"Cannot change the model after the initialization\");\n\n  if (value == \"help\") {\n    model_help(\"host\", surf_host_model_description);\n    sg_cfg_exit_early();\n  }\n\n  /* Make sure that the model exists */\n  find_model_description(surf_host_model_description, value);\n}\n\n/* callback of the cpu/model variable */\nstatic void _sg_cfg_cb__cpu_model(const std::string& value)\n{\n  xbt_assert(_sg_cfg_init_status < 2, \"Cannot change the model after the initialization\");\n\n  if (value == \"help\") {\n    model_help(\"CPU\", surf_cpu_model_description);\n    sg_cfg_exit_early();\n  }\n\n  /* New Module missing */\n  find_model_description(surf_cpu_model_description, value);\n}\n\n/* callback of the cpu/model variable */\nstatic void _sg_cfg_cb__optimization_mode(const std::string& value)\n{\n  xbt_assert(_sg_cfg_init_status < 2, \"Cannot change the model after the initialization\");\n\n  if (value == \"help\") {\n    model_help(\"optimization\", surf_optimization_mode_description);\n    sg_cfg_exit_early();\n  }\n\n  /* New Module missing */\n  find_model_description(surf_optimization_mode_description, value);\n}\n\n/* callback of the cpu/model variable */\nstatic void _sg_cfg_cb__storage_mode(const std::string& value)\n{\n  xbt_assert(_sg_cfg_init_status < 2, \"Cannot change the model after the initialization\");\n\n  if (value == \"help\") {\n    model_help(\"storage\", surf_storage_model_description);\n    sg_cfg_exit_early();\n  }\n\n  find_model_description(surf_storage_model_description, value);\n}\n\n/* callback of the network_model variable */\nstatic void _sg_cfg_cb__network_model(const std::string& value)\n{\n  xbt_assert(_sg_cfg_init_status < 2, \"Cannot change the model after the initialization\");\n\n  if (value == \"help\") {\n    model_help(\"network\", surf_network_model_description);\n    sg_cfg_exit_early();\n  }\n\n  /* New Module missing */\n  find_model_description(surf_network_model_description, value);\n}\n\nstatic void _sg_cfg_cb_contexts_parallel_mode(const std::string& mode_name)\n{\n  if (mode_name == \"posix\") {\n    SIMIX_context_set_parallel_mode(XBT_PARMAP_POSIX);\n  } else if (mode_name == \"futex\") {\n    SIMIX_context_set_parallel_mode(XBT_PARMAP_FUTEX);\n  } else if (mode_name == \"busy_wait\") {\n    SIMIX_context_set_parallel_mode(XBT_PARMAP_BUSY_WAIT);\n  } else {\n    xbt_die(\"Command line setting of the parallel synchronization mode should \"\n            \"be one of \\\"posix\\\", \\\"futex\\\" or \\\"busy_wait\\\"\");\n  }\n}\n\n/* build description line with possible values */\nstatic void describe_model(char *result,int resultsize,\n                           const s_surf_model_description_t model_description[],\n                           const char *name,\n                           const char *description)\n{\n  result[0] = '\\0';\n  char *p = result;\n  p += snprintf(result,resultsize-1, \"%s. Possible values: %s\", description,\n            model_description[0].name ? model_description[0].name : \"n/a\");\n  for (int i = 1; model_description[i].name; i++)\n    p += snprintf(p,resultsize-(p-result)-1, \", %s\", model_description[i].name);\n  p += snprintf(p,resultsize-(p-result)-1, \".\\n       (use 'help' as a value to see the long description of each %s)\", name);\n\n  xbt_assert(p<result+resultsize-1,\"Buffer too small to display the model description of %s\",name);\n}\n\n/* create the config set, register what should be and parse the command line*/\nvoid sg_config_init(int *argc, char **argv)\n{\n  const int descsize = 1024;\n  char description[descsize];\n\n  /* Create the configuration support */\n  if (_sg_cfg_init_status != 0) { /* Only create stuff if not already inited */\n    XBT_WARN(\"Call to sg_config_init() after initialization ignored\");\n    return;\n  }\n\n  /* Plugins configuration */\n  describe_model(description, descsize, surf_plugin_description, \"plugin\", \"The plugins\");\n  simgrid::config::declare_flag<std::string>(\"plugin\", description, \"\", &_sg_cfg_cb__plugin);\n\n  describe_model(description, descsize, surf_cpu_model_description, \"model\", \"The model to use for the CPU\");\n  simgrid::config::declare_flag<std::string>(\"cpu/model\", description, \"Cas01\", &_sg_cfg_cb__cpu_model);\n\n  describe_model(description, descsize, surf_storage_model_description, \"model\", \"The model to use for the storage\");\n  simgrid::config::declare_flag<std::string>(\"storage/model\", description, \"default\", &_sg_cfg_cb__storage_mode);\n\n  describe_model(description, descsize, surf_network_model_description, \"model\", \"The model to use for the network\");\n  simgrid::config::declare_flag<std::string>(\"network/model\", description, \"LV08\", &_sg_cfg_cb__network_model);\n\n  describe_model(description, descsize, surf_optimization_mode_description, \"optimization mode\",\n                 \"The optimization modes to use for the network\");\n  simgrid::config::declare_flag<std::string>(\"network/optim\", description, \"Lazy\", &_sg_cfg_cb__optimization_mode);\n\n  describe_model(description, descsize, surf_host_model_description, \"model\", \"The model to use for the host\");\n  simgrid::config::declare_flag<std::string>(\"host/model\", description, \"default\", &_sg_cfg_cb__host_model);\n\n  simgrid::config::bind_flag(sg_surf_precision, \"surf/precision\",\n                             \"Numerical precision used when updating simulation times (in seconds)\");\n\n  simgrid::config::bind_flag(sg_maxmin_precision, \"maxmin/precision\",\n                             \"Numerical precision used when computing resource sharing (in flops/sec or bytes/sec)\");\n\n  simgrid::config::bind_flag(sg_concurrency_limit, \"maxmin/concurrency-limit\", {\"maxmin/concurrency_limit\"},\n                             \"Maximum number of concurrent variables in the maxmim system. Also limits the number of \"\n                             \"processes on each host, at higher level. (default: -1 means no such limitation)\");\n\n  /* The parameters of network models */\n\n  sg_latency_factor = 13.01; // comes from the default LV08 network model\n  simgrid::config::bind_flag(sg_latency_factor, \"network/latency-factor\", {\"network/latency_factor\"},\n                             \"Correction factor to apply to the provided latency (default value set by network model)\");\n\n  sg_bandwidth_factor = 0.97; // comes from the default LV08 network model\n  simgrid::config::bind_flag(\n      sg_bandwidth_factor, \"network/bandwidth-factor\", {\"network/bandwidth_factor\"},\n      \"Correction factor to apply to the provided bandwidth (default value set by network model)\");\n\n  sg_weight_S_parameter = 20537; // comes from the default LV08 network model\n  simgrid::config::bind_flag(\n      sg_weight_S_parameter, \"network/weight-S\", {\"network/weight_S\"},\n      \"Correction factor to apply to the weight of competing streams (default value set by network model)\");\n\n  /* Inclusion path */\n  simgrid::config::declare_flag<std::string>(\"path\", \"Lookup path for inclusions in platform and deployment XML files\",\n                                             \"\", [](std::string const& path) {\n                                               if (not path.empty())\n                                                 surf_path.push_back(path);\n                                             });\n\n  simgrid::config::declare_flag<bool>(\"cpu/maxmin-selective-update\",\n                                      \"Update the constraint set propagating recursively to others constraints \"\n                                      \"(off by default unless optim is set to lazy)\",\n                                      \"no\");\n  simgrid::config::alias(\"cpu/maxmin-selective-update\", {\"cpu/maxmin_selective_update\"});\n  simgrid::config::declare_flag<bool>(\"network/maxmin-selective-update\", \"Update the constraint set propagating \"\n                                                                         \"recursively to others constraints (off by \"\n                                                                         \"default unless optim is set to lazy)\",\n                                      \"no\");\n  simgrid::config::alias(\"network/maxmin-selective-update\", {\"network/maxmin_selective_update\"});\n\n  extern bool _sg_do_verbose_exit;\n  simgrid::config::bind_flag(_sg_do_verbose_exit, \"verbose-exit\", \"Activate the \\\"do nothing\\\" mode in Ctrl-C\");\n\n  simgrid::config::declare_flag<int>(\"contexts/stack-size\", \"Stack size of contexts in KiB\", 8 * 1024,\n                                     [](int value) { smx_context_stack_size = value * 1024; });\n  simgrid::config::alias(\"contexts/stack-size\", {\"contexts/stack_size\"});\n\n  /* guard size for contexts stacks in memory pages */\n#if defined(_WIN32) || (PTH_STACKGROWTH != -1)\n  int default_guard_size = 0;\n#else\n  int default_guard_size = 1;\n#endif\n  simgrid::config::declare_flag<int>(\"contexts/guard-size\", \"Guard size for contexts stacks in memory pages\",\n                                     default_guard_size,\n                                     [](int value) { smx_context_guard_size = value * xbt_pagesize; });\n  simgrid::config::alias(\"contexts/guard-size\", {\"contexts/guard_size\"});\n  simgrid::config::declare_flag<int>(\"contexts/nthreads\", \"Number of parallel threads used to execute user contexts\", 1,\n                                     &SIMIX_context_set_nthreads);\n\n  simgrid::config::declare_flag<int>(\"contexts/parallel-threshold\",\n                                     \"Minimal number of user contexts to be run in parallel (raw contexts only)\", 2,\n                                     &SIMIX_context_set_parallel_threshold);\n  simgrid::config::alias(\"contexts/parallel-threshold\", {\"contexts/parallel_threshold\"});\n\n  /* synchronization mode for parallel user contexts */\n#if HAVE_FUTEX_H\n  std::string default_synchro_mode = \"futex\";\n#else //No futex on mac and posix is unimplememted yet\n  std::string default_synchro_mode = \"busy_wait\";\n#endif\n  simgrid::config::declare_flag<std::string>(\"contexts/synchro\", \"Synchronization mode to use when running contexts in \"\n                                                                 \"parallel (either futex, posix or busy_wait)\",\n                                             default_synchro_mode, &_sg_cfg_cb_contexts_parallel_mode);\n\n  // For smpi/bw-factor and smpi/lat-factor\n  // SMPI model can be used without enable_smpi, so keep this out of the ifdef.\n  simgrid::config::declare_flag<std::string>(\"smpi/bw-factor\",\n                                             \"Bandwidth factors for smpi. Format: \"\n                                             \"'threshold0:value0;threshold1:value1;...;thresholdN:valueN', \"\n                                             \"meaning if(size >=thresholdN ) return valueN.\",\n                                             \"65472:0.940694;15424:0.697866;9376:0.58729;5776:1.08739;3484:0.77493;\"\n                                             \"1426:0.608902;732:0.341987;257:0.338112;0:0.812084\");\n  simgrid::config::alias(\"smpi/bw-factor\", {\"smpi/bw_factor\"});\n\n  simgrid::config::declare_flag<std::string>(\"smpi/lat-factor\", \"Latency factors for smpi.\",\n                                             \"65472:11.6436;15424:3.48845;9376:2.59299;5776:2.18796;3484:1.88101;\"\n                                             \"1426:1.61075;732:1.9503;257:1.95341;0:2.01467\");\n  simgrid::config::alias(\"smpi/lat-factor\", {\"smpi/lat_factor\"});\n  simgrid::config::declare_flag<std::string>(\"smpi/IB-penalty-factors\",\n                                             \"Correction factor to communications using Infiniband model with \"\n                                             \"contention (default value based on Stampede cluster profiling)\",\n                                             \"0.965;0.925;1.35\");\n  simgrid::config::alias(\"smpi/IB-penalty-factors\", {\"smpi/IB_penalty_factors\"});\n\n#if HAVE_SMPI\n  simgrid::config::declare_flag<double>(\"smpi/host-speed\", \"Speed of the host running the simulation (in flop/s). \"\n                                                           \"Used to bench the operations.\",\n                                        20000.0);\n  simgrid::config::alias(\"smpi/host-speed\", {\"smpi/running_power\", \"smpi/running-power\"});\n\n  simgrid::config::declare_flag<bool>(\"smpi/keep-temps\", \"Whether we should keep the generated temporary files.\",\n                                      false);\n\n  simgrid::config::declare_flag<bool>(\"smpi/display-timing\", \"Whether we should display the timing after simulation.\",\n                                      false);\n  simgrid::config::alias(\"smpi/display-timing\", {\"smpi/display_timing\"});\n\n  simgrid::config::declare_flag<bool>(\n      \"smpi/simulate-computation\", \"Whether the computational part of the simulated application should be simulated.\",\n      true);\n  simgrid::config::alias(\"smpi/simulate-computation\", {\"smpi/simulate_computation\"});\n\n  simgrid::config::declare_flag<std::string>(\n      \"smpi/shared-malloc\", \"Whether SMPI_SHARED_MALLOC is enabled. Disable it for debugging purposes.\", \"global\");\n  simgrid::config::alias(\"smpi/shared-malloc\", {\"smpi/use_shared_malloc\", \"smpi/use-shared-malloc\"});\n  simgrid::config::declare_flag<double>(\"smpi/shared-malloc-blocksize\",\n                                        \"Size of the bogus file which will be created for global shared allocations\",\n                                        1UL << 20);\n  simgrid::config::declare_flag<std::string>(\"smpi/shared-malloc-hugepage\",\n                                             \"Path to a mounted hugetlbfs, to use huge pages with shared malloc.\", \"\");\n\n  simgrid::config::declare_flag<double>(\n      \"smpi/cpu-threshold\", \"Minimal computation time (in seconds) not discarded, or -1 for infinity.\", 1e-6);\n  simgrid::config::alias(\"smpi/cpu-threshold\", {\"smpi/cpu_threshold\"});\n\n  simgrid::config::declare_flag<int>(\n      \"smpi/async-small-thresh\",\n      \"Maximal size of messages that are to be sent asynchronously, without waiting for the receiver\", 0);\n  simgrid::config::alias(\"smpi/async-small-thresh\", {\"smpi/async_small_thres\", \"smpi/async_small_thresh\"});\n\n  simgrid::config::declare_flag<bool>(\"smpi/trace-call-location\",\n                                      \"Should filename and linenumber of MPI calls be traced?\", false);\n\n  simgrid::config::declare_flag<int>(\n      \"smpi/send-is-detached-thresh\",\n      \"Threshold of message size where MPI_Send stops behaving like MPI_Isend and becomes MPI_Ssend\", 65536);\n  simgrid::config::alias(\"smpi/send-is-detached-thresh\",\n                         {\"smpi/send_is_detached_thres\", \"smpi/send_is_detached_thresh\"});\n\n  const char* default_privatization = std::getenv(\"SMPI_PRIVATIZATION\");\n  if (default_privatization == nullptr)\n    default_privatization = \"no\";\n\n  simgrid::config::declare_flag<std::string>(\n      \"smpi/privatization\", \"How we should privatize global variable at runtime (no, yes, mmap, dlopen).\",\n      default_privatization);\n  simgrid::config::alias(\"smpi/privatization\", {\"smpi/privatize_global_variables\", \"smpi/privatize-global-variables\"});\n\n  simgrid::config::declare_flag<std::string>(\n      \"smpi/privatize-libs\", \"Add libraries (; separated) to privatize (libgfortran for example). You need to provide the full names of the files (libgfortran.so.4), or its full path\", \"\");\n\n  simgrid::config::declare_flag<bool>(\"smpi/grow-injected-times\",\n                                      \"Whether we want to make the injected time in MPI_Iprobe and MPI_Test grow, to \"\n                                      \"allow faster simulation. This can make simulation less precise, though.\",\n                                      true);\n\n#if HAVE_PAPI\n  simgrid::config::declare_flag<std::string>(\"smpi/papi-events\",\n                                             \"This switch enables tracking the specified counters with PAPI\", \"\");\n#endif\n  simgrid::config::declare_flag<std::string>(\"smpi/comp-adjustment-file\",\n                                             \"A file containing speedups or slowdowns for some parts of the code.\", \"\");\n  simgrid::config::declare_flag<std::string>(\n      \"smpi/os\", \"Small messages timings (MPI_Send minimum time for small messages)\", \"0:0:0:0:0\");\n  simgrid::config::declare_flag<std::string>(\n      \"smpi/ois\", \"Small messages timings (MPI_Isend minimum time for small messages)\", \"0:0:0:0:0\");\n  simgrid::config::declare_flag<std::string>(\n      \"smpi/or\", \"Small messages timings (MPI_Recv minimum time for small messages)\", \"0:0:0:0:0\");\n\n  simgrid::config::declare_flag<double>(\"smpi/iprobe-cpu-usage\",\n                                        \"Maximum usage of CPUs by MPI_Iprobe() calls. We've observed that MPI_Iprobes \"\n                                        \"consume significantly less power than the maximum of a specific application. \"\n                                        \"This value is then (Iprobe_Usage/Max_Application_Usage).\",\n                                        1.0);\n\n  simgrid::config::declare_flag<std::string>(\"smpi/coll-selector\", \"Which collective selector to use\", \"default\");\n  simgrid::config::alias(\"smpi/coll-selector\", {\"smpi/coll_selector\"});\n  simgrid::config::declare_flag<std::string>(\"smpi/gather\", \"Which collective to use for gather\", \"\");\n  simgrid::config::declare_flag<std::string>(\"smpi/allgather\", \"Which collective to use for allgather\", \"\");\n  simgrid::config::declare_flag<std::string>(\"smpi/barrier\", \"Which collective to use for barrier\", \"\");\n  simgrid::config::declare_flag<std::string>(\"smpi/reduce_scatter\", \"Which collective to use for reduce_scatter\", \"\");\n  simgrid::config::alias(\"smpi/reduce_scatter\", {\"smpi/reduce-scatter\"});\n  simgrid::config::declare_flag<std::string>(\"smpi/scatter\", \"Which collective to use for scatter\", \"\");\n  simgrid::config::declare_flag<std::string>(\"smpi/allgatherv\", \"Which collective to use for allgatherv\", \"\");\n  simgrid::config::declare_flag<std::string>(\"smpi/allreduce\", \"Which collective to use for allreduce\", \"\");\n  simgrid::config::declare_flag<std::string>(\"smpi/alltoall\", \"Which collective to use for alltoall\", \"\");\n  simgrid::config::declare_flag<std::string>(\"smpi/alltoallv\", \"Which collective to use for alltoallv\", \"\");\n  simgrid::config::declare_flag<std::string>(\"smpi/bcast\", \"Which collective to use for bcast\", \"\");\n  simgrid::config::declare_flag<std::string>(\"smpi/reduce\", \"Which collective to use for reduce\", \"\");\n#endif // HAVE_SMPI\n\n  /* Others */\n\n  simgrid::config::declare_flag<bool>(\n      \"exception/cutpath\", \"Whether to cut all path information from call traces, used e.g. in exceptions.\", false);\n\n  extern bool _sg_do_clean_atexit;\n  simgrid::config::bind_flag(_sg_do_clean_atexit, \"clean-atexit\", {\"clean_atexit\"},\n                             \"Whether to cleanup SimGrid at exit. Disable it if your code segfaults after its end.\");\n\n  if (surf_path.empty())\n    simgrid::config::set_default<std::string>(\"path\", \"./\");\n\n  _sg_cfg_init_status = 1;\n\n  sg_config_cmd_line(argc, argv);\n\n  xbt_mallocator_initialization_is_done(SIMIX_context_is_parallel());\n}\n\nvoid sg_config_finalize()\n{\n  if (not _sg_cfg_init_status)\n    return;                     /* Not initialized yet. Nothing to do */\n\n  simgrid::config::finalize();\n  _sg_cfg_init_status = 0;\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.21-2jw7hfw3ki7yfy6d52vbzhst6fypdxym/spack-src/src/smpi/smpi_main.c": "/* Copyright (c) 2007-2018. The SimGrid Team. All rights reserved.          */\n\n/* This program is free software; you can redistribute it and/or modify it\n * under the terms of the license (GNU LGPL) which comes with this package. */\n\n#include <stdio.h>\n#include <stdlib.h>\n\n#include <smpi/smpi.h>\n\nint main(int argc, char **argv)\n{\n  if (getenv(\"SMPI_PRETEND_CC\") != NULL) {\n    /* Hack to ensure that smpicc can pretend to be a simple compiler. Particularly handy to pass it to the\n     * configuration tools. This one is used with dlopen privatization. */\n    return 0;\n  }\n\n  if (argc < 2) {\n    fprintf(stderr, \"Usage: smpimain <program to launch>\\n\");\n    exit(1);\n  }\n  return smpi_main(argv[1], argc - 1, argv + 1);\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.21-2jw7hfw3ki7yfy6d52vbzhst6fypdxym/spack-src/src/smpi/internals/smpi_global.cpp": "/* Copyright (c) 2007-2018. The SimGrid Team. All rights reserved.          */\n\n/* This program is free software; you can redistribute it and/or modify it\n * under the terms of the license (GNU LGPL) which comes with this package. */\n\n#include \"mc/mc.h\"\n#include \"simgrid/s4u/Engine.hpp\"\n#include \"smpi_coll.hpp\"\n#include \"smpi_f2c.hpp\"\n#include \"smpi_host.hpp\"\n#include \"src/kernel/activity/CommImpl.hpp\"\n#include \"src/simix/smx_private.hpp\"\n#include \"src/smpi/include/smpi_actor.hpp\"\n#include \"xbt/config.hpp\"\n\n#include <algorithm>\n#include <cfloat> /* DBL_MAX */\n#include <dlfcn.h>\n#include <fcntl.h>\n#include <fstream>\n\n#if not defined(__APPLE__)\n#include <link.h>\n#endif\n\n#if defined(__APPLE__)\n# include <AvailabilityMacros.h>\n# ifndef MAC_OS_X_VERSION_10_12\n#   define MAC_OS_X_VERSION_10_12 101200\n# endif\n# define HAVE_WORKING_MMAP (MAC_OS_X_VERSION_MIN_REQUIRED >= MAC_OS_X_VERSION_10_12)\n#elif defined(__FreeBSD__)\n# define HAVE_WORKING_MMAP 0\n#else\n# define HAVE_WORKING_MMAP 1\n#endif\n\n#if HAVE_SENDFILE\n#include <sys/sendfile.h>\n#endif\n\nXBT_LOG_NEW_DEFAULT_SUBCATEGORY(smpi_kernel, smpi, \"Logging specific to SMPI (kernel)\");\n#include <boost/tokenizer.hpp>\n#include <boost/algorithm/string.hpp> /* trim_right / trim_left */\n\n#if SMPI_IFORT\n  extern \"C\" void for_rtl_init_ (int *, char **);\n  extern \"C\" void for_rtl_finish_ ();\n#elif SMPI_FLANG\n  extern \"C\" void __io_set_argc(int);\n  extern \"C\" void __io_set_argv(char **);\n#elif SMPI_GFORTRAN\n  extern \"C\" void _gfortran_set_args(int, char **);\n#endif\n\n/* RTLD_DEEPBIND is a bad idea of GNU ld that obviously does not exist on other platforms\n * See https://www.akkadia.org/drepper/dsohowto.pdf\n * and https://lists.freebsd.org/pipermail/freebsd-current/2016-March/060284.html\n*/\n#if !defined(RTLD_DEEPBIND) || HAVE_SANITIZER_ADDRESS || HAVE_SANITIZER_THREAD\n#define WANT_RTLD_DEEPBIND 0\n#else\n#define WANT_RTLD_DEEPBIND RTLD_DEEPBIND\n#endif\n\n#if HAVE_PAPI\n#include \"papi.h\"\nstd::string papi_default_config_name = \"default\";\nstd::map</* computation unit name */ std::string, papi_process_data> units2papi_setup;\n#endif\n\nusing simgrid::s4u::Actor;\nusing simgrid::s4u::ActorPtr;\nstd::unordered_map<std::string, double> location2speedup;\n\nstatic std::map</*process_id*/ ActorPtr, simgrid::smpi::ActorExt*> process_data;\nint process_count = 0;\nstatic int smpi_exit_status = 0;\nint smpi_universe_size = 0;\nextern double smpi_total_benched_time;\nxbt_os_timer_t global_timer;\nstatic std::vector<std::string> privatize_libs_paths;\n/**\n * Setting MPI_COMM_WORLD to MPI_COMM_UNINITIALIZED (it's a variable)\n * is important because the implementation of MPI_Comm checks\n * \"this == MPI_COMM_UNINITIALIZED\"? If yes, it uses smpi_process()->comm_world()\n * instead of \"this\".\n * This is basically how we only have one global variable but all processes have\n * different communicators (the one their SMPI instance uses).\n *\n * See smpi_comm.cpp and the functions therein for details.\n */\nMPI_Comm MPI_COMM_WORLD = MPI_COMM_UNINITIALIZED;\nMPI_Errhandler *MPI_ERRORS_RETURN = nullptr;\nMPI_Errhandler *MPI_ERRORS_ARE_FATAL = nullptr;\nMPI_Errhandler *MPI_ERRHANDLER_NULL = nullptr;\n// No instance gets manually created; check also the smpirun.in script as\n// this default name is used there as well (when the <actor> tag is generated).\nstatic const std::string smpi_default_instance_name(\"smpirun\");\nstatic simgrid::config::Flag<double> smpi_init_sleep(\n  \"smpi/init\", \"Time to inject inside a call to MPI_Init\", 0.0);\n\nvoid (*smpi_comm_copy_data_callback) (smx_activity_t, void*, size_t) = &smpi_comm_copy_buffer_callback;\n\nint smpi_process_count()\n{\n  return process_count;\n}\n\nsimgrid::smpi::ActorExt* smpi_process()\n{\n  ActorPtr me = Actor::self();\n\n  if (me == nullptr) // This happens sometimes (eg, when linking against NS3 because it pulls openMPI...)\n    return nullptr;\n\n  return process_data.at(me);\n}\n\nsimgrid::smpi::ActorExt* smpi_process_remote(ActorPtr actor)\n{\n  return process_data.at(actor);\n}\n\nMPI_Comm smpi_process_comm_self(){\n  return smpi_process()->comm_self();\n}\n\nvoid smpi_process_init(int *argc, char ***argv){\n  simgrid::smpi::ActorExt::init(argc, argv);\n}\n\nint smpi_process_index(){\n  return simgrid::s4u::this_actor::get_pid();\n}\n\nvoid * smpi_process_get_user_data(){\n  return Actor::self()->get_impl()->get_user_data();\n}\n\nvoid smpi_process_set_user_data(void *data){\n  Actor::self()->get_impl()->set_user_data(data);\n}\n\n\nint smpi_global_size()\n{\n  char *value = getenv(\"SMPI_GLOBAL_SIZE\");\n  xbt_assert(value,\"Please set env var SMPI_GLOBAL_SIZE to the expected number of processes.\");\n\n  return xbt_str_parse_int(value, \"SMPI_GLOBAL_SIZE contains a non-numerical value: %s\");\n}\n\nvoid smpi_comm_set_copy_data_callback(void (*callback) (smx_activity_t, void*, size_t))\n{\n  smpi_comm_copy_data_callback = callback;\n}\n\nstatic void memcpy_private(void* dest, const void* src, std::vector<std::pair<size_t, size_t>>& private_blocks)\n{\n  for (auto const& block : private_blocks)\n    memcpy((uint8_t*)dest+block.first, (uint8_t*)src+block.first, block.second-block.first);\n}\n\nstatic void check_blocks(std::vector<std::pair<size_t, size_t>> &private_blocks, size_t buff_size) {\n  for (auto const& block : private_blocks)\n    xbt_assert(block.first <= block.second && block.second <= buff_size, \"Oops, bug in shared malloc.\");\n}\n\nvoid smpi_comm_copy_buffer_callback(smx_activity_t synchro, void *buff, size_t buff_size)\n{\n  simgrid::kernel::activity::CommImplPtr comm =\n      boost::dynamic_pointer_cast<simgrid::kernel::activity::CommImpl>(synchro);\n  int src_shared                        = 0;\n  int dst_shared                        = 0;\n  size_t src_offset                     = 0;\n  size_t dst_offset                     = 0;\n  std::vector<std::pair<size_t, size_t>> src_private_blocks;\n  std::vector<std::pair<size_t, size_t>> dst_private_blocks;\n  XBT_DEBUG(\"Copy the data over\");\n  if((src_shared=smpi_is_shared(buff, src_private_blocks, &src_offset))) {\n    XBT_DEBUG(\"Sender %p is shared. Let's ignore it.\", buff);\n    src_private_blocks = shift_and_frame_private_blocks(src_private_blocks, src_offset, buff_size);\n  }\n  else {\n    src_private_blocks.clear();\n    src_private_blocks.push_back(std::make_pair(0, buff_size));\n  }\n  if((dst_shared=smpi_is_shared((char*)comm->dst_buff, dst_private_blocks, &dst_offset))) {\n    XBT_DEBUG(\"Receiver %p is shared. Let's ignore it.\", (char*)comm->dst_buff);\n    dst_private_blocks = shift_and_frame_private_blocks(dst_private_blocks, dst_offset, buff_size);\n  }\n  else {\n    dst_private_blocks.clear();\n    dst_private_blocks.push_back(std::make_pair(0, buff_size));\n  }\n  check_blocks(src_private_blocks, buff_size);\n  check_blocks(dst_private_blocks, buff_size);\n  auto private_blocks = merge_private_blocks(src_private_blocks, dst_private_blocks);\n  check_blocks(private_blocks, buff_size);\n  void* tmpbuff=buff;\n  if ((smpi_privatize_global_variables == SmpiPrivStrategies::MMAP) &&\n      (static_cast<char*>(buff) >= smpi_data_exe_start) &&\n      (static_cast<char*>(buff) < smpi_data_exe_start + smpi_data_exe_size)) {\n    XBT_DEBUG(\"Privatization : We are copying from a zone inside global memory... Saving data to temp buffer !\");\n    smpi_switch_data_segment(comm->src_proc->iface());\n    tmpbuff = static_cast<void*>(xbt_malloc(buff_size));\n    memcpy_private(tmpbuff, buff, private_blocks);\n  }\n\n  if ((smpi_privatize_global_variables == SmpiPrivStrategies::MMAP) && ((char*)comm->dst_buff >= smpi_data_exe_start) &&\n      ((char*)comm->dst_buff < smpi_data_exe_start + smpi_data_exe_size)) {\n    XBT_DEBUG(\"Privatization : We are copying to a zone inside global memory - Switch data segment\");\n    smpi_switch_data_segment(comm->dst_proc->iface());\n  }\n  XBT_DEBUG(\"Copying %zu bytes from %p to %p\", buff_size, tmpbuff,comm->dst_buff);\n  memcpy_private(comm->dst_buff, tmpbuff, private_blocks);\n\n  if (comm->detached) {\n    // if this is a detached send, the source buffer was duplicated by SMPI\n    // sender to make the original buffer available to the application ASAP\n    xbt_free(buff);\n    //It seems that the request is used after the call there this should be free somewhere else but where???\n    //xbt_free(comm->comm.src_data);// inside SMPI the request is kept inside the user data and should be free\n    comm->src_buff = nullptr;\n  }\n  if (tmpbuff != buff)\n    xbt_free(tmpbuff);\n}\n\nvoid smpi_comm_null_copy_buffer_callback(smx_activity_t comm, void *buff, size_t buff_size)\n{\n  /* nothing done in this version */\n}\n\nstatic void smpi_check_options()\n{\n  //check correctness of MPI parameters\n\n  xbt_assert(simgrid::config::get_value<int>(\"smpi/async-small-thresh\") <=\n             simgrid::config::get_value<int>(\"smpi/send-is-detached-thresh\"));\n\n  if (simgrid::config::is_default(\"smpi/host-speed\")) {\n    XBT_INFO(\"You did not set the power of the host running the simulation.  \"\n             \"The timings will certainly not be accurate.  \"\n             \"Use the option \\\"--cfg=smpi/host-speed:<flops>\\\" to set its value.\"\n             \"Check http://simgrid.org/simgrid/latest/doc/options.html#options_smpi_bench for more information.\");\n  }\n\n  xbt_assert(simgrid::config::get_value<double>(\"smpi/cpu-threshold\") >= 0,\n             \"The 'smpi/cpu-threshold' option cannot have negative values [anymore]. If you want to discard \"\n             \"the simulation of any computation, please use 'smpi/simulate-computation:no' instead.\");\n}\n\nint smpi_enabled() {\n  return not process_data.empty();\n}\n\nvoid smpi_global_init()\n{\n  if (not MC_is_active()) {\n    global_timer = xbt_os_timer_new();\n    xbt_os_walltimer_start(global_timer);\n  }\n\n  std::string filename = simgrid::config::get_value<std::string>(\"smpi/comp-adjustment-file\");\n  if (not filename.empty()) {\n    std::ifstream fstream(filename);\n    if (not fstream.is_open()) {\n      xbt_die(\"Could not open file %s. Does it exist?\", filename.c_str());\n    }\n\n    std::string line;\n    typedef boost::tokenizer< boost::escaped_list_separator<char>> Tokenizer;\n    std::getline(fstream, line); // Skip the header line\n    while (std::getline(fstream, line)) {\n      Tokenizer tok(line);\n      Tokenizer::iterator it  = tok.begin();\n      Tokenizer::iterator end = std::next(tok.begin());\n\n      std::string location = *it;\n      boost::trim(location);\n      location2speedup.insert(std::pair<std::string, double>(location, std::stod(*end)));\n    }\n  }\n\n#if HAVE_PAPI\n  // This map holds for each computation unit (such as \"default\" or \"process1\" etc.)\n  // the configuration as given by the user (counter data as a pair of (counter_name, counter_counter))\n  // and the (computed) event_set.\n\n  if (not simgrid::config::get_value<std::string>(\"smpi/papi-events\").empty()) {\n    if (PAPI_library_init(PAPI_VER_CURRENT) != PAPI_VER_CURRENT)\n      XBT_ERROR(\"Could not initialize PAPI library; is it correctly installed and linked?\"\n                \" Expected version is %u\", PAPI_VER_CURRENT);\n\n    typedef boost::tokenizer<boost::char_separator<char>> Tokenizer;\n    boost::char_separator<char> separator_units(\";\");\n    std::string str = simgrid::config::get_value<std::string>(\"smpi/papi-events\");\n    Tokenizer tokens(str, separator_units);\n\n    // Iterate over all the computational units. This could be processes, hosts, threads, ranks... You name it.\n    // I'm not exactly sure what we will support eventually, so I'll leave it at the general term \"units\".\n    for (auto const& unit_it : tokens) {\n      boost::char_separator<char> separator_events(\":\");\n      Tokenizer event_tokens(unit_it, separator_events);\n\n      int event_set = PAPI_NULL;\n      if (PAPI_create_eventset(&event_set) != PAPI_OK) {\n        // TODO: Should this let the whole simulation die?\n        XBT_CRITICAL(\"Could not create PAPI event set during init.\");\n      }\n\n      // NOTE: We cannot use a map here, as we must obey the order of the counters\n      // This is important for PAPI: We need to map the values of counters back\n      // to the event_names (so, when PAPI_read() has finished)!\n      papi_counter_t counters2values;\n\n      // Iterate over all counters that were specified for this specific\n      // unit.\n      // Note that we need to remove the name of the unit\n      // (that could also be the \"default\" value), which always comes first.\n      // Hence, we start at ++(events.begin())!\n      for (Tokenizer::iterator events_it = ++(event_tokens.begin()); events_it != event_tokens.end(); ++events_it) {\n\n        int event_code   = PAPI_NULL;\n        char* event_name = const_cast<char*>((*events_it).c_str());\n        if (PAPI_event_name_to_code(event_name, &event_code) == PAPI_OK) {\n          if (PAPI_add_event(event_set, event_code) != PAPI_OK) {\n            XBT_ERROR(\"Could not add PAPI event '%s'. Skipping.\", event_name);\n            continue;\n          } else {\n            XBT_DEBUG(\"Successfully added PAPI event '%s' to the event set.\", event_name);\n          }\n        } else {\n          XBT_CRITICAL(\"Could not find PAPI event '%s'. Skipping.\", event_name);\n          continue;\n        }\n\n        counters2values.push_back(\n            // We cannot just pass *events_it, as this is of type const basic_string\n            std::make_pair<std::string, long long>(std::string(*events_it), 0));\n      }\n\n      std::string unit_name    = *(event_tokens.begin());\n      papi_process_data config = {.counter_data = std::move(counters2values), .event_set = event_set};\n\n      units2papi_setup.insert(std::make_pair(unit_name, std::move(config)));\n    }\n  }\n#endif\n}\n\nvoid smpi_global_destroy()\n{\n  smpi_bench_destroy();\n  smpi_shared_destroy();\n  smpi_deployment_cleanup_instances();\n\n  if (simgrid::smpi::Colls::smpi_coll_cleanup_callback != nullptr)\n    simgrid::smpi::Colls::smpi_coll_cleanup_callback();\n\n  MPI_COMM_WORLD = MPI_COMM_NULL;\n\n  if (not MC_is_active()) {\n    xbt_os_timer_free(global_timer);\n  }\n\n  if (smpi_privatize_global_variables == SmpiPrivStrategies::MMAP)\n    smpi_destroy_global_memory_segments();\n  smpi_free_static();\n  if(simgrid::smpi::F2C::lookup() != nullptr)\n    simgrid::smpi::F2C::delete_lookup();\n}\n\nstatic void smpi_init_options(){\n  // return if already called\n  if (smpi_cpu_threshold > -1)\n    return;\n  simgrid::smpi::Colls::set_collectives();\n  simgrid::smpi::Colls::smpi_coll_cleanup_callback = nullptr;\n  smpi_cpu_threshold                               = simgrid::config::get_value<double>(\"smpi/cpu-threshold\");\n  smpi_host_speed                                  = simgrid::config::get_value<double>(\"smpi/host-speed\");\n  xbt_assert(smpi_host_speed > 0.0, \"You're trying to set the host_speed to a non-positive value (given: %f)\", smpi_host_speed);\n  std::string smpi_privatize_option = simgrid::config::get_value<std::string>(\"smpi/privatization\");\n  if (smpi_privatize_option == \"no\" || smpi_privatize_option == \"0\")\n    smpi_privatize_global_variables = SmpiPrivStrategies::NONE;\n  else if (smpi_privatize_option == \"yes\" || smpi_privatize_option == \"1\")\n    smpi_privatize_global_variables = SmpiPrivStrategies::DEFAULT;\n  else if (smpi_privatize_option == \"mmap\")\n    smpi_privatize_global_variables = SmpiPrivStrategies::MMAP;\n  else if (smpi_privatize_option == \"dlopen\")\n    smpi_privatize_global_variables = SmpiPrivStrategies::DLOPEN;\n  else\n    xbt_die(\"Invalid value for smpi/privatization: '%s'\", smpi_privatize_option.c_str());\n\n  if (not SMPI_switch_data_segment) {\n    XBT_DEBUG(\"Running without smpi_main(); disable smpi/privatization.\");\n    smpi_privatize_global_variables = SmpiPrivStrategies::NONE;\n  }\n#if !HAVE_WORKING_MMAP\n  if (smpi_privatize_global_variables == SmpiPrivStrategies::MMAP) {\n    XBT_INFO(\"mmap privatization is broken on this platform, switching to dlopen privatization instead.\");\n    smpi_privatize_global_variables = SmpiPrivStrategies::DLOPEN;\n  }\n#endif\n\n  if (smpi_cpu_threshold < 0)\n    smpi_cpu_threshold = DBL_MAX;\n\n  std::string val = simgrid::config::get_value<std::string>(\"smpi/shared-malloc\");\n  if ((val == \"yes\") || (val == \"1\") || (val == \"on\") || (val == \"global\")) {\n    smpi_cfg_shared_malloc = SharedMallocType::GLOBAL;\n  } else if (val == \"local\") {\n    smpi_cfg_shared_malloc = SharedMallocType::LOCAL;\n  } else if ((val == \"no\") || (val == \"0\") || (val == \"off\")) {\n    smpi_cfg_shared_malloc = SharedMallocType::NONE;\n  } else {\n    xbt_die(\"Invalid value '%s' for option smpi/shared-malloc. Possible values: 'on' or 'global', 'local', 'off'\",\n            val.c_str());\n  }\n}\n\ntypedef std::function<int(int argc, char *argv[])> smpi_entry_point_type;\ntypedef int (* smpi_c_entry_point_type)(int argc, char **argv);\ntypedef void (*smpi_fortran_entry_point_type)();\n\nstatic int smpi_run_entry_point(smpi_entry_point_type entry_point, std::vector<std::string> args)\n{\n  // copy C strings, we need them writable\n  std::vector<char*>* args4argv = new std::vector<char*>(args.size());\n  std::transform(begin(args), end(args), begin(*args4argv), [](const std::string& s) { return xbt_strdup(s.c_str()); });\n\n#if !SMPI_IFORT\n  // take a copy of args4argv to keep reference of the allocated strings\n  const std::vector<char*> args2str(*args4argv);\n#endif\n  int argc = args4argv->size();\n  args4argv->push_back(nullptr);\n  char** argv = args4argv->data();\n\n  simgrid::smpi::ActorExt::init(&argc, &argv);\n#if SMPI_IFORT\n  for_rtl_init_ (&argc, argv);\n#elif SMPI_FLANG\n  __io_set_argc(argc);\n  __io_set_argv(argv);\n#elif SMPI_GFORTRAN\n  _gfortran_set_args(argc, argv);\n#endif \n  int res = entry_point(argc, argv);\n\n#if SMPI_IFORT\n  for_rtl_finish_ ();\n#else\n  for (char* s : args2str)\n    xbt_free(s);\n  delete args4argv;\n#endif\n\n  if (res != 0){\n    XBT_WARN(\"SMPI process did not return 0. Return value : %d\", res);\n    if (smpi_exit_status == 0)\n      smpi_exit_status = res;\n  }\n  return 0;\n}\n\n\n// TODO, remove the number of functions involved here\nstatic smpi_entry_point_type smpi_resolve_function(void* handle)\n{\n  smpi_fortran_entry_point_type entry_point_fortran = (smpi_fortran_entry_point_type)dlsym(handle, \"user_main_\");\n  if (entry_point_fortran != nullptr) {\n    return [entry_point_fortran](int argc, char** argv) {\n      entry_point_fortran();\n      return 0;\n    };\n  }\n\n  smpi_c_entry_point_type entry_point = (smpi_c_entry_point_type)dlsym(handle, \"main\");\n  if (entry_point != nullptr) {\n    return entry_point;\n  }\n\n  return smpi_entry_point_type();\n}\n\nstatic void smpi_copy_file(std::string src, std::string target, off_t fdin_size)\n{\n  int fdin = open(src.c_str(), O_RDONLY);\n  xbt_assert(fdin >= 0, \"Cannot read from %s. Please make sure that the file exists and is executable.\", src.c_str());\n  int fdout = open(target.c_str(), O_CREAT | O_RDWR, S_IRWXU);\n  xbt_assert(fdout >= 0, \"Cannot write into %s\", target.c_str());\n\n  XBT_DEBUG(\"Copy %ld bytes into %s\", static_cast<long>(fdin_size), target.c_str());\n#if HAVE_SENDFILE\n  ssize_t sent_size = sendfile(fdout, fdin, NULL, fdin_size);\n  xbt_assert(sent_size == fdin_size, \"Error while copying %s: only %zd bytes copied instead of %ld (errno: %d -- %s)\",\n             target.c_str(), sent_size, fdin_size, errno, strerror(errno));\n#else\n  const int bufsize = 1024 * 1024 * 4;\n  char buf[bufsize];\n  while (int got = read(fdin, buf, bufsize)) {\n    if (got == -1) {\n      xbt_assert(errno == EINTR, \"Cannot read from %s\", src.c_str());\n    } else {\n      char* p  = buf;\n      int todo = got;\n      while (int done = write(fdout, p, todo)) {\n        if (done == -1) {\n          xbt_assert(errno == EINTR, \"Cannot write into %s\", target.c_str());\n        } else {\n          p += done;\n          todo -= done;\n        }\n      }\n    }\n  }\n#endif\n  close(fdin);\n  close(fdout);\n}\n\n#if not defined(__APPLE__)\nstatic int visit_libs(struct dl_phdr_info* info, size_t, void* data)\n{\n  char* libname = (char*)(data);\n  const char *path = info->dlpi_name;\n  if(strstr(path, libname)){\n    strncpy(libname, path, 512);\n    return 1;\n  }\n  \n  return 0;\n}\n#endif\n\nstatic void smpi_init_privatization_dlopen(std::string executable)\n{\n  // Prepare the copy of the binary (get its size)\n  struct stat fdin_stat;\n  stat(executable.c_str(), &fdin_stat);\n  off_t fdin_size         = fdin_stat.st_size;\n  static std::size_t rank = 0;\n\n  std::string libnames = simgrid::config::get_value<std::string>(\"smpi/privatize-libs\");\n  if (not libnames.empty()) {\n    // split option\n    std::vector<std::string> privatize_libs;\n    boost::split(privatize_libs, libnames, boost::is_any_of(\";\"));\n\n    for (auto const& libname : privatize_libs) {\n      // load the library once to add it to the local libs, to get the absolute path\n      void* libhandle = dlopen(libname.c_str(), RTLD_LAZY);\n      // get library name from path\n      char fullpath[512] = {'\\0'};\n      strcpy(fullpath, libname.c_str());\n#if not defined(__APPLE__)\n      int ret = dl_iterate_phdr(visit_libs, fullpath);\n      if (ret == 0)\n        xbt_die(\"Can't find a linked %s - check the setting you gave to smpi/privatize-libs\", fullpath);\n      else\n        XBT_DEBUG(\"Extra lib to privatize found : %s\", fullpath);\n#else\n      xbt_die(\"smpi/privatize-libs is not (yet) compatible with OSX\");\n#endif\n      privatize_libs_paths.push_back(fullpath);\n      dlclose(libhandle);\n    }\n  }\n\n  simix_global->default_function = [executable, fdin_size](std::vector<std::string> args) {\n    return std::function<void()>([executable, fdin_size, args] {\n\n      // Copy the dynamic library:\n      std::string target_executable =\n          executable + \"_\" + std::to_string(getpid()) + \"_\" + std::to_string(rank) + \".so\";\n\n      smpi_copy_file(executable, target_executable, fdin_size);\n      // if smpi/privatize-libs is set, duplicate pointed lib and link each executable copy to a different one.\n      std::vector<std::string> target_libs;\n      for (auto const& libpath : privatize_libs_paths) {\n        // if we were given a full path, strip it\n        size_t index = libpath.find_last_of(\"/\\\\\");\n        std::string libname;\n        if (index != std::string::npos)\n          libname = libpath.substr(index + 1);\n\n        if (not libname.empty()) {\n          // load the library to add it to the local libs, to get the absolute path\n          struct stat fdin_stat2;\n          stat(libpath.c_str(), &fdin_stat2);\n          off_t fdin_size2 = fdin_stat2.st_size;\n\n          // Copy the dynamic library, the new name must be the same length as the old one\n          // just replace the name with 7 digits for the rank and the rest of the name.\n          unsigned int pad = 7;\n          if (libname.length() < pad)\n            pad = libname.length();\n          std::string target_lib =\n              std::string(pad - std::to_string(rank).length(), '0') + std::to_string(rank) + libname.substr(pad);\n          target_libs.push_back(target_lib);\n          XBT_DEBUG(\"copy lib %s to %s, with size %lld\", libpath.c_str(), target_lib.c_str(), (long long)fdin_size2);\n          smpi_copy_file(libpath, target_lib, fdin_size2);\n\n          std::string sedcommand = \"sed -i -e 's/\" + libname + \"/\" + target_lib + \"/g' \" + target_executable;\n          int ret                = system(sedcommand.c_str());\n          if (ret != 0)\n            xbt_die(\"error while applying sed command %s \\n\", sedcommand.c_str());\n        }\n      }\n\n      rank++;\n      // Load the copy and resolve the entry point:\n      void* handle    = dlopen(target_executable.c_str(), RTLD_LAZY | RTLD_LOCAL | WANT_RTLD_DEEPBIND);\n      int saved_errno = errno;\n      if (simgrid::config::get_value<bool>(\"smpi/keep-temps\") == false) {\n        unlink(target_executable.c_str());\n        for (const std::string& target_lib : target_libs)\n          unlink(target_lib.c_str());\n      }\n      if (handle == nullptr)\n        xbt_die(\"dlopen failed: %s (errno: %d -- %s)\", dlerror(), saved_errno, strerror(saved_errno));\n      smpi_entry_point_type entry_point = smpi_resolve_function(handle);\n      if (not entry_point)\n        xbt_die(\"Could not resolve entry point\");\n      smpi_run_entry_point(entry_point, args);\n    });\n  };\n}\n\nstatic void smpi_init_privatization_no_dlopen(std::string executable)\n{\n  if (smpi_privatize_global_variables == SmpiPrivStrategies::MMAP)\n    smpi_prepare_global_memory_segment();\n  // Load the dynamic library and resolve the entry point:\n  void* handle = dlopen(executable.c_str(), RTLD_LAZY | RTLD_LOCAL);\n  if (handle == nullptr)\n    xbt_die(\"dlopen failed for %s: %s (errno: %d -- %s)\", executable.c_str(), dlerror(), errno, strerror(errno));\n  smpi_entry_point_type entry_point = smpi_resolve_function(handle);\n  if (not entry_point)\n    xbt_die(\"main not found in %s\", executable.c_str());\n  if (smpi_privatize_global_variables == SmpiPrivStrategies::MMAP)\n    smpi_backup_global_memory_segment();\n\n  // Execute the same entry point for each simulated process:\n  simix_global->default_function = [entry_point](std::vector<std::string> args) {\n    return std::function<void()>([entry_point, args] { smpi_run_entry_point(entry_point, args); });\n  };\n}\n\nint smpi_main(const char* executable, int argc, char* argv[])\n{\n  srand(SMPI_RAND_SEED);\n\n  if (getenv(\"SMPI_PRETEND_CC\") != nullptr) {\n    /* Hack to ensure that smpicc can pretend to be a simple compiler. Particularly handy to pass it to the\n     * configuration tools */\n    return 0;\n  }\n\n  TRACE_global_init();\n  SIMIX_global_init(&argc, argv);\n\n  SMPI_switch_data_segment = &smpi_switch_data_segment;\n\n  // TODO This will not be executed in the case where smpi_main is not called,\n  // e.g., not for smpi_msg_masterslave. This should be moved to another location\n  // that is always called -- maybe close to Actor::on_creation?\n  simgrid::s4u::Host::on_creation.connect(\n      [](simgrid::s4u::Host& host) { host.extension_set(new simgrid::smpi::Host(&host)); });\n\n  // parse the platform file: get the host list\n  simgrid::s4u::Engine::get_instance()->load_platform(argv[1]);\n  SIMIX_comm_set_copy_data_callback(smpi_comm_copy_buffer_callback);\n\n  smpi_init_options();\n  if (smpi_privatize_global_variables == SmpiPrivStrategies::DLOPEN)\n    smpi_init_privatization_dlopen(executable);\n  else\n    smpi_init_privatization_no_dlopen(executable);\n\n  SMPI_init();\n  simgrid::s4u::Engine::get_instance()->load_deployment(argv[2]);\n  SMPI_app_instance_register(smpi_default_instance_name.c_str(), nullptr,\n                             process_data.size()); // This call has a side effect on process_count...\n  MPI_COMM_WORLD = *smpi_deployment_comm_world(smpi_default_instance_name);\n  smpi_universe_size = process_count;\n\n\n  /* Clean IO before the run */\n  fflush(stdout);\n  fflush(stderr);\n\n  if (MC_is_active()) {\n    MC_run();\n  } else {\n\n    SIMIX_run();\n\n    xbt_os_walltimer_stop(global_timer);\n    if (simgrid::config::get_value<bool>(\"smpi/display-timing\")) {\n      double global_time = xbt_os_timer_elapsed(global_timer);\n      XBT_INFO(\"Simulated time: %g seconds. \\n\\n\"\n          \"The simulation took %g seconds (after parsing and platform setup)\\n\"\n          \"%g seconds were actual computation of the application\",\n          SIMIX_get_clock(), global_time , smpi_total_benched_time);\n\n      if (smpi_total_benched_time/global_time>=0.75)\n      XBT_INFO(\"More than 75%% of the time was spent inside the application code.\\n\"\n      \"You may want to use sampling functions or trace replay to reduce this.\");\n    }\n  }\n  smpi_global_destroy();\n\n  return smpi_exit_status;\n}\n\n// Called either directly from the user code, or from the code called by smpirun\nvoid SMPI_init(){\n  simgrid::s4u::Actor::on_creation.connect([](simgrid::s4u::ActorPtr actor) {\n    if (not actor->is_daemon()) {\n      process_data.insert({actor, new simgrid::smpi::ActorExt(actor, nullptr)});\n    }\n  });\n  simgrid::s4u::Actor::on_destruction.connect([](simgrid::s4u::ActorPtr actor) {\n    auto it = process_data.find(actor);\n    if (it != process_data.end()) {\n      delete it->second;\n      process_data.erase(it);\n    }\n  });\n\n  smpi_init_options();\n  smpi_global_init();\n  smpi_check_options();\n}\n\nvoid SMPI_finalize(){\n  smpi_global_destroy();\n}\n\nvoid smpi_mpi_init() {\n  smpi_init_fortran_types();\n  if(smpi_init_sleep > 0)\n    simcall_process_sleep(smpi_init_sleep);\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.21-2jw7hfw3ki7yfy6d52vbzhst6fypdxym/spack-src/src/simix/smx_context.cpp": "/* a fast and simple context switching library                              */\n\n/* Copyright (c) 2009-2018. The SimGrid Team. All rights reserved.          */\n\n/* This program is free software; you can redistribute it and/or modify it\n * under the terms of the license (GNU LGPL) which comes with this package. */\n\n#include \"simgrid/modelchecker.h\"\n#include \"src/internal_config.h\"\n#include \"src/simix/smx_private.hpp\"\n#include \"xbt/config.hpp\"\n\n#include <thread>\n\n#ifdef _WIN32\n#include <windows.h>\n#include <malloc.h>\n#else\n#include <sys/mman.h>\n#endif\n\n#ifdef __MINGW32__\n#define _aligned_malloc __mingw_aligned_malloc\n#define _aligned_free  __mingw_aligned_free\n#endif /*MINGW*/\n\n#if HAVE_VALGRIND_H\n# include <valgrind/valgrind.h>\n#endif\n\nXBT_LOG_NEW_DEFAULT_SUBCATEGORY(simix_context, simix, \"Context switching mechanism\");\n\nstatic std::pair<const char*, simgrid::kernel::context::ContextFactoryInitializer> context_factories[] = {\n#if HAVE_RAW_CONTEXTS\n  { \"raw\", &simgrid::kernel::context::raw_factory },\n#endif\n#if HAVE_UCONTEXT_CONTEXTS\n  { \"ucontext\", &simgrid::kernel::context::sysv_factory },\n#endif\n#if HAVE_BOOST_CONTEXTS\n  { \"boost\", &simgrid::kernel::context::boost_factory },\n#endif\n#if HAVE_THREAD_CONTEXTS\n  { \"thread\", &simgrid::kernel::context::thread_factory },\n#endif\n};\n\nstatic_assert(sizeof(context_factories) != 0, \"No context factories are enabled for this build\");\n\n// Create the list of possible contexts:\nstatic inline\nstd::string contexts_list()\n{\n  std::string res;\n  const std::size_t n = sizeof(context_factories) / sizeof(context_factories[0]);\n  for (std::size_t i = 1; i != n; ++i) {\n    res += \", \";\n    res += context_factories[i].first;\n  }\n  return res;\n}\n\nstatic simgrid::config::Flag<std::string> context_factory_name(\n  \"contexts/factory\",\n  (std::string(\"Possible values: \")+contexts_list()).c_str(),\n  context_factories[0].first);\n\nunsigned smx_context_stack_size;\nint smx_context_stack_size_was_set = 0;\nunsigned smx_context_guard_size;\nint smx_context_guard_size_was_set = 0;\nstatic thread_local smx_context_t smx_current_context_parallel;\nstatic smx_context_t smx_current_context_serial;\nstatic int smx_parallel_contexts = 1;\nstatic int smx_parallel_threshold = 2;\nstatic e_xbt_parmap_mode_t smx_parallel_synchronization_mode = XBT_PARMAP_DEFAULT;\n\n/**\n * This function is called by SIMIX_global_init() to initialize the context module.\n */\nvoid SIMIX_context_mod_init()\n{\n  xbt_assert(simix_global->context_factory == nullptr);\n\n  smx_context_stack_size_was_set = not simgrid::config::is_default(\"contexts/stack-size\");\n  smx_context_guard_size_was_set = not simgrid::config::is_default(\"contexts/guard-size\");\n\n#if HAVE_SMPI && (defined(__APPLE__) || defined(__NetBSD__))\n  std::string priv = simgrid::config::get_value<std::string>(\"smpi/privatization\");\n  if (context_factory_name == \"thread\" && (priv == \"dlopen\" || priv == \"yes\" || priv == \"default\" || priv == \"1\")) {\n    XBT_WARN(\"dlopen+thread broken on Apple and BSD. Switching to raw contexts.\");\n    context_factory_name = \"raw\";\n  }\n#endif\n\n#if HAVE_SMPI && defined(__FreeBSD__)\n  if (context_factory_name == \"thread\" && simgrid::config::get_value<std::string>(\"smpi/privatization\") != \"no\") {\n    XBT_WARN(\"mmap broken on FreeBSD, but dlopen+thread broken too. Switching to dlopen+raw contexts.\");\n    context_factory_name = \"raw\";\n  }\n#endif\n\n  /* select the context factory to use to create the contexts */\n  if (simgrid::kernel::context::factory_initializer != nullptr) { // Give Java a chance to hijack the factory mechanism\n    simix_global->context_factory = simgrid::kernel::context::factory_initializer();\n    return;\n  }\n  /* use the factory specified by --cfg=contexts/factory:value */\n  for (auto const& factory : context_factories)\n    if (context_factory_name == factory.first) {\n      simix_global->context_factory = factory.second();\n      break;\n    }\n\n  if (simix_global->context_factory == nullptr) {\n    XBT_ERROR(\"Invalid context factory specified. Valid factories on this machine:\");\n#if HAVE_RAW_CONTEXTS\n    XBT_ERROR(\"  raw: high performance context factory implemented specifically for SimGrid\");\n#else\n    XBT_ERROR(\"  (raw contexts were disabled at compilation time on this machine -- check configure logs for details)\");\n#endif\n#if HAVE_UCONTEXT_CONTEXTS\n    XBT_ERROR(\"  ucontext: classical system V contexts (implemented with makecontext, swapcontext and friends)\");\n#else\n    XBT_ERROR(\"  (ucontext was disabled at compilation time on this machine -- check configure logs for details)\");\n#endif\n#if HAVE_BOOST_CONTEXTS\n    XBT_ERROR(\"  boost: this uses the boost libraries context implementation\");\n#else\n    XBT_ERROR(\"  (boost was disabled at compilation time on this machine -- check configure logs for details. Did you install the libboost-context-dev package?)\");\n#endif\n    XBT_ERROR(\"  thread: slow portability layer using pthreads as provided by gcc\");\n    xbt_die(\"Please use a valid factory.\");\n  }\n}\n\n/**\n * This function is called by SIMIX_clean() to finalize the context module.\n */\nvoid SIMIX_context_mod_exit()\n{\n  delete simix_global->context_factory;\n  simix_global->context_factory = nullptr;\n}\n\nvoid *SIMIX_context_stack_new()\n{\n  void *stack;\n\n  if (smx_context_guard_size > 0 && not MC_is_active()) {\n\n#if !defined(PTH_STACKGROWTH) || (PTH_STACKGROWTH != -1)\n    xbt_die(\"Stack overflow protection is known to be broken on your system: you stacks grow upwards (or detection is \"\n            \"broken). \"\n            \"Please disable stack guards with --cfg=contexts:guard-size:0\");\n    /* Current code for stack overflow protection assumes that stacks are growing downward (PTH_STACKGROWTH == -1).\n     * Protected pages need to be put after the stack when PTH_STACKGROWTH == 1. */\n#endif\n\n    size_t size = smx_context_stack_size + smx_context_guard_size;\n#if SIMGRID_HAVE_MC\n    /* Cannot use posix_memalign when SIMGRID_HAVE_MC. Align stack by hand, and save the\n     * pointer returned by xbt_malloc0. */\n    char *alloc = (char*)xbt_malloc0(size + xbt_pagesize);\n    stack = alloc - ((uintptr_t)alloc & (xbt_pagesize - 1)) + xbt_pagesize;\n    *((void **)stack - 1) = alloc;\n#elif !defined(_WIN32)\n    if (posix_memalign(&stack, xbt_pagesize, size) != 0)\n      xbt_die(\"Failed to allocate stack.\");\n#else\n    stack = _aligned_malloc(size, xbt_pagesize);\n#endif\n\n#ifndef _WIN32\n    if (mprotect(stack, smx_context_guard_size, PROT_NONE) == -1) {\n      xbt_die(\n          \"Failed to protect stack: %s.\\n\"\n          \"If you are running a lot of actors, you may be exceeding the amount of mappings allowed per process.\\n\"\n          \"On Linux systems, change this value with sudo sysctl -w vm.max_map_count=newvalue (default value: 65536)\\n\"\n          \"Please see http://simgrid.gforge.inria.fr/simgrid/latest/doc/html/options.html#options_virt for more info.\",\n          strerror(errno));\n      /* This is fatal. We are going to fail at some point when we try reusing this. */\n    }\n#endif\n    stack = (char *)stack + smx_context_guard_size;\n  } else {\n    stack = xbt_malloc0(smx_context_stack_size);\n  }\n\n#if HAVE_VALGRIND_H\n  unsigned int valgrind_stack_id = VALGRIND_STACK_REGISTER(stack, (char *)stack + smx_context_stack_size);\n  memcpy((char *)stack + smx_context_usable_stack_size, &valgrind_stack_id, sizeof valgrind_stack_id);\n#endif\n\n  return stack;\n}\n\nvoid SIMIX_context_stack_delete(void *stack)\n{\n  if (not stack)\n    return;\n\n#if HAVE_VALGRIND_H\n  unsigned int valgrind_stack_id;\n  memcpy(&valgrind_stack_id, (char *)stack + smx_context_usable_stack_size, sizeof valgrind_stack_id);\n  VALGRIND_STACK_DEREGISTER(valgrind_stack_id);\n#endif\n\n#ifndef _WIN32\n  if (smx_context_guard_size > 0 && not MC_is_active()) {\n    stack = (char *)stack - smx_context_guard_size;\n    if (mprotect(stack, smx_context_guard_size, PROT_READ | PROT_WRITE) == -1) {\n      XBT_WARN(\"Failed to remove page protection: %s\", strerror(errno));\n      /* try to pursue anyway */\n    }\n#if SIMGRID_HAVE_MC\n    /* Retrieve the saved pointer.  See SIMIX_context_stack_new above. */\n    stack = *((void **)stack - 1);\n#endif\n  }\n#endif /* not windows */\n\n  xbt_free(stack);\n}\n\n/** @brief Returns whether some parallel threads are used for the user contexts. */\nint SIMIX_context_is_parallel() {\n  return smx_parallel_contexts > 1;\n}\n\n/**\n * @brief Returns the number of parallel threads used for the user contexts.\n * @return the number of threads (1 means no parallelism)\n */\nint SIMIX_context_get_nthreads() {\n  return smx_parallel_contexts;\n}\n\n/**\n * @brief Sets the number of parallel threads to use\n * for the user contexts.\n *\n * This function should be called before initializing SIMIX.\n * A value of 1 means no parallelism (1 thread only).\n * If the value is greater than 1, the thread support must be enabled.\n *\n * @param nb_threads the number of threads to use\n */\nvoid SIMIX_context_set_nthreads(int nb_threads) {\n  if (nb_threads<=0) {\n    nb_threads = std::thread::hardware_concurrency();\n    XBT_INFO(\"Auto-setting contexts/nthreads to %d\", nb_threads);\n  }\n#if !HAVE_THREAD_CONTEXTS\n  xbt_assert(nb_threads == 1, \"Parallel runs are impossible when the pthreads are missing.\");\n#endif\n  smx_parallel_contexts = nb_threads;\n}\n\n/**\n * @brief Returns the threshold above which user processes are run in parallel.\n *\n * If the number of threads is set to 1, there is no parallelism and this\n * threshold has no effect.\n *\n * @return when the number of user processes ready to run is above\n * this threshold, they are run in parallel\n */\nint SIMIX_context_get_parallel_threshold() {\n  return smx_parallel_threshold;\n}\n\n/**\n * @brief Sets the threshold above which user processes are run in parallel.\n *\n * If the number of threads is set to 1, there is no parallelism and this\n * threshold has no effect.\n *\n * @param threshold when the number of user processes ready to run is above\n * this threshold, they are run in parallel\n */\nvoid SIMIX_context_set_parallel_threshold(int threshold) {\n  smx_parallel_threshold = threshold;\n}\n\n/**\n * @brief Returns the synchronization mode used when processes are run in\n * parallel.\n * @return how threads are synchronized if processes are run in parallel\n */\ne_xbt_parmap_mode_t SIMIX_context_get_parallel_mode() {\n  return smx_parallel_synchronization_mode;\n}\n\n/**\n * @brief Sets the synchronization mode to use when processes are run in\n * parallel.\n * @param mode how to synchronize threads if processes are run in parallel\n */\nvoid SIMIX_context_set_parallel_mode(e_xbt_parmap_mode_t mode) {\n  smx_parallel_synchronization_mode = mode;\n}\n\n/**\n * @brief Returns the current context of this thread.\n * @return the current context of this thread\n */\nsmx_context_t SIMIX_context_get_current()\n{\n  if (SIMIX_context_is_parallel()) {\n    return smx_current_context_parallel;\n  }\n  else {\n    return smx_current_context_serial;\n  }\n}\n\n/**\n * @brief Sets the current context of this thread.\n * @param context the context to set\n */\nvoid SIMIX_context_set_current(smx_context_t context)\n{\n  if (SIMIX_context_is_parallel()) {\n    smx_current_context_parallel = context;\n  }\n  else {\n    smx_current_context_serial = context;\n  }\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.21-2jw7hfw3ki7yfy6d52vbzhst6fypdxym/spack-src/teshsuite/smpi/CMakeLists.txt": "if(enable_smpi)\n  if(WIN32)\n    set(CMAKE_C_FLAGS \"-include ${CMAKE_HOME_DIRECTORY}/include/smpi/smpi_main.h\")\n  else()\n    set(CMAKE_C_COMPILER \"${CMAKE_BINARY_DIR}/smpi_script/bin/smpicc\")\n  endif()\n\n  include_directories(BEFORE \"${CMAKE_HOME_DIRECTORY}/include/smpi\")\n  foreach(x coll-allgather coll-allgatherv coll-allreduce coll-alltoall coll-alltoallv coll-barrier coll-bcast\n            coll-gather coll-reduce coll-reduce-scatter coll-scatter macro-sample pt2pt-dsend pt2pt-pingpong\n            type-hvector type-indexed type-struct type-vector bug-17132 timers privatization )\n    add_executable       (${x}  ${x}/${x}.c)\n    target_link_libraries(${x}  simgrid)\n    set_target_properties(${x}  PROPERTIES RUNTIME_OUTPUT_DIRECTORY ${CMAKE_CURRENT_BINARY_DIR}/${x})\n  endforeach()\n\n  if(NOT WIN32)\n    foreach(x macro-shared macro-partial-shared macro-partial-shared-communication )\n      add_executable       (${x}  ${x}/${x}.c)\n      target_link_libraries(${x}  simgrid)\n      set_target_properties(${x}  PROPERTIES RUNTIME_OUTPUT_DIRECTORY ${CMAKE_CURRENT_BINARY_DIR}/${x})\n    endforeach()\n  endif()\n\n  if(enable_smpi AND SMPI_FORTRAN)\n    set(CMAKE_Fortran_COMPILER \"${CMAKE_BINARY_DIR}/smpi_script/bin/smpif90\")\n    add_executable       (fort_args fort_args/fort_args.f90)\n    target_link_libraries(fort_args simgrid)\n    set_target_properties(fort_args PROPERTIES RUNTIME_OUTPUT_DIRECTORY ${CMAKE_CURRENT_BINARY_DIR}/fort_args)\n  endif()\nendif()\n\nforeach(x coll-allgather coll-allgatherv coll-allreduce coll-alltoall coll-alltoallv coll-barrier coll-bcast\n    coll-gather coll-reduce coll-reduce-scatter coll-scatter macro-sample pt2pt-dsend pt2pt-pingpong\n    type-hvector type-indexed type-struct type-vector bug-17132 timers privatization\n    macro-shared macro-partial-shared macro-partial-shared-communication)\n  set(tesh_files    ${tesh_files}    ${CMAKE_CURRENT_SOURCE_DIR}/${x}/${x}.tesh)\n  set(teshsuite_src ${teshsuite_src} ${CMAKE_CURRENT_SOURCE_DIR}/${x}/${x}.c)\nendforeach()\n\nset(teshsuite_src ${teshsuite_src} ${CMAKE_CURRENT_SOURCE_DIR}/fort_args/fort_args.f90 PARENT_SCOPE)\nset(tesh_files    ${tesh_files}     ${CMAKE_CURRENT_SOURCE_DIR}/coll-allreduce/coll-allreduce-large.tesh\n                                    ${CMAKE_CURRENT_SOURCE_DIR}/coll-allreduce/coll-allreduce-automatic.tesh\n                                    ${CMAKE_CURRENT_SOURCE_DIR}/coll-alltoall/clusters.tesh\n                                    ${CMAKE_CURRENT_SOURCE_DIR}/pt2pt-pingpong/broken_hostfiles.tesh\n                                    ${CMAKE_CURRENT_SOURCE_DIR}/pt2pt-pingpong/TI_output.tesh\n                                    ${CMAKE_CURRENT_SOURCE_DIR}/fort_args/fort_args.tesh  PARENT_SCOPE)\nset(bin_files       ${bin_files}    ${CMAKE_CURRENT_SOURCE_DIR}/hostfile\n                                    ${CMAKE_CURRENT_SOURCE_DIR}/hostfile_cluster\n                                    ${CMAKE_CURRENT_SOURCE_DIR}/hostfile_coll\n                                    ${CMAKE_CURRENT_SOURCE_DIR}/hostfile_empty  PARENT_SCOPE)\n\n\nif(enable_smpi)\n  if(NOT WIN32)\n    ADD_TESH_FACTORIES(tesh-smpi-macro-shared \"thread;ucontext;raw;boost\" --setenv platfdir=${CMAKE_HOME_DIRECTORY}/examples/platforms --setenv bindir=${CMAKE_BINARY_DIR}/teshsuite/smpi/macro-shared --cd ${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/macro-shared macro-shared.tesh)\n    ADD_TESH_FACTORIES(tesh-smpi-macro-partial-shared \"thread;ucontext;raw;boost\" --setenv platfdir=${CMAKE_HOME_DIRECTORY}/examples/platforms --setenv bindir=${CMAKE_BINARY_DIR}/teshsuite/smpi/macro-partial-shared --cd ${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/macro-partial-shared macro-partial-shared.tesh)\n    ADD_TESH_FACTORIES(tesh-smpi-macro-partial-shared-communication \"thread;ucontext;raw;boost\" --setenv platfdir=${CMAKE_HOME_DIRECTORY}/examples/platforms --setenv bindir=${CMAKE_BINARY_DIR}/teshsuite/smpi/macro-partial-shared-communication --cd ${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/macro-partial-shared-communication macro-partial-shared-communication.tesh)\n  endif()\n\n  foreach(x coll-allgather coll-allgatherv coll-allreduce coll-alltoall coll-alltoallv coll-barrier coll-bcast\n            coll-gather coll-reduce coll-reduce-scatter coll-scatter macro-sample pt2pt-dsend pt2pt-pingpong\n\t    type-hvector type-indexed type-struct type-vector bug-17132 timers)\n    ADD_TESH_FACTORIES(tesh-smpi-${x} \"thread;ucontext;raw;boost\" --setenv platfdir=${CMAKE_HOME_DIRECTORY}/examples/platforms --setenv srcdir=${CMAKE_HOME_DIRECTORY}/examples/platforms --setenv bindir=${CMAKE_BINARY_DIR}/teshsuite/smpi/${x} --cd ${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/${x} ${x}.tesh)\n  endforeach()\n\n  if(SMPI_FORTRAN)\n    ADD_TESH_FACTORIES(tesh-smpi-fort_args \"thread;ucontext;raw;boost\" --setenv platfdir=${CMAKE_HOME_DIRECTORY}/examples/platforms --setenv srcdir=${CMAKE_HOME_DIRECTORY}/examples/platforms --setenv bindir=${CMAKE_BINARY_DIR}/teshsuite/smpi/fort_args --cd ${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/fort_args fort_args.tesh)\n  endif()\n\n  foreach (ALLGATHER 2dmesh 3dmesh bruck GB loosely_lr NTSLR NTSLR_NB pair rdb  rhv ring SMP_NTS smp_simple spreading_simple\n                     ompi mpich ompi_neighborexchange mvapich2 mvapich2_smp impi)\n    ADD_TESH(tesh-smpi-coll-allgather-${ALLGATHER} --cfg smpi/allgather:${ALLGATHER} --setenv platfdir=${CMAKE_HOME_DIRECTORY}/examples/platforms --setenv bindir=${CMAKE_BINARY_DIR}/teshsuite/smpi/coll-allgather --cd ${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/coll-allgather coll-allgather.tesh)\n  endforeach()\n\n  foreach (ALLGATHERV GB pair ring ompi mpich ompi_neighborexchange ompi_bruck mpich_rdb mpich_ring mvapich2 impi)\n    ADD_TESH(tesh-smpi-coll-allgatherv-${ALLGATHERV} --cfg smpi/allgatherv:${ALLGATHERV} --setenv platfdir=${CMAKE_HOME_DIRECTORY}/examples/platforms --setenv bindir=${CMAKE_BINARY_DIR}/teshsuite/smpi/coll-allgatherv --cd ${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/coll-allgatherv coll-allgatherv.tesh)\n  endforeach()\n\n  foreach (ALLREDUCE lr rab1 rab2 rab_rdb rdb smp_binomial smp_binomial_pipeline smp_rdb smp_rsag smp_rsag_lr impi\n                     smp_rsag_rab redbcast ompi mpich ompi_ring_segmented mvapich2 mvapich2_rs mvapich2_two_level)\n    ADD_TESH(tesh-smpi-coll-allreduce-${ALLREDUCE} --cfg smpi/allreduce:${ALLREDUCE} --setenv platfdir=${CMAKE_HOME_DIRECTORY}/examples/platforms --setenv bindir=${CMAKE_BINARY_DIR}/teshsuite/smpi/coll-allreduce --cd ${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/coll-allreduce coll-allreduce.tesh)\n  endforeach()\n\n  foreach (ALLTOALL 2dmesh 3dmesh pair pair_rma pair_one_barrier pair_light_barrier pair_mpi_barrier rdb ring\n                    ring_light_barrier ring_mpi_barrier ring_one_barrier bruck basic_linear ompi mpich mvapich2\n                    mvapich2_scatter_dest impi)\n    ADD_TESH(tesh-smpi-coll-alltoall-${ALLTOALL} --cfg smpi/alltoall:${ALLTOALL} --setenv platfdir=${CMAKE_HOME_DIRECTORY}/examples/platforms --setenv bindir=${CMAKE_BINARY_DIR}/teshsuite/smpi/coll-alltoall --cd ${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/coll-alltoall coll-alltoall.tesh)\n  endforeach()\n\n  foreach (ALLTOALLV pair pair_light_barrier pair_mpi_barrier pair_one_barrier  ring ring_light_barrier ring_mpi_barrier\n                     ring_one_barrier bruck ompi mpich mvapich2 ompi_basic_linear impi)\n    ADD_TESH(tesh-smpi-coll-alltoallv-${ALLTOALLV} --cfg smpi/alltoallv:${ALLTOALLV} --setenv platfdir=${CMAKE_HOME_DIRECTORY}/examples/platforms --setenv bindir=${CMAKE_BINARY_DIR}/teshsuite/smpi/coll-alltoallv --cd ${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/coll-alltoallv coll-alltoallv.tesh)\n  endforeach()\n\n  foreach (BARRIER ompi mpich mpich_smp ompi_basic_linear ompi_tree ompi_bruck ompi_recursivedoubling ompi_doublering mvapich2_pair mvapich2 impi)\n      ADD_TESH(tesh-smpi-coll-barrier-${BARRIER} --cfg smpi/barrier:${BARRIER} --setenv platfdir=${CMAKE_HOME_DIRECTORY}/examples/platforms --setenv bindir=${CMAKE_BINARY_DIR}/teshsuite/smpi/coll-barrier --cd ${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/coll-barrier coll-barrier.tesh)\n  endforeach()\n\n  foreach (BCAST arrival_pattern_aware arrival_pattern_aware_wait arrival_scatter binomial_tree flattree\n                 flattree_pipeline NTSB NTSL NTSL_Isend scatter_LR_allgather scatter_rdb_allgather SMP_binary\n                 SMP_binomial SMP_linear ompi mpich ompi_split_bintree ompi_pipeline mvapich2 mvapich2_intra_node\n                 mvapich2_knomial_intra_node impi)\n    ADD_TESH(tesh-smpi-coll-bcast-${BCAST} --cfg smpi/bcast:${BCAST} --setenv platfdir=${CMAKE_HOME_DIRECTORY}/examples/platforms --setenv bindir=${CMAKE_BINARY_DIR}/teshsuite/smpi/coll-bcast --cd ${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/coll-bcast coll-bcast.tesh)\n  endforeach()\n\n  foreach (GATHER ompi mpich ompi_basic_linear ompi_linear_sync ompi_binomial mvapich2 mvapich2_two_level impi)\n    ADD_TESH(tesh-smpi-coll-gather-${GATHER} --cfg smpi/gather:${GATHER} --setenv platfdir=${CMAKE_HOME_DIRECTORY}/examples/platforms --setenv bindir=${CMAKE_BINARY_DIR}/teshsuite/smpi/coll-gather --cd ${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/coll-gather coll-gather.tesh)\n  endforeach()\n\n  foreach (REDUCE arrival_pattern_aware binomial flat_tree NTSL scatter_gather ompi mpich ompi_chain ompi_binary impi\n                  ompi_basic_linear ompi_binomial ompi_in_order_binary mvapich2 mvapich2_knomial mvapich2_two_level rab)\n    ADD_TESH(tesh-smpi-coll-reduce-${REDUCE} --cfg smpi/reduce:${REDUCE} --setenv platfdir=${CMAKE_HOME_DIRECTORY}/examples/platforms --setenv bindir=${CMAKE_BINARY_DIR}/teshsuite/smpi/coll-reduce --cd ${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/coll-reduce coll-reduce.tesh)\n  endforeach()\n\n  foreach (REDUCE_SCATTER ompi mpich ompi_basic_recursivehalving ompi_ring mpich_noncomm mpich_pair mvapich2 mpich_rdb impi)\n    ADD_TESH(tesh-smpi-coll-reduce-scatter-${REDUCE_SCATTER} --cfg smpi/reduce_scatter:${REDUCE_SCATTER} --setenv platfdir=${CMAKE_HOME_DIRECTORY}/examples/platforms --setenv bindir=${CMAKE_BINARY_DIR}/teshsuite/smpi/coll-reduce-scatter --cd ${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/coll-reduce-scatter coll-reduce-scatter.tesh)\n  endforeach()\n\n  foreach (SCATTER ompi mpich ompi_basic_linear ompi_binomial mvapich2 mvapich2_two_level_binomial mvapich2_two_level_direct impi)\n    ADD_TESH(tesh-smpi-coll-scatter-${SCATTER} --cfg smpi/scatter:${SCATTER} --setenv platfdir=${CMAKE_HOME_DIRECTORY}/examples/platforms --setenv bindir=${CMAKE_BINARY_DIR}/teshsuite/smpi/coll-scatter --cd ${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/coll-scatter coll-scatter.tesh)\n  endforeach()\n\n  # Extra allreduce test: large automatic\n  ADD_TESH(tesh-smpi-coll-allreduce-large --cfg smpi/allreduce:ompi_ring_segmented --setenv platfdir=${CMAKE_HOME_DIRECTORY}/examples/platforms --setenv bindir=${CMAKE_BINARY_DIR}/teshsuite/smpi/coll-allreduce --cd ${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/coll-allreduce coll-allreduce-large.tesh)\n  ADD_TESH(tesh-smpi-coll-allreduce-automatic --setenv platfdir=${CMAKE_HOME_DIRECTORY}/examples/platforms --setenv bindir=${CMAKE_BINARY_DIR}/teshsuite/smpi/coll-allreduce --cd ${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/coll-allreduce coll-allreduce-automatic.tesh)\n\n  # Extra allreduce test: cluster-types\n  ADD_TESH(tesh-smpi-cluster-types --cfg smpi/alltoall:mvapich2 --setenv platfdir=${CMAKE_HOME_DIRECTORY}/examples/platforms --setenv bindir=${CMAKE_BINARY_DIR}/teshsuite/smpi/coll-alltoall --cd ${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/coll-alltoall clusters.tesh)\n\n  # Extra pt2pt pingpong test: broken usage ti-tracing\n  ADD_TESH_FACTORIES(tesh-smpi-broken  \"thread\"   --setenv platfdir=${CMAKE_HOME_DIRECTORY}/examples/platforms --setenv bindir=${CMAKE_BINARY_DIR}/teshsuite/smpi/pt2pt-pingpong --cd ${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/pt2pt-pingpong broken_hostfiles.tesh)\n  ADD_TESH(tesh-smpi-replay-ti-tracing            --setenv platfdir=${CMAKE_HOME_DIRECTORY}/examples/platforms --setenv srcdir=${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/pt2pt-pingpong --cd ${CMAKE_BINARY_DIR}/teshsuite/smpi/pt2pt-pingpong ${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/pt2pt-pingpong/TI_output.tesh)\n\n  # Simple privatization tests\n  if(HAVE_PRIVATIZATION)\n    foreach(PRIVATIZATION dlopen mmap)\n      ADD_TESH_FACTORIES(tesh-smpi-privatization-${PRIVATIZATION}  \"thread;ucontext;raw;boost\" --setenv privatization=${PRIVATIZATION} --setenv platfdir=${CMAKE_HOME_DIRECTORY}/examples/platforms --setenv bindir=${CMAKE_BINARY_DIR}/teshsuite/smpi/privatization --cd ${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/privatization privatization.tesh)\n    endforeach()\n  endif()\nendif()\n",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.21-2jw7hfw3ki7yfy6d52vbzhst6fypdxym/spack-src/teshsuite/smpi/mpich3-test/coll/CMakeLists.txt": "if(enable_smpi AND enable_smpi_MPICH3_testsuite)\n  if(WIN32)\n    set(CMAKE_C_FLAGS \"-include ${CMAKE_HOME_DIRECTORY}/include/smpi/smpi_main.h\")\n  else()\n    set(CMAKE_C_COMPILER \"${CMAKE_BINARY_DIR}/smpi_script/bin/smpicc\")\n    set(CMAKE_Fortran_COMPILER \"${CMAKE_BINARY_DIR}/smpi_script/bin/smpiff\")\n  endif()\n\n  include_directories(BEFORE \"${CMAKE_HOME_DIRECTORY}/include/smpi\")\n  include_directories(\"${CMAKE_CURRENT_SOURCE_DIR}/../include/\")\n\n  add_executable(allgather2 allgather2.c)\n  add_executable(allgather3 allgather3.c)\n  add_executable(allgather_struct allgather_struct.c)\n  add_executable(allgatherv2 allgatherv2.c)\n  add_executable(allgatherv3 allgatherv3.c)\n  if(HAVE_PRIVATIZATION)\n    add_executable(allgatherv4 allgatherv4.c)\n  else()\n    add_executable(allgatherv4 allgatherv4_manual.c)\n  endif()\n  add_executable(allred2 allred2.c)\n  add_executable(allred3 allred3.c)\n  add_executable(allred4 allred4.c)\n  add_executable(allred5 allred5.c)\n  add_executable(allred6 allred6.c)\n  if(HAVE_PRIVATIZATION)\n    add_executable(allred allred.c)\n  else()\n    add_executable(allred allred_manual.c)\n  endif()\n  add_executable(allredmany allredmany.c)\n  add_executable(alltoall1 alltoall1.c)\n  add_executable(alltoallv0 alltoallv0.c)\n  add_executable(alltoallv alltoallv.c)\n#  add_executable(alltoallw1 alltoallw1.c)\n#  add_executable(alltoallw2 alltoallw2.c)\n#  add_executable(alltoallw_zeros alltoallw_zeros.c)\n  add_executable(bcast_full bcast.c)\n  add_executable(bcast_min_datatypes bcast.c)\n  add_executable(bcast_comm_world bcast.c)\n  add_executable(bcasttest bcasttest.c)\n  add_executable(bcastzerotype bcastzerotype.c)\n  add_executable(coll10 coll10.c)\n  add_executable(coll11 coll11.c)\n  add_executable(coll12 coll12.c)\n  add_executable(coll13 coll13.c)\n  add_executable(coll2 coll2.c)\n  add_executable(coll3 coll3.c)\n  add_executable(coll4 coll4.c)\n  add_executable(coll5 coll5.c)\n  add_executable(coll6 coll6.c)\n  add_executable(coll7 coll7.c)\n  add_executable(coll8 coll8.c)\n  add_executable(coll9 coll9.c)\n  add_executable(exscan2 exscan2.c)\n  add_executable(exscan exscan.c)\n  add_executable(gather2 gather2.c)\n  add_executable(gather_big gather_big.c)\n  add_executable(gather gather.c)\n#  add_executable(iallred iallred.c)\n#  add_executable(ibarrier ibarrier.c)\n#  add_executable(icallgather icallgather.c)\n#  add_executable(icallgatherv icallgatherv.c)\n#  add_executable(icallreduce icallreduce.c)\n#  add_executable(icalltoall icalltoall.c)\n#  add_executable(icalltoallv icalltoallv.c)\n#  add_executable(icalltoallw icalltoallw.c)\n#  add_executable(icbarrier icbarrier.c)\n#  add_executable(icbcast icbcast.c)\n#  add_executable(icgather icgather.c)\n#  add_executable(icgatherv icgatherv.c)\n#  add_executable(icreduce icreduce.c)\n#  add_executable(icscatter icscatter.c)\n#  add_executable(icscatterv icscatterv.c)\n  add_executable(longuser longuser.c)\n#  add_executable(nonblocking2 nonblocking2.c)\n#  add_executable(nonblocking3 nonblocking3.c)\n#  add_executable(nonblocking nonblocking.c)\n#  add_executable(opband opband.c)\n#  add_executable(opbor opbor.c)\n#  add_executable(opbxor opbxor.c)\n  add_executable(op_commutative op_commutative.c)\n#  add_executable(opland opland.c)\n#  add_executable(oplor oplor.c)\n#  add_executable(oplxor oplxor.c)\n#  add_executable(opmax opmax.c)\n#  add_executable(opmaxloc opmaxloc.c)\n#  add_executable(opmin opmin.c)\n#  add_executable(opminloc opminloc.c)\n#  add_executable(opprod opprod.c)\n#  add_executable(opsum opsum.c)\n  add_executable(red3 red3.c)\n  add_executable(red4 red4.c)\n  add_executable(redscat2 redscat2.c)\n  add_executable(redscat3 redscat3.c)\n  add_executable(redscatbkinter redscatbkinter.c)\n  add_executable(redscatblk3 redscatblk3.c)\n  add_executable(red_scat_block2 red_scat_block2.c)\n  add_executable(red_scat_block red_scat_block.c)\n  add_executable(redscat redscat.c)\n#  add_executable(redscatinter redscatinter.c)\n  add_executable(reduce_mpich reduce.c)\n  add_executable(reduce_local reduce_local.c)\n  add_executable(scantst scantst.c)\n  add_executable(scatter2 scatter2.c)\n  add_executable(scatter3 scatter3.c)\n  add_executable(scattern scattern.c)\n  add_executable(scatterv scatterv.c)\n#  add_executable(uoplong uoplong.c)\n\n  target_link_libraries(allgather2  simgrid mtest_c)\n  target_link_libraries(allgather3  simgrid mtest_c)\n  target_link_libraries(allgather_struct  simgrid mtest_c)\n  target_link_libraries(allgatherv2  simgrid mtest_c)\n  target_link_libraries(allgatherv3  simgrid mtest_c)\n  target_link_libraries(allgatherv4  simgrid mtest_c)\n  target_link_libraries(allred2  simgrid mtest_c)\n  target_link_libraries(allred3  simgrid mtest_c)\n  target_link_libraries(allred4  simgrid mtest_c)\n  target_link_libraries(allred5  simgrid mtest_c)\n  target_link_libraries(allred6  simgrid mtest_c)\n  target_link_libraries(allred  simgrid mtest_c)\n  target_link_libraries(allredmany  simgrid mtest_c)\n  target_link_libraries(alltoall1  simgrid mtest_c)\n  target_link_libraries(alltoallv0  simgrid mtest_c)\n  target_link_libraries(alltoallv  simgrid mtest_c)\n#  target_link_libraries(alltoallw1  simgrid mtest_c)\n#  target_link_libraries(alltoallw2  simgrid mtest_c)\n#  target_link_libraries(alltoallw_zeros  simgrid mtest_c)\n  target_link_libraries(bcast_full  simgrid mtest_c)\n  target_link_libraries(bcast_min_datatypes  simgrid mtest_c)\n  target_link_libraries(bcast_comm_world  simgrid mtest_c)\n  target_link_libraries(bcasttest  simgrid mtest_c)\n  target_link_libraries(bcastzerotype  simgrid mtest_c)\n  target_link_libraries(coll10  simgrid mtest_c)\n  target_link_libraries(coll11  simgrid mtest_c)\n  target_link_libraries(coll12  simgrid mtest_c)\n  target_link_libraries(coll13  simgrid mtest_c)\n  target_link_libraries(coll2  simgrid mtest_c)\n  target_link_libraries(coll3  simgrid mtest_c)\n  target_link_libraries(coll4  simgrid mtest_c)\n  target_link_libraries(coll5  simgrid mtest_c)\n  target_link_libraries(coll6  simgrid mtest_c)\n  target_link_libraries(coll7  simgrid mtest_c)\n  target_link_libraries(coll8  simgrid mtest_c)\n  target_link_libraries(coll9  simgrid mtest_c)\n  target_link_libraries(exscan2  simgrid mtest_c)\n  target_link_libraries(exscan  simgrid mtest_c)\n  target_link_libraries(gather2  simgrid mtest_c)\n  target_link_libraries(gather_big  simgrid mtest_c)\n  target_link_libraries(gather  simgrid mtest_c)\n#  target_link_libraries(iallred  simgrid mtest_c)\n#  target_link_libraries(ibarrier  simgrid mtest_c)\n#  target_link_libraries(icallgather  simgrid mtest_c)\n#  target_link_libraries(icallgatherv  simgrid mtest_c)\n#  target_link_libraries(icallreduce  simgrid mtest_c)\n#  target_link_libraries(icalltoall  simgrid mtest_c)\n#  target_link_libraries(icalltoallv  simgrid mtest_c)\n#  target_link_libraries(icalltoallw  simgrid mtest_c)\n#  target_link_libraries(icbarrier  simgrid mtest_c)\n#  target_link_libraries(icbcast  simgrid mtest_c)\n#  target_link_libraries(icgather  simgrid mtest_c)\n#  target_link_libraries(icgatherv  simgrid mtest_c)\n#  target_link_libraries(icreduce  simgrid mtest_c)\n#  target_link_libraries(icscatter  simgrid mtest_c)\n#  target_link_libraries(icscatterv  simgrid mtest_c)\n  target_link_libraries(longuser  simgrid mtest_c)\n#  target_link_libraries(nonblocking2  simgrid mtest_c)\n#  target_link_libraries(nonblocking3  simgrid mtest_c)\n#  target_link_libraries(nonblocking  simgrid mtest_c)\n#  target_link_libraries(opband  simgrid mtest_c)\n#  target_link_libraries(opbor  simgrid mtest_c)\n#  target_link_libraries(opbxor  simgrid mtest_c)\n  target_link_libraries(op_commutative  simgrid mtest_c)\n#  target_link_libraries(opland  simgrid mtest_c)\n#  target_link_libraries(oplor  simgrid mtest_c)\n#  target_link_libraries(oplxor  simgrid mtest_c)\n#  target_link_libraries(opmax  simgrid mtest_c)\n#  target_link_libraries(opmaxloc  simgrid mtest_c)\n#  target_link_libraries(opmin  simgrid mtest_c)\n#  target_link_libraries(opminloc  simgrid mtest_c)\n#  target_link_libraries(opprod  simgrid mtest_c)\n#  target_link_libraries(opsum  simgrid mtest_c)\n  target_link_libraries(red3  simgrid mtest_c)\n  target_link_libraries(red4  simgrid mtest_c)\n  target_link_libraries(redscat2  simgrid mtest_c)\n  target_link_libraries(redscat3  simgrid mtest_c)\n  target_link_libraries(redscatbkinter  simgrid mtest_c)\n  target_link_libraries(redscatblk3  simgrid mtest_c)\n  target_link_libraries(red_scat_block2  simgrid mtest_c)\n  target_link_libraries(red_scat_block  simgrid mtest_c)\n  target_link_libraries(redscat  simgrid mtest_c)\n#  target_link_libraries(redscatinter  simgrid mtest_c)\n  target_link_libraries(reduce_mpich  simgrid mtest_c)\n  target_link_libraries(reduce_local  simgrid mtest_c)\n  target_link_libraries(scantst  simgrid mtest_c)\n  target_link_libraries(scatter2  simgrid mtest_c)\n  target_link_libraries(scatter3  simgrid mtest_c)\n  target_link_libraries(scattern  simgrid mtest_c)\n  target_link_libraries(scatterv  simgrid mtest_c)\n#  target_link_libraries(uoplong  simgrid mtest_c)\n\n  set_target_properties(allred PROPERTIES COMPILE_FLAGS \"-O0\" LINK_FLAGS \"-O0\")\n  set_target_properties(bcast_min_datatypes PROPERTIES COMPILE_FLAGS \"-DBCAST_MIN_DATATYPES_ONLY\" LINK_FLAGS \"-DBCAST_MIN_DATATYPES_ONLY\")\n  set_target_properties(bcast_comm_world PROPERTIES COMPILE_FLAGS \"-DBCAST_COMM_WORLD_ONLY\" LINK_FLAGS \"-DBCAST_COMM_WORLD_ONLY\")\n\n  # These tests take 5 to 15 seconds to run, so we don't want to run them several times.\n  # But at the same time, we'd like to check if they work for all factories and all privatization algorithm\n  # Thus the current matrix\n\n  MACRO(ADD_MPICH3_COLL SELECTOR FACTORY PRIVATIZATION)\n    set(NAME \"test-smpi-mpich3-coll-${SELECTOR}\")\n    set(ARGS \"-execarg=--cfg=smpi/coll-selector:${SELECTOR}\" ${ARGN})\n    if(NOT \"${PRIVATIZATION}\" STREQUAL \"\" AND HAVE_PRIVATIZATION)\n      set(NAME \"${NAME}-${PRIVATIZATION}\")\n      set(ARGS ${ARGS} \"-execarg=--cfg=smpi/privatization:${PRIVATIZATION}\")\n    endif()\n    string(TOUPPER \"HAVE_${FACTORY}_CONTEXTS\" HAVE_FACTORY)\n    if(NOT \"${FACTORY}\" STREQUAL \"\" AND ${HAVE_FACTORY})\n      set(NAME \"${NAME}-${FACTORY}\")\n      set(ARGS ${ARGS} \"-execarg=--cfg=contexts/factory:${FACTORY}\")\n    endif()\n    ADD_TEST(${NAME} ${CMAKE_COMMAND} -E chdir ${CMAKE_BINARY_DIR}/teshsuite/smpi/mpich3-test/coll ${PERL_EXECUTABLE} ${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/mpich3-test/runtests \"-wrapper=${TESH_WRAPPER}\" -mpiexec=${CMAKE_BINARY_DIR}/smpi_script/bin/smpirun -srcdir=${CMAKE_HOME_DIRECTORY}/teshsuite/smpi/mpich3-test/coll -tests=testlist ${ARGS})\n    SET_TESTS_PROPERTIES(${NAME} PROPERTIES PASS_REGULAR_EXPRESSION \"tests passed!\")\n  ENDMACRO()\n\n  # Test default selector; default factory; default privatization\n  ADD_MPICH3_COLL(default \"\" \"\")\n\n  # Test OMPI selector: thread factory, dlopen privatization\n  ADD_MPICH3_COLL(ompi \"thread\" \"dlopen\" -execarg=--cfg=smpi/bcast:binomial_tree)\n\n  # Test MPICH selector: boost factory, dlopen privatization\n  ADD_MPICH3_COLL(mpich \"boost\" \"dlopen\")\n\n  # Test MVAPICH2 selector: ucontext factory, mmap privatization\n  ADD_MPICH3_COLL(mvapich2 \"ucontext\" \"mmap\")\n\n  # Test IMPI selector: raw factory, mmap privatization\n  ADD_MPICH3_COLL(impi \"raw\" \"mmap\")\n\nendif()\n\nset(examples_src  ${examples_src}\n ${CMAKE_CURRENT_SOURCE_DIR}/allgather2.c \n ${CMAKE_CURRENT_SOURCE_DIR}/allgather_struct.c \n ${CMAKE_CURRENT_SOURCE_DIR}/allgather3.c \n ${CMAKE_CURRENT_SOURCE_DIR}/allgatherv2.c \n ${CMAKE_CURRENT_SOURCE_DIR}/allgatherv3.c \n ${CMAKE_CURRENT_SOURCE_DIR}/allgatherv4.c \n ${CMAKE_CURRENT_SOURCE_DIR}/allgatherv4_manual.c \n ${CMAKE_CURRENT_SOURCE_DIR}/allred2.c \n ${CMAKE_CURRENT_SOURCE_DIR}/allred3.c \n ${CMAKE_CURRENT_SOURCE_DIR}/allred4.c \n ${CMAKE_CURRENT_SOURCE_DIR}/allred5.c \n ${CMAKE_CURRENT_SOURCE_DIR}/allred6.c \n ${CMAKE_CURRENT_SOURCE_DIR}/allred.c \n ${CMAKE_CURRENT_SOURCE_DIR}/allred_manual.c \n ${CMAKE_CURRENT_SOURCE_DIR}/allredmany.c \n ${CMAKE_CURRENT_SOURCE_DIR}/alltoall1.c \n ${CMAKE_CURRENT_SOURCE_DIR}/alltoallv0.c \n ${CMAKE_CURRENT_SOURCE_DIR}/alltoallv.c \n ${CMAKE_CURRENT_SOURCE_DIR}/alltoallw1.c \n ${CMAKE_CURRENT_SOURCE_DIR}/alltoallw2.c \n ${CMAKE_CURRENT_SOURCE_DIR}/alltoallw_zeros.c \n ${CMAKE_CURRENT_SOURCE_DIR}/bcast.c \n ${CMAKE_CURRENT_SOURCE_DIR}/bcasttest.c \n ${CMAKE_CURRENT_SOURCE_DIR}/bcastzerotype.c \n ${CMAKE_CURRENT_SOURCE_DIR}/coll10.c \n ${CMAKE_CURRENT_SOURCE_DIR}/coll11.c \n ${CMAKE_CURRENT_SOURCE_DIR}/coll12.c \n ${CMAKE_CURRENT_SOURCE_DIR}/coll13.c \n ${CMAKE_CURRENT_SOURCE_DIR}/coll2.c \n ${CMAKE_CURRENT_SOURCE_DIR}/coll3.c \n ${CMAKE_CURRENT_SOURCE_DIR}/coll4.c \n ${CMAKE_CURRENT_SOURCE_DIR}/coll5.c \n ${CMAKE_CURRENT_SOURCE_DIR}/coll6.c \n ${CMAKE_CURRENT_SOURCE_DIR}/coll7.c \n ${CMAKE_CURRENT_SOURCE_DIR}/coll8.c \n ${CMAKE_CURRENT_SOURCE_DIR}/coll9.c \n ${CMAKE_CURRENT_SOURCE_DIR}/exscan2.c \n ${CMAKE_CURRENT_SOURCE_DIR}/exscan.c \n ${CMAKE_CURRENT_SOURCE_DIR}/gather2.c \n ${CMAKE_CURRENT_SOURCE_DIR}/gather_big.c \n ${CMAKE_CURRENT_SOURCE_DIR}/gather.c \n ${CMAKE_CURRENT_SOURCE_DIR}/iallred.c \n ${CMAKE_CURRENT_SOURCE_DIR}/ibarrier.c \n ${CMAKE_CURRENT_SOURCE_DIR}/icallgather.c \n ${CMAKE_CURRENT_SOURCE_DIR}/icallgatherv.c \n ${CMAKE_CURRENT_SOURCE_DIR}/icallreduce.c \n ${CMAKE_CURRENT_SOURCE_DIR}/icalltoall.c \n ${CMAKE_CURRENT_SOURCE_DIR}/icalltoallv.c \n ${CMAKE_CURRENT_SOURCE_DIR}/icalltoallw.c \n ${CMAKE_CURRENT_SOURCE_DIR}/icbarrier.c \n ${CMAKE_CURRENT_SOURCE_DIR}/icbcast.c \n ${CMAKE_CURRENT_SOURCE_DIR}/icgather.c \n ${CMAKE_CURRENT_SOURCE_DIR}/icgatherv.c \n ${CMAKE_CURRENT_SOURCE_DIR}/icreduce.c \n ${CMAKE_CURRENT_SOURCE_DIR}/icscatter.c \n ${CMAKE_CURRENT_SOURCE_DIR}/icscatterv.c \n ${CMAKE_CURRENT_SOURCE_DIR}/longuser.c \n ${CMAKE_CURRENT_SOURCE_DIR}/nonblocking2.c \n ${CMAKE_CURRENT_SOURCE_DIR}/nonblocking3.c \n ${CMAKE_CURRENT_SOURCE_DIR}/nonblocking.c \n ${CMAKE_CURRENT_SOURCE_DIR}/opband.c \n ${CMAKE_CURRENT_SOURCE_DIR}/opbor.c \n ${CMAKE_CURRENT_SOURCE_DIR}/opbxor.c \n ${CMAKE_CURRENT_SOURCE_DIR}/op_commutative.c \n ${CMAKE_CURRENT_SOURCE_DIR}/opland.c \n ${CMAKE_CURRENT_SOURCE_DIR}/oplor.c \n ${CMAKE_CURRENT_SOURCE_DIR}/oplxor.c \n ${CMAKE_CURRENT_SOURCE_DIR}/opmax.c \n ${CMAKE_CURRENT_SOURCE_DIR}/opmaxloc.c \n ${CMAKE_CURRENT_SOURCE_DIR}/opmin.c \n ${CMAKE_CURRENT_SOURCE_DIR}/opminloc.c \n ${CMAKE_CURRENT_SOURCE_DIR}/opprod.c \n ${CMAKE_CURRENT_SOURCE_DIR}/opsum.c \n ${CMAKE_CURRENT_SOURCE_DIR}/red3.c \n ${CMAKE_CURRENT_SOURCE_DIR}/red4.c \n ${CMAKE_CURRENT_SOURCE_DIR}/redscat2.c \n ${CMAKE_CURRENT_SOURCE_DIR}/redscat3.c \n ${CMAKE_CURRENT_SOURCE_DIR}/redscatbkinter.c \n ${CMAKE_CURRENT_SOURCE_DIR}/redscatblk3.c \n ${CMAKE_CURRENT_SOURCE_DIR}/red_scat_block2.c \n ${CMAKE_CURRENT_SOURCE_DIR}/red_scat_block.c \n ${CMAKE_CURRENT_SOURCE_DIR}/redscat.c \n ${CMAKE_CURRENT_SOURCE_DIR}/redscatinter.c \n ${CMAKE_CURRENT_SOURCE_DIR}/reduce.c \n ${CMAKE_CURRENT_SOURCE_DIR}/reduce_local.c \n ${CMAKE_CURRENT_SOURCE_DIR}/scantst.c \n ${CMAKE_CURRENT_SOURCE_DIR}/scatter2.c \n ${CMAKE_CURRENT_SOURCE_DIR}/scatter3.c \n ${CMAKE_CURRENT_SOURCE_DIR}/scattern.c \n ${CMAKE_CURRENT_SOURCE_DIR}/scatterv.c \n ${CMAKE_CURRENT_SOURCE_DIR}/uoplong.c \n  PARENT_SCOPE)\nset(txt_files  ${txt_files}  ${CMAKE_CURRENT_SOURCE_DIR}/testlist  PARENT_SCOPE)\n",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.21-2jw7hfw3ki7yfy6d52vbzhst6fypdxym/spack-src/tools/simgrid.supp": "# Valgrind suppressions for stuff that we cannot control\n\n# Memory leaks in standard tools (e.g. dash, tail, or sort)\n{\n   Memory leak in /bin tools\n   Memcheck:Leak\n   ...\n   obj:/bin/*\n}\n\n{\n   Memory leak in /usr/bin tools\n   Memcheck:Leak\n   ...\n   obj:/usr/bin/*\n}\n\n{\n   Memory leak in cmake\n   Memcheck:Leak\n   match-leak-kinds:reachable\n   ...\n   fun:_ZN4Json5Value13nullSingletonEv\n   obj:*/libjsoncpp.so*\n   ...\n   fun:_dl_init\n}\n\n# There's a constant leak of 56 bytes in the depths of libc which\n# manifests, for example, when using backtrace()\n{\n   Memory leak in libc/dlopen with -pthread\n   Memcheck:Leak\n   fun:malloc\n   fun:_dl_map_object_deps\n   fun:dl_open_worker\n   fun:_dl_catch_error\n   fun:_dl_open\n   fun:do_dlopen\n   fun:_dl_catch_error\n   fun:dlerror_run\n   fun:__libc_dlopen_mode\n}\n\n# Another problem in glibc, where makecontext does not reset the EBP register,\n# and backtrace goes too far when walking up the stack frames\n{\n   Invalid read in backtrace, called after makecontext\n   Memcheck:Addr4\n   fun:backtrace\n   ...\n   fun:makecontext\n}\n\n#There seems to be an issue with libc using an uninitialized value somewhere in dlopen\n{\n   Invalid read in dl_start\n   Memcheck:Cond\n   fun:index\n   fun:expand_dynamic_string_token\n   ...\n   fun:_dl_start\n}\n\n# 72704 bytes leak from GCC >5.1 https://gcc.gnu.org/bugzilla/show_bug.cgi?id=64535\n{\n   Memory leak in dl_init\n   Memcheck:Leak\n   match-leak-kinds:reachable\n   fun:malloc\n   obj:/usr/lib/*/libstdc++.so.*\n   fun:call_init.part.0\n   ...\n   fun:_dl_init\n}\n\n#Ignore leaks in SMPI sample codes\n{\n   Leaks in SMPI sample codes\n   Memcheck:Leak\n   match-leak-kinds: all\n   fun:malloc\n   fun:smpi_simulated_main_\n}\n\n#SMPI leaks the dlopen handle used to load the program\n{\n   dlopen handle leaks (1/3)\n   Memcheck:Leak\n   match-leak-kinds:reachable\n   fun:malloc\n   ...\n   fun:dlopen@@GLIBC_*\n}\n\n{\n   dlopen handle leaks (2/3)\n   Memcheck:Leak\n   match-leak-kinds:reachable\n   fun:calloc\n   ...\n   fun:dlopen@@GLIBC_*\n}\n\n{\n   dlopen handle leaks (3/3)\n   Memcheck:Leak\n   match-leak-kinds:reachable\n   fun:realloc\n   ...\n   fun:dlopen@@GLIBC_*\n}\n\n# Memory leaks appearing to be in libcgraph.  They can be seen with the\n# following simple program:\n# ,----\n# | #include <stdio.h>\n# | #include <graphviz/cgraph.h>\n# | int main(int argc, char *argv[])\n# | {\n# |     if (argc == 1) {\n# |         printf(\"Usage: %s <dotfile>\\n\", argv[0]);\n# |         return 1;\n# |     }\n# |     Agraph_t *g;\n# |     FILE *inf = fopen(argv[1], \"r\");\n# |     g = agread(inf, 0);\n# |     fclose(inf);\n# |     agclose(g);\n# |     return 0;\n# | }\n# `----\n{\n   Memory leak in libcgraph (1/2)\n   Memcheck:Leak\n   fun:malloc\n   ...\n   obj:/usr/lib/libcgraph.so*\n   fun:aaglex\n   fun:aagparse\n   fun:agconcat\n}\n{\n   Memory leak in libcgraph (1/2)\n   Memcheck:Leak\n   fun:calloc\n   ...\n   obj:/usr/lib/libcgraph.so*\n   fun:aagparse\n   fun:agconcat\n}\n{\n   Memory leak in libcgraph (2/2)\n   Memcheck:Leak\n   fun:malloc\n   ...\n   fun:agnode\n   obj:/usr/lib/libcgraph.so*\n   fun:aagparse\n   fun:agconcat\n}\n\n# We're not interested by memory leaks in the Lua interpreter\n{\n   Memory leak in lua\n   Memcheck:Leak\n   ...\n   fun:luaD_precall\n}\n\n# libunwind seems to be using msync poorly, thus triggering these\n# https://github.com/JuliaLang/julia/issues/4533\n{\n   msync unwind\n   Memcheck:Param\n   msync(start)\n   ...\n   obj:*/libpthread*.so\n   ...\n}\n\n{\n   ignore unwind cruft\n   Memcheck:Param\n   rt_sigprocmask(set)\n   ...\n   obj:/usr/lib/x86_64-linux-gnu/libunwind.so.*\n   ...\n}\n{\n   ignore unwind cruft\n   Memcheck:Param\n   msync(start)\n   ...\n   obj:/usr/lib/x86_64-linux-gnu/libunwind.so.*\n   ...\n}\n\n{\n   ignore unwind invalid reads\n   Memcheck:Addr8\n   fun:_Ux86_64_setcontext\n}\n\n# Java cruft\n{\n  JavaCruft 1\n  Memcheck:Addr4\n  ...\n  fun:_ZN9JavaCalls11call_helperEP9JavaValueP12methodHandleP17JavaCallArgumentsP6Thread\n  fun:JVM_DoPrivileged\n  ...\n}\n{\n   JavaCruft 2\n   Memcheck:Cond\n   ...\n   fun:_ZN13CompileBroker25invoke_compiler_on_methodEP11CompileTask\n   ...\n}\n\n{\n   Somewhere within the Java conditions and monitors\n   Memcheck:Cond\n   fun:MarsagliaXORV\n   ...\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.21-2jw7hfw3ki7yfy6d52vbzhst6fypdxym/spack-src/tools/tesh/tesh.py": "#! @PYTHON_EXECUTABLE@\n# -*- coding: utf-8 -*-\n\"\"\"\n\ntesh -- testing shell\n========================\n\nCopyright (c) 2012-2018. The SimGrid Team. All rights reserved.\n\nThis program is free software; you can redistribute it and/or modify it\nunder the terms of the license (GNU LGPL) which comes with this package.\n\n\n#TODO: child of child of child that printfs. Does it work?\n#TODO: a child dies after its parent. What happen?\n\n#TODO: regular expression in output\n#ex: >> Time taken: [0-9]+s\n#TODO: linked regular expression in output\n#ex:\n# >> Bytes sent: ([0-9]+)\n# >> Bytes recv: \\1\n# then, even better:\n# ! expect (\\1 > 500)\n\n\"\"\"\n\n\nimport sys, os\nimport shlex\nimport re\nimport difflib\nimport signal\nimport argparse\n\nif sys.version_info[0] == 3:\n    import subprocess\n    import _thread\nelse:\n    raise \"This program is expected to run with Python3 only\"\n\n##############\n#\n# Utilities\n#\n#\n\ndef isWindows():\n    return sys.platform.startswith('win')\n\n# Singleton metaclass that works in Python 2 & 3\n# http://stackoverflow.com/questions/6760685/creating-a-singleton-in-python\nclass _Singleton(type):\n    \"\"\" A metaclass that creates a Singleton base class when called. \"\"\"\n    _instances = {}\n    def __call__(cls, *args, **kwargs):\n        if cls not in cls._instances:\n            cls._instances[cls] = super(_Singleton, cls).__call__(*args, **kwargs)\n        return cls._instances[cls]\nclass Singleton(_Singleton('SingletonMeta', (object,), {})): pass\n\nSIGNALS_TO_NAMES_DICT = dict((getattr(signal, n), n) \\\n    for n in dir(signal) if n.startswith('SIG') and '_' not in n )\n\n\n\n#exit correctly\ndef tesh_exit(errcode):\n    #If you do not flush some prints are skipped\n    sys.stdout.flush()\n    #os._exit exit even when executed within a thread\n    os._exit(errcode)\n\n\ndef fatal_error(msg):\n    print(\"[Tesh/CRITICAL] \"+str(msg))\n    tesh_exit(1)\n\n\n#Set an environment variable.\n# arg must be a string with the format \"variable=value\"\ndef setenv(arg):\n    print(\"[Tesh/INFO] setenv \"+arg)\n    t = arg.split(\"=\")\n    os.environ[t[0]] = t[1]\n    #os.putenv(t[0], t[1]) does not work\n    #see http://stackoverflow.com/questions/17705419/python-os-environ-os-putenv-usr-bin-env\n\n\n#http://stackoverflow.com/questions/30734967/how-to-expand-environment-variables-in-python-as-bash-does\ndef expandvars2(path):\n    return re.sub(r'(?<!\\\\)\\$[A-Za-z_][A-Za-z0-9_]*', '', os.path.expandvars(path))\n\n# https://github.com/Cadair/jupyter_environment_kernels/issues/10\ntry:\n    FileNotFoundError\nexcept NameError:\n    #py2\n    FileNotFoundError = OSError\n\n##############\n#\n# Cleanup on signal\n#\n#\n\n# Global variable. Stores which process group should be killed (or None otherwise)\npgtokill = None\n\ndef kill_process_group(pgid):\n    if pgid is None: # Nobody to kill. We don't know who to kill on windows, or we don't have anyone to kill on signal handler\n        return\n\n    # print(\"Kill process group {}\".format(pgid))\n    try:\n        os.killpg(pgid, signal.SIGTERM)\n    except OSError:\n        # os.killpg failed. OK. Some subprocesses may still be running.\n        pass\n\ndef signal_handler(signal, frame):\n    print(\"Caught signal {}\".format(SIGNALS_TO_NAMES_DICT[signal]))\n    if pgtokill is not None:\n        kill_process_group(pgtokill)\n    tesh_exit(5)\n\n\n\n##############\n#\n# Classes\n#\n#\n\n\n\n# read file line per line (and concat line that ends with \"\\\")\nclass FileReader(Singleton):\n    def __init__(self, filename=None):\n        if filename is None:\n            self.filename = \"(stdin)\"\n            self.f = sys.stdin\n        else:\n            self.filename_raw = filename\n            self.filename = os.path.basename(filename)\n            self.abspath = os.path.abspath(filename)\n            self.f = open(self.filename_raw)\n\n        self.linenumber = 0\n\n    def __repr__(self):\n        return self.filename+\":\"+str(self.linenumber)\n\n    def readfullline(self):\n        try:\n            line = next(self.f)\n            self.linenumber += 1\n        except StopIteration:\n            return None\n        if line[-1] == \"\\n\":\n            txt = line[0:-1]\n        else:\n            txt = line\n        while len(line) > 1 and line[-2] == \"\\\\\":\n            txt = txt[0:-1]\n            line = next(self.f)\n            self.linenumber += 1\n            txt += line[0:-1]\n        return txt\n\n\n#keep the state of tesh (mostly configuration values)\nclass TeshState(Singleton):\n    def __init__(self):\n        self.threads = []\n        self.args_suffix = \"\"\n        self.ignore_regexps_common = []\n        self.jenkins = False # not a Jenkins run by default\n        self.timeout = 10 # default value: 10 sec\n        self.wrapper = None\n        self.keep = False\n\n    def add_thread(self, thread):\n        self.threads.append(thread)\n\n    def join_all_threads(self):\n        for t in self.threads:\n            t.acquire()\n            t.release()\n\n#Command line object\nclass Cmd(object):\n    def __init__(self):\n        self.input_pipe = []\n        self.output_pipe_stdout = []\n        self.output_pipe_stderr = []\n        self.timeout = TeshState().timeout\n        self.args = None\n        self.linenumber = -1\n\n        self.background = False\n        self.cwd = None\n\n        self.ignore_output = False\n        self.expect_return = 0\n\n        self.output_display = False\n\n        self.sort = -1\n\n        self.ignore_regexps = TeshState().ignore_regexps_common\n\n    def add_input_pipe(self, l):\n        self.input_pipe.append(l)\n\n    def add_output_pipe_stdout(self, l):\n        self.output_pipe_stdout.append(l)\n\n    def add_output_pipe_stderr(self, l):\n        self.output_pipe_stderr.append(l)\n\n    def set_cmd(self, args, linenumber):\n        self.args = args\n        self.linenumber = linenumber\n\n    def add_ignore(self, txt):\n        self.ignore_regexps.append(re.compile(txt))\n\n    def remove_ignored_lines(self, lines):\n        for ign in self.ignore_regexps:\n                lines = [l for l in lines if not ign.match(l)]\n        return lines\n\n\n    def _cmd_mkfile(self, argline):\n        filename = argline[len(\"mkfile \"):]\n        file = open(filename, \"w\")\n        if file is None:\n            fatal_error(\"Unable to create file \"+filename)\n        file.write(\"\\n\".join(self.input_pipe))\n        file.write(\"\\n\")\n        file.close()\n\n    def _cmd_cd(self, argline):\n        args = shlex.split(argline)\n        if len(args) != 2:\n            fatal_error(\"Too many arguments to cd\")\n        try:\n            os.chdir(args[1])\n            print(\"[Tesh/INFO] change directory to \"+args[1])\n        except FileNotFoundError:\n            print(\"Chdir to \"+args[1]+\" failed: No such file or directory\")\n            print(\"Test suite `\"+FileReader().filename+\"': NOK (system error)\")\n            tesh_exit(4)\n\n\n    #Run the Cmd if possible.\n    # Return False if nothing has been ran.\n    def run_if_possible(self):\n        if self.can_run():\n            if self.background:\n                #Python threads loose the cwd\n                self.cwd = os.getcwd()\n                lock = _thread.allocate_lock()\n                lock.acquire()\n                TeshState().add_thread(lock)\n                _thread.start_new_thread( Cmd._run, (self, lock) )\n            else:\n                self._run()\n            return True\n        else:\n            return False\n\n\n    def _run(self, lock=None):\n        #Python threads loose the cwd\n        if self.cwd is not None:\n            os.chdir(self.cwd)\n            self.cwd = None\n\n        #retrocompatibility: support ${aaa:=.} variable format\n        def replace_perl_variables(m):\n            vname = m.group(1)\n            vdefault = m.group(2)\n            if vname in os.environ:\n                return \"$\"+vname\n            else:\n                return vdefault\n        self.args = re.sub(r\"\\${(\\w+):=([^}]*)}\", replace_perl_variables, self.args)\n\n        #replace bash environment variables ($THINGS) to their values\n        self.args = expandvars2(self.args)\n\n        if re.match(\"^mkfile \", self.args) is not None:\n            self._cmd_mkfile(self.args)\n            if lock is not None: lock.release()\n            return\n\n        if re.match(\"^cd \", self.args) is not None:\n            self._cmd_cd(self.args)\n            if lock is not None: lock.release()\n            return\n\n        if TeshState().wrapper is not None:\n            self.timeout *= 20\n            self.args = TeshState().wrapper + self.args\n        elif re.match(\".*smpirun.*\", self.args) is not None:\n            self.args = \"sh \" + self.args\n        if TeshState().jenkins and self.timeout != None:\n            self.timeout *= 10\n\n        self.args += TeshState().args_suffix\n\n        print(\"[\"+FileReader().filename+\":\"+str(self.linenumber)+\"] \"+self.args)\n\n        args = shlex.split(self.args)\n        #print (args)\n\n        global pgtokill\n\n        try:\n            proc = subprocess.Popen(args, bufsize=1, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, universal_newlines=True, start_new_session=True)\n            try:\n                if not isWindows():\n                    pgtokill = os.getpgid(proc.pid)\n            except OSError:\n                # os.getpgid failed. OK. No cleanup.\n                pass\n        except PermissionError:\n            print(\"[\"+FileReader().filename+\":\"+str(self.linenumber)+\"] Cannot start '\"+args[0]+\"': The binary is not executable.\")\n            print(\"[\"+FileReader().filename+\":\"+str(self.linenumber)+\"] Current dir: \"+os.getcwd())\n            tesh_exit(3)            \n        except NotADirectoryError:\n            print(\"[\"+FileReader().filename+\":\"+str(self.linenumber)+\"] Cannot start '\"+args[0]+\"': The path to binary does not exist.\")\n            print(\"[\"+FileReader().filename+\":\"+str(self.linenumber)+\"] Current dir: \"+os.getcwd())\n            tesh_exit(3)\n        except FileNotFoundError:\n            print(\"[\"+FileReader().filename+\":\"+str(self.linenumber)+\"] Cannot start '\"+args[0]+\"': File not found\")\n            tesh_exit(3)\n        except OSError as osE:\n            if osE.errno == 8:\n                osE.strerror += \"\\nOSError: [Errno 8] Executed scripts should start with shebang line (like #!/usr/bin/env sh)\"\n            raise osE\n\n        cmdName = FileReader().filename+\":\"+str(self.linenumber)\n        try:\n            (stdout_data, stderr_data) = proc.communicate(\"\\n\".join(self.input_pipe), self.timeout)\n            pgtokill = None\n        except subprocess.TimeoutExpired:\n            print(\"Test suite `\"+FileReader().filename+\"': NOK (<\"+cmdName+\"> timeout after \"+str(self.timeout)+\" sec)\")\n            kill_process_group(pgtokill)\n            tesh_exit(3)\n\n        if self.output_display:\n            print(stdout_data)\n\n        #remove text colors\n        ansi_escape = re.compile(r'\\x1b[^m]*m')\n        stdout_data = ansi_escape.sub('', stdout_data)\n\n        #print ((stdout_data, stderr_data))\n\n        if self.ignore_output:\n            print(\"(ignoring the output of <\"+cmdName+\"> as requested)\")\n        else:\n            stdouta = stdout_data.split(\"\\n\")\n            while len(stdouta) > 0 and stdouta[-1] == \"\":\n                del stdouta[-1]\n            stdouta = self.remove_ignored_lines(stdouta)\n            stdcpy = stdouta[:]\n\n            # Mimic the \"sort\" bash command, which is case unsensitive.\n            if self.sort == 0:\n                stdouta.sort(key=lambda x: x.lower())\n                self.output_pipe_stdout.sort(key=lambda x: x.lower())\n            elif self.sort > 0:\n                stdouta.sort(key=lambda x: x[:self.sort].lower())\n                self.output_pipe_stdout.sort(key=lambda x: x[:self.sort].lower())\n\n            diff = list(difflib.unified_diff(self.output_pipe_stdout, stdouta,lineterm=\"\",fromfile='expected', tofile='obtained'))\n            if len(diff) > 0:\n                print(\"Output of <\"+cmdName+\"> mismatch:\")\n                if self.sort >= 0: # If sorted, truncate the diff output and show the unsorted version\n                    difflen = 0;\n                    for line in diff:\n                        if difflen<50:\n                            print(line)\n                        difflen += 1\n                    if difflen > 50:\n                        print(\"(diff truncated after 50 lines)\")\n                    print(\"Unsorted observed output:\\n\")\n                    for line in stdcpy:\n                        print(line)\n                else: # If not sorted, just display the diff\n                    for line in diff:\n                        print(line)\n\n                print(\"Test suite `\"+FileReader().filename+\"': NOK (<\"+cmdName+\"> output mismatch)\")\n                if lock is not None: lock.release()\n                if TeshState().keep:\n                    f = open('obtained','w')\n                    obtained = stdout_data.split(\"\\n\")\n                    while len(obtained) > 0 and obtained[-1] == \"\":\n                        del obtained[-1]\n                    obtained = self.remove_ignored_lines(obtained)\n                    for line in obtained:\n                        f.write(\"> \"+line+\"\\n\")\n                    f.close()\n                    print(\"Obtained output kept as requested: \"+os.path.abspath(\"obtained\"))\n                tesh_exit(2)\n\n        #print ((proc.returncode, self.expect_return))\n\n        if proc.returncode != self.expect_return:\n            if proc.returncode >= 0:\n                print(\"Test suite `\"+FileReader().filename+\"': NOK (<\"+cmdName+\"> returned code \"+str(proc.returncode)+\")\")\n                if lock is not None: lock.release()\n                tesh_exit(2)\n            else:\n                print(\"Test suite `\"+FileReader().filename+\"': NOK (<\"+cmdName+\"> got signal \"+SIGNALS_TO_NAMES_DICT[-proc.returncode]+\")\")\n                if lock is not None: lock.release()\n                tesh_exit(-proc.returncode)\n\n        if lock is not None: lock.release()\n\n\n\n    def can_run(self):\n        return self.args is not None\n\n\n\n\n##############\n#\n# Main\n#\n#\n\n\n\nif __name__ == '__main__':\n    signal.signal(signal.SIGINT, signal_handler)\n    signal.signal(signal.SIGTERM, signal_handler)\n\n    parser = argparse.ArgumentParser(description='tesh -- testing shell', add_help=True)\n    group1 = parser.add_argument_group('Options')\n    group1.add_argument('teshfile', nargs='?', help='Name of teshfile, stdin if omitted')\n    group1.add_argument('--cd', metavar='some/directory', help='ask tesh to switch the working directory before launching the tests')\n    group1.add_argument('--setenv', metavar='var=value', action='append', help='set a specific environment variable')\n    group1.add_argument('--cfg', metavar='arg', action='append', help='add parameter --cfg=arg to each command line')\n    group1.add_argument('--log', metavar='arg', action='append', help='add parameter --log=arg to each command line')\n    group1.add_argument('--ignore-jenkins', action='store_true', help='ignore all cruft generated on SimGrid continous integration servers')\n    group1.add_argument('--wrapper', metavar='arg', help='Run each command in the provided wrapper (eg valgrind)')\n    group1.add_argument('--keep', action='store_true', help='Keep the obtained output when it does not match the expected one')\n\n    try:\n        options = parser.parse_args()\n    except SystemExit:\n        tesh_exit(1)\n\n    if options.cd is not None:\n        print(\"[Tesh/INFO] change directory to \" + options.cd)\n        os.chdir(options.cd)\n\n    if options.ignore_jenkins:\n        print(\"Ignore all cruft seen on SimGrid's continous integration servers\")\n        # Note: regexps should match at the beginning of lines\n        TeshState().ignore_regexps_common = [\n           re.compile(r\"profiling:\"),\n           re.compile(r\"Unable to clean temporary file C:\"),\n           re.compile(r\".*Configuration change: Set 'contexts/\"),\n           re.compile(r\"Picked up JAVA_TOOL_OPTIONS: \"),\n           re.compile(r\"Picked up _JAVA_OPTIONS: \"),\n           re.compile(r\"==[0-9]+== ?WARNING: ASan doesn't fully support\"),\n           re.compile(r\"==[0-9]+== ?WARNING: ASan is ignoring requested __asan_handle_no_return: stack top:\"),\n           re.compile(r\"False positive error reports may follow\"),\n           re.compile(r\"For details see http://code.google.com/p/address-sanitizer/issues/detail\\?id=189\"),\n           re.compile(r\"For details see https://github.com/google/sanitizers/issues/189\"),\n           re.compile(r\"Python runtime initialized with LC_CTYPE=C .*\"),\n           re.compile(r\"cmake: /usr/local/lib/libcurl\\.so\\.4: no version information available \\(required by cmake\\)\"), # Seen on CircleCI\n           re.compile(r\".*mmap broken on FreeBSD, but dlopen\\+thread broken too. Switching to dlopen\\+raw contexts\\.\"),\n           re.compile(r\".*dlopen\\+thread broken on Apple and BSD\\. Switching to raw contexts\\.\"),\n           ]\n        TeshState().jenkins = True # This is a Jenkins build\n\n    if options.teshfile is None:\n        f = FileReader(None)\n        print(\"Test suite from stdin\")\n    else:\n        if not os.path.isfile(options.teshfile):\n            print(\"Cannot open teshfile '\"+options.teshfile+\"': File not found\")\n            tesh_exit(3)\n        f = FileReader(options.teshfile)\n        print(\"Test suite '\"+f.abspath+\"'\")\n\n    if options.setenv is not None:\n        for e in options.setenv:\n            setenv(e)\n\n    if options.cfg is not None:\n        for c in options.cfg:\n            TeshState().args_suffix += \" --cfg=\" + c\n    if options.log is not None:\n        for l in options.log:\n            TeshState().args_suffix += \" --log=\" + l\n\n    if options.wrapper is not None:\n        TeshState().wrapper = options.wrapper\n\n    if options.keep:\n        TeshState().keep = True\n\n    #cmd holds the current command line\n    # tech commands will add some parameters to it\n    # when ready, we execute it.\n    cmd = Cmd()\n\n    line = f.readfullline()\n    while line is not None:\n        #print(\">>=============\"+line+\"==<<\")\n        if len(line) == 0:\n            #print (\"END CMD block\")\n            if cmd.run_if_possible():\n                cmd = Cmd()\n\n        elif line[0] == \"#\":\n            pass\n\n        elif line[0:2] == \"p \":\n            print(\"[\"+str(FileReader())+\"] \"+line[2:])\n\n        elif line[0:2] == \"< \":\n            cmd.add_input_pipe(line[2:])\n        elif line[0:1] == \"<\":\n            cmd.add_input_pipe(line[1:])\n\n        elif line[0:2] == \"> \":\n            cmd.add_output_pipe_stdout(line[2:])\n        elif line[0:1] == \">\":\n            cmd.add_output_pipe_stdout(line[1:])\n\n        elif line[0:2] == \"$ \":\n            if cmd.run_if_possible():\n                cmd = Cmd()\n            cmd.set_cmd(line[2:], f.linenumber)\n\n        elif line[0:2] == \"& \":\n            if cmd.run_if_possible():\n                cmd = Cmd()\n            cmd.set_cmd(line[2:], f.linenumber)\n            cmd.background = True\n\n        elif line[0:15] == \"! output ignore\":\n            cmd.ignore_output = True\n            #print(\"cmd.ignore_output = True\")\n        elif line[0:16] == \"! output display\":\n            cmd.output_display = True\n            cmd.ignore_output = True\n        elif line[0:15] == \"! expect return\":\n            cmd.expect_return = int(line[16:])\n            #print(\"expect return \"+str(int(line[16:])))\n        elif line[0:15] == \"! expect signal\":\n            sig = line[16:]\n            #get the signal integer value from the signal module\n            if sig not in signal.__dict__:\n                fatal_error(\"unrecognized signal '\"+sig+\"'\")\n            sig = int(signal.__dict__[sig])\n            #popen return -signal when a process ends with a signal\n            cmd.expect_return = -sig\n        elif line[0:len(\"! timeout \")] == \"! timeout \":\n            if \"no\" in line[len(\"! timeout \"):]:\n                cmd.timeout = None\n            else:\n                cmd.timeout = int(line[len(\"! timeout \"):])\n\n        elif line[0:len(\"! output sort\")] == \"! output sort\":\n            if len(line) >= len(\"! output sort \"):\n                sort = int(line[len(\"! output sort \"):])\n            else:\n                sort = 0\n            cmd.sort = sort\n        elif line[0:len(\"! setenv \")] == \"! setenv \":\n            setenv(line[len(\"! setenv \"):])\n\n        elif line[0:len(\"! ignore \")] == \"! ignore \":\n            cmd.add_ignore(line[len(\"! ignore \"):])\n\n        else:\n            fatal_error(\"UNRECOGNIZED OPTION\")\n\n\n        line = f.readfullline()\n\n    cmd.run_if_possible()\n\n    TeshState().join_all_threads()\n\n    if f.filename == \"(stdin)\":\n        print(\"Test suite from stdin OK\")\n    else:\n        print(\"Test suite `\"+f.filename+\"' OK\")\n",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.21-2jw7hfw3ki7yfy6d52vbzhst6fypdxym/spack-src/docs/source/app_smpi.rst": ".. _SMPI_doc:\n\n===============================\nSMPI: Simulate MPI Applications\n===============================\n\n.. raw:: html\n\n   <object id=\"TOC\" data=\"graphical-toc.svg\" width=\"100%\" type=\"image/svg+xml\"></object>\n   <script>\n   window.onload=function() { // Wait for the SVG to be loaded before changing it\n     var elem=document.querySelector(\"#TOC\").contentDocument.getElementById(\"SMPIBox\")\n     elem.style=\"opacity:0.93999999;fill:#ff0000;fill-opacity:0.1\";\n   }\n   </script>\n   <br/>\n   <br/>\n\nSMPI enables the study of MPI application by emulating them on top of\nthe SimGrid simulator. This is particularly interesting to study\nexisting MPI applications within the comfort of the simulator.\n\nTo get started with SMPI, you should head to `the SMPI tutorial\n<usecase_smpi>`_. You may also want to read the `SMPI reference\narticle <https://hal.inria.fr/hal-01415484>`_ or these `introductory\nslides <http://simgrid.org/tutorials/simgrid-smpi-101.pdf>`_.  If you\nare new to MPI, you should first take our online `SMPI CourseWare\n<https://simgrid.github.io/SMPI_CourseWare/>`_. It consists in several\nprojects that progressively introduce the MPI concepts. It proposes to\nuse SimGrid and SMPI to run the experiments, but the learning\nobjectives are centered on MPI itself.\n\nOur goal is to enable the study of **unmodified MPI applications**.\nSome constructs and features are still missing, but we can probably\nadd them on demand.  If you already used MPI before, SMPI should sound\nvery familiar to you: Use smpicc instead of mpicc, and smpirun instead\nof mpirun. The main difference is that smpirun takes a :ref:`simulated\nplatform <platform>` as an extra parameter.\n\nFor **further scalability**, you may modify your code to speed up your\nstudies or save memory space.  Maximal **simulation accuracy**\nrequires some specific care from you.\n\n----------\nUsing SMPI\n----------\n\n...................\nCompiling your Code\n...................\n\nIf your application is in C, then simply use ``smpicc`` as a\ncompiler just like you use mpicc with other MPI implementations. This\nscript still calls your default compiler (gcc, clang, ...) and adds\nthe right compilation flags along the way. If your application is in\nC++, Fortran 77 or Fortran 90, use respectively ``smpicxx``,\n``smpiff`` or ``smpif90``.\n\n....................\nSimulating your Code\n....................\n\nUse the ``smpirun`` script as follows:\n\n.. code-block:: shell\n\n   smpirun -hostfile my_hostfile.txt -platform my_platform.xml ./program -blah\n\n- ``my_hostfile.txt`` is a classical MPI hostfile (that is, this file\n  lists the machines on which the processes must be dispatched, one\n  per line)\n- ``my_platform.xml`` is a classical SimGrid platform file. Of course,\n  the hosts of the hostfile must exist in the provided platform.\n- ``./program`` is the MPI program to simulate, that you compiled with ``smpicc``\n- ``-blah`` is a command-line parameter passed to this program.\n\n``smpirun`` accepts other parameters, such as ``-np`` if you don't\nwant to use all the hosts defined in the hostfile, ``-map`` to display\non which host each rank gets mapped of ``-trace`` to activate the\ntracing during the simulation. You can get the full list by running\n``smpirun -help``\n\n...............................\nDebugging your Code within SMPI\n...............................\n\nIf you want to explore the automatic platform and deployment files\nthat are generated by ``smpirun``, add ``-keep-temps`` to the command\nline.\n\nYou can also run your simulation within valgrind or gdb using the\nfollowing commands. Once in GDB, each MPI ranks will be represented as\na regular thread, and you can explore the state of each of them as\nusual.\n\n.. code-block:: shell\n\n   smpirun -wrapper valgrind ...other args...\n   smpirun -wrapper \"gdb --args\" --cfg=contexts/factory:thread ...other args...\n\n.. _SMPI_use_colls:\n\n................................   \nSimulating Collective Operations\n................................\n\nMPI collective operations are crucial to the performance of MPI\napplications and must be carefully optimized according to many\nparameters. Every existing implementation provides several algorithms\nfor each collective operation, and selects by default the best suited\none, depending on the sizes sent, the number of nodes, the\ncommunicator, or the communication library being used.  These\ndecisions are based on empirical results and theoretical complexity\nestimation, and are very different between MPI implementations. In\nmost cases, the users can also manually tune the algorithm used for\neach collective operation.\n\nSMPI can simulate the behavior of several MPI implementations:\nOpenMPI, MPICH, `STAR-MPI <http://star-mpi.sourceforge.net/>`_, and\nMVAPICH2. For that, it provides 115 collective algorithms and several\nselector algorithms, that were collected directly in the source code\nof the targeted MPI implementations.\n\nYou can switch the automatic selector through the\n``smpi/coll-selector`` configuration item. Possible values:\n\n - **ompi:** default selection logic of OpenMPI (version 3.1.2)\n - **mpich**: default selection logic of MPICH (version 3.3b)\n - **mvapich2**: selection logic of MVAPICH2 (version 1.9) tuned\n   on the Stampede cluster   \n - **impi**: preliminary version of an Intel MPI selector (version\n   4.1.3, also tuned for the Stampede cluster). Due the closed source\n   nature of Intel MPI, some of the algorithms described in the\n   documentation are not available, and are replaced by mvapich ones.   \n - **default**: legacy algorithms used in the earlier days of\n   SimGrid. Do not use for serious perform performance studies.\n\n.. todo:: default should not even exist.   \n\n....................\nAvailable Algorithms\n....................\n\nYou can also pick the algorithm used for each collective with the\ncorresponding configuration item. For example, to use the pairwise\nalltoall algorithm, one should add ``--cfg=smpi/alltoall:pair`` to the\nline. This will override the selector (if any) for this algorithm.  It\nmeans that the selected algorithm will be used\n\n.. Warning:: Some collective may require specific conditions to be\n   executed correctly (for instance having a communicator with a power\n   of two number of nodes only), which are currently not enforced by\n   Simgrid. Some crashes can be expected while trying these algorithms\n   with unusual sizes/parameters\n\nMPI_Alltoall\n^^^^^^^^^^^^\n\nMost of these are best described in `STAR-MPI <http://www.cs.arizona.edu/~dkl/research/papers/ics06.pdf>`_.\n\n - default: naive one, by default\n - ompi: use openmpi selector for the alltoall operations\n - mpich: use mpich selector for the alltoall operations\n - mvapich2: use mvapich2 selector for the alltoall operations\n - impi: use intel mpi selector for the alltoall operations\n - automatic (experimental): use an automatic self-benchmarking algorithm \n - bruck: Described by Bruck et.al. in <a href=\"http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=642949\">this paper</a>\n - 2dmesh: organizes the nodes as a two dimensional mesh, and perform allgather \n   along the dimensions\n - 3dmesh: adds a third dimension to the previous algorithm\n - rdb: recursive doubling: extends the mesh to a nth dimension, each one \n   containing two nodes\n - pair: pairwise exchange, only works for power of 2 procs, size-1 steps,\n   each process sends and receives from the same process at each step\n - pair_light_barrier: same, with small barriers between steps to avoid\n   contention\n - pair_mpi_barrier: same, with MPI_Barrier used\n - pair_one_barrier: only one barrier at the beginning\n - ring: size-1 steps, at each step a process send to process (n+i)%size, and receives from (n-i)%size\n - ring_light_barrier: same, with small barriers between some phases to avoid contention\n - ring_mpi_barrier: same, with MPI_Barrier used\n - ring_one_barrier: only one barrier at the beginning\n - basic_linear: posts all receives and all sends,\n   starts the communications, and waits for all communication to finish\n - mvapich2_scatter_dest: isend/irecv with scattered destinations, posting only a few messages at the same time\n\nMPI_Alltoallv\n^^^^^^^^^^^^^\n - default: naive one, by default\n - ompi: use openmpi selector for the alltoallv operations\n - mpich: use mpich selector for the alltoallv operations\n - mvapich2: use mvapich2 selector for the alltoallv operations\n - impi: use intel mpi selector for the alltoallv operations\n - automatic (experimental): use an automatic self-benchmarking algorithm \n - bruck: same as alltoall\n - pair: same as alltoall\n - pair_light_barrier: same as alltoall\n - pair_mpi_barrier: same as alltoall\n - pair_one_barrier: same as alltoall\n - ring: same as alltoall\n - ring_light_barrier: same as alltoall\n - ring_mpi_barrier: same as alltoall\n - ring_one_barrier: same as alltoall\n - ompi_basic_linear: same as alltoall\n\nMPI_Gather\n^^^^^^^^^^\n\n - default: naive one, by default\n - ompi: use openmpi selector for the gather operations\n - mpich: use mpich selector for the gather operations\n - mvapich2: use mvapich2 selector for the gather operations\n - impi: use intel mpi selector for the gather operations\n - automatic (experimental): use an automatic self-benchmarking algorithm which will iterate over all implemented versions and output the best\n - ompi_basic_linear: basic linear algorithm from openmpi, each process sends to the root\n - ompi_binomial: binomial tree algorithm\n - ompi_linear_sync: same as basic linear, but with a synchronization at the\n   beginning and message cut into two segments.\n - mvapich2_two_level: SMP-aware version from MVAPICH. Gather first intra-node (defaults to mpich's gather), and then exchange with only one process/node. Use mvapich2 selector to change these to tuned algorithms for Stampede cluster.\n\nMPI_Barrier\n^^^^^^^^^^^\n\n - default: naive one, by default\n - ompi: use openmpi selector for the barrier operations\n - mpich: use mpich selector for the barrier operations\n - mvapich2: use mvapich2 selector for the barrier operations\n - impi: use intel mpi selector for the barrier operations\n - automatic (experimental): use an automatic self-benchmarking algorithm \n - ompi_basic_linear: all processes send to root\n - ompi_two_procs: special case for two processes\n - ompi_bruck: nsteps = sqrt(size), at each step, exchange data with rank-2^k and rank+2^k\n - ompi_recursivedoubling: recursive doubling algorithm\n - ompi_tree: recursive doubling type algorithm, with tree structure\n - ompi_doublering: double ring algorithm\n - mvapich2_pair: pairwise algorithm\n - mpich_smp: barrier intra-node, then inter-node\n\nMPI_Scatter\n^^^^^^^^^^^\n\n - default: naive one, by default\n - ompi: use openmpi selector for the scatter operations\n - mpich: use mpich selector for the scatter operations\n - mvapich2: use mvapich2 selector for the scatter operations\n - impi: use intel mpi selector for the scatter operations\n - automatic (experimental): use an automatic self-benchmarking algorithm \n - ompi_basic_linear: basic linear scatter \n - ompi_binomial: binomial tree scatter\n - mvapich2_two_level_direct: SMP aware algorithm, with an intra-node stage (default set to mpich selector), and then a basic linear inter node stage. Use mvapich2 selector to change these to tuned algorithms for Stampede cluster. \n - mvapich2_two_level_binomial: SMP aware algorithm, with an intra-node stage (default set to mpich selector), and then a binomial phase. Use mvapich2 selector to change these to tuned algorithms for Stampede cluster.\n\nMPI_Reduce\n^^^^^^^^^^\n\n - default: naive one, by default\n - ompi: use openmpi selector for the reduce operations\n - mpich: use mpich selector for the reduce operations\n - mvapich2: use mvapich2 selector for the reduce operations\n - impi: use intel mpi selector for the reduce operations\n - automatic (experimental): use an automatic self-benchmarking algorithm \n - arrival_pattern_aware: root exchanges with the first process to arrive\n - binomial: uses a binomial tree\n - flat_tree: uses a flat tree\n - NTSL: Non-topology-specific pipelined linear-bcast function \n   0->1, 1->2 ,2->3, ....., ->last node: in a pipeline fashion, with segments\n   of 8192 bytes\n - scatter_gather: scatter then gather\n - ompi_chain: openmpi reduce algorithms are built on the same basis, but the\n   topology is generated differently for each flavor\n   chain = chain with spacing of size/2, and segment size of 64KB \n - ompi_pipeline: same with pipeline (chain with spacing of 1), segment size \n   depends on the communicator size and the message size\n - ompi_binary: same with binary tree, segment size of 32KB\n - ompi_in_order_binary: same with binary tree, enforcing order on the \n   operations\n - ompi_binomial: same with binomial algo (redundant with default binomial \n   one in most cases)\n - ompi_basic_linear: basic algorithm, each process sends to root\n - mvapich2_knomial: k-nomial algorithm. Default factor is 4 (mvapich2 selector adapts it through tuning)\n - mvapich2_two_level: SMP-aware reduce, with default set to mpich both for intra and inter communicators. Use mvapich2 selector to change these to tuned algorithms for Stampede cluster.\n - rab: `Rabenseifner <https://fs.hlrs.de/projects/par/mpi//myreduce.html>`_'s reduce algorithm \n\nMPI_Allreduce\n^^^^^^^^^^^^^\n\n - default: naive one, by default\n - ompi: use openmpi selector for the allreduce operations\n - mpich: use mpich selector for the allreduce operations\n - mvapich2: use mvapich2 selector for the allreduce operations\n - impi: use intel mpi selector for the allreduce operations\n - automatic (experimental): use an automatic self-benchmarking algorithm \n - lr: logical ring reduce-scatter then logical ring allgather\n - rab1: variations of the  <a href=\"https://fs.hlrs.de/projects/par/mpi//myreduce.html\">Rabenseifner</a> algorithm: reduce_scatter then allgather\n - rab2: variations of the  <a href=\"https://fs.hlrs.de/projects/par/mpi//myreduce.html\">Rabenseifner</a> algorithm: alltoall then allgather\n - rab_rsag: variation of the  <a href=\"https://fs.hlrs.de/projects/par/mpi//myreduce.html\">Rabenseifner</a> algorithm: recursive doubling \n   reduce_scatter then recursive doubling allgather \n - rdb: recursive doubling\n - smp_binomial: binomial tree with smp: binomial intra \n   SMP reduce, inter reduce, inter broadcast then intra broadcast\n - smp_binomial_pipeline: same with segment size = 4096 bytes\n - smp_rdb: intra: binomial allreduce, inter: Recursive \n   doubling allreduce, intra: binomial broadcast\n - smp_rsag: intra: binomial allreduce, inter: reduce-scatter, \n   inter:allgather, intra: binomial broadcast\n - smp_rsag_lr: intra: binomial allreduce, inter: logical ring \n   reduce-scatter, logical ring inter:allgather, intra: binomial broadcast\n - smp_rsag_rab: intra: binomial allreduce, inter: rab\n   reduce-scatter, rab inter:allgather, intra: binomial broadcast\n - redbcast: reduce then broadcast, using default or tuned algorithms if specified\n - ompi_ring_segmented: ring algorithm used by OpenMPI\n - mvapich2_rs: rdb for small messages, reduce-scatter then allgather else\n - mvapich2_two_level: SMP-aware algorithm, with mpich as intra algoritm, and rdb as inter (Change this behavior by using mvapich2 selector to use tuned values)\n - rab: default `Rabenseifner <https://fs.hlrs.de/projects/par/mpi//myreduce.html>`_ implementation\n\nMPI_Reduce_scatter\n^^^^^^^^^^^^^^^^^^\n\n - default: naive one, by default\n - ompi: use openmpi selector for the reduce_scatter operations\n - mpich: use mpich selector for the reduce_scatter operations\n - mvapich2: use mvapich2 selector for the reduce_scatter operations\n - impi: use intel mpi selector for the reduce_scatter operations\n - automatic (experimental): use an automatic self-benchmarking algorithm \n - ompi_basic_recursivehalving: recursive halving version from OpenMPI\n - ompi_ring: ring version from OpenMPI\n - mpich_pair: pairwise exchange version from MPICH\n - mpich_rdb: recursive doubling version from MPICH\n - mpich_noncomm: only works for power of 2 procs, recursive doubling for noncommutative ops\n\n\nMPI_Allgather\n^^^^^^^^^^^^^\n\n - default: naive one, by default\n - ompi: use openmpi selector for the allgather operations\n - mpich: use mpich selector for the allgather operations\n - mvapich2: use mvapich2 selector for the allgather operations\n - impi: use intel mpi selector for the allgather operations\n - automatic (experimental): use an automatic self-benchmarking algorithm \n - 2dmesh: see alltoall\n - 3dmesh: see alltoall\n - bruck: Described by Bruck et.al. in <a href=\"http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=642949\">\n   Efficient algorithms for all-to-all communications in multiport message-passing systems</a> \n - GB: Gather - Broadcast (uses tuned version if specified)\n - loosely_lr: Logical Ring with grouping by core (hardcoded, default \n   processes/node: 4)\n - NTSLR: Non Topology Specific Logical Ring\n - NTSLR_NB: Non Topology Specific Logical Ring, Non Blocking operations\n - pair: see alltoall\n - rdb: see alltoall\n - rhv: only power of 2 number of processes\n - ring: see alltoall\n - SMP_NTS: gather to root of each SMP, then every root of each SMP node \n   post INTER-SMP Sendrecv, then do INTRA-SMP Bcast for each receiving message, \n   using logical ring algorithm (hardcoded, default processes/SMP: 8)\n - smp_simple: gather to root of each SMP, then every root of each SMP node \n   post INTER-SMP Sendrecv, then do INTRA-SMP Bcast for each receiving message, \n   using simple algorithm (hardcoded, default processes/SMP: 8)\n - spreading_simple: from node i, order of communications is i -> i + 1, i ->\n   i + 2, ..., i -> (i + p -1) % P\n - ompi_neighborexchange: Neighbor Exchange algorithm for allgather. \n   Described by Chen et.al. in  `Performance Evaluation of Allgather\n   Algorithms on Terascale Linux Cluster with Fast Ethernet <http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1592302>`_\n - mvapich2_smp: SMP aware algorithm, performing intra-node gather, inter-node allgather with one process/node, and bcast intra-node\n\nMPI_Allgatherv\n^^^^^^^^^^^^^^\n\n - default: naive one, by default\n - ompi: use openmpi selector for the allgatherv operations\n - mpich: use mpich selector for the allgatherv operations\n - mvapich2: use mvapich2 selector for the allgatherv operations\n - impi: use intel mpi selector for the allgatherv operations\n - automatic (experimental): use an automatic self-benchmarking algorithm \n - GB: Gatherv - Broadcast (uses tuned version if specified, but only for Bcast, gatherv is not tuned)\n - pair: see alltoall\n - ring: see alltoall\n - ompi_neighborexchange: see allgather\n - ompi_bruck: see allgather\n - mpich_rdb: recursive doubling algorithm from MPICH\n - mpich_ring: ring algorithm from MPICh - performs differently from the  one from STAR-MPI\n\nMPI_Bcast\n^^^^^^^^^\n\n - default: naive one, by default\n - ompi: use openmpi selector for the bcast operations\n - mpich: use mpich selector for the bcast operations\n - mvapich2: use mvapich2 selector for the bcast operations\n - impi: use intel mpi selector for the bcast operations\n - automatic (experimental): use an automatic self-benchmarking algorithm \n - arrival_pattern_aware: root exchanges with the first process to arrive\n - arrival_pattern_aware_wait: same with slight variation\n - binomial_tree: binomial tree exchange\n - flattree: flat tree exchange\n - flattree_pipeline: flat tree exchange, message split into 8192 bytes pieces\n - NTSB: Non-topology-specific pipelined binary tree with 8192 bytes pieces\n - NTSL: Non-topology-specific pipelined linear with 8192 bytes pieces\n - NTSL_Isend: Non-topology-specific pipelined linear with 8192 bytes pieces, asynchronous communications\n - scatter_LR_allgather: scatter followed by logical ring allgather\n - scatter_rdb_allgather: scatter followed by recursive doubling allgather\n - arrival_scatter: arrival pattern aware scatter-allgather\n - SMP_binary: binary tree algorithm with 8 cores/SMP\n - SMP_binomial: binomial tree algorithm with 8 cores/SMP\n - SMP_linear: linear algorithm with 8 cores/SMP\n - ompi_split_bintree: binary tree algorithm from OpenMPI, with message split in 8192 bytes pieces\n - ompi_pipeline: pipeline algorithm from OpenMPI, with message split in 128KB pieces\n - mvapich2_inter_node: Inter node default mvapich worker \n - mvapich2_intra_node: Intra node default mvapich worker\n - mvapich2_knomial_intra_node:  k-nomial intra node default mvapich worker. default factor is 4.\n\nAutomatic Evaluation\n^^^^^^^^^^^^^^^^^^^^\n\n.. warning:: This is still very experimental.\n\nAn automatic version is available for each collective (or even as a selector). This specific \nversion will loop over all other implemented algorithm for this particular collective, and apply \nthem while benchmarking the time taken for each process. It will then output the quickest for \neach process, and the global quickest. This is still unstable, and a few algorithms which need \nspecific number of nodes may crash.\n\nAdding an algorithm\n^^^^^^^^^^^^^^^^^^^\n\nTo add a new algorithm, one should check in the src/smpi/colls folder\nhow other algorithms are coded. Using plain MPI code inside Simgrid\ncan't be done, so algorithms have to be changed to use smpi version of\nthe calls instead (MPI_Send will become smpi_mpi_send). Some functions\nmay have different signatures than their MPI counterpart, please check\nthe other algorithms or contact us using the `>SimGrid\ndevelopers mailing list <http://lists.gforge.inria.fr/mailman/listinfo/simgrid-devel>`_.\n\nExample: adding a \"pair\" version of the Alltoall collective.\n\n - Implement it in a file called alltoall-pair.c in the src/smpi/colls folder. This file should include colls_private.hpp.\n\n - The name of the new algorithm function should be smpi_coll_tuned_alltoall_pair, with the same signature as MPI_Alltoall.\n\n - Once the adaptation to SMPI code is done, add a reference to the file (\"src/smpi/colls/alltoall-pair.c\") in the SMPI_SRC part of the DefinePackages.cmake file inside buildtools/cmake, to allow the file to be built and distributed.\n\n - To register the new version of the algorithm, simply add a line to the corresponding macro in src/smpi/colls/cools.h ( add a \"COLL_APPLY(action, COLL_ALLTOALL_SIG, pair)\" to the COLL_ALLTOALLS macro ). The algorithm should now be compiled and be selected when using --cfg=smpi/alltoall:pair at runtime.\n\n - To add a test for the algorithm inside Simgrid's test suite, juste add the new algorithm name in the ALLTOALL_COLL list found inside teshsuite/smpi/CMakeLists.txt . When running ctest, a test for the new algorithm should be generated and executed. If it does not pass, please check your code or contact us.\n\n - Please submit your patch for inclusion in SMPI, for example through a pull request on GitHub or directly per email.\n\n\nTracing of Internal Communications\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nBy default, the collective operations are traced as a unique operation\nbecause tracing all point-to-point communications composing them could\nresult in overloaded, hard to interpret traces. If you want to debug\nand compare collective algorithms, you should set the\n``tracing/smpi/internals`` configuration item to 1 instead of 0.\n\nHere are examples of two alltoall collective algorithms runs on 16 nodes, \nthe first one with a ring algorithm, the second with a pairwise one.\n\n.. image:: /img/smpi_simgrid_alltoall_ring_16.png\n   :align: center\n\t   \nAlltoall on 16 Nodes with the Ring Algorithm.\n\n.. image:: /img/smpi_simgrid_alltoall_pair_16.png\n   :align: center\n\t   \nAlltoall on 16 Nodes with the Pairwise Algorithm.\n\n-------------------------\nWhat can run within SMPI?\n-------------------------\n\nYou can run unmodified MPI applications (both C/C++ and Fortran) within\nSMPI, provided that you only use MPI calls that we implemented. Global\nvariables should be handled correctly on Linux systems.\n\n....................\nMPI coverage of SMPI\n....................\n\nOur coverage of the interface is very decent, but still incomplete;\nGiven the size of the MPI standard, we may well never manage to \nimplement absolutely all existing primitives. Currently, we have\nalmost no support for I/O primitives, but we still pass a very large\namount of the MPICH coverage tests.\n\nThe full list of not yet implemented functions is documented in the\nfile `include/smpi/smpi.h\n<https://framagit.org/simgrid/simgrid/tree/master/include/smpi/smpi.h>`_\nin your version of SimGrid, between two lines containing the ``FIXME``\nmarker. If you really miss a feature, please get in touch with us: we\ncan guide you though the SimGrid code to help you implementing it, and\nwe'd be glad to integrate your contribution to the main project.\n\n.. _SMPI_what_globals:\n\n.................................\nPrivatization of global variables\n.................................\n\nConcerning the globals, the problem comes from the fact that usually,\nMPI processes run as real UNIX processes while they are all folded\ninto threads of a unique system process in SMPI. Global variables are\nusually private to each MPI process while they become shared between\nthe processes in SMPI.  The problem and some potential solutions are\ndiscussed in this article: `Automatic Handling of Global Variables for\nMulti-threaded MPI Programs\n<http://charm.cs.illinois.edu/newPapers/11-23/paper.pdf>` (note that\nthis article does not deal with SMPI but with a competing solution\ncalled AMPI that suffers of the same issue).  This point used to be\nproblematic in SimGrid, but the problem should now be handled\nautomatically on Linux.\n\nOlder versions of SimGrid came with a script that automatically\nprivatized the globals through static analysis of the source code. But\nour implementation was not robust enough to be used in production, so\nit was removed at some point. Currently, SMPI comes with two\nprivatization mechanisms that you can :ref:`select at runtime\n<options_smpi_privatization>`_.  The dlopen approach is used by\ndefault as it is much faster and still very robust.  The mmap approach\nis an older approach that proves to be slower.\n\nWith the **mmap approach**, SMPI duplicates and dynamically switch the\n``.data`` and ``.bss`` segments of the ELF process when switching the\nMPI ranks. This allows each ranks to have its own copy of the global\nvariables.  No copy actually occures as this mechanism uses ``mmap()``\nfor efficiency. This mechanism is considered to be very robust on all\nsystems supporting ``mmap()`` (Linux and most BSDs). Its performance\nis questionable since each context switch between MPI ranks induces\nseveral syscalls to change the ``mmap`` that redirects the ``.data``\nand ``.bss`` segments to the copies of the new rank. The code will\nalso be copied several times in memory, inducing a slight increase of\nmemory occupation.\n\nAnother limitation is that SMPI only accounts for global variables\ndefined in the executable. If the processes use external global\nvariables from dynamic libraries, they won't be switched\ncorrectly. The easiest way to solve this is to statically link against\nthe library with these globals. This way, each MPI rank will get its\nown copy of these libraries. Of course you should never statically\nlink against the SimGrid library itself.\n\nWith the **dlopen approach**, SMPI loads several copies of the same\nexecutable in memory as if it were a library, so that the global\nvariables get naturally dupplicated. It first requires the executable\nto be compiled as a relocatable binary, which is less common for\nprograms than for libraries. But most distributions are now compiled\nthis way for security reason as it allows to randomize the address\nspace layout. It should thus be safe to compile most (any?) program\nthis way.  The second trick is that the dynamic linker refuses to link\nthe exact same file several times, be it a library or a relocatable\nexecutable. It makes perfectly sense in the general case, but we need\nto circumvent this rule of thumb in our case. To that extend, the\nbinary is copied in a temporary file before being re-linked against.\n``dlmopen()`` cannot be used as it only allows 256 contextes, and as it\nwould also dupplicate simgrid itself.\n\nThis approach greatly speeds up the context switching, down to about\n40 CPU cycles with our raw contextes, instead of requesting several\nsyscalls with the ``mmap()`` approach. Another advantage is that it\npermits to run the SMPI contexts in parallel, which is obviously not\npossible with the ``mmap()`` approach. It was tricky to implement, but\nwe are not aware of any flaws, so smpirun activates it by default.\n\nIn the future, it may be possible to further reduce the memory and\ndisk consumption. It seems that we could `punch holes\n<https://lwn.net/Articles/415889/>`_ in the files before dl-loading\nthem to remove the code and constants, and mmap these area onto a\nunique copy. If done correctly, this would reduce the disk- and\nmemory- usage to the bare minimum, and would also reduce the pressure\non the CPU instruction cache. See the `relevant bug\n<https://github.com/simgrid/simgrid/issues/137>`_ on github for\nimplementation leads.\\n\n\nAlso, currently, only the binary is copied and dlopen-ed for each MPI\nrank. We could probably extend this to external dependencies, but for\nnow, any external dependencies must be statically linked into your\napplication. As usual, simgrid itself shall never be statically linked\nin your app. You don't want to give a copy of SimGrid to each MPI rank:\nthat's ways too much for them to deal with.\n\n.. todo: speak of smpi/privatize-libs here\n\n----------------------------------------------\nAdapting your MPI code for further scalability\n----------------------------------------------\n\nAs detailed in the `reference article\n<http://hal.inria.fr/hal-01415484>`_, you may want to adapt your code\nto improve the simulation performance. But these tricks may seriously\nhinder the result quality (or even prevent the app to run) if used\nwrongly. We assume that if you want to simulate an HPC application,\nyou know what you are doing. Don't prove us wrong!\n\n..............................\nReducing your memory footprint\n..............................\n\nIf you get short on memory (the whole app is executed on a single node when\nsimulated), you should have a look at the SMPI_SHARED_MALLOC and\nSMPI_SHARED_FREE macros. It allows to share memory areas between processes: The\npurpose of these macro is that the same line malloc on each process will point\nto the exact same memory area. So if you have a malloc of 2M and you have 16\nprocesses, this macro will change your memory consumption from 2M*16 to 2M\nonly. Only one block for all processes.\n\nIf your program is ok with a block containing garbage value because all\nprocesses write and read to the same place without any kind of coordination,\nthen this macro can dramatically shrink your memory consumption. For example,\nthat will be very beneficial to a matrix multiplication code, as all blocks will\nbe stored on the same area. Of course, the resulting computations will useless,\nbut you can still study the application behavior this way. \n\nNaturally, this won't work if your code is data-dependent. For example, a Jacobi\niterative computation depends on the result computed by the code to detect\nconvergence conditions, so turning them into garbage by sharing the same memory\narea between processes does not seem very wise. You cannot use the\nSMPI_SHARED_MALLOC macro in this case, sorry.\n\nThis feature is demoed by the example file\n`examples/smpi/NAS/dt.c <https://framagit.org/simgrid/simgrid/tree/master/examples/smpi/NAS/dt.c>`_\n\n.........................\nToward Faster Simulations\n.........................\n\nIf your application is too slow, try using SMPI_SAMPLE_LOCAL,\nSMPI_SAMPLE_GLOBAL and friends to indicate which computation loops can\nbe sampled. Some of the loop iterations will be executed to measure\ntheir duration, and this duration will be used for the subsequent\niterations. These samples are done per processor with\nSMPI_SAMPLE_LOCAL, and shared between all processors with\nSMPI_SAMPLE_GLOBAL. Of course, none of this will work if the execution\ntime of your loop iteration are not stable.\n\nThis feature is demoed by the example file \n`examples/smpi/NAS/ep.c <https://framagit.org/simgrid/simgrid/tree/master/examples/smpi/NAS/ep.c>`_\n\n.............................\nEnsuring Accurate Simulations\n.............................\n\nOut of the box, SimGrid may give you fairly accurate results, but\nthere is a plenty of factors that could go wrong and make your results\ninaccurate or even plainly wrong. Actually, you can only get accurate\nresults of a nicely built model, including both the system hardware\nand your application. Such models are hard to pass over and reuse in\nother settings, because elements that are not relevant to an\napplication (say, the latency of point-to-point communications,\ncollective operation implementation details or CPU-network\ninteraction) may be irrelevant to another application. The dream of\nthe perfect model, encompassing every aspects is only a chimera, as\nthe only perfect model of the reality is the reality. If you go for\nsimulation, then you have to ignore some irrelevant aspects of the\nreality, but which aspects are irrelevant is actually\napplication-dependent...\n\nThe only way to assess whether your settings provide accurate results\nis to double-check these results. If possible, you should first run\nthe same experiment in simulation and in real life, gathering as much\ninformation as you can. Try to understand the discrepancies in the\nresults that you observe between both settings (visualization can be\nprecious for that). Then, try to modify your model (of the platform,\nof the collective operations) to reduce the most preeminent differences.\n\nIf the discrepancies come from the computing time, try adapting the \n``smpi/host-speed``: reduce it if your simulation runs faster than in\nreality. If the error come from the communication, then you need to\nfiddle with your platform file.\n\nBe inventive in your modeling. Don't be afraid if the names given by\nSimGrid does not match the real names: we got very good results by\nmodeling multicore/GPU machines with a set of separate hosts\ninterconnected with very fast networks (but don't trust your model\nbecause it has the right names in the right place either).\n\nFinally, you may want to check `this article\n<https://hal.inria.fr/hal-00907887>`_ on the classical pitfalls in\nmodeling distributed systems.\n\n-------------------------\nTroubleshooting with SMPI\n-------------------------\n\n.................................\n./configure refuses to use smpicc\n.................................\n\nIf your ``./configure`` reports that the compiler is not\nfunctional or that you are cross-compiling, try to define the\n``SMPI_PRETEND_CC`` environment variable before running the\nconfiguration.\n\n.. code-block:: shell\n\n   SMPI_PRETEND_CC=1 ./configure # here come the configure parameters\n   make\n\nIndeed, the programs compiled with ``smpicc`` cannot be executed\nwithout ``smpirun`` (they are shared libraries and do weird things on\nstartup), while configure wants to test them directly.  With\n``SMPI_PRETEND_CC`` smpicc does not compile as shared, and the SMPI\ninitialization stops and returns 0 before doing anything that would\nfail without ``smpirun``.\n\n.. warning::\n\n  Make sure that SMPI_PRETEND_CC is only set when calling ./configure,\n  not during the actual execution, or any program compiled with smpicc\n  will stop before starting.\n\n..............................................\n./configure does not pick smpicc as a compiler\n..............................................\n\nIn addition to the previous answers, some projects also need to be\nexplicitely told what compiler to use, as follows:\n\n.. code-block:: shell\n\t\t\n   SMPI_PRETEND_CC=1 ./configure CC=smpicc # here come the other configure parameters\n   make\n\nMaybe your configure is using another variable, such as ``cc`` (in\nlower case) or similar. Just check the logs.\n\n.....................................\nerror: unknown type name 'useconds_t'\n.....................................\n\nTry to add ``-D_GNU_SOURCE`` to your compilation line to get ride\nof that error.\n\nThe reason is that SMPI provides its own version of ``usleep(3)``\nto override it and to block in the simulation world, not in the real\none. It needs the ``useconds_t`` type for that, which is declared\nonly if you declare ``_GNU_SOURCE`` before including\n``unistd.h``. If your project includes that header file before\nSMPI, then you need to ensure that you pass the right configuration\ndefines as advised above.\n",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.21-2jw7hfw3ki7yfy6d52vbzhst6fypdxym/spack-src/docs/source/scenar_config.rst": ".. _options:\n\nConfiguring SimGrid\n===================\n\n.. raw:: html\n\n   <object id=\"TOC\" data=\"graphical-toc.svg\" width=\"100%\" type=\"image/svg+xml\"></object>\n   <script>\n   window.onload=function() { // Wait for the SVG to be loaded before changing it\n     var elem=document.querySelector(\"#TOC\").contentDocument.getElementById(\"ConfigBox\")\n     elem.style=\"opacity:0.93999999;fill:#ff0000;fill-opacity:0.1;stroke:#000000;stroke-width:0.35277778;stroke-linecap:round;stroke-linejoin:round;stroke-miterlimit:4;stroke-dasharray:none;stroke-dashoffset:0;stroke-opacity:1\";\n   }\n   </script>\n   <br/>\n   <br/>\n\nA number of options can be given at runtime to change the default\nSimGrid behavior. For a complete list of all configuration options\naccepted by the SimGrid version used in your simulator, simply pass\nthe --help configuration flag to your program. If some of the options\nare not documented on this page, this is a bug that you should please\nreport so that we can fix it. Note that some of the options presented\nhere may not be available in your simulators, depending on the\n:ref:`compile-time options <install_src_config>` that you used.\n\nSetting Configuration Items\n---------------------------\n\nThere is several way to pass configuration options to the simulators.\nThe most common way is to use the ``--cfg`` command line argument. For\nexample, to set the item ``Item`` to the value ``Value``, simply\ntype the following on the command-line:\n\n.. code-block:: shell\n\t\t\n   my_simulator --cfg=Item:Value (other arguments)\n\nSeveral ``--cfg`` command line arguments can naturally be used. If you\nneed to include spaces in the argument, don't forget to quote the\nargument. You can even escape the included quotes (write @' for ' if\nyou have your argument between ').\n\nAnother solution is to use the ``<config>`` tag in the platform file. The\nonly restriction is that this tag must occure before the first\nplatform element (be it ``<zone>``, ``<cluster>``, ``<peer>`` or whatever).\nThe ``<config>`` tag takes an ``id`` attribute, but it is currently\nignored so you don't really need to pass it. The important part is that\nwithin that tag, you can pass one or several ``<prop>`` tags to specify\nthe configuration to use. For example, setting ``Item`` to ``Value``\ncan be done by adding the following to the beginning of your platform\nfile:\n\n.. code-block:: xml\n\t\t\n  <config>\n    <prop id=\"Item\" value=\"Value\"/>\n  </config>\n\nA last solution is to pass your configuration directly in your program\nwith :cpp:func:`simgrid::s4u::Engine::set_config` or :cpp:func:`MSG_config`.\n\n.. code-block:: cpp\n\t\t\n   #include <simgrid/s4u.hpp>\n\n   int main(int argc, char *argv[]) {\n     simgrid::s4u::Engine e(&argc, argv);\n     \n     e->set_config(\"Item:Value\");\n     \n     // Rest of your code\n   }\n\nExisting Configuration Items\n----------------------------\n\n.. note::\n  The full list can be retrieved by passing ``--help`` and\n  ``--help-cfg`` to an executable that uses SimGrid.\n\n- **clean-atexit:** :ref:`cfg=clean-atexit`\n\n- **contexts/factory:** :ref:`cfg=contexts/factory`\n- **contexts/guard-size:** :ref:`cfg=contexts/guard-size`\n- **contexts/nthreads:** :ref:`cfg=contexts/nthreads`\n- **contexts/parallel-threshold:** :ref:`cfg=contexts/parallel-threshold`\n- **contexts/stack-size:** :ref:`cfg=contexts/stack-size`\n- **contexts/synchro:** :ref:`cfg=contexts/synchro`\n\n- **cpu/maxmin-selective-update:** :ref:`Cpu Optimization Level <options_model_optim>`\n- **cpu/model:** :ref:`options_model_select`\n- **cpu/optim:** :ref:`Cpu Optimization Level <options_model_optim>`\n\n- **exception/cutpath:** :ref:`cfg=exception/cutpath`\n\n- **host/model:** :ref:`options_model_select`\n\n- **maxmin/precision:** :ref:`cfg=maxmin/precision`\n- **maxmin/concurrency-limit:** :ref:`cfg=maxmin/concurrency-limit`\n\n- **msg/debug-multiple-use:** :ref:`cfg=msg/debug-multiple-use`\n\n- **model-check:** :ref:`options_modelchecking`\n- **model-check/checkpoint:** :ref:`cfg=model-check/checkpoint`\n- **model-check/communications-determinism:** :ref:`cfg=model-check/communications-determinism`\n- **model-check/dot-output:** :ref:`cfg=model-check/dot-output`\n- **model-check/hash:** :ref:`cfg=model-checker/hash`\n- **model-check/max-depth:** :ref:`cfg=model-check/max-depth`\n- **model-check/property:** :ref:`cfg=model-check/property`\n- **model-check/record:** :ref:`cfg=model-check/record`\n- **model-check/reduction:** :ref:`cfg=model-check/reduction`\n- **model-check/replay:** :ref:`cfg=model-check/replay`\n- **model-check/send-determinism:** :ref:`cfg=model-check/send-determinism`\n- **model-check/sparse-checkpoint:** :ref:`cfg=model-check/sparse-checkpoint`\n- **model-check/termination:** :ref:`cfg=model-check/termination`\n- **model-check/timeout:** :ref:`cfg=model-check/timeout`\n- **model-check/visited:** :ref:`cfg=model-check/visited`\n\n- **network/bandwidth-factor:** :ref:`cfg=network/bandwidth-factor`\n- **network/crosstraffic:** :ref:`cfg=network/crosstraffic`\n- **network/latency-factor:** :ref:`cfg=network/latency-factor`\n- **network/maxmin-selective-update:** :ref:`Network Optimization Level <options_model_optim>`\n- **network/model:** :ref:`options_model_select`\n- **network/optim:** :ref:`Network Optimization Level <options_model_optim>`\n- **network/TCP-gamma:** :ref:`cfg=network/TCP-gamma`\n- **network/weight-S:** :ref:`cfg=network/weight-S`\n\n- **ns3/TcpModel:** :ref:`options_pls`\n- **path:** :ref:`cfg=path`\n- **plugin:** :ref:`cfg=plugin`\n\n- **simix/breakpoint:** :ref:`cfg=simix/breakpoint`\n\n- **storage/max_file_descriptors:** :ref:`cfg=storage/max_file_descriptors`\n\n- **surf/precision:** :ref:`cfg=surf/precision`\n\n- **For collective operations of SMPI,** please refer to Section :ref:`cfg=smpi/coll-selector`\n- **smpi/async-small-thresh:** :ref:`cfg=smpi/async-small-thresh`\n- **smpi/bw-factor:** :ref:`cfg=smpi/bw-factor`\n- **smpi/coll-selector:** :ref:`cfg=smpi/coll-selector`\n- **smpi/comp-adjustment-file:** :ref:`cfg=smpi/comp-adjustment-file`\n- **smpi/cpu-threshold:** :ref:`cfg=smpi/cpu-threshold`\n- **smpi/display-timing:** :ref:`cfg=smpi/display-timing`\n- **smpi/grow-injected-times:** :ref:`cfg=smpi/grow-injected-times`\n- **smpi/host-speed:** :ref:`cfg=smpi/host-speed`\n- **smpi/IB-penalty-factors:** :ref:`cfg=smpi/IB-penalty-factors`\n- **smpi/iprobe:** :ref:`cfg=smpi/iprobe`\n- **smpi/iprobe-cpu-usage:** :ref:`cfg=smpi/iprobe-cpu-usage`\n- **smpi/init:** :ref:`cfg=smpi/init`\n- **smpi/keep-temps:** :ref:`cfg=smpi/keep-temps`\n- **smpi/lat-factor:** :ref:`cfg=smpi/lat-factor`\n- **smpi/ois:** :ref:`cfg=smpi/ois`\n- **smpi/or:** :ref:`cfg=smpi/or`\n- **smpi/os:** :ref:`cfg=smpi/os`\n- **smpi/papi-events:** :ref:`cfg=smpi/papi-events`\n- **smpi/privatization:** :ref:`cfg=smpi/privatization`\n- **smpi/privatize-libs:** :ref:`cfg=smpi/privatize-libs`\n- **smpi/send-is-detached-thresh:** :ref:`cfg=smpi/send-is-detached-thresh`\n- **smpi/shared-malloc:** :ref:`cfg=smpi/shared-malloc`\n- **smpi/shared-malloc-hugepage:** :ref:`cfg=smpi/shared-malloc-hugepage`\n- **smpi/simulate-computation:** :ref:`cfg=smpi/simulate-computation`\n- **smpi/test:** :ref:`cfg=smpi/test`\n- **smpi/wtime:** :ref:`cfg=smpi/wtime`\n\n- **Tracing configuration options** can be found in Section :ref:`tracing_tracing_options`\n\n- **storage/model:** :ref:`options_model_select`\n- **verbose-exit:** :ref:`cfg=verbose-exit`\n\n- **vm/model:** :ref:`options_model_select`\n\n.. _options_model:\n\nConfiguring the Platform Models\n-------------------------------\n\n.. _options_model_select:\n\nChoosing the Platform Models\n............................\n\nSimGrid comes with several network, CPU and storage models built in,\nand you can change the used model at runtime by changing the passed\nconfiguration. The three main configuration items are given below.\nFor each of these items, passing the special ``help`` value gives you\na short description of all possible values (for example,\n``--cfg=network/model:help`` will present all provided network\nmodels). Also, ``--help-models`` should provide information about all\nmodels for all existing resources.\n\n- ``network/model``: specify the used network model. Possible values:\n  \n  - **LV08 (default one):** Realistic network analytic model\n    (slow-start modeled by multiplying latency by 13.01, bandwidth by\n    .97; bottleneck sharing uses a payload of S=20537 for evaluating\n    RTT). Described in `Accuracy Study and Improvement of Network\n    Simulation in the SimGrid Framework\n    <http://mescal.imag.fr/membres/arnaud.legrand/articles/simutools09.pdf>`_.     \n  - **Constant:** Simplistic network model where all communication\n    take a constant time (one second). This model provides the lowest\n    realism, but is (marginally) faster.\n  - **SMPI:** Realistic network model specifically tailored for HPC\n    settings (accurate modeling of slow start with correction factors on\n    three intervals: < 1KiB, < 64 KiB, >= 64 KiB). This model can be\n    :ref:`further configured <options_model_network>`.\n  - **IB:** Realistic network model specifically tailored for HPC\n    settings with InfiniBand networks (accurate modeling contention\n    behavior, based on the model explained in `this PhD work\n    <http://mescal.imag.fr/membres/jean-marc.vincent/index.html/PhD/Vienne.pdf>`_.\n    This model can be :ref:`further configured <options_model_network>`.\n  - **CM02:** Legacy network analytic model. Very similar to LV08, but\n    without corrective factors. The timings of small messages are thus\n    poorly modeled. This model is described in `A Network Model for\n    Simulation of Grid Application\n    <ftp://ftp.ens-lyon.fr/pub/LIP/Rapports/RR/RR2002/RR2002-40.ps.gz>`_.\n  - **Reno/Reno2/Vegas:** Models from Steven H. Low using lagrange_solve instead of\n    lmm_solve (experts only; check the code for more info).\n  - **NS3** (only available if you compiled SimGrid accordingly): \n    Use the packet-level network\n    simulators as network models (see :ref:`pls_ns3`).\n    This model can be :ref:`further configured <options_pls>`.\n    \n- ``cpu/model``: specify the used CPU model.  We have only one model\n  for now:\n\n  - **Cas01:** Simplistic CPU model (time=size/power)\n\n- ``host/model``: The host concept is the aggregation of a CPU with a\n  network card. Three models exists, but actually, only 2 of them are\n  interesting. The \"compound\" one is simply due to the way our\n  internal code is organized, and can easily be ignored. So at the\n  end, you have two host models: The default one allows to aggregate\n  an existing CPU model with an existing network model, but does not\n  allow parallel tasks because these beasts need some collaboration\n  between the network and CPU model. That is why, ptask_07 is used by\n  default when using SimDag.\n  \n  - **default:** Default host model. Currently, CPU:Cas01 and\n    network:LV08 (with cross traffic enabled)\n  - **compound:** Host model that is automatically chosen if\n    you change the network and CPU models\n  - **ptask_L07:** Host model somehow similar to Cas01+CM02 but\n    allowing \"parallel tasks\", that are intended to model the moldable\n    tasks of the grid scheduling literature.\n\n- ``storage/model``: specify the used storage model. Only one model is\n  provided so far.\n- ``vm/model``: specify the model for virtual machines. Only one model\n  is provided so far.\n\n.. todo: make 'compound' the default host model.\n\n.. _options_model_optim:\n\nOptimization Level\n..................\n\nThe network and CPU models that are based on lmm_solve (that\nis, all our analytical models) accept specific optimization\nconfigurations.\n\n  - items ``network/optim`` and ``cpu/optim`` (both default to 'Lazy'):\n    \n    - **Lazy:** Lazy action management (partial invalidation in lmm +\n      heap in action remaining).\n    - **TI:** Trace integration. Highly optimized mode when using\n      availability traces (only available for the Cas01 CPU model for\n      now).\n    - **Full:** Full update of remaining and variables. Slow but may be\n      useful when debugging.\n      \n  - items ``network/maxmin-selective-update`` and\n    ``cpu/maxmin-selective-update``: configure whether the underlying\n    should be lazily updated or not. It should have no impact on the\n    computed timings, but should speed up the computation. |br| It is\n    still possible to disable this feature because it can reveal\n    counter-productive in very specific scenarios where the\n    interaction level is high. In particular, if all your\n    communication share a given backbone link, you should disable it:\n    without it, a simple regular loop is used to update each\n    communication. With it, each of them is still updated (because of\n    the dependency induced by the backbone), but through a complicated\n    and slow pattern that follows the actual dependencies.\n\n.. _cfg=maxmin/precision:\n.. _cfg=surf/precision:\n\nNumerical Precision\n...................\n\n**Option** ``maxmin/precision`` **Default:** 0.00001 (in flops or bytes) |br|\n**Option** ``surf/precision`` **Default:** 0.00001 (in seconds)\n\nThe analytical models handle a lot of floating point values. It is\npossible to change the epsilon used to update and compare them through\nthis configuration item. Changing it may speedup the simulation by\ndiscarding very small actions, at the price of a reduced numerical\nprecision. You can modify separately the precision used to manipulate\ntimings (in seconds) and the one used to manipulate amounts of work\n(in flops or bytes).\n\n.. _cfg=maxmin/concurrency-limit:\n\nConcurrency Limit\n.................\n\n**Option** ``maxmin/concurrency-limit`` **Default:** -1 (no limit)\n\nThe maximum number of variables per resource can be tuned through this\noption. You can have as many simultaneous actions per resources as you\nwant. If your simulation presents a very high level of concurrency, it\nmay help to use e.g. 100 as a value here. It means that at most 100\nactions can consume a resource at a given time. The extraneous actions\nare queued and wait until the amount of concurrency of the considered\nresource lowers under the given boundary.\n\nSuch limitations help both to the simulation speed and simulation accuracy\non highly constrained scenarios, but the simulation speed suffers of this\nsetting on regular (less constrained) scenarios so it is off by default.\n\n.. _options_model_network:\n\nConfiguring the Network Model\n.............................\n\n.. _cfg=network/TCP-gamma:\n\nMaximal TCP Window Size\n^^^^^^^^^^^^^^^^^^^^^^^\n\n**Option** ``network/TCP-gamma`` **Default:** 4194304\n\nThe analytical models need to know the maximal TCP window size to take\nthe TCP congestion mechanism into account.  On Linux, this value can\nbe retrieved using the following commands. Both give a set of values,\nand you should use the last one, which is the maximal size.\n\n.. code-block:: shell\n\t\t\n   cat /proc/sys/net/ipv4/tcp_rmem # gives the sender window\n   cat /proc/sys/net/ipv4/tcp_wmem # gives the receiver window\n\n.. _cfg=smpi/IB-penalty-factors:\n.. _cfg=network/bandwidth-factor:\n.. _cfg=network/latency-factor:\n.. _cfg=network/weight-S:\n   \nCorrecting Important Network Parameters\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nSimGrid can take network irregularities such as a slow startup or\nchanging behavior depending on the message size into account.  You\nshould not change these values unless you really know what you're\ndoing.  The corresponding values were computed through data fitting\none the timings of packet-level simulators, as described in `Accuracy\nStudy and Improvement of Network Simulation in the SimGrid Framework\n<http://mescal.imag.fr/membres/arnaud.legrand/articles/simutools09.pdf>`_.\n\n\nIf you are using the SMPI model, these correction coefficients are\nthemselves corrected by constant values depending on the size of the\nexchange.  By default SMPI uses factors computed on the Stampede\nSupercomputer at TACC, with optimal deployment of processes on\nnodes. Again, only hardcore experts should bother about this fact.\n\nInfiniBand network behavior can be modeled through 3 parameters\n``smpi/IB-penalty-factors:\"\u03b2e;\u03b2s;\u03b3s\"``, as explained in `this PhD\nthesis\n<http://mescal.imag.fr/membres/jean-marc.vincent/index.html/PhD/Vienne.pdf>`_.\n\n.. todo:: This section should be rewritten, and actually explain the\n\t  options network/bandwidth-factor, network/latency-factor,\n\t  network/weight-S.\n\n.. _cfg=network/crosstraffic:\n\nSimulating Cross-Traffic\n^^^^^^^^^^^^^^^^^^^^^^^^\n\nSince SimGrid v3.7, cross-traffic effects can be taken into account in\nanalytical simulations. It means that ongoing and incoming\ncommunication flows are treated independently. In addition, the LV08\nmodel adds 0.05 of usage on the opposite direction for each new\ncreated flow. This can be useful to simulate some important TCP\nphenomena such as ack compression.\n\nFor that to work, your platform must have two links for each\npair of interconnected hosts. An example of usable platform is\navailable in ``examples/platforms/crosstraffic.xml``.\n\nThis is activated through the ``network/crosstraffic`` item, that\ncan be set to 0 (disable this feature) or 1 (enable it).\n\nNote that with the default host model this option is activated by default.\n\n.. _cfg=smpi/async-small-thresh:\n\nSimulating Asyncronous Send\n^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n(this configuration item is experimental and may change or disapear)\n\nIt is possible to specify that messages below a certain size will be\nsent as soon as the call to MPI_Send is issued, without waiting for\nthe correspondant receive. This threshold can be configured through\nthe ``smpi/async-small-thresh`` item. The default value is 0. This\nbehavior can also be manually set for mailboxes, by setting the\nreceiving mode of the mailbox with a call to\n:cpp:func:`MSG_mailbox_set_async`. After this, all messages sent to\nthis mailbox will have this behavior regardless of the message size.\n\nThis value needs to be smaller than or equals to the threshold set at\n@ref options_model_smpi_detached , because asynchronous messages are\nmeant to be detached as well.\n\n.. _options_pls:\n\nConfiguring NS3\n^^^^^^^^^^^^^^^\n\n**Option** ``ns3/TcpModel`` **Default:** \"default\" (NS3 default)\n\nWhen using NS3, there is an extra item ``ns3/TcpModel``, corresponding\nto the ``ns3::TcpL4Protocol::SocketType`` configuration item in\nNS3. The only valid values (enforced on the SimGrid side) are\n'default' (no change to the NS3 configuration), 'NewReno' or 'Reno' or\n'Tahoe'.\n\nConfiguring the Storage model\n.............................\n\n.. _cfg=storage/max_file_descriptors:\n\nFile Descriptor Cound per Host\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n**Option** ``storage/max_file_descriptors`` **Default:** 1024\n\nEach host maintains a fixed-size array of its file descriptors. You\ncan change its size through this item to either enlarge it if your\napplication requires it or to reduce it to save memory space.\n\n.. _cfg=plugin:\n\nActivating Plugins\n------------------\n\nSimGrid plugins allow to extend the framework without changing its\nsource code directly. Read the source code of the existing plugins to\nlearn how to do so (in ``src/plugins``), and ask your questions to the\nusual channels (Stack Overflow, Mailing list, IRC). The basic idea is\nthat plugins usually register callbacks to some signals of interest.\nIf they need to store some information about a given object (Link, CPU\nor Actor), they do so through the use of a dedicated object extension.\n\nSome of the existing plugins can be activated from the command line,\nmeaning that you can activate them from the command line without any\nmodification to your simulation code. For example, you can activate\nthe host energy plugin by adding ``--cfg=plugin:host_energy`` to your\ncommand line.\n\nHere is the full list of plugins that can be activated this way:\n\n - **host_energy:** keeps track of the energy dissipated by\n   computations. More details in @ref plugin_energy.\n - **link_energy:** keeps track of the energy dissipated by\n   communications. More details in @ref SURF_plugin_energy.\n - **host_load:** keeps track of the computational load. \n   More details in @ref plugin_load.\n\n.. _options_modelchecking:\n   \nConfiguring the Model-Checking\n------------------------------\n\nTo enable the SimGrid model-checking support the program should\nbe executed using the simgrid-mc wrapper:\n\n.. code-block:: shell\n\t\t\n   simgrid-mc ./my_program\n\nSafety properties are expressed as assertions using the function\n:cpp:func:`void MC_assert(int prop)`.\n\n.. _cfg=model-check/property:\n     \nSpecifying a liveness property\n..............................\n\n**Option** ``model-check/property`` **Default:** unset\n\nIf you want to specify liveness properties, you have to pass them on\nthe command line, specifying the name of the file containing the\nproperty, as formatted by the ltl2ba program.\n\n\n.. code-block:: shell\n\t\t\n   simgrid-mc ./my_program --cfg=model-check/property:<filename>\n\n.. _cfg=model-check/checkpoint:\n   \nGoing for Stateful Verification\n...............................\n\nBy default, the system is backtracked to its initial state to explore\nanother path instead of backtracking to the exact step before the fork\nthat we want to explore (this is called stateless verification). This\nis done this way because saving intermediate states can rapidly\nexhaust the available memory. If you want, you can change the value of\nthe ``model-check/checkpoint`` item. For example,\n``--cfg=model-check/checkpoint:1`` asks to take a checkpoint every\nstep.  Beware, this will certainly explode your memory. Larger values\nare probably better, make sure to experiment a bit to find the right\nsetting for your specific system.\n\n.. _cfg=model-check/reduction:\n\nSpecifying the kind of reduction\n................................\n\nThe main issue when using the model-checking is the state space\nexplosion. To counter that problem, you can chose a exploration\nreduction techniques with\n``--cfg=model-check/reduction:<technique>``. For now, this\nconfiguration variable can take 2 values:\n\n - **none:** Do not apply any kind of reduction (mandatory for now for\n   liveness properties)\n - **dpor:** Apply Dynamic Partial Ordering Reduction. Only valid if\n   you verify local safety properties (default value for safety\n   checks).\n\nThere is unfortunately no silver bullet here, and the most efficient\nreduction techniques cannot be applied to any properties. In\nparticular, the DPOR method cannot be applied on liveness properties\nsince our implementation of DPOR may break some cycles, while cycles\nare very important to the soundness of the exploration for liveness\nproperties.\n\n.. _cfg=model-check/visited:\n\nSize of Cycle Detection Set\n...........................\n\nIn order to detect cycles, the model-checker needs to check if a new\nexplored state is in fact the same state than a previous one. For\nthat, the model-checker can take a snapshot of each visited state:\nthis snapshot is then used to compare it with subsequent states in the\nexploration graph.\n\nThe ``model-check/visited`` item is the maximum number of states which\nare stored in memory. If the maximum number of snapshotted state is\nreached, some states will be removed from the memory and some cycles\nmight be missed. Small values can lead to incorrect verifications, but\nlarge value can exhaust your memory, so choose carefully.\n\nBy default, no state is snapshotted and cycles cannot be detected.\n\n.. _cfg=model-check/termination:\n\nNon-Termination Detection\n.........................\n\nThe ``model-check/termination`` configuration item can be used to\nreport if a non-termination execution path has been found. This is a\npath with a cycle which means that the program might never terminate.\n\nThis only works in safety mode, not in liveness mode.\n\nThis options is disabled by default.\n\n.. _cfg=model-check/dot-output:\n\nDot Output\n..........\n\nIf set, the ``model-check/dot-output`` configuration item is the name\nof a file in which to write a dot file of the path leading the found\nproperty (safety or liveness violation) as well as the cycle for\nliveness properties. This dot file can then fed to the graphviz dot\ntool to generate an corresponding graphical representation.\n\n.. _cfg=model-check/max-depth:\n\nExploration Depth Limit\n.......................\n\nThe ``model-checker/max-depth`` can set the maximum depth of the\nexploration graph of the model-checker. If this limit is reached, a\nlogging message is sent and the results might not be exact.\n\nBy default, there is not depth limit.\n\n.. _cfg=model-check/timeout:\n\nHandling of Timeouts\n....................\n\nBy default, the model-checker does not handle timeout conditions: the `wait`\noperations never time out. With the ``model-check/timeout`` configuration item\nset to **yes**, the model-checker will explore timeouts of `wait` operations.\n\n.. _cfg=model-check/communications-determinism:\n.. _cfg=model-check/send-determinism:\n\nCommunication Determinism\n.........................\n\nThe ``model-check/communications-determinism`` and\n``model-check/send-determinism`` items can be used to select the\ncommunication determinism mode of the model-checker which checks\ndeterminism properties of the communications of an application.\n\n.. _cfg=model-check/sparse-checkpoint:\n\nIncremental Checkpoints\n.......................\n\nWhen the model-checker is configured to take a snapshot of each\nexplored state (with the ``model-checker/visited`` item), the memory\nconsumption can rapidly reach GiB ou Tib of memory. However, for many\nworkloads, the memory does not change much between different snapshots\nand taking a complete copy of each snapshot is a waste of memory.\n\nThe ``model-check/sparse-checkpoint`` option item can be set to\n**yes** to avoid making a complete copy of each snapshot. Instead,\neach snapshot will be decomposed in blocks which will be stored\nseparately.  If multiple snapshots share the same block (or if the\nsame block is used in the same snapshot), the same copy of the block\nwill be shared leading to a reduction of the memory footprint.\n\nFor many applications, this option considerably reduces the memory\nconsumption.  In somes cases, the model-checker might be slightly\nslower because of the time taken to manage the metadata about the\nblocks. In other cases however, this snapshotting strategy will be\nmuch faster by reducing the cache consumption.  When the memory\nconsumption is important, by avoiding to hit the swap or reducing the\nswap usage, this option might be much faster than the basic\nsnapshotting strategy.\n\nThis option is currently disabled by default.\n\nVerification Performance Considerations\n.......................................\n\nThe size of the stacks can have a huge impact on the memory\nconsumption when using model-checking. By default, each snapshot will\nsave a copy of the whole stacks and not only of the part which is\nreally meaningful: you should expect the contribution of the memory\nconsumption of the snapshots to be @f$ @mbox{number of processes}\n@times @mbox{stack size} @times @mbox{number of states} @f$.\n\nThe ``model-check/sparse-checkpoint`` can be used to reduce the memory\nconsumption by trying to share memory between the different snapshots.\n\nWhen compiled against the model checker, the stacks are not\nprotected with guards: if the stack size is too small for your\napplication, the stack will silently overflow on other parts of the\nmemory (see :ref:`contexts/guard-size <cfg=contexts/guard-size>`).\n\n.. _cfg=model-checker/hash:\n\nState Hashing\n.............\n\nUsually most of the time of the model-checker is spent comparing states. This\nprocess is complicated and consumes a lot of bandwidth and cache.\nIn order to speedup the state comparison, the experimental ``model-checker/hash``\nconfiguration item enables the computation of a hash summarizing as much\ninformation of the state as possible into a single value. This hash can be used\nto avoid most of the comparisons: the costly comparison is then only used when\nthe hashes are identical.\n\nCurrently most of the state is not included in the hash because the\nimplementation was found to be buggy and this options is not as useful as\nit could be. For this reason, it is currently disabled by default.\n\n.. _cfg=model-check/record:\n.. _cfg=model-check/replay:\n\nRecord/Replay of Verification\n.............................\n\nAs the model-checker keeps jumping at different places in the execution graph,\nit is difficult to understand what happens when trying to debug an application\nunder the model-checker. Event the output of the program is difficult to\ninterpret. Moreover, the model-checker does not behave nicely with advanced\ndebugging tools such as valgrind. For those reason, to identify a trajectory\nin the execution graph with the model-checker and replay this trajcetory and\nwithout the model-checker black-magic but with more standard tools\n(such as a debugger, valgrind, etc.). For this reason, Simgrid implements an\nexperimental record/replay functionnality in order to record a trajectory with\nthe model-checker and replay it without the model-checker.\n\nWhen the model-checker finds an interesting path in the application\nexecution graph (where a safety or liveness property is violated), it\ncan generate an identifier for this path. To enable this behavious the\n``model-check/record`` must be set to **yes**, which is not the case\nby default.\n\nHere is an example of output:\n\n.. code-block:: shell\n\n   [  0.000000] (0:@) Check a safety property\n   [  0.000000] (0:@) **************************\n   [  0.000000] (0:@) *** PROPERTY NOT VALID ***\n   [  0.000000] (0:@) **************************\n   [  0.000000] (0:@) Counter-example execution trace:\n   [  0.000000] (0:@) Path = 1/3;1/4\n   [  0.000000] (0:@) [(1)Tremblay (app)] MC_RANDOM(3)\n   [  0.000000] (0:@) [(1)Tremblay (app)] MC_RANDOM(4)\n   [  0.000000] (0:@) Expanded states = 27\n   [  0.000000] (0:@) Visited states = 68\n   [  0.000000] (0:@) Executed transitions = 46\n\nThis path can then be replayed outside of the model-checker (and even\nin non-MC build of simgrid) by setting the ``model-check/replay`` item\nto the given path. The other options should be the same (but the\nmodel-checker should be disabled).\n\nThe format and meaning of the path may change between different\nreleases so the same release of Simgrid should be used for the record\nphase and the replay phase.\n\nConfiguring the User Code Virtualization\n----------------------------------------\n\n.. _cfg=contexts/factory:\n\nSelecting the Virtualization Factory\n....................................\n\n**Option** contexts/factory **Default:** \"raw\"\n\nIn SimGrid, the user code is virtualized in a specific mechanism that\nallows the simulation kernel to control its execution: when a user\nprocess requires a blocking action (such as sending a message), it is\ninterrupted, and only gets released when the simulated clock reaches\nthe point where the blocking operation is done. This is explained\ngraphically in the `relevant tutorial, available online\n<http://simgrid.gforge.inria.fr/tutorials/simgrid-simix-101.pdf>`_.\n\nIn SimGrid, the containers in which user processes are virtualized are\ncalled contexts. Several context factory are provided, and you can\nselect the one you want to use with the ``contexts/factory``\nconfiguration item. Some of the following may not exist on your\nmachine because of portability issues. In any case, the default one\nshould be the most effcient one (please report bugs if the\nauto-detection fails for you). They are approximately sorted here from\nthe slowest to the most efficient:\n\n - **thread:** very slow factory using full featured threads (either\n   pthreads or windows native threads). They are slow but very\n   standard. Some debuggers or profilers only work with this factory.\n - **java:** Java applications are virtualized onto java threads (that\n   are regular pthreads registered to the JVM)\n - **ucontext:** fast factory using System V contexts (Linux and FreeBSD only)\n - **boost:** This uses the `context\n   implementation <http://www.boost.org/doc/libs/1_59_0/libs/context/doc/html/index.html>`_\n   of the boost library for a performance that is comparable to our\n   raw implementation.\n   |br| Install the relevant library (e.g. with the\n   libboost-contexts-dev package on Debian/Ubuntu) and recompile\n   SimGrid. \n - **raw:** amazingly fast factory using a context switching mechanism\n   of our own, directly implemented in assembly (only available for x86\n   and amd64 platforms for now) and without any unneeded system call.\n\nThe main reason to change this setting is when the debugging tools get\nfooled by the optimized context factories. Threads are the most\ndebugging-friendly contextes, as they allow to set breakpoints\nanywhere with gdb and visualize backtraces for all processes, in order\nto debug concurrency issues. Valgrind is also more comfortable with\nthreads, but it should be usable with all factories (Exception: the\ncallgrind tool really dislikes raw and ucontext factories).\n\n.. _cfg=contexts/stack-size:\n\nAdapting the Stack Size\n.......................\n\n**Option** ``contexts/stack-size`` **Default:** 8192 KiB\n\nEach virtualized used process is executed using a specific system\nstack. The size of this stack has a huge impact on the simulation\nscalability, but its default value is rather large. This is because\nthe error messages that you get when the stack size is too small are\nrather disturbing: this leads to stack overflow (overwriting other\nstacks), leading to segfaults with corrupted stack traces.\n\nIf you want to push the scalability limits of your code, you might\nwant to reduce the ``contexts/stack-size`` item. Its default value is\n8192 (in KiB), while our Chord simulation works with stacks as small\nas 16 KiB, for example. For the thread factory, the default value is\nthe one of the system but you can still change it with this parameter.\n\nThe operating system should only allocate memory for the pages of the\nstack which are actually used and you might not need to use this in\nmost cases. However, this setting is very important when using the\nmodel checker (see :ref:`options_mc_perf`).\n\n.. _cfg=contexts/guard-size:\n\nDisabling Stack Guard Pages\n...........................\n\n**Option** ``contexts/guard-size`` **Default** 1 page in most case (0 pages on Windows or with MC)\n\nA stack guard page is usually used which prevents the stack of a given\nactor from overflowing on another stack. But the performance impact\nmay become prohibitive when the amount of actors increases.  The\noption ``contexts/guard-size`` is the number of stack guard pages\nused.  By setting it to 0, no guard pages will be used: in this case,\nyou should avoid using small stacks (with :ref:`contexts/stack-size\n<cfg=contexts/stack-size>`) as the stack will silently overflow on\nother parts of the memory.\n\nWhen no stack guard page is created, stacks may then silently overflow\non other parts of the memory if their size is too small for the\napplication.\n\n.. _cfg=contexts/nthreads:\n.. _cfg=contexts/parallel-threshold:\n.. _cfg=contexts/synchro:\n  \nRunning User Code in Parallel\n.............................\n\nParallel execution of the user code is only considered stable in\nSimGrid v3.7 and higher, and mostly for MSG simulations. SMPI\nsimulations may well fail in parallel mode. It is described in\n`INRIA RR-7653 <http://hal.inria.fr/inria-00602216/>`_.\n\nIf you are using the **ucontext** or **raw** context factories, you can\nrequest to execute the user code in parallel. Several threads are\nlaunched, each of them handling as much user contexts at each run. To\nactiave this, set the ``contexts/nthreads`` item to the amount of\ncores that you have in your computer (or lower than 1 to have\nthe amount of cores auto-detected).\n\nEven if you asked several worker threads using the previous option,\nyou can request to start the parallel execution (and pay the\nassociated synchronization costs) only if the potential parallelism is\nlarge enough. For that, set the ``contexts/parallel-threshold``\nitem to the minimal amount of user contexts needed to start the\nparallel execution. In any given simulation round, if that amount is\nnot reached, the contexts will be run sequentially directly by the\nmain thread (thus saving the synchronization costs). Note that this\noption is mainly useful when the grain of the user code is very fine,\nbecause our synchronization is now very efficient.\n\nWhen parallel execution is activated, you can choose the\nsynchronization schema used with the ``contexts/synchro`` item,\nwhich value is either:\n\n - **futex:** ultra optimized synchronisation schema, based on futexes\n   (fast user-mode mutexes), and thus only available on Linux systems.\n   This is the default mode when available.\n - **posix:** slow but portable synchronisation using only POSIX\n   primitives.\n - **busy_wait:** not really a synchronisation: the worker threads\n   constantly request new contexts to execute. It should be the most\n   efficient synchronisation schema, but it loads all the cores of\n   your machine for no good reason. You probably prefer the other less\n   eager schemas.\n\n   \nConfiguring the Tracing\n-----------------------\n\nThe :ref:`tracing subsystem <outcomes_vizu>` can be configured in\nseveral different ways depending on the nature of the simulator (MSG,\nSimDag, SMPI) and the kind of traces that need to be obtained. See the\n:ref:`Tracing Configuration Options subsection\n<tracing_tracing_options>` to get a detailed description of each\nconfiguration option.\n\nWe detail here a simple way to get the traces working for you, even if\nyou never used the tracing API.\n\n\n- Any SimGrid-based simulator (MSG, SimDag, SMPI, ...) and raw traces:\n\n  .. code-block:: shell\n\n     --cfg=tracing:yes --cfg=tracing/uncategorized:yes --cfg=triva/uncategorized:uncat.plist\n\n  The first parameter activates the tracing subsystem, the second\n  tells it to trace host and link utilization (without any\n  categorization) and the third creates a graph configuration file to\n  configure Triva when analysing the resulting trace file.\n\n- MSG or SimDag-based simulator and categorized traces (you need to\n  declare categories and classify your tasks according to them) \n\n  .. code-block:: shell\n\n     --cfg=tracing:yes --cfg=tracing/categorized:yes --cfg=triva/categorized:cat.plist\n\n  The first parameter activates the tracing subsystem, the second\n  tells it to trace host and link categorized utilization and the\n  third creates a graph configuration file to configure Triva when\n  analysing the resulting trace file.\n\n- SMPI simulator and traces for a space/time view:\n\n  .. code-block:: shell\n     \n     smpirun -trace ...\n\n  The `-trace` parameter for the smpirun script runs the simulation\n  with ``--cfg=tracing:yes --cfg=tracing/smpi:yes``. Check the\n  smpirun's `-help` parameter for additional tracing options.\n\nSometimes you might want to put additional information on the trace to\ncorrectly identify them later, or to provide data that can be used to\nreproduce an experiment. You have two ways to do that:\n\n- Add a string on top of the trace file as comment:\n\n  .. code-block:: shell\n\n     --cfg=tracing/comment:my_simulation_identifier\n\n- Add the contents of a textual file on top of the trace file as comment:\n\n  .. code-block:: shell\n\t\t  \n     --cfg=tracing/comment-file:my_file_with_additional_information.txt\n\nPlease, use these two parameters (for comments) to make reproducible\nsimulations. For additional details about this and all tracing\noptions, check See the :ref:`tracing_tracing_options`.\n\nConfiguring MSG\n---------------\n\n.. _cfg=msg/debug-multiple-use:\n\nDebugging MSG Code\n..................\n\n**Option** ``msg/debug-multiple-use`` **Default:** off\n\nSometimes your application may try to send a task that is still being\nexecuted somewhere else, making it impossible to send this task. However,\nfor debugging purposes, one may want to know what the other host is/was\ndoing. This option shows a backtrace of the other process.\n\nConfiguring SMPI\n----------------\n\nThe SMPI interface provides several specific configuration items.\nThese are uneasy to see since the code is usually launched through the\n``smiprun`` script directly.\n\n.. _cfg=smpi/host-speed:\n.. _cfg=smpi/cpu-threshold:\n.. _cfg=smpi/simulate-computation:\n\nAutomatic Benchmarking of SMPI Code\n...................................\n\nIn SMPI, the sequential code is automatically benchmarked, and these\ncomputations are automatically reported to the simulator. That is to\nsay that if you have a large computation between a ``MPI_Recv()`` and\na ``MPI_Send()``, SMPI will automatically benchmark the duration of\nthis code, and create an execution task within the simulator to take\nthis into account. For that, the actual duration is measured on the\nhost machine and then scaled to the power of the corresponding\nsimulated machine. The variable ``smpi/host-speed`` allows to specify\nthe computational speed of the host machine (in flop/s) to use when\nscaling the execution times. It defaults to 20000, but you really want\nto update it to get accurate simulation results.\n\nWhen the code is constituted of numerous consecutive MPI calls, the\nprevious mechanism feeds the simulation kernel with numerous tiny\ncomputations. The ``smpi/cpu-threshold`` item becomes handy when this\nimpacts badly the simulation performance. It specifies a threshold (in\nseconds) below which the execution chunks are not reported to the\nsimulation kernel (default value: 1e-6).\n\n.. note:: The option ``smpi/cpu-threshold`` ignores any computation\n   time spent below this threshold. SMPI does not consider the\n   `amount` of these computations; there is no offset for this. Hence,\n   a value that is too small, may lead to unreliable simulation\n   results.\n\nIn some cases, however, one may wish to disable simulation of\napplication computation. This is the case when SMPI is used not to\nsimulate an MPI applications, but instead an MPI code that performs\n\"live replay\" of another MPI app (e.g., ScalaTrace's replay tool,\nvarious on-line simulators that run an app at scale). In this case the\ncomputation of the replay/simulation logic should not be simulated by\nSMPI. Instead, the replay tool or on-line simulator will issue\n\"computation events\", which correspond to the actual MPI simulation\nbeing replayed/simulated. At the moment, these computation events can\nbe simulated using SMPI by calling internal smpi_execute*() functions.\n\nTo disable the benchmarking/simulation of computation in the simulated\napplication, the variable ``smpi/simulate-computation`` should be set\nto no.  This option just ignores the timings in your simulation; it\nstill executes the computations itself. If you want to stop SMPI from\ndoing that, you should check the SMPI_SAMPLE macros, documented in \nSection :ref:`SMPI_adapting_speed`.\n\n+------------------------------------+-------------------------+-----------------------------+\n|  Solution                          | Computations executed?  | Computations simulated?     |\n+====================================+=========================+=============================+   \n| --cfg=smpi/simulate-computation:no | Yes                     | Never                       |\n+------------------------------------+-------------------------+-----------------------------+\n| --cfg=smpi/cpu-threshold:42        | Yes, in all cases       | If it lasts over 42 seconds |\n+------------------------------------+-------------------------+-----------------------------+\n| SMPI_SAMPLE() macro                | Only once per loop nest | Always                      |\n+------------------------------------+-------------------------+-----------------------------+\n\n.. _cfg=smpi/comp-adjustment-file:\n\nSlow-down or speed-up parts of your code\n........................................\n\n**Option** ``smpi/comp-adjustment-file:`` **Default:** unset\n\nThis option allows you to pass a file that contains two columns: The\nfirst column defines the section that will be subject to a speedup;\nthe second column is the speedup. For instance:\n\n.. code-block:: shell\n\n  \"start:stop\",\"ratio\"\n  \"exchange_1.f:30:exchange_1.f:130\",1.18244559422142\n\nThe first line is the header - you must include it.  The following\nline means that the code between two consecutive MPI calls on line 30\nin exchange_1.f and line 130 in exchange_1.f should receive a speedup\nof 1.18244559422142. The value for the second column is therefore a\nspeedup, if it is larger than 1 and a slow-down if it is smaller\nthan 1. Nothing will be changed if it is equal to 1.\n\nOf course, you can set any arbitrary filenames you want (so the start\nand end don't have to be in the same file), but be aware that this\nmechanism only supports `consecutive calls!`\n\nPlease note that you must pass the ``-trace-call-location`` flag to\nsmpicc or smpiff, respectively. This flag activates some internal\nmacro definitions that help with obtaining the call location.\n\n.. _cfg=smpi/bw-factor:\n\nBandwidth Factors\n.................\n\n**Option** ``smpi/bw-factor``\n|br| **Default:** 65472:0.940694;15424:0.697866;9376:0.58729;5776:1.08739;3484:0.77493;1426:0.608902;732:0.341987;257:0.338112;0:0.812084\n\nThe possible throughput of network links is often dependent on the\nmessage sizes, as protocols may adapt to different message sizes. With\nthis option, a series of message sizes and factors are given, helping\nthe simulation to be more realistic. For instance, the current default\nvalue means that messages with size 65472 and more will get a total of\nMAX_BANDWIDTH*0.940694, messages of size 15424 to 65471 will get\nMAX_BANDWIDTH*0.697866 and so on (where MAX_BANDWIDTH denotes the\nbandwidth of the link).\n\nAn experimental script to compute these factors is available online. See\nhttp://simgrid.gforge.inria.fr/contrib/smpi-calibration-doc.html\nhttp://simgrid.gforge.inria.fr/contrib/smpi-saturation-doc.html\n\n.. _cfg=smpi/display-timing:\n       \nReporting Simulation Time\n.........................\n\n**Option** ``smpi/display-timing`` **Default:** 0 (false)\n\nMost of the time, you run MPI code with SMPI to compute the time it\nwould take to run it on a platform. But since the code is run through\nthe ``smpirun`` script, you don't have any control on the launcher\ncode, making it difficult to report the simulated time when the\nsimulation ends. If you enable the ``smpi/display-timing`` item,\n``smpirun`` will display this information when the simulation\nends.\n\n.. _cfg=smpi/keep-temps:\n\nKeeping temporary files after simulation\n........................................\n\n**Option** ``smpi/keep-temps`` **default:** 0 (false)\n\nSMPI usually generates a lot of temporary files that are cleaned after\nuse. This option request to preserve them, for example to debug or\nprofile your code. Indeed, the binary files are removed very early\nunder the dlopen privatization schema, which tend to fool the\ndebuggers.\n\n.. _cfg=smpi/lat-factor:\n\nLatency factors\n...............\n\n**Option** ``smpi/lat-factor`` |br|\n**default:** 65472:11.6436;15424:3.48845;9376:2.59299;5776:2.18796;3484:1.88101;1426:1.61075;732:1.9503;257:1.95341;0:2.01467\n\nThe motivation and syntax for this option is identical to the motivation/syntax\nof :ref:`cfg=smpi/bw-factor`.\n\nThere is an important difference, though: While smpi/bw-factor `reduces` the\nactual bandwidth (i.e., values between 0 and 1 are valid), latency factors\nincrease the latency, i.e., values larger than or equal to 1 are valid here.\n\n.. _cfg=smpi/papi-events:\n       \nTrace hardware counters with PAPI\n.................................\n\n**Option** ``smpi/papi-events`` **default:** unset\n\nWhen the PAPI support was compiled in SimGrid, this option takes the\nnames of PAPI counters and adds their respective values to the trace\nfiles (See Section :ref:`tracing_tracing_options`).\n\n.. warning::\n   \n   This feature currently requires superuser privileges, as registers\n   are queried.  Only use this feature with code you trust! Call\n   smpirun for instance via ``smpirun -wrapper \"sudo \"\n   <your-parameters>`` or run ``sudo sh -c \"echo 0 >\n   /proc/sys/kernel/perf_event_paranoid\"`` In the later case, sudo\n   will not be required.\n\nIt is planned to make this feature available on a per-process (or per-thread?) basis.\nThe first draft, however, just implements a \"global\" (i.e., for all processes) set\nof counters, the \"default\" set.\n\n.. code-block:: shell\n\n   --cfg=smpi/papi-events:\"default:PAPI_L3_LDM:PAPI_L2_LDM\"\n\n.. _cfg=smpi/privatization:\n\nAutomatic Privatization of Global Variables\n...........................................\n\n**Option** ``smpi/privatization`` **default:** \"dlopen\" (when using smpirun)\n\nMPI executables are usually meant to be executed in separated\nprocesses, but SMPI is executed in only one process. Global variables\nfrom executables will be placed in the same memory zone and shared\nbetween processes, causing intricate bugs.  Several options are\npossible to avoid this, as described in the main `SMPI publication\n<https://hal.inria.fr/hal-01415484>`_ and in the :ref:`SMPI\ndocumentation <SMPI_what_globals>`. SimGrid provides two ways of\nautomatically privatizing the globals, and this option allows to\nchoose between them.\n\n  - **no** (default when not using smpirun): Do not automatically\n    privatize variables.  Pass ``-no-privatize`` to smpirun to disable\n    this feature.\n  - **dlopen** or **yes** (default when using smpirun): Link multiple\n    times against the binary.\n  - **mmap** (slower, but maybe somewhat more stable):\n    Runtime automatic switching of the data segments.\n\n.. warning::\n   This configuration option cannot be set in your platform file. You can only\n   pass it as an argument to smpirun.\n\n.. _cfg=smpi/privatize-libs:\n\nAutomatic privatization of global variables inside external libraries\n.....................................................................\n\n**Option** ``smpi/privatize-libs`` **default:** unset\n\n**Linux/BSD only:** When using dlopen (default) privatization,\nprivatize specific shared libraries with internal global variables, if\nthey can't be linked statically.  For example libgfortran is usually\nused for Fortran I/O and indexes in files can be mixed up.\n\nMultiple libraries can be given, semicolon separated.\n\nThis configuration option can only use either full paths to libraries,\nor full names.  Check with ldd the name of the library you want to\nuse.  Example:\n\n.. code-block:: shell\n\t\t  \n   ldd allpairf90\n      ...\n      libgfortran.so.3 => /usr/lib/x86_64-linux-gnu/libgfortran.so.3 (0x00007fbb4d91b000)\n      ...\n\nThen you can use ``--cfg=smpi/privatize-libs:libgfortran.so.3``\nor ``--cfg=smpi/privatize-libs:/usr/lib/x86_64-linux-gnu/libgfortran.so.3``,\nbut not ``libgfortran`` nor ``libgfortran.so``.\n\n.. _cfg=smpi/send-is-detached-thresh:\n\nSimulating MPI detached send\n............................\n\n**Option** ``smpi/send-is-detached-thresh`` **default:** 65536\n\nThis threshold specifies the size in bytes under which the send will\nreturn immediately. This is different from the threshold detailed in\n:ref:`options_model_network_asyncsend` because the message is not\neffectively sent when the send is posted. SMPI still waits for the\ncorrespondant receive to be posted to perform the communication\noperation.\n\n.. _cfg=smpi/coll-selector:\n\nSimulating MPI collective algorithms\n....................................\n\n**Option** ``smpi/coll-selector`` **Possible values:** naive (default), ompi, mpich\n\nSMPI implements more than 100 different algorithms for MPI collective\ncommunication, to accurately simulate the behavior of most of the\nexisting MPI libraries. The ``smpi/coll-selector`` item can be used to\nuse the decision logic of either OpenMPI or MPICH libraries (by\ndefault SMPI uses naive version of collective operations).\n\nEach collective operation can be manually selected with a\n``smpi/collective_name:algo_name``. Available algorithms are listed in\n:ref:`SMPI_use_colls`.\n\n.. TODO:: All available collective algorithms will be made available\n          via the ``smpirun --help-coll`` command.\n\n.. _cfg=smpi/iprobe:\n\nInject constant times for MPI_Iprobe\n....................................\n\n**Option** ``smpi/iprobe`` **default:** 0.0001\n\nThe behavior and motivation for this configuration option is identical\nwith :ref:`smpi/test <cfg=smpi/test>`, but for the function\n``MPI_Iprobe()``\n\n.. _cfg=smpi/iprobe-cpu-usage:\n\nReduce speed for iprobe calls\n.............................\n\n**Option** ``smpi/iprobe-cpu-usage`` **default:** 1 (no change)\n\nMPI_Iprobe calls can be heavily used in applications. To account\ncorrectly for the energy cores spend probing, it is necessary to\nreduce the load that these calls cause inside SimGrid.\n\nFor instance, we measured a max power consumption of 220 W for a\nparticular application but only 180 W while this application was\nprobing. Hence, the correct factor that should be passed to this\noption would be 180/220 = 0.81.\n\n.. _cfg=smpi/init:\n\nInject constant times for MPI_Init\n..................................\n\n**Option** ``smpi/init`` **default:** 0\n\nThe behavior and motivation for this configuration option is identical\nwith :ref:`smpi/test <cfg=smpi/test>`, but for the function ``MPI_Init()``.\n\n.. _cfg=smpi/ois:\n\nInject constant times for MPI_Isend()\n.....................................\n\n**Option** ``smpi/ois``\n\nThe behavior and motivation for this configuration option is identical\nwith :ref:`smpi/os <cfg=smpi/os>`, but for the function ``MPI_Isend()``.\n\n.. _cfg=smpi/os:\n\nInject constant times for MPI_send()\n....................................\n\n**Option** ``smpi/os``\n\nIn several network models such as LogP, send (MPI_Send, MPI_Isend) and\nreceive (MPI_Recv) operations incur costs (i.e., they consume CPU\ntime). SMPI can factor these costs in as well, but the user has to\nconfigure SMPI accordingly as these values may vary by machine.  This\ncan be done by using ``smpi/os`` for MPI_Send operations; for MPI_Isend\nand MPI_Recv, use ``smpi/ois`` and ``smpi/or``, respectively. These work\nexactly as ``smpi/ois``.\n\nThis item can consist of multiple sections; each section takes three\nvalues, for example ``1:3:2;10:5:1``.  The sections are divided by \";\"\nso this example contains two sections.  Furthermore, each section\nconsists of three values.\n\n1. The first value denotes the minimum size for this section to take effect;\n   read it as \"if message size is greater than this value (and other section has a larger\n   first value that is also smaller than the message size), use this\".\n   In the first section above, this value is \"1\".\n\n2. The second value is the startup time; this is a constant value that will always\n   be charged, no matter what the size of the message. In the first section above,\n   this value is \"3\".\n\n3. The third value is the `per-byte` cost. That is, it is charged for every\n   byte of the message (incurring cost messageSize*cost_per_byte)\n   and hence accounts also for larger messages. In the first\n   section of the example above, this value is \"2\".\n\nNow, SMPI always checks which section it should take for a given\nmessage; that is, if a message of size 11 is sent with the\nconfiguration of the example above, only the second section will be\nused, not the first, as the first value of the second section is\ncloser to the message size. Hence, when ``smpi/os=1:3:2;10:5:1``, a\nmessage of size 11 incurs the following cost inside MPI_Send:\n``5+11*1`` because 5 is the startup cost and 1 is the cost per byte.\n\nNote that the order of sections can be arbitrary; they will be ordered internally.\n\n.. _cfg=smpi/or:\n\nInject constant times for MPI_Recv()\n....................................\n\n**Option** ``smpi/or``\n\nThe behavior and motivation for this configuration option is identical\nwith :ref:`smpi/os <cfg=smpi/os>`, but for the function ``MPI_Recv()``.\n\n.. _cfg=smpi/test:\n.. _cfg=smpi/grow-injected-times:\n\nInject constant times for MPI_Test\n..................................\n\n**Option** ``smpi/test`` **default:** 0.0001\n\nBy setting this option, you can control the amount of time a process\nsleeps when MPI_Test() is called; this is important, because SimGrid\nnormally only advances the time while communication is happening and\nthus, MPI_Test will not add to the time, resulting in a deadlock if\nused as a break-condition as in the following example:\n\n.. code-block:: cpp\n\n   while(!flag) {\n       MPI_Test(request, flag, status);\n       ...\n   }\n\nTo speed up execution, we use a counter to keep track on how often we\nalready checked if the handle is now valid or not. Hence, we actually\nuse counter*SLEEP_TIME, that is, the time MPI_Test() causes the\nprocess to sleep increases linearly with the number of previously\nfailed tests. This behavior can be disabled by setting\n``smpi/grow-injected-times`` to **no**. This will also disable this\nbehavior for MPI_Iprobe.\n\n.. _cfg=smpi/shared-malloc:\n.. _cfg=smpi/shared-malloc-hugepage:\n\nFactorize malloc()s\n...................\n\n**Option** ``smpi/shared-malloc`` **Possible values:** global (default), local\n\nIf your simulation consumes too much memory, you may want to modify\nyour code so that the working areas are shared by all MPI ranks. For\nexample, in a bloc-cyclic matrix multiplication, you will only\nallocate one set of blocs, and every processes will share them.\nNaturally, this will lead to very wrong results, but this will save a\nlot of memory so this is still desirable for some studies. For more on\nthe motivation for that feature, please refer to the `relevant section\n<https://simgrid.github.io/SMPI_CourseWare/topic_understanding_performance/matrixmultiplication>`_\nof the SMPI CourseWare (see Activity #2.2 of the pointed\nassignment). In practice, change the call to malloc() and free() into\nSMPI_SHARED_MALLOC() and SMPI_SHARED_FREE().\n\nSMPI provides two algorithms for this feature. The first one, called \n``local``, allocates one bloc per call to SMPI_SHARED_MALLOC() in your\ncode (each call location gets its own bloc) and this bloc is shared\namongst all MPI ranks.  This is implemented with the shm_* functions\nto create a new POSIX shared memory object (kept in RAM, in /dev/shm)\nfor each shared bloc.\n\nWith the ``global`` algorithm, each call to SMPI_SHARED_MALLOC()\nreturns a new adress, but it only points to a shadow bloc: its memory\narea is mapped on a 1MiB file on disk. If the returned bloc is of size\nN MiB, then the same file is mapped N times to cover the whole bloc.\nAt the end, no matter how many SMPI_SHARED_MALLOC you do, this will\nonly consume 1 MiB in memory.\n\nYou can disable this behavior and come back to regular mallocs (for\nexample for debugging purposes) using @c \"no\" as a value.\n\nIf you want to keep private some parts of the buffer, for instance if these\nparts are used by the application logic and should not be corrupted, you\ncan use SMPI_PARTIAL_SHARED_MALLOC(size, offsets, offsets_count). Example:\n\n.. code-block:: cpp\n\n   mem = SMPI_PARTIAL_SHARED_MALLOC(500, {27,42 , 100,200}, 2);\n\nThis will allocate 500 bytes to mem, such that mem[27..41] and\nmem[100..199] are shared while other area remain private.\n\nThen, it can be deallocated by calling SMPI_SHARED_FREE(mem).\n\nWhen smpi/shared-malloc:global is used, the memory consumption problem\nis solved, but it may induce too much load on the kernel's pages table. \nIn this case, you should use huge pages so that we create only one\nentry per Mb of malloced data instead of one entry per 4k.\nTo activate this, you must mount a hugetlbfs on your system and allocate\nat least one huge page:\n\n.. code-block:: shell\n\t\t\n    mkdir /home/huge\n    sudo mount none /home/huge -t hugetlbfs -o rw,mode=0777\n    sudo sh -c 'echo 1 > /proc/sys/vm/nr_hugepages' # echo more if you need more\n\nThen, you can pass the option\n``--cfg=smpi/shared-malloc-hugepage:/home/huge`` to smpirun to\nactually activate the huge page support in shared mallocs.\n\n.. _cfg=smpi/wtime:\n\nInject constant times for MPI_Wtime, gettimeofday and clock_gettime\n...................................................................\n\n**Option** ``smpi/wtime`` **default:** 10 ns\n\nThis option controls the amount of (simulated) time spent in calls to\nMPI_Wtime(), gettimeofday() and clock_gettime(). If you set this value\nto 0, the simulated clock is not advanced in these calls, which leads\nto issue if your application contains such a loop:\n\n.. code-block:: cpp\n\t\t\n   while(MPI_Wtime() < some_time_bound) {\n        /* some tests, with no communication nor computation */\n   }\n\nWhen the option smpi/wtime is set to 0, the time advances only on\ncommunications and computations, so the previous code results in an\ninfinite loop: the current [simulated] time will never reach\n``some_time_bound``.  This infinite loop is avoided when that option\nis set to a small amount, as it is by default since SimGrid v3.21.\n\nNote that if your application does not contain any loop depending on\nthe current time only, then setting this option to a non-zero value\nwill slow down your simulations by a tiny bit: the simulation loop has\nto be broken and reset each time your code ask for the current time.\nIf the simulation speed really matters to you, you can avoid this\nextra delay by setting smpi/wtime to 0.\n\nOther Configurations\n--------------------\n\n.. _cfg=clean-atexit:\n\nCleanup at Termination\n......................\n\n**Option** ``clean-atexit`` **default:** on\n\nIf your code is segfaulting during its finalization, it may help to\ndisable this option to request SimGrid to not attempt any cleanups at\nthe end of the simulation. Since the Unix process is ending anyway,\nthe operating system will wipe it all.\n\n.. _cfg=path:\n\nSearch Path\n...........\n\n**Option** ``path`` **default:** . (current dir)\n\nIt is possible to specify a list of directories to search into for the\ntrace files (see :ref:`pf_trace`) by using this configuration\nitem. To add several directory to the path, set the configuration\nitem several times, as in ``--cfg=path:toto --cfg=path:tutu``\n\n.. _cfg=simix/breakpoint:\n\nSet a Breakpoint\n................\n\n**Option** ``simix/breakpoint`` **default:** unset\n\nThis configuration option sets a breakpoint: when the simulated clock\nreaches the given time, a SIGTRAP is raised.  This can be used to stop\nthe execution and get a backtrace with a debugger.\n\nIt is also possible to set the breakpoint from inside the debugger, by\nwriting in global variable simgrid::simix::breakpoint. For example,\nwith gdb:\n\n.. code-block:: shell\n\n   set variable simgrid::simix::breakpoint = 3.1416\n\n.. _cfg=verbose-exit:\n   \nBehavior on Ctrl-C\n..................\n\n**Option** ``verbose-exit`` **default:** on\n\nBy default, when Ctrl-C is pressed, the status of all existing actors\nis displayed before exiting the simulation. This is very useful to\ndebug your code, but it can reveal troublesome if you have many\nactors. Set this configuration item to **off** to disable this\nfeature.\n\n.. _cfg=exception/cutpath:\n\nTruncate local path from exception backtrace\n............................................\n\n**Option** ``exception/cutpath`` **default:** off\n\nThis configuration option is used to remove the path from the\nbacktrace shown when an exception is thrown. This is mainly useful for\nthe tests: the full file path makes the tests not reproducible because\nthe path of source files depend of the build settings. That would\nbreak most of our tests as we keep comparing output.\n\nLogging Configuration\n---------------------\n\nIt can be done by using XBT. Go to :ref:`XBT_log` for more details.\n\n.. |br| raw:: html\n\n   <br />\n",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.21-2jw7hfw3ki7yfy6d52vbzhst6fypdxym/spack-src/doc/doxygen/FAQ.doc": "/*! @page FAQ MSG Frequently Asked Questions\n\n@tableofcontents\n\nThis document is the FAQ of the MSG interface. Some entries are a bit aging and it should be refreshed at some point.\n\n@section faq_simgrid I'm new to SimGrid. I have some questions. Where should I start?\n\nYou are at the right place... To understand what you can do or\ncannot do with SimGrid, you should read the\n<a href=\"http://simgrid.gforge.inria.fr/tutorials.php\">tutorial\nslides</a> from the SimGrid's website. You may find more uptodate\nmaterial on the\n<a href=\"http://people.irisa.fr/Martin.Quinson/blog/SimGrid/\">blog of\nMartin Quinson</a>. \n\nAnother great source of inspiration can be found in the @ref s4u_examples.\n\nIf you are stuck at any point and if this FAQ cannot help you, please drop us a\nmail to the user mailing list: <simgrid-user@lists.gforge.inria.fr>.\n\n@subsection faq_interfaces What is the difference between MSG and SimDag? Do they serve the same purpose?\n\nIt depend on how you define \"purpose\", I guess ;)\n\nThey all allow you to build a prototype of application which you can run\nwithin the simulator afterward. They all share the same simulation kernel,\nwhich is the core of the SimGrid project. They differ by the way you express\nyour application.\n\nWith SimDag, you express your code as a collection of interdependent\nparallel tasks. So, in this model, applications can be seen as a DAG of\ntasks. This is the interface of choice for people wanting to port old\ncode designed for SimGrid v1 or v2 to the framework current version.\n\nWith MSG, your application is seen as a set of communicating\nprocesses, exchanging data by the way of messages and performing\ncomputation on their own.\n\n@subsection faq_visualization Visualizing and analyzing the results\n\nIt is sometime convenient to \"see\" how the agents are behaving. If you\nlike colors, you can use <tt>tools/MSG_visualization/colorize.pl </tt>\nas a filter to your MSG outputs. It works directly with INFO. Beware,\nINFO() prints on stderr. Do not forget to redirect if you want to\nfilter (e.g. with bash):\n@verbatim\n./msg_test small_platform.xml small_deployment.xml 2>&1 | ../../tools/MSG_visualization/colorize.pl\n@endverbatim\n\nWe also have a more graphical output. Have a look at section @ref options_tracing.\n\n@subsection faq_C Argh! Do I really have to code in C?\n\nWe provide Java bindings of the MSG interface, which is the main\nSimGrid user API.\n\nMoreover If you use C++, you should be able to use the SimGrid library\nas a standard C library and everything should work fine (simply\n<i>link</i> against this library; recompiling SimGrid with a C++\ncompiler won't work and it wouldn't help if you could).\n\nFor now, we do not feel a real demand for any other language. But if\nyou think there is one, please speak up!\n\n@section faq_howto Feature related questions\n\n@subsection faq_MIA \"Could you please add (your favorite feature here) to SimGrid?\"\n\nHere is the deal. The whole SimGrid project (MSG, SURF, ...) is\nmeant to be kept as simple and generic as possible. We cannot add\nfunctions for everybody's needs when these functions can easily be\nbuilt from the ones already in the API. Most of the time, it is\npossible and when it was not possible we always have upgraded the API\naccordingly. When somebody asks us a question like \"How to do that?\nIs there a function in the API to simply do this?\", we're always glad\nto answer and help. However if we don't need this code for our own\nneed, there is no chance we're going to write it... it's your job! :)\nThe counterpart to our answers is that once you come up with a neat\nimplementation of this feature (task duplication, RPC, thread\nsynchronization, ...), you should send it to us and we will be glad to\nadd it to the distribution. Thus, other people will take advantage of\nit (and we don't have to answer this question again and again ;).\n\nYou'll find in this section a few \"Missing In Action\" features. Many\npeople have asked about it and we have given hints on how to simply do\nit with MSG. Feel free to contribute...\n\n@subsection faq_MIA_MSG MSG features\n\n@subsubsection faq_MIA_examples I want some more complex MSG examples!\n\nMany people have come to ask me a more complex example and each time,\nthey have realized afterward that the basics were in the previous three\nexamples.\n\nOf course they have often been needing more complex functions like\nMSG_process_suspend(), MSG_process_resume() and\nMSG_process_isSuspended() (to perform synchronization), or\nMSG_task_Iprobe() and MSG_process_sleep() (to avoid blocking\nreceptions), or even MSG_process_create() (to design asynchronous\ncommunications or computations). But the examples are sufficient to\nstart.\n\nWe know. We should add some more examples, but not really some more\ncomplex ones... We should add some examples that illustrate some other\nfunctionalists (like how to simply encode asynchronous\ncommunications, RPC, process migrations, thread synchronization, ...)\nand we will do it when we will have a little bit more time. We have\ntried to document the examples so that they are understandable. Tell\nus if something is not clear and once again feel free to participate!\n:)\n\n@subsubsection faq_MIA_taskdup Missing in action: MSG Task duplication/replication\n\nThere is no task duplication in MSG. When you create a task, you can\nprocess it or send it somewhere else. As soon as a process has sent\nthis task, he doesn't have this task anymore. It's gone. The receiver\nprocess has got the task. However, you could decide upon receiving to\ncreate a \"copy\" of a task but you have to handle by yourself the\nsemantic associated to this \"duplication\".\n\nAs we already told, we prefer keeping the API as simple as\npossible. This kind of feature is rather easy to implement by users\nand the semantic you associate really depends on people. Having a\n*generic* task duplication mechanism is not that trivial (in\nparticular because of the data field). That is why I would recommend\nthat you write it by yourself even if I can give you advice on how to\ndo it.\n\nYou have the following functions to get information about a task:\nMSG_task_get_name(), MSG_task_get_compute_duration(),\nMSG_task_get_remaining_computation(), MSG_task_get_data_size(),\nand MSG_task_get_data().\n\nYou could use a dictionary (#xbt_dict_t) of dynars (#xbt_dynar_t). If\nyou still don't see how to do it, please come back to us...\n\n@subsubsection faq_MIA_thread_synchronization How to synchronize my user processes?\n\nIt depends on why you want to synchronize them.  If you just want to\nhave a shared state between your processes, then you probably don't\nneed to do anything. User processes never get forcefully interrupted\nin SimGrid (unless you explicitly request the parallel execution of\nuser processes -- see @ref options_virt_parallel).\n\nEven if several processes are executed at the exact same time within\nthe simulation, they are linearized in reality by default: one process\nalways run in an exclusive manner, atomic, uninterrupted until it does\na simcall (until it ask a service from the simulation kernel). This is\nsurprising at first, but things are much easier this way, both for the\nuser (who don't have to protect her shared data) and for the kernel\n(that avoid many synchronization issues too). Processes are executed\nconcurrently in the simulated realm, but you don't need to bother with\nthis in the real realm.\n\nIf you really need to synchronize your processes (because it's what\nyou are studying or to create an atomic section that spans over\nseveral simcalls), you obviously cannot use regular synchronization\nmechanisms (pthread_mutexes in C or the synchronized keyword in Java).\nThis is because the SimGrid kernel locks all processes and unlock them\none after the other when they are supposed to run, until they give the\ncontrol back in their simcall. If one of them gets locked by the OS \nbefore returning the control to the kernel, that's definitively a\ndeadlock.\n\nInstead, you should use the synchronization mechanism provided by the\nsimulation kernel. This could with a SimGrid mutex, a SimGrid\ncondition variables or a SimGrid semaphore, as described in @ref\nmsg_synchro (in Java, only semaphores are available). But actually,\nmany synchronization patterns can be encoded with communication on\nmailboxes. Typically, if you need one process to notify another one,\nyou could use a condition variable or a semphore, but sending a\nmessage to a specific mailbox does the trick in most cases.\n\n@subsubsection faq_MIA_host_load Where is the get_host_load function hidden in MSG?\n\nThere is no such thing because its semantic wouldn't be really\nclear. Of course, it is something about the amount of host throughput,\nbut there is as many definition of \"host load\" as people asking for\nthis function. First, you have to remember that resource availability\nmay vary over time, which make any load notion harder to define.\n\nIt may be instantaneous value or an average one. Moreover it may be only the\npower of the computer, or may take the background load into account, or may\neven take the currently running tasks into account. In some SURF models,\ncommunications have an influence on computational power. Should it be taken\ninto account too?\n\nFirst of all, it's near to impossible to predict the load beforehand in the\nsimulator since it depends on too much parameters (background load\nvariation, bandwidth sharing algorithmic complexity) some of them even being\nnot known beforehand (other task starting at the same time). So, getting\nthis information is really hard (just like in real life). It's not just that\nwe want MSG to be as painful as real life. But as it is in some way\nrealistic, we face some of the same problems as we would face in real life.\n\nHow would you do it for real? The most common option is to use something\nlike NWS that performs active probes. The best solution is probably to do\nthe same within MSG, as in next code snippet. It is very close from what you\nwould have to do out of the simulator, and thus gives you information that\nyou could also get in real settings to not hinder the realism of your\nsimulation.\n\n@code\ndouble get_host_load() {\n   m_task_t task = MSG_task_create(\"test\", 0.001, 0, NULL);\n   double date = MSG_get_clock();\n\n   MSG_task_execute(task);\n   date = MSG_get_clock() - date;\n   MSG_task_destroy(task);\n   return (0.001/date);\n}\n@endcode\n\nOf course, it may not match your personal definition of \"host load\". In this\ncase, please detail what you mean on the mailing list, and we will extend\nthis FAQ section to fit your taste if possible.\n\n@subsubsection faq_MIA_communication_time How can I get the *real* communication time?\n\nCommunications are synchronous and thus if you simply get the time\nbefore and after a communication, you'll only get the transmission\ntime and the time spent to really communicate (it will also take into\naccount the time spent waiting for the other party to be\nready). However, getting the *real* communication time is not really\nhard either. The following solution is a good starting point.\n\n@code\nint sender()\n{\n  m_task_t task = MSG_task_create(\"Task\", task_comp_size, task_comm_size,\n                                  calloc(1,sizeof(double)));\n  *((double*) task->data) = MSG_get_clock();\n  MSG_task_put(task, slaves[i % slaves_count], PORT_22);\n  XBT_INFO(\"Send completed\");\n  return 0;\n}\nint receiver()\n{\n  m_task_t task = NULL;\n  double time1,time2;\n\n  time1 = MSG_get_clock();\n  a = MSG_task_get(&(task), PORT_22);\n  time2 = MSG_get_clock();\n  if(time1<*((double *)task->data))\n     time1 = *((double *) task->data);\n  XBT_INFO(\"Communication time :  \\\"%f\\\" \", time2-time1);\n  free(task->data);\n  MSG_task_destroy(task);\n  return 0;\n}\n@endcode\n\n@subsection faq_MIA_SimDag SimDag related questions\n\n@subsubsection faq_SG_comm Implementing communication delays between tasks.\n\nA classic question of SimDag newcomers is about how to express a\ncommunication delay between tasks. The thing is that in SimDag, both\ncomputation and communication are seen as tasks.  So, if you want to\nmodel a data dependency between two DAG tasks t1 and t2, you have to\ncreate 3 SD_tasks: t1, t2 and c and add dependencies in the following\nway:\n\n@code\nSD_task_dependency_add(t1, c);\nSD_task_dependency_add(c, t2);\n@endcode\n\nThis way task t2 cannot start before the termination of communication c\nwhich in turn cannot start before t1 ends.\n\nWhen creating task c, you have to associate an amount of data (in bytes)\ncorresponding to what has to be sent by t1 to t2.\n\nFinally to schedule the communication task c, you have to build a list\ncomprising the workstations on which t1 and t2 are scheduled (w1 and w2\nfor example) and build a communication matrix that should look like\n[0;amount ; 0; 0].\n\n@subsubsection faq_SG_DAG How to implement a distributed dynamic scheduler of DAGs.\n\nDistributed is somehow \"contagious\". If you start making distributed\ndecisions, there is no way to handle DAGs directly anymore (unless I\nam missing something). You have to encode your DAGs in term of\ncommunicating process to make the whole scheduling process\ndistributed. Here is an example of how you could do that. Assume T1\nhas to be done before T2.\n\n@code\n int your_agent(int argc, char *argv[] {\n   ...\n   T1 = MSG_task_create(...);\n   T2 = MSG_task_create(...);\n   ...\n   while(1) {\n     ...\n     if(cond) MSG_task_execute(T1);\n     ...\n     if((MSG_task_get_remaining_computation(T1)=0.0) && (you_re_in_a_good_mood))\n        MSG_task_execute(T2)\n     else {\n        /* do something else */\n     }\n   }\n }\n@endcode\n\nIf you decide that the distributed part is not that much important and that\nDAG is really the level of abstraction you want to work with, then you should\ngive a try to @ref SD_API.\n\n@subsection faq_MIA_generic Generic features\n\n@subsubsection faq_MIA_batch_scheduler Is there a native support for batch schedulers in SimGrid?\n\nNo, there is no native support for batch schedulers and none is\nplanned because this is a very specific need (and doing it in a\ngeneric way is thus very hard). However some people have implemented\ntheir own batch schedulers. Vincent Garonne wrote one during his PhD\nand put his code in the contrib directory of our SVN so that other can\nkeep working on it. You may find inspiring ideas in it.\n\n@subsubsection faq_MIA_checkpointing I need a checkpointing thing\n\nActually, it depends on whether you want to checkpoint the simulation, or to\nsimulate checkpoints.\n\nThe first one could help if your simulation is a long standing process you\nwant to keep running even on hardware issues. It could also help to\n<i>rewind</i> the simulation by jumping sometimes on an old checkpoint to\ncancel recent calculations.@n\nUnfortunately, such thing will probably never exist in SG. One would have to\nduplicate all data structures because doing a rewind at the simulator level\nis very very hard (not talking about the malloc free operations that might\nhave been done in between). Instead, you may be interested in the Libckpt\nlibrary (http://www.cs.utk.edu/~plank/plank/www/libckpt.html). This is the\ncheckpointing solution used in the condor project, for example. It makes it\neasy to create checkpoints (at the OS level, creating something like core\nfiles), and rerunning them on need.\n\nIf you want to simulate checkpoints instead, it means that you want the\nstate of an executing task (in particular, the progress made towards\ncompletion) to be saved somewhere.  So if a host (and the task executing on\nit) fails (cf. #MSG_HOST_FAILURE), then the task can be restarted\nfrom the last checkpoint.@n\n\nActually, such a thing does not exist in SimGrid either, but it's just\nbecause we don't think it is fundamental and it may be done in the user code\nat relatively low cost. You could for example use a watcher that\nperiodically get the remaining amount of things to do (using\nMSG_task_get_remaining_computation()), or fragment the task in smaller\nsubtasks.\n\n@subsection faq_platform Platform building and Dynamic resources\n\n@subsubsection faq_platform_example Where can I find SimGrid platform files?\n\nThere are several little examples in the archive, in the examples/msg\ndirectory. From time to time, we are asked for other files, but we\ndon't have much at hand right now.\n\nYou should refer to the Platform Description Archive\n(http://pda.gforge.inria.fr) project to see the other platform file we\nhave available, as well as the Simulacrum simulator, meant to generate\nSimGrid platforms using all classical generation algorithms.\n\n@subsubsection faq_platform_alnem How can I automatically map an existing platform?\n\nWe are working on a project called ALNeM (Application-Level Network\nMapper) which goal is to automatically discover the topology of an\nexisting network. Its output will be a platform description file\nfollowing the SimGrid syntax, so everybody will get the ability to map\ntheir own lab network (and contribute them to the catalog project).\nThis tool is not ready yet, but it move quite fast forward. Just stay\ntuned.\n\n@subsubsection faq_platform_synthetic Generating synthetic but realistic platforms\n\nThe third possibility to get a platform file (after manual or\nautomatic mapping of real platforms) is to generate synthetic\nplatforms. Getting a realistic result is not a trivial task, and\nmoreover, nobody is really able to define what \"realistic\" means when\nspeaking of topology files. You can find some more thoughts on this\ntopic in these\n<a href=\"http://graal.ens-lyon.fr/~alegrand/articles/Simgrid-Introduction.pdf\">slides</a>.\n\nIf you are looking for an actual tool, there we have a little tool to\nannotate Tiers-generated topologies. This perl-script is in\n<tt>tools/platform_generation/</tt> directory of the SVN. Dinda et Al.\nreleased a very comparable tool, and called it GridG.\n\n\nThe specified computing power will be available to up to 6 sequential\ntasks without sharing. If more tasks are placed on this host, the\nresource will be shared accordingly. For example, if you schedule 12\ntasks on the host, each will get half of the computing power. Please\nnote that although sound, this model were never scientifically\nassessed. Please keep this fact in mind when using it.\n\n\n@subsubsection faq_platform_random Using random variable for the resource power or availability\n\nThe best way to model the resouce power using a random variable is to\nuse an availability trace that is directed by a probability\ndistribution. This can be done using the function\ntmgr_trace_generator_value() below. The date and value generators is\ncreated with one of tmgr_event_generator_new_uniform(),\ntmgr_event_generator_new_exponential() or\ntmgr_event_generator_new_weibull() (if you need other generators,\nadding them to src/surf/trace_mgr.c should be quite trivial and your\npatch will be welcomed). Once your trace is created, you have to\nconnect it to the resource with the function\nsg_platf_new_trace_connect().\n\nThat the process is very similar if you want to model the\nresource availability with a random variable (deciding whether it's\non/off instead of deciding its speed) using the function\ntmgr_trace_generator_state() or tmgr_trace_generator_avail_unavail()\ninstead of tmgr_trace_generator_value().\n\nUnfortunately, all this is currently lacking a proper documentation,\nand there is even no proper example of use. You'll thus have to check\nthe header file include/simgrid/platf.h and experiment a bit by\nyourself. The following code should be a good starting point, and\ncontributing a little clean example would be a good way to help the\nSimGrid project.\n\n@code\ntmgr_trace_generator_value(\"mytrace\",tmgr_event_generator_new_exponential(.5)\n                                     tmgr_event_generator_new_uniform(100000,9999999));\n\t\t\t\t     \nsg_platf_trace_connect_cbarg_t myconnect = SG_PLATF_TRACE_CONNECT_INITIALIZER;\nmyconnect.kind = SURF_TRACE_CONNECT_KIND_BANDWIDTH;\nmyconnect.trace = \"mytrace\";\nmyconnect.element = \"mylink\";\n\nsg_platf_trace_connect(myconnect);\n@endcode\n\n@section faq_troubleshooting Troubleshooting\n\n@subsection faq_trouble_changelog The feature X stopped to work after my last update \n\nI guess that you want to read the ChangeLog file, that always contains\nall the information that could be important to the users during the\nupgrade. Actually, you may want to read it (alongside with the NEWS\nfile that highlights the most important changes) even before you\nupgrade your copy of SimGrid, too.\n\nWe do our best to maintain the backward compatibility, but we\nsometimes have to fix the things that are too broken. If we happen to\nkill a feature that you were using, we are sorry. We think that you\nshould update to the new way of doing things, but if you can't afford\nit, that's ok. Just stick to the last version that were working for\nyou, and have a pleasant day.\n\n@subsection faq_trouble_lib_compil SimGrid compilation and installation problems\n\n@subsubsection faq_trouble_lib_config cmake fails!\n\nWe know only one reason for the configure to fail:\n\n - <b>You are using a broken build environment</b>@n\n   Try updating your cmake version. If symptom is that the configury\n   magic complains about gcc not being able to build executables, you\n   are probably missing the libc6-dev package. Damn Ubuntu. \n\nIf you experience other kind of issue, please get in touch with us. We are\nalways interested in improving our portability to new systems.\n\n@subsubsection faq_trouble_distcheck Dude! \"ctest\" fails on my machine!\n\nDon't assume we never run this target, because we do. Check\nhttp://cdash.inria.fr/CDash/index.php?project=Simgrid (click on\nprevious if there is no result for today: results are produced only by\n11am, French time) and\nhttps://buildd.debian.org/status/logs.php?pkg=simgrid if you don't believe us.\n\nIf it's failing on your machine in a way not experienced by the\nautobuilders above, please drop us a mail on the mailing list so that\nwe can check it out. Make sure to read @ref faq_bugrepport before you\ndo so.\n\n@subsection faq_trouble_compil User code compilation problems\n\n@subsubsection faq_trouble_err_logcat \"gcc: _simgrid_this_log_category_does_not_exist__??? undeclared (first use in this function)\"\n\nThis is because you are using the log mechanism, but you didn't created\nany default category in this file. You should refer to @ref XBT_log\nfor all the details, but you simply forgot to call one of\nXBT_LOG_NEW_DEFAULT_CATEGORY() or XBT_LOG_NEW_DEFAULT_SUBCATEGORY().\n\n@subsubsection faq_trouble_pthreadstatic \"gcc: undefined reference to pthread_key_create\"\n\nThis indicates that one of the library SimGrid depends on (libpthread\nhere) was missing on the linking command line. Dependencies of\nlibsimgrid are expressed directly in the dynamic library, so it's\nquite impossible that you see this message when doing dynamic linking.\n\nIf you compile your code statically (and if you use a pthread version\nof SimGrid), you must absolutely\nspecify <tt>-lpthread</tt> on the linker command line. As usual, this should\ncome after <tt>-lsimgrid</tt> on this command line.\n\n@subsection faq_trouble_errors Runtime error messages\n\n@subsubsection faq_trouble_errors_big_fat_warning I'm told that my XML files are too old.\n\nThe format of the XML platform description files is sometimes\nimproved. For example, we decided to change the units used in SimGrid\nfrom MBytes, MFlops and seconds to Bytes, Flops and seconds to ease\npeople exchanging small messages. We also reworked the route\ndescriptions to allow more compact descriptions.\n\nThat is why the XML files are versionned using the 'version' attribute\nof the root tag. Currently, it should read:\n@verbatim\n  <platform version=\"4\">\n@endverbatim\n\nIf your files are too old, you can use the simgrid_update_xml.pl\nscript which can be found in the tools directory of the archive.\n\n@subsection faq_trouble_debug Debugging SMPI applications\n\nIn order to debug SMPI programs, you can use the following options:\n\n- <b>-wrapper 'gdb --args'</b>: this option is used to use a wrapper\n  in order to call the SMPI process. Good candidates for this options\n  are \"gdb --args\", \"valgrind\", \"rr record\", \"strace\", etc;\n\n- <b>-foreground</b>: this options gives the debugger access to the terminal\n  which is needed in order to use an interactive debugger.\n\nBoth options are needed in order to run the SMPI process under GDB.\n\n@subsection faq_trouble_valgrind Valgrind-related and other debugger issues\n\nIf you don't, you really should use valgrind to debug your code, it's\nalmost magic.\n\n@subsubsection faq_trouble_vg_libc Valgrind spits tons of errors about backtraces!\n\nIt may happen that valgrind, the memory debugger beloved by any decent C\nprogrammer, spits tons of warnings like the following :\n@verbatim ==8414== Conditional jump or move depends on uninitialised value(s)\n==8414==    at 0x400882D: (within /lib/ld-2.3.6.so)\n==8414==    by 0x414EDE9: (within /lib/tls/i686/cmov/libc-2.3.6.so)\n==8414==    by 0x400B105: (within /lib/ld-2.3.6.so)\n==8414==    by 0x414F937: _dl_open (in /lib/tls/i686/cmov/libc-2.3.6.so)\n==8414==    by 0x4150F4C: (within /lib/tls/i686/cmov/libc-2.3.6.so)\n==8414==    by 0x400B105: (within /lib/ld-2.3.6.so)\n==8414==    by 0x415102D: __libc_dlopen_mode (in /lib/tls/i686/cmov/libc-2.3.6.so)\n==8414==    by 0x412D6B9: backtrace (in /lib/tls/i686/cmov/libc-2.3.6.so)\n==8414==    by 0x8076446: xbt_dictelm_get_ext (dict_elm.c:714)\n==8414==    by 0x80764C1: xbt_dictelm_get (dict_elm.c:732)\n==8414==    by 0x8079010: xbt_cfg_register (config.c:208)\n==8414==    by 0x806821B: MSG_config (msg_config.c:42)\n@endverbatim\n\nThis problem is somewhere in the libc when using the backtraces and there is\nvery few things we can do ourselves to fix it. Instead, here is how to tell\nvalgrind to ignore the error. Add the following to your ~/.valgrind.supp (or\ncreate this file on need). Make sure to change the obj line according to\nyour personnal mileage (change 2.3.6 to the actual version you are using,\nwhich you can retrieve with a simple \"ls /lib/ld*.so\").\n\n@verbatim {\n   name: Backtrace madness\n   Memcheck:Cond\n   obj:/lib/ld-2.3.6.so\n   fun:dl_open_worker\n   fun:_dl_open\n   fun:do_dlopen\n   fun:dlerror_run\n   fun:__libc_dlopen_mode\n}@endverbatim\n\nThen, you have to specify valgrind to use this suppression file by passing\nthe <tt>--suppressions=$HOME/.valgrind.supp</tt> option on the command line.\nYou can also add the following to your ~/.bashrc so that it gets passed\nautomatically. Actually, it passes a bit more options to valgrind, and this\nhappen to be my personnal settings. Check the valgrind documentation for\nmore information.\n\n@verbatim export VALGRIND_OPTS=\"--leak-check=yes --leak-resolution=high --num-callers=40 --tool=memcheck --suppressions=$HOME/.valgrind.supp\" @endverbatim\n\n@subsubsection faq_trouble_backtraces Truncated backtraces\n\nWhen debugging SimGrid, it's easier to pass the\n--disable-compiler-optimization flag to the configure if valgrind or\ngdb get fooled by the optimization done by the compiler. But you\nshould remove these flag when everything works before going in\nproduction (before launching your 1252135 experiments), or everything\nwill run only one half of the true SimGrid potential.\n\n@subsection faq_deadlock There is a deadlock in my code!!!\n\nUnfortunately, we cannot debug every code written in SimGrid.  We\nfurthermore believe that the framework provides ways enough\ninformation to debug such information yourself. If the textual output\nis not enough, Make sure to check the @ref faq_visualization FAQ entry to see\nhow to get a graphical one.\n\nNow, if you come up with a really simple example that deadlocks and\nyou're absolutely convinced that it should not, you can ask on the\nlist. Just be aware that you'll be severely punished if the mistake is\non your side... We have plenty of FAQ entries to redact and new\nfeatures to implement for the impenitents! ;)\n\n@subsection faq_surf_network_latency I get weird timings when I play with the latencies.\n\nOK, first of all, remember that units should be Bytes, Flops and\nSeconds. If you don't use such units, some SimGrid constants (e.g. the\nSG_TCP_CTE_GAMMA constant used in most network models) won't have the\nright unit and you'll end up with weird results.\n\nHere is what happens with a single transfer of size L on a link\n(bw,lat) when nothing else happens.\n\n@verbatim\n0-----lat--------------------------------------------------t\n|-----|**** real_bw =min(bw,SG_TCP_CTE_GAMMA/(2*lat)) *****|\n@endverbatim\n\nIn more complex situations, this min is the solution of a complex\nmax-min linear system.  Have a look\n<a href=\"http://lists.gforge.inria.fr/pipermail/simgrid-devel/2006-April/thread.html\">here</a>\nand read the two threads \"Bug in SURF?\" and \"Surf bug not\nfixed?\". You'll have a few other examples of such computations. You\ncan also read \"A Network Model for Simulation of Grid Application\" by\nHenri Casanova and Loris Marchal to have all the details. The fact\nthat the real_bw is smaller than bw is easy to understand. The fact\nthat real_bw is smaller than SG_TCP_CTE_GAMMA/(2*lat) is due to the\nwindow-based congestion mechanism of TCP. With TCP, you can't exploit\nyour huge network capacity if you don't have a good round-trip-time\nbecause of the acks...\n\nAnyway, what you get is t=lat + L/min(bw,SG_TCP_CTE_GAMMA/(2*lat)).\n\n  * if I you set (bw,lat)=(100 000 000, 0.00001), you get t =  1.00001 (you fully\nuse your link)\n  * if I you set (bw,lat)=(100 000 000, 0.0001),  you get t =  1.0001 (you're on the\nlimit)\n  * if I you set (bw,lat)=(100 000 000, 0.001),   you get t = 10.001  (ouch!)\n\nThis bound on the effective bandwidth of a flow is not the only thing\nthat may make your result be unexpected. For example, two flows\ncompeting on a saturated link receive an amount of bandwidth inversely\nproportional to their round trip time.\n\n@subsection faq_bugrepport So I've found a bug in SimGrid. How to report it?\n\nWe do our best to make sure to hammer away any bugs of SimGrid, but this is\nstill an academic project so please be patient if/when you find bugs in it.\nIf you do, the best solution is to drop an email either on the simgrid-user\nor the simgrid-devel mailing list and explain us about the issue.  You can\nalso decide to open a formal bug report using the\n<a href=\"https://gforge.inria.fr/tracker/?atid=165&group_id=12&func=browse\">relevant\ninterface</a>. You need to login on the server to get the ability to submit\nbugs.\n\nWe will do our best to solve any problem repported, but you need to help us\nfinding the issue. Just telling \"it segfault\" isn't enough. Telling \"It\nsegfaults when running the attached simulator\" doesn't really help either.\nYou may find the following article interesting to see how to repport\ninformative bug repports:\nhttp://www.chiark.greenend.org.uk/~sgtatham/bugs.html (it is not SimGrid\nspecific at all, but it's full of good advices).\n\n*/\n"
    },
    "skipped": [
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.21-2jw7hfw3ki7yfy6d52vbzhst6fypdxym/spack-src/docs/source/tuto_s4u/img/Rscript-screenshot.png",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.21-2jw7hfw3ki7yfy6d52vbzhst6fypdxym/spack-src/docs/source/tuto_s4u/img/vite-screenshot.png",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.21-2jw7hfw3ki7yfy6d52vbzhst6fypdxym/spack-src/docs/source/tuto_s4u/img/result.png",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.21-2jw7hfw3ki7yfy6d52vbzhst6fypdxym/spack-src/docs/source/img/smpi_simgrid_alltoall_pair_16.png",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.21-2jw7hfw3ki7yfy6d52vbzhst6fypdxym/spack-src/docs/source/img/smpi_simgrid_alltoall_ring_16.png",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.21-2jw7hfw3ki7yfy6d52vbzhst6fypdxym/spack-src/docs/source/img/eclipseScreenShot.png",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.21-2jw7hfw3ki7yfy6d52vbzhst6fypdxym/spack-src/docs/source/img/extlink.png",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.21-2jw7hfw3ki7yfy6d52vbzhst6fypdxym/spack-src/docs/source/tuto_smpi/3hosts.png",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.21-2jw7hfw3ki7yfy6d52vbzhst6fypdxym/spack-src/docs/source/tuto_smpi/img/lu.S.4.png",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.21-2jw7hfw3ki7yfy6d52vbzhst6fypdxym/spack-src/doc/webcruft/Paje_MSG_screenshot_thn.jpg",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.21-2jw7hfw3ki7yfy6d52vbzhst6fypdxym/spack-src/doc/webcruft/storage_sample_scenario.png",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.21-2jw7hfw3ki7yfy6d52vbzhst6fypdxym/spack-src/doc/webcruft/output.goal.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.21-2jw7hfw3ki7yfy6d52vbzhst6fypdxym/spack-src/doc/webcruft/Paje_MSG_screenshot.jpg",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.21-2jw7hfw3ki7yfy6d52vbzhst6fypdxym/spack-src/doc/webcruft/AS_hierarchy.png",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.21-2jw7hfw3ki7yfy6d52vbzhst6fypdxym/spack-src/doc/webcruft/SGicon.gif",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.21-2jw7hfw3ki7yfy6d52vbzhst6fypdxym/spack-src/doc/webcruft/eclipseScreenShot.png",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.21-2jw7hfw3ki7yfy6d52vbzhst6fypdxym/spack-src/doc/webcruft/SGicon.icns",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.21-2jw7hfw3ki7yfy6d52vbzhst6fypdxym/spack-src/doc/webcruft/SGicon.ico",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.21-2jw7hfw3ki7yfy6d52vbzhst6fypdxym/spack-src/doc/webcruft/awstats_logo3.png",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.21-2jw7hfw3ki7yfy6d52vbzhst6fypdxym/spack-src/doc/webcruft/simgrid_logo_2011.png",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.21-2jw7hfw3ki7yfy6d52vbzhst6fypdxym/spack-src/doc/webcruft/simgrid_logo_2011.gif",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.21-2jw7hfw3ki7yfy6d52vbzhst6fypdxym/spack-src/doc/webcruft/poster_thumbnail.png",
        "/tmp/vanessa/spack-stage/spack-stage-simgrid-3.21-2jw7hfw3ki7yfy6d52vbzhst6fypdxym/spack-src/doc/webcruft/simgrid_logo_2011_small.png"
    ],
    "total_files": 2531
}