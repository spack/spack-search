{
    "matches": {
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/configure.ac.in": "dnl configure.ac -- Main configuration script for WHIZARD\ndnl\ndnl Process this file with autoconf to produce a configure script.\ndnl ************************************************************************\ndnl configure.ac -- Main configuration script for WHIZARD\ndnl configure.ac -- WHIZARD configuration\ndnl\ndnl Copyright (C) 1999-2020 by\ndnl     Wolfgang Kilian <kilian@physik.uni-siegen.de>\ndnl     Thorsten Ohl <ohl@physik.uni-wuerzburg.de>\ndnl     Juergen Reuter <juergen.reuter@desy.de>\ndnl     with contributions from\ndnl     cf. main AUTHORS file\ndnl\ndnl WHIZARD is free software; you can redistribute it and/or modify it\ndnl under the terms of the GNU General Public License as published by\ndnl the Free Software Foundation; either version 2, or (at your option)\ndnl any later version.\ndnl\ndnl WHIZARD is distributed in the hope that it will be useful, but\ndnl WITHOUT ANY WARRANTY; without even the implied warranty of\ndnl MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\ndnl GNU General Public License for more details.\ndnl\ndnl You should have received a copy of the GNU General Public License\ndnl along with this program; if not, write to the Free Software\ndnl Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.\ndnl\ndnl ***********************************************************************\ndnl Environment variables that can be set by the user:\ndnl   FC\t\tFortran compiler\ndnl   FCFLAGS\t\tFortran compiler flags\ndnl ***********************************************************************\ndnl\ndnl Start configuration\nAC_INIT([XXXWHIZARDXXX],[3.0.0_beta+])\nAC_CONFIG_MACRO_DIR([m4])\nAM_INIT_AUTOMAKE([1.12.2 color-tests parallel-tests])\nAC_PREREQ([2.65])\nAM_MAKE_INCLUDE\n\ndnl Make make less verbose to improve signal/noise\nAM_SILENT_RULES([yes])\n\n########################################################################\n### Package-specific initialization\n\nAC_MSG_NOTICE([**************************************************************])\nWO_CONFIGURE_SECTION([Start of package configuration])\n\n### Further version information\nPACKAGE_DATE=\"Aug 30 2020\"\nPACKAGE_STATUS=\"beta\"\n\nAC_SUBST(PACKAGE_DATE)\nAC_SUBST(PACKAGE_STATUS)\n\nAC_MSG_NOTICE([**************************************************************])\nAC_MSG_NOTICE([Package name: AC_PACKAGE_NAME()])\nAC_MSG_NOTICE([Version:      AC_PACKAGE_VERSION()])\nAC_MSG_NOTICE([Date:         $PACKAGE_DATE])\nAC_MSG_NOTICE([Status:       $PACKAGE_STATUS])\nAC_MSG_NOTICE([**************************************************************])\n\n### Dump Package version and date to file 'VERSION'\necho \"$PACKAGE_STRING ($PACKAGE_STATUS) $PACKAGE_DATE\" \\\n  > VERSION\n\n########################################################################\n###---------------------------------------------------------------------\n### shared library versioning (not the same as the package version!)\n\nLIBRARY_VERSION=\"-version-info 2:0:0\"\nAC_SUBST([LIBRARY_VERSION])\n\n########################################################################\n###---------------------------------------------------------------------\n### Define the main package variables\n\n### Source directory, for testing purposes\nSRCDIR=`cd $srcdir && pwd`\nAC_SUBST([SRCDIR])\n\n### Build directory, for testing purposes\nBUILDDIR=`pwd`\nAC_SUBST([BUILDDIR])\n\n### Location of installed libraries and such\neval BINDIR=$bindir\ncase $BINDIR in\nNONE*) eval BINDIR=$prefix/bin ;;\nesac\ncase $BINDIR in\nNONE*) BINDIR=\"\\${prefix}/bin\" ;;\nesac\nAC_SUBST([BINDIR])\n\neval INCLUDEDIR=$includedir\ncase $INCLUDEDIR in\nNONE*) eval INCLUDEDIR=$prefix/include ;;\nesac\ncase $INCLUDEDIR in\nNONE*) INCLUDEDIR=\"\\${prefix}/include\" ;;\nesac\nAC_SUBST([INCLUDEDIR])\n\neval LIBDIR=$libdir\ncase $LIBDIR in\nNONE*) eval LIBDIR=$prefix/lib ;;\nesac\ncase $LIBDIR in\nNONE*) eval LIBDIR=$ac_default_prefix/lib ;;\nesac\nAC_SUBST([LIBDIR])\n\n### Location of installed libraries and such\neval PKGLIBDIR=$libdir/$PACKAGE\ncase $PKGLIBDIR in\nNONE*) eval PKGLIBDIR=$prefix/lib/$PACKAGE ;;\nesac\ncase $PKGLIBDIR in\nNONE*) PKGLIBDIR=\"\\${prefix}/lib/$PACKAGE\" ;;\nesac\nAC_SUBST([PKGLIBDIR])\n\n### Location of installed system-independent data\neval PKGDATADIR=$datarootdir/$PACKAGE\ncase $PKGDATADIR in\nNONE*) eval PKGDATADIR=$prefix/share/$PACKAGE ;;\nesac\ncase $PKGDATADIR in\nNONE*) PKGDATADIR=\"\\${prefix}/share/$PACKAGE\" ;;\nesac\nAC_SUBST([PKGDATADIR])\n\n### Location of installed TeX files and such\neval PKGTEXDIR=$datarootdir/texmf/$PACKAGE\ncase $PKGTEXDIR in\nNONE*) eval PKGTEXDIR=$prefix/share/texmf/$PACKAGE ;;\nesac\ncase $PKGTEXDIR in\nNONE*) PKGTEXDIR=\"\\${prefix}/share/texmf/$PACKAGE\" ;;\nesac\nAC_SUBST([PKGTEXDIR])\n\n### Parent location of installed .mod files\n### To be used in Fortran source\nFMODDIR=$prefix/lib/mod\ncase $FMODDIR in\nNONE*) FMODDIR=\"\\${prefix}/lib/mod\" ;;\nesac\nAC_SUBST([FMODDIR])\n\n### To be used in Makefile.am\n### Don't use ${libdir} since lib may be changed to lib64 by configure\nfmoddir=\"\\${prefix}/lib/mod\"\nAC_SUBST([fmoddir])\n\n########################################################################\n###---------------------------------------------------------------------\n### Required programs and checks\n### GNU Tools\n\nWO_CONFIGURE_SECTION([Generic tools])\n\n### Initialize LIBTOOL\nLT_INIT(dlopen)\n\nLT_PREREQ([2.4.1b])\n\nAX_CHECK_GNU_MAKE()\nAC_PROG_GREP()\n\nAC_MSG_CHECKING([for the suffix of shared libraries])\ncase $host in\n  *-darwin* | rhapsody*)\n    SHRLIB_EXT=\"dylib\"\n    ;;\n  cygwin* | mingw* | pw32* | cegcc* | os2*)\n    SHRLIB_EXT=\"dll\"\n    ;;\n  hpux9* | hpux10* | hpux11*)\n    SHRLIB_EXT=\"sl\"\n    ;;\n  *)\n    SHRLIB_EXT=\"so\"\n    ;;\nesac\nif test \"x$SHRLIB_EXT\" != \"x\"; then\n   SHRLIB_EXT=$SHRLIB_EXT\nelse\n   SHRLIB_EXT=\"so\"\nfi\nAC_MSG_RESULT([.$SHRLIB_EXT])\nAC_SUBST(SHRLIB_EXT)\n\n### Export whether the C compiler is GNU\nAC_MSG_CHECKING([whether the C compiler is the GNU compiler])\nif test \"x$ac_cv_c_compiler_gnu\" = \"xyes\"; then\n   CC_IS_GNU=\".true.\"\nelse\n   CC_IS_GNU=\".false.\"\nfi\nAC_MSG_RESULT([$ac_cv_c_compiler_gnu])\nAC_SUBST([CC_IS_GNU])\n\nAC_CHECK_HEADERS([quadmath.h])\nif test \"x$ac_cv_header_quadmath_h\" = \"xyes\"; then\n   CC_HAS_QUADMATH=\".true.\"\nelse\n   CC_HAS_QUADMATH=\".false.\"\nfi\nAC_SUBST([CC_HAS_QUADMATH])\n\n########################################################################\n###---------------------------------------------------------------------\n### Host system MAC OS X check for XCode\n\ncase $host in\n     *-darwin*)\n        WO_HLINE()\n     \tAC_MSG_NOTICE([Host is $host, checking for XCode])\n        AC_PATH_PROG(XCODE_SELECT, xcode-select)\n\t# locate currently selected Xcode path\n\tif test \"x$XCODE_SELECT\" != \"x\"; then\n\t  AC_MSG_CHECKING(Xcode location)\n\t  DEVELOPER_DIR=`$XCODE_SELECT -print-path`\n\t  AC_MSG_RESULT([$DEVELOPER_DIR])\n\telse\n\t  DEVELOPER_DIR=/Developer\n\tfi\n\tAC_SUBST(DEVELOPER_DIR)\n\n\tXCODEPLIST=$DEVELOPER_DIR/Applications/Xcode.app/Contents/version.plist\n\tif test -r \"$XCODEPLIST\"; then\n\t  AC_MSG_CHECKING(Xcode version)\n\t  if test \"x$DEFAULTS\" != \"x\"; then\n\t    XCODE_VERSION=`$DEFAULTS read $DEVELOPER_DIR/Applications/Xcode.app/Contents/version CFBundleShortVersionString`\n\t  else\n\t    XCODE_VERSION=`tr -d '\\r\\n' < $XCODEPLIST | sed -e 's/.*<key>CFBundleShortVersionString<\\/key>.<string>\\([[0-9.]]*\\)<\\/string>.*/\\1/'`\n\t  fi\n\t  AC_MSG_RESULT([$XCODE_VERSION])\n\t  AC_SUBST(XCODE_VERSION)\n\tfi\n\n\tAC_MSG_NOTICE([checking for Security Integrity Protocol (SIP)])\n\tAC_PATH_PROG(CSRUTIL, csrutil)\n\tif test \"x$CSRUTIL\" != \"x\"; then\n\t   SIP_CHECK=`$CSRUTIL status | $SED \"s/System Integrity Protection status: //\"`\n\t   if test \"$SIP_CHECK\" = \"enabled.\"; then\n\t      SIP_ACTIVE=\"yes\"\n\t   else\n\t      SIP_ACTIVE=\"no\"\n \t   fi\n\telse\n\t   SIP_ACTIVE=\"no\"\n\tfi\n\tAC_MSG_CHECKING([Checking whether MAC OS X SIP is activated])\n\tAC_MSG_RESULT([$SIP_ACTIVE])\n\tAC_SUBST([SIP_ACTIVE])\n\n\tWO_HLINE()\n\t;;\n     *)\n        ;;\n     esac\n\n########################################################################\n###---------------------------------------------------------------------\n### Enable the distribution tools\n### (default: disabled, to speed up compilation)\n\nAC_ARG_ENABLE([distribution],\n  [AS_HELP_STRING([--enable-distribution],\n    [build the distribution incl. all docu (developers only) [[no]]])])\n\nAC_CACHE_CHECK([whether we want to build the distribution],\n[wo_cv_distribution],\n[dnl\nif test \"$enable_distribution\" = \"yes\"; then\n  wo_cv_distribution=yes\nelse\n  wo_cv_distribution=no\nfi])\n\nAM_CONDITIONAL([DISTRIBUTION],\n  [test \"$enable_distribution\" = \"yes\"])\n\n### ONLY_FULL {{{\n########################################################################\n###---------------------------------------------------------------------\n\nif test \"$enable_shared\" = no; then\n  AC_MSG_ERROR([you've used --disable-shared which will not produce a working Whizard.])\nfi\n### ONLY_FULL }}}\n\n########################################################################\n###---------------------------------------------------------------------\n### We include the m4 macro tool here\n\nAC_PATH_PROG(M4,m4,false)\nif test \"$M4\" = false; then\n   AM_CONDITIONAL([M4_AVAILABLE],[false])\nelse\n   AM_CONDITIONAL([M4_AVAILABLE],[true])\nfi\n\n########################################################################\n###---------------------------------------------------------------------\n### Dynamic runtime linking\n\nWO_CONFIGURE_SECTION([Dynamic runtime linking])\n\n### Look for libdl (should provide 'dlopen' and friends)\nAC_PROG_CC()\nWO_PROG_DL()\n\n### Define the conditional for static builds\n\nif test \"$enable_static\" = yes; then\n   AM_CONDITIONAL([STATIC_AVAILABLE],[true])\nelse\n   AM_CONDITIONAL([STATIC_AVAILABLE],[false])\nfi\n\n########################################################################\n###---------------------------------------------------------------------\n### Noweb\n\nWO_CONFIGURE_SECTION([Checks for 'noweb' system])\n\n### Enable/disable noweb and determine locations of notangle, cpif, noweave\nWO_PROG_NOWEB()\n\n########################################################################\n###---------------------------------------------------------------------\n### LaTeX\n\nWO_CONFIGURE_SECTION([Checks for 'LaTeX' system])\n\n### Determine whether LaTeX is present\nAC_PROG_LATEX()\nAC_PROG_DVIPS()\nAC_PROG_PDFLATEX()\nAC_PROG_MAKEINDEX()\nAC_PROG_PS2PDF()\nAC_PROG_EPSPDF()\nAC_PROG_EPSTOPDF()\nif test \"$EPSPDF\" = \"no\" -a \"$EPSTOPDF\" = \"no\"; then\n   AC_MSG_NOTICE([*********************************************************])\n   AC_MSG_NOTICE([WARNING: eps(to)pdf n/a; O'Mega documentation will crash!])\n   AC_MSG_NOTICE([WARNING:  this applies only to the svn developer version!])\n   AC_MSG_NOTICE([*********************************************************])\nfi\nAC_PROG_SUPP_PDF()\nAC_PROG_GZIP()\nAC_PATH_PROG(ACROREAD,acroread,false)\nAC_PATH_PROG(GHOSTVIEW,gv ghostview,false)\nAC_PROG_DOT()\n\n### Determine whether Metapost is present and whether event display is possible\nAC_PROG_MPOST()\nWO_CHECK_EVENT_ANALYSIS_METHODS()\n\n### We put here the check for HEVEA components as well\nWO_PROG_HEVEA()\n\n########################################################################\n###---------------------------------------------------------------------\n### Fortran compiler\n\nWO_CONFIGURE_SECTION([Fortran compiler checks])\n\n### Determine default compiler to use\nuser_FCFLAGS=\"${FCFLAGS}\"\nAC_PROG_FC()\n\n### Choose FC standard for PYTHIA6 F77 files\nAC_PROG_F77([$FC])\n\n### Determine compiler vendor and version\nWO_FC_GET_VENDOR_AND_VERSION()\n\n### Veto against old gfortran 4 versions\nWO_FC_VETO_GFORTRAN_4()\n\n### Veto against buggy gfortran 6.5.0 version\nWO_FC_VETO_GFORTRAN_65()\n\n### Veto against ifort 15/16/17\nWO_FC_VETO_IFORT_15_18()\n\n### Veto against ifort 19.0.0/1/2\nWO_FC_VETO_IFORT_190012()\n\n### Require extension '.f90' for all compiler checks\nAC_FC_SRCEXT([f90])\n\n### Determine flags and extensions\nWO_FC_PARAMETERS()\n\n### Determine flags for linking the Fortran runtime library\nWO_FC_LIBRARY_LDFLAGS()\n\n### Check for Fortran 95 features\nWO_FC_CHECK_F95()\n\n### Check for allocatable subobjects (TR15581)\nWO_FC_CHECK_TR15581()\n\n### Check for allocatable scalars\nWO_FC_CHECK_ALLOCATABLE_SCALARS()\n\n### Check for ISO C binding support\nWO_FC_CHECK_C_BINDING()\n\n### Check for procedures pointers and abstract interfaces\nWO_FC_CHECK_PROCEDURE_POINTERS()\n\n### Check for type extension and further OO features\nWO_FC_CHECK_OO_FEATURES()\n\n### Check for submodules (not yet used)\nWO_FC_CHECK_TR19767()\n\n### Check for F2003 command-line interface\nWO_FC_CHECK_CMDLINE()\n\n### Check for F2003-style access to environment variables\nWO_FC_CHECK_ENVVAR()\n\n### Check for the flush statement\nWO_FC_CHECK_FLUSH()\n\n### Check for iso_fortran_env\nWO_FC_CHECK_ISO_FORTRAN_ENV()\nWO_FC_CHECK_ISO_FORTRAN_ENV_2008()\n\n### Turn on/off master switch for debugging features\nWO_FC_SET_DEBUG()\n\n### OpenMP threading activated upon request\nAC_OPENMP()\nWO_FC_SET_OPENMP()\n\n### Profiling compilation enforced upon request\nWO_FC_SET_PROFILING()\n\n### Impure subroutines enforced upon request\nWO_FC_SET_OMEGA_IMPURE()\n\n### Find the extension of Fortran module files\nWO_FC_MODULE_FILE([FC_MODULE_NAME], [FCMOD], [$FC], [f90])\n\n###---------------------------------------------------------------------\n### Check for the requested precision\n\nWO_FC_CONFIGURE_KINDS([src/basics/kinds.f90])\n### ONLY_FULL {{{\nAC_PROG_INSTALL()\n${INSTALL} -d circe1/src\ncp -a src/basics/kinds.f90 circe1/src\n${INSTALL} -d circe2/src\ncp -a src/basics/kinds.f90 circe2/src\n${INSTALL} -d omega/src\ncp -a src/basics/kinds.f90 omega/src\n${INSTALL} -d vamp/src\ncp -a src/basics/kinds.f90 vamp/src\n### ONLY_FULL }}}\n\n### ONLY_VAMP_AND_FULL {{{\n########################################################################\n# VAMP Fortran options for the configure script\n########################################################################\n\nWO_FC_SET_MPI()\n\n### ONLY_VAMP_AND_FULL }}}\n\n########################################################################\n###---------------------------------------------------------------------\n### O'Caml\n\nWO_CONFIGURE_SECTION([Objective Caml checks])\n\n### Check for ocamlc and its relatives\nAC_PROG_OCAML()\nif test \"$enable_ocaml\" != \"no\"; then\n   AC_OCAML_VERSION_CHECK(402003)\n   AC_PROG_OCAMLLEX()\n   AC_PROG_OCAMLYACC()\n   AC_PROG_OCAMLCP()\n   AC_OCAML_BIGARRAY_MODULE()\n   ### Ocamlweb is required to be newer than v0.9\n   AC_PROG_OCAMLWEB(009000)\n   AC_PROG_OCAML_LABLGTK()\n   AC_PATH_PROGS([OCAMLDOT],[ocamldot],[no])\n   AM_CONDITIONAL([OCAMLDOT_AVAILABLE],[test \"$OCAMLDOT\" != \"no\"])\n   AC_PATH_PROGS([OCAMLDEP],[ocamldep],[no])\n   AM_CONDITIONAL([OCAMLDEP_AVAILABLE],[test \"$OCAMLDEP\" != \"no\"])\n   AC_PATH_PROGS([OCAMLDEFUN],[ocamldefun],[no])\nelse\n   AC_MSG_NOTICE([WARNING: O'Caml and O'Mega matrix elements disabled by request!])\n   AM_CONDITIONAL([OCAMLWEB_AVAILABLE],[false])\n   AM_CONDITIONAL([OCAMLDOT_AVAILABLE],[false])\n   AM_CONDITIONAL([OCAMLDEP_AVAILABLE],[false])\nfi\n\n########################################################################\n###---------------------------------------------------------------------\n### C++\n\nWO_CONFIGURE_SECTION([C++ compiler checks])\nAC_PROG_CXX()\nAC_CXX_LIBRARY_LDFLAGS()\n\n########################################################################\n###---------------------------------------------------------------------\n### Checks for external interfaces\n\nWO_CONFIGURE_SECTION([Checking for PYTHON / PYTHON API])\n\nAX_PYTHON_DEVEL([>= '2.7'])\nWO_PROG_PYTHON_API()\n\n### ONLY_OMEGA_AND_FULL {{{\n########################################################################\n# O'Mega options for the configure script\n########################################################################\n\n########################################################################\n###---------------------------------------------------------------------\n### O'Mega UFO file paths\n\nWO_CONFIGURE_SECTION([O'Mega UFO file paths])\n\nAC_ARG_ENABLE([default-UFO-dir],\n[  --enable-default-UFO-dir=directory\n                          Read precomputed model tables from this directory,\n                          which will be populated by an administrator at\n                          install time [[default=$datadir/UFO, enabled]].],\n[case \"$enableval\" in\n   no) OMEGA_DEFAULT_UFO_DIR=\".\"\n       ;;\n    *) OMEGA_DEFAULT_UFO_DIR=\"$enableval\"\n       ;;\nesac],\n[### use eval b/c $datadir defaults to unexpanded ${datarootdir}\ncase \"$OMEGA_DEFAULT_UFO_DIR\" in\n   \"\") OMEGA_DEFAULT_UFO_DIR=\"${prefix}/omega/share/UFO\"\n      ;;\n   *) eval OMEGA_DEFAULT_UFO_DIR=\"$datadir/UFO\"\n      ;;\nesac])\nAC_SUBST([OMEGA_DEFAULT_UFO_DIR])\n\ncase \"$OMEGA_DEFAULT_UFO_DIR\" in\n  .|\"\"|NONE*) OMEGA_DEFAULT_UFO_DIR=\".\"\n              ;;\n           *) AC_MSG_NOTICE([Creating default UFO directory $OMEGA_DEFAULT_UFO_DIR])\n              $MKDIR_P \"$OMEGA_DEFAULT_UFO_DIR\" 2>/dev/null\n              chmod u+w \"$OMEGA_DEFAULT_UFO_DIR\" 2>/dev/null\n              ;;\nesac\n\n###---------------------------------------------------------------------\n### Recola\n\nWO_CONFIGURE_SECTION([RECOLA])\n\nWO_PROG_RECOLA()\n\n### ONLY_OMEGA_AND_FULL }}}\n\n### ONLY_FULL {{{\n########################################################################\n###---------------------------------------------------------------------\n### Libraries\n\n###---------------------------------------------------------------------\n### LHAPDF\n\nWO_CONFIGURE_SECTION([LHAPDF])\n\nWO_PROG_LHAPDF()\n\n###---------------------------------------------------------------------\n### ROOT\n\nWO_CONFIGURE_SECTION([ROOT])\n\nWO_ROOT_PATH(,[\n        AC_DEFINE([HAVE_ROOT],,[Root library])\n        AC_CHECK_LIB([dl],[dlopen],[],AC_MSG_WARN([Root libraries not linking properly]))\n        ],AC_MSG_RESULT([The ROOT support of HepMC might not be working properly]))\n\n###---------------------------------------------------------------------\n### HepMC\n\nWO_CONFIGURE_SECTION([HepMC])\n\nWO_PROG_HEPMC()\n\n###---------------------------------------------------------------------\n### STDHEP\n\nWO_CONFIGURE_SECTION([STDHEP])\n\nWO_PROG_TIRPC()\n\nAC_MSG_NOTICE([StdHEP v5.06.01 is included internally])\n\n###---------------------------------------------------------------------\n### LCIO\n\nWO_CONFIGURE_SECTION([LCIO])\n\nWO_PROG_LCIO()\n\n###---------------------------------------------------------------------\n### HDF5 (for events, grids etc.)\n\nWO_CONFIGURE_SECTION([HDF5])\n\nWO_PROG_HDF5(1.8.0,no)\n\n###---------------------------------------------------------------------\n### PYTHIA6, PYTHIA8 etc\n\nWO_CONFIGURE_SECTION([SHOWERS PYTHIA6 PYTHIA8 MPI])\n\nWO_PROG_QCD()\n\nWO_PROG_PYTHIA8()\n\n###---------------------------------------------------------------------\n### HOPPET\n\nWO_CONFIGURE_SECTION([HOPPET])\n\nWO_PROG_HOPPET()\n\n###---------------------------------------------------------------------\n### FASTJET\n\nWO_CONFIGURE_SECTION([FASTJET])\n\nWO_PROG_FASTJET()\n\n###---------------------------------------------------------------------\n### GoSam\n\nWO_CONFIGURE_SECTION([GOSAM])\n\nWO_PROG_GOSAM()\n\n###---------------------------------------------------------------------\n### OpenLoops\n\nWO_CONFIGURE_SECTION([OPENLOOPS])\n\nWO_PROG_OPENLOOPS()\n\n###---------------------------------------------------------------------\n### LoopTools\n\nWO_CONFIGURE_SECTION([LOOPTOOLS])\n\nWO_PROG_LOOPTOOLS()\n\n### ONLY_FULL }}}\n\n########################################################################\n###---------------------------------------------------------------------\n### Extra flags for helping the linker finding libraries\n\nWO_CONFIGURE_SECTION([Handle linking with C++ libraries])\n\nWO_PROG_STDCPP()\n\n### ONLY_FULL {{{\n########################################################################\n###---------------------------------------------------------------------\n### Miscellaneous\n\nWO_CONFIGURE_SECTION([Numerical checks])\n\n### Disable irrelevant optimization for parameter files\n### (default: disabled, to speed up compilation)\n\nAC_ARG_ENABLE([optimization-for-parameter-files],\n  [AS_HELP_STRING([--enable-optimization-for-parameter-files],\n    [enable (useless) optimization for parameter files [[no]]])])\n\nAC_CACHE_CHECK([whether we want optimization for parameter files],\n[wo_cv_optimization_for_parfiles],\n[dnl\nif test \"$enable_optimization_for_parameter_files\" = \"yes\"; then\n  wo_cv_optimization_for_parfiles=yes\nelse\n  wo_cv_optimization_for_parfiles=no\nfi])\n\nAM_CONDITIONAL([OPTIMIZATION_FOR_PARFILES],\n  [test \"$enable_optimization_for_parameter_files\" = \"yes\"])\n\n### ONLY_FULL }}}\n\n########################################################################\n###---------------------------------------------------------------------\n### Wrapup\n\nWO_CONFIGURE_SECTION([Finalize configuration])\n\n### Main directory\n\nAC_CONFIG_FILES([Makefile])\n\n### ONLY_FULL {{{\n###---------------------------------------------------------------------\n### Subdirectory src\n\nAC_CONFIG_FILES([src/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory python: WHIZARD's PYTHON/CYTHON interface\n\nAC_CONFIG_FILES([python/Makefile])\nAC_CONFIG_FILES([python/setup.py], [chmod u+x python/setup.py])\nAC_CONFIG_LINKS([python/whizard_python.pyx:python/whizard_python.pyx])\nAC_CONFIG_LINKS([python/cwhizard.pxd:python/cwhizard.pxd])\n\n###---------------------------------------------------------------------\n### Subdirectory src/hepmc\n\nAC_CONFIG_FILES([src/hepmc/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/lcio\n\nAC_CONFIG_FILES([src/lcio/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory pythia6: WHIZARD's internal PYTHIA6 version\n\nAC_CONFIG_FILES([pythia6/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory tauola: WHIZARD's internal TAUOLA version\n\nAC_CONFIG_FILES([tauola/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory stdhep: WHIZARD's internal StdHep version\n\nAC_CONFIG_FILES([mcfio/Makefile])\nAC_CONFIG_FILES([stdhep/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/muli: multiple interactions\n\nAC_CONFIG_FILES([src/muli/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/lhapdf5: dummy library as LHAPDF5 replacement\n\nAC_CONFIG_FILES([src/lhapdf5/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/lhapdf: LHAPDF v6\n\nAC_CONFIG_FILES([src/lhapdf/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/pdf_builtin: Builtin PDFs\n\nAC_CONFIG_FILES([src/pdf_builtin/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/pdf_builtin: Electron PDFs\n\nAC_CONFIG_FILES([src/qed_pdf/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/tauola\n\nAC_CONFIG_FILES([src/tauola/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/xdr: XDR reader\n\nAC_CONFIG_FILES([src/xdr/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/hoppet\n\nAC_CONFIG_FILES([src/hoppet/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/fastjet\n\nAC_CONFIG_FILES([src/fastjet/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/looptools\n\nAC_CONFIG_FILES([src/looptools/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/shower: shower and all that\n\nAC_CONFIG_FILES([src/pythia8/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/shower: shower and all that\n\nAC_CONFIG_FILES([src/shower/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/noweb-frame: frame for whizard Noweb sources\n\nAC_CONFIG_FILES([src/noweb-frame/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/basics: numeric kinds, strings\n\nAC_CONFIG_FILES([src/basics/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/utilities: simple utilities\n\nAC_CONFIG_FILES([src/utilities/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/testing: unit-test support\n\nAC_CONFIG_FILES([src/testing/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/system: modules related to local setup and OS issues\n\nAC_CONFIG_FILES([src/system/Makefile])\n\nAC_CONFIG_FILES([src/system/system_dependencies.f90], [\n   maxlen=70\n   i=1\n   pat=\"\"\n   while test ${i} -lt ${maxlen}; do pat=\"${pat}.\"; i=`expr ${i} + 1`; done\n   pat=${pat}[[^\\\"]]\n   pat=\"/^       \\\"${pat}/ s/${pat}/&\\&\\\\\n       \\&/g\"\n   $SED \"${pat}\" < src/system/system_dependencies.f90 > \\\n      src/system/system_dependencies.tmp\n   mv -f src/system/system_dependencies.tmp src/system/system_dependencies.f90\n])\n\nAC_CONFIG_FILES([src/system/debug_master.f90])\n\n###---------------------------------------------------------------------\n### Subdirectory src/combinatorics: standard algorithms\n\nAC_CONFIG_FILES([src/combinatorics/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/parsing: text-handling and parsing\n\nAC_CONFIG_FILES([src/parsing/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/rng: random-number generation\n\nAC_CONFIG_FILES([src/rng/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/expr_base: abstract expressions\n\nAC_CONFIG_FILES([src/expr_base/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/physics: particle-physics related functions\n\nAC_CONFIG_FILES([src/physics/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/qft: quantum (field) theory concepts as data types\n\nAC_CONFIG_FILES([src/qft/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/types: HEP and other types for common use\n\nAC_CONFIG_FILES([src/types/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/matrix_elements: process code and libraries\n\nAC_CONFIG_FILES([src/matrix_elements/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/me_methods: specific process code and interface\n\nAC_CONFIG_FILES([src/me_methods/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/particles: particle objects\n\nAC_CONFIG_FILES([src/particles/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/beams: beams and beam structure\n\nAC_CONFIG_FILES([src/beams/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/events: generic events and event I/O\n\nAC_CONFIG_FILES([src/events/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/vegas: VEGAS Monte Carlo adaptive integration\n\nAC_CONFIG_FILES([src/vegas/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/mci: multi-channel integration and event generation\n\nAC_CONFIG_FILES([src/mci/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/phase_space: parameterization and evaluation\n\nAC_CONFIG_FILES([src/phase_space/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/blha: BLHA support (NLO data record)\n\nAC_CONFIG_FILES([src/blha/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/gosam: GoSAM support (NLO amplitudes)\n\nAC_CONFIG_FILES([src/gosam/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/openloops: OpenLoops support (NLO amplitudes)\n\nAC_CONFIG_FILES([src/openloops/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/recola: Recola support (NLO amplitudes)\n\nAC_CONFIG_FILES([src/recola/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/fks: FKS subtraction algorithm\n\nAC_CONFIG_FILES([src/fks/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/matching: matching algorithms\n\nAC_CONFIG_FILES([src/matching/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/variables: Implementation of variable lists\n\nAC_CONFIG_FILES([src/variables/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/model_features: Model access and methods\n\nAC_CONFIG_FILES([src/model_features/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/models: Model-specific code\n\nAC_CONFIG_FILES([src/models/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/threshold\n\nAC_CONFIG_FILES([src/threshold/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/models/threeshl_bundle\n\nAC_CONFIG_FILES([src/models/threeshl_bundle/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/process_integration\n\nAC_CONFIG_FILES([src/process_integration/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/transforms: event transforms and event API\n\nAC_CONFIG_FILES([src/transforms/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/whizard-core\n\nAC_CONFIG_FILES([src/whizard-core/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/api\n\nAC_CONFIG_FILES([src/api/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/main\n\nAC_CONFIG_FILES([src/main/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/prebuilt\n\nAC_CONFIG_FILES([src/prebuilt/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/feynmf\n\nAC_CONFIG_FILES([src/feynmf/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory src/gamelan: WHIZARD graphics package\n\nAC_CONFIG_FILES([src/gamelan/Makefile])\n\nAC_CONFIG_FILES([src/gamelan/whizard-gml], [chmod u+x src/gamelan/whizard-gml])\n###---------------------------------------------------------------------\n### Subdirectory share\n\nAC_CONFIG_FILES([share/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory share/doc\n\nAC_CONFIG_FILES([share/doc/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory share/models\n\nAC_CONFIG_FILES([share/models/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory share/cuts\n\nAC_CONFIG_FILES([share/cuts/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory share/beam-sim\n\nAC_CONFIG_FILES([share/beam-sim/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory share/susy\n\nAC_CONFIG_FILES([share/susy/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory share/examples\n\nAC_CONFIG_FILES([share/examples/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory share/tests\n\nAC_CONFIG_FILES([share/tests/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory share/muli\n\nAC_CONFIG_FILES([share/muli/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory share/SM_tt_threshold_data\n\nAC_CONFIG_FILES([share/SM_tt_threshold_data/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory share/gui\n\nAC_CONFIG_FILES([share/gui/Makefile])\n\n###---------------------------------------------------------------------\n### Subdirectory tests\n\nAC_CONFIG_FILES([tests/Makefile])\n\nAC_CONFIG_FILES([tests/models/Makefile])\nAC_CONFIG_FILES([tests/models/UFO/Makefile])\nAC_CONFIG_FILES([tests/models/UFO/SM/Makefile])\nAC_CONFIG_FILES([tests/models/UFO/MSSM/Makefile])\n\nAC_CONFIG_FILES([tests/unit_tests/Makefile])\nAC_CONFIG_FILES([tests/functional_tests/Makefile])\nAC_CONFIG_FILES([tests/ext_tests_mssm/Makefile])\nAC_CONFIG_FILES([tests/ext_tests_nmssm/Makefile])\nAC_CONFIG_FILES([tests/ext_tests_ilc/Makefile])\nAC_CONFIG_FILES([tests/ext_tests_shower/Makefile])\nAC_CONFIG_FILES([tests/ext_tests_nlo/Makefile])\nAC_CONFIG_FILES([tests/ext_tests_nlo_add/Makefile])\n\nAC_CONFIG_FILES([tests/unit_tests/run_whizard_ut.sh],\n  [chmod u+x tests/unit_tests/run_whizard_ut.sh])\nAC_CONFIG_FILES([tests/unit_tests/run_whizard_ut_c.sh],\n  [chmod u+x tests/unit_tests/run_whizard_ut_c.sh])\nAC_CONFIG_FILES([tests/unit_tests/run_whizard_ut_cc.sh],\n  [chmod u+x tests/unit_tests/run_whizard_ut_cc.sh])\nAC_CONFIG_FILES([tests/functional_tests/run_whizard.sh],\n  [chmod u+x tests/functional_tests/run_whizard.sh])\nAC_CONFIG_FILES([tests/ext_tests_mssm/run_whizard.sh],\n  [chmod u+x tests/ext_tests_mssm/run_whizard.sh])\nAC_CONFIG_FILES([tests/ext_tests_nmssm/run_whizard.sh],\n  [chmod u+x tests/ext_tests_nmssm/run_whizard.sh])\nAC_CONFIG_FILES([tests/ext_tests_ilc/run_whizard.sh],\n  [chmod u+x tests/ext_tests_ilc/run_whizard.sh])\nAC_CONFIG_FILES([tests/ext_tests_shower/run_whizard.sh],\n  [chmod u+x tests/ext_tests_shower/run_whizard.sh])\nAC_CONFIG_FILES([tests/ext_tests_nlo/run_whizard.sh],\n  [chmod u+x tests/ext_tests_nlo/run_whizard.sh])\nAC_CONFIG_FILES([tests/ext_tests_nlo_add/run_whizard.sh],\n  [chmod u+x tests/ext_tests_nlo_add/run_whizard.sh])\n\n###--------------------------------------------------------------------\n### Subdirectory scripts\n\nAC_CONFIG_FILES([scripts/Makefile])\n\nAC_CONFIG_FILES([scripts/whizard-config], [chmod u+x scripts/whizard-config])\nAC_CONFIG_FILES([scripts/whizard-setup.sh], [chmod u+x scripts/whizard-setup.sh])\nAC_CONFIG_FILES([scripts/whizard-setup.csh], [chmod u+x scripts/whizard-setup.csh])\n\n### ONLY_FULL }}}\n\n### ONLY_CIRCE1_AND_FULL {{{\n###--------------------------------------------------------------------\n### CIRCE1 subdirectory files\n\nAC_CONFIG_FILES([circe1/Makefile])\nAC_CONFIG_FILES([circe1/src/Makefile])\nAC_CONFIG_FILES([circe1/minuit/Makefile])\nAC_CONFIG_FILES([circe1/tools/Makefile])\nAC_CONFIG_FILES([circe1/share/Makefile])\nAC_CONFIG_FILES([circe1/share/data/Makefile])\nAC_CONFIG_FILES([circe1/share/doc/Makefile])\n\n### ONLY_CIRCE1_AND_FULL }}}\n\n### ONLY_CIRCE2_AND_FULL {{{\n###--------------------------------------------------------------------\n### CIRCE2 subdirectory files\n\nAC_CONFIG_FILES([circe2/Makefile])\nAC_CONFIG_FILES([circe2/src/Makefile])\nAC_CONFIG_FILES([circe2/share/Makefile])\nAC_CONFIG_FILES([circe2/share/doc/Makefile])\nAC_CONFIG_FILES([circe2/share/examples/Makefile])\nAC_CONFIG_FILES([circe2/share/data/Makefile])\nAC_CONFIG_FILES([circe2/share/tests/Makefile])\nAC_CONFIG_FILES([circe2/tests/Makefile])\n\n\nAC_CONFIG_FILES([circe2/tests/test_wrapper.sh], [chmod u+x circe2/tests/test_wrapper.sh])\nAC_CONFIG_FILES([circe2/tests/circe2_tool.sh], [chmod u+x circe2/tests/circe2_tool.sh])\nAC_CONFIG_FILES([circe2/tests/generate.sh], [chmod u+x circe2/tests/generate.sh])\n\n### ONLY_CIRCE2_AND_FULL }}}\n\n### ONLY_OMEGA_AND_FULL {{{\n###--------------------------------------------------------------------\n### OMEGA subdirectory files\n\nAC_CONFIG_FILES([omega/Makefile])\nAC_CONFIG_FILES([omega/bin/Makefile])\nAC_CONFIG_FILES([omega/lib/Makefile])\nAC_CONFIG_FILES([omega/models/Makefile])\nAC_CONFIG_FILES([omega/src/Makefile])\nAC_CONFIG_FILES([omega/share/Makefile])\nAC_CONFIG_FILES([omega/share/doc/Makefile])\nAC_CONFIG_FILES([omega/extensions/Makefile])\nAC_CONFIG_FILES([omega/extensions/people/Makefile])\nAC_CONFIG_FILES([omega/extensions/people/jr/Makefile])\nAC_CONFIG_FILES([omega/extensions/people/tho/Makefile])\nAC_CONFIG_FILES([omega/tests/Makefile])\nAC_CONFIG_FILES([omega/tests/UFO/Makefile])\nAC_CONFIG_FILES([omega/tests/UFO/SM/Makefile])\nAC_CONFIG_FILES([omega/tests/UFO/MSSM/Makefile])\nAC_CONFIG_FILES([omega/tools/Makefile])\nAC_CONFIG_FILES([omega/scripts/Makefile])\nAC_CONFIG_FILES([omega/scripts/omega-config], [chmod u+x omega/scripts/omega-config])\n\n\n# Copy config.mli to the build directory (otherwise ocamlc and/or\n# ocamlopt would create one on their own).\n\n###--------------------------------------------------------------------\nAC_CONFIG_FILES([omega/src/config.ml])\n\ncase \"$srcdir\" in\n .) ;;\n *) $MKDIR_P ./omega/src\n    rm -f ./omega/src/config.mli\n    cp $srcdir/omega/src/config.mli ./omega/src/config.mli 1>/dev/null 2>&1;;\nesac\n###--------------------------------------------------------------------\n\n### ONLY_OMEGA_AND_FULL }}}\n\n### ONLY_VAMP_AND_FULL {{{\n###--------------------------------------------------------------------\n### VAMP subdirectory files\n\nAC_CONFIG_FILES([vamp/Makefile])\nAC_CONFIG_FILES([vamp/src/Makefile])\nAC_CONFIG_FILES([vamp/share/Makefile])\nAC_CONFIG_FILES([vamp/share/doc/Makefile])\nAC_CONFIG_FILES([vamp/tests/Makefile])\n\n### ONLY_VAMP_AND_FULL }}}\n\n########################################################################\n###---------------------------------------------------------------------\n### Final output\n\nAC_OUTPUT()\n\n### ONLY_FULL {{{\n########################################################################\n###---------------------------------------------------------------------\n### Final output\n\nWO_SUMMARY()\n\n### ONLY_FULL }}}\n########################################################################\n",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/ltmain.sh": "#! /bin/sh\n## DO NOT EDIT - This file generated from ./build-aux/ltmain.in\n##               by inline-source v2014-01-03.01\n\n# libtool (GNU libtool) 2.4.6\n# Provide generalized library-building support services.\n# Written by Gordon Matzigkeit <gord@gnu.ai.mit.edu>, 1996\n\n# Copyright (C) 1996-2015 Free Software Foundation, Inc.\n# This is free software; see the source for copying conditions.  There is NO\n# warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\n# GNU Libtool is free software; you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation; either version 2 of the License, or\n# (at your option) any later version.\n#\n# As a special exception to the GNU General Public License,\n# if you distribute this file as part of a program or library that\n# is built using GNU Libtool, you may include this file under the\n# same distribution terms that you use for the rest of that program.\n#\n# GNU Libtool is distributed in the hope that it will be useful, but\n# WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\n\nPROGRAM=libtool\nPACKAGE=libtool\nVERSION=2.4.6\npackage_revision=2.4.6\n\n\n## ------ ##\n## Usage. ##\n## ------ ##\n\n# Run './libtool --help' for help with using this script from the\n# command line.\n\n\n## ------------------------------- ##\n## User overridable command paths. ##\n## ------------------------------- ##\n\n# After configure completes, it has a better idea of some of the\n# shell tools we need than the defaults used by the functions shared\n# with bootstrap, so set those here where they can still be over-\n# ridden by the user, but otherwise take precedence.\n\n: ${AUTOCONF=\"autoconf\"}\n: ${AUTOMAKE=\"automake\"}\n\n\n## -------------------------- ##\n## Source external libraries. ##\n## -------------------------- ##\n\n# Much of our low-level functionality needs to be sourced from external\n# libraries, which are installed to $pkgauxdir.\n\n# Set a version string for this script.\nscriptversion=2015-01-20.17; # UTC\n\n# General shell script boiler plate, and helper functions.\n# Written by Gary V. Vaughan, 2004\n\n# Copyright (C) 2004-2015 Free Software Foundation, Inc.\n# This is free software; see the source for copying conditions.  There is NO\n# warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\n# This program is free software; you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation; either version 3 of the License, or\n# (at your option) any later version.\n\n# As a special exception to the GNU General Public License, if you distribute\n# this file as part of a program or library that is built using GNU Libtool,\n# you may include this file under the same distribution terms that you use\n# for the rest of that program.\n\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNES FOR A PARTICULAR PURPOSE. See the GNU\n# General Public License for more details.\n\n# You should have received a copy of the GNU General Public License\n# along with this program. If not, see <http://www.gnu.org/licenses/>.\n\n# Please report bugs or propose patches to gary@gnu.org.\n\n\n## ------ ##\n## Usage. ##\n## ------ ##\n\n# Evaluate this file near the top of your script to gain access to\n# the functions and variables defined here:\n#\n#   . `echo \"$0\" | ${SED-sed} 's|[^/]*$||'`/build-aux/funclib.sh\n#\n# If you need to override any of the default environment variable\n# settings, do that before evaluating this file.\n\n\n## -------------------- ##\n## Shell normalisation. ##\n## -------------------- ##\n\n# Some shells need a little help to be as Bourne compatible as possible.\n# Before doing anything else, make sure all that help has been provided!\n\nDUALCASE=1; export DUALCASE # for MKS sh\nif test -n \"${ZSH_VERSION+set}\" && (emulate sh) >/dev/null 2>&1; then :\n  emulate sh\n  NULLCMD=:\n  # Pre-4.2 versions of Zsh do word splitting on ${1+\"$@\"}, which\n  # is contrary to our usage.  Disable this feature.\n  alias -g '${1+\"$@\"}'='\"$@\"'\n  setopt NO_GLOB_SUBST\nelse\n  case `(set -o) 2>/dev/null` in *posix*) set -o posix ;; esac\nfi\n\n# NLS nuisances: We save the old values in case they are required later.\n_G_user_locale=\n_G_safe_locale=\nfor _G_var in LANG LANGUAGE LC_ALL LC_CTYPE LC_COLLATE LC_MESSAGES\ndo\n  eval \"if test set = \\\"\\${$_G_var+set}\\\"; then\n          save_$_G_var=\\$$_G_var\n          $_G_var=C\n\t  export $_G_var\n\t  _G_user_locale=\\\"$_G_var=\\\\\\$save_\\$_G_var; \\$_G_user_locale\\\"\n\t  _G_safe_locale=\\\"$_G_var=C; \\$_G_safe_locale\\\"\n\tfi\"\ndone\n\n# CDPATH.\n(unset CDPATH) >/dev/null 2>&1 && unset CDPATH\n\n# Make sure IFS has a sensible default\nsp=' '\nnl='\n'\nIFS=\"$sp\t$nl\"\n\n# There are apparently some retarded systems that use ';' as a PATH separator!\nif test \"${PATH_SEPARATOR+set}\" != set; then\n  PATH_SEPARATOR=:\n  (PATH='/bin;/bin'; FPATH=$PATH; sh -c :) >/dev/null 2>&1 && {\n    (PATH='/bin:/bin'; FPATH=$PATH; sh -c :) >/dev/null 2>&1 ||\n      PATH_SEPARATOR=';'\n  }\nfi\n\n\n\n## ------------------------- ##\n## Locate command utilities. ##\n## ------------------------- ##\n\n\n# func_executable_p FILE\n# ----------------------\n# Check that FILE is an executable regular file.\nfunc_executable_p ()\n{\n    test -f \"$1\" && test -x \"$1\"\n}\n\n\n# func_path_progs PROGS_LIST CHECK_FUNC [PATH]\n# --------------------------------------------\n# Search for either a program that responds to --version with output\n# containing \"GNU\", or else returned by CHECK_FUNC otherwise, by\n# trying all the directories in PATH with each of the elements of\n# PROGS_LIST.\n#\n# CHECK_FUNC should accept the path to a candidate program, and\n# set $func_check_prog_result if it truncates its output less than\n# $_G_path_prog_max characters.\nfunc_path_progs ()\n{\n    _G_progs_list=$1\n    _G_check_func=$2\n    _G_PATH=${3-\"$PATH\"}\n\n    _G_path_prog_max=0\n    _G_path_prog_found=false\n    _G_save_IFS=$IFS; IFS=${PATH_SEPARATOR-:}\n    for _G_dir in $_G_PATH; do\n      IFS=$_G_save_IFS\n      test -z \"$_G_dir\" && _G_dir=.\n      for _G_prog_name in $_G_progs_list; do\n        for _exeext in '' .EXE; do\n          _G_path_prog=$_G_dir/$_G_prog_name$_exeext\n          func_executable_p \"$_G_path_prog\" || continue\n          case `\"$_G_path_prog\" --version 2>&1` in\n            *GNU*) func_path_progs_result=$_G_path_prog _G_path_prog_found=: ;;\n            *)     $_G_check_func $_G_path_prog\n\t\t   func_path_progs_result=$func_check_prog_result\n\t\t   ;;\n          esac\n          $_G_path_prog_found && break 3\n        done\n      done\n    done\n    IFS=$_G_save_IFS\n    test -z \"$func_path_progs_result\" && {\n      echo \"no acceptable sed could be found in \\$PATH\" >&2\n      exit 1\n    }\n}\n\n\n# We want to be able to use the functions in this file before configure\n# has figured out where the best binaries are kept, which means we have\n# to search for them ourselves - except when the results are already set\n# where we skip the searches.\n\n# Unless the user overrides by setting SED, search the path for either GNU\n# sed, or the sed that truncates its output the least.\ntest -z \"$SED\" && {\n  _G_sed_script=s/aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa/bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb/\n  for _G_i in 1 2 3 4 5 6 7; do\n    _G_sed_script=$_G_sed_script$nl$_G_sed_script\n  done\n  echo \"$_G_sed_script\" 2>/dev/null | sed 99q >conftest.sed\n  _G_sed_script=\n\n  func_check_prog_sed ()\n  {\n    _G_path_prog=$1\n\n    _G_count=0\n    printf 0123456789 >conftest.in\n    while :\n    do\n      cat conftest.in conftest.in >conftest.tmp\n      mv conftest.tmp conftest.in\n      cp conftest.in conftest.nl\n      echo '' >> conftest.nl\n      \"$_G_path_prog\" -f conftest.sed <conftest.nl >conftest.out 2>/dev/null || break\n      diff conftest.out conftest.nl >/dev/null 2>&1 || break\n      _G_count=`expr $_G_count + 1`\n      if test \"$_G_count\" -gt \"$_G_path_prog_max\"; then\n        # Best one so far, save it but keep looking for a better one\n        func_check_prog_result=$_G_path_prog\n        _G_path_prog_max=$_G_count\n      fi\n      # 10*(2^10) chars as input seems more than enough\n      test 10 -lt \"$_G_count\" && break\n    done\n    rm -f conftest.in conftest.tmp conftest.nl conftest.out\n  }\n\n  func_path_progs \"sed gsed\" func_check_prog_sed $PATH:/usr/xpg4/bin\n  rm -f conftest.sed\n  SED=$func_path_progs_result\n}\n\n\n# Unless the user overrides by setting GREP, search the path for either GNU\n# grep, or the grep that truncates its output the least.\ntest -z \"$GREP\" && {\n  func_check_prog_grep ()\n  {\n    _G_path_prog=$1\n\n    _G_count=0\n    _G_path_prog_max=0\n    printf 0123456789 >conftest.in\n    while :\n    do\n      cat conftest.in conftest.in >conftest.tmp\n      mv conftest.tmp conftest.in\n      cp conftest.in conftest.nl\n      echo 'GREP' >> conftest.nl\n      \"$_G_path_prog\" -e 'GREP$' -e '-(cannot match)-' <conftest.nl >conftest.out 2>/dev/null || break\n      diff conftest.out conftest.nl >/dev/null 2>&1 || break\n      _G_count=`expr $_G_count + 1`\n      if test \"$_G_count\" -gt \"$_G_path_prog_max\"; then\n        # Best one so far, save it but keep looking for a better one\n        func_check_prog_result=$_G_path_prog\n        _G_path_prog_max=$_G_count\n      fi\n      # 10*(2^10) chars as input seems more than enough\n      test 10 -lt \"$_G_count\" && break\n    done\n    rm -f conftest.in conftest.tmp conftest.nl conftest.out\n  }\n\n  func_path_progs \"grep ggrep\" func_check_prog_grep $PATH:/usr/xpg4/bin\n  GREP=$func_path_progs_result\n}\n\n\n## ------------------------------- ##\n## User overridable command paths. ##\n## ------------------------------- ##\n\n# All uppercase variable names are used for environment variables.  These\n# variables can be overridden by the user before calling a script that\n# uses them if a suitable command of that name is not already available\n# in the command search PATH.\n\n: ${CP=\"cp -f\"}\n: ${ECHO=\"printf %s\\n\"}\n: ${EGREP=\"$GREP -E\"}\n: ${FGREP=\"$GREP -F\"}\n: ${LN_S=\"ln -s\"}\n: ${MAKE=\"make\"}\n: ${MKDIR=\"mkdir\"}\n: ${MV=\"mv -f\"}\n: ${RM=\"rm -f\"}\n: ${SHELL=\"${CONFIG_SHELL-/bin/sh}\"}\n\n\n## -------------------- ##\n## Useful sed snippets. ##\n## -------------------- ##\n\nsed_dirname='s|/[^/]*$||'\nsed_basename='s|^.*/||'\n\n# Sed substitution that helps us do robust quoting.  It backslashifies\n# metacharacters that are still active within double-quoted strings.\nsed_quote_subst='s|\\([`\"$\\\\]\\)|\\\\\\1|g'\n\n# Same as above, but do not quote variable references.\nsed_double_quote_subst='s/\\([\"`\\\\]\\)/\\\\\\1/g'\n\n# Sed substitution that turns a string into a regex matching for the\n# string literally.\nsed_make_literal_regex='s|[].[^$\\\\*\\/]|\\\\&|g'\n\n# Sed substitution that converts a w32 file name or path\n# that contains forward slashes, into one that contains\n# (escaped) backslashes.  A very naive implementation.\nsed_naive_backslashify='s|\\\\\\\\*|\\\\|g;s|/|\\\\|g;s|\\\\|\\\\\\\\|g'\n\n# Re-'\\' parameter expansions in output of sed_double_quote_subst that\n# were '\\'-ed in input to the same.  If an odd number of '\\' preceded a\n# '$' in input to sed_double_quote_subst, that '$' was protected from\n# expansion.  Since each input '\\' is now two '\\'s, look for any number\n# of runs of four '\\'s followed by two '\\'s and then a '$'.  '\\' that '$'.\n_G_bs='\\\\'\n_G_bs2='\\\\\\\\'\n_G_bs4='\\\\\\\\\\\\\\\\'\n_G_dollar='\\$'\nsed_double_backslash=\"\\\n  s/$_G_bs4/&\\\\\n/g\n  s/^$_G_bs2$_G_dollar/$_G_bs&/\n  s/\\\\([^$_G_bs]\\\\)$_G_bs2$_G_dollar/\\\\1$_G_bs2$_G_bs$_G_dollar/g\n  s/\\n//g\"\n\n\n## ----------------- ##\n## Global variables. ##\n## ----------------- ##\n\n# Except for the global variables explicitly listed below, the following\n# functions in the '^func_' namespace, and the '^require_' namespace\n# variables initialised in the 'Resource management' section, sourcing\n# this file will not pollute your global namespace with anything\n# else. There's no portable way to scope variables in Bourne shell\n# though, so actually running these functions will sometimes place\n# results into a variable named after the function, and often use\n# temporary variables in the '^_G_' namespace. If you are careful to\n# avoid using those namespaces casually in your sourcing script, things\n# should continue to work as you expect. And, of course, you can freely\n# overwrite any of the functions or variables defined here before\n# calling anything to customize them.\n\nEXIT_SUCCESS=0\nEXIT_FAILURE=1\nEXIT_MISMATCH=63  # $? = 63 is used to indicate version mismatch to missing.\nEXIT_SKIP=77\t  # $? = 77 is used to indicate a skipped test to automake.\n\n# Allow overriding, eg assuming that you follow the convention of\n# putting '$debug_cmd' at the start of all your functions, you can get\n# bash to show function call trace with:\n#\n#    debug_cmd='eval echo \"${FUNCNAME[0]} $*\" >&2' bash your-script-name\ndebug_cmd=${debug_cmd-\":\"}\nexit_cmd=:\n\n# By convention, finish your script with:\n#\n#    exit $exit_status\n#\n# so that you can set exit_status to non-zero if you want to indicate\n# something went wrong during execution without actually bailing out at\n# the point of failure.\nexit_status=$EXIT_SUCCESS\n\n# Work around backward compatibility issue on IRIX 6.5. On IRIX 6.4+, sh\n# is ksh but when the shell is invoked as \"sh\" and the current value of\n# the _XPG environment variable is not equal to 1 (one), the special\n# positional parameter $0, within a function call, is the name of the\n# function.\nprogpath=$0\n\n# The name of this program.\nprogname=`$ECHO \"$progpath\" |$SED \"$sed_basename\"`\n\n# Make sure we have an absolute progpath for reexecution:\ncase $progpath in\n  [\\\\/]*|[A-Za-z]:\\\\*) ;;\n  *[\\\\/]*)\n     progdir=`$ECHO \"$progpath\" |$SED \"$sed_dirname\"`\n     progdir=`cd \"$progdir\" && pwd`\n     progpath=$progdir/$progname\n     ;;\n  *)\n     _G_IFS=$IFS\n     IFS=${PATH_SEPARATOR-:}\n     for progdir in $PATH; do\n       IFS=$_G_IFS\n       test -x \"$progdir/$progname\" && break\n     done\n     IFS=$_G_IFS\n     test -n \"$progdir\" || progdir=`pwd`\n     progpath=$progdir/$progname\n     ;;\nesac\n\n\n## ----------------- ##\n## Standard options. ##\n## ----------------- ##\n\n# The following options affect the operation of the functions defined\n# below, and should be set appropriately depending on run-time para-\n# meters passed on the command line.\n\nopt_dry_run=false\nopt_quiet=false\nopt_verbose=false\n\n# Categories 'all' and 'none' are always available.  Append any others\n# you will pass as the first argument to func_warning from your own\n# code.\nwarning_categories=\n\n# By default, display warnings according to 'opt_warning_types'.  Set\n# 'warning_func'  to ':' to elide all warnings, or func_fatal_error to\n# treat the next displayed warning as a fatal error.\nwarning_func=func_warn_and_continue\n\n# Set to 'all' to display all warnings, 'none' to suppress all\n# warnings, or a space delimited list of some subset of\n# 'warning_categories' to display only the listed warnings.\nopt_warning_types=all\n\n\n## -------------------- ##\n## Resource management. ##\n## -------------------- ##\n\n# This section contains definitions for functions that each ensure a\n# particular resource (a file, or a non-empty configuration variable for\n# example) is available, and if appropriate to extract default values\n# from pertinent package files. Call them using their associated\n# 'require_*' variable to ensure that they are executed, at most, once.\n#\n# It's entirely deliberate that calling these functions can set\n# variables that don't obey the namespace limitations obeyed by the rest\n# of this file, in order that that they be as useful as possible to\n# callers.\n\n\n# require_term_colors\n# -------------------\n# Allow display of bold text on terminals that support it.\nrequire_term_colors=func_require_term_colors\nfunc_require_term_colors ()\n{\n    $debug_cmd\n\n    test -t 1 && {\n      # COLORTERM and USE_ANSI_COLORS environment variables take\n      # precedence, because most terminfo databases neglect to describe\n      # whether color sequences are supported.\n      test -n \"${COLORTERM+set}\" && : ${USE_ANSI_COLORS=\"1\"}\n\n      if test 1 = \"$USE_ANSI_COLORS\"; then\n        # Standard ANSI escape sequences\n        tc_reset='\u001b[0m'\n        tc_bold='\u001b[1m';   tc_standout='\u001b[7m'\n        tc_red='\u001b[31m';   tc_green='\u001b[32m'\n        tc_blue='\u001b[34m';  tc_cyan='\u001b[36m'\n      else\n        # Otherwise trust the terminfo database after all.\n        test -n \"`tput sgr0 2>/dev/null`\" && {\n          tc_reset=`tput sgr0`\n          test -n \"`tput bold 2>/dev/null`\" && tc_bold=`tput bold`\n          tc_standout=$tc_bold\n          test -n \"`tput smso 2>/dev/null`\" && tc_standout=`tput smso`\n          test -n \"`tput setaf 1 2>/dev/null`\" && tc_red=`tput setaf 1`\n          test -n \"`tput setaf 2 2>/dev/null`\" && tc_green=`tput setaf 2`\n          test -n \"`tput setaf 4 2>/dev/null`\" && tc_blue=`tput setaf 4`\n          test -n \"`tput setaf 5 2>/dev/null`\" && tc_cyan=`tput setaf 5`\n        }\n      fi\n    }\n\n    require_term_colors=:\n}\n\n\n## ----------------- ##\n## Function library. ##\n## ----------------- ##\n\n# This section contains a variety of useful functions to call in your\n# scripts. Take note of the portable wrappers for features provided by\n# some modern shells, which will fall back to slower equivalents on\n# less featureful shells.\n\n\n# func_append VAR VALUE\n# ---------------------\n# Append VALUE onto the existing contents of VAR.\n\n  # We should try to minimise forks, especially on Windows where they are\n  # unreasonably slow, so skip the feature probes when bash or zsh are\n  # being used:\n  if test set = \"${BASH_VERSION+set}${ZSH_VERSION+set}\"; then\n    : ${_G_HAVE_ARITH_OP=\"yes\"}\n    : ${_G_HAVE_XSI_OPS=\"yes\"}\n    # The += operator was introduced in bash 3.1\n    case $BASH_VERSION in\n      [12].* | 3.0 | 3.0*) ;;\n      *)\n        : ${_G_HAVE_PLUSEQ_OP=\"yes\"}\n        ;;\n    esac\n  fi\n\n  # _G_HAVE_PLUSEQ_OP\n  # Can be empty, in which case the shell is probed, \"yes\" if += is\n  # useable or anything else if it does not work.\n  test -z \"$_G_HAVE_PLUSEQ_OP\" \\\n    && (eval 'x=a; x+=\" b\"; test \"a b\" = \"$x\"') 2>/dev/null \\\n    && _G_HAVE_PLUSEQ_OP=yes\n\nif test yes = \"$_G_HAVE_PLUSEQ_OP\"\nthen\n  # This is an XSI compatible shell, allowing a faster implementation...\n  eval 'func_append ()\n  {\n    $debug_cmd\n\n    eval \"$1+=\\$2\"\n  }'\nelse\n  # ...otherwise fall back to using expr, which is often a shell builtin.\n  func_append ()\n  {\n    $debug_cmd\n\n    eval \"$1=\\$$1\\$2\"\n  }\nfi\n\n\n# func_append_quoted VAR VALUE\n# ----------------------------\n# Quote VALUE and append to the end of shell variable VAR, separated\n# by a space.\nif test yes = \"$_G_HAVE_PLUSEQ_OP\"; then\n  eval 'func_append_quoted ()\n  {\n    $debug_cmd\n\n    func_quote_for_eval \"$2\"\n    eval \"$1+=\\\\ \\$func_quote_for_eval_result\"\n  }'\nelse\n  func_append_quoted ()\n  {\n    $debug_cmd\n\n    func_quote_for_eval \"$2\"\n    eval \"$1=\\$$1\\\\ \\$func_quote_for_eval_result\"\n  }\nfi\n\n\n# func_append_uniq VAR VALUE\n# --------------------------\n# Append unique VALUE onto the existing contents of VAR, assuming\n# entries are delimited by the first character of VALUE.  For example:\n#\n#   func_append_uniq options \" --another-option option-argument\"\n#\n# will only append to $options if \" --another-option option-argument \"\n# is not already present somewhere in $options already (note spaces at\n# each end implied by leading space in second argument).\nfunc_append_uniq ()\n{\n    $debug_cmd\n\n    eval _G_current_value='`$ECHO $'$1'`'\n    _G_delim=`expr \"$2\" : '\\(.\\)'`\n\n    case $_G_delim$_G_current_value$_G_delim in\n      *\"$2$_G_delim\"*) ;;\n      *) func_append \"$@\" ;;\n    esac\n}\n\n\n# func_arith TERM...\n# ------------------\n# Set func_arith_result to the result of evaluating TERMs.\n  test -z \"$_G_HAVE_ARITH_OP\" \\\n    && (eval 'test 2 = $(( 1 + 1 ))') 2>/dev/null \\\n    && _G_HAVE_ARITH_OP=yes\n\nif test yes = \"$_G_HAVE_ARITH_OP\"; then\n  eval 'func_arith ()\n  {\n    $debug_cmd\n\n    func_arith_result=$(( $* ))\n  }'\nelse\n  func_arith ()\n  {\n    $debug_cmd\n\n    func_arith_result=`expr \"$@\"`\n  }\nfi\n\n\n# func_basename FILE\n# ------------------\n# Set func_basename_result to FILE with everything up to and including\n# the last / stripped.\nif test yes = \"$_G_HAVE_XSI_OPS\"; then\n  # If this shell supports suffix pattern removal, then use it to avoid\n  # forking. Hide the definitions single quotes in case the shell chokes\n  # on unsupported syntax...\n  _b='func_basename_result=${1##*/}'\n  _d='case $1 in\n        */*) func_dirname_result=${1%/*}$2 ;;\n        *  ) func_dirname_result=$3        ;;\n      esac'\n\nelse\n  # ...otherwise fall back to using sed.\n  _b='func_basename_result=`$ECHO \"$1\" |$SED \"$sed_basename\"`'\n  _d='func_dirname_result=`$ECHO \"$1\"  |$SED \"$sed_dirname\"`\n      if test \"X$func_dirname_result\" = \"X$1\"; then\n        func_dirname_result=$3\n      else\n        func_append func_dirname_result \"$2\"\n      fi'\nfi\n\neval 'func_basename ()\n{\n    $debug_cmd\n\n    '\"$_b\"'\n}'\n\n\n# func_dirname FILE APPEND NONDIR_REPLACEMENT\n# -------------------------------------------\n# Compute the dirname of FILE.  If nonempty, add APPEND to the result,\n# otherwise set result to NONDIR_REPLACEMENT.\neval 'func_dirname ()\n{\n    $debug_cmd\n\n    '\"$_d\"'\n}'\n\n\n# func_dirname_and_basename FILE APPEND NONDIR_REPLACEMENT\n# --------------------------------------------------------\n# Perform func_basename and func_dirname in a single function\n# call:\n#   dirname:  Compute the dirname of FILE.  If nonempty,\n#             add APPEND to the result, otherwise set result\n#             to NONDIR_REPLACEMENT.\n#             value returned in \"$func_dirname_result\"\n#   basename: Compute filename of FILE.\n#             value retuned in \"$func_basename_result\"\n# For efficiency, we do not delegate to the functions above but instead\n# duplicate the functionality here.\neval 'func_dirname_and_basename ()\n{\n    $debug_cmd\n\n    '\"$_b\"'\n    '\"$_d\"'\n}'\n\n\n# func_echo ARG...\n# ----------------\n# Echo program name prefixed message.\nfunc_echo ()\n{\n    $debug_cmd\n\n    _G_message=$*\n\n    func_echo_IFS=$IFS\n    IFS=$nl\n    for _G_line in $_G_message; do\n      IFS=$func_echo_IFS\n      $ECHO \"$progname: $_G_line\"\n    done\n    IFS=$func_echo_IFS\n}\n\n\n# func_echo_all ARG...\n# --------------------\n# Invoke $ECHO with all args, space-separated.\nfunc_echo_all ()\n{\n    $ECHO \"$*\"\n}\n\n\n# func_echo_infix_1 INFIX ARG...\n# ------------------------------\n# Echo program name, followed by INFIX on the first line, with any\n# additional lines not showing INFIX.\nfunc_echo_infix_1 ()\n{\n    $debug_cmd\n\n    $require_term_colors\n\n    _G_infix=$1; shift\n    _G_indent=$_G_infix\n    _G_prefix=\"$progname: $_G_infix: \"\n    _G_message=$*\n\n    # Strip color escape sequences before counting printable length\n    for _G_tc in \"$tc_reset\" \"$tc_bold\" \"$tc_standout\" \"$tc_red\" \"$tc_green\" \"$tc_blue\" \"$tc_cyan\"\n    do\n      test -n \"$_G_tc\" && {\n        _G_esc_tc=`$ECHO \"$_G_tc\" | $SED \"$sed_make_literal_regex\"`\n        _G_indent=`$ECHO \"$_G_indent\" | $SED \"s|$_G_esc_tc||g\"`\n      }\n    done\n    _G_indent=\"$progname: \"`echo \"$_G_indent\" | $SED 's|.| |g'`\"  \" ## exclude from sc_prohibit_nested_quotes\n\n    func_echo_infix_1_IFS=$IFS\n    IFS=$nl\n    for _G_line in $_G_message; do\n      IFS=$func_echo_infix_1_IFS\n      $ECHO \"$_G_prefix$tc_bold$_G_line$tc_reset\" >&2\n      _G_prefix=$_G_indent\n    done\n    IFS=$func_echo_infix_1_IFS\n}\n\n\n# func_error ARG...\n# -----------------\n# Echo program name prefixed message to standard error.\nfunc_error ()\n{\n    $debug_cmd\n\n    $require_term_colors\n\n    func_echo_infix_1 \"  $tc_standout${tc_red}error$tc_reset\" \"$*\" >&2\n}\n\n\n# func_fatal_error ARG...\n# -----------------------\n# Echo program name prefixed message to standard error, and exit.\nfunc_fatal_error ()\n{\n    $debug_cmd\n\n    func_error \"$*\"\n    exit $EXIT_FAILURE\n}\n\n\n# func_grep EXPRESSION FILENAME\n# -----------------------------\n# Check whether EXPRESSION matches any line of FILENAME, without output.\nfunc_grep ()\n{\n    $debug_cmd\n\n    $GREP \"$1\" \"$2\" >/dev/null 2>&1\n}\n\n\n# func_len STRING\n# ---------------\n# Set func_len_result to the length of STRING. STRING may not\n# start with a hyphen.\n  test -z \"$_G_HAVE_XSI_OPS\" \\\n    && (eval 'x=a/b/c;\n      test 5aa/bb/cc = \"${#x}${x%%/*}${x%/*}${x#*/}${x##*/}\"') 2>/dev/null \\\n    && _G_HAVE_XSI_OPS=yes\n\nif test yes = \"$_G_HAVE_XSI_OPS\"; then\n  eval 'func_len ()\n  {\n    $debug_cmd\n\n    func_len_result=${#1}\n  }'\nelse\n  func_len ()\n  {\n    $debug_cmd\n\n    func_len_result=`expr \"$1\" : \".*\" 2>/dev/null || echo $max_cmd_len`\n  }\nfi\n\n\n# func_mkdir_p DIRECTORY-PATH\n# ---------------------------\n# Make sure the entire path to DIRECTORY-PATH is available.\nfunc_mkdir_p ()\n{\n    $debug_cmd\n\n    _G_directory_path=$1\n    _G_dir_list=\n\n    if test -n \"$_G_directory_path\" && test : != \"$opt_dry_run\"; then\n\n      # Protect directory names starting with '-'\n      case $_G_directory_path in\n        -*) _G_directory_path=./$_G_directory_path ;;\n      esac\n\n      # While some portion of DIR does not yet exist...\n      while test ! -d \"$_G_directory_path\"; do\n        # ...make a list in topmost first order.  Use a colon delimited\n\t# list incase some portion of path contains whitespace.\n        _G_dir_list=$_G_directory_path:$_G_dir_list\n\n        # If the last portion added has no slash in it, the list is done\n        case $_G_directory_path in */*) ;; *) break ;; esac\n\n        # ...otherwise throw away the child directory and loop\n        _G_directory_path=`$ECHO \"$_G_directory_path\" | $SED -e \"$sed_dirname\"`\n      done\n      _G_dir_list=`$ECHO \"$_G_dir_list\" | $SED 's|:*$||'`\n\n      func_mkdir_p_IFS=$IFS; IFS=:\n      for _G_dir in $_G_dir_list; do\n\tIFS=$func_mkdir_p_IFS\n        # mkdir can fail with a 'File exist' error if two processes\n        # try to create one of the directories concurrently.  Don't\n        # stop in that case!\n        $MKDIR \"$_G_dir\" 2>/dev/null || :\n      done\n      IFS=$func_mkdir_p_IFS\n\n      # Bail out if we (or some other process) failed to create a directory.\n      test -d \"$_G_directory_path\" || \\\n        func_fatal_error \"Failed to create '$1'\"\n    fi\n}\n\n\n# func_mktempdir [BASENAME]\n# -------------------------\n# Make a temporary directory that won't clash with other running\n# libtool processes, and avoids race conditions if possible.  If\n# given, BASENAME is the basename for that directory.\nfunc_mktempdir ()\n{\n    $debug_cmd\n\n    _G_template=${TMPDIR-/tmp}/${1-$progname}\n\n    if test : = \"$opt_dry_run\"; then\n      # Return a directory name, but don't create it in dry-run mode\n      _G_tmpdir=$_G_template-$$\n    else\n\n      # If mktemp works, use that first and foremost\n      _G_tmpdir=`mktemp -d \"$_G_template-XXXXXXXX\" 2>/dev/null`\n\n      if test ! -d \"$_G_tmpdir\"; then\n        # Failing that, at least try and use $RANDOM to avoid a race\n        _G_tmpdir=$_G_template-${RANDOM-0}$$\n\n        func_mktempdir_umask=`umask`\n        umask 0077\n        $MKDIR \"$_G_tmpdir\"\n        umask $func_mktempdir_umask\n      fi\n\n      # If we're not in dry-run mode, bomb out on failure\n      test -d \"$_G_tmpdir\" || \\\n        func_fatal_error \"cannot create temporary directory '$_G_tmpdir'\"\n    fi\n\n    $ECHO \"$_G_tmpdir\"\n}\n\n\n# func_normal_abspath PATH\n# ------------------------\n# Remove doubled-up and trailing slashes, \".\" path components,\n# and cancel out any \"..\" path components in PATH after making\n# it an absolute path.\nfunc_normal_abspath ()\n{\n    $debug_cmd\n\n    # These SED scripts presuppose an absolute path with a trailing slash.\n    _G_pathcar='s|^/\\([^/]*\\).*$|\\1|'\n    _G_pathcdr='s|^/[^/]*||'\n    _G_removedotparts=':dotsl\n\t\ts|/\\./|/|g\n\t\tt dotsl\n\t\ts|/\\.$|/|'\n    _G_collapseslashes='s|/\\{1,\\}|/|g'\n    _G_finalslash='s|/*$|/|'\n\n    # Start from root dir and reassemble the path.\n    func_normal_abspath_result=\n    func_normal_abspath_tpath=$1\n    func_normal_abspath_altnamespace=\n    case $func_normal_abspath_tpath in\n      \"\")\n        # Empty path, that just means $cwd.\n        func_stripname '' '/' \"`pwd`\"\n        func_normal_abspath_result=$func_stripname_result\n        return\n        ;;\n      # The next three entries are used to spot a run of precisely\n      # two leading slashes without using negated character classes;\n      # we take advantage of case's first-match behaviour.\n      ///*)\n        # Unusual form of absolute path, do nothing.\n        ;;\n      //*)\n        # Not necessarily an ordinary path; POSIX reserves leading '//'\n        # and for example Cygwin uses it to access remote file shares\n        # over CIFS/SMB, so we conserve a leading double slash if found.\n        func_normal_abspath_altnamespace=/\n        ;;\n      /*)\n        # Absolute path, do nothing.\n        ;;\n      *)\n        # Relative path, prepend $cwd.\n        func_normal_abspath_tpath=`pwd`/$func_normal_abspath_tpath\n        ;;\n    esac\n\n    # Cancel out all the simple stuff to save iterations.  We also want\n    # the path to end with a slash for ease of parsing, so make sure\n    # there is one (and only one) here.\n    func_normal_abspath_tpath=`$ECHO \"$func_normal_abspath_tpath\" | $SED \\\n          -e \"$_G_removedotparts\" -e \"$_G_collapseslashes\" -e \"$_G_finalslash\"`\n    while :; do\n      # Processed it all yet?\n      if test / = \"$func_normal_abspath_tpath\"; then\n        # If we ascended to the root using \"..\" the result may be empty now.\n        if test -z \"$func_normal_abspath_result\"; then\n          func_normal_abspath_result=/\n        fi\n        break\n      fi\n      func_normal_abspath_tcomponent=`$ECHO \"$func_normal_abspath_tpath\" | $SED \\\n          -e \"$_G_pathcar\"`\n      func_normal_abspath_tpath=`$ECHO \"$func_normal_abspath_tpath\" | $SED \\\n          -e \"$_G_pathcdr\"`\n      # Figure out what to do with it\n      case $func_normal_abspath_tcomponent in\n        \"\")\n          # Trailing empty path component, ignore it.\n          ;;\n        ..)\n          # Parent dir; strip last assembled component from result.\n          func_dirname \"$func_normal_abspath_result\"\n          func_normal_abspath_result=$func_dirname_result\n          ;;\n        *)\n          # Actual path component, append it.\n          func_append func_normal_abspath_result \"/$func_normal_abspath_tcomponent\"\n          ;;\n      esac\n    done\n    # Restore leading double-slash if one was found on entry.\n    func_normal_abspath_result=$func_normal_abspath_altnamespace$func_normal_abspath_result\n}\n\n\n# func_notquiet ARG...\n# --------------------\n# Echo program name prefixed message only when not in quiet mode.\nfunc_notquiet ()\n{\n    $debug_cmd\n\n    $opt_quiet || func_echo ${1+\"$@\"}\n\n    # A bug in bash halts the script if the last line of a function\n    # fails when set -e is in force, so we need another command to\n    # work around that:\n    :\n}\n\n\n# func_relative_path SRCDIR DSTDIR\n# --------------------------------\n# Set func_relative_path_result to the relative path from SRCDIR to DSTDIR.\nfunc_relative_path ()\n{\n    $debug_cmd\n\n    func_relative_path_result=\n    func_normal_abspath \"$1\"\n    func_relative_path_tlibdir=$func_normal_abspath_result\n    func_normal_abspath \"$2\"\n    func_relative_path_tbindir=$func_normal_abspath_result\n\n    # Ascend the tree starting from libdir\n    while :; do\n      # check if we have found a prefix of bindir\n      case $func_relative_path_tbindir in\n        $func_relative_path_tlibdir)\n          # found an exact match\n          func_relative_path_tcancelled=\n          break\n          ;;\n        $func_relative_path_tlibdir*)\n          # found a matching prefix\n          func_stripname \"$func_relative_path_tlibdir\" '' \"$func_relative_path_tbindir\"\n          func_relative_path_tcancelled=$func_stripname_result\n          if test -z \"$func_relative_path_result\"; then\n            func_relative_path_result=.\n          fi\n          break\n          ;;\n        *)\n          func_dirname $func_relative_path_tlibdir\n          func_relative_path_tlibdir=$func_dirname_result\n          if test -z \"$func_relative_path_tlibdir\"; then\n            # Have to descend all the way to the root!\n            func_relative_path_result=../$func_relative_path_result\n            func_relative_path_tcancelled=$func_relative_path_tbindir\n            break\n          fi\n          func_relative_path_result=../$func_relative_path_result\n          ;;\n      esac\n    done\n\n    # Now calculate path; take care to avoid doubling-up slashes.\n    func_stripname '' '/' \"$func_relative_path_result\"\n    func_relative_path_result=$func_stripname_result\n    func_stripname '/' '/' \"$func_relative_path_tcancelled\"\n    if test -n \"$func_stripname_result\"; then\n      func_append func_relative_path_result \"/$func_stripname_result\"\n    fi\n\n    # Normalisation. If bindir is libdir, return '.' else relative path.\n    if test -n \"$func_relative_path_result\"; then\n      func_stripname './' '' \"$func_relative_path_result\"\n      func_relative_path_result=$func_stripname_result\n    fi\n\n    test -n \"$func_relative_path_result\" || func_relative_path_result=.\n\n    :\n}\n\n\n# func_quote_for_eval ARG...\n# --------------------------\n# Aesthetically quote ARGs to be evaled later.\n# This function returns two values:\n#   i) func_quote_for_eval_result\n#      double-quoted, suitable for a subsequent eval\n#  ii) func_quote_for_eval_unquoted_result\n#      has all characters that are still active within double\n#      quotes backslashified.\nfunc_quote_for_eval ()\n{\n    $debug_cmd\n\n    func_quote_for_eval_unquoted_result=\n    func_quote_for_eval_result=\n    while test 0 -lt $#; do\n      case $1 in\n        *[\\\\\\`\\\"\\$]*)\n\t  _G_unquoted_arg=`printf '%s\\n' \"$1\" |$SED \"$sed_quote_subst\"` ;;\n        *)\n          _G_unquoted_arg=$1 ;;\n      esac\n      if test -n \"$func_quote_for_eval_unquoted_result\"; then\n\tfunc_append func_quote_for_eval_unquoted_result \" $_G_unquoted_arg\"\n      else\n        func_append func_quote_for_eval_unquoted_result \"$_G_unquoted_arg\"\n      fi\n\n      case $_G_unquoted_arg in\n        # Double-quote args containing shell metacharacters to delay\n        # word splitting, command substitution and variable expansion\n        # for a subsequent eval.\n        # Many Bourne shells cannot handle close brackets correctly\n        # in scan sets, so we specify it separately.\n        *[\\[\\~\\#\\^\\&\\*\\(\\)\\{\\}\\|\\;\\<\\>\\?\\'\\ \\\t]*|*]*|\"\")\n          _G_quoted_arg=\\\"$_G_unquoted_arg\\\"\n          ;;\n        *)\n          _G_quoted_arg=$_G_unquoted_arg\n\t  ;;\n      esac\n\n      if test -n \"$func_quote_for_eval_result\"; then\n\tfunc_append func_quote_for_eval_result \" $_G_quoted_arg\"\n      else\n        func_append func_quote_for_eval_result \"$_G_quoted_arg\"\n      fi\n      shift\n    done\n}\n\n\n# func_quote_for_expand ARG\n# -------------------------\n# Aesthetically quote ARG to be evaled later; same as above,\n# but do not quote variable references.\nfunc_quote_for_expand ()\n{\n    $debug_cmd\n\n    case $1 in\n      *[\\\\\\`\\\"]*)\n\t_G_arg=`$ECHO \"$1\" | $SED \\\n\t    -e \"$sed_double_quote_subst\" -e \"$sed_double_backslash\"` ;;\n      *)\n        _G_arg=$1 ;;\n    esac\n\n    case $_G_arg in\n      # Double-quote args containing shell metacharacters to delay\n      # word splitting and command substitution for a subsequent eval.\n      # Many Bourne shells cannot handle close brackets correctly\n      # in scan sets, so we specify it separately.\n      *[\\[\\~\\#\\^\\&\\*\\(\\)\\{\\}\\|\\;\\<\\>\\?\\'\\ \\\t]*|*]*|\"\")\n        _G_arg=\\\"$_G_arg\\\"\n        ;;\n    esac\n\n    func_quote_for_expand_result=$_G_arg\n}\n\n\n# func_stripname PREFIX SUFFIX NAME\n# ---------------------------------\n# strip PREFIX and SUFFIX from NAME, and store in func_stripname_result.\n# PREFIX and SUFFIX must not contain globbing or regex special\n# characters, hashes, percent signs, but SUFFIX may contain a leading\n# dot (in which case that matches only a dot).\nif test yes = \"$_G_HAVE_XSI_OPS\"; then\n  eval 'func_stripname ()\n  {\n    $debug_cmd\n\n    # pdksh 5.2.14 does not do ${X%$Y} correctly if both X and Y are\n    # positional parameters, so assign one to ordinary variable first.\n    func_stripname_result=$3\n    func_stripname_result=${func_stripname_result#\"$1\"}\n    func_stripname_result=${func_stripname_result%\"$2\"}\n  }'\nelse\n  func_stripname ()\n  {\n    $debug_cmd\n\n    case $2 in\n      .*) func_stripname_result=`$ECHO \"$3\" | $SED -e \"s%^$1%%\" -e \"s%\\\\\\\\$2\\$%%\"`;;\n      *)  func_stripname_result=`$ECHO \"$3\" | $SED -e \"s%^$1%%\" -e \"s%$2\\$%%\"`;;\n    esac\n  }\nfi\n\n\n# func_show_eval CMD [FAIL_EXP]\n# -----------------------------\n# Unless opt_quiet is true, then output CMD.  Then, if opt_dryrun is\n# not true, evaluate CMD.  If the evaluation of CMD fails, and FAIL_EXP\n# is given, then evaluate it.\nfunc_show_eval ()\n{\n    $debug_cmd\n\n    _G_cmd=$1\n    _G_fail_exp=${2-':'}\n\n    func_quote_for_expand \"$_G_cmd\"\n    eval \"func_notquiet $func_quote_for_expand_result\"\n\n    $opt_dry_run || {\n      eval \"$_G_cmd\"\n      _G_status=$?\n      if test 0 -ne \"$_G_status\"; then\n\teval \"(exit $_G_status); $_G_fail_exp\"\n      fi\n    }\n}\n\n\n# func_show_eval_locale CMD [FAIL_EXP]\n# ------------------------------------\n# Unless opt_quiet is true, then output CMD.  Then, if opt_dryrun is\n# not true, evaluate CMD.  If the evaluation of CMD fails, and FAIL_EXP\n# is given, then evaluate it.  Use the saved locale for evaluation.\nfunc_show_eval_locale ()\n{\n    $debug_cmd\n\n    _G_cmd=$1\n    _G_fail_exp=${2-':'}\n\n    $opt_quiet || {\n      func_quote_for_expand \"$_G_cmd\"\n      eval \"func_echo $func_quote_for_expand_result\"\n    }\n\n    $opt_dry_run || {\n      eval \"$_G_user_locale\n\t    $_G_cmd\"\n      _G_status=$?\n      eval \"$_G_safe_locale\"\n      if test 0 -ne \"$_G_status\"; then\n\teval \"(exit $_G_status); $_G_fail_exp\"\n      fi\n    }\n}\n\n\n# func_tr_sh\n# ----------\n# Turn $1 into a string suitable for a shell variable name.\n# Result is stored in $func_tr_sh_result.  All characters\n# not in the set a-zA-Z0-9_ are replaced with '_'. Further,\n# if $1 begins with a digit, a '_' is prepended as well.\nfunc_tr_sh ()\n{\n    $debug_cmd\n\n    case $1 in\n    [0-9]* | *[!a-zA-Z0-9_]*)\n      func_tr_sh_result=`$ECHO \"$1\" | $SED -e 's/^\\([0-9]\\)/_\\1/' -e 's/[^a-zA-Z0-9_]/_/g'`\n      ;;\n    * )\n      func_tr_sh_result=$1\n      ;;\n    esac\n}\n\n\n# func_verbose ARG...\n# -------------------\n# Echo program name prefixed message in verbose mode only.\nfunc_verbose ()\n{\n    $debug_cmd\n\n    $opt_verbose && func_echo \"$*\"\n\n    :\n}\n\n\n# func_warn_and_continue ARG...\n# -----------------------------\n# Echo program name prefixed warning message to standard error.\nfunc_warn_and_continue ()\n{\n    $debug_cmd\n\n    $require_term_colors\n\n    func_echo_infix_1 \"${tc_red}warning$tc_reset\" \"$*\" >&2\n}\n\n\n# func_warning CATEGORY ARG...\n# ----------------------------\n# Echo program name prefixed warning message to standard error. Warning\n# messages can be filtered according to CATEGORY, where this function\n# elides messages where CATEGORY is not listed in the global variable\n# 'opt_warning_types'.\nfunc_warning ()\n{\n    $debug_cmd\n\n    # CATEGORY must be in the warning_categories list!\n    case \" $warning_categories \" in\n      *\" $1 \"*) ;;\n      *) func_internal_error \"invalid warning category '$1'\" ;;\n    esac\n\n    _G_category=$1\n    shift\n\n    case \" $opt_warning_types \" in\n      *\" $_G_category \"*) $warning_func ${1+\"$@\"} ;;\n    esac\n}\n\n\n# func_sort_ver VER1 VER2\n# -----------------------\n# 'sort -V' is not generally available.\n# Note this deviates from the version comparison in automake\n# in that it treats 1.5 < 1.5.0, and treats 1.4.4a < 1.4-p3a\n# but this should suffice as we won't be specifying old\n# version formats or redundant trailing .0 in bootstrap.conf.\n# If we did want full compatibility then we should probably\n# use m4_version_compare from autoconf.\nfunc_sort_ver ()\n{\n    $debug_cmd\n\n    printf '%s\\n%s\\n' \"$1\" \"$2\" \\\n      | sort -t. -k 1,1n -k 2,2n -k 3,3n -k 4,4n -k 5,5n -k 6,6n -k 7,7n -k 8,8n -k 9,9n\n}\n\n# func_lt_ver PREV CURR\n# ---------------------\n# Return true if PREV and CURR are in the correct order according to\n# func_sort_ver, otherwise false.  Use it like this:\n#\n#  func_lt_ver \"$prev_ver\" \"$proposed_ver\" || func_fatal_error \"...\"\nfunc_lt_ver ()\n{\n    $debug_cmd\n\n    test \"x$1\" = x`func_sort_ver \"$1\" \"$2\" | $SED 1q`\n}\n\n\n# Local variables:\n# mode: shell-script\n# sh-indentation: 2\n# eval: (add-hook 'before-save-hook 'time-stamp)\n# time-stamp-pattern: \"10/scriptversion=%:y-%02m-%02d.%02H; # UTC\"\n# time-stamp-time-zone: \"UTC\"\n# End:\n#! /bin/sh\n\n# Set a version string for this script.\nscriptversion=2014-01-07.03; # UTC\n\n# A portable, pluggable option parser for Bourne shell.\n# Written by Gary V. Vaughan, 2010\n\n# Copyright (C) 2010-2015 Free Software Foundation, Inc.\n# This is free software; see the source for copying conditions.  There is NO\n# warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n\n# You should have received a copy of the GNU General Public License\n# along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\n# Please report bugs or propose patches to gary@gnu.org.\n\n\n## ------ ##\n## Usage. ##\n## ------ ##\n\n# This file is a library for parsing options in your shell scripts along\n# with assorted other useful supporting features that you can make use\n# of too.\n#\n# For the simplest scripts you might need only:\n#\n#   #!/bin/sh\n#   . relative/path/to/funclib.sh\n#   . relative/path/to/options-parser\n#   scriptversion=1.0\n#   func_options ${1+\"$@\"}\n#   eval set dummy \"$func_options_result\"; shift\n#   ...rest of your script...\n#\n# In order for the '--version' option to work, you will need to have a\n# suitably formatted comment like the one at the top of this file\n# starting with '# Written by ' and ending with '# warranty; '.\n#\n# For '-h' and '--help' to work, you will also need a one line\n# description of your script's purpose in a comment directly above the\n# '# Written by ' line, like the one at the top of this file.\n#\n# The default options also support '--debug', which will turn on shell\n# execution tracing (see the comment above debug_cmd below for another\n# use), and '--verbose' and the func_verbose function to allow your script\n# to display verbose messages only when your user has specified\n# '--verbose'.\n#\n# After sourcing this file, you can plug processing for additional\n# options by amending the variables from the 'Configuration' section\n# below, and following the instructions in the 'Option parsing'\n# section further down.\n\n## -------------- ##\n## Configuration. ##\n## -------------- ##\n\n# You should override these variables in your script after sourcing this\n# file so that they reflect the customisations you have added to the\n# option parser.\n\n# The usage line for option parsing errors and the start of '-h' and\n# '--help' output messages. You can embed shell variables for delayed\n# expansion at the time the message is displayed, but you will need to\n# quote other shell meta-characters carefully to prevent them being\n# expanded when the contents are evaled.\nusage='$progpath [OPTION]...'\n\n# Short help message in response to '-h' and '--help'.  Add to this or\n# override it after sourcing this library to reflect the full set of\n# options your script accepts.\nusage_message=\"\\\n       --debug        enable verbose shell tracing\n   -W, --warnings=CATEGORY\n                      report the warnings falling in CATEGORY [all]\n   -v, --verbose      verbosely report processing\n       --version      print version information and exit\n   -h, --help         print short or long help message and exit\n\"\n\n# Additional text appended to 'usage_message' in response to '--help'.\nlong_help_message=\"\nWarning categories include:\n       'all'          show all warnings\n       'none'         turn off all the warnings\n       'error'        warnings are treated as fatal errors\"\n\n# Help message printed before fatal option parsing errors.\nfatal_help=\"Try '\\$progname --help' for more information.\"\n\n\n\n## ------------------------- ##\n## Hook function management. ##\n## ------------------------- ##\n\n# This section contains functions for adding, removing, and running hooks\n# to the main code.  A hook is just a named list of of function, that can\n# be run in order later on.\n\n# func_hookable FUNC_NAME\n# -----------------------\n# Declare that FUNC_NAME will run hooks added with\n# 'func_add_hook FUNC_NAME ...'.\nfunc_hookable ()\n{\n    $debug_cmd\n\n    func_append hookable_fns \" $1\"\n}\n\n\n# func_add_hook FUNC_NAME HOOK_FUNC\n# ---------------------------------\n# Request that FUNC_NAME call HOOK_FUNC before it returns.  FUNC_NAME must\n# first have been declared \"hookable\" by a call to 'func_hookable'.\nfunc_add_hook ()\n{\n    $debug_cmd\n\n    case \" $hookable_fns \" in\n      *\" $1 \"*) ;;\n      *) func_fatal_error \"'$1' does not accept hook functions.\" ;;\n    esac\n\n    eval func_append ${1}_hooks '\" $2\"'\n}\n\n\n# func_remove_hook FUNC_NAME HOOK_FUNC\n# ------------------------------------\n# Remove HOOK_FUNC from the list of functions called by FUNC_NAME.\nfunc_remove_hook ()\n{\n    $debug_cmd\n\n    eval ${1}_hooks='`$ECHO \"\\$'$1'_hooks\" |$SED \"s| '$2'||\"`'\n}\n\n\n# func_run_hooks FUNC_NAME [ARG]...\n# ---------------------------------\n# Run all hook functions registered to FUNC_NAME.\n# It is assumed that the list of hook functions contains nothing more\n# than a whitespace-delimited list of legal shell function names, and\n# no effort is wasted trying to catch shell meta-characters or preserve\n# whitespace.\nfunc_run_hooks ()\n{\n    $debug_cmd\n\n    case \" $hookable_fns \" in\n      *\" $1 \"*) ;;\n      *) func_fatal_error \"'$1' does not support hook funcions.n\" ;;\n    esac\n\n    eval _G_hook_fns=\\$$1_hooks; shift\n\n    for _G_hook in $_G_hook_fns; do\n      eval $_G_hook '\"$@\"'\n\n      # store returned options list back into positional\n      # parameters for next 'cmd' execution.\n      eval _G_hook_result=\\$${_G_hook}_result\n      eval set dummy \"$_G_hook_result\"; shift\n    done\n\n    func_quote_for_eval ${1+\"$@\"}\n    func_run_hooks_result=$func_quote_for_eval_result\n}\n\n\n\n## --------------- ##\n## Option parsing. ##\n## --------------- ##\n\n# In order to add your own option parsing hooks, you must accept the\n# full positional parameter list in your hook function, remove any\n# options that you action, and then pass back the remaining unprocessed\n# options in '<hooked_function_name>_result', escaped suitably for\n# 'eval'.  Like this:\n#\n#    my_options_prep ()\n#    {\n#        $debug_cmd\n#\n#        # Extend the existing usage message.\n#        usage_message=$usage_message'\n#      -s, --silent       don'\\''t print informational messages\n#    '\n#\n#        func_quote_for_eval ${1+\"$@\"}\n#        my_options_prep_result=$func_quote_for_eval_result\n#    }\n#    func_add_hook func_options_prep my_options_prep\n#\n#\n#    my_silent_option ()\n#    {\n#        $debug_cmd\n#\n#        # Note that for efficiency, we parse as many options as we can\n#        # recognise in a loop before passing the remainder back to the\n#        # caller on the first unrecognised argument we encounter.\n#        while test $# -gt 0; do\n#          opt=$1; shift\n#          case $opt in\n#            --silent|-s) opt_silent=: ;;\n#            # Separate non-argument short options:\n#            -s*)         func_split_short_opt \"$_G_opt\"\n#                         set dummy \"$func_split_short_opt_name\" \\\n#                             \"-$func_split_short_opt_arg\" ${1+\"$@\"}\n#                         shift\n#                         ;;\n#            *)            set dummy \"$_G_opt\" \"$*\"; shift; break ;;\n#          esac\n#        done\n#\n#        func_quote_for_eval ${1+\"$@\"}\n#        my_silent_option_result=$func_quote_for_eval_result\n#    }\n#    func_add_hook func_parse_options my_silent_option\n#\n#\n#    my_option_validation ()\n#    {\n#        $debug_cmd\n#\n#        $opt_silent && $opt_verbose && func_fatal_help \"\\\n#    '--silent' and '--verbose' options are mutually exclusive.\"\n#\n#        func_quote_for_eval ${1+\"$@\"}\n#        my_option_validation_result=$func_quote_for_eval_result\n#    }\n#    func_add_hook func_validate_options my_option_validation\n#\n# You'll alse need to manually amend $usage_message to reflect the extra\n# options you parse.  It's preferable to append if you can, so that\n# multiple option parsing hooks can be added safely.\n\n\n# func_options [ARG]...\n# ---------------------\n# All the functions called inside func_options are hookable. See the\n# individual implementations for details.\nfunc_hookable func_options\nfunc_options ()\n{\n    $debug_cmd\n\n    func_options_prep ${1+\"$@\"}\n    eval func_parse_options \\\n        ${func_options_prep_result+\"$func_options_prep_result\"}\n    eval func_validate_options \\\n        ${func_parse_options_result+\"$func_parse_options_result\"}\n\n    eval func_run_hooks func_options \\\n        ${func_validate_options_result+\"$func_validate_options_result\"}\n\n    # save modified positional parameters for caller\n    func_options_result=$func_run_hooks_result\n}\n\n\n# func_options_prep [ARG]...\n# --------------------------\n# All initialisations required before starting the option parse loop.\n# Note that when calling hook functions, we pass through the list of\n# positional parameters.  If a hook function modifies that list, and\n# needs to propogate that back to rest of this script, then the complete\n# modified list must be put in 'func_run_hooks_result' before\n# returning.\nfunc_hookable func_options_prep\nfunc_options_prep ()\n{\n    $debug_cmd\n\n    # Option defaults:\n    opt_verbose=false\n    opt_warning_types=\n\n    func_run_hooks func_options_prep ${1+\"$@\"}\n\n    # save modified positional parameters for caller\n    func_options_prep_result=$func_run_hooks_result\n}\n\n\n# func_parse_options [ARG]...\n# ---------------------------\n# The main option parsing loop.\nfunc_hookable func_parse_options\nfunc_parse_options ()\n{\n    $debug_cmd\n\n    func_parse_options_result=\n\n    # this just eases exit handling\n    while test $# -gt 0; do\n      # Defer to hook functions for initial option parsing, so they\n      # get priority in the event of reusing an option name.\n      func_run_hooks func_parse_options ${1+\"$@\"}\n\n      # Adjust func_parse_options positional parameters to match\n      eval set dummy \"$func_run_hooks_result\"; shift\n\n      # Break out of the loop if we already parsed every option.\n      test $# -gt 0 || break\n\n      _G_opt=$1\n      shift\n      case $_G_opt in\n        --debug|-x)   debug_cmd='set -x'\n                      func_echo \"enabling shell trace mode\"\n                      $debug_cmd\n                      ;;\n\n        --no-warnings|--no-warning|--no-warn)\n                      set dummy --warnings none ${1+\"$@\"}\n                      shift\n\t\t      ;;\n\n        --warnings|--warning|-W)\n                      test $# = 0 && func_missing_arg $_G_opt && break\n                      case \" $warning_categories $1\" in\n                        *\" $1 \"*)\n                          # trailing space prevents matching last $1 above\n                          func_append_uniq opt_warning_types \" $1\"\n                          ;;\n                        *all)\n                          opt_warning_types=$warning_categories\n                          ;;\n                        *none)\n                          opt_warning_types=none\n                          warning_func=:\n                          ;;\n                        *error)\n                          opt_warning_types=$warning_categories\n                          warning_func=func_fatal_error\n                          ;;\n                        *)\n                          func_fatal_error \\\n                             \"unsupported warning category: '$1'\"\n                          ;;\n                      esac\n                      shift\n                      ;;\n\n        --verbose|-v) opt_verbose=: ;;\n        --version)    func_version ;;\n        -\\?|-h)       func_usage ;;\n        --help)       func_help ;;\n\n\t# Separate optargs to long options (plugins may need this):\n\t--*=*)        func_split_equals \"$_G_opt\"\n\t              set dummy \"$func_split_equals_lhs\" \\\n                          \"$func_split_equals_rhs\" ${1+\"$@\"}\n                      shift\n                      ;;\n\n       # Separate optargs to short options:\n        -W*)\n                      func_split_short_opt \"$_G_opt\"\n                      set dummy \"$func_split_short_opt_name\" \\\n                          \"$func_split_short_opt_arg\" ${1+\"$@\"}\n                      shift\n                      ;;\n\n        # Separate non-argument short options:\n        -\\?*|-h*|-v*|-x*)\n                      func_split_short_opt \"$_G_opt\"\n                      set dummy \"$func_split_short_opt_name\" \\\n                          \"-$func_split_short_opt_arg\" ${1+\"$@\"}\n                      shift\n                      ;;\n\n        --)           break ;;\n        -*)           func_fatal_help \"unrecognised option: '$_G_opt'\" ;;\n        *)            set dummy \"$_G_opt\" ${1+\"$@\"}; shift; break ;;\n      esac\n    done\n\n    # save modified positional parameters for caller\n    func_quote_for_eval ${1+\"$@\"}\n    func_parse_options_result=$func_quote_for_eval_result\n}\n\n\n# func_validate_options [ARG]...\n# ------------------------------\n# Perform any sanity checks on option settings and/or unconsumed\n# arguments.\nfunc_hookable func_validate_options\nfunc_validate_options ()\n{\n    $debug_cmd\n\n    # Display all warnings if -W was not given.\n    test -n \"$opt_warning_types\" || opt_warning_types=\" $warning_categories\"\n\n    func_run_hooks func_validate_options ${1+\"$@\"}\n\n    # Bail if the options were screwed!\n    $exit_cmd $EXIT_FAILURE\n\n    # save modified positional parameters for caller\n    func_validate_options_result=$func_run_hooks_result\n}\n\n\n\n## ----------------- ##\n## Helper functions. ##\n## ----------------- ##\n\n# This section contains the helper functions used by the rest of the\n# hookable option parser framework in ascii-betical order.\n\n\n# func_fatal_help ARG...\n# ----------------------\n# Echo program name prefixed message to standard error, followed by\n# a help hint, and exit.\nfunc_fatal_help ()\n{\n    $debug_cmd\n\n    eval \\$ECHO \\\"\"Usage: $usage\"\\\"\n    eval \\$ECHO \\\"\"$fatal_help\"\\\"\n    func_error ${1+\"$@\"}\n    exit $EXIT_FAILURE\n}\n\n\n# func_help\n# ---------\n# Echo long help message to standard output and exit.\nfunc_help ()\n{\n    $debug_cmd\n\n    func_usage_message\n    $ECHO \"$long_help_message\"\n    exit 0\n}\n\n\n# func_missing_arg ARGNAME\n# ------------------------\n# Echo program name prefixed message to standard error and set global\n# exit_cmd.\nfunc_missing_arg ()\n{\n    $debug_cmd\n\n    func_error \"Missing argument for '$1'.\"\n    exit_cmd=exit\n}\n\n\n# func_split_equals STRING\n# ------------------------\n# Set func_split_equals_lhs and func_split_equals_rhs shell variables after\n# splitting STRING at the '=' sign.\ntest -z \"$_G_HAVE_XSI_OPS\" \\\n    && (eval 'x=a/b/c;\n      test 5aa/bb/cc = \"${#x}${x%%/*}${x%/*}${x#*/}${x##*/}\"') 2>/dev/null \\\n    && _G_HAVE_XSI_OPS=yes\n\nif test yes = \"$_G_HAVE_XSI_OPS\"\nthen\n  # This is an XSI compatible shell, allowing a faster implementation...\n  eval 'func_split_equals ()\n  {\n      $debug_cmd\n\n      func_split_equals_lhs=${1%%=*}\n      func_split_equals_rhs=${1#*=}\n      test \"x$func_split_equals_lhs\" = \"x$1\" \\\n        && func_split_equals_rhs=\n  }'\nelse\n  # ...otherwise fall back to using expr, which is often a shell builtin.\n  func_split_equals ()\n  {\n      $debug_cmd\n\n      func_split_equals_lhs=`expr \"x$1\" : 'x\\([^=]*\\)'`\n      func_split_equals_rhs=\n      test \"x$func_split_equals_lhs\" = \"x$1\" \\\n        || func_split_equals_rhs=`expr \"x$1\" : 'x[^=]*=\\(.*\\)$'`\n  }\nfi #func_split_equals\n\n\n# func_split_short_opt SHORTOPT\n# -----------------------------\n# Set func_split_short_opt_name and func_split_short_opt_arg shell\n# variables after splitting SHORTOPT after the 2nd character.\nif test yes = \"$_G_HAVE_XSI_OPS\"\nthen\n  # This is an XSI compatible shell, allowing a faster implementation...\n  eval 'func_split_short_opt ()\n  {\n      $debug_cmd\n\n      func_split_short_opt_arg=${1#??}\n      func_split_short_opt_name=${1%\"$func_split_short_opt_arg\"}\n  }'\nelse\n  # ...otherwise fall back to using expr, which is often a shell builtin.\n  func_split_short_opt ()\n  {\n      $debug_cmd\n\n      func_split_short_opt_name=`expr \"x$1\" : 'x-\\(.\\)'`\n      func_split_short_opt_arg=`expr \"x$1\" : 'x-.\\(.*\\)$'`\n  }\nfi #func_split_short_opt\n\n\n# func_usage\n# ----------\n# Echo short help message to standard output and exit.\nfunc_usage ()\n{\n    $debug_cmd\n\n    func_usage_message\n    $ECHO \"Run '$progname --help |${PAGER-more}' for full usage\"\n    exit 0\n}\n\n\n# func_usage_message\n# ------------------\n# Echo short help message to standard output.\nfunc_usage_message ()\n{\n    $debug_cmd\n\n    eval \\$ECHO \\\"\"Usage: $usage\"\\\"\n    echo\n    $SED -n 's|^# ||\n        /^Written by/{\n          x;p;x\n        }\n\th\n\t/^Written by/q' < \"$progpath\"\n    echo\n    eval \\$ECHO \\\"\"$usage_message\"\\\"\n}\n\n\n# func_version\n# ------------\n# Echo version message to standard output and exit.\nfunc_version ()\n{\n    $debug_cmd\n\n    printf '%s\\n' \"$progname $scriptversion\"\n    $SED -n '\n        /(C)/!b go\n        :more\n        /\\./!{\n          N\n          s|\\n# | |\n          b more\n        }\n        :go\n        /^# Written by /,/# warranty; / {\n          s|^# ||\n          s|^# *$||\n          s|\\((C)\\)[ 0-9,-]*[ ,-]\\([1-9][0-9]* \\)|\\1 \\2|\n          p\n        }\n        /^# Written by / {\n          s|^# ||\n          p\n        }\n        /^warranty; /q' < \"$progpath\"\n\n    exit $?\n}\n\n\n# Local variables:\n# mode: shell-script\n# sh-indentation: 2\n# eval: (add-hook 'before-save-hook 'time-stamp)\n# time-stamp-pattern: \"10/scriptversion=%:y-%02m-%02d.%02H; # UTC\"\n# time-stamp-time-zone: \"UTC\"\n# End:\n\n# Set a version string.\nscriptversion='(GNU libtool) 2.4.6'\n\n\n# func_echo ARG...\n# ----------------\n# Libtool also displays the current mode in messages, so override\n# funclib.sh func_echo with this custom definition.\nfunc_echo ()\n{\n    $debug_cmd\n\n    _G_message=$*\n\n    func_echo_IFS=$IFS\n    IFS=$nl\n    for _G_line in $_G_message; do\n      IFS=$func_echo_IFS\n      $ECHO \"$progname${opt_mode+: $opt_mode}: $_G_line\"\n    done\n    IFS=$func_echo_IFS\n}\n\n\n# func_warning ARG...\n# -------------------\n# Libtool warnings are not categorized, so override funclib.sh\n# func_warning with this simpler definition.\nfunc_warning ()\n{\n    $debug_cmd\n\n    $warning_func ${1+\"$@\"}\n}\n\n\n## ---------------- ##\n## Options parsing. ##\n## ---------------- ##\n\n# Hook in the functions to make sure our own options are parsed during\n# the option parsing loop.\n\nusage='$progpath [OPTION]... [MODE-ARG]...'\n\n# Short help message in response to '-h'.\nusage_message=\"Options:\n       --config             show all configuration variables\n       --debug              enable verbose shell tracing\n   -n, --dry-run            display commands without modifying any files\n       --features           display basic configuration information and exit\n       --mode=MODE          use operation mode MODE\n       --no-warnings        equivalent to '-Wnone'\n       --preserve-dup-deps  don't remove duplicate dependency libraries\n       --quiet, --silent    don't print informational messages\n       --tag=TAG            use configuration variables from tag TAG\n   -v, --verbose            print more informational messages than default\n       --version            print version information\n   -W, --warnings=CATEGORY  report the warnings falling in CATEGORY [all]\n   -h, --help, --help-all   print short, long, or detailed help message\n\"\n\n# Additional text appended to 'usage_message' in response to '--help'.\nfunc_help ()\n{\n    $debug_cmd\n\n    func_usage_message\n    $ECHO \"$long_help_message\n\nMODE must be one of the following:\n\n       clean           remove files from the build directory\n       compile         compile a source file into a libtool object\n       execute         automatically set library path, then run a program\n       finish          complete the installation of libtool libraries\n       install         install libraries or executables\n       link            create a library or an executable\n       uninstall       remove libraries from an installed directory\n\nMODE-ARGS vary depending on the MODE.  When passed as first option,\n'--mode=MODE' may be abbreviated as 'MODE' or a unique abbreviation of that.\nTry '$progname --help --mode=MODE' for a more detailed description of MODE.\n\nWhen reporting a bug, please describe a test case to reproduce it and\ninclude the following information:\n\n       host-triplet:   $host\n       shell:          $SHELL\n       compiler:       $LTCC\n       compiler flags: $LTCFLAGS\n       linker:         $LD (gnu? $with_gnu_ld)\n       version:        $progname (GNU libtool) 2.4.6\n       automake:       `($AUTOMAKE --version) 2>/dev/null |$SED 1q`\n       autoconf:       `($AUTOCONF --version) 2>/dev/null |$SED 1q`\n\nReport bugs to <bug-libtool@gnu.org>.\nGNU libtool home page: <http://www.gnu.org/software/libtool/>.\nGeneral help using GNU software: <http://www.gnu.org/gethelp/>.\"\n    exit 0\n}\n\n\n# func_lo2o OBJECT-NAME\n# ---------------------\n# Transform OBJECT-NAME from a '.lo' suffix to the platform specific\n# object suffix.\n\nlo2o=s/\\\\.lo\\$/.$objext/\no2lo=s/\\\\.$objext\\$/.lo/\n\nif test yes = \"$_G_HAVE_XSI_OPS\"; then\n  eval 'func_lo2o ()\n  {\n    case $1 in\n      *.lo) func_lo2o_result=${1%.lo}.$objext ;;\n      *   ) func_lo2o_result=$1               ;;\n    esac\n  }'\n\n  # func_xform LIBOBJ-OR-SOURCE\n  # ---------------------------\n  # Transform LIBOBJ-OR-SOURCE from a '.o' or '.c' (or otherwise)\n  # suffix to a '.lo' libtool-object suffix.\n  eval 'func_xform ()\n  {\n    func_xform_result=${1%.*}.lo\n  }'\nelse\n  # ...otherwise fall back to using sed.\n  func_lo2o ()\n  {\n    func_lo2o_result=`$ECHO \"$1\" | $SED \"$lo2o\"`\n  }\n\n  func_xform ()\n  {\n    func_xform_result=`$ECHO \"$1\" | $SED 's|\\.[^.]*$|.lo|'`\n  }\nfi\n\n\n# func_fatal_configuration ARG...\n# -------------------------------\n# Echo program name prefixed message to standard error, followed by\n# a configuration failure hint, and exit.\nfunc_fatal_configuration ()\n{\n    func__fatal_error ${1+\"$@\"} \\\n      \"See the $PACKAGE documentation for more information.\" \\\n      \"Fatal configuration error.\"\n}\n\n\n# func_config\n# -----------\n# Display the configuration for all the tags in this script.\nfunc_config ()\n{\n    re_begincf='^# ### BEGIN LIBTOOL'\n    re_endcf='^# ### END LIBTOOL'\n\n    # Default configuration.\n    $SED \"1,/$re_begincf CONFIG/d;/$re_endcf CONFIG/,\\$d\" < \"$progpath\"\n\n    # Now print the configurations for the tags.\n    for tagname in $taglist; do\n      $SED -n \"/$re_begincf TAG CONFIG: $tagname\\$/,/$re_endcf TAG CONFIG: $tagname\\$/p\" < \"$progpath\"\n    done\n\n    exit $?\n}\n\n\n# func_features\n# -------------\n# Display the features supported by this script.\nfunc_features ()\n{\n    echo \"host: $host\"\n    if test yes = \"$build_libtool_libs\"; then\n      echo \"enable shared libraries\"\n    else\n      echo \"disable shared libraries\"\n    fi\n    if test yes = \"$build_old_libs\"; then\n      echo \"enable static libraries\"\n    else\n      echo \"disable static libraries\"\n    fi\n\n    exit $?\n}\n\n\n# func_enable_tag TAGNAME\n# -----------------------\n# Verify that TAGNAME is valid, and either flag an error and exit, or\n# enable the TAGNAME tag.  We also add TAGNAME to the global $taglist\n# variable here.\nfunc_enable_tag ()\n{\n    # Global variable:\n    tagname=$1\n\n    re_begincf=\"^# ### BEGIN LIBTOOL TAG CONFIG: $tagname\\$\"\n    re_endcf=\"^# ### END LIBTOOL TAG CONFIG: $tagname\\$\"\n    sed_extractcf=/$re_begincf/,/$re_endcf/p\n\n    # Validate tagname.\n    case $tagname in\n      *[!-_A-Za-z0-9,/]*)\n        func_fatal_error \"invalid tag name: $tagname\"\n        ;;\n    esac\n\n    # Don't test for the \"default\" C tag, as we know it's\n    # there but not specially marked.\n    case $tagname in\n        CC) ;;\n    *)\n        if $GREP \"$re_begincf\" \"$progpath\" >/dev/null 2>&1; then\n\t  taglist=\"$taglist $tagname\"\n\n\t  # Evaluate the configuration.  Be careful to quote the path\n\t  # and the sed script, to avoid splitting on whitespace, but\n\t  # also don't use non-portable quotes within backquotes within\n\t  # quotes we have to do it in 2 steps:\n\t  extractedcf=`$SED -n -e \"$sed_extractcf\" < \"$progpath\"`\n\t  eval \"$extractedcf\"\n        else\n\t  func_error \"ignoring unknown tag $tagname\"\n        fi\n        ;;\n    esac\n}\n\n\n# func_check_version_match\n# ------------------------\n# Ensure that we are using m4 macros, and libtool script from the same\n# release of libtool.\nfunc_check_version_match ()\n{\n    if test \"$package_revision\" != \"$macro_revision\"; then\n      if test \"$VERSION\" != \"$macro_version\"; then\n        if test -z \"$macro_version\"; then\n          cat >&2 <<_LT_EOF\n$progname: Version mismatch error.  This is $PACKAGE $VERSION, but the\n$progname: definition of this LT_INIT comes from an older release.\n$progname: You should recreate aclocal.m4 with macros from $PACKAGE $VERSION\n$progname: and run autoconf again.\n_LT_EOF\n        else\n          cat >&2 <<_LT_EOF\n$progname: Version mismatch error.  This is $PACKAGE $VERSION, but the\n$progname: definition of this LT_INIT comes from $PACKAGE $macro_version.\n$progname: You should recreate aclocal.m4 with macros from $PACKAGE $VERSION\n$progname: and run autoconf again.\n_LT_EOF\n        fi\n      else\n        cat >&2 <<_LT_EOF\n$progname: Version mismatch error.  This is $PACKAGE $VERSION, revision $package_revision,\n$progname: but the definition of this LT_INIT comes from revision $macro_revision.\n$progname: You should recreate aclocal.m4 with macros from revision $package_revision\n$progname: of $PACKAGE $VERSION and run autoconf again.\n_LT_EOF\n      fi\n\n      exit $EXIT_MISMATCH\n    fi\n}\n\n\n# libtool_options_prep [ARG]...\n# -----------------------------\n# Preparation for options parsed by libtool.\nlibtool_options_prep ()\n{\n    $debug_mode\n\n    # Option defaults:\n    opt_config=false\n    opt_dlopen=\n    opt_dry_run=false\n    opt_help=false\n    opt_mode=\n    opt_preserve_dup_deps=false\n    opt_quiet=false\n\n    nonopt=\n    preserve_args=\n\n    # Shorthand for --mode=foo, only valid as the first argument\n    case $1 in\n    clean|clea|cle|cl)\n      shift; set dummy --mode clean ${1+\"$@\"}; shift\n      ;;\n    compile|compil|compi|comp|com|co|c)\n      shift; set dummy --mode compile ${1+\"$@\"}; shift\n      ;;\n    execute|execut|execu|exec|exe|ex|e)\n      shift; set dummy --mode execute ${1+\"$@\"}; shift\n      ;;\n    finish|finis|fini|fin|fi|f)\n      shift; set dummy --mode finish ${1+\"$@\"}; shift\n      ;;\n    install|instal|insta|inst|ins|in|i)\n      shift; set dummy --mode install ${1+\"$@\"}; shift\n      ;;\n    link|lin|li|l)\n      shift; set dummy --mode link ${1+\"$@\"}; shift\n      ;;\n    uninstall|uninstal|uninsta|uninst|unins|unin|uni|un|u)\n      shift; set dummy --mode uninstall ${1+\"$@\"}; shift\n      ;;\n    esac\n\n    # Pass back the list of options.\n    func_quote_for_eval ${1+\"$@\"}\n    libtool_options_prep_result=$func_quote_for_eval_result\n}\nfunc_add_hook func_options_prep libtool_options_prep\n\n\n# libtool_parse_options [ARG]...\n# ---------------------------------\n# Provide handling for libtool specific options.\nlibtool_parse_options ()\n{\n    $debug_cmd\n\n    # Perform our own loop to consume as many options as possible in\n    # each iteration.\n    while test $# -gt 0; do\n      _G_opt=$1\n      shift\n      case $_G_opt in\n        --dry-run|--dryrun|-n)\n                        opt_dry_run=:\n                        ;;\n\n        --config)       func_config ;;\n\n        --dlopen|-dlopen)\n                        opt_dlopen=\"${opt_dlopen+$opt_dlopen\n}$1\"\n                        shift\n                        ;;\n\n        --preserve-dup-deps)\n                        opt_preserve_dup_deps=: ;;\n\n        --features)     func_features ;;\n\n        --finish)       set dummy --mode finish ${1+\"$@\"}; shift ;;\n\n        --help)         opt_help=: ;;\n\n        --help-all)     opt_help=': help-all' ;;\n\n        --mode)         test $# = 0 && func_missing_arg $_G_opt && break\n                        opt_mode=$1\n                        case $1 in\n                          # Valid mode arguments:\n                          clean|compile|execute|finish|install|link|relink|uninstall) ;;\n\n                          # Catch anything else as an error\n                          *) func_error \"invalid argument for $_G_opt\"\n                             exit_cmd=exit\n                             break\n                             ;;\n                        esac\n                        shift\n                        ;;\n\n        --no-silent|--no-quiet)\n                        opt_quiet=false\n                        func_append preserve_args \" $_G_opt\"\n                        ;;\n\n        --no-warnings|--no-warning|--no-warn)\n                        opt_warning=false\n                        func_append preserve_args \" $_G_opt\"\n                        ;;\n\n        --no-verbose)\n                        opt_verbose=false\n                        func_append preserve_args \" $_G_opt\"\n                        ;;\n\n        --silent|--quiet)\n                        opt_quiet=:\n                        opt_verbose=false\n                        func_append preserve_args \" $_G_opt\"\n                        ;;\n\n        --tag)          test $# = 0 && func_missing_arg $_G_opt && break\n                        opt_tag=$1\n                        func_append preserve_args \" $_G_opt $1\"\n                        func_enable_tag \"$1\"\n                        shift\n                        ;;\n\n        --verbose|-v)   opt_quiet=false\n                        opt_verbose=:\n                        func_append preserve_args \" $_G_opt\"\n                        ;;\n\n\t# An option not handled by this hook function:\n        *)\t\tset dummy \"$_G_opt\" ${1+\"$@\"};\tshift; break  ;;\n      esac\n    done\n\n\n    # save modified positional parameters for caller\n    func_quote_for_eval ${1+\"$@\"}\n    libtool_parse_options_result=$func_quote_for_eval_result\n}\nfunc_add_hook func_parse_options libtool_parse_options\n\n\n\n# libtool_validate_options [ARG]...\n# ---------------------------------\n# Perform any sanity checks on option settings and/or unconsumed\n# arguments.\nlibtool_validate_options ()\n{\n    # save first non-option argument\n    if test 0 -lt $#; then\n      nonopt=$1\n      shift\n    fi\n\n    # preserve --debug\n    test : = \"$debug_cmd\" || func_append preserve_args \" --debug\"\n\n    case $host in\n      # Solaris2 added to fix http://debbugs.gnu.org/cgi/bugreport.cgi?bug=16452\n      # see also: http://gcc.gnu.org/bugzilla/show_bug.cgi?id=59788\n      *cygwin* | *mingw* | *pw32* | *cegcc* | *solaris2* | *os2*)\n        # don't eliminate duplications in $postdeps and $predeps\n        opt_duplicate_compiler_generated_deps=:\n        ;;\n      *)\n        opt_duplicate_compiler_generated_deps=$opt_preserve_dup_deps\n        ;;\n    esac\n\n    $opt_help || {\n      # Sanity checks first:\n      func_check_version_match\n\n      test yes != \"$build_libtool_libs\" \\\n        && test yes != \"$build_old_libs\" \\\n        && func_fatal_configuration \"not configured to build any kind of library\"\n\n      # Darwin sucks\n      eval std_shrext=\\\"$shrext_cmds\\\"\n\n      # Only execute mode is allowed to have -dlopen flags.\n      if test -n \"$opt_dlopen\" && test execute != \"$opt_mode\"; then\n        func_error \"unrecognized option '-dlopen'\"\n        $ECHO \"$help\" 1>&2\n        exit $EXIT_FAILURE\n      fi\n\n      # Change the help message to a mode-specific one.\n      generic_help=$help\n      help=\"Try '$progname --help --mode=$opt_mode' for more information.\"\n    }\n\n    # Pass back the unparsed argument list\n    func_quote_for_eval ${1+\"$@\"}\n    libtool_validate_options_result=$func_quote_for_eval_result\n}\nfunc_add_hook func_validate_options libtool_validate_options\n\n\n# Process options as early as possible so that --help and --version\n# can return quickly.\nfunc_options ${1+\"$@\"}\neval set dummy \"$func_options_result\"; shift\n\n\n\n## ----------- ##\n##    Main.    ##\n## ----------- ##\n\nmagic='%%%MAGIC variable%%%'\nmagic_exe='%%%MAGIC EXE variable%%%'\n\n# Global variables.\nextracted_archives=\nextracted_serial=0\n\n# If this variable is set in any of the actions, the command in it\n# will be execed at the end.  This prevents here-documents from being\n# left over by shells.\nexec_cmd=\n\n\n# A function that is used when there is no print builtin or printf.\nfunc_fallback_echo ()\n{\n  eval 'cat <<_LTECHO_EOF\n$1\n_LTECHO_EOF'\n}\n\n# func_generated_by_libtool\n# True iff stdin has been generated by Libtool. This function is only\n# a basic sanity check; it will hardly flush out determined imposters.\nfunc_generated_by_libtool_p ()\n{\n  $GREP \"^# Generated by .*$PACKAGE\" > /dev/null 2>&1\n}\n\n# func_lalib_p file\n# True iff FILE is a libtool '.la' library or '.lo' object file.\n# This function is only a basic sanity check; it will hardly flush out\n# determined imposters.\nfunc_lalib_p ()\n{\n    test -f \"$1\" &&\n      $SED -e 4q \"$1\" 2>/dev/null | func_generated_by_libtool_p\n}\n\n# func_lalib_unsafe_p file\n# True iff FILE is a libtool '.la' library or '.lo' object file.\n# This function implements the same check as func_lalib_p without\n# resorting to external programs.  To this end, it redirects stdin and\n# closes it afterwards, without saving the original file descriptor.\n# As a safety measure, use it only where a negative result would be\n# fatal anyway.  Works if 'file' does not exist.\nfunc_lalib_unsafe_p ()\n{\n    lalib_p=no\n    if test -f \"$1\" && test -r \"$1\" && exec 5<&0 <\"$1\"; then\n\tfor lalib_p_l in 1 2 3 4\n\tdo\n\t    read lalib_p_line\n\t    case $lalib_p_line in\n\t\t\\#\\ Generated\\ by\\ *$PACKAGE* ) lalib_p=yes; break;;\n\t    esac\n\tdone\n\texec 0<&5 5<&-\n    fi\n    test yes = \"$lalib_p\"\n}\n\n# func_ltwrapper_script_p file\n# True iff FILE is a libtool wrapper script\n# This function is only a basic sanity check; it will hardly flush out\n# determined imposters.\nfunc_ltwrapper_script_p ()\n{\n    test -f \"$1\" &&\n      $lt_truncate_bin < \"$1\" 2>/dev/null | func_generated_by_libtool_p\n}\n\n# func_ltwrapper_executable_p file\n# True iff FILE is a libtool wrapper executable\n# This function is only a basic sanity check; it will hardly flush out\n# determined imposters.\nfunc_ltwrapper_executable_p ()\n{\n    func_ltwrapper_exec_suffix=\n    case $1 in\n    *.exe) ;;\n    *) func_ltwrapper_exec_suffix=.exe ;;\n    esac\n    $GREP \"$magic_exe\" \"$1$func_ltwrapper_exec_suffix\" >/dev/null 2>&1\n}\n\n# func_ltwrapper_scriptname file\n# Assumes file is an ltwrapper_executable\n# uses $file to determine the appropriate filename for a\n# temporary ltwrapper_script.\nfunc_ltwrapper_scriptname ()\n{\n    func_dirname_and_basename \"$1\" \"\" \".\"\n    func_stripname '' '.exe' \"$func_basename_result\"\n    func_ltwrapper_scriptname_result=$func_dirname_result/$objdir/${func_stripname_result}_ltshwrapper\n}\n\n# func_ltwrapper_p file\n# True iff FILE is a libtool wrapper script or wrapper executable\n# This function is only a basic sanity check; it will hardly flush out\n# determined imposters.\nfunc_ltwrapper_p ()\n{\n    func_ltwrapper_script_p \"$1\" || func_ltwrapper_executable_p \"$1\"\n}\n\n\n# func_execute_cmds commands fail_cmd\n# Execute tilde-delimited COMMANDS.\n# If FAIL_CMD is given, eval that upon failure.\n# FAIL_CMD may read-access the current command in variable CMD!\nfunc_execute_cmds ()\n{\n    $debug_cmd\n\n    save_ifs=$IFS; IFS='~'\n    for cmd in $1; do\n      IFS=$sp$nl\n      eval cmd=\\\"$cmd\\\"\n      IFS=$save_ifs\n      func_show_eval \"$cmd\" \"${2-:}\"\n    done\n    IFS=$save_ifs\n}\n\n\n# func_source file\n# Source FILE, adding directory component if necessary.\n# Note that it is not necessary on cygwin/mingw to append a dot to\n# FILE even if both FILE and FILE.exe exist: automatic-append-.exe\n# behavior happens only for exec(3), not for open(2)!  Also, sourcing\n# 'FILE.' does not work on cygwin managed mounts.\nfunc_source ()\n{\n    $debug_cmd\n\n    case $1 in\n    */* | *\\\\*)\t. \"$1\" ;;\n    *)\t\t. \"./$1\" ;;\n    esac\n}\n\n\n# func_resolve_sysroot PATH\n# Replace a leading = in PATH with a sysroot.  Store the result into\n# func_resolve_sysroot_result\nfunc_resolve_sysroot ()\n{\n  func_resolve_sysroot_result=$1\n  case $func_resolve_sysroot_result in\n  =*)\n    func_stripname '=' '' \"$func_resolve_sysroot_result\"\n    func_resolve_sysroot_result=$lt_sysroot$func_stripname_result\n    ;;\n  esac\n}\n\n# func_replace_sysroot PATH\n# If PATH begins with the sysroot, replace it with = and\n# store the result into func_replace_sysroot_result.\nfunc_replace_sysroot ()\n{\n  case $lt_sysroot:$1 in\n  ?*:\"$lt_sysroot\"*)\n    func_stripname \"$lt_sysroot\" '' \"$1\"\n    func_replace_sysroot_result='='$func_stripname_result\n    ;;\n  *)\n    # Including no sysroot.\n    func_replace_sysroot_result=$1\n    ;;\n  esac\n}\n\n# func_infer_tag arg\n# Infer tagged configuration to use if any are available and\n# if one wasn't chosen via the \"--tag\" command line option.\n# Only attempt this if the compiler in the base compile\n# command doesn't match the default compiler.\n# arg is usually of the form 'gcc ...'\nfunc_infer_tag ()\n{\n    $debug_cmd\n\n    if test -n \"$available_tags\" && test -z \"$tagname\"; then\n      CC_quoted=\n      for arg in $CC; do\n\tfunc_append_quoted CC_quoted \"$arg\"\n      done\n      CC_expanded=`func_echo_all $CC`\n      CC_quoted_expanded=`func_echo_all $CC_quoted`\n      case $@ in\n      # Blanks in the command may have been stripped by the calling shell,\n      # but not from the CC environment variable when configure was run.\n      \" $CC \"* | \"$CC \"* | \" $CC_expanded \"* | \"$CC_expanded \"* | \\\n      \" $CC_quoted\"* | \"$CC_quoted \"* | \" $CC_quoted_expanded \"* | \"$CC_quoted_expanded \"*) ;;\n      # Blanks at the start of $base_compile will cause this to fail\n      # if we don't check for them as well.\n      *)\n\tfor z in $available_tags; do\n\t  if $GREP \"^# ### BEGIN LIBTOOL TAG CONFIG: $z$\" < \"$progpath\" > /dev/null; then\n\t    # Evaluate the configuration.\n\t    eval \"`$SED -n -e '/^# ### BEGIN LIBTOOL TAG CONFIG: '$z'$/,/^# ### END LIBTOOL TAG CONFIG: '$z'$/p' < $progpath`\"\n\t    CC_quoted=\n\t    for arg in $CC; do\n\t      # Double-quote args containing other shell metacharacters.\n\t      func_append_quoted CC_quoted \"$arg\"\n\t    done\n\t    CC_expanded=`func_echo_all $CC`\n\t    CC_quoted_expanded=`func_echo_all $CC_quoted`\n\t    case \"$@ \" in\n\t    \" $CC \"* | \"$CC \"* | \" $CC_expanded \"* | \"$CC_expanded \"* | \\\n\t    \" $CC_quoted\"* | \"$CC_quoted \"* | \" $CC_quoted_expanded \"* | \"$CC_quoted_expanded \"*)\n\t      # The compiler in the base compile command matches\n\t      # the one in the tagged configuration.\n\t      # Assume this is the tagged configuration we want.\n\t      tagname=$z\n\t      break\n\t      ;;\n\t    esac\n\t  fi\n\tdone\n\t# If $tagname still isn't set, then no tagged configuration\n\t# was found and let the user know that the \"--tag\" command\n\t# line option must be used.\n\tif test -z \"$tagname\"; then\n\t  func_echo \"unable to infer tagged configuration\"\n\t  func_fatal_error \"specify a tag with '--tag'\"\n#\telse\n#\t  func_verbose \"using $tagname tagged configuration\"\n\tfi\n\t;;\n      esac\n    fi\n}\n\n\n\n# func_write_libtool_object output_name pic_name nonpic_name\n# Create a libtool object file (analogous to a \".la\" file),\n# but don't create it if we're doing a dry run.\nfunc_write_libtool_object ()\n{\n    write_libobj=$1\n    if test yes = \"$build_libtool_libs\"; then\n      write_lobj=\\'$2\\'\n    else\n      write_lobj=none\n    fi\n\n    if test yes = \"$build_old_libs\"; then\n      write_oldobj=\\'$3\\'\n    else\n      write_oldobj=none\n    fi\n\n    $opt_dry_run || {\n      cat >${write_libobj}T <<EOF\n# $write_libobj - a libtool object file\n# Generated by $PROGRAM (GNU $PACKAGE) $VERSION\n#\n# Please DO NOT delete this file!\n# It is necessary for linking the library.\n\n# Name of the PIC object.\npic_object=$write_lobj\n\n# Name of the non-PIC object\nnon_pic_object=$write_oldobj\n\nEOF\n      $MV \"${write_libobj}T\" \"$write_libobj\"\n    }\n}\n\n\n##################################################\n# FILE NAME AND PATH CONVERSION HELPER FUNCTIONS #\n##################################################\n\n# func_convert_core_file_wine_to_w32 ARG\n# Helper function used by file name conversion functions when $build is *nix,\n# and $host is mingw, cygwin, or some other w32 environment. Relies on a\n# correctly configured wine environment available, with the winepath program\n# in $build's $PATH.\n#\n# ARG is the $build file name to be converted to w32 format.\n# Result is available in $func_convert_core_file_wine_to_w32_result, and will\n# be empty on error (or when ARG is empty)\nfunc_convert_core_file_wine_to_w32 ()\n{\n  $debug_cmd\n\n  func_convert_core_file_wine_to_w32_result=$1\n  if test -n \"$1\"; then\n    # Unfortunately, winepath does not exit with a non-zero error code, so we\n    # are forced to check the contents of stdout. On the other hand, if the\n    # command is not found, the shell will set an exit code of 127 and print\n    # *an error message* to stdout. So we must check for both error code of\n    # zero AND non-empty stdout, which explains the odd construction:\n    func_convert_core_file_wine_to_w32_tmp=`winepath -w \"$1\" 2>/dev/null`\n    if test \"$?\" -eq 0 && test -n \"$func_convert_core_file_wine_to_w32_tmp\"; then\n      func_convert_core_file_wine_to_w32_result=`$ECHO \"$func_convert_core_file_wine_to_w32_tmp\" |\n        $SED -e \"$sed_naive_backslashify\"`\n    else\n      func_convert_core_file_wine_to_w32_result=\n    fi\n  fi\n}\n# end: func_convert_core_file_wine_to_w32\n\n\n# func_convert_core_path_wine_to_w32 ARG\n# Helper function used by path conversion functions when $build is *nix, and\n# $host is mingw, cygwin, or some other w32 environment. Relies on a correctly\n# configured wine environment available, with the winepath program in $build's\n# $PATH. Assumes ARG has no leading or trailing path separator characters.\n#\n# ARG is path to be converted from $build format to win32.\n# Result is available in $func_convert_core_path_wine_to_w32_result.\n# Unconvertible file (directory) names in ARG are skipped; if no directory names\n# are convertible, then the result may be empty.\nfunc_convert_core_path_wine_to_w32 ()\n{\n  $debug_cmd\n\n  # unfortunately, winepath doesn't convert paths, only file names\n  func_convert_core_path_wine_to_w32_result=\n  if test -n \"$1\"; then\n    oldIFS=$IFS\n    IFS=:\n    for func_convert_core_path_wine_to_w32_f in $1; do\n      IFS=$oldIFS\n      func_convert_core_file_wine_to_w32 \"$func_convert_core_path_wine_to_w32_f\"\n      if test -n \"$func_convert_core_file_wine_to_w32_result\"; then\n        if test -z \"$func_convert_core_path_wine_to_w32_result\"; then\n          func_convert_core_path_wine_to_w32_result=$func_convert_core_file_wine_to_w32_result\n        else\n          func_append func_convert_core_path_wine_to_w32_result \";$func_convert_core_file_wine_to_w32_result\"\n        fi\n      fi\n    done\n    IFS=$oldIFS\n  fi\n}\n# end: func_convert_core_path_wine_to_w32\n\n\n# func_cygpath ARGS...\n# Wrapper around calling the cygpath program via LT_CYGPATH. This is used when\n# when (1) $build is *nix and Cygwin is hosted via a wine environment; or (2)\n# $build is MSYS and $host is Cygwin, or (3) $build is Cygwin. In case (1) or\n# (2), returns the Cygwin file name or path in func_cygpath_result (input\n# file name or path is assumed to be in w32 format, as previously converted\n# from $build's *nix or MSYS format). In case (3), returns the w32 file name\n# or path in func_cygpath_result (input file name or path is assumed to be in\n# Cygwin format). Returns an empty string on error.\n#\n# ARGS are passed to cygpath, with the last one being the file name or path to\n# be converted.\n#\n# Specify the absolute *nix (or w32) name to cygpath in the LT_CYGPATH\n# environment variable; do not put it in $PATH.\nfunc_cygpath ()\n{\n  $debug_cmd\n\n  if test -n \"$LT_CYGPATH\" && test -f \"$LT_CYGPATH\"; then\n    func_cygpath_result=`$LT_CYGPATH \"$@\" 2>/dev/null`\n    if test \"$?\" -ne 0; then\n      # on failure, ensure result is empty\n      func_cygpath_result=\n    fi\n  else\n    func_cygpath_result=\n    func_error \"LT_CYGPATH is empty or specifies non-existent file: '$LT_CYGPATH'\"\n  fi\n}\n#end: func_cygpath\n\n\n# func_convert_core_msys_to_w32 ARG\n# Convert file name or path ARG from MSYS format to w32 format.  Return\n# result in func_convert_core_msys_to_w32_result.\nfunc_convert_core_msys_to_w32 ()\n{\n  $debug_cmd\n\n  # awkward: cmd appends spaces to result\n  func_convert_core_msys_to_w32_result=`( cmd //c echo \"$1\" ) 2>/dev/null |\n    $SED -e 's/[ ]*$//' -e \"$sed_naive_backslashify\"`\n}\n#end: func_convert_core_msys_to_w32\n\n\n# func_convert_file_check ARG1 ARG2\n# Verify that ARG1 (a file name in $build format) was converted to $host\n# format in ARG2. Otherwise, emit an error message, but continue (resetting\n# func_to_host_file_result to ARG1).\nfunc_convert_file_check ()\n{\n  $debug_cmd\n\n  if test -z \"$2\" && test -n \"$1\"; then\n    func_error \"Could not determine host file name corresponding to\"\n    func_error \"  '$1'\"\n    func_error \"Continuing, but uninstalled executables may not work.\"\n    # Fallback:\n    func_to_host_file_result=$1\n  fi\n}\n# end func_convert_file_check\n\n\n# func_convert_path_check FROM_PATHSEP TO_PATHSEP FROM_PATH TO_PATH\n# Verify that FROM_PATH (a path in $build format) was converted to $host\n# format in TO_PATH. Otherwise, emit an error message, but continue, resetting\n# func_to_host_file_result to a simplistic fallback value (see below).\nfunc_convert_path_check ()\n{\n  $debug_cmd\n\n  if test -z \"$4\" && test -n \"$3\"; then\n    func_error \"Could not determine the host path corresponding to\"\n    func_error \"  '$3'\"\n    func_error \"Continuing, but uninstalled executables may not work.\"\n    # Fallback.  This is a deliberately simplistic \"conversion\" and\n    # should not be \"improved\".  See libtool.info.\n    if test \"x$1\" != \"x$2\"; then\n      lt_replace_pathsep_chars=\"s|$1|$2|g\"\n      func_to_host_path_result=`echo \"$3\" |\n        $SED -e \"$lt_replace_pathsep_chars\"`\n    else\n      func_to_host_path_result=$3\n    fi\n  fi\n}\n# end func_convert_path_check\n\n\n# func_convert_path_front_back_pathsep FRONTPAT BACKPAT REPL ORIG\n# Modifies func_to_host_path_result by prepending REPL if ORIG matches FRONTPAT\n# and appending REPL if ORIG matches BACKPAT.\nfunc_convert_path_front_back_pathsep ()\n{\n  $debug_cmd\n\n  case $4 in\n  $1 ) func_to_host_path_result=$3$func_to_host_path_result\n    ;;\n  esac\n  case $4 in\n  $2 ) func_append func_to_host_path_result \"$3\"\n    ;;\n  esac\n}\n# end func_convert_path_front_back_pathsep\n\n\n##################################################\n# $build to $host FILE NAME CONVERSION FUNCTIONS #\n##################################################\n# invoked via '$to_host_file_cmd ARG'\n#\n# In each case, ARG is the path to be converted from $build to $host format.\n# Result will be available in $func_to_host_file_result.\n\n\n# func_to_host_file ARG\n# Converts the file name ARG from $build format to $host format. Return result\n# in func_to_host_file_result.\nfunc_to_host_file ()\n{\n  $debug_cmd\n\n  $to_host_file_cmd \"$1\"\n}\n# end func_to_host_file\n\n\n# func_to_tool_file ARG LAZY\n# converts the file name ARG from $build format to toolchain format. Return\n# result in func_to_tool_file_result.  If the conversion in use is listed\n# in (the comma separated) LAZY, no conversion takes place.\nfunc_to_tool_file ()\n{\n  $debug_cmd\n\n  case ,$2, in\n    *,\"$to_tool_file_cmd\",*)\n      func_to_tool_file_result=$1\n      ;;\n    *)\n      $to_tool_file_cmd \"$1\"\n      func_to_tool_file_result=$func_to_host_file_result\n      ;;\n  esac\n}\n# end func_to_tool_file\n\n\n# func_convert_file_noop ARG\n# Copy ARG to func_to_host_file_result.\nfunc_convert_file_noop ()\n{\n  func_to_host_file_result=$1\n}\n# end func_convert_file_noop\n\n\n# func_convert_file_msys_to_w32 ARG\n# Convert file name ARG from (mingw) MSYS to (mingw) w32 format; automatic\n# conversion to w32 is not available inside the cwrapper.  Returns result in\n# func_to_host_file_result.\nfunc_convert_file_msys_to_w32 ()\n{\n  $debug_cmd\n\n  func_to_host_file_result=$1\n  if test -n \"$1\"; then\n    func_convert_core_msys_to_w32 \"$1\"\n    func_to_host_file_result=$func_convert_core_msys_to_w32_result\n  fi\n  func_convert_file_check \"$1\" \"$func_to_host_file_result\"\n}\n# end func_convert_file_msys_to_w32\n\n\n# func_convert_file_cygwin_to_w32 ARG\n# Convert file name ARG from Cygwin to w32 format.  Returns result in\n# func_to_host_file_result.\nfunc_convert_file_cygwin_to_w32 ()\n{\n  $debug_cmd\n\n  func_to_host_file_result=$1\n  if test -n \"$1\"; then\n    # because $build is cygwin, we call \"the\" cygpath in $PATH; no need to use\n    # LT_CYGPATH in this case.\n    func_to_host_file_result=`cygpath -m \"$1\"`\n  fi\n  func_convert_file_check \"$1\" \"$func_to_host_file_result\"\n}\n# end func_convert_file_cygwin_to_w32\n\n\n# func_convert_file_nix_to_w32 ARG\n# Convert file name ARG from *nix to w32 format.  Requires a wine environment\n# and a working winepath. Returns result in func_to_host_file_result.\nfunc_convert_file_nix_to_w32 ()\n{\n  $debug_cmd\n\n  func_to_host_file_result=$1\n  if test -n \"$1\"; then\n    func_convert_core_file_wine_to_w32 \"$1\"\n    func_to_host_file_result=$func_convert_core_file_wine_to_w32_result\n  fi\n  func_convert_file_check \"$1\" \"$func_to_host_file_result\"\n}\n# end func_convert_file_nix_to_w32\n\n\n# func_convert_file_msys_to_cygwin ARG\n# Convert file name ARG from MSYS to Cygwin format.  Requires LT_CYGPATH set.\n# Returns result in func_to_host_file_result.\nfunc_convert_file_msys_to_cygwin ()\n{\n  $debug_cmd\n\n  func_to_host_file_result=$1\n  if test -n \"$1\"; then\n    func_convert_core_msys_to_w32 \"$1\"\n    func_cygpath -u \"$func_convert_core_msys_to_w32_result\"\n    func_to_host_file_result=$func_cygpath_result\n  fi\n  func_convert_file_check \"$1\" \"$func_to_host_file_result\"\n}\n# end func_convert_file_msys_to_cygwin\n\n\n# func_convert_file_nix_to_cygwin ARG\n# Convert file name ARG from *nix to Cygwin format.  Requires Cygwin installed\n# in a wine environment, working winepath, and LT_CYGPATH set.  Returns result\n# in func_to_host_file_result.\nfunc_convert_file_nix_to_cygwin ()\n{\n  $debug_cmd\n\n  func_to_host_file_result=$1\n  if test -n \"$1\"; then\n    # convert from *nix to w32, then use cygpath to convert from w32 to cygwin.\n    func_convert_core_file_wine_to_w32 \"$1\"\n    func_cygpath -u \"$func_convert_core_file_wine_to_w32_result\"\n    func_to_host_file_result=$func_cygpath_result\n  fi\n  func_convert_file_check \"$1\" \"$func_to_host_file_result\"\n}\n# end func_convert_file_nix_to_cygwin\n\n\n#############################################\n# $build to $host PATH CONVERSION FUNCTIONS #\n#############################################\n# invoked via '$to_host_path_cmd ARG'\n#\n# In each case, ARG is the path to be converted from $build to $host format.\n# The result will be available in $func_to_host_path_result.\n#\n# Path separators are also converted from $build format to $host format.  If\n# ARG begins or ends with a path separator character, it is preserved (but\n# converted to $host format) on output.\n#\n# All path conversion functions are named using the following convention:\n#   file name conversion function    : func_convert_file_X_to_Y ()\n#   path conversion function         : func_convert_path_X_to_Y ()\n# where, for any given $build/$host combination the 'X_to_Y' value is the\n# same.  If conversion functions are added for new $build/$host combinations,\n# the two new functions must follow this pattern, or func_init_to_host_path_cmd\n# will break.\n\n\n# func_init_to_host_path_cmd\n# Ensures that function \"pointer\" variable $to_host_path_cmd is set to the\n# appropriate value, based on the value of $to_host_file_cmd.\nto_host_path_cmd=\nfunc_init_to_host_path_cmd ()\n{\n  $debug_cmd\n\n  if test -z \"$to_host_path_cmd\"; then\n    func_stripname 'func_convert_file_' '' \"$to_host_file_cmd\"\n    to_host_path_cmd=func_convert_path_$func_stripname_result\n  fi\n}\n\n\n# func_to_host_path ARG\n# Converts the path ARG from $build format to $host format. Return result\n# in func_to_host_path_result.\nfunc_to_host_path ()\n{\n  $debug_cmd\n\n  func_init_to_host_path_cmd\n  $to_host_path_cmd \"$1\"\n}\n# end func_to_host_path\n\n\n# func_convert_path_noop ARG\n# Copy ARG to func_to_host_path_result.\nfunc_convert_path_noop ()\n{\n  func_to_host_path_result=$1\n}\n# end func_convert_path_noop\n\n\n# func_convert_path_msys_to_w32 ARG\n# Convert path ARG from (mingw) MSYS to (mingw) w32 format; automatic\n# conversion to w32 is not available inside the cwrapper.  Returns result in\n# func_to_host_path_result.\nfunc_convert_path_msys_to_w32 ()\n{\n  $debug_cmd\n\n  func_to_host_path_result=$1\n  if test -n \"$1\"; then\n    # Remove leading and trailing path separator characters from ARG.  MSYS\n    # behavior is inconsistent here; cygpath turns them into '.;' and ';.';\n    # and winepath ignores them completely.\n    func_stripname : : \"$1\"\n    func_to_host_path_tmp1=$func_stripname_result\n    func_convert_core_msys_to_w32 \"$func_to_host_path_tmp1\"\n    func_to_host_path_result=$func_convert_core_msys_to_w32_result\n    func_convert_path_check : \";\" \\\n      \"$func_to_host_path_tmp1\" \"$func_to_host_path_result\"\n    func_convert_path_front_back_pathsep \":*\" \"*:\" \";\" \"$1\"\n  fi\n}\n# end func_convert_path_msys_to_w32\n\n\n# func_convert_path_cygwin_to_w32 ARG\n# Convert path ARG from Cygwin to w32 format.  Returns result in\n# func_to_host_file_result.\nfunc_convert_path_cygwin_to_w32 ()\n{\n  $debug_cmd\n\n  func_to_host_path_result=$1\n  if test -n \"$1\"; then\n    # See func_convert_path_msys_to_w32:\n    func_stripname : : \"$1\"\n    func_to_host_path_tmp1=$func_stripname_result\n    func_to_host_path_result=`cygpath -m -p \"$func_to_host_path_tmp1\"`\n    func_convert_path_check : \";\" \\\n      \"$func_to_host_path_tmp1\" \"$func_to_host_path_result\"\n    func_convert_path_front_back_pathsep \":*\" \"*:\" \";\" \"$1\"\n  fi\n}\n# end func_convert_path_cygwin_to_w32\n\n\n# func_convert_path_nix_to_w32 ARG\n# Convert path ARG from *nix to w32 format.  Requires a wine environment and\n# a working winepath.  Returns result in func_to_host_file_result.\nfunc_convert_path_nix_to_w32 ()\n{\n  $debug_cmd\n\n  func_to_host_path_result=$1\n  if test -n \"$1\"; then\n    # See func_convert_path_msys_to_w32:\n    func_stripname : : \"$1\"\n    func_to_host_path_tmp1=$func_stripname_result\n    func_convert_core_path_wine_to_w32 \"$func_to_host_path_tmp1\"\n    func_to_host_path_result=$func_convert_core_path_wine_to_w32_result\n    func_convert_path_check : \";\" \\\n      \"$func_to_host_path_tmp1\" \"$func_to_host_path_result\"\n    func_convert_path_front_back_pathsep \":*\" \"*:\" \";\" \"$1\"\n  fi\n}\n# end func_convert_path_nix_to_w32\n\n\n# func_convert_path_msys_to_cygwin ARG\n# Convert path ARG from MSYS to Cygwin format.  Requires LT_CYGPATH set.\n# Returns result in func_to_host_file_result.\nfunc_convert_path_msys_to_cygwin ()\n{\n  $debug_cmd\n\n  func_to_host_path_result=$1\n  if test -n \"$1\"; then\n    # See func_convert_path_msys_to_w32:\n    func_stripname : : \"$1\"\n    func_to_host_path_tmp1=$func_stripname_result\n    func_convert_core_msys_to_w32 \"$func_to_host_path_tmp1\"\n    func_cygpath -u -p \"$func_convert_core_msys_to_w32_result\"\n    func_to_host_path_result=$func_cygpath_result\n    func_convert_path_check : : \\\n      \"$func_to_host_path_tmp1\" \"$func_to_host_path_result\"\n    func_convert_path_front_back_pathsep \":*\" \"*:\" : \"$1\"\n  fi\n}\n# end func_convert_path_msys_to_cygwin\n\n\n# func_convert_path_nix_to_cygwin ARG\n# Convert path ARG from *nix to Cygwin format.  Requires Cygwin installed in a\n# a wine environment, working winepath, and LT_CYGPATH set.  Returns result in\n# func_to_host_file_result.\nfunc_convert_path_nix_to_cygwin ()\n{\n  $debug_cmd\n\n  func_to_host_path_result=$1\n  if test -n \"$1\"; then\n    # Remove leading and trailing path separator characters from\n    # ARG. msys behavior is inconsistent here, cygpath turns them\n    # into '.;' and ';.', and winepath ignores them completely.\n    func_stripname : : \"$1\"\n    func_to_host_path_tmp1=$func_stripname_result\n    func_convert_core_path_wine_to_w32 \"$func_to_host_path_tmp1\"\n    func_cygpath -u -p \"$func_convert_core_path_wine_to_w32_result\"\n    func_to_host_path_result=$func_cygpath_result\n    func_convert_path_check : : \\\n      \"$func_to_host_path_tmp1\" \"$func_to_host_path_result\"\n    func_convert_path_front_back_pathsep \":*\" \"*:\" : \"$1\"\n  fi\n}\n# end func_convert_path_nix_to_cygwin\n\n\n# func_dll_def_p FILE\n# True iff FILE is a Windows DLL '.def' file.\n# Keep in sync with _LT_DLL_DEF_P in libtool.m4\nfunc_dll_def_p ()\n{\n  $debug_cmd\n\n  func_dll_def_p_tmp=`$SED -n \\\n    -e 's/^[\t ]*//' \\\n    -e '/^\\(;.*\\)*$/d' \\\n    -e 's/^\\(EXPORTS\\|LIBRARY\\)\\([\t ].*\\)*$/DEF/p' \\\n    -e q \\\n    \"$1\"`\n  test DEF = \"$func_dll_def_p_tmp\"\n}\n\n\n# func_mode_compile arg...\nfunc_mode_compile ()\n{\n    $debug_cmd\n\n    # Get the compilation command and the source file.\n    base_compile=\n    srcfile=$nonopt  #  always keep a non-empty value in \"srcfile\"\n    suppress_opt=yes\n    suppress_output=\n    arg_mode=normal\n    libobj=\n    later=\n    pie_flag=\n\n    for arg\n    do\n      case $arg_mode in\n      arg  )\n\t# do not \"continue\".  Instead, add this to base_compile\n\tlastarg=$arg\n\targ_mode=normal\n\t;;\n\n      target )\n\tlibobj=$arg\n\targ_mode=normal\n\tcontinue\n\t;;\n\n      normal )\n\t# Accept any command-line options.\n\tcase $arg in\n\t-o)\n\t  test -n \"$libobj\" && \\\n\t    func_fatal_error \"you cannot specify '-o' more than once\"\n\t  arg_mode=target\n\t  continue\n\t  ;;\n\n\t-pie | -fpie | -fPIE)\n          func_append pie_flag \" $arg\"\n\t  continue\n\t  ;;\n\n\t-shared | -static | -prefer-pic | -prefer-non-pic)\n\t  func_append later \" $arg\"\n\t  continue\n\t  ;;\n\n\t-no-suppress)\n\t  suppress_opt=no\n\t  continue\n\t  ;;\n\n\t-Xcompiler)\n\t  arg_mode=arg  #  the next one goes into the \"base_compile\" arg list\n\t  continue      #  The current \"srcfile\" will either be retained or\n\t  ;;            #  replaced later.  I would guess that would be a bug.\n\n\t-Wc,*)\n\t  func_stripname '-Wc,' '' \"$arg\"\n\t  args=$func_stripname_result\n\t  lastarg=\n\t  save_ifs=$IFS; IFS=,\n\t  for arg in $args; do\n\t    IFS=$save_ifs\n\t    func_append_quoted lastarg \"$arg\"\n\t  done\n\t  IFS=$save_ifs\n\t  func_stripname ' ' '' \"$lastarg\"\n\t  lastarg=$func_stripname_result\n\n\t  # Add the arguments to base_compile.\n\t  func_append base_compile \" $lastarg\"\n\t  continue\n\t  ;;\n\n\t*)\n\t  # Accept the current argument as the source file.\n\t  # The previous \"srcfile\" becomes the current argument.\n\t  #\n\t  lastarg=$srcfile\n\t  srcfile=$arg\n\t  ;;\n\tesac  #  case $arg\n\t;;\n      esac    #  case $arg_mode\n\n      # Aesthetically quote the previous argument.\n      func_append_quoted base_compile \"$lastarg\"\n    done # for arg\n\n    case $arg_mode in\n    arg)\n      func_fatal_error \"you must specify an argument for -Xcompile\"\n      ;;\n    target)\n      func_fatal_error \"you must specify a target with '-o'\"\n      ;;\n    *)\n      # Get the name of the library object.\n      test -z \"$libobj\" && {\n\tfunc_basename \"$srcfile\"\n\tlibobj=$func_basename_result\n      }\n      ;;\n    esac\n\n    # Recognize several different file suffixes.\n    # If the user specifies -o file.o, it is replaced with file.lo\n    case $libobj in\n    *.[cCFSifmso] | \\\n    *.ada | *.adb | *.ads | *.asm | \\\n    *.c++ | *.cc | *.ii | *.class | *.cpp | *.cxx | \\\n    *.[fF][09]? | *.for | *.java | *.go | *.obj | *.sx | *.cu | *.cup)\n      func_xform \"$libobj\"\n      libobj=$func_xform_result\n      ;;\n    esac\n\n    case $libobj in\n    *.lo) func_lo2o \"$libobj\"; obj=$func_lo2o_result ;;\n    *)\n      func_fatal_error \"cannot determine name of library object from '$libobj'\"\n      ;;\n    esac\n\n    func_infer_tag $base_compile\n\n    for arg in $later; do\n      case $arg in\n      -shared)\n\ttest yes = \"$build_libtool_libs\" \\\n\t  || func_fatal_configuration \"cannot build a shared library\"\n\tbuild_old_libs=no\n\tcontinue\n\t;;\n\n      -static)\n\tbuild_libtool_libs=no\n\tbuild_old_libs=yes\n\tcontinue\n\t;;\n\n      -prefer-pic)\n\tpic_mode=yes\n\tcontinue\n\t;;\n\n      -prefer-non-pic)\n\tpic_mode=no\n\tcontinue\n\t;;\n      esac\n    done\n\n    func_quote_for_eval \"$libobj\"\n    test \"X$libobj\" != \"X$func_quote_for_eval_result\" \\\n      && $ECHO \"X$libobj\" | $GREP '[]~#^*{};<>?\"'\"'\"'\t &()|`$[]' \\\n      && func_warning \"libobj name '$libobj' may not contain shell special characters.\"\n    func_dirname_and_basename \"$obj\" \"/\" \"\"\n    objname=$func_basename_result\n    xdir=$func_dirname_result\n    lobj=$xdir$objdir/$objname\n\n    test -z \"$base_compile\" && \\\n      func_fatal_help \"you must specify a compilation command\"\n\n    # Delete any leftover library objects.\n    if test yes = \"$build_old_libs\"; then\n      removelist=\"$obj $lobj $libobj ${libobj}T\"\n    else\n      removelist=\"$lobj $libobj ${libobj}T\"\n    fi\n\n    # On Cygwin there's no \"real\" PIC flag so we must build both object types\n    case $host_os in\n    cygwin* | mingw* | pw32* | os2* | cegcc*)\n      pic_mode=default\n      ;;\n    esac\n    if test no = \"$pic_mode\" && test pass_all != \"$deplibs_check_method\"; then\n      # non-PIC code in shared libraries is not supported\n      pic_mode=default\n    fi\n\n    # Calculate the filename of the output object if compiler does\n    # not support -o with -c\n    if test no = \"$compiler_c_o\"; then\n      output_obj=`$ECHO \"$srcfile\" | $SED 's%^.*/%%; s%\\.[^.]*$%%'`.$objext\n      lockfile=$output_obj.lock\n    else\n      output_obj=\n      need_locks=no\n      lockfile=\n    fi\n\n    # Lock this critical section if it is needed\n    # We use this script file to make the link, it avoids creating a new file\n    if test yes = \"$need_locks\"; then\n      until $opt_dry_run || ln \"$progpath\" \"$lockfile\" 2>/dev/null; do\n\tfunc_echo \"Waiting for $lockfile to be removed\"\n\tsleep 2\n      done\n    elif test warn = \"$need_locks\"; then\n      if test -f \"$lockfile\"; then\n\t$ECHO \"\\\n*** ERROR, $lockfile exists and contains:\n`cat $lockfile 2>/dev/null`\n\nThis indicates that another process is trying to use the same\ntemporary object file, and libtool could not work around it because\nyour compiler does not support '-c' and '-o' together.  If you\nrepeat this compilation, it may succeed, by chance, but you had better\navoid parallel builds (make -j) in this platform, or get a better\ncompiler.\"\n\n\t$opt_dry_run || $RM $removelist\n\texit $EXIT_FAILURE\n      fi\n      func_append removelist \" $output_obj\"\n      $ECHO \"$srcfile\" > \"$lockfile\"\n    fi\n\n    $opt_dry_run || $RM $removelist\n    func_append removelist \" $lockfile\"\n    trap '$opt_dry_run || $RM $removelist; exit $EXIT_FAILURE' 1 2 15\n\n    func_to_tool_file \"$srcfile\" func_convert_file_msys_to_w32\n    srcfile=$func_to_tool_file_result\n    func_quote_for_eval \"$srcfile\"\n    qsrcfile=$func_quote_for_eval_result\n\n    # Only build a PIC object if we are building libtool libraries.\n    if test yes = \"$build_libtool_libs\"; then\n      # Without this assignment, base_compile gets emptied.\n      fbsd_hideous_sh_bug=$base_compile\n\n      if test no != \"$pic_mode\"; then\n\tcommand=\"$base_compile $qsrcfile $pic_flag\"\n      else\n\t# Don't build PIC code\n\tcommand=\"$base_compile $qsrcfile\"\n      fi\n\n      func_mkdir_p \"$xdir$objdir\"\n\n      if test -z \"$output_obj\"; then\n\t# Place PIC objects in $objdir\n\tfunc_append command \" -o $lobj\"\n      fi\n\n      func_show_eval_locale \"$command\"\t\\\n          'test -n \"$output_obj\" && $RM $removelist; exit $EXIT_FAILURE'\n\n      if test warn = \"$need_locks\" &&\n\t test \"X`cat $lockfile 2>/dev/null`\" != \"X$srcfile\"; then\n\t$ECHO \"\\\n*** ERROR, $lockfile contains:\n`cat $lockfile 2>/dev/null`\n\nbut it should contain:\n$srcfile\n\nThis indicates that another process is trying to use the same\ntemporary object file, and libtool could not work around it because\nyour compiler does not support '-c' and '-o' together.  If you\nrepeat this compilation, it may succeed, by chance, but you had better\navoid parallel builds (make -j) in this platform, or get a better\ncompiler.\"\n\n\t$opt_dry_run || $RM $removelist\n\texit $EXIT_FAILURE\n      fi\n\n      # Just move the object if needed, then go on to compile the next one\n      if test -n \"$output_obj\" && test \"X$output_obj\" != \"X$lobj\"; then\n\tfunc_show_eval '$MV \"$output_obj\" \"$lobj\"' \\\n\t  'error=$?; $opt_dry_run || $RM $removelist; exit $error'\n      fi\n\n      # Allow error messages only from the first compilation.\n      if test yes = \"$suppress_opt\"; then\n\tsuppress_output=' >/dev/null 2>&1'\n      fi\n    fi\n\n    # Only build a position-dependent object if we build old libraries.\n    if test yes = \"$build_old_libs\"; then\n      if test yes != \"$pic_mode\"; then\n\t# Don't build PIC code\n\tcommand=\"$base_compile $qsrcfile$pie_flag\"\n      else\n\tcommand=\"$base_compile $qsrcfile $pic_flag\"\n      fi\n      if test yes = \"$compiler_c_o\"; then\n\tfunc_append command \" -o $obj\"\n      fi\n\n      # Suppress compiler output if we already did a PIC compilation.\n      func_append command \"$suppress_output\"\n      func_show_eval_locale \"$command\" \\\n        '$opt_dry_run || $RM $removelist; exit $EXIT_FAILURE'\n\n      if test warn = \"$need_locks\" &&\n\t test \"X`cat $lockfile 2>/dev/null`\" != \"X$srcfile\"; then\n\t$ECHO \"\\\n*** ERROR, $lockfile contains:\n`cat $lockfile 2>/dev/null`\n\nbut it should contain:\n$srcfile\n\nThis indicates that another process is trying to use the same\ntemporary object file, and libtool could not work around it because\nyour compiler does not support '-c' and '-o' together.  If you\nrepeat this compilation, it may succeed, by chance, but you had better\navoid parallel builds (make -j) in this platform, or get a better\ncompiler.\"\n\n\t$opt_dry_run || $RM $removelist\n\texit $EXIT_FAILURE\n      fi\n\n      # Just move the object if needed\n      if test -n \"$output_obj\" && test \"X$output_obj\" != \"X$obj\"; then\n\tfunc_show_eval '$MV \"$output_obj\" \"$obj\"' \\\n\t  'error=$?; $opt_dry_run || $RM $removelist; exit $error'\n      fi\n    fi\n\n    $opt_dry_run || {\n      func_write_libtool_object \"$libobj\" \"$objdir/$objname\" \"$objname\"\n\n      # Unlock the critical section if it was locked\n      if test no != \"$need_locks\"; then\n\tremovelist=$lockfile\n        $RM \"$lockfile\"\n      fi\n    }\n\n    exit $EXIT_SUCCESS\n}\n\n$opt_help || {\n  test compile = \"$opt_mode\" && func_mode_compile ${1+\"$@\"}\n}\n\nfunc_mode_help ()\n{\n    # We need to display help for each of the modes.\n    case $opt_mode in\n      \"\")\n        # Generic help is extracted from the usage comments\n        # at the start of this file.\n        func_help\n        ;;\n\n      clean)\n        $ECHO \\\n\"Usage: $progname [OPTION]... --mode=clean RM [RM-OPTION]... FILE...\n\nRemove files from the build directory.\n\nRM is the name of the program to use to delete files associated with each FILE\n(typically '/bin/rm').  RM-OPTIONS are options (such as '-f') to be passed\nto RM.\n\nIf FILE is a libtool library, object or program, all the files associated\nwith it are deleted. Otherwise, only FILE itself is deleted using RM.\"\n        ;;\n\n      compile)\n      $ECHO \\\n\"Usage: $progname [OPTION]... --mode=compile COMPILE-COMMAND... SOURCEFILE\n\nCompile a source file into a libtool library object.\n\nThis mode accepts the following additional options:\n\n  -o OUTPUT-FILE    set the output file name to OUTPUT-FILE\n  -no-suppress      do not suppress compiler output for multiple passes\n  -prefer-pic       try to build PIC objects only\n  -prefer-non-pic   try to build non-PIC objects only\n  -shared           do not build a '.o' file suitable for static linking\n  -static           only build a '.o' file suitable for static linking\n  -Wc,FLAG          pass FLAG directly to the compiler\n\nCOMPILE-COMMAND is a command to be used in creating a 'standard' object file\nfrom the given SOURCEFILE.\n\nThe output file name is determined by removing the directory component from\nSOURCEFILE, then substituting the C source code suffix '.c' with the\nlibrary object suffix, '.lo'.\"\n        ;;\n\n      execute)\n        $ECHO \\\n\"Usage: $progname [OPTION]... --mode=execute COMMAND [ARGS]...\n\nAutomatically set library path, then run a program.\n\nThis mode accepts the following additional options:\n\n  -dlopen FILE      add the directory containing FILE to the library path\n\nThis mode sets the library path environment variable according to '-dlopen'\nflags.\n\nIf any of the ARGS are libtool executable wrappers, then they are translated\ninto their corresponding uninstalled binary, and any of their required library\ndirectories are added to the library path.\n\nThen, COMMAND is executed, with ARGS as arguments.\"\n        ;;\n\n      finish)\n        $ECHO \\\n\"Usage: $progname [OPTION]... --mode=finish [LIBDIR]...\n\nComplete the installation of libtool libraries.\n\nEach LIBDIR is a directory that contains libtool libraries.\n\nThe commands that this mode executes may require superuser privileges.  Use\nthe '--dry-run' option if you just want to see what would be executed.\"\n        ;;\n\n      install)\n        $ECHO \\\n\"Usage: $progname [OPTION]... --mode=install INSTALL-COMMAND...\n\nInstall executables or libraries.\n\nINSTALL-COMMAND is the installation command.  The first component should be\neither the 'install' or 'cp' program.\n\nThe following components of INSTALL-COMMAND are treated specially:\n\n  -inst-prefix-dir PREFIX-DIR  Use PREFIX-DIR as a staging area for installation\n\nThe rest of the components are interpreted as arguments to that command (only\nBSD-compatible install options are recognized).\"\n        ;;\n\n      link)\n        $ECHO \\\n\"Usage: $progname [OPTION]... --mode=link LINK-COMMAND...\n\nLink object files or libraries together to form another library, or to\ncreate an executable program.\n\nLINK-COMMAND is a command using the C compiler that you would use to create\na program from several object files.\n\nThe following components of LINK-COMMAND are treated specially:\n\n  -all-static       do not do any dynamic linking at all\n  -avoid-version    do not add a version suffix if possible\n  -bindir BINDIR    specify path to binaries directory (for systems where\n                    libraries must be found in the PATH setting at runtime)\n  -dlopen FILE      '-dlpreopen' FILE if it cannot be dlopened at runtime\n  -dlpreopen FILE   link in FILE and add its symbols to lt_preloaded_symbols\n  -export-dynamic   allow symbols from OUTPUT-FILE to be resolved with dlsym(3)\n  -export-symbols SYMFILE\n                    try to export only the symbols listed in SYMFILE\n  -export-symbols-regex REGEX\n                    try to export only the symbols matching REGEX\n  -LLIBDIR          search LIBDIR for required installed libraries\n  -lNAME            OUTPUT-FILE requires the installed library libNAME\n  -module           build a library that can dlopened\n  -no-fast-install  disable the fast-install mode\n  -no-install       link a not-installable executable\n  -no-undefined     declare that a library does not refer to external symbols\n  -o OUTPUT-FILE    create OUTPUT-FILE from the specified objects\n  -objectlist FILE  use a list of object files found in FILE to specify objects\n  -os2dllname NAME  force a short DLL name on OS/2 (no effect on other OSes)\n  -precious-files-regex REGEX\n                    don't remove output files matching REGEX\n  -release RELEASE  specify package release information\n  -rpath LIBDIR     the created library will eventually be installed in LIBDIR\n  -R[ ]LIBDIR       add LIBDIR to the runtime path of programs and libraries\n  -shared           only do dynamic linking of libtool libraries\n  -shrext SUFFIX    override the standard shared library file extension\n  -static           do not do any dynamic linking of uninstalled libtool libraries\n  -static-libtool-libs\n                    do not do any dynamic linking of libtool libraries\n  -version-info CURRENT[:REVISION[:AGE]]\n                    specify library version info [each variable defaults to 0]\n  -weak LIBNAME     declare that the target provides the LIBNAME interface\n  -Wc,FLAG\n  -Xcompiler FLAG   pass linker-specific FLAG directly to the compiler\n  -Wl,FLAG\n  -Xlinker FLAG     pass linker-specific FLAG directly to the linker\n  -XCClinker FLAG   pass link-specific FLAG to the compiler driver (CC)\n\nAll other options (arguments beginning with '-') are ignored.\n\nEvery other argument is treated as a filename.  Files ending in '.la' are\ntreated as uninstalled libtool libraries, other files are standard or library\nobject files.\n\nIf the OUTPUT-FILE ends in '.la', then a libtool library is created,\nonly library objects ('.lo' files) may be specified, and '-rpath' is\nrequired, except when creating a convenience library.\n\nIf OUTPUT-FILE ends in '.a' or '.lib', then a standard library is created\nusing 'ar' and 'ranlib', or on Windows using 'lib'.\n\nIf OUTPUT-FILE ends in '.lo' or '.$objext', then a reloadable object file\nis created, otherwise an executable program is created.\"\n        ;;\n\n      uninstall)\n        $ECHO \\\n\"Usage: $progname [OPTION]... --mode=uninstall RM [RM-OPTION]... FILE...\n\nRemove libraries from an installation directory.\n\nRM is the name of the program to use to delete files associated with each FILE\n(typically '/bin/rm').  RM-OPTIONS are options (such as '-f') to be passed\nto RM.\n\nIf FILE is a libtool library, all the files associated with it are deleted.\nOtherwise, only FILE itself is deleted using RM.\"\n        ;;\n\n      *)\n        func_fatal_help \"invalid operation mode '$opt_mode'\"\n        ;;\n    esac\n\n    echo\n    $ECHO \"Try '$progname --help' for more information about other modes.\"\n}\n\n# Now that we've collected a possible --mode arg, show help if necessary\nif $opt_help; then\n  if test : = \"$opt_help\"; then\n    func_mode_help\n  else\n    {\n      func_help noexit\n      for opt_mode in compile link execute install finish uninstall clean; do\n\tfunc_mode_help\n      done\n    } | $SED -n '1p; 2,$s/^Usage:/  or: /p'\n    {\n      func_help noexit\n      for opt_mode in compile link execute install finish uninstall clean; do\n\techo\n\tfunc_mode_help\n      done\n    } |\n    $SED '1d\n      /^When reporting/,/^Report/{\n\tH\n\td\n      }\n      $x\n      /information about other modes/d\n      /more detailed .*MODE/d\n      s/^Usage:.*--mode=\\([^ ]*\\) .*/Description of \\1 mode:/'\n  fi\n  exit $?\nfi\n\n\n# func_mode_execute arg...\nfunc_mode_execute ()\n{\n    $debug_cmd\n\n    # The first argument is the command name.\n    cmd=$nonopt\n    test -z \"$cmd\" && \\\n      func_fatal_help \"you must specify a COMMAND\"\n\n    # Handle -dlopen flags immediately.\n    for file in $opt_dlopen; do\n      test -f \"$file\" \\\n\t|| func_fatal_help \"'$file' is not a file\"\n\n      dir=\n      case $file in\n      *.la)\n\tfunc_resolve_sysroot \"$file\"\n\tfile=$func_resolve_sysroot_result\n\n\t# Check to see that this really is a libtool archive.\n\tfunc_lalib_unsafe_p \"$file\" \\\n\t  || func_fatal_help \"'$lib' is not a valid libtool archive\"\n\n\t# Read the libtool library.\n\tdlname=\n\tlibrary_names=\n\tfunc_source \"$file\"\n\n\t# Skip this library if it cannot be dlopened.\n\tif test -z \"$dlname\"; then\n\t  # Warn if it was a shared library.\n\t  test -n \"$library_names\" && \\\n\t    func_warning \"'$file' was not linked with '-export-dynamic'\"\n\t  continue\n\tfi\n\n\tfunc_dirname \"$file\" \"\" \".\"\n\tdir=$func_dirname_result\n\n\tif test -f \"$dir/$objdir/$dlname\"; then\n\t  func_append dir \"/$objdir\"\n\telse\n\t  if test ! -f \"$dir/$dlname\"; then\n\t    func_fatal_error \"cannot find '$dlname' in '$dir' or '$dir/$objdir'\"\n\t  fi\n\tfi\n\t;;\n\n      *.lo)\n\t# Just add the directory containing the .lo file.\n\tfunc_dirname \"$file\" \"\" \".\"\n\tdir=$func_dirname_result\n\t;;\n\n      *)\n\tfunc_warning \"'-dlopen' is ignored for non-libtool libraries and objects\"\n\tcontinue\n\t;;\n      esac\n\n      # Get the absolute pathname.\n      absdir=`cd \"$dir\" && pwd`\n      test -n \"$absdir\" && dir=$absdir\n\n      # Now add the directory to shlibpath_var.\n      if eval \"test -z \\\"\\$$shlibpath_var\\\"\"; then\n\teval \"$shlibpath_var=\\\"\\$dir\\\"\"\n      else\n\teval \"$shlibpath_var=\\\"\\$dir:\\$$shlibpath_var\\\"\"\n      fi\n    done\n\n    # This variable tells wrapper scripts just to set shlibpath_var\n    # rather than running their programs.\n    libtool_execute_magic=$magic\n\n    # Check if any of the arguments is a wrapper script.\n    args=\n    for file\n    do\n      case $file in\n      -* | *.la | *.lo ) ;;\n      *)\n\t# Do a test to see if this is really a libtool program.\n\tif func_ltwrapper_script_p \"$file\"; then\n\t  func_source \"$file\"\n\t  # Transform arg to wrapped name.\n\t  file=$progdir/$program\n\telif func_ltwrapper_executable_p \"$file\"; then\n\t  func_ltwrapper_scriptname \"$file\"\n\t  func_source \"$func_ltwrapper_scriptname_result\"\n\t  # Transform arg to wrapped name.\n\t  file=$progdir/$program\n\tfi\n\t;;\n      esac\n      # Quote arguments (to preserve shell metacharacters).\n      func_append_quoted args \"$file\"\n    done\n\n    if $opt_dry_run; then\n      # Display what would be done.\n      if test -n \"$shlibpath_var\"; then\n\teval \"\\$ECHO \\\"\\$shlibpath_var=\\$$shlibpath_var\\\"\"\n\techo \"export $shlibpath_var\"\n      fi\n      $ECHO \"$cmd$args\"\n      exit $EXIT_SUCCESS\n    else\n      if test -n \"$shlibpath_var\"; then\n\t# Export the shlibpath_var.\n\teval \"export $shlibpath_var\"\n      fi\n\n      # Restore saved environment variables\n      for lt_var in LANG LANGUAGE LC_ALL LC_CTYPE LC_COLLATE LC_MESSAGES\n      do\n\teval \"if test \\\"\\${save_$lt_var+set}\\\" = set; then\n                $lt_var=\\$save_$lt_var; export $lt_var\n\t      else\n\t\t$lt_unset $lt_var\n\t      fi\"\n      done\n\n      # Now prepare to actually exec the command.\n      exec_cmd=\\$cmd$args\n    fi\n}\n\ntest execute = \"$opt_mode\" && func_mode_execute ${1+\"$@\"}\n\n\n# func_mode_finish arg...\nfunc_mode_finish ()\n{\n    $debug_cmd\n\n    libs=\n    libdirs=\n    admincmds=\n\n    for opt in \"$nonopt\" ${1+\"$@\"}\n    do\n      if test -d \"$opt\"; then\n\tfunc_append libdirs \" $opt\"\n\n      elif test -f \"$opt\"; then\n\tif func_lalib_unsafe_p \"$opt\"; then\n\t  func_append libs \" $opt\"\n\telse\n\t  func_warning \"'$opt' is not a valid libtool archive\"\n\tfi\n\n      else\n\tfunc_fatal_error \"invalid argument '$opt'\"\n      fi\n    done\n\n    if test -n \"$libs\"; then\n      if test -n \"$lt_sysroot\"; then\n        sysroot_regex=`$ECHO \"$lt_sysroot\" | $SED \"$sed_make_literal_regex\"`\n        sysroot_cmd=\"s/\\([ ']\\)$sysroot_regex/\\1/g;\"\n      else\n        sysroot_cmd=\n      fi\n\n      # Remove sysroot references\n      if $opt_dry_run; then\n        for lib in $libs; do\n          echo \"removing references to $lt_sysroot and '=' prefixes from $lib\"\n        done\n      else\n        tmpdir=`func_mktempdir`\n        for lib in $libs; do\n\t  $SED -e \"$sysroot_cmd s/\\([ ']-[LR]\\)=/\\1/g; s/\\([ ']\\)=/\\1/g\" $lib \\\n\t    > $tmpdir/tmp-la\n\t  mv -f $tmpdir/tmp-la $lib\n\tdone\n        ${RM}r \"$tmpdir\"\n      fi\n    fi\n\n    if test -n \"$finish_cmds$finish_eval\" && test -n \"$libdirs\"; then\n      for libdir in $libdirs; do\n\tif test -n \"$finish_cmds\"; then\n\t  # Do each command in the finish commands.\n\t  func_execute_cmds \"$finish_cmds\" 'admincmds=\"$admincmds\n'\"$cmd\"'\"'\n\tfi\n\tif test -n \"$finish_eval\"; then\n\t  # Do the single finish_eval.\n\t  eval cmds=\\\"$finish_eval\\\"\n\t  $opt_dry_run || eval \"$cmds\" || func_append admincmds \"\n       $cmds\"\n\tfi\n      done\n    fi\n\n    # Exit here if they wanted silent mode.\n    $opt_quiet && exit $EXIT_SUCCESS\n\n    if test -n \"$finish_cmds$finish_eval\" && test -n \"$libdirs\"; then\n      echo \"----------------------------------------------------------------------\"\n      echo \"Libraries have been installed in:\"\n      for libdir in $libdirs; do\n\t$ECHO \"   $libdir\"\n      done\n      echo\n      echo \"If you ever happen to want to link against installed libraries\"\n      echo \"in a given directory, LIBDIR, you must either use libtool, and\"\n      echo \"specify the full pathname of the library, or use the '-LLIBDIR'\"\n      echo \"flag during linking and do at least one of the following:\"\n      if test -n \"$shlibpath_var\"; then\n\techo \"   - add LIBDIR to the '$shlibpath_var' environment variable\"\n\techo \"     during execution\"\n      fi\n      if test -n \"$runpath_var\"; then\n\techo \"   - add LIBDIR to the '$runpath_var' environment variable\"\n\techo \"     during linking\"\n      fi\n      if test -n \"$hardcode_libdir_flag_spec\"; then\n\tlibdir=LIBDIR\n\teval flag=\\\"$hardcode_libdir_flag_spec\\\"\n\n\t$ECHO \"   - use the '$flag' linker flag\"\n      fi\n      if test -n \"$admincmds\"; then\n\t$ECHO \"   - have your system administrator run these commands:$admincmds\"\n      fi\n      if test -f /etc/ld.so.conf; then\n\techo \"   - have your system administrator add LIBDIR to '/etc/ld.so.conf'\"\n      fi\n      echo\n\n      echo \"See any operating system documentation about shared libraries for\"\n      case $host in\n\tsolaris2.[6789]|solaris2.1[0-9])\n\t  echo \"more information, such as the ld(1), crle(1) and ld.so(8) manual\"\n\t  echo \"pages.\"\n\t  ;;\n\t*)\n\t  echo \"more information, such as the ld(1) and ld.so(8) manual pages.\"\n\t  ;;\n      esac\n      echo \"----------------------------------------------------------------------\"\n    fi\n    exit $EXIT_SUCCESS\n}\n\ntest finish = \"$opt_mode\" && func_mode_finish ${1+\"$@\"}\n\n\n# func_mode_install arg...\nfunc_mode_install ()\n{\n    $debug_cmd\n\n    # There may be an optional sh(1) argument at the beginning of\n    # install_prog (especially on Windows NT).\n    if test \"$SHELL\" = \"$nonopt\" || test /bin/sh = \"$nonopt\" ||\n       # Allow the use of GNU shtool's install command.\n       case $nonopt in *shtool*) :;; *) false;; esac\n    then\n      # Aesthetically quote it.\n      func_quote_for_eval \"$nonopt\"\n      install_prog=\"$func_quote_for_eval_result \"\n      arg=$1\n      shift\n    else\n      install_prog=\n      arg=$nonopt\n    fi\n\n    # The real first argument should be the name of the installation program.\n    # Aesthetically quote it.\n    func_quote_for_eval \"$arg\"\n    func_append install_prog \"$func_quote_for_eval_result\"\n    install_shared_prog=$install_prog\n    case \" $install_prog \" in\n      *[\\\\\\ /]cp\\ *) install_cp=: ;;\n      *) install_cp=false ;;\n    esac\n\n    # We need to accept at least all the BSD install flags.\n    dest=\n    files=\n    opts=\n    prev=\n    install_type=\n    isdir=false\n    stripme=\n    no_mode=:\n    for arg\n    do\n      arg2=\n      if test -n \"$dest\"; then\n\tfunc_append files \" $dest\"\n\tdest=$arg\n\tcontinue\n      fi\n\n      case $arg in\n      -d) isdir=: ;;\n      -f)\n\tif $install_cp; then :; else\n\t  prev=$arg\n\tfi\n\t;;\n      -g | -m | -o)\n\tprev=$arg\n\t;;\n      -s)\n\tstripme=\" -s\"\n\tcontinue\n\t;;\n      -*)\n\t;;\n      *)\n\t# If the previous option needed an argument, then skip it.\n\tif test -n \"$prev\"; then\n\t  if test X-m = \"X$prev\" && test -n \"$install_override_mode\"; then\n\t    arg2=$install_override_mode\n\t    no_mode=false\n\t  fi\n\t  prev=\n\telse\n\t  dest=$arg\n\t  continue\n\tfi\n\t;;\n      esac\n\n      # Aesthetically quote the argument.\n      func_quote_for_eval \"$arg\"\n      func_append install_prog \" $func_quote_for_eval_result\"\n      if test -n \"$arg2\"; then\n\tfunc_quote_for_eval \"$arg2\"\n      fi\n      func_append install_shared_prog \" $func_quote_for_eval_result\"\n    done\n\n    test -z \"$install_prog\" && \\\n      func_fatal_help \"you must specify an install program\"\n\n    test -n \"$prev\" && \\\n      func_fatal_help \"the '$prev' option requires an argument\"\n\n    if test -n \"$install_override_mode\" && $no_mode; then\n      if $install_cp; then :; else\n\tfunc_quote_for_eval \"$install_override_mode\"\n\tfunc_append install_shared_prog \" -m $func_quote_for_eval_result\"\n      fi\n    fi\n\n    if test -z \"$files\"; then\n      if test -z \"$dest\"; then\n\tfunc_fatal_help \"no file or destination specified\"\n      else\n\tfunc_fatal_help \"you must specify a destination\"\n      fi\n    fi\n\n    # Strip any trailing slash from the destination.\n    func_stripname '' '/' \"$dest\"\n    dest=$func_stripname_result\n\n    # Check to see that the destination is a directory.\n    test -d \"$dest\" && isdir=:\n    if $isdir; then\n      destdir=$dest\n      destname=\n    else\n      func_dirname_and_basename \"$dest\" \"\" \".\"\n      destdir=$func_dirname_result\n      destname=$func_basename_result\n\n      # Not a directory, so check to see that there is only one file specified.\n      set dummy $files; shift\n      test \"$#\" -gt 1 && \\\n\tfunc_fatal_help \"'$dest' is not a directory\"\n    fi\n    case $destdir in\n    [\\\\/]* | [A-Za-z]:[\\\\/]*) ;;\n    *)\n      for file in $files; do\n\tcase $file in\n\t*.lo) ;;\n\t*)\n\t  func_fatal_help \"'$destdir' must be an absolute directory name\"\n\t  ;;\n\tesac\n      done\n      ;;\n    esac\n\n    # This variable tells wrapper scripts just to set variables rather\n    # than running their programs.\n    libtool_install_magic=$magic\n\n    staticlibs=\n    future_libdirs=\n    current_libdirs=\n    for file in $files; do\n\n      # Do each installation.\n      case $file in\n      *.$libext)\n\t# Do the static libraries later.\n\tfunc_append staticlibs \" $file\"\n\t;;\n\n      *.la)\n\tfunc_resolve_sysroot \"$file\"\n\tfile=$func_resolve_sysroot_result\n\n\t# Check to see that this really is a libtool archive.\n\tfunc_lalib_unsafe_p \"$file\" \\\n\t  || func_fatal_help \"'$file' is not a valid libtool archive\"\n\n\tlibrary_names=\n\told_library=\n\trelink_command=\n\tfunc_source \"$file\"\n\n\t# Add the libdir to current_libdirs if it is the destination.\n\tif test \"X$destdir\" = \"X$libdir\"; then\n\t  case \"$current_libdirs \" in\n\t  *\" $libdir \"*) ;;\n\t  *) func_append current_libdirs \" $libdir\" ;;\n\t  esac\n\telse\n\t  # Note the libdir as a future libdir.\n\t  case \"$future_libdirs \" in\n\t  *\" $libdir \"*) ;;\n\t  *) func_append future_libdirs \" $libdir\" ;;\n\t  esac\n\tfi\n\n\tfunc_dirname \"$file\" \"/\" \"\"\n\tdir=$func_dirname_result\n\tfunc_append dir \"$objdir\"\n\n\tif test -n \"$relink_command\"; then\n\t  # Determine the prefix the user has applied to our future dir.\n\t  inst_prefix_dir=`$ECHO \"$destdir\" | $SED -e \"s%$libdir\\$%%\"`\n\n\t  # Don't allow the user to place us outside of our expected\n\t  # location b/c this prevents finding dependent libraries that\n\t  # are installed to the same prefix.\n\t  # At present, this check doesn't affect windows .dll's that\n\t  # are installed into $libdir/../bin (currently, that works fine)\n\t  # but it's something to keep an eye on.\n\t  test \"$inst_prefix_dir\" = \"$destdir\" && \\\n\t    func_fatal_error \"error: cannot install '$file' to a directory not ending in $libdir\"\n\n\t  if test -n \"$inst_prefix_dir\"; then\n\t    # Stick the inst_prefix_dir data into the link command.\n\t    relink_command=`$ECHO \"$relink_command\" | $SED \"s%@inst_prefix_dir@%-inst-prefix-dir $inst_prefix_dir%\"`\n\t  else\n\t    relink_command=`$ECHO \"$relink_command\" | $SED \"s%@inst_prefix_dir@%%\"`\n\t  fi\n\n\t  func_warning \"relinking '$file'\"\n\t  func_show_eval \"$relink_command\" \\\n\t    'func_fatal_error \"error: relink '\\''$file'\\'' with the above command before installing it\"'\n\tfi\n\n\t# See the names of the shared library.\n\tset dummy $library_names; shift\n\tif test -n \"$1\"; then\n\t  realname=$1\n\t  shift\n\n\t  srcname=$realname\n\t  test -n \"$relink_command\" && srcname=${realname}T\n\n\t  # Install the shared library and build the symlinks.\n\t  func_show_eval \"$install_shared_prog $dir/$srcname $destdir/$realname\" \\\n\t      'exit $?'\n\t  tstripme=$stripme\n\t  case $host_os in\n\t  cygwin* | mingw* | pw32* | cegcc*)\n\t    case $realname in\n\t    *.dll.a)\n\t      tstripme=\n\t      ;;\n\t    esac\n\t    ;;\n\t  os2*)\n\t    case $realname in\n\t    *_dll.a)\n\t      tstripme=\n\t      ;;\n\t    esac\n\t    ;;\n\t  esac\n\t  if test -n \"$tstripme\" && test -n \"$striplib\"; then\n\t    func_show_eval \"$striplib $destdir/$realname\" 'exit $?'\n\t  fi\n\n\t  if test \"$#\" -gt 0; then\n\t    # Delete the old symlinks, and create new ones.\n\t    # Try 'ln -sf' first, because the 'ln' binary might depend on\n\t    # the symlink we replace!  Solaris /bin/ln does not understand -f,\n\t    # so we also need to try rm && ln -s.\n\t    for linkname\n\t    do\n\t      test \"$linkname\" != \"$realname\" \\\n\t\t&& func_show_eval \"(cd $destdir && { $LN_S -f $realname $linkname || { $RM $linkname && $LN_S $realname $linkname; }; })\"\n\t    done\n\t  fi\n\n\t  # Do each command in the postinstall commands.\n\t  lib=$destdir/$realname\n\t  func_execute_cmds \"$postinstall_cmds\" 'exit $?'\n\tfi\n\n\t# Install the pseudo-library for information purposes.\n\tfunc_basename \"$file\"\n\tname=$func_basename_result\n\tinstname=$dir/${name}i\n\tfunc_show_eval \"$install_prog $instname $destdir/$name\" 'exit $?'\n\n\t# Maybe install the static library, too.\n\ttest -n \"$old_library\" && func_append staticlibs \" $dir/$old_library\"\n\t;;\n\n      *.lo)\n\t# Install (i.e. copy) a libtool object.\n\n\t# Figure out destination file name, if it wasn't already specified.\n\tif test -n \"$destname\"; then\n\t  destfile=$destdir/$destname\n\telse\n\t  func_basename \"$file\"\n\t  destfile=$func_basename_result\n\t  destfile=$destdir/$destfile\n\tfi\n\n\t# Deduce the name of the destination old-style object file.\n\tcase $destfile in\n\t*.lo)\n\t  func_lo2o \"$destfile\"\n\t  staticdest=$func_lo2o_result\n\t  ;;\n\t*.$objext)\n\t  staticdest=$destfile\n\t  destfile=\n\t  ;;\n\t*)\n\t  func_fatal_help \"cannot copy a libtool object to '$destfile'\"\n\t  ;;\n\tesac\n\n\t# Install the libtool object if requested.\n\ttest -n \"$destfile\" && \\\n\t  func_show_eval \"$install_prog $file $destfile\" 'exit $?'\n\n\t# Install the old object if enabled.\n\tif test yes = \"$build_old_libs\"; then\n\t  # Deduce the name of the old-style object file.\n\t  func_lo2o \"$file\"\n\t  staticobj=$func_lo2o_result\n\t  func_show_eval \"$install_prog \\$staticobj \\$staticdest\" 'exit $?'\n\tfi\n\texit $EXIT_SUCCESS\n\t;;\n\n      *)\n\t# Figure out destination file name, if it wasn't already specified.\n\tif test -n \"$destname\"; then\n\t  destfile=$destdir/$destname\n\telse\n\t  func_basename \"$file\"\n\t  destfile=$func_basename_result\n\t  destfile=$destdir/$destfile\n\tfi\n\n\t# If the file is missing, and there is a .exe on the end, strip it\n\t# because it is most likely a libtool script we actually want to\n\t# install\n\tstripped_ext=\n\tcase $file in\n\t  *.exe)\n\t    if test ! -f \"$file\"; then\n\t      func_stripname '' '.exe' \"$file\"\n\t      file=$func_stripname_result\n\t      stripped_ext=.exe\n\t    fi\n\t    ;;\n\tesac\n\n\t# Do a test to see if this is really a libtool program.\n\tcase $host in\n\t*cygwin* | *mingw*)\n\t    if func_ltwrapper_executable_p \"$file\"; then\n\t      func_ltwrapper_scriptname \"$file\"\n\t      wrapper=$func_ltwrapper_scriptname_result\n\t    else\n\t      func_stripname '' '.exe' \"$file\"\n\t      wrapper=$func_stripname_result\n\t    fi\n\t    ;;\n\t*)\n\t    wrapper=$file\n\t    ;;\n\tesac\n\tif func_ltwrapper_script_p \"$wrapper\"; then\n\t  notinst_deplibs=\n\t  relink_command=\n\n\t  func_source \"$wrapper\"\n\n\t  # Check the variables that should have been set.\n\t  test -z \"$generated_by_libtool_version\" && \\\n\t    func_fatal_error \"invalid libtool wrapper script '$wrapper'\"\n\n\t  finalize=:\n\t  for lib in $notinst_deplibs; do\n\t    # Check to see that each library is installed.\n\t    libdir=\n\t    if test -f \"$lib\"; then\n\t      func_source \"$lib\"\n\t    fi\n\t    libfile=$libdir/`$ECHO \"$lib\" | $SED 's%^.*/%%g'`\n\t    if test -n \"$libdir\" && test ! -f \"$libfile\"; then\n\t      func_warning \"'$lib' has not been installed in '$libdir'\"\n\t      finalize=false\n\t    fi\n\t  done\n\n\t  relink_command=\n\t  func_source \"$wrapper\"\n\n\t  outputname=\n\t  if test no = \"$fast_install\" && test -n \"$relink_command\"; then\n\t    $opt_dry_run || {\n\t      if $finalize; then\n\t        tmpdir=`func_mktempdir`\n\t\tfunc_basename \"$file$stripped_ext\"\n\t\tfile=$func_basename_result\n\t        outputname=$tmpdir/$file\n\t        # Replace the output file specification.\n\t        relink_command=`$ECHO \"$relink_command\" | $SED 's%@OUTPUT@%'\"$outputname\"'%g'`\n\n\t        $opt_quiet || {\n\t          func_quote_for_expand \"$relink_command\"\n\t\t  eval \"func_echo $func_quote_for_expand_result\"\n\t        }\n\t        if eval \"$relink_command\"; then :\n\t          else\n\t\t  func_error \"error: relink '$file' with the above command before installing it\"\n\t\t  $opt_dry_run || ${RM}r \"$tmpdir\"\n\t\t  continue\n\t        fi\n\t        file=$outputname\n\t      else\n\t        func_warning \"cannot relink '$file'\"\n\t      fi\n\t    }\n\t  else\n\t    # Install the binary that we compiled earlier.\n\t    file=`$ECHO \"$file$stripped_ext\" | $SED \"s%\\([^/]*\\)$%$objdir/\\1%\"`\n\t  fi\n\tfi\n\n\t# remove .exe since cygwin /usr/bin/install will append another\n\t# one anyway\n\tcase $install_prog,$host in\n\t*/usr/bin/install*,*cygwin*)\n\t  case $file:$destfile in\n\t  *.exe:*.exe)\n\t    # this is ok\n\t    ;;\n\t  *.exe:*)\n\t    destfile=$destfile.exe\n\t    ;;\n\t  *:*.exe)\n\t    func_stripname '' '.exe' \"$destfile\"\n\t    destfile=$func_stripname_result\n\t    ;;\n\t  esac\n\t  ;;\n\tesac\n\tfunc_show_eval \"$install_prog\\$stripme \\$file \\$destfile\" 'exit $?'\n\t$opt_dry_run || if test -n \"$outputname\"; then\n\t  ${RM}r \"$tmpdir\"\n\tfi\n\t;;\n      esac\n    done\n\n    for file in $staticlibs; do\n      func_basename \"$file\"\n      name=$func_basename_result\n\n      # Set up the ranlib parameters.\n      oldlib=$destdir/$name\n      func_to_tool_file \"$oldlib\" func_convert_file_msys_to_w32\n      tool_oldlib=$func_to_tool_file_result\n\n      func_show_eval \"$install_prog \\$file \\$oldlib\" 'exit $?'\n\n      if test -n \"$stripme\" && test -n \"$old_striplib\"; then\n\tfunc_show_eval \"$old_striplib $tool_oldlib\" 'exit $?'\n      fi\n\n      # Do each command in the postinstall commands.\n      func_execute_cmds \"$old_postinstall_cmds\" 'exit $?'\n    done\n\n    test -n \"$future_libdirs\" && \\\n      func_warning \"remember to run '$progname --finish$future_libdirs'\"\n\n    if test -n \"$current_libdirs\"; then\n      # Maybe just do a dry run.\n      $opt_dry_run && current_libdirs=\" -n$current_libdirs\"\n      exec_cmd='$SHELL \"$progpath\" $preserve_args --finish$current_libdirs'\n    else\n      exit $EXIT_SUCCESS\n    fi\n}\n\ntest install = \"$opt_mode\" && func_mode_install ${1+\"$@\"}\n\n\n# func_generate_dlsyms outputname originator pic_p\n# Extract symbols from dlprefiles and create ${outputname}S.o with\n# a dlpreopen symbol table.\nfunc_generate_dlsyms ()\n{\n    $debug_cmd\n\n    my_outputname=$1\n    my_originator=$2\n    my_pic_p=${3-false}\n    my_prefix=`$ECHO \"$my_originator\" | $SED 's%[^a-zA-Z0-9]%_%g'`\n    my_dlsyms=\n\n    if test -n \"$dlfiles$dlprefiles\" || test no != \"$dlself\"; then\n      if test -n \"$NM\" && test -n \"$global_symbol_pipe\"; then\n\tmy_dlsyms=${my_outputname}S.c\n      else\n\tfunc_error \"not configured to extract global symbols from dlpreopened files\"\n      fi\n    fi\n\n    if test -n \"$my_dlsyms\"; then\n      case $my_dlsyms in\n      \"\") ;;\n      *.c)\n\t# Discover the nlist of each of the dlfiles.\n\tnlist=$output_objdir/$my_outputname.nm\n\n\tfunc_show_eval \"$RM $nlist ${nlist}S ${nlist}T\"\n\n\t# Parse the name list into a source file.\n\tfunc_verbose \"creating $output_objdir/$my_dlsyms\"\n\n\t$opt_dry_run || $ECHO > \"$output_objdir/$my_dlsyms\" \"\\\n/* $my_dlsyms - symbol resolution table for '$my_outputname' dlsym emulation. */\n/* Generated by $PROGRAM (GNU $PACKAGE) $VERSION */\n\n#ifdef __cplusplus\nextern \\\"C\\\" {\n#endif\n\n#if defined __GNUC__ && (((__GNUC__ == 4) && (__GNUC_MINOR__ >= 4)) || (__GNUC__ > 4))\n#pragma GCC diagnostic ignored \\\"-Wstrict-prototypes\\\"\n#endif\n\n/* Keep this code in sync between libtool.m4, ltmain, lt_system.h, and tests.  */\n#if defined _WIN32 || defined __CYGWIN__ || defined _WIN32_WCE\n/* DATA imports from DLLs on WIN32 can't be const, because runtime\n   relocations are performed -- see ld's documentation on pseudo-relocs.  */\n# define LT_DLSYM_CONST\n#elif defined __osf__\n/* This system does not cope well with relocations in const data.  */\n# define LT_DLSYM_CONST\n#else\n# define LT_DLSYM_CONST const\n#endif\n\n#define STREQ(s1, s2) (strcmp ((s1), (s2)) == 0)\n\n/* External symbol declarations for the compiler. */\\\n\"\n\n\tif test yes = \"$dlself\"; then\n\t  func_verbose \"generating symbol list for '$output'\"\n\n\t  $opt_dry_run || echo ': @PROGRAM@ ' > \"$nlist\"\n\n\t  # Add our own program objects to the symbol list.\n\t  progfiles=`$ECHO \"$objs$old_deplibs\" | $SP2NL | $SED \"$lo2o\" | $NL2SP`\n\t  for progfile in $progfiles; do\n\t    func_to_tool_file \"$progfile\" func_convert_file_msys_to_w32\n\t    func_verbose \"extracting global C symbols from '$func_to_tool_file_result'\"\n\t    $opt_dry_run || eval \"$NM $func_to_tool_file_result | $global_symbol_pipe >> '$nlist'\"\n\t  done\n\n\t  if test -n \"$exclude_expsyms\"; then\n\t    $opt_dry_run || {\n\t      eval '$EGREP -v \" ($exclude_expsyms)$\" \"$nlist\" > \"$nlist\"T'\n\t      eval '$MV \"$nlist\"T \"$nlist\"'\n\t    }\n\t  fi\n\n\t  if test -n \"$export_symbols_regex\"; then\n\t    $opt_dry_run || {\n\t      eval '$EGREP -e \"$export_symbols_regex\" \"$nlist\" > \"$nlist\"T'\n\t      eval '$MV \"$nlist\"T \"$nlist\"'\n\t    }\n\t  fi\n\n\t  # Prepare the list of exported symbols\n\t  if test -z \"$export_symbols\"; then\n\t    export_symbols=$output_objdir/$outputname.exp\n\t    $opt_dry_run || {\n\t      $RM $export_symbols\n\t      eval \"$SED -n -e '/^: @PROGRAM@ $/d' -e 's/^.* \\(.*\\)$/\\1/p' \"'< \"$nlist\" > \"$export_symbols\"'\n\t      case $host in\n\t      *cygwin* | *mingw* | *cegcc* )\n                eval \"echo EXPORTS \"'> \"$output_objdir/$outputname.def\"'\n                eval 'cat \"$export_symbols\" >> \"$output_objdir/$outputname.def\"'\n\t        ;;\n\t      esac\n\t    }\n\t  else\n\t    $opt_dry_run || {\n\t      eval \"$SED -e 's/\\([].[*^$]\\)/\\\\\\\\\\1/g' -e 's/^/ /' -e 's/$/$/'\"' < \"$export_symbols\" > \"$output_objdir/$outputname.exp\"'\n\t      eval '$GREP -f \"$output_objdir/$outputname.exp\" < \"$nlist\" > \"$nlist\"T'\n\t      eval '$MV \"$nlist\"T \"$nlist\"'\n\t      case $host in\n\t        *cygwin* | *mingw* | *cegcc* )\n\t          eval \"echo EXPORTS \"'> \"$output_objdir/$outputname.def\"'\n\t          eval 'cat \"$nlist\" >> \"$output_objdir/$outputname.def\"'\n\t          ;;\n\t      esac\n\t    }\n\t  fi\n\tfi\n\n\tfor dlprefile in $dlprefiles; do\n\t  func_verbose \"extracting global C symbols from '$dlprefile'\"\n\t  func_basename \"$dlprefile\"\n\t  name=$func_basename_result\n          case $host in\n\t    *cygwin* | *mingw* | *cegcc* )\n\t      # if an import library, we need to obtain dlname\n\t      if func_win32_import_lib_p \"$dlprefile\"; then\n\t        func_tr_sh \"$dlprefile\"\n\t        eval \"curr_lafile=\\$libfile_$func_tr_sh_result\"\n\t        dlprefile_dlbasename=\n\t        if test -n \"$curr_lafile\" && func_lalib_p \"$curr_lafile\"; then\n\t          # Use subshell, to avoid clobbering current variable values\n\t          dlprefile_dlname=`source \"$curr_lafile\" && echo \"$dlname\"`\n\t          if test -n \"$dlprefile_dlname\"; then\n\t            func_basename \"$dlprefile_dlname\"\n\t            dlprefile_dlbasename=$func_basename_result\n\t          else\n\t            # no lafile. user explicitly requested -dlpreopen <import library>.\n\t            $sharedlib_from_linklib_cmd \"$dlprefile\"\n\t            dlprefile_dlbasename=$sharedlib_from_linklib_result\n\t          fi\n\t        fi\n\t        $opt_dry_run || {\n\t          if test -n \"$dlprefile_dlbasename\"; then\n\t            eval '$ECHO \": $dlprefile_dlbasename\" >> \"$nlist\"'\n\t          else\n\t            func_warning \"Could not compute DLL name from $name\"\n\t            eval '$ECHO \": $name \" >> \"$nlist\"'\n\t          fi\n\t          func_to_tool_file \"$dlprefile\" func_convert_file_msys_to_w32\n\t          eval \"$NM \\\"$func_to_tool_file_result\\\" 2>/dev/null | $global_symbol_pipe |\n\t            $SED -e '/I __imp/d' -e 's/I __nm_/D /;s/_nm__//' >> '$nlist'\"\n\t        }\n\t      else # not an import lib\n\t        $opt_dry_run || {\n\t          eval '$ECHO \": $name \" >> \"$nlist\"'\n\t          func_to_tool_file \"$dlprefile\" func_convert_file_msys_to_w32\n\t          eval \"$NM \\\"$func_to_tool_file_result\\\" 2>/dev/null | $global_symbol_pipe >> '$nlist'\"\n\t        }\n\t      fi\n\t    ;;\n\t    *)\n\t      $opt_dry_run || {\n\t        eval '$ECHO \": $name \" >> \"$nlist\"'\n\t        func_to_tool_file \"$dlprefile\" func_convert_file_msys_to_w32\n\t        eval \"$NM \\\"$func_to_tool_file_result\\\" 2>/dev/null | $global_symbol_pipe >> '$nlist'\"\n\t      }\n\t    ;;\n          esac\n\tdone\n\n\t$opt_dry_run || {\n\t  # Make sure we have at least an empty file.\n\t  test -f \"$nlist\" || : > \"$nlist\"\n\n\t  if test -n \"$exclude_expsyms\"; then\n\t    $EGREP -v \" ($exclude_expsyms)$\" \"$nlist\" > \"$nlist\"T\n\t    $MV \"$nlist\"T \"$nlist\"\n\t  fi\n\n\t  # Try sorting and uniquifying the output.\n\t  if $GREP -v \"^: \" < \"$nlist\" |\n\t      if sort -k 3 </dev/null >/dev/null 2>&1; then\n\t\tsort -k 3\n\t      else\n\t\tsort +2\n\t      fi |\n\t      uniq > \"$nlist\"S; then\n\t    :\n\t  else\n\t    $GREP -v \"^: \" < \"$nlist\" > \"$nlist\"S\n\t  fi\n\n\t  if test -f \"$nlist\"S; then\n\t    eval \"$global_symbol_to_cdecl\"' < \"$nlist\"S >> \"$output_objdir/$my_dlsyms\"'\n\t  else\n\t    echo '/* NONE */' >> \"$output_objdir/$my_dlsyms\"\n\t  fi\n\n\t  func_show_eval '$RM \"${nlist}I\"'\n\t  if test -n \"$global_symbol_to_import\"; then\n\t    eval \"$global_symbol_to_import\"' < \"$nlist\"S > \"$nlist\"I'\n\t  fi\n\n\t  echo >> \"$output_objdir/$my_dlsyms\" \"\\\n\n/* The mapping between symbol names and symbols.  */\ntypedef struct {\n  const char *name;\n  void *address;\n} lt_dlsymlist;\nextern LT_DLSYM_CONST lt_dlsymlist\nlt_${my_prefix}_LTX_preloaded_symbols[];\\\n\"\n\n\t  if test -s \"$nlist\"I; then\n\t    echo >> \"$output_objdir/$my_dlsyms\" \"\\\nstatic void lt_syminit(void)\n{\n  LT_DLSYM_CONST lt_dlsymlist *symbol = lt_${my_prefix}_LTX_preloaded_symbols;\n  for (; symbol->name; ++symbol)\n    {\"\n\t    $SED 's/.*/      if (STREQ (symbol->name, \\\"&\\\")) symbol->address = (void *) \\&&;/' < \"$nlist\"I >> \"$output_objdir/$my_dlsyms\"\n\t    echo >> \"$output_objdir/$my_dlsyms\" \"\\\n    }\n}\"\n\t  fi\n\t  echo >> \"$output_objdir/$my_dlsyms\" \"\\\nLT_DLSYM_CONST lt_dlsymlist\nlt_${my_prefix}_LTX_preloaded_symbols[] =\n{ {\\\"$my_originator\\\", (void *) 0},\"\n\n\t  if test -s \"$nlist\"I; then\n\t    echo >> \"$output_objdir/$my_dlsyms\" \"\\\n  {\\\"@INIT@\\\", (void *) &lt_syminit},\"\n\t  fi\n\n\t  case $need_lib_prefix in\n\t  no)\n\t    eval \"$global_symbol_to_c_name_address\" < \"$nlist\" >> \"$output_objdir/$my_dlsyms\"\n\t    ;;\n\t  *)\n\t    eval \"$global_symbol_to_c_name_address_lib_prefix\" < \"$nlist\" >> \"$output_objdir/$my_dlsyms\"\n\t    ;;\n\t  esac\n\t  echo >> \"$output_objdir/$my_dlsyms\" \"\\\n  {0, (void *) 0}\n};\n\n/* This works around a problem in FreeBSD linker */\n#ifdef FREEBSD_WORKAROUND\nstatic const void *lt_preloaded_setup() {\n  return lt_${my_prefix}_LTX_preloaded_symbols;\n}\n#endif\n\n#ifdef __cplusplus\n}\n#endif\\\n\"\n\t} # !$opt_dry_run\n\n\tpic_flag_for_symtable=\n\tcase \"$compile_command \" in\n\t*\" -static \"*) ;;\n\t*)\n\t  case $host in\n\t  # compiling the symbol table file with pic_flag works around\n\t  # a FreeBSD bug that causes programs to crash when -lm is\n\t  # linked before any other PIC object.  But we must not use\n\t  # pic_flag when linking with -static.  The problem exists in\n\t  # FreeBSD 2.2.6 and is fixed in FreeBSD 3.1.\n\t  *-*-freebsd2.*|*-*-freebsd3.0*|*-*-freebsdelf3.0*)\n\t    pic_flag_for_symtable=\" $pic_flag -DFREEBSD_WORKAROUND\" ;;\n\t  *-*-hpux*)\n\t    pic_flag_for_symtable=\" $pic_flag\"  ;;\n\t  *)\n\t    $my_pic_p && pic_flag_for_symtable=\" $pic_flag\"\n\t    ;;\n\t  esac\n\t  ;;\n\tesac\n\tsymtab_cflags=\n\tfor arg in $LTCFLAGS; do\n\t  case $arg in\n\t  -pie | -fpie | -fPIE) ;;\n\t  *) func_append symtab_cflags \" $arg\" ;;\n\t  esac\n\tdone\n\n\t# Now compile the dynamic symbol file.\n\tfunc_show_eval '(cd $output_objdir && $LTCC$symtab_cflags -c$no_builtin_flag$pic_flag_for_symtable \"$my_dlsyms\")' 'exit $?'\n\n\t# Clean up the generated files.\n\tfunc_show_eval '$RM \"$output_objdir/$my_dlsyms\" \"$nlist\" \"${nlist}S\" \"${nlist}T\" \"${nlist}I\"'\n\n\t# Transform the symbol file into the correct name.\n\tsymfileobj=$output_objdir/${my_outputname}S.$objext\n\tcase $host in\n\t*cygwin* | *mingw* | *cegcc* )\n\t  if test -f \"$output_objdir/$my_outputname.def\"; then\n\t    compile_command=`$ECHO \"$compile_command\" | $SED \"s%@SYMFILE@%$output_objdir/$my_outputname.def $symfileobj%\"`\n\t    finalize_command=`$ECHO \"$finalize_command\" | $SED \"s%@SYMFILE@%$output_objdir/$my_outputname.def $symfileobj%\"`\n\t  else\n\t    compile_command=`$ECHO \"$compile_command\" | $SED \"s%@SYMFILE@%$symfileobj%\"`\n\t    finalize_command=`$ECHO \"$finalize_command\" | $SED \"s%@SYMFILE@%$symfileobj%\"`\n\t  fi\n\t  ;;\n\t*)\n\t  compile_command=`$ECHO \"$compile_command\" | $SED \"s%@SYMFILE@%$symfileobj%\"`\n\t  finalize_command=`$ECHO \"$finalize_command\" | $SED \"s%@SYMFILE@%$symfileobj%\"`\n\t  ;;\n\tesac\n\t;;\n      *)\n\tfunc_fatal_error \"unknown suffix for '$my_dlsyms'\"\n\t;;\n      esac\n    else\n      # We keep going just in case the user didn't refer to\n      # lt_preloaded_symbols.  The linker will fail if global_symbol_pipe\n      # really was required.\n\n      # Nullify the symbol file.\n      compile_command=`$ECHO \"$compile_command\" | $SED \"s% @SYMFILE@%%\"`\n      finalize_command=`$ECHO \"$finalize_command\" | $SED \"s% @SYMFILE@%%\"`\n    fi\n}\n\n# func_cygming_gnu_implib_p ARG\n# This predicate returns with zero status (TRUE) if\n# ARG is a GNU/binutils-style import library. Returns\n# with nonzero status (FALSE) otherwise.\nfunc_cygming_gnu_implib_p ()\n{\n  $debug_cmd\n\n  func_to_tool_file \"$1\" func_convert_file_msys_to_w32\n  func_cygming_gnu_implib_tmp=`$NM \"$func_to_tool_file_result\" | eval \"$global_symbol_pipe\" | $EGREP ' (_head_[A-Za-z0-9_]+_[ad]l*|[A-Za-z0-9_]+_[ad]l*_iname)$'`\n  test -n \"$func_cygming_gnu_implib_tmp\"\n}\n\n# func_cygming_ms_implib_p ARG\n# This predicate returns with zero status (TRUE) if\n# ARG is an MS-style import library. Returns\n# with nonzero status (FALSE) otherwise.\nfunc_cygming_ms_implib_p ()\n{\n  $debug_cmd\n\n  func_to_tool_file \"$1\" func_convert_file_msys_to_w32\n  func_cygming_ms_implib_tmp=`$NM \"$func_to_tool_file_result\" | eval \"$global_symbol_pipe\" | $GREP '_NULL_IMPORT_DESCRIPTOR'`\n  test -n \"$func_cygming_ms_implib_tmp\"\n}\n\n# func_win32_libid arg\n# return the library type of file 'arg'\n#\n# Need a lot of goo to handle *both* DLLs and import libs\n# Has to be a shell function in order to 'eat' the argument\n# that is supplied when $file_magic_command is called.\n# Despite the name, also deal with 64 bit binaries.\nfunc_win32_libid ()\n{\n  $debug_cmd\n\n  win32_libid_type=unknown\n  win32_fileres=`file -L $1 2>/dev/null`\n  case $win32_fileres in\n  *ar\\ archive\\ import\\ library*) # definitely import\n    win32_libid_type=\"x86 archive import\"\n    ;;\n  *ar\\ archive*) # could be an import, or static\n    # Keep the egrep pattern in sync with the one in _LT_CHECK_MAGIC_METHOD.\n    if eval $OBJDUMP -f $1 | $SED -e '10q' 2>/dev/null |\n       $EGREP 'file format (pei*-i386(.*architecture: i386)?|pe-arm-wince|pe-x86-64)' >/dev/null; then\n      case $nm_interface in\n      \"MS dumpbin\")\n\tif func_cygming_ms_implib_p \"$1\" ||\n\t   func_cygming_gnu_implib_p \"$1\"\n\tthen\n\t  win32_nmres=import\n\telse\n\t  win32_nmres=\n\tfi\n\t;;\n      *)\n\tfunc_to_tool_file \"$1\" func_convert_file_msys_to_w32\n\twin32_nmres=`eval $NM -f posix -A \\\"$func_to_tool_file_result\\\" |\n\t  $SED -n -e '\n\t    1,100{\n\t\t/ I /{\n\t\t    s|.*|import|\n\t\t    p\n\t\t    q\n\t\t}\n\t    }'`\n\t;;\n      esac\n      case $win32_nmres in\n      import*)  win32_libid_type=\"x86 archive import\";;\n      *)        win32_libid_type=\"x86 archive static\";;\n      esac\n    fi\n    ;;\n  *DLL*)\n    win32_libid_type=\"x86 DLL\"\n    ;;\n  *executable*) # but shell scripts are \"executable\" too...\n    case $win32_fileres in\n    *MS\\ Windows\\ PE\\ Intel*)\n      win32_libid_type=\"x86 DLL\"\n      ;;\n    esac\n    ;;\n  esac\n  $ECHO \"$win32_libid_type\"\n}\n\n# func_cygming_dll_for_implib ARG\n#\n# Platform-specific function to extract the\n# name of the DLL associated with the specified\n# import library ARG.\n# Invoked by eval'ing the libtool variable\n#    $sharedlib_from_linklib_cmd\n# Result is available in the variable\n#    $sharedlib_from_linklib_result\nfunc_cygming_dll_for_implib ()\n{\n  $debug_cmd\n\n  sharedlib_from_linklib_result=`$DLLTOOL --identify-strict --identify \"$1\"`\n}\n\n# func_cygming_dll_for_implib_fallback_core SECTION_NAME LIBNAMEs\n#\n# The is the core of a fallback implementation of a\n# platform-specific function to extract the name of the\n# DLL associated with the specified import library LIBNAME.\n#\n# SECTION_NAME is either .idata$6 or .idata$7, depending\n# on the platform and compiler that created the implib.\n#\n# Echos the name of the DLL associated with the\n# specified import library.\nfunc_cygming_dll_for_implib_fallback_core ()\n{\n  $debug_cmd\n\n  match_literal=`$ECHO \"$1\" | $SED \"$sed_make_literal_regex\"`\n  $OBJDUMP -s --section \"$1\" \"$2\" 2>/dev/null |\n    $SED '/^Contents of section '\"$match_literal\"':/{\n      # Place marker at beginning of archive member dllname section\n      s/.*/====MARK====/\n      p\n      d\n    }\n    # These lines can sometimes be longer than 43 characters, but\n    # are always uninteresting\n    /:[\t ]*file format pe[i]\\{,1\\}-/d\n    /^In archive [^:]*:/d\n    # Ensure marker is printed\n    /^====MARK====/p\n    # Remove all lines with less than 43 characters\n    /^.\\{43\\}/!d\n    # From remaining lines, remove first 43 characters\n    s/^.\\{43\\}//' |\n    $SED -n '\n      # Join marker and all lines until next marker into a single line\n      /^====MARK====/ b para\n      H\n      $ b para\n      b\n      :para\n      x\n      s/\\n//g\n      # Remove the marker\n      s/^====MARK====//\n      # Remove trailing dots and whitespace\n      s/[\\. \\t]*$//\n      # Print\n      /./p' |\n    # we now have a list, one entry per line, of the stringified\n    # contents of the appropriate section of all members of the\n    # archive that possess that section. Heuristic: eliminate\n    # all those that have a first or second character that is\n    # a '.' (that is, objdump's representation of an unprintable\n    # character.) This should work for all archives with less than\n    # 0x302f exports -- but will fail for DLLs whose name actually\n    # begins with a literal '.' or a single character followed by\n    # a '.'.\n    #\n    # Of those that remain, print the first one.\n    $SED -e '/^\\./d;/^.\\./d;q'\n}\n\n# func_cygming_dll_for_implib_fallback ARG\n# Platform-specific function to extract the\n# name of the DLL associated with the specified\n# import library ARG.\n#\n# This fallback implementation is for use when $DLLTOOL\n# does not support the --identify-strict option.\n# Invoked by eval'ing the libtool variable\n#    $sharedlib_from_linklib_cmd\n# Result is available in the variable\n#    $sharedlib_from_linklib_result\nfunc_cygming_dll_for_implib_fallback ()\n{\n  $debug_cmd\n\n  if func_cygming_gnu_implib_p \"$1\"; then\n    # binutils import library\n    sharedlib_from_linklib_result=`func_cygming_dll_for_implib_fallback_core '.idata$7' \"$1\"`\n  elif func_cygming_ms_implib_p \"$1\"; then\n    # ms-generated import library\n    sharedlib_from_linklib_result=`func_cygming_dll_for_implib_fallback_core '.idata$6' \"$1\"`\n  else\n    # unknown\n    sharedlib_from_linklib_result=\n  fi\n}\n\n\n# func_extract_an_archive dir oldlib\nfunc_extract_an_archive ()\n{\n    $debug_cmd\n\n    f_ex_an_ar_dir=$1; shift\n    f_ex_an_ar_oldlib=$1\n    if test yes = \"$lock_old_archive_extraction\"; then\n      lockfile=$f_ex_an_ar_oldlib.lock\n      until $opt_dry_run || ln \"$progpath\" \"$lockfile\" 2>/dev/null; do\n\tfunc_echo \"Waiting for $lockfile to be removed\"\n\tsleep 2\n      done\n    fi\n    func_show_eval \"(cd \\$f_ex_an_ar_dir && $AR x \\\"\\$f_ex_an_ar_oldlib\\\")\" \\\n\t\t   'stat=$?; rm -f \"$lockfile\"; exit $stat'\n    if test yes = \"$lock_old_archive_extraction\"; then\n      $opt_dry_run || rm -f \"$lockfile\"\n    fi\n    if ($AR t \"$f_ex_an_ar_oldlib\" | sort | sort -uc >/dev/null 2>&1); then\n     :\n    else\n      func_fatal_error \"object name conflicts in archive: $f_ex_an_ar_dir/$f_ex_an_ar_oldlib\"\n    fi\n}\n\n\n# func_extract_archives gentop oldlib ...\nfunc_extract_archives ()\n{\n    $debug_cmd\n\n    my_gentop=$1; shift\n    my_oldlibs=${1+\"$@\"}\n    my_oldobjs=\n    my_xlib=\n    my_xabs=\n    my_xdir=\n\n    for my_xlib in $my_oldlibs; do\n      # Extract the objects.\n      case $my_xlib in\n\t[\\\\/]* | [A-Za-z]:[\\\\/]*) my_xabs=$my_xlib ;;\n\t*) my_xabs=`pwd`\"/$my_xlib\" ;;\n      esac\n      func_basename \"$my_xlib\"\n      my_xlib=$func_basename_result\n      my_xlib_u=$my_xlib\n      while :; do\n        case \" $extracted_archives \" in\n\t*\" $my_xlib_u \"*)\n\t  func_arith $extracted_serial + 1\n\t  extracted_serial=$func_arith_result\n\t  my_xlib_u=lt$extracted_serial-$my_xlib ;;\n\t*) break ;;\n\tesac\n      done\n      extracted_archives=\"$extracted_archives $my_xlib_u\"\n      my_xdir=$my_gentop/$my_xlib_u\n\n      func_mkdir_p \"$my_xdir\"\n\n      case $host in\n      *-darwin*)\n\tfunc_verbose \"Extracting $my_xabs\"\n\t# Do not bother doing anything if just a dry run\n\t$opt_dry_run || {\n\t  darwin_orig_dir=`pwd`\n\t  cd $my_xdir || exit $?\n\t  darwin_archive=$my_xabs\n\t  darwin_curdir=`pwd`\n\t  func_basename \"$darwin_archive\"\n\t  darwin_base_archive=$func_basename_result\n\t  darwin_arches=`$LIPO -info \"$darwin_archive\" 2>/dev/null | $GREP Architectures 2>/dev/null || true`\n\t  if test -n \"$darwin_arches\"; then\n\t    darwin_arches=`$ECHO \"$darwin_arches\" | $SED -e 's/.*are://'`\n\t    darwin_arch=\n\t    func_verbose \"$darwin_base_archive has multiple architectures $darwin_arches\"\n\t    for darwin_arch in  $darwin_arches; do\n\t      func_mkdir_p \"unfat-$$/$darwin_base_archive-$darwin_arch\"\n\t      $LIPO -thin $darwin_arch -output \"unfat-$$/$darwin_base_archive-$darwin_arch/$darwin_base_archive\" \"$darwin_archive\"\n\t      cd \"unfat-$$/$darwin_base_archive-$darwin_arch\"\n\t      func_extract_an_archive \"`pwd`\" \"$darwin_base_archive\"\n\t      cd \"$darwin_curdir\"\n\t      $RM \"unfat-$$/$darwin_base_archive-$darwin_arch/$darwin_base_archive\"\n\t    done # $darwin_arches\n            ## Okay now we've a bunch of thin objects, gotta fatten them up :)\n\t    darwin_filelist=`find unfat-$$ -type f -name \\*.o -print -o -name \\*.lo -print | $SED -e \"$sed_basename\" | sort -u`\n\t    darwin_file=\n\t    darwin_files=\n\t    for darwin_file in $darwin_filelist; do\n\t      darwin_files=`find unfat-$$ -name $darwin_file -print | sort | $NL2SP`\n\t      $LIPO -create -output \"$darwin_file\" $darwin_files\n\t    done # $darwin_filelist\n\t    $RM -rf unfat-$$\n\t    cd \"$darwin_orig_dir\"\n\t  else\n\t    cd $darwin_orig_dir\n\t    func_extract_an_archive \"$my_xdir\" \"$my_xabs\"\n\t  fi # $darwin_arches\n\t} # !$opt_dry_run\n\t;;\n      *)\n        func_extract_an_archive \"$my_xdir\" \"$my_xabs\"\n\t;;\n      esac\n      my_oldobjs=\"$my_oldobjs \"`find $my_xdir -name \\*.$objext -print -o -name \\*.lo -print | sort | $NL2SP`\n    done\n\n    func_extract_archives_result=$my_oldobjs\n}\n\n\n# func_emit_wrapper [arg=no]\n#\n# Emit a libtool wrapper script on stdout.\n# Don't directly open a file because we may want to\n# incorporate the script contents within a cygwin/mingw\n# wrapper executable.  Must ONLY be called from within\n# func_mode_link because it depends on a number of variables\n# set therein.\n#\n# ARG is the value that the WRAPPER_SCRIPT_BELONGS_IN_OBJDIR\n# variable will take.  If 'yes', then the emitted script\n# will assume that the directory where it is stored is\n# the $objdir directory.  This is a cygwin/mingw-specific\n# behavior.\nfunc_emit_wrapper ()\n{\n\tfunc_emit_wrapper_arg1=${1-no}\n\n\t$ECHO \"\\\n#! $SHELL\n\n# $output - temporary wrapper script for $objdir/$outputname\n# Generated by $PROGRAM (GNU $PACKAGE) $VERSION\n#\n# The $output program cannot be directly executed until all the libtool\n# libraries that it depends on are installed.\n#\n# This wrapper script should never be moved out of the build directory.\n# If it is, it will not operate correctly.\n\n# Sed substitution that helps us do robust quoting.  It backslashifies\n# metacharacters that are still active within double-quoted strings.\nsed_quote_subst='$sed_quote_subst'\n\n# Be Bourne compatible\nif test -n \\\"\\${ZSH_VERSION+set}\\\" && (emulate sh) >/dev/null 2>&1; then\n  emulate sh\n  NULLCMD=:\n  # Zsh 3.x and 4.x performs word splitting on \\${1+\\\"\\$@\\\"}, which\n  # is contrary to our usage.  Disable this feature.\n  alias -g '\\${1+\\\"\\$@\\\"}'='\\\"\\$@\\\"'\n  setopt NO_GLOB_SUBST\nelse\n  case \\`(set -o) 2>/dev/null\\` in *posix*) set -o posix;; esac\nfi\nBIN_SH=xpg4; export BIN_SH # for Tru64\nDUALCASE=1; export DUALCASE # for MKS sh\n\n# The HP-UX ksh and POSIX shell print the target directory to stdout\n# if CDPATH is set.\n(unset CDPATH) >/dev/null 2>&1 && unset CDPATH\n\nrelink_command=\\\"$relink_command\\\"\n\n# This environment variable determines our operation mode.\nif test \\\"\\$libtool_install_magic\\\" = \\\"$magic\\\"; then\n  # install mode needs the following variables:\n  generated_by_libtool_version='$macro_version'\n  notinst_deplibs='$notinst_deplibs'\nelse\n  # When we are sourced in execute mode, \\$file and \\$ECHO are already set.\n  if test \\\"\\$libtool_execute_magic\\\" != \\\"$magic\\\"; then\n    file=\\\"\\$0\\\"\"\n\n    qECHO=`$ECHO \"$ECHO\" | $SED \"$sed_quote_subst\"`\n    $ECHO \"\\\n\n# A function that is used when there is no print builtin or printf.\nfunc_fallback_echo ()\n{\n  eval 'cat <<_LTECHO_EOF\n\\$1\n_LTECHO_EOF'\n}\n    ECHO=\\\"$qECHO\\\"\n  fi\n\n# Very basic option parsing. These options are (a) specific to\n# the libtool wrapper, (b) are identical between the wrapper\n# /script/ and the wrapper /executable/ that is used only on\n# windows platforms, and (c) all begin with the string \"--lt-\"\n# (application programs are unlikely to have options that match\n# this pattern).\n#\n# There are only two supported options: --lt-debug and\n# --lt-dump-script. There is, deliberately, no --lt-help.\n#\n# The first argument to this parsing function should be the\n# script's $0 value, followed by \"$@\".\nlt_option_debug=\nfunc_parse_lt_options ()\n{\n  lt_script_arg0=\\$0\n  shift\n  for lt_opt\n  do\n    case \\\"\\$lt_opt\\\" in\n    --lt-debug) lt_option_debug=1 ;;\n    --lt-dump-script)\n        lt_dump_D=\\`\\$ECHO \\\"X\\$lt_script_arg0\\\" | $SED -e 's/^X//' -e 's%/[^/]*$%%'\\`\n        test \\\"X\\$lt_dump_D\\\" = \\\"X\\$lt_script_arg0\\\" && lt_dump_D=.\n        lt_dump_F=\\`\\$ECHO \\\"X\\$lt_script_arg0\\\" | $SED -e 's/^X//' -e 's%^.*/%%'\\`\n        cat \\\"\\$lt_dump_D/\\$lt_dump_F\\\"\n        exit 0\n      ;;\n    --lt-*)\n        \\$ECHO \\\"Unrecognized --lt- option: '\\$lt_opt'\\\" 1>&2\n        exit 1\n      ;;\n    esac\n  done\n\n  # Print the debug banner immediately:\n  if test -n \\\"\\$lt_option_debug\\\"; then\n    echo \\\"$outputname:$output:\\$LINENO: libtool wrapper (GNU $PACKAGE) $VERSION\\\" 1>&2\n  fi\n}\n\n# Used when --lt-debug. Prints its arguments to stdout\n# (redirection is the responsibility of the caller)\nfunc_lt_dump_args ()\n{\n  lt_dump_args_N=1;\n  for lt_arg\n  do\n    \\$ECHO \\\"$outputname:$output:\\$LINENO: newargv[\\$lt_dump_args_N]: \\$lt_arg\\\"\n    lt_dump_args_N=\\`expr \\$lt_dump_args_N + 1\\`\n  done\n}\n\n# Core function for launching the target application\nfunc_exec_program_core ()\n{\n\"\n  case $host in\n  # Backslashes separate directories on plain windows\n  *-*-mingw | *-*-os2* | *-cegcc*)\n    $ECHO \"\\\n      if test -n \\\"\\$lt_option_debug\\\"; then\n        \\$ECHO \\\"$outputname:$output:\\$LINENO: newargv[0]: \\$progdir\\\\\\\\\\$program\\\" 1>&2\n        func_lt_dump_args \\${1+\\\"\\$@\\\"} 1>&2\n      fi\n      exec \\\"\\$progdir\\\\\\\\\\$program\\\" \\${1+\\\"\\$@\\\"}\n\"\n    ;;\n\n  *)\n    $ECHO \"\\\n      if test -n \\\"\\$lt_option_debug\\\"; then\n        \\$ECHO \\\"$outputname:$output:\\$LINENO: newargv[0]: \\$progdir/\\$program\\\" 1>&2\n        func_lt_dump_args \\${1+\\\"\\$@\\\"} 1>&2\n      fi\n      exec \\\"\\$progdir/\\$program\\\" \\${1+\\\"\\$@\\\"}\n\"\n    ;;\n  esac\n  $ECHO \"\\\n      \\$ECHO \\\"\\$0: cannot exec \\$program \\$*\\\" 1>&2\n      exit 1\n}\n\n# A function to encapsulate launching the target application\n# Strips options in the --lt-* namespace from \\$@ and\n# launches target application with the remaining arguments.\nfunc_exec_program ()\n{\n  case \\\" \\$* \\\" in\n  *\\\\ --lt-*)\n    for lt_wr_arg\n    do\n      case \\$lt_wr_arg in\n      --lt-*) ;;\n      *) set x \\\"\\$@\\\" \\\"\\$lt_wr_arg\\\"; shift;;\n      esac\n      shift\n    done ;;\n  esac\n  func_exec_program_core \\${1+\\\"\\$@\\\"}\n}\n\n  # Parse options\n  func_parse_lt_options \\\"\\$0\\\" \\${1+\\\"\\$@\\\"}\n\n  # Find the directory that this script lives in.\n  thisdir=\\`\\$ECHO \\\"\\$file\\\" | $SED 's%/[^/]*$%%'\\`\n  test \\\"x\\$thisdir\\\" = \\\"x\\$file\\\" && thisdir=.\n\n  # Follow symbolic links until we get to the real thisdir.\n  file=\\`ls -ld \\\"\\$file\\\" | $SED -n 's/.*-> //p'\\`\n  while test -n \\\"\\$file\\\"; do\n    destdir=\\`\\$ECHO \\\"\\$file\\\" | $SED 's%/[^/]*\\$%%'\\`\n\n    # If there was a directory component, then change thisdir.\n    if test \\\"x\\$destdir\\\" != \\\"x\\$file\\\"; then\n      case \\\"\\$destdir\\\" in\n      [\\\\\\\\/]* | [A-Za-z]:[\\\\\\\\/]*) thisdir=\\\"\\$destdir\\\" ;;\n      *) thisdir=\\\"\\$thisdir/\\$destdir\\\" ;;\n      esac\n    fi\n\n    file=\\`\\$ECHO \\\"\\$file\\\" | $SED 's%^.*/%%'\\`\n    file=\\`ls -ld \\\"\\$thisdir/\\$file\\\" | $SED -n 's/.*-> //p'\\`\n  done\n\n  # Usually 'no', except on cygwin/mingw when embedded into\n  # the cwrapper.\n  WRAPPER_SCRIPT_BELONGS_IN_OBJDIR=$func_emit_wrapper_arg1\n  if test \\\"\\$WRAPPER_SCRIPT_BELONGS_IN_OBJDIR\\\" = \\\"yes\\\"; then\n    # special case for '.'\n    if test \\\"\\$thisdir\\\" = \\\".\\\"; then\n      thisdir=\\`pwd\\`\n    fi\n    # remove .libs from thisdir\n    case \\\"\\$thisdir\\\" in\n    *[\\\\\\\\/]$objdir ) thisdir=\\`\\$ECHO \\\"\\$thisdir\\\" | $SED 's%[\\\\\\\\/][^\\\\\\\\/]*$%%'\\` ;;\n    $objdir )   thisdir=. ;;\n    esac\n  fi\n\n  # Try to get the absolute directory name.\n  absdir=\\`cd \\\"\\$thisdir\\\" && pwd\\`\n  test -n \\\"\\$absdir\\\" && thisdir=\\\"\\$absdir\\\"\n\"\n\n\tif test yes = \"$fast_install\"; then\n\t  $ECHO \"\\\n  program=lt-'$outputname'$exeext\n  progdir=\\\"\\$thisdir/$objdir\\\"\n\n  if test ! -f \\\"\\$progdir/\\$program\\\" ||\n     { file=\\`ls -1dt \\\"\\$progdir/\\$program\\\" \\\"\\$progdir/../\\$program\\\" 2>/dev/null | $SED 1q\\`; \\\\\n       test \\\"X\\$file\\\" != \\\"X\\$progdir/\\$program\\\"; }; then\n\n    file=\\\"\\$\\$-\\$program\\\"\n\n    if test ! -d \\\"\\$progdir\\\"; then\n      $MKDIR \\\"\\$progdir\\\"\n    else\n      $RM \\\"\\$progdir/\\$file\\\"\n    fi\"\n\n\t  $ECHO \"\\\n\n    # relink executable if necessary\n    if test -n \\\"\\$relink_command\\\"; then\n      if relink_command_output=\\`eval \\$relink_command 2>&1\\`; then :\n      else\n\t\\$ECHO \\\"\\$relink_command_output\\\" >&2\n\t$RM \\\"\\$progdir/\\$file\\\"\n\texit 1\n      fi\n    fi\n\n    $MV \\\"\\$progdir/\\$file\\\" \\\"\\$progdir/\\$program\\\" 2>/dev/null ||\n    { $RM \\\"\\$progdir/\\$program\\\";\n      $MV \\\"\\$progdir/\\$file\\\" \\\"\\$progdir/\\$program\\\"; }\n    $RM \\\"\\$progdir/\\$file\\\"\n  fi\"\n\telse\n\t  $ECHO \"\\\n  program='$outputname'\n  progdir=\\\"\\$thisdir/$objdir\\\"\n\"\n\tfi\n\n\t$ECHO \"\\\n\n  if test -f \\\"\\$progdir/\\$program\\\"; then\"\n\n\t# fixup the dll searchpath if we need to.\n\t#\n\t# Fix the DLL searchpath if we need to.  Do this before prepending\n\t# to shlibpath, because on Windows, both are PATH and uninstalled\n\t# libraries must come first.\n\tif test -n \"$dllsearchpath\"; then\n\t  $ECHO \"\\\n    # Add the dll search path components to the executable PATH\n    PATH=$dllsearchpath:\\$PATH\n\"\n\tfi\n\n\t# Export our shlibpath_var if we have one.\n\tif test yes = \"$shlibpath_overrides_runpath\" && test -n \"$shlibpath_var\" && test -n \"$temp_rpath\"; then\n\t  $ECHO \"\\\n    # Add our own library path to $shlibpath_var\n    $shlibpath_var=\\\"$temp_rpath\\$$shlibpath_var\\\"\n\n    # Some systems cannot cope with colon-terminated $shlibpath_var\n    # The second colon is a workaround for a bug in BeOS R4 sed\n    $shlibpath_var=\\`\\$ECHO \\\"\\$$shlibpath_var\\\" | $SED 's/::*\\$//'\\`\n\n    export $shlibpath_var\n\"\n\tfi\n\n\t$ECHO \"\\\n    if test \\\"\\$libtool_execute_magic\\\" != \\\"$magic\\\"; then\n      # Run the actual program with our arguments.\n      func_exec_program \\${1+\\\"\\$@\\\"}\n    fi\n  else\n    # The program doesn't exist.\n    \\$ECHO \\\"\\$0: error: '\\$progdir/\\$program' does not exist\\\" 1>&2\n    \\$ECHO \\\"This script is just a wrapper for \\$program.\\\" 1>&2\n    \\$ECHO \\\"See the $PACKAGE documentation for more information.\\\" 1>&2\n    exit 1\n  fi\nfi\\\n\"\n}\n\n\n# func_emit_cwrapperexe_src\n# emit the source code for a wrapper executable on stdout\n# Must ONLY be called from within func_mode_link because\n# it depends on a number of variable set therein.\nfunc_emit_cwrapperexe_src ()\n{\n\tcat <<EOF\n\n/* $cwrappersource - temporary wrapper executable for $objdir/$outputname\n   Generated by $PROGRAM (GNU $PACKAGE) $VERSION\n\n   The $output program cannot be directly executed until all the libtool\n   libraries that it depends on are installed.\n\n   This wrapper executable should never be moved out of the build directory.\n   If it is, it will not operate correctly.\n*/\nEOF\n\t    cat <<\"EOF\"\n#ifdef _MSC_VER\n# define _CRT_SECURE_NO_DEPRECATE 1\n#endif\n#include <stdio.h>\n#include <stdlib.h>\n#ifdef _MSC_VER\n# include <direct.h>\n# include <process.h>\n# include <io.h>\n#else\n# include <unistd.h>\n# include <stdint.h>\n# ifdef __CYGWIN__\n#  include <io.h>\n# endif\n#endif\n#include <malloc.h>\n#include <stdarg.h>\n#include <assert.h>\n#include <string.h>\n#include <ctype.h>\n#include <errno.h>\n#include <fcntl.h>\n#include <sys/stat.h>\n\n#define STREQ(s1, s2) (strcmp ((s1), (s2)) == 0)\n\n/* declarations of non-ANSI functions */\n#if defined __MINGW32__\n# ifdef __STRICT_ANSI__\nint _putenv (const char *);\n# endif\n#elif defined __CYGWIN__\n# ifdef __STRICT_ANSI__\nchar *realpath (const char *, char *);\nint putenv (char *);\nint setenv (const char *, const char *, int);\n# endif\n/* #elif defined other_platform || defined ... */\n#endif\n\n/* portability defines, excluding path handling macros */\n#if defined _MSC_VER\n# define setmode _setmode\n# define stat    _stat\n# define chmod   _chmod\n# define getcwd  _getcwd\n# define putenv  _putenv\n# define S_IXUSR _S_IEXEC\n#elif defined __MINGW32__\n# define setmode _setmode\n# define stat    _stat\n# define chmod   _chmod\n# define getcwd  _getcwd\n# define putenv  _putenv\n#elif defined __CYGWIN__\n# define HAVE_SETENV\n# define FOPEN_WB \"wb\"\n/* #elif defined other platforms ... */\n#endif\n\n#if defined PATH_MAX\n# define LT_PATHMAX PATH_MAX\n#elif defined MAXPATHLEN\n# define LT_PATHMAX MAXPATHLEN\n#else\n# define LT_PATHMAX 1024\n#endif\n\n#ifndef S_IXOTH\n# define S_IXOTH 0\n#endif\n#ifndef S_IXGRP\n# define S_IXGRP 0\n#endif\n\n/* path handling portability macros */\n#ifndef DIR_SEPARATOR\n# define DIR_SEPARATOR '/'\n# define PATH_SEPARATOR ':'\n#endif\n\n#if defined _WIN32 || defined __MSDOS__ || defined __DJGPP__ || \\\n  defined __OS2__\n# define HAVE_DOS_BASED_FILE_SYSTEM\n# define FOPEN_WB \"wb\"\n# ifndef DIR_SEPARATOR_2\n#  define DIR_SEPARATOR_2 '\\\\'\n# endif\n# ifndef PATH_SEPARATOR_2\n#  define PATH_SEPARATOR_2 ';'\n# endif\n#endif\n\n#ifndef DIR_SEPARATOR_2\n# define IS_DIR_SEPARATOR(ch) ((ch) == DIR_SEPARATOR)\n#else /* DIR_SEPARATOR_2 */\n# define IS_DIR_SEPARATOR(ch) \\\n\t(((ch) == DIR_SEPARATOR) || ((ch) == DIR_SEPARATOR_2))\n#endif /* DIR_SEPARATOR_2 */\n\n#ifndef PATH_SEPARATOR_2\n# define IS_PATH_SEPARATOR(ch) ((ch) == PATH_SEPARATOR)\n#else /* PATH_SEPARATOR_2 */\n# define IS_PATH_SEPARATOR(ch) ((ch) == PATH_SEPARATOR_2)\n#endif /* PATH_SEPARATOR_2 */\n\n#ifndef FOPEN_WB\n# define FOPEN_WB \"w\"\n#endif\n#ifndef _O_BINARY\n# define _O_BINARY 0\n#endif\n\n#define XMALLOC(type, num)      ((type *) xmalloc ((num) * sizeof(type)))\n#define XFREE(stale) do { \\\n  if (stale) { free (stale); stale = 0; } \\\n} while (0)\n\n#if defined LT_DEBUGWRAPPER\nstatic int lt_debug = 1;\n#else\nstatic int lt_debug = 0;\n#endif\n\nconst char *program_name = \"libtool-wrapper\"; /* in case xstrdup fails */\n\nvoid *xmalloc (size_t num);\nchar *xstrdup (const char *string);\nconst char *base_name (const char *name);\nchar *find_executable (const char *wrapper);\nchar *chase_symlinks (const char *pathspec);\nint make_executable (const char *path);\nint check_executable (const char *path);\nchar *strendzap (char *str, const char *pat);\nvoid lt_debugprintf (const char *file, int line, const char *fmt, ...);\nvoid lt_fatal (const char *file, int line, const char *message, ...);\nstatic const char *nonnull (const char *s);\nstatic const char *nonempty (const char *s);\nvoid lt_setenv (const char *name, const char *value);\nchar *lt_extend_str (const char *orig_value, const char *add, int to_end);\nvoid lt_update_exe_path (const char *name, const char *value);\nvoid lt_update_lib_path (const char *name, const char *value);\nchar **prepare_spawn (char **argv);\nvoid lt_dump_script (FILE *f);\nEOF\n\n\t    cat <<EOF\n#if __GNUC__ < 4 || (__GNUC__ == 4 && __GNUC_MINOR__ < 5)\n# define externally_visible volatile\n#else\n# define externally_visible __attribute__((externally_visible)) volatile\n#endif\nexternally_visible const char * MAGIC_EXE = \"$magic_exe\";\nconst char * LIB_PATH_VARNAME = \"$shlibpath_var\";\nEOF\n\n\t    if test yes = \"$shlibpath_overrides_runpath\" && test -n \"$shlibpath_var\" && test -n \"$temp_rpath\"; then\n              func_to_host_path \"$temp_rpath\"\n\t      cat <<EOF\nconst char * LIB_PATH_VALUE   = \"$func_to_host_path_result\";\nEOF\n\t    else\n\t      cat <<\"EOF\"\nconst char * LIB_PATH_VALUE   = \"\";\nEOF\n\t    fi\n\n\t    if test -n \"$dllsearchpath\"; then\n              func_to_host_path \"$dllsearchpath:\"\n\t      cat <<EOF\nconst char * EXE_PATH_VARNAME = \"PATH\";\nconst char * EXE_PATH_VALUE   = \"$func_to_host_path_result\";\nEOF\n\t    else\n\t      cat <<\"EOF\"\nconst char * EXE_PATH_VARNAME = \"\";\nconst char * EXE_PATH_VALUE   = \"\";\nEOF\n\t    fi\n\n\t    if test yes = \"$fast_install\"; then\n\t      cat <<EOF\nconst char * TARGET_PROGRAM_NAME = \"lt-$outputname\"; /* hopefully, no .exe */\nEOF\n\t    else\n\t      cat <<EOF\nconst char * TARGET_PROGRAM_NAME = \"$outputname\"; /* hopefully, no .exe */\nEOF\n\t    fi\n\n\n\t    cat <<\"EOF\"\n\n#define LTWRAPPER_OPTION_PREFIX         \"--lt-\"\n\nstatic const char *ltwrapper_option_prefix = LTWRAPPER_OPTION_PREFIX;\nstatic const char *dumpscript_opt       = LTWRAPPER_OPTION_PREFIX \"dump-script\";\nstatic const char *debug_opt            = LTWRAPPER_OPTION_PREFIX \"debug\";\n\nint\nmain (int argc, char *argv[])\n{\n  char **newargz;\n  int  newargc;\n  char *tmp_pathspec;\n  char *actual_cwrapper_path;\n  char *actual_cwrapper_name;\n  char *target_name;\n  char *lt_argv_zero;\n  int rval = 127;\n\n  int i;\n\n  program_name = (char *) xstrdup (base_name (argv[0]));\n  newargz = XMALLOC (char *, (size_t) argc + 1);\n\n  /* very simple arg parsing; don't want to rely on getopt\n   * also, copy all non cwrapper options to newargz, except\n   * argz[0], which is handled differently\n   */\n  newargc=0;\n  for (i = 1; i < argc; i++)\n    {\n      if (STREQ (argv[i], dumpscript_opt))\n\t{\nEOF\n\t    case $host in\n\t      *mingw* | *cygwin* )\n\t\t# make stdout use \"unix\" line endings\n\t\techo \"          setmode(1,_O_BINARY);\"\n\t\t;;\n\t      esac\n\n\t    cat <<\"EOF\"\n\t  lt_dump_script (stdout);\n\t  return 0;\n\t}\n      if (STREQ (argv[i], debug_opt))\n\t{\n          lt_debug = 1;\n          continue;\n\t}\n      if (STREQ (argv[i], ltwrapper_option_prefix))\n        {\n          /* however, if there is an option in the LTWRAPPER_OPTION_PREFIX\n             namespace, but it is not one of the ones we know about and\n             have already dealt with, above (inluding dump-script), then\n             report an error. Otherwise, targets might begin to believe\n             they are allowed to use options in the LTWRAPPER_OPTION_PREFIX\n             namespace. The first time any user complains about this, we'll\n             need to make LTWRAPPER_OPTION_PREFIX a configure-time option\n             or a configure.ac-settable value.\n           */\n          lt_fatal (__FILE__, __LINE__,\n\t\t    \"unrecognized %s option: '%s'\",\n                    ltwrapper_option_prefix, argv[i]);\n        }\n      /* otherwise ... */\n      newargz[++newargc] = xstrdup (argv[i]);\n    }\n  newargz[++newargc] = NULL;\n\nEOF\n\t    cat <<EOF\n  /* The GNU banner must be the first non-error debug message */\n  lt_debugprintf (__FILE__, __LINE__, \"libtool wrapper (GNU $PACKAGE) $VERSION\\n\");\nEOF\n\t    cat <<\"EOF\"\n  lt_debugprintf (__FILE__, __LINE__, \"(main) argv[0]: %s\\n\", argv[0]);\n  lt_debugprintf (__FILE__, __LINE__, \"(main) program_name: %s\\n\", program_name);\n\n  tmp_pathspec = find_executable (argv[0]);\n  if (tmp_pathspec == NULL)\n    lt_fatal (__FILE__, __LINE__, \"couldn't find %s\", argv[0]);\n  lt_debugprintf (__FILE__, __LINE__,\n                  \"(main) found exe (before symlink chase) at: %s\\n\",\n\t\t  tmp_pathspec);\n\n  actual_cwrapper_path = chase_symlinks (tmp_pathspec);\n  lt_debugprintf (__FILE__, __LINE__,\n                  \"(main) found exe (after symlink chase) at: %s\\n\",\n\t\t  actual_cwrapper_path);\n  XFREE (tmp_pathspec);\n\n  actual_cwrapper_name = xstrdup (base_name (actual_cwrapper_path));\n  strendzap (actual_cwrapper_path, actual_cwrapper_name);\n\n  /* wrapper name transforms */\n  strendzap (actual_cwrapper_name, \".exe\");\n  tmp_pathspec = lt_extend_str (actual_cwrapper_name, \".exe\", 1);\n  XFREE (actual_cwrapper_name);\n  actual_cwrapper_name = tmp_pathspec;\n  tmp_pathspec = 0;\n\n  /* target_name transforms -- use actual target program name; might have lt- prefix */\n  target_name = xstrdup (base_name (TARGET_PROGRAM_NAME));\n  strendzap (target_name, \".exe\");\n  tmp_pathspec = lt_extend_str (target_name, \".exe\", 1);\n  XFREE (target_name);\n  target_name = tmp_pathspec;\n  tmp_pathspec = 0;\n\n  lt_debugprintf (__FILE__, __LINE__,\n\t\t  \"(main) libtool target name: %s\\n\",\n\t\t  target_name);\nEOF\n\n\t    cat <<EOF\n  newargz[0] =\n    XMALLOC (char, (strlen (actual_cwrapper_path) +\n\t\t    strlen (\"$objdir\") + 1 + strlen (actual_cwrapper_name) + 1));\n  strcpy (newargz[0], actual_cwrapper_path);\n  strcat (newargz[0], \"$objdir\");\n  strcat (newargz[0], \"/\");\nEOF\n\n\t    cat <<\"EOF\"\n  /* stop here, and copy so we don't have to do this twice */\n  tmp_pathspec = xstrdup (newargz[0]);\n\n  /* do NOT want the lt- prefix here, so use actual_cwrapper_name */\n  strcat (newargz[0], actual_cwrapper_name);\n\n  /* DO want the lt- prefix here if it exists, so use target_name */\n  lt_argv_zero = lt_extend_str (tmp_pathspec, target_name, 1);\n  XFREE (tmp_pathspec);\n  tmp_pathspec = NULL;\nEOF\n\n\t    case $host_os in\n\t      mingw*)\n\t    cat <<\"EOF\"\n  {\n    char* p;\n    while ((p = strchr (newargz[0], '\\\\')) != NULL)\n      {\n\t*p = '/';\n      }\n    while ((p = strchr (lt_argv_zero, '\\\\')) != NULL)\n      {\n\t*p = '/';\n      }\n  }\nEOF\n\t    ;;\n\t    esac\n\n\t    cat <<\"EOF\"\n  XFREE (target_name);\n  XFREE (actual_cwrapper_path);\n  XFREE (actual_cwrapper_name);\n\n  lt_setenv (\"BIN_SH\", \"xpg4\"); /* for Tru64 */\n  lt_setenv (\"DUALCASE\", \"1\");  /* for MSK sh */\n  /* Update the DLL searchpath.  EXE_PATH_VALUE ($dllsearchpath) must\n     be prepended before (that is, appear after) LIB_PATH_VALUE ($temp_rpath)\n     because on Windows, both *_VARNAMEs are PATH but uninstalled\n     libraries must come first. */\n  lt_update_exe_path (EXE_PATH_VARNAME, EXE_PATH_VALUE);\n  lt_update_lib_path (LIB_PATH_VARNAME, LIB_PATH_VALUE);\n\n  lt_debugprintf (__FILE__, __LINE__, \"(main) lt_argv_zero: %s\\n\",\n\t\t  nonnull (lt_argv_zero));\n  for (i = 0; i < newargc; i++)\n    {\n      lt_debugprintf (__FILE__, __LINE__, \"(main) newargz[%d]: %s\\n\",\n\t\t      i, nonnull (newargz[i]));\n    }\n\nEOF\n\n\t    case $host_os in\n\t      mingw*)\n\t\tcat <<\"EOF\"\n  /* execv doesn't actually work on mingw as expected on unix */\n  newargz = prepare_spawn (newargz);\n  rval = (int) _spawnv (_P_WAIT, lt_argv_zero, (const char * const *) newargz);\n  if (rval == -1)\n    {\n      /* failed to start process */\n      lt_debugprintf (__FILE__, __LINE__,\n\t\t      \"(main) failed to launch target \\\"%s\\\": %s\\n\",\n\t\t      lt_argv_zero, nonnull (strerror (errno)));\n      return 127;\n    }\n  return rval;\nEOF\n\t\t;;\n\t      *)\n\t\tcat <<\"EOF\"\n  execv (lt_argv_zero, newargz);\n  return rval; /* =127, but avoids unused variable warning */\nEOF\n\t\t;;\n\t    esac\n\n\t    cat <<\"EOF\"\n}\n\nvoid *\nxmalloc (size_t num)\n{\n  void *p = (void *) malloc (num);\n  if (!p)\n    lt_fatal (__FILE__, __LINE__, \"memory exhausted\");\n\n  return p;\n}\n\nchar *\nxstrdup (const char *string)\n{\n  return string ? strcpy ((char *) xmalloc (strlen (string) + 1),\n\t\t\t  string) : NULL;\n}\n\nconst char *\nbase_name (const char *name)\n{\n  const char *base;\n\n#if defined HAVE_DOS_BASED_FILE_SYSTEM\n  /* Skip over the disk name in MSDOS pathnames. */\n  if (isalpha ((unsigned char) name[0]) && name[1] == ':')\n    name += 2;\n#endif\n\n  for (base = name; *name; name++)\n    if (IS_DIR_SEPARATOR (*name))\n      base = name + 1;\n  return base;\n}\n\nint\ncheck_executable (const char *path)\n{\n  struct stat st;\n\n  lt_debugprintf (__FILE__, __LINE__, \"(check_executable): %s\\n\",\n                  nonempty (path));\n  if ((!path) || (!*path))\n    return 0;\n\n  if ((stat (path, &st) >= 0)\n      && (st.st_mode & (S_IXUSR | S_IXGRP | S_IXOTH)))\n    return 1;\n  else\n    return 0;\n}\n\nint\nmake_executable (const char *path)\n{\n  int rval = 0;\n  struct stat st;\n\n  lt_debugprintf (__FILE__, __LINE__, \"(make_executable): %s\\n\",\n                  nonempty (path));\n  if ((!path) || (!*path))\n    return 0;\n\n  if (stat (path, &st) >= 0)\n    {\n      rval = chmod (path, st.st_mode | S_IXOTH | S_IXGRP | S_IXUSR);\n    }\n  return rval;\n}\n\n/* Searches for the full path of the wrapper.  Returns\n   newly allocated full path name if found, NULL otherwise\n   Does not chase symlinks, even on platforms that support them.\n*/\nchar *\nfind_executable (const char *wrapper)\n{\n  int has_slash = 0;\n  const char *p;\n  const char *p_next;\n  /* static buffer for getcwd */\n  char tmp[LT_PATHMAX + 1];\n  size_t tmp_len;\n  char *concat_name;\n\n  lt_debugprintf (__FILE__, __LINE__, \"(find_executable): %s\\n\",\n                  nonempty (wrapper));\n\n  if ((wrapper == NULL) || (*wrapper == '\\0'))\n    return NULL;\n\n  /* Absolute path? */\n#if defined HAVE_DOS_BASED_FILE_SYSTEM\n  if (isalpha ((unsigned char) wrapper[0]) && wrapper[1] == ':')\n    {\n      concat_name = xstrdup (wrapper);\n      if (check_executable (concat_name))\n\treturn concat_name;\n      XFREE (concat_name);\n    }\n  else\n    {\n#endif\n      if (IS_DIR_SEPARATOR (wrapper[0]))\n\t{\n\t  concat_name = xstrdup (wrapper);\n\t  if (check_executable (concat_name))\n\t    return concat_name;\n\t  XFREE (concat_name);\n\t}\n#if defined HAVE_DOS_BASED_FILE_SYSTEM\n    }\n#endif\n\n  for (p = wrapper; *p; p++)\n    if (*p == '/')\n      {\n\thas_slash = 1;\n\tbreak;\n      }\n  if (!has_slash)\n    {\n      /* no slashes; search PATH */\n      const char *path = getenv (\"PATH\");\n      if (path != NULL)\n\t{\n\t  for (p = path; *p; p = p_next)\n\t    {\n\t      const char *q;\n\t      size_t p_len;\n\t      for (q = p; *q; q++)\n\t\tif (IS_PATH_SEPARATOR (*q))\n\t\t  break;\n\t      p_len = (size_t) (q - p);\n\t      p_next = (*q == '\\0' ? q : q + 1);\n\t      if (p_len == 0)\n\t\t{\n\t\t  /* empty path: current directory */\n\t\t  if (getcwd (tmp, LT_PATHMAX) == NULL)\n\t\t    lt_fatal (__FILE__, __LINE__, \"getcwd failed: %s\",\n                              nonnull (strerror (errno)));\n\t\t  tmp_len = strlen (tmp);\n\t\t  concat_name =\n\t\t    XMALLOC (char, tmp_len + 1 + strlen (wrapper) + 1);\n\t\t  memcpy (concat_name, tmp, tmp_len);\n\t\t  concat_name[tmp_len] = '/';\n\t\t  strcpy (concat_name + tmp_len + 1, wrapper);\n\t\t}\n\t      else\n\t\t{\n\t\t  concat_name =\n\t\t    XMALLOC (char, p_len + 1 + strlen (wrapper) + 1);\n\t\t  memcpy (concat_name, p, p_len);\n\t\t  concat_name[p_len] = '/';\n\t\t  strcpy (concat_name + p_len + 1, wrapper);\n\t\t}\n\t      if (check_executable (concat_name))\n\t\treturn concat_name;\n\t      XFREE (concat_name);\n\t    }\n\t}\n      /* not found in PATH; assume curdir */\n    }\n  /* Relative path | not found in path: prepend cwd */\n  if (getcwd (tmp, LT_PATHMAX) == NULL)\n    lt_fatal (__FILE__, __LINE__, \"getcwd failed: %s\",\n              nonnull (strerror (errno)));\n  tmp_len = strlen (tmp);\n  concat_name = XMALLOC (char, tmp_len + 1 + strlen (wrapper) + 1);\n  memcpy (concat_name, tmp, tmp_len);\n  concat_name[tmp_len] = '/';\n  strcpy (concat_name + tmp_len + 1, wrapper);\n\n  if (check_executable (concat_name))\n    return concat_name;\n  XFREE (concat_name);\n  return NULL;\n}\n\nchar *\nchase_symlinks (const char *pathspec)\n{\n#ifndef S_ISLNK\n  return xstrdup (pathspec);\n#else\n  char buf[LT_PATHMAX];\n  struct stat s;\n  char *tmp_pathspec = xstrdup (pathspec);\n  char *p;\n  int has_symlinks = 0;\n  while (strlen (tmp_pathspec) && !has_symlinks)\n    {\n      lt_debugprintf (__FILE__, __LINE__,\n\t\t      \"checking path component for symlinks: %s\\n\",\n\t\t      tmp_pathspec);\n      if (lstat (tmp_pathspec, &s) == 0)\n\t{\n\t  if (S_ISLNK (s.st_mode) != 0)\n\t    {\n\t      has_symlinks = 1;\n\t      break;\n\t    }\n\n\t  /* search backwards for last DIR_SEPARATOR */\n\t  p = tmp_pathspec + strlen (tmp_pathspec) - 1;\n\t  while ((p > tmp_pathspec) && (!IS_DIR_SEPARATOR (*p)))\n\t    p--;\n\t  if ((p == tmp_pathspec) && (!IS_DIR_SEPARATOR (*p)))\n\t    {\n\t      /* no more DIR_SEPARATORS left */\n\t      break;\n\t    }\n\t  *p = '\\0';\n\t}\n      else\n\t{\n\t  lt_fatal (__FILE__, __LINE__,\n\t\t    \"error accessing file \\\"%s\\\": %s\",\n\t\t    tmp_pathspec, nonnull (strerror (errno)));\n\t}\n    }\n  XFREE (tmp_pathspec);\n\n  if (!has_symlinks)\n    {\n      return xstrdup (pathspec);\n    }\n\n  tmp_pathspec = realpath (pathspec, buf);\n  if (tmp_pathspec == 0)\n    {\n      lt_fatal (__FILE__, __LINE__,\n\t\t\"could not follow symlinks for %s\", pathspec);\n    }\n  return xstrdup (tmp_pathspec);\n#endif\n}\n\nchar *\nstrendzap (char *str, const char *pat)\n{\n  size_t len, patlen;\n\n  assert (str != NULL);\n  assert (pat != NULL);\n\n  len = strlen (str);\n  patlen = strlen (pat);\n\n  if (patlen <= len)\n    {\n      str += len - patlen;\n      if (STREQ (str, pat))\n\t*str = '\\0';\n    }\n  return str;\n}\n\nvoid\nlt_debugprintf (const char *file, int line, const char *fmt, ...)\n{\n  va_list args;\n  if (lt_debug)\n    {\n      (void) fprintf (stderr, \"%s:%s:%d: \", program_name, file, line);\n      va_start (args, fmt);\n      (void) vfprintf (stderr, fmt, args);\n      va_end (args);\n    }\n}\n\nstatic void\nlt_error_core (int exit_status, const char *file,\n\t       int line, const char *mode,\n\t       const char *message, va_list ap)\n{\n  fprintf (stderr, \"%s:%s:%d: %s: \", program_name, file, line, mode);\n  vfprintf (stderr, message, ap);\n  fprintf (stderr, \".\\n\");\n\n  if (exit_status >= 0)\n    exit (exit_status);\n}\n\nvoid\nlt_fatal (const char *file, int line, const char *message, ...)\n{\n  va_list ap;\n  va_start (ap, message);\n  lt_error_core (EXIT_FAILURE, file, line, \"FATAL\", message, ap);\n  va_end (ap);\n}\n\nstatic const char *\nnonnull (const char *s)\n{\n  return s ? s : \"(null)\";\n}\n\nstatic const char *\nnonempty (const char *s)\n{\n  return (s && !*s) ? \"(empty)\" : nonnull (s);\n}\n\nvoid\nlt_setenv (const char *name, const char *value)\n{\n  lt_debugprintf (__FILE__, __LINE__,\n\t\t  \"(lt_setenv) setting '%s' to '%s'\\n\",\n                  nonnull (name), nonnull (value));\n  {\n#ifdef HAVE_SETENV\n    /* always make a copy, for consistency with !HAVE_SETENV */\n    char *str = xstrdup (value);\n    setenv (name, str, 1);\n#else\n    size_t len = strlen (name) + 1 + strlen (value) + 1;\n    char *str = XMALLOC (char, len);\n    sprintf (str, \"%s=%s\", name, value);\n    if (putenv (str) != EXIT_SUCCESS)\n      {\n        XFREE (str);\n      }\n#endif\n  }\n}\n\nchar *\nlt_extend_str (const char *orig_value, const char *add, int to_end)\n{\n  char *new_value;\n  if (orig_value && *orig_value)\n    {\n      size_t orig_value_len = strlen (orig_value);\n      size_t add_len = strlen (add);\n      new_value = XMALLOC (char, add_len + orig_value_len + 1);\n      if (to_end)\n        {\n          strcpy (new_value, orig_value);\n          strcpy (new_value + orig_value_len, add);\n        }\n      else\n        {\n          strcpy (new_value, add);\n          strcpy (new_value + add_len, orig_value);\n        }\n    }\n  else\n    {\n      new_value = xstrdup (add);\n    }\n  return new_value;\n}\n\nvoid\nlt_update_exe_path (const char *name, const char *value)\n{\n  lt_debugprintf (__FILE__, __LINE__,\n\t\t  \"(lt_update_exe_path) modifying '%s' by prepending '%s'\\n\",\n                  nonnull (name), nonnull (value));\n\n  if (name && *name && value && *value)\n    {\n      char *new_value = lt_extend_str (getenv (name), value, 0);\n      /* some systems can't cope with a ':'-terminated path #' */\n      size_t len = strlen (new_value);\n      while ((len > 0) && IS_PATH_SEPARATOR (new_value[len-1]))\n        {\n          new_value[--len] = '\\0';\n        }\n      lt_setenv (name, new_value);\n      XFREE (new_value);\n    }\n}\n\nvoid\nlt_update_lib_path (const char *name, const char *value)\n{\n  lt_debugprintf (__FILE__, __LINE__,\n\t\t  \"(lt_update_lib_path) modifying '%s' by prepending '%s'\\n\",\n                  nonnull (name), nonnull (value));\n\n  if (name && *name && value && *value)\n    {\n      char *new_value = lt_extend_str (getenv (name), value, 0);\n      lt_setenv (name, new_value);\n      XFREE (new_value);\n    }\n}\n\nEOF\n\t    case $host_os in\n\t      mingw*)\n\t\tcat <<\"EOF\"\n\n/* Prepares an argument vector before calling spawn().\n   Note that spawn() does not by itself call the command interpreter\n     (getenv (\"COMSPEC\") != NULL ? getenv (\"COMSPEC\") :\n      ({ OSVERSIONINFO v; v.dwOSVersionInfoSize = sizeof(OSVERSIONINFO);\n         GetVersionEx(&v);\n         v.dwPlatformId == VER_PLATFORM_WIN32_NT;\n      }) ? \"cmd.exe\" : \"command.com\").\n   Instead it simply concatenates the arguments, separated by ' ', and calls\n   CreateProcess().  We must quote the arguments since Win32 CreateProcess()\n   interprets characters like ' ', '\\t', '\\\\', '\"' (but not '<' and '>') in a\n   special way:\n   - Space and tab are interpreted as delimiters. They are not treated as\n     delimiters if they are surrounded by double quotes: \"...\".\n   - Unescaped double quotes are removed from the input. Their only effect is\n     that within double quotes, space and tab are treated like normal\n     characters.\n   - Backslashes not followed by double quotes are not special.\n   - But 2*n+1 backslashes followed by a double quote become\n     n backslashes followed by a double quote (n >= 0):\n       \\\" -> \"\n       \\\\\\\" -> \\\"\n       \\\\\\\\\\\" -> \\\\\"\n */\n#define SHELL_SPECIAL_CHARS \"\\\"\\\\ \\001\\002\\003\\004\\005\\006\\007\\010\\011\\012\\013\\014\\015\\016\\017\\020\\021\\022\\023\\024\\025\\026\\027\\030\\031\\032\\033\\034\\035\\036\\037\"\n#define SHELL_SPACE_CHARS \" \\001\\002\\003\\004\\005\\006\\007\\010\\011\\012\\013\\014\\015\\016\\017\\020\\021\\022\\023\\024\\025\\026\\027\\030\\031\\032\\033\\034\\035\\036\\037\"\nchar **\nprepare_spawn (char **argv)\n{\n  size_t argc;\n  char **new_argv;\n  size_t i;\n\n  /* Count number of arguments.  */\n  for (argc = 0; argv[argc] != NULL; argc++)\n    ;\n\n  /* Allocate new argument vector.  */\n  new_argv = XMALLOC (char *, argc + 1);\n\n  /* Put quoted arguments into the new argument vector.  */\n  for (i = 0; i < argc; i++)\n    {\n      const char *string = argv[i];\n\n      if (string[0] == '\\0')\n\tnew_argv[i] = xstrdup (\"\\\"\\\"\");\n      else if (strpbrk (string, SHELL_SPECIAL_CHARS) != NULL)\n\t{\n\t  int quote_around = (strpbrk (string, SHELL_SPACE_CHARS) != NULL);\n\t  size_t length;\n\t  unsigned int backslashes;\n\t  const char *s;\n\t  char *quoted_string;\n\t  char *p;\n\n\t  length = 0;\n\t  backslashes = 0;\n\t  if (quote_around)\n\t    length++;\n\t  for (s = string; *s != '\\0'; s++)\n\t    {\n\t      char c = *s;\n\t      if (c == '\"')\n\t\tlength += backslashes + 1;\n\t      length++;\n\t      if (c == '\\\\')\n\t\tbackslashes++;\n\t      else\n\t\tbackslashes = 0;\n\t    }\n\t  if (quote_around)\n\t    length += backslashes + 1;\n\n\t  quoted_string = XMALLOC (char, length + 1);\n\n\t  p = quoted_string;\n\t  backslashes = 0;\n\t  if (quote_around)\n\t    *p++ = '\"';\n\t  for (s = string; *s != '\\0'; s++)\n\t    {\n\t      char c = *s;\n\t      if (c == '\"')\n\t\t{\n\t\t  unsigned int j;\n\t\t  for (j = backslashes + 1; j > 0; j--)\n\t\t    *p++ = '\\\\';\n\t\t}\n\t      *p++ = c;\n\t      if (c == '\\\\')\n\t\tbackslashes++;\n\t      else\n\t\tbackslashes = 0;\n\t    }\n\t  if (quote_around)\n\t    {\n\t      unsigned int j;\n\t      for (j = backslashes; j > 0; j--)\n\t\t*p++ = '\\\\';\n\t      *p++ = '\"';\n\t    }\n\t  *p = '\\0';\n\n\t  new_argv[i] = quoted_string;\n\t}\n      else\n\tnew_argv[i] = (char *) string;\n    }\n  new_argv[argc] = NULL;\n\n  return new_argv;\n}\nEOF\n\t\t;;\n\t    esac\n\n            cat <<\"EOF\"\nvoid lt_dump_script (FILE* f)\n{\nEOF\n\t    func_emit_wrapper yes |\n\t      $SED -n -e '\ns/^\\(.\\{79\\}\\)\\(..*\\)/\\1\\\n\\2/\nh\ns/\\([\\\\\"]\\)/\\\\\\1/g\ns/$/\\\\n/\ns/\\([^\\n]*\\).*/  fputs (\"\\1\", f);/p\ng\nD'\n            cat <<\"EOF\"\n}\nEOF\n}\n# end: func_emit_cwrapperexe_src\n\n# func_win32_import_lib_p ARG\n# True if ARG is an import lib, as indicated by $file_magic_cmd\nfunc_win32_import_lib_p ()\n{\n    $debug_cmd\n\n    case `eval $file_magic_cmd \\\"\\$1\\\" 2>/dev/null | $SED -e 10q` in\n    *import*) : ;;\n    *) false ;;\n    esac\n}\n\n# func_suncc_cstd_abi\n# !!ONLY CALL THIS FOR SUN CC AFTER $compile_command IS FULLY EXPANDED!!\n# Several compiler flags select an ABI that is incompatible with the\n# Cstd library. Avoid specifying it if any are in CXXFLAGS.\nfunc_suncc_cstd_abi ()\n{\n    $debug_cmd\n\n    case \" $compile_command \" in\n    *\" -compat=g \"*|*\\ -std=c++[0-9][0-9]\\ *|*\" -library=stdcxx4 \"*|*\" -library=stlport4 \"*)\n      suncc_use_cstd_abi=no\n      ;;\n    *)\n      suncc_use_cstd_abi=yes\n      ;;\n    esac\n}\n\n# func_mode_link arg...\nfunc_mode_link ()\n{\n    $debug_cmd\n\n    case $host in\n    *-*-cygwin* | *-*-mingw* | *-*-pw32* | *-*-os2* | *-cegcc*)\n      # It is impossible to link a dll without this setting, and\n      # we shouldn't force the makefile maintainer to figure out\n      # what system we are compiling for in order to pass an extra\n      # flag for every libtool invocation.\n      # allow_undefined=no\n\n      # FIXME: Unfortunately, there are problems with the above when trying\n      # to make a dll that has undefined symbols, in which case not\n      # even a static library is built.  For now, we need to specify\n      # -no-undefined on the libtool link line when we can be certain\n      # that all symbols are satisfied, otherwise we get a static library.\n      allow_undefined=yes\n      ;;\n    *)\n      allow_undefined=yes\n      ;;\n    esac\n    libtool_args=$nonopt\n    base_compile=\"$nonopt $@\"\n    compile_command=$nonopt\n    finalize_command=$nonopt\n\n    compile_rpath=\n    finalize_rpath=\n    compile_shlibpath=\n    finalize_shlibpath=\n    convenience=\n    old_convenience=\n    deplibs=\n    old_deplibs=\n    compiler_flags=\n    linker_flags=\n    dllsearchpath=\n    lib_search_path=`pwd`\n    inst_prefix_dir=\n    new_inherited_linker_flags=\n\n    avoid_version=no\n    bindir=\n    dlfiles=\n    dlprefiles=\n    dlself=no\n    export_dynamic=no\n    export_symbols=\n    export_symbols_regex=\n    generated=\n    libobjs=\n    ltlibs=\n    module=no\n    no_install=no\n    objs=\n    os2dllname=\n    non_pic_objects=\n    precious_files_regex=\n    prefer_static_libs=no\n    preload=false\n    prev=\n    prevarg=\n    release=\n    rpath=\n    xrpath=\n    perm_rpath=\n    temp_rpath=\n    thread_safe=no\n    vinfo=\n    vinfo_number=no\n    weak_libs=\n    single_module=$wl-single_module\n    func_infer_tag $base_compile\n\n    # We need to know -static, to get the right output filenames.\n    for arg\n    do\n      case $arg in\n      -shared)\n\ttest yes != \"$build_libtool_libs\" \\\n\t  && func_fatal_configuration \"cannot build a shared library\"\n\tbuild_old_libs=no\n\tbreak\n\t;;\n      -all-static | -static | -static-libtool-libs)\n\tcase $arg in\n\t-all-static)\n\t  if test yes = \"$build_libtool_libs\" && test -z \"$link_static_flag\"; then\n\t    func_warning \"complete static linking is impossible in this configuration\"\n\t  fi\n\t  if test -n \"$link_static_flag\"; then\n\t    dlopen_self=$dlopen_self_static\n\t  fi\n\t  prefer_static_libs=yes\n\t  ;;\n\t-static)\n\t  if test -z \"$pic_flag\" && test -n \"$link_static_flag\"; then\n\t    dlopen_self=$dlopen_self_static\n\t  fi\n\t  prefer_static_libs=built\n\t  ;;\n\t-static-libtool-libs)\n\t  if test -z \"$pic_flag\" && test -n \"$link_static_flag\"; then\n\t    dlopen_self=$dlopen_self_static\n\t  fi\n\t  prefer_static_libs=yes\n\t  ;;\n\tesac\n\tbuild_libtool_libs=no\n\tbuild_old_libs=yes\n\tbreak\n\t;;\n      esac\n    done\n\n    # See if our shared archives depend on static archives.\n    test -n \"$old_archive_from_new_cmds\" && build_old_libs=yes\n\n    # Go through the arguments, transforming them on the way.\n    while test \"$#\" -gt 0; do\n      arg=$1\n      shift\n      func_quote_for_eval \"$arg\"\n      qarg=$func_quote_for_eval_unquoted_result\n      func_append libtool_args \" $func_quote_for_eval_result\"\n\n      # If the previous option needs an argument, assign it.\n      if test -n \"$prev\"; then\n\tcase $prev in\n\toutput)\n\t  func_append compile_command \" @OUTPUT@\"\n\t  func_append finalize_command \" @OUTPUT@\"\n\t  ;;\n\tesac\n\n\tcase $prev in\n\tbindir)\n\t  bindir=$arg\n\t  prev=\n\t  continue\n\t  ;;\n\tdlfiles|dlprefiles)\n\t  $preload || {\n\t    # Add the symbol object into the linking commands.\n\t    func_append compile_command \" @SYMFILE@\"\n\t    func_append finalize_command \" @SYMFILE@\"\n\t    preload=:\n\t  }\n\t  case $arg in\n\t  *.la | *.lo) ;;  # We handle these cases below.\n\t  force)\n\t    if test no = \"$dlself\"; then\n\t      dlself=needless\n\t      export_dynamic=yes\n\t    fi\n\t    prev=\n\t    continue\n\t    ;;\n\t  self)\n\t    if test dlprefiles = \"$prev\"; then\n\t      dlself=yes\n\t    elif test dlfiles = \"$prev\" && test yes != \"$dlopen_self\"; then\n\t      dlself=yes\n\t    else\n\t      dlself=needless\n\t      export_dynamic=yes\n\t    fi\n\t    prev=\n\t    continue\n\t    ;;\n\t  *)\n\t    if test dlfiles = \"$prev\"; then\n\t      func_append dlfiles \" $arg\"\n\t    else\n\t      func_append dlprefiles \" $arg\"\n\t    fi\n\t    prev=\n\t    continue\n\t    ;;\n\t  esac\n\t  ;;\n\texpsyms)\n\t  export_symbols=$arg\n\t  test -f \"$arg\" \\\n\t    || func_fatal_error \"symbol file '$arg' does not exist\"\n\t  prev=\n\t  continue\n\t  ;;\n\texpsyms_regex)\n\t  export_symbols_regex=$arg\n\t  prev=\n\t  continue\n\t  ;;\n\tframework)\n\t  case $host in\n\t    *-*-darwin*)\n\t      case \"$deplibs \" in\n\t\t*\" $qarg.ltframework \"*) ;;\n\t\t*) func_append deplibs \" $qarg.ltframework\" # this is fixed later\n\t\t   ;;\n\t      esac\n\t      ;;\n\t  esac\n\t  prev=\n\t  continue\n\t  ;;\n\tinst_prefix)\n\t  inst_prefix_dir=$arg\n\t  prev=\n\t  continue\n\t  ;;\n\tmllvm)\n\t  # Clang does not use LLVM to link, so we can simply discard any\n\t  # '-mllvm $arg' options when doing the link step.\n\t  prev=\n\t  continue\n\t  ;;\n\tobjectlist)\n\t  if test -f \"$arg\"; then\n\t    save_arg=$arg\n\t    moreargs=\n\t    for fil in `cat \"$save_arg\"`\n\t    do\n#\t      func_append moreargs \" $fil\"\n\t      arg=$fil\n\t      # A libtool-controlled object.\n\n\t      # Check to see that this really is a libtool object.\n\t      if func_lalib_unsafe_p \"$arg\"; then\n\t\tpic_object=\n\t\tnon_pic_object=\n\n\t\t# Read the .lo file\n\t\tfunc_source \"$arg\"\n\n\t\tif test -z \"$pic_object\" ||\n\t\t   test -z \"$non_pic_object\" ||\n\t\t   test none = \"$pic_object\" &&\n\t\t   test none = \"$non_pic_object\"; then\n\t\t  func_fatal_error \"cannot find name of object for '$arg'\"\n\t\tfi\n\n\t\t# Extract subdirectory from the argument.\n\t\tfunc_dirname \"$arg\" \"/\" \"\"\n\t\txdir=$func_dirname_result\n\n\t\tif test none != \"$pic_object\"; then\n\t\t  # Prepend the subdirectory the object is found in.\n\t\t  pic_object=$xdir$pic_object\n\n\t\t  if test dlfiles = \"$prev\"; then\n\t\t    if test yes = \"$build_libtool_libs\" && test yes = \"$dlopen_support\"; then\n\t\t      func_append dlfiles \" $pic_object\"\n\t\t      prev=\n\t\t      continue\n\t\t    else\n\t\t      # If libtool objects are unsupported, then we need to preload.\n\t\t      prev=dlprefiles\n\t\t    fi\n\t\t  fi\n\n\t\t  # CHECK ME:  I think I busted this.  -Ossama\n\t\t  if test dlprefiles = \"$prev\"; then\n\t\t    # Preload the old-style object.\n\t\t    func_append dlprefiles \" $pic_object\"\n\t\t    prev=\n\t\t  fi\n\n\t\t  # A PIC object.\n\t\t  func_append libobjs \" $pic_object\"\n\t\t  arg=$pic_object\n\t\tfi\n\n\t\t# Non-PIC object.\n\t\tif test none != \"$non_pic_object\"; then\n\t\t  # Prepend the subdirectory the object is found in.\n\t\t  non_pic_object=$xdir$non_pic_object\n\n\t\t  # A standard non-PIC object\n\t\t  func_append non_pic_objects \" $non_pic_object\"\n\t\t  if test -z \"$pic_object\" || test none = \"$pic_object\"; then\n\t\t    arg=$non_pic_object\n\t\t  fi\n\t\telse\n\t\t  # If the PIC object exists, use it instead.\n\t\t  # $xdir was prepended to $pic_object above.\n\t\t  non_pic_object=$pic_object\n\t\t  func_append non_pic_objects \" $non_pic_object\"\n\t\tfi\n\t      else\n\t\t# Only an error if not doing a dry-run.\n\t\tif $opt_dry_run; then\n\t\t  # Extract subdirectory from the argument.\n\t\t  func_dirname \"$arg\" \"/\" \"\"\n\t\t  xdir=$func_dirname_result\n\n\t\t  func_lo2o \"$arg\"\n\t\t  pic_object=$xdir$objdir/$func_lo2o_result\n\t\t  non_pic_object=$xdir$func_lo2o_result\n\t\t  func_append libobjs \" $pic_object\"\n\t\t  func_append non_pic_objects \" $non_pic_object\"\n\t        else\n\t\t  func_fatal_error \"'$arg' is not a valid libtool object\"\n\t\tfi\n\t      fi\n\t    done\n\t  else\n\t    func_fatal_error \"link input file '$arg' does not exist\"\n\t  fi\n\t  arg=$save_arg\n\t  prev=\n\t  continue\n\t  ;;\n\tos2dllname)\n\t  os2dllname=$arg\n\t  prev=\n\t  continue\n\t  ;;\n\tprecious_regex)\n\t  precious_files_regex=$arg\n\t  prev=\n\t  continue\n\t  ;;\n\trelease)\n\t  release=-$arg\n\t  prev=\n\t  continue\n\t  ;;\n\trpath | xrpath)\n\t  # We need an absolute path.\n\t  case $arg in\n\t  [\\\\/]* | [A-Za-z]:[\\\\/]*) ;;\n\t  *)\n\t    func_fatal_error \"only absolute run-paths are allowed\"\n\t    ;;\n\t  esac\n\t  if test rpath = \"$prev\"; then\n\t    case \"$rpath \" in\n\t    *\" $arg \"*) ;;\n\t    *) func_append rpath \" $arg\" ;;\n\t    esac\n\t  else\n\t    case \"$xrpath \" in\n\t    *\" $arg \"*) ;;\n\t    *) func_append xrpath \" $arg\" ;;\n\t    esac\n\t  fi\n\t  prev=\n\t  continue\n\t  ;;\n\tshrext)\n\t  shrext_cmds=$arg\n\t  prev=\n\t  continue\n\t  ;;\n\tweak)\n\t  func_append weak_libs \" $arg\"\n\t  prev=\n\t  continue\n\t  ;;\n\txcclinker)\n\t  func_append linker_flags \" $qarg\"\n\t  func_append compiler_flags \" $qarg\"\n\t  prev=\n\t  func_append compile_command \" $qarg\"\n\t  func_append finalize_command \" $qarg\"\n\t  continue\n\t  ;;\n\txcompiler)\n\t  func_append compiler_flags \" $qarg\"\n\t  prev=\n\t  func_append compile_command \" $qarg\"\n\t  func_append finalize_command \" $qarg\"\n\t  continue\n\t  ;;\n\txlinker)\n\t  func_append linker_flags \" $qarg\"\n\t  func_append compiler_flags \" $wl$qarg\"\n\t  prev=\n\t  func_append compile_command \" $wl$qarg\"\n\t  func_append finalize_command \" $wl$qarg\"\n\t  continue\n\t  ;;\n\t*)\n\t  eval \"$prev=\\\"\\$arg\\\"\"\n\t  prev=\n\t  continue\n\t  ;;\n\tesac\n      fi # test -n \"$prev\"\n\n      prevarg=$arg\n\n      case $arg in\n      -all-static)\n\tif test -n \"$link_static_flag\"; then\n\t  # See comment for -static flag below, for more details.\n\t  func_append compile_command \" $link_static_flag\"\n\t  func_append finalize_command \" $link_static_flag\"\n\tfi\n\tcontinue\n\t;;\n\n      -allow-undefined)\n\t# FIXME: remove this flag sometime in the future.\n\tfunc_fatal_error \"'-allow-undefined' must not be used because it is the default\"\n\t;;\n\n      -avoid-version)\n\tavoid_version=yes\n\tcontinue\n\t;;\n\n      -bindir)\n\tprev=bindir\n\tcontinue\n\t;;\n\n      -dlopen)\n\tprev=dlfiles\n\tcontinue\n\t;;\n\n      -dlpreopen)\n\tprev=dlprefiles\n\tcontinue\n\t;;\n\n      -export-dynamic)\n\texport_dynamic=yes\n\tcontinue\n\t;;\n\n      -export-symbols | -export-symbols-regex)\n\tif test -n \"$export_symbols\" || test -n \"$export_symbols_regex\"; then\n\t  func_fatal_error \"more than one -exported-symbols argument is not allowed\"\n\tfi\n\tif test X-export-symbols = \"X$arg\"; then\n\t  prev=expsyms\n\telse\n\t  prev=expsyms_regex\n\tfi\n\tcontinue\n\t;;\n\n      -framework)\n\tprev=framework\n\tcontinue\n\t;;\n\n      -inst-prefix-dir)\n\tprev=inst_prefix\n\tcontinue\n\t;;\n\n      # The native IRIX linker understands -LANG:*, -LIST:* and -LNO:*\n      # so, if we see these flags be careful not to treat them like -L\n      -L[A-Z][A-Z]*:*)\n\tcase $with_gcc/$host in\n\tno/*-*-irix* | /*-*-irix*)\n\t  func_append compile_command \" $arg\"\n\t  func_append finalize_command \" $arg\"\n\t  ;;\n\tesac\n\tcontinue\n\t;;\n\n      -L*)\n\tfunc_stripname \"-L\" '' \"$arg\"\n\tif test -z \"$func_stripname_result\"; then\n\t  if test \"$#\" -gt 0; then\n\t    func_fatal_error \"require no space between '-L' and '$1'\"\n\t  else\n\t    func_fatal_error \"need path for '-L' option\"\n\t  fi\n\tfi\n\tfunc_resolve_sysroot \"$func_stripname_result\"\n\tdir=$func_resolve_sysroot_result\n\t# We need an absolute path.\n\tcase $dir in\n\t[\\\\/]* | [A-Za-z]:[\\\\/]*) ;;\n\t*)\n\t  absdir=`cd \"$dir\" && pwd`\n\t  test -z \"$absdir\" && \\\n\t    func_fatal_error \"cannot determine absolute directory name of '$dir'\"\n\t  dir=$absdir\n\t  ;;\n\tesac\n\tcase \"$deplibs \" in\n\t*\" -L$dir \"* | *\" $arg \"*)\n\t  # Will only happen for absolute or sysroot arguments\n\t  ;;\n\t*)\n\t  # Preserve sysroot, but never include relative directories\n\t  case $dir in\n\t    [\\\\/]* | [A-Za-z]:[\\\\/]* | =*) func_append deplibs \" $arg\" ;;\n\t    *) func_append deplibs \" -L$dir\" ;;\n\t  esac\n\t  func_append lib_search_path \" $dir\"\n\t  ;;\n\tesac\n\tcase $host in\n\t*-*-cygwin* | *-*-mingw* | *-*-pw32* | *-*-os2* | *-cegcc*)\n\t  testbindir=`$ECHO \"$dir\" | $SED 's*/lib$*/bin*'`\n\t  case :$dllsearchpath: in\n\t  *\":$dir:\"*) ;;\n\t  ::) dllsearchpath=$dir;;\n\t  *) func_append dllsearchpath \":$dir\";;\n\t  esac\n\t  case :$dllsearchpath: in\n\t  *\":$testbindir:\"*) ;;\n\t  ::) dllsearchpath=$testbindir;;\n\t  *) func_append dllsearchpath \":$testbindir\";;\n\t  esac\n\t  ;;\n\tesac\n\tcontinue\n\t;;\n\n      -l*)\n\tif test X-lc = \"X$arg\" || test X-lm = \"X$arg\"; then\n\t  case $host in\n\t  *-*-cygwin* | *-*-mingw* | *-*-pw32* | *-*-beos* | *-cegcc* | *-*-haiku*)\n\t    # These systems don't actually have a C or math library (as such)\n\t    continue\n\t    ;;\n\t  *-*-os2*)\n\t    # These systems don't actually have a C library (as such)\n\t    test X-lc = \"X$arg\" && continue\n\t    ;;\n\t  *-*-openbsd* | *-*-freebsd* | *-*-dragonfly* | *-*-bitrig*)\n\t    # Do not include libc due to us having libc/libc_r.\n\t    test X-lc = \"X$arg\" && continue\n\t    ;;\n\t  *-*-rhapsody* | *-*-darwin1.[012])\n\t    # Rhapsody C and math libraries are in the System framework\n\t    func_append deplibs \" System.ltframework\"\n\t    continue\n\t    ;;\n\t  *-*-sco3.2v5* | *-*-sco5v6*)\n\t    # Causes problems with __ctype\n\t    test X-lc = \"X$arg\" && continue\n\t    ;;\n\t  *-*-sysv4.2uw2* | *-*-sysv5* | *-*-unixware* | *-*-OpenUNIX*)\n\t    # Compiler inserts libc in the correct place for threads to work\n\t    test X-lc = \"X$arg\" && continue\n\t    ;;\n\t  esac\n\telif test X-lc_r = \"X$arg\"; then\n\t case $host in\n\t *-*-openbsd* | *-*-freebsd* | *-*-dragonfly* | *-*-bitrig*)\n\t   # Do not include libc_r directly, use -pthread flag.\n\t   continue\n\t   ;;\n\t esac\n\tfi\n\tfunc_append deplibs \" $arg\"\n\tcontinue\n\t;;\n\n      -mllvm)\n\tprev=mllvm\n\tcontinue\n\t;;\n\n      -module)\n\tmodule=yes\n\tcontinue\n\t;;\n\n      # Tru64 UNIX uses -model [arg] to determine the layout of C++\n      # classes, name mangling, and exception handling.\n      # Darwin uses the -arch flag to determine output architecture.\n      -model|-arch|-isysroot|--sysroot)\n\tfunc_append compiler_flags \" $arg\"\n\tfunc_append compile_command \" $arg\"\n\tfunc_append finalize_command \" $arg\"\n\tprev=xcompiler\n\tcontinue\n\t;;\n\n      -mt|-mthreads|-kthread|-Kthread|-pthread|-pthreads|--thread-safe \\\n      |-threads|-fopenmp|-openmp|-mp|-xopenmp|-omp|-qsmp=*)\n        case $CC in\n\t    nagfor*) ;;\n\t    *)\n\t\tfunc_append compiler_flags \" $arg\"\n\t\t;;\n\tesac\n\tfunc_append compile_command \" $arg\"\n\tfunc_append finalize_command \" $arg\"\n\tcase \"$new_inherited_linker_flags \" in\n\t    *\" $arg \"*) ;;\n\t    *) \n\t\tcase $CC in \n\t\t    nagfor*) ;;\n\t\t    *)\n\t\t\tfunc_append new_inherited_linker_flags \" $arg\"\n\t\t    ;;\n\t\tesac\n\t\t;;\n\tesac\n\tcontinue\n\t;;\n\n      -multi_module)\n\tsingle_module=$wl-multi_module\n\tcontinue\n\t;;\n\n      -no-fast-install)\n\tfast_install=no\n\tcontinue\n\t;;\n\n      -no-install)\n\tcase $host in\n\t*-*-cygwin* | *-*-mingw* | *-*-pw32* | *-*-os2* | *-*-darwin* | *-cegcc*)\n\t  # The PATH hackery in wrapper scripts is required on Windows\n\t  # and Darwin in order for the loader to find any dlls it needs.\n\t  func_warning \"'-no-install' is ignored for $host\"\n\t  func_warning \"assuming '-no-fast-install' instead\"\n\t  fast_install=no\n\t  ;;\n\t*) no_install=yes ;;\n\tesac\n\tcontinue\n\t;;\n\n      -no-undefined)\n\tallow_undefined=no\n\tcontinue\n\t;;\n\n      -objectlist)\n\tprev=objectlist\n\tcontinue\n\t;;\n\n      -os2dllname)\n\tprev=os2dllname\n\tcontinue\n\t;;\n\n      -o) prev=output ;;\n\n      -precious-files-regex)\n\tprev=precious_regex\n\tcontinue\n\t;;\n\n      -release)\n\tprev=release\n\tcontinue\n\t;;\n\n      -rpath)\n\tprev=rpath\n\tcontinue\n\t;;\n\n      -R)\n\tprev=xrpath\n\tcontinue\n\t;;\n\n      -R*)\n\tfunc_stripname '-R' '' \"$arg\"\n\tdir=$func_stripname_result\n\t# We need an absolute path.\n\tcase $dir in\n\t[\\\\/]* | [A-Za-z]:[\\\\/]*) ;;\n\t=*)\n\t  func_stripname '=' '' \"$dir\"\n\t  dir=$lt_sysroot$func_stripname_result\n\t  ;;\n\t*)\n\t  func_fatal_error \"only absolute run-paths are allowed\"\n\t  ;;\n\tesac\n\tcase \"$xrpath \" in\n\t*\" $dir \"*) ;;\n\t*) func_append xrpath \" $dir\" ;;\n\tesac\n\tcontinue\n\t;;\n\n      -shared)\n\t# The effects of -shared are defined in a previous loop.\n\tcontinue\n\t;;\n\n      -shrext)\n\tprev=shrext\n\tcontinue\n\t;;\n\n      -static | -static-libtool-libs)\n\t# The effects of -static are defined in a previous loop.\n\t# We used to do the same as -all-static on platforms that\n\t# didn't have a PIC flag, but the assumption that the effects\n\t# would be equivalent was wrong.  It would break on at least\n\t# Digital Unix and AIX.\n\tcontinue\n\t;;\n\n      -thread-safe)\n\tthread_safe=yes\n\tcontinue\n\t;;\n\n      -version-info)\n\tprev=vinfo\n\tcontinue\n\t;;\n\n      -version-number)\n\tprev=vinfo\n\tvinfo_number=yes\n\tcontinue\n\t;;\n\n      -weak)\n        prev=weak\n\tcontinue\n\t;;\n\n      -Wc,*)\n\tfunc_stripname '-Wc,' '' \"$arg\"\n\targs=$func_stripname_result\n\targ=\n\tsave_ifs=$IFS; IFS=,\n\tfor flag in $args; do\n\t  IFS=$save_ifs\n          func_quote_for_eval \"$flag\"\n\t  func_append arg \" $func_quote_for_eval_result\"\n\t  func_append compiler_flags \" $func_quote_for_eval_result\"\n\tdone\n\tIFS=$save_ifs\n\tfunc_stripname ' ' '' \"$arg\"\n\targ=$func_stripname_result\n\t;;\n\n      -Wl,*)\n\tfunc_stripname '-Wl,' '' \"$arg\"\n\targs=$func_stripname_result\n\targ=\n\tsave_ifs=$IFS; IFS=,\n\tfor flag in $args; do\n\t  IFS=$save_ifs\n          func_quote_for_eval \"$flag\"\n\t  func_append arg \" $wl$func_quote_for_eval_result\"\n\t  func_append compiler_flags \" $wl$func_quote_for_eval_result\"\n\t  func_append linker_flags \" $func_quote_for_eval_result\"\n\tdone\n\tIFS=$save_ifs\n\tfunc_stripname ' ' '' \"$arg\"\n\targ=$func_stripname_result\n\t;;\n\n      -Xcompiler)\n\tprev=xcompiler\n\tcontinue\n\t;;\n\n      -Xlinker)\n\tprev=xlinker\n\tcontinue\n\t;;\n\n      -XCClinker)\n\tprev=xcclinker\n\tcontinue\n\t;;\n\n      # -msg_* for osf cc\n      -msg_*)\n\tfunc_quote_for_eval \"$arg\"\n\targ=$func_quote_for_eval_result\n\t;;\n\n      # Flags to be passed through unchanged, with rationale:\n      # -64, -mips[0-9]      enable 64-bit mode for the SGI compiler\n      # -r[0-9][0-9]*        specify processor for the SGI compiler\n      # -xarch=*, -xtarget=* enable 64-bit mode for the Sun compiler\n      # +DA*, +DD*           enable 64-bit mode for the HP compiler\n      # -q*                  compiler args for the IBM compiler\n      # -m*, -t[45]*, -txscale* architecture-specific flags for GCC\n      # -F/path              path to uninstalled frameworks, gcc on darwin\n      # -p, -pg, --coverage, -fprofile-*  profiling flags for GCC\n      # -fstack-protector*   stack protector flags for GCC\n      # @file                GCC response files\n      # -tp=*                Portland pgcc target processor selection\n      # --sysroot=*          for sysroot support\n      # -O*, -g*, -flto*, -fwhopr*, -fuse-linker-plugin GCC link-time optimization\n      # -stdlib=*            select c++ std lib with clang\n      -64|-mips[0-9]|-r[0-9][0-9]*|-xarch=*|-xtarget=*|+DA*|+DD*|-q*|-m*| \\\n      -t[45]*|-txscale*|-p|-pg|--coverage|-fprofile-*|-F*|@*|-tp=*|--sysroot=*| \\\n      -O*|-g*|-flto*|-fwhopr*|-fuse-linker-plugin|-fstack-protector*|-stdlib=*)\n        func_quote_for_eval \"$arg\"\n\targ=$func_quote_for_eval_result\n        func_append compile_command \" $arg\"\n        func_append finalize_command \" $arg\"\n        func_append compiler_flags \" $arg\"\n        continue\n        ;;\n\n      -Z*)\n        if test os2 = \"`expr $host : '.*\\(os2\\)'`\"; then\n          # OS/2 uses -Zxxx to specify OS/2-specific options\n\t  compiler_flags=\"$compiler_flags $arg\"\n\t  func_append compile_command \" $arg\"\n\t  func_append finalize_command \" $arg\"\n\t  case $arg in\n\t  -Zlinker | -Zstack)\n\t    prev=xcompiler\n\t    ;;\n\t  esac\n\t  continue\n        else\n\t  # Otherwise treat like 'Some other compiler flag' below\n\t  func_quote_for_eval \"$arg\"\n\t  arg=$func_quote_for_eval_result\n        fi\n\t;;\n\n      # Some other compiler flag.\n      -* | +*)\n        func_quote_for_eval \"$arg\"\n\targ=$func_quote_for_eval_result\n\t;;\n\n      *.$objext)\n\t# A standard object.\n\tfunc_append objs \" $arg\"\n\t;;\n\n      *.lo)\n\t# A libtool-controlled object.\n\n\t# Check to see that this really is a libtool object.\n\tif func_lalib_unsafe_p \"$arg\"; then\n\t  pic_object=\n\t  non_pic_object=\n\n\t  # Read the .lo file\n\t  func_source \"$arg\"\n\n\t  if test -z \"$pic_object\" ||\n\t     test -z \"$non_pic_object\" ||\n\t     test none = \"$pic_object\" &&\n\t     test none = \"$non_pic_object\"; then\n\t    func_fatal_error \"cannot find name of object for '$arg'\"\n\t  fi\n\n\t  # Extract subdirectory from the argument.\n\t  func_dirname \"$arg\" \"/\" \"\"\n\t  xdir=$func_dirname_result\n\n\t  test none = \"$pic_object\" || {\n\t    # Prepend the subdirectory the object is found in.\n\t    pic_object=$xdir$pic_object\n\n\t    if test dlfiles = \"$prev\"; then\n\t      if test yes = \"$build_libtool_libs\" && test yes = \"$dlopen_support\"; then\n\t\tfunc_append dlfiles \" $pic_object\"\n\t\tprev=\n\t\tcontinue\n\t      else\n\t\t# If libtool objects are unsupported, then we need to preload.\n\t\tprev=dlprefiles\n\t      fi\n\t    fi\n\n\t    # CHECK ME:  I think I busted this.  -Ossama\n\t    if test dlprefiles = \"$prev\"; then\n\t      # Preload the old-style object.\n\t      func_append dlprefiles \" $pic_object\"\n\t      prev=\n\t    fi\n\n\t    # A PIC object.\n\t    func_append libobjs \" $pic_object\"\n\t    arg=$pic_object\n\t  }\n\n\t  # Non-PIC object.\n\t  if test none != \"$non_pic_object\"; then\n\t    # Prepend the subdirectory the object is found in.\n\t    non_pic_object=$xdir$non_pic_object\n\n\t    # A standard non-PIC object\n\t    func_append non_pic_objects \" $non_pic_object\"\n\t    if test -z \"$pic_object\" || test none = \"$pic_object\"; then\n\t      arg=$non_pic_object\n\t    fi\n\t  else\n\t    # If the PIC object exists, use it instead.\n\t    # $xdir was prepended to $pic_object above.\n\t    non_pic_object=$pic_object\n\t    func_append non_pic_objects \" $non_pic_object\"\n\t  fi\n\telse\n\t  # Only an error if not doing a dry-run.\n\t  if $opt_dry_run; then\n\t    # Extract subdirectory from the argument.\n\t    func_dirname \"$arg\" \"/\" \"\"\n\t    xdir=$func_dirname_result\n\n\t    func_lo2o \"$arg\"\n\t    pic_object=$xdir$objdir/$func_lo2o_result\n\t    non_pic_object=$xdir$func_lo2o_result\n\t    func_append libobjs \" $pic_object\"\n\t    func_append non_pic_objects \" $non_pic_object\"\n\t  else\n\t    func_fatal_error \"'$arg' is not a valid libtool object\"\n\t  fi\n\tfi\n\t;;\n\n      *.$libext)\n\t# An archive.\n\tfunc_append deplibs \" $arg\"\n\tfunc_append old_deplibs \" $arg\"\n\tcontinue\n\t;;\n\n      *.la)\n\t# A libtool-controlled library.\n\n\tfunc_resolve_sysroot \"$arg\"\n\tif test dlfiles = \"$prev\"; then\n\t  # This library was specified with -dlopen.\n\t  func_append dlfiles \" $func_resolve_sysroot_result\"\n\t  prev=\n\telif test dlprefiles = \"$prev\"; then\n\t  # The library was specified with -dlpreopen.\n\t  func_append dlprefiles \" $func_resolve_sysroot_result\"\n\t  prev=\n\telse\n\t  func_append deplibs \" $func_resolve_sysroot_result\"\n\tfi\n\tcontinue\n\t;;\n\n      # Some other compiler argument.\n      *)\n\t# Unknown arguments in both finalize_command and compile_command need\n\t# to be aesthetically quoted because they are evaled later.\n\tfunc_quote_for_eval \"$arg\"\n\targ=$func_quote_for_eval_result\n\t;;\n      esac # arg\n\n      # Now actually substitute the argument into the commands.\n      if test -n \"$arg\"; then\n\tfunc_append compile_command \" $arg\"\n\tfunc_append finalize_command \" $arg\"\n      fi\n    done # argument parsing loop\n\n    test -n \"$prev\" && \\\n      func_fatal_help \"the '$prevarg' option requires an argument\"\n\n    if test yes = \"$export_dynamic\" && test -n \"$export_dynamic_flag_spec\"; then\n      eval arg=\\\"$export_dynamic_flag_spec\\\"\n      func_append compile_command \" $arg\"\n      func_append finalize_command \" $arg\"\n    fi\n\n    oldlibs=\n    # calculate the name of the file, without its directory\n    func_basename \"$output\"\n    outputname=$func_basename_result\n    libobjs_save=$libobjs\n\n    if test -n \"$shlibpath_var\"; then\n      # get the directories listed in $shlibpath_var\n      eval shlib_search_path=\\`\\$ECHO \\\"\\$$shlibpath_var\\\" \\| \\$SED \\'s/:/ /g\\'\\`\n    else\n      shlib_search_path=\n    fi\n    eval sys_lib_search_path=\\\"$sys_lib_search_path_spec\\\"\n    eval sys_lib_dlsearch_path=\\\"$sys_lib_dlsearch_path_spec\\\"\n\n    # Definition is injected by LT_CONFIG during libtool generation.\n    func_munge_path_list sys_lib_dlsearch_path \"$LT_SYS_LIBRARY_PATH\"\n\n    func_dirname \"$output\" \"/\" \"\"\n    output_objdir=$func_dirname_result$objdir\n    func_to_tool_file \"$output_objdir/\"\n    tool_output_objdir=$func_to_tool_file_result\n    # Create the object directory.\n    func_mkdir_p \"$output_objdir\"\n\n    # Determine the type of output\n    case $output in\n    \"\")\n      func_fatal_help \"you must specify an output file\"\n      ;;\n    *.$libext) linkmode=oldlib ;;\n    *.lo | *.$objext) linkmode=obj ;;\n    *.la) linkmode=lib ;;\n    *) linkmode=prog ;; # Anything else should be a program.\n    esac\n\n    specialdeplibs=\n\n    libs=\n    # Find all interdependent deplibs by searching for libraries\n    # that are linked more than once (e.g. -la -lb -la)\n    for deplib in $deplibs; do\n      if $opt_preserve_dup_deps; then\n\tcase \"$libs \" in\n\t*\" $deplib \"*) func_append specialdeplibs \" $deplib\" ;;\n\tesac\n      fi\n      func_append libs \" $deplib\"\n    done\n\n    if test lib = \"$linkmode\"; then\n      libs=\"$predeps $libs $compiler_lib_search_path $postdeps\"\n\n      # Compute libraries that are listed more than once in $predeps\n      # $postdeps and mark them as special (i.e., whose duplicates are\n      # not to be eliminated).\n      pre_post_deps=\n      if $opt_duplicate_compiler_generated_deps; then\n\tfor pre_post_dep in $predeps $postdeps; do\n\t  case \"$pre_post_deps \" in\n\t  *\" $pre_post_dep \"*) func_append specialdeplibs \" $pre_post_deps\" ;;\n\t  esac\n\t  func_append pre_post_deps \" $pre_post_dep\"\n\tdone\n      fi\n      pre_post_deps=\n    fi\n\n    deplibs=\n    newdependency_libs=\n    newlib_search_path=\n    need_relink=no # whether we're linking any uninstalled libtool libraries\n    notinst_deplibs= # not-installed libtool libraries\n    notinst_path= # paths that contain not-installed libtool libraries\n\n    case $linkmode in\n    lib)\n\tpasses=\"conv dlpreopen link\"\n\tfor file in $dlfiles $dlprefiles; do\n\t  case $file in\n\t  *.la) ;;\n\t  *)\n\t    func_fatal_help \"libraries can '-dlopen' only libtool libraries: $file\"\n\t    ;;\n\t  esac\n\tdone\n\t;;\n    prog)\n\tcompile_deplibs=\n\tfinalize_deplibs=\n\talldeplibs=false\n\tnewdlfiles=\n\tnewdlprefiles=\n\tpasses=\"conv scan dlopen dlpreopen link\"\n\t;;\n    *)  passes=\"conv\"\n\t;;\n    esac\n\n    for pass in $passes; do\n      # The preopen pass in lib mode reverses $deplibs; put it back here\n      # so that -L comes before libs that need it for instance...\n      if test lib,link = \"$linkmode,$pass\"; then\n\t## FIXME: Find the place where the list is rebuilt in the wrong\n\t##        order, and fix it there properly\n        tmp_deplibs=\n\tfor deplib in $deplibs; do\n\t  tmp_deplibs=\"$deplib $tmp_deplibs\"\n\tdone\n\tdeplibs=$tmp_deplibs\n      fi\n\n      if test lib,link = \"$linkmode,$pass\" ||\n\t test prog,scan = \"$linkmode,$pass\"; then\n\tlibs=$deplibs\n\tdeplibs=\n      fi\n      if test prog = \"$linkmode\"; then\n\tcase $pass in\n\tdlopen) libs=$dlfiles ;;\n\tdlpreopen) libs=$dlprefiles ;;\n\tlink) libs=\"$deplibs %DEPLIBS% $dependency_libs\" ;;\n\tesac\n      fi\n      if test lib,dlpreopen = \"$linkmode,$pass\"; then\n\t# Collect and forward deplibs of preopened libtool libs\n\tfor lib in $dlprefiles; do\n\t  # Ignore non-libtool-libs\n\t  dependency_libs=\n\t  func_resolve_sysroot \"$lib\"\n\t  case $lib in\n\t  *.la)\tfunc_source \"$func_resolve_sysroot_result\" ;;\n\t  esac\n\n\t  # Collect preopened libtool deplibs, except any this library\n\t  # has declared as weak libs\n\t  for deplib in $dependency_libs; do\n\t    func_basename \"$deplib\"\n            deplib_base=$func_basename_result\n\t    case \" $weak_libs \" in\n\t    *\" $deplib_base \"*) ;;\n\t    *) func_append deplibs \" $deplib\" ;;\n\t    esac\n\t  done\n\tdone\n\tlibs=$dlprefiles\n      fi\n      if test dlopen = \"$pass\"; then\n\t# Collect dlpreopened libraries\n\tsave_deplibs=$deplibs\n\tdeplibs=\n      fi\n\n      for deplib in $libs; do\n\tlib=\n\tfound=false\n\tcase $deplib in\n\t-mt|-mthreads|-kthread|-Kthread|-pthread|-pthreads|--thread-safe \\\n        |-threads|-fopenmp|-openmp|-mp|-xopenmp|-omp|-qsmp=*)\n\t  if test prog,link = \"$linkmode,$pass\"; then\n\t    compile_deplibs=\"$deplib $compile_deplibs\"\n\t    finalize_deplibs=\"$deplib $finalize_deplibs\"\n\t  else\n\t    func_append compiler_flags \" $deplib\"\n\t    if test lib = \"$linkmode\"; then\n\t\tcase \"$new_inherited_linker_flags \" in\n\t\t    *\" $deplib \"*) ;;\n\t\t    * ) func_append new_inherited_linker_flags \" $deplib\" ;;\n\t\tesac\n\t    fi\n\t  fi\n\t  continue\n\t  ;;\n\t-l*)\n\t  if test lib != \"$linkmode\" && test prog != \"$linkmode\"; then\n\t    func_warning \"'-l' is ignored for archives/objects\"\n\t    continue\n\t  fi\n\t  func_stripname '-l' '' \"$deplib\"\n\t  name=$func_stripname_result\n\t  if test lib = \"$linkmode\"; then\n\t    searchdirs=\"$newlib_search_path $lib_search_path $compiler_lib_search_dirs $sys_lib_search_path $shlib_search_path\"\n\t  else\n\t    searchdirs=\"$newlib_search_path $lib_search_path $sys_lib_search_path $shlib_search_path\"\n\t  fi\n\t  for searchdir in $searchdirs; do\n\t    for search_ext in .la $std_shrext .so .a; do\n\t      # Search the libtool library\n\t      lib=$searchdir/lib$name$search_ext\n\t      if test -f \"$lib\"; then\n\t\tif test .la = \"$search_ext\"; then\n\t\t  found=:\n\t\telse\n\t\t  found=false\n\t\tfi\n\t\tbreak 2\n\t      fi\n\t    done\n\t  done\n\t  if $found; then\n\t    # deplib is a libtool library\n\t    # If $allow_libtool_libs_with_static_runtimes && $deplib is a stdlib,\n\t    # We need to do some special things here, and not later.\n\t    if test yes = \"$allow_libtool_libs_with_static_runtimes\"; then\n\t      case \" $predeps $postdeps \" in\n\t      *\" $deplib \"*)\n\t\tif func_lalib_p \"$lib\"; then\n\t\t  library_names=\n\t\t  old_library=\n\t\t  func_source \"$lib\"\n\t\t  for l in $old_library $library_names; do\n\t\t    ll=$l\n\t\t  done\n\t\t  if test \"X$ll\" = \"X$old_library\"; then # only static version available\n\t\t    found=false\n\t\t    func_dirname \"$lib\" \"\" \".\"\n\t\t    ladir=$func_dirname_result\n\t\t    lib=$ladir/$old_library\n\t\t    if test prog,link = \"$linkmode,$pass\"; then\n\t\t      compile_deplibs=\"$deplib $compile_deplibs\"\n\t\t      finalize_deplibs=\"$deplib $finalize_deplibs\"\n\t\t    else\n\t\t      deplibs=\"$deplib $deplibs\"\n\t\t      test lib = \"$linkmode\" && newdependency_libs=\"$deplib $newdependency_libs\"\n\t\t    fi\n\t\t    continue\n\t\t  fi\n\t\tfi\n\t\t;;\n\t      *) ;;\n\t      esac\n\t    fi\n\t  else\n\t    # deplib doesn't seem to be a libtool library\n\t    if test prog,link = \"$linkmode,$pass\"; then\n\t      compile_deplibs=\"$deplib $compile_deplibs\"\n\t      finalize_deplibs=\"$deplib $finalize_deplibs\"\n\t    else\n\t      deplibs=\"$deplib $deplibs\"\n\t      test lib = \"$linkmode\" && newdependency_libs=\"$deplib $newdependency_libs\"\n\t    fi\n\t    continue\n\t  fi\n\t  ;; # -l\n\t*.ltframework)\n\t  if test prog,link = \"$linkmode,$pass\"; then\n\t    compile_deplibs=\"$deplib $compile_deplibs\"\n\t    finalize_deplibs=\"$deplib $finalize_deplibs\"\n\t  else\n\t    deplibs=\"$deplib $deplibs\"\n\t    if test lib = \"$linkmode\"; then\n\t\tcase \"$new_inherited_linker_flags \" in\n\t\t    *\" $deplib \"*) ;;\n\t\t    * ) func_append new_inherited_linker_flags \" $deplib\" ;;\n\t\tesac\n\t    fi\n\t  fi\n\t  continue\n\t  ;;\n\t-L*)\n\t  case $linkmode in\n\t  lib)\n\t    deplibs=\"$deplib $deplibs\"\n\t    test conv = \"$pass\" && continue\n\t    newdependency_libs=\"$deplib $newdependency_libs\"\n\t    func_stripname '-L' '' \"$deplib\"\n\t    func_resolve_sysroot \"$func_stripname_result\"\n\t    func_append newlib_search_path \" $func_resolve_sysroot_result\"\n\t    ;;\n\t  prog)\n\t    if test conv = \"$pass\"; then\n\t      deplibs=\"$deplib $deplibs\"\n\t      continue\n\t    fi\n\t    if test scan = \"$pass\"; then\n\t      deplibs=\"$deplib $deplibs\"\n\t    else\n\t      compile_deplibs=\"$deplib $compile_deplibs\"\n\t      finalize_deplibs=\"$deplib $finalize_deplibs\"\n\t    fi\n\t    func_stripname '-L' '' \"$deplib\"\n\t    func_resolve_sysroot \"$func_stripname_result\"\n\t    func_append newlib_search_path \" $func_resolve_sysroot_result\"\n\t    ;;\n\t  *)\n\t    func_warning \"'-L' is ignored for archives/objects\"\n\t    ;;\n\t  esac # linkmode\n\t  continue\n\t  ;; # -L\n\t-R*)\n\t  if test link = \"$pass\"; then\n\t    func_stripname '-R' '' \"$deplib\"\n\t    func_resolve_sysroot \"$func_stripname_result\"\n\t    dir=$func_resolve_sysroot_result\n\t    # Make sure the xrpath contains only unique directories.\n\t    case \"$xrpath \" in\n\t    *\" $dir \"*) ;;\n\t    *) func_append xrpath \" $dir\" ;;\n\t    esac\n\t  fi\n\t  deplibs=\"$deplib $deplibs\"\n\t  continue\n\t  ;;\n\t*.la)\n\t  func_resolve_sysroot \"$deplib\"\n\t  lib=$func_resolve_sysroot_result\n\t  ;;\n\t*.$libext)\n\t  if test conv = \"$pass\"; then\n\t    deplibs=\"$deplib $deplibs\"\n\t    continue\n\t  fi\n\t  case $linkmode in\n\t  lib)\n\t    # Linking convenience modules into shared libraries is allowed,\n\t    # but linking other static libraries is non-portable.\n\t    case \" $dlpreconveniencelibs \" in\n\t    *\" $deplib \"*) ;;\n\t    *)\n\t      valid_a_lib=false\n\t      case $deplibs_check_method in\n\t\tmatch_pattern*)\n\t\t  set dummy $deplibs_check_method; shift\n\t\t  match_pattern_regex=`expr \"$deplibs_check_method\" : \"$1 \\(.*\\)\"`\n\t\t  if eval \"\\$ECHO \\\"$deplib\\\"\" 2>/dev/null | $SED 10q \\\n\t\t    | $EGREP \"$match_pattern_regex\" > /dev/null; then\n\t\t    valid_a_lib=:\n\t\t  fi\n\t\t;;\n\t\tpass_all)\n\t\t  valid_a_lib=:\n\t\t;;\n\t      esac\n\t      if $valid_a_lib; then\n\t\techo\n\t\t$ECHO \"*** Warning: Linking the shared library $output against the\"\n\t\t$ECHO \"*** static library $deplib is not portable!\"\n\t\tdeplibs=\"$deplib $deplibs\"\n\t      else\n\t\techo\n\t\t$ECHO \"*** Warning: Trying to link with static lib archive $deplib.\"\n\t\techo \"*** I have the capability to make that library automatically link in when\"\n\t\techo \"*** you link to this library.  But I can only do this if you have a\"\n\t\techo \"*** shared version of the library, which you do not appear to have\"\n\t\techo \"*** because the file extensions .$libext of this argument makes me believe\"\n\t\techo \"*** that it is just a static archive that I should not use here.\"\n\t      fi\n\t      ;;\n\t    esac\n\t    continue\n\t    ;;\n\t  prog)\n\t    if test link != \"$pass\"; then\n\t      deplibs=\"$deplib $deplibs\"\n\t    else\n\t      compile_deplibs=\"$deplib $compile_deplibs\"\n\t      finalize_deplibs=\"$deplib $finalize_deplibs\"\n\t    fi\n\t    continue\n\t    ;;\n\t  esac # linkmode\n\t  ;; # *.$libext\n\t*.lo | *.$objext)\n\t  if test conv = \"$pass\"; then\n\t    deplibs=\"$deplib $deplibs\"\n\t  elif test prog = \"$linkmode\"; then\n\t    if test dlpreopen = \"$pass\" || test yes != \"$dlopen_support\" || test no = \"$build_libtool_libs\"; then\n\t      # If there is no dlopen support or we're linking statically,\n\t      # we need to preload.\n\t      func_append newdlprefiles \" $deplib\"\n\t      compile_deplibs=\"$deplib $compile_deplibs\"\n\t      finalize_deplibs=\"$deplib $finalize_deplibs\"\n\t    else\n\t      func_append newdlfiles \" $deplib\"\n\t    fi\n\t  fi\n\t  continue\n\t  ;;\n\t%DEPLIBS%)\n\t  alldeplibs=:\n\t  continue\n\t  ;;\n\tesac # case $deplib\n\n\t$found || test -f \"$lib\" \\\n\t  || func_fatal_error \"cannot find the library '$lib' or unhandled argument '$deplib'\"\n\n\t# Check to see that this really is a libtool archive.\n\tfunc_lalib_unsafe_p \"$lib\" \\\n\t  || func_fatal_error \"'$lib' is not a valid libtool archive\"\n\n\tfunc_dirname \"$lib\" \"\" \".\"\n\tladir=$func_dirname_result\n\n\tdlname=\n\tdlopen=\n\tdlpreopen=\n\tlibdir=\n\tlibrary_names=\n\told_library=\n\tinherited_linker_flags=\n\t# If the library was installed with an old release of libtool,\n\t# it will not redefine variables installed, or shouldnotlink\n\tinstalled=yes\n\tshouldnotlink=no\n\tavoidtemprpath=\n\n\n\t# Read the .la file\n\tfunc_source \"$lib\"\n\n\t# Convert \"-framework foo\" to \"foo.ltframework\"\n\tif test -n \"$inherited_linker_flags\"; then\n\t  tmp_inherited_linker_flags=`$ECHO \"$inherited_linker_flags\" | $SED 's/-framework \\([^ $]*\\)/\\1.ltframework/g'`\n\t  for tmp_inherited_linker_flag in $tmp_inherited_linker_flags; do\n\t    case \" $new_inherited_linker_flags \" in\n\t      *\" $tmp_inherited_linker_flag \"*) ;;\n\t      *) func_append new_inherited_linker_flags \" $tmp_inherited_linker_flag\";;\n\t    esac\n\t  done\n\tfi\n\tdependency_libs=`$ECHO \" $dependency_libs\" | $SED 's% \\([^ $]*\\).ltframework% -framework \\1%g'`\n\tif test lib,link = \"$linkmode,$pass\" ||\n\t   test prog,scan = \"$linkmode,$pass\" ||\n\t   { test prog != \"$linkmode\" && test lib != \"$linkmode\"; }; then\n\t  test -n \"$dlopen\" && func_append dlfiles \" $dlopen\"\n\t  test -n \"$dlpreopen\" && func_append dlprefiles \" $dlpreopen\"\n\tfi\n\n\tif test conv = \"$pass\"; then\n\t  # Only check for convenience libraries\n\t  deplibs=\"$lib $deplibs\"\n\t  if test -z \"$libdir\"; then\n\t    if test -z \"$old_library\"; then\n\t      func_fatal_error \"cannot find name of link library for '$lib'\"\n\t    fi\n\t    # It is a libtool convenience library, so add in its objects.\n\t    func_append convenience \" $ladir/$objdir/$old_library\"\n\t    func_append old_convenience \" $ladir/$objdir/$old_library\"\n\t  elif test prog != \"$linkmode\" && test lib != \"$linkmode\"; then\n\t    func_fatal_error \"'$lib' is not a convenience library\"\n\t  fi\n\t  tmp_libs=\n\t  for deplib in $dependency_libs; do\n\t    deplibs=\"$deplib $deplibs\"\n\t    if $opt_preserve_dup_deps; then\n\t      case \"$tmp_libs \" in\n\t      *\" $deplib \"*) func_append specialdeplibs \" $deplib\" ;;\n\t      esac\n\t    fi\n\t    func_append tmp_libs \" $deplib\"\n\t  done\n\t  continue\n\tfi # $pass = conv\n\n\n\t# Get the name of the library we link against.\n\tlinklib=\n\tif test -n \"$old_library\" &&\n\t   { test yes = \"$prefer_static_libs\" ||\n\t     test built,no = \"$prefer_static_libs,$installed\"; }; then\n\t  linklib=$old_library\n\telse\n\t  for l in $old_library $library_names; do\n\t    linklib=$l\n\t  done\n\tfi\n\tif test -z \"$linklib\"; then\n\t  func_fatal_error \"cannot find name of link library for '$lib'\"\n\tfi\n\n\t# This library was specified with -dlopen.\n\tif test dlopen = \"$pass\"; then\n\t  test -z \"$libdir\" \\\n\t    && func_fatal_error \"cannot -dlopen a convenience library: '$lib'\"\n\t  if test -z \"$dlname\" ||\n\t     test yes != \"$dlopen_support\" ||\n\t     test no = \"$build_libtool_libs\"\n\t  then\n\t    # If there is no dlname, no dlopen support or we're linking\n\t    # statically, we need to preload.  We also need to preload any\n\t    # dependent libraries so libltdl's deplib preloader doesn't\n\t    # bomb out in the load deplibs phase.\n\t    func_append dlprefiles \" $lib $dependency_libs\"\n\t  else\n\t    func_append newdlfiles \" $lib\"\n\t  fi\n\t  continue\n\tfi # $pass = dlopen\n\n\t# We need an absolute path.\n\tcase $ladir in\n\t[\\\\/]* | [A-Za-z]:[\\\\/]*) abs_ladir=$ladir ;;\n\t*)\n\t  abs_ladir=`cd \"$ladir\" && pwd`\n\t  if test -z \"$abs_ladir\"; then\n\t    func_warning \"cannot determine absolute directory name of '$ladir'\"\n\t    func_warning \"passing it literally to the linker, although it might fail\"\n\t    abs_ladir=$ladir\n\t  fi\n\t  ;;\n\tesac\n\tfunc_basename \"$lib\"\n\tlaname=$func_basename_result\n\n\t# Find the relevant object directory and library name.\n\tif test yes = \"$installed\"; then\n\t  if test ! -f \"$lt_sysroot$libdir/$linklib\" && test -f \"$abs_ladir/$linklib\"; then\n\t    func_warning \"library '$lib' was moved.\"\n\t    dir=$ladir\n\t    absdir=$abs_ladir\n\t    libdir=$abs_ladir\n\t  else\n\t    dir=$lt_sysroot$libdir\n\t    absdir=$lt_sysroot$libdir\n\t  fi\n\t  test yes = \"$hardcode_automatic\" && avoidtemprpath=yes\n\telse\n\t  if test ! -f \"$ladir/$objdir/$linklib\" && test -f \"$abs_ladir/$linklib\"; then\n\t    dir=$ladir\n\t    absdir=$abs_ladir\n\t    # Remove this search path later\n\t    func_append notinst_path \" $abs_ladir\"\n\t  else\n\t    dir=$ladir/$objdir\n\t    absdir=$abs_ladir/$objdir\n\t    # Remove this search path later\n\t    func_append notinst_path \" $abs_ladir\"\n\t  fi\n\tfi # $installed = yes\n\tfunc_stripname 'lib' '.la' \"$laname\"\n\tname=$func_stripname_result\n\n\t# This library was specified with -dlpreopen.\n\tif test dlpreopen = \"$pass\"; then\n\t  if test -z \"$libdir\" && test prog = \"$linkmode\"; then\n\t    func_fatal_error \"only libraries may -dlpreopen a convenience library: '$lib'\"\n\t  fi\n\t  case $host in\n\t    # special handling for platforms with PE-DLLs.\n\t    *cygwin* | *mingw* | *cegcc* )\n\t      # Linker will automatically link against shared library if both\n\t      # static and shared are present.  Therefore, ensure we extract\n\t      # symbols from the import library if a shared library is present\n\t      # (otherwise, the dlopen module name will be incorrect).  We do\n\t      # this by putting the import library name into $newdlprefiles.\n\t      # We recover the dlopen module name by 'saving' the la file\n\t      # name in a special purpose variable, and (later) extracting the\n\t      # dlname from the la file.\n\t      if test -n \"$dlname\"; then\n\t        func_tr_sh \"$dir/$linklib\"\n\t        eval \"libfile_$func_tr_sh_result=\\$abs_ladir/\\$laname\"\n\t        func_append newdlprefiles \" $dir/$linklib\"\n\t      else\n\t        func_append newdlprefiles \" $dir/$old_library\"\n\t        # Keep a list of preopened convenience libraries to check\n\t        # that they are being used correctly in the link pass.\n\t        test -z \"$libdir\" && \\\n\t          func_append dlpreconveniencelibs \" $dir/$old_library\"\n\t      fi\n\t    ;;\n\t    * )\n\t      # Prefer using a static library (so that no silly _DYNAMIC symbols\n\t      # are required to link).\n\t      if test -n \"$old_library\"; then\n\t        func_append newdlprefiles \" $dir/$old_library\"\n\t        # Keep a list of preopened convenience libraries to check\n\t        # that they are being used correctly in the link pass.\n\t        test -z \"$libdir\" && \\\n\t          func_append dlpreconveniencelibs \" $dir/$old_library\"\n\t      # Otherwise, use the dlname, so that lt_dlopen finds it.\n\t      elif test -n \"$dlname\"; then\n\t        func_append newdlprefiles \" $dir/$dlname\"\n\t      else\n\t        func_append newdlprefiles \" $dir/$linklib\"\n\t      fi\n\t    ;;\n\t  esac\n\tfi # $pass = dlpreopen\n\n\tif test -z \"$libdir\"; then\n\t  # Link the convenience library\n\t  if test lib = \"$linkmode\"; then\n\t    deplibs=\"$dir/$old_library $deplibs\"\n\t  elif test prog,link = \"$linkmode,$pass\"; then\n\t    compile_deplibs=\"$dir/$old_library $compile_deplibs\"\n\t    finalize_deplibs=\"$dir/$old_library $finalize_deplibs\"\n\t  else\n\t    deplibs=\"$lib $deplibs\" # used for prog,scan pass\n\t  fi\n\t  continue\n\tfi\n\n\n\tif test prog = \"$linkmode\" && test link != \"$pass\"; then\n\t  func_append newlib_search_path \" $ladir\"\n\t  deplibs=\"$lib $deplibs\"\n\n\t  linkalldeplibs=false\n\t  if test no != \"$link_all_deplibs\" || test -z \"$library_names\" ||\n\t     test no = \"$build_libtool_libs\"; then\n\t    linkalldeplibs=:\n\t  fi\n\n\t  tmp_libs=\n\t  for deplib in $dependency_libs; do\n\t    case $deplib in\n\t    -L*) func_stripname '-L' '' \"$deplib\"\n\t         func_resolve_sysroot \"$func_stripname_result\"\n\t         func_append newlib_search_path \" $func_resolve_sysroot_result\"\n\t\t ;;\n\t    esac\n\t    # Need to link against all dependency_libs?\n\t    if $linkalldeplibs; then\n\t      deplibs=\"$deplib $deplibs\"\n\t    else\n\t      # Need to hardcode shared library paths\n\t      # or/and link against static libraries\n\t      newdependency_libs=\"$deplib $newdependency_libs\"\n\t    fi\n\t    if $opt_preserve_dup_deps; then\n\t      case \"$tmp_libs \" in\n\t      *\" $deplib \"*) func_append specialdeplibs \" $deplib\" ;;\n\t      esac\n\t    fi\n\t    func_append tmp_libs \" $deplib\"\n\t  done # for deplib\n\t  continue\n\tfi # $linkmode = prog...\n\n\tif test prog,link = \"$linkmode,$pass\"; then\n\t  if test -n \"$library_names\" &&\n\t     { { test no = \"$prefer_static_libs\" ||\n\t         test built,yes = \"$prefer_static_libs,$installed\"; } ||\n\t       test -z \"$old_library\"; }; then\n\t    # We need to hardcode the library path\n\t    if test -n \"$shlibpath_var\" && test -z \"$avoidtemprpath\"; then\n\t      # Make sure the rpath contains only unique directories.\n\t      case $temp_rpath: in\n\t      *\"$absdir:\"*) ;;\n\t      *) func_append temp_rpath \"$absdir:\" ;;\n\t      esac\n\t    fi\n\n\t    # Hardcode the library path.\n\t    # Skip directories that are in the system default run-time\n\t    # search path.\n\t    case \" $sys_lib_dlsearch_path \" in\n\t    *\" $absdir \"*) ;;\n\t    *)\n\t      case \"$compile_rpath \" in\n\t      *\" $absdir \"*) ;;\n\t      *) func_append compile_rpath \" $absdir\" ;;\n\t      esac\n\t      ;;\n\t    esac\n\t    case \" $sys_lib_dlsearch_path \" in\n\t    *\" $libdir \"*) ;;\n\t    *)\n\t      case \"$finalize_rpath \" in\n\t      *\" $libdir \"*) ;;\n\t      *) func_append finalize_rpath \" $libdir\" ;;\n\t      esac\n\t      ;;\n\t    esac\n\t  fi # $linkmode,$pass = prog,link...\n\n\t  if $alldeplibs &&\n\t     { test pass_all = \"$deplibs_check_method\" ||\n\t       { test yes = \"$build_libtool_libs\" &&\n\t\t test -n \"$library_names\"; }; }; then\n\t    # We only need to search for static libraries\n\t    continue\n\t  fi\n\tfi\n\n\tlink_static=no # Whether the deplib will be linked statically\n\tuse_static_libs=$prefer_static_libs\n\tif test built = \"$use_static_libs\" && test yes = \"$installed\"; then\n\t  use_static_libs=no\n\tfi\n\tif test -n \"$library_names\" &&\n\t   { test no = \"$use_static_libs\" || test -z \"$old_library\"; }; then\n\t  case $host in\n\t  *cygwin* | *mingw* | *cegcc* | *os2*)\n\t      # No point in relinking DLLs because paths are not encoded\n\t      func_append notinst_deplibs \" $lib\"\n\t      need_relink=no\n\t    ;;\n\t  *)\n\t    if test no = \"$installed\"; then\n\t      func_append notinst_deplibs \" $lib\"\n\t      need_relink=yes\n\t    fi\n\t    ;;\n\t  esac\n\t  # This is a shared library\n\n\t  # Warn about portability, can't link against -module's on some\n\t  # systems (darwin).  Don't bleat about dlopened modules though!\n\t  dlopenmodule=\n\t  for dlpremoduletest in $dlprefiles; do\n\t    if test \"X$dlpremoduletest\" = \"X$lib\"; then\n\t      dlopenmodule=$dlpremoduletest\n\t      break\n\t    fi\n\t  done\n\t  if test -z \"$dlopenmodule\" && test yes = \"$shouldnotlink\" && test link = \"$pass\"; then\n\t    echo\n\t    if test prog = \"$linkmode\"; then\n\t      $ECHO \"*** Warning: Linking the executable $output against the loadable module\"\n\t    else\n\t      $ECHO \"*** Warning: Linking the shared library $output against the loadable module\"\n\t    fi\n\t    $ECHO \"*** $linklib is not portable!\"\n\t  fi\n\t  if test lib = \"$linkmode\" &&\n\t     test yes = \"$hardcode_into_libs\"; then\n\t    # Hardcode the library path.\n\t    # Skip directories that are in the system default run-time\n\t    # search path.\n\t    case \" $sys_lib_dlsearch_path \" in\n\t    *\" $absdir \"*) ;;\n\t    *)\n\t      case \"$compile_rpath \" in\n\t      *\" $absdir \"*) ;;\n\t      *) func_append compile_rpath \" $absdir\" ;;\n\t      esac\n\t      ;;\n\t    esac\n\t    case \" $sys_lib_dlsearch_path \" in\n\t    *\" $libdir \"*) ;;\n\t    *)\n\t      case \"$finalize_rpath \" in\n\t      *\" $libdir \"*) ;;\n\t      *) func_append finalize_rpath \" $libdir\" ;;\n\t      esac\n\t      ;;\n\t    esac\n\t  fi\n\n\t  if test -n \"$old_archive_from_expsyms_cmds\"; then\n\t    # figure out the soname\n\t    set dummy $library_names\n\t    shift\n\t    realname=$1\n\t    shift\n\t    libname=`eval \"\\\\$ECHO \\\"$libname_spec\\\"\"`\n\t    # use dlname if we got it. it's perfectly good, no?\n\t    if test -n \"$dlname\"; then\n\t      soname=$dlname\n\t    elif test -n \"$soname_spec\"; then\n\t      # bleh windows\n\t      case $host in\n\t      *cygwin* | mingw* | *cegcc* | *os2*)\n\t        func_arith $current - $age\n\t\tmajor=$func_arith_result\n\t\tversuffix=-$major\n\t\t;;\n\t      esac\n\t      eval soname=\\\"$soname_spec\\\"\n\t    else\n\t      soname=$realname\n\t    fi\n\n\t    # Make a new name for the extract_expsyms_cmds to use\n\t    soroot=$soname\n\t    func_basename \"$soroot\"\n\t    soname=$func_basename_result\n\t    func_stripname 'lib' '.dll' \"$soname\"\n\t    newlib=libimp-$func_stripname_result.a\n\n\t    # If the library has no export list, then create one now\n\t    if test -f \"$output_objdir/$soname-def\"; then :\n\t    else\n\t      func_verbose \"extracting exported symbol list from '$soname'\"\n\t      func_execute_cmds \"$extract_expsyms_cmds\" 'exit $?'\n\t    fi\n\n\t    # Create $newlib\n\t    if test -f \"$output_objdir/$newlib\"; then :; else\n\t      func_verbose \"generating import library for '$soname'\"\n\t      func_execute_cmds \"$old_archive_from_expsyms_cmds\" 'exit $?'\n\t    fi\n\t    # make sure the library variables are pointing to the new library\n\t    dir=$output_objdir\n\t    linklib=$newlib\n\t  fi # test -n \"$old_archive_from_expsyms_cmds\"\n\n\t  if test prog = \"$linkmode\" || test relink != \"$opt_mode\"; then\n\t    add_shlibpath=\n\t    add_dir=\n\t    add=\n\t    lib_linked=yes\n\t    case $hardcode_action in\n\t    immediate | unsupported)\n\t      if test no = \"$hardcode_direct\"; then\n\t\tadd=$dir/$linklib\n\t\tcase $host in\n\t\t  *-*-sco3.2v5.0.[024]*) add_dir=-L$dir ;;\n\t\t  *-*-sysv4*uw2*) add_dir=-L$dir ;;\n\t\t  *-*-sysv5OpenUNIX* | *-*-sysv5UnixWare7.[01].[10]* | \\\n\t\t    *-*-unixware7*) add_dir=-L$dir ;;\n\t\t  *-*-darwin* )\n\t\t    # if the lib is a (non-dlopened) module then we cannot\n\t\t    # link against it, someone is ignoring the earlier warnings\n\t\t    if /usr/bin/file -L $add 2> /dev/null |\n\t\t\t $GREP \": [^:]* bundle\" >/dev/null; then\n\t\t      if test \"X$dlopenmodule\" != \"X$lib\"; then\n\t\t\t$ECHO \"*** Warning: lib $linklib is a module, not a shared library\"\n\t\t\tif test -z \"$old_library\"; then\n\t\t\t  echo\n\t\t\t  echo \"*** And there doesn't seem to be a static archive available\"\n\t\t\t  echo \"*** The link will probably fail, sorry\"\n\t\t\telse\n\t\t\t  add=$dir/$old_library\n\t\t\tfi\n\t\t      elif test -n \"$old_library\"; then\n\t\t\tadd=$dir/$old_library\n\t\t      fi\n\t\t    fi\n\t\tesac\n\t      elif test no = \"$hardcode_minus_L\"; then\n\t\tcase $host in\n\t\t*-*-sunos*) add_shlibpath=$dir ;;\n\t\tesac\n\t\tadd_dir=-L$dir\n\t\tadd=-l$name\n\t      elif test no = \"$hardcode_shlibpath_var\"; then\n\t\tadd_shlibpath=$dir\n\t\tadd=-l$name\n\t      else\n\t\tlib_linked=no\n\t      fi\n\t      ;;\n\t    relink)\n\t      if test yes = \"$hardcode_direct\" &&\n\t         test no = \"$hardcode_direct_absolute\"; then\n\t\tadd=$dir/$linklib\n\t      elif test yes = \"$hardcode_minus_L\"; then\n\t\tadd_dir=-L$absdir\n\t\t# Try looking first in the location we're being installed to.\n\t\tif test -n \"$inst_prefix_dir\"; then\n\t\t  case $libdir in\n\t\t    [\\\\/]*)\n\t\t      func_append add_dir \" -L$inst_prefix_dir$libdir\"\n\t\t      ;;\n\t\t  esac\n\t\tfi\n\t\tadd=-l$name\n\t      elif test yes = \"$hardcode_shlibpath_var\"; then\n\t\tadd_shlibpath=$dir\n\t\tadd=-l$name\n\t      else\n\t\tlib_linked=no\n\t      fi\n\t      ;;\n\t    *) lib_linked=no ;;\n\t    esac\n\n\t    if test yes != \"$lib_linked\"; then\n\t      func_fatal_configuration \"unsupported hardcode properties\"\n\t    fi\n\n\t    if test -n \"$add_shlibpath\"; then\n\t      case :$compile_shlibpath: in\n\t      *\":$add_shlibpath:\"*) ;;\n\t      *) func_append compile_shlibpath \"$add_shlibpath:\" ;;\n\t      esac\n\t    fi\n\t    if test prog = \"$linkmode\"; then\n\t      test -n \"$add_dir\" && compile_deplibs=\"$add_dir $compile_deplibs\"\n\t      test -n \"$add\" && compile_deplibs=\"$add $compile_deplibs\"\n\t    else\n\t      test -n \"$add_dir\" && deplibs=\"$add_dir $deplibs\"\n\t      test -n \"$add\" && deplibs=\"$add $deplibs\"\n\t      if test yes != \"$hardcode_direct\" &&\n\t\t test yes != \"$hardcode_minus_L\" &&\n\t\t test yes = \"$hardcode_shlibpath_var\"; then\n\t\tcase :$finalize_shlibpath: in\n\t\t*\":$libdir:\"*) ;;\n\t\t*) func_append finalize_shlibpath \"$libdir:\" ;;\n\t\tesac\n\t      fi\n\t    fi\n\t  fi\n\n\t  if test prog = \"$linkmode\" || test relink = \"$opt_mode\"; then\n\t    add_shlibpath=\n\t    add_dir=\n\t    add=\n\t    # Finalize command for both is simple: just hardcode it.\n\t    if test yes = \"$hardcode_direct\" &&\n\t       test no = \"$hardcode_direct_absolute\"; then\n\t      add=$libdir/$linklib\n\t    elif test yes = \"$hardcode_minus_L\"; then\n\t      add_dir=-L$libdir\n\t      add=-l$name\n\t    elif test yes = \"$hardcode_shlibpath_var\"; then\n\t      case :$finalize_shlibpath: in\n\t      *\":$libdir:\"*) ;;\n\t      *) func_append finalize_shlibpath \"$libdir:\" ;;\n\t      esac\n\t      add=-l$name\n\t    elif test yes = \"$hardcode_automatic\"; then\n\t      if test -n \"$inst_prefix_dir\" &&\n\t\t test -f \"$inst_prefix_dir$libdir/$linklib\"; then\n\t\tadd=$inst_prefix_dir$libdir/$linklib\n\t      else\n\t\tadd=$libdir/$linklib\n\t      fi\n\t    else\n\t      # We cannot seem to hardcode it, guess we'll fake it.\n\t      add_dir=-L$libdir\n\t      # Try looking first in the location we're being installed to.\n\t      if test -n \"$inst_prefix_dir\"; then\n\t\tcase $libdir in\n\t\t  [\\\\/]*)\n\t\t    func_append add_dir \" -L$inst_prefix_dir$libdir\"\n\t\t    ;;\n\t\tesac\n\t      fi\n\t      add=-l$name\n\t    fi\n\n\t    if test prog = \"$linkmode\"; then\n\t      test -n \"$add_dir\" && finalize_deplibs=\"$add_dir $finalize_deplibs\"\n\t      test -n \"$add\" && finalize_deplibs=\"$add $finalize_deplibs\"\n\t    else\n\t      test -n \"$add_dir\" && deplibs=\"$add_dir $deplibs\"\n\t      test -n \"$add\" && deplibs=\"$add $deplibs\"\n\t    fi\n\t  fi\n\telif test prog = \"$linkmode\"; then\n\t  # Here we assume that one of hardcode_direct or hardcode_minus_L\n\t  # is not unsupported.  This is valid on all known static and\n\t  # shared platforms.\n\t  if test unsupported != \"$hardcode_direct\"; then\n\t    test -n \"$old_library\" && linklib=$old_library\n\t    compile_deplibs=\"$dir/$linklib $compile_deplibs\"\n\t    finalize_deplibs=\"$dir/$linklib $finalize_deplibs\"\n\t  else\n\t    compile_deplibs=\"-l$name -L$dir $compile_deplibs\"\n\t    finalize_deplibs=\"-l$name -L$dir $finalize_deplibs\"\n\t  fi\n\telif test yes = \"$build_libtool_libs\"; then\n\t  # Not a shared library\n\t  if test pass_all != \"$deplibs_check_method\"; then\n\t    # We're trying link a shared library against a static one\n\t    # but the system doesn't support it.\n\n\t    # Just print a warning and add the library to dependency_libs so\n\t    # that the program can be linked against the static library.\n\t    echo\n\t    $ECHO \"*** Warning: This system cannot link to static lib archive $lib.\"\n\t    echo \"*** I have the capability to make that library automatically link in when\"\n\t    echo \"*** you link to this library.  But I can only do this if you have a\"\n\t    echo \"*** shared version of the library, which you do not appear to have.\"\n\t    if test yes = \"$module\"; then\n\t      echo \"*** But as you try to build a module library, libtool will still create \"\n\t      echo \"*** a static module, that should work as long as the dlopening application\"\n\t      echo \"*** is linked with the -dlopen flag to resolve symbols at runtime.\"\n\t      if test -z \"$global_symbol_pipe\"; then\n\t\techo\n\t\techo \"*** However, this would only work if libtool was able to extract symbol\"\n\t\techo \"*** lists from a program, using 'nm' or equivalent, but libtool could\"\n\t\techo \"*** not find such a program.  So, this module is probably useless.\"\n\t\techo \"*** 'nm' from GNU binutils and a full rebuild may help.\"\n\t      fi\n\t      if test no = \"$build_old_libs\"; then\n\t\tbuild_libtool_libs=module\n\t\tbuild_old_libs=yes\n\t      else\n\t\tbuild_libtool_libs=no\n\t      fi\n\t    fi\n\t  else\n\t    deplibs=\"$dir/$old_library $deplibs\"\n\t    link_static=yes\n\t  fi\n\tfi # link shared/static library?\n\n\tif test lib = \"$linkmode\"; then\n\t  if test -n \"$dependency_libs\" &&\n\t     { test yes != \"$hardcode_into_libs\" ||\n\t       test yes = \"$build_old_libs\" ||\n\t       test yes = \"$link_static\"; }; then\n\t    # Extract -R from dependency_libs\n\t    temp_deplibs=\n\t    for libdir in $dependency_libs; do\n\t      case $libdir in\n\t      -R*) func_stripname '-R' '' \"$libdir\"\n\t           temp_xrpath=$func_stripname_result\n\t\t   case \" $xrpath \" in\n\t\t   *\" $temp_xrpath \"*) ;;\n\t\t   *) func_append xrpath \" $temp_xrpath\";;\n\t\t   esac;;\n\t      *) func_append temp_deplibs \" $libdir\";;\n\t      esac\n\t    done\n\t    dependency_libs=$temp_deplibs\n\t  fi\n\n\t  func_append newlib_search_path \" $absdir\"\n\t  # Link against this library\n\t  test no = \"$link_static\" && newdependency_libs=\"$abs_ladir/$laname $newdependency_libs\"\n\t  # ... and its dependency_libs\n\t  tmp_libs=\n\t  for deplib in $dependency_libs; do\n\t    newdependency_libs=\"$deplib $newdependency_libs\"\n\t    case $deplib in\n              -L*) func_stripname '-L' '' \"$deplib\"\n                   func_resolve_sysroot \"$func_stripname_result\";;\n              *) func_resolve_sysroot \"$deplib\" ;;\n            esac\n\t    if $opt_preserve_dup_deps; then\n\t      case \"$tmp_libs \" in\n\t      *\" $func_resolve_sysroot_result \"*)\n                func_append specialdeplibs \" $func_resolve_sysroot_result\" ;;\n\t      esac\n\t    fi\n\t    func_append tmp_libs \" $func_resolve_sysroot_result\"\n\t  done\n\n\t  if test no != \"$link_all_deplibs\"; then\n\t    # Add the search paths of all dependency libraries\n\t    for deplib in $dependency_libs; do\n\t      path=\n\t      case $deplib in\n\t      -L*) path=$deplib ;;\n\t      *.la)\n\t        func_resolve_sysroot \"$deplib\"\n\t        deplib=$func_resolve_sysroot_result\n\t        func_dirname \"$deplib\" \"\" \".\"\n\t\tdir=$func_dirname_result\n\t\t# We need an absolute path.\n\t\tcase $dir in\n\t\t[\\\\/]* | [A-Za-z]:[\\\\/]*) absdir=$dir ;;\n\t\t*)\n\t\t  absdir=`cd \"$dir\" && pwd`\n\t\t  if test -z \"$absdir\"; then\n\t\t    func_warning \"cannot determine absolute directory name of '$dir'\"\n\t\t    absdir=$dir\n\t\t  fi\n\t\t  ;;\n\t\tesac\n\t\tif $GREP \"^installed=no\" $deplib > /dev/null; then\n\t\tcase $host in\n\t\t*-*-darwin*)\n\t\t  depdepl=\n\t\t  eval deplibrary_names=`$SED -n -e 's/^library_names=\\(.*\\)$/\\1/p' $deplib`\n\t\t  if test -n \"$deplibrary_names\"; then\n\t\t    for tmp in $deplibrary_names; do\n\t\t      depdepl=$tmp\n\t\t    done\n\t\t    if test -f \"$absdir/$objdir/$depdepl\"; then\n\t\t      depdepl=$absdir/$objdir/$depdepl\n\t\t      darwin_install_name=`$OTOOL -L $depdepl | awk '{if (NR == 2) {print $1;exit}}'`\n                      if test -z \"$darwin_install_name\"; then\n                          darwin_install_name=`$OTOOL64 -L $depdepl  | awk '{if (NR == 2) {print $1;exit}}'`\n                      fi\n\t\t      func_append compiler_flags \" $wl-dylib_file $wl$darwin_install_name:$depdepl\"\n\t\t      func_append linker_flags \" -dylib_file $darwin_install_name:$depdepl\"\n\t\t      path=\n\t\t    fi\n\t\t  fi\n\t\t  ;;\n\t\t*)\n\t\t  path=-L$absdir/$objdir\n\t\t  ;;\n\t\tesac\n\t\telse\n\t\t  eval libdir=`$SED -n -e 's/^libdir=\\(.*\\)$/\\1/p' $deplib`\n\t\t  test -z \"$libdir\" && \\\n\t\t    func_fatal_error \"'$deplib' is not a valid libtool archive\"\n\t\t  test \"$absdir\" != \"$libdir\" && \\\n\t\t    func_warning \"'$deplib' seems to be moved\"\n\n\t\t  path=-L$absdir\n\t\tfi\n\t\t;;\n\t      esac\n\t      case \" $deplibs \" in\n\t      *\" $path \"*) ;;\n\t      *) deplibs=\"$path $deplibs\" ;;\n\t      esac\n\t    done\n\t  fi # link_all_deplibs != no\n\tfi # linkmode = lib\n      done # for deplib in $libs\n      if test link = \"$pass\"; then\n\tif test prog = \"$linkmode\"; then\n\t  compile_deplibs=\"$new_inherited_linker_flags $compile_deplibs\"\n\t  finalize_deplibs=\"$new_inherited_linker_flags $finalize_deplibs\"\n\telse\n\t  compiler_flags=\"$compiler_flags \"`$ECHO \" $new_inherited_linker_flags\" | $SED 's% \\([^ $]*\\).ltframework% -framework \\1%g'`\n\tfi\n      fi\n      dependency_libs=$newdependency_libs\n      if test dlpreopen = \"$pass\"; then\n\t# Link the dlpreopened libraries before other libraries\n\tfor deplib in $save_deplibs; do\n\t  deplibs=\"$deplib $deplibs\"\n\tdone\n      fi\n      if test dlopen != \"$pass\"; then\n\ttest conv = \"$pass\" || {\n\t  # Make sure lib_search_path contains only unique directories.\n\t  lib_search_path=\n\t  for dir in $newlib_search_path; do\n\t    case \"$lib_search_path \" in\n\t    *\" $dir \"*) ;;\n\t    *) func_append lib_search_path \" $dir\" ;;\n\t    esac\n\t  done\n\t  newlib_search_path=\n\t}\n\n\tif test prog,link = \"$linkmode,$pass\"; then\n\t  vars=\"compile_deplibs finalize_deplibs\"\n\telse\n\t  vars=deplibs\n\tfi\n\tfor var in $vars dependency_libs; do\n\t  # Add libraries to $var in reverse order\n\t  eval tmp_libs=\\\"\\$$var\\\"\n\t  new_libs=\n\t  for deplib in $tmp_libs; do\n\t    # FIXME: Pedantically, this is the right thing to do, so\n\t    #        that some nasty dependency loop isn't accidentally\n\t    #        broken:\n\t    #new_libs=\"$deplib $new_libs\"\n\t    # Pragmatically, this seems to cause very few problems in\n\t    # practice:\n\t    case $deplib in\n\t    -L*) new_libs=\"$deplib $new_libs\" ;;\n\t    -R*) ;;\n\t    *)\n\t      # And here is the reason: when a library appears more\n\t      # than once as an explicit dependence of a library, or\n\t      # is implicitly linked in more than once by the\n\t      # compiler, it is considered special, and multiple\n\t      # occurrences thereof are not removed.  Compare this\n\t      # with having the same library being listed as a\n\t      # dependency of multiple other libraries: in this case,\n\t      # we know (pedantically, we assume) the library does not\n\t      # need to be listed more than once, so we keep only the\n\t      # last copy.  This is not always right, but it is rare\n\t      # enough that we require users that really mean to play\n\t      # such unportable linking tricks to link the library\n\t      # using -Wl,-lname, so that libtool does not consider it\n\t      # for duplicate removal.\n\t      case \" $specialdeplibs \" in\n\t      *\" $deplib \"*) new_libs=\"$deplib $new_libs\" ;;\n\t      *)\n\t\tcase \" $new_libs \" in\n\t\t*\" $deplib \"*) ;;\n\t\t*) new_libs=\"$deplib $new_libs\" ;;\n\t\tesac\n\t\t;;\n\t      esac\n\t      ;;\n\t    esac\n\t  done\n\t  tmp_libs=\n\t  for deplib in $new_libs; do\n\t    case $deplib in\n\t    -L*)\n\t      case \" $tmp_libs \" in\n\t      *\" $deplib \"*) ;;\n\t      *) func_append tmp_libs \" $deplib\" ;;\n\t      esac\n\t      ;;\n\t    *) func_append tmp_libs \" $deplib\" ;;\n\t    esac\n\t  done\n\t  eval $var=\\\"$tmp_libs\\\"\n\tdone # for var\n      fi\n\n      # Add Sun CC postdeps if required:\n      test CXX = \"$tagname\" && {\n        case $host_os in\n        linux*)\n          case `$CC -V 2>&1 | sed 5q` in\n          *Sun\\ C*) # Sun C++ 5.9\n            func_suncc_cstd_abi\n\n            if test no != \"$suncc_use_cstd_abi\"; then\n              func_append postdeps ' -library=Cstd -library=Crun'\n            fi\n            ;;\n          esac\n          ;;\n\n        solaris*)\n          func_cc_basename \"$CC\"\n          case $func_cc_basename_result in\n          CC* | sunCC*)\n            func_suncc_cstd_abi\n\n            if test no != \"$suncc_use_cstd_abi\"; then\n              func_append postdeps ' -library=Cstd -library=Crun'\n            fi\n            ;;\n          esac\n          ;;\n        esac\n      }\n\n      # Last step: remove runtime libs from dependency_libs\n      # (they stay in deplibs)\n      tmp_libs=\n      for i in $dependency_libs; do\n\tcase \" $predeps $postdeps $compiler_lib_search_path \" in\n\t*\" $i \"*)\n\t  i=\n\t  ;;\n\tesac\n\tif test -n \"$i\"; then\n\t  func_append tmp_libs \" $i\"\n\tfi\n      done\n      dependency_libs=$tmp_libs\n    done # for pass\n    if test prog = \"$linkmode\"; then\n      dlfiles=$newdlfiles\n    fi\n    if test prog = \"$linkmode\" || test lib = \"$linkmode\"; then\n      dlprefiles=$newdlprefiles\n    fi\n\n    case $linkmode in\n    oldlib)\n      if test -n \"$dlfiles$dlprefiles\" || test no != \"$dlself\"; then\n\tfunc_warning \"'-dlopen' is ignored for archives\"\n      fi\n\n      case \" $deplibs\" in\n      *\\ -l* | *\\ -L*)\n\tfunc_warning \"'-l' and '-L' are ignored for archives\" ;;\n      esac\n\n      test -n \"$rpath\" && \\\n\tfunc_warning \"'-rpath' is ignored for archives\"\n\n      test -n \"$xrpath\" && \\\n\tfunc_warning \"'-R' is ignored for archives\"\n\n      test -n \"$vinfo\" && \\\n\tfunc_warning \"'-version-info/-version-number' is ignored for archives\"\n\n      test -n \"$release\" && \\\n\tfunc_warning \"'-release' is ignored for archives\"\n\n      test -n \"$export_symbols$export_symbols_regex\" && \\\n\tfunc_warning \"'-export-symbols' is ignored for archives\"\n\n      # Now set the variables for building old libraries.\n      build_libtool_libs=no\n      oldlibs=$output\n      func_append objs \"$old_deplibs\"\n      ;;\n\n    lib)\n      # Make sure we only generate libraries of the form 'libNAME.la'.\n      case $outputname in\n      lib*)\n\tfunc_stripname 'lib' '.la' \"$outputname\"\n\tname=$func_stripname_result\n\teval shared_ext=\\\"$shrext_cmds\\\"\n\teval libname=\\\"$libname_spec\\\"\n\t;;\n      *)\n\ttest no = \"$module\" \\\n\t  && func_fatal_help \"libtool library '$output' must begin with 'lib'\"\n\n\tif test no != \"$need_lib_prefix\"; then\n\t  # Add the \"lib\" prefix for modules if required\n\t  func_stripname '' '.la' \"$outputname\"\n\t  name=$func_stripname_result\n\t  eval shared_ext=\\\"$shrext_cmds\\\"\n\t  eval libname=\\\"$libname_spec\\\"\n\telse\n\t  func_stripname '' '.la' \"$outputname\"\n\t  libname=$func_stripname_result\n\tfi\n\t;;\n      esac\n\n      if test -n \"$objs\"; then\n\tif test pass_all != \"$deplibs_check_method\"; then\n\t  func_fatal_error \"cannot build libtool library '$output' from non-libtool objects on this host:$objs\"\n\telse\n\t  echo\n\t  $ECHO \"*** Warning: Linking the shared library $output against the non-libtool\"\n\t  $ECHO \"*** objects $objs is not portable!\"\n\t  func_append libobjs \" $objs\"\n\tfi\n      fi\n\n      test no = \"$dlself\" \\\n\t|| func_warning \"'-dlopen self' is ignored for libtool libraries\"\n\n      set dummy $rpath\n      shift\n      test 1 -lt \"$#\" \\\n\t&& func_warning \"ignoring multiple '-rpath's for a libtool library\"\n\n      install_libdir=$1\n\n      oldlibs=\n      if test -z \"$rpath\"; then\n\tif test yes = \"$build_libtool_libs\"; then\n\t  # Building a libtool convenience library.\n\t  # Some compilers have problems with a '.al' extension so\n\t  # convenience libraries should have the same extension an\n\t  # archive normally would.\n\t  oldlibs=\"$output_objdir/$libname.$libext $oldlibs\"\n\t  build_libtool_libs=convenience\n\t  build_old_libs=yes\n\tfi\n\n\ttest -n \"$vinfo\" && \\\n\t  func_warning \"'-version-info/-version-number' is ignored for convenience libraries\"\n\n\ttest -n \"$release\" && \\\n\t  func_warning \"'-release' is ignored for convenience libraries\"\n      else\n\n\t# Parse the version information argument.\n\tsave_ifs=$IFS; IFS=:\n\tset dummy $vinfo 0 0 0\n\tshift\n\tIFS=$save_ifs\n\n\ttest -n \"$7\" && \\\n\t  func_fatal_help \"too many parameters to '-version-info'\"\n\n\t# convert absolute version numbers to libtool ages\n\t# this retains compatibility with .la files and attempts\n\t# to make the code below a bit more comprehensible\n\n\tcase $vinfo_number in\n\tyes)\n\t  number_major=$1\n\t  number_minor=$2\n\t  number_revision=$3\n\t  #\n\t  # There are really only two kinds -- those that\n\t  # use the current revision as the major version\n\t  # and those that subtract age and use age as\n\t  # a minor version.  But, then there is irix\n\t  # that has an extra 1 added just for fun\n\t  #\n\t  case $version_type in\n\t  # correct linux to gnu/linux during the next big refactor\n\t  darwin|freebsd-elf|linux|osf|windows|none)\n\t    func_arith $number_major + $number_minor\n\t    current=$func_arith_result\n\t    age=$number_minor\n\t    revision=$number_revision\n\t    ;;\n\t  freebsd-aout|qnx|sunos)\n\t    current=$number_major\n\t    revision=$number_minor\n\t    age=0\n\t    ;;\n\t  irix|nonstopux)\n\t    func_arith $number_major + $number_minor\n\t    current=$func_arith_result\n\t    age=$number_minor\n\t    revision=$number_minor\n\t    lt_irix_increment=no\n\t    ;;\n\t  esac\n\t  ;;\n\tno)\n\t  current=$1\n\t  revision=$2\n\t  age=$3\n\t  ;;\n\tesac\n\n\t# Check that each of the things are valid numbers.\n\tcase $current in\n\t0|[1-9]|[1-9][0-9]|[1-9][0-9][0-9]|[1-9][0-9][0-9][0-9]|[1-9][0-9][0-9][0-9][0-9]) ;;\n\t*)\n\t  func_error \"CURRENT '$current' must be a nonnegative integer\"\n\t  func_fatal_error \"'$vinfo' is not valid version information\"\n\t  ;;\n\tesac\n\n\tcase $revision in\n\t0|[1-9]|[1-9][0-9]|[1-9][0-9][0-9]|[1-9][0-9][0-9][0-9]|[1-9][0-9][0-9][0-9][0-9]) ;;\n\t*)\n\t  func_error \"REVISION '$revision' must be a nonnegative integer\"\n\t  func_fatal_error \"'$vinfo' is not valid version information\"\n\t  ;;\n\tesac\n\n\tcase $age in\n\t0|[1-9]|[1-9][0-9]|[1-9][0-9][0-9]|[1-9][0-9][0-9][0-9]|[1-9][0-9][0-9][0-9][0-9]) ;;\n\t*)\n\t  func_error \"AGE '$age' must be a nonnegative integer\"\n\t  func_fatal_error \"'$vinfo' is not valid version information\"\n\t  ;;\n\tesac\n\n\tif test \"$age\" -gt \"$current\"; then\n\t  func_error \"AGE '$age' is greater than the current interface number '$current'\"\n\t  func_fatal_error \"'$vinfo' is not valid version information\"\n\tfi\n\n\t# Calculate the version variables.\n\tmajor=\n\tversuffix=\n\tverstring=\n\tcase $version_type in\n\tnone) ;;\n\n\tdarwin)\n\t  # Like Linux, but with the current version available in\n\t  # verstring for coding it into the library header\n\t  func_arith $current - $age\n\t  major=.$func_arith_result\n\t  versuffix=$major.$age.$revision\n\t  # Darwin ld doesn't like 0 for these options...\n\t  func_arith $current + 1\n\t  minor_current=$func_arith_result\n\t  xlcverstring=\"$wl-compatibility_version $wl$minor_current $wl-current_version $wl$minor_current.$revision\"\n\t  verstring=\"-compatibility_version $minor_current -current_version $minor_current.$revision\"\n          # On Darwin other compilers\n          case $CC in\n              nagfor*)\n                  verstring=\"$wl-compatibility_version $wl$minor_current $wl-current_version $wl$minor_current.$revision\"\n                  ;;\n              *)\n                  verstring=\"-compatibility_version $minor_current -current_version $minor_current.$revision\"\n                  ;;\n          esac\n\t  ;;\n\n\tfreebsd-aout)\n\t  major=.$current\n\t  versuffix=.$current.$revision\n\t  ;;\n\n\tfreebsd-elf)\n\t  func_arith $current - $age\n\t  major=.$func_arith_result\n\t  versuffix=$major.$age.$revision\n\t  ;;\n\n\tirix | nonstopux)\n\t  if test no = \"$lt_irix_increment\"; then\n\t    func_arith $current - $age\n\t  else\n\t    func_arith $current - $age + 1\n\t  fi\n\t  major=$func_arith_result\n\n\t  case $version_type in\n\t    nonstopux) verstring_prefix=nonstopux ;;\n\t    *)         verstring_prefix=sgi ;;\n\t  esac\n\t  verstring=$verstring_prefix$major.$revision\n\n\t  # Add in all the interfaces that we are compatible with.\n\t  loop=$revision\n\t  while test 0 -ne \"$loop\"; do\n\t    func_arith $revision - $loop\n\t    iface=$func_arith_result\n\t    func_arith $loop - 1\n\t    loop=$func_arith_result\n\t    verstring=$verstring_prefix$major.$iface:$verstring\n\t  done\n\n\t  # Before this point, $major must not contain '.'.\n\t  major=.$major\n\t  versuffix=$major.$revision\n\t  ;;\n\n\tlinux) # correct to gnu/linux during the next big refactor\n\t  func_arith $current - $age\n\t  major=.$func_arith_result\n\t  versuffix=$major.$age.$revision\n\t  ;;\n\n\tosf)\n\t  func_arith $current - $age\n\t  major=.$func_arith_result\n\t  versuffix=.$current.$age.$revision\n\t  verstring=$current.$age.$revision\n\n\t  # Add in all the interfaces that we are compatible with.\n\t  loop=$age\n\t  while test 0 -ne \"$loop\"; do\n\t    func_arith $current - $loop\n\t    iface=$func_arith_result\n\t    func_arith $loop - 1\n\t    loop=$func_arith_result\n\t    verstring=$verstring:$iface.0\n\t  done\n\n\t  # Make executables depend on our current version.\n\t  func_append verstring \":$current.0\"\n\t  ;;\n\n\tqnx)\n\t  major=.$current\n\t  versuffix=.$current\n\t  ;;\n\n\tsco)\n\t  major=.$current\n\t  versuffix=.$current\n\t  ;;\n\n\tsunos)\n\t  major=.$current\n\t  versuffix=.$current.$revision\n\t  ;;\n\n\twindows)\n\t  # Use '-' rather than '.', since we only want one\n\t  # extension on DOS 8.3 file systems.\n\t  func_arith $current - $age\n\t  major=$func_arith_result\n\t  versuffix=-$major\n\t  ;;\n\n\t*)\n\t  func_fatal_configuration \"unknown library version type '$version_type'\"\n\t  ;;\n\tesac\n\n\t# Clear the version info if we defaulted, and they specified a release.\n\tif test -z \"$vinfo\" && test -n \"$release\"; then\n\t  major=\n\t  case $version_type in\n\t  darwin)\n\t    # we can't check for \"0.0\" in archive_cmds due to quoting\n\t    # problems, so we reset it completely\n\t    verstring=\n\t    ;;\n\t  *)\n\t    verstring=0.0\n\t    ;;\n\t  esac\n\t  if test no = \"$need_version\"; then\n\t    versuffix=\n\t  else\n\t    versuffix=.0.0\n\t  fi\n\tfi\n\n\t# Remove version info from name if versioning should be avoided\n\tif test yes,no = \"$avoid_version,$need_version\"; then\n\t  major=\n\t  versuffix=\n\t  verstring=\n\tfi\n\n\t# Check to see if the archive will have undefined symbols.\n\tif test yes = \"$allow_undefined\"; then\n\t  if test unsupported = \"$allow_undefined_flag\"; then\n\t    if test yes = \"$build_old_libs\"; then\n\t      func_warning \"undefined symbols not allowed in $host shared libraries; building static only\"\n\t      build_libtool_libs=no\n\t    else\n\t      func_fatal_error \"can't build $host shared library unless -no-undefined is specified\"\n\t    fi\n\t  fi\n\telse\n\t  # Don't allow undefined symbols.\n\t  allow_undefined_flag=$no_undefined_flag\n\tfi\n\n      fi\n\n      func_generate_dlsyms \"$libname\" \"$libname\" :\n      func_append libobjs \" $symfileobj\"\n      test \" \" = \"$libobjs\" && libobjs=\n\n      if test relink != \"$opt_mode\"; then\n\t# Remove our outputs, but don't remove object files since they\n\t# may have been created when compiling PIC objects.\n\tremovelist=\n\ttempremovelist=`$ECHO \"$output_objdir/*\"`\n\tfor p in $tempremovelist; do\n\t  case $p in\n\t    *.$objext | *.gcno)\n\t       ;;\n\t    $output_objdir/$outputname | $output_objdir/$libname.* | $output_objdir/$libname$release.*)\n\t       if test -n \"$precious_files_regex\"; then\n\t\t if $ECHO \"$p\" | $EGREP -e \"$precious_files_regex\" >/dev/null 2>&1\n\t\t then\n\t\t   continue\n\t\t fi\n\t       fi\n\t       func_append removelist \" $p\"\n\t       ;;\n\t    *) ;;\n\t  esac\n\tdone\n\ttest -n \"$removelist\" && \\\n\t  func_show_eval \"${RM}r \\$removelist\"\n      fi\n\n      # Now set the variables for building old libraries.\n      if test yes = \"$build_old_libs\" && test convenience != \"$build_libtool_libs\"; then\n\tfunc_append oldlibs \" $output_objdir/$libname.$libext\"\n\n\t# Transform .lo files to .o files.\n\toldobjs=\"$objs \"`$ECHO \"$libobjs\" | $SP2NL | $SED \"/\\.$libext$/d; $lo2o\" | $NL2SP`\n      fi\n\n      # Eliminate all temporary directories.\n      #for path in $notinst_path; do\n      #\tlib_search_path=`$ECHO \"$lib_search_path \" | $SED \"s% $path % %g\"`\n      #\tdeplibs=`$ECHO \"$deplibs \" | $SED \"s% -L$path % %g\"`\n      #\tdependency_libs=`$ECHO \"$dependency_libs \" | $SED \"s% -L$path % %g\"`\n      #done\n\n      if test -n \"$xrpath\"; then\n\t# If the user specified any rpath flags, then add them.\n\ttemp_xrpath=\n\tfor libdir in $xrpath; do\n\t  func_replace_sysroot \"$libdir\"\n\t  func_append temp_xrpath \" -R$func_replace_sysroot_result\"\n\t  case \"$finalize_rpath \" in\n\t  *\" $libdir \"*) ;;\n\t  *) func_append finalize_rpath \" $libdir\" ;;\n\t  esac\n\tdone\n\tif test yes != \"$hardcode_into_libs\" || test yes = \"$build_old_libs\"; then\n\t  dependency_libs=\"$temp_xrpath $dependency_libs\"\n\tfi\n      fi\n\n      # Make sure dlfiles contains only unique files that won't be dlpreopened\n      old_dlfiles=$dlfiles\n      dlfiles=\n      for lib in $old_dlfiles; do\n\tcase \" $dlprefiles $dlfiles \" in\n\t*\" $lib \"*) ;;\n\t*) func_append dlfiles \" $lib\" ;;\n\tesac\n      done\n\n      # Make sure dlprefiles contains only unique files\n      old_dlprefiles=$dlprefiles\n      dlprefiles=\n      for lib in $old_dlprefiles; do\n\tcase \"$dlprefiles \" in\n\t*\" $lib \"*) ;;\n\t*) func_append dlprefiles \" $lib\" ;;\n\tesac\n      done\n\n      if test yes = \"$build_libtool_libs\"; then\n\tif test -n \"$rpath\"; then\n\t  case $host in\n\t  *-*-cygwin* | *-*-mingw* | *-*-pw32* | *-*-os2* | *-*-beos* | *-cegcc* | *-*-haiku*)\n\t    # these systems don't actually have a c library (as such)!\n\t    ;;\n\t  *-*-rhapsody* | *-*-darwin1.[012])\n\t    # Rhapsody C library is in the System framework\n\t    func_append deplibs \" System.ltframework\"\n\t    ;;\n\t  *-*-netbsd*)\n\t    # Don't link with libc until the a.out ld.so is fixed.\n\t    ;;\n\t  *-*-openbsd* | *-*-freebsd* | *-*-dragonfly*)\n\t    # Do not include libc due to us having libc/libc_r.\n\t    ;;\n\t  *-*-sco3.2v5* | *-*-sco5v6*)\n\t    # Causes problems with __ctype\n\t    ;;\n\t  *-*-sysv4.2uw2* | *-*-sysv5* | *-*-unixware* | *-*-OpenUNIX*)\n\t    # Compiler inserts libc in the correct place for threads to work\n\t    ;;\n\t  *)\n\t    # Add libc to deplibs on all other systems if necessary.\n\t    if test yes = \"$build_libtool_need_lc\"; then\n\t      func_append deplibs \" -lc\"\n\t    fi\n\t    ;;\n\t  esac\n\tfi\n\n\t# Transform deplibs into only deplibs that can be linked in shared.\n\tname_save=$name\n\tlibname_save=$libname\n\trelease_save=$release\n\tversuffix_save=$versuffix\n\tmajor_save=$major\n\t# I'm not sure if I'm treating the release correctly.  I think\n\t# release should show up in the -l (ie -lgmp5) so we don't want to\n\t# add it in twice.  Is that correct?\n\trelease=\n\tversuffix=\n\tmajor=\n\tnewdeplibs=\n\tdroppeddeps=no\n\tcase $deplibs_check_method in\n\tpass_all)\n\t  # Don't check for shared/static.  Everything works.\n\t  # This might be a little naive.  We might want to check\n\t  # whether the library exists or not.  But this is on\n\t  # osf3 & osf4 and I'm not really sure... Just\n\t  # implementing what was already the behavior.\n\t  newdeplibs=$deplibs\n\t  ;;\n\ttest_compile)\n\t  # This code stresses the \"libraries are programs\" paradigm to its\n\t  # limits. Maybe even breaks it.  We compile a program, linking it\n\t  # against the deplibs as a proxy for the library.  Then we can check\n\t  # whether they linked in statically or dynamically with ldd.\n\t  $opt_dry_run || $RM conftest.c\n\t  cat > conftest.c <<EOF\n\t  int main() { return 0; }\nEOF\n\t  $opt_dry_run || $RM conftest\n\t  if $LTCC $LTCFLAGS -o conftest conftest.c $deplibs; then\n\t    ldd_output=`ldd conftest`\n\t    for i in $deplibs; do\n\t      case $i in\n\t      -l*)\n\t\tfunc_stripname -l '' \"$i\"\n\t\tname=$func_stripname_result\n\t\tif test yes = \"$allow_libtool_libs_with_static_runtimes\"; then\n\t\t  case \" $predeps $postdeps \" in\n\t\t  *\" $i \"*)\n\t\t    func_append newdeplibs \" $i\"\n\t\t    i=\n\t\t    ;;\n\t\t  esac\n\t\tfi\n\t\tif test -n \"$i\"; then\n\t\t  libname=`eval \"\\\\$ECHO \\\"$libname_spec\\\"\"`\n\t\t  deplib_matches=`eval \"\\\\$ECHO \\\"$library_names_spec\\\"\"`\n\t\t  set dummy $deplib_matches; shift\n\t\t  deplib_match=$1\n\t\t  if test `expr \"$ldd_output\" : \".*$deplib_match\"` -ne 0; then\n\t\t    func_append newdeplibs \" $i\"\n\t\t  else\n\t\t    droppeddeps=yes\n\t\t    echo\n\t\t    $ECHO \"*** Warning: dynamic linker does not accept needed library $i.\"\n\t\t    echo \"*** I have the capability to make that library automatically link in when\"\n\t\t    echo \"*** you link to this library.  But I can only do this if you have a\"\n\t\t    echo \"*** shared version of the library, which I believe you do not have\"\n\t\t    echo \"*** because a test_compile did reveal that the linker did not use it for\"\n\t\t    echo \"*** its dynamic dependency list that programs get resolved with at runtime.\"\n\t\t  fi\n\t\tfi\n\t\t;;\n\t      *)\n\t\tfunc_append newdeplibs \" $i\"\n\t\t;;\n\t      esac\n\t    done\n\t  else\n\t    # Error occurred in the first compile.  Let's try to salvage\n\t    # the situation: Compile a separate program for each library.\n\t    for i in $deplibs; do\n\t      case $i in\n\t      -l*)\n\t\tfunc_stripname -l '' \"$i\"\n\t\tname=$func_stripname_result\n\t\t$opt_dry_run || $RM conftest\n\t\tif $LTCC $LTCFLAGS -o conftest conftest.c $i; then\n\t\t  ldd_output=`ldd conftest`\n\t\t  if test yes = \"$allow_libtool_libs_with_static_runtimes\"; then\n\t\t    case \" $predeps $postdeps \" in\n\t\t    *\" $i \"*)\n\t\t      func_append newdeplibs \" $i\"\n\t\t      i=\n\t\t      ;;\n\t\t    esac\n\t\t  fi\n\t\t  if test -n \"$i\"; then\n\t\t    libname=`eval \"\\\\$ECHO \\\"$libname_spec\\\"\"`\n\t\t    deplib_matches=`eval \"\\\\$ECHO \\\"$library_names_spec\\\"\"`\n\t\t    set dummy $deplib_matches; shift\n\t\t    deplib_match=$1\n\t\t    if test `expr \"$ldd_output\" : \".*$deplib_match\"` -ne 0; then\n\t\t      func_append newdeplibs \" $i\"\n\t\t    else\n\t\t      droppeddeps=yes\n\t\t      echo\n\t\t      $ECHO \"*** Warning: dynamic linker does not accept needed library $i.\"\n\t\t      echo \"*** I have the capability to make that library automatically link in when\"\n\t\t      echo \"*** you link to this library.  But I can only do this if you have a\"\n\t\t      echo \"*** shared version of the library, which you do not appear to have\"\n\t\t      echo \"*** because a test_compile did reveal that the linker did not use this one\"\n\t\t      echo \"*** as a dynamic dependency that programs can get resolved with at runtime.\"\n\t\t    fi\n\t\t  fi\n\t\telse\n\t\t  droppeddeps=yes\n\t\t  echo\n\t\t  $ECHO \"*** Warning!  Library $i is needed by this library but I was not able to\"\n\t\t  echo \"*** make it link in!  You will probably need to install it or some\"\n\t\t  echo \"*** library that it depends on before this library will be fully\"\n\t\t  echo \"*** functional.  Installing it before continuing would be even better.\"\n\t\tfi\n\t\t;;\n\t      *)\n\t\tfunc_append newdeplibs \" $i\"\n\t\t;;\n\t      esac\n\t    done\n\t  fi\n\t  ;;\n\tfile_magic*)\n\t  set dummy $deplibs_check_method; shift\n\t  file_magic_regex=`expr \"$deplibs_check_method\" : \"$1 \\(.*\\)\"`\n\t  for a_deplib in $deplibs; do\n\t    case $a_deplib in\n\t    -l*)\n\t      func_stripname -l '' \"$a_deplib\"\n\t      name=$func_stripname_result\n\t      if test yes = \"$allow_libtool_libs_with_static_runtimes\"; then\n\t\tcase \" $predeps $postdeps \" in\n\t\t*\" $a_deplib \"*)\n\t\t  func_append newdeplibs \" $a_deplib\"\n\t\t  a_deplib=\n\t\t  ;;\n\t\tesac\n\t      fi\n\t      if test -n \"$a_deplib\"; then\n\t\tlibname=`eval \"\\\\$ECHO \\\"$libname_spec\\\"\"`\n\t\tif test -n \"$file_magic_glob\"; then\n\t\t  libnameglob=`func_echo_all \"$libname\" | $SED -e $file_magic_glob`\n\t\telse\n\t\t  libnameglob=$libname\n\t\tfi\n\t\ttest yes = \"$want_nocaseglob\" && nocaseglob=`shopt -p nocaseglob`\n\t\tfor i in $lib_search_path $sys_lib_search_path $shlib_search_path; do\n\t\t  if test yes = \"$want_nocaseglob\"; then\n\t\t    shopt -s nocaseglob\n\t\t    potential_libs=`ls $i/$libnameglob[.-]* 2>/dev/null`\n\t\t    $nocaseglob\n\t\t  else\n\t\t    potential_libs=`ls $i/$libnameglob[.-]* 2>/dev/null`\n\t\t  fi\n\t\t  for potent_lib in $potential_libs; do\n\t\t      # Follow soft links.\n\t\t      if ls -lLd \"$potent_lib\" 2>/dev/null |\n\t\t\t $GREP \" -> \" >/dev/null; then\n\t\t\tcontinue\n\t\t      fi\n\t\t      # The statement above tries to avoid entering an\n\t\t      # endless loop below, in case of cyclic links.\n\t\t      # We might still enter an endless loop, since a link\n\t\t      # loop can be closed while we follow links,\n\t\t      # but so what?\n\t\t      potlib=$potent_lib\n\t\t      while test -h \"$potlib\" 2>/dev/null; do\n\t\t\tpotliblink=`ls -ld $potlib | $SED 's/.* -> //'`\n\t\t\tcase $potliblink in\n\t\t\t[\\\\/]* | [A-Za-z]:[\\\\/]*) potlib=$potliblink;;\n\t\t\t*) potlib=`$ECHO \"$potlib\" | $SED 's|[^/]*$||'`\"$potliblink\";;\n\t\t\tesac\n\t\t      done\n\t\t      if eval $file_magic_cmd \\\"\\$potlib\\\" 2>/dev/null |\n\t\t\t $SED -e 10q |\n\t\t\t $EGREP \"$file_magic_regex\" > /dev/null; then\n\t\t\tfunc_append newdeplibs \" $a_deplib\"\n\t\t\ta_deplib=\n\t\t\tbreak 2\n\t\t      fi\n\t\t  done\n\t\tdone\n\t      fi\n\t      if test -n \"$a_deplib\"; then\n\t\tdroppeddeps=yes\n\t\techo\n\t\t$ECHO \"*** Warning: linker path does not have real file for library $a_deplib.\"\n\t\techo \"*** I have the capability to make that library automatically link in when\"\n\t\techo \"*** you link to this library.  But I can only do this if you have a\"\n\t\techo \"*** shared version of the library, which you do not appear to have\"\n\t\techo \"*** because I did check the linker path looking for a file starting\"\n\t\tif test -z \"$potlib\"; then\n\t\t  $ECHO \"*** with $libname but no candidates were found. (...for file magic test)\"\n\t\telse\n\t\t  $ECHO \"*** with $libname and none of the candidates passed a file format test\"\n\t\t  $ECHO \"*** using a file magic. Last file checked: $potlib\"\n\t\tfi\n\t      fi\n\t      ;;\n\t    *)\n\t      # Add a -L argument.\n\t      func_append newdeplibs \" $a_deplib\"\n\t      ;;\n\t    esac\n\t  done # Gone through all deplibs.\n\t  ;;\n\tmatch_pattern*)\n\t  set dummy $deplibs_check_method; shift\n\t  match_pattern_regex=`expr \"$deplibs_check_method\" : \"$1 \\(.*\\)\"`\n\t  for a_deplib in $deplibs; do\n\t    case $a_deplib in\n\t    -l*)\n\t      func_stripname -l '' \"$a_deplib\"\n\t      name=$func_stripname_result\n\t      if test yes = \"$allow_libtool_libs_with_static_runtimes\"; then\n\t\tcase \" $predeps $postdeps \" in\n\t\t*\" $a_deplib \"*)\n\t\t  func_append newdeplibs \" $a_deplib\"\n\t\t  a_deplib=\n\t\t  ;;\n\t\tesac\n\t      fi\n\t      if test -n \"$a_deplib\"; then\n\t\tlibname=`eval \"\\\\$ECHO \\\"$libname_spec\\\"\"`\n\t\tfor i in $lib_search_path $sys_lib_search_path $shlib_search_path; do\n\t\t  potential_libs=`ls $i/$libname[.-]* 2>/dev/null`\n\t\t  for potent_lib in $potential_libs; do\n\t\t    potlib=$potent_lib # see symlink-check above in file_magic test\n\t\t    if eval \"\\$ECHO \\\"$potent_lib\\\"\" 2>/dev/null | $SED 10q | \\\n\t\t       $EGREP \"$match_pattern_regex\" > /dev/null; then\n\t\t      func_append newdeplibs \" $a_deplib\"\n\t\t      a_deplib=\n\t\t      break 2\n\t\t    fi\n\t\t  done\n\t\tdone\n\t      fi\n\t      if test -n \"$a_deplib\"; then\n\t\tdroppeddeps=yes\n\t\techo\n\t\t$ECHO \"*** Warning: linker path does not have real file for library $a_deplib.\"\n\t\techo \"*** I have the capability to make that library automatically link in when\"\n\t\techo \"*** you link to this library.  But I can only do this if you have a\"\n\t\techo \"*** shared version of the library, which you do not appear to have\"\n\t\techo \"*** because I did check the linker path looking for a file starting\"\n\t\tif test -z \"$potlib\"; then\n\t\t  $ECHO \"*** with $libname but no candidates were found. (...for regex pattern test)\"\n\t\telse\n\t\t  $ECHO \"*** with $libname and none of the candidates passed a file format test\"\n\t\t  $ECHO \"*** using a regex pattern. Last file checked: $potlib\"\n\t\tfi\n\t      fi\n\t      ;;\n\t    *)\n\t      # Add a -L argument.\n\t      func_append newdeplibs \" $a_deplib\"\n\t      ;;\n\t    esac\n\t  done # Gone through all deplibs.\n\t  ;;\n\tnone | unknown | *)\n\t  newdeplibs=\n\t  tmp_deplibs=`$ECHO \" $deplibs\" | $SED 's/ -lc$//; s/ -[LR][^ ]*//g'`\n\t  if test yes = \"$allow_libtool_libs_with_static_runtimes\"; then\n\t    for i in $predeps $postdeps; do\n\t      # can't use Xsed below, because $i might contain '/'\n\t      tmp_deplibs=`$ECHO \" $tmp_deplibs\" | $SED \"s|$i||\"`\n\t    done\n\t  fi\n\t  case $tmp_deplibs in\n\t  *[!\\\t\\ ]*)\n\t    echo\n\t    if test none = \"$deplibs_check_method\"; then\n\t      echo \"*** Warning: inter-library dependencies are not supported in this platform.\"\n\t    else\n\t      echo \"*** Warning: inter-library dependencies are not known to be supported.\"\n\t    fi\n\t    echo \"*** All declared inter-library dependencies are being dropped.\"\n\t    droppeddeps=yes\n\t    ;;\n\t  esac\n\t  ;;\n\tesac\n\tversuffix=$versuffix_save\n\tmajor=$major_save\n\trelease=$release_save\n\tlibname=$libname_save\n\tname=$name_save\n\n\tcase $host in\n\t*-*-rhapsody* | *-*-darwin1.[012])\n\t  # On Rhapsody replace the C library with the System framework\n\t  newdeplibs=`$ECHO \" $newdeplibs\" | $SED 's/ -lc / System.ltframework /'`\n\t  ;;\n\tesac\n\n\tif test yes = \"$droppeddeps\"; then\n\t  if test yes = \"$module\"; then\n\t    echo\n\t    echo \"*** Warning: libtool could not satisfy all declared inter-library\"\n\t    $ECHO \"*** dependencies of module $libname.  Therefore, libtool will create\"\n\t    echo \"*** a static module, that should work as long as the dlopening\"\n\t    echo \"*** application is linked with the -dlopen flag.\"\n\t    if test -z \"$global_symbol_pipe\"; then\n\t      echo\n\t      echo \"*** However, this would only work if libtool was able to extract symbol\"\n\t      echo \"*** lists from a program, using 'nm' or equivalent, but libtool could\"\n\t      echo \"*** not find such a program.  So, this module is probably useless.\"\n\t      echo \"*** 'nm' from GNU binutils and a full rebuild may help.\"\n\t    fi\n\t    if test no = \"$build_old_libs\"; then\n\t      oldlibs=$output_objdir/$libname.$libext\n\t      build_libtool_libs=module\n\t      build_old_libs=yes\n\t    else\n\t      build_libtool_libs=no\n\t    fi\n\t  else\n\t    echo \"*** The inter-library dependencies that have been dropped here will be\"\n\t    echo \"*** automatically added whenever a program is linked with this library\"\n\t    echo \"*** or is declared to -dlopen it.\"\n\n\t    if test no = \"$allow_undefined\"; then\n\t      echo\n\t      echo \"*** Since this library must not contain undefined symbols,\"\n\t      echo \"*** because either the platform does not support them or\"\n\t      echo \"*** it was explicitly requested with -no-undefined,\"\n\t      echo \"*** libtool will only create a static version of it.\"\n\t      if test no = \"$build_old_libs\"; then\n\t\toldlibs=$output_objdir/$libname.$libext\n\t\tbuild_libtool_libs=module\n\t\tbuild_old_libs=yes\n\t      else\n\t\tbuild_libtool_libs=no\n\t      fi\n\t    fi\n\t  fi\n\tfi\n\t# Done checking deplibs!\n\tdeplibs=$newdeplibs\n      fi\n      # Time to change all our \"foo.ltframework\" stuff back to \"-framework foo\"\n      case $host in\n\t*-*-darwin*)\n\t  newdeplibs=`$ECHO \" $newdeplibs\" | $SED 's% \\([^ $]*\\).ltframework% -framework \\1%g'`\n\t  new_inherited_linker_flags=`$ECHO \" $new_inherited_linker_flags\" | $SED 's% \\([^ $]*\\).ltframework% -framework \\1%g'`\n\t  deplibs=`$ECHO \" $deplibs\" | $SED 's% \\([^ $]*\\).ltframework% -framework \\1%g'`\n\t  ;;\n      esac\n\n      # move library search paths that coincide with paths to not yet\n      # installed libraries to the beginning of the library search list\n      new_libs=\n      for path in $notinst_path; do\n\tcase \" $new_libs \" in\n\t*\" -L$path/$objdir \"*) ;;\n\t*)\n\t  case \" $deplibs \" in\n\t  *\" -L$path/$objdir \"*)\n\t    func_append new_libs \" -L$path/$objdir\" ;;\n\t  esac\n\t  ;;\n\tesac\n      done\n      for deplib in $deplibs; do\n\tcase $deplib in\n\t-L*)\n\t  case \" $new_libs \" in\n\t  *\" $deplib \"*) ;;\n\t  *) func_append new_libs \" $deplib\" ;;\n\t  esac\n\t  ;;\n\t*) func_append new_libs \" $deplib\" ;;\n\tesac\n      done\n      deplibs=$new_libs\n\n      # All the library-specific variables (install_libdir is set above).\n      library_names=\n      old_library=\n      dlname=\n\n      # Test again, we may have decided not to build it any more\n      if test yes = \"$build_libtool_libs\"; then\n\t# Remove $wl instances when linking with ld.\n\t# FIXME: should test the right _cmds variable.\n\tcase $archive_cmds in\n\t  *\\$LD\\ *) wl= ;;\n        esac\n\tif test yes = \"$hardcode_into_libs\"; then\n\t  # Hardcode the library paths\n\t  hardcode_libdirs=\n\t  dep_rpath=\n\t  rpath=$finalize_rpath\n\t  test relink = \"$opt_mode\" || rpath=$compile_rpath$rpath\n\t  for libdir in $rpath; do\n\t    if test -n \"$hardcode_libdir_flag_spec\"; then\n\t      if test -n \"$hardcode_libdir_separator\"; then\n\t\tfunc_replace_sysroot \"$libdir\"\n\t\tlibdir=$func_replace_sysroot_result\n\t\tif test -z \"$hardcode_libdirs\"; then\n\t\t  hardcode_libdirs=$libdir\n\t\telse\n\t\t  # Just accumulate the unique libdirs.\n\t\t  case $hardcode_libdir_separator$hardcode_libdirs$hardcode_libdir_separator in\n\t\t  *\"$hardcode_libdir_separator$libdir$hardcode_libdir_separator\"*)\n\t\t    ;;\n\t\t  *)\n\t\t    func_append hardcode_libdirs \"$hardcode_libdir_separator$libdir\"\n\t\t    ;;\n\t\t  esac\n\t\tfi\n\t      else\n\t\teval flag=\\\"$hardcode_libdir_flag_spec\\\"\n\t\tfunc_append dep_rpath \" $flag\"\n\t      fi\n\t    elif test -n \"$runpath_var\"; then\n\t      case \"$perm_rpath \" in\n\t      *\" $libdir \"*) ;;\n\t      *) func_append perm_rpath \" $libdir\" ;;\n\t      esac\n\t    fi\n\t  done\n\t  # Substitute the hardcoded libdirs into the rpath.\n\t  if test -n \"$hardcode_libdir_separator\" &&\n\t     test -n \"$hardcode_libdirs\"; then\n\t    libdir=$hardcode_libdirs\n\t    eval \"dep_rpath=\\\"$hardcode_libdir_flag_spec\\\"\"\n\t  fi\n\t  if test -n \"$runpath_var\" && test -n \"$perm_rpath\"; then\n\t    # We should set the runpath_var.\n\t    rpath=\n\t    for dir in $perm_rpath; do\n\t      func_append rpath \"$dir:\"\n\t    done\n\t    eval \"$runpath_var='$rpath\\$$runpath_var'; export $runpath_var\"\n\t  fi\n\t  test -n \"$dep_rpath\" && deplibs=\"$dep_rpath $deplibs\"\n\tfi\n\n\tshlibpath=$finalize_shlibpath\n\ttest relink = \"$opt_mode\" || shlibpath=$compile_shlibpath$shlibpath\n\tif test -n \"$shlibpath\"; then\n\t  eval \"$shlibpath_var='$shlibpath\\$$shlibpath_var'; export $shlibpath_var\"\n\tfi\n\n\t# Get the real and link names of the library.\n\teval shared_ext=\\\"$shrext_cmds\\\"\n\teval library_names=\\\"$library_names_spec\\\"\n\tset dummy $library_names\n\tshift\n\trealname=$1\n\tshift\n\n\tif test -n \"$soname_spec\"; then\n\t  eval soname=\\\"$soname_spec\\\"\n\telse\n\t  soname=$realname\n\tfi\n\tif test -z \"$dlname\"; then\n\t  dlname=$soname\n\tfi\n\n\tlib=$output_objdir/$realname\n\tlinknames=\n\tfor link\n\tdo\n\t  func_append linknames \" $link\"\n\tdone\n\n\t# Use standard objects if they are pic\n\ttest -z \"$pic_flag\" && libobjs=`$ECHO \"$libobjs\" | $SP2NL | $SED \"$lo2o\" | $NL2SP`\n\ttest \"X$libobjs\" = \"X \" && libobjs=\n\n\tdelfiles=\n\tif test -n \"$export_symbols\" && test -n \"$include_expsyms\"; then\n\t  $opt_dry_run || cp \"$export_symbols\" \"$output_objdir/$libname.uexp\"\n\t  export_symbols=$output_objdir/$libname.uexp\n\t  func_append delfiles \" $export_symbols\"\n\tfi\n\n\torig_export_symbols=\n\tcase $host_os in\n\tcygwin* | mingw* | cegcc*)\n\t  if test -n \"$export_symbols\" && test -z \"$export_symbols_regex\"; then\n\t    # exporting using user supplied symfile\n\t    func_dll_def_p \"$export_symbols\" || {\n\t      # and it's NOT already a .def file. Must figure out\n\t      # which of the given symbols are data symbols and tag\n\t      # them as such. So, trigger use of export_symbols_cmds.\n\t      # export_symbols gets reassigned inside the \"prepare\n\t      # the list of exported symbols\" if statement, so the\n\t      # include_expsyms logic still works.\n\t      orig_export_symbols=$export_symbols\n\t      export_symbols=\n\t      always_export_symbols=yes\n\t    }\n\t  fi\n\t  ;;\n\tesac\n\n\t# Prepare the list of exported symbols\n\tif test -z \"$export_symbols\"; then\n\t  if test yes = \"$always_export_symbols\" || test -n \"$export_symbols_regex\"; then\n\t    func_verbose \"generating symbol list for '$libname.la'\"\n\t    export_symbols=$output_objdir/$libname.exp\n\t    $opt_dry_run || $RM $export_symbols\n\t    cmds=$export_symbols_cmds\n\t    save_ifs=$IFS; IFS='~'\n\t    for cmd1 in $cmds; do\n\t      IFS=$save_ifs\n\t      # Take the normal branch if the nm_file_list_spec branch\n\t      # doesn't work or if tool conversion is not needed.\n\t      case $nm_file_list_spec~$to_tool_file_cmd in\n\t\t*~func_convert_file_noop | *~func_convert_file_msys_to_w32 | ~*)\n\t\t  try_normal_branch=yes\n\t\t  eval cmd=\\\"$cmd1\\\"\n\t\t  func_len \" $cmd\"\n\t\t  len=$func_len_result\n\t\t  ;;\n\t\t*)\n\t\t  try_normal_branch=no\n\t\t  ;;\n\t      esac\n\t      if test yes = \"$try_normal_branch\" \\\n\t\t && { test \"$len\" -lt \"$max_cmd_len\" \\\n\t\t      || test \"$max_cmd_len\" -le -1; }\n\t      then\n\t\tfunc_show_eval \"$cmd\" 'exit $?'\n\t\tskipped_export=false\n\t      elif test -n \"$nm_file_list_spec\"; then\n\t\tfunc_basename \"$output\"\n\t\toutput_la=$func_basename_result\n\t\tsave_libobjs=$libobjs\n\t\tsave_output=$output\n\t\toutput=$output_objdir/$output_la.nm\n\t\tfunc_to_tool_file \"$output\"\n\t\tlibobjs=$nm_file_list_spec$func_to_tool_file_result\n\t\tfunc_append delfiles \" $output\"\n\t\tfunc_verbose \"creating $NM input file list: $output\"\n\t\tfor obj in $save_libobjs; do\n\t\t  func_to_tool_file \"$obj\"\n\t\t  $ECHO \"$func_to_tool_file_result\"\n\t\tdone > \"$output\"\n\t\teval cmd=\\\"$cmd1\\\"\n\t\tfunc_show_eval \"$cmd\" 'exit $?'\n\t\toutput=$save_output\n\t\tlibobjs=$save_libobjs\n\t\tskipped_export=false\n\t      else\n\t\t# The command line is too long to execute in one step.\n\t\tfunc_verbose \"using reloadable object file for export list...\"\n\t\tskipped_export=:\n\t\t# Break out early, otherwise skipped_export may be\n\t\t# set to false by a later but shorter cmd.\n\t\tbreak\n\t      fi\n\t    done\n\t    IFS=$save_ifs\n\t    if test -n \"$export_symbols_regex\" && test : != \"$skipped_export\"; then\n\t      func_show_eval '$EGREP -e \"$export_symbols_regex\" \"$export_symbols\" > \"${export_symbols}T\"'\n\t      func_show_eval '$MV \"${export_symbols}T\" \"$export_symbols\"'\n\t    fi\n\t  fi\n\tfi\n\n\tif test -n \"$export_symbols\" && test -n \"$include_expsyms\"; then\n\t  tmp_export_symbols=$export_symbols\n\t  test -n \"$orig_export_symbols\" && tmp_export_symbols=$orig_export_symbols\n\t  $opt_dry_run || eval '$ECHO \"$include_expsyms\" | $SP2NL >> \"$tmp_export_symbols\"'\n\tfi\n\n\tif test : != \"$skipped_export\" && test -n \"$orig_export_symbols\"; then\n\t  # The given exports_symbols file has to be filtered, so filter it.\n\t  func_verbose \"filter symbol list for '$libname.la' to tag DATA exports\"\n\t  # FIXME: $output_objdir/$libname.filter potentially contains lots of\n\t  # 's' commands, which not all seds can handle. GNU sed should be fine\n\t  # though. Also, the filter scales superlinearly with the number of\n\t  # global variables. join(1) would be nice here, but unfortunately\n\t  # isn't a blessed tool.\n\t  $opt_dry_run || $SED -e '/[ ,]DATA/!d;s,\\(.*\\)\\([ \\,].*\\),s|^\\1$|\\1\\2|,' < $export_symbols > $output_objdir/$libname.filter\n\t  func_append delfiles \" $export_symbols $output_objdir/$libname.filter\"\n\t  export_symbols=$output_objdir/$libname.def\n\t  $opt_dry_run || $SED -f $output_objdir/$libname.filter < $orig_export_symbols > $export_symbols\n\tfi\n\n\ttmp_deplibs=\n\tfor test_deplib in $deplibs; do\n\t  case \" $convenience \" in\n\t  *\" $test_deplib \"*) ;;\n\t  *)\n\t    func_append tmp_deplibs \" $test_deplib\"\n\t    ;;\n\t  esac\n\tdone\n\tdeplibs=$tmp_deplibs\n\n\tif test -n \"$convenience\"; then\n\t  if test -n \"$whole_archive_flag_spec\" &&\n\t    test yes = \"$compiler_needs_object\" &&\n\t    test -z \"$libobjs\"; then\n\t    # extract the archives, so we have objects to list.\n\t    # TODO: could optimize this to just extract one archive.\n\t    whole_archive_flag_spec=\n\t  fi\n\t  if test -n \"$whole_archive_flag_spec\"; then\n\t    save_libobjs=$libobjs\n\t    eval libobjs=\\\"\\$libobjs $whole_archive_flag_spec\\\"\n\t    test \"X$libobjs\" = \"X \" && libobjs=\n\t  else\n\t    gentop=$output_objdir/${outputname}x\n\t    func_append generated \" $gentop\"\n\n\t    func_extract_archives $gentop $convenience\n\t    func_append libobjs \" $func_extract_archives_result\"\n\t    test \"X$libobjs\" = \"X \" && libobjs=\n\t  fi\n\tfi\n\n\tif test yes = \"$thread_safe\" && test -n \"$thread_safe_flag_spec\"; then\n\t  eval flag=\\\"$thread_safe_flag_spec\\\"\n\t  func_append linker_flags \" $flag\"\n\tfi\n\n\t# Make a backup of the uninstalled library when relinking\n\tif test relink = \"$opt_mode\"; then\n\t  $opt_dry_run || eval '(cd $output_objdir && $RM ${realname}U && $MV $realname ${realname}U)' || exit $?\n\tfi\n\n\t# Do each of the archive commands.\n\tif test yes = \"$module\" && test -n \"$module_cmds\"; then\n\t  if test -n \"$export_symbols\" && test -n \"$module_expsym_cmds\"; then\n\t    eval test_cmds=\\\"$module_expsym_cmds\\\"\n\t    cmds=$module_expsym_cmds\n\t  else\n\t    eval test_cmds=\\\"$module_cmds\\\"\n\t    cmds=$module_cmds\n\t  fi\n\telse\n\t  if test -n \"$export_symbols\" && test -n \"$archive_expsym_cmds\"; then\n\t    eval test_cmds=\\\"$archive_expsym_cmds\\\"\n\t    cmds=$archive_expsym_cmds\n\t  else\n\t    eval test_cmds=\\\"$archive_cmds\\\"\n\t    cmds=$archive_cmds\n\t  fi\n\tfi\n\n\tif test : != \"$skipped_export\" &&\n\t   func_len \" $test_cmds\" &&\n\t   len=$func_len_result &&\n\t   test \"$len\" -lt \"$max_cmd_len\" || test \"$max_cmd_len\" -le -1; then\n\t  :\n\telse\n\t  # The command line is too long to link in one step, link piecewise\n\t  # or, if using GNU ld and skipped_export is not :, use a linker\n\t  # script.\n\n\t  # Save the value of $output and $libobjs because we want to\n\t  # use them later.  If we have whole_archive_flag_spec, we\n\t  # want to use save_libobjs as it was before\n\t  # whole_archive_flag_spec was expanded, because we can't\n\t  # assume the linker understands whole_archive_flag_spec.\n\t  # This may have to be revisited, in case too many\n\t  # convenience libraries get linked in and end up exceeding\n\t  # the spec.\n\t  if test -z \"$convenience\" || test -z \"$whole_archive_flag_spec\"; then\n\t    save_libobjs=$libobjs\n\t  fi\n\t  save_output=$output\n\t  func_basename \"$output\"\n\t  output_la=$func_basename_result\n\n\t  # Clear the reloadable object creation command queue and\n\t  # initialize k to one.\n\t  test_cmds=\n\t  concat_cmds=\n\t  objlist=\n\t  last_robj=\n\t  k=1\n\n\t  if test -n \"$save_libobjs\" && test : != \"$skipped_export\" && test yes = \"$with_gnu_ld\"; then\n\t    output=$output_objdir/$output_la.lnkscript\n\t    func_verbose \"creating GNU ld script: $output\"\n\t    echo 'INPUT (' > $output\n\t    for obj in $save_libobjs\n\t    do\n\t      func_to_tool_file \"$obj\"\n\t      $ECHO \"$func_to_tool_file_result\" >> $output\n\t    done\n\t    echo ')' >> $output\n\t    func_append delfiles \" $output\"\n\t    func_to_tool_file \"$output\"\n\t    output=$func_to_tool_file_result\n\t  elif test -n \"$save_libobjs\" && test : != \"$skipped_export\" && test -n \"$file_list_spec\"; then\n\t    output=$output_objdir/$output_la.lnk\n\t    func_verbose \"creating linker input file list: $output\"\n\t    : > $output\n\t    set x $save_libobjs\n\t    shift\n\t    firstobj=\n\t    if test yes = \"$compiler_needs_object\"; then\n\t      firstobj=\"$1 \"\n\t      shift\n\t    fi\n\t    for obj\n\t    do\n\t      func_to_tool_file \"$obj\"\n\t      $ECHO \"$func_to_tool_file_result\" >> $output\n\t    done\n\t    func_append delfiles \" $output\"\n\t    func_to_tool_file \"$output\"\n\t    output=$firstobj\\\"$file_list_spec$func_to_tool_file_result\\\"\n\t  else\n\t    if test -n \"$save_libobjs\"; then\n\t      func_verbose \"creating reloadable object files...\"\n\t      output=$output_objdir/$output_la-$k.$objext\n\t      eval test_cmds=\\\"$reload_cmds\\\"\n\t      func_len \" $test_cmds\"\n\t      len0=$func_len_result\n\t      len=$len0\n\n\t      # Loop over the list of objects to be linked.\n\t      for obj in $save_libobjs\n\t      do\n\t\tfunc_len \" $obj\"\n\t\tfunc_arith $len + $func_len_result\n\t\tlen=$func_arith_result\n\t\tif test -z \"$objlist\" ||\n\t\t   test \"$len\" -lt \"$max_cmd_len\"; then\n\t\t  func_append objlist \" $obj\"\n\t\telse\n\t\t  # The command $test_cmds is almost too long, add a\n\t\t  # command to the queue.\n\t\t  if test 1 -eq \"$k\"; then\n\t\t    # The first file doesn't have a previous command to add.\n\t\t    reload_objs=$objlist\n\t\t    eval concat_cmds=\\\"$reload_cmds\\\"\n\t\t  else\n\t\t    # All subsequent reloadable object files will link in\n\t\t    # the last one created.\n\t\t    reload_objs=\"$objlist $last_robj\"\n\t\t    eval concat_cmds=\\\"\\$concat_cmds~$reload_cmds~\\$RM $last_robj\\\"\n\t\t  fi\n\t\t  last_robj=$output_objdir/$output_la-$k.$objext\n\t\t  func_arith $k + 1\n\t\t  k=$func_arith_result\n\t\t  output=$output_objdir/$output_la-$k.$objext\n\t\t  objlist=\" $obj\"\n\t\t  func_len \" $last_robj\"\n\t\t  func_arith $len0 + $func_len_result\n\t\t  len=$func_arith_result\n\t\tfi\n\t      done\n\t      # Handle the remaining objects by creating one last\n\t      # reloadable object file.  All subsequent reloadable object\n\t      # files will link in the last one created.\n\t      test -z \"$concat_cmds\" || concat_cmds=$concat_cmds~\n\t      reload_objs=\"$objlist $last_robj\"\n\t      eval concat_cmds=\\\"\\$concat_cmds$reload_cmds\\\"\n\t      if test -n \"$last_robj\"; then\n\t        eval concat_cmds=\\\"\\$concat_cmds~\\$RM $last_robj\\\"\n\t      fi\n\t      func_append delfiles \" $output\"\n\n\t    else\n\t      output=\n\t    fi\n\n\t    ${skipped_export-false} && {\n\t      func_verbose \"generating symbol list for '$libname.la'\"\n\t      export_symbols=$output_objdir/$libname.exp\n\t      $opt_dry_run || $RM $export_symbols\n\t      libobjs=$output\n\t      # Append the command to create the export file.\n\t      test -z \"$concat_cmds\" || concat_cmds=$concat_cmds~\n\t      eval concat_cmds=\\\"\\$concat_cmds$export_symbols_cmds\\\"\n\t      if test -n \"$last_robj\"; then\n\t\teval concat_cmds=\\\"\\$concat_cmds~\\$RM $last_robj\\\"\n\t      fi\n\t    }\n\n\t    test -n \"$save_libobjs\" &&\n\t      func_verbose \"creating a temporary reloadable object file: $output\"\n\n\t    # Loop through the commands generated above and execute them.\n\t    save_ifs=$IFS; IFS='~'\n\t    for cmd in $concat_cmds; do\n\t      IFS=$save_ifs\n\t      $opt_quiet || {\n\t\t  func_quote_for_expand \"$cmd\"\n\t\t  eval \"func_echo $func_quote_for_expand_result\"\n\t      }\n\t      $opt_dry_run || eval \"$cmd\" || {\n\t\tlt_exit=$?\n\n\t\t# Restore the uninstalled library and exit\n\t\tif test relink = \"$opt_mode\"; then\n\t\t  ( cd \"$output_objdir\" && \\\n\t\t    $RM \"${realname}T\" && \\\n\t\t    $MV \"${realname}U\" \"$realname\" )\n\t\tfi\n\n\t\texit $lt_exit\n\t      }\n\t    done\n\t    IFS=$save_ifs\n\n\t    if test -n \"$export_symbols_regex\" && ${skipped_export-false}; then\n\t      func_show_eval '$EGREP -e \"$export_symbols_regex\" \"$export_symbols\" > \"${export_symbols}T\"'\n\t      func_show_eval '$MV \"${export_symbols}T\" \"$export_symbols\"'\n\t    fi\n\t  fi\n\n          ${skipped_export-false} && {\n\t    if test -n \"$export_symbols\" && test -n \"$include_expsyms\"; then\n\t      tmp_export_symbols=$export_symbols\n\t      test -n \"$orig_export_symbols\" && tmp_export_symbols=$orig_export_symbols\n\t      $opt_dry_run || eval '$ECHO \"$include_expsyms\" | $SP2NL >> \"$tmp_export_symbols\"'\n\t    fi\n\n\t    if test -n \"$orig_export_symbols\"; then\n\t      # The given exports_symbols file has to be filtered, so filter it.\n\t      func_verbose \"filter symbol list for '$libname.la' to tag DATA exports\"\n\t      # FIXME: $output_objdir/$libname.filter potentially contains lots of\n\t      # 's' commands, which not all seds can handle. GNU sed should be fine\n\t      # though. Also, the filter scales superlinearly with the number of\n\t      # global variables. join(1) would be nice here, but unfortunately\n\t      # isn't a blessed tool.\n\t      $opt_dry_run || $SED -e '/[ ,]DATA/!d;s,\\(.*\\)\\([ \\,].*\\),s|^\\1$|\\1\\2|,' < $export_symbols > $output_objdir/$libname.filter\n\t      func_append delfiles \" $export_symbols $output_objdir/$libname.filter\"\n\t      export_symbols=$output_objdir/$libname.def\n\t      $opt_dry_run || $SED -f $output_objdir/$libname.filter < $orig_export_symbols > $export_symbols\n\t    fi\n\t  }\n\n\t  libobjs=$output\n\t  # Restore the value of output.\n\t  output=$save_output\n\n\t  if test -n \"$convenience\" && test -n \"$whole_archive_flag_spec\"; then\n\t    eval libobjs=\\\"\\$libobjs $whole_archive_flag_spec\\\"\n\t    test \"X$libobjs\" = \"X \" && libobjs=\n\t  fi\n\t  # Expand the library linking commands again to reset the\n\t  # value of $libobjs for piecewise linking.\n\n\t  # Do each of the archive commands.\n\t  if test yes = \"$module\" && test -n \"$module_cmds\"; then\n\t    if test -n \"$export_symbols\" && test -n \"$module_expsym_cmds\"; then\n\t      cmds=$module_expsym_cmds\n\t    else\n\t      cmds=$module_cmds\n\t    fi\n\t  else\n\t    if test -n \"$export_symbols\" && test -n \"$archive_expsym_cmds\"; then\n\t      cmds=$archive_expsym_cmds\n\t    else\n\t      cmds=$archive_cmds\n\t    fi\n\t  fi\n\tfi\n\n\tif test -n \"$delfiles\"; then\n\t  # Append the command to remove temporary files to $cmds.\n\t  eval cmds=\\\"\\$cmds~\\$RM $delfiles\\\"\n\tfi\n\n\t# Add any objects from preloaded convenience libraries\n\tif test -n \"$dlprefiles\"; then\n\t  gentop=$output_objdir/${outputname}x\n\t  func_append generated \" $gentop\"\n\n\t  func_extract_archives $gentop $dlprefiles\n\t  func_append libobjs \" $func_extract_archives_result\"\n\t  test \"X$libobjs\" = \"X \" && libobjs=\n\tfi\n\n\tsave_ifs=$IFS; IFS='~'\n\tfor cmd in $cmds; do\n\t  IFS=$sp$nl\n\t  eval cmd=\\\"$cmd\\\"\n\t  IFS=$save_ifs\n\t  $opt_quiet || {\n\t    func_quote_for_expand \"$cmd\"\n\t    eval \"func_echo $func_quote_for_expand_result\"\n\t  }\n\t  $opt_dry_run || eval \"$cmd\" || {\n\t    lt_exit=$?\n\n\t    # Restore the uninstalled library and exit\n\t    if test relink = \"$opt_mode\"; then\n\t      ( cd \"$output_objdir\" && \\\n\t        $RM \"${realname}T\" && \\\n\t\t$MV \"${realname}U\" \"$realname\" )\n\t    fi\n\n\t    exit $lt_exit\n\t  }\n\tdone\n\tIFS=$save_ifs\n\n\t# Restore the uninstalled library and exit\n\tif test relink = \"$opt_mode\"; then\n\t  $opt_dry_run || eval '(cd $output_objdir && $RM ${realname}T && $MV $realname ${realname}T && $MV ${realname}U $realname)' || exit $?\n\n\t  if test -n \"$convenience\"; then\n\t    if test -z \"$whole_archive_flag_spec\"; then\n\t      func_show_eval '${RM}r \"$gentop\"'\n\t    fi\n\t  fi\n\n\t  exit $EXIT_SUCCESS\n\tfi\n\n\t# Create links to the real library.\n\tfor linkname in $linknames; do\n\t  if test \"$realname\" != \"$linkname\"; then\n\t    func_show_eval '(cd \"$output_objdir\" && $RM \"$linkname\" && $LN_S \"$realname\" \"$linkname\")' 'exit $?'\n\t  fi\n\tdone\n\n\t# If -module or -export-dynamic was specified, set the dlname.\n\tif test yes = \"$module\" || test yes = \"$export_dynamic\"; then\n\t  # On all known operating systems, these are identical.\n\t  dlname=$soname\n\tfi\n      fi\n      ;;\n\n    obj)\n      if test -n \"$dlfiles$dlprefiles\" || test no != \"$dlself\"; then\n\tfunc_warning \"'-dlopen' is ignored for objects\"\n      fi\n\n      case \" $deplibs\" in\n      *\\ -l* | *\\ -L*)\n\tfunc_warning \"'-l' and '-L' are ignored for objects\" ;;\n      esac\n\n      test -n \"$rpath\" && \\\n\tfunc_warning \"'-rpath' is ignored for objects\"\n\n      test -n \"$xrpath\" && \\\n\tfunc_warning \"'-R' is ignored for objects\"\n\n      test -n \"$vinfo\" && \\\n\tfunc_warning \"'-version-info' is ignored for objects\"\n\n      test -n \"$release\" && \\\n\tfunc_warning \"'-release' is ignored for objects\"\n\n      case $output in\n      *.lo)\n\ttest -n \"$objs$old_deplibs\" && \\\n\t  func_fatal_error \"cannot build library object '$output' from non-libtool objects\"\n\n\tlibobj=$output\n\tfunc_lo2o \"$libobj\"\n\tobj=$func_lo2o_result\n\t;;\n      *)\n\tlibobj=\n\tobj=$output\n\t;;\n      esac\n\n      # Delete the old objects.\n      $opt_dry_run || $RM $obj $libobj\n\n      # Objects from convenience libraries.  This assumes\n      # single-version convenience libraries.  Whenever we create\n      # different ones for PIC/non-PIC, this we'll have to duplicate\n      # the extraction.\n      reload_conv_objs=\n      gentop=\n      # if reload_cmds runs $LD directly, get rid of -Wl from\n      # whole_archive_flag_spec and hope we can get by with turning comma\n      # into space.\n      case $reload_cmds in\n        *\\$LD[\\ \\$]*) wl= ;;\n      esac\n      if test -n \"$convenience\"; then\n\tif test -n \"$whole_archive_flag_spec\"; then\n\t  eval tmp_whole_archive_flags=\\\"$whole_archive_flag_spec\\\"\n\t  test -n \"$wl\" || tmp_whole_archive_flags=`$ECHO \"$tmp_whole_archive_flags\" | $SED 's|,| |g'`\n\t  reload_conv_objs=$reload_objs\\ $tmp_whole_archive_flags\n\telse\n\t  gentop=$output_objdir/${obj}x\n\t  func_append generated \" $gentop\"\n\n\t  func_extract_archives $gentop $convenience\n\t  reload_conv_objs=\"$reload_objs $func_extract_archives_result\"\n\tfi\n      fi\n\n      # If we're not building shared, we need to use non_pic_objs\n      test yes = \"$build_libtool_libs\" || libobjs=$non_pic_objects\n\n      # Create the old-style object.\n      reload_objs=$objs$old_deplibs' '`$ECHO \"$libobjs\" | $SP2NL | $SED \"/\\.$libext$/d; /\\.lib$/d; $lo2o\" | $NL2SP`' '$reload_conv_objs\n\n      output=$obj\n      func_execute_cmds \"$reload_cmds\" 'exit $?'\n\n      # Exit if we aren't doing a library object file.\n      if test -z \"$libobj\"; then\n\tif test -n \"$gentop\"; then\n\t  func_show_eval '${RM}r \"$gentop\"'\n\tfi\n\n\texit $EXIT_SUCCESS\n      fi\n\n      test yes = \"$build_libtool_libs\" || {\n\tif test -n \"$gentop\"; then\n\t  func_show_eval '${RM}r \"$gentop\"'\n\tfi\n\n\t# Create an invalid libtool object if no PIC, so that we don't\n\t# accidentally link it into a program.\n\t# $show \"echo timestamp > $libobj\"\n\t# $opt_dry_run || eval \"echo timestamp > $libobj\" || exit $?\n\texit $EXIT_SUCCESS\n      }\n\n      if test -n \"$pic_flag\" || test default != \"$pic_mode\"; then\n\t# Only do commands if we really have different PIC objects.\n\treload_objs=\"$libobjs $reload_conv_objs\"\n\toutput=$libobj\n\tfunc_execute_cmds \"$reload_cmds\" 'exit $?'\n      fi\n\n      if test -n \"$gentop\"; then\n\tfunc_show_eval '${RM}r \"$gentop\"'\n      fi\n\n      exit $EXIT_SUCCESS\n      ;;\n\n    prog)\n      case $host in\n\t*cygwin*) func_stripname '' '.exe' \"$output\"\n\t          output=$func_stripname_result.exe;;\n      esac\n      test -n \"$vinfo\" && \\\n\tfunc_warning \"'-version-info' is ignored for programs\"\n\n      test -n \"$release\" && \\\n\tfunc_warning \"'-release' is ignored for programs\"\n\n      $preload \\\n\t&& test unknown,unknown,unknown = \"$dlopen_support,$dlopen_self,$dlopen_self_static\" \\\n\t&& func_warning \"'LT_INIT([dlopen])' not used. Assuming no dlopen support.\"\n\n      case $host in\n      *-*-rhapsody* | *-*-darwin1.[012])\n\t# On Rhapsody replace the C library is the System framework\n\tcompile_deplibs=`$ECHO \" $compile_deplibs\" | $SED 's/ -lc / System.ltframework /'`\n\tfinalize_deplibs=`$ECHO \" $finalize_deplibs\" | $SED 's/ -lc / System.ltframework /'`\n\t;;\n      esac\n\n      case $host in\n      *-*-darwin*)\n\t# Don't allow lazy linking, it breaks C++ global constructors\n\t# But is supposedly fixed on 10.4 or later (yay!).\n\tif test CXX = \"$tagname\"; then\n\t  case ${MACOSX_DEPLOYMENT_TARGET-10.0} in\n\t    10.[0123])\n\t      func_append compile_command \" $wl-bind_at_load\"\n\t      func_append finalize_command \" $wl-bind_at_load\"\n\t    ;;\n\t  esac\n\tfi\n\t# Time to change all our \"foo.ltframework\" stuff back to \"-framework foo\"\n\tcompile_deplibs=`$ECHO \" $compile_deplibs\" | $SED 's% \\([^ $]*\\).ltframework% -framework \\1%g'`\n\tfinalize_deplibs=`$ECHO \" $finalize_deplibs\" | $SED 's% \\([^ $]*\\).ltframework% -framework \\1%g'`\n\t;;\n      esac\n\n\n      # move library search paths that coincide with paths to not yet\n      # installed libraries to the beginning of the library search list\n      new_libs=\n      for path in $notinst_path; do\n\tcase \" $new_libs \" in\n\t*\" -L$path/$objdir \"*) ;;\n\t*)\n\t  case \" $compile_deplibs \" in\n\t  *\" -L$path/$objdir \"*)\n\t    func_append new_libs \" -L$path/$objdir\" ;;\n\t  esac\n\t  ;;\n\tesac\n      done\n      for deplib in $compile_deplibs; do\n\tcase $deplib in\n\t-L*)\n\t  case \" $new_libs \" in\n\t  *\" $deplib \"*) ;;\n\t  *) func_append new_libs \" $deplib\" ;;\n\t  esac\n\t  ;;\n\t*) func_append new_libs \" $deplib\" ;;\n\tesac\n      done\n      compile_deplibs=$new_libs\n\n\n      func_append compile_command \" $compile_deplibs\"\n      func_append finalize_command \" $finalize_deplibs\"\n\n      if test -n \"$rpath$xrpath\"; then\n\t# If the user specified any rpath flags, then add them.\n\tfor libdir in $rpath $xrpath; do\n\t  # This is the magic to use -rpath.\n\t  case \"$finalize_rpath \" in\n\t  *\" $libdir \"*) ;;\n\t  *) func_append finalize_rpath \" $libdir\" ;;\n\t  esac\n\tdone\n      fi\n\n      # Now hardcode the library paths\n      rpath=\n      hardcode_libdirs=\n      for libdir in $compile_rpath $finalize_rpath; do\n\tif test -n \"$hardcode_libdir_flag_spec\"; then\n\t  if test -n \"$hardcode_libdir_separator\"; then\n\t    if test -z \"$hardcode_libdirs\"; then\n\t      hardcode_libdirs=$libdir\n\t    else\n\t      # Just accumulate the unique libdirs.\n\t      case $hardcode_libdir_separator$hardcode_libdirs$hardcode_libdir_separator in\n\t      *\"$hardcode_libdir_separator$libdir$hardcode_libdir_separator\"*)\n\t\t;;\n\t      *)\n\t\tfunc_append hardcode_libdirs \"$hardcode_libdir_separator$libdir\"\n\t\t;;\n\t      esac\n\t    fi\n\t  else\n\t    eval flag=\\\"$hardcode_libdir_flag_spec\\\"\n\t    func_append rpath \" $flag\"\n\t  fi\n\telif test -n \"$runpath_var\"; then\n\t  case \"$perm_rpath \" in\n\t  *\" $libdir \"*) ;;\n\t  *) func_append perm_rpath \" $libdir\" ;;\n\t  esac\n\tfi\n\tcase $host in\n\t*-*-cygwin* | *-*-mingw* | *-*-pw32* | *-*-os2* | *-cegcc*)\n\t  testbindir=`$ECHO \"$libdir\" | $SED -e 's*/lib$*/bin*'`\n\t  case :$dllsearchpath: in\n\t  *\":$libdir:\"*) ;;\n\t  ::) dllsearchpath=$libdir;;\n\t  *) func_append dllsearchpath \":$libdir\";;\n\t  esac\n\t  case :$dllsearchpath: in\n\t  *\":$testbindir:\"*) ;;\n\t  ::) dllsearchpath=$testbindir;;\n\t  *) func_append dllsearchpath \":$testbindir\";;\n\t  esac\n\t  ;;\n\tesac\n      done\n      # Substitute the hardcoded libdirs into the rpath.\n      if test -n \"$hardcode_libdir_separator\" &&\n\t test -n \"$hardcode_libdirs\"; then\n\tlibdir=$hardcode_libdirs\n\teval rpath=\\\" $hardcode_libdir_flag_spec\\\"\n      fi\n      compile_rpath=$rpath\n\n      rpath=\n      hardcode_libdirs=\n      for libdir in $finalize_rpath; do\n\tif test -n \"$hardcode_libdir_flag_spec\"; then\n\t  if test -n \"$hardcode_libdir_separator\"; then\n\t    if test -z \"$hardcode_libdirs\"; then\n\t      hardcode_libdirs=$libdir\n\t    else\n\t      # Just accumulate the unique libdirs.\n\t      case $hardcode_libdir_separator$hardcode_libdirs$hardcode_libdir_separator in\n\t      *\"$hardcode_libdir_separator$libdir$hardcode_libdir_separator\"*)\n\t\t;;\n\t      *)\n\t\tfunc_append hardcode_libdirs \"$hardcode_libdir_separator$libdir\"\n\t\t;;\n\t      esac\n\t    fi\n\t  else\n\t    eval flag=\\\"$hardcode_libdir_flag_spec\\\"\n\t    func_append rpath \" $flag\"\n\t  fi\n\telif test -n \"$runpath_var\"; then\n\t  case \"$finalize_perm_rpath \" in\n\t  *\" $libdir \"*) ;;\n\t  *) func_append finalize_perm_rpath \" $libdir\" ;;\n\t  esac\n\tfi\n      done\n      # Substitute the hardcoded libdirs into the rpath.\n      if test -n \"$hardcode_libdir_separator\" &&\n\t test -n \"$hardcode_libdirs\"; then\n\tlibdir=$hardcode_libdirs\n\teval rpath=\\\" $hardcode_libdir_flag_spec\\\"\n      fi\n      finalize_rpath=$rpath\n\n      if test -n \"$libobjs\" && test yes = \"$build_old_libs\"; then\n\t# Transform all the library objects into standard objects.\n\tcompile_command=`$ECHO \"$compile_command\" | $SP2NL | $SED \"$lo2o\" | $NL2SP`\n\tfinalize_command=`$ECHO \"$finalize_command\" | $SP2NL | $SED \"$lo2o\" | $NL2SP`\n      fi\n\n      func_generate_dlsyms \"$outputname\" \"@PROGRAM@\" false\n\n      # template prelinking step\n      if test -n \"$prelink_cmds\"; then\n\tfunc_execute_cmds \"$prelink_cmds\" 'exit $?'\n      fi\n\n      wrappers_required=:\n      case $host in\n      *cegcc* | *mingw32ce*)\n        # Disable wrappers for cegcc and mingw32ce hosts, we are cross compiling anyway.\n        wrappers_required=false\n        ;;\n      *cygwin* | *mingw* )\n        test yes = \"$build_libtool_libs\" || wrappers_required=false\n        ;;\n      *)\n        if test no = \"$need_relink\" || test yes != \"$build_libtool_libs\"; then\n          wrappers_required=false\n        fi\n        ;;\n      esac\n      $wrappers_required || {\n\t# Replace the output file specification.\n\tcompile_command=`$ECHO \"$compile_command\" | $SED 's%@OUTPUT@%'\"$output\"'%g'`\n\tlink_command=$compile_command$compile_rpath\n\n\t# We have no uninstalled library dependencies, so finalize right now.\n\texit_status=0\n\tfunc_show_eval \"$link_command\" 'exit_status=$?'\n\n\tif test -n \"$postlink_cmds\"; then\n\t  func_to_tool_file \"$output\"\n\t  postlink_cmds=`func_echo_all \"$postlink_cmds\" | $SED -e 's%@OUTPUT@%'\"$output\"'%g' -e 's%@TOOL_OUTPUT@%'\"$func_to_tool_file_result\"'%g'`\n\t  func_execute_cmds \"$postlink_cmds\" 'exit $?'\n\tfi\n\n\t# Delete the generated files.\n\tif test -f \"$output_objdir/${outputname}S.$objext\"; then\n\t  func_show_eval '$RM \"$output_objdir/${outputname}S.$objext\"'\n\tfi\n\n\texit $exit_status\n      }\n\n      if test -n \"$compile_shlibpath$finalize_shlibpath\"; then\n\tcompile_command=\"$shlibpath_var=\\\"$compile_shlibpath$finalize_shlibpath\\$$shlibpath_var\\\" $compile_command\"\n      fi\n      if test -n \"$finalize_shlibpath\"; then\n\tfinalize_command=\"$shlibpath_var=\\\"$finalize_shlibpath\\$$shlibpath_var\\\" $finalize_command\"\n      fi\n\n      compile_var=\n      finalize_var=\n      if test -n \"$runpath_var\"; then\n\tif test -n \"$perm_rpath\"; then\n\t  # We should set the runpath_var.\n\t  rpath=\n\t  for dir in $perm_rpath; do\n\t    func_append rpath \"$dir:\"\n\t  done\n\t  compile_var=\"$runpath_var=\\\"$rpath\\$$runpath_var\\\" \"\n\tfi\n\tif test -n \"$finalize_perm_rpath\"; then\n\t  # We should set the runpath_var.\n\t  rpath=\n\t  for dir in $finalize_perm_rpath; do\n\t    func_append rpath \"$dir:\"\n\t  done\n\t  finalize_var=\"$runpath_var=\\\"$rpath\\$$runpath_var\\\" \"\n\tfi\n      fi\n\n      if test yes = \"$no_install\"; then\n\t# We don't need to create a wrapper script.\n\tlink_command=$compile_var$compile_command$compile_rpath\n\t# Replace the output file specification.\n\tlink_command=`$ECHO \"$link_command\" | $SED 's%@OUTPUT@%'\"$output\"'%g'`\n\t# Delete the old output file.\n\t$opt_dry_run || $RM $output\n\t# Link the executable and exit\n\tfunc_show_eval \"$link_command\" 'exit $?'\n\n\tif test -n \"$postlink_cmds\"; then\n\t  func_to_tool_file \"$output\"\n\t  postlink_cmds=`func_echo_all \"$postlink_cmds\" | $SED -e 's%@OUTPUT@%'\"$output\"'%g' -e 's%@TOOL_OUTPUT@%'\"$func_to_tool_file_result\"'%g'`\n\t  func_execute_cmds \"$postlink_cmds\" 'exit $?'\n\tfi\n\n\texit $EXIT_SUCCESS\n      fi\n\n      case $hardcode_action,$fast_install in\n        relink,*)\n\t  # Fast installation is not supported\n\t  link_command=$compile_var$compile_command$compile_rpath\n\t  relink_command=$finalize_var$finalize_command$finalize_rpath\n\n\t  func_warning \"this platform does not like uninstalled shared libraries\"\n\t  func_warning \"'$output' will be relinked during installation\"\n\t  ;;\n        *,yes)\n\t  link_command=$finalize_var$compile_command$finalize_rpath\n\t  relink_command=`$ECHO \"$compile_var$compile_command$compile_rpath\" | $SED 's%@OUTPUT@%\\$progdir/\\$file%g'`\n          ;;\n\t*,no)\n\t  link_command=$compile_var$compile_command$compile_rpath\n\t  relink_command=$finalize_var$finalize_command$finalize_rpath\n          ;;\n\t*,needless)\n\t  link_command=$finalize_var$compile_command$finalize_rpath\n\t  relink_command=\n          ;;\n      esac\n\n      # Replace the output file specification.\n      link_command=`$ECHO \"$link_command\" | $SED 's%@OUTPUT@%'\"$output_objdir/$outputname\"'%g'`\n\n      # Delete the old output files.\n      $opt_dry_run || $RM $output $output_objdir/$outputname $output_objdir/lt-$outputname\n\n      func_show_eval \"$link_command\" 'exit $?'\n\n      if test -n \"$postlink_cmds\"; then\n\tfunc_to_tool_file \"$output_objdir/$outputname\"\n\tpostlink_cmds=`func_echo_all \"$postlink_cmds\" | $SED -e 's%@OUTPUT@%'\"$output_objdir/$outputname\"'%g' -e 's%@TOOL_OUTPUT@%'\"$func_to_tool_file_result\"'%g'`\n\tfunc_execute_cmds \"$postlink_cmds\" 'exit $?'\n      fi\n\n      # Now create the wrapper script.\n      func_verbose \"creating $output\"\n\n      # Quote the relink command for shipping.\n      if test -n \"$relink_command\"; then\n\t# Preserve any variables that may affect compiler behavior\n\tfor var in $variables_saved_for_relink; do\n\t  if eval test -z \\\"\\${$var+set}\\\"; then\n\t    relink_command=\"{ test -z \\\"\\${$var+set}\\\" || $lt_unset $var || { $var=; export $var; }; }; $relink_command\"\n\t  elif eval var_value=\\$$var; test -z \"$var_value\"; then\n\t    relink_command=\"$var=; export $var; $relink_command\"\n\t  else\n\t    func_quote_for_eval \"$var_value\"\n\t    relink_command=\"$var=$func_quote_for_eval_result; export $var; $relink_command\"\n\t  fi\n\tdone\n\trelink_command=\"(cd `pwd`; $relink_command)\"\n\trelink_command=`$ECHO \"$relink_command\" | $SED \"$sed_quote_subst\"`\n      fi\n\n      # Only actually do things if not in dry run mode.\n      $opt_dry_run || {\n\t# win32 will think the script is a binary if it has\n\t# a .exe suffix, so we strip it off here.\n\tcase $output in\n\t  *.exe) func_stripname '' '.exe' \"$output\"\n\t         output=$func_stripname_result ;;\n\tesac\n\t# test for cygwin because mv fails w/o .exe extensions\n\tcase $host in\n\t  *cygwin*)\n\t    exeext=.exe\n\t    func_stripname '' '.exe' \"$outputname\"\n\t    outputname=$func_stripname_result ;;\n\t  *) exeext= ;;\n\tesac\n\tcase $host in\n\t  *cygwin* | *mingw* )\n\t    func_dirname_and_basename \"$output\" \"\" \".\"\n\t    output_name=$func_basename_result\n\t    output_path=$func_dirname_result\n\t    cwrappersource=$output_path/$objdir/lt-$output_name.c\n\t    cwrapper=$output_path/$output_name.exe\n\t    $RM $cwrappersource $cwrapper\n\t    trap \"$RM $cwrappersource $cwrapper; exit $EXIT_FAILURE\" 1 2 15\n\n\t    func_emit_cwrapperexe_src > $cwrappersource\n\n\t    # The wrapper executable is built using the $host compiler,\n\t    # because it contains $host paths and files. If cross-\n\t    # compiling, it, like the target executable, must be\n\t    # executed on the $host or under an emulation environment.\n\t    $opt_dry_run || {\n\t      $LTCC $LTCFLAGS -o $cwrapper $cwrappersource\n\t      $STRIP $cwrapper\n\t    }\n\n\t    # Now, create the wrapper script for func_source use:\n\t    func_ltwrapper_scriptname $cwrapper\n\t    $RM $func_ltwrapper_scriptname_result\n\t    trap \"$RM $func_ltwrapper_scriptname_result; exit $EXIT_FAILURE\" 1 2 15\n\t    $opt_dry_run || {\n\t      # note: this script will not be executed, so do not chmod.\n\t      if test \"x$build\" = \"x$host\"; then\n\t\t$cwrapper --lt-dump-script > $func_ltwrapper_scriptname_result\n\t      else\n\t\tfunc_emit_wrapper no > $func_ltwrapper_scriptname_result\n\t      fi\n\t    }\n\t  ;;\n\t  * )\n\t    $RM $output\n\t    trap \"$RM $output; exit $EXIT_FAILURE\" 1 2 15\n\n\t    func_emit_wrapper no > $output\n\t    chmod +x $output\n\t  ;;\n\tesac\n      }\n      exit $EXIT_SUCCESS\n      ;;\n    esac\n\n    # See if we need to build an old-fashioned archive.\n    for oldlib in $oldlibs; do\n\n      case $build_libtool_libs in\n        convenience)\n\t  oldobjs=\"$libobjs_save $symfileobj\"\n\t  addlibs=$convenience\n\t  build_libtool_libs=no\n\t  ;;\n\tmodule)\n\t  oldobjs=$libobjs_save\n\t  addlibs=$old_convenience\n\t  build_libtool_libs=no\n          ;;\n\t*)\n\t  oldobjs=\"$old_deplibs $non_pic_objects\"\n\t  $preload && test -f \"$symfileobj\" \\\n\t    && func_append oldobjs \" $symfileobj\"\n\t  addlibs=$old_convenience\n\t  ;;\n      esac\n\n      if test -n \"$addlibs\"; then\n\tgentop=$output_objdir/${outputname}x\n\tfunc_append generated \" $gentop\"\n\n\tfunc_extract_archives $gentop $addlibs\n\tfunc_append oldobjs \" $func_extract_archives_result\"\n      fi\n\n      # Do each command in the archive commands.\n      if test -n \"$old_archive_from_new_cmds\" && test yes = \"$build_libtool_libs\"; then\n\tcmds=$old_archive_from_new_cmds\n      else\n\n\t# Add any objects from preloaded convenience libraries\n\tif test -n \"$dlprefiles\"; then\n\t  gentop=$output_objdir/${outputname}x\n\t  func_append generated \" $gentop\"\n\n\t  func_extract_archives $gentop $dlprefiles\n\t  func_append oldobjs \" $func_extract_archives_result\"\n\tfi\n\n\t# POSIX demands no paths to be encoded in archives.  We have\n\t# to avoid creating archives with duplicate basenames if we\n\t# might have to extract them afterwards, e.g., when creating a\n\t# static archive out of a convenience library, or when linking\n\t# the entirety of a libtool archive into another (currently\n\t# not supported by libtool).\n\tif (for obj in $oldobjs\n\t    do\n\t      func_basename \"$obj\"\n\t      $ECHO \"$func_basename_result\"\n\t    done | sort | sort -uc >/dev/null 2>&1); then\n\t  :\n\telse\n\t  echo \"copying selected object files to avoid basename conflicts...\"\n\t  gentop=$output_objdir/${outputname}x\n\t  func_append generated \" $gentop\"\n\t  func_mkdir_p \"$gentop\"\n\t  save_oldobjs=$oldobjs\n\t  oldobjs=\n\t  counter=1\n\t  for obj in $save_oldobjs\n\t  do\n\t    func_basename \"$obj\"\n\t    objbase=$func_basename_result\n\t    case \" $oldobjs \" in\n\t    \" \") oldobjs=$obj ;;\n\t    *[\\ /]\"$objbase \"*)\n\t      while :; do\n\t\t# Make sure we don't pick an alternate name that also\n\t\t# overlaps.\n\t\tnewobj=lt$counter-$objbase\n\t\tfunc_arith $counter + 1\n\t\tcounter=$func_arith_result\n\t\tcase \" $oldobjs \" in\n\t\t*[\\ /]\"$newobj \"*) ;;\n\t\t*) if test ! -f \"$gentop/$newobj\"; then break; fi ;;\n\t\tesac\n\t      done\n\t      func_show_eval \"ln $obj $gentop/$newobj || cp $obj $gentop/$newobj\"\n\t      func_append oldobjs \" $gentop/$newobj\"\n\t      ;;\n\t    *) func_append oldobjs \" $obj\" ;;\n\t    esac\n\t  done\n\tfi\n\tfunc_to_tool_file \"$oldlib\" func_convert_file_msys_to_w32\n\ttool_oldlib=$func_to_tool_file_result\n\teval cmds=\\\"$old_archive_cmds\\\"\n\n\tfunc_len \" $cmds\"\n\tlen=$func_len_result\n\tif test \"$len\" -lt \"$max_cmd_len\" || test \"$max_cmd_len\" -le -1; then\n\t  cmds=$old_archive_cmds\n\telif test -n \"$archiver_list_spec\"; then\n\t  func_verbose \"using command file archive linking...\"\n\t  for obj in $oldobjs\n\t  do\n\t    func_to_tool_file \"$obj\"\n\t    $ECHO \"$func_to_tool_file_result\"\n\t  done > $output_objdir/$libname.libcmd\n\t  func_to_tool_file \"$output_objdir/$libname.libcmd\"\n\t  oldobjs=\" $archiver_list_spec$func_to_tool_file_result\"\n\t  cmds=$old_archive_cmds\n\telse\n\t  # the command line is too long to link in one step, link in parts\n\t  func_verbose \"using piecewise archive linking...\"\n\t  save_RANLIB=$RANLIB\n\t  RANLIB=:\n\t  objlist=\n\t  concat_cmds=\n\t  save_oldobjs=$oldobjs\n\t  oldobjs=\n\t  # Is there a better way of finding the last object in the list?\n\t  for obj in $save_oldobjs\n\t  do\n\t    last_oldobj=$obj\n\t  done\n\t  eval test_cmds=\\\"$old_archive_cmds\\\"\n\t  func_len \" $test_cmds\"\n\t  len0=$func_len_result\n\t  len=$len0\n\t  for obj in $save_oldobjs\n\t  do\n\t    func_len \" $obj\"\n\t    func_arith $len + $func_len_result\n\t    len=$func_arith_result\n\t    func_append objlist \" $obj\"\n\t    if test \"$len\" -lt \"$max_cmd_len\"; then\n\t      :\n\t    else\n\t      # the above command should be used before it gets too long\n\t      oldobjs=$objlist\n\t      if test \"$obj\" = \"$last_oldobj\"; then\n\t\tRANLIB=$save_RANLIB\n\t      fi\n\t      test -z \"$concat_cmds\" || concat_cmds=$concat_cmds~\n\t      eval concat_cmds=\\\"\\$concat_cmds$old_archive_cmds\\\"\n\t      objlist=\n\t      len=$len0\n\t    fi\n\t  done\n\t  RANLIB=$save_RANLIB\n\t  oldobjs=$objlist\n\t  if test -z \"$oldobjs\"; then\n\t    eval cmds=\\\"\\$concat_cmds\\\"\n\t  else\n\t    eval cmds=\\\"\\$concat_cmds~\\$old_archive_cmds\\\"\n\t  fi\n\tfi\n      fi\n      func_execute_cmds \"$cmds\" 'exit $?'\n    done\n\n    test -n \"$generated\" && \\\n      func_show_eval \"${RM}r$generated\"\n\n    # Now create the libtool archive.\n    case $output in\n    *.la)\n      old_library=\n      test yes = \"$build_old_libs\" && old_library=$libname.$libext\n      func_verbose \"creating $output\"\n\n      # Preserve any variables that may affect compiler behavior\n      for var in $variables_saved_for_relink; do\n\tif eval test -z \\\"\\${$var+set}\\\"; then\n\t  relink_command=\"{ test -z \\\"\\${$var+set}\\\" || $lt_unset $var || { $var=; export $var; }; }; $relink_command\"\n\telif eval var_value=\\$$var; test -z \"$var_value\"; then\n\t  relink_command=\"$var=; export $var; $relink_command\"\n\telse\n\t  func_quote_for_eval \"$var_value\"\n\t  relink_command=\"$var=$func_quote_for_eval_result; export $var; $relink_command\"\n\tfi\n      done\n      # Quote the link command for shipping.\n      relink_command=\"(cd `pwd`; $SHELL \\\"$progpath\\\" $preserve_args --mode=relink $libtool_args @inst_prefix_dir@)\"\n      relink_command=`$ECHO \"$relink_command\" | $SED \"$sed_quote_subst\"`\n      if test yes = \"$hardcode_automatic\"; then\n\trelink_command=\n      fi\n\n      # Only create the output if not a dry run.\n      $opt_dry_run || {\n\tfor installed in no yes; do\n\t  if test yes = \"$installed\"; then\n\t    if test -z \"$install_libdir\"; then\n\t      break\n\t    fi\n\t    output=$output_objdir/${outputname}i\n\t    # Replace all uninstalled libtool libraries with the installed ones\n\t    newdependency_libs=\n\t    for deplib in $dependency_libs; do\n\t      case $deplib in\n\t      *.la)\n\t\tfunc_basename \"$deplib\"\n\t\tname=$func_basename_result\n\t\tfunc_resolve_sysroot \"$deplib\"\n\t\teval libdir=`$SED -n -e 's/^libdir=\\(.*\\)$/\\1/p' $func_resolve_sysroot_result`\n\t\ttest -z \"$libdir\" && \\\n\t\t  func_fatal_error \"'$deplib' is not a valid libtool archive\"\n\t\tfunc_append newdependency_libs \" ${lt_sysroot:+=}$libdir/$name\"\n\t\t;;\n\t      -L*)\n\t\tfunc_stripname -L '' \"$deplib\"\n\t\tfunc_replace_sysroot \"$func_stripname_result\"\n\t\tfunc_append newdependency_libs \" -L$func_replace_sysroot_result\"\n\t\t;;\n\t      -R*)\n\t\tfunc_stripname -R '' \"$deplib\"\n\t\tfunc_replace_sysroot \"$func_stripname_result\"\n\t\tfunc_append newdependency_libs \" -R$func_replace_sysroot_result\"\n\t\t;;\n\t      *) func_append newdependency_libs \" $deplib\" ;;\n\t      esac\n\t    done\n\t    dependency_libs=$newdependency_libs\n\t    newdlfiles=\n\n\t    for lib in $dlfiles; do\n\t      case $lib in\n\t      *.la)\n\t        func_basename \"$lib\"\n\t\tname=$func_basename_result\n\t\teval libdir=`$SED -n -e 's/^libdir=\\(.*\\)$/\\1/p' $lib`\n\t\ttest -z \"$libdir\" && \\\n\t\t  func_fatal_error \"'$lib' is not a valid libtool archive\"\n\t\tfunc_append newdlfiles \" ${lt_sysroot:+=}$libdir/$name\"\n\t\t;;\n\t      *) func_append newdlfiles \" $lib\" ;;\n\t      esac\n\t    done\n\t    dlfiles=$newdlfiles\n\t    newdlprefiles=\n\t    for lib in $dlprefiles; do\n\t      case $lib in\n\t      *.la)\n\t\t# Only pass preopened files to the pseudo-archive (for\n\t\t# eventual linking with the app. that links it) if we\n\t\t# didn't already link the preopened objects directly into\n\t\t# the library:\n\t\tfunc_basename \"$lib\"\n\t\tname=$func_basename_result\n\t\teval libdir=`$SED -n -e 's/^libdir=\\(.*\\)$/\\1/p' $lib`\n\t\ttest -z \"$libdir\" && \\\n\t\t  func_fatal_error \"'$lib' is not a valid libtool archive\"\n\t\tfunc_append newdlprefiles \" ${lt_sysroot:+=}$libdir/$name\"\n\t\t;;\n\t      esac\n\t    done\n\t    dlprefiles=$newdlprefiles\n\t  else\n\t    newdlfiles=\n\t    for lib in $dlfiles; do\n\t      case $lib in\n\t\t[\\\\/]* | [A-Za-z]:[\\\\/]*) abs=$lib ;;\n\t\t*) abs=`pwd`\"/$lib\" ;;\n\t      esac\n\t      func_append newdlfiles \" $abs\"\n\t    done\n\t    dlfiles=$newdlfiles\n\t    newdlprefiles=\n\t    for lib in $dlprefiles; do\n\t      case $lib in\n\t\t[\\\\/]* | [A-Za-z]:[\\\\/]*) abs=$lib ;;\n\t\t*) abs=`pwd`\"/$lib\" ;;\n\t      esac\n\t      func_append newdlprefiles \" $abs\"\n\t    done\n\t    dlprefiles=$newdlprefiles\n\t  fi\n\t  $RM $output\n\t  # place dlname in correct position for cygwin\n\t  # In fact, it would be nice if we could use this code for all target\n\t  # systems that can't hard-code library paths into their executables\n\t  # and that have no shared library path variable independent of PATH,\n\t  # but it turns out we can't easily determine that from inspecting\n\t  # libtool variables, so we have to hard-code the OSs to which it\n\t  # applies here; at the moment, that means platforms that use the PE\n\t  # object format with DLL files.  See the long comment at the top of\n\t  # tests/bindir.at for full details.\n\t  tdlname=$dlname\n\t  case $host,$output,$installed,$module,$dlname in\n\t    *cygwin*,*lai,yes,no,*.dll | *mingw*,*lai,yes,no,*.dll | *cegcc*,*lai,yes,no,*.dll)\n\t      # If a -bindir argument was supplied, place the dll there.\n\t      if test -n \"$bindir\"; then\n\t\tfunc_relative_path \"$install_libdir\" \"$bindir\"\n\t\ttdlname=$func_relative_path_result/$dlname\n\t      else\n\t\t# Otherwise fall back on heuristic.\n\t\ttdlname=../bin/$dlname\n\t      fi\n\t      ;;\n\t  esac\n\t  $ECHO > $output \"\\\n# $outputname - a libtool library file\n# Generated by $PROGRAM (GNU $PACKAGE) $VERSION\n#\n# Please DO NOT delete this file!\n# It is necessary for linking the library.\n\n# The name that we can dlopen(3).\ndlname='$tdlname'\n\n# Names of this library.\nlibrary_names='$library_names'\n\n# The name of the static archive.\nold_library='$old_library'\n\n# Linker flags that cannot go in dependency_libs.\ninherited_linker_flags='$new_inherited_linker_flags'\n\n# Libraries that this one depends upon.\ndependency_libs='$dependency_libs'\n\n# Names of additional weak libraries provided by this library\nweak_library_names='$weak_libs'\n\n# Version information for $libname.\ncurrent=$current\nage=$age\nrevision=$revision\n\n# Is this an already installed library?\ninstalled=$installed\n\n# Should we warn about portability when linking against -modules?\nshouldnotlink=$module\n\n# Files to dlopen/dlpreopen\ndlopen='$dlfiles'\ndlpreopen='$dlprefiles'\n\n# Directory that this library needs to be installed in:\nlibdir='$install_libdir'\"\n\t  if test no,yes = \"$installed,$need_relink\"; then\n\t    $ECHO >> $output \"\\\nrelink_command=\\\"$relink_command\\\"\"\n\t  fi\n\tdone\n      }\n\n      # Do a symbolic link so that the libtool archive can be found in\n      # LD_LIBRARY_PATH before the program is installed.\n      func_show_eval '( cd \"$output_objdir\" && $RM \"$outputname\" && $LN_S \"../$outputname\" \"$outputname\" )' 'exit $?'\n      ;;\n    esac\n    exit $EXIT_SUCCESS\n}\n\nif test link = \"$opt_mode\" || test relink = \"$opt_mode\"; then\n  func_mode_link ${1+\"$@\"}\nfi\n\n\n# func_mode_uninstall arg...\nfunc_mode_uninstall ()\n{\n    $debug_cmd\n\n    RM=$nonopt\n    files=\n    rmforce=false\n    exit_status=0\n\n    # This variable tells wrapper scripts just to set variables rather\n    # than running their programs.\n    libtool_install_magic=$magic\n\n    for arg\n    do\n      case $arg in\n      -f) func_append RM \" $arg\"; rmforce=: ;;\n      -*) func_append RM \" $arg\" ;;\n      *) func_append files \" $arg\" ;;\n      esac\n    done\n\n    test -z \"$RM\" && \\\n      func_fatal_help \"you must specify an RM program\"\n\n    rmdirs=\n\n    for file in $files; do\n      func_dirname \"$file\" \"\" \".\"\n      dir=$func_dirname_result\n      if test . = \"$dir\"; then\n\todir=$objdir\n      else\n\todir=$dir/$objdir\n      fi\n      func_basename \"$file\"\n      name=$func_basename_result\n      test uninstall = \"$opt_mode\" && odir=$dir\n\n      # Remember odir for removal later, being careful to avoid duplicates\n      if test clean = \"$opt_mode\"; then\n\tcase \" $rmdirs \" in\n\t  *\" $odir \"*) ;;\n\t  *) func_append rmdirs \" $odir\" ;;\n\tesac\n      fi\n\n      # Don't error if the file doesn't exist and rm -f was used.\n      if { test -L \"$file\"; } >/dev/null 2>&1 ||\n\t { test -h \"$file\"; } >/dev/null 2>&1 ||\n\t test -f \"$file\"; then\n\t:\n      elif test -d \"$file\"; then\n\texit_status=1\n\tcontinue\n      elif $rmforce; then\n\tcontinue\n      fi\n\n      rmfiles=$file\n\n      case $name in\n      *.la)\n\t# Possibly a libtool archive, so verify it.\n\tif func_lalib_p \"$file\"; then\n\t  func_source $dir/$name\n\n\t  # Delete the libtool libraries and symlinks.\n\t  for n in $library_names; do\n\t    func_append rmfiles \" $odir/$n\"\n\t  done\n\t  test -n \"$old_library\" && func_append rmfiles \" $odir/$old_library\"\n\n\t  case $opt_mode in\n\t  clean)\n\t    case \" $library_names \" in\n\t    *\" $dlname \"*) ;;\n\t    *) test -n \"$dlname\" && func_append rmfiles \" $odir/$dlname\" ;;\n\t    esac\n\t    test -n \"$libdir\" && func_append rmfiles \" $odir/$name $odir/${name}i\"\n\t    ;;\n\t  uninstall)\n\t    if test -n \"$library_names\"; then\n\t      # Do each command in the postuninstall commands.\n\t      func_execute_cmds \"$postuninstall_cmds\" '$rmforce || exit_status=1'\n\t    fi\n\n\t    if test -n \"$old_library\"; then\n\t      # Do each command in the old_postuninstall commands.\n\t      func_execute_cmds \"$old_postuninstall_cmds\" '$rmforce || exit_status=1'\n\t    fi\n\t    # FIXME: should reinstall the best remaining shared library.\n\t    ;;\n\t  esac\n\tfi\n\t;;\n\n      *.lo)\n\t# Possibly a libtool object, so verify it.\n\tif func_lalib_p \"$file\"; then\n\n\t  # Read the .lo file\n\t  func_source $dir/$name\n\n\t  # Add PIC object to the list of files to remove.\n\t  if test -n \"$pic_object\" && test none != \"$pic_object\"; then\n\t    func_append rmfiles \" $dir/$pic_object\"\n\t  fi\n\n\t  # Add non-PIC object to the list of files to remove.\n\t  if test -n \"$non_pic_object\" && test none != \"$non_pic_object\"; then\n\t    func_append rmfiles \" $dir/$non_pic_object\"\n\t  fi\n\tfi\n\t;;\n\n      *)\n\tif test clean = \"$opt_mode\"; then\n\t  noexename=$name\n\t  case $file in\n\t  *.exe)\n\t    func_stripname '' '.exe' \"$file\"\n\t    file=$func_stripname_result\n\t    func_stripname '' '.exe' \"$name\"\n\t    noexename=$func_stripname_result\n\t    # $file with .exe has already been added to rmfiles,\n\t    # add $file without .exe\n\t    func_append rmfiles \" $file\"\n\t    ;;\n\t  esac\n\t  # Do a test to see if this is a libtool program.\n\t  if func_ltwrapper_p \"$file\"; then\n\t    if func_ltwrapper_executable_p \"$file\"; then\n\t      func_ltwrapper_scriptname \"$file\"\n\t      relink_command=\n\t      func_source $func_ltwrapper_scriptname_result\n\t      func_append rmfiles \" $func_ltwrapper_scriptname_result\"\n\t    else\n\t      relink_command=\n\t      func_source $dir/$noexename\n\t    fi\n\n\t    # note $name still contains .exe if it was in $file originally\n\t    # as does the version of $file that was added into $rmfiles\n\t    func_append rmfiles \" $odir/$name $odir/${name}S.$objext\"\n\t    if test yes = \"$fast_install\" && test -n \"$relink_command\"; then\n\t      func_append rmfiles \" $odir/lt-$name\"\n\t    fi\n\t    if test \"X$noexename\" != \"X$name\"; then\n\t      func_append rmfiles \" $odir/lt-$noexename.c\"\n\t    fi\n\t  fi\n\tfi\n\t;;\n      esac\n      func_show_eval \"$RM $rmfiles\" 'exit_status=1'\n    done\n\n    # Try to remove the $objdir's in the directories where we deleted files\n    for dir in $rmdirs; do\n      if test -d \"$dir\"; then\n\tfunc_show_eval \"rmdir $dir >/dev/null 2>&1\"\n      fi\n    done\n\n    exit $exit_status\n}\n\nif test uninstall = \"$opt_mode\" || test clean = \"$opt_mode\"; then\n  func_mode_uninstall ${1+\"$@\"}\nfi\n\ntest -z \"$opt_mode\" && {\n  help=$generic_help\n  func_fatal_help \"you must specify a MODE\"\n}\n\ntest -z \"$exec_cmd\" && \\\n  func_fatal_help \"invalid operation mode '$opt_mode'\"\n\nif test -n \"$exec_cmd\"; then\n  eval exec \"$exec_cmd\"\n  exit $EXIT_FAILURE\nfi\n\nexit $exit_status\n\n\n# The TAGs below are defined such that we never get into a situation\n# where we disable both kinds of libraries.  Given conflicting\n# choices, we go for a static library, that is the most portable,\n# since we can't tell whether shared libraries were disabled because\n# the user asked for that or because the platform doesn't support\n# them.  This is particularly important on AIX, because we don't\n# support having both static and shared libraries enabled at the same\n# time on that platform, so we default to a shared-only configuration.\n# If a disable-shared tag is given, we'll fallback to a static-only\n# configuration.  But we'll never go from static-only to shared-only.\n\n# ### BEGIN LIBTOOL TAG CONFIG: disable-shared\nbuild_libtool_libs=no\nbuild_old_libs=yes\n# ### END LIBTOOL TAG CONFIG: disable-shared\n\n# ### BEGIN LIBTOOL TAG CONFIG: disable-static\nbuild_old_libs=`case $build_libtool_libs in yes) echo no;; *) echo yes;; esac`\n# ### END LIBTOOL TAG CONFIG: disable-static\n\n# Local Variables:\n# mode:shell-script\n# sh-indentation:2\n# End:\n",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/src/system/system.nw": "% -*- ess-noweb-default-code-mode: f90-mode; noweb-default-code-mode: f90-mode; -*-\n% WHIZARD code as NOWEB source: system interfaces\n\\chapter{System: Interfaces and Handlers}\n\\includemodulegraph{system}\n\nHere, we collect modules that deal with the ``system'':\noperating-system interfaces, error handlers and diagnostics.\n\\begin{description}\n\\item[system\\_defs]\n  Constants relevant for the modules in this set.\n\\item[diagnostics]\n  Error and diagnostic message handling.  Any\n  messages and errors issued by WHIZARD functions are handled by the\n  subroutines in this module, if possible.\n\\item[os\\_interface]\n  Execute system calls, build and link external object files and libraries.\n\\item[cputime]\n  Timer data type and methods, for measuring performance.\n\\end{description}\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\\section{Constants}\nThe parameters here are used in various parts of the program,\nstarting from the modules in the current chapter.  Some of them may be\nmodified if the need arises.\n<<[[system_defs.f90]]>>=\n<<File header>>\n\nmodule system_defs\n\n  use, intrinsic :: iso_fortran_env, only: iostat_end, iostat_eor !NODEP!\n\n<<Standard module head>>\n\n<<System defs: public parameters>>\n\nend module system_defs\n@ %def system_defs\n@\n\\subsection{Version}\nThe version string is used for checking files.  Note that the string\nlength MUST NOT be changed, because reading binary files relies on it.\n<<System defs: public parameters>>=\n  integer, parameter, public :: VERSION_STRLEN = 255\n  character(len=VERSION_STRLEN), parameter, public :: &\n       & VERSION_STRING = \"WHIZARD version <<Version>> (<<Date>>)\"\n\n@ %def VERSION_STRLEN VERSION_STRING\n@\n\\subsection{Text Buffer}\nThere is a hard limit on the line length which we should export.  This\nbuffer size is used both by the message handler, the lexer, and some\nfurther modules.\n<<System defs: public parameters>>=\n  integer, parameter, public :: BUFFER_SIZE = 1000\n\n@ %def BUFFER_SIZE\n@\n\\subsection{IOSTAT Codes}\nDefined in [[iso_fortran_env]], but we would like to use shorthands.\n<<System defs: public parameters>>=\n  integer, parameter, public :: EOF = iostat_end,  EOR = iostat_eor\n\n@ %def EOF EOR\n@\n\\subsection{Character Codes}\nSingle-character constants.\n<<System defs: public parameters>>=\n  character, parameter, public :: BLANK = ' '\n  character, parameter, public :: TAB = achar(9)\n  character, parameter, public :: CR = achar(13)\n  character, parameter, public :: LF = achar(10)\n  character, parameter, public :: BACKSLASH = achar(92)\n\n@ %def BLANK TAB CR NL\n@ Character strings that indicate character classes.\n<<System defs: public parameters>>=\n  character(*), parameter, public :: WHITESPACE_CHARS = BLANK// TAB // CR // LF\n  character(*), parameter, public :: LCLETTERS = \"abcdefghijklmnopqrstuvwxyz\"\n  character(*), parameter, public :: UCLETTERS = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n  character(*), parameter, public :: DIGITS = \"0123456789\"\n\n@ %def WHITESPACE_CHARS LCLETTERS UCLETTERS DIGITS\n@\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\\section{C wrapper for sigaction}\nThis implements calls to [[sigaction]] and the appropriate signal handlers in\nC.  The functionality is needed for the [[diagnostics]] module.\n<<[[signal_interface.c]]>>=\n/*\n<<File header>>\n*/\n#include <signal.h>\n#include <stdlib.h>\n\nextern int wo_sigint;\nextern int wo_sigterm;\nextern int wo_sigxcpu;\nextern int wo_sigxfsz;\n\nstatic void wo_handler_sigint (int sig) {\n  wo_sigint = sig;\n}\n\nstatic void wo_handler_sigterm (int sig) {\n  wo_sigterm = sig;\n}\n\nstatic void wo_handler_sigxcpu (int sig) {\n  wo_sigxcpu = sig;\n}\n\nstatic void wo_handler_sigxfsz (int sig) {\n  wo_sigxfsz = sig;\n}\n\nint wo_mask_sigint () {\n  struct sigaction sa;\n  sigset_t blocks;\n  sigfillset (&blocks);\n  sa.sa_flags = 0;\n  sa.sa_mask = blocks;\n  sa.sa_handler = wo_handler_sigint;\n  return sigaction(SIGINT, &sa, NULL);\n}\n\nint wo_mask_sigterm () {\n  struct sigaction sa;\n  sigset_t blocks;\n  sigfillset (&blocks);\n  sa.sa_flags = 0;\n  sa.sa_mask = blocks;\n  sa.sa_handler = wo_handler_sigterm;\n  return sigaction(SIGTERM, &sa, NULL);\n}\n\nint wo_mask_sigxcpu () {\n  struct sigaction sa;\n  sigset_t blocks;\n  sigfillset (&blocks);\n  sa.sa_flags = 0;\n  sa.sa_mask = blocks;\n  sa.sa_handler = wo_handler_sigxcpu;\n  return sigaction(SIGXCPU, &sa, NULL);\n}\n\nint wo_mask_sigxfsz () {\n  struct sigaction sa;\n  sigset_t blocks;\n  sigfillset (&blocks);\n  sa.sa_flags = 0;\n  sa.sa_mask = blocks;\n  sa.sa_handler = wo_handler_sigxfsz;\n  return sigaction(SIGXFSZ, &sa, NULL);\n}\n\nint wo_release_sigint () {\n  struct sigaction sa;\n  sigset_t blocks;\n  sigfillset (&blocks);\n  sa.sa_flags = 0;\n  sa.sa_mask = blocks;\n  sa.sa_handler = SIG_DFL;\n  return sigaction(SIGINT, &sa, NULL);\n}\n\nint wo_release_sigterm () {\n  struct sigaction sa;\n  sigset_t blocks;\n  sigfillset (&blocks);\n  sa.sa_flags = 0;\n  sa.sa_mask = blocks;\n  sa.sa_handler = SIG_DFL;\n  return sigaction(SIGTERM, &sa, NULL);\n}\n\nint wo_release_sigxcpu () {\n  struct sigaction sa;\n  sigset_t blocks;\n  sigfillset (&blocks);\n  sa.sa_flags = 0;\n  sa.sa_mask = blocks;\n  sa.sa_handler = SIG_DFL;\n  return sigaction(SIGXCPU, &sa, NULL);\n}\n\nint wo_release_sigxfsz () {\n  struct sigaction sa;\n  sigset_t blocks;\n  sigfillset (&blocks);\n  sa.sa_flags = 0;\n  sa.sa_mask = blocks;\n  sa.sa_handler = SIG_DFL;\n  return sigaction(SIGXFSZ, &sa, NULL);\n}\n@\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\\section{C wrapper for printf}\nThe [[printf]] family of functions is implemented in C with an undefined\nnumber of arguments.  This is not supported by the [[bind(C)]] interface.  We\ntherefore write wrappers for the versions of [[sprintf]] that\nwe will actually use.\n\nThis is used by the [[formats]] module.\n<<[[sprintf_interface.c]]>>=\n/*\n<<File header>>\n*/\n#include <stdio.h>\n\nint sprintf_none(char* str, const char* format) {\n  return sprintf(str, format);\n}\n\nint sprintf_int(char* str, const char* format, int val) {\n  return sprintf(str, format, val);\n}\n\nint sprintf_double(char* str, const char* format, double val) {\n  return sprintf(str, format, val);\n}\n\nint sprintf_str(char* str, const char* format, const char* val) {\n  return sprintf(str, format, val);\n}\n\n<<sprintf interfaces>>=\n  interface\n    function sprintf_none (str, fmt) result (stat) bind(C)\n      use iso_c_binding !NODEP!\n      integer(c_int) :: stat\n      character(c_char), dimension(*), intent(inout) :: str\n      character(c_char), dimension(*), intent(in) :: fmt\n    end function sprintf_none\n  end interface\n\n  interface\n    function sprintf_int (str, fmt, val) result (stat) bind(C)\n      use iso_c_binding !NODEP!\n      integer(c_int) :: stat\n      character(c_char), dimension(*), intent(inout) :: str\n      character(c_char), dimension(*), intent(in) :: fmt\n      integer(c_int), value :: val\n    end function sprintf_int\n  end interface\n\n  interface\n    function sprintf_double (str, fmt, val) result (stat) bind(C)\n      use iso_c_binding !NODEP!\n      integer(c_int) :: stat\n      character(c_char), dimension(*), intent(inout) :: str\n      character(c_char), dimension(*), intent(in) :: fmt\n      real(c_double), value :: val\n    end function sprintf_double\n  end interface\n\n  interface\n    function sprintf_str(str, fmt, val) result (stat) bind(C)\n      use iso_c_binding !NODEP!\n      integer(c_int) :: stat\n      character(c_char), dimension(*), intent(inout) :: str\n      character(c_char), dimension(*), intent(in) :: fmt\n      character(c_char), dimension(*), intent(in) :: val\n    end function sprintf_str\n  end interface\n\n@ %def sprintf_int sprintf_double sprintf_str\n@\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\\section{Error, Message and Signal Handling}\nWe are not so ambitious as to do proper exception handling in\n[[WHIZARD]], but at least it may be useful to have a common interface\nfor diagnostics: Results, messages, warnings, and such.  As module\nvariables we keep a buffer where the current message may be written to\nand a level indicator which tells which messages should be written on\nscreen and which ones should be skipped.  Alternatively, a string may\nbe directly supplied to the message routine: this overrides the\nbuffer, avoiding the necessety of formatted I/O in trivial cases.\n<<[[diagnostics.f90]]>>=\n<<File header>>\n\nmodule diagnostics\n\n  use, intrinsic :: iso_c_binding !NODEP!\n  use, intrinsic :: iso_fortran_env, only: output_unit !NODEP!\n\n<<Use kinds>>\n<<Use strings>>\n<<Use debug>>\n  use string_utils, only: str\n  use io_units\n\n  use system_dependencies\n  use system_defs, only: BUFFER_SIZE, MAX_ERRORS\n\n<<Standard module head>>\n\n<<Diagnostics: public>>\n\n<<Diagnostics: parameters>>\n\n<<Diagnostics: types>>\n\n<<Diagnostics: variables>>\n\n<<Diagnostics: interfaces>>\n\ncontains\n\n<<Diagnostics: procedures>>\n\nend module diagnostics\n\n\n<<Diagnostics: external procedures>>\n@ %def diagnostics\n@\nDiagnostics levels:\n<<Diagnostics: public>>=\n  public :: RESULT, DEBUG, DEBUG2\n<<Diagnostics: parameters>>=\n  integer, parameter :: TERMINATE=-2, BUG=-1, FATAL=1, &\n       ERROR=2, WARNING=3, MESSAGE=4, RESULT=5, &\n       DEBUG=6, DEBUG2=7\n@ %def FATAL ERROR WARNING MESSAGE RESULT DEBUG DEBUG2\nDiagnostics areas:\n<<Diagnostics: public>>=\n  public :: d_area\n<<Diagnostics: interfaces>>=\n  interface d_area\n     module procedure d_area_of_string\n     module procedure d_area_to_string\n  end interface\n<<Diagnostics: procedures>>=\n  function d_area_of_string (string) result (i)\n    integer :: i\n    type(string_t), intent(in) :: string\n    select case (char (string))\n    case (\"particles\")\n       i = D_PARTICLES\n    case (\"events\")\n       i = D_EVENTS\n    case (\"shower\")\n       i = D_SHOWER\n    case (\"model_features\")\n       i = D_MODEL_F\n    case (\"matching\")\n       i = D_MATCHING\n    case (\"transforms\")\n       i = D_TRANSFORMS\n    case (\"subtraction\")\n       i = D_SUBTRACTION\n    case (\"virtual\")\n       i = D_VIRTUAL\n    case (\"threshold\")\n       i = D_THRESHOLD\n    case (\"phasespace\")\n       i = D_PHASESPACE\n    case (\"mismatch\")\n       i = D_MISMATCH\n    case (\"me_methods\")\n       i = D_ME_METHODS\n    case (\"process_integration\")\n       i = D_PROCESS_INTEGRATION\n    case (\"tauola\")\n       i = D_TAUOLA\n    case (\"core\")\n       i = D_CORE\n    case (\"vamp2\")\n       i = D_VAMP2\n    case (\"mpi\")\n       i = D_MPI\n    case (\"qft\")\n       i = D_QFT\n    case (\"beams\")\n       i = D_BEAMS\n    case (\"real\")\n       i = D_REAL\n    case (\"all\")\n       i = D_ALL\n    case default\n       print \"(A)\", \"Possible values for --debug are:\"\n       do i = 0, D_LAST\n          print \"(A)\", char ('  ' // d_area_to_string(i))\n       end do\n       call msg_fatal (\"Please use one of the listed areas\")\n    end select\n  end function d_area_of_string\n\n  elemental function d_area_to_string (i) result (string)\n    type(string_t) :: string\n    integer, intent(in) :: i\n    select case (i)\n    case (D_PARTICLES)\n       string = \"particles\"\n    case (D_EVENTS)\n       string = \"events\"\n    case (D_SHOWER)\n       string = \"shower\"\n    case (D_MODEL_F)\n       string = \"model_features\"\n    case (D_MATCHING)\n       string = \"matching\"\n    case (D_TRANSFORMS)\n       string = \"transforms\"\n    case (D_SUBTRACTION)\n       string = \"subtraction\"\n    case (D_VIRTUAL)\n       string = \"virtual\"\n    case (D_THRESHOLD)\n       string = \"threshold\"\n    case (D_PHASESPACE)\n       string = \"phasespace\"\n    case (D_MISMATCH)\n       string = \"mismatch\"\n    case (D_ME_METHODS)\n       string = \"me_methods\"\n    case (D_PROCESS_INTEGRATION)\n       string = \"process_integration\"\n    case (D_TAUOLA)\n       string = \"tauola\"\n    case (D_CORE)\n       string = \"core\"\n    case (D_VAMP2)\n       string = \"vamp2\"\n    case (D_MPI)\n       string = \"mpi\"\n    case (D_QFT)\n       string = \"qft\"\n    case (D_BEAMS)\n       string = \"beams\"\n    case (D_REAL)\n       string = \"real\"\n    case (D_ALL)\n       string = \"all\"\n    case default\n       string = \"undefined\"\n    end select\n  end function d_area_to_string\n\n@ %def d_area\n@\n<<Diagnostics: public>>=\n  public :: D_PARTICLES, D_EVENTS, D_SHOWER, D_MODEL_F, &\n       D_MATCHING, D_TRANSFORMS, D_SUBTRACTION, D_VIRTUAL, D_THRESHOLD, &\n       D_PHASESPACE, D_MISMATCH, D_ME_METHODS, D_PROCESS_INTEGRATION, &\n       D_TAUOLA, D_CORE, D_VAMP2, D_MPI, D_QFT, D_BEAMS, D_REAL\n<<Diagnostics: parameters>>=\n  integer, parameter :: D_ALL=0, D_PARTICLES=1, D_EVENTS=2, &\n       D_SHOWER=3, D_MODEL_F=4, &\n       D_MATCHING=5, D_TRANSFORMS=6, &\n       D_SUBTRACTION=7, D_VIRTUAL=8, D_THRESHOLD=9, D_PHASESPACE=10, &\n       D_MISMATCH=11, D_ME_METHODS=12, D_PROCESS_INTEGRATION=13, &\n       D_TAUOLA=14, D_CORE=15, D_VAMP2 = 16, D_MPI = 17, D_QFT = 18, &\n       D_BEAMS=19, D_REAL=20, D_LAST=20\n@ %def D_ALL D_PARTICLES D_EVENTS\n@ %def D_SHOWER D_MODEL_F D_MATCHING D_TRANSFORMS\n@ %def D_SUBTRACTION D_VIRTUAL D_THRESHOLD D_PHASESPACE\n@ %def D_MISMATCH D_ME_METHODS D_PROCESS_INTEGRATION\n@ %def D_TAUOLA D_CORE D_VAMP2 D_MPI D_QFT\n@\n<<Diagnostics: public>>=\n  public :: msg_level\n<<Diagnostics: variables>>=\n  integer, save, dimension(D_ALL:D_LAST) :: msg_level = RESULT\n@ %def msg_level\n@\n<<Diagnostics: parameters>>=\n  integer, parameter, public :: COL_UNDEFINED = -1\n  integer, parameter, public :: COL_GREY = 90, COL_PEACH = 91, COL_LIGHT_GREEN = 92, &\n     COL_LIGHT_YELLOW = 93, COL_LIGHT_BLUE = 94, COL_PINK = 95, &\n     COL_LIGHT_AQUA = 96, COL_PEARL_WHITE = 97, COL_BLACK = 30, &\n     COL_RED = 31, COL_GREEN = 32, COL_YELLOW = 33, COL_BLUE = 34, &\n     COL_PURPLE = 35, COL_AQUA = 36\n\n@ %def COLORS\n@\n<<Diagnostics: public>>=\n  public :: set_debug_levels\n<<Diagnostics: procedures>>=\n  subroutine set_debug_levels (area_str)\n    type(string_t), intent(in) :: area_str\n    integer :: area\n    if (.not. debug_on)  call msg_fatal (\"Debugging options &\n         &can be used only if configured with --enable-fc-debug\")\n    area = d_area (area_str)\n    if (area == D_ALL) then\n       msg_level = DEBUG\n    else\n       msg_level(area) = DEBUG\n    end if\n  end subroutine set_debug_levels\n\n@ %def set_debug_levels\n@\n<<Diagnostics: public>>=\n  public :: set_debug2_levels\n<<Diagnostics: procedures>>=\n  subroutine set_debug2_levels (area_str)\n    type(string_t), intent(in) :: area_str\n    integer :: area\n    if (.not. debug_on)  call msg_fatal (\"Debugging options &\n         &can be used only if configured with --enable-fc-debug\")\n    area = d_area (area_str)\n    if (area == D_ALL) then\n       msg_level = DEBUG2\n    else\n       msg_level(area) = DEBUG2\n    end if\n  end subroutine set_debug2_levels\n\n@ %def set_debug2_levels\n@\n<<Diagnostics: types>>=\n  type :: terminal_color_t\n     integer :: color = COL_UNDEFINED\n  contains\n  <<Diagnostics: terminal color: TBP>>\n  end type terminal_color_t\n\n@ %def terminal_color_t\n@\n<<Diagnostics: public>>=\n  public :: term_col\n<<Diagnostics: interfaces>>=\n  interface term_col\n     module procedure term_col_int\n     module procedure term_col_char\n  end interface term_col\n\n@ %def term_col\n@\n<<Diagnostics: procedures>>=\n  function term_col_int (col_int) result (color)\n    type(terminal_color_t) :: color\n    integer, intent(in) :: col_int\n    color%color = col_int\n  end function term_col_int\n\n  function term_col_char (col_char) result (color)\n    type(terminal_color_t) :: color\n    character(len=*), intent(in) :: col_char\n    type(string_t) :: buf\n    select case (col_char)\n    case ('Grey')\n       color%color = COL_GREY\n    case ('Peach')\n       color%color = COL_PEACH\n    case ('Light Green')\n       color%color = COL_LIGHT_GREEN\n    case ('Light Yellow')\n       color%color = COL_LIGHT_YELLOW\n    case ('Light Blue')\n       color%color = COL_LIGHT_BLUE\n    case ('Pink')\n       color%color = COL_PINK\n    case ('Light Aqua')\n       color%color = COL_LIGHT_AQUA\n    case ('Pearl White')\n       color%color = COL_PEARL_WHITE\n    case ('Black')\n       color%color = COL_BLACK\n    case ('Red')\n       color%color = COL_RED\n    case ('Green')\n       color%color = COL_GREEN\n    case ('Yellow')\n       color%color = COL_YELLOW\n    case ('Blue')\n       color%color = COL_BLUE\n    case ('Purple')\n       color%color = COL_PURPLE\n    case ('Aqua')\n       color%color = COL_AQUA\n    case default\n       buf = var_str ('Color ') // var_str (col_char) // var_str (' is not defined')\n       call msg_warning (char (buf))\n       color%color = COL_UNDEFINED\n    end select\n  end function term_col_char\n@\nMask fatal errors so that are treated as normal errors.  Useful for\ninteractive mode.\n<<Diagnostics: public>>=\n  public :: mask_fatal_errors\n<<Diagnostics: variables>>=\n  logical, save :: mask_fatal_errors = .false.\n@ %def mask_fatal_errors\n@\nHow to handle bugs and unmasked fatal errors.  Either execute a normal\nstop statement, or call the C [[exit()]] function, or try to cause a\nprogram crash by dereferencing a null pointer.\n\nThese procedures are appended to the [[diagnostics]] source code, but\nnot as module procedures but as external procedures.  This avoids a\ncircular module dependency across source directories.\n<<Diagnostics: parameters>>=\n  integer, parameter, public :: TERM_STOP = 0, TERM_EXIT = 1, TERM_CRASH = 2\n@ %def TERM_STOP TERM_EXIT TERM_CRASH\n<<Diagnostics: public>>=\n  public :: handle_fatal_errors\n<<Diagnostics: variables>>=\n  integer, save :: handle_fatal_errors = TERM_EXIT\n<<Diagnostics: external procedures>>=\n  subroutine fatal_force_crash ()\n    use diagnostics, only: handle_fatal_errors, TERM_CRASH !NODEP!\n    implicit none\n    handle_fatal_errors = TERM_CRASH\n  end subroutine fatal_force_crash\n\n  subroutine fatal_force_exit ()\n    use diagnostics, only: handle_fatal_errors, TERM_EXIT !NODEP!\n    implicit none\n    handle_fatal_errors = TERM_EXIT\n  end subroutine fatal_force_exit\n\n  subroutine fatal_force_stop ()\n    use diagnostics, only: handle_fatal_errors, TERM_STOP !NODEP!\n    implicit none\n    handle_fatal_errors = TERM_STOP\n  end subroutine fatal_force_stop\n\n@ %def fatal_force_crash\n@ %def fatal_force_exit\n@ %def fatal_force_stop\n@\nKeep track of errors.  This might be used for exception handling,\nlater.  The counter is incremented only for screen messages, to avoid\ndouble counting.\n<<Diagnostics: public>>=\n  public :: msg_count\n<<Diagnostics: variables>>=\n  integer, dimension(TERMINATE:WARNING), save :: msg_count = 0\n@ %def msg_count\n@ Keep a list of all errors and warnings.  Since we do not know the number of\nentries beforehand, we use a linked list.\n<<Diagnostics: types>>=\n  type :: string_list\n     character(len=BUFFER_SIZE) :: string\n     type(string_list), pointer :: next\n  end type string_list\n  type :: string_list_pointer\n     type(string_list), pointer :: first, last\n  end type string_list_pointer\n\n@ %def string_list string_list_pointer\n<<Diagnostics: variables>>=\n  type(string_list_pointer), dimension(TERMINATE:WARNING), save :: &\n       & msg_list = string_list_pointer (null(), null())\n@ %def msg_list\n@ Create a format string indicating color\n\n@ Add the current message buffer contents to the internal list.\n<<Diagnostics: procedures>>=\n  subroutine msg_add (level)\n    integer, intent(in) :: level\n    type(string_list), pointer :: message\n    select case (level)\n    case (TERMINATE:WARNING)\n       allocate (message)\n       message%string = msg_buffer\n       nullify (message%next)\n       if (.not.associated (msg_list(level)%first)) &\n            & msg_list(level)%first => message\n       if (associated (msg_list(level)%last)) &\n            & msg_list(level)%last%next => message\n       msg_list(level)%last => message\n       msg_count(level) = msg_count(level) + 1\n    end select\n  end subroutine msg_add\n\n@ %def msg_add\n@\nInitialization:\n<<Diagnostics: public>>=\n  public :: msg_list_clear\n<<Diagnostics: procedures>>=\n  subroutine msg_list_clear\n    integer :: level\n    type(string_list), pointer :: message\n    do level = TERMINATE, WARNING\n       do while (associated (msg_list(level)%first))\n          message => msg_list(level)%first\n          msg_list(level)%first => message%next\n          deallocate (message)\n       end do\n       nullify (msg_list(level)%last)\n    end do\n    msg_count = 0\n  end subroutine msg_list_clear\n\n@ %def msg_list_clear\n@ Display the summary of errors and warnings (no need to count\nfatals\\ldots)\n<<Diagnostics: public>>=\n  public :: msg_summary\n<<Diagnostics: procedures>>=\n  subroutine msg_summary (unit)\n    integer, intent(in), optional :: unit\n    call expect_summary (unit)\n1   format (A,1x,I2,1x,A,I2,1x,A)\n    if (msg_count(ERROR) > 0 .and. msg_count(WARNING) > 0) then\n       write (msg_buffer, 1) \"There were\", &\n            & msg_count(ERROR), \"error(s) and  \", &\n            & msg_count(WARNING), \"warning(s).\"\n       call msg_message (unit=unit)\n    else if (msg_count(ERROR) > 0) then\n       write (msg_buffer, 1) \"There were\", &\n            & msg_count(ERROR), \"error(s) and no warnings.\"\n       call msg_message (unit=unit)\n    else if (msg_count(WARNING) > 0) then\n       write (msg_buffer, 1) \"There were no errors and  \", &\n            & msg_count(WARNING), \"warning(s).\"\n       call msg_message (unit=unit)\n    end if\n  end subroutine msg_summary\n\n@ %def msg_summary\n@ Print the list of all messages of a given level.\n<<Diagnostics: public>>=\n  public :: msg_listing\n<<Diagnostics: procedures>>=\n  subroutine msg_listing (level, unit, prefix)\n    integer, intent(in) :: level\n    integer, intent(in), optional :: unit\n    character(len=*), intent(in), optional :: prefix\n    type(string_list), pointer :: message\n    integer :: u\n    u = given_output_unit (unit);  if (u < 0)  return\n    if (present (unit))  u = unit\n    message => msg_list(level)%first\n    do while (associated (message))\n       if (present (prefix)) then\n          write (u, \"(A)\") prefix // trim (message%string)\n       else\n          write (u, \"(A)\") trim (message%string)\n       end if\n       message => message%next\n    end do\n    flush (u)\n  end subroutine msg_listing\n\n@ %def msg_listing\n@ The message buffer:\n<<Diagnostics: public>>=\n  public :: msg_buffer\n<<Diagnostics: variables>>=\n  character(len=BUFFER_SIZE), save :: msg_buffer = \" \"\n@ %def msg_buffer\n@\nAfter a message is issued, the buffer should be cleared:\n<<Diagnostics: procedures>>=\n  subroutine buffer_clear\n    msg_buffer = \" \"\n  end subroutine buffer_clear\n\n@ %def buffer_clear\n<<Diagnostics: public>>=\n  public :: create_col_string\n<<Diagnostics: procedures>>=\n  function create_col_string (color) result (col_string)\n     type(string_t) :: col_string\n     integer, intent(in) :: color\n     character(2) :: buf\n     write (buf, '(I2)') color\n     col_string = var_str (\"[\") // var_str (buf) // var_str (\"m\")\n  end function create_col_string\n\n@ %def create_col_string\n@ The generic handler for messages.  If the unit is omitted (or $=6$), the\nmessage is written to standard output if the precedence if\nsufficiently high (as determined by the value of\n[[msg_level]]).  If the string is omitted, the buffer is used.\nIn any case, the buffer is cleared after printing.  In accordance with\nFORTRAN custom, the first column in the output is left blank.  For\nmessages and warnings, an additional exclamation mark and a blank is\nprepended.  Furthermore, each message is appended to the internal\nmessage list (without prepending anything).\n<<Diagnostics: procedures>>=\n  subroutine message_print (level, string, str_arr, unit, logfile, area, color)\n    integer, intent(in) :: level\n    character(len=*), intent(in), optional :: string\n    type(string_t), dimension(:), intent(in), optional :: str_arr\n    integer, intent(in), optional :: unit\n    logical, intent(in), optional :: logfile\n    integer, intent(in), optional :: area\n    integer, intent(in), optional :: color\n    type(string_t) :: col_string, prep_string, aux_string, head_footer, app_string\n    integer :: lu, i, ar\n    logical :: severe, is_error\n    ar = D_ALL; if (present (area))  ar = area\n    severe = .false.\n    head_footer  = \"******************************************************************************\"\n    aux_string = \"\"\n    is_error = .false.\n    app_string = \"\"\n    select case (level)\n    case (TERMINATE)\n       prep_string = \"\"\n    case (BUG)\n       prep_string   = \"*** WHIZARD BUG: \"\n       aux_string    = \"***              \"\n       severe = .true.\n       is_error = .true.\n    case (FATAL)\n       prep_string   = \"*** FATAL ERROR: \"\n       aux_string    = \"***              \"\n       severe = .true.\n       is_error = .true.\n    case (ERROR)\n       prep_string = \"*** ERROR: \"\n       aux_string  = \"***        \"\n       is_error = .true.\n    case (WARNING)\n       prep_string = \"Warning: \"\n    case (MESSAGE)\n       prep_string = \"| \"\n    case (DEBUG, DEBUG2)\n       prep_string = \"D: \"\n    case default\n       prep_string = \"\"\n    end select\n    if (present (color)) then\n       if (color > COL_UNDEFINED) then\n          col_string = create_col_string (color)\n          prep_string = achar(27) // col_string // prep_string\n          app_string = app_string // achar(27) // \"[0m\"\n       end if\n    end if\n    if (present(string))  msg_buffer = string\n    lu = log_unit\n    if (present(unit)) then\n       if (unit /= output_unit) then\n          if (severe) write (unit, \"(A)\") char(head_footer)\n          if (is_error) write (unit, \"(A)\") char(head_footer)\n          write (unit, \"(A,A,A)\") char(prep_string), trim(msg_buffer), &\n               char(app_string)\n          if (present (str_arr)) then\n             do i = 1, size(str_arr)\n                write (unit, \"(A,A)\") char(aux_string), char(trim(str_arr(i)))\n             end do\n          end if\n          if (is_error) write (unit, \"(A)\") char(head_footer)\n          if (severe) write (unit, \"(A)\") char(head_footer)\n          flush (unit)\n          lu = -1\n       else if (level <= msg_level(ar)) then\n          if (severe) print \"(A)\", char(head_footer)\n          if (is_error) print \"(A)\", char(head_footer)\n          print \"(A,A,A)\", char(prep_string), trim(msg_buffer), &\n               char(app_string)\n          if (present (str_arr)) then\n             do i = 1, size(str_arr)\n                print \"(A,A)\", char(aux_string), char(trim(str_arr(i)))\n             end do\n          end if\n          if (is_error) print \"(A)\", char(head_footer)\n          if (severe) print \"(A)\", char(head_footer)\n          flush (output_unit)\n          if (unit == log_unit)  lu = -1\n       end if\n    else if (level <= msg_level(ar)) then\n       if (severe) print \"(A)\", char(head_footer)\n       if (is_error) print \"(A)\", char(head_footer)\n       print \"(A,A,A)\", char(prep_string), trim(msg_buffer), &\n               char(app_string)\n          if (present (str_arr)) then\n             do i = 1, size(str_arr)\n                print \"(A,A)\", char(aux_string), char(trim(str_arr(i)))\n             end do\n          end if\n       if (is_error) print \"(A)\", char(head_footer)\n       if (severe) print \"(A)\", char(head_footer)\n       flush (output_unit)\n    end if\n    if (present (logfile)) then\n       if (.not. logfile)  lu = -1\n    end if\n    if (logging .and. lu >= 0) then\n       if (severe) write (lu, \"(A)\") char(head_footer)\n       if (is_error) write (lu, \"(A)\") char(head_footer)\n       write (lu, \"(A,A,A)\")  char(prep_string), trim(msg_buffer), &\n               char(app_string)\n       if (present (str_arr)) then\n          do i = 1, size(str_arr)\n             write (lu, \"(A,A)\") char(aux_string), char(trim(str_arr(i)))\n          end do\n       end if\n       if (is_error) write (lu, \"(A)\") char(head_footer)\n       if (severe) write (lu, \"(A)\") char(head_footer)\n       flush (lu)\n    end if\n    call msg_add (level)\n    call buffer_clear\n  end subroutine message_print\n\n@ %def message_print\n@\nThe number of non-fatal errors that we allow before stopping the\nprogram.  We might trade this later for an adjustable number.\n<<System defs: public parameters>>=\n  integer, parameter, public :: MAX_ERRORS = 10\n@ %def MAX_ERRORS\n@ The specific handlers.  In the case of fatal errors, bugs (failed\nassertions) and normal termination execution is stopped.  For\nnon-fatal errors a message is printed to standard output if no unit is\ngiven.  Only if the number of [[MAX_ERRORS]] errors is reached, we\nabort the program.  There are no further actions in the other cases,\nbut this may change.\n<<Diagnostics: public>>=\n  public :: msg_terminate\n  public :: msg_bug, msg_fatal, msg_error, msg_warning\n  public :: msg_message, msg_result\n<<Diagnostics: procedures>>=\n  subroutine msg_terminate (string, unit, quit_code)\n    integer, intent(in), optional :: unit\n    character(len=*), intent(in), optional :: string\n    integer, intent(in), optional :: quit_code\n    integer(c_int) :: return_code\n    call release_term_signals ()\n    if (present (quit_code)) then\n       return_code = quit_code\n    else\n       return_code = 0\n    end if\n    if (present (string)) &\n         call message_print (MESSAGE, string, unit=unit)\n    call msg_summary (unit)\n    if (return_code == 0 .and. expect_failures /= 0) then\n       return_code = 5\n       call message_print (MESSAGE, &\n            \"WHIZARD run finished with 'expect' failure(s).\", unit=unit)\n    else if (return_code == 7) then\n       call message_print (MESSAGE, &\n            \"WHIZARD run finished with failed self-test.\", unit=unit)\n    else\n       call message_print (MESSAGE, \"WHIZARD run finished.\", unit=unit)\n    end if\n    call message_print (0, &\n         \"|=============================================================================|\", unit=unit)\n    call logfile_final ()\n    call msg_list_clear ()\n    if (return_code /= 0) then\n       call exit (return_code)\n    else\n       !!! Should implement WHIZARD exit code (currently only via C)\n       call exit (0)\n    end if\n  end subroutine msg_terminate\n\n  subroutine msg_bug (string, arr, unit)\n    integer, intent(in), optional :: unit\n    character(len=*), intent(in), optional :: string\n    type(string_t), dimension(:), intent(in), optional :: arr\n    logical, pointer :: crash_ptr\n    call message_print (BUG, string, arr, unit)\n    call msg_summary (unit)\n    select case (handle_fatal_errors)\n    case (TERM_EXIT)\n       call message_print (TERMINATE, \"WHIZARD run aborted.\", unit=unit)\n       call exit (-1_c_int)\n    case (TERM_CRASH)\n       print *, \"*** Intentional crash ***\"\n       crash_ptr => null ()\n       print *, crash_ptr\n    end select\n    stop \"WHIZARD run aborted.\"\n  end subroutine msg_bug\n\n  recursive subroutine msg_fatal (string, arr, unit)\n    integer, intent(in), optional :: unit\n    character(len=*), intent(in), optional :: string\n    type(string_t), dimension(:), intent(in), optional :: arr\n    logical, pointer :: crash_ptr\n    if (mask_fatal_errors) then\n       call msg_error (string, arr, unit)\n    else\n       call message_print (FATAL, string, arr, unit)\n       call msg_summary (unit)\n       select case (handle_fatal_errors)\n       case (TERM_EXIT)\n          call message_print (TERMINATE, \"WHIZARD run aborted.\", unit=unit)\n          call exit (1_c_int)\n       case (TERM_CRASH)\n          print *, \"*** Intentional crash ***\"\n          crash_ptr => null ()\n          print *, crash_ptr\n       end select\n       stop \"WHIZARD run aborted.\"\n    end if\n  end subroutine msg_fatal\n\n  subroutine msg_error (string, arr, unit)\n    integer, intent(in), optional :: unit\n    character(len=*), intent(in), optional :: string\n    type(string_t), dimension(:), intent(in), optional :: arr\n    call message_print (ERROR, string, arr, unit)\n    if (msg_count(ERROR) >= MAX_ERRORS) then\n       mask_fatal_errors = .false.\n       call msg_fatal (\" Too many errors encountered.\")\n    else if (.not.present(unit) .and. .not.mask_fatal_errors)  then\n       call message_print (MESSAGE, \"            (WHIZARD run continues)\")\n    end if\n  end subroutine msg_error\n\n  subroutine msg_warning (string, arr, unit, color)\n    integer, intent(in), optional :: unit\n    character(len=*), intent(in), optional :: string\n    type(string_t), dimension(:), intent(in), optional :: arr\n    type(terminal_color_t), intent(in), optional :: color\n    integer :: cl\n    cl = COL_UNDEFINED; if (present (color)) cl = color%color\n    call message_print (level = WARNING, string = string, &\n       str_arr = arr, unit = unit, color = cl)\n  end subroutine msg_warning\n\n  subroutine msg_message (string, unit, arr, logfile, color)\n    integer, intent(in), optional :: unit\n    character(len=*), intent(in), optional :: string\n    type(string_t), dimension(:), intent(in), optional :: arr\n    logical, intent(in), optional :: logfile\n    type(terminal_color_t), intent(in), optional :: color\n    integer :: cl\n    cl = COL_UNDEFINED; if (present (color)) cl = color%color\n    call message_print (level = MESSAGE, &\n       string = string, str_arr = arr, unit = unit, &\n       logfile = logfile, color = cl)\n  end subroutine msg_message\n\n  subroutine msg_result (string, arr, unit, logfile, color)\n    integer, intent(in), optional :: unit\n    character(len=*), intent(in), optional :: string\n    type(string_t), dimension(:), intent(in), optional :: arr\n    logical, intent(in), optional :: logfile\n    type(terminal_color_t), intent(in), optional :: color\n    integer :: cl\n    cl = COL_UNDEFINED; if (present (color)) cl = color%color\n    call message_print (level = RESULT, string = string, &\n       str_arr = arr, unit = unit, logfile = logfile, color = cl)\n  end subroutine msg_result\n\n@ %def msg_warning msg_message msg_result\n@ Debugging aids.  Print messages or values of various kinds.  All\nversions ultimately call [[msg_debug_none]], which in turn uses\n[[message_print]].\n\nSafeguard: force crash if a routine (i.e., a debugging routine below)\nis called while the master switch [[debug_on]] is unset.  Such calls\nshould always be hidden behind [[if (debug_on)]], since they can\nsignificantly slow down the program.\n<<debug guard>>=\nif (.not. debug_on)  call msg_bug (\"msg_debug called with debug_on=.false.\")\n@\nThe [[debug_on]] flag is provided by the [[debug_master]] module, and\nwe can assume that it is a compile-time parameter.\n<<Diagnostics: public>>=\n  public :: msg_debug\n<<Diagnostics: interfaces>>=\n  interface msg_debug\n     module procedure msg_debug_none\n     module procedure msg_debug_logical\n     module procedure msg_debug_integer\n     module procedure msg_debug_real\n     module procedure msg_debug_complex\n     module procedure msg_debug_string\n  end interface\n<<Diagnostics: procedures>>=\n  subroutine msg_debug_none (area, string, color)\n    integer, intent(in) :: area\n    character(len=*), intent(in), optional :: string\n    type(terminal_color_t), intent(in), optional :: color\n    integer :: cl\n    if (debug_active (area)) then\n       cl = COL_BLUE; if (present (color)) cl = color%color\n       call message_print (DEBUG, string, unit = output_unit, &\n            area = area, logfile = .false., color = cl)\n    else\n       <<debug guard>>\n    end if\n  end subroutine msg_debug_none\n\n  subroutine msg_debug_logical (area, string, value, color)\n    logical, intent(in) :: value\n  <<msg debug implementation>>\n  end subroutine msg_debug_logical\n\n  subroutine msg_debug_integer (area, string, value, color)\n    integer, intent(in) :: value\n  <<msg debug implementation>>\n  end subroutine msg_debug_integer\n\n  subroutine msg_debug_real (area, string, value, color)\n    real(default), intent(in) :: value\n  <<msg debug implementation>>\n  end subroutine msg_debug_real\n\n  subroutine msg_debug_complex (area, string, value, color)\n    complex(default), intent(in) :: value\n  <<msg debug implementation>>\n  end subroutine msg_debug_complex\n\n  subroutine msg_debug_string (area, string, value, color)\n    type(string_t), intent(in) :: value\n    integer, intent(in) :: area\n    character(len=*), intent(in) :: string\n    type(terminal_color_t), intent(in), optional :: color\n    if (debug_active (area)) then\n       call msg_debug_none (area, string // \" = \" // char (value), &\n            color = color)\n    else\n       <<debug guard>>\n    end if\n  end subroutine msg_debug_string\n\n@ %def msg_debug\n<<msg debug implementation>>=\n  integer, intent(in) :: area\n  character(len=*), intent(in) :: string\n  type(terminal_color_t), intent(in), optional :: color\n  character(len=64) :: buffer\n  if (debug_active (area)) then\n     write (buffer, *)  value\n     call msg_debug_none (area, string // \" = \" // trim (buffer), &\n          color = color)\n  else\n     <<debug guard>>\n  end if\n@\n<<Diagnostics: public>>=\n  public :: msg_print_color\n<<Diagnostics: interfaces>>=\n  interface msg_print_color\n     module procedure msg_print_color_none\n     module procedure msg_print_color_logical\n     module procedure msg_print_color_integer\n     module procedure msg_print_color_real\n  end interface\n<<Diagnostics: procedures>>=\n  subroutine msg_print_color_none (string, color)\n    character(len=*), intent(in) :: string\n    !!!type(terminal_color_t), intent(in) :: color\n    integer, intent(in) :: color\n    call message_print (0, string, color = color)\n  end subroutine msg_print_color_none\n\n  subroutine msg_print_color_logical (string, value, color)\n    character(len=*), intent(in) :: string\n    logical, intent(in) :: value\n    integer, intent(in) :: color\n    call msg_print_color_none (char (string // \" = \" // str (value)), &\n       color = color)\n  end subroutine msg_print_color_logical\n\n  subroutine msg_print_color_integer (string, value, color)\n    character(len=*), intent(in) :: string\n    integer, intent(in) :: value\n    integer, intent(in) :: color\n    call msg_print_color_none (char (string // \" = \" // str (value)), &\n       color = color)\n  end subroutine msg_print_color_integer\n\n  subroutine msg_print_color_real (string, value, color)\n    character(len=*), intent(in) :: string\n    real(default), intent(in) :: value\n    integer, intent(in) :: color\n    call msg_print_color_none (char (string // \" = \" // str (value)), &\n       color = color)\n  end subroutine msg_print_color_real\n\n@ %def msg_print_color_none, msg_print_color_logical\n@ %def msg_print_color_integer, msg_print_color_real\n@ Secondary debugging aids which implement more fine-grained debugging.\nAgain, there is a safeguard against calling anything while\n[[debug_on=.false.]].\n<<debug2 guard>>=\nif (.not. debug_on)  call msg_bug (\"msg_debug2 called with debug_on=.false.\")\n<<Diagnostics: public>>=\n  public :: msg_debug2\n<<Diagnostics: interfaces>>=\n  interface msg_debug2\n     module procedure msg_debug2_none\n     module procedure msg_debug2_logical\n     module procedure msg_debug2_integer\n     module procedure msg_debug2_real\n     module procedure msg_debug2_complex\n     module procedure msg_debug2_string\n  end interface\n<<Diagnostics: procedures>>=\n  subroutine msg_debug2_none (area, string, color)\n    integer, intent(in) :: area\n    character(len=*), intent(in), optional :: string\n    type(terminal_color_t), intent(in), optional :: color\n    integer :: cl\n    if (debug2_active (area)) then\n       cl = COL_BLUE; if (present (color)) cl = color%color\n       call message_print (DEBUG2, string, unit = output_unit, &\n            area = area, logfile = .false., color = cl)\n    else\n       <<debug2 guard>>\n    end if\n  end subroutine msg_debug2_none\n\n  subroutine msg_debug2_logical (area, string, value, color)\n    logical, intent(in) :: value\n  <<msg debug2 implementation>>\n  end subroutine msg_debug2_logical\n\n  subroutine msg_debug2_integer (area, string, value, color)\n    integer, intent(in) :: value\n  <<msg debug2 implementation>>\n  end subroutine msg_debug2_integer\n\n  subroutine msg_debug2_real (area, string, value, color)\n    real(default), intent(in) :: value\n  <<msg debug2 implementation>>\n  end subroutine msg_debug2_real\n\n  subroutine msg_debug2_complex (area, string, value, color)\n    complex(default), intent(in) :: value\n  <<msg debug2 implementation>>\n  end subroutine msg_debug2_complex\n\n  subroutine msg_debug2_string (area, string, value, color)\n    type(string_t), intent(in) :: value\n    integer, intent(in) :: area\n    character(len=*), intent(in) :: string\n    type(terminal_color_t), intent(in), optional :: color\n    if (debug2_active (area)) then\n       call msg_debug2_none (area, string // \" = \" // char (value), &\n            color = color)\n    else\n       <<debug2 guard>>\n    end if\n  end subroutine msg_debug2_string\n\n@ %def msg_debug2\n<<msg debug2 implementation>>=\n  integer, intent(in) :: area\n  character(len=*), intent(in) :: string\n  type(terminal_color_t), intent(in), optional :: color\n  character(len=64) :: buffer\n  if (debug2_active (area)) then\n     write (buffer, *)  value\n     call msg_debug2_none (area, string // \" = \" // trim (buffer), &\n          color = color)\n  else\n     <<debug2 guard>>\n  end if\n@\n<<Diagnostics: public>>=\n  public :: debug_active\n<<Diagnostics: procedures>>=\n  elemental function debug_active (area) result (active)\n    logical :: active\n    integer, intent(in) :: area\n    active = debug_on .and. msg_level(area) >= DEBUG\n  end function debug_active\n\n@ %def debug_active\n@\n<<Diagnostics: public>>=\n  public :: debug2_active\n<<Diagnostics: procedures>>=\n  elemental function debug2_active (area) result (active)\n    logical :: active\n    integer, intent(in) :: area\n    active = debug_on .and. msg_level(area) >= DEBUG2\n  end function debug2_active\n\n@ %def debug2_active\n@ Show the progress of a loop in steps of 10 \\%.  Could be generalized\nto other step sizes with an optional argument.\n<<Diagnostics: public>>=\n  public :: msg_show_progress\n<<Diagnostics: procedures>>=\n  subroutine msg_show_progress (i_call, n_calls)\n    integer, intent(in) :: i_call, n_calls\n    real(default) :: progress\n    integer, save :: next_check\n    if (i_call == 1) next_check = 10\n    progress = (i_call * 100._default) / n_calls\n    if (progress >= next_check) then\n       write (msg_buffer, \"(F5.1,A)\") progress, \"%\"\n       call msg_message ()\n       next_check = next_check + 10\n    end if\n  end subroutine msg_show_progress\n\n@ %def msg_show_progress\n@ Interface to the standard clib exit function\n<<Diagnostics: public>>=\n  public :: exit\n<<Diagnostics: interfaces>>=\n  interface\n     subroutine exit (status) bind (C)\n       use iso_c_binding !NODEP!\n       integer(c_int), value :: status\n     end subroutine exit\n  end interface\n\n@ %def exit\n@ Print the WHIZARD banner:\n<<Diagnostics: public>>=\n  public :: msg_banner\n<<Diagnostics: procedures>>=\n  subroutine msg_banner (unit)\n    integer, intent(in), optional :: unit\n    call message_print (0, \"|=============================================================================|\", unit=unit)\n    call message_print (0, \"|                                                                             |\", unit=unit)\n    call message_print (0, \"|    WW             WW  WW   WW  WW  WWWWWW      WW      WWWWW    WWWW        |\", unit=unit)\n    call message_print (0, \"|     WW    WW     WW   WW   WW  WW     WW      WWWW     WW  WW   WW  WW      |\", unit=unit)\n    call message_print (0, \"|      WW  WW WW  WW    WWWWWWW  WW    WW      WW  WW    WWWWW    WW   WW     |\", unit=unit)\n    call message_print (0, \"|       WWWW   WWWW     WW   WW  WW   WW      WWWWWWWW   WW  WW   WW  WW      |\", unit=unit)\n    call message_print (0, \"|        WW     WW      WW   WW  WW  WWWWWW  WW      WW  WW   WW  WWWW        |\", unit=unit)\n    call message_print (0, \"|                                                                             |\", unit=unit)\n    call message_print (0, \"|                                                                             |\", unit=unit)\n    call message_print (0, \"|                                        W                                    |\", unit=unit)\n    call message_print (0, \"|                                       sW                                    |\", unit=unit)\n    call message_print (0, \"|                                       WW                                    |\", unit=unit)\n    call message_print (0, \"|                                      sWW                                    |\", unit=unit)\n    call message_print (0, \"|                                      WWW                                    |\", unit=unit)\n    call message_print (0, \"|                                     wWWW                                    |\", unit=unit)\n    call message_print (0, \"|                                    wWWWW                                    |\", unit=unit)\n    call message_print (0, \"|                                    WW WW                                    |\", unit=unit)\n    call message_print (0, \"|                                    WW WW                                    |\", unit=unit)\n    call message_print (0, \"|                                   wWW WW                                    |\", unit=unit)\n    call message_print (0, \"|                                  wWW  WW                                    |\", unit=unit)\n    call message_print (0, \"|                                  WW   WW                                    |\", unit=unit)\n    call message_print (0, \"|                                  WW   WW                                    |\", unit=unit)\n    call message_print (0, \"|                                 WW    WW                                    |\", unit=unit)\n    call message_print (0, \"|                                 WW    WW                                    |\", unit=unit)\n    call message_print (0, \"|                                WW     WW                                    |\", unit=unit)\n    call message_print (0, \"|                                WW     WW                                    |\", unit=unit)\n    call message_print (0, \"|           wwwwww              WW      WW                                    |\", unit=unit)\n    call message_print (0, \"|              WWWWWww          WW      WW                                    |\", unit=unit)\n    call message_print (0, \"|                 WWWWWwwwww   WW       WW                                    |\", unit=unit)\n    call message_print (0, \"|                     wWWWwwwwwWW       WW                                    |\", unit=unit)\n    call message_print (0, \"|                 wWWWWWWWWWWwWWW       WW                                    |\", unit=unit)\n    call message_print (0, \"|                wWWWWW       wW        WWWWWWW                               |\", unit=unit)\n    call message_print (0, \"|                  WWWW       wW        WW  wWWWWWWWwww                       |\", unit=unit)\n    call message_print (0, \"|                   WWWW                      wWWWWWWWwwww                    |\", unit=unit)\n    call message_print (0, \"|                     WWWW                      WWWW     WWw                  |\", unit=unit)\n    call message_print (0, \"|                       WWWWww                   WWWW                         |\", unit=unit)\n    call message_print (0, \"|                           WWWwwww              WWWW                         |\", unit=unit)\n    call message_print (0, \"|                               wWWWWwww       wWWWWW                         |\", unit=unit)\n    call message_print (0, \"|                                     WwwwwwwwwWWW                            |\", unit=unit)\n    call message_print (0, \"|                                                                             |\", unit=unit)\n    call message_print (0, \"|                                                                             |\", unit=unit)\n    call message_print (0, \"|                                                                             |\", unit=unit)\n    call message_print (0, \"|  by:   Wolfgang Kilian, Thorsten Ohl, Juergen Reuter                        |\", unit=unit)\n    call message_print (0, \"|        with contributions from Christian Speckner                           |\", unit=unit)\n    call message_print (0, \"|        Contact: <whizard@desy.de>                                           |\", unit=unit)\n    call message_print (0, \"|                                                                             |\", unit=unit)\n    call message_print (0, \"|  if you use WHIZARD please cite:                                            |\", unit=unit)\n    call message_print (0, \"|        W. Kilian, T. Ohl, J. Reuter,  Eur.Phys.J.C71 (2011) 1742            |\", unit=unit)\n    call message_print (0, \"|                                          [arXiv: 0708.4233 [hep-ph]]        |\", unit=unit)\n    call message_print (0, \"|        M. Moretti, T. Ohl, J. Reuter, arXiv: hep-ph/0102195                 |\", unit=unit)\n    call message_print (0, \"|                                                                             |\", unit=unit)\n    call message_print (0, \"|=============================================================================|\", unit=unit)\n    call message_print (0, \"|                               WHIZARD \" // WHIZARD_VERSION, unit=unit)\n    call message_print (0, \"|=============================================================================|\", unit=unit)\n  end subroutine msg_banner\n\n@ %def msg_banner\n@\n\\subsection{Logfile}\nAll screen output should be duplicated in the logfile, unless\nrequested otherwise.\n<<Diagnostics: public>>=\n  public :: logging\n<<Diagnostics: variables>>=\n  integer, save :: log_unit = -1\n  logical, target, save :: logging = .false.\n<<Diagnostics: public>>=\n  public :: logfile_init\n<<Diagnostics: procedures>>=\n  subroutine logfile_init (filename)\n    type(string_t), intent(in) :: filename\n    call msg_message (\"Writing log to '\" // char (filename) // \"'\")\n    if (.not. logging)  call msg_message (\"(Logging turned off.)\")\n    log_unit = free_unit ()\n    open (file = char (filename), unit = log_unit, &\n          action = \"write\", status = \"replace\")\n  end subroutine logfile_init\n\n@ %def logfile_init\n<<Diagnostics: public>>=\n  public :: logfile_final\n<<Diagnostics: procedures>>=\n  subroutine logfile_final ()\n    if (log_unit >= 0) then\n       close (log_unit)\n       log_unit = -1\n    end if\n  end subroutine logfile_final\n\n@ %def logfile_final\n@ This returns the valid logfile unit only if the default is write to\nscreen, and if [[logfile]] is not set false.\n<<Diagnostics: public>>=\n  public :: logfile_unit\n<<Diagnostics: procedures>>=\n  function logfile_unit (unit, logfile)\n    integer :: logfile_unit\n    integer, intent(in), optional :: unit\n    logical, intent(in), optional :: logfile\n    if (logging) then\n       if (present (unit)) then\n          if (unit == output_unit) then\n             logfile_unit = log_unit\n          else\n             logfile_unit = -1\n          end if\n       else if (present (logfile)) then\n          if (logfile) then\n             logfile_unit = log_unit\n          else\n             logfile_unit = -1\n          end if\n       else\n          logfile_unit = log_unit\n       end if\n    else\n       logfile_unit = -1\n    end if\n  end function logfile_unit\n\n@ %def logfile_unit\n@\n\\subsection{Checking values}\nThe [[expect]] function does not just check a value for correctness\n(actually, it checks if a logical expression is true); it records its\nresult here.  If failures are present when the program terminates, the\nexit code is nonzero.\n<<Diagnostics: variables>>=\n  integer, save :: expect_total = 0\n  integer, save :: expect_failures = 0\n\n@ %def expect_total expect_failures\n<<Diagnostics: public>>=\n  public :: expect_record\n<<Diagnostics: procedures>>=\n  subroutine expect_record (success)\n    logical, intent(in) :: success\n    expect_total = expect_total + 1\n    if (.not. success)  expect_failures = expect_failures + 1\n  end subroutine expect_record\n\n@ %def expect_record\n<<Diagnostics: public>>=\n  public :: expect_clear\n<<Diagnostics: procedures>>=\n  subroutine expect_clear ()\n    expect_total = 0\n    expect_failures = 0\n  end subroutine expect_clear\n\n@ %def expect_clear\n<<Diagnostics: public>>=\n  public :: expect_summary\n<<Diagnostics: procedures>>=\n  subroutine expect_summary (unit, force)\n    integer, intent(in), optional :: unit\n    logical, intent(in), optional :: force\n    logical :: force_output\n    force_output = .false.;  if (present (force))  force_output = force\n    if (expect_total /= 0 .or. force_output) then\n       call msg_message (\"Summary of value checks:\", unit)\n       write (msg_buffer, \"(2x,A,1x,I0,1x,A,1x,A,1x,I0)\") &\n            \"Failures:\", expect_failures, \"/\", \"Total:\", expect_total\n       call msg_message (unit=unit)\n    end if\n  end subroutine expect_summary\n\n@ %def expect_summary\n@ Helpers for converting integers into strings with minimal length.\n<<Diagnostics: public>>=\n  public :: int2string\n  public :: int2char\n  public :: int2fixed\n<<Diagnostics: procedures>>=\n  pure function int2fixed (i) result (c)\n    integer, intent(in) :: i\n    character(200) :: c\n    c = \"\"\n    write (c, *) i\n    c = adjustl (c)\n  end function int2fixed\n\n  pure function int2string (i) result (s)\n    integer, intent(in) :: i\n    type (string_t) :: s\n    s = trim (int2fixed (i))\n  end function int2string\n\n  pure function int2char (i) result (c)\n    integer, intent(in) :: i\n    character(len (trim (int2fixed (i)))) :: c\n    c = int2fixed (i)\n  end function int2char\n\n@ %def int2fixed int2string int2char\n@ Dito for reals.\n<<Diagnostics: public>>=\n  public :: real2string\n  public :: real2char\n  public :: real2fixed\n<<Diagnostics: interfaces>>=\n  interface real2string\n     module procedure real2string_list, real2string_fmt\n  end interface\n  interface real2char\n     module procedure real2char_list, real2char_fmt\n  end interface\n<<Diagnostics: procedures>>=\n  pure function real2fixed (x, fmt) result (c)\n    real(default), intent(in) :: x\n    character(*), intent(in), optional :: fmt\n    character(200) :: c\n    c = \"\"\n    write (c, *) x\n    c = adjustl (c)\n  end function real2fixed\n\n  pure function real2fixed_fmt (x, fmt) result (c)\n    real(default), intent(in) :: x\n    character(*), intent(in) :: fmt\n    character(200) :: c\n    c = \"\"\n    write (c, fmt)  x\n    c = adjustl (c)\n  end function real2fixed_fmt\n\n  pure function real2string_list (x) result (s)\n    real(default), intent(in) :: x\n    type(string_t) :: s\n    s = trim (real2fixed (x))\n  end function real2string_list\n\n  pure function real2string_fmt (x, fmt) result (s)\n    real(default), intent(in) :: x\n    character(*), intent(in) :: fmt\n    type(string_t) :: s\n    s = trim (real2fixed_fmt (x, fmt))\n  end function real2string_fmt\n\n  pure function real2char_list (x) result (c)\n    real(default), intent(in) :: x\n    character(len_trim (real2fixed (x))) :: c\n    c = real2fixed (x)\n  end function real2char_list\n\n  pure function real2char_fmt (x, fmt) result (c)\n    real(default), intent(in) :: x\n    character(*), intent(in) :: fmt\n    character(len_trim (real2fixed_fmt (x, fmt))) :: c\n    c = real2fixed_fmt (x, fmt)\n  end function real2char_fmt\n\n@ %def real2fixed real2string real2char\n@ Dito for complex values; we do not use the slightly ugly FORTRAN output form\nhere but instead introduce our own. Ifort and Portland seem to have problems\nwith this, therefore temporarily disable it.\n%\n<<CCC Diagnostics: public>>=\n   public :: cmplx2string\n   public :: cmplx2char\n<<CCC Diagnostics: procedures>>=\n   pure function cmplx2string (x) result (s)\n     complex(default), intent(in) :: x\n     type(string_t) :: s\n     s = real2string (real (x, default))\n     if (aimag (x) /= 0) s = s // \" + \" // real2string (aimag (x)) // \" I\"\n   end function cmplx2string\n\n   pure function cmplx2char (x) result (c)\n     complex(default), intent(in) :: x\n     character(len (char (cmplx2string (x)))) :: c\n     c = char (cmplx2string (x))\n   end function cmplx2char\n\n@ %def cmplx2string cmplx2char\n@\n\\subsection{Suppression of numerical noise}\n<<Diagnostics: public>>=\n  public :: pacify\n<<Diagnostics: interfaces>>=\n  interface pacify\n     module procedure pacify_real_default\n     module procedure pacify_complex_default\n  end interface pacify\n\n@\n<<Diagnostics: procedures>>=\n  elemental subroutine pacify_real_default (x, tolerance)\n    real(default), intent(inout) :: x\n    real(default), intent(in) :: tolerance\n    if (abs (x) < tolerance)  x = 0._default\n  end subroutine pacify_real_default\n\n  elemental subroutine pacify_complex_default (x, tolerance)\n    complex(default), intent(inout) :: x\n    real(default), intent(in) :: tolerance\n    if (abs (real (x)) < tolerance)   &\n         x = cmplx (0._default, aimag (x), kind=default)\n    if (abs (aimag (x)) < tolerance)  &\n         x = cmplx (real (x), 0._default, kind=default)\n  end subroutine pacify_complex_default\n\n@ %def pacify\n@\n\\subsection{Signal handling}\nKilling the program by external signals may leave the files written by it in\nan undefined state.  This can be avoided by catching signals and deferring\nprogram termination.  Instead of masking only critical sections, we choose\nto mask signals globally (done in the main program) and terminate the program\nat predefined checkpoints only.  Checkpoints are after each command, within\nthe sampling function (so the program can be terminated after each event),\nand after each iteration in the phase-space generation algorithm.\n\nSignal handling is done via a C interface to the [[sigaction]] system call.\nWhen a signal is raised that has been masked by the handler, the corresponding\nvariable is set to the value of the signal.  The variables are visible from\nthe C signal handler.\n\nThe signal SIGINT is for keyboard interrupt (ctrl-C), SIGTERM is for system\ninterrupt, e.g., at shutdown.  The SIGXCPU and SIGXFSZ signals may be issued\nby batch systems.\n<<Diagnostics: public>>=\n  public :: wo_sigint\n  public :: wo_sigterm\n  public :: wo_sigxcpu\n  public :: wo_sigxfsz\n\n<<Diagnostics: variables>>=\n  integer(c_int), bind(C), volatile :: wo_sigint = 0\n  integer(c_int), bind(C), volatile :: wo_sigterm = 0\n  integer(c_int), bind(C), volatile :: wo_sigxcpu = 0\n  integer(c_int), bind(C), volatile :: wo_sigxfsz = 0\n\n@ %def wo_sigint wo_sigterm wo_sigxcpu wo_sigxfsz\n@ Here are the interfaces to the C functions.  The routine\n[[mask_term_signals]] forces termination signals to be delayed.\n[[release_term_signals]] restores normal behavior.  However, the program can be\nterminated anytime by calling [[terminate_now_if_signal]] which inspects the\nsignals and terminates the program if requested..\n<<Diagnostics: public>>=\n  public :: mask_term_signals\n<<Diagnostics: procedures>>=\n  subroutine mask_term_signals ()\n    logical :: ok\n    wo_sigint = 0\n    ok = wo_mask_sigint () == 0\n    if (.not. ok)  call msg_error (\"Masking SIGINT failed\")\n    wo_sigterm = 0\n    ok = wo_mask_sigterm () == 0\n    if (.not. ok)  call msg_error (\"Masking SIGTERM failed\")\n    wo_sigxcpu = 0\n    ok = wo_mask_sigxcpu () == 0\n    if (.not. ok)  call msg_error (\"Masking SIGXCPU failed\")\n    wo_sigxfsz = 0\n    ok = wo_mask_sigxfsz () == 0\n    if (.not. ok)  call msg_error (\"Masking SIGXFSZ failed\")\n  end subroutine mask_term_signals\n\n@ %def mask_term_signals\n<<Diagnostics: interfaces>>=\n  interface\n     integer(c_int) function wo_mask_sigint () bind(C)\n       import\n     end function wo_mask_sigint\n  end interface\n  interface\n     integer(c_int) function wo_mask_sigterm () bind(C)\n       import\n     end function wo_mask_sigterm\n  end interface\n  interface\n     integer(c_int) function wo_mask_sigxcpu () bind(C)\n       import\n     end function wo_mask_sigxcpu\n  end interface\n  interface\n     integer(c_int) function wo_mask_sigxfsz () bind(C)\n       import\n     end function wo_mask_sigxfsz\n  end interface\n\n@ %def wo_mask_sigint wo_mask_sigterm wo_mask_sigxcpu wo_mask_sigxfsz\n<<Diagnostics: public>>=\n  public :: release_term_signals\n<<Diagnostics: procedures>>=\n  subroutine release_term_signals ()\n    logical :: ok\n    ok = wo_release_sigint () == 0\n    if (.not. ok)  call msg_error (\"Releasing SIGINT failed\")\n    ok = wo_release_sigterm () == 0\n    if (.not. ok)  call msg_error (\"Releasing SIGTERM failed\")\n    ok = wo_release_sigxcpu () == 0\n    if (.not. ok)  call msg_error (\"Releasing SIGXCPU failed\")\n    ok = wo_release_sigxfsz () == 0\n    if (.not. ok)  call msg_error (\"Releasing SIGXFSZ failed\")\n  end subroutine release_term_signals\n\n@ %def release_term_signals\n<<Diagnostics: interfaces>>=\n  interface\n     integer(c_int) function wo_release_sigint () bind(C)\n       import\n     end function wo_release_sigint\n  end interface\n  interface\n     integer(c_int) function wo_release_sigterm () bind(C)\n       import\n     end function wo_release_sigterm\n  end interface\n  interface\n     integer(c_int) function wo_release_sigxcpu () bind(C)\n       import\n     end function wo_release_sigxcpu\n  end interface\n  interface\n     integer(c_int) function wo_release_sigxfsz () bind(C)\n       import\n     end function wo_release_sigxfsz\n  end interface\n\n@ %def wo_release_sigint wo_release_sigterm\n@ %def wo_release_sigxcpu wo_release_sigxfsz\n<<Diagnostics: public>>=\n  public :: signal_is_pending\n<<Diagnostics: procedures>>=\n  function signal_is_pending () result (flag)\n    logical :: flag\n    flag = &\n         wo_sigint /= 0 .or. &\n         wo_sigterm /= 0 .or. &\n         wo_sigxcpu /= 0 .or. &\n         wo_sigxfsz /= 0\n  end function signal_is_pending\n\n@ %def signal_is_pending\n<<Diagnostics: public>>=\n  public :: terminate_now_if_signal\n<<Diagnostics: procedures>>=\n  subroutine terminate_now_if_signal ()\n    if (wo_sigint /= 0) then\n       call msg_terminate (\"Signal SIGINT (keyboard interrupt) received.\", &\n          quit_code=int (wo_sigint))\n    else if (wo_sigterm /= 0) then\n       call msg_terminate (\"Signal SIGTERM (termination signal) received.\", &\n          quit_code=int (wo_sigterm))\n    else if (wo_sigxcpu /= 0) then\n       call msg_terminate (\"Signal SIGXCPU (CPU time limit exceeded) received.\", &\n          quit_code=int (wo_sigxcpu))\n    else if (wo_sigxfsz /= 0) then\n       call msg_terminate (\"Signal SIGXFSZ (file size limit exceeded) received.\", &\n          quit_code=int (wo_sigxfsz))\n    end if\n  end subroutine terminate_now_if_signal\n\n@ %def terminate_now_if_signal\n@\n<<Diagnostics: public>>=\n  public :: single_event\n<<Diagnostics: variables>>=\n  logical :: single_event = .false.\n@\n<<Diagnostics: public>>=\n  public :: terminate_now_if_single_event\n<<Diagnostics: procedures>>=\n  subroutine terminate_now_if_single_event ()\n    integer, save :: n_calls = 0\n    n_calls = n_calls + 1\n    if (single_event .and. n_calls > 1) then\n       call msg_terminate (\"Stopping after one event\", quit_code=0)\n    end if\n  end subroutine terminate_now_if_single_event\n\n@ %def terminate_now_if_single_event\n@\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\\section{Operating-system interface}\nFor specific purposes, we need direct access to the OS (system\ncalls).  This is, of course, system dependent.  The current version is\nvalid for GNU/Linux; we expect to use a preprocessor for this module\nif different OSs are to be supported.\n\nThe current implementation lacks error handling.\n<<[[os_interface.f90]]>>=\n<<File header>>\n\nmodule os_interface\n\n  use, intrinsic :: iso_c_binding !NODEP!\n\n<<Use strings>>\n  use io_units\n  use diagnostics\n  use system_defs, only: DLERROR_LEN, ENVVAR_LEN\n  use system_dependencies\n\n<<Use mpi f08>>\n\n<<Standard module head>>\n\n<<OS interface: public>>\n\n<<OS interface: types>>\n\n<<OS interface: interfaces>>\n\ncontains\n\n<<OS interface: procedures>>\n\nend module os_interface\n@ %def os_interface\n@\n\\subsection{Path variables}\nThis is a transparent container for storing user-defined path variables.\n<<OS interface: public>>=\n  public :: paths_t\n<<OS interface: types>>=\n  type :: paths_t\n     type(string_t) :: prefix\n     type(string_t) :: exec_prefix\n     type(string_t) :: bindir\n     type(string_t) :: libdir\n     type(string_t) :: includedir\n     type(string_t) :: datarootdir\n     type(string_t) :: localprefix\n     type(string_t) :: libtool\n     type(string_t) :: lhapdfdir\n  end type paths_t\n\n@ %def paths_t\n<<OS interface: public>>=\n  public :: paths_init\n<<OS interface: procedures>>=\n  subroutine paths_init (paths)\n    type(paths_t), intent(out) :: paths\n    paths%prefix = \"\"\n    paths%exec_prefix = \"\"\n    paths%bindir = \"\"\n    paths%libdir = \"\"\n    paths%includedir = \"\"\n    paths%datarootdir = \"\"\n    paths%localprefix = \"\"\n    paths%libtool = \"\"\n    paths%lhapdfdir = \"\"\n  end subroutine paths_init\n\n@ %def paths_init\n@\n\\subsection{System dependencies}\nWe store all potentially system- and user/run-dependent data in a\ntransparent container.  This includes compiler/linker names and flags,\nfile extensions, etc. There are actually two different possibilities\nfor extensions of shared libraries, depending on whether the Fortran\ncompiler or the system linker (usually the C compiler) has been used\nfor linking. The default for the Fortran compiler on most systems is\n[[.so]].\n<<OS interface: public>>=\n  public :: os_data_t\n<<OS interface: types>>=\n  type :: os_data_t\n     logical :: use_libtool\n     logical :: use_testfiles\n     type(string_t) :: fc\n     type(string_t) :: fcflags\n     type(string_t) :: fcflags_pic\n     type(string_t) :: fclibs\n     type(string_t) :: fc_src_ext\n     type(string_t) :: cc\n     type(string_t) :: cflags\n     type(string_t) :: cflags_pic\n     type(string_t) :: cxx\n     type(string_t) :: cxxflags\n     type(string_t) :: cxxlibs\n     type(string_t) :: obj_ext\n     type(string_t) :: ld\n     type(string_t) :: ldflags\n     type(string_t) :: ldflags_so\n     type(string_t) :: ldflags_static\n     type(string_t) :: ldflags_hepmc\n     type(string_t) :: ldflags_lcio\n     type(string_t) :: ldflags_hoppet\n     type(string_t) :: ldflags_looptools\n     type(string_t) :: shrlib_ext\n     type(string_t) :: fc_shrlib_ext\n     type(string_t) :: pack_cmd\n     type(string_t) :: unpack_cmd\n     type(string_t) :: pack_ext\n     type(string_t) :: makeflags\n     type(string_t) :: prefix\n     type(string_t) :: exec_prefix\n     type(string_t) :: bindir\n     type(string_t) :: libdir\n     type(string_t) :: includedir\n     type(string_t) :: datarootdir\n     type(string_t) :: whizard_omega_binpath\n     type(string_t) :: whizard_includes\n     type(string_t) :: whizard_ldflags\n     type(string_t) :: whizard_libtool\n     type(string_t) :: whizard_modelpath\n     type(string_t) :: whizard_modelpath_ufo\n     type(string_t) :: whizard_models_libpath\n     type(string_t) :: whizard_susypath\n     type(string_t) :: whizard_gmlpath\n     type(string_t) :: whizard_cutspath\n     type(string_t) :: whizard_texpath\n     type(string_t) :: whizard_sharepath\n     type(string_t) :: whizard_testdatapath\n     type(string_t) :: whizard_modelpath_local\n     type(string_t) :: whizard_models_libpath_local\n     type(string_t) :: whizard_omega_binpath_local\n     type(string_t) :: whizard_circe2path\n     type(string_t) :: whizard_beamsimpath\n     type(string_t) :: whizard_mulipath\n     type(string_t) :: pdf_builtin_datapath\n     logical :: event_analysis = .false.\n     logical :: event_analysis_ps  = .false.\n     logical :: event_analysis_pdf = .false.\n     type(string_t) :: latex\n     type(string_t) :: mpost\n     type(string_t) :: gml\n     type(string_t) :: dvips\n     type(string_t) :: ps2pdf\n     type(string_t) :: gosampath\n     type(string_t) :: golempath\n     type(string_t) :: formpath\n     type(string_t) :: qgrafpath\n     type(string_t) :: ninjapath\n     type(string_t) :: samuraipath\n   contains\n   <<OS interface: os data: TBP>>\n  end type os_data_t\n\n@ %def os_data_t\n@ Since all are allocatable strings, explicit initialization is\nnecessary.\n<<System defs: public parameters>>=\n  integer, parameter, public :: ENVVAR_LEN = 1000\n@ %def ENVVAR_LEN\n<<OS interface: os data: TBP>>=\n  procedure :: init => os_data_init\n<<OS interface: procedures>>=\n  subroutine os_data_init (os_data, paths)\n    class(os_data_t), intent(out) :: os_data\n    type(paths_t), intent(in), optional :: paths\n    character(len=ENVVAR_LEN) :: home\n    type(string_t) :: localprefix, local_includes\n    os_data%use_libtool = .true.\n    inquire (file = \"TESTFLAG\", exist = os_data%use_testfiles)\n    call get_environment_variable (\"HOME\", home)\n    if (present(paths)) then\n       if (paths%localprefix == \"\") then\n          localprefix = trim (home) // \"/.whizard\"\n       else\n          localprefix = paths%localprefix\n       end if\n    else\n       localprefix = trim (home) // \"/.whizard\"\n    end if\n    local_includes = localprefix // \"/lib/whizard/mod/models\"\n    os_data%whizard_modelpath_local = localprefix // \"/share/whizard/models\"\n    os_data%whizard_models_libpath_local = localprefix // \"/lib/whizard/models\"\n    os_data%whizard_omega_binpath_local = localprefix // \"/bin\"\n    os_data%fc             = DEFAULT_FC\n    os_data%fcflags        = DEFAULT_FCFLAGS\n    os_data%fcflags_pic    = DEFAULT_FCFLAGS_PIC\n    os_data%fclibs         = FCLIBS\n    os_data%fc_src_ext     = DEFAULT_FC_SRC_EXT\n    os_data%cc             = DEFAULT_CC\n    os_data%cflags         = DEFAULT_CFLAGS\n    os_data%cflags_pic     = DEFAULT_CFLAGS_PIC\n    os_data%cxx            = DEFAULT_CXX\n    os_data%cxxflags       = DEFAULT_CXXFLAGS\n    os_data%cxxlibs        = DEFAULT_CXXLIBS\n    os_data%obj_ext        = DEFAULT_OBJ_EXT\n    os_data%ld             = DEFAULT_LD\n    os_data%ldflags        = DEFAULT_LDFLAGS\n    os_data%ldflags_so     = DEFAULT_LDFLAGS_SO\n    os_data%ldflags_static = DEFAULT_LDFLAGS_STATIC\n    os_data%ldflags_hepmc  = DEFAULT_LDFLAGS_HEPMC\n    os_data%ldflags_lcio   = DEFAULT_LDFLAGS_LCIO\n    os_data%ldflags_hoppet = DEFAULT_LDFLAGS_HOPPET\n    os_data%ldflags_looptools = DEFAULT_LDFLAGS_LOOPTOOLS\n    os_data%shrlib_ext     = DEFAULT_SHRLIB_EXT\n    os_data%fc_shrlib_ext  = DEFAULT_FC_SHRLIB_EXT\n    os_data%pack_cmd       = DEFAULT_PACK_CMD\n    os_data%unpack_cmd     = DEFAULT_UNPACK_CMD\n    os_data%pack_ext       = DEFAULT_PACK_EXT\n    os_data%makeflags      = DEFAULT_MAKEFLAGS\n    os_data%prefix      = PREFIX\n    os_data%exec_prefix = EXEC_PREFIX\n    os_data%bindir      = BINDIR\n    os_data%libdir      = LIBDIR\n    os_data%includedir  = INCLUDEDIR\n    os_data%datarootdir = DATAROOTDIR\n    if (present (paths)) then\n       if (paths%prefix      /= \"\")  os_data%prefix      = paths%prefix\n       if (paths%exec_prefix /= \"\")  os_data%exec_prefix = paths%exec_prefix\n       if (paths%bindir      /= \"\")  os_data%bindir      = paths%bindir\n       if (paths%libdir      /= \"\")  os_data%libdir      = paths%libdir\n       if (paths%includedir  /= \"\")  os_data%includedir  = paths%includedir\n       if (paths%datarootdir /= \"\")  os_data%datarootdir = paths%datarootdir\n    end if\n    if (os_data%use_testfiles) then\n       os_data%whizard_omega_binpath  = WHIZARD_TEST_OMEGA_BINPATH\n       os_data%whizard_includes       = WHIZARD_TEST_INCLUDES\n       os_data%whizard_ldflags        = WHIZARD_TEST_LDFLAGS\n       os_data%whizard_libtool        = WHIZARD_LIBTOOL_TEST\n       os_data%whizard_modelpath      = WHIZARD_TEST_MODELPATH\n       os_data%whizard_modelpath_ufo  = WHIZARD_TEST_MODELPATH_UFO\n       os_data%whizard_models_libpath = WHIZARD_TEST_MODELS_LIBPATH\n       os_data%whizard_susypath       = WHIZARD_TEST_SUSYPATH\n       os_data%whizard_gmlpath        = WHIZARD_TEST_GMLPATH\n       os_data%whizard_cutspath       = WHIZARD_TEST_CUTSPATH\n       os_data%whizard_texpath        = WHIZARD_TEST_TEXPATH\n       os_data%whizard_sharepath      = WHIZARD_TEST_SHAREPATH\n       os_data%whizard_testdatapath   = WHIZARD_TEST_TESTDATAPATH\n       os_data%whizard_circe2path     = WHIZARD_TEST_CIRCE2PATH\n       os_data%whizard_beamsimpath    = WHIZARD_TEST_BEAMSIMPATH\n       os_data%whizard_mulipath       = WHIZARD_TEST_MULIPATH\n       os_data%pdf_builtin_datapath   = PDF_BUILTIN_TEST_DATAPATH\n    else\n       if (os_dir_exist (local_includes)) then\n          os_data%whizard_includes = \"-I\" // local_includes // \" \"// &\n             WHIZARD_INCLUDES\n       else\n          os_data%whizard_includes = WHIZARD_INCLUDES\n       end if\n       os_data%whizard_omega_binpath  = WHIZARD_OMEGA_BINPATH\n       os_data%whizard_ldflags        = WHIZARD_LDFLAGS\n       os_data%whizard_libtool        = WHIZARD_LIBTOOL\n       if(present(paths)) then\n          if (paths%libtool /= \"\")  os_data%whizard_libtool = paths%libtool\n       end if\n       os_data%whizard_modelpath      = WHIZARD_MODELPATH\n       os_data%whizard_modelpath_ufo  = WHIZARD_MODELPATH_UFO\n       os_data%whizard_models_libpath = WHIZARD_MODELS_LIBPATH\n       os_data%whizard_susypath       = WHIZARD_SUSYPATH\n       os_data%whizard_gmlpath        = WHIZARD_GMLPATH\n       os_data%whizard_cutspath       = WHIZARD_CUTSPATH\n       os_data%whizard_texpath        = WHIZARD_TEXPATH\n       os_data%whizard_sharepath      = WHIZARD_SHAREPATH\n       os_data%whizard_testdatapath   = WHIZARD_TESTDATAPATH\n       os_data%whizard_circe2path     = WHIZARD_CIRCE2PATH\n       os_data%whizard_beamsimpath    = WHIZARD_BEAMSIMPATH\n       os_data%whizard_mulipath       = WHIZARD_MULIPATH\n       os_data%pdf_builtin_datapath   = PDF_BUILTIN_DATAPATH\n    end if\n    os_data%event_analysis     = EVENT_ANALYSIS     == \"yes\"\n    os_data%event_analysis_ps  = EVENT_ANALYSIS_PS  == \"yes\"\n    os_data%event_analysis_pdf = EVENT_ANALYSIS_PDF == \"yes\"\n    os_data%latex  = PRG_LATEX // \" \" // OPT_LATEX\n    os_data%mpost  = PRG_MPOST // \" \" // OPT_MPOST\n    if (os_data%use_testfiles) then\n       os_data%gml    = os_data%whizard_gmlpath // \"/whizard-gml\" // \" \" // &\n            OPT_MPOST // \" \" // \"--gmldir \" // os_data%whizard_gmlpath\n    else\n       os_data%gml    = os_data%bindir // \"/whizard-gml\" // \" \" // OPT_MPOST &\n         // \" \" // \"--gmldir \" // os_data%whizard_gmlpath\n    end if\n    os_data%dvips  = PRG_DVIPS\n    os_data%ps2pdf = PRG_PS2PDF\n    call os_data_expand_paths (os_data)\n    os_data%gosampath = GOSAM_DIR\n    os_data%golempath = GOLEM_DIR\n    os_data%formpath = FORM_DIR\n    os_data%qgrafpath = QGRAF_DIR\n    os_data%ninjapath = NINJA_DIR\n    os_data%samuraipath = SAMURAI_DIR\n  end subroutine os_data_init\n\n@ %def os_data_init\n@ Replace occurences of GNU path variables (such as [[${prefix}]]) by their\nvalues.  Do this for all strings that could depend on them, and do the\nreplacement in reverse order, since the path variables may be defined in terms\nof each other.    %% Fooling Noweb Emacs mode: $\n<<OS interface: procedures>>=\n  subroutine os_data_expand_paths (os_data)\n    type(os_data_t), intent(inout) :: os_data\n    integer, parameter :: N_VARIABLES = 6\n    type(string_t), dimension(N_VARIABLES) :: variable, value\n    variable(1) = \"${prefix}\";       value(1) = os_data%prefix\n    variable(2) = \"${exec_prefix}\";  value(2) = os_data%exec_prefix\n    variable(3) = \"${bindir}\";       value(3) = os_data%bindir\n    variable(4) = \"${libdir}\";       value(4) = os_data%libdir\n    variable(5) = \"${includedir}\";   value(5) = os_data%includedir\n    variable(6) = \"${datarootdir}\";  value(6) = os_data%datarootdir\n    call expand_paths (os_data%whizard_omega_binpath)\n    call expand_paths (os_data%whizard_includes)\n    call expand_paths (os_data%whizard_ldflags)\n    call expand_paths (os_data%whizard_libtool)\n    call expand_paths (os_data%whizard_modelpath)\n    call expand_paths (os_data%whizard_modelpath_ufo)\n    call expand_paths (os_data%whizard_models_libpath)\n    call expand_paths (os_data%whizard_susypath)\n    call expand_paths (os_data%whizard_gmlpath)\n    call expand_paths (os_data%whizard_cutspath)\n    call expand_paths (os_data%whizard_texpath)\n    call expand_paths (os_data%whizard_sharepath)\n    call expand_paths (os_data%whizard_testdatapath)\n    call expand_paths (os_data%whizard_circe2path)\n    call expand_paths (os_data%whizard_beamsimpath)\n    call expand_paths (os_data%whizard_mulipath)\n    call expand_paths (os_data%whizard_models_libpath_local)\n    call expand_paths (os_data%whizard_modelpath_local)\n    call expand_paths (os_data%whizard_omega_binpath_local)\n    call expand_paths (os_data%pdf_builtin_datapath)\n    call expand_paths (os_data%latex)\n    call expand_paths (os_data%mpost)\n    call expand_paths (os_data%gml)\n    call expand_paths (os_data%dvips)\n    call expand_paths (os_data%ps2pdf)\n  contains\n    subroutine expand_paths (string)\n      type(string_t), intent(inout) :: string\n      integer :: i\n      do i = N_VARIABLES, 1, -1\n         string = replace (string, variable(i), value(i), every=.true.)\n      end do\n    end subroutine expand_paths\n  end subroutine os_data_expand_paths\n\n@ %def os_data_update_paths\n@ Write contents\n<<OS interface: os data: TBP>>=\n  procedure :: write => os_data_write\n<<OS interface: procedures>>=\n  subroutine os_data_write (os_data, unit)\n    class(os_data_t), intent(in) :: os_data\n    integer, intent(in), optional :: unit\n    integer :: u\n    u = given_output_unit (unit);  if (u < 0)  return\n    write (u, \"(A)\")  \"OS data:\"\n    write (u, *) \"use_libtool    = \", os_data%use_libtool\n    write (u, *) \"use_testfiles  = \", os_data%use_testfiles\n    write (u, *) \"fc             = \", char (os_data%fc)\n    write (u, *) \"fcflags        = \", char (os_data%fcflags)\n    write (u, *) \"fcflags_pic    = \", char (os_data%fcflags_pic)\n    write (u, *) \"fclibs         = \", char (os_data%fclibs)\n    write (u, *) \"fc_src_ext     = \", char (os_data%fc_src_ext)\n    write (u, *) \"cc             = \", char (os_data%cc)\n    write (u, *) \"cflags         = \", char (os_data%cflags)\n    write (u, *) \"cflags_pic     = \", char (os_data%cflags_pic)\n    write (u, *) \"cxx            = \", char (os_data%cxx)\n    write (u, *) \"cxxflags       = \", char (os_data%cxxflags)\n    write (u, *) \"cxxlibs        = \", char (os_data%cxxlibs)\n    write (u, *) \"obj_ext        = \", char (os_data%obj_ext)\n    write (u, *) \"ld             = \", char (os_data%ld)\n    write (u, *) \"ldflags        = \", char (os_data%ldflags)\n    write (u, *) \"ldflags_so     = \", char (os_data%ldflags_so)\n    write (u, *) \"ldflags_static = \", char (os_data%ldflags_static)\n    write (u, *) \"ldflags_hepmc  = \", char (os_data%ldflags_hepmc)\n    write (u, *) \"ldflags_lcio   = \", char (os_data%ldflags_lcio)\n    write (u, *) \"ldflags_hoppet = \", char (os_data%ldflags_hoppet)\n    write (u, *) \"ldflags_looptools = \", char (os_data%ldflags_looptools)\n    write (u, *) \"shrlib_ext     = \", char (os_data%shrlib_ext)\n    write (u, *) \"fc_shrlib_ext  = \", char (os_data%fc_shrlib_ext)\n    write (u, *) \"makeflags      = \", char (os_data%makeflags)\n    write (u, *) \"prefix         = \", char (os_data%prefix)\n    write (u, *) \"exec_prefix    = \", char (os_data%exec_prefix)\n    write (u, *) \"bindir         = \", char (os_data%bindir)\n    write (u, *) \"libdir         = \", char (os_data%libdir)\n    write (u, *) \"includedir     = \", char (os_data%includedir)\n    write (u, *) \"datarootdir    = \", char (os_data%datarootdir)\n    write (u, *) \"whizard_omega_binpath  = \", &\n         char (os_data%whizard_omega_binpath)\n    write (u, *) \"whizard_includes       = \", char (os_data%whizard_includes)\n    write (u, *) \"whizard_ldflags        = \", char (os_data%whizard_ldflags)\n    write (u, *) \"whizard_libtool        = \", char (os_data%whizard_libtool)\n    write (u, *) \"whizard_modelpath      = \", &\n         char (os_data%whizard_modelpath)\n    write (u, *) \"whizard_modelpath_ufo  = \", &\n         char (os_data%whizard_modelpath_ufo)\n    write (u, *) \"whizard_models_libpath = \", &\n         char (os_data%whizard_models_libpath)\n    write (u, *) \"whizard_susypath       = \", char (os_data%whizard_susypath)\n    write (u, *) \"whizard_gmlpath        = \", char (os_data%whizard_gmlpath)\n    write (u, *) \"whizard_cutspath       = \", char (os_data%whizard_cutspath)\n    write (u, *) \"whizard_texpath        = \", char (os_data%whizard_texpath)\n    write (u, *) \"whizard_circe2path     = \", char (os_data%whizard_circe2path)\n    write (u, *) \"whizard_beamsimpath    = \", char (os_data%whizard_beamsimpath)\n    write (u, *) \"whizard_mulipath    = \", char (os_data%whizard_mulipath)\n    write (u, *) \"whizard_sharepath  = \", &\n         char (os_data%whizard_sharepath)\n    write (u, *) \"whizard_testdatapath  = \", &\n         char (os_data%whizard_testdatapath)\n    write (u, *) \"whizard_modelpath_local      = \", &\n         char (os_data%whizard_modelpath_local)\n    write (u, *) \"whizard_models_libpath_local = \", &\n         char (os_data%whizard_models_libpath_local)\n    write (u, *) \"whizard_omega_binpath_local  = \", &\n         char (os_data%whizard_omega_binpath_local)\n    write (u, *) \"event_analysis     = \", os_data%event_analysis\n    write (u, *) \"event_analysis_ps  = \", os_data%event_analysis_ps\n    write (u, *) \"event_analysis_pdf = \", os_data%event_analysis_pdf\n    write (u, *) \"latex  = \", char (os_data%latex)\n    write (u, *) \"mpost  = \", char (os_data%mpost)\n    write (u, *) \"gml    = \", char (os_data%gml)\n    write (u, *) \"dvips  = \", char (os_data%dvips)\n    write (u, *) \"ps2pdf = \", char (os_data%ps2pdf)\n    if (os_data%gosampath /= \"\") then\n       write (u, *) \"gosam   = \", char (os_data%gosampath)\n       write (u, *) \"golem   = \", char (os_data%golempath)\n       write (u, *) \"form    = \", char (os_data%formpath)\n       write (u, *) \"qgraf   = \", char (os_data%qgrafpath)\n       write (u, *) \"ninja   = \", char (os_data%ninjapath)\n       write (u, *) \"samurai = \", char (os_data%samuraipath)\n    end if\n  end subroutine os_data_write\n\n@ %def os_data_write\n@\n<<OS interface: os data: TBP>>=\n  procedure :: build_latex_file => os_data_build_latex_file\n<<OS interface: procedures>>=\n  subroutine os_data_build_latex_file (os_data, filename, stat_out)\n    class(os_data_t), intent(in) :: os_data\n    type(string_t), intent(in) :: filename\n    integer, intent(out), optional :: stat_out\n    type(string_t) :: setenv_tex, pipe, pipe_dvi\n    integer :: unit_dev, status\n    status = -1\n    if (os_data%event_analysis_ps) then\n       !!! Check if our OS has a /dev/null\n       unit_dev = free_unit ()\n       open (file = \"/dev/null\", unit = unit_dev, &\n            action = \"write\", iostat = status)\n       close (unit_dev)\n       if (status /= 0) then\n          pipe = \"\"\n          pipe_dvi = \"\"\n       else\n          pipe = \" > /dev/null\"\n          pipe_dvi = \" 2>/dev/null 1>/dev/null\"\n       end if\n       if (os_data%whizard_texpath /= \"\") then\n          setenv_tex = \"TEXINPUTS=\" // &\n               os_data%whizard_texpath // \":$TEXINPUTS \"\n       else\n          setenv_tex = \"\"\n       end if\n       call os_system_call (setenv_tex // &\n            os_data%latex // \" \" // filename // \".tex \" // pipe, &\n            verbose = .true., status = status)\n       call os_system_call (os_data%dvips // \" -o \" // filename // &\n            \".ps \" // filename // \".dvi\" // pipe_dvi, verbose = .true., &\n            status = status)\n       call os_system_call (os_data%ps2pdf // \" \" // filename // \".ps\", &\n            verbose = .true., status = status)\n    end if\n    if (present (stat_out)) stat_out = status\n  end subroutine os_data_build_latex_file\n\n@ %def os_data_build_latex_file\n@\n\\subsection{Dynamic linking}\nWe define a type that holds the filehandle for a dynamically linked\nlibrary (shared object), together with functions to open and close the\nlibrary, and to access functions in this library.\n<<OS interface: public>>=\n  public :: dlaccess_t\n<<OS interface: types>>=\n  type :: dlaccess_t\n     private\n     type(string_t) :: filename\n     type(c_ptr) :: handle = c_null_ptr\n     logical :: is_open = .false.\n     logical :: has_error = .false.\n     type(string_t) :: error\n   contains\n   <<OS interface: dlaccess: TBP>>\n  end type dlaccess_t\n\n@ %def dlaccess_t\n@ Output.  This is called by the output routine for the process\nlibrary.\n<<OS interface: dlaccess: TBP>>=\n  procedure :: write => dlaccess_write\n<<OS interface: procedures>>=\n  subroutine dlaccess_write (object, unit)\n    class(dlaccess_t), intent(in) :: object\n    integer, intent(in) :: unit\n    write (unit, \"(1x,A)\")  \"DL access info:\"\n    write (unit, \"(3x,A,L1)\")   \"is open   = \", object%is_open\n    if (object%has_error) then\n       write (unit, \"(3x,A,A,A)\")  \"error     = '\", char (object%error), \"'\"\n    else\n       write (unit, \"(3x,A)\")      \"error     = [none]\"\n    end if\n  end subroutine dlaccess_write\n\n@ %def dlaccess_write\n@ The interface to the library functions:\n<<OS interface: interfaces>>=\n  interface\n     function dlopen (filename, flag) result (handle) bind(C)\n       import\n       character(c_char), dimension(*) :: filename\n       integer(c_int), value :: flag\n       type(c_ptr) :: handle\n     end function dlopen\n  end interface\n\n  interface\n     function dlclose (handle) result (status) bind(C)\n       import\n       type(c_ptr), value :: handle\n       integer(c_int) :: status\n     end function dlclose\n  end interface\n\n  interface\n     function dlerror () result (str) bind(C)\n       import\n       type(c_ptr) :: str\n     end function dlerror\n  end interface\n\n  interface\n     function dlsym (handle, symbol) result (fptr) bind(C)\n       import\n       type(c_ptr), value :: handle\n       character(c_char), dimension(*) :: symbol\n       type(c_funptr) :: fptr\n     end function dlsym\n  end interface\n\n@ %def dlopen dlclose dlsym\n@ This reads an error string and transforms it into a [[string_t]]\nobject, if an error has occured.  If not, set the error flag to false\nand return an empty string.\n<<System defs: public parameters>>=\n  integer, parameter, public :: DLERROR_LEN = 160\n<<OS interface: procedures>>=\n  subroutine read_dlerror (has_error, error)\n    logical, intent(out) :: has_error\n    type(string_t), intent(out) :: error\n    type(c_ptr) :: err_cptr\n    character(len=DLERROR_LEN, kind=c_char), pointer :: err_fptr\n    integer :: str_end\n    err_cptr = dlerror ()\n    if (c_associated (err_cptr)) then\n       call c_f_pointer (err_cptr, err_fptr)\n       has_error = .true.\n       str_end = scan (err_fptr, c_null_char)\n       if (str_end > 0) then\n          error = err_fptr(1:str_end-1)\n       else\n          error = err_fptr\n       end if\n    else\n       has_error = .false.\n       error = \"\"\n    end if\n  end subroutine read_dlerror\n\n@ %def read_dlerror\n@ This is the Fortran API.  Init/final open and close the file,\ni.e., load and unload the library.\n\nNote that a library can be opened more than once, and that for an\nultimate close as many [[dlclose]] calls as [[dlopen]] calls are\nnecessary.  However, we assume that it is opened and closed only once.\n<<OS interface: public>>=\n  public :: dlaccess_init\n  public :: dlaccess_final\n<<OS interface: dlaccess: TBP>>=\n  procedure :: init => dlaccess_init\n  procedure :: final => dlaccess_final\n<<OS interface: procedures>>=\n  subroutine dlaccess_init (dlaccess, prefix, libname, os_data)\n    class(dlaccess_t), intent(out) :: dlaccess\n    type(string_t), intent(in) :: prefix, libname\n    type(os_data_t), intent(in), optional :: os_data\n    type(string_t) :: filename\n    logical :: exist\n    dlaccess%filename = libname\n    filename = prefix // \"/\" // libname\n    inquire (file=char(filename), exist=exist)\n    if (.not. exist) then\n       filename = prefix // \"/.libs/\" // libname\n       inquire (file=char(filename), exist=exist)\n       if (.not. exist) then\n          dlaccess%has_error = .true.\n          dlaccess%error = \"Library '\" // filename // \"' not found\"\n          return\n       end if\n    end if\n    dlaccess%handle = dlopen (char (filename) // c_null_char, ior ( &\n       RTLD_LAZY, RTLD_LOCAL))\n    dlaccess%is_open = c_associated (dlaccess%handle)\n    call read_dlerror (dlaccess%has_error, dlaccess%error)\n  end subroutine dlaccess_init\n\n  subroutine dlaccess_final (dlaccess)\n    class(dlaccess_t), intent(inout) :: dlaccess\n    integer(c_int) :: status\n    if (dlaccess%is_open) then\n       status = dlclose (dlaccess%handle)\n       dlaccess%is_open = .false.\n       call read_dlerror (dlaccess%has_error, dlaccess%error)\n    end if\n  end subroutine dlaccess_final\n\n@ %def dlaccess_init dlaccess_final\n@ Return true if an error has occured.\n<<OS interface: public>>=\n  public :: dlaccess_has_error\n<<OS interface: procedures>>=\n  function dlaccess_has_error (dlaccess) result (flag)\n    logical :: flag\n    type(dlaccess_t), intent(in) :: dlaccess\n    flag = dlaccess%has_error\n  end function dlaccess_has_error\n\n@ %def dlaccess_has_error\n@ Return the error string currently stored in the [[dlaccess]] object.\n<<OS interface: public>>=\n  public :: dlaccess_get_error\n<<OS interface: procedures>>=\n  function dlaccess_get_error (dlaccess) result (error)\n    type(string_t) :: error\n    type(dlaccess_t), intent(in) :: dlaccess\n    error = dlaccess%error\n  end function dlaccess_get_error\n\n@ %def dlaccess_get_error\n@ The symbol handler returns the C address of the function with the\ngiven string name.  (It is a good idea to use [[bind(C)]] for all\nfunctions accessed by this, such that the name string is\nwell-defined.)  Call [[c_f_procpointer]] to cast this into a Fortran\nprocedure pointer with an appropriate interface.\n<<OS interface: public>>=\n  public :: dlaccess_get_c_funptr\n<<OS interface: procedures>>=\n  function dlaccess_get_c_funptr (dlaccess, fname) result (fptr)\n    type(c_funptr) :: fptr\n    type(dlaccess_t), intent(inout) :: dlaccess\n    type(string_t), intent(in) :: fname\n    fptr = dlsym (dlaccess%handle, char (fname) // c_null_char)\n    call read_dlerror (dlaccess%has_error, dlaccess%error)\n  end function dlaccess_get_c_funptr\n\n@ %def dlaccess_get_c_funptr\n@\n\\subsection{Predicates}\nReturn true if the library is loaded.  In particular, this is false if\nloading was unsuccessful.\n<<OS interface: public>>=\n  public :: dlaccess_is_open\n<<OS interface: procedures>>=\n  function dlaccess_is_open (dlaccess) result (flag)\n    logical :: flag\n    type(dlaccess_t), intent(in) :: dlaccess\n    flag = dlaccess%is_open\n  end function dlaccess_is_open\n\n@ %def dlaccess_is_open\n@\n\\subsection{Shell access}\nThis is the standard system call for executing a shell command, such\nas invoking a compiler.\n\nIn F2008 there will be the equivalent built-in command\n[[execute_command_line]].\n<<OS interface: public>>=\n  public :: os_system_call\n<<OS interface: procedures>>=\n  subroutine os_system_call (command_string, status, verbose)\n    type(string_t), intent(in) :: command_string\n    integer, intent(out), optional :: status\n    logical, intent(in), optional :: verbose\n    logical :: verb\n    integer :: stat\n    verb = .false.;  if (present (verbose))  verb = verbose\n    if (verb) &\n         call msg_message (\"command: \" // char (command_string))\n    stat = system (char (command_string) // c_null_char)\n    if (present (status)) then\n       status = stat\n    else if (stat /= 0) then\n       if (.not. verb) &\n            call msg_message (\"command: \" // char (command_string))\n       write (msg_buffer, \"(A,I0)\")  \"Return code = \", stat\n       call msg_message ()\n       call msg_fatal (\"System command returned with nonzero status code\")\n    end if\n  end subroutine os_system_call\n\n@ %def os_system_call\n<<OS interface: interfaces>>=\n  interface\n     function system (command) result (status) bind(C)\n       import\n       integer(c_int) :: status\n       character(c_char), dimension(*) :: command\n     end function system\n  end interface\n\n@ %def system\n@\n\\subsection{Querying for a directory}\nThis queries for the existence of a directory. There is no standard way to\nachieve this in FORTRAN, and if we were to call into [[libc]], we would need access\nto C macros for evaluating the result, so we resort to calling [[test]] as a\nsystem call.\n<<OS interface: public>>=\n  public :: os_dir_exist\n<<OS interface: procedures>>=\n  function os_dir_exist (name) result (res)\n    type(string_t), intent(in) :: name\n    logical :: res\n    integer :: status\n    call os_system_call ('test -d \"' // name // '\"', status=status)\n    res = status == 0\n  end function os_dir_exist\n@ %def os_dir_exist\n@\n<<OS interface: public>>=\n  public :: os_file_exist\n<<OS interface: procedures>>=\n  function os_file_exist (name) result (exist)\n    type(string_t), intent(in) :: name\n!    logical, intent(in), optional :: verb\n    logical :: exist\n!    integer :: status\n!    call  os_system_call ('test -f \"' // name // '\"', status=status, verbose=verb)\n!    res = (status == 0)\n    inquire (file = char (name), exist=exist)\n  end function os_file_exist\n\n@ %def os_file_exist\n@\n\\subsection{Pack/unpack}\nThe argument to [[pack]] may be a file or a directory.  The name of the packed\nfile will get the [[pack_ext]] extension appended.  The argument to [[unpack]]\nmust be a file, with the extension already included in the file name.\n<<OS interface: public>>=\n  public :: os_pack_file\n  public :: os_unpack_file\n<<OS interface: procedures>>=\n  subroutine os_pack_file (file, os_data, status)\n    type(string_t), intent(in) :: file\n    type(os_data_t), intent(in) :: os_data\n    integer, intent(out), optional :: status\n    type(string_t) :: command_string\n    command_string = os_data%pack_cmd // \" \" &\n         // file // os_data%pack_ext // \" \" // file\n    call os_system_call (command_string, status)\n  end subroutine os_pack_file\n\n  subroutine os_unpack_file (file, os_data, status)\n    type(string_t), intent(in) :: file\n    type(os_data_t), intent(in) :: os_data\n    integer, intent(out), optional :: status\n    type(string_t) :: command_string\n    command_string = os_data%unpack_cmd // \" \" // file\n    call os_system_call (command_string, status)\n  end subroutine os_unpack_file\n\n@ %def os_pack_file\n@ %def os_unpack_file\n@\n\\subsection{Fortran compiler and linker}\nCompile a single module for use in a shared library, but without\nlinking.\n<<OS interface: public>>=\n  public :: os_compile_shared\n<<OS interface: procedures>>=\n  subroutine os_compile_shared (src, os_data, status)\n    type(string_t), intent(in) :: src\n    type(os_data_t), intent(in) :: os_data\n    integer, intent(out), optional :: status\n    type(string_t) :: command_string\n    if (os_data%use_libtool) then\n       command_string = &\n            os_data%whizard_libtool // \" --mode=compile \" // &\n            os_data%fc // \" \" // &\n            \"-c \" // &\n            os_data%whizard_includes // \" \" // &\n            os_data%fcflags // \" \" // &\n            \"'\" // src // os_data%fc_src_ext // \"'\"\n    else\n       command_string = &\n            os_data%fc // \" \" // &\n            \"-c  \" // &\n            os_data%fcflags_pic // \" \" // &\n            os_data%whizard_includes // \" \" // &\n            os_data%fcflags // \" \" // &\n            \"'\" // src // os_data%fc_src_ext // \"'\"\n    end if\n    call os_system_call (command_string, status)\n  end subroutine os_compile_shared\n\n@ %def os_compile_shared\n@ Link an array of object files to build a shared object library.  In\nthe libtool case, we have to specify a [[-rpath]], otherwise only a\nstatic library can be built.  However, since the library is never\ninstalled, this rpath is irrelevant.\n<<OS interface: public>>=\n  public :: os_link_shared\n<<OS interface: procedures>>=\n  subroutine os_link_shared (objlist, lib, os_data, status)\n    type(string_t), intent(in) :: objlist, lib\n    type(os_data_t), intent(in) :: os_data\n    integer, intent(out), optional :: status\n    type(string_t) :: command_string\n    if (os_data%use_libtool) then\n       command_string = &\n            os_data%whizard_libtool // \" --mode=link \" // &\n            os_data%fc // \" \" // &\n            \"-module \" // &\n            \"-rpath /usr/local/lib\" // \" \" // &\n            os_data%fcflags // \" \" // &\n            os_data%whizard_ldflags // \" \" // &\n            os_data%ldflags // \" \" // &\n            \"-o '\" // lib // \".la' \" // &\n            objlist\n    else\n       command_string = &\n            os_data%ld // \" \" // &\n            os_data%ldflags_so // \" \" // &\n            os_data%fcflags // \" \" // &\n            os_data%whizard_ldflags // \" \" // &\n            os_data%ldflags // \" \" // &\n            \"-o '\" // lib // \".\" // os_data%fc_shrlib_ext // \"' \" // &\n            objlist\n    end if\n    call os_system_call (command_string, status)\n  end subroutine os_link_shared\n\n@ %def os_link_shared\n@ Link an array of object files / libraries to build a static executable.\n<<OS interface: public>>=\n  public :: os_link_static\n<<OS interface: procedures>>=\n  subroutine os_link_static (objlist, exec_name, os_data, status)\n    type(string_t), intent(in) :: objlist, exec_name\n    type(os_data_t), intent(in) :: os_data\n    integer, intent(out), optional :: status\n    type(string_t) :: command_string\n    if (os_data%use_libtool) then\n       command_string = &\n            os_data%whizard_libtool // \" --mode=link \" // &\n            os_data%fc // \" \" // &\n            \"-static \" // &\n            os_data%fcflags // \" \" // &\n            os_data%whizard_ldflags // \" \" // &\n            os_data%ldflags // \" \" // &\n            os_data%ldflags_static // \" \" // &\n            \"-o '\" // exec_name // \"' \" // &\n            objlist // \" \" // &\n            os_data%ldflags_hepmc // \" \" // &\n            os_data%ldflags_lcio // \" \" // &\n            os_data%ldflags_hoppet // \" \" // &\n            os_data%ldflags_looptools\n    else\n       command_string = &\n            os_data%ld // \" \" // &\n            os_data%ldflags_so // \" \" // &\n            os_data%fcflags // \" \" // &\n            os_data%whizard_ldflags // \" \" // &\n            os_data%ldflags // \" \" // &\n            os_data%ldflags_static // \" \" // &\n            \"-o '\" // exec_name // \"' \" // &\n            objlist // \" \" // &\n            os_data%ldflags_hepmc // \" \" // &\n            os_data%ldflags_lcio // \" \" // &\n            os_data%ldflags_hoppet // \" \" // &\n            os_data%ldflags_looptools\n    end if\n    call os_system_call (command_string, status)\n  end subroutine os_link_static\n\n@ %def os_link_static\n@ Determine the name of the shared library to link.  If libtool is\nused, this is encoded in the [[.la]] file which resides in place of\nthe library itself.\n<<OS interface: public>>=\n  public :: os_get_dlname\n<<OS interface: procedures>>=\n  function os_get_dlname (lib, os_data, ignore, silent) result (dlname)\n    type(string_t) :: dlname\n    type(string_t), intent(in) :: lib\n    type(os_data_t), intent(in) :: os_data\n    logical, intent(in), optional :: ignore, silent\n    type(string_t) :: filename\n    type(string_t) :: buffer\n    logical :: exist, required, quiet\n    integer :: u\n    u = free_unit ()\n    if (present (ignore)) then\n       required = .not. ignore\n    else\n       required = .true.\n    end if\n   if (present (silent)) then\n       quiet = silent\n    else\n       quiet = .false.\n    end if\n    if (os_data%use_libtool) then\n       filename = lib // \".la\"\n       inquire (file=char(filename), exist=exist)\n       if (exist) then\n          open (unit=u, file=char(filename), action=\"read\", status=\"old\")\n          SCAN_LTFILE: do\n             call get (u, buffer)\n             if (extract (buffer, 1, 7) == \"dlname=\") then\n                dlname = extract (buffer, 9)\n                dlname = remove (dlname, len (dlname))\n                exit SCAN_LTFILE\n             end if\n          end do SCAN_LTFILE\n          close (u)\n       else if (required) then\n          if (.not. quiet) call msg_fatal (\" Library '\" // char (lib) &\n               // \"': libtool archive not found\")\n          dlname = \"\"\n       else\n          if (.not. quiet) call msg_message (\"[No compiled library '\" &\n               // char (lib) // \"']\")\n          dlname = \"\"\n       end if\n    else\n       dlname = lib // \".\" // os_data%fc_shrlib_ext\n       inquire (file=char(dlname), exist=exist)\n       if (.not. exist) then\n          if (required) then\n             if (.not. quiet) call msg_fatal (\" Library '\" // char (lib) &\n                  // \"' not found\")\n          else\n             if (.not. quiet) call msg_message &\n                (\"[No compiled process library '\" // char (lib) // \"']\")\n             dlname = \"\"\n          end if\n       end if\n    end if\n  end function os_get_dlname\n\n@ %def os_get_dlname\n@\n\\subsection{Controlling OpenMP}\nOpenMP is handled automatically by the library for the most part.  Here\nis a convenience routine for setting the number of threads, with some\ndiagnostics.\n<<OS interface: public>>=\n  public :: openmp_set_num_threads_verbose\n<<OS interface: procedures>>=\n  subroutine openmp_set_num_threads_verbose (num_threads, openmp_logging)\n    integer, intent(in) :: num_threads\n    integer :: n_threads\n    logical, intent(in), optional :: openmp_logging\n    logical :: logging\n    if (present (openmp_logging)) then\n       logging = openmp_logging\n    else\n       logging = .true.\n    end if\n    n_threads = num_threads\n    if (openmp_is_active ()) then\n       if (num_threads == 1) then\n          if (logging) then\n             write (msg_buffer, \"(A,I0,A)\")  \"OpenMP: Using \", num_threads, &\n                  \" thread\"\n             call msg_message\n          end if\n          n_threads = num_threads\n       else if (num_threads > 1) then\n          if (logging) then\n             write (msg_buffer, \"(A,I0,A)\")  \"OpenMP: Using \", num_threads, &\n                  \" threads\"\n             call msg_message\n          end if\n          n_threads = num_threads\n       else\n          if (logging) then\n             write (msg_buffer, \"(A,I0,A)\")  \"OpenMP: \" &\n                  // \"Illegal value of openmp_num_threads (\", num_threads, &\n               \") ignored\"\n             call msg_error\n          end if\n          n_threads = openmp_get_default_max_threads ()\n          if (logging) then\n             write (msg_buffer, \"(A,I0,A)\")  \"OpenMP: Using \", &\n                  n_threads, \" threads\"\n             call msg_message\n          end if\n       end if\n       if (n_threads > openmp_get_default_max_threads ()) then\n          if (logging) then\n             write (msg_buffer, \"(A,I0)\")  \"OpenMP: \" &\n                  // \"Number of threads is greater than library default of \", &\n                  openmp_get_default_max_threads ()\n             call msg_warning\n          end if\n       end if\n       call openmp_set_num_threads (n_threads)\n    else if (num_threads /= 1) then\n       if (logging) then\n          write (msg_buffer, \"(A,I0,A)\")  \"openmp_num_threads set to \", &\n               num_threads, \", but OpenMP is not active: ignored\"\n          call msg_warning\n       end if\n    end if\n  end subroutine openmp_set_num_threads_verbose\n\n@ %def openmp_set_num_threads_verbose\n@\n\\subsection{Controlling MPI}\nThe overall MPI handling has to be defined a context specific way,\nbut we can simplify things like logging or receiving [[n_size]] or [[rank]].\n<<OS interface: public>>=\n  public :: mpi_set_logging\n<<OS interface: procedures>>=\n  subroutine mpi_set_logging (mpi_logging)\n    logical, intent(in) :: mpi_logging\n    integer :: n_size, rank\n    call mpi_get_comm_id (n_size, rank)\n    if (mpi_logging .and. n_size > 1) then\n       write (msg_buffer, \"(A,I0,A)\") \"MPI: Using \", n_size, \" processes.\"\n       call msg_message ()\n       if (rank == 0) then\n          call msg_message (\"MPI: master worker\")\n       else\n          write (msg_buffer, \"(A,I0)\") \"MPI: slave worker #\", rank\n          call msg_message ()\n       end if\n    end if\n  end subroutine mpi_set_logging\n\n@ %def mpi_set_logging\n@ Receive communicator size and rank inside communicator. The subroutine is a stub, if not compiled with [[MPI]].\n<<OS interface: public>>=\n  public :: mpi_get_comm_id\n<<OS interface: procedures>>=\n  subroutine mpi_get_comm_id (n_size, rank)\n    integer, intent(out) :: n_size\n    integer, intent(out) :: rank\n    n_size = 1\n    rank = 0\n  <<OS interface: mpi get comm id>>\n  end subroutine mpi_get_comm_id\n\n@ %def mpi_get_comm_id\n<<OS interface: mpi get comm id>>=\n@\n<<MPI: OS interface: mpi get comm id>>=\n  call MPI_Comm_size (MPI_COMM_WORLD, n_size)\n  call MPI_Comm_rank (MPI_COMM_WORLD, rank)\n@\n<<OS interface: public>>=\n  public :: mpi_is_comm_master\n<<OS interface: procedures>>=\n  logical function mpi_is_comm_master () result (flag)\n    integer :: n_size, rank\n    call mpi_get_comm_id (n_size, rank)\n    flag = (rank == 0)\n  end function mpi_is_comm_master\n\n@ %def mpi_is_comm_master\n@\n\\subsection{Unit tests}\nTest module, followed by the corresponding implementation module.\n<<[[os_interface_ut.f90]]>>=\n<<File header>>\n\nmodule os_interface_ut\n  use unit_tests\n  use os_interface_uti\n\n<<Standard module head>>\n\n<<OS interface: public test>>\n\ncontains\n\n<<OS interface: test driver>>\n\nend module os_interface_ut\n@ %def os_interface_ut\n@\n<<[[os_interface_uti.f90]]>>=\n<<File header>>\n\nmodule os_interface_uti\n\n  use, intrinsic :: iso_c_binding !NODEP!\n\n<<Use strings>>\n  use io_units\n\n  use os_interface\n\n<<Standard module head>>\n\n<<OS interface: test declarations>>\n\ncontains\n\n<<OS interface: tests>>\n\nend module os_interface_uti\n@ %def os_interface_ut\n@ API: driver for the unit tests below.\n<<OS interface: public test>>=\n  public :: os_interface_test\n<<OS interface: test driver>>=\n  subroutine os_interface_test (u, results)\n    integer, intent(in) :: u\n    type(test_results_t), intent(inout) :: results\n  <<OS interface: execute tests>>\n  end subroutine os_interface_test\n\n@ %def os_interface_test\n@ Write a Fortran source file, compile it to a shared library, load\nit, and execute the contained function.\n<<OS interface: execute tests>>=\n  call test (os_interface_1, \"os_interface_1\", &\n       \"check OS interface routines\", &\n       u, results)\n<<OS interface: test declarations>>=\n  public :: os_interface_1\n<<OS interface: tests>>=\n  subroutine os_interface_1 (u)\n    integer, intent(in) :: u\n    type(dlaccess_t) :: dlaccess\n    type(string_t) :: fname, libname, ext\n    type(os_data_t) :: os_data\n    type(string_t) :: filename_src, filename_obj\n    abstract interface\n       function so_test_proc (i) result (j) bind(C)\n         import c_int\n         integer(c_int), intent(in) :: i\n         integer(c_int) :: j\n       end function so_test_proc\n    end interface\n    procedure(so_test_proc), pointer :: so_test => null ()\n    type(c_funptr) :: c_fptr\n    integer :: unit\n    integer(c_int) :: i\n    call os_data%init ()\n    fname = \"so_test\"\n    filename_src = fname // os_data%fc_src_ext\n    if (os_data%use_libtool) then\n       ext = \".lo\"\n    else\n       ext = os_data%obj_ext\n    end if\n    filename_obj = fname // ext\n    libname = fname // '.' // os_data%fc_shrlib_ext\n\n    write (u, \"(A)\")  \"* Test output: OS interface\"\n    write (u, \"(A)\")  \"*   Purpose: check os_interface routines\"\n    write (u, \"(A)\")\n\n    write (u, \"(A)\")  \"* write source file 'so_test.f90'\"\n    write (u, \"(A)\")\n    unit = free_unit ()\n    open (unit=unit, file=char(filename_src), action=\"write\")\n    write (unit, \"(A)\")  \"function so_test (i) result (j) bind(C)\"\n    write (unit, \"(A)\")  \"  use iso_c_binding\"\n    write (unit, \"(A)\")  \"  integer(c_int), intent(in) :: i\"\n    write (unit, \"(A)\")  \"  integer(c_int) :: j\"\n    write (unit, \"(A)\")  \"  j = 2 * i\"\n    write (unit, \"(A)\")  \"end function so_test\"\n    close (unit)\n    write (u, \"(A)\")  \"* compile and link as 'so_test.so/dylib'\"\n    write (u, \"(A)\")\n    call os_compile_shared (fname, os_data)\n    call os_link_shared (filename_obj, fname, os_data)\n    write (u, \"(A)\")  \"* load library 'so_test.so/dylib'\"\n    write (u, \"(A)\")\n    call dlaccess_init (dlaccess, var_str (\".\"), libname, os_data)\n    if (dlaccess_is_open (dlaccess)) then\n       write (u, \"(A)\") \"     success\"\n    else\n       write (u, \"(A)\") \"     failure\"\n    end if\n    write (u, \"(A)\")  \"* load symbol 'so_test'\"\n    write (u, \"(A)\")\n    c_fptr = dlaccess_get_c_funptr (dlaccess, fname)\n    if (c_associated (c_fptr)) then\n       write (u, \"(A)\") \"     success\"\n    else\n       write (u, \"(A)\") \"     failure\"\n    end if\n    call c_f_procpointer (c_fptr, so_test)\n    write (u, \"(A)\") \"* Execute function from 'so_test.so/dylib'\"\n    i = 7\n    write (u, \"(A,1x,I1)\")  \"     input  = \", i\n    write (u, \"(A,1x,I1)\")  \"     result = \", so_test(i)\n    if (so_test(i) / i .ne. 2) then\n       write (u, \"(A)\")  \"* Compiling and linking ISO C functions failed.\"\n    else\n       write (u, \"(A)\")  \"* Successful.\"\n    end if\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Cleanup\"\n    call dlaccess_final (dlaccess)\n  end subroutine os_interface_1\n\n@ %def os_interface_1\n@\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\\section{Interface for formatted I/O}\nFor access to formatted printing (possibly input), we interface the C\n[[printf]] family of functions.  There are two important issues here:\n\\begin{enumerate}\n\\item\n  [[printf]] takes an arbitrary number of arguments, relying on the C stack.\n  This is not interoperable.  We interface it with C wrappers that output a\n  single integer, real or string and restrict the allowed formats accordingly.\n\\item\n  Restricting format strings is essential also for preventing format string\n  attacks.  Allowing arbitrary format string would create a real security hole\n  in a Fortran program.\n\\item\n  The string returned by [[sprintf]] must be allocated to the right size.\n\\end{enumerate}\n<<[[formats.f90]]>>=\n<<File header>>\n\nmodule formats\n\n  use, intrinsic :: iso_c_binding\n\n<<Use kinds>>\n<<Use strings>>\n  use io_units\n  use diagnostics\n\n<<Standard module head>>\n\n<<Formats: public>>\n\n<<Formats: parameters>>\n\n<<Formats: types>>\n\n<<Formats: interfaces>>\n\ncontains\n\n<<Formats: procedures>>\n\nend module formats\n@ %def formats\n@\n\\subsection{Parsing a C format string}\nThe C format string contains characters and format conversion specifications.\nThe latter are initiated by a [[%]] sign.  If the next letter is also a [[%]],\na percent sign is printed and no conversion is done.  Otherwise, a conversion\nis done and applied to the next argument in the argument list.  First comes an\noptional flag ([[#]], [[0]], [[-]], [[+]], or space), an optional field width\n(decimal digits starting not with zero), an optional precision (period, then\nanother decimal digit string), a length modifier (irrelevant for us, therefore\nnot supported), and a conversion specifier: [[d]] or [[i]] for integer; [[e]],\n[[f]], [[g]] (also upper case) for double-precision real, [[s]] for a string.\n\nWe explicitly exclude all other conversion specifiers, and we check the\nspecifiers against the actual arguments.\n\n\\subsubsection{A type for passing arguments}\nThis is a polymorphic type that can hold integer, real (double), and string\narguments.\n<<Formats: parameters>>=\n  integer, parameter, public :: ARGTYPE_NONE = 0\n  integer, parameter, public :: ARGTYPE_LOG = 1\n  integer, parameter, public :: ARGTYPE_INT = 2\n  integer, parameter, public :: ARGTYPE_REAL = 3\n  integer, parameter, public :: ARGTYPE_STR = 4\n\n@ %def ARGTYPE_NONE ARGTYPE_LOG ARGTYPE_INT ARGTYPE_REAL ARGTYPE_STRING\n@ The integer and real entries are actually scalars, but we avoid relying on\nthe allocatable-scalar feature and make them one-entry arrays.  The character\nentry is a real array which is a copy of the string.\n\nLogical values are mapped to strings (true or false), so this type parameter\nvalue is mostly unused.\n<<Formats: public>>=\n  public :: sprintf_arg_t\n<<Formats: types>>=\n  type :: sprintf_arg_t\n    private\n    integer :: type = ARGTYPE_NONE\n    integer(c_int), dimension(:), allocatable :: ival\n    real(c_double), dimension(:), allocatable :: rval\n    character(c_char), dimension(:), allocatable :: sval\n  end type sprintf_arg_t\n\n@ %def sprintf_arg_t\n<<Formats: public>>=\n  public :: sprintf_arg_init\n<<Formats: interfaces>>=\n  interface sprintf_arg_init\n     module procedure sprintf_arg_init_log\n     module procedure sprintf_arg_init_int\n     module procedure sprintf_arg_init_real\n     module procedure sprintf_arg_init_str\n  end interface\n\n<<Formats: procedures>>=\n  subroutine sprintf_arg_init_log (arg, lval)\n    type(sprintf_arg_t), intent(out) :: arg\n    logical, intent(in) :: lval\n    arg%type = ARGTYPE_STR\n    if (lval) then\n       allocate (arg%sval (5))\n       arg%sval = ['t', 'r', 'u', 'e', c_null_char]\n    else\n       allocate (arg%sval (6))\n       arg%sval = ['f', 'a', 'l', 's', 'e', c_null_char]\n    end if\n  end subroutine sprintf_arg_init_log\n\n  subroutine sprintf_arg_init_int (arg, ival)\n    type(sprintf_arg_t), intent(out) :: arg\n    integer, intent(in) :: ival\n    arg%type = ARGTYPE_INT\n    allocate (arg%ival (1))\n    arg%ival = ival\n  end subroutine sprintf_arg_init_int\n\n  subroutine sprintf_arg_init_real (arg, rval)\n    type(sprintf_arg_t), intent(out) :: arg\n    real(default), intent(in) :: rval\n    arg%type = ARGTYPE_REAL\n    allocate (arg%rval (1))\n    arg%rval = rval\n  end subroutine sprintf_arg_init_real\n\n  subroutine sprintf_arg_init_str (arg, sval)\n    type(sprintf_arg_t), intent(out) :: arg\n    type(string_t), intent(in) :: sval\n    integer :: i\n    arg%type = ARGTYPE_STR\n    allocate (arg%sval (len (sval) + 1))\n    do i = 1, len (sval)\n       arg%sval(i) = extract (sval, i, i)\n    end do\n    arg%sval(len (sval) + 1) = c_null_char\n  end subroutine sprintf_arg_init_str\n\n@ %def sprintf_arg_init\n<<Formats: procedures>>=\n  subroutine sprintf_arg_write (arg, unit)\n    type(sprintf_arg_t), intent(in) :: arg\n    integer, intent(in), optional :: unit\n    integer :: u\n    u = given_output_unit (unit)\n    select case (arg%type)\n    case (ARGTYPE_NONE)\n      write (u, *) \"[none]\"\n    case (ARGTYPE_INT)\n      write (u, \"(1x,A,1x)\", advance = \"no\")  \"[int]\"\n      write (u, *)  arg%ival\n    case (ARGTYPE_REAL)\n      write (u, \"(1x,A,1x)\", advance = \"no\")  \"[real]\"\n      write (u, *)  arg%rval\n    case (ARGTYPE_STR)\n      write (u, \"(1x,A,1x,A)\", advance = \"no\")  \"[string]\", '\"'\n      write (u, *)  arg%rval, '\"'\n    end select\n  end subroutine sprintf_arg_write\n\n@ %def sprintf_arg_write\n@ Return an upper bound for the length of the printed version; in case of\nstrings the result is exact.\n<<Formats: procedures>>=\n  elemental function sprintf_arg_get_length (arg) result (length)\n    integer :: length\n    type(sprintf_arg_t), intent(in) :: arg\n    select case (arg%type)\n    case (ARGTYPE_INT)\n       length = log10 (real (huge (arg%ival(1)))) + 2\n    case (ARGTYPE_REAL)\n       length = log10 (real (radix (arg%rval(1))) ** digits (arg%rval(1))) + 8\n    case (ARGTYPE_STR)\n       length = size (arg%sval)\n    case default\n       length = 0\n    end select\n  end function sprintf_arg_get_length\n\n@ %def sprintf_arg_get_length\n<<Formats: procedures>>=\n  subroutine sprintf_arg_apply_sprintf (arg, fmt, result, actual_length)\n    type(sprintf_arg_t), intent(in) :: arg\n    character(c_char), dimension(:), intent(in) :: fmt\n    character(c_char), dimension(:), intent(inout) :: result\n    integer, intent(out) :: actual_length\n    integer(c_int) :: ival\n    real(c_double) :: rval\n    select case (arg%type)\n    case (ARGTYPE_NONE)\n      actual_length = sprintf_none (result, fmt)\n    case (ARGTYPE_INT)\n      ival = arg%ival(1)\n      actual_length = sprintf_int (result, fmt, ival)\n    case (ARGTYPE_REAL)\n      rval = arg%rval(1)\n      actual_length = sprintf_double (result, fmt, rval)\n    case (ARGTYPE_STR)\n      actual_length = sprintf_str (result, fmt, arg%sval)\n    case default\n      call msg_bug (\"sprintf_arg_apply_sprintf called with illegal type\")\n    end select\n    if (actual_length < 0) then\n       write (msg_buffer, *) \"Format: '\", fmt, \"'\"\n       call msg_message ()\n       write (msg_buffer, *) \"Output: '\", result, \"'\"\n       call msg_message ()\n       call msg_error (\"I/O error in sprintf call\")\n       actual_length = 0\n    end if\n  end subroutine sprintf_arg_apply_sprintf\n\n@ %def sprintf_arg_apply_sprintf\n@\n\\subsubsection{Container type for the output}\nThere is a procedure which chops the format string into pieces that contain at\nmost one conversion specifier.  Pairing this with a [[sprintf_arg]] object, we\nget the actual input to the [[sprintf]] interface.  The type below holds this\ninput and can allocate the output string.\n<<Formats: types>>=\n  type :: sprintf_interface_t\n    private\n    character(c_char), dimension(:), allocatable :: input_fmt\n    type(sprintf_arg_t) :: arg\n    character(c_char), dimension(:), allocatable :: output_str\n    integer :: output_str_len = 0\n  end type sprintf_interface_t\n\n@ %def sprintf_fmt_t\n<<Formats: procedures>>=\n  subroutine sprintf_interface_init (intf, fmt, arg)\n    type(sprintf_interface_t), intent(out) :: intf\n    type(string_t), intent(in) :: fmt\n    type(sprintf_arg_t), intent(in) :: arg\n    integer :: fmt_len, i\n    fmt_len = len (fmt)\n    allocate (intf%input_fmt (fmt_len + 1))\n    do i = 1, fmt_len\n       intf%input_fmt(i) = extract (fmt, i, i)\n    end do\n    intf%input_fmt(fmt_len+1) = c_null_char\n    intf%arg = arg\n    allocate (intf%output_str (len (fmt) + sprintf_arg_get_length (arg) + 1))\n  end subroutine sprintf_interface_init\n\n@ %def sprintf_interface_init\n<<Formats: procedures>>=\n  subroutine sprintf_interface_write (intf, unit)\n    type(sprintf_interface_t), intent(in) :: intf\n    integer, intent(in), optional :: unit\n    integer :: u\n    u = given_output_unit (unit)\n    write (u, *) \"Format string = \", '\"', intf%input_fmt, '\"'\n    write (u, \"(1x,A,1x)\", advance = \"no\") \"Argument = \"\n    call sprintf_arg_write (intf%arg, unit)\n    if (intf%output_str_len > 0) then\n       write (u, *) \"Result string = \", &\n            '\"', intf%output_str (1:intf%output_str_len), '\"'\n    end if\n  end subroutine sprintf_interface_write\n\n@ %def sprintf_interface_write\n@ Return the output string:\n<<Formats: procedures>>=\n  function sprintf_interface_get_result (intf) result (string)\n    type(string_t) :: string\n    type(sprintf_interface_t), intent(in) :: intf\n    character(kind = c_char, len = max (intf%output_str_len, 0)) :: buffer\n    integer :: i\n    if (intf%output_str_len > 0) then\n       do i = 1, intf%output_str_len\n          buffer(i:i) = intf%output_str(i)\n       end do\n       string = buffer(1:intf%output_str_len)\n    else\n       string = \"\"\n    end if\n  end function sprintf_interface_get_result\n\n@ %def sprintf_interface_get_result\n<<Formats: procedures>>=\n  subroutine sprintf_interface_apply_sprintf (intf)\n    type(sprintf_interface_t), intent(inout) :: intf\n    call sprintf_arg_apply_sprintf &\n         (intf%arg, intf%input_fmt, intf%output_str, intf%output_str_len)\n  end subroutine sprintf_interface_apply_sprintf\n\n@ %def sprintf_interface_apply_sprintf\n@ Import the interfaces defined in the previous section:\n<<Formats: interfaces>>=\n<<sprintf interfaces>>\n\n@\n\\subsubsection{Scan the format string}\nChop it into pieces that contain one conversion\nspecifier each.  The zero-th piece contains the part before the first\nspecifier.  Check the specifiers and allow only the subset that we support.\nAlso check for an exact match between conversion specifiers and input\narguments.  The result is an allocated array of [[sprintf_interface]] object;\neach one contains a piece of the format string and the corresponding\nargument.\n<<Formats: procedures>>=\n  subroutine chop_and_check_format_string (fmt, arg, intf)\n    type(string_t), intent(in) :: fmt\n    type(sprintf_arg_t), dimension(:), intent(in) :: arg\n    type(sprintf_interface_t), dimension(:), intent(out), allocatable :: intf\n    integer :: n_args, i\n    type(string_t), dimension(:), allocatable :: split_fmt\n    type(string_t) :: word, buffer, separator\n    integer :: pos, length, l\n    logical :: ok\n    type(sprintf_arg_t) :: arg_null\n    ok = .true.\n    length = 0\n    n_args = size (arg)\n    allocate (split_fmt (0:n_args))\n    split_fmt = \"\"\n    buffer = fmt\n    SCAN_ARGS: do i = 1, n_args\n       FIND_CONVERSION: do\n          call split (buffer, word, \"%\", separator=separator)\n          if (separator == \"\") then\n             call msg_message ('\"' // char (fmt) // '\"')\n             call msg_error (\"C-formatting string: \" &\n                  // \"too few conversion specifiers in format string\")\n             ok = .false.;  exit SCAN_ARGS\n          end if\n          split_fmt(i-1) = split_fmt(i-1) // word\n          if (extract (buffer, 1, 1) /= \"%\") then\n             split_fmt(i) = \"%\"\n             exit FIND_CONVERSION\n          else\n             split_fmt(i-1) = split_fmt(i-1) // \"%\"\n          end if\n       end do FIND_CONVERSION\n       pos = verify (buffer, \"#0-+ \")   ! Flag characters (zero or more)\n       split_fmt(i) = split_fmt(i) // extract (buffer, 1, pos-1)\n       buffer = remove (buffer, 1, pos-1)\n       pos = verify (buffer, \"123456890\")  ! Field width\n       word = extract (buffer, 1, pos-1)\n       if (len (word) /= 0) then\n         call read_int_from_string (word, len (word), l)\n         length = length + l\n       end if\n       split_fmt(i) = split_fmt(i) // word\n       buffer = remove (buffer, 1, pos-1)\n       if (extract (buffer, 1, 1) == \".\") then\n          buffer = remove (buffer, 1, 1)\n          pos = verify (buffer, \"1234567890\")   ! Precision\n          split_fmt(i) = split_fmt(i) // \".\" // extract (buffer, 1, pos-1)\n          buffer = remove (buffer, 1, pos-1)\n       end if\n       ! Length modifier would come here, but is not allowed\n       select case (char (extract (buffer, 1, 1)))  ! conversion specifier\n       case (\"d\", \"i\")\n          if (arg(i)%type /= ARGTYPE_INT) then\n             call msg_message ('\"' // char (fmt) // '\"')\n             call msg_error (\"C-formatting string: \" &\n                  // \"argument type mismatch: integer value expected\")\n             ok = .false.;  exit SCAN_ARGS\n          end if\n       case (\"e\", \"E\", \"f\", \"F\", \"g\", \"G\")\n          if (arg(i)%type /= ARGTYPE_REAL) then\n             call msg_message ('\"' // char (fmt) // '\"')\n             call msg_error (\"C-formatting string: \" &\n                  // \"argument type mismatch: real value expected\")\n             ok = .false.;  exit SCAN_ARGS\n          end if\n       case (\"s\")\n          if (arg(i)%type /= ARGTYPE_STR) then\n             call msg_message ('\"' // char (fmt) // '\"')\n             call msg_error (\"C-formatting string: \" &\n                  // \"argument type mismatch: logical or string value expected\")\n             ok = .false.;  exit SCAN_ARGS\n          end if\n       case default\n          call msg_message ('\"' // char (fmt) // '\"')\n          call msg_error (\"C-formatting string: \" &\n               // \"illegal or incomprehensible conversion specifier\")\n          ok = .false.;  exit SCAN_ARGS\n       end select\n       split_fmt(i) = split_fmt(i) // extract (buffer, 1, 1)\n       buffer = remove (buffer, 1, 1)\n    end do SCAN_ARGS\n    if (ok) then\n       FIND_EXTRA_CONVERSION: do\n          call split (buffer, word, \"%\", separator=separator)\n          split_fmt(n_args) = split_fmt(n_args) // word // separator\n          if (separator == \"\")  exit FIND_EXTRA_CONVERSION\n          if (extract (buffer, 1, 1) == \"%\") then\n             split_fmt(n_args) = split_fmt(n_args) // \"%\"\n             buffer = remove (buffer, 1, 1)\n          else\n             call msg_message ('\"' // char (fmt) // '\"')\n             call msg_error (\"C-formatting string: \" &\n                  // \"too many conversion specifiers in format string\")\n             ok = .false.;  exit FIND_EXTRA_CONVERSION\n          end if\n       end do FIND_EXTRA_CONVERSION\n       split_fmt(n_args) = split_fmt(n_args) // buffer\n       allocate (intf (0:n_args))\n       call sprintf_interface_init (intf(0), split_fmt(0), arg_null)\n       do i = 1, n_args\n          call sprintf_interface_init (intf(i), split_fmt(i), arg(i))\n       end do\n    else\n       allocate (intf (0))\n    end if\n  contains\n    subroutine read_int_from_string (word, length, l)\n      type(string_t), intent(in) :: word\n      integer, intent(in) :: length\n      integer, intent(out) :: l\n      character(len=length) :: buffer\n      buffer = word\n      read (buffer, *) l\n    end subroutine read_int_from_string\n  end subroutine chop_and_check_format_string\n\n@ %def chop_and_check_format_string\n@\n\\subsection{API}\n<<Formats: public>>=\n  public :: sprintf\n<<Formats: procedures>>=\n  function sprintf (fmt, arg) result (string)\n    type(string_t) :: string\n    type(string_t), intent(in) :: fmt\n    type(sprintf_arg_t), dimension(:), intent(in) :: arg\n    type(sprintf_interface_t), dimension(:), allocatable :: intf\n    integer :: i\n    string = \"\"\n    call chop_and_check_format_string (fmt, arg, intf)\n    if (size (intf) > 0) then\n       do i = 0, ubound (intf, 1)\n          call sprintf_interface_apply_sprintf (intf(i))\n          string = string // sprintf_interface_get_result (intf(i))\n       end do\n    end if\n  end function sprintf\n\n@ %def sprintf\n@\n\\subsection{Unit tests}\nTest module, followed by the corresponding implementation module.\n<<[[formats_ut.f90]]>>=\n<<File header>>\n\nmodule formats_ut\n  use unit_tests\n  use formats_uti\n\n<<Standard module head>>\n\n<<Formats: public test>>\n\ncontains\n\n<<Formats: test driver>>\n\nend module formats_ut\n@ %def formats_ut\n@\n<<[[formats_uti.f90]]>>=\n<<File header>>\n\nmodule formats_uti\n\n<<Use kinds>>\n<<Use strings>>\n\n  use formats\n\n<<Standard module head>>\n\n<<Formats: test declarations>>\n\n<<Formats: test types>>\n\ncontains\n\n<<Formats: tests>>\n\nend module formats_uti\n@ %def formats_ut\n@ API: driver for the unit tests below.\n<<Formats: public test>>=\n  public :: format_test\n<<Formats: test driver>>=\n  subroutine format_test (u, results)\n    integer, intent(in) :: u\n    type(test_results_t), intent(inout) :: results\n  <<Formats: execute tests>>\n  end subroutine format_test\n\n@ %def format_test\n<<Formats: execute tests>>=\n  call test (format_1, \"format_1\", &\n       \"check formatting routines\", &\n       u, results)\n<<Formats: test declarations>>=\n  public :: format_1\n<<Formats: tests>>=\n  subroutine format_1 (u)\n    integer, intent(in) :: u\n    write (u, \"(A)\")  \"*** Test 1: a string ***\"\n    write (u, \"(A)\")\n    call test_run (var_str(\"%s\"), 1, [4], ['abcdefghij'], u)\n    write (u, \"(A)\")  \"*** Test 2: two integers ***\"\n    write (u, \"(A)\")\n    call test_run (var_str(\"%d,%d\"), 2, [2, 2], ['42', '13'], u)\n    write (u, \"(A)\")  \"*** Test 3: floating point number ***\"\n    write (u, \"(A)\")\n    call test_run (var_str(\"%8.4f\"), 1, [3], ['42567.12345'], u)\n    write (u, \"(A)\")  \"*** Test 4: general expression ***\"\n    call test_run (var_str(\"%g\"), 1, [3], ['3.1415'], u)\n    contains\n      subroutine test_run (fmt, n_args, type, buffer, unit)\n        type(string_t), intent(in) :: fmt\n        integer, intent(in) :: n_args, unit\n        logical :: lval\n        integer :: ival\n        real(default) :: rval\n        integer :: i\n        type(string_t) :: string\n        type(sprintf_arg_t), dimension(:), allocatable :: arg\n        integer, dimension(n_args), intent(in) :: type\n        character(*), dimension(n_args), intent(in) :: buffer\n        write (unit, \"(A,A)\")   \"Format string :\", char(fmt)\n        write (unit, \"(A,I1)\")  \"Number of args:\", n_args\n        allocate (arg (n_args))\n        do i = 1, n_args\n           write (unit, \"(A,I1)\")  \"Argument (type ) = \", type(i)\n           select case (type(i))\n           case (ARGTYPE_LOG)\n              read (buffer(i), *)  lval\n              call sprintf_arg_init (arg(i), lval)\n           case (ARGTYPE_INT)\n              read (buffer(i), *)  ival\n              call sprintf_arg_init (arg(i), ival)\n           case (ARGTYPE_REAL)\n              read (buffer(i), *)  rval\n              call sprintf_arg_init (arg(i), rval)\n           case (ARGTYPE_STR)\n              call sprintf_arg_init (arg(i), var_str (trim (buffer(i))))\n           end select\n         end do\n         string = sprintf (fmt, arg)\n         write (unit, \"(A,A,A)\")  \"Result: '\", char (string), \"'\"\n         deallocate (arg)\n       end subroutine test_run\n  end subroutine format_1\n\n@ %def format_1\n@\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\\section{CPU timing}\n\nThe time is stored in a simple derived type which just holds a\nfloating-point number.\n<<[[cputime.f90]]>>=\n<<File header>>\n\nmodule cputime\n\n<<Use kinds>>\n  use io_units\n<<Use strings>>\n  use diagnostics\n\n<<Standard module head>>\n\n<<CPU time: public>>\n\n<<CPU time: types>>\n\n<<CPU time: interfaces>>\n\ncontains\n\n<<CPU time: procedures>>\n\nend module cputime\n@ %def cputime\n@ The CPU time is a floating-point number with an arbitrary reference time.\nIt is single precision (default real, not [[real(default)]]).\nIt is measured in seconds.\n<<CPU time: public>>=\n  public :: time_t\n<<CPU time: types>>=\n  type :: time_t\n     private\n     logical :: known = .false.\n     real :: value = 0\n   contains\n   <<CPU time: time: TBP>>\n  end type time_t\n\n@ %def time_t\n<<CPU time: time: TBP>>=\n  procedure :: write => time_write\n<<CPU time: procedures>>=\n  subroutine time_write (object, unit)\n    class(time_t), intent(in) :: object\n    integer, intent(in), optional :: unit\n    integer :: u\n    u = given_output_unit (unit)\n    write (u, \"(1x,A)\", advance=\"no\")  \"Time in seconds =\"\n    if (object%known) then\n       write (u, \"(1x,ES10.3)\")  object%value\n    else\n       write (u, \"(1x,A)\")  \"[unknown]\"\n    end if\n  end subroutine time_write\n\n@ %def time_write\n@ Set the current time\n<<CPU time: time: TBP>>=\n  procedure :: set_current => time_set_current\n<<CPU time: procedures>>=\n  subroutine time_set_current (time)\n    class(time_t), intent(out) :: time\n    integer :: msecs\n    call system_clock (msecs)\n    time%value = real (msecs) / 1000.\n    time%known = time%value > 0\n  end subroutine time_set_current\n\n@ %def time_set_current\n@ Assign to a [[real(default]] value.  If the time is undefined, return zero.\n<<CPU time: public>>=\n  public :: assignment(=)\n<<CPU time: interfaces>>=\n  interface assignment(=)\n    module procedure real_assign_time\n    module procedure real_default_assign_time\n  end interface\n\n<<CPU time: procedures>>=\n  pure subroutine real_assign_time (r, time)\n    real, intent(out) :: r\n    class(time_t), intent(in) :: time\n    if (time%known) then\n       r = time%value\n    else\n       r = 0\n    end if\n  end subroutine real_assign_time\n\n  pure subroutine real_default_assign_time (r, time)\n    real(default), intent(out) :: r\n    class(time_t), intent(in) :: time\n    if (time%known) then\n       r = time%value\n    else\n       r = 0\n    end if\n  end subroutine real_default_assign_time\n\n@ %def real_assign_time\n@ Assign an integer or (single precision) real value to the time object.\n<<CPU time: time: TBP>>=\n  generic :: assignment(=) => time_assign_from_integer, time_assign_from_real\n  procedure, private :: time_assign_from_integer\n  procedure, private :: time_assign_from_real\n<<CPU time: procedures>>=\n  subroutine time_assign_from_integer (time, ival)\n    class(time_t), intent(out) :: time\n    integer, intent(in) :: ival\n    time%value = ival\n    time%known = .true.\n  end subroutine time_assign_from_integer\n\n  subroutine time_assign_from_real (time, rval)\n    class(time_t), intent(out) :: time\n    real, intent(in) :: rval\n    time%value = rval\n    time%known = .true.\n  end subroutine time_assign_from_real\n\n@ %def time_assign_from_real\n@ Add times and compute time differences.  If any input value is undefined,\nthe result is undefined.\n<<CPU time: time: TBP>>=\n  generic :: operator(-) => subtract_times\n  generic :: operator(+) => add_times\n  procedure, private :: subtract_times\n  procedure, private :: add_times\n<<CPU time: procedures>>=\n  pure function subtract_times (t_end, t_begin) result (time)\n    type(time_t) :: time\n    class(time_t), intent(in) :: t_end, t_begin\n    if (t_end%known .and. t_begin%known) then\n       time%known = .true.\n       time%value = t_end%value - t_begin%value\n    end if\n  end function subtract_times\n\n  pure function add_times (t1, t2) result (time)\n    type(time_t) :: time\n    class(time_t), intent(in) :: t1, t2\n    if (t1%known .and. t2%known) then\n       time%known = .true.\n       time%value = t1%value + t2%value\n    end if\n  end function add_times\n\n@ %def subtract_times\n@ %def add_times\n@ Check if a time is known, so we can use it:\n<<CPU time: time: TBP>>=\n  procedure :: is_known => time_is_known\n<<CPU time: procedures>>=\n  function time_is_known (time) result (flag)\n    class(time_t), intent(in) :: time\n    logical :: flag\n    flag = time%known\n  end function time_is_known\n\n@ %def time_is_known\n@ We define functions for converting the time into ss / mm:ss / hh:mm:ss\n/ dd:mm:hh:ss.\n<<CPU time: time: TBP>>=\n  generic :: expand => time_expand_s, time_expand_ms, &\n       time_expand_hms, time_expand_dhms\n  procedure, private :: time_expand_s\n  procedure, private :: time_expand_ms\n  procedure, private :: time_expand_hms\n  procedure, private :: time_expand_dhms\n<<CPU time: procedures>>=\n  subroutine time_expand_s (time, sec)\n    class(time_t), intent(in) :: time\n    integer, intent(out) :: sec\n    if (time%known) then\n       sec = time%value\n    else\n       call msg_bug (\"Time: attempt to expand undefined value\")\n    end if\n  end subroutine time_expand_s\n\n  subroutine time_expand_ms (time, min, sec)\n    class(time_t), intent(in) :: time\n    integer, intent(out) :: min, sec\n    if (time%known) then\n       if (time%value >= 0) then\n          sec = mod (int (time%value), 60)\n       else\n          sec = - mod (int (- time%value), 60)\n       end if\n       min = time%value / 60\n    else\n       call msg_bug (\"Time: attempt to expand undefined value\")\n    end if\n  end subroutine time_expand_ms\n\n  subroutine time_expand_hms (time, hour, min, sec)\n    class(time_t), intent(in) :: time\n    integer, intent(out) :: hour, min, sec\n    call time%expand (min, sec)\n    hour = min / 60\n    if (min >= 0) then\n       min = mod (min, 60)\n    else\n       min = - mod (-min, 60)\n    end if\n  end subroutine time_expand_hms\n\n  subroutine time_expand_dhms (time, day, hour, min, sec)\n    class(time_t), intent(in) :: time\n    integer, intent(out) :: day, hour, min, sec\n    call time%expand (hour, min, sec)\n    day = hour / 24\n    if (hour >= 0) then\n       hour = mod (hour, 24)\n    else\n       hour = - mod (- hour, 24)\n    end if\n  end subroutine time_expand_dhms\n\n@ %def time_expand\n@ Use the above expansions to generate a time string.\n<<CPU time: time: TBP>>=\n  procedure :: to_string_s => time_to_string_s\n  procedure :: to_string_ms => time_to_string_ms\n  procedure :: to_string_hms => time_to_string_hms\n  procedure :: to_string_dhms => time_to_string_dhms\n<<CPU time: procedures>>=\n  function time_to_string_s (time) result (str)\n    class(time_t), intent(in) :: time\n    type(string_t) :: str\n    character(256) :: buffer\n    integer :: s\n    call time%expand (s)\n    write (buffer, \"(I0,'s')\")  s\n    str = trim (buffer)\n  end function time_to_string_s\n\n  function time_to_string_ms (time, blank) result (str)\n    class(time_t), intent(in) :: time\n    logical, intent(in), optional :: blank\n    type(string_t) :: str\n    character(256) :: buffer\n    integer :: s, m\n    logical :: x_out\n    x_out = .false.\n    if (present (blank))  x_out = blank\n    call time%expand (m, s)\n    write (buffer, \"(I0,'m:',I2.2,'s')\")  m, abs (s)\n    str = trim (buffer)\n    if (x_out) then\n       str = replace (str, len(str)-1, \"X\")\n    end if\n  end function time_to_string_ms\n\n  function time_to_string_hms (time) result (str)\n    class(time_t), intent(in) :: time\n    type(string_t) :: str\n    character(256) :: buffer\n    integer :: s, m, h\n    call time%expand (h, m, s)\n    write (buffer, \"(I0,'h:',I2.2,'m:',I2.2,'s')\")  h, abs (m), abs (s)\n    str = trim (buffer)\n  end function time_to_string_hms\n\n  function time_to_string_dhms (time) result (str)\n    class(time_t), intent(in) :: time\n    type(string_t) :: str\n    character(256) :: buffer\n    integer :: s, m, h, d\n    call time%expand (d, h, m, s)\n    write (buffer, \"(I0,'d:',I2.2,'h:',I2.2,'m:',I2.2,'s')\")  &\n         d, abs (h), abs (m), abs (s)\n    str = trim (buffer)\n  end function time_to_string_dhms\n\n@ %def time_to_string\n@\n\\subsection{Timer}\nA timer can measure real (wallclock) time differences.  The base type\ncorresponds to the result, i.e., time difference.  The object contains\ntwo further times for start and stop time.\n<<CPU time: public>>=\n  public :: timer_t\n<<CPU time: types>>=\n  type, extends (time_t) :: timer_t\n     private\n     logical :: running = .false.\n     type(time_t) :: t1, t2\n   contains\n   <<CPU time: timer: TBP>>\n  end type timer_t\n\n@ %def timer_t\n@ Output.  If the timer is running, we indicate this, otherwise write\njust the result.\n<<CPU time: timer: TBP>>=\n  procedure :: write => timer_write\n<<CPU time: procedures>>=\n  subroutine timer_write (object, unit)\n    class(timer_t), intent(in) :: object\n    integer, intent(in), optional :: unit\n    integer :: u\n    u = given_output_unit (unit)\n    if (object%running) then\n       write (u, \"(1x,A)\")  \"Time in seconds = [running]\"\n    else\n       call object%time_t%write (u)\n    end if\n  end subroutine timer_write\n\n@ %def timer_write\n@ Start the timer: store the current time in the first entry and adapt\nthe status.  We forget any previous values.\n<<CPU time: timer: TBP>>=\n  procedure :: start => timer_start\n<<CPU time: procedures>>=\n  subroutine timer_start (timer)\n    class(timer_t), intent(out) :: timer\n    call timer%t1%set_current ()\n    timer%running = .true.\n  end subroutine timer_start\n\n@ %def timer_start\n@ Restart the timer: simply adapt the status, keeping the start time.\n<<CPU time: timer: TBP>>=\n  procedure :: restart => timer_restart\n<<CPU time: procedures>>=\n  subroutine timer_restart (timer)\n    class(timer_t), intent(inout) :: timer\n    if (timer%t1%known .and. .not. timer%running) then\n       timer%running = .true.\n    else\n       call msg_bug (\"Timer: restart attempt from wrong status\")\n    end if\n  end subroutine timer_restart\n\n@ %def timer_start\n@ Stop the timer: store the current time in the second entry, adapt\nthe status, and compute the elapsed time.\n<<CPU time: timer: TBP>>=\n  procedure :: stop => timer_stop\n<<CPU time: procedures>>=\n  subroutine timer_stop (timer)\n    class(timer_t), intent(inout) :: timer\n    call timer%t2%set_current ()\n    timer%running = .false.\n    call timer%evaluate ()\n  end subroutine timer_stop\n\n@ %def timer_stop\n@ Manually set the time (for unit test)\n<<CPU time: timer: TBP>>=\n  procedure :: set_test_time1 => timer_set_test_time1\n  procedure :: set_test_time2 => timer_set_test_time2\n<<CPU time: procedures>>=\n  subroutine timer_set_test_time1 (timer, t)\n    class(timer_t), intent(inout) :: timer\n    integer, intent(in) :: t\n    timer%t1 = t\n  end subroutine timer_set_test_time1\n\n  subroutine timer_set_test_time2 (timer, t)\n    class(timer_t), intent(inout) :: timer\n    integer, intent(in) :: t\n    timer%t2 = t\n  end subroutine timer_set_test_time2\n\n@ %def timer_set_test_time1\n@ %def timer_set_test_time2\n@ This is separate, available for the unit test.\n<<CPU time: timer: TBP>>=\n  procedure :: evaluate => timer_evaluate\n<<CPU time: procedures>>=\n  subroutine timer_evaluate (timer)\n    class(timer_t), intent(inout) :: timer\n    timer%time_t = timer%t2 - timer%t1\n  end subroutine timer_evaluate\n\n@ %def timer_evaluate\n@\n\\subsection{Unit tests}\nTest module, followed by the corresponding implementation module.\n<<[[cputime_ut.f90]]>>=\n<<File header>>\n\nmodule cputime_ut\n  use unit_tests\n  use cputime_uti\n\n<<Standard module head>>\n\n<<CPU time: public test>>\n\ncontains\n\n<<CPU time: test driver>>\n\nend module cputime_ut\n@ %def cputime_ut\n@\n<<[[cputime_uti.f90]]>>=\n<<File header>>\n\nmodule cputime_uti\n\n<<Use strings>>\n\n  use cputime\n\n<<Standard module head>>\n\n<<CPU time: test declarations>>\n\ncontains\n\n<<CPU time: tests>>\n\nend module cputime_uti\n@ %def cputime_ut\n@ API: driver for the unit tests below.\n<<CPU time: public test>>=\n  public :: cputime_test\n<<CPU time: test driver>>=\n  subroutine cputime_test (u, results)\n    integer, intent(in) :: u\n    type(test_results_t), intent(inout) :: results\n  <<CPU time: execute tests>>\n  end subroutine cputime_test\n\n@ %def cputime_test\n@\n\\subsubsection{Basic tests}\nCheck basic functions of the time object.  The part which we can't\ncheck is getting the actual time from the system clock, since the\noutput will not be reproducible.  However, we can check time formats\nand operations.\n<<CPU time: execute tests>>=\n  call test (cputime_1, \"cputime_1\", &\n       \"time operations\", &\n       u, results)\n<<CPU time: test declarations>>=\n  public :: cputime_1\n<<CPU time: tests>>=\n  subroutine cputime_1 (u)\n    integer, intent(in) :: u\n    type(time_t) :: time, time1, time2\n    real :: t\n    integer :: d, h, m, s\n\n    write (u, \"(A)\")  \"* Test output: cputime_1\"\n    write (u, \"(A)\")  \"*   Purpose: check time operations\"\n    write (u, \"(A)\")\n\n    write (u, \"(A)\") \"* Undefined time\"\n    write (u, *)\n\n    call time%write (u)\n\n    write (u, *)\n    write (u, \"(A)\") \"* Set time to zero\"\n    write (u, *)\n\n    time = 0\n    call time%write (u)\n\n    write (u, *)\n    write (u, \"(A)\") \"* Set time to 1.234 s\"\n    write (u, *)\n\n    time = 1.234\n    call time%write (u)\n\n    t = time\n    write (u, \"(1x,A,F6.3)\")  \"Time as real =\", t\n\n    write (u, *)\n    write (u, \"(A)\") \"* Compute time difference\"\n    write (u, *)\n\n    time1 = 5.33\n    time2 = 7.55\n    time = time2 - time1\n\n    call time1%write (u)\n    call time2%write (u)\n    call time%write (u)\n\n    write (u, *)\n    write (u, \"(A)\") \"* Compute time sum\"\n    write (u, *)\n\n    time = time2 + time1\n\n    call time1%write (u)\n    call time2%write (u)\n    call time%write (u)\n\n    write (u, *)\n    write (u, \"(A)\") \"* Expand time\"\n    write (u, *)\n\n    time1 = ((24 + 1) * 60 + 1) * 60 + 1\n    time2 = ((3 * 24 + 23) * 60 + 59) * 60 + 59\n\n    call time1%expand (s)\n    write (u, 1)  \"s =\", s\n    call time1%expand (m,s)\n    write (u, 1)  \"ms =\", m, s\n    call time1%expand (h,m,s)\n    write (u, 1)  \"hms =\", h, m, s\n    call time1%expand (d,h,m,s)\n    write (u, 1)  \"dhms =\", d, h, m, s\n\n    call time2%expand (s)\n    write (u, 1)  \"s =\", s\n    call time2%expand (m,s)\n    write (u, 1)  \"ms =\", m, s\n    call time2%expand (h,m,s)\n    write (u, 1)  \"hms =\", h, m, s\n    call time2%expand (d,h,m,s)\n    write (u, 1)  \"dhms =\", d, h, m, s\n\n    write (u, *)\n    write (u, \"(A)\") \"* Expand negative time\"\n    write (u, *)\n\n    time1 = - (((24 + 1) * 60 + 1) * 60 + 1)\n    time2 = - (((3 * 24 + 23) * 60 + 59) * 60 + 59)\n\n    call time1%expand (s)\n    write (u, 1)  \"s =\", s\n    call time1%expand (m,s)\n    write (u, 1)  \"ms =\", m, s\n    call time1%expand (h,m,s)\n    write (u, 1)  \"hms =\", h, m, s\n    call time1%expand (d,h,m,s)\n    write (u, 1)  \"dhms =\", d, h, m, s\n\n    call time2%expand (s)\n    write (u, 1)  \"s =\", s\n    call time2%expand (m,s)\n    write (u, 1)  \"ms =\", m, s\n    call time2%expand (h,m,s)\n    write (u, 1)  \"hms =\", h, m, s\n    call time2%expand (d,h,m,s)\n    write (u, 1)  \"dhms =\", d, h, m, s\n\n1   format (1x,A,1x,4(I0,:,':'))\n\n    write (u, *)\n    write (u, \"(A)\") \"* String from time\"\n    write (u, *)\n\n    time1 = ((24 + 1) * 60 + 1) * 60 + 1\n    time2 = ((3 * 24 + 23) * 60 + 59) * 60 + 59\n\n    write (u, \"(A)\")  char (time1%to_string_s ())\n    write (u, \"(A)\")  char (time1%to_string_ms ())\n    write (u, \"(A)\")  char (time1%to_string_hms ())\n    write (u, \"(A)\")  char (time1%to_string_dhms ())\n\n    write (u, \"(A)\")  char (time2%to_string_s ())\n    write (u, \"(A)\")  char (time2%to_string_ms ())\n    write (u, \"(A)\")  char (time2%to_string_hms ())\n    write (u, \"(A)\")  char (time2%to_string_dhms ())\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Blanking out the last second entry\"\n    write (u, \"(A)\")\n\n    write (u, \"(A)\")  char (time1%to_string_ms ())\n    write (u, \"(A)\")  char (time1%to_string_ms (.true.))\n\n    write (u, *)\n    write (u, \"(A)\") \"* String from negative time\"\n    write (u, *)\n\n    time1 = -(((24 + 1) * 60 + 1) * 60 + 1)\n    time2 = -(((3 * 24 + 23) * 60 + 59) * 60 + 59)\n\n    write (u, \"(A)\")  char (time1%to_string_s ())\n    write (u, \"(A)\")  char (time1%to_string_ms ())\n    write (u, \"(A)\")  char (time1%to_string_hms ())\n    write (u, \"(A)\")  char (time1%to_string_dhms ())\n\n    write (u, \"(A)\")  char (time2%to_string_s ())\n    write (u, \"(A)\")  char (time2%to_string_ms ())\n    write (u, \"(A)\")  char (time2%to_string_hms ())\n    write (u, \"(A)\")  char (time2%to_string_dhms ())\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Test output end: cputime_1\"\n\n  end subroutine cputime_1\n\n@ %def cputime_1\n@\n\\subsubsection{Timer tests}\nCheck a timer object.\n<<CPU time: execute tests>>=\n  call test (cputime_2, \"cputime_2\", &\n       \"timer\", &\n       u, results)\n<<CPU time: test declarations>>=\n  public :: cputime_2\n<<CPU time: tests>>=\n  subroutine cputime_2 (u)\n    integer, intent(in) :: u\n    type(timer_t) :: timer\n\n    write (u, \"(A)\")  \"* Test output: cputime_2\"\n    write (u, \"(A)\")  \"*   Purpose: check timer\"\n    write (u, \"(A)\")\n\n    write (u, \"(A)\") \"* Undefined timer\"\n    write (u, *)\n\n    call timer%write (u)\n\n    write (u, *)\n    write (u, \"(A)\") \"* Start timer\"\n    write (u, *)\n\n    call timer%start ()\n    call timer%write (u)\n\n    write (u, *)\n    write (u, \"(A)\") \"* Stop timer (injecting fake timings)\"\n    write (u, *)\n\n    call timer%stop ()\n    call timer%set_test_time1 (2)\n    call timer%set_test_time2 (5)\n    call timer%evaluate ()\n    call timer%write (u)\n\n    write (u, *)\n    write (u, \"(A)\") \"* Restart timer\"\n    write (u, *)\n\n    call timer%restart ()\n    call timer%write (u)\n\n    write (u, *)\n    write (u, \"(A)\") \"* Stop timer again (injecting fake timing)\"\n    write (u, *)\n\n    call timer%stop ()\n    call timer%set_test_time2 (10)\n    call timer%evaluate ()\n    call timer%write (u)\n\n    write (u, *)\n    write (u, \"(A)\")  \"* Test output end: cputime_2\"\n\n  end subroutine cputime_2\n\n@ %def cputime_2\n",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/src/system/system_dependencies.f90.in": "! WHIZARD <<Version>> <<Date>>\n! \n! Copyright (C) 1999-2020 by \n!     Wolfgang Kilian <kilian@physik.uni-siegen.de>\n!     Thorsten Ohl <ohl@physik.uni-wuerzburg.de>\n!     Juergen Reuter <juergen.reuter@desy.de>\n!     with contributions from\n!     cf. main AUTHORS file\n!\n! WHIZARD is free software; you can redistribute it and/or modify it\n! under the terms of the GNU General Public License as published by \n! the Free Software Foundation; either version 2, or (at your option)\n! any later version.\n!\n! WHIZARD is distributed in the hope that it will be useful, but\n! WITHOUT ANY WARRANTY; without even the implied warranty of\n! MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the \n! GNU General Public License for more details.\n!\n! You should have received a copy of the GNU General Public License\n! along with this program; if not, write to the Free Software\n! Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.\n!\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\nmodule system_dependencies\n\n  !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n  ! All character strings indented by 7 blanks will be automatically\n  ! split into chunks respecting the FORTRAN line length constraint by\n  ! configure.\n  !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n\n  @FC_OPENMP_HEADER@\n\n  implicit none\n  public\n \n  ! Program version\n  character(*), parameter :: WHIZARD_VERSION = \"@PACKAGE_VERSION@\"\n  character(*), parameter :: WHIZARD_DATE = \"@PACKAGE_DATE@\"\n\n  ! System paths\n  ! These are used for testing without existing installation\n  character(*), parameter :: WHIZARD_TEST_BASICS_MODPATH = &\n       \"@BUILDDIR@/src/basics\"\n  character(*), parameter :: WHIZARD_TEST_UTILITIES_MODPATH = &\n       \"@BUILDDIR@/src/utilities\"\n  character(*), parameter :: WHIZARD_TEST_COMBINATORICS_MODPATH = &\n       \"@BUILDDIR@/src/combinatorics\"\n  character(*), parameter :: WHIZARD_TEST_SYSTEM_MODPATH = &\n       \"@BUILDDIR@/src/system\"\n  character(*), parameter :: WHIZARD_TEST_PHYSICS_MODPATH = &\n       \"@BUILDDIR@/src/physics\"\n  character(*), parameter :: WHIZARD_TEST_ME_MODPATH = &\n       \"@BUILDDIR@/src/matrix_elements\"\n  character(*), parameter :: WHIZARD_TEST_MODELS_MODPATH = &\n       \"@BUILDDIR@/src/models\"\n  character(*), parameter :: WHIZARD_TEST_THRESHOLD_MODPATH = &\n       \"@BUILDDIR@/src/threshold\"\n  character(*), parameter :: WHIZARD_TEST_OMEGA_MODPATH = &\n       \"@BUILDDIR@/omega/src\"\n  character(*), parameter :: WHIZARD_TEST_MAIN_LIBPATH = &\n       \"@BUILDDIR@/src/main\"\n  character(*), parameter :: WHIZARD_TEST_OMEGA_BINPATH = &\n       \"@BUILDDIR@/omega/bin\"\n  character(*), parameter :: WHIZARD_TEST_SRC_LIBPATH = &\n       \"@BUILDDIR@/src\"\n  character(*), parameter :: WHIZARD_TEST_HEPMC_LIBPATH = &\n       \"@BUILDDIR@/src/hepmc\"\n  character(*), parameter :: WHIZARD_TEST_LCIO_LIBPATH = &\n       \"@BUILDDIR@/src/lcio\"\n  character(*), parameter :: WHIZARD_TEST_HOPPET_LIBPATH = &\n       \"@BUILDDIR@/src/hoppet\"\n  character(*), parameter :: WHIZARD_TEST_LOOPTOOLS_LIBPATH = &\n       \"@BUILDDIR@/src/looptools\"\n  character(*), parameter :: WHIZARD_TEST_MODELPATH = &\n       \"@SRCDIR@/share/models\"\n  character(*), parameter :: WHIZARD_TEST_MODELPATH_UFO = &\n       \"@SRCDIR@/share/models/UFO\"\n  character(*), parameter :: WHIZARD_TEST_MODELS_LIBPATH = &\n       \"@BUILDDIR@/src/models\"\n  character(*), parameter :: WHIZARD_TEST_SUSYPATH = &\n       \"@SRCDIR@/share/susy\"\n  character(*), parameter :: WHIZARD_TEST_GMLPATH= &\n       \"@BUILDDIR@/src/gamelan\"\n  character(*), parameter :: WHIZARD_TEST_CUTSPATH = &\n       \"@SRCDIR@/share/cuts\"\n  character(*), parameter :: WHIZARD_TEST_SHAREPATH = &\n       \"@SRCDIR@/share\"\n  character(*), parameter :: WHIZARD_TEST_TESTDATAPATH = &\n       \"@SRCDIR@/share/test\"\n  character(*), parameter :: WHIZARD_TEST_TEXPATH = &\n       \"@SRCDIR@/src/feynmf\"\n  character(*), parameter :: WHIZARD_TEST_CIRCE2PATH = &\n       \"@SRCDIR@/circe2/share/data\"\n  character(*), parameter :: WHIZARD_TEST_BEAMSIMPATH = &\n       \"@SRCDIR@/share/beam-sim\"\n  character(*), parameter :: WHIZARD_TEST_MULIPATH = &\n       \"@SRCDIR@/share/muli\"\n  character(*), parameter :: PDF_BUILTIN_TEST_DATAPATH = &\n       \"@SRCDIR@/share/pdf_builtin\"\n\n  ! WHIZARD-specific include flags\n  character(*), parameter :: WHIZARD_TEST_INCLUDES = &\n       \"-I\" // WHIZARD_TEST_MODELS_MODPATH // \" \" // &\n       \"-I\" // WHIZARD_TEST_THRESHOLD_MODPATH // \" \" // &\n       \"-I\" // WHIZARD_TEST_OMEGA_MODPATH // \" \" // &\n       \"-I\" // WHIZARD_TEST_ME_MODPATH // \" \" // &\n       \"-I\" // WHIZARD_TEST_PHYSICS_MODPATH // \" \" // &\n       \"-I\" // WHIZARD_TEST_SYSTEM_MODPATH // \" \" // &\n       \"-I\" // WHIZARD_TEST_COMBINATORICS_MODPATH // \" \" // &\n       \"-I\" // WHIZARD_TEST_UTILITIES_MODPATH // \" \" // &\n       \"-I\" // WHIZARD_TEST_BASICS_MODPATH // \" \" // &\n       \"@OPENLOOPS_INCLUDES@ @RECOLA_INCLUDES@\" \n\n  ! WHIZARD-specific link flags\n  character(*), parameter :: WHIZARD_TEST_LDFLAGS = &\n       \"-L\" // WHIZARD_TEST_MAIN_LIBPATH // \" \" // &\n       \"-L\" // WHIZARD_TEST_SRC_LIBPATH // \" \" // &\n       \"-L\" // WHIZARD_TEST_HEPMC_LIBPATH // \" \" // &\n       \"-L\" // WHIZARD_TEST_LCIO_LIBPATH // \" \" // &\n       \"-L\" // WHIZARD_TEST_HOPPET_LIBPATH // \" \" // &\n       \"-L\" // WHIZARD_TEST_LOOPTOOLS_LIBPATH // \" \" // &\n       \"-lwhizard_main -lwhizard -lomega \" // &\n       \"@RPC_CFLAGS@ \" // &\n       \"@LDFLAGS_HEPMC@ @LDFLAGS_LCIO@ @LDFLAGS_HOPPET@ \" // &\n       \"@LDFLAGS_LOOPTOOLS@ @LDFLAGS_OPENLOOPS@ \" // &\n       \"@LDFLAGS_RECOLA@\"\n\n  ! Libtool\n  character(*), parameter :: WHIZARD_LIBTOOL_TEST = &\n       \"@BUILDDIR@/libtool\"\n\n  ! System paths\n  ! These are used for the installed version\n  character(*), parameter :: PREFIX = &\n       \"@prefix@\"\n  character(*), parameter :: EXEC_PREFIX = &\n       \"@exec_prefix@\"\n  character(*), parameter :: BINDIR = &\n       \"@bindir@\"\n  character(*), parameter :: LIBDIR = &\n       \"@libdir@\"\n  character(*), parameter :: INCLUDEDIR = &\n       \"@includedir@\"\n  character(*), parameter :: DATAROOTDIR = &\n       \"@datarootdir@\"\n  character(*), parameter :: FMODDIR = &\n       \"@FMODDIR@\"\n\n  character(*), parameter :: PKGLIBDIR = LIBDIR  // \"/whizard\"\n  character(*), parameter :: PKGDATADIR = DATAROOTDIR // \"/whizard\"\n  character(*), parameter :: PKGTEXDIR = DATAROOTDIR // \"/texmf/whizard\"\n  character(*), parameter :: PKGCIRCE2DIR = DATAROOTDIR // \"/circe2\"\n\n  character(*), parameter :: WHIZARD_MODPATH = &\n       FMODDIR // \"/whizard\"\n  character(*), parameter :: OMEGA_MODPATH = &\n       FMODDIR // \"/omega\"\n  character(*), parameter :: MODELS_MODPATH = &\n       FMODDIR // \"/models\"\n  character(*), parameter :: WHIZARD_OMEGA_BINPATH = &\n       BINDIR\n  character(*), parameter :: WHIZARD_OMEGA_LIBPATH = &\n       LIBDIR\n  character(*), parameter :: WHIZARD_MODELPATH = &\n       PKGDATADIR // \"/models\"\n  character(*), parameter :: WHIZARD_MODELPATH_UFO = &\n       PKGDATADIR // \"/models/UFO\"\n  character(*), parameter :: WHIZARD_MODELS_LIBPATH = &\n       PKGLIBDIR // \"/models\"\n  character(*), parameter :: WHIZARD_SUSYPATH = &\n       PKGDATADIR // \"/susy\"\n  character(*), parameter :: WHIZARD_GMLPATH= &\n       PKGLIBDIR // \"/gamelan\"\n  character(*), parameter :: WHIZARD_SHAREPATH = &\n       PKGDATADIR\n  character(*), parameter :: WHIZARD_TESTDATAPATH = &\n       PKGDATADIR // \"/test\"\n  character(*), parameter :: WHIZARD_CUTSPATH = &\n       PKGDATADIR // \"/cuts\"\n  character(*), parameter :: WHIZARD_TEXPATH = &\n       PKGTEXDIR\n  character(*), parameter :: WHIZARD_CIRCE2PATH = &\n       PKGCIRCE2DIR // \"/data\"\n  character(*), parameter :: WHIZARD_BEAMSIMPATH = &\n       PKGDATADIR // \"/beam-sim\"\n  character(*), parameter :: WHIZARD_MULIPATH = &\n       PKGDATADIR // \"/muli\"\n  character(*), parameter :: PDF_BUILTIN_DATAPATH = &\n       PKGDATADIR // \"/pdf_builtin\"\n\n  ! WHIZARD-specific include flags\n  character(*), parameter :: WHIZARD_INCLUDES = &\n      \"-I\" // WHIZARD_MODPATH // \" \" // &\n      \"-I\" // OMEGA_MODPATH // \" \" // &\n      \"-I\" // MODELS_MODPATH // \" \" // &\n       \"@OPENLOOPS_INCLUDES@ @RECOLA_INCLUDES@\"\n\n  ! WHIZARD-specific link flags\n  character(*), parameter :: WHIZARD_LDFLAGS = &\n      \"-L\" // WHIZARD_OMEGA_LIBPATH // \" \" // &\n      \"-lwhizard_main -lwhizard -lomega \" // &\n       \"@RPC_CFLAGS@ \" // &\n       \"@LDFLAGS_HEPMC@ @LDFLAGS_LCIO@ @LDFLAGS_HOPPET@ \" // &\n       \"@LDFLAGS_LOOPTOOLS@ @LDFLAGS_OPENLOOPS@ \" // &\n       \"@LDFLAGS_RECOLA@\"\n\n  ! Libtool\n  character(*), parameter :: WHIZARD_LIBTOOL = &\n      PKGLIBDIR // \"/libtool\"\n\n\n  ! Fortran compiler\n  character(*), parameter :: DEFAULT_FC = &\n       \"@FC@\"\n  character(*), parameter :: DEFAULT_FCFLAGS = &\n       \"@FCFLAGS_PROFILING@ @FCFLAGS_OPENMP@ @FCFLAGS_MPI@ @FCFLAGS@\"\n  character(*), parameter :: DEFAULT_FCFLAGS_PIC = &\n       \"@FCFLAGS_PIC@\"\n  character(*), parameter :: DEFAULT_FC_SRC_EXT = &\n       \".@FC_SRC_EXT@\"\n  character(*), parameter :: DEFAULT_FC_PRECISION = &\n       \"@FC_PRECISION@\"\n  character(*), parameter :: FCLIBS = &\n       \"@FCLIBS@\"\n\n  logical, parameter      :: OS_IS_DARWIN = @OS_IS_DARWIN@\n  \n  ! C compiler\n  character(*), parameter :: DEFAULT_CC = &\n       \"@CC@\"\n  character(*), parameter :: DEFAULT_CFLAGS = &\n       \"@CFLAGS@\"\n  character(*), parameter :: DEFAULT_CFLAGS_PIC = &\n       \"@CFLAGS_PIC@\"\n  logical, parameter :: CC_IS_GNU = @CC_IS_GNU@\n  logical, parameter :: CC_HAS_QUADMATH = @CC_HAS_QUADMATH@\n\n  ! C++ compiler\n  character(*), parameter :: DEFAULT_CXX = &\n       \"@CXX@\"\n  character(*), parameter :: DEFAULT_CXXFLAGS = &\n       \"@CXXFLAGS@\"\n  character(*), parameter :: DEFAULT_CXXLIBS = &\n       \"@CXXLIBS@\"\n\n  ! Object files\n  character(*), parameter :: DEFAULT_OBJ_EXT = &\n       \".@OBJ_EXT@\"\n\n  ! Linker\n  character(*), parameter :: DEFAULT_LD = &\n       \"@LD@\"\n  character(*), parameter :: DEFAULT_LDFLAGS = &\n       \"\"\n  character(*), parameter :: DEFAULT_LDFLAGS_SO = \"-shared\"\n  character(*), parameter :: DEFAULT_LDFLAGS_STATIC = &\n       \"@LDFLAGS_STATIC@\"\n  character(*), parameter :: DEFAULT_LDFLAGS_HEPMC = &\n       \"@LDFLAGS_HEPMC@\"\n  character(*), parameter :: DEFAULT_LDFLAGS_LCIO = &\n       \"@LDFLAGS_LCIO@\"\n  character(*), parameter :: DEFAULT_LDFLAGS_HOPPET = &\n       \"@LDFLAGS_HOPPET@\"\n  character(*), parameter :: DEFAULT_LDFLAGS_LOOPTOOLS = &\n       \"@LDFLAGS_LOOPTOOLS@\"\n  character(*), parameter :: DEFAULT_SHRLIB_EXT = \"@SHRLIB_EXT@\"\n  character(*), parameter :: DEFAULT_FC_SHRLIB_EXT = \"so\"\n\n  ! Pack/unpack\n  character(*), parameter :: DEFAULT_PACK_CMD = \"tar -czf\"\n  character(*), parameter :: DEFAULT_UNPACK_CMD = \"tar -xzf\"\n  character(*), parameter :: DEFAULT_PACK_EXT = \".tgz\"\n\n  ! Make\n  character(*), parameter :: DEFAULT_MAKEFLAGS = &\n       \"@DEFAULT_MAKEFLAGS@\"\n\n  ! LHAPDF library\n  character(*), parameter :: LHAPDF_PDFSETS_PATH = &\n       \"@LHAPDF_PDFSETS_PATH@\"\n\n  ! Available methods for event analysis display\n  character(*), parameter :: EVENT_ANALYSIS = &\n       \"@EVENT_ANALYSIS@\"\n  character(*), parameter :: EVENT_ANALYSIS_PS = &\n       \"@EVENT_ANALYSIS_PS@\"\n  character(*), parameter :: EVENT_ANALYSIS_PDF = &\n       \"@EVENT_ANALYSIS_PDF@\"\n\n  ! Programs used for event analysis display\n  character(*), parameter :: PRG_LATEX  = &\n       \"@LATEX@\"\n  character(*), parameter :: PRG_MPOST  = &\n       \"@MPOST@\"\n  character(*), parameter :: PRG_DVIPS  = &\n       \"@DVIPS@\"\n  character(*), parameter :: PRG_PS2PDF = &\n       \"@PS2PDF@\"\n\n  ! Programs and libraries used for NLO calculations\n  ! GoSam\n  character(*), parameter :: GOSAM_DIR = &\n       \"@GOSAM_DIR@\"\n  character(*), parameter :: GOLEM_DIR = &\n       \"@GOLEM_DIR@\"\n  character(*), parameter :: FORM_DIR = &\n       \"@FORM_DIR@\"\n  character(*), parameter :: QGRAF_DIR = &\n       \"@QGRAF_DIR@\"\n  character(*), parameter :: NINJA_DIR = &\n       \"@NINJA_DIR@\"\n  character(*), parameter :: SAMURAI_DIR = &\n       \"@SAMURAI_DIR@\"\n\n  ! OpenLoops\n  character(*), parameter :: OPENLOOPS_DIR = &\n       \"@OPENLOOPS_DIR@\"\n  character(*), parameter :: RECOLA_DIR = &\n       \"@RECOLA_DIR@\"  \n\n  ! Hardwired options for batch-mode processing\n  character(*), parameter :: OPT_LATEX  = &\n       \"-halt-on-error\"\n  character(*), parameter :: OPT_MPOST  = &\n       \"@MPOSTFLAG@ -halt-on-error\"\n\n  ! dlopen parameters\n  integer, parameter :: &\n     RTLD_LAZY   = @RTLD_LAZY_VALUE@ , &\n     RTLD_NOW    = @RTLD_NOW_VALUE@ , &\n     RTLD_GLOBAL = @RTLD_GLOBAL_VALUE@ , &\n     RTLD_LOCAL  = @RTLD_LOCAL_VALUE@\n\n  ! Misc\n  logical, parameter :: MPOST_AVAILABLE = @MPOST_AVAILABLE_FLAG@\n\n  logical, parameter :: LHAPDF5_AVAILABLE = @LHAPDF5_AVAILABLE_FLAG@\n  logical, parameter :: LHAPDF6_AVAILABLE = @LHAPDF6_AVAILABLE_FLAG@\n  logical, parameter :: HEPMC2_AVAILABLE = @HEPMC2_AVAILABLE_FLAG@\n  logical, parameter :: HEPMC3_AVAILABLE = @HEPMC3_AVAILABLE_FLAG@\n  logical, parameter :: LCIO_AVAILABLE = \"@LCIO_AVAILABLE_FLAG@\" == \"yes\"\n  logical, parameter :: HOPPET_AVAILABLE = @HOPPET_AVAILABLE_FLAG@\n\n  logical, parameter :: PYTHIA6_AVAILABLE = @PYTHIA6_AVAILABLE_FLAG@\n  logical, parameter :: PYTHIA8_AVAILABLE = @PYTHIA8_AVAILABLE_FLAG@\n\n  logical, parameter :: GOSAM_AVAILABLE = @GOSAM_AVAILABLE_FLAG@\n  logical, parameter :: OPENLOOPS_AVAILABLE = @OPENLOOPS_AVAILABLE_FLAG@\n  logical, parameter :: RECOLA_AVAILABLE = @RECOLA_AVAILABLE_FLAG@  \n\ncontains\n\n  ! Subroutines that depend on configure settings\n\n  ! OpenMP wrapper routines, work independent of OpenMP status\n  function openmp_is_active () result (flag)\n    logical :: flag\n@FC_OPENMP_ON@    flag = .true.\n@FC_OPENMP_OFF@    flag = .false.\n  end function openmp_is_active\n\n  subroutine openmp_set_num_threads (num)\n    integer, intent(in) :: num\n@FC_OPENMP_ON@    call omp_set_num_threads (num)\n  end subroutine openmp_set_num_threads\n  \n  function openmp_get_num_threads () result (num)\n    integer :: num\n@FC_OPENMP_ON@    num = omp_get_num_threads ()\n@FC_OPENMP_OFF@    num = 1\n  end function openmp_get_num_threads\n  \n  function openmp_get_max_threads () result (num)\n    integer :: num\n@FC_OPENMP_ON@    num = omp_get_max_threads ()\n@FC_OPENMP_OFF@    num = 1\n  end function openmp_get_max_threads\n  \n  function openmp_get_default_max_threads () result (num)\n    integer :: num\n    num = @FC_OPENMP_DEFAULT_MAX_THREADS@\n  end function openmp_get_default_max_threads\n\nend module system_dependencies\n",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/src/matrix_elements/matrix_elements.nw": "% -*- ess-noweb-default-code-mode: f90-mode; noweb-default-code-mode: f90-mode; -*-\n% WHIZARD code as NOWEB source: matrix elements and process libraries\n\\chapter{Matrix Element Handling}\n\\includemodulegraph{matrix_elements}\n\nIn this chapter, we support internal and external matrix elements:\ninitialization, automatic generation where necessary, and numerical\nevaluation.  We provide the interface for code generation and linking.\nMatrix-element code is organized in processes and process libraries.\n\\begin{description}\n\\item[process\\_constants]\n  A record of static process properties, for easy transfer between\n  various \\whizard\\ modules.\n\\item[prclib\\_interfaces]\n  This module deals with matrix-element code which is accessible via\n  external libraries (Fortran libraries or generic C-compatible\n  libraries) and must either be generated by the program or provided\n  by the user explicitly.\n\n  The module defines and uses an abstract type [[prc_writer_t]] and two\n  abstract extensions, one for a Fortran module and one for a C-compatible\n  library.   The implementation provides the specific methods for writing the\n  appropriate parts in external matrix element code.\n\\item[prc\\_core\\_def]\n  This module defines the abstract types [[prc_core_def_t]] and\n  [[prc_driver_t]].  The implementation of the former provides the\n  configuration for processes of a certain class, while the latter accesses\n  the corresponding matrix element, in particular those generated by the\n  appropriate [[prc_writer_t]] object.\n\\item[process\\_libraries]\n  This module combines the functionality of\n  the previous module with the means for holding processes definitions\n  (the internal counterpart of appropriate declarations in the user\n  interface), for handling matrix elements which do not need external\n  code, and for accessing the matrix elements by the procedures for\n  matrix-element evaluation, integration and event generation.\n\\item[prclib\\_stacks]\n  Collect process libraries.\n\\item[test\\_me] This module provides a test implementation for the abstract\n  types in the [[prc_core_def]] module.  The implementation is intended for\n  self-tests of several later modules.  The implementation is internal, i.e.,\n  no external code has is generated.\n\\end{description}\nAll data structures which are specific for a particular way of\ngenerating code or evaluating matrix element are kept abstract and\nthus generic.  Later modules such as [[prc_omega]] provide\nimplementations, in the form of type extensions for the various\nabstract types.\n\n\\clearpage\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\\section{Process data block}\n\nWe define a simple transparent type that contains universal constant\nprocess data.  We will reference objects of this type for the\nphase-space setup, for interfacing with process libraries, for\nimplementing matrix-element generation, and in the master\nprocess-handling module.\n<<[[process_constants.f90]]>>=\n<<File header>>\n\nmodule process_constants\n\n<<Use kinds>>\n<<Use strings>>\n\n  use io_units, only: given_output_unit, free_unit\n  use format_utils, only: write_integer_array\n  use md5, only: md5sum\n\n  use pdg_arrays\n\n<<Standard module head>>\n\n<<Process Constants: public>>\n\n<<Process Constants: types>>\n\ncontains\n\n<<Process Constants: procedures>>\n\nend module process_constants\n@ %def process_constants\n@\nThe data type is just a block of public objects, only elementary\ntypes, no type-bound procedures.\n<<Process Constants: public>>=\n  public :: process_constants_t\n<<Process Constants: types>>=\n  type :: process_constants_t\n     type(string_t) :: id\n     type(string_t) :: model_name\n     character(32) :: md5sum = \"\"\n     logical :: openmp_supported = .false.\n     integer :: n_in  = 0\n     integer :: n_out = 0\n     integer :: n_flv = 0\n     integer :: n_hel = 0\n     integer :: n_col = 0\n     integer :: n_cin = 0\n     integer :: n_cf  = 0\n     integer, dimension(:,:), allocatable :: flv_state\n     integer, dimension(:,:), allocatable :: hel_state\n     integer, dimension(:,:,:), allocatable :: col_state\n     logical, dimension(:,:), allocatable :: ghost_flag\n     complex(default), dimension(:), allocatable :: color_factors\n     integer, dimension(:,:), allocatable :: cf_index\n     integer, dimension(:), allocatable :: eqv_flv_index\n     integer, dimension(:), allocatable :: eqv_hel_index\n  contains\n  <<Process Constants: process constants: TBP>>\n  end type process_constants_t\n\n@ %def process_constants_t\n@\n<<Process Constants: process constants: TBP>>=\n  procedure :: get_n_tot => process_constants_get_n_tot\n<<Process Constants: procedures>>=\n  elemental function process_constants_get_n_tot (prc_const) result (n_tot)\n    integer :: n_tot\n    class(process_constants_t), intent(in) :: prc_const\n    n_tot = prc_const%n_in + prc_const%n_out\n  end function process_constants_get_n_tot\n\n@ %def process_constants_get_n_tot\n@\n<<Process Constants: process constants: TBP>>=\n  procedure :: get_flv_state => process_constants_get_flv_state\n<<Process Constants: procedures>>=\n  subroutine process_constants_get_flv_state (prc_const, flv_state)\n    class(process_constants_t), intent(in) :: prc_const\n    integer, dimension(:,:), allocatable, intent(out) :: flv_state\n    allocate (flv_state (size (prc_const%flv_state, 1), &\n         size (prc_const%flv_state, 2)))\n    flv_state = prc_const%flv_state\n  end subroutine process_constants_get_flv_state\n\n@ %def process_constants_get_flv_state\n@\n<<Process Constants: process constants: TBP>>=\n  procedure :: get_n_flv => process_constants_get_n_flv\n<<Process Constants: procedures>>=\n  function process_constants_get_n_flv (data) result (n_flv)\n    integer :: n_flv\n    class(process_constants_t), intent(in) :: data\n    n_flv = data%n_flv\n  end function process_constants_get_n_flv\n\n@ %def process_constants_get_n_flv\n@\n<<Process Constants: process constants: TBP>>=\n  procedure :: get_n_hel => process_constants_get_n_hel\n<<Process Constants: procedures>>=\n  function process_constants_get_n_hel (data) result (n_hel)\n    integer :: n_hel\n    class(process_constants_t), intent(in) :: data\n    n_hel = data%n_hel\n  end function process_constants_get_n_hel\n\n@ %def process_constants_get_n_flv\n@\n<<Process Constants: process constants: TBP>>=\n  procedure :: get_hel_state => process_constants_get_hel_state\n<<Process Constants: procedures>>=\n  subroutine process_constants_get_hel_state (prc_const, hel_state)\n    class(process_constants_t), intent(in) :: prc_const\n    integer, dimension(:,:), allocatable, intent(out) :: hel_state\n    allocate (hel_state (size (prc_const%hel_state, 1), &\n         size (prc_const%hel_state, 2)))\n    hel_state = prc_const%hel_state\n  end subroutine process_constants_get_hel_state\n\n@ %def process_constants_get_hel_state\n@\n<<Process Constants: process constants: TBP>>=\n  procedure :: get_col_state => process_constants_get_col_state\n<<Process Constants: procedures>>=\n  subroutine process_constants_get_col_state (prc_const, col_state)\n    class(process_constants_t), intent(in) :: prc_const\n    integer, dimension(:,:,:), allocatable, intent(out) :: col_state\n    allocate (col_state (size (prc_const%col_state, 1), &\n         size (prc_const%col_state, 2), size (prc_const%col_state, 3)))\n    col_state = prc_const%col_state\n  end subroutine process_constants_get_col_state\n\n@ %def process_constants_get_col_state\n@\n<<Process Constants: process constants: TBP>>=\n  procedure :: get_ghost_flag => process_constants_get_ghost_flag\n<<Process Constants: procedures>>=\n  subroutine process_constants_get_ghost_flag (prc_const, ghost_flag)\n    class(process_constants_t), intent(in) :: prc_const\n    logical, dimension(:,:), allocatable, intent(out) :: ghost_flag\n    allocate (ghost_flag (size (prc_const%ghost_flag, 1), &\n         size (prc_const%ghost_flag, 2)))\n    ghost_flag = prc_const%ghost_flag\n  end subroutine process_constants_get_ghost_flag\n\n@ %def process_constants_get_ghost_flag\n@\n<<Process Constants: process constants: TBP>>=\n  procedure :: get_color_factors => process_constants_get_color_factors\n<<Process Constants: procedures>>=\n  subroutine process_constants_get_color_factors (prc_const, col_facts)\n    class(process_constants_t), intent(in) :: prc_const\n    complex(default), dimension(:), allocatable, intent(out) :: col_facts\n    allocate (col_facts (size (prc_const%color_factors)))\n    col_facts = prc_const%color_factors\n  end subroutine process_constants_get_color_factors\n\n@ %def process_constants_get_color_factors\n@\n<<Process Constants: process constants: TBP>>=\n  procedure :: get_cf_index => process_constants_get_cf_index\n<<Process Constants: procedures>>=\n  subroutine process_constants_get_cf_index (prc_const, cf_index)\n    class(process_constants_t), intent(in) :: prc_const\n    integer, intent(out), dimension(:,:), allocatable :: cf_index\n    allocate (cf_index (size (prc_const%cf_index, 1), &\n         size (prc_const%cf_index, 2)))\n    cf_index = prc_const%cf_index\n  end subroutine process_constants_get_cf_index\n\n@ %def process_constants_get_cf_index\n@\n<<Process Constants: process constants: TBP>>=\n  procedure :: set_flv_state => process_constants_set_flv_state\n<<Process Constants: procedures>>=\n  subroutine process_constants_set_flv_state (prc_const, flv_state)\n    class(process_constants_t), intent(inout) :: prc_const\n    integer, intent(in), dimension(:,:), allocatable :: flv_state\n    if (allocated (prc_const%flv_state)) deallocate (prc_const%flv_state)\n    allocate (prc_const%flv_state (size (flv_state, 1), &\n         size (flv_state, 2)))\n    prc_const%flv_state = flv_state\n    prc_const%n_flv = size (flv_state, 2)\n  end subroutine process_constants_set_flv_state\n\n@ %def process_constants_set_flv_state\n@\n<<Process Constants: process constants: TBP>>=\n  procedure :: set_col_state => process_constants_set_col_state\n<<Process Constants: procedures>>=\n  subroutine process_constants_set_col_state (prc_const, col_state)\n    class(process_constants_t), intent(inout) :: prc_const\n    integer, intent(in), dimension(:,:,:), allocatable :: col_state\n    allocate (prc_const%col_state (size (col_state, 1), &\n         size (col_state, 2), size (col_state, 3)))\n    prc_const%col_state = col_state\n  end subroutine process_constants_set_col_state\n\n@ %def process_constants_set_col_state\n@\n<<Process Constants: process constants: TBP>>=\n  procedure :: set_cf_index => process_constants_set_cf_index\n<<Process Constants: procedures>>=\n  subroutine process_constants_set_cf_index (prc_const, cf_index)\n    class(process_constants_t), intent(inout) :: prc_const\n    integer, dimension(:,:), intent(in), allocatable :: cf_index\n    allocate (prc_const%cf_index (size (cf_index, 1), &\n         size (cf_index, 2)))\n    prc_const%cf_index = cf_index\n  end subroutine process_constants_set_cf_index\n\n@ %def process_constants_set_cf_index\n@\n<<Process Constants: process constants: TBP>>=\n  procedure :: set_color_factors => process_constants_set_color_factors\n<<Process Constants: procedures>>=\n  subroutine process_constants_set_color_factors (prc_const, color_factors)\n    class(process_constants_t), intent(inout) :: prc_const\n    complex(default), dimension(:), intent(in), allocatable :: color_factors\n    allocate (prc_const%color_factors (size (color_factors)))\n    prc_const%color_factors = color_factors\n  end subroutine process_constants_set_color_factors\n\n@ %def process_constants_set_color_factors\n@\n<<Process Constants: process constants: TBP>>=\n  procedure :: set_ghost_flag => process_constants_set_ghost_flag\n<<Process Constants: procedures>>=\n  subroutine process_constants_set_ghost_flag (prc_const, ghost_flag)\n    class(process_constants_t), intent(inout) :: prc_const\n    logical, dimension(:,:), allocatable, intent(in) :: ghost_flag\n    allocate (prc_const%ghost_flag (size (ghost_flag, 1), &\n         size (ghost_flag, 2)))\n    prc_const%ghost_flag = ghost_flag\n  end subroutine process_constants_set_ghost_flag\n@ %def process_constants_set_ghost_flag\n@\n<<Process Constants: process constants: TBP>>=\n  procedure :: get_pdg_in => process_constants_get_pdg_in\n<<Process Constants: procedures>>=\n  function process_constants_get_pdg_in (prc_const) result (pdg_in)\n    type(pdg_array_t), dimension(:), allocatable :: pdg_in\n    class(process_constants_t), intent(in) :: prc_const\n    type(pdg_array_t) :: pdg_tmp\n    integer :: i\n    allocate (pdg_in (prc_const%n_in))\n    do i = 1, prc_const%n_in\n       pdg_tmp = prc_const%flv_state(i,:)\n       pdg_in(i) = sort_abs (pdg_tmp, unique = .true.)\n    end do\n  end function process_constants_get_pdg_in\n\n@ %def process_constants_get_pdg_in\n@\n<<Process Constants: process constants: TBP>>=\n  procedure :: compute_md5sum => process_constants_compute_md5sum\n<<Process Constants: procedures>>=\n  subroutine process_constants_compute_md5sum (prc_const, include_id)\n    class(process_constants_t), intent(inout) :: prc_const\n    logical, intent(in) :: include_id\n    integer :: unit\n    unit = prc_const%fill_unit_for_md5sum (include_id)\n    rewind (unit)\n    prc_const%md5sum = md5sum (unit)\n    close (unit)\n  end subroutine process_constants_compute_md5sum\n\n@ %process_constants_compute_md5sum\n@\n<<Process Constants: process constants: TBP>>=\n  procedure :: fill_unit_for_md5sum => process_constants_fill_unit_for_md5sum\n<<Process Constants: procedures>>=\n  function process_constants_fill_unit_for_md5sum (prc_const, include_id) result (unit)\n    integer :: unit\n    class(process_constants_t), intent(in) :: prc_const\n    logical, intent(in) :: include_id\n    integer :: i, j, k\n    unit = free_unit ()\n    open (unit, status=\"scratch\", action=\"readwrite\")\n    if (include_id) write (unit, '(A)') char (prc_const%id)\n    write (unit, '(A)') char (prc_const%model_name)\n    write (unit, '(L1)') prc_const%openmp_supported\n    write (unit, '(I0)') prc_const%n_in\n    write (unit, '(I0)') prc_const%n_out\n    write (unit, '(I0)') prc_const%n_flv\n    write (unit, '(I0)') prc_const%n_hel\n    write (unit, '(I0)') prc_const%n_col\n    write (unit, '(I0)') prc_const%n_cin\n    write (unit, '(I0)') prc_const%n_cf\n    do i = 1, size (prc_const%flv_state, dim=1)\n       do j = 1, size (prc_const%flv_state, dim=2)\n          write (unit, '(I0)') prc_const%flv_state (i, j)\n       end do\n    end do\n    do i = 1, size (prc_const%hel_state, dim=1)\n       do j = 1, size (prc_const%hel_state, dim=2)\n          write (unit, '(I0)') prc_const%hel_state (i, j)\n       end do\n    end do\n    do i = 1, size (prc_const%col_state, dim=1)\n       do j = 1, size (prc_const%col_state, dim=2)\n          do k = 1, size (prc_const%col_state, dim=3)\n             write (unit, '(I0)') prc_const%col_state (i, j, k)\n          end do\n      end do\n    end do\n    do i = 1, size (prc_const%ghost_flag, dim=1)\n       do j = 1, size (prc_const%ghost_flag, dim=2)\n          write (unit, '(L1)') prc_const%ghost_flag (i, j)\n       end do\n    end do\n    do i = 1, size (prc_const%color_factors)\n       write (unit, '(F0.0,F0.0)') real (prc_const%color_factors(i)), &\n          aimag (prc_const%color_factors(i))\n    end do\n    do i = 1, size (prc_const%cf_index, dim=1)\n       do j = 1, size (prc_const%cf_index, dim=2)\n          write (unit, '(I0)') prc_const%cf_index(i, j)\n       end do\n    end do\n  end function process_constants_fill_unit_for_md5sum\n\n@ %def process_constants_fill_unit_for_md5sum\n@\n<<Process Constants: process constants: TBP>>=\n  procedure :: write => process_constants_write\n<<Process Constants: procedures>>=\n  subroutine process_constants_write (prc_const, unit)\n    class(process_constants_t), intent(in) :: prc_const\n    integer, intent(in), optional :: unit\n    integer :: u, i\n    u = given_output_unit (unit)\n    write (u, \"(1x,A,A)\") \"Process data of id: \", char (prc_const%id)\n    write (u, \"(1x,A,A)\") \"Associated model: \", char (prc_const%model_name)\n    write (u, \"(1x,A,I0)\") \"n_in: \", prc_const%n_in\n    write (u, \"(1x,A,I0)\") \"n_out: \", prc_const%n_out\n    write (u, \"(1x,A,I0)\") \"n_flv: \", prc_const%n_flv\n    write (u, \"(1x,A,I0)\") \"n_hel: \", prc_const%n_hel\n    write (u, \"(1x,A,I0)\") \"n_col: \", prc_const%n_col\n    write (u, \"(1x,A,I0)\") \"n_cin: \", prc_const%n_cin\n    write (u, \"(1x,A,I0)\") \"n_cf: \", prc_const%n_cf\n    write (u, \"(1x,A)\") \"Flavors: \"\n    do i = 1, prc_const%n_flv\n       write (u, \"(1x,A,I0)\") \"i_flv: \", i\n       call write_integer_array (prc_const%flv_state (:,i))\n    end do\n  end subroutine process_constants_write\n\n@ %def process_constants_write\n@\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\\section{Process library interface}\n\nThe module [[prclib_interfaces]] handles external matrix-element code.\n\n\n\\subsection{Overview}\nThe top-level data structure is the [[prclib_driver_t]] data type.\nThe associated type-bound procedures deal with the generation of\nexternal code, compilation and linking, and accessing the active\nexternal library.\n\nAn object of type [[prclib_driver_t]] consists of the following parts:\n\\begin{enumerate}\n\\item\\ Metadata that identify name and status of the library driver,\n  etc.\n\\item\\ An array of process records ([[prclib_driver_record_t]]), one\n  for each external matrix element.\n\\item\\ A record of type [[dlaccess_t]] which handles the\n  operating-system part of linking a dynamically loadable library.\n\\item\\ A collection of procedure pointers which have a counterpart in\n  the external library interface.  Given the unique identifier of a\n  matrix element, the procedures retrieve generic matrix-element\n  information such as the particle content and helicity combination\n  tables.  There is also a procedure which returns pointers to the\n  more specific procedures that a matrix element provides, called\n  \\emph{features}.\n\\end{enumerate}\n\nThe process records of type [[prclib_driver_record_t]] handle the\nindividual matrix elements.  Each record identifies a process by name\n([[id]]), names the physics model to be loaded for this process, lists\nthe features that the associated matrix-element code provides, and\nholds a [[writer]] object which handles all operations that depend on\nthe process type.  The numbering of process records is identical to\nthe numbering of matrix-element codes in the external library.\n\nThe writer object is of abstract type [[prc_writer_t]].  The module\ndefines two basic, also abstract, extensions:\n[[prc_writer_f_module_t]] and [[prc_writer_c_lib_t]].  The first\nversion is for matrix-element code that is available in form of\nFortran modules.  The writer contains type-bound procedures which\ncreate appropriate [[use]] directives and [[C]]-compatible wrapper\nfunctions for the given set of Fortran modules and their features.\nThe second version is for matrix-element code that is available in\nform of a C-compatible library (this includes Fortran libraries with\nproper C bindings).  The writer needs not write wrapper function, but\nexplicit interface blocks for the matrix-element features.\n\nEach matrix-element variant is encoded in an appropriate extension of\n[[prc_writer_t]].  For instance, \\oMega\\ matrix elements provide an\nimplementation [[omega_writer_t]] which extends\n[[prc_writer_f_module_t]].\n\n\\subsection{Workflow}\nWe expect that the functionality provided by this module is called in\nthe following order:\n\\begin{enumerate}\n\\item\n  The caller initializes the [[prclib_driver_t]] object and fills the\n  array of [[prclib_record_t]] entries with the appropriate process\n  data and process-specific writer objects.\n\\item\n  It calls the [[generate_makefile]] method to set up an appropriate\n  makefile in the current directory.  The makefile will handle source\n  generation, compilation and linking both for the individual matrix\n  elements (unless this has to be done manually) and for the common\n  external driver code which interfaces those matrix element.\n\\item\n  The [[generate_driver_code]] writes the common driver as source code\n  to file.\n\\item\n  The methods [[make_source]], [[make_compile]], and [[make_link]]\n  individually perform the corresponding steps in building the\n  library.   Wherever possible, they simply use the generated makefile.\n  By calling [[make]], we make sure that we can avoid\n  unnecessary recompilation.  For the\n  compilation and linking steps, the makefile will employ [[libtool]].\n\\item\n  The [[load]] method loads the library procedures into the\n  corresponding procedure pointers, using the [[dlopen]] mechanism via\n  the [[dlaccess]] subobject.\n\\end{enumerate}\n\n\\subsection{The module}\n<<[[prclib_interfaces.f90]]>>=\n<<File header>>\n\nmodule prclib_interfaces\n\n  use, intrinsic :: iso_c_binding !NODEP!\n\n  use kinds\n<<Use strings>>\n  use io_units\n  use system_defs, only: TAB\n  use string_utils, only: lower_case\n  use diagnostics\n  use os_interface\n\n<<Standard module head>>\n\n<<Prclib interfaces: public>>\n\n<<Prclib interfaces: types>>\n\n<<Prclib interfaces: interfaces>>\n\ncontains\n\n<<Prclib interfaces: procedures>>\n\nend module prclib_interfaces\n@ %def prclib_interfaces\n@\n\\subsection{Writers}\nExternal matrix element code provides externally visible procedures,\nwhich we denote as \\emph{features}.  The features consist of\ninformational subroutines and functions which are mandatory (universal\nfeatures) and matrix-element specific subroutines and functions\n(specific features).  The driver interfaces the\ngeneric features directly, while it returns the specific features in\nform of bind(C) procedure pointers to the caller.  For instance,\nfunction [[n_in]] is generic, while the matrix matrix-element value\nitself is specific.\n\nTo implement these tasks, the driver needs [[use]] directives for\nFortran module procedures, interface blocks for other external stuff,\nwrapper code, and Makefile snippets.\n\n\\subsubsection{Generic writer}\nIn the [[prc_writer_t]] data type, we collect the procedures which\nimplement the writing tasks.  The type is abstract.  The\nconcrete implementations are defined by an extension which is specific\nfor the process type.\n\nThe MD5 sum stored here should be the MD5 checksum of the current process\ncomponent, which can be calculated once the process is configured completely.\nIt can be used by implementations which work with external files, such as\n\\oMega.\n<<Prclib interfaces: public>>=\n  public :: prc_writer_t\n<<Prclib interfaces: types>>=\n  type, abstract :: prc_writer_t\n     character(32) :: md5sum = \"\"\n   contains\n   <<Prclib interfaces: prc writer: TBP>>\n  end type prc_writer_t\n\n@ %def prc_writer_t\n@ In any case, it is useful to have a string representation of the\nwriter type.  This must be implemented by all extensions.\n<<Prclib interfaces: prc writer: TBP>>=\n  procedure(get_const_string), nopass, deferred :: type_name\n<<Prclib interfaces: interfaces>>=\n  abstract interface\n     function get_const_string () result (string)\n       import\n       type(string_t) :: string\n     end function get_const_string\n  end interface\n\n@ %def get_const_string\n@ Return the name of a procedure that implements a given feature, as\nit is provided by the external matrix-element code.  For a reasonable\ndefault, we take the feature name unchanged.\n<<Prclib interfaces: prc writer: TBP>>=\n  procedure, nopass :: get_procname => prc_writer_get_procname\n<<Prclib interfaces: procedures>>=\n  function prc_writer_get_procname (feature) result (name)\n    type(string_t) :: name\n    type(string_t), intent(in) :: feature\n    name = feature\n  end function prc_writer_get_procname\n\n@ %def prc_writer_get_procname\n@ Return the name of a procedure that implements a given feature with\nthe bind(C) property, so it can be accessed via a C procedure pointer and\nhandled by dlopen.  We need this for all special features of a matrix\nelement, since the interface has to return a C function pointer for it.\nFor a default implementation, we prefix the external procedure name by\nthe process ID.\n<<Prclib interfaces: prc writer: TBP>>=\n  procedure :: get_c_procname => prc_writer_get_c_procname\n<<Prclib interfaces: procedures>>=\n  function prc_writer_get_c_procname (writer, id, feature) result (name)\n    class(prc_writer_t), intent(in) :: writer\n    type(string_t), intent(in) :: id, feature\n    type(string_t) :: name\n    name = id // \"_\" // feature\n  end function prc_writer_get_c_procname\n\n@ %def get_c_procname\n@ Common signature of code-writing procedures.  The procedure may\nuse the process ID, and the feature name.\n(Not necessarily all of them.)\n<<Prclib interfaces: interfaces>>=\n  abstract interface\n     subroutine write_code_file (writer, id)\n       import\n       class(prc_writer_t), intent(in) :: writer\n       type(string_t), intent(in) :: id\n     end subroutine write_code_file\n  end interface\n\n  abstract interface\n     subroutine write_code (writer, unit, id)\n       import\n       class(prc_writer_t), intent(in) :: writer\n       integer, intent(in) :: unit\n       type(string_t), intent(in) :: id\n     end subroutine write_code\n  end interface\n\n  abstract interface\n     subroutine write_code_os &\n          (writer, unit, id, os_data, verbose, testflag)\n       import\n       class(prc_writer_t), intent(in) :: writer\n       integer, intent(in) :: unit\n       type(string_t), intent(in) :: id\n       type(os_data_t), intent(in) :: os_data\n       logical, intent(in) :: verbose\n       logical, intent(in), optional :: testflag\n     end subroutine write_code_os\n  end interface\n\n  abstract interface\n     subroutine write_feature_code (writer, unit, id, feature)\n       import\n       class(prc_writer_t), intent(in) :: writer\n       integer, intent(in) :: unit\n       type(string_t), intent(in) :: id, feature\n     end subroutine write_feature_code\n  end interface\n\n@ %def write_code write_feature_code\n@ There must be a procedure which writes an interface block for a\ngiven feature.  If the external matrix element is implemented as a\nFortran module, this is required only for the specific features which\nare returned as procedure pointers.\n<<Prclib interfaces: prc writer: TBP>>=\n  procedure(write_feature_code), deferred :: write_interface\n@ %def write_interface\n@ There must also be a procedure which writes Makefile code which is\nspecific for the current process, but not the feature.\n<<Prclib interfaces: prc writer: TBP>>=\n  procedure(write_code_os), deferred :: write_makefile_code\n@ %def write_makefile_code\n@ This procedure writes code process-specific source-code file\n(which need not be Fortran).  It is called before [[make]] [[source]] is\ncalled.  It may be a no-op, if the source code is\ngenerated by Make instead.\n<<Prclib interfaces: prc writer: TBP>>=\n  procedure(write_code_file), deferred :: write_source_code\n@ %def write_source_code\n@ This procedure is executed, once for each process, before (after)\n[[make]] [[compile]] is called, respectively.\n<<Prclib interfaces: prc writer: TBP>>=\n  procedure(write_code_file), deferred :: before_compile\n  procedure(write_code_file), deferred :: after_compile\n@ %def before_compile\n@ %def after_compile\n@\n\\subsubsection{Writer for Fortran-module matrix elements}\nIf the matrix element is available as a Fortran module, we have\nspecific requirements: (i) the features are imported via [[use]]\ndirectives, (ii) the specific features require bind(C) wrappers.\n\nThe type is still abstract, all methods must be implemented explicitly\nfor a specific matrix-element variant.\n<<Prclib interfaces: public>>=\n  public :: prc_writer_f_module_t\n<<Prclib interfaces: types>>=\n  type, extends (prc_writer_t), abstract :: prc_writer_f_module_t\n   contains\n   <<Prclib interfaces: prc writer f module: TBP>>\n  end type prc_writer_f_module_t\n\n@ %def prc_writer_f_module_t\n@ Return the name of the Fortran module.  As a default\nimplementation, we take the process ID unchanged.\n<<Prclib interfaces: prc writer f module: TBP>>=\n  procedure, nopass :: get_module_name => prc_writer_get_module_name\n<<Prclib interfaces: procedures>>=\n  function prc_writer_get_module_name (id) result (name)\n    type(string_t) :: name\n    type(string_t), intent(in) :: id\n    name = id\n  end function prc_writer_get_module_name\n\n@ %def prc_writer_get_module_name\n@ Write a [[use]] directive that associates the driver reference with\nthe procedure in the matrix element code.  By default, we use the C\nname for this.\n<<Prclib interfaces: prc writer f module: TBP>>=\n  procedure :: write_use_line => prc_writer_write_use_line\n<<Prclib interfaces: procedures>>=\n  subroutine prc_writer_write_use_line (writer, unit, id, feature)\n    class(prc_writer_f_module_t), intent(in) :: writer\n    integer, intent(in) :: unit\n    type(string_t) :: id, feature\n    write (unit, \"(2x,9A)\")  \"use \", char (writer%get_module_name (id)), &\n         \", only: \", char (writer%get_c_procname (id, feature)), &\n         \" => \", char (writer%get_procname (feature))\n  end subroutine prc_writer_write_use_line\n\n@ %def prc_writer_write_use_line\n@ Write a wrapper routine for a feature.  This also associates a C\nname the module procedure.  The details depend on the writer variant.\n<<Prclib interfaces: prc writer f module: TBP>>=\n  procedure(prc_write_wrapper), deferred :: write_wrapper\n<<Prclib interfaces: interfaces>>=\n  abstract interface\n     subroutine prc_write_wrapper (writer, unit, id, feature)\n       import\n       class(prc_writer_f_module_t), intent(in) :: writer\n       integer, intent(in) :: unit\n       type(string_t), intent(in) :: id, feature\n     end subroutine prc_write_wrapper\n  end interface\n\n@ %def prc_write_wrapper\n@ This is used for testing only: initialize the writer with a specific MD5 sum\nstring.\n<<Prclib interfaces: prc writer: TBP>>=\n  procedure :: init_test => prc_writer_init_test\n<<Prclib interfaces: procedures>>=\n  subroutine prc_writer_init_test (writer)\n    class(prc_writer_t), intent(out) :: writer\n    writer%md5sum = \"1234567890abcdef1234567890abcdef\"\n  end subroutine prc_writer_init_test\n\n@ %def prc_writer_init_test\n@\n\\subsubsection{Writer for C-library matrix elements}\nThis applies if the matrix element is available as a C library or a Fortran\nlibrary with bind(C) compatible interface.  We can use the basic\nversion.\n\nThe type is still abstract, all methods must be implemented explicitly\nfor a specific matrix-element variant.\n<<Prclib interfaces: public>>=\n  public :: prc_writer_c_lib_t\n<<Prclib interfaces: types>>=\n  type, extends (prc_writer_t), abstract :: prc_writer_c_lib_t\n   contains\n   <<Prclib interfaces: prc writer c lib: TBP>>\n  end type prc_writer_c_lib_t\n\n@ %def prc_writer_c_lib_t\n@\n\\subsection{Process records in the library driver}\nA process record holds the process (component) [[ID]], the physics\n[[model_name]], and the array of [[feature]]s that are\nimplemented by the corresponding matrix element code.\n\nThe [[writer]] component holds procedures.  The procedures write\nsource code for the current record, either for the driver or for the\nMakefile.\n<<Prclib interfaces: types>>=\n  type :: prclib_driver_record_t\n     type(string_t) :: id\n     type(string_t) :: model_name\n     type(string_t), dimension(:), allocatable :: feature\n     class(prc_writer_t), pointer :: writer => null ()\n   contains\n   <<Prclib interfaces: prclib driver record: TBP>>\n  end type prclib_driver_record_t\n\n@ %def prclib_driver_record\n@ Output routine.  We indent the output, so it smoothly integrates\ninto the output routine for the whole driver.\n\nNote: the pointer [[writer]] is introduced as a workaround for a NAG compiler\nbug.\n<<Prclib interfaces: prclib driver record: TBP>>=\n  procedure :: write => prclib_driver_record_write\n<<Prclib interfaces: procedures>>=\n  subroutine prclib_driver_record_write (object, unit)\n    class(prclib_driver_record_t), intent(in) :: object\n    integer, intent(in) :: unit\n    integer :: j\n    class(prc_writer_t), pointer :: writer\n    write (unit, \"(3x,A,2x,'[',A,']')\")  &\n         char (object%id), char (object%model_name)\n    if (allocated (object%feature)) then\n       writer => object%writer\n       write (unit, \"(5x,A,A)\", advance=\"no\") &\n            char (writer%type_name ()), \":\"\n       do j = 1, size (object%feature)\n          write (unit, \"(1x,A)\", advance=\"no\") &\n               char (object%feature(j))\n       end do\n       write (unit, *)\n    end if\n  end subroutine prclib_driver_record_write\n\n@ %def prclib_driver_record_write\n@ Get the C procedure name for a feature.\n<<Prclib interfaces: prclib driver record: TBP>>=\n  procedure :: get_c_procname => prclib_driver_record_get_c_procname\n<<Prclib interfaces: procedures>>=\n  function prclib_driver_record_get_c_procname (record, feature) result (name)\n    type(string_t) :: name\n    class(prclib_driver_record_t), intent(in) :: record\n    type(string_t), intent(in) :: feature\n    name = record%writer%get_c_procname (record%id, feature)\n  end function prclib_driver_record_get_c_procname\n\n@ %def prclib_driver_record_get_c_procname\n@ Write a USE directive for a given feature.  Applies only if the\nrecord corresponds to a Fortran module.\n<<Prclib interfaces: prclib driver record: TBP>>=\n  procedure :: write_use_line => prclib_driver_record_write_use_line\n<<Prclib interfaces: procedures>>=\n  subroutine prclib_driver_record_write_use_line (record, unit, feature)\n    class(prclib_driver_record_t), intent(in) :: record\n    integer, intent(in) :: unit\n    type(string_t), intent(in) :: feature\n    select type (writer => record%writer)\n    class is (prc_writer_f_module_t)\n       call writer%write_use_line (unit, record%id, feature)\n    end select\n  end subroutine prclib_driver_record_write_use_line\n\n@ %def prclib_driver_record_write_use_line\n@ The alternative: write an interface block for a given feature,\nunless the record corresponds to a Fortran module.\n<<Prclib interfaces: prclib driver record: TBP>>=\n  procedure :: write_interface => prclib_driver_record_write_interface\n<<Prclib interfaces: procedures>>=\n  subroutine prclib_driver_record_write_interface (record, unit, feature)\n    class(prclib_driver_record_t), intent(in) :: record\n    integer, intent(in) :: unit\n    type(string_t), intent(in) :: feature\n    select type (writer => record%writer)\n    class is (prc_writer_f_module_t)\n    class default\n       call writer%write_interface (unit, record%id, feature)\n    end select\n  end subroutine prclib_driver_record_write_interface\n\n@ %def prclib_driver_record_write_use_line\n@ Write all special feature interfaces for the current record.  Do\nthis for all process variants.\n<<Prclib interfaces: prclib driver record: TBP>>=\n  procedure :: write_interfaces => prclib_driver_record_write_interfaces\n<<Prclib interfaces: procedures>>=\n  subroutine prclib_driver_record_write_interfaces (record, unit)\n    class(prclib_driver_record_t), intent(in) :: record\n    integer, intent(in) :: unit\n    integer :: i\n    do i = 1, size (record%feature)\n       call record%writer%write_interface (unit, record%id, record%feature(i))\n    end do\n  end subroutine prclib_driver_record_write_interfaces\n\n@ %def prclib_driver_record_write_interfaces\n@ Write the wrapper routines for this record, if it corresponds to a\nFortran module.\n<<Prclib interfaces: prclib driver record: TBP>>=\n  procedure :: write_wrappers => prclib_driver_record_write_wrappers\n<<Prclib interfaces: procedures>>=\n  subroutine prclib_driver_record_write_wrappers (record, unit)\n    class(prclib_driver_record_t), intent(in) :: record\n    integer, intent(in) :: unit\n    integer :: i\n    select type (writer => record%writer)\n    class is (prc_writer_f_module_t)\n       do i = 1, size (record%feature)\n          call writer%write_wrapper (unit, record%id, record%feature(i))\n       end do\n    end select\n  end subroutine prclib_driver_record_write_wrappers\n\n@ %def prclib_driver_record_write_wrappers\n@ Write the Makefile code for this record.\n<<Prclib interfaces: prclib driver record: TBP>>=\n  procedure :: write_makefile_code => prclib_driver_record_write_makefile_code\n<<Prclib interfaces: procedures>>=\n  subroutine prclib_driver_record_write_makefile_code &\n       (record, unit, os_data, verbose, testflag)\n    class(prclib_driver_record_t), intent(in) :: record\n    integer, intent(in) :: unit\n    type(os_data_t), intent(in) :: os_data\n    logical, intent(in) :: verbose\n    logical, intent(in), optional :: testflag\n    call record%writer%write_makefile_code &\n         (unit, record%id, os_data, verbose, testflag)\n  end subroutine prclib_driver_record_write_makefile_code\n\n@ %def prclib_driver_record_write_makefile_code\n@ Write source-code files for this record.  This can be used as an alternative\nto handling source code via Makefile.  In fact, this procedure is executed\nbefore [[make]] [[source]] is called.  Usually, does nothing.\n<<Prclib interfaces: prclib driver record: TBP>>=\n  procedure :: write_source_code => prclib_driver_record_write_source_code\n<<Prclib interfaces: procedures>>=\n  subroutine prclib_driver_record_write_source_code (record)\n    class(prclib_driver_record_t), intent(in) :: record\n    call record%writer%write_source_code (record%id)\n  end subroutine prclib_driver_record_write_source_code\n\n@ %def prclib_driver_record_write_source_code\n@ Execute commands for this record that depend on the sources, so they\ncannot be included in the previous procedure.  This procedure is\nexecuted before (after) [[make]] [[compile]] is called, respectively.\nUsually, does nothing.\n<<Prclib interfaces: prclib driver record: TBP>>=\n  procedure :: before_compile => prclib_driver_record_before_compile\n  procedure :: after_compile => prclib_driver_record_after_compile\n<<Prclib interfaces: procedures>>=\n  subroutine prclib_driver_record_before_compile (record)\n    class(prclib_driver_record_t), intent(in) :: record\n    call record%writer%before_compile (record%id)\n  end subroutine prclib_driver_record_before_compile\n\n  subroutine prclib_driver_record_after_compile (record)\n    class(prclib_driver_record_t), intent(in) :: record\n    call record%writer%after_compile (record%id)\n  end subroutine prclib_driver_record_after_compile\n\n@ %def prclib_driver_record_before_compile\n@ %def prclib_driver_record_after_compile\n@\n\\subsection{The process library driver object}\nA [[prclib_driver_t]] object provides the interface to external matrix element\ncode.  The code is provided by an external library which is either\nstatically or dynamically linked.\n\nThe dynamic and static versions of the library are two different\nimplementations of the abstract base type.\n\nThe [[basename]] identifies the library, both by file names and by Fortran\nvariable names.\n\nThe [[loaded]] flag becomes true once all procedure pointers to the\nmatrix element have been assigned.\n\nFor a dynamical external library, the communication proceeds via a\n[[dlaccess]] object.\n\n[[n_processes]] is the number of external process code components that\nare referenced by this library.  The code is addressed by index ([[i_lib]]\nin the process library entry above).  This number should be equal to\nthe number returned by [[get_n_prc]].\n\nFor each external process, there is a separate [[record]] which holds\nthe data that are needed for the driver parts which are specific\nfor a given process component.  The actual pointers for the loaded\nlibrary will be assigned elsewhere.\n\nThe remainder is a collection of procedure pointers, which can be\nassigned once all external code has been compiled and linked.\nThe procedure pointers all take a process component code\nindex as an argument.  Most return information about the process\ncomponent that should match the process definition.  The [[get_fptr]]\nprocedures return a function pointer, which is the actual means to\ncompute matrix elements or retrieve associated data.\n\nFinally, the [[unload_hook]] and [[reload_hook]] pointers allow for\nthe insertion of additional code when a library is loaded.\n<<Prclib interfaces: public>>=\n  public :: prclib_driver_t\n<<Prclib interfaces: types>>=\n  type, abstract :: prclib_driver_t\n     type(string_t) :: basename\n     character(32) :: md5sum = \"\"\n     logical :: loaded = .false.\n     type(string_t) :: libname\n     type(string_t) :: modellibs_ldflags\n     integer :: n_processes = 0\n     type(prclib_driver_record_t), dimension(:), allocatable :: record\n     procedure(prc_get_n_processes), nopass, pointer :: &\n          get_n_processes => null ()\n     procedure(prc_get_stringptr), nopass, pointer :: &\n          get_process_id_ptr => null ()\n     procedure(prc_get_stringptr), nopass, pointer :: &\n          get_model_name_ptr => null ()\n     procedure(prc_get_stringptr), nopass, pointer :: &\n          get_md5sum_ptr => null ()\n     procedure(prc_get_log), nopass, pointer :: &\n          get_openmp_status => null ()\n     procedure(prc_get_int), nopass, pointer :: get_n_in  => null ()\n     procedure(prc_get_int), nopass, pointer :: get_n_out => null ()\n     procedure(prc_get_int), nopass, pointer :: get_n_flv => null ()\n     procedure(prc_get_int), nopass, pointer :: get_n_hel => null ()\n     procedure(prc_get_int), nopass, pointer :: get_n_col => null ()\n     procedure(prc_get_int), nopass, pointer :: get_n_cin => null ()\n     procedure(prc_get_int), nopass, pointer :: get_n_cf  => null ()\n     procedure(prc_set_int_tab1), nopass, pointer :: &\n          set_flv_state_ptr => null ()\n     procedure(prc_set_int_tab1), nopass, pointer :: &\n          set_hel_state_ptr => null ()\n     procedure(prc_set_col_state), nopass, pointer :: &\n          set_col_state_ptr => null ()\n     procedure(prc_set_color_factors), nopass, pointer :: &\n          set_color_factors_ptr => null ()\n     procedure(prc_get_fptr), nopass, pointer :: get_fptr => null ()\n   contains\n   <<Prclib interfaces: prclib driver: TBP>>\n  end type prclib_driver_t\n\n@ %def prclib_driver_t\n@ This is the dynamic version.  It contains a [[dlaccess]] object for\ncommunicating with the OS.\n<<Prclib interfaces: public>>=\n  public :: prclib_driver_dynamic_t\n<<Prclib interfaces: types>>=\n  type, extends (prclib_driver_t) :: prclib_driver_dynamic_t\n     type(dlaccess_t) :: dlaccess\n   contains\n   <<Prclib interfaces: prclib driver dynamic: TBP>>\n  end type prclib_driver_dynamic_t\n\n@ %def prclib_driver_dynamic_t\n@ Print just the metadata.  Procedure pointers cannot be printed.\n<<Prclib interfaces: prclib driver: TBP>>=\n  procedure :: write => prclib_driver_write\n<<Prclib interfaces: procedures>>=\n  subroutine prclib_driver_write (object, unit, libpath)\n    class(prclib_driver_t), intent(in) :: object\n    integer, intent(in) :: unit\n    logical, intent(in), optional :: libpath\n    logical :: write_lib\n    integer :: i\n    write_lib = .true.\n    if (present (libpath))  write_lib = libpath\n    write (unit, \"(1x,A,A)\")  &\n         \"External matrix-element code library: \", char (object%basename)\n    select type (object)\n    type is (prclib_driver_dynamic_t)\n       write (unit, \"(3x,A,L1)\")  \"static    = F\"\n    class default\n       write (unit, \"(3x,A,L1)\")  \"static    = T\"\n    end select\n    write (unit, \"(3x,A,L1)\")  \"loaded    = \", object%loaded\n    write (unit, \"(3x,A,A,A)\") \"MD5 sum   = '\", object%md5sum, \"'\"\n    if (write_lib) then\n       write (unit, \"(3x,A,A,A)\") \"Mdl flags = '\", &\n            char (object%modellibs_ldflags), \"'\"\n    end if\n    select type (object)\n    type is (prclib_driver_dynamic_t)\n       write (unit, *)\n       call object%dlaccess%write (unit)\n    end select\n    write (unit, *)\n    if (allocated (object%record)) then\n       write (unit, \"(1x,A)\")  \"Matrix-element code entries:\"\n       do i = 1, object%n_processes\n          call object%record(i)%write (unit)\n       end do\n    else\n       write (unit, \"(1x,A)\")  \"Matrix-element code entries: [undefined]\"\n    end if\n  end subroutine prclib_driver_write\n\n@ %def prclib_driver_write\n@ Allocate a library as either static or dynamic.  For static\nlibraries, the procedure defers control to an external procedure which\nknows about the available static libraries.  By default, this\nprocedure is empty, but when we build a stand-alone executable, we\nreplace the dummy by an actual dispatcher for the available\nstatic libraries.  If the static dispatcher was not successful, we\nallocate a dynamic library.\n\nThe default version of [[dispatch_prclib_static]] resides in the\n[[prebuilt]] section of the \\whizard\\ tree, in a separate\nlibrary.  It does nothing, but can be replaced by a different\nprocedure that allocates a static library driver if requested by name.\n<<Prclib interfaces: public>>=\n  public :: dispatch_prclib_driver\n<<Prclib interfaces: procedures>>=\n  subroutine dispatch_prclib_driver &\n       (driver, basename, modellibs_ldflags)\n    class(prclib_driver_t), intent(out), allocatable :: driver\n    type(string_t), intent(in) :: basename\n    type(string_t), intent(in), optional :: modellibs_ldflags\n    procedure(dispatch_prclib_driver) :: dispatch_prclib_static\n    if (allocated (driver))  deallocate (driver)\n    call dispatch_prclib_static (driver, basename)\n    if (.not. allocated (driver)) then\n       allocate (prclib_driver_dynamic_t :: driver)\n    end if\n    driver%basename = basename\n    driver%modellibs_ldflags = modellibs_ldflags\n  end subroutine dispatch_prclib_driver\n\n@ %def dispatch_prclib_driver\n@ Initialize the ID array and set [[n_processes]] accordingly.\n<<Prclib interfaces: prclib driver: TBP>>=\n  procedure :: init => prclib_driver_init\n<<Prclib interfaces: procedures>>=\n  subroutine prclib_driver_init (driver, n_processes)\n    class(prclib_driver_t), intent(inout) :: driver\n    integer, intent(in) :: n_processes\n    driver%n_processes = n_processes\n    allocate (driver%record (n_processes))\n  end subroutine prclib_driver_init\n\n@ %def prclib_driver_init\n@ Set the MD5 sum.  This is separate because the MD5 sum may be known only\nafter initialization.\n<<Prclib interfaces: prclib driver: TBP>>=\n  procedure :: set_md5sum => prclib_driver_set_md5sum\n<<Prclib interfaces: procedures>>=\n  subroutine prclib_driver_set_md5sum (driver, md5sum)\n    class(prclib_driver_t), intent(inout) :: driver\n    character(32), intent(in) :: md5sum\n    driver%md5sum = md5sum\n  end subroutine prclib_driver_set_md5sum\n\n@ %def prclib_driver_set_md5sum\n@ Set the process record for a specific library entry.  If the index\nis zero, we do nothing.\n\n<<Prclib interfaces: prclib driver: TBP>>=\n  procedure :: set_record => prclib_driver_set_record\n<<Prclib interfaces: procedures>>=\n  subroutine prclib_driver_set_record (driver, i, &\n       id, model_name, features, writer)\n    class(prclib_driver_t), intent(inout) :: driver\n    integer, intent(in) :: i\n    type(string_t), intent(in) :: id\n    type(string_t), intent(in) :: model_name\n    type(string_t), dimension(:), intent(in) :: features\n    class(prc_writer_t), intent(in), pointer :: writer\n    if (i > 0) then\n       associate (record => driver%record(i))\n         record%id = id\n         record%model_name = model_name\n         allocate (record%feature (size (features)))\n         record%feature = features\n         record%writer => writer\n       end associate\n    end if\n  end subroutine prclib_driver_set_record\n\n@ %def prclib_driver_set_record\n@ Write all USE directives for a given feature, scanning the array of\nprocesses.  Only Fortran-module processes count.  Then, write\ninterface blocks for the remaining processes.\n\nThe [[implicit none]] statement must go in-between.\n<<Prclib interfaces: prclib driver: TBP>>=\n  procedure :: write_interfaces => prclib_driver_write_interfaces\n<<Prclib interfaces: procedures>>=\n  subroutine prclib_driver_write_interfaces (driver, unit, feature)\n    class(prclib_driver_t), intent(in) :: driver\n    integer, intent(in) :: unit\n    type(string_t), intent(in) :: feature\n    integer :: i\n    do i = 1, driver%n_processes\n       call driver%record(i)%write_use_line (unit, feature)\n    end do\n    write (unit, \"(2x,9A)\")  \"implicit none\"\n    do i = 1, driver%n_processes\n       call driver%record(i)%write_interface (unit, feature)\n    end do\n  end subroutine prclib_driver_write_interfaces\n\n@ %def prclib_driver_write_interfaces\n@\n\\subsection{Write makefile}\nThe makefile contains constant parts, parts that depend on the library\nname, and parts that depend on the specific processes and their types.\n<<Prclib interfaces: prclib driver: TBP>>=\n  procedure :: generate_makefile => prclib_driver_generate_makefile\n<<Prclib interfaces: procedures>>=\n  subroutine prclib_driver_generate_makefile (driver, unit, os_data, verbose, testflag)\n    class(prclib_driver_t), intent(in) :: driver\n    integer, intent(in) :: unit\n    type(os_data_t), intent(in) :: os_data\n    logical, intent(in) :: verbose\n    logical, intent(in), optional :: testflag\n    integer :: i\n    write (unit, \"(A)\")  \"# WHIZARD: Makefile for process library '\" &\n         // char (driver%basename) // \"'\"\n    write (unit, \"(A)\")  \"# Automatically generated file, do not edit\"\n    write (unit, \"(A)\")  \"\"\n    write (unit, \"(A)\")  \"# Integrity check (don't modify the following line!)\"\n    write (unit, \"(A)\")  \"MD5SUM = '\" // driver%md5sum // \"'\"\n    write (unit, \"(A)\")  \"\"\n    write (unit, \"(A)\")  \"# Library name\"\n    write (unit, \"(A)\")  \"BASE = \" // char (driver%basename)\n    write (unit, \"(A)\")  \"\"\n    write (unit, \"(A)\")  \"# Compiler\"\n    write (unit, \"(A)\")  \"FC = \" // char (os_data%fc)\n    write (unit, \"(A)\")  \"CC = \" // char (os_data%cc)\n    write (unit, \"(A)\")  \"\"\n    write (unit, \"(A)\")  \"# Included libraries\"\n    write (unit, \"(A)\")  \"FCINCL = \" // char (os_data%whizard_includes)\n    write (unit, \"(A)\")  \"\"\n    write (unit, \"(A)\")  \"# Compiler flags\"\n    write (unit, \"(A)\")  \"FCFLAGS = \" // char (os_data%fcflags)\n    write (unit, \"(A)\")  \"FCFLAGS_PIC = \" // char (os_data%fcflags_pic)\n    write (unit, \"(A)\")  \"CFLAGS = \" // char (os_data%cflags)\n    write (unit, \"(A)\")  \"CFLAGS_PIC = \" // char (os_data%cflags_pic)\n    write (unit, \"(A)\")  \"LDFLAGS = \" // char (os_data%whizard_ldflags) &\n         // \" \" // char (os_data%ldflags) // \" \" // &\n         char (driver%modellibs_ldflags)\n    write (unit, \"(A)\")  \"\"\n    write (unit, \"(A)\")  \"# LaTeX setup\"\n    write (unit, \"(A)\")  \"LATEX = \" // char (os_data%latex)\n    write (unit, \"(A)\")  \"MPOST = \" // char (os_data%mpost)\n    write (unit, \"(A)\")  \"DVIPS = \" // char (os_data%dvips)\n    write (unit, \"(A)\")  \"PS2PDF = \" // char (os_data%ps2pdf)\n    write (unit, \"(A)\")  'TEX_FLAGS = \"$$TEXINPUTS:' // &\n         char(os_data%whizard_texpath) // '\"'\n    write (unit, \"(A)\")  'MP_FLAGS  = \"$$MPINPUTS:' // &\n         char(os_data%whizard_texpath) // '\"'\n    write (unit, \"(A)\")  \"\"\n    write (unit, \"(A)\")  \"# Libtool\"\n    write (unit, \"(A)\")  \"LIBTOOL = \" // char (os_data%whizard_libtool)\n    if (verbose) then\n       write (unit, \"(A)\")  \"FCOMPILE = $(LIBTOOL) --tag=FC --mode=compile\"\n       write (unit, \"(A)\")  \"CCOMPILE = $(LIBTOOL) --tag=CC --mode=compile\"\n       write (unit, \"(A)\")  \"LINK = $(LIBTOOL) --tag=FC --mode=link\"\n    else\n       write (unit, \"(A)\")  \"FCOMPILE = @$(LIBTOOL) --silent --tag=FC --mode=compile\"\n       write (unit, \"(A)\")  \"CCOMPILE = @$(LIBTOOL) --silent --tag=CC --mode=compile\"\n       write (unit, \"(A)\")  \"LINK = @$(LIBTOOL) --silent --tag=FC --mode=link\"\n    end if\n    write (unit, \"(A)\")  \"\"\n    write (unit, \"(A)\")  \"# Compile commands (default)\"\n    write (unit, \"(A)\")  \"LTFCOMPILE = $(FCOMPILE) $(FC) -c &\n         &$(FCINCL) $(FCFLAGS) $(FCFLAGS_PIC)\"\n    write (unit, \"(A)\")  \"LTCCOMPILE = $(CCOMPILE) $(CC) -c &\n         &$(CFLAGS) $(CFLAGS_PIC)\"\n    write (unit, \"(A)\")  \"\"\n    write (unit, \"(A)\")  \"# Default target\"\n    write (unit, \"(A)\")  \"all: link diags\"\n    write (unit, \"(A)\")  \"\"\n    write (unit, \"(A)\")  \"# Matrix-element code files\"\n    do i = 1, size (driver%record)\n       call driver%record(i)%write_makefile_code (unit, os_data, verbose, testflag)\n    end do\n    write (unit, \"(A)\")  \"\"\n    write (unit, \"(A)\")  \"# Library driver\"\n    write (unit, \"(A)\")  \"$(BASE).lo: $(BASE).f90 $(OBJECTS)\"\n    write (unit, \"(A)\")  TAB // \"$(LTFCOMPILE) $<\"\n    if (.not. verbose) then\n       write (unit, \"(A)\")  TAB // '@echo  \"  FC       \" $@'\n    end if\n    write (unit, \"(A)\")  \"\"\n    write (unit, \"(A)\")  \"# Library\"\n    write (unit, \"(A)\")  \"$(BASE).la: $(BASE).lo $(OBJECTS)\"\n    if (.not. verbose) then\n       write (unit, \"(A)\")  TAB // '@echo  \"  FCLD     \" $@'\n    end if\n    write (unit, \"(A)\")  TAB // \"$(LINK) $(FC) -module -rpath /dev/null &\n         &$(FCFLAGS) $(LDFLAGS) -o $(BASE).la $^\"\n    write (unit, \"(A)\")  \"\"\n    write (unit, \"(A)\")  \"# Main targets\"\n    write (unit, \"(A)\")  \"link: compile $(BASE).la\"\n    write (unit, \"(A)\")  \"compile: source $(OBJECTS) $(TEX_OBJECTS) $(BASE).lo\"\n    write (unit, \"(A)\")  \"compile_tex: $(TEX_OBJECTS)\"\n    write (unit, \"(A)\")  \"source: $(SOURCES) $(BASE).f90 $(TEX_SOURCES)\"\n    write (unit, \"(A)\")  \".PHONY: link diags compile compile_tex source\"\n    write (unit, \"(A)\")  \"\"\n    write (unit, \"(A)\")  \"# Specific cleanup targets\"\n    do i = 1, size (driver%record)\n       write (unit, \"(A)\")  \"clean-\" // char (driver%record(i)%id) // \":\"\n       write (unit, \"(A)\")  \".PHONY: clean-\" // char (driver%record(i)%id)\n    end do\n    write (unit, \"(A)\")  \"\"\n    write (unit, \"(A)\")  \"# Generic cleanup targets\"\n    write (unit, \"(A)\")  \"clean-library:\"\n    if (verbose) then\n       write (unit, \"(A)\")  TAB // \"rm -f $(BASE).la\"\n    else\n       write (unit, \"(A)\")  TAB // '@echo  \"  RM        $(BASE).la\"'\n       write (unit, \"(A)\")  TAB // \"@rm -f $(BASE).la\"\n    end if\n    write (unit, \"(A)\")  \"clean-objects:\"\n    if (verbose) then\n       write (unit, \"(A)\")  TAB // \"rm -f $(BASE).lo $(BASE)_driver.mod &\n            &$(CLEAN_OBJECTS)\"\n    else\n       write (unit, \"(A)\")  TAB // '@echo  \"  RM        $(BASE).lo &\n            &$(BASE)_driver.mod $(CLEAN_OBJECTS)\"'\n       write (unit, \"(A)\")  TAB // \"@rm -f $(BASE).lo $(BASE)_driver.mod &\n            &$(CLEAN_OBJECTS)\"\n    end if\n    write (unit, \"(A)\")  \"clean-source:\"\n    if (verbose) then\n       write (unit, \"(A)\")  TAB // \"rm -f $(CLEAN_SOURCES)\"\n    else\n       write (unit, \"(A)\")  TAB // '@echo  \"  RM        $(CLEAN_SOURCES)\"'\n       write (unit, \"(A)\")  TAB // \"@rm -f $(CLEAN_SOURCES)\"\n    end if\n    write (unit, \"(A)\")  \"clean-driver:\"\n    if (verbose) then\n       write (unit, \"(A)\")  TAB // \"rm -f $(BASE).f90\"\n    else\n       write (unit, \"(A)\")  TAB // '@echo  \"  RM        $(BASE).f90\"'\n       write (unit, \"(A)\")  TAB // \"@rm -f $(BASE).f90\"\n    end if\n    write (unit, \"(A)\")  \"clean-makefile:\"\n    if (verbose) then\n       write (unit, \"(A)\")  TAB // \"rm -f $(BASE).makefile\"\n    else\n       write (unit, \"(A)\")  TAB // '@echo  \"  RM        $(BASE).makefile\"'\n       write (unit, \"(A)\")  TAB // \"@rm -f $(BASE).makefile\"\n    end if\n    write (unit, \"(A)\")  \".PHONY: clean-library clean-objects &\n         &clean-source clean-driver clean-makefile\"\n    write (unit, \"(A)\")  \"\"\n    write (unit, \"(A)\")  \"clean: clean-library clean-objects clean-source\"\n    write (unit, \"(A)\")  \"distclean: clean clean-driver clean-makefile\"\n    write (unit, \"(A)\")  \".PHONY: clean distclean\"\n  end subroutine prclib_driver_generate_makefile\n\n@ %def prclib_driver_generate_makefile\n@\n\\subsection{Write driver file}\nThis procedure writes the process library driver source code to the\nspecified output unit.  The individual routines for writing\nsource-code procedures are given below.\n<<Prclib interfaces: prclib driver: TBP>>=\n  procedure :: generate_driver_code => prclib_driver_generate_code\n<<Prclib interfaces: procedures>>=\n  subroutine prclib_driver_generate_code (driver, unit)\n    class(prclib_driver_t), intent(in) :: driver\n    integer, intent(in) :: unit\n    type(string_t) :: prefix\n    integer :: i\n\n    prefix = driver%basename // \"_\"\n\n    write (unit, \"(A)\")  \"! WHIZARD matrix-element code interface\"\n    write (unit, \"(A)\")  \"!\"\n    write (unit, \"(A)\")  \"! Automatically generated file, do not edit\"\n    call driver%write_module (unit, prefix)\n    call driver%write_lib_md5sum_fun (unit, prefix)\n    call driver%write_get_n_processes_fun (unit, prefix)\n    call driver%write_get_process_id_fun (unit, prefix)\n    call driver%write_get_model_name_fun (unit, prefix)\n    call driver%write_get_md5sum_fun (unit, prefix)\n    call driver%write_string_to_array_fun (unit, prefix)\n    call driver%write_get_openmp_status_fun (unit, prefix)\n    call driver%write_get_int_fun (unit, prefix, var_str (\"n_in\"))\n    call driver%write_get_int_fun (unit, prefix, var_str (\"n_out\"))\n    call driver%write_get_int_fun (unit, prefix, var_str (\"n_flv\"))\n    call driver%write_get_int_fun (unit, prefix, var_str (\"n_hel\"))\n    call driver%write_get_int_fun (unit, prefix, var_str (\"n_col\"))\n    call driver%write_get_int_fun (unit, prefix, var_str (\"n_cin\"))\n    call driver%write_get_int_fun (unit, prefix, var_str (\"n_cf\"))\n    call driver%write_set_int_sub (unit, prefix, var_str (\"flv_state\"))\n    call driver%write_set_int_sub (unit, prefix, var_str (\"hel_state\"))\n    call driver%write_set_col_state_sub (unit, prefix)\n    call driver%write_set_color_factors_sub (unit, prefix)\n    call driver%write_get_fptr_sub (unit, prefix)\n    do i = 1, driver%n_processes\n       call driver%record(i)%write_wrappers (unit)\n    end do\n  end subroutine prclib_driver_generate_code\n\n@ %def prclib_driver_generate_code\n@ The driver module is used and required \\emph{only} if we intend to\nlink the library statically.  Then, it provides the (static) driver\ntype as a concrete implementation of the abstract library driver.\nThis type contains the internal dispatcher for assigning the library\nprocedures to their appropriate procedure pointers.  In the dynamical\ncase, the assignment is done via the base-type dispatcher which invokes\nthe DL mechanism.\n\nHowever, compiling this together with the rest in any case should not\ndo any harm.\n<<Prclib interfaces: prclib driver: TBP>>=\n  procedure, nopass :: write_module => prclib_driver_write_module\n<<Prclib interfaces: procedures>>=\n  subroutine prclib_driver_write_module (unit, prefix)\n    integer, intent(in) :: unit\n    type(string_t), intent(in) :: prefix\n    write (unit, \"(A)\")  \"\"\n    write (unit, \"(A)\")  \"! Module: define library driver as an extension &\n         &of the abstract driver type.\"\n    write (unit, \"(A)\")  \"! This is used _only_ by the library dispatcher &\n         &of a static executable.\"\n    write (unit, \"(A)\")  \"! For a dynamical library, the stand-alone proce&\n         &dures are linked via libdl.\"\n    write (unit, \"(A)\")  \"\"\n    write (unit, \"(A)\")  \"module \" &\n         // char (prefix) // \"driver\"\n    write (unit, \"(A)\")  \"  use iso_c_binding\"\n    write (unit, \"(A)\")  \"  use iso_varying_string, string_t => varying_string\"\n    write (unit, \"(A)\")  \"  use diagnostics\"\n    write (unit, \"(A)\")  \"  use prclib_interfaces\"\n    write (unit, \"(A)\")  \"\"\n    write (unit, \"(A)\")  \"  implicit none\"\n    write (unit, \"(A)\")  \"\"\n    write (unit, \"(A)\")  \"  type, extends (prclib_driver_t) :: \" &\n         // char (prefix) // \"driver_t\"\n    write (unit, \"(A)\")  \"   contains\"\n    write (unit, \"(A)\")  \"     procedure :: get_c_funptr => \" &\n         // char (prefix) // \"driver_get_c_funptr\"\n    write (unit, \"(A)\")  \"  end type \" &\n         // char (prefix) // \"driver_t\"\n    write (unit, \"(A)\")  \"\"\n    write (unit, \"(A)\")  \"contains\"\n    write (unit, \"(A)\")  \"\"\n    write (unit, \"(A)\")  \"  function \" &\n         // char (prefix) // \"driver_get_c_funptr (driver, feature) result &\n         &(c_fptr)\"\n    write (unit, \"(A)\")  \"    class(\" &\n         // char (prefix) // \"driver_t), intent(inout) :: driver\"\n    write (unit, \"(A)\")  \"    type(string_t), intent(in) :: feature\"\n    write (unit, \"(A)\")  \"    type(c_funptr) :: c_fptr\"\n    call write_decl (\"get_n_processes\", \"get_n_processes\")\n    call write_decl (\"get_stringptr\", \"get_process_id_ptr\")\n    call write_decl (\"get_stringptr\", \"get_model_name_ptr\")\n    call write_decl (\"get_stringptr\", \"get_md5sum_ptr\")\n    call write_decl (\"get_log\", \"get_openmp_status\")\n    call write_decl (\"get_int\", \"get_n_in\")\n    call write_decl (\"get_int\", \"get_n_out\")\n    call write_decl (\"get_int\", \"get_n_flv\")\n    call write_decl (\"get_int\", \"get_n_hel\")\n    call write_decl (\"get_int\", \"get_n_col\")\n    call write_decl (\"get_int\", \"get_n_cin\")\n    call write_decl (\"get_int\", \"get_n_cf\")\n    call write_decl (\"set_int_tab1\", \"set_flv_state_ptr\")\n    call write_decl (\"set_int_tab1\", \"set_hel_state_ptr\")\n    call write_decl (\"set_col_state\", \"set_col_state_ptr\")\n    call write_decl (\"set_color_factors\", \"set_color_factors_ptr\")\n    call write_decl (\"get_fptr\", \"get_fptr\")\n    write (unit, \"(A)\")  \"    select case (char (feature))\"\n    call write_case (\"get_n_processes\")\n    call write_case (\"get_process_id_ptr\")\n    call write_case (\"get_model_name_ptr\")\n    call write_case (\"get_md5sum_ptr\")\n    call write_case (\"get_openmp_status\")\n    call write_case (\"get_n_in\")\n    call write_case (\"get_n_out\")\n    call write_case (\"get_n_flv\")\n    call write_case (\"get_n_hel\")\n    call write_case (\"get_n_col\")\n    call write_case (\"get_n_cin\")\n    call write_case (\"get_n_cf\")\n    call write_case (\"set_flv_state_ptr\")\n    call write_case (\"set_hel_state_ptr\")\n    call write_case (\"set_col_state_ptr\")\n    call write_case (\"set_color_factors_ptr\")\n    call write_case (\"get_fptr\")\n    write (unit, \"(A)\")  \"    case default\"\n    write (unit, \"(A)\")  \"       call msg_bug ('prclib2 driver setup: unknown &\n         &function name')\"\n    write (unit, \"(A)\")  \"    end select\"\n    write (unit, \"(A)\")  \"  end function \" &\n         // char (prefix) // \"driver_get_c_funptr\"\n    write (unit, \"(A)\")  \"\"\n    write (unit, \"(A)\")  \"end module \" &\n         // char (prefix) // \"driver\"\n    write (unit, \"(A)\")  \"\"\n    write (unit, \"(A)\")  \"! Stand-alone external procedures: used for both &\n         &static and dynamic linkage\"\n  contains\n    subroutine write_decl (template, feature)\n      character(*), intent(in) :: template, feature\n      write (unit, \"(A)\")  \"    procedure(prc_\" // template // \") &\"\n      write (unit, \"(A)\")  \"         :: \" &\n           // char (prefix) // feature\n    end subroutine write_decl\n    subroutine write_case (feature)\n      character(*), intent(in) :: feature\n      write (unit, \"(A)\")  \"    case ('\" // feature // \"')\"\n      write (unit, \"(A)\")  \"       c_fptr = c_funloc (\" &\n           // char (prefix) // feature // \")\"\n    end subroutine write_case\n  end subroutine prclib_driver_write_module\n\n@ %def prclib_driver_write_module\n@ This function provides the overall library MD5sum.  The function is for\ninternal use (therefore not bind(C)), the external interface is via the\n[[get_md5sum_ptr]] procedure with index 0.\n<<Prclib interfaces: prclib driver: TBP>>=\n  procedure :: write_lib_md5sum_fun => prclib_driver_write_lib_md5sum_fun\n<<Prclib interfaces: procedures>>=\n  subroutine prclib_driver_write_lib_md5sum_fun (driver, unit, prefix)\n    class(prclib_driver_t), intent(in) :: driver\n    integer, intent(in) :: unit\n    type(string_t), intent(in) :: prefix\n    write (unit, \"(A)\")  \"\"\n    write (unit, \"(A)\")  \"! The MD5 sum of the library\"\n    write (unit, \"(A)\")  \"function \" // char (prefix) &\n         // \"md5sum () result (md5sum)\"\n    write (unit, \"(A)\")  \"  implicit none\"\n    write (unit, \"(A)\")  \"  character(32) :: md5sum\"\n    write (unit, \"(A)\")  \"  md5sum = '\" // driver%md5sum // \"'\"\n    write (unit, \"(A)\")  \"end function \" // char (prefix) // \"md5sum\"\n  end subroutine prclib_driver_write_lib_md5sum_fun\n\n@ %def prclib_driver_write_lib_md5sum_fun\n@\n\\subsection{Interface bodies for informational functions}\nThese interfaces implement the communication between WHIZARD (the main\nprogram) and the process-library driver.  The procedures are all\nBIND(C), so they can safely be exposed by the library and handled by\nthe [[dlopen]] mechanism, which apparently understands only C calling\nconventions.\n\nIn the sections below, for each procedure, we provide both the\ninterface itself and a procedure that writes the correponding\nprocedure as source code to the process library driver.\n\n\\subsubsection{Process count}\nReturn the number of processes contained in the library.\n<<Prclib interfaces: public>>=\n  public :: prc_get_n_processes\n<<Prclib interfaces: interfaces>>=\n  abstract interface\n     function prc_get_n_processes () result (n) bind(C)\n       import\n       integer(c_int) :: n\n     end function prc_get_n_processes\n  end interface\n@ %def prc_get_n_processes\n@ Here is the code.\n<<Prclib interfaces: prclib driver: TBP>>=\n  procedure :: write_get_n_processes_fun\n<<Prclib interfaces: procedures>>=\n  subroutine write_get_n_processes_fun (driver, unit, prefix)\n    class(prclib_driver_t), intent(in) :: driver\n    integer, intent(in) :: unit\n    type(string_t), intent(in) :: prefix\n    write (unit, \"(A)\")  \"\"\n    write (unit, \"(A)\")  \"! Return the number of processes in this library\"\n    write (unit, \"(A)\")  \"function \" // char (prefix) &\n         // \"get_n_processes () result (n) bind(C)\"\n    write (unit, \"(A)\")  \"  use iso_c_binding\"\n    write (unit, \"(A)\")  \"  implicit none\"\n    write (unit, \"(A)\")  \"  integer(c_int) :: n\"\n    write (unit, \"(A,I0)\")  \"  n = \", driver%n_processes\n    write (unit, \"(A)\")  \"end function \" // char (prefix) &\n         // \"get_n_processes\"\n  end subroutine write_get_n_processes_fun\n\n@ %def write_get_n_processes_fun\n@\n\\subsubsection{Informational string functions}\nThese functions return constant information about the matrix-element\ncode.\n\nThe following procedures have to return strings.  With the BIND(C)\nconstraint, we choose to return the C pointer to a string, and its\nlength, so the procedures implement this interface.  They are actually\nsubroutines.\n<<Prclib interfaces: public>>=\n  public :: prc_get_stringptr\n<<Prclib interfaces: interfaces>>=\n  abstract interface\n     subroutine prc_get_stringptr (i, cptr, len) bind(C)\n       import\n       integer(c_int), intent(in) :: i\n       type(c_ptr), intent(out) :: cptr\n       integer(c_int), intent(out) :: len\n     end subroutine prc_get_stringptr\n  end interface\n@ %def prc_get_stringptr\n@ To hide this complication, we introduce a subroutine that converts the\nreturned C pointer to a [[string_t]] object.  As a side effect, we\ndeallocate the original after conversion -- otherwise, we might have a\nmemory leak.\n\nFor the conversion, we first pointer-convert the C pointer to a\nFortran character array pointer, length 1 and size [[len]].  Using\nargument association and an internal subroutine, we convert this to a\ncharacter array with length [[len]] and size 1.  Using ordinary\nassignment, we finally convert this to [[string_t]].\n\nThe function takes the pointer-returning function as an argument.  The\nindex [[i]] identifies the process in the library.\n<<Prclib interfaces: procedures>>=\n  subroutine get_string_via_cptr (string, i, get_stringptr)\n    type(string_t), intent(out) :: string\n    integer, intent(in) :: i\n    procedure(prc_get_stringptr) :: get_stringptr\n    type(c_ptr) :: cptr\n    integer(c_int) :: pid, len\n    character(kind=c_char), dimension(:), pointer :: c_array\n    pid = i\n    call get_stringptr (pid, cptr, len)\n    if (c_associated (cptr)) then\n       call c_f_pointer (cptr, c_array, shape = [len])\n       call set_string (c_array)\n       call get_stringptr (0_c_int, cptr, len)\n    else\n       string = \"\"\n    end if\n  contains\n    subroutine set_string (buffer)\n      character(len, kind=c_char), dimension(1), intent(in) :: buffer\n      string = buffer(1)\n    end subroutine set_string\n  end subroutine get_string_via_cptr\n\n@ %def get_string_via_cptr\n@ Since the module procedures return Fortran strings, we have to\nconvert them.  This is the necessary auxiliary routine.  The routine\nis not BIND(C), it is not accessed from outside.\n<<Prclib interfaces: prclib driver: TBP>>=\n  procedure, nopass :: write_string_to_array_fun\n<<Prclib interfaces: procedures>>=\n  subroutine write_string_to_array_fun (unit, prefix)\n    integer, intent(in) :: unit\n    type(string_t), intent(in) :: prefix\n    write (unit, \"(A)\")  \"\"\n    write (unit, \"(A)\")  \"! Auxiliary: convert character string &\n         &to array pointer\"\n    write (unit, \"(A)\")  \"subroutine \" // char (prefix) &\n         // \"string_to_array (string, a)\"\n    write (unit, \"(A)\")  \"  use iso_c_binding\"\n    write (unit, \"(A)\")  \"  implicit none\"\n    write (unit, \"(A)\")  \"  character(*), intent(in) :: string\"\n    write (unit, \"(A)\")  \"  character(kind=c_char), dimension(:), &\n         &allocatable, intent(out) :: a\"\n    write (unit, \"(A)\")  \"  integer :: i\"\n    write (unit, \"(A)\")  \"  allocate (a (len (string)))\"\n    write (unit, \"(A)\")  \"  do i = 1, size (a)\"\n    write (unit, \"(A)\")  \"     a(i) = string(i:i)\"\n    write (unit, \"(A)\")  \"  end do\"\n    write (unit, \"(A)\")  \"end subroutine \" // char (prefix) &\n         // \"string_to_array\"\n  end subroutine write_string_to_array_fun\n\n@ %def write_string_to_array_fun\n@ The above routine is called by other functions.  It is not in a\nmodule, so they need its interface explicitly.\n<<Prclib interfaces: procedures>>=\n  subroutine write_string_to_array_interface (unit, prefix)\n    integer, intent(in) :: unit\n    type(string_t), intent(in) :: prefix\n    write (unit, \"(2x,A)\")  \"interface\"\n    write (unit, \"(2x,A)\")  \"   subroutine \" // char (prefix) &\n         // \"string_to_array (string, a)\"\n    write (unit, \"(2x,A)\")  \"     use iso_c_binding\"\n    write (unit, \"(2x,A)\")  \"     implicit none\"\n    write (unit, \"(2x,A)\")  \"     character(*), intent(in) :: string\"\n    write (unit, \"(2x,A)\")  \"     character(kind=c_char), dimension(:), &\n         &allocatable, intent(out) :: a\"\n    write (unit, \"(2x,A)\")  \"   end subroutine \" // char (prefix) &\n         // \"string_to_array\"\n    write (unit, \"(2x,A)\")  \"end interface\"\n  end subroutine write_string_to_array_interface\n\n@ %def write_string_to_array_interface\n@\nHere are the info functions which return strings, implementing the interface\n[[prc_get_stringptr]].\n\nReturn the process ID for each process.\n<<Prclib interfaces: prclib driver: TBP>>=\n  procedure :: write_get_process_id_fun\n<<Prclib interfaces: procedures>>=\n  subroutine write_get_process_id_fun (driver, unit, prefix)\n    class(prclib_driver_t), intent(in) :: driver\n    integer, intent(in) :: unit\n    type(string_t), intent(in) :: prefix\n    integer :: i\n    write (unit, \"(A)\")  \"\"\n    write (unit, \"(A)\")  \"! Return the process ID of process #i &\n         &(as a C pointer to a character array)\"\n    write (unit, \"(A)\")  \"subroutine \" // char (prefix) &\n         // \"get_process_id_ptr (i, cptr, len) bind(C)\"\n    write (unit, \"(A)\")  \"  use iso_c_binding\"\n    write (unit, \"(A)\")  \"  implicit none\"\n    write (unit, \"(A)\")  \"  integer(c_int), intent(in) :: i\"\n    write (unit, \"(A)\")  \"  type(c_ptr), intent(out) :: cptr\"\n    write (unit, \"(A)\")  \"  integer(c_int), intent(out) :: len\"\n    write (unit, \"(A)\")  \"  character(kind=c_char), dimension(:), &\n         &allocatable, target, save :: a\"\n    call write_string_to_array_interface (unit, prefix)\n    write (unit, \"(A)\")  \"  select case (i)\"\n    write (unit, \"(A)\")  \"  case (0);  if (allocated (a))  deallocate (a)\"\n    do i = 1, driver%n_processes\n       write (unit, \"(A,I0,9A)\")  \"  case (\", i, \");  \", &\n            \"call \", char (prefix), \"string_to_array ('\", &\n            char (driver%record(i)%id), \"', a)\"\n    end do\n    write (unit, \"(A)\")  \"  end select\"\n    write (unit, \"(A)\")  \"  if (allocated (a)) then\"\n    write (unit, \"(A)\")  \"     cptr = c_loc (a)\"\n    write (unit, \"(A)\")  \"     len = size (a)\"\n    write (unit, \"(A)\")  \"  else\"\n    write (unit, \"(A)\")  \"     cptr = c_null_ptr\"\n    write (unit, \"(A)\")  \"     len = 0\"\n    write (unit, \"(A)\")  \"  end if\"\n    write (unit, \"(A)\")  \"end subroutine \" // char (prefix) &\n         // \"get_process_id_ptr\"\n  end subroutine write_get_process_id_fun\n\n@ %def write_get_process_id_fun\n@ Return the model name, given explicitly.\n<<Prclib interfaces: prclib driver: TBP>>=\n  procedure :: write_get_model_name_fun\n<<Prclib interfaces: procedures>>=\n  subroutine write_get_model_name_fun (driver, unit, prefix)\n    class(prclib_driver_t), intent(in) :: driver\n    integer, intent(in) :: unit\n    type(string_t), intent(in) :: prefix\n    integer :: i\n    write (unit, \"(A)\")  \"\"\n    write (unit, \"(A)\")  \"! Return the model name for process #i &\n         &(as a C pointer to a character array)\"\n    write (unit, \"(A)\")  \"subroutine \" // char (prefix) &\n         // \"get_model_name_ptr (i, cptr, len) bind(C)\"\n    write (unit, \"(A)\")  \"  use iso_c_binding\"\n    write (unit, \"(A)\")  \"  implicit none\"\n    write (unit, \"(A)\")  \"  integer(c_int), intent(in) :: i\"\n    write (unit, \"(A)\")  \"  type(c_ptr), intent(out) :: cptr\"\n    write (unit, \"(A)\")  \"  integer(c_int), intent(out) :: len\"\n    write (unit, \"(A)\")  \"  character(kind=c_char), dimension(:), &\n         &allocatable, target, save :: a\"\n    call write_string_to_array_interface (unit, prefix)\n    write (unit, \"(A)\")  \"  select case (i)\"\n    write (unit, \"(A)\")  \"  case (0);  if (allocated (a))  deallocate (a)\"\n    do i = 1, driver%n_processes\n       write (unit, \"(A,I0,9A)\")  \"  case (\", i, \");  \", &\n            \"call \", char (prefix), \"string_to_array ('\" , &\n            char (driver%record(i)%model_name), &\n            \"', a)\"\n    end do\n    write (unit, \"(A)\")  \"  end select\"\n    write (unit, \"(A)\")  \"  if (allocated (a)) then\"\n    write (unit, \"(A)\")  \"     cptr = c_loc (a)\"\n    write (unit, \"(A)\")  \"     len = size (a)\"\n    write (unit, \"(A)\")  \"  else\"\n    write (unit, \"(A)\")  \"     cptr = c_null_ptr\"\n    write (unit, \"(A)\")  \"     len = 0\"\n    write (unit, \"(A)\")  \"  end if\"\n    write (unit, \"(A)\")  \"end subroutine \" // char (prefix) &\n         // \"get_model_name_ptr\"\n  end subroutine write_get_model_name_fun\n\n@ %def write_get_model_name_fun\n@ Call the MD5 sum function for the process.  The function calls the\ncorresponding function of the matrix-element code, and it returns the\nC address of a character array with length 32.\n<<Prclib interfaces: prclib driver: TBP>>=\n  procedure :: write_get_md5sum_fun\n<<Prclib interfaces: procedures>>=\n  subroutine write_get_md5sum_fun (driver, unit, prefix)\n    class(prclib_driver_t), intent(in) :: driver\n    integer, intent(in) :: unit\n    type(string_t), intent(in) :: prefix\n    integer :: i\n    write (unit, \"(A)\")  \"\"\n    write (unit, \"(A)\")  \"! Return the MD5 sum for the process configuration &\n         &(as a C pointer to a character array)\"\n    write (unit, \"(A)\")  \"subroutine \" // char (prefix) &\n         // \"get_md5sum_ptr (i, cptr, len) bind(C)\"\n    write (unit, \"(A)\")  \"  use iso_c_binding\"\n    call driver%write_interfaces (unit, var_str (\"md5sum\"))\n    write (unit, \"(A)\")  \"  interface\"\n    write (unit, \"(A)\")  \"     function \" // char (prefix) &\n         // \"md5sum () result (md5sum)\"\n    write (unit, \"(A)\")  \"       character(32) :: md5sum\"\n    write (unit, \"(A)\")  \"     end function \" // char (prefix) // \"md5sum\"\n    write (unit, \"(A)\")  \"  end interface\"\n    write (unit, \"(A)\")  \"  integer(c_int), intent(in) :: i\"\n    write (unit, \"(A)\")  \"  type(c_ptr), intent(out) :: cptr\"\n    write (unit, \"(A)\")  \"  integer(c_int), intent(out) :: len\"\n    write (unit, \"(A)\")  \"  character(kind=c_char), dimension(32), &\n         &target, save :: md5sum\"\n    write (unit, \"(A)\")  \"  select case (i)\"\n    write (unit, \"(A)\")  \"  case (0)\"\n    write (unit, \"(A)\")  \"     call copy (\" // char (prefix) // \"md5sum ())\"\n    write (unit, \"(A)\")  \"     cptr = c_loc (md5sum)\"\n    do i = 1, driver%n_processes\n       write (unit, \"(A,I0,A)\")  \"  case (\", i, \")\"\n       call driver%record(i)%write_md5sum_call (unit)\n    end do\n    write (unit, \"(A)\")  \"  case default\"\n    write (unit, \"(A)\")  \"     cptr = c_null_ptr\"\n    write (unit, \"(A)\")  \"  end select\"\n    write (unit, \"(A)\")  \"  len = 32\"\n    write (unit, \"(A)\")  \"contains\"\n    write (unit, \"(A)\")  \"  subroutine copy (md5sum_tmp)\"\n    write (unit, \"(A)\")  \"    character, dimension(32), intent(in) :: &\n         &md5sum_tmp\"\n    write (unit, \"(A)\")  \"    md5sum = md5sum_tmp\"\n    write (unit, \"(A)\")  \"  end subroutine copy\"\n    write (unit, \"(A)\")  \"end subroutine \" // char (prefix) &\n           // \"get_md5sum_ptr\"\n  end subroutine write_get_md5sum_fun\n\n@ %def write_get_md5sum_fun\n@ The actual call depends on the type of matrix element.\n<<Prclib interfaces: prclib driver record: TBP>>=\n  procedure :: write_md5sum_call => prclib_driver_record_write_md5sum_call\n<<Prclib interfaces: procedures>>=\n  subroutine prclib_driver_record_write_md5sum_call (record, unit)\n    class(prclib_driver_record_t), intent(in) :: record\n    integer, intent(in) :: unit\n    call record%writer%write_md5sum_call (unit, record%id)\n  end subroutine prclib_driver_record_write_md5sum_call\n\n@ %def prclib_driver_record_write_md5sum_call\n@ The interface goes into the writer base type:\n<<Prclib interfaces: prc writer: TBP>>=\n  procedure(write_code), deferred :: write_md5sum_call\n@ %def write_md5sum_call\n@ In the Fortran module case, we take a detour.  The string returned\nby the Fortran function is copied into a fixed-size array.  The copy\nroutine is an internal subroutine of [[get_md5sum_ptr]].  We\nreturn the C address of the target array.\n<<Prclib interfaces: prc writer f module: TBP>>=\n  procedure :: write_md5sum_call => prc_writer_f_module_write_md5sum_call\n<<Prclib interfaces: procedures>>=\n  subroutine prc_writer_f_module_write_md5sum_call (writer, unit, id)\n    class(prc_writer_f_module_t), intent(in) :: writer\n    integer, intent(in) :: unit\n    type(string_t), intent(in) :: id\n    write (unit, \"(5x,9A)\")  \"call copy (\", &\n         char (writer%get_c_procname (id, var_str (\"md5sum\"))), \" ())\"\n    write (unit, \"(5x,9A)\")  \"cptr = c_loc (md5sum)\"\n  end subroutine prc_writer_f_module_write_md5sum_call\n\n@ %def prc_writer_f_module_write_md5sum_call\n@ In the C library case, the library function returns a C pointer,\nwhich we can just copy.\n<<Prclib interfaces: prc writer c lib: TBP>>=\n  procedure :: write_md5sum_call => prc_writer_c_lib_write_md5sum_call\n<<Prclib interfaces: procedures>>=\n  subroutine prc_writer_c_lib_write_md5sum_call (writer, unit, id)\n    class(prc_writer_c_lib_t), intent(in) :: writer\n    integer, intent(in) :: unit\n    type(string_t), intent(in) :: id\n    write (unit, \"(5x,9A)\") &\n         \"cptr =  \", &\n         char (writer%get_c_procname (id, var_str (\"get_md5sum\"))), \" ()\"\n  end subroutine prc_writer_c_lib_write_md5sum_call\n\n@ %def prc_writer_c_lib_write_md5sum_call\n@\n\\subsubsection{Actual references to the info functions}\nThe string-valued info functions return C character arrays.  For the\nAPI of the library driver, we provide convenience functions which\n(re)convert those arrays into [[string_t]] objects.\n<<Prclib interfaces: prclib driver: TBP>>=\n  procedure :: get_process_id => prclib_driver_get_process_id\n  procedure :: get_model_name => prclib_driver_get_model_name\n  procedure :: get_md5sum => prclib_driver_get_md5sum\n<<Prclib interfaces: procedures>>=\n  function prclib_driver_get_process_id (driver, i) result (string)\n    type(string_t) :: string\n    class(prclib_driver_t), intent(in) :: driver\n    integer, intent(in) :: i\n    call get_string_via_cptr (string, i, driver%get_process_id_ptr)\n  end function prclib_driver_get_process_id\n\n  function prclib_driver_get_model_name (driver, i) result (string)\n    type(string_t) :: string\n    class(prclib_driver_t), intent(in) :: driver\n    integer, intent(in) :: i\n    call get_string_via_cptr (string, i, driver%get_model_name_ptr)\n  end function prclib_driver_get_model_name\n\n  function prclib_driver_get_md5sum (driver, i) result (string)\n    type(string_t) :: string\n    class(prclib_driver_t), intent(in) :: driver\n    integer, intent(in) :: i\n    call get_string_via_cptr (string, i, driver%get_md5sum_ptr)\n  end function prclib_driver_get_md5sum\n\n@ %def prclib_driver_get_process_id\n@ %def prclib_driver_get_model_name\n@ %def prclib_driver_get_md5sum\n@\n\\subsubsection{Informational logical functions}\nWhen returning a logical value, we use the C boolean type, which\nmay differ from Fortran.\n<<Prclib interfaces: public>>=\n  public :: prc_get_log\n<<Prclib interfaces: interfaces>>=\n  abstract interface\n     function prc_get_log (pid) result (l) bind(C)\n       import\n       integer(c_int), intent(in) :: pid\n       logical(c_bool) :: l\n     end function prc_get_log\n  end interface\n@ %def prc_get_log\n@ Return a logical flag which tells whether OpenMP is supported for a\nspecific process code.\n<<Prclib interfaces: prclib driver: TBP>>=\n  procedure :: write_get_openmp_status_fun\n<<Prclib interfaces: procedures>>=\n  subroutine write_get_openmp_status_fun (driver, unit, prefix)\n    class(prclib_driver_t), intent(in) :: driver\n    integer, intent(in) :: unit\n    type(string_t), intent(in) :: prefix\n    integer :: i\n    write (unit, \"(A)\")  \"\"\n    write (unit, \"(A)\")  \"! Return the OpenMP support status\"\n    write (unit, \"(A)\")  \"function \" // char (prefix) &\n         // \"get_openmp_status (i) result (openmp_status) bind(C)\"\n    write (unit, \"(A)\")  \"  use iso_c_binding\"\n    call driver%write_interfaces (unit, var_str (\"openmp_supported\"))\n    write (unit, \"(A)\")  \"  integer(c_int), intent(in) :: i\"\n    write (unit, \"(A)\")  \"  logical(c_bool) :: openmp_status\"\n    write (unit, \"(A)\")  \"  select case (i)\"\n    do i = 1, driver%n_processes\n       write (unit, \"(A,I0,9A)\")  \"  case (\", i, \");  \", &\n            \"openmp_status = \", &\n            char (driver%record(i)%get_c_procname &\n            (var_str (\"openmp_supported\"))), \" ()\"\n    end do\n    write (unit, \"(A)\")  \"  end select\"\n    write (unit, \"(A)\")  \"end function \" // char (prefix) &\n         // \"get_openmp_status\"\n  end subroutine write_get_openmp_status_fun\n\n@ %def write_get_openmp_status_fun\n@\n\\subsubsection{Informational integer functions}\nVarious process metadata are integer values.  We can use a single\ninterface for all of them.\n<<Prclib interfaces: public>>=\n  public :: prc_get_int\n<<Prclib interfaces: interfaces>>=\n  abstract interface\n     function prc_get_int (pid) result (n) bind(C)\n       import\n       integer(c_int), intent(in) :: pid\n       integer(c_int) :: n\n     end function prc_get_int\n  end interface\n@ %def prc_get_int\n@ This function returns any data of type integer, for each process.\n<<Prclib interfaces: prclib driver: TBP>>=\n  procedure :: write_get_int_fun\n<<Prclib interfaces: procedures>>=\n  subroutine write_get_int_fun (driver, unit, prefix, feature)\n    class(prclib_driver_t), intent(in) :: driver\n    integer, intent(in) :: unit\n    type(string_t), intent(in) :: prefix\n    type(string_t), intent(in) :: feature\n    integer :: i\n    write (unit, \"(A)\")  \"\"\n    write (unit, \"(9A)\")  \"! Return the value of \", char (feature)\n    write (unit, \"(9A)\")  \"function \", char (prefix), &\n         \"get_\", char (feature), \" (pid)\", &\n         \" result (\", char (feature), \") bind(C)\"\n    write (unit, \"(9A)\")  \"  use iso_c_binding\"\n    call driver%write_interfaces (unit, feature)\n    write (unit, \"(9A)\")  \"  integer(c_int), intent(in) :: pid\"\n    write (unit, \"(9A)\")  \"  integer(c_int) :: \", char (feature)\n    write (unit, \"(9A)\")  \"  select case (pid)\"\n    do i = 1, driver%n_processes\n       write (unit, \"(2x,A,I0,9A)\")  \"case (\", i, \");  \", &\n            char (feature), \" = \", &\n            char (driver%record(i)%get_c_procname (feature)), &\n            \" ()\"\n    end do\n    write (unit, \"(9A)\")  \"  end select\"\n    write (unit, \"(9A)\")  \"end function \", char (prefix), &\n         \"get_\", char (feature)\n  end subroutine write_get_int_fun\n\n@ %def write_get_int_fun\n@ Write a [[case]] line that assigns the value of the external function\nto the current return value.\n<<Prclib interfaces: procedures>>=\n  subroutine write_case_int_fun (record, unit, i, feature)\n    class(prclib_driver_record_t), intent(in) :: record\n    integer, intent(in) :: unit\n    integer, intent(in) :: i\n    type(string_t), intent(in) :: feature\n    write (unit, \"(5x,A,I0,9A)\")  \"case (\", i, \");  \", &\n         char (feature), \" = \", char (record%get_c_procname (feature))\n  end subroutine write_case_int_fun\n\n@ %def write_case_int_fun\n@\n\\subsubsection{Flavor and helicity tables}\nTransferring tables is more complicated.  First, a two-dimensional array.\n<<Prclib interfaces: public>>=\n  public :: prc_set_int_tab1\n<<Prclib interfaces: interfaces>>=\n  abstract interface\n     subroutine prc_set_int_tab1 (pid, tab, shape) bind(C)\n       import\n       integer(c_int), intent(in) :: pid\n       integer(c_int), dimension(*), intent(out) :: tab\n       integer(c_int), dimension(2), intent(in) :: shape\n     end subroutine prc_set_int_tab1\n  end interface\n@ %def prc_set_int_tab1\n@ This subroutine returns a table of integers.\n<<Prclib interfaces: prclib driver: TBP>>=\n  procedure :: write_set_int_sub\n<<Prclib interfaces: procedures>>=\n  subroutine write_set_int_sub (driver, unit, prefix, feature)\n    class(prclib_driver_t), intent(in) :: driver\n    integer, intent(in) :: unit\n    type(string_t), intent(in) :: prefix\n    type(string_t), intent(in) :: feature\n    integer :: i\n    write (unit, \"(A)\")  \"\"\n    write (unit, \"(9A)\")  \"! Set table: \", char (feature)\n    write (unit, \"(9A)\")  \"subroutine \", char (prefix), &\n         \"set_\", char (feature), \"_ptr (pid, \", char (feature), &\n         \", shape) bind(C)\"\n    write (unit, \"(9A)\")  \"  use iso_c_binding\"\n    call driver%write_interfaces (unit, feature)\n    write (unit, \"(9A)\")  \"  integer(c_int), intent(in) :: pid\"\n    write (unit, \"(9A)\")  \"  integer(c_int), dimension(*), intent(out) :: \", &\n         char (feature)\n    write (unit, \"(9A)\")  \"  integer(c_int), dimension(2), intent(in) :: shape\"\n    write (unit, \"(9A)\")  \"  integer, dimension(:,:), allocatable :: \", &\n         char (feature), \"_tmp\"\n    write (unit, \"(9A)\")  \"  integer :: i, j\"\n    write (unit, \"(9A)\")  \"  select case (pid)\"\n    do i = 1, driver%n_processes\n       write (unit, \"(2x,A,I0,A)\")  \"case (\", i, \")\"\n       call driver%record(i)%write_int_sub_call (unit, feature)\n    end do\n    write (unit, \"(9A)\")  \"  end select\"\n    write (unit, \"(9A)\")  \"end subroutine \", char (prefix), &\n         \"set_\", char (feature), \"_ptr\"\n  end subroutine write_set_int_sub\n\n@ %def write_set_int_sub\n@ The actual call depends on the type of matrix element.\n<<Prclib interfaces: prclib driver record: TBP>>=\n  procedure :: write_int_sub_call => prclib_driver_record_write_int_sub_call\n<<Prclib interfaces: procedures>>=\n  subroutine prclib_driver_record_write_int_sub_call (record, unit, feature)\n    class(prclib_driver_record_t), intent(in) :: record\n    integer, intent(in) :: unit\n    type(string_t), intent(in) :: feature\n    call record%writer%write_int_sub_call (unit, record%id, feature)\n  end subroutine prclib_driver_record_write_int_sub_call\n\n@ %def prclib_driver_record_write_int_sub_call\n@ The interface goes into the writer base type:\n<<Prclib interfaces: prc writer: TBP>>=\n  procedure(write_feature_code), deferred :: write_int_sub_call\n@ %def write_int_sub_call\n@ In the Fortran module case, we need an extra copy in the\n(academical) situation where default integer and [[c_int]] differ.\nOtherwise, we just associate a Fortran array with the C pointer and\nlet the matrix-element subroutine fill the array.\n<<Prclib interfaces: prc writer f module: TBP>>=\n  procedure :: write_int_sub_call => prc_writer_f_module_write_int_sub_call\n<<Prclib interfaces: procedures>>=\n  subroutine prc_writer_f_module_write_int_sub_call (writer, unit, id, feature)\n    class(prc_writer_f_module_t), intent(in) :: writer\n    integer, intent(in) :: unit\n    type(string_t), intent(in) :: id, feature\n    write (unit, \"(5x,9A)\")  \"allocate (\",  char (feature), \"_tmp \", &\n         \"(shape(1), shape(2)))\"\n    write (unit, \"(5x,9A)\")  \"call \", &\n         char (writer%get_c_procname (id, feature)), &\n         \" (\", char (feature), \"_tmp)\"\n    write (unit, \"(5x,9A)\")  \"forall (i=1:shape(1), j=1:shape(2)) \"\n    write (unit, \"(8x,9A)\")  char (feature), \"(i + shape(1)*(j-1)) = \", &\n         char (feature), \"_tmp\", \"(i,j)\"\n    write (unit, \"(5x,9A)\")  \"end forall\"\n  end subroutine prc_writer_f_module_write_int_sub_call\n\n@ %def prc_writer_f_module_write_int_sub_call\n@ In the C library case, we just transfer the C pointer to the library\nfunction.\n<<Prclib interfaces: prc writer c lib: TBP>>=\n  procedure :: write_int_sub_call => prc_writer_c_lib_write_int_sub_call\n<<Prclib interfaces: procedures>>=\n  subroutine prc_writer_c_lib_write_int_sub_call (writer, unit, id, feature)\n    class(prc_writer_c_lib_t), intent(in) :: writer\n    integer, intent(in) :: unit\n    type(string_t), intent(in) :: id, feature\n    write (unit, \"(5x,9A)\")  \"call \", &\n         char (writer%get_c_procname (id, feature)), \" (\", char (feature), \")\"\n  end subroutine prc_writer_c_lib_write_int_sub_call\n\n@ %def prc_writer_c_lib_write_int_sub_call\n@\n\\subsubsection{Color state table}\nThe color-state specification needs a table of integers (one array per\ncolor flow) and a corresponding array of color-ghost flags.\n<<Prclib interfaces: public>>=\n  public :: prc_set_col_state\n<<Prclib interfaces: interfaces>>=\n  abstract interface\n     subroutine prc_set_col_state (pid, col_state, ghost_flag, shape) bind(C)\n       import\n       integer(c_int), intent(in) :: pid\n       integer(c_int), dimension(*), intent(out) :: col_state\n       logical(c_bool), dimension(*), intent(out) :: ghost_flag\n       integer(c_int), dimension(3), intent(in) :: shape\n     end subroutine prc_set_col_state\n  end interface\n@ %def prc_set_int_tab2\n@\n<<Prclib interfaces: prclib driver: TBP>>=\n  procedure :: write_set_col_state_sub\n<<Prclib interfaces: procedures>>=\n  subroutine write_set_col_state_sub (driver, unit, prefix)\n    class(prclib_driver_t), intent(in) :: driver\n    integer, intent(in) :: unit\n    type(string_t), intent(in) :: prefix\n    integer :: i\n    type(string_t) :: feature\n    feature = \"col_state\"\n    write (unit, \"(A)\")  \"\"\n    write (unit, \"(9A)\")  \"! Set tables: col_state, ghost_flag\"\n    write (unit, \"(9A)\")  \"subroutine \", char (prefix), &\n         \"set_col_state_ptr (pid, col_state, ghost_flag, shape) bind(C)\"\n    write (unit, \"(9A)\")  \"  use iso_c_binding\"\n    call driver%write_interfaces (unit, feature)\n    write (unit, \"(9A)\")  \"  integer(c_int), intent(in) :: pid\"\n    write (unit, \"(9A)\") &\n         \"  integer(c_int), dimension(*), intent(out) :: col_state\"\n    write (unit, \"(9A)\") &\n         \"  logical(c_bool), dimension(*), intent(out) :: ghost_flag\"\n    write (unit, \"(9A)\") &\n         \"  integer(c_int), dimension(3), intent(in) :: shape\"\n    write (unit, \"(9A)\") &\n         \"  integer, dimension(:,:,:), allocatable :: col_state_tmp\"\n    write (unit, \"(9A)\") &\n         \"  logical, dimension(:,:), allocatable :: ghost_flag_tmp\"\n    write (unit, \"(9A)\") \"  integer :: i, j, k\"\n    write (unit, \"(A)\")  \"  select case (pid)\"\n    do i = 1, driver%n_processes\n       write (unit, \"(A,I0,A)\")  \"  case (\", i, \")\"\n       call driver%record(i)%write_col_state_call (unit)\n    end do\n    write (unit, \"(A)\")  \"  end select\"\n    write (unit, \"(9A)\")  \"end subroutine \", char (prefix), &\n         \"set_col_state_ptr\"\n  end subroutine write_set_col_state_sub\n\n@ %def write_set_col_state_sub\n@ The actual call depends on the type of matrix element.\n<<Prclib interfaces: prclib driver record: TBP>>=\n  procedure :: write_col_state_call => prclib_driver_record_write_col_state_call\n<<Prclib interfaces: procedures>>=\n  subroutine prclib_driver_record_write_col_state_call (record, unit)\n    class(prclib_driver_record_t), intent(in) :: record\n    integer, intent(in) :: unit\n    call record%writer%write_col_state_call (unit, record%id)\n  end subroutine prclib_driver_record_write_col_state_call\n\n@ %def prclib_driver_record_write_col_state_call\n@ The interface goes into the writer base type:\n<<Prclib interfaces: prc writer: TBP>>=\n  procedure(write_code), deferred :: write_col_state_call\n@ %def write_col_state_call\n@ In the Fortran module case, we need an extra copy in the\n(academical) situation where default integer and [[c_int]] differ.\nOtherwise, we just associate a Fortran array with the C pointer and\nlet the matrix-element subroutine fill the array.\n<<Prclib interfaces: prc writer f module: TBP>>=\n  procedure :: write_col_state_call => prc_writer_f_module_write_col_state_call\n<<Prclib interfaces: procedures>>=\n  subroutine prc_writer_f_module_write_col_state_call (writer, unit, id)\n    class(prc_writer_f_module_t), intent(in) :: writer\n    integer, intent(in) :: unit\n    type(string_t), intent(in) :: id\n    write (unit, \"(9A)\")  \"  allocate (col_state_tmp \", &\n            \"(shape(1), shape(2), shape(3)))\"\n    write (unit, \"(5x,9A)\")  \"allocate (ghost_flag_tmp \", &\n               \"(shape(2), shape(3)))\"\n    write (unit, \"(5x,9A)\")  \"call \", &\n         char (writer%get_c_procname (id, var_str (\"col_state\"))), &\n         \" (col_state_tmp, ghost_flag_tmp)\"\n    write (unit, \"(5x,9A)\")  \"forall (i = 1:shape(2), j = 1:shape(3))\"\n    write (unit, \"(8x,9A)\")  \"forall (k = 1:shape(1))\"\n    write (unit, \"(11x,9A)\")  &\n         \"col_state(k + shape(1) * (i + shape(2)*(j-1) - 1)) \", &\n         \"= col_state_tmp(k,i,j)\"\n    write (unit, \"(8x,9A)\")  \"end forall\"\n    write (unit, \"(8x,9A)\")  &\n         \"ghost_flag(i + shape(2)*(j-1)) = ghost_flag_tmp(i,j)\"\n    write (unit, \"(5x,9A)\")  \"end forall\"\n  end subroutine prc_writer_f_module_write_col_state_call\n\n@ %def prc_writer_f_module_write_col_state_call\n@ In the C library case, we just transfer the C pointer to the library\nfunction.\n<<Prclib interfaces: prc writer c lib: TBP>>=\n  procedure :: write_col_state_call => prc_writer_c_lib_write_col_state_call\n<<Prclib interfaces: procedures>>=\n  subroutine prc_writer_c_lib_write_col_state_call (writer, unit, id)\n    class(prc_writer_c_lib_t), intent(in) :: writer\n    integer, intent(in) :: unit\n    type(string_t), intent(in) :: id\n    write (unit, \"(5x,9A)\")  \"call \", &\n         char (writer%get_c_procname (id, var_str (\"col_state\"))), &\n         \" (col_state, ghost_flag)\"\n  end subroutine prc_writer_c_lib_write_col_state_call\n\n@ %def prc_writer_c_lib_write_col_state_call\n@\n\\subsubsection{Color factors}\nFor the color-factor information, we return two integer arrays and a\ncomplex array.\n<<Prclib interfaces: public>>=\n  public :: prc_set_color_factors\n<<Prclib interfaces: interfaces>>=\n  abstract interface\n     subroutine prc_set_color_factors &\n          (pid, cf_index1, cf_index2, color_factors, shape) bind(C)\n       import\n       integer(c_int), intent(in) :: pid\n       integer(c_int), dimension(*), intent(out) :: cf_index1, cf_index2\n       complex(c_default_complex), dimension(*), intent(out) :: color_factors\n       integer(c_int), dimension(1), intent(in) :: shape\n     end subroutine prc_set_color_factors\n  end interface\n\n@ %def prc_set_color_factors\n@ This subroutine returns the color-flavor factor table.\n<<Prclib interfaces: prclib driver: TBP>>=\n  procedure :: write_set_color_factors_sub\n<<Prclib interfaces: procedures>>=\n  subroutine write_set_color_factors_sub (driver, unit, prefix)\n    class(prclib_driver_t), intent(in) :: driver\n    integer, intent(in) :: unit\n    type(string_t), intent(in) :: prefix\n    integer :: i\n    type(string_t) :: feature\n    feature = \"color_factors\"\n    write (unit, \"(A)\")  \"\"\n    write (unit, \"(A)\")  \"! Set tables: color factors\"\n    write (unit, \"(9A)\")  \"subroutine \", char (prefix), &\n         \"set_color_factors_ptr (pid, cf_index1, cf_index2, color_factors, \", &\n         \"shape) bind(C)\"\n    write (unit, \"(A)\")  \"  use iso_c_binding\"\n    write (unit, \"(A)\")  \"  use kinds\"\n    write (unit, \"(A)\")  \"  use omega_color\"\n    call driver%write_interfaces (unit, feature)\n    write (unit, \"(A)\")  \"  integer(c_int), intent(in) :: pid\"\n    write (unit, \"(A)\")  \"  integer(c_int), dimension(1), intent(in) :: shape\"\n    write (unit, \"(A)\")  \"  integer(c_int), dimension(*), intent(out) :: &\n         &cf_index1, cf_index2\"\n    write (unit, \"(A)\")  \"  complex(c_default_complex), dimension(*), &\n         &intent(out) :: color_factors\"\n    write (unit, \"(A)\")  \"  type(omega_color_factor), dimension(:), &\n         &allocatable :: cf\"\n    write (unit, \"(A)\")  \"  select case (pid)\"\n    do i = 1, driver%n_processes\n       write (unit, \"(2x,A,I0,A)\")  \"case (\", i, \")\"\n       call driver%record(i)%write_color_factors_call (unit)\n    end do\n    write (unit, \"(A)\")  \"  end select\"\n    write (unit, \"(A)\")  \"end subroutine \" // char (prefix) &\n         // \"set_color_factors_ptr\"\n  end subroutine write_set_color_factors_sub\n\n@ %def write_set_color_factors_sub\n@ The actual call depends on the type of matrix element.\n<<Prclib interfaces: prclib driver record: TBP>>=\n  procedure :: write_color_factors_call => prclib_driver_record_write_color_factors_call\n<<Prclib interfaces: procedures>>=\n  subroutine prclib_driver_record_write_color_factors_call (record, unit)\n    class(prclib_driver_record_t), intent(in) :: record\n    integer, intent(in) :: unit\n    call record%writer%write_color_factors_call (unit, record%id)\n  end subroutine prclib_driver_record_write_color_factors_call\n\n@ %def prclib_driver_record_write_color_factors_call\n@ The interface goes into the writer base type:\n<<Prclib interfaces: prc writer: TBP>>=\n  procedure(write_code), deferred :: write_color_factors_call\n@ %def write_color_factors_call\n@ In the Fortran module case, the matrix-element procedure fills an\narray of [[omega_color_factor]] elements.  We distribute this array\namong two integer arrays and one complex-valued array, for which we\nhave the C pointers.\n<<Prclib interfaces: prc writer f module: TBP>>=\n  procedure :: write_color_factors_call => prc_writer_f_module_write_color_factors_call\n<<Prclib interfaces: procedures>>=\n  subroutine prc_writer_f_module_write_color_factors_call (writer, unit, id)\n    class(prc_writer_f_module_t), intent(in) :: writer\n    integer, intent(in) :: unit\n    type(string_t), intent(in) :: id\n    write (unit, \"(5x,A)\")  \"allocate (cf (shape(1)))\"\n    write (unit, \"(5x,9A)\")  \"call \", &\n         char (writer%get_c_procname (id, var_str (\"color_factors\"))), \" (cf)\"\n    write (unit, \"(5x,9A)\")  \"cf_index1(1:shape(1)) = cf%i1\"\n    write (unit, \"(5x,9A)\")  \"cf_index2(1:shape(1)) = cf%i2\"\n    write (unit, \"(5x,9A)\")  \"color_factors(1:shape(1)) = cf%factor\"\n  end subroutine prc_writer_f_module_write_color_factors_call\n\n@ %def prc_writer_f_module_write_color_factors_call\n@ In the C library case, we just transfer the C pointers to the library\nfunction.  There are three arrays.\n<<Prclib interfaces: prc writer c lib: TBP>>=\n  procedure :: write_color_factors_call => &\n       prc_writer_c_lib_write_color_factors_call\n<<Prclib interfaces: procedures>>=\n  subroutine prc_writer_c_lib_write_color_factors_call (writer, unit, id)\n    class(prc_writer_c_lib_t), intent(in) :: writer\n    integer, intent(in) :: unit\n    type(string_t), intent(in) :: id\n    write (unit, \"(5x,9A)\")  \"call \", &\n         char (writer%get_c_procname (id, var_str (\"color_factors\"))), &\n         \" (cf_index1, cf_index2, color_factors)\"\n  end subroutine prc_writer_c_lib_write_color_factors_call\n\n@ %def prc_writer_c_lib_write_color_factors_call\n@\n\\subsection{Interfaces for C-library matrix element}\nIf the matrix element code is not provided as a Fortran module but as\na C or bind(C) Fortran library, we need explicit interfaces for the\nlibrary functions.  They are not identical to the Fortran module\nversions.  They transfer pointers directly.\n\nThe implementation is part of the [[prc_writer_c_lib]] type, which\nserves as base type for all C-library writers.  It writes specific\ninterfaces depending on the feature.\n\nWe bind this as the method [[write_standard_interface]] instead of\n[[write_interface]], because we have to override the latter.\nOtherwise we could not call the method because the writer type is\nabstract.\n<<Prclib interfaces: prc writer c lib: TBP>>=\n  procedure :: write_standard_interface => prc_writer_c_lib_write_interface\n<<Prclib interfaces: procedures>>=\n  subroutine prc_writer_c_lib_write_interface (writer, unit, id, feature)\n    class(prc_writer_c_lib_t), intent(in) :: writer\n    integer, intent(in) :: unit\n    type(string_t), intent(in) :: id, feature\n    select case (char (feature))\n    case (\"md5sum\")\n       write (unit, \"(2x,9A)\")  \"interface\"\n       write (unit, \"(5x,9A)\")  \"function \", &\n            char (writer%get_c_procname (id, var_str (\"get_md5sum\"))), &\n            \" () result (cptr) bind(C)\"\n       write (unit, \"(7x,9A)\")  \"import\"\n       write (unit, \"(7x,9A)\")  \"implicit none\"\n       write (unit, \"(7x,9A)\")  \"type(c_ptr) :: cptr\"\n       write (unit, \"(5x,9A)\")  \"end function \", &\n            char (writer%get_c_procname (id, var_str (\"get_md5sum\")))\n       write (unit, \"(2x,9A)\")  \"end interface\"\n    case (\"openmp_supported\")\n       write (unit, \"(2x,9A)\")  \"interface\"\n       write (unit, \"(5x,9A)\")  \"function \", &\n            char (writer%get_c_procname (id, feature)), &\n            \" () result (status) bind(C)\"\n       write (unit, \"(7x,9A)\")  \"import\"\n       write (unit, \"(7x,9A)\")  \"implicit none\"\n       write (unit, \"(7x,9A)\")  \"logical(c_bool) :: status\"\n       write (unit, \"(5x,9A)\")  \"end function \", &\n            char (writer%get_c_procname (id, feature))\n       write (unit, \"(2x,9A)\")  \"end interface\"\n    case (\"n_in\", \"n_out\", \"n_flv\", \"n_hel\", \"n_col\", \"n_cin\", \"n_cf\")\n       write (unit, \"(2x,9A)\")  \"interface\"\n       write (unit, \"(5x,9A)\")  \"function \", &\n            char (writer%get_c_procname (id, feature)), &\n            \" () result (n) bind(C)\"\n       write (unit, \"(7x,9A)\")  \"import\"\n       write (unit, \"(7x,9A)\")  \"implicit none\"\n       write (unit, \"(7x,9A)\")  \"integer(c_int) :: n\"\n       write (unit, \"(5x,9A)\")  \"end function \", &\n            char (writer%get_c_procname (id, feature))\n       write (unit, \"(2x,9A)\")  \"end interface\"\n    case (\"flv_state\", \"hel_state\")\n       write (unit, \"(2x,9A)\")  \"interface\"\n       write (unit, \"(5x,9A)\")  \"subroutine \", &\n            char (writer%get_c_procname (id, feature)), &\n            \" (\", char (feature), \") bind(C)\"\n       write (unit, \"(7x,9A)\")  \"import\"\n       write (unit, \"(7x,9A)\")  \"implicit none\"\n       write (unit, \"(7x,9A)\")  \"integer(c_int), dimension(*), intent(out) \", &\n            \":: \", char (feature)\n       write (unit, \"(5x,9A)\")  \"end subroutine \", &\n            char (writer%get_c_procname (id, feature))\n       write (unit, \"(2x,9A)\")  \"end interface\"\n    case (\"col_state\")\n       write (unit, \"(2x,9A)\")  \"interface\"\n       write (unit, \"(5x,9A)\")  \"subroutine \", &\n            char (writer%get_c_procname (id, feature)), &\n            \" (col_state, ghost_flag) bind(C)\"\n       write (unit, \"(7x,9A)\")  \"import\"\n       write (unit, \"(7x,9A)\")  \"implicit none\"\n       write (unit, \"(7x,9A)\")  \"integer(c_int), dimension(*), intent(out) \", &\n            \":: col_state\"\n       write (unit, \"(7x,9A)\")  \"logical(c_bool), dimension(*), intent(out) \", &\n            \":: ghost_flag\"\n       write (unit, \"(5x,9A)\")  \"end subroutine \", &\n            char (writer%get_c_procname (id, feature))\n       write (unit, \"(2x,9A)\")  \"end interface\"\n    case (\"color_factors\")\n       write (unit, \"(2x,9A)\")  \"interface\"\n       write (unit, \"(5x,9A)\")  \"subroutine \", &\n            char (writer%get_c_procname (id, feature)), &\n            \" (cf_index1, cf_index2, color_factors) bind(C)\"\n       write (unit, \"(7x,9A)\")  \"import\"\n       write (unit, \"(7x,9A)\")  \"implicit none\"\n       write (unit, \"(7x,9A)\")  \"integer(c_int), dimension(*), &\n            &intent(out) :: cf_index1\"\n       write (unit, \"(7x,9A)\")  \"integer(c_int), dimension(*), &\n            &intent(out) :: cf_index2\"\n       write (unit, \"(7x,9A)\")  \"complex(c_default_complex), dimension(*), &\n            &intent(out) :: color_factors\"\n       write (unit, \"(5x,9A)\")  \"end subroutine \", &\n            char (writer%get_c_procname (id, feature))\n       write (unit, \"(2x,9A)\")  \"end interface\"\n    end select\n  end subroutine prc_writer_c_lib_write_interface\n\n@ %def prc_writer_c_lib_write_interface\n@\n\\subsection{Retrieving the tables}\nIn the previous section we had the writer routines for procedures that\nreturn tables, actually C pointers to tables.  Here, we write\nconvenience routines that unpack them and move the contents to\nsuitable Fortran arrays.\n\nThe flavor and helicity tables are two-dimensional integer arrays.  We\nuse intermediate storage for correctly transforming C to Fortran data\ntypes.\n<<Prclib interfaces: prclib driver: TBP>>=\n  procedure :: set_flv_state => prclib_driver_set_flv_state\n  procedure :: set_hel_state => prclib_driver_set_hel_state\n<<Prclib interfaces: procedures>>=\n  subroutine prclib_driver_set_flv_state (driver, i, flv_state)\n    class(prclib_driver_t), intent(in) :: driver\n    integer, intent(in) :: i\n    integer, dimension(:,:), allocatable, intent(out) :: flv_state\n    integer :: n_tot, n_flv\n    integer(c_int) :: pid\n    integer(c_int), dimension(:,:), allocatable :: c_flv_state\n    pid = i\n    n_tot = driver%get_n_in (pid) + driver%get_n_out (pid)\n    n_flv = driver%get_n_flv (pid)\n    allocate (flv_state (n_tot, n_flv))\n    allocate (c_flv_state (n_tot, n_flv))\n    call driver%set_flv_state_ptr &\n         (pid, c_flv_state, int ([n_tot, n_flv], kind=c_int))\n    flv_state = c_flv_state\n  end subroutine prclib_driver_set_flv_state\n\n  subroutine prclib_driver_set_hel_state (driver, i, hel_state)\n    class(prclib_driver_t), intent(in) :: driver\n    integer, intent(in) :: i\n    integer, dimension(:,:), allocatable, intent(out) :: hel_state\n    integer :: n_tot, n_hel\n    integer(c_int) :: pid\n    integer(c_int), dimension(:,:), allocatable, target :: c_hel_state\n    pid = i\n    n_tot = driver%get_n_in (pid) + driver%get_n_out (pid)\n    n_hel = driver%get_n_hel (pid)\n    allocate (hel_state (n_tot, n_hel))\n    allocate (c_hel_state (n_tot, n_hel))\n    call driver%set_hel_state_ptr &\n         (pid, c_hel_state, int ([n_tot, n_hel], kind=c_int))\n    hel_state = c_hel_state\n  end subroutine prclib_driver_set_hel_state\n\n@ %def prclib_driver_set_flv_state\n@ %def prclib_driver_set_hel_state\n@ The color-flow table is three-dimensional, otherwise similar.  We\nsimultaneously set the ghost-flag table, which consists of logical\nentries.\n<<Prclib interfaces: prclib driver: TBP>>=\n  procedure :: set_col_state => prclib_driver_set_col_state\n<<Prclib interfaces: procedures>>=\n  subroutine prclib_driver_set_col_state (driver, i, col_state, ghost_flag)\n    class(prclib_driver_t), intent(in) :: driver\n    integer, intent(in) :: i\n    integer, dimension(:,:,:), allocatable, intent(out) :: col_state\n    logical, dimension(:,:), allocatable, intent(out) :: ghost_flag\n    integer :: n_cin, n_tot, n_col\n    integer(c_int) :: pid\n    integer(c_int), dimension(:,:,:), allocatable :: c_col_state\n    logical(c_bool), dimension(:,:), allocatable :: c_ghost_flag\n    pid = i\n    n_cin = driver%get_n_cin (pid)\n    n_tot = driver%get_n_in (pid) + driver%get_n_out (pid)\n    n_col = driver%get_n_col (pid)\n    allocate (col_state (n_cin, n_tot, n_col))\n    allocate (c_col_state (n_cin, n_tot, n_col))\n    allocate (ghost_flag (n_tot, n_col))\n    allocate (c_ghost_flag (n_tot, n_col))\n    call driver%set_col_state_ptr (pid, &\n         c_col_state, c_ghost_flag, int ([n_cin, n_tot, n_col], kind=c_int))\n    col_state = c_col_state\n    ghost_flag = c_ghost_flag\n  end subroutine prclib_driver_set_col_state\n\n@ %def prclib_driver_set_col_state\n@ The color-factor table is a sparse matrix: a two-column array of indices and\none array which contains the corresponding factors.\n<<Prclib interfaces: prclib driver: TBP>>=\n  procedure :: set_color_factors => prclib_driver_set_color_factors\n<<Prclib interfaces: procedures>>=\n  subroutine prclib_driver_set_color_factors (driver, i, color_factors, cf_index)\n    class(prclib_driver_t), intent(in) :: driver\n    integer, intent(in) :: i\n    complex(default), dimension(:), allocatable, intent(out) :: color_factors\n    integer, dimension(:,:), allocatable, intent(out) :: cf_index\n    integer :: n_cf\n    integer(c_int) :: pid\n    complex(c_default_complex), dimension(:), allocatable, target :: c_color_factors\n    integer(c_int), dimension(:), allocatable, target :: c_cf_index1\n    integer(c_int), dimension(:), allocatable, target :: c_cf_index2\n    pid = i\n    n_cf = driver%get_n_cf (pid)\n    allocate (color_factors (n_cf))\n    allocate (c_color_factors (n_cf))\n    allocate (c_cf_index1 (n_cf))\n    allocate (c_cf_index2 (n_cf))\n    call driver%set_color_factors_ptr (pid, &\n         c_cf_index1, c_cf_index2, &\n         c_color_factors, int ([n_cf], kind=c_int))\n    color_factors = c_color_factors\n    allocate (cf_index (2, n_cf))\n    cf_index(1,:) = c_cf_index1\n    cf_index(2,:) = c_cf_index2\n  end subroutine prclib_driver_set_color_factors\n\n@ %def prclib_driver_set_color_factors\n@\n\\subsection{Returning a procedure pointer}\nThe functions that directly access the matrix element, event by event,\nare assigned to a process-specific driver object as procedure\npointers.  For the [[dlopen]] interface, we use C function pointers.\nThis subroutine returns such a pointer:\n<<Prclib interfaces: public>>=\n  public :: prc_get_fptr\n<<Prclib interfaces: interfaces>>=\n  abstract interface\n     subroutine prc_get_fptr (pid, fid, fptr) bind(C)\n       import\n       integer(c_int), intent(in) :: pid\n       integer(c_int), intent(in) :: fid\n       type(c_funptr), intent(out) :: fptr\n     end subroutine prc_get_fptr\n  end interface\n\n@ %def prc_get_fptr\n@ This procedure writes the source code for the procedure pointer\nreturning subroutine.\n\nAll C functions that are provided by the matrix element code of a\nspecific process are handled here.  The selection consists of a double\nlayered [[select]] [[case]] construct.\n<<Prclib interfaces: prclib driver: TBP>>=\n  procedure :: write_get_fptr_sub\n<<Prclib interfaces: procedures>>=\n  subroutine write_get_fptr_sub (driver, unit, prefix)\n    class(prclib_driver_t), intent(in) :: driver\n    integer, intent(in) :: unit\n    type(string_t), intent(in) :: prefix\n    integer :: i, j\n    write (unit, \"(A)\")  \"\"\n    write (unit, \"(A)\")  \"! Return C pointer to a procedure:\"\n    write (unit, \"(A)\")  \"! pid = process index;  fid = function index\"\n    write (unit, \"(4A)\")  \"subroutine \", char (prefix), \"get_fptr \", &\n         \"(pid, fid, fptr) bind(C)\"\n    write (unit, \"(A)\")  \"  use iso_c_binding\"\n    write (unit, \"(A)\")  \"  use kinds\"\n    write (unit, \"(A)\")  \"  implicit none\"\n    write (unit, \"(A)\")  \"  integer(c_int), intent(in) :: pid\"\n    write (unit, \"(A)\")  \"  integer(c_int), intent(in) :: fid\"\n    write (unit, \"(A)\")  \"  type(c_funptr), intent(out) :: fptr\"\n    do i = 1, driver%n_processes\n       call driver%record(i)%write_interfaces (unit)\n    end do\n    write (unit, \"(A)\")  \"  select case (pid)\"\n    do i = 1, driver%n_processes\n       write (unit, \"(2x,A,I0,A)\")  \"case (\", i, \")\"\n       write (unit, \"(5x,A)\")  \"select case (fid)\"\n       associate (record => driver%record(i))\n         do j = 1, size (record%feature)\n            write (unit, \"(5x,A,I0,9A)\")  \"case (\", j, \");  \", &\n                 \"fptr = c_funloc (\", &\n                 char (record%get_c_procname (record%feature(j))), &\n                 \")\"\n         end do\n       end associate\n       write (unit, \"(5x,A)\")  \"end select\"\n    end do\n    write (unit, \"(A)\")  \"  end select\"\n    write (unit, \"(3A)\")  \"end subroutine \", char (prefix), \"get_fptr\"\n  end subroutine write_get_fptr_sub\n\n@ %def write_get_fptr_sub\n@ The procedures for which we want to return a pointer (the 'features'\nof the matrix element code) are actually Fortran module procedures.\nIf we want to have a C signature, we must write wrapper functions for\nall of them.  The procedures, their signatures, and the appropriate\nwriter routines are specific for the process type.\n\nTo keep this generic, we do not provide the writer routines here, but\njust the interface for a writer routine.  The actual routines are\nstored in the process record.\n\nThe [[prefix]] indicates the library, the [[id]] indicates the\nprocess, and [[procname]] is the bare name of the procedure to be\nwritten.\n<<Prclib interfaces: public>>=\n  public :: write_driver_code\n<<Prclib interfaces: interfaces>>=\n  abstract interface\n     subroutine write_driver_code (unit, prefix, id, procname)\n       import\n       integer, intent(in) :: unit\n       type(string_t), intent(in) :: prefix\n       type(string_t), intent(in) :: id\n       type(string_t), intent(in) :: procname\n     end subroutine write_driver_code\n  end interface\n\n@ %def write_driver_code\n@\n\\subsection{Hooks}\nInterface for additional library unload / reload hooks (currently unused!)\n<<Prclib interfaces: public>>=\n  public :: prclib_unload_hook\n  public :: prclib_reload_hook\n<<Prclib interfaces: interfaces>>=\n  abstract interface\n     subroutine prclib_unload_hook (libname)\n       import\n       type(string_t), intent(in) :: libname\n     end subroutine prclib_unload_hook\n\n     subroutine prclib_reload_hook (libname)\n       import\n       type(string_t), intent(in) :: libname\n     end subroutine prclib_reload_hook\n  end interface\n@ %def prclib_unload_hook\n@ %def prclib_reload_hook\n@\n\\subsection{Make source, compile, link}\nSince we should have written a Makefile, these tasks amount to simple\n[[make]] calls.  Note that the Makefile targets depend on each other,\nso calling [[link]] executes also the [[source]] and [[compile]]\nsteps, when necessary.\n\nOptionally, we can use a subdirectory.  We construct a prefix for the\nsubdirectory, and generate a shell [[cd]] call that moves us into the\nworkspace.\n\nThe [[prefix]] version is intended to be prepended to a filename, and can be\nempty.  The [[path]] version is intended to be prepended with a following\nslash, so the default is [[.]].\n<<Prclib interfaces: public>>=\n  public :: workspace_prefix\n  public :: workspace_path\n<<Prclib interfaces: procedures>>=\n  function workspace_prefix (workspace) result (prefix)\n    type(string_t), intent(in), optional :: workspace\n    type(string_t) :: prefix\n    if (present (workspace)) then\n       if (workspace /= \"\") then\n          prefix = workspace // \"/\"\n       else\n          prefix = \"\"\n       end if\n    else\n       prefix = \"\"\n    end if\n  end function workspace_prefix\n\n  function workspace_path (workspace) result (path)\n    type(string_t), intent(in), optional :: workspace\n    type(string_t) :: path\n    if (present (workspace)) then\n       if (workspace /= \"\") then\n          path = workspace\n       else\n          path = \".\"\n       end if\n    else\n       path = \".\"\n    end if\n  end function workspace_path\n\n  function workspace_cmd (workspace) result (cmd)\n    type(string_t), intent(in), optional :: workspace\n    type(string_t) :: cmd\n    if (present (workspace)) then\n       if (workspace /= \"\") then\n          cmd = \"cd \" // workspace // \" && \"\n       else\n          cmd = \"\"\n       end if\n    else\n       cmd = \"\"\n    end if\n  end function workspace_cmd\n  \n@ %def workspace_prefix\n@ %def workspace_path\n@ %def workspace_cmd\n@ The first routine writes source-code files for the individual\nprocesses.  First it calls the writer routines directly for each\nprocess, then it calls [[make source]].  The make command may either\npost-process the files, or it may do the complete work, e.g., calling\nan external program the generates the files.\n<<Prclib interfaces: prclib driver: TBP>>=\n  procedure :: make_source => prclib_driver_make_source\n<<Prclib interfaces: procedures>>=\n  subroutine prclib_driver_make_source (driver, os_data, workspace)\n    class(prclib_driver_t), intent(in) :: driver\n    type(os_data_t), intent(in) :: os_data\n    type(string_t), intent(in), optional :: workspace\n    integer :: i\n    do i = 1, driver%n_processes\n       call driver%record(i)%write_source_code ()\n    end do\n    call os_system_call ( &\n         workspace_cmd (workspace) &\n         // \"make source \" // os_data%makeflags &\n         // \" -f \" // driver%basename // \".makefile\")\n  end subroutine prclib_driver_make_source\n\n@ %def prclib_driver_make_source\n@ Compile matrix element source code and the driver source code.  As above, we\nfirst iterate through all processes and call [[before_compile]].  This is\nusually empty, but can execute code that depends on [[make_source]] already\ncompleted.  Similarly, [[after_compile]] scans all processes again.\n<<Prclib interfaces: prclib driver: TBP>>=\n  procedure :: make_compile => prclib_driver_make_compile\n<<Prclib interfaces: procedures>>=\n  subroutine prclib_driver_make_compile (driver, os_data, workspace)\n    class(prclib_driver_t), intent(in) :: driver\n    type(os_data_t), intent(in) :: os_data\n    type(string_t), intent(in), optional :: workspace\n    integer :: i\n    do i = 1, driver%n_processes\n       call driver%record(i)%before_compile ()\n    end do\n    call os_system_call ( &\n         workspace_cmd (workspace) &\n         // \"make compile \" // os_data%makeflags &\n         // \" -f \" // driver%basename // \".makefile\")\n    do i = 1, driver%n_processes\n       call driver%record(i)%after_compile ()\n    end do\n  end subroutine prclib_driver_make_compile\n\n@ %def prclib_driver_make_compile\n@ Combine all matrix-element code together with the driver in a\nprocess library on disk.\n<<Prclib interfaces: prclib driver: TBP>>=\n  procedure :: make_link => prclib_driver_make_link\n<<Prclib interfaces: procedures>>=\n  subroutine prclib_driver_make_link (driver, os_data, workspace)\n    class(prclib_driver_t), intent(in) :: driver\n    type(os_data_t), intent(in) :: os_data\n    type(string_t), intent(in), optional :: workspace\n    integer :: i\n    call os_system_call ( &\n         workspace_cmd (workspace) &\n         // \"make link \" // os_data%makeflags &\n         // \" -f \" // driver%basename // \".makefile\")\n  end subroutine prclib_driver_make_link\n\n@ %def prclib_driver_make_link\n@\n\\subsection{Clean up generated files}\nThe task of cleaning any generated files should also be deferred to\nMakefile targets.  Apart from removing everything, removing specific\nfiles may be useful for partial rebuilds.  (Note that removing the\nmakefile itself can only be done once, for obvious reasons.)\n\nIf there is no makefile, do nothing.\n<<Prclib interfaces: prclib driver: TBP>>=\n  procedure :: clean_library => prclib_driver_clean_library\n  procedure :: clean_objects => prclib_driver_clean_objects\n  procedure :: clean_source => prclib_driver_clean_source\n  procedure :: clean_driver => prclib_driver_clean_driver\n  procedure :: clean_makefile => prclib_driver_clean_makefile\n  procedure :: clean => prclib_driver_clean\n  procedure :: distclean => prclib_driver_distclean\n<<Prclib interfaces: procedures>>=\n  subroutine prclib_driver_clean_library (driver, os_data, workspace)\n    class(prclib_driver_t), intent(in) :: driver\n    type(os_data_t), intent(in) :: os_data\n    type(string_t), intent(in), optional :: workspace\n    if (driver%makefile_exists ()) then\n       call os_system_call ( &\n         workspace_cmd (workspace) &\n         // \"make clean-library \" // os_data%makeflags &\n            // \" -f \" // driver%basename // \".makefile\")\n    end if\n  end subroutine prclib_driver_clean_library\n\n  subroutine prclib_driver_clean_objects (driver, os_data, workspace)\n    class(prclib_driver_t), intent(in) :: driver\n    type(os_data_t), intent(in) :: os_data\n    type(string_t), intent(in), optional :: workspace\n    if (driver%makefile_exists ()) then\n       call os_system_call ( &\n         workspace_cmd (workspace) &\n         // \"make clean-objects \" // os_data%makeflags &\n            // \" -f \" // driver%basename // \".makefile\")\n    end if\n  end subroutine prclib_driver_clean_objects\n\n  subroutine prclib_driver_clean_source (driver, os_data, workspace)\n    class(prclib_driver_t), intent(in) :: driver\n    type(os_data_t), intent(in) :: os_data\n    type(string_t), intent(in), optional :: workspace\n    if (driver%makefile_exists ()) then\n       call os_system_call ( &\n         workspace_cmd (workspace) &\n         // \"make clean-source \" // os_data%makeflags &\n            // \" -f \" // driver%basename // \".makefile\")\n    end if\n  end subroutine prclib_driver_clean_source\n\n  subroutine prclib_driver_clean_driver (driver, os_data, workspace)\n    class(prclib_driver_t), intent(in) :: driver\n    type(os_data_t), intent(in) :: os_data\n    type(string_t), intent(in), optional :: workspace\n    if (driver%makefile_exists ()) then\n       call os_system_call ( &\n         workspace_cmd (workspace) &\n         // \"make clean-driver \" // os_data%makeflags &\n            // \" -f \" // driver%basename // \".makefile\")\n    end if\n  end subroutine prclib_driver_clean_driver\n\n  subroutine prclib_driver_clean_makefile (driver, os_data, workspace)\n    class(prclib_driver_t), intent(in) :: driver\n    type(os_data_t), intent(in) :: os_data\n    type(string_t), intent(in), optional :: workspace\n    if (driver%makefile_exists ()) then\n       call os_system_call ( &\n         workspace_cmd (workspace) &\n         // \"make clean-makefile \" // os_data%makeflags &\n            // \" -f \" // driver%basename // \".makefile\")\n    end if\n  end subroutine prclib_driver_clean_makefile\n\n  subroutine prclib_driver_clean (driver, os_data, workspace)\n    class(prclib_driver_t), intent(in) :: driver\n    type(os_data_t), intent(in) :: os_data\n    type(string_t), intent(in), optional :: workspace\n    if (driver%makefile_exists ()) then\n       call os_system_call ( &\n         workspace_cmd (workspace) &\n         // \"make clean \" // os_data%makeflags &\n            // \" -f \" // driver%basename // \".makefile\")\n    end if\n  end subroutine prclib_driver_clean\n\n  subroutine prclib_driver_distclean (driver, os_data, workspace)\n    class(prclib_driver_t), intent(in) :: driver\n    type(os_data_t), intent(in) :: os_data\n    type(string_t), intent(in), optional :: workspace\n    if (driver%makefile_exists ()) then\n       call os_system_call ( &\n         workspace_cmd (workspace) &\n         // \"make distclean \" // os_data%makeflags &\n            // \" -f \" // driver%basename // \".makefile\")\n    end if\n  end subroutine prclib_driver_distclean\n\n@ %def prclib_driver_clean_library\n@ %def prclib_driver_clean_objects\n@ %def prclib_driver_clean_source\n@ %def prclib_driver_clean_driver\n@ %def prclib_driver_clean_makefile\n@ %def prclib_driver_clean\n@ %def prclib_driver_distclean\n@ This Make target should remove all files that apply to a specific process.\nWe execute this when we want to force remaking source code.  Note that source\ntargets need not have prerequisites, so just calling [[make_source]] would not\ndo anything if the files exist.\n<<Prclib interfaces: prclib driver: TBP>>=\n  procedure :: clean_proc => prclib_driver_clean_proc\n<<Prclib interfaces: procedures>>=\n  subroutine prclib_driver_clean_proc (driver, i, os_data, workspace)\n    class(prclib_driver_t), intent(in) :: driver\n    integer, intent(in) :: i\n    type(os_data_t), intent(in) :: os_data\n    type(string_t), intent(in), optional :: workspace\n    type(string_t) :: id\n    if (driver%makefile_exists ()) then\n       id = driver%record(i)%id\n      call os_system_call ( &\n         workspace_cmd (workspace) &\n         // \"make clean-\" // driver%record(i)%id // \" \" &\n           // os_data%makeflags &\n           // \" -f \" // driver%basename // \".makefile\")\n    end if\n  end subroutine prclib_driver_clean_proc\n\n@ %def prclib_driver_clean_proc\n@\n\\subsection{Further Tools}\nCheck for the appropriate makefile.\n<<Prclib interfaces: prclib driver: TBP>>=\n  procedure :: makefile_exists => prclib_driver_makefile_exists\n<<Prclib interfaces: procedures>>=\n  function prclib_driver_makefile_exists (driver, workspace) result (flag)\n    class(prclib_driver_t), intent(in) :: driver\n    type(string_t), intent(in), optional :: workspace\n    logical :: flag\n    inquire (file = char (workspace_prefix (workspace) &\n         &                // driver%basename) // \".makefile\", &\n         exist = flag)\n  end function prclib_driver_makefile_exists\n\n@ %def prclib_driver_makefile_exists\n@\n\\subsection{Load the library}\nOnce the library has been linked, we can dlopen it and assign all\nprocedure pointers to their proper places in the library driver\nobject.  The [[loaded]] flag is set only if all required pointers\nhave become assigned.\n<<Prclib interfaces: prclib driver: TBP>>=\n  procedure :: load => prclib_driver_load\n<<Prclib interfaces: procedures>>=\n  subroutine prclib_driver_load (driver, os_data, noerror, workspace)\n    class(prclib_driver_t), intent(inout) :: driver\n    type(os_data_t), intent(in) :: os_data\n    logical, intent(in), optional :: noerror\n    type(string_t), intent(in), optional :: workspace\n    type(c_funptr) :: c_fptr\n    logical :: ignore\n\n    ignore = .false.;  if (present (noerror))  ignore = noerror\n\n    driver%libname = os_get_dlname ( &\n         workspace_prefix (workspace) // driver%basename, &\n         os_data, noerror, noerror)\n    if (driver%libname == \"\")  return\n    select type (driver)\n    type is (prclib_driver_dynamic_t)\n       if (.not. dlaccess_is_open (driver%dlaccess)) then\n          call dlaccess_init &\n               (driver%dlaccess, workspace_path (workspace), &\n                driver%libname, os_data)\n          if (.not. ignore)  call driver%check_dlerror ()\n       end if\n       driver%loaded = dlaccess_is_open (driver%dlaccess)\n    class default\n       driver%loaded = .true.\n    end select\n    if (.not. driver%loaded)  return\n\n    c_fptr = driver%get_c_funptr (var_str (\"get_n_processes\"))\n    call c_f_procpointer (c_fptr, driver%get_n_processes)\n    driver%loaded = driver%loaded .and. associated (driver%get_n_processes)\n\n    c_fptr = driver%get_c_funptr (var_str (\"get_process_id_ptr\"))\n    call c_f_procpointer (c_fptr, driver%get_process_id_ptr)\n    driver%loaded = driver%loaded .and. associated (driver%get_process_id_ptr)\n\n    c_fptr = driver%get_c_funptr (var_str (\"get_model_name_ptr\"))\n    call c_f_procpointer (c_fptr, driver%get_model_name_ptr)\n    driver%loaded = driver%loaded .and. associated (driver%get_model_name_ptr)\n\n    c_fptr = driver%get_c_funptr (var_str (\"get_md5sum_ptr\"))\n    call c_f_procpointer (c_fptr, driver%get_md5sum_ptr)\n    driver%loaded = driver%loaded .and. associated (driver%get_md5sum_ptr)\n\n    c_fptr = driver%get_c_funptr (var_str (\"get_openmp_status\"))\n    call c_f_procpointer (c_fptr, driver%get_openmp_status)\n    driver%loaded = driver%loaded .and. associated (driver%get_openmp_status)\n\n    c_fptr = driver%get_c_funptr (var_str (\"get_n_in\"))\n    call c_f_procpointer (c_fptr, driver%get_n_in)\n    driver%loaded = driver%loaded .and. associated (driver%get_n_in)\n\n    c_fptr = driver%get_c_funptr (var_str (\"get_n_out\"))\n    call c_f_procpointer (c_fptr, driver%get_n_out)\n    driver%loaded = driver%loaded .and. associated (driver%get_n_out)\n\n    c_fptr = driver%get_c_funptr (var_str (\"get_n_flv\"))\n    call c_f_procpointer (c_fptr, driver%get_n_flv)\n    driver%loaded = driver%loaded .and. associated (driver%get_n_flv)\n\n    c_fptr = driver%get_c_funptr (var_str (\"get_n_hel\"))\n    call c_f_procpointer (c_fptr, driver%get_n_hel)\n    driver%loaded = driver%loaded .and. associated (driver%get_n_hel)\n\n    c_fptr = driver%get_c_funptr (var_str (\"get_n_col\"))\n    call c_f_procpointer (c_fptr, driver%get_n_col)\n    driver%loaded = driver%loaded .and. associated (driver%get_n_col)\n\n    c_fptr = driver%get_c_funptr (var_str (\"get_n_cin\"))\n    call c_f_procpointer (c_fptr, driver%get_n_cin)\n    driver%loaded = driver%loaded .and. associated (driver%get_n_cin)\n\n    c_fptr = driver%get_c_funptr (var_str (\"get_n_cf\"))\n    call c_f_procpointer (c_fptr, driver%get_n_cf)\n    driver%loaded = driver%loaded .and. associated (driver%get_n_cf)\n\n    c_fptr = driver%get_c_funptr (var_str (\"set_flv_state_ptr\"))\n    call c_f_procpointer (c_fptr, driver%set_flv_state_ptr)\n    driver%loaded = driver%loaded .and. associated (driver%set_flv_state_ptr)\n\n    c_fptr = driver%get_c_funptr (var_str (\"set_hel_state_ptr\"))\n    call c_f_procpointer (c_fptr, driver%set_hel_state_ptr)\n    driver%loaded = driver%loaded .and. associated (driver%set_hel_state_ptr)\n\n    c_fptr = driver%get_c_funptr (var_str (\"set_col_state_ptr\"))\n    call c_f_procpointer (c_fptr, driver%set_col_state_ptr)\n    driver%loaded = driver%loaded .and. associated (driver%set_col_state_ptr)\n\n    c_fptr = driver%get_c_funptr (var_str (\"set_color_factors_ptr\"))\n    call c_f_procpointer (c_fptr, driver%set_color_factors_ptr)\n    driver%loaded = driver%loaded .and. associated (driver%set_color_factors_ptr)\n\n    c_fptr = driver%get_c_funptr (var_str (\"get_fptr\"))\n    call c_f_procpointer (c_fptr, driver%get_fptr)\n    driver%loaded = driver%loaded .and. associated (driver%get_fptr)\n\n  end subroutine prclib_driver_load\n\n@ %def prclib_driver_load\n@ Unload.  To be sure, nullify the procedure pointers.\n<<Prclib interfaces: prclib driver: TBP>>=\n  procedure :: unload => prclib_driver_unload\n<<Prclib interfaces: procedures>>=\n  subroutine prclib_driver_unload (driver)\n    class(prclib_driver_t), intent(inout) :: driver\n    select type (driver)\n    type is (prclib_driver_dynamic_t)\n       if (dlaccess_is_open (driver%dlaccess)) then\n          call dlaccess_final (driver%dlaccess)\n          call driver%check_dlerror ()\n       end if\n    end select\n    driver%loaded = .false.\n    nullify (driver%get_n_processes)\n    nullify (driver%get_process_id_ptr)\n    nullify (driver%get_model_name_ptr)\n    nullify (driver%get_md5sum_ptr)\n    nullify (driver%get_openmp_status)\n    nullify (driver%get_n_in)\n    nullify (driver%get_n_out)\n    nullify (driver%get_n_flv)\n    nullify (driver%get_n_hel)\n    nullify (driver%get_n_col)\n    nullify (driver%get_n_cin)\n    nullify (driver%get_n_cf)\n    nullify (driver%set_flv_state_ptr)\n    nullify (driver%set_hel_state_ptr)\n    nullify (driver%set_col_state_ptr)\n    nullify (driver%set_color_factors_ptr)\n    nullify (driver%get_fptr)\n  end subroutine prclib_driver_unload\n\n@ %def prclib_driver_unload\n@ This subroutine checks the [[dlerror]] content and issues a fatal\nerror if it finds an error there.\n<<Prclib interfaces: prclib driver dynamic: TBP>>=\n  procedure :: check_dlerror => prclib_driver_check_dlerror\n<<Prclib interfaces: procedures>>=\n  subroutine prclib_driver_check_dlerror (driver)\n    class(prclib_driver_dynamic_t), intent(in) :: driver\n    if (dlaccess_has_error (driver%dlaccess)) then\n       call msg_fatal (char (dlaccess_get_error (driver%dlaccess)))\n    end if\n  end subroutine prclib_driver_check_dlerror\n\n@ %def prclib_driver_check_dlerror\n@ Get the handle (C function pointer) for a given ``feature'' of the\nmatrix element code, so it can be assigned to the appropriate\nprocedure pointer slot.  In the static case, this is a\ntrivial pointer assignment, hard-coded into the driver type\nimplementation.\n<<Prclib interfaces: prclib driver: TBP>>=\n  procedure (prclib_driver_get_c_funptr), deferred :: get_c_funptr\n<<Prclib interfaces: interfaces>>=\n  abstract interface\n     function prclib_driver_get_c_funptr (driver, feature) result (c_fptr)\n       import\n       class(prclib_driver_t), intent(inout) :: driver\n       type(string_t), intent(in) :: feature\n       type(c_funptr) :: c_fptr\n     end function prclib_driver_get_c_funptr\n  end interface\n\n@ %def prclib_driver_get_c_funptr\n@ In the dynamic-library case, we call the DL interface to retrieve the C\npointer to a named procedure.\n<<Prclib interfaces: prclib driver dynamic: TBP>>=\n  procedure :: get_c_funptr => prclib_driver_dynamic_get_c_funptr\n<<Prclib interfaces: procedures>>=\n  function prclib_driver_dynamic_get_c_funptr (driver, feature) result (c_fptr)\n    class(prclib_driver_dynamic_t), intent(inout) :: driver\n    type(string_t), intent(in) :: feature\n    type(c_funptr) :: c_fptr\n    type(string_t) :: prefix, full_name\n    prefix = lower_case (driver%basename) // \"_\"\n    full_name = prefix // feature\n    c_fptr = dlaccess_get_c_funptr (driver%dlaccess, full_name)\n    call driver%check_dlerror ()\n  end function prclib_driver_dynamic_get_c_funptr\n\n@ %def prclib_driver_get_c_funptr\n@\n\\subsection{MD5 sums}\nRecall the MD5 sum written in the Makefile\n<<Prclib interfaces: prclib driver: TBP>>=\n  procedure :: get_md5sum_makefile => prclib_driver_get_md5sum_makefile\n<<Prclib interfaces: procedures>>=\n  function prclib_driver_get_md5sum_makefile (driver, workspace) result (md5sum)\n    class(prclib_driver_t), intent(in) :: driver\n    type(string_t), intent(in), optional :: workspace\n    character(32) :: md5sum\n    type(string_t) :: filename\n    character(80) :: buffer\n    logical :: exist\n    integer :: u, iostat\n    md5sum = \"\"\n    filename = workspace_prefix (workspace) // driver%basename // \".makefile\"\n    inquire (file = char (filename), exist = exist)\n    if (exist) then\n       u = free_unit ()\n       open (u, file = char (filename), action = \"read\", status = \"old\")\n       iostat = 0\n       do\n          read (u, \"(A)\", iostat = iostat)  buffer\n          if (iostat /= 0)  exit\n          buffer = adjustl (buffer)\n          select case (buffer(1:9))\n          case (\"MD5SUM = \")\n             read (buffer(11:), \"(A32)\")  md5sum\n             exit\n          end select\n       end do\n       close (u)\n    end if\n  end function prclib_driver_get_md5sum_makefile\n\n@ %def prclib_driver_get_md5sum_makefile\n@ Recall the MD5 sum written in the driver source code.\n<<Prclib interfaces: prclib driver: TBP>>=\n  procedure :: get_md5sum_driver => prclib_driver_get_md5sum_driver\n<<Prclib interfaces: procedures>>=\n  function prclib_driver_get_md5sum_driver (driver, workspace) result (md5sum)\n    class(prclib_driver_t), intent(in) :: driver\n    type(string_t), intent(in), optional :: workspace\n    character(32) :: md5sum\n    type(string_t) :: filename\n    character(80) :: buffer\n    logical :: exist\n    integer :: u, iostat\n    md5sum = \"\"\n    filename = workspace_prefix (workspace) // driver%basename // \".f90\"\n    inquire (file = char (filename), exist = exist)\n    if (exist) then\n       u = free_unit ()\n       open (u, file = char (filename), action = \"read\", status = \"old\")\n       iostat = 0\n       do\n          read (u, \"(A)\", iostat = iostat)  buffer\n          if (iostat /= 0)  exit\n          buffer = adjustl (buffer)\n          select case (buffer(1:9))\n          case (\"md5sum = \")\n             read (buffer(11:), \"(A32)\")  md5sum\n             exit\n          end select\n       end do\n       close (u)\n    end if\n  end function prclib_driver_get_md5sum_driver\n\n@ %def prclib_driver_get_md5sum_driver\n@ Recall the MD5 sum written in the matrix element source code.\n<<Prclib interfaces: prclib driver: TBP>>=\n  procedure :: get_md5sum_source => prclib_driver_get_md5sum_source\n<<Prclib interfaces: procedures>>=\n  function prclib_driver_get_md5sum_source &\n       (driver, i, workspace) result (md5sum)\n    class(prclib_driver_t), intent(in) :: driver\n    integer, intent(in) :: i\n    type(string_t), intent(in), optional :: workspace\n    character(32) :: md5sum\n    type(string_t) :: filename\n    character(80) :: buffer\n    logical :: exist\n    integer :: u, iostat\n    md5sum = \"\"\n\n    filename = workspace_prefix (workspace) // driver%record(i)%id // \".f90\"\n    inquire (file = char (filename), exist = exist)\n    if (exist) then\n       u = free_unit ()\n       open (u, file = char (filename), action = \"read\", status = \"old\")\n       iostat = 0\n       do\n          read (u, \"(A)\", iostat = iostat)  buffer\n          if (iostat /= 0)  exit\n          buffer = adjustl (buffer)\n          select case (buffer(1:9))\n          case (\"md5sum = \")\n             read (buffer(11:), \"(A32)\")  md5sum\n             exit\n          end select\n       end do\n       close (u)\n    end if\n  end function prclib_driver_get_md5sum_source\n\n@ %def prclib_driver_get_md5sum_source\n@\n\\subsection{Unit Test}\nTest module, followed by the corresponding implementation module.\n<<[[prclib_interfaces_ut.f90]]>>=\n<<File header>>\n\nmodule prclib_interfaces_ut\n  use kinds\n  use system_dependencies, only: CC_IS_GNU, CC_HAS_QUADMATH\n  use unit_tests\n  use prclib_interfaces_uti\n\n<<Standard module head>>\n\n<<Prclib interfaces: public test>>\n\n<<Prclib interfaces: public test auxiliary>>\n\ncontains\n\n<<Prclib interfaces: test driver>>\n\nend module prclib_interfaces_ut\n@ %def prclib_interfaces_ut\n@\n<<[[prclib_interfaces_uti.f90]]>>=\n<<File header>>\n\nmodule prclib_interfaces_uti\n\n  use, intrinsic :: iso_c_binding !NODEP!\n\n  use kinds\n  use system_dependencies, only: CC_HAS_QUADMATH, DEFAULT_FC_PRECISION\n<<Use strings>>\n  use io_units\n  use system_defs, only: TAB\n  use os_interface\n\n  use prclib_interfaces\n\n<<Standard module head>>\n\n<<Prclib interfaces: public test auxiliary>>\n\n<<Prclib interfaces: test declarations>>\n\n<<Prclib interfaces: test types>>\n\ncontains\n\n<<Prclib interfaces: tests>>\n\n<<Prclib interfaces: test auxiliary>>\n\nend module prclib_interfaces_uti\n@ %def prclib_interfaces_ut\n@ API: driver for the unit tests below.\n<<Prclib interfaces: public test>>=\n  public :: prclib_interfaces_test\n<<Prclib interfaces: test driver>>=\n  subroutine prclib_interfaces_test (u, results)\n    integer, intent(in) :: u\n    type(test_results_t), intent(inout) :: results\n  <<Prclib interfaces: execute tests>>\n  end subroutine prclib_interfaces_test\n\n@ %def prclib_interfaces_test\n@\n\\subsubsection{Empty process list}\nTest 1: Create a driver object and display its contents.  One of the\nfeature lists references a writer procedure; this is just a dummy that\ndoes nothing useful.\n<<Prclib interfaces: execute tests>>=\n  call test (prclib_interfaces_1, \"prclib_interfaces_1\", &\n       \"create driver object\", &\n       u, results)\n<<Prclib interfaces: test declarations>>=\n  public :: prclib_interfaces_1\n<<Prclib interfaces: tests>>=\n  subroutine prclib_interfaces_1 (u)\n    integer, intent(in) :: u\n    class(prclib_driver_t), allocatable :: driver\n    character(32), parameter :: md5sum = \"prclib_interfaces_1_md5sum      \"\n    class(prc_writer_t), pointer :: test_writer_1\n\n\n    write (u, \"(A)\")  \"* Test output: prclib_interfaces_1\"\n    write (u, \"(A)\")  \"*   Purpose: display the driver object contents\"\n    write (u, *)\n    write (u, \"(A)\")  \"* Create a prclib driver object\"\n    write (u, \"(A)\")\n\n    call dispatch_prclib_driver (driver, var_str (\"prclib\"), var_str (\"\"))\n    call driver%init (3)\n    call driver%set_md5sum (md5sum)\n\n    allocate (test_writer_1_t :: test_writer_1)\n\n    call driver%set_record (1, var_str (\"test1\"), var_str (\"test_model\"), &\n         [var_str (\"init\")], test_writer_1)\n\n    call driver%set_record (2, var_str (\"test2\"), var_str (\"foo_model\"), &\n         [var_str (\"another_proc\")], test_writer_1)\n\n    call driver%set_record (3, var_str (\"test3\"), var_str (\"test_model\"), &\n         [var_str (\"init\"), var_str (\"some_proc\")], test_writer_1)\n\n    call driver%write (u)\n\n    deallocate (test_writer_1)\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Test output end: prclib_interfaces_1\"\n  end subroutine prclib_interfaces_1\n\n@ %def prclib_interfaces_1\n@ The writer: the procedures write just comment lines.  We can fix an\ninstance of this as a parameter (since it has no mutable content) and\njust reference the fixed parameter.\n\nNOTE: temporarily made public.\n<<Prclib interfaces: test types>>=\n  type, extends (prc_writer_t) :: test_writer_1_t\n   contains\n     procedure, nopass :: type_name => test_writer_1_type_name\n     procedure :: write_makefile_code => test_writer_1_mk\n     procedure :: write_source_code => test_writer_1_src\n     procedure :: write_interface => test_writer_1_if\n     procedure :: write_md5sum_call => test_writer_1_md5sum\n     procedure :: write_int_sub_call => test_writer_1_int_sub\n     procedure :: write_col_state_call => test_writer_1_col_state\n     procedure :: write_color_factors_call => test_writer_1_col_factors\n     procedure :: before_compile => test_writer_1_before_compile\n     procedure :: after_compile => test_writer_1_after_compile\n  end type test_writer_1_t\n\n@ %def test_writer_1\n@\n<<Prclib interfaces: test auxiliary>>=\n  function test_writer_1_type_name () result (string)\n    type(string_t) :: string\n    string = \"test_1\"\n  end function test_writer_1_type_name\n\n  subroutine test_writer_1_mk &\n       (writer, unit, id, os_data, verbose, testflag)\n    class(test_writer_1_t), intent(in) :: writer\n    integer, intent(in) :: unit\n    type(string_t), intent(in) :: id\n    type(os_data_t), intent(in) :: os_data\n    logical, intent(in) :: verbose\n    logical, intent(in), optional :: testflag\n    write (unit, \"(5A)\")  \"# Makefile code for process \", char (id), &\n         \" goes here.\"\n  end subroutine test_writer_1_mk\n\n  subroutine test_writer_1_src (writer, id)\n    class(test_writer_1_t), intent(in) :: writer\n    type(string_t), intent(in) :: id\n  end subroutine test_writer_1_src\n\n  subroutine test_writer_1_if (writer, unit, id, feature)\n    class(test_writer_1_t), intent(in) :: writer\n    integer, intent(in) :: unit\n    type(string_t), intent(in) :: id, feature\n    write (unit, \"(2x,9A)\")  \"! Interface code for \", &\n       char (id), \"_\", char (writer%get_procname (feature)), &\n       \" goes here.\"\n  end subroutine test_writer_1_if\n\n  subroutine test_writer_1_md5sum (writer, unit, id)\n    class(test_writer_1_t), intent(in) :: writer\n    integer, intent(in) :: unit\n    type(string_t), intent(in) :: id\n    write (unit, \"(5x,9A)\")  \"! MD5sum call for \", char (id), \" goes here.\"\n  end subroutine test_writer_1_md5sum\n\n  subroutine test_writer_1_int_sub (writer, unit, id, feature)\n    class(test_writer_1_t), intent(in) :: writer\n    integer, intent(in) :: unit\n    type(string_t), intent(in) :: id, feature\n    write (unit, \"(5x,9A)\")  \"! \", char (feature), \" call for \", &\n         char (id), \" goes here.\"\n  end subroutine test_writer_1_int_sub\n\n  subroutine test_writer_1_col_state (writer, unit, id)\n    class(test_writer_1_t), intent(in) :: writer\n    integer, intent(in) :: unit\n    type(string_t), intent(in) :: id\n    write (unit, \"(5x,9A)\")  \"! col_state call for \", &\n         char (id), \" goes here.\"\n  end subroutine test_writer_1_col_state\n\n  subroutine test_writer_1_col_factors (writer, unit, id)\n    class(test_writer_1_t), intent(in) :: writer\n    integer, intent(in) :: unit\n    type(string_t), intent(in) :: id\n    write (unit, \"(5x,9A)\")  \"! color_factors call for \", &\n         char (id), \" goes here.\"\n  end subroutine test_writer_1_col_factors\n\n  subroutine test_writer_1_before_compile (writer, id)\n    class(test_writer_1_t), intent(in) :: writer\n    type(string_t), intent(in) :: id\n  end subroutine test_writer_1_before_compile\n  \n  subroutine test_writer_1_after_compile (writer, id)\n    class(test_writer_1_t), intent(in) :: writer\n    type(string_t), intent(in) :: id\n  end subroutine test_writer_1_after_compile\n  \n@ %def test_writer_1_type_name\n@ %def test_writer_1_mk test_writer_1_if\n@ %def test_writer_1_md5sum test_writer_1_int_sub\n@ %def test_writer_1_col_state test_writer_1_col_factors\n@ %def test_writer_1_before_compile test_writer_1_after_compile\n@\n\\subsubsection{Process library driver file}\nTest 2: Write the driver file for a test case with two processes.  The\nfirst process needs no wrapper (C library), the second one needs\nwrappers (Fortran module library).\n<<Prclib interfaces: execute tests>>=\n  call test (prclib_interfaces_2, \"prclib_interfaces_2\", &\n       \"write driver file\", &\n       u, results)\n<<Prclib interfaces: test declarations>>=\n  public :: prclib_interfaces_2\n<<Prclib interfaces: tests>>=\n  subroutine prclib_interfaces_2 (u)\n    integer, intent(in) :: u\n    class(prclib_driver_t), allocatable :: driver\n    character(32), parameter :: md5sum = \"prclib_interfaces_2_md5sum      \"\n    class(prc_writer_t), pointer :: test_writer_1, test_writer_2\n\n    write (u, \"(A)\")  \"* Test output: prclib_interfaces_2\"\n    write (u, \"(A)\")  \"*   Purpose: check the generated driver source code\"\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Create a prclib driver object (2 processes)\"\n    write (u, \"(A)\")\n\n    call dispatch_prclib_driver (driver, var_str (\"prclib2\"), var_str (\"\"))\n    call driver%init (2)\n    call driver%set_md5sum (md5sum)\n\n    allocate (test_writer_1_t :: test_writer_1)\n    allocate (test_writer_2_t :: test_writer_2)\n\n    call driver%set_record (1, var_str (\"test1\"), var_str (\"Test_model\"), &\n         [var_str (\"proc1\")], test_writer_1)\n\n    call driver%set_record (2, var_str (\"test2\"), var_str (\"Test_model\"), &\n         [var_str (\"proc1\"), var_str (\"proc2\")], test_writer_2)\n\n    call driver%write (u)\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Write the driver file\"\n    write (u, \"(A)\")  \"* File contents:\"\n    write (u, \"(A)\")\n\n    call driver%generate_driver_code (u)\n\n    deallocate (test_writer_1)\n    deallocate (test_writer_2)\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Test output end: prclib_interfaces_2\"\n  end subroutine prclib_interfaces_2\n\n@ %def prclib_interfaces_2\n@ A writer with wrapper code: the procedures again write just comment\nlines.  Since all procedures are NOPASS, we can reuse two of the TBP.\n<<Prclib interfaces: test types>>=\n  type, extends (prc_writer_f_module_t) :: test_writer_2_t\n   contains\n     procedure, nopass :: type_name => test_writer_2_type_name\n     procedure :: write_makefile_code => test_writer_2_mk\n     procedure :: write_source_code => test_writer_2_src\n     procedure :: write_interface => test_writer_2_if\n     procedure :: write_wrapper => test_writer_2_wr\n     procedure :: before_compile => test_writer_2_before_compile\n     procedure :: after_compile => test_writer_2_after_compile\n  end type test_writer_2_t\n\n@ %def test_writer_2\n@\n<<Prclib interfaces: test auxiliary>>=\n  function test_writer_2_type_name () result (string)\n    type(string_t) :: string\n    string = \"test_2\"\n  end function test_writer_2_type_name\n\n  subroutine test_writer_2_mk &\n       (writer, unit, id, os_data, verbose, testflag)\n    class(test_writer_2_t), intent(in) :: writer\n    integer, intent(in) :: unit\n    type(string_t), intent(in) :: id\n    type(os_data_t), intent(in) :: os_data\n    logical, intent(in) :: verbose\n    logical, intent(in), optional :: testflag\n    write (unit, \"(5A)\")  \"# Makefile code for process \", char (id), &\n         \" goes here.\"\n  end subroutine test_writer_2_mk\n\n  subroutine test_writer_2_src (writer, id)\n    class(test_writer_2_t), intent(in) :: writer\n    type(string_t), intent(in) :: id\n  end subroutine test_writer_2_src\n\n  subroutine test_writer_2_if (writer, unit, id, feature)\n    class(test_writer_2_t), intent(in) :: writer\n    integer, intent(in) :: unit\n    type(string_t), intent(in) :: id, feature\n    write (unit, \"(2x,9A)\")  \"! Interface code for \", &\n       char (writer%get_module_name (id)), \"_\", &\n       char (writer%get_procname (feature)), \" goes here.\"\n  end subroutine test_writer_2_if\n\n  subroutine test_writer_2_wr (writer, unit, id, feature)\n    class(test_writer_2_t), intent(in) :: writer\n    integer, intent(in) :: unit\n    type(string_t), intent(in) :: id, feature\n    write (unit, *)\n    write (unit, \"(9A)\")  \"! Wrapper code for \", &\n       char (writer%get_c_procname (id, feature)), \" goes here.\"\n  end subroutine test_writer_2_wr\n\n  subroutine test_writer_2_before_compile (writer, id)\n    class(test_writer_2_t), intent(in) :: writer\n    type(string_t), intent(in) :: id\n  end subroutine test_writer_2_before_compile\n  \n  subroutine test_writer_2_after_compile (writer, id)\n    class(test_writer_2_t), intent(in) :: writer\n    type(string_t), intent(in) :: id\n  end subroutine test_writer_2_after_compile\n  \n@ %def test_writer_2_type_name test_writer_2_wr\n@ %def test_writer_2_before_compile test_writer_2_after_compile\n@\n\\subsubsection{Process library makefile}\nTest 3: Write the makefile for compiling and linking the process\nlibrary (processes and driver code).  There are two processes, one\nwith one method, one with two methods.\n\nTo have predictable output, we reset the system-dependent initial\ncomponents of [[os_data]] to known values.\n<<Prclib interfaces: execute tests>>=\n  call test (prclib_interfaces_3, \"prclib_interfaces_3\", &\n       \"write makefile\", &\n       u, results)\n<<Prclib interfaces: test declarations>>=\n  public :: prclib_interfaces_3\n<<Prclib interfaces: tests>>=\n  subroutine prclib_interfaces_3 (u)\n    integer, intent(in) :: u\n    class(prclib_driver_t), allocatable :: driver\n    type(os_data_t) :: os_data\n    character(32), parameter :: md5sum = \"prclib_interfaces_3_md5sum      \"\n    class(prc_writer_t), pointer :: test_writer_1, test_writer_2\n\n    call os_data%init ()\n    os_data%fc = \"fortran-compiler\"\n    os_data%whizard_includes = \"-I module-dir\"\n    os_data%fcflags = \"-C=all\"\n    os_data%fcflags_pic = \"-PIC\"\n    os_data%cc = \"c-compiler\"\n    os_data%cflags = \"-I include-dir\"\n    os_data%cflags_pic = \"-PIC\"\n    os_data%whizard_ldflags = \"\"\n    os_data%ldflags = \"\"\n    os_data%whizard_libtool = \"my-libtool\"\n    os_data%latex = \"latex -halt-on-error\"\n    os_data%mpost = \"mpost --math=scaled -halt-on-error\"\n    os_data%dvips = \"dvips\"\n    os_data%ps2pdf = \"ps2pdf14\"\n    os_data%whizard_texpath = \"\"\n\n    write (u, \"(A)\")  \"* Test output: prclib_interfaces_3\"\n    write (u, \"(A)\")  \"*   Purpose: check the generated Makefile\"\n    write (u, *)\n    write (u, \"(A)\")  \"* Create a prclib driver object (2 processes)\"\n    write (u, \"(A)\")\n\n    call dispatch_prclib_driver (driver, var_str (\"prclib3\"), var_str (\"\"))\n    call driver%init (2)\n    call driver%set_md5sum (md5sum)\n\n    allocate (test_writer_1_t :: test_writer_1)\n    allocate (test_writer_2_t :: test_writer_2)\n\n    call driver%set_record (1, var_str (\"test1\"), var_str (\"Test_model\"), &\n         [var_str (\"proc1\")], test_writer_1)\n\n    call driver%set_record (2, var_str (\"test2\"), var_str (\"Test_model\"), &\n         [var_str (\"proc1\"), var_str (\"proc2\")], test_writer_2)\n\n    call driver%write (u)\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Write Makefile\"\n    write (u, \"(A)\")  \"* File contents:\"\n    write (u, \"(A)\")\n\n    call driver%generate_makefile (u, os_data, verbose = .true.)\n\n    deallocate (test_writer_1)\n    deallocate (test_writer_2)\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Test output end: prclib_interfaces_3\"\n  end subroutine prclib_interfaces_3\n\n@ %def prclib_interfaces_3\n@\n\\subsubsection{Compile test with Fortran module}\nTest 4: Write driver and makefile and try to compile and link the\nlibrary driver.\n\nThere is a single test process with a single feature.  The process\ncode is provided as a Fortran module, therefore we need a wrapper for\nthe featured procedure.\n<<Prclib interfaces: execute tests>>=\n  call test (prclib_interfaces_4, \"prclib_interfaces_4\", &\n       \"compile and link (Fortran module)\", &\n       u, results)\n<<Prclib interfaces: test declarations>>=\n  public :: prclib_interfaces_4\n<<Prclib interfaces: tests>>=\n  subroutine prclib_interfaces_4 (u)\n    integer, intent(in) :: u\n    class(prclib_driver_t), allocatable :: driver\n    class(prc_writer_t), pointer :: test_writer_4\n    type(os_data_t) :: os_data\n    integer :: u_file\n\n    integer, dimension(:,:), allocatable :: flv_state\n    integer, dimension(:,:), allocatable :: hel_state\n    integer, dimension(:,:,:), allocatable :: col_state\n    logical, dimension(:,:), allocatable :: ghost_flag\n    integer, dimension(:,:), allocatable :: cf_index\n    complex(default), dimension(:), allocatable :: color_factors\n    character(32), parameter :: md5sum = \"prclib_interfaces_4_md5sum      \"\n    character(32) :: md5sum_file\n\n    type(c_funptr) :: proc1_ptr\n    interface\n       subroutine proc1_t (n) bind(C)\n         import\n         integer(c_int), intent(out) :: n\n       end subroutine proc1_t\n    end interface\n    procedure(proc1_t), pointer :: proc1\n    integer(c_int) :: n\n\n    write (u, \"(A)\")  \"* Test output: prclib_interfaces_4\"\n    write (u, \"(A)\")  \"*   Purpose: compile, link, and load process library\"\n    write (u, \"(A)\")  \"*            with (fake) matrix-element code &\n         &as a Fortran module\"\n    write (u, *)\n    write (u, \"(A)\")  \"* Create a prclib driver object (1 process)\"\n    write (u, \"(A)\")\n\n    call os_data%init ()\n\n    allocate (test_writer_4_t :: test_writer_4)\n    call test_writer_4%init_test ()\n\n    call dispatch_prclib_driver (driver, var_str (\"prclib4\"), var_str (\"\"))\n    call driver%init (1)\n    call driver%set_md5sum (md5sum)\n\n    call driver%set_record (1, var_str (\"test4\"), var_str (\"Test_model\"), &\n         [var_str (\"proc1\")], test_writer_4)\n\n    call driver%write (u)\n\n    write (u, *)\n    write (u, \"(A)\")  \"* Write Makefile\"\n    u_file = free_unit ()\n    open (u_file, file=\"prclib4.makefile\", status=\"replace\", action=\"write\")\n    call driver%generate_makefile (u_file, os_data, verbose = .false.)\n    close (u_file)\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Recall MD5 sum from Makefile\"\n    write (u, \"(A)\")\n\n    md5sum_file = driver%get_md5sum_makefile ()\n    write (u, \"(1x,A,A,A)\")  \"MD5 sum = '\", md5sum_file, \"'\"\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Write driver source code\"\n\n    u_file = free_unit ()\n    open (u_file, file=\"prclib4.f90\", status=\"replace\", action=\"write\")\n    call driver%generate_driver_code (u_file)\n    close (u_file)\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Recall MD5 sum from driver source\"\n    write (u, \"(A)\")\n\n    md5sum_file = driver%get_md5sum_driver ()\n    write (u, \"(1x,A,A,A)\")  \"MD5 sum = '\", md5sum_file, \"'\"\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Write matrix-element source code\"\n    call driver%make_source (os_data)\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Recall MD5 sum from matrix-element source\"\n    write (u, \"(A)\")\n\n    md5sum_file = driver%get_md5sum_source (1)\n    write (u, \"(1x,A,A,A)\")  \"MD5 sum = '\", md5sum_file, \"'\"\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Compile source code\"\n    call driver%make_compile (os_data)\n\n    write (u, \"(A)\")  \"* Link library\"\n    call driver%make_link (os_data)\n\n    write (u, \"(A)\")  \"* Load library\"\n    call driver%load (os_data)\n\n    write (u, *)\n    call driver%write (u)\n    write (u, *)\n\n    if (driver%loaded) then\n       write (u, \"(A)\")  \"* Call library functions:\"\n       write (u, *)\n       write (u, \"(1x,A,I0)\")  \"n_processes   = \", driver%get_n_processes ()\n       write (u, \"(1x,A,A,A)\")  \"process_id    = '\", &\n            char (driver%get_process_id (1)), \"'\"\n       write (u, \"(1x,A,A,A)\")  \"model_name    = '\", &\n            char (driver%get_model_name (1)), \"'\"\n       write (u, \"(1x,A,A,A)\")  \"md5sum (lib)  = '\", &\n            char (driver%get_md5sum (0)), \"'\"\n       write (u, \"(1x,A,A,A)\")  \"md5sum (proc) = '\", &\n            char (driver%get_md5sum (1)), \"'\"\n       write (u, \"(1x,A,L1)\")  \"openmp_status = \", driver%get_openmp_status (1)\n       write (u, \"(1x,A,I0)\")  \"n_in  = \", driver%get_n_in (1)\n       write (u, \"(1x,A,I0)\")  \"n_out = \", driver%get_n_out (1)\n       write (u, \"(1x,A,I0)\")  \"n_flv = \", driver%get_n_flv (1)\n       write (u, \"(1x,A,I0)\")  \"n_hel = \", driver%get_n_hel (1)\n       write (u, \"(1x,A,I0)\")  \"n_col = \", driver%get_n_col (1)\n       write (u, \"(1x,A,I0)\")  \"n_cin = \", driver%get_n_cin (1)\n       write (u, \"(1x,A,I0)\")  \"n_cf  = \", driver%get_n_cf (1)\n\n       call driver%set_flv_state (1, flv_state)\n       write (u, \"(1x,A,10(1x,I0))\")  \"flv_state =\", flv_state\n\n       call driver%set_hel_state (1, hel_state)\n       write (u, \"(1x,A,10(1x,I0))\")  \"hel_state =\", hel_state\n\n       call driver%set_col_state (1, col_state, ghost_flag)\n       write (u, \"(1x,A,10(1x,I0))\")  \"col_state =\", col_state\n       write (u, \"(1x,A,10(1x,L1))\")  \"ghost_flag =\", ghost_flag\n\n       call driver%set_color_factors (1, color_factors, cf_index)\n       write (u, \"(1x,A,10(1x,F5.3))\")  \"color_factors =\", color_factors\n       write (u, \"(1x,A,10(1x,I0))\")  \"cf_index =\", cf_index\n\n       call driver%get_fptr (1, 1, proc1_ptr)\n       call c_f_procpointer (proc1_ptr, proc1)\n       if (associated (proc1)) then\n          write (u, *)\n          call proc1 (n)\n          write (u, \"(1x,A,I0)\")  \"proc1(1) = \", n\n       end if\n\n    end if\n\n    deallocate (test_writer_4)\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Test output end: prclib_interfaces_4\"\n  end subroutine prclib_interfaces_4\n\n@ %def prclib_interfaces_4\n@ This version of test-code writer actually writes an interface and\nwrapper code.  The wrapped function is a no-parameter function with integer\nresult.\n\nThe stored MD5 sum may be modified.\n\nWe will reuse this later, therefore public.\n<<Prclib interfaces: public test auxiliary>>=\n  public :: test_writer_4_t\n<<Prclib interfaces: test types>>=\n  type, extends (prc_writer_f_module_t) :: test_writer_4_t\n   contains\n     procedure, nopass :: type_name => test_writer_4_type_name\n     procedure, nopass :: get_module_name => &\n          test_writer_4_get_module_name\n     procedure :: write_makefile_code => test_writer_4_mk\n     procedure :: write_source_code => test_writer_4_src\n     procedure :: write_interface => test_writer_4_if\n     procedure :: write_wrapper => test_writer_4_wr\n     procedure :: before_compile => test_writer_4_before_compile\n     procedure :: after_compile => test_writer_4_after_compile\n  end type test_writer_4_t\n\n@ %def test_writer_4\n@\n<<Prclib interfaces: test auxiliary>>=\n  function test_writer_4_type_name () result (string)\n    type(string_t) :: string\n    string = \"test_4\"\n  end function test_writer_4_type_name\n\n  function test_writer_4_get_module_name (id) result (name)\n    type(string_t), intent(in) :: id\n    type(string_t) :: name\n    name = \"tpr_\" // id\n  end function test_writer_4_get_module_name\n\n  subroutine test_writer_4_mk &\n       (writer, unit, id, os_data, verbose, testflag)\n    class(test_writer_4_t), intent(in) :: writer\n    integer, intent(in) :: unit\n    type(string_t), intent(in) :: id\n    type(os_data_t), intent(in) :: os_data\n    logical, intent(in) :: verbose\n    logical, intent(in), optional :: testflag\n    write (unit, \"(5A)\")  \"SOURCES += \", char (id), \".f90\"\n    write (unit, \"(5A)\")  \"OBJECTS += \", char (id), \".lo\"\n    write (unit, \"(5A)\")  \"CLEAN_SOURCES += \", char (id), \".f90\"\n    write (unit, \"(5A)\")  \"CLEAN_OBJECTS += tpr_\", char (id), \".mod\"\n    write (unit, \"(5A)\")  \"CLEAN_OBJECTS += \", char (id), \".lo\"\n    write (unit, \"(5A)\")  char (id), \".lo: \", char (id), \".f90\"\n    if (.not. verbose) then\n       write (unit, \"(5A)\")  TAB // '@echo  \"  FC       \" $@'\n    end if\n    write (unit, \"(5A)\")  TAB, \"$(LTFCOMPILE) $<\"\n  end subroutine test_writer_4_mk\n\n  subroutine test_writer_4_src (writer, id)\n    class(test_writer_4_t), intent(in) :: writer\n    type(string_t), intent(in) :: id\n    call write_test_module_file (id, var_str (\"proc1\"), writer%md5sum)\n  end subroutine test_writer_4_src\n\n  subroutine test_writer_4_if (writer, unit, id, feature)\n    class(test_writer_4_t), intent(in) :: writer\n    integer, intent(in) :: unit\n    type(string_t), intent(in) :: id, feature\n    write (unit, \"(2x,9A)\")  \"interface\"\n    write (unit, \"(5x,9A)\")  \"subroutine \", &\n       char (writer%get_c_procname (id, feature)), &\n       \" (n) bind(C)\"\n    write (unit, \"(7x,9A)\")  \"import\"\n    write (unit, \"(7x,9A)\")  \"implicit none\"\n    write (unit, \"(7x,9A)\")  \"integer(c_int), intent(out) :: n\"\n    write (unit, \"(5x,9A)\")  \"end subroutine \", &\n       char (writer%get_c_procname (id, feature))\n    write (unit, \"(2x,9A)\")  \"end interface\"\n  end subroutine test_writer_4_if\n\n  subroutine test_writer_4_wr (writer, unit, id, feature)\n    class(test_writer_4_t), intent(in) :: writer\n    integer, intent(in) :: unit\n    type(string_t), intent(in) :: id, feature\n    write (unit, *)\n    write (unit, \"(9A)\")  \"subroutine \", &\n         char (writer%get_c_procname (id, feature)), &\n       \" (n) bind(C)\"\n    write (unit, \"(2x,9A)\")  \"use iso_c_binding\"\n    write (unit, \"(2x,9A)\")  \"use tpr_\", char (id), \", only: \", &\n         char (writer%get_procname (feature))\n    write (unit, \"(2x,9A)\")  \"implicit none\"\n    write (unit, \"(2x,9A)\")  \"integer(c_int), intent(out) :: n\"\n    write (unit, \"(2x,9A)\")  \"call \", char (feature), \" (n)\"\n    write (unit, \"(9A)\")  \"end subroutine \", &\n       char (writer%get_c_procname (id, feature))\n  end subroutine test_writer_4_wr\n\n  subroutine test_writer_4_before_compile (writer, id)\n    class(test_writer_4_t), intent(in) :: writer\n    type(string_t), intent(in) :: id\n  end subroutine test_writer_4_before_compile\n  \n  subroutine test_writer_4_after_compile (writer, id)\n    class(test_writer_4_t), intent(in) :: writer\n    type(string_t), intent(in) :: id\n  end subroutine test_writer_4_after_compile\n  \n@ %def test_writer_2_type_name test_writer_4_wr\n@ %def test_writer_4_before_compile test_writer_4_after_compile\n@\nWe need a test module file (actually, one for each process in the test\nabove) that allows us to check compilation and linking.  The test\nmodule implements a colorless $1\\to 2$ process, and it implements one\nadditional function (feature), the name given as an argument.\n<<Prclib interfaces: test auxiliary>>=\n  subroutine write_test_module_file (basename, feature, md5sum)\n    type(string_t), intent(in) :: basename\n    type(string_t), intent(in) :: feature\n    character(32), intent(in) :: md5sum\n    integer :: u\n    u = free_unit ()\n    open (u, file = char (basename) // \".f90\", &\n         status = \"replace\", action = \"write\")\n    write (u, \"(A)\")  \"! (Pseudo) matrix element code file &\n         &for WHIZARD self-test\"\n    write (u, *)\n    write (u, \"(A)\")  \"module tpr_\" // char (basename)\n    write (u, *)\n    write (u, \"(2x,A)\")  \"use kinds\"\n    write (u, \"(2x,A)\")  \"use omega_color, OCF => omega_color_factor\"\n    write (u, *)\n    write (u, \"(2x,A)\")  \"implicit none\"\n    write (u, \"(2x,A)\")  \"private\"\n    write (u, *)\n    call write_test_me_code_1 (u)\n    write (u, *)\n    write (u, \"(2x,A)\")  \"public :: \" // char (feature)\n    write (u, *)\n    write (u, \"(A)\")  \"contains\"\n    write (u, *)\n    call write_test_me_code_2 (u, md5sum)\n    write (u, *)\n    write (u, \"(2x,A)\")  \"subroutine \" // char (feature) // \" (n)\"\n    write (u, \"(2x,A)\")  \"  integer, intent(out) :: n\"\n    write (u, \"(2x,A)\")  \"  n = 42\"\n    write (u, \"(2x,A)\")  \"end subroutine \" // char (feature)\n    write (u, *)\n    write (u, \"(A)\")  \"end module tpr_\" // char (basename)\n    close (u)\n  end subroutine write_test_module_file\n\n@ %def write_test_module_file\n@\nThe following two subroutines provide building blocks for a\nmatrix-element source code file, useful only for testing the\nworkflow.  The first routine writes the header part, the other routine\nthe implementation of the procedures listed in the header.\n<<Prclib interfaces: test auxiliary>>=\n  subroutine write_test_me_code_1 (u)\n    integer, intent(in) :: u\n    write (u, \"(2x,A)\")  \"public :: md5sum\"\n    write (u, \"(2x,A)\")  \"public :: openmp_supported\"\n    write (u, *)\n    write (u, \"(2x,A)\")  \"public :: n_in\"\n    write (u, \"(2x,A)\")  \"public :: n_out\"\n    write (u, \"(2x,A)\")  \"public :: n_flv\"\n    write (u, \"(2x,A)\")  \"public :: n_hel\"\n    write (u, \"(2x,A)\")  \"public :: n_cin\"\n    write (u, \"(2x,A)\")  \"public :: n_col\"\n    write (u, \"(2x,A)\")  \"public :: n_cf\"\n    write (u, *)\n    write (u, \"(2x,A)\")  \"public :: flv_state\"\n    write (u, \"(2x,A)\")  \"public :: hel_state\"\n    write (u, \"(2x,A)\")  \"public :: col_state\"\n    write (u, \"(2x,A)\")  \"public :: color_factors\"\n  end subroutine write_test_me_code_1\n\n  subroutine write_test_me_code_2 (u, md5sum)\n    integer, intent(in) :: u\n    character(32), intent(in) :: md5sum\n    write (u, \"(2x,A)\")  \"pure function md5sum ()\"\n    write (u, \"(2x,A)\")  \"  character(len=32) :: md5sum\"\n    write (u, \"(2x,A)\")  \"  md5sum = '\" // md5sum // \"'\"\n    write (u, \"(2x,A)\")  \"end function md5sum\"\n    write (u, *)\n    write (u, \"(2x,A)\")  \"pure function openmp_supported () result (status)\"\n    write (u, \"(2x,A)\")  \"  logical :: status\"\n    write (u, \"(2x,A)\")  \"  status = .false.\"\n    write (u, \"(2x,A)\")  \"end function openmp_supported\"\n    write (u, *)\n    write (u, \"(2x,A)\")  \"pure function n_in () result (n)\"\n    write (u, \"(2x,A)\")  \"  integer :: n\"\n    write (u, \"(2x,A)\")  \"  n = 1\"\n    write (u, \"(2x,A)\")  \"end function n_in\"\n    write (u, *)\n    write (u, \"(2x,A)\")  \"pure function n_out () result (n)\"\n    write (u, \"(2x,A)\")  \"  integer :: n\"\n    write (u, \"(2x,A)\")  \"  n = 2\"\n    write (u, \"(2x,A)\")  \"end function n_out\"\n    write (u, *)\n    write (u, \"(2x,A)\")  \"pure function n_flv () result (n)\"\n    write (u, \"(2x,A)\")  \"  integer :: n\"\n    write (u, \"(2x,A)\")  \"  n = 1\"\n    write (u, \"(2x,A)\")  \"end function n_flv\"\n    write (u, *)\n    write (u, \"(2x,A)\")  \"pure function n_hel () result (n)\"\n    write (u, \"(2x,A)\")  \"  integer :: n\"\n    write (u, \"(2x,A)\")  \"  n = 1\"\n    write (u, \"(2x,A)\")  \"end function n_hel\"\n    write (u, *)\n    write (u, \"(2x,A)\")  \"pure function n_cin () result (n)\"\n    write (u, \"(2x,A)\")  \"  integer :: n\"\n    write (u, \"(2x,A)\")  \"  n = 2\"\n    write (u, \"(2x,A)\")  \"end function n_cin\"\n    write (u, *)\n    write (u, \"(2x,A)\")  \"pure function n_col () result (n)\"\n    write (u, \"(2x,A)\")  \"  integer :: n\"\n    write (u, \"(2x,A)\")  \"  n = 1\"\n    write (u, \"(2x,A)\")  \"end function n_col\"\n    write (u, *)\n    write (u, \"(2x,A)\")  \"pure function n_cf () result (n)\"\n    write (u, \"(2x,A)\")  \"  integer :: n\"\n    write (u, \"(2x,A)\")  \"  n = 1\"\n    write (u, \"(2x,A)\")  \"end function n_cf\"\n    write (u, *)\n    write (u, \"(2x,A)\")  \"pure subroutine flv_state (a)\"\n    write (u, \"(2x,A)\")  \"  integer, dimension(:,:), intent(out) :: a\"\n    write (u, \"(2x,A)\")  \"  a = reshape ([1,2,3], [3,1])\"\n    write (u, \"(2x,A)\")  \"end subroutine flv_state\"\n    write (u, *)\n    write (u, \"(2x,A)\")  \"pure subroutine hel_state (a)\"\n    write (u, \"(2x,A)\")  \"  integer, dimension(:,:), intent(out) :: a\"\n    write (u, \"(2x,A)\")  \"  a = reshape ([0,0,0], [3,1])\"\n    write (u, \"(2x,A)\")  \"end subroutine hel_state\"\n    write (u, *)\n    write (u, \"(2x,A)\")  \"pure subroutine col_state (a, g)\"\n    write (u, \"(2x,A)\")  \"  integer, dimension(:,:,:), intent(out) :: a\"\n    write (u, \"(2x,A)\")  \"  logical, dimension(:,:), intent(out) :: g\"\n    write (u, \"(2x,A)\")  \"  a = reshape ([0,0, 0,0, 0,0], [2,3,1])\"\n    write (u, \"(2x,A)\")  \"  g = reshape ([.false., .false., .false.], [3,1])\"\n    write (u, \"(2x,A)\")  \"end subroutine col_state\"\n    write (u, *)\n    write (u, \"(2x,A)\")  \"pure subroutine color_factors (cf)\"\n    write (u, \"(2x,A)\")  \"  type(OCF), dimension(:), intent(out) :: cf\"\n    write (u, \"(2x,A)\")  \"  cf = [ OCF(1,1,+1._default) ]\"\n    write (u, \"(2x,A)\")  \"end subroutine color_factors\"\n  end subroutine write_test_me_code_2\n\n@ %def write_test_me_code_1 write_test_me_code_2\n@\n\\subsubsection{Compile test with Fortran bind(C) library}\nTest 5: Write driver and makefile and try to compile and link the\nlibrary driver.\n\nThere is a single test process with a single feature.  The process\ncode is provided as a Fortran library of independent procedures.\nThese procedures are bind(C).\n<<Prclib interfaces: execute tests>>=\n  call test (prclib_interfaces_5, \"prclib_interfaces_5\", &\n       \"compile and link (Fortran library)\", &\n       u, results)\n<<Prclib interfaces: test declarations>>=\n  public :: prclib_interfaces_5\n<<Prclib interfaces: tests>>=\n  subroutine prclib_interfaces_5 (u)\n    integer, intent(in) :: u\n    class(prclib_driver_t), allocatable :: driver\n    class(prc_writer_t), pointer :: test_writer_5\n    type(os_data_t) :: os_data\n    integer :: u_file\n\n    integer, dimension(:,:), allocatable :: flv_state\n    integer, dimension(:,:), allocatable :: hel_state\n    integer, dimension(:,:,:), allocatable :: col_state\n    logical, dimension(:,:), allocatable :: ghost_flag\n    integer, dimension(:,:), allocatable :: cf_index\n    complex(default), dimension(:), allocatable :: color_factors\n    character(32), parameter :: md5sum = \"prclib_interfaces_5_md5sum      \"\n\n    type(c_funptr) :: proc1_ptr\n    interface\n       subroutine proc1_t (n) bind(C)\n         import\n         integer(c_int), intent(out) :: n\n       end subroutine proc1_t\n    end interface\n    procedure(proc1_t), pointer :: proc1\n    integer(c_int) :: n\n\n    write (u, \"(A)\")  \"* Test output: prclib_interfaces_5\"\n    write (u, \"(A)\")  \"*   Purpose: compile, link, and load process library\"\n    write (u, \"(A)\")  \"*            with (fake) matrix-element code &\n         &as a Fortran bind(C) library\"\n    write (u, *)\n    write (u, \"(A)\")  \"* Create a prclib driver object (1 process)\"\n    write (u, \"(A)\")\n\n    call os_data%init ()\n    allocate (test_writer_5_t :: test_writer_5)\n\n    call dispatch_prclib_driver (driver, var_str (\"prclib5\"), var_str (\"\"))\n    call driver%init (1)\n    call driver%set_md5sum (md5sum)\n\n    call driver%set_record (1, var_str (\"test5\"), var_str (\"Test_model\"), &\n         [var_str (\"proc1\")], test_writer_5)\n\n    call driver%write (u)\n\n    write (u, *)\n    write (u, \"(A)\")  \"* Write makefile\"\n    u_file = free_unit ()\n    open (u_file, file=\"prclib5.makefile\", status=\"replace\", action=\"write\")\n    call driver%generate_makefile (u_file, os_data, verbose = .false.)\n    close (u_file)\n\n    write (u, \"(A)\")  \"* Write driver source code\"\n    u_file = free_unit ()\n    open (u_file, file=\"prclib5.f90\", status=\"replace\", action=\"write\")\n    call driver%generate_driver_code (u_file)\n    close (u_file)\n\n    write (u, \"(A)\")  \"* Write matrix-element source code\"\n    call driver%make_source (os_data)\n\n    write (u, \"(A)\")  \"* Compile source code\"\n    call driver%make_compile (os_data)\n\n    write (u, \"(A)\")  \"* Link library\"\n    call driver%make_link (os_data)\n\n    write (u, \"(A)\")  \"* Load library\"\n    call driver%load (os_data)\n\n    write (u, *)\n    call driver%write (u)\n    write (u, *)\n\n    if (driver%loaded) then\n       write (u, \"(A)\")  \"* Call library functions:\"\n       write (u, *)\n       write (u, \"(1x,A,I0)\")  \"n_processes   = \", driver%get_n_processes ()\n       write (u, \"(1x,A,A)\")  \"process_id    = \", &\n            char (driver%get_process_id (1))\n       write (u, \"(1x,A,A)\")  \"model_name    = \", &\n            char (driver%get_model_name (1))\n       write (u, \"(1x,A,A)\")  \"md5sum        = \", &\n            char (driver%get_md5sum (1))\n       write (u, \"(1x,A,L1)\")  \"openmp_status = \", driver%get_openmp_status (1)\n       write (u, \"(1x,A,I0)\")  \"n_in  = \", driver%get_n_in (1)\n       write (u, \"(1x,A,I0)\")  \"n_out = \", driver%get_n_out (1)\n       write (u, \"(1x,A,I0)\")  \"n_flv = \", driver%get_n_flv (1)\n       write (u, \"(1x,A,I0)\")  \"n_hel = \", driver%get_n_hel (1)\n       write (u, \"(1x,A,I0)\")  \"n_col = \", driver%get_n_col (1)\n       write (u, \"(1x,A,I0)\")  \"n_cin = \", driver%get_n_cin (1)\n       write (u, \"(1x,A,I0)\")  \"n_cf  = \", driver%get_n_cf (1)\n\n       call driver%set_flv_state (1, flv_state)\n       write (u, \"(1x,A,10(1x,I0))\")  \"flv_state =\", flv_state\n\n       call driver%set_hel_state (1, hel_state)\n       write (u, \"(1x,A,10(1x,I0))\")  \"hel_state =\", hel_state\n\n       call driver%set_col_state (1, col_state, ghost_flag)\n       write (u, \"(1x,A,10(1x,I0))\")  \"col_state =\", col_state\n       write (u, \"(1x,A,10(1x,L1))\")  \"ghost_flag =\", ghost_flag\n\n       call driver%set_color_factors (1, color_factors, cf_index)\n       write (u, \"(1x,A,10(1x,F5.3))\")  \"color_factors =\", color_factors\n       write (u, \"(1x,A,10(1x,I0))\")  \"cf_index =\", cf_index\n\n       call driver%get_fptr (1, 1, proc1_ptr)\n       call c_f_procpointer (proc1_ptr, proc1)\n       if (associated (proc1)) then\n          write (u, *)\n          call proc1 (n)\n          write (u, \"(1x,A,I0)\")  \"proc1(1) = \", n\n       end if\n\n    end if\n\n    deallocate (test_writer_5)\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Test output end: prclib_interfaces_5\"\n  end subroutine prclib_interfaces_5\n\n@ %def prclib_interfaces_5\n@ This version of test-code writer writes interfaces for all standard\nfeatures plus one specific feature.  The interfaces are all bind(C),\nso no wrapper is needed.\n<<Prclib interfaces: test types>>=\n  type, extends (prc_writer_c_lib_t) :: test_writer_5_t\n   contains\n     procedure, nopass :: type_name => test_writer_5_type_name\n     procedure :: write_makefile_code => test_writer_5_mk\n     procedure :: write_source_code => test_writer_5_src\n     procedure :: write_interface => test_writer_5_if\n     procedure :: before_compile => test_writer_5_before_compile\n     procedure :: after_compile => test_writer_5_after_compile\n  end type test_writer_5_t\n\n@ %def test_writer_5\n@ The\n<<Prclib interfaces: test auxiliary>>=\n  function test_writer_5_type_name () result (string)\n    type(string_t) :: string\n    string = \"test_5\"\n  end function test_writer_5_type_name\n\n  subroutine test_writer_5_mk &\n       (writer, unit, id, os_data, verbose, testflag)\n    class(test_writer_5_t), intent(in) :: writer\n    integer, intent(in) :: unit\n    type(string_t), intent(in) :: id\n    type(os_data_t), intent(in) :: os_data\n    logical, intent(in) :: verbose\n    logical, intent(in), optional :: testflag\n    write (unit, \"(5A)\")  \"SOURCES += \", char (id), \".f90\"\n    write (unit, \"(5A)\")  \"OBJECTS += \", char (id), \".lo\"\n    write (unit, \"(5A)\")  char (id), \".lo: \", char (id), \".f90\"\n    if (.not. verbose) then\n       write (unit, \"(5A)\")  TAB // '@echo  \"  FC       \" $@'\n    end if\n    write (unit, \"(5A)\")  TAB, \"$(LTFCOMPILE) $<\"    \n  end subroutine test_writer_5_mk\n\n  subroutine test_writer_5_src (writer, id)\n    class(test_writer_5_t), intent(in) :: writer\n    type(string_t), intent(in) :: id\n    call write_test_f_lib_file (id, var_str (\"proc1\"))\n  end subroutine test_writer_5_src\n\n  subroutine test_writer_5_if (writer, unit, id, feature)\n    class(test_writer_5_t), intent(in) :: writer\n    integer, intent(in) :: unit\n    type(string_t), intent(in) :: id, feature\n    select case (char (feature))\n    case (\"proc1\")\n       write (unit, \"(2x,9A)\")  \"interface\"\n       write (unit, \"(5x,9A)\")  \"subroutine \", &\n            char (writer%get_c_procname (id, feature)), &\n            \" (n) bind(C)\"\n       write (unit, \"(7x,9A)\")  \"import\"\n       write (unit, \"(7x,9A)\")  \"implicit none\"\n       write (unit, \"(7x,9A)\")  \"integer(c_int), intent(out) :: n\"\n       write (unit, \"(5x,9A)\")  \"end subroutine \", &\n            char (writer%get_c_procname (id, feature))\n       write (unit, \"(2x,9A)\")  \"end interface\"\n    case default\n       call writer%write_standard_interface (unit, id, feature)\n    end select\n  end subroutine test_writer_5_if\n\n  subroutine test_writer_5_before_compile (writer, id)\n    class(test_writer_5_t), intent(in) :: writer\n    type(string_t), intent(in) :: id\n  end subroutine test_writer_5_before_compile\n  \n  subroutine test_writer_5_after_compile (writer, id)\n    class(test_writer_5_t), intent(in) :: writer\n    type(string_t), intent(in) :: id\n  end subroutine test_writer_5_after_compile\n  \n@ %def test_writer_5_type_name test_writer_5_mk\n@ %def test_writer_5_if\n@ %def test_writer_5_before_compile test_writer_5_after_compile\n@\nWe need a test module file (actually, one for each process in the test\nabove) that allows us to check compilation and linking.  The test\nmodule implements a colorless $1\\to 2$ process, and it implements one\nadditional function (feature), the name given as an argument.\n<<Prclib interfaces: test auxiliary>>=\n  subroutine write_test_f_lib_file (basename, feature)\n    type(string_t), intent(in) :: basename\n    type(string_t), intent(in) :: feature\n    integer :: u\n    u = free_unit ()\n    open (u, file = char (basename) // \".f90\", &\n         status = \"replace\", action = \"write\")\n    write (u, \"(A)\")  \"! (Pseudo) matrix element code file &\n         &for WHIZARD self-test\"\n    call write_test_me_code_3 (u, char (basename))\n    write (u, *)\n    write (u, \"(A)\")  \"subroutine \" // char (basename) // \"_\" &\n         // char (feature) // \" (n) bind(C)\"\n    write (u, \"(A)\")  \"  use iso_c_binding\"\n    write (u, \"(A)\")  \"  implicit none\"\n    write (u, \"(A)\")  \"  integer(c_int), intent(out) :: n\"\n    write (u, \"(A)\")  \"  n = 42\"\n    write (u, \"(A)\")  \"end subroutine \" // char (basename) // \"_\" &\n         // char (feature)\n    close (u)\n  end subroutine write_test_f_lib_file\n\n@ %def write_test_module_file\n@\nThe following matrix-element source code is identical to the previous\none, but modified such as to provide independent procedures without a\nmodule envelope.\n<<Prclib interfaces: test auxiliary>>=\n  subroutine write_test_me_code_3 (u, id)\n    integer, intent(in) :: u\n    character(*), intent(in) :: id\n    write (u, \"(A)\")  \"function \" // id // \"_get_md5sum () &\n         &result (cptr) bind(C)\"\n    write (u, \"(A)\")  \"  use iso_c_binding\"\n    write (u, \"(A)\")  \"  implicit none\"\n    write (u, \"(A)\")  \"  type(c_ptr) :: cptr\"\n    write (u, \"(A)\")  \"  character(c_char), dimension(32), &\n         &target, save :: md5sum\"\n    write (u, \"(A)\")  \"  md5sum = copy (c_char_&\n         &'1234567890abcdef1234567890abcdef')\"\n    write (u, \"(A)\")  \"  cptr = c_loc (md5sum)\"\n    write (u, \"(A)\")  \"contains\"\n    write (u, \"(A)\")  \"  function copy (md5sum)\"\n    write (u, \"(A)\")  \"    character(c_char), dimension(32) :: copy\"\n    write (u, \"(A)\")  \"    character(c_char), dimension(32), intent(in) :: &\n         &md5sum\"\n    write (u, \"(A)\")  \"    copy = md5sum\"\n    write (u, \"(A)\")  \"  end function copy\"\n    write (u, \"(A)\")  \"end function \" // id // \"_get_md5sum\"\n    write (u, *)\n    write (u, \"(A)\")  \"function \" // id // \"_openmp_supported () &\n         &result (status) bind(C)\"\n    write (u, \"(A)\")  \"  use iso_c_binding\"\n    write (u, \"(A)\")  \"  implicit none\"\n    write (u, \"(A)\")  \"  logical(c_bool) :: status\"\n    write (u, \"(A)\")  \"  status = .false.\"\n    write (u, \"(A)\")  \"end function \" // id // \"_openmp_supported\"\n    write (u, *)\n    write (u, \"(A)\")  \"function \" // id // \"_n_in () result (n) bind(C)\"\n    write (u, \"(A)\")  \"  use iso_c_binding\"\n    write (u, \"(A)\")  \"  implicit none\"\n    write (u, \"(A)\")  \"  integer(c_int) :: n\"\n    write (u, \"(A)\")  \"  n = 1\"\n    write (u, \"(A)\")  \"end function \" // id // \"_n_in\"\n    write (u, *)\n    write (u, \"(A)\")  \"function \" // id // \"_n_out () result (n) bind(C)\"\n    write (u, \"(A)\")  \"  use iso_c_binding\"\n    write (u, \"(A)\")  \"  implicit none\"\n    write (u, \"(A)\")  \"  integer(c_int) :: n\"\n    write (u, \"(A)\")  \"  n = 2\"\n    write (u, \"(A)\")  \"end function \" // id // \"_n_out\"\n    write (u, *)\n    write (u, \"(A)\")  \"function \" // id // \"_n_flv () result (n) bind(C)\"\n    write (u, \"(A)\")  \"  use iso_c_binding\"\n    write (u, \"(A)\")  \"  implicit none\"\n    write (u, \"(A)\")  \"  integer(c_int) :: n\"\n    write (u, \"(A)\")  \"  n = 1\"\n    write (u, \"(A)\")  \"end function \" // id // \"_n_flv\"\n    write (u, *)\n    write (u, \"(A)\")  \"function \" // id // \"_n_hel () result (n) bind(C)\"\n    write (u, \"(A)\")  \"  use iso_c_binding\"\n    write (u, \"(A)\")  \"  implicit none\"\n    write (u, \"(A)\")  \"  integer(c_int) :: n\"\n    write (u, \"(A)\")  \"  n = 1\"\n    write (u, \"(A)\")  \"end function \" // id // \"_n_hel\"\n    write (u, *)\n    write (u, \"(A)\")  \"function \" // id // \"_n_cin () result (n) bind(C)\"\n    write (u, \"(A)\")  \"  use iso_c_binding\"\n    write (u, \"(A)\")  \"  implicit none\"\n    write (u, \"(A)\")  \"  integer(c_int) :: n\"\n    write (u, \"(A)\")  \"  n = 2\"\n    write (u, \"(A)\")  \"end function \" // id // \"_n_cin\"\n    write (u, *)\n    write (u, \"(A)\")  \"function \" // id // \"_n_col () result (n) bind(C)\"\n    write (u, \"(A)\")  \"  use iso_c_binding\"\n    write (u, \"(A)\")  \"  implicit none\"\n    write (u, \"(A)\")  \"  integer(c_int) :: n\"\n    write (u, \"(A)\")  \"  n = 1\"\n    write (u, \"(A)\")  \"end function \" // id // \"_n_col\"\n    write (u, *)\n    write (u, \"(A)\")  \"function \" // id // \"_n_cf () result (n) bind(C)\"\n    write (u, \"(A)\")  \"  use iso_c_binding\"\n    write (u, \"(A)\")  \"  implicit none\"\n    write (u, \"(A)\")  \"  integer(c_int) :: n\"\n    write (u, \"(A)\")  \"  n = 1\"\n    write (u, \"(A)\")  \"end function \" // id // \"_n_cf\"\n    write (u, *)\n    write (u, \"(A)\")  \"subroutine \" // id // \"_flv_state (flv_state) bind(C)\"\n    write (u, \"(A)\")  \"  use iso_c_binding\"\n    write (u, \"(A)\")  \"  implicit none\"\n    write (u, \"(A)\")  \"  integer(c_int), dimension(*), intent(out) :: flv_state\"\n    write (u, \"(A)\")  \"  flv_state(1:3) = [1,2,3]\"\n    write (u, \"(A)\")  \"end subroutine \" // id // \"_flv_state\"\n    write (u, *)\n    write (u, \"(A)\")  \"subroutine \" // id // \"_hel_state (hel_state) bind(C)\"\n    write (u, \"(A)\")  \"  use iso_c_binding\"\n    write (u, \"(A)\")  \"  implicit none\"\n    write (u, \"(A)\")  \"  integer(c_int), dimension(*), intent(out) :: hel_state\"\n    write (u, \"(A)\")  \"  hel_state(1:3) = [0,0,0]\"\n    write (u, \"(A)\")  \"end subroutine \" // id // \"_hel_state\"\n    write (u, *)\n    write (u, \"(A)\")  \"subroutine \" // id // \"_col_state &\n         &(col_state, ghost_flag) bind(C)\"\n    write (u, \"(A)\")  \"  use iso_c_binding\"\n    write (u, \"(A)\")  \"  implicit none\"\n    write (u, \"(A)\")  \"  integer(c_int), dimension(*), intent(out) &\n         &:: col_state\"\n    write (u, \"(A)\")  \"  logical(c_bool), dimension(*), intent(out) &\n         &:: ghost_flag\"\n    write (u, \"(A)\")  \"  col_state(1:6) = [0,0, 0,0, 0,0]\"\n    write (u, \"(A)\")  \"  ghost_flag(1:3) = [.false., .false., .false.]\"\n    write (u, \"(A)\")  \"end subroutine \" // id // \"_col_state\"\n    write (u, *)\n    write (u, \"(A)\")  \"subroutine \" // id // \"_color_factors &\n         &(cf_index1, cf_index2, color_factors) bind(C)\"\n    write (u, \"(A)\")  \"  use iso_c_binding\"\n    write (u, \"(A)\")  \"  use kinds\"\n    write (u, \"(A)\")  \"  implicit none\"\n    write (u, \"(A)\")  \"  integer(c_int), dimension(*), intent(out) :: cf_index1\"\n    write (u, \"(A)\")  \"  integer(c_int), dimension(*), intent(out) :: cf_index2\"\n    write (u, \"(A)\")  \"  complex(c_default_complex), dimension(*), &\n         &intent(out) :: color_factors\"\n    write (u, \"(A)\")  \"  cf_index1(1:1) = [1]\"\n    write (u, \"(A)\")  \"  cf_index2(1:1) = [1]\"\n    write (u, \"(A)\")  \"  color_factors(1:1) = [1]\"\n    write (u, \"(A)\")  \"end subroutine \" // id // \"_color_factors\"\n  end subroutine write_test_me_code_3\n\n@ %def write_test_me_code_3\n@\n\\subsubsection{Compile test with genuine C library}\nTest 6: Write driver and makefile and try to compile and link the\nlibrary driver.\n\nThere is a single test process with a single feature.  The process\ncode is provided as a C library of independent procedures.\nThese procedures should match the Fortran bind(C) interface.\n<<Prclib interfaces: execute tests>>=\n  if (default == double .or. (CC_IS_GNU .and. CC_HAS_QUADMATH)) then\n     call test (prclib_interfaces_6, \"prclib_interfaces_6\", &\n          \"compile and link (C library)\", &\n          u, results)\n  end if\n<<Prclib interfaces: test declarations>>=\n  public :: prclib_interfaces_6\n<<Prclib interfaces: tests>>=\n  subroutine prclib_interfaces_6 (u)\n    integer, intent(in) :: u\n    class(prclib_driver_t), allocatable :: driver\n    class(prc_writer_t), pointer :: test_writer_6\n    type(os_data_t) :: os_data\n    integer :: u_file\n\n    integer, dimension(:,:), allocatable :: flv_state\n    integer, dimension(:,:), allocatable :: hel_state\n    integer, dimension(:,:,:), allocatable :: col_state\n    logical, dimension(:,:), allocatable :: ghost_flag\n    integer, dimension(:,:), allocatable :: cf_index\n    complex(default), dimension(:), allocatable :: color_factors\n    character(32), parameter :: md5sum = \"prclib_interfaces_6_md5sum      \"\n\n    type(c_funptr) :: proc1_ptr\n    interface\n       subroutine proc1_t (n) bind(C)\n         import\n         integer(c_int), intent(out) :: n\n       end subroutine proc1_t\n    end interface\n    procedure(proc1_t), pointer :: proc1\n    integer(c_int) :: n\n\n    write (u, \"(A)\")  \"* Test output: prclib_interfaces_6\"\n    write (u, \"(A)\")  \"*   Purpose: compile, link, and load process library\"\n    write (u, \"(A)\")  \"*            with (fake) matrix-element code &\n         &as a C library\"\n    write (u, *)\n    write (u, \"(A)\")  \"* Create a prclib driver object (1 process)\"\n    write (u, \"(A)\")\n\n    call os_data%init ()\n    allocate (test_writer_6_t :: test_writer_6)\n\n    call dispatch_prclib_driver (driver, var_str (\"prclib6\"), var_str (\"\"))\n    call driver%init (1)\n    call driver%set_md5sum (md5sum)\n\n    call driver%set_record (1, var_str (\"test6\"), var_str (\"Test_model\"), &\n         [var_str (\"proc1\")], test_writer_6)\n\n    call driver%write (u)\n\n    write (u, *)\n    write (u, \"(A)\")  \"* Write makefile\"\n    u_file = free_unit ()\n    open (u_file, file=\"prclib6.makefile\", status=\"replace\", action=\"write\")\n    call driver%generate_makefile (u_file, os_data, verbose = .false.)\n    close (u_file)\n\n    write (u, \"(A)\")  \"* Write driver source code\"\n    u_file = free_unit ()\n    open (u_file, file=\"prclib6.f90\", status=\"replace\", action=\"write\")\n    call driver%generate_driver_code (u_file)\n    close (u_file)\n\n    write (u, \"(A)\")  \"* Write matrix-element source code\"\n    call driver%make_source (os_data)\n\n    write (u, \"(A)\")  \"* Compile source code\"\n    call driver%make_compile (os_data)\n\n    write (u, \"(A)\")  \"* Link library\"\n    call driver%make_link (os_data)\n\n    write (u, \"(A)\")  \"* Load library\"\n    call driver%load (os_data)\n\n    write (u, *)\n    call driver%write (u)\n    write (u, *)\n\n    if (driver%loaded) then\n       write (u, \"(A)\")  \"* Call library functions:\"\n       write (u, *)\n       write (u, \"(1x,A,I0)\")  \"n_processes   = \", driver%get_n_processes ()\n       write (u, \"(1x,A,A)\")  \"process_id    = \", &\n            char (driver%get_process_id (1))\n       write (u, \"(1x,A,A)\")  \"model_name    = \", &\n            char (driver%get_model_name (1))\n       write (u, \"(1x,A,A)\")  \"md5sum        = \", &\n            char (driver%get_md5sum (1))\n       write (u, \"(1x,A,L1)\")  \"openmp_status = \", driver%get_openmp_status (1)\n       write (u, \"(1x,A,I0)\")  \"n_in  = \", driver%get_n_in (1)\n       write (u, \"(1x,A,I0)\")  \"n_out = \", driver%get_n_out (1)\n       write (u, \"(1x,A,I0)\")  \"n_flv = \", driver%get_n_flv (1)\n       write (u, \"(1x,A,I0)\")  \"n_hel = \", driver%get_n_hel (1)\n       write (u, \"(1x,A,I0)\")  \"n_col = \", driver%get_n_col (1)\n       write (u, \"(1x,A,I0)\")  \"n_cin = \", driver%get_n_cin (1)\n       write (u, \"(1x,A,I0)\")  \"n_cf  = \", driver%get_n_cf (1)\n\n       call driver%set_flv_state (1, flv_state)\n       write (u, \"(1x,A,10(1x,I0))\")  \"flv_state =\", flv_state\n\n       call driver%set_hel_state (1, hel_state)\n       write (u, \"(1x,A,10(1x,I0))\")  \"hel_state =\", hel_state\n\n       call driver%set_col_state (1, col_state, ghost_flag)\n       write (u, \"(1x,A,10(1x,I0))\")  \"col_state =\", col_state\n       write (u, \"(1x,A,10(1x,L1))\")  \"ghost_flag =\", ghost_flag\n\n       call driver%set_color_factors (1, color_factors, cf_index)\n       write (u, \"(1x,A,10(1x,F5.3))\")  \"color_factors =\", color_factors\n       write (u, \"(1x,A,10(1x,I0))\")  \"cf_index =\", cf_index\n\n       call driver%get_fptr (1, 1, proc1_ptr)\n       call c_f_procpointer (proc1_ptr, proc1)\n       if (associated (proc1)) then\n          write (u, *)\n          call proc1 (n)\n          write (u, \"(1x,A,I0)\")  \"proc1(1) = \", n\n       end if\n\n    end if\n\n    deallocate (test_writer_6)\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Test output end: prclib_interfaces_6\"\n  end subroutine prclib_interfaces_6\n\n@ %def prclib_interfaces_6\n@ This version of test-code writer writes interfaces for all standard\nfeatures plus one specific feature.  The interfaces are all bind(C),\nso no wrapper is needed.\n\nThe driver part is identical to the Fortran case, so we simply extend\nthe previous [[test_writer_5]] type.  We only have to override the\nMakefile writer.\n<<Prclib interfaces: test types>>=\n  type, extends (test_writer_5_t) :: test_writer_6_t\n   contains\n     procedure, nopass :: type_name => test_writer_6_type_name\n     procedure :: write_makefile_code => test_writer_6_mk\n     procedure :: write_source_code => test_writer_6_src\n  end type test_writer_6_t\n\n@ %def test_writer_6\n@\n<<Prclib interfaces: test auxiliary>>=\n  function test_writer_6_type_name () result (string)\n    type(string_t) :: string\n    string = \"test_6\"\n  end function test_writer_6_type_name\n\n  subroutine test_writer_6_mk &\n       (writer, unit, id, os_data, verbose, testflag)\n    class(test_writer_6_t), intent(in) :: writer\n    integer, intent(in) :: unit\n    type(string_t), intent(in) :: id\n    type(os_data_t), intent(in) :: os_data\n    logical, intent(in) :: verbose\n    logical, intent(in), optional :: testflag\n    write (unit, \"(5A)\")  \"SOURCES += \", char (id), \".c\"\n    write (unit, \"(5A)\")  \"OBJECTS += \", char (id), \".lo\"\n    write (unit, \"(5A)\")  char (id), \".lo: \", char (id), \".c\"\n    if (.not. verbose) then\n       write (unit, \"(5A)\")  TAB // '@echo  \"  FC       \" $@'\n    end if    \n    write (unit, \"(5A)\")  TAB, \"$(LTCCOMPILE) $<\"\n  end subroutine test_writer_6_mk\n\n  subroutine test_writer_6_src (writer, id)\n    class(test_writer_6_t), intent(in) :: writer\n    type(string_t), intent(in) :: id\n    call write_test_c_lib_file (id, var_str (\"proc1\"))\n  end subroutine test_writer_6_src\n\n@ %def test_writer_6_type_name test_writer_6_mk\n@\nWe need a test module file (actually, one for each process in the test\nabove) that allows us to check compilation and linking.  The test\nmodule implements a colorless $1\\to 2$ process, and it implements one\nadditional function (feature), the name given as an argument.\n<<Prclib interfaces: test auxiliary>>=\n  subroutine write_test_c_lib_file (basename, feature)\n    type(string_t), intent(in) :: basename\n    type(string_t), intent(in) :: feature\n    integer :: u\n    u = free_unit ()\n    open (u, file = char (basename) // \".c\", &\n         status = \"replace\", action = \"write\")\n    write (u, \"(A)\")  \"/* (Pseudo) matrix element code file &\n         &for WHIZARD self-test */\"\n    write (u, \"(A)\")  \"#include <stdbool.h>\"\n    if (CC_HAS_QUADMATH) then\n       write (u, \"(A)\")  \"#include <quadmath.h>\"\n    end if\n    write (u, *)\n    call write_test_me_code_4 (u, char (basename))\n    write (u, *)\n    write (u, \"(A)\")  \"void \" // char (basename) // \"_\" &\n         // char (feature) // \"(int* n) {\"\n    write (u, \"(A)\")  \"  *n = 42;\"\n    write (u, \"(A)\")  \"}\"\n    close (u)\n  end subroutine write_test_c_lib_file\n\n@ %def write_test_module_file\n@\nThe following matrix-element source code is equivalent to the code in\nthe previous example, but coded in C.\n<<Prclib interfaces: test auxiliary>>=\n  subroutine write_test_me_code_4 (u, id)\n    integer, intent(in) :: u\n    character(*), intent(in) :: id\n    write (u, \"(A)\")  \"char* \" // id // \"_get_md5sum() {\"\n    write (u, \"(A)\")  \"  return \"\"1234567890abcdef1234567890abcdef\"\";\"\n    write (u, \"(A)\")  \"}\"\n    write (u, *)\n    write (u, \"(A)\")  \"bool \" // id // \"_openmp_supported() {\"\n    write (u, \"(A)\")  \"  return false;\"\n    write (u, \"(A)\")  \"}\"\n    write (u, *)\n    write (u, \"(A)\")  \"int \" // id // \"_n_in() {\"\n    write (u, \"(A)\")  \"  return 1;\"\n    write (u, \"(A)\")  \"}\"\n    write (u, *)\n    write (u, \"(A)\")  \"int \" // id // \"_n_out() {\"\n    write (u, \"(A)\")  \"  return 2;\"\n    write (u, \"(A)\")  \"}\"\n    write (u, *)\n    write (u, \"(A)\")  \"int \" // id // \"_n_flv() {\"\n    write (u, \"(A)\")  \"  return 1;\"\n    write (u, \"(A)\")  \"}\"\n    write (u, *)\n    write (u, \"(A)\")  \"int \" // id // \"_n_hel() {\"\n    write (u, \"(A)\")  \"  return 1;\"\n    write (u, \"(A)\")  \"}\"\n    write (u, *)\n    write (u, \"(A)\")  \"int \" // id // \"_n_cin() {\"\n    write (u, \"(A)\")  \"  return 2;\"\n    write (u, \"(A)\")  \"}\"\n    write (u, *)\n    write (u, \"(A)\")  \"int \" // id // \"_n_col() {\"\n    write (u, \"(A)\")  \"  return 1;\"\n    write (u, \"(A)\")  \"}\"\n    write (u, *)\n    write (u, \"(A)\")  \"int \" // id // \"_n_cf() {\"\n    write (u, \"(A)\")  \"  return 1;\"\n    write (u, \"(A)\")  \"}\"\n    write (u, *)\n    write (u, \"(A)\")  \"void \" // id // \"_flv_state( int (*a)[] ) {\"\n    write (u, \"(A)\")  \"  static int flv_state[1][3] =  { { 1, 2, 3 } };\"\n    write (u, \"(A)\")  \"  int j;\"\n    write (u, \"(A)\")  \"  for (j = 0; j < 3; j++) { (*a)[j] &\n         &= flv_state[0][j]; }\"\n    write (u, \"(A)\")  \"}\"\n    write (u, *)\n    write (u, \"(A)\")  \"void \" // id // \"_hel_state( int (*a)[] ) {\"\n    write (u, \"(A)\")  \"  static int hel_state[1][3] =  { { 0, 0, 0 } };\"\n    write (u, \"(A)\")  \"  int j;\"\n    write (u, \"(A)\")  \"  for (j = 0; j < 3; j++) { (*a)[j] &\n         &= hel_state[0][j]; }\"\n    write (u, \"(A)\")  \"}\"\n    write (u, *)\n    write (u, \"(A)\")  \"void \" // id // \"_col_state&\n         &( int (*a)[], bool (*g)[] ) {\"\n    write (u, \"(A)\")  \"  static int col_state[1][3][2] = &\n         &{ { {0, 0}, {0, 0}, {0, 0} } };\"\n    write (u, \"(A)\")  \"  static bool ghost_flag[1][3] =  &\n         &{ { false, false, false } };\"\n    write (u, \"(A)\")  \"  int j,k;\"\n    write (u, \"(A)\")  \"  for (j = 0; j < 3; j++) {\"\n    write (u, \"(A)\")  \"    for (k = 0; k < 2; k++) {\"\n    write (u, \"(A)\")  \"       (*a)[j*2+k] = col_state[0][j][k];\"\n    write (u, \"(A)\")  \"    }\"\n    write (u, \"(A)\")  \"    (*g)[j] = ghost_flag[0][j];\"\n    write (u, \"(A)\")  \"  }\"\n    write (u, \"(A)\")  \"}\"\n    write (u, *)\n    select case (DEFAULT_FC_PRECISION)\n    case (\"quadruple\")\n       write (u, \"(A)\")  \"void \" // id // \"_color_factors&\n            &( int (*cf_index1)[], int (*cf_index2)[], &\n            &__complex128 (*color_factors)[] ) {\"\n    case (\"extended\")\n       write (u, \"(A)\")  \"void \" // id // \"_color_factors&\n            &( int (*cf_index1)[], int (*cf_index2)[], &\n            &long double _Complex (*color_factors)[] ) {\"\n    case default\n       write (u, \"(A)\")  \"void \" // id // \"_color_factors&\n            &( int (*cf_index1)[], int (*cf_index2)[], &\n            &double _Complex (*color_factors)[] ) {\"\n    end select\n    write (u, \"(A)\")  \"  (*color_factors)[0] = 1;\"\n    write (u, \"(A)\")  \"  (*cf_index1)[0] = 1;\"\n    write (u, \"(A)\")  \"  (*cf_index2)[0] = 1;\"\n    write (u, \"(A)\")  \"}\"\n  end subroutine write_test_me_code_4\n\n@ %def write_test_me_code_4\n@\n\\subsubsection{Test cleanup targets}\nTest 7: Repeat test 4 (create, compile, link Fortran module and\ndriver) and properly clean up all generated files.\n<<Prclib interfaces: execute tests>>=\n  call test (prclib_interfaces_7, \"prclib_interfaces_7\", &\n       \"cleanup\", &\n       u, results)\n<<Prclib interfaces: test declarations>>=\n  public :: prclib_interfaces_7\n<<Prclib interfaces: tests>>=\n  subroutine prclib_interfaces_7 (u)\n    integer, intent(in) :: u\n    class(prclib_driver_t), allocatable :: driver\n    class(prc_writer_t), pointer :: test_writer_4\n    type(os_data_t) :: os_data\n    integer :: u_file\n    character(32), parameter :: md5sum = \"1234567890abcdef1234567890abcdef\"\n\n    write (u, \"(A)\")  \"* Test output: prclib_interfaces_7\"\n    write (u, \"(A)\")  \"*   Purpose: compile and link process library\"\n    write (u, \"(A)\")  \"*            with (fake) matrix-element code &\n         &as a Fortran module\"\n    write (u, \"(A)\")  \"*            then clean up generated files\"\n    write (u, *)\n    write (u, \"(A)\")  \"* Create a prclib driver object (1 process)\"\n\n    allocate (test_writer_4_t :: test_writer_4)\n\n    call os_data%init ()\n    call dispatch_prclib_driver (driver, var_str (\"prclib7\"), var_str (\"\"))\n    call driver%init (1)\n    call driver%set_md5sum (md5sum)\n    call driver%set_record (1, var_str (\"test7\"), var_str (\"Test_model\"), &\n         [var_str (\"proc1\")], test_writer_4)\n\n    write (u, \"(A)\")  \"* Write makefile\"\n    u_file = free_unit ()\n    open (u_file, file=\"prclib7.makefile\", status=\"replace\", action=\"write\")\n    call driver%generate_makefile (u_file, os_data, verbose = .false.)\n    close (u_file)\n\n    write (u, \"(A)\")  \"* Write driver source code\"\n    u_file = free_unit ()\n    open (u_file, file=\"prclib7.f90\", status=\"replace\", action=\"write\")\n    call driver%generate_driver_code (u_file)\n    close (u_file)\n\n    write (u, \"(A)\")  \"* Write matrix-element source code\"\n    call driver%make_source (os_data)\n\n    write (u, \"(A)\")  \"* Compile source code\"\n    call driver%make_compile (os_data)\n\n    write (u, \"(A)\")  \"* Link library\"\n    call driver%make_link (os_data)\n\n\n    write (u, \"(A)\")  \"* File check\"\n    write (u, *)\n    call check_file (u, \"test7.f90\")\n    call check_file (u, \"tpr_test7.mod\")\n    call check_file (u, \"test7.lo\")\n    call check_file (u, \"prclib7.makefile\")\n    call check_file (u, \"prclib7.f90\")\n    call check_file (u, \"prclib7.lo\")\n    call check_file (u, \"prclib7.la\")\n\n    write (u, *)\n    write (u, \"(A)\")  \"* Delete library\"\n    write (u, *)\n    call driver%clean_library (os_data)\n    call check_file (u, \"prclib7.la\")\n\n    write (u, *)\n    write (u, \"(A)\")  \"* Delete object code\"\n    write (u, *)\n    call driver%clean_objects (os_data)\n    call check_file (u, \"test7.lo\")\n    call check_file (u, \"tpr_test7.mod\")\n    call check_file (u, \"prclib7.lo\")\n\n    write (u, *)\n    write (u, \"(A)\")  \"* Delete source code\"\n    write (u, *)\n    call driver%clean_source (os_data)\n    call check_file (u, \"test7.f90\")\n\n    write (u, *)\n    write (u, \"(A)\")  \"* Delete driver source code\"\n    write (u, *)\n    call driver%clean_driver (os_data)\n    call check_file (u, \"prclib7.f90\")\n\n    write (u, *)\n    write (u, \"(A)\")  \"* Delete makefile\"\n    write (u, *)\n    call driver%clean_makefile (os_data)\n    call check_file (u, \"prclib7.makefile\")\n\n    deallocate (test_writer_4)\n\n    write (u, *)\n    write (u, \"(A)\")  \"* Test output end: prclib_interfaces_7\"\n  end subroutine prclib_interfaces_7\n\n@ %def prclib_interfaces_7\n@ Auxiliary routine: check and report existence of a file\n<<Prclib interfaces: test auxiliary>>=\n  subroutine check_file (u, file)\n    integer, intent(in) :: u\n    character(*), intent(in) :: file\n    logical :: exist\n    inquire (file=file, exist=exist)\n    write (u, \"(2x,A,A,L1)\")  file, \" = \", exist\n  end subroutine check_file\n\n@ %def check_file\n@\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\\section{Abstract process core configuration}\nIn this module, we define abstract data types that handle the method-specific\npart of defining a process (including all of its options) and accessing an\nexternal matrix element.\n\nThere are no unit tests, these are deferred to the [[process_libraries]]\nmodule below.\n<<[[prc_core_def.f90]]>>=\n<<File header>>\n\nmodule prc_core_def\n\n<<Use strings>>\n  use io_units\n  use diagnostics\n\n  use process_constants\n  use prclib_interfaces\n\n<<Standard module head>>\n\n<<Prc core def: public>>\n\n<<Prc core def: types>>\n\n<<Prc core def: interfaces>>\n\ncontains\n\n<<Prc core def: procedures>>\n\nend module prc_core_def\n@ %def prc_core_def\n@\n\\subsection{Process core definition type}\nFor storing configuration data that depend on the specific process\nvariant, we introduce a polymorphic type.  At this point, we just\ndeclare an abstract base type.  This allows us to defer the\nimplementation to later modules.\n\nThere should be no components that need explicit finalization,\notherwise we would have to call a finalizer from the\n[[process_component_def_t]] wrapper.\n\n@ Translate a [[prc_core_def_t]] to above named integers\n<<Prc core def: public>>=\n  public :: prc_core_def_t\n<<Prc core def: types>>=\n  type, abstract :: prc_core_def_t\n     class(prc_writer_t), allocatable :: writer\n   contains\n   <<Prc core def: process core def: TBP>>\n  end type prc_core_def_t\n\n@ %def prc_core_def_t\n@ Interfaces for the deferred methods.\n\nThis returns a string.  No passed argument; the string is constant and\ndepends just on the type.\n<<Prc core def: process core def: TBP>>=\n  procedure (prc_core_def_get_string), nopass, deferred :: type_string\n<<Prc core def: interfaces>>=\n  abstract interface\n     function prc_core_def_get_string () result (string)\n       import\n       type(string_t) :: string\n     end function prc_core_def_get_string\n  end interface\n\n@ %def prc_core_def_get_string\n@\nThe [[write]] method should\ndisplay the content completely.\n<<Prc core def: process core def: TBP>>=\n  procedure (prc_core_def_write), deferred :: write\n<<Prc core def: interfaces>>=\n  abstract interface\n     subroutine prc_core_def_write (object, unit)\n       import\n       class(prc_core_def_t), intent(in) :: object\n       integer, intent(in) :: unit\n     end subroutine prc_core_def_write\n  end interface\n\n@ %def prc_core_def_write\n@\nThe [[read]] method should\nfill the content completely.\n<<Prc core def: process core def: TBP>>=\n  procedure (prc_core_def_read), deferred :: read\n<<Prc core def: interfaces>>=\n  abstract interface\n     subroutine prc_core_def_read (object, unit)\n       import\n       class(prc_core_def_t), intent(out) :: object\n       integer, intent(in) :: unit\n     end subroutine prc_core_def_read\n  end interface\n\n@ %def prc_core_def_read\n@ This communicates a MD5 checksum to the writer inside the [[core_def]]\nobject, if there is any.  Usually, this checksum is not yet known at the time\nwhen the writer is initialized.\n<<Prc core def: process core def: TBP>>=\n  procedure :: set_md5sum => prc_core_def_set_md5sum\n<<Prc core def: procedures>>=\n  subroutine prc_core_def_set_md5sum (core_def, md5sum)\n    class(prc_core_def_t), intent(inout) :: core_def\n    character(32) :: md5sum\n    if (allocated (core_def%writer))  core_def%writer%md5sum = md5sum\n  end subroutine prc_core_def_set_md5sum\n\n@ %def prc_core_def_set_md5sum\n@ Allocate an appropriate driver object which corresponds to the\nchosen process core definition.\n\nFor internal matrix element (i.e., those which do not need external\ncode), the driver should have access to all matrix element information\nfrom the beginning.  In short, it is the matrix-element code.\n\nFor external matrix elements, the driver will get access to the\nexternal matrix element code.\n<<Prc core def: process core def: TBP>>=\n  procedure(prc_core_def_allocate_driver), deferred :: allocate_driver\n<<Prc core def: interfaces>>=\n  abstract interface\n     subroutine prc_core_def_allocate_driver (object, driver, basename)\n       import\n       class(prc_core_def_t), intent(in) :: object\n       class(prc_core_driver_t), intent(out), allocatable :: driver\n       type(string_t), intent(in) :: basename\n     end subroutine prc_core_def_allocate_driver\n  end interface\n\n@ %def prc_core_def_allocate_driver\n@ This flag tells whether the particular variant needs external code.\nWe implement a default function which returns false.  The flag\ndepends only on the type, therefore we implement it as [[nopass]].\n<<Prc core def: process core def: TBP>>=\n  procedure, nopass :: needs_code => prc_core_def_needs_code\n<<Prc core def: procedures>>=\n  function prc_core_def_needs_code () result (flag)\n    logical :: flag\n    flag = .false.\n  end function prc_core_def_needs_code\n\n@ %def prc_core_def_needs_code\n@ This subroutine allocates an array which holds the name of all\nfeatures that this process core implements.  This feature\napplies to matrix element code that is not coded as a Fortran module\nbut communicates via independent library functions, which follow the C\ncalling conventions.  The addresses of those functions are returned as\nC function pointers, which can be converted into Fortran procedure\npointers.  The conversion is done in code specific for the process\nvariant; here we just retrieve the C function pointer.\n\nThe array returned here serves the purpose of writing specific\ndriver code.  The driver interfaces only those C functions which are\nsupported for the given process core.\n\nIf the process core does not require external code, this array is\nmeaningless.\n<<Prc core def: process core def: TBP>>=\n  procedure(prc_core_def_get_features), nopass, deferred &\n       :: get_features\n<<Prc core def: interfaces>>=\n  abstract interface\n     subroutine prc_core_def_get_features (features)\n       import\n       type(string_t), dimension(:), allocatable, intent(out) :: features\n     end subroutine prc_core_def_get_features\n  end interface\n\n@ %def prc_core_def_get_features\n@ Assign pointers to the process-specific procedures to the driver, if\nthe process is external.\n<<Prc core def: process core def: TBP>>=\n  procedure(prc_core_def_connect), deferred :: connect\n<<Prc core def: interfaces>>=\n  abstract interface\n     subroutine prc_core_def_connect (def, lib_driver, i, proc_driver)\n       import\n       class(prc_core_def_t), intent(in) :: def\n       class(prclib_driver_t), intent(in) :: lib_driver\n       integer, intent(in) :: i\n       class(prc_core_driver_t), intent(inout) :: proc_driver\n     end subroutine prc_core_def_connect\n  end interface\n\n@ %def prc_core_def_connect\n@\n\\subsection{Process core template}\nWe must be able to automatically allocate a process core definition object\nwith the appropriate type, given only the type name.\n\nTo this end, we introduce a [[prc_template_t]] type which is simply a wrapper\nfor an empty [[prc_core_def_t]] object.  Choosing one of the templates from an\narray, we can allocate the target object.\n<<Prc core def: public>>=\n  public :: prc_template_t\n<<Prc core def: types>>=\n  type :: prc_template_t\n     class(prc_core_def_t), allocatable :: core_def\n  end type prc_template_t\n\n@ %def prc_template_t\n@ The allocation routine.  We use the [[source]] option of the [[allocate]]\nstatement.   The [[mold]] option would probably more appropriate, but is a\nF2008 feature.\n<<Prc core def: public>>=\n  public :: allocate_core_def\n<<Prc core def: procedures>>=\n  subroutine allocate_core_def (template, name, core_def)\n    type(prc_template_t), dimension(:), intent(in) :: template\n    type(string_t), intent(in) :: name\n    class(prc_core_def_t), allocatable :: core_def\n    integer :: i\n    do i = 1, size (template)\n       if (template(i)%core_def%type_string () == name) then\n          allocate (core_def, source = template(i)%core_def)\n          return\n       end if\n    end do\n  end subroutine allocate_core_def\n\n@ %def allocate_core_def\n@\n\\subsection{Process driver}\nFor each process component, we implement a driver object which holds\nthe calls to the matrix element and various auxiliary routines as\nprocedure pointers.  Any actual calculation will use this object to\ncommunicate with the process.\n\nDepending on the type of process (as described by a corresponding\n[[prc_core_def]] object), the procedure pointers may refer to\nexternal or internal code, and there may be additional procedures for\ncertain types.  The base type defined here is abstract.\n<<Prc core def: public>>=\n  public :: prc_core_driver_t\n<<Prc core def: types>>=\n  type, abstract :: prc_core_driver_t\n   contains\n   <<Prc core def: process driver: TBP>>\n  end type prc_core_driver_t\n\n@ %def prc_core_driver_t\n@ This returns the process type.  No reference to contents.\n<<Prc core def: process driver: TBP>>=\n  procedure(prc_core_driver_type_name), nopass, deferred :: type_name\n<<Prc core def: interfaces>>=\n  abstract interface\n     function prc_core_driver_type_name () result (type)\n       import\n       type(string_t) :: type\n     end function prc_core_driver_type_name\n  end interface\n\n@ %def prc_core_driver_type_name\n@\n\\subsection{Process driver for intrinsic process}\nThis is an abstract extension for the driver type.  It has one\nadditional method, namely a subroutine that fills the record of\nconstant process data.  For an external process, this task is\nperformed by the external library driver instead.\n<<Prc core def: public>>=\n  public :: process_driver_internal_t\n<<Prc core def: types>>=\n  type, extends (prc_core_driver_t), abstract :: process_driver_internal_t\n   contains\n   <<Prc core def: process driver internal: TBP>>\n  end type process_driver_internal_t\n\n@ %def process_driver_internal_t\n<<Prc core def: process driver internal: TBP>>=\n  procedure(process_driver_fill_constants), deferred :: fill_constants\n<<Prc core def: interfaces>>=\n  abstract interface\n     subroutine process_driver_fill_constants (driver, data)\n       import\n       class(process_driver_internal_t), intent(in) :: driver\n       type(process_constants_t), intent(out) :: data\n     end subroutine process_driver_fill_constants\n  end interface\n\n@ %def process_driver_fill_constants\n@\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\\section{Process library access}\n\\label{sec:process_libraries}\nProcesses (the code and data that are necessary for evaluating matrix\nelements of a particular process or process component) are organized\nin process libraries.  In full form, process libraries contain\ngenerated and dynamically compiled and linked code, so they are actual\nlibraries on the OS level.  Alternatively, there may be simple\nprocesses that can be generated without referring to external\nlibraries, and external libraries that are just linked in.\n\nThis module interfaces the OS to create, build, and use process\nlibraries.\n\nWe work with two related data structures.  There is the list of\nprocess configurations that stores the user input and data derived\nfrom it.  A given process configuration list is scanned for creating a\nprocess library, which consists of both data and code.  The creation\nstep involves calling external programs and incorporating external\ncode.\n\nFor the subsequent integration and event generation steps, we read the\nprocess library.  We also support partial (re)creation of the process\nlibrary.  To this end, we should be able to reconstruct the\nconfiguration data records from the process library.\n<<[[process_libraries.f90]]>>=\n<<File header>>\n\nmodule process_libraries\n\n  use, intrinsic :: iso_c_binding !NODEP!\n\n<<Use strings>>\n  use io_units\n  use diagnostics\n  use md5\n  use physics_defs\n  use os_interface\n  use model_data\n  use particle_specifiers\n  use process_constants\n  use prclib_interfaces\n  use prc_core_def\n\n<<Standard module head>>\n\n<<Process libraries: public>>\n\n<<Process libraries: parameters>>\n\n<<Process libraries: types>>\n\ncontains\n\n<<Process libraries: procedures>>\n\nend module process_libraries\n@ %def process_libraries\n@\n\\subsection{Auxiliary stuff}\nHere is a small subroutine that strips the left-hand side and the\nequals sign off an equation.\n<<Process libraries: public>>=\n  public :: strip_equation_lhs\n<<Process libraries: procedures>>=\n  subroutine strip_equation_lhs (buffer)\n    character(*), intent(inout) :: buffer\n    type(string_t) :: string, prefix\n    string = buffer\n    call split (string, prefix, \"=\")\n    buffer = string\n  end subroutine strip_equation_lhs\n\n@ %def strip_equation_lhs\n@\n\\subsection{Process definition objects}\nWe collect process configuration data in a derived type,\n[[process_def_t]].  A process can be a collection of several\ncomponents which are treated as a single entity for the purpose of\nobservables and event generation.  Multiple process components may\ninitially be defined by the user.  The system may add additional\ncomponents, e.g., subtraction terms.  The common data type is\n[[process_component_def_t]].  Within each component, there are several\nuniversal data items, and a part which depend on the particular\nprocess variant.  The latter is covered by an abstract type\n[[prc_core_def_t]] and its extensions.\n\n@\n\\subsubsection{Wrapper for components}\nWe define a wrapper type for the configuration of individual\ncomponents.\n\nThe string [[basename]] is used for building file, module, and\nfunction names for the current process component.  Initially, it will\nbe built from the corresponding process basename by appending an\nalphanumeric suffix.\n\nThe logical [[initial]] tells whether this is a user-defined (true) or\nsystem-generated (false) configuration.\n\nThe numbers [[n_in]], [[n_out]], and [[n_tot]] denote the incoming,\noutgoing and total number of particles (partons) participating in the\nprocess component, respectively.  These are the nominal particles, as\ninput by the user (recombination may change the particle content, for\nthe output events).\n\nThe string arrays [[prt_in]] and [[prt_out]] hold the particle\nspecifications as provided by the user.  For a system-generated\nprocess component, they remain deallocated.\n\nThe [[method]] string is used to determine the type of process matrix\nelement and how it is obtained.\n\nThe [[description]] string collects the information about particle\ncontent and method in a single human-readable string.\n\nThe pointer object [[core_def]] is allocated according to the\nactual process variant, which depends on the method.  The subobject\nholds any additional configuration data that is relevant for the\nprocess component.\n\nWe assume that no finalizer is needed.\n<<Process libraries: public>>=\n  public :: process_component_def_t\n<<Process libraries: types>>=\n  type :: process_component_def_t\n     private\n     type(string_t) :: basename\n     logical :: initial = .false.\n     integer :: n_in = 0\n     integer :: n_out = 0\n     integer :: n_tot = 0\n     type(prt_spec_t), dimension(:), allocatable :: prt_in\n     type(prt_spec_t), dimension(:), allocatable :: prt_out\n     type(string_t) :: method\n     type(string_t) :: description\n     class(prc_core_def_t), allocatable :: core_def\n     character(32) :: md5sum = \"\"\n     integer :: nlo_type = BORN\n     integer, dimension(N_ASSOCIATED_COMPONENTS) :: associated_components = 0\n     logical :: active\n     integer :: fixed_emitter = -1\n     integer :: alpha_power = 0\n     integer :: alphas_power = 0\n   contains\n   <<Process libraries: process component def: TBP>>\n  end type process_component_def_t\n\n@ %def process_component_def_t\n@ Display the complete content.\n<<Process libraries: process component def: TBP>>=\n  procedure :: write => process_component_def_write\n<<Process libraries: procedures>>=\n  subroutine process_component_def_write (object, unit)\n    class(process_component_def_t), intent(in) :: object\n    integer, intent(in), optional :: unit\n    integer :: u\n    u = given_output_unit (unit)\n    write (u, \"(3x,A,A)\")  \"Component ID        = \", char (object%basename)\n    write (u, \"(3x,A,L1)\") \"Initial component   = \", object%initial\n    write (u, \"(3x,A,I0,1x,I0,1x,I0)\") \"N (in, out, tot)    = \", &\n         object%n_in, object%n_out, object%n_tot\n    write (u, \"(3x,A)\", advance=\"no\") \"Particle content    = \"\n    if (allocated (object%prt_in)) then\n       call prt_spec_write (object%prt_in, u, advance=\"no\")\n    else\n       write (u, \"(A)\", advance=\"no\")  \"[undefined]\"\n    end if\n    write (u, \"(A)\", advance=\"no\") \" => \"\n    if (allocated (object%prt_out)) then\n       call prt_spec_write (object%prt_out, u, advance=\"no\")\n    else\n       write (u, \"(A)\", advance=\"no\")  \"[undefined]\"\n    end if\n    write (u, \"(A)\")\n    if (object%method /= \"\") then\n       write (u, \"(3x,A,A)\")  \"Method              = \", &\n            char (object%method)\n    else\n       write (u, \"(3x,A)\")  \"Method              = [undefined]\"\n    end if\n    if (allocated (object%core_def)) then\n       write (u, \"(3x,A,A)\")  \"Process variant     = \", &\n            char (object%core_def%type_string ())\n       call object%core_def%write (u)\n    else\n       write (u, \"(3x,A)\")  \"Process variant     = [undefined]\"\n    end if\n    write (u, \"(3x,A,A,A)\") \"MD5 sum (def)       = '\", object%md5sum, \"'\"\n  end subroutine process_component_def_write\n\n@ %def process_component_def_write\n@ Read the process component definition.  Allocate the process variant\ndefinition with appropriate type, matching the type name on file with\nthe provided templates.\n<<Process libraries: process component def: TBP>>=\n  procedure :: read => process_component_def_read\n<<Process libraries: procedures>>=\n  subroutine process_component_def_read (component, unit, core_def_templates)\n    class(process_component_def_t), intent(out) :: component\n    integer, intent(in) :: unit\n    type(prc_template_t), dimension(:), intent(in) :: core_def_templates\n    character(80) :: buffer\n    type(string_t) :: var_buffer, prefix, in_state, out_state\n    type(string_t) :: variant_type\n\n    read (unit, \"(A)\")  buffer\n    call strip_equation_lhs (buffer)\n    component%basename = trim (adjustl (buffer))\n\n    read (unit, \"(A)\")  buffer\n    call strip_equation_lhs (buffer)\n    read (buffer, *)  component%initial\n\n    read (unit, \"(A)\")  buffer\n    call strip_equation_lhs (buffer)\n    read (buffer, *)  component%n_in, component%n_out, component%n_tot\n\n    call get (unit, var_buffer)\n    call split (var_buffer, prefix, \"=\")   ! keeps 'in => out'\n    call split (var_buffer, prefix, \"=\")   ! actually: separator is '=>'\n\n    in_state = prefix\n    if (component%n_in > 0) then\n       call prt_spec_read (component%prt_in, in_state)\n    end if\n\n    out_state = extract (var_buffer, 2)\n    if (component%n_out > 0) then\n       call prt_spec_read (component%prt_out, out_state)\n    end if\n\n    read (unit, \"(A)\")  buffer\n    call strip_equation_lhs (buffer)\n    component%method = trim (adjustl (buffer))\n    if (component%method == \"[undefined]\") &\n         component%method = \"\"\n\n    read (unit, \"(A)\")  buffer\n    call strip_equation_lhs (buffer)\n    variant_type = trim (adjustl (buffer))\n    call allocate_core_def &\n         (core_def_templates, variant_type, component%core_def)\n    if (allocated (component%core_def)) then\n       call component%core_def%read (unit)\n    end if\n\n    read (unit, \"(A)\")  buffer\n    call strip_equation_lhs (buffer)\n    read (buffer(3:34), \"(A32)\")  component%md5sum\n\n  end subroutine process_component_def_read\n\n@ %def process_component_def_read\n@ Short account.\n<<Process libraries: process component def: TBP>>=\n  procedure :: show => process_component_def_show\n<<Process libraries: procedures>>=\n  subroutine process_component_def_show (object, unit)\n    class(process_component_def_t), intent(in) :: object\n    integer, intent(in), optional :: unit\n    integer :: u\n    u = given_output_unit (unit)\n    write (u, \"(6x,A)\", advance=\"no\")  char (object%basename)\n    if (.not. object%initial) &\n         write (u, \"('*')\", advance=\"no\")\n    write (u, \"(':',1x)\", advance=\"no\")\n    if (allocated (object%prt_in)) then\n       call prt_spec_write (object%prt_in, u, advance=\"no\")\n    else\n       write (u, \"(A)\", advance=\"no\")  \"[undefined]\"\n    end if\n    write (u, \"(A)\", advance=\"no\") \" => \"\n    if (allocated (object%prt_out)) then\n       call prt_spec_write (object%prt_out, u, advance=\"no\")\n    else\n       write (u, \"(A)\", advance=\"no\")  \"[undefined]\"\n    end if\n    if (object%method /= \"\") then\n       write (u, \"(2x,'[',A,']')\")  char (object%method)\n    else\n       write (u, *)\n    end if\n  end subroutine process_component_def_show\n\n@ %def process_component_def_show\n@ Compute the MD5 sum of a process component.  We reset the stored MD5\nsum to the empty string (so a previous value is not included in the\ncalculation), the write a temporary file and calculate the MD5 sum of\nthat file.\n\nThis implies that all data that are displayed by the [[write]] method\nbecome part of the MD5 sum calculation.\n\nThe [[model]] is not part of the object, but must be included in the MD5 sum.\nOtherwise, modifying the model and nothing else would not trigger remaking the\nprocess-component source.  Note that the model parameters may change later and\ntherefore are not incorporated.\n\nAfter the MD5 sum of the component has been computed, we communicate it to the\n[[writer]] subobject of the specific [[core_def]] component.  Although these\ntypes are abstract, the MD5-related features are valid for the abstract\ntypes.\n<<Process libraries: process component def: TBP>>=\n  procedure :: compute_md5sum => process_component_def_compute_md5sum\n<<Process libraries: procedures>>=\n  subroutine process_component_def_compute_md5sum (component, model)\n    class(process_component_def_t), intent(inout) :: component\n    class(model_data_t), intent(in), optional, target :: model\n    integer :: u\n    component%md5sum = \"\"\n    u = free_unit ()\n    open (u, status = \"scratch\", action = \"readwrite\")\n    if (present (model))  write (u, \"(A32)\")  model%get_md5sum ()\n    call component%write (u)\n    rewind (u)\n    component%md5sum = md5sum (u)\n    close (u)\n    if (allocated (component%core_def)) then\n       call component%core_def%set_md5sum (component%md5sum)\n    end if\n  end subroutine process_component_def_compute_md5sum\n\n@ %def process_component_def_compute_md5sum\n@\n<<Process libraries: process component def: TBP>>=\n  procedure :: get_def_type_string => process_component_def_get_def_type_string\n<<Process libraries: procedures>>=\n  function process_component_def_get_def_type_string (component) result (type_string)\n    type(string_t) :: type_string\n    class(process_component_def_t), intent(in) :: component\n    type_string = component%core_def%type_string ()\n  end function process_component_def_get_def_type_string\n\n@ %def process_component_def_get_def_type_string\n@ Allocate the process driver (with a suitable type) for a process\ncomponent.  For internal processes, we may set all data already at\nthis stage.\n<<Process libraries: process component def: TBP>>=\n  procedure :: allocate_driver => process_component_def_allocate_driver\n<<Process libraries: procedures>>=\n  subroutine process_component_def_allocate_driver (component, driver)\n    class(process_component_def_t), intent(in) :: component\n    class(prc_core_driver_t), intent(out), allocatable :: driver\n    if (allocated (component%core_def)) then\n       call component%core_def%allocate_driver (driver, component%basename)\n    end if\n  end subroutine process_component_def_allocate_driver\n\n@ %def process_component_def_allocate_driver\n@ Tell whether the process core needs external code.\n<<Process libraries: process component def: TBP>>=\n  procedure :: needs_code => process_component_def_needs_code\n<<Process libraries: procedures>>=\n  function process_component_def_needs_code (component) result (flag)\n    class(process_component_def_t), intent(in) :: component\n    logical :: flag\n    flag = component%core_def%needs_code ()\n  end function process_component_def_needs_code\n\n@ %def process_component_def_needs_code\n@ If there is external code, the [[core_def]] subobject should\nprovide a writer object.  This method returns a pointer to the writer.\n<<Process libraries: process component def: TBP>>=\n  procedure :: get_writer_ptr => process_component_def_get_writer_ptr\n<<Process libraries: procedures>>=\n  function process_component_def_get_writer_ptr (component) result (writer)\n    class(process_component_def_t), intent(in), target :: component\n    class(prc_writer_t), pointer :: writer\n    writer => component%core_def%writer\n  end function process_component_def_get_writer_ptr\n\n@ %def process_component_def_get_writer_ptr\n@ Return an array which holds the names of all C functions that this\nprocess component implements.\n<<Process libraries: process component def: TBP>>=\n  procedure :: get_features => process_component_def_get_features\n<<Process libraries: procedures>>=\n  function process_component_def_get_features (component) result (features)\n    class(process_component_def_t), intent(in) :: component\n    type(string_t), dimension(:), allocatable :: features\n    call component%core_def%get_features (features)\n  end function process_component_def_get_features\n\n@ %def process_component_def_get_features\n@ Assign procedure pointers in the [[driver]] component (external\nprocesses).  For internal processes, this is meaningless.\n<<Process libraries: process component def: TBP>>=\n  procedure :: connect => process_component_def_connect\n<<Process libraries: procedures>>=\n  subroutine process_component_def_connect &\n       (component, lib_driver, i, proc_driver)\n    class(process_component_def_t), intent(in) :: component\n    class(prclib_driver_t), intent(in) :: lib_driver\n    integer, intent(in) :: i\n    class(prc_core_driver_t), intent(inout) :: proc_driver\n    select type (proc_driver)\n    class is (process_driver_internal_t)\n       !!! Nothing to do\n    class default\n       call component%core_def%connect (lib_driver, i, proc_driver)\n    end select\n  end subroutine process_component_def_connect\n\n@ %def process_component_def_connect\n@ Return a pointer to the process core definition, which is of\nabstract type.\n<<Process libraries: process component def: TBP>>=\n  procedure :: get_core_def_ptr => process_component_get_core_def_ptr\n<<Process libraries: procedures>>=\n  function process_component_get_core_def_ptr (component) result (ptr)\n    class(process_component_def_t), intent(in), target :: component\n    class(prc_core_def_t), pointer :: ptr\n    ptr => component%core_def\n  end function process_component_get_core_def_ptr\n\n@ %def process_component_get_core_def_ptr\n@ Return nominal particle counts, as input by the user.\n<<Process libraries: process component def: TBP>>=\n  procedure :: get_n_in  => process_component_def_get_n_in\n  procedure :: get_n_out => process_component_def_get_n_out\n  procedure :: get_n_tot => process_component_def_get_n_tot\n<<Process libraries: procedures>>=\n  function process_component_def_get_n_in (component) result (n_in)\n    class(process_component_def_t), intent(in) :: component\n    integer :: n_in\n    n_in = component%n_in\n  end function process_component_def_get_n_in\n\n  function process_component_def_get_n_out (component) result (n_out)\n    class(process_component_def_t), intent(in) :: component\n    integer :: n_out\n    n_out = component%n_out\n  end function process_component_def_get_n_out\n\n  function process_component_def_get_n_tot (component) result (n_tot)\n    class(process_component_def_t), intent(in) :: component\n    integer :: n_tot\n    n_tot = component%n_tot\n  end function process_component_def_get_n_tot\n\n@ %def process_component_def_get_n_in\n@ %def process_component_def_get_n_out\n@ %def process_component_def_get_n_tot\n@ Allocate and return string arrays for the incoming and outgoing particles.\n<<Process libraries: process component def: TBP>>=\n  procedure :: get_prt_in => process_component_def_get_prt_in\n  procedure :: get_prt_out => process_component_def_get_prt_out\n<<Process libraries: procedures>>=\n  subroutine process_component_def_get_prt_in (component, prt)\n    class(process_component_def_t), intent(in) :: component\n    type(string_t), dimension(:), intent(out), allocatable :: prt\n    integer :: i\n    allocate (prt (component%n_in))\n    do i = 1, component%n_in\n       prt(i) = component%prt_in(i)%to_string ()\n    end do\n  end subroutine process_component_def_get_prt_in\n\n  subroutine process_component_def_get_prt_out (component, prt)\n    class(process_component_def_t), intent(in) :: component\n    type(string_t), dimension(:), intent(out), allocatable :: prt\n    integer :: i\n    allocate (prt (component%n_out))\n    do i = 1, component%n_out\n       prt(i) = component%prt_out(i)%to_string ()\n    end do\n  end subroutine process_component_def_get_prt_out\n\n@ %def process_component_def_get_prt_in\n@ %def process_component_def_get_prt_out\n@ Return the incoming and outgoing particle specifiers as-is.\n<<Process libraries: process component def: TBP>>=\n  procedure :: get_prt_spec_in => process_component_def_get_prt_spec_in\n  procedure :: get_prt_spec_out => process_component_def_get_prt_spec_out\n<<Process libraries: procedures>>=\n  function process_component_def_get_prt_spec_in (component) result (prt)\n    class(process_component_def_t), intent(in) :: component\n    type(prt_spec_t), dimension(:), allocatable :: prt\n    allocate (prt (component%n_in))\n    prt(:) = component%prt_in(:)\n  end function process_component_def_get_prt_spec_in\n\n  function process_component_def_get_prt_spec_out (component) result (prt)\n    class(process_component_def_t), intent(in) :: component\n    type(prt_spec_t), dimension(:), allocatable :: prt\n    allocate (prt (component%n_out))\n    prt(:) = component%prt_out(:)\n  end function process_component_def_get_prt_spec_out\n\n@ %def process_component_def_get_prt_spec_in\n@ %def process_component_def_get_prt_spec_out\n@ Return the combination of incoming particles as a PDG code\n<<Process libraries: process component def: TBP>>=\n  procedure :: get_pdg_in => process_component_def_get_pdg_in\n<<Process libraries: procedures>>=\n  subroutine process_component_def_get_pdg_in (component, model, pdg)\n    class(process_component_def_t), intent(in) :: component\n    class(model_data_t), intent(in), target :: model\n    integer, intent(out), dimension(:) :: pdg\n    integer :: i\n    do i = 1, size (pdg)\n       pdg(i) = model%get_pdg (component%prt_in(i)%to_string ())\n    end do\n  end subroutine process_component_def_get_pdg_in\n\n@ %def process_component_def_get_pdg_in\n@ Return the MD5 sum.\n<<Process libraries: process component def: TBP>>=\n  procedure :: get_md5sum => process_component_def_get_md5sum\n<<Process libraries: procedures>>=\n  pure function process_component_def_get_md5sum (component) result (md5sum)\n    class(process_component_def_t), intent(in) :: component\n    character(32) :: md5sum\n    md5sum = component%md5sum\n  end function process_component_def_get_md5sum\n\n@ %def process_component_def_get_md5sum\n@ Get NLO data\n<<Process libraries: process component def: TBP>>=\n  procedure :: get_nlo_type => process_component_def_get_nlo_type\n  procedure :: get_associated_born &\n       => process_component_def_get_associated_born\n  procedure :: get_associated_real_fin &\n       => process_component_def_get_associated_real_fin\n  procedure :: get_associated_real_sing &\n       => process_component_def_get_associated_real_sing\n  procedure :: get_associated_subtraction &\n       => process_component_def_get_associated_subtraction\n  procedure :: get_association_list &\n       => process_component_def_get_association_list\n  procedure :: can_be_integrated &\n       => process_component_def_can_be_integrated\n  procedure :: get_associated_real => process_component_def_get_associated_real\n<<Process libraries: procedures>>=\n  elemental function process_component_def_get_nlo_type (component) result (nlo_type)\n    integer :: nlo_type\n    class(process_component_def_t), intent(in) :: component\n    nlo_type = component%nlo_type\n  end function process_component_def_get_nlo_type\n\n  elemental function process_component_def_get_associated_born (component) result (i_born)\n    integer :: i_born\n    class(process_component_def_t), intent(in) :: component\n    i_born = component%associated_components(ASSOCIATED_BORN)\n  end function process_component_def_get_associated_born\n\n  elemental function process_component_def_get_associated_real_fin (component) result (i_rfin)\n    integer :: i_rfin\n    class(process_component_def_t), intent(in) :: component\n    i_rfin = component%associated_components(ASSOCIATED_REAL_FIN)\n  end function process_component_def_get_associated_real_fin\n\n  elemental function process_component_def_get_associated_real_sing (component) result (i_rsing)\n    integer :: i_rsing\n    class(process_component_def_t), intent(in) :: component\n    i_rsing = component%associated_components(ASSOCIATED_REAL_SING)\n  end function process_component_def_get_associated_real_sing\n\n  elemental function process_component_def_get_associated_subtraction (component) result (i_sub)\n    integer :: i_sub\n    class(process_component_def_t), intent(in) :: component\n    i_sub = component%associated_components(ASSOCIATED_SUB)\n  end function process_component_def_get_associated_subtraction\n\n  elemental function process_component_def_can_be_integrated (component) result (active)\n    logical :: active\n    class(process_component_def_t), intent(in) :: component\n    active = component%active\n  end function process_component_def_can_be_integrated\n\n  function process_component_def_get_association_list (component, i_skip_in) result (list)\n    integer, dimension(:), allocatable :: list\n    class(process_component_def_t), intent(in) :: component\n    integer, intent(in), optional :: i_skip_in\n    integer :: i, j, n, i_skip\n    logical :: valid\n    i_skip = 0; if (present (i_skip_in)) i_skip = i_skip_in\n    n = count (component%associated_components /= 0) - 1\n    if (i_skip > 0) n = n - 1\n    allocate (list (n))\n    j = 1\n    do i = 1, size(component%associated_components)\n       valid = component%associated_components(i) /= 0 &\n               .and. i /= ASSOCIATED_SUB .and. i /= i_skip\n       if (valid) then\n          list(j) = component%associated_components(i)\n          j = j + 1\n       end if\n    end do\n  end function process_component_def_get_association_list\n\n  function process_component_def_get_associated_real (component) result (i_real)\n    integer :: i_real\n    class(process_component_def_t), intent(in) :: component\n    i_real = component%associated_components(ASSOCIATED_REAL)\n  end function process_component_def_get_associated_real\n\n@ %def process_component_def_get_nlo_type, process_component_def_get_associated_born\n@ %def process_component_def_can_be_integrated\n@ %def process_component_def_get_association_list\n@ %def process_component_def_get_associated_real\n@ %def process_component_def_get_associated_real_fin\n@ %def process_component_def_get_associated_subtraction\n@\n<<Process libraries: process component def: TBP>>=\n  procedure :: get_me_method => process_component_def_get_me_method\n<<Process libraries: procedures>>=\n  elemental function process_component_def_get_me_method (component) result (method)\n    type(string_t) :: method\n    class(process_component_def_t), intent(in) :: component\n    method = component%method\n  end function process_component_def_get_me_method\n\n@ %def process_component_def_get_me_method\n@\n<<Process libraries: process component def: TBP>>=\n  procedure :: get_fixed_emitter => process_component_def_get_fixed_emitter\n<<Process libraries: procedures>>=\n  function process_component_def_get_fixed_emitter (component) result (emitter)\n     integer :: emitter\n     class(process_component_def_t), intent(in) :: component\n     emitter = component%fixed_emitter\n  end function process_component_def_get_fixed_emitter\n\n@ %def process_component_def_get_fixed_emitter\n@\n<<Process libraries: process component def: TBP>>=\n  procedure :: get_coupling_powers => process_component_def_get_coupling_powers\n<<Process libraries: procedures>>=\n  pure subroutine process_component_def_get_coupling_powers (component, alpha_power, alphas_power)\n    class(process_component_def_t), intent(in) :: component\n    integer, intent(out) :: alpha_power, alphas_power\n    alpha_power = component%alpha_power\n    alphas_power = component%alphas_power\n  end subroutine process_component_def_get_coupling_powers\n\n@ %def process_component_def_get_coupling_powers\n@\n\\subsubsection{Process definition}\nThe process component definitions are collected in a common process\ndefinition object.\n\nThe [[id]] is the ID string that the user has provided for identifying\nthis process.  It must be a string that is allowed as part of a\nFortran variable name, since it may be used for generating code.\n\nThe number [[n_in]] is 1 or 2 for a decay or scattering process,\nrespectively.  This must be identical to [[n_in]] for all components.\n\nThe initial and extra component definitions (see above) are allocated as the\n[[initial]] and [[extra]] arrays, respectively.  The latter\nare determined from the former.\n\nThe [[md5sum]] is used to verify the integrity of the configuration.\n<<Process libraries: public>>=\n  public :: process_def_t\n<<Process libraries: types>>=\n  type :: process_def_t\n     private\n     type(string_t) :: id\n     integer :: num_id = 0\n     class(model_data_t), pointer :: model => null ()\n     type(string_t) :: model_name\n     integer :: n_in  = 0\n     integer :: n_initial = 0\n     integer :: n_extra = 0\n     type(process_component_def_t), dimension(:), allocatable :: initial\n     type(process_component_def_t), dimension(:), allocatable :: extra\n     character(32) :: md5sum = \"\"\n     logical :: nlo_process = .false.\n     logical :: requires_resonances = .false.\n   contains\n   <<Process libraries: process def: TBP>>\n  end type process_def_t\n\n@ %def process_def_t\n@ Write the process definition including components:\n<<Process libraries: process def: TBP>>=\n  procedure :: write => process_def_write\n<<Process libraries: procedures>>=\n  subroutine process_def_write (object, unit)\n    class(process_def_t), intent(in) :: object\n    integer, intent(in) :: unit\n    integer :: i\n    write (unit, \"(1x,A,A,A)\") \"ID = '\", char (object%id), \"'\"\n    if (object%num_id /= 0) &\n         write (unit, \"(1x,A,I0)\")  \"ID(num) = \", object%num_id\n    select case (object%n_in)\n    case (1);  write (unit, \"(1x,A)\")  \"Decay\"\n    case (2);  write (unit, \"(1x,A)\")  \"Scattering\"\n    case default\n       write (unit, \"(1x,A)\")  \"[Undefined process]\"\n       return\n    end select\n    if (object%model_name /= \"\") then\n       write (unit, \"(1x,A,A)\")  \"Model = \", char (object%model_name)\n    else\n       write (unit, \"(1x,A)\")  \"Model = [undefined]\"\n    end if\n    write (unit, \"(1x,A,I0)\")  \"Initially defined component(s) = \", &\n         object%n_initial\n    write (unit, \"(1x,A,I0)\")  \"Extra generated component(s)   = \", &\n         object%n_extra\n    if (object%requires_resonances) then\n       ! This line has to matched with the reader below!\n       write (unit, \"(1x,A,I0)\")  \"Resonant subprocesses required\"\n    end if\n    write (unit, \"(1x,A,A,A)\") \"MD5 sum   = '\", object%md5sum, \"'\"\n    if (allocated (object%initial)) then\n       do i = 1, size (object%initial)\n          write (unit, \"(1x,A,I0)\")  \"Component #\", i\n          call object%initial(i)%write (unit)\n       end do\n    end if\n    if (allocated (object%extra)) then\n       do i = 1, size (object%extra)\n          write (unit, \"(1x,A,I0)\")  \"Component #\", object%n_initial + i\n          call object%extra(i)%write (unit)\n       end do\n    end if\n  end subroutine process_def_write\n\n@ %def process_def_write\n@ Read the process definition including components.\n<<Process libraries: process def: TBP>>=\n  procedure :: read => process_def_read\n<<Process libraries: procedures>>=\n  subroutine process_def_read (object, unit, core_def_templates)\n    class(process_def_t), intent(out) :: object\n    integer, intent(in) :: unit\n    type(prc_template_t), dimension(:), intent(in) :: core_def_templates\n    integer :: i, i1, i2\n    character(80) :: buffer, ref\n    read (unit, \"(A)\")  buffer\n    call strip_equation_lhs (buffer)\n    i1 = scan (buffer, \"'\")\n    i2 = scan (buffer, \"'\", back=.true.)\n    if (i2 > i1) then\n       object%id = buffer(i1+1:i2-1)\n    else\n       object%id = \"\"\n    end if\n\n    read (unit, \"(A)\")  buffer\n    select case (buffer(2:11))\n    case (\"Decay     \"); object%n_in = 1\n    case (\"Scattering\"); object%n_in = 2\n    case default\n       return\n    end select\n\n    read (unit, \"(A)\")  buffer\n    call strip_equation_lhs (buffer)\n    object%model_name = trim (adjustl (buffer))\n    if (object%model_name == \"[undefined]\")  object%model_name = \"\"\n\n    read (unit, \"(A)\")  buffer\n    call strip_equation_lhs (buffer)\n    read (buffer, *)  object%n_initial\n\n    read (unit, \"(A)\")  buffer\n    call strip_equation_lhs (buffer)\n    read (buffer, *)  object%n_extra\n\n    read (unit, \"(A)\")  buffer\n    if (buffer(1:9) == \" Resonant\") then\n       object%requires_resonances = .true.\n       read (unit, \"(A)\")  buffer\n    else\n       object%requires_resonances = .false.\n    end if\n\n    call strip_equation_lhs (buffer)\n    read (buffer(3:34), \"(A32)\")  object%md5sum\n\n    if (object%n_initial > 0) then\n       allocate (object%initial (object%n_initial))\n       do i = 1, object%n_initial\n          read (unit, \"(A)\")  buffer\n          write (ref, \"(1x,A,I0)\")  \"Component #\", i\n          if (buffer /= ref)  return                ! Wrong component header\n          call object%initial(i)%read (unit, core_def_templates)\n       end do\n    end if\n\n  end subroutine process_def_read\n\n@ %def process_def_read\n@ Short account.\n<<Process libraries: process def: TBP>>=\n  procedure :: show => process_def_show\n<<Process libraries: procedures>>=\n  subroutine process_def_show (object, unit)\n    class(process_def_t), intent(in) :: object\n    integer, intent(in) :: unit\n    integer :: i\n    write (unit, \"(4x,A)\", advance=\"no\") char (object%id)\n    if (object%num_id /= 0) &\n         write (unit, \"(1x,'(',I0,')')\", advance=\"no\")  object%num_id\n    if (object%model_name /= \"\") &\n         write (unit, \"(1x,'[',A,']')\", advance=\"no\")  char (object%model_name)\n    if (object%requires_resonances) then\n       write (unit, \"(1x,A)\", advance=\"no\")  \"[+ resonant subprocesses]\"\n    end if\n    write (unit, *)\n    if (allocated (object%initial)) then\n       do i = 1, size (object%initial)\n          call object%initial(i)%show (unit)\n       end do\n    end if\n    if (allocated (object%extra)) then\n       do i = 1, size (object%extra)\n          call object%extra(i)%show (unit)\n       end do\n    end if\n  end subroutine process_def_show\n\n@ %def process_def_show\n@ Initialize an entry (initialize the process definition inside).  We\nallocate the 'initial' set of components.  Extra components remain\nunallocated.\n\nThe model should be present as a pointer.  This allows us to retrieve the\nmodel's MD5 sum.  However, for various tests it is sufficient to have the\nname.\n\nWe create the basenames for the process components by appending a\nsuffix which we increment for each component.\n<<Process libraries: process def: TBP>>=\n  procedure :: init => process_def_init\n<<Process libraries: procedures>>=\n  subroutine process_def_init (def, id, &\n       model, model_name, n_in, n_components, num_id, &\n       nlo_process, requires_resonances)\n    class(process_def_t), intent(out) :: def\n    type(string_t), intent(in), optional :: id\n    class(model_data_t), intent(in), optional, target :: model\n    type(string_t), intent(in), optional :: model_name\n    integer, intent(in), optional :: n_in\n    integer, intent(in), optional :: n_components\n    integer, intent(in), optional :: num_id\n    logical, intent(in), optional :: nlo_process\n    logical, intent(in), optional :: requires_resonances\n    character(16) :: suffix\n    integer :: i\n    if (present (id)) then\n       def%id = id\n    else\n       def%id = \"\"\n    end if\n    if (present (num_id)) then\n       def%num_id = num_id\n    end if\n    if (present (model)) then\n       def%model => model\n       def%model_name = model%get_name ()\n    else\n       def%model => null ()\n       if (present (model_name)) then\n          def%model_name = model_name\n       else\n          def%model_name = \"\"\n       end if\n    end if\n    if (present (n_in))  def%n_in = n_in\n    if (present (n_components)) then\n       def%n_initial = n_components\n       allocate (def%initial (n_components))\n    end if\n    if (present (nlo_process)) then\n       def%nlo_process = nlo_process\n    end if\n    if (present (requires_resonances)) then\n       def%requires_resonances = requires_resonances\n    end if\n    def%initial%initial = .true.\n    def%initial%method     = \"\"\n    do i = 1, def%n_initial\n       write (suffix, \"(A,I0)\")  \"_i\", i\n       def%initial(i)%basename = def%id // trim (suffix)\n    end do\n    def%initial%description = \"\"\n  end subroutine process_def_init\n\n@ %def process_def_init\n@ Explicitly set the model name (for unit test).\n<<Process libraries: process def: TBP>>=\n  procedure :: set_model_name => process_def_set_model_name\n<<Process libraries: procedures>>=\n  subroutine process_def_set_model_name (def, model_name)\n    class(process_def_t), intent(inout) :: def\n    type(string_t), intent(in) :: model_name\n    def%model_name = model_name\n  end subroutine process_def_set_model_name\n\n@ %def process_def_set_model_name\n@ Initialize an initial component.  The particle content\nmust be specified.  The process core block is not (yet) allocated.\n\nWe assume that the particle arrays match the [[n_in]] and\n[[n_out]] values in size.  The model is referred to by name; it is\nidentified as an existing model later.  The index [[i]] must refer to\nan existing element of the component array.\n\nData specific for the process core of a component are imported as\nthe [[core_def]] argument.  We should allocate an object of class\n[[prc_core_def_t]] with the appropriate specific type, fill it,\nand transfer it to the process component definition here.  The\nallocation is moved, so the original allocated object is returned empty.\n<<Process libraries: process def: TBP>>=\n  procedure :: import_component => process_def_import_component\n<<Process libraries: procedures>>=\n  subroutine process_def_import_component (def, &\n       i, n_out, prt_in, prt_out, method, variant, &\n       nlo_type, can_be_integrated)\n    class(process_def_t), intent(inout) :: def\n    integer, intent(in) :: i\n    integer, intent(in), optional :: n_out\n    type(prt_spec_t), dimension(:), intent(in), optional :: prt_in\n    type(prt_spec_t), dimension(:), intent(in), optional :: prt_out\n    type(string_t), intent(in), optional :: method\n    integer, intent(in), optional :: nlo_type\n    logical, intent(in), optional :: can_be_integrated\n    type(string_t) :: nlo_type_string\n    class(prc_core_def_t), &\n         intent(inout), allocatable, optional :: variant\n    integer :: p\n    associate (comp => def%initial(i))\n      if (present (n_out)) then\n         comp%n_in  = def%n_in\n         comp%n_out = n_out\n         comp%n_tot = def%n_in + n_out\n      end if\n      if (present (prt_in)) then\n         allocate (comp%prt_in (size (prt_in)))\n         comp%prt_in = prt_in\n      end if\n      if (present (prt_out)) then\n         allocate (comp%prt_out (size (prt_out)))\n         comp%prt_out = prt_out\n      end if\n      if (present (method))  comp%method = method\n      if (present (variant)) then\n         call move_alloc (variant, comp%core_def)\n      end if\n      if (present (nlo_type)) then\n        comp%nlo_type = nlo_type\n      end if\n      if (present (can_be_integrated)) then\n         comp%active = can_be_integrated\n      else\n         comp%active = .true.\n      end if\n      if (allocated (comp%prt_in) .and. allocated (comp%prt_out)) then\n         associate (d => comp%description)\n           d = \"\"\n           do p = 1, size (prt_in)\n              if (p > 1)  d = d // \", \"\n              d = d // comp%prt_in(p)%to_string ()\n           end do\n           d = d // \" => \"\n           do p = 1, size (prt_out)\n              if (p > 1)  d = d // \", \"\n              d = d // comp%prt_out(p)%to_string ()\n           end do\n           if (comp%method /= \"\") then\n              if ((def%nlo_process .and. .not. comp%active) .or. &\n                   comp%nlo_type == NLO_SUBTRACTION) then\n                 d = d // \" [inactive]\"\n              else\n                 d = d // \" [\" // comp%method // \"]\"\n              end if\n           end if\n           nlo_type_string = component_status (comp%nlo_type)\n           if (nlo_type_string /= \"born\") then\n             d = d // \", [\" // nlo_type_string // \"]\"\n           end if\n         end associate\n      end if\n    end associate\n  end subroutine process_def_import_component\n\n@ %def process_def_import_component\n@\n<<Process libraries: process def: TBP>>=\n  procedure :: get_n_components => process_def_get_n_components\n<<Process libraries: procedures>>=\n  function process_def_get_n_components (def) result (n)\n    class(process_def_t), intent(in) :: def\n    integer :: n\n    n = size (def%initial)\n  end function process_def_get_n_components\n\n@ %def process_def_get_n_components\n@\n<<Process libraries: process def: TBP>>=\n  procedure :: set_fixed_emitter => process_def_set_fixed_emitter\n<<Process libraries: procedures>>=\n  subroutine process_def_set_fixed_emitter (def, i, emitter)\n    class(process_def_t), intent(inout) :: def\n    integer, intent(in) :: i, emitter\n    def%initial(i)%fixed_emitter = emitter\n  end subroutine process_def_set_fixed_emitter\n\n@ %def process_def_set_fixed_emitter\n@\n<<Process libraries: process def: TBP>>=\n  procedure :: set_coupling_powers => process_def_set_coupling_powers\n<<Process libraries: procedures>>=\n  subroutine process_def_set_coupling_powers (def, alpha_power, alphas_power)\n    class(process_def_t), intent(inout) :: def\n    integer, intent(in) :: alpha_power, alphas_power\n    def%initial(1)%alpha_power = alpha_power\n    def%initial(1)%alphas_power = alphas_power\n  end subroutine process_def_set_coupling_powers\n\n@ %def process_def_set_coupling_powers\n@\n<<Process libraries: process def: TBP>>=\n  procedure :: set_associated_components => &\n       process_def_set_associated_components\n<<Process libraries: procedures>>=\n  subroutine process_def_set_associated_components (def, i, &\n       i_list, remnant, real_finite, mismatch)\n    class(process_def_t), intent(inout) :: def\n    logical, intent(in) :: remnant, real_finite, mismatch\n    integer, intent(in) :: i\n    integer, dimension(:), intent(in) :: i_list\n    integer :: add_index\n    add_index = 0\n    associate (comp => def%initial(i)%associated_components)\n       comp(ASSOCIATED_BORN) = i_list(1)\n       comp(ASSOCIATED_REAL) = i_list(2)\n       comp(ASSOCIATED_VIRT) = i_list(3)\n       comp(ASSOCIATED_SUB) = i_list(4)\n       if (remnant) then\n          comp(ASSOCIATED_PDF) = i_list(5)\n          add_index = add_index + 1\n       end if\n       if (real_finite) then\n          comp(ASSOCIATED_REAL_FIN) = i_list(5+add_index)\n          add_index = add_index + 1\n       end if\n       if (mismatch) then\n          !!! incomplete\n       end if\n    end associate\n  end subroutine process_def_set_associated_components\n\n@ %def process_def_set_associated_components\n@\nCompute the MD5 sum for this process definition.  We compute the MD5\nsums for all components individually, than concatenate a string of\nthose and compute the MD5 sum of this string.  We also include the\nmodel name.  All other data part of the component definitions.\n<<Process libraries: process def: TBP>>=\n  procedure :: compute_md5sum => process_def_compute_md5sum\n<<Process libraries: procedures>>=\n  subroutine process_def_compute_md5sum (def, model)\n    class(process_def_t), intent(inout) :: def\n    class(model_data_t), intent(in), optional, target :: model\n    integer :: i\n    type(string_t) :: buffer\n    buffer = def%model_name\n    do i = 1, def%n_initial\n       call def%initial(i)%compute_md5sum (model)\n       buffer = buffer // def%initial(i)%md5sum\n    end do\n    do i = 1, def%n_extra\n       call def%extra(i)%compute_md5sum (model)\n       buffer = buffer // def%initial(i)%md5sum\n    end do\n    def%md5sum = md5sum (char (buffer))\n  end subroutine process_def_compute_md5sum\n\n@ %def process_def_compute_md5sum\n@ Return the MD5 sum of the process or of a process component.\n<<Process libraries: process def: TBP>>=\n  procedure :: get_md5sum => process_def_get_md5sum\n<<Process libraries: procedures>>=\n  function process_def_get_md5sum (def, i_component) result (md5sum)\n    class(process_def_t), intent(in) :: def\n    integer, intent(in), optional :: i_component\n    character(32) :: md5sum\n    if (present (i_component)) then\n       md5sum = def%initial(i_component)%md5sum\n    else\n       md5sum = def%md5sum\n    end if\n  end function process_def_get_md5sum\n\n@ %def process_def_get_md5sum\n@ Return a pointer to the definition of a particular component (for\ntest purposes).\n<<Process libraries: process def: TBP>>=\n  procedure :: get_core_def_ptr => process_def_get_core_def_ptr\n<<Process libraries: procedures>>=\n  function process_def_get_core_def_ptr (def, i_component) result (ptr)\n    class(process_def_t), intent(in), target :: def\n    integer, intent(in) :: i_component\n    class(prc_core_def_t), pointer :: ptr\n    ptr => def%initial(i_component)%get_core_def_ptr ()\n  end function process_def_get_core_def_ptr\n\n@ %def process_def_get_core_def_ptr\n@\nThis query tells whether a specific process component relies on\nexternal code.  This includes all traditional WHIZARD matrix elements\nwhich rely on \\oMega\\ for code generation.  Other process components\n(trivial decays, subtraction terms) do not require external code.\n\nNOTE: Implemented only for initial component.\n\nThe query is passed to the process component.\n<<Process libraries: process def: TBP>>=\n  procedure :: needs_code => process_def_needs_code\n<<Process libraries: procedures>>=\n  function process_def_needs_code (def, i_component) result (flag)\n    class(process_def_t), intent(in) :: def\n    integer, intent(in) :: i_component\n    logical :: flag\n    flag = def%initial(i_component)%needs_code ()\n  end function process_def_needs_code\n\n@ %def process_def_needs_code\n@ Return the first entry for the incoming particle(s), PDG code, of\nthis process.\n<<Process libraries: process def: TBP>>=\n  procedure :: get_pdg_in_1 => process_def_get_pdg_in_1\n<<Process libraries: procedures>>=\n  subroutine process_def_get_pdg_in_1 (def, pdg)\n    class(process_def_t), intent(in), target :: def\n    integer, dimension(:), intent(out) :: pdg\n    call def%initial(1)%get_pdg_in (def%model, pdg)\n  end subroutine process_def_get_pdg_in_1\n\n@ %def process_def_get_pdg_in_1\n@\n<<Process libraries: process def: TBP>>=\n  procedure :: is_nlo => process_def_is_nlo\n<<Process libraries: procedures>>=\n  elemental function process_def_is_nlo (def) result (flag)\n    logical :: flag\n    class(process_def_t), intent(in) :: def\n    flag = def%nlo_process\n  end function process_def_is_nlo\n\n@ %def process_def_is_nlo\n@\n<<Process libraries: process def: TBP>>=\n  procedure :: get_nlo_type => process_def_get_nlo_type\n<<Process libraries: procedures>>=\n  elemental function process_def_get_nlo_type (def, i_component) result (nlo_type)\n    integer :: nlo_type\n    class(process_def_t), intent(in) :: def\n    integer, intent(in) :: i_component\n    nlo_type = def%initial(i_component)%nlo_type\n  end function process_def_get_nlo_type\n\n@ %def process_def_get_nlo_type\n@ Number of incoming particles, common to all components.\n<<Process libraries: process def: TBP>>=\n  procedure :: get_n_in => process_def_get_n_in\n<<Process libraries: procedures>>=\n  function process_def_get_n_in (def) result (n_in)\n    class(process_def_t), intent(in) :: def\n    integer :: n_in\n    n_in = def%n_in\n  end function process_def_get_n_in\n\n@ %def process_def_get_n_in\n@ Pointer to a particular component definition record.\n<<Process libraries: process def: TBP>>=\n  procedure :: get_component_def_ptr => process_def_get_component_def_ptr\n<<Process libraries: procedures>>=\n  function process_def_get_component_def_ptr (def, i) result (component)\n    type(process_component_def_t), pointer :: component\n    class(process_def_t), intent(in), target :: def\n    integer, intent(in) :: i\n    if (i <= def%n_initial) then\n       component => def%initial(i)\n    else\n       component => null ()\n    end if\n  end function process_def_get_component_def_ptr\n\n@ %def process_def_get_component_def_ptr\n@\n\\subsubsection{Process definition list}\nA list of process definitions is the starting point for creating a\nprocess library.  The list is built when reading the user input.  When\nreading an existing process library, the list is used for\ncross-checking and updating the configuration.\n\nWe need a type for the list entry.  The simplest way is to extend the\nprocess definition type, so all methods apply to the process\ndefinition directly.\n<<Process libraries: public>>=\n  public :: process_def_entry_t\n<<Process libraries: types>>=\n  type, extends (process_def_t) :: process_def_entry_t\n     private\n     type(process_def_entry_t), pointer :: next => null ()\n  end type process_def_entry_t\n\n@ %def process_def_entry_t\n@ This is the type for the list itself.\n<<Process libraries: public>>=\n  public :: process_def_list_t\n<<Process libraries: types>>=\n  type :: process_def_list_t\n     private\n     type(process_def_entry_t), pointer :: first => null ()\n     type(process_def_entry_t), pointer :: last => null ()\n   contains\n   <<Process libraries: process def list: TBP>>\n  end type process_def_list_t\n\n@ %def process_def_list_t\n@ The deallocates the list iteratively.  We assume that the list\nentries do not need finalization themselves.\n<<Process libraries: process def list: TBP>>=\n  procedure :: final => process_def_list_final\n<<Process libraries: procedures>>=\n  subroutine process_def_list_final (list)\n    class(process_def_list_t), intent(inout) :: list\n    type(process_def_entry_t), pointer :: current\n    nullify (list%last)\n    do while (associated (list%first))\n       current => list%first\n       list%first => current%next\n       deallocate (current)\n    end do\n  end subroutine process_def_list_final\n\n@ %def process_def_list_final\n@ Write the complete list.\n<<Process libraries: process def list: TBP>>=\n  procedure :: write => process_def_list_write\n<<Process libraries: procedures>>=\n  subroutine process_def_list_write (object, unit, libpath)\n    class(process_def_list_t), intent(in) :: object\n    integer, intent(in), optional :: unit\n    logical, intent(in), optional :: libpath\n    type(process_def_entry_t), pointer :: entry\n    integer :: i, u\n    u = given_output_unit (unit)\n    if (associated (object%first)) then\n       i = 1\n       entry => object%first\n       do while (associated (entry))\n          write (u, \"(1x,A,I0,A)\")  \"Process #\", i, \":\"\n          call entry%write (u)\n          i = i + 1\n          entry => entry%next\n          if (associated (entry))  write (u, *)\n       end do\n    else\n       write (u, \"(1x,A)\")  \"Process definition list: [empty]\"\n    end if\n  end subroutine process_def_list_write\n\n@ %def process_def_list_write\n@ Short account.\n<<Process libraries: process def list: TBP>>=\n  procedure :: show => process_def_list_show\n<<Process libraries: procedures>>=\n  subroutine process_def_list_show (object, unit)\n    class(process_def_list_t), intent(in) :: object\n    integer, intent(in), optional :: unit\n    type(process_def_entry_t), pointer :: entry\n    integer :: u\n    u = given_output_unit (unit)\n    if (associated (object%first)) then\n       write (u, \"(2x,A)\")  \"Processes:\"\n       entry => object%first\n       do while (associated (entry))\n          call entry%show (u)\n          entry => entry%next\n       end do\n    else\n       write (u, \"(2x,A)\")  \"Processes: [empty]\"\n    end if\n  end subroutine process_def_list_show\n\n@ %def process_def_list_show\n@ Read the complete list.  We need an array of templates for the\ncomponent subobjects of abstract [[prc_core_t]] type, to\nallocate them with the correct specific type.\n\nNOTE: Error handling is missing.  Reading will just be aborted on\nerror, or an I/O error occurs.\n<<Process libraries: process def list: TBP>>=\n  procedure :: read => process_def_list_read\n<<Process libraries: procedures>>=\n  subroutine process_def_list_read (object, unit, core_def_templates)\n    class(process_def_list_t), intent(out) :: object\n    integer, intent(in) :: unit\n    type(prc_template_t), dimension(:), intent(in) :: core_def_templates\n    type(process_def_entry_t), pointer :: entry\n    character(80) :: buffer, ref\n    integer :: i\n    read (unit, \"(A)\")  buffer\n    write (ref, \"(1x,A)\")  \"Process definition list: [empty]\"\n    if (buffer == ref)  return         ! OK: empty library\n    backspace (unit)\n    READ_ENTRIES: do i = 1, huge (0)\n       if (i > 1) read (unit, *, end=1)\n       read (unit, \"(A)\")  buffer\n\n       write (ref, \"(1x,A,I0,A)\")  \"Process #\", i, \":\"\n       if (buffer /= ref)  return      ! Wrong process header: done.\n       allocate (entry)\n       call entry%read (unit, core_def_templates)\n       call object%append (entry)\n    end do READ_ENTRIES\n1   continue                           ! EOF: done\n  end subroutine process_def_list_read\n\n@ %def process_def_list_read\n@ Append an entry to the list.  The entry should be allocated as a\npointer, and the pointer allocation is transferred.  The original\npointer is returned null.\n<<Process libraries: process def list: TBP>>=\n  procedure :: append => process_def_list_append\n<<Process libraries: procedures>>=\n  subroutine process_def_list_append (list, entry)\n    class(process_def_list_t), intent(inout) :: list\n    type(process_def_entry_t), intent(inout), pointer :: entry\n    if (list%contains (entry%id)) then\n       call msg_fatal (\"Recording process: '\" // char (entry%id) &\n            // \"' has already been defined\")\n    end if\n    if (associated (list%first)) then\n       list%last%next => entry\n    else\n       list%first => entry\n    end if\n    list%last => entry\n    entry => null ()\n  end subroutine process_def_list_append\n\n@ %def process_def_list_append\n@\n\\subsubsection{Probe the process definition list}\nReturn the number of processes supported by the library.\n<<Process libraries: process def list: TBP>>=\n  procedure :: get_n_processes => process_def_list_get_n_processes\n<<Process libraries: procedures>>=\n  function process_def_list_get_n_processes (list) result (n)\n    integer :: n\n    class(process_def_list_t), intent(in) :: list\n    type(process_def_entry_t), pointer :: current\n    n = 0\n    current => list%first\n    do while (associated (current))\n       n = n + 1\n       current => current%next\n    end do\n  end function process_def_list_get_n_processes\n\n@ %def process_def_list_get_n_processes\n@ Allocate an array with the process IDs supported by the library.\n<<Process libraries: process def list: TBP>>=\n  procedure :: get_process_id_list => process_def_list_get_process_id_list\n<<Process libraries: procedures>>=\n  subroutine process_def_list_get_process_id_list (list, id)\n    class(process_def_list_t), intent(in) :: list\n    type(string_t), dimension(:), allocatable, intent(out) :: id\n    type(process_def_entry_t), pointer :: current\n    integer :: i\n    allocate (id (list%get_n_processes ()))\n    i = 0\n    current => list%first\n    do while (associated (current))\n       i = i + 1\n       id(i) = current%id\n       current => current%next\n    end do\n  end subroutine process_def_list_get_process_id_list\n\n@ %def process_def_list_get_process_id_list\n@ Return just the processes which require resonant subprocesses.\n<<Process libraries: process def list: TBP>>=\n  procedure :: get_process_id_req_resonant => &\n       process_def_list_get_process_id_req_resonant\n<<Process libraries: procedures>>=\n  subroutine process_def_list_get_process_id_req_resonant (list, id)\n    class(process_def_list_t), intent(in) :: list\n    type(string_t), dimension(:), allocatable, intent(out) :: id\n    type(process_def_entry_t), pointer :: current\n    integer :: i\n    allocate (id (list%get_n_processes ()))\n    i = 0\n    current => list%first\n    do while (associated (current))\n       if (current%requires_resonances) then\n          i = i + 1\n          id(i) = current%id\n       end if\n       current => current%next\n    end do\n    id = id(1:i)\n  end subroutine process_def_list_get_process_id_req_resonant\n\n@ %def process_def_list_get_process_id_list\n@ Return a pointer to a particular process entry.\n<<Process libraries: process def list: TBP>>=\n  procedure :: get_process_def_ptr => process_def_list_get_process_def_ptr\n<<Process libraries: procedures>>=\n  function process_def_list_get_process_def_ptr (list, id) result (entry)\n    type(process_def_entry_t), pointer :: entry\n    class(process_def_list_t), intent(in) :: list\n    type(string_t), intent(in) :: id\n    type(process_def_entry_t), pointer :: current\n    current => list%first\n    do while (associated (current))\n       if (id == current%id)  exit\n       current => current%next\n    end do\n    entry => current\n  end function process_def_list_get_process_def_ptr\n\n@ %def process_def_list_get_process_def_ptr  \n@ Return true if a given process is in the library.\n<<Process libraries: process def list: TBP>>=\n  procedure :: contains => process_def_list_contains\n<<Process libraries: procedures>>=\n  function process_def_list_contains (list, id) result (flag)\n    logical :: flag\n    class(process_def_list_t), intent(in) :: list\n    type(string_t), intent(in) :: id\n    type(process_def_entry_t), pointer :: current\n    current => list%get_process_def_ptr (id)\n    flag = associated (current)\n  end function process_def_list_contains\n\n@ %def process_def_list_contains\n@ Return the index of the entry that corresponds to a given process.\n<<Process libraries: process def list: TBP>>=\n  procedure :: get_entry_index => process_def_list_get_entry_index\n<<Process libraries: procedures>>=\n  function process_def_list_get_entry_index (list, id) result (n)\n    integer :: n\n    class(process_def_list_t), intent(in) :: list\n    type(string_t), intent(in) :: id\n    type(process_def_entry_t), pointer :: current\n    n = 0\n    current => list%first\n    do while (associated (current))\n       n = n + 1\n       if (id == current%id) then\n          return\n       end if\n       current => current%next\n    end do\n    n = 0\n  end function process_def_list_get_entry_index\n\n@ %def process_def_list_get_entry_index\n@ Return the numerical ID for a process.\n<<Process libraries: process def list: TBP>>=\n  procedure :: get_num_id => process_def_list_get_num_id\n<<Process libraries: procedures>>=\n  function process_def_list_get_num_id (list, id) result (num_id)\n    integer :: num_id\n    class(process_def_list_t), intent(in) :: list\n    type(string_t), intent(in) :: id\n    type(process_def_entry_t), pointer :: current\n    current => list%get_process_def_ptr (id)\n    if (associated (current)) then\n       num_id = current%num_id\n    else\n       num_id = 0\n    end if\n  end function process_def_list_get_num_id\n\n@ %def process_def_list_get_num_id\n@ Return the model name for a given process in the library.\n<<Process libraries: process def list: TBP>>=\n  procedure :: get_model_name => process_def_list_get_model_name\n<<Process libraries: procedures>>=\n  function process_def_list_get_model_name (list, id) result (model_name)\n    type(string_t) :: model_name\n    class(process_def_list_t), intent(in) :: list\n    type(string_t), intent(in) :: id\n    type(process_def_entry_t), pointer :: current\n    current => list%get_process_def_ptr (id)\n    if (associated (current)) then\n       model_name = current%model_name\n    else\n       model_name = \"\"\n    end if\n  end function process_def_list_get_model_name\n\n@ %def process_def_list_get_model_name\n@ Return the number of incoming particles of a given process in the library.\nThis tells us whether the process is a decay or a scattering.\n<<Process libraries: process def list: TBP>>=\n  procedure :: get_n_in => process_def_list_get_n_in\n<<Process libraries: procedures>>=\n  function process_def_list_get_n_in (list, id) result (n)\n    integer :: n\n    class(process_def_list_t), intent(in) :: list\n    type(string_t), intent(in) :: id\n    type(process_def_entry_t), pointer :: current\n    current => list%get_process_def_ptr (id)\n    if (associated (current)) then\n       n = current%n_in\n    else\n       n = 0\n    end if\n  end function process_def_list_get_n_in\n\n@ %def process_def_list_get_n_in\n@ Return the incoming particle pdg codesnumber of incoming particles\nof a given process in the library.  If there is a PDG array, return\nonly the first code for each beam.  This serves as a quick way\nfor (re)constructing beam properties.\n<<Process libraries: process def list: TBP>>=\n  procedure :: get_pdg_in_1 => process_def_list_get_pdg_in_1\n<<Process libraries: procedures>>=\n  subroutine process_def_list_get_pdg_in_1 (list, id, pdg)\n    class(process_def_list_t), intent(in) :: list\n    type(string_t), intent(in) :: id\n    integer, dimension(:), intent(out) :: pdg\n    type(process_def_entry_t), pointer :: current\n    current => list%get_process_def_ptr (id)\n    if (associated (current)) then\n       call current%get_pdg_in_1 (pdg)\n    else\n       pdg = 0\n    end if\n  end subroutine process_def_list_get_pdg_in_1\n\n@ %def process_def_list_get_pdg_in_1\n@ Return the list of component IDs of a given process in the library.\n<<Process libraries: process def list: TBP>>=\n  procedure :: get_component_list => process_def_list_get_component_list\n<<Process libraries: procedures>>=\n  subroutine process_def_list_get_component_list (list, id, cid)\n    class(process_def_list_t), intent(in) :: list\n    type(string_t), intent(in) :: id\n    type(string_t), dimension(:), allocatable, intent(out) :: cid\n    type(process_def_entry_t), pointer :: current\n    integer :: i, n\n    current => list%get_process_def_ptr (id)\n    if (associated (current)) then\n       allocate (cid (current%n_initial + current%n_extra))\n       do i = 1, current%n_initial\n          cid(i) = current%initial(i)%basename\n       end do\n       n = current%n_initial\n       do i = 1, current%n_extra\n          cid(n + i) = current%extra(i)%basename\n       end do\n    end if\n  end subroutine process_def_list_get_component_list\n\n@ %def process_def_list_get_component_list\n@ Return the list of component description strings for a given process\nin the library.\n<<Process libraries: process def list: TBP>>=\n  procedure :: get_component_description_list => &\n       process_def_list_get_component_description_list\n<<Process libraries: procedures>>=\n  subroutine process_def_list_get_component_description_list &\n       (list, id, description)\n    class(process_def_list_t), intent(in) :: list\n    type(string_t), intent(in) :: id\n    type(string_t), dimension(:), allocatable, intent(out) :: description\n    type(process_def_entry_t), pointer :: current\n    integer :: i, n\n    current => list%get_process_def_ptr (id)\n    if (associated (current)) then\n       allocate (description (current%n_initial + current%n_extra))\n       do i = 1, current%n_initial\n          description(i) = current%initial(i)%description\n       end do\n       n = current%n_initial\n       do i = 1, current%n_extra\n          description(n + i) = current%extra(i)%description\n       end do\n    end if\n  end subroutine process_def_list_get_component_description_list\n\n@ %def process_def_list_get_component_description_list\n@ Return whether the entry requires construction of a resonanct\nsubprocess set.\n<<Process libraries: process def list: TBP>>=\n  procedure :: req_resonant => process_def_list_req_resonant\n<<Process libraries: procedures>>=\n  function process_def_list_req_resonant (list, id) result (flag)\n    class(process_def_list_t), intent(in) :: list\n    type(string_t), intent(in) :: id\n    logical :: flag\n    type(process_def_entry_t), pointer :: current\n    current => list%get_process_def_ptr (id)\n    if (associated (current)) then\n       flag = current%requires_resonances\n    else\n       flag = .false.\n    end if\n  end function process_def_list_req_resonant\n\n@ %def process_def_list_req_resonant\n@\n\\subsection{Process library}\nThe process library object is the interface between the process\ndefinition data, as provided by the user, generated or linked process\ncode on file, and the process run data that reference the process\ncode.\n\n\\subsubsection{Process library entry}\nFor each process component that is part of the library, there is a\nseparate library entry ([[process_library_entry_t]].  The library\nentry connects a process definition with the specific code (if any) in\nthe compiled driver library.\n\nThe [[status]] indicates how far the process has been\nprocessed by the system (definition, code generation, compilation,\nlinking).  A process with status [[STAT_LOADED]] is accessible for\ncomputing matrix elements.\n\nThe [[def]] pointer identifies the corresponding process definition.\nThe process component within that definition is identified by the\n[[i_component]] index.\n\nThe [[i_external]] index refers to the compiled library driver.  If it is zero,\nthere is no associated matrix-element code.\n\nThe [[driver]] component holds the pointers to the matrix-element\nspecific functions, in particular the matrix element function itself.\n<<Process libraries: types>>=\n  type :: process_library_entry_t\n     private\n     integer :: status = STAT_UNKNOWN\n     type(process_def_t), pointer :: def => null ()\n     integer :: i_component = 0\n     integer :: i_external = 0\n     class(prc_core_driver_t), allocatable :: driver\n   contains\n   <<Process libraries: process library entry: TBP>>\n  end type process_library_entry_t\n\n@ %def process_library_entry_t\n@ Here are the available status codes.  An entry starts with\n[[UNKNOWN]] status.  Once the association with a valid process\ndefinition is established, the status becomes [[CONFIGURED]].\nIf matrix element source code is to be generated by the system or\nprovided from elsewhere, [[CODE_GENERATED]] indicates that this is\ndone.  The [[COMPILED]] status is next, it also applies to\nprocesses which are accessed as precompiled binaries.  Finally, the\nlibrary is linked and process pointers are set; this is marked as\n[[LOADED]].\n\nFor a process library, the initial status is [[OPEN]], since process\ndefinitions may be added.  After configuration, the process content is fixed\nand the status becomes [[CONFIGURED]].  The further states are as above,\nalways referring to the lowest status among the process entries.\n<<Process libraries: parameters>>=\n  integer, parameter, public :: STAT_UNKNOWN = 0\n  integer, parameter, public :: STAT_OPEN = 1\n  integer, parameter, public :: STAT_CONFIGURED = 2\n  integer, parameter, public :: STAT_SOURCE = 3\n  integer, parameter, public :: STAT_COMPILED = 4\n  integer, parameter, public :: STAT_LINKED = 5\n  integer, parameter, public :: STAT_ACTIVE = 6\n\n  integer, parameter, public :: ASSOCIATED_BORN = 1\n  integer, parameter, public :: ASSOCIATED_REAL = 2\n  integer, parameter, public :: ASSOCIATED_VIRT = 3\n  integer, parameter, public :: ASSOCIATED_SUB = 4\n  integer, parameter, public :: ASSOCIATED_PDF = 5\n  integer, parameter, public :: ASSOCIATED_REAL_SING = 6\n  integer, parameter, public :: ASSOCIATED_REAL_FIN = 7\n  integer, parameter, public :: N_ASSOCIATED_COMPONENTS = 7\n\n@ %def STAT_UNKNOWN STAT_OPEN STAT_CONFIGURED\n@ %def STAT_SOURCE STAT_COMPILED STAT_LINKED STAT_ACTIVE\n@ These are the associated code letters, for output:\n<<Process libraries: parameters>>=\n  character, dimension(0:6), parameter :: STATUS_LETTER = &\n       [\"?\", \"o\", \"f\", \"s\", \"c\", \"l\", \"a\"]\n\n@ %def STATUS_LETTER\n@ This produces a condensed account of the library entry.  The status\nis indicated by a letter in brackets, then the ID and component index\nof the associated process definition, finally the library index, if available.\n<<Process libraries: process library entry: TBP>>=\n  procedure :: to_string => process_library_entry_to_string\n<<Process libraries: procedures>>=\n  function process_library_entry_to_string (object) result (string)\n    type(string_t) :: string\n    class(process_library_entry_t), intent(in) :: object\n    character(32) :: buffer\n    string = \"[\" // STATUS_LETTER(object%status) // \"]\"\n    select case (object%status)\n    case (STAT_UNKNOWN)\n    case default\n       if (associated (object%def)) then\n          write (buffer, \"(I0)\")  object%i_component\n          string = string // \" \" // object%def%id // \".\" // trim (buffer)\n       end if\n       if (object%i_external /= 0) then\n          write (buffer, \"(I0)\")  object%i_external\n          string = string // \" = ext:\" // trim (buffer)\n       else\n          string = string // \" = int\"\n       end if\n       if (allocated (object%driver)) then\n          string = string // \" (\" // object%driver%type_name () // \")\"\n       end if\n    end select\n  end function process_library_entry_to_string\n\n@ %def process_library_entry_to_string\n@ Initialize with data.  Used for the unit tests.\n<<Process libraries: process library entry: TBP>>=\n  procedure :: init => process_library_entry_init\n<<Process libraries: procedures>>=\n  subroutine process_library_entry_init (object, &\n       status, def, i_component, i_external, driver_template)\n    class(process_library_entry_t), intent(out) :: object\n    integer, intent(in) :: status\n    type(process_def_t), target, intent(in) :: def\n    integer, intent(in) :: i_component\n    integer, intent(in) :: i_external\n    class(prc_core_driver_t), intent(inout), allocatable, optional &\n         :: driver_template\n    object%status = status\n    object%def => def\n    object%i_component = i_component\n    object%i_external = i_external\n    if (present (driver_template)) then\n       call move_alloc (driver_template, object%driver)\n    end if\n  end subroutine process_library_entry_init\n\n@ %def process_library_entry_init\n@ Assign pointers for all process-specific features.  We have to\ncombine the method from the [[core_def]] specification, the\nassigned pointers within the library driver, the index within that\ndriver, and the process driver which should receive the links.\n<<Process libraries: process library entry: TBP>>=\n  procedure :: connect => process_library_entry_connect\n<<Process libraries: procedures>>=\n  subroutine process_library_entry_connect (entry, lib_driver, i)\n    class(process_library_entry_t), intent(inout) :: entry\n    class(prclib_driver_t), intent(in) :: lib_driver\n    integer, intent(in) :: i\n    call entry%def%initial(entry%i_component)%connect &\n         (lib_driver, i, entry%driver)\n  end subroutine process_library_entry_connect\n\n@ %def process_library_entry_connect\n@\n\\subsubsection{The process library object}\nThe [[process_library_t]] type is an extension of the\n[[process_def_list_t]] type.  Thus, it automatically contains the\nprocess definition list.\n\nThe [[basename]] identifies the library generically.\n\nThe [[external]] flag is true if any process within the library needs external\ncode, so the library must correspond to an actual code library (statically or\ndynamically linked).\n\nThe [[entry]] array contains all process components that can be handled by this\nlibrary. Each entry refers to the process (component) definition and to the\nassociated external matrix element code, if there is any.\n\nThe [[driver]] object is needed only if [[external]] is true.  This object\nhandles all interactions with external matrix-element code.\n\nThe [[md5sum]] summarizes the complete [[process_def_list_t]] base\nobject.  It can be used to check if the library configuration has changed.\n<<Process libraries: public>>=\n  public :: process_library_t\n<<Process libraries: types>>=\n  type, extends (process_def_list_t) :: process_library_t\n     private\n     type(string_t) :: basename\n     integer :: n_entries = 0\n     logical :: external = .false.\n     integer :: status = STAT_UNKNOWN\n     logical :: static = .false.\n     logical :: driver_exists = .false.\n     logical :: makefile_exists = .false.\n     integer :: update_counter = 0\n     type(process_library_entry_t), dimension(:), allocatable :: entry\n     class(prclib_driver_t), allocatable :: driver\n     character(32) :: md5sum = \"\"\n   contains\n   <<Process libraries: process library: TBP>>\n  end type process_library_t\n\n@ %def process_library_t\n@ For the output, we write first the metadata and the DL access\nrecord, then the library entries in short form, and finally the\nprocess definition list which is the base object.\n\nDon't write the MD5 sum since this is used to generate it.\n<<Process libraries: process library: TBP>>=\n  procedure :: write => process_library_write\n<<Process libraries: procedures>>=\n  subroutine process_library_write (object, unit, libpath)\n    class(process_library_t), intent(in) :: object\n    integer, intent(in), optional :: unit\n    logical, intent(in), optional :: libpath\n    integer :: i, u\n    u = given_output_unit (unit)\n    write (u, \"(1x,A,A)\")  \"Process library: \", char (object%basename)\n    write (u, \"(3x,A,L1)\")   \"external        = \", object%external\n    write (u, \"(3x,A,L1)\")   \"makefile exists = \", object%makefile_exists\n    write (u, \"(3x,A,L1)\")   \"driver exists   = \", object%driver_exists\n    write (u, \"(3x,A,A1)\")   \"code status     = \", &\n         STATUS_LETTER (object%status)\n    write (u, *)\n    if (allocated (object%entry)) then\n       write (u, \"(1x,A)\", advance=\"no\")  \"Process library entries:\"\n       write (u, \"(1x,I0)\")  object%n_entries\n       do i = 1, size (object%entry)\n          write (u, \"(1x,A,I0,A,A)\")  \"Entry #\", i, \": \", &\n               char (object%entry(i)%to_string ())\n       end do\n       write (u, *)\n    end if\n    if (object%external) then\n       call object%driver%write (u, libpath)\n       write (u, *)\n    end if\n    call object%process_def_list_t%write (u)\n  end subroutine process_library_write\n\n@ %def process_library_write\n@ Condensed version for screen output.\n<<Process libraries: process library: TBP>>=\n  procedure :: show => process_library_show\n<<Process libraries: procedures>>=\n  subroutine process_library_show (object, unit)\n    class(process_library_t), intent(in) :: object\n    integer, intent(in), optional :: unit\n    integer :: u\n    u = given_output_unit (unit)\n    write (u, \"(A,A)\")  \"Process library: \", char (object%basename)\n    write (u, \"(2x,A,L1)\")   \"external        = \", object%external\n    if (object%static) then\n       write (u, \"(2x,A,L1)\")   \"static          = \", .true.\n    else\n       write (u, \"(2x,A,L1)\")   \"makefile exists = \", object%makefile_exists\n       write (u, \"(2x,A,L1)\")   \"driver exists   = \", object%driver_exists\n    end if\n    write (u, \"(2x,A,A1)\", advance=\"no\")   \"code status     = \"\n    select case (object%status)\n    case (STAT_UNKNOWN);    write (u, \"(A)\")  \"[unknown]\"\n    case (STAT_OPEN);       write (u, \"(A)\")  \"open\"\n    case (STAT_CONFIGURED); write (u, \"(A)\")  \"configured\"\n    case (STAT_SOURCE);     write (u, \"(A)\")  \"source code exists\"\n    case (STAT_COMPILED);   write (u, \"(A)\")  \"compiled\"\n    case (STAT_LINKED);     write (u, \"(A)\")  \"linked\"\n    case (STAT_ACTIVE);     write (u, \"(A)\")  \"active\"\n    end select\n    call object%process_def_list_t%show (u)\n  end subroutine process_library_show\n\n@ %def process_library_show\n@\nThe initializer defines just the basename.  We may now add process definitions\nto the library.\n<<Process libraries: process library: TBP>>=\n  procedure :: init => process_library_init\n<<Process libraries: procedures>>=\n  subroutine process_library_init (lib, basename)\n    class(process_library_t), intent(out) :: lib\n    type(string_t), intent(in) :: basename\n    lib%basename = basename\n    lib%status = STAT_OPEN\n    call msg_message (\"Process library '\" // char (basename) &\n         // \"': initialized\")\n  end subroutine process_library_init\n\n@ %def process_library_init\n@\nThis alternative initializer declares the library as static.  We\nshould now add process definitions to the library, but all external\nprocess code exists already.  We need the driver object, and we should\ncheck the defined processes against the stored ones.\n<<Process libraries: process library: TBP>>=\n  procedure :: init_static => process_library_init_static\n<<Process libraries: procedures>>=\n  subroutine process_library_init_static (lib, basename)\n    class(process_library_t), intent(out) :: lib\n    type(string_t), intent(in) :: basename\n    lib%basename = basename\n    lib%status = STAT_OPEN\n    lib%static = .true.\n    call msg_message (\"Static process library '\" // char (basename) &\n         // \"': initialized\")\n  end subroutine process_library_init_static\n\n@ %def process_library_init_static\n@ The [[configure]] procedure scans the allocated entries in the process\ndefinition list.  The configuration proceeds in three passes.\n\nIn the first pass, we scan the process definition list and count the\nnumber of process components and the number of components which need\nexternal code.  This is used to allocate the [[entry]] array.\n\nIn the second pass, we initialize the [[entry]] elements which connect\nprocess definitions, process driver objects, and external code.\n\nIn the third pass, we initialize the library driver object, allocating\nan entry for each external matrix element.\n\nNOTE: Currently we handle only [[initial]] process components; [[extra]]\ncomponents are ignored.\n<<Process libraries: process library: TBP>>=\n  procedure :: configure => process_library_configure\n<<Process libraries: procedures>>=\n  subroutine process_library_configure (lib, os_data)\n    class(process_library_t), intent(inout) :: lib\n    type(os_data_t), intent(in) :: os_data\n    type(process_def_entry_t), pointer :: def_entry\n    integer :: n_entries, n_external, i_entry, i_external\n    type(string_t) :: model_name\n    integer :: i_component\n\n    n_entries = 0\n    n_external = 0\n    if (allocated (lib%entry))  deallocate (lib%entry)\n\n    def_entry => lib%first\n    do while (associated (def_entry))\n       do i_component = 1, def_entry%n_initial\n          n_entries = n_entries + 1\n          if (def_entry%initial(i_component)%needs_code ()) then\n             n_external = n_external + 1\n             lib%external = .true.\n          end if\n       end do\n       def_entry => def_entry%next\n    end do\n\n    call lib%allocate_entries (n_entries)\n\n    i_entry = 0\n    i_external = 0\n    def_entry => lib%first\n    do while (associated (def_entry))\n       do i_component = 1, def_entry%n_initial\n          i_entry = i_entry + 1\n          associate (lib_entry => lib%entry(i_entry))\n            lib_entry%status = STAT_CONFIGURED\n            lib_entry%def => def_entry%process_def_t\n            lib_entry%i_component = i_component\n            if (def_entry%initial(i_component)%needs_code ()) then\n               i_external = i_external + 1\n               lib_entry%i_external = i_external\n            end if\n            call def_entry%initial(i_component)%allocate_driver &\n                 (lib_entry%driver)\n          end associate\n       end do\n       def_entry => def_entry%next\n    end do\n\n    call dispatch_prclib_driver (lib%driver, &\n         lib%basename, lib%get_modellibs_ldflags (os_data))\n    call lib%driver%init (n_external)\n    do i_entry = 1, n_entries\n       associate (lib_entry => lib%entry(i_entry))\n         i_component = lib_entry%i_component\n         model_name = lib_entry%def%model_name\n         associate (def => lib_entry%def%initial(i_component))\n           if (def%needs_code ()) then\n              call lib%driver%set_record (lib_entry%i_external, &\n                   def%basename, &\n                   model_name, &\n                   def%get_features (), def%get_writer_ptr ())\n           end if\n         end associate\n       end associate\n    end do\n\n    if (lib%static) then\n       if (lib%n_entries /= 0)  lib%entry%status = STAT_LINKED\n       lib%status = STAT_LINKED\n    else if (lib%external) then\n       where (lib%entry%i_external == 0)  lib%entry%status = STAT_LINKED\n       lib%status = STAT_CONFIGURED\n       lib%makefile_exists = .false.\n       lib%driver_exists = .false.\n    else\n       if (lib%n_entries /= 0)  lib%entry%status = STAT_LINKED\n       lib%status = STAT_LINKED\n    end if\n  end subroutine process_library_configure\n\n@ %def process_library_configure\n@ Basic setup: allocate the [[entry]] array.\n<<Process libraries: process library: TBP>>=\n  procedure :: allocate_entries => process_library_allocate_entries\n<<Process libraries: procedures>>=\n  subroutine process_library_allocate_entries (lib, n_entries)\n    class(process_library_t), intent(inout) :: lib\n    integer, intent(in) :: n_entries\n    lib%n_entries = n_entries\n    allocate (lib%entry (n_entries))\n  end subroutine process_library_allocate_entries\n\n@ %def process_library_allocate_entries\n@ Initialize an entry with data (used by unit tests).\n<<Process libraries: process library: TBP>>=\n  procedure :: init_entry => process_library_init_entry\n<<Process libraries: procedures>>=\n  subroutine process_library_init_entry (lib, i, &\n       status, def, i_component, i_external, driver_template)\n    class(process_library_t), intent(inout) :: lib\n    integer, intent(in) :: i\n    integer, intent(in) :: status\n    type(process_def_t), target, intent(in) :: def\n    integer, intent(in) :: i_component\n    integer, intent(in) :: i_external\n    class(prc_core_driver_t), intent(inout), allocatable, optional &\n         :: driver_template\n    call lib%entry(i)%init (status, def, i_component, i_external, &\n         driver_template)\n  end subroutine process_library_init_entry\n\n@ %def process_library_init_entry\n@ Compute the MD5 sum.  We concatenate the individual MD5 sums of all\nprocesses (which, in turn, are derived from the MD5 sums of their\ncomponents) and compute the MD5 sum of that.\n\nThis should be executed \\emph{after} configuration, where the driver was\ninitialized, since otherwise the MD5 sum stored in the driver would be\noverwritten.\n<<Process libraries: process library: TBP>>=\n  procedure :: compute_md5sum => process_library_compute_md5sum\n<<Process libraries: procedures>>=\n  subroutine process_library_compute_md5sum (lib, model)\n    class(process_library_t), intent(inout) :: lib\n    class(model_data_t), intent(in), optional, target :: model\n    type(process_def_entry_t), pointer :: def_entry\n    type(string_t) :: buffer\n    buffer = lib%basename\n    def_entry => lib%first\n    do while (associated (def_entry))\n       call def_entry%compute_md5sum (model)\n       buffer = buffer // def_entry%md5sum\n       def_entry => def_entry%next\n    end do\n    lib%md5sum = md5sum (char (buffer))\n    call lib%driver%set_md5sum (lib%md5sum)\n  end subroutine process_library_compute_md5sum\n\n@ %def process_library_compute_md5sum\n@ Write an appropriate makefile, if there are external processes.  Unless\n[[force]] is in effect, first check if there is already a makefile with the\ncorrect MD5 sum.  If yes, do nothing.\n\nThe [[workspace]] optional argument puts any library code in a subdirectory.\n<<Process libraries: process library: TBP>>=\n  procedure :: write_makefile => process_library_write_makefile\n<<Process libraries: procedures>>=\n  subroutine process_library_write_makefile &\n       (lib, os_data, force, verbose, testflag, workspace)\n    class(process_library_t), intent(inout) :: lib\n    type(os_data_t), intent(in) :: os_data\n    logical, intent(in) :: force, verbose\n    logical, intent(in), optional :: testflag\n    type(string_t), intent(in), optional :: workspace\n    character(32) :: md5sum_file\n    logical :: generate\n    integer :: unit\n    if (lib%external .and. .not. lib%static) then\n       generate = .true.\n       if (.not. force) then\n          md5sum_file = lib%driver%get_md5sum_makefile (workspace)\n          if (lib%md5sum == md5sum_file) then\n             call msg_message (\"Process library '\" // char (lib%basename) &\n                  // \"': keeping makefile\")\n             generate = .false.\n          end if\n       end if\n       if (generate) then\n          call msg_message (\"Process library '\" // char (lib%basename) &\n               // \"': writing makefile\")\n          unit = free_unit ()\n          open (unit, &\n               file = char (workspace_prefix (workspace) &\n               &            // lib%driver%basename // \".makefile\"), &\n               status=\"replace\", action=\"write\")\n          call lib%driver%generate_makefile (unit, os_data, verbose, testflag)\n          close (unit)\n       end if\n       lib%makefile_exists = .true.\n    end if\n  end subroutine process_library_write_makefile\n\n@ %def process_library_write_makefile\n@ \n@ Write the driver source code for the library to file, if there are\nexternal processes.\n<<Process libraries: process library: TBP>>=\n  procedure :: write_driver => process_library_write_driver\n<<Process libraries: procedures>>=\n  subroutine process_library_write_driver (lib, force, workspace)\n    class(process_library_t), intent(inout) :: lib\n    logical, intent(in) :: force\n    type(string_t), intent(in), optional :: workspace\n    character(32) :: md5sum_file\n    logical :: generate\n    integer :: unit\n    if (lib%external .and. .not. lib%static) then\n       generate = .true.\n       if (.not. force) then\n          md5sum_file = lib%driver%get_md5sum_driver (workspace)\n          if (lib%md5sum == md5sum_file) then\n             call msg_message (\"Process library '\" // char (lib%basename) &\n                  // \"': keeping driver\")\n             generate = .false.\n          end if\n       end if\n       if (generate) then\n          call msg_message (\"Process library '\" // char (lib%basename) &\n               // \"': writing driver\")\n          unit = free_unit ()\n          open (unit, & \n               file = char (workspace_prefix (workspace) &\n               &            // lib%driver%basename // \".f90\"), &\n               status=\"replace\", action=\"write\")\n          call lib%driver%generate_driver_code (unit)\n          close (unit)\n       end if\n       lib%driver_exists = .true.\n    end if\n  end subroutine process_library_write_driver\n\n@ %def process_library_write_driver\n@ Update the compilation status of an external library.\n\nStrictly speaking, this is not necessary for a one-time run, since the\nindividual library methods will update the status themselves.\nHowever, it allows us to identify compilation steps that we can skip\nbecause the file exists or is already loaded, for the whole library or\nfor particular entries.\n\nIndependently, the building process is controlled by a makefile.\nThus, previous files are reused if they are not modified by the\ncurrent compilation.\n\\begin{enumerate}\n\\item\n  If it is not already loaded, attempt to load the library.  If successful,\n  check the overall MD5 sum.  If it matches, just keep it loaded and mark as\n  ACTIVE.  If not, check the MD5 sum for all linked process components.\n  Where it matches, mark the entry as COMPILED.  Then, unload the library and\n  mark as CONFIGURED.\n\n  Thus, we can identify compiled files for all matrix elements which are\n  accessible via the previous compiled library, even if it is no longer up to\n  date.\n\\item\n  If the library is now in CONFIGURED state, look for valid source files.\n  Each entry that is just in CONFIGURED state will advance to SOURCE if the\n  MD5 sum matches.  Finally, advance the whole library to SOURCE if all\n  entries are at least in this condition.\n\\end{enumerate}\n<<Process libraries: process library: TBP>>=\n  procedure :: update_status => process_library_update_status\n<<Process libraries: procedures>>=\n  subroutine process_library_update_status (lib, os_data, workspace)\n    class(process_library_t), intent(inout) :: lib\n    type(os_data_t), intent(in) :: os_data\n    type(string_t), intent(in), optional :: workspace\n    character(32) :: md5sum_file\n    integer :: i, i_external, i_component\n    if (lib%external) then\n       select case (lib%status)\n       case (STAT_CONFIGURED:STAT_LINKED)\n          call lib%driver%load (os_data, noerror=.true., workspace=workspace)\n       end select\n       if (lib%driver%loaded) then\n          md5sum_file = lib%driver%get_md5sum (0)\n          if (lib%md5sum == md5sum_file) then\n             call lib%load_entries ()\n             lib%entry%status = STAT_ACTIVE\n             lib%status = STAT_ACTIVE\n             call msg_message (\"Process library '\" // char (lib%basename) &\n                  // \"': active\")\n          else\n             do i = 1, lib%n_entries\n                associate (entry => lib%entry(i))\n                  i_external = entry%i_external\n                  i_component = entry%i_component\n                  if (i_external /= 0) then\n                     md5sum_file = lib%driver%get_md5sum (i_external)\n                     if (entry%def%get_md5sum (i_component) == md5sum_file) then\n                        entry%status = STAT_COMPILED\n                     else\n                        entry%status = STAT_CONFIGURED\n                     end if\n                  end if\n                end associate\n             end do\n             call lib%driver%unload ()\n             lib%status = STAT_CONFIGURED\n          end if\n       end if\n       select case (lib%status)\n       case (STAT_CONFIGURED)\n          do i = 1, lib%n_entries\n             associate (entry => lib%entry(i))\n               i_external = entry%i_external\n               i_component = entry%i_component\n               if (i_external /= 0) then\n                  select case (entry%status)\n                  case (STAT_CONFIGURED)\n                     md5sum_file = lib%driver%get_md5sum_source &\n                          (i_external, workspace)\n                     if (entry%def%get_md5sum (i_component) == md5sum_file) then\n                        entry%status = STAT_SOURCE\n                     end if\n                  end select\n               end if\n             end associate\n          end do\n          if (all (lib%entry%status >= STAT_SOURCE)) then\n             md5sum_file = lib%driver%get_md5sum_driver (workspace)\n             if (lib%md5sum == md5sum_file) then\n                lib%status = STAT_SOURCE\n             end if\n          end if\n       end select\n    end if\n  end subroutine process_library_update_status\n\n@ %def process_library_update_status\n@\nThis procedure triggers code generation for all processes where this\nis possible.\n\nWe generate code only for external processes of status\n[[STAT_CONFIGURED]], which then advance to [[STAT_SOURCE]].  If, for a\nparticular process, the status is already advanced, we do not remove previous\nfiles, so [[make]] will consider them as up to date if they exist.  Otherwise,\nwe remove those files to force a fresh [[make]].\n\nFinally, if any source code has been generated, we need a driver file.\n<<Process libraries: process library: TBP>>=\n  procedure :: make_source => process_library_make_source\n<<Process libraries: procedures>>=\n  subroutine process_library_make_source &\n       (lib, os_data, keep_old_source, workspace)\n    class(process_library_t), intent(inout) :: lib\n    type(os_data_t), intent(in) :: os_data\n    logical, intent(in), optional :: keep_old_source\n    type(string_t), intent(in), optional :: workspace\n    logical :: keep_old\n    integer :: i, i_external\n    keep_old = .false.\n    if (present (keep_old_source))  keep_old = keep_old_source\n    if (lib%external .and. .not. lib%static) then\n       select case (lib%status)\n       case (STAT_CONFIGURED)\n          if (keep_old) then\n             call msg_message (\"Process library '\" // char (lib%basename) &\n                  // \"': keeping source code\")\n          else\n             call msg_message (\"Process library '\" // char (lib%basename) &\n                  // \"': creating source code\")\n             do i = 1, size (lib%entry)\n                associate (entry => lib%entry(i))\n                  i_external = entry%i_external\n                  if (i_external /= 0 &\n                       .and. lib%entry(i)%status == STAT_CONFIGURED) then\n                     call lib%driver%clean_proc &\n                          (i_external, os_data, workspace)\n                  end if\n                end associate\n                if (signal_is_pending ())  return\n             end do\n             call lib%driver%make_source (os_data, workspace)\n          end if\n          lib%status = STAT_SOURCE\n          where (lib%entry%i_external /= 0 &\n               .and. lib%entry%status == STAT_CONFIGURED)\n             lib%entry%status = STAT_SOURCE\n          end where\n          lib%status = STAT_SOURCE\n       end select\n    end if\n  end subroutine process_library_make_source\n\n@ %def process_library_make_source\n@ Compile the generated code and update the status codes.  Try to make\nthe sources first, just in case. This includes compiling possible \\LaTeX\nFeynman diagram files.\n<<Process libraries: process library: TBP>>=\n  procedure :: make_compile => process_library_make_compile\n<<Process libraries: procedures>>=\n  subroutine process_library_make_compile &\n       (lib, os_data, keep_old_source, workspace)\n    class(process_library_t), intent(inout) :: lib\n    type(os_data_t), intent(in) :: os_data\n    logical, intent(in), optional :: keep_old_source\n    type(string_t), intent(in), optional :: workspace\n    if (lib%external .and. .not. lib%static) then\n       select case (lib%status)\n       case (STAT_CONFIGURED)\n          call lib%make_source (os_data, keep_old_source, workspace)\n       end select\n       if (signal_is_pending ())  return\n       select case (lib%status)\n       case (STAT_SOURCE)\n          call msg_message (\"Process library '\" // char (lib%basename) &\n               // \"': compiling sources\")\n          call lib%driver%make_compile (os_data, workspace)\n          where (lib%entry%i_external /= 0 &\n               .and. lib%entry%status == STAT_SOURCE)\n             lib%entry%status = STAT_COMPILED\n          end where\n          lib%status = STAT_COMPILED\n       end select\n    end if\n  end subroutine process_library_make_compile\n\n@ %def process_library_make_compile\n@ Link the process library.  Try to compile first, just in case.\n<<Process libraries: process library: TBP>>=\n  procedure :: make_link => process_library_make_link\n<<Process libraries: procedures>>=\n  subroutine process_library_make_link &\n       (lib, os_data, keep_old_source, workspace)\n    class(process_library_t), intent(inout) :: lib\n    type(os_data_t), intent(in) :: os_data\n    logical, intent(in), optional :: keep_old_source\n    type(string_t), intent(in), optional :: workspace\n    if (lib%external .and. .not. lib%static) then\n       select case (lib%status)\n       case (STAT_CONFIGURED:STAT_SOURCE)\n          call lib%make_compile (os_data, keep_old_source, workspace)\n       end select\n       if (signal_is_pending ())  return\n       select case (lib%status)\n       case (STAT_COMPILED)\n          call msg_message (\"Process library '\" // char (lib%basename) &\n               // \"': linking\")\n          call lib%driver%make_link (os_data, workspace)\n          lib%entry%status = STAT_LINKED\n          lib%status = STAT_LINKED\n       end select\n    end if\n  end subroutine process_library_make_link\n\n@ %def process_library_make_link\n@ Load the process library, i.e., assign pointers to the library\nfunctions.\n<<Process libraries: process library: TBP>>=\n  procedure :: load => process_library_load\n<<Process libraries: procedures>>=\n  subroutine process_library_load (lib, os_data, keep_old_source, workspace)\n    class(process_library_t), intent(inout) :: lib\n    type(os_data_t), intent(in) :: os_data\n    logical, intent(in), optional :: keep_old_source\n    type(string_t), intent(in), optional :: workspace\n    select case (lib%status)\n    case (STAT_CONFIGURED:STAT_COMPILED)\n       call lib%make_link (os_data, keep_old_source, workspace)\n    end select\n    if (signal_is_pending ())  return\n    select case (lib%status)\n    case (STAT_LINKED)\n       if (lib%external) then\n          call msg_message (\"Process library '\" // char (lib%basename) &\n               // \"': loading\")\n          call lib%driver%load (os_data, workspace=workspace)\n          call lib%load_entries ()\n       end if\n       lib%entry%status = STAT_ACTIVE\n       lib%status = STAT_ACTIVE\n    end select\n  end subroutine process_library_load\n\n@ %def process_library_load\n@ This is the actual loading part for the process methods.\n<<Process libraries: process library: TBP>>=\n  procedure :: load_entries => process_library_load_entries\n<<Process libraries: procedures>>=\n  subroutine process_library_load_entries (lib)\n    class(process_library_t), intent(inout) :: lib\n    integer :: i\n    do i = 1, size (lib%entry)\n       associate (entry => lib%entry(i))\n         if (entry%i_external /= 0) then\n            call entry%connect (lib%driver, entry%i_external)\n         end if\n       end associate\n    end do\n  end subroutine process_library_load_entries\n\n@ %def process_library_load_entries\n@ Unload the library, if possible.  This reverts the status to ``linked''.\n<<Process libraries: process library: TBP>>=\n  procedure :: unload => process_library_unload\n<<Process libraries: procedures>>=\n  subroutine process_library_unload (lib)\n    class(process_library_t), intent(inout) :: lib\n    select case (lib%status)\n    case (STAT_ACTIVE)\n       if (lib%external) then\n          call msg_message (\"Process library '\" // char (lib%basename) &\n               // \"': unloading\")\n          call lib%driver%unload ()\n       end if\n       lib%entry%status = STAT_LINKED\n       lib%status = STAT_LINKED\n    end select\n  end subroutine process_library_unload\n\n@ %def process_library_unload\n@ Unload, clean all generated files and revert the library status.  If\n[[distclean]] is set, also remove the makefile and the driver source.\n<<Process libraries: process library: TBP>>=\n  procedure :: clean => process_library_clean\n<<Process libraries: procedures>>=\n  subroutine process_library_clean (lib, os_data, distclean, workspace)\n    class(process_library_t), intent(inout) :: lib\n    type(os_data_t), intent(in) :: os_data\n    logical, intent(in) :: distclean\n    type(string_t), intent(in), optional :: workspace\n    call lib%unload ()\n    if (lib%external .and. .not. lib%static) then\n       call msg_message (\"Process library '\" // char (lib%basename) &\n            // \"': removing old files\")\n       if (distclean) then\n          call lib%driver%distclean (os_data, workspace)\n       else\n          call lib%driver%clean (os_data, workspace)\n       end if\n    end if\n    where (lib%entry%i_external /= 0)\n       lib%entry%status = STAT_CONFIGURED\n    elsewhere\n       lib%entry%status = STAT_LINKED\n    end where\n    if (lib%external) then\n       lib%status = STAT_CONFIGURED\n    else\n       lib%status = STAT_LINKED\n    end if\n  end subroutine process_library_clean\n\n@ %def process_library_clean\n@ Unload and revert the library status to INITIAL.  This allows for\nappending new processes.  No files are deleted.\n<<Process libraries: process library: TBP>>=\n  procedure :: open => process_library_open\n<<Process libraries: procedures>>=\n  subroutine process_library_open (lib)\n    class(process_library_t), intent(inout) :: lib\n    select case (lib%status)\n    case (STAT_OPEN)\n    case default\n       call lib%unload ()\n       if (.not. lib%static) then\n          lib%entry%status = STAT_OPEN\n          lib%status = STAT_OPEN\n          if (lib%external)  lib%update_counter = lib%update_counter + 1\n          call msg_message (\"Process library '\" // char (lib%basename) &\n               // \"': open\")\n       else\n          call msg_error (\"Static process library '\" // char (lib%basename) &\n               // \"': processes can't be appended\")\n       end if\n    end select\n  end subroutine process_library_open\n\n@ %def process_library_open\n@\n\\subsection{Use the library}\nReturn the base name of the library\n<<Process libraries: process library: TBP>>=\n  procedure :: get_name => process_library_get_name\n<<Process libraries: procedures>>=\n  function process_library_get_name (lib) result (name)\n    class(process_library_t), intent(in) :: lib\n    type(string_t) :: name\n    name = lib%basename\n  end function process_library_get_name\n\n@ %def process_library_get_name\n@\nOnce activated, we view the process library object as an interface for\naccessing the matrix elements.\n<<Process libraries: process library: TBP>>=\n  procedure :: is_active => process_library_is_active\n<<Process libraries: procedures>>=\n  function process_library_is_active (lib) result (flag)\n    logical :: flag\n    class(process_library_t), intent(in) :: lib\n    flag = lib%status == STAT_ACTIVE\n  end function process_library_is_active\n\n@ %def process_library_is_active\n@ Return the current status code of the library.  If an index is\nprovided, return the status of that entry.\n<<Process libraries: process library: TBP>>=\n  procedure :: get_status => process_library_get_status\n<<Process libraries: procedures>>=\n  function process_library_get_status (lib, i) result (status)\n    class(process_library_t), intent(in) :: lib\n    integer, intent(in), optional :: i\n    integer :: status\n    if (present (i)) then\n       status = lib%entry(i)%status\n    else\n       status = lib%status\n    end if\n  end function process_library_get_status\n\n@ %def process_library_get_status\n@ Return the update counter.  Since this is incremented each time the\nlibrary is re-opened, we can use this to check if existing pointers to\nmatrix element code are still valid.\n<<Process libraries: process library: TBP>>=\n  procedure :: get_update_counter => process_library_get_update_counter\n<<Process libraries: procedures>>=\n  function process_library_get_update_counter (lib) result (counter)\n    class(process_library_t), intent(in) :: lib\n    integer :: counter\n    counter = lib%update_counter\n  end function process_library_get_update_counter\n\n@ %def process_library_get_update_counter\n@ Manually set the current status code of the library.  If the\noptional flag is set, set also the entry status codes.  This is used\nfor unit tests.\n<<Process libraries: process library: TBP>>=\n  procedure :: set_status => process_library_set_status\n<<Process libraries: procedures>>=\n  subroutine process_library_set_status (lib, status, entries)\n    class(process_library_t), intent(inout) :: lib\n    integer, intent(in) :: status\n    logical, intent(in), optional :: entries\n    lib%status = status\n    if (present (entries)) then\n       if (entries)  lib%entry%status = status\n    end if\n  end subroutine process_library_set_status\n\n@ %def process_library_set_status\n@ Return the load status of the associated driver.\n<<Process libraries: process library: TBP>>=\n  procedure :: is_loaded => process_library_is_loaded\n<<Process libraries: procedures>>=\n  function process_library_is_loaded (lib) result (flag)\n    class(process_library_t), intent(in) :: lib\n    logical :: flag\n    flag = lib%driver%loaded\n  end function process_library_is_loaded\n\n@ %def process_library_is_loaded\n@ Retrieve constants using the process library driver.  We assume that\nthe process code has been loaded, if external.\n<<Process libraries: process library entry: TBP>>=\n  procedure :: fill_constants => process_library_entry_fill_constants\n<<Process libraries: procedures>>=\n  subroutine process_library_entry_fill_constants (entry, driver, data)\n    class(process_library_entry_t), intent(in) :: entry\n    class(prclib_driver_t), intent(in) :: driver\n    type(process_constants_t), intent(out) :: data\n    integer :: i\n    if (entry%i_external /= 0) then\n       i = entry%i_external\n       data%id         = driver%get_process_id (i)\n       data%model_name = driver%get_model_name (i)\n       data%md5sum     = driver%get_md5sum (i)\n       data%openmp_supported = driver%get_openmp_status (i)\n       data%n_in  = driver%get_n_in  (i)\n       data%n_out = driver%get_n_out (i)\n       data%n_flv = driver%get_n_flv (i)\n       data%n_hel = driver%get_n_hel (i)\n       data%n_col = driver%get_n_col (i)\n       data%n_cin = driver%get_n_cin (i)\n       data%n_cf  = driver%get_n_cf  (i)\n       call driver%set_flv_state (i, data%flv_state)\n       call driver%set_hel_state (i, data%hel_state)\n       call driver%set_col_state (i, data%col_state, data%ghost_flag)\n       call driver%set_color_factors (i, data%color_factors, data%cf_index)\n    else\n       select type (proc_driver => entry%driver)\n       class is (process_driver_internal_t)\n          call proc_driver%fill_constants (data)\n       end select\n    end if\n  end subroutine process_library_entry_fill_constants\n\n@ %def process_library_entry_fill_constants\n@ Retrieve the constants for a process\n<<Process libraries: process library: TBP>>=\n  procedure :: fill_constants => process_library_fill_constants\n<<Process libraries: procedures>>=\n  subroutine process_library_fill_constants (lib, id, i_component, data)\n    class(process_library_t), intent(in) :: lib\n    type(string_t), intent(in) :: id\n    integer, intent(in) :: i_component\n    type(process_constants_t), intent(out) :: data\n    integer :: i\n    do i = 1, size (lib%entry)\n       associate (entry => lib%entry(i))\n          if (entry%def%id == id .and. entry%i_component == i_component) then\n             call entry%fill_constants (lib%driver, data)\n             return\n          end if\n       end associate\n    end do\n  end subroutine process_library_fill_constants\n\n@ %def process_library_fill_constants\n@ Retrieve the constants and a connected driver for a process,\nidentified by a process ID and a subprocess index.  We\nscan the process entries until we have found a match.\n<<Process libraries: process library: TBP>>=\n  procedure :: connect_process => process_library_connect_process\n<<Process libraries: procedures>>=\n  subroutine process_library_connect_process &\n       (lib, id, i_component, data, proc_driver)\n    class(process_library_t), intent(in) :: lib\n    type(string_t), intent(in) :: id\n    integer, intent(in) :: i_component\n    type(process_constants_t), intent(out) :: data\n    class(prc_core_driver_t), allocatable, intent(out) :: proc_driver\n    integer :: i\n    do i = 1, size (lib%entry)\n       associate (entry => lib%entry(i))\n         if (entry%def%id == id .and. entry%i_component == i_component) then\n            call entry%fill_constants (lib%driver, data)\n            allocate (proc_driver, source = entry%driver)\n            return\n         end if\n       end associate\n    end do\n    call msg_fatal (\"Process library '\" // char (lib%basename) &\n               // \"': process '\" // char (id) // \"' not found\")\n  end subroutine process_library_connect_process\n\n@ %def process_library_connect_process\n@\nShortcut for use in unit tests: fetch the MD5sum from a specific\nlibrary entry and inject it into the writer of a specific record.\n<<Process libraries: process library: TBP>>=\n  procedure :: test_transfer_md5sum => process_library_test_transfer_md5sum\n<<Process libraries: procedures>>=\n  subroutine process_library_test_transfer_md5sum (lib, r, e, c)\n    class(process_library_t), intent(inout) :: lib\n    integer, intent(in) :: r, e, c\n    associate (writer => lib%driver%record(r)%writer)\n       writer%md5sum = lib%entry(e)%def%get_md5sum (c)\n    end associate\n  end subroutine process_library_test_transfer_md5sum\n\n@ %def process_library_test_transfer_md5sum\n@\n<<Process libraries: process library: TBP>>=\n  procedure :: get_nlo_type => process_library_get_nlo_type\n<<Process libraries: procedures>>=\n  function process_library_get_nlo_type (lib, id, i_component) result (nlo_type)\n    integer :: nlo_type\n    class(process_library_t), intent(in) :: lib\n    type(string_t), intent(in) :: id\n    integer, intent(in) :: i_component\n    integer :: i\n    do i = 1, size (lib%entry)\n       if (lib%entry(i)%def%id == id .and. lib%entry(i)%i_component == i_component) then\n          nlo_type = lib%entry(i)%def%get_nlo_type (i_component)\n          exit\n       end if\n    end do\n  end function process_library_get_nlo_type\n\n@ %def process_library_get_nlo_type\n@\n\\subsection{Collect model-specific libraries}\nThis returns appropriate linker flags for the model parameter libraries that\nare used by the generated matrix element.  At the end, the main libwhizard is\nappended (again), because functions from that may be reqired.\n\nExtra models in the local user space need to be treated individually.\n<<Process libraries: process library: TBP>>=\n  procedure :: get_modellibs_ldflags => process_library_get_modellibs_ldflags\n<<Process libraries: procedures>>=\n  function process_library_get_modellibs_ldflags (prc_lib, os_data) result (flags)\n    class(process_library_t), intent(in) :: prc_lib\n    type(os_data_t), intent(in) :: os_data\n    type(string_t) :: flags\n    type(string_t), dimension(:), allocatable :: models\n    type(string_t) :: modelname, modellib, modellib_full\n    logical :: exist\n    integer :: i, j, mi\n    flags = \" -lomega\"\n    if ((.not. os_data%use_testfiles) .and. &\n\t       os_dir_exist (os_data%whizard_models_libpath_local)) &\n\t\t flags = flags // \" -L\" // os_data%whizard_models_libpath_local\n    flags = flags // \" -L\" // os_data%whizard_models_libpath\n    allocate (models(prc_lib%n_entries + 1))\n    models = \"\"\n    mi = 1\n    if (allocated (prc_lib%entry)) then\n       SCAN: do i = 1, prc_lib%n_entries\n          if (associated (prc_lib%entry(i)%def)) then\n             if (prc_lib%entry(i)%def%model_name /= \"\") then\n                modelname = prc_lib%entry(i)%def%model_name\n             else\n                cycle SCAN\n             end if\n          else\n             cycle SCAN\n          end if\n          do j = 1, mi\n             if (models(mi) == modelname) cycle SCAN\n          end do\n          models(mi) = modelname\n          mi = mi + 1\n          if (os_data%use_libtool) then\n             modellib = \"libparameters_\" // modelname // \".la\"\n          else\n             modellib = \"libparameters_\" // modelname // \".a\"\n          end if\n          exist = .false.\n          if (.not. os_data%use_testfiles) then\n             modellib_full = os_data%whizard_models_libpath_local &\n                  // \"/\" // modellib\n             inquire (file=char (modellib_full), exist=exist)\n          end if\n          if (.not. exist) then\n             modellib_full = os_data%whizard_models_libpath &\n                  // \"/\" // modellib\n             inquire (file=char (modellib_full), exist=exist)\n          end if\n          if (exist) flags = flags // \" -lparameters_\" // modelname\n       end do SCAN\n    end if\n    deallocate (models)\n    flags = flags // \" -lwhizard\"\n  end function process_library_get_modellibs_ldflags\n\n@ %def process_library_get_modellibs_ldflags\n@\n<<Process libraries: process library: TBP>>=\n  procedure :: get_static_modelname => process_library_get_static_modelname\n<<Process libraries: procedures>>=\n  function process_library_get_static_modelname (prc_lib, os_data) result (name)\n    class(process_library_t), intent(in) :: prc_lib\n    type(os_data_t), intent(in) :: os_data\n    type(string_t) :: name\n    type(string_t), dimension(:), allocatable :: models\n    type(string_t) :: modelname, modellib, modellib_full\n    logical :: exist\n    integer :: i, j, mi\n    name = \"\"\n    allocate (models(prc_lib%n_entries + 1))\n    models = \"\"\n    mi = 1\n    if (allocated (prc_lib%entry)) then\n       SCAN: do i = 1, prc_lib%n_entries\n          if (associated (prc_lib%entry(i)%def)) then\n             if (prc_lib%entry(i)%def%model_name /= \"\") then\n                modelname = prc_lib%entry(i)%def%model_name\n             else\n                cycle SCAN\n             end if\n          else\n             cycle SCAN\n          end if\n          do j = 1, mi\n             if (models(mi) == modelname) cycle SCAN\n          end do\n          models(mi) = modelname\n          mi = mi + 1\n          modellib = \"libparameters_\" // modelname // \".a\"\n          exist = .false.\n          if (.not. os_data%use_testfiles) then\n             modellib_full = os_data%whizard_models_libpath_local &\n                  // \"/\" // modellib\n             inquire (file=char (modellib_full), exist=exist)\n          end if\n          if (.not. exist) then\n             modellib_full = os_data%whizard_models_libpath &\n                  // \"/\" // modellib\n             inquire (file=char (modellib_full), exist=exist)\n          end if\n          if (exist) name = name // \" \" // modellib_full\n       end do SCAN\n    end if\n    deallocate (models)\n  end function process_library_get_static_modelname\n\n@ %def process_library_get_static_modelname\n@\n\\subsection{Unit Test}\nTest module, followed by the corresponding implementation module.\n<<[[process_libraries_ut.f90]]>>=\n<<File header>>\n\nmodule process_libraries_ut\n  use unit_tests\n  use process_libraries_uti\n\n<<Standard module head>>\n\n<<Process libraries: public test>>\n\ncontains\n\n<<Process libraries: test driver>>\n\nend module process_libraries_ut\n@ %def process_libraries_ut\n@\n<<[[process_libraries_uti.f90]]>>=\n<<File header>>\n\nmodule process_libraries_uti\n\n  use, intrinsic :: iso_c_binding !NODEP!\n\n<<Use strings>>\n  use io_units\n  use os_interface\n  use particle_specifiers, only: new_prt_spec\n  use process_constants\n  use prclib_interfaces\n  use prc_core_def\n\n  use process_libraries\n\n  use prclib_interfaces_ut, only: test_writer_4_t\n\n<<Standard module head>>\n\n<<Process libraries: test declarations>>\n\n<<Process libraries: test types>>\n\ncontains\n\n<<Process libraries: tests>>\n\n<<Process libraries: test auxiliary>>\n\nend module process_libraries_uti\n@ %def process_libraries_ut\n@ API: driver for the unit tests below.\n<<Process libraries: public test>>=\n  public :: process_libraries_test\n<<Process libraries: test driver>>=\n  subroutine process_libraries_test (u, results)\n    integer, intent(in) :: u\n    type(test_results_t), intent(inout) :: results\n  <<Process libraries: execute tests>>\n  end subroutine process_libraries_test\n\n@ %def process_libraries_test\n@\n\\subsubsection{Empty process list}\nTest 1: Write an empty process list.\n<<Process libraries: execute tests>>=\n  call test (process_libraries_1, \"process_libraries_1\", &\n       \"empty process list\", &\n       u, results)\n<<Process libraries: test declarations>>=\n  public :: process_libraries_1\n<<Process libraries: tests>>=\n  subroutine process_libraries_1 (u)\n    integer, intent(in) :: u\n    type(process_def_list_t) :: process_def_list\n\n    write (u, \"(A)\")  \"* Test output: process_libraries_1\"\n    write (u, \"(A)\")  \"*   Purpose: Display an empty process definition list\"\n    write (u, \"(A)\")\n\n    call process_def_list%write (u)\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Test output end: process_libraries_1\"\n  end subroutine process_libraries_1\n\n@ %def process_libraries_1\n@\n\\subsubsection{Process definition list}\nTest 2: Process definition list with processes and components.\nConstruct the list, write to file, read it in again, and display.\nFinalize and delete the list after use.\n\nWe define a trivial 'test' type for the process variant.  The test\ntype contains just one (meaningless) data item, which is an integer.\n<<Process libraries: test types>>=\n  type, extends (prc_core_def_t) :: prcdef_2_t\n     integer :: data = 0\n     logical :: file = .false.\n   contains\n   <<Process libraries: prcdef 2: TBP>>\n  end type prcdef_2_t\n\n@ %def prcdef_2_t\n@ The process variant is named 'test'.\n<<Process libraries: prcdef 2: TBP>>=\n  procedure, nopass :: type_string => prcdef_2_type_string\n<<Process libraries: test auxiliary>>=\n  function prcdef_2_type_string () result (string)\n    type(string_t) :: string\n    string = \"test\"\n  end function prcdef_2_type_string\n\n@ %def prcdef_2_type_string\n@ Write the contents (the integer value).\n<<Process libraries: prcdef 2: TBP>>=\n  procedure :: write => prcdef_2_write\n<<Process libraries: test auxiliary>>=\n  subroutine prcdef_2_write (object, unit)\n    class(prcdef_2_t), intent(in) :: object\n    integer, intent(in) :: unit\n    write (unit, \"(3x,A,I0)\")  \"Test data         = \", object%data\n  end subroutine prcdef_2_write\n\n@ %def prcdef_2_write\n@ Recover the integer value.\n<<Process libraries: prcdef 2: TBP>>=\n  procedure :: read => prcdef_2_read\n<<Process libraries: test auxiliary>>=\n  subroutine prcdef_2_read (object, unit)\n    class(prcdef_2_t), intent(out) :: object\n    integer, intent(in) :: unit\n    character(80) :: buffer\n    read (unit, \"(A)\")  buffer\n    call strip_equation_lhs (buffer)\n    read (buffer, *)  object%data\n  end subroutine prcdef_2_read\n\n@ %def prcdef_2_read\n@ No external procedures.\n<<Process libraries: prcdef 2: TBP>>=\n  procedure, nopass :: get_features => prcdef_2_get_features\n<<Process libraries: test auxiliary>>=\n  subroutine prcdef_2_get_features (features)\n    type(string_t), dimension(:), allocatable, intent(out) :: features\n    allocate (features (0))\n  end subroutine prcdef_2_get_features\n\n@ %def prcdef_2_get_features\n@ No code generated.\n<<Process libraries: prcdef 2: TBP>>=\n  procedure :: generate_code => prcdef_2_generate_code\n<<Process libraries: test auxiliary>>=\n  subroutine prcdef_2_generate_code (object, &\n       basename, model_name, prt_in, prt_out)\n    class(prcdef_2_t), intent(in) :: object\n    type(string_t), intent(in) :: basename\n    type(string_t), intent(in) :: model_name\n    type(string_t), dimension(:), intent(in) :: prt_in\n    type(string_t), dimension(:), intent(in) :: prt_out\n  end subroutine prcdef_2_generate_code\n\n@ %def prcdef_2_generate_code\n@ Allocate the driver with the appropriate type.\n<<Process libraries: prcdef 2: TBP>>=\n  procedure :: allocate_driver => prcdef_2_allocate_driver\n<<Process libraries: test auxiliary>>=\n  subroutine prcdef_2_allocate_driver (object, driver, basename)\n    class(prcdef_2_t), intent(in) :: object\n    class(prc_core_driver_t), intent(out), allocatable :: driver\n    type(string_t), intent(in) :: basename\n    allocate (prctest_2_t :: driver)\n  end subroutine prcdef_2_allocate_driver\n\n@ %def prcdef_2_allocate_driver\n@ Nothing to connect.\n<<Process libraries: prcdef 2: TBP>>=\n  procedure :: connect => prcdef_2_connect\n<<Process libraries: test auxiliary>>=\n  subroutine prcdef_2_connect (def, lib_driver, i, proc_driver)\n    class(prcdef_2_t), intent(in) :: def\n    class(prclib_driver_t), intent(in) :: lib_driver\n    integer, intent(in) :: i\n    class(prc_core_driver_t), intent(inout) :: proc_driver\n  end subroutine prcdef_2_connect\n\n@ %def prcdef_2_connect\n@ The associated driver type.\n<<Process libraries: test types>>=\n  type, extends (process_driver_internal_t) :: prctest_2_t\n   contains\n   <<Process libraries: prctest 2: TBP>>\n  end type prctest_2_t\n\n@ %def prctest_2_t\n@ Return the type name.\n<<Process libraries: prctest 2: TBP>>=\n  procedure, nopass :: type_name => prctest_2_type_name\n<<Process libraries: test auxiliary>>=\n  function prctest_2_type_name () result (type)\n    type(string_t) :: type\n    type = \"test\"\n  end function prctest_2_type_name\n\n@ %def prctest_2_type_name\n@ This should fill constant process data.  We do not check those here,\nhowever, therefore nothing done.\n<<Process libraries: prctest 2: TBP>>=\n  procedure :: fill_constants => prctest_2_fill_constants\n<<Process libraries: test auxiliary>>=\n  subroutine prctest_2_fill_constants (driver, data)\n    class(prctest_2_t), intent(in) :: driver\n    type(process_constants_t), intent(out) :: data\n  end subroutine prctest_2_fill_constants\n\n@ %def prctest_2_fill_constants\n@\nHere is the actual test.\n\nFor reading, we need a list of templates, i.e., an array containing\nallocated objects for all available process variants.  This is the\npurpose of [[process_core_templates]].  Here, we have only a single\ntemplate for the 'test' variant.\n<<Process libraries: execute tests>>=\n  call test (process_libraries_2, \"process_libraries_2\", &\n       \"process definition list\", &\n       u, results)\n<<Process libraries: test declarations>>=\n  public :: process_libraries_2\n<<Process libraries: tests>>=\n  subroutine process_libraries_2 (u)\n    integer, intent(in) :: u\n    type(prc_template_t), dimension(:), allocatable :: process_core_templates\n    type(process_def_list_t) :: process_def_list\n    type(process_def_entry_t), pointer :: entry => null ()\n    class(prc_core_def_t), allocatable :: test_def\n    integer :: scratch_unit\n\n    write (u, \"(A)\")  \"* Test output: process_libraries_2\"\n    write (u, \"(A)\")  \"* Purpose: Construct a process definition list,\"\n    write (u, \"(A)\")  \"*          write it to file and reread it\"\n    write (u, \"(A)\")  \"\"\n    write (u, \"(A)\")  \"* Construct a process definition list\"\n    write (u, \"(A)\")  \"*   First process definition: empty\"\n    write (u, \"(A)\")  \"*   Second process definition: two components\"\n    write (u, \"(A)\")  \"*     First component: empty\"\n    write (u, \"(A)\")  \"*     Second component: test data\"\n    write (u, \"(A)\")  \"*   Third process definition:\"\n    write (u, \"(A)\")  \"*     Embedded decays and polarization\"\n    write (u, \"(A)\")\n\n    allocate (process_core_templates (1))\n    allocate (prcdef_2_t :: process_core_templates(1)%core_def)\n\n    allocate (entry)\n    call entry%init (var_str (\"first\"), n_in = 0, n_components = 0)\n    call entry%compute_md5sum ()\n    call process_def_list%append (entry)\n\n    allocate (entry)\n    call entry%init (var_str (\"second\"), model_name = var_str (\"Test\"), &\n         n_in = 1, n_components = 2)\n    allocate (prcdef_2_t :: test_def)\n    select type (test_def)\n    type is (prcdef_2_t);  test_def%data = 42\n    end select\n    call entry%import_component (2, n_out = 2, &\n         prt_in  = new_prt_spec ([var_str (\"a\")]), &\n         prt_out = new_prt_spec ([var_str (\"b\"), var_str (\"c\")]), &\n         method  = var_str (\"test\"), &\n         variant = test_def)\n    call entry%compute_md5sum ()\n    call process_def_list%append (entry)\n\n    allocate (entry)\n    call entry%init (var_str (\"third\"), model_name = var_str (\"Test\"), &\n         n_in = 2, n_components = 1)\n    allocate (prcdef_2_t :: test_def)\n    call entry%import_component (1, n_out = 3, &\n         prt_in  = &\n           new_prt_spec ([var_str (\"a\"), var_str (\"b\")]), &\n         prt_out = &\n           [new_prt_spec (var_str (\"c\")), &\n            new_prt_spec (var_str (\"d\"), .true.), &\n            new_prt_spec (var_str (\"e\"), [var_str (\"e_decay\")])], &\n         method  = var_str (\"test\"), &\n         variant = test_def)\n    call entry%compute_md5sum ()\n    call process_def_list%append (entry)\n    call process_def_list%write (u)\n\n    write (u, \"(A)\")  \"\"\n    write (u, \"(A)\")  \"* Write the process definition list to (scratch) file\"\n\n    scratch_unit = free_unit ()\n    open (unit = scratch_unit, status=\"scratch\", action = \"readwrite\")\n    call process_def_list%write (scratch_unit)\n    call process_def_list%final ()\n\n    write (u, \"(A)\")  \"* Reread it\"\n    write (u, \"(A)\")  \"\"\n\n    rewind (scratch_unit)\n    call process_def_list%read (scratch_unit, process_core_templates)\n    close (scratch_unit)\n\n    call process_def_list%write (u)\n    call process_def_list%final ()\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Test output end: process_libraries_2\"\n  end subroutine process_libraries_2\n\n@ %def process_libraries_2\n@\n\\subsubsection{Process library object}\nTest 3: Process library object with several process definitions and\nlibrary entries.  Just construct the object, modify some initial\ncontent, and write the result.  The modifications are mostly applied\ndirectly, so we do not test anything but the contents and the output\nroutine.\n<<Process libraries: execute tests>>=\n  call test (process_libraries_3, \"process_libraries_3\", &\n       \"recover process definition list from file\", &\n       u, results)\n<<Process libraries: test declarations>>=\n  public :: process_libraries_3\n<<Process libraries: tests>>=\n  subroutine process_libraries_3 (u)\n    integer, intent(in) :: u\n    type(process_library_t) :: lib\n    type(process_def_entry_t), pointer :: entry\n    class(prc_core_driver_t), allocatable :: driver_template\n\n    write (u, \"(A)\")  \"* Test output: process_libraries_3\"\n    write (u, \"(A)\")  \"* Purpose: Construct a process library object &\n         &with entries\"\n    write (u, \"(A)\")  \"\"\n    write (u, \"(A)\")  \"* Construct and display a process library object\"\n    write (u, \"(A)\")  \"*   with 5 entries\"\n    write (u, \"(A)\")  \"*   associated with 3 matrix element codes\"\n    write (u, \"(A)\")  \"*   corresponding to 3 process definitions\"\n    write (u, \"(A)\")  \"*   with 2, 1, 1 components, respectively\"\n    write (u, \"(A)\")\n\n    call lib%init (var_str (\"testlib\"))\n\n    call lib%set_status (STAT_ACTIVE)\n    call lib%allocate_entries (5)\n\n    allocate (entry)\n    call entry%init (var_str (\"test_a\"), n_in = 2, n_components = 2)\n    allocate (prctest_2_t :: driver_template)\n    call lib%init_entry (3, STAT_SOURCE, entry%process_def_t, 2, 2, &\n         driver_template)\n    call lib%init_entry (4, STAT_COMPILED, entry%process_def_t, 1, 0)\n    call lib%append (entry)\n\n    allocate (entry)\n    call entry%init (var_str (\"test_b\"), n_in = 2, n_components = 1)\n    call lib%init_entry (2, STAT_CONFIGURED, entry%process_def_t, 1, 1)\n    call lib%append (entry)\n\n    allocate (entry)\n    call entry%init (var_str (\"test_c\"), n_in = 2, n_components = 1)\n    allocate (prctest_2_t :: driver_template)\n    call lib%init_entry (5, STAT_LINKED, entry%process_def_t, 1, 3, &\n         driver_template)\n    call lib%append (entry)\n\n    call lib%write (u)\n    call lib%final ()\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Test output end: process_libraries_3\"\n  end subroutine process_libraries_3\n\n@ %def process_libraries_3\n@\n\\subsubsection{Process library for test matrix element (no file)}\nTest 4: We proceed through the library generation and loading phases\nwith a test matrix element type that needs no code written on file.\n<<Process libraries: execute tests>>=\n  call test (process_libraries_4, \"process_libraries_4\", &\n       \"build and load internal process library\", &\n       u, results)\n<<Process libraries: test declarations>>=\n  public :: process_libraries_4\n<<Process libraries: tests>>=\n  subroutine process_libraries_4 (u)\n    integer, intent(in) :: u\n    type(process_library_t) :: lib\n    type(process_def_entry_t), pointer :: entry\n    class(prc_core_def_t), allocatable :: core_def\n    type(os_data_t) :: os_data\n\n    write (u, \"(A)\")  \"* Test output: process_libraries_4\"\n    write (u, \"(A)\")  \"* Purpose: build a process library with an &\n         &internal (pseudo) matrix element\"\n    write (u, \"(A)\")  \"*          No Makefile or code should be generated\"\n    write (u, \"(A)\")\n\n    write (u, \"(A)\")  \"* Initialize a process library with one entry &\n         &(no external code)\"\n    write (u, \"(A)\")\n    call os_data%init ()\n    call lib%init (var_str (\"proclibs4\"))\n\n    allocate (prcdef_2_t :: core_def)\n\n    allocate (entry)\n    call entry%init (var_str (\"proclibs4_a\"), n_in = 1, n_components = 1)\n    call entry%import_component (1, n_out = 2, variant = core_def)\n    call lib%append (entry)\n\n    write (u, \"(A)\")  \"* Configure library\"\n    write (u, \"(A)\")\n    call lib%configure (os_data)\n\n    write (u, \"(A)\")  \"* Compute MD5 sum\"\n    write (u, \"(A)\")\n    call lib%compute_md5sum ()\n\n    write (u, \"(A)\")  \"* Write makefile (no-op)\"\n    write (u, \"(A)\")\n    call lib%write_makefile (os_data, force = .true., verbose = .true.)\n\n    write (u, \"(A)\")  \"* Write driver source code (no-op)\"\n    write (u, \"(A)\")\n    call lib%write_driver (force = .true.)\n\n    write (u, \"(A)\")  \"* Write process source code (no-op)\"\n    write (u, \"(A)\")\n    call lib%make_source (os_data)\n\n    write (u, \"(A)\")  \"* Compile (no-op)\"\n    write (u, \"(A)\")\n    call lib%make_compile (os_data)\n\n    write (u, \"(A)\")  \"* Link (no-op)\"\n    write (u, \"(A)\")\n    call lib%make_link (os_data)\n\n    write (u, \"(A)\")  \"* Load (no-op)\"\n    write (u, \"(A)\")\n    call lib%load (os_data)\n\n    call lib%write (u)\n    call lib%final ()\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Test output end: process_libraries_4\"\n  end subroutine process_libraries_4\n\n@ %def process_libraries_4\n@\n\\subsubsection{Build workflow for test matrix element}\nTest 5: We write source code for a dummy process.\n\nWe define another trivial type for the process variant.  The test\ntype contains just no variable data, but produces code on file.\n<<Process libraries: test types>>=\n  type, extends (prc_core_def_t) :: prcdef_5_t\n   contains\n   <<Process libraries: prcdef 5: TBP>>\n  end type prcdef_5_t\n\n@ %def prcdef_5_t\n@ The process variant is named [[test_file]].\n<<Process libraries: prcdef 5: TBP>>=\n  procedure, nopass :: type_string => prcdef_5_type_string\n<<Process libraries: test auxiliary>>=\n  function prcdef_5_type_string () result (string)\n    type(string_t) :: string\n    string = \"test_file\"\n  end function prcdef_5_type_string\n\n@ %def prcdef_5_type_string\n@ We reuse the writer [[test_writer_4]] from the previous module.\n<<Process libraries: prcdef 5: TBP>>=\n  procedure :: init => prcdef_5_init\n<<Process libraries: test auxiliary>>=\n  subroutine prcdef_5_init (object)\n    class(prcdef_5_t), intent(out) :: object\n    allocate (test_writer_4_t :: object%writer)\n  end subroutine prcdef_5_init\n\n@ %def prcdef_5_init\n@ Nothing to write.\n<<Process libraries: prcdef 5: TBP>>=\n  procedure :: write => prcdef_5_write\n<<Process libraries: test auxiliary>>=\n  subroutine prcdef_5_write (object, unit)\n    class(prcdef_5_t), intent(in) :: object\n    integer, intent(in) :: unit\n  end subroutine prcdef_5_write\n\n@ %def prcdef_5_write\n@ Nothing to read.\n<<Process libraries: prcdef 5: TBP>>=\n  procedure :: read => prcdef_5_read\n<<Process libraries: test auxiliary>>=\n  subroutine prcdef_5_read (object, unit)\n    class(prcdef_5_t), intent(out) :: object\n    integer, intent(in) :: unit\n  end subroutine prcdef_5_read\n\n@ %def prcdef_5_read\n@ Allocate the driver with the appropriate type.\n<<Process libraries: prcdef 5: TBP>>=\n  procedure :: allocate_driver => prcdef_5_allocate_driver\n<<Process libraries: test auxiliary>>=\n  subroutine prcdef_5_allocate_driver (object, driver, basename)\n    class(prcdef_5_t), intent(in) :: object\n    class(prc_core_driver_t), intent(out), allocatable :: driver\n    type(string_t), intent(in) :: basename\n    allocate (prctest_5_t :: driver)\n  end subroutine prcdef_5_allocate_driver\n\n@ %def prcdef_5_allocate_driver\n@ This time we need code:\n<<Process libraries: prcdef 5: TBP>>=\n  procedure, nopass :: needs_code => prcdef_5_needs_code\n<<Process libraries: test auxiliary>>=\n  function prcdef_5_needs_code () result (flag)\n    logical :: flag\n    flag = .true.\n  end function prcdef_5_needs_code\n\n@ %def prcdef_5_needs_code\n@ For the test case, we implement a single feature [[proc1]].\n<<Process libraries: prcdef 5: TBP>>=\n  procedure, nopass :: get_features => prcdef_5_get_features\n<<Process libraries: test auxiliary>>=\n  subroutine prcdef_5_get_features (features)\n    type(string_t), dimension(:), allocatable, intent(out) :: features\n    allocate (features (1))\n    features = [ var_str (\"proc1\") ]\n  end subroutine prcdef_5_get_features\n\n@ %def prcdef_5_get_features\n@ Nothing to connect.\n<<Process libraries: prcdef 5: TBP>>=\n  procedure :: connect => prcdef_5_connect\n<<Process libraries: test auxiliary>>=\n  subroutine prcdef_5_connect (def, lib_driver, i, proc_driver)\n    class(prcdef_5_t), intent(in) :: def\n    class(prclib_driver_t), intent(in) :: lib_driver\n    integer, intent(in) :: i\n    class(prc_core_driver_t), intent(inout) :: proc_driver\n  end subroutine prcdef_5_connect\n\n@ %def prcdef_5_connect\n@ The driver type.\n<<Process libraries: test types>>=\n  type, extends (prc_core_driver_t) :: prctest_5_t\n   contains\n   <<Process libraries: prctest 5: TBP>>\n  end type prctest_5_t\n\n@ %def prctest_5_t\n@ Return the type name.\n<<Process libraries: prctest 5: TBP>>=\n  procedure, nopass :: type_name => prctest_5_type_name\n<<Process libraries: test auxiliary>>=\n  function prctest_5_type_name () result (type)\n    type(string_t) :: type\n    type = \"test_file\"\n  end function prctest_5_type_name\n\n@ %def prctest_5_type_name\n@\nHere is the actual test:\n<<Process libraries: execute tests>>=\n  call test (process_libraries_5, \"process_libraries_5\", &\n       \"build external process library\", &\n       u, results)\n<<Process libraries: test declarations>>=\n  public :: process_libraries_5\n<<Process libraries: tests>>=\n  subroutine process_libraries_5 (u)\n    integer, intent(in) :: u\n    type(process_library_t) :: lib\n    type(process_def_entry_t), pointer :: entry\n    class(prc_core_def_t), allocatable :: core_def\n    type(os_data_t) :: os_data\n\n    write (u, \"(A)\")  \"* Test output: process_libraries_5\"\n    write (u, \"(A)\")  \"* Purpose: build a process library with an &\n         &external (pseudo) matrix element\"\n    write (u, \"(A)\")\n\n    write (u, \"(A)\")  \"* Initialize a process library with one entry\"\n    write (u, \"(A)\")\n    call lib%init (var_str (\"proclibs5\"))\n    call os_data%init ()\n\n    allocate (prcdef_5_t :: core_def)\n    select type (core_def)\n    type is (prcdef_5_t)\n       call core_def%init ()\n    end select\n\n    allocate (entry)\n    call entry%init (var_str (\"proclibs5_a\"), &\n         model_name = var_str (\"Test_Model\"), &\n         n_in = 1, n_components = 1)\n    call entry%import_component (1, n_out = 2, &\n         prt_in  = new_prt_spec ([var_str (\"a\")]), &\n         prt_out = new_prt_spec ([var_str (\"b\"), var_str (\"c\")]), &\n         method  = var_str (\"test\"), &\n         variant = core_def)\n    call lib%append (entry)\n\n    write (u, \"(A)\")  \"* Configure library\"\n    write (u, \"(A)\")\n    call lib%configure (os_data)\n\n    write (u, \"(A)\")  \"* Compute MD5 sum\"\n    write (u, \"(A)\")\n    call lib%compute_md5sum ()\n\n    write (u, \"(A)\")  \"* Write makefile\"\n    write (u, \"(A)\")\n    call lib%write_makefile (os_data, force = .true., verbose = .false.)\n\n    write (u, \"(A)\")  \"* Write driver source code\"\n    write (u, \"(A)\")\n    call lib%write_driver (force = .true.)\n\n    write (u, \"(A)\")  \"* Write process source code\"\n    write (u, \"(A)\")\n    call lib%make_source (os_data)\n\n    write (u, \"(A)\")  \"* Compile\"\n    write (u, \"(A)\")\n    call lib%make_compile (os_data)\n\n    write (u, \"(A)\")  \"* Link\"\n    write (u, \"(A)\")\n    call lib%make_link (os_data)\n\n    call lib%write (u, libpath = .false.)\n\n    call lib%final ()\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Test output end: process_libraries_5\"\n  end subroutine process_libraries_5\n\n@ %def process_libraries_5\n@\n\\subsubsection{Build and load library with test matrix element}\nTest 6: We write source code for a dummy process.\n\nThis process variant is identical to the previous case, but it\nsupports a driver for the test procedure 'proc1'.\n<<Process libraries: test types>>=\n  type, extends (prc_core_def_t) :: prcdef_6_t\n   contains\n   <<Process libraries: prcdef 6: TBP>>\n  end type prcdef_6_t\n\n@ %def prcdef_6_t\n@ The process variant is named [[test_file]].\n<<Process libraries: prcdef 6: TBP>>=\n  procedure, nopass :: type_string => prcdef_6_type_string\n<<Process libraries: test auxiliary>>=\n  function prcdef_6_type_string () result (string)\n    type(string_t) :: string\n    string = \"test_file\"\n  end function prcdef_6_type_string\n\n@ %def prcdef_6_type_string\n@ We reuse the writer [[test_writer_4]] from the previous module.\n<<Process libraries: prcdef 6: TBP>>=\n  procedure :: init => prcdef_6_init\n<<Process libraries: test auxiliary>>=\n  subroutine prcdef_6_init (object)\n    class(prcdef_6_t), intent(out) :: object\n    allocate (test_writer_4_t :: object%writer)\n    call object%writer%init_test ()\n  end subroutine prcdef_6_init\n\n@ %def prcdef_6_init\n@ Nothing to write.\n<<Process libraries: prcdef 6: TBP>>=\n  procedure :: write => prcdef_6_write\n<<Process libraries: test auxiliary>>=\n  subroutine prcdef_6_write (object, unit)\n    class(prcdef_6_t), intent(in) :: object\n    integer, intent(in) :: unit\n  end subroutine prcdef_6_write\n\n@ %def prcdef_6_write\n@ Nothing to read.\n<<Process libraries: prcdef 6: TBP>>=\n  procedure :: read => prcdef_6_read\n<<Process libraries: test auxiliary>>=\n  subroutine prcdef_6_read (object, unit)\n    class(prcdef_6_t), intent(out) :: object\n    integer, intent(in) :: unit\n  end subroutine prcdef_6_read\n\n@ %def prcdef_6_read\n@ Allocate the driver with the appropriate type.\n<<Process libraries: prcdef 6: TBP>>=\n  procedure :: allocate_driver => prcdef_6_allocate_driver\n<<Process libraries: test auxiliary>>=\n  subroutine prcdef_6_allocate_driver (object, driver, basename)\n    class(prcdef_6_t), intent(in) :: object\n    class(prc_core_driver_t), intent(out), allocatable :: driver\n    type(string_t), intent(in) :: basename\n    allocate (prctest_6_t :: driver)\n  end subroutine prcdef_6_allocate_driver\n\n@ %def prcdef_6_allocate_driver\n@ This time we need code:\n<<Process libraries: prcdef 6: TBP>>=\n  procedure, nopass :: needs_code => prcdef_6_needs_code\n<<Process libraries: test auxiliary>>=\n  function prcdef_6_needs_code () result (flag)\n    logical :: flag\n    flag = .true.\n  end function prcdef_6_needs_code\n\n@ %def prcdef_6_needs_code\n@ For the test case, we implement a single feature [[proc1]].\n<<Process libraries: prcdef 6: TBP>>=\n  procedure, nopass :: get_features => prcdef_6_get_features\n<<Process libraries: test auxiliary>>=\n  subroutine prcdef_6_get_features (features)\n    type(string_t), dimension(:), allocatable, intent(out) :: features\n    allocate (features (1))\n    features = [ var_str (\"proc1\") ]\n  end subroutine prcdef_6_get_features\n\n@ %def prcdef_6_get_features\n@ The interface of the only specific feature.\n<<Process libraries: test types>>=\n  abstract interface\n     subroutine proc1_t (n) bind(C)\n       import\n       integer(c_int), intent(out) :: n\n     end subroutine proc1_t\n  end interface\n\n@ %def proc1_t\n@ Connect the feature [[proc1]] with the process driver.\n<<Process libraries: prcdef 6: TBP>>=\n  procedure :: connect => prcdef_6_connect\n<<Process libraries: test auxiliary>>=\n  subroutine prcdef_6_connect (def, lib_driver, i, proc_driver)\n    class(prcdef_6_t), intent(in) :: def\n    class(prclib_driver_t), intent(in) :: lib_driver\n    integer, intent(in) :: i\n    class(prc_core_driver_t), intent(inout) :: proc_driver\n    integer(c_int) :: pid, fid\n    type(c_funptr) :: fptr\n    select type (proc_driver)\n    type is  (prctest_6_t)\n       pid = i\n       fid = 1\n       call lib_driver%get_fptr (pid, fid, fptr)\n       call c_f_procpointer (fptr, proc_driver%proc1)\n    end select\n  end subroutine prcdef_6_connect\n\n@ %def prcdef_6_connect\n@\nThe driver type.\n<<Process libraries: test types>>=\n  type, extends (prc_core_driver_t) :: prctest_6_t\n     procedure(proc1_t), nopass, pointer :: proc1 => null ()\n   contains\n   <<Process libraries: prctest 6: TBP>>\n  end type prctest_6_t\n\n@ %def prctest_6_t\n@ Return the type name.\n<<Process libraries: prctest 6: TBP>>=\n  procedure, nopass :: type_name => prctest_6_type_name\n<<Process libraries: test auxiliary>>=\n  function prctest_6_type_name () result (type)\n    type(string_t) :: type\n    type = \"test_file\"\n  end function prctest_6_type_name\n\n@ %def prctest_6_type_name\n@\nHere is the actual test:\n<<Process libraries: execute tests>>=\n  call test (process_libraries_6, \"process_libraries_6\", &\n       \"build and load external process library\", &\n       u, results)\n<<Process libraries: test declarations>>=\n  public :: process_libraries_6\n<<Process libraries: tests>>=\n  subroutine process_libraries_6 (u)\n    integer, intent(in) :: u\n    type(process_library_t) :: lib\n    type(process_def_entry_t), pointer :: entry\n    class(prc_core_def_t), allocatable :: core_def\n    type(os_data_t) :: os_data\n    type(string_t), dimension(:), allocatable :: name_list\n    type(process_constants_t) :: data\n    class(prc_core_driver_t), allocatable :: proc_driver\n    integer :: i\n    integer(c_int) :: n\n\n    write (u, \"(A)\")  \"* Test output: process_libraries_6\"\n    write (u, \"(A)\")  \"* Purpose: build and load a process library\"\n    write (u, \"(A)\")  \"*          with an external (pseudo) matrix element\"\n    write (u, \"(A)\")  \"*          Check single-call linking\"\n    write (u, \"(A)\")\n\n    write (u, \"(A)\")  \"* Initialize a process library with one entry\"\n    write (u, \"(A)\")\n    call lib%init (var_str (\"proclibs6\"))\n    call os_data%init ()\n\n    allocate (prcdef_6_t :: core_def)\n    select type (core_def)\n    type is (prcdef_6_t)\n       call core_def%init ()\n    end select\n\n    allocate (entry)\n    call entry%init (var_str (\"proclibs6_a\"), &\n         model_name = var_str (\"Test_model\"), &\n         n_in = 1, n_components = 1)\n    call entry%import_component (1, n_out = 2, &\n         prt_in  = new_prt_spec ([var_str (\"a\")]), &\n         prt_out = new_prt_spec ([var_str (\"b\"), var_str (\"c\")]), &\n         method  = var_str (\"test\"), &\n         variant = core_def)\n    call lib%append (entry)\n\n    write (u, \"(A)\")  \"* Configure library\"\n    write (u, \"(A)\")\n    call lib%configure (os_data)\n\n    write (u, \"(A)\")  \"* Write makefile\"\n    write (u, \"(A)\")\n    call lib%write_makefile (os_data, force = .true., verbose = .false.)\n\n    write (u, \"(A)\")  \"* Write driver source code\"\n    write (u, \"(A)\")\n    call lib%write_driver (force = .true.)\n\n    write (u, \"(A)\")  \"* Write process source code, compile, link, load\"\n    write (u, \"(A)\")\n    call lib%load (os_data)\n\n    call lib%write (u, libpath = .false.)\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Probe library API:\"\n    write (u, \"(A)\")\n\n    write (u, \"(1x,A,A,A)\")  \"name                      = '\", &\n         char (lib%get_name ()), \"'\"\n    write (u, \"(1x,A,L1)\")  \"is active                 = \", &\n         lib%is_active ()\n    write (u, \"(1x,A,I0)\")  \"n_processes               = \", &\n         lib%get_n_processes ()\n    write (u, \"(1x,A)\", advance=\"no\")  \"processes                 =\"\n    call lib%get_process_id_list (name_list)\n    do i = 1, size (name_list)\n       write (u, \"(1x,A)\", advance=\"no\")  char (name_list(i))\n    end do\n    write (u, *)\n    write (u, \"(1x,A,L1)\")  \"proclibs6_a is process    = \", &\n         lib%contains (var_str (\"proclibs6_a\"))\n    write (u, \"(1x,A,I0)\")  \"proclibs6_a has index     = \", &\n         lib%get_entry_index (var_str (\"proclibs6_a\"))\n    write (u, \"(1x,A,L1)\")  \"foobar is process         = \", &\n         lib%contains (var_str (\"foobar\"))\n    write (u, \"(1x,A,I0)\")  \"foobar has index          = \", &\n         lib%get_entry_index (var_str (\"foobar\"))\n    write (u, \"(1x,A,I0)\")  \"n_in(proclibs6_a)         = \", &\n         lib%get_n_in (var_str (\"proclibs6_a\"))\n    write (u, \"(1x,A,A)\")   \"model_name(proclibs6_a)   = \", &\n         char (lib%get_model_name (var_str (\"proclibs6_a\")))\n    write (u, \"(1x,A)\", advance=\"no\")  \"components(proclibs6_a)   =\"\n    call lib%get_component_list (var_str (\"proclibs6_a\"), name_list)\n    do i = 1, size (name_list)\n       write (u, \"(1x,A)\", advance=\"no\")  char (name_list(i))\n    end do\n    write (u, *)\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Constants of proclibs6_a_i1:\"\n    write (u, \"(A)\")\n\n    call lib%connect_process (var_str (\"proclibs6_a\"), 1, data, proc_driver)\n\n    write (u, \"(1x,A,A)\")  \"component ID     = \", char (data%id)\n    write (u, \"(1x,A,A)\")  \"model name       = \", char (data%model_name)\n    write (u, \"(1x,A,A,A)\")  \"md5sum           = '\", data%md5sum, \"'\"\n    write (u, \"(1x,A,L1)\") \"openmp supported = \", data%openmp_supported\n    write (u, \"(1x,A,I0)\") \"n_in  = \", data%n_in\n    write (u, \"(1x,A,I0)\") \"n_out = \", data%n_out\n    write (u, \"(1x,A,I0)\") \"n_flv = \", data%n_flv\n    write (u, \"(1x,A,I0)\") \"n_hel = \", data%n_hel\n    write (u, \"(1x,A,I0)\") \"n_col = \", data%n_col\n    write (u, \"(1x,A,I0)\") \"n_cin = \", data%n_cin\n    write (u, \"(1x,A,I0)\") \"n_cf  = \", data%n_cf\n    write (u, \"(1x,A,10(1x,I0))\") \"flv state =\", data%flv_state\n    write (u, \"(1x,A,10(1x,I0))\") \"hel state =\", data%hel_state\n    write (u, \"(1x,A,10(1x,I0))\") \"col state =\", data%col_state\n    write (u, \"(1x,A,10(1x,L1))\") \"ghost flag =\", data%ghost_flag\n    write (u, \"(1x,A,10(1x,F5.3))\") \"color factors =\", data%color_factors\n    write (u, \"(1x,A,10(1x,I0))\") \"cf index =\", data%cf_index\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Call feature of proclibs6_a:\"\n    write (u, \"(A)\")\n\n    select type (proc_driver)\n    type is (prctest_6_t)\n       call proc_driver%proc1 (n)\n       write (u, \"(1x,A,I0)\") \"proc1 = \", n\n    end select\n\n    call lib%final ()\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Test output end: process_libraries_6\"\n  end subroutine process_libraries_6\n\n@ %def process_libraries_6\n@\n\\subsubsection{MD5 sums}\nCheck MD5 sum calculation.\n<<Process libraries: execute tests>>=\n  call test (process_libraries_7, \"process_libraries_7\", &\n       \"process definition list\", &\n       u, results)\n<<Process libraries: test declarations>>=\n  public :: process_libraries_7\n<<Process libraries: tests>>=\n  subroutine process_libraries_7 (u)\n    integer, intent(in) :: u\n    type(prc_template_t), dimension(:), allocatable :: process_core_templates\n    type(process_def_entry_t), target :: entry\n    class(prc_core_def_t), allocatable :: test_def\n    class(prc_core_def_t), pointer :: def\n\n    write (u, \"(A)\")  \"* Test output: process_libraries_7\"\n    write (u, \"(A)\")  \"* Purpose: Construct a process definition list &\n         &and check MD5 sums\"\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Construct a process definition list\"\n    write (u, \"(A)\")  \"*   Process: two components\"\n    write (u, \"(A)\")\n\n    allocate (process_core_templates (1))\n    allocate (prcdef_2_t :: process_core_templates(1)%core_def)\n\n    call entry%init (var_str (\"first\"), model_name = var_str (\"Test\"), &\n         n_in = 1, n_components = 2)\n    allocate (prcdef_2_t :: test_def)\n    select type (test_def)\n    type is (prcdef_2_t);  test_def%data = 31\n    end select\n    call entry%import_component (1, n_out = 3, &\n         prt_in  = new_prt_spec ([var_str (\"a\")]), &\n         prt_out = new_prt_spec ([var_str (\"b\"), var_str (\"c\"), &\n                                  var_str (\"e\")]), &\n         method  = var_str (\"test\"), &\n         variant = test_def)\n    allocate (prcdef_2_t :: test_def)\n    select type (test_def)\n    type is (prcdef_2_t);  test_def%data = 42\n    end select\n    call entry%import_component (2, n_out = 2, &\n         prt_in  = new_prt_spec ([var_str (\"a\")]), &\n         prt_out = new_prt_spec ([var_str (\"b\"), var_str (\"c\")]), &\n         method  = var_str (\"test\"), &\n         variant = test_def)\n    call entry%write (u)\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Compute MD5 sums\"\n    write (u, \"(A)\")\n\n    call entry%compute_md5sum ()\n    call entry%write (u)\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Recalculate MD5 sums (should be identical)\"\n    write (u, \"(A)\")\n\n    call entry%compute_md5sum ()\n    call entry%write (u)\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Modify a component and recalculate MD5 sums\"\n    write (u, \"(A)\")\n\n    def => entry%get_core_def_ptr (2)\n    select type (def)\n    type is (prcdef_2_t)\n       def%data = 54\n    end select\n    call entry%compute_md5sum ()\n    call entry%write (u)\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Modify the model and recalculate MD5 sums\"\n    write (u, \"(A)\")\n\n    call entry%set_model_name (var_str (\"foo\"))\n    call entry%compute_md5sum ()\n    call entry%write (u)\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Test output end: process_libraries_7\"\n  end subroutine process_libraries_7\n\n@ %def process_libraries_7\n@\nHere is the actual test:\n<<Process libraries: execute tests>>=\n  call test (process_libraries_8, \"process_libraries_8\", &\n       \"library status checks\", &\n       u, results)\n<<Process libraries: test declarations>>=\n  public :: process_libraries_8\n<<Process libraries: tests>>=\n  subroutine process_libraries_8 (u)\n    integer, intent(in) :: u\n    type(process_library_t) :: lib\n    type(process_def_entry_t), pointer :: entry\n    class(prc_core_def_t), allocatable :: core_def\n    type(os_data_t) :: os_data\n\n    write (u, \"(A)\")  \"* Test output: process_libraries_8\"\n    write (u, \"(A)\")  \"* Purpose: build and load a process library\"\n    write (u, \"(A)\")  \"*          with an external (pseudo) matrix element\"\n    write (u, \"(A)\")  \"*          Check status updates\"\n    write (u, \"(A)\")\n\n    write (u, \"(A)\")  \"* Initialize a process library with one entry\"\n    write (u, \"(A)\")\n    call lib%init (var_str (\"proclibs8\"))\n    call os_data%init ()\n\n    allocate (prcdef_6_t :: core_def)\n    select type (core_def)\n    type is (prcdef_6_t)\n       call core_def%init ()\n    end select\n\n    allocate (entry)\n    call entry%init (var_str (\"proclibs8_a\"), &\n         model_name = var_str (\"Test_model\"), &\n         n_in = 1, n_components = 1)\n    call entry%import_component (1, n_out = 2, &\n         prt_in  = new_prt_spec ([var_str (\"a\")]), &\n         prt_out = new_prt_spec ([var_str (\"b\"), var_str (\"c\")]), &\n         method  = var_str (\"test\"), &\n         variant = core_def)\n    call lib%append (entry)\n\n    write (u, \"(A)\")  \"* Configure library\"\n    write (u, \"(A)\")\n\n    call lib%configure (os_data)\n    call lib%compute_md5sum ()\n\n    call lib%test_transfer_md5sum (1, 1, 1)\n\n    write (u, \"(1x,A,L1)\")  \"library loaded = \", lib%is_loaded ()\n    write (u, \"(1x,A,I0)\")  \"lib status   = \", lib%get_status ()\n    write (u, \"(1x,A,I0)\")  \"proc1 status = \", lib%get_status (1)\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Write makefile\"\n    write (u, \"(A)\")\n    call lib%write_makefile (os_data, force = .true., verbose = .false.)\n\n    write (u, \"(A)\")  \"* Update status\"\n    write (u, \"(A)\")\n\n    call lib%update_status (os_data)\n    write (u, \"(1x,A,L1)\")  \"library loaded = \", lib%is_loaded ()\n    write (u, \"(1x,A,I0)\")  \"lib status   = \", lib%get_status ()\n    write (u, \"(1x,A,I0)\")  \"proc1 status = \", lib%get_status (1)\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Write driver source code\"\n    write (u, \"(A)\")\n    call lib%write_driver (force = .false.)\n\n    write (u, \"(A)\")  \"* Write process source code\"\n    write (u, \"(A)\")\n    call lib%make_source (os_data)\n\n    write (u, \"(1x,A,L1)\")  \"library loaded = \", lib%is_loaded ()\n    write (u, \"(1x,A,I0)\")  \"lib status   = \", lib%get_status ()\n    write (u, \"(1x,A,I0)\")  \"proc1 status = \", lib%get_status (1)\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Compile and load\"\n    write (u, \"(A)\")\n\n    call lib%load (os_data)\n    write (u, \"(1x,A,L1)\")  \"library loaded = \", lib%is_loaded ()\n    write (u, \"(1x,A,I0)\")  \"lib status   = \", lib%get_status ()\n    write (u, \"(1x,A,I0)\")  \"proc1 status = \", lib%get_status (1)\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Append process and reconfigure\"\n    write (u, \"(A)\")\n\n    allocate (prcdef_6_t :: core_def)\n    select type (core_def)\n    type is (prcdef_6_t)\n       call core_def%init ()\n    end select\n\n    allocate (entry)\n    call entry%init (var_str (\"proclibs8_b\"), &\n         model_name = var_str (\"Test_model\"), &\n         n_in = 1, n_components = 1)\n    call entry%import_component (1, n_out = 2, &\n         prt_in  = new_prt_spec ([var_str (\"a\")]), &\n         prt_out = new_prt_spec ([var_str (\"b\"), var_str (\"d\")]), &\n         method  = var_str (\"test\"), &\n         variant = core_def)\n    call lib%append (entry)\n\n    call lib%configure (os_data)\n    call lib%compute_md5sum ()\n    call lib%test_transfer_md5sum (2, 2, 1)\n    call lib%write_makefile (os_data, force = .false., verbose = .false.)\n    call lib%write_driver (force = .false.)\n\n    write (u, \"(1x,A,L1)\")  \"library loaded = \", lib%is_loaded ()\n    write (u, \"(1x,A,I0)\")  \"lib status   = \", lib%get_status ()\n    write (u, \"(1x,A,I0)\")  \"proc1 status = \", lib%get_status (1)\n    write (u, \"(1x,A,I0)\")  \"proc2 status = \", lib%get_status (2)\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Update status\"\n    write (u, \"(A)\")\n\n    call lib%update_status (os_data)\n    write (u, \"(1x,A,L1)\")  \"library loaded = \", lib%is_loaded ()\n    write (u, \"(1x,A,I0)\")  \"lib status   = \", lib%get_status ()\n    write (u, \"(1x,A,I0)\")  \"proc1 status = \", lib%get_status (1)\n    write (u, \"(1x,A,I0)\")  \"proc2 status = \", lib%get_status (2)\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Write source code\"\n    write (u, \"(A)\")\n\n    call lib%make_source (os_data)\n    write (u, \"(1x,A,L1)\")  \"library loaded = \", lib%is_loaded ()\n    write (u, \"(1x,A,I0)\")  \"lib status   = \", lib%get_status ()\n    write (u, \"(1x,A,I0)\")  \"proc1 status = \", lib%get_status (1)\n    write (u, \"(1x,A,I0)\")  \"proc2 status = \", lib%get_status (2)\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Reset status\"\n    write (u, \"(A)\")\n\n    call lib%set_status (STAT_CONFIGURED, entries=.true.)\n    write (u, \"(1x,A,L1)\")  \"library loaded = \", lib%is_loaded ()\n    write (u, \"(1x,A,I0)\")  \"lib status   = \", lib%get_status ()\n    write (u, \"(1x,A,I0)\")  \"proc1 status = \", lib%get_status (1)\n    write (u, \"(1x,A,I0)\")  \"proc2 status = \", lib%get_status (2)\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Update status\"\n    write (u, \"(A)\")\n\n    call lib%update_status (os_data)\n    write (u, \"(1x,A,L1)\")  \"library loaded = \", lib%is_loaded ()\n    write (u, \"(1x,A,I0)\")  \"lib status   = \", lib%get_status ()\n    write (u, \"(1x,A,I0)\")  \"proc1 status = \", lib%get_status (1)\n    write (u, \"(1x,A,I0)\")  \"proc2 status = \", lib%get_status (2)\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Partial cleanup\"\n    write (u, \"(A)\")\n\n    call lib%clean (os_data, distclean = .false.)\n    write (u, \"(1x,A,L1)\")  \"library loaded = \", lib%is_loaded ()\n    write (u, \"(1x,A,I0)\")  \"lib status   = \", lib%get_status ()\n    write (u, \"(1x,A,I0)\")  \"proc1 status = \", lib%get_status (1)\n    write (u, \"(1x,A,I0)\")  \"proc2 status = \", lib%get_status (2)\n\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Update status\"\n    write (u, \"(A)\")\n\n    call lib%update_status (os_data)\n    write (u, \"(1x,A,L1)\")  \"library loaded = \", lib%is_loaded ()\n    write (u, \"(1x,A,I0)\")  \"lib status   = \", lib%get_status ()\n    write (u, \"(1x,A,I0)\")  \"proc1 status = \", lib%get_status (1)\n    write (u, \"(1x,A,I0)\")  \"proc2 status = \", lib%get_status (2)\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Complete cleanup\"\n\n    call lib%clean (os_data, distclean = .true.)\n    call lib%final ()\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Test output end: process_libraries_8\"\n  end subroutine process_libraries_8\n\n@ %def process_libraries_8\n@\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\\section{Process Library Stacks}\n\nFor storing and handling multiple libraries, we define process library stacks.\nThese are ordinary stacks where new entries are pushed onto the top.\n<<[[prclib_stacks.f90]]>>=\n<<File header>>\n\nmodule prclib_stacks\n\n<<Use strings>>\n  use io_units\n  use format_utils, only: write_separator\n  use process_libraries\n\n<<Standard module head>>\n\n<<Prclib stacks: public>>\n\n<<Prclib stacks: types>>\n\ncontains\n\n<<Prclib stacks: procedures>>\n\nend module prclib_stacks\n@ %def prclib_stacks\n@\n\\subsection{The stack entry type}\nA stack entry is a process library object, augmented by a pointer to the\nnext entry.  We do not need specific methods, all relevant methods are\ninherited.\n\nOn higher level, process libraries should be prepared as process entry objects.\n<<Prclib stacks: public>>=\n  public :: prclib_entry_t\n<<Prclib stacks: types>>=\n  type, extends (process_library_t) :: prclib_entry_t\n     type(prclib_entry_t), pointer :: next => null ()\n  end type prclib_entry_t\n\n@ %def prclib_entry_t\n@\n\\subsection{The prclib stack type}\nFor easy conversion and lookup it is useful to store the filling\nnumber in the object.  The content is stored as a linked list.\n<<Prclib stacks: public>>=\n  public :: prclib_stack_t\n<<Prclib stacks: types>>=\n  type :: prclib_stack_t\n     integer :: n = 0\n     type(prclib_entry_t), pointer :: first => null ()\n   contains\n   <<Prclib stacks: prclib stack: TBP>>\n  end type prclib_stack_t\n\n@ %def prclib_stack_t\n@ Finalizer.  Iteratively deallocate the stack entries.  The resulting\nempty stack can be immediately recycled, if necessary.\n<<Prclib stacks: prclib stack: TBP>>=\n  procedure :: final => prclib_stack_final\n<<Prclib stacks: procedures>>=\n  subroutine prclib_stack_final (object)\n    class(prclib_stack_t), intent(inout) :: object\n    type(prclib_entry_t), pointer :: lib\n    do while (associated (object%first))\n       lib => object%first\n       object%first => lib%next\n       call lib%final ()\n       deallocate (lib)\n    end do\n    object%n = 0\n  end subroutine prclib_stack_final\n\n@ %def prclib_stack_final\n@ Output.  The entries on the stack will be ordered LIFO, i.e., backwards.\n<<Prclib stacks: prclib stack: TBP>>=\n  procedure :: write => prclib_stack_write\n<<Prclib stacks: procedures>>=\n  subroutine prclib_stack_write (object, unit, libpath)\n    class(prclib_stack_t), intent(in) :: object\n    integer, intent(in), optional :: unit\n    logical, intent(in), optional :: libpath\n    type(prclib_entry_t), pointer :: lib\n    integer :: u\n    u = given_output_unit (unit)\n    call write_separator (u, 2)\n    select case (object%n)\n    case (0)\n       write (u, \"(1x,A)\")  \"Process library stack: [empty]\"\n    case default\n       write (u, \"(1x,A)\")  \"Process library stack:\"\n       lib => object%first\n       do while (associated (lib))\n          call write_separator (u)\n          call lib%write (u, libpath)\n          lib => lib%next\n       end do\n    end select\n    call write_separator (u, 2)\n  end subroutine prclib_stack_write\n\n@ %def prclib_stack_write\n@\n\\subsection{Operating on Stacks}\nWe take a library entry pointer and push it onto the stack.  The previous\npointer is nullified.  Subsequently, the library entry is `owned' by the\nstack and will be finalized when the stack is deleted.\n<<Prclib stacks: prclib stack: TBP>>=\n  procedure :: push => prclib_stack_push\n<<Prclib stacks: procedures>>=\n  subroutine prclib_stack_push (stack, lib)\n    class(prclib_stack_t), intent(inout) :: stack\n    type(prclib_entry_t), intent(inout), pointer :: lib\n    lib%next => stack%first\n    stack%first => lib\n    lib => null ()\n    stack%n = stack%n + 1\n  end subroutine prclib_stack_push\n\n@ %def prclib_stack_push\n@\n\\subsection{Accessing Contents}\nReturn a pointer to the topmost stack element.  The result type is\njust the bare [[process_library_t]].  There is no [[target]] attribute\nrequired since the stack elements are allocated via pointers.\n<<Prclib stacks: prclib stack: TBP>>=\n  procedure :: get_first_ptr => prclib_stack_get_first_ptr\n<<Prclib stacks: procedures>>=\n  function prclib_stack_get_first_ptr (stack) result (ptr)\n    class(prclib_stack_t), intent(in) :: stack\n    type(process_library_t), pointer :: ptr\n    if (associated (stack%first)) then\n       ptr => stack%first%process_library_t\n    else\n       ptr => null ()\n    end if\n  end function prclib_stack_get_first_ptr\n\n@ %def prclib_stack_get_first_ptr\n@ Return a complete list of the libraries (names) in the stack.  The list is\nin the order in which the elements got pushed onto the stack, so the 'first'\nentry is listed last.\n<<Prclib stacks: prclib stack: TBP>>=\n  procedure :: get_names => prclib_stack_get_names\n<<Prclib stacks: procedures>>=\n  subroutine prclib_stack_get_names (stack, libname)\n    class(prclib_stack_t), intent(in) :: stack\n    type(string_t), dimension(:), allocatable, intent(out) :: libname\n    type(prclib_entry_t), pointer :: lib\n    integer :: i\n    allocate (libname (stack%n))\n    i = stack%n\n    lib => stack%first\n    do while (associated (lib))\n       libname(i) = lib%get_name ()\n       i = i - 1\n       lib => lib%next\n    end do\n  end subroutine prclib_stack_get_names\n\n@ %def prclib_stack_get_names\n@ Return a pointer to the library with given name.\n<<Prclib stacks: prclib stack: TBP>>=\n  procedure :: get_library_ptr => prclib_stack_get_library_ptr\n<<Prclib stacks: procedures>>=\n  function prclib_stack_get_library_ptr (stack, libname) result (ptr)\n    class(prclib_stack_t), intent(in) :: stack\n    type(string_t), intent(in) :: libname\n    type(process_library_t), pointer :: ptr\n    type(prclib_entry_t), pointer :: current\n    current => stack%first\n    do while (associated (current))\n       if (current%get_name () == libname) then\n          ptr => current%process_library_t\n          return\n       end if\n       current => current%next\n    end do\n    ptr => null ()\n  end function prclib_stack_get_library_ptr\n\n@ %def prclib_stack_get_library_ptr\n@\n\\subsection{Unit tests}\nTest module, followed by the corresponding implementation module.\n<<[[prclib_stacks_ut.f90]]>>=\n<<File header>>\n\nmodule prclib_stacks_ut\n  use unit_tests\n  use prclib_stacks_uti\n\n<<Standard module head>>\n\n<<Prclib stacks: public test>>\n\ncontains\n\n<<Prclib stacks: test driver>>\n\nend module prclib_stacks_ut\n@ %def prclib_stacks_ut\n@\n<<[[prclib_stacks_uti.f90]]>>=\n<<File header>>\n\nmodule prclib_stacks_uti\n\n<<Use strings>>\n\n  use prclib_stacks\n\n<<Standard module head>>\n\n<<Prclib stacks: test declarations>>\n\ncontains\n\n<<Prclib stacks: tests>>\n\nend module prclib_stacks_uti\n@ %def prclib_stacks_ut\n@ API: driver for the unit tests below.\n<<Prclib stacks: public test>>=\n  public :: prclib_stacks_test\n<<Prclib stacks: test driver>>=\n  subroutine prclib_stacks_test (u, results)\n    integer, intent(in) :: u\n    type(test_results_t), intent(inout) :: results\n  <<Prclib stacks: execute tests>>\n  end subroutine prclib_stacks_test\n\n@ %def prclib_stacks_test\n@\n\\subsubsection{Write an empty process library stack}\nThe most trivial test is to write an uninitialized process library stack.\n<<Prclib stacks: execute tests>>=\n  call test (prclib_stacks_1, \"prclib_stacks_1\", &\n       \"write an empty process library stack\", &\n       u, results)\n<<Prclib stacks: test declarations>>=\n  public :: prclib_stacks_1\n<<Prclib stacks: tests>>=\n  subroutine prclib_stacks_1 (u)\n    integer, intent(in) :: u\n    type(prclib_stack_t) :: stack\n\n    write (u, \"(A)\")  \"* Test output: prclib_stacks_1\"\n    write (u, \"(A)\")  \"*   Purpose: display an empty process library stack\"\n    write (u, \"(A)\")\n\n    call stack%write (u)\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Test output end: prclib_stacks_1\"\n\n  end subroutine prclib_stacks_1\n\n@ %def prclib_stacks_1\n@\n\\subsubsection{Fill a process library stack}\nFill a process library stack with two (identical) processes.\n<<Prclib stacks: execute tests>>=\n  call test (prclib_stacks_2, \"prclib_stacks_2\", &\n       \"fill a process library stack\", &\n       u, results)\n<<Prclib stacks: test declarations>>=\n  public :: prclib_stacks_2\n<<Prclib stacks: tests>>=\n  subroutine prclib_stacks_2 (u)\n    integer, intent(in) :: u\n    type(prclib_stack_t) :: stack\n    type(prclib_entry_t), pointer :: lib\n\n    write (u, \"(A)\")  \"* Test output: prclib_stacks_2\"\n    write (u, \"(A)\")  \"*   Purpose: fill a process library stack\"\n    write (u, \"(A)\")\n\n    write (u, \"(A)\")  \"* Initialize two (empty) libraries &\n         &and push them on the stack\"\n    write (u, \"(A)\")\n\n    allocate (lib)\n    call lib%init (var_str (\"lib1\"))\n    call stack%push (lib)\n\n    allocate (lib)\n    call lib%init (var_str (\"lib2\"))\n    call stack%push (lib)\n\n    call stack%write (u)\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Cleanup\"\n\n    call stack%final ()\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Test output end: prclib_stacks_2\"\n\n  end subroutine prclib_stacks_2\n\n@ %def prclib_stacks_2\n@\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\\section{Trivial matrix element for tests}\n\nFor the purpose of testing the workflow, we implement here two matrix\nelements with the simplest possible structure.\n\nThis matrix element generator can only generate a single scattering\nprocess and a single decay process.  The scattering process is a\nquartic interaction of a massless, neutral and colorless scalar [[s]]\nwith unit coupling results in a trivial $2\\to 2$ scattering process.\nThe matrix element is implemented internally, so we do not need the\nmachinery of external process libraries.  The decay process is a decay\nof [[s]] into a pair of colored fermions [[f]].\n\n<<[[prc_test.f90]]>>=\n<<File header>>\n\nmodule prc_test\n\n  use, intrinsic :: iso_c_binding !NODEP!\n\n<<Use kinds>>\n<<Use strings>>\n  use os_interface\n  use process_constants\n  use prclib_interfaces\n  use prc_core_def\n  use particle_specifiers, only: new_prt_spec\n  use process_libraries\n\n<<Standard module head>>\n\n<<Test ME: public>>\n\n<<Test ME: types>>\n\ncontains\n\n<<Test ME: procedures>>\n\nend module prc_test\n@ %def prc_test\n@\n\\subsection{Process definition}\nFor the process definition we implement an extension of the\n[[prc_core_def_t]] abstract type.\n<<Test ME: public>>=\n  public :: prc_test_def_t\n<<Test ME: types>>=\n  type, extends (prc_core_def_t) :: prc_test_def_t\n     type(string_t) :: model_name\n     type(string_t), dimension(:), allocatable :: prt_in\n     type(string_t), dimension(:), allocatable :: prt_out\n   contains\n   <<Test ME: test me def: TBP>>\n  end type prc_test_def_t\n\n@ %def prc_test_def_t\n<<Test ME: test me def: TBP>>=\n  procedure, nopass :: type_string => prc_test_def_type_string\n<<Test ME: procedures>>=\n  function prc_test_def_type_string () result (string)\n    type(string_t) :: string\n    string = \"test_me\"\n  end function prc_test_def_type_string\n\n@ %def prc_test_def_type_string\n@ There is no 'feature' here since there is no external code.\n<<Test ME: test me def: TBP>>=\n  procedure, nopass :: get_features => prc_test_def_get_features\n<<Test ME: procedures>>=\n  subroutine prc_test_def_get_features (features)\n    type(string_t), dimension(:), allocatable, intent(out) :: features\n    allocate (features (0))\n  end subroutine prc_test_def_get_features\n\n@ %def prc_test_def_get_features\n@ Initialization: set some data (not really useful).\n<<Test ME: test me def: TBP>>=\n  procedure :: init => prc_test_def_init\n<<Test ME: procedures>>=\n  subroutine prc_test_def_init (object, model_name, prt_in, prt_out)\n    class(prc_test_def_t), intent(out) :: object\n    type(string_t), intent(in) :: model_name\n    type(string_t), dimension(:), intent(in) :: prt_in\n    type(string_t), dimension(:), intent(in) :: prt_out\n    object%model_name = model_name\n    allocate (object%prt_in (size (prt_in)))\n    object%prt_in = prt_in\n    allocate (object%prt_out (size (prt_out)))\n    object%prt_out = prt_out\n  end subroutine prc_test_def_init\n\n@ %def prc_test_def_init\n@ Write/read process- and method-specific data.  (No-op)\n<<Test ME: test me def: TBP>>=\n  procedure :: write => prc_test_def_write\n<<Test ME: procedures>>=\n  subroutine prc_test_def_write (object, unit)\n    class(prc_test_def_t), intent(in) :: object\n    integer, intent(in) :: unit\n  end subroutine prc_test_def_write\n\n@ %def prc_test_def_write\n@\n<<Test ME: test me def: TBP>>=\n  procedure :: read => prc_test_def_read\n<<Test ME: procedures>>=\n  subroutine prc_test_def_read (object, unit)\n    class(prc_test_def_t), intent(out) :: object\n    integer, intent(in) :: unit\n  end subroutine prc_test_def_read\n\n@ %def prc_test_def_read\n@ Allocate the driver for test ME matrix elements.  We get the\nactual component ID (basename), and we can transfer all\nprocess-specific data from the process definition.\n<<Test ME: test me def: TBP>>=\n  procedure :: allocate_driver => prc_test_def_allocate_driver\n<<Test ME: procedures>>=\n  subroutine prc_test_def_allocate_driver (object, driver, basename)\n    class(prc_test_def_t), intent(in) :: object\n    class(prc_core_driver_t), intent(out), allocatable :: driver\n    type(string_t), intent(in) :: basename\n    allocate (prc_test_t :: driver)\n    select type (driver)\n    type is (prc_test_t)\n       driver%id = basename\n       driver%model_name = object%model_name\n       select case (size (object%prt_in))\n       case (1);  driver%scattering = .false.\n       case (2);  driver%scattering = .true.\n       end select\n    end select\n  end subroutine prc_test_def_allocate_driver\n\n@ %def prc_test_def_allocate_driver\n@ Nothing to connect.  This subroutine will not be called.\n<<Test ME: test me def: TBP>>=\n  procedure :: connect => prc_test_def_connect\n<<Test ME: procedures>>=\n  subroutine prc_test_def_connect (def, lib_driver, i, proc_driver)\n    class(prc_test_def_t), intent(in) :: def\n    class(prclib_driver_t), intent(in) :: lib_driver\n    integer, intent(in) :: i\n    class(prc_core_driver_t), intent(inout) :: proc_driver\n  end subroutine prc_test_def_connect\n\n@ %def prc_test_def_connect\n@\n\\subsection{Driver}\n<<Test ME: public>>=\n  public :: prc_test_t\n<<Test ME: types>>=\n  type, extends (process_driver_internal_t) :: prc_test_t\n     type(string_t) :: id\n     type(string_t) :: model_name\n     logical :: scattering = .true.\n   contains\n   <<Test ME: test me driver: TBP>>\n  end type prc_test_t\n\n@ %def prc_test_t\n@ In contrast to generic matrix-element implementations, we can\nhard-wire the amplitude method as a type-bound procedure.\n<<Test ME: test me driver: TBP>>=\n  procedure, nopass :: get_amplitude => prc_test_get_amplitude\n<<Test ME: procedures>>=\n  function prc_test_get_amplitude (p) result (amp)\n    complex(default) :: amp\n    real(default), dimension(:,:), intent(in) :: p\n    amp = 1\n  end function prc_test_get_amplitude\n\n@ %def prc_test_get_amplitude\n@ The reported type is the same as for the [[prc_test_def_t]] type.\n<<Test ME: test me driver: TBP>>=\n  procedure, nopass :: type_name => prc_test_type_name\n<<Test ME: procedures>>=\n  function prc_test_type_name () result (string)\n    type(string_t) :: string\n    string = \"test_me\"\n  end function prc_test_type_name\n\n@ %def prc_test_type_name\n@ Fill process constants.\n<<Test ME: test me driver: TBP>>=\n  procedure :: fill_constants => prc_test_fill_constants\n<<Test ME: procedures>>=\n  subroutine prc_test_fill_constants (driver, data)\n    class(prc_test_t), intent(in) :: driver\n    type(process_constants_t), intent(out) :: data\n    data%id = driver%id\n    data%model_name = driver%model_name\n    if (driver%scattering) then\n       data%n_in  = 2\n       data%n_out = 2\n       data%n_flv = 1\n       data%n_hel = 1\n       data%n_col = 1\n       data%n_cin = 2\n       data%n_cf  = 1\n       allocate (data%flv_state (4, 1))\n       data%flv_state = 25\n       allocate (data%hel_state (4, 1))\n       data%hel_state = 0\n       allocate (data%col_state (2, 4, 1))\n       data%col_state = 0\n       allocate (data%ghost_flag (4, 1))\n       data%ghost_flag = .false.\n       allocate (data%color_factors (1))\n       data%color_factors = 1\n       allocate (data%cf_index (2, 1))\n       data%cf_index = 1\n    else\n       data%n_in  = 1\n       data%n_out = 2\n       data%n_flv = 1\n       data%n_hel = 2\n       data%n_col = 1\n       data%n_cin = 2\n       data%n_cf  = 1\n       allocate (data%flv_state (3, 1))\n       data%flv_state(:,1) = [25, 6, -6]\n       allocate (data%hel_state (3, 2))\n       data%hel_state(:,1) = [0, 1,-1]\n       data%hel_state(:,2) = [0,-1, 1]\n       allocate (data%col_state (2, 3, 1))\n       data%col_state = reshape ([0,0, 1,0, 0,-1], [2,3,1])\n       allocate (data%ghost_flag (3, 1))\n       data%ghost_flag = .false.\n       allocate (data%color_factors (1))\n       data%color_factors = 3\n       allocate (data%cf_index (2, 1))\n       data%cf_index = 1\n    end if\n  end subroutine prc_test_fill_constants\n\n@ %def prc_test_fill_constants\n@\n\\subsection{Shortcut}\nSince this module is there for testing purposes, we set up a\nsubroutine that does all the work at once: create a library with the\ntwo processes (scattering and decay), configure and load, and set up\nthe driver.\n<<Test ME: public>>=\n  public :: prc_test_create_library\n<<Test ME: procedures>>=\n  subroutine prc_test_create_library &\n       (libname, lib, scattering, decay, procname1, procname2)\n    type(string_t), intent(in) :: libname\n    type(process_library_t), intent(out) :: lib\n    logical, intent(in), optional :: scattering, decay\n    type(string_t), intent(in), optional :: procname1, procname2\n    type(string_t) :: model_name, procname\n    type(string_t), dimension(:), allocatable :: prt_in, prt_out\n    class(prc_core_def_t), allocatable :: def\n    type(process_def_entry_t), pointer :: entry\n    type(os_data_t) :: os_data\n    logical :: sca, dec\n    sca = .true.;   if (present (scattering))  sca = scattering\n    dec = .false.;  if (present (decay))       dec = decay\n\n    call os_data%init ()\n    call lib%init (libname)\n    model_name = \"Test\"\n\n    if (sca) then\n       if (present (procname1)) then\n          procname = procname1\n       else\n          procname = libname\n       end if\n       allocate (prt_in (2), prt_out (2))\n       prt_in  = [var_str (\"s\"), var_str (\"s\")]\n       prt_out = [var_str (\"s\"), var_str (\"s\")]\n       allocate (prc_test_def_t :: def)\n       select type (def)\n       type is (prc_test_def_t)\n          call def%init (model_name, prt_in, prt_out)\n       end select\n       allocate (entry)\n       call entry%init (procname, model_name = model_name, &\n            n_in = 2, n_components = 1)\n       call entry%import_component (1, n_out = size (prt_out), &\n            prt_in  = new_prt_spec (prt_in), &\n            prt_out = new_prt_spec (prt_out), &\n            method  = var_str (\"test_me\"), &\n            variant = def)\n       call lib%append (entry)\n    end if\n\n    if (dec) then\n       if (present (procname2)) then\n          procname = procname2\n       else\n          procname = libname\n       end if\n       if (allocated (prt_in))  deallocate (prt_in, prt_out)\n       allocate (prt_in (1), prt_out (2))\n       prt_in  = [var_str (\"s\")]\n       prt_out = [var_str (\"f\"), var_str (\"fbar\")]\n       allocate (prc_test_def_t :: def)\n       select type (def)\n       type is (prc_test_def_t)\n          call def%init (model_name, prt_in, prt_out)\n       end select\n       allocate (entry)\n       call entry%init (procname, model_name = model_name, &\n            n_in = 1, n_components = 1)\n       call entry%import_component (1, n_out = size (prt_out), &\n            prt_in  = new_prt_spec (prt_in), &\n            prt_out = new_prt_spec (prt_out), &\n            method  = var_str (\"test_decay\"), &\n            variant = def)\n       call lib%append (entry)\n    end if\n\n    call lib%configure (os_data)\n    call lib%load (os_data)\n  end subroutine prc_test_create_library\n\n@ %def prc_test_create_library\n@\n\\subsection{Unit Test}\nTest module, followed by the corresponding implementation module.\n<<[[prc_test_ut.f90]]>>=\n<<File header>>\n\nmodule prc_test_ut\n  use unit_tests\n  use prc_test_uti\n\n<<Standard module head>>\n\n<<Test ME: public test>>\n\ncontains\n\n<<Test ME: test driver>>\n\nend module prc_test_ut\n@ %def prc_test_ut\n@\n<<[[prc_test_uti.f90]]>>=\n<<File header>>\n\nmodule prc_test_uti\n\n<<Use kinds>>\n<<Use strings>>\n  use os_interface\n  use particle_specifiers, only: new_prt_spec\n  use process_constants\n  use prc_core_def\n  use process_libraries\n\n  use prc_test\n\n<<Standard module head>>\n\n<<Test ME: test declarations>>\n\ncontains\n\n<<Test ME: tests>>\n\nend module prc_test_uti\n@ %def prc_test_ut\n@ API: driver for the unit tests below.\n<<Test ME: public test>>=\n  public :: prc_test_test\n<<Test ME: test driver>>=\n  subroutine prc_test_test (u, results)\n    integer, intent(in) :: u\n    type(test_results_t), intent(inout) :: results\n  <<Test ME: execute tests>>\nend subroutine prc_test_test\n\n@ %def prc_test_test\n@\n\\subsubsection{Generate and load the scattering process}\nThe process is $s s \\to s s$, where $s$ is a trivial scalar particle,\nfor vanishing mass and unit coupling.  We initialize the process,\nbuild the library, and compute the particular matrix element for\nmomenta of unit energy and right-angle scattering.  (The scattering is\nindependent of angle.)  The matrix element is equal to unity.\n<<Test ME: execute tests>>=\n  call test (prc_test_1, \"prc_test_1\", &\n       \"build and load trivial process\", &\n       u, results)\n<<Test ME: test declarations>>=\n  public :: prc_test_1\n<<Test ME: tests>>=\n  subroutine prc_test_1 (u)\n    integer, intent(in) :: u\n    type(os_data_t) :: os_data\n    type(process_library_t) :: lib\n    class(prc_core_def_t), allocatable :: def\n    type(process_def_entry_t), pointer :: entry\n    type(string_t) :: model_name\n    type(string_t), dimension(:), allocatable :: prt_in, prt_out\n    type(process_constants_t) :: data\n    class(prc_core_driver_t), allocatable :: driver\n    real(default), dimension(0:3,4) :: p\n    integer :: i\n\n    write (u, \"(A)\")  \"* Test output: prc_test_1\"\n    write (u, \"(A)\")  \"*   Purpose: create a trivial process\"\n    write (u, \"(A)\")  \"*            build a library and &\n         &access the matrix element\"\n    write (u, \"(A)\")\n\n    write (u, \"(A)\")  \"* Initialize a process library with one entry\"\n    write (u, \"(A)\")\n    call os_data%init ()\n    call lib%init (var_str (\"prc_test1\"))\n\n    model_name = \"Test\"\n    allocate (prt_in (2), prt_out (2))\n    prt_in  = [var_str (\"s\"), var_str (\"s\")]\n    prt_out = [var_str (\"s\"), var_str (\"s\")]\n\n    allocate (prc_test_def_t :: def)\n    select type (def)\n    type is (prc_test_def_t)\n       call def%init (model_name, prt_in, prt_out)\n    end select\n    allocate (entry)\n    call entry%init (var_str (\"prc_test1_a\"), model_name = model_name, &\n         n_in = 2, n_components = 1)\n    call entry%import_component (1, n_out = size (prt_out), &\n         prt_in  = new_prt_spec (prt_in), &\n         prt_out = new_prt_spec (prt_out), &\n         method  = var_str (\"test_me\"), &\n         variant = def)\n    call lib%append (entry)\n\n    write (u, \"(A)\")  \"* Configure library\"\n    write (u, \"(A)\")\n    call lib%configure (os_data)\n\n    write (u, \"(A)\")  \"* Load library\"\n    write (u, \"(A)\")\n    call lib%load (os_data)\n\n    call lib%write (u)\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Probe library API:\"\n    write (u, \"(A)\")\n\n    write (u, \"(1x,A,L1)\")  \"is active                 = \", &\n         lib%is_active ()\n    write (u, \"(1x,A,I0)\")  \"n_processes               = \", &\n         lib%get_n_processes ()\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Constants of prc_test1_a_i1:\"\n    write (u, \"(A)\")\n\n    call lib%connect_process (var_str (\"prc_test1_a\"), 1, data, driver)\n\n    write (u, \"(1x,A,A)\")  \"component ID     = \", char (data%id)\n    write (u, \"(1x,A,A)\")  \"model name       = \", char (data%model_name)\n    write (u, \"(1x,A,A,A)\")  \"md5sum           = '\", data%md5sum, \"'\"\n    write (u, \"(1x,A,L1)\") \"openmp supported = \", data%openmp_supported\n    write (u, \"(1x,A,I0)\") \"n_in  = \", data%n_in\n    write (u, \"(1x,A,I0)\") \"n_out = \", data%n_out\n    write (u, \"(1x,A,I0)\") \"n_flv = \", data%n_flv\n    write (u, \"(1x,A,I0)\") \"n_hel = \", data%n_hel\n    write (u, \"(1x,A,I0)\") \"n_col = \", data%n_col\n    write (u, \"(1x,A,I0)\") \"n_cin = \", data%n_cin\n    write (u, \"(1x,A,I0)\") \"n_cf  = \", data%n_cf\n    write (u, \"(1x,A,10(1x,I0))\") \"flv state =\", data%flv_state\n    write (u, \"(1x,A,10(1x,I2))\") \"hel state =\", data%hel_state(:,1)\n    write (u, \"(1x,A,10(1x,I0))\") \"col state =\", data%col_state\n    write (u, \"(1x,A,10(1x,L1))\") \"ghost flag =\", data%ghost_flag\n    write (u, \"(1x,A,10(1x,F5.3))\") \"color factors =\", data%color_factors\n    write (u, \"(1x,A,10(1x,I0))\") \"cf index =\", data%cf_index\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Set kinematics:\"\n    write (u, \"(A)\")\n\n    p = reshape ([ &\n         1.0_default, 0.0_default, 0.0_default, 1.0_default, &\n         1.0_default, 0.0_default, 0.0_default,-1.0_default, &\n         1.0_default, 1.0_default, 0.0_default, 0.0_default, &\n         1.0_default,-1.0_default, 0.0_default, 0.0_default &\n         ], [4,4])\n    do i = 1, 4\n       write (u, \"(2x,A,I0,A,4(1x,F7.4))\")  \"p\", i, \" =\", p(:,i)\n    end do\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Compute matrix element:\"\n    write (u, \"(A)\")\n\n    select type (driver)\n    type is (prc_test_t)\n       write (u, \"(1x,A,1x,E11.4)\") \"|amp| =\", abs (driver%get_amplitude (p))\n    end select\n\n    call lib%final ()\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Test output end: prc_test_1\"\n\n  end subroutine prc_test_1\n\n@ %def prc_test_1\n@\n\\subsubsection{Shortcut}\nThis is identical to the previous test, but we create the library be a single\ncommand.  This is handy for other modules which use the test process.\n<<Test ME: execute tests>>=\n  call test (prc_test_2, \"prc_test_2\", &\n       \"build and load trivial process using shortcut\", &\n       u, results)\n<<Test ME: test declarations>>=\n  public :: prc_test_2\n<<Test ME: tests>>=\n  subroutine prc_test_2 (u)\n    integer, intent(in) :: u\n    type(process_library_t) :: lib\n    class(prc_core_driver_t), allocatable :: driver\n    type(process_constants_t) :: data\n    real(default), dimension(0:3,4) :: p\n\n    write (u, \"(A)\")  \"* Test output: prc_test_2\"\n    write (u, \"(A)\")  \"*   Purpose: create a trivial process\"\n    write (u, \"(A)\")  \"*            build a library and &\n         &access the matrix element\"\n    write (u, \"(A)\")\n\n    write (u, \"(A)\")  \"* Build and load a process library with one entry\"\n\n    call prc_test_create_library (var_str (\"prc_test2\"), lib)\n    call lib%connect_process (var_str (\"prc_test2\"), 1, data, driver)\n\n    p = reshape ([ &\n         1.0_default, 0.0_default, 0.0_default, 1.0_default, &\n         1.0_default, 0.0_default, 0.0_default,-1.0_default, &\n         1.0_default, 1.0_default, 0.0_default, 0.0_default, &\n         1.0_default,-1.0_default, 0.0_default, 0.0_default &\n         ], [4,4])\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Compute matrix element:\"\n    write (u, \"(A)\")\n\n    select type (driver)\n    type is (prc_test_t)\n       write (u, \"(1x,A,1x,E11.4)\") \"|amp| =\", abs (driver%get_amplitude (p))\n    end select\n\n    call lib%final ()\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Test output end: prc_test_2\"\n\n  end subroutine prc_test_2\n\n@ %def prc_test_2\n@\n\\subsubsection{Generate and load the decay process}\nThe process is $s \\to f\\bar f$, where $s$ is a trivial scalar particle\nand $f$ is a colored fermion.  We initialize the process,\nbuild the library, and compute the particular matrix element for a\nfixed momentum configuration.  (The decay is\nindependent of angle.)  The matrix element is equal to unity.\n<<Test ME: execute tests>>=\n  call test (prc_test_3, \"prc_test_3\", &\n       \"build and load trivial decay\", &\n       u, results)\n<<Test ME: test declarations>>=\n  public :: prc_test_3\n<<Test ME: tests>>=\n  subroutine prc_test_3 (u)\n    integer, intent(in) :: u\n    type(os_data_t) :: os_data\n    type(process_library_t) :: lib\n    class(prc_core_def_t), allocatable :: def\n    type(process_def_entry_t), pointer :: entry\n    type(string_t) :: model_name\n    type(string_t), dimension(:), allocatable :: prt_in, prt_out\n    type(process_constants_t) :: data\n    class(prc_core_driver_t), allocatable :: driver\n    real(default), dimension(0:3,3) :: p\n    integer :: i\n\n    write (u, \"(A)\")  \"* Test output: prc_test_3\"\n    write (u, \"(A)\")  \"*   Purpose: create a trivial decay process\"\n    write (u, \"(A)\")  \"*            build a library and &\n         &access the matrix element\"\n    write (u, \"(A)\")\n\n    write (u, \"(A)\")  \"* Initialize a process library with one entry\"\n    write (u, \"(A)\")\n    call os_data%init ()\n    call lib%init (var_str (\"prc_test3\"))\n\n    model_name = \"Test\"\n    allocate (prt_in (1), prt_out (2))\n    prt_in  = [var_str (\"s\")]\n    prt_out = [var_str (\"f\"), var_str (\"F\")]\n\n    allocate (prc_test_def_t :: def)\n    select type (def)\n    type is (prc_test_def_t)\n       call def%init (model_name, prt_in, prt_out)\n    end select\n    allocate (entry)\n    call entry%init (var_str (\"prc_test3_a\"), model_name = model_name, &\n         n_in = 1, n_components = 1)\n    call entry%import_component (1, n_out = size (prt_out), &\n         prt_in  = new_prt_spec (prt_in), &\n         prt_out = new_prt_spec (prt_out), &\n         method  = var_str (\"test_me\"), &\n         variant = def)\n    call lib%append (entry)\n\n    write (u, \"(A)\")  \"* Configure library\"\n    write (u, \"(A)\")\n    call lib%configure (os_data)\n\n    write (u, \"(A)\")  \"* Load library\"\n    write (u, \"(A)\")\n    call lib%load (os_data)\n\n    call lib%write (u)\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Probe library API:\"\n    write (u, \"(A)\")\n\n    write (u, \"(1x,A,L1)\")  \"is active                 = \", &\n         lib%is_active ()\n    write (u, \"(1x,A,I0)\")  \"n_processes               = \", &\n         lib%get_n_processes ()\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Constants of prc_test3_a_i1:\"\n    write (u, \"(A)\")\n\n    call lib%connect_process (var_str (\"prc_test3_a\"), 1, data, driver)\n\n    write (u, \"(1x,A,A)\")  \"component ID     = \", char (data%id)\n    write (u, \"(1x,A,A)\")  \"model name       = \", char (data%model_name)\n    write (u, \"(1x,A,A,A)\")  \"md5sum           = '\", data%md5sum, \"'\"\n    write (u, \"(1x,A,L1)\") \"openmp supported = \", data%openmp_supported\n    write (u, \"(1x,A,I0)\") \"n_in  = \", data%n_in\n    write (u, \"(1x,A,I0)\") \"n_out = \", data%n_out\n    write (u, \"(1x,A,I0)\") \"n_flv = \", data%n_flv\n    write (u, \"(1x,A,I0)\") \"n_hel = \", data%n_hel\n    write (u, \"(1x,A,I0)\") \"n_col = \", data%n_col\n    write (u, \"(1x,A,I0)\") \"n_cin = \", data%n_cin\n    write (u, \"(1x,A,I0)\") \"n_cf  = \", data%n_cf\n    write (u, \"(1x,A,10(1x,I0))\") \"flv state =\", data%flv_state\n    write (u, \"(1x,A,10(1x,I2))\") \"hel state =\", data%hel_state(:,1)\n    write (u, \"(1x,A,10(1x,I2))\") \"hel state =\", data%hel_state(:,2)\n    write (u, \"(1x,A,10(1x,I0))\") \"col state =\", data%col_state\n    write (u, \"(1x,A,10(1x,L1))\") \"ghost flag =\", data%ghost_flag\n    write (u, \"(1x,A,10(1x,F5.3))\") \"color factors =\", data%color_factors\n    write (u, \"(1x,A,10(1x,I0))\") \"cf index =\", data%cf_index\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Set kinematics:\"\n    write (u, \"(A)\")\n\n    p = reshape ([ &\n         125._default, 0.0_default, 0.0_default, 0.0_default, &\n         62.5_default, 0.0_default, 0.0_default, 62.5_default, &\n         62.5_default, 0.0_default, 0.0_default,-62.5_default &\n         ], [4,3])\n    do i = 1, 3\n       write (u, \"(2x,A,I0,A,4(1x,F8.4))\")  \"p\", i, \" =\", p(:,i)\n    end do\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Compute matrix element:\"\n    write (u, \"(A)\")\n\n    select type (driver)\n    type is (prc_test_t)\n       write (u, \"(1x,A,1x,E11.4)\") \"|amp| =\", abs (driver%get_amplitude (p))\n    end select\n\n    call lib%final ()\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Test output end: prc_test_3\"\n\n  end subroutine prc_test_3\n\n@ %def prc_test_3\n@\n\\subsubsection{Shortcut}\nThis is identical to the previous test, but we create the library be a single\ncommand.  This is handy for other modules which use the test process.\n<<Test ME: execute tests>>=\n  call test (prc_test_4, \"prc_test_4\", &\n       \"build and load trivial decay using shortcut\", &\n       u, results)\n<<Test ME: test declarations>>=\n  public :: prc_test_4\n<<Test ME: tests>>=\n  subroutine prc_test_4 (u)\n    integer, intent(in) :: u\n    type(process_library_t) :: lib\n    class(prc_core_driver_t), allocatable :: driver\n    type(process_constants_t) :: data\n    real(default), dimension(0:3,3) :: p\n\n    write (u, \"(A)\")  \"* Test output: prc_test_4\"\n    write (u, \"(A)\")  \"*   Purpose: create a trivial decay process\"\n    write (u, \"(A)\")  \"*            build a library and &\n         &access the matrix element\"\n    write (u, \"(A)\")\n\n    write (u, \"(A)\")  \"* Build and load a process library with one entry\"\n\n    call prc_test_create_library (var_str (\"prc_test4\"), lib, &\n         scattering=.false., decay=.true.)\n    call lib%connect_process (var_str (\"prc_test4\"), 1, data, driver)\n\n    p = reshape ([ &\n         125._default, 0.0_default, 0.0_default, 0.0_default, &\n         62.5_default, 0.0_default, 0.0_default, 62.5_default, &\n         62.5_default, 0.0_default, 0.0_default,-62.5_default &\n         ], [4,3])\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Compute matrix element:\"\n    write (u, \"(A)\")\n\n    select type (driver)\n    type is (prc_test_t)\n       write (u, \"(1x,A,1x,E11.4)\") \"|amp| =\", abs (driver%get_amplitude (p))\n    end select\n\n    call lib%final ()\n\n    write (u, \"(A)\")\n    write (u, \"(A)\")  \"* Test output end: prc_test_4\"\n\n  end subroutine prc_test_4\n\n@ %def prc_test_4\n",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/m4/libtool.m4": "# libtool.m4 - Configure libtool for the host system. -*-Autoconf-*-\n#\n#   Copyright (C) 1996-2001, 2003-2015 Free Software Foundation, Inc.\n#   Written by Gordon Matzigkeit, 1996\n#\n# This file is free software; the Free Software Foundation gives\n# unlimited permission to copy and/or distribute it, with or without\n# modifications, as long as this notice is preserved.\n\nm4_define([_LT_COPYING], [dnl\n# Copyright (C) 2014 Free Software Foundation, Inc.\n# This is free software; see the source for copying conditions.  There is NO\n# warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\n# GNU Libtool is free software; you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation; either version 2 of of the License, or\n# (at your option) any later version.\n#\n# As a special exception to the GNU General Public License, if you\n# distribute this file as part of a program or library that is built\n# using GNU Libtool, you may include this file under the  same\n# distribution terms that you use for the rest of that program.\n#\n# GNU Libtool is distributed in the hope that it will be useful, but\n# WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program.  If not, see <http://www.gnu.org/licenses/>.\n])\n\n# serial 58 LT_INIT\n\n\n# LT_PREREQ(VERSION)\n# ------------------\n# Complain and exit if this libtool version is less that VERSION.\nm4_defun([LT_PREREQ],\n[m4_if(m4_version_compare(m4_defn([LT_PACKAGE_VERSION]), [$1]), -1,\n       [m4_default([$3],\n\t\t   [m4_fatal([Libtool version $1 or higher is required],\n\t\t             63)])],\n       [$2])])\n\n\n# _LT_CHECK_BUILDDIR\n# ------------------\n# Complain if the absolute build directory name contains unusual characters\nm4_defun([_LT_CHECK_BUILDDIR],\n[case `pwd` in\n  *\\ * | *\\\t*)\n    AC_MSG_WARN([Libtool does not cope well with whitespace in `pwd`]) ;;\nesac\n])\n\n\n# LT_INIT([OPTIONS])\n# ------------------\nAC_DEFUN([LT_INIT],\n[AC_PREREQ([2.62])dnl We use AC_PATH_PROGS_FEATURE_CHECK\nAC_REQUIRE([AC_CONFIG_AUX_DIR_DEFAULT])dnl\nAC_BEFORE([$0], [LT_LANG])dnl\nAC_BEFORE([$0], [LT_OUTPUT])dnl\nAC_BEFORE([$0], [LTDL_INIT])dnl\nm4_require([_LT_CHECK_BUILDDIR])dnl\n\ndnl Autoconf doesn't catch unexpanded LT_ macros by default:\nm4_pattern_forbid([^_?LT_[A-Z_]+$])dnl\nm4_pattern_allow([^(_LT_EOF|LT_DLGLOBAL|LT_DLLAZY_OR_NOW|LT_MULTI_MODULE)$])dnl\ndnl aclocal doesn't pull ltoptions.m4, ltsugar.m4, or ltversion.m4\ndnl unless we require an AC_DEFUNed macro:\nAC_REQUIRE([LTOPTIONS_VERSION])dnl\nAC_REQUIRE([LTSUGAR_VERSION])dnl\nAC_REQUIRE([LTVERSION_VERSION])dnl\nAC_REQUIRE([LTOBSOLETE_VERSION])dnl\nm4_require([_LT_PROG_LTMAIN])dnl\n\n_LT_SHELL_INIT([SHELL=${CONFIG_SHELL-/bin/sh}])\n\ndnl Parse OPTIONS\n_LT_SET_OPTIONS([$0], [$1])\n\n# This can be used to rebuild libtool when needed\nLIBTOOL_DEPS=$ltmain\n\n# Always use our own libtool.\nLIBTOOL='$(SHELL) $(top_builddir)/libtool'\nAC_SUBST(LIBTOOL)dnl\n\n_LT_SETUP\n\n# Only expand once:\nm4_define([LT_INIT])\n])# LT_INIT\n\n# Old names:\nAU_ALIAS([AC_PROG_LIBTOOL], [LT_INIT])\nAU_ALIAS([AM_PROG_LIBTOOL], [LT_INIT])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_PROG_LIBTOOL], [])\ndnl AC_DEFUN([AM_PROG_LIBTOOL], [])\n\n\n# _LT_PREPARE_CC_BASENAME\n# -----------------------\nm4_defun([_LT_PREPARE_CC_BASENAME], [\n# Calculate cc_basename.  Skip known compiler wrappers and cross-prefix.\nfunc_cc_basename ()\n{\n    for cc_temp in @S|@*\"\"; do\n      case $cc_temp in\n        compile | *[[\\\\/]]compile | ccache | *[[\\\\/]]ccache ) ;;\n        distcc | *[[\\\\/]]distcc | purify | *[[\\\\/]]purify ) ;;\n        \\-*) ;;\n        *) break;;\n      esac\n    done\n    func_cc_basename_result=`$ECHO \"$cc_temp\" | $SED \"s%.*/%%; s%^$host_alias-%%\"`\n}\n])# _LT_PREPARE_CC_BASENAME\n\n\n# _LT_CC_BASENAME(CC)\n# -------------------\n# It would be clearer to call AC_REQUIREs from _LT_PREPARE_CC_BASENAME,\n# but that macro is also expanded into generated libtool script, which\n# arranges for $SED and $ECHO to be set by different means.\nm4_defun([_LT_CC_BASENAME],\n[m4_require([_LT_PREPARE_CC_BASENAME])dnl\nAC_REQUIRE([_LT_DECL_SED])dnl\nAC_REQUIRE([_LT_PROG_ECHO_BACKSLASH])dnl\nfunc_cc_basename $1\ncc_basename=$func_cc_basename_result\n])\n\n\n# _LT_FILEUTILS_DEFAULTS\n# ----------------------\n# It is okay to use these file commands and assume they have been set\n# sensibly after 'm4_require([_LT_FILEUTILS_DEFAULTS])'.\nm4_defun([_LT_FILEUTILS_DEFAULTS],\n[: ${CP=\"cp -f\"}\n: ${MV=\"mv -f\"}\n: ${RM=\"rm -f\"}\n])# _LT_FILEUTILS_DEFAULTS\n\n\n# _LT_SETUP\n# ---------\nm4_defun([_LT_SETUP],\n[AC_REQUIRE([AC_CANONICAL_HOST])dnl\nAC_REQUIRE([AC_CANONICAL_BUILD])dnl\nAC_REQUIRE([_LT_PREPARE_SED_QUOTE_VARS])dnl\nAC_REQUIRE([_LT_PROG_ECHO_BACKSLASH])dnl\n\n_LT_DECL([], [PATH_SEPARATOR], [1], [The PATH separator for the build system])dnl\ndnl\n_LT_DECL([], [host_alias], [0], [The host system])dnl\n_LT_DECL([], [host], [0])dnl\n_LT_DECL([], [host_os], [0])dnl\ndnl\n_LT_DECL([], [build_alias], [0], [The build system])dnl\n_LT_DECL([], [build], [0])dnl\n_LT_DECL([], [build_os], [0])dnl\ndnl\nAC_REQUIRE([AC_PROG_CC])dnl\nAC_REQUIRE([LT_PATH_LD])dnl\nAC_REQUIRE([LT_PATH_NM])dnl\ndnl\nAC_REQUIRE([AC_PROG_LN_S])dnl\ntest -z \"$LN_S\" && LN_S=\"ln -s\"\n_LT_DECL([], [LN_S], [1], [Whether we need soft or hard links])dnl\ndnl\nAC_REQUIRE([LT_CMD_MAX_LEN])dnl\n_LT_DECL([objext], [ac_objext], [0], [Object file suffix (normally \"o\")])dnl\n_LT_DECL([], [exeext], [0], [Executable file suffix (normally \"\")])dnl\ndnl\nm4_require([_LT_FILEUTILS_DEFAULTS])dnl\nm4_require([_LT_CHECK_SHELL_FEATURES])dnl\nm4_require([_LT_PATH_CONVERSION_FUNCTIONS])dnl\nm4_require([_LT_CMD_RELOAD])dnl\nm4_require([_LT_CHECK_MAGIC_METHOD])dnl\nm4_require([_LT_CHECK_SHAREDLIB_FROM_LINKLIB])dnl\nm4_require([_LT_CMD_OLD_ARCHIVE])dnl\nm4_require([_LT_CMD_GLOBAL_SYMBOLS])dnl\nm4_require([_LT_WITH_SYSROOT])dnl\nm4_require([_LT_CMD_TRUNCATE])dnl\n\n_LT_CONFIG_LIBTOOL_INIT([\n# See if we are running on zsh, and set the options that allow our\n# commands through without removal of \\ escapes INIT.\nif test -n \"\\${ZSH_VERSION+set}\"; then\n   setopt NO_GLOB_SUBST\nfi\n])\nif test -n \"${ZSH_VERSION+set}\"; then\n   setopt NO_GLOB_SUBST\nfi\n\n_LT_CHECK_OBJDIR\n\nm4_require([_LT_TAG_COMPILER])dnl\n\ncase $host_os in\naix3*)\n  # AIX sometimes has problems with the GCC collect2 program.  For some\n  # reason, if we set the COLLECT_NAMES environment variable, the problems\n  # vanish in a puff of smoke.\n  if test set != \"${COLLECT_NAMES+set}\"; then\n    COLLECT_NAMES=\n    export COLLECT_NAMES\n  fi\n  ;;\nesac\n\n# Global variables:\nofile=libtool\ncan_build_shared=yes\n\n# All known linkers require a '.a' archive for static linking (except MSVC,\n# which needs '.lib').\nlibext=a\n\nwith_gnu_ld=$lt_cv_prog_gnu_ld\n\nold_CC=$CC\nold_CFLAGS=$CFLAGS\n\n# Set sane defaults for various variables\ntest -z \"$CC\" && CC=cc\ntest -z \"$LTCC\" && LTCC=$CC\ntest -z \"$LTCFLAGS\" && LTCFLAGS=$CFLAGS\ntest -z \"$LD\" && LD=ld\ntest -z \"$ac_objext\" && ac_objext=o\n\n_LT_CC_BASENAME([$compiler])\n\n# Only perform the check for file, if the check method requires it\ntest -z \"$MAGIC_CMD\" && MAGIC_CMD=file\ncase $deplibs_check_method in\nfile_magic*)\n  if test \"$file_magic_cmd\" = '$MAGIC_CMD'; then\n    _LT_PATH_MAGIC\n  fi\n  ;;\nesac\n\n# Use C for the default configuration in the libtool script\nLT_SUPPORTED_TAG([CC])\n_LT_LANG_C_CONFIG\n_LT_LANG_DEFAULT_CONFIG\n_LT_CONFIG_COMMANDS\n])# _LT_SETUP\n\n\n# _LT_PREPARE_SED_QUOTE_VARS\n# --------------------------\n# Define a few sed substitution that help us do robust quoting.\nm4_defun([_LT_PREPARE_SED_QUOTE_VARS],\n[# Backslashify metacharacters that are still active within\n# double-quoted strings.\nsed_quote_subst='s/\\([[\"`$\\\\]]\\)/\\\\\\1/g'\n\n# Same as above, but do not quote variable references.\ndouble_quote_subst='s/\\([[\"`\\\\]]\\)/\\\\\\1/g'\n\n# Sed substitution to delay expansion of an escaped shell variable in a\n# double_quote_subst'ed string.\ndelay_variable_subst='s/\\\\\\\\\\\\\\\\\\\\\\$/\\\\\\\\\\\\$/g'\n\n# Sed substitution to delay expansion of an escaped single quote.\ndelay_single_quote_subst='s/'\\''/'\\'\\\\\\\\\\\\\\'\\''/g'\n\n# Sed substitution to avoid accidental globbing in evaled expressions\nno_glob_subst='s/\\*/\\\\\\*/g'\n])\n\n# _LT_PROG_LTMAIN\n# ---------------\n# Note that this code is called both from 'configure', and 'config.status'\n# now that we use AC_CONFIG_COMMANDS to generate libtool.  Notably,\n# 'config.status' has no value for ac_aux_dir unless we are using Automake,\n# so we pass a copy along to make sure it has a sensible value anyway.\nm4_defun([_LT_PROG_LTMAIN],\n[m4_ifdef([AC_REQUIRE_AUX_FILE], [AC_REQUIRE_AUX_FILE([ltmain.sh])])dnl\n_LT_CONFIG_LIBTOOL_INIT([ac_aux_dir='$ac_aux_dir'])\nltmain=$ac_aux_dir/ltmain.sh\n])# _LT_PROG_LTMAIN\n\n\n## ------------------------------------- ##\n## Accumulate code for creating libtool. ##\n## ------------------------------------- ##\n\n# So that we can recreate a full libtool script including additional\n# tags, we accumulate the chunks of code to send to AC_CONFIG_COMMANDS\n# in macros and then make a single call at the end using the 'libtool'\n# label.\n\n\n# _LT_CONFIG_LIBTOOL_INIT([INIT-COMMANDS])\n# ----------------------------------------\n# Register INIT-COMMANDS to be passed to AC_CONFIG_COMMANDS later.\nm4_define([_LT_CONFIG_LIBTOOL_INIT],\n[m4_ifval([$1],\n          [m4_append([_LT_OUTPUT_LIBTOOL_INIT],\n                     [$1\n])])])\n\n# Initialize.\nm4_define([_LT_OUTPUT_LIBTOOL_INIT])\n\n\n# _LT_CONFIG_LIBTOOL([COMMANDS])\n# ------------------------------\n# Register COMMANDS to be passed to AC_CONFIG_COMMANDS later.\nm4_define([_LT_CONFIG_LIBTOOL],\n[m4_ifval([$1],\n          [m4_append([_LT_OUTPUT_LIBTOOL_COMMANDS],\n                     [$1\n])])])\n\n# Initialize.\nm4_define([_LT_OUTPUT_LIBTOOL_COMMANDS])\n\n\n# _LT_CONFIG_SAVE_COMMANDS([COMMANDS], [INIT_COMMANDS])\n# -----------------------------------------------------\nm4_defun([_LT_CONFIG_SAVE_COMMANDS],\n[_LT_CONFIG_LIBTOOL([$1])\n_LT_CONFIG_LIBTOOL_INIT([$2])\n])\n\n\n# _LT_FORMAT_COMMENT([COMMENT])\n# -----------------------------\n# Add leading comment marks to the start of each line, and a trailing\n# full-stop to the whole comment if one is not present already.\nm4_define([_LT_FORMAT_COMMENT],\n[m4_ifval([$1], [\nm4_bpatsubst([m4_bpatsubst([$1], [^ *], [# ])],\n              [['`$\\]], [\\\\\\&])]m4_bmatch([$1], [[!?.]$], [], [.])\n)])\n\n\n\n## ------------------------ ##\n## FIXME: Eliminate VARNAME ##\n## ------------------------ ##\n\n\n# _LT_DECL([CONFIGNAME], VARNAME, VALUE, [DESCRIPTION], [IS-TAGGED?])\n# -------------------------------------------------------------------\n# CONFIGNAME is the name given to the value in the libtool script.\n# VARNAME is the (base) name used in the configure script.\n# VALUE may be 0, 1 or 2 for a computed quote escaped value based on\n# VARNAME.  Any other value will be used directly.\nm4_define([_LT_DECL],\n[lt_if_append_uniq([lt_decl_varnames], [$2], [, ],\n    [lt_dict_add_subkey([lt_decl_dict], [$2], [libtool_name],\n\t[m4_ifval([$1], [$1], [$2])])\n    lt_dict_add_subkey([lt_decl_dict], [$2], [value], [$3])\n    m4_ifval([$4],\n\t[lt_dict_add_subkey([lt_decl_dict], [$2], [description], [$4])])\n    lt_dict_add_subkey([lt_decl_dict], [$2],\n\t[tagged?], [m4_ifval([$5], [yes], [no])])])\n])\n\n\n# _LT_TAGDECL([CONFIGNAME], VARNAME, VALUE, [DESCRIPTION])\n# --------------------------------------------------------\nm4_define([_LT_TAGDECL], [_LT_DECL([$1], [$2], [$3], [$4], [yes])])\n\n\n# lt_decl_tag_varnames([SEPARATOR], [VARNAME1...])\n# ------------------------------------------------\nm4_define([lt_decl_tag_varnames],\n[_lt_decl_filter([tagged?], [yes], $@)])\n\n\n# _lt_decl_filter(SUBKEY, VALUE, [SEPARATOR], [VARNAME1..])\n# ---------------------------------------------------------\nm4_define([_lt_decl_filter],\n[m4_case([$#],\n  [0], [m4_fatal([$0: too few arguments: $#])],\n  [1], [m4_fatal([$0: too few arguments: $#: $1])],\n  [2], [lt_dict_filter([lt_decl_dict], [$1], [$2], [], lt_decl_varnames)],\n  [3], [lt_dict_filter([lt_decl_dict], [$1], [$2], [$3], lt_decl_varnames)],\n  [lt_dict_filter([lt_decl_dict], $@)])[]dnl\n])\n\n\n# lt_decl_quote_varnames([SEPARATOR], [VARNAME1...])\n# --------------------------------------------------\nm4_define([lt_decl_quote_varnames],\n[_lt_decl_filter([value], [1], $@)])\n\n\n# lt_decl_dquote_varnames([SEPARATOR], [VARNAME1...])\n# ---------------------------------------------------\nm4_define([lt_decl_dquote_varnames],\n[_lt_decl_filter([value], [2], $@)])\n\n\n# lt_decl_varnames_tagged([SEPARATOR], [VARNAME1...])\n# ---------------------------------------------------\nm4_define([lt_decl_varnames_tagged],\n[m4_assert([$# <= 2])dnl\n_$0(m4_quote(m4_default([$1], [[, ]])),\n    m4_ifval([$2], [[$2]], [m4_dquote(lt_decl_tag_varnames)]),\n    m4_split(m4_normalize(m4_quote(_LT_TAGS)), [ ]))])\nm4_define([_lt_decl_varnames_tagged],\n[m4_ifval([$3], [lt_combine([$1], [$2], [_], $3)])])\n\n\n# lt_decl_all_varnames([SEPARATOR], [VARNAME1...])\n# ------------------------------------------------\nm4_define([lt_decl_all_varnames],\n[_$0(m4_quote(m4_default([$1], [[, ]])),\n     m4_if([$2], [],\n\t   m4_quote(lt_decl_varnames),\n\tm4_quote(m4_shift($@))))[]dnl\n])\nm4_define([_lt_decl_all_varnames],\n[lt_join($@, lt_decl_varnames_tagged([$1],\n\t\t\tlt_decl_tag_varnames([[, ]], m4_shift($@))))dnl\n])\n\n\n# _LT_CONFIG_STATUS_DECLARE([VARNAME])\n# ------------------------------------\n# Quote a variable value, and forward it to 'config.status' so that its\n# declaration there will have the same value as in 'configure'.  VARNAME\n# must have a single quote delimited value for this to work.\nm4_define([_LT_CONFIG_STATUS_DECLARE],\n[$1='`$ECHO \"$][$1\" | $SED \"$delay_single_quote_subst\"`'])\n\n\n# _LT_CONFIG_STATUS_DECLARATIONS\n# ------------------------------\n# We delimit libtool config variables with single quotes, so when\n# we write them to config.status, we have to be sure to quote all\n# embedded single quotes properly.  In configure, this macro expands\n# each variable declared with _LT_DECL (and _LT_TAGDECL) into:\n#\n#    <var>='`$ECHO \"$<var>\" | $SED \"$delay_single_quote_subst\"`'\nm4_defun([_LT_CONFIG_STATUS_DECLARATIONS],\n[m4_foreach([_lt_var], m4_quote(lt_decl_all_varnames),\n    [m4_n([_LT_CONFIG_STATUS_DECLARE(_lt_var)])])])\n\n\n# _LT_LIBTOOL_TAGS\n# ----------------\n# Output comment and list of tags supported by the script\nm4_defun([_LT_LIBTOOL_TAGS],\n[_LT_FORMAT_COMMENT([The names of the tagged configurations supported by this script])dnl\navailable_tags='_LT_TAGS'dnl\n])\n\n\n# _LT_LIBTOOL_DECLARE(VARNAME, [TAG])\n# -----------------------------------\n# Extract the dictionary values for VARNAME (optionally with TAG) and\n# expand to a commented shell variable setting:\n#\n#    # Some comment about what VAR is for.\n#    visible_name=$lt_internal_name\nm4_define([_LT_LIBTOOL_DECLARE],\n[_LT_FORMAT_COMMENT(m4_quote(lt_dict_fetch([lt_decl_dict], [$1],\n\t\t\t\t\t   [description])))[]dnl\nm4_pushdef([_libtool_name],\n    m4_quote(lt_dict_fetch([lt_decl_dict], [$1], [libtool_name])))[]dnl\nm4_case(m4_quote(lt_dict_fetch([lt_decl_dict], [$1], [value])),\n    [0], [_libtool_name=[$]$1],\n    [1], [_libtool_name=$lt_[]$1],\n    [2], [_libtool_name=$lt_[]$1],\n    [_libtool_name=lt_dict_fetch([lt_decl_dict], [$1], [value])])[]dnl\nm4_ifval([$2], [_$2])[]m4_popdef([_libtool_name])[]dnl\n])\n\n\n# _LT_LIBTOOL_CONFIG_VARS\n# -----------------------\n# Produce commented declarations of non-tagged libtool config variables\n# suitable for insertion in the LIBTOOL CONFIG section of the 'libtool'\n# script.  Tagged libtool config variables (even for the LIBTOOL CONFIG\n# section) are produced by _LT_LIBTOOL_TAG_VARS.\nm4_defun([_LT_LIBTOOL_CONFIG_VARS],\n[m4_foreach([_lt_var],\n    m4_quote(_lt_decl_filter([tagged?], [no], [], lt_decl_varnames)),\n    [m4_n([_LT_LIBTOOL_DECLARE(_lt_var)])])])\n\n\n# _LT_LIBTOOL_TAG_VARS(TAG)\n# -------------------------\nm4_define([_LT_LIBTOOL_TAG_VARS],\n[m4_foreach([_lt_var], m4_quote(lt_decl_tag_varnames),\n    [m4_n([_LT_LIBTOOL_DECLARE(_lt_var, [$1])])])])\n\n\n# _LT_TAGVAR(VARNAME, [TAGNAME])\n# ------------------------------\nm4_define([_LT_TAGVAR], [m4_ifval([$2], [$1_$2], [$1])])\n\n\n# _LT_CONFIG_COMMANDS\n# -------------------\n# Send accumulated output to $CONFIG_STATUS.  Thanks to the lists of\n# variables for single and double quote escaping we saved from calls\n# to _LT_DECL, we can put quote escaped variables declarations\n# into 'config.status', and then the shell code to quote escape them in\n# for loops in 'config.status'.  Finally, any additional code accumulated\n# from calls to _LT_CONFIG_LIBTOOL_INIT is expanded.\nm4_defun([_LT_CONFIG_COMMANDS],\n[AC_PROVIDE_IFELSE([LT_OUTPUT],\n\tdnl If the libtool generation code has been placed in $CONFIG_LT,\n\tdnl instead of duplicating it all over again into config.status,\n\tdnl then we will have config.status run $CONFIG_LT later, so it\n\tdnl needs to know what name is stored there:\n        [AC_CONFIG_COMMANDS([libtool],\n            [$SHELL $CONFIG_LT || AS_EXIT(1)], [CONFIG_LT='$CONFIG_LT'])],\n    dnl If the libtool generation code is destined for config.status,\n    dnl expand the accumulated commands and init code now:\n    [AC_CONFIG_COMMANDS([libtool],\n        [_LT_OUTPUT_LIBTOOL_COMMANDS], [_LT_OUTPUT_LIBTOOL_COMMANDS_INIT])])\n])#_LT_CONFIG_COMMANDS\n\n\n# Initialize.\nm4_define([_LT_OUTPUT_LIBTOOL_COMMANDS_INIT],\n[\n\n# The HP-UX ksh and POSIX shell print the target directory to stdout\n# if CDPATH is set.\n(unset CDPATH) >/dev/null 2>&1 && unset CDPATH\n\nsed_quote_subst='$sed_quote_subst'\ndouble_quote_subst='$double_quote_subst'\ndelay_variable_subst='$delay_variable_subst'\n_LT_CONFIG_STATUS_DECLARATIONS\nLTCC='$LTCC'\nLTCFLAGS='$LTCFLAGS'\ncompiler='$compiler_DEFAULT'\n\n# A function that is used when there is no print builtin or printf.\nfunc_fallback_echo ()\n{\n  eval 'cat <<_LTECHO_EOF\n\\$[]1\n_LTECHO_EOF'\n}\n\n# Quote evaled strings.\nfor var in lt_decl_all_varnames([[ \\\n]], lt_decl_quote_varnames); do\n    case \\`eval \\\\\\\\\\$ECHO \\\\\\\\\"\"\\\\\\\\\\$\\$var\"\\\\\\\\\"\\` in\n    *[[\\\\\\\\\\\\\\`\\\\\"\\\\\\$]]*)\n      eval \"lt_\\$var=\\\\\\\\\\\\\"\\\\\\`\\\\\\$ECHO \\\\\"\\\\\\$\\$var\\\\\" | \\\\\\$SED \\\\\"\\\\\\$sed_quote_subst\\\\\"\\\\\\`\\\\\\\\\\\\\"\" ## exclude from sc_prohibit_nested_quotes\n      ;;\n    *)\n      eval \"lt_\\$var=\\\\\\\\\\\\\"\\\\\\$\\$var\\\\\\\\\\\\\"\"\n      ;;\n    esac\ndone\n\n# Double-quote double-evaled strings.\nfor var in lt_decl_all_varnames([[ \\\n]], lt_decl_dquote_varnames); do\n    case \\`eval \\\\\\\\\\$ECHO \\\\\\\\\"\"\\\\\\\\\\$\\$var\"\\\\\\\\\"\\` in\n    *[[\\\\\\\\\\\\\\`\\\\\"\\\\\\$]]*)\n      eval \"lt_\\$var=\\\\\\\\\\\\\"\\\\\\`\\\\\\$ECHO \\\\\"\\\\\\$\\$var\\\\\" | \\\\\\$SED -e \\\\\"\\\\\\$double_quote_subst\\\\\" -e \\\\\"\\\\\\$sed_quote_subst\\\\\" -e \\\\\"\\\\\\$delay_variable_subst\\\\\"\\\\\\`\\\\\\\\\\\\\"\" ## exclude from sc_prohibit_nested_quotes\n      ;;\n    *)\n      eval \"lt_\\$var=\\\\\\\\\\\\\"\\\\\\$\\$var\\\\\\\\\\\\\"\"\n      ;;\n    esac\ndone\n\n_LT_OUTPUT_LIBTOOL_INIT\n])\n\n# _LT_GENERATED_FILE_INIT(FILE, [COMMENT])\n# ------------------------------------\n# Generate a child script FILE with all initialization necessary to\n# reuse the environment learned by the parent script, and make the\n# file executable.  If COMMENT is supplied, it is inserted after the\n# '#!' sequence but before initialization text begins.  After this\n# macro, additional text can be appended to FILE to form the body of\n# the child script.  The macro ends with non-zero status if the\n# file could not be fully written (such as if the disk is full).\nm4_ifdef([AS_INIT_GENERATED],\n[m4_defun([_LT_GENERATED_FILE_INIT],[AS_INIT_GENERATED($@)])],\n[m4_defun([_LT_GENERATED_FILE_INIT],\n[m4_require([AS_PREPARE])]dnl\n[m4_pushdef([AS_MESSAGE_LOG_FD])]dnl\n[lt_write_fail=0\ncat >$1 <<_ASEOF || lt_write_fail=1\n#! $SHELL\n# Generated by $as_me.\n$2\nSHELL=\\${CONFIG_SHELL-$SHELL}\nexport SHELL\n_ASEOF\ncat >>$1 <<\\_ASEOF || lt_write_fail=1\nAS_SHELL_SANITIZE\n_AS_PREPARE\nexec AS_MESSAGE_FD>&1\n_ASEOF\ntest 0 = \"$lt_write_fail\" && chmod +x $1[]dnl\nm4_popdef([AS_MESSAGE_LOG_FD])])])# _LT_GENERATED_FILE_INIT\n\n# LT_OUTPUT\n# ---------\n# This macro allows early generation of the libtool script (before\n# AC_OUTPUT is called), incase it is used in configure for compilation\n# tests.\nAC_DEFUN([LT_OUTPUT],\n[: ${CONFIG_LT=./config.lt}\nAC_MSG_NOTICE([creating $CONFIG_LT])\n_LT_GENERATED_FILE_INIT([\"$CONFIG_LT\"],\n[# Run this file to recreate a libtool stub with the current configuration.])\n\ncat >>\"$CONFIG_LT\" <<\\_LTEOF\nlt_cl_silent=false\nexec AS_MESSAGE_LOG_FD>>config.log\n{\n  echo\n  AS_BOX([Running $as_me.])\n} >&AS_MESSAGE_LOG_FD\n\nlt_cl_help=\"\\\n'$as_me' creates a local libtool stub from the current configuration,\nfor use in further configure time tests before the real libtool is\ngenerated.\n\nUsage: $[0] [[OPTIONS]]\n\n  -h, --help      print this help, then exit\n  -V, --version   print version number, then exit\n  -q, --quiet     do not print progress messages\n  -d, --debug     don't remove temporary files\n\nReport bugs to <bug-libtool@gnu.org>.\"\n\nlt_cl_version=\"\\\nm4_ifset([AC_PACKAGE_NAME], [AC_PACKAGE_NAME ])config.lt[]dnl\nm4_ifset([AC_PACKAGE_VERSION], [ AC_PACKAGE_VERSION])\nconfigured by $[0], generated by m4_PACKAGE_STRING.\n\nCopyright (C) 2011 Free Software Foundation, Inc.\nThis config.lt script is free software; the Free Software Foundation\ngives unlimited permision to copy, distribute and modify it.\"\n\nwhile test 0 != $[#]\ndo\n  case $[1] in\n    --version | --v* | -V )\n      echo \"$lt_cl_version\"; exit 0 ;;\n    --help | --h* | -h )\n      echo \"$lt_cl_help\"; exit 0 ;;\n    --debug | --d* | -d )\n      debug=: ;;\n    --quiet | --q* | --silent | --s* | -q )\n      lt_cl_silent=: ;;\n\n    -*) AC_MSG_ERROR([unrecognized option: $[1]\nTry '$[0] --help' for more information.]) ;;\n\n    *) AC_MSG_ERROR([unrecognized argument: $[1]\nTry '$[0] --help' for more information.]) ;;\n  esac\n  shift\ndone\n\nif $lt_cl_silent; then\n  exec AS_MESSAGE_FD>/dev/null\nfi\n_LTEOF\n\ncat >>\"$CONFIG_LT\" <<_LTEOF\n_LT_OUTPUT_LIBTOOL_COMMANDS_INIT\n_LTEOF\n\ncat >>\"$CONFIG_LT\" <<\\_LTEOF\nAC_MSG_NOTICE([creating $ofile])\n_LT_OUTPUT_LIBTOOL_COMMANDS\nAS_EXIT(0)\n_LTEOF\nchmod +x \"$CONFIG_LT\"\n\n# configure is writing to config.log, but config.lt does its own redirection,\n# appending to config.log, which fails on DOS, as config.log is still kept\n# open by configure.  Here we exec the FD to /dev/null, effectively closing\n# config.log, so it can be properly (re)opened and appended to by config.lt.\nlt_cl_success=:\ntest yes = \"$silent\" &&\n  lt_config_lt_args=\"$lt_config_lt_args --quiet\"\nexec AS_MESSAGE_LOG_FD>/dev/null\n$SHELL \"$CONFIG_LT\" $lt_config_lt_args || lt_cl_success=false\nexec AS_MESSAGE_LOG_FD>>config.log\n$lt_cl_success || AS_EXIT(1)\n])# LT_OUTPUT\n\n\n# _LT_CONFIG(TAG)\n# ---------------\n# If TAG is the built-in tag, create an initial libtool script with a\n# default configuration from the untagged config vars.  Otherwise add code\n# to config.status for appending the configuration named by TAG from the\n# matching tagged config vars.\nm4_defun([_LT_CONFIG],\n[m4_require([_LT_FILEUTILS_DEFAULTS])dnl\n_LT_CONFIG_SAVE_COMMANDS([\n  m4_define([_LT_TAG], m4_if([$1], [], [C], [$1]))dnl\n  m4_if(_LT_TAG, [C], [\n    # See if we are running on zsh, and set the options that allow our\n    # commands through without removal of \\ escapes.\n    if test -n \"${ZSH_VERSION+set}\"; then\n      setopt NO_GLOB_SUBST\n    fi\n\n    cfgfile=${ofile}T\n    trap \"$RM \\\"$cfgfile\\\"; exit 1\" 1 2 15\n    $RM \"$cfgfile\"\n\n    cat <<_LT_EOF >> \"$cfgfile\"\n#! $SHELL\n# Generated automatically by $as_me ($PACKAGE) $VERSION\n# Libtool was configured on host `(hostname || uname -n) 2>/dev/null | sed 1q`:\n# NOTE: Changes made to this file will be lost: look at ltmain.sh.\n\n# Provide generalized library-building support services.\n# Written by Gordon Matzigkeit, 1996\n\n_LT_COPYING\n_LT_LIBTOOL_TAGS\n\n# Configured defaults for sys_lib_dlsearch_path munging.\n: \\${LT_SYS_LIBRARY_PATH=\"$configure_time_lt_sys_library_path\"}\n\n# ### BEGIN LIBTOOL CONFIG\n_LT_LIBTOOL_CONFIG_VARS\n_LT_LIBTOOL_TAG_VARS\n# ### END LIBTOOL CONFIG\n\n_LT_EOF\n\n    cat <<'_LT_EOF' >> \"$cfgfile\"\n\n# ### BEGIN FUNCTIONS SHARED WITH CONFIGURE\n\n_LT_PREPARE_MUNGE_PATH_LIST\n_LT_PREPARE_CC_BASENAME\n\n# ### END FUNCTIONS SHARED WITH CONFIGURE\n\n_LT_EOF\n\n  case $host_os in\n  aix3*)\n    cat <<\\_LT_EOF >> \"$cfgfile\"\n# AIX sometimes has problems with the GCC collect2 program.  For some\n# reason, if we set the COLLECT_NAMES environment variable, the problems\n# vanish in a puff of smoke.\nif test set != \"${COLLECT_NAMES+set}\"; then\n  COLLECT_NAMES=\n  export COLLECT_NAMES\nfi\n_LT_EOF\n    ;;\n  esac\n\n  _LT_PROG_LTMAIN\n\n  # We use sed instead of cat because bash on DJGPP gets confused if\n  # if finds mixed CR/LF and LF-only lines.  Since sed operates in\n  # text mode, it properly converts lines to CR/LF.  This bash problem\n  # is reportedly fixed, but why not run on old versions too?\n  sed '$q' \"$ltmain\" >> \"$cfgfile\" \\\n     || (rm -f \"$cfgfile\"; exit 1)\n\n   mv -f \"$cfgfile\" \"$ofile\" ||\n    (rm -f \"$ofile\" && cp \"$cfgfile\" \"$ofile\" && rm -f \"$cfgfile\")\n  chmod +x \"$ofile\"\n],\n[cat <<_LT_EOF >> \"$ofile\"\n\ndnl Unfortunately we have to use $1 here, since _LT_TAG is not expanded\ndnl in a comment (ie after a #).\n# ### BEGIN LIBTOOL TAG CONFIG: $1\n_LT_LIBTOOL_TAG_VARS(_LT_TAG)\n# ### END LIBTOOL TAG CONFIG: $1\n_LT_EOF\n])dnl /m4_if\n],\n[m4_if([$1], [], [\n    PACKAGE='$PACKAGE'\n    VERSION='$VERSION'\n    RM='$RM'\n    ofile='$ofile'], [])\n])dnl /_LT_CONFIG_SAVE_COMMANDS\n])# _LT_CONFIG\n\n\n# LT_SUPPORTED_TAG(TAG)\n# ---------------------\n# Trace this macro to discover what tags are supported by the libtool\n# --tag option, using:\n#    autoconf --trace 'LT_SUPPORTED_TAG:$1'\nAC_DEFUN([LT_SUPPORTED_TAG], [])\n\n\n# C support is built-in for now\nm4_define([_LT_LANG_C_enabled], [])\nm4_define([_LT_TAGS], [])\n\n\n# LT_LANG(LANG)\n# -------------\n# Enable libtool support for the given language if not already enabled.\nAC_DEFUN([LT_LANG],\n[AC_BEFORE([$0], [LT_OUTPUT])dnl\nm4_case([$1],\n  [C],\t\t\t[_LT_LANG(C)],\n  [C++],\t\t[_LT_LANG(CXX)],\n  [Go],\t\t\t[_LT_LANG(GO)],\n  [Java],\t\t[_LT_LANG(GCJ)],\n  [Fortran 77],\t\t[_LT_LANG(F77)],\n  [Fortran],\t\t[_LT_LANG(FC)],\n  [Windows Resource],\t[_LT_LANG(RC)],\n  [m4_ifdef([_LT_LANG_]$1[_CONFIG],\n    [_LT_LANG($1)],\n    [m4_fatal([$0: unsupported language: \"$1\"])])])dnl\n])# LT_LANG\n\n\n# _LT_LANG(LANGNAME)\n# ------------------\nm4_defun([_LT_LANG],\n[m4_ifdef([_LT_LANG_]$1[_enabled], [],\n  [LT_SUPPORTED_TAG([$1])dnl\n  m4_append([_LT_TAGS], [$1 ])dnl\n  m4_define([_LT_LANG_]$1[_enabled], [])dnl\n  _LT_LANG_$1_CONFIG($1)])dnl\n])# _LT_LANG\n\n\nm4_ifndef([AC_PROG_GO], [\n############################################################\n# NOTE: This macro has been submitted for inclusion into   #\n#  GNU Autoconf as AC_PROG_GO.  When it is available in    #\n#  a released version of Autoconf we should remove this    #\n#  macro and use it instead.                               #\n############################################################\nm4_defun([AC_PROG_GO],\n[AC_LANG_PUSH(Go)dnl\nAC_ARG_VAR([GOC],     [Go compiler command])dnl\nAC_ARG_VAR([GOFLAGS], [Go compiler flags])dnl\n_AC_ARG_VAR_LDFLAGS()dnl\nAC_CHECK_TOOL(GOC, gccgo)\nif test -z \"$GOC\"; then\n  if test -n \"$ac_tool_prefix\"; then\n    AC_CHECK_PROG(GOC, [${ac_tool_prefix}gccgo], [${ac_tool_prefix}gccgo])\n  fi\nfi\nif test -z \"$GOC\"; then\n  AC_CHECK_PROG(GOC, gccgo, gccgo, false)\nfi\n])#m4_defun\n])#m4_ifndef\n\n\n# _LT_LANG_DEFAULT_CONFIG\n# -----------------------\nm4_defun([_LT_LANG_DEFAULT_CONFIG],\n[AC_PROVIDE_IFELSE([AC_PROG_CXX],\n  [LT_LANG(CXX)],\n  [m4_define([AC_PROG_CXX], defn([AC_PROG_CXX])[LT_LANG(CXX)])])\n\nAC_PROVIDE_IFELSE([AC_PROG_F77],\n  [LT_LANG(F77)],\n  [m4_define([AC_PROG_F77], defn([AC_PROG_F77])[LT_LANG(F77)])])\n\nAC_PROVIDE_IFELSE([AC_PROG_FC],\n  [LT_LANG(FC)],\n  [m4_define([AC_PROG_FC], defn([AC_PROG_FC])[LT_LANG(FC)])])\n\ndnl The call to [A][M_PROG_GCJ] is quoted like that to stop aclocal\ndnl pulling things in needlessly.\nAC_PROVIDE_IFELSE([AC_PROG_GCJ],\n  [LT_LANG(GCJ)],\n  [AC_PROVIDE_IFELSE([A][M_PROG_GCJ],\n    [LT_LANG(GCJ)],\n    [AC_PROVIDE_IFELSE([LT_PROG_GCJ],\n      [LT_LANG(GCJ)],\n      [m4_ifdef([AC_PROG_GCJ],\n\t[m4_define([AC_PROG_GCJ], defn([AC_PROG_GCJ])[LT_LANG(GCJ)])])\n       m4_ifdef([A][M_PROG_GCJ],\n\t[m4_define([A][M_PROG_GCJ], defn([A][M_PROG_GCJ])[LT_LANG(GCJ)])])\n       m4_ifdef([LT_PROG_GCJ],\n\t[m4_define([LT_PROG_GCJ], defn([LT_PROG_GCJ])[LT_LANG(GCJ)])])])])])\n\nAC_PROVIDE_IFELSE([AC_PROG_GO],\n  [LT_LANG(GO)],\n  [m4_define([AC_PROG_GO], defn([AC_PROG_GO])[LT_LANG(GO)])])\n\nAC_PROVIDE_IFELSE([LT_PROG_RC],\n  [LT_LANG(RC)],\n  [m4_define([LT_PROG_RC], defn([LT_PROG_RC])[LT_LANG(RC)])])\n])# _LT_LANG_DEFAULT_CONFIG\n\n# Obsolete macros:\nAU_DEFUN([AC_LIBTOOL_CXX], [LT_LANG(C++)])\nAU_DEFUN([AC_LIBTOOL_F77], [LT_LANG(Fortran 77)])\nAU_DEFUN([AC_LIBTOOL_FC], [LT_LANG(Fortran)])\nAU_DEFUN([AC_LIBTOOL_GCJ], [LT_LANG(Java)])\nAU_DEFUN([AC_LIBTOOL_RC], [LT_LANG(Windows Resource)])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_LIBTOOL_CXX], [])\ndnl AC_DEFUN([AC_LIBTOOL_F77], [])\ndnl AC_DEFUN([AC_LIBTOOL_FC], [])\ndnl AC_DEFUN([AC_LIBTOOL_GCJ], [])\ndnl AC_DEFUN([AC_LIBTOOL_RC], [])\n\n\n# _LT_TAG_COMPILER\n# ----------------\nm4_defun([_LT_TAG_COMPILER],\n[AC_REQUIRE([AC_PROG_CC])dnl\n\n_LT_DECL([LTCC], [CC], [1], [A C compiler])dnl\n_LT_DECL([LTCFLAGS], [CFLAGS], [1], [LTCC compiler flags])dnl\n_LT_TAGDECL([CC], [compiler], [1], [A language specific compiler])dnl\n_LT_TAGDECL([with_gcc], [GCC], [0], [Is the compiler the GNU compiler?])dnl\n\n# If no C compiler was specified, use CC.\nLTCC=${LTCC-\"$CC\"}\n\n# If no C compiler flags were specified, use CFLAGS.\nLTCFLAGS=${LTCFLAGS-\"$CFLAGS\"}\n\n# Allow CC to be a program name with arguments.\ncompiler=$CC\n])# _LT_TAG_COMPILER\n\n\n# _LT_COMPILER_BOILERPLATE\n# ------------------------\n# Check for compiler boilerplate output or warnings with\n# the simple compiler test code.\nm4_defun([_LT_COMPILER_BOILERPLATE],\n[m4_require([_LT_DECL_SED])dnl\nac_outfile=conftest.$ac_objext\necho \"$lt_simple_compile_test_code\" >conftest.$ac_ext\neval \"$ac_compile\" 2>&1 >/dev/null | $SED '/^$/d; /^ *+/d' >conftest.err\n_lt_compiler_boilerplate=`cat conftest.err`\n$RM conftest*\n])# _LT_COMPILER_BOILERPLATE\n\n\n# _LT_LINKER_BOILERPLATE\n# ----------------------\n# Check for linker boilerplate output or warnings with\n# the simple link test code.\nm4_defun([_LT_LINKER_BOILERPLATE],\n[m4_require([_LT_DECL_SED])dnl\nac_outfile=conftest.$ac_objext\necho \"$lt_simple_link_test_code\" >conftest.$ac_ext\neval \"$ac_link\" 2>&1 >/dev/null | $SED '/^$/d; /^ *+/d' >conftest.err\n_lt_linker_boilerplate=`cat conftest.err`\n$RM -r conftest*\n])# _LT_LINKER_BOILERPLATE\n\n# _LT_REQUIRED_DARWIN_CHECKS\n# -------------------------\nm4_defun_once([_LT_REQUIRED_DARWIN_CHECKS],[\n  case $host_os in\n    rhapsody* | darwin*)\n    AC_CHECK_TOOL([DSYMUTIL], [dsymutil], [:])\n    AC_CHECK_TOOL([NMEDIT], [nmedit], [:])\n    AC_CHECK_TOOL([LIPO], [lipo], [:])\n    AC_CHECK_TOOL([OTOOL], [otool], [:])\n    AC_CHECK_TOOL([OTOOL64], [otool64], [:])\n    _LT_DECL([], [DSYMUTIL], [1],\n      [Tool to manipulate archived DWARF debug symbol files on Mac OS X])\n    _LT_DECL([], [NMEDIT], [1],\n      [Tool to change global to local symbols on Mac OS X])\n    _LT_DECL([], [LIPO], [1],\n      [Tool to manipulate fat objects and archives on Mac OS X])\n    _LT_DECL([], [OTOOL], [1],\n      [ldd/readelf like tool for Mach-O binaries on Mac OS X])\n    _LT_DECL([], [OTOOL64], [1],\n      [ldd/readelf like tool for 64 bit Mach-O binaries on Mac OS X 10.4])\n\n    AC_CACHE_CHECK([for -single_module linker flag],[lt_cv_apple_cc_single_mod],\n      [lt_cv_apple_cc_single_mod=no\n      if test -z \"$LT_MULTI_MODULE\"; then\n\t# By default we will add the -single_module flag. You can override\n\t# by either setting the environment variable LT_MULTI_MODULE\n\t# non-empty at configure time, or by adding -multi_module to the\n\t# link flags.\n\trm -rf libconftest.dylib*\n\techo \"int foo(void){return 1;}\" > conftest.c\n\techo \"$LTCC $LTCFLAGS $LDFLAGS -o libconftest.dylib \\\n-dynamiclib -Wl,-single_module conftest.c\" >&AS_MESSAGE_LOG_FD\n\t$LTCC $LTCFLAGS $LDFLAGS -o libconftest.dylib \\\n\t  -dynamiclib -Wl,-single_module conftest.c 2>conftest.err\n        _lt_result=$?\n\t# If there is a non-empty error log, and \"single_module\"\n\t# appears in it, assume the flag caused a linker warning\n        if test -s conftest.err && $GREP single_module conftest.err; then\n\t  cat conftest.err >&AS_MESSAGE_LOG_FD\n\t# Otherwise, if the output was created with a 0 exit code from\n\t# the compiler, it worked.\n\telif test -f libconftest.dylib && test 0 = \"$_lt_result\"; then\n\t  lt_cv_apple_cc_single_mod=yes\n\telse\n\t  cat conftest.err >&AS_MESSAGE_LOG_FD\n\tfi\n\trm -rf libconftest.dylib*\n\trm -f conftest.*\n      fi])\n\n    AC_CACHE_CHECK([for -exported_symbols_list linker flag],\n      [lt_cv_ld_exported_symbols_list],\n      [lt_cv_ld_exported_symbols_list=no\n      save_LDFLAGS=$LDFLAGS\n      echo \"_main\" > conftest.sym\n      LDFLAGS=\"$LDFLAGS -Wl,-exported_symbols_list,conftest.sym\"\n      AC_LINK_IFELSE([AC_LANG_PROGRAM([],[])],\n\t[lt_cv_ld_exported_symbols_list=yes],\n\t[lt_cv_ld_exported_symbols_list=no])\n\tLDFLAGS=$save_LDFLAGS\n    ])\n\n    AC_CACHE_CHECK([for -force_load linker flag],[lt_cv_ld_force_load],\n      [lt_cv_ld_force_load=no\n      cat > conftest.c << _LT_EOF\nint forced_loaded() { return 2;}\n_LT_EOF\n      echo \"$LTCC $LTCFLAGS -c -o conftest.o conftest.c\" >&AS_MESSAGE_LOG_FD\n      $LTCC $LTCFLAGS -c -o conftest.o conftest.c 2>&AS_MESSAGE_LOG_FD\n      echo \"$AR cru libconftest.a conftest.o\" >&AS_MESSAGE_LOG_FD\n      $AR cru libconftest.a conftest.o 2>&AS_MESSAGE_LOG_FD\n      echo \"$RANLIB libconftest.a\" >&AS_MESSAGE_LOG_FD\n      $RANLIB libconftest.a 2>&AS_MESSAGE_LOG_FD\n      cat > conftest.c << _LT_EOF\nint main() { return 0;}\n_LT_EOF\n      echo \"$LTCC $LTCFLAGS $LDFLAGS -o conftest conftest.c -Wl,-force_load,./libconftest.a\" >&AS_MESSAGE_LOG_FD\n      $LTCC $LTCFLAGS $LDFLAGS -o conftest conftest.c -Wl,-force_load,./libconftest.a 2>conftest.err\n      _lt_result=$?\n      if test -s conftest.err && $GREP force_load conftest.err; then\n\tcat conftest.err >&AS_MESSAGE_LOG_FD\n      elif test -f conftest && test 0 = \"$_lt_result\" && $GREP forced_load conftest >/dev/null 2>&1; then\n\tlt_cv_ld_force_load=yes\n      else\n\tcat conftest.err >&AS_MESSAGE_LOG_FD\n      fi\n        rm -f conftest.err libconftest.a conftest conftest.c\n        rm -rf conftest.dSYM\n    ])\n    case $host_os in\n    rhapsody* | darwin1.[[012]])\n      _lt_dar_allow_undefined='$wl-undefined ${wl}suppress' ;;\n    darwin1.*)\n      _lt_dar_allow_undefined='$wl-flat_namespace $wl-undefined ${wl}suppress' ;;\n    darwin*) # darwin 5.x on\n      # if running on 10.5 or later, the deployment target defaults\n      # to the OS version, if on x86, and 10.4, the deployment\n      # target defaults to 10.4. Don't you love it?\n      case ${MACOSX_DEPLOYMENT_TARGET-10.0},$host in\n\t10.0,*86*-darwin8*|10.0,*-darwin[[912]]*)\n\t  _lt_dar_allow_undefined='$wl-undefined ${wl}dynamic_lookup' ;;\n\t10.[[012]][[,.]]*)\n\t  _lt_dar_allow_undefined='$wl-flat_namespace $wl-undefined ${wl}suppress' ;;\n\t10.*|11.*)\n\t  _lt_dar_allow_undefined='$wl-undefined ${wl}dynamic_lookup' ;;\n      esac\n    ;;\n  esac\n    if test yes = \"$lt_cv_apple_cc_single_mod\"; then\n      _lt_dar_single_mod='$single_module'\n    fi\n    if test yes = \"$lt_cv_ld_exported_symbols_list\"; then\n      _lt_dar_export_syms=' $wl-exported_symbols_list,$output_objdir/$libname-symbols.expsym'\n    else\n      _lt_dar_export_syms='~$NMEDIT -s $output_objdir/$libname-symbols.expsym $lib'\n    fi\n    if test : != \"$DSYMUTIL\" && test no = \"$lt_cv_ld_force_load\"; then\n      _lt_dsymutil='~$DSYMUTIL $lib || :'\n    else\n      _lt_dsymutil=\n    fi\n    ;;\n  esac\n])\n\n\n# _LT_DARWIN_LINKER_FEATURES([TAG])\n# ---------------------------------\n# Checks for linker and compiler features on darwin\nm4_defun([_LT_DARWIN_LINKER_FEATURES],\n[\n  m4_require([_LT_REQUIRED_DARWIN_CHECKS])\n  _LT_TAGVAR(archive_cmds_need_lc, $1)=no\n  _LT_TAGVAR(hardcode_direct, $1)=no\n  _LT_TAGVAR(hardcode_automatic, $1)=yes\n  _LT_TAGVAR(hardcode_shlibpath_var, $1)=unsupported\n  if test yes = \"$lt_cv_ld_force_load\"; then\n    _LT_TAGVAR(whole_archive_flag_spec, $1)='`for conv in $convenience\\\"\\\"; do test  -n \\\"$conv\\\" && new_convenience=\\\"$new_convenience $wl-force_load,$conv\\\"; done; func_echo_all \\\"$new_convenience\\\"`'\n    m4_case([$1], [F77], [_LT_TAGVAR(compiler_needs_object, $1)=yes],\n                  [FC],  [_LT_TAGVAR(compiler_needs_object, $1)=yes])\n  else\n    _LT_TAGVAR(whole_archive_flag_spec, $1)=''\n  fi\n  _LT_TAGVAR(link_all_deplibs, $1)=yes\n  _LT_TAGVAR(allow_undefined_flag, $1)=$_lt_dar_allow_undefined\n  case $cc_basename in\n     ifort*|nagfor*) _lt_dar_can_shared=yes ;;\n     *) _lt_dar_can_shared=$GCC ;;\n  esac\n  if test yes = \"$_lt_dar_can_shared\"; then\n    output_verbose_link_cmd=func_echo_all\n    _LT_TAGVAR(archive_cmds, $1)=\"\\$CC -dynamiclib \\$allow_undefined_flag -o \\$lib \\$libobjs \\$deplibs \\$compiler_flags -install_name \\$rpath/\\$soname \\$verstring $_lt_dar_single_mod$_lt_dsymutil\"\n    _LT_TAGVAR(module_cmds, $1)=\"\\$CC \\$allow_undefined_flag -o \\$lib -bundle \\$libobjs \\$deplibs \\$compiler_flags$_lt_dsymutil\"\n    _LT_TAGVAR(archive_expsym_cmds, $1)=\"sed 's|^|_|' < \\$export_symbols > \\$output_objdir/\\$libname-symbols.expsym~\\$CC -dynamiclib \\$allow_undefined_flag -o \\$lib \\$libobjs \\$deplibs \\$compiler_flags -install_name \\$rpath/\\$soname \\$verstring $_lt_dar_single_mod$_lt_dar_export_syms$_lt_dsymutil\"\n    _LT_TAGVAR(module_expsym_cmds, $1)=\"sed -e 's|^|_|' < \\$export_symbols > \\$output_objdir/\\$libname-symbols.expsym~\\$CC \\$allow_undefined_flag -o \\$lib -bundle \\$libobjs \\$deplibs \\$compiler_flags$_lt_dar_export_syms$_lt_dsymutil\"\n    m4_if([$1], [CXX],\n[   if test yes != \"$lt_cv_apple_cc_single_mod\"; then\n      _LT_TAGVAR(archive_cmds, $1)=\"\\$CC -r -keep_private_externs -nostdlib -o \\$lib-master.o \\$libobjs~\\$CC -dynamiclib \\$allow_undefined_flag -o \\$lib \\$lib-master.o \\$deplibs \\$compiler_flags -install_name \\$rpath/\\$soname \\$verstring$_lt_dsymutil\"\n      _LT_TAGVAR(archive_expsym_cmds, $1)=\"sed 's|^|_|' < \\$export_symbols > \\$output_objdir/\\$libname-symbols.expsym~\\$CC -r -keep_private_externs -nostdlib -o \\$lib-master.o \\$libobjs~\\$CC -dynamiclib \\$allow_undefined_flag -o \\$lib \\$lib-master.o \\$deplibs \\$compiler_flags -install_name \\$rpath/\\$soname \\$verstring$_lt_dar_export_syms$_lt_dsymutil\"\n    fi\n],[])\n  else\n  _LT_TAGVAR(ld_shlibs, $1)=no\n  fi\n])\n\n# _LT_SYS_MODULE_PATH_AIX([TAGNAME])\n# ----------------------------------\n# Links a minimal program and checks the executable\n# for the system default hardcoded library path. In most cases,\n# this is /usr/lib:/lib, but when the MPI compilers are used\n# the location of the communication and MPI libs are included too.\n# If we don't find anything, use the default library path according\n# to the aix ld manual.\n# Store the results from the different compilers for each TAGNAME.\n# Allow to override them for all tags through lt_cv_aix_libpath.\nm4_defun([_LT_SYS_MODULE_PATH_AIX],\n[m4_require([_LT_DECL_SED])dnl\nif test set = \"${lt_cv_aix_libpath+set}\"; then\n  aix_libpath=$lt_cv_aix_libpath\nelse\n  AC_CACHE_VAL([_LT_TAGVAR([lt_cv_aix_libpath_], [$1])],\n  [AC_LINK_IFELSE([AC_LANG_PROGRAM],[\n  lt_aix_libpath_sed='[\n      /Import File Strings/,/^$/ {\n\t  /^0/ {\n\t      s/^0  *\\([^ ]*\\) *$/\\1/\n\t      p\n\t  }\n      }]'\n  _LT_TAGVAR([lt_cv_aix_libpath_], [$1])=`dump -H conftest$ac_exeext 2>/dev/null | $SED -n -e \"$lt_aix_libpath_sed\"`\n  # Check for a 64-bit object if we didn't find anything.\n  if test -z \"$_LT_TAGVAR([lt_cv_aix_libpath_], [$1])\"; then\n    _LT_TAGVAR([lt_cv_aix_libpath_], [$1])=`dump -HX64 conftest$ac_exeext 2>/dev/null | $SED -n -e \"$lt_aix_libpath_sed\"`\n  fi],[])\n  if test -z \"$_LT_TAGVAR([lt_cv_aix_libpath_], [$1])\"; then\n    _LT_TAGVAR([lt_cv_aix_libpath_], [$1])=/usr/lib:/lib\n  fi\n  ])\n  aix_libpath=$_LT_TAGVAR([lt_cv_aix_libpath_], [$1])\nfi\n])# _LT_SYS_MODULE_PATH_AIX\n\n\n# _LT_SHELL_INIT(ARG)\n# -------------------\nm4_define([_LT_SHELL_INIT],\n[m4_divert_text([M4SH-INIT], [$1\n])])# _LT_SHELL_INIT\n\n\n\n# _LT_PROG_ECHO_BACKSLASH\n# -----------------------\n# Find how we can fake an echo command that does not interpret backslash.\n# In particular, with Autoconf 2.60 or later we add some code to the start\n# of the generated configure script that will find a shell with a builtin\n# printf (that we can use as an echo command).\nm4_defun([_LT_PROG_ECHO_BACKSLASH],\n[ECHO='\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'\nECHO=$ECHO$ECHO$ECHO$ECHO$ECHO\nECHO=$ECHO$ECHO$ECHO$ECHO$ECHO$ECHO\n\nAC_MSG_CHECKING([how to print strings])\n# Test print first, because it will be a builtin if present.\nif test \"X`( print -r -- -n ) 2>/dev/null`\" = X-n && \\\n   test \"X`print -r -- $ECHO 2>/dev/null`\" = \"X$ECHO\"; then\n  ECHO='print -r --'\nelif test \"X`printf %s $ECHO 2>/dev/null`\" = \"X$ECHO\"; then\n  ECHO='printf %s\\n'\nelse\n  # Use this function as a fallback that always works.\n  func_fallback_echo ()\n  {\n    eval 'cat <<_LTECHO_EOF\n$[]1\n_LTECHO_EOF'\n  }\n  ECHO='func_fallback_echo'\nfi\n\n# func_echo_all arg...\n# Invoke $ECHO with all args, space-separated.\nfunc_echo_all ()\n{\n    $ECHO \"$*\"\n}\n\ncase $ECHO in\n  printf*) AC_MSG_RESULT([printf]) ;;\n  print*) AC_MSG_RESULT([print -r]) ;;\n  *) AC_MSG_RESULT([cat]) ;;\nesac\n\nm4_ifdef([_AS_DETECT_SUGGESTED],\n[_AS_DETECT_SUGGESTED([\n  test -n \"${ZSH_VERSION+set}${BASH_VERSION+set}\" || (\n    ECHO='\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'\n    ECHO=$ECHO$ECHO$ECHO$ECHO$ECHO\n    ECHO=$ECHO$ECHO$ECHO$ECHO$ECHO$ECHO\n    PATH=/empty FPATH=/empty; export PATH FPATH\n    test \"X`printf %s $ECHO`\" = \"X$ECHO\" \\\n      || test \"X`print -r -- $ECHO`\" = \"X$ECHO\" )])])\n\n_LT_DECL([], [SHELL], [1], [Shell to use when invoking shell scripts])\n_LT_DECL([], [ECHO], [1], [An echo program that protects backslashes])\n])# _LT_PROG_ECHO_BACKSLASH\n\n\n# _LT_WITH_SYSROOT\n# ----------------\nAC_DEFUN([_LT_WITH_SYSROOT],\n[AC_MSG_CHECKING([for sysroot])\nAC_ARG_WITH([sysroot],\n[AS_HELP_STRING([--with-sysroot@<:@=DIR@:>@],\n  [Search for dependent libraries within DIR (or the compiler's sysroot\n   if not specified).])],\n[], [with_sysroot=no])\n\ndnl lt_sysroot will always be passed unquoted.  We quote it here\ndnl in case the user passed a directory name.\nlt_sysroot=\ncase $with_sysroot in #(\n yes)\n   if test yes = \"$GCC\"; then\n     lt_sysroot=`$CC --print-sysroot 2>/dev/null`\n   fi\n   ;; #(\n /*)\n   lt_sysroot=`echo \"$with_sysroot\" | sed -e \"$sed_quote_subst\"`\n   ;; #(\n no|'')\n   ;; #(\n *)\n   AC_MSG_RESULT([$with_sysroot])\n   AC_MSG_ERROR([The sysroot must be an absolute path.])\n   ;;\nesac\n\n AC_MSG_RESULT([${lt_sysroot:-no}])\n_LT_DECL([], [lt_sysroot], [0], [The root where to search for ]dnl\n[dependent libraries, and where our libraries should be installed.])])\n\n# _LT_ENABLE_LOCK\n# ---------------\nm4_defun([_LT_ENABLE_LOCK],\n[AC_ARG_ENABLE([libtool-lock],\n  [AS_HELP_STRING([--disable-libtool-lock],\n    [avoid locking (might break parallel builds)])])\ntest no = \"$enable_libtool_lock\" || enable_libtool_lock=yes\n\n# Some flags need to be propagated to the compiler or linker for good\n# libtool support.\ncase $host in\nia64-*-hpux*)\n  # Find out what ABI is being produced by ac_compile, and set mode\n  # options accordingly.\n  echo 'int i;' > conftest.$ac_ext\n  if AC_TRY_EVAL(ac_compile); then\n    case `/usr/bin/file conftest.$ac_objext` in\n      *ELF-32*)\n\tHPUX_IA64_MODE=32\n\t;;\n      *ELF-64*)\n\tHPUX_IA64_MODE=64\n\t;;\n    esac\n  fi\n  rm -rf conftest*\n  ;;\n*-*-irix6*)\n  # Find out what ABI is being produced by ac_compile, and set linker\n  # options accordingly.\n  echo '[#]line '$LINENO' \"configure\"' > conftest.$ac_ext\n  if AC_TRY_EVAL(ac_compile); then\n    if test yes = \"$lt_cv_prog_gnu_ld\"; then\n      case `/usr/bin/file conftest.$ac_objext` in\n\t*32-bit*)\n\t  LD=\"${LD-ld} -melf32bsmip\"\n\t  ;;\n\t*N32*)\n\t  LD=\"${LD-ld} -melf32bmipn32\"\n\t  ;;\n\t*64-bit*)\n\t  LD=\"${LD-ld} -melf64bmip\"\n\t;;\n      esac\n    else\n      case `/usr/bin/file conftest.$ac_objext` in\n\t*32-bit*)\n\t  LD=\"${LD-ld} -32\"\n\t  ;;\n\t*N32*)\n\t  LD=\"${LD-ld} -n32\"\n\t  ;;\n\t*64-bit*)\n\t  LD=\"${LD-ld} -64\"\n\t  ;;\n      esac\n    fi\n  fi\n  rm -rf conftest*\n  ;;\n\nmips64*-*linux*)\n  # Find out what ABI is being produced by ac_compile, and set linker\n  # options accordingly.\n  echo '[#]line '$LINENO' \"configure\"' > conftest.$ac_ext\n  if AC_TRY_EVAL(ac_compile); then\n    emul=elf\n    case `/usr/bin/file conftest.$ac_objext` in\n      *32-bit*)\n\temul=\"${emul}32\"\n\t;;\n      *64-bit*)\n\temul=\"${emul}64\"\n\t;;\n    esac\n    case `/usr/bin/file conftest.$ac_objext` in\n      *MSB*)\n\temul=\"${emul}btsmip\"\n\t;;\n      *LSB*)\n\temul=\"${emul}ltsmip\"\n\t;;\n    esac\n    case `/usr/bin/file conftest.$ac_objext` in\n      *N32*)\n\temul=\"${emul}n32\"\n\t;;\n    esac\n    LD=\"${LD-ld} -m $emul\"\n  fi\n  rm -rf conftest*\n  ;;\n\nx86_64-*kfreebsd*-gnu|x86_64-*linux*|powerpc*-*linux*| \\\ns390*-*linux*|s390*-*tpf*|sparc*-*linux*)\n  # Find out what ABI is being produced by ac_compile, and set linker\n  # options accordingly.  Note that the listed cases only cover the\n  # situations where additional linker options are needed (such as when\n  # doing 32-bit compilation for a host where ld defaults to 64-bit, or\n  # vice versa); the common cases where no linker options are needed do\n  # not appear in the list.\n  echo 'int i;' > conftest.$ac_ext\n  if AC_TRY_EVAL(ac_compile); then\n    case `/usr/bin/file conftest.o` in\n      *32-bit*)\n\tcase $host in\n\t  x86_64-*kfreebsd*-gnu)\n\t    LD=\"${LD-ld} -m elf_i386_fbsd\"\n\t    ;;\n\t  x86_64-*linux*)\n\t    case `/usr/bin/file conftest.o` in\n\t      *x86-64*)\n\t\tLD=\"${LD-ld} -m elf32_x86_64\"\n\t\t;;\n\t      *)\n\t\tLD=\"${LD-ld} -m elf_i386\"\n\t\t;;\n\t    esac\n\t    ;;\n\t  powerpc64le-*linux*)\n\t    LD=\"${LD-ld} -m elf32lppclinux\"\n\t    ;;\n\t  powerpc64-*linux*)\n\t    LD=\"${LD-ld} -m elf32ppclinux\"\n\t    ;;\n\t  s390x-*linux*)\n\t    LD=\"${LD-ld} -m elf_s390\"\n\t    ;;\n\t  sparc64-*linux*)\n\t    LD=\"${LD-ld} -m elf32_sparc\"\n\t    ;;\n\tesac\n\t;;\n      *64-bit*)\n\tcase $host in\n\t  x86_64-*kfreebsd*-gnu)\n\t    LD=\"${LD-ld} -m elf_x86_64_fbsd\"\n\t    ;;\n\t  x86_64-*linux*)\n\t    LD=\"${LD-ld} -m elf_x86_64\"\n\t    ;;\n\t  powerpcle-*linux*)\n\t    LD=\"${LD-ld} -m elf64lppc\"\n\t    ;;\n\t  powerpc-*linux*)\n\t    LD=\"${LD-ld} -m elf64ppc\"\n\t    ;;\n\t  s390*-*linux*|s390*-*tpf*)\n\t    LD=\"${LD-ld} -m elf64_s390\"\n\t    ;;\n\t  sparc*-*linux*)\n\t    LD=\"${LD-ld} -m elf64_sparc\"\n\t    ;;\n\tesac\n\t;;\n    esac\n  fi\n  rm -rf conftest*\n  ;;\n\n*-*-sco3.2v5*)\n  # On SCO OpenServer 5, we need -belf to get full-featured binaries.\n  SAVE_CFLAGS=$CFLAGS\n  CFLAGS=\"$CFLAGS -belf\"\n  AC_CACHE_CHECK([whether the C compiler needs -belf], lt_cv_cc_needs_belf,\n    [AC_LANG_PUSH(C)\n     AC_LINK_IFELSE([AC_LANG_PROGRAM([[]],[[]])],[lt_cv_cc_needs_belf=yes],[lt_cv_cc_needs_belf=no])\n     AC_LANG_POP])\n  if test yes != \"$lt_cv_cc_needs_belf\"; then\n    # this is probably gcc 2.8.0, egcs 1.0 or newer; no need for -belf\n    CFLAGS=$SAVE_CFLAGS\n  fi\n  ;;\n*-*solaris*)\n  # Find out what ABI is being produced by ac_compile, and set linker\n  # options accordingly.\n  echo 'int i;' > conftest.$ac_ext\n  if AC_TRY_EVAL(ac_compile); then\n    case `/usr/bin/file conftest.o` in\n    *64-bit*)\n      case $lt_cv_prog_gnu_ld in\n      yes*)\n        case $host in\n        i?86-*-solaris*|x86_64-*-solaris*)\n          LD=\"${LD-ld} -m elf_x86_64\"\n          ;;\n        sparc*-*-solaris*)\n          LD=\"${LD-ld} -m elf64_sparc\"\n          ;;\n        esac\n        # GNU ld 2.21 introduced _sol2 emulations.  Use them if available.\n        if ${LD-ld} -V | grep _sol2 >/dev/null 2>&1; then\n          LD=${LD-ld}_sol2\n        fi\n        ;;\n      *)\n\tif ${LD-ld} -64 -r -o conftest2.o conftest.o >/dev/null 2>&1; then\n\t  LD=\"${LD-ld} -64\"\n\tfi\n\t;;\n      esac\n      ;;\n    esac\n  fi\n  rm -rf conftest*\n  ;;\nesac\n\nneed_locks=$enable_libtool_lock\n])# _LT_ENABLE_LOCK\n\n\n# _LT_PROG_AR\n# -----------\nm4_defun([_LT_PROG_AR],\n[AC_CHECK_TOOLS(AR, [ar], false)\n: ${AR=ar}\n: ${AR_FLAGS=cru}\n_LT_DECL([], [AR], [1], [The archiver])\n_LT_DECL([], [AR_FLAGS], [1], [Flags to create an archive])\n\nAC_CACHE_CHECK([for archiver @FILE support], [lt_cv_ar_at_file],\n  [lt_cv_ar_at_file=no\n   AC_COMPILE_IFELSE([AC_LANG_PROGRAM],\n     [echo conftest.$ac_objext > conftest.lst\n      lt_ar_try='$AR $AR_FLAGS libconftest.a @conftest.lst >&AS_MESSAGE_LOG_FD'\n      AC_TRY_EVAL([lt_ar_try])\n      if test 0 -eq \"$ac_status\"; then\n\t# Ensure the archiver fails upon bogus file names.\n\trm -f conftest.$ac_objext libconftest.a\n\tAC_TRY_EVAL([lt_ar_try])\n\tif test 0 -ne \"$ac_status\"; then\n          lt_cv_ar_at_file=@\n        fi\n      fi\n      rm -f conftest.* libconftest.a\n     ])\n  ])\n\nif test no = \"$lt_cv_ar_at_file\"; then\n  archiver_list_spec=\nelse\n  archiver_list_spec=$lt_cv_ar_at_file\nfi\n_LT_DECL([], [archiver_list_spec], [1],\n  [How to feed a file listing to the archiver])\n])# _LT_PROG_AR\n\n\n# _LT_CMD_OLD_ARCHIVE\n# -------------------\nm4_defun([_LT_CMD_OLD_ARCHIVE],\n[_LT_PROG_AR\n\nAC_CHECK_TOOL(STRIP, strip, :)\ntest -z \"$STRIP\" && STRIP=:\n_LT_DECL([], [STRIP], [1], [A symbol stripping program])\n\nAC_CHECK_TOOL(RANLIB, ranlib, :)\ntest -z \"$RANLIB\" && RANLIB=:\n_LT_DECL([], [RANLIB], [1],\n    [Commands used to install an old-style archive])\n\n# Determine commands to create old-style static archives.\nold_archive_cmds='$AR $AR_FLAGS $oldlib$oldobjs'\nold_postinstall_cmds='chmod 644 $oldlib'\nold_postuninstall_cmds=\n\nif test -n \"$RANLIB\"; then\n  case $host_os in\n  bitrig* | openbsd*)\n    old_postinstall_cmds=\"$old_postinstall_cmds~\\$RANLIB -t \\$tool_oldlib\"\n    ;;\n  *)\n    old_postinstall_cmds=\"$old_postinstall_cmds~\\$RANLIB \\$tool_oldlib\"\n    ;;\n  esac\n  old_archive_cmds=\"$old_archive_cmds~\\$RANLIB \\$tool_oldlib\"\nfi\n\ncase $host_os in\n  darwin*)\n    lock_old_archive_extraction=yes ;;\n  *)\n    lock_old_archive_extraction=no ;;\nesac\n_LT_DECL([], [old_postinstall_cmds], [2])\n_LT_DECL([], [old_postuninstall_cmds], [2])\n_LT_TAGDECL([], [old_archive_cmds], [2],\n    [Commands used to build an old-style archive])\n_LT_DECL([], [lock_old_archive_extraction], [0],\n    [Whether to use a lock for old archive extraction])\n])# _LT_CMD_OLD_ARCHIVE\n\n\n# _LT_COMPILER_OPTION(MESSAGE, VARIABLE-NAME, FLAGS,\n#\t\t[OUTPUT-FILE], [ACTION-SUCCESS], [ACTION-FAILURE])\n# ----------------------------------------------------------------\n# Check whether the given compiler option works\nAC_DEFUN([_LT_COMPILER_OPTION],\n[m4_require([_LT_FILEUTILS_DEFAULTS])dnl\nm4_require([_LT_DECL_SED])dnl\nAC_CACHE_CHECK([$1], [$2],\n  [$2=no\n   m4_if([$4], , [ac_outfile=conftest.$ac_objext], [ac_outfile=$4])\n   echo \"$lt_simple_compile_test_code\" > conftest.$ac_ext\n   lt_compiler_flag=\"$3\"  ## exclude from sc_useless_quotes_in_assignment\n   # Insert the option either (1) after the last *FLAGS variable, or\n   # (2) before a word containing \"conftest.\", or (3) at the end.\n   # Note that $ac_compile itself does not contain backslashes and begins\n   # with a dollar sign (not a hyphen), so the echo should work correctly.\n   # The option is referenced via a variable to avoid confusing sed.\n   lt_compile=`echo \"$ac_compile\" | $SED \\\n   -e 's:.*FLAGS}\\{0,1\\} :&$lt_compiler_flag :; t' \\\n   -e 's: [[^ ]]*conftest\\.: $lt_compiler_flag&:; t' \\\n   -e 's:$: $lt_compiler_flag:'`\n   (eval echo \"\\\"\\$as_me:$LINENO: $lt_compile\\\"\" >&AS_MESSAGE_LOG_FD)\n   (eval \"$lt_compile\" 2>conftest.err)\n   ac_status=$?\n   cat conftest.err >&AS_MESSAGE_LOG_FD\n   echo \"$as_me:$LINENO: \\$? = $ac_status\" >&AS_MESSAGE_LOG_FD\n   if (exit $ac_status) && test -s \"$ac_outfile\"; then\n     # The compiler can only warn and ignore the option if not recognized\n     # So say no if there are warnings other than the usual output.\n     $ECHO \"$_lt_compiler_boilerplate\" | $SED '/^$/d' >conftest.exp\n     $SED '/^$/d; /^ *+/d' conftest.err >conftest.er2\n     if test ! -s conftest.er2 || diff conftest.exp conftest.er2 >/dev/null; then\n       $2=yes\n     fi\n   fi\n   $RM conftest*\n])\n\nif test yes = \"[$]$2\"; then\n    m4_if([$5], , :, [$5])\nelse\n    m4_if([$6], , :, [$6])\nfi\n])# _LT_COMPILER_OPTION\n\n# Old name:\nAU_ALIAS([AC_LIBTOOL_COMPILER_OPTION], [_LT_COMPILER_OPTION])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_LIBTOOL_COMPILER_OPTION], [])\n\n\n# _LT_LINKER_OPTION(MESSAGE, VARIABLE-NAME, FLAGS,\n#                  [ACTION-SUCCESS], [ACTION-FAILURE])\n# ----------------------------------------------------\n# Check whether the given linker option works\nAC_DEFUN([_LT_LINKER_OPTION],\n[m4_require([_LT_FILEUTILS_DEFAULTS])dnl\nm4_require([_LT_DECL_SED])dnl\nAC_CACHE_CHECK([$1], [$2],\n  [$2=no\n   save_LDFLAGS=$LDFLAGS\n   LDFLAGS=\"$LDFLAGS $3\"\n   echo \"$lt_simple_link_test_code\" > conftest.$ac_ext\n   if (eval $ac_link 2>conftest.err) && test -s conftest$ac_exeext; then\n     # The linker can only warn and ignore the option if not recognized\n     # So say no if there are warnings\n     if test -s conftest.err; then\n       # Append any errors to the config.log.\n       cat conftest.err 1>&AS_MESSAGE_LOG_FD\n       $ECHO \"$_lt_linker_boilerplate\" | $SED '/^$/d' > conftest.exp\n       $SED '/^$/d; /^ *+/d' conftest.err >conftest.er2\n       if diff conftest.exp conftest.er2 >/dev/null; then\n         $2=yes\n       fi\n     else\n       $2=yes\n     fi\n   fi\n   $RM -r conftest*\n   LDFLAGS=$save_LDFLAGS\n])\n\nif test yes = \"[$]$2\"; then\n    m4_if([$4], , :, [$4])\nelse\n    m4_if([$5], , :, [$5])\nfi\n])# _LT_LINKER_OPTION\n\n# Old name:\nAU_ALIAS([AC_LIBTOOL_LINKER_OPTION], [_LT_LINKER_OPTION])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_LIBTOOL_LINKER_OPTION], [])\n\n\n# LT_CMD_MAX_LEN\n#---------------\nAC_DEFUN([LT_CMD_MAX_LEN],\n[AC_REQUIRE([AC_CANONICAL_HOST])dnl\n# find the maximum length of command line arguments\nAC_MSG_CHECKING([the maximum length of command line arguments])\nAC_CACHE_VAL([lt_cv_sys_max_cmd_len], [dnl\n  i=0\n  teststring=ABCD\n\n  case $build_os in\n  msdosdjgpp*)\n    # On DJGPP, this test can blow up pretty badly due to problems in libc\n    # (any single argument exceeding 2000 bytes causes a buffer overrun\n    # during glob expansion).  Even if it were fixed, the result of this\n    # check would be larger than it should be.\n    lt_cv_sys_max_cmd_len=12288;    # 12K is about right\n    ;;\n\n  gnu*)\n    # Under GNU Hurd, this test is not required because there is\n    # no limit to the length of command line arguments.\n    # Libtool will interpret -1 as no limit whatsoever\n    lt_cv_sys_max_cmd_len=-1;\n    ;;\n\n  cygwin* | mingw* | cegcc*)\n    # On Win9x/ME, this test blows up -- it succeeds, but takes\n    # about 5 minutes as the teststring grows exponentially.\n    # Worse, since 9x/ME are not pre-emptively multitasking,\n    # you end up with a \"frozen\" computer, even though with patience\n    # the test eventually succeeds (with a max line length of 256k).\n    # Instead, let's just punt: use the minimum linelength reported by\n    # all of the supported platforms: 8192 (on NT/2K/XP).\n    lt_cv_sys_max_cmd_len=8192;\n    ;;\n\n  mint*)\n    # On MiNT this can take a long time and run out of memory.\n    lt_cv_sys_max_cmd_len=8192;\n    ;;\n\n  amigaos*)\n    # On AmigaOS with pdksh, this test takes hours, literally.\n    # So we just punt and use a minimum line length of 8192.\n    lt_cv_sys_max_cmd_len=8192;\n    ;;\n\n  bitrig* | darwin* | dragonfly* | freebsd* | netbsd* | openbsd*)\n    # This has been around since 386BSD, at least.  Likely further.\n    if test -x /sbin/sysctl; then\n      lt_cv_sys_max_cmd_len=`/sbin/sysctl -n kern.argmax`\n    elif test -x /usr/sbin/sysctl; then\n      lt_cv_sys_max_cmd_len=`/usr/sbin/sysctl -n kern.argmax`\n    else\n      lt_cv_sys_max_cmd_len=65536\t# usable default for all BSDs\n    fi\n    # And add a safety zone\n    lt_cv_sys_max_cmd_len=`expr $lt_cv_sys_max_cmd_len \\/ 4`\n    lt_cv_sys_max_cmd_len=`expr $lt_cv_sys_max_cmd_len \\* 3`\n    ;;\n\n  interix*)\n    # We know the value 262144 and hardcode it with a safety zone (like BSD)\n    lt_cv_sys_max_cmd_len=196608\n    ;;\n\n  os2*)\n    # The test takes a long time on OS/2.\n    lt_cv_sys_max_cmd_len=8192\n    ;;\n\n  osf*)\n    # Dr. Hans Ekkehard Plesser reports seeing a kernel panic running configure\n    # due to this test when exec_disable_arg_limit is 1 on Tru64. It is not\n    # nice to cause kernel panics so lets avoid the loop below.\n    # First set a reasonable default.\n    lt_cv_sys_max_cmd_len=16384\n    #\n    if test -x /sbin/sysconfig; then\n      case `/sbin/sysconfig -q proc exec_disable_arg_limit` in\n        *1*) lt_cv_sys_max_cmd_len=-1 ;;\n      esac\n    fi\n    ;;\n  sco3.2v5*)\n    lt_cv_sys_max_cmd_len=102400\n    ;;\n  sysv5* | sco5v6* | sysv4.2uw2*)\n    kargmax=`grep ARG_MAX /etc/conf/cf.d/stune 2>/dev/null`\n    if test -n \"$kargmax\"; then\n      lt_cv_sys_max_cmd_len=`echo $kargmax | sed 's/.*[[\t ]]//'`\n    else\n      lt_cv_sys_max_cmd_len=32768\n    fi\n    ;;\n  *)\n    lt_cv_sys_max_cmd_len=`(getconf ARG_MAX) 2> /dev/null`\n    if test -n \"$lt_cv_sys_max_cmd_len\" && \\\n       test undefined != \"$lt_cv_sys_max_cmd_len\"; then\n      lt_cv_sys_max_cmd_len=`expr $lt_cv_sys_max_cmd_len \\/ 4`\n      lt_cv_sys_max_cmd_len=`expr $lt_cv_sys_max_cmd_len \\* 3`\n    else\n      # Make teststring a little bigger before we do anything with it.\n      # a 1K string should be a reasonable start.\n      for i in 1 2 3 4 5 6 7 8; do\n        teststring=$teststring$teststring\n      done\n      SHELL=${SHELL-${CONFIG_SHELL-/bin/sh}}\n      # If test is not a shell built-in, we'll probably end up computing a\n      # maximum length that is only half of the actual maximum length, but\n      # we can't tell.\n      while { test X`env echo \"$teststring$teststring\" 2>/dev/null` \\\n\t         = \"X$teststring$teststring\"; } >/dev/null 2>&1 &&\n\t      test 17 != \"$i\" # 1/2 MB should be enough\n      do\n        i=`expr $i + 1`\n        teststring=$teststring$teststring\n      done\n      # Only check the string length outside the loop.\n      lt_cv_sys_max_cmd_len=`expr \"X$teststring\" : \".*\" 2>&1`\n      teststring=\n      # Add a significant safety factor because C++ compilers can tack on\n      # massive amounts of additional arguments before passing them to the\n      # linker.  It appears as though 1/2 is a usable value.\n      lt_cv_sys_max_cmd_len=`expr $lt_cv_sys_max_cmd_len \\/ 2`\n    fi\n    ;;\n  esac\n])\nif test -n \"$lt_cv_sys_max_cmd_len\"; then\n  AC_MSG_RESULT($lt_cv_sys_max_cmd_len)\nelse\n  AC_MSG_RESULT(none)\nfi\nmax_cmd_len=$lt_cv_sys_max_cmd_len\n_LT_DECL([], [max_cmd_len], [0],\n    [What is the maximum length of a command?])\n])# LT_CMD_MAX_LEN\n\n# Old name:\nAU_ALIAS([AC_LIBTOOL_SYS_MAX_CMD_LEN], [LT_CMD_MAX_LEN])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_LIBTOOL_SYS_MAX_CMD_LEN], [])\n\n\n# _LT_HEADER_DLFCN\n# ----------------\nm4_defun([_LT_HEADER_DLFCN],\n[AC_CHECK_HEADERS([dlfcn.h], [], [], [AC_INCLUDES_DEFAULT])dnl\n])# _LT_HEADER_DLFCN\n\n\n# _LT_TRY_DLOPEN_SELF (ACTION-IF-TRUE, ACTION-IF-TRUE-W-USCORE,\n#                      ACTION-IF-FALSE, ACTION-IF-CROSS-COMPILING)\n# ----------------------------------------------------------------\nm4_defun([_LT_TRY_DLOPEN_SELF],\n[m4_require([_LT_HEADER_DLFCN])dnl\nif test yes = \"$cross_compiling\"; then :\n  [$4]\nelse\n  lt_dlunknown=0; lt_dlno_uscore=1; lt_dlneed_uscore=2\n  lt_status=$lt_dlunknown\n  cat > conftest.$ac_ext <<_LT_EOF\n[#line $LINENO \"configure\"\n#include \"confdefs.h\"\n\n#if HAVE_DLFCN_H\n#include <dlfcn.h>\n#endif\n\n#include <stdio.h>\n\n#ifdef RTLD_GLOBAL\n#  define LT_DLGLOBAL\t\tRTLD_GLOBAL\n#else\n#  ifdef DL_GLOBAL\n#    define LT_DLGLOBAL\t\tDL_GLOBAL\n#  else\n#    define LT_DLGLOBAL\t\t0\n#  endif\n#endif\n\n/* We may have to define LT_DLLAZY_OR_NOW in the command line if we\n   find out it does not work in some platform. */\n#ifndef LT_DLLAZY_OR_NOW\n#  ifdef RTLD_LAZY\n#    define LT_DLLAZY_OR_NOW\t\tRTLD_LAZY\n#  else\n#    ifdef DL_LAZY\n#      define LT_DLLAZY_OR_NOW\t\tDL_LAZY\n#    else\n#      ifdef RTLD_NOW\n#        define LT_DLLAZY_OR_NOW\tRTLD_NOW\n#      else\n#        ifdef DL_NOW\n#          define LT_DLLAZY_OR_NOW\tDL_NOW\n#        else\n#          define LT_DLLAZY_OR_NOW\t0\n#        endif\n#      endif\n#    endif\n#  endif\n#endif\n\n/* When -fvisibility=hidden is used, assume the code has been annotated\n   correspondingly for the symbols needed.  */\n#if defined __GNUC__ && (((__GNUC__ == 3) && (__GNUC_MINOR__ >= 3)) || (__GNUC__ > 3))\nint fnord () __attribute__((visibility(\"default\")));\n#endif\n\nint fnord () { return 42; }\nint main ()\n{\n  void *self = dlopen (0, LT_DLGLOBAL|LT_DLLAZY_OR_NOW);\n  int status = $lt_dlunknown;\n\n  if (self)\n    {\n      if (dlsym (self,\"fnord\"))       status = $lt_dlno_uscore;\n      else\n        {\n\t  if (dlsym( self,\"_fnord\"))  status = $lt_dlneed_uscore;\n          else puts (dlerror ());\n\t}\n      /* dlclose (self); */\n    }\n  else\n    puts (dlerror ());\n\n  return status;\n}]\n_LT_EOF\n  if AC_TRY_EVAL(ac_link) && test -s \"conftest$ac_exeext\" 2>/dev/null; then\n    (./conftest; exit; ) >&AS_MESSAGE_LOG_FD 2>/dev/null\n    lt_status=$?\n    case x$lt_status in\n      x$lt_dlno_uscore) $1 ;;\n      x$lt_dlneed_uscore) $2 ;;\n      x$lt_dlunknown|x*) $3 ;;\n    esac\n  else :\n    # compilation failed\n    $3\n  fi\nfi\nrm -fr conftest*\n])# _LT_TRY_DLOPEN_SELF\n\n\n# LT_SYS_DLOPEN_SELF\n# ------------------\nAC_DEFUN([LT_SYS_DLOPEN_SELF],\n[m4_require([_LT_HEADER_DLFCN])dnl\nif test yes != \"$enable_dlopen\"; then\n  enable_dlopen=unknown\n  enable_dlopen_self=unknown\n  enable_dlopen_self_static=unknown\nelse\n  lt_cv_dlopen=no\n  lt_cv_dlopen_libs=\n\n  case $host_os in\n  beos*)\n    lt_cv_dlopen=load_add_on\n    lt_cv_dlopen_libs=\n    lt_cv_dlopen_self=yes\n    ;;\n\n  mingw* | pw32* | cegcc*)\n    lt_cv_dlopen=LoadLibrary\n    lt_cv_dlopen_libs=\n    ;;\n\n  cygwin*)\n    lt_cv_dlopen=dlopen\n    lt_cv_dlopen_libs=\n    ;;\n\n  darwin*)\n    # if libdl is installed we need to link against it\n    AC_CHECK_LIB([dl], [dlopen],\n\t\t[lt_cv_dlopen=dlopen lt_cv_dlopen_libs=-ldl],[\n    lt_cv_dlopen=dyld\n    lt_cv_dlopen_libs=\n    lt_cv_dlopen_self=yes\n    ])\n    ;;\n\n  tpf*)\n    # Don't try to run any link tests for TPF.  We know it's impossible\n    # because TPF is a cross-compiler, and we know how we open DSOs.\n    lt_cv_dlopen=dlopen\n    lt_cv_dlopen_libs=\n    lt_cv_dlopen_self=no\n    ;;\n\n  *)\n    AC_CHECK_FUNC([shl_load],\n\t  [lt_cv_dlopen=shl_load],\n      [AC_CHECK_LIB([dld], [shl_load],\n\t    [lt_cv_dlopen=shl_load lt_cv_dlopen_libs=-ldld],\n\t[AC_CHECK_FUNC([dlopen],\n\t      [lt_cv_dlopen=dlopen],\n\t  [AC_CHECK_LIB([dl], [dlopen],\n\t\t[lt_cv_dlopen=dlopen lt_cv_dlopen_libs=-ldl],\n\t    [AC_CHECK_LIB([svld], [dlopen],\n\t\t  [lt_cv_dlopen=dlopen lt_cv_dlopen_libs=-lsvld],\n\t      [AC_CHECK_LIB([dld], [dld_link],\n\t\t    [lt_cv_dlopen=dld_link lt_cv_dlopen_libs=-ldld])\n\t      ])\n\t    ])\n\t  ])\n\t])\n      ])\n    ;;\n  esac\n\n  if test no = \"$lt_cv_dlopen\"; then\n    enable_dlopen=no\n  else\n    enable_dlopen=yes\n  fi\n\n  case $lt_cv_dlopen in\n  dlopen)\n    save_CPPFLAGS=$CPPFLAGS\n    test yes = \"$ac_cv_header_dlfcn_h\" && CPPFLAGS=\"$CPPFLAGS -DHAVE_DLFCN_H\"\n\n    save_LDFLAGS=$LDFLAGS\n    wl=$lt_prog_compiler_wl eval LDFLAGS=\\\"\\$LDFLAGS $export_dynamic_flag_spec\\\"\n\n    save_LIBS=$LIBS\n    LIBS=\"$lt_cv_dlopen_libs $LIBS\"\n\n    AC_CACHE_CHECK([whether a program can dlopen itself],\n\t  lt_cv_dlopen_self, [dnl\n\t  _LT_TRY_DLOPEN_SELF(\n\t    lt_cv_dlopen_self=yes, lt_cv_dlopen_self=yes,\n\t    lt_cv_dlopen_self=no, lt_cv_dlopen_self=cross)\n    ])\n\n    if test yes = \"$lt_cv_dlopen_self\"; then\n      wl=$lt_prog_compiler_wl eval LDFLAGS=\\\"\\$LDFLAGS $lt_prog_compiler_static\\\"\n      AC_CACHE_CHECK([whether a statically linked program can dlopen itself],\n\t  lt_cv_dlopen_self_static, [dnl\n\t  _LT_TRY_DLOPEN_SELF(\n\t    lt_cv_dlopen_self_static=yes, lt_cv_dlopen_self_static=yes,\n\t    lt_cv_dlopen_self_static=no,  lt_cv_dlopen_self_static=cross)\n      ])\n    fi\n\n    CPPFLAGS=$save_CPPFLAGS\n    LDFLAGS=$save_LDFLAGS\n    LIBS=$save_LIBS\n    ;;\n  esac\n\n  case $lt_cv_dlopen_self in\n  yes|no) enable_dlopen_self=$lt_cv_dlopen_self ;;\n  *) enable_dlopen_self=unknown ;;\n  esac\n\n  case $lt_cv_dlopen_self_static in\n  yes|no) enable_dlopen_self_static=$lt_cv_dlopen_self_static ;;\n  *) enable_dlopen_self_static=unknown ;;\n  esac\nfi\n_LT_DECL([dlopen_support], [enable_dlopen], [0],\n\t [Whether dlopen is supported])\n_LT_DECL([dlopen_self], [enable_dlopen_self], [0],\n\t [Whether dlopen of programs is supported])\n_LT_DECL([dlopen_self_static], [enable_dlopen_self_static], [0],\n\t [Whether dlopen of statically linked programs is supported])\n])# LT_SYS_DLOPEN_SELF\n\n# Old name:\nAU_ALIAS([AC_LIBTOOL_DLOPEN_SELF], [LT_SYS_DLOPEN_SELF])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_LIBTOOL_DLOPEN_SELF], [])\n\n\n# _LT_COMPILER_C_O([TAGNAME])\n# ---------------------------\n# Check to see if options -c and -o are simultaneously supported by compiler.\n# This macro does not hard code the compiler like AC_PROG_CC_C_O.\nm4_defun([_LT_COMPILER_C_O],\n[m4_require([_LT_DECL_SED])dnl\nm4_require([_LT_FILEUTILS_DEFAULTS])dnl\nm4_require([_LT_TAG_COMPILER])dnl\nAC_CACHE_CHECK([if $compiler supports -c -o file.$ac_objext],\n  [_LT_TAGVAR(lt_cv_prog_compiler_c_o, $1)],\n  [_LT_TAGVAR(lt_cv_prog_compiler_c_o, $1)=no\n   $RM -r conftest 2>/dev/null\n   mkdir conftest\n   cd conftest\n   mkdir out\n   echo \"$lt_simple_compile_test_code\" > conftest.$ac_ext\n\n   lt_compiler_flag=\"-o out/conftest2.$ac_objext\"\n   # Insert the option either (1) after the last *FLAGS variable, or\n   # (2) before a word containing \"conftest.\", or (3) at the end.\n   # Note that $ac_compile itself does not contain backslashes and begins\n   # with a dollar sign (not a hyphen), so the echo should work correctly.\n   lt_compile=`echo \"$ac_compile\" | $SED \\\n   -e 's:.*FLAGS}\\{0,1\\} :&$lt_compiler_flag :; t' \\\n   -e 's: [[^ ]]*conftest\\.: $lt_compiler_flag&:; t' \\\n   -e 's:$: $lt_compiler_flag:'`\n   (eval echo \"\\\"\\$as_me:$LINENO: $lt_compile\\\"\" >&AS_MESSAGE_LOG_FD)\n   (eval \"$lt_compile\" 2>out/conftest.err)\n   ac_status=$?\n   cat out/conftest.err >&AS_MESSAGE_LOG_FD\n   echo \"$as_me:$LINENO: \\$? = $ac_status\" >&AS_MESSAGE_LOG_FD\n   if (exit $ac_status) && test -s out/conftest2.$ac_objext\n   then\n     # The compiler can only warn and ignore the option if not recognized\n     # So say no if there are warnings\n     $ECHO \"$_lt_compiler_boilerplate\" | $SED '/^$/d' > out/conftest.exp\n     $SED '/^$/d; /^ *+/d' out/conftest.err >out/conftest.er2\n     if test ! -s out/conftest.er2 || diff out/conftest.exp out/conftest.er2 >/dev/null; then\n       _LT_TAGVAR(lt_cv_prog_compiler_c_o, $1)=yes\n     fi\n   fi\n   chmod u+w . 2>&AS_MESSAGE_LOG_FD\n   $RM conftest*\n   # SGI C++ compiler will create directory out/ii_files/ for\n   # template instantiation\n   test -d out/ii_files && $RM out/ii_files/* && rmdir out/ii_files\n   $RM out/* && rmdir out\n   cd ..\n   $RM -r conftest\n   $RM conftest*\n])\n_LT_TAGDECL([compiler_c_o], [lt_cv_prog_compiler_c_o], [1],\n\t[Does compiler simultaneously support -c and -o options?])\n])# _LT_COMPILER_C_O\n\n\n# _LT_COMPILER_FILE_LOCKS([TAGNAME])\n# ----------------------------------\n# Check to see if we can do hard links to lock some files if needed\nm4_defun([_LT_COMPILER_FILE_LOCKS],\n[m4_require([_LT_ENABLE_LOCK])dnl\nm4_require([_LT_FILEUTILS_DEFAULTS])dnl\n_LT_COMPILER_C_O([$1])\n\nhard_links=nottested\nif test no = \"$_LT_TAGVAR(lt_cv_prog_compiler_c_o, $1)\" && test no != \"$need_locks\"; then\n  # do not overwrite the value of need_locks provided by the user\n  AC_MSG_CHECKING([if we can lock with hard links])\n  hard_links=yes\n  $RM conftest*\n  ln conftest.a conftest.b 2>/dev/null && hard_links=no\n  touch conftest.a\n  ln conftest.a conftest.b 2>&5 || hard_links=no\n  ln conftest.a conftest.b 2>/dev/null && hard_links=no\n  AC_MSG_RESULT([$hard_links])\n  if test no = \"$hard_links\"; then\n    AC_MSG_WARN(['$CC' does not support '-c -o', so 'make -j' may be unsafe])\n    need_locks=warn\n  fi\nelse\n  need_locks=no\nfi\n_LT_DECL([], [need_locks], [1], [Must we lock files when doing compilation?])\n])# _LT_COMPILER_FILE_LOCKS\n\n\n# _LT_CHECK_OBJDIR\n# ----------------\nm4_defun([_LT_CHECK_OBJDIR],\n[AC_CACHE_CHECK([for objdir], [lt_cv_objdir],\n[rm -f .libs 2>/dev/null\nmkdir .libs 2>/dev/null\nif test -d .libs; then\n  lt_cv_objdir=.libs\nelse\n  # MS-DOS does not allow filenames that begin with a dot.\n  lt_cv_objdir=_libs\nfi\nrmdir .libs 2>/dev/null])\nobjdir=$lt_cv_objdir\n_LT_DECL([], [objdir], [0],\n         [The name of the directory that contains temporary libtool files])dnl\nm4_pattern_allow([LT_OBJDIR])dnl\nAC_DEFINE_UNQUOTED([LT_OBJDIR], \"$lt_cv_objdir/\",\n  [Define to the sub-directory where libtool stores uninstalled libraries.])\n])# _LT_CHECK_OBJDIR\n\n\n# _LT_LINKER_HARDCODE_LIBPATH([TAGNAME])\n# --------------------------------------\n# Check hardcoding attributes.\nm4_defun([_LT_LINKER_HARDCODE_LIBPATH],\n[AC_MSG_CHECKING([how to hardcode library paths into programs])\n_LT_TAGVAR(hardcode_action, $1)=\nif test -n \"$_LT_TAGVAR(hardcode_libdir_flag_spec, $1)\" ||\n   test -n \"$_LT_TAGVAR(runpath_var, $1)\" ||\n   test yes = \"$_LT_TAGVAR(hardcode_automatic, $1)\"; then\n\n  # We can hardcode non-existent directories.\n  if test no != \"$_LT_TAGVAR(hardcode_direct, $1)\" &&\n     # If the only mechanism to avoid hardcoding is shlibpath_var, we\n     # have to relink, otherwise we might link with an installed library\n     # when we should be linking with a yet-to-be-installed one\n     ## test no != \"$_LT_TAGVAR(hardcode_shlibpath_var, $1)\" &&\n     test no != \"$_LT_TAGVAR(hardcode_minus_L, $1)\"; then\n    # Linking always hardcodes the temporary library directory.\n    _LT_TAGVAR(hardcode_action, $1)=relink\n  else\n    # We can link without hardcoding, and we can hardcode nonexisting dirs.\n    _LT_TAGVAR(hardcode_action, $1)=immediate\n  fi\nelse\n  # We cannot hardcode anything, or else we can only hardcode existing\n  # directories.\n  _LT_TAGVAR(hardcode_action, $1)=unsupported\nfi\nAC_MSG_RESULT([$_LT_TAGVAR(hardcode_action, $1)])\n\nif test relink = \"$_LT_TAGVAR(hardcode_action, $1)\" ||\n   test yes = \"$_LT_TAGVAR(inherit_rpath, $1)\"; then\n  # Fast installation is not supported\n  enable_fast_install=no\nelif test yes = \"$shlibpath_overrides_runpath\" ||\n     test no = \"$enable_shared\"; then\n  # Fast installation is not necessary\n  enable_fast_install=needless\nfi\n_LT_TAGDECL([], [hardcode_action], [0],\n    [How to hardcode a shared library path into an executable])\n])# _LT_LINKER_HARDCODE_LIBPATH\n\n\n# _LT_CMD_STRIPLIB\n# ----------------\nm4_defun([_LT_CMD_STRIPLIB],\n[m4_require([_LT_DECL_EGREP])\nstriplib=\nold_striplib=\nAC_MSG_CHECKING([whether stripping libraries is possible])\nif test -n \"$STRIP\" && $STRIP -V 2>&1 | $GREP \"GNU strip\" >/dev/null; then\n  test -z \"$old_striplib\" && old_striplib=\"$STRIP --strip-debug\"\n  test -z \"$striplib\" && striplib=\"$STRIP --strip-unneeded\"\n  AC_MSG_RESULT([yes])\nelse\n# FIXME - insert some real tests, host_os isn't really good enough\n  case $host_os in\n  darwin*)\n    if test -n \"$STRIP\"; then\n      striplib=\"$STRIP -x\"\n      old_striplib=\"$STRIP -S\"\n      AC_MSG_RESULT([yes])\n    else\n      AC_MSG_RESULT([no])\n    fi\n    ;;\n  *)\n    AC_MSG_RESULT([no])\n    ;;\n  esac\nfi\n_LT_DECL([], [old_striplib], [1], [Commands to strip libraries])\n_LT_DECL([], [striplib], [1])\n])# _LT_CMD_STRIPLIB\n\n\n# _LT_PREPARE_MUNGE_PATH_LIST\n# ---------------------------\n# Make sure func_munge_path_list() is defined correctly.\nm4_defun([_LT_PREPARE_MUNGE_PATH_LIST],\n[[# func_munge_path_list VARIABLE PATH\n# -----------------------------------\n# VARIABLE is name of variable containing _space_ separated list of\n# directories to be munged by the contents of PATH, which is string\n# having a format:\n# \"DIR[:DIR]:\"\n#       string \"DIR[ DIR]\" will be prepended to VARIABLE\n# \":DIR[:DIR]\"\n#       string \"DIR[ DIR]\" will be appended to VARIABLE\n# \"DIRP[:DIRP]::[DIRA:]DIRA\"\n#       string \"DIRP[ DIRP]\" will be prepended to VARIABLE and string\n#       \"DIRA[ DIRA]\" will be appended to VARIABLE\n# \"DIR[:DIR]\"\n#       VARIABLE will be replaced by \"DIR[ DIR]\"\nfunc_munge_path_list ()\n{\n    case x@S|@2 in\n    x)\n        ;;\n    *:)\n        eval @S|@1=\\\"`$ECHO @S|@2 | $SED 's/:/ /g'` \\@S|@@S|@1\\\"\n        ;;\n    x:*)\n        eval @S|@1=\\\"\\@S|@@S|@1 `$ECHO @S|@2 | $SED 's/:/ /g'`\\\"\n        ;;\n    *::*)\n        eval @S|@1=\\\"\\@S|@@S|@1\\ `$ECHO @S|@2 | $SED -e 's/.*:://' -e 's/:/ /g'`\\\"\n        eval @S|@1=\\\"`$ECHO @S|@2 | $SED -e 's/::.*//' -e 's/:/ /g'`\\ \\@S|@@S|@1\\\"\n        ;;\n    *)\n        eval @S|@1=\\\"`$ECHO @S|@2 | $SED 's/:/ /g'`\\\"\n        ;;\n    esac\n}\n]])# _LT_PREPARE_PATH_LIST\n\n\n# _LT_SYS_DYNAMIC_LINKER([TAG])\n# -----------------------------\n# PORTME Fill in your ld.so characteristics\nm4_defun([_LT_SYS_DYNAMIC_LINKER],\n[AC_REQUIRE([AC_CANONICAL_HOST])dnl\nm4_require([_LT_DECL_EGREP])dnl\nm4_require([_LT_FILEUTILS_DEFAULTS])dnl\nm4_require([_LT_DECL_OBJDUMP])dnl\nm4_require([_LT_DECL_SED])dnl\nm4_require([_LT_CHECK_SHELL_FEATURES])dnl\nm4_require([_LT_PREPARE_MUNGE_PATH_LIST])dnl\nAC_MSG_CHECKING([dynamic linker characteristics])\nm4_if([$1],\n\t[], [\nif test yes = \"$GCC\"; then\n  case $host_os in\n    darwin*) lt_awk_arg='/^libraries:/,/LR/' ;;\n    *) lt_awk_arg='/^libraries:/' ;;\n  esac\n  case $host_os in\n    mingw* | cegcc*) lt_sed_strip_eq='s|=\\([[A-Za-z]]:\\)|\\1|g' ;;\n    *) lt_sed_strip_eq='s|=/|/|g' ;;\n  esac\n  lt_search_path_spec=`$CC -print-search-dirs | awk $lt_awk_arg | $SED -e \"s/^libraries://\" -e $lt_sed_strip_eq`\n  case $lt_search_path_spec in\n  *\\;*)\n    # if the path contains \";\" then we assume it to be the separator\n    # otherwise default to the standard path separator (i.e. \":\") - it is\n    # assumed that no part of a normal pathname contains \";\" but that should\n    # okay in the real world where \";\" in dirpaths is itself problematic.\n    lt_search_path_spec=`$ECHO \"$lt_search_path_spec\" | $SED 's/;/ /g'`\n    ;;\n  *)\n    lt_search_path_spec=`$ECHO \"$lt_search_path_spec\" | $SED \"s/$PATH_SEPARATOR/ /g\"`\n    ;;\n  esac\n  # Ok, now we have the path, separated by spaces, we can step through it\n  # and add multilib dir if necessary...\n  lt_tmp_lt_search_path_spec=\n  lt_multi_os_dir=/`$CC $CPPFLAGS $CFLAGS $LDFLAGS -print-multi-os-directory 2>/dev/null`\n  # ...but if some path component already ends with the multilib dir we assume\n  # that all is fine and trust -print-search-dirs as is (GCC 4.2? or newer).\n  case \"$lt_multi_os_dir; $lt_search_path_spec \" in\n  \"/; \"* | \"/.; \"* | \"/./; \"* | *\"$lt_multi_os_dir \"* | *\"$lt_multi_os_dir/ \"*)\n    lt_multi_os_dir=\n    ;;\n  esac\n  for lt_sys_path in $lt_search_path_spec; do\n    if test -d \"$lt_sys_path$lt_multi_os_dir\"; then\n      lt_tmp_lt_search_path_spec=\"$lt_tmp_lt_search_path_spec $lt_sys_path$lt_multi_os_dir\"\n    elif test -n \"$lt_multi_os_dir\"; then\n      test -d \"$lt_sys_path\" && \\\n\tlt_tmp_lt_search_path_spec=\"$lt_tmp_lt_search_path_spec $lt_sys_path\"\n    fi\n  done\n  lt_search_path_spec=`$ECHO \"$lt_tmp_lt_search_path_spec\" | awk '\nBEGIN {RS = \" \"; FS = \"/|\\n\";} {\n  lt_foo = \"\";\n  lt_count = 0;\n  for (lt_i = NF; lt_i > 0; lt_i--) {\n    if ($lt_i != \"\" && $lt_i != \".\") {\n      if ($lt_i == \"..\") {\n        lt_count++;\n      } else {\n        if (lt_count == 0) {\n          lt_foo = \"/\" $lt_i lt_foo;\n        } else {\n          lt_count--;\n        }\n      }\n    }\n  }\n  if (lt_foo != \"\") { lt_freq[[lt_foo]]++; }\n  if (lt_freq[[lt_foo]] == 1) { print lt_foo; }\n}'`\n  # AWK program above erroneously prepends '/' to C:/dos/paths\n  # for these hosts.\n  case $host_os in\n    mingw* | cegcc*) lt_search_path_spec=`$ECHO \"$lt_search_path_spec\" |\\\n      $SED 's|/\\([[A-Za-z]]:\\)|\\1|g'` ;;\n  esac\n  sys_lib_search_path_spec=`$ECHO \"$lt_search_path_spec\" | $lt_NL2SP`\nelse\n  sys_lib_search_path_spec=\"/lib /usr/lib /usr/local/lib\"\nfi])\nlibrary_names_spec=\nlibname_spec='lib$name'\nsoname_spec=\nshrext_cmds=.so\npostinstall_cmds=\npostuninstall_cmds=\nfinish_cmds=\nfinish_eval=\nshlibpath_var=\nshlibpath_overrides_runpath=unknown\nversion_type=none\ndynamic_linker=\"$host_os ld.so\"\nsys_lib_dlsearch_path_spec=\"/lib /usr/lib\"\nneed_lib_prefix=unknown\nhardcode_into_libs=no\n\n# when you set need_version to no, make sure it does not cause -set_version\n# flags to be left without arguments\nneed_version=unknown\n\nAC_ARG_VAR([LT_SYS_LIBRARY_PATH],\n[User-defined run-time library search path.])\n\ncase $host_os in\naix3*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  library_names_spec='$libname$release$shared_ext$versuffix $libname.a'\n  shlibpath_var=LIBPATH\n\n  # AIX 3 has no versioning support, so we append a major version to the name.\n  soname_spec='$libname$release$shared_ext$major'\n  ;;\n\naix[[4-9]]*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  need_lib_prefix=no\n  need_version=no\n  hardcode_into_libs=yes\n  if test ia64 = \"$host_cpu\"; then\n    # AIX 5 supports IA64\n    library_names_spec='$libname$release$shared_ext$major $libname$release$shared_ext$versuffix $libname$shared_ext'\n    shlibpath_var=LD_LIBRARY_PATH\n  else\n    # With GCC up to 2.95.x, collect2 would create an import file\n    # for dependence libraries.  The import file would start with\n    # the line '#! .'.  This would cause the generated library to\n    # depend on '.', always an invalid library.  This was fixed in\n    # development snapshots of GCC prior to 3.0.\n    case $host_os in\n      aix4 | aix4.[[01]] | aix4.[[01]].*)\n      if { echo '#if __GNUC__ > 2 || (__GNUC__ == 2 && __GNUC_MINOR__ >= 97)'\n\t   echo ' yes '\n\t   echo '#endif'; } | $CC -E - | $GREP yes > /dev/null; then\n\t:\n      else\n\tcan_build_shared=no\n      fi\n      ;;\n    esac\n    # Using Import Files as archive members, it is possible to support\n    # filename-based versioning of shared library archives on AIX. While\n    # this would work for both with and without runtime linking, it will\n    # prevent static linking of such archives. So we do filename-based\n    # shared library versioning with .so extension only, which is used\n    # when both runtime linking and shared linking is enabled.\n    # Unfortunately, runtime linking may impact performance, so we do\n    # not want this to be the default eventually. Also, we use the\n    # versioned .so libs for executables only if there is the -brtl\n    # linker flag in LDFLAGS as well, or --with-aix-soname=svr4 only.\n    # To allow for filename-based versioning support, we need to create\n    # libNAME.so.V as an archive file, containing:\n    # *) an Import File, referring to the versioned filename of the\n    #    archive as well as the shared archive member, telling the\n    #    bitwidth (32 or 64) of that shared object, and providing the\n    #    list of exported symbols of that shared object, eventually\n    #    decorated with the 'weak' keyword\n    # *) the shared object with the F_LOADONLY flag set, to really avoid\n    #    it being seen by the linker.\n    # At run time we better use the real file rather than another symlink,\n    # but for link time we create the symlink libNAME.so -> libNAME.so.V\n\n    case $with_aix_soname,$aix_use_runtimelinking in\n    # AIX (on Power*) has no versioning support, so currently we cannot hardcode correct\n    # soname into executable. Probably we can add versioning support to\n    # collect2, so additional links can be useful in future.\n    aix,yes) # traditional libtool\n      dynamic_linker='AIX unversionable lib.so'\n      # If using run time linking (on AIX 4.2 or later) use lib<name>.so\n      # instead of lib<name>.a to let people know that these are not\n      # typical AIX shared libraries.\n      library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n      ;;\n    aix,no) # traditional AIX only\n      dynamic_linker='AIX lib.a[(]lib.so.V[)]'\n      # We preserve .a as extension for shared libraries through AIX4.2\n      # and later when we are not doing run time linking.\n      library_names_spec='$libname$release.a $libname.a'\n      soname_spec='$libname$release$shared_ext$major'\n      ;;\n    svr4,*) # full svr4 only\n      dynamic_linker=\"AIX lib.so.V[(]$shared_archive_member_spec.o[)]\"\n      library_names_spec='$libname$release$shared_ext$major $libname$shared_ext'\n      # We do not specify a path in Import Files, so LIBPATH fires.\n      shlibpath_overrides_runpath=yes\n      ;;\n    *,yes) # both, prefer svr4\n      dynamic_linker=\"AIX lib.so.V[(]$shared_archive_member_spec.o[)], lib.a[(]lib.so.V[)]\"\n      library_names_spec='$libname$release$shared_ext$major $libname$shared_ext'\n      # unpreferred sharedlib libNAME.a needs extra handling\n      postinstall_cmds='test -n \"$linkname\" || linkname=\"$realname\"~func_stripname \"\" \".so\" \"$linkname\"~$install_shared_prog \"$dir/$func_stripname_result.$libext\" \"$destdir/$func_stripname_result.$libext\"~test -z \"$tstripme\" || test -z \"$striplib\" || $striplib \"$destdir/$func_stripname_result.$libext\"'\n      postuninstall_cmds='for n in $library_names $old_library; do :; done~func_stripname \"\" \".so\" \"$n\"~test \"$func_stripname_result\" = \"$n\" || func_append rmfiles \" $odir/$func_stripname_result.$libext\"'\n      # We do not specify a path in Import Files, so LIBPATH fires.\n      shlibpath_overrides_runpath=yes\n      ;;\n    *,no) # both, prefer aix\n      dynamic_linker=\"AIX lib.a[(]lib.so.V[)], lib.so.V[(]$shared_archive_member_spec.o[)]\"\n      library_names_spec='$libname$release.a $libname.a'\n      soname_spec='$libname$release$shared_ext$major'\n      # unpreferred sharedlib libNAME.so.V and symlink libNAME.so need extra handling\n      postinstall_cmds='test -z \"$dlname\" || $install_shared_prog $dir/$dlname $destdir/$dlname~test -z \"$tstripme\" || test -z \"$striplib\" || $striplib $destdir/$dlname~test -n \"$linkname\" || linkname=$realname~func_stripname \"\" \".a\" \"$linkname\"~(cd \"$destdir\" && $LN_S -f $dlname $func_stripname_result.so)'\n      postuninstall_cmds='test -z \"$dlname\" || func_append rmfiles \" $odir/$dlname\"~for n in $old_library $library_names; do :; done~func_stripname \"\" \".a\" \"$n\"~func_append rmfiles \" $odir/$func_stripname_result.so\"'\n      ;;\n    esac\n    shlibpath_var=LIBPATH\n  fi\n  ;;\n\namigaos*)\n  case $host_cpu in\n  powerpc)\n    # Since July 2007 AmigaOS4 officially supports .so libraries.\n    # When compiling the executable, add -use-dynld -Lsobjs: to the compileline.\n    library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n    ;;\n  m68k)\n    library_names_spec='$libname.ixlibrary $libname.a'\n    # Create ${libname}_ixlibrary.a entries in /sys/libs.\n    finish_eval='for lib in `ls $libdir/*.ixlibrary 2>/dev/null`; do libname=`func_echo_all \"$lib\" | $SED '\\''s%^.*/\\([[^/]]*\\)\\.ixlibrary$%\\1%'\\''`; $RM /sys/libs/${libname}_ixlibrary.a; $show \"cd /sys/libs && $LN_S $lib ${libname}_ixlibrary.a\"; cd /sys/libs && $LN_S $lib ${libname}_ixlibrary.a || exit 1; done'\n    ;;\n  esac\n  ;;\n\nbeos*)\n  library_names_spec='$libname$shared_ext'\n  dynamic_linker=\"$host_os ld.so\"\n  shlibpath_var=LIBRARY_PATH\n  ;;\n\nbsdi[[45]]*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  need_version=no\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  finish_cmds='PATH=\"\\$PATH:/sbin\" ldconfig $libdir'\n  shlibpath_var=LD_LIBRARY_PATH\n  sys_lib_search_path_spec=\"/shlib /usr/lib /usr/X11/lib /usr/contrib/lib /lib /usr/local/lib\"\n  sys_lib_dlsearch_path_spec=\"/shlib /usr/lib /usr/local/lib\"\n  # the default ld.so.conf also contains /usr/contrib/lib and\n  # /usr/X11R6/lib (/usr/X11 is a link to /usr/X11R6), but let us allow\n  # libtool to hard-code these into programs\n  ;;\n\ncygwin* | mingw* | pw32* | cegcc*)\n  version_type=windows\n  shrext_cmds=.dll\n  need_version=no\n  need_lib_prefix=no\n\n  case $GCC,$cc_basename in\n  yes,*)\n    # gcc\n    library_names_spec='$libname.dll.a'\n    # DLL is installed to $(libdir)/../bin by postinstall_cmds\n    postinstall_cmds='base_file=`basename \\$file`~\n      dlpath=`$SHELL 2>&1 -c '\\''. $dir/'\\''\\$base_file'\\''i; echo \\$dlname'\\''`~\n      dldir=$destdir/`dirname \\$dlpath`~\n      test -d \\$dldir || mkdir -p \\$dldir~\n      $install_prog $dir/$dlname \\$dldir/$dlname~\n      chmod a+x \\$dldir/$dlname~\n      if test -n '\\''$stripme'\\'' && test -n '\\''$striplib'\\''; then\n        eval '\\''$striplib \\$dldir/$dlname'\\'' || exit \\$?;\n      fi'\n    postuninstall_cmds='dldll=`$SHELL 2>&1 -c '\\''. $file; echo \\$dlname'\\''`~\n      dlpath=$dir/\\$dldll~\n       $RM \\$dlpath'\n    shlibpath_overrides_runpath=yes\n\n    case $host_os in\n    cygwin*)\n      # Cygwin DLLs use 'cyg' prefix rather than 'lib'\n      soname_spec='`echo $libname | sed -e 's/^lib/cyg/'``echo $release | $SED -e 's/[[.]]/-/g'`$versuffix$shared_ext'\nm4_if([$1], [],[\n      sys_lib_search_path_spec=\"$sys_lib_search_path_spec /usr/lib/w32api\"])\n      ;;\n    mingw* | cegcc*)\n      # MinGW DLLs use traditional 'lib' prefix\n      soname_spec='$libname`echo $release | $SED -e 's/[[.]]/-/g'`$versuffix$shared_ext'\n      ;;\n    pw32*)\n      # pw32 DLLs use 'pw' prefix rather than 'lib'\n      library_names_spec='`echo $libname | sed -e 's/^lib/pw/'``echo $release | $SED -e 's/[[.]]/-/g'`$versuffix$shared_ext'\n      ;;\n    esac\n    dynamic_linker='Win32 ld.exe'\n    ;;\n\n  *,cl*)\n    # Native MSVC\n    libname_spec='$name'\n    soname_spec='$libname`echo $release | $SED -e 's/[[.]]/-/g'`$versuffix$shared_ext'\n    library_names_spec='$libname.dll.lib'\n\n    case $build_os in\n    mingw*)\n      sys_lib_search_path_spec=\n      lt_save_ifs=$IFS\n      IFS=';'\n      for lt_path in $LIB\n      do\n        IFS=$lt_save_ifs\n        # Let DOS variable expansion print the short 8.3 style file name.\n        lt_path=`cd \"$lt_path\" 2>/dev/null && cmd //C \"for %i in (\".\") do @echo %~si\"`\n        sys_lib_search_path_spec=\"$sys_lib_search_path_spec $lt_path\"\n      done\n      IFS=$lt_save_ifs\n      # Convert to MSYS style.\n      sys_lib_search_path_spec=`$ECHO \"$sys_lib_search_path_spec\" | sed -e 's|\\\\\\\\|/|g' -e 's| \\\\([[a-zA-Z]]\\\\):| /\\\\1|g' -e 's|^ ||'`\n      ;;\n    cygwin*)\n      # Convert to unix form, then to dos form, then back to unix form\n      # but this time dos style (no spaces!) so that the unix form looks\n      # like /cygdrive/c/PROGRA~1:/cygdr...\n      sys_lib_search_path_spec=`cygpath --path --unix \"$LIB\"`\n      sys_lib_search_path_spec=`cygpath --path --dos \"$sys_lib_search_path_spec\" 2>/dev/null`\n      sys_lib_search_path_spec=`cygpath --path --unix \"$sys_lib_search_path_spec\" | $SED -e \"s/$PATH_SEPARATOR/ /g\"`\n      ;;\n    *)\n      sys_lib_search_path_spec=$LIB\n      if $ECHO \"$sys_lib_search_path_spec\" | [$GREP ';[c-zC-Z]:/' >/dev/null]; then\n        # It is most probably a Windows format PATH.\n        sys_lib_search_path_spec=`$ECHO \"$sys_lib_search_path_spec\" | $SED -e 's/;/ /g'`\n      else\n        sys_lib_search_path_spec=`$ECHO \"$sys_lib_search_path_spec\" | $SED -e \"s/$PATH_SEPARATOR/ /g\"`\n      fi\n      # FIXME: find the short name or the path components, as spaces are\n      # common. (e.g. \"Program Files\" -> \"PROGRA~1\")\n      ;;\n    esac\n\n    # DLL is installed to $(libdir)/../bin by postinstall_cmds\n    postinstall_cmds='base_file=`basename \\$file`~\n      dlpath=`$SHELL 2>&1 -c '\\''. $dir/'\\''\\$base_file'\\''i; echo \\$dlname'\\''`~\n      dldir=$destdir/`dirname \\$dlpath`~\n      test -d \\$dldir || mkdir -p \\$dldir~\n      $install_prog $dir/$dlname \\$dldir/$dlname'\n    postuninstall_cmds='dldll=`$SHELL 2>&1 -c '\\''. $file; echo \\$dlname'\\''`~\n      dlpath=$dir/\\$dldll~\n       $RM \\$dlpath'\n    shlibpath_overrides_runpath=yes\n    dynamic_linker='Win32 link.exe'\n    ;;\n\n  *)\n    # Assume MSVC wrapper\n    library_names_spec='$libname`echo $release | $SED -e 's/[[.]]/-/g'`$versuffix$shared_ext $libname.lib'\n    dynamic_linker='Win32 ld.exe'\n    ;;\n  esac\n  # FIXME: first we should search . and the directory the executable is in\n  shlibpath_var=PATH\n  ;;\n\ndarwin* | rhapsody*)\n  dynamic_linker=\"$host_os dyld\"\n  version_type=darwin\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='$libname$release$major$shared_ext $libname$shared_ext'\n  soname_spec='$libname$release$major$shared_ext'\n  shlibpath_overrides_runpath=yes\n  shlibpath_var=DYLD_LIBRARY_PATH\n  shrext_cmds='`test .$module = .yes && echo .so || echo .dylib`'\nm4_if([$1], [],[\n  sys_lib_search_path_spec=\"$sys_lib_search_path_spec /usr/local/lib\"])\n  sys_lib_dlsearch_path_spec='/usr/local/lib /lib /usr/lib'\n  ;;\n\ndgux*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  shlibpath_var=LD_LIBRARY_PATH\n  ;;\n\nfreebsd* | dragonfly*)\n  # DragonFly does not have aout.  When/if they implement a new\n  # versioning mechanism, adjust this.\n  if test -x /usr/bin/objformat; then\n    objformat=`/usr/bin/objformat`\n  else\n    case $host_os in\n    freebsd[[23]].*) objformat=aout ;;\n    *) objformat=elf ;;\n    esac\n  fi\n  version_type=freebsd-$objformat\n  case $version_type in\n    freebsd-elf*)\n      library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n      soname_spec='$libname$release$shared_ext$major'\n      need_version=no\n      need_lib_prefix=no\n      ;;\n    freebsd-*)\n      library_names_spec='$libname$release$shared_ext$versuffix $libname$shared_ext$versuffix'\n      need_version=yes\n      ;;\n  esac\n  shlibpath_var=LD_LIBRARY_PATH\n  case $host_os in\n  freebsd2.*)\n    shlibpath_overrides_runpath=yes\n    ;;\n  freebsd3.[[01]]* | freebsdelf3.[[01]]*)\n    shlibpath_overrides_runpath=yes\n    hardcode_into_libs=yes\n    ;;\n  freebsd3.[[2-9]]* | freebsdelf3.[[2-9]]* | \\\n  freebsd4.[[0-5]] | freebsdelf4.[[0-5]] | freebsd4.1.1 | freebsdelf4.1.1)\n    shlibpath_overrides_runpath=no\n    hardcode_into_libs=yes\n    ;;\n  *) # from 4.6 on, and DragonFly\n    shlibpath_overrides_runpath=yes\n    hardcode_into_libs=yes\n    ;;\n  esac\n  ;;\n\nhaiku*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  need_lib_prefix=no\n  need_version=no\n  dynamic_linker=\"$host_os runtime_loader\"\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  shlibpath_var=LIBRARY_PATH\n  shlibpath_overrides_runpath=no\n  sys_lib_dlsearch_path_spec='/boot/home/config/lib /boot/common/lib /boot/system/lib'\n  hardcode_into_libs=yes\n  ;;\n\nhpux9* | hpux10* | hpux11*)\n  # Give a soname corresponding to the major version so that dld.sl refuses to\n  # link against other versions.\n  version_type=sunos\n  need_lib_prefix=no\n  need_version=no\n  case $host_cpu in\n  ia64*)\n    shrext_cmds='.so'\n    hardcode_into_libs=yes\n    dynamic_linker=\"$host_os dld.so\"\n    shlibpath_var=LD_LIBRARY_PATH\n    shlibpath_overrides_runpath=yes # Unless +noenvvar is specified.\n    library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n    soname_spec='$libname$release$shared_ext$major'\n    if test 32 = \"$HPUX_IA64_MODE\"; then\n      sys_lib_search_path_spec=\"/usr/lib/hpux32 /usr/local/lib/hpux32 /usr/local/lib\"\n      sys_lib_dlsearch_path_spec=/usr/lib/hpux32\n    else\n      sys_lib_search_path_spec=\"/usr/lib/hpux64 /usr/local/lib/hpux64\"\n      sys_lib_dlsearch_path_spec=/usr/lib/hpux64\n    fi\n    ;;\n  hppa*64*)\n    shrext_cmds='.sl'\n    hardcode_into_libs=yes\n    dynamic_linker=\"$host_os dld.sl\"\n    shlibpath_var=LD_LIBRARY_PATH # How should we handle SHLIB_PATH\n    shlibpath_overrides_runpath=yes # Unless +noenvvar is specified.\n    library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n    soname_spec='$libname$release$shared_ext$major'\n    sys_lib_search_path_spec=\"/usr/lib/pa20_64 /usr/ccs/lib/pa20_64\"\n    sys_lib_dlsearch_path_spec=$sys_lib_search_path_spec\n    ;;\n  *)\n    shrext_cmds='.sl'\n    dynamic_linker=\"$host_os dld.sl\"\n    shlibpath_var=SHLIB_PATH\n    shlibpath_overrides_runpath=no # +s is required to enable SHLIB_PATH\n    library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n    soname_spec='$libname$release$shared_ext$major'\n    ;;\n  esac\n  # HP-UX runs *really* slowly unless shared libraries are mode 555, ...\n  postinstall_cmds='chmod 555 $lib'\n  # or fails outright, so override atomically:\n  install_override_mode=555\n  ;;\n\ninterix[[3-9]]*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  dynamic_linker='Interix 3.x ld.so.1 (PE, like ELF)'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=no\n  hardcode_into_libs=yes\n  ;;\n\nirix5* | irix6* | nonstopux*)\n  case $host_os in\n    nonstopux*) version_type=nonstopux ;;\n    *)\n\tif test yes = \"$lt_cv_prog_gnu_ld\"; then\n\t\tversion_type=linux # correct to gnu/linux during the next big refactor\n\telse\n\t\tversion_type=irix\n\tfi ;;\n  esac\n  need_lib_prefix=no\n  need_version=no\n  soname_spec='$libname$release$shared_ext$major'\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$release$shared_ext $libname$shared_ext'\n  case $host_os in\n  irix5* | nonstopux*)\n    libsuff= shlibsuff=\n    ;;\n  *)\n    case $LD in # libtool.m4 will add one of these switches to LD\n    *-32|*\"-32 \"|*-melf32bsmip|*\"-melf32bsmip \")\n      libsuff= shlibsuff= libmagic=32-bit;;\n    *-n32|*\"-n32 \"|*-melf32bmipn32|*\"-melf32bmipn32 \")\n      libsuff=32 shlibsuff=N32 libmagic=N32;;\n    *-64|*\"-64 \"|*-melf64bmip|*\"-melf64bmip \")\n      libsuff=64 shlibsuff=64 libmagic=64-bit;;\n    *) libsuff= shlibsuff= libmagic=never-match;;\n    esac\n    ;;\n  esac\n  shlibpath_var=LD_LIBRARY${shlibsuff}_PATH\n  shlibpath_overrides_runpath=no\n  sys_lib_search_path_spec=\"/usr/lib$libsuff /lib$libsuff /usr/local/lib$libsuff\"\n  sys_lib_dlsearch_path_spec=\"/usr/lib$libsuff /lib$libsuff\"\n  hardcode_into_libs=yes\n  ;;\n\n# No shared lib support for Linux oldld, aout, or coff.\nlinux*oldld* | linux*aout* | linux*coff*)\n  dynamic_linker=no\n  ;;\n\nlinux*android*)\n  version_type=none # Android doesn't support versioned libraries.\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='$libname$release$shared_ext'\n  soname_spec='$libname$release$shared_ext'\n  finish_cmds=\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=yes\n\n  # This implies no fast_install, which is unacceptable.\n  # Some rework will be needed to allow for fast_install\n  # before this can be enabled.\n  hardcode_into_libs=yes\n\n  dynamic_linker='Android linker'\n  # Don't embed -rpath directories since the linker doesn't support them.\n  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n  ;;\n\n# This must be glibc/ELF.\nlinux* | k*bsd*-gnu | kopensolaris*-gnu | gnu*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  finish_cmds='PATH=\"\\$PATH:/sbin\" ldconfig -n $libdir'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=no\n\n  # Some binutils ld are patched to set DT_RUNPATH\n  AC_CACHE_VAL([lt_cv_shlibpath_overrides_runpath],\n    [lt_cv_shlibpath_overrides_runpath=no\n    save_LDFLAGS=$LDFLAGS\n    save_libdir=$libdir\n    eval \"libdir=/foo; wl=\\\"$_LT_TAGVAR(lt_prog_compiler_wl, $1)\\\"; \\\n\t LDFLAGS=\\\"\\$LDFLAGS $_LT_TAGVAR(hardcode_libdir_flag_spec, $1)\\\"\"\n    AC_LINK_IFELSE([AC_LANG_PROGRAM([],[])],\n      [AS_IF([ ($OBJDUMP -p conftest$ac_exeext) 2>/dev/null | grep \"RUNPATH.*$libdir\" >/dev/null],\n\t [lt_cv_shlibpath_overrides_runpath=yes])])\n    LDFLAGS=$save_LDFLAGS\n    libdir=$save_libdir\n    ])\n  shlibpath_overrides_runpath=$lt_cv_shlibpath_overrides_runpath\n\n  # This implies no fast_install, which is unacceptable.\n  # Some rework will be needed to allow for fast_install\n  # before this can be enabled.\n  hardcode_into_libs=yes\n\n  # Ideally, we could use ldconfig to report *all* directores which are\n  # searched for libraries, however this is still not possible.  Aside from not\n  # being certain /sbin/ldconfig is available, command\n  # 'ldconfig -N -X -v | grep ^/' on 64bit Fedora does not report /usr/lib64,\n  # even though it is searched at run-time.  Try to do the best guess by\n  # appending ld.so.conf contents (and includes) to the search path.\n  if test -f /etc/ld.so.conf; then\n    lt_ld_extra=`awk '/^include / { system(sprintf(\"cd /etc; cat %s 2>/dev/null\", \\[$]2)); skip = 1; } { if (!skip) print \\[$]0; skip = 0; }' < /etc/ld.so.conf | $SED -e 's/#.*//;/^[\t ]*hwcap[\t ]/d;s/[:,\t]/ /g;s/=[^=]*$//;s/=[^= ]* / /g;s/\"//g;/^$/d' | tr '\\n' ' '`\n    sys_lib_dlsearch_path_spec=\"/lib /usr/lib $lt_ld_extra\"\n  fi\n\n  # We used to test for /lib/ld.so.1 and disable shared libraries on\n  # powerpc, because MkLinux only supported shared libraries with the\n  # GNU dynamic linker.  Since this was broken with cross compilers,\n  # most powerpc-linux boxes support dynamic linking these days and\n  # people can always --disable-shared, the test was removed, and we\n  # assume the GNU/Linux dynamic linker is in use.\n  dynamic_linker='GNU/Linux ld.so'\n  ;;\n\nnetbsd*)\n  version_type=sunos\n  need_lib_prefix=no\n  need_version=no\n  if echo __ELF__ | $CC -E - | $GREP __ELF__ >/dev/null; then\n    library_names_spec='$libname$release$shared_ext$versuffix $libname$shared_ext$versuffix'\n    finish_cmds='PATH=\"\\$PATH:/sbin\" ldconfig -m $libdir'\n    dynamic_linker='NetBSD (a.out) ld.so'\n  else\n    library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n    soname_spec='$libname$release$shared_ext$major'\n    dynamic_linker='NetBSD ld.elf_so'\n  fi\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=yes\n  hardcode_into_libs=yes\n  ;;\n\nnewsos6)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=yes\n  ;;\n\n*nto* | *qnx*)\n  version_type=qnx\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=no\n  hardcode_into_libs=yes\n  dynamic_linker='ldqnx.so'\n  ;;\n\nopenbsd* | bitrig*)\n  version_type=sunos\n  sys_lib_dlsearch_path_spec=/usr/lib\n  need_lib_prefix=no\n  if test -z \"`echo __ELF__ | $CC -E - | $GREP __ELF__`\"; then\n    need_version=no\n  else\n    need_version=yes\n  fi\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$shared_ext$versuffix'\n  finish_cmds='PATH=\"\\$PATH:/sbin\" ldconfig -m $libdir'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=yes\n  ;;\n\nos2*)\n  libname_spec='$name'\n  version_type=windows\n  shrext_cmds=.dll\n  need_version=no\n  need_lib_prefix=no\n  # OS/2 can only load a DLL with a base name of 8 characters or less.\n  soname_spec='`test -n \"$os2dllname\" && libname=\"$os2dllname\";\n    v=$($ECHO $release$versuffix | tr -d .-);\n    n=$($ECHO $libname | cut -b -$((8 - ${#v})) | tr . _);\n    $ECHO $n$v`$shared_ext'\n  library_names_spec='${libname}_dll.$libext'\n  dynamic_linker='OS/2 ld.exe'\n  shlibpath_var=BEGINLIBPATH\n  sys_lib_search_path_spec=\"/lib /usr/lib /usr/local/lib\"\n  sys_lib_dlsearch_path_spec=$sys_lib_search_path_spec\n  postinstall_cmds='base_file=`basename \\$file`~\n    dlpath=`$SHELL 2>&1 -c '\\''. $dir/'\\''\\$base_file'\\''i; $ECHO \\$dlname'\\''`~\n    dldir=$destdir/`dirname \\$dlpath`~\n    test -d \\$dldir || mkdir -p \\$dldir~\n    $install_prog $dir/$dlname \\$dldir/$dlname~\n    chmod a+x \\$dldir/$dlname~\n    if test -n '\\''$stripme'\\'' && test -n '\\''$striplib'\\''; then\n      eval '\\''$striplib \\$dldir/$dlname'\\'' || exit \\$?;\n    fi'\n  postuninstall_cmds='dldll=`$SHELL 2>&1 -c '\\''. $file; $ECHO \\$dlname'\\''`~\n    dlpath=$dir/\\$dldll~\n    $RM \\$dlpath'\n  ;;\n\nosf3* | osf4* | osf5*)\n  version_type=osf\n  need_lib_prefix=no\n  need_version=no\n  soname_spec='$libname$release$shared_ext$major'\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  shlibpath_var=LD_LIBRARY_PATH\n  sys_lib_search_path_spec=\"/usr/shlib /usr/ccs/lib /usr/lib/cmplrs/cc /usr/lib /usr/local/lib /var/shlib\"\n  sys_lib_dlsearch_path_spec=$sys_lib_search_path_spec\n  ;;\n\nrdos*)\n  dynamic_linker=no\n  ;;\n\nsolaris*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=yes\n  hardcode_into_libs=yes\n  # ldd complains unless libraries are executable\n  postinstall_cmds='chmod +x $lib'\n  ;;\n\nsunos4*)\n  version_type=sunos\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$shared_ext$versuffix'\n  finish_cmds='PATH=\"\\$PATH:/usr/etc\" ldconfig $libdir'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=yes\n  if test yes = \"$with_gnu_ld\"; then\n    need_lib_prefix=no\n  fi\n  need_version=yes\n  ;;\n\nsysv4 | sysv4.3*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  shlibpath_var=LD_LIBRARY_PATH\n  case $host_vendor in\n    sni)\n      shlibpath_overrides_runpath=no\n      need_lib_prefix=no\n      runpath_var=LD_RUN_PATH\n      ;;\n    siemens)\n      need_lib_prefix=no\n      ;;\n    motorola)\n      need_lib_prefix=no\n      need_version=no\n      shlibpath_overrides_runpath=no\n      sys_lib_search_path_spec='/lib /usr/lib /usr/ccs/lib'\n      ;;\n  esac\n  ;;\n\nsysv4*MP*)\n  if test -d /usr/nec; then\n    version_type=linux # correct to gnu/linux during the next big refactor\n    library_names_spec='$libname$shared_ext.$versuffix $libname$shared_ext.$major $libname$shared_ext'\n    soname_spec='$libname$shared_ext.$major'\n    shlibpath_var=LD_LIBRARY_PATH\n  fi\n  ;;\n\nsysv5* | sco3.2v5* | sco5v6* | unixware* | OpenUNIX* | sysv4*uw2*)\n  version_type=sco\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=yes\n  hardcode_into_libs=yes\n  if test yes = \"$with_gnu_ld\"; then\n    sys_lib_search_path_spec='/usr/local/lib /usr/gnu/lib /usr/ccs/lib /usr/lib /lib'\n  else\n    sys_lib_search_path_spec='/usr/ccs/lib /usr/lib'\n    case $host_os in\n      sco3.2v5*)\n        sys_lib_search_path_spec=\"$sys_lib_search_path_spec /lib\"\n\t;;\n    esac\n  fi\n  sys_lib_dlsearch_path_spec='/usr/lib'\n  ;;\n\ntpf*)\n  # TPF is a cross-target only.  Preferred cross-host = GNU/Linux.\n  version_type=linux # correct to gnu/linux during the next big refactor\n  need_lib_prefix=no\n  need_version=no\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  shlibpath_var=LD_LIBRARY_PATH\n  shlibpath_overrides_runpath=no\n  hardcode_into_libs=yes\n  ;;\n\nuts4*)\n  version_type=linux # correct to gnu/linux during the next big refactor\n  library_names_spec='$libname$release$shared_ext$versuffix $libname$release$shared_ext$major $libname$shared_ext'\n  soname_spec='$libname$release$shared_ext$major'\n  shlibpath_var=LD_LIBRARY_PATH\n  ;;\n\n*)\n  dynamic_linker=no\n  ;;\nesac\nAC_MSG_RESULT([$dynamic_linker])\ntest no = \"$dynamic_linker\" && can_build_shared=no\n\nvariables_saved_for_relink=\"PATH $shlibpath_var $runpath_var\"\nif test yes = \"$GCC\"; then\n  variables_saved_for_relink=\"$variables_saved_for_relink GCC_EXEC_PREFIX COMPILER_PATH LIBRARY_PATH\"\nfi\n\nif test set = \"${lt_cv_sys_lib_search_path_spec+set}\"; then\n  sys_lib_search_path_spec=$lt_cv_sys_lib_search_path_spec\nfi\n\nif test set = \"${lt_cv_sys_lib_dlsearch_path_spec+set}\"; then\n  sys_lib_dlsearch_path_spec=$lt_cv_sys_lib_dlsearch_path_spec\nfi\n\n# remember unaugmented sys_lib_dlsearch_path content for libtool script decls...\nconfigure_time_dlsearch_path=$sys_lib_dlsearch_path_spec\n\n# ... but it needs LT_SYS_LIBRARY_PATH munging for other configure-time code\nfunc_munge_path_list sys_lib_dlsearch_path_spec \"$LT_SYS_LIBRARY_PATH\"\n\n# to be used as default LT_SYS_LIBRARY_PATH value in generated libtool\nconfigure_time_lt_sys_library_path=$LT_SYS_LIBRARY_PATH\n\n_LT_DECL([], [variables_saved_for_relink], [1],\n    [Variables whose values should be saved in libtool wrapper scripts and\n    restored at link time])\n_LT_DECL([], [need_lib_prefix], [0],\n    [Do we need the \"lib\" prefix for modules?])\n_LT_DECL([], [need_version], [0], [Do we need a version for libraries?])\n_LT_DECL([], [version_type], [0], [Library versioning type])\n_LT_DECL([], [runpath_var], [0],  [Shared library runtime path variable])\n_LT_DECL([], [shlibpath_var], [0],[Shared library path variable])\n_LT_DECL([], [shlibpath_overrides_runpath], [0],\n    [Is shlibpath searched before the hard-coded library search path?])\n_LT_DECL([], [libname_spec], [1], [Format of library name prefix])\n_LT_DECL([], [library_names_spec], [1],\n    [[List of archive names.  First name is the real one, the rest are links.\n    The last name is the one that the linker finds with -lNAME]])\n_LT_DECL([], [soname_spec], [1],\n    [[The coded name of the library, if different from the real name]])\n_LT_DECL([], [install_override_mode], [1],\n    [Permission mode override for installation of shared libraries])\n_LT_DECL([], [postinstall_cmds], [2],\n    [Command to use after installation of a shared archive])\n_LT_DECL([], [postuninstall_cmds], [2],\n    [Command to use after uninstallation of a shared archive])\n_LT_DECL([], [finish_cmds], [2],\n    [Commands used to finish a libtool library installation in a directory])\n_LT_DECL([], [finish_eval], [1],\n    [[As \"finish_cmds\", except a single script fragment to be evaled but\n    not shown]])\n_LT_DECL([], [hardcode_into_libs], [0],\n    [Whether we should hardcode library paths into libraries])\n_LT_DECL([], [sys_lib_search_path_spec], [2],\n    [Compile-time system search path for libraries])\n_LT_DECL([sys_lib_dlsearch_path_spec], [configure_time_dlsearch_path], [2],\n    [Detected run-time system search path for libraries])\n_LT_DECL([], [configure_time_lt_sys_library_path], [2],\n    [Explicit LT_SYS_LIBRARY_PATH set during ./configure time])\n])# _LT_SYS_DYNAMIC_LINKER\n\n\n# _LT_PATH_TOOL_PREFIX(TOOL)\n# --------------------------\n# find a file program that can recognize shared library\nAC_DEFUN([_LT_PATH_TOOL_PREFIX],\n[m4_require([_LT_DECL_EGREP])dnl\nAC_MSG_CHECKING([for $1])\nAC_CACHE_VAL(lt_cv_path_MAGIC_CMD,\n[case $MAGIC_CMD in\n[[\\\\/*] |  ?:[\\\\/]*])\n  lt_cv_path_MAGIC_CMD=$MAGIC_CMD # Let the user override the test with a path.\n  ;;\n*)\n  lt_save_MAGIC_CMD=$MAGIC_CMD\n  lt_save_ifs=$IFS; IFS=$PATH_SEPARATOR\ndnl $ac_dummy forces splitting on constant user-supplied paths.\ndnl POSIX.2 word splitting is done only on the output of word expansions,\ndnl not every word.  This closes a longstanding sh security hole.\n  ac_dummy=\"m4_if([$2], , $PATH, [$2])\"\n  for ac_dir in $ac_dummy; do\n    IFS=$lt_save_ifs\n    test -z \"$ac_dir\" && ac_dir=.\n    if test -f \"$ac_dir/$1\"; then\n      lt_cv_path_MAGIC_CMD=$ac_dir/\"$1\"\n      if test -n \"$file_magic_test_file\"; then\n\tcase $deplibs_check_method in\n\t\"file_magic \"*)\n\t  file_magic_regex=`expr \"$deplibs_check_method\" : \"file_magic \\(.*\\)\"`\n\t  MAGIC_CMD=$lt_cv_path_MAGIC_CMD\n\t  if eval $file_magic_cmd \\$file_magic_test_file 2> /dev/null |\n\t    $EGREP \"$file_magic_regex\" > /dev/null; then\n\t    :\n\t  else\n\t    cat <<_LT_EOF 1>&2\n\n*** Warning: the command libtool uses to detect shared libraries,\n*** $file_magic_cmd, produces output that libtool cannot recognize.\n*** The result is that libtool may fail to recognize shared libraries\n*** as such.  This will affect the creation of libtool libraries that\n*** depend on shared libraries, but programs linked with such libtool\n*** libraries will work regardless of this problem.  Nevertheless, you\n*** may want to report the problem to your system manager and/or to\n*** bug-libtool@gnu.org\n\n_LT_EOF\n\t  fi ;;\n\tesac\n      fi\n      break\n    fi\n  done\n  IFS=$lt_save_ifs\n  MAGIC_CMD=$lt_save_MAGIC_CMD\n  ;;\nesac])\nMAGIC_CMD=$lt_cv_path_MAGIC_CMD\nif test -n \"$MAGIC_CMD\"; then\n  AC_MSG_RESULT($MAGIC_CMD)\nelse\n  AC_MSG_RESULT(no)\nfi\n_LT_DECL([], [MAGIC_CMD], [0],\n\t [Used to examine libraries when file_magic_cmd begins with \"file\"])dnl\n])# _LT_PATH_TOOL_PREFIX\n\n# Old name:\nAU_ALIAS([AC_PATH_TOOL_PREFIX], [_LT_PATH_TOOL_PREFIX])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_PATH_TOOL_PREFIX], [])\n\n\n# _LT_PATH_MAGIC\n# --------------\n# find a file program that can recognize a shared library\nm4_defun([_LT_PATH_MAGIC],\n[_LT_PATH_TOOL_PREFIX(${ac_tool_prefix}file, /usr/bin$PATH_SEPARATOR$PATH)\nif test -z \"$lt_cv_path_MAGIC_CMD\"; then\n  if test -n \"$ac_tool_prefix\"; then\n    _LT_PATH_TOOL_PREFIX(file, /usr/bin$PATH_SEPARATOR$PATH)\n  else\n    MAGIC_CMD=:\n  fi\nfi\n])# _LT_PATH_MAGIC\n\n\n# LT_PATH_LD\n# ----------\n# find the pathname to the GNU or non-GNU linker\nAC_DEFUN([LT_PATH_LD],\n[AC_REQUIRE([AC_PROG_CC])dnl\nAC_REQUIRE([AC_CANONICAL_HOST])dnl\nAC_REQUIRE([AC_CANONICAL_BUILD])dnl\nm4_require([_LT_DECL_SED])dnl\nm4_require([_LT_DECL_EGREP])dnl\nm4_require([_LT_PROG_ECHO_BACKSLASH])dnl\n\nAC_ARG_WITH([gnu-ld],\n    [AS_HELP_STRING([--with-gnu-ld],\n\t[assume the C compiler uses GNU ld @<:@default=no@:>@])],\n    [test no = \"$withval\" || with_gnu_ld=yes],\n    [with_gnu_ld=no])dnl\n\nac_prog=ld\nif test yes = \"$GCC\"; then\n  # Check if gcc -print-prog-name=ld gives a path.\n  AC_MSG_CHECKING([for ld used by $CC])\n  case $host in\n  *-*-mingw*)\n    # gcc leaves a trailing carriage return, which upsets mingw\n    ac_prog=`($CC -print-prog-name=ld) 2>&5 | tr -d '\\015'` ;;\n  *)\n    ac_prog=`($CC -print-prog-name=ld) 2>&5` ;;\n  esac\n  case $ac_prog in\n    # Accept absolute paths.\n    [[\\\\/]]* | ?:[[\\\\/]]*)\n      re_direlt='/[[^/]][[^/]]*/\\.\\./'\n      # Canonicalize the pathname of ld\n      ac_prog=`$ECHO \"$ac_prog\"| $SED 's%\\\\\\\\%/%g'`\n      while $ECHO \"$ac_prog\" | $GREP \"$re_direlt\" > /dev/null 2>&1; do\n\tac_prog=`$ECHO $ac_prog| $SED \"s%$re_direlt%/%\"`\n      done\n      test -z \"$LD\" && LD=$ac_prog\n      ;;\n  \"\")\n    # If it fails, then pretend we aren't using GCC.\n    ac_prog=ld\n    ;;\n  *)\n    # If it is relative, then search for the first ld in PATH.\n    with_gnu_ld=unknown\n    ;;\n  esac\nelif test yes = \"$with_gnu_ld\"; then\n  AC_MSG_CHECKING([for GNU ld])\nelse\n  AC_MSG_CHECKING([for non-GNU ld])\nfi\nAC_CACHE_VAL(lt_cv_path_LD,\n[if test -z \"$LD\"; then\n  lt_save_ifs=$IFS; IFS=$PATH_SEPARATOR\n  for ac_dir in $PATH; do\n    IFS=$lt_save_ifs\n    test -z \"$ac_dir\" && ac_dir=.\n    if test -f \"$ac_dir/$ac_prog\" || test -f \"$ac_dir/$ac_prog$ac_exeext\"; then\n      lt_cv_path_LD=$ac_dir/$ac_prog\n      # Check to see if the program is GNU ld.  I'd rather use --version,\n      # but apparently some variants of GNU ld only accept -v.\n      # Break only if it was the GNU/non-GNU ld that we prefer.\n      case `\"$lt_cv_path_LD\" -v 2>&1 </dev/null` in\n      *GNU* | *'with BFD'*)\n\ttest no != \"$with_gnu_ld\" && break\n\t;;\n      *)\n\ttest yes != \"$with_gnu_ld\" && break\n\t;;\n      esac\n    fi\n  done\n  IFS=$lt_save_ifs\nelse\n  lt_cv_path_LD=$LD # Let the user override the test with a path.\nfi])\nLD=$lt_cv_path_LD\nif test -n \"$LD\"; then\n  AC_MSG_RESULT($LD)\nelse\n  AC_MSG_RESULT(no)\nfi\ntest -z \"$LD\" && AC_MSG_ERROR([no acceptable ld found in \\$PATH])\n_LT_PATH_LD_GNU\nAC_SUBST([LD])\n\n_LT_TAGDECL([], [LD], [1], [The linker used to build libraries])\n])# LT_PATH_LD\n\n# Old names:\nAU_ALIAS([AM_PROG_LD], [LT_PATH_LD])\nAU_ALIAS([AC_PROG_LD], [LT_PATH_LD])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AM_PROG_LD], [])\ndnl AC_DEFUN([AC_PROG_LD], [])\n\n\n# _LT_PATH_LD_GNU\n#- --------------\nm4_defun([_LT_PATH_LD_GNU],\n[AC_CACHE_CHECK([if the linker ($LD) is GNU ld], lt_cv_prog_gnu_ld,\n[# I'd rather use --version here, but apparently some GNU lds only accept -v.\ncase `$LD -v 2>&1 </dev/null` in\n*GNU* | *'with BFD'*)\n  lt_cv_prog_gnu_ld=yes\n  ;;\n*)\n  lt_cv_prog_gnu_ld=no\n  ;;\nesac])\nwith_gnu_ld=$lt_cv_prog_gnu_ld\n])# _LT_PATH_LD_GNU\n\n\n# _LT_CMD_RELOAD\n# --------------\n# find reload flag for linker\n#   -- PORTME Some linkers may need a different reload flag.\nm4_defun([_LT_CMD_RELOAD],\n[AC_CACHE_CHECK([for $LD option to reload object files],\n  lt_cv_ld_reload_flag,\n  [lt_cv_ld_reload_flag='-r'])\nreload_flag=$lt_cv_ld_reload_flag\ncase $reload_flag in\n\"\" | \" \"*) ;;\n*) reload_flag=\" $reload_flag\" ;;\nesac\nreload_cmds='$LD$reload_flag -o $output$reload_objs'\ncase $host_os in\n  cygwin* | mingw* | pw32* | cegcc*)\n    if test yes != \"$GCC\"; then\n      reload_cmds=false\n    fi\n    ;;\n  darwin*)\n    if test yes = \"$GCC\"; then\n      reload_cmds='$LTCC $LTCFLAGS -nostdlib $wl-r -o $output$reload_objs'\n    else\n      reload_cmds='$LD$reload_flag -o $output$reload_objs'\n    fi\n    ;;\nesac\n_LT_TAGDECL([], [reload_flag], [1], [How to create reloadable object files])dnl\n_LT_TAGDECL([], [reload_cmds], [2])dnl\n])# _LT_CMD_RELOAD\n\n\n# _LT_PATH_DD\n# -----------\n# find a working dd\nm4_defun([_LT_PATH_DD],\n[AC_CACHE_CHECK([for a working dd], [ac_cv_path_lt_DD],\n[printf 0123456789abcdef0123456789abcdef >conftest.i\ncat conftest.i conftest.i >conftest2.i\n: ${lt_DD:=$DD}\nAC_PATH_PROGS_FEATURE_CHECK([lt_DD], [dd],\n[if \"$ac_path_lt_DD\" bs=32 count=1 <conftest2.i >conftest.out 2>/dev/null; then\n  cmp -s conftest.i conftest.out \\\n  && ac_cv_path_lt_DD=\"$ac_path_lt_DD\" ac_path_lt_DD_found=:\nfi])\nrm -f conftest.i conftest2.i conftest.out])\n])# _LT_PATH_DD\n\n\n# _LT_CMD_TRUNCATE\n# ----------------\n# find command to truncate a binary pipe\nm4_defun([_LT_CMD_TRUNCATE],\n[m4_require([_LT_PATH_DD])\nAC_CACHE_CHECK([how to truncate binary pipes], [lt_cv_truncate_bin],\n[printf 0123456789abcdef0123456789abcdef >conftest.i\ncat conftest.i conftest.i >conftest2.i\nlt_cv_truncate_bin=\nif \"$ac_cv_path_lt_DD\" bs=32 count=1 <conftest2.i >conftest.out 2>/dev/null; then\n  cmp -s conftest.i conftest.out \\\n  && lt_cv_truncate_bin=\"$ac_cv_path_lt_DD bs=4096 count=1\"\nfi\nrm -f conftest.i conftest2.i conftest.out\ntest -z \"$lt_cv_truncate_bin\" && lt_cv_truncate_bin=\"$SED -e 4q\"])\n_LT_DECL([lt_truncate_bin], [lt_cv_truncate_bin], [1],\n  [Command to truncate a binary pipe])\n])# _LT_CMD_TRUNCATE\n\n\n# _LT_CHECK_MAGIC_METHOD\n# ----------------------\n# how to check for library dependencies\n#  -- PORTME fill in with the dynamic library characteristics\nm4_defun([_LT_CHECK_MAGIC_METHOD],\n[m4_require([_LT_DECL_EGREP])\nm4_require([_LT_DECL_OBJDUMP])\nAC_CACHE_CHECK([how to recognize dependent libraries],\nlt_cv_deplibs_check_method,\n[lt_cv_file_magic_cmd='$MAGIC_CMD'\nlt_cv_file_magic_test_file=\nlt_cv_deplibs_check_method='unknown'\n# Need to set the preceding variable on all platforms that support\n# interlibrary dependencies.\n# 'none' -- dependencies not supported.\n# 'unknown' -- same as none, but documents that we really don't know.\n# 'pass_all' -- all dependencies passed with no checks.\n# 'test_compile' -- check by making test program.\n# 'file_magic [[regex]]' -- check by looking for files in library path\n# that responds to the $file_magic_cmd with a given extended regex.\n# If you have 'file' or equivalent on your system and you're not sure\n# whether 'pass_all' will *always* work, you probably want this one.\n\ncase $host_os in\naix[[4-9]]*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nbeos*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nbsdi[[45]]*)\n  lt_cv_deplibs_check_method='file_magic ELF [[0-9]][[0-9]]*-bit [[ML]]SB (shared object|dynamic lib)'\n  lt_cv_file_magic_cmd='/usr/bin/file -L'\n  lt_cv_file_magic_test_file=/shlib/libc.so\n  ;;\n\ncygwin*)\n  # func_win32_libid is a shell function defined in ltmain.sh\n  lt_cv_deplibs_check_method='file_magic ^x86 archive import|^x86 DLL'\n  lt_cv_file_magic_cmd='func_win32_libid'\n  ;;\n\nmingw* | pw32*)\n  # Base MSYS/MinGW do not provide the 'file' command needed by\n  # func_win32_libid shell function, so use a weaker test based on 'objdump',\n  # unless we find 'file', for example because we are cross-compiling.\n  if ( file / ) >/dev/null 2>&1; then\n    lt_cv_deplibs_check_method='file_magic ^x86 archive import|^x86 DLL'\n    lt_cv_file_magic_cmd='func_win32_libid'\n  else\n    # Keep this pattern in sync with the one in func_win32_libid.\n    lt_cv_deplibs_check_method='file_magic file format (pei*-i386(.*architecture: i386)?|pe-arm-wince|pe-x86-64)'\n    lt_cv_file_magic_cmd='$OBJDUMP -f'\n  fi\n  ;;\n\ncegcc*)\n  # use the weaker test based on 'objdump'. See mingw*.\n  lt_cv_deplibs_check_method='file_magic file format pe-arm-.*little(.*architecture: arm)?'\n  lt_cv_file_magic_cmd='$OBJDUMP -f'\n  ;;\n\ndarwin* | rhapsody*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nfreebsd* | dragonfly*)\n  if echo __ELF__ | $CC -E - | $GREP __ELF__ > /dev/null; then\n    case $host_cpu in\n    i*86 )\n      # Not sure whether the presence of OpenBSD here was a mistake.\n      # Let's accept both of them until this is cleared up.\n      lt_cv_deplibs_check_method='file_magic (FreeBSD|OpenBSD|DragonFly)/i[[3-9]]86 (compact )?demand paged shared library'\n      lt_cv_file_magic_cmd=/usr/bin/file\n      lt_cv_file_magic_test_file=`echo /usr/lib/libc.so.*`\n      ;;\n    esac\n  else\n    lt_cv_deplibs_check_method=pass_all\n  fi\n  ;;\n\nhaiku*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nhpux10.20* | hpux11*)\n  lt_cv_file_magic_cmd=/usr/bin/file\n  case $host_cpu in\n  ia64*)\n    lt_cv_deplibs_check_method='file_magic (s[[0-9]][[0-9]][[0-9]]|ELF-[[0-9]][[0-9]]) shared object file - IA64'\n    lt_cv_file_magic_test_file=/usr/lib/hpux32/libc.so\n    ;;\n  hppa*64*)\n    [lt_cv_deplibs_check_method='file_magic (s[0-9][0-9][0-9]|ELF[ -][0-9][0-9])(-bit)?( [LM]SB)? shared object( file)?[, -]* PA-RISC [0-9]\\.[0-9]']\n    lt_cv_file_magic_test_file=/usr/lib/pa20_64/libc.sl\n    ;;\n  *)\n    lt_cv_deplibs_check_method='file_magic (s[[0-9]][[0-9]][[0-9]]|PA-RISC[[0-9]]\\.[[0-9]]) shared library'\n    lt_cv_file_magic_test_file=/usr/lib/libc.sl\n    ;;\n  esac\n  ;;\n\ninterix[[3-9]]*)\n  # PIC code is broken on Interix 3.x, that's why |\\.a not |_pic\\.a here\n  lt_cv_deplibs_check_method='match_pattern /lib[[^/]]+(\\.so|\\.a)$'\n  ;;\n\nirix5* | irix6* | nonstopux*)\n  case $LD in\n  *-32|*\"-32 \") libmagic=32-bit;;\n  *-n32|*\"-n32 \") libmagic=N32;;\n  *-64|*\"-64 \") libmagic=64-bit;;\n  *) libmagic=never-match;;\n  esac\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\n# This must be glibc/ELF.\nlinux* | k*bsd*-gnu | kopensolaris*-gnu | gnu*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nnetbsd*)\n  if echo __ELF__ | $CC -E - | $GREP __ELF__ > /dev/null; then\n    lt_cv_deplibs_check_method='match_pattern /lib[[^/]]+(\\.so\\.[[0-9]]+\\.[[0-9]]+|_pic\\.a)$'\n  else\n    lt_cv_deplibs_check_method='match_pattern /lib[[^/]]+(\\.so|_pic\\.a)$'\n  fi\n  ;;\n\nnewos6*)\n  lt_cv_deplibs_check_method='file_magic ELF [[0-9]][[0-9]]*-bit [[ML]]SB (executable|dynamic lib)'\n  lt_cv_file_magic_cmd=/usr/bin/file\n  lt_cv_file_magic_test_file=/usr/lib/libnls.so\n  ;;\n\n*nto* | *qnx*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nopenbsd* | bitrig*)\n  if test -z \"`echo __ELF__ | $CC -E - | $GREP __ELF__`\"; then\n    lt_cv_deplibs_check_method='match_pattern /lib[[^/]]+(\\.so\\.[[0-9]]+\\.[[0-9]]+|\\.so|_pic\\.a)$'\n  else\n    lt_cv_deplibs_check_method='match_pattern /lib[[^/]]+(\\.so\\.[[0-9]]+\\.[[0-9]]+|_pic\\.a)$'\n  fi\n  ;;\n\nosf3* | osf4* | osf5*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nrdos*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nsolaris*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nsysv5* | sco3.2v5* | sco5v6* | unixware* | OpenUNIX* | sysv4*uw2*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\n\nsysv4 | sysv4.3*)\n  case $host_vendor in\n  motorola)\n    lt_cv_deplibs_check_method='file_magic ELF [[0-9]][[0-9]]*-bit [[ML]]SB (shared object|dynamic lib) M[[0-9]][[0-9]]* Version [[0-9]]'\n    lt_cv_file_magic_test_file=`echo /usr/lib/libc.so*`\n    ;;\n  ncr)\n    lt_cv_deplibs_check_method=pass_all\n    ;;\n  sequent)\n    lt_cv_file_magic_cmd='/bin/file'\n    lt_cv_deplibs_check_method='file_magic ELF [[0-9]][[0-9]]*-bit [[LM]]SB (shared object|dynamic lib )'\n    ;;\n  sni)\n    lt_cv_file_magic_cmd='/bin/file'\n    lt_cv_deplibs_check_method=\"file_magic ELF [[0-9]][[0-9]]*-bit [[LM]]SB dynamic lib\"\n    lt_cv_file_magic_test_file=/lib/libc.so\n    ;;\n  siemens)\n    lt_cv_deplibs_check_method=pass_all\n    ;;\n  pc)\n    lt_cv_deplibs_check_method=pass_all\n    ;;\n  esac\n  ;;\n\ntpf*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\nos2*)\n  lt_cv_deplibs_check_method=pass_all\n  ;;\nesac\n])\n\nfile_magic_glob=\nwant_nocaseglob=no\nif test \"$build\" = \"$host\"; then\n  case $host_os in\n  mingw* | pw32*)\n    if ( shopt | grep nocaseglob ) >/dev/null 2>&1; then\n      want_nocaseglob=yes\n    else\n      file_magic_glob=`echo aAbBcCdDeEfFgGhHiIjJkKlLmMnNoOpPqQrRsStTuUvVwWxXyYzZ | $SED -e \"s/\\(..\\)/s\\/[[\\1]]\\/[[\\1]]\\/g;/g\"`\n    fi\n    ;;\n  esac\nfi\n\nfile_magic_cmd=$lt_cv_file_magic_cmd\ndeplibs_check_method=$lt_cv_deplibs_check_method\ntest -z \"$deplibs_check_method\" && deplibs_check_method=unknown\n\n_LT_DECL([], [deplibs_check_method], [1],\n    [Method to check whether dependent libraries are shared objects])\n_LT_DECL([], [file_magic_cmd], [1],\n    [Command to use when deplibs_check_method = \"file_magic\"])\n_LT_DECL([], [file_magic_glob], [1],\n    [How to find potential files when deplibs_check_method = \"file_magic\"])\n_LT_DECL([], [want_nocaseglob], [1],\n    [Find potential files using nocaseglob when deplibs_check_method = \"file_magic\"])\n])# _LT_CHECK_MAGIC_METHOD\n\n\n# LT_PATH_NM\n# ----------\n# find the pathname to a BSD- or MS-compatible name lister\nAC_DEFUN([LT_PATH_NM],\n[AC_REQUIRE([AC_PROG_CC])dnl\nAC_CACHE_CHECK([for BSD- or MS-compatible name lister (nm)], lt_cv_path_NM,\n[if test -n \"$NM\"; then\n  # Let the user override the test.\n  lt_cv_path_NM=$NM\nelse\n  lt_nm_to_check=${ac_tool_prefix}nm\n  if test -n \"$ac_tool_prefix\" && test \"$build\" = \"$host\"; then\n    lt_nm_to_check=\"$lt_nm_to_check nm\"\n  fi\n  for lt_tmp_nm in $lt_nm_to_check; do\n    lt_save_ifs=$IFS; IFS=$PATH_SEPARATOR\n    for ac_dir in $PATH /usr/ccs/bin/elf /usr/ccs/bin /usr/ucb /bin; do\n      IFS=$lt_save_ifs\n      test -z \"$ac_dir\" && ac_dir=.\n      tmp_nm=$ac_dir/$lt_tmp_nm\n      if test -f \"$tmp_nm\" || test -f \"$tmp_nm$ac_exeext\"; then\n\t# Check to see if the nm accepts a BSD-compat flag.\n\t# Adding the 'sed 1q' prevents false positives on HP-UX, which says:\n\t#   nm: unknown option \"B\" ignored\n\t# Tru64's nm complains that /dev/null is an invalid object file\n\t# MSYS converts /dev/null to NUL, MinGW nm treats NUL as empty\n\tcase $build_os in\n\tmingw*) lt_bad_file=conftest.nm/nofile ;;\n\t*) lt_bad_file=/dev/null ;;\n\tesac\n\tcase `\"$tmp_nm\" -B $lt_bad_file 2>&1 | sed '1q'` in\n\t*$lt_bad_file* | *'Invalid file or object type'*)\n\t  lt_cv_path_NM=\"$tmp_nm -B\"\n\t  break 2\n\t  ;;\n\t*)\n\t  case `\"$tmp_nm\" -p /dev/null 2>&1 | sed '1q'` in\n\t  */dev/null*)\n\t    lt_cv_path_NM=\"$tmp_nm -p\"\n\t    break 2\n\t    ;;\n\t  *)\n\t    lt_cv_path_NM=${lt_cv_path_NM=\"$tmp_nm\"} # keep the first match, but\n\t    continue # so that we can try to find one that supports BSD flags\n\t    ;;\n\t  esac\n\t  ;;\n\tesac\n      fi\n    done\n    IFS=$lt_save_ifs\n  done\n  : ${lt_cv_path_NM=no}\nfi])\nif test no != \"$lt_cv_path_NM\"; then\n  NM=$lt_cv_path_NM\nelse\n  # Didn't find any BSD compatible name lister, look for dumpbin.\n  if test -n \"$DUMPBIN\"; then :\n    # Let the user override the test.\n  else\n    AC_CHECK_TOOLS(DUMPBIN, [dumpbin \"link -dump\"], :)\n    case `$DUMPBIN -symbols -headers /dev/null 2>&1 | sed '1q'` in\n    *COFF*)\n      DUMPBIN=\"$DUMPBIN -symbols -headers\"\n      ;;\n    *)\n      DUMPBIN=:\n      ;;\n    esac\n  fi\n  AC_SUBST([DUMPBIN])\n  if test : != \"$DUMPBIN\"; then\n    NM=$DUMPBIN\n  fi\nfi\ntest -z \"$NM\" && NM=nm\nAC_SUBST([NM])\n_LT_DECL([], [NM], [1], [A BSD- or MS-compatible name lister])dnl\n\nAC_CACHE_CHECK([the name lister ($NM) interface], [lt_cv_nm_interface],\n  [lt_cv_nm_interface=\"BSD nm\"\n  echo \"int some_variable = 0;\" > conftest.$ac_ext\n  (eval echo \"\\\"\\$as_me:$LINENO: $ac_compile\\\"\" >&AS_MESSAGE_LOG_FD)\n  (eval \"$ac_compile\" 2>conftest.err)\n  cat conftest.err >&AS_MESSAGE_LOG_FD\n  (eval echo \"\\\"\\$as_me:$LINENO: $NM \\\\\\\"conftest.$ac_objext\\\\\\\"\\\"\" >&AS_MESSAGE_LOG_FD)\n  (eval \"$NM \\\"conftest.$ac_objext\\\"\" 2>conftest.err > conftest.out)\n  cat conftest.err >&AS_MESSAGE_LOG_FD\n  (eval echo \"\\\"\\$as_me:$LINENO: output\\\"\" >&AS_MESSAGE_LOG_FD)\n  cat conftest.out >&AS_MESSAGE_LOG_FD\n  if $GREP 'External.*some_variable' conftest.out > /dev/null; then\n    lt_cv_nm_interface=\"MS dumpbin\"\n  fi\n  rm -f conftest*])\n])# LT_PATH_NM\n\n# Old names:\nAU_ALIAS([AM_PROG_NM], [LT_PATH_NM])\nAU_ALIAS([AC_PROG_NM], [LT_PATH_NM])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AM_PROG_NM], [])\ndnl AC_DEFUN([AC_PROG_NM], [])\n\n# _LT_CHECK_SHAREDLIB_FROM_LINKLIB\n# --------------------------------\n# how to determine the name of the shared library\n# associated with a specific link library.\n#  -- PORTME fill in with the dynamic library characteristics\nm4_defun([_LT_CHECK_SHAREDLIB_FROM_LINKLIB],\n[m4_require([_LT_DECL_EGREP])\nm4_require([_LT_DECL_OBJDUMP])\nm4_require([_LT_DECL_DLLTOOL])\nAC_CACHE_CHECK([how to associate runtime and link libraries],\nlt_cv_sharedlib_from_linklib_cmd,\n[lt_cv_sharedlib_from_linklib_cmd='unknown'\n\ncase $host_os in\ncygwin* | mingw* | pw32* | cegcc*)\n  # two different shell functions defined in ltmain.sh;\n  # decide which one to use based on capabilities of $DLLTOOL\n  case `$DLLTOOL --help 2>&1` in\n  *--identify-strict*)\n    lt_cv_sharedlib_from_linklib_cmd=func_cygming_dll_for_implib\n    ;;\n  *)\n    lt_cv_sharedlib_from_linklib_cmd=func_cygming_dll_for_implib_fallback\n    ;;\n  esac\n  ;;\n*)\n  # fallback: assume linklib IS sharedlib\n  lt_cv_sharedlib_from_linklib_cmd=$ECHO\n  ;;\nesac\n])\nsharedlib_from_linklib_cmd=$lt_cv_sharedlib_from_linklib_cmd\ntest -z \"$sharedlib_from_linklib_cmd\" && sharedlib_from_linklib_cmd=$ECHO\n\n_LT_DECL([], [sharedlib_from_linklib_cmd], [1],\n    [Command to associate shared and link libraries])\n])# _LT_CHECK_SHAREDLIB_FROM_LINKLIB\n\n\n# _LT_PATH_MANIFEST_TOOL\n# ----------------------\n# locate the manifest tool\nm4_defun([_LT_PATH_MANIFEST_TOOL],\n[AC_CHECK_TOOL(MANIFEST_TOOL, mt, :)\ntest -z \"$MANIFEST_TOOL\" && MANIFEST_TOOL=mt\nAC_CACHE_CHECK([if $MANIFEST_TOOL is a manifest tool], [lt_cv_path_mainfest_tool],\n  [lt_cv_path_mainfest_tool=no\n  echo \"$as_me:$LINENO: $MANIFEST_TOOL '-?'\" >&AS_MESSAGE_LOG_FD\n  $MANIFEST_TOOL '-?' 2>conftest.err > conftest.out\n  cat conftest.err >&AS_MESSAGE_LOG_FD\n  if $GREP 'Manifest Tool' conftest.out > /dev/null; then\n    lt_cv_path_mainfest_tool=yes\n  fi\n  rm -f conftest*])\nif test yes != \"$lt_cv_path_mainfest_tool\"; then\n  MANIFEST_TOOL=:\nfi\n_LT_DECL([], [MANIFEST_TOOL], [1], [Manifest tool])dnl\n])# _LT_PATH_MANIFEST_TOOL\n\n\n# _LT_DLL_DEF_P([FILE])\n# ---------------------\n# True iff FILE is a Windows DLL '.def' file.\n# Keep in sync with func_dll_def_p in the libtool script\nAC_DEFUN([_LT_DLL_DEF_P],\n[dnl\n  test DEF = \"`$SED -n dnl\n    -e '\\''s/^[[\t ]]*//'\\'' dnl Strip leading whitespace\n    -e '\\''/^\\(;.*\\)*$/d'\\'' dnl      Delete empty lines and comments\n    -e '\\''s/^\\(EXPORTS\\|LIBRARY\\)\\([[\t ]].*\\)*$/DEF/p'\\'' dnl\n    -e q dnl                          Only consider the first \"real\" line\n    $1`\" dnl\n])# _LT_DLL_DEF_P\n\n\n# LT_LIB_M\n# --------\n# check for math library\nAC_DEFUN([LT_LIB_M],\n[AC_REQUIRE([AC_CANONICAL_HOST])dnl\nLIBM=\ncase $host in\n*-*-beos* | *-*-cegcc* | *-*-cygwin* | *-*-haiku* | *-*-pw32* | *-*-darwin*)\n  # These system don't have libm, or don't need it\n  ;;\n*-ncr-sysv4.3*)\n  AC_CHECK_LIB(mw, _mwvalidcheckl, LIBM=-lmw)\n  AC_CHECK_LIB(m, cos, LIBM=\"$LIBM -lm\")\n  ;;\n*)\n  AC_CHECK_LIB(m, cos, LIBM=-lm)\n  ;;\nesac\nAC_SUBST([LIBM])\n])# LT_LIB_M\n\n# Old name:\nAU_ALIAS([AC_CHECK_LIBM], [LT_LIB_M])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_CHECK_LIBM], [])\n\n\n# _LT_COMPILER_NO_RTTI([TAGNAME])\n# -------------------------------\nm4_defun([_LT_COMPILER_NO_RTTI],\n[m4_require([_LT_TAG_COMPILER])dnl\n\n_LT_TAGVAR(lt_prog_compiler_no_builtin_flag, $1)=\n\nif test yes = \"$GCC\"; then\n  case $cc_basename in\n  nvcc*)\n    _LT_TAGVAR(lt_prog_compiler_no_builtin_flag, $1)=' -Xcompiler -fno-builtin' ;;\n  *)\n    _LT_TAGVAR(lt_prog_compiler_no_builtin_flag, $1)=' -fno-builtin' ;;\n  esac\n\n  _LT_COMPILER_OPTION([if $compiler supports -fno-rtti -fno-exceptions],\n    lt_cv_prog_compiler_rtti_exceptions,\n    [-fno-rtti -fno-exceptions], [],\n    [_LT_TAGVAR(lt_prog_compiler_no_builtin_flag, $1)=\"$_LT_TAGVAR(lt_prog_compiler_no_builtin_flag, $1) -fno-rtti -fno-exceptions\"])\nfi\n_LT_TAGDECL([no_builtin_flag], [lt_prog_compiler_no_builtin_flag], [1],\n\t[Compiler flag to turn off builtin functions])\n])# _LT_COMPILER_NO_RTTI\n\n\n# _LT_CMD_GLOBAL_SYMBOLS\n# ----------------------\nm4_defun([_LT_CMD_GLOBAL_SYMBOLS],\n[AC_REQUIRE([AC_CANONICAL_HOST])dnl\nAC_REQUIRE([AC_PROG_CC])dnl\nAC_REQUIRE([AC_PROG_AWK])dnl\nAC_REQUIRE([LT_PATH_NM])dnl\nAC_REQUIRE([LT_PATH_LD])dnl\nm4_require([_LT_DECL_SED])dnl\nm4_require([_LT_DECL_EGREP])dnl\nm4_require([_LT_TAG_COMPILER])dnl\n\n# Check for command to grab the raw symbol name followed by C symbol from nm.\nAC_MSG_CHECKING([command to parse $NM output from $compiler object])\nAC_CACHE_VAL([lt_cv_sys_global_symbol_pipe],\n[\n# These are sane defaults that work on at least a few old systems.\n# [They come from Ultrix.  What could be older than Ultrix?!! ;)]\n\n# Character class describing NM global symbol codes.\nsymcode='[[BCDEGRST]]'\n\n# Regexp to match symbols that can be accessed directly from C.\nsympat='\\([[_A-Za-z]][[_A-Za-z0-9]]*\\)'\n\n# Define system-specific variables.\ncase $host_os in\naix*)\n  symcode='[[BCDT]]'\n  ;;\ncygwin* | mingw* | pw32* | cegcc*)\n  symcode='[[ABCDGISTW]]'\n  ;;\nhpux*)\n  if test ia64 = \"$host_cpu\"; then\n    symcode='[[ABCDEGRST]]'\n  fi\n  ;;\nirix* | nonstopux*)\n  symcode='[[BCDEGRST]]'\n  ;;\nosf*)\n  symcode='[[BCDEGQRST]]'\n  ;;\nsolaris*)\n  symcode='[[BDRT]]'\n  ;;\nsco3.2v5*)\n  symcode='[[DT]]'\n  ;;\nsysv4.2uw2*)\n  symcode='[[DT]]'\n  ;;\nsysv5* | sco5v6* | unixware* | OpenUNIX*)\n  symcode='[[ABDT]]'\n  ;;\nsysv4)\n  symcode='[[DFNSTU]]'\n  ;;\nesac\n\n# If we're using GNU nm, then use its standard symbol codes.\ncase `$NM -V 2>&1` in\n*GNU* | *'with BFD'*)\n  symcode='[[ABCDGIRSTW]]' ;;\nesac\n\nif test \"$lt_cv_nm_interface\" = \"MS dumpbin\"; then\n  # Gets list of data symbols to import.\n  lt_cv_sys_global_symbol_to_import=\"sed -n -e 's/^I .* \\(.*\\)$/\\1/p'\"\n  # Adjust the below global symbol transforms to fixup imported variables.\n  lt_cdecl_hook=\" -e 's/^I .* \\(.*\\)$/extern __declspec(dllimport) char \\1;/p'\"\n  lt_c_name_hook=\" -e 's/^I .* \\(.*\\)$/  {\\\"\\1\\\", (void *) 0},/p'\"\n  lt_c_name_lib_hook=\"\\\n  -e 's/^I .* \\(lib.*\\)$/  {\\\"\\1\\\", (void *) 0},/p'\\\n  -e 's/^I .* \\(.*\\)$/  {\\\"lib\\1\\\", (void *) 0},/p'\"\nelse\n  # Disable hooks by default.\n  lt_cv_sys_global_symbol_to_import=\n  lt_cdecl_hook=\n  lt_c_name_hook=\n  lt_c_name_lib_hook=\nfi\n\n# Transform an extracted symbol line into a proper C declaration.\n# Some systems (esp. on ia64) link data and code symbols differently,\n# so use this general approach.\nlt_cv_sys_global_symbol_to_cdecl=\"sed -n\"\\\n$lt_cdecl_hook\\\n\" -e 's/^T .* \\(.*\\)$/extern int \\1();/p'\"\\\n\" -e 's/^$symcode$symcode* .* \\(.*\\)$/extern char \\1;/p'\"\n\n# Transform an extracted symbol line into symbol name and symbol address\nlt_cv_sys_global_symbol_to_c_name_address=\"sed -n\"\\\n$lt_c_name_hook\\\n\" -e 's/^: \\(.*\\) .*$/  {\\\"\\1\\\", (void *) 0},/p'\"\\\n\" -e 's/^$symcode$symcode* .* \\(.*\\)$/  {\\\"\\1\\\", (void *) \\&\\1},/p'\"\n\n# Transform an extracted symbol line into symbol name with lib prefix and\n# symbol address.\nlt_cv_sys_global_symbol_to_c_name_address_lib_prefix=\"sed -n\"\\\n$lt_c_name_lib_hook\\\n\" -e 's/^: \\(.*\\) .*$/  {\\\"\\1\\\", (void *) 0},/p'\"\\\n\" -e 's/^$symcode$symcode* .* \\(lib.*\\)$/  {\\\"\\1\\\", (void *) \\&\\1},/p'\"\\\n\" -e 's/^$symcode$symcode* .* \\(.*\\)$/  {\\\"lib\\1\\\", (void *) \\&\\1},/p'\"\n\n# Handle CRLF in mingw tool chain\nopt_cr=\ncase $build_os in\nmingw*)\n  opt_cr=`$ECHO 'x\\{0,1\\}' | tr x '\\015'` # option cr in regexp\n  ;;\nesac\n\n# Try without a prefix underscore, then with it.\nfor ac_symprfx in \"\" \"_\"; do\n\n  # Transform symcode, sympat, and symprfx into a raw symbol and a C symbol.\n  symxfrm=\"\\\\1 $ac_symprfx\\\\2 \\\\2\"\n\n  # Write the raw and C identifiers.\n  if test \"$lt_cv_nm_interface\" = \"MS dumpbin\"; then\n    # Fake it for dumpbin and say T for any non-static function,\n    # D for any global variable and I for any imported variable.\n    # Also find C++ and __fastcall symbols from MSVC++,\n    # which start with @ or ?.\n    lt_cv_sys_global_symbol_pipe=\"$AWK ['\"\\\n\"     {last_section=section; section=\\$ 3};\"\\\n\"     /^COFF SYMBOL TABLE/{for(i in hide) delete hide[i]};\"\\\n\"     /Section length .*#relocs.*(pick any)/{hide[last_section]=1};\"\\\n\"     /^ *Symbol name *: /{split(\\$ 0,sn,\\\":\\\"); si=substr(sn[2],2)};\"\\\n\"     /^ *Type *: code/{print \\\"T\\\",si,substr(si,length(prfx))};\"\\\n\"     /^ *Type *: data/{print \\\"I\\\",si,substr(si,length(prfx))};\"\\\n\"     \\$ 0!~/External *\\|/{next};\"\\\n\"     / 0+ UNDEF /{next}; / UNDEF \\([^|]\\)*()/{next};\"\\\n\"     {if(hide[section]) next};\"\\\n\"     {f=\\\"D\\\"}; \\$ 0~/\\(\\).*\\|/{f=\\\"T\\\"};\"\\\n\"     {split(\\$ 0,a,/\\||\\r/); split(a[2],s)};\"\\\n\"     s[1]~/^[@?]/{print f,s[1],s[1]; next};\"\\\n\"     s[1]~prfx {split(s[1],t,\\\"@\\\"); print f,t[1],substr(t[1],length(prfx))}\"\\\n\"     ' prfx=^$ac_symprfx]\"\n  else\n    lt_cv_sys_global_symbol_pipe=\"sed -n -e 's/^.*[[\t ]]\\($symcode$symcode*\\)[[\t ]][[\t ]]*$ac_symprfx$sympat$opt_cr$/$symxfrm/p'\"\n  fi\n  lt_cv_sys_global_symbol_pipe=\"$lt_cv_sys_global_symbol_pipe | sed '/ __gnu_lto/d'\"\n\n  # Check to see that the pipe works correctly.\n  pipe_works=no\n\n  rm -f conftest*\n  cat > conftest.$ac_ext <<_LT_EOF\n#ifdef __cplusplus\nextern \"C\" {\n#endif\nchar nm_test_var;\nvoid nm_test_func(void);\nvoid nm_test_func(void){}\n#ifdef __cplusplus\n}\n#endif\nint main(){nm_test_var='a';nm_test_func();return(0);}\n_LT_EOF\n\n  if AC_TRY_EVAL(ac_compile); then\n    # Now try to grab the symbols.\n    nlist=conftest.nm\n    if AC_TRY_EVAL(NM conftest.$ac_objext \\| \"$lt_cv_sys_global_symbol_pipe\" \\> $nlist) && test -s \"$nlist\"; then\n      # Try sorting and uniquifying the output.\n      if sort \"$nlist\" | uniq > \"$nlist\"T; then\n\tmv -f \"$nlist\"T \"$nlist\"\n      else\n\trm -f \"$nlist\"T\n      fi\n\n      # Make sure that we snagged all the symbols we need.\n      if $GREP ' nm_test_var$' \"$nlist\" >/dev/null; then\n\tif $GREP ' nm_test_func$' \"$nlist\" >/dev/null; then\n\t  cat <<_LT_EOF > conftest.$ac_ext\n/* Keep this code in sync between libtool.m4, ltmain, lt_system.h, and tests.  */\n#if defined _WIN32 || defined __CYGWIN__ || defined _WIN32_WCE\n/* DATA imports from DLLs on WIN32 can't be const, because runtime\n   relocations are performed -- see ld's documentation on pseudo-relocs.  */\n# define LT@&t@_DLSYM_CONST\n#elif defined __osf__\n/* This system does not cope well with relocations in const data.  */\n# define LT@&t@_DLSYM_CONST\n#else\n# define LT@&t@_DLSYM_CONST const\n#endif\n\n#ifdef __cplusplus\nextern \"C\" {\n#endif\n\n_LT_EOF\n\t  # Now generate the symbol file.\n\t  eval \"$lt_cv_sys_global_symbol_to_cdecl\"' < \"$nlist\" | $GREP -v main >> conftest.$ac_ext'\n\n\t  cat <<_LT_EOF >> conftest.$ac_ext\n\n/* The mapping between symbol names and symbols.  */\nLT@&t@_DLSYM_CONST struct {\n  const char *name;\n  void       *address;\n}\nlt__PROGRAM__LTX_preloaded_symbols[[]] =\n{\n  { \"@PROGRAM@\", (void *) 0 },\n_LT_EOF\n\t  $SED \"s/^$symcode$symcode* .* \\(.*\\)$/  {\\\"\\1\\\", (void *) \\&\\1},/\" < \"$nlist\" | $GREP -v main >> conftest.$ac_ext\n\t  cat <<\\_LT_EOF >> conftest.$ac_ext\n  {0, (void *) 0}\n};\n\n/* This works around a problem in FreeBSD linker */\n#ifdef FREEBSD_WORKAROUND\nstatic const void *lt_preloaded_setup() {\n  return lt__PROGRAM__LTX_preloaded_symbols;\n}\n#endif\n\n#ifdef __cplusplus\n}\n#endif\n_LT_EOF\n\t  # Now try linking the two files.\n\t  mv conftest.$ac_objext conftstm.$ac_objext\n\t  lt_globsym_save_LIBS=$LIBS\n\t  lt_globsym_save_CFLAGS=$CFLAGS\n\t  LIBS=conftstm.$ac_objext\n\t  CFLAGS=\"$CFLAGS$_LT_TAGVAR(lt_prog_compiler_no_builtin_flag, $1)\"\n\t  if AC_TRY_EVAL(ac_link) && test -s conftest$ac_exeext; then\n\t    pipe_works=yes\n\t  fi\n\t  LIBS=$lt_globsym_save_LIBS\n\t  CFLAGS=$lt_globsym_save_CFLAGS\n\telse\n\t  echo \"cannot find nm_test_func in $nlist\" >&AS_MESSAGE_LOG_FD\n\tfi\n      else\n\techo \"cannot find nm_test_var in $nlist\" >&AS_MESSAGE_LOG_FD\n      fi\n    else\n      echo \"cannot run $lt_cv_sys_global_symbol_pipe\" >&AS_MESSAGE_LOG_FD\n    fi\n  else\n    echo \"$progname: failed program was:\" >&AS_MESSAGE_LOG_FD\n    cat conftest.$ac_ext >&5\n  fi\n  rm -rf conftest* conftst*\n\n  # Do not use the global_symbol_pipe unless it works.\n  if test yes = \"$pipe_works\"; then\n    break\n  else\n    lt_cv_sys_global_symbol_pipe=\n  fi\ndone\n])\nif test -z \"$lt_cv_sys_global_symbol_pipe\"; then\n  lt_cv_sys_global_symbol_to_cdecl=\nfi\nif test -z \"$lt_cv_sys_global_symbol_pipe$lt_cv_sys_global_symbol_to_cdecl\"; then\n  AC_MSG_RESULT(failed)\nelse\n  AC_MSG_RESULT(ok)\nfi\n\n# Response file support.\nif test \"$lt_cv_nm_interface\" = \"MS dumpbin\"; then\n  nm_file_list_spec='@'\nelif $NM --help 2>/dev/null | grep '[[@]]FILE' >/dev/null; then\n  nm_file_list_spec='@'\nfi\n\n_LT_DECL([global_symbol_pipe], [lt_cv_sys_global_symbol_pipe], [1],\n    [Take the output of nm and produce a listing of raw symbols and C names])\n_LT_DECL([global_symbol_to_cdecl], [lt_cv_sys_global_symbol_to_cdecl], [1],\n    [Transform the output of nm in a proper C declaration])\n_LT_DECL([global_symbol_to_import], [lt_cv_sys_global_symbol_to_import], [1],\n    [Transform the output of nm into a list of symbols to manually relocate])\n_LT_DECL([global_symbol_to_c_name_address],\n    [lt_cv_sys_global_symbol_to_c_name_address], [1],\n    [Transform the output of nm in a C name address pair])\n_LT_DECL([global_symbol_to_c_name_address_lib_prefix],\n    [lt_cv_sys_global_symbol_to_c_name_address_lib_prefix], [1],\n    [Transform the output of nm in a C name address pair when lib prefix is needed])\n_LT_DECL([nm_interface], [lt_cv_nm_interface], [1],\n    [The name lister interface])\n_LT_DECL([], [nm_file_list_spec], [1],\n    [Specify filename containing input files for $NM])\n]) # _LT_CMD_GLOBAL_SYMBOLS\n\n\n# _LT_COMPILER_PIC([TAGNAME])\n# ---------------------------\nm4_defun([_LT_COMPILER_PIC],\n[m4_require([_LT_TAG_COMPILER])dnl\n_LT_TAGVAR(lt_prog_compiler_wl, $1)=\n_LT_TAGVAR(lt_prog_compiler_pic, $1)=\n_LT_TAGVAR(lt_prog_compiler_static, $1)=\n\nm4_if([$1], [CXX], [\n  # C++ specific cases for pic, static, wl, etc.\n  if test yes = \"$GXX\"; then\n    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n    _LT_TAGVAR(lt_prog_compiler_static, $1)='-static'\n\n    case $host_os in\n    aix*)\n      # All AIX code is PIC.\n      if test ia64 = \"$host_cpu\"; then\n\t# AIX 5 now supports IA64 processor\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n      fi\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n      ;;\n\n    amigaos*)\n      case $host_cpu in\n      powerpc)\n            # see comment about AmigaOS4 .so support\n            _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n        ;;\n      m68k)\n            # FIXME: we need at least 68020 code to build shared libraries, but\n            # adding the '-m68020' flag to GCC prevents building anything better,\n            # like '-m68040'.\n            _LT_TAGVAR(lt_prog_compiler_pic, $1)='-m68020 -resident32 -malways-restore-a4'\n        ;;\n      esac\n      ;;\n\n    beos* | irix5* | irix6* | nonstopux* | osf3* | osf4* | osf5*)\n      # PIC is the default for these OSes.\n      ;;\n    mingw* | cygwin* | os2* | pw32* | cegcc*)\n      # This hack is so that the source file can tell whether it is being\n      # built for inclusion in a dll (and should export symbols for example).\n      # Although the cygwin gcc ignores -fPIC, still need this for old-style\n      # (--disable-auto-import) libraries\n      m4_if([$1], [GCJ], [],\n\t[_LT_TAGVAR(lt_prog_compiler_pic, $1)='-DDLL_EXPORT'])\n      case $host_os in\n      os2*)\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='$wl-static'\n\t;;\n      esac\n      ;;\n    darwin* | rhapsody*)\n      # PIC is the default on this platform\n      # Common symbols not allowed in MH_DYLIB files\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fno-common'\n      ;;\n    *djgpp*)\n      # DJGPP does not support shared libraries at all\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)=\n      ;;\n    haiku*)\n      # PIC is the default for Haiku.\n      # The \"-static\" flag exists, but is broken.\n      _LT_TAGVAR(lt_prog_compiler_static, $1)=\n      ;;\n    interix[[3-9]]*)\n      # Interix 3.x gcc -fpic/-fPIC options generate broken code.\n      # Instead, we relocate shared libraries at runtime.\n      ;;\n    sysv4*MP*)\n      if test -d /usr/nec; then\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)=-Kconform_pic\n      fi\n      ;;\n    hpux*)\n      # PIC is the default for 64-bit PA HP-UX, but not for 32-bit\n      # PA HP-UX.  On IA64 HP-UX, PIC is the default but the pic flag\n      # sets the default TLS model and affects inlining.\n      case $host_cpu in\n      hppa*64*)\n\t;;\n      *)\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n\t;;\n      esac\n      ;;\n    *qnx* | *nto*)\n      # QNX uses GNU C++, but need to define -shared option too, otherwise\n      # it will coredump.\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC -shared'\n      ;;\n    *)\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n      ;;\n    esac\n  else\n    case $host_os in\n      aix[[4-9]]*)\n\t# All AIX code is PIC.\n\tif test ia64 = \"$host_cpu\"; then\n\t  # AIX 5 now supports IA64 processor\n\t  _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n\telse\n\t  _LT_TAGVAR(lt_prog_compiler_static, $1)='-bnso -bI:/lib/syscalls.exp'\n\tfi\n\t;;\n      chorus*)\n\tcase $cc_basename in\n\tcxch68*)\n\t  # Green Hills C++ Compiler\n\t  # _LT_TAGVAR(lt_prog_compiler_static, $1)=\"--no_auto_instantiation -u __main -u __premain -u _abort -r $COOL_DIR/lib/libOrb.a $MVME_DIR/lib/CC/libC.a $MVME_DIR/lib/classix/libcx.s.a\"\n\t  ;;\n\tesac\n\t;;\n      mingw* | cygwin* | os2* | pw32* | cegcc*)\n\t# This hack is so that the source file can tell whether it is being\n\t# built for inclusion in a dll (and should export symbols for example).\n\tm4_if([$1], [GCJ], [],\n\t  [_LT_TAGVAR(lt_prog_compiler_pic, $1)='-DDLL_EXPORT'])\n\t;;\n      dgux*)\n\tcase $cc_basename in\n\t  ec++*)\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n\t    ;;\n\t  ghcx*)\n\t    # Green Hills C++ Compiler\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-pic'\n\t    ;;\n\t  *)\n\t    ;;\n\tesac\n\t;;\n      freebsd* | dragonfly*)\n\t# FreeBSD uses GNU C++\n\t;;\n      hpux9* | hpux10* | hpux11*)\n\tcase $cc_basename in\n\t  CC*)\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='$wl-a ${wl}archive'\n\t    if test ia64 != \"$host_cpu\"; then\n\t      _LT_TAGVAR(lt_prog_compiler_pic, $1)='+Z'\n\t    fi\n\t    ;;\n\t  aCC*)\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='$wl-a ${wl}archive'\n\t    case $host_cpu in\n\t    hppa*64*|ia64*)\n\t      # +Z the default\n\t      ;;\n\t    *)\n\t      _LT_TAGVAR(lt_prog_compiler_pic, $1)='+Z'\n\t      ;;\n\t    esac\n\t    ;;\n\t  *)\n\t    ;;\n\tesac\n\t;;\n      interix*)\n\t# This is c89, which is MS Visual C++ (no shared libs)\n\t# Anyone wants to do a port?\n\t;;\n      irix5* | irix6* | nonstopux*)\n\tcase $cc_basename in\n\t  CC*)\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='-non_shared'\n\t    # CC pic flag -KPIC is the default.\n\t    ;;\n\t  *)\n\t    ;;\n\tesac\n\t;;\n      linux* | k*bsd*-gnu | kopensolaris*-gnu | gnu*)\n\tcase $cc_basename in\n\t  KCC*)\n\t    # KAI C++ Compiler\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='--backend -Wl,'\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n\t    ;;\n\t  ecpc* )\n\t    # old Intel C++ for x86_64, which still supported -KPIC.\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='-static'\n\t    ;;\n\t  icpc* )\n\t    # Intel C++, used to be incompatible with GCC.\n\t    # ICC 10 doesn't accept -KPIC any more.\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='-static'\n\t    ;;\n\t  pgCC* | pgcpp*)\n\t    # Portland Group C++ compiler\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fpic'\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n\t    ;;\n\t  cxx*)\n\t    # Compaq C++\n\t    # Make sure the PIC flag is empty.  It appears that all Alpha\n\t    # Linux and Compaq Tru64 Unix objects are PIC.\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)=\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='-non_shared'\n\t    ;;\n\t  xlc* | xlC* | bgxl[[cC]]* | mpixl[[cC]]*)\n\t    # IBM XL 8.0, 9.0 on PPC and BlueGene\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-qpic'\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='-qstaticlink'\n\t    ;;\n\t  *)\n\t    case `$CC -V 2>&1 | sed 5q` in\n\t    *Sun\\ C*)\n\t      # Sun C++ 5.9\n\t      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n\t      _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n\t      _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Qoption ld '\n\t      ;;\n\t    esac\n\t    ;;\n\tesac\n\t;;\n      lynxos*)\n\t;;\n      m88k*)\n\t;;\n      mvs*)\n\tcase $cc_basename in\n\t  cxx*)\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-W c,exportall'\n\t    ;;\n\t  *)\n\t    ;;\n\tesac\n\t;;\n      netbsd*)\n\t;;\n      *qnx* | *nto*)\n        # QNX uses GNU C++, but need to define -shared option too, otherwise\n        # it will coredump.\n        _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC -shared'\n        ;;\n      osf3* | osf4* | osf5*)\n\tcase $cc_basename in\n\t  KCC*)\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='--backend -Wl,'\n\t    ;;\n\t  RCC*)\n\t    # Rational C++ 2.4.1\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-pic'\n\t    ;;\n\t  cxx*)\n\t    # Digital/Compaq C++\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t    # Make sure the PIC flag is empty.  It appears that all Alpha\n\t    # Linux and Compaq Tru64 Unix objects are PIC.\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)=\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='-non_shared'\n\t    ;;\n\t  *)\n\t    ;;\n\tesac\n\t;;\n      psos*)\n\t;;\n      solaris*)\n\tcase $cc_basename in\n\t  CC* | sunCC*)\n\t    # Sun C++ 4.2, 5.x and Centerline C++\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Qoption ld '\n\t    ;;\n\t  gcx*)\n\t    # Green Hills C++ Compiler\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-PIC'\n\t    ;;\n\t  *)\n\t    ;;\n\tesac\n\t;;\n      sunos4*)\n\tcase $cc_basename in\n\t  CC*)\n\t    # Sun C++ 4.x\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-pic'\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n\t    ;;\n\t  lcc*)\n\t    # Lucid\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-pic'\n\t    ;;\n\t  *)\n\t    ;;\n\tesac\n\t;;\n      sysv5* | unixware* | sco3.2v5* | sco5v6* | OpenUNIX*)\n\tcase $cc_basename in\n\t  CC*)\n\t    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n\t    _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n\t    ;;\n\tesac\n\t;;\n      tandem*)\n\tcase $cc_basename in\n\t  NCC*)\n\t    # NonStop-UX NCC 3.20\n\t    _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n\t    ;;\n\t  *)\n\t    ;;\n\tesac\n\t;;\n      vxworks*)\n\t;;\n      *)\n\t_LT_TAGVAR(lt_prog_compiler_can_build_shared, $1)=no\n\t;;\n    esac\n  fi\n],\n[\n  if test yes = \"$GCC\"; then\n    _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n    _LT_TAGVAR(lt_prog_compiler_static, $1)='-static'\n\n    case $host_os in\n      aix*)\n      # All AIX code is PIC.\n      if test ia64 = \"$host_cpu\"; then\n\t# AIX 5 now supports IA64 processor\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n      fi\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n      ;;\n\n    amigaos*)\n      case $host_cpu in\n      powerpc)\n            # see comment about AmigaOS4 .so support\n            _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n        ;;\n      m68k)\n            # FIXME: we need at least 68020 code to build shared libraries, but\n            # adding the '-m68020' flag to GCC prevents building anything better,\n            # like '-m68040'.\n            _LT_TAGVAR(lt_prog_compiler_pic, $1)='-m68020 -resident32 -malways-restore-a4'\n        ;;\n      esac\n      ;;\n\n    beos* | irix5* | irix6* | nonstopux* | osf3* | osf4* | osf5*)\n      # PIC is the default for these OSes.\n      ;;\n\n    mingw* | cygwin* | pw32* | os2* | cegcc*)\n      # This hack is so that the source file can tell whether it is being\n      # built for inclusion in a dll (and should export symbols for example).\n      # Although the cygwin gcc ignores -fPIC, still need this for old-style\n      # (--disable-auto-import) libraries\n      m4_if([$1], [GCJ], [],\n\t[_LT_TAGVAR(lt_prog_compiler_pic, $1)='-DDLL_EXPORT'])\n      case $host_os in\n      os2*)\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='$wl-static'\n\t;;\n      esac\n      ;;\n\n    darwin* | rhapsody*)\n      # PIC is the default on this platform\n      # Common symbols not allowed in MH_DYLIB files\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fno-common'\n      ;;\n\n    haiku*)\n      # PIC is the default for Haiku.\n      # The \"-static\" flag exists, but is broken.\n      _LT_TAGVAR(lt_prog_compiler_static, $1)=\n      ;;\n\n    hpux*)\n      # PIC is the default for 64-bit PA HP-UX, but not for 32-bit\n      # PA HP-UX.  On IA64 HP-UX, PIC is the default but the pic flag\n      # sets the default TLS model and affects inlining.\n      case $host_cpu in\n      hppa*64*)\n\t# +Z the default\n\t;;\n      *)\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n\t;;\n      esac\n      ;;\n\n    interix[[3-9]]*)\n      # Interix 3.x gcc -fpic/-fPIC options generate broken code.\n      # Instead, we relocate shared libraries at runtime.\n      ;;\n\n    msdosdjgpp*)\n      # Just because we use GCC doesn't mean we suddenly get shared libraries\n      # on systems that don't support them.\n      _LT_TAGVAR(lt_prog_compiler_can_build_shared, $1)=no\n      enable_shared=no\n      ;;\n\n    *nto* | *qnx*)\n      # QNX uses GNU C++, but need to define -shared option too, otherwise\n      # it will coredump.\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC -shared'\n      ;;\n\n    sysv4*MP*)\n      if test -d /usr/nec; then\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)=-Kconform_pic\n      fi\n      ;;\n\n    *)\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n      ;;\n    esac\n\n    case $cc_basename in\n    nvcc*) # Cuda Compiler Driver 2.2\n      _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Xlinker '\n      if test -n \"$_LT_TAGVAR(lt_prog_compiler_pic, $1)\"; then\n        _LT_TAGVAR(lt_prog_compiler_pic, $1)=\"-Xcompiler $_LT_TAGVAR(lt_prog_compiler_pic, $1)\"\n      fi\n      ;;\n    esac\n  else\n    # PORTME Check for flag to pass linker flags through the system compiler.\n    case $host_os in\n    aix*)\n      _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n      if test ia64 = \"$host_cpu\"; then\n\t# AIX 5 now supports IA64 processor\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n      else\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='-bnso -bI:/lib/syscalls.exp'\n      fi\n      ;;\n\n    darwin* | rhapsody*)\n      # PIC is the default on this platform\n      # Common symbols not allowed in MH_DYLIB files\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fno-common'\n      case $cc_basename in\n      # icc used to be incompatible with GCC.\n      # ICC 10 doesn't accept -KPIC any more.\n      icc* | ifort*)\n\t_LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='-static'\n        ;;      \n      nagfor*)\n        # NAG Fortran compiler\n        _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,-Wl,,'\n        _LT_TAGVAR(lt_prog_compiler_pic, $1)='-PIC'\n        _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n        ;;\n      esac\n      ;;\n\n    mingw* | cygwin* | pw32* | os2* | cegcc*)\n      # This hack is so that the source file can tell whether it is being\n      # built for inclusion in a dll (and should export symbols for example).\n      m4_if([$1], [GCJ], [],\n\t[_LT_TAGVAR(lt_prog_compiler_pic, $1)='-DDLL_EXPORT'])\n      case $host_os in\n      os2*)\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='$wl-static'\n\t;;\n      esac\n      ;;\n\n    hpux9* | hpux10* | hpux11*)\n      _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n      # PIC is the default for IA64 HP-UX and 64-bit HP-UX, but\n      # not for PA HP-UX.\n      case $host_cpu in\n      hppa*64*|ia64*)\n\t# +Z the default\n\t;;\n      *)\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)='+Z'\n\t;;\n      esac\n      # Is there a better lt_prog_compiler_static that works with the bundled CC?\n      _LT_TAGVAR(lt_prog_compiler_static, $1)='$wl-a ${wl}archive'\n      ;;\n\n    irix5* | irix6* | nonstopux*)\n      _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n      # PIC (with -KPIC) is the default.\n      _LT_TAGVAR(lt_prog_compiler_static, $1)='-non_shared'\n      ;;\n\n    linux* | k*bsd*-gnu | kopensolaris*-gnu | gnu*)\n      case $cc_basename in\n      # old Intel for x86_64, which still supported -KPIC.\n      ecc*)\n\t_LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='-static'\n        ;;\n      # icc used to be incompatible with GCC.\n      # ICC 10 doesn't accept -KPIC any more.\n      icc* | ifort*)\n\t_LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='-static'\n        ;;\n      # Lahey Fortran 8.1.\n      lf95*)\n\t_LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)='--shared'\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='--static'\n\t;;\n      nagfor*)\n\t# NAG Fortran compiler\n\t_LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,-Wl,,'\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)='-PIC'\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n\t;;\n      tcc*)\n\t# Fabrice Bellard et al's Tiny C Compiler\n\t_LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='-static'\n\t;;\n      armflang* | flang*)\n        # Flang and ARM HPC Compiler\n        _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n        _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC -DPIC'\n        _LT_TAGVAR(lt_prog_compiler_static, $1)='-static'\n        ;;\n      pgcc* | pgf77* | pgf90* | pgf95* | pgfortran*)\n        # Portland Group compilers (*not* the Pentium gcc compiler,\n\t# which looks to be a dead project)\n\t_LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)='-fpic'\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n        ;;\n      ccc*)\n        _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n        # All Alpha code is PIC.\n        _LT_TAGVAR(lt_prog_compiler_static, $1)='-non_shared'\n        ;;\n      xl* | bgxl* | bgf* | mpixl*)\n\t# IBM XL C 8.0/Fortran 10.1, 11.1 on PPC and BlueGene\n\t_LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)='-qpic'\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='-qstaticlink'\n\t;;\n      *)\n\tcase `$CC -V 2>&1 | sed 5q` in\n\t*Sun\\ Ceres\\ Fortran* | *Sun*Fortran*\\ [[1-7]].* | *Sun*Fortran*\\ 8.[[0-3]]*)\n\t  # Sun Fortran 8.3 passes all unrecognized flags to the linker\n\t  _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n\t  _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n\t  _LT_TAGVAR(lt_prog_compiler_wl, $1)=''\n\t  ;;\n\t*Sun\\ F* | *Sun*Fortran*)\n\t  _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n\t  _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n\t  _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Qoption ld '\n\t  ;;\n\t*Sun\\ C*)\n\t  # Sun C 5.9\n\t  _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n\t  _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n\t  _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t  ;;\n        *Intel*\\ [[CF]]*Compiler*)\n\t  _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t  _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC'\n\t  _LT_TAGVAR(lt_prog_compiler_static, $1)='-static'\n\t  ;;\n\t*Portland\\ Group*)\n\t  _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n\t  _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fpic'\n\t  _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n\t  ;;\n\tesac\n\t;;\n      esac\n      ;;\n\n    newsos6)\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n      _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n      ;;\n\n    *nto* | *qnx*)\n      # QNX uses GNU C++, but need to define -shared option too, otherwise\n      # it will coredump.\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-fPIC -shared'\n      ;;\n\n    osf3* | osf4* | osf5*)\n      _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n      # All OSF/1 code is PIC.\n      _LT_TAGVAR(lt_prog_compiler_static, $1)='-non_shared'\n      ;;\n\n    rdos*)\n      _LT_TAGVAR(lt_prog_compiler_static, $1)='-non_shared'\n      ;;\n\n    solaris*)\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n      _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n      case $cc_basename in\n      f77* | f90* | f95* | sunf77* | sunf90* | sunf95*)\n\t_LT_TAGVAR(lt_prog_compiler_wl, $1)='-Qoption ld ';;\n      *)\n\t_LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,';;\n      esac\n      ;;\n\n    sunos4*)\n      _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Qoption ld '\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-PIC'\n      _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n      ;;\n\n    sysv4 | sysv4.2uw2* | sysv4.3*)\n      _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n      _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n      ;;\n\n    sysv4*MP*)\n      if test -d /usr/nec; then\n\t_LT_TAGVAR(lt_prog_compiler_pic, $1)='-Kconform_pic'\n\t_LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n      fi\n      ;;\n\n    sysv5* | unixware* | sco3.2v5* | sco5v6* | OpenUNIX*)\n      _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-KPIC'\n      _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n      ;;\n\n    unicos*)\n      _LT_TAGVAR(lt_prog_compiler_wl, $1)='-Wl,'\n      _LT_TAGVAR(lt_prog_compiler_can_build_shared, $1)=no\n      ;;\n\n    uts4*)\n      _LT_TAGVAR(lt_prog_compiler_pic, $1)='-pic'\n      _LT_TAGVAR(lt_prog_compiler_static, $1)='-Bstatic'\n      ;;\n\n    *)\n      _LT_TAGVAR(lt_prog_compiler_can_build_shared, $1)=no\n      ;;\n    esac\n  fi\n])\ncase $host_os in\n  # For platforms that do not support PIC, -DPIC is meaningless:\n  *djgpp*)\n    _LT_TAGVAR(lt_prog_compiler_pic, $1)=\n    ;;\n  *)\n    _LT_TAGVAR(lt_prog_compiler_pic, $1)=\"$_LT_TAGVAR(lt_prog_compiler_pic, $1)@&t@m4_if([$1],[],[ -DPIC],[m4_if([$1],[CXX],[ -DPIC],[])])\"\n    ;;\nesac\n\nAC_CACHE_CHECK([for $compiler option to produce PIC],\n  [_LT_TAGVAR(lt_cv_prog_compiler_pic, $1)],\n  [_LT_TAGVAR(lt_cv_prog_compiler_pic, $1)=$_LT_TAGVAR(lt_prog_compiler_pic, $1)])\n_LT_TAGVAR(lt_prog_compiler_pic, $1)=$_LT_TAGVAR(lt_cv_prog_compiler_pic, $1)\n\n#\n# Check to make sure the PIC flag actually works.\n#\nif test -n \"$_LT_TAGVAR(lt_prog_compiler_pic, $1)\"; then\n  _LT_COMPILER_OPTION([if $compiler PIC flag $_LT_TAGVAR(lt_prog_compiler_pic, $1) works],\n    [_LT_TAGVAR(lt_cv_prog_compiler_pic_works, $1)],\n    [$_LT_TAGVAR(lt_prog_compiler_pic, $1)@&t@m4_if([$1],[],[ -DPIC],[m4_if([$1],[CXX],[ -DPIC],[])])], [],\n    [case $_LT_TAGVAR(lt_prog_compiler_pic, $1) in\n     \"\" | \" \"*) ;;\n     *) _LT_TAGVAR(lt_prog_compiler_pic, $1)=\" $_LT_TAGVAR(lt_prog_compiler_pic, $1)\" ;;\n     esac],\n    [_LT_TAGVAR(lt_prog_compiler_pic, $1)=\n     _LT_TAGVAR(lt_prog_compiler_can_build_shared, $1)=no])\nfi\n_LT_TAGDECL([pic_flag], [lt_prog_compiler_pic], [1],\n\t[Additional compiler flags for building library objects])\n\n_LT_TAGDECL([wl], [lt_prog_compiler_wl], [1],\n\t[How to pass a linker flag through the compiler])\n#\n# Check to make sure the static flag actually works.\n#\nwl=$_LT_TAGVAR(lt_prog_compiler_wl, $1) eval lt_tmp_static_flag=\\\"$_LT_TAGVAR(lt_prog_compiler_static, $1)\\\"\n_LT_LINKER_OPTION([if $compiler static flag $lt_tmp_static_flag works],\n  _LT_TAGVAR(lt_cv_prog_compiler_static_works, $1),\n  $lt_tmp_static_flag,\n  [],\n  [_LT_TAGVAR(lt_prog_compiler_static, $1)=])\n_LT_TAGDECL([link_static_flag], [lt_prog_compiler_static], [1],\n\t[Compiler flag to prevent dynamic linking])\n])# _LT_COMPILER_PIC\n\n\n# _LT_LINKER_SHLIBS([TAGNAME])\n# ----------------------------\n# See if the linker supports building shared libraries.\nm4_defun([_LT_LINKER_SHLIBS],\n[AC_REQUIRE([LT_PATH_LD])dnl\nAC_REQUIRE([LT_PATH_NM])dnl\nm4_require([_LT_PATH_MANIFEST_TOOL])dnl\nm4_require([_LT_FILEUTILS_DEFAULTS])dnl\nm4_require([_LT_DECL_EGREP])dnl\nm4_require([_LT_DECL_SED])dnl\nm4_require([_LT_CMD_GLOBAL_SYMBOLS])dnl\nm4_require([_LT_TAG_COMPILER])dnl\nAC_MSG_CHECKING([whether the $compiler linker ($LD) supports shared libraries])\nm4_if([$1], [CXX], [\n  _LT_TAGVAR(export_symbols_cmds, $1)='$NM $libobjs $convenience | $global_symbol_pipe | $SED '\\''s/.* //'\\'' | sort | uniq > $export_symbols'\n  _LT_TAGVAR(exclude_expsyms, $1)=['_GLOBAL_OFFSET_TABLE_|_GLOBAL__F[ID]_.*']\n  case $host_os in\n  aix[[4-9]]*)\n    # If we're using GNU nm, then we don't want the \"-C\" option.\n    # -C means demangle to GNU nm, but means don't demangle to AIX nm.\n    # Without the \"-l\" option, or with the \"-B\" option, AIX nm treats\n    # weak defined symbols like other global defined symbols, whereas\n    # GNU nm marks them as \"W\".\n    # While the 'weak' keyword is ignored in the Export File, we need\n    # it in the Import File for the 'aix-soname' feature, so we have\n    # to replace the \"-B\" option with \"-P\" for AIX nm.\n    if $NM -V 2>&1 | $GREP 'GNU' > /dev/null; then\n      _LT_TAGVAR(export_symbols_cmds, $1)='$NM -Bpg $libobjs $convenience | awk '\\''{ if (((\\$ 2 == \"T\") || (\\$ 2 == \"D\") || (\\$ 2 == \"B\") || (\\$ 2 == \"W\")) && ([substr](\\$ 3,1,1) != \".\")) { if (\\$ 2 == \"W\") { print \\$ 3 \" weak\" } else { print \\$ 3 } } }'\\'' | sort -u > $export_symbols'\n    else\n      _LT_TAGVAR(export_symbols_cmds, $1)='`func_echo_all $NM | $SED -e '\\''s/B\\([[^B]]*\\)$/P\\1/'\\''` -PCpgl $libobjs $convenience | awk '\\''{ if (((\\$ 2 == \"T\") || (\\$ 2 == \"D\") || (\\$ 2 == \"B\") || (\\$ 2 == \"W\") || (\\$ 2 == \"V\") || (\\$ 2 == \"Z\")) && ([substr](\\$ 1,1,1) != \".\")) { if ((\\$ 2 == \"W\") || (\\$ 2 == \"V\") || (\\$ 2 == \"Z\")) { print \\$ 1 \" weak\" } else { print \\$ 1 } } }'\\'' | sort -u > $export_symbols'\n    fi\n    ;;\n  pw32*)\n    _LT_TAGVAR(export_symbols_cmds, $1)=$ltdll_cmds\n    ;;\n  cygwin* | mingw* | cegcc*)\n    case $cc_basename in\n    cl*)\n      _LT_TAGVAR(exclude_expsyms, $1)='_NULL_IMPORT_DESCRIPTOR|_IMPORT_DESCRIPTOR_.*'\n      ;;\n    *)\n      _LT_TAGVAR(export_symbols_cmds, $1)='$NM $libobjs $convenience | $global_symbol_pipe | $SED -e '\\''/^[[BCDGRS]][[ ]]/s/.*[[ ]]\\([[^ ]]*\\)/\\1 DATA/;s/^.*[[ ]]__nm__\\([[^ ]]*\\)[[ ]][[^ ]]*/\\1 DATA/;/^I[[ ]]/d;/^[[AITW]][[ ]]/s/.* //'\\'' | sort | uniq > $export_symbols'\n      _LT_TAGVAR(exclude_expsyms, $1)=['[_]+GLOBAL_OFFSET_TABLE_|[_]+GLOBAL__[FID]_.*|[_]+head_[A-Za-z0-9_]+_dll|[A-Za-z0-9_]+_dll_iname']\n      ;;\n    esac\n    ;;\n  *)\n    _LT_TAGVAR(export_symbols_cmds, $1)='$NM $libobjs $convenience | $global_symbol_pipe | $SED '\\''s/.* //'\\'' | sort | uniq > $export_symbols'\n    ;;\n  esac\n], [\n  runpath_var=\n  _LT_TAGVAR(allow_undefined_flag, $1)=\n  _LT_TAGVAR(always_export_symbols, $1)=no\n  _LT_TAGVAR(archive_cmds, $1)=\n  _LT_TAGVAR(archive_expsym_cmds, $1)=\n  _LT_TAGVAR(compiler_needs_object, $1)=no\n  _LT_TAGVAR(enable_shared_with_static_runtimes, $1)=no\n  _LT_TAGVAR(export_dynamic_flag_spec, $1)=\n  _LT_TAGVAR(export_symbols_cmds, $1)='$NM $libobjs $convenience | $global_symbol_pipe | $SED '\\''s/.* //'\\'' | sort | uniq > $export_symbols'\n  _LT_TAGVAR(hardcode_automatic, $1)=no\n  _LT_TAGVAR(hardcode_direct, $1)=no\n  _LT_TAGVAR(hardcode_direct_absolute, $1)=no\n  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)=\n  _LT_TAGVAR(hardcode_libdir_separator, $1)=\n  _LT_TAGVAR(hardcode_minus_L, $1)=no\n  _LT_TAGVAR(hardcode_shlibpath_var, $1)=unsupported\n  _LT_TAGVAR(inherit_rpath, $1)=no\n  _LT_TAGVAR(link_all_deplibs, $1)=unknown\n  _LT_TAGVAR(module_cmds, $1)=\n  _LT_TAGVAR(module_expsym_cmds, $1)=\n  _LT_TAGVAR(old_archive_from_new_cmds, $1)=\n  _LT_TAGVAR(old_archive_from_expsyms_cmds, $1)=\n  _LT_TAGVAR(thread_safe_flag_spec, $1)=\n  _LT_TAGVAR(whole_archive_flag_spec, $1)=\n  # include_expsyms should be a list of space-separated symbols to be *always*\n  # included in the symbol list\n  _LT_TAGVAR(include_expsyms, $1)=\n  # exclude_expsyms can be an extended regexp of symbols to exclude\n  # it will be wrapped by ' (' and ')$', so one must not match beginning or\n  # end of line.  Example: 'a|bc|.*d.*' will exclude the symbols 'a' and 'bc',\n  # as well as any symbol that contains 'd'.\n  _LT_TAGVAR(exclude_expsyms, $1)=['_GLOBAL_OFFSET_TABLE_|_GLOBAL__F[ID]_.*']\n  # Although _GLOBAL_OFFSET_TABLE_ is a valid symbol C name, most a.out\n  # platforms (ab)use it in PIC code, but their linkers get confused if\n  # the symbol is explicitly referenced.  Since portable code cannot\n  # rely on this symbol name, it's probably fine to never include it in\n  # preloaded symbol tables.\n  # Exclude shared library initialization/finalization symbols.\ndnl Note also adjust exclude_expsyms for C++ above.\n  extract_expsyms_cmds=\n\n  case $host_os in\n  cygwin* | mingw* | pw32* | cegcc*)\n    # FIXME: the MSVC++ port hasn't been tested in a loooong time\n    # When not using gcc, we currently assume that we are using\n    # Microsoft Visual C++.\n    if test yes != \"$GCC\"; then\n      with_gnu_ld=no\n    fi\n    ;;\n  interix*)\n    # we just hope/assume this is gcc and not c89 (= MSVC++)\n    with_gnu_ld=yes\n    ;;\n  openbsd* | bitrig*)\n    with_gnu_ld=no\n    ;;\n  esac\n\n  _LT_TAGVAR(ld_shlibs, $1)=yes\n\n  # On some targets, GNU ld is compatible enough with the native linker\n  # that we're better off using the native interface for both.\n  lt_use_gnu_ld_interface=no\n  if test yes = \"$with_gnu_ld\"; then\n    case $host_os in\n      aix*)\n\t# The AIX port of GNU ld has always aspired to compatibility\n\t# with the native linker.  However, as the warning in the GNU ld\n\t# block says, versions before 2.19.5* couldn't really create working\n\t# shared libraries, regardless of the interface used.\n\tcase `$LD -v 2>&1` in\n\t  *\\ \\(GNU\\ Binutils\\)\\ 2.19.5*) ;;\n\t  *\\ \\(GNU\\ Binutils\\)\\ 2.[[2-9]]*) ;;\n\t  *\\ \\(GNU\\ Binutils\\)\\ [[3-9]]*) ;;\n\t  *)\n\t    lt_use_gnu_ld_interface=yes\n\t    ;;\n\tesac\n\t;;\n      *)\n\tlt_use_gnu_ld_interface=yes\n\t;;\n    esac\n  fi\n\n  if test yes = \"$lt_use_gnu_ld_interface\"; then\n    # If archive_cmds runs LD, not CC, wlarc should be empty\n    wlarc='$wl'\n\n    # Set some defaults for GNU ld with shared library support. These\n    # are reset later if shared libraries are not supported. Putting them\n    # here allows them to be overridden if necessary.\n    runpath_var=LD_RUN_PATH\n    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n    _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl--export-dynamic'\n    # ancient GNU ld didn't support --whole-archive et. al.\n    if $LD --help 2>&1 | $GREP 'no-whole-archive' > /dev/null; then\n      _LT_TAGVAR(whole_archive_flag_spec, $1)=$wlarc'--whole-archive$convenience '$wlarc'--no-whole-archive'\n    else\n      _LT_TAGVAR(whole_archive_flag_spec, $1)=\n    fi\n    supports_anon_versioning=no\n    case `$LD -v | $SED -e 's/([^)]\\+)\\s\\+//' 2>&1` in\n      *GNU\\ gold*) supports_anon_versioning=yes ;;\n      *\\ [[01]].* | *\\ 2.[[0-9]].* | *\\ 2.10.*) ;; # catch versions < 2.11\n      *\\ 2.11.93.0.2\\ *) supports_anon_versioning=yes ;; # RH7.3 ...\n      *\\ 2.11.92.0.12\\ *) supports_anon_versioning=yes ;; # Mandrake 8.2 ...\n      *\\ 2.11.*) ;; # other 2.11 versions\n      *) supports_anon_versioning=yes ;;\n    esac\n\n    # See if GNU ld supports shared libraries.\n    case $host_os in\n    aix[[3-9]]*)\n      # On AIX/PPC, the GNU linker is very broken\n      if test ia64 != \"$host_cpu\"; then\n\t_LT_TAGVAR(ld_shlibs, $1)=no\n\tcat <<_LT_EOF 1>&2\n\n*** Warning: the GNU linker, at least up to release 2.19, is reported\n*** to be unable to reliably create shared libraries on AIX.\n*** Therefore, libtool is disabling shared libraries support.  If you\n*** really care for shared libraries, you may want to install binutils\n*** 2.20 or above, or modify your PATH so that a non-GNU linker is found.\n*** You will then need to restart the configuration process.\n\n_LT_EOF\n      fi\n      ;;\n\n    amigaos*)\n      case $host_cpu in\n      powerpc)\n            # see comment about AmigaOS4 .so support\n            _LT_TAGVAR(archive_cmds, $1)='$CC -shared $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n            _LT_TAGVAR(archive_expsym_cmds, $1)=''\n        ;;\n      m68k)\n            _LT_TAGVAR(archive_cmds, $1)='$RM $output_objdir/a2ixlibrary.data~$ECHO \"#define NAME $libname\" > $output_objdir/a2ixlibrary.data~$ECHO \"#define LIBRARY_ID 1\" >> $output_objdir/a2ixlibrary.data~$ECHO \"#define VERSION $major\" >> $output_objdir/a2ixlibrary.data~$ECHO \"#define REVISION $revision\" >> $output_objdir/a2ixlibrary.data~$AR $AR_FLAGS $lib $libobjs~$RANLIB $lib~(cd $output_objdir && a2ixlibrary -32)'\n            _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n            _LT_TAGVAR(hardcode_minus_L, $1)=yes\n        ;;\n      esac\n      ;;\n\n    beos*)\n      if $LD --help 2>&1 | $GREP ': supported targets:.* elf' > /dev/null; then\n\t_LT_TAGVAR(allow_undefined_flag, $1)=unsupported\n\t# Joseph Beckenbach <jrb3@best.com> says some releases of gcc\n\t# support --undefined.  This deserves some investigation.  FIXME\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -nostart $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n      else\n\t_LT_TAGVAR(ld_shlibs, $1)=no\n      fi\n      ;;\n\n    cygwin* | mingw* | pw32* | cegcc*)\n      # _LT_TAGVAR(hardcode_libdir_flag_spec, $1) is actually meaningless,\n      # as there is no search path for DLLs.\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n      _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl--export-all-symbols'\n      _LT_TAGVAR(allow_undefined_flag, $1)=unsupported\n      _LT_TAGVAR(always_export_symbols, $1)=no\n      _LT_TAGVAR(enable_shared_with_static_runtimes, $1)=yes\n      _LT_TAGVAR(export_symbols_cmds, $1)='$NM $libobjs $convenience | $global_symbol_pipe | $SED -e '\\''/^[[BCDGRS]][[ ]]/s/.*[[ ]]\\([[^ ]]*\\)/\\1 DATA/;s/^.*[[ ]]__nm__\\([[^ ]]*\\)[[ ]][[^ ]]*/\\1 DATA/;/^I[[ ]]/d;/^[[AITW]][[ ]]/s/.* //'\\'' | sort | uniq > $export_symbols'\n      _LT_TAGVAR(exclude_expsyms, $1)=['[_]+GLOBAL_OFFSET_TABLE_|[_]+GLOBAL__[FID]_.*|[_]+head_[A-Za-z0-9_]+_dll|[A-Za-z0-9_]+_dll_iname']\n\n      if $LD --help 2>&1 | $GREP 'auto-import' > /dev/null; then\n        _LT_TAGVAR(archive_cmds, $1)='$CC -shared $libobjs $deplibs $compiler_flags -o $output_objdir/$soname $wl--enable-auto-image-base -Xlinker --out-implib -Xlinker $lib'\n\t# If the export-symbols file already is a .def file, use it as\n\t# is; otherwise, prepend EXPORTS...\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='if _LT_DLL_DEF_P([$export_symbols]); then\n          cp $export_symbols $output_objdir/$soname.def;\n        else\n          echo EXPORTS > $output_objdir/$soname.def;\n          cat $export_symbols >> $output_objdir/$soname.def;\n        fi~\n        $CC -shared $output_objdir/$soname.def $libobjs $deplibs $compiler_flags -o $output_objdir/$soname $wl--enable-auto-image-base -Xlinker --out-implib -Xlinker $lib'\n      else\n\t_LT_TAGVAR(ld_shlibs, $1)=no\n      fi\n      ;;\n\n    haiku*)\n      _LT_TAGVAR(archive_cmds, $1)='$CC -shared $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n      _LT_TAGVAR(link_all_deplibs, $1)=yes\n      ;;\n\n    os2*)\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n      _LT_TAGVAR(hardcode_minus_L, $1)=yes\n      _LT_TAGVAR(allow_undefined_flag, $1)=unsupported\n      shrext_cmds=.dll\n      _LT_TAGVAR(archive_cmds, $1)='$ECHO \"LIBRARY ${soname%$shared_ext} INITINSTANCE TERMINSTANCE\" > $output_objdir/$libname.def~\n\t$ECHO \"DESCRIPTION \\\"$libname\\\"\" >> $output_objdir/$libname.def~\n\t$ECHO \"DATA MULTIPLE NONSHARED\" >> $output_objdir/$libname.def~\n\t$ECHO EXPORTS >> $output_objdir/$libname.def~\n\temxexp $libobjs | $SED /\"_DLL_InitTerm\"/d >> $output_objdir/$libname.def~\n\t$CC -Zdll -Zcrtdll -o $output_objdir/$soname $libobjs $deplibs $compiler_flags $output_objdir/$libname.def~\n\temximp -o $lib $output_objdir/$libname.def'\n      _LT_TAGVAR(archive_expsym_cmds, $1)='$ECHO \"LIBRARY ${soname%$shared_ext} INITINSTANCE TERMINSTANCE\" > $output_objdir/$libname.def~\n\t$ECHO \"DESCRIPTION \\\"$libname\\\"\" >> $output_objdir/$libname.def~\n\t$ECHO \"DATA MULTIPLE NONSHARED\" >> $output_objdir/$libname.def~\n\t$ECHO EXPORTS >> $output_objdir/$libname.def~\n\tprefix_cmds=\"$SED\"~\n\tif test EXPORTS = \"`$SED 1q $export_symbols`\"; then\n\t  prefix_cmds=\"$prefix_cmds -e 1d\";\n\tfi~\n\tprefix_cmds=\"$prefix_cmds -e \\\"s/^\\(.*\\)$/_\\1/g\\\"\"~\n\tcat $export_symbols | $prefix_cmds >> $output_objdir/$libname.def~\n\t$CC -Zdll -Zcrtdll -o $output_objdir/$soname $libobjs $deplibs $compiler_flags $output_objdir/$libname.def~\n\temximp -o $lib $output_objdir/$libname.def'\n      _LT_TAGVAR(old_archive_From_new_cmds, $1)='emximp -o $output_objdir/${libname}_dll.a $output_objdir/$libname.def'\n      _LT_TAGVAR(enable_shared_with_static_runtimes, $1)=yes\n      ;;\n\n    interix[[3-9]]*)\n      _LT_TAGVAR(hardcode_direct, $1)=no\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath,$libdir'\n      _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-E'\n      # Hack: On Interix 3.x, we cannot compile PIC because of a broken gcc.\n      # Instead, shared libraries are loaded at an image base (0x10000000 by\n      # default) and relocated if they conflict, which is a slow very memory\n      # consuming and fragmenting process.  To avoid this, we pick a random,\n      # 256 KiB-aligned image base between 0x50000000 and 0x6FFC0000 at link\n      # time.  Moving up from 0x10000000 also allows more sbrk(2) space.\n      _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-h,$soname $wl--image-base,`expr ${RANDOM-$$} % 4096 / 2 \\* 262144 + 1342177280` -o $lib'\n      _LT_TAGVAR(archive_expsym_cmds, $1)='sed \"s|^|_|\" $export_symbols >$output_objdir/$soname.expsym~$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-h,$soname $wl--retain-symbols-file,$output_objdir/$soname.expsym $wl--image-base,`expr ${RANDOM-$$} % 4096 / 2 \\* 262144 + 1342177280` -o $lib'\n      ;;\n\n    gnu* | linux* | tpf* | k*bsd*-gnu | kopensolaris*-gnu)\n      tmp_diet=no\n      if test linux-dietlibc = \"$host_os\"; then\n\tcase $cc_basename in\n\t  diet\\ *) tmp_diet=yes;;\t# linux-dietlibc with static linking (!diet-dyn)\n\tesac\n      fi\n      if $LD --help 2>&1 | $EGREP ': supported targets:.* elf' > /dev/null \\\n\t && test no = \"$tmp_diet\"\n      then\n\ttmp_addflag=' $pic_flag'\n\ttmp_sharedflag='-shared'\n\tcase $cc_basename,$host_cpu in\n        pgcc*)\t\t\t\t# Portland Group C compiler\n\t  _LT_TAGVAR(whole_archive_flag_spec, $1)='$wl--whole-archive`for conv in $convenience\\\"\\\"; do test  -n \\\"$conv\\\" && new_convenience=\\\"$new_convenience,$conv\\\"; done; func_echo_all \\\"$new_convenience\\\"` $wl--no-whole-archive'\n\t  tmp_addflag=' $pic_flag'\n\t  ;;\n\tpgf77* | pgf90* | pgf95* | pgfortran*)\n\t\t\t\t\t# Portland Group f77 and f90 compilers\n\t  _LT_TAGVAR(whole_archive_flag_spec, $1)='$wl--whole-archive`for conv in $convenience\\\"\\\"; do test  -n \\\"$conv\\\" && new_convenience=\\\"$new_convenience,$conv\\\"; done; func_echo_all \\\"$new_convenience\\\"` $wl--no-whole-archive'\n\t  tmp_addflag=' $pic_flag -Mnomain' ;;\n\tecc*,ia64* | icc*,ia64*)\t# Intel C compiler on ia64\n\t  tmp_addflag=' -i_dynamic' ;;\n\tefc*,ia64* | ifort*,ia64*)\t# Intel Fortran compiler on ia64\n\t  tmp_addflag=' -i_dynamic -nofor_main' ;;\n\tifc* | ifort*)\t\t\t# Intel Fortran compiler\n\t  tmp_addflag=' -nofor_main' ;;\n\tlf95*)\t\t\t\t# Lahey Fortran 8.1\n\t  _LT_TAGVAR(whole_archive_flag_spec, $1)=\n\t  tmp_sharedflag='--shared' ;;\n        nagfor*)                        # NAGFOR 5.3\n          tmp_sharedflag='-Wl,-shared' ;;\n\txl[[cC]]* | bgxl[[cC]]* | mpixl[[cC]]*) # IBM XL C 8.0 on PPC (deal with xlf below)\n\t  tmp_sharedflag='-qmkshrobj'\n\t  tmp_addflag= ;;\n\tnvcc*)\t# Cuda Compiler Driver 2.2\n\t  _LT_TAGVAR(whole_archive_flag_spec, $1)='$wl--whole-archive`for conv in $convenience\\\"\\\"; do test  -n \\\"$conv\\\" && new_convenience=\\\"$new_convenience,$conv\\\"; done; func_echo_all \\\"$new_convenience\\\"` $wl--no-whole-archive'\n\t  _LT_TAGVAR(compiler_needs_object, $1)=yes\n\t  ;;\n\tesac\n\tcase `$CC -V 2>&1 | sed 5q` in\n\t*Sun\\ C*)\t\t\t# Sun C 5.9\n\t  _LT_TAGVAR(whole_archive_flag_spec, $1)='$wl--whole-archive`new_convenience=; for conv in $convenience\\\"\\\"; do test -z \\\"$conv\\\" || new_convenience=\\\"$new_convenience,$conv\\\"; done; func_echo_all \\\"$new_convenience\\\"` $wl--no-whole-archive'\n\t  _LT_TAGVAR(compiler_needs_object, $1)=yes\n\t  tmp_sharedflag='-G' ;;\n\t*Sun\\ F*)\t\t\t# Sun Fortran 8.3\n\t  tmp_sharedflag='-G' ;;\n\tesac\n\t_LT_TAGVAR(archive_cmds, $1)='$CC '\"$tmp_sharedflag\"\"$tmp_addflag\"' $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n\n        if test yes = \"$supports_anon_versioning\"; then\n          _LT_TAGVAR(archive_expsym_cmds, $1)='echo \"{ global:\" > $output_objdir/$libname.ver~\n            cat $export_symbols | sed -e \"s/\\(.*\\)/\\1;/\" >> $output_objdir/$libname.ver~\n            echo \"local: *; };\" >> $output_objdir/$libname.ver~\n            $CC '\"$tmp_sharedflag\"\"$tmp_addflag\"' $libobjs $deplibs $compiler_flags $wl-soname $wl$soname $wl-version-script $wl$output_objdir/$libname.ver -o $lib'\n        fi\n\n\tcase $cc_basename in\n\ttcc*)\n\t  _LT_TAGVAR(export_dynamic_flag_spec, $1)='-rdynamic'\n\t  ;;\n\txlf* | bgf* | bgxlf* | mpixlf*)\n\t  # IBM XL Fortran 10.1 on PPC cannot create shared libs itself\n\t  _LT_TAGVAR(whole_archive_flag_spec, $1)='--whole-archive$convenience --no-whole-archive'\n\t  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n\t  _LT_TAGVAR(archive_cmds, $1)='$LD -shared $libobjs $deplibs $linker_flags -soname $soname -o $lib'\n\t  if test yes = \"$supports_anon_versioning\"; then\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)='echo \"{ global:\" > $output_objdir/$libname.ver~\n              cat $export_symbols | sed -e \"s/\\(.*\\)/\\1;/\" >> $output_objdir/$libname.ver~\n              echo \"local: *; };\" >> $output_objdir/$libname.ver~\n              $LD -shared $libobjs $deplibs $linker_flags -soname $soname -version-script $output_objdir/$libname.ver -o $lib'\n\t  fi\n\t  ;;\n\tesac\n      else\n        _LT_TAGVAR(ld_shlibs, $1)=no\n      fi\n      ;;\n\n    netbsd*)\n      if echo __ELF__ | $CC -E - | $GREP __ELF__ >/dev/null; then\n\t_LT_TAGVAR(archive_cmds, $1)='$LD -Bshareable $libobjs $deplibs $linker_flags -o $lib'\n\twlarc=\n      else\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-soname $wl$soname $wl-retain-symbols-file $wl$export_symbols -o $lib'\n      fi\n      ;;\n\n    solaris*)\n      if $LD -v 2>&1 | $GREP 'BFD 2\\.8' > /dev/null; then\n\t_LT_TAGVAR(ld_shlibs, $1)=no\n\tcat <<_LT_EOF 1>&2\n\n*** Warning: The releases 2.8.* of the GNU linker cannot reliably\n*** create shared libraries on Solaris systems.  Therefore, libtool\n*** is disabling shared libraries support.  We urge you to upgrade GNU\n*** binutils to release 2.9.1 or newer.  Another option is to modify\n*** your PATH or compiler configuration so that the native linker is\n*** used, and then restart.\n\n_LT_EOF\n      elif $LD --help 2>&1 | $GREP ': supported targets:.* elf' > /dev/null; then\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-soname $wl$soname $wl-retain-symbols-file $wl$export_symbols -o $lib'\n      else\n\t_LT_TAGVAR(ld_shlibs, $1)=no\n      fi\n      ;;\n\n    sysv5* | sco3.2v5* | sco5v6* | unixware* | OpenUNIX*)\n      case `$LD -v 2>&1` in\n        *\\ [[01]].* | *\\ 2.[[0-9]].* | *\\ 2.1[[0-5]].*)\n\t_LT_TAGVAR(ld_shlibs, $1)=no\n\tcat <<_LT_EOF 1>&2\n\n*** Warning: Releases of the GNU linker prior to 2.16.91.0.3 cannot\n*** reliably create shared libraries on SCO systems.  Therefore, libtool\n*** is disabling shared libraries support.  We urge you to upgrade GNU\n*** binutils to release 2.16.91.0.3 or newer.  Another option is to modify\n*** your PATH or compiler configuration so that the native linker is\n*** used, and then restart.\n\n_LT_EOF\n\t;;\n\t*)\n\t  # For security reasons, it is highly recommended that you always\n\t  # use absolute paths for naming shared libraries, and exclude the\n\t  # DT_RUNPATH tag from executables and libraries.  But doing so\n\t  # requires that you compile everything twice, which is a pain.\n\t  if $LD --help 2>&1 | $GREP ': supported targets:.* elf' > /dev/null; then\n\t    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n\t    _LT_TAGVAR(archive_cmds, $1)='$CC -shared $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $libobjs $deplibs $compiler_flags $wl-soname $wl$soname $wl-retain-symbols-file $wl$export_symbols -o $lib'\n\t  else\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t  fi\n\t;;\n      esac\n      ;;\n\n    sunos4*)\n      _LT_TAGVAR(archive_cmds, $1)='$LD -assert pure-text -Bshareable -o $lib $libobjs $deplibs $linker_flags'\n      wlarc=\n      _LT_TAGVAR(hardcode_direct, $1)=yes\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      ;;\n\n    *)\n      if $LD --help 2>&1 | $GREP ': supported targets:.* elf' > /dev/null; then\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-soname $wl$soname $wl-retain-symbols-file $wl$export_symbols -o $lib'\n      else\n\t_LT_TAGVAR(ld_shlibs, $1)=no\n      fi\n      ;;\n    esac\n\n    if test no = \"$_LT_TAGVAR(ld_shlibs, $1)\"; then\n      runpath_var=\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)=\n      _LT_TAGVAR(export_dynamic_flag_spec, $1)=\n      _LT_TAGVAR(whole_archive_flag_spec, $1)=\n    fi\n  else\n    # PORTME fill in a description of your system's linker (not GNU ld)\n    case $host_os in\n    aix3*)\n      _LT_TAGVAR(allow_undefined_flag, $1)=unsupported\n      _LT_TAGVAR(always_export_symbols, $1)=yes\n      _LT_TAGVAR(archive_expsym_cmds, $1)='$LD -o $output_objdir/$soname $libobjs $deplibs $linker_flags -bE:$export_symbols -T512 -H512 -bM:SRE~$AR $AR_FLAGS $lib $output_objdir/$soname'\n      # Note: this linker hardcodes the directories in LIBPATH if there\n      # are no directories specified by -L.\n      _LT_TAGVAR(hardcode_minus_L, $1)=yes\n      if test yes = \"$GCC\" && test -z \"$lt_prog_compiler_static\"; then\n\t# Neither direct hardcoding nor static linking is supported with a\n\t# broken collect2.\n\t_LT_TAGVAR(hardcode_direct, $1)=unsupported\n      fi\n      ;;\n\n    aix[[4-9]]*)\n      if test ia64 = \"$host_cpu\"; then\n\t# On IA64, the linker does run time linking by default, so we don't\n\t# have to do anything special.\n\taix_use_runtimelinking=no\n\texp_sym_flag='-Bexport'\n\tno_entry_flag=\n      else\n\t# If we're using GNU nm, then we don't want the \"-C\" option.\n\t# -C means demangle to GNU nm, but means don't demangle to AIX nm.\n\t# Without the \"-l\" option, or with the \"-B\" option, AIX nm treats\n\t# weak defined symbols like other global defined symbols, whereas\n\t# GNU nm marks them as \"W\".\n\t# While the 'weak' keyword is ignored in the Export File, we need\n\t# it in the Import File for the 'aix-soname' feature, so we have\n\t# to replace the \"-B\" option with \"-P\" for AIX nm.\n\tif $NM -V 2>&1 | $GREP 'GNU' > /dev/null; then\n\t  _LT_TAGVAR(export_symbols_cmds, $1)='$NM -Bpg $libobjs $convenience | awk '\\''{ if (((\\$ 2 == \"T\") || (\\$ 2 == \"D\") || (\\$ 2 == \"B\") || (\\$ 2 == \"W\")) && ([substr](\\$ 3,1,1) != \".\")) { if (\\$ 2 == \"W\") { print \\$ 3 \" weak\" } else { print \\$ 3 } } }'\\'' | sort -u > $export_symbols'\n\telse\n\t  _LT_TAGVAR(export_symbols_cmds, $1)='`func_echo_all $NM | $SED -e '\\''s/B\\([[^B]]*\\)$/P\\1/'\\''` -PCpgl $libobjs $convenience | awk '\\''{ if (((\\$ 2 == \"T\") || (\\$ 2 == \"D\") || (\\$ 2 == \"B\") || (\\$ 2 == \"W\") || (\\$ 2 == \"V\") || (\\$ 2 == \"Z\")) && ([substr](\\$ 1,1,1) != \".\")) { if ((\\$ 2 == \"W\") || (\\$ 2 == \"V\") || (\\$ 2 == \"Z\")) { print \\$ 1 \" weak\" } else { print \\$ 1 } } }'\\'' | sort -u > $export_symbols'\n\tfi\n\taix_use_runtimelinking=no\n\n\t# Test if we are trying to use run time linking or normal\n\t# AIX style linking. If -brtl is somewhere in LDFLAGS, we\n\t# have runtime linking enabled, and use it for executables.\n\t# For shared libraries, we enable/disable runtime linking\n\t# depending on the kind of the shared library created -\n\t# when \"with_aix_soname,aix_use_runtimelinking\" is:\n\t# \"aix,no\"   lib.a(lib.so.V) shared, rtl:no,  for executables\n\t# \"aix,yes\"  lib.so          shared, rtl:yes, for executables\n\t#            lib.a           static archive\n\t# \"both,no\"  lib.so.V(shr.o) shared, rtl:yes\n\t#            lib.a(lib.so.V) shared, rtl:no,  for executables\n\t# \"both,yes\" lib.so.V(shr.o) shared, rtl:yes, for executables\n\t#            lib.a(lib.so.V) shared, rtl:no\n\t# \"svr4,*\"   lib.so.V(shr.o) shared, rtl:yes, for executables\n\t#            lib.a           static archive\n\tcase $host_os in aix4.[[23]]|aix4.[[23]].*|aix[[5-9]]*)\n\t  for ld_flag in $LDFLAGS; do\n\t  if (test x-brtl = \"x$ld_flag\" || test x-Wl,-brtl = \"x$ld_flag\"); then\n\t    aix_use_runtimelinking=yes\n\t    break\n\t  fi\n\t  done\n\t  if test svr4,no = \"$with_aix_soname,$aix_use_runtimelinking\"; then\n\t    # With aix-soname=svr4, we create the lib.so.V shared archives only,\n\t    # so we don't have lib.a shared libs to link our executables.\n\t    # We have to force runtime linking in this case.\n\t    aix_use_runtimelinking=yes\n\t    LDFLAGS=\"$LDFLAGS -Wl,-brtl\"\n\t  fi\n\t  ;;\n\tesac\n\n\texp_sym_flag='-bexport'\n\tno_entry_flag='-bnoentry'\n      fi\n\n      # When large executables or shared objects are built, AIX ld can\n      # have problems creating the table of contents.  If linking a library\n      # or program results in \"error TOC overflow\" add -mminimal-toc to\n      # CXXFLAGS/CFLAGS for g++/gcc.  In the cases where that is not\n      # enough to fix the problem, add -Wl,-bbigtoc to LDFLAGS.\n\n      _LT_TAGVAR(archive_cmds, $1)=''\n      _LT_TAGVAR(hardcode_direct, $1)=yes\n      _LT_TAGVAR(hardcode_direct_absolute, $1)=yes\n      _LT_TAGVAR(hardcode_libdir_separator, $1)=':'\n      _LT_TAGVAR(link_all_deplibs, $1)=yes\n      _LT_TAGVAR(file_list_spec, $1)='$wl-f,'\n      case $with_aix_soname,$aix_use_runtimelinking in\n      aix,*) ;; # traditional, no import file\n      svr4,* | *,yes) # use import file\n\t# The Import File defines what to hardcode.\n\t_LT_TAGVAR(hardcode_direct, $1)=no\n\t_LT_TAGVAR(hardcode_direct_absolute, $1)=no\n\t;;\n      esac\n\n      if test yes = \"$GCC\"; then\n\tcase $host_os in aix4.[[012]]|aix4.[[012]].*)\n\t# We only want to do this on AIX 4.2 and lower, the check\n\t# below for broken collect2 doesn't work under 4.3+\n\t  collect2name=`$CC -print-prog-name=collect2`\n\t  if test -f \"$collect2name\" &&\n\t   strings \"$collect2name\" | $GREP resolve_lib_name >/dev/null\n\t  then\n\t  # We have reworked collect2\n\t  :\n\t  else\n\t  # We have old collect2\n\t  _LT_TAGVAR(hardcode_direct, $1)=unsupported\n\t  # It fails to find uninstalled libraries when the uninstalled\n\t  # path is not listed in the libpath.  Setting hardcode_minus_L\n\t  # to unsupported forces relinking\n\t  _LT_TAGVAR(hardcode_minus_L, $1)=yes\n\t  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n\t  _LT_TAGVAR(hardcode_libdir_separator, $1)=\n\t  fi\n\t  ;;\n\tesac\n\tshared_flag='-shared'\n\tif test yes = \"$aix_use_runtimelinking\"; then\n\t  shared_flag=\"$shared_flag \"'$wl-G'\n\tfi\n\t# Need to ensure runtime linking is disabled for the traditional\n\t# shared library, or the linker may eventually find shared libraries\n\t# /with/ Import File - we do not want to mix them.\n\tshared_flag_aix='-shared'\n\tshared_flag_svr4='-shared $wl-G'\n      else\n\t# not using gcc\n\tif test ia64 = \"$host_cpu\"; then\n\t# VisualAge C++, Version 5.5 for AIX 5L for IA-64, Beta 3 Release\n\t# chokes on -Wl,-G. The following line is correct:\n\t  shared_flag='-G'\n\telse\n\t  if test yes = \"$aix_use_runtimelinking\"; then\n\t    shared_flag='$wl-G'\n\t  else\n\t    shared_flag='$wl-bM:SRE'\n\t  fi\n\t  shared_flag_aix='$wl-bM:SRE'\n\t  shared_flag_svr4='$wl-G'\n\tfi\n      fi\n\n      _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-bexpall'\n      # It seems that -bexpall does not export symbols beginning with\n      # underscore (_), so it is better to generate a list of symbols to export.\n      _LT_TAGVAR(always_export_symbols, $1)=yes\n      if test aix,yes = \"$with_aix_soname,$aix_use_runtimelinking\"; then\n\t# Warning - without using the other runtime loading flags (-brtl),\n\t# -berok will link without error, but may produce a broken library.\n\t_LT_TAGVAR(allow_undefined_flag, $1)='-berok'\n        # Determine the default libpath from the value encoded in an\n        # empty executable.\n        _LT_SYS_MODULE_PATH_AIX([$1])\n        _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-blibpath:$libdir:'\"$aix_libpath\"\n        _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -o $output_objdir/$soname $libobjs $deplibs $wl'$no_entry_flag' $compiler_flags `if test -n \"$allow_undefined_flag\"; then func_echo_all \"$wl$allow_undefined_flag\"; else :; fi` $wl'$exp_sym_flag:\\$export_symbols' '$shared_flag\n      else\n\tif test ia64 = \"$host_cpu\"; then\n\t  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-R $libdir:/usr/lib:/lib'\n\t  _LT_TAGVAR(allow_undefined_flag, $1)=\"-z nodefs\"\n\t  _LT_TAGVAR(archive_expsym_cmds, $1)=\"\\$CC $shared_flag\"' -o $output_objdir/$soname $libobjs $deplibs '\"\\$wl$no_entry_flag\"' $compiler_flags $wl$allow_undefined_flag '\"\\$wl$exp_sym_flag:\\$export_symbols\"\n\telse\n\t # Determine the default libpath from the value encoded in an\n\t # empty executable.\n\t _LT_SYS_MODULE_PATH_AIX([$1])\n\t _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-blibpath:$libdir:'\"$aix_libpath\"\n\t  # Warning - without using the other run time loading flags,\n\t  # -berok will link without error, but may produce a broken library.\n\t  _LT_TAGVAR(no_undefined_flag, $1)=' $wl-bernotok'\n\t  _LT_TAGVAR(allow_undefined_flag, $1)=' $wl-berok'\n\t  if test yes = \"$with_gnu_ld\"; then\n\t    # We only use this code for GNU lds that support --whole-archive.\n\t    _LT_TAGVAR(whole_archive_flag_spec, $1)='$wl--whole-archive$convenience $wl--no-whole-archive'\n\t  else\n\t    # Exported symbols can be pulled into shared objects from archives\n\t    _LT_TAGVAR(whole_archive_flag_spec, $1)='$convenience'\n\t  fi\n\t  _LT_TAGVAR(archive_cmds_need_lc, $1)=yes\n\t  _LT_TAGVAR(archive_expsym_cmds, $1)='$RM -r $output_objdir/$realname.d~$MKDIR $output_objdir/$realname.d'\n\t  # -brtl affects multiple linker settings, -berok does not and is overridden later\n\t  compiler_flags_filtered='`func_echo_all \"$compiler_flags \" | $SED -e \"s%-brtl\\\\([[, ]]\\\\)%-berok\\\\1%g\"`'\n\t  if test svr4 != \"$with_aix_soname\"; then\n\t    # This is similar to how AIX traditionally builds its shared libraries.\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)=\"$_LT_TAGVAR(archive_expsym_cmds, $1)\"'~$CC '$shared_flag_aix' -o $output_objdir/$realname.d/$soname $libobjs $deplibs $wl-bnoentry '$compiler_flags_filtered'$wl-bE:$export_symbols$allow_undefined_flag~$AR $AR_FLAGS $output_objdir/$libname$release.a $output_objdir/$realname.d/$soname'\n\t  fi\n\t  if test aix != \"$with_aix_soname\"; then\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)=\"$_LT_TAGVAR(archive_expsym_cmds, $1)\"'~$CC '$shared_flag_svr4' -o $output_objdir/$realname.d/$shared_archive_member_spec.o $libobjs $deplibs $wl-bnoentry '$compiler_flags_filtered'$wl-bE:$export_symbols$allow_undefined_flag~$STRIP -e $output_objdir/$realname.d/$shared_archive_member_spec.o~( func_echo_all \"#! $soname($shared_archive_member_spec.o)\"; if test shr_64 = \"$shared_archive_member_spec\"; then func_echo_all \"# 64\"; else func_echo_all \"# 32\"; fi; cat $export_symbols ) > $output_objdir/$realname.d/$shared_archive_member_spec.imp~$AR $AR_FLAGS $output_objdir/$soname $output_objdir/$realname.d/$shared_archive_member_spec.o $output_objdir/$realname.d/$shared_archive_member_spec.imp'\n\t  else\n\t    # used by -dlpreopen to get the symbols\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)=\"$_LT_TAGVAR(archive_expsym_cmds, $1)\"'~$MV  $output_objdir/$realname.d/$soname $output_objdir'\n\t  fi\n\t  _LT_TAGVAR(archive_expsym_cmds, $1)=\"$_LT_TAGVAR(archive_expsym_cmds, $1)\"'~$RM -r $output_objdir/$realname.d'\n\tfi\n      fi\n      ;;\n\n    amigaos*)\n      case $host_cpu in\n      powerpc)\n            # see comment about AmigaOS4 .so support\n            _LT_TAGVAR(archive_cmds, $1)='$CC -shared $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n            _LT_TAGVAR(archive_expsym_cmds, $1)=''\n        ;;\n      m68k)\n            _LT_TAGVAR(archive_cmds, $1)='$RM $output_objdir/a2ixlibrary.data~$ECHO \"#define NAME $libname\" > $output_objdir/a2ixlibrary.data~$ECHO \"#define LIBRARY_ID 1\" >> $output_objdir/a2ixlibrary.data~$ECHO \"#define VERSION $major\" >> $output_objdir/a2ixlibrary.data~$ECHO \"#define REVISION $revision\" >> $output_objdir/a2ixlibrary.data~$AR $AR_FLAGS $lib $libobjs~$RANLIB $lib~(cd $output_objdir && a2ixlibrary -32)'\n            _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n            _LT_TAGVAR(hardcode_minus_L, $1)=yes\n        ;;\n      esac\n      ;;\n\n    bsdi[[45]]*)\n      _LT_TAGVAR(export_dynamic_flag_spec, $1)=-rdynamic\n      ;;\n\n    cygwin* | mingw* | pw32* | cegcc*)\n      # When not using gcc, we currently assume that we are using\n      # Microsoft Visual C++.\n      # hardcode_libdir_flag_spec is actually meaningless, as there is\n      # no search path for DLLs.\n      case $cc_basename in\n      cl*)\n\t# Native MSVC\n\t_LT_TAGVAR(hardcode_libdir_flag_spec, $1)=' '\n\t_LT_TAGVAR(allow_undefined_flag, $1)=unsupported\n\t_LT_TAGVAR(always_export_symbols, $1)=yes\n\t_LT_TAGVAR(file_list_spec, $1)='@'\n\t# Tell ltmain to make .lib files, not .a files.\n\tlibext=lib\n\t# Tell ltmain to make .dll files, not .so files.\n\tshrext_cmds=.dll\n\t# FIXME: Setting linknames here is a bad hack.\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -o $output_objdir/$soname $libobjs $compiler_flags $deplibs -Wl,-DLL,-IMPLIB:\"$tool_output_objdir$libname.dll.lib\"~linknames='\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='if _LT_DLL_DEF_P([$export_symbols]); then\n            cp \"$export_symbols\" \"$output_objdir/$soname.def\";\n            echo \"$tool_output_objdir$soname.def\" > \"$output_objdir/$soname.exp\";\n          else\n            $SED -e '\\''s/^/-link -EXPORT:/'\\'' < $export_symbols > $output_objdir/$soname.exp;\n          fi~\n          $CC -o $tool_output_objdir$soname $libobjs $compiler_flags $deplibs \"@$tool_output_objdir$soname.exp\" -Wl,-DLL,-IMPLIB:\"$tool_output_objdir$libname.dll.lib\"~\n          linknames='\n\t# The linker will not automatically build a static lib if we build a DLL.\n\t# _LT_TAGVAR(old_archive_from_new_cmds, $1)='true'\n\t_LT_TAGVAR(enable_shared_with_static_runtimes, $1)=yes\n\t_LT_TAGVAR(exclude_expsyms, $1)='_NULL_IMPORT_DESCRIPTOR|_IMPORT_DESCRIPTOR_.*'\n\t_LT_TAGVAR(export_symbols_cmds, $1)='$NM $libobjs $convenience | $global_symbol_pipe | $SED -e '\\''/^[[BCDGRS]][[ ]]/s/.*[[ ]]\\([[^ ]]*\\)/\\1,DATA/'\\'' | $SED -e '\\''/^[[AITW]][[ ]]/s/.*[[ ]]//'\\'' | sort | uniq > $export_symbols'\n\t# Don't use ranlib\n\t_LT_TAGVAR(old_postinstall_cmds, $1)='chmod 644 $oldlib'\n\t_LT_TAGVAR(postlink_cmds, $1)='lt_outputfile=\"@OUTPUT@\"~\n          lt_tool_outputfile=\"@TOOL_OUTPUT@\"~\n          case $lt_outputfile in\n            *.exe|*.EXE) ;;\n            *)\n              lt_outputfile=$lt_outputfile.exe\n              lt_tool_outputfile=$lt_tool_outputfile.exe\n              ;;\n          esac~\n          if test : != \"$MANIFEST_TOOL\" && test -f \"$lt_outputfile.manifest\"; then\n            $MANIFEST_TOOL -manifest \"$lt_tool_outputfile.manifest\" -outputresource:\"$lt_tool_outputfile\" || exit 1;\n            $RM \"$lt_outputfile.manifest\";\n          fi'\n\t;;\n      *)\n\t# Assume MSVC wrapper\n\t_LT_TAGVAR(hardcode_libdir_flag_spec, $1)=' '\n\t_LT_TAGVAR(allow_undefined_flag, $1)=unsupported\n\t# Tell ltmain to make .lib files, not .a files.\n\tlibext=lib\n\t# Tell ltmain to make .dll files, not .so files.\n\tshrext_cmds=.dll\n\t# FIXME: Setting linknames here is a bad hack.\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -o $lib $libobjs $compiler_flags `func_echo_all \"$deplibs\" | $SED '\\''s/ -lc$//'\\''` -link -dll~linknames='\n\t# The linker will automatically build a .lib file if we build a DLL.\n\t_LT_TAGVAR(old_archive_from_new_cmds, $1)='true'\n\t# FIXME: Should let the user specify the lib program.\n\t_LT_TAGVAR(old_archive_cmds, $1)='lib -OUT:$oldlib$oldobjs$old_deplibs'\n\t_LT_TAGVAR(enable_shared_with_static_runtimes, $1)=yes\n\t;;\n      esac\n      ;;\n\n    darwin* | rhapsody*)\n      _LT_DARWIN_LINKER_FEATURES($1)\n      ;;\n\n    dgux*)\n      _LT_TAGVAR(archive_cmds, $1)='$LD -G -h $soname -o $lib $libobjs $deplibs $linker_flags'\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      ;;\n\n    # FreeBSD 2.2.[012] allows us to include c++rt0.o to get C++ constructor\n    # support.  Future versions do this automatically, but an explicit c++rt0.o\n    # does not break anything, and helps significantly (at the cost of a little\n    # extra space).\n    freebsd2.2*)\n      _LT_TAGVAR(archive_cmds, $1)='$LD -Bshareable -o $lib $libobjs $deplibs $linker_flags /usr/lib/c++rt0.o'\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-R$libdir'\n      _LT_TAGVAR(hardcode_direct, $1)=yes\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      ;;\n\n    # Unfortunately, older versions of FreeBSD 2 do not have this feature.\n    freebsd2.*)\n      _LT_TAGVAR(archive_cmds, $1)='$LD -Bshareable -o $lib $libobjs $deplibs $linker_flags'\n      _LT_TAGVAR(hardcode_direct, $1)=yes\n      _LT_TAGVAR(hardcode_minus_L, $1)=yes\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      ;;\n\n    # FreeBSD 3 and greater uses gcc -shared to do shared libraries.\n    freebsd* | dragonfly*)\n      _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag -o $lib $libobjs $deplibs $compiler_flags'\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-R$libdir'\n      _LT_TAGVAR(hardcode_direct, $1)=yes\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      ;;\n\n    hpux9*)\n      if test yes = \"$GCC\"; then\n\t_LT_TAGVAR(archive_cmds, $1)='$RM $output_objdir/$soname~$CC -shared $pic_flag $wl+b $wl$install_libdir -o $output_objdir/$soname $libobjs $deplibs $compiler_flags~test \"x$output_objdir/$soname\" = \"x$lib\" || mv $output_objdir/$soname $lib'\n      else\n\t_LT_TAGVAR(archive_cmds, $1)='$RM $output_objdir/$soname~$LD -b +b $install_libdir -o $output_objdir/$soname $libobjs $deplibs $linker_flags~test \"x$output_objdir/$soname\" = \"x$lib\" || mv $output_objdir/$soname $lib'\n      fi\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl+b $wl$libdir'\n      _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n      _LT_TAGVAR(hardcode_direct, $1)=yes\n\n      # hardcode_minus_L: Not really in the search PATH,\n      # but as the default location of the library.\n      _LT_TAGVAR(hardcode_minus_L, $1)=yes\n      _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-E'\n      ;;\n\n    hpux10*)\n      if test yes,no = \"$GCC,$with_gnu_ld\"; then\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $wl+h $wl$soname $wl+b $wl$install_libdir -o $lib $libobjs $deplibs $compiler_flags'\n      else\n\t_LT_TAGVAR(archive_cmds, $1)='$LD -b +h $soname +b $install_libdir -o $lib $libobjs $deplibs $linker_flags'\n      fi\n      if test no = \"$with_gnu_ld\"; then\n\t_LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl+b $wl$libdir'\n\t_LT_TAGVAR(hardcode_libdir_separator, $1)=:\n\t_LT_TAGVAR(hardcode_direct, $1)=yes\n\t_LT_TAGVAR(hardcode_direct_absolute, $1)=yes\n\t_LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-E'\n\t# hardcode_minus_L: Not really in the search PATH,\n\t# but as the default location of the library.\n\t_LT_TAGVAR(hardcode_minus_L, $1)=yes\n      fi\n      ;;\n\n    hpux11*)\n      if test yes,no = \"$GCC,$with_gnu_ld\"; then\n\tcase $host_cpu in\n\thppa*64*)\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -shared $wl+h $wl$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t  ;;\n\tia64*)\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $wl+h $wl$soname $wl+nodefaultrpath -o $lib $libobjs $deplibs $compiler_flags'\n\t  ;;\n\t*)\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $wl+h $wl$soname $wl+b $wl$install_libdir -o $lib $libobjs $deplibs $compiler_flags'\n\t  ;;\n\tesac\n      else\n\tcase $host_cpu in\n\thppa*64*)\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -b $wl+h $wl$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t  ;;\n\tia64*)\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -b $wl+h $wl$soname $wl+nodefaultrpath -o $lib $libobjs $deplibs $compiler_flags'\n\t  ;;\n\t*)\n\tm4_if($1, [], [\n\t  # Older versions of the 11.00 compiler do not understand -b yet\n\t  # (HP92453-01 A.11.01.20 doesn't, HP92453-01 B.11.X.35175-35176.GP does)\n\t  _LT_LINKER_OPTION([if $CC understands -b],\n\t    _LT_TAGVAR(lt_cv_prog_compiler__b, $1), [-b],\n\t    [_LT_TAGVAR(archive_cmds, $1)='$CC -b $wl+h $wl$soname $wl+b $wl$install_libdir -o $lib $libobjs $deplibs $compiler_flags'],\n\t    [_LT_TAGVAR(archive_cmds, $1)='$LD -b +h $soname +b $install_libdir -o $lib $libobjs $deplibs $linker_flags'])],\n\t  [_LT_TAGVAR(archive_cmds, $1)='$CC -b $wl+h $wl$soname $wl+b $wl$install_libdir -o $lib $libobjs $deplibs $compiler_flags'])\n\t  ;;\n\tesac\n      fi\n      if test no = \"$with_gnu_ld\"; then\n\t_LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl+b $wl$libdir'\n\t_LT_TAGVAR(hardcode_libdir_separator, $1)=:\n\n\tcase $host_cpu in\n\thppa*64*|ia64*)\n\t  _LT_TAGVAR(hardcode_direct, $1)=no\n\t  _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n\t  ;;\n\t*)\n\t  _LT_TAGVAR(hardcode_direct, $1)=yes\n\t  _LT_TAGVAR(hardcode_direct_absolute, $1)=yes\n\t  _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-E'\n\n\t  # hardcode_minus_L: Not really in the search PATH,\n\t  # but as the default location of the library.\n\t  _LT_TAGVAR(hardcode_minus_L, $1)=yes\n\t  ;;\n\tesac\n      fi\n      ;;\n\n    irix5* | irix6* | nonstopux*)\n      if test yes = \"$GCC\"; then\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-soname $wl$soname `test -n \"$verstring\" && func_echo_all \"$wl-set_version $wl$verstring\"` $wl-update_registry $wl$output_objdir/so_locations -o $lib'\n\t# Try to use the -exported_symbol ld option, if it does not\n\t# work, assume that -exports_file does not work either and\n\t# implicitly export all symbols.\n\t# This should be the same for all languages, so no per-tag cache variable.\n\tAC_CACHE_CHECK([whether the $host_os linker accepts -exported_symbol],\n\t  [lt_cv_irix_exported_symbol],\n\t  [save_LDFLAGS=$LDFLAGS\n\t   LDFLAGS=\"$LDFLAGS -shared $wl-exported_symbol ${wl}foo $wl-update_registry $wl/dev/null\"\n\t   AC_LINK_IFELSE(\n\t     [AC_LANG_SOURCE(\n\t        [AC_LANG_CASE([C], [[int foo (void) { return 0; }]],\n\t\t\t      [C++], [[int foo (void) { return 0; }]],\n\t\t\t      [Fortran 77], [[\n      subroutine foo\n      end]],\n\t\t\t      [Fortran], [[\n      subroutine foo\n      end]])])],\n\t      [lt_cv_irix_exported_symbol=yes],\n\t      [lt_cv_irix_exported_symbol=no])\n           LDFLAGS=$save_LDFLAGS])\n\tif test yes = \"$lt_cv_irix_exported_symbol\"; then\n          _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-soname $wl$soname `test -n \"$verstring\" && func_echo_all \"$wl-set_version $wl$verstring\"` $wl-update_registry $wl$output_objdir/so_locations $wl-exports_file $wl$export_symbols -o $lib'\n\tfi\n      else\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared $libobjs $deplibs $compiler_flags -soname $soname `test -n \"$verstring\" && func_echo_all \"-set_version $verstring\"` -update_registry $output_objdir/so_locations -o $lib'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $libobjs $deplibs $compiler_flags -soname $soname `test -n \"$verstring\" && func_echo_all \"-set_version $verstring\"` -update_registry $output_objdir/so_locations -exports_file $export_symbols -o $lib'\n      fi\n      _LT_TAGVAR(archive_cmds_need_lc, $1)='no'\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n      _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n      _LT_TAGVAR(inherit_rpath, $1)=yes\n      _LT_TAGVAR(link_all_deplibs, $1)=yes\n      ;;\n\n    linux*)\n      case $cc_basename in\n      tcc*)\n\t# Fabrice Bellard et al's Tiny C Compiler\n\t_LT_TAGVAR(ld_shlibs, $1)=yes\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag -o $lib $libobjs $deplibs $compiler_flags'\n\t;;\n      esac\n      ;;\n\n    netbsd*)\n      if echo __ELF__ | $CC -E - | $GREP __ELF__ >/dev/null; then\n\t_LT_TAGVAR(archive_cmds, $1)='$LD -Bshareable -o $lib $libobjs $deplibs $linker_flags'  # a.out\n      else\n\t_LT_TAGVAR(archive_cmds, $1)='$LD -shared -o $lib $libobjs $deplibs $linker_flags'      # ELF\n      fi\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-R$libdir'\n      _LT_TAGVAR(hardcode_direct, $1)=yes\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      ;;\n\n    newsos6)\n      _LT_TAGVAR(archive_cmds, $1)='$LD -G -h $soname -o $lib $libobjs $deplibs $linker_flags'\n      _LT_TAGVAR(hardcode_direct, $1)=yes\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n      _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      ;;\n\n    *nto* | *qnx*)\n      ;;\n\n    openbsd* | bitrig*)\n      if test -f /usr/libexec/ld.so; then\n\t_LT_TAGVAR(hardcode_direct, $1)=yes\n\t_LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n\t_LT_TAGVAR(hardcode_direct_absolute, $1)=yes\n\tif test -z \"`echo __ELF__ | $CC -E - | $GREP __ELF__`\"; then\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag -o $lib $libobjs $deplibs $compiler_flags'\n\t  _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $pic_flag -o $lib $libobjs $deplibs $compiler_flags $wl-retain-symbols-file,$export_symbols'\n\t  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath,$libdir'\n\t  _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-E'\n\telse\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag -o $lib $libobjs $deplibs $compiler_flags'\n\t  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath,$libdir'\n\tfi\n      else\n\t_LT_TAGVAR(ld_shlibs, $1)=no\n      fi\n      ;;\n\n    os2*)\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n      _LT_TAGVAR(hardcode_minus_L, $1)=yes\n      _LT_TAGVAR(allow_undefined_flag, $1)=unsupported\n      shrext_cmds=.dll\n      _LT_TAGVAR(archive_cmds, $1)='$ECHO \"LIBRARY ${soname%$shared_ext} INITINSTANCE TERMINSTANCE\" > $output_objdir/$libname.def~\n\t$ECHO \"DESCRIPTION \\\"$libname\\\"\" >> $output_objdir/$libname.def~\n\t$ECHO \"DATA MULTIPLE NONSHARED\" >> $output_objdir/$libname.def~\n\t$ECHO EXPORTS >> $output_objdir/$libname.def~\n\temxexp $libobjs | $SED /\"_DLL_InitTerm\"/d >> $output_objdir/$libname.def~\n\t$CC -Zdll -Zcrtdll -o $output_objdir/$soname $libobjs $deplibs $compiler_flags $output_objdir/$libname.def~\n\temximp -o $lib $output_objdir/$libname.def'\n      _LT_TAGVAR(archive_expsym_cmds, $1)='$ECHO \"LIBRARY ${soname%$shared_ext} INITINSTANCE TERMINSTANCE\" > $output_objdir/$libname.def~\n\t$ECHO \"DESCRIPTION \\\"$libname\\\"\" >> $output_objdir/$libname.def~\n\t$ECHO \"DATA MULTIPLE NONSHARED\" >> $output_objdir/$libname.def~\n\t$ECHO EXPORTS >> $output_objdir/$libname.def~\n\tprefix_cmds=\"$SED\"~\n\tif test EXPORTS = \"`$SED 1q $export_symbols`\"; then\n\t  prefix_cmds=\"$prefix_cmds -e 1d\";\n\tfi~\n\tprefix_cmds=\"$prefix_cmds -e \\\"s/^\\(.*\\)$/_\\1/g\\\"\"~\n\tcat $export_symbols | $prefix_cmds >> $output_objdir/$libname.def~\n\t$CC -Zdll -Zcrtdll -o $output_objdir/$soname $libobjs $deplibs $compiler_flags $output_objdir/$libname.def~\n\temximp -o $lib $output_objdir/$libname.def'\n      _LT_TAGVAR(old_archive_From_new_cmds, $1)='emximp -o $output_objdir/${libname}_dll.a $output_objdir/$libname.def'\n      _LT_TAGVAR(enable_shared_with_static_runtimes, $1)=yes\n      ;;\n\n    osf3*)\n      if test yes = \"$GCC\"; then\n\t_LT_TAGVAR(allow_undefined_flag, $1)=' $wl-expect_unresolved $wl\\*'\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared$allow_undefined_flag $libobjs $deplibs $compiler_flags $wl-soname $wl$soname `test -n \"$verstring\" && func_echo_all \"$wl-set_version $wl$verstring\"` $wl-update_registry $wl$output_objdir/so_locations -o $lib'\n      else\n\t_LT_TAGVAR(allow_undefined_flag, $1)=' -expect_unresolved \\*'\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared$allow_undefined_flag $libobjs $deplibs $compiler_flags -soname $soname `test -n \"$verstring\" && func_echo_all \"-set_version $verstring\"` -update_registry $output_objdir/so_locations -o $lib'\n      fi\n      _LT_TAGVAR(archive_cmds_need_lc, $1)='no'\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n      _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n      ;;\n\n    osf4* | osf5*)\t# as osf3* with the addition of -msym flag\n      if test yes = \"$GCC\"; then\n\t_LT_TAGVAR(allow_undefined_flag, $1)=' $wl-expect_unresolved $wl\\*'\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared$allow_undefined_flag $pic_flag $libobjs $deplibs $compiler_flags $wl-msym $wl-soname $wl$soname `test -n \"$verstring\" && func_echo_all \"$wl-set_version $wl$verstring\"` $wl-update_registry $wl$output_objdir/so_locations -o $lib'\n\t_LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n      else\n\t_LT_TAGVAR(allow_undefined_flag, $1)=' -expect_unresolved \\*'\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared$allow_undefined_flag $libobjs $deplibs $compiler_flags -msym -soname $soname `test -n \"$verstring\" && func_echo_all \"-set_version $verstring\"` -update_registry $output_objdir/so_locations -o $lib'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='for i in `cat $export_symbols`; do printf \"%s %s\\\\n\" -exported_symbol \"\\$i\" >> $lib.exp; done; printf \"%s\\\\n\" \"-hidden\">> $lib.exp~\n          $CC -shared$allow_undefined_flag $wl-input $wl$lib.exp $compiler_flags $libobjs $deplibs -soname $soname `test -n \"$verstring\" && $ECHO \"-set_version $verstring\"` -update_registry $output_objdir/so_locations -o $lib~$RM $lib.exp'\n\n\t# Both c and cxx compiler support -rpath directly\n\t_LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-rpath $libdir'\n      fi\n      _LT_TAGVAR(archive_cmds_need_lc, $1)='no'\n      _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n      ;;\n\n    solaris*)\n      _LT_TAGVAR(no_undefined_flag, $1)=' -z defs'\n      if test yes = \"$GCC\"; then\n\twlarc='$wl'\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $wl-z ${wl}text $wl-h $wl$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='echo \"{ global:\" > $lib.exp~cat $export_symbols | $SED -e \"s/\\(.*\\)/\\1;/\" >> $lib.exp~echo \"local: *; };\" >> $lib.exp~\n          $CC -shared $pic_flag $wl-z ${wl}text $wl-M $wl$lib.exp $wl-h $wl$soname -o $lib $libobjs $deplibs $compiler_flags~$RM $lib.exp'\n      else\n\tcase `$CC -V 2>&1` in\n\t*\"Compilers 5.0\"*)\n\t  wlarc=''\n\t  _LT_TAGVAR(archive_cmds, $1)='$LD -G$allow_undefined_flag -h $soname -o $lib $libobjs $deplibs $linker_flags'\n\t  _LT_TAGVAR(archive_expsym_cmds, $1)='echo \"{ global:\" > $lib.exp~cat $export_symbols | $SED -e \"s/\\(.*\\)/\\1;/\" >> $lib.exp~echo \"local: *; };\" >> $lib.exp~\n            $LD -G$allow_undefined_flag -M $lib.exp -h $soname -o $lib $libobjs $deplibs $linker_flags~$RM $lib.exp'\n\t  ;;\n\t*)\n\t  wlarc='$wl'\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -G$allow_undefined_flag -h $soname -o $lib $libobjs $deplibs $compiler_flags'\n\t  _LT_TAGVAR(archive_expsym_cmds, $1)='echo \"{ global:\" > $lib.exp~cat $export_symbols | $SED -e \"s/\\(.*\\)/\\1;/\" >> $lib.exp~echo \"local: *; };\" >> $lib.exp~\n            $CC -G$allow_undefined_flag -M $lib.exp -h $soname -o $lib $libobjs $deplibs $compiler_flags~$RM $lib.exp'\n\t  ;;\n\tesac\n      fi\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-R$libdir'\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      case $host_os in\n      solaris2.[[0-5]] | solaris2.[[0-5]].*) ;;\n      *)\n\t# The compiler driver will combine and reorder linker options,\n\t# but understands '-z linker_flag'.  GCC discards it without '$wl',\n\t# but is careful enough not to reorder.\n\t# Supported since Solaris 2.6 (maybe 2.5.1?)\n\tif test yes = \"$GCC\"; then\n\t  _LT_TAGVAR(whole_archive_flag_spec, $1)='$wl-z ${wl}allextract$convenience $wl-z ${wl}defaultextract'\n\telse\n\t  _LT_TAGVAR(whole_archive_flag_spec, $1)='-z allextract$convenience -z defaultextract'\n\tfi\n\t;;\n      esac\n      _LT_TAGVAR(link_all_deplibs, $1)=yes\n      ;;\n\n    sunos4*)\n      if test sequent = \"$host_vendor\"; then\n\t# Use $CC to link under sequent, because it throws in some extra .o\n\t# files that make .init and .fini sections work.\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -G $wl-h $soname -o $lib $libobjs $deplibs $compiler_flags'\n      else\n\t_LT_TAGVAR(archive_cmds, $1)='$LD -assert pure-text -Bstatic -o $lib $libobjs $deplibs $linker_flags'\n      fi\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n      _LT_TAGVAR(hardcode_direct, $1)=yes\n      _LT_TAGVAR(hardcode_minus_L, $1)=yes\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      ;;\n\n    sysv4)\n      case $host_vendor in\n\tsni)\n\t  _LT_TAGVAR(archive_cmds, $1)='$LD -G -h $soname -o $lib $libobjs $deplibs $linker_flags'\n\t  _LT_TAGVAR(hardcode_direct, $1)=yes # is this really true???\n\t;;\n\tsiemens)\n\t  ## LD is ld it makes a PLAMLIB\n\t  ## CC just makes a GrossModule.\n\t  _LT_TAGVAR(archive_cmds, $1)='$LD -G -o $lib $libobjs $deplibs $linker_flags'\n\t  _LT_TAGVAR(reload_cmds, $1)='$CC -r -o $output$reload_objs'\n\t  _LT_TAGVAR(hardcode_direct, $1)=no\n        ;;\n\tmotorola)\n\t  _LT_TAGVAR(archive_cmds, $1)='$LD -G -h $soname -o $lib $libobjs $deplibs $linker_flags'\n\t  _LT_TAGVAR(hardcode_direct, $1)=no #Motorola manual says yes, but my tests say they lie\n\t;;\n      esac\n      runpath_var='LD_RUN_PATH'\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      ;;\n\n    sysv4.3*)\n      _LT_TAGVAR(archive_cmds, $1)='$LD -G -h $soname -o $lib $libobjs $deplibs $linker_flags'\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      _LT_TAGVAR(export_dynamic_flag_spec, $1)='-Bexport'\n      ;;\n\n    sysv4*MP*)\n      if test -d /usr/nec; then\n\t_LT_TAGVAR(archive_cmds, $1)='$LD -G -h $soname -o $lib $libobjs $deplibs $linker_flags'\n\t_LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n\trunpath_var=LD_RUN_PATH\n\thardcode_runpath_var=yes\n\t_LT_TAGVAR(ld_shlibs, $1)=yes\n      fi\n      ;;\n\n    sysv4*uw2* | sysv5OpenUNIX* | sysv5UnixWare7.[[01]].[[10]]* | unixware7* | sco3.2v5.0.[[024]]*)\n      _LT_TAGVAR(no_undefined_flag, $1)='$wl-z,text'\n      _LT_TAGVAR(archive_cmds_need_lc, $1)=no\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      runpath_var='LD_RUN_PATH'\n\n      if test yes = \"$GCC\"; then\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $wl-Bexport:$export_symbols $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n      else\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -G $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='$CC -G $wl-Bexport:$export_symbols $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n      fi\n      ;;\n\n    sysv5* | sco3.2v5* | sco5v6*)\n      # Note: We CANNOT use -z defs as we might desire, because we do not\n      # link with -lc, and that would cause any symbols used from libc to\n      # always be unresolved, which means just about no library would\n      # ever link correctly.  If we're not using GNU ld we use -z text\n      # though, which does catch some bad symbols but isn't as heavy-handed\n      # as -z defs.\n      _LT_TAGVAR(no_undefined_flag, $1)='$wl-z,text'\n      _LT_TAGVAR(allow_undefined_flag, $1)='$wl-z,nodefs'\n      _LT_TAGVAR(archive_cmds_need_lc, $1)=no\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-R,$libdir'\n      _LT_TAGVAR(hardcode_libdir_separator, $1)=':'\n      _LT_TAGVAR(link_all_deplibs, $1)=yes\n      _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-Bexport'\n      runpath_var='LD_RUN_PATH'\n\n      if test yes = \"$GCC\"; then\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $wl-Bexport:$export_symbols $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n      else\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -G $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='$CC -G $wl-Bexport:$export_symbols $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n      fi\n      ;;\n\n    uts4*)\n      _LT_TAGVAR(archive_cmds, $1)='$LD -G -h $soname -o $lib $libobjs $deplibs $linker_flags'\n      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      ;;\n\n    *)\n      _LT_TAGVAR(ld_shlibs, $1)=no\n      ;;\n    esac\n\n    if test sni = \"$host_vendor\"; then\n      case $host in\n      sysv4 | sysv4.2uw2* | sysv4.3* | sysv5*)\n\t_LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-Blargedynsym'\n\t;;\n      esac\n    fi\n  fi\n])\nAC_MSG_RESULT([$_LT_TAGVAR(ld_shlibs, $1)])\ntest no = \"$_LT_TAGVAR(ld_shlibs, $1)\" && can_build_shared=no\n\n_LT_TAGVAR(with_gnu_ld, $1)=$with_gnu_ld\n\n_LT_DECL([], [libext], [0], [Old archive suffix (normally \"a\")])dnl\n_LT_DECL([], [shrext_cmds], [1], [Shared library suffix (normally \".so\")])dnl\n_LT_DECL([], [extract_expsyms_cmds], [2],\n    [The commands to extract the exported symbol list from a shared archive])\n\n#\n# Do we need to explicitly link libc?\n#\ncase \"x$_LT_TAGVAR(archive_cmds_need_lc, $1)\" in\nx|xyes)\n  # Assume -lc should be added\n  _LT_TAGVAR(archive_cmds_need_lc, $1)=yes\n\n  if test yes,yes = \"$GCC,$enable_shared\"; then\n    case $_LT_TAGVAR(archive_cmds, $1) in\n    *'~'*)\n      # FIXME: we may have to deal with multi-command sequences.\n      ;;\n    '$CC '*)\n      # Test whether the compiler implicitly links with -lc since on some\n      # systems, -lgcc has to come before -lc. If gcc already passes -lc\n      # to ld, don't add -lc before -lgcc.\n      AC_CACHE_CHECK([whether -lc should be explicitly linked in],\n\t[lt_cv_]_LT_TAGVAR(archive_cmds_need_lc, $1),\n\t[$RM conftest*\n\techo \"$lt_simple_compile_test_code\" > conftest.$ac_ext\n\n\tif AC_TRY_EVAL(ac_compile) 2>conftest.err; then\n\t  soname=conftest\n\t  lib=conftest\n\t  libobjs=conftest.$ac_objext\n\t  deplibs=\n\t  wl=$_LT_TAGVAR(lt_prog_compiler_wl, $1)\n\t  pic_flag=$_LT_TAGVAR(lt_prog_compiler_pic, $1)\n\t  compiler_flags=-v\n\t  linker_flags=-v\n\t  verstring=\n\t  output_objdir=.\n\t  libname=conftest\n\t  lt_save_allow_undefined_flag=$_LT_TAGVAR(allow_undefined_flag, $1)\n\t  _LT_TAGVAR(allow_undefined_flag, $1)=\n\t  if AC_TRY_EVAL(_LT_TAGVAR(archive_cmds, $1) 2\\>\\&1 \\| $GREP \\\" -lc \\\" \\>/dev/null 2\\>\\&1)\n\t  then\n\t    lt_cv_[]_LT_TAGVAR(archive_cmds_need_lc, $1)=no\n\t  else\n\t    lt_cv_[]_LT_TAGVAR(archive_cmds_need_lc, $1)=yes\n\t  fi\n\t  _LT_TAGVAR(allow_undefined_flag, $1)=$lt_save_allow_undefined_flag\n\telse\n\t  cat conftest.err 1>&5\n\tfi\n\t$RM conftest*\n\t])\n      _LT_TAGVAR(archive_cmds_need_lc, $1)=$lt_cv_[]_LT_TAGVAR(archive_cmds_need_lc, $1)\n      ;;\n    esac\n  fi\n  ;;\nesac\n\n_LT_TAGDECL([build_libtool_need_lc], [archive_cmds_need_lc], [0],\n    [Whether or not to add -lc for building shared libraries])\n_LT_TAGDECL([allow_libtool_libs_with_static_runtimes],\n    [enable_shared_with_static_runtimes], [0],\n    [Whether or not to disallow shared libs when runtime libs are static])\n_LT_TAGDECL([], [export_dynamic_flag_spec], [1],\n    [Compiler flag to allow reflexive dlopens])\n_LT_TAGDECL([], [whole_archive_flag_spec], [1],\n    [Compiler flag to generate shared objects directly from archives])\n_LT_TAGDECL([], [compiler_needs_object], [1],\n    [Whether the compiler copes with passing no objects directly])\n_LT_TAGDECL([], [old_archive_from_new_cmds], [2],\n    [Create an old-style archive from a shared archive])\n_LT_TAGDECL([], [old_archive_from_expsyms_cmds], [2],\n    [Create a temporary old-style archive to link instead of a shared archive])\n_LT_TAGDECL([], [archive_cmds], [2], [Commands used to build a shared archive])\n_LT_TAGDECL([], [archive_expsym_cmds], [2])\n_LT_TAGDECL([], [module_cmds], [2],\n    [Commands used to build a loadable module if different from building\n    a shared archive.])\n_LT_TAGDECL([], [module_expsym_cmds], [2])\n_LT_TAGDECL([], [with_gnu_ld], [1],\n    [Whether we are building with GNU ld or not])\n_LT_TAGDECL([], [allow_undefined_flag], [1],\n    [Flag that allows shared libraries with undefined symbols to be built])\n_LT_TAGDECL([], [no_undefined_flag], [1],\n    [Flag that enforces no undefined symbols])\n_LT_TAGDECL([], [hardcode_libdir_flag_spec], [1],\n    [Flag to hardcode $libdir into a binary during linking.\n    This must work even if $libdir does not exist])\n_LT_TAGDECL([], [hardcode_libdir_separator], [1],\n    [Whether we need a single \"-rpath\" flag with a separated argument])\n_LT_TAGDECL([], [hardcode_direct], [0],\n    [Set to \"yes\" if using DIR/libNAME$shared_ext during linking hardcodes\n    DIR into the resulting binary])\n_LT_TAGDECL([], [hardcode_direct_absolute], [0],\n    [Set to \"yes\" if using DIR/libNAME$shared_ext during linking hardcodes\n    DIR into the resulting binary and the resulting library dependency is\n    \"absolute\", i.e impossible to change by setting $shlibpath_var if the\n    library is relocated])\n_LT_TAGDECL([], [hardcode_minus_L], [0],\n    [Set to \"yes\" if using the -LDIR flag during linking hardcodes DIR\n    into the resulting binary])\n_LT_TAGDECL([], [hardcode_shlibpath_var], [0],\n    [Set to \"yes\" if using SHLIBPATH_VAR=DIR during linking hardcodes DIR\n    into the resulting binary])\n_LT_TAGDECL([], [hardcode_automatic], [0],\n    [Set to \"yes\" if building a shared library automatically hardcodes DIR\n    into the library and all subsequent libraries and executables linked\n    against it])\n_LT_TAGDECL([], [inherit_rpath], [0],\n    [Set to yes if linker adds runtime paths of dependent libraries\n    to runtime path list])\n_LT_TAGDECL([], [link_all_deplibs], [0],\n    [Whether libtool must link a program against all its dependency libraries])\n_LT_TAGDECL([], [always_export_symbols], [0],\n    [Set to \"yes\" if exported symbols are required])\n_LT_TAGDECL([], [export_symbols_cmds], [2],\n    [The commands to list exported symbols])\n_LT_TAGDECL([], [exclude_expsyms], [1],\n    [Symbols that should not be listed in the preloaded symbols])\n_LT_TAGDECL([], [include_expsyms], [1],\n    [Symbols that must always be exported])\n_LT_TAGDECL([], [prelink_cmds], [2],\n    [Commands necessary for linking programs (against libraries) with templates])\n_LT_TAGDECL([], [postlink_cmds], [2],\n    [Commands necessary for finishing linking programs])\n_LT_TAGDECL([], [file_list_spec], [1],\n    [Specify filename containing input files])\ndnl FIXME: Not yet implemented\ndnl _LT_TAGDECL([], [thread_safe_flag_spec], [1],\ndnl    [Compiler flag to generate thread safe objects])\n])# _LT_LINKER_SHLIBS\n\n\n# _LT_LANG_C_CONFIG([TAG])\n# ------------------------\n# Ensure that the configuration variables for a C compiler are suitably\n# defined.  These variables are subsequently used by _LT_CONFIG to write\n# the compiler configuration to 'libtool'.\nm4_defun([_LT_LANG_C_CONFIG],\n[m4_require([_LT_DECL_EGREP])dnl\nlt_save_CC=$CC\nAC_LANG_PUSH(C)\n\n# Source file extension for C test sources.\nac_ext=c\n\n# Object file extension for compiled C test sources.\nobjext=o\n_LT_TAGVAR(objext, $1)=$objext\n\n# Code to be used in simple compile tests\nlt_simple_compile_test_code=\"int some_variable = 0;\"\n\n# Code to be used in simple link tests\nlt_simple_link_test_code='int main(){return(0);}'\n\n_LT_TAG_COMPILER\n# Save the default compiler, since it gets overwritten when the other\n# tags are being tested, and _LT_TAGVAR(compiler, []) is a NOP.\ncompiler_DEFAULT=$CC\n\n# save warnings/boilerplate of simple test code\n_LT_COMPILER_BOILERPLATE\n_LT_LINKER_BOILERPLATE\n\n## CAVEAT EMPTOR:\n## There is no encapsulation within the following macros, do not change\n## the running order or otherwise move them around unless you know exactly\n## what you are doing...\nif test -n \"$compiler\"; then\n  _LT_COMPILER_NO_RTTI($1)\n  _LT_COMPILER_PIC($1)\n  _LT_COMPILER_C_O($1)\n  _LT_COMPILER_FILE_LOCKS($1)\n  _LT_LINKER_SHLIBS($1)\n  _LT_SYS_DYNAMIC_LINKER($1)\n  _LT_LINKER_HARDCODE_LIBPATH($1)\n  LT_SYS_DLOPEN_SELF\n  _LT_CMD_STRIPLIB\n\n  # Report what library types will actually be built\n  AC_MSG_CHECKING([if libtool supports shared libraries])\n  AC_MSG_RESULT([$can_build_shared])\n\n  AC_MSG_CHECKING([whether to build shared libraries])\n  test no = \"$can_build_shared\" && enable_shared=no\n\n  # On AIX, shared libraries and static libraries use the same namespace, and\n  # are all built from PIC.\n  case $host_os in\n  aix3*)\n    test yes = \"$enable_shared\" && enable_static=no\n    if test -n \"$RANLIB\"; then\n      archive_cmds=\"$archive_cmds~\\$RANLIB \\$lib\"\n      postinstall_cmds='$RANLIB $lib'\n    fi\n    ;;\n\n  aix[[4-9]]*)\n    if test ia64 != \"$host_cpu\"; then\n      case $enable_shared,$with_aix_soname,$aix_use_runtimelinking in\n      yes,aix,yes) ;;\t\t\t# shared object as lib.so file only\n      yes,svr4,*) ;;\t\t\t# shared object as lib.so archive member only\n      yes,*) enable_static=no ;;\t# shared object in lib.a archive as well\n      esac\n    fi\n    ;;\n  esac\n  AC_MSG_RESULT([$enable_shared])\n\n  AC_MSG_CHECKING([whether to build static libraries])\n  # Make sure either enable_shared or enable_static is yes.\n  test yes = \"$enable_shared\" || enable_static=yes\n  AC_MSG_RESULT([$enable_static])\n\n  _LT_CONFIG($1)\nfi\nAC_LANG_POP\nCC=$lt_save_CC\n])# _LT_LANG_C_CONFIG\n\n\n# _LT_LANG_CXX_CONFIG([TAG])\n# --------------------------\n# Ensure that the configuration variables for a C++ compiler are suitably\n# defined.  These variables are subsequently used by _LT_CONFIG to write\n# the compiler configuration to 'libtool'.\nm4_defun([_LT_LANG_CXX_CONFIG],\n[m4_require([_LT_FILEUTILS_DEFAULTS])dnl\nm4_require([_LT_DECL_EGREP])dnl\nm4_require([_LT_PATH_MANIFEST_TOOL])dnl\nif test -n \"$CXX\" && ( test no != \"$CXX\" &&\n    ( (test g++ = \"$CXX\" && `g++ -v >/dev/null 2>&1` ) ||\n    (test g++ != \"$CXX\"))); then\n  AC_PROG_CXXCPP\nelse\n  _lt_caught_CXX_error=yes\nfi\n\nAC_LANG_PUSH(C++)\n_LT_TAGVAR(archive_cmds_need_lc, $1)=no\n_LT_TAGVAR(allow_undefined_flag, $1)=\n_LT_TAGVAR(always_export_symbols, $1)=no\n_LT_TAGVAR(archive_expsym_cmds, $1)=\n_LT_TAGVAR(compiler_needs_object, $1)=no\n_LT_TAGVAR(export_dynamic_flag_spec, $1)=\n_LT_TAGVAR(hardcode_direct, $1)=no\n_LT_TAGVAR(hardcode_direct_absolute, $1)=no\n_LT_TAGVAR(hardcode_libdir_flag_spec, $1)=\n_LT_TAGVAR(hardcode_libdir_separator, $1)=\n_LT_TAGVAR(hardcode_minus_L, $1)=no\n_LT_TAGVAR(hardcode_shlibpath_var, $1)=unsupported\n_LT_TAGVAR(hardcode_automatic, $1)=no\n_LT_TAGVAR(inherit_rpath, $1)=no\n_LT_TAGVAR(module_cmds, $1)=\n_LT_TAGVAR(module_expsym_cmds, $1)=\n_LT_TAGVAR(link_all_deplibs, $1)=unknown\n_LT_TAGVAR(old_archive_cmds, $1)=$old_archive_cmds\n_LT_TAGVAR(reload_flag, $1)=$reload_flag\n_LT_TAGVAR(reload_cmds, $1)=$reload_cmds\n_LT_TAGVAR(no_undefined_flag, $1)=\n_LT_TAGVAR(whole_archive_flag_spec, $1)=\n_LT_TAGVAR(enable_shared_with_static_runtimes, $1)=no\n\n# Source file extension for C++ test sources.\nac_ext=cpp\n\n# Object file extension for compiled C++ test sources.\nobjext=o\n_LT_TAGVAR(objext, $1)=$objext\n\n# No sense in running all these tests if we already determined that\n# the CXX compiler isn't working.  Some variables (like enable_shared)\n# are currently assumed to apply to all compilers on this platform,\n# and will be corrupted by setting them based on a non-working compiler.\nif test yes != \"$_lt_caught_CXX_error\"; then\n  # Code to be used in simple compile tests\n  lt_simple_compile_test_code=\"int some_variable = 0;\"\n\n  # Code to be used in simple link tests\n  lt_simple_link_test_code='int main(int, char *[[]]) { return(0); }'\n\n  # ltmain only uses $CC for tagged configurations so make sure $CC is set.\n  _LT_TAG_COMPILER\n\n  # save warnings/boilerplate of simple test code\n  _LT_COMPILER_BOILERPLATE\n  _LT_LINKER_BOILERPLATE\n\n  # Allow CC to be a program name with arguments.\n  lt_save_CC=$CC\n  lt_save_CFLAGS=$CFLAGS\n  lt_save_LD=$LD\n  lt_save_GCC=$GCC\n  GCC=$GXX\n  lt_save_with_gnu_ld=$with_gnu_ld\n  lt_save_path_LD=$lt_cv_path_LD\n  if test -n \"${lt_cv_prog_gnu_ldcxx+set}\"; then\n    lt_cv_prog_gnu_ld=$lt_cv_prog_gnu_ldcxx\n  else\n    $as_unset lt_cv_prog_gnu_ld\n  fi\n  if test -n \"${lt_cv_path_LDCXX+set}\"; then\n    lt_cv_path_LD=$lt_cv_path_LDCXX\n  else\n    $as_unset lt_cv_path_LD\n  fi\n  test -z \"${LDCXX+set}\" || LD=$LDCXX\n  CC=${CXX-\"c++\"}\n  CFLAGS=$CXXFLAGS\n  compiler=$CC\n  _LT_TAGVAR(compiler, $1)=$CC\n  _LT_CC_BASENAME([$compiler])\n\n  if test -n \"$compiler\"; then\n    # We don't want -fno-exception when compiling C++ code, so set the\n    # no_builtin_flag separately\n    if test yes = \"$GXX\"; then\n      _LT_TAGVAR(lt_prog_compiler_no_builtin_flag, $1)=' -fno-builtin'\n    else\n      _LT_TAGVAR(lt_prog_compiler_no_builtin_flag, $1)=\n    fi\n\n    if test yes = \"$GXX\"; then\n      # Set up default GNU C++ configuration\n\n      LT_PATH_LD\n\n      # Check if GNU C++ uses GNU ld as the underlying linker, since the\n      # archiving commands below assume that GNU ld is being used.\n      if test yes = \"$with_gnu_ld\"; then\n        _LT_TAGVAR(archive_cmds, $1)='$CC $pic_flag -shared -nostdlib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname -o $lib'\n        _LT_TAGVAR(archive_expsym_cmds, $1)='$CC $pic_flag -shared -nostdlib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname $wl-retain-symbols-file $wl$export_symbols -o $lib'\n\n        _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n        _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl--export-dynamic'\n\n        # If archive_cmds runs LD, not CC, wlarc should be empty\n        # XXX I think wlarc can be eliminated in ltcf-cxx, but I need to\n        #     investigate it a little bit more. (MM)\n        wlarc='$wl'\n\n        # ancient GNU ld didn't support --whole-archive et. al.\n        if eval \"`$CC -print-prog-name=ld` --help 2>&1\" |\n\t  $GREP 'no-whole-archive' > /dev/null; then\n          _LT_TAGVAR(whole_archive_flag_spec, $1)=$wlarc'--whole-archive$convenience '$wlarc'--no-whole-archive'\n        else\n          _LT_TAGVAR(whole_archive_flag_spec, $1)=\n        fi\n      else\n        with_gnu_ld=no\n        wlarc=\n\n        # A generic and very simple default shared library creation\n        # command for GNU C++ for the case where it uses the native\n        # linker, instead of GNU ld.  If possible, this setting should\n        # overridden to take advantage of the native linker features on\n        # the platform it is being used on.\n        _LT_TAGVAR(archive_cmds, $1)='$CC -shared -nostdlib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags -o $lib'\n      fi\n\n      # Commands to make compiler produce verbose output that lists\n      # what \"hidden\" libraries, object files and flags are used when\n      # linking a shared library.\n      output_verbose_link_cmd='$CC -shared $CFLAGS -v conftest.$objext 2>&1 | $GREP -v \"^Configured with:\" | $GREP \"\\-L\"'\n\n    else\n      GXX=no\n      with_gnu_ld=no\n      wlarc=\n    fi\n\n    # PORTME: fill in a description of your system's C++ link characteristics\n    AC_MSG_CHECKING([whether the $compiler linker ($LD) supports shared libraries])\n    _LT_TAGVAR(ld_shlibs, $1)=yes\n    case $host_os in\n      aix3*)\n        # FIXME: insert proper C++ library support\n        _LT_TAGVAR(ld_shlibs, $1)=no\n        ;;\n      aix[[4-9]]*)\n        if test ia64 = \"$host_cpu\"; then\n          # On IA64, the linker does run time linking by default, so we don't\n          # have to do anything special.\n          aix_use_runtimelinking=no\n          exp_sym_flag='-Bexport'\n          no_entry_flag=\n        else\n          aix_use_runtimelinking=no\n\n          # Test if we are trying to use run time linking or normal\n          # AIX style linking. If -brtl is somewhere in LDFLAGS, we\n          # have runtime linking enabled, and use it for executables.\n          # For shared libraries, we enable/disable runtime linking\n          # depending on the kind of the shared library created -\n          # when \"with_aix_soname,aix_use_runtimelinking\" is:\n          # \"aix,no\"   lib.a(lib.so.V) shared, rtl:no,  for executables\n          # \"aix,yes\"  lib.so          shared, rtl:yes, for executables\n          #            lib.a           static archive\n          # \"both,no\"  lib.so.V(shr.o) shared, rtl:yes\n          #            lib.a(lib.so.V) shared, rtl:no,  for executables\n          # \"both,yes\" lib.so.V(shr.o) shared, rtl:yes, for executables\n          #            lib.a(lib.so.V) shared, rtl:no\n          # \"svr4,*\"   lib.so.V(shr.o) shared, rtl:yes, for executables\n          #            lib.a           static archive\n          case $host_os in aix4.[[23]]|aix4.[[23]].*|aix[[5-9]]*)\n\t    for ld_flag in $LDFLAGS; do\n\t      case $ld_flag in\n\t      *-brtl*)\n\t        aix_use_runtimelinking=yes\n\t        break\n\t        ;;\n\t      esac\n\t    done\n\t    if test svr4,no = \"$with_aix_soname,$aix_use_runtimelinking\"; then\n\t      # With aix-soname=svr4, we create the lib.so.V shared archives only,\n\t      # so we don't have lib.a shared libs to link our executables.\n\t      # We have to force runtime linking in this case.\n\t      aix_use_runtimelinking=yes\n\t      LDFLAGS=\"$LDFLAGS -Wl,-brtl\"\n\t    fi\n\t    ;;\n          esac\n\n          exp_sym_flag='-bexport'\n          no_entry_flag='-bnoentry'\n        fi\n\n        # When large executables or shared objects are built, AIX ld can\n        # have problems creating the table of contents.  If linking a library\n        # or program results in \"error TOC overflow\" add -mminimal-toc to\n        # CXXFLAGS/CFLAGS for g++/gcc.  In the cases where that is not\n        # enough to fix the problem, add -Wl,-bbigtoc to LDFLAGS.\n\n        _LT_TAGVAR(archive_cmds, $1)=''\n        _LT_TAGVAR(hardcode_direct, $1)=yes\n        _LT_TAGVAR(hardcode_direct_absolute, $1)=yes\n        _LT_TAGVAR(hardcode_libdir_separator, $1)=':'\n        _LT_TAGVAR(link_all_deplibs, $1)=yes\n        _LT_TAGVAR(file_list_spec, $1)='$wl-f,'\n        case $with_aix_soname,$aix_use_runtimelinking in\n        aix,*) ;;\t# no import file\n        svr4,* | *,yes) # use import file\n          # The Import File defines what to hardcode.\n          _LT_TAGVAR(hardcode_direct, $1)=no\n          _LT_TAGVAR(hardcode_direct_absolute, $1)=no\n          ;;\n        esac\n\n        if test yes = \"$GXX\"; then\n          case $host_os in aix4.[[012]]|aix4.[[012]].*)\n          # We only want to do this on AIX 4.2 and lower, the check\n          # below for broken collect2 doesn't work under 4.3+\n\t  collect2name=`$CC -print-prog-name=collect2`\n\t  if test -f \"$collect2name\" &&\n\t     strings \"$collect2name\" | $GREP resolve_lib_name >/dev/null\n\t  then\n\t    # We have reworked collect2\n\t    :\n\t  else\n\t    # We have old collect2\n\t    _LT_TAGVAR(hardcode_direct, $1)=unsupported\n\t    # It fails to find uninstalled libraries when the uninstalled\n\t    # path is not listed in the libpath.  Setting hardcode_minus_L\n\t    # to unsupported forces relinking\n\t    _LT_TAGVAR(hardcode_minus_L, $1)=yes\n\t    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n\t    _LT_TAGVAR(hardcode_libdir_separator, $1)=\n\t  fi\n          esac\n          shared_flag='-shared'\n\t  if test yes = \"$aix_use_runtimelinking\"; then\n\t    shared_flag=$shared_flag' $wl-G'\n\t  fi\n\t  # Need to ensure runtime linking is disabled for the traditional\n\t  # shared library, or the linker may eventually find shared libraries\n\t  # /with/ Import File - we do not want to mix them.\n\t  shared_flag_aix='-shared'\n\t  shared_flag_svr4='-shared $wl-G'\n        else\n          # not using gcc\n          if test ia64 = \"$host_cpu\"; then\n\t  # VisualAge C++, Version 5.5 for AIX 5L for IA-64, Beta 3 Release\n\t  # chokes on -Wl,-G. The following line is correct:\n\t  shared_flag='-G'\n          else\n\t    if test yes = \"$aix_use_runtimelinking\"; then\n\t      shared_flag='$wl-G'\n\t    else\n\t      shared_flag='$wl-bM:SRE'\n\t    fi\n\t    shared_flag_aix='$wl-bM:SRE'\n\t    shared_flag_svr4='$wl-G'\n          fi\n        fi\n\n        _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-bexpall'\n        # It seems that -bexpall does not export symbols beginning with\n        # underscore (_), so it is better to generate a list of symbols to\n\t# export.\n        _LT_TAGVAR(always_export_symbols, $1)=yes\n\tif test aix,yes = \"$with_aix_soname,$aix_use_runtimelinking\"; then\n          # Warning - without using the other runtime loading flags (-brtl),\n          # -berok will link without error, but may produce a broken library.\n          # The \"-G\" linker flag allows undefined symbols.\n          _LT_TAGVAR(no_undefined_flag, $1)='-bernotok'\n          # Determine the default libpath from the value encoded in an empty\n          # executable.\n          _LT_SYS_MODULE_PATH_AIX([$1])\n          _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-blibpath:$libdir:'\"$aix_libpath\"\n\n          _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -o $output_objdir/$soname $libobjs $deplibs $wl'$no_entry_flag' $compiler_flags `if test -n \"$allow_undefined_flag\"; then func_echo_all \"$wl$allow_undefined_flag\"; else :; fi` $wl'$exp_sym_flag:\\$export_symbols' '$shared_flag\n        else\n          if test ia64 = \"$host_cpu\"; then\n\t    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-R $libdir:/usr/lib:/lib'\n\t    _LT_TAGVAR(allow_undefined_flag, $1)=\"-z nodefs\"\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)=\"\\$CC $shared_flag\"' -o $output_objdir/$soname $libobjs $deplibs '\"\\$wl$no_entry_flag\"' $compiler_flags $wl$allow_undefined_flag '\"\\$wl$exp_sym_flag:\\$export_symbols\"\n          else\n\t    # Determine the default libpath from the value encoded in an\n\t    # empty executable.\n\t    _LT_SYS_MODULE_PATH_AIX([$1])\n\t    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-blibpath:$libdir:'\"$aix_libpath\"\n\t    # Warning - without using the other run time loading flags,\n\t    # -berok will link without error, but may produce a broken library.\n\t    _LT_TAGVAR(no_undefined_flag, $1)=' $wl-bernotok'\n\t    _LT_TAGVAR(allow_undefined_flag, $1)=' $wl-berok'\n\t    if test yes = \"$with_gnu_ld\"; then\n\t      # We only use this code for GNU lds that support --whole-archive.\n\t      _LT_TAGVAR(whole_archive_flag_spec, $1)='$wl--whole-archive$convenience $wl--no-whole-archive'\n\t    else\n\t      # Exported symbols can be pulled into shared objects from archives\n\t      _LT_TAGVAR(whole_archive_flag_spec, $1)='$convenience'\n\t    fi\n\t    _LT_TAGVAR(archive_cmds_need_lc, $1)=yes\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)='$RM -r $output_objdir/$realname.d~$MKDIR $output_objdir/$realname.d'\n\t    # -brtl affects multiple linker settings, -berok does not and is overridden later\n\t    compiler_flags_filtered='`func_echo_all \"$compiler_flags \" | $SED -e \"s%-brtl\\\\([[, ]]\\\\)%-berok\\\\1%g\"`'\n\t    if test svr4 != \"$with_aix_soname\"; then\n\t      # This is similar to how AIX traditionally builds its shared\n\t      # libraries. Need -bnortl late, we may have -brtl in LDFLAGS.\n\t      _LT_TAGVAR(archive_expsym_cmds, $1)=\"$_LT_TAGVAR(archive_expsym_cmds, $1)\"'~$CC '$shared_flag_aix' -o $output_objdir/$realname.d/$soname $libobjs $deplibs $wl-bnoentry '$compiler_flags_filtered'$wl-bE:$export_symbols$allow_undefined_flag~$AR $AR_FLAGS $output_objdir/$libname$release.a $output_objdir/$realname.d/$soname'\n\t    fi\n\t    if test aix != \"$with_aix_soname\"; then\n\t      _LT_TAGVAR(archive_expsym_cmds, $1)=\"$_LT_TAGVAR(archive_expsym_cmds, $1)\"'~$CC '$shared_flag_svr4' -o $output_objdir/$realname.d/$shared_archive_member_spec.o $libobjs $deplibs $wl-bnoentry '$compiler_flags_filtered'$wl-bE:$export_symbols$allow_undefined_flag~$STRIP -e $output_objdir/$realname.d/$shared_archive_member_spec.o~( func_echo_all \"#! $soname($shared_archive_member_spec.o)\"; if test shr_64 = \"$shared_archive_member_spec\"; then func_echo_all \"# 64\"; else func_echo_all \"# 32\"; fi; cat $export_symbols ) > $output_objdir/$realname.d/$shared_archive_member_spec.imp~$AR $AR_FLAGS $output_objdir/$soname $output_objdir/$realname.d/$shared_archive_member_spec.o $output_objdir/$realname.d/$shared_archive_member_spec.imp'\n\t    else\n\t      # used by -dlpreopen to get the symbols\n\t      _LT_TAGVAR(archive_expsym_cmds, $1)=\"$_LT_TAGVAR(archive_expsym_cmds, $1)\"'~$MV  $output_objdir/$realname.d/$soname $output_objdir'\n\t    fi\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)=\"$_LT_TAGVAR(archive_expsym_cmds, $1)\"'~$RM -r $output_objdir/$realname.d'\n          fi\n        fi\n        ;;\n\n      beos*)\n\tif $LD --help 2>&1 | $GREP ': supported targets:.* elf' > /dev/null; then\n\t  _LT_TAGVAR(allow_undefined_flag, $1)=unsupported\n\t  # Joseph Beckenbach <jrb3@best.com> says some releases of gcc\n\t  # support --undefined.  This deserves some investigation.  FIXME\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -nostart $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n\telse\n\t  _LT_TAGVAR(ld_shlibs, $1)=no\n\tfi\n\t;;\n\n      chorus*)\n        case $cc_basename in\n          *)\n\t  # FIXME: insert proper C++ library support\n\t  _LT_TAGVAR(ld_shlibs, $1)=no\n\t  ;;\n        esac\n        ;;\n\n      cygwin* | mingw* | pw32* | cegcc*)\n\tcase $GXX,$cc_basename in\n\t,cl* | no,cl*)\n\t  # Native MSVC\n\t  # hardcode_libdir_flag_spec is actually meaningless, as there is\n\t  # no search path for DLLs.\n\t  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)=' '\n\t  _LT_TAGVAR(allow_undefined_flag, $1)=unsupported\n\t  _LT_TAGVAR(always_export_symbols, $1)=yes\n\t  _LT_TAGVAR(file_list_spec, $1)='@'\n\t  # Tell ltmain to make .lib files, not .a files.\n\t  libext=lib\n\t  # Tell ltmain to make .dll files, not .so files.\n\t  shrext_cmds=.dll\n\t  # FIXME: Setting linknames here is a bad hack.\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -o $output_objdir/$soname $libobjs $compiler_flags $deplibs -Wl,-DLL,-IMPLIB:\"$tool_output_objdir$libname.dll.lib\"~linknames='\n\t  _LT_TAGVAR(archive_expsym_cmds, $1)='if _LT_DLL_DEF_P([$export_symbols]); then\n              cp \"$export_symbols\" \"$output_objdir/$soname.def\";\n              echo \"$tool_output_objdir$soname.def\" > \"$output_objdir/$soname.exp\";\n            else\n              $SED -e '\\''s/^/-link -EXPORT:/'\\'' < $export_symbols > $output_objdir/$soname.exp;\n            fi~\n            $CC -o $tool_output_objdir$soname $libobjs $compiler_flags $deplibs \"@$tool_output_objdir$soname.exp\" -Wl,-DLL,-IMPLIB:\"$tool_output_objdir$libname.dll.lib\"~\n            linknames='\n\t  # The linker will not automatically build a static lib if we build a DLL.\n\t  # _LT_TAGVAR(old_archive_from_new_cmds, $1)='true'\n\t  _LT_TAGVAR(enable_shared_with_static_runtimes, $1)=yes\n\t  # Don't use ranlib\n\t  _LT_TAGVAR(old_postinstall_cmds, $1)='chmod 644 $oldlib'\n\t  _LT_TAGVAR(postlink_cmds, $1)='lt_outputfile=\"@OUTPUT@\"~\n            lt_tool_outputfile=\"@TOOL_OUTPUT@\"~\n            case $lt_outputfile in\n              *.exe|*.EXE) ;;\n              *)\n                lt_outputfile=$lt_outputfile.exe\n                lt_tool_outputfile=$lt_tool_outputfile.exe\n                ;;\n            esac~\n            func_to_tool_file \"$lt_outputfile\"~\n            if test : != \"$MANIFEST_TOOL\" && test -f \"$lt_outputfile.manifest\"; then\n              $MANIFEST_TOOL -manifest \"$lt_tool_outputfile.manifest\" -outputresource:\"$lt_tool_outputfile\" || exit 1;\n              $RM \"$lt_outputfile.manifest\";\n            fi'\n\t  ;;\n\t*)\n\t  # g++\n\t  # _LT_TAGVAR(hardcode_libdir_flag_spec, $1) is actually meaningless,\n\t  # as there is no search path for DLLs.\n\t  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n\t  _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl--export-all-symbols'\n\t  _LT_TAGVAR(allow_undefined_flag, $1)=unsupported\n\t  _LT_TAGVAR(always_export_symbols, $1)=no\n\t  _LT_TAGVAR(enable_shared_with_static_runtimes, $1)=yes\n\n\t  if $LD --help 2>&1 | $GREP 'auto-import' > /dev/null; then\n\t    _LT_TAGVAR(archive_cmds, $1)='$CC -shared -nostdlib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags -o $output_objdir/$soname $wl--enable-auto-image-base -Xlinker --out-implib -Xlinker $lib'\n\t    # If the export-symbols file already is a .def file, use it as\n\t    # is; otherwise, prepend EXPORTS...\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)='if _LT_DLL_DEF_P([$export_symbols]); then\n              cp $export_symbols $output_objdir/$soname.def;\n            else\n              echo EXPORTS > $output_objdir/$soname.def;\n              cat $export_symbols >> $output_objdir/$soname.def;\n            fi~\n            $CC -shared -nostdlib $output_objdir/$soname.def $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags -o $output_objdir/$soname $wl--enable-auto-image-base -Xlinker --out-implib -Xlinker $lib'\n\t  else\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t  fi\n\t  ;;\n\tesac\n\t;;\n      darwin* | rhapsody*)\n        _LT_DARWIN_LINKER_FEATURES($1)\n\t;;\n\n      os2*)\n\t_LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-L$libdir'\n\t_LT_TAGVAR(hardcode_minus_L, $1)=yes\n\t_LT_TAGVAR(allow_undefined_flag, $1)=unsupported\n\tshrext_cmds=.dll\n\t_LT_TAGVAR(archive_cmds, $1)='$ECHO \"LIBRARY ${soname%$shared_ext} INITINSTANCE TERMINSTANCE\" > $output_objdir/$libname.def~\n\t  $ECHO \"DESCRIPTION \\\"$libname\\\"\" >> $output_objdir/$libname.def~\n\t  $ECHO \"DATA MULTIPLE NONSHARED\" >> $output_objdir/$libname.def~\n\t  $ECHO EXPORTS >> $output_objdir/$libname.def~\n\t  emxexp $libobjs | $SED /\"_DLL_InitTerm\"/d >> $output_objdir/$libname.def~\n\t  $CC -Zdll -Zcrtdll -o $output_objdir/$soname $libobjs $deplibs $compiler_flags $output_objdir/$libname.def~\n\t  emximp -o $lib $output_objdir/$libname.def'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='$ECHO \"LIBRARY ${soname%$shared_ext} INITINSTANCE TERMINSTANCE\" > $output_objdir/$libname.def~\n\t  $ECHO \"DESCRIPTION \\\"$libname\\\"\" >> $output_objdir/$libname.def~\n\t  $ECHO \"DATA MULTIPLE NONSHARED\" >> $output_objdir/$libname.def~\n\t  $ECHO EXPORTS >> $output_objdir/$libname.def~\n\t  prefix_cmds=\"$SED\"~\n\t  if test EXPORTS = \"`$SED 1q $export_symbols`\"; then\n\t    prefix_cmds=\"$prefix_cmds -e 1d\";\n\t  fi~\n\t  prefix_cmds=\"$prefix_cmds -e \\\"s/^\\(.*\\)$/_\\1/g\\\"\"~\n\t  cat $export_symbols | $prefix_cmds >> $output_objdir/$libname.def~\n\t  $CC -Zdll -Zcrtdll -o $output_objdir/$soname $libobjs $deplibs $compiler_flags $output_objdir/$libname.def~\n\t  emximp -o $lib $output_objdir/$libname.def'\n\t_LT_TAGVAR(old_archive_From_new_cmds, $1)='emximp -o $output_objdir/${libname}_dll.a $output_objdir/$libname.def'\n\t_LT_TAGVAR(enable_shared_with_static_runtimes, $1)=yes\n\t;;\n\n      dgux*)\n        case $cc_basename in\n          ec++*)\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n          ghcx*)\n\t    # Green Hills C++ Compiler\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n          *)\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n        esac\n        ;;\n\n      freebsd2.*)\n        # C++ shared libraries reported to be fairly broken before\n\t# switch to ELF\n        _LT_TAGVAR(ld_shlibs, $1)=no\n        ;;\n\n      freebsd-elf*)\n        _LT_TAGVAR(archive_cmds_need_lc, $1)=no\n        ;;\n\n      freebsd* | dragonfly*)\n        # FreeBSD 3 and later use GNU C++ and GNU ld with standard ELF\n        # conventions\n        _LT_TAGVAR(ld_shlibs, $1)=yes\n        ;;\n\n      haiku*)\n        _LT_TAGVAR(archive_cmds, $1)='$CC -shared $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n        _LT_TAGVAR(link_all_deplibs, $1)=yes\n        ;;\n\n      hpux9*)\n        _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl+b $wl$libdir'\n        _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n        _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-E'\n        _LT_TAGVAR(hardcode_direct, $1)=yes\n        _LT_TAGVAR(hardcode_minus_L, $1)=yes # Not in the search PATH,\n\t\t\t\t             # but as the default\n\t\t\t\t             # location of the library.\n\n        case $cc_basename in\n          CC*)\n            # FIXME: insert proper C++ library support\n            _LT_TAGVAR(ld_shlibs, $1)=no\n            ;;\n          aCC*)\n            _LT_TAGVAR(archive_cmds, $1)='$RM $output_objdir/$soname~$CC -b $wl+b $wl$install_libdir -o $output_objdir/$soname $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags~test \"x$output_objdir/$soname\" = \"x$lib\" || mv $output_objdir/$soname $lib'\n            # Commands to make compiler produce verbose output that lists\n            # what \"hidden\" libraries, object files and flags are used when\n            # linking a shared library.\n            #\n            # There doesn't appear to be a way to prevent this compiler from\n            # explicitly linking system object files so we need to strip them\n            # from the output so that they don't get included in the library\n            # dependencies.\n            output_verbose_link_cmd='templist=`($CC -b $CFLAGS -v conftest.$objext 2>&1) | $EGREP \"\\-L\"`; list= ; for z in $templist; do case $z in conftest.$objext) list=\"$list $z\";; *.$objext);; *) list=\"$list $z\";;esac; done; func_echo_all \"$list\"'\n            ;;\n          *)\n            if test yes = \"$GXX\"; then\n              _LT_TAGVAR(archive_cmds, $1)='$RM $output_objdir/$soname~$CC -shared -nostdlib $pic_flag $wl+b $wl$install_libdir -o $output_objdir/$soname $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags~test \"x$output_objdir/$soname\" = \"x$lib\" || mv $output_objdir/$soname $lib'\n            else\n              # FIXME: insert proper C++ library support\n              _LT_TAGVAR(ld_shlibs, $1)=no\n            fi\n            ;;\n        esac\n        ;;\n\n      hpux10*|hpux11*)\n        if test no = \"$with_gnu_ld\"; then\n\t  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl+b $wl$libdir'\n\t  _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n\n          case $host_cpu in\n            hppa*64*|ia64*)\n              ;;\n            *)\n\t      _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-E'\n              ;;\n          esac\n        fi\n        case $host_cpu in\n          hppa*64*|ia64*)\n            _LT_TAGVAR(hardcode_direct, $1)=no\n            _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n            ;;\n          *)\n            _LT_TAGVAR(hardcode_direct, $1)=yes\n            _LT_TAGVAR(hardcode_direct_absolute, $1)=yes\n            _LT_TAGVAR(hardcode_minus_L, $1)=yes # Not in the search PATH,\n\t\t\t\t\t         # but as the default\n\t\t\t\t\t         # location of the library.\n            ;;\n        esac\n\n        case $cc_basename in\n          CC*)\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n          aCC*)\n\t    case $host_cpu in\n\t      hppa*64*)\n\t        _LT_TAGVAR(archive_cmds, $1)='$CC -b $wl+h $wl$soname -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags'\n\t        ;;\n\t      ia64*)\n\t        _LT_TAGVAR(archive_cmds, $1)='$CC -b $wl+h $wl$soname $wl+nodefaultrpath -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags'\n\t        ;;\n\t      *)\n\t        _LT_TAGVAR(archive_cmds, $1)='$CC -b $wl+h $wl$soname $wl+b $wl$install_libdir -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags'\n\t        ;;\n\t    esac\n\t    # Commands to make compiler produce verbose output that lists\n\t    # what \"hidden\" libraries, object files and flags are used when\n\t    # linking a shared library.\n\t    #\n\t    # There doesn't appear to be a way to prevent this compiler from\n\t    # explicitly linking system object files so we need to strip them\n\t    # from the output so that they don't get included in the library\n\t    # dependencies.\n\t    output_verbose_link_cmd='templist=`($CC -b $CFLAGS -v conftest.$objext 2>&1) | $GREP \"\\-L\"`; list= ; for z in $templist; do case $z in conftest.$objext) list=\"$list $z\";; *.$objext);; *) list=\"$list $z\";;esac; done; func_echo_all \"$list\"'\n\t    ;;\n          *)\n\t    if test yes = \"$GXX\"; then\n\t      if test no = \"$with_gnu_ld\"; then\n\t        case $host_cpu in\n\t          hppa*64*)\n\t            _LT_TAGVAR(archive_cmds, $1)='$CC -shared -nostdlib -fPIC $wl+h $wl$soname -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags'\n\t            ;;\n\t          ia64*)\n\t            _LT_TAGVAR(archive_cmds, $1)='$CC -shared -nostdlib $pic_flag $wl+h $wl$soname $wl+nodefaultrpath -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags'\n\t            ;;\n\t          *)\n\t            _LT_TAGVAR(archive_cmds, $1)='$CC -shared -nostdlib $pic_flag $wl+h $wl$soname $wl+b $wl$install_libdir -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags'\n\t            ;;\n\t        esac\n\t      fi\n\t    else\n\t      # FIXME: insert proper C++ library support\n\t      _LT_TAGVAR(ld_shlibs, $1)=no\n\t    fi\n\t    ;;\n        esac\n        ;;\n\n      interix[[3-9]]*)\n\t_LT_TAGVAR(hardcode_direct, $1)=no\n\t_LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n\t_LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath,$libdir'\n\t_LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-E'\n\t# Hack: On Interix 3.x, we cannot compile PIC because of a broken gcc.\n\t# Instead, shared libraries are loaded at an image base (0x10000000 by\n\t# default) and relocated if they conflict, which is a slow very memory\n\t# consuming and fragmenting process.  To avoid this, we pick a random,\n\t# 256 KiB-aligned image base between 0x50000000 and 0x6FFC0000 at link\n\t# time.  Moving up from 0x10000000 also allows more sbrk(2) space.\n\t_LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-h,$soname $wl--image-base,`expr ${RANDOM-$$} % 4096 / 2 \\* 262144 + 1342177280` -o $lib'\n\t_LT_TAGVAR(archive_expsym_cmds, $1)='sed \"s|^|_|\" $export_symbols >$output_objdir/$soname.expsym~$CC -shared $pic_flag $libobjs $deplibs $compiler_flags $wl-h,$soname $wl--retain-symbols-file,$output_objdir/$soname.expsym $wl--image-base,`expr ${RANDOM-$$} % 4096 / 2 \\* 262144 + 1342177280` -o $lib'\n\t;;\n      irix5* | irix6*)\n        case $cc_basename in\n          CC*)\n\t    # SGI C++\n\t    _LT_TAGVAR(archive_cmds, $1)='$CC -shared -all -multigot $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags -soname $soname `test -n \"$verstring\" && func_echo_all \"-set_version $verstring\"` -update_registry $output_objdir/so_locations -o $lib'\n\n\t    # Archives containing C++ object files must be created using\n\t    # \"CC -ar\", where \"CC\" is the IRIX C++ compiler.  This is\n\t    # necessary to make sure instantiated templates are included\n\t    # in the archive.\n\t    _LT_TAGVAR(old_archive_cmds, $1)='$CC -ar -WR,-u -o $oldlib $oldobjs'\n\t    ;;\n          *)\n\t    if test yes = \"$GXX\"; then\n\t      if test no = \"$with_gnu_ld\"; then\n\t        _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag -nostdlib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname `test -n \"$verstring\" && func_echo_all \"$wl-set_version $wl$verstring\"` $wl-update_registry $wl$output_objdir/so_locations -o $lib'\n\t      else\n\t        _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag -nostdlib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname `test -n \"$verstring\" && func_echo_all \"$wl-set_version $wl$verstring\"` -o $lib'\n\t      fi\n\t    fi\n\t    _LT_TAGVAR(link_all_deplibs, $1)=yes\n\t    ;;\n        esac\n        _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n        _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n        _LT_TAGVAR(inherit_rpath, $1)=yes\n        ;;\n\n      linux* | k*bsd*-gnu | kopensolaris*-gnu | gnu*)\n        case $cc_basename in\n          KCC*)\n\t    # Kuck and Associates, Inc. (KAI) C++ Compiler\n\n\t    # KCC will only create a shared library if the output file\n\t    # ends with \".so\" (or \".sl\" for HP-UX), so rename the library\n\t    # to its proper name (with version) after linking.\n\t    _LT_TAGVAR(archive_cmds, $1)='tempext=`echo $shared_ext | $SED -e '\\''s/\\([[^()0-9A-Za-z{}]]\\)/\\\\\\\\\\1/g'\\''`; templib=`echo $lib | $SED -e \"s/\\$tempext\\..*/.so/\"`; $CC $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags --soname $soname -o \\$templib; mv \\$templib $lib'\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)='tempext=`echo $shared_ext | $SED -e '\\''s/\\([[^()0-9A-Za-z{}]]\\)/\\\\\\\\\\1/g'\\''`; templib=`echo $lib | $SED -e \"s/\\$tempext\\..*/.so/\"`; $CC $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags --soname $soname -o \\$templib $wl-retain-symbols-file,$export_symbols; mv \\$templib $lib'\n\t    # Commands to make compiler produce verbose output that lists\n\t    # what \"hidden\" libraries, object files and flags are used when\n\t    # linking a shared library.\n\t    #\n\t    # There doesn't appear to be a way to prevent this compiler from\n\t    # explicitly linking system object files so we need to strip them\n\t    # from the output so that they don't get included in the library\n\t    # dependencies.\n\t    output_verbose_link_cmd='templist=`$CC $CFLAGS -v conftest.$objext -o libconftest$shared_ext 2>&1 | $GREP \"ld\"`; rm -f libconftest$shared_ext; list= ; for z in $templist; do case $z in conftest.$objext) list=\"$list $z\";; *.$objext);; *) list=\"$list $z\";;esac; done; func_echo_all \"$list\"'\n\n\t    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath,$libdir'\n\t    _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl--export-dynamic'\n\n\t    # Archives containing C++ object files must be created using\n\t    # \"CC -Bstatic\", where \"CC\" is the KAI C++ compiler.\n\t    _LT_TAGVAR(old_archive_cmds, $1)='$CC -Bstatic -o $oldlib $oldobjs'\n\t    ;;\n\t  icpc* | ecpc* )\n\t    # Intel C++\n\t    with_gnu_ld=yes\n\t    # version 8.0 and above of icpc choke on multiply defined symbols\n\t    # if we add $predep_objects and $postdep_objects, however 7.1 and\n\t    # earlier do not add the objects themselves.\n\t    case `$CC -V 2>&1` in\n\t      *\"Version 7.\"*)\n\t        _LT_TAGVAR(archive_cmds, $1)='$CC -shared $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname -o $lib'\n\t\t_LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname $wl-retain-symbols-file $wl$export_symbols -o $lib'\n\t\t;;\n\t      *)  # Version 8.0 or newer\n\t        tmp_idyn=\n\t        case $host_cpu in\n\t\t  ia64*) tmp_idyn=' -i_dynamic';;\n\t\tesac\n\t        _LT_TAGVAR(archive_cmds, $1)='$CC -shared'\"$tmp_idyn\"' $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n\t\t_LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared'\"$tmp_idyn\"' $libobjs $deplibs $compiler_flags $wl-soname $wl$soname $wl-retain-symbols-file $wl$export_symbols -o $lib'\n\t\t;;\n\t    esac\n\t    _LT_TAGVAR(archive_cmds_need_lc, $1)=no\n\t    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath,$libdir'\n\t    _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl--export-dynamic'\n\t    _LT_TAGVAR(whole_archive_flag_spec, $1)='$wl--whole-archive$convenience $wl--no-whole-archive'\n\t    ;;\n          pgCC* | pgcpp*)\n            # Portland Group C++ compiler\n\t    case `$CC -V` in\n\t    *pgCC\\ [[1-5]].* | *pgcpp\\ [[1-5]].*)\n\t      _LT_TAGVAR(prelink_cmds, $1)='tpldir=Template.dir~\n               rm -rf $tpldir~\n               $CC --prelink_objects --instantiation_dir $tpldir $objs $libobjs $compile_deplibs~\n               compile_command=\"$compile_command `find $tpldir -name \\*.o | sort | $NL2SP`\"'\n\t      _LT_TAGVAR(old_archive_cmds, $1)='tpldir=Template.dir~\n                rm -rf $tpldir~\n                $CC --prelink_objects --instantiation_dir $tpldir $oldobjs$old_deplibs~\n                $AR $AR_FLAGS $oldlib$oldobjs$old_deplibs `find $tpldir -name \\*.o | sort | $NL2SP`~\n                $RANLIB $oldlib'\n\t      _LT_TAGVAR(archive_cmds, $1)='tpldir=Template.dir~\n                rm -rf $tpldir~\n                $CC --prelink_objects --instantiation_dir $tpldir $predep_objects $libobjs $deplibs $convenience $postdep_objects~\n                $CC -shared $pic_flag $predep_objects $libobjs $deplibs `find $tpldir -name \\*.o | sort | $NL2SP` $postdep_objects $compiler_flags $wl-soname $wl$soname -o $lib'\n\t      _LT_TAGVAR(archive_expsym_cmds, $1)='tpldir=Template.dir~\n                rm -rf $tpldir~\n                $CC --prelink_objects --instantiation_dir $tpldir $predep_objects $libobjs $deplibs $convenience $postdep_objects~\n                $CC -shared $pic_flag $predep_objects $libobjs $deplibs `find $tpldir -name \\*.o | sort | $NL2SP` $postdep_objects $compiler_flags $wl-soname $wl$soname $wl-retain-symbols-file $wl$export_symbols -o $lib'\n\t      ;;\n\t    *) # Version 6 and above use weak symbols\n\t      _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname -o $lib'\n\t      _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $pic_flag $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname $wl-retain-symbols-file $wl$export_symbols -o $lib'\n\t      ;;\n\t    esac\n\n\t    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl--rpath $wl$libdir'\n\t    _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl--export-dynamic'\n\t    _LT_TAGVAR(whole_archive_flag_spec, $1)='$wl--whole-archive`for conv in $convenience\\\"\\\"; do test  -n \\\"$conv\\\" && new_convenience=\\\"$new_convenience,$conv\\\"; done; func_echo_all \\\"$new_convenience\\\"` $wl--no-whole-archive'\n            ;;\n\t  cxx*)\n\t    # Compaq C++\n\t    _LT_TAGVAR(archive_cmds, $1)='$CC -shared $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname -o $lib'\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname  -o $lib $wl-retain-symbols-file $wl$export_symbols'\n\n\t    runpath_var=LD_RUN_PATH\n\t    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-rpath $libdir'\n\t    _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n\n\t    # Commands to make compiler produce verbose output that lists\n\t    # what \"hidden\" libraries, object files and flags are used when\n\t    # linking a shared library.\n\t    #\n\t    # There doesn't appear to be a way to prevent this compiler from\n\t    # explicitly linking system object files so we need to strip them\n\t    # from the output so that they don't get included in the library\n\t    # dependencies.\n\t    output_verbose_link_cmd='templist=`$CC -shared $CFLAGS -v conftest.$objext 2>&1 | $GREP \"ld\"`; templist=`func_echo_all \"$templist\" | $SED \"s/\\(^.*ld.*\\)\\( .*ld .*$\\)/\\1/\"`; list= ; for z in $templist; do case $z in conftest.$objext) list=\"$list $z\";; *.$objext);; *) list=\"$list $z\";;esac; done; func_echo_all \"X$list\" | $Xsed'\n\t    ;;\n\t  xl* | mpixl* | bgxl*)\n\t    # IBM XL 8.0 on PPC, with GNU ld\n\t    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n\t    _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl--export-dynamic'\n\t    _LT_TAGVAR(archive_cmds, $1)='$CC -qmkshrobj $libobjs $deplibs $compiler_flags $wl-soname $wl$soname -o $lib'\n\t    if test yes = \"$supports_anon_versioning\"; then\n\t      _LT_TAGVAR(archive_expsym_cmds, $1)='echo \"{ global:\" > $output_objdir/$libname.ver~\n                cat $export_symbols | sed -e \"s/\\(.*\\)/\\1;/\" >> $output_objdir/$libname.ver~\n                echo \"local: *; };\" >> $output_objdir/$libname.ver~\n                $CC -qmkshrobj $libobjs $deplibs $compiler_flags $wl-soname $wl$soname $wl-version-script $wl$output_objdir/$libname.ver -o $lib'\n\t    fi\n\t    ;;\n\t  *)\n\t    case `$CC -V 2>&1 | sed 5q` in\n\t    *Sun\\ C*)\n\t      # Sun C++ 5.9\n\t      _LT_TAGVAR(no_undefined_flag, $1)=' -zdefs'\n\t      _LT_TAGVAR(archive_cmds, $1)='$CC -G$allow_undefined_flag -h$soname -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags'\n\t      _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -G$allow_undefined_flag -h$soname -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-retain-symbols-file $wl$export_symbols'\n\t      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-R$libdir'\n\t      _LT_TAGVAR(whole_archive_flag_spec, $1)='$wl--whole-archive`new_convenience=; for conv in $convenience\\\"\\\"; do test -z \\\"$conv\\\" || new_convenience=\\\"$new_convenience,$conv\\\"; done; func_echo_all \\\"$new_convenience\\\"` $wl--no-whole-archive'\n\t      _LT_TAGVAR(compiler_needs_object, $1)=yes\n\n\t      # Not sure whether something based on\n\t      # $CC $CFLAGS -v conftest.$objext -o libconftest$shared_ext 2>&1\n\t      # would be better.\n\t      output_verbose_link_cmd='func_echo_all'\n\n\t      # Archives containing C++ object files must be created using\n\t      # \"CC -xar\", where \"CC\" is the Sun C++ compiler.  This is\n\t      # necessary to make sure instantiated templates are included\n\t      # in the archive.\n\t      _LT_TAGVAR(old_archive_cmds, $1)='$CC -xar -o $oldlib $oldobjs'\n\t      ;;\n\t    esac\n\t    ;;\n\tesac\n\t;;\n\n      lynxos*)\n        # FIXME: insert proper C++ library support\n\t_LT_TAGVAR(ld_shlibs, $1)=no\n\t;;\n\n      m88k*)\n        # FIXME: insert proper C++ library support\n        _LT_TAGVAR(ld_shlibs, $1)=no\n\t;;\n\n      mvs*)\n        case $cc_basename in\n          cxx*)\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n\t  *)\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n\tesac\n\t;;\n\n      netbsd*)\n        if echo __ELF__ | $CC -E - | $GREP __ELF__ >/dev/null; then\n\t  _LT_TAGVAR(archive_cmds, $1)='$LD -Bshareable  -o $lib $predep_objects $libobjs $deplibs $postdep_objects $linker_flags'\n\t  wlarc=\n\t  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-R$libdir'\n\t  _LT_TAGVAR(hardcode_direct, $1)=yes\n\t  _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n\tfi\n\t# Workaround some broken pre-1.5 toolchains\n\toutput_verbose_link_cmd='$CC -shared $CFLAGS -v conftest.$objext 2>&1 | $GREP conftest.$objext | $SED -e \"s:-lgcc -lc -lgcc::\"'\n\t;;\n\n      *nto* | *qnx*)\n        _LT_TAGVAR(ld_shlibs, $1)=yes\n\t;;\n\n      openbsd* | bitrig*)\n\tif test -f /usr/libexec/ld.so; then\n\t  _LT_TAGVAR(hardcode_direct, $1)=yes\n\t  _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n\t  _LT_TAGVAR(hardcode_direct_absolute, $1)=yes\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags -o $lib'\n\t  _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath,$libdir'\n\t  if test -z \"`echo __ELF__ | $CC -E - | grep __ELF__`\"; then\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $pic_flag $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-retain-symbols-file,$export_symbols -o $lib'\n\t    _LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-E'\n\t    _LT_TAGVAR(whole_archive_flag_spec, $1)=$wlarc'--whole-archive$convenience '$wlarc'--no-whole-archive'\n\t  fi\n\t  output_verbose_link_cmd=func_echo_all\n\telse\n\t  _LT_TAGVAR(ld_shlibs, $1)=no\n\tfi\n\t;;\n\n      osf3* | osf4* | osf5*)\n        case $cc_basename in\n          KCC*)\n\t    # Kuck and Associates, Inc. (KAI) C++ Compiler\n\n\t    # KCC will only create a shared library if the output file\n\t    # ends with \".so\" (or \".sl\" for HP-UX), so rename the library\n\t    # to its proper name (with version) after linking.\n\t    _LT_TAGVAR(archive_cmds, $1)='tempext=`echo $shared_ext | $SED -e '\\''s/\\([[^()0-9A-Za-z{}]]\\)/\\\\\\\\\\1/g'\\''`; templib=`echo \"$lib\" | $SED -e \"s/\\$tempext\\..*/.so/\"`; $CC $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags --soname $soname -o \\$templib; mv \\$templib $lib'\n\n\t    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath,$libdir'\n\t    _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n\n\t    # Archives containing C++ object files must be created using\n\t    # the KAI C++ compiler.\n\t    case $host in\n\t      osf3*) _LT_TAGVAR(old_archive_cmds, $1)='$CC -Bstatic -o $oldlib $oldobjs' ;;\n\t      *) _LT_TAGVAR(old_archive_cmds, $1)='$CC -o $oldlib $oldobjs' ;;\n\t    esac\n\t    ;;\n          RCC*)\n\t    # Rational C++ 2.4.1\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n          cxx*)\n\t    case $host in\n\t      osf3*)\n\t        _LT_TAGVAR(allow_undefined_flag, $1)=' $wl-expect_unresolved $wl\\*'\n\t        _LT_TAGVAR(archive_cmds, $1)='$CC -shared$allow_undefined_flag $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $soname `test -n \"$verstring\" && func_echo_all \"$wl-set_version $verstring\"` -update_registry $output_objdir/so_locations -o $lib'\n\t        _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n\t\t;;\n\t      *)\n\t        _LT_TAGVAR(allow_undefined_flag, $1)=' -expect_unresolved \\*'\n\t        _LT_TAGVAR(archive_cmds, $1)='$CC -shared$allow_undefined_flag $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags -msym -soname $soname `test -n \"$verstring\" && func_echo_all \"-set_version $verstring\"` -update_registry $output_objdir/so_locations -o $lib'\n\t        _LT_TAGVAR(archive_expsym_cmds, $1)='for i in `cat $export_symbols`; do printf \"%s %s\\\\n\" -exported_symbol \"\\$i\" >> $lib.exp; done~\n                  echo \"-hidden\">> $lib.exp~\n                  $CC -shared$allow_undefined_flag $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags -msym -soname $soname $wl-input $wl$lib.exp  `test -n \"$verstring\" && $ECHO \"-set_version $verstring\"` -update_registry $output_objdir/so_locations -o $lib~\n                  $RM $lib.exp'\n\t        _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-rpath $libdir'\n\t\t;;\n\t    esac\n\n\t    _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n\n\t    # Commands to make compiler produce verbose output that lists\n\t    # what \"hidden\" libraries, object files and flags are used when\n\t    # linking a shared library.\n\t    #\n\t    # There doesn't appear to be a way to prevent this compiler from\n\t    # explicitly linking system object files so we need to strip them\n\t    # from the output so that they don't get included in the library\n\t    # dependencies.\n\t    output_verbose_link_cmd='templist=`$CC -shared $CFLAGS -v conftest.$objext 2>&1 | $GREP \"ld\" | $GREP -v \"ld:\"`; templist=`func_echo_all \"$templist\" | $SED \"s/\\(^.*ld.*\\)\\( .*ld.*$\\)/\\1/\"`; list= ; for z in $templist; do case $z in conftest.$objext) list=\"$list $z\";; *.$objext);; *) list=\"$list $z\";;esac; done; func_echo_all \"$list\"'\n\t    ;;\n\t  *)\n\t    if test yes,no = \"$GXX,$with_gnu_ld\"; then\n\t      _LT_TAGVAR(allow_undefined_flag, $1)=' $wl-expect_unresolved $wl\\*'\n\t      case $host in\n\t        osf3*)\n\t          _LT_TAGVAR(archive_cmds, $1)='$CC -shared -nostdlib $allow_undefined_flag $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-soname $wl$soname `test -n \"$verstring\" && func_echo_all \"$wl-set_version $wl$verstring\"` $wl-update_registry $wl$output_objdir/so_locations -o $lib'\n\t\t  ;;\n\t        *)\n\t          _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag -nostdlib $allow_undefined_flag $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-msym $wl-soname $wl$soname `test -n \"$verstring\" && func_echo_all \"$wl-set_version $wl$verstring\"` $wl-update_registry $wl$output_objdir/so_locations -o $lib'\n\t\t  ;;\n\t      esac\n\n\t      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-rpath $wl$libdir'\n\t      _LT_TAGVAR(hardcode_libdir_separator, $1)=:\n\n\t      # Commands to make compiler produce verbose output that lists\n\t      # what \"hidden\" libraries, object files and flags are used when\n\t      # linking a shared library.\n\t      output_verbose_link_cmd='$CC -shared $CFLAGS -v conftest.$objext 2>&1 | $GREP -v \"^Configured with:\" | $GREP \"\\-L\"'\n\n\t    else\n\t      # FIXME: insert proper C++ library support\n\t      _LT_TAGVAR(ld_shlibs, $1)=no\n\t    fi\n\t    ;;\n        esac\n        ;;\n\n      psos*)\n        # FIXME: insert proper C++ library support\n        _LT_TAGVAR(ld_shlibs, $1)=no\n        ;;\n\n      sunos4*)\n        case $cc_basename in\n          CC*)\n\t    # Sun C++ 4.x\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n          lcc*)\n\t    # Lucid\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n          *)\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n        esac\n        ;;\n\n      solaris*)\n        case $cc_basename in\n          CC* | sunCC*)\n\t    # Sun C++ 4.2, 5.x and Centerline C++\n            _LT_TAGVAR(archive_cmds_need_lc,$1)=yes\n\t    _LT_TAGVAR(no_undefined_flag, $1)=' -zdefs'\n\t    _LT_TAGVAR(archive_cmds, $1)='$CC -G$allow_undefined_flag -h$soname -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags'\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)='echo \"{ global:\" > $lib.exp~cat $export_symbols | $SED -e \"s/\\(.*\\)/\\1;/\" >> $lib.exp~echo \"local: *; };\" >> $lib.exp~\n              $CC -G$allow_undefined_flag $wl-M $wl$lib.exp -h$soname -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags~$RM $lib.exp'\n\n\t    _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='-R$libdir'\n\t    _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n\t    case $host_os in\n\t      solaris2.[[0-5]] | solaris2.[[0-5]].*) ;;\n\t      *)\n\t\t# The compiler driver will combine and reorder linker options,\n\t\t# but understands '-z linker_flag'.\n\t        # Supported since Solaris 2.6 (maybe 2.5.1?)\n\t\t_LT_TAGVAR(whole_archive_flag_spec, $1)='-z allextract$convenience -z defaultextract'\n\t        ;;\n\t    esac\n\t    _LT_TAGVAR(link_all_deplibs, $1)=yes\n\n\t    output_verbose_link_cmd='func_echo_all'\n\n\t    # Archives containing C++ object files must be created using\n\t    # \"CC -xar\", where \"CC\" is the Sun C++ compiler.  This is\n\t    # necessary to make sure instantiated templates are included\n\t    # in the archive.\n\t    _LT_TAGVAR(old_archive_cmds, $1)='$CC -xar -o $oldlib $oldobjs'\n\t    ;;\n          gcx*)\n\t    # Green Hills C++ Compiler\n\t    _LT_TAGVAR(archive_cmds, $1)='$CC -shared $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-h $wl$soname -o $lib'\n\n\t    # The C++ compiler must be used to create the archive.\n\t    _LT_TAGVAR(old_archive_cmds, $1)='$CC $LDFLAGS -archive -o $oldlib $oldobjs'\n\t    ;;\n          *)\n\t    # GNU C++ compiler with Solaris linker\n\t    if test yes,no = \"$GXX,$with_gnu_ld\"; then\n\t      _LT_TAGVAR(no_undefined_flag, $1)=' $wl-z ${wl}defs'\n\t      if $CC --version | $GREP -v '^2\\.7' > /dev/null; then\n\t        _LT_TAGVAR(archive_cmds, $1)='$CC -shared $pic_flag -nostdlib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-h $wl$soname -o $lib'\n\t        _LT_TAGVAR(archive_expsym_cmds, $1)='echo \"{ global:\" > $lib.exp~cat $export_symbols | $SED -e \"s/\\(.*\\)/\\1;/\" >> $lib.exp~echo \"local: *; };\" >> $lib.exp~\n                  $CC -shared $pic_flag -nostdlib $wl-M $wl$lib.exp $wl-h $wl$soname -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags~$RM $lib.exp'\n\n\t        # Commands to make compiler produce verbose output that lists\n\t        # what \"hidden\" libraries, object files and flags are used when\n\t        # linking a shared library.\n\t        output_verbose_link_cmd='$CC -shared $CFLAGS -v conftest.$objext 2>&1 | $GREP -v \"^Configured with:\" | $GREP \"\\-L\"'\n\t      else\n\t        # g++ 2.7 appears to require '-G' NOT '-shared' on this\n\t        # platform.\n\t        _LT_TAGVAR(archive_cmds, $1)='$CC -G -nostdlib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags $wl-h $wl$soname -o $lib'\n\t        _LT_TAGVAR(archive_expsym_cmds, $1)='echo \"{ global:\" > $lib.exp~cat $export_symbols | $SED -e \"s/\\(.*\\)/\\1;/\" >> $lib.exp~echo \"local: *; };\" >> $lib.exp~\n                  $CC -G -nostdlib $wl-M $wl$lib.exp $wl-h $wl$soname -o $lib $predep_objects $libobjs $deplibs $postdep_objects $compiler_flags~$RM $lib.exp'\n\n\t        # Commands to make compiler produce verbose output that lists\n\t        # what \"hidden\" libraries, object files and flags are used when\n\t        # linking a shared library.\n\t        output_verbose_link_cmd='$CC -G $CFLAGS -v conftest.$objext 2>&1 | $GREP -v \"^Configured with:\" | $GREP \"\\-L\"'\n\t      fi\n\n\t      _LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-R $wl$libdir'\n\t      case $host_os in\n\t\tsolaris2.[[0-5]] | solaris2.[[0-5]].*) ;;\n\t\t*)\n\t\t  _LT_TAGVAR(whole_archive_flag_spec, $1)='$wl-z ${wl}allextract$convenience $wl-z ${wl}defaultextract'\n\t\t  ;;\n\t      esac\n\t    fi\n\t    ;;\n        esac\n        ;;\n\n    sysv4*uw2* | sysv5OpenUNIX* | sysv5UnixWare7.[[01]].[[10]]* | unixware7* | sco3.2v5.0.[[024]]*)\n      _LT_TAGVAR(no_undefined_flag, $1)='$wl-z,text'\n      _LT_TAGVAR(archive_cmds_need_lc, $1)=no\n      _LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n      runpath_var='LD_RUN_PATH'\n\n      case $cc_basename in\n        CC*)\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -G $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t  _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -G $wl-Bexport:$export_symbols $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t  ;;\n\t*)\n\t  _LT_TAGVAR(archive_cmds, $1)='$CC -shared $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t  _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $wl-Bexport:$export_symbols $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t  ;;\n      esac\n      ;;\n\n      sysv5* | sco3.2v5* | sco5v6*)\n\t# Note: We CANNOT use -z defs as we might desire, because we do not\n\t# link with -lc, and that would cause any symbols used from libc to\n\t# always be unresolved, which means just about no library would\n\t# ever link correctly.  If we're not using GNU ld we use -z text\n\t# though, which does catch some bad symbols but isn't as heavy-handed\n\t# as -z defs.\n\t_LT_TAGVAR(no_undefined_flag, $1)='$wl-z,text'\n\t_LT_TAGVAR(allow_undefined_flag, $1)='$wl-z,nodefs'\n\t_LT_TAGVAR(archive_cmds_need_lc, $1)=no\n\t_LT_TAGVAR(hardcode_shlibpath_var, $1)=no\n\t_LT_TAGVAR(hardcode_libdir_flag_spec, $1)='$wl-R,$libdir'\n\t_LT_TAGVAR(hardcode_libdir_separator, $1)=':'\n\t_LT_TAGVAR(link_all_deplibs, $1)=yes\n\t_LT_TAGVAR(export_dynamic_flag_spec, $1)='$wl-Bexport'\n\trunpath_var='LD_RUN_PATH'\n\n\tcase $cc_basename in\n          CC*)\n\t    _LT_TAGVAR(archive_cmds, $1)='$CC -G $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -G $wl-Bexport:$export_symbols $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t    _LT_TAGVAR(old_archive_cmds, $1)='$CC -Tprelink_objects $oldobjs~\n              '\"$_LT_TAGVAR(old_archive_cmds, $1)\"\n\t    _LT_TAGVAR(reload_cmds, $1)='$CC -Tprelink_objects $reload_objs~\n              '\"$_LT_TAGVAR(reload_cmds, $1)\"\n\t    ;;\n\t  *)\n\t    _LT_TAGVAR(archive_cmds, $1)='$CC -shared $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t    _LT_TAGVAR(archive_expsym_cmds, $1)='$CC -shared $wl-Bexport:$export_symbols $wl-h,$soname -o $lib $libobjs $deplibs $compiler_flags'\n\t    ;;\n\tesac\n      ;;\n\n      tandem*)\n        case $cc_basename in\n          NCC*)\n\t    # NonStop-UX NCC 3.20\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n          *)\n\t    # FIXME: insert proper C++ library support\n\t    _LT_TAGVAR(ld_shlibs, $1)=no\n\t    ;;\n        esac\n        ;;\n\n      vxworks*)\n        # FIXME: insert proper C++ library support\n        _LT_TAGVAR(ld_shlibs, $1)=no\n        ;;\n\n      *)\n        # FIXME: insert proper C++ library support\n        _LT_TAGVAR(ld_shlibs, $1)=no\n        ;;\n    esac\n\n    AC_MSG_RESULT([$_LT_TAGVAR(ld_shlibs, $1)])\n    test no = \"$_LT_TAGVAR(ld_shlibs, $1)\" && can_build_shared=no\n\n    _LT_TAGVAR(GCC, $1)=$GXX\n    _LT_TAGVAR(LD, $1)=$LD\n\n    ## CAVEAT EMPTOR:\n    ## There is no encapsulation within the following macros, do not change\n    ## the running order or otherwise move them around unless you know exactly\n    ## what you are doing...\n    _LT_SYS_HIDDEN_LIBDEPS($1)\n    _LT_COMPILER_PIC($1)\n    _LT_COMPILER_C_O($1)\n    _LT_COMPILER_FILE_LOCKS($1)\n    _LT_LINKER_SHLIBS($1)\n    _LT_SYS_DYNAMIC_LINKER($1)\n    _LT_LINKER_HARDCODE_LIBPATH($1)\n\n    _LT_CONFIG($1)\n  fi # test -n \"$compiler\"\n\n  CC=$lt_save_CC\n  CFLAGS=$lt_save_CFLAGS\n  LDCXX=$LD\n  LD=$lt_save_LD\n  GCC=$lt_save_GCC\n  with_gnu_ld=$lt_save_with_gnu_ld\n  lt_cv_path_LDCXX=$lt_cv_path_LD\n  lt_cv_path_LD=$lt_save_path_LD\n  lt_cv_prog_gnu_ldcxx=$lt_cv_prog_gnu_ld\n  lt_cv_prog_gnu_ld=$lt_save_with_gnu_ld\nfi # test yes != \"$_lt_caught_CXX_error\"\n\nAC_LANG_POP\n])# _LT_LANG_CXX_CONFIG\n\n\n# _LT_FUNC_STRIPNAME_CNF\n# ----------------------\n# func_stripname_cnf prefix suffix name\n# strip PREFIX and SUFFIX off of NAME.\n# PREFIX and SUFFIX must not contain globbing or regex special\n# characters, hashes, percent signs, but SUFFIX may contain a leading\n# dot (in which case that matches only a dot).\n#\n# This function is identical to the (non-XSI) version of func_stripname,\n# except this one can be used by m4 code that may be executed by configure,\n# rather than the libtool script.\nm4_defun([_LT_FUNC_STRIPNAME_CNF],[dnl\nAC_REQUIRE([_LT_DECL_SED])\nAC_REQUIRE([_LT_PROG_ECHO_BACKSLASH])\nfunc_stripname_cnf ()\n{\n  case @S|@2 in\n  .*) func_stripname_result=`$ECHO \"@S|@3\" | $SED \"s%^@S|@1%%; s%\\\\\\\\@S|@2\\$%%\"`;;\n  *)  func_stripname_result=`$ECHO \"@S|@3\" | $SED \"s%^@S|@1%%; s%@S|@2\\$%%\"`;;\n  esac\n} # func_stripname_cnf\n])# _LT_FUNC_STRIPNAME_CNF\n\n\n# _LT_SYS_HIDDEN_LIBDEPS([TAGNAME])\n# ---------------------------------\n# Figure out \"hidden\" library dependencies from verbose\n# compiler output when linking a shared library.\n# Parse the compiler output and extract the necessary\n# objects, libraries and library flags.\nm4_defun([_LT_SYS_HIDDEN_LIBDEPS],\n[m4_require([_LT_FILEUTILS_DEFAULTS])dnl\nAC_REQUIRE([_LT_FUNC_STRIPNAME_CNF])dnl\n# Dependencies to place before and after the object being linked:\n_LT_TAGVAR(predep_objects, $1)=\n_LT_TAGVAR(postdep_objects, $1)=\n_LT_TAGVAR(predeps, $1)=\n_LT_TAGVAR(postdeps, $1)=\n_LT_TAGVAR(compiler_lib_search_path, $1)=\n\ndnl we can't use the lt_simple_compile_test_code here,\ndnl because it contains code intended for an executable,\ndnl not a library.  It's possible we should let each\ndnl tag define a new lt_????_link_test_code variable,\ndnl but it's only used here...\nm4_if([$1], [], [cat > conftest.$ac_ext <<_LT_EOF\nint a;\nvoid foo (void) { a = 0; }\n_LT_EOF\n], [$1], [CXX], [cat > conftest.$ac_ext <<_LT_EOF\nclass Foo\n{\npublic:\n  Foo (void) { a = 0; }\nprivate:\n  int a;\n};\n_LT_EOF\n], [$1], [F77], [cat > conftest.$ac_ext <<_LT_EOF\n      subroutine foo\n      implicit none\n      integer*4 a\n      a=0\n      return\n      end\n_LT_EOF\n], [$1], [FC], [cat > conftest.$ac_ext <<_LT_EOF\n      subroutine foo\n      implicit none\n      integer a\n      a=0\n      return\n      end\n_LT_EOF\n], [$1], [GCJ], [cat > conftest.$ac_ext <<_LT_EOF\npublic class foo {\n  private int a;\n  public void bar (void) {\n    a = 0;\n  }\n};\n_LT_EOF\n], [$1], [GO], [cat > conftest.$ac_ext <<_LT_EOF\npackage foo\nfunc foo() {\n}\n_LT_EOF\n])\n\n_lt_libdeps_save_CFLAGS=$CFLAGS\ncase \"$CC $CFLAGS \" in #(\n*\\ -flto*\\ *) CFLAGS=\"$CFLAGS -fno-lto\" ;;\n*\\ -fwhopr*\\ *) CFLAGS=\"$CFLAGS -fno-whopr\" ;;\n*\\ -fuse-linker-plugin*\\ *) CFLAGS=\"$CFLAGS -fno-use-linker-plugin\" ;;\nesac\n\ndnl Parse the compiler output and extract the necessary\ndnl objects, libraries and library flags.\nif AC_TRY_EVAL(ac_compile); then\n  # Parse the compiler output and extract the necessary\n  # objects, libraries and library flags.\n\n  # Sentinel used to keep track of whether or not we are before\n  # the conftest object file.\n  pre_test_object_deps_done=no\n\n  for p in `eval \"$output_verbose_link_cmd\"`; do\n    case $prev$p in\n\n    -L* | -R* | -l*)\n       # Some compilers place space between \"-{L,R}\" and the path.\n       # Remove the space.\n       if test x-L = \"$p\" ||\n          test x-R = \"$p\"; then\n\t prev=$p\n\t continue\n       fi\n\n       # Expand the sysroot to ease extracting the directories later.\n       if test -z \"$prev\"; then\n         case $p in\n         -L*) func_stripname_cnf '-L' '' \"$p\"; prev=-L; p=$func_stripname_result ;;\n         -R*) func_stripname_cnf '-R' '' \"$p\"; prev=-R; p=$func_stripname_result ;;\n         -l*) func_stripname_cnf '-l' '' \"$p\"; prev=-l; p=$func_stripname_result ;;\n         esac\n       fi\n       case $p in\n       =*) func_stripname_cnf '=' '' \"$p\"; p=$lt_sysroot$func_stripname_result ;;\n       esac\n       if test no = \"$pre_test_object_deps_done\"; then\n\t case $prev in\n\t -L | -R)\n\t   # Internal compiler library paths should come after those\n\t   # provided the user.  The postdeps already come after the\n\t   # user supplied libs so there is no need to process them.\n\t   if test -z \"$_LT_TAGVAR(compiler_lib_search_path, $1)\"; then\n\t     _LT_TAGVAR(compiler_lib_search_path, $1)=$prev$p\n\t   else\n\t     _LT_TAGVAR(compiler_lib_search_path, $1)=\"${_LT_TAGVAR(compiler_lib_search_path, $1)} $prev$p\"\n\t   fi\n\t   ;;\n\t # The \"-l\" case would never come before the object being\n\t # linked, so don't bother handling this case.\n\t esac\n       else\n\t if test -z \"$_LT_TAGVAR(postdeps, $1)\"; then\n\t   _LT_TAGVAR(postdeps, $1)=$prev$p\n\t else\n\t   _LT_TAGVAR(postdeps, $1)=\"${_LT_TAGVAR(postdeps, $1)} $prev$p\"\n\t fi\n       fi\n       prev=\n       ;;\n\n    *.lto.$objext) ;; # Ignore GCC LTO objects\n    *.$objext)\n       # This assumes that the test object file only shows up\n       # once in the compiler output.\n       if test \"$p\" = \"conftest.$objext\"; then\n\t pre_test_object_deps_done=yes\n\t continue\n       fi\n\n       if test no = \"$pre_test_object_deps_done\"; then\n\t if test -z \"$_LT_TAGVAR(predep_objects, $1)\"; then\n\t   _LT_TAGVAR(predep_objects, $1)=$p\n\t else\n\t   _LT_TAGVAR(predep_objects, $1)=\"$_LT_TAGVAR(predep_objects, $1) $p\"\n\t fi\n       else\n\t if test -z \"$_LT_TAGVAR(postdep_objects, $1)\"; then\n\t   _LT_TAGVAR(postdep_objects, $1)=$p\n\t else\n\t   _LT_TAGVAR(postdep_objects, $1)=\"$_LT_TAGVAR(postdep_objects, $1) $p\"\n\t fi\n       fi\n       ;;\n\n    *) ;; # Ignore the rest.\n\n    esac\n  done\n\n  # Clean up.\n  rm -f a.out a.exe\nelse\n  echo \"libtool.m4: error: problem compiling $1 test program\"\nfi\n\n$RM -f confest.$objext\nCFLAGS=$_lt_libdeps_save_CFLAGS\n\n# PORTME: override above test on systems where it is broken\nm4_if([$1], [CXX],\n[case $host_os in\ninterix[[3-9]]*)\n  # Interix 3.5 installs completely hosed .la files for C++, so rather than\n  # hack all around it, let's just trust \"g++\" to DTRT.\n  _LT_TAGVAR(predep_objects,$1)=\n  _LT_TAGVAR(postdep_objects,$1)=\n  _LT_TAGVAR(postdeps,$1)=\n  ;;\nesac\n])\n\ncase \" $_LT_TAGVAR(postdeps, $1) \" in\n*\" -lc \"*) _LT_TAGVAR(archive_cmds_need_lc, $1)=no ;;\nesac\n _LT_TAGVAR(compiler_lib_search_dirs, $1)=\nif test -n \"${_LT_TAGVAR(compiler_lib_search_path, $1)}\"; then\n _LT_TAGVAR(compiler_lib_search_dirs, $1)=`echo \" ${_LT_TAGVAR(compiler_lib_search_path, $1)}\" | $SED -e 's! -L! !g' -e 's!^ !!'`\nfi\n_LT_TAGDECL([], [compiler_lib_search_dirs], [1],\n    [The directories searched by this compiler when creating a shared library])\n_LT_TAGDECL([], [predep_objects], [1],\n    [Dependencies to place before and after the objects being linked to\n    create a shared library])\n_LT_TAGDECL([], [postdep_objects], [1])\n_LT_TAGDECL([], [predeps], [1])\n_LT_TAGDECL([], [postdeps], [1])\n_LT_TAGDECL([], [compiler_lib_search_path], [1],\n    [The library search path used internally by the compiler when linking\n    a shared library])\n])# _LT_SYS_HIDDEN_LIBDEPS\n\n\n# _LT_LANG_F77_CONFIG([TAG])\n# --------------------------\n# Ensure that the configuration variables for a Fortran 77 compiler are\n# suitably defined.  These variables are subsequently used by _LT_CONFIG\n# to write the compiler configuration to 'libtool'.\nm4_defun([_LT_LANG_F77_CONFIG],\n[AC_LANG_PUSH(Fortran 77)\nif test -z \"$F77\" || test no = \"$F77\"; then\n  _lt_disable_F77=yes\nfi\n\n_LT_TAGVAR(archive_cmds_need_lc, $1)=no\n_LT_TAGVAR(allow_undefined_flag, $1)=\n_LT_TAGVAR(always_export_symbols, $1)=no\n_LT_TAGVAR(archive_expsym_cmds, $1)=\n_LT_TAGVAR(export_dynamic_flag_spec, $1)=\n_LT_TAGVAR(hardcode_direct, $1)=no\n_LT_TAGVAR(hardcode_direct_absolute, $1)=no\n_LT_TAGVAR(hardcode_libdir_flag_spec, $1)=\n_LT_TAGVAR(hardcode_libdir_separator, $1)=\n_LT_TAGVAR(hardcode_minus_L, $1)=no\n_LT_TAGVAR(hardcode_automatic, $1)=no\n_LT_TAGVAR(inherit_rpath, $1)=no\n_LT_TAGVAR(module_cmds, $1)=\n_LT_TAGVAR(module_expsym_cmds, $1)=\n_LT_TAGVAR(link_all_deplibs, $1)=unknown\n_LT_TAGVAR(old_archive_cmds, $1)=$old_archive_cmds\n_LT_TAGVAR(reload_flag, $1)=$reload_flag\n_LT_TAGVAR(reload_cmds, $1)=$reload_cmds\n_LT_TAGVAR(no_undefined_flag, $1)=\n_LT_TAGVAR(whole_archive_flag_spec, $1)=\n_LT_TAGVAR(enable_shared_with_static_runtimes, $1)=no\n\n# Source file extension for f77 test sources.\nac_ext=f\n\n# Object file extension for compiled f77 test sources.\nobjext=o\n_LT_TAGVAR(objext, $1)=$objext\n\n# No sense in running all these tests if we already determined that\n# the F77 compiler isn't working.  Some variables (like enable_shared)\n# are currently assumed to apply to all compilers on this platform,\n# and will be corrupted by setting them based on a non-working compiler.\nif test yes != \"$_lt_disable_F77\"; then\n  # Code to be used in simple compile tests\n  lt_simple_compile_test_code=\"\\\n      subroutine t\n      return\n      end\n\"\n\n  # Code to be used in simple link tests\n  lt_simple_link_test_code=\"\\\n      program t\n      end\n\"\n\n  # ltmain only uses $CC for tagged configurations so make sure $CC is set.\n  _LT_TAG_COMPILER\n\n  # save warnings/boilerplate of simple test code\n  _LT_COMPILER_BOILERPLATE\n  _LT_LINKER_BOILERPLATE\n\n  # Allow CC to be a program name with arguments.\n  lt_save_CC=$CC\n  lt_save_GCC=$GCC\n  lt_save_CFLAGS=$CFLAGS\n  CC=${F77-\"f77\"}\n  CFLAGS=$FFLAGS\n  compiler=$CC\n  _LT_TAGVAR(compiler, $1)=$CC\n  _LT_CC_BASENAME([$compiler])\n  GCC=$G77\n  if test -n \"$compiler\"; then\n    AC_MSG_CHECKING([if libtool supports shared libraries])\n    AC_MSG_RESULT([$can_build_shared])\n\n    AC_MSG_CHECKING([whether to build shared libraries])\n    test no = \"$can_build_shared\" && enable_shared=no\n\n    # On AIX, shared libraries and static libraries use the same namespace, and\n    # are all built from PIC.\n    case $host_os in\n      aix3*)\n        test yes = \"$enable_shared\" && enable_static=no\n        if test -n \"$RANLIB\"; then\n          archive_cmds=\"$archive_cmds~\\$RANLIB \\$lib\"\n          postinstall_cmds='$RANLIB $lib'\n        fi\n        ;;\n      aix[[4-9]]*)\n\tif test ia64 != \"$host_cpu\"; then\n\t  case $enable_shared,$with_aix_soname,$aix_use_runtimelinking in\n\t  yes,aix,yes) ;;\t\t# shared object as lib.so file only\n\t  yes,svr4,*) ;;\t\t# shared object as lib.so archive member only\n\t  yes,*) enable_static=no ;;\t# shared object in lib.a archive as well\n\t  esac\n\tfi\n        ;;\n    esac\n    AC_MSG_RESULT([$enable_shared])\n\n    AC_MSG_CHECKING([whether to build static libraries])\n    # Make sure either enable_shared or enable_static is yes.\n    test yes = \"$enable_shared\" || enable_static=yes\n    AC_MSG_RESULT([$enable_static])\n\n    _LT_TAGVAR(GCC, $1)=$G77\n    _LT_TAGVAR(LD, $1)=$LD\n\n    ## CAVEAT EMPTOR:\n    ## There is no encapsulation within the following macros, do not change\n    ## the running order or otherwise move them around unless you know exactly\n    ## what you are doing...\n    _LT_COMPILER_PIC($1)\n    _LT_COMPILER_C_O($1)\n    _LT_COMPILER_FILE_LOCKS($1)\n    _LT_LINKER_SHLIBS($1)\n    _LT_SYS_DYNAMIC_LINKER($1)\n    _LT_LINKER_HARDCODE_LIBPATH($1)\n\n    _LT_CONFIG($1)\n  fi # test -n \"$compiler\"\n\n  GCC=$lt_save_GCC\n  CC=$lt_save_CC\n  CFLAGS=$lt_save_CFLAGS\nfi # test yes != \"$_lt_disable_F77\"\n\nAC_LANG_POP\n])# _LT_LANG_F77_CONFIG\n\n\n# _LT_LANG_FC_CONFIG([TAG])\n# -------------------------\n# Ensure that the configuration variables for a Fortran compiler are\n# suitably defined.  These variables are subsequently used by _LT_CONFIG\n# to write the compiler configuration to 'libtool'.\nm4_defun([_LT_LANG_FC_CONFIG],\n[AC_LANG_PUSH(Fortran)\n\nif test -z \"$FC\" || test no = \"$FC\"; then\n  _lt_disable_FC=yes\nfi\n\n_LT_TAGVAR(archive_cmds_need_lc, $1)=no\n_LT_TAGVAR(allow_undefined_flag, $1)=\n_LT_TAGVAR(always_export_symbols, $1)=no\n_LT_TAGVAR(archive_expsym_cmds, $1)=\n_LT_TAGVAR(export_dynamic_flag_spec, $1)=\n_LT_TAGVAR(hardcode_direct, $1)=no\n_LT_TAGVAR(hardcode_direct_absolute, $1)=no\n_LT_TAGVAR(hardcode_libdir_flag_spec, $1)=\n_LT_TAGVAR(hardcode_libdir_separator, $1)=\n_LT_TAGVAR(hardcode_minus_L, $1)=no\n_LT_TAGVAR(hardcode_automatic, $1)=no\n_LT_TAGVAR(inherit_rpath, $1)=no\n_LT_TAGVAR(module_cmds, $1)=\n_LT_TAGVAR(module_expsym_cmds, $1)=\n_LT_TAGVAR(link_all_deplibs, $1)=unknown\n_LT_TAGVAR(old_archive_cmds, $1)=$old_archive_cmds\n_LT_TAGVAR(reload_flag, $1)=$reload_flag\n_LT_TAGVAR(reload_cmds, $1)=$reload_cmds\n_LT_TAGVAR(no_undefined_flag, $1)=\n_LT_TAGVAR(whole_archive_flag_spec, $1)=\n_LT_TAGVAR(enable_shared_with_static_runtimes, $1)=no\n\n# Source file extension for fc test sources.\nac_ext=${ac_fc_srcext-f}\n\n# Object file extension for compiled fc test sources.\nobjext=o\n_LT_TAGVAR(objext, $1)=$objext\n\n# No sense in running all these tests if we already determined that\n# the FC compiler isn't working.  Some variables (like enable_shared)\n# are currently assumed to apply to all compilers on this platform,\n# and will be corrupted by setting them based on a non-working compiler.\nif test yes != \"$_lt_disable_FC\"; then\n  # Code to be used in simple compile tests\n  lt_simple_compile_test_code=\"\\\n      subroutine t\n      return\n      end\n\"\n\n  # Code to be used in simple link tests\n  lt_simple_link_test_code=\"\\\n      program t\n      end\n\"\n\n  # ltmain only uses $CC for tagged configurations so make sure $CC is set.\n  _LT_TAG_COMPILER\n\n  # save warnings/boilerplate of simple test code\n  _LT_COMPILER_BOILERPLATE\n  _LT_LINKER_BOILERPLATE\n\n  # Allow CC to be a program name with arguments.\n  lt_save_CC=$CC\n  lt_save_GCC=$GCC\n  lt_save_CFLAGS=$CFLAGS\n  CC=${FC-\"f95\"}\n  CFLAGS=$FCFLAGS\n  compiler=$CC\n  GCC=$ac_cv_fc_compiler_gnu\n\n  _LT_TAGVAR(compiler, $1)=$CC\n  _LT_CC_BASENAME([$compiler])\n\n  if test -n \"$compiler\"; then\n    AC_MSG_CHECKING([if libtool supports shared libraries])\n    AC_MSG_RESULT([$can_build_shared])\n\n    AC_MSG_CHECKING([whether to build shared libraries])\n    test no = \"$can_build_shared\" && enable_shared=no\n\n    # On AIX, shared libraries and static libraries use the same namespace, and\n    # are all built from PIC.\n    case $host_os in\n      aix3*)\n        test yes = \"$enable_shared\" && enable_static=no\n        if test -n \"$RANLIB\"; then\n          archive_cmds=\"$archive_cmds~\\$RANLIB \\$lib\"\n          postinstall_cmds='$RANLIB $lib'\n        fi\n        ;;\n      aix[[4-9]]*)\n\tif test ia64 != \"$host_cpu\"; then\n\t  case $enable_shared,$with_aix_soname,$aix_use_runtimelinking in\n\t  yes,aix,yes) ;;\t\t# shared object as lib.so file only\n\t  yes,svr4,*) ;;\t\t# shared object as lib.so archive member only\n\t  yes,*) enable_static=no ;;\t# shared object in lib.a archive as well\n\t  esac\n\tfi\n        ;;\n    esac\n    AC_MSG_RESULT([$enable_shared])\n\n    AC_MSG_CHECKING([whether to build static libraries])\n    # Make sure either enable_shared or enable_static is yes.\n    test yes = \"$enable_shared\" || enable_static=yes\n    AC_MSG_RESULT([$enable_static])\n\n    _LT_TAGVAR(GCC, $1)=$ac_cv_fc_compiler_gnu\n    _LT_TAGVAR(LD, $1)=$LD\n\n    ## CAVEAT EMPTOR:\n    ## There is no encapsulation within the following macros, do not change\n    ## the running order or otherwise move them around unless you know exactly\n    ## what you are doing...\n    _LT_SYS_HIDDEN_LIBDEPS($1)\n    _LT_COMPILER_PIC($1)\n    _LT_COMPILER_C_O($1)\n    _LT_COMPILER_FILE_LOCKS($1)\n    _LT_LINKER_SHLIBS($1)\n    _LT_SYS_DYNAMIC_LINKER($1)\n    _LT_LINKER_HARDCODE_LIBPATH($1)\n\n    _LT_CONFIG($1)\n  fi # test -n \"$compiler\"\n\n  GCC=$lt_save_GCC\n  CC=$lt_save_CC\n  CFLAGS=$lt_save_CFLAGS\nfi # test yes != \"$_lt_disable_FC\"\n\nAC_LANG_POP\n])# _LT_LANG_FC_CONFIG\n\n\n# _LT_LANG_GCJ_CONFIG([TAG])\n# --------------------------\n# Ensure that the configuration variables for the GNU Java Compiler compiler\n# are suitably defined.  These variables are subsequently used by _LT_CONFIG\n# to write the compiler configuration to 'libtool'.\nm4_defun([_LT_LANG_GCJ_CONFIG],\n[AC_REQUIRE([LT_PROG_GCJ])dnl\nAC_LANG_SAVE\n\n# Source file extension for Java test sources.\nac_ext=java\n\n# Object file extension for compiled Java test sources.\nobjext=o\n_LT_TAGVAR(objext, $1)=$objext\n\n# Code to be used in simple compile tests\nlt_simple_compile_test_code=\"class foo {}\"\n\n# Code to be used in simple link tests\nlt_simple_link_test_code='public class conftest { public static void main(String[[]] argv) {}; }'\n\n# ltmain only uses $CC for tagged configurations so make sure $CC is set.\n_LT_TAG_COMPILER\n\n# save warnings/boilerplate of simple test code\n_LT_COMPILER_BOILERPLATE\n_LT_LINKER_BOILERPLATE\n\n# Allow CC to be a program name with arguments.\nlt_save_CC=$CC\nlt_save_CFLAGS=$CFLAGS\nlt_save_GCC=$GCC\nGCC=yes\nCC=${GCJ-\"gcj\"}\nCFLAGS=$GCJFLAGS\ncompiler=$CC\n_LT_TAGVAR(compiler, $1)=$CC\n_LT_TAGVAR(LD, $1)=$LD\n_LT_CC_BASENAME([$compiler])\n\n# GCJ did not exist at the time GCC didn't implicitly link libc in.\n_LT_TAGVAR(archive_cmds_need_lc, $1)=no\n\n_LT_TAGVAR(old_archive_cmds, $1)=$old_archive_cmds\n_LT_TAGVAR(reload_flag, $1)=$reload_flag\n_LT_TAGVAR(reload_cmds, $1)=$reload_cmds\n\n## CAVEAT EMPTOR:\n## There is no encapsulation within the following macros, do not change\n## the running order or otherwise move them around unless you know exactly\n## what you are doing...\nif test -n \"$compiler\"; then\n  _LT_COMPILER_NO_RTTI($1)\n  _LT_COMPILER_PIC($1)\n  _LT_COMPILER_C_O($1)\n  _LT_COMPILER_FILE_LOCKS($1)\n  _LT_LINKER_SHLIBS($1)\n  _LT_LINKER_HARDCODE_LIBPATH($1)\n\n  _LT_CONFIG($1)\nfi\n\nAC_LANG_RESTORE\n\nGCC=$lt_save_GCC\nCC=$lt_save_CC\nCFLAGS=$lt_save_CFLAGS\n])# _LT_LANG_GCJ_CONFIG\n\n\n# _LT_LANG_GO_CONFIG([TAG])\n# --------------------------\n# Ensure that the configuration variables for the GNU Go compiler\n# are suitably defined.  These variables are subsequently used by _LT_CONFIG\n# to write the compiler configuration to 'libtool'.\nm4_defun([_LT_LANG_GO_CONFIG],\n[AC_REQUIRE([LT_PROG_GO])dnl\nAC_LANG_SAVE\n\n# Source file extension for Go test sources.\nac_ext=go\n\n# Object file extension for compiled Go test sources.\nobjext=o\n_LT_TAGVAR(objext, $1)=$objext\n\n# Code to be used in simple compile tests\nlt_simple_compile_test_code=\"package main; func main() { }\"\n\n# Code to be used in simple link tests\nlt_simple_link_test_code='package main; func main() { }'\n\n# ltmain only uses $CC for tagged configurations so make sure $CC is set.\n_LT_TAG_COMPILER\n\n# save warnings/boilerplate of simple test code\n_LT_COMPILER_BOILERPLATE\n_LT_LINKER_BOILERPLATE\n\n# Allow CC to be a program name with arguments.\nlt_save_CC=$CC\nlt_save_CFLAGS=$CFLAGS\nlt_save_GCC=$GCC\nGCC=yes\nCC=${GOC-\"gccgo\"}\nCFLAGS=$GOFLAGS\ncompiler=$CC\n_LT_TAGVAR(compiler, $1)=$CC\n_LT_TAGVAR(LD, $1)=$LD\n_LT_CC_BASENAME([$compiler])\n\n# Go did not exist at the time GCC didn't implicitly link libc in.\n_LT_TAGVAR(archive_cmds_need_lc, $1)=no\n\n_LT_TAGVAR(old_archive_cmds, $1)=$old_archive_cmds\n_LT_TAGVAR(reload_flag, $1)=$reload_flag\n_LT_TAGVAR(reload_cmds, $1)=$reload_cmds\n\n## CAVEAT EMPTOR:\n## There is no encapsulation within the following macros, do not change\n## the running order or otherwise move them around unless you know exactly\n## what you are doing...\nif test -n \"$compiler\"; then\n  _LT_COMPILER_NO_RTTI($1)\n  _LT_COMPILER_PIC($1)\n  _LT_COMPILER_C_O($1)\n  _LT_COMPILER_FILE_LOCKS($1)\n  _LT_LINKER_SHLIBS($1)\n  _LT_LINKER_HARDCODE_LIBPATH($1)\n\n  _LT_CONFIG($1)\nfi\n\nAC_LANG_RESTORE\n\nGCC=$lt_save_GCC\nCC=$lt_save_CC\nCFLAGS=$lt_save_CFLAGS\n])# _LT_LANG_GO_CONFIG\n\n\n# _LT_LANG_RC_CONFIG([TAG])\n# -------------------------\n# Ensure that the configuration variables for the Windows resource compiler\n# are suitably defined.  These variables are subsequently used by _LT_CONFIG\n# to write the compiler configuration to 'libtool'.\nm4_defun([_LT_LANG_RC_CONFIG],\n[AC_REQUIRE([LT_PROG_RC])dnl\nAC_LANG_SAVE\n\n# Source file extension for RC test sources.\nac_ext=rc\n\n# Object file extension for compiled RC test sources.\nobjext=o\n_LT_TAGVAR(objext, $1)=$objext\n\n# Code to be used in simple compile tests\nlt_simple_compile_test_code='sample MENU { MENUITEM \"&Soup\", 100, CHECKED }'\n\n# Code to be used in simple link tests\nlt_simple_link_test_code=$lt_simple_compile_test_code\n\n# ltmain only uses $CC for tagged configurations so make sure $CC is set.\n_LT_TAG_COMPILER\n\n# save warnings/boilerplate of simple test code\n_LT_COMPILER_BOILERPLATE\n_LT_LINKER_BOILERPLATE\n\n# Allow CC to be a program name with arguments.\nlt_save_CC=$CC\nlt_save_CFLAGS=$CFLAGS\nlt_save_GCC=$GCC\nGCC=\nCC=${RC-\"windres\"}\nCFLAGS=\ncompiler=$CC\n_LT_TAGVAR(compiler, $1)=$CC\n_LT_CC_BASENAME([$compiler])\n_LT_TAGVAR(lt_cv_prog_compiler_c_o, $1)=yes\n\nif test -n \"$compiler\"; then\n  :\n  _LT_CONFIG($1)\nfi\n\nGCC=$lt_save_GCC\nAC_LANG_RESTORE\nCC=$lt_save_CC\nCFLAGS=$lt_save_CFLAGS\n])# _LT_LANG_RC_CONFIG\n\n\n# LT_PROG_GCJ\n# -----------\nAC_DEFUN([LT_PROG_GCJ],\n[m4_ifdef([AC_PROG_GCJ], [AC_PROG_GCJ],\n  [m4_ifdef([A][M_PROG_GCJ], [A][M_PROG_GCJ],\n    [AC_CHECK_TOOL(GCJ, gcj,)\n      test set = \"${GCJFLAGS+set}\" || GCJFLAGS=\"-g -O2\"\n      AC_SUBST(GCJFLAGS)])])[]dnl\n])\n\n# Old name:\nAU_ALIAS([LT_AC_PROG_GCJ], [LT_PROG_GCJ])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([LT_AC_PROG_GCJ], [])\n\n\n# LT_PROG_GO\n# ----------\nAC_DEFUN([LT_PROG_GO],\n[AC_CHECK_TOOL(GOC, gccgo,)\n])\n\n\n# LT_PROG_RC\n# ----------\nAC_DEFUN([LT_PROG_RC],\n[AC_CHECK_TOOL(RC, windres,)\n])\n\n# Old name:\nAU_ALIAS([LT_AC_PROG_RC], [LT_PROG_RC])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([LT_AC_PROG_RC], [])\n\n\n# _LT_DECL_EGREP\n# --------------\n# If we don't have a new enough Autoconf to choose the best grep\n# available, choose the one first in the user's PATH.\nm4_defun([_LT_DECL_EGREP],\n[AC_REQUIRE([AC_PROG_EGREP])dnl\nAC_REQUIRE([AC_PROG_FGREP])dnl\ntest -z \"$GREP\" && GREP=grep\n_LT_DECL([], [GREP], [1], [A grep program that handles long lines])\n_LT_DECL([], [EGREP], [1], [An ERE matcher])\n_LT_DECL([], [FGREP], [1], [A literal string matcher])\ndnl Non-bleeding-edge autoconf doesn't subst GREP, so do it here too\nAC_SUBST([GREP])\n])\n\n\n# _LT_DECL_OBJDUMP\n# --------------\n# If we don't have a new enough Autoconf to choose the best objdump\n# available, choose the one first in the user's PATH.\nm4_defun([_LT_DECL_OBJDUMP],\n[AC_CHECK_TOOL(OBJDUMP, objdump, false)\ntest -z \"$OBJDUMP\" && OBJDUMP=objdump\n_LT_DECL([], [OBJDUMP], [1], [An object symbol dumper])\nAC_SUBST([OBJDUMP])\n])\n\n# _LT_DECL_DLLTOOL\n# ----------------\n# Ensure DLLTOOL variable is set.\nm4_defun([_LT_DECL_DLLTOOL],\n[AC_CHECK_TOOL(DLLTOOL, dlltool, false)\ntest -z \"$DLLTOOL\" && DLLTOOL=dlltool\n_LT_DECL([], [DLLTOOL], [1], [DLL creation program])\nAC_SUBST([DLLTOOL])\n])\n\n# _LT_DECL_SED\n# ------------\n# Check for a fully-functional sed program, that truncates\n# as few characters as possible.  Prefer GNU sed if found.\nm4_defun([_LT_DECL_SED],\n[AC_PROG_SED\ntest -z \"$SED\" && SED=sed\nXsed=\"$SED -e 1s/^X//\"\n_LT_DECL([], [SED], [1], [A sed program that does not truncate output])\n_LT_DECL([], [Xsed], [\"\\$SED -e 1s/^X//\"],\n    [Sed that helps us avoid accidentally triggering echo(1) options like -n])\n])# _LT_DECL_SED\n\nm4_ifndef([AC_PROG_SED], [\n############################################################\n# NOTE: This macro has been submitted for inclusion into   #\n#  GNU Autoconf as AC_PROG_SED.  When it is available in   #\n#  a released version of Autoconf we should remove this    #\n#  macro and use it instead.                               #\n############################################################\n\nm4_defun([AC_PROG_SED],\n[AC_MSG_CHECKING([for a sed that does not truncate output])\nAC_CACHE_VAL(lt_cv_path_SED,\n[# Loop through the user's path and test for sed and gsed.\n# Then use that list of sed's as ones to test for truncation.\nas_save_IFS=$IFS; IFS=$PATH_SEPARATOR\nfor as_dir in $PATH\ndo\n  IFS=$as_save_IFS\n  test -z \"$as_dir\" && as_dir=.\n  for lt_ac_prog in sed gsed; do\n    for ac_exec_ext in '' $ac_executable_extensions; do\n      if $as_executable_p \"$as_dir/$lt_ac_prog$ac_exec_ext\"; then\n        lt_ac_sed_list=\"$lt_ac_sed_list $as_dir/$lt_ac_prog$ac_exec_ext\"\n      fi\n    done\n  done\ndone\nIFS=$as_save_IFS\nlt_ac_max=0\nlt_ac_count=0\n# Add /usr/xpg4/bin/sed as it is typically found on Solaris\n# along with /bin/sed that truncates output.\nfor lt_ac_sed in $lt_ac_sed_list /usr/xpg4/bin/sed; do\n  test ! -f \"$lt_ac_sed\" && continue\n  cat /dev/null > conftest.in\n  lt_ac_count=0\n  echo $ECHO_N \"0123456789$ECHO_C\" >conftest.in\n  # Check for GNU sed and select it if it is found.\n  if \"$lt_ac_sed\" --version 2>&1 < /dev/null | grep 'GNU' > /dev/null; then\n    lt_cv_path_SED=$lt_ac_sed\n    break\n  fi\n  while true; do\n    cat conftest.in conftest.in >conftest.tmp\n    mv conftest.tmp conftest.in\n    cp conftest.in conftest.nl\n    echo >>conftest.nl\n    $lt_ac_sed -e 's/a$//' < conftest.nl >conftest.out || break\n    cmp -s conftest.out conftest.nl || break\n    # 10000 chars as input seems more than enough\n    test 10 -lt \"$lt_ac_count\" && break\n    lt_ac_count=`expr $lt_ac_count + 1`\n    if test \"$lt_ac_count\" -gt \"$lt_ac_max\"; then\n      lt_ac_max=$lt_ac_count\n      lt_cv_path_SED=$lt_ac_sed\n    fi\n  done\ndone\n])\nSED=$lt_cv_path_SED\nAC_SUBST([SED])\nAC_MSG_RESULT([$SED])\n])#AC_PROG_SED\n])#m4_ifndef\n\n# Old name:\nAU_ALIAS([LT_AC_PROG_SED], [AC_PROG_SED])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([LT_AC_PROG_SED], [])\n\n\n# _LT_CHECK_SHELL_FEATURES\n# ------------------------\n# Find out whether the shell is Bourne or XSI compatible,\n# or has some other useful features.\nm4_defun([_LT_CHECK_SHELL_FEATURES],\n[if ( (MAIL=60; unset MAIL) || exit) >/dev/null 2>&1; then\n  lt_unset=unset\nelse\n  lt_unset=false\nfi\n_LT_DECL([], [lt_unset], [0], [whether the shell understands \"unset\"])dnl\n\n# test EBCDIC or ASCII\ncase `echo X|tr X '\\101'` in\n A) # ASCII based system\n    # \\n is not interpreted correctly by Solaris 8 /usr/ucb/tr\n  lt_SP2NL='tr \\040 \\012'\n  lt_NL2SP='tr \\015\\012 \\040\\040'\n  ;;\n *) # EBCDIC based system\n  lt_SP2NL='tr \\100 \\n'\n  lt_NL2SP='tr \\r\\n \\100\\100'\n  ;;\nesac\n_LT_DECL([SP2NL], [lt_SP2NL], [1], [turn spaces into newlines])dnl\n_LT_DECL([NL2SP], [lt_NL2SP], [1], [turn newlines into spaces])dnl\n])# _LT_CHECK_SHELL_FEATURES\n\n\n# _LT_PATH_CONVERSION_FUNCTIONS\n# -----------------------------\n# Determine what file name conversion functions should be used by\n# func_to_host_file (and, implicitly, by func_to_host_path).  These are needed\n# for certain cross-compile configurations and native mingw.\nm4_defun([_LT_PATH_CONVERSION_FUNCTIONS],\n[AC_REQUIRE([AC_CANONICAL_HOST])dnl\nAC_REQUIRE([AC_CANONICAL_BUILD])dnl\nAC_MSG_CHECKING([how to convert $build file names to $host format])\nAC_CACHE_VAL(lt_cv_to_host_file_cmd,\n[case $host in\n  *-*-mingw* )\n    case $build in\n      *-*-mingw* ) # actually msys\n        lt_cv_to_host_file_cmd=func_convert_file_msys_to_w32\n        ;;\n      *-*-cygwin* )\n        lt_cv_to_host_file_cmd=func_convert_file_cygwin_to_w32\n        ;;\n      * ) # otherwise, assume *nix\n        lt_cv_to_host_file_cmd=func_convert_file_nix_to_w32\n        ;;\n    esac\n    ;;\n  *-*-cygwin* )\n    case $build in\n      *-*-mingw* ) # actually msys\n        lt_cv_to_host_file_cmd=func_convert_file_msys_to_cygwin\n        ;;\n      *-*-cygwin* )\n        lt_cv_to_host_file_cmd=func_convert_file_noop\n        ;;\n      * ) # otherwise, assume *nix\n        lt_cv_to_host_file_cmd=func_convert_file_nix_to_cygwin\n        ;;\n    esac\n    ;;\n  * ) # unhandled hosts (and \"normal\" native builds)\n    lt_cv_to_host_file_cmd=func_convert_file_noop\n    ;;\nesac\n])\nto_host_file_cmd=$lt_cv_to_host_file_cmd\nAC_MSG_RESULT([$lt_cv_to_host_file_cmd])\n_LT_DECL([to_host_file_cmd], [lt_cv_to_host_file_cmd],\n         [0], [convert $build file names to $host format])dnl\n\nAC_MSG_CHECKING([how to convert $build file names to toolchain format])\nAC_CACHE_VAL(lt_cv_to_tool_file_cmd,\n[#assume ordinary cross tools, or native build.\nlt_cv_to_tool_file_cmd=func_convert_file_noop\ncase $host in\n  *-*-mingw* )\n    case $build in\n      *-*-mingw* ) # actually msys\n        lt_cv_to_tool_file_cmd=func_convert_file_msys_to_w32\n        ;;\n    esac\n    ;;\nesac\n])\nto_tool_file_cmd=$lt_cv_to_tool_file_cmd\nAC_MSG_RESULT([$lt_cv_to_tool_file_cmd])\n_LT_DECL([to_tool_file_cmd], [lt_cv_to_tool_file_cmd],\n         [0], [convert $build files to toolchain format])dnl\n])# _LT_PATH_CONVERSION_FUNCTIONS\n",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/m4/ltoptions.m4": "# Helper functions for option handling.                    -*- Autoconf -*-\n#\n#   Copyright (C) 2004-2005, 2007-2009, 2011-2015 Free Software\n#   Foundation, Inc.\n#   Written by Gary V. Vaughan, 2004\n#\n# This file is free software; the Free Software Foundation gives\n# unlimited permission to copy and/or distribute it, with or without\n# modifications, as long as this notice is preserved.\n\n# serial 8 ltoptions.m4\n\n# This is to help aclocal find these macros, as it can't see m4_define.\nAC_DEFUN([LTOPTIONS_VERSION], [m4_if([1])])\n\n\n# _LT_MANGLE_OPTION(MACRO-NAME, OPTION-NAME)\n# ------------------------------------------\nm4_define([_LT_MANGLE_OPTION],\n[[_LT_OPTION_]m4_bpatsubst($1__$2, [[^a-zA-Z0-9_]], [_])])\n\n\n# _LT_SET_OPTION(MACRO-NAME, OPTION-NAME)\n# ---------------------------------------\n# Set option OPTION-NAME for macro MACRO-NAME, and if there is a\n# matching handler defined, dispatch to it.  Other OPTION-NAMEs are\n# saved as a flag.\nm4_define([_LT_SET_OPTION],\n[m4_define(_LT_MANGLE_OPTION([$1], [$2]))dnl\nm4_ifdef(_LT_MANGLE_DEFUN([$1], [$2]),\n        _LT_MANGLE_DEFUN([$1], [$2]),\n    [m4_warning([Unknown $1 option '$2'])])[]dnl\n])\n\n\n# _LT_IF_OPTION(MACRO-NAME, OPTION-NAME, IF-SET, [IF-NOT-SET])\n# ------------------------------------------------------------\n# Execute IF-SET if OPTION is set, IF-NOT-SET otherwise.\nm4_define([_LT_IF_OPTION],\n[m4_ifdef(_LT_MANGLE_OPTION([$1], [$2]), [$3], [$4])])\n\n\n# _LT_UNLESS_OPTIONS(MACRO-NAME, OPTION-LIST, IF-NOT-SET)\n# -------------------------------------------------------\n# Execute IF-NOT-SET unless all options in OPTION-LIST for MACRO-NAME\n# are set.\nm4_define([_LT_UNLESS_OPTIONS],\n[m4_foreach([_LT_Option], m4_split(m4_normalize([$2])),\n\t    [m4_ifdef(_LT_MANGLE_OPTION([$1], _LT_Option),\n\t\t      [m4_define([$0_found])])])[]dnl\nm4_ifdef([$0_found], [m4_undefine([$0_found])], [$3\n])[]dnl\n])\n\n\n# _LT_SET_OPTIONS(MACRO-NAME, OPTION-LIST)\n# ----------------------------------------\n# OPTION-LIST is a space-separated list of Libtool options associated\n# with MACRO-NAME.  If any OPTION has a matching handler declared with\n# LT_OPTION_DEFINE, dispatch to that macro; otherwise complain about\n# the unknown option and exit.\nm4_defun([_LT_SET_OPTIONS],\n[# Set options\nm4_foreach([_LT_Option], m4_split(m4_normalize([$2])),\n    [_LT_SET_OPTION([$1], _LT_Option)])\n\nm4_if([$1],[LT_INIT],[\n  dnl\n  dnl Simply set some default values (i.e off) if boolean options were not\n  dnl specified:\n  _LT_UNLESS_OPTIONS([LT_INIT], [dlopen], [enable_dlopen=no\n  ])\n  _LT_UNLESS_OPTIONS([LT_INIT], [win32-dll], [enable_win32_dll=no\n  ])\n  dnl\n  dnl If no reference was made to various pairs of opposing options, then\n  dnl we run the default mode handler for the pair.  For example, if neither\n  dnl 'shared' nor 'disable-shared' was passed, we enable building of shared\n  dnl archives by default:\n  _LT_UNLESS_OPTIONS([LT_INIT], [shared disable-shared], [_LT_ENABLE_SHARED])\n  _LT_UNLESS_OPTIONS([LT_INIT], [static disable-static], [_LT_ENABLE_STATIC])\n  _LT_UNLESS_OPTIONS([LT_INIT], [pic-only no-pic], [_LT_WITH_PIC])\n  _LT_UNLESS_OPTIONS([LT_INIT], [fast-install disable-fast-install],\n\t\t   [_LT_ENABLE_FAST_INSTALL])\n  _LT_UNLESS_OPTIONS([LT_INIT], [aix-soname=aix aix-soname=both aix-soname=svr4],\n\t\t   [_LT_WITH_AIX_SONAME([aix])])\n  ])\n])# _LT_SET_OPTIONS\n\n\n## --------------------------------- ##\n## Macros to handle LT_INIT options. ##\n## --------------------------------- ##\n\n# _LT_MANGLE_DEFUN(MACRO-NAME, OPTION-NAME)\n# -----------------------------------------\nm4_define([_LT_MANGLE_DEFUN],\n[[_LT_OPTION_DEFUN_]m4_bpatsubst(m4_toupper([$1__$2]), [[^A-Z0-9_]], [_])])\n\n\n# LT_OPTION_DEFINE(MACRO-NAME, OPTION-NAME, CODE)\n# -----------------------------------------------\nm4_define([LT_OPTION_DEFINE],\n[m4_define(_LT_MANGLE_DEFUN([$1], [$2]), [$3])[]dnl\n])# LT_OPTION_DEFINE\n\n\n# dlopen\n# ------\nLT_OPTION_DEFINE([LT_INIT], [dlopen], [enable_dlopen=yes\n])\n\nAU_DEFUN([AC_LIBTOOL_DLOPEN],\n[_LT_SET_OPTION([LT_INIT], [dlopen])\nAC_DIAGNOSE([obsolete],\n[$0: Remove this warning and the call to _LT_SET_OPTION when you\nput the 'dlopen' option into LT_INIT's first parameter.])\n])\n\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_LIBTOOL_DLOPEN], [])\n\n\n# win32-dll\n# ---------\n# Declare package support for building win32 dll's.\nLT_OPTION_DEFINE([LT_INIT], [win32-dll],\n[enable_win32_dll=yes\n\ncase $host in\n*-*-cygwin* | *-*-mingw* | *-*-pw32* | *-*-cegcc*)\n  AC_CHECK_TOOL(AS, as, false)\n  AC_CHECK_TOOL(DLLTOOL, dlltool, false)\n  AC_CHECK_TOOL(OBJDUMP, objdump, false)\n  ;;\nesac\n\ntest -z \"$AS\" && AS=as\n_LT_DECL([], [AS],      [1], [Assembler program])dnl\n\ntest -z \"$DLLTOOL\" && DLLTOOL=dlltool\n_LT_DECL([], [DLLTOOL], [1], [DLL creation program])dnl\n\ntest -z \"$OBJDUMP\" && OBJDUMP=objdump\n_LT_DECL([], [OBJDUMP], [1], [Object dumper program])dnl\n])# win32-dll\n\nAU_DEFUN([AC_LIBTOOL_WIN32_DLL],\n[AC_REQUIRE([AC_CANONICAL_HOST])dnl\n_LT_SET_OPTION([LT_INIT], [win32-dll])\nAC_DIAGNOSE([obsolete],\n[$0: Remove this warning and the call to _LT_SET_OPTION when you\nput the 'win32-dll' option into LT_INIT's first parameter.])\n])\n\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_LIBTOOL_WIN32_DLL], [])\n\n\n# _LT_ENABLE_SHARED([DEFAULT])\n# ----------------------------\n# implement the --enable-shared flag, and supports the 'shared' and\n# 'disable-shared' LT_INIT options.\n# DEFAULT is either 'yes' or 'no'.  If omitted, it defaults to 'yes'.\nm4_define([_LT_ENABLE_SHARED],\n[m4_define([_LT_ENABLE_SHARED_DEFAULT], [m4_if($1, no, no, yes)])dnl\nAC_ARG_ENABLE([shared],\n    [AS_HELP_STRING([--enable-shared@<:@=PKGS@:>@],\n\t[build shared libraries @<:@default=]_LT_ENABLE_SHARED_DEFAULT[@:>@])],\n    [p=${PACKAGE-default}\n    case $enableval in\n    yes) enable_shared=yes ;;\n    no) enable_shared=no ;;\n    *)\n      enable_shared=no\n      # Look at the argument we got.  We use all the common list separators.\n      lt_save_ifs=$IFS; IFS=$IFS$PATH_SEPARATOR,\n      for pkg in $enableval; do\n\tIFS=$lt_save_ifs\n\tif test \"X$pkg\" = \"X$p\"; then\n\t  enable_shared=yes\n\tfi\n      done\n      IFS=$lt_save_ifs\n      ;;\n    esac],\n    [enable_shared=]_LT_ENABLE_SHARED_DEFAULT)\n\n    _LT_DECL([build_libtool_libs], [enable_shared], [0],\n\t[Whether or not to build shared libraries])\n])# _LT_ENABLE_SHARED\n\nLT_OPTION_DEFINE([LT_INIT], [shared], [_LT_ENABLE_SHARED([yes])])\nLT_OPTION_DEFINE([LT_INIT], [disable-shared], [_LT_ENABLE_SHARED([no])])\n\n# Old names:\nAC_DEFUN([AC_ENABLE_SHARED],\n[_LT_SET_OPTION([LT_INIT], m4_if([$1], [no], [disable-])[shared])\n])\n\nAC_DEFUN([AC_DISABLE_SHARED],\n[_LT_SET_OPTION([LT_INIT], [disable-shared])\n])\n\nAU_DEFUN([AM_ENABLE_SHARED], [AC_ENABLE_SHARED($@)])\nAU_DEFUN([AM_DISABLE_SHARED], [AC_DISABLE_SHARED($@)])\n\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AM_ENABLE_SHARED], [])\ndnl AC_DEFUN([AM_DISABLE_SHARED], [])\n\n\n\n# _LT_ENABLE_STATIC([DEFAULT])\n# ----------------------------\n# implement the --enable-static flag, and support the 'static' and\n# 'disable-static' LT_INIT options.\n# DEFAULT is either 'yes' or 'no'.  If omitted, it defaults to 'yes'.\nm4_define([_LT_ENABLE_STATIC],\n[m4_define([_LT_ENABLE_STATIC_DEFAULT], [m4_if($1, no, no, yes)])dnl\nAC_ARG_ENABLE([static],\n    [AS_HELP_STRING([--enable-static@<:@=PKGS@:>@],\n\t[build static libraries @<:@default=]_LT_ENABLE_STATIC_DEFAULT[@:>@])],\n    [p=${PACKAGE-default}\n    case $enableval in\n    yes) enable_static=yes ;;\n    no) enable_static=no ;;\n    *)\n     enable_static=no\n      # Look at the argument we got.  We use all the common list separators.\n      lt_save_ifs=$IFS; IFS=$IFS$PATH_SEPARATOR,\n      for pkg in $enableval; do\n\tIFS=$lt_save_ifs\n\tif test \"X$pkg\" = \"X$p\"; then\n\t  enable_static=yes\n\tfi\n      done\n      IFS=$lt_save_ifs\n      ;;\n    esac],\n    [enable_static=]_LT_ENABLE_STATIC_DEFAULT)\n\n    _LT_DECL([build_old_libs], [enable_static], [0],\n\t[Whether or not to build static libraries])\n])# _LT_ENABLE_STATIC\n\nLT_OPTION_DEFINE([LT_INIT], [static], [_LT_ENABLE_STATIC([yes])])\nLT_OPTION_DEFINE([LT_INIT], [disable-static], [_LT_ENABLE_STATIC([no])])\n\n# Old names:\nAC_DEFUN([AC_ENABLE_STATIC],\n[_LT_SET_OPTION([LT_INIT], m4_if([$1], [no], [disable-])[static])\n])\n\nAC_DEFUN([AC_DISABLE_STATIC],\n[_LT_SET_OPTION([LT_INIT], [disable-static])\n])\n\nAU_DEFUN([AM_ENABLE_STATIC], [AC_ENABLE_STATIC($@)])\nAU_DEFUN([AM_DISABLE_STATIC], [AC_DISABLE_STATIC($@)])\n\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AM_ENABLE_STATIC], [])\ndnl AC_DEFUN([AM_DISABLE_STATIC], [])\n\n\n\n# _LT_ENABLE_FAST_INSTALL([DEFAULT])\n# ----------------------------------\n# implement the --enable-fast-install flag, and support the 'fast-install'\n# and 'disable-fast-install' LT_INIT options.\n# DEFAULT is either 'yes' or 'no'.  If omitted, it defaults to 'yes'.\nm4_define([_LT_ENABLE_FAST_INSTALL],\n[m4_define([_LT_ENABLE_FAST_INSTALL_DEFAULT], [m4_if($1, no, no, yes)])dnl\nAC_ARG_ENABLE([fast-install],\n    [AS_HELP_STRING([--enable-fast-install@<:@=PKGS@:>@],\n    [optimize for fast installation @<:@default=]_LT_ENABLE_FAST_INSTALL_DEFAULT[@:>@])],\n    [p=${PACKAGE-default}\n    case $enableval in\n    yes) enable_fast_install=yes ;;\n    no) enable_fast_install=no ;;\n    *)\n      enable_fast_install=no\n      # Look at the argument we got.  We use all the common list separators.\n      lt_save_ifs=$IFS; IFS=$IFS$PATH_SEPARATOR,\n      for pkg in $enableval; do\n\tIFS=$lt_save_ifs\n\tif test \"X$pkg\" = \"X$p\"; then\n\t  enable_fast_install=yes\n\tfi\n      done\n      IFS=$lt_save_ifs\n      ;;\n    esac],\n    [enable_fast_install=]_LT_ENABLE_FAST_INSTALL_DEFAULT)\n\n_LT_DECL([fast_install], [enable_fast_install], [0],\n\t [Whether or not to optimize for fast installation])dnl\n])# _LT_ENABLE_FAST_INSTALL\n\nLT_OPTION_DEFINE([LT_INIT], [fast-install], [_LT_ENABLE_FAST_INSTALL([yes])])\nLT_OPTION_DEFINE([LT_INIT], [disable-fast-install], [_LT_ENABLE_FAST_INSTALL([no])])\n\n# Old names:\nAU_DEFUN([AC_ENABLE_FAST_INSTALL],\n[_LT_SET_OPTION([LT_INIT], m4_if([$1], [no], [disable-])[fast-install])\nAC_DIAGNOSE([obsolete],\n[$0: Remove this warning and the call to _LT_SET_OPTION when you put\nthe 'fast-install' option into LT_INIT's first parameter.])\n])\n\nAU_DEFUN([AC_DISABLE_FAST_INSTALL],\n[_LT_SET_OPTION([LT_INIT], [disable-fast-install])\nAC_DIAGNOSE([obsolete],\n[$0: Remove this warning and the call to _LT_SET_OPTION when you put\nthe 'disable-fast-install' option into LT_INIT's first parameter.])\n])\n\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_ENABLE_FAST_INSTALL], [])\ndnl AC_DEFUN([AM_DISABLE_FAST_INSTALL], [])\n\n\n# _LT_WITH_AIX_SONAME([DEFAULT])\n# ----------------------------------\n# implement the --with-aix-soname flag, and support the `aix-soname=aix'\n# and `aix-soname=both' and `aix-soname=svr4' LT_INIT options. DEFAULT\n# is either `aix', `both' or `svr4'.  If omitted, it defaults to `aix'.\nm4_define([_LT_WITH_AIX_SONAME],\n[m4_define([_LT_WITH_AIX_SONAME_DEFAULT], [m4_if($1, svr4, svr4, m4_if($1, both, both, aix))])dnl\nshared_archive_member_spec=\ncase $host,$enable_shared in\npower*-*-aix[[5-9]]*,yes)\n  AC_MSG_CHECKING([which variant of shared library versioning to provide])\n  AC_ARG_WITH([aix-soname],\n    [AS_HELP_STRING([--with-aix-soname=aix|svr4|both],\n      [shared library versioning (aka \"SONAME\") variant to provide on AIX, @<:@default=]_LT_WITH_AIX_SONAME_DEFAULT[@:>@.])],\n    [case $withval in\n    aix|svr4|both)\n      ;;\n    *)\n      AC_MSG_ERROR([Unknown argument to --with-aix-soname])\n      ;;\n    esac\n    lt_cv_with_aix_soname=$with_aix_soname],\n    [AC_CACHE_VAL([lt_cv_with_aix_soname],\n      [lt_cv_with_aix_soname=]_LT_WITH_AIX_SONAME_DEFAULT)\n    with_aix_soname=$lt_cv_with_aix_soname])\n  AC_MSG_RESULT([$with_aix_soname])\n  if test aix != \"$with_aix_soname\"; then\n    # For the AIX way of multilib, we name the shared archive member\n    # based on the bitwidth used, traditionally 'shr.o' or 'shr_64.o',\n    # and 'shr.imp' or 'shr_64.imp', respectively, for the Import File.\n    # Even when GNU compilers ignore OBJECT_MODE but need '-maix64' flag,\n    # the AIX toolchain works better with OBJECT_MODE set (default 32).\n    if test 64 = \"${OBJECT_MODE-32}\"; then\n      shared_archive_member_spec=shr_64\n    else\n      shared_archive_member_spec=shr\n    fi\n  fi\n  ;;\n*)\n  with_aix_soname=aix\n  ;;\nesac\n\n_LT_DECL([], [shared_archive_member_spec], [0],\n    [Shared archive member basename, for filename based shared library versioning on AIX])dnl\n])# _LT_WITH_AIX_SONAME\n\nLT_OPTION_DEFINE([LT_INIT], [aix-soname=aix], [_LT_WITH_AIX_SONAME([aix])])\nLT_OPTION_DEFINE([LT_INIT], [aix-soname=both], [_LT_WITH_AIX_SONAME([both])])\nLT_OPTION_DEFINE([LT_INIT], [aix-soname=svr4], [_LT_WITH_AIX_SONAME([svr4])])\n\n\n# _LT_WITH_PIC([MODE])\n# --------------------\n# implement the --with-pic flag, and support the 'pic-only' and 'no-pic'\n# LT_INIT options.\n# MODE is either 'yes' or 'no'.  If omitted, it defaults to 'both'.\nm4_define([_LT_WITH_PIC],\n[AC_ARG_WITH([pic],\n    [AS_HELP_STRING([--with-pic@<:@=PKGS@:>@],\n\t[try to use only PIC/non-PIC objects @<:@default=use both@:>@])],\n    [lt_p=${PACKAGE-default}\n    case $withval in\n    yes|no) pic_mode=$withval ;;\n    *)\n      pic_mode=default\n      # Look at the argument we got.  We use all the common list separators.\n      lt_save_ifs=$IFS; IFS=$IFS$PATH_SEPARATOR,\n      for lt_pkg in $withval; do\n\tIFS=$lt_save_ifs\n\tif test \"X$lt_pkg\" = \"X$lt_p\"; then\n\t  pic_mode=yes\n\tfi\n      done\n      IFS=$lt_save_ifs\n      ;;\n    esac],\n    [pic_mode=m4_default([$1], [default])])\n\n_LT_DECL([], [pic_mode], [0], [What type of objects to build])dnl\n])# _LT_WITH_PIC\n\nLT_OPTION_DEFINE([LT_INIT], [pic-only], [_LT_WITH_PIC([yes])])\nLT_OPTION_DEFINE([LT_INIT], [no-pic], [_LT_WITH_PIC([no])])\n\n# Old name:\nAU_DEFUN([AC_LIBTOOL_PICMODE],\n[_LT_SET_OPTION([LT_INIT], [pic-only])\nAC_DIAGNOSE([obsolete],\n[$0: Remove this warning and the call to _LT_SET_OPTION when you\nput the 'pic-only' option into LT_INIT's first parameter.])\n])\n\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_LIBTOOL_PICMODE], [])\n\n## ----------------- ##\n## LTDL_INIT Options ##\n## ----------------- ##\n\nm4_define([_LTDL_MODE], [])\nLT_OPTION_DEFINE([LTDL_INIT], [nonrecursive],\n\t\t [m4_define([_LTDL_MODE], [nonrecursive])])\nLT_OPTION_DEFINE([LTDL_INIT], [recursive],\n\t\t [m4_define([_LTDL_MODE], [recursive])])\nLT_OPTION_DEFINE([LTDL_INIT], [subproject],\n\t\t [m4_define([_LTDL_MODE], [subproject])])\n\nm4_define([_LTDL_TYPE], [])\nLT_OPTION_DEFINE([LTDL_INIT], [installable],\n\t\t [m4_define([_LTDL_TYPE], [installable])])\nLT_OPTION_DEFINE([LTDL_INIT], [convenience],\n\t\t [m4_define([_LTDL_TYPE], [convenience])])\n",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/m4/dl.m4": "dnl dl.m4 -- checks for dynamic-linking library\ndnl\n\n### Activate dynamic linking: look for 'dlopen'\nAC_DEFUN([WO_PROG_DL],\n[dnl\nAC_ARG_ENABLE([dl],\n  [AS_HELP_STRING([--enable-dl],\n    [enable libdl for creating/loading process libraries on-the-fly [[yes]]])],\n  [], [enable_dl=\"yes\"])\n\nRTLD_LAZY_VALUE=0\nRTLD_NOW_VALUE=0\nRTLD_GLOBAL_VALUE=0\nRTLD_LOCAL_VALUE=0\nAC_SUBST([RTLD_LAZY_VALUE])\nAC_SUBST([RTLD_NOW_VALUE])\nAC_SUBST([RTLD_GLOBAL_VALUE])\nAC_SUBST([RTLD_LOCAL_VALUE])\n\nif test \"$enable_dl\" = \"yes\"; then\n  AC_LANG_PUSH([C])\n  AC_SEARCH_LIBS([dlopen], [dl], [], [enable_dl=\"no\"])\n  AC_CHECK_HEADERS([dlfcn.h],[],[enable_dl=\"no\"])\n  if test \"$enable_dl\" = \"yes\"; then\n     AC_MSG_CHECKING([for the values of RTLD_LAZY & friends])\n     AC_RUN_IFELSE([AC_LANG_SOURCE([dnl\n        #include <stdio.h>\n        #include <dlfcn.h>\n        \n        int main () {\n        FILE* handle = fopen (\"conftest.out\", \"w\");\n           if (!handle) return 1;\n           if (!fprintf (handle, \"RTLD_LAZY_VALUE=%i\\n\", RTLD_LAZY)) return 1;\n           if (!fprintf (handle, \"RTLD_NOW_VALUE=%i\\n\", RTLD_NOW)) return 1;\n           if (!fprintf (handle, \"RTLD_GLOBAL_VALUE=%i\\n\", RTLD_GLOBAL)) return 1;\n           if (!fprintf (handle, \"RTLD_LOCAL_VALUE=%i\\n\", RTLD_LOCAL)) return 1;\n           if (fclose (handle)) return 1;\n        }\n      ])],[. ./conftest.out],[enable_dl=\"no\"])\n     if test \"$enable_dl\" = \"yes\"; then\n        AC_MSG_RESULT([success])\n     else\n        AC_MSG_RESULT([failed])\n     fi\n  fi\n  AC_MSG_CHECKING([for $CC flag to produce position-independent code])\n  AC_MSG_RESULT([$lt_prog_compiler_pic_CC])\n  CFLAGS_PIC=$lt_prog_compiler_pic_CC\n  AC_SUBST([CFLAGS_PIC])\n  AC_LANG_POP()\nelse\n  AC_MSG_CHECKING([for dl (dynamic linking)])\n  CFLAGS_PIC=''\n  AC_SUBST([CFLAGS_PIC])\n  AC_MSG_RESULT([(disabled)])\nfi\n\nAM_CONDITIONAL([DL_AVAILABLE], [test \"$enable_dl\" = \"yes\"])\n\n\n### For make check of an installed WHIZARD we have to take\n### care of library interdependencies on MAC OS X\ncase $host in\n  *-darwin*)\n     DYLD_FLAGS=\"DYLD_LIBRARY_PATH=\\$(pwd)/../../src/.libs:\\$(pwd)/../../src/main/.libs:\\$(pwd)/../../omega/src/.libs:\\${DYLD_LIBRARY_PATH}; export DYLD_LIBRARY_PATH\" ;; \n  *)\n     DYLD_FLAGS=\"\" ;;\nesac\nAC_SUBST(DYLD_FLAGS)\n])\n\nAC_DEFUN([WO_CC_FLAGS],\n[dnl\n])\n\n",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/m4/ltdl.m4": "# ltdl.m4 - Configure ltdl for the target system. -*-Autoconf-*-\n#\n#   Copyright (C) 1999-2008, 2011-2015 Free Software Foundation, Inc.\n#   Written by Thomas Tanner, 1999\n#\n# This file is free software; the Free Software Foundation gives\n# unlimited permission to copy and/or distribute it, with or without\n# modifications, as long as this notice is preserved.\n\n# serial 20 LTDL_INIT\n\n# LT_CONFIG_LTDL_DIR(DIRECTORY, [LTDL-MODE])\n# ------------------------------------------\n# DIRECTORY contains the libltdl sources.  It is okay to call this\n# function multiple times, as long as the same DIRECTORY is always given.\nAC_DEFUN([LT_CONFIG_LTDL_DIR],\n[AC_BEFORE([$0], [LTDL_INIT])\n_$0($*)\n])# LT_CONFIG_LTDL_DIR\n\n# We break this out into a separate macro, so that we can call it safely\n# internally without being caught accidentally by the sed scan in libtoolize.\nm4_defun([_LT_CONFIG_LTDL_DIR],\n[dnl remove trailing slashes\nm4_pushdef([_ARG_DIR], m4_bpatsubst([$1], [/*$]))\nm4_case(_LTDL_DIR,\n\t[], [dnl only set lt_ltdl_dir if _ARG_DIR is not simply '.'\n\t     m4_if(_ARG_DIR, [.],\n\t             [],\n\t\t [m4_define([_LTDL_DIR], _ARG_DIR)\n\t          _LT_SHELL_INIT([lt_ltdl_dir=']_ARG_DIR['])])],\n    [m4_if(_ARG_DIR, _LTDL_DIR,\n\t    [],\n\t[m4_fatal([multiple libltdl directories: ']_LTDL_DIR[', ']_ARG_DIR['])])])\nm4_popdef([_ARG_DIR])\n])# _LT_CONFIG_LTDL_DIR\n\n# Initialise:\nm4_define([_LTDL_DIR], [])\n\n\n# _LT_BUILD_PREFIX\n# ----------------\n# If Autoconf is new enough, expand to '$(top_build_prefix)', otherwise\n# to '$(top_builddir)/'.\nm4_define([_LT_BUILD_PREFIX],\n[m4_ifdef([AC_AUTOCONF_VERSION],\n   [m4_if(m4_version_compare(m4_defn([AC_AUTOCONF_VERSION]), [2.62]),\n\t  [-1], [m4_ifdef([_AC_HAVE_TOP_BUILD_PREFIX],\n\t\t\t  [$(top_build_prefix)],\n\t\t\t  [$(top_builddir)/])],\n\t  [$(top_build_prefix)])],\n   [$(top_builddir)/])[]dnl\n])\n\n\n# LTDL_CONVENIENCE\n# ----------------\n# sets LIBLTDL to the link flags for the libltdl convenience library and\n# LTDLINCL to the include flags for the libltdl header and adds\n# --enable-ltdl-convenience to the configure arguments.  Note that\n# AC_CONFIG_SUBDIRS is not called here.  LIBLTDL will be prefixed with\n# '$(top_build_prefix)' if available, otherwise with '$(top_builddir)/',\n# and LTDLINCL will be prefixed with '$(top_srcdir)/' (note the single\n# quotes!).  If your package is not flat and you're not using automake,\n# define top_build_prefix, top_builddir, and top_srcdir appropriately\n# in your Makefiles.\nAC_DEFUN([LTDL_CONVENIENCE],\n[AC_BEFORE([$0], [LTDL_INIT])dnl\ndnl Although the argument is deprecated and no longer documented,\ndnl LTDL_CONVENIENCE used to take a DIRECTORY orgument, if we have one\ndnl here make sure it is the same as any other declaration of libltdl's\ndnl location!  This also ensures lt_ltdl_dir is set when configure.ac is\ndnl not yet using an explicit LT_CONFIG_LTDL_DIR.\nm4_ifval([$1], [_LT_CONFIG_LTDL_DIR([$1])])dnl\n_$0()\n])# LTDL_CONVENIENCE\n\n# AC_LIBLTDL_CONVENIENCE accepted a directory argument in older libtools,\n# now we have LT_CONFIG_LTDL_DIR:\nAU_DEFUN([AC_LIBLTDL_CONVENIENCE],\n[_LT_CONFIG_LTDL_DIR([m4_default([$1], [libltdl])])\n_LTDL_CONVENIENCE])\n\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_LIBLTDL_CONVENIENCE], [])\n\n\n# _LTDL_CONVENIENCE\n# -----------------\n# Code shared by LTDL_CONVENIENCE and LTDL_INIT([convenience]).\nm4_defun([_LTDL_CONVENIENCE],\n[case $enable_ltdl_convenience in\n  no) AC_MSG_ERROR([this package needs a convenience libltdl]) ;;\n  \"\") enable_ltdl_convenience=yes\n      ac_configure_args=\"$ac_configure_args --enable-ltdl-convenience\" ;;\nesac\nLIBLTDL='_LT_BUILD_PREFIX'\"${lt_ltdl_dir+$lt_ltdl_dir/}libltdlc.la\"\nLTDLDEPS=$LIBLTDL\nLTDLINCL='-I$(top_srcdir)'\"${lt_ltdl_dir+/$lt_ltdl_dir}\"\n\nAC_SUBST([LIBLTDL])\nAC_SUBST([LTDLDEPS])\nAC_SUBST([LTDLINCL])\n\n# For backwards non-gettext consistent compatibility...\nINCLTDL=$LTDLINCL\nAC_SUBST([INCLTDL])\n])# _LTDL_CONVENIENCE\n\n\n# LTDL_INSTALLABLE\n# ----------------\n# sets LIBLTDL to the link flags for the libltdl installable library\n# and LTDLINCL to the include flags for the libltdl header and adds\n# --enable-ltdl-install to the configure arguments.  Note that\n# AC_CONFIG_SUBDIRS is not called from here.  If an installed libltdl\n# is not found, LIBLTDL will be prefixed with '$(top_build_prefix)' if\n# available, otherwise with '$(top_builddir)/', and LTDLINCL will be\n# prefixed with '$(top_srcdir)/' (note the single quotes!).  If your\n# package is not flat and you're not using automake, define top_build_prefix,\n# top_builddir, and top_srcdir appropriately in your Makefiles.\n# In the future, this macro may have to be called after LT_INIT.\nAC_DEFUN([LTDL_INSTALLABLE],\n[AC_BEFORE([$0], [LTDL_INIT])dnl\ndnl Although the argument is deprecated and no longer documented,\ndnl LTDL_INSTALLABLE used to take a DIRECTORY orgument, if we have one\ndnl here make sure it is the same as any other declaration of libltdl's\ndnl location!  This also ensures lt_ltdl_dir is set when configure.ac is\ndnl not yet using an explicit LT_CONFIG_LTDL_DIR.\nm4_ifval([$1], [_LT_CONFIG_LTDL_DIR([$1])])dnl\n_$0()\n])# LTDL_INSTALLABLE\n\n# AC_LIBLTDL_INSTALLABLE accepted a directory argument in older libtools,\n# now we have LT_CONFIG_LTDL_DIR:\nAU_DEFUN([AC_LIBLTDL_INSTALLABLE],\n[_LT_CONFIG_LTDL_DIR([m4_default([$1], [libltdl])])\n_LTDL_INSTALLABLE])\n\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_LIBLTDL_INSTALLABLE], [])\n\n\n# _LTDL_INSTALLABLE\n# -----------------\n# Code shared by LTDL_INSTALLABLE and LTDL_INIT([installable]).\nm4_defun([_LTDL_INSTALLABLE],\n[if test -f \"$prefix/lib/libltdl.la\"; then\n  lt_save_LDFLAGS=$LDFLAGS\n  LDFLAGS=\"-L$prefix/lib $LDFLAGS\"\n  AC_CHECK_LIB([ltdl], [lt_dlinit], [lt_lib_ltdl=yes])\n  LDFLAGS=$lt_save_LDFLAGS\n  if test yes = \"${lt_lib_ltdl-no}\"; then\n    if test yes != \"$enable_ltdl_install\"; then\n      # Don't overwrite $prefix/lib/libltdl.la without --enable-ltdl-install\n      AC_MSG_WARN([not overwriting libltdl at $prefix, force with '--enable-ltdl-install'])\n      enable_ltdl_install=no\n    fi\n  elif test no = \"$enable_ltdl_install\"; then\n    AC_MSG_WARN([libltdl not installed, but installation disabled])\n  fi\nfi\n\n# If configure.ac declared an installable ltdl, and the user didn't override\n# with --disable-ltdl-install, we will install the shipped libltdl.\ncase $enable_ltdl_install in\n  no) ac_configure_args=\"$ac_configure_args --enable-ltdl-install=no\"\n      LIBLTDL=-lltdl\n      LTDLDEPS=\n      LTDLINCL=\n      ;;\n  *)  enable_ltdl_install=yes\n      ac_configure_args=\"$ac_configure_args --enable-ltdl-install\"\n      LIBLTDL='_LT_BUILD_PREFIX'\"${lt_ltdl_dir+$lt_ltdl_dir/}libltdl.la\"\n      LTDLDEPS=$LIBLTDL\n      LTDLINCL='-I$(top_srcdir)'\"${lt_ltdl_dir+/$lt_ltdl_dir}\"\n      ;;\nesac\n\nAC_SUBST([LIBLTDL])\nAC_SUBST([LTDLDEPS])\nAC_SUBST([LTDLINCL])\n\n# For backwards non-gettext consistent compatibility...\nINCLTDL=$LTDLINCL\nAC_SUBST([INCLTDL])\n])# LTDL_INSTALLABLE\n\n\n# _LTDL_MODE_DISPATCH\n# -------------------\nm4_define([_LTDL_MODE_DISPATCH],\n[dnl If _LTDL_DIR is '.', then we are configuring libltdl itself:\nm4_if(_LTDL_DIR, [],\n\t[],\n    dnl if _LTDL_MODE was not set already, the default value is 'subproject':\n    [m4_case(m4_default(_LTDL_MODE, [subproject]),\n\t  [subproject], [AC_CONFIG_SUBDIRS(_LTDL_DIR)\n\t\t\t  _LT_SHELL_INIT([lt_dlopen_dir=$lt_ltdl_dir])],\n\t  [nonrecursive], [_LT_SHELL_INIT([lt_dlopen_dir=$lt_ltdl_dir; lt_libobj_prefix=$lt_ltdl_dir/])],\n\t  [recursive], [],\n\t[m4_fatal([unknown libltdl mode: ]_LTDL_MODE)])])dnl\ndnl Be careful not to expand twice:\nm4_define([$0], [])\n])# _LTDL_MODE_DISPATCH\n\n\n# _LT_LIBOBJ(MODULE_NAME)\n# -----------------------\n# Like AC_LIBOBJ, except that MODULE_NAME goes into _LT_LIBOBJS instead\n# of into LIBOBJS.\nAC_DEFUN([_LT_LIBOBJ], [\n  m4_pattern_allow([^_LT_LIBOBJS$])\n  _LT_LIBOBJS=\"$_LT_LIBOBJS $1.$ac_objext\"\n])# _LT_LIBOBJS\n\n\n# LTDL_INIT([OPTIONS])\n# --------------------\n# Clients of libltdl can use this macro to allow the installer to\n# choose between a shipped copy of the ltdl sources or a preinstalled\n# version of the library.  If the shipped ltdl sources are not in a\n# subdirectory named libltdl, the directory name must be given by\n# LT_CONFIG_LTDL_DIR.\nAC_DEFUN([LTDL_INIT],\n[dnl Parse OPTIONS\n_LT_SET_OPTIONS([$0], [$1])\n\ndnl We need to keep our own list of libobjs separate from our parent project,\ndnl and the easiest way to do that is redefine the AC_LIBOBJs macro while\ndnl we look for our own LIBOBJs.\nm4_pushdef([AC_LIBOBJ], m4_defn([_LT_LIBOBJ]))\nm4_pushdef([AC_LIBSOURCES])\n\ndnl If not otherwise defined, default to the 1.5.x compatible subproject mode:\nm4_if(_LTDL_MODE, [],\n        [m4_define([_LTDL_MODE], m4_default([$2], [subproject]))\n        m4_if([-1], [m4_bregexp(_LTDL_MODE, [\\(subproject\\|\\(non\\)?recursive\\)])],\n                [m4_fatal([unknown libltdl mode: ]_LTDL_MODE)])])\n\nAC_ARG_WITH([included_ltdl],\n    [AS_HELP_STRING([--with-included-ltdl],\n                    [use the GNU ltdl sources included here])])\n\nif test yes != \"$with_included_ltdl\"; then\n  # We are not being forced to use the included libltdl sources, so\n  # decide whether there is a useful installed version we can use.\n  AC_CHECK_HEADER([ltdl.h],\n      [AC_CHECK_DECL([lt_dlinterface_register],\n\t   [AC_CHECK_LIB([ltdl], [lt_dladvise_preload],\n\t       [with_included_ltdl=no],\n\t       [with_included_ltdl=yes])],\n\t   [with_included_ltdl=yes],\n\t   [AC_INCLUDES_DEFAULT\n\t    #include <ltdl.h>])],\n      [with_included_ltdl=yes],\n      [AC_INCLUDES_DEFAULT]\n  )\nfi\n\ndnl If neither LT_CONFIG_LTDL_DIR, LTDL_CONVENIENCE nor LTDL_INSTALLABLE\ndnl was called yet, then for old times' sake, we assume libltdl is in an\ndnl eponymous directory:\nAC_PROVIDE_IFELSE([LT_CONFIG_LTDL_DIR], [], [_LT_CONFIG_LTDL_DIR([libltdl])])\n\nAC_ARG_WITH([ltdl_include],\n    [AS_HELP_STRING([--with-ltdl-include=DIR],\n                    [use the ltdl headers installed in DIR])])\n\nif test -n \"$with_ltdl_include\"; then\n  if test -f \"$with_ltdl_include/ltdl.h\"; then :\n  else\n    AC_MSG_ERROR([invalid ltdl include directory: '$with_ltdl_include'])\n  fi\nelse\n  with_ltdl_include=no\nfi\n\nAC_ARG_WITH([ltdl_lib],\n    [AS_HELP_STRING([--with-ltdl-lib=DIR],\n                    [use the libltdl.la installed in DIR])])\n\nif test -n \"$with_ltdl_lib\"; then\n  if test -f \"$with_ltdl_lib/libltdl.la\"; then :\n  else\n    AC_MSG_ERROR([invalid ltdl library directory: '$with_ltdl_lib'])\n  fi\nelse\n  with_ltdl_lib=no\nfi\n\ncase ,$with_included_ltdl,$with_ltdl_include,$with_ltdl_lib, in\n  ,yes,no,no,)\n\tm4_case(m4_default(_LTDL_TYPE, [convenience]),\n\t    [convenience], [_LTDL_CONVENIENCE],\n\t    [installable], [_LTDL_INSTALLABLE],\n\t  [m4_fatal([unknown libltdl build type: ]_LTDL_TYPE)])\n\t;;\n  ,no,no,no,)\n\t# If the included ltdl is not to be used, then use the\n\t# preinstalled libltdl we found.\n\tAC_DEFINE([HAVE_LTDL], [1],\n\t  [Define this if a modern libltdl is already installed])\n\tLIBLTDL=-lltdl\n\tLTDLDEPS=\n\tLTDLINCL=\n\t;;\n  ,no*,no,*)\n\tAC_MSG_ERROR(['--with-ltdl-include' and '--with-ltdl-lib' options must be used together])\n\t;;\n  *)\twith_included_ltdl=no\n\tLIBLTDL=\"-L$with_ltdl_lib -lltdl\"\n\tLTDLDEPS=\n\tLTDLINCL=-I$with_ltdl_include\n\t;;\nesac\nINCLTDL=$LTDLINCL\n\n# Report our decision...\nAC_MSG_CHECKING([where to find libltdl headers])\nAC_MSG_RESULT([$LTDLINCL])\nAC_MSG_CHECKING([where to find libltdl library])\nAC_MSG_RESULT([$LIBLTDL])\n\n_LTDL_SETUP\n\ndnl restore autoconf definition.\nm4_popdef([AC_LIBOBJ])\nm4_popdef([AC_LIBSOURCES])\n\nAC_CONFIG_COMMANDS_PRE([\n    _ltdl_libobjs=\n    _ltdl_ltlibobjs=\n    if test -n \"$_LT_LIBOBJS\"; then\n      # Remove the extension.\n      _lt_sed_drop_objext='s/\\.o$//;s/\\.obj$//'\n      for i in `for i in $_LT_LIBOBJS; do echo \"$i\"; done | sed \"$_lt_sed_drop_objext\" | sort -u`; do\n        _ltdl_libobjs=\"$_ltdl_libobjs $lt_libobj_prefix$i.$ac_objext\"\n        _ltdl_ltlibobjs=\"$_ltdl_ltlibobjs $lt_libobj_prefix$i.lo\"\n      done\n    fi\n    AC_SUBST([ltdl_LIBOBJS], [$_ltdl_libobjs])\n    AC_SUBST([ltdl_LTLIBOBJS], [$_ltdl_ltlibobjs])\n])\n\n# Only expand once:\nm4_define([LTDL_INIT])\n])# LTDL_INIT\n\n# Old names:\nAU_DEFUN([AC_LIB_LTDL], [LTDL_INIT($@)])\nAU_DEFUN([AC_WITH_LTDL], [LTDL_INIT($@)])\nAU_DEFUN([LT_WITH_LTDL], [LTDL_INIT($@)])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_LIB_LTDL], [])\ndnl AC_DEFUN([AC_WITH_LTDL], [])\ndnl AC_DEFUN([LT_WITH_LTDL], [])\n\n\n# _LTDL_SETUP\n# -----------\n# Perform all the checks necessary for compilation of the ltdl objects\n#  -- including compiler checks and header checks.  This is a public\n# interface  mainly for the benefit of libltdl's own configure.ac, most\n# other users should call LTDL_INIT instead.\nAC_DEFUN([_LTDL_SETUP],\n[AC_REQUIRE([AC_PROG_CC])dnl\nAC_REQUIRE([LT_SYS_MODULE_EXT])dnl\nAC_REQUIRE([LT_SYS_MODULE_PATH])dnl\nAC_REQUIRE([LT_SYS_DLSEARCH_PATH])dnl\nAC_REQUIRE([LT_LIB_DLLOAD])dnl\nAC_REQUIRE([LT_SYS_SYMBOL_USCORE])dnl\nAC_REQUIRE([LT_FUNC_DLSYM_USCORE])dnl\nAC_REQUIRE([LT_SYS_DLOPEN_DEPLIBS])dnl\nAC_REQUIRE([LT_FUNC_ARGZ])dnl\n\nm4_require([_LT_CHECK_OBJDIR])dnl\nm4_require([_LT_HEADER_DLFCN])dnl\nm4_require([_LT_CHECK_DLPREOPEN])dnl\nm4_require([_LT_DECL_SED])dnl\n\ndnl Don't require this, or it will be expanded earlier than the code\ndnl that sets the variables it relies on:\n_LT_ENABLE_INSTALL\n\ndnl _LTDL_MODE specific code must be called at least once:\n_LTDL_MODE_DISPATCH\n\n# In order that ltdl.c can compile, find out the first AC_CONFIG_HEADERS\n# the user used.  This is so that ltdl.h can pick up the parent projects\n# config.h file, The first file in AC_CONFIG_HEADERS must contain the\n# definitions required by ltdl.c.\n# FIXME: Remove use of undocumented AC_LIST_HEADERS (2.59 compatibility).\nAC_CONFIG_COMMANDS_PRE([dnl\nm4_pattern_allow([^LT_CONFIG_H$])dnl\nm4_ifset([AH_HEADER],\n    [LT_CONFIG_H=AH_HEADER],\n    [m4_ifset([AC_LIST_HEADERS],\n\t    [LT_CONFIG_H=`echo \"AC_LIST_HEADERS\" | $SED 's|^[[      ]]*||;s|[[ :]].*$||'`],\n\t[])])])\nAC_SUBST([LT_CONFIG_H])\n\nAC_CHECK_HEADERS([unistd.h dl.h sys/dl.h dld.h mach-o/dyld.h dirent.h],\n\t[], [], [AC_INCLUDES_DEFAULT])\n\nAC_CHECK_FUNCS([closedir opendir readdir], [], [AC_LIBOBJ([lt__dirent])])\nAC_CHECK_FUNCS([strlcat strlcpy], [], [AC_LIBOBJ([lt__strl])])\n\nm4_pattern_allow([LT_LIBEXT])dnl\nAC_DEFINE_UNQUOTED([LT_LIBEXT],[\"$libext\"],[The archive extension])\n\nname=\neval \"lt_libprefix=\\\"$libname_spec\\\"\"\nm4_pattern_allow([LT_LIBPREFIX])dnl\nAC_DEFINE_UNQUOTED([LT_LIBPREFIX],[\"$lt_libprefix\"],[The archive prefix])\n\nname=ltdl\neval \"LTDLOPEN=\\\"$libname_spec\\\"\"\nAC_SUBST([LTDLOPEN])\n])# _LTDL_SETUP\n\n\n# _LT_ENABLE_INSTALL\n# ------------------\nm4_define([_LT_ENABLE_INSTALL],\n[AC_ARG_ENABLE([ltdl-install],\n    [AS_HELP_STRING([--enable-ltdl-install], [install libltdl])])\n\ncase ,$enable_ltdl_install,$enable_ltdl_convenience in\n  *yes*) ;;\n  *) enable_ltdl_convenience=yes ;;\nesac\n\nm4_ifdef([AM_CONDITIONAL],\n[AM_CONDITIONAL(INSTALL_LTDL, test no != \"${enable_ltdl_install-no}\")\n AM_CONDITIONAL(CONVENIENCE_LTDL, test no != \"${enable_ltdl_convenience-no}\")])\n])# _LT_ENABLE_INSTALL\n\n\n# LT_SYS_DLOPEN_DEPLIBS\n# ---------------------\nAC_DEFUN([LT_SYS_DLOPEN_DEPLIBS],\n[AC_REQUIRE([AC_CANONICAL_HOST])dnl\nAC_CACHE_CHECK([whether deplibs are loaded by dlopen],\n  [lt_cv_sys_dlopen_deplibs],\n  [# PORTME does your system automatically load deplibs for dlopen?\n  # or its logical equivalent (e.g. shl_load for HP-UX < 11)\n  # For now, we just catch OSes we know something about -- in the\n  # future, we'll try test this programmatically.\n  lt_cv_sys_dlopen_deplibs=unknown\n  case $host_os in\n  aix3*|aix4.1.*|aix4.2.*)\n    # Unknown whether this is true for these versions of AIX, but\n    # we want this 'case' here to explicitly catch those versions.\n    lt_cv_sys_dlopen_deplibs=unknown\n    ;;\n  aix[[4-9]]*)\n    lt_cv_sys_dlopen_deplibs=yes\n    ;;\n  amigaos*)\n    case $host_cpu in\n    powerpc)\n      lt_cv_sys_dlopen_deplibs=no\n      ;;\n    esac\n    ;;\n  bitrig*)\n    lt_cv_sys_dlopen_deplibs=yes\n    ;;\n  darwin*)\n    # Assuming the user has installed a libdl from somewhere, this is true\n    # If you are looking for one http://www.opendarwin.org/projects/dlcompat\n    lt_cv_sys_dlopen_deplibs=yes\n    ;;\n  freebsd* | dragonfly*)\n    lt_cv_sys_dlopen_deplibs=yes\n    ;;\n  gnu* | linux* | k*bsd*-gnu | kopensolaris*-gnu)\n    # GNU and its variants, using gnu ld.so (Glibc)\n    lt_cv_sys_dlopen_deplibs=yes\n    ;;\n  hpux10*|hpux11*)\n    lt_cv_sys_dlopen_deplibs=yes\n    ;;\n  interix*)\n    lt_cv_sys_dlopen_deplibs=yes\n    ;;\n  irix[[12345]]*|irix6.[[01]]*)\n    # Catch all versions of IRIX before 6.2, and indicate that we don't\n    # know how it worked for any of those versions.\n    lt_cv_sys_dlopen_deplibs=unknown\n    ;;\n  irix*)\n    # The case above catches anything before 6.2, and it's known that\n    # at 6.2 and later dlopen does load deplibs.\n    lt_cv_sys_dlopen_deplibs=yes\n    ;;\n  netbsd*)\n    lt_cv_sys_dlopen_deplibs=yes\n    ;;\n  openbsd*)\n    lt_cv_sys_dlopen_deplibs=yes\n    ;;\n  osf[[1234]]*)\n    # dlopen did load deplibs (at least at 4.x), but until the 5.x series,\n    # it did *not* use an RPATH in a shared library to find objects the\n    # library depends on, so we explicitly say 'no'.\n    lt_cv_sys_dlopen_deplibs=no\n    ;;\n  osf5.0|osf5.0a|osf5.1)\n    # dlopen *does* load deplibs and with the right loader patch applied\n    # it even uses RPATH in a shared library to search for shared objects\n    # that the library depends on, but there's no easy way to know if that\n    # patch is installed.  Since this is the case, all we can really\n    # say is unknown -- it depends on the patch being installed.  If\n    # it is, this changes to 'yes'.  Without it, it would be 'no'.\n    lt_cv_sys_dlopen_deplibs=unknown\n    ;;\n  osf*)\n    # the two cases above should catch all versions of osf <= 5.1.  Read\n    # the comments above for what we know about them.\n    # At > 5.1, deplibs are loaded *and* any RPATH in a shared library\n    # is used to find them so we can finally say 'yes'.\n    lt_cv_sys_dlopen_deplibs=yes\n    ;;\n  qnx*)\n    lt_cv_sys_dlopen_deplibs=yes\n    ;;\n  solaris*)\n    lt_cv_sys_dlopen_deplibs=yes\n    ;;\n  sysv5* | sco3.2v5* | sco5v6* | unixware* | OpenUNIX* | sysv4*uw2*)\n    libltdl_cv_sys_dlopen_deplibs=yes\n    ;;\n  esac\n  ])\nif test yes != \"$lt_cv_sys_dlopen_deplibs\"; then\n AC_DEFINE([LTDL_DLOPEN_DEPLIBS], [1],\n    [Define if the OS needs help to load dependent libraries for dlopen().])\nfi\n])# LT_SYS_DLOPEN_DEPLIBS\n\n# Old name:\nAU_ALIAS([AC_LTDL_SYS_DLOPEN_DEPLIBS], [LT_SYS_DLOPEN_DEPLIBS])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_LTDL_SYS_DLOPEN_DEPLIBS], [])\n\n\n# LT_SYS_MODULE_EXT\n# -----------------\nAC_DEFUN([LT_SYS_MODULE_EXT],\n[m4_require([_LT_SYS_DYNAMIC_LINKER])dnl\nAC_CACHE_CHECK([what extension is used for runtime loadable modules],\n  [libltdl_cv_shlibext],\n[\nmodule=yes\neval libltdl_cv_shlibext=$shrext_cmds\nmodule=no\neval libltdl_cv_shrext=$shrext_cmds\n  ])\nif test -n \"$libltdl_cv_shlibext\"; then\n  m4_pattern_allow([LT_MODULE_EXT])dnl\n  AC_DEFINE_UNQUOTED([LT_MODULE_EXT], [\"$libltdl_cv_shlibext\"],\n    [Define to the extension used for runtime loadable modules, say, \".so\".])\nfi\nif test \"$libltdl_cv_shrext\" != \"$libltdl_cv_shlibext\"; then\n  m4_pattern_allow([LT_SHARED_EXT])dnl\n  AC_DEFINE_UNQUOTED([LT_SHARED_EXT], [\"$libltdl_cv_shrext\"],\n    [Define to the shared library suffix, say, \".dylib\".])\nfi\nif test -n \"$shared_archive_member_spec\"; then\n  m4_pattern_allow([LT_SHARED_LIB_MEMBER])dnl\n  AC_DEFINE_UNQUOTED([LT_SHARED_LIB_MEMBER], [\"($shared_archive_member_spec.o)\"],\n    [Define to the shared archive member specification, say \"(shr.o)\".])\nfi\n])# LT_SYS_MODULE_EXT\n\n# Old name:\nAU_ALIAS([AC_LTDL_SHLIBEXT], [LT_SYS_MODULE_EXT])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_LTDL_SHLIBEXT], [])\n\n\n# LT_SYS_MODULE_PATH\n# ------------------\nAC_DEFUN([LT_SYS_MODULE_PATH],\n[m4_require([_LT_SYS_DYNAMIC_LINKER])dnl\nAC_CACHE_CHECK([what variable specifies run-time module search path],\n  [lt_cv_module_path_var], [lt_cv_module_path_var=$shlibpath_var])\nif test -n \"$lt_cv_module_path_var\"; then\n  m4_pattern_allow([LT_MODULE_PATH_VAR])dnl\n  AC_DEFINE_UNQUOTED([LT_MODULE_PATH_VAR], [\"$lt_cv_module_path_var\"],\n    [Define to the name of the environment variable that determines the run-time module search path.])\nfi\n])# LT_SYS_MODULE_PATH\n\n# Old name:\nAU_ALIAS([AC_LTDL_SHLIBPATH], [LT_SYS_MODULE_PATH])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_LTDL_SHLIBPATH], [])\n\n\n# LT_SYS_DLSEARCH_PATH\n# --------------------\nAC_DEFUN([LT_SYS_DLSEARCH_PATH],\n[m4_require([_LT_SYS_DYNAMIC_LINKER])dnl\nAC_CACHE_CHECK([for the default library search path],\n  [lt_cv_sys_dlsearch_path],\n  [lt_cv_sys_dlsearch_path=$sys_lib_dlsearch_path_spec])\nif test -n \"$lt_cv_sys_dlsearch_path\"; then\n  sys_dlsearch_path=\n  for dir in $lt_cv_sys_dlsearch_path; do\n    if test -z \"$sys_dlsearch_path\"; then\n      sys_dlsearch_path=$dir\n    else\n      sys_dlsearch_path=$sys_dlsearch_path$PATH_SEPARATOR$dir\n    fi\n  done\n  m4_pattern_allow([LT_DLSEARCH_PATH])dnl\n  AC_DEFINE_UNQUOTED([LT_DLSEARCH_PATH], [\"$sys_dlsearch_path\"],\n    [Define to the system default library search path.])\nfi\n])# LT_SYS_DLSEARCH_PATH\n\n# Old name:\nAU_ALIAS([AC_LTDL_SYSSEARCHPATH], [LT_SYS_DLSEARCH_PATH])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_LTDL_SYSSEARCHPATH], [])\n\n\n# _LT_CHECK_DLPREOPEN\n# -------------------\nm4_defun([_LT_CHECK_DLPREOPEN],\n[m4_require([_LT_CMD_GLOBAL_SYMBOLS])dnl\nAC_CACHE_CHECK([whether libtool supports -dlopen/-dlpreopen],\n  [libltdl_cv_preloaded_symbols],\n  [if test -n \"$lt_cv_sys_global_symbol_pipe\"; then\n    libltdl_cv_preloaded_symbols=yes\n  else\n    libltdl_cv_preloaded_symbols=no\n  fi\n  ])\nif test yes = \"$libltdl_cv_preloaded_symbols\"; then\n  AC_DEFINE([HAVE_PRELOADED_SYMBOLS], [1],\n    [Define if libtool can extract symbol lists from object files.])\nfi\n])# _LT_CHECK_DLPREOPEN\n\n\n# LT_LIB_DLLOAD\n# -------------\nAC_DEFUN([LT_LIB_DLLOAD],\n[m4_pattern_allow([^LT_DLLOADERS$])\nLT_DLLOADERS=\nAC_SUBST([LT_DLLOADERS])\n\nAC_LANG_PUSH([C])\nlt_dlload_save_LIBS=$LIBS\n\nLIBADD_DLOPEN=\nAC_SEARCH_LIBS([dlopen], [dl],\n\t[AC_DEFINE([HAVE_LIBDL], [1],\n\t\t   [Define if you have the libdl library or equivalent.])\n\tif test \"$ac_cv_search_dlopen\" != \"none required\"; then\n\t  LIBADD_DLOPEN=-ldl\n\tfi\n\tlibltdl_cv_lib_dl_dlopen=yes\n\tLT_DLLOADERS=\"$LT_DLLOADERS ${lt_dlopen_dir+$lt_dlopen_dir/}dlopen.la\"],\n    [AC_LINK_IFELSE([AC_LANG_PROGRAM([[#if HAVE_DLFCN_H\n#  include <dlfcn.h>\n#endif\n    ]], [[dlopen(0, 0);]])],\n\t    [AC_DEFINE([HAVE_LIBDL], [1],\n\t\t       [Define if you have the libdl library or equivalent.])\n\t    libltdl_cv_func_dlopen=yes\n\t    LT_DLLOADERS=\"$LT_DLLOADERS ${lt_dlopen_dir+$lt_dlopen_dir/}dlopen.la\"],\n\t[AC_CHECK_LIB([svld], [dlopen],\n\t\t[AC_DEFINE([HAVE_LIBDL], [1],\n\t\t\t [Define if you have the libdl library or equivalent.])\n\t        LIBADD_DLOPEN=-lsvld libltdl_cv_func_dlopen=yes\n\t\tLT_DLLOADERS=\"$LT_DLLOADERS ${lt_dlopen_dir+$lt_dlopen_dir/}dlopen.la\"])])])\nif test yes = \"$libltdl_cv_func_dlopen\" || test yes = \"$libltdl_cv_lib_dl_dlopen\"\nthen\n  lt_save_LIBS=$LIBS\n  LIBS=\"$LIBS $LIBADD_DLOPEN\"\n  AC_CHECK_FUNCS([dlerror])\n  LIBS=$lt_save_LIBS\nfi\nAC_SUBST([LIBADD_DLOPEN])\n\nLIBADD_SHL_LOAD=\nAC_CHECK_FUNC([shl_load],\n\t[AC_DEFINE([HAVE_SHL_LOAD], [1],\n\t\t   [Define if you have the shl_load function.])\n\tLT_DLLOADERS=\"$LT_DLLOADERS ${lt_dlopen_dir+$lt_dlopen_dir/}shl_load.la\"],\n    [AC_CHECK_LIB([dld], [shl_load],\n\t    [AC_DEFINE([HAVE_SHL_LOAD], [1],\n\t\t       [Define if you have the shl_load function.])\n\t    LT_DLLOADERS=\"$LT_DLLOADERS ${lt_dlopen_dir+$lt_dlopen_dir/}shl_load.la\"\n\t    LIBADD_SHL_LOAD=-ldld])])\nAC_SUBST([LIBADD_SHL_LOAD])\n\ncase $host_os in\ndarwin[[1567]].*)\n# We only want this for pre-Mac OS X 10.4.\n  AC_CHECK_FUNC([_dyld_func_lookup],\n\t[AC_DEFINE([HAVE_DYLD], [1],\n\t\t   [Define if you have the _dyld_func_lookup function.])\n\tLT_DLLOADERS=\"$LT_DLLOADERS ${lt_dlopen_dir+$lt_dlopen_dir/}dyld.la\"])\n  ;;\nbeos*)\n  LT_DLLOADERS=\"$LT_DLLOADERS ${lt_dlopen_dir+$lt_dlopen_dir/}load_add_on.la\"\n  ;;\ncygwin* | mingw* | pw32*)\n  AC_CHECK_DECLS([cygwin_conv_path], [], [], [[#include <sys/cygwin.h>]])\n  LT_DLLOADERS=\"$LT_DLLOADERS ${lt_dlopen_dir+$lt_dlopen_dir/}loadlibrary.la\"\n  ;;\nesac\n\nAC_CHECK_LIB([dld], [dld_link],\n\t[AC_DEFINE([HAVE_DLD], [1],\n\t\t   [Define if you have the GNU dld library.])\n\t\tLT_DLLOADERS=\"$LT_DLLOADERS ${lt_dlopen_dir+$lt_dlopen_dir/}dld_link.la\"])\nAC_SUBST([LIBADD_DLD_LINK])\n\nm4_pattern_allow([^LT_DLPREOPEN$])\nLT_DLPREOPEN=\nif test -n \"$LT_DLLOADERS\"\nthen\n  for lt_loader in $LT_DLLOADERS; do\n    LT_DLPREOPEN=\"$LT_DLPREOPEN-dlpreopen $lt_loader \"\n  done\n  AC_DEFINE([HAVE_LIBDLLOADER], [1],\n            [Define if libdlloader will be built on this platform])\nfi\nAC_SUBST([LT_DLPREOPEN])\n\ndnl This isn't used anymore, but set it for backwards compatibility\nLIBADD_DL=\"$LIBADD_DLOPEN $LIBADD_SHL_LOAD\"\nAC_SUBST([LIBADD_DL])\n\nLIBS=$lt_dlload_save_LIBS\nAC_LANG_POP\n])# LT_LIB_DLLOAD\n\n# Old name:\nAU_ALIAS([AC_LTDL_DLLIB], [LT_LIB_DLLOAD])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_LTDL_DLLIB], [])\n\n\n# LT_SYS_SYMBOL_USCORE\n# --------------------\n# does the compiler prefix global symbols with an underscore?\nAC_DEFUN([LT_SYS_SYMBOL_USCORE],\n[m4_require([_LT_CMD_GLOBAL_SYMBOLS])dnl\nAC_CACHE_CHECK([for _ prefix in compiled symbols],\n  [lt_cv_sys_symbol_underscore],\n  [lt_cv_sys_symbol_underscore=no\n  cat > conftest.$ac_ext <<_LT_EOF\nvoid nm_test_func(){}\nint main(){nm_test_func;return 0;}\n_LT_EOF\n  if AC_TRY_EVAL(ac_compile); then\n    # Now try to grab the symbols.\n    ac_nlist=conftest.nm\n    if AC_TRY_EVAL(NM conftest.$ac_objext \\| $lt_cv_sys_global_symbol_pipe \\> $ac_nlist) && test -s \"$ac_nlist\"; then\n      # See whether the symbols have a leading underscore.\n      if grep '^. _nm_test_func' \"$ac_nlist\" >/dev/null; then\n        lt_cv_sys_symbol_underscore=yes\n      else\n        if grep '^. nm_test_func ' \"$ac_nlist\" >/dev/null; then\n\t  :\n        else\n\t  echo \"configure: cannot find nm_test_func in $ac_nlist\" >&AS_MESSAGE_LOG_FD\n        fi\n      fi\n    else\n      echo \"configure: cannot run $lt_cv_sys_global_symbol_pipe\" >&AS_MESSAGE_LOG_FD\n    fi\n  else\n    echo \"configure: failed program was:\" >&AS_MESSAGE_LOG_FD\n    cat conftest.c >&AS_MESSAGE_LOG_FD\n  fi\n  rm -rf conftest*\n  ])\n  sys_symbol_underscore=$lt_cv_sys_symbol_underscore\n  AC_SUBST([sys_symbol_underscore])\n])# LT_SYS_SYMBOL_USCORE\n\n# Old name:\nAU_ALIAS([AC_LTDL_SYMBOL_USCORE], [LT_SYS_SYMBOL_USCORE])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_LTDL_SYMBOL_USCORE], [])\n\n\n# LT_FUNC_DLSYM_USCORE\n# --------------------\nAC_DEFUN([LT_FUNC_DLSYM_USCORE],\n[AC_REQUIRE([_LT_COMPILER_PIC])dnl\tfor lt_prog_compiler_wl\nAC_REQUIRE([LT_SYS_SYMBOL_USCORE])dnl\tfor lt_cv_sys_symbol_underscore\nAC_REQUIRE([LT_SYS_MODULE_EXT])dnl\tfor libltdl_cv_shlibext\nif test yes = \"$lt_cv_sys_symbol_underscore\"; then\n  if test yes = \"$libltdl_cv_func_dlopen\" || test yes = \"$libltdl_cv_lib_dl_dlopen\"; then\n    AC_CACHE_CHECK([whether we have to add an underscore for dlsym],\n      [libltdl_cv_need_uscore],\n      [libltdl_cv_need_uscore=unknown\n      dlsym_uscore_save_LIBS=$LIBS\n      LIBS=\"$LIBS $LIBADD_DLOPEN\"\n      libname=conftmod # stay within 8.3 filename limits!\n      cat >$libname.$ac_ext <<_LT_EOF\n[#line $LINENO \"configure\"\n#include \"confdefs.h\"\n/* When -fvisibility=hidden is used, assume the code has been annotated\n   correspondingly for the symbols needed.  */\n#if defined __GNUC__ && (((__GNUC__ == 3) && (__GNUC_MINOR__ >= 3)) || (__GNUC__ > 3))\nint fnord () __attribute__((visibility(\"default\")));\n#endif\nint fnord () { return 42; }]\n_LT_EOF\n\n      # ltfn_module_cmds module_cmds\n      # Execute tilde-delimited MODULE_CMDS with environment primed for\n      # $module_cmds or $archive_cmds type content.\n      ltfn_module_cmds ()\n      {( # subshell avoids polluting parent global environment\n          module_cmds_save_ifs=$IFS; IFS='~'\n          for cmd in @S|@1; do\n            IFS=$module_cmds_save_ifs\n            libobjs=$libname.$ac_objext; lib=$libname$libltdl_cv_shlibext\n            rpath=/not-exists; soname=$libname$libltdl_cv_shlibext; output_objdir=.\n            major=; versuffix=; verstring=; deplibs=\n            ECHO=echo; wl=$lt_prog_compiler_wl; allow_undefined_flag=\n            eval $cmd\n          done\n          IFS=$module_cmds_save_ifs\n      )}\n\n      # Compile a loadable module using libtool macro expansion results.\n      $CC $pic_flag -c $libname.$ac_ext\n      ltfn_module_cmds \"${module_cmds:-$archive_cmds}\"\n\n      # Try to fetch fnord with dlsym().\n      libltdl_dlunknown=0; libltdl_dlnouscore=1; libltdl_dluscore=2\n      cat >conftest.$ac_ext <<_LT_EOF\n[#line $LINENO \"configure\"\n#include \"confdefs.h\"\n#if HAVE_DLFCN_H\n#include <dlfcn.h>\n#endif\n#include <stdio.h>\n#ifndef RTLD_GLOBAL\n#  ifdef DL_GLOBAL\n#    define RTLD_GLOBAL DL_GLOBAL\n#  else\n#    define RTLD_GLOBAL 0\n#  endif\n#endif\n#ifndef RTLD_NOW\n#  ifdef DL_NOW\n#    define RTLD_NOW DL_NOW\n#  else\n#    define RTLD_NOW 0\n#  endif\n#endif\nint main () {\n  void *handle = dlopen (\"`pwd`/$libname$libltdl_cv_shlibext\", RTLD_GLOBAL|RTLD_NOW);\n  int status = $libltdl_dlunknown;\n  if (handle) {\n    if (dlsym (handle, \"fnord\"))\n      status = $libltdl_dlnouscore;\n    else {\n      if (dlsym (handle, \"_fnord\"))\n        status = $libltdl_dluscore;\n      else\n\tputs (dlerror ());\n    }\n    dlclose (handle);\n  } else\n    puts (dlerror ());\n  return status;\n}]\n_LT_EOF\n      if AC_TRY_EVAL(ac_link) && test -s \"conftest$ac_exeext\" 2>/dev/null; then\n        (./conftest; exit; ) >&AS_MESSAGE_LOG_FD 2>/dev/null\n        libltdl_status=$?\n        case x$libltdl_status in\n          x$libltdl_dlnouscore) libltdl_cv_need_uscore=no ;;\n\t  x$libltdl_dluscore) libltdl_cv_need_uscore=yes ;;\n\t  x*) libltdl_cv_need_uscore=unknown ;;\n        esac\n      fi\n      rm -rf conftest* $libname*\n      LIBS=$dlsym_uscore_save_LIBS\n    ])\n  fi\nfi\n\nif test yes = \"$libltdl_cv_need_uscore\"; then\n  AC_DEFINE([NEED_USCORE], [1],\n    [Define if dlsym() requires a leading underscore in symbol names.])\nfi\n])# LT_FUNC_DLSYM_USCORE\n\n# Old name:\nAU_ALIAS([AC_LTDL_DLSYM_USCORE], [LT_FUNC_DLSYM_USCORE])\ndnl aclocal-1.4 backwards compatibility:\ndnl AC_DEFUN([AC_LTDL_DLSYM_USCORE], [])\n",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/share/doc/manual.tex": "\\documentclass[12pt]{book}\n% \\usepackage{feynmp}\n\\usepackage{microtype}\n\\usepackage{graphics,graphicx}\n\\usepackage{color}\n\\usepackage{amsmath,amssymb}\n\\usepackage[colorlinks,bookmarks,bookmarksnumbered=true]{hyperref}\n\\usepackage{thophys}\n\\usepackage{fancyvrb}\n\\usepackage{makeidx}\n\\usepackage{units}\n\\usepackage{ifpdf}\n%HEVEA\\pdftrue\n\\makeindex\n\\usepackage{url}\n\\usepackage[latin1]{inputenc}\n%HEVEA\\@def@charset{UTF-8}\n%BEGIN LATEX\n\\usepackage{supertabular,fancyvrb}\n\\usepackage{hevea}\n%END LATEX\n\\renewcommand{\\topfraction}{0.9}\n\\renewcommand{\\bottomfraction}{0.8}\n\\renewcommand{\\textfraction}{0.1}\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%% Macro section\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\\newcommand{\\email}[2]{\\thanks{\\ahref{#1@{}#2}{#1@{}#2}}}\n\\newcommand{\\hepforgepage}{\\url{https://whizard.hepforge.org}}\n\\newcommand{\\whizardwiki}{\\url{https://whizard.hepforge.org/trac/wiki}}\n\\tocnumber\n%BEGIN LATEX\n\\DeclareMathOperator{\\diag}{diag}\n%END LATEX\n%BEGIN LATEX\n\\makeatletter\n\\newif\\if@preliminary\n\\@preliminaryfalse\n\\def\\preliminary{\\@preliminarytrue}\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%% Changes referring to article.cls\n%\n%%% Title page\n\\def\\preprintno#1{\\def\\@preprintno{#1}}\n\\def\\address#1{\\def\\@address{#1}}\n\\def\\email#1#2{\\thanks{\\tt #1@{}#2}}\n\\def\\abstract#1{\\def\\@abstract{#1}}\n\\newcommand\\abstractname{ABSTRACT}\n\\newlength\\preprintnoskip\n\\setlength\\preprintnoskip{\\textwidth\\@plus -1cm}\n\\newlength\\abstractwidth\n\\setlength\\abstractwidth{\\textwidth\\@plus -3cm}\n%\n\\@titlepagetrue\n\\renewcommand\\maketitle{\\begin{titlepage}%\n  \\let\\footnotesize\\small\n  \\hfill\\parbox{\\preprintnoskip}{%\n  \\begin{flushright}\\@preprintno\\end{flushright}}\\hspace*{1cm}\n  \\vskip 60\\p@\n  \\begin{center}%\n    {\\Large\\bf\\boldmath \\@title \\par}\\vskip 1cm%\n    {\\sc\\@author \\par}\\vskip 3mm%\n    {\\@address \\par}%\n    \\if@preliminary\n      \\vskip 2cm {\\large\\sf PRELIMINARY DRAFT \\par \\@date}%\n    \\fi\n  \\end{center}\\par\n  \\@thanks\n  \\vfill\n  \\begin{center}%\n    \\parbox{\\abstractwidth}{\\centerline{\\abstractname}%\n    \\vskip 3mm%\n    \\@abstract}\n  \\end{center}\n  \\end{titlepage}%\n  \\setcounter{footnote}{0}%\n  \\let\\thanks\\relax\\let\\maketitle\\relax\n  \\gdef\\@thanks{}\\gdef\\@author{}\\gdef\\@address{}%\n  \\gdef\\@title{}\\gdef\\@abstract{}\\gdef\\@preprintno{}\n}%\n%\n%%% New settings of dimensions\n\\topmargin -1.5cm\n\\textheight 22cm\n\\textwidth 17cm\n\\oddsidemargin 0cm\n\\evensidemargin 0cm\n%\n%%% Original Latex definition of citex, except for the removal of\n%%% 'space' following a ','. \\citerange replaces the ',' by '--'.\n\\def\\@citex[#1]#2{\\if@filesw\\immediate\\write\\@auxout{\\string\\citation{#2}}\\fi\n  \\def\\@citea{}\\@cite{\\@for\\@citeb:=#2\\do\n    {\\@citea\\def\\@citea{,\\penalty\\@m}\\@ifundefined\n       {b@\\@citeb}{{\\bf ?}\\@warning\n       {Citation `\\@citeb' on page \\thepage \\space undefined}}%\n\\hbox{\\csname b@\\@citeb\\endcsname}}}{#1}}\n\\def\\citerange{\\@ifnextchar [{\\@tempswatrue\\@citexr}{\\@tempswafalse\\@citexr[]}}\n\\def\\@citexr[#1]#2{\\if@filesw\\immediate\\write\\@auxout{\\string\\citation{#2}}\\fi\n  \\def\\@citea{}\\@cite{\\@for\\@citeb:=#2\\do\n    {\\@citea\\def\\@citea{--\\penalty\\@m}\\@ifundefined\n       {b@\\@citeb}{{\\bf ?}\\@warning\n       {Citation `\\@citeb' on page \\thepage \\space undefined}}%\n\\hbox{\\csname b@\\@citeb\\endcsname}}}{#1}}\n%\n%%% Captions set in italics\n\\long\\def\\@makecaption#1#2{%\n  \\vskip\\abovecaptionskip\n  \\sbox\\@tempboxa{#1: \\emph{#2}}%\n  \\ifdim \\wd\\@tempboxa >\\hsize\n    #1: \\emph{#2}\\par\n  \\else\n    \\hbox to\\hsize{\\hfil\\box\\@tempboxa\\hfil}%\n  \\fi\n  \\vskip\\belowcaptionskip}\n%\n%%% Other useful macros\n\\def\\fmslash{\\@ifnextchar[{\\fmsl@sh}{\\fmsl@sh[0mu]}}\n\\def\\fmsl@sh[#1]#2{%\n  \\mathchoice\n    {\\@fmsl@sh\\displaystyle{#1}{#2}}%\n    {\\@fmsl@sh\\textstyle{#1}{#2}}%\n    {\\@fmsl@sh\\scriptstyle{#1}{#2}}%\n    {\\@fmsl@sh\\scriptscriptstyle{#1}{#2}}}\n\\def\\@fmsl@sh#1#2#3{\\m@th\\ooalign{$\\hfil#1\\mkern#2/\\hfil$\\crcr$#1#3$}}\n\\makeatother\n\n% Labelling command for Feynman graphs generated by package FEYNMF\n%\\def\\fmfL(#1,#2,#3)#4{\\put(#1,#2){\\makebox(0,0)[#3]{#4}}}\n\n%END LATEX\n%%%% Environment for showing user input and program response\n\\newenvironment{interaction}%\n  {\\begingroup\\small\n   \\Verbatim}%\n  {\\endVerbatim\n   \\endgroup\\noindent}\n%BEGIN LATEX\n\n%%%% Environment for typesetting listings verbatim\n\\newenvironment{code}%\n  {\\begingroup\\footnotesize\n   \\quote\n   \\Verbatim}%\n  {\\endVerbatim\n   \\endquote\n   \\endgroup\\noindent}\n\n%%%% Boxed environment for typesetting listings verbatim\n\\newenvironment{Code}%\n  {\\begingroup\\footnotesize\n   \\quote\n   \\Verbatim[frame=single]}%\n  {\\endVerbatim\n   \\endquote\n   \\endgroup\\noindent}\n\n%%% Environment for displaying syntax\n\\newenvironment{syntax}%\n  {\\begin{quote}\n   \\begin{flushleft}\\tt}%\n  {\\end{flushleft}\n   \\end{quote}}\n\\newcommand{\\var}[1]{$\\langle$\\textit{#1}$\\rangle$}\n\n\n%END LATEX\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n% Macros specific for this paper\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\\newcommand{\\ttt}[1]{\\texttt{#1}}\n\\newcommand{\\whizard}{\\ttt{WHIZARD}}\n\\newcommand{\\oMega}{\\ttt{O'Mega}}\n\\newcommand{\\vamp}{\\ttt{VAMP}}\n\\newcommand{\\vamptwo}{\\ttt{VAMP2}}\n\\newcommand{\\vegas}{\\ttt{VEGAS}}\n\\newcommand{\\madgraph}{\\ttt{MadGraph}}\n\\newcommand{\\CalcHep}{\\ttt{CalcHep}}\n\\newcommand{\\helas}{\\ttt{HELAS}}\n\\newcommand{\\herwig}{\\ttt{HERWIG}}\n\\newcommand{\\isajet}{\\ttt{ISAJET}}\n\\newcommand{\\pythia}{\\ttt{PYTHIA}}\n\\newcommand{\\pythiasix}{\\ttt{PYTHIA6}}\n\\newcommand{\\pythiaeight}{\\ttt{PYTHIA8}}\n\\newcommand{\\jetset}{\\ttt{JETSET}}\n\\newcommand{\\comphep}{\\ttt{CompHEP}}\n\\newcommand{\\circe}{\\ttt{CIRCE}}\n\\newcommand{\\circeone}{\\ttt{CIRCE1}}\n\\newcommand{\\circetwo}{\\ttt{CIRCE2}}\n\\newcommand{\\gamelan}{\\textsf{gamelan}}\n\\newcommand{\\stdhep}{\\ttt{STDHEP}}\n\\newcommand{\\lcio}{\\ttt{LCIO}}\n\\newcommand{\\pdflib}{\\ttt{PDFLIB}}\n\\newcommand{\\lhapdf}{\\ttt{LHAPDF}}\n\\newcommand{\\hepmc}{\\ttt{HepMC}}\n\\newcommand{\\hepmcthree}{\\ttt{HepMC3}}\n\\newcommand{\\fastjet}{\\ttt{FastJet}}\n\\newcommand{\\hoppet}{\\ttt{HOPPET}}\n\\newcommand{\\metapost}{\\ttt{MetaPost}}\n\\newcommand{\\sarah}{\\ttt{SARAH}}\n\\newcommand{\\spheno}{\\ttt{SPheno}}\n\\newcommand{\\Mathematica}{\\ttt{Mathematica}}\n\\newcommand{\\FeynRules}{\\ttt{FeynRules}}\n\\newcommand{\\UFO}{\\ttt{UFO}}\n\\newcommand{\\gosam}{\\ttt{Gosam}}\n\\newcommand{\\openloops}{\\ttt{OpenLoops}}\n\\newcommand{\\recola}{\\ttt{Recola}}\n\\newcommand{\\collier}{\\ttt{Collier}}\n\\newcommand{\\powheg}{\\ttt{POWHEG}}\n\\newcommand{\\delphes}{\\ttt{Delphes}}\n\\newcommand{\\geant}{\\ttt{Geant}}\n\\newcommand{\\ROOT}{\\ttt{ROOT}}\n\\newcommand{\\rivet}{\\ttt{Rivet}}\n%%%%%\n\\newcommand{\\sindarin}{\\ttt{SINDARIN}}\n\\newcommand{\\cpp}{\\ttt{C++}}\n\\newcommand{\\fortran}{\\ttt{Fortran}}\n\\newcommand{\\fortranSeventySeven}{\\ttt{FORTRAN77}}\n\\newcommand{\\fortranNinetyFive}{\\ttt{Fortran95}}\n\\newcommand{\\fortranOThree}{\\ttt{Fortran2003}}\n\\newcommand{\\ocaml}{\\ttt{OCaml}}\n\\newcommand{\\python}{\\ttt{Python}}\n\n\\newenvironment{commands}{\\begin{quote}\\tt}{\\end{quote}}\n\\newcommand{\\eemm}{$e^+e^- \\to \\mu^+\\mu^-$}\n\n%\\def\\~{$\\sim$}\n\\newcommand{\\sgn}{\\mathop{\\rm sgn}\\nolimits}\n\\newcommand{\\GeV}{\\textrm{GeV}}\n\\newcommand{\\fb}{\\textrm{fb}}\n\\newcommand{\\ab}{\\textrm{ab}}\n\n\\newenvironment{parameters}{%\n\\begin{center}\n\\begin{tabular}{lccp{65mm}}\n\\hline\nParameter & Value & Default & Description \\\\\n\\hline\n}{%\n\\hline\n\\end{tabular}\n\\end{center}\n}\n\n\\newenvironment{options}{%\n\\begin{center}\n\\begin{tabular}{llcp{80mm}}\n\\hline\nOption & Long version & Value & Description \\\\\n\\hline\n}{%\n\\hline\n\\end{tabular}\n\\end{center}\n}\n\n%BEGIN LATEX\n\\renewenvironment{options}{%\n\\begin{center}\n\\tablehead{\\hline\nOption & Long version & Value & Description \\\\\n\\hline\n}\n\\begin{supertabular}{llcp{80mm}}\n}{%\n\\hline\n\\end{supertabular}\n\\end{center}\n}\n%END LATEX\n\n%BEGIN LATEX\n\\renewenvironment{parameters}{%\n\\begin{center}\n\\tablehead{\\hline\nParameter & Value & Default & Description \\\\\n\\hline\n}\n\\begin{supertabular}{lccp{65mm}}\n}{%\n\\hline\n\\end{supertabular}\n\\end{center}\n}\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%END LATEX\n\\newcommand{\\thisversion}{3.0.0 $\\beta$}\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\\begin{document}\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%BEGIN LATEX\n\\preprintno{}\n%%%\\preprintno{arXiv:0708.4233 (also based on LC-TOOL-2001-039 (revised))}\n%END LATEX\n\\title{%\n%HEVEA WHIZARD 3.0 \\\\\n%BEGIN LATEX\n \\ttt{\\huge WHIZARD 3.0} \\\\[\\baselineskip]\n%END LATEX\n A generic \\\\ Monte-Carlo integration and event generation package \\\\\n for multi-particle processes\\\\[\\baselineskip]\n MANUAL\n \\footnote{%\n This work is supported by Helmholtz-Alliance ``Physics at the\n Terascale''.\n In former stages this work has also been supported by\n the Helmholtz-Gemeinschaft VH--NG--005 \\\\\n E-mail: \\ttt{whizard@desy.de}\n }\n \\\\[\\baselineskip]\n}\n% \\def\\authormail{\\ttt{kilian@physik.uni-siegen.de},\n%   \\ttt{ohl@physik.uni-wuerzburg.de},\n%   \\ttt{juergen.reuter@desy.de}, \\ttt{cnspeckn@googlemail.com}}\n\\author{%\n  Wolfgang Kilian, %\n  Thorsten Ohl, %\n  J\\\"urgen Reuter, %\n  with contributions from\n  Fabian Bach, %\n  Simon Bra\\ss, %\n  Pia Bredt, %\n  Bijan Chokouf\\'{e} Nejad, %\n  Christian Fleper, %\n  Vincent Rothe, %\n  Sebastian Schmidt, %\n  Marco Sekulla, %\n  Christian Speckner, %\n  So Young Shim, %\n  Florian Staub, %\n  Pascal Stienemeier, %\n  Christian Weiss}\n\n%BEGIN LATEX\n\\address{%\n Universit\\\"at Siegen, Emmy-Noether-Campus, Walter-Flex-Str. 3,\n D--57068 Siegen, Germany \\\\\n Universit\\\"at W\\\"urzburg, Emil-Hilb-Weg 22,\n D--97074 W\\\"urzburg, Germany \\\\\n Deutsches Elektronen-Synchrotron DESY, Notkestr. 85,\n D--22603 Hamburg, Germany \\\\\n %% \\authormail\n \\vspace{1cm}\n \\begin{center}\n \\includegraphics[width=4cm]{Whizard-Logo}\n \\end{center}\n \\mbox{} \\\\\n \\vspace{2cm}\n \\mbox{} when using \\whizard\\ please cite: \\\\\n W. Kilian, T. Ohl, J. Reuter, \\\\ {\\em WHIZARD: Simulating Multi-Particle\n Processes at LHC and ILC}, \\\\\n Eur.Phys.J.{\\bf C71} (2011) 1742, arXiv:\n 0708.4233 [hep-ph]; \\\\\n M. Moretti, T. Ohl, J. Reuter, \\\\ {\\em O'Mega: An Optimizing Matrix\n Element Generator}, \\\\\n arXiv: hep-ph/0102195\n}\n%END LATEX\n%BEGIN LATEX\n\\abstract{%\n\\whizard\\ is a program system designed for the efficient calculation\nof multi-particle scattering cross sections and simulated event\nsamples.  The generated events can be written to file in various formats\n(including HepMC, LHEF, STDHEP, LCIO, and ASCII) or analyzed directly on the\nparton or hadron level using a built-in \\LaTeX-compatible graphics\npackage.\n\\\\[\\baselineskip]\nComplete tree-level matrix elements are generated automatically for arbitrary\npartonic multi-particle processes by calling the built-in matrix-element\ngenerator \\oMega.  Beyond hard matrix elements, \\whizard\\ can generate\n(cascade) decays with complete spin correlations.\nVarious models beyond the SM are implemented, in particular,\nthe MSSM is supported with an interface to the SUSY Les Houches Accord\ninput format.  Matrix elements obtained by alternative methods (e.g.,\nincluding loop corrections) may be interfaced as well.\n\\\\[\\baselineskip]\nThe program uses an adaptive multi-channel method for phase space\nintegration, which allows to calculate numerically stable signal and\nbackground cross sections and generate unweighted event samples with\nreasonable efficiency for processes with up to eight and more\nfinal-state particles.  Polarization is treated exactly for both the\ninitial and final states.  Quark or lepton flavors can be\nsummed over automatically where needed.\n\\\\[\\baselineskip]\nFor hadron collider physics, we ship the package with the most recent\nPDF sets from the MSTW/MMHT and CTEQ/CT10/CJ12/CJ15/CT14\ncollaborations. Furthermore, an interface to the \\lhapdf\\ library is\nprovided.\n\\\\[\\baselineskip]\nFor Linear Collider physics,\nbeamstrahlung (\\circeone, \\circetwo), Compton and ISR spectra are\nincluded for electrons and photons, including the most recent ILC and\nCLIC collider designs. Alternatively, beam-crossing events can be read\ndirectly from file.\n\\\\[\\baselineskip]\nFor parton showering and matching/merging with hard matrix elements ,\nfragmenting and hadronizing the final state, a first version of two\ndifferent parton shower algorithms are included in the \\whizard\\\npackage. This also includes infrastructure for the MLM matching and\nmerging algorithm. For hadronization and hadronic decays, \\pythia\\\nand \\herwig\\ interfaces are provided which follow the Les Houches\nAccord. In addition, the last and final version of (\\fortran) \\pythia\\\nis included in the package.\n\\\\[\\baselineskip]\nThe \\whizard\\ distribution is available at\n%%% \\begin{center}\n%%%   \\ttt{http://whizard.event-generator.org}\n%%% \\end{center}\n%%% or at\n\\begin{center}\n  \\url{https://whizard.hepforge.org}\n\\end{center}\nwhere also the \\ttt{svn} repository is located.\n}\n%END LATEX\n%\n\\maketitle\n\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%% Text\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%\\begin{fmffile}\n\\tableofcontents\n\n\\newpage\n\\chapter{Introduction}\n\n\\section{Disclaimer}\n\n\\emph{This is a preliminary version of the WHIZARD manual.  Many parts\n  are still missing or incomplete, and some parts will be rewritten and\n  improved soon.  To find updated versions of the manual,\n  visit the \\whizard\\ website}\n\\begin{center}\n  \\hepforgepage\n\\end{center}\n\\emph{or consult the current version in the \\ttt{svn} repository\n  on \\hepforgepage\\ directly. Note, that the most recent version of\n  the manual might contain information about features of the\n  current \\ttt{svn} version, which are not contained in the last\n  official release version!}\n\n\\emph{For information that is not (yet) written in the manual, please\nconsult the examples in the \\whizard\\ distribution.  You will find these in\nthe subdirectory \\ttt{share/examples} of the main directory where\n\\whizard\\ is installed. More information about the examples can be\nfound on the \\whizard\\ Wiki page}\n\\begin{center}\n  \\whizardwiki .\n\\end{center}\n\n%%%%%\n\n\\clearpage\n\\section{Overview}\n\n\\whizard\\ is a multi-purpose event generator that covers all parts of\nevent generation (unweighted and weighted), either through intrinsic\ncomponents or interfaces to external packages. Realistic collider\nenvironments are covered through sophisticated descriptions for beam\nstructures at hadron colliders, lepton colliders, lepton-hadron\ncolliders, both circular and linear machines. Other options include\nscattering processes e.g. for dark matter annihilation or particle\ndecays. \\whizard\\ contains its in-house generator for (tree-level)\nhigh-multiplicity matrix elements, \\oMega\\, that supports the whole\nStandard Model (SM) of particle physics and basically all possibile\nextensions of it. QCD parton shower describe high-multiplicity\npartonic jet events that can be matched with matrix elements. At the\nmoment, only hadron collider parton distribution functions (PDFs) and\nhadronization are handled by packages not written by the main\nauthors.\n\nThis manual is organized mainly along the lines of the way how to run\n\\whizard: this is done through a command language, \\sindarin\\ (Scripting\nINtegration, Data Analysis, Results display and INterfaces.) Though\nthis seems a complication at first glance, the user is rewarded with a\nlarge possibility, flexibility and versatility on how to steer\n\\whizard.\n\nAfter some general remarks in the follow-up sections, in\nChap.~\\ref{chap:installation} we describe how to get the program, the\npackage structure, the prerequisites, possible external extensions of\nthe program and the basics of the installation (both as superuser and\nlocally). Also, a first technical overview how to work with \\whizard\\\non single computer, batch clusters and farms are given. Furthermore,\nsome rare uncommon possible build problems are discussed, and a tour\nthrough options for debugging, testing and validation is being made.\n\nA first dive into the running of the program is made in\nChap.~\\ref{chap:start}. This is following by an extensive, but rather\ntechnical introduction into the steering language \\sindarin\\ in\nChap.~\\ref{chap:sindarinintro}. Here, the basic elements of the\nlanguage like commands, statements, control structures, expressions\nand variables as well as the form of warnings and error messages are\nexplained in detail.\n\nChap.~\\ref{chap:sindarin} contains the application of the \\sindarin\\\ncommand language to the main tasks in running \\whizard\\ in a physics\nframework: the defintion of particles, subevents, cuts, and event\nselections. The specification of a particular physics models is\n\\begin{figure}[t]\n  \\centering\n  \\includegraphics[width=0.9\\textwidth]{whizstruct}\n  \\caption{General structure of the \\whizard\\ package.}\n\\end{figure}\ndiscussed, while the next sections are devoted to the setup and\ncompilation of code for particular processes, the specification of\nbeams, beam structure and polarization. The next step is the\nintegration, controlling the integration, phase space, generator cuts,\nscales and weights, proceeding further to event generation and\ndecays. At the end of this chapter, \\whizard's internal data analysis\nmethods and graphical visualization options are documented.\n\nThe following chapters are dedicated to the physics implemented in\n\\whizard: methods for hard matrix interactions in\nChap.~\\ref{chap:hardint}. Then, in Chap.~\\ref{chap:physics},\nimplemented methods for adaptive multi-channel integration,\nparticularly the integrator \\vamp\\ are explained, together with the\nalgorithms for the generation of the phase-space in \\whizard. Finally,\nan overview is given over the physics models implemented in \\whizard\\\nand its matrix element generator \\oMega, together with possibilities\nfor their extension. After that, the next chapter discusses parton\nshowering, matching and hadronization as well as options for event\nnormalizations and supported event formats. Also weighted event\ngeneration is explained along the lines with options for negative\nweights.\n\nChap.~\\ref{chap:visualization} is a stand-alone documentation of\nGAMELAN, the interal graphics support for the visualization of data\nand analysis. The next chapter, Chap.~\\ref{chap:userint} details user\ninterfaces: how to use more options of the \\whizard\\ command on the\ncommand line, how to use \\whizard\\ interactively, and how to include\n\\whizard\\ as a library into the user's own program.\n\nThen, an extensive list of examples in Chap.~\\ref{chap:examples}\ndocumenting physics examples from the LEP, SLC, HERA, Tevatron, and\nLHC colliders to future linear and circular colliders. This chapter is\na particular good reference for the beginning, as the whole chain from\nchoosing a model, setting up processes, the beam structure, the\nintegration, and finally simulation and (graphical) analysis are\nexplained in detail.\n\nMore technical details about efficiency, tuning and advance usage of\n\\whizard\\ are collected in Chap.~\\ref{chap:tuning}. Then,\nChap.~\\ref{chap:extmodels} shows how to set up your own new physics\nmodel with the help of external programs like \\sarah\\ or\n\\FeynRules\\ program or the Universal Feynrules Output, UFO, and\ninclude it into the \\whizard\\ event generator.\n\nIn the appendices, we e.g. give an exhaustive reference list of\n\\sindarin\\ commands and built-in variables.\n\nPlease report any inconsistencies, bugs, problems or simply pose open\nquestions to our contact \\url{whizard@desy.de}.\n\nThere is now also a support page on \\texttt{Launchpad}, which offers\nsupport that is easily visible for the whole user community:\n\\url{https://launchpad.net/whizard}.\n\n\n\n%%%%%\n\n\\section{Historical remarks}\n\nThis section gives a historical overview over the development of\n\\whizard\\ and can be easily skipped in a (first) reading of the\nmanual. \\whizard\\ has been developed in a first place as a tool for\nthe physics at the then planned linear electron-positron collider\nTESLA around 1999. The intention was to have a tool at hand to\ndescribe electroweak physics of multiple weak bosons and the Higgs\nboson as precise as possible with full matrix elements. Hence, the\nacronym: \\ttt{WHiZard}, which stood for $\\mathbf{W}$, {\\bf H}iggs,\n$\\mathbf{Z}$, {\\bf a}nd {\\bf r}espective {\\bf d}ecays.\n\nSeveral components of the \\whizard\\ package that are also available as\nindependent sub-packages have been published already before the first\nversions of the \\whizard\\ generator itself: the multi-channel adaptive\nMonte-Carlo integration package \\vamp\\ has been released mid\n1998~\\cite{VAMP}. The dedicated packages for the simulation of linear\nlepton collider beamstrahlung and the option for a photon collider on\nCompton backscattering (\\ttt{CIRCE1/2}) date back even to mid\n1996~\\cite{CIRCE}. Also parts of the code for \\whizard's internal\ngraphical analysis (the \\gamelan\\ module) came into existence already\naround 1998.\n\nAfter first inofficial versions, the official version 1 of \\whizard\\\nwas release in the year 2000. The development, improvement and\nincorporation of new features continued for roughly a decade. Major\nmilestones in the development were the full support of all kinds of\nbeyond the Standard Model (BSM) models including spin 3/2 and spin 2\nparticles and the inclusion of the MSSM, the NMSSM, Little Higgs\nmodels and models for anomalous couplings as well as extra-dimensional\nmodels from version 1.90 on. In the beginning, several methods for\nmatrix elements have been used, until the in-house matrix element\ngenerator \\oMega\\ became available from version 1.20 on. It was\nincluded as a part of the \\whizard\\ package from version 1.90 on. The\nsupport for full color amplitudes came with version 1.50, but in a\nfull-fledged version from 2.0 on. Version 1.40 brought the necessary\nsetups for all kinds of collider environments, i.e. asymmetric beams,\ndecay processes, and intrinsic $p_T$ in structure functions.\n\nVersion 2.0 was released in April 2010 as an almost complete rewriting\nof the original code. It brought the construction of an internal\ndensity-matrix formalism which allowed the use of factorized\nproduction and (cascade) decay processes including complete color and\nspin correlations. Another big new feature was the command-line\nlanguage \\sindarin\\ for steering all parts of the program. Also, many\nperformance improvement have taken place in the new release series,\nlike OpenMP parallelization, speed gain in matrix element generation\netc. Version 2.2 came out in May 2014 as a major refactoring of the\nprogram internals but keeping (almost everywhere) the same user\ninterface. New features are inclusive processes, reweighting, and more\ninterfaces for QCD environments (BLHA/HOPPET).\n\nThe following tables shows some of the major steps (physics\nimplementation and/or technical improvements) in the development\nof \\whizard (we break the table into logical and temporal blocks of\n\\whizard\\ development):\n\n\\begin{center}\n\\begin{tabular}{|l|l|l|}\\hline\n  0.99 & 08/1999 & Beta version \\\\\\hline\n  1.00 & 12/2000 & First public version \\\\\\hline\n  1.10 & 03/2001 & Libraries; \\pythiasix\\ interface \\\\\n  1.11 & 04/2001 & PDF support; anomalous couplings \\\\ \\hline\n  1.20 & 02/2002 & \\oMega\\ matrix elements; \\ttt{CIRCE} support\\\\\n  1.22 & 03/2002 & QED ISR; beam remnants, phase space improvements \\\\\n  1.25 & 05/2003 & MSSM; weighted events; user-code plug-in \\\\\n  1.28 & 04/2004 & Improved phase space; SLHA interface; signal catching\n  \\\\\\hline\n  1.30 & 09/2004 & Major technical overhaul \\\\\\hline\n  1.40 & 12/2004 & Asymmetric beams; decays; $p_T$ in structure\n  functions \\\\\\hline\n  1.50 & 02/2006 & QCD support in \\oMega\\ (color flows); LHA format \\\\\n  1.51 & 06/2006 & $Hgg$, $H\\gamma\\gamma$; Spin 3/2 + 2; BSM models\n  \\\\\\hline\n  1.90 & 11/2007 & \\oMega\\ included; LHAPDF support; $Z'$; $WW$ scattering \\\\\n  1.92 & 03/2008 & LHE format; UED; parton shower beta version \\\\\n  1.93 & 04/2009 & NMSSM; SLHA2 accord; improved color/flavor sums \\\\\n  1.95 & 02/2010 & MLM matching; development stop in version 1\n  \\\\\n  1.97 & 05/2011 & Manual for version 1 completed. \\\\\\hline\\hline\n\\end{tabular}\n\\end{center}\n\\begin{center}\n\\begin{tabular}{|l|l|l|}\\hline\n  2.0.0 & 04/2010 & Major refactoring: automake setup; dynamic\n  libraries \\\\\n  & & improved speed; cascades; OpenMP; \\sindarin\\ steering language \\\\\n  2.0.3 & 07/2010 & QCD ISR+FSR shower; polarized beams \\\\\n  2.0.5 & 05/2011 & Builtin PDFs; static builds; relocation scripts \\\\\n  2.0.6 & 12/2011 & Anomalous top couplings; unit tests \\\\\\hline\n  2.1.0 & 06/2012 & Analytic ISR+FSR parton shower; anomalous Higgs\n  couplings \\\\\\hline\n  2.2.0 & 05/2014 & Major technical refactoring: abstract\n  object-orientation; THDM; \\\\\n  & & reweighting; LHE v2/3; BLHA; HOPPET interface; inclusive\n  processes \\\\\n  2.2.1 & 05/2014 & CJ12 PDFs; FastJet interface \\\\\n  2.2.2 & 07/2014 & LHAPDF6 support; correlated LC beams; GuineaPig\n  interface \\\\\n  2.2.3 & 11/2014 & O'Mega virtual machine; lepton collider top\n  pair threshold; \\\\\n  & & Higgs singlet extension \\\\\n  2.2.4 & 02/2015 & LCIO support; progress on NLO; many technical\n  bug fixes \\\\\n  2.2.7 & 08/2015 & progress on POWHEG; fixed-order NLO events; \\\\\n  & & revalidation of ILC event chain \\\\\n  2.2.8 & 11/2015 & support for quadruple precision; StdHEP included; \\\\\n  & & SM dim 6 operators supported\n  \\\\\\hline\n\\end{tabular}\n\\end{center}\n\\begin{center}\n\\begin{tabular}{|l|l|l|}\\hline\n  2.3.0 & 07/2016 & NLO: resonance mappings for FKS subtraction; \\\\\n  & & more advanced cascade syntax; \\\\\n  & & GUI ($\\alpha$ version); UFO support\n  ($\\alpha$ version); ILC v1.9x-v2.x final validation \\\\\n  2.3.1 & 08/2016 & Complex mass scheme\n  \\\\\\hline\n  2.4.0 & 11/2016 & Refactoring of NLO setup \\\\\n  2.4.1 & 03/2017 & $\\alpha$ version of new VEGAS implementation\n  \\\\\\hline\n  2.5.0 & 05/2017 & Full UFO support (SM-like models)\n  \\\\\\hline\n  2.6.0 & 09/2017 & MPI parallel integration and event generation;\n  resonance histories \\\\\n  & & for showers; RECOLA support \\\\\n  2.6.1 & 11/2017 & EPA/ISR transverse distributions, handling of\n  shower resonances; \\\\\n  & & more efficient (alternative) phase space generation \\\\\n  2.6.2 & 12/2017 & $Hee$ coupling, improved resonance matching \\\\\n  2.6.3 & 02/2018 & Partial NLO refactoring for quantum numbers, \\\\\n  &  & unified RECOLA 1/2 interface. \\\\\n  2.6.4 & 08/2018 & Gridpack functionality; Bug fixes: color flows,\n  HSExt model, MPI setup\n  \\\\\\hline\n  2.7.0 & 01/2019 & PYTHIA8 interface, process setup refactoring,\n  RAMBO PS option; \\\\\n  & & \\quad gfortran 5.0+ necessary\n  \\\\\\hline\n  2.8.0 & 08/2019 & (Almost) complete UFO support, general Lorentz\n  structures, n-point vertices \\\\\n  2.8.1 & 09/2019 & HepMC3, NLO QCD pp (almost)\n  complete, b/c jet selection, photon isolation \\\\\n  2.8.2 & 10/2019 & Support for OCaml $\\geq$ 4.06.0, UFO Spin-2 support,\n  LCIO alternative weights \\\\\n  2.8.3 & 07/2020 & UFO Majorana feature complete, many $e^+e^-$ related\n  improvements \\\\\n  2.8.4 & 07/2020 & Bug fix for UFO Majorana models \\\\\n  2.8.5 & 09/2020 & Bug fix for polarizations in $H\\to\\tau\\tau$\n  \\\\\\hline\\hline\n\\end{tabular}\n\\end{center}\n\n\\vspace{.5cm}\n\nFor a detailed overview over the historical development of the code\nconfer the \\ttt{ChangeLog} file and the commit messages in our\nrevision control system repository.\n\n%%%%%\n\n\\section{About examples in this manual}\n\nAlthough \\whizard\\ has been designed as a Monte Carlo event generator\nfor LHC physics, several elementary steps and aspects of its usage\nthroughout the manual will be demonstrated with the famous textbook\nexample of $e^+e^- \\to \\mu^+ \\mu^-$. This is the same process, the\ntextbook by Peskin/Schroeder \\cite{PeskinSchroeder} uses as a prime\nexample to teach the basics of quantum field theory. We use this\nexample not because it is very special for \\whizard\\ or at the time\nbeing a relevant physics case, but simply because it is the easiest\nfundamental field theoretic process without the complications of\nstructured beams (which can nevertheless be switched on like for ISR\nand beamstrahlung!), the need for jet definitions/algorithms and\nflavor sums; furthermore, it easily accomplishes a demonstration of\npolarized beams. After the basics of \\whizard\\ usage have been\nexplained, we move on to actual physics cases from LHC (or Tevatron).\n\n\n\\newpage\n\\chapter{Installation}\n\\label{chap:installation}\n\n\\section{Package Structure}\n\n\\whizard\\ is a software package that consists of a main executable\nprogram (which is called \\ttt{whizard}), libraries, auxiliary\nexecutable programs, and machine-independent data files.  The whole\npackage can be installed by the system administrator, by default, on a\ncentral location in the file system (\\ttt{/usr/local} with its proper\nsubdirectories).  Alternatively, it is possible to install it in a\nuser's home directory, without administrator privileges, or at any\nother location.\n\nA \\whizard\\ run requires a workspace, i.e., a writable directory where\nit can put generated code and data.  There are no constraints on the\nlocation of this directory, but we recommend to use a separate\ndirectory for each \\whizard\\ project, or even for each \\whizard\\ run.\n\nSince \\whizard\\ generates the matrix elements for scattering and decay\nprocesses in form of \\fortran\\ code that is automatically compiled and\ndynamically linked into the running program, it requires a working\n\\fortran\\ compiler not just for the installation, but also at runtime.\n\nThe previous major version \\whizard1 did put more constraints on the\nsetup.  In a nutshell, not just the matrix element code was compiled\nat runtime, but other parts of the program as well, so the whole\npackage was interleaved and had to be installed in user space.  The\nworkflow was controlled by \\ttt{make} and PERL scripts.  These\nconstraints are gone in the present version in favor of a clean\nseparation of installation and runtime workspace.\n\n\n\\section{\\label{sec:prerequisites}Prerequisites}\n\n\\subsection{No Binary Distribution}\n\n\\whizard\\ is currently not distributed as a binary package, nor is it\navailable as a debian or RPM package.  This might change in the\nfuture.  However, compiling from source is very simple (see below).\nSince the package needs a compiler also at runtime, it would not work\nwithout some development tools installed on the machine, anyway.\n\nNote, however, that we support an install script, that downloads all\nnecessary prerequisites, and does the configuration and compilation\ndescribed below automatically. This is called the ``instant WHIZARD''\nand is accessible through the WHIZARD webpage from version 2.1.1 on:\n\\url{https://whizard.hepforge.org/versions/install/install-whizard-2.X.X.sh}.\nDownload this shell script, make it executable by\n\\begin{interaction}\n  chmod +x install-whizard-2.X.X.sh\n\\end{interaction}\nand execute it. Note that this also involves compilation of the\nrequired \\fortran\\ compiler which takes 1-3 hours depending on\nyour system.\n\\ttt{Darwin} operating systems (a.k.a. as \\ttt{Mac OS X}) have a very\nsimilar general system for all sorts of software, called\n\\ttt{MacPorts} (\\url{http://www.macports.org}). This offers to install\n\\whizard\\ as one of its software ports, and is very similar to\n``instant WHIZARD'' described above.\n\n\n\\subsection{Tarball Distribution}\n\\label{sec:tarballdistr}\n\nThis is the recommended way of obtaining \\whizard.  You may download\nthe current stable distribution from the \\whizard\\ webpage,\nhosted at the HepForge webpage\n\\begin{quote}\n  \\hepforgepage\n\\end{quote}\nThe distribution is a single file, say \\ttt{whizard-\\thisversion.tgz} for\nversion \\thisversion.\n\nYou need the additional prerequisites:\n\\begin{itemize}\n\\item\n  GNU \\ttt{tar} (or \\ttt{gunzip} and \\ttt{tar}) for unpacking the\n  tarball.\n\\item\n  The \\ttt{make} utility.  Other standard Unix utilities (\\ttt{sed},\n  \\ttt{grep}, etc.) are usually installed by default.\n\\item\n  A modern \\fortran\\ compiler (see Sec.~\\ref{sec:compilers} for\n  details).\n\\item\n  The \\ocaml\\ system.  \\ocaml\\ is a functional and object-oriented\n  language.  Version 4.02.3 or newer is required to compile all\n  components of \\whizard. The package is freely available either as a\n  debian/RPM package on your system (it might be necessary to install\n  it from the usual repositories), or you can obtain it directly from\n  \\begin{quote}\n    \\url{http://caml.inria.fr}\n  \\end{quote}\n  and install it yourself.  If desired, the package can be installed\n  in user space without administrator privileges\\footnote{\n    Unfortunately, the version of the \\ocaml\\\n    compiler from 3.12.0 broke backwards compatibility. Therefore,\n    versions of \\oMega/\\whizard\\ up to 2.0.2 only compile with older\n    versions (3.11.x works). This has been fixed in versions\n    2.0.3 and later. See also\n    Sec.~\\ref{sec:buildproblems}. \\whizard\\ versions up to 2.7.1 were\n    still backwards compatible with \\ocaml\\ 3.12.0}.\n\\end{itemize}\nThe following optional external packages are not required, but used\nfor certain purposes.  Make sure to check whether you will need any of\nthem, before you install \\whizard.\n\\begin{itemize}\n\\item\n  \\LaTeX\\ and \\metapost\\ for data visualization.  Both are part of the\n  \\TeX\\ program family.  These programs are not absolutely necessary,\n  but \\whizard\\ will lack the tools for visualization without them.\n\\item\n  The \\lhapdf\\ structure-function library.  See\n  Sec.~\\ref{sec:lhapdf_install}.\n\\item\n  The \\hoppet\\ structure-function matching tool. See\n  Sec.~\\ref{sec:hoppet}.\n\\item\n  The \\hepmc\\ event-format package.  See Sec.~\\ref{sec:hepmc}.\n\\item\n  The \\fastjet\\ jet-algorithm package.  See Sec.~\\ref{sec:fastjet}.\n\\item\n  The \\lcio\\ event-format package.  See Sec.~\\ref{sec:lcio}.\n\\end{itemize}\nUntil version v2.2.7 of \\whizard, the event-format package \\stdhep\\ used\nto be available as an external package. As their distribution is frozen\nwith the final version v5.06.01, and it used to be notoriously difficult to\ncompile and link \\stdhep\\ into \\whizard, it was decided to include \\stdhep\\\ninto \\whizard. This is the case from version v2.2.8 of \\whizard\\ on. Linking\nagainst an external version of \\stdhep\\ is precluded from there\non. Nevertheless, we list some explanations in Sec.~\\ref{sec:stdhep},\nparticularly on the need to install the \\ttt{libtirpc} headers for the\nlegacy support of this event format. Once these prerequisites are met,\nyou may unpack the package in a directory of your choice\n\\begin{quote}\\small\\tt\n  some-directory> tar xzf whizard-\\thisversion.tgz\n\\end{quote}\nand proceed.\\footnote{Without GNU \\ttt{tar}, this would read\n  \\ttt{\\small gunzip -c whizard-\\thisversion.tgz | tar xz -}}\n\nFor using external physics models that are directly supported by\n\\whizard\\ and \\oMega, the user can use tools like \\sarah\\ or\n\\FeynRules. There installation and linking to \\whizard\\ will be\nexplained in Chap.~\\ref{chap:extmodels}. Besides this, also new models\ncan be conveniently included via \\UFO\\ files, which will be explained\nas well in that chapter.\n\nThe directory will then contain a subdirectory \\ttt{whizard-\\thisversion}\nwhere the complete source tree is located.  To update later to a new\nversion, repeat these steps.  Each new version will unpack in a\nseparate directory with the appropriate name.\n\n%%%%%\n\n\\subsection{SVN Repository Version}\n\nIf you want to install the latest development version, you have to\ncheck it out from the \\whizard\\ SVN repository. Note that since a\ncouple of years our development is now via a Git revision control\nsystem hosted at the University of Siegen, cf. the next subsection. \n\nIn addition to the prerequisites listed in the previous section, you\nneed:\n\\begin{itemize}\n\\item\n  The \\ttt{subversion} package (\\ttt{svn}), the tool for dealing with\n  SVN repositories.\n\\item\n  The \\ttt{autoconf} package, part of the \\ttt{autotools} development\n  system. \\ttt{automake} is needed with version \\ttt{1.12.2} or newer.\n\\item\n  The \\ttt{noweb} package, a light-weight tool for literate programming.  This\n  package is nowadays often part of Linux distributions\\footnote{In\n    Ubuntu from version 10.04 on, and in Debian since\n    squeeze. For \\ttt{Mac OS X}, \\ttt{noweb} is available via the\n    \\ttt{MacPorts} system.}.  You can obtain the source code\n  from\\footnote{Please, do not use any of the binary builds from this\n    webpage. Probably all of them are quite old and broken.}\n  \\begin{quote}\n    \\url{http://www.cs.tufts.edu/~nr/noweb/}\n  \\end{quote}\n\\end{itemize}\nTo start, go to a directory of your choice and execute\n\\begin{interaction}\n  your-src-directory> svn checkout\n  svn+ssh://vcs@phab.hepforge.org/source/whizardsvn/trunk \\;\\; .\n\\end{interaction}\nNote that for the time being after the HepForge system modernization\nearly September 2018, a HepForge account with a local ssl key is\nnecessary to checkout the subversion repository. This is enforced by\nthe phabricator framework of HepForge, and will hopefully be relaxed\nin the future. The SVN source tree will appear in the current\ndirectory.  To update later, you just have to execute\n\\begin{interaction}\n  your-src-directory> svn update\n\\end{interaction}\nwithin that directory.\n\nAfter checking out the sources, you first have to create\n\\ttt{configure.ac} by executing the shell script\n\\ttt{build\\_master.sh}. In order to build the \\ttt{configure}\nscript, the \\ttt{autotools} package \\ttt{autoreconf} has to be run. On\nsome \\ttt{Unix} systems the \\ttt{RPC} headers needed for the legacy\nsupport of the \\stdhep\\ event format are provided by the \\ttt{TIRPC}\nlibrary (cf. Sec.~\\ref{sec:stdhep}). To easily check for them,\n\\ttt{configure.ac} processed by \\ttt{autoreconf} makes use of the\n\\ttt{pkg-config} tool which needs to be installed for the developer\nversion. So now, run\\footnote{At least, version\n  2.65 of the \\ttt{autoconf} package is required.}\n\\begin{interaction}\n  your-src-directory> autoreconf\n\\end{interaction}\nThis will generate a \\ttt{configure} script.\n\n%%%%%\n\n\\subsection{Public Git Repository Version}\n\nSince a couple of years, development of \\whizard\\ is done by means of\na Git revision system, hosted at the University of Siegen. There is a\npublic mirror of that Git repository available at\n\\begin{quote}\n  \\url{https://gitlab.tp.nt.uni-siegen.de/whizard/public}\n\\end{quote}\nCloning via HTTPS brings the user to the same change as the SVN\ncheckout from HepForge described in the previous subsection:\n\\begin{quote}\n  git clone https://gitlab.tp.nt.uni-siegen.de/whizard/public.git\n\\end{quote}\nThe next steps are the same as described in the previous subsection.\n\n%%%%%\n\n\\subsection{Nightly development snapshots}\n\nNightly development snapshots that are pre-packaged in the same way\nas an official distribution are available from\n\\begin{quote}\n  \\url{https://whizard.tp.nt.uni-siegen.de/}\n\\end{quote}\nBuilding \\whizard\\ works the way as described in\nSec.~\\ref{sec:tarballdistr}. \n\n\n%%%%%\n\n\\subsection{\\label{sec:compilers}Fortran Compilers}\n\n\\whizard\\ is written in modern \\fortran.  To be precise, it uses a\nsubset of the \\fortranOThree\\ standard.  At the time of this writing,\nthis subset is supported by, at least, the following compilers:\n\\begin{itemize}\n\\item\n  \\ttt{gfortran} (GNU, Open Source).  You will need version 5.1.0\n  or higher\\footnote{Note that \\whizard\\ versions 2.0.0 until 2.3.1 compiled\n  with \\ttt{gfortran} 4.7.4, but the object-oriented\n  refactoring of the \\whizard\\ code from 2.4.0 on until version 2.6.5\n  made a switch to \\ttt{gfortran} 4.8.4 or higher necessary. In the\n  same way, since version 2.7.0, \\ttt{gfortran} 5.1.0 or newer is\n  needed}. We recommend to use at least version 5.4 or higher, as\n  especially the the early version of the \\texttt{gfortran} experience\n  some bugs. \\ttt{gfortran} 6.5.0 has a severe regression and cannot\n  be used.\n\\item\n  \\ttt{nagfor} (NAG).  You will need version 6.2 or higher.\n\\item\n  \\ttt{ifort} (Intel). You will need version 19.0.2 or\n  higher\n\\end{itemize}\n\n%%%%%\n\n\\subsection{LHAPDF}\n\\label{sec:lhapdf_install}\n\nFor computing scattering processes at hadron colliders such as the\nLHC, \\whizard\\ has a small set of standard structure-function\nparameterizations built in, cf.\\ Sec.~\\ref{sec:built-in-pdf}.  For\nmany applications, this will be sufficient, and you can skip this\nsection.\n\nHowever, if you need structure-function parameterizations that are not\nin the default set (e.g. PDF error sets), you can use the \\lhapdf\\\nstructure-function library, which is an external package.  It has to\nbe linked during \\whizard\\ installation.  For use with \\whizard,\nversion 5.3.0 or higher of the library is required\\footnote{ Note that\n  PDF sets which contain photons as partons are only supported with\n  \\whizard\\ for \\lhapdf\\ version 5.7.1 or higher}. The \\lhapdf\\\npackage has undergone a major rewriting from \\fortran\\ version 5\nto \\cpp\\ version 6. While still maintaining the interface for\nthe \\lhapdf\\ version 5 series, from version 2.2.2 of \\whizard\\ on, the\nnew release series of \\lhapdf, version 6.0 and higher, is also\nsupported.\n\nIf \\lhapdf\\ is not yet installed on your system, you can download it from\n\\begin{quote}\n  \\url{https://lhapdf.hepforge.org}\n\\end{quote}\nfor the most recent LHAPDF version 6 and newer, or\n\\begin{quote}\n  \\url{https://lhapdf.hepforge.org/lhapdf5}\n\\end{quote}\nfor version 5 and older, and install it.  The website contains\ncomprehensive documentation on the configuring and installation\nprocedure.  Make sure that you have downloaded and installed not just\nthe package, but also the data sets. Note that \\lhapdf\\ version 5\nneeds both a \\fortran\\ and a \\cpp\\ compiler.\n\nDuring \\whizard\\ configuration, \\whizard\\ looks for the script\n\\ttt{lhapdf} (which is present in \\lhapdf\\ series 6) first, and then\nfor \\ttt{lhapdf-config} (which is present since \\lhapdf\\ version\n4.1.0): if those are in an executable path (or only\nthe latter for \\lhapdf\\ version 5), the environment variables for\n\\lhapdf\\ are automatically recognized by \\whizard, as well as the\nversion number. This should look like this in the \\ttt{configure}\noutput (for \\lhapdf\\ version 6 or newer),\n\n\\begin{footnotesize}\n\\begin{verbatim}\n   configure: --------------------------------------------------------------\n   configure: --- LHAPDF ---\n   configure:\n   checking for lhapdf... /usr/local/bin/lhapdf\n   checking for lhapdf-config... /usr/local/bin/lhapdf-config\n   checking the LHAPDF version... 6.2.1\n   checking the major version... 6\n   checking the LHAPDF pdfsets path... /usr/local/share/LHAPDF\n   checking the standard PDF sets...  all standard PDF sets installed\n   checking if LHAPDF is functional... yes\n   checking LHAPDF... yes\n   configure: --------------------------------------------------------------\n\\end{verbatim}\n\\end{footnotesize}\nwhile for \\lhapdf\\ version 5 and older it looks like this:\n\n\\begin{footnotesize}\n\\begin{verbatim}\n   configure: --------------------------------------------------------------\n   configure: --- LHAPDF ---\n   configure:\n   checking for lhapdf... no\n   checking for lhapdf-config... /usr/local/bin/lhapdf-config\n   checking the LHAPDF version... 5.9.1\n   checking the major version... 5\n   checking the LHAPDF pdfsets path... /usr/local/share/lhapdf/PDFsets\n   checking the standard PDF sets...  all standard PDF sets installed\n   checking for getxminm in -lLHAPDF... yes\n   checking for has_photon in -lLHAPDF... yes\n   configure: --------------------------------------------------------------\n\\end{verbatim}\n\\end{footnotesize}\n\nIf you want to use a different \\lhapdf\\ (e.g. because the one installed\non your system by default is an older one), the preferred way to do so\nis to put the \\ttt{lhapdf} (and/or \\ttt{lhapdf-config}) scripts in an\nexecutable path that is checked before the system paths,\ne.g. \\ttt{<home>/bin}.\n\nFor the old series, \\lhapdf\\ version 5, a possible error could arise\nif \\lhapdf\\ had been compiled with a different \\fortran\\ compiler than\n\\whizard, and if the run-time library of that \\fortran\\ compiler had\nnot been included in the \\whizard\\ configure process. The output then\nlooks like this:\n\n\\begin{footnotesize}\n\\begin{verbatim}\n   configure: --------------------------------------------------------------\n   configure: --- LHAPDF ---\n   configure:\n   checking for lhapdf... no\n   checking for lhapdf-config... /usr/local/bin/lhapdf-config\n   checking the LHAPDF version... 5.9.1\n   checking the major version... 5\n   checking the LHAPDF pdfsets path... /usr/local/share/lhapdf/PDFsets\n   checking for standard PDF sets... all standard PDF sets installed\n   checking for getxminm in -lLHAPDF... no\n   checking for has_photon in -lLHAPDF... no\n   configure: --------------------------------------------------------------\n\\end{verbatim}\n\\end{footnotesize}\n\nSo, the \\whizard\\ configure found the \\lhapdf\\ distribution, but could\nnot link because it could not resolve the symbols inside the\nlibrary. In case of failure, for more details confer the\n\\ttt{config.log}.\n\nIf \\lhapdf\\ is installed in a non-default directory where\n\\whizard\\ would not find it, set the environment variable\n\\ttt{LHAPDF\\_DIR} to the correct installation path when configuring\n\\whizard.\n\nThe check for the standard PDF sets are those sets that are used in\nthe default \\whizard\\ self tests in the case \\lhapdf\\ is enabled and\ncorrectly linked. If some of them are missing, then this test will\nresult in a failure. They are the \\ttt{CT10} set for \\lhapdf\\ version\n6 (for version 5, \\ttt{cteq61.LHpdf}, \\ttt{cteq6ll.LHpdf},\n\\ttt{cteq5l.LHgrid}, and \\ttt{GSG961.LHgrid} are demanded). If you\nwant to use \\lhapdf\\ inside \\whizard\\ please install them such that\n\\whizard\\ could perform all its sanity checks with them. The last\ncheck is for the \\ttt{has\\_photon} flag, which tests whether photon\nPDFs are available in the found \\lhapdf\\ installation.\n\n%%%%%\n\n\\subsection{HOPPET}\n\\label{sec:hoppet}\n\n\\hoppet\\ (not Hobbit) is a tool for the QCD DGLAP evolution of PDFs\nfor hadron colliders. It provides possibilities for matching\nalgorithms for 4- and 5-flavor schemes, that are important for\nprecision simulations of $b$-parton initiated processes at hadron\ncolliders. If you are not interested in those features, you can skip\nthis section. Note that this feature is not enabled by default (unlike\ne.g. \\lhapdf), but has to be explicitly during the configuration\n(see below):\n\\begin{interaction}\n  your-build-directory> your-src-directory/configure --enable-hoppet\n\\end{interaction}\nIf you \\ttt{configure} messages like the following:\n\\begin{footnotesize}\n\\begin{verbatim}\nconfigure: --------------------------------------------------------------\nconfigure: --- HOPPET ---\nconfigure:\nchecking for hoppet-config... /usr/local/bin/hoppet-config\nchecking for hoppetAssign in -lhoppet_v1... yes\nchecking the HOPPET version... 1.2.0\nconfigure: --------------------------------------------------------------\n\\end{verbatim}\n\\end{footnotesize}\nthen you know that \\hoppet\\ has been found and was correctly\nlinked. If that is not the case, you have to specify the location of\nthe \\hoppet\\ library, e.g. by adding\n\\begin{interaction}\n  HOPPET=<hoppet\\_directory>/lib\n\\end{interaction}\nto the \\ttt{configure} options above. For more details, please confer\nthe \\hoppet\\ manual.\n\n%%%%%\n\n\\subsection{HepMC}\n\\label{sec:hepmc}\n\nWith version 2.8.1, \\whizard\\ supports both the \"classical\" version 2\nas well as the newly designed version 3 (release 2019). The configure\nstep can successfully recognize the two  different versions, the user\ndo not have to specify which version is installed.\n\n\\hepmc\\ is a \\cpp\\ class library for handling collider scattering\nevents.  In particular, it provides a portable format for event files.\nIf you want to use this format, you should link \\whizard\\ with \\hepmc,\notherwise you can skip this section.\n\nIf it is not already installed on your system, you may obtain\n\\hepmc\\ from one of these two webpages:\n\\begin{quote}\n  \\url{http://hepmc.web.cern.ch/hepmc/}\n\\end{quote}\nor\n\\begin{quote}\n  \\url{http://hepmc.web.cern.ch/hepmc/}\n\\end{quote}\nIf the \\hepmc\\ library is linked with the installation, \\whizard\\ is\nable to read and write files in the \\hepmc\\ format.\n\nDetailed information on the installation and usage can be found on the\n\\hepmc\\ homepage. We give here only some brief details relevant for\nthe usage with \\whizard: For the compilation of HepMC one needs a\n\\cpp\\ compiler. Then the procedure is the same as for the\n\\whizard\\ package, namely configure HepMC:\n\\begin{interaction}\n  configure --with-momentum=GEV --with-length=MM --prefix=<install dir>\n\\end{interaction}\nNote that the particle momentum and decay length flags are mandatory, and\nwe highly recommend to set them to the values \\ttt{GEV} and \\ttt{MM},\nrespectively. After configuration, do \\ttt{make}, an optional\n\\ttt{make check} (which might sometimes fail for non-standard values\nof momentum and length), and finally \\ttt{make install}.\n\nThe latest version of \\hepmc\\ (2.6.10) as well as the new relase\nseries use \\texttt{cmake} for their build process. For more\ninformation, confer the \\hepmc\\ webpage.\n\nA \\whizard\\ configuration for \\hepmc\\ looks like this:\n\\begin{footnotesize}\n  \\begin{verbatim}\n   configure: --------------------------------------------------------------\n   configure: --- HepMC ---\n   configure:\n   checking for HepMC-config... no\n   checking HepMC3 or newer... no\n   configure: HepMC3 not found, incompatible, or HepMC-config not found\n   configure: looking for HepMC2 instead ...\n   checking the HepMC version... 2.06.10\n   checking for GenEvent class in -lHepMC... yes\n   configure: --------------------------------------------------------------\n  \\end{verbatim}\n\\end{footnotesize}\n\nIf \\hepmc\\ is installed in a non-default directory where \\whizard\\\nwould not find it, set the environment variable \\ttt{HEPMC\\_DIR} to\nthe correct installation path when configuring \\whizard.  Furthermore,\nthe environment variable \\ttt{CXXFLAGS} allows you to set specific\n\\ttt{C/C++} preprocessor flags, e.g. non-standard include paths for\nheader files.\n\nA typical configuration of \\hepmcthree\\ will look like this:\n\\begin{footnotesize}\n\\begin{verbatim}\nconfigure: --------------------------------------------------------------\nconfigure: --- ROOT ---\nconfigure:\nchecking for root-config... /usr/local/bin/root-config\nchecking for root... /usr/local/bin/root\nchecking for rootcint... /usr/local/bin/rootcint\nchecking for dlopen in -ldl... (cached) yes\nconfigure: --------------------------------------------------------------\nconfigure: --- HepMC ---\nconfigure:\nchecking for HepMC3-config... /usr/local/bin/HepMC3-config\nchecking if HepMC3 is built with ROOT interface... yes\nchecking if HepMC3 is functional... yes\nchecking for HepMC3... yes\nchecking the HepMC3 version... 3.02.01\nconfigure: --------------------------------------------------------------\n\\end{verbatim}\n\\end{footnotesize}\nAs can be seen, \\whizard\\ will check for the \\ROOT\\ environment as\nwell as whether \\hepmcthree\\ has been built with support for the\n\\ROOT\\ and \\ttt{RootTree} writer classes. This is an easy option to\nuse \\whizard\\ to write out \\ROOT\\ events. For more information see\nSec.~\\ref{sec:root}.\n\n%%%%%\n\n\\subsection{PYTHIA6}\n\\label{sec:pythia6_conf}\n\nThe \\whizard\\ package ships with the final version of the old\n\\pythiasix\\ release series, v6.427. This is no longer maintained, but\nmany analyses are still set up for this shower and hadronization tool,\nso \\whizard\\ offers the possibility of backwards compatibility here.\n\\begin{quote}\nconfigure: --------------------------------------------------------------\nconfigure: --- SHOWERS PYTHIA6 PYTHIA8 MPI ---\nconfigure: \nchecking whether we want to enable PYTHIA6... yes\nchecking for PYTHIA6... (enabled)\nchecking for PYTHIA6 eh settings... (disabled)\n\\end{quote}\n\\whizard\\ automatically compiles \\pythiasix, it has not to be\nspecifically enabled by the user.\n\nIn order to properly use \\pythiasix\\ for high-energy electron-hadron\ncollisions which allow much further forward regions to be explored as\nold experiments like HERA, there is a special switch to enable those\nspecific settings for $eh$-colliders:\n\\begin{quote}\n  \\ttt{--enable-pythia6\\_ep}\n\\end{quote}\nThose settings have been provided by~\\cite{UtaKlein}.\n\n%%%%%\n\n\\subsection{PYTHIA8}\n\\label{sec:pythia8}\n\n\\pythiaeight\\ is a \\cpp\\ class library for handling hadronization,\nshowering and underlying event. If you want to use this feature (once it is\nfully supported in \\whizard), you should link \\whizard\\ with \\pythiaeight,\notherwise you can skip this section.\n\nIf it is not already installed on your system, you may obtain\n\\pythiaeight\\ from\n\\begin{quote}\n  \\url{http://home.thep.lu.se/~torbjorn/Pythia.html}\n\\end{quote}\nIf the \\pythiaeight\\ library is linked with the installation, \\whizard\\ will\nbe able to use its hadronization and showering, once this is fully supported\nwithin \\whizard.\n\nTo link a \\pythiaeight\\ installation to \\whizard, you should specify the flag\n\\begin{quote}\n\\ttt{--enable-pythia8}\n\\end{quote}\nto \\ttt{configure}.  If  \\pythiaeight\\ is installed in a non-default directory\nwhere \\whizard\\ would not find it, specify also\n\\begin{quote}\n\\ttt{--with-pythia8=\\emph{<your-pythia8-installation-path>}}\n\\end{quote}\n\nA successful \\whizard\\ configuration should produce a screen output\nsimilar to this:\n\\begin{footnotesize}\n\\begin{verbatim}\nconfigure: --------------------------------------------------------------\nconfigure: --- SHOWERS PYTHIA6 PYTHIA8 MPI ---\nconfigure:\n[....]\nchecking for pythia8-config... /usr/local/bin/pythia8-config\nchecking if PYTHIA8 is functional... yes\nchecking PYTHIA8... yes\nconfigure: WARNING: PYTHIA8 configure is for testing purposes at the moment.\nconfigure: --------------------------------------------------------------\n\\end{verbatim}\n\\end{footnotesize}\n\n%%%%%\n\n\\subsection{FastJet}\n\\label{sec:fastjet}\n\n\\fastjet\\ is a \\cpp\\ class library for handling jet clustering.\nIf you want to use this feature, you should link \\whizard\\ with \\fastjet,\notherwise you can skip this section.\n\nIf it is not already installed on your system, you may obtain\n\\fastjet\\ from\n\\begin{quote}\n  \\url{http://fastjet.fr}\n\\end{quote}\nIf the \\fastjet\\ library is linked with the installation, \\whizard\\ is\nable to call the jet algorithms provided by this program for the purposes of\napplying cuts and analysis.\n\nTo link a \\fastjet\\ installation to \\whizard, you should specify the flag\n\\begin{quote}\n\\ttt{--enable-fastjet}\n\\end{quote}\nto \\ttt{configure}.  If  \\fastjet\\ is installed in a non-default directory\nwhere \\whizard\\ would not find it, specify also\n\\begin{quote}\n\\ttt{--with-fastjet=\\emph{<your-fastjet-installation-path>}}\n\\end{quote}\n\nA successful \\whizard\\ configuration should produce a screen output\nsimilar to this:\n\\begin{footnotesize}\n\\begin{verbatim}\nconfigure: --------------------------------------------------------------\nconfigure: --- FASTJET ---\nconfigure:\nchecking for fastjet-config... /usr/local/bin/fastjet-config\nchecking if FastJet is functional... yes\nchecking FastJet... yes\nchecking the FastJet version... 3.3.4\nconfigure: --------------------------------------------------------------\n\\end{verbatim}\n\\end{footnotesize}\n\nNote that when compiling on Darwin/macOS it might be necessary to\nset the option \\ttt{--disable-auto-ptr} when compiling with\n\\ttt{clang++}.\n\n%%%%%\n\n\\subsection{STDHEP}\n\\label{sec:stdhep}\n\n\\stdhep\\ is a  library for handling collider scattering\nevents~\\cite{stdhep}.  In particular, it provides a portable format\nfor event files. Until version 2.2.7 of \\whizard, \\stdhep\\ that was\nmaintained by Fermilab, could be linked as an externally compiled\nlibrary. As the \\stdhep\\ package is frozen in its final release\nv5.06.1 and no longer maintained, it has from version 2.2.8 been\nincluded \\whizard. This eases many things, as it was notoriously\ndifficult to compile and link \\stdhep\\ in a way compatible with\n\\whizard. Not the full package has been included, but only the\nlibraries for file I/O (\\ttt{mcfio}, the library for the XDR\nconversion), while the various translation tools for \\pythia, \\herwig,\netc.  have been abandoned. Note that \\stdhep\\ has largely been\nreplaced in the hadron collider community by the \\hepmc\\ format, and\nin the lepton collider community by \\lcio. \\whizard\\ might serve as a\nconversion tools for all these formats, but other tools also exist, of\ncourse. Note that the \\ttt{mcfio} framework makes use of the \\ttt{RPC}\nheaders. These come -- provided by \\ttt{SunOS/Oracle America, Inc.} --\ntogether with the system headers, but on some \\ttt{Unix} systems\n(e.g. \\ttt{ArchLinux}, \\ttt{Fedora}) have been replaced by the\n\\ttt{libtirpc} headers . The \\ttt{configure} script searches for these\nheaders so these have to be installed mandatorily.\n\nIf the \\stdhep\\ library is linked with the installation, \\whizard\\ is\nable to write files in the \\stdhep\\ format, the  corresponding\nconfigure output notifies you that \\stdhep\\ is always included:\n\\begin{footnotesize}\n\\begin{verbatim}\nconfigure: --------------------------------------------------------------\nconfigure: --- STDHEP ---\nconfigure:\nchecking for pkg-config... /opt/local/bin/pkg-config\nchecking pkg-config is at least version 0.9.0... yes\nchecking for libtirpc... no\nconfigure: for StdHEP legacy code: using SunRPC headers and library\nconfigure: StdHEP v5.06.01 is included internally\nconfigure: --------------------------------------------------------------\n\\end{verbatim}\n\\end{footnotesize}\n\n%%%%%\n\n\\subsection{LCIO}\n\\label{sec:lcio}\n\n\n\\lcio\\ is a \\cpp\\ class library for handling collider scattering\nevents.  In particular, it provides a portable format for event files.\nIf you want to use this format, you should link \\whizard\\ with \\lcio,\notherwise you can skip this section.\n\nIf it is not already installed on your system, you may obtain\n\\lcio\\ from:\n\\begin{quote}\n  \\url{http://lcio.desy.de}\n\\end{quote}\nIf the \\lcio\\ library is linked with the installation, \\whizard\\ is\nable to read and write files in the \\lcio\\ format.\n\nDetailed information on the installation and usage can be found on the\n\\lcio\\ homepage. We give here only some brief details relevant for\nthe usage with \\whizard: For the compilation of \\lcio\\ one needs a\n\\cpp\\ compiler. \\lcio\\ is based on \\ttt{cmake}. For the\ncorresponding options please confer the \\lcio\\ manual.\n\nA \\whizard\\ configuration for \\lcio\\ looks like this:\n\\begin{footnotesize}\n  \\begin{verbatim}\n   configure: --------------------------------------------------------------\n   configure: --- LCIO ---\n   configure:\n   checking the LCIO version... 2.12.1\n   checking for LCEventImpl class in -llcio... yes\n   configure: --------------------------------------------------------------\n  \\end{verbatim}\n\\end{footnotesize}\n\nIf \\lcio\\ is installed in a non-default directory where \\whizard\\\nwould not find it, set the environment variable \\ttt{LCIO} or\n\\ttt{LCIO\\_DIR} to the correct installation path when configuring\n\\whizard.  The first one is the variable exported by the\n\\ttt{setup.sh}  script while the second one is analogous to the\nenvironment variables of other external packages. \\ttt{LCIO} takes\nprecedence over \\ttt{LCIO\\_DIR}. Furthermore, the environment variable\n\\ttt{CXXFLAGS} allows you to set specific \\ttt{C/C++} preprocessor\nflags, e.g. non-standard include paths for header files.\n\n%%%%%\n\n\\section{Installation}\n\\label{sec:installation}\n\nOnce you have unpacked the source (either the tarball or the SVN\nversion), you are ready to compile it.  There are several options.\n\n\n\\subsection{Central Installation}\nThis is the default and recommended way, but it requires adminstrator\nprivileges.  Make sure that all\nprerequisites are met (Sec.~\\ref{sec:prerequisites}).\n\\begin{enumerate}\n\\item\n  Create a fresh directory for the \\whizard\\ build.  It is recommended\n  to keep this separate from the source directory.\n\\item\n  Go to that directory and execute\n  \\begin{interaction}\n    your-build-directory> your-src-directory/configure\n  \\end{interaction}\n  This will analyze your system and prepare the compilation of \\whizard\\\n  in the build directory.  Make sure to set the proper options to\n  \\ttt{configure}, see Sec.~\\ref{sec:configure-options} below.\n\\item\n  Call \\ttt{make} to compile and link \\whizard:\n  \\begin{interaction}\n    your-build-directory> make\n  \\end{interaction}\n\\item\n  If you want to make sure that everything works, run\n  \\begin{interaction}\n    your-build-directory> make check\n  \\end{interaction}\n  This will take some more time.\n\\item\n  Become superuser and say\n  \\begin{interaction}\n    your-build-directory> make install\n  \\end{interaction}\n\\end{enumerate}\n\\whizard\\ should now installed in the default locations, and the\nexecutable should be available in the standard path.  Try to call\n\\ttt{whizard --help} in order to check this.\n\n\\subsection{Installation in User Space}\nYou may lack administrator privileges on your system.  In that case,\nyou can still install and run \\whizard.  Make sure that all\nprerequisites are met (Sec.~\\ref{sec:prerequisites}).\n\\begin{enumerate}\n\\item\n  Create a fresh directory for the \\whizard\\ build.  It is recommended\n  to keep this separate from the source directory.\n\\item\n  Reserve a directory in user space for the \\whizard\\ installation.\n  It should be empty, or yet non-existent.\n\\item\n  Go to that directory and execute\n  \\begin{interaction}\n    your-build-directory> your-src-directory/configure\n                               --prefix=your-install-directory\n  \\end{interaction}\n  This will analyze your system and prepare the compilation of \\whizard\\\n  in the build directory.  Make sure to set the proper additional options to\n  \\ttt{configure}, see Sec.~\\ref{sec:configure-options} below.\n\\item\n  Call \\ttt{make} to compile and link \\whizard:\n  \\begin{interaction}\n    your-build-directory> make\n  \\end{interaction}\n\\item\n  If you want to make sure that everything works, run\n  \\begin{interaction}\n    your-build-directory> make check\n  \\end{interaction}\n  This will take some more time.\n\\item\n  Install:\n  \\begin{interaction}\n    your-build-directory> make install\n  \\end{interaction}\n\\end{enumerate}\n\\whizard\\ should now be installed in the installation directory of your\nchoice.  If the installation is not in your standard search paths, you\nhave to account for this by extending the paths appropriately, see\nSec.~\\ref{sec:workspace}.\n\n\n\\subsection{Configure Options}\n\\label{sec:configure-options}\n\nThe configure script accepts environment variables and flags.  They\ncan be given as arguments to the \\ttt{configure} program in arbitrary\norder.  You may run \\ttt{configure --help} for a listing; only the\nlast part of this long listing is specific for the \\whizard\\ system.\nHere is an example:\n\\begin{interaction}\n  configure  FC=gfortran-5.4  FCFLAGS=\"-g -O3\"  --enable-fc-openmp\n\\end{interaction}\n\nThe most important options are\n\\begin{itemize}\n\\item\n  \\ttt{FC} (variable): The \\fortran\\ compiler.  This is necessary if\n  you need a compiler different from the standard compiler on the\n  system, e.g., if the latter is too old.\n\\item\n  \\ttt{FCFLAGS} (variable): The flags to be given to the \\fortran\\\n  compiler.  The main use is to control the level of optimization.\n\\item\n  \\ttt{--prefix=\\var{directory-name}}: Specify a non-default directory\n  for installation.\n\\item\n  \\ttt{--enable-fc-openmp}: Enable parallel executing via OpenMP on a\n  multi-processor/multi-core machine.  This works only if OpenMP is\n  supported by the compiler (e.g., \\ttt{gfortran}).  When running\n  \\whizard, the number of processors that are actually requested can\n  be controlled by the user.  Without this option, \\whizard\\ will run\n  in serial mode on a single core.  See Sec.~\\ref{sec:openmp} for\n  further details.\n\\item\n  \\ttt{--enable-fc-mpi}: Enable parallel executing via MPI on a single\n  machine using several cores or several machines. This works only if a MPI\n  library is installed (e.g. \\ttt{OpenMPI}) and \\ttt{FC=mpifort CC=mpicc CXX=mpic++} is\n  set. Without this option, \\whizard\\ will run in serial mode on a single core.\n  The flag can be combined with \\ttt{--enable-fc-openmp}. See Sec.~\\ref{sec:mpi}\n  for further details.\n\\item\n  \\ttt{LHADPF\\_DIR} (variable): The location of the optional \\lhapdf\\\n  package, if non-default.\n\\item\n  \\ttt{LOOPTOOLS\\_DIR} (variable): The location of the optional \\ttt{LOOPTOOLS}\n  package, if non-default.\n\\item\n  \\ttt{OPENLOOPS\\_DIR} (variable): The location of the optional \\openloops\\\n  package, if non-default.\n\\item\n  \\ttt{GOSAM\\_DIR} (variable): The location of the optional \\gosam\\\n  package, if non-default.\n\\item\n  \\ttt{HOPPET\\_DIR} (variable): The location of the optional \\hoppet\\\n  package, if non-default.\n\\item\n  \\ttt{HEPMC\\_DIR} (variable): The location of the optional \\hepmc\\ package, if\n  non-default.\n\\item\n  \\ttt{LCIO}/\\ttt{LCIO\\_DIR} (variable): The location of the optional\n  \\lcio\\ package, if non-default.\n\\end{itemize}\n\nOther flags that might help to work around possible problems are the\nflags for the $C$ and \\cpp\\  compilers as well as the \\ttt{Fortran77}\ncompiler, or the linker flags and additional libraries for the linking\nprocess.\n\\begin{itemize}\n\\item\n  \\ttt{CC} (variable): \\ttt{C} compiler command\n\\item\n  \\ttt{F77} (variable): \\ttt{Fortran77} compiler command\n\\item\n  \\ttt{CXX} (variable): \\ttt{C++} compiler command\n\\item\n  \\ttt{CPP} (variable): \\ttt{C} preprocessor\n\\item\n  \\ttt{CXXCPP} (variable): \\ttt{C++} preprocessor\n\\item\n  \\ttt{CFLAGS} (variable): \\ttt{C} compiler flags\n\\item\n  \\ttt{FFLAGS} (variable): \\ttt{Fortran77} compiler flags\n\\item\n  \\ttt{CXXFLAGS} (variable): \\ttt{C++} compiler flags\n\\item\n  \\ttt{LIBS} (variable): libraries to be passed to the linker as\n  \\ttt{-l{\\em library}}\n\\item\n  \\ttt{LDFLAGS} (variable): non-standard linker flags\n\\end{itemize}\n\nFor other options (like e.g. \\ttt{--with-precision=...} etc.) please\nsee the \\ttt{configure --help} option.\n\n%%%%%\n\n\\subsection{Details on the Configure Process}\n\nThe configure process checks for the build and host system type; only\nif this is not detected automatically, the user would have to specify\nthis by himself. After that system-dependent files are searched for,\nLaTeX and Acroread for documentation and plots, the \\fortran\\ compiler\nis checked, and finally the \\ocaml\\ compiler. The next step is the\nchecks for external programs like \\lhapdf\\ and \\ttt{HepMC}.\nFinally, all the Makefiles are being built.\n\nThe compilation is done by invoking \\ttt{make} and finally\n\\ttt{make install}. You could also do a \\ttt{make check} in\norder to test whether the compilation has produced sane files on your\nsystem. This is highly recommended.\n\nBe aware that there be problems for the installation if the install\npath or a user's home directory is part of an AFS file system. Several\ntimes problems were encountered connected with conflicts with\npermissions inside the OS permission environment variables and the AFS\npermission flags which triggered errors during the \\ttt{make install}\nprocedure. Also please avoid using \\ttt{make -j} options of parallel\nexecution of \\ttt{Makefile} directives as AFS filesystems might not be\nfast enough to cope with this.\n\nFor specific problems that might have been encountered in rare\ncircumstances for some FORTRAN compilers confer the webpage\n\\url{https://whizard.hepforge.org/compilers.html}.\n\nNote that the \\pythia\\  bundle for showering and hadronization (and\nsome other external legacy code pieces) do still contain good old\n\\ttt{Fortran77} code. These parts should better be\ncompiled with the very same \\ttt{Fortran2003} compiler as the\n\\whizard\\ core. There is, however, one subtlety:\nwhen the \\ttt{configure} flag \\ttt{FC} gets a full system path as\nargument, \\ttt{libtool} is not able to recognize this as a valid (GNU)\n\\ttt{Fortran77} compiler. It then searches automatically for binaries\nlike \\ttt{f77}, \\ttt{g77} etc. or a standard system compiler. This\nmight result in a compilation failure of the \\ttt{Fortran77} code. A\nviable solution is to define an executable link and use this (not the\nfull path!) as \\ttt{FC} flag.\n\nIt is possible to compile \\whizard\\ without the \\ocaml\\ parts of\n\\oMega, namely by using the \\ttt{--disable-omega} option of the\nconfigure. This will result in a built of \\whizard\\ with the \\oMega\\\n\\fortran\\ library, but without the binaries for the matrix element\ngeneration. All selftests (cf. \\ref{sec:selftests}) requiring \\oMega\\\nmatrix elements are thereby switched off. Note that you can install\nsuch a built (e.g. on a batch system without \\ocaml\\ installation), but\nthe try to build a distribution (all \\ttt{make distxxx} targets) will fail.\n\n%%%%%%%%%%%\n\n\\subsection{Building on Darwin/macOS}\n\nThe easiest way to build \\whizard\\ on Darwin/macOS is to install the\ncomplete GNU compiler suite (\\ttt{gcc/g++/gfortran}). This can be done\nwith one of the code repositories like \\ttt{MacPorts}, \\ttt{HomeBrew}\nor \\ttt{Fink}. In order to include \\ROOT\\ which natively should be\nbuilt using the intrinsic \\ttt{clang/clang++} for the graphics\nsupport, there is also the possibility to build external tools like\n\\hepmcthree, \\pythiaeight, \\fastjet, and \\lcio\\ with \\ttt{clang++},\nand set in the configure option for \\whizard\\ \\ttt{C} and \\ttt{C++}\ncompiler accordingly:\n\\begin{quote}\n  ../configure CC=clang CXX=clang++ [...]\n\\end{quote}\nNote that \\fastjet\\ might need to be configured with the\n\\ttt{--disable-auto-ptr} option when compiling with \\ttt{clang++}\nand strict \\ttt{C++17} standard.\n\nSince Darwin v10.11, the security measures of the new Darwin systems\ndo not allow e.g. environment variables passed to subprocesses. This\ndoes not change anything for the installed WHIZARD, but the testsuite\n(make check) will not work before make install has been executed. make\ndistcheck will not work on El Capitan. There is also the option to\ndisable the System Integrity Protocol (SIP) of modern OSX by booting\nin Recovery Mode, open a terminal and type \\ttt{csrutil\ndisable}. However, we do not recommend to do so.\n\n%%%%%%%%%%%\n\n\\subsection{Building on Windows}\n\nFor Windows, from \\ttt{Windows 10} onwards, there is the possibility\nto install and use an underlying Linux operating system,\ne.g. \\ttt{Ubuntu}. Installation and usage of \\whizard\\ works then the\nsame way as described above. \n\n%%%%%%%%%%%\n\n\n\\subsection{\\whizard\\ self tests/checks}\n\\label{sec:selftests}\n\n\\whizard\\ has a number of self-consistency checks and tests which assure\nthat most of its features are running in the intended way. The\nstandard procedure to invoke these self tests is to perform a\n\\ttt{make check} from the \\ttt{build} directory. If \\ttt{src}\nand \\ttt{build} directories are the same, all relevant files for\nthese self-tests reside in the \\ttt{tests} subdirectory of the main\n\\whizard\\ directory. In that case, one could in principle just call the\nscripts individually from the command line. Note, that if \\ttt{src}\nand \\ttt{build} directory are different as recommended, then the\ninput files will have been installed in\n\\ttt{prefix/share/whizard/test}, while the corresponding test shell\nscripts remain in the \\ttt{srcdir/test} directory. As the main shell\nscript \\ttt{run\\_whizard.sh} has been built in the \\ttt{build}\ndirectory, one now has to copy the files over by and set the correct\npaths by hand, if one wishes to run the test scripts individually.\n\\ttt{make check} still correctly performs all \\whizard\\\nself-consistency tests. The tests itself fall into two categories,\nunit self test that individually test the modular structure of\n\\whizard, and tests that are run by \\sindarin\\ files. In future releases\nof \\whizard, these two categories of tests will be better separated\nthan in the 2.2.1 release.\n\nThere are additional, quite extensiv numerical tests for validation\nand backwards compatibility checks for SM and MSSM processes. As a\nstandard, these extended self tests are not invoked. However, they can\nbe enabled by executing the corresponding specific \\ttt{make check}\noperations in the subdirectories for these extensive tests.\n\nAs the new \\whizard\\ testsuite does very thorough and scrupulous tests\nof the whole \\whizard\\ structure, it is always possible that some\ntests are failing due to some weird circumstances or because of\nnumerical fluctuations. In such a case do not panic, contact the\ndevelopers (\\ttt{whizard@desy.de}) and provide them with the logfiles\nof the failing test as well as the setup of your configuration.\n\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n\\clearpage\n\n\\chapter{Working with \\whizard}\n\\label{chap:start}\n\n\\whizard\\ can run as a stand-alone program.  You (the user) can steer\n\\whizard\\ either interactively or by a script file.  We will first\ndescribe the latter method, since it will be the most common way to\ninteract with the \\whizard\\ system.\n\n\\section{Hello World}\n\nThe legacy version series 1 of the program relied on a bunch of input\nfiles that the user had to provide in some obfuscated format.  This\napproach is sufficient for straightforward applications.  However, once\nyou get experienced with a program, you start thinking about uses that\nthe program's authors did not foresee.  In case of a Monte Carlo\npackage, typical abuses are parameter scans, complex patterns of cuts\nand reweighting factors, or data analysis without recourse to external\npackages.  This requires more flexibility.\n\nInstead of transferring control over data input to some generic\nscripting language like \\ttt{PERL} or \\python\\ (or even \\cpp), which\ncome with their own peculiarities and learning curves, we decided to\nunify data input and scripting in a dedicated steering language that\nis particularly adapted to the needs of Monte-Carlo integration,\nsimulation, and simple analysis of the results.  Thus we discovered\nwhat everybody knew anyway: that W(h)izards communicate in \\sindarin,\nScripting INtegration, Data Analysis, Results display and INterfaces.\n\n\\sindarin\\ is a DSL -- a domain-specific scripting language -- that is\ndesigned for the single purpose of steering and talking to \\whizard.\nNow since \\sindarin\\ is a programming language, we honor the old\ntradition of starting with the famous Hello World program.  In\n\\sindarin\\ this reads simply\n\\begin{quote}\n\\begin{verbatim}\nprintf \"Hello World!\"\n\\end{verbatim}\n\\end{quote}\nOpen your favorite editor, type this text, and save it into a file\nnamed \\verb|hello.sin|.\n\n\\begin{figure}\n  \\centering\n\\begin{scriptsize}\n\\begin{Verbatim}[frame=single]\n    | Writing log to 'whizard.log'\n    |=============================================================================|\n    |                                                                             |\n    |    WW             WW  WW   WW  WW  WWWWWW      WW      WWWWW    WWWW        |\n    |     WW    WW     WW   WW   WW  WW     WW      WWWW     WW  WW   WW  WW      |\n    |      WW  WW WW  WW    WWWWWWW  WW    WW      WW  WW    WWWWW    WW   WW     |\n    |       WWWW   WWWW     WW   WW  WW   WW      WWWWWWWW   WW  WW   WW  WW      |\n    |        WW     WW      WW   WW  WW  WWWWWW  WW      WW  WW   WW  WWWW        |\n    |                                                                             |\n    |                                                                             |\n    |                                        W                                    |\n    |                                       sW                                    |\n    |                                       WW                                    |\n    |                                      sWW                                    |\n    |                                      WWW                                    |\n    |                                     wWWW                                    |\n    |                                    wWWWW                                    |\n    |                                    WW WW                                    |\n    |                                    WW WW                                    |\n    |                                   wWW WW                                    |\n    |                                  wWW  WW                                    |\n    |                                  WW   WW                                    |\n    |                                  WW   WW                                    |\n    |                                 WW    WW                                    |\n    |                                 WW    WW                                    |\n    |                                WW     WW                                    |\n    |                                WW     WW                                    |\n    |           wwwwww              WW      WW                                    |\n    |              WWWWWww          WW      WW                                    |\n    |                 WWWWWwwwww   WW       WW                                    |\n    |                     wWWWwwwwwWW       WW                                    |\n    |                 wWWWWWWWWWWwWWW       WW                                    |\n    |                wWWWWW       wW        WWWWWWW                               |\n    |                  WWWW       wW        WW  wWWWWWWWwww                       |\n    |                   WWWW                      wWWWWWWWwwww                    |\n    |                     WWWW                      WWWW     WWw                  |\n    |                       WWWWww                   WWWW                         |\n    |                           WWWwwww              WWWW                         |\n    |                               wWWWWwww       wWWWWW                         |\n    |                                     WwwwwwwwwWWW                            |\n    |                                                                             |\n    |                                                                             |\n    |                                                                             |\n    |  by:   Wolfgang Kilian, Thorsten Ohl, Juergen Reuter                        |\n    |        with contributions from Christian Speckner                           |\n    |        Contact: <whizard@desy.de>                                           |\n    |                                                                             |\n    |  if you use WHIZARD please cite:                                            |\n    |        W. Kilian, T. Ohl, J. Reuter,  Eur.Phys.J.C71 (2011) 1742            |\n    |                                          [arXiv: 0708.4233 [hep-ph]]        |\n    |        M. Moretti, T. Ohl, J. Reuter, arXiv: hep-ph/0102195                 |\n    |                                                                             |\n    |=============================================================================|\n    |                               WHIZARD 3.0.0_beta\n    |=============================================================================|\n    | Reading model file '/usr/local/share/whizard/models/SM.mdl'\n    | Preloaded model: SM\n    | Process library 'default_lib': initialized\n    | Preloaded library: default_lib\n    | Reading commands from file 'hello.sin'\n    Hello World!\n    | WHIZARD run finished.\n    |=============================================================================|\n\\end{Verbatim}\n\\end{scriptsize}\n  \\caption{Output of the \\ttt{\"Hello world!\"} \\sindarin\\ script.\\label{fig:helloworld}}\n\\end{figure}\n\nNow we assume that you -- or your kind system administrator -- has\ninstalled \\whizard\\ in your executable path.  Then you should open a\ncommand shell and execute (we will come to the meaning of the\n\\verb|-r| option later.)\n\\begin{verbatim}\n/home/user$ whizard -r hello.sin\n\\end{verbatim}\nand if everything works well, you get the output (the complete output\nincluding the \\whizard\\ banner is shown in Fig.~\\ref{fig:helloworld})\n\\begin{footnotesize}\n\\begin{verbatim}\n| Writing log to 'whizard.log'\n\\end{verbatim}\n\\centerline{[... here a banner is displayed]}\n\\begin{Verbatim}\n|=============================================================================|\n|                               WHIZARD 3.0.0_beta\n|=============================================================================|\n| Reading model file '/usr/local/share/whizard/models/SM.mdl'\n| Preloaded model: SM\n! Process library 'default_lib': initialized\n! Preloaded library: default_lib\n| Reading commands from file 'hello.sin'\nHello World!\n| WHIZARD run finished.\n|=============================================================================|\n\\end{Verbatim}\n\\end{footnotesize}\nIf this has just worked for you, you can be confident that you have a working\n\\whizard\\ installation, and you have been able to successfully run the\nprogram.\n\n\\section{A Simple Calculation}\nYou may object that \\whizard\\ is not exactly designed for printing out\nplain text.  So let us demonstrate a more useful example.\n\nLooking at the Hello World output, we first observe that the program\nwrites a log file named (by default) \\verb|whizard.log|.  This file\nreceives all screen output, except for the output of external programs\nthat are called by \\whizard.  You don't have to cache \\whizard's screen\noutput yourself.\n\nAfter the welcome banner, \\whizard\\ tells you that it reads a physics\n\\emph{model}, and that it initializes and preloads a \\emph{process library}.  The\nprocess library is initially empty.  It is ready for receiving\ndefinitions of elementary high-energy physics processes (scattering or\ndecay) that you provide.  The processes are set in the context of a\ndefinite model of high-energy physics.  By default this is the\nStandard Model, dubbed \\verb|SM|.\n\nHere is the \\sindarin\\ code for defining a SM physics process, computing\nits cross section, and generating a simulated event sample in Les Houches\nevent format:\n\\begin{quote}\n\\begin{Verbatim}\nprocess ee = e1, E1 => e2, E2\nsqrts = 360 GeV\nn_events = 10\nsample_format = lhef\nsimulate (ee)\n\\end{Verbatim}\n\\end{quote}\nAs before, you save this text in a file (named, e.g.,\n\\verb|ee.sin|) which is run by\n\\begin{verbatim}\n/home/user$ whizard -r ee.sin\n\\end{verbatim}\n(We will come to the meaning of the \\verb|-r| option later.)\nThis produces a lot of output which looks similar to this:\n\n \\begin{footnotesize}\n \\begin{verbatim}\n | Writing log to 'whizard.log'\n[... banner ...]\n |=============================================================================|\n |                               WHIZARD 3.0.0_beta\n |=============================================================================|\n | Reading model file '/usr/local/share/whizard/models/SM.mdl'\n | Preloaded model: SM\n | Process library 'default_lib': initialized\n | Preloaded library: default_lib\n | Reading commands from file 'ee.sin'\n | Process library 'default_lib': recorded process 'ee'\n sqrts =  3.600000000000E+02\n n_events = 10\n \\end{verbatim}\n\n \\begin{verbatim}\n | Starting simulation for process 'ee'\n | Simulate: process 'ee' needs integration\n | Integrate: current process library needs compilation\n | Process library 'default_lib': compiling ...\n | Process library 'default_lib': writing makefile\n | Process library 'default_lib': removing old files\n rm -f default_lib.la\n rm -f default_lib.lo default_lib_driver.mod opr_ee_i1.mod ee_i1.lo\n rm -f ee_i1.f90\n | Process library 'default_lib': writing driver\n | Process library 'default_lib': creating source code\n rm -f ee_i1.f90\n rm -f opr_ee_i1.mod\n rm -f ee_i1.lo\n /usr/local/bin/omega_SM.opt -o ee_i1.f90 -target:whizard\n  -target:parameter_module parameters_SM -target:module opr_ee_i1\n  -target:md5sum '70DB728462039A6DC1564328E2F3C3A5' -fusion:progress\n  -scatter 'e- e+ -> mu- mu+'\n [1/1] e- e+ -> mu- mu+ ... allowed. [time: 0.00 secs, total: 0.00 secs, remaining: 0.00 secs]\n all processes done. [total time: 0.00 secs]\n SUMMARY: 6 fusions, 2 propagators, 2 diagrams\n | Process library 'default_lib': compiling sources\n[.....]\n \\end{verbatim}\n\n\n \\begin{verbatim}\n | Process library 'default_lib': loading\n | Process library 'default_lib': ... success.\n | Integrate: compilation done\n | RNG: Initializing TAO random-number generator\n | RNG: Setting seed for random-number generator to 9616\n | Initializing integration for process ee:\n | ------------------------------------------------------------------------\n | Process [scattering]: 'ee'\n |   Library name  = 'default_lib'\n |   Process index = 1\n |   Process components:\n |     1: 'ee_i1':   e-, e+ => mu-, mu+ [omega]\n | ------------------------------------------------------------------------\n | Beam structure: [any particles]\n | Beam data (collision):\n |   e-  (mass = 5.1099700E-04 GeV)\n |   e+  (mass = 5.1099700E-04 GeV)\n |   sqrts = 3.600000000000E+02 GeV\n | Phase space: generating configuration ...\n | Phase space: ... success.\n | Phase space: writing configuration file 'ee_i1.phs'\n | Phase space: 2 channels, 2 dimensions\n | Phase space: found 2 channels, collected in 2 groves.\n | Phase space: Using 2 equivalences between channels.\n | Phase space: wood\n Warning: No cuts have been defined.\n \\end{verbatim}\n\n\n \\begin{verbatim}\n | Starting integration for process 'ee'\n | Integrate: iterations not specified, using default\n | Integrate: iterations = 3:1000:\"gw\", 3:10000:\"\"\n | Integrator: 2 chains, 2 channels, 2 dimensions\n | Integrator: Using VAMP channel equivalences\n | Integrator: 1000 initial calls, 20 bins, stratified = T\n | Integrator: VAMP\n |=============================================================================|\n | It      Calls  Integral[fb]  Error[fb]   Err[%]    Acc  Eff[%]   Chi2 N[It] |\n |=============================================================================|\n    1        784  8.3282892E+02  1.68E+00    0.20    0.06*  39.99\n    2        784  8.3118961E+02  1.23E+00    0.15    0.04*  76.34\n    3        784  8.3278951E+02  1.36E+00    0.16    0.05   54.45\n |-----------------------------------------------------------------------------|\n    3       2352  8.3211789E+02  8.01E-01    0.10    0.05   54.45    0.50   3\n |-----------------------------------------------------------------------------|\n    4       9936  8.3331732E+02  1.22E-01    0.01    0.01*  54.51\n    5       9936  8.3341072E+02  1.24E-01    0.01    0.01   54.52\n    6       9936  8.3331151E+02  1.23E-01    0.01    0.01*  54.51\n |-----------------------------------------------------------------------------|\n    6      29808  8.3334611E+02  7.10E-02    0.01    0.01   54.51    0.20   3\n |=============================================================================|\n \\end{verbatim}\n\n \\begin{verbatim}\n[.....]\n| Simulate: integration done\n| Simulate: using integration grids from file 'ee_m1.vg'\n| RNG: Initializing TAO random-number generator\n| RNG: Setting seed for random-number generator to 9617\n| Simulation: requested number of events = 10\n|             corr. to luminosity [fb-1] =   1.2000E-02\n| Events: writing to LHEF file 'ee.lhe'\n| Events: writing to raw file 'ee.evx'\n| Events: generating 10 unweighted, unpolarized events ...\n| Events: event normalization mode '1'\n|         ... event sample complete.\n| Events: closing LHEF file 'ee.lhe'\n| Events: closing raw file 'ee.evx'\n| There were no errors and    1 warning(s).\n| WHIZARD run finished.\n|=============================================================================|\n \\end{verbatim}\n \\end{footnotesize}\n%$\nThe final result is the desired event file, \\ttt{ee.lhe}.\n\nLet us discuss the output quickly to walk you through the procedures\nof a \\whizard\\ run: after the logfile message and the banner, the\nreading of the physics model and the initialization of a process\nlibrary, the recorded process with tag \\ttt{'ee'} is recorded. Next,\nuser-defined parameters like the center-of-mass energy and the number\nof demanded (unweighted) events are displayed. As a next step,\n\\whizard\\ is starting the simulation of the process with tag\n\\ttt{'ee'}. It recognizes that there has not yet been an integration\nover phase space (done by an optional \\ttt{integrate} command,\ncf. Sec.~\\ref{sec:integrate}), and consequently starts the\nintegration. It then acknowledges, that the process code for the\nprocess \\ttt{'ee'} needs to be compiled first (done by an optional\n\\ttt{compile} command, cf. Sec.~\\ref{sec:compilation}). So, \\whizard\\\ncompiles the process library, writes the makefile for its steering,\nand as a safeguard against garbage removes possibly existing\nfiles. Then, the source code for the library and its processes are\ngenerated: for the process code, the default method -- the matrix\nelement generator \\oMega\\ is called (cf. Sec.~\\ref{sec:omega_me}); and\nthe sources are being compiled.\n\nThe next steps are the loading of the process library, and \\whizard\\\nreports the completion of the integration. For the Monte-Carlo\nintegration, a random number generator is initialized. Here, it is the\ndefault generator, TAO (for more details, cf. Sec.~\\ref{sec:tao},\nwhile the random seed is set to a value initialized by the system\nclock, as no seed has been provided in the \\sindarin\\ input file.\n\nNow, the integration for the process \\ttt{'ee'} is initialized, and\ninformation about the process (its name, the name of its process\nlibrary, its index inside the library, and the process components out\nof which it consists, cf. Sec.~\\ref{sec:processcomp}) are\ndisplayed. Then, the beam structure is shown, which in that case are\nsymmetric partonic electron and positron beams with the center-of-mass\nenergy provided by the user (360 GeV). The next step is the generation\nof the phase space, for which the default phase space method\n\\ttt{wood} (for more details cf. Sec.~\\ref{sec:wood}) is selected. The\nintegration is performed, and the result with absolute and relative\nerror, unweighting efficiency, accuracy, $\\chi^2$ quality is shown.\n\nThe final step is the event generation\n(cf. Chap.~\\ref{chap:events}). The integration grids are now being\nused, again the random number generator is initialized. Finally, event\ngeneration of ten unweighted events starts (\\whizard\\ let us know to\nwhich integrated luminosity that would correspond), and events are\nwritten both in an internal (binary) event format as well as in the\ndemanded LHE format. This concludes the \\whizard\\ run.\n\nAfter a more comprehensive introduction into the \\sindarin\\ steering\nlanguage in the next chapter, Chap.~\\ref{chap:sindarinintro}, we will\ndiscuss all the details of the different steps of this introductory\nexample.\n\n\n\\clearpage\n\n\\section{WHIZARD in a Computing Environment}\n\n\\subsection{Working on a Single Computer}\n\\label{sec:workspace}\n\nAfter installation, \\whizard\\ is ready for use.  There is a slight\ncomplication if \\whizard\\ has been installed in a location that is not\nin your standard search paths.\n\nIn that case, to successfully run \\whizard, you may either\n\\begin{itemize}\n\\item\n  manually add \\ttt{your-install-directory/bin} to your execution PATH\\\\\n  and \\ttt{your-install-directory/lib} to your library search path\n  (LD\\_LIBRARY\\_PATH), or\n\\item\n  whenever you start a project, execute\n  \\begin{interaction}\n    your-workspace> . your-install-directory/bin/whizard-setup.sh\n  \\end{interaction}\n  which will enable the paths in your current environment, or\n\\item\n  source \\ttt{whizard-setup.sh} script in your shell startup file.\n\\end{itemize}\nIn either case, try to call \\ttt{whizard --help} in order to check\nwhether this is done correctly.\n\nFor a new \\whizard\\ project, you should set up a new (empty)\ndirectory.  Depending on the complexity of your task, you may want to\nset up separate directories for each subproblem that you want to\ntackle, or even for each separate run.  The location of the\ndirectories is arbitrary.\n\nTo run, \\whizard\\ needs only a single input file, a \\sindarin\\ command\nscript with extension \\ttt{.sin} (by convention).  Running\n\\whizard\\ is as simple as\n\\begin{interaction}\n  your-workspace> whizard your-input.sin\n\\end{interaction}\nNo other configuration files are needed.  The total number of\nauxiliary and output files generated in a single run may get quite\nlarge, however, and they may clutter your workspace.  This is the\nreason behind keeping subdirectories on a per-run basis.\n\nBasic usage of \\whizard\\ is explained in Chapter~\\ref{chap:start}, for\nmore details, consult the following chapters.  In\nSec.~\\ref{sec:cmdline-options} we give an account of the command-line\noptions that \\whizard\\ accepts.\n\n\\subsection{Working Parallel on Several Computers}\n\\label{sec:mpi}\n\nFor integration (only VAMP2), \\whizard\\ supports parallel execution via MPI\nby communicating between parallel tasks on a single machine or distributed over\nseveral machines.\n\nDuring integration the calculation of channels is distributed along several\nworkers where a master worker collects the results and adapts weights and grids.\nIn wortwhile cases (e.g. high number of calls in one channel), the calculation\nof a single grid is distributed.\n\nIn order to use these advancements, \\whizard\\ requires an installed MPI-3.1 capable\nlibrary (e.g. OpenMPI) and configuration and compilation with the appropriate flags,\ncf.~Sec.~\\ref{sec:installation}.\n\nMPI support is only active when the integration method is set to VAMP2.\nAdditionally, to preserve the numerical properties of a single task run, it is\nrecommended to use the RNGstream as random number generator.\n\\begin{code}\n  $integration_method = 'vamp2'\n  $rng_method = 'rng_stream'\n\\end{code}\n\n\\whizard\\ has then to be called by mpirun\n\\begin{footnotesize}\n\\begin{Verbatim}[frame=single]\n  your-workspace> mpirun -f hostfile -np 4 --output-filename mpi.log whizard your-input.sin\n\\end{Verbatim}\n\\end{footnotesize}\nwhere the number of parallel tasks can be set by \\ttt{-np} and a hostfile can be\ngiven by \\ttt{--hostfile}. It is recommended to use \\ttt{--output-filename} which\nlets mpirun redirect the standard (error) output to a file, for each worker separatly.\n\n\\subsubsection{Notes on Parallelization with MPI}\n\nThe parallelization of \\whizard\\ requires that all instances of the\nparallel run be able to write and read all files by produced\n\\whizard\\ in a network file system as the current implementation does\nnot handle parallel I/O. Usually, high-performance clusters have\nsupport for at least one network filesystem.\n\nFurthermore, not all functions of \\whizard\\ are currently supported or\nare only supported in a limited way in parallel mode. Currently the\n\\verb|?rebuild_<flags>| for the phase space and the matrix element\nlibrary are not yet available, as well as the calculation of matrix\nelements with resonance history.\n\nSome features that have been missing in the very first implementation\nof the parallelized integration have now been made available, like\nthe support of run IDs and the parallelization of the event generation.\n\nA final remark on the stability of the numerical results in terms of\nthe number of workers involved. Under certain circumstances, results\nbetween different numbers of workers but using otherwise an identical\n\\sindarin\\ file can lead to slightly numerically different (but\nstatistically compatible) results for integration or event generation\nThis is related to the execution of the computational operations in\nMPI, which we use to reduce results from all workers. If the order of\nthe numbers in the arithmetical operations changes, for example, by\ndifferent setups of the workers, then the numerical results change\nslightly, which in turn is amplified under the influence of the\nadaptation. Nevertheless, the results are all statistically\nconsistent.\n\n\\subsection{Stopping and Resuming WHIZARD Jobs}\n\nOn a Unix-like system, it is possible to prematurely stop running jobs\nby a \\ttt{kill(1)} command, or by entering \\ttt{Ctrl-C} on the\nterminal.\n\nIf the system supports this, \\whizard\\ traps these signals.  It also\ntraps some signals that a batch operating system might issue, e.g.,\nfor exceeding a predefined execution time limit.  \\whizard\\ tries to\ncomplete the calculation of the current event and gracefully close\nopen files.  Then, the program terminates with a message and a nonzero\nreturn code.  Usually, this should not take more than a fraction of a\nsecond.\n\nIf, for any reason, the program does not respond to an interrupt, it\nis always possible to kill it by \\ttt{kill -9}.  A convenient method,\non a terminal, would be to suspend it first by \\ttt{Ctrl-Z} and then\nto kill the suspended process.\n\nThe program is usually able to recover after being stopped.  Simply\nrun the job again from start, with the same input, all output files\ngenerated so far left untouched.  The results obtained so far will be\nquickly recovered or gathered from files written in the previous run,\nand the actual time-consuming calculation is resumed near the point\nwhere it was interrupted.\\footnote{This holds for simple workflow.  In\n  case of scans and repeated integrations of the same process, there\n  may be name clashes on the written files which prevent resuming.  A\n  future \\whizard\\ version will address this problem.}  If the\ninterruption happened during an integration step, it is resumed after\nthe last complete iteration.  If it was during event generation, the\nprevious events are taken from file and event generation is continued.\n\nThe same mechanism allows for efficiently redoing a calculation with\nsimilar, somewhat modified input.  For instance, you might want to add\na further observable to event analysis, or write the events in a\ndifferent format.  The time for rerunning the program is determined\njust by the time it takes to read the existing integration or event\nfiles, and the additional calculation is done on the recovered\ninformation.\n\nBy managing various checksums on its input and output files, \\whizard\\\ndetects changes that affect further calculations, so it does a\nreal recalculation only where it is actually needed.  This applies to\nall steps that are potentially time-consuming: matrix-element code\ngeneration, compilation, phase-space setup, integration, and event\ngeneration.  If desired, you can set command-line options or\n\\sindarin\\ parameters that explicitly discard previously generated\ninformation.\n\n\n\\subsection{Files and Directories: default and customization}\n\n\\whizard\\ jobs take a small set of files as input.  In many cases, this is\njust a single \\sindarin\\ script provided by the user.\nWhen running, \\whizard\\ can produce a set of auxiliary and output files:\n\\begin{enumerate}\n\\item\n  \\textbf{Job.}\n  Files pertaining to the \\whizard\\ job as a whole.  This is the default log\n  file \\ttt{whizard.log}.\n\\item\n  \\textbf{Process compilation.}  Files that originate from generating and\n  compiling process code.  If the default \\oMega\\ generator is used, these\n  files include \\fortran\\ source code as well as compiled libraries that are\n  dynamically linked to the running executable.  The file names are derived\n  from either the process-library name or the individual process names, as\n  defined in the \\sindarin\\ input.  The default library name is\n  \\ttt{default\\_lib}.\n\\item\n  \\textbf{Integration.}\n  Files that are created by integration, i.e., when calculating the total cross\n  section for a scattering process using the Monte-Carlo algorithm.  The file\n  names are derived from the process name.\n\\item\n  \\textbf{Simulation.}\n  Files that are created during simulation, i.e., generating event samples for\n  a process or a set of processes.  By default, the file names are derived\n  from the name of the first process.  Event-file formats are distinguished\n  by appropriate file name extensions.\n\\item\n  \\textbf{Result Analysis.}\n  Files that are created by the internal analysis tools and written by the\n  command \\ttt{write\\_analysis} (or \\ttt{compile\\_analysis}).  The default\n  base name is \\ttt{whizard\\_analysis}.\n\\end{enumerate}\n\nA complex workflow with several processes, parameter sets, or runs, can easily\nlead to in file-name clashes or a messy working directory.  Furthermore,\nrunning a batch job on a dedicated computing environment often requires\ntransferring data from a user directory to the server and back.\n\nCustom directory and file names can be used to organize things and facilitate\ndealing with the environment, along with the available batch-system tools for\ncoordinating file transfer.\n\\begin{enumerate}\n\\item\n  \\textbf{Job.}\n  \\begin{itemize}\n  \\item\n    The \\ttt{-L} option on the command line defines a custom base name for\n    the log file.\n  \\item\n    The \\ttt{-J} option on the command line defines a job ID.  For instance,\n    this may be set to the job ID assigned by the batch system.  Within the\n    \\sindarin\\ script, the job ID is available as the string variable\n    \\ttt{\\$job\\_id} and can be used for constructing custom job-specific file\n    and directory names, as described below.\n  \\end{itemize}\n\\item\n  \\textbf{Process compilation.}\n  \\begin{itemize}\n  \\item\n    The user can require the program to put all files created during the\n    compilation step including the library to be linked, in a subdirectory of\n    the working directory.  To enable this, set the string variable\n    \\ttt{\\$compile\\_workspace} within the \\sindarin\\ script.\n  \\end{itemize}\n\\item\n  \\textbf{Integration.}\n  \\begin{itemize}\n  \\item\n    The value of the string variable \\ttt{\\$run\\_id}, if set, is appended to\n    the base name of all files created by integration, separated by dots.  If\n    the \\sindarin\\ script scans over parameters, varying the run ID avoids\n    repeatedly overwriting files with identical name during the scan.\n  \\item\n    The user can require the program to put the important files created during\n    the integration step -- the phase-space configuration file and the\n    \\vamp\\ grid files -- in a subdirectory of the working directory.  To\n    enable this, set the string variable \\ttt{\\$integrate\\_workspace} within\n    the \\sindarin\\ script.  (\\ttt{\\$compile\\_workspace} and\n    \\ttt{\\$integrate\\_workspace} may be set to the same value.)\n  \\end{itemize}\n  Log files produced during the integration step are put in the working\n  directory.\n\\item\n  \\textbf{Simulation.}\n  \\begin{itemize}\n  \\item\n    The value of the string variable \\ttt{\\$run\\_id}, if set, identifies\n    the specific integration run that is used for the event sample.  It is\n    also inserted into default event-sample file names.\n  \\item\n    The variable \\ttt{\\$sample}, if set, defines an arbitrary base name for the\n    files related to the event sample.\n  \\end{itemize}\n  Files resulting from simulation are put in the working directory.\n\\item\n  \\textbf{Result Analysis.}\n  \\begin{itemize}\n  \\item\n    The variable \\ttt{\\$out\\_file}, if set,\n    defines an arbitrary base name for the analysis data and\n    auxiliary files.\n  \\end{itemize}\n  Files resulting from result analysis are put in the working directory.\n\\end{enumerate}\n\n\n\\subsection{Batch jobs on a different machine}\n\nIt is possible to separate the tasks of process-code compilation, integration,\nand simulation, and execute them on different machines.  To make use of\nthis feature, the local and remote machines including all\ninstalled libraries that are relevant for \\whizard, must be\nbinary-compatible.\n\\begin{enumerate}\n\\item\n  Process-code compilation may be done once on a local machine, while the\n  time-consuming tasks of integration and event generation for specific\n  parameter sets are delegated to a remote machine, e.g., a batch cluster.  To\n  enable this, prepare a \\sindarin\\ script that just produces process code\n  (i.e., terminates with a \\ttt{compile} command) for the local machine.  You\n  may define \\ttt{\\$compile\\_workspace} such that all generated code\n  conveniently ends up in a single subdirectory.\n\n  To start the batch job, transfer the workspace subdirectory to the remote\n  machine\n  and start \\whizard\\ there.  The \\sindarin\\ script on the remote machine must\n  include the local script unchanged in all parts that are relevant for\n  process definition.  The program will recognize the contents of the\n  workspace, skip compilation and instead link the process library immediately.\n  To proceed further, the script should define the run-specific parameters and\n  contain the appropriate commands for integration and simulation.\n\\item\n  Analogously, you may execute both process-code compilation and integration\n  locally, but generate event samples on a remote machine.  To this end,\n  prepare a \\sindarin\\ script that produces process code and computes integrals\n  (i.e., terminates with an \\ttt{integrate} command) for the local machine.\n  You may define \\ttt{\\$compile\\_workspace} and \\ttt{\\$integrate\\_workspace}\n  (which may coincide) such that all generated code, phase-space and\n  integration grid data conveniently end up in subdirectories.\n\n  To start the batch job, transfer the workspace(s) to the remote machine and\n  start \\whizard\\ there.  The \\sindarin\\ script on the remote machine must\n  include the local script unchanged in all parts that are relevant for\n  process definition and integration.  The program will recognize the contents\n  of the workspace, skip compilation and integration and instead load the\n  process library and integration results immediately.  To proceed further,\n  the script should define the sample-specific parameters and contain the\n  appropriate commands for simulation.\n\\end{enumerate}\n\nTo simplify transferring whole directories, \\whizard\\ supports the\n\\ttt{--pack} and \\ttt{--unpack} options.  You may specify any number of these\noptions for a \\whizard\\ run.  (The feature relies on the GNU version of the\n\\ttt{tar} utility.)\n\nFor instance,\n\\begin{code}\nwhizard script1.sin --pack my_ws\n\\end{code}\nruns \\whizard\\ with the \\sindarin\\ script \\ttt{script1.sin} as input, where\nwithin the script you have defined\n\\begin{code}\n$compile_workspace = \"my_ws\"\n\\end{code}\nas the target directory for process-compilation files.  After completion, the\nprogram will tar and gzip the target directory as \\ttt{my\\_ws.tgz}.  You\nshould copy this file to the remote machine as one of the job's input files.\n\nOn the remote machine, you can then run the program with\n\\begin{code}\nwhizard script2.sin --unpack my_ws.tgz\n\\end{code}\nwhere \\ttt{script2.sin} should include \\ttt{script1.sin}, and add integration\nor simulation commands.  The contents of \\ttt{ws.tgz} will thus be unpacked\nand reused on the remote machine, instead of generating new process code.\n\n\n\n\\subsection{Static Linkage}\n\nIn its default running mode, \\whizard\\ compiles process-specific matrix\nelement code on the fly and dynamically links the resulting library.  On the\ncomputing server, this requires availability of the appropriate \\fortran\\\ncompiler, as well as the \\ocaml\\ compiler suite, and the dynamical linking\nfeature.\n\nSince this may be unavailable or undesired, there is a possibility to\ndistribute \\whizard\\ as a statically linked executable that contains a\npre-compiled library of processes.  This removes the need for the \\fortran\\\ncompiler, the \\ocaml\\ system, and extra dynamic linking.  Any external\nlibraries that are accessed (the \\fortran\\ runtime environment, and possibly\nsome dynamically linked external libraries and/or the \\cpp\\ runtime library,\nmust still be available on the target system, binary-compatible.  Otherwise,\nthere is no need for transferring the complete \\whizard\\ installation or\nprocess-code compilation data.\n\nGenerating, compiling and linking matrix element code is done in advance on a\nmachine that can access the required tools and produces compatible libraries.\nThis procedure is accomplished by \\sindarin\\ commands, explained below in\nSec.~\\ref{sec:static}.\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\\newpage\n\n\\section{Troubleshooting}\n\\label{sec:troubleshooting}\n\nIn this section, we list known issues or problems and give advice on\nwhat can be done in case something does not work as intended.\n\n\\subsection{Possible (uncommon) build problems}\n\\label{sec:buildproblems}\n\n\\subsubsection{\\ocaml\\ versions and \\oMega\\ builds}\n\nFor the matrix element generator \\oMega\\ of \\whizard\\, the functional\nprogramming language \\ocaml\\ is used. Unfortunately, the versions of\nthe \\ocaml\\ compiler from 3.12.0 on broke backwards\ncompatibility. Therefore,  versions of \\oMega/\\whizard\\ up to v2.0.2\nonly compile with older versions (3.04 to 3.11 works). This has been\nfixed in all \\whizard\\ versions from 2.0.3 on.\n\n\\subsubsection{Identical Build and Source directories}\n\nThere is a problem that only occurred with version 2.0.0 and has been\ncorected for all follow-up versions. It can only appear if you\ncompile the \\whizard\\ sources in the source directory. Then an error\nlike this may occur:\n\\begin{footnotesize}\n\\begin{Verbatim}[frame=single]\n...\nlibtool: compile:  gfortran -I../misc -I../vamp -g -O2 -c processes.f90 -fPIC -o\n          .libs/processes.o\nlibtool: compile:  gfortran -I../misc -I../vamp -g -O2 -c processes.f90 -o\n          processes.o >/dev/null 2>&1\nmake[2]: *** No rule to make target `limits.lo', needed by `decays.lo'.  Stop.\n...\nmake: *** [all-recursive] Error 1\n\\end{Verbatim}\n\\end{footnotesize}\nIn this case, please unpack a fresh copy of \\whizard\\ and configure it\nin a separate directory (not necessarily a subdirectory). Then the\ncompilation will go through:\n\\begin{footnotesize}\n\\begin{Verbatim}[frame=single]\n$ zcat whizard-3.0.0.tar.gz | tar xf -\n$ cd whizard-3.0.0\n$ mkdir _build\n$ cd _build\n$ ../configure FC=gfortran\n$ make\n\\end{Verbatim}\n\\end{footnotesize}\nThe developers use this setup to be able to test different\ncompilers. Therefore building in the same directory is not as\nthoroughly tested. This behavior has been patched from version 2.0.1\non. But note that in general it is always adviced to keep\nbuild and source directory apart from each other.\n\n%%%%%\n\n\\subsection{What happens if \\whizard\\ throws an error?}\n\\label{ref:errors}\n\n\\subsubsection{Particle name special characters in process\n  declarations}\n\nTrying to use a process declaration like\n\\begin{code}\nprocess foo = e-, e+ => mu-, mu+\n\\end{code}\nwill lead to a \\sindarin\\ syntax error:\n\\begin{Code}\nprocess foo = e-, e+ => mu-, mu+\n               ^^\n| Expected syntax: SEQUENCE    <cmd_process> = process <process_id> '=' <process_p\n| Found token: KEYWORD:    '-'\n******************************************************************************\n******************************************************************************\n*** FATAL ERROR:  Syntax error (at or before the location indicated above)\n******************************************************************************\n******************************************************************************\n\\end{Code}\n\\whizard\\ tries to interpret the minus and plus signs as operators\n(\\ttt{KEYWORD: '-'}), so you have to quote the particle names:\n\\ttt{process foo = \"e-\", \"e+\" => \"mu-\", \"mu+\"}.\n\n\n\\subsubsection{Missing collider energy}\n\nThis happens if you forgot to set the collider energy in the\nintegration of a scattering process:\n\\begin{Code}\n******************************************************************************\n******************************************************************************\n*** FATAL ERROR:  Colliding beams: sqrts is zero (please set sqrts)\n******************************************************************************\n******************************************************************************\n\\end{Code}\nThis will solve your problem:\n\\begin{code}\nsqrts = <your_energy>\n\\end{code}\n\n\\subsubsection{Missing process declaration}\n\nIf you try to integrate or simulate a process that has not declared\nbefore (and is also not available in a library that might be loaded),\n\\whizard\\ will complain:\n\\begin{Code}\n******************************************************************************\n******************************************************************************\n*** FATAL ERROR: Process library doesn't contain process 'f00'\n******************************************************************************\n******************************************************************************\n\\end{Code}\nNote that this could sometimes be a simple typo, e.g. in that case an\n\\ttt{integrate (f00)} instead of \\ttt{integrate (foo)}\n\n\\subsubsection{Ambiguous initial state without beam declaration}\n\nWhen the user declares a process with a flavor sum in the initial\nstate, e.g.\n\\begin{code}\nprocess qqaa = u:d, U:D => A, A\nsqrts = <your_energy>\nintegrate (qqaa)\n\\end{code}\nthen a fatal error will be issued:\n\\begin{Code}\n******************************************************************************\n******************************************************************************\n*** FATAL ERROR: Setting up process 'qqaa':\n***                 --------------------------------------------\n***              Inconsistent initial state. This happens if either\n***              several processes with non-matching initial states\n***              have been added, or for a single process with an\n***              initial state flavor sum. In that case, please set beams\n***              explicitly [singling out a flavor / structure function.]\n******************************************************************************\n******************************************************************************\n\\end{Code}\nWhat now? Either a structure function providing a tensor structure in\nflavors has to be provided like\n\\begin{code}\nbeams = p, pbar => pdf_builtin\n\\end{code}\nor, if the partonic process was intended, a specific flavor has to be\nsingled out,\n\\begin{code}\nbeams = u, U\n\\end{code}\nwhich would take only the up-quarks. Note that a sum over process\ncomponents with varying initial states is not possible.\n\n\\subsubsection{Invalid or unsupported beam structure}\n\nAn error message like\n\\begin{Code}\n******************************************************************************\n******************************************************************************\n*** FATAL ERROR: Beam structure: [.......] not supported\n******************************************************************************\n******************************************************************************\n\\end{Code}\nThis happens if you try to use a beam structure with is either not\nsupported by \\whizard\\ (meaning that there is no phase-space\nparameterization for Monte-Carlo integration available in order to\nallow an efficient sampling), or you have chosen a combination of beam\nstructure functions that do not make sense physically. Here is an\nexample for the latter (lepton collider ISR applied to protons, then\nproton PDFs):\n\\begin{code}\nbeams = p, p => isr => pdf_builtin\n\\end{code}\n\n\\subsubsection{Mismatch in beams}\n\nSometimes you get a rather long error output statement followed by a\nfatal error:\n\\begin{Code}\n Evaluator product\n First interaction\n Interaction: 6\n Virtual:\n Particle 1\n  [momentum undefined]\n[.......]\n State matrix:  norm =  1.000000000000E+00\n [f(2212)]\n   [f(11)]\n     [f(92) c(1 )]\n       [f(-6) c(-1 )] => ME(1) = ( 0.000000000000E+00, 0.000000000000E+00)\n[.......]\n******************************************************************************\n******************************************************************************\n*** FATAL ERROR: Product of density matrices is empty\n***                 --------------------------------------------\n***              This happens when two density matrices are convoluted\n***              but the processes they belong to (e.g., production\n***              and decay) do not match. This could happen if the\n***              beam specification does not match the hard\n***              process. Or it may indicate a WHIZARD bug.\n******************************************************************************\n******************************************************************************\n\\end{Code}\nAs \\whizard\\ indicates, this could have happened because the hard\nprocess setup did not match the specification of the beams as in:\n\\begin{code}\nprocess neutral_current_DIS = e1, u => e1, u\nbeams_momentum = 27.5 GeV, 920 GeV\nbeams = p, e => pdf_builtin, none\nintegrate (neutral_current_DIS)\n\\end{code}\nIn that case, the order of the beam particles simply was wrong,\nexchange proton and electron (together with the structure functions)\ninto \\ttt{beams = e, p => none, pdf\\_builtin}, and \\whizard\\ will be\nhappy.\n\n\\subsubsection{Unstable heavy beam particles}\n\nIf you try to use unstable particles as beams that can potentially\ndecay into the final state particles, you might encounter the\nfollowing error message:\n\\begin{Code}\n******************************************************************************\n******************************************************************************\n*** FATAL ERROR:  Phase space: Initial beam particle can decay\n******************************************************************************\n******************************************************************************\n\\end{Code}\nThis happens basically only for  processes in testing/validation (like\n$t \\bar t \\to b \\bar b$). In principle, it could also happen in a real\nphysics setup, e.g. when simulating electron pairs at a muon collider:\n\\begin{code}\nprocess mmee = \"mu-\", \"mu+\" => \"e-\", \"e+\"\n\\end{code}\nHowever, \\whizard\\ at the moment does not allow a muon width, and so\n\\whizard\\ is not able to decay a muon in a scattering process.\nA possibile decay of the beam particle into (part of) the final state\nmight lead to instabilities in the phase space setup. Hence, \\whizard\\\ndo not let you perform such an integration right away. When you\nnevertheless encounter such a rare occasion in your setup, there is a\npossibility to convert this fatal error into a simple warning by\nsetting the flag:\n\\begin{code}\n?fatal_beam_decay = false\n\\end{code}\n\n\\subsubsection{Impossible beam polarization}\n\nIf you specify a beam polarization that cannot correspond to any\nphysically allowed spin density matrix, e.g.,\n\\begin{code}\nbeams = e1, E1\nbeams_pol_density = @(-1), @(1:1:.5, -1, 1:-1)\n\\end{code}\n\\whizard\\ will throw a fatal\nerror like this:\n\\begin{Code}\n Trace of matrix square =    1.4444444444444444\n Polarization: spin density matrix\n   spin type     = 2\n   multiplicity  = 2\n   massive       = F\n   chirality     = 0\n   pol.degree    = 1.0000000\n   pure state    = F\n   @(+1: +1: ( 3.333333333333E-01, 0.000000000000E+00))\n   @(-1: -1: ( 6.666666666667E-01, 0.000000000000E+00))\n   @(-1: +1: ( 6.666666666667E-01, 0.000000000000E+00))\n******************************************************************************\n******************************************************************************\n*** FATAL ERROR: Spin density matrix: not permissible as density matrix\n******************************************************************************\n******************************************************************************\n\\end{Code}\n\n\\subsubsection{Beams with crossing angle}\n\nSpecifying a crossing angle (e.g. at a linear lepton collider) without\nexplicitly setting the beam momenta,\n\\begin{code}\n  sqrts = 1 TeV\n  beams = e1, E1\n  beams\\_theta = 0, 10 degree\n\\end{code}\ntriggers a fatal:\n\\begin{Code}\n******************************************************************************\n******************************************************************************\n*** FATAL ERROR: Beam structure: angle theta/phi specified but momentum/a p undefined\n******************************************************************************\n******************************************************************************\n\\end{Code}\nIn that case the single beam momenta have to be explicitly set:\n\\begin{code}\n  beams = e1, E1\n  beams\\_momentum = 500 GeV, 500 GeV\n  beams\\_theta = 0, 10 degree\n\\end{code}\n\n\\subsubsection{Phase-space generation failed}\n\nSometimes an error might be issued that \\whizard\\ could not generate a\nvalid phase-space parameterization:\n\\begin{Code}\n| Phase space: ... failed.  Increasing phs_off_shell ...\n| Phase space: ... failed.  Increasing phs_off_shell ...\n| Phase space: ... failed.  Increasing phs_off_shell ...\n| Phase space: ... failed.  Increasing phs_off_shell ...\n******************************************************************************\n******************************************************************************\n*** FATAL ERROR: Phase-space: generation failed\n******************************************************************************\n******************************************************************************\n\\end{Code}\nYou see that \\whizard\\ tried to increase the number of off-shell lines\nthat are taken into account for the phase-space setup. The second most\nimportant parameter for the phase-space setup, \\ttt{phs\\_t\\_channel},\nhowever, is not increased automatically. Its default value is $6$, so\ne.g. for the process $e^+ e^- \\to 8\\gamma$ you will run into the\nproblem above. Setting\n\\begin{code}\nphs_off_shell = <n>-1\n\\end{code}\nwhere \\ttt{<n>} is the number of final-state particles will solve the problem.\n\n\\subsubsection{Non-converging process integration}\n\nThere could be several reasons for this to happen. The most prominent\none is that no cuts have been specified for the process (\\whizard\\ttt{2}\ndoes not apply default cuts), and there are singular regions in the\nphase space over which the integration stumbles. If cuts have been\nspecified, it could be that they are not sufficient. E.g. in $pp \\to\njj$ a distance cut between the two jets prevents singular collinear\nsplitting in their generation, but if no $p_T$ cut have been set,\nthere is still singular collinear splitting from the beams.\n\n\\subsubsection{Why is there no event file?}\n\nIf no event file has been generated, \\whizard\\ stumled over some error\nand should have told you, or, you simply forgot to set a \\ttt{simulate}\ncommand for your process. In case there was a \\ttt{simulate} command\nbut the process under consideration is not possible (e.g. a typo,\n\\ttt{e1, E1 => e2, E3} instead of \\ttt{e1, E1 => e3, E3}), then you\nget an error like that:\n\\begin{Code}\n******************************************************************************\n*** ERROR: Simulate: no process has a valid matrix element.\n******************************************************************************\n\\end{Code}\n\n\\subsubsection{Why is the event file empty?}\n\nIn order to get events, you need to set either a desired number of\nevents:\n\\begin{code}\nn_events = <integer>\n\\end{code}\nor you have to specify a certain integrated luminosity (the default\nunit being inverse femtobarn:\n\\begin{code}\nluminosity = <real> / 1 fbarn\n\\end{code}\nIn case you set both, \\whizard\\ will take the one that leads to the\nhigher number of events.\n\n\\subsubsection{Parton showering fails}\n\nFor BSM models containing massive stable or long-lived particles\nparton showering with \\pythiasix\\ fails:\n\\begin{Code}\n     Advisory warning type 3 given after        0 PYEXEC calls:\n     (PYRESD:) Failed to decay particle  1000022 with mass   15.000\n******************************************************************************\n******************************************************************************\n*** FATAL ERROR: Simulation: failed to generate valid event after 10000 tries\n******************************************************************************\n******************************************************************************\n\\end{Code}\nThe solution to that problem is discussed in Sec.~\\ref{sec:pythia6}.\n\n\\vspace{1cm}\n\n\n%%%%%\n\n\\subsection{Debugging, testing, and validation}\n\n\n\\subsubsection{Catching/tracking arithmetic exceptions}\n\nCatching arithmetic exceptions is not automatically supported by\n\\fortran\\ compilers. In general, flags that cause the compiler to keep\ntrack of arithmetic exceptions are diminishing the maximally possible\nperformance, and hence they should not be used in production\nruns. Hence, we refrained from making these flags a default.\nThey can be added using the \\ttt{FCFLAGS = {\\em <flags>}} settings during\nconfiguration. For the \\ttt{NAG} \\fortran\\ compiler we use the flags\n\\ttt{-C=all -nan -gline} for debugging purposes. For the \\ttt{gfortran}\ncompilers, the flags \\ttt{-ffpe-trap=invalid,zero,overflow} are the\ncorresponding debugging flags. For tests, debugging or first sanity\nchecks on your setup, you might want to make use of these flags in\norder to track possible numerical exceptions in the produced code.\nSome compilers started to include \\ttt{IEEE} exception handling\nsupport (\\ttt{Fortran 2008} status), but we do not use these\nimplementations in the \\whizard\\ code (yet).\n\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n\\chapter{Steering WHIZARD: \\sindarin\\ Overview}\n\\label{chap:sindarinintro}\n\n\n\\section{The command language for WHIZARD}\nA conventional physics application program gets its data from a set of input\nfiles.  Alternatively, it is called as a library, so the user has to write his\nown code to interface it, or it combines these two approaches.  \\whizard~1 was\nbuilt in this way: there were some input files which were written by the user,\nand it could be called both stand-alone or as an external library.\n\n\\whizard~2 is also a stand-alone program.  It comes with its own full-fledged\nscript language, called \\sindarin.  All interaction between the user and the\nprogram is done in \\sindarin\\ expressions, commands, and scripts.  Two main\nreasons led us to this choice:\n\\begin{itemize}\n\\item\n  In any nontrivial physics study, cuts and (parton- or hadron-level) analysis\n  are of central importance.  The task of specifying appropriate kinematics\n  and particle selection for a given process is well defined, but it is\n  impossible to cover all possiblities in a simple format like the cut files\n  of \\whizard~1.\n\n  The usual way of dealing with this problem is to write analysis driver code\n  (often in \\cpp, using external libraries for Lorentz algebra etc.  However,\n  the overhead of writing correct \\cpp\\ or \\ttt{Fortran} greatly blows up problems\n  that could be formulated in a few lines of text.\n\\item\n  While many problems lead to a repetitive workflow (process definition,\n  integration, simulation), there are more involved tasks that involve\n  parameter scans, comparisons of different processes, conditional execution,\n  or writing output in widely different formats.  This is easily done by a\n  steering script, which should be formulated in a complete language.\n\\end{itemize}\nThe \\sindarin\\ language is built specifically around event analysis, suitably\nextended to support steering, including data types, loops, conditionals, and\nI/O.\n\nIt would have been possible to use an established general-purpose language for\nthese tasks.  For instance, \\ocaml\\ which is a functional language would be a\nsuitable candidate, and the matrix-element generator \\oMega\\ is written in that\nlanguage.  Another candidate would be a popular scripting language such as\nPYTHON.\n\nWe started to support interfaces for commonly used languages: prime\nexamples for \\ttt{C}, \\cpp, and PYTHON are found in the\n\\ttt{share/interfaces} subdirectory. However, introducing a\nspecial-purpose language has the three distinct\nadvantages: First, it is compiled and executed by the very \\ttt{Fortran} code that\nhandles data and thus accesses it without interfaces.  Second, it can be\ndesigned with a syntax especially suited to the task of event handling and\nMonte-Carlo steering, and third, the user is not forced to learn all those\nfeatures of a generic language that are of no relevance to the application he/she\nis interested in.\n\n\n\\section{\\sindarin\\ scripts}\n\nA \\sindarin\\ script tells the \\whizard\\ program what it has to do.  Typically,\nthe script is contained in a file which you (the user) create.  The file name\nis arbitrary; by convention, it has the extension `\\verb|.sin|'.\n\\whizard\\ takes the file name as its argument on the command line and\nexecutes the contained script:\n\\begin{verbatim}\n/home/user$ whizard script.sin\n\\end{verbatim}\nAlternatively, you can call \\whizard\\ interactively and execute\nstatements line by line; we describe this below in Sec.\\ref{sec:whish}.\n\nA \\sindarin\\ script is a sequence of \\emph{statements}, similar to the\nstatements in any imperative language such as \\ttt{Fortran} or\n\\ttt{C}.  Examples of statements are commands like \\ttt{integrate},\nvariable declarations like \\ttt{logical ?flag} or assigments like\n\\ttt{mH = 130 GeV}.\n\nThe script is free-form, i.e., indentation, extra whitespace and\nnewlines are syntactically insignificant.  In contrast to most\nlanguages, there is no statement separator.  Statements simply follow each\nother, just separated by whitespace.\n\\begin{code}\nstatement1 statement2\nstatement3\n               statement4\n\\end{code}\nNevertheless, for clarity we recommend to\nwrite one statement per line where possible, and to use proper\nindentation for longer statements, nested and bracketed expressions.\n\nA command may consist of a \\emph{keyword}, a list of \\emph{arguments} in\nparantheses \\ttt{(}\\ldots\\ttt{)}, and an \\emph{option} script which\nitself is a sequence of statements.\n\\begin{code}\ncommand\ncommand_with_args (arg1, arg2)\ncommand_with_option { option }\ncommand_with_options (arg) {\n  option_statement1\n  option_statement2\n}\n\\end{code}\nAs a rule, parentheses \\ttt{()} enclose arguments and expressions, as\nyou would expect.  Arguments enclosed in square brackets \\ttt{[]} also\nexist.  They have a special meaning, they denote subevents\n(collections of momenta) in event analysis.  Braces \\ttt{\\{\\}} enclose\nblocks of \\sindarin\\ code.  In particular, the option script\nassociated with a command is a block of code that may contain local\nparameter settings, for instance.  Braces always indicate a scoping\nunit, so parameters will be restored their previous values when the\nexecution of that command is completed.\n\nThe script can contain comments.   Comments are initiated by either a \\verb|#|\nor a \\verb|!| character and extend to the end of the current line.\n\\begin{code}\nstatement\n# This is a comment\nstatement  ! This is also a comment\n\\end{code}\n\n\n%%%%%%%%%%%%%%%\n\n\\section{Errors}\n\\label{sec:errors}\n\nBefore turning to proper \\sindarin\\ syntax, let us consider error messages.\n\\sindarin\\ distinguishes syntax errors and runtime errors.\n\nSyntax errors are recognized when the script is read and compiled,\nbefore any part is executed.  Look at this example:\n\\begin{code}\nprocess foo = u, ubar => d, dbar\nmd = 10\nintegrade (foo)\n\\end{code}\n\\whizard\\ will fail with the error message\n\\begin{interaction}\nsqrts = 1 TeV\nintegrade (foo)\n          ^^\n| Expected syntax: SEQUENCE    <cmd_num> = <var_name> '=' <expr>\n| Found token: KEYWORD:    '('\n******************************************************************************\n******************************************************************************\n*** FATAL ERROR:  Syntax error (at or before the location indicated above)\n******************************************************************************\n******************************************************************************\nWHIZARD run aborted.\n\\end{interaction}\nwhich tells you that you have misspelled the command\n\\verb|integrate|, so the compiler tried to interpret it as a variable.\n\nRuntime errors are categorized by their severity.  A warning is simply\nprinted:\n\\begin{interaction}\nWarning: No cuts have been defined.\n\\end{interaction}\nThis indicates a condition that is suspicious, but may actually be\nintended by the user.\n\nWhen an error is encountered, it is printed with more emphasis\n\\begin{interaction}\n******************************************************************************\n*** ERROR: Variable 'md' set without declaration\n******************************************************************************\n\\end{interaction}\nand the program tries to continue.  However, this usually indicates\nthat there is something wrong.  (The $d$ quark is defined\nmassless, so \\verb|md| is not a model parameter.)  \\whizard\\ counts\nerrors and warnings and tells you at the end\n\\begin{interaction}\n| There were  1 error(s) and no warnings.\n\\end{interaction}\njust in case you missed the message.\n\nOther errors are considered fatal, and execution stops at this point.\n\\begin{interaction}\n******************************************************************************\n******************************************************************************\n*** FATAL ERROR:  Colliding beams: sqrts is zero (please set sqrts)\n******************************************************************************\n******************************************************************************\n\\end{interaction}\nHere, \\whizard\\ was unable to do anything sensible. But at least (in\nthis case) it told the user what to do to resolve the problem.\n\n%%%%%%%%%%%%%%%\n\n\\section{Statements}\n\\label{sec:statements}\n\n\\sindarin\\ statements are executed one by one.  For an overview, we\nlist the most common statements in the order in which they typically\nappear in a \\sindarin\\ script, and quote the basic syntax and simple\nexamples.  This should give an impression on the \\whizard's\ncapabilities and on the user interface.  The list is not complete.\nNote that there are no\nmandatory commands (although an empty \\sindarin\\ script is not really\nuseful).  The details and options are explained in later sections.\n\n\\subsection{Process Configuration}\n\n\\subsubsection{model}\n\\begin{syntax}\nmodel = \\var{model-name}\n\\end{syntax}\nThis assignment sets or resets the current physics model.  The\nStandard Model is already preloaded, so the \\ttt{model} assignment\napplies to non-default models.  Obviously, the model must be known to\n\\whizard. Example:\n\\begin{code}\nmodel = MSSM\n\\end{code}\nSee Sec.~\\ref{sec:models}.\n\n\\subsubsection{alias}\n\\begin{syntax}\nalias \\var{alias-name} = \\var{alias-definition}\n\\end{syntax}\nParticles are specified by their names.   For most particles, there\nare various equivalent names.  Names containing special characters\nsuch as a \\verb|+| sign have to be quoted.  The \\ttt{alias} assignment\ndefines an alias for a list of particles.  This is useful for setting\nup processes with sums over flavors, cut expressions, and more.  The\nalias name is then used like a simple particle name.  Example:\n\\begin{syntax}\nalias jet = u:d:s:U:D:S:g\n\\end{syntax}\nSee Sec.~\\ref{sec:alias}.\n\n\n\\subsubsection{process}\n\\begin{syntax}\nprocess \\var{tag} = \\var{incoming} \\verb|=>| \\var{outgoing}\n\\end{syntax}\nDefine a process.  You give the process a name \\var{tag} by which it is\nidentified later, and specify the incoming and outgoing particles,\nand possibly options.  You can define an arbitrary number of processes\nas long as they are distinguished by their names.  Example:\n\\begin{code}\nprocess w_plus_jets = g, g => \"W+\", jet, jet\n\\end{code}\nSee Sec.~\\ref{sec:processes}.\n\n\n\\subsubsection{sqrts}\n\\begin{syntax}\nsqrts = \\var{energy-value}\n\\end{syntax}\nDefine the center-of-mass energy for collision processes.  The default\nsetup will assume head-on central collisions of two beams.  Example:\n\\begin{code}\nsqrts = 500 GeV\n\\end{code}\nSee Sec.~\\ref{sec:beam-setup}.\n\n\n\\subsubsection{beams}\n\\begin{syntax}\nbeams = \\var{beam-particles} \\\\\nbeams = \\var{beam-particles} => \\var{structure-function-setup}\n\\end{syntax}\nDeclare beam particles and properties.  The current value of \\ttt{sqrts} is\nused, unless specified otherwise.  Example:\n\\begin{code}\nbeams = u:d:s, U:D:S => lhapdf\n\\end{code}\nWith options, the assignment allows for\ndefining beam structure in some detail.  This includes beamstrahlung and ISR\nfor lepton colliders, precise structure function definition for hadron\ncolliders, asymmetric beams, beam polarization, and more.  See\nSec.~\\ref{sec:beams}.\n\n\n\\subsection{Parameters}\n\n\\subsubsection{Parameter settings}\n\\begin{syntax}\n\\var{parameter} = \\var{value} \\\\\n\\var{type} \\var{user-parameter} \\\\\n\\var{type} \\var{user-parameter} = \\var{value}\n\\end{syntax}\nSpecify a value for a parameter.  There are predefined parameters that affect\nthe behavior of a command, model-specific parameters (masses, couplings), and\nuser-defined parameters.  The latter have to be declared with a type, which\nmay be \\ttt{int} (integer), \\ttt{real}, \\ttt{complex}, \\ttt{logical},\n\\ttt{string}, or \\ttt{alias}.  Logical parameter\nnames begin with a question mark, string parameter names with a dollar sign.\nExamples:\n\\begin{code}\nmb = 4.2 GeV\n?rebuild_grids = true\nreal mass_sum = mZ + mW\nstring $message = \"This is a string\"\n\\end{code}\n% $\nThe value need not be a literal, it can be an arbitrary expression of the\ncorrect type.  See Sec.~\\ref{sec:variables}.\n\n\n\\subsubsection{read\\_slha}\n\\begin{syntax}\nread\\_slha (\\var{filename})\n\\end{syntax}\nThis is useful only for supersymmetric models: read a parameter file\nin the SUSY Les Houches Accord format.  The file defines parameter\nvalues and, optionally, decay widths, so this command removes the need\nfor writing assignments for each of them.\n\\begin{code}\nread_slha (\"sps1a.slha\")\n\\end{code}\nSee Sec.~\\ref{sec:slha}.\n\n\n\\subsubsection{show}\n\\begin{syntax}\nshow (\\var{data-objects})\n\\end{syntax}\nPrint the current value of some data object.  This includes not just\nvariables, but also models, libraries, cuts, etc.  This is rather a\ndebugging aid, so don't expect the output to be concise in the latter\ncases.  Example:\n\\begin{code}\nshow (mH, wH)\n\\end{code}\nSee Sec.~\\ref{sec:I/O}.\n\n\n\\subsubsection{printf}\n\\begin{syntax}\nprintf \\var{format-string} (\\var{data-objects})\n\\end{syntax}\nPretty-print the data objects according to the given format string.\nIf there are no data objects, just print the format string.\nThis command is borrowed from the \\ttt{C} programming language; it is\nactually an interface to the system's \\ttt{printf(3)} function.  The\nconversion specifiers are restricted to \\ttt{d,i,e,f,g,s},\ncorresponding to the output of integer, real, and string variables.\nExample:\n\\begin{code}\nprintf \"The Higgs mass is %f GeV\" (mH)\n\\end{code}\nSee Sec.~\\ref{sec:I/O}.\n\n\n\\subsection{Integration}\n\n\\subsubsection{cuts}\n\\begin{syntax}\ncuts = \\var{logical-cut-expression}\n\\end{syntax}\nThe cut expression is a logical macro expression that is evaluated for each\nphase space point during integration and event generation.  You may construct\nexpressions out of various observables that are computed for the (partonic)\nparticle content of the current event.  If the expression evaluates to\n\\verb|true|, the matrix element is calculated and the event is used.  If it\nevaluates to \\verb|false|, the matrix element is set zero and the event is\ndiscarded. Note that for collisions the expression is evaluated in the\nlab frame, while for decays it is evaluated in the rest frame of the\ndecaying particle.  In case you want to impose cuts on a factorized\nprocess, i.e. a combination of a production process and one or more\ndecay processes, you have to use the \\ttt{selection} keyword\ninstead.\n\nExample for the keyword \\ttt{cuts}:\n\\begin{code}\ncuts = all Pt > 20 GeV [jet]\n  and  all mZ - 10 GeV < M < mZ + 10 GeV [lepton, lepton]\n  and  no  abs (Eta) < 2 [jet]\n\\end{code}\nSee Sec.~\\ref{sec:cuts}.\n\n\n\\subsubsection{integrate}\n\\begin{syntax}\nintegrate (\\var{process-tags})\n\\end{syntax}\nCompute the total cross section for a process.  The command takes into account\nthe definition of the process, the beam setup, cuts, and parameters as defined\nin the script.  Parameters may also be specified as options to the command.\n\nIntegration is necessary for each process for which you want to know total or\ndifferential cross sections, or event samples.  Apart from computing a value,\nit sets up and adapts phase space and integration grids that are used in event\ngeneration.   If you just need an event sample, you can omit an explicit\n\\ttt{integrate} command; the \\ttt{simulate} command will call it\nautomatically.  Example:\n\\begin{code}\nintegrate (w_plus_jets, z_plus_jets)\n\\end{code}\nSee Sec.~\\ref{sec:integrate}.\n\n\\subsubsection{?phs\\_only/n\\_calls\\_test}\n\\begin{syntax}\nintegrate (\\var{process-tag}) \\{ ?phs\\_only = true  n\\_calls\\_test = 1000 \\}\n\\end{syntax}\nThese are just optional settings for the \\ttt{integrate} command\ndiscussed just a second ago. The \\ttt{?phs\\_only = true} (note that\nvariables starting with a question mark are logicals) option tells\n\\whizard\\ to prepare a process for integration, but instead of\nperforming the integration, just to generate a phase space\nparameterization. \\ttt{n\\_calls\\_test = <num>} evaluates the sampling\nfunction for random integration channels and random momenta.  \\vamp\\\nintegration grids are neither generated nor used, so the channel\nselection corresponds to the first integration pass, before any grids\nor channel weights are adapted.  The number of sampling points is\ngiven by \\verb|<num>|. The output contains information about the\ntiming, number of sampling points that passed the kinematics\nselection, and the number of matrix-element values that were actually\nevaluated. This command is useful mainly for debugging and\ndiagnostics.  Example:\n\\begin{code}\nintegrate (some_large_process) { ?phs_only = true  n_calls_test = 1000 }\n\\end{code}\n(Note that there used to be a separate command\n\\ttt{matrix\\_element\\_test} until version 2.1.1 of \\whizard\\ which has\nbeen discarded in order to simplify the \\sindarin\\ syntax.)\n\n\\subsection{Events}\n\n\\subsubsection{histogram}\n\\begin{syntax}\nhistogram \\var{tag} (\\var{lower-bound}, \\var{upper-bound}) \\\\\nhistogram \\var{tag} (\\var{lower-bound}, \\var{upper-bound}, \\var{step}) \\\\\n\\end{syntax}\nDeclare a histogram for event analysis.  The histogram is filled by an\nanalysis expression, which is evaluated once for each event during a\nsubsequent simulation step.  Example:\n\\begin{code}\nhistogram pt_distribution (0, 150 GeV, 10 GeV)\n\\end{code}\nSee Sec.~\\ref{sec:histogram}.\n\n\n\\subsubsection{plot}\n\\begin{syntax}\nplot \\var{tag}\n\\end{syntax}\nDeclare a plot for displaying data points.  The plot may be filled by an\nanalysis expression that is evaluated for each event; this would result in a\nscatter plot.  More likely, you will use this feature for displaying data such\nas the energy dependence of a cross section.  Example:\n\\begin{code}\nplot total_cross_section\n\\end{code}\nSee Sec.~\\ref{sec:plot}.\n\n\n\\subsubsection{selection}\n\\begin{syntax}\nselection = \\var{selection-expression}\n\\end{syntax}\nThe selection expression is a logical macro expression that is evaluated once\nfor each event. It is applied to the event record,\nafter all decays have been executed (if any). It is therefore intended\ne.g. for modelling detector acceptance cuts etc. For unfactorized\nprocesses the usage of \\ttt{cuts} or \\ttt{selection} leads to\nthe same results. Events for which the selection expression evaluates\nto false are dropped; they are neither analyzed nor written to any\nuser-defined output file. However, the dropped events are written to\n\\whizard's native event file. For unfactorized processes it is\ntherefore preferable to implement all cuts using the \\ttt{cuts}\nkeyword for the integration, see \\ttt{cuts} above.\nExample:\n\\begin{code}\nselection = all Pt > 50 GeV [lepton]\n\\end{code}\nThe syntax is generically the same as for the \\ttt{cuts\nexpression}, see Sec.~\\ref{sec:cuts}. For more information see also\nSec.~\\ref{sec:analysis}.\n\n\n\\subsubsection{analysis}\n\\begin{syntax}\nanalysis = \\var{analysis-expression}\n\\end{syntax}\nThe analysis expression is a logical macro expression that is evaluated once\nfor each event that passes the integration and selection cuts in a\nsubsequent simulation step.  The\nexpression has type logical in analogy with the cut expression; however, its\nmain use will be in side effects caused by embedded \\ttt{record} expressions.\nThe \\ttt{record} expression books a value, calculated from observables\nevaluated for the current event, in one of the predefined histograms or plots.\nExample:\n\\begin{code}\nanalysis = record pt_distribution (eval Pt [photon])\n      and  record mval (eval M [lepton, lepton])\n\\end{code}\nSee Sec.~\\ref{sec:analysis}.\n\n\n\\subsubsection{unstable}\n\\begin{syntax}\nunstable \\var{particle} (\\var{decay-channels})\n\\end{syntax}\nSpecify that a particle can decay, if it occurs in the final state of a\nsubsequent simulation step.  (In the integration step, all final-state\nparticles are considered stable.)  The decay channels are processes which\nshould have been declared before by a \\ttt{process} command\n(alternatively, there are options that \\whizard\\ takes care of this\nautomatically; cf. Sec.~\\ref{sec:decays}).  They may be\nintegrated explicitly, otherwise the \\ttt{unstable} command will take care of\nthe integration before particle decays are generated.  Example:\n\\begin{code}\nunstable Z (z_ee, z_jj)\n\\end{code}\nNote that the decay is an on-shell approximation.  Alternatively, \\whizard\\ is\ncapable of generating the final state(s) directly, automatically including the\nparticle as an internal resonance together with irreducible background.\nDepending on the physical problem and on the complexity of the matrix-element\ncalculation, either option may be more appropriate.\n\nSee Sec.~\\ref{sec:decays}.\n\n\n\\subsubsection{n\\_events}\n\\begin{syntax}\nn\\_events = \\var{integer}\n\\end{syntax}\nSpecify the number of events that a subsequent simulation step should produce.\nBy default, simulated events are unweighted.  (Unweighting is done by a\nrejection operation on weighted events, so the usual caveats on event\nunweighting by a numerical Monte-Carlo generator do apply.)  Example:\n\\begin{code}\nn_events = 20000\n\\end{code}\nSee Sec.~\\ref{sec:simulation}.\n\n\n\\subsubsection{simulate}\n\\begin{syntax}\nsimulate (\\var{process-tags})\n\\end{syntax}\nGenerate an event sample.  The command allows for analyzing the generated\nevents by the \\ttt{analysis} expression.  Furthermore, events can be written\nto file in various formats.  Optionally, the partonic events can be showered\nand hadronized, partly using included external (\\pythia) or truly\nexternal programs called by \\whizard. Example:\n\\begin{code}\nsimulate (w_plus_jets) { sample_format = lhef }\n\\end{code}\nSee Sec.~\\ref{sec:simulation} and Chapter~\\ref{chap:events}.\n\n\n\\subsubsection{graph}\n\\begin{syntax}\ngraph (\\var{tag}) = \\var{histograms-and-plots}\n\\end{syntax}\nCombine existing histograms and plots into a common graph.  Also\nuseful for pretty-printing single histograms or plots.  Example:\n\\begin{code}\ngraph comparison {\n  $title = \"$p_T$ distribution for two different values of $m_h$\"\n} = hist1 & hist2\n\\end{code}\n% $\nSee Sec.~\\ref{sec:graphs}.\n\n\n\\subsubsection{write\\_analysis}\n\\begin{syntax}\nwrite\\_analysis (\\var{analysis-objects})\n\\end{syntax}\nWrites out data tables for the specified analysis objects (plots,\ngraphs, histograms).  If the argument is empty or absent, write all\nanalysis objects currently available.  The tables are\navailable for feeding external programs.  Example:\n\\begin{code}\nwrite_analysis\n\\end{code}\nSee Sec.~\\ref{sec:analysis}.\n\n\n\\subsubsection{compile\\_analysis}\n\\begin{syntax}\ncompile\\_analysis (\\var{analysis-objects})\n\\end{syntax}\nAnalogous to \\ttt{write\\_analysis}, but the generated data tables are\nprocessed by \\LaTeX\\ and \\gamelan, which produces Postscript and PDF\nversions of the displayed data.  Example:\n\\begin{code}\ncompile_analysis\n\\end{code}\nSee Sec.~\\ref{sec:analysis}.\n\n\n\n\\section{Control Structures}\n\nLike any complete programming language, \\sindarin\\ provides means for\nbranching and looping the program flow.\n\n\\subsection{Conditionals}\n\n\\subsubsection{if}\n\\begin{syntax}\nif \\var{logical\\_expression} then \\var{statements} \\\\\nelsif \\var{logical\\_expression} then \\var{statements} \\\\\nelse \\var{statements} \\\\\nendif\n\\end{syntax}\nExecute statements conditionally, depending on the value of a logical\nexpression. There may be none or multiple \\ttt{elsif} branches, and\nthe \\ttt{else} branch is also optional.  Example:\n\\begin{code}\nif (sqrts > 2 * mtop) then\n  integrate (top_pair_production)\nelse\n  printf \"Top pair production is not possible\"\nendif\n\\end{code}\nThe current \\sindarin\\ implementation puts some restriction on the\nstatements that can appear in a conditional.  For instance, process\ndefinitions must be done unconditionally.\n\n\\subsection{Loops}\n\\subsubsection{scan}\n\\begin{syntax}\nscan \\var{variable} = (\\var{value-list}) \\{ \\var{statements} \\}\n\\end{syntax}\nExecute the statements repeatedly, once for each value of the scan\nvariable.  The statements are executed in a local context, analogous\nto the option statement list for commands.  The value list is a\ncomma-separated list of expressions, where each item evaluates to the\nvalue that is assigned to \\ttt{\\var{variable}} for this iteration.\n\nThe type of the variable is not restricted to numeric, scans can be\ndone for various object types.  For instance, here is a scan over strings:\n\\begin{code}\nscan string $str = (\"%.3g\", \"%.4g\", \"%.5g\") { printf $str (mW) }\n\\end{code}\n% $\nThe output:\n\\begin{interaction}\n[user variable] $str = \"%.3g\"\n80.4\n[user variable] $str = \"%.4g\"\n80.42\n[user variable] $str = \"%.5g\"\n80.419\n\\end{interaction}\n% $\nFor a numeric scan variable in particular, there are iterators that\nimplement the usual functionality of \\ttt{for} loops.  If the scan\nvariable is of type integer, an iterator may take one of the forms\n\\begin{syntax}\n\\var{start-value} \\verb|=>| \\var{end-value} \\\\\n\\var{start-value} \\verb|=>| \\var{end-value} \\verb|/+| \\var{add-step} \\\\\n\\var{start-value} \\verb|=>| \\var{end-value} \\verb|/-| \\var{subtract-step} \\\\\n\\var{start-value} \\verb|=>| \\var{end-value} \\verb|/*| \\var{multiplicator} \\\\\n\\var{start-value} \\verb|=>| \\var{end-value} \\verb|//| \\var{divisor} \\\\\n\\end{syntax}\nThe iterator can be put in place of an expression in the\n\\ttt{\\var{value-list}}.  Here is an example:\n\\begin{code}\nscan int i = (1, (3 => 5), (10 => 20 /+ 4))\n\\end{code}\nwhich results in the output\n\\begin{interaction}\n[user variable] i =            1\n[user variable] i =            3\n[user variable] i =            4\n[user variable] i =            5\n[user variable] i =           10\n[user variable] i =           14\n[user variable] i =           18\n\\end{interaction}\n[Note that the \\ttt{\\var{statements}} part of the scan construct may\nbe empty or absent.]\n\nFor real scan variables, there are even more possibilities for iterators:\n\\begin{syntax}\n\\var{start-value} \\verb|=>| \\var{end-value} \\\\\n\\var{start-value} \\verb|=>| \\var{end-value} \\verb|/+| \\var{add-step} \\\\\n\\var{start-value} \\verb|=>| \\var{end-value} \\verb|/-| \\var{subtract-step} \\\\\n\\var{start-value} \\verb|=>| \\var{end-value} \\verb|/*| \\var{multiplicator} \\\\\n\\var{start-value} \\verb|=>| \\var{end-value} \\verb|//| \\var{divisor} \\\\\n\\var{start-value} \\verb|=>| \\var{end-value} \\verb|/+/| \\var{n-points-linear} \\\\\n\\var{start-value} \\verb|=>| \\var{end-value} \\verb|/*/| \\var{n-points-logarithmic} \\\\\n\\end{syntax}\nThe first variant is equivalent to \\ttt{/+ 1}.  The \\ttt{/+} and\n\\ttt{/-} operators are intended to add or subtract the given step once\nfor each iteration.  Since in floating-point arithmetic this would be\nplagued by rounding ambiguities, the actual implementation first\ndetermines the (integer) number of iterations from the provided step\nvalue, then recomputes the step so that the iterations are evenly\nspaced with the first and last value included.\n\nThe \\ttt{/*} and \\ttt{//} operators are analogous.  Here, the initial\nvalue is intended to be multiplied by the step value once for each\niteration.  After determining the integer number of iterations, the\nactual scan values will be evenly spaced on a logarithmic scale.\n\nFinally, the \\ttt{/+/} and \\ttt{/*/} operators allow to specify the\nnumber of iterations (not counting the initial value) directly.  The\n\\ttt{\\var{start-value}} and \\ttt{\\var{end-value}} are always included,\nand the intermediate values will be evenly spaced on a linear\n(\\ttt{/+/}) or logarithmic (\\ttt{/*/}) scale.\n\nExample:\n\\begin{code}\nscan real mh = (130 GeV,\n           (140 GeV => 160 GeV /+ 5 GeV),\n           180 GeV,\n           (200 GeV => 1 TeV /*/ 10))\n  {  integrate (higgs_decay) }\n\\end{code}\n\n\n\\subsection{Including Files}\n\\subsubsection{include}\n\\begin{syntax}\ninclude (\\var{file-name})\n\\end{syntax}\nInclude a \\sindarin\\ script from the specified file.  The contents\nmust be complete commands; they are compiled and executed as if they\nwere part of the current script.  Example:\n\\begin{code}\ninclude (\"default_cuts.sin\")\n\\end{code}\n\n\n\n\n\n\\section{Expressions}\n\n\\sindarin\\ expressions are classified by their types.  The\ntype of an expression is verified when the script is compiled, before\nit is executed.  This provides some safety against simple coding\nerrors.\n\nWithin expressions, grouping is done using ordinary brackets \\ttt{()}.\nFor subevent expressions, use square brackets \\ttt{[]}.\n\n\\subsection{Numeric}\nThe language supports the classical numeric types\n\\begin{itemize}\n\\item\n   \\ttt{int} for integer: machine-default, usually 32 bit;\n\\item\n   \\ttt{real}, usually \\emph{double precision} or 64 bit;\n\\item\n   \\ttt{complex}, consisting of real and imaginary part equivalent to a\n   \\ttt{real} each.\n\\end{itemize}\n\\sindarin\\ supports arithmetic expressions similar to conventional\nlanguages.  In arithmetic expressions, the three numeric types can be\nmixed as appropriate.  The computation essentially follows the rules\nfor mixed arithmetic in \\fortran.  The arithmetic operators are\n\\verb|+|, \\verb|-|, \\verb|*|, \\verb|/|, \\verb|^|. Standard functions\nsuch as \\ttt{sin}, \\ttt{sqrt}, etc. are available.  See\nSec.~\\ref{sec:real} to Sec.~\\ref{sec:complex}.\n\nNumeric values can be associated with units.  Units evaluate to\nnumerical factors, and their use is optional, but they can be useful\nin the physics context for which \\whizard\\ is designed.  Note that the\ndefault energy/mass unit is \\verb|GeV|, and the default unit for cross\nsections is \\verb|fbarn|.\n\n\n\\subsection{Logical and String}\n\nThe language also has the following standard types:\n\\begin{itemize}\n\\item\n   \\ttt{logical} (a.k.a.\\ boolean). Logical variable names have a\n   \\ttt{?} (question mark) as prefix.\n\\item\n   \\ttt{string} (arbitrary length).  String variable names have a \\ttt{\\$}\n   (dollar) sign as prefix.\n\\end{itemize}\nThere are comparisons, logical operations, string concatenation, and a\nmechanism for formatting objects as strings for output.\n\n\n\\subsection{Special}\n\nFurthermore, \\sindarin\\ deals with a bunch of data types tailored\nspecifically for Monte Carlo applications:\n\\begin{itemize}\n\\item\n  \\ttt{alias} objects denote a set of particle species.\n\\item\n  \\ttt{subevt} objects denote a collection of particle momenta within an\n  event.  They have their uses in cut and analysis expressions.\n\\item\n  \\ttt{process} object are generated by a \\ttt{process} statement.\n  There are no expressions involving processes, but they are referred\n  to by \\ttt{integrate} and \\ttt{simulate} commands.\n\\item\n  \\ttt{model}: There is always a current object of type and name\n  \\ttt{model}.  Several models can be used concurrently by\n  appropriately defining processes, but this happens behind the scenes.\n\\item\n  \\ttt{beams}: Similarly, the current implementation allows only for a single\n  object of this type at a given time, which is assigned by a \\ttt{beams =}\n  statement and used by \\ttt{integrate}.\n\\end{itemize}\n\nIn the current implementation, \\sindarin\\ has no container data types\nderived from basic types, such as lists, arrays, or hashes, and there\nare no user-defined data types.  (The \\ttt{subevt} type is a container\nfor particles in the context of events, but there is no type for an\nindividual particle: this is represented as a one-particle\n\\ttt{subevt}). There are also containers for inclusive processes which\nare however simply handled as an expansion into several components of\na master process tag.\n\n\n\n\n\n\\section{Variables}\n\\label{sec:variables}\n\n\\sindarin\\ supports global variables, variables local to a scoping unit (the\noption body of a command, the body of a \\ttt{scan} loop), and variables local\nto an expression.\n\nSome variables are predefined by the system (\\emph{intrinsic\n  variables}).  They are further separated into \\emph{independent}\nvariables that can be reset by the user, and \\emph{derived} or locked\nvariables that are automatically computed by the program, but not\ndirectly user-modifiable.  On top of that, the user is free to\nintroduce his own variables (\\emph{user variables}).\n\nThe names of numerical variables consist of alphanumeric characters and\nunderscores.  The first character must not be a digit.  Logical\nvariable names are furthermore prefixed by a\n\\ttt{?} (question mark) sign, while string variable names begin\nwith a \\ttt{\\$} (dollar) sign.\n\nCharacter case does matter.  In this manual we follow the\nconvention that variable names consist of lower-case letters,\ndigits, and underscores only, but you may also use upper-case\nletters if you wish.\n\nPhysics models contain their own, specific set of numeric variables\n(masses, couplings).  They are attached to the model where they are\ndefined, so they appear and disappear with the model that is currently\nloaded.  In particular, if two different models contain a variable\nwith the same name, these two variables are nevertheless distinct:\nsetting one doesn't affect the other.  This feature might be called,\nin computer-science jargon, a \\emph{mixin}.\n\nUser variables -- global or local -- are declared by their type when they are\nintroduced, and acquire an initial value upon declaration.  Examples:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  int i = 3\n  real my_cut_value = 10 GeV\n  complex c = 3 - 4 * I\n  logical ?top_decay_allowed = mH > 2 * mtop\n  string $hello = \"Hello world!\"\n  alias q = d:u:s:c\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nAn existing user variable can be assigned a new value without a declaration:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  i = i + 1\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nand it may also be redeclared if the new declaration specifies the same type,\nthis is equivalent to assigning a new value.\n\nVariables local to an expression are introduced by the \\ttt{let ... in}\ncontruct.  Example:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  real a = let int n = 2 in\n           x^n + y^n\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nThe explicit \\ttt{int} declaration is necessary only if the variable \\ttt{n}\nhas not been declared before.  An intrinsic variable must not be declared:\n\\ttt{let mtop = 175.3 GeV in \\ldots}\n\n\\ttt{let} constructs can be concatenated if several local variables need to\nbe assigned: \\ttt{let a = 3 in let b = 4 in \\textit{expression}}.\n\nVariables of type \\ttt{subevt} can only be defined in \\ttt{let} constructs.\n\nExclusively in the context of particle selections (event analysis), there are\n\\emph{observables} as special numeric objects.  They are used like numeric\nvariables, but they are never declared or assigned.  They get their value\nassigned dynamically, computed from the particle momentum configuration.\nHence, they may be understood as (intrinsic and predefined) macros.\nBy convention, observable names begin with a capital letter.\n\nFurther macros are\n\\begin{itemize}\n\\item\n  \\ttt{cuts} and \\ttt{analysis}.  They are of type logical, and can be\n  assigned an expression by the user.  They are evaluated once for\n  each event.\n\\item\n  \\ttt{scale}, \\ttt{factorization\\_scale} and\n  \\ttt{renormalization\\_scale} are real numeric macros which define the\n  energy scale(s) of an event.  The latter two override the former.\n  If no scale is defined, the partonic energy is used as the process scale.\n\\item\n  \\ttt{weight} is a real numeric macro.  If it is assigned an\n  expression, the expression is evaluated for each valid phase-space\n  point, and the result multiplies the matrix element.\n\\end{itemize}\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n\\chapter{\\sindarin\\ in Details}\n\\label{chap:sindarin}\n\n\\section{Data and expressions}\n\n\\subsection{Real-valued objects}\n\\label{sec:real}\n\nReal literals have their usual form, mantissa and, optionally, exponent:\n\\begin{center}\n\\ttt{0.}\\quad  \\ttt{3.14}\\quad \\ttt{-.5}\\quad\n\\ttt{2.345e-3}\\quad \\ttt{.890E-023}\n\\end{center}\nInternally, real values are treated as double precision.  The values are read\nby the \\fortran\\ library, so details depend on its implementation.\n\nA special feature of \\sindarin\\ is that numerics (real and integer) can be\nimmediately followed by a physical unit.  The supported units are presently\nhard-coded, they are\n\\begin{center}\n  \\ttt{meV}\\quad \\ttt{eV}\\quad \\ttt{keV}\\quad\n  \\ttt{MeV}\\quad \\ttt{GeV}\\quad \\ttt{TeV}\n\\\\\n  \\ttt{nbarn}\\quad \\ttt{pbarn}\\quad \\ttt{fbarn}\\quad \\ttt{abarn}\n\\\\\n  \\ttt{rad}\\quad \\ttt{mrad}\\quad \\ttt{degree}\n\\\\\n  \\ttt{\\%}\n\\end{center}\nIf a number is followed by a unit, it is automatically normalized to the\ncorresponding default unit: \\ttt{14.TeV} is transformed into the real number\n\\ttt{14000.}  Default units are \\ttt{GeV}, \\ttt{fbarn}, and \\ttt{rad}.  The\n\\ttt{\\%} sign after a number has the effect that the number is multiplied by\n$0.01$.  Note that no checks for consistency of units are done, so you can add\n\\ttt{1 meV + 3 abarn} if you absolutely wish to.  Omitting units is always\nallowed, in that case, the default unit is assumed.\n\nUnits are not treated as variables.  In particular, you can't write \\ttt{theta\n  / degree}, the correct form is \\ttt{theta / 1 degree}.\n\nThere is a single predefined real constant, namely $\\pi$ which is referred to\nby the keyword \\ttt{pi}. In addition, there is a single predefined\ncomplex constant, which is the complex unit $i$, being referred to by\nthe keyword \\ttt{I}.\n\nThe arithmetic operators are\n\\begin{center}\n  \\verb|+| \\verb|-| \\verb|*| \\verb|/| \\verb|^|\n\\end{center}\nwith their obvious meaning and the usual precedence rules.\n\n\\sindarin\\ supports a bunch of standard numerical functions, mostly equivalent\nto their \\fortran\\ counterparts:\n\\begin{center}\n  \\ttt{abs}\\quad \\ttt{conjg}\\quad \\ttt{sgn}\\quad \\ttt{mod}\\quad \\ttt{modulo}\n\\\\\n  \\ttt{sqrt}\\quad \\ttt{exp}\\quad \\ttt{log}\\quad \\ttt{log10}\n\\\\\n  \\ttt{sin}\\quad \\ttt{cos}\\quad \\ttt{tan}\\quad\n  \\ttt{asin}\\quad \\ttt{acos}\\quad \\ttt{atan}\n\\\\\n  \\ttt{sinh}\\quad \\ttt{cosh}\\quad \\ttt{tanh}\n\\end{center}\n(Unlike \\fortran, the \\ttt{sgn} function takes only one argument and returns\n$1.$, or $-1.$) The function argument is enclosed in brackets: \\ttt{sqrt\n  (2.)}, \\ttt{tan (11.5 degree)}.\n\nThere are two functions with two real arguments:\n\\begin{center}\n  \\ttt{max}\\quad \\ttt{min}\n\\end{center}\nExample: \\verb|real lighter_mass = min (mZ, mH)|\n\nThe following functions of a real convert to integer:\n\\begin{center}\n  \\ttt{int}\\quad \\ttt{nint}\\quad \\ttt{floor}\\quad \\ttt{ceiling} %% \\; .\n\\end{center}\nand this converts to complex type:\n\\begin{center}\n  \\ttt{complex}\n\\end{center}\n\nReal values can be compared by the following operators, the result is a\nlogical value:\n\\begin{center}\n  \\verb|==|\\quad \\verb|<>|\n\\\\\n  \\verb|>|\\quad \\verb|<|\\quad \\verb|>=|\\quad \\verb|<=|\n\\end{center}\nIn \\sindarin, it is possible to have more than two operands in a logical\nexpressions.  The comparisons are done from left to right.  Hence,\n\\begin{center}\n  \\verb|115 GeV < mH < 180 GeV|\n\\end{center}\nis valid \\sindarin\\ code and evaluates to \\ttt{true} if the Higgs mass is in the\ngiven range.\n\nTests for equality and inequality with machine-precision real numbers are\nnotoriously unreliable and should be avoided altogether.  To deal with this\nproblem, \\sindarin\\ has the possibility to make the comparison operators\n``fuzzy'' which should be read as ``equal (unequal) up to an absolute\ntolerance'', where the tolerance is given by the real-valued intrinsic\nvariable \\ttt{tolerance}. This variable is initially zero, but can be\nset to any value (for instance, \\ttt{tolerance = 1.e-13} by the user.\nNote that for non-zero tolerance, operators like\n\\verb|==| and \\verb|<>| or \\verb|<| and \\verb|>| are not mutually\nexclusive\\footnote{In older versions of \\whizard, until v2.1.1, there\nused to be separate comparators for the comparisons up to a tolerance,\nnamely \\ttt{==\\~{}} and \\ttt{<>\\~{}}. These have been discarded from\nv2.2.0 on in order to simplify the syntax.}.\n\n%%%%%%%%%%%%%%%\n\n\\subsection{Integer-valued objects}\n\\label{sec:integer}\n\nInteger literals are obvious:\n\\begin{center}\n\\ttt{1}\\quad \\ttt{-98765}\\quad \\ttt{0123}\n\\end{center}\nIntegers are always signed.  Their range is the default-integer range as\ndetermined by the \\fortran\\ compiler.\n\nLike real values, integer values can be followed by a physical unit: \\ttt{1\n  TeV}, \\ttt{30 degree}.  This actually transforms the integer into a real.\n\nStandard arithmetics is supported:\n\\begin{center}\n  \\verb|+| \\verb|-| \\verb|*| \\verb|/| \\verb|^|\n\\end{center}\nIt is important to note that there is no fraction datatype, and pure integer\narithmetics does not convert to real.  Hence \\ttt{3/4} evaluates to \\ttt{0},\nbut \\ttt{3 GeV / 4 GeV} evaluates to \\ttt{0.75}.\n\nSince all arithmetics is handled by the underlying \\fortran\\ library, integer\noverflow is not detected.  If in doubt, do real arithmetics.\n\nInteger functions are more restricted than real functions.  We support the\nfollowing:\n\\begin{center}\n  \\ttt{abs}\\quad \\ttt{sgn}\\quad \\ttt{mod}\\quad \\ttt{modulo}\n\\\\\n  \\ttt{max}\\quad \\ttt{min}\n\\end{center}\nand the conversion functions\n\\begin{center}\n  \\ttt{real}\\quad \\ttt{complex}\n\\end{center}\nComparisons of integers among themselves and with reals are possible using the\nsame set of comparison operators as for real values.  This includes\nthe operators with a finite tolerance.\n\n%%%%%%%%%%%%%%%%\n\n\\subsection{Complex-valued objects}\n\\label{sec:complex}\n\nComplex variables and values are currently not yet used by the physics\nmodels implemented in \\whizard. There complex input coupling constants\nare always split into their real and imaginary parts (or modulus and\nphase). They are exclusively available for arithmetic calculations.\n\nThere is no form for complex literals.  Complex values must be created via an\narithmetic expression,\n\\begin{center}\n  \\ttt{complex c = 1 + 2 * I}\n\\end{center}\nwhere the imaginary unit \\ttt{I} is predefined as a constant.\n\nThe standard arithmetic operations are supported (also mixed with real and\ninteger).  Support for functions is currently still incomplete, among the\nsupported functions there are \\ttt{sqrt}, \\ttt{log}, \\ttt{exp}.\n\n\n\n\\subsection{Logical-valued objects}\n\nThere are two predefined logical constants, \\ttt{true} and \\ttt{false}.\nLogicals are \\emph{not} equivalent to integers (like in C) or to strings (like\nin PERL), but they make up a type of their own.  Only in \\verb|printf| output,\nthey are treated as strings, that is, they require the \\verb|%s| conversion\nspecifier.\n\nThe names of logical variables begin with a question mark \\ttt{?}.  Here is\nthe declaration of a logical user variable:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{footnotesize}\n\\begin{verbatim}\nlogical ?higgs_decays_into_tt = mH > 2 * mtop\n\\end{verbatim}\n\\end{footnotesize}\n\\end{footnotesize}\n\\end{quote}\n\nLogical expressions use the standard boolean operations\n\\begin{center}\n  \\ttt{or}\\quad \\ttt{and}\\quad \\ttt{not}\n\\end{center}\nThe results of comparisons (see above) are logicals.\n\nThere is also a special logical operator with lower priority, concatenation by\na semicolon:\n\\begin{center}\n  \\ttt{\\textit{lexpr1} ; \\textit{lexpr2}}\n\\end{center}\nThis evaluates \\textit{lexpr1} and throws its result away, then evaluates\n\\textit{lexpr2} and returns that result.  This feature is to used with logical\nexpressions that have a side effect, namely the \\ttt{record} function within\nanalysis expressions.\n\nThe primary use for intrinsic logicals are flags that change the behavior of\ncommands.  For instance, \\ttt{?unweighted = true} and \\ttt{?unweighted =\n  false} switch the unweighting of simulated event samples on and off.\n\n\n\\subsection{String-valued objects and string operations}\n\\label{sec:sprintf}\n\nString literals are enclosed in double quotes: \\ttt{\"This is a string.\"}\nThe empty string is \\ttt{\"\"}.  String variables begin with the dollar\nsign: \\verb|$|. There is only one string operation, concatenation\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\nstring $foo = \"abc\" & \"def\"\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\n\nHowever, it is possible to transform variables and values to a string using\nthe \\ttt{sprintf} function.  This function is an interface to the system's \\ttt{C}\nfunction \\ttt{sprintf} with some restrictions and modifications.  The allowed\nconversion specifiers are\n\\begin{center}\n  \\verb|%d|\\quad \\verb|%i| (integer)\n\\\\\n  \\verb|%e|\\quad \\verb|%f|\\quad \\verb|%g|\\quad\n  \\verb|%E|\\quad \\verb|%F|\\quad \\verb|%G| (real)\n\\\\\n  \\verb|%s| (string and logical)\n\\end{center}\nThe conversions can use flag parameter, field width, and precision, but length\nmodifiers are not supported since they have no meaning for the application.\n(See also Sec.~\\ref{sec:I/O}.)\n\nThe \\ttt{sprintf} function has the syntax\n\\begin{center}\n  \\ttt{sprintf} \\textit{format-string}\n  \\ttt{(}\\textit{arg-list}\\ttt{)}\n\\end{center}\nThis is an expression that evaluates to a string.  The format string contains\nthe mentioned conversion specifiers.  The argument list is optional.  The\narguments are separated by commas.  Allowed arguments are integer, real,\nlogical, and string variables, and numeric expressions.  Logical and string\nexpressions can also be printed, but they have to be dressed as\n\\emph{anonymous variables}.  A logical anonymous variable has the form\n\\ttt{?(}\\textit{logical\\_expr}\\ttt{)} (example: \\ttt{?(mH > 115 GeV)}).  A\nstring anonymous variable has the form \\ttt{\\$(}\\textit{string-expr}\\ttt{)}.\n\nExample:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\nstring $unit = \"GeV\"\nstring $str = sprintf \"mW = %f %s\" (mW, $unit)\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nThe related \\ttt{printf} command with the same syntax prints the formatted\nstring to standard output\\footnote{In older versions of \\whizard,\n  until v2.1.1, there also used to be a \\ttt{sprintd} function and a\n  \\ttt{printd} command for default formats without a format\n  string. They have been discarded in order to simplify the syntax\n  from version v2.2.0 on.}.\n\n\n\\section{Particles and (sub)events}\n\n\\subsection{Particle aliases}\n\\label{sec:alias}\n\nA particle species is denoted by its name as a string: \\verb|\"W+\"|.\nAlternatively, it can be addressed by an \\ttt{alias}.  For instance, the $W^+$\nboson has the alias \\ttt{Wp}.  Aliases are used like variables in a context\nwhere a particle species is expected, and the user can specify his/her own\naliases.\n\nAn alias may either denote a single particle species or a class of particles\nspecies.  A colon \\ttt{:} concatenates particle names and aliases to yield\nmulti-species aliases:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\nalias quark = u:d:s\nalias wboson = \"W+\":\"W-\"\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nSuch aliases are used for defining processes with summation over flavors, and\nfor defining classes of particles for analysis.\n\nEach model files define both names and (single-particle) aliases for all\nparticles it contains.  Furthermore, it defines the class aliases\n\\verb|colored| and \\verb|charged| which are particularly useful for event\nanalysis.\n\n\n\\subsection{Subevents}\n\nSubevents are sets of particles, extracted from an event.  The sets are\nunordered by default, but may be ordered by appropriate functions.  Obviously,\nsubevents are meaningful only in a context where an event is available.  The\npossible context may be the specification of a cut, weight, scale, or analysis\nexpression.\n\nTo construct a simple subevent, we put a particle alias or an expression of\ntype particle alias into square brackets:\n\\begin{quote}\n\\begin{footnotesize}\n  \\verb|[\"W+\"]|\\quad\n  \\verb|[u:d:s]|\\quad\n  \\verb|[colored]|\n\\end{footnotesize}\n\\end{quote}\nThese subevents evaluate to the set of all $W^+$ bosons (to be precise, their\nfour-momenta), all $u$, $d$, or $s$ quarks, and all colored particles,\nrespectively.\n\nA subevent can contain pseudoparticles, i.e., particle combinations.\nThat is, the four-momenta of\ndistinct particles are combined (added conmponent-wise), and the results\nbecome subevent elements just like ordinary particles.\n\nThe (pseudo)particles in a subevent are non-overlapping.  That is, for\nany of the particles in the original event, there is at most one\n(pseudo)particle in the subevent in which it is contained.\n\nSometimes, variables (actually, named constants) of type subevent are useful.\nSubevent variables are declared by the \\ttt{subevt} keyword, and their\nnames carry the prefix \\verb|@|.  Subevent variables exist only within the\nscope of a \\verb|cuts| (or \\verb|scale|, \\verb|analysis|, etc.) macro, which\nis evaluated in the presence of an actual event.  In the macro body, they are\nassigned via the \\ttt{let} construct:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\ncuts =\n  let subevt @jets = select if Pt > 10 GeV [colored]\n  in\n  all Theta > 10 degree [@jets, @jets]\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nIn this expression, we first define \\verb|@jets| to stand for the set of all\ncolored partons with $p_T>10\\;\\mathrm{GeV}$.  This abbreviation is then used\nin a logical expression, which evaluates to true if all relative angles\nbetween distinct jets are greater than $10$ degree.\n\nWe note that the example also introduces pairs of subevents: the square\nbracket with two entries evaluates to the list of all possible pairs which do\nnot overlap.  The objects within square brackets can be either subevents or\nalias expressions.  The latter are transformed into subevents before they are\nused.\n\nAs a special case, the original event is always available as the predefined\nsubevent \\verb|@evt|.\n\n\\subsection{Subevent functions}\n\nThere are several functions that take a subevent (or an alias) as an argument\nand return a new subevent.  Here we describe them:\n\n\\subsubsection{collect}\n\\begin{quote}\n\\begin{footnotesize}\n  \\ttt{collect [\\textit{particles}]} \\\\\n  \\ttt{collect if \\textit{condition} [\\textit{particles}]} \\\\\n  \\ttt{collect if \\textit{condition} [\\textit{particles}, \\textit{ref\\_particles}]}\n\\end{footnotesize}\n\\end{quote}\nFirst version: collect all particle momenta in the argument and combine them\nto a single four-momentum.  The \\textit{particles} argument may either be a\n\\ttt{subevt} expression or an \\ttt{alias} expression.  The result is a\none-entry \\ttt{subevt}.  In the second form, only those particles are collected\nwhich satisfy the \\textit{condition}, a logical expression.  Example:\n\\ttt{collect if Pt > 10 GeV [colored]}\n\nThe third version is useful if you want to put binary observables (i.e.,\nobservables constructed from two different particles) in the condition.  The\n\\textit{ref\\_particles} provide the second argument for binary observables in\nthe \\textit{condition}.  A particle is taken into account if the condition is\ntrue with respect to all reference particles that do not overlap with this\nparticle.  Example: \\ttt{collect if Theta > 5 degree [photon, charged]}:\ncombine all photons that are separated by 5 degrees from all charged\nparticles.\n\n\n\\subsubsection{cluster}\n\n\\begin{quote}\n\\begin{footnotesize}\n  \\ttt{cluster [\\textit{particles}]} \\\\\n  \\ttt{cluster if \\textit{condition} [\\textit{particles}]} \\\\\n\\end{footnotesize}\n\\end{quote}\nFirst version: collect all particle momenta in the argument and cluster them\nto a set of jets.  The \\textit{particles} argument may either be a\n\\ttt{subevt} expression or an \\ttt{alias} expression.  The result is a\none-entry \\ttt{subevt}.  In the second form, only those particles are clustered\nwhich satisfy the \\textit{condition}, a logical expression.  Example:\n\\ttt{cluster if Pt > 10 GeV [colored]}\n\n% The third version is usefule if you want to put binary observables (i.e.,\n% observables constructed from two different particles) in the condition.  The\n% \\textit{ref\\_particles} provide the second argument for binary observables in\n% the \\textit{condition}.  A particle is taken into account if the condition is\n% true with respect to all reference particles that do not overlap with this\n% particle.  Example: \\ttt{cluster if Theta > 5 degree [photon, charged]}:\n% combine all photons that are separated by 5 degrees from all charged\n% particles.\n\nThis command is available from \\whizard\\ version 2.2.1 on, and only if\nthe \\fastjet\\ package has been installed and linked with \\whizard\\\n(cf. Sec.\\ref{sec:fastjet}); in a future version of \\whizard\\ it is\nforeseen to have also an intrinsic clustering package inside \\whizard\\\nwhich will be able to support some of the clustering algorithms\nbelow. To use it in an analysis, you have to set the variable\n\\ttt{jet\\_algorithm} to one of the predefined jet-algorithm values\n(integer constants):\n\\begin{quote}\n\\begin{footnotesize}\n  \\ttt{kt\\_algorithm}\\\\\n  \\ttt{cambridge\\_algorithm}\\\\\n  \\ttt{antikt\\_algorithm}\\\\\n  \\ttt{genkt\\_algorithm}\\\\\n  \\ttt{cambridge\\_for\\_passive\\_algorithm}\\\\\n  \\ttt{genkt\\_for\\_passive\\_algorithm}\\\\\n  \\ttt{ee\\_kt\\_algorithm}\\\\\n  \\ttt{ee\\_genkt\\_algorithm}\\\\\n  \\ttt{plugin\\_algorithm}\n\\end{footnotesize}\n\\end{quote}\nand the variable \\ttt{jet\\_r} to the desired $R$ parameter value, as\nappropriate for the analysis and the jet algorithm.  Example:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  jet_algorithm = antikt_algorithm\n  jet_r = 0.7\n  cuts = all Pt > 15 GeV [cluster if Pt > 5 GeV [colored]]\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\n\n\\subsubsection{select\\_b\\_jet, select\\_non\\_b\\_jet, select\\_c\\_jet,\n  select\\_light\\_jet}\n\nThis command is available from \\whizard\\ version 2.8.1 on, and it only\ngenerates anything non-trivial if the \\fastjet\\ package has been\ninstalled and linked with \\whizard\\ (cf. Sec.\\ref{sec:fastjet}). It\nonly returns sensible results when it is applied to subevents after\nthe \\ttt{cluster} command (cf. the paragraph before). It is similar to\nthe \\ttt{select} command, and accepts a logical expression as a\npossible condition. The four commands \\ttt{select\\_b\\_jet},\n\\ttt{select\\_non\\_b\\_jet}, \\ttt{select\\_c\\_jet}, and\n\\ttt{select\\_light\\_jet} select $b$ jets, non-$b$ jets\n(anything lighter than $b$s), $c$ jets (neither $b$ nor light) and\nlight jets (anything besides $b$ and $c$), respectively. An example\nlooks like this:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  alias lightjet = u:U:d:D:s:S:c:C:gl\n  alias jet = b:B:lightjet\n  process eebbjj = e1, E1 => b, B, lightjet, lightjet\n  jet_algorithm = antikt_algorithm\n  jet_r = 0.5\n  cuts = let subevt @clustered_jets = cluster [jet] in\n         let subevt @bjets = select_b_jet [@clustered_jets] in\n         .....\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\n\n\\subsubsection{photon\\_isolation}\n\nThis command is available from \\whizard\\ version 2.8.1 on. It provides\nisolation of photons from hadronic (and possibly electromagnetic)\nactivity in the event to define a (especially) NLO cross section that\nis completely perturbative. The isolation criterion according to\nFrixione, cf.~\\cite{Frixione:1998jh}, removes the non-perturbative\ncontribution from the photon fragmentation function. This command can\nin principle be applied to elementary hard process partons (and\nleptons), but generates something sensible only if the\n\\fastjet\\ package has been installed and linked with\n\\whizard\\ (cf. Sec.\\ref{sec:fastjet}). There are three parameters\nwhich allow to tune the isolation, \\ttt{photon\\_iso\\_r0}, which is the\nradius $R^0_\\gamma$ of the isolation cone, \\ttt{photon\\_iso\\_eps},\nwhich is the fraction $\\epsilon_\\gamma$ of the photon (transverse)\nenergy that enters the isolation criterion, and the exponent of the\nisolation cone, \\ttt{photon\\_iso\\_n}, $n^\\gamma$. For more information\ncf.~\\cite{Frixione:1998jh}. The command allows also a conditional cut\non the photon which is applied before the isolation takes place. The\nfirst argument are the photons in the event, the second the particles\nfrom which they should be isolated. If also the electromagnetic\nactivity is to be isolated, photons need to be isolated from\nthemselves and must be included in the second argument. This is\nmandatory if leptons appear in the second argument. Two examples look\nlike this:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  alias jet = u:U:d:D:s:S:c:C:gl\n  process eeaajj = e1, E1 => A, A, jet, jet\n  jet_algorithm = antikt_algorithm\n  jet_r = 0.5\n  cuts = photon_isolation if Pt > 10 GeV [A, jet]\n         ....\n  cuts = let subevt @jets = cluster [jet] in\n         photon_isolation if Pt > 10 GeV [A, @jets]\n         .....\n  process eeajmm = e1, E1 => A, jet, e2, E2\n  cuts = let subevt @jets = cluster [jet] in\n         let subevt @iso = join [@jets, A:e2:E2]\n         photon_isolation [A, @iso]\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\n\n\n\\subsubsection{combine}\n\\begin{quote}\n\\begin{footnotesize}\n  \\ttt{combine [\\textit{particles\\_1}, \\textit{particles\\_2}]} \\\\\n  \\ttt{combine if \\textit{condition}} [\\textit{particles\\_1}, \\textit{particles\\_2}]\n\\end{footnotesize}\n\\end{quote}\nMake a new subevent of composite particles.  The composites are generated by\ncombining all particles from subevent \\textit{particles\\_1} with all particles\nfrom subevent \\textit{particles\\_2} in all possible combinations.  Overlapping\ncombinations are excluded, however: if a (composite) particle in the first\nargument has a constituent in common with a composite particle in the second\nargument, the combination is dropped.  In particular, this applies if the\nparticles are identical.\n\nIf a \\textit{condition} is provided, the combination is done only when the\nlogical expression, applied to the particle pair in question, returns true.\nFor instance, here we reconstruct intermediate $W^-$ bosons:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\nlet @W_candidates = combine if 70 GeV < M < 80 GeV [\"mu-\", \"numubar\"]\nin ...\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nNote that the combination may fail, so the resulting subevent could be empty.\n\n\n\\subsubsection{operator +}\n\nIf there is no condition, the $+$ operator provides a convenient\nshorthand for the \\verb|combine| command.  In particular, it can be\nused if there are several particles to combine.  Example:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\ncuts = any 170 GeV < M < 180 GeV [b + lepton + invisible]\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\n\n\n\\subsubsection{select}\n\\begin{quote}\n\\begin{footnotesize}\n  \\ttt{select if \\textit{condition} [\\textit{particles}]}   \\\\\n  \\ttt{select if \\textit{condition} [\\textit{particles}, \\textit{ref\\_particles}]}\n\\end{footnotesize}\n\\end{quote}\nOne argument: select all particles in the argument that satisfy the\n\\textit{condition} and drop the rest.  Two arguments: the\n\\textit{ref\\_particles} provide a second argument for binary observables.\nSelect particles if the condition is satisfied for all reference particles.\n\n\\subsubsection{extract}\n\\begin{quote}\n\\begin{footnotesize}\n  \\ttt{extract [\\textit{particles}]}   \\\\\n  \\ttt{extract index \\textit{index-value} [\\textit{particles}]}\n\\end{footnotesize}\n\\end{quote}\nReturn a single-particle subevent.  In the first version, it contains the\nfirst particle in the subevent \\textit{particles}.  In the second version, the\nparticle with index \\textit{index-value} is returned, where\n\\textit{index-value} is an integer expression.  If its value is negative, the\nindex is counted from the end of the subevent.\n\nThe order of particles in an event or subevent is not always well-defined, so\nyou may wish to sort the subevent before applying the \\textit{extract}\nfunction to it.\n\n\\subsubsection{sort}\n\\begin{quote}\n\\begin{footnotesize}\n   \\ttt{sort [\\textit{particles}]} \\\\\n   \\ttt{sort by \\textit{observable} [\\textit{particles}]}   \\\\\n   \\ttt{sort by \\textit{observable} [\\textit{particles}, \\textit{ref\\_particle}]}\n\\end{footnotesize}\n\\end{quote}\nSort the subevent according to some criterion.  If no criterion is supplied\n(first version), the subevent is sorted by increasing PDG code (first\nparticles, then antiparticles).  In the second version, the\n\\textit{observable} is a real expression which is evaluated for each particle\nof the subevent in turn.  The subevent is sorted by increasing value of this\nexpression, for instance:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\nlet @sorted_evt = sort by Pt [@evt]\nin ...\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nIn the third version, a reference particle is provided as second argument, so\nthe sorting can be done for binary observables.  It doesn't make much sense to\nhave several reference particles at once, so the \\ttt{sort} function uses\nonly the first entry in the subevent \\textit{ref-particle}, if it has more\nthan one.\n\n\n\\subsubsection{join}\n\\begin{quote}\n\\begin{footnotesize}\n  \\ttt{join [\\textit{particles}, \\textit{new\\_particles}]} \\\\\n  \\ttt{join if \\textit{condition} [\\textit{particles}, \\textit{new\\_particles}]}\n\\end{footnotesize}\n\\end{quote}\nThis commands appends the particles in subevent \\textit{new\\_particles} to the\nsubevent \\textit{particles}, i.e., it joins the two particle sets.  To be\nprecise, a (pseudo)particle from \\textit{new\\_particles} is only appended if it\ndoes not overlap with any of the (pseudo)particles\npresent in \\textit{particles}, so the function will not produce overlapping\nentries.\n\nIn the second version, each particle from \\textit{new\\_particles} is also\nchecked with all particles in the first set whether \\textit{condition} is\nfulfilled.  If yes, and there is no overlap, it is appended, otherwise\nit is dropped.\n\n\n\\subsubsection{operator \\&}\n\nSubevents can also be concatenated by the operator \\verb|&|.  This effectively\napplies \\ttt{join} to all operands in turn.  Example:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\nlet @visible =\n    select if Pt > 10 GeV and E > 5 GeV [photon]\n  & select if Pt > 20 GeV and E > 10 GeV [colored]\n  & select if Pt > 10 GeV [lepton]\nin ...\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\n\n\n\\subsection{Calculating observables}\n\nObservables (invariant mass \\ttt{M}, energy \\ttt{E}, \\ldots) are used in\nexpressions just like ordinary numeric variables.  By convention, their names\nstart with a capital letter.  They are computed using a particle momentum (or\ntwo particle momenta) which are taken from a subsequent subevent argument.\n\nWe can extract the value of an observable for an event and make it available\nfor computing the \\ttt{scale} value, or for histogramming etc.:\n\n\\subsubsection{eval}\n\\begin{quote}\n\\begin{footnotesize}\n  \\ttt{eval \\textit{expr} [\\textit{particles}]} \\\\\n  \\ttt{eval \\textit{expr} [\\textit{particles\\_1}, \\textit{particles\\_2}]}\n\\end{footnotesize}\n\\end{quote}\n\nThe function \\ttt{eval} takes an expression involving observables and\nevaluates it for the first momentum (or momentum pair) of the subevent (or\nsubevent pair) in square brackets that follows the expression.  For example,\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  eval Pt [colored]\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nevaluates to the transverse momentum of the first colored particle,\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  eval M [@jets, @jets]\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nevaluates to the invariant mass of the first distinct pair of jets (assuming\nthat \\verb|@jets| has been defined in a \\ttt{let} construct), and\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  eval E - M [combine [e1, N1]]\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nevaluates to the difference of energy and mass of the combination of the first\nelectron-neutrino pair in the event.\n\nThe last example illustrates why observables are treated like variables, even\nthough they are functions of particles: the \\ttt{eval} construct with the\nparticle reference in square brackets after the expression allows to compute\nderived observables -- observables which are functions of new observables --\nwithout the need for hard-coding them as new functions.\n\n\n\\subsection{Cuts and event selection}\n\\label{sec:cuts}\n\nInstead of a numeric value, we can use observables to compute a logical value.\n\n\\subsubsection{all}\n\\begin{quote}\n\\begin{footnotesize}\n  \\ttt{all \\textit{logical\\_expr} [\\textit{particles}]} \\\\\n  \\ttt{all \\textit{logical\\_expr} [\\textit{particles\\_1}, \\textit{particles\\_2}]}\n\\end{footnotesize}\n\\end{quote}\nThe \\ttt{all} construct expects a logical expression and one or two subevent\narguments in square brackets.\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  all Pt > 10 GeV [charged]\n  all 80 GeV < M < 100 GeV [lepton, antilepton]\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nIn the second example, \\ttt{lepton} and \\ttt{antilepton} should be aliases\ndefined in a \\ttt{let} construct.  (Recall that aliases are promoted to\nsubevents if they occur within square brackets.)\n\nThis construction defines a cut.  The result value is \\ttt{true} if the\nlogical expression evaluates to \\ttt{true} for all particles in the subevent\nin square brackets.  In the two-argument case it must be \\ttt{true} for all\nnon-overlapping combinations of particles in the two subevents.  If one of the\narguments is the empty subevent, the result is also \\ttt{true}.\n\n\\subsubsection{any}\n\\begin{quote}\n\\begin{footnotesize}\n  \\ttt{any \\textit{logical\\_expr} [\\textit{particles}]} \\\\\n  \\ttt{any \\textit{logical\\_expr} [\\textit{particles\\_1}, \\textit{particles\\_2}]}\n\\end{footnotesize}\n\\end{quote}\nThe \\ttt{any} construct is true if the logical expression is true for at least\none particle or non-overlapping particle combination:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  any E > 100 GeV [photon]\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nThis defines a trigger or selection condition.  If a subevent argument is\nempty, it evaluates to \\ttt{false}\n\n\\subsubsection{no}\n\\begin{quote}\n\\begin{footnotesize}\n  \\ttt{no \\textit{logical\\_expr} [\\textit{particles}]} \\\\\n  \\ttt{no \\textit{logical\\_expr} [\\textit{particles\\_1}, \\textit{particles\\_2}]}\n\\end{footnotesize}\n\\end{quote}\nThe \\ttt{no} construct is true if the logical expression is true for no single\none particle or non-overlapping particle combination:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  no 5 degree < Theta < 175 degree [\"e-\":\"e+\"]\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nThis defines a veto condition.  If a subevent argument is empty, it\nevaluates to \\ttt{true}.  It is equivalent to \\ttt{not any\\ldots}, but\nincluded for notational convenience.\n\n\n\\subsection{More particle functions}\n\n\\subsubsection{count}\n\\begin{quote}\n\\begin{footnotesize}\n  \\ttt{count [\\textit{particles}]} \\\\\n  \\ttt{count [\\textit{particles\\_1}, \\textit{particles\\_2}]} \\\\\n  \\ttt{count if \\textit{logical-expr} [\\textit{particles}]} \\\\\n  \\ttt{count if \\textit{logical-expr} [\\textit{particles}, \\textit{ref\\_particles}]}\n\\end{footnotesize}\n\\end{quote}\nThis counts the number of events in a subevent, the result is of type\n\\ttt{int}.  If there is a conditional expression, it counts the number of\n\\ttt{particle} in the subevent that pass the test.   If there are two\narguments, it counts the number of non-overlapping particle pairs (that pass\nthe test, if any).\n\n\n\\subsubsection{Predefined observables}\n\nThe following real-valued observables are available in \\sindarin\\ for use in\n\\ttt{eval}, \\ttt{all}, \\ttt{any}, \\ttt{no}, and \\ttt{count} constructs.  The\nargument is always the subevent or alias enclosed in square brackets.\n\\begin{itemize}\n\\item \\ttt{M2}\n  \\begin{itemize}\n  \\item One argument: Invariant mass squared of the (composite) particle in the\n    argument.\n  \\item Two arguments: Invariant mass squared of the sum of the two momenta.\n  \\end{itemize}\n\\item \\ttt{M}\n  \\begin{itemize}\n  \\item Signed square root of \\ttt{M2}: positive if $\\ttt{M2}>0$, negative if\n    $\\ttt{M2}<0$.\n  \\end{itemize}\n\\item \\ttt{E}\n  \\begin{itemize}\n  \\item One argument: Energy of the (composite) particle in the argument.\n  \\item Two arguments: Sum of the energies of the two momenta.\n  \\end{itemize}\n\\item \\ttt{Px}, \\ttt{Py}, \\ttt{Pz}\n  \\begin{itemize}\n  \\item Like \\ttt{E}, but returning the spatial momentum components.\n  \\end{itemize}\n\\item \\ttt{P}\n  \\begin{itemize}\n  \\item Like \\ttt{E}, returning the absolute value of the spatial momentum.\n  \\end{itemize}\n\\item \\ttt{Pt}, \\ttt{Pl}\n  \\begin{itemize}\n  \\item Like \\ttt{E}, returning the transversal and longitudinal momentum,\n    respectively.\n  \\end{itemize}\n\\item \\ttt{Theta}\n  \\begin{itemize}\n  \\item One argument: Absolute polar angle in the lab frame\n  \\item Two arguments: Angular distance of two particles in the lab frame.\n  \\end{itemize}\n\\item \\ttt{Theta\\_star}\n  Only with two arguments, gives the relative polar angle of the two momenta\n  in the rest system of the momentum sum (i.e. mother particle).\n\\item \\ttt{Phi}\n  \\begin{itemize}\n  \\item One argument: Absolute azimuthal angle in the lab frame\n  \\item Two arguments: Azimuthal distance of two particles in the lab frame\n  \\end{itemize}\n\\item \\ttt{Rap}, \\ttt{Eta}\n  \\begin{itemize}\n  \\item One argument: rapidity / pseudorapidity\n  \\item Two arguments: rapidity / pseudorapidity difference\n  \\end{itemize}\n\\item \\ttt{Dist}\n  \\begin{itemize}\n  \\item Two arguments: Distance on the $\\eta$-$\\phi$ cylinder, i.e.,\n    $\\sqrt{\\Delta\\eta^2 + \\Delta\\phi^2}$\n  \\end{itemize}\n\\item \\ttt{kT}\n  \\begin{itemize}\n  \\item Two arguments: $k_T$ jet clustering variable:\n    $2 \\min (E_{j1}^2, E_{j2}^2) / Q^2 \\times (1 -\n    \\cos\\theta_{j1,j2})$. At the moment, $Q^2 = 1$ GeV$^2$.\n  \\end{itemize}\n\\end{itemize}\nThere are also integer-valued observables:\n\\begin{itemize}\n\\item \\ttt{PDG}\n  \\begin{itemize}\n  \\item One argument: PDG code of the particle.  For a composite particle, the\n    code is undefined (value 0).  For flavor sums in the \\ttt{cuts} statement,\n    this observable always returns the same flavor, i.e. the first one from the\n    flavor list.  It is thus only sensible to use it in an \\ttt{analysis} or\n    \\ttt{selection} statement when simulating events.\n  \\end{itemize}\n\\item \\ttt{Ncol}\n  \\begin{itemize}\n  \\item One argument: Number of open color lines.  Only count color\n    lines, not anticolor lines.  This is defined only if the global flag\n    \\ttt{?colorize\\_subevt} is true.\n  \\end{itemize}\n\\item \\ttt{Nacl}\n  \\begin{itemize}\n  \\item One argument: Number of open anticolor lines.  Only count anticolor\n    lines, not color lines.  This is defined only if the global flag\n    \\ttt{?colorize\\_subevt} is true.\n  \\end{itemize}\n\\end{itemize}\n\n\n%%%%%%%%%%%%%%%\n\n\\section{Physics Models}\n\\label{sec:models}\n\nA physics model is a combination of particles, numerical parameters (masses,\ncouplings, widths), and Feynman rules.  Many physics analyses are done in the\ncontext of the Standard Model (SM).  The SM is also the default model for\n\\whizard.  Alternatively, you can choose a subset of the SM (QED or QCD),\nvariants of the SM (e.g., with or without nontrivial CKM matrix), or various\nextensions of the SM.  The complete list is displayed in\nTable~\\ref{tab:models}.\n\nThe model definitions are contained in text files with filename extension\n\\ttt{.mdl}, e.g., \\ttt{SM.mdl}, which are located in the \\ttt{share/models}\nsubdirectory of the \\whizard\\ installation.  These files are easily readable,\nso if you need details of a model implementation, inspect their contents.  The\nmodel file contains the complete particle and parameter definitions as well as\ntheir default values.  It also contains a list of vertices.  This is used only\nfor phase-space setup; the vertices used for generating amplitudes and the\ncorresponding Feynman rules are stored in different files within the\n\\oMega\\ source tree.\n\nIn a \\sindarin\\ script, a model is a special object of type \\ttt{model}.  There\nis always a \\emph{current} model.  Initially, this is the SM, so on startup\n\\whizard\\ reads the \\ttt{SM.mdl} model file and assigns its content to the\ncurrent model object.  (You can change the default model by the \\ttt{--model}\noption on the command line. Also the preloading of a model can be\nswitched off with the \\ttt{--no-model} option)  Once the model has\nbeen loaded, you can define processes for the model, and you have all\nindependent model parameters at your disposal.  As noted before, these\nare intrinsic parameters which need not be declared when you assign\nthem a value, for instance:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  mW = 80.33 GeV\n  wH = 243.1 MeV\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nOther parameters are \\emph{derived}.  They can be used in expressions like any\nother parameter, they are also intrinsic, but they cannot be modified directly\nat all.  For instance, the electromagnetic coupling \\ttt{ee} is a derived\nparameter.  If you change either \\ttt{GF} (the Fermi constant), \\ttt{mW} (the\n$W$ mass), or \\ttt{mZ} (the $Z$ mass), this parameter will reflect the change,\nbut setting it directly is an error.  In other words, the SM is defined within\n\\whizard\\ in the $G_F$-$m_W$-$m_Z$ scheme.  (While this scheme is unusual for\nloop calculations, it is natural for a tree-level event generator where the\n$Z$ and $W$ poles have to be at their experimentally determined\nlocation\\footnote{In future versions of \\whizard\\ it is foreseen to\n  implement other electroweak schemes.}.)\n\nThe model also defines the particle names and aliases that you can use for\ndefining processes, cuts, or analyses.\n\nIf you would like to generate a SUSY process instead, for instance, you can\nassign a different model (cf.\\ Table~\\ref{tab:models}) to the current model\nobject:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  model = MSSM\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nThis assignment has the consequence that the list of SM parameters and\nparticles is replaced by the corresponding MSSM list (which is much longer).\nThe MSSM contains essentially all SM parameters by the same name, but in fact\nthey are different parameters.  This is revealed when you say\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  model = SM\n  mb = 5.0 GeV\n  model = MSSM\n  show (mb)\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nAfter the model is reassigned, you will see the MSSM value of $m_b$ which\nstill has its default value, not the one you have given.  However, if you\nrevert to the SM later,\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  model = SM\n  show (mb)\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nyou will see that your modification of the SM's $m_b$ value has been\nremembered.  If you want both mass values to agree, you have to set them\nseparately in the context of their respective model.  Although this might seem\ncumbersome at first, it is nevertheless a sensible procedure since the\nparameters defined by the user might anyhow not be defined or available for\nall chosen models.\n\nWhen using two different models which need an SLHA input file,\nthese {\\em have} to be provided for both models.\n\nWithin a given scope, there is only one current model.  The current model can\nbe reset permanently as above.  It can also be temporarily be reset in a local\nscope, i.e., the option body of a command or the body of a \\ttt{scan} loop.\nIt is thus possible to use several models within the same script.  For\ninstance, you may define a SUSY signal process and a pure-SM background\nprocess. Each process depends only on the respective model's parameter set,\nand a change to a parameter in one of the models affects only the\ncorresponding process.\n\n\n\\section{Processes}\n\\label{sec:processes}\n\nThe purpose of \\whizard\\ is the integration and simulation of high-energy\nphysics processes: scatterings and decays.  Hence, \\ttt{process} objects play\nthe central role in \\sindarin\\ scripts.\n\nA \\sindarin\\ script may contain an arbitrary number of process definitions.  The\ninitial states need not agree, and the processes may belong to different\nphysics models.\n\n\n\\subsection{Process definition}\n\\label{sec:procdef}\n\nA process object is defined in a straightforward notation.  The definition\nsyntax is straightforward:\n\\begin{quote}\n\\begin{footnotesize}\n  \\ttt{process \\textit{process-id} = \\textit{incoming-particles}} \\verb|=>|\n  \\ttt{\\textit{outgoing-particles}}\n\\end{footnotesize}\n\\end{quote}\nHere are typical examples:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  process w_pair_production = e1, E1 => \"W+\", \"W-\"\n  process zdecay = Z => u, ubar\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nThroughout the program, the process will be identified by its\n\\textit{process-id}, so this is the name of the process object.  This\nidentifier is arbitrary, chosen by the user.  It follows the rules for\nvariable names, so it consists of alphanumeric characters and underscores,\nwhere the first character is not numeric.  As a special rule, it must not\ncontain upper-case characters.  The reason is that this name is used for\nidentifying the process not just within the script, but also within the\n\\fortran\\ code that the matrix-element generator produces for this process.\n\nAfter the equals sign, there follow the lists of incoming and outgoing\nparticles.  The number of incoming particles is either one or two: scattering\nprocesses and decay processes.  The number of outgoing particles should be two\nor larger (as $2\\to 1$ processes are proportional to a $\\delta$\nfunction they can only be sensibly integrated when using a structure\nfunction like a hadron collider PDF or a beamstrahlung spectrum.).\nThere is no hard upper limit; the complexity of processes that\n\\whizard\\ can handle depends only on the practical computing\nlimitations (CPU time and memory).  Roughly speaking, one can assume\nthat processes up to $2\\to 6$ particles are safe, $2\\to 8$ processes\nare feasible given sufficient time for reaching a stable integration,\nwhile more complicated processes are largely unexplored.\n\nWe emphasize that in the default setup, the matrix element of a physics\nprocess is computed exactly in leading-order perturbation theory, i.e., at\ntree level.  There is no restriction of intermediate states, the result always\ncontains the complete set of Feynman graphs that connect the initial with the\nfinal state.  If the result would actually be expanded in Feynman graphs\n(which is not done by the \\oMega\\ matrix element generator that\n\\whizard\\ uses), the number of graphs can easily reach several thousands,\ndepending on the complexity of the process and on the physics model.\n\nMore details about the different methods for quantum field-theoretical\nmatrix elements can be found in Chap.~\\ref{chap:hardint}. In the\nfollowing, we will discuss particle names, options for processes like\nrestrictions on intermediate states, parallelization, flavor sums and\nprocess components for inclusive event samples (process containers).\n\n\n\\subsection{Particle names}\n\nThe particle names are taken from the particle definition in the current model\nfile.  Looking at the SM, for instance, the electron entry in\n\\ttt{share/models/SM.mdl} reads\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\nparticle E_LEPTON 11\n  spin 1/2  charge  -1   isospin -1/2\n  name \"e-\" e1 electron e\n  anti \"e+\" E1 positron\n  tex_name \"e^-\"\n  tex_anti \"e^+\"\n  mass me\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nThis tells that you can identify an electron either as \\verb|\"e-\"|, \\verb|e1|,\n\\verb|electron|, or simply \\verb|e|.  The first version is used for output,\nbut needs to be quoted, because otherwise \\sindarin\\ would interpret the minus\nsign as an operator.  (Technically, unquoted particle identifiers are aliases,\nwhile the quoted versions -- you can say either \\verb|e1| or \\verb|\"e1\"| --\nare names.  On input, this makes no difference.)  The alternative version\n\\verb|e1| follows a convention, inherited from\n\\comphep~\\cite{Boos:2004kh}, that particles are indicated by lower\ncase, antiparticles by upper case, and for leptons, the generation\nindex is appended: \\verb|e2| is the muon, \\verb|e3| the tau.  These\nalternative names need not be quoted because they contain no special\ncharacters.\n\nIn Table~\\ref{tab:SM-particles}, we list the recommended names as well as\nmass and width parameters for all SM particles.  For other models, you may\nlook up the names in the corresponding model file.\n\n\\begin{table}[p]\n  \\begin{center}\n    \\begin{tabular}{|l|l|l|l|cc|}\n      \\hline\n      & Particle & Output name & Alternative names & Mass & Width\\\\\n      \\hline\\hline\n      Leptons\n      &$e^-$ & \\verb|e-| & \\ttt{e1}\\quad\\ttt{electron} & \\ttt{me} & \\\\\n      &$e^+$ & \\verb|e+| & \\ttt{E1}\\quad\\ttt{positron} & \\ttt{me} & \\\\\n      \\hline\n      &$\\mu^-$ & \\verb|mu-| & \\ttt{e2}\\quad\\ttt{muon} & \\ttt{mmu} & \\\\\n      &$\\mu^+$ & \\verb|mu+| & \\ttt{E2} & \\ttt{mmu} & \\\\\n      \\hline\n      &$\\tau^-$ & \\verb|tau-| & \\ttt{e3}\\quad\\ttt{tauon} & \\ttt{mtau} & \\\\\n      &$\\tau^+$ & \\verb|tau+| & \\ttt{E3} & \\ttt{mtau} & \\\\\n      \\hline\\hline\n      Neutrinos\n      &$\\nu_e$ & \\verb|nue| & \\ttt{n1} & & \\\\\n      &$\\bar\\nu_e$ & \\verb|nuebar| & \\ttt{N1} & & \\\\\n      \\hline\n      &$\\nu_\\mu$ & \\verb|numu| & \\ttt{n2} & & \\\\\n      &$\\bar\\nu_\\mu$ & \\verb|numubar| & \\ttt{N2} & & \\\\\n      \\hline\n      &$\\nu_\\tau$ & \\verb|nutau| & \\ttt{n3} & & \\\\\n      &$\\bar\\nu_\\tau$ & \\verb|nutaubar| & \\ttt{N3} & & \\\\\n      \\hline\\hline\n      Quarks\n      &$d$ & \\verb|d| & \\ttt{down} & & \\\\\n      &$\\bar d$ & \\verb|dbar| & \\ttt{D} & & \\\\\n      \\hline\n      &$u$ & \\verb|u| & \\ttt{up} & & \\\\\n      &$\\bar u$ & \\verb|ubar| & \\ttt{U} & & \\\\\n      \\hline\n      &$s$ & \\verb|s| & \\ttt{strange} & \\ttt{ms} & \\\\\n      &$\\bar s$ & \\verb|sbar| & \\ttt{S} & \\ttt{ms}  & \\\\\n      \\hline\n      &$c$ & \\verb|c| & \\ttt{charm} & \\ttt{mc}  & \\\\\n      &$\\bar c$ & \\verb|cbar| & \\ttt{C} & \\ttt{mc} & \\\\\n      \\hline\n      &$b$ & \\verb|b| & \\ttt{bottom} & \\ttt{mb} & \\\\\n      &$\\bar b$ & \\verb|bbar| & \\ttt{B} &  \\ttt{mb} & \\\\\n      \\hline\n      &$t$ & \\verb|t| & \\ttt{top} &  \\ttt{mtop} & \\ttt{wtop} \\\\\n      &$\\bar t$ & \\verb|tbar| & \\ttt{T} &  \\ttt{mtop} & \\ttt{wtop} \\\\\n      \\hline\\hline\n      Vector bosons\n      &$g$ & \\verb|gl| & \\ttt{g}\\quad\\ttt{G}\\quad\\ttt{gluon} & & \\\\\n      \\hline\n      &$\\gamma$ & \\verb|A| & \\ttt{gamma}\\quad\\ttt{photon} & & \\\\\n      \\hline\n      &$Z$ & \\verb|Z| & & \\ttt{mZ} & \\ttt{wZ} \\\\\n      \\hline\n      &$W^+$ & \\verb|W+| & \\ttt{Wp} & \\ttt{mW} & \\ttt{wW} \\\\\n      &$W^-$ & \\verb|W-| & \\ttt{Wm} & \\ttt{mW} & \\ttt{wW} \\\\\n      \\hline\\hline\n      Scalar bosons\n      &$H$ & \\verb|H| & \\ttt{h}\\quad \\ttt{Higgs} & \\ttt{mH} & \\ttt{wH} \\\\\n      \\hline\n    \\end{tabular}\n  \\end{center}\n  \\caption{\\label{tab:SM-particles} Names that can be used for SM particles.\n    Also shown are the intrinsic variables that can be used to set mass and\n    width, if applicable.}\n\\end{table}\n\nWhere no mass or width parameters are listed in the table, the particle is\nassumed to be massless or stable, respectively.  This is obvious for particles\nsuch as the photon.  For neutrinos, the mass is meaningless to particle\nphysics collider experiments, so it is zero.  For quarks, the $u$ or\n$d$ quark mass is unobservable directly, so we also set it zero.  For\nthe heavier quarks, the mass may play a role, so it is kept.  (The $s$\nquark is borderline; one may argue that its mass is also unobservable\ndirectly.)  On the other hand, the electron mass is relevant, e.g., in\nphoton radiation without cuts, so it is not zero by default.\n\nIt pays off to set particle masses to zero, if the approximation is justified,\nsince fewer helicity states will contribute to the matrix element.  Switching\noff one of the helicity states of an external fermion speeds up the\ncalculation by a factor of two.  Therefore, script files will usually contain\nthe assignments\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  me = 0  mmu = 0  ms = 0  mc = 0\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nunless they deal with processes where this simplification is\nphenomenologically unacceptable.  Often $m_\\tau$ and $m_b$ can also be\nneglected, but this excludes processes where the Higgs couplings of $\\tau$ or\n$b$ are relevant.\n\nSetting fermion masses to zero enables, furthermore, the possibility to define\nmulti-flavor aliases\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  alias q = d:u:s:c\n  alias Q = D:U:S:C\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nand handle processes such as\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  process two_jets_at_ilc = e1, E1 => q, Q\n  process w_pairs_at_lhc = q, Q => Wp, Wm\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nwhere a sum over all allowed flavor combination is automatically included.\nFor technical reasons, such flavor sums are possible only for massless\nparticles (or more general for mass-degenerate particles). If you want\nto generate inclusive processes with sums over particles of different\nmasses (e.g. summing over $W/Z$ in the final state etc.), confer below\nthe section about process components, Sec.~\\ref{sec:processcomp}.\n\nAssignments of masses, widths and other parameters are actually in effect when\na process is integrated, not when it is defined.  So, these assignments may\ncome before or after the process definition, with no significant difference.\nHowever, since flavor summation requires masses to be zero, the assignments\nmay be put before the alias definition which is used in the process.\n\nThe muon, tau, and the heavier quarks are actually unstable.  However, the\nwidth is set to zero because their decay is a macroscopic effect and, except for\nthe muon, affected by hadron physics, so it is not described by \\whizard.  (In\nthe current \\whizard\\ setup, all decays occur at the production vertex.  A\nfuture version may describe hadronic physics and/or macroscopic particle\npropagation, and this restriction may be eventually removed.)\n\n\n\n\n\\subsection{Options for processes}\n\\label{sec:process options}\n\nThe \\ttt{process} definition may contain an optional argument:\n\\begin{quote}\n\\begin{footnotesize}\n  \\ttt{process \\textit{process-id} = \\textit{incoming-particles}} \\verb|=>|\n  \\ttt{\\textit{outgoing-particles}} \\ttt{\\{\\textit{options\\ldots}\\}}\n\\end{footnotesize}\n\\end{quote}\nThe \\textit{options} are a \\sindarin\\ script that is executed in a context local\nto the \\ttt{process} command.  The assignments it contains apply only to the\nprocess that is defined. In the following, we describe the set of potentially\nuseful options (which all can be also set globally):\n\n\\subsubsection{Model reassignment}\n\nIt is possible to locally reassign the model via a  \\ttt{model =} statment,\npermitting the definition of process using a model other than the globally\nselected model. The process will retain this association during\nintegration and event generation.\n\n\\subsubsection{Restrictions on matrix elements}\n\\label{subsec:restrictions}\n\nAnother useful option is the setting\n\\begin{quote}\n\\begin{footnotesize}\n  \\verb|$restrictions =| \\ttt{\\textit{string}}\n\\end{footnotesize}\n\\end{quote}\nThis option allows to select particular classes of Feynman graphs for the\nprocess when using the \\oMega\\ matrix element generator.  The\n\\verb|$restrictions| string specifies e.g. propagators that the graph\nmust contain.  Here is an example:\n\\begin{code}\n  process zh_invis = e1, E1 => n1:n2:n3, N1:N2:N3, H { $restrictions = \"1+2 ~ Z\" }\n\\end{code}\nThe complete process $e^-e^+ \\to \\nu\\bar\\nu H$, summed over all neutrino\ngenerations,  contains both $ZH$ pair production (Higgs-strahlung) and\n$W^+W^-\\to H$ fusion.  The restrictions string selects the Higgs-strahlung\ngraph where the initial electrons combine to a $Z$ boson.  Here, the particles\nin the process are consecutively numbered, starting with the initial\nparticles.  An alternative for the same selection would be\n\\verb|$restrictions = \"3+4 ~ Z\"|.  Restrictions can be combined using\n\\verb|&&|, for instance\n\\begin{code}\n  $restrictions = \"1+2 ~ Z && 3 + 4 ~ Z\"\n\\end{code}\nwhich is redundant here, however.\n\nThe restriction keeps the full energy dependence in the intermediate\npropagator, so the Breit-Wigner shape can be observed in distributions.  This\nbreaks gauge invariance, in particular if the intermediate state is off shell,\nso you should use the feature only if you know the implications. For\nmore details, cf. the Chap.~\\ref{chap:hardint} and the \\oMega\\ manual.\n\nOther restrictions that can be combined with the restrictions above on\nintermediate propagators allow to exclude certain particles from\nintermediate propagators, or to exclude certain vertices from the\nmatrix elements. For example,\n\\begin{code}\n  process eemm = e1, E1 => e2, E2  { $restrictions = \"!A\" }\n\\end{code}\nwould exclude all photon propagators from the matrix element and\nleaves only the $Z$ exchange here. In the same way,\n\\verb|$restrictions = \"!gl\"| would exclude all gluon exchange. This\nexclusion of internal propagators works also for lists of particles,\nlike\n\\begin{code}\n  $restrictions = \"!Z:H\"\n\\end{code}\nexcludes all $Z$ and $H$ propagators from the matrix elements.\n\nBesides excluding certain particles as internal lines, it is also\npossible to exclude certain vertices using the restriction command\n\\begin{code}\n  process eeww = e1, E1 => Wp, Wm  { $restrictions = \"^[W+,W-,Z]\" }\n\\end{code}\nThis would generate the matrix element for the production of two $W$\nbosons at LEP without the non-Abelian vertex $W^+W^-Z$. Again, these\nrestrictions are able to work on lists, so\n\\begin{code}\n  $restrictions = \"^[W+,W-,A:Z]\"\n\\end{code}\nwould exclude all triple gauge boson vertices from the above process\nand leave only the $t$-channel neutrino exchange.\n\nIt is also possible to exlude vertices by their coupling constants,\ne.g. the photon exchange in the process $e^+ e^- \\to \\mu^+ \\mu^-$ can\nalso be removed by the following restriction:\n\\begin{code}\n  $restrictions = \"^qlep\"\n\\end{code}\nHere, \\ttt{qlep} is the \\fortran\\ variable for the coupling constant\nof the electron-positron-photon vertex.\n\n\\begin{table}\n  \\begin{center}\n    \\begin{tabular}{|l|l|}\n      \\hline\n      \\verb|3+4~Z| & external particles 3 and 4 must come from\n      intermediate $Z$ \\\\\\hline\n      \\verb| && |   & logical ``and'', e.g. in\n      \\verb| 3+5~t && 4+6~tbar| \\\\\\hline\n      \\verb| !A | & exclude all $\\gamma$ propagators \\\\\\hline\n      \\verb| !e+:nue | & exclude a list of propagators, here $\\gamma$,\n      $\\nu_e$ \\\\\\hline\n      \\verb|^qlep:gnclep| & exclude all vertices with\n      \\ttt{qlep},\\ttt{gnclep} coupling constants \\\\\\hline\n      \\verb|^[A:Z,W+,W-]| & exclude all vertices $W^+W^-Z$,\n      $W^+W^-\\gamma$ \\\\\\hline\n      \\verb|^c1:c2:c3[H,H,H]| & exclude all triple Higgs couplings\n      with $c_i$ constants\n      \\\\\\hline\n    \\end{tabular}\n  \\end{center}\n  \\caption{List of possible restrictions that can be applied to\n    \\oMega\\ matrix elements.}\n  \\label{tab:restrictions}\n\\end{table}\nThe Tab.~\\ref{tab:restrictions} gives a list of options that can be\napplied to the \\oMega\\ matrix elements.\n\n\n\\subsubsection{Other options}\n\nThere are some further options that the \\oMega\\ matrix-element generator can\ntake.  If desired, any string of options that is contained in this variable\n\\begin{quote}\n\\begin{footnotesize}\n  \\verb|$omega_flags =| \\ttt{\\textit{string}}\n\\end{footnotesize}\n\\end{quote}\nwill be copied verbatim to the \\oMega\\ call, after all other options.\n\nOne important application is the scheme of treating the width of unstable\nparticles in the $t$-channel.  This is modified by the \\verb|model:| class of\n\\oMega\\ options.\n\nIt is well known that for some processes, e.g., single $W$ production from\nphoton-$W$ fusion, gauge invariance puts constraints on the treatment of the\nunstable-particle width.  By default, \\oMega\\ puts a nonzero width in the $s$\nchannel only.  This correctly represents the resummed Dyson series for the\npropagator, but it violates QED gauge invariance, although the effect is only\nvisible if the cuts permit the photon to be almost on-shell.\n\nAn alternative is\n\\begin{quote}\n\\begin{footnotesize}\n  \\verb|$omega_flags = \"-model:fudged_width\"|\n\\end{footnotesize},\n\\end{quote}\nwhich puts zero width in the matrix element, so that gauge cancellations\nhold, and reinstates the $s$-channel width in the appropriate places by an\noverall factor that multiplies the whole matrix element.\nNote that the fudged width option only applies to charged unstable particles, such as the $W$ boson or top quark.\nAnother possibility is\n\\begin{quote}\n\\begin{footnotesize}\n  \\verb|$omega_flags = \"-model:constant_width\"|\n\\end{footnotesize},\n\\end{quote}\nwhich puts the width both in the $s$- and in the $t$-channel like diagrams.\nA third option is provided by the running width scheme\n\\begin{quote}\n  \\begin{footnotesize}\n   \\verb|$omega_flags = \"-model:running_width\"|\n  \\end{footnotesize},\n\\end{quote}\nwhich applies the width only for $s$-channel like diagrams and multiplies it by a factor of $p^2 / M^2$.\nThe additional $p^2$-dependent factor mimicks the momentum dependence of the imaginary part of a vacuum polarization for a particle decaying into massles decay products.\nIt is noted that none of the above options preserves gauge invariance.\n\nFor a gauge preserving approach (at least at tree level), \\oMega\\ provides the complex-mass scheme\n\\begin{quote}\n  \\begin{footnotesize}\n    \\verb|$omega_flags = \"-model:cms_width|\n  \\end{footnotesize}.\n\\end{quote}\nHowever, in this case, one also has to modify the model in usage.\nFor example, the parameter setting for the Standard Model can be changed by,\n\\begin{quote}\n  \\begin{footnotesize}\n    \\verb|model = SM (Complex_Mass_Scheme)|\n  \\end{footnotesize}.\n\\end{quote}\n\n\\subsubsection{Multithreaded calculation of helicity sums via OpenMP}\n\\label{sec:openmp}\n\nOn multicore and / or multiprocessor systems, it is possible to speed\nup the calculation by using multiple threads to perform the helicity\nsum in the matrix element calculation. As the processing time used by\n\\whizard\\ is not used up solely in the matrix element, the speedup thus\nachieved varies greatly depending on the process under consideration;\nwhile simple processes without flavor sums do not profit significantly\nfrom this parallelization, the computation time for processes\ninvolving flavor sums with four or more particles in the final state\nis typically reduced by a factor between two and three when utilizing\nfour parallel threads.\n\nThe parallization is implemented using \\ttt{OpenMP} and requires\n\\whizard\\ to be compiled with an \\ttt{OpenMP} aware compiler and the\nappropiate compiler flags This is done in the configuration step, cf.\\\nSec.~\\ref{sec:installation}.\n\nAs with all \\ttt{OpenMP} programs, the default number of threads used at\nruntime is up to the compiler runtime support and typically set to the\nnumber of independent hardware threads (cores / processors /\nhyperthreads) available in the system.  This default can be adjusted\nby setting the \\ttt{OMP\\_NUM\\_THREADS} environment variable prior to\ncalling WHIZARD.  Alternatively, the available number of threads can\nbe reset anytime by the \\sindarin\\ parameter\n\\ttt{openmp\\_num\\_threads}.  Note however that the total number of\nthreads that can be sensibly used is limited by the number of\nnonvanishing helicity combinations.\n\n%%%%%%%%%%%%%%%\n\n\\subsection{Process components}\n\\label{sec:processcomp}\n\nIt was mentioned above that processes with flavor sums (in the initial\nor final state or both) have to be mass-degenerate (in most cases\nmassless) in all particles that are summed over at a certain\nposition. This condition is necessary in order to use the same\nphase-space parameterization and integration for the flavor-summed\nprocess. However, in many applications the user wants to handle\ninclusive process definitions, e.g. by defining inclusive decays,\ninclusive SUSY samples at hadron colliders (gluino pairs, squark\npairs, gluino-squark associated production), or maybe lepton-inclusive\nsamples where the tau and muon mass should be kept at different\nvalues. In \\whizard\\, from version v2.2.0 on, there is the possibility\nto define such inclusive process containers. The infrastructure for\nthis feature is realized via so-called process components: processes\nare allowed to contain several process components. Those components\nneed not be provided by the same matrix element generator,\ne.g. internal matrix elements, \\oMega\\ matrix elements, external\nmatrix element (e.g. from a one-loop program, OLP) can be mixed. The\nvery same infrastructure can also be used for next-to-leading order\n(NLO) calculations, containing the born with real emission, possible\nsubtraction terms to make the several components infrared- and\ncollinear finite, as well as the virtual corrections.\n\nHere, we want to discuss the use for inclusive particle samples. There\nare several options, the simplest of which to add up different final\nstates by just using the \\ttt{+} operator in \\sindarin, e.g.:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n   process multi_comp = e1, E1 => (e2, E2) + (e3, E3) + (A, A)\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nThe brackets are not only used for a better grouping of the expressions,\nthey are not mandatory for \\whizard\\ to interpret the sum\ncorrectly. When integrating, \\whizard\\ tells you that this a process\nwith three different components:\n\\begin{footnotesize}\n\\begin{Verbatim}\n| Initializing integration for process multi_comp_1_p1:\n| ------------------------------------------------------------------------\n| Process [scattering]: 'multi_comp'\n|   Library name  = 'default_lib'\n|   Process index = 1\n|   Process components:\n|     1: 'multi_comp_i1':   e-, e+ => m-, m+ [omega]\n|     2: 'multi_comp_i2':   e-, e+ => t-, t+ [omega]\n|     3: 'multi_comp_i3':   e-, e+ => A, A [omega]\n| ------------------------------------------------------------------------\n\\end{Verbatim}\n\\end{footnotesize}\nA different phase-space setup is used for each different\ncomponent. The integration for each different component is performed\nseparately, and displayed on screen. At the end, a sum of all\ncomponents is shown. All files that depend on the components are being\nattached an \\ttt{\\_i{\\em <n>}} where \\ttt{{\\em <n>}} is the number of\nthe process component that appears in the list above: the \\fortran\\\ncode for the matrix element, the \\ttt{.phs} file for the phase space\nparameterization, and the grid files for the \\vamp\\ Monte-Carlo\nintegration (or any other integration method). However, there will be\nonly one event file for the inclusive process, into which a mixture of\nevents according to the size of the individual process component cross\nsection enter.\n\nMore options are to specify additive lists of particles. \\whizard\\\nthen expands the final states according to tensor product algebra:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n   process multi_tensor = e1, E1 => e2 + e3 + A, E2 + E3 + A\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nThis gives the same three process components as above, but \\whizard\\\nrecognized that e.g. $e^- e^+ \\to \\mu^- \\gamma$ is a vanishing\nprocess, hence the numbering is different:\n\\begin{footnotesize}\n\\begin{Verbatim}\n| Process component 'multi_tensor_i2': matrix element vanishes\n| Process component 'multi_tensor_i3': matrix element vanishes\n| Process component 'multi_tensor_i4': matrix element vanishes\n| Process component 'multi_tensor_i6': matrix element vanishes\n| Process component 'multi_tensor_i7': matrix element vanishes\n| Process component 'multi_tensor_i8': matrix element vanishes\n| ------------------------------------------------------------------------\n| Process [scattering]: 'multi_tensor'\n|   Library name  = 'default_lib'\n|   Process index = 1\n|   Process components:\n|     1: 'multi_tensor_i1':   e-, e+ => m-, m+ [omega]\n|     5: 'multi_tensor_i5':   e-, e+ => t-, t+ [omega]\n|     9: 'multi_tensor_i9':   e-, e+ => A, A [omega]\n| ------------------------------------------------------------------------\n\\end{Verbatim}\n\\end{footnotesize}\nIdentical copies of the same process that would be created by\nexpanding the tensor product of final states are eliminated and appear\nonly once in the final sum of process components.\n\nNaturally, inclusive process definitions are also available for\ndecays:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{Verbatim}\nprocess multi_dec = Wp => E2 + E3, n2 + n3\n\\end{Verbatim}\n\\end{footnotesize}\n\\end{quote}\nThis yields:\n\\begin{footnotesize}\n\\begin{Verbatim}\n| Process component 'multi_dec_i2': matrix element vanishes\n| Process component 'multi_dec_i3': matrix element vanishes\n| ------------------------------------------------------------------------\n| Process [decay]: 'multi_dec'\n|   Library name  = 'default_lib'\n|   Process index = 2\n|   Process components:\n|     1: 'multi_dec_i1':   W+ => mu+, numu [omega]\n|     4: 'multi_dec_i4':   W+ => tau+, nutau [omega]\n| ------------------------------------------------------------------------\n\\end{Verbatim}\n\\end{footnotesize}\n\n\n%%%%%%%%%%%%%%%\n\n\\subsection{Compilation}\n\\label{sec:compilation}\n\nOnce processes have been set up, to make them available for integration they\nhave to be compiled.  More precisely, the matrix-element generator\n\\oMega\\ (and it works similarly if a different matrix element method\nis chosen) is called to generate matrix element code, the compiler is\ncalled to transform this \\fortran\\ code into object files, and the\nlinker is called to collect this in a dynamically loadable library.\nFinally, this library is linked to the program. From version v2.2.0 of\n\\whizard\\ this is no longer done by system calls of the OS but steered\nvia process library Makefiles. Hence, the user can execute and\nmanipulate those Makefiles in order to manually intervene in the\nparticular steps, if he/she wants to do so.\n\nAll this is done automatically when an \\ttt{integrate}, \\ttt{unstable}, or\n\\ttt{simulate} command is encountered for the first time.  You may also force\ncompilation explicitly by the command\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  compile\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nwhich performs all steps as listed above, including loading the generated\nlibrary.\n\nThe \\fortran\\ part of the compilation will be done using the \\fortran\\ compiler\nspecified by the string variable\n\\verb|$fc| and the compiler flags specified as \\verb|$fcflags|.  The default\nsettings are those that have been used for compiling \\whizard\\ itself during\ninstallation.  For library compatibility, you should stick to the compiler.\nThe flags may be set differently.  They are applied in the compilation and\nloading steps, and they are processed by \\ttt{libtool}, so\n\\ttt{libtool}-specific flags can also be given.\n\n\\whizard\\ has some precautions against unnecessary repetitions.  Hence, when a\n\\ttt{compile} command is executed (explicitly, or implicitly by the first\nintegration), the program checks first whether the library is already loaded,\nand whether source code already exists for the requested processes.  If yes,\nthis code is used and no calls to \\oMega\\ (or another matrix element\nmethod) or to the compiler are issued.\nOtherwise, it will detect any modification to the process configuration and\nregenerate the matrix element or recompile accordingly.  Thus, a \\sindarin\\\nscript can be executed repeatedly without rebuilding everything from scratch,\nand you can safely add more processes to a script in a subsequent run without\nhaving to worry about the processes that have already been treated.\n\nThis default behavior can be changed.  By setting\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  ?rebuild_library = true\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\ncode will be re-generated and re-compiled even if \\whizard\\ would think that\nthis is unncessary.  The same effect is achieved by calling \\whizard\\ with a\ncommand-line switch,\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  /home/user$ whizard --rebuild_library\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nThere are further \\ttt{rebuild} switches which are described below.  If\neverything is to be rebuilt, you can set a master switch \\ttt{?rebuild} or the\ncommand line option \\verb|--rebuild|.  The latter can be abbreviated as a short\ncommand-line option:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  /home/user$ whizard -r\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nSetting this switch is always a good idea when starting a new project, just in\ncase some old files clutter the working directory.  When re-running the same\nscript, possibly modified, the \\verb|-r| switch should be omitted, so the\nexisting files can be reused.\n\n\n\n\\subsection{Process libraries}\n\nProcesses are collected in \\emph{libraries}.  A script may use more than one\nlibrary, although for most applications a single library will probably be\nsufficient.\n\nThe default library is \\ttt{default\\_lib}.  If you do not specify anything else,\nthe processes you compile will be collected by a driver file\n\\ttt{default\\_lib.f90} which is compiled together with the process code and\ncombined as a libtool archive \\ttt{default\\_lib.la}, which is dynamically linked\nto the running \\whizard\\ process.\n\nOnce in a while, you work on several projects at once, and you didn't care\nabout opening a new working directory for each.  If the \\verb|-r| option is\ngiven, a new run will erase the existing library, which may contain processes\nneeded for the other project.  You could omit \\verb|-r|, so all processes will\nbe collected in the same library (this does not hurt), but you may wish to\ncleanly separate the projects.  In that case, you should open a separate\nlibrary for each project.\n\nAgain, there are two possibilities.  You may start the script with the\nspecification\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  library = \"my_lhc_proc\"\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nto open a library \\verb|my_lhc_proc| in place of the default library.\nRepeating the command with different arguments, you may introduce several\nlibraries in the script.  The active library is always the one specified\nlast.  It is possible to issue this command locally, so a particular process\ngoes into its own library.\n\nAlternatively, you may call \\whizard\\ with the option\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  /home/user$ whizard --library=my_lhc_proc\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\n\nIf several libraries are open simultaneously, the \\ttt{compile} command will\ncompile all libraries that the script has referenced so far.  If this is not\nintended, you may give the command an argument,\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  compile (\"my_lhc_proc\", \"my_other_proc\")\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nto compile only a specific subset.\n\nThe command\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  show (library)\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nwill display the contents of the actually loaded library together with\na status code which indicates the status of the library and the processes within.\n\n%%%%%%%%%%%%%%%\n\n\\subsection{Stand-alone \\whizard\\ with precompiled processes}\n\\label{sec:static}\n\nOnce you have set up a process library, it is straightforward to make a\nspecial stand-alone \\whizard\\ executable which will have this library\npreloaded on startup.  This is a matter of convenience, and it is also useful\nif you need a statically linked executable for reasons of profiling,\nbatch processing, etc.\n\nFor this task, there is a variant of the \\ttt{compile} command:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  compile as \"my_whizard\" ()\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nwhich produces an executable \\verb|my_whizard|.  You can omit the library\nargument if you simply want to include everything.  (Note that this command\nwill \\emph{not} load a library into the current process, it is intended for\ncreating a separate program that will be started independently.)\n\nAs an example, the script\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  process proc1 = e1, E1 => e1, E1\n  process proc2 = e1, E1 => e2, E2\n  process proc3 = e1, E1 => e3, E3\n  compile as \"whizard-leptons\" ()\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nwill make a new executable program \\verb|whizard-leptons|.  This\nprogram behaves completely identical to vanilla \\whizard, except for the fact\nthat the processes \\ttt{proc1}, \\ttt{proc2}, and \\ttt{proc3} are available\nwithout configuring them or loading any library.\n\n% This feature is particularly useful when compiling with the \\ttt{-static}\n% flag.  As long as the architecture is compatible, the resulting binary may be\n% run on a different computer where no \\whizard\\ libraries are present.  (The\n% program will still need to find its model files, however.)\n\n\n\n\\section{Beams}\n\\label{sec:beams}\n\nBefore processes can be integrated and simulated, the program has to know\nabout the collider properties.  They can be specified by the \\ttt{beams}\nstatement.\n\nIn the command script, it is irrelevant whether a \\ttt{beams} statement comes\nbefore or after process specification.  The \\ttt{integrate} or \\ttt{simulate}\ncommands will use the \\ttt{beams} statement that was issued last.\n\n\n\\subsection{Beam setup}\n\\label{sec:beam-setup}\n\nIf the beams have no special properties, and the colliding particles are the\nincoming particles in the process themselves, there is no need for a\n\\ttt{beams} statement at all.  You only \\emph{must} specify the\ncenter-of-momentum energy of the collider by setting the value of $\\sqrt{s}$,\nfor instance\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  sqrts = 14 TeV\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nThe \\ttt{beams} statement comes into play if\n\\begin{itemize}\n\\item\n  the beams have nontrivial structure, e.g., parton structure in hadron\n  collision or photon radiation in lepton collision, or\n\\item\n  the beams have non-standard properties: polarization, asymmetry, crossing\n  angle.\n\\end{itemize}\nNote that some of the abovementioned beam properties had not yet been\nreimplemented in the \\whizard\\ttt{2} release series. From version\nv2.2.0 on all options of the legacy series \\whizard\\ttt{1} are\navailable again. From version v2.1 to version v2.2 of \\whizard\\ there\nhas also been a change in possible options to the \\ttt{beams}\nstatement: in the early versions of \\whizard\\ttt{2} (v2.0/v2.1), local\noptions could be specified within the beam settings, e.g. \\ttt{beams =\np, p { sqrts = 14 TeV } => pdf\\_builtin}. These possibility has been\nabandoned from version v2.2 on, and the \\ttt{beams} command does not\nallow for {\\em any} optional arguments any more.\n\nHence, beam parameters can -- with the exception of the specification\nof structure functions -- be specified only globally:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  sqrts = 14 TeV\n  beams = p, p => lhapdf\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nIt does not make any difference whether the value of \\ttt{sqrts} is\nset before or after the \\ttt{beams} statement, the last value found\nbefore an \\ttt{integrate} or \\ttt{simulate} is the relevant one. This\nin particularly allows to specify the beam structure, and then after\nthat perform a loop or scan over beam energies, beam parameters, or\nstructure function settings.\n\nThe \\ttt{beams} statement also applies to particle decay processes, where there\nis only a single beam.  Here, it is usually redundant because no structure\nfunctions are possible, and the energy is fixed to the decaying particle's\nmass.  However, it is needed for computing polarized decay, e.g.\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  beams = Z\n  beams_pol_density = @(0)\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nwhere for a boson at rest, the polarization axis is defined to be the $z$\naxis.\n\nBeam polarization is described in detail below in Sec.~\\ref{sec:polarization}.\n\nNote also that future versions of \\whizard\\ might give support for\nsingle-beam events, where structure functions for single particles\nindeed do make sense.\n\nIn the following sections we list the available options for structure\nfunctions or spectra inside \\whizard\\ and explain their usage. More\nabout the physics of the implemented structure functions can be found\nin Chap.~\\ref{chap:hardint}.\n\n%%%%%%%%%%%%%%%\n\n\\subsection{Asymmetric beams and Crossing angles}\n\\label{sec:asymmetricbeams}\n\n\\whizard\\ not only allows symmetric beam collisions, but basically\narbitrary collider setups. In the case there are two different beam\nenergies, the command\n\\begin{quote}\n\\begin{footnotesize}\n  \\ttt{beams\\_momentum = {\\em <beam\\_mom1>}, {\\em <beam\\_mom2>}}\n\\end{footnotesize}\n\\end{quote}\nallows to specify the momentum (or as well energies for massless\nparticles) for the beams. Note that for scattering processes both\nvalues for the beams must be present. So the following to setups for\n14 TeV LHC proton-proton collisions are equivalent:\n\\begin{quote}\n\\begin{footnotesize}\n  \\ttt{beams = p, p => pdf\\_builtin} \\newline\n  \\ttt{sqrts = 14 TeV}\n\\end{footnotesize}\n\\end{quote}\nand\n\\begin{quote}\n\\begin{footnotesize}\n  \\ttt{beams = p, p => pdf\\_builtin} \\newline\n  \\ttt{beams\\_momentum = 7 TeV, 7 TeV}\n\\end{footnotesize}\n\\end{quote}\nAsymmetric setups can be set by using different values for the two\nbeam momenta, e.g. in a HERA setup:\n\\begin{quote}\n\\begin{footnotesize}\n  \\ttt{beams = e, p => none, pdf\\_builtin}\n  \\ttt{beams\\_momentum = 27.5 GeV, 920 GeV}\n\\end{footnotesize}\n\\end{quote}\nor for the BELLE experiment at the KEKB accelerator:\n\\begin{quote}\n\\begin{footnotesize}\n  \\ttt{beams = e1, E1}\n  \\ttt{beams\\_momentum = 8 GeV, 3.5 GeV}\n\\end{footnotesize}\n\\end{quote}\n\\whizard\\ lets you know about the beam structure and calculates for\nyou that the center of mass energy corresponds to 10.58 GeV:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{Verbatim}\n| Beam structure: e-, e+\n|   momentum = 8.000000000000E+00, 3.500000000000E+00\n| Beam data (collision):\n|   e-  (mass = 5.1099700E-04 GeV)\n|   e+  (mass = 5.1099700E-04 GeV)\n|   sqrts = 1.058300530253E+01 GeV\n| Beam structure: lab and c.m. frame differ\n\\end{Verbatim}\n\\end{footnotesize}\n\\end{quote}\n\nIt is also possible to specify beams for decaying particles, where\n\\ttt{beams\\_momentum} then only has a single argument, e.g.:\n\\begin{quote}\n\\begin{footnotesize}\n  \\ttt{process zee = Z => \"e-\", \"e+\"} \\\\\n  \\ttt{beams = Z} \\\\\n  \\ttt{beams\\_momentum = 500 GeV} \\\\\n  \\ttt{simulate (zee) \\{ n\\_events = 100 \\} }\n\\end{footnotesize}\n\\end{quote}\nThis would correspond to a beam of $Z$ bosons with a momentum of 500\nGeV. Note, however, that \\whizard\\ will always do the integration of\nthe particle width in the particle's rest frame, while the moving beam\nis then only taken into account for the frame of reference for the\nsimulation.\n\nFurther options then simply having different beam energies describe a\nnon-vanishing between the two incoming beams. Such concepts are quite\ncommon e.g. for linear colliders to improve the beam properties in the\ncollimation region at the beam interaction points. Such crossing\nangles can be specified in the beam setup, too, using the\n\\ttt{beams\\_theta} command:\n\\begin{quote}\n\\begin{footnotesize}\n  \\ttt{beams = e1, E1} \\\\\n  \\ttt{beams\\_momentum = 500 GeV, 500 GeV} \\\\\n  \\ttt{beams\\_theta = 0, 10 degree}\n\\end{footnotesize}\n\\end{quote}\nIt is important that when a crossing angle is being specified, and the\ncollision system consequently never is the center-of-momentum system,\nthe beam momenta have to explicitly set. Besides a planar crossing\nangle, one is even able to rotate an azimuthal distance:\n\\begin{quote}\n\\begin{footnotesize}\n  \\ttt{beams = e1, E1} \\\\\n  \\ttt{beams\\_momentum = 500 GeV, 500 GeV} \\\\\n  \\ttt{beams\\_theta = 0, 10 degree} \\\\\n  \\ttt{beams\\_phi = 0, 45 degree}\n\\end{footnotesize}\n\\end{quote}\n\n%%%%%%%%%%%%%%%\n\n\\subsection{LHAPDF}\n\\label{sec:lhapdf}\n\nFor incoming hadron beams, the \\ttt{beams} statement specifies which structure\nfunctions are used.  The simplest example is the study of parton-parton\nscattering processes at a hadron-hadron collider such as LHC or Tevatron.  The\n\\lhapdf\\ structure function set is selected by a syntax similar to the\nprocess setup, namely the example already shown above:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  beams = p, p => lhapdf\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nNote that there are slight differences in using the \\lhapdf\\ release\nseries 6 and the older \\fortran\\ \\lhapdf\\ release series 5, at least\nconcerning the naming conventions for the PDF sets~\\footnote{Until\n  \\whizard\\ version 2.2.1 including, only the \\lhapdf\\ series 5 was\n  supported, while from version 2.2.2 on also the \\lhapdf\\ release\n  series 6 has been supported.}. The above \\ttt{beams}\nstatement selects a default \\lhapdf\\ structure-function set for both\nproton beams (which is the \\ttt{CT10} central set for \\lhapdf\\ 6, and\n\\ttt{cteq6ll.LHpdf} central set for \\lhapdf 5).  The structure\nfunction will apply for all quarks, antiquarks, and the gluon as far\nas supported by the particular \\lhapdf\\ set.  Choosing a different set\nis done by adding the  filename as a local option to the \\ttt{lhapdf}\nkeyword:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  beams = p, p => lhapdf\n  $lhapdf_file = \"MSTW2008lo68cl\"\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nfor the actual \\lhapdf\\ 6 series, and\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  beams = p, p => lhapdf\n  $lhapdf_file = \"MSTW2008lo68cl.LHgrid\"\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nfor \\lhapdf 5.Similarly, a member within the set is selected by the\nnumeric variable \\verb|lhapdf_member| (for both release series of \\lhapdf).\n\nIn some cases, different structure functions have to be chosen for the two\nbeams.  For instance, we may look at $ep$ collisions:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  beams = \"e-\", p => none, lhapdf\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nHere, there is a list of two independent structure functions (each with its\nown option set, if applicable) which applies to the two beams.\n\nAnother mixed case is $p\\gamma$ collisions, where the photon is to be\nresolved as a hadron.  The simple assignment\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  beams = p, gamma => lhapdf, lhapdf_photon\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nwill be understood as follows: \\whizard\\ selects the appropriate default\nstructure functions (here we are using \\lhapdf\\ 5 as an example as the\nsupport of photon and pion PDFs in \\lhapdf\\ 6 has been dropped),\n\\ttt{cteq6ll.LHpdf} for the proton and\n\\ttt{GSG960.LHgrid} for the photon.  The photon case has an additional\ninteger-valued parameter \\verb|lhapdf_photon_scheme|.  (There are also pion\nstructure functions available.)  For modifying the default, you have to\nspecify separate structure functions\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  beams = p, gamma => lhapdf, lhapdf_photon\n  $lhapdf_file = ...\n  $lhapdf_photon_file = ...\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nFinally, the scattering of elementary photons on partons is described by\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  beams = p, gamma => lhapdf, none\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\n\nNote that for \\lhapdf\\ version 5.7.1 or higher and for PDF sets which\nsupport it, photons can be used as partons.\n\nThere is one more option for the \\lhapdf\\ PDFs, namely to specify the\npath where the \\lhapdf\\ PDF sets reside: this is done with the string\nvariable \\ttt{\\$lhapdf\\_dir = \"{\\em <path-to-lhapdf>}\"}. Usually, it\nis not necessary to set this because \\whizard\\ detects this path via\nthe \\ttt{lhapdf-config} script during configuration, but in the case\npaths have been moved, or special files/special locations are to be\nused, the user can specify this location explicitly.\n\n%%%%%%%%%%%%%%%\n\n\\subsection{Built-in PDFs}\n\\label{sec:built-in-pdf}\n\nIn addition to the possibility of linking against \\lhapdf, \\whizard\\\ncomes with a couple of built-in PDFs which are selected via the\n\\verb?pdf_builtin? keyword\n%\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  beams = p, p => pdf_builtin\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\n%\n\nThe default PDF set is CTEQ6L, but other choices are also available by\nsetting the string variable \\verb?$pdf_builtin_set? to an\nappropiate value. E.g, modifying the above\nsetup to\n%\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  beams = p, p => pdf_builtin\n  $pdf_builtin_set = \"mrst2004qedp\"\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\n%\nwould select the proton PDF from the MRST2004QED set. A list of all currently\navailable PDFs can be found in Table~\\ref{tab:pdfs}.\n%\n\\begin{table}\n\\centerline{\\begin{tabular}{|l||l|p{0.2\\textwidth}|l|}\n\\hline\nTag & Name & Notes & References \\\\\\hline\\hline\n%\n\\ttt{cteq6l} & CTEQ6L & \\mbox{}\\hfill---\\hfill\\mbox{} &\n   \\cite{Pumplin:2002vw} \\\\\\hline\n\\ttt{cteq6l1} & CTEQ6L1 & \\mbox{}\\hfill---\\hfill\\mbox{} &\n   \\cite{Pumplin:2002vw} \\\\\\hline\n\\ttt{cteq6d} & CTEQ6D & \\mbox{}\\hfill---\\hfill\\mbox{} &\n   \\cite{Pumplin:2002vw} \\\\\\hline\n\\ttt{cteq6m} & CTEQ6M & \\mbox{}\\hfill---\\hfill\\mbox{} &\n   \\cite{Pumplin:2002vw} \\\\\\hline\n\\hline\n\\ttt{mrst2004qedp} & MRST2004QED (proton) & includes photon &\n   \\cite{Martin:2004dh} \\\\\\hline\n\\hline\n\\ttt{mrst2004qedn} & MRST2004QED (neutron) & includes photon &\n   \\cite{Martin:2004dh} \\\\\\hline\n\\hline\n\\ttt{mstw2008lo} & MSTW2008LO & \\mbox{}\\hfill---\\hfill\\mbox{} &\n   \\cite{Martin:2009iq} \\\\\\hline\n\\ttt{mstw2008nlo} & MSTW2008NLO & \\mbox{}\\hfill---\\hfill\\mbox{} &\n   \\cite{Martin:2009iq} \\\\\\hline\n\\ttt{mstw2008nnlo} & MSTW2008NNLO & \\mbox{}\\hfill---\\hfill\\mbox{} &\n   \\cite{Martin:2009iq} \\\\\\hline\n\\hline\n\\ttt{ct10} & CT10 & \\mbox{}\\hfill---\\hfill\\mbox{} &\n   \\cite{Lai:2010vv} \\\\\\hline\n\\hline\n\\ttt{CJ12\\_max} & CJ12\\_max & \\mbox{}\\hfill---\\hfill\\mbox{} &\n   \\cite{Owens:2012bv} \\\\\\hline\n\\ttt{CJ12\\_mid} & CJ12\\_mid & \\mbox{}\\hfill---\\hfill\\mbox{} &\n   \\cite{Owens:2012bv} \\\\\\hline\n\\ttt{CJ12\\_min} & CJ12\\_min & \\mbox{}\\hfill---\\hfill\\mbox{} &\n   \\cite{Owens:2012bv} \\\\\\hline\n\\hline\n\\ttt{CJ15LO} & CJ15LO & \\mbox{}\\hfill---\\hfill\\mbox{} &\n   \\cite{Accardi:2016qay} \\\\\\hline\n\\ttt{CJ15NLO} & CJ15NLO & \\mbox{}\\hfill---\\hfill\\mbox{} &\n   \\cite{Accardi:2016qay} \\\\\\hline\n\\hline\n\\ttt{mmht2014lo} & MMHT2014LO & \\mbox{}\\hfill---\\hfill\\mbox{} &\n   \\cite{Harland-Lang:2014zoa} \\\\\\hline\n\\ttt{mmht2014nlo} & MMHT2014NLO & \\mbox{}\\hfill---\\hfill\\mbox{} &\n   \\cite{Harland-Lang:2014zoa} \\\\\\hline\n\\ttt{mmht2014nnlo} & MMHT2014NNLO & \\mbox{}\\hfill---\\hfill\\mbox{} &\n   \\cite{Harland-Lang:2014zoa} \\\\\\hline\n\\hline\n\\ttt{CT14LL} & CT14LLO & \\mbox{}\\hfill---\\hfill\\mbox{} &\n   \\cite{Dulat:2015mca} \\\\\\hline\n\\ttt{CT14L} & CT14LO & \\mbox{}\\hfill---\\hfill\\mbox{} &\n   \\cite{Dulat:2015mca} \\\\\\hline\n\\ttt{CT14N} & CT1414NLO & \\mbox{}\\hfill---\\hfill\\mbox{} &\n   \\cite{Dulat:2015mca} \\\\\\hline\n\\ttt{CT14NN} & CT14NNLO & \\mbox{}\\hfill---\\hfill\\mbox{} &\n   \\cite{Dulat:2015mca} \\\\\\hline\n\\hline\n%\n\\end{tabular}}\n\\caption{All PDF sets available as builtin sets. The two MRST2004QED\n  sets also contain a photon.}\n\\label{tab:pdfs}\n\\end{table}\n\nThe two MRST2004QED sets also contain the photon as a parton, which\ncan be used in the same way as for \\lhapdf\\ from v5.7.1 on. Note,\nhowever, that there is no builtin PDF that contains a photon structure\nfunction. There is a \\ttt{beams} structure function specifier\n\\ttt{pdf\\_builtin\\_photon}, but at the moment this throws an error. It\njust has been implemented for the case that in future versions of\n\\whizard\\ a photon structure function might be included.\n\nNote that in general only the data sets for the central values of the\ndifferent PDFs ship with \\whizard. Using the error sets is possible,\ni.e. it is supported in the syntax of the code, but you have to\ndownload the corresponding data sets from the web pages of the PDF\nfitting collaborations.\n\n%%%%%%%%%%%%%%%\n\n\\subsection{HOPPET $b$ parton matching}\n\nWhen the \\hoppet\\ tool~\\cite{Salam:2008qg} for hadron-collider PDF\nstructure functions and their manipulations are\ncorrectly linked to \\whizard, it can be used for advanced\ncalculations and simulations of hadron collider physics. Its main\nusage inside \\whizard\\ is for matching schemes between 4-flavor and\n5-flavor schemes in $b$-parton initiated processes at hadron\ncolliders. Note that in versions 2.2.0 and 2.2.1 it only worked\ntogether with \\lhapdf\\ version 5, while with the \\lhapdf\\ version 6\ninterface from version 2.2.2 on it can be used also with the modern\nversion of PDFs from \\lhapdf. Furthermore, from version 2.2.2, the\n\\hoppet\\ $b$ parton matching also works for the builtin PDFs.\n\nIt depends on the corresponding process and the energy scales involved\nwhether it is a better description to use the\n$g\\to b\\bar b$ splitting from the DGLAP evolution inside the PDF and\njust take the $b$ parton content of a PDF, e.g. in BSM Higgs\nproduction for large $\\tan\\beta$: $pp \\to H$ with a partonic\nsubprocess $b\\bar b \\to H$, or directly take the gluon PDFs and use\n$pp \\to b\\bar b H$ with a partonic subprocess $gg \\to b \\bar b\nH$. Elaborate schemes for a proper matching between the two\nprescriptions have been developed and have been incorporated into the\n\\hoppet\\ interface.\n\nAnother prime example for using these matching schemes is single top\nproduction at hadron colliders. Let us consider the following setup:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{Verbatim}\nprocess proc1 = b, u => t, d\nprocess proc2 = u, b => t, d\nprocess proc3 = g, u => t, d, B\t{ $restrictions = \"2+4 ~ W+\" }\nprocess proc4 = u, g => t, d, B\t{ $restrictions = \"1+4 ~ W+\" }\n\nbeams = p,p => pdf_builtin\nsqrts = 14 TeV\n?hoppet_b_matching = true\n\n$sample = \"single_top_matched\"\nluminosity = 1 / 1 fbarn\nsimulate (proc1, proc2, proc3, proc4)\n\\end{Verbatim}\n\\end{footnotesize}%$\n\\end{quote}\nThe first two processes are single top production from $b$ PDFs, the\nlast two processes contain an explicit $g\\to b\\bar b$ splitting (the\nrestriction, cf. Sec.~\\ref{sec:process options} has been placed in\norder to single out the single top production signal process). PDFs\nare then chosen from the default builtin PDF (which is \\ttt{CTEQ6L}),\nand the \\hoppet\\ matching routines are switched on by the flag\n\\ttt{?hoppet\\_b\\_matching}.\n\n%%%%%%%%%%%%%%%\n\n\\subsection{Lepton Collider ISR structure functions}\n\\label{sec:lepton_isr}\n\nInitial state QED radiation off leptons is an important feature at all\nkinds of lepton colliders: the radiative return to the $Z$ resonance\nby ISR radiation was in fact the largest higher-order effect for the\nSLC and LEP I colliders. The soft-collinear and soft photon radiation\ncan indeed be resummed/exponentiated to all orders in perturbation\ntheory~\\cite{Gribov:1972rt}, while higher orders in hard-collinear\nphotons have to be explicitly calculated order by\norder~\\cite{Kuraev:1985hb,Skrzypek:1990qs}. \\whizard\\ has an intrinsic\nimplementation of the lepton ISR structure function that includes all\norders of soft and soft-collinear photons as well as up to the third\norder in hard-collinear photons. It can be switched on by the\nfollowing statement:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{Verbatim}\nbeams = e1, E1 => isr\n\\end{Verbatim}\n\\end{footnotesize}\n\\end{quote}\nAs the ISR structure function is a single-beam structure function,\nthis expression is synonymous for\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{Verbatim}\nbeams = e1, E1 => isr, isr\n\\end{Verbatim}\n\\end{footnotesize}\n\\end{quote}\nThe ISR structure function can again be applied to only one of the two\nbeams, e.g. in a HERA-like setup:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{Verbatim}\nbeams = e1, p => isr, pdf_builtin\n\\end{Verbatim}\n\\end{footnotesize}\n\\end{quote}\n\nTheir are several options for the lepton-collider ISR structure\nfunction that are summarized in the following:\n\n\\vspace{2mm}\n\n\\centerline{\\begin{tabular}{|l|l|l|}\\hline\nParameter & Default & Meaning \\\\\\hline\\hline\n\\ttt{isr\\_alpha} & \\ttt{0}/intrinsic & value of $\\alpha_{QED}$ for ISR\n\\\\\\hline\n\\ttt{isr\\_order} & \\ttt{3} & max. order of hard-collinear photon\nemission \\\\\\hline\n\\ttt{isr\\_mass} & \\ttt{0}/intrinsic & mass of the radiating lepton  \\\\\\hline\n\\ttt{isr\\_q\\_max} & \\ttt{0}/$\\sqrt{s}$ & upper cutoff for ISR \\\\\\hline\n\\hline\n\\ttt{?isr\\_recoil} & \\ttt{false} & flag to switch on recoil/$p_T$\n(\\emph{deprecated})\\\\\\hline\n\\ttt{?isr\\_keep\\_energy} & \\ttt{false} & recoil flag: conserve\nenergy in splitting (\\emph{deprecated})\n\\\\\\hline\n\\end{tabular}}\\mbox{}\n\nThe maximal order of the hard-collinear photon emission taken into\naccount by \\whizard\\ is set by the integer variable \\ttt{isr\\_order};\nthe default is the maximally available order of three. With the\nvariable \\ttt{isr\\_alpha}, the value of the QED coupling constant\n$\\alpha_{QED}$ used in the ISR structure function can be set. The\ndefault is taken from the active physics model. The mass of the\nradiating lepton (in most cases the electron) is set by\n\\ttt{isr\\_mass}; again the default is taken from the active physics\nmodel. Furthermore, the upper integration border for the ISR structure\nfunction which acts roughly as an upper hardness cutoff for the emitted\nphotons, can be set through \\ttt{isr\\_q\\_max}; if not set, the\ncollider energy (possibly after beamstrahlung,\ncf. Sec.~\\ref{sec:beamstrahlung}) $\\sqrt{s}$ (or $\\sqrt{\\widehat{s}}$)\nis taken.  Note that \\whizard\\ accounts for the\nexclusive effects of ISR radiation at the moment by a single (hard,\nresolved) photon in the event; a more realistic treatment of exclusive\nISR photons in simulation is foreseen for a future version.\n\nWhile the ISR structure function is evaluated in the collinear limit,\nit is possible to generate transverse momentum for both the radiated\nphotons and the recoiling partonic system.  We recommend to stick to\nthe collinear approximation for the integration step.  Integration\ncuts should be set up such that they do not significantly depend on\nphoton transverse momentum.  In a subsequent simulation step, it is\npossible to transform the events with collinear ISR radiation into\nmore realistic events with non-collinear radiation.  To this end,\n\\whizard\\ provides a separate ISR photon handler which can be\nactivated in the simulation step.  The algorithm operates on the\npartonic event: it takes the radiated photons and the partons entering\nthe hard process, and applies a $p_T$ distribution to those particles\nand their interaction products, i.e., all outgoing particles.  Cuts\nthat depend on photon $p_T$ may be applied to the modified events.\nFor details on the ISR photon handler,\ncf.\\ Sec.~\\ref{sec:isr-photon-handler}.\n\n{\\footnotesize The flag \\ttt{?isr\\_recoil} switches on $p_T$ recoil of\n  the emitting lepton against photon radiation during integration; per\n  default it is off.  The flag \\ttt{?isr\\_keep\\_energy} controls the\n  mode of on-shell projection for the splitting process with $p_T$.\n  Note that this feature is kept for backwards compatibility, but\n  should not be used for new simulations.  The reason is as follows:\n  For a fraction of events, $p_T$ will become significant, and (i)\n  energy/momentum non-conservation, applied to both beams separately,\n  can lead to unexpected and unphysical effects, and (ii) the modified\n  momenta enter the hard process, so the collinear approximation used\n  in the ISR structure function computation does not hold.  }\n\n%%%%%%%%%%%%%%%\n\n\\subsection{Lepton Collider Beamstrahlung}\n\\label{sec:beamstrahlung}\n\nAt linear lepton colliders, the macroscopic electromagnetic\ninteraction of the bunches leads to a distortion of the spectrum of\nthe bunches that is important for an exact simulation of the beam\nspectrum. There are several methods to account for these effects. The\nmost important tool to simulate classical beam-beam interactions in\nlepton-collider physics is\n\\ttt{GuineaPig++}~\\cite{Schulte:1998au,Schulte:1999tx,Schulte:2007zz}. A\ndirect interface between this tool \\ttt{GuineaPig++} and \\whizard\\ had\nexisted as an inofficial add-on to the legacy branch \\whizard\\ttt{1},\nbut is no longer applicable in \\whizard\\ttt{2}. A \\whizard-internal\ninterface is foreseen for the very near future, most probably within\nthis v2.2 release. Other options are to use parameterizations of the\nbeam spectrum that have been included in the package \\circeone~\\cite{CIRCE}\nwhich has been interfaced to \\whizard\\ since version v1.20 and been\nincluded in the \\whizard\\ttt{2} release series. Another option is to\ngenerate a beam spectrum externally and then read it in as an ASCII\ndata file, cf. Sec.~\\ref{sec:beamevents}. More about this can be found\nin a dedicated section on lepton collider spectra,\nSec.~\\ref{sec:beamspectra}.\n\nIn this section, we discuss the usage of beamstrahlung spectra by\nmeans of the \\circeone\\ package. The beamstrahlung spectra are\ntrue spectra, so they have to be applied to pairs of beams, and an\napplication to only one beam is meaningless. They are switched on by\nthis \\ttt{beams} statement including structure functions:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{Verbatim}\nbeams = e1, E1 => circe1\n\\end{Verbatim}\n\\end{footnotesize}\n\\end{quote}\nIt is important to note that the parameterization of the beamstrahlung\nspectra within \\circeone\\ contain also processes where $e\\to\\gamma$\nconversions have been taking place, i.e. also hard processes with one\n(or two) initial photons can be simulated with beamstrahlung switched\non. In that case, the explicit photon flags, \\ttt{?circe1\\_photon1}\nand \\ttt{?circe1\\_photon2}, for the two beams have to be properly set,\ne.g. (ordering in the final state does not play a role):\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{Verbatim}\nprocess proc1 = A, e1 => A, e1\nsqrts = 500 GeV\nbeams = e1, E1 => circe1\n?circe1_photon1 = true\nintegrate (proc1)\n\nprocess proc2 = e1, A => A, e1\nsqrts = 1000 GeV\nbeams = e1, A => circe1\n?circe1_photon2 = true\n\\end{Verbatim}\n\\end{footnotesize}\n\\end{quote}\nor\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{Verbatim}\nprocess proc1 = A, A => Wp, Wm\nsqrts = 200 GeV\nbeams = e1, E1 => circe1\n?circe1_photon1 = true\n?circe1_photon2 = true\n?circe1_generate = false\n\\end{Verbatim}\n\\end{footnotesize}\n\\end{quote}\nIn all cases (one or both beams with photon conversion) the beam\nspectrum applies to both beams simultaneously.\n\nIn the last example ($\\gamma\\gamma\\to W^+W^-$) the default\n\\circeone\\ generator mode was turned off by unsetting\n\\verb|?circe1_generate|.  In the other examples this flag is\nset, by default.  For standard use cases,\n\\circeone\\ implements a beam-event generator inside the\n\\whizard\\ generator, which provides beam-event samples with correctly\ndistributed probability.  For electrons, the beamstrahlung spectrum\nsharply peaks near maximum energy.  This distribution is most\nefficiently handled by the generator mode.  By contrast, in the $\\gamma\\gamma$\nmode, the beam-event c.m.\\ energy is concentrated at low values.  For\nfinal states with low invariant mass, which are typically produced by\nbeamstrahlung photons, the generator mode is appropriate.\nHowever, the $W^+W^-$ system requires substantial energy, and such\nevents will be very rare in the beam-event sample.  Switching off the\n\\circeone\\ generator mode solves this\nproblem.\n\nThis is an overview over all options and flags for the \\circeone\\\nsetup for lepton collider beamstrahlung:\n\n\\vspace{2mm}\n\n\\centerline{\\begin{tabular}{|l|l|l|}\\hline\nParameter & Default & Meaning \\\\\\hline\\hline\n\\ttt{?circe1\\_photon1} & \\ttt{false} & $e\\to\\gamma$ conversion for beam 1\n\\\\\\hline\n\\ttt{?circe1\\_photon2} & \\ttt{false} & $e\\to\\gamma$ conversion for beam 2\n\\\\\\hline\n\\ttt{circe1\\_sqrts} & $\\sqrt{s}$ & collider energy for the beam spectrum  \\\\\\hline\n\\ttt{?circe1\\_generate} & \\ttt{true} & flag for the \\circeone\\ generator mode \\\\\\hline\n\\ttt{?circe1\\_map} & \\ttt{true} & flag to apply special phase-space mapping\n\\\\\\hline\n\\ttt{circe1\\_mapping\\_slope} & \\ttt{2.} & value of PS mapping exponent\n\\\\\\hline\n\\ttt{circe1\\_eps} & \\ttt{1E-5} & parameter for mapping of spectrum peak\nposition \\\\\\hline\n\\ttt{circe1\\_ver} & \\ttt{0} & internal version of \\circeone\\ package\n\\\\\\hline\n\\ttt{circe1\\_rev} & \\ttt{0}/most recent & internal revision of\n\\circeone\\ \\\\\\hline\n\\ttt{\\$circe1\\_acc} & \\ttt{SBAND} & accelerator type \\\\\\hline\n\\ttt{circe1\\_chat} & \\ttt{0} & chattiness/verbosity of \\circeone \\\\\\hline\n\\end{tabular}}\\mbox{}\n\nThe collider energy relevant for the beamstrahlung spectrum is set by\n\\ttt{circe1\\_sqrts}. As a default, this is always the value of\n\\ttt{sqrts} set in the \\sindarin\\ script. However, sometimes these\nvalues do not match, e.g. the user wants to simulate $t\\bar t h$ at\n\\ttt{sqrts = 550 GeV}, but the only available beam spectrum is for 500\nGeV. In that case, \\ttt{circe1\\_sqrts = 500 GeV} has to be set to use\nthe closest possible available beam spectrum.\n\nAs mentioned in the discussion of the examples above, in\n\\circeone\\ there are two options to use the beam spectra for\nbeamstrahlung: intrinsic semi-analytic approximation formulae for the\nspectra, or a Monte-Carlo sampling of the sampling. The second\npossibility always give a better description of the spectra, and is\nthe default for \\whizard. It can, however, be switched off by setting\nthe flag \\ttt{?circe1\\_generate} to \\ttt{false}.\n\nAs the beamstrahlung spectra are sharply peaked at the collider\nenergy, but still having long tails, a mapping of the spectra for an\nefficient phase-space sampling is almost mandatory. This is the\ndefault in \\whizard, which can be changed by the flag\n\\ttt{?circe1\\_map}. Also, the default exponent for the mapping can be\nchanged from its default value \\ttt{2.} with the variable\n\\ttt{circe1\\_mapping\\_slope}. It is important to efficiently sample\nthe peak position of the spectrum; the effective ratio of the peak to\nthe whole sampling interval can be set by the parameter\n\\ttt{circe1\\_eps}. The integer parameter \\ttt{circe1\\_chat} sets the\nchattiness or verbosity of the \\circeone\\ package, i.e. how many\nmessages and warnings from the beamstrahlung generation/sampling will\nbe issued.\n\nThe actual internal version and revision of the \\circeone\\ package are\nset by the two integer parameters \\ttt{circe1\\_ver} and\n\\ttt{circe1\\_rev}. The default is in any case always the newest\nversion and revision, while older versions are still kept for\nbackwards compatibility and regression testing.\n\nFinally, the geometry and design of the accelerator type is set with\nthe string variable \\ttt{\\$circe1\\_acc}: it contains the possible\noptions for the old \\ttt{\"SBAND\"} and \\ttt{\"XBAND\"} setups, as well as\nthe \\ttt{\"TESLA\"} and JLC/NLC SLAC design \\ttt{\"JLCNLC\"}. The setups\nfor the most important energies of the ILC as they are summarized in\nthe ILC\nTDR~\\cite{Behnke:2013xla,Baer:2013cma,Adolphsen:2013jya,Adolphsen:2013kya}\nare available as \\ttt{ILC}. Beam spectra for the\nCLIC~\\cite{Aicheler:2012bya,Lebrun:2012hj,Linssen:2012hp} linear\ncollider are much more demanding to correctly simulate (due to the\ndrive beam concept; only the low-energy modes where the drive beam is\noff can be simulated with the same setup as the abovementioned\nmachines). Their setup will be supported soon in one of the upcoming\n\\whizard\\ versions within the \\circetwo\\ package.\n\nAn example of how to generate beamstrahlung spectra with the help of\nthe package \\circetwo\\ (that is also a part of \\whizard) is this:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{Verbatim}\nprocess eemm = e1, E1 => e2, E2\nsqrts = 500 GeV\nbeams = e1, E1 => circe2\n$circe2_file = \"ilc500.circe\"\n$circe2_design = \"ILC\"\n?circe_polarized = false\n\\end{Verbatim}\n\\end{footnotesize}%$\n\\end{quote}\nHere, the ILC design is used for a beamstrahlung spectrum at 500 GeV\nnominal energy, with polarization averaged (hence, the setting of\npolarization to \\ttt{false}). A list of all available options can be\nfound in Sec.~\\ref{sec:photoncoll}.\n\nMore technical details about the simulation of beamstrahlung spectra\nsee the documented source code of the \\circeone\\ package, as well as\nChap.~\\ref{chap:hardint}. In the next section, we discuss how to read\nin beam spectra from external files.\n\n%%%%%%%%%%%%%%%\n\n\\subsection{Beam events}\n\\label{sec:beamevents}\n\nAs mentioned in the previous section, beamstrahlung is one of the\ncrucial ingredients for a realistic simulation of linear lepton\ncolliders. One option is to take a pre-generated beam spectrum for\nsuch a machine, and make it available for simulation within \\whizard\\\nas an external ASCII data file. Such files basically contain only\npairs of energy fractions of the nominal collider energy $\\sqrt{s}$\n($x$ values). In \\whizard\\ they can be used in simulation with the\nfollowing \\ttt{beams} statement:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{Verbatim}\nbeams = e1, E1 => beam_events\n$beam_events_file = \"<beam_spectrum_file>\"\n\\end{Verbatim}\n\\end{footnotesize}%$\n\\end{quote}\nNote that beam spectra must always be pair spectra, i.e. they are\nautomatically applied to both beam simultaneously.\nBeam spectra via external files are expected to reside in the current\nworking directory. Alternatively, \\whizard\\ searches for them in the\ninstall directory of \\whizard\\ in \\ttt{share/beam-sim}. There you can\nfind an example file, \\ttt{uniform\\_spread\\_2.5\\%.dat} for such a beam\nspectrum. The only possible parameter that can be set is the flag\n\\ttt{?beam\\_events\\_warn\\_eof} whose default is \\ttt{true}. This\ntriggers the issuing of a warning when the end of file of an external\nbeam spectrum file is reached. In such a case, \\whizard\\ starts to\nreuse the same file again from the beginning. If the available data\npoints in the beam events file are not big enough, this could result\nin an insufficient sampling of the beam spectrum.\n\n%%%%%%%%%%%%%%%\n\n\\subsection{Gaussian beam-energy spread}\n\\label{sec:gaussian}\n\nReal beams have a small energy spread.  If beamstrahlung is small, the spread\nmay be approximately described as Gaussian.  As a replacement for the full\nsimulation that underlies \\ttt{CIRCE2} spectra, it is possible to\nimpose a Gaussian distributed beam energy, separately for each beam.\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{Verbatim}\nbeams = e1, E1 => gaussian\ngaussian_spread1 = 0.1\\%\ngaussian_spread2 = 0.2\\%\n\\end{Verbatim}\n\\end{footnotesize}%$\n\\end{quote}\n(Note that the \\% sign means multiplication by 0.01, as it should.)  The\nspread values are defined as the $\\sigma$ value of the Gaussian distribution,\ni.e., $2/3$ of the events are within $\\pm 1\\sigma$ for each beam,\nrespectively.\n\n%%%%%%%%%%%%%%%%\n\n\\subsection{Equivalent photon approximation}\n\\label{sec:epa}\n\nThe equivalent photon approximation (EPA) uses an on-shell approximation for\nthe $e \\to e\\gamma$ collinear splitting to allow the simulation of\nphoton-induced backgrounds in lepton collider physics. The original\nconcept is that of the Weizs\\\"acker-Williams\napproximation~\\cite{vonWeizsacker:1934sx,Williams:1934ad,Budnev:1974de}. This\nis a single-beam structure function that can be applied to both beams,\nor also to one beam only. Usually, there are some simplifications\nbeing made in the derivation. The formula which is implemented here\nand seems to be the best for the QCD background for low-$p_T$ hadrons,\ncorresponds to Eq.~(6.17) of Ref.~\\cite{Budnev:1974de}. As this\nreference already found, this leads to an \"overshooting\" of accuracy,\nand especially in the high-$x$ (high-energy) region to wrong\nresults. This formula corresponds to\n\\begin{equation}\n  \\label{eq:budnev_617}\n  f(x) = \\frac{\\alpha}{\\pi} \\frac{1}{x} \\biggl[ \\left( \\bar{x} +\n    \\frac{x^2}{2} \\right) \\log\n    \\frac{Q^2_{\\text{max}}}{Q^2_{\\text{min}}}\n    - \\left( 1 - \\frac{x}{2} \\right)^2\n    \\log \\frac{x^2 + \\tfrac{Q^2_{\\text{max}}}{E^2}}{x^2 +\n      \\tfrac{Q^2_{\\text{min}}}{E^2}}\n    - \\frac{m_e^2 x^2}{Q^2_{\\text{min}}} \\left( 1 -\n    \\frac{Q^2_{\\text{min}}}{Q^2_{\\text{max}}} \\right) \\biggr] \\qquad .\n\\end{equation}\nHere, $x$ is the ratio of the photon energy (called frequency $\\omega$\nin~\\cite{Budnev:1974de} over the original electron (or positron) beam\nenergy $E$. The energy of the electron (or positron) after the\nsplitting is given by $\\bar{x} = 1-x$.\n\nThe simplified version is the one that corresponds to many\npublications about the EPA during SLC and LEP times, and corresponds\nto the $q^2$ integration of Eq.~(6.16e) in~\\cite{Budnev:1974de}, where\n$q^2$ is the virtuality or momentum transfer of the photon in the EPA:\n\\begin{equation}\n  \\label{eq:budnev_616e}\n  f(x) = \\frac{\\alpha}{\\pi} \\frac{1}{x} \\biggl[ \\left( \\bar{x} +\n    \\frac{x^2}{2} \\right) \\log\n    \\frac{Q^2_{\\text{max}}}{Q^2_{\\text{min}}}\n    - \\frac{m_e^2 x^2}{Q^2_{\\text{min}}} \\left( 1 -\n    \\frac{Q^2_{\\text{min}}}{Q^2_{\\text{max}}} \\right) \\biggr] \\qquad .\n\\end{equation}\nWhile Eq.~(\\ref{eq:budnev_617}) is supposed to be the better choice\nfor simulating hadronic background like low-$p_T$ hadrons and should\nbe applied for the low-$x$ region of the EPA,\nEq.~(\\ref{eq:budnev_616e}) seems better suited for high-$x$\nsimulations like the photoproduction of BSM resonances etc.\nNote that the first term in Eqs.~(\\ref{eq:budnev_617}) and\n(\\ref{eq:budnev_616e}) is the standard Altarelli-Parisi QED splitting\nfunction of electron, $P_{e\\to e\\gamma}(x) \\propto 1 + (1-x)^2$, while\nthe last term in both equations is the default power correction.\n\nThe two parameters $Q^2_{\\text{max}}$ and $Q^2_{\\text{min}}$ are the\nintegration boundaries of the photon virtuality integration. Usually,\nthey are given by the kinematic limits:\n\\begin{equation}\n  Q^2_{\\text{min}} = \\frac{m_e^2 x^2}{\\bar{x}} \\qquad\\qquad\n  Q^2_{\\text{max}} = 4 E^2 \\bar{x} = s \\bar{x} \\qquad .\n\\end{equation}\nFor low-$p_T$ hadron simulations, it is not a good idea to take the\nkinematic limit as an upper limit, but one should cut the simulation\noff at a hadronic scale like e.g. a multiple of the $\\rho$ mass.\n\nThe user can switch between the two different options using the setting\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{Verbatim}\n$epa_mode = \"default\"\n\\end{Verbatim}\n\\end{footnotesize}\n\\end{quote}\nor\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{Verbatim}\n$epa_mode = \"Budnev_617\"\n\\end{Verbatim}\n\\end{footnotesize}\n\\end{quote}\nfor Eq.~(\\ref{eq:budnev_617}), while Eq.~(\\ref{eq:budnev_616e}) can be\nchosen with\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{Verbatim}\n$epa_mode = \"Budnev_616e\"\n\\end{Verbatim}\n\\end{footnotesize}\n\\end{quote}\nNote that a thorough study for high-energy $e^+e^-$ colliders\nregarding the suitability of different EPA options is still lacking.\n\nFor testing purposes also three more variants or simplifications of\nEq.~(\\ref{eq:budnev_616e}) are implemented: the first, steered by\n\\ttt{\\$epa\\_mode = log\\_power} uses simply $Q^2_{\\text{max}} =\ns$. This is also the case for the two other method. But the switch\n\\ttt{\\$epa\\_mode = log\\_simple} uses just \\ttt{epa\\_mass} (cf. below)\nas $Q^2_{\\text{min}}$. The final simplification is to drop the power\ncorrection, which can be chosen with \\ttt{\\$epa\\_mode = log}. This\ncorresponds to the simple formula:\n\\begin{equation}\n  f(x) = \\frac{\\alpha}{2\\pi} \\frac{1}{x} \\, \\log\\frac{s}{m^2}\n  \\qquad .\n\\end{equation}\n\nExamples for the application of the EPA in \\whizard\\ are:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{Verbatim}\nbeams = e1, E1 => epa\n\\end{Verbatim}\n\\end{footnotesize}\n\\end{quote}\nor for a single beam:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{Verbatim}\nbeams = e1, p => epa, pdf_builtin\n\\end{Verbatim}\n\\end{footnotesize}\n\\end{quote}\nThe last process allows the reaction of (quasi-) on-shell photons with\nprotons.\n\nIn the following, we collect the parameters and flags that can be\nadjusted when using the EPA inside \\whizard:\n\n\\vspace{2mm}\n\n\\centerline{\\begin{tabular}{|l|l|l|}\\hline\nParameter & Default & Meaning \\\\\\hline\\hline\n\\ttt{epa\\_alpha} & \\ttt{0}/intrinsic & value of $\\alpha_{QED}$ for EPA\n\\\\\\hline\n\\ttt{epa\\_x\\_min} & \\ttt{0.} & soft photon cutoff in $x$ (mandatory)\n\\\\\\hline\n\\ttt{epa\\_q\\_min} & \\ttt{0.} & minimal $\\gamma$ momentum transfer \\\\\\hline\n\\ttt{epa\\_mass} & \\ttt{0}/intrinsic & mass of the radiating fermion (mandatory)  \\\\\\hline\n\\ttt{epa\\_q\\_max} & \\ttt{0}/$\\sqrt{s}$ & upper cutoff for EPA \\\\\\hline\n\\ttt{?epa\\_recoil} & \\ttt{false} & flag to switch on recoil/$p_T$\n\\\\\\hline\n\\ttt{?epa\\_keep\\_energy} & \\ttt{false} & recoil flag to conserve\nenergy in splitting\n\\\\\\hline\n\\end{tabular}}\\mbox{}\n\nThe adjustable parameters are partially similar to the parameters in\nthe QED initial-state radiation (ISR), cf. Sec.~\\ref{sec:lepton_isr}:\nthe parameter \\ttt{epa\\_alpha} sets the value of the electromagnetic\ncoupling constant, $\\alpha_{QED}$ used in the EPA structure\nfunction. If not set, this is taken from the value inside the active\nphysics model. The same is true for the mass of the particle that\nradiates the photon of the hard interaction, which can be reset by the\nuser with the variable \\ttt{epa\\_mass}. There are two dimensionful\nscale parameters, the minimal momentum transfer to the photon,\n\\ttt{epa\\_q\\_min}, which must not be zero, and the upper momentum-transfer\ncutoff\nfor the EPA structure function, \\ttt{epa\\_q\\_max}. The default for the\nlatter value is the collider energy, $\\sqrt{s}$, or the energy reduced\nby another structure function like e.g. beamstrahlung,\n$\\sqrt{\\hat{s}}$. Furthermore, there is a soft-photon regulator for\nthe splitting function in $x$ space, \\ttt{epa\\_x\\_min}, which also has\nto be explicitly set different from zero. Hence, a minimal viable\nscenario that will be accepted by \\whizard\\ looks like this:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{Verbatim}\nbeams = e1, E1 => epa\nepa_q_min = 5 GeV\nepa_x_min = 0.01\n\\end{Verbatim}\n\\end{footnotesize}\n\\end{quote}\n\nFinally, like the ISR case in Sec.~\\ref{sec:lepton_isr}, there is a\nflag to consider the recoil of the photon against the radiating\nelectron by setting \\ttt{?epa\\_recoil} to \\ttt{true} (default:\n\\ttt{false}).\n\nThough in principle processes like $e^+ e^- \\to e^+ e^- \\gamma \\gamma$\nwhere the two photons have been created almost collinearly and then\ninitiate a hard process could be described by exact matrix elements\nand exact kinematics. However, the numerical stability in the very far\ncollinear kinematics is rather challenging, such that the use of the\nEPA is very often an acceptable trade-off between quality of the\ndescription on the one hand and numerical stability and speed on the\nother hand.\n\nIn the case, the EPA is set after a second structure function like a\nhadron collider PDF, there is a flavor summation over the quark\nconstituents inside the proton, which are then the radiating fermions\nfor the EPA. Here, the masses of all fermions have to be identical.\n\nMore about the physics of the equivalent photon approximation can be\nfound in Chap.~\\ref{chap:hardint}.\n\n%%%%%%%%%%%%%%%\n\n\\subsection{Effective $W$ approximation}\n\\label{sec:ewa}\n\nAn approach similar to the equivalent photon approximation (EPA)\ndiscussed in the previous section Sec.~\\ref{sec:epa}, is the usage\nof a collinear splitting function for the radiation of massive\nelectroweak vector bosons $W$/$Z$, the effective $W$ approximation\n(EWA). It has been developed for the\ndescription of high-energy weak vector-boson fusion and scattering\nprocesses at hadron colliders, particularly the Superconducting\nSuper-Collider (SSC). This was at a time when the simulation of $2\\to\n4$ processes war still very challenging and $2\\to 6$ processes almost\nimpossible, such that this approximation was the only viable solution\nfor the simulation of processes like $pp \\to jjVV$ and subsequent\ndecays of the bosons $V \\equiv W, Z$.\n\nUnlike the EPA, the EWA is much more involved as the structure\nfunctions do depend on the isospin of the radiating fermions, and are\nalso different for transversal and longitudinal polarizations. Also, a\ntruely collinear kinematics is never possible due to the finite $W$\nand $Z$ boson masses, which start becoming more and more negligible\nfor energies larger than the nominal LHC energy of 14 TeV.\n\nThough in principle all processes for which the EWA might be\napplicable are technically feasible in \\whizard\\ to be generated also\nvia full matrix elements, the EWA has been implemented in \\whizard\\\nfor testing purposes, backwards compatibility and comparison with\nolder simulations. Like the EPA, it is a single-beam structure\nfunction that can be applied to one or both beams. We only give an\nexample for both beams here, this is for a 3 TeV CLIC collider:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{Verbatim}\nsqrts = 3 TeV\nbeams = e1, E1 => ewa\n\\end{Verbatim}\n\\end{footnotesize}\n\\end{quote}\nAnd this is for LHC or a higher-energy follow-up collider (which also\nshows the concatenation of the single-beam structure functions,\napplied to both beams consecutively,\ncf. Sec.~\\ref{sec:concatenation}:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{Verbatim}\nsqrts = 14 TeV\nbeams = p, p => pdf_builtin => ewa\n\\end{Verbatim}\n\\end{footnotesize}\n\\end{quote}\n\nAgain, we list all the options, parameters and flags that can be\nadapted for the EWA:\n\n\\vspace{2mm}\n\n\\centerline{\\begin{tabular}{|l|l|l|}\\hline\nParameter & Default & Meaning \\\\\\hline\\hline\n\\ttt{ewa\\_x\\_min} & \\ttt{0.} & soft $W$/$Z$ cutoff in $x$ (mandatory)\n\\\\\\hline\n\\ttt{ewa\\_mass} & \\ttt{0}/intrinsic & mass of the radiating fermion  \\\\\\hline\n\\ttt{ewa\\_pt\\_max} & \\ttt{0}/$\\sqrt{\\hat{s}}$ & upper cutoff for EWA \\\\\\hline\n\\ttt{?ewa\\_recoil} & \\ttt{false} & recoil switch\n\\\\\\hline\n\\ttt{?ewa\\_keep\\_energy} & \\ttt{false} & energy conservation for\nrecoil in splitting\n\\\\\\hline\n\\end{tabular}}\\mbox{}\n\nFirst of all, all coupling constants are taken from the active physics\nmodel as they have to be consistent with electroweak gauge\ninvariance. Like for EPA, there is a soft $x$ cutoff for the $f \\to f\nV$ splitting, \\ttt{ewa\\_x\\_min}, that has to be set different from\nzero by the user. Again, the mass of the radiating fermion can be set\nexplicitly by the user; and, also again, the masses for the flavor sum\nof quarks after a PDF as radiators of the electroweak bosons have to\nbe identical. Also for the EWA, there is an upper cutoff for the $p_T$\nof the electroweak boson, that can be set via\n\\ttt{eta\\_pt\\_max}. Indeed, the transversal $W$/$Z$ structure function\nis logarithmically divergent in that variable. If it is not set by the\nuser, it is estimated from $\\sqrt{s}$ and the splitting kinematics.\n\nFor the EWA, there is a flag to switch on a recoil for the\nelectroweak boson against the radiating fermion,\n\\ttt{?ewa\\_recoil}. Note that this is an experimental feature that is\nnot completely tested. In any case, the non-collinear kinematics\nviolates 4-four momentum conservation, so there are two choices:\neither to conserve the energy (\\ttt{?ewa\\_keep\\_energy = true}) or to\nconserve 3-momentum (\\ttt{?ewa\\_keep\\_energy = false}). Momentum\nconservation for the kinematics is the default. This is due to the\nfact that for energy conservation, there will be a net total momentum\nin the event including the beam remnants (ISR/EPA/EWA radiated\nparticles) that leeds to unexpected or unphysical features in the\nenergy distributions of the beam remnants recoiling against the rest\nof the event.\n\nMore details about the physics can be found in\nChap.~\\ref{chap:hardint}.\n\n\n%%%%%%%%%%%%%%%\n\n\\subsection{Energy scans using structure functions}\n\nIn \\whizard, there is an implementation of a pair spectrum,\n\\ttt{energy\\_scan}, that allows to scan the energy dependence of a\ncross section without actually scanning over the collider\nenergies. Instead, only a single integration at the upper end of the\nscan interval over the process with an additional pair spectrum\nstructure function performed. The structure function is chosen\nin such a way, that the distribution of $x$ values of the energy scan\npair spectrum translates in a plot over the energy of the final state\nin an energy scan from \\ttt{0} to \\ttt{sqrts} for the process under\nconsideration.\n\nThe simplest example is the $1/s$ fall-off with the $Z$ resonance in\n$e^+e^- \\to \\mu^+ \\mu^-$, where the syntax is very easy:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{Verbatim}\nprocess eemm = e1, E1 => e2, E2\nsqrts = 500 GeV\ncuts = sqrts_hat > 50\nbeams = e1, E1 => energy_scan\nintegrate (eemm)\n\\end{Verbatim}\n\\end{footnotesize}\n\\end{quote}\nThe value of \\ttt{sqrts = 500 GeV} gives the upper limit for the scan,\nwhile the cut effectively let the scan start at 50 GeV. There are no\nadjustable parameters for this structure function. How to plot the\ninvariant mass distribution of the final-state muon pair to show the\nenergy scan over the cross section, will be explained in\nSec.~\\ref{sec:analysis}.\n\nMore details can be found in Chap.~\\ref{chap:hardint}.\n\n%%%%%%%%%%%%%%%\n\n\\subsection{Photon collider spectra}\n\\label{sec:photoncoll}\n\nOne option that has been discussed as an alternative possibility for a\nhigh-energy linear lepton collider is to convert the electron and\npositron beam via Compton backscattering off intense laser beams into\nphoton\nbeams~\\cite{Ginzburg:1981vm,Telnov:1989sd,Telnov:1995hc}. Naturally,\ndue to the production\nof the photon beams and the inherent electron spectrum, the photon\nbeams have a characteristic spectrum. The simulation of such spectra\nis possible within \\whizard\\ by means of the subpackage \\circetwo,\nwhich have been mentioned already in Sec.~\\ref{sec:beamstrahlung}. It\nallows to give a much more elaborate description of a linear lepton\ncollider environment than\n\\circeone\\ (which, however, is not in all cases necessary, as the ILC\nbeamspectra for electron/positrons can be perfectly well described\nwith \\circeone).\n\nHere is a typical photon collider setup where we take a\nphoton-initiated process:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{Verbatim}\nprocess aaww = A, A => Wp, Wm\n\nbeams = A, A => circe2\n$circe2_file = \"teslagg_500_polavg.circe\"\n$circe2_design = \"TESLA/GG\"\n?circe2_polarized = false\n\\end{Verbatim}\n\\end{footnotesize}%$\n\\end{quote}\n\nHere, the photons are the initial states initiating the hard\nscattering. The structure function is \\ttt{circe2} which always is a\npair spectrum. The list of available options are:\n\n\\vspace{2mm}\n\n\\centerline{\\begin{tabular}{|l|l|l|}\\hline\nParameter & Default & Meaning \\\\\\hline\\hline\n\\ttt{?circe2\\_polarized} & \\ttt{true} & spectrum respects polarization info\n\\\\\\hline\n\\ttt{\\$circe2\\_file} & -- & name of beam spectrum data file\n\\\\\\hline\n\\ttt{\\$circe2\\_design} & \\ttt{\"*\"} & collider design\n\\\\\\hline\n\\end{tabular}}\\mbox{}\n\nThe only logical flag \\ttt{?circe2\\_polarized} let \\whizard\\ know\nwhether it should keep polarization information in the beam spectra or\naverage over polarizations. Naturally, because of the Compton\nbackscattering generation of the photons, photon spectra are always\npolarized. The collider design can be specified by the string variable\n\\ttt{\\$circe2\\_design}, where the default setting \\ttt{\"*\"}\ncorresponds to the default of \\circetwo\\ (which is the TESLA 500 GeV\nmachine as discussed in the TESLA Technical Design\nReport~\\cite{AguilarSaavedra:2001rg,Richard:2001qm}). Note that up to\nnow there have not been any setups for a photon collider option for\nthe modern linear collider concepts like ILC and CLIC. The string\nvariable \\ttt{\\$circe2\\_file} then allows to give the name of the file\ncontaining the actual beam spectrum; all files that ship with\n\\whizard\\ are stored in the directory \\ttt{circe2/share/data}.\n\nMore details about the subpackage \\circetwo\\ and the physics it\ncovers, can be found in its own manual and the chapter\nChap.~\\ref{chap:hardint}.\n\n%%%%%%%%%%%%%%%\n\n\\subsection{Concatenation of several structure functions}\n\\label{sec:concatenation}\n\nAs has been shown already in Sec.~\\ref{sec:epa} and\nSec.~\\ref{sec:ewa}, it is possible within \\whizard\\ to concatenate\nmore than one structure function, irrespective of the fact, whether\nthe structure functions are single-beam structure functions or pair\nspectra. One important thing is whether there is a phase-space mapping\nfor these structure functions. Also, there are some combinations which\ndo not make sense from the physics point of view, for example using\nlepton-collider ISR for protons, and then afterwards switching on\nPDFs. Such combinations will be vetoed by \\whizard, and you will find\nan error message like (cf. also Sec.~\\ref{sec:errors}):\n\\begin{interaction}\n******************************************************************************\n******************************************************************************\n*** FATAL ERROR: Beam structure: [....] not supported\n******************************************************************************\n******************************************************************************\n\\end{interaction}\n\nCommon examples for the concatenation of structure functions are\nlinear collider applications, where beamstrahlung (macroscopic\nelectromagnetic beam-beam interactions) and electron QED initial-state\nradiation are both switched on:\n\\begin{code}\nbeams = e1, E1 => circe1 => isr\n\\end{code}\nAnother possibility is the simulation of photon-induced backgrounds at\nILC or CLIC, using beamstrahlung and equivalent photon approximation\n(EPA):\n\\begin{code}\nbeams = e1, E1 => circe1 => epa\n\\end{code}\nor with beam events from a data file:\n\\begin{code}\nbeams = e1, E1 => beam_events => isr\n\\end{code}\n\nIn hadron collider physics, parton distribution functions (PDFs) are\nbasically always switched on, while afterwards the user could specify\nto use the effective $W$ approximation (EWA) to simulate high-energy\nvector boson scattering:\n\\begin{code}\nsqrts = 100 TeV\nbeams = p, p => pdf_builtin => ewa\n\\end{code}\nNote that this last case involves a flavor sum over the five active\nquark (and anti-quark) species $u$, $d$, $c$, $s$, $b$ in the proton,\nall of which act as radiators for the electroweak vector bosons in the\nEWA.\n\nThis would be an example with three structure functions:\n\\begin{code}\nbeams = e1, E1 => circe1 => isr => epa\n\\end{code}\n\n%%%%%%%%%%%%%%%\n\n\\section{Polarization}\n\\label{sec:polarization}\n\n%%%%%\n\n\\subsection{Initial state polarization}\n\\label{sec:initialpolarization}\n\n\\whizard\\ supports polarizing the inital state fully or partially by\nassigning a nontrivial density matrix in helicity space.\nInitial state polarization requires a beam setup and is initialized by\nmeans of the \\ttt{beams\\_pol\\_density} statement\\footnote{Note that\n  the syntax for the specification of beam polarization has changed\n  from version v2.1 to v2.2 and is incompatible between the two\n  release series. The old syntax \\ttt{beam\\_polarization} with its\n  different polarization constructors has been discarded in favor of a\n  unified syntax.}:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\nbeams_pol_density = @([<spin entries>]), @([<spin entries>])\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nThe command \\ttt{beams\\_pol\\_fraction} gives the degree of\npolarization of the two beams:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\nbeams_pol_fraction = <degree beam 1>, <degree beam 2>\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nBoth commands in the form written above apply to scattering processes,\nwhere the polarization of both beams must be specified. The\n\\ttt{beams\\_pol\\_density} and \\ttt{beams\\_pol\\_fraction} are possible\nwith a single beam declaration if a decay process is considered, but\nonly then.\n\nWhile the syntax for the command \\ttt{beams\\_pol\\_fraction} is pretty\nobvious, the syntax for the actual specification of the beam\npolarization is more intricate. We start with the polarization\nfraction: for each beam there is a real number between zero\n(unpolarized) and one (complete polarization) that can be specified\neither as a floating point number like \\ttt{0.4} or with a percentage:\n\\ttt{40 \\%}. Note that the actual arithmetics is sometimes\ncounterintuitive: 80 \\% left-handed electron polarization means that\n80 \\% of the electron beam are polarized, 20 \\% are unpolarized,\ni.e. 20 \\% have half left- and half right-handed polarization\neach. Hence, 90 \\% of the electron beam is left-handed, 10 \\% is\nright-handed.\n\nHow does the specification of the polarization work? If there are no\nentries at all in the polarization constructor, \\ttt{@()}, the beam is\nunpolarized, and the spin density matrix is proportional to the\nunit/identity matrix. Placing entries into the \\ttt{@()} constructor\nfollows the concept of sparse matrices, i.e. the entries that have\nbeen specified will be present, while the rest remains zero. Single\nnumbers do specify entries for that particular helicity on the main\ndiagonal of the spin density matrix, e.g. for an electron \\ttt{@(-1)}\nmeans (100\\%) left-handed polarization. Different entries are\nseparated by commas: \\ttt{@(1,-1)} sets the two diagonal entries at\npositions $(1,1)$ and $(-1,-1)$ in the density matrix both equal to\none. Two remarks are in order\nalready here. First, note that you do not have to worry about the\ncorrect normalization of the spin density matrix, \\whizard\\ is taking\ncare of this automatically. Second, in the screen output for the beam\ndata, only those entries of the spin density matrix that have been\nspecified by the user, will be displayed. If a\n\\ttt{beams\\_pol\\_fraction} statement appears, other components will be\nnon-zero, but might not be shown. E.g. ILC-like, 80 \\% polarization of\nthe electrons, 30 \\% positron polarization will be specified like this\nfor left-handed electrons and right-handed positrons:\n\\begin{code}\nbeams = e1, E1\nbeams_pol_density = @(-1), @(+1)\nbeams_pol_fraction = 80%, 30%\n\\end{code}\nThe screen output will be like this:\n\\begin{code}\n| ------------------------------------------------------------------------\n| Beam structure: e-, e+\n|   polarization (beam 1):\n|     @(-1: -1: ( 1.000000000000E+00, 0.000000000000E+00))\n|   polarization (beam 2):\n|     @(+1: +1: ( 1.000000000000E+00, 0.000000000000E+00))\n|   polarization degree = 0.8000000, 0.3000000\n| Beam data (collision):\n|   e-   (mass = 0.0000000E+00 GeV)  polarized\n|   e+   (mass = 0.0000000E+00 GeV)  polarized\n\\end{code}\nBut because of the fraction of unpolarized electrons and positrons,\nthe spin density matrices for electrons and positrons are:\n\\[\n\\rho(e^-) = \\diag \\left ( 0.10, 0.90 \\right) \\qquad\n\\rho(e^+) = \\diag \\left ( 0.65, 0.35 \\right) \\quad ,\n\\]\nrespectively. So, in general, only the entries due to the polarized\nfraction will be displayed on screen. We will come back to more\nexamples below.\n\nAgain, the setting of a single entry, e.g. \\ttt{@($\\pm m$)}, which\nalways sets the diagonal component $(\\pm m, \\pm m)$ of the spin\ndensity matrix equal to one. Here $m$ can have the following values\nfor the different spins (in parentheses are entries that exist only\nfor massive particles):\n\n\\vspace{1mm}\n\n\\begin{center}\n\\begin{tabular}{|l|l|l|}\\hline\n  Spin $j$ & Particle type & possible $m$ values \\\\\\hline\n  0   & Scalar boson           & 0 \\\\\n  1/2 & Spinor                 & +1, -1 \\\\\n  1   & (Massive) Vector boson & +1, (0), -1 \\\\\n  3/2 & (Massive) Vectorspinor & +2, (+1), (-1), -2 \\\\\n  2   & (Massive) Tensor       & +2, (+1), (0), (-1), -2\n  \\\\\\hline\n\\end{tabular}\n\\end{center}\n\n\\vspace{1mm}\n\nOff-diagonal entries that are equal to one (up to the normalization)\nof the spin-density matrix can be specified simply by the position,\nnamely: \\ttt{@($m$:$m'$, $m''$)}. This would result in a spin density\nmatrix with diagonal entry $1$ for the position $(m'', m'')$, and an entry\nof $1$ for the off-diagonal position $(m,m')$.\n\nFurthermore, entries in the density matrix different from $1$ with a\nnumerical value \\ttt{{\\em <val>}} can be\nspecified, separated by another colon: \\ttt{@($m$:$m'$:{\\em\n<val>})}. Here, it does not matter whether $m$ and $m'$ are different\nor not. For $m = m'$ also diagonal spin density matrix entries\ndifferent from one can be specified. Note that because spin density\nmatrices have to be Hermitian, only the entry $(m,m')$ has to be set,\nwhile the complex conjugate entry at the transposed position $(m',m)$\nis set automatically by \\whizard.\n\nWe will give some general density\nmatrices now, and after that a few more definite examples. In the\ngeneral setups below, we always give the expression for the spin\ndensity matrix only for one single beam.\n%\n{\n\n\\newcommand{\\cssparse}[4]{%\n\\begin{pmatrix}\n  #1     & 0      & \\cdots & \\cdots & #3     \\\\\n  0      & 0      & \\ddots &        & 0      \\\\\n  \\vdots & \\ddots & \\ddots & \\ddots & \\vdots \\\\\n  0      &        & \\ddots & 0      & 0      \\\\\n  #4     & \\cdots & \\cdots & 0      & #2\n\\end{pmatrix}%\n}\n%\n\n\\begin{itemize}\n\\item {\\bf Unpolarized:}\n  \\begin{center}\n    \\begin{footnotesize}\n    \\ttt{beams\\_pol\\_density = @()}\n    \\end{footnotesize}\n  \\end{center}\n% \\newline\nThis has the same effect as not specifying any\npolarization at all and is the only constructor available for scalars and\nfermions declared as left- or right-handed (like the neutrino). Density matrix:\n\\[ \\rho = \\frac{1}{|m|}\\mathbb{I} \\]\n($|m|$: particle multiplicity which is 2 for massless, $2j + 1$ for massive particles).\n%\n\\item {\\bf Circular polarization:}\n  \\begin{center}\n    \\begin{footnotesize}\n    \\ttt{beams\\_pol\\_density = @($\\pm j$) \\qquad beams\\_pol\\_fraction\n      = $f$}\n    \\end{footnotesize}\n  \\end{center}\nA fraction $f$ (parameter range $f \\in \\left[0\\;;\\;1\\right]$) of\nthe particles are in the maximum / minimum helicity eigenstate $\\pm\nj$, the remainder is unpolarized. For spin $\\frac{1}{2}$ and massless\nparticles of spin $>0$, only the maximal / minimal entries of the\ndensity matrix are populated, and the density matrix looks like this:\n\\[ \\rho = \\diag\\left(\\frac{1\\pm f}{2}\\;,\\;0\\;,\\;\\dots\\;,\\;0\\;,\n\\frac{1\\mp f}{2}\\right) \\]\n%\n\\item {\\bf Longitudinal polarization (massive):}\n  \\begin{center}\n    \\begin{footnotesize}\n    \\ttt{beams\\_pol\\_density = @(0) \\qquad beams\\_pol\\_fraction = $f$}\n    \\end{footnotesize}\n  \\end{center}\nWe consider massive particles with maximal spin component $j$, a\nfraction $f$ of which having longitudinal polarization, the remainder\nis unpolarized. Longitudinal polarization is (obviously) only\navailable for massive bosons of spin $>0$. Again, the parameter range\nfor the fraction is: $f \\in \\left[0\\;;\\;1\\right]$. The density matrix\nhas the form:\n\\[ \\rho = \\diag\\left(\\frac{1-f}{|m|}\\;,\\;\\dots\\;,\\;\\frac{1-f}{|m|}\\;,\\;\n\\frac{1+f \\left(|m| - 1\\right)}{|m|}\\;,\\;\\frac{1-f}{|m|}\\;,\n\\;\\dots\\;,\\;\\frac{1-f}{|m|}\\right)\n\\]\n($|m| = 2j+1 $: particle multiplicity)\n%\n\\item {\\bf Transverse polarization (along an axis):}\n  \\begin{center}\n    \\begin{footnotesize}\n    \\ttt{beams\\_pol\\_density = @(j, -j, j:-j:exp(-I*phi)) \\qquad\n      beams\\_pol\\_fraction = $f$}\n    \\end{footnotesize}\n  \\end{center}\nThis so called transverse polarization is a polarization along an\narbitrary direction in the $x-y$ plane, with $\\phi=0$ being the positive\n$x$ direction and $\\phi=90^\\circ$ the positive $y$ direction. Note that\nthe value of \\ttt{phi} has either to be set inside the beam\npolarization expression explicitly or by a statement \\ttt{real phi =\n  {\\em val} degree} before. A fraction $f$ of the particles are\npolarized, the remainder is unpolarized. Note that, although\nthis yields a valid density matrix for all particles with multiplicity\n$>1$ (in which the only the highest and lowest helicity states are\npopulated), it is meaningful only for spin $\\frac{1}{2}$ particles and\nmassless bosons of spin $>0$. The range of the parameters are:\n$f \\in \\left[0\\;;\\;1\\right]$ and $\\phi \\in \\mathbb{R}$. This yields a\ndensity matrix:\n\\[ \\rho =\n\\cssparse{1}{1}\n   {\\frac{f}{2}\\,e^{-i\\phi}} {\\frac{f}{2}\\,e^{i\\phi}} \\]\n(for antiparticles, the matrix is conjugated).\n%\n\\item {\\bf Polarization along arbitrary axis $\\left(\\theta, \\phi\\right)$:}\n  \\begin{center}\n    \\begin{footnotesize}\n    \\ttt{beams\\_pol\\_density = @(j:j:1-cos(theta),\n      j:-j:sin(theta)*exp(-I*phi), -j:-j:1+cos(theta))} \\qquad\\quad\\qquad\n    \\ttt{beams\\_pol\\_fraction = $f$}\n    \\end{footnotesize}\n  \\end{center}\nThis example describes polarization along an arbitrary axis in polar\ncoordinates (polar axis in positive $z$ direction, polar angle\n$\\theta$, azimuthal angle $\\phi$). A fraction $f$ of the particles are\npolarized, the remainder is unpolarized. Note that, although axis\npolarization defines a valid density matrix for all particles with\nmultiplicity $>1$, it is meaningful only for particles with spin\n$\\frac{1}{2}$. Valid ranges for the parameters are $f \\in\n\\left[0\\;;\\;1\\right]$, $\\theta \\in \\mathbb{R}$, $\\phi \\in\n\\mathbb{R}$. The density matrix then has the form:\n\\[ \\rho = \\frac{1}{2}\\cdot\n\\cssparse{1 - f\\cos\\theta}{1 + f\\cos\\theta}\n   {f\\sin\\theta\\, e^{-i\\phi}}{f\\sin\\theta\\, e^{i\\phi}}\n\\]\n%\n\\item {\\bf Diagonal density matrix:}\n  \\begin{center}\n    \\begin{footnotesize}\n    \\ttt{beams\\_pol\\_density = @(j:j:$h_j$, j-1:j-1:$h_{j-1}$,\n      $\\ldots$, -j:-j:$h_{-j}$)}\n    \\end{footnotesize}\n  \\end{center}\nThis defines an arbitrary diagonal density matrix with entries\n$\\rho_{j,j}\\,,\\,\\dots\\,,\\,\\rho_{-j,-j}$.\n%\n\\item {\\bf Arbitrary density matrix:}\n  \\begin{center}\n    \\begin{footnotesize}\n    \\ttt{beams\\_pol\\_density = @($\\{m:m':x_{m,m'}\\}$)}:\n    \\end{footnotesize}\n  \\end{center}\nHere, \\ttt{$\\{m:m':x_{m,m'}\\}$} denotes a selection of entries at\nvarious positions somewhere in the spin density matrix. \\whizard\\\nwill check whether this is a valid spin density matrix, but it does\ne.g. not have to correspond to a pure state.\n%\n\\end{itemize}\n}\n%\n\nThe beam polarization statements can be used both globally directly\nwith the \\ttt{beams} specification, or locally inside the\n\\ttt{integrate} or \\ttt{simulate} command. Some more specific examples\nare in order to show how initial state polarization works:\n%\n\\begin{itemize}\n\\item\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\nbeams = A, A\nbeams_pol_density = @(+1),  @(1, -1, 1:-1:-I)\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nThis declares the initial state to be composed of two incoming\nphotons, where the first photon is right-handed, and the second photon\nhas transverse polarization in $y$ direction.\n%\n\\item\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\nbeams = A, A\nbeams_pol_density = @(+1),  @(1, -1, 1:-1:-1)\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nSame as before, but this time the second photon has transverse\npolarization in $x$ direction.\n\n%\n\\item\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\nbeams = \"W+\"\nbeams_pol\\_density = @(0)\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nThis example sets up the decay of a longitudinal vector boson.\n%\n\\item\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\nbeams = E1, e1\nscan int hel_ep = (-1, 1) {\n   scan int hel_em = (-1, 1) {\n      beams_pol_density = @(hel_ep), @(hel_em)\n      integrate (eeww)\n   }\n}\nintegrate (eeww)\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nThis example loops over the different positron and electron helicity\ncombinations and calculates the respective integrals. The\n\\ttt{beams\\_pol\\_density} statement is local to the scan loop(s) and,\ntherefore, the last \\ttt{integrate} calculates the unpolarized\nintegral.\n\\end{itemize}\n%\n\nAlthough beam polarization should be straightforward to use, some pitfalls exist\nfor the unwary:\n\\begin{itemize}\n\\item Once \\ttt{beams\\_pol\\_density} is set globally, it persists and\nis applied every time \\ttt{beams} is executed (unless it is reset). In\nparticular, this means that code like\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\nprocess wwaa = Wp, Wm => A, A\nprocess zee = Z => e1, E1\n\nsqrts = 200 GeV\nbeams_pol_density = @(1, -1, 1:-1:-1), @()\nbeams = Wp, Wm\nintegrate (wwaa)\nbeams = Z\nintegrate (zee)\nbeams_pol_density = @(0)\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nwill throw an error, because \\whizard\\ complains that the spin density\nmatrix has the wrong dimensionality for the second (the decay) process.\nThis kind of trap can be avoided be using \\ttt{beams\\_pol\\_density}\nonly locally in \\ttt{integrate} or \\ttt{simulate} statements.\n%\n\\item On-the-fly integrations executed by \\ttt{simulate}\nuse the beam\nsetup found at the point of execution. This implies that any polarization\nsettings you have previously done affect the result of the integration.\n%\n\\item The \\ttt{unstable} command also requires integrals of the selected decay\n  processes, and will compute them on-the-fly if they are unavailable.  Here,\n  a polarized integral is not meaningful at all.  Therefore, this command\n  ignores the current \\ttt{beam} setting and issues a warning if a previous\n  polarized integral is available; this will be discarded.\n\\end{itemize}\n\n\n\\subsection{Final state polarization}\n\nFinal state polarization is available in \\whizard\\ in the sense that the\npolarization of real final state particles can be retained when generating\nsimulated\nevents. In order for the polarization of a particle to be retained, it must be\ndeclared as polarized via the \\ttt{polarized} statement\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\npolarized particle [, particle, ...]\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nThe effect of \\ttt{polarized} can be reversed with the \\ttt{unpolarized}\nstatement which has the same syntax. For example,\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\npolarized \"W+\", \"W-\", Z\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nwill cause the polarization of all final state $W$ and $Z$ bosons to be\nretained, while\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\nunpolarized \"W+\", \"W-\", Z\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nwill reverse the effect and cause the polarization to be summed over again. Note\nthat \\ttt{polarized} and \\ttt{unpolarized} are global statements which cannot be\nused locally as command arguments and if you use them e.g. in a loop, the\neffects will persist beyond the loop body. Also, a particle cannot be\n\\ttt{polarized} and \\ttt{unstable} at the same time (this restriction\nmight be loosened in future versions of \\whizard).\n\nAfter toggling the polarization flag, the generation of polarized events can be\nrequested by using the \\ttt{?polarized\\_events} option of the \\ttt{simulate}\ncommand, e.g.\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\nsimulate (eeww) { ?polarized_events = true }\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nWhen \\ttt{simulate} is run in this mode, helicity information for final state\nparticles that have been toggled as \\ttt{polarized} is written to the event\nfile(s) (provided that polarization is supported by the selected event file\nformat(s) ) and can also be accessed in the analysis by means of the \\ttt{Hel}\nobservable. For example, an analysis definition like\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\nanalysis =\n  if (all Hel == -1 [\"W+\"] and all Hel == -1 [\"W-\"] ) then\n    record cta_nn (eval cos (Theta) [\"W+\"]) endif;\n  if (all Hel == -1 [\"W+\"] and all Hel ==  0 [\"W-\"] )\n    then record cta_nl (eval cos (Theta) [\"W+\"]) endif\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\ncan be used to histogram the angular distribution for the production of\npolarized $W$ pairs (obviously, the example would have to be extended\nto cover all possible helicity combinations). Note, however, that\nhelicity information is not available in the integration step;\ntherefore, it is not possible to use \\ttt{Hel} as a cut observable.\n\nWhile final state polarization is straightforward to use, there is a caveat when\nused in combination with flavor products. If a particle in a flavor product is\ndefined as \\ttt{polarized}, then all particles ``originating'' from the product will\nact as if they had been declared as \\ttt{polarized} --- their polarization will\nbe recorded in the generated events. E.g., the example\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\nprocess test = u:d, ubar:dbar => d:u, dbar:ubar, u, ubar\n\n! insert compilation, cuts and integration here\n\npolarized d, dbar\nsimulate (test) {?polarized_events = true}\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nwill generate events including helicity information for all final state $d$ and\n$\\overline{d}$ quarks, but only for part of the final state $u$ and $\\overline{u}$\nquarks. In this case, if you had wanted to keep the helicity information also\nfor all $u$ and $\\overline{u}$, you would have had to explicitely include them\ninto the \\ttt{polarized} statement.\n\n\n\\section{Cross sections}\n\nIntegrating matrix elements over phase space is the core of \\whizard's\nactivities.  For any process where we want the cross section, distributions,\nor event samples, the cross section has to be determined first.  This is done\nby a doubly adaptive multi-channel Monte-Carlo integration.  The integration,\nin turn, requires a \\emph{phase-space setup}, i.e., a collection of\nphase-space \\emph{channels}, which are mappings of the unit hypercube onto the\ncomplete space of multi-particle kinematics.  This phase-space information is\nencoded in the file \\emph{xxx}\\ttt{.phs}, where \\emph{xxx} is the process tag.\n\\whizard\\ generates the phase-space file on the fly and can reuse it in later\nintegrations.\n\nFor each phase-space channel, the unit hypercube is binned in each dimension.\nThe bin boundaries are allowed to move during a sequence of iterations, each\nwith a fixed number of sampled phase-space points, so they adapt to the actual\nphase-space density as far as possible.  In addition to this \\emph{intrinsic}\nadaptation, the relative channel weights are also allowed to vary.\n\nAll these steps are done automatically when the \\ttt{integrate} command is\nexecuted.  At the end of the iterative adaptation procedure, the program has\nobtained an estimate for the integral of the matrix element over phase space,\ntogether with an error estimate, and a set of integration \\emph{grids} which\ncontains all information on channel weights and bin boundaries.  This\ninformation is stored in a file \\emph{xxx}\\ttt{.vg}, where \\emph{xxx} is the\nprocess tag, and is used for event generation by the \\ttt{simulate}\ncommand.\n\n\n\\subsection{Integration}\n\\label{sec:integrate}\n\nSince everything can be handled automatically using default parameters, it\noften suffices to write the command\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  integrate (proc1)\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nfor integrating the process with name tag \\ttt{proc1}, and similarly\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  integrate (proc1, proc2, proc3)\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nfor integrating several processes consecutively.  Options to the integrate\ncommand are specified, if not globally, by a local option string\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  integrate (proc1, proc2, proc3) { mH = 200 GeV }\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\n(It is possible to place a \\ttt{beams} statement inside the option string, if\ndesired.)\n\nIf the process is configured but not compiled, compilation will be done\nautomatically.   If it is not available at all, integration will fail.\n\nThe integration method can be specified by the string variable\n\\begin{quote}\n\\begin{footnotesize}\n  \\ttt{\\$integration\\_method = \"{\\em <method>}\"}\n\\end{footnotesize}\n\\end{quote} %$\nThe default method is called \\ttt{\"vamp\"} and uses the \\vamp\\\nalgorithm and code. (At the moment, there is only a single simplistic\nalternative, using the midpoint rule or rectangle method for\nintegration, \\ttt{\"midpoint\"}. This is mainly for testing purposes. In\nfuture versions of \\whizard, more methods like e.g. Gauss integration\nwill be made available). \\vamp, however, is clearly the main\nintegration method. It is done in several \\emph{passes} (usually two),\nand each pass consists of several \\emph{iterations}.  An iteration\nconsists of a definite number of \\emph{calls} to the matrix-element\nfunction.\n\nFor each iteration, \\whizard\\ computes an estimate of the integral and an\nestimate of the error, based on the binned sums of matrix element values and\nsquares.  It also computes an estimate of the rejection efficiency for\ngenerating unweighted events, i.e., the ratio of the average sampling function\nvalue over the maximum value of this function.\n\nAfter each iteration, both the integration grids (the binnings) and the\nrelative weights of the integration channels can be adapted to\nminimize the variance estimate of the integral.  After each pass of several\niterations, \\whizard\\ computes an average of the iterations within the pass,\nthe corresponding error estimate, and a $\\chi^2$ value.  The integral, error,\nefficiency and $\\chi^2$ value computed for the most recent integration pass,\ntogether with the most recent integration grid, are used for any subsequent\ncalculation that involves this process, in particular for event generation.\n\nIn the default setup, during the first pass(es) both grid binnings and channel\nweights are adapted.  In the final (usually second) pass, only binnings are\nfurther adapted.  Roughly speaking, the final pass is the actual calculation,\nwhile the previous pass(es) are used for ``warming up'' the integration grids,\nwithout using the numerical results. Below, in the section about the\nspecification of the iterations, Sec.~\\ref{sec:iterations}, we will\nexplain how it is possible to change the behavior of adapting grids\nand weights.\n\nHere is an example of the integration output, which illustrates these\nproperties.  The \\sindarin\\ script describes the process $e^+e^-\\to q\\bar q\nq\\bar q$ with $q$ being any light quark, i.e., $W^+W^-$ and $ZZ$ production\nand hadronic decay together will any irreducible background.  We cut on $p_T$\nand energy of jets, and on the invariant mass of jet pairs.  Here is the\nscript:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\nalias q = d:u:s:c\nalias Q = D:U:S:C\nprocess proc_4f = e1, E1 => q, Q, q, Q\n\nms = 0  mc = 0\nsqrts = 500 GeV\ncuts = all (Pt > 10 GeV and E > 10 GeV) [q:Q]\n   and all M > 10 GeV [q:Q, q:Q]\n\nintegrate (proc_4f)\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nAfter the run is finished, the integration output looks like\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n| Process library 'default_lib': loading\n| Process library 'default_lib': ... success.\n| Integrate: compilation done\n| RNG: Initializing TAO random-number generator\n| RNG: Setting seed for random-number generator to 12511\n| Initializing integration for process proc_4f:\n| ------------------------------------------------------------------------\n| Process [scattering]: 'proc_4f'\n|   Library name  = 'default_lib'\n|   Process index = 1\n|   Process components:\n|     1: 'proc_4f_i1':   e-, e+ => d:u:s:c, dbar:ubar:sbar:cbar,\n|                                  d:u:s:c, dbar:ubar:sbar:cbar [omega]\n| ------------------------------------------------------------------------\n| Beam structure: [any particles]\n| Beam data (collision):\n|   e-  (mass = 5.1099700E-04 GeV)\n|   e+  (mass = 5.1099700E-04 GeV)\n|   sqrts = 5.000000000000E+02 GeV\n| Phase space: generating configuration ...\n| Phase space: ... success.\n| Phase space: writing configuration file 'proc_4f_i1.phs'\n| Phase space: 123 channels, 8 dimensions\n| Phase space: found 123 channels, collected in 15 groves.\n| Phase space: Using 195 equivalences between channels.\n| Phase space: wood\n| Applying user-defined cuts.\n| OpenMP: Using 8 threads\n| Starting integration for process 'proc_4f'\n| Integrate: iterations not specified, using default\n| Integrate: iterations = 10:10000:\"gw\", 5:20000:\"\"\n| Integrator: 15 chains, 123 channels, 8 dimensions\n| Integrator: Using VAMP channel equivalences\n| Integrator: 10000 initial calls, 20 bins, stratified = T\n| Integrator: VAMP\n|=============================================================================|\n| It      Calls  Integral[fb]  Error[fb]   Err[%]    Acc  Eff[%]   Chi2 N[It] |\n|=============================================================================|\n   1       9963  2.3797857E+03  3.37E+02   14.15   14.13*   4.02\n   2       9887  2.8307603E+03  9.58E+01    3.39    3.37*   4.31\n   3       9815  3.0132091E+03  5.10E+01    1.69    1.68*   8.37\n   4       9754  2.9314937E+03  3.64E+01    1.24    1.23*  10.65\n   5       9704  2.9088284E+03  3.40E+01    1.17    1.15*  12.99\n   6       9639  2.9725788E+03  3.53E+01    1.19    1.17   15.34\n   7       9583  2.9812484E+03  3.10E+01    1.04    1.02*  17.97\n   8       9521  2.9295139E+03  2.88E+01    0.98    0.96*  22.27\n   9       9435  2.9749262E+03  2.94E+01    0.99    0.96   20.25\n  10       9376  2.9563369E+03  3.01E+01    1.02    0.99   21.10\n|-----------------------------------------------------------------------------|\n  10      96677  2.9525019E+03  1.16E+01    0.39    1.22   21.10    1.15  10\n|-----------------------------------------------------------------------------|\n  11      19945  2.9599072E+03  2.13E+01    0.72    1.02   15.03\n  12      19945  2.9367733E+03  1.99E+01    0.68    0.96*  12.68\n  13      19945  2.9487747E+03  2.03E+01    0.69    0.97   11.63\n  14      19945  2.9777794E+03  2.03E+01    0.68    0.96*  11.19\n  15      19945  2.9246612E+03  1.95E+01    0.67    0.94*  10.34\n|-----------------------------------------------------------------------------|\n  15      99725  2.9488622E+03  9.04E+00    0.31    0.97   10.34    1.05   5\n|=============================================================================|\n| Time estimate for generating 10000 events: 0d:00h:00m:51s\n| Creating integration history display proc_4f-history.ps and proc_4f-history.pdf\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nEach row shows the index of a single iteration, the number of matrix element\ncalls for that iteration, and the integral and error estimate.  Note\nthat the number of calls displayed are the real calls to the matrix\nelements after all cuts and possible rejections. The error\nshould be viewed as the $1\\sigma$ uncertainty, computed on a statistical\n\\begin{figure}\n  \\centering\n  \\includegraphics[width=.56\\textwidth]{proc_4f-history}\n  \\caption{\\label{fig:inthistory} Graphical output of the convergence\n    of the adaptation during the integration of a \\whizard\\ process.}\n\\end{figure}\nbasis.  The next two columns display the error in percent, and the\n\\emph{accuracy} which is the same error normalized by $\\sqrt{n_{\\rm calls}}$.\nThe accuracy value has the property that it is independent of $n_{\\rm calls}$,\nit describes the quality of adaptation of the current grids.  Good-quality\ngrids have a number of order one, the smaller the better.  The next column is\nthe estimate for the rejection efficiency in percent.  Here, the value should\nbe as high as possible, with $100\\,\\%$ being the possible maximum.\n\nIn the example, the grids are adapted over ten iterations, after which the\naccuracy and efficiency have saturated at about $1.0$ and $10\\,\\%$,\nrespectively.  The asterisk in the accuracy column marks those iterations\nwhere an improvement over the previous iteration is seen.  The average over\nthese iterations exhibits an accuracy of $1.22$, corresponding to $0.39\\,\\%$\nerror, and a $\\chi^2$ value of $1.15$, which is just right:\napparently, the phase-space for this process and set of cuts is\nwell-behaved.  The subsequent five iterations are used for obtaining\nthe final integral, which has an accuracy below one (error $0.3\\,\\%$),\nwhile the efficiency settles at about\n$10\\,\\%$.  In this example, the final $\\chi^2$ value happens to be quite\nsmall, i.e., the individual results are closer together than the error\nestimates would suggest.  One should nevertheless not scale down the error,\nbut rather scale it up if the $\\chi^2$ result happens to be much larger than\nunity: this often indicates sub-optimally adapted grids, which insufficiently\nmap some corner of phase space.\n\nOne should note that all values are subject to statistical fluctuations, since\nthe number of calls within each iterations is finite.  Typically, fluctuations\nin the efficiency estimate are considerably larger than fluctuations in the\nerror/accuracy estimate.  Two subsequent runs of the same script should yield\nstatistically independent results which may differ in all quantities, within\nthe error estimates, since the seed of the random-number generator will differ\nby default.\n\nIt is possible to get exactly reproducible results by setting the\nrandom-number seed explicitly, e.g.,\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  seed = 12345\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nat any point in the \\sindarin\\ script.  \\ttt{seed} is a predefined intrinsic\nvariable.  The value can be any 32bit integer.  Two runs with different seeds\ncan be safely taken as statistically independent. In the example\nabove, no seed has been set, and the seed has therefore been\ndetermined internally by \\whizard\\ from the system clock.\n\nThe concluding line with the time estimate applies to a subsequent simulation\nstep with unweighted events, which is not actually requested in the current\nexample.  It is based on the timing and efficiency estimate of the most recent\niteration.\n\nAs a default, a graphical output of the integration history will be\nproduced (if both \\LaTeX\\ and \\metapost\\ have been available during\nconfiguration). Fig.~\\ref{fig:inthistory} shows how this looks like,\nand demonstrates how a proper convergence of the integral during the\nadaptation looks like. The generation of these graphical history files\ncan be switched off using the command \\ttt{?vis\\_history = false}.\n\n%%%%%\n\n\\subsection{Integration run IDs}\n\nA single \\sindarin\\ script may contain multiple calls to the\n\\ttt{integrate} command with different parameters.  By default,\nfiles generated for the same process in a subsequent integration will\noverwrite the previous ones.  This is undesirable when the script is\nre-run: all results that have been overwritten have to be recreated.\n\nTo avoid this, the user may identify a specific run by a string-valued\nID, e.g.\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  integrate (foo) { $run_id = \"first\" }\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nThis ID will become part of the file name for all files that are\ncreated specifically for this run.  Often it is useful to create a run\nID from a numerical value using \\ttt{sprintf}, e.g., in this scan:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  scan real mh = (100 => 200 /+ 10) {\n    $run_id = sprintf \"%e\" (mh)\n    integrate (h_production)\n  }\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\n\nWith unique run IDs, a subsequent run of the same \\sindarin\\ script\nwill be able to reuse all previous results, even if there is more than\na single integration per process.\n\n\n\n\n\\subsection{Controlling iterations}\n\\label{sec:iterations}\n\n\\whizard\\ has some predefined numbers of iterations and calls for the first\nand second integration pass, respectively, which depend on the number of\ninitial and final-state particles.  They are guesses for values that yield\ngood-quality grids and error values in standard situations, where no\nexceptionally strong peaks or loose cuts are present in the integrand.\nActually, the large number of warmup iterations in the previous example\nindicates some safety margin in that respect.\n\nIt is possible, and often advisable, to adjust the iteration and call numbers\nto the particular situation.  One may reduce the default numbers to short-cut\nthe integration, if either less accuracy is needed, or CPU time is to be\nsaved.  Otherwise, if convergence is bad, the number of iterations or calls\nmight be increased.\n\nTo set iterations manually, there is the \\ttt{iterations} command:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  iterations = 5:50000, 3:100000\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nThis is a comma-separated list.  Each pair of values corresponds to an\nintegration pass.  The value before the colon is the number of iterations for\nthis pass, the other number is the number of calls per iteration.\n\nWhile the default number of passes is two (one for warmup, one for the final\nresult), you may specify a single pass\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  iterations = 5:100000\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nwhere the relative channel weights will \\emph{not} be adjusted (because this\nis the final pass).  This is appropriate for well-behaved integrands where\nweight adaptation is not necessary.\n\nYou can also define more than two passes.  That might be useful when reusing a\nprevious grid file with insufficient quality: specify the previous passes\nas-is, so the previous results will be read in, and then a new pass for\nfurther adaptation.\n\nIn the final pass, the default behavior is to not adapt grids and\nweights anymore. Otherwise, different iterations would be correlated,\nand a final reliable error estimate would not be possible. For all but\nthe final passes, the user can decide whether to adapt grids and\nweights by attaching a string specifier to the number of iterations:\n\\ttt{\"g\"} does adapt grids, but not weights, \\ttt{\"w\"} the other way\nround. \\ttt{\"gw\"} or \\ttt{\"wg\"} does adapt both. By the setting\n\\ttt{\"\"}, all adaptations are switched off. An example looks like\nthis:\n\\begin{code}\n  iterations = 2:10000:\"gw\", 3:5000\n\\end{code}\n\nSince it is often not known beforehand how many iterations the grid\nadaptation will need, it is generally a good idea to give the first\npass a large number of iterations.  However, in many cases these turn\nout to be not necessary.  To shortcut iterations, you can set any of\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\naccuracy_goal\nerror_goal\nrelative_error_goal\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nto a positive value.  If this is done, \\whizard\\ will skip warmup\niterations once all of the specified goals are reached by the current\niteration.  The final iterations (without weight adaptation) are\nalways performed.\n\n\n\\subsection{Phase space}\n\nBefore \\ttt{integrate} can start its work, it must have a phase-space\nconfiguration for the process at hand.  The method for the phase-space\nparameterization is determined by the string variable\n\\ttt{\\$phs\\_method}. At the moment there are only two options,\n\\ttt{\"single\"}, for testing purposes, that is mainly used internally,\nand \\whizard's traditional method, \\ttt{\"wood\"}. This parameterization\nis particularly adapted and fine-tuned for electroweak processes and\nmight not be the ideal for for pure jet cross sections. In future\nversions of \\whizard, more options for phase-space parameterizations\nwill be made available, e.g. the \\ttt{RAMBO} algorithm and its massive\ncousin, and phase-space parameterizations that take care of the\ndipole-like emission structure in collinear QCD (or QED) splittings.\nFor the standard method, the phase-space parameterization is laid out\nin an ASCII file \\ttt{\\textit{<process-name>\\_}i\\textit{<comp>}.phs}.\nHere, \\ttt{{\\em <process-name>}} is the process name chosen by the\nuser while \\ttt{{\\em <comp>}} is the number of the process component\nof the corresponding process. This immediately shows that different\ncomponents of processes are getting different phase space setups. This\nis necessary for inclusive processes, e.g. the sum of $pp \\to Z + nj$\nand $pp \\to W + nj$, or in future versions of \\whizard\\ for NLO\nprocesses, where one component is the interference between the virtual\nand the Born matrix element, and another one is the subtraction terms.\nNormally, you do not have to deal with this file, since \\whizard\\ will\ngenerate one automatically if it does not find one. (\\whizard\\ is\ncareful to check for consistency of process definition and parameters\nbefore using an existing file.)\n\nExperts might find it useful to generate a phase-space file and inspect and/or\nmodify it before proceeding further.  To this end, there is the parameter\n\\verb|?phs_only|.  If you set this \\ttt{true}, \\whizard\\ skips the actual\nintegration after the phase-space file has been generated.  There is also a\nparameter \\verb|?vis_channels| which can be set independently; if this is\n\\ttt{true}, \\whizard\\ will generate a graphical visualization of the\nphase-space parameterizations encoded in the phase-space file. This\nfile has to be taken with a grain of salt because phase space channels\nare represented by sample Feynman diagrams for the corresponding\nchannel. This does however {\\em not} mean that in the matrix element\nother Feynman diagrams are missing (the default matrix element method,\n\\oMega, is not using Feynman-diagrammatic amplitudes at all).\n\nThings might go wrong with the default phase-space generation, or manual\nintervention might be necessary to improve later performance.  There are a few\nparameters that control the algorithm of phase-space generation.  To\nunderstand their meaning, you should realize that phase-space\nparameterizations are modeled after (dominant) Feynman graphs for the current\nprocess.\n\n\\subsubsection{The main phase space setup {\\em wood}}\n\nFor the main phase-space parameterization of \\whizard, which is called\n\\ttt{\"wood\"}, there are many different parameters and flags that allow\nto tune and customize the phase-space setup for every certain process:\n\nThe parameter \\verb|phs_off_shell| controls the number of off-shell lines in\nthose graphs, not counting $s$-channel resonances and logarithmically enhanced\n$s$- and $t$-channel lines.  The default value is $2$.  Setting it to zero\nwill drop everything that is not resonant or logarithmically enhanced.\nIncreasing it will include more subdominant graphs.  (\\whizard\\ increases the\nvalue automatically if the default value does not work.)\n\nThere is a similar parameter \\verb|phs_t_channel| which controls\nmultiperipheral graphs in the parameterizations.  The default value is $6$, so\ngraphs with up to $6$ $t/u$-channel lines are considered.  In particular\ncases, such as $e^+e^-\\to n\\gamma$, all graphs are multiperipheral, and for\n$n>7$ \\whizard\\ would find no parameterizations in the default setup.\nIncreasing the value of \\verb|phs_t_channel| solves this problem.  (This is\npresently not done automatically.)\n\nThere are two numerical parameters that describe whether particles are treated\nlike massless particles in particular situations.  The value of\n\\verb|phs_threshold_s| has the default value $50\\;\\GeV$.  Hence, $W$ and $Z$\nare considered massive, while $b$ quarks are considered massless.  This\ncategorization is used for deciding whether radiation of $b$ quarks can lead\nto (nearly) singular behavior, i.e., logarithmic enhancement, in the infrared\nand collinear regions.  If yes, logarithmic mappings are applied to phase\nspace.  Analogously, \\verb|phs_threshold_t| decides about potential\n$t$-channel singularities.  Here, the default value is $100\\;\\GeV$, so\namplitudes with $W$ and $Z$ in the $t$-channel are considered as\nlogarithmically enhanced. For a high-energy hadron collider of 40 or\n100 TeV energy, also $W$ and $Z$ in $s$-channel like situations might\nbe necessary to be considered massless.\n\nSuch logarithmic mappings need a dimensionful scale as parameter.  There are\nthree such scales, all with default value $10\\;\\GeV$: \\verb|phs_e_scale|\n(energy), \\verb|phs_m_scale| (invariant mass), and \\verb|phs_q_scale|\n(momentum transfer).  If cuts and/or masses are such that energies, invariant\nmasses of particle pairs, and momentum transfer values below $10\\;\\GeV$ are\nexcluded or suppressed, the values can be kept.  In special cases they should\nbe changed: for instance, if you want to describe $\\gamma^*\\to\\mu^+\\mu^-$\nsplitting well down to the muon mass, no cuts, you may set\n\\verb|phs_m_scale = mmu|.  The convergence of the Monte-Carlo integration\nresult will be considerably faster.\n\nThere are more flags. These and more details about the phase space\nparameterization will be described in Sec.~\\ref{sec:wood}.\n\n\n\\subsection{Cuts}\n\n\\whizard~2 does not apply default cuts to the integrand.  Therefore, processes\nwith massless particles in the initial, intermediate, or final states may not\nhave a finite cross section.  This fact will manifest itself in an integration\nthat does not converge, or is unstable, or does not yield a reasonable error\nor reweighting efficiency even for very large numbers of iterations or calls\nper iterations.  When doing any calculation, you should verify first that the\nresult that you are going to compute is finite on physical grounds.  If not,\nyou have to apply cuts that make it finite.\n\nA set of cuts is defined by the \\ttt{cuts} statement.  Here is an example\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\ncuts = all Pt > 20 GeV [colored]\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nThis implies that events are kept only (for integration and simulation) if the\ntransverse momenta of all colored particles are above $20\\;\\GeV$.\n\nTechnically, \\ttt{cuts} is a special object, which is unique within a given\nscope, and is defined by the logical expression on the right-hand side of the\nassignment.  It may be defined in global scope, so it is applied to all\nsubsequent processes.  It may be redefined by another \\ttt{cuts} statement.\nThis overrides the first cuts setting: the \\ttt{cuts} statement is not\ncumulative.  Multiple cuts should be specified by the logical operators of\n\\sindarin, for instance\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\ncuts = all Pt > 20 GeV [colored]\n  and all E > 5 GeV [photon]\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nCuts may also be defined local to an \\ttt{integrate} command, i.e., in the\noptions in braces.   They will apply only to the processes being integrated,\noverriding any global cuts.\n\nThe right-hand side expression in the \\ttt{cuts} statement is evaluated at the\npoint where it is used by an \\ttt{integrate} command (which could be an\nimplicit one called by \\ttt{simulate}).  Hence, if the logical expression\ncontains parameters, such as\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\nmH = 120 GeV\ncuts = all M > mH [b, bbar]\nmH = 150 GeV\nintegrate (myproc)\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nthe Higgs mass value that is inserted is the value in place when\n\\ttt{integrate} is evaluated, $150\\;\\GeV$ in this example.  This same value\nwill also be used when the process is called by a subsequent \\ttt{simulate};\nit is \\ttt{integrate} which compiles the cut expression and stores it among\nthe process data.  This behavior allows for scanning over parameters without\nredefining the cuts every time.\n\nThe cut expression can make use of all variables and constructs that are\ndefined at the point where it is evaluated.  In particular, it can make use of\nthe particle content and kinematics of the hard process, as in the example\nabove.  In addition to the predefined variables and those defined by the user,\nthere are the following variables which depend on the hard process:\n\\begin{quote}\n\\begin{tabular}{ll}\ninteger: & \\ttt{n\\_in}, \\ttt{n\\_out}, \\ttt{n\\_tot} \\\\\nreal: & \\ttt{sqrts}, \\ttt{sqrts\\_hat}\n\\end{tabular}\n\\end{quote}\nExample:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\ncuts = sqrts_hat > 150 GeV\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nThe constants \\ttt{n\\_in} etc.\\ are sometimes useful if a generic set of cuts\nis defined, which applies to various processes simultaneously.\n\nThe user is encouraged to define his/her own set of cuts, if possible in a\nprocess-independent manner, even if it is not required.  The \\ttt{include}\ncommand allows for storing a set of cuts in a separate \\sindarin\\ script which\nmay be read in anywhere.  As an example, the system directories contain a file\n\\verb|default_cuts.sin| which may be invoked by\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\ninclude (\"default_cuts.sin\")\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\n\n\n\\subsection{QCD scale and coupling}\n\n\\whizard\\ treats all physical parameters of a model, the coefficients in the\nLagrangian, as constants.  As a leading-order program, \\whizard\\ does not make\nuse of running parameters as they are described by renormalization theory.\nFor electroweak interactions where the perturbative expansion is sufficiently\nwell behaved, this is a consistent approach.\n\nAs far as QCD is concerned, this approach does not yield numerically\nreliable results, even on the validity scale of the tree approximation.\nIn \\whizard\\ttt{2}, it is therefore possible to replace the fixed value of\n$\\alpha_s$ (which is accessible as the intrinsic model variable\n\\verb|alphas|), by a function of an energy scale $\\mu$.\n\nThis is controlled by the parameter \\verb|?alphas_is_fixed|, which is\n\\ttt{true} by default.  Setting it to \\ttt{false} enables running~$\\alpha_s$.\nThe user has then to decide how $\\alpha_s$ is calculated.\n\nOne option is to set \\verb|?alphas_from_lhapdf| (default \\ttt{false}).  This\nis recommended if the \\lhapdf\\ library is used for including structure\nfunctions, but it may also be set if \\lhapdf\\ is not invoked.  \\whizard\\ will\nthen use the $\\alpha_s$ formula and value that matches the active\n\\lhapdf\\ structure function set and member.\n\nIn the very same way, the $\\alpha_s$ running from the PDFs implemented\nintrinsically in \\whizard\\ can be taken by setting\n\\verb|?alphas_from_pdf_builtin| to \\ttt{true}. This is the same\nrunning then the one from \\lhapdf, if the intrinsic PDF coincides with\na PDF chosen from \\lhapdf.\n\nIf this is not appropriate, there are again two possibilities.  If\n\\verb|?alphas_from_mz| is \\ttt{true}, the user input value \\verb|alphas| is\ninterpreted as the running value $\\alpha_s(m_Z)$, and for the particular\nevent, the coupling is evolved to the appropriate scale $\\mu$.  The formula is\ncontrolled by the further parameters \\verb|alphas_order| (default $0$,\nmeaning leading-log; maximum $2$) and \\verb|alphas_nf| (default $5$).\n\nOtherwise there is the option to set \\verb|?alphas_from_lambda_qcd = true|\nin order to evaluate $\\alpha_s$ from the scale $\\Lambda_{\\rm QCD}$,\nrepresented by the intrinsic variable \\verb|lambda_qcd|. The reference\nvalue for the QCD scale is $\\Lambda\\_{\\rm QCD} = 200$\nMeV. \\verb|alphas_order| and \\verb|alphas_nf| apply analogously.\n\nNote that for using one of the running options for $\\alpha_s$, always\n\\ttt{?alphas\\_is\\_fixed = false} has to be invoked.\n\nIn any case, if $\\alpha_s$ is not fixed, each event has to be assigned an\nenergy scale.  By default, this is $\\sqrt{\\hat s}$, the partonic invariant\nmass of the event.  This can be replaced by a user-defined scale, the special\nobject \\ttt{scale}.  This is assigned and used just like the \\ttt{cuts}\nobject.  The right-hand side is a real-valued expression.  Here is an example:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\nscale = eval Pt [sort by -Pt [colored]]\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nThis selects the $p_T$ value of the first entry in the list of colored\nparticles sorted by decreasing $p_T$, i.e., the $p_T$ of the hardest jet.\n\nThe \\ttt{scale} definition is used not just for running $\\alpha_s$ (if\nenabled), but it is also the factorization scale for the \\lhapdf\\ structure\nfunctions.\n\nThese two values can be set differently by specifying\n\\ttt{factorization\\_scale} for the scale at which the PDFs are\nevaluated. Analogously, there is a variable\n\\ttt{renormalization\\_scale} that sets the scale value for the running\n$\\alpha_s$. Whenever any of these two values is set, it supersedes the\n\\ttt{scale} value.\n\nJust like the \\ttt{cuts} expression, the expressions for \\ttt{scale},\n\\ttt{factorization\\_scale} and also \\ttt{renormalization\\_scale}\nare evaluated at the point where it is read by an explicit or implicit\n\\ttt{integrate} command.\n\n\n\\subsection{Reweighting factor}\n\nIt is possible to reweight the integrand by a user-defined function of the\nevent kinematics.  This is done by specifying a \\ttt{weight} expression.\nSyntax and usage is exactly analogous to the \\ttt{scale} expression.  Example:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\nweight = eval (1 + cos (Theta) ^ 2) [lepton]\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nWe should note that the phase-space setup is not aware of this reweighting, so\nin complicated cases you should not expect adaptation to achieve as accurate\nresults as for plain cross sections.\n\nNeedless to say, the default \\ttt{weight} is unity.\n\n\n\\section{Events}\n\nAfter the cross section integral of a scattering process is known (or the\npartial-width integral of a decay process), \\whizard\\ can generate event\nsamples.  There are two limiting cases or modes of event generation:\n\\begin{enumerate}\n\\item\n  For a physics simulation, one needs \\emph{unweighted} events, so the\n  probability of a process and a kinematical configuration in the event sample\n  is given by its squared matrix element.\n\\item\n  Monte-Carlo integration yields \\emph{weighted} events, where the probability\n  (without any grid adaptation) is uniformly distributed over phase space,\n  while the weight of the event is given by its squared matrix element.\n\\end{enumerate}\nThe choice of parameterizations and the iterative adaptation of the\nintegration grids gradually shift the generation mode from option 2 to option\n1, which obviously is preferred since it simulates the actual outcome of an\nexperiment.  Unfortunately, this adaptation is perfect only in trivial cases,\nsuch that the Monte-Carlo integration yields non-uniform probability still\nwith weighted events.  Unweighted events are obtained by rejection, i.e.,\naccepting an event with a probability equal to its own weight divided by the\nmaximal possible weight.  Furthermore, the maximal weight is never precisely\nknown, so this probability can only be estimated.\n\nThe default generation mode of \\whizard\\ is unweighted.  This is controlled by\nthe parameter \\verb|?unweighted| with default value \\ttt{true}.  Unweighted\nevents are easy to interpret and can be directly compared with experiment, if\nproperly interfaced with detector simulation and analysis.\n\nHowever, when applying rejection to generate unweighted events, the generator\ndiscards information, and for a single event it needs, on the average,\n$1/\\epsilon$ calls, where the efficiency $\\epsilon$ is the ratio of the\naverage weight over the maximal weight.  If \\verb|?unweighted| is \\ttt{false},\nall events are kept and assigned their respective weights in histograms or\nevent files.\n\n\n\\subsection{Simulation}\n\\label{sec:simulation}\n\nThe \\ttt{simulate} command generates an event sample.  The number of events\ncan be set either by specifying the integer variable \\verb|n_events|, or by\nthe real variable \\verb|luminosity|.  (This holds for unweighted events.  If\nweighted events are requested, the luminosity value is ignored.)  The\nluminosity is measured in\nfemtobarns, but other units can be used, too.  Since the cross sections for the\nprocesses are known at that point, the number of events is determined as the\nluminosity multiplied by the cross section.\n\nAs usual, both parameters can be set either as global or as local parameters:\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  n_events = 10000\n  simulate (proc1)\n  simulate (proc2, proc3) { luminosity = 100 / 1 pbarn }\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nIn the second example, both \\verb|n_events| and \\verb|luminosity| are set.\nIn that case, \\whizard\\ chooses whatever produces the larger number of events.\n\nIf more than one process is specified in the argument of \\ttt{simulate},\nevents are distributed among the processes with fractions proportional to\ntheir cross section values.  The processes are mixed randomly, as it would be\nthe case for real data.\n\nThe raw event sample is written to a file which is named after the first process\nin the argument of \\ttt{simulate}.  If the process name is \\ttt{proc1}, the\nfile will be named \\ttt{proc1.evx}.  You can choose another basename by the\nstring variable \\verb|$sample|.  For instance,\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\n  simulate (proc1) { n_events = 4000  $sample = \"my_events\" }\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nwill produce an event file \\verb|my_events.evx| which contains $4000$ events.\n\nThis event file is in a machine-dependent binary format, so it is not of\nimmediate use.  Its principal purpose is to serve as a cache: if you re-run\nthe same script, before starting simulation, it will look for an existing\nevent file that matches the input.  If nothing has changed, it will find the\nfile previously generated and read in the events, instead of generating them.\nThus you can modify the analysis or any further steps without repeating the\ntime-consuming task of generating a large event sample.  If you change the\nnumber of events to generate, the program will make use of the existing event\nsample and generate further events only when it is used up.  If necessary, you\ncan suppress the writing/reading of the raw event file by the parameters\n\\verb|?write_raw| and \\verb|?read_raw|.\n\nIf you try to reuse an event file that has been written by a previous version\nof \\whizard, you may run into an incompatibility, which will be detected as an\nerror.  If this happens, you may enforce a compatibility mode (also for\nwriting) by setting \\ttt{\\$event\\_file\\_version} to the appropriate version\nstring, e.g., \\verb|\"2.0\"|.  Be aware that this may break some more recent\nfeatures in the event analysis.\n\nGenerating an event sample can serve several purposes.  First of all,\nit can be analyzed directly, by \\whizard's built-in capabilities, to\nproduce tables, histograms, or calculate inclusive observables.  The\nbasic analysis features of \\whizard\\ are described below in\nSec.~\\ref{sec:analysis}.  It can be written to an external file in a\nstandard format that a human or an external program can understand.\nIn Chap.~\\ref{chap:events}, you will find a more thorough discussion\nof event generation with \\whizard, which also covers in detail the\navailable event-file formats.  Finally, \\whizard\\ can rescan an\nexisting event sample.  The event sample may either be the result of a\nprevious \\ttt{simulate} run or, under certain conditions, an external\nevent sample produced by another generator or reconstructed from\ndata.\n\\begin{quote}\n\\begin{footnotesize}\n\\begin{verbatim}\nrescan \"my_events\" (proc1) { $pdf_builtin_set = \"MSTW2008LO\" }\n\\end{verbatim}\n\\end{footnotesize}\n\\end{quote}\nThe rescanning may apply different parameters and recalculate the\nmatrix element, it may apply a different event selection, it may\nreweight the events by a different PDF set (as above).  The modified\nevent sample can again be analyzed or written to file.  For more\ndetails, cf.\\ Sec.~\\ref{sec:rescan}.\n\n%%%%%%%%%%%%%%%\n\n\\subsection{Decays}\n\\label{sec:decays}\n\nNormally, the events generated by the \\ttt{simulate} command will be identical\nin structure to the events that the \\ttt{integrate} command generates.  This\nimplies that for a process such as $pp\\to W^+W^-$, the final-state particles\nare on-shell and stable, so they appear explicitly in the generated event\nfiles.  If events are desired where the decay products of the $W$ bosons\nappear, one has to generate another process, e.g., $pp\\to u\\bar d\\bar ud$.  In\nthis case, the intermediate vector bosons, if reconstructed, are off-shell as\ndictated by physics, and the process contains all intermediate states that are\npossible.  In this example, the matrix element contains also $ZZ$, photon, and\nnon-resonant intermediate states.  (This can be restricted via the\n\\verb|$restrictions| option, cf.\\ \\ref{sec:process options}.\n\nAnother approach is to factorize the process in production (of $W$ bosons) and\ndecays ($W\\to q\\bar q$).  This is actually the traditional approach, since it\nis much less computing-intensive.  The factorization neglects all off-shell\neffects and irreducible background diagrams that do not have the decaying\nparticles as an intermediate resonance.  While \\whizard\\ is able to deal with\nmulti-particle processes without factorization, the needed computing resources\nrapidly increase with the number of external particles. Particularly,\nit is the phase space integration that becomes the true bottleneck for\na high multiplicity of final state particles.\n\nIn order to use the factorized approach, one has to specify particles\nas \\ttt{unstable}.  (Also, the \\ttt{?allow\\_decays} switch must be \\ttt{true};\nthis is however its default value.)  We give an example for a $pp \\to Wj$ final\nstate:\n\\begin{code}\nprocess wj  = u, gl => d, Wp\nprocess wen = Wp => E1, n1\n\nintegrate (wen)\n\nsqrts = 7 TeV\nbeams = p, p => pdf_builtin\nunstable Wp (wen)\nsimulate (wj) { n_events = 1 }\n\\end{code}\nThis defines a $2 \\to 2$ hard scattering process of $W + j$ production\nat the 7 TeV LHC 2011 run. The $W^+$ is marked as unstable, with its\ndecay process being $W^+ \\to e^+ \\nu_e$. In the \\ttt{simulate} command\nboth processes, the production process \\ttt{wj} and the decay process\n\\ttt{wen} will be integrated, while the $W$ decays become effective\nonly in the final event sample. This event sample will contain final\nstates with multiplicity $3$, namely $e^+ \\nu_e d$. Note that here\nonly one decay process is given, hence the branching ratio for the\ndecay will be taken to be $100 \\%$ by \\whizard.\n\nA natural restriction of the factorized approach is the implied narrow-width\napproximation.  Theoretically, this restriction is necessary since whenever\nthe width plays an important role, the usage of the factorized approach will\nnot be fully justified.  In particular, all involved matrix elements must be\nevaluated on-shell, or otherwise gauge-invariance issues could spoil the\ncalculation.  (There are plans for a future \\whizard\\ version\nto also include Breit-Wigner or Gaussian distributions when using the\nfactorized approach.)\n\nDecays can be concatenated, e.g. for top pair production and\ndecay, $e^+ e^- \\to t \\bar t$ with decay $t \\to W^+ b$, and subsequent\nleptonic decay of the $W$ as in $W^+ \\to \\mu^+ \\nu_\\mu$:\n\\begin{code}\nprocess eett = e1, E1 => t, tbar\nprocess t_dec = t => Wp, b\nprocess W_dec = Wp => E2, n2\n\nunstable t (t_dec)\nunstable Wp (W_dec)\n\nsqrts = 500\nsimulate (eett) { n_events = 1 }\n\\end{code}\nNote that in this case the final state in the event file will consist\nof $\\bar t b \\mu^+ \\nu_\\mu$ because the anti-top is not decayed.\n\nIf more than one decay process is being specified like in\n\\begin{code}\n  process eeww = e1, E1 => Wp, Wm\n  process w_dec1 = Wp => E2, n2\n  process w_dec2 = Wp => E3, n3\n\n  unstable Wp (w_dec1, w_dec2)\n\n  sqrts = 500\n  simulate (eeww) { n_events = 100 }\n\\end{code}\nthen \\whizard\\ takes the integrals of the specified decay processes\nand distributes the decays statistically according to the calculated\nbranching ratio. Note that this might not be the true branching ratios\nif decay processes are missing, or loop corrections to partial widths\ngive large(r) deviations. In the calculation of the code above,\n\\whizard\\ will issue an output like\n\\begin{code}\n| Unstable particle W+: computed branching ratios:\n|   w_dec1: 5.0018253E-01   mu+, numu\n|   w_dec2: 4.9981747E-01   tau+, nutau\n|   Total width = 4.5496085E-01 GeV (computed)\n|               = 2.0490000E+00 GeV (preset)\n|   Decay options: helicity treated exactly\n\\end{code}\nSo in this case, \\whizard\\ uses 50 \\% muonic and 50 \\% tauonic decays\nof the positively charged $W$, while the $W^-$ appears directly in the\nevent file. \\whizard\\ shows the difference between the preset $W$\nwidth from the physics model file and the value computed from the two\ndecay channels.\n\nNote that a particle in a \\sindarin\\ input script can be also explictly\nmarked as being stable, using the\n\\begin{code}\nstable <particle-tag>\n\\end{code}\nconstructor for the particle \\ttt{<particle-tag>}.\n\n\n\\subsubsection{Resetting branching fractions}\n\\label{sec:br-reset}\n\nAs described above, decay processes that appear in a simulation must\nfirst be integrated by the program, either explicitly via the\n\\verb|integrate| command, or implicitly by \\verb|unstable|.  In either\ncase, \\whizard\\ will use the computed partial widths in order to\ndetermine branching fractions.  In the spirit of a purely leading-order\ncalculation, this is consistent.\n\nHowever, it may be desired to rather use different branching-fraction\nvalues for the decays of a particle, for instance, NLO-corrected\nvalues.  In fact, after \\whizard\\ has integrated any process, the\nintegration result becomes available as an ordinary\n\\sindarin\\ variable.  For instance, if a decay process has the ID\n\\verb|h_bb|, the integral of this process -- the partial width, in\nthis case -- becomes the variable \\verb|integral(h_bb)|.  This\nvariable may be reset just like any other variable:\n\\begin{code}\n  integral(h_bb) = 2.40e-3 GeV\n\\end{code}\nThe new value will be used for all subsequent Higgs branching-ratio\ncalculations and decays, if an unstable Higgs appears in a process for\nsimulation.\n\n\n\\subsubsection{Spin correlations in decays}\n\\label{sec:spin-correlations}\n\nBy default, \\whizard\\ applies full spin and color correlations to the\nfactorized processes, so it keeps both color and spin coherence between\nproductions and decays.  Correlations between decay products of distinct\nunstable particles in the same event are also fully retained.  The program\nsums over all intermediate quantum numbers.\n\nAlthough this approach obviously yields the optimal description with the\nlimits of production-decay factorization, there is support for a simplified\nhandling of particle decays.  Essentially, there are four options, taking a\ndecay \\ttt{W\\_ud}: $W^-\\to \\bar u d$ as an example:\n\\begin{enumerate}\n\\item\n  Full spin correlations: \\verb|unstable Wp (W_ud)|\n\\item\n  Isotropic decay: \\verb|unstable Wp (W_ud) { ?isotropic_decay = true }|\n\\item\n  Diagonal decay matrix:\n  \\verb|unstable Wp (W_ud) { ?diagonal_decay = true }|\n\\item\n  Project onto specific helicity:\n  \\verb|unstable Wp (W_ud) { decay_helicity = -1 }|\n\\end{enumerate}\nHere, the isotropic option completely eliminates spin correlations.  The\ndiagonal-decays option eliminates just the off-diagonal entries of the $W$\nspin-density matrix.  This is equivalent to a measurement of spin before the\ndecay.  As a result, spin correlations are still present in the classical\nsense, while quantum coherence is lost.  The definite-helicity option is\nsimilar and additional selects only the specified helicity component for the\ndecaying particle, so its decay distribution assumes the shape for an\naccordingly polarized particle.  All options apply in the rest frame of the\ndecaying particle, with the particle's momentum as the quantization axis.\n\n\\subsubsection{Automatic decays}\n\nA convenient option is if the user did not have to specify the decay\nmode by hand, but if they were generated automatically. \\whizard\\ does\nhave this option: the flag \\ttt{?auto\\_decays} can be set to\n\\ttt{true}, and is taking care of that. In that case the list for the\ndecay processes of the particle marked as unstable is left empty (we\ntake a $W^-$ again as example):\n\\begin{code}\nunstable Wm () { ?auto_decays = true }\n\\end{code}\n\\whizard\\ then inspects at the local position within the \\sindarin\\\ninput file where that \\ttt{unstable} statement appears the masses of\nall the particles of the active physics model in order to determine\nwhich decays are possible. It then calculates their partial widths.\nThere are a few options to customize the decays. The integer variable\n\\ttt{auto\\_decays\\_multiplicity} allows to set the maximal\nmultiplicity of the final states considered in the auto decay\noption. The defaul value of that variable is \\ttt{2}; please be quite\ncareful when setting this to values larger than that. If you do so,\nthe flag \\ttt{?auto\\_decays\\_radiative} allows to specify whether\nfinal states simply containing additional resolved gluons or photons\nare taken into account or not. For the example above, you almost hit\nthe PDG value for the $W$ total width:\n\\begin{code}\n| Unstable particle W-: computed branching ratios:\n|   decay_a24_1: 3.3337068E-01   d, ubar\n|   decay_a24_2: 3.3325864E-01   s, cbar\n|   decay_a24_3: 1.1112356E-01   e-, nuebar\n|   decay_a24_4: 1.1112356E-01   mu-, numubar\n|   decay_a24_5: 1.1112356E-01   tau-, nutaubar\n|   Total width = 2.0478471E+00 GeV (computed)\n|               = 2.0490000E+00 GeV (preset)\n|   Decay options: helicity treated exactly\n\\end{code}\n\n\\subsubsection{Future shorter notation for decays}\n\n{\\color{red} In an upcoming \\whizard\\ version there will be a shorter and more\n  concise notation already in the process definition for such decays,\n  which, however, is current not yet implemented. The two first examples\n  above will then be shorter and have this form:}\n  \\begin{code}\n    process wj = u, gl => (Wp => E1, n1), d\n  \\end{code}\n  {\\color{red} as well as }\n  \\begin{code}\n    process eett = e1, E1 => (t => (Wp => E2, n2), b), tbar\n  \\end{code}\n\n%%%%%\n\n\\subsection{Event formats}\n\nAs mentioned above, the internal \\whizard\\ event format is a\nmachine-dependent event format. There are a series of human-readable\nASCII event formats that are supported: very verbose formats intended\nfor debugging, formats that have been agreed upon during the Les\nHouches workshops like LHA and LHEF, or formats that are steered\nthrough external packages like HepMC. More details about event formats\ncan be found in Sec.~\\ref{sec:eventformats}.\n\n%%%%%%%%%%%%%%%\n\n\\section{Analysis and Visualization}\n\\label{sec:analysis}\n\n\\sindarin\\ natively supports basic methods of data analysis and visualization\nwhich are frequently used in high-energy physics studies.  Data generated\nduring script execution, in particular simulated event samples, can be\nanalyzed to evaluate further observables, fill histograms, and draw\ntwo-dimensional plots.\n\nSo the user does not have to rely on his/her own external graphical\nanalysis method (like e.g. \\ttt{gnuplot} or \\ttt{ROOT} etc.), but can\nuse methods that automatically ship with \\whizard. In many cases, the\nuser, however, clearly will use his/her own analysis machinery,\nespecially experimental collaborations.\n\nIn the following sections, we first summarize the available data structures,\nbefore we consider their graphical display.\n\n\n\n\\subsection{Observables}\n\nAnalyses in high-energy physics often involve averages of quantities other\nthan a total cross section.  \\sindarin\\ supports this by its \\ttt{observable}\nobjects.  An \\ttt{observable} is a container that collects a single\nreal-valued variable with a statistical distribution.  It is declared by a\ncommand of the form\n\\begin{quote}\n  \\begin{footnotesize}\n\\ttt{observable \\emph{analysis-tag}}\n  \\end{footnotesize}\n\\end{quote}\nwhere \\ttt{\\emph{analysis-tag}} is an identifier that follows the same rules\nas a variable name.\n\nOnce the observable has been declared, it can be filled with values.  This is\ndone via the \\ttt{record} command:\n\\begin{quote}\n  \\begin{footnotesize}\n\\ttt{record \\emph{analysis-tag} (\\emph{value})}\n  \\end{footnotesize}\n\\end{quote}\nTo make use of this, after values have been filled, we want to perform the\nactual analysis and display the results.  For an observable, these are the\nmean value and the standard deviation.  There is the command\n\\ttt{write\\_analysis}:\n\\begin{quote}\n  \\begin{footnotesize}\n\\ttt{write\\_analysis (\\emph{analysis-tag})}\n  \\end{footnotesize}\n\\end{quote}\n\nHere is an example:\n\\begin{quote}\n  \\begin{footnotesize}\n\\begin{verbatim}\nobservable obs\nrecord obs (1.2)  record obs (1.3)  record obs (2.1)  record obs (1.4)\nwrite_analysis (obs)\n\\end{verbatim}\n  \\end{footnotesize}\n\\end{quote}\nThe result is displayed on screen:\n\\begin{quote}\n  \\begin{footnotesize}\n\\begin{verbatim}\n###############################################################################\n# Observable: obs\naverage     =  1.500000000000E+00\nerror[abs]  =  2.041241452319E-01\nerror[rel]  =  1.360827634880E-01\nn_entries   = 4\n\\end{verbatim}\n  \\end{footnotesize}\n\\end{quote}\n\n\n\\subsection{The analysis expression}\n\\label{subsec:analysis}\n\nThe most common application is the computation of event observables -- for\ninstance, a forward-backward asymmetry -- during simulation.  To this end,\nthere is an \\ttt{analysis} expression, which behaves very similar to the\n\\ttt{cuts} expression.  It is defined either globally\n\\begin{quote}\n  \\begin{footnotesize}\n    \\ttt{analysis = \\emph{logical-expr}}\n  \\end{footnotesize}\n\\end{quote}\nor as a local option to the \\ttt{simulate} or \\ttt{rescan} commands which\ngenerate and handle event samples.  If this expression is defined, it is not\nevaluated immediately, but it is evaluated once for each event in the sample.\n\nIn contrast to the \\ttt{cuts} expression, the logical value of the\n\\ttt{analysis} expression is discarded; the expression form has been chosen\njust by analogy.  To make this useful, there is a variant of the \\ttt{record}\ncommand, namely a \\ttt{record} function with exactly the same syntax.  As an\nexample, here is a calculation of the forward-backward symmetry in a process\n\\ttt{ee\\_mumu} with final state $\\mu^+\\mu^-$:\n\\begin{quote}\n  \\begin{footnotesize}\n\\begin{verbatim}\n  observable a_fb\n  analysis = record a_fb (eval sgn (Pz) [\"mu-\"])\n  simulate (ee_mumu) { luminosity = 1 / 1 fbarn }\n\\end{verbatim}\n  \\end{footnotesize}\n\\end{quote}\nThe logical return value of \\ttt{record} -- which is discarded here -- is\n\\ttt{true} if the recording was successful.  In case of histograms (see below)\nit is true if the value falls within bounds, false otherwise.\n\nNote that the function version of \\ttt{record} can be used anywhere in\nexpressions, not just in the \\ttt{analysis} expression.\n\nWhen \\ttt{record} is called for an observable or histogram in simulation mode,\nthe recorded value is weighted appropriately.  If \\ttt{?unweighted} is true,\nthe weight is unity, otherwise it is the event weight.\n\nThe \\ttt{analysis} expression can involve any other construct\nthat can be expressed as an expression in \\sindarin.  For instance, this\nrecords the energy of the 4th hardest jet in a histogram \\ttt{pt\\_dist}, if it\nis in the central region:\n\\begin{quote}\n  \\begin{footnotesize}\n\\begin{verbatim}\n  analysis =\n    record pt_dist (eval E [extract index 4\n                             [sort by - Pt\n                               [select if -2.5 < Eta < 2.5 [colored]]]])\n\\end{verbatim}\n  \\end{footnotesize}\n\\end{quote}\nHere, if there is no 4th jet in the event which satisfies the criterion, the\nresult will be an undefined value which is not recorded.  In that case,\n\\ttt{record} evaluates to \\ttt{false}.\n\nSelection cuts can be part of the analysis expression:\n\\begin{code}\n  analysis =\n    if any Pt > 50 GeV [lepton] then\n      record jet_energy (eval E [collect [jet]])\n    endif\n\\end{code}\nAlternatively, we can specify a separate selection expression:\n\\begin{code}\n  selection = any Pt > 50 GeV [lepton]\n  analysis = record jet_energy (eval E [collect [jet]])\n\\end{code}\nThe former version writes all events to file (if requested), but\napplies the analysis expression only to the selected events.  This\nallows for the simultaneous application of different selections to a\nsingle event sample.  The latter version applies the selection to all\nevents before they are analyzed or written to file.\n\nThe analysis expression can make use of all variables and constructs that are\ndefined at the point where it is evaluated.  In particular, it can make use of\nthe particle content and kinematics of the hard process, as in the example\nabove.  In addition to the predefined variables and those defined by the user,\nthere are the following variables which depend on the hard process.  Some of\nthem are constants, some vary event by event:\n\\begin{quote}\n\\begin{tabular}{ll}\ninteger: &\\ttt{event\\_index} \\\\\ninteger: &\\ttt{process\\_num\\_id} \\\\\nstring: &\\ttt{\\$process\\_id} \\\\\ninteger: &\\ttt{n\\_in}, \\ttt{n\\_out}, \\ttt{n\\_tot} \\\\\nreal: &\\ttt{sqrts}, \\ttt{sqrts\\_hat} \\\\\nreal: &\\ttt{sqme}, \\ttt{sqme\\_ref} \\\\\nreal: &\\ttt{event\\_weight}, \\ttt{event\\_excess}\n\\end{tabular}\n\\end{quote}\nThe \\ttt{process\\_num\\_id} is the numeric ID as used by external\nprograms, while the process index refers to the current library. By\ndefault, the two are identical.  The process index itself is not\navailable as a predefined observable. The \\ttt{sqme} and\n\\ttt{sqme\\_ref} values indicate the squared matrix element and the\nreference squared matrix element, respectively.  The latter applies\nwhen comparing with a reference sample (the \\ttt{rescan} command).\n\n\\ttt{record} evaluates to a logical, so several \\ttt{record} functions may\nbe concatenated by the logical operators \\ttt{and} or \\ttt{or}.  However,\nsince usually the further evaluation should not depend on the return value of\n\\ttt{record}, it is more advisable to concatenate them by the semicolon\n(\\ttt{;}) operator.  This is an operator (\\emph{not} a statement separator or\nterminator) that connects two logical expressions and evaluates both of them\nin order.  The lhs result is discarded, the result is the value of the rhs:\n\\begin{quote}\n  \\begin{footnotesize}\n\\begin{verbatim}\n  analysis =\n    record hist_pt (eval Pt [lepton]) ; record hist_ct (eval cos (Theta) [lepton])\n\\end{verbatim}\n  \\end{footnotesize}\n\\end{quote}\n\n\n\\subsection{Histograms}\n\\label{sec:histogram}\n\nIn \\sindarin, a histogram is declared by the command\n\\begin{quote}\n  \\begin{footnotesize}\n\\ttt{histogram \\emph{analysis-tag} (\\emph{lower-bound}, \\emph{upper-bound})}\n  \\end{footnotesize}\n\\end{quote}\nThis creates a histogram data structure for an (unspecified) observable.  The\nentries are organized in bins between the real values \\ttt{\\emph{lower-bound}}\nand \\ttt{\\emph{upper-bound}}.  The number of bins is given by the value of the\nintrinsic integer variable \\ttt{n\\_bins}, the default value is 20.\n\nThe \\ttt{histogram} declaration supports an optional argument, so the number\nof bins can be set locally, for instance\n\\begin{quote}\n  \\begin{footnotesize}\n\\ttt{histogram pt\\_distribution (0 GeV, 500 GeV) \\{ n\\_bins = 50 \\}}\n  \\end{footnotesize}\n\\end{quote}\nSometimes it is more convenient to set the bin width directly.  This can be\ndone in a third argument to the \\ttt{histogram} command.\n\\begin{quote}\n  \\begin{footnotesize}\n\\ttt{histogram pt\\_distribution (0 GeV, 500 GeV, 10 GeV)}\n  \\end{footnotesize}\n\\end{quote}\nIf the bin width is specified this way, it overrides the setting of\n\\ttt{n\\_bins}.\n\nThe \\ttt{record} command or function fills histograms.  A single call\n\\begin{quote}\n  \\begin{footnotesize}\n\\ttt{record (\\emph{real-expr})}\n  \\end{footnotesize}\n\\end{quote}\nputs the value of \\ttt{\\emph{real-expr}} into the appropriate bin.  If\nthe call is issued during a simulation where \\ttt{unweighted} is false, the\nentry is weighted appropriately.\n\nIf the value is outside the range specified in the histogram declaration, it\nis put into one of the special underflow and overflow bins.\n\nThe \\ttt{write\\_analysis} command prints the histogram contents as a table in\nblank-separated fixed columns.  The columns are: $x$ (bin midpoint), $y$ (bin\ncontents), $\\Delta y$ (error), excess weight, and $n$ (number of entries).\nThe output also contains comments initiated by a \\verb|#| sign, and following\nthe histogram proper, information about underflow and overflow as well as\noverall contents is added.\n\n\n\\subsection{Plots}\n\\label{sec:plot}\n\nWhile a histogram stores only summary information about a data set, a\n\\ttt{plot} stores all data as $(x,y)$ pairs, optionally with errors.  A plot\ndeclaration is as simple as\n\\begin{quote}\n  \\begin{footnotesize}\n\\ttt{plot \\emph{analysis-tag}}\n  \\end{footnotesize}\n\\end{quote}\nLike observables and histograms, plots are filled by the \\ttt{record} command\nor expression.  To this end, it can take two arguments,\n\\begin{quote}\n  \\begin{footnotesize}\n\\ttt{record (\\emph{x-expr}, \\emph{y-expr})}\n  \\end{footnotesize}\n\\end{quote}\nor up to four:\n\\begin{quote}\n  \\begin{footnotesize}\n\\ttt{record (\\emph{x-expr}, \\emph{y-expr}, \\emph{y-error})}\n\\\\\n\\ttt{record (\\emph{x-expr}, \\emph{y-expr},\n  \\emph{y-error-expr}, \\emph{x-error-expr})}\n  \\end{footnotesize}\n\\end{quote}\nNote that the $y$ error comes first.  This is because applications will\ndemand errors for the $y$ value much more often than $x$ errors.\n\nThe plot output, again written by \\ttt{write\\_analysis} contains the four\nvalues for each point, again in the ordering $x,y,\\Delta y, \\Delta x$.\n\n\n\\subsection{Analysis Output}\n\nThere is a default format for piping information into observables,\nhistograms, and plots. In older versions of \\whizard\\ there was a\nfirst version of a custom format, which was however rather limited.\nA more versatile custom output format will be coming soon.\n\n\\begin{enumerate}\n\\item\nBy default, the \\ttt{write\\_analysis} command prints all data to the\nstandard output. The data are also written to a default file with the\nname \\ttt{whizard\\_analysis.dat}.\nOutput is redirected to a file with a different name if the\nvariable \\ttt{\\$out\\_file} has a nonempty value.  If the file is\nalready open, the output will be appended to\nthe file, and it will be kept open.  If the file is not open,\n\\ttt{write\\_analysis} will open the output file by itself, overwriting any\nprevious file with the same name, and close it again after data have been\nwritten.\n\nThe command is able to print more than one dataset, following the syntax\n\\begin{quote}\n  \\begin{footnotesize}\n  \\ttt{write\\_analysis (\\emph{analysis-tag1}, \\emph{analysis-tag2}, \\ldots)\n  \\{ \\emph{options} \\}}\n  \\end{footnotesize}\n\\end{quote}\nThe argument in brackets may also be empty or absent; in this case, all\ncurrently existing datasets are printed.\n\nThe default data format is suitable for compiling analysis data by \\whizard's\nbuilt-in \\gamelan\\ graphics driver (see below and particularly\nChap.~\\ref{chap:visualization}).  Data are written in\nblank-separated fixed columns, headlines and comments are initiated by the\n\\verb|#| sign, and each data set is terminated by a blank line.  However,\nexternal programs often require special formatting.\n\nThe internal graphics driver \\gamelan\\ of \\whizard\\ is initiated by\nthe \\ttt{compile\\_analysis} command. Its syntax is the same, and it\ncontains the \\ttt{write\\_analysis} if that has not been separately\ncalled (which is unnecessary). For more details about the \\gamelan\\\ngraphics driver and data visualization within \\whizard, confer\nChap.~\\ref{chap:visualization}.\n\n\\item\nCustom format. Not yet (re-)implemented in a general form.\n\\end{enumerate}\n\n\n\\section{Custom Input/Output}\n\\label{sec:I/O}\n\n\\whizard\\ is rather chatty.  When you run examples or your own scripts, you\nwill observe that the program echoes most operations (assignments, commands,\netc.) on the standard output channel, i.e., on screen.  Furthermore, all\nscreen output is copied to a log file which by default is named\n\\ttt{whizard.log}.\n\nFor each integration run, \\whizard\\ writes additional process-specific\ninformation to a file \\ttt{\\var{tag}.log}, where \\ttt{\\var{tag}} is the\nprocess name.  Furthermore, the \\ttt{write\\_analysis} command dumps analysis\ndata -- tables for histograms and plots -- to its own set of files, cf.\\\nSec.~\\ref{sec:analysis}.\n\nHowever, there is the occasional need to write data to extra files in a custom\nformat.  \\sindarin\\ deals with that in terms of the following commands:\n\n\\subsection{Output Files}\n\n\\subsubsection{open\\_out}\n\\begin{syntax}\nopen\\_out (\\var{filename}) \\\\\nopen\\_out (\\var{filename}) \\{ \\var{options} \\}\n\\end{syntax}\nOpen an external file for writing.  If the file exists, it is overwritten\nwithout warning, otherwise it is created.  Example:\n\\begin{code}\nopen_out (\"my_output.dat\")\n\\end{code}\n\n\n\\subsubsection{close\\_out}\n\\begin{syntax}\nclose\\_out (\\var{filename}) \\\\\nclose\\_out (\\var{filename}) \\{ \\var{options} \\}\n\\end{syntax}\nClose an external file that is open for writing.  Example:\n\\begin{code}\nclose_out (\"my_output.dat\")\n\\end{code}\n\n\n\\subsection{Printing Data}\n\n\\subsubsection{printf}\n\\begin{syntax}\nprintf \\var{format-string-expr} \\\\\nprintf \\var{format-string-expr} (\\var{data-objects})\n\\end{syntax}\nFormat \\ttt{\\var{data-objects}} according to \\ttt{\\var{format-string-expr}}\nand print the resulting string to standard output if the string variable\n\\ttt{\\$out\\_file} is undefined.  If \\ttt{\\$out\\_file} is defined and the file\nwith this name is open for writing, print to this file instead.\n\nPrint a newline at the end if \\ttt{?out\\_advance} is true, otherwise don't\nfinish the line.\n\nThe \\ttt{\\var{format-string-expr}} must evaluate to a string.  Formatting\nfollows a subset of the rules for the \\ttt{printf(3)} command in the \\ttt{C}\nlanguage.  The supported rules are:\n\\begin{itemize}\n\\item All characters are printed as-is, with the exception of embedded\n  conversion specifications.\n\\item Conversion specifications are initiated by a percent (\\verb|%|) sign and\n  followed by an optional prefix flag, an optional integer value, an optional\n  dot followed by another integer, and a mandatory letter as the conversion\n  specifier.\n\\item A percent sign immediately followed by another percent sign is\n  interpreted as a single percent sign, not as a conversion specification.\n\\item The number of conversion specifiers must be equal to the number of data\n  objects.  The data types must also match.\n\\item The first integer indicates the minimum field width, the second one the\n  precision.  The field is expanded as needed.\n\\item The conversion specifiers \\ttt{d} and \\ttt{i} are equivalent, they\n  indicate an integer value.\n\\item The conversion specifier \\ttt{e} indicates a real value that should be\n  printed in exponential notation.\n\\item The conversion specifier \\ttt{f} indicates a real value that should be\n  printed in decimal notation without exponent.\n\\item The conversion specifier \\ttt{g} indicates a real value that should be\n  printed either in exponential or in decimal notation, depending on its\n  value.\n\\item The conversion specifier \\ttt{s} indicates a logical or string value\n  that should be printed as a string.\n\\item Possible prefixes are \\verb|#| (alternate form, mandatory decimal point\n  for reals), \\verb|0| (zero padding), \\verb|-| (left adjusted), \\verb|+|\n  (always print sign), `\\verb| |' (print space before a positive number).\n\\end{itemize}\nFor more details, consult the \\verb|printf(3)| manpage.  Note that other\nconversions are not supported and will be rejected by \\whizard.\n\nThe data arguments are numeric, logical or string variables or expressions.\nNumeric expressions must be enclosed in parantheses.  Logical expressions must\nbe enclosed in parantheses prefixed by a question mark \\verb|?|.  String\nexpressions must be enclosed in parantheses prefixed by a dollar sign\n\\verb|$|.  These forms behave as anonymous variables.\n\nNote that for simply printing a text string, you may call \\ttt{printf} with\njust a format string and no data arguments.\n\nExamples:\n\\begin{code}\nprintf \"The W mass is %8f GeV\" (mW)\n\nint i = 2\nint j = 3\nprintf \"%i + %i = %i\" (i, j, (i+j))\n\nstring $directory = \"/usr/local/share\"\nstring $file = \"foo.dat\"\nprintf \"File path: %s/%s\" ($directory, $file)\n\\end{code}\nThere is a related \\ttt{sprintf} function, cf.~Sec.~\\ref{sec:sprintf}.\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n\\section{WHIZARD at next-to-leading order}\n\\subsection{Prerequisites}\nA full NLO computation requires virtual matrix elements obtained from\nloop diagrams. Since \\oMega\\ cannot calculate such diagrams, external\nprograms are used.  \\whizard\\ has a generic interface to matrix-element\ngenerators that are BLHA-compatible.\nExplicit implementations exist for \\gosam, \\openloops\\ and \\recola.\n\n%%%%%\n\n\\subsubsection{Setting up \\gosam}\n\nThe installation of \\gosam\\ is detailed on the HepForge page\n\\url{https://gosam/hepforge.org}.  We mention here some of the steps\nnecessary to get it to be linked with \\whizard.\n\n{\\bf Bug in \\gosam\\ installation scripts:} In many versions of\n\\gosam\\ there is a bug in the installation scripts that is only\nrelevant if \\gosam\\ is installed with superuser privileges. Then all\nfiles in \\ttt{\\$installdir/share/golem} do not have read privileges\nfor normal users. These privileges must be given manually to all files\nin that directory.\n\nPrerequisites for \\gosam\\ to produce code for one-loop matrix elements\nare the scientific algebra program \\ttt{form} and the generator of\nloop topologies and diagrams, \\ttt{qgraf}.\nThese can be accessed via their respective webpages\n\\url{http://www.nikhef.nl/~form/} and\n\\url{http://cfif.ist.utl.pt/~paulo/qgraf.html}. Note also that both\n\\ttt{Java} and the Java runtime environment have to be installed in\norder for \\gosam\\ to properly work.  Furthermore, \\ttt{libtool}\nneeds to be installed.  A more convenient way to install \\gosam, is the\nautomatic installation script\n\\url{https://gosam.hepforge.org/gosam_installer.py}.\n\n%%%%%\n\n\\subsubsection{Setting up \\openloops}\n\\label{sec:openloops-setup}\n\nThe installation of \\openloops\\ is explained in detail on the HepForge\npage \\url{https://openloops.hepforge.org}.  In the following, the main\nsteps for usage with \\whizard\\ are summarized.\n\nPlease note that at the moment, \\openloops\\ cannot be installed such\nthat in almost all cases the explicit \\openloops\\ package directory\nhas to be set via \\ttt{--with-openloops=<openloops\\_dir>}.\n\n\\openloops\\ can be checked out with\n\\begin{code}\n  git clone https://gitlab.com/openloops/OpenLoops.git\n\\end{code}\nNote that \\whizard\\ only supports \\openloops\\ version that are at\nleast 2.1.1 or newer. Alternatively, one can use the public beta\nversion of \\openloops, which can be checked out by the command\n\\begin{code}\n  git clone -b public_beta https://gitlab.com/openloops/OpenLoops.git\n\\end{code}\nThe program can be build by running \\ttt{scons} or \\ttt{./scons}, a\nlocal version that is included in the \\openloops\\ directory.  This\nproduces the script \\ttt{./openloops}, which is the main hook for the\nfurther usage of the program.\n\n\\openloops\\ works by downloading prebuild process libraries, which have\nto be installed for each individual process. This requires the file\n\\ttt{openloops.cfg}, which should contain\nthe following content:\n\\begin{code}\n   [OpenLoops]\n   process_repositories=public, whizard\n   compile_extra=1\n\\end{code}\nThe first line instructs \\openloops\\ to also look for process libraries\nin an additional lepton collider repository.  The second line triggers\nthe inclusion of $N+1$-particle tree-level matrix elements in the\nprocess directory, so that a complete NLO calculation including real\namplitudes can be performed only with \\openloops.\n\nThe libraries can then be installed via\n\\begin{code}\n   ./openloops libinstall proc_name\n\\end{code}\nA list of supported library names can be found on the \\openloops\\ web\npage.  Note that a process library also includes all possible permutated\nprocesses.  The process library \\ttt{ppllj}, for example, can also be\nused to compute the matrix elements for $e^+ e^- \\rightarrow q \\bar{q}$\n(massless quarks only).  The massive case of the top quark is handled in\n\\ttt{eett}.  Additionally, there are process libraries for top and gauge\nboson decays, \\ttt{tbw}, \\ttt{vjj}, \\ttt{tbln} and \\ttt{tbqq}.\n\nFinally, \\openloops\\ can be linked to \\whizard\\ during configuration by\nincluding\n\\begin{code}\n  --enable-openloops --with-openloops=$OPENLOOPS_PATH,\n\\end{code}\nwhere \\ttt{\\$OPENLOOPS\\_PATH} is the directory the \\openloops\\\nexecutable is located in.  \\openloops\\ one-loop diagrams can then be\nused with the \\sindarin\\ option\n\\begin{code}\n  $loop_me_method = \"openloops\".\n\\end{code}\nThe functional tests which check the \\openloops\\ functionality require\nthe libraries \\ttt{ppllj}, \\ttt{eett} and \\ttt{tbw} to be installed (note\nthat \\ttt{eett} is not contained in \\ttt{ppll}).  During the\nconfiguration of \\whizard, it is automatically checked that these two\nlibraries, as well as the option \\ttt{compile\\_extra=1}, are present.\n\n\\subsubsection{\\openloops\\ \\sindarin\\ flags}\nSeveral \\sindarin\\ options exist to control the behavior of \\openloops.\n\\begin{itemize}\n  \\item \\ttt{openloops\\_verbosity}:\\\\\n    Decide how much \\openloops\\ output is printed. Can have values 0, 1\n    and 2.\n  \\item \\ttt{?openloops\\_use\\_cms}:\\\\\n    Activates the complex mass scheme. For computations with decaying\n    resonances like the top quark or W or Z bosons, this is the\n    preferred option to avoid gauge-dependencies.\n  \\item \\ttt{openloops\\_phs\\_tolerance}:\\\\\n    Controls the exponent of \\ttt{extra psp\\_tolerance} in the BLHA\n    interface, which is the numerical tolerance for the on-shell\n    condition of external particles\n  \\item \\ttt{openloops\\_switch\\_off\\_muon\\_yukawa}:\\\\\n    Sets the Yukawa coupling of muons to zero in order to assure\n    agreement with \\oMega, which is possibly used for other\n    components and per default does not take $H\\mu\\mu$ couplings\n    into account.\n  \\item \\ttt{openloops\\_stability\\_log}:\\\\\n    Creates the directory \\ttt{stability\\_log}, which contains information\n    about the performance of the matrix elements. Possible values are\n    \\begin{itemize}\n    \\item 0: No output (default),\n    \\item 1: On finish() call,\n    \\item 2: Adaptive,\n    \\item 3: Always\n   \\end{itemize}\n  \\item \\ttt{?openloops\\_use\\_collier}: Use Collier as the reduction\n    method (default true).\n\\end{itemize}\n\n%%%%%\n\n\\subsubsection{Setting up \\recola}\n\\label{sec:recola-setup}\n\nThe installation of \\recola\\ is explained in detail on the HepForge page\n\\url{https://recola.hepforge.org}. In the following the main steps for\nusage with \\whizard\\ are summarized. The minimal required version number\nof \\recola\\ is 1.3.0.\n\n\\recola\\ can be linked to \\whizard\\ during configuration by including\n\\begin{code}\n  --enable-recola\n\\end{code}\nIn case the \\recola\\ library is not in a standard path or a path\naccessible in the \\ttt{LD\\_LIBRARY\\_PATH} (or\n\\ttt{DYLD\\_LIBRARY\\_PATH}) of the operating system, then the option\n\\begin{code}\n   --with-recola=$RECOLA_PATH\n\\end{code}\ncan be set, where \\ttt{\\$RECOLA\\_PATH} is the directory the\n\\recola\\ library is located in. \\recola\\ can then be used with the\n\\sindarin\\ option\n\\begin{code}\n  $method = \"recola\"\n\\end{code}\nor any other of the matrix element methods.\n\nNote that there might be a clash of the \\collier\\ libraries when you\nhave \\collier\\ installed both via \\recola\\ and via \\openloops, but\nhave compiled them with different \\fortran\\ compilers.\n\n%%%%%\n\n\\subsection{NLO cross sections}\nAn NLO computation can be switched on in \\sindarin\\ with\n\\begin{code}\n  process proc_nlo = in1, in2 => out1, ..., outN { nlo_calculation = <components> },\n\\end{code}\nwhere the \\ttt{nlo\\_calculation} can be followed by a list of strings\nspecifying the desired NLO-components to be integrated, i.e.\n\\ttt{born}, \\ttt{real}, \\ttt{virtual}, \\ttt{dglap}, (for hadron\ncollisions) or \\ttt{mismatch} (for the soft mismatch in\nresonance-aware computations) and \\ttt{full}. The \\ttt{full} option\nswitches on all components and is required if the total NLO result is\ndesired. For example, specifying\n\\begin{code}\n  nlo_calculation = born, virtual\n\\end{code}\nwill result in the computation of the Born and virtual component.\n\nThe integration can be carried out in two different modes: Combined\nand separate integration.  In the separate integration mode, each\ncomponent is integrated individually, allowing for a good overview of\ntheir contributions to the total cross section and a fine tuned\ncontrol over the iterations in each component.  In the combined\nintegration mode, all components are added up during integration so that\nthe sum of them is evaluated.  Here, only one integration will be\ndisplayed.  The default method is the separate integration.\n\nThe convergence of the integration can crucially be influenced by the\npresence of resonances.  A better convergence is in this case achieved\nactivating the resonance-aware FKS subtraction,\n\\begin{code}\n  $fks_mapping_type = \"resonances\".\n\\end{code}\nThis mode comes with an additional integration component, the\nso-called soft mismatch.\n\nNote that you can modify the number of iterations in each component with\nthe multipliers:\n\\begin{itemize}\n  \\item \\ttt{mult\\_call\\_real} multiplies the number of calls to be used\n    in the integration of the real component. A reasonable choice is\n    \\ttt{10.0} as the real phase-space is more complicated than the Born\n    but the matrix elements evaluate faster than the virtuals.\n  \\item \\ttt{mult\\_call\\_virt} multiplies the number of calls to be used\n    in the integration of the virtual component. A reasonable choice is\n    \\ttt{0.5} to make sure that the fast Born component only contributes\n    a negligible MC error compared to the real and virtual components.\n  \\item \\ttt{mult\\_call\\_dglap} multiplies the number of calls to be used\n    in the integration of the DGLAP component.\n\\end{itemize}\n\n\\subsection{Fixed-order NLO events}\n\\label{ss:fixedorderNLOevents}\nFixed-order NLO events can also be produced in three different modes:\nCombined weighted, combined unweighted and separated weighted.\n\\begin{itemize}\n  \\item \\textbf{Combined weighted}\\\\\n    In the combined mode, one single integration grid is produced, from\n    which events are generated with the total NLO weight. The\n    corresponding event file contains $N$ events with born-like\n    kinematics and weight equal to $\\mathcal{B} + \\mathcal{V} +\n    \\sum_{\\alpha_r} \\mathcal{C}_{\\alpha_r}$, where $\\mathcal{B}$ is the\n    Born matrix element, $\\mathcal{V}$ is the virtual matrix element and\n    $\\mathcal{C}_{\\alpha_r}$ are the subtraction terms in each singular\n    region. For resonance-aware processes, also the mismatch value is\n    added. Each born-like event is followed by $N_{\\text{phs}}$\n    associated events with real kinematics, i.e. events where one\n    additional QCD particle is present. The corresponding real\n    matrix elements $\\mathcal{R}_\\alpha$ form the weight of these events.\n    $N_{\\text{phs}}$ is the number of distinct phase spaces. Two phase spaces\n    are distinct if they have different resonance histories and/or have\n    different emitters. So, two $\\alpha_r$ can share the same phase\n    space index.\n\n    The combined event mode is activated by\n    \\begin{code}\n      ?combined_nlo_integration = true\n      ?unweighted = false\n      ?fixed_order_nlo_events = true\n    \\end{code}\n    Moreover, the process must be specified at next-to-leading-order in its\n    definition using \\ttt{nlo\\_calculation = full}.  \\whizard\\ then\n    proceeds as in the usual simulation mode. I.e. it first checks\n    whether integration grids are already present and uses them if they\n    fit. Otherwise, it starts an integration.\n  \\item \\textbf{Combined unweighted}\\\\\n    The unweighted combined events can be generated by using the\n    \\powheg\\ mode, cf. also the next subsection, but disabling the\n    additional radiation and Sudakov factors with the\n    \\ttt{?powheg\\_disable\\_sudakov} switch:\n    \\begin{code}\n      ?combined_nlo_integration = true\n      ?powheg_matching = true\n      ?powheg_disable_sudakov = true\n    \\end{code}\n    This will produce events with Born kinematics and unit weights (as\n    \\ttt{?unweighted} is \\ttt{true} by default).  The events are\n    unweighted by using $\\mathcal{B} + \\mathcal{V} + \\sum_{\\alpha_r}\n    (\\mathcal{C}_{\\alpha_r} + \\mathcal{R}_{\\alpha_r})$.  Of course, this\n    only works when these weights are positive over the full\n    phase-space, which is not guaranteed for all scales and regions at\n    NLO.  However, for many processes perturbation theory works nicely\n    and this is not an issue.\n\n  \\item \\textbf{Separate weighted}\\\\\n    In the separate mode, grids and events are generated for each\n    individual component of the NLO process. This method is preferable\n    for complicated processes, since it allows to individually tune each\n    grid generation. Moreover, the grid generation is then trivially\n    parallelized.  The event files either contain only Born\n    kinematics with weight $\\mathcal{B}$ or $\\mathcal{V}$ (and mismatch\n    in case of a resonance-aware process) or mixed Born and real\n    kinematics for the real component like in the combined mode.\n    However, the Born events have only the weight $\\sum_{\\alpha_r}\n    \\mathcal{C}_{\\alpha_r}$ in this case.\n\n    The separate event mode is activated by\n    \\begin{code}\n      ?unweighted = false\n      ?negative_weights = true\n      ?fixed_order_nlo_events = true\n    \\end{code}\n    Note that negative weights have to be switched on because, in contrast\n    to the combined mode, the total cross sections of the individual\n    components can be negative.\n\n    Also, the desired component has to appear in the process NLO\n    specification, e.g. using \\ttt{nlo\\_calculation = real}.\n\\end{itemize}\nWeighted fixed-order NLO events are supported by any output format that\nsupports weights like the \\ttt{HepMC} format and unweighted NLO events\nwork with any format. The output can either be written to disk or put\ninto a FIFO to interface it to an analysis program without writing\nevents to file.\n\nThe weights in the real event output, both in the combined and separate\nweighted mode, are divided by a factor $N_{\\text{phs}} + 1$. This\nis to account for the fact that we artificially increase the number of\nevents in the output file.  Thus, the sum of all event weights correctly\nreproduces the total cross section.\n\n\\subsection{\\powheg\\ matching}\nTo match the NLO computation with a parton shower, \\whizard\\ supports\nthe  \\powheg\\ matching.  It generates a distribution according to\n\\begin{align}\n  \\label{eq:powheg}\n  \\text{d}\\sigma &= \\text{d}\\Phi_n \\,{\\bar{B}_{\\text{s}}}\\,\\biggl(\n  {\\Delta_{\\text{s}}}(p_T^{\\text{min}}\\bigr) +\n  \\text{d}\\Phi_{\\text{rad}}\\,{\\Delta_{\\text{s}}}(k_{\\text{T}}(\\Phi_{\\text{rad}})\\bigr)\n  {\\frac{R_{\\text{s}}}B}\\biggr) \\quad \\text{where} \\\\\n  {\\bar{B}_{\\text{s}}} &= {B} + {\\mathcal{V}} + \\text{d}\\Phi_{\\text{rad}}\\,\n    {\\mathcal{R}_{\\text{s}}} \\quad \\text{and} \\\\\n  {\\Delta_{\\text{s}}}(p_T) &= \\exp\\left[- \\int{\\text{d}\\Phi_{\\text{rad}}}\n   {\\frac{R_{\\text{s}}}{B}}\\; \\theta\\left(k_T^2(\\Phi_{\\text{rad}}) -\n   p_T^2\\right)\\right]\\;.\n\\end{align}\nThe subscript s refers to the singular part of the real component, cf.\nto the next subsection.  Eq.~\\eqref{eq:powheg} produces either no or one\nadditional emission.  These events can then either be analyzed directly\nor passed on to the parton shower\\footnote{E.g. \\pythiaeight\\ has\nexplicit examples for \\powheg\\ input, see also\n\\url{http://home.thep.lu.se/Pythia/pythia82html/POWHEGMerging.html}.}\nfor the full simulation.  You activate this with\n\\begin{code}\n  ?fixed_order_nlo_events = false\n  ?combined_nlo_integration = true\n  ?powheg_matching = true\n\\end{code}\nThe $p_T^{\\text{min}}$ of Eq.~\\eqref{eq:powheg} can be set with\n\\ttt{powheg\\_pt\\_min}.  It sets the minimal scale for the \\powheg\\\nevolution and should be of order 1 GeV and set accordingly in the\ninterfaced shower.  The maximal scale is currently given by \\ttt{sqrts}\nbut should in the future be changeable with \\ttt{powheg\\_pt\\_max}.\n\nNote that the \\powheg\\ event generation needs an additional grid for\nefficient event generation that is automatically generated during\nintegration.  Further options that steer the efficiency of this grid are\n\\ttt{powheg\\_grid\\_size\\_xi} and \\ttt{powheg\\_grid\\_size\\_y}.\n\n\\subsection{Separation of finite and singular contributions}\n\nFor both the pure NLO computations as well as the \\powheg\\ event\ngeneration, \\whizard\\ supports the partitioning of the real into finite\nand singular contributions with the flag\n\\begin{code}\n  ?nlo_use_real_partition = true\n\\end{code}\nThe finite contributions, which by definition should not contain soft or\ncollinear emissions, will then integrate like a ordinary LO integration\nwith one additional particle.  Similarly, the event generation will\nproduce only real events without subtraction terms with Born kinematics\nfor this additional finite component.  The \\powheg\\ event generation\nwill also only use the singular parts.\n\nThe current implementation uses the following parametrization\n\\begin{align}\n  R                 &= R_{\\text{fin}} + R_{\\text{sing}} \\;,\\\\\n  R_{\\text{sing}}     &= R F(\\Phi_{n+1}) \\;,\\\\\n  R_{\\text{fin}}      &= R (1-F(\\Phi_{n+1})) \\;,\\\\\n  F(\\Phi_{n+1})     &=\n  \\begin{cases}\n    1 & \\text{if} \\quad\\exists\\,(i,j)\\in\\mathcal{P}_{\\text{FKS}}\\quad \\text{with} \\quad\n      \\sqrt{(p_i+p_j)^2} < h + m_i + m_j  \\\\\n    0 & \\text{else}\n  \\end{cases} \\;.\n\\end{align}\nThus, a point is {singular ($F=1$)}, if {any} of the {FKS tuples}\nforms an {invariant mass} that is {smaller than the hardness scale\n$h$}. This parameter is controlled in \\sindarin\\ with\n\\ttt{real\\_partition\\_scale}.\nThis simplifies in {massless case} to\n\\begin{align}\n  F(\\Phi_{n+1}) =\n  \\begin{cases}\n    1 & \\text{if} \\;\\exists\\,(i,j)\\in\\mathcal{P}_{\\text{FKS}}\\quad \\text{with} \\quad\n      2 E_i E_j (1-\\cos\\theta_{ij}) < h^2  \\\\\n    0 & \\text{else}\n  \\end{cases} \\;.\n\\end{align}\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n\\chapter{Random number generators}\n\\label{chap:rng}\n\n\\section{General remarks}\n\\label{sec:rng}\n\nThe random number generators (RNG) are one of the crucialer points of Monte\nCarlo calculations, hence, giving those their ``randomness''. A decent\nmultipurpose random generator covers\n\\begin{itemize}\n\\item reproducibility\n\\item large period\n\\item fast generation\n\\item independence\n\\end{itemize}\nof the random numbers. Therefore, special care is taken for the choice of the\nRNGs in \\whizard{}. It is stated that \\whizard{} utilizes \\textit{pseudo}-RNGs,\nwhich are based on one (or more) recursive algorithm(s) and start-seed(s) to have\nreproducible sequences of numbers. In contrast, a genuine random generator relies\non physical processes.\n\n\\whizard\\ ships with two completely different random number generators which can be\nselected by setting the \\sindarin\\ option\n\\begin{code}\n  $rng_method = \"rng_tao\"\n\\end{code}\nAlthough, \\whizard{} sets a default seed, it is adviced to use a different one\n\\begin{code}\n  seed = 175368842\n\\end{code}\nnote that some RNGs do not allow certain seed values (e.g. zero seed).\n\n\\section{The TAO Random Number Generator}\n\\label{sec:tao}\n\nThe TAO (``The Art Of'') random number generator is a lagged Fibonacci\ngenerator based upon (signed) 32-bit integer arithmetic and was proposed by\nDonald E. Knuth and is implemented in the \\vamp\\ package.\nThe TAO random number generator is the default RNG of \\whizard{}, but can additionally\nbe set as \\sindarin\\ option\n\\begin{code}\n  $rng_method = rng_tao\n\\end{code}\n\nThe TAO random number generators is a subtractive lagged Fibonacci generator\n\\begin{equation*}\n  x_{j} = \\left( x_{j-k} - x_{j-L} \\right) \\mod 2^{30}\n\\end{equation*}\nwith lags $k = 100$ and $l = 37$ and period length $\\rho = 2^{30} - 2$.\n\n\\section{The RNGStream Generator}\n\\label{sec:rngstream}\n\nThe RNGStream \\cite{L_Ecuyer:2002} was originally implemented in \\cpp\\ with\nfloating point arithmetic and has been ported to \\fortranOThree{}. The RNGstream\ncan be selected by the \\sindarin\\ option\n\\begin{code}\n  $rng_method = \"rng_stream\"\n\\end{code}\n\nThe RNGstream supports multiple independent streams and substreams of random\nnumbers which can be directly accessed.\n\nThe main advantage of the RNGStream lies in the domain of parallelization where\ndifferent worker have to access different parts of the random number stream to\nensure numerical reproducibility. The RNGstream provides exactly this property with its\n(sub)stream-driven model.\n\nUnfortunately, the RNGStream can only be used in combination with \\vamptwo{}.\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n\\chapter{Integration Methods}\n\n\\section{The Monte-Carlo integration routine: \\ttt{VAMP}}\n\\label{sec:vamp}\n\n\\vamp\\ \\cite{Ohl:1998jn}\nis a multichannel extension of the \\vegas\\ \\cite{Lepage:1980dq}\nalgorithm. For all possible singularities in the integrand, suitable\nmaps and integration channels are chosen which are then weighted and\nsuperimposed to build the phase space parameterization. Both grids and\nweights are modified in the adaption phase of the integration.\n\nThe multichannel integration algorithm is implemented as a\n\\fortranNinetyFive\\ library with the task of mapping out the integrand\nand finding suitable parameterizations being completely delegated to\nthe calling program (\\whizard\\ core in this case). This makes the\nactual \\vamp\\ library completely agnostic of the model under\nconsideration.\n\n\\section{The next generation integrator: \\ttt{VAMP2}}\n\\label{sec:vamp2}\n\n\\vamptwo\\ is a modern implementation of the integrator package \\vamp\\ written\nin \\fortranOThree\\, providing the same features. The backbone integrator is\nstill \\vegas\\ \\cite{Lepage:1980dq}, although implemented differently as in\n\\vamp{}.\n\nThe main advantage over \\vamp\\ is the overall faster integration due to the usage\nof \\fortranOThree{}, the possible usage of different random number generators\nand the complete parallelization of \\vegas\\ and the multichannel integration.\n\n\\vamptwo{} can be set by the \\sindarin{} option\n\\begin{code}\n  $integration_method = \"vamp2\"\n\\end{code}\n\nIt is said that the generated grids between \\vamp{} and \\vamptwo{} are\nincompatible.\n\n\\subsection{Multichannel integration}\n\\label{sec:multi-channel}\n\nThe usual matrix elements do not factorise with respect to their integration\nvariables, thus making an direct integration ansatz with VEGAS\nunfavorable.\\footnote{One prerequisite for the VEGAS algorithm is that the\n  integral factorises, and such produces only the best results for those.} Instead, we\napply the multichannel ansatz and let VEGAS integrate each channel in a\nfactorising mapping.\n\nThe different structures of the matrix element are separated by a partition of\nunity and the respective mappings, such that each structure factorise at least\nonce. We define the mappings $\\phi_i : U \\mapsto \\Omega$, where $U$ is the unit\nhypercube and $\\Omega$ the physical phase space. We refer to each mapping as a\n\\textit{channel}. Each channel then gives rise to a probability density $g_i : U\n\\mapsto [0, \\infty)$, normalised to unity\n\\begin{equation*}\n  \\int_0^1 g_i(\\phi_i^{-1}(p)) \\left| \\frac{\\partial \\phi_i^{-1}}{\\partial p} \\right| \\mathrm{d}\\mu(p) = 1, \\quad g_i(\\phi_i^{-1}(p)) \\geq 0,\n\\end{equation*}\nwritten for a phase space point $p$ using the mapping $\\phi_i$.\nThe \\textit{a-priori} channel weights $\\alpha_i$ are defined as partition of\nunity by $\\sum_{i\\in I} \\alpha_i = 1$ and $0 \\leq \\alpha_i \\leq 1$. The overall\nprobability density $g$ of a random sample is then obtained by\n\\begin{equation*}\n  g(p) = \\sum_{i \\in I} \\alpha_i g_i(\\phi_i^{-1}(p)) \\left| \\frac{\\partial \\phi_i^{-1}}{\\partial p} \\right|,\n\\end{equation*}\nwhich is also a non-negative and normalized probability density.\n\nWe reformulate the integral\n\\begin{equation*}\n  I(f) = \\sum_{i \\in I} \\alpha_i \\int_\\Omega g_i(\\phi_i^{-1}(p)) \\left| \\frac{\\partial \\phi_i^{-1}}{\\partial p} \\right| \\frac{f(p)}{g(p)} \\mathrm{d}\\mu(p).\n\\end{equation*}\nThe actual integration of each channel is then done by VEGAS, which shapes the $g_i$.\n\n\\subsection{VEGAS}\n\\label{sec:vegas}\n\nVEGAS is an adaptive and iterative Monte Carlo algorithm for integration using\nimportance sampling. After each iteration, VEGAS adapts the probability density\n$g_i$ using information collected while sampling. For independent\nintegration variables, the probability density factorises $g_i = \\prod_{j =\n  1}^{d} g_{i,j}$ for each integration axis and each (independent) $g_{i,j}$ is\ndefined by a normalised step function\n\\begin{equation*}\n  g_{i,j} (x_j) = \\frac{1}{N\\Delta x_{j,k}}, \\quad x_{j,k} - \\Delta x_{j,k} \\leq x_{j} < x_{j,k},\n\\end{equation*}\nwhere the steps are $0 = x_{j, 0} < \\cdots < x_{j,k} < \\cdots < x_{j,N} = 1$ for\neach dimension $j$.\nThe algorithm randomly selects for each dimension a bin and a position inside\nthe bin and calculates the respective $g_{i,j}$.\n\n\\subsection{Channel equivalences}\n\\label{sec:equivalences}\n\nThe automated mulitchannel phasespace configuration can lead to a surplus of\ndegrees of freedom, e.g. for a highly complex process with a large number of\nchannels (VBS). In order to marginalize the redundant degrees of freedom of\nphasespace configuration, the adaptation distribution of the grids are aligned in accordance to their\nphasespace relation, hence the binning of the grids is equialized. These equivalences are activated by\ndefault for \\vamp{} and \\vamptwo{}, but can be steered by:\n\n\\begin{code}\n  ?use_vamp_equivalences = true\n\\end{code}\n\nBe aware, that the usage of equivalences are currently only possible for LO\nprocesses.\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n\\chapter{Phase space parameterizations}\n\n\\section{General remarks}\n\n\\whizard\\ as a default performs an adaptive multi-channel Monte-Carlo\nintegration. Besides its default phase space algorithm, \\ttt{wood}, to\nbe detailed in Sec.~\\ref{sec:wood}, \\whizard\\ contains a phase space\nmethod \\ttt{phs\\_none} which is a dummy method that is intended for\nsetups of processes where no phase space integration is needed, but\nthe program flow needs a (dummy) integrator for internal\nconsistency. Then, for testing purposes, there is a single-channel\nphase space integrator, \\ttt{phs\\_single}. From version 2.6.0 of\n\\whizard\\ on, there is also a second implementation of the \\ttt{wood}\nphase space algorithm, called \\ttt{fast\\_wood},\ncf. Sec.~\\ref{sec:fast_wood}, whose implementation differs technically\nand which therefore solves certain technical flaws of the \\ttt{wood}\nimplementation.\nAdditionally, \\whizard\\ supports single-channel, flat phase-space using RAMBO\n(on diet).\n\n%%%\n\n\\section{The flat method: \\ttt{rambo}}\n\\label{sec:rambo}\n\nThe \\ttt{RAMBO} algorithm produces a flat phase-space with constant volume for\nmassless particles. \\ttt{RAMBO} was originally published in\n\\cite{Kleiss:1985gy}. We use the slim version, called \\ttt{RAMBO} on diet,\npublished in \\cite{Platzer:2013esa}.\nThe overall weighting efficiency of the algorithm is unity for massless\nfinal-state particles. For the massive case, the weighting efficiency of unity will\ndecrease rendering the algorithm less efficient. But in most cases, the\ninvariants are in regions of phase space where they are much larger than the\nmasses of the final-state particles.\n\nWe provide the \\ttt{RAMBO} mainly for cross checking our\nimplementation and do not recommend it for real world application,\neven though it can be used as one.  The \\ttt{RAMBO} method becomes\nuseful as a fall-back option if the standard algorithm fails for\nphysical reasons, see, e.g., Sec.~\\ref{sec:ps_anomalous}.\n\n%%%\n\n\\section{The default method: \\ttt{wood}}\n\\label{sec:wood}\n\nThe \\ttt{wood} algorithm classifies different phase space channels\naccording to their importance for a full scattering or decay process\nfollowing heuristic rules. For that purpose, \\whizard\\ investigates\nthe kinematics of the different channels depending on the total\ncenter-of-mass energy (or the mass of the decaying particle) and the\nmasses of the final-state particles.\n\nThe \\ttt{wood} phase space inherits its name from the naming schemes\nof structures of increasing complexities, namely trees, forests and\ngroves. Simply stated, a phase-space forest is a collection of\nphase-space trees. A phase-space tree is a parameterization for a\nvalid channel in the multi-channel adaptive integration, and each\nvariable in the a tree corresponds to an integration dimension,\ndefined by an appropriate mapping of the $(0,1)$ interval of the unit\nhypercube to the allowed range of the corresponding integration\nvariable. The whole set of these phase-space trees, collected in a\nphase-space forest object hence contains all parameterizations of the\nphase space that \\whizard\\ will use for a single hard process. Note\nthat processes might contain flavor sums of particles in the final\nstate. As \\whizard\\ will use the same phase space parameterization for\nall channels for this set of subprocesses, all particles in those\nflavor sums have to have the same mass. E.g. in the definition of a\n\"light\" jet consisting of the first five quarks and antiquarks,\n\\begin{code}\n  alias jet = u:d:s:c:b:U:D:S:C:B\n\\end{code}\nall quarks including strange, charm and bottom have to be massless for\nthe phase-space integration. \\whizard\\ can treat processes with\nsubprocesses having final-state particles with different masses in an\n\"additive\" way, where each subprocess will become a distinct component\nof the whole process. Each process component will get its own\nphase-space parameterization, such that they can allow for different\nmasses. E.g. in a 4-flavor scheme for massless $u,d,s,c$ quarks one\ncan write\n\\begin{code}\n  alias jet = u:d:s:c:U:D:S:C\n  process eeqq = e1, E1 => (jet, jet) + (b, B)\n\\end{code}\nIn that case, the parameterizations will be for massless final state\nquarks for the first subprocess, and for massive $b$ quarks for the\nsecond subprocess. In general, for high-energy lepton colliders, the\ndifference would not matter much, but performing the integration\ne.g. for $\\sqrt{s} = 11$ GeV, the difference will be\ntremendous. \\whizard\\ avoids inconsistent phase-space\nparameterizations in that way.\n\nAs a multi-particle process will contain hundred or thousands of\ndifferent channels, the different integration channels (trees) are\ngrouped into so called {\\em groves}. All channels/trees in the same\ngrove share a common weight for the phase-space integration, following\nthe assumption that they are related by some approximate symmetry. The\n\\vamp\\ adaptive multi-channel integrator (cf. Sec.~\\ref{sec:vamp})\nallows for equivalences between different integration channels. This\nmeans that trees/channels that are related by an exact symmetry are\nconnected by an array of these equivalences.\n\nThe phase-space setup, i.e. the detailed structure of trees and\nforests, are written by \\whizard\\ into a phase-space file that has the\nsame name as the corresponding process (or process component) with the\nsuffix \\ttt{.phs}. For the \\ttt{wood} phase-space method this file is\nwritten by a \\fortran\\ module which constructs a similar tree-like\nstructure as the directed acyclical graphs (DAGs) in the\n\\oMega\\ matrix element generator but in a less efficient way.\n\nIn some very rare cases with externally generated models\n(cf. Chapter~\\ref{chap:extmodels}) the phase-space generation has been\nreported to fail as \\whizard\\ could not find a valid phase-space\nchannel. Such pathological cases cannot occur for the hard-coded model\nimplementations inside \\whizard. They can only happen if there are in\nprinciple two different Feynman diagrams contributing to the same\nphase-space channel and \\whizard\\ considers the second one as\nextremely subleading (and would hence drop it). If for some reason\nhowever the first Feynman diagram is then absent, no phase-space\nchannel could be found. This problem cannot occur with the\n\\ttt{fast\\_wood} implementation discussed in the next section,\ncf.~\\ref{sec:fast_wood}.\n\nThe \\ttt{wood} algorithms orders the different groves of phase-space\nchannels according to a heuristic importance depending on the\nkinematic properties of the different phase-space channels in the\ngroves. A phase-space (\\ttt{.phs}) file looks typically like this:\n\\begin{code}\n process sm_i1\n\n! List of subprocesses with particle bincodes:\n!  8  4      1   2\n! e+ e- => mu+ mu-\n!  8  4      1   2\n\n   md5sum_process    = \"1B3B7A30C24664A73D3D027382CFB4EF\"\n   md5sum_model_par  = \"7656C90A0B2C4325AD911301DACF50EB\"\n   md5sum_phs_config = \"6F72D447E8960F50FDE4AE590AD7044B\"\n   sqrts         =  1.000000000000E+02\n   m_threshold_s =  5.000000000000E+01\n   m_threshold_t =  1.000000000000E+02\n   off_shell = 2\n   t_channel = 6\n   keep_nonresonant = T\n\n ! Multiplicity = 2, no resonances,  0 logs,  0 off-shell,  s-channel graph\n grove #1\n ! Channel #1\n   tree  3\n\n ! Multiplicity = 1, 1 resonance,   0 logs,  0 off-shell,  s-channel graph\n grove #2\n ! Channel #2\n   tree  3\n   map   3 s_channel      23 ! Z\n\\end{code}\nThe first line contains the process name, followed by a list of\nsubprocesses with the external particles and their binary codes. Then\nthere are three lines of MD5 check sums, used for consistency\nchecks. \\whizard\\ (unless told otherwise) will check for the existence\nof a phase-space file, and if the check sum matches, it will reuse the\nexisting file and not generate it again. Next, there are several\nkinematic parameters, namely the center-of-mass energy of the process,\n\\ttt{sqrts}, and two mass thresholds, \\ttt{m\\_threshold\\_s} and\n\\ttt{m\\_threshold\\_t}. The latter two are kinematical thresholds,\nbelow which \\whizard\\ will consider $s$-channel and $t$-channel-like\nkinematic configurations as effectively massless, respectively. The\ndefault values shown in the example have turned out to be optimal\nvalues for Standard Model particles. The two integers \\ttt{off\\_shell}\nand \\ttt{t\\_channel} give the number of off-shell lines and of\n$t$-channel lines that \\whizard\\ will allow for finding valid\nphase-space channels, respectively. This neglects extremley multi-peripheral\nbackground-like diagram constellations which are very subdominamnt\ncompared to resonant signal processes. The final flag specifies\nwhether \\whizard\\ will keep non-resonant phase-space channels\n(default), or whether it will focus only on resonant situations.\n\nAfter this header, there is a list of all groves, i.e. collections of\nphase-space channels which are connected by quasi-symmetries, together\nwith the corresponding multiplicity of subchannels in that\ngrove. In the phase-space file behind the multiplicity,\n\\whizard\\ denotes the number of (massive) resonances, logarithmcally\nenhanced kinematics (e.g. collinear regions), and number of off-shell\nlines, respectively. The final entry in the grove header notifies\nwhether the diagrams in that grove have $s$-channel topologies, or\ncount the number of corresponding $t$-channel lines.\n\nAnother example is shown here,\n\\begin{code}\n ! Multiplicity = 3, no resonances,  2 logs,  0 off-shell,  1 t-channel line\n grove #1\n ! Channel #1\n   tree  3 12\n   map   3 infrared       22 ! A\n   map  12 t_channel       2 ! u\n ! Channel #2\n   tree  3 11\n   map   3 infrared       22 ! A\n   map  11 t_channel       2 ! u\n ! Channel #3\n   tree  3 20\n   map   3 infrared       22 ! A\n   map  20 t_channel       2 ! u\n ! Channel #4\n   tree  3 19\n   map   3 infrared       22 ! A\n   map  19 t_channel       2 ! u\n\\end{code}\nwhere \\whizard\\ notifies in different situations a photon exchange as\n\\ttt{infrared}. So it detects a possible infrared singularity where a\nparticle can become arbitrarily soft. Such a situation can tell the\nuser that there might be a cut necessary in order to get a meaningful\nintegration result.\n\nThe phase-space setup that is generated and used by the \\ttt{wood}\nphase-space method can be visualized using the \\sindarin\\ option\n\\begin{code}\n  ?vis_channels = true\n\\end{code}\n\nThe \\ttt{wood} phase-space method can be invoked with the\n\\sindarin\\ command\n\\begin{code}\n  $phs_method = \"wood\"\n\\end{code}\nNote that this line is unnecessary, as \\ttt{wood} is the default\nphase-space method of \\whizard.\n\n%%%%%\n\n\\section{A new method: \\ttt{fast\\_wood}}\n\\label{sec:fast_wood}\n\nThis method (which is available from version 2.6.0 on) is an\nalternative implementation of the \\ttt{wood} phase-space algorithm. It\nuses the recursive structures inside the \\oMega\\ matrix element\ngenerator to generate all the structures needed for the different\nphase-space channels. In that way, it can avoid some of the\nbottlenecks of the \\ttt{wood} \\fortran\\ implementation of the\nalgorithm. On the other hand, it is only available if the\n\\oMega\\ matrix element generator has been enabled (which is the\ndefault for \\whizard). The \\ttt{fast\\_wood} method is then invoked via\n\\begin{code}\n  ?omega_write_phs_output = true\n  $phs_method = \"fast_wood\"\n\\end{code}\nThe first option is necessary in order to tell \\oMega\\ to write out\nthe output needed for the \\ttt{fast\\_wood} parser in order to generate\nthe phase-space file. This is not enabled by default in order not to\ngenerate unnecessary files in case the default method \\ttt{wood} is\nused.\n\nSo the \\ttt{fast\\_wood} implementation of the \\ttt{wood} phase-space\nalgorithm parses the tree-like represenation of the recursive set of\none-particle off-shell wave functions that make up the whole amplitude\ninside \\oMega\\ in the form of a directed acyclical graph (DAG) in\norder to generate the phase-space (\\ttt{.phs}) file\n(cf. Sec.~\\ref{sec:wood}). In that way, the algorithm makes sure that\nonly phase-space channels are generated for which there are indeed\n(sub)amplitudes in the matrix elements, and this also allows to\nexclude vetoed channels due to restrictions imposed on the matrix\nelements from the phase-space setup (cf. next\nSec.~\\ref{sec:ps_restrictions}).\n\n%%%%%\n\n\\section{Phase space respecting restrictions on subdiagrams}\n\\label{sec:ps_restrictions}\n\nThe \\fortran\\ implementation of the \\ttt{wood} phase-space does not\nknow anything about possible restrictions that maybe imposed on the\n\\oMega\\ matrix elements, cf. Sec.~\\ref{sec:process options}.\nConsequently, the \\ttt{wood} phase space also generates phase-space\nchannels that might be absent when restrictions are imposed. This is\nnot a principal problem, as in the adaptation of the phase-space\nchannels \\whizard's integrator \\vamp\\ will recognize that there is\nzero weight in that channel and will drop the channel (stop sampling\nin that channel) after some iterations. However, this is a waste of\nressources as it is in principle known that this channel is\nabsent. Using the \\ttt{fast\\_wood} phase-space algorithm\n(cf. Sec.~\\ref{sec:fast_wood} will take restrictions into account, as\n\\oMega\\ will not generate trees for channels that are removed with the\nrestrictions command. So it advisable for the user in the case of very\ncomplicated processes with restrictions to use the \\ttt{fast\\_wood}\nphase-space method to make \\whizard\\ generation and integration of the\nphase space less cumbersome.\n\n%%%%%\n\n\\section{Phase space for processes forbidden at tree level}\n\\label{sec:ps_anomalous}\n\nThe phase-space generators \\ttt{wood} and \\ttt{fast\\_wood} are\nintended for tree-level processes with their typical patterns of\nsingularities, which can be read off from Feynman graphs.  They can\nand should be used for loop-induced or for externally provided matrix\nelements as long as \\whizard\\ does not provide a dedicated phase-space\nmodule.\n\nSome scattering processes do not occur at tree level but become\nallowed if loop effects are included in the calculation.  A simple\nexample is the elastic QED process\n\\begin{displaymath}\n  A\\quad A \\longrightarrow A\\quad A\n\\end{displaymath}\nwhich is mediated by a fermion loop.  Similarly, certain applications\nprovide externally provided or hand-taylored matrix-element code that\nreplaces the standard \\oMega\\ code.\n\nCurrently, \\whizard's phase-space parameterization is nevertheless\ntied to the \\oMega\\ generator, so for tree-level forbidden processes\nthe phase-space construction process will fail.\n\nThere are two possible solutions for this problem:\n\\begin{enumerate}\n\\item\n  It is possible to provide the phase-space parameterization\n  information externally, by supplying an appropriately formatted\n  \\ttt{.phs} file, bypassing the automatic algorithm.  Assuming that\n  this phase-space file has been named \\ttt{my\\_phase\\_space.phs}, the\n  \\sindarin\\ code should contain the following:\n  \\begin{code}\n    ?rebuild_phase_space = false\n    $phs_file = \"my_phase_space.phs\"\n  \\end{code}\n  Regarding the contents of this file, we recommend to generate an\n  appropriate \\ttt{.phs} for a similar setup, using the standard\n  algorithm.  The generated file can serve as a template, which can be\n  adapted to the particular case.\n\n  In detail, the \\ttt{.phs} file consists of entries that specify the\n  process, then a standard header which contains MD5 sums and such --\n  these variables must be present but their values are irrelevant for\n  the present case --, and finally at least one \\ttt{grove} with\n  \\ttt{tree} entries that specify the parameterization.  Individual\n  parameterizations are built from the final-state and initial-state\n  momenta (in this order) which we label in binary form as\n  $1,2,4,8,\\dots$.  The actual tree consists of iterative fusions of\n  those external lines.  Each fusion is indicated by the number that\n  results from adding the binary codes of the external momenta that\n  contribute to it.\n\n  For instance, a valid phase-space tree for the process $AA\\to AA$ is\n  given by the simple entry\n  \\begin{code}\n    tree 3\n  \\end{code}\n  which indicates that the final-state momenta $1$ and $2$ are\n  combined to a fusion $1+2=3$.  The setup is identical to a process\n  such as $e^+e^-\\to\\mu^+\\mu^-$ below the $Z$ threshold.  Hence, we\n  can take the \\ttt{.phs} file for the latter process, replace the\n  process tag, and use it as an external phase-space file.\n\\item\n  For realistic applications of \\whizard\\ together with one-loop\n  matrix-element providers, the actual number of final-state particles may be\n  rather small, say $2,3,4$.  Furthermore, one-loop processes which are\n  forbidden at tree level do not contain soft or collinear\n  singularities.  In this situation, the \\ttt{RAMBO}\n  phase-space integration method, cf.\\ Sec.~\\ref{sec:rambo} is a\n  viable alternative which does not suffer from the problem.\n\\end{enumerate}\n\n\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n\\chapter{Methods for Hard Interactions}\n\\label{chap:hardint}\n\nThe hard interaction process is the core of any physics simulation\nwithin an MC event generator. One tries to describe the dominant\nparticle interaction in the physics process of interest at a given\norder in perturbation theory, thereby making use of field-theoretic\nfactorization theorems, especially for QCD, in order to separate\nnon-perturbative physics like parton distribution functions (PDFs) or\nfragmentation functions from the perturbative part. Still, it is in\nmany cases not possible to describe the perturbative part completely\nby means of fixed-order hard matrix elements: in soft and/or collinear\nregions of phase space, multiple emission of gluons and quarks (in\ngeneral QCD jets) and photons necessitates a resummation, as large\nlogarithms accompany the perturbative coupling constants and render\nfixed-order perturbation theory unreliable. The resummation of these\nlarge logarithms can be done analytically or (semi-)numerically,\nhowever, usually only for very inclusive quantities. At the level of\nexclusive events, these phase space regions are the realm of (QCD and\nalso QED) parton showers that approximate multi-leg matrix elements\nfrom the hard perturbative into to the soft-/collinear regime.\n\nThe hard matrix elements are then the core building blocks of the\nphysics description inside the MC event generator. \\whizard\\ generates\nthese hard matrix elements at tree-level (or sometimes for\nloop-induced processes using effective operators as insertions) as\nleading-order processes. This is done by the \\oMega\\ subpackage that\nis automatically called by \\whizard. Besides these physical matrix\nelements, there exist a couple of methods to generate dummy matrix\nelements for testing purposes, or for generating beam profiles and\nusing them with externally linked special matrix elements.\n\nEspecially for one-loop processes (next-to-leading order for\ntree-allowed processes or leading-order for loop-induced processes),\n\\whizard\\ allows to use matrix elements from external providers, so\ncalled OLP programs (one-loop providers). Of course, all of these\nexternal packages can also generate tree-level matrix elements, which\ncan then be used as well in \\whizard.\n\nWe start the discussion with the two different options for test matrix\nelements, internal test matrix elements with no generated compiled code\nin Sec.~\\ref{sec:test_me} and so called template matrix elements with\nactual \\fortran\\ code that is compiled and linked, and can also be\nmodified by the user in Sec.~\\ref{sec:template_me}. Then, we move to\nthe main matrix element method by the matrix element generator\n\\oMega\\ in Sec.~\\ref{sec:omega_me}. Matrix elements from the external\nmatrix element generators are discussed in the order of which\ninterfaces for the external tools have been implemented: \\gosam\\ in\nSec.~\\ref{sec:gosam_me}, \\openloops\\ in Sec.~\\ref{sec:openloops_me},\nand \\recola\\ in Sec.~\\ref{sec:recola_me}.\n\n%%%%%\n\n\\section{Internal test matrix elements}\n\\label{sec:test_me}\n\nThis method is merely for internal consistency checks inside \\whizard,\nand is not really intended to be utilized by the user. The method is\ninvoked by\n\\begin{code}\n  $method = \"unit_test\"\n\\end{code}\nThis particular method is only applicable for the internal test model\n\\ttt{Test.mdl}, which just contains a Higgs boson and a top\nquark. Technically, it will also works within model specifications\nfor the Standard Model, or the Minimal Supersymmetric Standard Model\n(MSSM), or all models which contain particles named as \\ttt{H} and\n\\ttt{t} with PDG codes 25 and 6, respectively. So, the models\n\\ttt{QED} and {QCD} will not work. Irrespective of what is given in\nthe \\sindarin\\ file as a scattering input process, \\whizard\\ will\nalways take the process\n\\begin{code}\n  model = SM\n  process <proc_name>= H, H => H, H\n\\end{code}\nor for the test model:\n\\begin{code}\n  model = Test\n  process <proc_name>= s, s => s, s\n\\end{code}\nas corresponding process. (This is the same process, just with\ndiffering nomenclature in the different models). No matrix element\ncode is generated and compiled, the matrix element is completely\ninternal, included in the \\whizard\\ executable (or library), with a\nunit value for the squared amplitude. The integration will always be\nperformed for this particularly process, even if the user provides a\ndifferent process for that method. Hence, the result will always be\nthe volume of the relativistic two-particle phase space. The only two\nparameters that influence the result are the collider energy,\n\\ttt{sqrts}, and the mass of the Higgs particle with PDG code 25 (this\nmass parameter can be changed in the model \\ttt{Test} as \\ttt{ms},\nwhile it would be \\ttt{mH} in the Standard Model \\ttt{SM}.\n\nIt is also possible to use a test matrix element, again internal, for\ndecay processes, where again \\whizard\\ will take a predefined process:\n\\begin{code}\n  model = SM\n  process <proc_name> = H => t, tbar\n\\end{code}\nin the \\ttt{SM} model or\n\\begin{code}\n  model = Test\n  process <proc_name> = s => f, fbar\n\\end{code}\nAgain, this is the same process with PDG codes $25 \\to 6 \\; -6$ in the\ncorresponding models. Note that in the model \\ttt{SM} the mass of the\nquark is set via the variable \\ttt{mtop}, while it is \\ttt{mf} in the\nmodel \\ttt{Test}.\n\nBesides the fact that the user always gets a fixed process and cannot\nmodify any matrix element code by hand, one can do all things as for a\nnormal process like generating events, different weights, testing\nrebuild flags, using different setups and reweight events\naccordingly. Also factorized processes with production and decay can\nbe tested that way.\n\nIn order to avoid confusion, it is highly recommended to use this\nmethod \\ttt{unit\\_test} only with the test model setup, model\n\\ttt{Test}.\n\nOn the technical side, the method \\ttt{unit\\_test} does not produce a\nprocess library (at least not an externally linked one), and also not\na makefile in order to modify any process files (which anyways do not\nexist for that method). Except for the logfiles and the phase space\nfile, all files are internal.\n\n%%%%%\n\n\\section{Template matrix elements}\n\\label{sec:template_me}\n\nMuch more versatile for the user than the previous matrix element\nmethod in~\\ref{sec:test_me}, are two different methods with constant\ntemplate matrix elements. These are written out as \\fortran\\ code by\nthe \\whizard\\ main executable (or library), providing an interface\nthat is (almost) identical to the matrix element code produced by the\n\\oMega\\ generator (cf. the next section,\nSec.~\\ref{sec:omega_me}. There are actually two different methods for\nthat purpose, providing matrix elements with different normalizations:\n\\begin{code}\n  $method = \"template\"\n\\end{code}\ngenerates matrix elements which give after integration over phase\nspace exactly one. Of course, for multi-particle final states the\nintegration can fluctuate numerically and could then give numbers that\nare only close to one but not exactly one. Furthermore, the\nnormalization is not exact if any of the external particles have\nnon-zero masses, or there are any cuts involved. But otherwise, the\nintegral from \\whizard\\ should give unity irrespective of the number\nof final state particles.\n\nIn contrast to this, the second method,\n\\begin{code}\n  $method = \"template_unity\"\n\\end{code}\ngives a unit matrix elements, or rather a matrix element that contains\nhelicity and color averaging factors for the initial state and the\nsquare root of the factorials of identical final state particles in\nthe denominator. Hence, integration over the final state momentum\nconfiguration gives a cross section that corresponds to the volume of\nthe $n$-particle final state phase space, divided by the corresponding\nflux factor, resulting in\n\\begin{equation}\n  \\sigma(s, 2 \\to 2,0) = \\frac{3.8937966\\cdot 10^{11}}{16\\pi} \\cdot\n  \\frac{1}{s \\text{[GeV]}^2} \\; \\text{fb}\n\\end{equation}\nfor the massless case and\n\\begin{equation}\n  \\sigma(s, 2 \\to 2,m_i) = \\frac{3.8937966\\cdot 10^{11}}{16\\pi} \\cdot\n  \\sqrt{\\frac{\\lambda (s,m_3^2,m_4^2)}{\\lambda (s,m_1^2,m_2^2)}}\n  \\cdot \\frac{1}{s \\text{[GeV]}^2} \\; \\text{fb}\n\\end{equation}\nfor the massive case. Here, $m_1$ and $m_2$ are the masses of the\nincoming, $m_3$ and $m_4$ the masses of the outgoing particles, and\n$\\lambda(x,y,z) = x^2 + y^2 + z^2 - 2xy - 2xz - 2yz$.\n\nFor the general massless case with no cuts, the integral should be\nexactly\n\\begin{equation}\n  \\sigma(s, 2\\to n, 0) = \\frac{(2\\pi)^4}{2 s}\\Phi_n(s)\n  = \\frac{1}{16\\pi s}\\,\\frac{\\Phi_n(s)}{\\Phi_2(s)},\n\\end{equation}\nwhere the volume of the massless $n$-particle phase space is\ngiven by\n\\begin{equation}\\label{phi-n}\n  \\Phi_n(s) = \\frac{1}{4(2\\pi)^5} \\left(\\frac{s}{16\\pi^2}\\right)^{n-2}\n  \\frac{1}{(n-1)!(n-2)!}.\n\\end{equation}\nFor $n\\neq2$ the phase space volume is dimensionful, so the\nunits of the integral are $\\fb\\times\\GeV^{2(n-2)}$. (Note that for\nphysical matrix elements this is compensated by momentum factors from\nwave functions, propagators, vertices and possibly dimensionful\ncoupling constants, but here the matrix element is just equal to\nunity.)\n\nNote that the phase-space integration for the \\ttt{template} and\n\\ttt{template\\_unity} matrix element methods is organized in the same\nway as it would be for the real $2\\to n$ process.  Since such a phase\nspace parameterization is not optimized for the constant matrix\nelement that is supplied instead, good convergence is not guaranteed.\n(Setting \\ttt{?stratified = true} may be helpful here.)\n\nThe possibility to call a dummy matrix element with this method allows\nto histogram spectra or structure functions: Choose a trivial process\nsuch as $uu\\to dd$, select the \\ttt{template\\_unity} method, switch\non structure functions for one (or both) beams, and generate events.\nThe distribution of the final-state mass squared reflects the $x$\ndependence of the selected structure function.\n\nFurthermore, the constant in the source code of the unit matrix\nelements can be easily modified by the user with their \\fortran\\ code\nin order to study customized matrix elements. Just rerun\n\\whizard\\ with the \\ttt{--recompile} option after the modification of\nthe matrix element code.\n\nBoth methods, \\ttt{template} and \\ttt{template\\_unity} will also work\neven if no \\ocaml\\ compiler is found or used and consequently the\n\\oMega\\ matrix elemente generator (cf. Sec.~\\ref{sec:omega_me} is\ndisable. The methods produce a process library for their corresponding\nprocesses, and a makefile, by  which \\whizard\\ steers compilation and\nlinking of the process source code.\n\n%%%%%\n\n\\section{The O'Mega matrix elements}\n\\label{sec:omega_me}\n\n\\oMega\\ is a subpackage of \\whizard, written in \\ocaml, which can\nproduce matrix elements for a wide class of implemented physics models\n(cf. Sec.~\\ref{sec:smandfriends} and \\ref{sec:bsmmodels} for a list of\nall implemented physics models), and even almost arbitrary models when\nusing external Lagrange level tools, cf. Chap.~\\ref{chap:extmodels}.\nThere are two different variants for matrix elements from \\oMega:\nthe first one is invoked as\n\\begin{code}\n  $method = \"omega\"\n\\end{code}\nand is the default method for \\whizard. It produces matrix element as\n\\fortran\\ code which is then compiled and linked. An alternative\nmethod, which for the moment is only available for the Standard Model\nand its variants as well models which are quite similar to the SM,\ne.g. the Two-Higgs doublet model or the Higgs-singlet extension. This\nmethod is taken when setting\n\\begin{code}\n  $method = \"ovm\"\n\\end{code}\nThe acronym \\ttt{ovm} stands for \\oMega\\ Virtual Machine (OVM). The\nfirst (default) method (\\ttt{omega}) of \\oMega\\ matrix elements\nproduces \\fortran\\ code for the matrix elements,that is compiled by\nthe same compiler with which \\whizard\\ has been compiled. The OVM\nmethod (\\ttt{ovm}) generates an \\ttt{ASCII} file with so called op\ncode for operations. These are just numbers which tell what numerical\noperations are to be performed on momenta, wave functions and vertex\nexpression in order to yield a complex number for the amplitude. The\nop codes are interpreted by the OVM in the same as a Java Virtual\nMachine. In both cases, a compiled \\fortran\\ is generated which for\nthe \\ttt{omega} method contains the full expression for the matrix\nelement as \\fortran\\ code, while for the \\ttt{ovm} method this is the\ndriver file of the OVM. Hence, for the \\ttt{ovm} method this file\nalways has roughly the same size irrespective of the complexity of the\nprocess. For the \\ttt{ovm} method, there will also be the \\ttt{ASCII}\nfile that contains the op codes, which has a name with an \\ttt{.hbc}\nsuffix: \\ttt{<process\\_name>.hbc}.\n\nFor both \\oMega\\ methods, there will be a process library created as\nfor the template matrix elements (cf. Sec.~\\ref{sec:template_me})\nnamed \\ttt{default\\_lib.f90} which can be given a user-defined name\nusing the \\ttt{library = \"<library>\"} command. Again, for both methods\n\\ttt{omega} and \\ttt{ovm}, a makefile named\n\\ttt{<library>\\_lib.makefile} is generated by which \\whizard\\ steers\ncompilation, linking and clean-up of the process sources. This\nmakefile can handily be adapted by the user in case she or he wants to\nmodify the source code for the process (in the case of the source code\nmethod).\n\nNote that \\whizard's default ME method via \\oMega\\ allows the user to\nspecify many different options either globally for all processes in\nthe \\sindarin, or locally for each process separately in curly\nbrackets behind the corresponding process definition. Examples are\n\\begin{itemize}\n\\item\n  Restrictions for the matrix elements like the exclusion of\n  intermediate resonances, the appearance of specific vertices or\n  coupling constants in the matrix elments. For more details on this\n  cf. Sec.~\\ref{subsec:restrictions}.\n\\item\n  Choice of a specific scheme for the width of massive intermediate\n  resonances, whether to use constant width, widths only in\n  $s$-channel like kinematics (this is the default), a fudged-width\n  scheme or the complex-mass scheme. The latter is actually steered as\n  a specific scheme of the underlying model and not with a specific\n  \\oMega\\ command.\n\\item\n  Choice of the electroweak gauge for the amplitude. The default is\n  the unitary gauge.\n\\end{itemize}\nWith the exception of the restrictions steered by the\n\\ttt{\\$restrictions = \"<restriction>\"} string expression, these options\nhave to be set in their specific \\oMega\\ syntax verbatim via the\nstring command \\ttt{\\$omega\\_flags = \"<expr>\"}.\n\n\n\n%%%%%\n\n\\section{Interface to GoSam}\n\\label{sec:gosam_me}\n\nOne of the supported methods for automated matrix elements from\nexternal providers is for the \\gosam\\ package. This program package\nwhich is a combination of \\python\\ scripts and \\fortran\\ libraries,\nallows both for tree and one-loop matrix elements (which is leading or\nnext-to-leading order, depending on whether the corresponding process\nis allowed at the tree level or not). In principle, the advanced\nversion of \\gosam\\ also allows for the evaluation of two-loop virtual\nmatrix elements, however, this is currently not supported in\n\\whizard. This method is invoked via the command\n\\begin{code}\n  $method = \"gosam\"\n\\end{code}\nOf course, this will only work correctly of \\gosam\\ with all its\nsubcomponents has been correctly found during configuration of\n\\whizard\\ and then subsequently correctly linked.\n\nIn order to generate the tables for spin, flavor and color states for\nthe  corresponding process, first \\oMega\\ is called to provide\n\\fortran\\ code for the interfaces to all the metadata for the\nprocess(es) to be evaluated. Next, the \\gosam\\ \\python\\ script is\nautomatically invoked that first checks for the necessary ingredients\nto produce, compile and link the \\gosam\\ matrix elements. These are\nthe the \\ttt{Qgraf} topology generator for the diagrams, \\ttt{Form} to\nperform algebra, the \\ttt{Samurai}, \\ttt{AVHLoop}, \\ttt{QCDLoop} and\n\\ttt{Ninja} libraries for Passarino-Veltman reduction, one-loop tensor\nintegrals etc. As a next step, \\gosam\\ automatically writes and\nexecutes a \\ttt{configure} script, and then it exchanges the Binoth\nLes Houches accord (BLHA) contract files between \\whizard\\ and\nitself~\\cite{Binoth:2010xt,Alioli:2013nda} to check whether it\nactually generate code for the demanded process at the given\norder. Note that the contract and answer files do not have to be\nwritten by the user by hand, but are generated automatically within\nthe program work flow initiated by the original\n\\sindarin\\ script. \\gosam\\ then generates \\fortran\\ code for the\ndifferent components of the processes, compiles it and links it into a\nlibrary, which is then automatically accessible (as an external\nprocess library) from inside \\whizard. The phase space setup and the\nintegration as well as the LO (and NLO) event generation work then in\nexactly the same way as for \\oMega\\ matrix elements.\n\nAs an NLO calculation consists of different components for the Born,\nthe real correction, the virtual correction, the subtraction part and\npossible further components depending on the details of the\ncalculation, there is the possible to separately choose the matrix\nelement method for those components via the keywords\n\\ttt{\\$loop\\_me\\_method}, \\ttt{\\$real\\_tree\\_me\\_method},\n\\ttt{\\$correlation\\_me\\_method}  etc. These\nkeywords overwrite the master switch of the \\ttt{\\$method} keyword.\n\nFor more information on the switches and details of the functionality\nof \\gosam, cf. \\url{http://gosam.hepforge.org}.\n\n%%%%%\n\n\\section{Interface to Openloops}\n\\label{sec:openloops_me}\n\nVery similar to the case of \\gosam, cf. Sec.~\\ref{sec:gosam_me}, is\nthe case for \\openloops\\ matrix elements. Also here, first \\oMega\\ is\ncalled in order to provide an interface for the spin, flavor and color\ndegrees of freedom for the corresponding process. Information exchange\nbetween \\whizard\\ and \\openloops\\ then works in the same automatic way\nas for \\gosam\\ via the BLHA interface. This matrix element method is\ninvoked via\n\\begin{code}\n  $method = \"openloops\"\n\\end{code}\nThis again is the master switch that will tell \\whizard\\ to use\n\\openloops\\ for all components, while there are special keywords to\ntailor-make the setup for the different components of an NLO\ncalculation (cf. Sec.~\\ref{sec:gosam_me}.\n\nThe main difference between \\openloops\\ and \\gosam\\ is that for\n\\openloops\\ there is no process code to be generated, compiled and\nlinked for a process, but a precompiled library is called and linked,\ne.g. \\ttt{ppllj} for the Drell-Yan process. Of course, this library has\nto be installed on the system, but if that is not the case, the user\ncan execute the \\openloops\\ script in the source directory of\n\\openloops\\ to download, compile and link the corresponding dynamic\nlibrary. This limits (for the moment) the usage of \\openloops\\ to\nprocesses where pre-existint libraries for that specific processes\nhave been generated by the \\openloops\\ authors. A new improved\ngenerator for general process libraries for \\openloops\\ will get rid\nof that restriction.\n\nFor more information on the installation, switches and details of the\nfunctionality of \\openloops, cf. \\url{http://openloops.hepforge.org}.\n\n%%%%%\n\n\\section{Interface to Recola}\n\\label{sec:recola_me}\n\nThe third one-loop provider (OLP) for external matrix elements that\nis supported by \\whizard, is \\recola. In contrast to \\gosam,\ncf. Sec.~\\ref{sec:gosam_me}, and \\openloops,\ncf. Sec.~\\ref{sec:openloops_me}, \\recola\\ does not use a BLHA\ninterface to exchange information with \\whizard, but its own\ntailor-made C interoperable library interface to communicate to the\nMonte Carlo side. \\recola\\ matrix elements are called for via\n\\begin{code}\n  $method = \"recola\"\n\\end{code}\n\\recola\\ uses a highly efficient algorithm to generate process code\nfor LO and NLO SM amplitudes in a fully recursive manner. At the\nmoment, the setup of the interface within \\whizard\\ does not allow to\ninvoke more than one different process in \\recola: this would lead to\na repeated initialization of the main setup of \\recola\\ and would\nconsequently crash it. It is foreseen in the future to have a\nsafeguard mechanism inside \\whizard\\ in order to guarantee\ninitialization of \\recola\\ only once, but this is not yet\nimplemented.\n\nFurther information on the installation, details and parameters of\n\\recola\\ can be found at \\url{http://recola.hepforge.org}.\n\n%%%%%\n\n\\section{Special applications}\n\\label{sec:special_me}\n\nThere are also special applications with combinations of matrix\nelements from different sources for dedicated purposes like e.g. for\nthe matched top--anti-top threshold in $e^+e^-$. For this special\napplication which depending on the order of the matching takes only\n\\oMega\\ matrix elements or at NLO combines amplitudes from \\oMega\\ and\n\\openloops, is invoked by the method:\n\\begin{code}\n  $method = \"threshold\"\n\\end{code}\n\n\n\\newpage\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n\\chapter{Implemented physics}\n\\label{chap:physics}\n\n%%%%%\n\n\\section{The hard interaction models}\n\nIn this section, we give a brief overview over the different\nincarnations of models for the description of the realm of subatomic\nparticles and their interactions inside \\whizard. In\nSec.~\\ref{sec:smandfriends}, the Standard Model (SM) itself and\nstraightforward extensions and modifications thereof in the gauge,\nfermionic and Higgs sector are described. Then,\nSec.~\\ref{sec:bsmmodels} gives a list and short description of all\ngenuine beyond the SM models (BSM) that are currently implemented in\n\\whizard\\ and its matrix element generator \\oMega. Additional models\nbeyond that can be integrated and handled via the interfaces to\nexternal tools like \\sarah\\ and \\FeynRules, or the universal model\nformat \\UFO, cf. Chap.~\\ref{chap:extmodels}.\n\n%%%%%%%%%%%%%%%\n\n\\subsection{The Standard Model and friends}\n\\label{sec:smandfriends}\n\n\n%%%%\n\n\\subsection{Beyond the Standard Model}\n\\label{sec:bsmmodels}\n\n\\begin{table}\n        \\begin{center}\n           \\begin{tabular}{|l|l|l|}\n             \\hline\n             MODEL TYPE & with CKM matrix & trivial CKM \\\\\n             \\hline\\hline\n             Yukawa test model & \\tt{---} & \\tt{Test} \\\\\n             \\hline\n             QED with $e,\\mu,\\tau,\\gamma$ & \\tt{---} &  \\tt{QED} \\\\\n             QCD with $d,u,s,c,b,t,g$ & \\tt{---} &  \\tt{QCD} \\\\\n             Standard Model        & \\tt{SM\\_CKM} & \\tt{SM} \\\\\n             SM with anomalous gauge couplings &  \\tt{SM\\_ac\\_CKM} &\n             \\tt{SM\\_ac} \\\\\n             SM with $Hgg$, $H\\gamma\\gamma$, $H\\mu\\mu$, $He^+e^-$ &\n             \\tt{SM\\_Higgs\\_CKM} & \\tt{SM\\_Higgs} \\\\\n             SM with bosonic dim-6 operators &  \\tt{---} &\n             \\tt{SM\\_dim6} \\\\\n             SM with charge 4/3 top &  \\tt{---} &\n             \\tt{SM\\_top} \\\\\n             SM with anomalous top couplings &  \\tt{---} &\n             \\tt{SM\\_top\\_anom} \\\\\n             SM with anomalous Higgs couplings &  \\tt{---} &\n             \\tt{SM\\_rx}/\\tt{NoH\\_rx}/\\tt{SM\\_ul} \\\\\\hline\n             SM extensions for $VV$ scattering & \\tt{---} &\n             \\tt{SSC}/\\tt{AltH}/\\tt{SSC\\_2}/\\tt{SSC\\_AltT} \\\\\\hline\n             SM with $Z'$ & \\tt{---} & \\tt{Zprime} \\\\\n             \\hline\n             Two-Higgs Doublet Model & \\tt{THDM\\_CKM} & \\tt{THDM} \\\\ \\hline\\hline\n             MSSM &   \\tt{MSSM\\_CKM} & \\tt{MSSM} \\\\\n             \\hline\n             MSSM with gravitinos &   \\tt{---} & \\tt{MSSM\\_Grav} \\\\\n             \\hline\n             NMSSM &   \\tt{NMSSM\\_CKM} & \\tt{NMSSM} \\\\\n             \\hline\n             extended SUSY models &   \\tt{---} & \\tt{PSSSM} \\\\\n             \\hline\\hline\n             Littlest Higgs &  \\tt{---} & \\tt{Littlest} \\\\\n             \\hline\n             Littlest Higgs with ungauged $U(1)$ &  \\tt{---} &\n             \\tt{Littlest\\_Eta} \\\\\n             \\hline\n             Littlest Higgs with $T$ parity &  \\tt{---} &\n             \\tt{Littlest\\_Tpar} \\\\\n             \\hline\n             Simplest Little Higgs (anomaly-free) &  \\tt{---} &\n             \\tt{Simplest} \\\\\n             \\hline\n             Simplest Little Higgs (universal) &  \\tt{---} &\n             \\tt{Simplest\\_univ} \\\\\n             \\hline\\hline\n             SM with graviton & \\tt{---} & \\tt{Xdim} \\\\\n             \\hline\n             UED & \\tt{---} & \\tt{UED} \\\\\n             \\hline\n             ``SQED'' with gravitino & \\tt{---} & \\tt{GravTest} \\\\\n             \\hline\n             Augmentable SM template & \\tt{---} & \\tt{Template} \\\\\n             \\hline\n           \\end{tabular}\n         \\end{center}\n  \\caption{\\label{tab:models} List of models available in\n          \\whizard. There are pure test models or models implemented\n          for theoretical investigations, a long list of SM variants\n          as well as a large number of BSM models.}\n\\end{table}\n\n\\subsubsection{Strongly Interacting Models and Composite Models}\n\nHiggsless models have been studied extensively before the Higgs boson\ndiscovery at the LHC Run I in 2012 in order to detect possible\nloopholes in the electroweak Higgs sector discovery potential of this\ncollider. The Threesite Higgsless Model is one of the simplest\nincarnations of these models, and was one of the first BSM models\nbeyond SUSY and Little Higgs models that have been implemented in\n\\whizard~\\cite{Speckner:2010zi}. It is also called the Minimal\nHiggsless Model (MHM)~\\cite{Chivukula:2006cg} is a  minimal\ndeconstructed Higgsless model which contains only the first resonance\nin  the tower of Kaluza-Klein modes of a Higgsless extra-dimensional\nmodel. It is a non-renormalizable, effective theory whose\ngauge group is an extension of the SM with an extra $SU(2)$ gauge\ngroup.  The breaking of the extended electroweak gauge symmetry is\naccomplished by a set of nonlinear sigma fields which represent the\neffects of physics at a higher scale and make the theory\nnonrenormalizable. The physical vector boson spectrum contains the\nusual photon, $W^\\pm$ and $Z$ bosons as well as a $W'^\\pm$ and $Z'$\nboson.  Additionally, a new set of heavy fermions are introduced to\naccompany the new gauge group ``site'' which mix to form the physical\neigenstates.  This mixing is controlled by the small mixing parameter\n$\\epsilon_L$ which is adjusted to satisfy constraints from precision\nobservables, such as the S parameter~\\cite{Chivukula:2005xm}.\nHere, additional weak gauge boson production at the LHC was\none of the focus of the studies with \\whizard~\\cite{Ohl:2008ri}.\n\n\n\\subsubsection{Supersymmetric Models}\n\n\\whizard/\\oMega\\ was the first multi-leg matrix-element/event\ngenerator to include the full Minimal Supersymmetric Standard Model\n(MSSM), and also the NMSSM. The SUSY implementations in \\whizard\\ have\nbeen extensively tested~\\cite{Ohl:2002jp,Reuter:2009ex}, and have been\nused for many theoretical and experimental studies (some prime\nexamples\nbeing~\\cite{Kalinowski:2008fk,Robens:2008sa,Hagiwara:2005wg}.\n\n\\subsubsection{Little Higgs Models}\n\n\\subsubsection{Inofficial models}\n\nThere have been several models that have been included within the\n\\whizard/\\oMega\\ framework but never found their way into the official\nrelease series. One famous example is the non-commutative extension of\nthe SM, the NCSM. There have been several studies, e.g. simulations on\nthe $s$-channel production of a $Z$ boson at the photon collider\noption of the ILC~\\cite{Ohl:2004tn}. Also, the production of\nelectroweak gauge bosons at the LHC in the framework of the NCSM have\nbeen studied~\\cite{Ohl:2010zf}.\n\n\n%%%%%%%%%%%%%%%\n\n\\section{The SUSY Les Houches Accord (SLHA) interface}\n\\label{sec:slha}\n\n\nTo be filled in\n...~\\cite{Skands:2003cj,AguilarSaavedra:2005pw,Allanach:2008qq}.\n\nThe neutralino sector deserves special attention. After\ndiagonalization of the mass matrix expresssed in terms\nof the gaugino and higgsino eigenstates, the resulting mass\neigenvalues may be either negative or positive. In this case, two\nprocedures can be followed.  Either the masses are rendered\npositive and the associated mixing matrix gets purely imaginary\nentries or the masses are kept signed, the mixing matrix in this case\nbeing real.  According to the SLHA agreement, the second option is\nadopted. For a specific eigenvalue, the phase is absorbed into the\ndefinition of the relevant eigenvector, rendering the mass\nnegative. However, \\whizard\\ has not yet officially tested for\nnegative masses. For external SUSY models\n(cf.~Chap.~\\ref{chap:extmodels}) this means, that one must be careful\nusing a SLHA file with explicit factors of\nthe complex unity in the mixing matrix, and on the other hand,\nreal and positive masses for the neutralinos. For the hard-coded SUSY\nmodels, this is completely handled internally. Especially\nRef.~\\cite{Hagiwara:2005wg} discusses the details of the neutralino\n(and chargino) mixing matrix.\n\n%%%%%%%%%%%%%%%%\n\n\\section{Lepton Collider Beam Spectra}\n\\label{sec:beamspectra}\n\nFor the simulation of lepton collider beam spectra there are two\ndedicated tools, \\circeone\\ and \\circetwo\\ that have been written as\nin principle independent tools. Both attempt to describe the\ndetails of electron (and positron) beams in a realistic lepton\ncollider environment. Due to the quest for achieving high peak\nluminosities at $e^+e^-$ machines, the goal is to make the spatial\nextension of the beam as small as possible but keeping the area of the\nbeam roughly constant. This is achieved by forcing the beams in the\nfinal focus into the shape of a quasi-2D bunch. Due to the high charge\ndensity in that bunch, the bunch electron distribution is modified by\nclassical electromagnetic radiation, so called {\\em beamstrahlung}.\nThe two \\circe\\ packages are intended to perform a simulation of this\nbeamstrahlung and its consequences on the electron beam spectrum as\nrealistic as possible. More details about the two packages can be\nfound in their stand-alone documentations. We will discuss the basic\nfeatures of lepton-collider beam simulations in the next two sections,\nincluding the technicalities of passing simulations of the machine\nbeam setup to \\whizard. This will be followed by a section on the\nsimulation of photon collider spectra, included for historical\nreasons.\n\n%%%%%\n\n\\subsection{\\circeone}\n\nWhile the bunches in a linear collider cross only once, due to their\nsmall size they experience a strong beam-beam effect. There is a\ncode to simulate the impact of this effect on luminosity and\nbackground, called\n\\ttt{GuineaPig++}~\\cite{Schulte:1998au,Schulte:1999tx,Schulte:2007zz}.\nThis takes into account the details of the accelerator, the final\nfocus etc. on the structure of the beam and the main features of the\nresulting energy spectrum of the electrons and positrons. It offers\nthe state-of-the-art simulation of lepton-collider beam spectra as\nclose as possible to reality. However, for many high-luminosity\nsimulations, event files produced with \\ttt{GuineaPig++} are usually\ntoo small, in the sense that not enough independent events are\navailable for physics simulations. Lepton collider beam spectra do\npeak at the nominal beam energy ($\\sqrt{s}/2$) of the collider, and\nfeature very steeply falling tails. Such steeply falling distributions\nare very poorly mapped by histogrammed distributions with fixed bin\nwidths.\n\nThe main working assumption to handle such spectra are being followed\nwithin \\circeone:\n\\begin{enumerate}\n\\label{circe1_assumptions}\n\\item The beam spectra for the two beams $P_1$ and $P_2$ factorize\n  (here $x_1$ and $x_2$ are the energy fractions of the two beams,\n  respectively):\n  \\begin{equation*}\n    D_{P_1P_2} (x_1, x_2) = D_{P_1} (x_1) \\cdot D_{P_2} (x_2)\n  \\end{equation*}\n\n\\item\n  The peak is described with a delta distribution, and the tail with a\n  power law:\n  \\begin{equation*}\n    D(x) = d \\cdot \\delta(1-x) \\; + \\; c \\cdot x^\\alpha \\, (1-x)^\\beta\n  \\end{equation*}\n\\end{enumerate}\nThe two powers $\\alpha$ and $\\beta$ are the main coefficients that can\nbe tuned in order to describe the spectrum with \\circeone\\ as close as\npossible as the original \\ttt{GuineaPig++} spectrum. More details\nabout how \\circeone\\ works and what it does can be found in its own\nwrite-up in \\ttt{circe1/share/doc}.\n\n\\subsection{\\circetwo}\n\nThe two conditions listed in \\ref{circe1_assumptions} are too\nrestrictive and hence insufficient to describe more complicated\nlepton-collider beam spectra, as they e.g. occur in the CLIC\ndrive-beam design. Here, the two beams are highly correlated and also\na power-law description does not give good enough precision for the\ntails. To deal with these problems, \\circetwo\\ starts with a\ntwo-dimensional histogram featuring factorized, but variable bin\nwidths in order to simulate the steep parts of the\ndistributions. The limited statistics from too small\n\\ttt{GuineaPig++} event output files leads to correlated\nfluctuations that would leave strange artifacts in the\ndistributions. To abandon them, Gaussian filters are applied to smooth\nout the correlated fluctuations. Here care has to be taken when going\nfrom the continuum in $x$ momentum fraction space to the corresponding\n\\begin{figure}\n  \\centering\n  \\includegraphics{circe2-smoothing}\n  \\caption{\\label{fig:circe2-smoothing}\n    Smoothing the bin at the $x_{e^+} = 1$ boundary with Gaussian\n    filters of 3 and 10 bins width compared to no smoothing.}\n\\end{figure}\nboundaries: separate smoothing procedures are being applied to the\nbins in the continuum region and those in the boundary in order to\navoid artificial unphysical beam energy\nspreads. Fig.~\\ref{fig:circe2-smoothing} shows the smoothing of the\ndistribution for the bin at the $x_{e^+} = 1$ boundary. The blue dots\nshow the direct \\ttt{GuineaPig++} output comprising the\nfluctuations due to the low statistics. Gaussian filters with widths\nof 3 and 10 bins, respectively, have been applied (orange and green\ndots, resp.). While there is still considerable fluctuation for 3 bin\nwidth Gaussian filtering, the distribution is perfectly smooth for 10\nbin width. Hence, five bin widths seem a reasonable compromise for\nhistograms with a total of 100 bins. Note that the bins are not\nequidistant, but shrink with a power law towards the $x_{e^-} = 1$\nboundary on the right hand side of Fig.~\\ref{fig:circe2-smoothing}.\n\n\\whizard\\ ships (inside its subpackage \\circetwo) with prepared beam\nspectra ready to be used within \\circetwo\\ for the ILC beam spectra\nused in the ILC\nTDR~\\cite{Behnke:2013xla,Baer:2013cma,Adolphsen:2013jya,Adolphsen:2013kya,Behnke:2013lya}. These\ncomprise the designed staging energies of 200 GeV, 230 GeV, 250 GeV,\n350 GeV, and 500 GeV. Note that all of these spectra up to now do not\ntake polarization of the original beams on the beamstrahlung into\naccount, but are polarization-averaged. For backwards compatibility,\nalso the 500 GeV spectra for the TESLA\ndesign~\\cite{AguilarSaavedra:2001rg,Richard:2001qm}, here both for\npolarized and polarization-averaged cases, are included. Correlated\nspectra for CLIC staging energies like 350 GeV, 1400 GeV and 3000 GeV\nare not yet (as of version 2.2.4) included in the \\whizard\\\ndistribution.\n\nIn the following we describe how to obtain such files with the tools\nincluded in \\whizard (resp. \\circetwo). The procedure is equivalent to\nthe so-called \\ttt{lumi-linker} construction used by Timothy\nBarklow (SLAC) together with the legacy version \\whizard\\ttt{ 1.95}.\nThe workflow to produce such files is to run \\ttt{GuineaPig++} with\nthe following input parameters:\n\\begin{Code}\n  do_lumi = 7;\n  num_lumi = 100000000;\n  num_lumi_eg = 100000000;\n  num_lumi_gg = 100000000;\n\\end{Code}\nThis demands from \\ttt{GuineaPig++} the generation of distributions\nfor the $e^-e^+$, $e^\\mp \\gamma$, and $\\gamma\\gamma$ components of the\nbeamstrahlung's spectrum, respectively. These are the files\n\\ttt{lumi.ee.out}, \\ttt{lumi.eg.out}, \\ttt{lumi.ge.out}, and\n\\ttt{lumi.gg.out}, respectively. These contain pairs $(E_1, E_2)$\nof beam energies, {\\em not} fractions of the original beam\nenergy. Huge event numbers are out in here, as \\ttt{GuineaPig++}\nwill produce only a small fraction due to a very low generation\nefficiency.\n\nThe next step is to transfer these output files from\n\\ttt{GuineaPig++} into input files used with \\circetwo. This is\ndone by means of the tool \\ttt{circe\\_tool.opt} that is installed\ntogether with the \\whizard\\ main binary and libraries. The user should\nrun this executable with the following input file:\n\\begin{Code}\n{ file=\"ilc500/ilc500.circe\"                   # to be loaded by WHIZARD\n  { design=\"ILC\" roots=500 bins=100 scale=250 # E in [0,1]\n    { pid/1=electron pid/2=positron pol=0     # unpolarized e-/e+\n      events=\"ilc500/lumi.ee.out\" columns=2   # <= Guinea-Pig\n      lumi = 1564.763360                      # <= Guinea-Pig\n      iterations = 10                         # adapting bins\n      smooth = 5 [0,1) [0,1)                  # Gaussian filter 5 bins\n      smooth = 5 [1] [0,1) smooth = 5 [0,1) [1] } } }\n\\end{Code}\nThe first line defines the output file, that later can be read in into\nthe beamstrahlung's description of \\whizard\\ (cf. below). Then, in the\nsecond line the design of the collider (here: ILC for 500 GeV\ncenter-of-mass energy, with the number of bins) is specified. The next\nline tells the tool to take the unpolarized case, then the\n\\ttt{GuineaPig++} parameters (event file and luminosity) are\nset. In the last three lines, details concerning the adaptation of the\nsimulation as well as the smoothing procedure are being specified: the\nnumber of iterations in the adaptation procedure, and for the\nsmoothing with the Gaussian filter first in the continuum and then at\nthe two edges of the spectrum. For more details confer the\ndocumentation in the \\circetwo\\ subpackage.\n\nThis produces the corresponding input files that can be used within\n\\whizard\\ to describe beamstrahlung for lepton colliders, using a\n\\sindarin\\ input file like:\n\\begin{Code}\n        beams = e1, E1 => circe2\n        $circe2_file = \"ilc500.circe\"\n        $circe2_design = \"ILC\"\n        ?circe2_polarized = false\n\\end{Code}\n\n\n%%%%%\n\n\\subsection{Photon Collider Spectra}\n\nFor details confer the complete write-up of the \\circetwo\\\nsubpackage.\n\n%%%%%\n\n\\section{Transverse momentum for ISR photons}\n\\label{sec:isr-photon-handler}\n\nThe structure functions that describe the splitting of a beam particle\ninto a particle pair, of which one enters the hard interaction and the\nother one is radiated, are defined and evaluated in the strict\ncollinear approximation.  In particular, this holds for the ISR\nstructure function which describes the radiation of photons off a\ncharged particle in the initial state.\n\nThe ISR structure function that is used by \\whizard\\ is understood to\nbe inclusive, i.e., it implicitly contains an integration over\ntransverse momentum.  This approach is to be used for computing a\ntotal cross section via \\ttt{integrate}.  In \\whizard, it is possible\nto unfold this integration, as a transformation that is applied by\n\\ttt{simulate} step, event by event.  The resulting modified events\nwill show a proper logarithmic momentum-transfer ($Q^2$) distribution\nfor the radiated photons.  The recoil is applied to the\nhard-interaction system, such that four-momentum and $\\sqrt{\\hat s}$\nare conserved.  The distribution is cut off by $Q_{\\text{max}}^2$\n(cf. \\ttt{isr\\_q\\_max}) for large momentum transfer, and smoothly by\nthe parton mass (cf.\\ \\ttt{isr\\_mass}) for small momentum transfer.\n\nTo activate this modification, set\n\\begin{Code}\n  ?isr_handler = true\n  $isr_handler_mode = \"recoil\"\n\\end{Code}\nbefore, or as an option to, the \\ttt{simulate} command.\n\nLimitations: the current implementation of the $p_T$ modification\nworks only for the symmetric double-ISR case, i.e., both beams have to\nbe charged particles with identical mass (e.g., $e^+e^-$).  The mode\n\\ttt{recoil} generates exactly one photon per beam, i.e., it modifies\nthe momentum of the single collinear photon that the ISR structure\nfunction implementation produces, for each beam.  (It is foreseen that\nfurther modes or options will allow to generate multiple photons.\nAlternatively, the \\pythia\\ shower can be used to simulate multiple\nphotons radiated from the initial state.)\n\n%%%%%\n\n\\section{Transverse momentum for the EPA approximation}\n\\label{sec:epa-beam-handler}\n\nFor the equivalent-photon approximation (EPA), which is also defined\nin the collinear limit, recoil momentum can be inserted into generated\nevents in an entirely analogous way.  The appropriate settings are\n\\begin{Code}\n  ?epa_handler = true\n  $epa_handler_mode = \"recoil\"\n\\end{Code}\n\nLimitations: as for ISR, the current implementation of the $p_T$\nmodification works only for the symmetric double-EPA case.  Both\nincoming particles of the hard process must be photons, while both\nbeams must be charged particles with identical mass (e.g., $e^+e^-$).\nFurthermore, the current implementation does not respect the\nkinematical limit parameter \\verb|epa_q_min|, it has to be set to\nzero. In effect, the lower $Q^2$ cutoff is determined by the\nbeam-particle mass \\verb|epa_mass|, and the upper cutoff is either\ngiven by $Q_{\\text{max}}$ (the parameter\n\\verb|epa_q_max|), or by the limit $\\sqrt{s}$ if this is not set.\n\nIt is possible to combine the ISR and EPA handlers, for processes\nwhere ISR is active for one of the beams, EPA for the other beam.  For\nthis scenario to work, both handler switches must be on, and both mode\nstrings must coincide.  The parameters are set separately for ISR and\nEPA, as described above.\n\n%%%%%\n\n\\section{Resonances and continuum}\n\n\\subsection{Complete matrix elements}\n\nMany elementary physical processes are composed of contributions that can be\nqualified as (multiply) \\emph{resonant} or \\emph{continuum}.  For instance,\nthe amplitude for the process $e^+e^-\\to q\\bar q q\\bar q$, evaluated at tree\nlevel in perturbation theory, contains Feynman diagrams with zero, one, or two\n$W$ and $Z$ bosons as virtual lines.  If the kinematical constraints allow\nthis, two vector bosons can become simultaneously on-shell in part of phase\nspace.  To a first approximation, this situation is understood as $W^+W^-$ or\n$ZZ$ production with subsequent decay.  The kinematical distributions show\ndistinct resonances in the quark-pair spectra.  Other graphs contain only one\ns-channel $W/Z$ boson, or none at all, such as graphs with $q\\bar q$\nproduction and subsequent gluon radiation, splitting into another $q\\bar q$\npair.\n\nA \\whizard\\ declaration of the form\n\\begin{Code}\n        process q4 = e1, E1 => u, U, d, D\n\\end{Code}\nproduces the full set of graphs for the selected final state, which after\nsquaring and integrating yields the exact tree-level result for the process.\nThe result contains all doubly and singly resonant parts, with correct\nresonance shapes, as well as the continuum contribution and all interference.\nThis is, to given order in perturbation theory, the best possible\napproximation to the true result.\n\n\\subsection{Processes restricted to resonances}\n\nFor an intuitive separation of a two-boson ``signal'' contribution, it is\npossible to restrict the set of graphs to a certain intermediate state.  For\ninstance, the declaration\n\\begin{Code}\n  process q4_zz = e1, E1 => u, U, d, D { $restrictions = \"3+4~Z && 5+6~Z\" }\n\\end{Code}\ngenerates an amplitude that contains only those Feynman graphs where the\nspecified quarks are connected to a $Z$ virtual line.  The result may be\nunderstood as $ZZ$ production with subsequent decay, where the $Z$ resonances\nexhibit a Breit-Wigner shape.  Combining this with the\nanalogous $W^+W^-$ restricted process, the user can generate ``signal''\nprocesses.\n\nAdding both ``signal'' cross sections $WW$ and $ZZ$ will result in a\nreasonable approximation to the exact tree-level cross section.  The amplitude\nmisses the single-resonant and continuum contributions, and the squared\namplitude misses the interference terms, however.  More importantly, the\nrestricted processes as such are not gauge-invariant (with respect to the\nelectroweak gauge group), and they are no longer dominant away from resonant\nkinematics.  We therefore strongly recommend that such restricted processes\nare always accompanied by a cut setup that restricts the kinematics to an\napproximately on-shell pattern for both resonances.  For instance:\n\\begin{Code}\n  cuts = all 85 GeV < M < 95 GeV [u:U]\n     and all 85 GeV < M < 95 GeV [d:D]\n\\end{Code}\nIn this region, the gauge-dependent and continuum contributions are strictly\nsubdominant.  Away from the resonance(s), the results for a restricted process\nare meaningless, and the full process has to be computed instead.\n\n\\subsection{Factorized processes}\n\nAnother method for obtaining the signal contribution is a proper factorization\ninto resonance production and decay.  We would have to generate a production\nprocess and two decay processes:\n\\begin{Code}\n        process z_uu = Z => u, U\n        process z_dd = Z => d, D\n        process zz = e1, E1 => Z, Z\n\\end{Code}\nAll three processes must be integrated.  The integration results are partial\ndecay widths and the $ZZ$ production cross section, respectively.  (Note that\ncut expressions in \\sindarin\\ apply to all integrations, so make sure that\nno production-process cuts are active when integrating the decay\nprocesses.)\n\nDuring a later event-generation step, the $Z$ decays can then be activated by declaring the $Z$ as\nunstable,\n\\begin{Code}\n        unstable Z (z_uu, z_dd)\n\\end{Code}\nand then simulating the production process\n\\begin{Code}\n        simulate (zz)\n\\end{Code}\nThe generated events will consist of four-fermion final states, including all\ncombinations of both decay modes.  It is important to note that in this setup,\nthe invariant $u\\bar u$ and $d\\bar d$ masses will be always \\emph{exactly}\nequal to the $Z$ mass.  There is no Breit-Wigner shape involved.  However, in\nthis approximation the results are gauge-invariant, as there is no off-shell\ncontribution involved.\n\nFor further details on factorized processes and spin correlations,\ncf.\\ Sec.~\\ref{sec:spin-correlations}.\n\n\n\\subsection{Resonance insertion in the event record}\n\nFrom the above discussion, we may conclude that it is always preferable to\ncompute the complete process for a given final state, as long as this is\ncomputationally feasible.  However, in the simulation step this approach also\nhas a drawback.  Namely, if a parton-shower module (see below) is switched on,\nthe parton-shower algorithm relies on event details in order to determine the\nradiation pattern of gluons and further splitting.  In the generated event\nrecords, the full-process events carry the signature of non-resonant continuum\nproduction with no intermediate resonances.  The parton shower will thus start\nthe evolution at the process energy scale, the total available energy.  By\ncontrast, for an electroweak production and decay process, the evolution\nshould start only at the vector boson mass, $m_Z$.  In effect, even though the\nresonant contribution of $WW$ and $ZZ$ constitutes the bulk of the cross\nsection, the radiation pattern follows the dynamics of four-quark continuum\nproduction.  In general, the number of radiated hadrons will be too high.\n\n\n\\begin{figure}\n  \\begin{center}\n    \\includegraphics[width=.41\\textwidth]{resonance_e_gam}\n    \\includegraphics[width=.41\\textwidth]{resonance_n_charged} \\\\\n    \\includegraphics[width=.41\\textwidth]{resonance_n_hadron}\n    \\includegraphics[width=.41\\textwidth]{resonance_n_particles} \\\\\n    \\includegraphics[width=.41\\textwidth]{resonance_n_photons}\n    \\includegraphics[width=.41\\textwidth]{resonance_n_visible}\n  \\end{center}\n  \\caption{The process $e^+e^- \\to jjjj$ at 250 GeV center-of-mass\n    energy is compared transferring the partonic events naively to the\n    parton shower, i.e. without respecting any intermediate resonances\n    (red lines). The blue lines show the process factorized into $WW$\n    production and decay, where the shower knows the origin of the two\n    jet pairs. The orange and dark green lines show the resonance\n    treatment as mentioned in the text, with\n    \\ttt{resonance\\_on\\_shell\\_limit = 1} and \\ttt{= 4},\n    respectively. \\pythiasix\\ parton shower and hadronization with the\n    OPAL tune have been used. The observables are: photon energy\n    distribution and number of charged tracks (upper line left/right,\n    number of hadrons and total number of particles (middle\n    left/right), and number of photons and neutral particles (lower\n    line left/right).}\n\\end{figure}\n\nTo overcome this problem, there is a refinement of the process description\navailable in \\whizard.  By modifying the process declaration to\n\\begin{Code}\n  ?resonance_history = true\n  resonance_on_shell_limit = 4\n  process q4 = e1, E1 => u, U, d, D\n\\end{Code}\nwe advise the program to produce not just the complete matrix element, but\nalso all possible restricted matrix elements containing resonant intermediate\nstates.  This has no effect at all on the integration step, and thus on the\ntotal cross section.\n\nHowever, when subsequently events are generated with this setting, the program\nchecks, for each event, the kinematics and determines the set of potentially\nresonant contributions.  The criterion is whether the off-shellness of a\nparticular would-be resonance is less than the resonance width multiplied by\nthe value of \\verb|resonance_on_shell_limit| (default value $=4$).  For the\nset of resonance histories which pass this criterion (which can be empty),\ntheir respective squared matrix element is related to the full-process matrix\nelement.  The ratio is interpreted as a probability.  The random-number\ngenerator then selects one or none of the resonance histories, and modifies\nthe event record accordingly.  In effect, for an appropriate fraction of the\nevents, depending on the kinematics, the parton-shower module is provided with\nresonance information, so it can adjust the radiation pattern accordingly.\n\nIt has to be mentioned that generating the matrix-element code for all\npossible resonance histories takes additional computing resources.  In the\ncurrent default setup, this feature is switched off.  It has to be explicitly\nactivated via the \\verb|?resonance_history| flag.\n\nAlso, the feature can be activated or deactivated individually for\neach process, such as in\n\\begin{Code}\n  ?resonance_history = true\n  process q4_with_res = e1, E1 => u, U, d, D  { ?resonance_history = true }\n  process q4_wo_res   = e1, E1 => u, U, d, D  { ?resonance_history = false }\n\\end{Code}\nIf the flag is \\verb|false| for a process, no resonance code will be\ngenerated.  Similarly, the flag has to be globally or locally active\nwhen \\verb|simulate| is called, such that the feature takes effect for\nevent generation.\n\nThere are two additional parameters that can fine-tune the conditions for\nresonance insertion in the event record.  Firstly, the parameter\n\\verb|resonance_on_shell_turnoff|, if nonzero, enables a Gaussian suppression\nof the probability for resonance insertion.  For instance, setting\n\\begin{Code}\n  ?resonance_history = true\n  resonance_on_shell_turnoff = 4\n  resonance_on_shell_limit = 8\n\\end{Code}\nwill reduce the probability for the event to be qualified as resonant by\n$e^{-1}= 37\\,\\%$ if the kinematics is off-shell by four units of the width,\nand by $e^{-4}=2\\,\\%$ at eight units of the width.  Beyond this point, the\nsetting of the \\verb|resonance_on_shell_limit| parameter eliminates resonance\ninsertion altogether.  In effect, the resonance-background transition is\nrealized in a smooth way.  Secondly, within the resonant-kinematics range the\nprobability for qualifying the event as background can be reduced by the\nparameter \\verb|resonance_background_factor| (default value $=1$) to a number\nbetween zero and one.  Setting this to zero means that the event will be\nnecessarily qualified as resonant, if it falls within the resonant-kinematics\nrange.\n\nNote that if an event, by the above mechanism, is identified as following a\ncertain resonance history, the assigned color flow will be chosen to match the\nresonance history, not the complete matrix element.  This may result in a\nreassignment of color flow with respect to the original partonic event.\n\nFinally, we mention the order of execution: any additional\nmatrix element code is compiled and linked when \\verb|compile| is\nexecuted for the processes in question.  If this command is omitted,\nthe \\verb|simulate| command will trigger compilation.\n\n\n\\section{Parton showers and Hadronization}\n\nIn order to produce sensible events, final state QCD (and also QED)\nradiation has to be considered as well as the binding of strongly\ninteracting partons into mesons and baryons. Furthermore, final state\nhadronic resonances undergo subsequent decays into those particles\nshowing up in (or traversing) the detector. The latter are mostly\npions, kaons, photons, electrons and muons.\n\nThe physics associated with these topics can be divided into the\nperturbative part which is the regime of the parton shower, and the\nnon-perturbative part which is the regime for the\nhadronization. \\whizard\\ comes with its own two different parton\nshower implementations, an analytic and a so-called $k_T$-ordered\nparton shower that will be detailed in the next section.\n\nNote that in general it is not advisable to use different shower and\nhadronization methods, or in other words, when using shower and\nhadronization methods from different programs these would have to be\ntuned together again with the corresponding data.\n\nParton showers are approximations to full matrix elements taking only\nthe leading color flow into account, and neglecting all interferences\nbetween different amplitudes leading to the same exclusive final\nstate. They rely on the QCD (and QED) splitting functions to describe\nthe emissions of partons off other partons. This is encoded in the\nso-called Sudakov form factor~\\cite{Sudakov:1954sw}:\n\\begin{equation*}\n  \\Delta( t_1, t_2) = \\exp \\left[ \\int\\limits_{t_1}^{t_2} \\mbox{d} t\n    \\int\\limits_{z_-}^{z_+} \\mbox{d} z \\frac{\\alpha_s}{2 \\pi t} P(z)\n    \\right]\n\\end{equation*}\nThis gives the probability for a parton to evolve from scale $t_2$ to\n$t_1$ without any further emissions of partons. $t$ is the evolution\nparameter of the shower, which can be a parton energy, an emission\nangle, a virtuality, a transverse momentum etc. The variable $z$\nrelates the two partons after the branching, with the most common\nchoice being the ratio of energies of the parton after and before the\nbranching. For final-state radiation brachings occur after the hard\ninteraction, the evolution of the shower starts at the scale of the\nhard interaction, $t \\sim \\hat{s}$, down to a cut-off scale $t =\nt_{\\text{cut}}$ that marks the transition to the non-perturbative\nregime of hadronization. In the space-like evolution for the\ninitial-state shower, the evolution is from a cut-off representing the\nfactorization scale for the parton distribution functions (PDFs) to the\ninverse of the hard process scale, $-\\hat{s}$. Technically, this\nevolution is then backwards in (shower) time~\\cite{Sjostrand:1985xi},\nleading to the necessity to include the PDFs in the Sudakov factors.\n\nThe main switches for the shower and hadronization which are realized\nas transformations on the partonic events within \\whizard\\ are\n\\ttt{?allow\\_shower} and \\ttt{?allow\\_hadronization}, which are\ntrue by default and only there for technical reasons. Next, different\nshower and hadronization methods can be chosen within \\whizard:\n\\begin{code}\n  $shower_method = \"WHIZARD\"\n  $hadronization_method = \"PYTHIA6\"\n\\end{code}\nThe snippet above shows the default choices in \\whizard\\, namely\n\\whizard's intrinsic parton shower, but \\pythiasix\\ as hadronization\ntool. (Note that \\whizard\\ does not have its own hadronization module\nyet.)  The usage of \\pythiasix\\ for showering and hadronization will\nbe explained in Sec.~\\ref{sec:pythia6}, while the two different\nimplementations of the \\whizard\\ homebrew parton showers are discussed\nin Sec.~\\ref{sec:ktordered} and~\\ref{sec:analytic}, respectively.\n\n%%%%%\n\n\\subsection{The $k_T$-ordered parton shower}\n\\label{sec:ktordered}\n\n%%%%%\n\n\\subsection{The analytic parton shower}\n\\label{sec:analytic}\n\n%%%%%\n\n\\subsection{Parton shower and hadronization from \\pythiasix}\n\\label{sec:pythia6}\n\nDevelopment of the \\pythiasix\\ generator for parton shower and\nhadronization (the \\fortran\\ version) has been discontinued by the\nauthors several years ago. Hence, the final release of that program is\nfrozen. This allowed to ship this final version, v6.427, with the\n\\whizard\\ distribution without the need of updating it all the\ntime. One of the main reasons for that inclusion -- besides having the\nstandard tool for showering and hadronization for decays at hand -- is\nto allow for backwards validation within \\whizard\\ particularly for\nthe event samples generated for the development of linear collider\nphysics: first for TESLA, JLC and NLC, and later on for the Conceptual\nand Technical Design Report for ILC, for the Conceptual Design Report\nfor CLIC as well as for the Letters of Intent for the LC detectors,\nILD and SiD.\n\nUsually, an external parton shower and hadronization program (PS) is\nsteered via the transfer of event files that are given to the PS via\nLHE events, while the PS program then produces hadron level events,\nusually in HepMC format. These can then be directed towards a full or\nfast detector simulation program. As \\pythiasix\\ has been completely\nintegrated inside the \\whizard\\ framework, the showered or more\ngeneral hadron level events can be returned to and kept inside\n\\whizard's internal event record, and hence be used in \\whizard's\ninternal event analysis. In that way, the events can be also written\nout in event formats that are not supported by \\pythiasix,\ne.g. \\ttt{LCIO} via the output capabilities of \\whizard.\n\nThere are several switches to directly steer \\pythiasix\\ (the values\nin brackets correspond to the \\pythiasix\\ variables):\n\\begin{code}\n  ps_mass_cutoff = 1 GeV                  [PARJ(82)]\n  ps_fsr_lambda = 0.29 GeV                [PARP(72)]\n  ps_isr_lambda = 0.29 GeV                [PARP(61)]\n  ps_max_n_flavors = 5                    [MSTJ(45)]\n  ?ps_isr_alphas_running = true           [MSTP(64)]\n  ?ps_fsr_alphas_running = true           [MSTJ(44)]\n  ps_fixed_alphas = 0.2                   [PARU(111)]\n  ?ps_isr_angular_ordered = true          [MSTP(62)]\n  ps_isr_primordial_kt_width = 1.5 GeV    [PARP(91)]\n  ps_isr_primordial_kt_cutoff = 5.0 GeV   [PARP(93)]\n  ps_isr_z_cutoff = 0.999                 [1-PARP(66)]\n  ps_isr_minenergy = 2 GeV                [PARP(65)]\n  ?ps_isr_only_onshell_emitted_partons =\n        true                              [MSTP(63)]\n\\end{code}\nThe values given above are the default values. The first value\ncorresponds to the \\pythiasix\\ parameter \\ttt{PARJ(82)}, its\nsquared being the minimal virtuality that is allowed for the parton\nshower, i.e. the cross-over to the hadronization. The same parameter\nis used also for the \\whizard\\ showers. \\ttt{ps\\_fsr\\_lambda} is\nthe equivalent of \\ttt{PARP(72)} and is the $\\Lambda_{\\text{QCD}}$\nfor the final state shower. The corresponding variable for the initial\nstate shower is called \\ttt{PARP(61)} in \\pythiasix. By the next\nvariable (\\ttt{MSTJ(45)}), the maximal number of flavors produced\nin splittings in the shower is given, together with the number of\nactive flavors in the running of\n$\\alpha_s$. \\ttt{?ps\\_isr\\_alphas\\_running} which corresponds to\n\\ttt{MSTP(64)} in \\pythiasix\\ determines whether or net a running\n$\\alpha_s$ is taken in the space-like initial state showers. The same\nvariable for the final state shower is \\ttt{MSTJ(44)}. For fixed\n$\\alpha_s$, the default value is given by \\ttt{ps\\_fixed\\_alpha},\ncorresponding to \\ttt{PARU(111)}. \\ttt{MSTP(62)} determines\nwhether the ISR shower is angular order, i.e. whether angles are\nincreasing towards the hard interaction. This is per default true, and\nset in the variable \\ttt{?ps\\_isr\\_angular\\_ordered}. The width of\nthe distribution for the primordial (intrinsic) $k_T$ distribution\n(which is a non-perturbative quantity) is the \\pythiasix\\ variable\n\\ttt{PARP(91)}, while in \\whizard\\ it is given by\n\\ttt{pythia\\_isr\\_primordial\\_kt\\_width}. The next variable\n(\\ttt{PARP(93}) gives the upper cutoff for that distribution, which\nis 5 GeV per default. For splitting in space-like showers, there is a\ncutoff on the $z$ variable named \\ttt{ps\\_isr\\_z\\_cutoff} in\n\\whizard. This corresponds to one minus the value of the\n\\pythiasix\\ parameter \\ttt{PARP(66)}. \\ttt{PARP(65)}, on the\nother hand, gives the minimal (effective) energy for a time-like or\non-shell emitted parton on a space-like QCD shower, given by the\n\\sindarin\\ parameter \\ttt{ps\\_isr\\_minenergy}. Whether or not\npartons emitted from space-like showers are allowed to be only\non-shell is given by\n\\ttt{?ps\\_isr\\_only\\_onshell\\_emitted\\_partons}, \\ttt{MSTP(63)}\nin \\pythiasix\\ language.\nFor more details confer the\n\\pythiasix\\ manual~\\cite{Sjostrand:2006za}.\n\nAny other non-standard \\pythiasix\\ parameter can be fed into the\nparton shower via the string variable\n\\begin{code}\n  $ps_PYTHIA_PYGIVE = \"....\"\n\\end{code}\nVariables set here get preference over the ones set explicitly by\ndedicated \\sindarin\\ commands. For example, the OPAL tune for hadronic\nfinal states can be set via:\n\\begin{code}\n  $ps_PYTHIA_PYGIVE = \"MSTJ(28)=0; PMAS(25,1)=120.; PMAS(25,2)=0.3605E-02; MSTJ(41)=2;\n   MSTU(22)=2000; PARJ(21)=0.40000; PARJ(41)=0.11000; PARJ(42)=0.52000; PARJ(81)=0.25000;\n   PARJ(82)=1.90000; MSTJ(11)=3; PARJ(54)=-0.03100; PARJ(55)=-0.00200; PARJ(1)=0.08500;\n   PARJ(3)=0.45000; PARJ(4)=0.02500; PARJ(2)=0.31000; PARJ(11)=0.60000; PARJ(12)=0.40000;\n   PARJ(13)=0.72000; PARJ(14)=0.43000; PARJ(15)=0.08000; PARJ(16)=0.08000;\n   PARJ(17)=0.17000; MSTP(3)=1;MSTP(71)=1\"\n\\end{code}\n\n\\vspace{0.5cm}\n\nA very common error that appears quite often when using\n\\pythiasix\\ for SUSY or any other model having a stable particle that\nserves as a possible Dark Matter candidate, is the following\nwarning/error message:\n\\begin{Code}\n     Advisory warning type 3 given after        0 PYEXEC calls:\n     (PYRESD:) Failed to decay particle  1000022 with mass   15.000\n******************************************************************************\n******************************************************************************\n*** FATAL ERROR: Simulation: failed to generate valid event after 10000 tries\n******************************************************************************\n******************************************************************************\n\\end{Code}\nIn that case, \\pythiasix\\ gets a stable particle (here the lightest\nneutralino with the PDG code 1000022) handed over and does not know\nwhat to do with it. Particularly, it wants to treat it as a heavy\nresonance which should be decayed, but does not know how do\nthat. After a certain number of tries (in the example abobe 10k),\n\\whizard\\ ends with a fatal error telling the user that the event\ntransformation for the parton shower in the simulation has failed\nwithout producing a valid event. The solution to work around that\nproblem is to let \\pythiasix\\ know that the neutralino (or any other\nDM candidate) is stable by means of\n\\begin{code}\n  $ps_PYTHIA_PYGIVE = \"MDCY(C1000022,1)=0\"\n\\end{code}\nHere, 1000022 has to be replaced by the stable dark matter candidate\nor long-lived particle in the user's favorite model. Also note that\nwith other options being passed to \\pythiasix\\, the \\ttt{MDCY}\noption above has to be added to an existing\n\\ttt{\\$ps\\_PYTHIA\\_PYGIVE} command separated by a semicolon.\n\n%%%%%\n\n\\subsection{Parton shower and hadronization from \\pythiaeight}\n\n\\subsection{Other tools for parton shower and hadronization}\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n\\chapter{More on Event Generation}\n\\label{chap:events}\n\nIn order to perform a physics analysis with \\whizard\\ one has to\ngenerate events. This seems to be a trivial statement, but as there\nhave been any questions like \"My \\whizard\\ does not produce plots --\nwhat has gone wrong?\" we believe that repeating that rule is\nworthwile. Of course, it is not mandatory to use \\whizard's own analysis\nset-up, the user can always choose to just generate events and use\nhis/her own analysis package like \\ttt{ROOT}, or \\ttt{TopDrawer}, or\nyou name it for the analysis.\n\nAccordingly, we first start to describe how to generate events and\nwhat options there are -- different event formats, renaming output\nfiles, using weighted or unweighted events with different\nnormalizations. How to re-use and manipulate already generated event\nsamples, how to limit the number of events per file, etc. etc.\n\n\\section{Event generation}\n\nTo explain how event generation works, we again take our favourite\nexample, $e^+e^- \\to \\mu^+ \\mu^-$,\n\\begin{verbatim}\n  process eemm = e1, E1 => e2, E2\n\\end{verbatim}\nThe command to trigger generation of events is \\ttt{simulate\n  (<proc\\_name>) \\{ <options> \\}}, so in our case -- neglecting any\noptions for now -- simply:\n\\begin{verbatim}\n  simulate (eemm)\n\\end{verbatim}\nWhen you run this \\sindarin\\ file you will experience a fatal error:\n\\ttt{FATAL ERROR: Colliding beams: sqrts is zero (please set\nsqrts)}. This is because \\whizard\\ needs to compile and integrate the\nprocess \\ttt{eemm} first before event simulation, because it needs the\ninformation of the corresponding cross section, phase space\nparameterization and grids. It does both automatically, but you have\nto provide \\whizard\\ with the beam setup, or at least with the\ncenter-of-momentum energy.  A corresponding \\ttt{integrate} command\nlike\n\\begin{verbatim}\n  sqrts = 500 GeV\n  integrate (eemm) { iterations = 3:10000 }\n\\end{verbatim}\nobviously has to appear {\\em before} the corresponding \\ttt{simulate}\ncommand (otherwise you would be punished by the same error message as\nbefore). Putting things in the correct order results in an output\nlike:\n\\begin{footnotesize}\n\\begin{verbatim}\n| Reading model file '/usr/local/share/whizard/models/SM.mdl'\n| Preloaded model: SM\n| Process library 'default_lib': initialized\n| Preloaded library: default_lib\n| Reading commands from file 'bla.sin'\n| Process library 'default_lib': recorded process 'eemm'\nsqrts =  5.000000000000E+02\n| Integrate: current process library needs compilation\n| Process library 'default_lib': compiling ...\n| Process library 'default_lib': keeping makefile\n| Process library 'default_lib': keeping driver\n| Process library 'default_lib': active\n| Process library 'default_lib': ... success.\n| Integrate: compilation done\n| RNG: Initializing TAO random-number generator\n| RNG: Setting seed for random-number generator to 29912\n| Initializing integration for process eemm:\n| ------------------------------------------------------------------------\n| Process [scattering]: 'eemm'\n|   Library name  = 'default_lib'\n|   Process index = 1\n|   Process components:\n|     1: 'eemm_i1':   e-, e+ => mu-, mu+ [omega]\n| ------------------------------------------------------------------------\n| Beam structure: [any particles]\n| Beam data (collision):\n|   e-  (mass = 5.1099700E-04 GeV)\n|   e+  (mass = 5.1099700E-04 GeV)\n|   sqrts = 5.000000000000E+02 GeV\n| Phase space: generating configuration ...\n| Phase space: ... success.\n| Phase space: writing configuration file 'eemm_i1.phs'\n| Phase space: 2 channels, 2 dimensions\n| Phase space: found 2 channels, collected in 2 groves.\n| Phase space: Using 2 equivalences between channels.\n| Phase space: wood\nWarning: No cuts have been defined.\n| OpenMP: Using 8 threads\n| Starting integration for process 'eemm'\n| Integrate: iterations = 3:10000\n| Integrator: 2 chains, 2 channels, 2 dimensions\n| Integrator: Using VAMP channel equivalences\n| Integrator: 10000 initial calls, 20 bins, stratified = T\n| Integrator: VAMP\n|=============================================================================|\n| It      Calls  Integral[fb]  Error[fb]   Err[%]    Acc  Eff[%]   Chi2 N[It] |\n|=============================================================================|\n   1       9216  4.2833237E+02  7.14E-02    0.02    0.02*  40.29\n   2       9216  4.2829071E+02  7.08E-02    0.02    0.02*  40.29\n   3       9216  4.2838304E+02  7.04E-02    0.02    0.02*  40.29\n|-----------------------------------------------------------------------------|\n   3      27648  4.2833558E+02  4.09E-02    0.01    0.02   40.29    0.43   3\n|=============================================================================|\n| Time estimate for generating 10000 events: 0d:00h:00m:04s\n| Creating integration history display eemm-history.ps and eemm-history.pdf\n| Starting simulation for process 'eemm'\n| Simulate: using integration grids from file 'eemm_m1.vg'\n| RNG: Initializing TAO random-number generator\n| RNG: Setting seed for random-number generator to 29913\n| OpenMP: Using 8 threads\n| Simulation: requested number of events = 0\n|             corr. to luminosity [fb-1] =   0.0000E+00\n| Events: writing to raw file 'eemm.evx'\n| Events: generating 0 unweighted, unpolarized events ...\n| Events: event normalization mode '1'\n|         ... event sample complete.\n| Events: closing raw file 'eemm.evx'\n| There were no errors and    1 warning(s).\n| WHIZARD run finished.\n|=============================================================================|\n\\end{verbatim}\n\\end{footnotesize}\n\nSo, \\whizard\\ tells you that it has entered simulation mode, but besides\nthis, it has not done anything. The next step is that you have to\ndemand event generation -- there are two ways to do this: you could\neither specify a certain number, say 42, of events you want to have\ngenerated by \\whizard, or you could provide a number for an integrated\nluminosity of some experiment. (Note, that if you choose to take both\noptions, \\whizard\\ will take the one which gives the larger event\nsample. This, of course, depends on the given process(es) -- as well\nas cuts -- and its corresponding cross section(s).) The first of these\noptions is set with the command: \\ttt{n\\_events = <number>}, the\nsecond with \\ttt{luminosity = <number> <opt. unit>}.\n\nAnother important point already stated several times in the manual is\nthat \\whizard\\ follows the commands in the steering \\sindarin\\ file in a\nchronological order. Hence, a given number of events or luminosity\n{\\em after} a \\ttt{simulate} command will be ignored -- or are\nrelevant only for any \\ttt{simulate} command potentially following\nfurther down in the \\sindarin\\ file. So, in our case, try:\n\\begin{verbatim}\n n_events = 500\n luminosity = 10\n simulate (eemm)\n\\end{verbatim}\nPer default, numbers for integrated luminosity are understood as\ninverse femtobarn. So, for the cross section above this would\ncorrespond to 4283 events, clearly superseding the demand for 500\nevents. After reducing the luminosity number from ten to one inverse\nfemtobarn, 500 is the larger number of events taken by \\whizard\\ for\nevent generation. Now \\whizard\\ tells you:\n\\begin{verbatim}\n| Simulation: requested number of events = 500\n|             corr. to luminosity [fb-1] =   1.1673E+00\n| Events: reading from raw file 'eemm.evx'\n| Events: reading 500 unweighted, unpolarized events ...\n| Events: event normalization mode '1'\n| ... event file terminates after 0 events.\n| Events: appending to raw file 'eemm.evx'\n| Generating remaining  500 events ...\n|         ... event sample complete.\n| Events: closing raw file 'eemm.evx'\n\\end{verbatim}\nI.e., it evaluates the luminosity to which the sample of 500 events\nwould correspond to, which is now, of course, bigger than the $1\n\\fb^{-1}$ explicitly given for the luminosity. Furthermore, you can\nread off that a file \\ttt{whizard.evx} has been generated, containing\nthe demanded 500 events. (It was there before containing zero events,\nbecause to \\ttt{n\\_events} or \\ttt{luminosity} value had been\nset. \\whizard\\ then tried to get the events first from file before\ngenerating new ones). Files with the suffix \\ttt{.evx} are binary\nformat event files, using a machine-dependent \\whizard-specific\nevent file format. Before we list the event formats supported by\n\\whizard, the next two sections will tell you more about unweighted and\nweighted events as well as different possibilities to normalize events\nin \\whizard.\n\nAs already explained for the libraries, as well as the phase space and\ngrid files in Chap.~\\ref{chap:sindarin}, \\whizard\\ is trying to re-use\nas much information as possible. This is of course also true for the\nevent files. There are special MD5 check sums testing the integrity\nand compatibility of the event files. If you demand for a process for\nwhich an event file already exists (as in the example above, though it\nwas empty) equally many or less events than generated before,\n\\whizard\\ will not generate again but re-use the existing events (as\nalready explained, the events are stored in a \\whizard-own\nbinary event format, i.e. in a so-called \\ttt{.evx} file. If you\nsuppress generation of that file, as will be described in subsection\n\\ref{sec:eventformats} then \\whizard\\ has to generate events all the\ntime). From version v2.2.0 of \\whizard\\ on, the program is also able\nto read in event from different event formats. However, most event\nformats do not contain as many information as \\whizard's internal\nformat, and a complete reconstruction of the events might not be\npossible. Re-using event files is very practical for doing several\ndifferent analyses with the same data, especially if there are many\nand big data samples. Consider\nthe case, there is an event file with 200 events, and you now ask\n\\whizard\\ to generate 300 events, then it will re-use the 200 events\n(if MD5 check sums are OK!), generate the remaining 100 events and\nappend them to the existing file. If the user for some reason,\nhowever, wants to regenerate events (i.e. ignoring possibly existing\nevents), there is the command option \\ttt{whizard --rebuild-events}.\n\n%%%%%%%%%\n\n\\section{Unweighted and weighted events}\n\n\\whizard\\ is able to generate unweighted events, i.e. events that are\ndistributed uniformly and each contribute with the same event weight\nto the whole sample. This is done by mapping out the phase space of\nthe process under consideration according to its different phase space\nchannels (which each get their own weights), and then unweighting the\nsample of weighted events. Only a sample of unweighted events could in\nprinciple be compared to a real data sample from some experiment. The\nseventh column in the \\whizard\\ iteration/adaptation procedure tells you\nabout the efficiency of the grids, i.e. how well the phase space is\nmapped to a flat function. The better this is achieved, the higher the\nefficiency becomes, and the closer the weights of the different phase\nspace channels are to uniformity. This means, for higher efficiency\nless weighted events (\"calls\") are needed to generate a single\nunweighted event. An efficiency of 10 \\% means that ten weighted\nevents are needed to generate one single unweighted event. After the\nintegration is done, \\whizard\\ uses the duration of calls during the\nadaptation to estimate a time interval needed to generate 10,000\nunweighted events. The ability of the adaptive multi-channel Monte\nCarlo decreases with the number of integrations, i.e. with the number\nof final state particles. Adding more and more final state particles\nin general also increases the complexity of phase space, especially\nits singularity structure. For a $2 \\to 2$ process the efficiency is\nroughly of the order of several tens of per cent. As a rule of thumb,\none can say that with every additional pair of final state particle\nthe average efficiency one can achieve decreases by a factor of five\nto ten.\n\nThe default of \\whizard\\ is to generate {\\em unweighted} events. One can\nuse the logical variable \\ttt{?unweighted = false} to disable\nunweighting and generate weighted events. (The command\n\\ttt{?unweighted = true} is a tautology, because \\ttt{true} is the\ndefault for this variable.) Note that again this command has to appear\n{\\em before} the corresponding \\ttt{simulate} command, otherwise it will\nbe ignored or effective only for any \\ttt{simulate} command appearing\nlater in the \\sindarin\\ file.\n\nIn the unweighted procedure, \\whizard\\ is keeping track of the highest\nweight that has been appeared during the adaptation, and the\nefficiency for the unweighting has been estimated from the average\nvalue of the sampling function compared to the maximum value. In\nprinciple, during event generation no events should be generated whose\nsampling function value exceeds the maximum function value encountered\nduring the grid adaptation. Sometimes, however, there are numerical\nfluctuations and such events are happening. They are called {\\em\nexcess events}. \\whizard\\ does keep track of these excess events\nduring event generation and will report about them, e.g.:\n\\begin{code}\nWarning: Encountered events with excess weight: 9 events (  0.090 %)\n| Maximum excess weight = 6.083E-01\n| Average excess weight = 2.112E-04\n\\end{code}\nWhenever in an event generation excess events appear, this shows that\nthe adaptation of the sampling function has not been perfect. When the\nnumber of excess weights is a finite number of percent, you should\ninspect the phase-space setup and try to improve its settings to get a\nbetter adaptation.\n\nGenerating \\emph{weighted} events is, of course, much faster if the\nsame number of events is requested.  Each event carries a weight\nfactor which is taken into account for any internal analysis\n(histograms), and written to file if an external file format has been\nselected.  The file format must support event weights.\n\nIn a weighted event sample, there is typically a fraction of events\nwhich effectively have weight zero, namely those that have been\ncreated by the phase-space sampler but do not pass the requested\ncuts.  In the default setup, those events are silently dropped, such\nthat the events written to file or available for analysis all have\nnonzero weight.  However, dropping such events affects the overall\nnormalization.  If this has happened, the program will issue a warning\nof the form\n\\begin{code}\n| Dropped events (weight zero) = 1142 (total 2142)\nWarning: All event weights must be rescaled by f = 4.66853408E-01\n\\end{code}\nThis factor has to be applied by hand to any external event files (and\nto internally generated histograms).  The program cannot include the\nfactor in the event records, because it is known only after all events\nhave been generated.  To avoid this problem, there is the logical flag\n\\ttt{?keep\\_failed\\_events} which tells \\whizard\\ not to drop events with\nweight zero.  The normalization will be correct, but the event sample\nwill include invalid events which have to be vetoed by their zero\nweight, before any operations on the event record are performed.\n\n\n%%%%%%%%%\n\n\\section{Choice on event normalizations}\n\nThere are basically four different choices to normalize event weights\n($\\braket{\\ldots}$ denotes the average):\n\\begin{enumerate}\n\\item $\\braket{w_i} = 1$, \\qquad\\qquad $\\Braket{\\sum_i w_i} = N$\n\\item $\\braket{w_i} = \\sigma$, \\qquad\\qquad $\\Braket{\\sum_i w_i} = N\n  \\times \\sigma$\n\\item $\\braket{w_i} = 1/N$, \\quad\\qquad $\\Braket{\\sum_i w_i} = 1$\n\\item $\\braket{w_i} = \\sigma/N$, \\quad\\qquad $\\Braket{\\sum_i w_i} = \\sigma$\n\\end{enumerate}\nSo the four options are to have the average weight equal to unity, to\nthe cross section of the corresponding process, to one over the number\nof events, or the cross section over the event calls. In these four\ncases, the event weights sum up to the event number, the event number\ntimes the cross section, to unity, and to the cross section,\nrespectively. Note that neither of these really guarantees that all\nevent weights individually lie in the interval $0 \\leq w_i \\leq 1$.\n\nThe user can steer the normalization of events by using in \\sindarin\\\ninput files the string variable \\ttt{\\$sample\\_normalization}. The default is\n\\ttt{\\$sample\\_normalization = \"auto\"}, which uses option 1 for\nunweighted and 2 for weighted events, respectively. Note that this is\nalso what the Les Houches Event Format (LHEF) demands for both types\nof events. This is \\whizard's preferred mode, also for the reason, that\nevent normalizations are independent from the number of events. Hence,\nevent samples can be cut or expanded without further need to adjust\nthe normalization. The unit normalization (option 1) can be switched\non also for weighted events by setting the event normalization\nvariable equal to \\ttt{\"1\"}. Option 2 can be demanded\nby setting \\ttt{\\$sample\\_normalization = \"sigma\"}. Options 3 and 4 can\nbe set by \\ttt{\"1/n\"} and \\ttt{\"sigma/n\"}, respectively. \\whizard\\\naccepts small and capital letters for these expressions.\n\nIn the following section we show some examples when discussing the\ndifferent event formats available in \\whizard.\n\n%%%%%%%%%\n\n\\section{Event selection}\n\nThe \\ttt{selection} expression (cf.\\ Sec.~\\ref{subsec:analysis})\nreduces the event sample during generation or rescanning, selecting\nonly events for which the expression evaluates to \\ttt{true}.  Apart\nfrom internal analysis, the selection also applies to writing external\nfiles.  For instance, the following code generates a $e^+e^-\\to\nW^+W^-$ sample with longitudinally polarized $W$ bosons only:\n\\begin{footnotesize}\n\\begin{verbatim}\nprocess ww = \"e+\", \"e-\" => \"W-\", \"W+\"\npolarized \"W+\"\npolarized \"W-\"\n?polarized_events = true\nsqrts = 500\nselection = all Hel == 0 [\"W+\":\"W-\"]\nsimulate (ww) { n_events = 1000 }\n\\end{verbatim}\n\\end{footnotesize}\nThe number of events that end up in the sample on file is equal to the\nnumber of events with longitudinally polarized $W$s in the generated\nsample, so the file will contain less than 1000 events.\n\n\n%%%%%%%%%\n\n\\section{Supported event formats}\n\\label{sec:eventformats}\n\nEvent formats can either be distinguished whether they are plain\ntext (i.e. ASCII) formats or binary formats. Besides this, one can\nclassify event formats according to whether they are natively\nsupported by \\whizard\\ or need some external program or library to be\nlinked. Table~\\ref{tab:eventformats} gives a complete list of all\nevent formats available in \\whizard. The second column shows whether\nthese are ASCII or binary formats, the third column contains brief\nremarks about the corresponding format, while the last column tells\nwhether external programs or libraries are needed (which is the case\nonly for the HepMC formats).\n\n\\begin{table}\n  \\begin{center}\n    \\begin{tabular}{|l||l|l|r|}\\hline\n      Format & Type & remark & ext. \\\\\\hline\n      ascii & ASCII & \\whizard\\ verbose format & no\n      \\\\\n      Athena & ASCII & variant of HEPEVT & no\n      \\\\\n      debug & ASCII & most verbose \\whizard\\ format & no\n      \\\\\n      evx   & binary & \\whizard's home-brew & no\n      \\\\\n      HepMC & ASCII & HepMC format & yes\n      \\\\\n      HEPEVT & ASCII & \\whizard~1 style & no\n      \\\\\n      LCIO & ASCII & LCIO format & yes\n      \\\\\n      LHA  & ASCII & \\whizard~1/old Les Houches style &no\n      \\\\\n      LHEF & ASCII & Les Houches accord compliant & no\n      \\\\\n      long & ASCII & variant of HEPEVT & no\n      \\\\\n      mokka & ASCII & variant of HEPEVT & no\n      \\\\\n      short & ASCII & variant of HEPEVT & no\n      \\\\\n      StdHEP (HEPEVT) & binary & based on HEPEVT common block  & no\n      \\\\\n      StdHEP (HEPRUP/EUP) & binary & based on HEPRUP/EUP common block\n      & no \\\\\n      Weight stream & ASCII & just weights & no \\\\\n      \\hline\n    \\end{tabular}\n  \\end{center}\n  \\caption{\\label{tab:eventformats}\n    Event formats supported by \\whizard, classified according to\n    ASCII/binary formats and whether an external program or library is\n    needed to generate a file of this format. For both the HEPEVT and\n    the LHA format there is a more verbose variant.\n  }\n\\end{table}\nThe \"\\ttt{.evx}'' is \\whizard's native binary event format. If you\ndemand event generation and do not specify anything further, \\whizard\\\nwill write out its events exclusively in this binary format. So in the\nexamples discussed in the previous chapters (where we omitted all\ndetails about event formats), in all cases this and only this internal\nbinary format has been generated. The generation of this raw format\ncan be suppressed (e.g. if you want to have only one specific event\nfile type) by setting the variable \\verb|?write_raw = false|. However,\nif the raw event file is not present, \\whizard\\ is not able to re-use\nexisting events (e.g. from an ASCII file) and will regenerate events\nfor a given process. Note that from version v2.2.0 of \\whizard\\ on,\nthe program is able to (partially) reconstruct complete events also\nfrom other formats than its internal format (e.g. LHEF), but this is\nstill under construction and not yet complete.\n\nOther event formats can be written out by setting the variable\n\\ttt{sample\\_format = <format>}, where \\ttt{<format>} can be any of\nthe following supported variables:\n\\begin{itemize}\n\\item \\ttt{ascii}: a quite verbose ASCII format which contains lots of\n  information (an example is shown in the appendix). \\newline\n  Standard suffix: \\ttt{.evt}\n\\item \\ttt{debug}: an even more verbose ASCII format intended for\n  debugging which prints out also information about the internal data\n  structures \\newline\n  Standard suffix: \\ttt{.debug}\n\\item \\ttt{hepevt}: ASCII format that writes out a specific\n  incarnation of the HEPEVT common block (\\whizard~1\n  back-compatibility) \\newline\n  Standard suffix: \\ttt{.hepevt}\n\\item \\ttt{hepevt\\_verb}: more verbose version of \\ttt{hepevt} (\\whizard~1\n  back-compatibility) \\newline\n  Standard suffix: \\ttt{.hepevt.verb}\n\\item \\ttt{short}: abbreviated variant of the previous HEPEVT (\\whizard\\\n  1 back-compatibility)  \\newline\n  Standard suffix: \\ttt{.short.evt}\n\\item \\ttt{long}: HEPEVT variant that contains a little bit more\n  information than the short format but less than HEPEVT (\\whizard\\\n  1 back-compatibility)  \\newline\n  Standard suffix: \\ttt{.long.evt}\n\\item \\ttt{athena}: HEPEVT variant suitable for read-out in the ATLAS\n  ATHENA software environment (\\whizard\\\n  1 back-compatibility)  \\newline\n  Standard suffix: \\ttt{.athena.evt}\n\\item \\ttt{mokka}: HEPEVT variant suitable for read-out in the MOKKA\n  ILC software environment \\newline\n  Standard suffix: \\ttt{.mokka.evt}\n\\item \\ttt{lcio}: LCIO ASCII format (only available if LCIO is\n  installed and correctly linked) \\newline\n  Standard suffix: \\ttt{.lcio}\n\\item \\ttt{lha}: Implementation of the Les Houches Accord as it was in\n  the old MadEvent and \\whizard~1 \\newline\n  Standard suffix: \\ttt{.lha}\n\\item \\ttt{lha\\_verb}: more verbose version of \\ttt{lha} \\newline\n  Standard suffix: \\ttt{.lha.verb}\n\\item \\ttt{lhef}: Formatted Les Houches Accord implementation that\n  contains the XML headers \\newline\n  Standard suffix: \\ttt{.lhe}\n\\item \\ttt{hepmc}: HepMC ASCII format (only available if HepMC is\n  installed and correctly linked) \\newline\n  Standard suffix: \\ttt{.hepmc}\n\\item \\ttt{stdhep}: StdHEP binary format based on the HEPEVT common\n  block\n  \\newline\n  Standard suffix: \\ttt{.hep}\n\\item \\ttt{stdhep\\_up}: StdHEP binary format based on the HEPRUP/HEPEUP\n  common blocks\n  \\newline\n  Standard suffix: \\ttt{.up.hep}\n\\item \\ttt{stdhep\\_ev4}: StdHEP binary format based on the HEPEVT/HEPEV4\n  common blocks\n  \\newline\n  Standard suffix: \\ttt{.ev4.hep}\n\\item \\ttt{weight\\_stream}: Format that prints out only the event\n  weight (and maybe alternative ones) \\newline\n  Standard suffix: \\ttt{.weight.dat}\n\\end{itemize}\nOf course, the variable \\ttt{sample\\_format} can contain more than one\nof the above identifiers, in which case more  than one different event\nfile format is generated. The list above also shows the standard\nsuffixes for these event formats (remember, that the native binary\nformat of \\whizard\\ does have the suffix \\ttt{.evx}). (The suffix of\nthe different event formats can even be changed by the user by setting\nthe corresponding variable \\ttt{\\$extension\\_lhef = \"foo\"} or\n\\ttt{\\$extension\\_ascii\\_short = \"bread\"}. The dot is automatically\nincluded.)\n\nThe name of the corresponding event sample is taken to be the string\nof the name of the first process in the \\ttt{simulate}\nstatement. Remember, that conventionally the events for all processes\nin one \\ttt{simulate} statement will be written into one single event\nfile. So \\ttt{simulate (proc1, proc2)} will write events for the two\nprocesses \\ttt{proc1} and \\ttt{proc2} into one single event file with\nname \\ttt{proc1.evx}. The name can be changed by the user with the\ncommand \\ttt{\\$sample = \"<name>\"}.\n\nThe commands \\ttt{\\$sample} and \\ttt{sample\\_format} are both accepted\nas optional arguments of a \\ttt{simulate} command, so e.g.\n\\ttt{simulate (proc) \\{ \\$sample = \"foo\" sample\\_format = hepmc \\}}\ngenerates an event sample in the HepMC format for the process\n\\ttt{proc} in the file \\ttt{foo.hepmc}.\n\nExamples for event formats, for specifications of the event formats correspond\nthe different accords and publications~\\footnote{Some event formats, based on\n  the \\ttt{HEPEVT} or \\ttt{HEPEUP} common blocks, use fixed-form ASCII output\n  with a two-digit exponent for real numbers.  There are rare cases (mainly,\n  ISR photons) where the event record can contain numbers with absolute value\n  less than $10^{-99}$.  Since those numbers are not representable in that\n  format, \\whizard\\ will set all non-zero numbers below that value to $\\pm\n  10^{-99}$, when filling either common block.  Obviously, such values are\n  physically irrelevant, but in the output they are representable and\n  distinguishable from zero.}:\n\n\\paragraph{HEPEVT:}\n\nThe HEPEVT is an ASCII event format that does not contain an event\nfile header. There is a one-line header for each single event,\ncontaining four entries. The number of particles in the event\n(\\ttt{ISTHEP}), which is four for a fictitious example process $hh\\to\nhh$, but could be larger if e.g. beam remnants are demanded to be included in the\nevent. The second entry and third entry are the number of outgoing\nparticles and beam remnants, respectively. The event weight is the\nlast entry. For each particle in the event there are three lines:\nthe first one is the status according to the HEPEVT format,\n\\ttt{ISTHEP}, the second one the PDG code, \\ttt{IDHEP}, then there are\nthe one or two possible mother particle, \\ttt{JMOHEP}, the first and\nlast possible daughter particle, \\ttt{JDAHEP}, and the polarization.\nThe second line contains the three momentum components, $p_x$, $p_y$,\n$p_z$, the particle energy $E$, and its mass, $m$.\nThe last line contains the position of the vertex in the event\nreconstruction.\n\n\\begin{scriptsize}\n  \\begin{verbatim}\n 4 2 0  3.0574068604E+08\n 2 25 0 0 3 4 0\n  0.0000000000E+00  0.0000000000E+00  4.8412291828E+02  5.0000000000E+02  1.2500000000E+02\n  0.0000000000E+00  0.0000000000E+00  0.0000000000E+00  0.0000000000E+00  0.0000000000E+00\n 2 25 0 0 3 4 0\n  0.0000000000E+00  0.0000000000E+00 -4.8412291828E+02  5.0000000000E+02  1.2500000000E+02\n  0.0000000000E+00  0.0000000000E+00  0.0000000000E+00  0.0000000000E+00  0.0000000000E+00\n 1 25 1 2 0 0 0\n -1.4960220911E+02 -4.6042825611E+02  0.0000000000E+00  5.0000000000E+02  1.2500000000E+02\n  0.0000000000E+00  0.0000000000E+00  0.0000000000E+00  0.0000000000E+00  0.0000000000E+00\n 1 25 1 2 0 0 0\n  1.4960220911E+02  4.6042825611E+02  0.0000000000E+00  5.0000000000E+02  1.2500000000E+02\n  0.0000000000E+00  0.0000000000E+00  0.0000000000E+00  0.0000000000E+00  0.0000000000E+00\n  \\end{verbatim}\n\\end{scriptsize}\n\n\\paragraph{ASCII SHORT:}\n\nThis is basically the same as the HEPEVT standard, but very much\nabbreviated. The header line for each event is identical, but the first\nline per particle does only contain the PDG and the polarization,\nwhile the vertex information line is omitted.\n\n\\begin{scriptsize}\n  \\begin{verbatim}\n 4 2 0  3.0574068604E+08\n 25 0\n  0.0000000000E+00  0.0000000000E+00  4.8412291828E+02  5.0000000000E+02  1.2500000000E+02\n 25 0\n  0.0000000000E+00  0.0000000000E+00 -4.8412291828E+02  5.0000000000E+02  1.2500000000E+02\n 25 0\n -1.4960220911E+02 -4.6042825611E+02  0.0000000000E+00  5.0000000000E+02  1.2500000000E+02\n 25 0\n  1.4960220911E+02  4.6042825611E+02  0.0000000000E+00  5.0000000000E+02  1.2500000000E+02\n  \\end{verbatim}\n\\end{scriptsize}\n\n\\paragraph{ASCII LONG:}\n\nIdentical to the ASCII short format, but after each event there is a\nline containg two values: the value of the sample function to be\nintegrated over phase space, so basically the squared matrix element\nincluding all normalization factors, flux factor, structure functions\netc.\n\n\\begin{scriptsize}\n  \\begin{verbatim}\n 4 2 0  3.0574068604E+08\n 25 0\n  0.0000000000E+00  0.0000000000E+00  4.8412291828E+02  5.0000000000E+02  1.2500000000E+02\n 25 0\n  0.0000000000E+00  0.0000000000E+00 -4.8412291828E+02  5.0000000000E+02  1.2500000000E+02\n 25 0\n -1.4960220911E+02 -4.6042825611E+02  0.0000000000E+00  5.0000000000E+02  1.2500000000E+02\n 25 0\n  1.4960220911E+02  4.6042825611E+02  0.0000000000E+00  5.0000000000E+02  1.2500000000E+02\n  1.0000000000E+00  1.0000000000E+00\n  \\end{verbatim}\n\\end{scriptsize}\n\n\\paragraph{ATHENA:}\n\nQuite similar to the HEPEVT ASCII format. The header line, however,\ndoes contain only two numbers: an event counter, and the number of\nparticles in the event. The first line for each particle lacks the\npolarization information (irrelevant for the ATHENA environment), but\nhas as leading entry an ordering number counting the particles in the\nevent. The vertex information line has only the four relevant position\nentries.\n\n\n\\begin{scriptsize}\n  \\begin{verbatim}\n 0 4\n 1 2 25 0 0 3 4\n  0.0000000000E+00  0.0000000000E+00  4.8412291828E+02  5.0000000000E+02  1.2500000000E+02\n  0.0000000000E+00  0.0000000000E+00  0.0000000000E+00  0.0000000000E+00\n 2 2 25 0 0 3 4\n  0.0000000000E+00  0.0000000000E+00 -4.8412291828E+02  5.0000000000E+02  1.2500000000E+02\n  0.0000000000E+00  0.0000000000E+00  0.0000000000E+00  0.0000000000E+00\n 3 1 25 1 2 0 0\n -1.4960220911E+02 -4.6042825611E+02  0.0000000000E+00  5.0000000000E+02  1.2500000000E+02\n  0.0000000000E+00  0.0000000000E+00  0.0000000000E+00  0.0000000000E+00\n 4 1 25 1 2 0 0\n  1.4960220911E+02  4.6042825611E+02  0.0000000000E+00  5.0000000000E+02  1.2500000000E+02\n  0.0000000000E+00  0.0000000000E+00  0.0000000000E+00  0.0000000000E+00\n  \\end{verbatim}\n\\end{scriptsize}\n\n\\paragraph{MOKKA:}\n\nQuite similar to the ASCII short format, but the event entries are the\nparticle status, the PDG code, the first and last daughter, the\nthree spatial components of the momentum, as well as the mass.\n\n\\begin{scriptsize}\n\\begin{verbatim}\n 4 2 0  3.0574068604E+08\n 2 25 3 4  0.0000000000E+00  0.0000000000E+00  4.8412291828E+02  1.2500000000E+02\n 2 25 3 4  0.0000000000E+00  0.0000000000E+00 -4.8412291828E+02  1.2500000000E+02\n 1 25 0 0 -1.4960220911E+02 -4.6042825611E+02  0.0000000000E+00  1.2500000000E+02\n 1 25 0 0  1.4960220911E+02  4.6042825611E+02  0.0000000000E+00  1.2500000000E+02\n\\end{verbatim}\n\\end{scriptsize}\n\n\\paragraph{LHA:}\n\nThis is the implementation of the Les Houches Accord, as it was used\nin \\whizard\\ 1 and the old MadEvent. There is a first line containing\nsix entries: 1. the number of particles in the event, \\ttt{NUP},\n2. the subprocess identification index, \\ttt{IDPRUP}, 3. the event\nweight, \\ttt{XWGTUP}, 4. the scale of the process, \\ttt{SCALUP},\n5. the value or status of $\\alpha_{QED}$, \\ttt{AQEDUP}, 6. the value\nfor $\\alpha_s$, \\ttt{AQCDUP}. The next seven lines contain as many\nentries as there are particles in the event: the first one has the PDG\ncodes, \\ttt{IDUP}, the next two the first and second mother of the particles,\n\\ttt{MOTHUP}, the fourth and fifth line the two color indices,\n\\ttt{ICOLUP}, the next one the status of the particle, \\ttt{ISTUP},\nand the last line the polarization information, \\ttt{ISPINUP}.\nAt the end of the event there are as lines for each particles with the\ncounter in the event and the four-vector of the particle. For more\ninformation on this event format confer~\\cite{LesHouches}.\n\n\\begin{scriptsize}\n  \\begin{verbatim}\n 25 25  5.0000000000E+02  5.0000000000E+02 -1 -1 -1 -1 3 1\n  1.0000000000E-01  1.0000000000E-03  1.0000000000E+00 42\n     4     1  3.0574068604E+08  1.000000E+03 -1.000000E+00 -1.000000E+00\n    25    25    25    25\n     0     0     1     1\n     0     0     2     2\n     0     0     0     0\n     0     0     0     0\n    -1    -1     1     1\n     9     9     9     9\n     1  5.0000000000E+02  0.0000000000E+00  0.0000000000E+00  4.8412291828E+02\n     2  5.0000000000E+02  0.0000000000E+00  0.0000000000E+00 -4.8412291828E+02\n     3  5.0000000000E+02 -1.4960220911E+02 -4.6042825611E+02  0.0000000000E+00\n     4  5.0000000000E+02  1.4960220911E+02  4.6042825611E+02  0.0000000000E+00\n  \\end{verbatim}\n\\end{scriptsize}\n\n\\paragraph{LHEF:}\n\nThis is the modern version of the Les Houches accord event format\n(LHEF), for the details confer the corresponding publication~\\cite{LHEF}.\n\n\\begin{scriptsize}\n  \\begin{verbatim}\n<LesHouchesEvents version=\"1.0\">\n<header>\n  <generator_name>WHIZARD</generator_name>\n  <generator_version>3.0.0_beta</generator_version>\n</header>\n<init>\n 25 25  5.0000000000E+02  5.0000000000E+02 -1 -1 -1 -1 3 1\n  1.0000000000E-01  1.0000000000E-03  1.0000000000E+00 42\n</init>\n<event>\n 4 42  3.0574068604E+08  1.0000000000E+03 -1.0000000000E+00 -1.0000000000E+00\n 25 -1 0 0 0 0  0.0000000000E+00  0.0000000000E+00  4.8412291828E+02  5.0000000000E+02  1.2500000000E+02  0.0000000000E+00  9.0000000000E+00\n 25 -1 0 0 0 0  0.0000000000E+00  0.0000000000E+00 -4.8412291828E+02  5.0000000000E+02  1.2500000000E+02  0.0000000000E+00  9.0000000000E+00\n 25 1 1 2 0 0 -1.4960220911E+02 -4.6042825611E+02  0.0000000000E+00  5.0000000000E+02  1.2500000000E+02  0.0000000000E+00  9.0000000000E+00\n 25 1 1 2 0 0  1.4960220911E+02  4.6042825611E+02  0.0000000000E+00  5.0000000000E+02  1.2500000000E+02  0.0000000000E+00  9.0000000000E+00\n</event>\n</LesHouchesEvents>\n  \\end{verbatim}\n\\end{scriptsize}\n\nNote that for the LHEF format, there are different versions according\nto the different stages of agreement. They can be addressed from\nwithin the \\sindarin\\ file by setting the string variable\n\\ttt{\\$lhef\\_version} to one of (at the moment) three values:\n\\ttt{\"1.0\"}, \\ttt{\"2.0\"}, or \\ttt{\"3.0\"}. The examples above\ncorresponds (as is indicated in the header) to the version \\ttt{\"1.0\"}\nof the LHEF format. Additional information in form of alternative\nsquared matrix elements or event weights in the event are the most\nprominent features of the other two more advanced versions. For more\ndetails confer the literature.\n\n\\vspace{.5cm}\n\nSample files for the default ASCII format as well as for the debug\nevent format are shown in the appendix.\n\n%%%%%%%%%\n\n\\section[Interfaces to Parton Showers, Matching and\nHadronization]{Interfaces to Parton Showers, Matching\\\\and\n  Hadronization}\n\nThis section describes the interfaces to the internal parton shower as\nwell as the parton shower and hadronization routines from\n\\pythia. Moreover, our implementation of the MLM matching making use\nof the parton showers is described. Sample \\sindarin\\ files are\nlocated in the \\ttt{share/examples} directory.\nAll input files come in two versions, one using the internal shower,\nending in \\ttt{W.sin}, and one using \\pythia's shower, ending in\n\\ttt{P.sin}. Thus we state all file names as ending with \\ttt{X.sin},\nwhere \\ttt{X} has to be replaced by either \\ttt{W} or \\ttt{P}.\nThe input files include \\ttt{EENoMatchingX.sin} and\n\\ttt{DrellYanNoMatchingX.sin} for $e^+ e^- \\to hadrons$ and $p\\bar{p}\n\\to Z$ without matching. The corresponding \\sindarin\\ files with\nmatching enabled are \\ttt{EEMatching2X.sin} to \\ttt{EEMatching5X.sin}\nfor $e^+ e^- \\to hadrons$ with a different number of partons included\nin the matrix element and \\ttt{DrallYanMatchingX.sin} for Drell-Yan\nwith one matched emission.\n\n\\subsection{Parton Showers and Hadronization}\n\nFrom version 2.1 onwards, \\whizard\\ contains an implementation of an\nanalytic parton shower as presented in \\cite{Kilian:2011ka}, providing\nthe opportunity to perform the parton shower from whithin\n\\whizard. Moreover, an interface to \\pythia\\ is included, which can be\nused to delegate the parton shower to \\pythia. The same interface can\nbe used to hadronize events using the generated events using \\pythia's\nhadronization routines. Note that by \\pythia's default, when\nperforming initial-state radiation multiple interactions are included\nand when performing the hadronization hadronic decays are included. If\nrequired, these additional steps have to be switched off using the\ncorresponding arguments for \\pythia's \\ttt{PYGIVE} routine via the\n\\ttt{\\$ps\\_PYTHIA\\_PYGIVE} string.\n\nNote that from version 2.2.4 on the earlier flag\n\\ttt{--enable-shower} flag has been abandoned, and there is only a\nflag to either compile or not compile the interally attached\n\\pythia\\ttt{6} package (\\ttt{--enable-pythia6}) last release of\nthe \\fortran\\ \\pythia, v6.427) as well as the interface. It can be\ninvoked by the following \\sindarin\\ keywords:\\\\[2ex]\n%\n\\centerline{\\begin{tabular}{|l|l|}\n\\hline\\ttt{?ps\\_fsr\\_active = true} & master switch for final-state\nparton showers\\\\\\hline\n\\ttt{?ps\\_isr\\_active = true} & master switch for initial-state parton\nshowers\\\\\\hline\n\\ttt{?ps\\_taudec\\_active = true} & master switch for $\\tau$ decays (at\nthe moment only via \\ttt{TAUOLA}\\\\\\hline\n\\ttt{?hadronization\\_active = true} & master switch to enable\nhadronization\\\\\\hline\n\\ttt{\\$shower\\_method = \"PYTHIA6\"} & switch to use \\pythiasix's parton\nshower instead of \\\\ &\n \\whizard's own shower\\\\\\hline\n\\end{tabular}}\\mbox{}\n\n\\vspace{4mm}\n\nIf either \\ttt{?ps\\_fsr\\_active} or \\ttt{?ps\\_isr\\_active} is set to \\verb|true|, the\nevent will be transferred to the internal shower routines or the \\pythia\\ data structures,\nand the chosen shower steps (initial- and final-state radiation) will be\nperformed. If hadronization is enabled via the \\ttt{?hadronization\\_active} switch, \\whizard\\ will call \\pythia's hadronization routine.\nThe hadron\\-ization can be applied to events showered using the internal shower or showered using \\pythia's shower routines, as well as unshowered events.\nAny necessary transfer of event data to \\pythia\\ is automatically taken care of within \\whizard's shower interface.\nThe resulting (showered and/or hadronized) event will be transferred back to \\whizard,\nthe former final particles will be marked as intermediate. The\nanalysis can be applied to a showered and/or hadronized event just\nlike in the unshowered/unhadronized case. Any event file can be used\nand will contain the showered/hadronized event.\n\nSettings for the internal analytic parton shower are set via the following \\sindarin\\ variables:\\\\[2ex]\n\\begin{description}\n\\item[\\ttt{ps\\_mass\\_cutoff}] The cut-off in virtuality, below\n  which, partons are assumed to radiate no more. Used for both ISR and\n  FSR. Given in $\\mbox{GeV}$. (Default = 1.0)\n\\item[\\ttt{ps\\_fsr\\_lambda}] The value for $\\Lambda$ used in\n  calculating the value of the running coupling constant $\\alpha_S$\n  for Final State Radiation. Given in $\\mbox{GeV}$. (Default = 0.29)\n\\item[\\ttt{ps\\_isr\\_lambda}] The value for $\\Lambda$ used in\n  calculating the value of the running coupling constant $\\alpha_S$\n  for Initial State Radiation. Given in $\\mbox{GeV}$. (Default = 0.29)\n\\item[\\ttt{ps\\_max\\_n\\_flavors}] Number of quark flavours taken\n  into account during shower evolution. Meaningful choices are 3 to\n  include $u,d,s$-quarks, 4 to include $u,d,s,c$-quarks and 5 to\n  include $u,d,s,c,b$-quarks. (Default = 5)\n\\item[\\ttt{?ps\\_isr\\_alphas\\_running}] Switch to decide between a\n  constant $\\alpha_S$, given by \\ttt{ps\\_fixed\\_alphas}, and a\n  running $\\alpha_S$, calculated using \\ttt{ps\\_isr\\_lambda} for\n  ISR. (Default = true)\n\\item[\\ttt{?ps\\_fsr\\_alphas\\_running}] Switch to decide between a\n  constant $\\alpha_S$, given by \\ttt{ps\\_fixed\\_alphas}, and a\n  running $\\alpha_S$, calculated using \\ttt{ps\\_fsr\\_lambda} for\n  FSR. (Default = true)\n\\item[\\ttt{ps\\_fixed\\_alphas}] Fixed value of $\\alpha_S$ for the\n  parton shower. Used if either one of the variables\n  \\ttt{?ps\\_fsr\\_alphas\\_running}\n  or \\ttt{?ps\\_isr\\_alphas\\_running} are set to\n  \\verb|false|. (Default = 0.0)\n\\item[\\ttt{?ps\\_isr\\_angular\\_ordered}] Switch for angular ordered\n  ISR. (Default = true )\\footnote{The FSR is always simulated with\n    angular ordering enabled.}\n\\item[\\ttt{ps\\_isr\\_primordial\\_kt\\_width}] The width in\n  $\\mbox{GeV}$ of the Gaussian assumed to describe the transverse\n  momentum of partons inside the proton. Other shapes are not yet\n  implemented. (Default = 0.0)\n\\item[\\ttt{ps\\_isr\\_primordial\\_kt\\_cutoff}] The maximal transverse\n  momentum in $\\mbox{GeV}$ of a parton inside the proton. Used as a\n  cut-off for the Gaussian. (Default = 5.0)\n\\item[\\ttt{ps\\_isr\\_z\\_cutoff}] Maximal $z$-value in initial state\n  branchings. (Default = 0.999)\n\\item[\\ttt{ps\\_isr\\_minenergy}] Minimal energy in $\\mbox{GeV}$ of\n  an emitted timelike or final parton. Note that the energy is not\n  calculated in the labframe but in the center-of-mas frame of the two\n  most initial partons resolved so far, so deviations may\n  occur. (Default = 1.0)\n\\item[\\ttt{ps\\_isr\\_tscalefactor}] Factor for the starting scale in\n  the initial state shower evolution. ( Default = 1.0 )\n\\item[\\ttt{?ps\\_isr\\_only\\_onshell\\_emitted\\_partons}] Switch to\n  allow only for on-shell emitted partons, thereby rejecting all\n  possible final state parton showers starting from partons emitted\n  during the ISR. (Default = false)\n\\end{description}\n\nSettings for the \\pythia\\ are transferred using the following\n\\sindarin\\ variables:\\\\[2ex]\n\\centerline{\\begin{tabular}{|l|l|}\n\\hline\\ttt{?ps\\_PYTHIA\\_verbose} & if set to false, output from\n\\pythia\\ will be suppressed\\\\\\hline\n\\ttt{\\$ps\\_PYTHIA\\_PYGIVE} & a string containing settings transferred\nto \\pythia's \\ttt{PYGIVE} subroutine.\\\\ & The format is explained in\nthe \\pythia\\ manual. The limitation to 100 \\\\ & characters mentioned\nthere does not apply here, the string is split \\\\ & appropriately\nbefore being transferred to \\pythia.\\\\\\hline\n\\end{tabular}}\\mbox{}\n\n\\vspace{4mm}\n\nNote that the included version of \\pythia\\ uses \\lhapdf\\ for initial state\nradiation whenever this is available, but the PDF set has to be set\nmanually in that case using the keyword \\ttt{ps\\_PYTHIA\\_PYGIVE}.\n\n\\subsection{Parton shower -- Matrix Element Matching}\n\nAlong with the inclusion of the parton showers, \\whizard\\ includes an\nimplementation of the MLM matching procedure. For a detailed\ndescription of the implemented steps see \\cite{Kilian:2011ka}. The\ninclusion of MLM matching still demands some manual settings in the\n\\sindarin\\ file. For a given base process and a matching of $N$\nadditional jets, all processes that can be obtained by attaching up to\n$N$ QCD splittings, either a quark emitting a gluon or a gluon\nsplitting into two quarks ar two gluons, have to be manually specified\nas additional processes. These additional processes need to be\nincluded in the \\ttt{simulate} statement along with the original\nprocess. The \\sindarin\\ variable \\ttt{mlm\\_nmaxMEjets} has to be\nset to the maximum number of additional jets $N$. Moreover additional\ncuts have to be specified for the additional processes.\n\\begin{verbatim}\n  alias quark = u:d:s:c\n  alias antiq = U:D:S:C\n  alias j = quark:antiq:g\n\n  ?mlm_matching = true\n  mlm_ptmin = 5 GeV\n  mlm_etamax = 2.5\n  mlm_Rmin = 1\n\n  cuts = all Dist > mlm_Rmin [j, j]\n         and all Pt > mlm_ptmin [j]\n         and all abs(Eta) < mlm_etamax [j]\n\\end{verbatim}\nNote that the variables \\ttt{mlm\\_ptmin}, \\ttt{mlm\\_etamax} and\n\\ttt{mlm\\_Rmin} are used by the matching routine. Thus, replacing the\nvariables in the \\ttt{cut} expression and omitting the assignment\nwould destroy the matching procedure.\n\nThe complete list of variables introduced to steer the matching procedure is as follows:\n\\begin{description}\n\\item[\\ttt{?mlm\\_matching\\_active}] Master switch to enable MLM\n  matching. (Default = false)\n\\item[\\ttt{mlm\\_ptmin}] Minimal transverse momentum, also used in\n  the definition of a jet\n\\item[\\ttt{mlm\\_etamax}] Maximal absolute value of pseudorapidity\n  $\\eta$, also used in defining a jet\n\\item[\\ttt{mlm\\_Rmin}] Minimal $\\eta-\\phi$ distance $R_{min}$\n\\item[\\ttt{mlm\\_nmaxMEjets}] Maximum number of jets $N$\n\\item[\\ttt{mlm\\_ETclusfactor}] Factor to vary the jet\n  definition. Should be $\\geq 1$ for complete coverage of phase\n  space. (Default = 1)\n\\item[\\ttt{mlm\\_ETclusminE}] Minimal energy in the variation of the\n  jet definition\n\\item[\\ttt{mlm\\_etaclusfactor}] Factor in the variation of the jet\n  definition. Should be $\\leq 1$ for complete coverage of phase\n  space. (Default = 1)\n\\item[\\ttt{mlm\\_Rclusfactor}] Factor in the variation of the jet\n  definition. Should be $\\ge 1$ for complete coverage of phase\n  space. (Default = 1)\n\\end{description}\nThe variation of the jet definition is a tool to asses systematic\nuncertainties introduced by the matching procedure (See section 3.1 in\n\\cite{Kilian:2011ka}).\n\n\n%%%%%%%%%\n\n\\section{Rescanning and recalculating events}\n\\label{sec:rescan}\n\nIn the simplest mode of execution, \\whizard\\ handles its events at the\npoint where they are generated.  It can apply event transforms such as\ndecays or shower (see above), it can analyze the events, calculate and\nplot observables, and it can output them to file.  However, it is also\npossible to apply two different operations to those events in\nparallel, or to reconsider and rescan an event sample that has been\npreviously generated.\n\nWe first discuss the possibilities that \\ttt{simulate} offers.  For\neach event, \\whizard\\ calculates the matrix element for the hard\ninteraction, supplements this by Jacobian and phase-space factors in\norder to obtain the event weight, optionally applies a rejection step\nin order to gather uniformly weighted events, and applies the\ncuts and analysis setup.  We may ask about the event matrix element or\nweight, or the analysis result, that we would have obtained for a\ndifferent setting.  To this end, there is an \\ttt{alt\\_setup} option.\n\nThis option allows us to recalculate, event by event, the matrix\nelement, weight, or analysis contribution with a different parameter\nset but identical kinematics.  For instance, we may evaluate a\ndistribution for both zero and non-zero anomalous coupling \\ttt{fw}\nand enter some observable in separate histograms:\n\n\\begin{footnotesize}\n\\begin{verbatim}\n  simulate (some_proc) {\n      fw = 0\n      analysis = record hist1 (eval Pt [H])\n    alt_setup = {\n       fw = 0.01\n       analysis = record hist2 (eval Pt [H])\n    }\n  }\n\\end{verbatim}\n\\end{footnotesize}\n\nIn fact, the \\ttt{alt\\_setup} object is not restricted to a single\ncode block (enclosed in curly braces) but can take a list of those,\n\\begin{footnotesize}\n\\begin{verbatim}\n  alt_setup = { fw = 0.01 }, { fw = 0.02 }, ...\n\\end{verbatim}\n\\end{footnotesize}\nEach block provides the environment for a separate evaluation of the\nevent data.  The generation of these events, i.e., their kinematics,\nis still steered by the primary environment.\n\nThe \\ttt{alt\\_setup} blocks may modify various settings that affect the\nevaluation of an event, including physical parameters, PDF choice,\ncuts and analysis, output format, etc.  This must not (i.e., cannot)\naffect the kinematics of an event, so don't modify particle masses.\nWhen applying cuts, they can only reduce the generated event sample,\nso they apply on top of the primary cuts for the simulation.\n\nAlternatively, it is possible to \\ttt{rescan} a sample that has been\ngenerated by a previous \\ttt{simulate} command:\n\\begin{footnotesize}\n\\begin{verbatim}\n  simulate (some_proc) { $sample = \"my_events\"\n    analysis = record hist1 (eval Pt [H])\n  }\n  ?update_sqme = true\n  ?update_weight = true\n  rescan \"my_events\" (some_proc) {\n    fw = 0.01\n    analysis = record hist2 (eval Pt [H])\n  }\n  rescan \"my_events\" (some_proc) {\n    fw = 0.05\n    analysis = record hist3 (eval Pt [H])\n  }\n\\end{verbatim}\n\\end{footnotesize}\nIn more complicated situation, rescanning is more transparent and\noffers greater flexibility than doing all operations at the very point\nof event generation.\n\nCombining these features with the \\ttt{scan} looping construct, we\nalready cover a considerable range of applications.  (There are\nlimitations due to the fact that \\sindarin\\ doesn't provide array\nobjects, yet.)  Note that the \\ttt{rescan} construct also allows\nfor an \\ttt{alt\\_setup} option.\n\nYou may generate a new sample by rescanning, for which you may choose\nany output format:\n\\begin{footnotesize}\n\\begin{verbatim}\n  rescan \"my_events\" (some_proc) {\n    selection = all Pt > 100 GeV [H]\n    $sample = \"new_events\"\n    sample_format = lhef\n  }\n\\end{verbatim}\n\\end{footnotesize}\n\nThe event sample that you rescan need not be an internal raw \\whizard\\\nfile, as above.  You may rescan a LHEF file,\n\\begin{footnotesize}\n\\begin{verbatim}\n  rescan \"lhef_events\" (proc) {\n    $rescan_input_format = \"lhef\"\n  }\n\\end{verbatim}\n\\end{footnotesize}\nThis file may have any origin, not necessarily from \\whizard.  To\nunderstand such an external file, \\whizard\\ must be able to\nreconstruct the hard process and match it to a process with a known\nname (e.g., \\ttt{proc}), that has been defined in the \\sindarin\\ script\npreviously.\n\nWithin its limits, \\whizard\\ can thus be used for translating an event\nsample from one format to another format.\n\nThere are three important switches that control the rescanning\nbehavior.  They can be set or unset independently.\n\\begin{itemize}\n\\item \\ttt{?update\\_sqme} (default: false).\n  If true, \\whizard\\ will recalculate the hard matrix element for each\n  event.  When applying an analysis, the recalculated squared matrix\n  element (averaged and summed over quantum numbers as usual) is\n  available as the variable \\ttt{sqme\\_prc}.  This may be related to\n  \\ttt{sqme\\_ref}, the corresponding\n  value in the event file, if available.  (For the \\ttt{alt\\_env}\n  option, this switch is implied.)\n\\item \\ttt{?update\\_weight} (default: false).\n  If true, \\whizard\\ will recalculate the event weight according to\n  the current environment and apply this to the event.  In particular,\n  the user may apply a \\ttt{reweight} expression.  In an\n  analysis, the new weight value is available as \\ttt{weight\\_prc}, to\n  be related\n  to \\ttt{weight\\_ref} from the sample.  The updated weight will be\n  applied for histograms and averages.  An unweighted event sample\n  will thus be transformed into a weighted event sample.  (This switch\n  is also implied for the \\ttt{alt\\_env} option.)\n\\item \\ttt{?update\\_event} (default: false).\n  If true, \\whizard\\ will generate a new decay chain etc., if\n  applicable.  That is, it reuses just the particles in the hard\n  process.  Otherwise, the complete event is kept as it is written to\n  file.\n\\end{itemize}\nFor these options to make sense, \\whizard\\ must have access to a full\nprocess object, so the \\sindarin\\ script must contain not just a\ndefinition but also a \\ttt{compile} command for the matrix elements in\nquestion.\n\nIf an event file (other than raw format) contains several processes as\na mixture, they must be identifiable by a numeric ID.  \\whizard\\ will\nrecognize the processes if their respective \\sindarin\\ definitions\ncontain appropriate \\ttt{process\\_num\\_id} options, such as\n\\begin{footnotesize}\n\\begin{verbatim}\n  process foo = u, ubar => d, dbar { process_num_id = 42 }\n\\end{verbatim}\n\\end{footnotesize}\n\nCertain event-file formats, such as LHEF, support alternative\nmatrix-element values or weights.  \\whizard\\ can thus write both\noriginal and\nrecalculated matrix-element and weight values.\nOther formats support only a single\nevent weight, so the \\ttt{?update\\_weight} option is necessary for a\nvisible effect.\n\nExternal event files in formats such as LHEF, HepMC, or LCIO, also may\ncarry information about the value of the strong coupling $\\alpha_s$\nand the energy scale of each event.  This information will also be\nprovided by \\whizard\\ when writing external event files.  When such an\nevent file is rescanned, the user has the choice to either user the\n$\\alpha_s$ value that \\whizard\\ defines in the current context (or the\nmethod for obtaining an event-specific running $\\alpha_s$ value), or\noverride this for each event by using the value in the event file.\nThe corresponding parameter is \\ttt{?use\\_alphas\\_from\\_file}, which\nis false by default.  Analogously, the parameter\n\\ttt{?use\\_scale\\_from\\_file} may be set to override the scale\ndefinition in the current context.  Obviously, these settings\ninfluence matrix-element recalculation and therefore require\n\\ttt{?update\\_sqme} to be set in order to become operational.\n\n%%%%%%%%%\n\n\\section{Negative weight events}\nFor usage at NLO refer to Subsection~\\ref{ss:fixedorderNLOevents}.\nIn case, you have some other mechanism to produce events with negative\nweights (e.g. with the \\ttt{weight = {\\em <expr>}} command), keep in\nmind that you should activate \\ttt{?negative\\_weights = true} and\n\\ttt{unweighted = false}.  The generation of unweighted events with\nvarying sign (also known as events and counter events) is currently not\nsupported.\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\\chapter{Internal Data Visualization}\n\\label{chap:visualization}\n\n\\section{GAMELAN}\n\nThe data values and tables that we have introduced in the previous section can\nbe visualized using built-in features of \\whizard.  To be precise,\n\\whizard\\ can write \\LaTeX\\ code which incorporates code in the graphics\nlanguage GAMELAN to produce a pretty-printed account of observables,\nhistograms, and plots.\n\nGAMELAN is a macro package for MetaPost, which is part of the\n\\TeX/\\LaTeX\\ family.  MetaPost, a derivative of Knuth's MetaFont language for\nfont design, is usually bundled with the \\TeX\\ distribution, but might need a\nseparate switch for installation.  The GAMELAN macros are contained in a\nsubdirectory of the \\whizard\\ package.  Upon installation, they will be\ninstalled in the appropriate directory, including the \\ttt{gamelan.sty} driver\nfor \\LaTeX.  \\whizard\\ uses a subset of GAMELAN's graphics macros\ndirectly, but it allows for access to the full package if desired.\n\nAn (incomplete) manual for GAMELAN can be found in the \\ttt{share/doc}\nsubdirectory of the \\whizard\\ system.  \\whizard\\ itself uses a subset of the\nGAMELAN capabilities, interfaced by \\sindarin\\ commands and parameters.  They\nare described in this chapter.\n\nTo process analysis output beyond writing tables to file, the\n\\ttt{write\\_analysis} command described in the previous section should be\nreplaced by \\ttt{compile\\_analysis}, with the same syntax:\n\\begin{quote}\n  \\begin{footnotesize}\n    \\ttt{compile\\_analysis (\\emph{analysis-tags}) \\{ \\ttt{\\emph{options}} \\}}\n  \\end{footnotesize}\n\\end{quote}\nwhere \\ttt{\\emph{analysis-tags}}, a comma-separated list of analysis objects,\nis optional.  If there are no tags, all analysis objects are processed.  The\n\\ttt{\\emph{options}} script of local commands is also optional, of course.\n\nThis command will perform the following actions:\n\\begin{enumerate}\n\\item\n  It writes a data file in default format, as \\ttt{write\\_analysis} would do.\n  The file name is given by \\ttt{\\$out\\_file}, if nonempty.  The file must not\n  be already open, since the command needs a self-contained file, but the name\n  is otherwise arbitrary.  If the value of \\ttt{\\$out\\_file} is empty, the\n  default file name is \\ttt{whizard\\_analysis.dat}.\n\\item\n  It writes a driver file for the chosen datasets, whose name is derived from\n  the data file by replacing the file extension of the data file with the\n  extension \\ttt{.tex}.  The driver file is a \\LaTeX\\ source file which\n  contains embedded GAMELAN code that handles the selected graphics data.  In\n  the \\LaTeX\\ document, there is a separate section for each contained\n  dataset. Furthermore, a process-/analysis-specific makefile with the\n  name \\ttt{<process\\_name>\\_ana.makefile} is created that can be used\n  to generate postscript or PDF output from the \\LaTeX\\ source. If the\n  steering flag \\ttt{?analysis\\_file\\_only} is set to \\ttt{true}, then\n  the \\LaTeX\\ file and the makefile are only written, but no execution\n  of the makefile resulting in compilation of the \\LaTeX\\ code (see\n  the next item) is invoked.\n\\item\n  As mentioned above, if the flag \\ttt{?analysis\\_file\\_only} is set\n  to \\ttt{false} (which is the default), the driver file is processed\n  by \\LaTeX (invoked by calling the makefile with the name\n  \\ttt{<process\\_name>\\_ana.makefile}), which generates an appropriate\n  GAMELAN source file with extension \\ttt{.mp}.  This code is executed\n  (calling GAMELAN/MetaPost, and again \\LaTeX\\ for typesetting embedded\n  labels).  There is a second \\LaTeX\\ pass (automatically done by the\n  makefile) which collects the results, and finally conversion to\n  PostScript and PDF formats.\n\\end{enumerate}\n\nThe resulting PostScript or PDF file -- the file name is the name of the data\nfile with the extension replaced by \\ttt{.ps} or \\ttt{.pdf}, respectively\n-- can be printed or viewed with an appropriate viewer such as \\ttt{gv}.  The\nviewing command is not executed automatically by \\whizard.\n\nNote that \\LaTeX\\ will write further files with extensions \\ttt{.log},\n\\ttt{.aux}, and \\ttt{.dvi}, and GAMELAN will produce auxiliary files with\nextensions \\ttt{.ltp} and \\ttt{.mpx}. The log file in particular, could\noverwrite \\whizard's log file if the basename is identical.  Be careful to use\na value for \\ttt{\\$out\\_file} which is not likely to cause name clashes.\n\n\n\\subsection{User-specific changes}\n\nIn the case, that the \\sindarin\\ \\ttt{compile\\_analysis} command is\ninvoked and the flag named \\ttt{?analysis\\_file\\_only} is not changed\nfrom its default value \\ttt{false}, \\whizard\\ calls the\nprocess-/analysis-specific makefile triggering the compilation of the\n\\LaTeX\\ code and the GAMELAN plots and histograms. If the user wants\nto edit the analysis output, for example changing captions, headlines,\nlabels, properties of the plots, graphs and histograms using GAMELAN\nspecials etc., this is possible and the output can be regenerated\nusing the makefile. The user can also directly invoke the GAMELAN\nscript, \\ttt{whizard-gml}, that is installed in the binary directly\nalong with the \\whizard\\ binary and other scripts. Note however, that\nthe \\LaTeX\\ environment for the specific style files have to be set by\nhand (the command line invocation in the makefile does this\nautomatically). Those style files are generally written into\n\\ttt{share/texmf/whizard/} directory. The user can execute the\ncommands in the same way as denoted in the process-/analysis-specific\nmakefile by hand.\n\n\n%%%%%\n\n\\section{Histogram Display}\n\n\n%%%%%\n\n\\section{Plot Display}\n\n\n\\section{Graphs}\n\\label{sec:graphs}\n\nGraphs are an additional type of analysis object.  In contrast to histograms\nand plots, they do not collect data directly, but they rather act as\ncontainers for graph elements, which are copies of existing histograms and\nplots.  Their single purpose is to be displayed by the GAMELAN driver.\n\nGraphs are declared by simple assignments such as\n\\begin{quote}\n  \\begin{footnotesize}\n    \\ttt{graph g1 = hist1}\n\\\\\n    \\ttt{graph g2 = hist2 \\& hist3 \\& plot1}\n  \\end{footnotesize}\n\\end{quote}\nThe first declaration copies a single histogram into the graph, the second one\ncopies two histograms and a plot.  The syntax for collecting analysis objects\nuses the \\ttt{\\&} concatenation operator, analogous to string concatenation.\nIn the assignment, the rhs must contain only histograms and plots.  Further\nconcatenating previously declared graphs is not supported.\n\nAfter the graph has been declared, its contents can be written to file\n(\\ttt{write\\_analysis}) or, usually, compiledd by the \\LaTeX/GAMELAN driver\nvia the \\ttt{compile\\_analysis} command.\n\nThe graph elements on the right-hand side of the graph assignment are copied\nwith their current data content.  This implies a well-defined order of\nstatements: first, histograms and plots are declared, then they are filled via\n\\ttt{record} commands or functions, and finally they can be collected for\ndisplay by graph declarations.\n\nA simple graph declaration without options as above is possible, but usually\nthere are option which affect the graph display.  There are two kinds of\noptions: graph options and drawing options.  Graph options apply to the graph\nas a whole (title, labels, etc.) and are placed in braces on the lhs of the\nassigment.  Drawing options apply to the individual graph elements\nrepresenting the contained histograms and plots, and are placed together with\nthe graph element on the rhs of the assignment.  Thus, the complete syntax for\nassigning multiple graph elements is\n\\begin{quote}\n  \\begin{footnotesize}\n    \\ttt{graph \\emph{graph-tag} \\{ \\emph{graph-options} \\}}\n\\\\\n    \\ttt{= \\emph{graph-element-tag1} \\{ \\emph{drawing-options1} \\}}\n\\\\\n    \\ttt{\\& \\emph{graph-element-tag2} \\{ \\emph{drawing-options2} \\}}\n\\\\\n     \\ldots\n  \\end{footnotesize}\n\\end{quote}\nThis form is recommended, but graph and drawing options can also be set as\nglobal parameters, as usual.\n\nWe list the supported graph and drawing options in\nTables~\\ref{tab:graph-options} and \\ref{tab:drawing-options}, respectively.\n\n\\begin{table}\n  \\caption{Graph options.  The content of strings of type \\LaTeX\\ must be\n    valid \\LaTeX\\ code (containing typesetting commands such as math mode).\n    The content of strings of type GAMELAN must be valid GAMELAN code.\n    If a graph bound is kept \\emph{undefined}, the actual graph bound is\n    determined such as not to crop the graph contents in the selected\n    direction.}\n  \\label{tab:graph-options}\n\n  \\begin{center}\n    \\begin{tabular}{|l|l|l|l|}\n      \\hline\n      Variable & Default & Type & Meaning\n      \\\\\n      \\hline\\hline\n      \\ttt{\\$title}  & \\ttt{\"\"} & \\LaTeX &\n        Title of the graph = subsection headline\n      \\\\\n      \\hline\n      \\ttt{\\$description}  & \\ttt{\"\"} &  \\LaTeX &\n        Description text for the graph\n      \\\\\n      \\hline\n      \\ttt{\\$x\\_label} & \\ttt{\"\"} & \\LaTeX &\n        $x$-axis label\n      \\\\\n      \\hline\n      \\ttt{\\$y\\_label} & \\ttt{\"\"} & \\LaTeX &\n        $y$-axis label\n      \\\\\n      \\hline\n      \\ttt{graph\\_width\\_mm} & 130 & Integer &\n        graph width (on paper) in mm\n      \\\\\n      \\hline\n      \\ttt{graph\\_height\\_mm} & 90 & Integer &\n        graph height (on paper) in mm\n      \\\\\n      \\hline\n      \\ttt{?x\\_log} & false & Logical &\n        Whether the $x$-axis scale is linear or logarithmic\n      \\\\\n      \\hline\n      \\ttt{?y\\_log} & false & Logical &\n        Whether the $y$-axis scale is linear or logarithmic\n      \\\\\n      \\hline\n      \\ttt{x\\_min} & \\emph{undefined} & Real &\n        Lower bound for the $x$ axis\n      \\\\\n      \\hline\n      \\ttt{x\\_max} & \\emph{undefined} & Real &\n        Upper bound for the $x$ axis\n      \\\\\n      \\hline\n      \\ttt{y\\_min} & \\emph{undefined} & Real &\n        Lower bound for the $y$ axis\n      \\\\\n      \\hline\n      \\ttt{y\\_max} & \\emph{undefined} & Real &\n        Upper bound for the $y$ axis\n      \\\\\n      \\hline\n      \\ttt{gmlcode\\_bg} & \\ttt{\"\"} & GAMELAN &\n         Code to be executed before drawing\n      \\\\\n      \\hline\n      \\ttt{gmlcode\\_fg} & \\ttt{\"\"} & GAMELAN &\n         Code to be executed after drawing\n      \\\\\n      \\hline\n    \\end{tabular}\n  \\end{center}\n\\end{table}\n\n\\begin{table}\n  \\caption{Drawing options.  The content of strings of type GAMELAN must be\n    valid GAMELAN code.  The behavior w.r.t. the flags with \\emph{undefined}\n    default value depends on the type of graph element.  Histograms: draw\n    baseline, piecewise, fill area, draw curve, no errors, no symbols;  Plots:\n    no baseline, no fill, draw curve, no errors, no symbols.}\n  \\label{tab:drawing-options}\n\n  \\begin{center}\n    \\begin{tabular}{|l|l|l|l|}\n      \\hline\n      Variable & Default & Type & Meaning\n      \\\\\n      \\hline\\hline\n      \\ttt{?draw\\_base}  & \\emph{undefined} & Logical &\n        Whether to draw a baseline for the curve\n      \\\\\n      \\hline\n      \\ttt{?draw\\_piecewise}  & \\emph{undefined} & Logical &\n        Whether to draw bins separately (histogram)\n      \\\\\n      \\hline\n      \\ttt{?fill\\_curve}  & \\emph{undefined} & Logical &\n        Whether to fill area between baseline and curve\n      \\\\\n      \\hline\n      \\ttt{\\$fill\\_options} & \\ttt{\"\"} & GAMELAN &\n        Options for filling the area\n      \\\\\n      \\hline\n      \\ttt{?draw\\_curve} & \\emph{undefined} & Logical &\n        Whether to draw the curve as a line\n      \\\\\n      \\hline\n      \\ttt{\\$draw\\_options} & \\ttt{\"\"} & GAMELAN &\n        Options for drawing the line\n      \\\\\n      \\hline\n      \\ttt{?draw\\_errors} & \\emph{undefined} & Logical &\n        Whether to draw error bars for data points\n      \\\\\n      \\hline\n      \\ttt{\\$err\\_options} & \\ttt{\"\"} & GAMELAN &\n        Options for drawing the error bars\n      \\\\\n      \\hline\n      \\ttt{?draw\\_symbols} & \\emph{undefined} & Logical &\n        Whether to draw symbols at data points\n      \\\\\n      \\hline\n      \\ttt{\\$symbol} & Black dot & GAMELAN &\n        Symbol to be drawn\n      \\\\\n      \\hline\n      \\ttt{gmlcode\\_bg} & \\ttt{\"\"} & GAMELAN &\n         Code to be executed before drawing\n      \\\\\n      \\hline\n      \\ttt{gmlcode\\_fg} & \\ttt{\"\"} & GAMELAN &\n         Code to be executed after drawing\n      \\\\\n      \\hline\n    \\end{tabular}\n  \\end{center}\n\\end{table}\n\n\n\\section{Drawing options}\n\nThe options for coloring lines, filling curves, or choosing line styles make\nuse of macros in the GAMELAN language.  At this place, we do not intend to\ngive a full account of the possiblities, but we rather list a few basic\nfeatures that are likely to be useful for drawing graphs.\n\n\n\\subsubsection{Colors}\n\nGAMELAN knows about basic colors identified by name:\n\\begin{center}\n  \\ttt{black}, \\ttt{white}, \\ttt{red}, \\ttt{green}, \\ttt{blue}, \\ttt{cyan},\n  \\ttt{magenta}, \\ttt{yellow}\n\\end{center}\nMore generically, colors in GAMELAN are RGB triplets of numbers (actually,\nnumeric expressions) with values between 0 and 1, enclosed in brackets:\n\\begin{center}\n  \\ttt{(\\emph{r}, \\emph{g}, \\emph{b})}\n\\end{center}\n\nTo draw an object in color, one should apply the construct \\ttt{withcolor\n  \\emph{color}} to its drawing code.  The default color is always black.\nThus, this will make a plot drawn in blue:\n\\begin{quote}\n  \\begin{footnotesize}\n    \\ttt{\\$draw\\_options = \"withcolor blue\"}\n  \\end{footnotesize}\n\\end{quote}\nand this will fill the drawing area of some histogram with an RGB color:\n\\begin{quote}\n  \\begin{footnotesize}\n    \\ttt{\\$fill\\_options = \"withcolor (0.8, 0.7, 1)\"}\n  \\end{footnotesize}\n\\end{quote}\n\n\n\\subsubsection{Dashes}\n\nBy default, lines are drawn continuously.  Optionally, they can be drawn using\na \\emph{dash pattern}.  Predefined dash patterns are\n\\begin{center}\n  \\ttt{evenly}, \\ttt{withdots}, \\ttt{withdashdots}\n\\end{center}\nGoing beyond the predefined patterns, a generic dash pattern has the syntax\n\\begin{center}\n  \\ttt{dashpattern (on \\emph{l1} off \\emph{l2} on} \\ldots \\ttt{)}\n\\end{center}\nwith an arbitrary repetition of \\ttt{on} and \\ttt{off} clauses.  The numbers\n\\ttt{\\emph{l1}}, \\ttt{\\emph{l2}}, \\ldots\\ are lengths measured in pt.\n\nTo apply a dash pattern, the option syntax \\ttt{dashed \\emph{dash-pattern}}\nshould be used.  Options strings can be concatenated.  Here is how to draw in\ncolor with dashes:\n\\begin{quote}\n  \\begin{footnotesize}\n    \\ttt{\\$draw\\_options = \"withcolor red dashed evenly\"}\n  \\end{footnotesize}\n\\end{quote}\nand this draws error bars consisting of intermittent dashes and\ndots:\n\\begin{quote}\n  \\begin{footnotesize}\n    \\ttt{\\$err\\_options = \"dashed (withdashdots scaled 0.5)\"}\n  \\end{footnotesize}\n\\end{quote}\nThe extra brackets ensure that the scale factor $1/2$ is applied only the dash\npattern.\n\n\n\\subsubsection{Hatching}\n\nAreas (e.g., below a histogram) can be filled with plain colors by the\n\\ttt{withcolor} option.  They can also be hatched by stripes, optionally\nrotated by some angle.  The syntax is completely analogous to dashes.  There\nare two predefined \\emph{hatch patterns}:\n\\begin{center}\n   \\ttt{withstripes}, \\ttt{withlines}\n\\end{center}\nand a generic hatch pattern is written\n\\begin{center}\n  \\ttt{hatchpattern (on \\emph{w1} off \\emph{w2} on} \\ldots \\ttt{)}\n\\end{center}\nwhere the numbers \\ttt{\\emph{l1}}, \\ttt{\\emph{l2}}, \\ldots\\ determine the\nwidths of the stripes, measured in pt.\n\nWhen applying a hatch pattern, the pattern may be rotated by some angle (in\ndegrees) and scaled.  This looks like\n\\begin{quote}\n  \\begin{footnotesize}\n    \\ttt{\\$fill\\_options = \"hatched (withstripes scaled 0.8 rotated 60)\"}\n  \\end{footnotesize}\n\\end{quote}\n\n\n\\subsubsection{Smooth curves}\n\nPlot points are normally connected by straight lines.  If data are acquired by\nstatistical methods, such as Monte Carlo integration, this is usually\nrecommended.  However, if a plot is generated using an analytic mathematical\nformula, or with sufficient statistics to remove fluctuations, it might be\nappealing to connect lines by some smooth interpolation.  GAMELAN can switch\non spline interpolation by the specific drawing option \\ttt{linked smoothly}.\nNote that the results can be surprising if the data points do have sizable\nfluctuations or sharp kinks.\n\n\n\\subsubsection{Error bars}\n\nPlots and histograms can be drawn with error bars.  For histograms, only\nvertical error bars are supported, while plot points can have error bars in\n$x$ and $y$ direction.  Error bars are switched on by the \\ttt{?draw\\_errors}\nflag.\n\nThere is an option to draw error bars with ticks: \\ttt{withticks} and an\nalternative option to draw arrow heads: \\ttt{witharrows}.  These can be used\nin the \\ttt{\\$err\\_options} string.\n\n\n\\subsubsection{Symbols}\n\nTo draw symbols at plot points (or histogram midpoints), the flag\n\\ttt{?draw\\_symbols} has to be switched on.\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n\\chapter{Fast Detector Simulation and External Analysis}\n\\label{chap:ext_anal}\n\nEvents from a Monte Carlo event generator are further used in an\nanalysis, most often combined with a detector simulation. Event files\nfrom the generator are then classified whether they are (i) parton\nlevel (coming from the hard matrix element) for which mostly LHE or\n\\hepmc\\ event formats are used, particle level (after parton shower\nand hadronization) - usually in \\hepmc\\ or \\lcio\\ format -, or\ndetector level objects. The latter is the realm of packages like\n\\ROOT\\ or specific software from the experimental software\nframeworks. While detailed experimental studies take into account the\nbest-possible detector description in a so-called full simulation via\n\\geant\\ which takes several seconds per event, fast studies are made\nwith parameterized fast detector simulations like in \\delphes\\ or\n\\texttt{SGV}. In the following, we discuss the options to interface\nexternal packages for these purposes or to pipe events from\n\\whizard\\ to such external packages.\n\n%%%%%\n\n\\section{Interfacing ROOT}\n\\label{sec:root}\n\nOne of the most distributed analysis framework is\n\\ROOT~\\cite{Brun:1997pa}. In \\whizard\\ for the moment there is no\ndirect interface to the \\ROOT\\ framework. The easiest way to write\nout particle-level events in the \\ROOT\\ or \\ttt{RootTree} format is to\nuse \\whizard's interface to \\hepmcthree: this modern incarnation of\nthe \\hepmc\\ format has different writer classes, where the writer\nclass for \\ROOT\\ and \\ttt{RootTree} files is supported by \\whizard's\n\\hepmcthree\\ interface. For this to work, one only has to make sure\nthat \\hepmcthree\\ has been built with \\ROOT\\ support, and that the\n\\whizard\\ \\ttt{configure} has to detect the \\ROOT\\ setup on the\ncomputing environment. For more details cf. the installation\nsection~\\ref{sec:hepmc}. If this has been successfully linked, then\n\\whizard\\ can use its own \\hepmcthree\\ interface to write out\n\\ROOT\\ or \\ttt{RootTree} formats.\n\nThis can be done by setting the following options in the\n\\sindarin\\ files:\n\\begin{code}\n  $hepmc3_mode = \"Root\"\n\\end{code}\nor\n\\begin{code}\n  $hepmc3_mode = \"RootTree\"\n\\end{code}\nFor more details cf.~the \\ROOT\\ manual and documentation therein.\n\n%%%%%\n\n\\section{Interfacing RIVET}\n\\label{sec:rivet}\n\n\\rivet~\\cite{Buckley:2010ar} is a very mighty analysis framework which\nhas been developed to make experimental analyses from the LHC\nexperiments available for non-collaboration members. It can be easily\nused to analyze events and produce high-quality plots for differential\ndistributions and experimental observables. Since version\n3~\\cite{Bierlich:2019rhm} there is now also a lot of functionality\nthat comes very handy for plotting differential distributions at fixed\norder in NLO calculations, e.g. negative weights in bins or how to\ntreat imperfectly balanced events and counterevents close to bin\nboundaries etc. For the moment, \\whizard\\ does not have a dedicated\ninterface to \\rivet, so the preferred method is to write out events,\nbest in the \\hepmc\\ or \\hepmcthree\\ format and then read them into\n\\rivet. A more sophisticated interface is foreseen for a future\nversion of \\whizard, while there are already development versions\nwhere \\whizard\\ detects all the \\rivet\\ infrastructure and\nlibraries. But they are not yet used.\n\nFor more details and practical examples cf.~the \\rivet\\ manual. This\ndescribes in detail especially the \\rivet\\ installation. A typical\nerror that occurs on systems where no \\ROOT\\ is installed\n(cf.~Sec.~\\ref{sec:root}) is the one these \\ttt{Missing TPython.h}\nmissing headers. Then \\rivet\\ can nevertheless be easily built without\n\\ROOT\\ support by setting\n\\begin{code}\n  --disable-root\n\\end{code}\nin the \\ttt{rivet-bootstrap} script. For an installation of \\rivet\\ it\nis favorable to include the location of the \\rivet\\ \\python\\ scripts\nin the \\ttt{PYTHONPATH} environment variable. They can be accessed\nfrom the \\rivet\\ configuration script as\n\\begin{code}\n  <path_to_rivet-config>/rivet-config --pythonpath\n\\end{code}\nIf the \\python\\ path is not known within the environment variables,\nthen one commonly encounters error like \\ttt{No module named rivet} or\n\\ttt{Import error: no module named yoda} when running \\rivet\\ scripts\nlike e.g. \\ttt{yodamerge}.\n\nIf you use a \\rivet\\ version older than \\ttt{v3.1.1} there is no\nsupport for \\hepmcthree\\ yet, so when using \\hepmcthree\\ with\n\\whizard\\ please use the backwards compatibility mode of \\hepmcthree\nin the \\sindarin\\ file:\n\\begin{code}\n  $hepmc3_mode = \"HepMC2\"\n\\end{code}\nWhen using MPI parallelized runs of \\whizard\\ there will a large\nnumber of different \\ttt{.hepmc} files (also if some grid architecture\nhas produced these event files in junks). Then one has to first merge\nthese event files.\n\nHere, we quickly explain how to steer \\rivet\\ for your own\nanalysis. For more details, please confer the \\rivet\\ manual.\n\\begin{enumerate}\n\\item The command\n  \\begin{code}\n    rivet-mkanalysis <name>\n  \\end{code}\n  creates a template \\rivet\\ plugin for the analysis \\ttt{<name>.cc},\n  a template info file \\ttt{<name>.info} amd a template file for the\n  plot generation \\ttt{<name>.plot}. Note that this overwrites\n  potentially existing files in this folder with the same name.\n\n\\item\n  Now, analysis statements like e.g. cuts etc. can be implemented in\n  \\ttt{<name>.cc}. For analysis of parton-level events without parton\n  showering, the cuts can be equivalent to those in \\whizard, i.e. the\n  generator-level cuts can be as strict as the analysis cuts to avoid\n  generating unnecessary events. If parton showering is applied it is\n  better to have looser generator than analysis cuts to avoid\n  undesired plot artifacts.\n\n\\item\n  Next, one executes the command (the shared library name might be\n  different e.g. on Darwin or BSD OS)\n  \\begin{code}\n    rivet-buildplugin Rivet<name>.so <name>.cc\n  \\end{code}\n  This creates an executable \\rivet\\ analysis library\n  \\ttt{Rivet<name>.so}. The custom analysis should now appear in the\n  output of\n  \\begin{code}\n    rivet --list <name>\n  \\end{code}\n  If this is not the case, the analysis path has to be exported first\n  as \\ttt{RIVET\\_ANALYSIS\\_PATH=\\$PWD}.\n\n\\item\n  We are now ready to use the custom analysis to analyze the\n  \\ttt{.hepmc} events by executing the command\n  \\begin{code}\n    rivet --pwd --analysis=<name> -o <outfile>.yoda <path/to/hepmcfiles>\n  \\end{code}\n  and save the produced histograms of the analysis in the \\ttt{.yoda}\n  format. In general the option \\ttt{--ignore-beams} for\n  \\rivet\\ should be used to prevent \\rivet\\ to stumble over beam\n  remnants. This is also relevant for lepton collider processes with\n  electron PDFs. For a large number of events, event files can become\n  very big. To avoid writing them all on disk, a FIFO for the\n  \\ttt{<path/to/hepmcfiles>} can be used.\n\n\\item\n  Different \\ttt{yoda} files can now be merged into a single file\n  using the command\n  \\begin{code}\n    <yodamerge --add -o <name>_full.yoda <name>_01.yoda ...\n  \\end{code}\n  This should be applied e.g. for the case of fixed-order NLO\n  differential distributions where Born, real and virtual components\n  have been generated separately.\n\n\\item\n  Finally, plots can be produced: after listing all the histograms to\n  be plotted in the plot file \\ttt{<name>.plot}, the command\n  \\begin{code}\n    rivet-mkhtml <name>_full.yoda\n  \\end{code}\n  translates the \\ttt{.yoda} file into a histogram file in the\n  \\ttt{.dat} format. These plots can either be visually enhanced by\n  modifying the \\ttt{<name>.plot} file as is described on the webpage\n  \\url{https://rivet.hepforge.org/make-plots.html}, or by using any\n  other external plotting tool like e.g. \\ttt{Gnuplot} for the\n  \\ttt{.dat} files.\n\n\\end{enumerate}\n\nClearly, this gives only a rough sketch on how to use \\rivet\\ for an\nanalysis. For more details, please consult the \\rivet\\ webpage and the\n\\rivet\\ manual.\n\n%%%%%\n\n\\vspace{1cm}\n\n\\section{Fast Detector Simulation with DELPHES}\n\\label{sec:delphes}\n\nFast detector simulation allows relatively quick checks whether\nexperimental analyses actually work in a semi-realistic detector\nstudy. There are some older tools for fast simulation like\ne.g.~\\ttt{PGS} (which is no longer actively maintained) and \\ttt{SGV}\nwhich is default fast simulation for ILC studies. For LHC and general\nfuture hadron collider studies, \\delphes~\\cite{deFavereau:2013fsa} is\nthe most commonly used tool for fast detector simulation.\n\nThe details on how to obtain and build \\delphes\\ can be obtained from\ntheir webpage, \\url{https://cp3.irmp.ucl.ac.be/projects/delphes}. It\ndepends both on~\\ttt{Tcl/Tk} as well as\n\\ROOT~(cf. Sec.~\\ref{sec:root}. Interfacing any Monte Carlo event\ngenerator with a fast detector simulation like \\delphes\\ is rather\ntrivial: \\delphes\\ ships with up to five executables\n\\begin{code}\n  DelphesHepMC\n  DelphesLHEF\n  DelphesPythia8\n  DelphesROOT\n  DelphesSTDHEP\n\\end{code}\n\\ttt{DelphesPythia8} is a direct interface between \\pythiaeight\\ and\n\\delphes, so detector-level events are directly produced via an API\ninterface between \\pythiaeight\\ and \\delphes. This is the most\nconvenient method which is foreseen for \\whizard, however not yet\nimplemented. The other four binaries take input files in the \\hepmc,\nLHE, \\stdhep\\ and \\ROOT\\ format, apply a fast detector simulation\naccording to the chosen input file and give a \\ROOT\\ detector-level\nevent file as output.\n\nExecuting one of the binaries above without options, the following\nmessage will be displayed:\n\\begin{code}\n  ./DelphesHepMC\n Usage: DelphesHepMC config_file output_file [input_file(s)]\n config_file - configuration file in Tcl format,\n output_file - output file in ROOT format,\n input_file(s) - input file(s) in HepMC format,\n with no input_file, or when input_file is -, read standard input.\n\\end{code}\nUsing \\delphes\\ with \\hepmc\\ event files then works as\n\\begin{code}\n  ./DelphesHepMC cards/delphes_card_ATLAS.tcl output.root input.hepmc\n\\end{code}\nFor \\stdhep\\ files which are directly by \\whizard\\ without external\npackages (only assuming that the XDR C libraries are present on the\nsystem), execute\n\\begin{code}\n  ./DelphesSTDHEP cards/delphes_card_ILD.tcl delphes_output.root input.hep\n\\end{code}\nFor LHE files as input, use\n\\begin{code}\n  ./DelphesLHEF cards/delphes_card_CLICdet_Stage1.tcl delphes_output.root input.lhef\n\\end{code}\nand for \\ROOT\\ (particle-level) files use\n\\begin{code}\n  ./DelphesROOT cards/delphes_card_CMS.tcl delphes_output.root input.root\n\\end{code}\nIn the \\delphes\\ cards directory, there is a long list of supported\ninput files for existing and future detectors, a few of which we have\ndisplayed here.\n\n\\delphes\\ detector-level output files can then be analyzed with\n\\ROOT\\ as described in the \\delphes\\ manual.\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n\\chapter{User Interfaces for WHIZARD}\n\\label{chap:userint}\n\n\\section{Command Line and \\sindarin\\ Input Files}\n\\label{sec:cmdline-options}\n\nThe standard way of using \\whizard\\ involves a command script written\nin \\sindarin.  This script is executed by \\whizard\\ by mentioning it\non the command line:\n\\begin{interaction}\n  whizard script-name.sin\n\\end{interaction}\nYou may specify several script files on the command line; they will be\nexecuted consecutively.\n\nIf there is no script file, \\whizard\\ will read commands from standard\ninput.  Hence, this is equivalent:\n\\begin{interaction}\n  cat script-name.sin | whizard\n\\end{interaction}\n\nWhen executed from the command line, \\whizard\\ accepts several options.\nThey are given in long form, i.e., they begin with two dashes.  Values\nthat belong to options follow the option string, separated either by\nwhitespace or by an equals sign.  Hence, \\ttt{--prefix /usr} and\n\\ttt{--prefix=/usr} are equivalent.  Some options are also available\nin short form, a single dash with a single letter.  Short-form options\ncan be concatenated, i.e., a dash followed by several option letters.\n\nThe first set of options is intended for normal operation.\n\\begin{description}\n\\item[\\ttt{--debug AREA}]: Switch on debug output for \\ttt{AREA}.\n  \\ttt{AREA} can be one of \\whizard's source directories or \\ttt{all}.\n\\item[\\ttt{--debug2 AREA}]: Switch on more verbose debug output for \\ttt{AREA}.\n\\item[\\ttt{--single-event}]: Only compute one phase-space point (for debugging).\n\\item[\\ttt{--execute COMMANDS}]:  Execute \\ttt{COMMANDS} as a script\n  before the script file (see below).  Short version: \\ttt{-e}\n\\item[\\ttt{--file CMDFILE}]:  Execute commands in \\ttt{CMDFILE} before the\n  main script file (see below).  Short version: \\ttt{-f}\n\\item[\\ttt{--help}]:  List the available options and exit.  Short version:\n  \\ttt{-h}\n\\item[\\ttt{--interactive}]:  Run \\whizard\\ interactively.  See\n  Sec.~\\ref{sec:whish}.  Short version: \\ttt{-i}.\n\\item[\\ttt{--library LIB}]:  Preload process library \\ttt{LIB}\n  (instead of the default \\ttt{processes}).  Short version: \\ttt{-l}.\n\\item[\\ttt{--localprefix DIR}]:  Search in \\ttt{DIR} for local\n  models.  Default is \\ttt{\\$HOME/.whizard}.\n\\item[\\ttt{--logfile \\ttt{FILE}}]: Write log to \\ttt{FILE}.  Default is\n  \\ttt{whizard.log}.  Short version: \\ttt{-L}.\n\\item[\\ttt{--logging}]: Start logging on startup (default).\n\\item[\\ttt{--model MODEL}]: Preload model \\ttt{MODEL}.  Default is the\n  Standard Model \\ttt{SM}.  Short version: \\ttt{-m}.\n\\item[\\ttt{--no-banner}]: Do not display banner at startup.\n\\item[\\ttt{--no-library}]: Do not preload a library.\n\\item[\\ttt{--no-logfile}]: Do not write a logfile.\n\\item[\\ttt{--no-logging}]: Do not issue information into the logfile.\n\\item[\\ttt{--no-model}]: Do not preload a specific physics model.\n\\item[\\ttt{--no-rebuild}]: Do not force a rebuild.\n\\item[\\ttt{--query VARIABLE}]: Display documentation of \\ttt{VARIABLE}.\n  Short version: \\ttt{-q}.\n\\item[\\ttt{--rebuild}]: Do not preload a process library and do all\n  calculations from scratch, even if results exist.  This combines all\n  rebuild options.  Short version: \\ttt{-r}.\n\\item[\\ttt{--rebuild-library}]: Rebuild the process library, even if code\n  exists.\n\\item[\\ttt{--rebuild-phase-space}]: Rebuild the phase space setup, even if\n  it exists.\n\\item[\\ttt{--rebuild-grids}]: Redo the integration, even if previous grids\n  and results exist.\n\\item[\\ttt{--rebuild-events}]: Redo event generation, discarding previous\n  event files.\n\\item[\\ttt{--show-config}]: Show build-time configuration.\n\\item[\\ttt{--version}]: Print version information and exit.  Short version:\n  \\ttt{-V}.\n\\item[-]: Any further options are interpreted as file names.\n\\end{description}\nThe second set of options refers to the configuration.  They are\nrelevant when dealing with a relocated \\whizard\\ installation, e.g.,\non a batch systems.\n\\begin{description}\n\\item[\\ttt{--prefix DIR}]: Specify the actual location of the \\whizard\\\n  installation, including all subdirectories.\n\\item[\\ttt{--exec-prefix DIR}]:  Specify the actual location of the\n  machine-specific parts of the \\whizard\\ installation (rarely needed).\n\\item[\\ttt{--bindir DIR}]:  Specify the actual location of the\n  executables contained in the \\whizard\\ installation (rarely needed).\n\\item[\\ttt{--libdir DIR}]:  Specify the actual location of the\n  libraries contained in the \\whizard\\ installation (rarely needed).\n\\item[\\ttt{--includedir DIR}]:  Specify the actual location of the\n  include files contained in the \\whizard\\ installation (rarely needed).\n\\item[\\ttt{--datarootdir DIR}]:  Specify the actual location of the\n  data files contained in the \\whizard\\ installation (rarely needed).\n\\item[\\ttt{--libtool LOCAL\\_LIBTOOL}]:  Specify the actual location and\n  name of the \\ttt{libtool} script that should be used by \\whizard.\n\\item[\\ttt{--lhapdfdir DIR}]:  Specify the actual location and\n  of the \\lhapdf\\ installation that should be used by \\whizard.\n\\end{description}\n\nThe \\ttt{--execute} and \\ttt{--file} options allow for fine-tuning the command\nflow.  The \\whizard\\ main program will concatenate all commands given in\n\\ttt{--execute} commands together with all commands contained in \\ttt{--file}\noptions, in the order they are encountered, as a contiguous command stream\nthat is executed \\emph{before} the main script (in the example above,\n\\ttt{script-name.sin}).\n\nRegarding the \\ttt{--execute} option, commands that contain blanks must be\nenclosed in matching single- or double-quote characters since the individual\ntokens would otherwise be intepreted as separate option strings.\nUnfortunately, a Unix/Linux shell interpreter will strip quotes before handing\nthe command string over to the program.  In that situation, the\nquote-characters must be quoted themselves, or the string must be enclosed in\nquotes twice.  Either version should work as a command line interpreted by\nthe shell:\n\\begin{interaction}\n  whizard --execute \\'int my_flag = 1\\' script-name.sin\n  whizard --execute \"'int my_flag = 1'\" script-name.sin\n\\end{interaction}\n\n\n\\section{WHISH -- The \\whizard\\ Shell/Interactive mode}\n\\label{sec:whish}\n\n\\whizard\\ can be also run in the interactive mode using its own shell\nenvironment. This is called the \\whizard\\ Shell (WHISH). For this\npurpose, one starts with the command\n\\begin{interaction}\n  /home/user$ whizard --interactive\n\\end{interaction}\nor\n\\begin{interaction}\n  /home/user$ whizard -i\n\\end{interaction}\n\\whizard\\ will preload the Standard Model and display a command\nprompt:\n\\begin{interaction}\n  whish?\n\\end{interaction}\nYou now can enter one or more \\sindarin\\ commands, just as if they\nwere contained in a script file.  The commands are compiled and\nexecuted after you hit the ENTER key.  When done, you get a new\nprompt.  The WHISH can be closed by the \\ttt{quit} command:\n\\begin{verbatim}\n  whish? quit\n\\end{verbatim}\nObviously, each input must be self-contained: commands must be\ncomplete, and conditionals or scans must be closed on the same line.\n\nIf \\whizard\\ is run without options and without a script file, it\nalso reads commands interactively, from standard input.  The\ndifference is that in this case, interactive input is multi-line,\nterminated by \\ttt{Ctrl-D}, the script is then compiled and\nexecuted as a whole, and \\whizard\\ terminates.\n\nIn WHISH mode, each input line is compiled and executed individually.\nFurthermore, fatal errors are masked, so in case of error the program\ndoes not terminate but returns to the WHISH command line.  (The\nattempt to recover may fail in some circumstances, however.)\n\n\n\\section{Graphical user interface}\n\n\\emph{This is still experimental.}\n\n\\whizard\\ ships with a graphical interface that can be steered in a\nbrowser of your choice. It is located in \\ttt{share/gui}.  To use it,\nyou have to run \\ttt{npm install} (which will install javascript\nlibraries locally in that folder) and \\ttt{npm start} (which will start\na local web server on your machine) in that folder.  More technical\ndetails and how to get \\ttt{npm} is discussed in\n\\ttt{share/gui/README.md}.  When it is running, you can access the GUI\nby entering \\ttt{localhost:3000} as address in your browser.  The GUI is\nseparated into different tabs for basic settings, integration,\nsimulation, cuts, scans, NLO and beams.  You can select and enter what\nyou are interested in and the GUI will produce a \\sindarin\\ file.  You\ncan use the GUI to run WHIZARD with that \\sindarin\\ or just produce it\nwith the GUI and then tweak it further with an editor.  In case you run\nit in the GUI, the log file will be updated in the browser as it is\nproduced.  Any \\sindarin\\ features that are not supported by the GUI can\nbe added directly as \"Additional Code\".\n\n\\section{\\whizard\\ as a library}\n\nThe compiled \\whizard\\ program consists of two libraries (\\ttt{libwhizard} and\n\\ttt{libomega}).  In the standard setup, these are linked to a short main\nprogram which deals with command line options and top-level administration.\nThis is the stand-alone \\ttt{whizard} executable program.\n\nAlternatively, it is possible to link the libraries to a different main\nprogram of the user's choice.  The user program can take complete control of\nthe \\whizard\\ features.  The \\ttt{libwhizard} library provides an API, a\nwell-defined set of procedures which can be called from a foreign main\nprogram.  The supported languages are \\fortran, \\ttt{C}, and \\cpp.\nUsing the C API, any other language which supports linking against C\nlibraries can also be interfaced.\n\n\\subsection{Fortran main program}\n\nTo link a \\fortran\\ main program with the \\whizard\\ library, the following steps\nmust be performed:\n\\begin{enumerate}\n\\item\n  Configure, build and install \\whizard\\ as normal.\n\\item\n  Include code for accessing \\whizard\\ functionality in the user program.\n  The code should initialize\n  \\whizard, execute the intended commands, and finalize.  For an example, see\n  below.\n\\item\n  Compile the user program.   The user program must be\n  compiled with the same \\fortran\\ compiler that has been used for the \\whizard\\\n  build.\n\n  If necessary, specify an option that finds the\n  installed \\whizard\\ module files.\n  For instance, if \\whizard\\ has been installed in \\ttt{whizard-path}, this\n  should read\n  \\begin{code}\n    -Iwhizard-path/lib/mod/whizard\n  \\end{code}\n\\item\n  Link the program (or compile-link in a single step).  If necessary, specify\n  options that find the installed \\whizard\\ and \\oMega\\ libraries.  For\n  instance, if \\whizard\\ has been installed in \\ttt{whizard-path}, this should\n  read\n  \\begin{code}\n    -Lwhizard-path/lib -lwhizard -lwhizard_prebuilt -lomega\n  \\end{code}\n  On some systems, you may have to replace \\ttt{lib} by \\ttt{lib64}.\n\n  Such an example compile-link could look like\n  \\begin{code}\n    gfortran manual_example_api.f90 -Lwhizard-path/lib -lwhizard -lwhizard_prebuilt -lomega\n  \\end{code}\n\n  If \\whizard\\ has been compiled with a non-default \\fortran\\ compiler, you may\n  have to explicitly link the appropriate \\fortran\\ run-time libraries.\n\n  The \\ttt{tirpc} library is used by the \\ttt{StdHEP} subsystem for \\ttt{xdr}\n  functionality.  This library should be present on the host\n  system. This library needs only be linked of the SunRPC library is\n  not installed on the system.\n\n  If additional libraries such as\n  \\hepmc\\ are enabled in the \\whizard\\ configuration, it may be necessary to\n  provide extra options for linking those.\n\n  An example here looks like\n  \\begin{code}\n    gfortran manual_example_api.f90 -Lwhizard-path/lib -lwhizard\n        -lwhizard_prebuilt -lomega -lHepMC3 -lHepMC3rootIO -llcio\n  \\end{code}\n\n\\item\n  Run the program.  If necessary, provide the path to the installed shared\n  libraries.  For instance, if \\whizard\\ has been installed in\n  \\ttt{whizard-path}, this should read\n  \\begin{code}\n    export LD_LIBRARY_PATH=\"whizard-path/lib:$LD_LIBRARY_PATH\"\n  \\end{code}\n  On some systems, you may have to replace \\ttt{lib} by \\ttt{lib64}, as above.\n\n  The \\whizard\\ subsystem will work with input and output\n  files in the current working directory, unless asked to do otherwise.\n\\end{enumerate}\nBelow is an example program, adapted from \\whizard's internal unit-test suite.\nThe user program controls the \\whizard\\ workflow in the same way as a\n\\sindarin\\ script would do.  The commands are a mixture of \\sindarin\\ command\ncalls and functionality for passing information between the \\whizard\\\nsubsystem and the host program.\nIn particular, the program can process generated events one-by-one.\n\\begin{code}\nprogram main\n\n  ! WHIZARD API as a module\n  use api\n\n  ! Standard numeric types\n  use iso_fortran_env, only: real64, int32\n\n  implicit none\n\n  ! WHIZARD and event-sample objects\n  type(whizard_api_t)    :: whizard\n  type(simulation_api_t) :: sample\n\n  ! Local variables\n  real(real64)   :: integral, error\n  real(real64)   :: sqme, weight\n  integer(int32) :: idx\n  integer(int32) :: i, it_begin, it_end\n\n  ! Initialize WHIZARD, setting some global option\n  call whizard%option (\"model\", \"QED\")\n  call whizard%init ()\n\n  ! Define a process, set some variables\n  call whizard%command (\"process mupair = e1, E1 => e2, E2\")\n  call whizard%set_var (\"sqrts\", 100._real64)\n  call whizard%set_var (\"seed\", 0)\n\n  ! Generate matrix-element code, integrate and retrieve result\n  call whizard%command (\"integrate (mupair)\")\n  call whizard%get_integration_result (\"mupair\", integral, error)\n\n  ! Print result\n  print 1, \"cross section =\", integral / 1000, \"pb\"\n  print 1, \"error         =\", error    / 1000, \"pb\"\n1 format (2x,A,1x,F5.1,1x,A)\n2 format (2x,A,1x,L1)\n\n  ! Settings for event generation\n  call whizard%set_var (\"$sample\", \"mupair_events\")\n  call whizard%set_var (\"n_events\", 2)\n\n  ! Create an event-sample object and generate events\n  call whizard%new_sample (\"mupair\", sample)\n  call sample%open (it_begin, it_end)\n  do i = it_begin, it_end\n     call sample%next_event ()\n     call sample%get_event_index (idx)\n     call sample%get_weight (weight)\n     call sample%get_sqme (sqme)\n     print \"(A,I0)\", \"Event #\", idx\n     print 3, \"sqme    =\", sqme\n     print 3, \"weight  =\", weight\n3    format (2x,A,1x,ES10.3)\n  end do\n\n  ! Finalize the event-sample object\n  call sample%close ()\n\n  ! Finalize the WHIZARD object\n  call whizard%final ()\n\nend program main\n\\end{code}\nThe API provides the following commands as \\fortran\\ subroutines.  Most of them\nare used in the example above.\n\n\\subsubsection{Module}\nThere is only one module from the \\whizard\\ package which must be\n\\texttt{use}d by the user program:\n\\begin{quote}\n  \\tt use api\n\\end{quote}\nYou may \\texttt{use} any other \\whizard\\ module in our program, all module\nfiles are part of the installation.  Be aware,\nhowever, that all other modules are considered internal.  Unless explictly\nmentioned in this manual, interfaces are\nnot documented here and may change between versions.\n\nChanges to the \\ttt{api} module, if any, will be documented here.\n\n\\subsubsection{Master object}\nAll functionality is accessed via a master API object which should be declared\nas follows:\n\\begin{quote}\n  \\tt type(whizard\\_api\\_t) :: whizard\n\\end{quote}\nThere should be only one master object.\n\n\\subsubsection{Pre-Initialization options}\nBefore initializing the API object, it is possible to provide options.  The\navailable options mirror the command-line options of the stand-alone program,\ncf.\\ Sec.~\\ref{sec:cmdline-options}.\n\\begin{quote}\n  \\tt call whizard\\%option (\\textit{key}, \\textit{value})\n\\end{quote}\nAll keys and values are \\fortran\\ character strings.  The following options are\navailable.  For all options, default values exist as listed in\nSec.~\\ref{sec:cmdline-options}.\n\\begin{description}\n\\item[\\tt model] Model that should be preloaded.\n\\item[\\tt library] Name of the library where matrix-element code should end up.\n\\item[\\tt logfile] Name of the logfile that \\whizard\\ will write.\n\\item[\\tt job\\_id] Name of the current job; can be used for writing unique output\n  files.\n\\item[\\tt unpack] Comma-separated list of files to be uncompressed and unpacked\n  (via \\ttt{tar} and \\ttt{gzip}) when \\ttt{init} is called on the API object.\n\\item[\\tt pack] Comma-separated list of files or directories to be packed and\n  compressed when \\ttt{final} is called.\n\\item[\\tt rebuild] All of the following:\n\\item[\\tt rebuild\\_library]  Force rebuilding a matrix-element code library,\n  overwriting results from a previous run.\n\\item[\\tt recompile]  Force recompiling the matrix-element code library.\n\\item[\\tt rebuild\\_grids]  Force reproducing integration passes.\n\\item[\\tt rebuild\\_events]  Force regenerating event samples.\n\\end{description}\n\n\\subsubsection{Initialization and finalization}\nAfter options have been set, the system is initialized via\n\\begin{quote}\n  \\tt call whizard\\%init\n\\end{quote}\nOnce initialized, \\whizard\\ can execute commands as listed below.  When this\nis complete, clean up by\n\\begin{quote}\n  \\tt call whizard\\%final\n\\end{quote}\n\n\\subsubsection{Variables and values}\n\nIn the API, \\whizard\\ requires numeric data types according to the IEEE\nstandard, which is available to \\fortran\\ in the \\ttt{iso\\_fortran\\_env}\nintrinsic module.  Strictly speaking, integer data must have type \\ttt{int32},\nand real data must have type \\ttt{real64}.\n\nFor most systems and default compiler settings, it\nis not really necessary to \\ttt{use} the ISO module and its data types.\nIntegers map to default \\fortran\\ \\ttt{integer},\nand real values map to default \\fortran\\ \\ttt{double precision}.\n\nAs an\nalternative, you may \\ttt{use} the \\whizard\\ internal \\ttt{kinds} module which\ndeclares a \\ttt{real(default)} type\n\\begin{quote}\n  \\tt use kinds, only: default\n\\end{quote}\nOn most systems, this will be equivalent\nto \\ttt{real(real64)}.\n\nTo set a \\sindarin\\ variable, use the function that corresponds to the data\ntype:\n\\begin{quote}\n  \\tt call whizard\\%set\\_var (\\textit{name}, \\textit{value})\n\\end{quote}\nThe name is a \\fortran\\ string which has to be equal to the name of the\ncorresponding \\sindarin\\ variable, including any prefix character (\\$ or ?).\nThe value depends on the type of the \\sindarin\\\nvariable.\n\nTo retrieve the current value of a variable:\n\\begin{quote}\n  \\tt call whizard\\%get\\_var (\\textit{name}, \\textit{var})\n\\end{quote}\nThe variable must be declared as \\ttt{integer}, \\ttt{real(real64)},\n\\ttt{logical},  or\n\\ttt{character(:), allocatable}.  This depends on the \\sindarin\\ variable type.\n\n\\subsubsection{Commands}\nAny \\sindarin\\ command can be called via\n\\begin{quote}\n  \\tt call whizard\\%command (\\textit{command})\n\\end{quote}\n\\ttt{\\it command} is a \\fortran\\ character string, as it would appear\nin a \\sindarin\\ script.\n\nThis includes, in particular, the important commands \\ttt{process},\n\\ttt{integrate}, and \\ttt{simulate}.  You may also set variables that way.\n\n\\subsubsection{Retrieving cross-section results}\nThis call returns the results (integration and error) from a preceding\nintegration run for the process \\textit{process-name}:\n\\begin{quote}\n  \\tt call whizard\\%get\\_integration\\_result (\"\\textit{process-name}\",\n  integral, error)\n\\end{quote}\nThere is also an optional argument \\ttt{known} of type \\ttt{logical} which is\nset if the integration run was successful, so integral and error are\nmeaningful.\n\n\n\n\\subsubsection{Event-sample object}\nA \\ttt{simulate} command will produce an event sample.  With the appropriate\nsettings, the sample will be written to file in any chosen format, to be\npost-processed when it is complete.\n\nHowever, a possible purpose of using the \\whizard\\ API is to process events one-by-one\nwhen they are generated.  To this end, there is an event-sample handle, which\ncan be declared in this way:\n\\begin{quote}\n  \\tt type(simulation\\_api\\_t) :: sample\n\\end{quote}\nAn instance \\ttt{sample} of this type is created by this factory method:\n\\begin{quote}\n  \\tt call whizard\\%new\\_sample (\"\\textit{process-name(s)}\", sample)\n\\end{quote}\nThe command accepts a comma-separated list of process names which should be\nincluded in the event sample.\n\nTo start event generation for this sample, call\n\\begin{quote}\n  \\tt call sample\\%open (\\textit{it\\_begin}, \\textit{it\\_end} )\n\\end{quote}\nwhere the two output parameters (integers) \\ttt{\\it it\\_begin} and \\ttt{\\it it\\_end}\nprovide the bounds for an event loop in the calling program.  (In serial mode,\nthe bounds are equal to 1 and \\ttt{n\\_events}, respectively, but in an MPI\nparallel environment, they depend on the computing node.)\n\nThis command generates a new event, to be enclosed within an event loop:\n\\begin{quote}\n  \\tt call sample\\%next\\_event\n\\end{quote}\nThe event will be available by format-specific access methods, see below.\n\nThis command closes and deletes an event sample after the event loop has\ncompleted:\n\\begin{quote}\n  \\tt call sample\\%close\n\\end{quote}\n\n\\subsubsection{Retrieving event data}\n\nAfter a call to \\ttt{next\\_event}, the sample object can be queried for\nspecific event data.\n\\begin{quote}\n  \\tt call sample\\%get\\_event\\_index (\\textit{value})\n\\end{quote}\nreturns the index (integer counter) of the current event.\n\\begin{quote}\n  \\tt call sample\\%get\\_process\\_index (\\textit{value})\n  \\\\\n  \\tt call sample\\%get\\_process\\_id (\\textit{value})\n\\end{quote}\nreturns the numeric (string) ID of the hard process, respectively, that was\ngenerated in this event.  The variables must be declared as \\ttt{integer} and\n\\ttt{character(:), allocatable}, respectively.\n\nThe following methods return \\ttt{real(real64)} values.\n\\begin{quote}\n  \\tt call sample\\%get\\_sqrts (\\textit{value})\n\\end{quote}\nreturns the $\\sqrt{s}$ value of this event.\n\\begin{quote}\n  \\tt call sample\\%get\\_fac\\_scale (\\textit{value})\n\\end{quote}\nreturns the factorization scale of this event (\\textit{value}).\n\\begin{quote}\n  \\tt call sample\\%get\\_alpha\\_s (\\textit{value})\n\\end{quote}\nreturns the value of the strong coupling for this event (\\textit{value}).\n\\begin{quote}\n  \\tt call sample\\%get\\_sqme (\\textit{value})\n\\end{quote}\nreturns the value of the squared matrix element (summed over final states and\naveraged over initial states).\n\\begin{quote}\n  \\tt call sample\\%get\\_weight (\\textit{value})\n\\end{quote}\nreturns the Monte-Carlo weight of this event.\n\nAccess to the event record depends on the event format that has been\nselected.  The format must allow access to individual events via data\nstructures in memory.  There are three cases where such structures exist and\nare accessible:\n\\begin{enumerate}\n\\item\n  If the event format uses a COMMON block, event data is accessible\n  via this COMMON block, which must be declared in the calling routine.\n\\item\n  The \\hepmc\\ event format communicates via a \\cpp\\ object.  In \\fortran, there\n  is a wrapper which has to be declared as\n  \\begin{quote}\n    \\tt type(hepmc\\_event\\_t) :: hepmc\\_event\n  \\end{quote}\n  To activate this handle, the \\ttt{next\\_event} call must reference it as\n  an argument:\n  \\begin{quote}\n    \\tt call sample\\%next\\_event (hepmc\\_event)\n  \\end{quote}\n  The \\whizard\\ module \\ttt{hepmc\\_interface} contains procedures which can\n  work with this record.  A pointer to the actual \\cpp\\ object can be retrieved\n  as a \\fortran\\\n  \\ttt{c\\_ptr} object as follows:\n  \\begin{quote}\n    \\tt\n    type(c\\_ptr) :: hepmc\\_ptr\n    \\\\\n    \\dots\n    \\\\\n    hepmc\\_ptr = hepmc\\_event\\_get\\_c\\_ptr (hepmc\\_event)\n  \\end{quote}\n\\item\n  The \\lcio\\ event format also communicates via a \\cpp\\ object.  The access\n  methods are entirely analogous, replacing \\ttt{hepmc} by \\ttt{lcio} in all\n  calls and names.\n\\end{enumerate}\n\n\n\\subsection{C main program}\nTo link a C main program with the \\whizard\\ library, the following steps\nmust be performed:\n\\begin{enumerate}\n\\item\n  Configure, build and install \\whizard\\ as normal.\n\\item\n  Include code for accessing \\whizard\\ functionality in the user program.\n  The code should initialize\n  \\whizard, execute the intended commands, and finalize.  For an example, see\n  below.\n\\item\n  Compile the user program with the option that finds the WHIZARD \\ttt{C/C++}\n  interface header file.\n  For instance, if \\whizard\\ has been installed in \\ttt{whizard-path}, this\n  should read\n  \\begin{code}\n    -Iwhizard-path/include\n  \\end{code}\n\\item\n  Link the program with the necessary libraries (or compile-link in a single\n  step).  If\n  \\whizard\\ has been installed in a system path, this should work\n  automatically.  If\n  \\whizard\\ has been installed in a non-default \\ttt{whizard-path}, these\n  are the options:\n  \\begin{code}\n    -Lwhizard-path/lib -lwhizard -lwhizard_prebuilt -lomega -ltirpc\n  \\end{code}\n  On some systems, you may have to replace \\ttt{lib} by \\ttt{lib64}.\n\n  If \\whizard\\ has been compiled with a non-default \\fortran\\ compiler, you may\n  have to explicitly link the appropriate \\fortran\\ run-time libraries.\n\n  The \\ttt{tirpc} library is used by the \\ttt{StdHEP} subsystem for \\ttt{xdr}\n  functionality.  This library should be present on the host\n  system. Cf. the corresponding remarks in the section for a\n  \\fortran\\ main program.\n\n  If additional libraries such as\n  \\hepmc\\ are enabled in the \\whizard\\ configuration, it may be necessary to\n  provide extra options for linking those.\n\n\\item\n  Run the program.  If necessary, provide the path to the installed shared\n  libraries.  For instance, if \\whizard\\ has been installed in\n  \\ttt{whizard-path}, this should read\n  \\begin{code}\n    export LD_LIBRARY_PATH=\"whizard-path/lib:$LD_LIBRARY_PATH\"\n  \\end{code}\n  On some systems, you may have to replace \\ttt{lib} by \\ttt{lib64}, as above.\n\n  The \\whizard\\ subsystem will work with input and output\n  files in the current working directory, unless asked to do otherwise.\n\\end{enumerate}\nBelow is an example program, adapted from \\whizard's internal unit-test suite.\nThe user program controls the \\whizard\\ workflow in the same way as a\n\\sindarin\\ script would do.  The commands are a mixture of \\sindarin\\ command\ncalls and functionality for passing information between the \\whizard\\\nsubsystem and the host program.\nIn particular, the program can process generated events one-by-one.\n\\begin{code}\n#include <stdio.h>\n#include \"whizard.h\"\n\nint main( int argc, char* argv[] )\n{\n  /* WHIZARD and event-sample objects */\n  void* wh;\n  void* sample;\n\n  /* Local variables */\n  double integral, error;\n  double sqme, weight;\n  int idx;\n  int it, it_begin, it_end;\n\n  /* Initialize WHIZARD, setting some global option */\n  whizard_create( &wh );\n  whizard_option( &wh, \"model\", \"QED\" );\n  whizard_init( &wh );\n\n  /* Define a process, set some variables */\n  whizard_command( &wh, \"process mupair = e1, E1 => e2, E2\" );\n  whizard_set_double( &wh, \"sqrts\", 10. );\n  whizard_set_int( &wh, \"seed\", 0 );\n\n  /* Generate matrix-element code, integrate and retrieve result */\n  whizard_command( &wh, \"integrate (mupair)\" );\n\n  /* Print result */\n  whizard_get_integration_result( &wh, \"mupair\", &integral, &error);\n  printf( \"  cross section = %5.1f pb\\n\", integral / 1000. );\n  printf( \"  error         = %5.1f pb\\n\", error / 1000. );\n\n  /* Settings for event generation */\n  whizard_set_char( &wh, \"$sample\", \"mupair_events\" );\n  whizard_set_int( &wh, \"n_events\", 2 );\n\n  /* Create an event-sample object and generate events */\n  whizard_new_sample( &wh, \"mupair\", &sample );\n  whizard_sample_open( &sample, &it_begin, &it_end );\n  for (it=it_begin; it<=it_end; it++) {\n    whizard_sample_next_event( &sample );\n    whizard_sample_get_event_index( &sample, &idx );\n    whizard_sample_get_weight( &sample, &weight );\n    whizard_sample_get_sqme( &sample, &sqme );\n    printf( \"Event #%d\\n\", idx );\n    printf( \"  sqme    = %10.3e\\n\", sqme );\n    printf( \"  weight  = %10.3e\\n\", weight );\n  }\n\n  /* Finalize the event-sample object */\n  whizard_sample_close( &sample );\n\n  /* Finalize the WHIZARD object */\n  whizard_final( &wh );\n}\n\\end{code}\n\n\\subsubsection{Header}\nThe necessary declarations are imported by the directive\n\\begin{quote}\n  \\tt \\#include \"whizard.h\"\n\\end{quote}\n\n\\subsubsection{Master object}\nAll functionality is accessed via a master API object which should be declared\nas a \\ttt{void*} pointer:\n\\begin{quote}\n  \\tt void* wh;\n\\end{quote}\nThe object must be explicitly created:\n\\begin{quote}\n  \\tt whizard\\_create( \\&wh );\n\\end{quote}\nThere should be only one master object.\n\n\\subsubsection{Pre-Initialization options}\nBefore initializing the API object, it is possible to provide options.  The\navailable options mirror the command-line options of the stand-alone program,\ncf.\\ Sec.~\\ref{sec:cmdline-options}.\n\\begin{quote}\n  \\tt  whizard\\_option( \\&wh, \\textit{key}, \\textit{value} );\n\\end{quote}\nAll keys and values are null-terminated C character strings.  The available\noptions are\nlisted above in the \\fortran\\ interface documentation.\n\n\\subsubsection{Initialization and finalization}\nAfter options have been set, the system is initialized via\n\\begin{quote}\n  \\tt whizard\\_init( \\&wh );\n\\end{quote}\nOnce initialized, \\whizard\\ can execute commands as listed below.  When this\nis complete, clean up by\n\\begin{quote}\n  \\tt whizard\\_final( \\&wh );\n\\end{quote}\n\n\\subsubsection{Variables and values}\n\nIn the API, \\whizard\\ requires numeric data types according to the IEEE\nstandard.  Integers map to C \\ttt{int}, and real values map to C\n\\ttt{double}.  Logical values map to C \\ttt{int} interpreted as \\ttt{bool},\nand string values map to null-terminated C strings.\n\nTo set a \\sindarin\\ variable of appropriate type:\n\\begin{quote}\n  \\tt whizard\\_set\\_int ( \\&wh, \\textit{name}, \\textit{value} );\n  \\\\\n  \\tt whizard\\_set\\_double ( \\&wh, \\textit{name}, \\textit{value} );\n  \\\\\n  \\tt whizard\\_set\\_bool ( \\&wh, \\textit{name}, \\textit{value} );\n  \\\\\n  \\tt whizard\\_set\\_char ( \\&wh, \\textit{name}, \\textit{value} );\n\\end{quote}\n\\textit{name} is declared \\ttt{const char*}.  It must match the corresponding\n\\sindarin\\ variable name, including any prefix character (\\$ or ?).\n\\textit{value} is declared \\ttt{const double/int/char*}.\n\nTo retrieve the current value of a variable:\n\\begin{quote}\n  \\tt whizard\\_get\\_int ( \\&wh, \\textit{name}, \\&\\textit{var} );\n  \\\\\n  \\tt whizard\\_get\\_double ( \\&wh, \\textit{name}, \\&\\textit{var} );\n  \\\\\n  \\tt whizard\\_get\\_bool ( \\&wh, \\textit{name}, \\&\\textit{var} );\n  \\\\\n  \\tt whizard\\_get\\_char ( \\&wh, \\textit{name}, \\textit{var}, \\textit{len} );\n\\end{quote}\nHere, \\ttt{\\it var} is a C variable of appropriate type.  In the character\ncase, \\ttt{\\it var} is a C character array declared as\n\\ttt{\\it var}[\\ttt{\\it len}].  The functions return zero if the \\sindarin\\\nvariable has a known value.\n\n\\subsubsection{Commands}\nAny \\sindarin\\ command can be called via\n\\begin{quote}\n  \\tt whizard\\_command( \\&wh, \\textit{command} );\n\\end{quote}\n\\ttt{\\it command} is a null-terminated C string that contains commands as they\nwould appear in a \\sindarin\\ script.\n\nThis includes, in particular, the important commands \\ttt{process},\n\\ttt{integrate}, and \\ttt{simulate}.  You may also set variables that way.\n\n\\subsubsection{Retrieving cross-section results}\nThis call returns the results (integration and error) from a preceding\nintegration run for the process \\textit{process-name}:\n\\begin{quote}\n  \\tt whizard\\_get\\_integration\\_result( \\&wh, \"\\textit{process-name}\",\n  \\&\\textit{integral}, \\&\\textit{error})\n\\end{quote}\n\\ttt{\\it integral} and \\ttt{\\it error} are C variables of type \\ttt{double}.\nThe function returns zero if the integration run was successful, so integral\nand error are meaningful.\n\n\\subsubsection{Event-sample object}\nA \\ttt{simulate} command will produce an event sample.  With the appropriate\nsettings, the sample will be written to file in any chosen format, to be\npost-processed when it is complete.\n\nHowever, a possible purpose of using the \\whizard\\ API is to process events one-by-one\nwhen they are generated.  To this end, there is an event-sample handle, which\ncan be declared in this way:\n\\begin{quote}\n  \\tt void* \\textit{sample};\n\\end{quote}\nAn instance \\ttt{\\it sample} of this type is created by this factory method:\n\\begin{quote}\n  \\tt whizard\\_new\\_sample( \\&wh, \"\\textit{process-name(s)}\", \\&\\textit{sample});\n\\end{quote}\nThe command accepts a comma-separated list of process names which should be\nincluded in the event sample.\n\nTo start event generation for this sample, call\n\\begin{quote}\n  \\tt whizard\\_sample\\_open( \\&\\textit{sample}, \\&\\textit{it\\_begin},\n  \\&\\textit{it\\_end} );\n\\end{quote}\nwhere the two output variables (\\ttt{int}) \\ttt{\\it it\\_begin} and\n\\ttt{\\it it\\_end}\nprovide the bounds for an event loop in the calling program.  (In serial mode,\nthe bounds are equal to 1 and \\ttt{n\\_events}, respectively, but in an MPI\nparallel environment, they depend on the computing node.)\n\nThis command generates a new event, to be enclosed within an event loop:\n\\begin{quote}\n  \\tt whizard\\_sample\\_next\\_event( \\&\\textit{sample} );\n\\end{quote}\nThe event will be available by format-specific access methods, see below.\n\nThis command closes and deletes an event sample after the event loop has\ncompleted:\n\\begin{quote}\n  \\tt whizard\\_sample\\_close( \\&\\textit{sample} );\n\\end{quote}\n\n\\subsubsection{Retrieving event data}\n\nAfter a call to \\ttt{whizard\\_sample\\_next\\_event}, the sample object can be\nqueried for specific event data.\n\\begin{quote}\n  \\tt whizard\\_sample\\_get\\_event\\_index( \\&\\textit{sample}, \\&\\textit{value} );\n  \\\\\n  \\tt whizard\\_sample\\_get\\_process\\_index( \\&\\textit{sample}, \\&\\textit{value} );\n  \\\\\n  \\tt whizard\\_sample\\_get\\_process\\_id( \\&\\textit{sample}, \\textit{value}, \\textit{len} );\n  \\\\\n  \\tt whizard\\_sample\\_get\\_sqrts( \\&\\textit{sample}, \\&\\textit{value} );\n  \\\\\n  \\tt whizard\\_sample\\_get\\_fac\\_scale( \\&\\textit{sample}, \\&\\textit{value} );\n  \\\\\n  \\tt whizard\\_sample\\_get\\_alpha\\_s( \\&\\textit{sample}, \\&\\textit{value} );\n  \\\\\n  \\tt whizard\\_sample\\_get\\_sqme( \\&\\textit{sample}, \\&\\textit{value} );\n  \\\\\n  \\tt whizard\\_sample\\_get\\_weight( \\&\\textit{sample}, \\&\\textit{value} );\n\\end{quote}\nwhere the \\ttt{\\it value} is a variable of appropriate type (see above).\n\nEvent data are stored in a format-specific way.  This may be a COMMON block,\nor a \\hepmc\\ or \\lcio\\ event record.  In the latter cases, cf.\\ the \\cpp\\ API\nbelow for access information.\n\n\\subsection{C++ main program}\nTo link a \\cpp\\ main program with the \\whizard\\ library, the following steps\nmust be performed:\n\\begin{enumerate}\n\\item\n  Configure, build and install \\whizard\\ as normal.\n\\item\n  Include code for accessing \\whizard\\ functionality in the user program.\n  The code should initialize\n  \\whizard, execute the intended commands, and finalize.  For an example, see\n  below.\n\\item\n  Compile the user program with the option that finds the WHIZARD\n  \\ttt{C/C++} interface header file.\n  For instance, if \\whizard\\ has been installed in \\ttt{whizard-path}, this\n  should read\n  \\begin{code}\n    -Iwhizard-path/include\n  \\end{code}\n\\item\n  Link the program with the necessary libraries (or compile-link in a single\n  step).  If\n  \\whizard\\ has been installed in a system path, this should work\n  automatically.  If\n  \\whizard\\ has been installed in a non-default \\ttt{whizard-path}, these\n  are the options:\n  \\begin{code}\n    -Lwhizard-path/lib -lwhizard -lwhizard_prebuilt -lomega -ltirpc\n  \\end{code}\n  On some systems, you may have to replace \\ttt{lib} by \\ttt{lib64}.\n\n  If \\whizard\\ has been compiled with a non-default \\fortran\\ compiler, you may\n  have to explicitly link the appropriate \\fortran\\ run-time libraries.\n\n  The \\ttt{tirpc} library is used by the \\ttt{StdHEP} subsystem for \\ttt{xdr}\n  functionality.  This\n  library should be present on the host system.\n\n  If additional libraries such as\n  \\hepmc\\ are enabled in the \\whizard\\ configuration, it may be necessary to\n  provide extra options for linking those.\n\\item\n  Run the program.  If necessary, provide the path to the installed shared\n  libraries.  For instance, if \\whizard\\ has been installed in\n  \\ttt{whizard-path}, this should read\n  \\begin{code}\n    export LD_LIBRARY_PATH=\"whizard-path/lib:$LD_LIBRARY_PATH\"\n  \\end{code}\n  On some systems, you may have to replace \\ttt{lib} by \\ttt{lib64}, as above.\n\n  The \\whizard\\ subsystem will work with input and output\n  files in the current working directory, unless asked to do otherwise.\n\\end{enumerate}\nBelow is an example program, adapted from \\whizard's internal unit-test suite.\nThe user program controls the \\whizard\\ workflow in the same way as a\n\\sindarin\\ script would do.  The commands are a mixture of \\sindarin\\ command\ncalls and functionality for passing information between the \\whizard\\\nsubsystem and the host program.\nIn particular, the program can process generated events one-by-one.\n\\begin{code}\n#include <cstdio>\n#include <string>\n#include \"whizard.h\"\n\nint main( int argc, char* argv[] )\n{\n  // WHIZARD and event-sample objects\n  Whizard* whizard;\n  WhizardSample* sample;\n\n  // Local variables\n  double integral, error;\n  double sqme, weight;\n  int idx;\n  int it, it_begin, it_end;\n\n  // Initialize WHIZARD, setting some global option\n  whizard = new Whizard();\n  whizard->option( \"model\", \"QED\" );\n  whizard->init();\n\n  // Define a process, set some variables\n  whizard->command( \"process mupair = e1, E1 => e2, E2\" );\n  whizard->set_double( \"sqrts\", 10. );\n  whizard->set_int( \"seed\", 0 );\n\n  // Generate matrix-element code, integrate and retrieve result\n  whizard->command( \"integrate (mupair)\" );\n\n  // Print result\n  whizard->get_integration_result( \"mupair\", &integral, &error );\n  printf( \"  cross section = %5.1f pb\\n\", integral / 1000. );\n  printf( \"  error         = %5.1f pb\\n\", error / 1000. );\n\n  // Settings for event generation\n  whizard->set_string( \"$sample\", \"mupair_events\" );\n  whizard->set_int( \"n_events\", 2 );\n\n  // Create an event-sample object and generate events\n  sample = whizard->new_sample( \"mupair\" );\n  sample->open( &it_begin, &it_end );\n  for (it=it_begin; it<=it_end; it++) {\n    sample->next_event();\n    idx = sample->get_event_index();\n    weight = sample->get_weight();\n    sqme = sample->get_sqme();\n    printf( \"Event #%d\\n\", idx );\n    printf( \"  sqme    = %10.3e\\n\", sqme );\n    printf( \"  weight  = %10.3e\\n\", weight );\n  }\n\n  // Finalize the event-sample object\n  sample->close();\n  delete sample;\n\n  // Finalize the WHIZARD object\n  delete whizard;\n}\n\\end{code}\n\n\\subsubsection{Header}\nThe necessary declarations are imported by the directive\n\\begin{quote}\n  \\tt \\#include \"whizard.h\"\n\\end{quote}\n\n\\subsubsection{Master object}\nAll functionality is accessed via a master API object which should be declared\nas follows:\n\\begin{quote}\n  \\tt Whizard* whizard;\n\\end{quote}\nThe constructor takes no arguments:\n\\begin{quote}\n  \\tt whizard = new Whizard();\n\\end{quote}\nThere should be only one master object.\n\n\\subsubsection{Pre-Initialization options}\nBefore initializing the API object, it is possible to provide options.  The\navailable options mirror the command-line options of the stand-alone program,\ncf.\\ Sec.~\\ref{sec:cmdline-options}.\n\\begin{quote}\n  \\tt  whizard->option( \\textit{key}, \\textit{value} );\n\\end{quote}\nAll keys and values are \\cpp\\ strings.  The available options are\nlisted above in the \\fortran\\ interface documentation.\n\n\\subsubsection{Initialization and finalization}\nAfter options have been set, the system is initialized via\n\\begin{quote}\n  \\tt whizard->init();\n\\end{quote}\nOnce initialized, \\whizard\\ can execute commands as listed below.  When all\nis complete, delete the \\whizard\\ object.  This will call the destructor that\ncorrectly finalizes the \\whizard\\ workflow.\n\n\\subsubsection{Variables and values}\n\nIn the API, \\whizard\\ requires numeric data types according to the IEEE\nstandard.  Integers map to C \\ttt{int}, and real values map to C\n\\ttt{double}.  Logical values map to C \\ttt{int} interpreted as \\ttt{bool},\nand string values map to \\cpp\\ \\ttt{string}.\n\nTo set a \\sindarin\\ variable of appropriate type:\n\\begin{quote}\n  \\tt whizard->set\\_int ( \\textit{name}, \\textit{value} );\n  \\\\\n  \\tt whizard->set\\_double ( \\textit{name}, \\textit{value} );\n  \\\\\n  \\tt whizard->set\\_bool ( \\textit{name}, \\textit{value} );\n  \\\\\n  \\tt whizard->set\\_string ( \\textit{name}, \\textit{value} );\n\\end{quote}\n\\textit{name} is a \\cpp\\ string value.  It must match the corresponding\n\\sindarin\\ variable name, including any prefix character (\\$ or ?).\n\\textit{value} is a \\ttt{double/int/string}, respectively.\n\nTo retrieve the current value of a variable:\n\\begin{quote}\n  \\tt whizard->get\\_int ( \\textit{name}, \\&\\textit{var} );\n  \\\\\n  \\tt whizard->get\\_double ( \\textit{name}, \\&\\textit{var} );\n  \\\\\n  \\tt whizard->get\\_bool ( \\textit{name}, \\&\\textit{var} );\n  \\\\\n  \\tt whizard->get\\_string ( \\textit{name}, \\&\\textit{var} );\n\\end{quote}\nHere, \\ttt{\\it var} is a C variable of appropriate type.  The functions return\nzero if the \\sindarin\\ variable has a known value.\n\n\\subsubsection{Commands}\nAny \\sindarin\\ command can be called via\n\\begin{quote}\n  \\tt whizard->command( \\textit{command} );\n\\end{quote}\n\\ttt{\\it command} is a \\cpp\\ string value that contains commands as they\nwould appear in a \\sindarin\\ script.\n\nThis includes, in particular, the important commands \\ttt{process},\n\\ttt{integrate}, and \\ttt{simulate}.  You may also set variables that way.\n\n\\subsubsection{Retrieving cross-section results}\nThis call returns the results (integration and error) from a preceding\nintegration run for the process \\textit{process-name}:\n\\begin{quote}\n  \\tt whizard->get\\_integration\\_result( \"\\textit{process-name}\",\n  \\&\\textit{integral}, \\&\\textit{error} );\n\\end{quote}\n\\ttt{\\it integral} and \\ttt{\\it error} are variables of type \\ttt{double}.\nThe function returns zero if the integration run was successful, so integral\nand error are meaningful.\n\n\\subsubsection{Event-sample object}\nA \\ttt{simulate} command will produce an event sample.  With the appropriate\nsettings, the sample will be written to file in any chosen format, to be\npost-processed when it is complete.\n\nHowever, a possible purpose of using the \\whizard\\ API is to process events one-by-one\nwhen they are generated.  To this end, there is an event-sample handle, which\ncan be declared in this way:\n\\begin{quote}\n  \\tt WhizardSample* {sample};\n\\end{quote}\nAn instance \\ttt{\\it sample} of this type is created by this factory method:\n\\begin{quote}\n  \\tt {sample} = whizard->new\\_sample( \"\\textit{process-name(s)}\" );\n\\end{quote}\nThe command accepts a comma-separated list of process names which should be\nincluded in the event sample.\n\nTo start event generation for this sample, call\n\\begin{quote}\n  \\tt sample->open( \\&\\textit{it\\_begin},\n  \\&\\textit{it\\_end});\n\\end{quote}\nwhere the two output variables (\\ttt{int}) \\ttt{\\it it\\_begin} and\n\\ttt{\\it it\\_end}\nprovide the bounds for an event loop in the calling program.  (In serial mode,\nthe bounds are equal to 1 and \\ttt{n\\_events}, respectively, but in an MPI\nparallel environment, they depend on the computing node.)\n\nThis command generates a new event, to be enclosed within an event loop:\n\\begin{quote}\n  \\tt sample->next\\_event();\n\\end{quote}\nThe event will be available by format-specific access methods, see below.\n\nThis command closes and deletes an event sample after the event loop has\ncompleted:\n\\begin{quote}\n  \\tt sample->close();\n\\end{quote}\n\n\\subsubsection{Retrieving event data}\n\nAfter a call to \\ttt{sample->next\\_event}, the sample object can be\nqueried for specific event data.\n\\begin{quote}\n  \\tt value = sample->get\\_event\\_index();\n  \\\\\n  \\tt value = sample->get\\_process\\_index();\n  \\\\\n  \\tt value = sample->get\\_process\\_id();\n  \\\\\n  \\tt value = sample->get\\_sqrts();\n  \\\\\n  \\tt value = sample->get\\_fac\\_scale();\n  \\\\\n  \\tt value = sample->get\\_alpha\\_s();\n  \\\\\n  \\tt value = sample->get\\_sqme();\n  \\\\\n  \\tt value = sample->get\\_weight();\n\\end{quote}\nwhere the \\ttt{\\it value} is a variable of appropriate type (see above).\n\nEvent data are stored in a format-specific way.  This may be a \\hepmc\\ or\n\\lcio\\ \\cpp\\ event record.\n\nFor interfacing with the \\hepmc\\ event record, the appropriate declarations\nmust be in place, e.g.,\n\\begin{quote}\n  \\tt \\#include \"HepMC/GenEvent.h\"\n  \\\\\n  using namespace HepMC;\n\\end{quote}\nAn event-record object must be declared,\n\\begin{quote}\n  \\tt GenEvent* evt;\n\\end{quote}\nand the \\whizard\\ event call must take the event as an argument\n\\begin{quote}\n  \\tt sample->next\\_event ( \\&evt );\n\\end{quote}\nThis will create a new \\ttt{evt} object.\nThen, the \\hepmc\\ event record can be accessed via its own methods.  After\nan event has been processed, the event record should be deleted\n\\begin{quote}\n  \\tt delete evt;\n\\end{quote}\n\nAnalogously, for interfacing with the \\lcio\\ event record, the appropriate declarations\nmust be in place, e.g.,\n\\begin{quote}\n  \\tt\n  \\#include \"lcio.h\"\n  \\\\\n  \\#include \"IMPL/LCEventImpl.h\"\n  \\\\\n  using namespace lcio;\n\\end{quote}\nAn event-record object must be declared,\n\\begin{quote}\n  \\tt LCEvent* evt;\n\\end{quote}\nand the \\whizard\\ event call must take the event as an argument\n\\begin{quote}\n  \\tt sample->next\\_event ( \\&evt );\n\\end{quote}\nThis will create a new \\ttt{evt} object.\nThen, the \\lcio\\ event record can be accessed via its own methods.  After\nan event has been processed, the event record should be deleted\n\\begin{quote}\n  \\tt delete evt;\n\\end{quote}\n\n\n\\subsection{Python main program}\nTo create a \\python\\ executable, \\whizard\\ provides a \\ttt{Cython}\ninterface that uses \\cpp\\ bindings to link a dynamic library which can\nthen be loaded as a module via \\python. Note that \\whizard's\n\\ttt{Cython}/\\python\\ interface only works with \\python\\ttt{v3}. Also\nmake sure that you do not mix different \\python\\ versions when linking\nexternal programs which also provide \\python\\ interfaces like\n\\hepmc\\ or \\lcio.\n\nTo link a \\python\\ main program with the \\whizard\\ library, the following steps\nmust be performed:\n\\begin{enumerate}\n\\item\n  Configure, build and install \\whizard\\ as normal.\n\\item\n  Include code for accessing \\whizard\\ functionality in the user program.\n  The code should initialize\n  \\whizard, execute the intended commands, and finalize.  For an example, see\n  below.\n\\item\n  Run \\python\\ on the user program. Make sure that the operating\n  system finds the \\whizard\\ \\python\\ and library path.\n  If \\whizard\\ has been installed in a non-default \\ttt{whizard-path}, these\n  are the options:\n  \\begin{code}\n    export PYTHONPATH=whizard-path/lib/python/site-packages/:$PYTHONPATH\n  \\end{code}\n\n  If necessary, provide the path to the installed shared\n  libraries.  For instance, if \\whizard\\ has been installed in\n  \\ttt{whizard-path}, this should read\n  \\begin{code}\n    export LD_LIBRARY_PATH=\"whizard-path/lib:$LD_LIBRARY_PATH\"\n  \\end{code}\n  On some systems, you may have to replace \\ttt{lib} by \\ttt{lib64}, as above.\n\n  The \\whizard\\ subsystem will work with input and output\n  files in the current working directory, unless asked to do otherwise.\n  \n\\item\n  The \\ttt{tirpc} library is used by the \\ttt{StdHEP} subsystem for \\ttt{xdr}\n  functionality.  This\n  library should be present on the host system.\n\n\\item\n  Run the program.  \n\\end{enumerate}\nBelow is an example program, similar to \\whizard's internal unit-test\nsuite for different external programming languages. The user program\ncontrols the \\whizard\\ workflow in the same way as a \\sindarin\\ script\nwould do.  The commands are a mixture of \\sindarin\\ command \ncalls and functionality for passing information between the \\whizard\\\nsubsystem and the host program.\nIn particular, the program can process generated events one-by-one.\n\\begin{code}\nimport whizard\n\nwz = whizard.Whizard()\n\nwz.option(\"logfile\", \"whizard_1_py.log\")\nwz.option(\"job_id\", \"whizard_1_py_ID\")\nwz.option(\"library\", \"whizard_1_py_1_lib\")\nwz.option(\"model\", \"QED\")\n\nwz.init()\n\nwz.set_double(\"sqrts\", 100)\nwz.set_int(\"n_events\", 3)\nwz.set_bool(\"?unweighted\", True)\nwz.set_string(\"$sample\", \"foobar\")\n\nwz.set_int(\"seed\", 0)\n\nwz.command(\"process whizard_1_py_1_p = e1, E1 => e2, E2\")\nwz.command(\"iterations = 1:100\")\n\nintegral, error = wz.get_integration_result(\"whizard_1_py_1_p\")\nprint(integral, error)\n\nwz.command(\"integrate (whizard_1_py_1_p)\")\nsqrts = wz.get_double(\"sqrts\")\nprint(f\"sqrts  = {sqrts:5.1f} GeV\")\nprint(f\"sigma   = integral:5.1f} pb\")\nprint(f\"error    {error:5.1f} pb\")\n\nsample = wz.new_sample(\"whizard_1_py_p1, whizard_1_py_p2, whizard_1_py_p3\")\nit_begin, it_end = sample.open()\nfor it in range(it_begin, it_end + 1):\n    sample.next_event()\n    idx = sample.get_event_index()\n    i_proc  = sample.get_process_index()\n    proc_id = sample.get_process_id()\n    f_scale = sample.get_fac_scale()\n    alpha_s = sample.get_alpha_s()\n    weight  = sample.get_weight()\n    sqme    = sample.get_sqme()\n    print(f\"Event #{idx}\")\n    print(f\"  process #{i_proc}\")\n    print(f\"  proc_id = {proc_id}\")\n    print(f\"  f_scale = {f_scale:10.3e}\")\n    print(f\"  alpha_s = {f_scale:10.3e}\")\n    print(f\"  sqme    = {f_scale:10.3e}\")\n    print(f\"  weight  = {f_scale:10.3e}\")\n\nsample.close()\n\ndel(wz)      \n\\end{code}\n\n\\subsubsection{Python module import}\nThere are no necessary headers here as all of this information has\nbeen automatically taken care by the \\ttt{Cython} interface layer. The\n\\whizard\\ module needs to be imported by \\python\\:\n\\begin{quote}\n  \\tt import whizard\n\\end{quote}\n\n\\subsubsection{Master object}\nAll functionality is accessed via a master API object which should be declared\nas follows:\n\\begin{quote}\n  \\tt wz = whizard.Whizard()\n\\end{quote}\nThe constructor takes no arguments.There should be only one master\nobject.\n\n\\subsubsection{Pre-Initialization options}\nBefore initializing the API object, it is possible to provide options.  The\navailable options mirror the command-line options of the stand-alone program,\ncf.\\ Sec.~\\ref{sec:cmdline-options}.\n\\begin{quote}\n  \\tt  wz.option( \\textit{key}, \\textit{value} );\n\\end{quote}\nAll keys and values are \\python\\ strings.  The available options are\nlisted above in the \\fortran\\ interface documentation.\n\n\\subsubsection{Initialization and finalization}\nAfter options have been set, the system is initialized via\n\\begin{quote}\n  \\tt wz.init()\n\\end{quote}\nOnce initialized, \\whizard\\ can execute commands as listed below.  When all\nis complete, delete the \\whizard\\ object.  This will call the destructor that\ncorrectly finalizes the \\whizard\\ workflow.\n\n\\subsubsection{Variables and values}\n\nIn the API, \\whizard\\ requires numeric data types according to the IEEE\nstandard.  Integers map to \\ttt{Python int}, and real values map to \\ttt{Python\ndouble}.  Logical values map to \\ttt{True} and \\ttt{False},\nand string values map to \\python\\ strings.\n\nTo set a \\sindarin\\ variable of appropriate type:\n\\begin{quote}\n  \\tt wz.set\\_int ( \\textit{name}, \\textit{value} );\n  \\\\   \n  \\tt wz.set\\_double ( \\textit{name}, \\textit{value} );\n  \\\\   \n  \\tt wz.set\\_bool ( \\textit{name}, \\textit{value} );\n  \\\\  \n  \\tt wz.set\\_string ( \\textit{name}, \\textit{value} );\n\\end{quote}\n\\textit{name} is a \\python\\ string value.  It must match the corresponding\n\\sindarin\\ variable name, including any prefix character (\\$ or ?).\n\\textit{value} is a \\ttt{double/int/string}, respectively.\n\nTo retrieve the current value of a variable:\n\\begin{quote}\n  \\tt wz.get\\_int ( \\textit{name}, \\textit{var} );\n  \\\\\n  \\tt wz.get\\_double ( \\textit{name}, \\textit{var} );\n  \\\\\n  \\tt wz.get\\_bool ( \\textit{name}, \\textit{var} );\n  \\\\\n  \\tt wz.get\\_string ( \\textit{name}, \\textit{var} );\n\\end{quote}\nHere, \\ttt{\\it var} is a \\python\\ variable of appropriate type.  The\nfunctions return zero if the \\sindarin\\ variable has a known value.\n\n\\subsubsection{Commands}\nAny \\sindarin\\ command can be called via\n\\begin{quote}\n  \\tt wz.command( \\textit{command} );\n\\end{quote}\n\\ttt{\\it command} is a \\python\\ string value that contains commands as they\nwould appear in a \\sindarin\\ script.\n\nThis includes, in particular, the important commands \\ttt{process},\n\\ttt{integrate}, and \\ttt{simulate}.  You may also set variables that way.\n\n\\subsubsection{Retrieving cross-section results}\nThis call returns the results (integration and error) from a preceding\nintegration run for the process \\textit{process-name}:\n\\begin{quote}\n  \\tt wz.get\\_integration\\_result( \"\\textit{process-name}\",\n  \\textit{integral}, \\textit{error} );\n\\end{quote}\n\\ttt{\\it integral} and \\ttt{\\it error} are variables of type \\ttt{double}.\nThe function returns zero if the integration run was successful, so integral\nand error are meaningful.\n\n\\subsubsection{Event-sample object}\nA \\ttt{simulate} command will produce an event sample.  With the appropriate\nsettings, the sample will be written to file in any chosen format, to be\npost-processed when it is complete.\n\nHowever, a possible purpose of using the \\whizard\\ API is to process events one-by-one\nwhen they are generated.  To this end, there is an event-sample handle, which\ncan be declared in this way:\n\\begin{quote}\n  \\tt WhizardSample* {sample};\n\\end{quote}\nAn instance \\ttt{\\it sample} of this type is created by this factory method:\n\\begin{quote}\n  \\tt {sample} = wz.new\\_sample( \"\\textit{process-name(s)}\" );\n\\end{quote}\nThe command accepts a comma-separated list of process names which should be\nincluded in the event sample.\n\nTo start event generation for this sample, call\n\\begin{quote}\n  \\tt \\textit{it\\_begin}, \\textit{it\\_end} = wz.sample\\_open()\n\\end{quote}\nwhere the two output variables (\\ttt{int}) \\ttt{\\it it\\_begin} and\n\\ttt{\\it it\\_end}\nprovide the bounds for an event loop in the calling program.  (In serial mode,\nthe bounds are equal to 1 and \\ttt{n\\_events}, respectively, but in an MPI\nparallel environment, they depend on the computing node.)\n\nThis command generates a new event, to be enclosed within an event loop:\n\\begin{quote}\n  \\tt sample.next\\_event();\n\\end{quote}\nThe event will be available by format-specific access methods, see below.\n\nThis command closes and deletes an event sample after the event loop has\ncompleted:\n\\begin{quote}\n  \\tt sample.close();\n\\end{quote}\n\n\\subsubsection{Retrieving event data}\n\nAfter a call to \\ttt{sample.next\\_event}, the sample object can be\nqueried for specific event data.\n\\begin{quote}\n  \\tt value = sample.get\\_event\\_index();\n  \\\\\n  \\tt value = sample.get\\_process\\_index();\n  \\\\\n  \\tt value = sample.get\\_process\\_id();\n  \\\\\n  \\tt value = sample.get\\_sqrts();\n  \\\\\n  \\tt value = sample.get\\_fac\\_scale();\n  \\\\\n  \\tt value = sample.get\\_alpha\\_s();\n  \\\\\n  \\tt value = sample.get\\_sqme();\n  \\\\\n  \\tt value = sample.get\\_weight();\n\\end{quote}\nwhere the \\ttt{\\it value} is a variable of appropriate type (see above).\n\nEvent data are stored in a format-specific way.  This may be a \\hepmc\\ or\n\\lcio\\ \\cpp\\ event record, or some formats supported by\n\\whizard\\ intrinsically like LHEF etc.\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n\\chapter{Examples}\n\\label{chap:examples}\n\nIn this chapter we discuss the running and steering of \\whizard\\ with\nthe help of several examples. These examples can be found in the\n\\ttt{share/examples} directory of your installation. All of these\nexamples are also shown on the \\whizard\\ Wiki page:\n\\url{https://whizard.hepforge.org/trac/wiki}.\n\n\n\\section{$Z$ lineshape at LEP I}\n\nBy this example, we demonstrate how a scan over collision energies\nworks, using as example the measurement of the $Z$ lineshape at LEP I\nin 1989. The \\sindarin\\ script for this example, \\ttt{Z-lineshape.sin}\ncan be found in the \\ttt{share/examples} folder of the \\whizard\\\ninstallation.\n\nWe first use the Standard model as physics model:\n\\begin{code}\nmodel = SM\n\\end{code}\nAliases for electron, muon and their antiparticles as leptons and\nthose including the photon as particles in general are introduced:\n\\begin{code}\nalias lep = e1:E1:e2:E2\nalias prt = lep:A\n\\end{code}\nNext, the two processes are defined, \\eemm, and the same with an\nexplicit QED photon: $e^+e^- \\to \\mu^+\\mu^-\\gamma$,\n\\begin{code}\nprocess bornproc = e1, E1 => e2, E2\nprocess rc = e1, E1 => e2, E2, A\ncompile\n\\end{code}\nand the processes are compiled. Now, we define some very loose cuts to\navoid singular regions in phase space, name an infrared cutoff of 100\nMeV for all particles, a cut on the angular separation from the beam\naxis and a di-particle invariant mass cut which regularizes collinear\nsingularities:\n\\begin{code}\ncuts = all E >= 100 MeV [prt]\n   and all abs (cos(Theta)) <= 0.99 [prt]\n   and all M2 >= (1 GeV)^2 [prt, prt]\n\\end{code}\nFor the graphical analysis, we give a description and labels for the\n$x$- and $y$-axis in \\LaTeX\\ syntax:\n\\begin{code}\n$description = \"A WHIZARD Example\"\n$x_label = \"$\\sqrt{s}$/GeV\"\n$y_label = \"$\\sigma(s)$/pb\"\n\\end{code}\nWe define two plots for the lineshape of the \\eemm\\ process between 88\nand 95 GeV,\n\\begin{code}\n$title = \"The Z Lineshape in $e^+e^-\\to\\mu^+\\mu^-$\"\nplot lineshape_born { x_min = 88 GeV  x_max = 95 GeV }\n\\end{code}\nand the same for the radiative process with an additional photon:\n\\begin{code}\n$title = \"The Z Lineshape in $e^+e^-\\to\\mu^+\\mu^-\\gamma$\"\nplot lineshape_rc { x_min = 88 GeV  x_max = 95 GeV }\n\\end{code}\n%$\nThe next part of the \\sindarin\\ file actually performs the scan:\n\\begin{code}\nscan sqrts = ((88.0 GeV => 90.0 GeV /+ 0.5 GeV),\n              (90.1 GeV => 91.9 GeV /+ 0.1 GeV),\n              (92.0 GeV => 95.0 GeV /+ 0.5 GeV)) {\n  beams = e1, E1\n  integrate (bornproc) { iterations = 2:1000:\"gw\", 1:2000 }\n  record lineshape_born (sqrts, integral (bornproc) / 1000)\n  integrate (rc)   { iterations = 5:3000:\"gw\", 2:5000 }\n  record lineshape_rc (sqrts, integral (rc) / 1000)\n}\n\\end{code}\nSo from 88 to 90 GeV, we go in 0.5 GeV steps, then from 90 to 92 GeV\nin tenth of GeV, and then up to 95 GeV again in half a GeV steps. The\npartonic beam definition is redundant. Then, the born process is\nintegrated, using a certain specification of calls with adaptation of\ngrids and weights, as well as a final pass. The lineshape of the Born\nprocess is defined as a \\ttt{record} statement, generating tuples of\n$\\sqrt{s}$ and the Born cross section (converted from femtobarn to\npicobarn). The same happens for the radiative $2\\to3$ process with a\nbit more iterations because of the complexity, and the definition of\nthe corresponding lineshape record.\n\nIf you run the \\sindarin\\ script, you will find an output like:\n\\begin{scriptsize}\n\\begin{Verbatim}[frame=single]\n           | Process library 'default_lib': loading\n           | Process library 'default_lib': ... success.\n           $description = \"A WHIZARD Example\"\n           $x_label = \"$\\sqrt{s}$/GeV\"\n           $y_label = \"$\\sigma(s)$/pb\"\n           $title = \"The Z Lineshape in $e^+e^-\\to\\mu^+\\mu^-$\"\n           x_min =  8.800000000000E+01\n           x_max =  9.500000000000E+01\n           $title = \"The Z Lineshape in $e^+e^-\\to\\mu^+\\mu^-\\gamma$\"\n           x_min =  8.800000000000E+01\n           x_max =  9.500000000000E+01\n           sqrts =  8.800000000000E+01\n           | RNG: Initializing TAO random-number generator\n           | RNG: Setting seed for random-number generator to 10713\n           | Initializing integration for process bornproc:\n           | ------------------------------------------------------------------------\n           | Process [scattering]: 'bornproc'\n           |   Library name  = 'default_lib'\n           |   Process index = 1\n           |   Process components:\n           |     1: 'bornproc_i1':   e-, e+ => mu-, mu+ [omega]\n           | ------------------------------------------------------------------------\n           | Beam structure: e-, e+\n           | Beam data (collision):\n           |   e-  (mass = 5.1099700E-04 GeV)\n           |   e+  (mass = 5.1099700E-04 GeV)\n           |   sqrts = 8.800000000000E+01 GeV\n           | Phase space: generating configuration ...\n           | Phase space: ... success.\n           | Phase space: writing configuration file 'bornproc_i1.phs'\n           | Phase space: 1 channels, 2 dimensions\n           | Phase space: found 1 channel, collected in 1 grove.\n           | Phase space: Using 1 equivalence between channels.\n           | Phase space: wood\n           | Applying user-defined cuts.\n           | OpenMP: Using 8 threads\n           | Starting integration for process 'bornproc'\n           | Integrate: iterations = 2:1000:\"gw\", 1:2000\n           | Integrator: 1 chains, 1 channels, 2 dimensions\n           | Integrator: Using VAMP channel equivalences\n           | Integrator: 1000 initial calls, 20 bins, stratified = T\n           | Integrator: VAMP\n           |=============================================================================|\n           | It      Calls  Integral[fb]  Error[fb]   Err[%]    Acc  Eff[%]   Chi2 N[It] |\n           |=============================================================================|\n              1        800  2.5881432E+05  1.85E+03    0.72    0.20*  48.97\n              2        800  2.6368495E+05  9.25E+02    0.35    0.10*  28.32\n           |-----------------------------------------------------------------------------|\n              2       1600  2.6271122E+05  8.28E+02    0.32    0.13   28.32    5.54   2\n           |-----------------------------------------------------------------------------|\n              3       1988  2.6313791E+05  5.38E+02    0.20    0.09*  35.09\n           |-----------------------------------------------------------------------------|\n              3       1988  2.6313791E+05  5.38E+02    0.20    0.09   35.09\n           |=============================================================================|\n           | Time estimate for generating 10000 events: 0d:00h:00m:05s\n           [.......]\n\\end{Verbatim}\n\\end{scriptsize} %$\nand then the integrations for the other energy points of the scan will\n\\begin{figure}\n  \\centering\n  \\includegraphics[width=.47\\textwidth]{Z-lineshape_1}\n  \\includegraphics[width=.47\\textwidth]{Z-lineshape_2}\n\\caption{\\label{fig:zlineshape} $Z$ lineshape in the dimuon final\n  state (left), and with an additional photon (right)}\n\\end{figure}\nfollow, and finally the same is done for the radiative process as\nwell. At the end of the \\sindarin\\ script we compile the graphical\n\\whizard\\ analysis and direct the data for the plots into the file\n\\ttt{Z-lineshape.dat}:\n\\begin{code}\ncompile_analysis { $out_file = \"Z-lineshape.dat\" }\n\\end{code}\n%$\nIn this case there is no event generation, but simply the cross\nsection values for the scan are dumped into a data file:\n\\begin{scriptsize}\n\\begin{Verbatim}[frame=single]\n           $out_file = \"Z-lineshape.dat\"\n           | Opening file 'Z-lineshape.dat' for output\n           | Writing analysis data to file 'Z-lineshape.dat'\n           | Closing file 'Z-lineshape.dat' for output\n           | Compiling analysis results display in 'Z-lineshape.tex'\n\\end{Verbatim}\n\\end{scriptsize}\n%$\nFig.~\\ref{fig:zlineshape} shows the graphical \\whizard\\ output of the\n$Z$ lineshape in the dimuon final state from the scan on the left, and\nthe same for the radiative process with an additional photon on the\nright.\n\n%%%%%%%%%%%%%%%\n\n\\section{$W$ pairs at LEP II}\n\nThis example which can be found as file \\ttt{LEP\\_cc10.sin} in the\n\\ttt{share/examples} directory, shows $W$ pair production in the\nsemileptonic mode at LEP II with its final energy of 209 GeV. Because\nthere are ten contributing Feynman diagrams, the process has been\ndubbed CC10: charged current process with 10 diagrams. We work within\nthe Standard Model:\n\\begin{code}\n  model = SM\n\\end{code}\nThen the process is defined, where no flavor summation is done for the\njets here:\n\\begin{code}\n  process cc10 = e1, E1 => e2, N2, u, D\n\\end{code}\nA compilation statement is optional, and then we set the muon mass to\nzero:\n\\begin{code}\n  mmu = 0\n\\end{code}\nThe final LEP center-of-momentum energy of 209 GeV is set:\n\\begin{code}\n  sqrts = 209 GeV\n\\end{code}\nThen, we integrate the process:\n\\begin{code}\n  integrate (cc10) { iterations = 12:20000 }\n\\end{code}\nRunning the \\sindarin\\ file up to here, results in the output:\n\\begin{scriptsize}\n\\begin{Verbatim}[frame=single]\n          | Process library 'default_lib': loading\n          | Process library 'default_lib': ... success.\n          SM.mmu =  0.000000000000E+00\n          sqrts =  2.090000000000E+02\n          | RNG: Initializing TAO random-number generator\n          | RNG: Setting seed for random-number generator to 31255\n          | Initializing integration for process cc10:\n          | ------------------------------------------------------------------------\n          | Process [scattering]: 'cc10'\n          |   Library name  = 'default_lib'\n          |   Process index = 1\n          |   Process components:\n          |     1: 'cc10_i1':   e-, e+ => mu-, numubar, u, dbar [omega]\n          | ------------------------------------------------------------------------\n          | Beam structure: [any particles]\n          | Beam data (collision):\n          |   e-  (mass = 5.1099700E-04 GeV)\n          |   e+  (mass = 5.1099700E-04 GeV)\n          |   sqrts = 2.090000000000E+02 GeV\n          | Phase space: generating configuration ...\n          | Phase space: ... success.\n          | Phase space: writing configuration file 'cc10_i1.phs'\n          | Phase space: 25 channels, 8 dimensions\n          | Phase space: found 25 channels, collected in 7 groves.\n          | Phase space: Using 25 equivalences between channels.\n          | Phase space: wood\n          Warning: No cuts have been defined.\n          | OpenMP: Using 8 threads\n          | Starting integration for process 'cc10'\n          | Integrate: iterations = 12:20000\n          | Integrator: 7 chains, 25 channels, 8 dimensions\n          | Integrator: Using VAMP channel equivalences\n          | Integrator: 20000 initial calls, 20 bins, stratified = T\n          | Integrator: VAMP\n          |=============================================================================|\n          | It      Calls  Integral[fb]  Error[fb]   Err[%]    Acc  Eff[%]   Chi2 N[It] |\n          |=============================================================================|\n             1      19975  6.4714908E+02  2.17E+01    3.36    4.75*   2.33\n             2      19975  7.3251876E+02  2.45E+01    3.34    4.72*   2.17\n             3      19975  6.7746497E+02  2.39E+01    3.52    4.98    1.77\n             4      19975  7.2075198E+02  2.41E+01    3.34    4.72*   1.76\n             5      19975  6.5976152E+02  2.26E+01    3.43    4.84    1.46\n             6      19975  6.6633310E+02  2.26E+01    3.39    4.79*   1.43\n             7      19975  6.7539385E+02  2.29E+01    3.40    4.80    1.43\n             8      19975  6.6754027E+02  2.11E+01    3.15    4.46*   1.41\n             9      19975  7.3975817E+02  2.52E+01    3.40    4.81    1.53\n            10      19975  7.2284275E+02  2.39E+01    3.31    4.68*   1.47\n            11      19975  6.5476917E+02  2.18E+01    3.33    4.71    1.33\n            12      19975  7.2963866E+02  2.54E+01    3.48    4.92    1.46\n          |-----------------------------------------------------------------------------|\n            12     239700  6.8779583E+02  6.69E+00    0.97    4.76    1.46    2.18  12\n          |=============================================================================|\n          | Time estimate for generating 10000 events: 0d:00h:01m:16s\n          | Creating integration history display cc10-history.ps and cc10-history.pdf\n\\end{Verbatim}\n\\end{scriptsize}\n\\begin{figure}\n  \\centering\n  \\includegraphics[width=.6\\textwidth]{cc10_1}\n  \\\\\\vspace{5mm}\n  \\includegraphics[width=.6\\textwidth]{cc10_2}\n  \\caption{Histogram of the dijet invariant mass from the CC10 $W$\n    pair production at LEP II, peaking around the $W$ mass (upper\n    plot), and of the muon energy (lower plot).}\n  \\label{fig:cc10}\n\\end{figure}\nThe next step is event generation. In order to get smooth\ndistributions, we set the integrated luminosity to 10\nfb${}^{-1}$. (Note that LEP II in its final year 2000 had an\nintegrated luminosity of roughly 0.2 fb${}^{-1}$.)\n\\begin{code}\n  luminosity = 10\n\\end{code}\nWith the simulated events corresponding to those 10 inverse femtobarn\nwe want to perform a \\whizard\\ analysis: we are going to plot the\ndijet invariant mass, as well as the energy of the outgoing muon. For\nthe plot of the analysis, we define a description and label the $y$\naxis:\n\\begin{code}\n$description =\n  \"A WHIZARD Example.\n   Charged current CC10 process from LEP 2.\"\n$y_label = \"$N_{\\textrm{events}}$\"\n\\end{code}\nWe also use \\LaTeX-syntax for the title of the first plot and the\n$x$-label, and then define the histogram of the dijet invariant mass\nin the range around the $W$ mass from 70 to 90 GeV in steps of half a\nGeV:\n\\begin{code}\n$title = \"Di-jet invariant mass $M_{jj}$ in $e^+e^- \\to \\mu^- \\bar\\nu_\\mu u \\bar d$\"\n$x_label = \"$M_{jj}$/GeV\"\nhistogram m_jets (70 GeV, 90 GeV, 0.5 GeV)\n\\end{code}\nAnd we do the same for the second histogram of the muon energy:\n\\begin{code}\n$title = \"Muon energy $E_\\mu$ in $e^+e^- \\to \\mu^- \\bar\\nu_\\mu u \\bar d$\"\n$x_label = \"$E_\\mu$/GeV\"\nhistogram e_muon (0 GeV, 209 GeV, 4)\n\\end{code}\nNow, we define the \\ttt{analysis} consisting of two \\ttt{record}\nstatements initializing the two observables that are plotted as\nhistograms:\n\\begin{code}\nanalysis = record m_jets (eval M [u,D]);\n           record e_muon (eval E [e2])\n\\end{code}\nAt the very end, we perform the event generation\n\\begin{code}\nsimulate (cc10)\n\\end{code}\nand finally the writing and compilation of the analysis in a named\ndata file:\n\\begin{code}\ncompile_analysis { $out_file = \"cc10.dat\" }\n\\end{code}\nThis event generation part screen output looks like this:\n\\begin{scriptsize}\n\\begin{Verbatim}[frame=single]\n          luminosity =  1.000000000000E+01\n          $description = \"A WHIZARD Example.\n             Charged current CC10 process from LEP 2.\"\n          $y_label = \"$N_{\\textrm{events}}$\"\n          $title = \"Di-jet invariant mass $M_{jj}$ in $e^+e^- \\to \\mu^- \\bar\\nu_\\mu u \\bar d$\"\n          $x_label = \"$M_{jj}$/GeV\"\n          $title = \"Muon energy $E_\\mu$ in $e^+e^- \\to \\mu^- \\bar\\nu_\\mu u \\bar d$\"\n          $x_label = \"$E_\\mu$/GeV\"\n          | Starting simulation for process 'cc10'\n          | Simulate: using integration grids from file 'cc10_m1.vg'\n          | RNG: Initializing TAO random-number generator\n          | RNG: Setting seed for random-number generator to 9910\n          | OpenMP: Using 8 threads\n          | Simulation: using n_events as computed from luminosity value\n          | Events: writing to raw file 'cc10.evx'\n          | Events: generating 6830 unweighted, unpolarized events ...\n          | Events: event normalization mode '1'\n          |         ... event sample complete.\n          Warning: Encountered events with excess weight: 39 events (  0.571 %)\n          | Maximum excess weight = 1.027E+00\n          | Average excess weight = 6.764E-04\n          | Events: closing raw file 'cc10.evx'\n          $out_file = \"cc10.dat\"\n          | Opening file 'cc10.dat' for output\n          | Writing analysis data to file 'cc10.dat'\n          | Closing file 'cc10.dat' for output\n          | Compiling analysis results display in 'cc10.tex'\n\\end{Verbatim}\n\\end{scriptsize} %$\nThen comes the \\LaTeX\\ output of the compilation of the graphical\nanalysis. Fig.~\\ref{fig:cc10} shows the two histograms as the are\nproduced as result of the \\whizard\\ internal graphical analysis.\n\n%%%%%%%%%%%%%%%\n\n\\section{Higgs search at LEP II}\n\nThis example can be found under the name \\ttt{LEP\\_higgs.sin} in the\n\\ttt{share/doc} folder of \\whizard. It displays different search\nchannels for a very light would-be SM Higgs boson of mass 115 GeV at\nthe LEP II machine at its highest energy it finally achieved, 209 GeV.\nFirst, we use the Standard Model:\n\\begin{code}\nmodel = SM\n\\end{code}\nThen, we define aliases for neutrinos, antineutrinos, light quarks and\nlight anti-quarks:\n\\begin{code}\nalias n = n1:n2:n3\nalias N = N1:N2:N3\nalias q = u:d:s:c\nalias Q = U:D:S:C\n\\end{code}\nNow, we define the signal process, which is Higgsstrahlung,\n\\begin{code}\nprocess zh = e1, E1 => Z, h\n\\end{code}\nthe missing-energy channel,\n\\begin{code}\nprocess nnbb = e1, E1 => n, N, b, B\n\\end{code}\nand finally the 4-jet as well as dilepton-dijet channels:\n\\begin{code}\nprocess qqbb = e1, E1 => q, Q, b, B\nprocess bbbb = e1, E1 => b, B, b, B\nprocess eebb = e1, E1 => e1, E1, b, B\nprocess qqtt = e1, E1 => q, Q, e3, E3\nprocess bbtt = e1, E1 => b, B, e3, E3\n\ncompile\n\\end{code}\nand we compile the code. We set the center-of-momentum energy to the\nhighest energy LEP II achieved,\n\\begin{code}\nsqrts = 209 GeV\n\\end{code}\nFor the Higgs boson, we take the values of a would-be SM Higgs boson\nwith mass of 115 GeV, which would have had a width of a bit more than\n3 MeV:\n\\begin{code}\nmH = 115 GeV\nwH = 3.228 MeV\n\\end{code}\nWe take a running $b$ quark mass to take into account NLO corrections\nto the $Hb\\bar b$ vertex, while all other fermions are massless:\n\\begin{code}\nmb = 2.9 GeV\nme = 0\nms = 0\nmc = 0\n\\end{code}\n\\begin{scriptsize}\n\\begin{Verbatim}[frame=single]\n           | Process library 'default_lib': loading\n           | Process library 'default_lib': ... success.\n           sqrts =  2.090000000000E+02\n           SM.mH =  1.150000000000E+02\n           SM.wH =  3.228000000000E-03\n           SM.mb =  2.900000000000E+00\n           SM.me =  0.000000000000E+00\n           SM.ms =  0.000000000000E+00\n           SM.mc =  0.000000000000E+00\n\\end{Verbatim}\n\\end{scriptsize}\nTo avoid soft-collinear singular phase-space regions, we apply an\ninvariant mass cut on light quark pairs:\n\\begin{code}\ncuts = all M >= 10 GeV [q,Q]\n\\end{code}\nNow, we integrate the signal process as well as the combined signal\nand background processes:\n\\begin{code}\nintegrate (zh) { iterations = 5:5000}\n\nintegrate(nnbb,qqbb,bbbb,eebb,qqtt,bbtt) { iterations = 12:20000 }\n\\end{code}\n\\begin{scriptsize}\n\\begin{Verbatim}[frame=single]\n           | RNG: Initializing TAO random-number generator\n           | RNG: Setting seed for random-number generator to 21791\n           | Initializing integration for process zh:\n           | ------------------------------------------------------------------------\n           | Process [scattering]: 'zh'\n           |   Library name  = 'default_lib'\n           |   Process index = 1\n           |   Process components:\n           |     1: 'zh_i1':   e-, e+ => Z, H [omega]\n           | ------------------------------------------------------------------------\n           | Beam structure: [any particles]\n           | Beam data (collision):\n           |   e-  (mass = 0.0000000E+00 GeV)\n           |   e+  (mass = 0.0000000E+00 GeV)\n           |   sqrts = 2.090000000000E+02 GeV\n           | Phase space: generating configuration ...\n           | Phase space: ... success.\n           | Phase space: writing configuration file 'zh_i1.phs'\n           | Phase space: 1 channels, 2 dimensions\n           | Phase space: found 1 channel, collected in 1 grove.\n           | Phase space: Using 1 equivalence between channels.\n           | Phase space: wood\n           | Applying user-defined cuts.\n           | OpenMP: Using 8 threads\n           | Starting integration for process 'zh'\n           | Integrate: iterations = 5:5000\n           | Integrator: 1 chains, 1 channels, 2 dimensions\n           | Integrator: Using VAMP channel equivalences\n           | Integrator: 5000 initial calls, 20 bins, stratified = T\n           | Integrator: VAMP\n           |=============================================================================|\n           | It      Calls  Integral[fb]  Error[fb]   Err[%]    Acc  Eff[%]   Chi2 N[It] |\n           |=============================================================================|\n              1       4608  1.6114109E+02  5.52E-04    0.00    0.00*  99.43\n              2       4608  1.6114220E+02  5.59E-04    0.00    0.00   99.43\n              3       4608  1.6114103E+02  5.77E-04    0.00    0.00   99.43\n              4       4608  1.6114111E+02  5.74E-04    0.00    0.00*  99.43\n              5       4608  1.6114103E+02  5.66E-04    0.00    0.00*  99.43\n           |-----------------------------------------------------------------------------|\n              5      23040  1.6114130E+02  2.53E-04    0.00    0.00   99.43    0.82   5\n           |=============================================================================|\n           [.....]\n\\end{Verbatim}\n\\end{scriptsize}\n\\begin{figure}\n  \\centering\n  \\includegraphics[width=.48\\textwidth]{lep_higgs_1}\n  \\includegraphics[width=.48\\textwidth]{lep_higgs_2}\n  \\\\\\vspace{5mm}\n  \\includegraphics[width=.48\\textwidth]{lep_higgs_3}\n  \\caption{Upper line: final state $bb + E_{miss}$, histogram of\n    the invisible mass distribution (left), and of the di-$b$\n    distribution (right). Lower plot: light dijet distribution in the\n    $bbjj$ final state.}\n  \\label{fig:lep_higgs}\n\\end{figure}\nBecause the other integrations look rather similar, we refrain from\ndisplaying them here, too. As a next step, we define titles,\ndescriptions and axis labels for the histograms we want to\ngenerate. There are two of them, one os the invisible mass\ndistribution, the other is the di-$b$-jet invariant mass. Both\nhistograms are taking values between 70 and 130 GeV with\nbin widths of half a GeV:\n\\begin{code}\n$description =\n  \"A WHIZARD Example. Light Higgs search at LEP. A 115 GeV pseudo-Higgs\n    has been added. Luminosity enlarged by two orders of magnitude.\"\n$y_label = \"$N_{\\textrm{events}}$\"\n\n$title = \"Invisible mass distribution in $e^+e^- \\to \\nu\\bar\\nu b \\bar b$\"\n$x_label = \"$M_{\\nu\\nu}$/GeV\"\nhistogram m_invisible (70 GeV, 130 GeV, 0.5 GeV)\n\n$title = \"$bb$ invariant mass distribution in $e^+e^- \\to \\nu\\bar\\nu b \\bar b$\"\n$x_label = \"$M_{b\\bar b}$/GeV\"\nhistogram m_bb (70 GeV, 130 GeV, 0.5 GeV)\n\\end{code}\nThe analysis is initialized by defining the two records for the\ninvisible mass and the invariant mass of the two $b$ jets:\n\\begin{code}\nanalysis = record m_invisible (eval M [n,N]);\n           record m_bb (eval M [b,B])\n\\end{code}\nIn order to have enough statistics, we enlarge the LEP integrated\nluminosity at 209 GeV by more than two orders of magnitude:\n\\begin{code}\nluminosity = 10\n\\end{code}\nWe start event generation by simulating the process with two $b$ jets\nand two neutrinos in the final state:\n\\begin{code}\nsimulate (nnbb)\n\\end{code}\nAs a third histogram, we define the dijet invariant mass of two light\njets:\n\\begin{code}\n$title = \"Dijet invariant mass distribution in $e^+e^- \\to q \\bar q b \\bar b$\"\n$x_label = \"$M_{q\\bar q}$/GeV\"\nhistogram m_jj (70 GeV, 130 GeV, 0.5 GeV)\n\\end{code}\nThen we simulate the 4-jet process defining the light-dijet\ndistribution as a local record:\n\\begin{code}\nsimulate (qqbb) { analysis = record m_jj (eval M / 1 GeV [combine [q,Q]]) }\n\\end{code}\nFinally, we compile the analysis,\n\\begin{code}\ncompile_analysis { $out_file = \"lep_higgs.dat\" }\n\\end{code}\n\\begin{scriptsize}\n\\begin{Verbatim}[frame=single]\n           | Starting simulation for process 'nnbb'\n           | Simulate: using integration grids from file 'nnbb_m1.vg'\n           | RNG: Initializing TAO random-number generator\n           | RNG: Setting seed for random-number generator to 21798\n           | OpenMP: Using 8 threads\n           | Simulation: using n_events as computed from luminosity value\n           | Events: writing to raw file 'nnbb.evx'\n           | Events: generating 1070 unweighted, unpolarized events ...\n           | Events: event normalization mode '1'\n           |         ... event sample complete.\n           Warning: Encountered events with excess weight: 207 events ( 19.346 %)\n           | Maximum excess weight = 1.534E+00\n           | Average excess weight = 4.909E-02\n           | Events: closing raw file 'nnbb.evx'\n           $title = \"Dijet invariant mass distribution in $e^+e^- \\to q \\bar q b \\bar b$\"\n           $x_label = \"$M_{q\\bar q}$/GeV\"\n           | Starting simulation for process 'qqbb'\n           | Simulate: using integration grids from file 'qqbb_m1.vg'\n           | RNG: Initializing TAO random-number generator\n           | RNG: Setting seed for random-number generator to 21799\n           | OpenMP: Using 8 threads\n           | Simulation: using n_events as computed from luminosity value\n           | Events: writing to raw file 'qqbb.evx'\n           | Events: generating 4607 unweighted, unpolarized events ...\n           | Events: event normalization mode '1'\n           |         ... event sample complete.\n           Warning: Encountered events with excess weight: 112 events (  2.431 %)\n           | Maximum excess weight = 8.875E-01\n           | Average excess weight = 4.030E-03\n           | Events: closing raw file 'qqbb.evx'\n           $out_file = \"lep_higgs.dat\"\n           | Opening file 'lep_higgs.dat' for output\n           | Writing analysis data to file 'lep_higgs.dat'\n           | Closing file 'lep_higgs.dat' for output\n           | Compiling analysis results display in 'lep_higgs.tex'\n\\end{Verbatim}\n\\end{scriptsize}\nThe graphical analysis of the events generated by \\whizard\\ are shown\nin Fig.~\\ref{fig:lep_higgs}. In the upper left, the invisible mass\ndistribution in the $b\\bar b + E_{miss}$ state is shown, peaking\naround the $Z$ mass. The upper right shows the $M(b\\bar b)$\ndistribution in the same final state, while the lower plot has the\ninvariant mass distribution of the two non-$b$-tagged (light) jets in\nthe $bbjj$ final state. The latter shows only the $Z$\npeak, while the former exhibits the narrow would-be 115 GeV Higgs\nstate.\n\n%%%%%%%%%%%%%%%\n\n\\section{Deep Inelastic Scattering at HERA}\n\n%%%%%%%%%%%%%%%\n\n\\section{$W$ endpoint at LHC}\n\n%%%%%%%%%%%%%%%\n\n\\section{SUSY Cascades at LHC}\n\n%%%%%%%%%%%%%%%\n\n\\section{Polarized $WW$ at ILC}\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n\\chapter{Technical details -- Advanced Spells}\n\\label{chap:tuning}\n\n\\section{Efficiency and tuning}\n\nSince massless fermions and vector bosons (or almost massless states\nin a certain approximation) lead to restrictive selection rules for\nallowed helicity combinations in the initial and final state. To make\nuse of this fact for the efficiency of the \\whizard\\ program, we are\napplying some sort of heuristics: \\whizard\\ dices events into all\ncombinatorially possible helicity configuration during a warm-up\nphase. The user can specify a helicity threshold which sets the number\nof zeros \\whizard\\ should have got back from a specific helicity\ncombination in order to ignore that combination from now on. By that\nmechanism, typically half up to more than three quarters of all\nhelicity combinations are discarded (and hence the corresponding\nnumber of matrix element calls). This reduces calculation time up to\nmore than one order of magnitude. \\whizard\\ shows at the end of the\nintegration those helicity combinations which finally contributed to\nthe process matrix element.\n\nNote that this list -- due to the numerical heuristics -- might very\nwell depend on the number of calls for the matrix elements per\niteration, and also on the corresponding random number seed.\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n\\chapter{New External Physics Models}\n\\label{chap:extmodels}\n\nIt is never possible to include all incarnations of physics models that\ncan be described by the maybe weirdest form of a quantum field theory\nin a tailor-made implementation within a program like \\whizard. Users\nclearly want to be able to use their own special type of model; in\norder to do so there are external tools to translate models described\nby their field content and Lagrangian densities into Feynman rules and\nmake them available in an event generator like \\whizard. In this\nchapter, we describe the interfaces to two such external models,\n\\sarah\\ and \\FeynRules.\n\nThe \\FeynRules\\ interface had been started already for the legacy\nversion \\whizard\\ttt{1} (where it had to be downloaded from\n\\url{https://whizard.hepforge.org} as a separate package), but\nfor the \\whizard\\ttt{two} release series it has been included in the\n\\FeynRules\\ package (from their version v1.6.0 on). Note that there\nwas a regression for the usage of external models (from either \\sarah\\\nor \\FeynRules) in the first release of series v2.2, v2.2.0. This has\nbeen fixed in all upcoming versions.\n\nBesides using \\sarah\\ or \\FeynRules\\ via their interfaces, there is\nnow a much easier way to let those programs output model files in the\n\"Universal FeynRules Output\" (or \\UFO). This option does not have any\nprinciple limitations for models, and also does not rely on the never\ntruly constant interfaces between two different tools. Their usage is\ndescribed in Sec.~\\ref{sec:ufo}.\n\n%%%%%%%%%%%%%%%\n\n\\section{New physics models via \\sarah}\n\\sarah~\\cite{Staub:2008uz,Staub:2009bi,Staub:2010jh,Staub:2012pb,Staub:2013tta}\nis a \\Mathematica~\\cite{mathematica} package which\nderives for a given model the\nminimum conditions of the vacuum, the mass matrices, and vertices at tree-level\nas well as expressions for the one-loop corrections for all masses and the\nfull two-loop renormalization group equations (RGEs). The vertices can be exported\nto be used with \\whizard/\\oMega. All other information can be used to generate\n\\fortran\\ source code for the RGE solution tool and spectrum generator\n\\spheno~\\cite{Porod:2003um,Porod:2011nf}  to get a spectrum generator\nfor any model. The\nadvantage is that \\spheno\\ calculates a consistent set of parameters (couplings,\nmasses, rotation matrices, decay widths) which can be used as input for \\whizard.\n\\sarah\\ and \\spheno\\ can be also downloaded from the \\ttt{HepForge} server:\n\\begin{center}\n\\url{https://sarah.hepforge.org} \\\\\n\\url{https://spheno.hepforge.org}\n\\end{center}\n\n\n\\subsection{\\whizard/\\oMega\\ model files from \\sarah}\n\n\\subsubsection{Generating the model files}\n\nHere we are giving only the information relevant to generate models\nfor \\whizard. For more details about the installation of \\sarah\\ and\nan exhaustion documentation about its usage, confer the \\sarah\\\nmanual.\n\nTo generate the model files for \\whizard/\\oMega\\ with \\sarah, a\nnew \\Mathematica\\ session has to be started. \\sarah\\ is loaded via\n\\begin{code}\n<<SARAH-4.2.1/SARAH.m;\n\\end{code}\nif \\sarah\\ has been stored in the applications directory of\n\\Mathematica. Otherwise, the full path has to be given\n\\begin{code}\n<<[Path_to_SARAH]/SARAH.m;\n\\end{code}\nTo get an overview which models are delivered with \\sarah, the command \\verb\"ShowModels\"\ncan be used. As an example, we use in the following the triplet\nextended MSSM (TMSSM) and initialize it in \\sarah\\ via\n\\begin{code}\nStart[\"TMSSM\"];\n\\end{code}\nFinally, the output intended for \\whizard/\\oMega\\ is started via\n\\begin{code}\nMakeWHIZARD[Options]\n\\end{code}\nThe possible options of the \\verb\"MakeWHIZARD\" command are\n\\begin{enumerate}\n  \\item \\verb\"WriteOmega\", with values: \\verb\"True\" or \\verb\"False\", default:\n    \\verb\"True\" \\\\\n    Defines if the model files for \\oMega\\ should be written\n  \\item \\verb\"WriteWHIZARD\", with values: \\verb\"True\" or \\verb\"False\",\n    default: \\verb\"True\" \\\\\n    Defines if the model files for \\whizard\\ should be written\n  \\item \\verb\"Exclude\", with values: list of generic type, Default:\n    \\verb\"{SSSS}\" \\\\\n    Defines which generic vertices are {\\em not} exported to the model\n    file\n  \\item \\verb\"WOModelName\", with values: string, default: name of the\n    model in \\sarah\\ followed by \\verb\"_sarah\"  \\\\\n    Gives the possibility to change the model name\n  \\item \\verb\"MaximalCouplingsPerFile\", with values: integer, default:\n    \\ttt{150} \\\\\n    Defines the maximal number of couplings written per file\n  \\item \\verb\"Version\", with values: formatted number, Default:\n    \\verb\"2.2.1\"~\\footnote{Due to a regression in \\whizard\\ version\n      v2.2.0, \\sarah\\ models cannot be successfully linked within\n      that version. Hence, the default value here has been set to\n      version number 2.2.1}, \\\\\n    Defines the version of \\whizard\\ for which the model file is generated\n\\end{enumerate}\nAll options and the default values are also shown in the\n\\Mathematica\\ session via \\newline\\verb\"Options[MakeWHIZARD]\".\n\n\\subsubsection{Using the generated model files with \\whizard}\n\nAfter the interface has completed evaluation, the generated files can\nbe found in the subdirectory \\verb\"WHIZARD_Omega\" of {\\sarah}s output\ndirectory. In order to use it the generated code must be compiled and\ninstalled. For this purpose, open a terminal, enter the output directory\n\\begin{code}\n<PATH_to_SARAH>/Output/TMSSM/EWSB/WHIZARD_Omega/\n\\end{code}\nand run\n%\n\\begin{code}\n./configure\nmake install\n\\end{code}\n%\nBy default, the last command installs the compiled model into \\verb\".whizard\"\nin current user's home directory where it is automatically picked up by\n\\whizard. Alternative installation paths can be specified using the\n\\verb\"--prefix\" option to \\whizard.\n%\n\\begin{code}\n./configure --prefix=/path/to/installation/prefix\n\\end{code}\n%\nIf the files are installed into the \\whizard\\\ninstallation prefix, the program will also pick them up automatically, while\n{\\whizard}'s \\verb\"--localprefix\" option must be used to communicate any other\nchoice to \\whizard. In case \\whizard\\ is not available in the binary search\npath, the \\verb\"WO_CONFIG\" environment variable can be used to point\n\\verb\"configure\" to the binaries\n%\n\\begin{code}\n./configure WO_CONFIG=/path/to/whizard/binaries\n\\end{code}\n%\nMore information on the available options and their syntax can be obtained with\nthe\n\\verb\"--help\" option.\n\nAfter the model is compiled it can be used in \\whizard\\ as\n\\begin{code}\nmodel = tmssm_sarah\n\\end{code}\n\n\n\n\\subsection{Linking \\spheno\\ and \\whizard}\nAs mentioned above, the user can also use \\spheno\\ to generate spectra\nfor its models. This is done by means of \\fortran\\ code for \\spheno,\nexported from \\sarah.  To do so, the user has to apply the command\n\\verb\"MakeSPheno[]\". For more details\nabout the options of this command and how to compile and use the \\spheno\\ output,\nwe refer to the \\sarah\\ manual. \\\\\nAs soon as the \\spheno\\ version for the given model is ready it can be used to\ngenerate files with all necessary numerical values for the parameters in a format\nwhich is understood by \\whizard. For this purpose, the corresponding flag in the\nLes Houches input file of \\spheno\\ has to be turned on:\n\\begin{code}\nBlock SPhenoInput   # SPheno specific input\n...\n75 1               # Write WHIZARD files\n\\end{code}\nAfterwards, \\spheno\\ returns not only the spectrum file in the\nstandard SUSY Les Houches accord (SLHA) format (for more details about\nthe SLHA and the \\whizard\\ SLHA interface cf. Sec.~\\ref{sec:slha}),\nbut also an additional file called \\verb\"WHIZARD.par.TMSSM\" for our example.\nThis file can be used\nin the \\sindarin\\ input file via\n\\begin{code}\ninclude (\"WHIZARD.par.TMSSM\")\n\\end{code}\n\n%%%%%\n\n\\subsection{BSM Toolbox}\n\nA convenient way to install \\sarah\\ together with \\whizard, \\spheno\\\nand some  other codes are the \\ttt{BSM Toolbox} scripts\n\\footnote{Those script have been published\nunder the name SUSY Toolbox but \\sarah\\ is with version 4 no longer\nrestricted to SUSY models}~\\cite{Staub:2011dp}. These scripts are\navailable at\n\\begin{center}\n \\url{https://sarah.hepforge.org/Toolbox.html}\n\\end{center}\nThe \\ttt{Toolbox} provides two scripts. First, the \\verb\"configure\" script is\nused via\n\\begin{code}\ntoolbox-src-dir> mkdir build\ntoolbox-src-dir> cd build\ntoolbox-src-dir> ../configure\n\\end{code}\n%\nThe  \\verb\"configure\" script checks for the requirements of the\ndifferent packages and downloads all codes. All downloaded archives will\nbe placed in the \\verb\"tarballs\" subdirectory of the directory containing the\n\\verb\"configure\" script.\nCommand line options can be used to disable specific packages and to point the\nscript to custom locations of compilers and of the \\Mathematica\\ kernel; a full\nlist of those can be obtained by calling \\verb\"configure\" with the \\verb\"--help\"\noption.\n\nAfter \\verb\"configure\" finishes successfully, \\verb\"make\" can be called to build\nall configured packages\n%\n\\begin{code}\ntoolbox-build-dir> make\n\\end{code}\n\n\\verb\"configure\" creates also the second script which automates the implementation\nof a new model into all packages. The \\verb\"butler\" script takes as argument the\nname of the model in \\sarah, e.g.\n\\begin{code}\n> ./butler TMSSM\n\\end{code}\nThe \\verb\"butler\" script runs \\sarah\\ to get the output in the same\nform as the \\whizard/\\oMega\\\nmodel files and the code for \\spheno. Afterwards, it installs the\nmodel in all packages and compiles the new \\whizard/\\oMega\\ model\nfiles as well as the new \\spheno\\ module.\n\n%%%%%\n\\newpage\n\n\\section{New physics models via \\FeynRules}\n\nIn this section, we present the interface between the external tool\n\\FeynRules\\ \\cite{Christensen:2008py,Christensen:2009jx,Duhr:2011se}\nand \\whizard. \\FeynRules\\ is a\n\\Mathematica~\\cite{mathematica} package that allows to derive\nFeynman rules from any perturbative quantum field theory-based Lagrangian\nin an automated way. It can be downloaded from\n\\begin{center}\n  \\url{http://feynrules.irmp.ucl.ac.be/}\n\\end{center}\nThe input provided by the user is threefold and consists\nof the Lagrangian defining the model, together with the definitions of\nall the\nparticles and parameters that appear in the model.\nOnce this information is provided, \\FeynRules\\ can perform basic checks\non the sanity of the implementation (e.g. hermiticity, normalization\nof the quadratic terms), and finally computes all the interaction\nvertices associated  with the model and store them in an internal\nformat for later processing. After the Feynman rules have been\nobtained, \\FeynRules\\ can export the interaction vertices to \\whizard\\\nvia a dedicated interface~\\cite{Christensen:2010wz}. The interface\nchecks whether all the vertices are compliant with the structures\nsupported by \\whizard's\nmatrix element generator \\oMega, and discard them in the case\nthey are not supported. The output of the interface consists of a set\nof files organized in a single directory which can be injected into\n\\whizard/\\oMega\\ and used as any other built-in models. Together with\nthe model files, a framework is created which allows to communicate\nthe new models to \\whizard\\ in a well defined way, after which\nstep the model can be used exactly like the built-in ones.\nThis specifically means that the user is not required to\nmanually modify the code of \\whizard/\\oMega, the models created by the\ninterface can be used directly without any further user intervention.\nWe first describe the installation and general usage of the interface,\nand then list the general properties like the supported particle\ntypes, color quantum numbers and Lorentz structures as well as types\nof gauge interactions.\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n\\subsection{Installation and Usage of the \\whizard-\\FeynRules\\ interface}\n\\label{sec:interface-usage}\n\n\\paragraph{{\\bf Installation and basic usage:}}\n%\nFrom \\FeynRules\\ version 1.6.0 onward, the interface to \\whizard\\ is\npart of the \\FeynRules\\ distribution\\footnote{Note that though the\n  main interface of \\FeynRules\\ to \\whizard\\ is for the most recent\n  \\whizard\\ release, but also the legacy branch\n  \\whizard\\ttt{1} is supported.}. In addition, the latest version\nof the interface can be downloaded from the \\whizard\\ homepage on\n\\ttt{HepForge}. There you can also find an installer that can be used\nto inject the interface into an existing \\FeynRules\\\ninstallation (which allows to use the interface with the \\FeynRules\\\nrelease series1.4.x where it is not part of the package).\n\nOnce installed, the interface can be called and used in the same way\n\\FeynRules' other interfaces described\nin~\\cite{Christensen:2008py}. The details of how to install and use\n\\FeynRules\\ itself can be found\nthere,~\\cite{Christensen:2008py,Christensen:2009jx,Duhr:2011se}. Here,\nwe only describe how to use the interface to inject new models into\n\\whizard.  For example, once the  \\FeynRules\\ environment has been\ninitialized and a model has been loaded, the command\n\\begin{code}\n  WriteWOOutput[L]\n\\end{code}\nwill call the \\ttt{FeynmanRules} command to extract the Feynman\nrules from the Lagrangian \\ttt{L}, translate them together with the\nmodel data and finally write the files necessary for using the model\nwithin \\whizard\\ to an output directory (the name of which is inferred\nfrom the model name by default). Options can be added for further\ncontrol over the translation process (see\nSec.~\\ref{app:interface-options}). Instead of using a Lagrangian, it\nis also possible to call the interface on a pure vertex list. For\nexample, the following command\n\\begin{code}\n  WriteWOOutput[Input -> list]\n\\end{code}\nwill directly translate the vertex list \\ttt{list}. Note that this\nvertex list must be given in flavor-expanded form in order for the\ninterface to process it correctly.\n\nThe interface also supports the \\ttt{WriteWOExtParams} command\ndescribed in~\\cite{Christensen:2008py}. Issuing\n\\begin{code}\n  WriteWOExtParams[filename]\n\\end{code}\nwill write a list of all the external parameters to\n\\ttt{filename}. This is done in the form of a \\sindarin\\\nscript. The only option accepted by the command above is the target\nversion of \\whizard, set by the option \\ttt{WOWhizardVersion}.\n\nDuring execution, the interface will print out a series of\nmessages. It is highly advised to carefully read through this output\nas it not only summarizes the settings and the location of the output\nfiles, but also contains information on any skipped vertices or\npotential incompatibilities of the model with \\whizard.\n\nAfter the interface has run successfully and written the model files to the\noutput directory, the model must be imported into \\whizard. For doing\nso, the model files have to be compiled and can then be installed\nindependently of \\whizard. In the simplest scenario, assuming that the\noutput directory is the current working directory and that the\n\\whizard\\ binaries can be found in the current \\ttt{\\$\\{PATH\\}},\nthe installation is performed by simply executing\n\\begin{code}\n./configure~\\&\\&~make clean~\\&\\&~make install\n\\end{code}\n\nThis will compile the model and install it into the directory\n\\ttt{\\$\\{HOME\\}/.whizard}, making it fully available to \\whizard\\\nwithout any further intervention. The build system can be adapted to\nmore complicated cases through several options to the\n\\ttt{configure} which are listed in the \\ttt{INSTALL} file\ncreated in the output directory. A detailed explanation of all options\ncan be found in Sec.~\\ref{app:interface-options}.\n\n\\paragraph{\\bf Supported fields and vertices:}\n\nThe following fields are currently supported by the interface:\nscalars, Dirac and Majorana fermions, vectors and symmetric tensors.\nThe set of accepted operators, the full list of which can be found in\nTab.~\\ref{tab-operators}, is a subset of all the operators supported\nby \\oMega. While still limited, this list is sufficient for a large\nnumber of BSM models. In addition, a future version of\n\\whizard/\\oMega\\ will support the definition of completely general\nLorentz structures in the model, allowing the interface to\ntranslate all interactions handled by \\FeynRules. This will be done by\nmeans of a parser within \\oMega\\ of the \\ttt{UFO} file format for\nmodel files from \\FeynRules.\n\n\\begin{table*}[!t]\n\\centerline{\\begin{tabular}{|c|c|}\n\\hline Particle spins & Supported Lorentz structures \\\\\\hline\\hline\nFFS & \\parbox{0.7\\textwidth}{\\raggedright\n   All operators of dimension four are supported.\n\\strut}\\\\\\hline\nFFV & \\parbox[t]{0.7\\textwidth}{\\raggedright\n   All operators of dimension four are\n   supported.\n\\strut}\\\\\\hline\nSSS & \\parbox{0.7\\textwidth}{\\raggedright\n   All dimension three interactions are supported.\n\\strut}\\\\\\hline\nSVV & \\parbox[t]{0.7\\textwidth}{\\raggedright\n   Supported operators:\\\\\n   \\mbox{}\\hspace{5ex}$\\begin{aligned}\n      \\text{dimension 3:} & \\quad\\mathcal{O}_3 = V_1^\\mu V_{2\\mu}\\phi \\mbox{}\\\\\n      \\text{dimension 5:} & \\quad\\mathcal{O}_5 = \\phi\n         \\left(\\partial^\\mu V_1^\\nu - \\partial^\\nu V_1^\\mu\\right)\n         \\left(\\partial_\\mu V_{2\\nu} - \\partial_\\nu V_{2\\mu}\\right)\n   \\end{aligned}$\\\\\nNote that $\\mathcal{O}_5$ generates the effective gluon-gluon-Higgs couplings obtained by integrating out heavy quarks.\n\\strut}\\\\\\hline\nSSV & \\parbox[t]{0.7\\textwidth}{\\raggedright\n   $\\left(\\phi_1\\partial^\\mu\\phi_2 - \\phi_2\\partial^\\mu\\phi_1\\right)V_\\mu\\;$\n   type interactions are supported.\n\\strut}\\\\\\hline\nSSVV & \\parbox{0.7\\textwidth}{\\raggedright\n   All dimension four interactions are supported.\n\\strut}\\\\\\hline\nSSSS & \\parbox{0.7\\textwidth}{\\raggedright\n   All dimension four interactions are supported.\n\\strut}\\\\\\hline\nVVV & \\parbox[t]{0.7\\textwidth}{\\raggedright\n   All parity-conserving dimension four operators are supported, with\n   the restriction that non-gauge interactions may be split into\n   several vertices and can only be handled if all three fields are\n   mutually different.\\strut\n\\strut}\\\\\\hline\nVVVV & \\parbox[t]{0.7\\textwidth}{\\raggedright\n   All parity conserving dimension four operators are supported.\n\\strut}\\\\\\hline\nTSS, TVV, TFF & \\parbox[t]{0.7\\textwidth}{\\raggedright\n   The three point couplings in the Appendix of Ref.\\\n   \\cite{Han:1998sg} are supported.\n\\strut}\\\\\\hline\n\\end{tabular}}\n\\caption{All Lorentz structures currently supported by the\n  \\whizard-\\FeynRules\\ interface, sorted with respect to the spins of\n  the particles. ``S'' stands for scalar, ``F'' for fermion (either\n  Majorana or Dirac) and ``V'' for vector.}\n\\label{tab-operators}\n\\end{table*}\n\n\\paragraph{\\bf Color:}\n%\nColor is treated in \\oMega\\ in the color flow decomposition,\nwith the flow structure being implicitly determined from\nthe representations of the particles present at the vertex. Therefore, the\ninterface has to strip the color structure from the vertices derived by\n\\FeynRules\\ before writing them out to the model files.\nWhile this process is straightforward for all color structures which\ncorrespond only to a single flow assignment, vertices with several\npossible flow configurations must be treated with care in order to\navoid mismatches between the flows assigned by \\oMega\\ and those\nactually encoded in the couplings. To this end, the interface derives\nthe color flow decomposition from the color structure determined by\n\\FeynRules\\ and rejects all vertices which would lead to a wrong flow\nassignment by \\oMega\\ (these rejections are accompanied by warnings\nfrom the interface)\\footnote{For the old \\whizard\\ttt{1} legacy\n  branch, there was a maximum number of external color flows that had\n  to explicitly specified. Essentially, this is $n_8 - \\frac{1}{2}n_3$\n  where $n_8$ is the maximum number of external color octets and $n_3$\n  is the maximum number of external triplets and antitriplets. This\n  can be set in the \\whizard/\\FeynRules\\ interface by the\n  \\ttt{WOMaxNcf} command, whose default is \\ttt{4}.}.\n\nAt the moment, the $SU(3)_C$ representations supported by\nboth \\whizard\\ and the interface are singlets ($1$), triplets ($3$),\nantitriplets ($\\bar{3}$) and octets ($8$). Tab.~\\ref{tab:su3struct}\nshows all combinations of these representations which can\nform singlets together with the support status of the respective color\nstructures in \\whizard\\ and the interface. Although the supported\ncolor structures do not comprise all possible singlets, the list is\nsufficient for a large number of SM extensions. Furthermore, a future\nrevision of \\whizard/\\oMega\\ will allow for explicit color flow\nassignments, thus removing most of the current restrictions.\n\n\\begin{table*}\n\\centerline{\\begin{tabular}{|c|c|}\n\\hline $SU(3)_C$ representations &\n   Support status\n\\\\\\hline\\hline\n\\parbox[t]{0.2\\textwidth}{\n   \\centerline{\\begin{tabular}[t]{lll}\n   $111,\\quad$ & $\\bar{3}31,\\quad$ & $\\bar{3}38,$ \\\\\n   $1111,$ & $\\bar{3}311,$ & $\\bar{3}381$\n   \\end{tabular}}} &\n\\parbox[t]{0.7\\textwidth}{\\raggedright\\strut Fully supported by the interface\\strut}\n\\\\\\hline\n$888,\\quad 8881$ &\n\\parbox{0.7\\textwidth}{\\raggedright\\strut Supported only if at least two of the octets\nare identical particles.\\strut}\n\\\\\\hline\n$881,\\quad 8811$ &\n\\parbox{0.7\\textwidth}{\\raggedright\\strut Fully supported by the\n  interface\\footnote{%\n    Not available in version 1.95 and earlier. Note that in order to\n    use such couplings in 1.96/97, the\n    \\oMega\\ option \\ttt{2g} must be added to the process definition\n    in \\ttt{whizard.prc}.}.\\strut}\n\\\\\\hline\n$\\bar{3}388$ &\n\\parbox{0.7\\textwidth}{\\raggedright\\strut Supported only if the octets\n  are identical\nparticles.\\strut}\n\\\\\\hline\n$8888$ &\n\\parbox{0.7\\textwidth}{\\raggedright\\strut The only supported flow structure is\n\\begin{equation*}\n\\parbox{21mm}{\\includegraphics{flow4}}\\cdot\\;\\Gamma(1,2,3,4)\n   \\quad+\\quad \\text{all acyclic permutations}\n\\end{equation*}\nwhere $\\Gamma(1,2,3,4)$ represents the Lorentz structure associated with the\nfirst flow.\\strut}\n\\\\\\hline\n\\parbox[t]{0.2\\textwidth}{\n   \\centerline{\\begin{tabular}[t]{lll}\n   $333,\\quad$ & $\\bar{3}\\bar{3}\\bar{3},\\quad$ & $3331$\\\\\n   $\\bar{3}\\bar{3}\\bar{3}1,$ & $\\bar{3}\\bar{3}33$\n   \\end{tabular}}} &\n\\parbox[t]{0.7\\textwidth}{\\raggedright\\strut Unsupported (at the\n  moment)\\strut}\n\\\\\\hline\n\\end{tabular}}\n\\caption{All possible combinations of three or four $SU(3)_C$\nrepresentations supported by \\FeynRules\\ which can be used to build singlets,\ntogether with the support status of the corresponding color structures in\n\\whizard\\ and the interface.}\n\\label{tab:su3struct}\n\\end{table*}\n\n\\paragraph{\\bf Running $\\alpha_S$:}\n\nWhile a running strong coupling is fully supported by the interface, a\nchoice has to be made which quantities are to be reevaluated when the\nstrong coupling is evolved. By default \\ttt{aS}, \\ttt{G} (see\nRef.~\\cite{Christensen:2008py} for the nomenclature regarding\nthe QCD coupling) and any vertex factors depending on them are evolved.\nThe list of internal parameters that are to be recalculated (together\nwith the vertex factors depending on them) can be\nextended (beyond \\ttt{aS} and \\ttt{G}) by using\nthe option \\ttt{WORunParameters} when calling the\ninterface~\\footnote{As the legacy branch, \\whizard\\ttt{1}, does not\n  support a running strong coupling, this is also vetoed by the\n  interface when using \\whizard \\ttt{1.x}.}.\n\n\\paragraph{\\bf Gauge choices:}\n\\label{sec:gauge-choices}\n\nThe interface supports the unitarity, Feynman and $R_\\xi$ gauges. The choice of\ngauge must be communicated to the interface via the option \\ttt{WOGauge}.\nNote that massless gauge bosons are always treated in Feynman gauge.\n\nIf the selected gauge is Feynman or $R_\\xi$, the interface can\nautomatically assign the proper masses to the Goldstone bosons. This behavior is\nrequested by using the \\ttt{WOAutoGauge} option. In the $R_\\xi$\ngauges, the symbol representing the gauge $\\xi$ must be communicated to the\ninterface by using the \\ttt{WOGaugeSymbol} option (the symbol is\nautomatically introduced into the list of external\nparameters if \\ttt{WOAutoGauge} is\nselected at the same time). This feature can be used to automatically extend\nmodels implemented in Feynman gauge to the $R_\\xi$ gauges.\n\nSince \\whizard\\ (at least until the release series 2.3) is a\ntree-level tool working with helicity amplitudes, the ghost sector is\nirrelevant for \\whizard\\ and hence dropped by the interface.\n\n\\subsection{Options of the \\whizard-\\FeynRules\\ interface}\n\\label{app:interface-options}\n\nIn the following we present a comprehensive list of all the options accepted by\n\\ttt{WriteWOOutput}. Additionally, we note that all options of the\n\\FeynRules\\ command \\ttt{FeynmanRules} are accepted by\n\\ttt{WriteWOOutput}, which passes them on to \\ttt{FeynmanRules}.\n\n\\begin{description}\n\\item[\\ttt{Input}]\\mbox{}\\\\\nAn optional vertex list to use instead of a Lagrangian (which can then be\nomitted).\n%\n\\item[\\ttt{WOWhizardVersion}]\\mbox{}\\\\\nSelect the \\whizard\\ version for which code is to be generated.\nThe currently available choices are summarized in\nTab.~\\ref{tab-wowhizardversion}.\n%%\n\\begin{table}\n\\centerline{\\begin{tabular}{|l|l|}\n\\hline \\ttt{WOWhizardVersion} & \\whizard\\ versions supported\n\\\\\\hline\\hline\n\\ttt{\"2.0.3\"} (default) & 2.0.3+ \\\\\\hline\n\\ttt{\"2.0\"} & 2.0.0 -- 2.0.2 \\\\\\hline\\hline\n\\ttt{\"1.96\"} & 1.96+ \\qquad (deprecated) \\\\\\hline\n\\ttt{\"1.93\"} & 1.93 -- 1.95 \\qquad (deprecated) \\\\\\hline\n\\ttt{\"1.92\"} & 1.92 \\qquad (deprecated) \\\\\\hline\n\\end{tabular}}\n\\caption{Currently available choices for the \\ttt{WOWhizardVersion} option,\ntogether with the respective \\whizard\\ versions supported by them.}\n\\label{tab-wowhizardversion}\n\\end{table}\n%%\nThis list  will expand as the program evolves. To get a summary\nof all choices available in a particular version of the interface, use\nthe command\n\\ttt{?WOWhizardVersion}.\n%\n\\item[\\ttt{WOModelName}]\\mbox{}\\\\\nThe name under which the model will be known to\n\\whizard\\footnote{For versions 1.9x, model names must start\n  with ``\\ttt{fr\\_}'' if they are to be picked up by \\whizard\\\n  automatically.}. The default is determined from the \\FeynRules\\\nmodel name.\n%\n\\item[\\ttt{Output}]\\mbox{}\\\\\nThe name of the output directory. The default is determined from the\n\\FeynRules\\ model name.\n%\n\\item[\\ttt{WOGauge}]\\mbox{}\\\\\nGauge choice (\\emph{cf.} Sec.~\\ref{sec:gauge-choices}).\nPossible values are: \\ttt{WOUnitarity} (default),\n\\ttt{WOFeynman}, \\ttt{WORxi}\n%\n\\item[\\ttt{WOGaugeParameter}]\\mbox{}\\\\\nThe external or internal parameter representing the gauge $\\xi$ in\nthe $R_\\xi$ gauges (\\emph{cf.} Sec.~\\ref{sec:gauge-choices}). Default:\n\\ttt{Rxi}\n%\n\\item[\\ttt{WOAutoGauge}]\\mbox{}\\\\\nAutomatically assign the Goldstone boson masses in the Feynman and $R_\\xi$\ngauges and automatically append the symbol for $\\xi$ to the parameter list in\nthe $R_\\xi$ gauges. Default: \\ttt{False}\n%\n\\item[\\ttt{WORunParameters}]\\mbox{}\\\\\nThe list of all internal parameters which will be recalculated if $\\alpha_S$ is\nevolved (see above)\\footnote{Not available for versions older than\n  2.0.0}. Default: \\mbox{\\ttt{\\{aS, G\\}}}\n%\n\\item[\\ttt{WOFast}]\\mbox{}\\\\\nIf the interface drops vertices which are supported, this option can be\nset to \\ttt{False} to enable some more time consuming checks which might aid\nthe identification. Default: \\ttt{True}\n%\n\\item[\\ttt{WOMaxCouplingsPerFile}]\\mbox{}\\\\\nThe maximum number of couplings that are written to a single \\fortran\\\nfile. If compilation takes too long or fails, this can be\nlowered. Default: \\ttt{500}\n%\n\\item[\\ttt{WOVerbose}]\\mbox{}\\\\\nEnable verbose output and in particular more extensive information on any\nskipped vertices. Default: \\ttt{False}\n\\end{description}\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n\\subsection{Validation of the interface}\n\nThe output of the interface has been extensively\nvalidated. Specifically, the integrated cross sections for all\npossible $2\\rightarrow 2$ processes in the \\FeynRules\\ SM, the MSSM\nand the Three-Site Higgsless Model have been compared between\n\\whizard, \\madgraph, and \\CalcHep, using the respective \\FeynRules\\\ninterfaces as well as the in-house implementations of these models\n(the Three-Site Higgsless model not being available in \\madgraph).\nAlso, different gauges have been checked for \\whizard\\ and \\CalcHep.\nIn all comparisons, excellent agreement within the Monte Carlo errors\nwas achieved. The detailed comparison including examples of the\ncomparison tables can be found in~\\cite{Christensen:2010wz}.\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n\\subsection{Examples for the \\whizard-/\\FeynRules\\ interface}\n\nHere, we will use the Standard Model, the MSSM and the Three-Site\nHiggsless Model as prime examples to explain the usage of the\ninterface. Those are the models that have been used in the validation\nof the interface in~\\cite{Christensen:2010wz}. The examples are\nconstructed to show the application of the different options of the\ninterface and to serve as a starting point for the generation of the\nuser's own \\whizard\\ versions of other \\FeynRules\\ models.\n\n\\subsubsection{\\whizard-\\FeynRules\\ example: Standard\n  Model}\\label{sec:usageSM}\n\nTo start off, we will create {\\sc Whizard} 2 versions of the Standard\nModel as implemented in \\FeynRules\\ for different gauge choices.\n\n\\paragraph{SM: Unitarity Gauge}\n\nIn order to invoke \\FeynRules, we change to the corresponding\ndirectory and load the program in \\Mathematica\\ via\n\\begin{code}\n$FeynRulesPath =\n     SetDirectory[\"<path-to-FeynRules>\"];\n<<FeynRules`\n\\end{code}\n%$\nThe model is loaded by\n\\begin{code}\nLoadModel[\"Models/SM/SM.fr\"];\nFeynmanGauge = False;\n\\end{code}\nNote that the second line is required to switch the Standard\nModel to Unitarity gauge as opposed to Feynman gauge (which is the default).\nGenerating a \\whizard\\ model is now simply done by\n\\begin{code}\nWriteWOOutput[LSM];\n\\end{code}\nAfter invokation, the interface first gives a short summary of the setup\n\\begin{code}\nShort model name is \"fr_standard_model\"\nGauge: Unitarity\nGenerating code for WHIZARD / O'Mega\n                        version 2.0.3\nMaximum number of couplings per FORTRAN\n                           module: 500\nExtensive lorentz structure checks disabled.\n\\end{code}\n\nNote that, as we have not changed any options, those settings represent the\ndefaults. The output proceeds with the calculation of the Feynman rules from the\nStandard Model Lagrangian \\verb?LSM?. After the rules have been derived, the\ninterface starts generating output and tries to match the vertices to\ntheir \\whizard/\\oMega\\ counterparts.\n\\begin{code}\n   10 of 75 vertices processed...\n   20 of 75 vertices processed...\n   30 of 75 vertices processed...\n   40 of 75 vertices processed...\n   50 of 75 vertices processed...\n   60 of 75 vertices processed...\n   70 of 75 vertices processed...\nprocessed a total of 75 vertices, kept 74\n   of them and threw away 1, 1 of which\n   contained ghosts or goldstone bosons.\n\\end{code}\nThe last line of the above output is particularily interesting, as it informs us\nthat everything worked out correctly: the interface was able to match all\nvertices, and the only discarded vertex was the QCD ghost interaction.\nAfter the interface has finished running, the model files in the output\ndirectory are ready to use and can be compiled using the procedure described in\nthe previous section.\n\n%%%%%\n\n\\paragraph{SM: Feynman and $R_\\xi$ gauges}\n\nAs the Standard Model as implemented in \\FeynRules\\ also supports Feynman\ngauge, we can use the program to generate a Feynman gauge version of the model.\nLoading \\FeynRules\\ and the model proceeds as above, with the only\ndifference being the change\n\\begin{code}\nFeynmanGauge = True;\n\\end{code}\nIn order to inform the interface about the modified gauge, we have to\nadd the option \\verb?WOGauge?\n\\begin{code}\nWriteWOOutput[LSM, WOGauge -> WOFeynman];\n\\end{code}\nThe modified gauge is reflected in the output of the interface\n\\begin{code}\nShort model name is \"fr_standard_model\"\nGauge: Feynman\nGenerating code for WHIZARD / O'Mega\n                        version 2.0.3\nMaximum number of couplings per FORTRAN\n                           module: 500\nExtensive lorentz structure checks disabled.\n\\end{code}\nThe summary of the vertex identification now takes the following form\n\\begin{code}\nprocessed a total of 163 vertices, kept 139\n   of them and threw away 24, 24 of which\n   contained ghosts.\n\\end{code}\nAgain, this line tells us that there were no problems --- the only\ndiscarded interactions involved the ghost sector which is irrelevant\nfor the tree-level part of \\whizard.\n\nFor a tree-level calculation, the only difference between the\ndifferent gauges from the perspective of the interface are the gauge\nboson propagators and the Goldstone boson masses. Therefore, the\ninterface can automatically convert a model in Feynman gauge to a\nmodel in $R_\\xi$ gauge. To this end, the call to the interface must be\nchanged to\n\\begin{code}\nWriteWOOutput[LSM, WOGauge -> WORxi,\n               WOAutoGauge -> True];\n\\end{code}\nThe \\verb?WOAutoGauge? argument instructs the interface to\nautomatically\n\\begin{enumerate}\n\\item Introduce a symbol for the gauge parameter $\\xi$ into the\nlist of external parameters\n\\item Generate the Goldstone boson masses from those of the associated\n  gauge bosons (ignoring the values provided by \\FeynRules)\n\\end{enumerate}\nThe modified setup is again reflected in the interface output\n\\begin{code}\nShort model name is \"fr_standard_model\"\nGauge: Rxi\nGauge symbol: \"Rxi\"\nGenerating code for WHIZARD / O'Mega\n                       version 2.0.3\nMaximum number of couplings per FORTRAN\n                         module: 500\nExtensive lorentz structure checks disabled.\n\\end{code}\nNote the default choice \\verb?Rxi? for the name of the $\\xi$ parameter\n-- this can be modified via the option \\verb?WOGaugeParameter?.\n\nWhile the \\verb?WOAutoGauge? feature allows to generate $R_\\xi$ gauged models\nfrom models implemented in Feynman gauge, it is of course also possible to use\nmodels genuinely implemented in $R_\\xi$ gauge by setting this parameter to\n\\verb?False?. Also, note that the choice of gauge only affects the propagators\nof massive fields. Massless gauge bosons are always treated in Feynman\ngauge.\n\n\\paragraph{Compilation and usage}\n\nIn order to compile and use the freshly generated model files, change to the\noutput directory which can be determined from the interface output (in this\nexample, it is \\verb?fr_standard_model-WO?). Assuming that \\whizard\\ is\navailable in the binary search path, compilation and installation proceeds as\ndescribed above by executing\n\\begin{code}\n./configure && make && make install\n\\end{code}\nThe model is now ready and can be used similarly to the builtin\n\\whizard\\ models. For example, a minimal \\whizard\\ input file for\ncalculating the $e^+e^- \\longrightarrow W^+W^-$ scattering cross\nsection in the freshly generated model would look like\n\\begin{code}\nmodel = fr_standard_model\nprocess test = \"e+\", \"e-\" -> \"W+\", \"W-\"\nsqrts = 500 GeV\nintegrate (test)\n\\end{code}\n\n%%%%%\n\n\\subsubsection{\\whizard/\\FeynRules\\ example: MSSM}\nIn this Section, we illustrate the usage of the interface between {\\sc\nFeynRules} and {\\sc Whizard} in the context of the MSSM. All the\nparameters of the model are then ordered in Les Houches blocks and\ncounters following the SUSY Les Houches Accord (SLHA)\n\\cite{Skands:2003cj,AguilarSaavedra:2005pw,Allanach:2008qq} (cf. also\nSec.~\\ref{sec:slha}).\n\nAfter having downloaded the model\nfrom the \\FeynRules\\ website, we store it in a new directory, labelled\n\\verb\"MSSM\", of the model library of the local installation of\n\\FeynRules. The model can then be loaded in \\Mathematica\\ as in the\ncase of the SM example above\n\\begin{code}\n$FeynRulesPath =\n        SetDirectory[\"<path-to-FeynRules>\"];\n<<FeynRules`\nLoadModel[\"Models/MSSM/MSSM.fr\"];\nFeynmanGauge = False;\n\\end{code}\n%$\nWe are again adopting unitarity gauge.\n\nThe number of vertices associated to supersymmetric Lagrangians is in general\nvery large (several thousands). For such models with many interactions,\nit is recommended to first extract all the Feynman rules of the theory before\ncalling the interface between \\whizard\\ and \\FeynRules.\nThe reason is related to the efficiency of the interface  which takes\na lot of time in the extraction of the interaction vertices. In the\ncase one wishes to study the phenomenology of several benchmark\nscenarios, this procedure, which is illustrated below,\nallows to use the interface in the best way. The Feynman rules\nare derived from the Lagrangian once and for all and then reused by the\ninterface for each set of \\whizard\\ model files to be produced,\nconsiderably  speeding up the generation of multiple model files\nissued from a single Lagrangian. In addition, the scalar potential of\nsupersymmetric theories contains a large set of four scalar\ninteractions, in general irrelevant for collider phenomenology. These\nvertices can be neglected with the help of the\n\\verb\"Exclude4Scalars->True\" option of both interface commands\n\\verb\"FeynmanRules\" and \\verb\"WriteWOOutput\". The Feynman\nrules of the MSSM are then computed within the \\Mathematica\\ notebook\nby\n\\begin{code}\nrules = FeynmanRules[lag,\n   Exclude4Scalars->True, FlavorExpand->True];\n\\end{code}\nwhere \\verb'lag' is the variable containing the Lagrangian.\n\nBy default, all the parameters of the model are set to the value of\n\\ttt{1}. A complete parameter \\ttt{{\\em <slha\\_params>}.dat} file\nmust therefore be loaded. Such a parameter file can be downloaded from\nthe \\FeynRules\\ website or created by hand by the user, and loaded\ninto \\FeynRules\\ as\n\\begin{code}\nReadLHAFile[Input -> \"<slha_params>.dat\"];\n\\end{code}\nThis command does not reduce the size of the model output by removing\nvertices with vanishing couplings.  However, if desired, this task\ncould be done with the  \\ttt{LoadRestriction} command (see Ref.\\\n\\cite{Fuks:2012im} for details).\n\nThe vertices are exported to \\whizard\\ by the command\n\\begin{code}\nWriteWOOutput[Input -> rules];\n\\end{code}\nNote that the numerical values of the parameters of the model can be\nmodified directly from \\whizard, without having to generate a second\ntime the \\whizard\\ model files from \\FeynRules. A \\sindarin\\ script is\ncreated by the interface with the help of the instruction\n\\begin{code}\nWriteWOExtParams[\"parameters.sin\"];\n\\end{code}\nand can be further modified according to the needs of the user.\n\n\\subsubsection{\\whizard-\\FeynRules\\ example: Three-Site Higgsless Model}\n\n\nThe Three-Site Higgsless model or Minimal Higgsless model (MHM) has\nbeen implemented into \\ttt{LanHEP}~\\cite{He:2007ge}, \\FeynRules\\\nand independently into \\whizard~\\cite{Speckner:2010zi},\nand the collider phenomenology has been studied by making use of these\nimplementations \\cite{He:2007ge,Ohl:2010zf,Speckner:2010zi}.\nFurthermore, the independent implementations in \\FeynRules\\ and\ndirectly into {\\sc Whizard} have been compared and found to\nagree~\\cite{Christensen:2010wz}. After the discovery of a Higgs boson\nat the LHC in 2012, such a model is not in good agreement with\nexperimental data any more. Here, we simply use it as a guinea pig to\ndescribe the handling of a model with non-renormalizable interactions\nwith the \\FeynRules\\ interface, and discuss how to generate \\whizard\\\nmodel files for it. The model has been implemented in Feynman gauge as\nwell as unitarity gauge and contains the variable \\verb|FeynmanGauge|\nwhich can be set to \\verb|True|  or \\verb|False|. When set to\n\\verb|True|, the option \\verb|WOGauge-> WOFeynman| must be used, as\nexplained in~\\cite{Christensen:2010wz}. $R_\\xi$ gauge can also be\naccomplished with this model by use of the options\n\\verb|WOGauge -> WORxi| and \\verb?WOAutoGauge -> True?.\n\nSince this model makes use of a nonlinear sigma field of the form\n\\begin{equation}\n\\Sigma = 1 + i\\pi - \\frac{1}{2}\\pi^2+\\cdots\n\\end{equation}\nmany higher dimensional operators are included in the model which are\nnot currently not supported by \\whizard. Even for a future release of\n\\whizard\\ containing general Lorentz structures in interaction\nvertices, the user would be forced to expand the series only up to a\ncertain order. Although \\whizard\\ can reject these vertices\nand print a warning message to the user, it is preferable to remove\nthe vertices right away in the interface by the option\n\\verb|MaxCanonicalDimension->4|. This is passed to the command\n\\verb|FeynmanRules| and restricts the Feynman rules to those of\ndimension four and smaller\\footnote{\\ttt{MaxCanonicalDimension} is an\n  option of the \\ttt{FeynmanRules} function rather than of the\n  interface, itself. In fact, the interface accepts all the options of\n  {\\tt FeynmanRules} and simply passes them on to the latter.}.\n\nAs the use of different gauges was already illustrated in the SM\nexample, we discuss the model only in Feynman gauge here. We load\n\\FeynRules:\n\\begin{code}\n$FeynRulesPath =\n     SetDirectory[\"<path-to-FeynRules>\"];\n<<FeynRules`\n\\end{code}\n%$\nThe MHM model itself is then loaded by\n\\begin{code}\nSetDirectory[\"<path-to-MHM>\"];\nLoadModel[\"3-Site-particles.fr\",\n   \"3-Site-parameters.fr\",\n   \"3-Site-lagrangian.fr\"];\nFeynmanGauge = True;\n\\end{code}\nwhere \\verb|<path-to-MHM>| is the path to the directory where the MHM\nmodel files are stored and where the output of the \\whizard\\\ninterface will be written. The \\whizard\\ interface is then initiated:\n\\begin{code}\nWriteWOOutput[LGauge, LGold, LGhost, LFermion,\n   LGoldLeptons, LGoldQuarks,\n   MaxCanonicalDimension->4,\n   WOGauge->WOFeynman, WOModelName->\"fr_mhm\"];\n\\end{code}\nwhere we have also made use of the option \\verb|WOModelName| to change\nthe name of the model as seen by \\whizard. As in the case of the SM,\nthe interface begins by writing a short informational message:\n\\begin{code}\nShort model name is \"fr_mhm\"\nGauge: Feynman\nGenerating code for WHIZARD / O'Mega\n                       version 2.0.3\nAutomagically assigning Goldstone\n                        boson masses...\nMaximum number of couplings per FORTRAN\n                        module: 500\nExtensive lorentz structure checks disabled.\n\\end{code}\nAfter calculating the Feynman rules and processing the vertices, the\ninterface gives a summary:\n\\begin{code}\nprocessed a total of 922 vertices, kept 633\n  of them and threw away 289, 289 of which\n  contained ghosts.\n\\end{code}\nshowing that no vertices were missed.  The files are stored in the\ndirectory \\verb|fr_mhm| and are ready to be installed and used with\n\\whizard.\n\n%%%%%%%%%%%%%%%\n\n\\section{New physics models via the \\UFO\\ file format}\n\\label{sec:ufo}\n\nIn this section, we describe how to use the {\\em Universal FeynRules\nOutput} (\\UFO, \\cite{Degrande:2011ua}) format for physics models\ninside \\whizard. Please refer the manuals of e.g.~\\FeynRules\\ manual\nfor details on how to generate a \\UFO\\ file for your favorite physics\nmodel. \\UFO\\ files are a collection of \\python\\ scripts that\nencode the particles, the couplings, the Lorentz structures, the\ndecays, as well as parameters, vertices and propagators of the\ncorresponding model. They reside in a directory of the exact name of\nthe model they have been created from.\n\nIf the user wants to generate events for processes from a physics\nmodel from a \\UFO\\ file, then this directory of scripts generated by\n\\FeynRules\\ is immediately available if it is a subdirectory of the working\ndirectory of \\whizard.  The directory name will be taken as the model\nname. (The \\UFO-model file name must not start with a\n  non-letter character, i.e. especially not a number.  In case such a\n  file name wants to be used at all costs, the model name in the\n  \\sindarin\\ script has to put in quotation marks, but this is not\n  guaranteed to always work.)  Then, a \\UFO\\ model named, e.g.,\n\\ttt{test\\_model} is accessed by an extra \\ttt{ufo} tag in the model\nassignment:\n\\begin{Code}\n  model = test_model (ufo)\n\\end{Code}\n\nIf desired, \\whizard\\ can access a directory of \\UFO\\ files elsewhere\non the file system.  For instance, if \\FeynRules\\ output resides in\nthe subdirectory \\ttt{MyMdl} of\n\\ttt{/home/users/john/ufo}, \\whizard\\ can use the model\nnamed \\ttt{MyMdl} as follows\n\\begin{Code}\n  model = MyMdl (ufo ('/home/users/john/my_ufo_models'))\n\\end{Code}\nthat is, the \\sindarin\\ keyword \\ttt{ufo} can take an argument.  Note\nhowever, that the latter approach can backfire --- in case just the working\ndirectory is packed and archived for future reference.\n\n%%%%%%%%%%%%%%%\n\n\n\n\\clearpage\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n\\appendix\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\\chapter{\\sindarin\\ Reference}\n\nIn the \\sindarin\\ language, there are certain pre-defined constructors or\ncommands that cannot be used in different context by the user, which\nare e.g. \\ttt{alias}, \\ttt{beams}, \\ttt{integrate}, \\ttt{simulate} etc.\nA complete list will be given below. Also units are fixed, like\n\\ttt{degree}, \\ttt{eV}, \\ttt{keV},\n\\ttt{MeV}, \\ttt{GeV}, and \\ttt{TeV}. Again, these tags are locked and\nnot user-redefinable. Their functionality will be listed in detail\nbelow, too. Furthermore, a variable with a preceding\nquestion mark, ?, is a logical, while a preceding dollar, \\$, denotes a\ncharacter string variable.  Also, a lot of unary and binary operators\nexist, \\ttt{+ - $\\backslash$ , = : => < > <= >= \\^ \\;  () [] \\{\\} }\n\\url{==}, as well as quotation marks, \". Note that the\ndifferent parentheses and brackets fulfill different purposes, which\nwill be explained below. Comments in a line can either be marked by a\nhash, \\#, or an exclamation mark, !.\n\n\\section{Commands and Operators}\nWe begin the \\sindarin\\ reference with all commands, operators, functions\nand constructors.\nThe list of variables (which can be set to change behavior of \\whizard) can\nbe found in the next section.\n\\begin{itemize}\n\\item\n\\ttt{+} \\newline\n1) Arithmetic operator for addition of integers, reals and complex\nnumbers. Example: \\ttt{real mm = mH + mZ} (cf. also \\ttt{-}, \\ttt{*},\n\\ttt{/}, \\ttt{\\^{}}). 2) It also adds different particles for inclusive\nprocess containers: \\ttt{process foo = e1, E1 => (e2, E2) + (e3,\n  E3)}. 3) It also serves as a shorthand notation for the\nconcatenation of ($\\to$) \\ttt{combine} operations on\nparticles/subevents, e.g. \\ttt{cuts = any 170 GeV < M < 180 GeV [b +\n  lepton + invisible]}.\n%%%%%\n\\item\n\\ttt{-} \\newline\nArithmetic operator for subtraction of integers, reals and complex\nnumbers. Example: \\ttt{real foo = 3.1 - 5.7} (cf. also \\ttt{+}, \\ttt{*},\n\\ttt{/}, \\ttt{\\^{}}).\n%%%%%\n\\item\n\\ttt{/} \\newline\nArithmetic operator for division of integers, reals and complex\nnumbers. Example: \\ttt{scale = mH / 2} (cf. also \\ttt{+}, \\ttt{*},\n\\ttt{-}, \\ttt{\\^{}}).\n%%%%%\n\\item\n\\ttt{*} \\newline\nArithmetic operator for multiplication of integers, reals and complex\nnumbers. Example: \\ttt{complex z = 2 * I} (cf. also \\ttt{+}, \\ttt{/},\n\\ttt{-}, \\ttt{\\^{}}).\n%%%%%\n\\item\n\\ttt{\\^{}} \\newline\nArithmetic operator for exponentiation of integers, reals and complex\nnumbers. Example: \\ttt{real z = x\\^{}2 + y\\^{}2} (cf. also \\ttt{+},\n\\ttt{/}, \\ttt{-}, \\ttt{\\^{}}).\n%%%%%\n\\item\n\\ttt{<} \\newline\nArithmetic comparator between values that checks for ordering\nof two values: \\ttt{{\\em <val1>} < {\\em <val2>}} tests whether\n\\ttt{{\\em val1}} is smaller than \\ttt{{\\em val2}}. Allowed for\ninteger and real values. Note that this is an exact comparison if\n\\ttt{tolerance} is set to zero. For a finite value of \\ttt{tolerance}\nit is a ``fuzzy'' comparison. (cf. also \\ttt{tolerance}, \\ttt{<>},\n\\ttt{==}, \\ttt{>}, \\ttt{>=}, \\ttt{<=})\n%%%%%\n\\item\n\\ttt{>} \\newline\nArithmetic comparator between values that checks for ordering\nof two values: \\ttt{{\\em <val1>} > {\\em <val2>}} tests whether\n\\ttt{{\\em val1}} is larger than \\ttt{{\\em val2}}. Allowed for\ninteger and real values. Note that this is an exact comparison if\n\\ttt{tolerance} is set to zero. For a finite value of \\ttt{tolerance}\nit is a ``fuzzy'' comparison. (cf. also \\ttt{tolerance}, \\ttt{<>},\n\\ttt{==}, \\ttt{>}, \\ttt{>=}, \\ttt{<=})\n%%%%%\n\\item\n\\ttt{<=} \\newline\nArithmetic comparator between values that checks for ordering\nof two values: \\ttt{{\\em <val1>} <= {\\em <val2>}} tests whether\n\\ttt{{\\em val1}} is smaller than or equal \\ttt{{\\em val2}}. Allowed for\ninteger and real values. Note that this is an exact comparison if\n\\ttt{tolerance} is set to zero. For a finite value of \\ttt{tolerance}\nit is a ``fuzzy'' comparison. (cf. also \\ttt{tolerance}, \\ttt{<>},\n\\ttt{==}, \\ttt{>}, \\ttt{<}, \\ttt{>=})\n%%%%%\n\\item\n\\ttt{>=} \\newline\nArithmetic comparator between values that checks for ordering\nof two values: \\ttt{{\\em <val1>} >= {\\em <val2>}} tests whether\n\\ttt{{\\em val1}} is larger than or equal \\ttt{{\\em val2}}. Allowed for\ninteger and real values. Note that this is an exact comparison if\n\\ttt{tolerance} is set to zero. For a finite value of \\ttt{tolerance}\nit is a ``fuzzy'' comparison. (cf. also \\ttt{tolerance}, \\ttt{<>},\n\\ttt{==}, \\ttt{>}, \\ttt{<}, \\ttt{>=})\n%%%%%\n\\item\n\\ttt{==} \\newline\nArithmetic comparator between values that checks for identity\nof two values: \\ttt{{\\em <val1>} == {\\em <val2>}}. Allowed for\ninteger and real values. Note that this is an exact comparison if\n\\ttt{tolerance} is set to zero. For a finite value of \\ttt{tolerance}\nit is a ``fuzzy'' comparison. (cf. also \\ttt{tolerance}, \\ttt{<>},\n\\ttt{>}, \\ttt{<}, \\ttt{>=}, \\ttt{<=})\n%%%%%\n\\item\n\\ttt{<>} \\newline\nArithmetic comparator between values that checks for\ntwo values being unequal: \\ttt{{\\em <val1>} <> {\\em <val2>}}. Allowed for\ninteger and real values. Note that this is an exact comparison if\n\\ttt{tolerance} is set to zero. For a finite value of \\ttt{tolerance}\nit is a ``fuzzy'' comparison. (cf. also \\ttt{tolerance}, \\ttt{==},\n\\ttt{>}, \\ttt{<}, \\ttt{>=}, \\ttt{<=})\n%%%%%\n\\item\n\\ttt{!} \\newline\nThe exclamation mark tells \\sindarin\\ that everything that follows in\nthat line should be treated as a comment. It is the same as ($\\to$)\n\\ttt{\\#}.\n%%%%%\n\\item\n\\ttt{\\#} \\newline\nThe hash tells \\sindarin\\ that everything that follows in\nthat line should be treated as a comment. It is the same as ($\\to$)\n\\ttt{!}.\n%%%%%\n\\item\n\\ttt{\\&} \\newline\nConcatenates two or more particle lists/subevents and hence acts in\nthe same way as the subevent function ($\\to$) \\ttt{join}: \\ttt{let\n@visible = [photon] \\& [colored] \\& [lepton] in ...}. (cf. also\n\\ttt{join}, \\ttt{combine}, \\ttt{collect}, \\ttt{extract}, \\ttt{sort}).\n%%%%%\n\\item\n\\ttt{\\$} \\newline\nConstructor at the beginning of a variable name,\n\\ttt{\\${\\em <string\\_var>}}, that specifies a string variable.\n%%%%%\n\\item\n\\ttt{@} \\newline\nConstructor at the beginning of a variable name, \\ttt{@{\\em\n<subevt\\_var>}}, that specifies a subevent variable, e.g. \\ttt{let\n@W\\_candidates = combine [\"mu-\", \"numubar\"] in ...}.\n%%%%%\n\\item\n\\ttt{=} \\newline\nBinary constructor to appoint values to commands, e.g. \\ttt{{\\em <command>}\n  = {\\em <expr>}} or \\newline \\ttt{{\\em <command>} {\\em <var\\_name>} =\n  {\\em <expr>}}.\n%%%%%\n\\item\n\\ttt{\\%} \\newline\nConstructor that gives the percentage of a number, so in\nprinciple multiplies a real number by \\ttt{0.01}. Example: \\ttt{1.23\n  \\%} is equal to \\ttt{0.0123}.\n%%%%%\n\\item\n\\ttt{:} \\newline\nSeparator in alias expressions for particles, e.g. \\ttt{alias neutrino\n  = n1:n2:n3:N1:N2:N3}. (cf. also \\ttt{alias})\n%%%%%\n\\item\n\\ttt{;} \\newline\nConcatenation operator for logical expressions: \\ttt{{\\em lexpr1} ;\n  {\\em lexpr2}}. Evaluates \\ttt{{\\em lexpr1}} and throws the result\naway, then evaluates \\ttt{{\\em lexpr2}} and returns that result. Used\nin analysis expressions. (cf. also \\ttt{analysis}, \\ttt{record})\n%%%%%\n\\item\n\\ttt{/+} \\newline\nIncrementor for ($\\to$) \\ttt{scan} ranges, that increments additively,\n\\ttt{scan {\\em <num\\_spec> <num>} = ({\\em <lower val>} => {\\em <upper\n    val>} /+ {\\em <step\nsize>})}. E.g. \\ttt{scan int i = (1 => 5 /+ 2)} scans over the values \\ttt{1},\n\\ttt{3}, \\ttt{5}. For real ranges, it divides the interval between\nupper and lower bound into as many intervals as the incrementor\nprovides, e.g. \\ttt{scan real r = (1 => 1.5 /+ 0.2)} runs over\n\\ttt{1.0}, \\ttt{1.333}, \\ttt{1.667}, \\ttt{1.5}.\n%%%%%\n\\item\n\\ttt{/+/} \\newline\nIncrementor for ($\\to$) \\ttt{scan} ranges, that increments additively,\nbut the number after the incrementor is the number of steps, not the\nstep size: \\ttt{scan {\\em <num\\_spec> <num>} = ({\\em <lower val>} =>\n  {\\em <upper val>}\n/+/ {\\em <steps>})}. It is only available for real scan ranges, and divides\nthe interval \\ttt{{\\em <upper val>} - {\\em <lower val>}} into\n\\ttt{{\\em <steps>}} steps,\ne.g. \\ttt{scan real r = (1 => 1.5 /+/ 3)} runs over \\ttt{1.0},\n\\ttt{1.25}, \\ttt{1.5}.\n%%%%%\n\\item\n\\ttt{/-} \\newline\nIncrementor for ($\\to$) \\ttt{scan} ranges, that increments subtractively,\n\\ttt{scan {\\em <num\\_spec>} {\\em <num>} = ({\\em <lower val>} => {\\em <upper val>} /- {\\em <step\nsize>})}. E.g. \\ttt{scan int i = (9 => 0 /+ 3)} scans over the values \\ttt{9},\n\\ttt{6}, \\ttt{3}, \\ttt{0}. For real ranges, it divides the interval\nbetween upper and lower bound into as many intervals as the incrementor\nprovides, e.g. \\ttt{scan real r = (1 => 0.5 /- 0.2)} runs over\n\\ttt{1.0}, \\ttt{0.833}, \\ttt{0.667}, \\ttt{0.5}.\n%%%%%\n\\item\n\\ttt{/*} \\newline\nIncrementor for ($\\to$) \\ttt{scan} ranges, that increments multiplicatively,\n\\ttt{scan {\\em <num\\_spec>} {\\em <num>} = ({\\em <lower val>} => {\\em <upper val>} /* {\\em <step\nsize>})}. E.g. \\ttt{scan int i = (1 => 4 /* 2)} scans over the values \\ttt{1},\n\\ttt{2}, \\ttt{4}. For real ranges, it divides the interval\nbetween upper and lower bound into as many intervals as the incrementor\nprovides, e.g. \\ttt{scan real r = (1 => 5 /* 2)} runs over\n\\ttt{1.0}, \\ttt{2.236} (i.e. $\\sqrt{5}$), \\ttt{5.0}.\n%%%%%\n\\item\n\\ttt{/*/} \\newline\nIncrementor for ($\\to$) \\ttt{scan} ranges, that increments multiplicatively,\nbut the number after the incrementor is the number of steps, not the\nstep size: \\ttt{scan {\\em <num\\_spec>} {\\em <num>} = ({\\em <lower val>} => {\\em <upper val>}\n/*/ {\\em <steps>})}. It is only available for real scan ranges, and divides\nthe interval \\ttt{{\\em <upper val>} - {\\em <lower val>}} into \\ttt{{\\em <steps>}} steps,\ne.g. \\ttt{scan real r = (1 => 9 /*/ 4)} runs over \\ttt{1.000},\n\\ttt{2.080}, \\ttt{4.327}, \\ttt{9.000}.\n%%%%%\n\\item\n\\ttt{//} \\newline\nIncrementor for ($\\to$) \\ttt{scan} ranges, that increments by division,\n\\ttt{scan {\\em <num\\_spec>} {\\em <num>} = ({\\em <lower val>} => {\\em <upper val>} // {\\em <step\nsize>})}. E.g. \\ttt{scan int i = (13 => 0 // 3)} scans over the values \\ttt{13},\n\\ttt{4}, \\ttt{1}, \\ttt{0}. For real ranges, it divides the interval\nbetween upper and lower bound into as many intervals as the incrementor\nprovides, e.g. \\ttt{scan real r = (5 => 1 // 2)} runs over\n\\ttt{5.0}, \\ttt{2.236} (i.e. $\\sqrt{5}$), \\ttt{1.0}.\n%%%%%\n\\item\n\\ttt{=>} \\newline\nBinary operator that is used in several different contexts: 1) in\nprocess declarations between the particles specifying the\ninitial and final state, e.g. \\ttt{process {\\em <proc\\_name>} = {\\em <in1>}, {\\em <in2>}\n=> {\\em <out1>}, ....}; 2) for the specification of beams when\nstructure functions are applied to the beam particles, e.g. \\ttt{beams\n= p, p => pdf\\_builtin}; 3) for the specification of the scan range in\nthe \\ttt{scan {\\em <var>} {\\em <var\\_name>} = ({\\em <scan\\_start>} => {\\em <scan\\_end>}\n  {\\em <incrementor>})} (cf. also \\ttt{process}, \\ttt{beams}, \\ttt{scan})\n%%%%%\n\\item\n\\ttt{\\%d} \\newline\nFormat specifier in analogy to the \\ttt{C} language for the print out\non screen by the ($\\to$) \\ttt{printf} or into strings by the ($\\to$)\n\\ttt{sprintf} command. It is used for decimal integer numbers,\ne.g. \\ttt{printf \"one = \\%d\" (i)}. The difference between \\ttt{\\%i}\nand \\ttt{\\%d} does not play a role here. (cf. also \\ttt{printf}, \\ttt{sprintf},\n\\ttt{\\%i}, \\ttt{\\%e}, \\ttt{\\%f}, \\ttt{\\%g}, \\ttt{\\%E}, \\ttt{\\%F},\n\\ttt{\\%G}, \\ttt{\\%s})\n%%%%%\n\\item\n\\ttt{\\%e} \\newline\nFormat specifier in analogy to the \\ttt{C} language for the print out\non screen by the ($\\to$) \\ttt{printf} or into strings by the ($\\to$)\n\\ttt{sprintf} command. It is used for floating-point numbers in\nstandard form \\ttt{[-]d.ddd e[+/-]ddd}. Usage e.g. \\ttt{printf \"pi =\n\\%e\" (PI)}.  (cf. also \\ttt{printf}, \\ttt{sprintf},\n\\ttt{\\%d}, \\ttt{\\%i}, \\ttt{\\%f}, \\ttt{\\%g}, \\ttt{\\%E}, \\ttt{\\%F},\n\\ttt{\\%G}, \\ttt{\\%s})\n%%%%%\n\\item\n\\ttt{\\%E} \\newline\nSame as ($\\to$) \\ttt{\\%e}, but using upper-case letters.  (cf. also\n\\ttt{printf}, \\ttt{sprintf}, \\ttt{\\%d}, \\ttt{\\%i}, \\ttt{\\%e}, \\ttt{\\%f},\n\\ttt{\\%g}, \\ttt{\\%F}, \\ttt{\\%G}, \\ttt{\\%s})\n%%%%%\n\\item\n\\ttt{\\%f} \\newline\nFormat specifier in analogy to the \\ttt{C} language for the print out\non screen by the ($\\to$) \\ttt{printf} or into strings by the ($\\to$)\n\\ttt{sprintf} command. It is used for floating-point numbers in\nfixed-point form. Usage e.g. \\ttt{printf \"pi =\n\\%f\" (PI)}.  (cf. also \\ttt{printf}, \\ttt{sprintf},\n\\ttt{\\%d}, \\ttt{\\%i}, \\ttt{\\%e}, \\ttt{\\%g}, \\ttt{\\%E}, \\ttt{\\%F},\n\\ttt{\\%G}, \\ttt{\\%s})\n%%%%%\n\\item\n\\ttt{\\%F} \\newline\nSame as ($\\to$) \\ttt{\\%f}, but using upper-case letters.  (cf. also\n\\ttt{printf}, \\ttt{sprintf}, \\ttt{\\%d}, \\ttt{\\%i}, \\ttt{\\%e}, \\ttt{\\%f},\n\\ttt{\\%g}, \\ttt{\\%E}, \\ttt{\\%G}, \\ttt{\\%s})\n%%%%%\n\\item\n\\ttt{\\%g} \\newline\nFormat specifier in analogy to the \\ttt{C} language for the print out\non screen by the ($\\to$) \\ttt{printf} or into strings by the ($\\to$)\n\\ttt{sprintf} command. It is used for floating-point numbers in\nnormal or exponential notation, whichever is more approriate. Usage\ne.g. \\ttt{printf \"pi = \\%g\" (PI)}.  (cf. also \\ttt{printf}, \\ttt{sprintf},\n\\ttt{\\%d}, \\ttt{\\%i}, \\ttt{\\%e}, \\ttt{\\%f}, \\ttt{\\%E}, \\ttt{\\%F},\n\\ttt{\\%G}, \\ttt{\\%s})\n%%%%%\n\\item\n\\ttt{\\%G} \\newline\nSame as ($\\to$) \\ttt{\\%g}, but using upper-case letters.  (cf. also\n\\ttt{printf}, \\ttt{sprintf}, \\ttt{\\%d}, \\ttt{\\%i}, \\ttt{\\%e}, \\ttt{\\%f},\n\\ttt{\\%g}, \\ttt{\\%E}, \\ttt{\\%F}, \\ttt{\\%s})\n%%%%%\n\\item\n\\ttt{\\%i} \\newline\nFormat specifier in analogy to the \\ttt{C} language for the print out\non screen by the ($\\to$) \\ttt{printf} or into strings by the ($\\to$)\n\\ttt{sprintf} command. It is used for integer numbers,\ne.g. \\ttt{printf \"one = \\%i\" (i)}. The difference between \\ttt{\\%i}\nand \\ttt{\\%d} does not play a role here. (cf. \\ttt{printf}, \\ttt{sprintf},\n\\ttt{\\%d}, \\ttt{\\%e}, \\ttt{\\%f}, \\ttt{\\%g}, \\ttt{\\%E}, \\ttt{\\%F},\n\\ttt{\\%G}, \\ttt{\\%s})\n%%%%%\n\\item\n\\ttt{\\%s} \\newline\nFormat specifier in analogy to the \\ttt{C} language for the print out\non screen by the ($\\to$) \\ttt{printf} or into strings by the ($\\to$)\n\\ttt{sprintf} command. It is used for logical or string variables\ne.g. \\ttt{printf \"foo = \\%s\" (\\$method)}. (cf. \\ttt{printf}, \\ttt{sprintf},\n\\ttt{\\%d}, \\ttt{\\%i}, \\ttt{\\%e}, \\ttt{\\%f}, \\ttt{\\%g}, \\ttt{\\%E}, \\ttt{\\%F},\n\\ttt{\\%G})\n%%%%%\n\\item\n\\ttt{abarn} \\newline\nPhysical unit, stating that a number is in attobarns ($10^{-18}$\nbarn). (cf. also \\ttt{nbarn}, \\ttt{fbarn}, \\ttt{pbarn})\n%%%%%\n\\item\n\\ttt{abs} \\newline\nNumerical function that takes the absolute value of its argument:\n\\ttt{abs ({\\em <num\\_val>})} yields \\ttt{|{\\em\n<num\\_val>}|}. (cf. also \\ttt{conjg}, \\ttt{sgn}, \\ttt{mod}, \\ttt{modulo})\n%%%%%\n\\item\n\\ttt{acos} \\newline\nNumerical function \\ttt{asin ({\\em <num\\_val>})} that calculates the\narccosine trigonometric function (inverse of \\ttt{cos}) of real and\ncomplex numerical numbers or variables. (cf. also \\ttt{sin},\n\\ttt{cos}, \\ttt{tan}, \\ttt{asin}, \\ttt{atan})\n%%%%%\n\\item\n\\ttt{alias} \\newline\nThis allows to define a collective expression for a class of\nparticles, e.g. to define a generic expression for leptons, neutrinos\nor a jet as \\ttt{alias lepton = e1:e2:e3:E1:E2:E3}, \\ttt{alias\nneutrino = n1:n2:n3:N1:N2:N3}, and \\ttt{alias jet =\nu:d:s:c:U:D:S:C:g}, respectively.\n%%%%%\n\\item\n\\ttt{all} \\newline\n\\ttt{all} is a function that works on a logical expression and a list,\n\\ttt{all {\\em <log\\_expr>} [{\\em <list>}]}, and returns \\ttt{true} if and only if\n\\ttt{log\\_expr} is fulfilled for {\\em all} entries in \\ttt{list}, and\n\\ttt{false} otherwise. Examples: \\ttt{all Pt > 100 GeV [lepton]}\nchecks whether all leptons are harder than 100 GeV, \\ttt{all Dist > 2\n  [u:U, d:D]} checks whether all pairs of corresponding quarks\nare separated in $R$ space by more than 2. Logical expressions with\n\\ttt{all} can be logically combined with \\ttt{and} and\n\\ttt{or}. (cf. also \\ttt{any}, \\ttt{and}, \\ttt{no}, and \\ttt{or})\n%%%%%\n\\item\n\\ttt{alt\\_setup} \\newline\nThis command allows to specify alternative setups for a process/list\nof processes, \\ttt{alt\\_setup = \\{ {\\em <setup1>} \\} [, \\{ {\\em <setup2>} \\} ,\n  ...]}. An alternative setup can be a resetting of a coupling\nconstant, or different cuts etc. It can be particularly used in a\n($\\to$) \\ttt{rescan} procedure.\n%%%%%\n\\item\n\\ttt{analysis} \\newline\nThis command, \\ttt{analysis = {\\em <log\\_expr>}}, allows to define an\nanalysis as a logical expression, with a syntax similar to the ($\\to$)\n\\ttt{cuts} or ($\\to$) \\ttt{selection} command. Note that a ($\\to$)\nformally is a logical expression.\n%%%%%\n\\item\n\\ttt{and} \\newline\nThis is the standard two-place logical connective that has the value\ntrue if both of its operands are true, otherwise a value of false. It\nis applied to logical values, e.g. cut expressions. (cf. also\n\\ttt{all}, \\ttt{no}, \\ttt{or}).\n%%%%%\n\\item\n\\ttt{any} \\newline\n\\ttt{any} is a function that works on a logical expression and a list,\n\\ttt{any {\\em <log\\_expr>} [{\\em <list>}]}, and returns \\ttt{true} if\n\\ttt{log\\_expr} is fulfilled for any entry in \\ttt{list}, and\n\\ttt{false} otherwise. Examples: \\ttt{any PDG == 13 [lepton]} checks\nwhether any lepton is a muon, \\ttt{any E > 2 * mW [jet]} checks\nwhether any jet has an energy of twice the $W$ mass. Logical\nexpressions with \\ttt{any} can be logically combined with \\ttt{and}\nand \\ttt{or}. (cf. also \\ttt{all}, \\ttt{and}, \\ttt{no}, and \\ttt{or})\n%%%%%\n\\item\n\\ttt{as} \\newline\ncf. \\ttt{compile}\n%%%%%\n\\item\n\\ttt{ascii} \\newline\nSpecifier for the \\ttt{sample\\_format} command to demand the\ngeneration of the standard \\whizard\\ verbose/debug ASCII event\nfiles. (cf. also \\ttt{\\$sample}, \\ttt{\\$sample\\_normalization},\n\\ttt{sample\\_format})\n%%%%%\n\\item\n\\ttt{asin} \\newline\nNumerical function \\ttt{asin ({\\em <num\\_val>})} that calculates the\narcsine trigonometric function (inverse of \\ttt{sin}) of real and\ncomplex numerical numbers or variables. (cf. also \\ttt{sin},\n\\ttt{cos}, \\ttt{tan}, \\ttt{acos}, \\ttt{atan})\n%%%%%\n\\item\n\\ttt{atan} \\newline\nNumerical function \\ttt{atan ({\\em <num\\_val>})} that calculates the\narctangent trigonometric function (inverse of \\ttt{tan}) of real and\ncomplex numerical numbers or variables. (cf. also \\ttt{sin},\n\\ttt{cos}, \\ttt{tan}, \\ttt{asin}, \\ttt{acos})\n%%%%%\n\\item\n\\ttt{athena} \\newline\nSpecifier for the \\ttt{sample\\_format} command to demand the\ngeneration of the ATHENA variant for HEPEVT ASCII event\nfiles. (cf. also \\ttt{\\$sample}, \\ttt{\\$sample\\_normalization},\n\\ttt{sample\\_format})\n%%%%%\n\\item\n\\ttt{beam} \\newline\nConstructor that specifies a particle (in a subevent) as beam particle. It is\nused in cuts, analyses or selections, e.g. \\ttt{cuts = all Theta > 20\ndegree [beam lepton, lepton]}. (cf. also \\ttt{incoming}, \\ttt{outgoing},\n\\ttt{cuts}, \\ttt{analysis}, \\ttt{selection}, \\ttt{record})\n%%%%%\n\\item\n\\ttt{beam\\_events} \\newline\nBeam structure specifier to read in lepton collider beamstrahlung's\nspectra from external files as pairs of energy fractions: \\ttt{beams:\n  e1, E1 => beam\\_events}. Note that this is a pair spectrum that has to\nbe applied to both beams simultaneously. (cf. also \\ttt{beams},\n\\ttt{\\$beam\\_events\\_file}, \\ttt{?beam\\_events\\_warn\\_eof})\n%%%%%\n\\item\n\\ttt{beams} \\newline\nThis specifies the contents and structure of the beams: \\ttt{beams =\n  {\\em <prt1>}, {\\em <prt2>} [ => {\\em <str\\_fun1>} ....]}. If this\ncommand is absent in the input file, \\whizard\\ automatically takes the\ntwo incoming partons (or one for decays) of the corresponding process\nas beam particles, and no structure functions are applied. Protons and\nantiprotons as beam particles are predefined as \\ttt{p} and\n\\ttt{pbar}, respectively. A structure function, like \\ttt{pdf\\_builtin},\n\\ttt{ISR}, \\ttt{EPA} and so on are switched on as e.g. \\ttt{beams = p,\np => lhapdf}. Structure functions can be specified for one of the two\nbeam particles only, of the structure function is not a\nspectrum. (cf. also \\ttt{beams\\_momentum}, \\ttt{beams\\_theta},\n\\ttt{beams\\_phi}, \\ttt{beams\\_pol\\_density},\n\\ttt{beams\\_pol\\_fraction}, \\ttt{beam\\_events}, \\ttt{circe1},\n\\ttt{circe2}, \\ttt{energy\\_scan}, \\ttt{epa}, \\ttt{ewa}, \\ttt{isr},\n\\ttt{lhapdf}, \\ttt{pdf\\_builtin}).\n%%%%%\n\\item\n\\ttt{beams\\_momentum} \\newline\nCommand to set the momenta (or energies) for the two beams of a\nscattering process: \\ttt{beams\\_momentum = {\\em <mom1>}, {\\em <mom2>}} to allow\nfor asymmetric beam setups (e.g. HERA: \\ttt{beams\\_momentum = 27.5\n  GeV, 920 GeV}). Two arguments must be present\nfor a scattering process, but the command can be used with one\nargument to integrate and simulate a decay of a moving\nparticle. (cf. also \\ttt{beams}, \\ttt{beams\\_theta},\n\\ttt{beams\\_phi}, \\ttt{beams\\_pol\\_density},\n\\ttt{beams\\_pol\\_fraction})\n%%%%%\n\\item\n\\ttt{beams\\_phi} \\newline\nSame as ($\\to$) \\ttt{beams\\_theta}, but to allow for a non-vanishing\nbeam azimuth angle, too. (cf. also \\ttt{beams}, \\ttt{beams\\_theta},\n\\ttt{beams\\_momentum}, \\ttt{beams\\_pol\\_density},\n\\ttt{beams\\_pol\\_fraction})\n%%%%%\n\\item\n\\ttt{beams\\_pol\\_density} \\newline\nThis command allows to specify the initial state for polarized beams\nby the syntax: \\ttt{beams\\_pol\\_density = @({\\em <pol\\_spec\\_1>}),\n  @({\\em <pol\\_spec\\_2>})}. Two polarization specifiers are mandatory for\nscattering, while one can be used for decays from polarized\nprobes. The specifier \\ttt{{\\em <pol\\_spec\\_i>}} can be empty (no\npolarization), has one entry (for a definite helicity/spin\norientation), or ranges of entries of a spin density matrix. The\ncommand can be used globally, or as a local argument of the\n\\ttt{integrate} command. For detailed information, see\nSec.~\\ref{sec:initialpolarization}. It is also possible to use\nvariables as placeholders in the specifiers. Note that polarization is\nassumed to be complete, for partial polarization use ($\\to$)\n\\ttt{beams\\_pol\\_fraction}. (cf. also \\ttt{beams}, \\ttt{beams\\_theta},\n\\ttt{beams\\_phi}, \\ttt{beams\\_momentum}, \\ttt{beams\\_pol\\_fraction})\n%%%%%\n\\item\n\\ttt{beams\\_pol\\_fraction} \\newline\nThis command allows to specify the amount of polarization when using\npolarized beams ($\\to$ \\ttt{beams\\_pol\\_density}). The syntax is:\n\\ttt{beams\\_pol\\_fraction = {\\em <frac\\_1>}, {\\em <frac\\_2>}}. Two fractions must\nbe present for scatterings, being real numbers between \\ttt{0} and\n\\ttt{1}. A specification with percentage is also possible,\ne.g. \\ttt{beams\\_pol\\_fraction = 80\\%, 40\\%}. (cf. also \\ttt{beams},\n\\ttt{beams\\_theta}, \\ttt{beams\\_phi}, \\ttt{beams\\_momentum},\n\\ttt{beams\\_pol\\_density})\n%%%%%\n\\item\n\\ttt{beams\\_theta} \\newline\nCommand to set a crossing angle (with respect to the $z$ axis) for one\nor both of the beams of a\nscattering process: \\ttt{beams\\_theta = {\\em <angle1>}, {\\em <angle2>}} to allow\nfor asymmetric beam setups (e.g. \\ttt{beams\\_angle = 0, 10\ndegree}). Two arguments must be present for a scattering process, but\nthe command can be used with one argument to integrate and simulate a\ndecay of a moving particle. (cf. also \\ttt{beams}, \\ttt{beams\\_phi},\n\\ttt{beams\\_momentum}, \\ttt{beams\\_pol\\_density},\n\\ttt{beams\\_pol\\_fraction})\n%%%%%\n\\item\n\\ttt{by} \\newline\nConstructor that replaces the default sorting criterion (according to\nPDG codes) of the ($\\to$) \\ttt{sort} function on particle\nlists/subevents by one given by a unary or binary particle observable:\n\\ttt{sort by {\\em <observable>} [{\\em <particles>} [, {\\em\n<ref\\_particles>}] ]}. (cf. also \\ttt{sort}, \\ttt{extract}, \\ttt{join},\n\\ttt{collect}, \\ttt{combine}, \\ttt{+})\n%%%%%\n\\item\n\\ttt{ceiling} \\newline\nThis is a function \\ttt{ceiling ({\\em <num\\_val>})} that gives the\nleast integer greater than or equal to \\ttt{{\\em <num\\_val>}},\ne.g. \\ttt{int i = ceiling (4.56789)} gives \\ttt{i = 5}. (cf. also\n\\ttt{int}, \\ttt{nint}, \\ttt{floor})\n%%%%%\n\\item\n\\ttt{circe1} \\newline\nBeam structure specifier for the \\circeone\\ structure function for\nbeamstrahlung at a linear lepton collider: \\ttt{beams = e1, E1 =>\ncirce1}. Note that this is a pair spectrum, so the specifier acts for\nboth beams simultaneously. (cf. also \\ttt{beams}, \\ttt{?circe1\\_photons},\n\\ttt{?circe1\\_photon2}, \\ttt{circe1\\_sqrts},\n\\ttt{?circe1\\_generate}, \\ttt{?circe1\\_map},\n\\ttt{circe1\\_eps}, \\newline \\ttt{circe1\\_mapping\\_slope}, \\ttt{circe1\\_ver},\n\\ttt{circe1\\_rev}, \\ttt{\\$circe1\\_acc}, \\ttt{circe1\\_chat})\n%%%%%\n\\item\n\\ttt{circe2} \\newline\nBeam structure specifier for the lepton-collider structure function\nfor photon spectra, \\circetwo: \\ttt{beams = A, A => circe2}. Note that\nthis is a pair spectrum, an application to only one beam is not\npossible. (cf. also \\ttt{beams}, \\ttt{?circe2\\_polarized},\n\\ttt{\\$circe2\\_file}, \\ttt{\\$circe2\\_design})\n%%%%%\n\\item\n\\ttt{clear} \\newline\nThis command allows to clear a variable set before: \\ttt{clear\n({\\em <clearable var.>})} resets the variable \\ttt{{\\em <clearable var.>}} which\ncould be the \\ttt{beams}, the \\ttt{unstable} settings, \\ttt{sqrts},\nany kind of \\ttt{cuts} or \\ttt{scale} expressions, any user-set\nvariable etc. The syntax of the command is completely analogous to\n($\\to$) \\ttt{show}.\n%%%%%\n\\item\n\\ttt{close\\_out} \\newline\nWith the command, \\ttt{close\\_out (\"{\\em <out\\_file\">})} user-defined\ninformation like data or ($\\to$) \\ttt{printf} statements can be\nwritten out to a user-defined file. The command closes an I/O stream to\nan external file \\ttt{{\\em <out\\_file>}}. (cf. also \\ttt{open\\_out},\n\\ttt{\\$out\\_file}, \\ttt{printf})\n%%%%%\n\\item\n\\ttt{cluster} \\newline\nCommand that allows to cluster all particles in a subevent to a set of\njets: \\ttt{cluster [{\\em<particles>}]}. It also to cluster particles\nsubject to a certain boolean condition, \\ttt{cluster if\n  {\\em<condition>} [{\\em<particles>}]}. At the moment only available\nif the \\fastjet\\ package is linked.\n(cf. also \\ttt{jet\\_r}, \\ttt{combine}, \\ttt{jet\\_algorithm},\n\\ttt{kt\\_algorithm}, \\newline \\ttt{cambridge\\_[for\\_passive\\_]algorithm},\n\\ttt{antikt\\_algorithm}, \\ttt{plugin\\_algorithm}, \\newline\n\\ttt{genkt\\_[for\\_passive\\_]algorithm},\n\\ttt{ee\\_kt\\_algorithm}, \\ttt{ee\\_genkt\\_algorithm},\n\\ttt{?keep\\_flavors\\_when\\_clustering})\n%%%%%\n\\item\n\\ttt{collect} \\newline\nThe \\ttt{collect [{\\em <list>}]} operation collects all particles in\nthe list \\ttt{{\\em <list>}} into a one-entry subevent with a\nfour-momentum of the sum of all four-momenta of non-overlapping\nparticles in \\ttt{{\\em <list>}}. (cf. also \\ttt{combine},\n\\ttt{select}, \\ttt{extract}, \\ttt{sort})\n%%%%%\n\\item\n\\ttt{complex} \\newline\nDefines a complex variable. The syntax is e.g. \\ttt{complex x = 2 + 3\n  * I}. (cf.~also \\ttt{int}, \\ttt{real})\n%%%%%\n\\item\n\\ttt{combine} \\newline\nThe \\ttt{combine [{\\em <list1>}, {\\em <list2>}]} operation makes a particle list\nwhose entries are the result of adding (the momenta of) each pair of\nparticles in the two input lists \\ttt{list1}, {list2}. For example,\n\\ttt{combine [incoming lepton, lepton]} constructs all mutual pairings\nof an incoming lepton with an outgoing lepton (an alias for the\nleptons has to be defined, of course). (cf. also \\ttt{collect},\n\\ttt{select}, \\ttt{extract}, \\ttt{sort}, \\ttt{+})\n%%%%%\n\\item\n\\ttt{compile} \\newline\nThe \\ttt{compile ()} command has no arguments (the parentheses can\nalso been left out: /\\ttt{compile ()}. The command is optional, it\ninvokes the compilation of the process(es) (i.e. the matrix element\nfile(s)) to be compiled as a shared library. This shared object file\nhas the standard name \\ttt{default\\_lib.so} and resides in the\n\\ttt{.libs} subdirectory of the corresponding user workspace. If the\nuser has defined a different library name \\ttt{lib\\_name} with the\n\\ttt{library} command, then WHIZARD compiles this as the shared object\n\\ttt{.libs/lib\\_name.so}. (This allows to split process classes and to\navoid too large libraries.)\nAnother possibility is to use the command \\ttt{compile as\n  \"static\\_name\"}. This will compile and link the process library in a\nstatic way and create the static executable \\ttt{static\\_name} in the\nuser workspace. (cf. also \\ttt{library})\n%%%%%\n\\item\n\\ttt{compile\\_analysis} \\newline\nThe \\ttt{compile\\_analysis} statement does the same as\nthe \\ttt{write\\_analysis} command, namely to tell \\whizard\\ to write\nthe analysis setup by the user for the \\sindarin\\ input file under\nconsideration. If no \\ttt{\\$out\\_file} is provided, the histogram\ntables/plot data etc. are written to the default file\n\\ttt{whizard\\_analysis.dat}. In addition to \\ttt{write\\_analysis},\n\\ttt{compile\\_analysis} also invokes the \\whizard\\ \\LaTeX routines for\nproducing postscript or PDF output of the data (unless the flag\n$\\rightarrow$ \\ttt{?analysis\\_file\\_only} is set to \\ttt{true}).\n(cf. also \\ttt{\\$out\\_file}, \\ttt{write\\_analysis},\n\\ttt{?analysis\\_file\\_only})\n%%%%%\n\\item\n\\ttt{conjg} \\newline\nNumerical function that takes the complex conjugate of its argument:\n\\ttt{conjg ({\\em <num\\_val>})} yields \\ttt{{\\em\n<num\\_val>}$^\\ast$}. (cf. also \\ttt{abs}, \\ttt{sgn}, \\ttt{mod}, \\ttt{modulo})\n%%%%%\n\\item\n\\ttt{cos} \\newline\nNumerical function \\ttt{cos ({\\em <num\\_val>})} that calculates the\ncosine trigonometric function of real and complex numerical numbers or\nvariables. (cf. also \\ttt{sin}, \\ttt{tan}, \\ttt{asin}, \\ttt{acos},\n\\ttt{atan})\n%%%%%\n\\item\n\\ttt{cosh} \\newline\nNumerical function \\ttt{cosh ({\\em <num\\_val>})} that calculates the\nhyperbolic cosine function of real and complex numerical numbers or\nvariables. Note that its inverse function is part of the\n\\ttt{Fortran2008} status and hence not realized. (cf. also \\ttt{sinh},\n\\ttt{tanh})\n%%%%%\n\\item\n\\ttt{count} \\newline\nSubevent function that counts the number of particles or particle\npairs in a subevent: \\ttt{count [{\\em <particles\\_1>} [, {\\em\n<particles\\_2>}]]}. This can also be a counting subject to a\ncondition: \\ttt{count if {\\em <condition>} [{\\em <particles\\_1>} [,\n{\\em <particles\\_2>}]]}.\n%%%%%\n\\item\n\\ttt{cuts} \\newline\nThis command defines the cuts to be applied to certain processes. The\nsyntax is: \\ttt{cuts = {\\em <log\\_class>} {\\em <log\\_expr>} [{\\em <unary or binary\n  particle (list) arg>}]}, where the cut expression must be initialized\nwith a logical classifier \\ttt{log\\_class} like \\ttt{all}, \\ttt{any},\n\\ttt{no}. The logical expression \\ttt{log\\_expr} contains the cut to\nbe evaluated. Note that this need not only be a kinematical cut\nexpression like \\ttt{E > 10  GeV} or \\ttt{5 degree < Theta < 175 degree},\nbut can also be some sort of trigger expression or event selection.\nWhether the expression is evaluated on particles or pairs\nof particles depends on whether the discriminating variable is unary or\nbinary, \\ttt{Dist} being obviously binary, \\ttt{Pt} being unary. Note that\nsome variables are both unary and binary, e.g. the invariant mass $M$. Cut\nexpressions can be connected by the logical  connectives \\ttt{and} and\n\\ttt{or}. The \\ttt{cuts} statement acts on all subsequent process\nintegrations and analyses until a new \\ttt{cuts} statement appears.\n(cf. also \\ttt{all}, \\ttt{any},\n\\ttt{Dist}, \\ttt{E}, \\ttt{M},\n\\ttt{no}, \\ttt{Pt}).\n%%%%%\n\\item\n\\ttt{debug} \\newline\nSpecifier for the \\ttt{sample\\_format} command to demand the\ngeneration of the very verbose \\whizard\\ ASCII event\nfile format intended for debugging. (cf. also \\ttt{\\$sample},\n\\ttt{sample\\_format}, \\ttt{\\$sample\\_normalization})\n%%%%%\n\\item\n\\ttt{degree} \\newline\nExpression specifying the physical unit of degree for angular\nvariables, e.g. the cut expression function \\ttt{Theta}. (if no unit is\nspecified for angular variables, radians are used; cf. \\ttt{rad}, \\ttt{mrad}).\n%%%%\n\\item\n\\ttt{Dist} \\newline\nBinary observable specifier, that gives the $\\eta$-$\\phi$-\n(pseudorapidity-azimuth) distance $R = \\sqrt{(\\Delta \\eta)^2 +\n(\\Delta\\phi)^2}$ between the momenta of the two particles: \\ttt{eval\nDist [jet, jet]}. (cf. also \\ttt{eval}, \\ttt{cuts}, \\ttt{selection},\n\\ttt{Theta}, \\ttt{Eta}, \\ttt{Phi})\n%%%%%\n\\item\n\\ttt{dump} \\newline\nSpecifier for the \\ttt{sample\\_format} command to demand the\ngeneration of the intrinsic \\whizard\\ event record format\n(output of the \\ttt{particle\\_t} type container). (cf. also\n\\ttt{\\$sample}, \\ttt{sample\\_format}, \\ttt{\\$sample\\_normalization}\n%%%%%\n\\item\n\\ttt{E} \\newline\nUnary (binary) observable specifier for the energy of a single\n(two) particle(s), e.g. \\ttt{eval E [\"W+\"]}, \\ttt{all E > 200 GeV [b,\n  B]}. (cf. \\ttt{eval}, \\ttt{cuts}, \\ttt{selection})\n%%%%%\n\\item\n\\ttt{else} \\label{sindarin_else}\\newline\nConstructor for providing an alternative in a conditional clause:\n\\ttt{if {\\em <log\\_expr>} then {\\em <expr 1>} else {\\em <expr 2>} endif}. (cf. also\n\\ttt{if}, \\ttt{elsif}, \\ttt{endif}, \\ttt{then}).\n%%%%%\n\\item\n\\ttt{elsif} \\newline\nConstructor for concatenating more than one conditional clause with\neach other: \\ttt{if {\\em <log\\_expr 1>} then {\\em <expr 1>} elsif {\\em <log\\_expr 2>}\nthen {\\em <expr 2>} \\ldots endif}. (cf. also \\ttt{if}, \\ttt{else},\n\\ttt{endif}, \\ttt{then}).\n%%%%%\n\\item\n\\ttt{endif} \\newline\nMandatory constructor to conclude a conditional clause: \\ttt{if\n  {\\em <log\\_expr>} then \\ldots endif}. (cf. also \\ttt{if},\n\\ttt{else}, \\ttt{elsif}, \\ttt{then}).\n%%%%%\n\\item\n\\ttt{energy\\_scan} \\newline\nBeam structure specifier for the energy scan structure function:\n\\ttt{beams = e1, E1 => energy\\_scan}. This pair spectrum that has to\nbe applied to both beams simultaneously can be used to scan over a\nrange of collider energies without using the \\ttt{scan} command.\n(cf. also \\ttt{beams}, \\ttt{scan}, \\ttt{?energy\\_scan\\_normalize})\n%%%%%\n\\item\n\\ttt{epa} \\newline\nBeam structure specifier for the equivalent-photon approximation\n(EPA), i.e the Weizs\\\"acker-Williams structure function:\ne.g. \\ttt{beams = e1, E1 => epa} (applied to both beams), or\ne.g. \\ttt{beams = e1, u => epa, none} (applied to only one\nbeam). (cf. also \\ttt{beams}, \\ttt{epa\\_alpha}, \\ttt{epa\\_x\\_min},\n\\ttt{epa\\_mass}, \\ttt{epa\\_q\\_max}, \\ttt{epa\\_q\\_min},\n\\ttt{?epa\\_recoil}, \\ttt{?epa\\_keep\\_energy})\n%%%%%\n\\item\n\\ttt{Eta} \\newline\nUnary and also binary observable specifier, that as a unary observable\ngives the pseudorapidity of a particle momentum. The pseudorapidity is\ngiven by $\\eta = - \\log \\left[ \\tan (\\theta/2) \\right]$, where\n$\\theta$ is the angle with the beam direction. As a binary\nobservable, it gives the pseudorapidity difference between the momenta\nof two particles, where $\\theta$ is the enclosed angle: \\ttt{eval Eta\n[e1]},  \\ttt{all abs (Eta) < 3.5 [jet, jet]}. (cf. also \\ttt{eval},\n\\ttt{cuts}, \\ttt{selection}, \\ttt{Rap}, \\ttt{abs})\n%%%%%\n\\item\n\\ttt{eV} \\newline\nPhysical unit, stating that the corresponding number is in electron\nvolt. (cf. also \\ttt{keV}, \\ttt{meV}, \\ttt{MeV}, \\ttt{GeV}, \\ttt{TeV})\n%%%%%\n\\item\n\\ttt{eval} \\newline\nEvaluator that tells \\whizard\\ to evaluate the following expr:\n\\ttt{eval {\\em <expr>}}. Examples are: \\ttt{eval Rap [e1]}, \\ttt{eval\n  M / 1 GeV [combine [q,Q]]} etc. (cf. also \\ttt{cuts},\n\\ttt{selection}, \\ttt{record})\n%%%%%\n\\item\n\\ttt{ewa} \\newline\nBeam structure specifier for the equivalent-photon approximation\n(EWA): e.g. \\ttt{beams = e1, E1 => ewa} (applied to both beams), or\ne.g. \\ttt{beams = e1, u => ewa, none} (applied to only one\nbeam). (cf. also \\ttt{beams}, \\ttt{ewa\\_x\\_min}, \\ttt{ewa\\_pt\\_max},\n\\ttt{ewa\\_mass}, \\ttt{?ewa\\_keep\\_energy},\n\\ttt{?ewa\\_recoil})\n%%%%%\n\\item\n\\ttt{exec} \\newline\nConstructor \\ttt{exec (\"{\\em <cmd\\_name>}\")} that demands WHIZARD to\nexecute/run the command \\ttt{cmd\\_name}. For this to work that\nspecific command must be present either in the path of the operating\nsystem or as a command in the user workspace.\n%%%%%\n\\item\n\\ttt{exit} \\newline\nCommand to finish the \\whizard\\ run (and not execute any further code\nbeyond the appearance of \\ttt{exit} in the \\sindarin\\ file. The command\n(which is the same as $\\to$ \\ttt{quit}) allows for an argument,\n\\ttt{exit ({\\em <expr>})}, where the expression can be executed, e.g. a\nscreen message or an exit code.\n%%%%%\n\\item\n\\ttt{exp} \\newline\nNumerical function \\ttt{exp ({\\em <num\\_val>})} that calculates the\nexponential of real and complex numerical numbers or\nvariables. (cf. also \\ttt{sqrt}, \\ttt{log}, \\ttt{log10})\n%%%%%\n\\item\n\\ttt{expect} \\newline\nThe binary function \\ttt{expect} compares two numerical expressions\nwhether they fulfill a certain ordering condition or are equal up\nto a specific uncertainty or tolerance which can bet set by the\nspecifier \\ttt{tolerance}, i.e. in principle it checks whether a\nlogical expression is true. The \\ttt{expect} function does actually\nnot just check a value for correctness, but also records its result.\nIf failures are present when the program terminates, the exit code is\nnonzero. The syntax is  \\ttt{expect ({\\em <num1>} {\\em\n<log\\_comp>} {\\em <num2>})}, where \\ttt{{\\em <num1>}} and\n\\ttt{{\\em <num2>}} are two numerical values (or\ncorresponding variables) and  \\ttt{{\\em <log\\_comp>}} is one of the following\nlogical comparators: \\ttt{<}, \\ttt{>}, \\ttt{<=},  \\ttt{>=}, \\ttt{==},\n\\ttt{<>}.\n(cf. also \\ttt{<}, \\ttt{>}, \\ttt{<=},  \\ttt{>=}, \\ttt{==}, \\ttt{<>},\n\\ttt{tolerance}).\n%%%%%\n\\item\n\\ttt{extract} \\newline\nSubevent function that either extracts the first element of a\nparticle list/subevent: \\ttt{extract [ {\\em <particles>}]}, or the\nelement at position \\ttt{<index\\_value>} of the particle list:\n\\ttt{extract {\\em index <index\\_value>} [ {\\em\n    <particles>}]}. Negative index values count from the end of the\nlist. (cf. also \\ttt{sort}, \\ttt{combine},\n\\ttt{collect}, \\ttt{+}, \\ttt{index})\n%%%%%\n\\item\n\\ttt{factorization\\_scale} \\newline\nThis is a command, \\ttt{factorization\\_scale = {\\em <expr>}}, that sets\nthe factorization scale of a process or list of processes. It\noverwrites a possible scale set by the ($\\to$) \\ttt{scale} command.\n\\ttt{{\\em <expr>}} can be any kinematic expression that leads to a result of\nmomentum dimension one, e.g. \\ttt{100 GeV}, \\ttt{eval\nPt [e1]}. (cf. also \\ttt{renormalization\\_scale}).\n%%%%%\n\\item\n\\ttt{false} \\newline\nConstructor stating that a logical expression or variable is false,\ne.g. \\ttt{?{\\em <log\\_var>} = false}. (cf. also \\ttt{true}).\n%%%%%\n\\item\n\\ttt{fbarn} \\newline\nPhysical unit, stating that a number is in femtobarns ($10^{-15}$\nbarn). (cf. also \\ttt{nbarn}, \\ttt{abarn}, \\ttt{pbarn})\n%%%%%\n\\item\n\\ttt{floor} \\newline\nThis is a function \\ttt{floor ({\\em <num\\_val>})} that gives the\ngreatest integer less than or equal to \\ttt{{\\em <num\\_val>}},\ne.g. \\ttt{int i = floor (4.56789)} gives \\ttt{i = 4}. (cf. also\n\\ttt{int}, \\ttt{nint}, \\ttt{ceiling})\n%%%%%\n\\item\n\\ttt{gaussian} \\newline\nBeam structure specifier that imposes a Gaussian energy distribution,\nseparately for each beam.  The $\\sigma$ values are set by\n\\ttt{gaussian\\_spread1} and \\ttt{gaussian\\_spread2}, respectively.\n%%%%%\n\\item\n\\ttt{GeV} \\newline\nPhysical unit, energies in $10^9$ electron volt. This is the default\nenergy unit of WHIZARD. (cf. also \\ttt{eV}, \\ttt{keV}, \\ttt{MeV}, \\ttt{meV},\n\\ttt{TeV})\n%%%%%\n\\item\n\\ttt{graph} \\newline\nThis command defines the necessary information regarding producing\na graph of a function in \\whizard's internal graphical \\gamelan\\\noutput. The syntax is: \\ttt{graph {\\em <record\\_name>} \\{ {\\em <optional\narguments>} \\}}. The record with name \\ttt{{\\em <record\\_name>}} has to be\ndefined, either before or after the graph definition. Possible optional\narguments of the \\ttt{graph} command are the minimal and maximal values\nof the axes (\\ttt{x\\_min}, \\ttt{x\\_max}, \\ttt{y\\_min}, \\ttt{y\\_max}).\n(cf. \\ttt{plot}, \\ttt{histogram}, \\ttt{record})\n%%%%%\n\\item\n\\ttt{Hel} \\newline\nUnary observable specifier that allows to specify the helicity of a\nparticle, e.g. \\ttt{all Hel == -1 [e1]} in a selection. (cf. also\n\\ttt{eval}, \\ttt{cuts}, \\ttt{selection})\n%%%%%\n\\item\n\\ttt{hepevt} \\newline\nSpecifier for the \\ttt{sample\\_format} command to demand the\ngeneration of HEPEVT ASCII event files. (cf. also \\ttt{\\$sample},\n\\ttt{sample\\_format})\n%%%%%\n\\item\n\\ttt{hepevt\\_verb} \\newline\nSpecifier for the \\ttt{sample\\_format} command to demand the\ngeneration of the extended or verbose version of HEPEVT ASCII event\nfiles. (cf. also \\ttt{\\$sample}, \\ttt{sample\\_format})\n%%%%%\n\\item\n\\ttt{hepmc} \\newline\nSpecifier for the \\ttt{sample\\_format} command to demand the\ngeneration of HepMC ASCII event files. Note that this is only\navailable if the HepMC package is installed and correctly\nlinked. (cf. also \\ttt{\\$sample}, \\ttt{sample\\_format},\n\\ttt{?hepmc\\_output\\_cross\\_section})\n%%%%%\n\\item\n\\ttt{histogram} \\newline\nThis command defines the necessary information regarding plotting data\nas a histogram, in the form of: \\ttt{histogram {\\em <record\\_name>} \\{\n{\\em <optional arguments>} \\}}. The record with name \\ttt{{\\em <record\\_name>}} has to be\ndefined, either before or after the histogram definition. Possible optional\narguments of the \\ttt{histogram} command are the minimal and maximal values\nof the axes (\\ttt{x\\_min}, \\ttt{x\\_max}, \\ttt{y\\_min}, \\ttt{y\\_max}).\n(cf. \\ttt{graph}, \\ttt{plot}, \\ttt{record})\n%%%%%\n\\item\n\\ttt{if} \\newline\nConditional clause with the construction \\ttt{if {\\em <log\\_expr>} then\n{\\em <expr>} [else {\\em <expr>} \\ldots] endif}. Note that there must be an\n\\ttt{endif}  statement. For more complicated expressions it is better\nto use expressions in parentheses: \\ttt{if ({\\em <log\\_expr>}) then\n\\{{\\em <expr>}\\} else \\{{\\em <expr>}\\} endif}. Examples are a selection of up quarks\nover down quarks depending on a logical variable: \\ttt{if ?ok then u\n  else d}, or the setting of an integer variable depending on the\nrapidity of some particle: \\ttt{if (eta > 0) then \\{ a = +1\\} else\n\\{ a = -1\\}}. (cf. also \\ttt{elsif}, \\ttt{endif}, \\ttt{then})\n%%%%%\n\\item\n\\ttt{in} \\newline\nSecond part of the constructor to let a variable be local to an\nexpression. It has the syntax \\ttt{let {\\em <var>} = {\\em <value>} in\n{\\em <expression>}}.  E.g. \\ttt{let int a = 3 in let int b = 4 in\n{\\em <expression>}} (cf. also \\ttt{let})\n%%%%%\n\\item\n\\ttt{include} \\newline\nThe \\ttt{include} statement, \\ttt{include (\"file.sin\")} allows to\ninclude external \\sindarin\\ files \\ttt{file.sin} into the main WHIZARD\ninput file. A standard example is the inclusion of the standard cut\nfile \\ttt{default\\_cuts.sin}.\n%%%%%\n\\item\n\\ttt{incoming} \\newline\nConstructor that specifies particles (or subevents) as incoming. It is\nused in cuts, analyses or selections, e.g. \\ttt{cuts = all Theta > 20\ndegree [incoming lepton, lepton]}. (cf. also \\ttt{beam}, \\ttt{outgoing},\n\\ttt{cuts}, \\ttt{analysis}, \\ttt{selection}, \\ttt{record})\n%%%%%\n\\item\n\\ttt{index} \\newline\nSpecifies the position of the element of a particle to be extracted by\nthe subevent function ($\\to$) \\ttt{extract}: \\ttt{extract {\\em index\n<index\\_value>} [ {\\em <particles>}]}. Negative index values count\nfrom the end of the list. (cf. also \\ttt{extract}, \\ttt{sort}, \\ttt{combine},\n\\ttt{collect}, \\ttt{+})\n%%%%%\n\\item\n\\ttt{int} \\newline\n1) This is a constructor to specify integer constants in the input\nfile. Strictly speaking, it is a unary function setting the value\n\\ttt{int\\_val} of the integer variable \\ttt{int\\_var}:\n\\ttt{int {\\em <int\\_var>} = {\\em <int\\_val>}}. Note that is mandatory for all\nuser-defined variables. (cf. also \\ttt{real} and \\ttt{complex})\n2) It is a function \\ttt{int ({\\em <num\\_val>})} that converts real and\ncomplex numbers (here their real parts) into integers. (cf. also\n\\ttt{nint}, \\ttt{floor}, \\ttt{ceiling})\n%%%%%\n\\item\n\\ttt{integrate} \\newline\nThe \\ttt{integrate ({\\em <proc\\_name>}) \\{ {\\em <integrate\\_options>} \\}} command\ninvokes the integration (phase-space generation and Monte-Carlo\nsampling) of the process \\ttt{proc\\_name} (which can also be a list of\nprocesses) with the integration options\n\\ttt{{\\em <integrate\\_options>}}. Possible options are (1) via\n\\ttt{\\$integration\\_method = \"{\\em <intg. method>}\"} the integration\nmethod (the default being VAMP), (2) the number of iterations and\ncalls per integration during the Monte-Carlo phase-space integration\nvia the \\ttt{iterations} specifier; (3) goal for the\naccuracy, error or relative error (\\ttt{accuracy\\_goal},\n\\ttt{error\\_goal}, \\ttt{relative\\_error\\_goal}). (4) Invoking only\nphase space generation (\\ttt{?phs\\_only = true}), (5) making test\ncalls of the matrix element. (cf. also \\ttt{iterations},\n\\ttt{accuracy\\_goal}, \\ttt{error\\_goal}, \\ttt{relative\\_error\\_goal},\n\\ttt{error\\_threshold})\n%%%%%\n\\item\n\\ttt{isr} \\newline\nBeam structure specifier for the lepton-collider/QED initial-state\nradiation (ISR) structure function: e.g. \\ttt{beams = e1, E1 => isr}\n(applied to both beams), or e.g. \\ttt{beams = e1, u => isr, none}\n(applied to only one beam). (cf. also \\ttt{beams}, \\ttt{isr\\_alpha},\n\\ttt{isr\\_q\\_max}, \\ttt{isr\\_mass}, \\ttt{isr\\_order},\n\\ttt{?isr\\_recoil}, \\ttt{?isr\\_keep\\_energy})\n%%%%%\n\\item\n\\ttt{iterations} \\qquad (default: internal heuristics) \\newline\nOption to set the number of iterations and calls per iteration during\nthe Monte-Carlo phase-space integration process. The syntax is\n\\ttt{iterations = {\\em <n\\_iterations>}:{\\em <n\\_calls>}}. Note that this can be\nalso a list, separated by colons, which breaks up the integration\nprocess into passes of the specified number of integrations and calls\neach. It works for all integration methods. For VAMP, there is the\nadditional option to specify whether grids and channel weights should\nbe adapted during iterations (\\ttt{\"g\"}, \\ttt{\"w\"},\n\\ttt{\"gw\"} for both, or \\ttt{\"\"} for no adaptation).   (cf. also\n\\ttt{integrate}, \\ttt{accuracy\\_goal}, \\ttt{error\\_goal},\n\\ttt{relative\\_error\\_goal}, \\ttt{error\\_threshold}).\n%%%%%\n\\item\n\\ttt{join} \\newline\nSubevent function that concatenates two particle lists/subevents if\nthere is no overlap: \\ttt{join [{\\em <particles>}, {\\em\n<new\\_particles>}]}. The joining of the two lists can also be made\ndepending on a condition: \\ttt{join if {\\em <condition>} [{\\em\n<particles>}, {\\em <new\\_particles>}]}. (cf. also \\ttt{\\&},\n\\ttt{collect}, \\ttt{combine}, \\ttt{extract}, \\ttt{sort}, \\ttt{+})\n%%%%%\n\\item\n\\ttt{keV} \\newline\nPhysical unit, energies in $10^3$ electron volt. (cf. also \\ttt{eV},\n\\ttt{meV}, \\ttt{MeV}, \\ttt{GeV}, \\ttt{TeV})\n%%%%%\n\\item\n\\ttt{kT} \\newline\nBinary particle observable that represents a jet $k_T$ clustering\nmeasure: \\ttt{kT [j1, j2]} gives the following kinematic expression:\n$2 \\min(E_{j1}^2, E_{j2}^2) / Q^2 \\times (1 - \\cos\\theta_{j1,j2})$. At the\nmoment, $Q^2 = 1$.\n%%%%%\n\\item\n\\ttt{let} \\newline\nThis allows to let a variable be local to an expression. It has the\nsyntax \\ttt{let {\\em <var>} = {\\em <value>} in {\\em <expression>}}.\nE.g. \\ttt{let int a = 3 in let int b = 4 in {\\em <expression>}}\n(cf. also \\ttt{in})\n%%%%%\n\\item\n\\ttt{lha} \\newline\nSpecifier for the \\ttt{sample\\_format} command to demand the\ngeneration of the \\whizard\\ version 1 style (deprecated) LHA ASCII event\nformat files. (cf. also \\ttt{\\$sample}, \\newline\n\\ttt{sample\\_format})\n%%%%%\n\\item\n\\ttt{lhapdf} \\newline\nThis is a beams specifier to demand calling \\lhapdf\\ parton densities as\nstructure functions to integrate processes in hadron collisions. Note\nthat this only works if the external \\lhapdf\\ library is present and\ncorrectly linked. (cf. \\ttt{beams}, \\ttt{\\$lhapdf\\_dir},\n\\ttt{\\$lhapdf\\_file}, \\ttt{lhapdf\\_photon},\n\\ttt{\\$lhapdf\\_photon\\_file}, \\ttt{lhapdf\\_member},\n\\ttt{lhapdf\\_photon\\_scheme})\n%%%%%\n\\item\n\\ttt{lhapdf\\_photon} \\newline\nThis is a beams specifier to demand calling \\lhapdf\\ parton densities as\nstructure functions to integrate processes in hadron collisions with a\nphoton as initializer of the hard scattering process. Note\nthat this only works if the external \\lhapdf\\ library is present and\ncorrectly linked. (cf. \\ttt{beams}, \\ttt{lhapdf}, \\ttt{\\$lhapdf\\_dir},\n\\ttt{\\$lhapdf\\_file}, \\ttt{\\$lhapdf\\_photon\\_file},\n\\ttt{lhapdf\\_member}, \\ttt{lhapdf\\_photon\\_scheme})\n%%%%%\n\\item\n\\ttt{lhef} \\newline\nSpecifier for the \\ttt{sample\\_format} command to demand the\ngeneration of the Les Houches Accord (LHEF) event format files, with\nXML headers. There are several different versions of this format,\nwhich can be selected via the \\ttt{\\$lhef\\_version} specifier\n(cf. also \\ttt{\\$sample}, \\ttt{sample\\_format}, \\ttt{\\$lhef\\_version},\n\\ttt{\\$lhef\\_extension}, \\ttt{?lhef\\_write\\_sqme\\_prc},\n\\newline \\ttt{?lhef\\_write\\_sqme\\_ref}, \\ttt{?lhef\\_write\\_sqme\\_alt})\n%%%%%\n\\item\n\\ttt{library} \\newline\nThe command \\ttt{library = \"{\\em <lib\\_name>}\"} allows to specify a separate\nshared object library archive \\ttt{lib\\_name.so}, not using the\nstandard library \\ttt{default\\_lib.so}. Those libraries (when using\nshared libraries) are located in the \\ttt{.libs} subdirectory of the\nuser workspace. Specifying a separate library is useful for splitting\nup large lists of processes, or to restrict a larger number of\ndifferent loaded model files to one specific process library.\n(cf. also \\ttt{compile}, \\ttt{\\$library\\_name})\n%%%%%\n\\item\n\\ttt{log} \\newline\nNumerical function \\ttt{log ({\\em <num\\_val>})} that calculates the\nnatural logarithm of real and complex numerical numbers or\nvariables. (cf. also \\ttt{sqrt}, \\ttt{exp}, \\ttt{log10})\n%%%%%\n\\item\n\\ttt{log10} \\newline\nNumerical function \\ttt{log10 ({\\em <num\\_val>})} that calculates the\nbase 10 logarithm of real and complex numerical numbers or\nvariables. (cf. also \\ttt{sqrt}, \\ttt{exp}, \\ttt{log})\n%%%%%\n\\item\n\\ttt{long} \\newline\nSpecifier for the \\ttt{sample\\_format} command to demand the\ngeneration of the long variant of HEPEVT ASCII event\nfiles. (cf. also \\ttt{\\$sample},\n\\ttt{sample\\_format})\n%%%%%\n\\item\n\\ttt{M} \\newline\nUnary (binary) observable specifier for the (signed) mass of a single\n(two) particle(s), e.g. \\ttt{eval M [e1]}, \\ttt{any M = 91 GeV [e2,\n  E2]}. (cf. \\ttt{eval}, \\ttt{cuts}, \\ttt{selection})\n%%%%%\n\\item\n\\ttt{M2} \\newline\nUnary (binary) observable specifier for the mass squared of a single\n(two) particle(s), e.g. \\ttt{eval M2 [e1]}, \\ttt{all M2 > 2*mZ [e2,\n  E2]}. (cf. \\ttt{eval}, \\ttt{cuts}, \\ttt{selection})\n%%%%%\n\\item\n\\ttt{max} \\newline\nNumerical function with two arguments \\ttt{max ({\\em <var1>}, {\\em\n<var2>})} that gives the maximum of the two arguments: $\\max (var1,\nvar2)$. It can act on all combinations of integer and real\nvariables. Example: \\ttt{real heavier\\_mass = max (mZ, mH)}. (cf. also\n\\ttt{min})\n%%%%%\n\\item\n\\ttt{meV} \\newline\nPhysical unit, stating that the corresponding number is in $10^{-3}$\nelectron volt. (cf. also \\ttt{eV}, \\ttt{keV}, \\ttt{MeV}, \\ttt{GeV},\n\\ttt{TeV})\n%%%%%\n\\item\n\\ttt{MeV} \\newline\nPhysical unit, energies in $10^6$ electron volt. (cf. also \\ttt{eV},\n\\ttt{keV}, \\ttt{meV}, \\ttt{GeV}, \\ttt{TeV})\n%%%%%\n\\item\n\\ttt{min} \\newline\nNumerical function with two arguments \\ttt{min ({\\em <var1>}, {\\em\n<var2>})} that gives the minimum of the two arguments: $\\min (var1,\nvar2)$. It can act on all combinations of integer and real\nvariables. Example: \\ttt{real lighter\\_mass = min (mZ, mH)}. (cf. also\n\\ttt{max})\n%%%%%\n\\item\n\\ttt{mod} \\newline\nNumerical function for integer and real numbers \\ttt{mod (x, y)} that\ncomputes the remainder of the division of \\ttt{x} by \\ttt{y} (which\nmust not be zero). (cf. also\n\\ttt{abs}, \\ttt{conjg}, \\ttt{sgn}, \\ttt{modulo})\n%%%%%\n\\item\n\\ttt{model} \\qquad (default: \\ttt{SM}) \\newline\nWith this specifier, \\ttt{model = {\\em <model\\_name>}}, one sets the hard\ninteraction physics model for the processes defined after this model\nspecification. The list of available models can be found in Table\n\\ref{tab:models}. Note that the model specification can appear\narbitrarily often in a \\sindarin\\ input file, e.g. for compiling and\nrunning processes defined in different physics models. (cf. also\n\\ttt{\\$model\\_name})\n%%%%%\n\\item\n\\ttt{modulo} \\newline\nNumerical function for integer and real numbers \\ttt{modulo (x, y)} that\ncomputes the value of $x$ modulo $y$. (cf. also\n\\ttt{abs}, \\ttt{conjg}, \\ttt{sgn}, \\ttt{mod})\n%%%%%\n\\item\n\\ttt{mokka} \\newline\nSpecifier for the \\ttt{sample\\_format} command to demand the\ngeneration of the MOKKA variant for HEPEVT ASCII event\nfiles. (cf. also \\ttt{\\$sample},\n\\ttt{sample\\_format})\n%%%%%\n\\item\n\\ttt{mrad} \\newline\nExpression specifying the physical unit of milliradians for angular\nvariables. This default in \\whizard\\ is \\ttt{rad}. (cf. \\ttt{degree}, \\ttt{rad}).\n%%%%%\n\\item\n\\ttt{nbarn} \\newline\nPhysical unit, stating that a number is in nanobarns ($10^{-9}$\nbarn). (cf. also \\ttt{abarn}, \\ttt{fbarn}, \\ttt{pbarn})\n%%%%%\n\\item\n\\ttt{n\\_in} \\newline\nInteger variable that accesses the number of incoming particles of a\nprocess. It can be used in cuts or in an analysis. (cf. also\n\\ttt{sqrts\\_hat}, \\ttt{cuts}, \\ttt{record}, \\ttt{n\\_out}, \\ttt{n\\_tot})\n%%%%%\n\\item\n\\ttt{Nacl} \\newline\nUnary observable specifier that returns the total number of open anticolor lines\nof a particle or subevent (i.e., composite particle).  Defined only if\n\\ttt{?colorize\\_subevt} is true.. (cf. also\n\\ttt{Ncol}, \\ttt{?colorize\\_subevt})\n%%%%%\n\\item\n\\ttt{Ncol} \\newline\nUnary observable specifier that returns the total number of open color lines\nof a particle or subevent (i.e., composite particle).  Defined only if\n\\ttt{?colorize\\_subevt} is true.. (cf. also\n\\ttt{Nacl}, \\ttt{?colorize\\_subevt})\n%%%%%\n\\item\n\\ttt{nint} \\newline\nThis is a function \\ttt{nint ({\\em <num\\_val>})} that converts real\nnumbers into the closest integer, e.g. \\ttt{int i = nint (4.56789)}\ngives \\ttt{i = 5}. (cf. also\n\\ttt{int}, \\ttt{floor}, \\ttt{ceiling})\n%%%%%\n\\item\n\\ttt{no} \\newline\n\\ttt{no} is a function that works on a logical expression and a list,\n\\ttt{no {\\em <log\\_expr>} [{\\em <list>}]}, and returns \\ttt{true} if and only if\n\\ttt{log\\_expr} is fulfilled for {\\em none} of the entries in\n\\ttt{list}, and \\ttt{false} otherwise. Examples: \\ttt{no Pt < 100 GeV\n  [lepton]} checks whether no lepton is softer than 100 GeV. It is the\nlogical opposite of the function \\ttt{all}. Logical expressions with\n\\ttt{no} can be logically combined with \\ttt{and} and\n\\ttt{or}. (cf. also \\ttt{all}, \\ttt{any}, \\ttt{and}, and \\ttt{or})\n%%%%%\n\\item\n\\ttt{none} \\newline\nBeams specifier that can used to explicitly {\\em not} apply a\nstructure function to a beam, e.g. in HERA physics: \\ttt{beams = e1, P\n  => none, pdf\\_builtin}. (cf. also \\ttt{beams})\n%%%%%\n\\item\n\\ttt{not} \\newline\nThis is the standard logical negation that converts true into false\nand vice versa. It is applied to logical values, e.g. cut\nexpressions. (cf. also \\ttt{and}, \\ttt{or}).\n%%%%%\n\\item\n\\ttt{n\\_out} \\newline\nInteger variable that accesses the number of outgoing particles of a\nprocess. It can be used in cuts or in an analysis. (cf. also\n\\ttt{sqrts\\_hat}, \\ttt{cuts}, \\ttt{record}, \\ttt{n\\_in}, \\ttt{n\\_tot})\n%%%%%\n\\item\n\\ttt{n\\_tot} \\newline\nInteger variable that accesses the total number of particles (incoming\nplus outgoing) of a process. It can be used in cuts or in an\nanalysis. (cf. also \\ttt{sqrts\\_hat}, \\ttt{cuts}, \\ttt{record},\n\\ttt{n\\_in}, \\ttt{n\\_out})\n%%%%%\n\\item\n\\ttt{observable} \\newline\nWith this, \\ttt{observable = {\\em <obs\\_spec>}}, the user is able to define\na variable specifier \\ttt{obs\\_spec} for observables. These can be\nreused in the analysis, e.g. as a \\ttt{record}, as functions of the\nfundamental kinematical variables of the processes.\n(cf. \\ttt{analysis}, \\ttt{record})\n%%%%%\n\\item\n\\ttt{open\\_out} \\newline\nWith the command, \\ttt{open\\_out (\"{\\em <out\\_file\">})} user-defined\ninformation like data or ($\\to$) \\ttt{printf} statements can be\nwritten out to a user-defined file. The command opens an I/O stream to\nan external file \\ttt{{\\em <out\\_file>}}. (cf. also \\ttt{close\\_out},\n\\ttt{\\$out\\_file}, \\ttt{printf})\n%%%%%\n\\item\n\\ttt{or} \\newline\nThis is the standard two-place logical connective that has the value\ntrue if one of its operands is true, otherwise a value of false. It\nis applied to logical values, e.g. cut expressions. (cf. also\n\\ttt{and}, \\ttt{not}).\n%%%%%\n\\item\n\\ttt{outgoing} \\newline\nConstructor that specifies particles (or subevents) as outgoing. It is\nused in cuts, analyses or selections, e.g. \\ttt{cuts = all Theta > 20\ndegree [incoming lepton, outgoing lepton]}. Note that the \\ttt{outgoing}\nkeyword is redundant and included only for completeness: \\ttt{outgoing lepton}\nhas the same meaning as \\ttt{lepton}.  (cf. also \\ttt{beam},\n\\ttt{incoming},\n\\ttt{cuts}, \\ttt{analysis}, \\ttt{selection}, \\ttt{record})\n%%%%%\n\\item\n\\ttt{P} \\newline\nUnary (binary) observable specifier for the spatial momentum\n$\\sqrt{\\vec{p}^2}$ of a single (two) particle(s), e.g. \\ttt{eval P\n[\"W+\"]}, \\ttt{all P > 200 GeV [b, B]}. (cf. \\ttt{eval}, \\ttt{cuts},\n\\ttt{selection})\n%%%%%\n\\item\n\\ttt{pbarn} \\newline\nPhysical unit, stating that a number is in picobarns ($10^{-12}$\nbarn). (cf. also \\ttt{abarn}, \\ttt{fbarn}, \\ttt{nbarn})\n%%%%%\n\\item\n\\ttt{pdf\\_builtin} \\newline\nThis is a beams specifier for \\whizard's internal PDF structure\nfunctions to integrate processes in hadron collisions.\n(cf. \\ttt{beams}, \\ttt{pdf\\_builtin\\_photon},\n\\ttt{\\$pdf\\_builtin\\_file})\n%%%%%\n\\item\n\\ttt{pdf\\_builtin\\_photon} \\newline\nThis is a beams specifier for \\whizard's internal PDF structure\nfunctions to integrate processes in hadron collisions with a photon as\ninitializer of the hard scattering process.\n(cf. \\ttt{beams}, \\ttt{\\$pdf\\_builtin\\_file})\n%%%%%\n\\item\n\\ttt{PDG} \\newline\nUnary observable specifier that allows to specify the PDG code of a\nparticle, e.g. \\ttt{eval PDG [e1]}, giving \\ttt{11}. (cf. also\n\\ttt{eval}, \\ttt{cuts}, \\ttt{selection})\n%%%%%\n\\item\n\\ttt{Phi} \\newline\nUnary and also binary observable specifier, that as a unary observable\ngives the azimuthal angle of a particle's momentum in the detector\nframe (beam into $+z$ direction). As a binary observable, it gives the\nazimuthal difference between the momenta of two particles: \\ttt{eval\nPhi [e1]},  \\ttt{all Phi > Pi [jet, jet]}. (cf. also \\ttt{eval},\n\\ttt{cuts}, \\ttt{selection}, \\ttt{Theta})\n%%%%%\n\\item\n\\ttt{photon\\_isolation} \\newline\nLogical function \\ttt{photon\\_isolation if {\\em <condition>} [{\\em\n<list1>} , {\\em <list2>}]} that cuts out event where the photons in\n\\ttt{{\\em <list1>}} do not fulfill the condition \\ttt{{\\em\n<condition>}} and are not isolated from hadronic (and electromagnetic)\nactivity, i.e. the photon fragmentation. (cf. also \\ttt{cluster},\n\\ttt{collect}, \\ttt{combine}, \\ttt{extract}, \\ttt{select},\n\\ttt{sort}, \\ttt{+})\n%%%%%\n\\item\n\\ttt{Pl} \\newline\nUnary (binary) observable specifier for the longitudinal momentum\n($p_z$ in the c.m. frame) of a single (two) particle(s),\ne.g. \\ttt{eval Pl [\"W+\"]}, \\ttt{all Pl > 200 GeV [b,\nB]}. (cf. \\ttt{eval}, \\ttt{cuts}, \\ttt{selection})\n%%%%%\n\\item\n\\ttt{plot} \\newline\nThis command defines the necessary information regarding plotting data\nas a graph, in the form of: \\ttt{plot {\\em <record\\_name>} \\{ {\\em <optional\narguments>} \\}}. The record with name \\ttt{{\\em <record\\_name>}} has to be\ndefined, either before or after the plot definition. Possible optional\narguments of the \\ttt{plot} command are the minimal and maximal values\nof the axes (\\ttt{x\\_min}, \\ttt{x\\_max}, \\ttt{y\\_min}, \\ttt{y\\_max}).\n(cf. \\ttt{graph}, \\ttt{histogram}, \\ttt{record})\n%%%%%\n\\item\n\\ttt{polarized} \\newline\nConstructor to instruct \\whizard\\ to retain polarization of the\ncorresponding particles in the generated events: \\ttt{polarized {\\em <prt1>}\n  [, {\\em <prt2>} , ...]}. (cf. also \\ttt{unpolarized}, \\ttt{simulate},\n\\ttt{?polarized\\_events})\n%%%%%\n\\item\n\\ttt{printf} \\newline\nCommand that allows to print data as screen messages, into logfiles or\ninto user-defined output files: \\ttt{printf \"{\\em <string\\_expr>}\"}. There\nexist format specifiers, very similar to the \\ttt{C} command\n\\ttt{printf}, e.g. \\ttt{printf \"\\%i\" (123)}. (cf. also\n\\ttt{open\\_out}, \\ttt{close\\_out}, \\ttt{\\$out\\_file},\n\\ttt{?out\\_advance}, \\ttt{sprintf}, \\ttt{\\%d}, \\ttt{\\%i}, \\ttt{\\%e},\n\\ttt{\\%f}, \\ttt{\\%g}, \\ttt{\\%E}, \\ttt{\\%F}, \\ttt{\\%G}, \\ttt{\\%s})\n%%%%%\n\\item\n\\ttt{process} \\newline\nAllows to set a hard interaction process, either for a decay process\nwith name \\ttt{{\\em <decay\\_proc>}} as \\ttt{process {\\em\n<decay\\_proc>} = {\\em <mother>} => {\\em <daughter1>}, {\\em\n<daughter2>}, ...}, or for a scattering process\nwith name \\ttt{{\\em <scat\\_proc}} as \\ttt{process {\\em <scat\\_proc>} =\n{\\em <in1>}, {\\em <in2>} => {\\em <out1>}, {\\em <out2>}, ...}. Note\nthat there can be arbitrarily many processes to be defined in a\n\\sindarin\\ input file. There are two options for particle/process sums: flavor sums:\n\\ttt{{\\em <prt1>}:{\\em <prt2>}:...}, where all masses have to be identical, and\ninclusive sums, \\ttt{{\\em <prt1>} + {\\em <prt2>} + ...}. The latter can be done on\nthe level of individual particles, or sums over whole final\nstates. Here, masses can differ, and terms will be translated into\ndifferent process components. The \\ttt{process} command also allows for\noptional arguments, e.g. to specify a numerical identifier\n(cf. \\ttt{process\\_num\\_id}), the method how to generate the code for\nthe matrix element(s): \\ttt{\\$method}, possible methods are either\nwith the \\oMega\\ matrix element generator, using template matrix\nelements with different normalizations, or completely internal matrix\nelement; for \\oMega\\ matrix elements there is also the possibility to\nspecify possible restrictions (cf. \\ttt{\\$restrictions}).\n%%%%%\n\\item\n\\ttt{Pt} \\newline\nUnary (binary) observable specifier for the transverse momentum\n($\\sqrt{p_x^2 + p_y^2}$ in the c.m. frame) of a single (two)\nparticle(s), e.g. \\ttt{eval Pt [\"W+\"]}, \\ttt{all Pt > 200 GeV [b,\nB]}. (cf. \\ttt{eval}, \\ttt{cuts}, \\ttt{selection})\n%%%%%\n\\item\n\\ttt{Px} \\newline\nUnary (binary) observable specifier for the $x$-component of the\nmomentum of a single (two) particle(s), e.g. \\ttt{eval Px [\"W+\"]},\n\\ttt{all Px > 200 GeV [b, B]}. (cf. \\ttt{eval}, \\ttt{cuts},\n\\ttt{selection})\n%%%%%\n\\item\n\\ttt{Py} \\newline\nUnary (binary) observable specifier for the $y$-component of the\nmomentum of a single (two) particle(s), e.g. \\ttt{eval Py [\"W+\"]},\n\\ttt{all Py > 200 GeV [b, B]}. (cf. \\ttt{eval}, \\ttt{cuts},\n\\ttt{selection})\n%%%%%\n\\item\n\\ttt{Pz} \\newline\nUnary (binary) observable specifier for the $z$-component of the\nmomentum of a single (two) particle(s), e.g. \\ttt{eval Pz [\"W+\"]},\n\\ttt{all Pz > 200 GeV [b, B]}. (cf. \\ttt{eval}, \\ttt{cuts},\n\\ttt{selection})\n%%%%%\n\\item\n\\ttt{quit} \\newline\nCommand to finish the \\whizard\\ run (and not execute any further code\nbeyond the appearance of \\ttt{quit} in the \\sindarin\\ file. The command\n(which is the same as $\\to$ \\ttt{exit}) allows for an argument,\n\\ttt{quit ({\\em <expr>})}, where the expression can be executed, e.g. a\nscreen message or an quit code.\n%%%%%\n\\item\n\\ttt{rad} \\newline\nExpression specifying the physical unit of radians for angular\nvariables. This is the default in \\whizard. (cf. \\ttt{degree}, \\ttt{mrad}).\n%%%%%\n\\item\n\\ttt{Rap} \\newline\nUnary and also binary observable specifier, that as a unary observable\ngives the rapidity of a particle momentum. The rapidity is given by $y\n= \\frac12 \\log \\left[ (E + p_z)/(E-p_z) \\right]$. As a binary\nobservable, it gives the rapidity difference between the momenta of\ntwo particles: \\ttt{eval Rap [e1]},  \\ttt{all abs (Rap) < 3.5 [jet,\n  jet]}. (cf. also \\ttt{eval}, \\ttt{cuts}, \\ttt{selection}, \\ttt{Eta},\n\\ttt{abs})\n%%%%%\n\\item\n\\ttt{read\\_slha} \\newline\nTells \\whizard\\ to read in an input file in the SUSY Les Houches accord\n(SLHA), as \\ttt{read\\_slha (\"slha\\_file.slha\")}. Note that the files\nfor the use in \\whizard\\ should have the suffix \\ttt{.slha}.\n(cf. also \\ttt{write\\_slha}, \\ttt{?slha\\_read\\_decays},\n\\ttt{?slha\\_read\\_input}, \\ttt{?slha\\_read\\_spectrum})\n%%%%%\n\\item\n\\ttt{real} \\newline\nThis is a constructor to specify real constants in the input\nfile. Strictly speaking, it is a unary function setting the value\n\\ttt{real\\_val} of the real variable \\ttt{real\\_var}:\n\\ttt{real {\\em <real\\_var>} = {\\em <real\\_val>}}. (cf. also \\ttt{int} and\n\\ttt{complex})\n%%%%%\n\\item\n\\ttt{real\\_epsilon}\\\\\nPredefined real; the relative uncertainty intrinsic to the floating\npoint type of the \\fortran\\ compiler with which \\whizard\\ has been\nbuilt.\n%%%%%\n\\item\n\\ttt{real\\_precision}\\\\\nPredefined integer; the decimal precision of the floating point type\nof the \\fortran\\ compiler with which \\whizard\\ has been built.\n%%%%%\n\\item\n\\ttt{real\\_range}\\\\\nPredefined integer; the decimal range of the floating point type of\nthe \\fortran\\ compiler with which \\whizard\\ has been built.\n%%%%%\n\\item\n\\ttt{real\\_tiny}\\\\\nPredefined real; the smallest number which can be represented by the\nfloating point type of the \\fortran\\ compiler with which \\whizard\\ has\nbeen built.\n%%%%%\n\\item\n\\ttt{record} \\newline\nThe \\ttt{record} constructor provides an internal data structure in\n\\sindarin\\ input files. Its syntax is in general \\ttt{record\n  {\\em <record\\_name>} ({\\em <cmd\\_expr>})}. The \\ttt{{\\em <cmd\\_expr>}} could be the\ndefinition of a tuple of points for a histogram or an \\ttt{eval}\nconstructor that tells \\whizard\\ e.g. by which rule to calculate an\nobservable to be stored in the record \\ttt{record\\_name}. Example:\n\\ttt{record h (12)} is a record for a histogram defined under the name\n\\ttt{h} with the single data point (bin) at value 12; \\ttt{record rap1\n(eval Rap [e1])} defines a record with name \\ttt{rap1} which has an\nevaluator to calculate the rapidity (predefined \\whizard\\ function) of\nan outgoing electron.\n(cf. also \\ttt{eval}, \\ttt{histogram}, \\ttt{plot})\n%%%%%\n\\item\n\\ttt{renormalization\\_scale} \\newline\nThis is a command, \\ttt{renormalization\\_scale = {\\em <expr>}}, that sets\nthe renormalization scale of a process or list of processes. It\noverwrites a possible scale set by the ($\\to$) \\ttt{scale} command.\n\\ttt{{\\em <expr>}} can be any kinematic expression that leads to a result of\nmomentum dimension one, e.g. \\ttt{100 GeV}, \\ttt{eval\nPt [e1]}. (cf. also \\ttt{factorization\\_scale}).\n%%%%%\n\\item\n\\ttt{rescan} \\newline\nThis command allows to rescan event samples with modified model\nparameter, beam structure etc. to recalculate (analysis) observables,\ne.g.: \\newline\n\\ttt{rescan \"{\\em <event\\_file>}\" ({\\em <proc\\_name>}) \\{ {\\em <rescan\\_setup>}\\}}.\n\\newline\n\\ttt{\"{\\em <event\\_file>}\"} is the name of the event file and\n\\ttt{{\\em <proc\\_name>}} is the process whose (existing) event\nfile of arbitrary size that is to be rescanned. Several flags allow to\nreconstruct the beams ($\\to$ \\ttt{?recover\\_beams}), to reuse only the\nhard process but rebuild the full events ($\\to$\n\\ttt{?update\\_event}), to recalculate the matrix element ($\\to$\n\\ttt{?update\\_sqme}) or to recalculate the individual event weight ($\\to$\n\\ttt{?update\\_weight}). Further rescan options are redefining model\nparameter input, or defining a completely new alternative setup ($\\to$\n\\ttt{alt\\_setup}) (cf. also \\ttt{\\$rescan\\_input\\_format})\n%%%%%\n\\item\n\\ttt{results} \\newline\nOnly used in the combination \\ttt{show (results)}. Forces \\whizard\\ to\nprint out a results summary for the integrated processes.\n(cf. also \\ttt{show})\n%%%%%\n\\item\n\\ttt{reweight} \\newline\nThe \\ttt{reweight = {\\em <expr>}} command allows to give for a process or\nlist of processes an alternative weight, given by any kind of scalar\nexpression \\ttt{{\\em <expr>}}, e.g. \\ttt{reweight = 0.2} or \\ttt{reweight =\n(eval M2 [e1, E1]) / (eval M2 [e2, E2])}. (cf. also \\ttt{alt\\_setup},\n\\ttt{weight}, \\ttt{rescan})\n%%%%%\n\\item\n\\ttt{sample\\_format} \\newline\nVariable that allows the user to specify additional event formats\nbeyond the \\whizard\\ native binary event format. Its syntax is\n\\ttt{sample\\_format = {\\em <format>}}, where \\ttt{{\\em <format>}} can be any of\nthe following specifiers: \\ttt{hepevt}, \\ttt{hepevt\\_verb}, \\ttt{ascii},\n\\ttt{athena}, \\ttt{debug}, \\ttt{long}, \\ttt{short}, \\ttt{hepmc},\n\\ttt{lhef}, \\ttt{lha}, \\ttt{lha\\_verb}, \\ttt{stdhep}, \\ttt{stdhep\\_up},\n\\texttt{lcio}, \\texttt{mokka}.\n(cf. also \\ttt{\\$sample}, \\ttt{simulate}, \\ttt{hepevt}, \\ttt{ascii},\n\\ttt{athena}, \\ttt{debug}, \\ttt{long}, \\ttt{short}, \\ttt{hepmc},\n\\ttt{lhef}, \\ttt{lha}, \\ttt{stdhep}, \\ttt{stdhep\\_up}, \\texttt{lcio},\n\\texttt{mokka}, \\ttt{\\$sample\\_normalization}, \\ttt{?sample\\_pacify}, \\newline\n\\ttt{sample\\_max\\_tries}, \\ttt{sample\\_split\\_n\\_evt}, \\ttt{sample\\_split\\_n\\_kbytes})\n%%%%%\n\\item\n\\ttt{scale} \\newline\nThis is a command, \\ttt{scale = {\\em <expr>}}, that sets the kinematic scale\nof a process or list of processes. Unless overwritten explicitly by\n($\\to$) \\ttt{factorization\\_scale} and/or ($\\to$)\n\\ttt{renormalization\\_scale} it sets both scales. \\ttt{{\\em <expr>}} can be\nany kinematic expression that leads to a result of momentum dimension\none, e.g. \\ttt{scale = 100 GeV}, \\ttt{scale = eval Pt [e1]}.\n%%%%%\n\\item\n\\ttt{scan} \\newline\nConstructor to perform loops over variables or scan over processes in\nthe integration procedure. The syntax is \\ttt{scan {\\em <var>} {\\em <var\\_name>}\n  ({\\em <value list>} or  {\\em <value\\_init>} => {\\em <value\\_fin>} /{\\em <incrementor>}\n  {\\em <increment>}) \\{ {\\em <scan\\_cmd>} \\}}. The variable \\ttt{var} can be\nspecified if it is not a real, e.g. an integer. \\ttt{var\\_name} is the\nname of the variable which is also allowed to be a predefined one like\n\\ttt{seed}. For the scan, one can either specify an explicit list of\nvalues \\ttt{value list}, or use an initial and final value and a\nrule to increment. The \\ttt{scan\\_cmd}  can either be just a\n\\ttt{show} to print out the scanned variable or the integration of a process.\nExamples are: \\ttt{scan seed (32 => 1 // 2) \\{ show (seed\\_value) \\}\n}, which runs the seed down in steps 32, 16, 8, 4, 2, 1 (division by\ntwo). \\ttt{scan mW (75 GeV, 80 GeV => 82 GeV /+ 0.5 GeV,  83 GeV => 90\nGeV /* 1.2) \\{ show (sw) \\} } scans over the $W$ mass for the values\n75, 80, 80.5, 81, 81.5, 82, 83 GeV, namely one discrete value, steps\nby adding 0.5 GeV, and increase by 20 \\% (the latter having no effect\nas it already exceeds the final value). It prints out the\ncorresponding value of the effective mixing angle which is defined as\na dependent variable in the model input file(s). \\ttt{scan sqrts (500 GeV =>\n  600 GeV /+ 10 GeV) \\{ integrate (proc) \\} } integrates the process\n\\ttt{proc} in eleven increasing 10 GeV steps in center-of-mass energy\nfrom 500 to 600 GeV. (cf. also \\ttt{/+}, \\ttt{/+/}, \\ttt{/-},\n\\ttt{/*}, \\ttt{/*/}, \\ttt{//})\n%%%%%\n\\item\n\\ttt{select} \\newline\nSubevent function \\ttt{select if {\\em <condition>} [{\\em <list1>} [ ,\n  {\\em <list2>}]]} that selects all particles in \\ttt{{\\em <list1>}}\nthat satisfy the condition \\ttt{{\\em <condition>}}. The second\nparticle list \\ttt{{\\em <list2>}} is for conditions that depend on\nbinary observables. (cf. also \\ttt{collect},\n\\ttt{combine}, \\ttt{extract}, \\ttt{sort}, \\ttt{+})\n%%%%%\n\\item\n\\ttt{select\\_b\\_jet} \\newline\nSubevent function \\ttt{select if {\\em <condition>} [{\\em <list1>} [ ,\n  {\\em <list2>}]]} that selects all particles in \\ttt{{\\em <list1>}}\nthat are $b$ jets and satisfy the condition \\ttt{{\\em\n<condition>}}. The second particle list \\ttt{{\\em <list2>}} is for\nconditions that depend on binary observables. (cf. also \\ttt{cluster},\n\\ttt{collect}, \\ttt{combine}, \\ttt{extract}, \\ttt{select},\n\\ttt{sort}, \\ttt{+})\n%%%%%\n\\item\n\\ttt{select\\_c\\_jet} \\newline\nSubevent function \\ttt{select if {\\em <condition>} [{\\em <list1>} [ ,\n  {\\em <list2>}]]} that selects all particles in \\ttt{{\\em <list1>}}\nthat are $c$ jets (but {\\em not} $b$ jets) and satisfy the condition\n\\ttt{{\\em <condition>}}. The second particle list \\ttt{{\\em <list2>}}\nis for conditions that depend on binary observables. (cf. also\n\\ttt{cluster}, \\ttt{collect}, \\ttt{combine}, \\ttt{extract},\n\\ttt{select}, \\ttt{sort}, \\ttt{+})\n%%%%%\n\\item\n\\ttt{select\\_light\\_jet} \\newline\nSubevent function \\ttt{select if {\\em <condition>} [{\\em <list1>} [ ,\n  {\\em <list2>}]]} that selects all particles in \\ttt{{\\em <list1>}}\nthat are light(-flavor) jets and satisfy the condition\n\\ttt{{\\em <condition>}}. The second particle list \\ttt{{\\em <list2>}}\nis for conditions that depend on binary observables. (cf. also\n\\ttt{cluster}, \\ttt{collect}, \\ttt{combine}, \\ttt{extract},\n\\ttt{select}, \\ttt{sort}, \\ttt{+})\n%%%%%\n\\item\n\\ttt{select\\_non\\_b\\_jet} \\newline\nSubevent function \\ttt{select if {\\em <condition>} [{\\em <list1>} [ ,\n{\\em <list2>}]]} that selects all particles in \\ttt{{\\em <list1>}}\nthat are {\\em not} $b$ jets ($c$ and light jets) and satisfy the\ncondition \\ttt{{\\em <condition>}}. The second particle list \\ttt{{\\em\n<list2>}} is for conditions that depend on binary\nobservables. (cf. also \\ttt{cluster}, \\ttt{collect}, \\ttt{combine},\n\\ttt{extract}, \\ttt{select}, \\ttt{sort}, \\ttt{+})\n%%%%%\n\\item\n\\ttt{selection} \\newline\nCommand that allows to select particular final states in an analysis\nselection, \\ttt{selection = {\\em <log\\_expr>}}. The term \\ttt{log\\_expr} can\nbe any kind of logical expression. The syntax matches exactly\nthe one of the ($\\to$) \\ttt{cuts} command. E.g. \\ttt{selection = any\nPDG == 13} is an electron selection in a lepton sample.\n%%%%%\n\\item\n\\ttt{sgn} \\newline\nNumerical function for integer and real numbers that gives the sign of\nits argument: \\ttt{sgn ({\\em <num\\_val>})} yields $+1$ if \\ttt{{\\em\n<num\\_val>}} is positive or zero, and $-1$ otherwise. (cf. also\n\\ttt{abs}, \\ttt{conjg}, \\ttt{mod}, \\ttt{modulo})\n%%%%%\n\\item\n\\ttt{short} \\newline\nSpecifier for the \\ttt{sample\\_format} command to demand the\ngeneration of the short variant of HEPEVT ASCII event\nfiles. (cf. also \\ttt{\\$sample}, \\ttt{sample\\_format})\n%%%%%\n\\item\n\\ttt{show} \\newline\nThis is a unary function that is operating on specific constructors in\norder to print them out in the \\whizard\\ screen output as well as the\nlog file \\ttt{whizard.log}. Examples are \\ttt{show({\\em <parameter\\_name>})}\nto issue a specific parameter from a model or a constant defined in a\n\\sindarin\\ input file, \\ttt{show(integral({\\em <proc\\_name>}))},\n\\ttt{show(library)}, \\ttt{show(results)}, or \\ttt{show({\\em <var>})} for any\narbitrary variable. Further possibilities are \\ttt{show(real)},\n\\ttt{show(string)}, \\ttt{show(logical)} etc. to allow to show all\ndefined real, string, logical etc. variables, respectively.\n(cf. also \\ttt{library}, \\ttt{results})\n%%%%%\n\\item\n\\ttt{simulate} \\newline\nThis command invokes the generation of events for the process\n\\ttt{proc} by means of \\ttt{simulate ({\\em <proc>})}.\nOptional arguments: \\ttt{\\$sample}, \\ttt{sample\\_format},\n\\ttt{checkpoint} (cf. also \\ttt{integrate}, \\ttt{luminosity},\n\\ttt{n\\_events}, \\ttt{\\$sample}, \\ttt{sample\\_format},\n\\ttt{checkpoint}, \\ttt{?unweighted}, \\ttt{safety\\_factor},\n\\ttt{?negative\\_weights}, \\ttt{sample\\_max\\_tries},\n\\ttt{sample\\_split\\_n\\_evt}, \\ttt{sample\\_split\\_n\\_kbytes})\n%%%%%\n\\item\n\\ttt{sin} \\newline\nNumerical function \\ttt{sin ({\\em <num\\_val>})} that calculates the\nsine trigonometric function of real and complex numerical numbers or\nvariables. (cf. also \\ttt{cos}, \\ttt{tan}, \\ttt{asin}, \\ttt{acos},\n\\ttt{atan})\n%%%%%\n\\item\n\\ttt{sinh} \\newline\nNumerical function \\ttt{sinh ({\\em <num\\_val>})} that calculates the\nhyperbolic sine function of real and complex numerical numbers or\nvariables. Note that its inverse function is part of the\n\\ttt{Fortran2008} status and hence not realized. (cf. also \\ttt{cosh},\n\\ttt{tanh})\n%%%%%\n\\item\n\\ttt{sort} \\newline\nSubevent function that allows to sort a particle list/subevent either\nby increasing PDG code: \\ttt{sort [{\\em <particles>}]} (particles\nfirst, then antiparticles). Alternatively, it can sort according to a\nunary or binary particle observable (in that case there is a second\nparticle list, where the first particle is taken as a reference):\n\\ttt{sort by {\\em <observable>} [{\\em <particles>} [, {\\em\n<ref\\_particles>}]]}. (cf. also \\ttt{extract}, \\ttt{combine},\n\\ttt{collect}, \\ttt{join}, \\ttt{by}, \\ttt{+})\n%%%%%\n\\item\n\\ttt{sprintf} \\newline\nCommand that allows to print data into a string variable: \\ttt{sprintf\n\"{\\em <string\\_expr>}\"}. There exist format specifiers, very similar\nto the \\ttt{C} command \\ttt{sprintf}, e.g. \\ttt{sprintf \"\\%i\"\n(123)}. (cf. \\ttt{printf}, \\ttt{\\%d}, \\ttt{\\%i}, \\ttt{\\%e},\n\\ttt{\\%f}, \\ttt{\\%g}, \\ttt{\\%E}, \\ttt{\\%F}, \\ttt{\\%G}, \\ttt{\\%s})\n%%%%%\n\\item\n\\ttt{sqrt} \\newline\nNumerical function \\ttt{sqrt ({\\em <num\\_val>})} that calculates the\nsquare root of real and complex numerical numbers or\nvariables. (cf. also \\ttt{exp}, \\ttt{log}, \\ttt{log10})\n%%%%%\n\\item\n\\ttt{sqrts\\_hat} \\newline\nReal variable that accesses the partonic energy of a hard-scattering\nprocess. It can be used in cuts or in an analysis, e.g. \\ttt{cuts =\nsqrts\\_hat > {\\em <num>} [ {\\em <phys\\_unit>} ]}. The physical unit\ncan be one of the following \\ttt{eV}, \\ttt{keV}, \\ttt{MeV}, \\ttt{GeV},\nand \\ttt{TeV}. (cf. also \\ttt{sqrts}, \\ttt{cuts}, \\ttt{record})\n%%%%%\n\\item\n\\ttt{stable} \\newline\nThis constructor allows particles in the final states of processes in\ndecay cascade set-up to be set as stable, and not letting them\ndecay. The syntax is \\ttt{stable {\\em <prt\\_name>}} (cf. also \\ttt{unstable})\n%%%%%\n\\item\n\\ttt{stdhep} \\newline\nSpecifier for the \\ttt{sample\\_format} command to demand the\ngeneration of binary StdHEP event files based on the HEPEVT common\nblock. (cf. also \\ttt{\\$sample}, \\ttt{sample\\_format})\n%%%%%\n\\item\n\\ttt{stdhep\\_up} \\newline\nSpecifier for the \\ttt{sample\\_format} command to demand the\ngeneration of binary StdHEP event files based on the HEPRUP/HEPEUP common\nblocks. (cf. also \\ttt{\\$sample}, \\ttt{sample\\_format})\n%%%%%\n\\item\n\\ttt{tan} \\newline\nNumerical function \\ttt{tan ({\\em <num\\_val>})} that calculates the\ntangent trigonometric function of real and complex numerical numbers or\nvariables. (cf. also \\ttt{sin}, \\ttt{cos}, \\ttt{asin}, \\ttt{acos},\n\\ttt{atan})\n%%%%%\n\\item\n\\ttt{tanh} \\newline\nNumerical function \\ttt{tanh ({\\em <num\\_val>})} that calculates the\nhyperbolic tangent function of real and complex numerical numbers or\nvariables. Note that its inverse function is part of the\n\\ttt{Fortran2008} status and hence not realized. (cf. also \\ttt{cosh},\n\\ttt{sinh})\n%%%%%\n\\item\n\\ttt{TeV} \\newline\nPhysical unit, for energies in $10^{12}$ electron volt. (cf. also\n\\ttt{eV}, \\ttt{keV}, \\ttt{MeV}, \\ttt{meV}, \\ttt{GeV})\n%%%%\n\\item\n\\ttt{then} \\newline\nMandatory phrase in a conditional clause: \\ttt{if {\\em <log\\_expr>} then\n  {\\em <expr 1>} \\ldots endif}. (cf. also \\ttt{if}, \\ttt{else}, \\ttt{elsif},\n\\ttt{endif}).\n%%%%%\n\\item\n\\ttt{Theta} \\newline\nUnary and also binary observable specifier, that as a unary observable\ngives the angle between a particle's momentum and the beam axis ($+z$\ndirection). As a binary observable, it gives the angle enclosed\nbetween the momenta of the two particles: \\ttt{eval Theta [e1]},\n\\ttt{all Theta > 30 degrees [jet, jet]}. (cf. also \\ttt{eval},\n\\ttt{cuts}, \\ttt{selection}, \\ttt{Phi}, \\ttt{Theta\\_star})\n%%%%%\n\\item\n\\ttt{Theta\\_star} \\newline\nBinary observable specifier, that gives the polar angle enclosed\nbetween the momenta of the two particles in the rest frame of the\nmother particle (momentum sum of the two particle): \\ttt{eval\nTheta\\_star [jet, jet]}. (cf. also \\ttt{eval},\n\\ttt{cuts}, \\ttt{selection}, \\ttt{Theta})\n%%%%%\n\\item\n\\ttt{true} \\newline\nConstructor stating that a logical expression or variable is true,\ne.g. \\ttt{?{\\em <log\\_var>} = true}. (cf. also \\ttt{false}).\n%%%%%\n\\item\n\\ttt{unpolarized} \\newline\nConstructor to force \\whizard\\ to discard polarization of the\ncorresponding particles in the generated events: \\ttt{unpolarized {\\em <prt1>}\n  [, {\\em <prt2>} , ...]}. (cf. also \\ttt{polarized}, \\ttt{simulate},\n\\ttt{?polarized\\_events})\n%%%%%\n\\item\n\\ttt{unstable} \\newline\nThis constructor allows to let final state particles of the hard\ninteraction undergo a subsequent (cascade) decay (in the on-shell\napproximation). For this the user has to define the list of desired\n\\begin{figure}\n  \\begin{Verbatim}[frame=single]\n    process zee =   Z => e1, E1\n    process zuu =   Z => u, U\n    process zz = e1, E1 => Z, Z\n    compile\n    integrate (zee) { iterations = 1:100 }\n    integrate (zuu) { iterations = 1:100 }\n    sqrts = 500 GeV\n    integrate (zz) { iterations = 3:5000, 2:5000 }\n    unstable Z (zee, zuu)\n \\end{Verbatim}\n  \\caption{\\label{fig:ex_unstable} \\sindarin\\ input file for unstable\n    particles and inclusive decays.}\n\\end{figure}\ndecay channels as \\ttt{unstable {\\em <mother>} ({\\em <decay1>}, {\\em <decay2>}, ....)},\nwhere \\ttt{mother} is the mother particle, and the argument is a list\nof decay channels. Note that -- unless the \\ttt{?auto\\_decays = true}\nflag has been set -- these decay channels have to be provided by the\nuser as  in the example in Fig. \\ref{fig:ex_unstable}. First, the $Z$\ndecays to electrons and up quarks are generated, then $ZZ$ production\nat a 500 GeV ILC is called, and then both $Z$s are decayed according\nto the probability distribution of the two generated decay matrix\nelements. This obviously allows also for inclusive decays.\n(cf. also \\ttt{stable}, \\ttt{?auto\\_decays})\n%%%%%\n\\item\n\\ttt{weight} \\newline\nThis is a command, \\ttt{weight = {\\em <expr>}}, that allows to specify a\nweight for a process or list of processes. \\ttt{{\\em <expr>}} can be\nany expression that leads to a scalar result, e.g. \\ttt{weight = 0.2},\n\\ttt{weight = eval Pt [jet]}.  (cf. also \\ttt{rescan},\n\\ttt{alt\\_setup}, \\ttt{reweight})\n%%%%%\n\\item\n\\ttt{write\\_analysis} \\newline\nThe \\ttt{write\\_analysis} statement tells \\whizard\\ to write the\nanalysis setup by the user for the \\sindarin\\ input file under\nconsideration. If no \\ttt{\\$out\\_file} is provided, the histogram\ntables/plot data etc. are written to the default file\n\\ttt{whizard\\_analysis.dat}. Note that the related command\n\\ttt{compile\\_analysis} does the same as \\ttt{write\\_analysis} but in\naddition invokes the \\whizard\\ \\LaTeX routines for producing\npostscript or PDF output of the data.\n(cf. also \\ttt{\\$out\\_file}, \\ttt{compile\\_analysis})\n%%%%%\n\\item\n\\ttt{write\\_slha} \\newline\nDemands \\whizard\\ to write out a file in the SUSY Les Houches accord\n(SLHA) format. (cf. also \\ttt{read\\_slha}, \\ttt{?slha\\_read\\_decays},\n\\ttt{?slha\\_read\\_input}, \\ttt{?slha\\_read\\_spectrum})\n%%%%%\n\\end{itemize}\n\\section{Variables}\n\\subsection{Rebuild Variables}\n\\begin{itemize}\n\\item\n\\ttt{?rebuild\\_events} \\qquad (default: \\ttt{false}) \\newline\nThis logical variable, if set \\ttt{true} triggers \\whizard\\ to newly\ncreate an event sample, even if nothing seems to have changed,\nincluding the MD5 checksum. This can be used when manually\nmanipulating some settings. (cf also \\ttt{?rebuild\\_grids},\n\\ttt{?rebuild\\_library}, \\ttt{?rebuild\\_phase\\_space})\n%%%%%\n\\item\n\\ttt{?rebuild\\_grids} \\qquad (default: \\ttt{false}) \\newline\nThe logical variable \\ttt{?rebuild\\_grids} forces \\whizard\\ to newly\ncreate the VAMP grids when using VAMP as an integration method, even\nif they are already present. (cf. also \\ttt{?rebuild\\_events},\n\\ttt{?rebuild\\_library}, \\ttt{?rebuild\\_phase\\_space})\n%%%%%\n\\item\n\\ttt{?rebuild\\_library} \\qquad (default: \\ttt{false}) \\newline\nThe logical variable \\ttt{?rebuild\\_library = true/false} specifies\nwhether the library(-ies) for the matrix element code for processes is\nre-generated (incl. possible Makefiles etc.) by the corresponding ME\nmethod (e.g. if the process has been changed, but not its name). This\ncan also be set as a command-line option \\ttt{whizard --rebuild}. The\ndefault is \\ttt{false}, i.e. code is never re-generated if it is\npresent and the MD5 checksum is valid.\n(cf. also \\ttt{?recompile\\_library}, \\ttt{?rebuild\\_grids},\n\\ttt{?rebuild\\_phase\\_space})\n%%%%%\n\\item\n\\ttt{?rebuild\\_phase\\_space} \\qquad (default: \\ttt{false}) \\newline\nThis logical variable, if set \\ttt{true}, triggers recreation of the\nphase space file by \\whizard\\. (cf. also \\ttt{?rebuild\\_events},\n\\ttt{?rebuild\\_grids}, \\ttt{?rebuild\\_library})\n%%%%%\n\\item\n\\ttt{?recompile\\_library} \\qquad (default: \\ttt{false}) \\newline\nThe logical variable \\ttt{?recompile\\_library = true/false} specifies\nwhether the library(-ies) for the matrix element code for processes is\nre-compiled (e.g. if the process code has been manually modified by\nthe user). This can also be set as a command-line option \\ttt{whizard\n  --recompile}. The default is \\ttt{false}, i.e. code is never\nre-compiled if its corresponding object file is present. (cf. also\n\\ttt{?rebuild\\_library})\n%%%%%\n\\end{itemize}\n\\subsection{Standard Variables}\n\\begin{itemize}\n\\input{variables}\n\\end{itemize}\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\\clearpage\n\\section*{Acknowledgements}\n\nWe would like to thank E.~Boos, R.~Chierici, K.~Desch, M.~Kobel,\nF.~Krauss, P.M.~Manakos, N.~Meyer, K.~M\\\"onig, H.~Reuter, T.~Robens,\nS.~Rosati, J.~Schumacher, M.~Schumacher, and C.~Schwinn who\ncontributed to \\whizard\\ by their suggestions, bits of codes and\nvaluable remarks and/or used several versions of the program for\nreal-life applications and thus helped a lot in debugging and\nimproving the code.  Special thanks go to A.~Vaught and J.~Weill for\ntheir continuos efforts on improving the g95 and gfortran compilers,\nrespectively.\n\n%\\end{fmffile}\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%% References\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%\\baselineskip15pt\n\\begin{thebibliography}{19}\n\n\\bibitem{PYTHIA}\n  T.~Sj\\\"ostrand,\n  Comput.\\ Phys.\\ Commun.\\ \\textbf{82} (1994) 74.\n\n\\bibitem{comphep}\n  A.~Pukhov, \\emph{et al.},\n  Preprint INP MSU 98-41/542, \\ttt{hep-ph/9908288}.\n\n\\bibitem{madgraph}\n  T.~Stelzer and W.F.~Long,\n  Comput.\\ Phys.\\ Commun.\\ \\textbf{81} (1994) 357.\n\n\\bibitem{omega}\n  T.~Ohl,\n  \\emph{Proceedings of the Seventh International Workshop on\n  Advanced Computing and Analysis Technics in Physics Research},\n  ACAT 2000, Fermilab, October 2000,\n  IKDA-2000-30, \\ttt{hep-ph/0011243};\n  M.~Moretti, Th.~Ohl, and J.~Reuter,\n  LC-TOOL-2001-040\n\n\\bibitem{VAMP}\n  T.~Ohl,\n  {\\em Vegas revisited: Adaptive Monte Carlo integration beyond\n    factorization},\n  Comput.\\ Phys.\\ Commun.\\  {\\bf 120}, 13 (1999)\n  [arXiv:hep-ph/9806432].\n  %%CITATION = CPHCB,120,13;%%\n\n\\bibitem{CIRCE}\n  T.~Ohl,\n  {\\em CIRCE version 1.0: Beam spectra for simulating linear collider\n    physics},\n  Comput.\\ Phys.\\ Commun.\\  {\\bf 101}, 269 (1997)\n  [arXiv:hep-ph/9607454].\n  %%CITATION = CPHCB,101,269;%%\n\n%\\cite{Gribov:1972rt}\n\\bibitem{Gribov:1972rt}\n  V.~N.~Gribov and L.~N.~Lipatov,\n  {\\em e+ e- pair annihilation and deep inelastic e p scattering in\n    perturbation theory},\n  Sov.\\ J.\\ Nucl.\\ Phys.\\  {\\bf 15}, 675 (1972)\n  [Yad.\\ Fiz.\\  {\\bf 15}, 1218 (1972)].\n  %%CITATION = SJNCA,15,675;%%\n\n%\\cite{Kuraev:1985hb}\n\\bibitem{Kuraev:1985hb}\n  E.~A.~Kuraev and V.~S.~Fadin,\n  {\\em On Radiative Corrections to e+ e- Single Photon Annihilation at\n    High-Energy},\n  Sov.\\ J.\\ Nucl.\\ Phys.\\  {\\bf 41}, 466 (1985)\n  [Yad.\\ Fiz.\\  {\\bf 41}, 733 (1985)].\n  %%CITATION = SJNCA,41,466;%%\n\n%\\cite{Skrzypek:1990qs}\n\\bibitem{Skrzypek:1990qs}\n  M.~Skrzypek and S.~Jadach,\n  {\\em Exact and approximate solutions for the electron nonsinglet\n    structure function in QED},\n  Z.\\ Phys.\\ C {\\bf 49}, 577 (1991).\n  %%CITATION = ZEPYA,C49,577;%%\n\n%\\cite{Schulte:1998au}\n\\bibitem{Schulte:1998au}\n  D.~Schulte,\n  {\\em Beam-beam simulations with Guinea-Pig},\n  eConf C {\\bf 980914}, 127 (1998).\n  %%CITATION = ECONF,C980914,127;%%\n\n%\\cite{Schulte:1999tx}\n\\bibitem{Schulte:1999tx}\n  D.~Schulte,\n  {\\em Beam-beam simulations with GUINEA-PIG},\n  CERN-PS-99-014-LP.\n  %%CITATION = CERN-PS-99-014-LP;%%\n\n%\\cite{Schulte:2007zz}\n\\bibitem{Schulte:2007zz}\n  D.~Schulte, M.~Alabau, P.~Bambade, O.~Dadoun, G.~Le Meur, C.~Rimbault and F.~Touze,\n  {\\em GUINEA PIG++ : An Upgraded Version of the Linear Collider Beam\n    Beam Interaction Simulation Code GUINEA PIG},\n  Conf.\\ Proc.\\ C {\\bf 070625}, 2728 (2007).\n  %%CITATION = CONFP,C070625,2728;%%\n\n%\\cite{Behnke:2013xla}\n\\bibitem{Behnke:2013xla}\n  T.~Behnke, J.~E.~Brau, B.~Foster, J.~Fuster, M.~Harrison, J.~M.~Paterson, M.~Peskin and M.~Stanitzki {\\it et al.},\n  {\\em The International Linear Collider Technical Design Report -\n    Volume 1: Executive Summary},\n  arXiv:1306.6327 [physics.acc-ph].\n  %%CITATION = ARXIV:1306.6327;%%\n\n%\\cite{Baer:2013cma}\n\\bibitem{Baer:2013cma}\n  H.~Baer, T.~Barklow, K.~Fujii, Y.~Gao, A.~Hoang, S.~Kanemura, J.~List and H.~E.~Logan {\\it et al.},\n  {\\em The International Linear Collider Technical Design Report -\n    Volume 2: Physics},\n  arXiv:1306.6352 [hep-ph].\n  %%CITATION = ARXIV:1306.6352;%%\n\n%\\cite{Adolphsen:2013jya}\n\\bibitem{Adolphsen:2013jya}\n  C.~Adolphsen, M.~Barone, B.~Barish, K.~Buesser, P.~Burrows, J.~Carwardine, J.~Clark and H\\'{e}l\\`{e}n.~M.~Durand {\\it et al.},\n  {\\em The International Linear Collider Technical Design Report -\n    Volume 3.I: Accelerator \\& in the Technical Design Phase},\n  arXiv:1306.6353 [physics.acc-ph].\n  %%CITATION = ARXIV:1306.6353;%%\n\n%\\cite{Adolphsen:2013kya}\n\\bibitem{Adolphsen:2013kya}\n  C.~Adolphsen, M.~Barone, B.~Barish, K.~Buesser, P.~Burrows, J.~Carwardine, J.~Clark and H\\'{e}l\\`{e}n.~M.~Durand {\\it et al.},\n  {\\em The International Linear Collider Technical Design Report -\n    Volume 3.II: Accelerator Baseline Design},\n  arXiv:1306.6328 [physics.acc-ph].\n  %%CITATION = ARXIV:1306.6328;%%\n\n%\\cite{Behnke:2013lya}\n\\bibitem{Behnke:2013lya}\n  T.~Behnke, J.~E.~Brau, P.~N.~Burrows, J.~Fuster, M.~Peskin, M.~Stanitzki, Y.~Sugimoto and S.~Yamada {\\it et al.},\n  %``The International Linear Collider Technical Design Report - Volume 4: Detectors,''\n  arXiv:1306.6329 [physics.ins-det].\n  %%CITATION = ARXIV:1306.6329;%%\n\n%\\cite{Aicheler:2012bya}\n\\bibitem{Aicheler:2012bya}\n  M.~Aicheler, P.~Burrows, M.~Draper, T.~Garvey, P.~Lebrun, K.~Peach and N.~Phinney {\\it et al.},\n  {\\em A Multi-TeV Linear Collider Based on CLIC Technology : CLIC\n    Conceptual Design Report},\n  CERN-2012-007.\n  %%CITATION = CERN-2012-007;%%\n\n%\\cite{Lebrun:2012hj}\n\\bibitem{Lebrun:2012hj}\n  P.~Lebrun, L.~Linssen, A.~Lucaci-Timoce, D.~Schulte, F.~Simon, S.~Stapnes, N.~Toge and H.~Weerts {\\it et al.},\n  {\\em The CLIC Programme: Towards a Staged e+e- Linear Collider\n    Exploring the Terascale : CLIC Conceptual Design Report},\n  arXiv:1209.2543 [physics.ins-det].\n  %%CITATION = ARXIV:1209.2543;%%\n\n%\\cite{Linssen:2012hp}\n\\bibitem{Linssen:2012hp}\n  L.~Linssen, A.~Miyamoto, M.~Stanitzki and H.~Weerts,\n  {\\em Physics and Detectors at CLIC: CLIC Conceptual Design Report},\n  arXiv:1202.5940 [physics.ins-det].\n  %%CITATION = ARXIV:1202.5940;%%\n\n%\\cite{vonWeizsacker:1934sx}\n\\bibitem{vonWeizsacker:1934sx}\n  C.~F.~von Weizs\\\"acker,\n  {\\em Radiation emitted in collisions of very fast electrons},\n  Z.\\ Phys.\\  {\\bf 88}, 612 (1934).\n  %%CITATION = ZEPYA,88,612;%%\n\n%\\cite{Williams:1934ad}\n\\bibitem{Williams:1934ad}\n  E.~J.~Williams,\n  {\\em Nature of the high-energy particles of penetrating radiation\n    and status of ionization and radiation formulae},\n  Phys.\\ Rev.\\  {\\bf 45}, 729 (1934).\n  %%CITATION = PHRVA,45,729;%%\n\n%\\cite{Budnev:1974de}\n\\bibitem{Budnev:1974de}\n  V.~M.~Budnev, I.~F.~Ginzburg, G.~V.~Meledin and V.~G.~Serbo,\n  {\\em The Two photon particle production mechanism. Physical problems.\n  Applications. Equivalent photon approximation},\n  Phys.\\ Rept.\\  {\\bf 15} (1974) 181.\n  %%CITATION = PRPLC,15,181;%%\n\n%\\cite{Ginzburg:1981vm}\n\\bibitem{Ginzburg:1981vm}\n  I.~F.~Ginzburg, G.~L.~Kotkin, V.~G.~Serbo and V.~I.~Telnov,\n  {\\em Colliding gamma e and gamma gamma Beams Based on the Single\n    Pass Accelerators (of Vlepp Type)},\n  Nucl.\\ Instrum.\\ Meth.\\  {\\bf 205}, 47 (1983).\n  %%CITATION = NUIMA,205,47;%%\n\n%\\cite{Telnov:1989sd}\n\\bibitem{Telnov:1989sd}\n  V.~I.~Telnov,\n  {\\em Problems of Obtaining $\\gamma \\gamma$ and $\\gamma \\epsilon$\n    Colliding Beams at Linear Colliders},\n  Nucl.\\ Instrum.\\ Meth.\\ A {\\bf 294}, 72 (1990).\n  %%CITATION = NUIMA,A294,72;%%\n\n%\\cite{Telnov:1995hc}\n\\bibitem{Telnov:1995hc}\n  V.~I.~Telnov,\n  {\\em Principles of photon colliders},\n  Nucl.\\ Instrum.\\ Meth.\\ A {\\bf 355}, 3 (1995).\n  %%CITATION = NUIMA,A355,3;%%\n\n%\\cite{AguilarSaavedra:2001rg}\n\\bibitem{AguilarSaavedra:2001rg}\n  J.~A.~Aguilar-Saavedra {\\it et al.}  [ECFA/DESY LC Physics Working\n  Group Collaboration],\n  {\\em TESLA: The Superconducting electron positron linear collider\n    with an integrated x-ray laser laboratory. Technical design\n    report. Part 3. Physics at an e+ e- linear collider},\n  hep-ph/0106315.\n  %%CITATION = HEP-PH/0106315;%%\n\n%\\cite{Richard:2001qm}\n\\bibitem{Richard:2001qm}\n  F.~Richard, J.~R.~Schneider, D.~Trines and A.~Wagner,\n  {\\em TESLA, The Superconducting Electron Positron Linear Collider\n    with an Integrated X-ray Laser Laboratory, Technical Design Report\n    Part 1 : Executive Summary},\n  hep-ph/0106314.\n  %%CITATION = HEP-PH/0106314;%%\n\n%\\cite{Sudakov:1954sw}\n\\bibitem{Sudakov:1954sw}\n  V.~V.~Sudakov,\n  %``Vertex parts at very high-energies in quantum electrodynamics,''\n  Sov.\\ Phys.\\ JETP {\\bf 3}, 65 (1956)\n  [Zh.\\ Eksp.\\ Teor.\\ Fiz.\\  {\\bf 30}, 87 (1956)].\n  %%CITATION = SPHJA,3,65;%%\n\n\\cite{Sjostrand:1985xi}\n\\bibitem{Sjostrand:1985xi}\n  T.~Sjostrand,\n  %``A Model for Initial State Parton Showers,''\n  Phys.\\ Lett.\\  {\\bf 157B}, 321 (1985).\n  doi:10.1016/0370-2693(85)90674-4\n  %%CITATION = doi:10.1016/0370-2693(85)90674-4;%%\n\n%\\cite{Sjostrand:2006za}\n\\bibitem{Sjostrand:2006za}\n  T.~Sjostrand, S.~Mrenna and P.~Z.~Skands,\n  %``PYTHIA 6.4 Physics and Manual,''\n  JHEP {\\bf 0605}, 026 (2006)\n  doi:10.1088/1126-6708/2006/05/026\n  [hep-ph/0603175].\n  %%CITATION = doi:10.1088/1126-6708/2006/05/026;%%\n\n%\\cite{Ohl:1998jn}\n\\bibitem{Ohl:1998jn}\n  T.~Ohl,\n  {\\em Vegas revisited: Adaptive Monte Carlo integration beyond\n    factorization},\n  Comput.\\ Phys.\\ Commun.\\  {\\bf 120}, 13 (1999)\n  [hep-ph/9806432].\n  %%CITATION = HEP-PH/9806432;%%\n\n%\\cite{Lepage:1980dq}\n\\bibitem{Lepage:1980dq}\n  G.~P.~Lepage,\n  %``Vegas: An Adaptive Multidimensional Integration Program,''\n  CLNS-80/447.\n  %%CITATION = CLNS-80/447;%%\n\n\\bibitem{HDECAY}\n  A.~Djouadi, J.~Kalinowski, M.~Spira,\n  Comput.\\ Phys.\\ Commun.\\ \\textbf{108} (1998) 56-74.\n\n%\\cite{Beyer:2006hx}\n\\bibitem{Beyer:2006hx}\n  M.~Beyer, W.~Kilian, P.~Krstono\\v{s}ic, K.~M\\\"onig, J.~Reuter, E.~Schmidt\n  and H.~Schr\\\"oder,\n  {\\em Determination of New Electroweak Parameters at the ILC -\n    Sensitivity to New Physics},\n  Eur.\\ Phys.\\ J.\\ C {\\bf 48}, 353 (2006)\n  [hep-ph/0604048].\n  %%CITATION = HEP-PH/0604048;%%\n\n%\\cite{Alboteanu:2008my}\n\\bibitem{Alboteanu:2008my}\n  A.~Alboteanu, W.~Kilian and J.~Reuter,\n  {\\em Resonances and Unitarity in Weak Boson Scattering at the LHC},\n  JHEP {\\bf 0811}, 010 (2008)\n  [arXiv:0806.4145 [hep-ph]].\n  %%CITATION = ARXIV:0806.4145;%%\n\n%\\cite{Binoth:2010xt}\n\\bibitem{Binoth:2010xt}\n  T.~Binoth {\\it et al.},\n  %``A Proposal for a standard interface between Monte Carlo tools and one-loop programs,''\n  Comput.\\ Phys.\\ Commun.\\  {\\bf 181}, 1612 (2010)\n  doi:10.1016/j.cpc.2010.05.016\n  [arXiv:1001.1307 [hep-ph]].\n  %%CITATION = doi:10.1016/j.cpc.2010.05.016;%%\n\n%\\cite{Alioli:2013nda}\n\\bibitem{Alioli:2013nda}\n  S.~Alioli {\\it et al.},\n  %``Update of the Binoth Les Houches Accord for a standard interface\n  %between Monte Carlo tools and one-loop programs,''\n  Comput.\\ Phys.\\ Commun.\\  {\\bf 185}, 560 (2014)\n  doi:10.1016/j.cpc.2013.10.020\n  [arXiv:1308.3462 [hep-ph]].\n  %%CITATION = doi:10.1016/j.cpc.2013.10.020;%%\n\n%\\cite{Speckner:2010zi}\n\\bibitem{Speckner:2010zi}\n  C.~Speckner,\n  {\\em LHC Phenomenology of the Three-Site Higgsless Model},\n  PhD thesis, arXiv:1011.1851 [hep-ph].\n  %%CITATION = ARXIV:1011.1851;%%\n\n%\\cite{Chivukula:2006cg}\n\\bibitem{Chivukula:2006cg}\n  R.~S.~Chivukula, B.~Coleppa, S.~Di Chiara, E.~H.~Simmons, H.~-J.~He,\n  M.~Kurachi and M.~Tanabashi,\n  {\\em A Three Site Higgsless Model},\n  Phys.\\ Rev.\\ D {\\bf 74}, 075011 (2006)\n  [hep-ph/0607124].\n  %%CITATION = HEP-PH/0607124;%%\n\n%\\cite{Chivukula:2005xm}\n\\bibitem{Chivukula:2005xm}\n  R.~S.~Chivukula, E.~H.~Simmons, H.~-J.~He, M.~Kurachi and M.~Tanabashi,\n  {\\em Ideal fermion delocalization in Higgsless models},\n  Phys.\\ Rev.\\ D {\\bf 72}, 015008 (2005)\n  [hep-ph/0504114].\n  %%CITATION = HEP-PH/0504114;%%\n\n%\\cite{Ohl:2008ri}\n\\bibitem{Ohl:2008ri}\n  T.~Ohl and C.~Speckner,\n  {\\em Production of Almost Fermiophobic Gauge Bosons in the Minimal\n    Higgsless Model at the LHC},\n  Phys.\\ Rev.\\ D {\\bf 78}, 095008 (2008)\n  [arXiv:0809.0023 [hep-ph]].\n  %%CITATION = ARXIV:0809.0023;%%\n\n%\\cite{Ohl:2002jp}\n\\bibitem{Ohl:2002jp}\n  T.~Ohl and J.~Reuter,\n  {\\em Clockwork SUSY: Supersymmetric Ward and Slavnov-Taylor\n    identities at work in Green's functions and scattering\n    amplitudes},\n  Eur.\\ Phys.\\ J.\\ C {\\bf 30}, 525 (2003)\n  [hep-th/0212224].\n  %%CITATION = HEP-TH/0212224;%%\n\n%\\cite{Reuter:2009ex}\n\\bibitem{Reuter:2009ex}\n  J.~Reuter and F.~Braam,\n  {\\em The NMSSM implementation in WHIZARD},\n  AIP Conf.\\ Proc.\\  {\\bf 1200}, 470 (2010)\n  [arXiv:0909.3059 [hep-ph]].\n  %%CITATION = ARXIV:0909.3059;%%\n\n%\\cite{Kalinowski:2008fk}\n\\bibitem{Kalinowski:2008fk}\n  J.~Kalinowski, W.~Kilian, J.~Reuter, T.~Robens and K.~Rolbiecki,\n  {\\em Pinning down the Invisible Sneutrino},\n  JHEP {\\bf 0810}, 090 (2008)\n  [arXiv:0809.3997 [hep-ph]].\n  %%CITATION = ARXIV:0809.3997;%%\n\n%\\cite{Robens:2008sa}\n\\bibitem{Robens:2008sa}\n  T.~Robens, J.~Kalinowski, K.~Rolbiecki, W.~Kilian and J.~Reuter,\n  {\\em (N)LO Simulation of Chargino Production and Decay},\n  Acta Phys.\\ Polon.\\ B {\\bf 39}, 1705 (2008)\n  [arXiv:0803.4161 [hep-ph]].\n  %%CITATION = ARXIV:0803.4161;%%\n\n%\\cite{Kilian:2004pp}\n\\bibitem{Kilian:2004pp}\n  W.~Kilian, D.~Rainwater and J.~Reuter,\n  {\\em Pseudo-axions in little Higgs models},\n  Phys.\\ Rev.\\ D {\\bf 71}, 015008 (2005)\n  [hep-ph/0411213].\n  %%CITATION = HEP-PH/0411213;%%\n\n%\\cite{Kilian:2006eh}\n\\bibitem{Kilian:2006eh}\n  W.~Kilian, D.~Rainwater and J.~Reuter,\n  {\\em Distinguishing little-Higgs product and simple group models at\n    the LHC and ILC},\n  Phys.\\ Rev.\\ D {\\bf 74}, 095003 (2006)\n  [Erratum-ibid.\\ D {\\bf 74}, 099905 (2006)]\n  [hep-ph/0609119].\n  %%CITATION = HEP-PH/0609119;%%\n\n%\\cite{Ohl:2004tn}\n\\bibitem{Ohl:2004tn}\n  T.~Ohl and J.~Reuter,\n  {\\em Testing the noncommutative standard model at a future photon\n    collider},\n  Phys.\\ Rev.\\ D {\\bf 70}, 076007 (2004)\n  [hep-ph/0406098].\n  %%CITATION = HEP-PH/0406098;%%\n\n%\\cite{Ohl:2010zf}\n\\bibitem{Ohl:2010zf}\n  T.~Ohl and C.~Speckner,\n  {\\em The Noncommutative Standard Model and Polarization in Charged\n    Gauge Boson Production at the LHC},\n  Phys.\\ Rev.\\ D {\\bf 82}, 116011 (2010)\n  [arXiv:1008.4710 [hep-ph]].\n  %%CITATION = ARXIV:1008.4710;%%\n\n\\bibitem{LesHouches}\n  E.~Boos {\\it et al.},\n  {\\em Generic user process interface for event generators},\n  arXiv:hep-ph/0109068.\n  %%CITATION = HEP-PH/0109068;%%\n\n\\bibitem{Skands:2003cj}\n  P.~Z.~Skands {\\it et al.},\n  {\\em SUSY Les Houches Accord: Interfacing SUSY Spectrum Calculators, Decay\n  Packages, and Event Generators},\n  JHEP {\\bf 0407}, 036 (2004)\n  [arXiv:hep-ph/0311123].\n  %%CITATION = JHEPA,0407,036;%%\n\n%\\cite{AguilarSaavedra:2005pw}\n\\bibitem{AguilarSaavedra:2005pw}\n  J.~A.~Aguilar-Saavedra, A.~Ali, B.~C.~Allanach, R.~L.~Arnowitt, H.~A.~Baer, J.~A.~Bagger, C.~Balazs and V.~D.~Barger {\\it et al.},\n  {\\em Supersymmetry parameter analysis: SPA convention and project},\n  Eur.\\ Phys.\\ J.\\ C {\\bf 46}, 43 (2006)\n  [hep-ph/0511344].\n  %%CITATION = HEP-PH/0511344;%%\n\n%\\cite{Allanach:2008qq}\n\\bibitem{Allanach:2008qq}\n  B.~C.~Allanach, C.~Balazs, G.~Belanger, M.~Bernhardt, F.~Boudjema, D.~Choudhury, K.~Desch and U.~Ellwanger {\\it et al.},\n  %``SUSY Les Houches Accord 2,''\n  Comput.\\ Phys.\\ Commun.\\  {\\bf 180}, 8 (2009)\n  [arXiv:0801.0045 [hep-ph]].\n  %%CITATION = ARXIV:0801.0045;%%\n\n\\bibitem{LHEF}\n  J.~Alwall {\\it et al.},\n  {\\em A standard format for Les Houches event files},\n  Comput.\\ Phys.\\ Commun.\\  {\\bf 176}, 300 (2007)\n  [arXiv:hep-ph/0609017].\n  %%CITATION = CPHCB,176,300;%%\n\n\\bibitem{Hagiwara:2005wg}\n  K.~Hagiwara {\\it et al.},\n  {\\em Supersymmetry simulations with off-shell effects for LHC and\n    ILC},\n  Phys.\\ Rev.\\  D {\\bf 73}, 055005 (2006)\n  [arXiv:hep-ph/0512260].\n  %%CITATION = PHRVA,D73,055005;%%\n\n\\bibitem{Allanach:2002nj}\n  B.~C.~Allanach {\\it et al.},\n  {\\em The Snowmass points and slopes: Benchmarks for SUSY searches},\n  in {\\it Proc. of the APS/DPF/DPB Summer Study on the Future of Particle Physics (Snowmass 2001) } ed. N.~Graf,\n  Eur.\\ Phys.\\ J.\\ C {\\bf 25} (2002) 113\n  [eConf {\\bf C010630} (2001) P125]\n  [arXiv:hep-ph/0202233].\n  %%CITATION = HEP-PH 0202233;%%\n\n\\bibitem{PeskinSchroeder}\n  M.E. Peskin, D.V.Schroeder, {\\em An Introduction to Quantum Field\n    Theory}, Addison-Wesley Publishing Co., 1995.\n\n\\bibitem{UtaKlein}\n  U. Klein, O. Fischer, {\\em private communications}.\n\n\\bibitem{stdhep}\n  L.~Garren, {\\em StdHep, Monte Carlo Standardization at FNAL},\n  Fermilab CS-doc-903,\n  \\url{http://cd-docdb.fnal.gov/cgi-bin/ShowDocument?docid=903}\n\n%\\cite{Frixione:1998jh}\n\\bibitem{Frixione:1998jh}\n  S.~Frixione,\n  %``Isolated photons in perturbative QCD,''\n  Phys.\\ Lett.\\ B {\\bf 429}, 369 (1998)\n  doi:10.1016/S0370-2693(98)00454-7\n  [hep-ph/9801442].\n  %%CITATION = doi:10.1016/S0370-2693(98)00454-7;%%\n\n\\bibitem{LHAPDF}\n  W.~Giele {\\it et al.},\n  {\\em The QCD / SM working group: Summary report},\n  arXiv:hep-ph/0204316;\n  %%CITATION = HEP-PH/0204316;%%\n  M.~R.~Whalley, D.~Bourilkov and R.~C.~Group,\n  {\\em The Les Houches Accord PDFs (LHAPDF) and Lhaglue},\n  arXiv:hep-ph/0508110;\n  %%CITATION = HEP-PH/0508110;%%\n  D.~Bourilkov, R.~C.~Group and M.~R.~Whalley,\n  {\\em LHAPDF: PDF use from the Tevatron to the LHC},\n  arXiv:hep-ph/0605240.\n  %%CITATION = HEP-PH/0605240;%%\n\n\\bibitem{HepMC}\n  M.~Dobbs and J.~B.~Hansen,\n  {\\em The HepMC C++ Monte Carlo event record for High Energy\n    Physics},\n  Comput.\\ Phys.\\ Commun.\\  {\\bf 134}, 41 (2001).\n  %%CITATION = CPHCB,134,41;%%\n\n%\\cite{Boos:2004kh}\n\\bibitem{Boos:2004kh}\n  E.~Boos {\\it et al.}  [CompHEP Collaboration],\n  %``CompHEP 4.4: Automatic computations from Lagrangians to events,''\n  Nucl.\\ Instrum.\\ Meth.\\ A {\\bf 534}, 250 (2004)\n  [hep-ph/0403113].\n  %%CITATION = HEP-PH/0403113;%%\n  %493 citations counted in INSPIRE as of 12 May 2014\n\n% Parton distributions\n%\\cite{Pumplin:2002vw}\n\\bibitem{Pumplin:2002vw}\n  J.~Pumplin, D.~R.~Stump, J.~Huston {\\it et al.},\n  {\\em New generation of parton distributions with uncertainties from\n    global QCD analysis},\n  JHEP {\\bf 0207}, 012 (2002).\n  [hep-ph/0201195].\n%\\cite{Martin:2004dh}\n\\bibitem{Martin:2004dh}\n  A.~D.~Martin, R.~G.~Roberts, W.~J.~Stirling {\\it et al.},\n  {\\em Parton distributions incorporating QED contributions},\n  Eur.\\ Phys.\\ J.\\  {\\bf C39}, 155-161 (2005).\n  [hep-ph/0411040].\n%\\cite{Martin:2009iq}\n\\bibitem{Martin:2009iq}\n  A.~D.~Martin, W.~J.~Stirling, R.~S.~Thorne {\\it et al.},\n  {\\em Parton distributions for the LHC},\n  Eur.\\ Phys.\\ J.\\  {\\bf C63}, 189-285 (2009).\n  [arXiv:0901.0002 [hep-ph]].\n%\\cite{Lai:2010vv}\n\\bibitem{Lai:2010vv}\n  H.~L.~Lai, M.~Guzzi, J.~Huston, Z.~Li, P.~M.~Nadolsky, J.~Pumplin and C.~P.~Yuan,\n  {\\em New parton distributions for collider physics},\n  Phys.\\ Rev.\\  D {\\bf 82}, 074024 (2010)\n  [arXiv:1007.2241 [hep-ph]].\n  %%CITATION = PHRVA,D82,074024;%%\n%\\cite{Owens:2012bv}\n\\bibitem{Owens:2012bv}\n  J.~F.~Owens, A.~Accardi and W.~Melnitchouk,\n  {\\em Global parton distributions with nuclear and finite-$Q^2$\n    corrections},\n  Phys.\\ Rev.\\ D {\\bf 87}, no. 9, 094012 (2013)\n  [arXiv:1212.1702 [hep-ph]].\n  %%CITATION = ARXIV:1212.1702;%%\n%\\cite{Accardi:2016qay}\n\\bibitem{Accardi:2016qay}\n  A.~Accardi, L.~T.~Brady, W.~Melnitchouk, J.~F.~Owens and N.~Sato,\n  %``Constraints on large-$x$ parton distributions from new weak boson production and deep-inelastic scattering data,''\n  arXiv:1602.03154 [hep-ph].\n  %%CITATION = ARXIV:1602.03154;%%\n%\\cite{Harland-Lang:2014zoa}\n\\bibitem{Harland-Lang:2014zoa}\n  L.~A.~Harland-Lang, A.~D.~Martin, P.~Motylinski and R.~S.~Thorne,\n  %``Parton distributions in the LHC era: MMHT 2014 PDFs,''\n  arXiv:1412.3989 [hep-ph].\n  %%CITATION = ARXIV:1412.3989;%%\n%\\cite{Dulat:2015mca}\n\\bibitem{Dulat:2015mca}\n  S.~Dulat {\\it et al.},\n  %``The CT14 Global Analysis of Quantum Chromodynamics,''\n  arXiv:1506.07443 [hep-ph].\n  %%CITATION = ARXIV:1506.07443;%%\n\n\n%\\cite{Salam:2008qg}\n\\bibitem{Salam:2008qg}\n  G.~P.~Salam and J.~Rojo,\n  {\\em A Higher Order Perturbative Parton Evolution Toolkit (HOPPET)},\n  Comput.\\ Phys.\\ Commun.\\  {\\bf 180}, 120 (2009)\n  [arXiv:0804.3755 [hep-ph]].\n  %%CITATION = ARXIV:0804.3755;%%\n\n%\\cite{Kilian:2011ka}\n\\bibitem{Kilian:2011ka}\n  W.~Kilian, J.~Reuter, S.~Schmidt and D.~Wiesler,\n  {\\em An Analytic Initial-State Parton Shower},\n  JHEP {\\bf 1204} (2012) 013\n  [arXiv:1112.1039 [hep-ph]].\n  %%CITATION = ARXIV:1112.1039;%%\n\n%\\cite{Staub:2008uz}\n\\bibitem{Staub:2008uz}\n  F.~Staub,\n  {\\em Sarah},\n  arXiv:0806.0538 [hep-ph].\n  %%CITATION = ARXIV:0806.0538;%%\n\n%\\cite{Staub:2009bi}\n\\bibitem{Staub:2009bi}\n  F.~Staub,\n  {\\em From Superpotential to Model Files for FeynArts and\n    CalcHep/CompHep},\n  Comput.\\ Phys.\\ Commun.\\  {\\bf 181}, 1077 (2010)\n  [arXiv:0909.2863 [hep-ph]].\n  %%CITATION = ARXIV:0909.2863;%%\n\n%\\cite{Staub:2010jh}\n\\bibitem{Staub:2010jh}\n  F.~Staub,\n  {\\em Automatic Calculation of supersymmetric Renormalization Group\n    Equations and Self Energies},\n  Comput.\\ Phys.\\ Commun.\\  {\\bf 182}, 808 (2011)\n  [arXiv:1002.0840 [hep-ph]].\n  %%CITATION = ARXIV:1002.0840;%%\n\n%\\cite{Staub:2012pb}\n\\bibitem{Staub:2012pb}\n  F.~Staub,\n  {\\em SARAH 3.2: Dirac Gauginos, UFO output, and more},\n  Computer Physics Communications {\\bf 184}, pp. 1792 (2013)\n  [Comput.\\ Phys.\\ Commun.\\  {\\bf 184}, 1792 (2013)]\n  [arXiv:1207.0906 [hep-ph]].\n  %%CITATION = ARXIV:1207.0906;%%\n\n%\\cite{Staub:2013tta}\n\\bibitem{Staub:2013tta}\n  F.~Staub,\n  {\\em SARAH 4: A tool for (not only SUSY) model builders},\n  Comput.\\ Phys.\\ Commun.\\  {\\bf 185}, 1773 (2014)\n  [arXiv:1309.7223 [hep-ph]].\n  %%CITATION = ARXIV:1309.7223;%%\n\n\\bibitem{mathematica}\n  \\Mathematica\\ is a registered trademark of Wolfram Research, Inc.,\n  Champain, IL, USA.\n\n%\\cite{Porod:2003um}\n\\bibitem{Porod:2003um}\n  W.~Porod,\n  {\\em SPheno, a program for calculating supersymmetric spectra, SUSY\n    particle decays and SUSY particle production at e+ e- colliders},\n  Comput.\\ Phys.\\ Commun.\\  {\\bf 153}, 275 (2003)\n  [hep-ph/0301101].\n  %%CITATION = HEP-PH/0301101;%%\n\n%\\cite{Porod:2011nf}\n\\bibitem{Porod:2011nf}\n  W.~Porod and F.~Staub,\n  {\\em SPheno 3.1: Extensions including flavour, CP-phases and models\n    beyond the MSSM},\n  Comput.\\ Phys.\\ Commun.\\  {\\bf 183}, 2458 (2012)\n  [arXiv:1104.1573 [hep-ph]].\n  %%CITATION = ARXIV:1104.1573;%%\n\n%\\cite{Staub:2011dp}\n\\bibitem{Staub:2011dp}\n  F.~Staub, T.~Ohl, W.~Porod and C.~Speckner,\n  %``A Tool Box for Implementing Supersymmetric Models,''\n  Comput.\\ Phys.\\ Commun.\\  {\\bf 183}, 2165 (2012)\n  [arXiv:1109.5147 [hep-ph]].\n  %%CITATION = ARXIV:1109.5147;%%\n\n%%%%% FeynRules %%%%%\n\n%\\cite{Christensen:2008py}\n\\bibitem{Christensen:2008py}\n  N.~D.~Christensen and C.~Duhr,\n  {\\em FeynRules - Feynman rules made easy},\n  Comput.\\ Phys.\\ Commun.\\  {\\bf 180}, 1614 (2009)\n  [arXiv:0806.4194 [hep-ph]].\n  %%CITATION = ARXIV:0806.4194;%%\n\n%\\cite{Christensen:2009jx}\n\\bibitem{Christensen:2009jx}\n  N.~D.~Christensen, P.~de Aquino, C.~Degrande, C.~Duhr, B.~Fuks,\n  M.~Herquet, F.~Maltoni and S.~Schumann,\n  {\\em A Comprehensive approach to new physics simulations},\n  Eur.\\ Phys.\\ J.\\ C {\\bf 71}, 1541 (2011)\n  [arXiv:0906.2474 [hep-ph]].\n  %%CITATION = ARXIV:0906.2474;%%\n\n%\\cite{Duhr:2011se}\n\\bibitem{Duhr:2011se}\n  C.~Duhr and B.~Fuks,\n  %``A superspace module for the FeynRules package,''\n  Comput.\\ Phys.\\ Commun.\\  {\\bf 182}, 2404 (2011)\n  [arXiv:1102.4191 [hep-ph]].\n  %%CITATION = ARXIV:1102.4191;%%\n\n%\\cite{Christensen:2010wz}\n\\bibitem{Christensen:2010wz}\n  N.~D.~Christensen, C.~Duhr, B.~Fuks, J.~Reuter and C.~Speckner,\n  {\\em Introducing an interface between WHIZARD and FeynRules},\n  Eur.\\ Phys.\\ J.\\ C {\\bf 72}, 1990 (2012)\n  [arXiv:1010.3251 [hep-ph]].\n  %%CITATION = ARXIV:1010.3251;%%\n\n%\\cite{Degrande:2011ua}\n\\bibitem{Degrande:2011ua}\n  C.~Degrande, C.~Duhr, B.~Fuks, D.~Grellscheid, O.~Mattelaer and T.~Reiter,\n  %``UFO - The Universal FeynRules Output,''\n  Comput.\\ Phys.\\ Commun.\\  {\\bf 183}, 1201 (2012)\n  doi:10.1016/j.cpc.2012.01.022\n  [arXiv:1108.2040 [hep-ph]].\n  %%CITATION = doi:10.1016/j.cpc.2012.01.022;%%\n\n%\\cite{Han:1998sg}\n\\bibitem{Han:1998sg}\n  T.~Han, J.~D.~Lykken and R.~-J.~Zhang,\n  {\\em On Kaluza-Klein states from large extra dimensions},\n  Phys.\\ Rev.\\ D {\\bf 59}, 105006 (1999)\n  [hep-ph/9811350].\n  %%CITATION = HEP-PH/9811350;%%\n\n%\\cite{Fuks:2012im}\n\\bibitem{Fuks:2012im}\n  B.~Fuks,\n  {\\em Beyond the Minimal Supersymmetric Standard Model: from theory\n    to phenomenology},\n  Int.\\ J.\\ Mod.\\ Phys.\\ A {\\bf 27}, 1230007 (2012)\n  [arXiv:1202.4769 [hep-ph]].\n  %%CITATION = ARXIV:1202.4769;%%\n\n%\\cite{He:2007ge}\n\\bibitem{He:2007ge}\n  H.~-J.~He, Y.~-P.~Kuang, Y.~-H.~Qi, B.~Zhang, A.~Belyaev,\n  R.~S.~Chivukula, N.~D.~Christensen and A.~Pukhov {\\it et al.},\n  {\\em CERN LHC Signatures of New Gauge Bosons in Minimal Higgsless\n    Model},\n  Phys.\\ Rev.\\ D {\\bf 78}, 031701 (2008)\n  [arXiv:0708.2588 [hep-ph]].\n  %%CITATION = ARXIV:0708.2588;%%\n\n%%%%% WHIZARD NLO %%%%%\n\n%\\cite{Kilian:2006cj}\n\\bibitem{Kilian:2006cj}\n  W.~Kilian, J.~Reuter and T.~Robens,\n  {\\em NLO Event Generation for Chargino Production at the ILC},\n  Eur.\\ Phys.\\ J.\\ C {\\bf 48}, 389 (2006)\n  [hep-ph/0607127].\n  %%CITATION = HEP-PH/0607127;%%\n\n%\\cite{Binoth:2010ra}\n\\bibitem{Binoth:2010ra}\n  J.~R.~Andersen {\\it et al.}  [SM and NLO Multileg Working Group\n  Collaboration],\n  {\\em Les Houches 2009: The SM and NLO Multileg Working Group:\n    Summary report},\n  arXiv:1003.1241 [hep-ph].\n  %%CITATION = ARXIV:1003.1241;%%\n\n%\\cite{Butterworth:2010ym}\n\\bibitem{Butterworth:2010ym}\n  J.~M.~Butterworth, A.~Arbey, L.~Basso, S.~Belov, A.~Bharucha,\n  F.~Braam, A.~Buckley and M.~Campanelli {\\it et al.},\n  {\\em Les Houches 2009: The Tools and Monte Carlo working group\n    Summary Report},\n  arXiv:1003.1643 [hep-ph], arXiv:1003.1643 [hep-ph].\n  %%CITATION = ARXIV:1003.1643;%%\n\n%\\cite{Binoth:2009rv}\n\\bibitem{Binoth:2009rv}\n  T.~Binoth, N.~Greiner, A.~Guffanti, J.~Reuter, J.-P.~.Guillet and T.~Reiter,\n  {\\em Next-to-leading order QCD corrections to pp --> b anti-b b\n    anti-b + X at the LHC: the quark induced case},\n  Phys.\\ Lett.\\ B {\\bf 685}, 293 (2010)\n  [arXiv:0910.4379 [hep-ph]].\n  %%CITATION = ARXIV:0910.4379;%%\n\n%\\cite{Greiner:2011mp}\n\\bibitem{Greiner:2011mp}\n  N.~Greiner, A.~Guffanti, T.~Reiter and J.~Reuter,\n  {\\em NLO QCD corrections to the production of two bottom-antibottom\n    pairs at the LHC}\n  Phys.\\ Rev.\\ Lett.\\  {\\bf 107}, 102002 (2011)\n  [arXiv:1105.3624 [hep-ph]].\n  %% CITATION = ARXIV:1105.3624;%%\n\n%\\cite{L_Ecuyer:2002}\n\\bibitem{L_Ecuyer:2002}\n  P.~L\\'{e}Ecuyer, R.~Simard, E.~J.~Chen, and W.~D.~Kelton,\n  {\\em An Object-Oriented Random-Number Package with Many Long Streams and\n    Substreams},\n  Operations Research, vol. 50, no. 6, pp. 1073-1075, Dec. 2002.\n\n %\\cite{Platzer:2013esa}\n\\bibitem{Platzer:2013esa}\n  S.~Pl\\\"atzer,\n  {\\em RAMBO on diet},\n  [arXiv:1308.2922 [hep-ph]].\n  %% CITATION = ARXIV:1308.2922;%%\n\n%\\cite{Kleiss:1991rn}\n\\bibitem{Kleiss:1991rn}\n  R.~Kleiss and W.~J.~Stirling,\n  {\\em Massive multiplicities and Monte Carlo},\n  Nucl.\\ Phys.\\ B {\\bf 385}, 413 (1992).\n  doi:10.1016/0550-3213(92)90107-M\n  %%CITATION = doi:10.1016/0550-3213(92)90107-M;%%\n\n%\\cite{Kleiss:1985gy}\n\\bibitem{Kleiss:1985gy}\n  R.~Kleiss, W.~J.~Stirling and S.~D.~Ellis,\n  {\\em A New Monte Carlo Treatment of Multiparticle Phase Space at High-energies},\n  Comput.\\ Phys.\\ Commun.\\  {\\bf 40} (1986) 359.\n  doi:10.1016/0010-4655(86)90119-0\n  %% CITATION = doi:10.1016/0010-4655(86)90119-0;%%\n\n%\\cite{Brun:1997pa}\n\\bibitem{Brun:1997pa}\n  R.~Brun and F.~Rademakers,\n  {\\em ROOT: An object oriented data analysis framework},\n  Nucl. Instrum. Meth. A \\textbf{389}, 81-86 (1997)\n  doi:10.1016/S0168-9002(97)00048-X\n\n%\\cite{Buckley:2010ar}\n\\bibitem{Buckley:2010ar}\nA.~Buckley, J.~Butterworth, L.~L\\\"onnblad, D.~Grellscheid, H.~Hoeth, J.~Monk, H.~Schulz and F.~Siegert,\n{\\em Rivet user manual},\nComput. Phys. Commun. \\textbf{184}, 2803-2819 (2013)\ndoi:10.1016/j.cpc.2013.05.021\n[arXiv:1003.0694 [hep-ph]].\n\n%\\cite{Bierlich:2019rhm}\n\\bibitem{Bierlich:2019rhm}\nC.~Bierlich, A.~Buckley, J.~Butterworth, C.~H.~Christensen, L.~Corpe,\nD.~Grellscheid, J.~F.~Grosse-Oetringhaus, C.~Gutschow,\nP.~Karczmarczyk, J.~Klein, L.~L\\\"onnblad, C.~S.~Pollard, P.~Richardson,\nH.~Schulz and F.~Siegert, \n{\\em Robust Independent Validation of Experiment and Theory: Rivet\n  version 3}, \nSciPost Phys. \\textbf{8}, 026 (2020)\ndoi:10.21468/SciPostPhys.8.2.026\n[arXiv:1912.05451 [hep-ph]].\n\n%\\cite{deFavereau:2013fsa}\n\\bibitem{deFavereau:2013fsa}\nJ.~de Favereau \\textit{et al.} [DELPHES 3],\n{\\em DELPHES 3, A modular framework for fast simulation of a generic\n  collider experiment},\nJHEP \\textbf{02}, 057 (2014)\ndoi:10.1007/JHEP02(2014)057\n[arXiv:1307.6346 [hep-ex]]\n\n\\end{thebibliography}\n\n\\end{document}\n"
    },
    "skipped": [
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/.git/objects/pack/pack-94b2bee1258285441adcb607a8548c34dec3621d.idx",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/.git/objects/pack/pack-94b2bee1258285441adcb607a8548c34dec3621d.pack",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/circe1/share/doc/fit13.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/circe1/share/doc/dist78.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/circe1/share/doc/fit25.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/circe1/share/doc/figures1.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/circe1/share/doc/fit23.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/circe1/share/doc/fit15.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/circe1/share/doc/fit11.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/circe1/share/doc/fit12.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/circe1/share/doc/fit21.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/circe1/share/doc/fit22.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/omega/share/doc/mom_flow.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/omega/share/doc/omega-paper-1-pics-3.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/omega/share/doc/omega-paper-1-pics-6.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/omega/share/doc/ocamlweb.sty",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/omega/share/doc/bhabha.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/omega/share/doc/omega-paper-1-pics-8.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/omega/share/doc/omega-paper-1-pics-9.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/omega/share/doc/fusion_rules.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/omega/share/doc/omega-paper-1-pics-2.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/omega/share/doc/omega-paper-1-pics-4.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/omega/share/doc/epemudbardubar0.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/omega/share/doc/epemudbardubar.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/omega/share/doc/omega-paper-1-pics-1.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/omega/share/doc/bhabha0.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/omega/share/doc/mom_choice.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/omega/share/doc/omega-paper-1-pics-7.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/omega/share/doc/omega-paper-1-pics-5.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/omega/share/doc/modules.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/omega/share/doc/epemudbarmunumubar.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/omega/share/doc/epemudbarmunumubar0.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/omega/share/doc/omega-paper-1-pics-10.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/omega/share/doc/sign_ex.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/share/doc/resonance_n_photons.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/share/doc/resonance_n_hadron.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/share/doc/resonance_n_particles.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/share/doc/Z-lineshape_2.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/share/doc/Whizard-Logo.jpg",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/share/doc/whizstruct.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/share/doc/cc10_1.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/share/doc/flow4.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/share/doc/resonance_n_charged.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/share/doc/lep_higgs_3.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/share/doc/resonance_e_gam.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/share/doc/lep_higgs_1.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/share/doc/circe2-smoothing.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/share/doc/cc10_2.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/share/doc/lep_higgs_2.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/share/doc/Z-lineshape_1.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/share/doc/proc_4f-history.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/share/doc/resonance_n_visible.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/share/gui/public/images/favicon.ico",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/share/gui/public/fonts/glyphicons-halflings-regular.woff",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/share/gui/public/fonts/glyphicons-halflings-regular.eot",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/share/gui/public/fonts/glyphicons-halflings-regular.woff2",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/share/gui/public/fonts/glyphicons-halflings-regular.ttf",
        "/tmp/vanessa/spack-stage/spack-stage-whizard-master-k3ion6r4gto4y2m445q76c7w2lrexlkx/spack-src/circe2/share/doc/ocamlweb.sty"
    ],
    "total_files": 3451
}