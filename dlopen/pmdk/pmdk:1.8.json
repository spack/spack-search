{
    "matches": {
        "/tmp/vanessa/spack-stage/spack-stage-pmdk-1.8-vkfgscx7enzm2hpgfrtndnbmwkp76kum/spack-src/src/common/dlsym.h": "/*\n * Copyright 2016-2017, Intel Corporation\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n *\n *     * Redistributions of source code must retain the above copyright\n *       notice, this list of conditions and the following disclaimer.\n *\n *     * Redistributions in binary form must reproduce the above copyright\n *       notice, this list of conditions and the following disclaimer in\n *       the documentation and/or other materials provided with the\n *       distribution.\n *\n *     * Neither the name of the copyright holder nor the names of its\n *       contributors may be used to endorse or promote products derived\n *       from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n * \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n\n/*\n * dlsym.h -- dynamic linking utilities with library-specific implementation\n */\n\n#ifndef PMDK_DLSYM_H\n#define PMDK_DLSYM_H 1\n\n#include \"out.h\"\n\n#if defined(USE_LIBDL) && !defined(_WIN32)\n\n#include <dlfcn.h>\n\n/*\n * util_dlopen -- calls real dlopen()\n */\nstatic inline void *\nutil_dlopen(const char *filename)\n{\n\tLOG(3, \"filename %s\", filename);\n\n\treturn dlopen(filename, RTLD_NOW);\n}\n\n/*\n * util_dlerror -- calls real dlerror()\n */\nstatic inline char *\nutil_dlerror(void)\n{\n\treturn dlerror();\n}\n\n/*\n * util_dlsym -- calls real dlsym()\n */\nstatic inline void *\nutil_dlsym(void *handle, const char *symbol)\n{\n\tLOG(3, \"handle %p symbol %s\", handle, symbol);\n\n\treturn dlsym(handle, symbol);\n}\n\n/*\n * util_dlclose -- calls real dlclose()\n */\nstatic inline int\nutil_dlclose(void *handle)\n{\n\tLOG(3, \"handle %p\", handle);\n\n\treturn dlclose(handle);\n}\n\n#else /* empty functions */\n\n/*\n * util_dlopen -- empty function\n */\nstatic inline void *\nutil_dlopen(const char *filename)\n{\n\terrno = ENOSYS;\n\treturn NULL;\n}\n\n/*\n * util_dlerror -- empty function\n */\nstatic inline char *\nutil_dlerror(void)\n{\n\terrno = ENOSYS;\n\treturn NULL;\n}\n\n/*\n * util_dlsym -- empty function\n */\nstatic inline void *\nutil_dlsym(void *handle, const char *symbol)\n{\n\terrno = ENOSYS;\n\treturn NULL;\n}\n\n/*\n * util_dlclose -- empty function\n */\nstatic inline int\nutil_dlclose(void *handle)\n{\n\terrno = ENOSYS;\n\treturn 0;\n}\n\n#endif\n\n#endif\n",
        "/tmp/vanessa/spack-stage/spack-stage-pmdk-1.8-vkfgscx7enzm2hpgfrtndnbmwkp76kum/spack-src/src/common/set.c": "/*\n * Copyright 2015-2019, Intel Corporation\n * Copyright (c) 2016, Microsoft Corporation. All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n *\n *     * Redistributions of source code must retain the above copyright\n *       notice, this list of conditions and the following disclaimer.\n *\n *     * Redistributions in binary form must reproduce the above copyright\n *       notice, this list of conditions and the following disclaimer in\n *       the documentation and/or other materials provided with the\n *       distribution.\n *\n *     * Neither the name of the copyright holder nor the names of its\n *       contributors may be used to endorse or promote products derived\n *       from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n * \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n\n/*\n * set.c -- pool set utilities\n */\n\n#ifndef _GNU_SOURCE\n#define _GNU_SOURCE\n#endif\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <sys/stat.h>\n#include <sys/mman.h>\n#include <fcntl.h>\n#include <unistd.h>\n#include <stdint.h>\n#include <endian.h>\n#include <errno.h>\n#include <stddef.h>\n#include <time.h>\n#include <ctype.h>\n#include <linux/limits.h>\n#include <sys/mman.h>\n\n#include \"libpmem.h\"\n#include \"librpmem.h\"\n#include \"set.h\"\n#include \"file.h\"\n#include \"os.h\"\n#include \"mmap.h\"\n#include \"util.h\"\n#include \"out.h\"\n#include \"dlsym.h\"\n#include \"valgrind_internal.h\"\n#include \"sys_util.h\"\n#include \"util_pmem.h\"\n#include \"fs.h\"\n#include \"os_deep.h\"\n#include \"badblock.h\"\n\n#define LIBRARY_REMOTE \"librpmem.so.1\"\n#define SIZE_AUTODETECT_STR \"AUTO\"\n\n#define PMEM_EXT \".pmem\"\n#define PMEM_EXT_LEN sizeof(PMEM_EXT)\n#define PMEM_FILE_PADDING 6\n#define PMEM_FILE_NAME_MAX_LEN 20\n#define PMEM_FILE_MAX_LEN (PMEM_FILE_NAME_MAX_LEN + PMEM_FILE_PADDING)\n\nstatic RPMEMpool *(*Rpmem_create)(const char *target, const char *pool_set_name,\n\t\t\tvoid *pool_addr, size_t pool_size, unsigned *nlanes,\n\t\t\tconst struct rpmem_pool_attr *rpmem_attr);\nstatic RPMEMpool *(*Rpmem_open)(const char *target, const char *pool_set_name,\n\t\t\tvoid *pool_addr, size_t pool_size, unsigned *nlanes,\n\t\t\tstruct rpmem_pool_attr *rpmem_attr);\nint (*Rpmem_close)(RPMEMpool *rpp);\nint (*Rpmem_persist)(RPMEMpool *rpp, size_t offset, size_t length,\n\t\t\tunsigned lane, unsigned flags);\nint (*Rpmem_deep_persist)(RPMEMpool *rpp, size_t offset, size_t length,\n\t\t\tunsigned lane);\nint (*Rpmem_read)(RPMEMpool *rpp, void *buff, size_t offset,\n\t\tsize_t length, unsigned lane);\nint (*Rpmem_remove)(const char *target, const char *pool_set_name, int flags);\nint (*Rpmem_set_attr)(RPMEMpool *rpp, const struct rpmem_pool_attr *rattr);\n\nstatic int Remote_replication_available;\nstatic os_mutex_t Remote_lock;\nstatic void *Rpmem_handle_remote;\n\nint Prefault_at_open = 0;\nint Prefault_at_create = 0;\nint SDS_at_create = POOL_FEAT_INCOMPAT_DEFAULT & POOL_E_FEAT_SDS ? 1 : 0;\nint Fallocate_at_create = 1;\nint COW_at_open = 0;\n\n/* list of pool set option names and flags */\nstatic const struct pool_set_option Options[] = {\n\t{ \"SINGLEHDR\", OPTION_SINGLEHDR },\n#ifndef _WIN32\n\t{ \"NOHDRS\", OPTION_NOHDRS },\n#endif\n\t{ NULL, OPTION_UNKNOWN }\n};\n\n/*\n * util_remote_init -- initialize remote replication\n */\nvoid\nutil_remote_init(void)\n{\n\tLOG(3, NULL);\n\n\t/* XXX Is duplicate initialization really okay? */\n\tif (!Remote_replication_available) {\n\t\tutil_mutex_init(&Remote_lock);\n\t\tRemote_replication_available = 1;\n\t}\n}\n\n/*\n * util_remote_fini -- finalize remote replication\n */\nvoid\nutil_remote_fini(void)\n{\n\tLOG(3, NULL);\n\n\tutil_remote_unload();\n\n\t/* XXX Okay to be here if not initialized? */\n\tif (Remote_replication_available) {\n\t\tRemote_replication_available = 0;\n\t\tutil_mutex_destroy(&Remote_lock);\n\t}\n}\n\n/*\n * util_dl_check_error -- check libdl error\n */\nstatic int\nutil_dl_check_error(void *handle, const char *func)\n{\n\tLOG(15, \"handle %p func %s\", handle, func);\n\n\tif (handle == NULL) {\n\t\tchar *errstr = util_dlerror();\n\t\tif (errstr)\n\t\t\tERR(\"%s(): %s\", func, errstr);\n\t\terrno = ELIBACC;\n\t\treturn -1;\n\t}\n\treturn 0;\n}\n\n/*\n * util_remote_unload_core -- (internal) unload remote library (core function)\n */\nstatic void\nutil_remote_unload_core(void)\n{\n\tif (Rpmem_handle_remote != NULL) {\n\t\tutil_dlclose(Rpmem_handle_remote);\n\t\tRpmem_handle_remote = NULL;\n\t}\n\tRpmem_create = NULL;\n\tRpmem_open = NULL;\n\tRpmem_close = NULL;\n\tRpmem_persist = NULL;\n\tRpmem_deep_persist = NULL;\n\tRpmem_read = NULL;\n\tRpmem_remove = NULL;\n\tRpmem_set_attr = NULL;\n}\n\n/*\n * util_remote_unload -- unload remote library\n */\nvoid\nutil_remote_unload(void)\n{\n\tLOG(3, NULL);\n\n\tif (!Remote_replication_available)\n\t\treturn;\n\n\tutil_mutex_lock(&Remote_lock);\n\n\tutil_remote_unload_core();\n\n\tutil_mutex_unlock(&Remote_lock);\n}\n\n/*\n * util_remote_load -- load remote library\n */\nint\nutil_remote_load(void)\n{\n\tLOG(3, NULL);\n\n\tif (!Remote_replication_available) {\n\t\tERR(\"remote replication is not available\");\n\t\treturn -1;\n\t}\n\n\tCHECK_FUNC_COMPATIBLE(rpmem_create, *Rpmem_create);\n\tCHECK_FUNC_COMPATIBLE(rpmem_open, *Rpmem_open);\n\tCHECK_FUNC_COMPATIBLE(rpmem_close, *Rpmem_close);\n\tCHECK_FUNC_COMPATIBLE(rpmem_persist, *Rpmem_persist);\n\tCHECK_FUNC_COMPATIBLE(rpmem_deep_persist, *Rpmem_deep_persist);\n\tCHECK_FUNC_COMPATIBLE(rpmem_read, *Rpmem_read);\n\tCHECK_FUNC_COMPATIBLE(rpmem_remove, *Rpmem_remove);\n\n\tutil_mutex_lock(&Remote_lock);\n\n\tif (Rpmem_handle_remote)\n\t\tgoto end;\n\n\tRpmem_handle_remote = util_dlopen(LIBRARY_REMOTE);\n\tif (util_dl_check_error(Rpmem_handle_remote, \"dlopen\")) {\n\t\tERR(\"the pool set requires a remote replica, \"\n\t\t    \"but the '%s' library cannot be loaded\",\n\t\t    LIBRARY_REMOTE);\n\t\tgoto err;\n\t}\n\n\tRpmem_create = util_dlsym(Rpmem_handle_remote, \"rpmem_create\");\n\tif (util_dl_check_error(Rpmem_create, \"dlsym\")) {\n\t\tERR(\"symbol 'rpmem_create' not found\");\n\t\tgoto err;\n\t}\n\n\tRpmem_open = util_dlsym(Rpmem_handle_remote, \"rpmem_open\");\n\tif (util_dl_check_error(Rpmem_open, \"dlsym\")) {\n\t\tERR(\"symbol 'rpmem_open' not found\");\n\t\tgoto err;\n\t}\n\n\tRpmem_close = util_dlsym(Rpmem_handle_remote, \"rpmem_close\");\n\tif (util_dl_check_error(Rpmem_close, \"dlsym\")) {\n\t\tERR(\"symbol 'rpmem_close' not found\");\n\t\tgoto err;\n\t}\n\n\tRpmem_persist = util_dlsym(Rpmem_handle_remote, \"rpmem_persist\");\n\tif (util_dl_check_error(Rpmem_persist, \"dlsym\")) {\n\t\tERR(\"symbol 'rpmem_persist' not found\");\n\t\tgoto err;\n\t}\n\n\tRpmem_deep_persist = util_dlsym(Rpmem_handle_remote,\n\t\t\t\"rpmem_deep_persist\");\n\tif (util_dl_check_error(Rpmem_deep_persist, \"dlsym\")) {\n\t\tERR(\"symbol 'rpmem_deep_persist' not found\");\n\t\tgoto err;\n\t}\n\n\tRpmem_read = util_dlsym(Rpmem_handle_remote, \"rpmem_read\");\n\tif (util_dl_check_error(Rpmem_read, \"dlsym\")) {\n\t\tERR(\"symbol 'rpmem_read' not found\");\n\t\tgoto err;\n\t}\n\n\tRpmem_remove = util_dlsym(Rpmem_handle_remote, \"rpmem_remove\");\n\tif (util_dl_check_error(Rpmem_remove, \"dlsym\")) {\n\t\tERR(\"symbol 'rpmem_remove' not found\");\n\t\tgoto err;\n\t}\n\n\tRpmem_set_attr = util_dlsym(Rpmem_handle_remote, \"rpmem_set_attr\");\n\tif (util_dl_check_error(Rpmem_set_attr, \"dlsym\")) {\n\t\tERR(\"symbol 'rpmem_set_attr' not found\");\n\t\tgoto err;\n\t}\n\nend:\n\tutil_mutex_unlock(&Remote_lock);\n\treturn 0;\n\nerr:\n\tLOG(4, \"error clean up\");\n\tutil_remote_unload_core();\n\tutil_mutex_unlock(&Remote_lock);\n\treturn -1;\n}\n\n/* reserve space for size, path and some whitespace and/or comment */\n\nenum parser_codes {\n\tPARSER_CONTINUE = 0,\n\tPARSER_PMEMPOOLSET,\n\tPARSER_REPLICA,\n\tPARSER_INVALID_TOKEN,\n\tPARSER_REMOTE_REPLICA_EXPECTED,\n\tPARSER_WRONG_SIZE,\n\tPARSER_CANNOT_READ_SIZE,\n\tPARSER_ABSOLUTE_PATH_EXPECTED,\n\tPARSER_RELATIVE_PATH_EXPECTED,\n\tPARSER_SET_NO_PARTS,\n\tPARSER_REP_NO_PARTS,\n\tPARSER_REMOTE_REP_UNEXPECTED_PARTS,\n\tPARSER_SIZE_MISMATCH,\n\tPARSER_OUT_OF_MEMORY,\n\tPARSER_OPTION_UNKNOWN,\n\tPARSER_OPTION_EXPECTED,\n\tPARSER_FORMAT_OK,\n\tPARSER_MAX_CODE\n};\n\nstatic const char *parser_errstr[PARSER_MAX_CODE] = {\n\t\"\", /* parsing */\n\t\"the first line must be exactly 'PMEMPOOLSET'\",\n\t\"exactly 'REPLICA' expected\",\n\t\"invalid token found in the current line\",\n\t\"address of remote node and descriptor of remote pool set expected\",\n\t\"incorrect format of size\",\n\t\"cannot determine size of a part\",\n\t\"incorrect path (must be an absolute one)\",\n\t\"incorrect descriptor (must be a relative path)\",\n\t\"no pool set parts\",\n\t\"no replica parts\",\n\t\"unexpected parts for remote replica\",\n\t\"sizes of pool set and replica mismatch\",\n\t\"allocating memory failed\",\n\t\"unknown option\",\n\t\"missing option name\",\n\t\"\" /* format correct */\n};\n\n/*\n * util_replica_force_page_allocation - (internal) forces page allocation for\n * replica\n */\nstatic void\nutil_replica_force_page_allocation(struct pool_replica *rep)\n{\n\tvolatile char *cur_addr = rep->part[0].addr;\n\tchar *addr_end = (char *)cur_addr + rep->resvsize;\n\tfor (; cur_addr < addr_end; cur_addr += Pagesize) {\n\t\t*cur_addr = *cur_addr;\n\t\tVALGRIND_SET_CLEAN(cur_addr, 1);\n\t}\n}\n\n/*\n * util_map_hdr -- map a header of a pool set\n */\nint\nutil_map_hdr(struct pool_set_part *part, int flags, int rdonly)\n{\n\tLOG(3, \"part %p flags %d\", part, flags);\n\n\tCOMPILE_ERROR_ON(POOL_HDR_SIZE == 0);\n\tASSERTeq(POOL_HDR_SIZE % Pagesize, 0);\n\n\t/*\n\t * Workaround for Device DAX not allowing to map a portion\n\t * of the device if offset/length are not aligned to the internal\n\t * device alignment (page size).  I.e. if the device alignment\n\t * is 2M, we cannot map the 4K header, but need to align the mapping\n\t * length to 2M.\n\t *\n\t * According to mmap(2), system should automatically align mapping\n\t * length to be a multiple of the underlying page size, but it's\n\t * not true for Device DAX.\n\t */\n\tsize_t hdrsize = part->alignment > POOL_HDR_SIZE\n\t\t\t? part->alignment : POOL_HDR_SIZE;\n\n\tvoid *addr = NULL;\n\n#if VG_MEMCHECK_ENABLED\n\tif (On_valgrind) {\n\t\t/* this is required only for Device DAX & memcheck */\n\t\taddr = util_map_hint(hdrsize, hdrsize);\n\t\tif (addr == MAP_FAILED) {\n\t\t\tLOG(1, \"cannot find a contiguous region of given size\");\n\t\t\t/* there's nothing we can do */\n\t\t\treturn -1;\n\t\t}\n\t}\n#endif\n\n\tint prot = rdonly ? PROT_READ : PROT_READ|PROT_WRITE;\n\tvoid *hdrp = util_map_sync(addr, hdrsize, prot, flags,\n\t\t\tpart->fd, 0, &part->hdr_map_sync);\n\tif (hdrp == MAP_FAILED) {\n\t\tERR(\"!mmap: %s\", part->path);\n\t\treturn -1;\n\t}\n\n\tpart->hdrsize = hdrsize;\n\tpart->hdr = hdrp;\n\n\tVALGRIND_REGISTER_PMEM_MAPPING(part->hdr, part->hdrsize);\n\tVALGRIND_REGISTER_PMEM_FILE(part->fd, part->hdr, part->hdrsize, 0);\n\n\treturn 0;\n}\n\n/*\n * util_unmap_hdr -- unmap pool set part header\n */\nvoid\nutil_unmap_hdr(struct pool_set_part *part)\n{\n\tif (part->hdr == NULL || part->hdrsize == 0)\n\t\treturn;\n\n\tLOG(4, \"munmap: addr %p size %zu\", part->hdr, part->hdrsize);\n\tVALGRIND_REMOVE_PMEM_MAPPING(part->hdr, part->hdrsize);\n\tif (munmap(part->hdr, part->hdrsize) != 0)\n\t\t/* this means there's a bug on the caller side */\n\t\tFATAL(\"!munmap: %s\", part->path);\n\tpart->hdr = NULL;\n\tpart->hdrsize = 0;\n}\n\n/*\n * util_map_part -- map a part of a pool set\n */\nint\nutil_map_part(struct pool_set_part *part, void *addr, size_t size,\n\tsize_t offset, int flags, int rdonly)\n{\n\tLOG(3, \"part %p addr %p size %zu offset %zu flags %d\",\n\t\tpart, addr, size, offset, flags);\n\n\tASSERTeq((uintptr_t)addr % Mmap_align, 0);\n\tASSERTeq(offset % Mmap_align, 0);\n\tASSERTeq(size % Mmap_align, 0);\n\tASSERT(((os_off_t)offset) >= 0);\n\tASSERTeq(offset % part->alignment, 0);\n\tASSERT(offset < part->filesize);\n\n\tif (!size)\n\t\tsize = (part->filesize - offset) & ~(part->alignment - 1);\n\telse\n\t\tsize = roundup(size, part->alignment);\n\n\tint prot = rdonly ? PROT_READ : PROT_READ | PROT_WRITE;\n\tvoid *addrp = util_map_sync(addr, size, prot, flags, part->fd,\n\t\t\t(os_off_t)offset, &part->map_sync);\n\tif (addrp == MAP_FAILED) {\n\t\tERR(\"!mmap: %s\", part->path);\n\t\treturn -1;\n\t}\n\n\tif (addr != NULL && (flags & MAP_FIXED) && addrp != addr) {\n\t\tERR(\"unable to map at requested address %p\", addr);\n\t\tmunmap(addrp, size);\n\t\treturn -1;\n\t}\n\n\tpart->addr = addrp;\n\tpart->size = size;\n\n\tVALGRIND_REGISTER_PMEM_MAPPING(part->addr, part->size);\n\tVALGRIND_REGISTER_PMEM_FILE(part->fd, part->addr, part->size, offset);\n\n\treturn 0;\n}\n\n/*\n * util_unmap_part -- unmap a part of a pool set\n */\nint\nutil_unmap_part(struct pool_set_part *part)\n{\n\tLOG(3, \"part %p\", part);\n\n\tif (part->addr != NULL && part->size != 0) {\n\t\tLOG(4, \"munmap: addr %p size %zu\", part->addr, part->size);\n\t\tVALGRIND_REMOVE_PMEM_MAPPING(part->addr, part->size);\n\t\tif (munmap(part->addr, part->size) != 0) {\n\t\t\tERR(\"!munmap: %s\", part->path);\n\t\t}\n\n\t\tpart->addr = NULL;\n\t\tpart->size = 0;\n\t}\n\n\treturn 0;\n}\n\n/*\n * util_unmap_parts -- unmap parts from start_index to the end_index\n */\nint\nutil_unmap_parts(struct pool_replica *rep, unsigned start_index,\n\tunsigned end_index)\n{\n\tLOG(3, \"rep: %p, start_index: %u, end_index: %u\", rep, start_index,\n\t\tend_index);\n\n\tfor (unsigned p = start_index; p <= end_index; p++)\n\t\tutil_unmap_part(&rep->part[p]);\n\n\treturn 0;\n}\n\n/*\n * util_poolset_free -- free pool set info\n */\nvoid\nutil_poolset_free(struct pool_set *set)\n{\n\tLOG(3, \"set %p\", set);\n\n\tfor (unsigned r = 0; r < set->nreplicas; r++) {\n\t\tstruct pool_replica *rep = set->replica[r];\n\t\tif (rep->remote == NULL) {\n\t\t\t/* only local replicas have paths */\n\t\t\tfor (unsigned p = 0; p < rep->nallocated; p++) {\n\t\t\t\tFree((void *)(rep->part[p].path));\n\t\t\t}\n\t\t} else {\n\t\t\t/* remote replica */\n\t\t\tASSERTeq(rep->nparts, 1);\n\t\t\tFree(rep->remote->node_addr);\n\t\t\tFree(rep->remote->pool_desc);\n\t\t\tFree(rep->remote);\n\t\t}\n\t\tstruct pool_set_directory *d;\n\t\tVEC_FOREACH_BY_PTR(d, &rep->directory) {\n\t\t\tFree((void *)d->path);\n\t\t}\n\t\tVEC_DELETE(&rep->directory);\n\t\tFree(set->replica[r]);\n\t}\n\tFree(set->path);\n\tFree(set);\n}\n\n/*\n * util_poolset_open -- open all replicas from a poolset\n */\nint\nutil_poolset_open(struct pool_set *set)\n{\n\tfor (unsigned r = 0; r < set->nreplicas; ++r) {\n\t\tif (util_replica_open(set, r, MAP_SHARED)) {\n\t\t\tLOG(2, \"replica open failed: replica %u\", r);\n\t\t\terrno = EINVAL;\n\t\t\treturn -1;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n/*\n * util_replica_close_local -- close local replica, optionally delete the\n *                             replica's parts\n */\nint\nutil_replica_close_local(struct pool_replica *rep, unsigned repn,\n\t\tenum del_parts_mode del)\n{\n\tfor (unsigned p = 0; p < rep->nparts; p++) {\n\t\tif (rep->part[p].fd != -1)\n\t\t\t(void) os_close(rep->part[p].fd);\n\n\t\tif ((del == DELETE_CREATED_PARTS && rep->part[p].created) ||\n\t\t\t\tdel == DELETE_ALL_PARTS) {\n\t\t\tLOG(4, \"unlink %s\", rep->part[p].path);\n\t\t\tint olderrno = errno;\n\t\t\tif (util_unlink(rep->part[p].path) && errno != ENOENT) {\n\t\t\t\tERR(\"!unlink %s failed (part %u, replica %u)\",\n\t\t\t\t\t\trep->part[p].path, p, repn);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\terrno = olderrno;\n\t\t}\n\t}\n\treturn 0;\n}\n\n/*\n * util_replica_close_remote -- close remote replica, optionally delete the\n *                              replica\n */\nint\nutil_replica_close_remote(struct pool_replica *rep, unsigned repn,\n\t\tenum del_parts_mode del)\n{\n\tif (!rep->remote)\n\t\treturn 0;\n\n\tif (rep->remote->rpp) {\n\t\tLOG(4, \"closing remote replica #%u\", repn);\n\t\tRpmem_close(rep->remote->rpp);\n\t\trep->remote->rpp = NULL;\n\t}\n\n\tif ((del == DELETE_CREATED_PARTS && rep->part[0].created) ||\n\t\t\tdel == DELETE_ALL_PARTS) {\n\t\tLOG(4, \"removing remote replica #%u\", repn);\n\t\tint ret = Rpmem_remove(rep->remote->node_addr,\n\t\t\trep->remote->pool_desc, 0);\n\t\tif (ret) {\n\t\t\tLOG(1, \"!removing remote replica #%u failed\", repn);\n\t\t\treturn -1;\n\t\t}\n\t}\n\treturn 0;\n}\n\n/*\n * util_poolset_close -- unmap and close all the parts of the pool set,\n *                       optionally delete parts\n */\nvoid\nutil_poolset_close(struct pool_set *set, enum del_parts_mode del)\n{\n\tLOG(3, \"set %p del %d\", set, del);\n\n\tint oerrno = errno;\n\n\tfor (unsigned r = 0; r < set->nreplicas; r++) {\n\t\tutil_replica_close(set, r);\n\n\t\tstruct pool_replica *rep = set->replica[r];\n\t\tif (!rep->remote)\n\t\t\t(void) util_replica_close_local(rep, r, del);\n\t\telse\n\t\t\t(void) util_replica_close_remote(rep, r, del);\n\t}\n\n\t/*\n\t * XXX On FreeBSD, mmap()ing a file does not increment the flock()\n\t *     reference count, so we had to keep the files open until now.\n\t */\n#ifdef __FreeBSD__\n\tutil_poolset_fdclose_always(set);\n#endif\n\tutil_poolset_free(set);\n\n\terrno = oerrno;\n}\n\n/*\n * util_poolset_chmod -- change mode for all created files related to pool set\n */\nint\nutil_poolset_chmod(struct pool_set *set, mode_t mode)\n{\n\tLOG(3, \"set %p mode %o\", set, mode);\n\n\tfor (unsigned r = 0; r < set->nreplicas; r++) {\n\t\tstruct pool_replica *rep = set->replica[r];\n\n\t\t/* skip remote replicas */\n\t\tif (rep->remote != NULL)\n\t\t\tcontinue;\n\n\t\tfor (unsigned p = 0; p < rep->nparts; p++) {\n\t\t\tstruct pool_set_part *part = &rep->part[p];\n\n\t\t\t/* skip not created or closed parts */\n\t\t\tif (!part->created || part->fd == -1)\n\t\t\t\tcontinue;\n\n\t\t\tos_stat_t stbuf;\n\t\t\tif (os_fstat(part->fd, &stbuf) != 0) {\n\t\t\t\tERR(\"!fstat %d %s\", part->fd, part->path);\n\t\t\t\treturn -1;\n\t\t\t}\n\n\t\t\tif (stbuf.st_mode & ~(unsigned)S_IFMT) {\n\t\t\t\tLOG(1, \"file permissions changed during pool \"\n\t\t\t\t\t\"initialization, file: %s (%o)\",\n\t\t\t\t\tpart->path,\n\t\t\t\t\tstbuf.st_mode & ~(unsigned)S_IFMT);\n\t\t\t}\n\n\t\t\tif (os_chmod(part->path, mode)) {\n\t\t\t\tERR(\"!chmod %u/%u/%s\", r, p, part->path);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n/*\n * util_poolset_fdclose_always -- close file descriptors related to pool set\n */\nvoid\nutil_poolset_fdclose_always(struct pool_set *set)\n{\n\tLOG(3, \"set %p\", set);\n\n\tfor (unsigned r = 0; r < set->nreplicas; r++)\n\t\tutil_replica_fdclose(set->replica[r]);\n}\n\n/*\n * util_poolset_fdclose -- close pool set file descriptors if not FreeBSD\n *\n * XXX On FreeBSD, mmap()ing a file does not increment the flock()\n *\treference count, so we need to keep the files open.\n */\nvoid\nutil_poolset_fdclose(struct pool_set *set)\n{\n#ifdef __FreeBSD__\n\tLOG(3, \"set %p: holding open\", set);\n#else\n\tutil_poolset_fdclose_always(set);\n#endif\n}\n\n/*\n * util_autodetect_size -- (internal) retrieves size of an existing file\n */\nstatic ssize_t\nutil_autodetect_size(const char *path)\n{\n\tenum file_type type = util_file_get_type(path);\n\tif (type < 0)\n\t\treturn -1;\n\n\tif (type == TYPE_NORMAL) {\n\t\tERR(\"size autodetection is supported only for device dax\");\n\t\treturn -1;\n\t}\n\n\treturn util_file_get_size(path);\n}\n\n/*\n * parser_read_line -- (internal) read line and validate size and path\n *                      from a pool set file\n */\nstatic enum parser_codes\nparser_read_line(char *line, size_t *size, char **path)\n{\n\tint ret;\n\tchar *size_str;\n\tchar *path_str;\n\tchar *rest_str;\n\tchar *saveptr = NULL; /* must be NULL initialized on Windows */\n\n\tsize_str = strtok_r(line, \" \\t\", &saveptr);\n\tpath_str = strtok_r(NULL, \" \\t\", &saveptr);\n\trest_str = strtok_r(NULL, \" \\t\", &saveptr);\n\n\tif (!size_str || !path_str || rest_str)\n\t\treturn PARSER_INVALID_TOKEN;\n\n\tLOG(10, \"size '%s' path '%s'\", size_str, path_str);\n\n\t/*\n\t * A format of the size is checked in detail. As regards the path,\n\t * it is checked only if the read path is an absolute path.\n\t * The rest should be checked during creating/opening the file.\n\t */\n\n\t/* check if the read path is an absolute path */\n\tif (!util_is_absolute_path(path_str))\n\t\treturn PARSER_ABSOLUTE_PATH_EXPECTED;\n\n\t*path = Strdup(path_str);\n\tif (!(*path)) {\n\t\tERR(\"!Strdup\");\n\t\treturn PARSER_OUT_OF_MEMORY;\n\t}\n\n\tif (strcmp(SIZE_AUTODETECT_STR, size_str) == 0) {\n\t\t/*\n\t\t * XXX: this should be done after the parsing completes, but\n\t\t * currently this operation is performed in simply too many\n\t\t * places in the code to move this someplace else.\n\t\t */\n\t\tssize_t s = util_autodetect_size(path_str);\n\t\tif (s < 0) {\n\t\t\tFree(*path);\n\t\t\t*path = NULL;\n\t\t\treturn PARSER_CANNOT_READ_SIZE;\n\t\t}\n\n\t\t*size = (size_t)s;\n\n\t\treturn PARSER_CONTINUE;\n\t}\n\n\tret = util_parse_size(size_str, size);\n\tif (ret != 0 || *size == 0) {\n\t\tFree(*path);\n\t\t*path = NULL;\n\t\treturn PARSER_WRONG_SIZE;\n\t}\n\n\treturn PARSER_CONTINUE;\n}\n\n/*\n * parser_read_replica -- (internal) read line and validate remote replica\n *                        from a pool set file\n */\nstatic enum parser_codes\nparser_read_replica(char *line, char **node_addr, char **pool_desc)\n{\n\tchar *addr_str;\n\tchar *desc_str;\n\tchar *rest_str;\n\tchar *saveptr = NULL; /* must be NULL initialized on Windows */\n\n\taddr_str = strtok_r(line, \" \\t\", &saveptr);\n\tdesc_str = strtok_r(NULL, \" \\t\", &saveptr);\n\trest_str = strtok_r(NULL, \" \\t\", &saveptr);\n\n\tif (!addr_str || !desc_str)\n\t\treturn PARSER_REMOTE_REPLICA_EXPECTED;\n\n\tif (rest_str)\n\t\treturn PARSER_INVALID_TOKEN;\n\n\tLOG(10, \"node address '%s' pool set descriptor '%s'\",\n\t\taddr_str, desc_str);\n\n\t/* check if the descriptor is a relative path */\n\tif (util_is_absolute_path(desc_str))\n\t\treturn PARSER_RELATIVE_PATH_EXPECTED;\n\n\t*node_addr = Strdup(addr_str);\n\t*pool_desc = Strdup(desc_str);\n\n\tif (!(*node_addr) || !(*pool_desc)) {\n\t\tERR(\"!Strdup\");\n\t\tif (*node_addr)\n\t\t\tFree(*node_addr);\n\t\tif (*pool_desc)\n\t\t\tFree(*pool_desc);\n\t\treturn PARSER_OUT_OF_MEMORY;\n\t}\n\n\treturn PARSER_CONTINUE;\n}\n\n/*\n * parser_read_options -- (internal) read line and validate options\n */\nstatic enum parser_codes\nparser_read_options(char *line, unsigned *options)\n{\n\tLOG(3, \"line '%s'\", line);\n\n\tint opt_cnt = 0;\n\tchar *saveptr = NULL; /* must be NULL initialized on Windows */\n\n\tchar *opt_str = strtok_r(line, \" \\t\", &saveptr);\n\twhile (opt_str != NULL) {\n\t\tLOG(4, \"option '%s'\", opt_str);\n\n\t\tint i = 0;\n\t\twhile (Options[i].name && strcmp(opt_str, Options[i].name) != 0)\n\t\t\ti++;\n\n\t\tif (Options[i].name == NULL) {\n\t\t\tLOG(4, \"unknown option '%s'\", opt_str);\n\t\t\treturn PARSER_OPTION_UNKNOWN;\n\t\t}\n\n\t\tif (*options & Options[i].flag)\n\t\t\tLOG(4, \"duplicated option '%s'\", opt_str);\n\n\t\t*options |= Options[i].flag;\n\n\t\topt_cnt++;\n\t\topt_str = strtok_r(NULL, \" \\t\", &saveptr);\n\t}\n\n\tif (opt_cnt == 0)\n\t\treturn PARSER_OPTION_EXPECTED;\n\n\treturn PARSER_CONTINUE;\n}\n\n/*\n * util_replica_reserve -- reserves part slots capacity in a replica\n */\nstatic int\nutil_replica_reserve(struct pool_replica **repp, unsigned n)\n{\n\tLOG(3, \"replica %p n %u\", *repp, n);\n\n\tstruct pool_replica *rep = *repp;\n\tif (rep->nallocated >= n)\n\t\treturn 0;\n\n\trep = Realloc(rep, sizeof(struct pool_replica) +\n\t\t(n) * sizeof(struct pool_set_part));\n\tif (rep == NULL) {\n\t\tERR(\"!Realloc\");\n\t\treturn -1;\n\t}\n\n\tsize_t nsize = sizeof(struct pool_set_part) * (n - rep->nallocated);\n\tmemset(rep->part + rep->nallocated, 0, nsize);\n\n\trep->nallocated = n;\n\t*repp = rep;\n\n\treturn 0;\n}\n\n/*\n * util_replica_add_part_by_idx -- (internal) allocates, initializes and adds a\n *\tpart structure at the provided location in the replica info\n */\nstatic int\nutil_replica_add_part_by_idx(struct pool_replica **repp,\n\tconst char *path, size_t filesize, unsigned p)\n{\n\tLOG(3, \"replica %p path %s filesize %zu\", *repp, path, filesize);\n\n\tif (util_replica_reserve(repp, p + 1) != 0)\n\t\treturn -1;\n\n\tstruct pool_replica *rep = *repp;\n\tASSERTne(rep, NULL);\n\n\tint is_dev_dax = 0;\n\n\tif (path != NULL) {\n\t\tenum file_type type = util_file_get_type(path);\n\t\tif (type == OTHER_ERROR)\n\t\t\treturn -1;\n\n\t\tis_dev_dax = type == TYPE_DEVDAX;\n\t}\n\n\trep->part[p].path = path;\n\trep->part[p].filesize = filesize;\n\trep->part[p].fd = -1;\n\trep->part[p].is_dev_dax = is_dev_dax;\n\trep->part[p].created = 0;\n\trep->part[p].hdr = NULL;\n\trep->part[p].addr = NULL;\n\trep->part[p].remote_hdr = NULL;\n\trep->part[p].has_bad_blocks = 0;\n\n\tif (is_dev_dax)\n\t\trep->part[p].alignment = util_file_device_dax_alignment(path);\n\telse\n\t\trep->part[p].alignment = Mmap_align;\n\n\tASSERTne(rep->part[p].alignment, 0);\n\n\trep->nparts += 1;\n\n\treturn 0;\n}\n\n/*\n * util_replica_add_part -- adds a next part in replica info\n */\nstatic int\nutil_replica_add_part(struct pool_replica **repp,\n\tconst char *path, size_t filesize)\n{\n\tLOG(3, \"replica %p path \\\"%s\\\" filesize %zu\", *repp, path, filesize);\n\n\treturn util_replica_add_part_by_idx(repp, path,\n\t\tfilesize, (*repp)->nparts);\n}\n\n/*\n * util_parse_add_part -- (internal) add a new part file to the replica info\n */\nstatic int\nutil_parse_add_part(struct pool_set *set, const char *path, size_t filesize)\n{\n\tLOG(3, \"set %p path %s filesize %zu\", set, path, filesize);\n\n\tASSERTne(set, NULL);\n\n\tif (set->directory_based) {\n\t\tERR(\"cannot mix directories and files in a set\");\n\t\terrno = EINVAL;\n\t\treturn -1;\n\t}\n\n\treturn util_replica_add_part(&set->replica[set->nreplicas - 1],\n\t\tpath, filesize);\n}\n\n/*\n * util_parse_add_directory --\n *\t(internal) add a new directory to the replica info\n */\nstatic int\nutil_parse_add_directory(struct pool_set *set, const char *path,\n\tsize_t filesize)\n{\n\tLOG(3, \"set %p path %s filesize %zu\", set, path, filesize);\n\n\tASSERTne(set, NULL);\n\n\tstruct pool_replica *rep = set->replica[set->nreplicas - 1];\n\tASSERTne(rep, NULL);\n\n\tif (set->directory_based == 0) {\n\t\tif (rep->nparts > 0 || set->nreplicas > 1) {\n\t\t\tERR(\"cannot mix directories and files in a set\");\n\t\t\terrno = EINVAL;\n\t\t\treturn -1;\n\t\t}\n\t\tset->directory_based = 1;\n\t}\n\n\tchar *rpath = util_part_realpath(path);\n\tif (rpath == NULL) {\n\t\tERR(\"cannot resolve realpath of new directory\");\n\t\treturn -1;\n\t}\n\n\tfor (unsigned i = 0; i < set->nreplicas; ++i) {\n\t\tstruct pool_replica *r = set->replica[i];\n\t\tstruct pool_set_directory *dir;\n\t\tchar *dpath = NULL;\n\t\tVEC_FOREACH_BY_PTR(dir, &r->directory) {\n\t\t\tdpath = util_part_realpath(dir->path);\n\t\t\tASSERTne(dpath, NULL); /* must have been resolved */\n\t\t\tif (strcmp(rpath, dpath) == 0) {\n\t\t\t\tERR(\"cannot use the same directory twice\");\n\t\t\t\terrno = EEXIST;\n\t\t\t\tfree(dpath);\n\t\t\t\tfree(rpath);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tfree(dpath);\n\t\t}\n\t}\n\tfree(rpath);\n\n\tstruct pool_set_directory d;\n\td.path = path;\n\td.resvsize = filesize;\n\n\tif (VEC_PUSH_BACK(&rep->directory, d) != 0)\n\t\treturn -1;\n\n\trep->resvsize += filesize;\n\n\treturn 0;\n}\n\n/*\n * util_parse_add_element --\n *\t(internal) add a new element to the replica info\n */\nstatic int\nutil_parse_add_element(struct pool_set *set, const char *path, size_t filesize)\n{\n\tLOG(3, \"set %p path %s filesize %zu\", set, path, filesize);\n\n\tos_stat_t stat;\n\n\tint olderrno = errno;\n\n\tif (os_stat(path, &stat) == 0 && S_ISDIR(stat.st_mode))\n\t\treturn util_parse_add_directory(set, path, filesize);\n\n\terrno = olderrno;\n\n\treturn util_parse_add_part(set, path, filesize);\n}\n\n/*\n * util_parse_add_replica -- (internal) add a new replica to the pool set info\n */\nstatic int\nutil_parse_add_replica(struct pool_set **setp)\n{\n\tLOG(3, \"setp %p\", setp);\n\n\tASSERTne(setp, NULL);\n\n\tstruct pool_set *set = *setp;\n\tASSERTne(set, NULL);\n\n\tset = Realloc(set, sizeof(struct pool_set) +\n\t\t\t(set->nreplicas + 1) * sizeof(struct pool_replica *));\n\tif (set == NULL) {\n\t\tERR(\"!Realloc\");\n\t\treturn -1;\n\t}\n\t*setp = set;\n\n\tstruct pool_replica *rep;\n\trep = Zalloc(sizeof(struct pool_replica));\n\tif (rep == NULL) {\n\t\tERR(\"!Zalloc\");\n\t\treturn -1;\n\t}\n\n\tVEC_INIT(&rep->directory);\n\n\tunsigned r = set->nreplicas++;\n\n\tset->replica[r] = rep;\n\n\treturn 0;\n}\n\n/*\n * util_replica_check_map_sync -- (internal) check MAP_SYNC restrictions\n */\nstatic int\nutil_replica_check_map_sync(struct pool_set *set, unsigned repidx,\n\tint check_hdr)\n{\n\tLOG(3, \"set %p repidx %u\", set, repidx);\n\n\tstruct pool_replica *rep = set->replica[repidx];\n\n\tint map_sync = rep->part[0].map_sync;\n\n\tfor (unsigned p = 1; p < rep->nparts; p++) {\n\t\tif (map_sync != rep->part[p].map_sync) {\n\t\t\tERR(\"replica #%u part %u %smapped with MAP_SYNC\",\n\t\t\t\trepidx, p, rep->part[p].map_sync ? \"\" : \"not\");\n\t\t\treturn -1;\n\t\t}\n\t}\n\n\tif (check_hdr) {\n\t\tfor (unsigned p = 0; p < rep->nhdrs; p++) {\n\t\t\tif (map_sync != rep->part[p].hdr_map_sync) {\n\t\t\t\tERR(\"replica #%u part %u header %smapped \"\n\t\t\t\t\t\"with MAP_SYNC\", repidx, p,\n\t\t\t\t\trep->part[p].hdr_map_sync ?\n\t\t\t\t\t\"\" : \"not\");\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n/*\n * util_poolset_check_devdax -- (internal) check Device DAX restrictions\n */\nstatic int\nutil_poolset_check_devdax(struct pool_set *set)\n{\n\tLOG(3, \"set %p\", set);\n\n\tif (set->directory_based)\n\t\treturn 0;\n\n\tfor (unsigned r = 0; r < set->nreplicas; r++) {\n\t\tstruct pool_replica *rep = set->replica[r];\n\t\tint is_dev_dax = rep->part[0].is_dev_dax;\n\n\t\tfor (unsigned p = 0; p < rep->nparts; p++) {\n\t\t\tif (rep->part[p].is_dev_dax != is_dev_dax) {\n\t\t\t\tERR(\n\t\t\t\t\t\"either all the parts must be Device DAX or none\");\n\t\t\t\treturn -1;\n\t\t\t}\n\n\t\t\tif (is_dev_dax && rep->nparts > 1 &&\n\t\t\t\t\t(set->options & (OPTION_SINGLEHDR |\n\t\t\t\t\tOPTION_NOHDRS)) == 0 &&\n\t\t\t    util_file_device_dax_alignment(rep->part[p].path)\n\t\t\t\t\t!= Pagesize) {\n\t\t\t\tERR(\n\t\t\t\t\t\"Multiple DAX devices with alignment other than 4KB. Use the SINGLEHDR poolset option.\");\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t}\n\t}\n\treturn 0;\n}\n\n/*\n * util_poolset_check_options -- (internal) check if poolset options are\n *                               admissible\n */\nstatic int\nutil_poolset_check_options(struct pool_set *set)\n{\n\tLOG(3, \"set %p\", set);\n\tif ((set->options & OPTION_SINGLEHDR) &&\n\t\t\t(set->options & OPTION_NOHDRS)) {\n\t\tERR(\n\t\t\"both SINGLEHDR and NOHDR poolset options used at the same time\");\n\t\treturn -1;\n\t}\n\treturn 0;\n}\n\n/*\n * util_poolset_set_size -- (internal) calculate pool size\n */\nstatic void\nutil_poolset_set_size(struct pool_set *set)\n{\n\tLOG(3, \"set %p\", set);\n\n\tset->poolsize = SIZE_MAX;\n\tset->resvsize = SIZE_MAX;\n\n\tfor (unsigned r = 0; r < set->nreplicas; r++) {\n\t\tstruct pool_replica *rep = set->replica[r];\n\n\t\tif (set->options & OPTION_SINGLEHDR)\n\t\t\trep->nhdrs = 1;\n\t\telse if (set->options & OPTION_NOHDRS)\n\t\t\trep->nhdrs = 0;\n\t\telse\n\t\t\trep->nhdrs = rep->nparts;\n\n\t\trep->repsize = 0;\n\t\tfor (unsigned p = 0; p < rep->nparts; p++) {\n\t\t\trep->repsize +=\n\t\t\t\t(rep->part[p].filesize & ~(Mmap_align - 1));\n\t\t}\n\t\tif (rep->nhdrs > 0)\n\t\t\trep->repsize -= (rep->nhdrs - 1) * Mmap_align;\n\n\t\tif (rep->resvsize == 0)\n\t\t\trep->resvsize = rep->repsize;\n\n\t\t/*\n\t\t * Calculate pool size - choose the smallest replica size.\n\t\t * Ignore remote replicas.\n\t\t */\n\t\tif (rep->remote == NULL && rep->repsize < set->poolsize)\n\t\t\tset->poolsize = rep->repsize;\n\t\tif (rep->remote == NULL && rep->resvsize < set->resvsize)\n\t\t\tset->resvsize = rep->resvsize;\n\t}\n\n\tLOG(3, \"pool size set to %zu\", set->poolsize);\n}\n\n/*\n * util_parse_add_remote_replica -- (internal) add a new remote replica\n *                                  to the pool set info\n */\nstatic int\nutil_parse_add_remote_replica(struct pool_set **setp, char *node_addr,\n\t\t\t\tchar *pool_desc)\n{\n\tLOG(3, \"setp %p node_addr %s pool_desc %s\", setp, node_addr, pool_desc);\n\n\tASSERTne(setp, NULL);\n\tASSERTne(node_addr, NULL);\n\tASSERTne(pool_desc, NULL);\n\n\tint ret = util_parse_add_replica(setp);\n\tif (ret != 0)\n\t\treturn ret;\n\n\t/*\n\t * A remote replica has one fake part of size equal twice pool header\n\t * size for storing pool header and pool descriptor.\n\t */\n\tret = util_parse_add_part(*setp, NULL, 2 * POOL_HDR_SIZE);\n\tif (ret != 0)\n\t\treturn ret;\n\n\tstruct pool_set *set = *setp;\n\tstruct pool_replica *rep = set->replica[set->nreplicas - 1];\n\tASSERTne(rep, NULL);\n\n\trep->remote = Zalloc(sizeof(struct remote_replica));\n\tif (rep->remote == NULL) {\n\t\tERR(\"!Malloc\");\n\t\treturn -1;\n\t}\n\trep->remote->node_addr = node_addr;\n\trep->remote->pool_desc = pool_desc;\n\tset->remote = 1;\n\n\treturn 0;\n}\n\n/*\n * util_part_idx_by_file_name -- (internal) retrieves the part index from a\n *\tname of the file that is an element of a directory poolset\n */\nstatic long\nutil_part_idx_by_file_name(const char *filename)\n{\n\tLOG(3, \"filename \\\"%s\\\"\", filename);\n\n\tint olderrno = errno;\n\terrno = 0;\n\tlong part_idx = strtol(filename, NULL, 10);\n\tif (errno != 0)\n\t\treturn -1;\n\n\terrno = olderrno;\n\n\treturn part_idx;\n}\n\n/*\n * util_poolset_directory_load -- (internal) loads and initializes all\n *\texisting parts in a single directory\n */\nstatic int\nutil_poolset_directory_load(struct pool_replica **repp, const char *directory)\n{\n\tLOG(3, \"rep %p dir \\\"%s\\\"\", *repp, directory);\n\n\tstruct fs *f = fs_new(directory);\n\tif (f == NULL) {\n\t\tERR(\"!fs_new: \\\"%s\\\"\", directory);\n\t\treturn -1;\n\t}\n\n\tint nparts = 0;\n\tchar *path = NULL;\n\n\tstruct fs_entry *entry;\n\twhile ((entry = fs_read(f)) != NULL) {\n\t\tif (entry->level != 1)\n\t\t\tcontinue;\n\t\tif (entry->type != FS_ENTRY_FILE)\n\t\t\tcontinue;\n\t\tif (entry->namelen < PMEM_EXT_LEN)\n\t\t\tcontinue;\n\t\tconst char *ext = entry->path + entry->pathlen -\n\t\t\tPMEM_EXT_LEN + 1;\n\t\tif (strcmp(PMEM_EXT, ext) != 0)\n\t\t\tcontinue;\n\n\t\tlong part_idx = util_part_idx_by_file_name(entry->name);\n\t\tif (part_idx < 0)\n\t\t\tcontinue;\n\n\t\tssize_t size = util_file_get_size(entry->path);\n\t\tif (size < 0) {\n\t\t\tLOG(2,\n\t\t\t\"cannot read size of file (%s) in a poolset directory\",\n\t\t\tentry->path);\n\t\t\tgoto err;\n\t\t}\n\n\t\tif ((path = Strdup(entry->path)) == NULL) {\n\t\t\tERR(\"!Strdup\");\n\t\t\tgoto err;\n\t\t}\n\n\t\tif (util_replica_add_part_by_idx(repp, path,\n\t\t\t\t(size_t)size, (unsigned)part_idx) != 0) {\n\t\t\tERR(\"unable to load part %s\", entry->path);\n\t\t\tgoto err;\n\t\t}\n\t\tnparts++;\n\t}\n\n\tfs_delete(f);\n\treturn nparts;\n\nerr:\n\tfs_delete(f);\n\treturn -1;\n}\n\n/*\n * util_poolset_directories_load -- (internal) loads and initializes all\n *\texisting parts in the poolset directories\n */\nstatic int\nutil_poolset_directories_load(struct pool_set *set)\n{\n\tLOG(3, \"set %p\", set);\n\n\tif (!set->directory_based)\n\t\treturn 0;\n\n\tunsigned next_part_id = 0;\n\tunsigned max_parts_rep = 0;\n\tfor (unsigned r = 0; r < set->nreplicas; r++) {\n\t\tnext_part_id = 0;\n\n\t\tstruct pool_set_directory *d;\n\t\tint nparts = 0;\n\t\tint prev_nparts = 0;\n\t\tVEC_FOREACH_BY_PTR(d, &set->replica[r]->directory) {\n\t\t\tprev_nparts = nparts;\n\t\t\tnparts = util_poolset_directory_load(&set->replica[r],\n\t\t\t\td->path);\n\t\t\tif (nparts < 0) {\n\t\t\t\tERR(\"failed to load parts from directory %s\",\n\t\t\t\t\td->path);\n\t\t\t\treturn -1;\n\t\t\t}\n\n\t\t\tnext_part_id += (unsigned)nparts;\n\n\t\t\t/* always try to evenly spread files across dirs */\n\t\t\tif (r == 0 && prev_nparts > nparts)\n\t\t\t\tset->next_directory_id++;\n\t\t}\n\n\t\tif (next_part_id > set->replica[max_parts_rep]->nparts)\n\t\t\tmax_parts_rep = r;\n\n\t\tif (r == 0)\n\t\t\tset->next_id = next_part_id;\n\t}\n\n\t/*\n\t * In order to maintain the same semantics of poolset parsing for\n\t * regular poolsets and directory poolsets, we need to speculatively\n\t * recreate the information regarding any missing parts in replicas.\n\t */\n\tstruct pool_replica *rep;\n\tstruct pool_replica *mrep = set->replica[max_parts_rep];\n\n\tfor (unsigned r = 0; r < set->nreplicas; r++) {\n\t\tif (set->replica[r]->nparts == mrep->nparts)\n\t\t\tcontinue;\n\n\t\tif (VEC_SIZE(&set->replica[r]->directory) == 0) {\n\t\t\terrno = ENOENT;\n\t\t\tERR(\"!no directories in replica\");\n\t\t\treturn -1;\n\t\t}\n\n\t\tif (util_replica_reserve(&set->replica[r], mrep->nparts) != 0)\n\t\t\treturn -1;\n\n\t\trep = set->replica[r];\n\n\t\tstruct pool_set_directory *d = VEC_GET(&rep->directory, 0);\n\n\t\tfor (unsigned pidx = 0; pidx < rep->nallocated; ++pidx) {\n\t\t\tstruct pool_set_part *p = &rep->part[pidx];\n\t\t\t*p = mrep->part[pidx];\n\n\t\t\tsize_t path_len = strlen(d->path) + PMEM_FILE_MAX_LEN;\n\t\t\tif ((p->path = Malloc(path_len)) == NULL) {\n\t\t\t\tERR(\"!Malloc\");\n\t\t\t\treturn -1;\n\t\t\t}\n\n\t\t\tsnprintf((char *)p->path, path_len,\n\t\t\t\t\t\"%s\" OS_DIR_SEP_STR \"%0*u%s\",\n\t\t\t\t\td->path, PMEM_FILE_PADDING,\n\t\t\t\t\tpidx, PMEM_EXT);\n\t\t}\n\t\trep->nparts = mrep->nparts;\n\t}\n\n\treturn 0;\n}\n\n/*\n * util_poolset_parse -- parse pool set config file\n *\n * Returns 0 if the file is a valid poolset config file,\n * and -1 in case of any error.\n *\n * XXX: use memory mapped file\n */\nint\nutil_poolset_parse(struct pool_set **setp, const char *path, int fd)\n{\n\tLOG(3, \"setp %p path %s fd %d\", setp, path, fd);\n\n\tstruct pool_set *set = NULL;\n\tenum parser_codes result;\n\tchar *line;\n\tchar *ppath;\n\tchar *pool_desc;\n\tchar *node_addr;\n\tchar *cp;\n\tsize_t psize;\n\tFILE *fs;\n\tint oerrno;\n\n\tif (os_lseek(fd, 0, SEEK_SET) != 0) {\n\t\tERR(\"!lseek %d\", fd);\n\t\treturn -1;\n\t}\n\n\tfd = dup(fd);\n\tif (fd < 0) {\n\t\tERR(\"!dup\");\n\t\treturn -1;\n\t}\n\n\t/* associate a stream with the file descriptor */\n\tif ((fs = os_fdopen(fd, \"r\")) == NULL) {\n\t\tERR(\"!fdopen %d\", fd);\n\t\tos_close(fd);\n\t\treturn -1;\n\t}\n\n\tunsigned nlines = 0;\n\tunsigned nparts = 0; /* number of parts in current replica */\n\n\t/* read the first line */\n\tline = util_readline(fs);\n\tif (line == NULL) {\n\t\tERR(\"!Reading poolset file\");\n\t\tgoto err;\n\t}\n\tnlines++;\n\n\tset = Zalloc(sizeof(struct pool_set));\n\tif (set == NULL) {\n\t\tERR(\"!Malloc for pool set\");\n\t\tgoto err;\n\t}\n\n\tset->path = Strdup(path);\n\tif (set->path == NULL)  {\n\t\tERR(\"!Strdup\");\n\t\tgoto err;\n\t}\n\n\t/* check also if the last character is '\\n' */\n\tif (strncmp(line, POOLSET_HDR_SIG, POOLSET_HDR_SIG_LEN) == 0 &&\n\t    line[POOLSET_HDR_SIG_LEN] == '\\n') {\n\t\t/* 'PMEMPOOLSET' signature detected */\n\t\tLOG(10, \"PMEMPOOLSET\");\n\n\t\tint ret = util_parse_add_replica(&set);\n\t\tif (ret != 0)\n\t\t\tgoto err;\n\n\t\tnparts = 0;\n\t\tresult = PARSER_CONTINUE;\n\t} else {\n\t\tresult = PARSER_PMEMPOOLSET;\n\t}\n\n\twhile (result == PARSER_CONTINUE) {\n\t\tFree(line);\n\t\t/* read next line */\n\t\tline = util_readline(fs);\n\t\tnlines++;\n\n\t\tif (line) {\n\t\t\t/* chop off newline and comments */\n\t\t\tif ((cp = strchr(line, '\\n')) != NULL)\n\t\t\t\t*cp = '\\0';\n\t\t\tif (cp != line && (cp = strchr(line, '#')) != NULL)\n\t\t\t\t*cp = '\\0';\n\n\t\t\t/* skip comments and blank lines */\n\t\t\tif (cp == line)\n\t\t\t\tcontinue;\n\t\t}\n\n\t\tif (!line) {\n\t\t\tif (nparts >= 1) {\n\t\t\t\tresult = PARSER_FORMAT_OK;\n\t\t\t} else {\n\t\t\t\tif (set->nreplicas == 1)\n\t\t\t\t\tresult = PARSER_SET_NO_PARTS;\n\t\t\t\telse\n\t\t\t\t\tresult = PARSER_REP_NO_PARTS;\n\t\t\t}\n\t\t} else if (strncmp(line, POOLSET_OPTION_SIG,\n\t\t\t\t\tPOOLSET_OPTION_SIG_LEN) == 0) {\n\t\t\tresult = parser_read_options(\n\t\t\t\t\tline + POOLSET_OPTION_SIG_LEN,\n\t\t\t\t\t&set->options);\n\t\t\tif (result == PARSER_CONTINUE) {\n\t\t\t\tLOG(10, \"OPTIONS: %x\", set->options);\n\t\t\t}\n\t\t} else if (strncmp(line, POOLSET_REPLICA_SIG,\n\t\t\t\t\tPOOLSET_REPLICA_SIG_LEN) == 0) {\n\t\t\tif (line[POOLSET_REPLICA_SIG_LEN] != '\\0') {\n\t\t\t\t/* something more than 'REPLICA' */\n\t\t\t\tchar c = line[POOLSET_REPLICA_SIG_LEN];\n\t\t\t\tif (!isblank((unsigned char)c)) {\n\t\t\t\t\tresult = PARSER_REPLICA;\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\t/* check if it is a remote replica */\n\t\t\t\tresult = parser_read_replica(\n\t\t\t\t\t\tline + POOLSET_REPLICA_SIG_LEN,\n\t\t\t\t\t\t&node_addr, &pool_desc);\n\t\t\t\tif (result == PARSER_CONTINUE) {\n\t\t\t\t\t/* remote REPLICA */\n\t\t\t\t\tLOG(10, \"REMOTE REPLICA \"\n\t\t\t\t\t\t\"node address '%s' \"\n\t\t\t\t\t\t\"pool set descriptor '%s'\",\n\t\t\t\t\t\tnode_addr, pool_desc);\n\t\t\t\t\tif (util_parse_add_remote_replica(&set,\n\t\t\t\t\t\t\tnode_addr, pool_desc))\n\t\t\t\t\t\tgoto err;\n\t\t\t\t}\n\t\t\t} else if (nparts >= 1) {\n\t\t\t\t/* 'REPLICA' signature detected */\n\t\t\t\tLOG(10, \"REPLICA\");\n\n\t\t\t\tint ret = util_parse_add_replica(&set);\n\t\t\t\tif (ret != 0)\n\t\t\t\t\tgoto err;\n\n\t\t\t\tnparts = 0;\n\t\t\t\tresult = PARSER_CONTINUE;\n\t\t\t} else {\n\t\t\t\tif (set->nreplicas == 1)\n\t\t\t\t\tresult = PARSER_SET_NO_PARTS;\n\t\t\t\telse\n\t\t\t\t\tresult = PARSER_REP_NO_PARTS;\n\t\t\t}\n\t\t} else {\n\t\t\t/* there could be no parts for remote replicas */\n\t\t\tif (set->replica[set->nreplicas - 1]->remote) {\n\t\t\t\tresult = PARSER_REMOTE_REP_UNEXPECTED_PARTS;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t/* read size and path */\n\t\t\tresult = parser_read_line(line, &psize, &ppath);\n\t\t\tif (result == PARSER_CONTINUE) {\n\t\t\t\t/* add a new pool's part to the list */\n\t\t\t\tint ret = util_parse_add_element(set,\n\t\t\t\t\tppath, psize);\n\t\t\t\tif (ret != 0) {\n\t\t\t\t\tFree(ppath);\n\t\t\t\t\tgoto err;\n\t\t\t\t}\n\t\t\t\tnparts++;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (result != PARSER_FORMAT_OK) {\n\t\tERR(\"%s [%s:%d]\", path, parser_errstr[result], nlines);\n\t\tswitch (result) {\n\t\tcase PARSER_CANNOT_READ_SIZE:\n\t\tcase PARSER_OUT_OF_MEMORY:\n\t\t\t/* do not overwrite errno */\n\t\t\tbreak;\n\t\tdefault:\n\t\t\terrno = EINVAL;\n\t\t}\n\t\tgoto err;\n\t}\n\n\tif (util_poolset_check_devdax(set) != 0) {\n\t\terrno = EINVAL;\n\t\tgoto err;\n\t}\n\n\tif (util_poolset_directories_load(set) != 0) {\n\t\tERR(\"cannot load part files from directories\");\n\t\tgoto err;\n\t}\n\n\tLOG(4, \"set file format correct (%s)\", path);\n\t(void) os_fclose(fs);\n\tFree(line);\n\tutil_poolset_check_options(set);\n\tutil_poolset_set_size(set);\n\t*setp = set;\n\treturn 0;\n\nerr:\n\toerrno = errno;\n\tFree(line);\n\t(void) os_fclose(fs);\n\tif (set)\n\t\tutil_poolset_free(set);\n\terrno = oerrno;\n\treturn -1;\n}\n\n/*\n * util_poolset_single -- (internal) create a one-part pool set\n *\n * On success returns a pointer to a newly allocated and initialized\n * pool set structure.  Otherwise, NULL is returned.\n */\nstatic struct pool_set *\nutil_poolset_single(const char *path, size_t filesize, int create,\n\tint ignore_sds)\n{\n\tLOG(3, \"path %s filesize %zu create %d\",\n\t\t\tpath, filesize, create);\n\n\tenum file_type type = util_file_get_type(path);\n\tif (type == OTHER_ERROR)\n\t\treturn NULL;\n\n\tstruct pool_set *set;\n\tset = Zalloc(sizeof(struct pool_set) +\n\t\t\tsizeof(struct pool_replica *));\n\tif (set == NULL) {\n\t\tERR(\"!Malloc for pool set\");\n\t\treturn NULL;\n\t}\n\n\tset->path = Strdup(path);\n\tif (set->path == NULL)  {\n\t\tERR(\"!Strdup\");\n\t\tFree(set);\n\t\treturn NULL;\n\t}\n\n\tstruct pool_replica *rep;\n\trep = Zalloc(sizeof(struct pool_replica) +\n\t\t\tsizeof(struct pool_set_part));\n\tif (rep == NULL) {\n\t\tERR(\"!Malloc for pool set replica\");\n\t\tFree(set->path);\n\t\tFree(set);\n\t\treturn NULL;\n\t}\n\n\tVEC_INIT(&rep->directory);\n\n\tset->replica[0] = rep;\n\n\trep->part[0].filesize = filesize;\n\trep->part[0].path = Strdup(path);\n\trep->part[0].fd = -1;\t/* will be filled out by util_poolset_file() */\n\trep->part[0].is_dev_dax = type == TYPE_DEVDAX;\n\trep->part[0].created = create;\n\trep->part[0].hdr = NULL;\n\trep->part[0].addr = NULL;\n\trep->part[0].has_bad_blocks = 0;\n\n\tif (rep->part[0].is_dev_dax)\n\t\trep->part[0].alignment = util_file_device_dax_alignment(path);\n\telse\n\t\trep->part[0].alignment = Mmap_align;\n\n\tASSERTne(rep->part[0].alignment, 0);\n\n\trep->nallocated = 1;\n\trep->nparts = 1;\n\trep->nhdrs = 1;\n\n\t/* it does not have a remote replica */\n\trep->remote = NULL;\n\tset->remote = 0;\n\n\t/* round down to the nearest mapping alignment boundary */\n\trep->repsize = rep->part[0].filesize & ~(rep->part[0].alignment - 1);\n\trep->resvsize = rep->repsize;\n\n\tset->poolsize = rep->repsize;\n\tset->resvsize = rep->resvsize;\n\n\tset->nreplicas = 1;\n\tset->ignore_sds = ignore_sds || (set->options & OPTION_NOHDRS);\n\n\treturn set;\n}\n\n/*\n * util_part_open -- open or create a single part file\n */\nint\nutil_part_open(struct pool_set_part *part, size_t minsize, int create_part)\n{\n\tLOG(3, \"part %p minsize %zu create %d\", part, minsize, create_part);\n\n\tint exists = util_file_exists(part->path);\n\tif (exists < 0)\n\t\treturn -1;\n\n\tint create_file = create_part;\n\n\tif (exists)\n\t\tcreate_file = 0;\n\n\tpart->created = 0;\n\tif (create_file) {\n\t\tpart->fd = util_file_create(part->path, part->filesize,\n\t\t\t\tminsize);\n\t\tif (part->fd == -1) {\n\t\t\tLOG(2, \"failed to create file: %s\", part->path);\n\t\t\treturn -1;\n\t\t}\n\t\tpart->created = 1;\n\t} else {\n\t\tsize_t size = 0;\n\t\tint flags = O_RDWR;\n\t\tpart->fd = util_file_open(part->path, &size, minsize, flags);\n\t\tif (part->fd == -1) {\n\t\t\tLOG(2, \"failed to open file: %s\", part->path);\n\t\t\treturn -1;\n\t\t}\n\n\t\tif (Fallocate_at_create && create_part && !part->is_dev_dax) {\n\t\t\tint ret = os_posix_fallocate(part->fd, 0,\n\t\t\t\t\t(os_off_t)size);\n\t\t\tif (ret != 0) {\n\t\t\t\terrno = ret;\n\t\t\t\tERR(\"!posix_fallocate \\\"%s\\\", %zu\", part->path,\n\t\t\t\t\tsize);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t}\n\n\t\t/* check if filesize matches */\n\t\tif (part->filesize != size) {\n\t\t\tERR(\"file size does not match config: %s, %zu != %zu\",\n\t\t\t\tpart->path, size, part->filesize);\n\t\t\terrno = EINVAL;\n\t\t\treturn -1;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n/*\n * util_part_fdclose -- close part file\n */\nvoid\nutil_part_fdclose(struct pool_set_part *part)\n{\n\tLOG(3, \"part %p\", part);\n\n\tif (part->fd != -1) {\n\t\t(void) os_close(part->fd);\n\t\tpart->fd = -1;\n\t}\n}\n\n/*\n * util_set_rpmem_attr -- (internal) overwrite existing pool attributes\n *\n * does not set uuid, next_part_uuid, prev_part_uuid\n */\nstatic void\nutil_set_rpmem_attr(struct pool_hdr *hdrp, const struct rpmem_pool_attr *rattr)\n{\n\tLOG(5, \"hdrp %p rattr %p\", hdrp, rattr);\n\tmemcpy(hdrp->signature, rattr->signature, POOL_HDR_SIG_LEN);\n\thdrp->major = rattr->major;\n\thdrp->features.compat = rattr->compat_features;\n\thdrp->features.incompat = rattr->incompat_features;\n\thdrp->features.ro_compat = rattr->ro_compat_features;\n\tmemcpy(hdrp->poolset_uuid, rattr->poolset_uuid, POOL_HDR_UUID_LEN);\n\tmemcpy(hdrp->next_repl_uuid, rattr->next_uuid, POOL_HDR_UUID_LEN);\n\tmemcpy(hdrp->prev_repl_uuid, rattr->prev_uuid, POOL_HDR_UUID_LEN);\n\tmemcpy(&hdrp->arch_flags, rattr->user_flags, sizeof(struct arch_flags));\n}\n\n/*\n * util_get_rpmem_attr -- (internal) get attributes for remote replica header\n */\nstatic void\nutil_get_rpmem_attr(struct rpmem_pool_attr *rattr, const struct pool_hdr *hdrp)\n{\n\tLOG(5, \"rpmem_attr %p hdrp %p\", rattr, hdrp);\n\tASSERTne(rattr, NULL);\n\tmemcpy(rattr->signature, hdrp->signature, POOL_HDR_SIG_LEN);\n\trattr->major = hdrp->major;\n\trattr->compat_features = hdrp->features.compat;\n\trattr->incompat_features = hdrp->features.incompat;\n\trattr->ro_compat_features = hdrp->features.ro_compat;\n\tmemcpy(rattr->poolset_uuid, hdrp->poolset_uuid, POOL_HDR_UUID_LEN);\n\tmemcpy(rattr->uuid, hdrp->uuid, POOL_HDR_UUID_LEN);\n\tmemcpy(rattr->next_uuid, hdrp->next_repl_uuid, POOL_HDR_UUID_LEN);\n\tmemcpy(rattr->prev_uuid, hdrp->prev_repl_uuid, POOL_HDR_UUID_LEN);\n\tmemcpy(rattr->user_flags, &hdrp->arch_flags, sizeof(struct arch_flags));\n}\n\n/*\n * util_remote_store_attr -- (internal) store attributes read from remote\n *                           replica in the local volatile pool header\n */\nstatic void\nutil_remote_store_attr(struct pool_hdr *hdrp,\n\t\tconst struct rpmem_pool_attr *rattr)\n{\n\tLOG(4, \"hdrp %p rpmem_attr %p\", hdrp, rattr);\n\n\tutil_set_rpmem_attr(hdrp, rattr);\n\tmemcpy(hdrp->uuid, rattr->uuid, POOL_HDR_UUID_LEN);\n\tmemcpy(hdrp->next_part_uuid, rattr->uuid, POOL_HDR_UUID_LEN);\n\tmemcpy(hdrp->prev_part_uuid, rattr->uuid, POOL_HDR_UUID_LEN);\n}\n\n/*\n * util_update_remote_header --  update attributes of a remote replica;\n *                               the remote replica must be open\n */\nint\nutil_update_remote_header(struct pool_set *set, unsigned repn)\n{\n\tLOG(3, \"set %p, repn %u\", set, repn);\n\n\tASSERTne(REP(set, repn)->remote, NULL);\n\tASSERTne(REP(set, repn)->remote->rpp, NULL);\n\n\tstruct pool_replica *rep = REP(set, repn);\n\tstruct pool_hdr *hdr = HDR(rep, 0);\n\n\t/* get attributes from the local pool header */\n\tstruct rpmem_pool_attr attributes;\n\tutil_get_rpmem_attr(&attributes, hdr);\n\n\t/* push the attributes to the remote replica */\n\tRPMEMpool *rpp = rep->remote->rpp;\n\tint ret = Rpmem_set_attr(rpp, &attributes);\n\tif (ret) {\n\t\tERR(\"!Rpmem_set_attr\");\n\t\treturn -1;\n\t}\n\treturn 0;\n}\n\n/*\n * util_pool_close_remote -- close a remote replica\n */\nint\nutil_pool_close_remote(RPMEMpool *rpp)\n{\n\tLOG(3, \"rpp %p\", rpp);\n\n\treturn Rpmem_close(rpp);\n}\n\n/*\n * util_poolset_remote_open -- open or create a remote replica\n */\nint\nutil_poolset_remote_open(struct pool_replica *rep, unsigned repidx,\n\t\t\tsize_t minsize, int create, void *pool_addr,\n\t\t\tsize_t pool_size, unsigned *nlanes)\n{\n\tLOG(3, \"rep %p repidx %u minsize %zu create %d \"\n\t\t\"pool_addr %p pool_size %zu nlanes %p\",\n\t\trep, repidx, minsize, create,\n\t\tpool_addr, pool_size, nlanes);\n\n\tASSERTne(nlanes, NULL);\n\n\tif (!Rpmem_handle_remote) {\n\t\treturn -1;\n\t}\n\n\tunsigned remote_nlanes = *nlanes;\n\n\tif (create) {\n\t\tstruct rpmem_pool_attr rpmem_attr_create;\n\t\tutil_get_rpmem_attr(&rpmem_attr_create, rep->part[0].hdr);\n\n\t\trep->remote->rpp = Rpmem_create(rep->remote->node_addr,\n\t\t\t\t\t\trep->remote->pool_desc,\n\t\t\t\t\t\tpool_addr,\n\t\t\t\t\t\tpool_size,\n\t\t\t\t\t\t&remote_nlanes,\n\t\t\t\t\t\t&rpmem_attr_create);\n\t\tif (rep->remote->rpp == NULL) {\n\t\t\tERR(\"creating remote replica #%u failed\", repidx);\n\t\t\treturn -1;\n\t\t}\n\t\trep->part[0].created = 1;\n\t} else { /* open */\n\t\tstruct rpmem_pool_attr rpmem_attr_open;\n\n\t\trep->remote->rpp = Rpmem_open(rep->remote->node_addr,\n\t\t\t\t\t\trep->remote->pool_desc,\n\t\t\t\t\t\tpool_addr,\n\t\t\t\t\t\tpool_size,\n\t\t\t\t\t\t&remote_nlanes,\n\t\t\t\t\t\t&rpmem_attr_open);\n\t\tif (rep->remote->rpp == NULL) {\n\t\t\tERR(\"opening remote replica #%u failed\", repidx);\n\t\t\treturn -1;\n\t\t}\n\n\t\tutil_remote_store_attr(rep->part[0].hdr, &rpmem_attr_open);\n\t}\n\n\tif (remote_nlanes < *nlanes)\n\t\t*nlanes = remote_nlanes;\n\n\treturn 0;\n}\n\n/*\n * util_poolset_files_local -- (internal) open or create all the local\n *                              part files of a pool set and replica sets\n */\nstatic int\nutil_poolset_files_local(struct pool_set *set, size_t minpartsize, int create)\n{\n\tLOG(3, \"set %p minpartsize %zu create %d\", set, minpartsize, create);\n\n\tfor (unsigned r = 0; r < set->nreplicas; r++) {\n\t\tstruct pool_replica *rep = set->replica[r];\n\t\tif (!rep->remote) {\n\t\t\tfor (unsigned p = 0; p < rep->nparts; p++) {\n\t\t\t\tif (util_part_open(&rep->part[p], minpartsize,\n\t\t\t\t\t\tcreate))\n\t\t\t\t\treturn -1;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n/*\n * util_poolset_remote_replica_open -- open remote replica\n */\nint\nutil_poolset_remote_replica_open(struct pool_set *set, unsigned repidx,\n\tsize_t minsize, int create, unsigned *nlanes)\n{\n#ifndef _WIN32\n\t/*\n\t * This is a workaround for an issue with using device dax with\n\t * libibverbs. To handle fork() function calls correctly libfabric use\n\t * ibv_fork_init(3) which makes all registered memory being madvised\n\t * with MADV_DONTFORK flag. In libpmemobj the remote replication is\n\t * performed without pool header (first 4k). In such case the address\n\t * passed to madvise(2) is aligned to 4k, but device dax can require\n\t * different alignment (default is 2MB). This workaround madvises the\n\t * entire memory region before registering it by fi_mr_reg(3).\n\t *\n\t * The librpmem client requires fork() support to work correctly.\n\t */\n\tif (set->replica[0]->part[0].is_dev_dax) {\n\t\tint ret = os_madvise(set->replica[0]->part[0].addr,\n\t\t\t\tset->replica[0]->part[0].filesize,\n\t\t\t\tMADV_DONTFORK);\n\t\tif (ret) {\n\t\t\tERR(\"!madvise\");\n\t\t\treturn ret;\n\t\t}\n\t}\n#endif\n\n\tvoid *pool_addr = (void *)((uintptr_t)set->replica[0]->part[0].addr);\n\n\treturn util_poolset_remote_open(set->replica[repidx], repidx, minsize,\n\t\t\tcreate, pool_addr, set->poolsize, nlanes);\n}\n\n/*\n * util_poolset_files_remote -- (internal) open or create all the remote\n *                              part files of a pool set and replica sets\n */\nstatic int\nutil_poolset_files_remote(struct pool_set *set, size_t minsize,\n\t\t\t\tunsigned *nlanes, int create)\n{\n\tLOG(3, \"set %p minsize %zu nlanes %p create %d\",\n\t\tset, minsize, nlanes, create);\n\n\tfor (unsigned r = 0; r < set->nreplicas; r++) {\n\t\tstruct pool_replica *rep = set->replica[r];\n\t\tif (rep->remote) {\n\t\t\tif (util_poolset_remote_replica_open(set, r,\n\t\t\t\tminsize, create, nlanes))\n\t\t\t\treturn -1;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n/*\n * util_poolset_read -- read memory pool set file\n *\n * On success returns 0 and a pointer to a newly allocated structure\n * containing the info of all the parts of the pool set and replicas.\n */\nint\nutil_poolset_read(struct pool_set **setp, const char *path)\n{\n\tLOG(3, \"setp %p path %s\", setp, path);\n\n\tint oerrno;\n\tint ret = 0;\n\tint fd;\n\n\tif ((fd = os_open(path, O_RDONLY)) < 0) {\n\t\tERR(\"!open: path \\\"%s\\\"\", path);\n\t\treturn -1;\n\t}\n\n\tret = util_poolset_parse(setp, path, fd);\n\n\toerrno = errno;\n\t(void) os_close(fd);\n\terrno = oerrno;\n\treturn ret;\n}\n\n/*\n * util_poolset_create_set -- create a new pool set structure\n *\n * On success returns 0 and a pointer to a newly allocated structure\n * containing the info of all the parts of the pool set and replicas.\n */\nint\nutil_poolset_create_set(struct pool_set **setp, const char *path,\n\tsize_t poolsize, size_t minsize, int ignore_sds)\n{\n\tLOG(3, \"setp %p path %s poolsize %zu minsize %zu\",\n\t\tsetp, path, poolsize, minsize);\n\n\tint oerrno;\n\tint ret = 0;\n\tint fd;\n\tsize_t size = 0;\n\n\tenum file_type type = util_file_get_type(path);\n\tif (type == OTHER_ERROR)\n\t\treturn -1;\n\n\tif (poolsize != 0) {\n\t\tif (type == TYPE_DEVDAX) {\n\t\t\tERR(\"size must be zero for device dax\");\n\t\t\treturn -1;\n\t\t}\n\t\t*setp = util_poolset_single(path, poolsize, 1, ignore_sds);\n\t\tif (*setp == NULL)\n\t\t\treturn -1;\n\n\t\treturn 0;\n\t}\n\n\t/* do not check minsize */\n\tif ((fd = util_file_open(path, &size, 0, O_RDONLY)) == -1)\n\t\treturn -1;\n\n\tchar signature[POOLSET_HDR_SIG_LEN];\n\tif (type == TYPE_NORMAL) {\n\t\t/*\n\t\t * read returns ssize_t, but we know it will return value\n\t\t * between -1 and POOLSET_HDR_SIG_LEN (11), so we can safely\n\t\t * cast it to int\n\t\t */\n\t\tret = (int)read(fd, signature, POOLSET_HDR_SIG_LEN);\n\t\tif (ret < 0) {\n\t\t\tERR(\"!read %d\", fd);\n\t\t\tgoto err;\n\t\t}\n\t}\n\n\tif (type == TYPE_DEVDAX || ret < POOLSET_HDR_SIG_LEN ||\n\t    strncmp(signature, POOLSET_HDR_SIG, POOLSET_HDR_SIG_LEN)) {\n\t\tLOG(4, \"not a pool set header\");\n\t\t(void) os_close(fd);\n\n\t\tif (size < minsize) {\n\t\t\tERR(\"file is not a poolset file and its size (%zu)\"\n\t\t\t\t\" is smaller than %zu\", size, minsize);\n\t\t\terrno = EINVAL;\n\t\t\treturn -1;\n\t\t}\n\t\t*setp = util_poolset_single(path, size, 0, ignore_sds);\n\t\tif (*setp == NULL)\n\t\t\treturn -1;\n\n\t\treturn 0;\n\t}\n\n\tret = util_poolset_parse(setp, path, fd);\n\tif (ret)\n\t\tgoto err;\n\n\t(*setp)->ignore_sds = ignore_sds || ((*setp)->options & OPTION_NOHDRS);\n#ifdef _WIN32\n\t/* remote replication is not supported on Windows */\n\tif ((*setp)->remote) {\n\t\tutil_poolset_free(*setp);\n\t\tERR(\"remote replication is not supported on Windows\");\n\t\terrno = ENOTSUP;\n\t\tret = -1;\n\t\tgoto err;\n\t}\n#endif /* _WIN32 */\n\nerr:\n\toerrno = errno;\n\t(void) os_close(fd);\n\terrno = oerrno;\n\treturn ret;\n}\n\n/*\n * util_poolset_check_header_options -- (internal) check if poolset options\n *                                      match given flags\n */\nstatic int\nutil_poolset_check_header_options(struct pool_set *set, uint32_t incompat)\n{\n\tLOG(3, \"set %p, incompat %#x\", set, incompat);\n\n\tif (((set->options & OPTION_SINGLEHDR) == 0) !=\n\t\t\t((incompat & POOL_FEAT_SINGLEHDR) == 0)) {\n\t\tERR(\n\t\t\t\"poolset file options (%u) do not match incompat feature flags (%#x)\",\n\t\t\tset->options, incompat);\n\t\terrno = EINVAL;\n\t\treturn -1;\n\t}\n\treturn 0;\n}\n\n/*\n * util_header_create -- create header of a single pool set file\n */\nint\nutil_header_create(struct pool_set *set, unsigned repidx, unsigned partidx,\n\tconst struct pool_attr *attr, int overwrite)\n{\n\tLOG(3, \"set %p repidx %u partidx %u attr %p overwrite %d\", set, repidx,\n\t\tpartidx, attr, overwrite);\n\n\tASSERTne(attr, NULL);\n\n\tstruct pool_replica *rep = set->replica[repidx];\n\n\t/* opaque info lives at the beginning of mapped memory pool */\n\tstruct pool_hdr *hdrp = rep->part[partidx].hdr;\n\n\t/* check if the pool header is all zeros */\n\tif (!util_is_zeroed(hdrp, sizeof(*hdrp)) && !overwrite) {\n\t\tERR(\"Non-empty file detected\");\n\t\terrno = EEXIST;\n\t\treturn -1;\n\t}\n\n\t/* create pool's header */\n\tutil_pool_attr2hdr(hdrp, attr);\n\n\tif (set->options & OPTION_SINGLEHDR)\n\t\thdrp->features.incompat |= POOL_FEAT_SINGLEHDR;\n\n\tmemcpy(hdrp->poolset_uuid, set->uuid, POOL_HDR_UUID_LEN);\n\tmemcpy(hdrp->uuid, PART(rep, partidx)->uuid, POOL_HDR_UUID_LEN);\n\n\t/* link parts */\n\tif (set->options & OPTION_SINGLEHDR) {\n\t\t/* next/prev part point to part #0 */\n\t\tASSERTeq(partidx, 0);\n\t\tmemcpy(hdrp->prev_part_uuid, PART(rep, 0)->uuid,\n\t\t\t\t\t\t\tPOOL_HDR_UUID_LEN);\n\t\tmemcpy(hdrp->next_part_uuid, PART(rep, 0)->uuid,\n\t\t\t\t\t\t\tPOOL_HDR_UUID_LEN);\n\t} else {\n\t\tmemcpy(hdrp->prev_part_uuid, PARTP(rep, partidx)->uuid,\n\t\t\t\t\t\t\tPOOL_HDR_UUID_LEN);\n\t\tmemcpy(hdrp->next_part_uuid, PARTN(rep, partidx)->uuid,\n\t\t\t\t\t\t\tPOOL_HDR_UUID_LEN);\n\t}\n\n\t/* link replicas */\n\tif (!util_is_zeroed(attr->prev_repl_uuid, POOL_HDR_UUID_LEN)) {\n\t\tmemcpy(hdrp->prev_repl_uuid, attr->prev_repl_uuid,\n\t\t\t\tPOOL_HDR_UUID_LEN);\n\t} else {\n\t\tmemcpy(hdrp->prev_repl_uuid, PART(REPP(set, repidx), 0)->uuid,\n\t\t\tPOOL_HDR_UUID_LEN);\n\t}\n\tif (!util_is_zeroed(attr->next_repl_uuid, POOL_HDR_UUID_LEN)) {\n\t\tmemcpy(hdrp->next_repl_uuid, attr->next_repl_uuid,\n\t\t\t\tPOOL_HDR_UUID_LEN);\n\t} else {\n\t\tmemcpy(hdrp->next_repl_uuid, PART(REPN(set, repidx), 0)->uuid,\n\t\t\tPOOL_HDR_UUID_LEN);\n\t}\n\n\tif (!rep->remote) {\n\t\tos_stat_t stbuf;\n\n\t\tif (os_fstat(rep->part[partidx].fd, &stbuf) != 0) {\n\t\t\tERR(\"!fstat\");\n\t\t\treturn -1;\n\t\t}\n\t\tASSERT(stbuf.st_ctime);\n\t\thdrp->crtime = (uint64_t)stbuf.st_ctime;\n\t}\n\n\tint arch_is_zeroed = util_is_zeroed(attr->arch_flags,\n\t\t\tPOOL_HDR_ARCH_LEN);\n\tif (arch_is_zeroed)\n\t\tutil_get_arch_flags(&hdrp->arch_flags);\n\n\tutil_convert2le_hdr(hdrp);\n\n\tif (!arch_is_zeroed) {\n\t\tmemcpy(&hdrp->arch_flags, attr->arch_flags, POOL_HDR_ARCH_LEN);\n\t}\n\n\tif (!set->ignore_sds && partidx == 0 && !rep->remote) {\n\t\tshutdown_state_init(&hdrp->sds, rep);\n\t\tfor (unsigned p = 0; p < rep->nparts; p++) {\n\t\t\tif (shutdown_state_add_part(&hdrp->sds,\n\t\t\t\t\tPART(rep, p)->path, rep))\n\t\t\t\treturn -1;\n\t\t}\n\t\tshutdown_state_set_dirty(&hdrp->sds, rep);\n\t}\n\n\tutil_checksum(hdrp, sizeof(*hdrp), &hdrp->checksum,\n\t\t1, POOL_HDR_CSUM_END_OFF(hdrp));\n\n\t/* store pool's header */\n\tutil_persist_auto(rep->is_pmem, hdrp, sizeof(*hdrp));\n\n\treturn 0;\n}\n\n/*\n * util_header_check -- (internal) validate header of a single pool set file\n */\nstatic int\nutil_header_check(struct pool_set *set, unsigned repidx, unsigned partidx,\n\tconst struct pool_attr *attr)\n{\n\tLOG(3, \"set %p repidx %u partidx %u attr %p\", set, repidx, partidx,\n\t\t\tattr);\n\n\tASSERTne(attr, NULL);\n\n\tstruct pool_replica *rep = set->replica[repidx];\n\n\t/* opaque info lives at the beginning of mapped memory pool */\n\tstruct pool_hdr *hdrp = rep->part[partidx].hdr;\n\tstruct pool_hdr hdr;\n\n\tmemcpy(&hdr, hdrp, sizeof(hdr));\n\n\t/* local copy of a remote header does not need to be converted */\n\tif (rep->remote == NULL)\n\t\tutil_convert2h_hdr_nocheck(&hdr);\n\n\t/* to be valid, a header must have a major version of at least 1 */\n\tif (hdr.major == 0) {\n\t\tERR(\"invalid major version (0)\");\n\t\terrno = EINVAL;\n\t\treturn -1;\n\t}\n\n\t/* check signature */\n\tif (memcmp(hdr.signature, attr->signature, POOL_HDR_SIG_LEN)) {\n\t\tERR(\"wrong pool type: \\\"%.8s\\\"\", hdr.signature);\n\t\terrno = EINVAL;\n\t\treturn -1;\n\t}\n\n\t/* check format version number */\n\tif (hdr.major != attr->major) {\n\t\tERR(\"pool version %d (library expects %d)\", hdr.major,\n\t\t\t\tattr->major);\n\t\tif (hdr.major < attr->major)\n\t\t\tERR(\n\t\t\t\t\"Please run the pmdk-convert utility to upgrade the pool.\");\n\t\terrno = EINVAL;\n\t\treturn -1;\n\t}\n\n\trep->part[partidx].rdonly = 0;\n\n\tint retval = util_feature_check(&hdr, attr->features);\n\tif (retval < 0)\n\t\treturn -1;\n\n\tif (retval == 0)\n\t\trep->part[partidx].rdonly = 1;\n\n\tif (rep->remote == NULL) {\n\t\t/*\n\t\t * and to be valid, the fields must checksum correctly\n\t\t *\n\t\t * NOTE: checksum validation is performed after format version\n\t\t * and feature check, because if POOL_FEAT_CKSUM_2K flag is set,\n\t\t * we want to report it as incompatible feature, rather than\n\t\t * invalid checksum.\n\t\t */\n\t\tif (!util_checksum(&hdr, sizeof(hdr), &hdr.checksum,\n\t\t\t\t0, POOL_HDR_CSUM_END_OFF(&hdr))) {\n\t\t\tERR(\"invalid checksum of pool header\");\n\t\t\terrno = EINVAL;\n\t\t\treturn -1;\n\t\t}\n\n\t\tLOG(3, \"valid header, signature \\\"%.8s\\\"\", hdr.signature);\n\t}\n\n\tif (util_check_arch_flags(&hdr.arch_flags)) {\n\t\tERR(\"wrong architecture flags\");\n\t\terrno = EINVAL;\n\t\treturn -1;\n\t}\n\n\t/* check pool set UUID */\n\tif (memcmp(HDR(REP(set, 0), 0)->poolset_uuid, hdr.poolset_uuid,\n\t\t\t\t\t\tPOOL_HDR_UUID_LEN)) {\n\t\tERR(\"wrong pool set UUID\");\n\t\terrno = EINVAL;\n\t\treturn -1;\n\t}\n\n\t/* check pool set linkage */\n\tif (memcmp(HDRP(rep, partidx)->uuid, hdr.prev_part_uuid,\n\t\t\t\t\t\tPOOL_HDR_UUID_LEN) ||\n\t    memcmp(HDRN(rep, partidx)->uuid, hdr.next_part_uuid,\n\t\t\t\t\t\tPOOL_HDR_UUID_LEN)) {\n\t\tERR(\"wrong part UUID\");\n\t\terrno = EINVAL;\n\t\treturn -1;\n\t}\n\n\t/* check format version */\n\tif (HDR(rep, 0)->major != hdrp->major) {\n\t\tERR(\"incompatible pool format\");\n\t\terrno = EINVAL;\n\t\treturn -1;\n\t}\n\n\t/* check compatibility features */\n\tif (HDR(rep, 0)->features.compat != hdrp->features.compat ||\n\t    HDR(rep, 0)->features.incompat != hdrp->features.incompat ||\n\t    HDR(rep, 0)->features.ro_compat != hdrp->features.ro_compat) {\n\t\tERR(\"incompatible feature flags\");\n\t\terrno = EINVAL;\n\t\treturn -1;\n\t}\n\n\t/* check poolset options */\n\tif (util_poolset_check_header_options(set,\n\t\t\tHDR(rep, 0)->features.incompat))\n\t\treturn -1;\n\n\treturn 0;\n}\n\n/*\n * util_header_check_remote -- (internal) validate header of a remote\n *                             pool set file\n */\nstatic int\nutil_header_check_remote(struct pool_set *set, unsigned partidx)\n{\n\tLOG(3, \"set %p partidx %u \", set, partidx);\n\n\t/* there is only one replica in remote poolset */\n\tstruct pool_replica *rep = set->replica[0];\n\t/* opaque info lives at the beginning of mapped memory pool */\n\tstruct pool_hdr *hdrp = rep->part[partidx].hdr;\n\tstruct pool_hdr hdr;\n\n\tif (util_is_zeroed(hdrp, sizeof(*hdrp))) {\n\t\tERR(\"pool header zeroed\");\n\t\terrno = EINVAL;\n\t\treturn -1;\n\t}\n\n\tmemcpy(&hdr, hdrp, sizeof(hdr));\n\n\tutil_convert2h_hdr_nocheck(&hdr);\n\n\t/* valid header found */\n\tif (memcmp(HDR(rep, 0)->signature, hdrp->signature, POOL_HDR_SIG_LEN)) {\n\t\tERR(\"pool signature mismatch in part %d\", partidx);\n\t\terrno = EINVAL;\n\t\treturn -1;\n\t}\n\n\t/* check format version */\n\tif (HDR(rep, 0)->major != hdrp->major) {\n\t\tERR(\"pool version mismatch in part %d\", partidx);\n\t\terrno = EINVAL;\n\t\treturn -1;\n\t}\n\n\t/* check compatibility features */\n\tif (HDR(rep, 0)->features.compat != hdrp->features.compat) {\n\t\tERR(\"'may have' compatibility flags mismatch in part %d\",\n\t\t\t\t\t\t\t\tpartidx);\n\t\terrno = EINVAL;\n\t\treturn -1;\n\t}\n\tif (HDR(rep, 0)->features.incompat != hdrp->features.incompat) {\n\t\tERR(\"'must support' compatibility flags mismatch in part %d\",\n\t\t\t\t\t\t\t\tpartidx);\n\t\terrno = EINVAL;\n\t\treturn -1;\n\t}\n\tif (HDR(rep, 0)->features.ro_compat != hdrp->features.ro_compat) {\n\t\tERR(\"'force read-only' compatibility flags mismatch in part %d\",\n\t\t\t\t\t\t\t\tpartidx);\n\t\terrno = EINVAL;\n\t\treturn -1;\n\t}\n\n\t/*\n\t * and to be valid, the fields must checksum correctly\n\t *\n\t * NOTE: checksum validation is performed after format version and\n\t * feature check, because if POOL_FEAT_CKSUM_2K flag is set,\n\t * we want to report it as incompatible feature, rather than invalid\n\t * checksum.\n\t */\n\tif (!util_checksum(&hdr, sizeof(hdr), &hdr.checksum,\n\t\t\t0, POOL_HDR_CSUM_END_OFF(&hdr))) {\n\t\tERR(\"invalid checksum of pool header\");\n\t\treturn -1;\n\t}\n\n\tLOG(3, \"valid header, signature \\\"%.8s\\\"\", hdr.signature);\n\n\t/* check pool set UUID */\n\tif (memcmp(HDR(rep, 0)->poolset_uuid, hdrp->poolset_uuid,\n\t\t\t\t\t\t\tPOOL_HDR_UUID_LEN)) {\n\t\tERR(\"wrong pool set UUID in part %d\", partidx);\n\t\terrno = EINVAL;\n\t\treturn -1;\n\t}\n\n\t/* check previous replica UUID */\n\tif (memcmp(HDR(rep, 0)->prev_repl_uuid, hdrp->prev_repl_uuid,\n\t\t\t\t\t\t\tPOOL_HDR_UUID_LEN)) {\n\t\tERR(\"wrong previous replica UUID in part %d\", partidx);\n\t\terrno = EINVAL;\n\t\treturn -1;\n\t}\n\n\t/* check next replica UUID */\n\tif (memcmp(HDR(rep, 0)->next_repl_uuid, hdrp->next_repl_uuid,\n\t\t\t\t\t\tPOOL_HDR_UUID_LEN)) {\n\t\tERR(\"wrong next replica UUID in part %d\", partidx);\n\t\terrno = EINVAL;\n\t\treturn -1;\n\t}\n\n\tif (memcmp(&HDR(rep, 0)->arch_flags, &hdrp->arch_flags,\n\t\t\t\t\t\tsizeof(hdrp->arch_flags))) {\n\t\tERR(\"wrong architecture flags\");\n\t\terrno = EINVAL;\n\t\treturn -1;\n\t}\n\n\t/* check pool set linkage */\n\tif (memcmp(HDRP(rep, partidx)->uuid, hdrp->prev_part_uuid,\n\t\t\t\t\t\t\tPOOL_HDR_UUID_LEN) ||\n\t    memcmp(HDRN(rep, partidx)->uuid, hdrp->next_part_uuid,\n\t\t\t\t\t\t\tPOOL_HDR_UUID_LEN)) {\n\t\tERR(\"wrong part UUID in part %d\", partidx);\n\t\terrno = EINVAL;\n\t\treturn -1;\n\t}\n\n\t/* read shutdown state toggle from header */\n\tset->ignore_sds |= IGNORE_SDS(HDR(rep, 0));\n\n\tif (!set->ignore_sds && partidx == 0) {\n\t\tstruct shutdown_state sds;\n\t\tshutdown_state_init(&sds, NULL);\n\t\tfor (unsigned p = 0; p < rep->nparts; p++) {\n\t\t\tif (shutdown_state_add_part(&sds,\n\t\t\t\t\tPART(rep, p)->path, NULL))\n\t\t\t\treturn -1;\n\t\t}\n\n\t\tif (shutdown_state_check(&sds, &hdrp->sds, rep)) {\n\t\t\terrno = EINVAL;\n\t\t\treturn -1;\n\t\t}\n\n\t\tshutdown_state_set_dirty(&hdrp->sds, rep);\n\t}\n\n\trep->part[partidx].rdonly = 0;\n\n\treturn 0;\n}\n\n/*\n * util_replica_set_is_pmem -- sets per-replica is_pmem flag\n *\n * The replica is PMEM if:\n * - all parts are on device dax, or\n * - all parts are mapped with MAP_SYNC.\n *\n * It's enough to check only first part because it's already verified\n * that either all or none parts are device dax or mapped with MAP_SYNC.\n */\nstatic inline void\nutil_replica_set_is_pmem(struct pool_replica *rep)\n{\n\trep->is_pmem = rep->part[0].is_dev_dax || rep->part[0].map_sync ||\n\t\tpmem_is_pmem(rep->part[0].addr, rep->resvsize);\n}\n\n/*\n * util_replica_map_local -- (internal) map memory pool for local replica\n */\nstatic int\nutil_replica_map_local(struct pool_set *set, unsigned repidx, int flags)\n{\n\tLOG(3, \"set %p repidx %u flags %d\", set, repidx, flags);\n\n\t/*\n\t * XXX: Like we reserve space for all parts in this replica when we map\n\t * the first part, we need to reserve the space for all replicas\n\t * upfront.  It is not necessary that the replicas are contiguous but\n\t * that way we would not fragment the memory much.  I think we should\n\t * leave this to MM, but let's have a note as per our collective minds.\n\t */\n\n#ifndef _WIN32\n\tint remaining_retries = 0;\n#else\n\tint remaining_retries = 10;\n#endif\n\tint retry_for_contiguous_addr;\n\tsize_t mapsize;\n\t/* header size for all headers but the first one */\n\tsize_t hdrsize = (set->options & (OPTION_SINGLEHDR | OPTION_NOHDRS)) ?\n\t\t\t0 : Mmap_align;\n\tvoid *addr;\n\tstruct pool_replica *rep = set->replica[repidx];\n\n\tASSERTeq(rep->remote, NULL);\n\tASSERTne(rep->part, NULL);\n\n\tdo {\n\t\tretry_for_contiguous_addr = 0;\n\t\tmapsize = rep->part[0].filesize & ~(Mmap_align - 1);\n\n\t\t/* determine a hint address for mmap() */\n\t\taddr = util_map_hint(rep->resvsize, 0);\n\t\tif (addr == MAP_FAILED) {\n\t\t\tLOG(1, \"cannot find a contiguous region of given size\");\n\t\t\treturn -1;\n\t\t}\n\n\t\t/* map the first part and reserve space for remaining parts */\n\t\tif (util_map_part(&rep->part[0], addr, rep->resvsize, 0,\n\t\t\t\tflags, 0) != 0) {\n\t\t\tLOG(2, \"pool mapping failed - replica #%u part #0\",\n\t\t\t\trepidx);\n\t\t\treturn -1;\n\t\t}\n\n\t\tVALGRIND_REGISTER_PMEM_MAPPING(rep->part[0].addr,\n\t\t\t\trep->part[0].size);\n\t\tVALGRIND_REGISTER_PMEM_FILE(rep->part[0].fd,\n\t\t\t\trep->part[0].addr, rep->part[0].size, 0);\n\n\t\tset->zeroed &= rep->part[0].created;\n\n\t\taddr = (char *)rep->part[0].addr + mapsize;\n\n\t\t/*\n\t\t * map the remaining parts of the usable pool space\n\t\t * (aligned to memory mapping granularity)\n\t\t */\n\t\tfor (unsigned p = 1; p < rep->nparts; p++) {\n\t\t\t/* map data part */\n\t\t\tif (util_map_part(&rep->part[p], addr, 0, hdrsize,\n\t\t\t\t\tflags | MAP_FIXED, 0) != 0) {\n\t\t\t\t/*\n\t\t\t\t * if we can't map the part at the address we\n\t\t\t\t * asked for, unmap all the parts that are\n\t\t\t\t * mapped and remap at a different address.\n\t\t\t\t */\n\t\t\t\tif ((errno == EINVAL) &&\n\t\t\t\t    (remaining_retries > 0)) {\n\t\t\t\t\tLOG(2, \"usable space mapping failed - \"\n\t\t\t\t\t\t\"part #%d - retrying\", p);\n\t\t\t\t\tretry_for_contiguous_addr = 1;\n\t\t\t\t\tremaining_retries--;\n\n\t\t\t\t\tutil_unmap_parts(rep, 0, p - 1);\n\n\t\t\t\t\t/* release rest of the VA reserved */\n\t\t\t\t\tASSERTne(addr, NULL);\n\t\t\t\t\tASSERTne(addr, MAP_FAILED);\n\t\t\t\t\tmunmap(addr, rep->resvsize - mapsize);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tLOG(2, \"usable space mapping failed - part #%d\",\n\t\t\t\t\tp);\n\t\t\t\tgoto err;\n\t\t\t}\n\n\t\t\tVALGRIND_REGISTER_PMEM_FILE(rep->part[p].fd,\n\t\t\t\trep->part[p].addr, rep->part[p].size,\n\t\t\t\thdrsize);\n\n\t\t\tmapsize += rep->part[p].size;\n\t\t\tset->zeroed &= rep->part[p].created;\n\t\t\taddr = (char *)addr + rep->part[p].size;\n\t\t}\n\t} while (retry_for_contiguous_addr);\n\n\t/*\n\t * Initially part[0].size is the size of address space\n\t * reservation for all parts from given replica. After\n\t * mapping that space we need to overwrite part[0].size\n\t * with its actual size to be consistent - size for each\n\t * part should be the actual mapping size of this part\n\t * only - it simplifies future calculations.\n\t */\n\trep->part[0].size = rep->part[0].filesize & ~(Mmap_align - 1);\n\n\tif (util_replica_check_map_sync(set, repidx, 0))\n\t\tgoto err;\n\n\tutil_replica_set_is_pmem(rep);\n\n\tif (Prefault_at_create)\n\t\tutil_replica_force_page_allocation(rep);\n\n\tASSERTeq(mapsize, rep->repsize);\n\n\tLOG(3, \"replica #%u addr %p\", repidx, rep->part[0].addr);\n\n\treturn 0;\n\nerr:\n\tLOG(4, \"error clean up\");\n\tint oerrno = errno;\n\tif (mapsize < rep->repsize) {\n\t\tASSERTne(rep->part[0].addr, NULL);\n\t\tASSERTne(rep->part[0].addr, MAP_FAILED);\n\t\tmunmap(rep->part[0].addr, rep->resvsize - mapsize);\n\t}\n\tfor (unsigned p = 0; p < rep->nparts; p++) {\n\t\tutil_unmap_part(&rep->part[p]);\n\t}\n\terrno = oerrno;\n\treturn -1;\n}\n\n/*\n * util_replica_init_headers_local -- (internal) initialize pool headers\n */\nstatic int\nutil_replica_init_headers_local(struct pool_set *set, unsigned repidx,\n\tint flags, const struct pool_attr *attr)\n{\n\tLOG(3, \"set %p repidx %u flags %d attr %p\", set, repidx, flags, attr);\n\n\tstruct pool_replica *rep = set->replica[repidx];\n\n\t/* map all headers - don't care about the address */\n\tfor (unsigned p = 0; p < rep->nhdrs; p++) {\n\t\tif (util_map_hdr(&rep->part[p], flags, 0) != 0) {\n\t\t\tLOG(2, \"header mapping failed - part #%d\", p);\n\t\t\tgoto err;\n\t\t}\n\t}\n\n\t/* create headers, set UUID's */\n\tfor (unsigned p = 0; p < rep->nhdrs; p++) {\n\t\tif (util_header_create(set, repidx, p, attr, 0) != 0) {\n\t\t\tLOG(2, \"header creation failed - part #%d\", p);\n\t\t\tgoto err;\n\t\t}\n\t}\n\n\t/* unmap all headers */\n\tfor (unsigned p = 0; p < rep->nhdrs; p++)\n\t\tutil_unmap_hdr(&rep->part[p]);\n\n\treturn 0;\n\nerr:\n\tLOG(4, \"error clean up\");\n\tint oerrno = errno;\n\tfor (unsigned p = 0; p < rep->nhdrs; p++) {\n\t\tutil_unmap_hdr(&rep->part[p]);\n\t}\n\terrno = oerrno;\n\treturn -1;\n}\n\n/*\n * util_replica_create_local -- (internal) create a new memory pool for local\n * replica\n */\nstatic int\nutil_replica_create_local(struct pool_set *set, unsigned repidx, int flags,\n\tconst struct pool_attr *attr)\n{\n\tLOG(3, \"set %p repidx %u flags %d attr %p\", set, repidx, flags, attr);\n\n\t/*\n\t * the first replica has to be mapped prior to remote ones so if\n\t * a replica is already mapped skip mapping creation\n\t */\n\tif (PART(REP(set, repidx), 0)->addr == NULL) {\n\t\tif (util_replica_map_local(set, repidx, flags) != 0) {\n\t\t\tLOG(2, \"replica #%u map failed\", repidx);\n\t\t\treturn -1;\n\t\t}\n\t}\n\n\tif (attr == NULL)\n\t\treturn 0;\n\n\tif (util_replica_init_headers_local(set, repidx, flags, attr) != 0) {\n\t\tLOG(2, \"replica #%u headers initialization failed\", repidx);\n\t\treturn -1;\n\t}\n\treturn 0;\n}\n\n/*\n * util_replica_create_remote -- (internal) create a new memory pool\n *                               for remote replica\n */\nstatic int\nutil_replica_create_remote(struct pool_set *set, unsigned repidx, int flags,\n\tconst struct pool_attr *attr)\n{\n\tLOG(3, \"set %p repidx %u flags %d attr %p\", set, repidx, flags, attr);\n\n\tstruct pool_replica *rep = set->replica[repidx];\n\n\tASSERTne(rep->remote, NULL);\n\tASSERTne(rep->part, NULL);\n\tASSERTeq(rep->nparts, 1);\n\tASSERTeq(rep->nhdrs, 1);\n\tASSERTne(attr, NULL);\n\n\tstruct pool_set_part *part = rep->part;\n\n\t/*\n\t * A remote replica has one fake part of size equal twice pool header\n\t * size for storing pool header and pool descriptor.\n\t */\n\tpart->size = rep->repsize;\n\tASSERT(IS_PAGE_ALIGNED(part->size));\n\tpart->remote_hdr = Zalloc(part->size + Pagesize);\n\tif (!part->remote_hdr) {\n\t\tERR(\"!Zalloc\");\n\t\treturn -1;\n\t}\n\n\tpart->hdr = PAGE_ALIGN_UP(part->remote_hdr);\n\tpart->addr = PAGE_ALIGN_UP(part->remote_hdr);\n\tpart->hdrsize = POOL_HDR_SIZE;\n\n\t/* create header, set UUID's */\n\tif (util_header_create(set, repidx, 0, attr, 0) != 0) {\n\t\tLOG(2, \"header creation failed - part #0\");\n\t\tFree(part->remote_hdr);\n\t\treturn -1;\n\t}\n\n\tLOG(3, \"replica #%u addr %p\", repidx, rep->part[0].addr);\n\n\treturn 0;\n}\n\n/*\n * util_replica_close -- close a memory pool replica\n *\n * This function unmaps all mapped memory regions.\n */\nint\nutil_replica_close(struct pool_set *set, unsigned repidx)\n{\n\tLOG(3, \"set %p repidx %u\", set, repidx);\n\tstruct pool_replica *rep = set->replica[repidx];\n\n\tif (rep->remote == NULL) {\n\t\tstruct pool_set_part *part = PART(rep, 0);\n\t\tif (!set->ignore_sds && part->addr != NULL &&\n\t\t\t\tpart->size != 0) {\n\t\t\tstruct pool_hdr *hdr = part->addr;\n\t\t\tRANGE_RW(hdr, sizeof(*hdr), part->is_dev_dax);\n\t\t\t/*\n\t\t\t * deep drain will call msync on one page in each\n\t\t\t * part in replica to trigger WPQ flush.\n\t\t\t * This pages may have been marked as\n\t\t\t * undefined/inaccessible, but msyncing such memory\n\t\t\t * is not a bug, so as a workaround temporarily\n\t\t\t * disable error reporting.\n\t\t\t */\n\t\t\tVALGRIND_DO_DISABLE_ERROR_REPORTING;\n\t\t\tutil_replica_deep_drain(part->addr, rep->repsize,\n\t\t\t\tset, repidx);\n\t\t\tVALGRIND_DO_ENABLE_ERROR_REPORTING;\n\t\t\tshutdown_state_clear_dirty(&hdr->sds, rep);\n\t\t}\n\t\tfor (unsigned p = 0; p < rep->nhdrs; p++)\n\t\t\tutil_unmap_hdr(&rep->part[p]);\n\n\t\trep->part[0].size = rep->resvsize;\n\t\tutil_unmap_part(&rep->part[0]);\n\t} else {\n\t\tLOG(4, \"freeing volatile header of remote replica #%u\", repidx);\n\t\tFree(rep->part[0].remote_hdr);\n\t\trep->part[0].remote_hdr = NULL;\n\t\trep->part[0].hdr = NULL;\n\t\trep->part[0].hdrsize = 0;\n\t\trep->part[0].addr = NULL;\n\t\trep->part[0].size = 0;\n\t}\n\n\treturn 0;\n}\n\n/*\n * util_poolset_append_new_part -- (internal) creates a new part in each replica\n *\tof the poolset\n */\nstatic int\nutil_poolset_append_new_part(struct pool_set *set, size_t size)\n{\n\tLOG(3, \"set %p size %zu\", set, size);\n\n\tif (!set->directory_based)\n\t\treturn -1;\n\n\tstruct pool_set_directory *d;\n\tsize_t directory_id;\n\tchar *path;\n\tsize_t path_len;\n\n\tunsigned r;\n\tfor (r = 0; r < set->nreplicas; ++r) {\n\t\tstruct pool_replica *rep = set->replica[r];\n\n\t\tdirectory_id = set->next_directory_id %\n\t\t\tVEC_SIZE(&rep->directory);\n\t\td = VEC_GET(&rep->directory, directory_id);\n\n\t\tpath_len = strlen(d->path) + PMEM_FILE_MAX_LEN;\n\t\tif ((path = Malloc(path_len)) == NULL) {\n\t\t\tERR(\"!Malloc\");\n\t\t\tgoto err_part_init;\n\t\t}\n\n\t\tsnprintf(path, path_len, \"%s\" OS_DIR_SEP_STR \"%0*u%s\",\n\t\t\td->path, PMEM_FILE_PADDING, set->next_id, PMEM_EXT);\n\n\t\tif (util_replica_add_part(&set->replica[r], path, size) != 0)\n\t\t\tFATAL(\"cannot add a new part to the replica info\");\n\t}\n\n\tset->next_directory_id += 1;\n\tset->next_id += 1;\n\n\tutil_poolset_set_size(set);\n\n\treturn 0;\n\nerr_part_init:\n\t/* for each replica 0..r-1 remove the last part */\n\tfor (unsigned rn = 0; rn < r; ++rn) {\n\t\tstruct pool_replica *rep = set->replica[rn];\n\t\tunsigned pidx = rep->nparts - 1;\n\t\tFree((void *)(rep->part[pidx].path));\n\t\trep->part[pidx].path = NULL;\n\t\trep->nparts--;\n\t}\n\n\treturn -1;\n}\n\n/*\n * util_pool_extend -- extends the poolset by the provided size\n */\nvoid *\nutil_pool_extend(struct pool_set *set, size_t *size, size_t minpartsize)\n{\n\tLOG(3, \"set %p size %zu minpartsize %zu\", set, *size, minpartsize);\n\n\tif (*size == 0) {\n\t\tERR(\"cannot extend pool by 0 bytes\");\n\t\treturn NULL;\n\t}\n\n\tif ((set->options & OPTION_SINGLEHDR) == 0) {\n\t\tERR(\n\t\t\"extending the pool by appending parts with headers is not supported!\");\n\t\treturn NULL;\n\t}\n\n\tif (set->poolsize + *size > set->resvsize) {\n\t\t*size = set->resvsize - set->poolsize;\n\t\tif (*size < minpartsize) {\n\t\t\tERR(\"exceeded reservation size\");\n\t\t\treturn NULL;\n\t\t}\n\t\tLOG(4, \"extend size adjusted to not exceed reservation size\");\n\t}\n\n\tsize_t old_poolsize = set->poolsize;\n\n\tif (util_poolset_append_new_part(set, *size) != 0) {\n\t\tERR(\"unable to append a new part to the pool\");\n\t\treturn NULL;\n\t}\n\n\tsize_t hdrsize = (set->options & OPTION_SINGLEHDR) ? 0 : Mmap_align;\n\tvoid *addr = NULL;\n\tvoid *addr_base = NULL;\n\n\tunsigned r;\n\tfor (r = 0; r < set->nreplicas; r++) {\n\t\tstruct pool_replica *rep = set->replica[r];\n\t\tunsigned pidx = rep->nparts - 1;\n\t\tstruct pool_set_part *p = &rep->part[pidx];\n\n\t\tif (util_part_open(p, 0, 1 /* create */) != 0) {\n\t\t\tERR(\"cannot open the new part\");\n\t\t\tgoto err;\n\t\t}\n\n\t\taddr = (char *)rep->part[0].addr + old_poolsize;\n\t\tif (addr_base == NULL)\n\t\t\taddr_base = addr;\n\n\t\tif (util_map_part(p, addr, 0, hdrsize,\n\t\t\t\tMAP_SHARED | MAP_FIXED, 0) != 0) {\n\t\t\tERR(\"cannot map the new part\");\n\t\t\tgoto err;\n\t\t}\n\n\t\t/*\n\t\t * new part must be mapped the same way as all the rest\n\t\t * within a replica\n\t\t */\n\t\tif (p->map_sync != rep->part[0].map_sync) {\n\t\t\tif (p->map_sync)\n\t\t\t\tERR(\"new part cannot be mapped with MAP_SYNC\");\n\t\t\telse\n\t\t\t\tERR(\"new part mapped with MAP_SYNC\");\n\t\t\tgoto err;\n\t\t}\n\t}\n\n\t/* XXX: mode should be the same as for pmemxxx_create() */\n\tif (util_poolset_chmod(set, S_IWUSR | S_IRUSR))\n\t\tgoto err;\n\n\tutil_poolset_fdclose(set);\n\n\treturn addr_base;\n\nerr:\n\tfor (unsigned rn = 0; rn <= r; ++rn) {\n\t\tstruct pool_replica *rep = set->replica[r];\n\t\tunsigned pidx = rep->nparts - 1;\n\t\tstruct pool_set_part *p = &rep->part[pidx];\n\t\trep->nparts--;\n\n\t\tif (p->fd != 0)\n\t\t\t(void) os_close(p->fd);\n\t\tif (p->created)\n\t\t\tos_unlink(p->path);\n\t\tFree((void *)p->path);\n\t\tp->path = NULL;\n\t}\n\tutil_poolset_set_size(set);\n\n\treturn NULL;\n}\n\n/*\n * util_print_bad_files_cb -- (internal) callback printing names of pool files\n *                            containing bad blocks\n */\nstatic int\nutil_print_bad_files_cb(struct part_file *pf, void *arg)\n{\n\tif (!pf->is_remote && pf->part && pf->part->has_bad_blocks)\n\t\tERR(\"file contains bad blocks -- '%s'\", pf->part->path);\n\n\treturn 0;\n}\n\n/*\n * util_pool_create_uuids -- create a new memory pool (set or a single file)\n *                           with given uuids\n *\n * On success returns 0 and a pointer to a newly allocated structure\n * containing the info of all the parts of the pool set and replicas.\n */\nint\nutil_pool_create_uuids(struct pool_set **setp, const char *path,\n\tsize_t poolsize, size_t minsize, size_t minpartsize,\n\tconst struct pool_attr *attr, unsigned *nlanes, int can_have_rep,\n\tint remote)\n{\n\tLOG(3, \"setp %p path %s poolsize %zu minsize %zu minpartsize %zu \"\n\t\t\"pattr %p nlanes %p can_have_rep %i remote %i\", setp, path,\n\t\tpoolsize, minsize, minpartsize, attr, nlanes, can_have_rep,\n\t\tremote);\n\n\t/* attributes cannot be NULL for local replicas */\n\tASSERT(remote || attr != NULL);\n\n\tint flags = MAP_SHARED;\n\tint oerrno;\n\n\tint exists = util_file_exists(path);\n\tif (exists < 0)\n\t\treturn -1;\n\n\t/* check if file exists */\n\tif (poolsize > 0 && exists) {\n\t\tERR(\"file %s already exists\", path);\n\t\terrno = EEXIST;\n\t\treturn -1;\n\t}\n\n\tint ret = util_poolset_create_set(setp, path, poolsize, minsize,\n\t\t\tIGNORE_SDS(attr));\n\tif (ret < 0) {\n\t\tLOG(2, \"cannot create pool set -- '%s'\", path);\n\t\treturn -1;\n\t}\n\n\tstruct pool_set *set = *setp;\n\n\tASSERT(set->nreplicas > 0);\n\n\tif (!remote && (set->options & OPTION_NOHDRS)) {\n\t\tERR(\n\t\t\t\"the NOHDRS poolset option is not supported for local poolsets\");\n\t\terrno = EINVAL;\n\t\tgoto err_poolset_free;\n\t}\n\n\tif ((attr == NULL) != ((set->options & OPTION_NOHDRS) != 0)) {\n\t\tERR(\n\t\t\t\"pool attributes are not supported for poolsets without headers (with the NOHDRS option)\");\n\t\terrno = EINVAL;\n\t\tgoto err_poolset_free;\n\t}\n\n\tif (set->directory_based && ((set->options & OPTION_SINGLEHDR) == 0)) {\n\t\tERR(\n\t\t\t\"directory based pools are not supported for poolsets with headers (without SINGLEHDR option)\");\n\t\terrno = EINVAL;\n\t\tgoto err_poolset_free;\n\t}\n\n\tif (set->resvsize < minsize) {\n\t\tERR(\"reservation pool size %zu smaller than %zu\",\n\t\t\tset->resvsize, minsize);\n\t\terrno = EINVAL;\n\t\tgoto err_poolset_free;\n\t}\n\n\tif (set->directory_based && set->poolsize == 0 &&\n\t\t\tutil_poolset_append_new_part(set, minsize) != 0) {\n\t\tERR(\"cannot create a new part in provided directories\");\n\t\tgoto err_poolset_free;\n\t}\n\n\tif (attr != NULL &&\n\t    (attr->features.compat & POOL_FEAT_CHECK_BAD_BLOCKS)) {\n\t\tint bbs = badblocks_check_poolset(set, 1 /* create */);\n\t\tif (bbs < 0) {\n\t\t\tLOG(1,\n\t\t\t\t\"failed to check pool set for bad blocks -- '%s'\",\n\t\t\t\tpath);\n\t\t\tgoto err_poolset_free;\n\t\t}\n\n\t\tif (bbs > 0) {\n\t\t\tutil_poolset_foreach_part_struct(set,\n\t\t\t\t\t\t\tutil_print_bad_files_cb,\n\t\t\t\t\t\t\tNULL);\n\t\t\tERR(\n\t\t\t\t\"pool set contains bad blocks and cannot be created, run 'pmempool create --clear-bad-blocks' utility to clear bad blocks and create a pool\");\n\t\t\terrno = EIO;\n\t\t\tgoto err_poolset_free;\n\t\t}\n\t}\n\n\tif (set->poolsize < minsize) {\n\t\tERR(\"net pool size %zu smaller than %zu\",\n\t\t\tset->poolsize, minsize);\n\t\terrno = EINVAL;\n\t\tgoto err_poolset_free;\n\t}\n\n\tif (remote) {\n\t\t/* it is a remote replica - it cannot have replicas */\n\t\tif (set->nreplicas > 1) {\n\t\t\tLOG(2, \"remote pool set cannot have replicas\");\n\t\t\terrno = EINVAL;\n\t\t\tgoto err_poolset_free;\n\t\t}\n\n\t\t/* check if poolset options match remote pool attributes */\n\t\tif (attr != NULL &&\n\t\t\t\t((set->options & OPTION_SINGLEHDR) == 0) !=\n\t\t\t\t((attr->features.incompat &\n\t\t\t\t\t\tPOOL_FEAT_SINGLEHDR) == 0)) {\n\t\t\tERR(\n\t\t\t\t\"pool incompat feature flags and remote poolset options do not match\");\n\t\t\terrno = EINVAL;\n\t\t\tgoto err_poolset_free;\n\t\t}\n\t}\n\n\tif (!can_have_rep && set->nreplicas > 1) {\n\t\tERR(\"replication not supported\");\n\t\terrno = ENOTSUP;\n\t\tgoto err_poolset_free;\n\t}\n\n\tif (set->remote && util_remote_load()) {\n\t\tERR(\n\t\t\t\"the pool set requires a remote replica, but the '%s' library cannot be loaded\",\n\t\t\tLIBRARY_REMOTE);\n\t\tgoto err_poolset_free;\n\t}\n\n\tset->zeroed = 1;\n\n\tif (attr != NULL) {\n\t\tif (!util_is_zeroed(attr->poolset_uuid, POOL_HDR_UUID_LEN)) {\n\t\t\tmemcpy(set->uuid, attr->poolset_uuid,\n\t\t\t\t\tPOOL_HDR_UUID_LEN);\n\t\t} else {\n\t\t\t/* generate pool set UUID */\n\t\t\tret = util_uuid_generate(set->uuid);\n\t\t\tif (ret < 0) {\n\t\t\t\tLOG(2, \"cannot generate pool set UUID\");\n\t\t\t\tgoto err_poolset;\n\t\t\t}\n\t\t}\n\n\t\t/* generate UUID's for all the parts */\n\t\tfor (unsigned r = 0; r < set->nreplicas; r++) {\n\t\t\tstruct pool_replica *rep = set->replica[r];\n\t\t\tfor (unsigned i = 0; i < rep->nhdrs; i++) {\n\t\t\t\tret = util_uuid_generate(rep->part[i].uuid);\n\t\t\t\tif (ret < 0) {\n\t\t\t\t\tLOG(2,\n\t\t\t\t\t\"cannot generate pool set part UUID\");\n\t\t\t\t\tgoto err_poolset;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t/* overwrite UUID of the first part if given */\n\t\tif (!util_is_zeroed(attr->first_part_uuid, POOL_HDR_UUID_LEN)) {\n\t\t\tmemcpy(set->replica[0]->part[0].uuid,\n\t\t\t\tattr->first_part_uuid, POOL_HDR_UUID_LEN);\n\t\t}\n\t}\n\n\tret = util_poolset_files_local(set, minpartsize, 1);\n\tif (ret != 0)\n\t\tgoto err_poolset;\n\n\t/* map first local replica - it has to exist prior to remote ones */\n\tret = util_replica_map_local(set, 0, flags);\n\tif (ret != 0)\n\t\tgoto err_poolset;\n\n\t/* prepare remote replicas first */\n\tif (set->remote) {\n\t\tfor (unsigned r = 0; r < set->nreplicas; r++) {\n\t\t\tif (REP(set, r)->remote == NULL) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (util_replica_create_remote(set, r, flags, attr) !=\n\t\t\t\t\t0) {\n\t\t\t\tLOG(2, \"replica #%u creation failed\", r);\n\t\t\t\tgoto err_create;\n\t\t\t}\n\t\t}\n\n\t\tret = util_poolset_files_remote(set, minsize, nlanes,\n\t\t\t\t1 /* create */);\n\t\tif (ret != 0)\n\t\t\tgoto err_create;\n\t}\n\n\t/* prepare local replicas */\n\tif (remote) {\n\t\tif (util_replica_create_local(set, 0, flags, attr) != 0) {\n\t\t\tLOG(2, \"replica #0 creation failed\");\n\t\t\tgoto err_create;\n\t\t}\n\t} else {\n\t\tfor (unsigned r = 0; r < set->nreplicas; r++) {\n\t\t\tif (REP(set, r)->remote != NULL) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (util_replica_create_local(set, r, flags, attr) !=\n\t\t\t\t\t0) {\n\t\t\t\tLOG(2, \"replica #%u creation failed\", r);\n\t\t\t\tgoto err_create;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn 0;\n\nerr_create:\n\toerrno = errno;\n\tfor (unsigned r = 0; r < set->nreplicas; r++)\n\t\tutil_replica_close(set, r);\n\terrno = oerrno;\nerr_poolset:\n\toerrno = errno;\n\tutil_poolset_close(set, DELETE_CREATED_PARTS);\n\terrno = oerrno;\n\treturn -1;\n\nerr_poolset_free:\n\toerrno = errno;\n\tutil_poolset_free(set);\n\terrno = oerrno;\n\treturn -1;\n}\n\n/*\n * util_pool_create -- create a new memory pool (set or a single file)\n *\n * On success returns 0 and a pointer to a newly allocated structure\n * containing the info of all the parts of the pool set and replicas.\n */\nint\nutil_pool_create(struct pool_set **setp, const char *path, size_t poolsize,\n\tsize_t minsize, size_t minpartsize, const struct pool_attr *attr,\n\tunsigned *nlanes, int can_have_rep)\n{\n\tLOG(3, \"setp %p path %s poolsize %zu minsize %zu minpartsize %zu \"\n\t\t\"attr %p nlanes %p can_have_rep %i\", setp, path, poolsize,\n\t\tminsize, minpartsize, attr, nlanes, can_have_rep);\n\n\treturn util_pool_create_uuids(setp, path, poolsize, minsize,\n\t\t\tminpartsize, attr, nlanes, can_have_rep, POOL_LOCAL);\n}\n\n/*\n * util_replica_open_local -- (internal) open a memory pool local replica\n */\nstatic int\nutil_replica_open_local(struct pool_set *set, unsigned repidx, int flags)\n{\n\tLOG(3, \"set %p repidx %u flags %d\", set, repidx, flags);\n\n\tint remaining_retries = 10;\n\tint retry_for_contiguous_addr;\n\tsize_t mapsize;\n\tsize_t hdrsize = (set->options & (OPTION_SINGLEHDR | OPTION_NOHDRS)) ?\n\t\t\t0 : Mmap_align;\n\tstruct pool_replica *rep = set->replica[repidx];\n\tvoid *addr = NULL;\n\n\tdo {\n\t\tretry_for_contiguous_addr = 0;\n\n\t\t/* determine a hint address for mmap() if not specified */\n\t\tif (addr == NULL)\n\t\t\taddr = util_map_hint(rep->resvsize, 0);\n\t\tif (addr == MAP_FAILED) {\n\t\t\tLOG(1, \"cannot find a contiguous region of given size\");\n\t\t\treturn -1;\n\t\t}\n\n\t\tmapsize = rep->part[0].filesize & ~(Mmap_align - 1);\n\n\t\t/* map the first part and reserve space for remaining parts */\n\t\tif (util_map_part(&rep->part[0], addr, rep->resvsize, 0,\n\t\t\t\tflags, 0) != 0) {\n\t\t\tLOG(2, \"pool mapping failed - replica #%u part #0\",\n\t\t\t\trepidx);\n\t\t\treturn -1;\n\t\t}\n\n\t\tVALGRIND_REGISTER_PMEM_MAPPING(rep->part[0].addr,\n\t\t\trep->resvsize);\n\t\tVALGRIND_REGISTER_PMEM_FILE(rep->part[0].fd,\n\t\t\trep->part[0].addr, rep->resvsize, 0);\n\n\t\t/* map all headers - don't care about the address */\n\t\tfor (unsigned p = 0; p < rep->nhdrs; p++) {\n\t\t\tif (util_map_hdr(&rep->part[p], flags, 0) != 0) {\n\t\t\t\tLOG(2, \"header mapping failed - part #%d\", p);\n\t\t\t\tgoto err;\n\t\t\t}\n\t\t}\n\n\t\taddr = (char *)rep->part[0].addr + mapsize;\n\n\t\t/*\n\t\t * map the remaining parts of the usable pool space\n\t\t * (aligned to memory mapping granularity)\n\t\t */\n\t\tfor (unsigned p = 1; p < rep->nparts; p++) {\n\t\t\tstruct pool_set_part *part = &rep->part[p];\n\t\t\tsize_t targetsize = mapsize +\n\t\t\t\tALIGN_DOWN(part->filesize - hdrsize,\n\t\t\t\tpart->alignment);\n\t\t\tif (targetsize > rep->resvsize) {\n\t\t\t\tERR(\n\t\t\t\t\t\"pool mapping failed - address space reservation too small\");\n\t\t\t\terrno = EINVAL;\n\t\t\t\tgoto err;\n\t\t\t}\n\n\t\t\t/* map data part */\n\t\t\tif (util_map_part(part, addr, 0, hdrsize,\n\t\t\t\t\tflags | MAP_FIXED, 0) != 0) {\n\t\t\t\t/*\n\t\t\t\t * if we can't map the part at the address we\n\t\t\t\t * asked for, unmap all the parts that are\n\t\t\t\t * mapped and remap at a different address.\n\t\t\t\t */\n\t\t\t\tif ((errno == EINVAL) &&\n\t\t\t\t    (remaining_retries > 0)) {\n\t\t\t\t\tLOG(2, \"usable space mapping failed - \"\n\t\t\t\t\t\t\"part #%d - retrying\", p);\n\t\t\t\t\tretry_for_contiguous_addr = 1;\n\t\t\t\t\tremaining_retries--;\n\n\t\t\t\t\tutil_unmap_parts(rep, 0, p - 1);\n\n\t\t\t\t\t/* release rest of the VA reserved */\n\t\t\t\t\tmunmap(rep->part[0].addr,\n\t\t\t\t\t\trep->resvsize);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tLOG(2, \"usable space mapping failed - part #%d\",\n\t\t\t\t\tp);\n\t\t\t\tgoto err;\n\t\t\t}\n\n\t\t\tVALGRIND_REGISTER_PMEM_FILE(part->fd,\n\t\t\t\tpart->addr, part->size, hdrsize);\n\n\t\t\tmapsize += part->size;\n\t\t\taddr = (char *)addr + part->size;\n\t\t}\n\t} while (retry_for_contiguous_addr);\n\n\t/*\n\t * Initially part[0].size is the size of address space\n\t * reservation for all parts from given replica. After\n\t * mapping that space we need to overwrite part[0].size\n\t * with its actual size to be consistent - size for each\n\t * part should be the actual mapping size of this part\n\t * only - it simplifies future calculations.\n\t */\n\trep->part[0].size = rep->part[0].filesize & ~(Mmap_align - 1);\n\n\tif (util_replica_check_map_sync(set, repidx, 1))\n\t\tgoto err;\n\n\tutil_replica_set_is_pmem(rep);\n\n\tif (Prefault_at_open)\n\t\tutil_replica_force_page_allocation(rep);\n\n\tASSERTeq(mapsize, rep->repsize);\n\n\t/* calculate pool size - choose the smallest replica size */\n\tif (rep->repsize < set->poolsize)\n\t\tset->poolsize = rep->repsize;\n\n\tLOG(3, \"replica addr %p\", rep->part[0].addr);\n\n\treturn 0;\nerr:\n\tLOG(4, \"error clean up\");\n\tint oerrno = errno;\n\tif (mapsize < rep->repsize) {\n\t\tASSERTne(rep->part[0].addr, NULL);\n\t\tASSERTne(rep->part[0].addr, MAP_FAILED);\n\t\tmunmap(rep->part[0].addr, rep->resvsize - mapsize);\n\t}\n\tfor (unsigned p = 0; p < rep->nhdrs; p++)\n\t\tutil_unmap_hdr(&rep->part[p]);\n\tfor (unsigned p = 0; p < rep->nparts; p++)\n\t\tutil_unmap_part(&rep->part[p]);\n\terrno = oerrno;\n\treturn -1;\n}\n\n/*\n * util_replica_open_remote -- open a memory pool for remote replica\n */\nint\nutil_replica_open_remote(struct pool_set *set, unsigned repidx, int flags)\n{\n\tLOG(3, \"set %p repidx %u flags %d\", set, repidx, flags);\n\n\tstruct pool_replica *rep = set->replica[repidx];\n\n\tASSERTne(rep->remote, NULL);\n\tASSERTne(rep->part, NULL);\n\tASSERTeq(rep->nparts, 1);\n\tASSERTeq(rep->nhdrs, 1);\n\n\tstruct pool_set_part *part = rep->part;\n\n\tpart->size = rep->repsize;\n\tASSERT(IS_PAGE_ALIGNED(part->size));\n\tpart->remote_hdr = Zalloc(part->size + Pagesize);\n\tif (!part->remote_hdr) {\n\t\tERR(\"!Zalloc\");\n\t\treturn -1;\n\t}\n\n\tpart->hdr = PAGE_ALIGN_UP(part->remote_hdr);\n\tpart->addr = PAGE_ALIGN_UP(part->remote_hdr);\n\tpart->hdrsize = POOL_HDR_SIZE;\n\n\tLOG(3, \"replica #%u addr %p\", repidx, rep->part[0].addr);\n\n\treturn 0;\n}\n\n/*\n * util_replica_open -- open a memory pool replica\n */\nint\nutil_replica_open(struct pool_set *set, unsigned repidx, int flags)\n{\n\tLOG(3, \"set %p repidx %u flags %d\", set, repidx, flags);\n\n\tif (set->replica[repidx]->remote)\n\t\treturn util_replica_open_remote(set, repidx, flags);\n\n\treturn util_replica_open_local(set, repidx, flags);\n}\n\n/*\n * util_replica_set_attr -- overwrite existing replica attributes\n */\nint\nutil_replica_set_attr(struct pool_replica *rep,\n\t\tconst struct rpmem_pool_attr *rattr)\n{\n\tLOG(3, \"rep %p, rattr %p\", rep, rattr);\n\tASSERT(rattr != NULL || rep->nhdrs == 0);\n\n\tif (rattr != NULL && rep->nhdrs == 0) {\n\t\tERR(\n\t\t\"cannot set pool attributes for a replica without headers (with the NOHDRS option)\");\n\t\terrno = EINVAL;\n\t\treturn -1;\n\t}\n\tint flags = MAP_SHARED;\n\n\t/* map all headers - don't care about the address */\n\tfor (unsigned p = 0; p < rep->nparts; p++) {\n\t\tif (util_map_hdr(&rep->part[p], flags, 0) != 0) {\n\t\t\tLOG(2, \"header mapping failed - part #%d\", p);\n\t\t\tgoto err;\n\t\t}\n\t}\n\n\tfor (unsigned p = 0; p < rep->nhdrs; p++) {\n\t\tASSERTne(rattr, NULL);\n\n\t\tstruct pool_hdr *hdrp = HDR(rep, p);\n\t\tASSERTne(hdrp, NULL);\n\t\tutil_convert2h_hdr_nocheck(hdrp);\n\n\t\tutil_set_rpmem_attr(hdrp, rattr);\n\n\t\tif (hdrp == HDR(rep, 0))\n\t\t\tmemcpy(hdrp->uuid, rattr->uuid, POOL_HDR_UUID_LEN);\n\t\tif (hdrp == HDRP(rep, 0))\n\t\t\tmemcpy(hdrp->next_part_uuid, rattr->uuid,\n\t\t\t\t\tPOOL_HDR_UUID_LEN);\n\t\tif (hdrp == HDRN(rep, 0))\n\t\t\tmemcpy(hdrp->prev_part_uuid, rattr->uuid,\n\t\t\t\t\tPOOL_HDR_UUID_LEN);\n\n\t\tutil_convert2le_hdr(hdrp);\n\n\t\tutil_checksum(hdrp, sizeof(*hdrp), &hdrp->checksum,\n\t\t\t1, POOL_HDR_CSUM_END_OFF(hdrp));\n\n\t\t/* store pool's header */\n\t\tutil_persist_auto(rep->is_pmem, hdrp, sizeof(*hdrp));\n\t}\n\n\t/* unmap all headers */\n\tfor (unsigned p = 0; p < rep->nhdrs; p++)\n\t\tutil_unmap_hdr(&rep->part[p]);\n\n\treturn 0;\nerr:\n\tfor (unsigned p = 0; p < rep->nhdrs; p++) {\n\t\tutil_unmap_hdr(&rep->part[p]);\n\t}\n\treturn -1;\n}\n\n/*\n * util_get_attr_from_header -- get pool attributes from a pool header\n */\nvoid\nutil_pool_hdr2attr(struct pool_attr *attr, struct pool_hdr *hdr)\n{\n\tLOG(3, \"attr %p, hdr %p\", attr, hdr);\n\tASSERTne(attr, NULL);\n\tASSERTne(hdr, NULL);\n\tmemset(attr, 0, sizeof(*attr));\n\tmemcpy(attr->signature, hdr->signature, POOL_HDR_SIG_LEN);\n\tattr->major = hdr->major;\n\tattr->features.compat = hdr->features.compat;\n\tattr->features.incompat = hdr->features.incompat;\n\tattr->features.ro_compat = hdr->features.ro_compat;\n\tmemcpy(attr->poolset_uuid, hdr->poolset_uuid, POOL_HDR_UUID_LEN);\n}\n\n/*\n * util_copy_attr_to_header -- copy pool attributes into pool header\n */\nvoid\nutil_pool_attr2hdr(struct pool_hdr *hdr, const struct pool_attr *attr)\n{\n\tLOG(3, \"hdr %p, attr %p\", hdr, attr);\n\tASSERTne(hdr, NULL);\n\tASSERTne(attr, NULL);\n\tmemcpy(hdr->signature, attr->signature, POOL_HDR_SIG_LEN);\n\thdr->major = attr->major;\n\thdr->features.compat = attr->features.compat;\n\thdr->features.incompat = attr->features.incompat;\n\thdr->features.ro_compat = attr->features.ro_compat;\n}\n\n/*\n * util_unmap_all_hdrs -- unmap all pool set headers\n */\nstatic void\nutil_unmap_all_hdrs(struct pool_set *set)\n{\n\tLOG(3, \"set %p\", set);\n\n\tfor (unsigned r = 0; r < set->nreplicas; r++) {\n\t\tstruct pool_replica *rep = set->replica[r];\n\t\tif (rep->remote == NULL) {\n\t\t\tfor (unsigned p = 0; p < rep->nhdrs; p++)\n\t\t\t\tutil_unmap_hdr(&rep->part[p]);\n\t\t} else {\n\t\t\t/*\n\t\t\t * hdr & hdrsize were set only for util_header_check(),\n\t\t\t * they will not be used any more. The memory will be\n\t\t\t * freed by util_replica_close()\n\t\t\t */\n\t\t\trep->part[0].hdr = NULL;\n\t\t\trep->part[0].hdrsize = 0;\n\t\t}\n\t}\n}\n\n/*\n * util_replica_check -- check headers, check UUID's, check replicas linkage\n */\nstatic int\nutil_replica_check(struct pool_set *set, const struct pool_attr *attr)\n{\n\tLOG(3, \"set %p attr %p\", set, attr);\n\n\t/* read shutdown state toggle from header */\n\tset->ignore_sds |= IGNORE_SDS(HDR(REP(set, 0), 0));\n\n\tfor (unsigned r = 0; r < set->nreplicas; r++) {\n\t\tstruct pool_replica *rep = set->replica[r];\n\t\tfor (unsigned p = 0; p < rep->nhdrs; p++) {\n\t\t\tif (util_header_check(set, r, p, attr) != 0) {\n\t\t\t\tLOG(2, \"header check failed - part #%d\", p);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tset->rdonly |= rep->part[p].rdonly;\n\t\t}\n\n\t\tif (memcmp(HDR(REPP(set, r), 0)->uuid,\n\t\t\t\t\tHDR(REP(set, r), 0)->prev_repl_uuid,\n\t\t\t\t\tPOOL_HDR_UUID_LEN) ||\n\t\t    memcmp(HDR(REPN(set, r), 0)->uuid,\n\t\t\t\t\tHDR(REP(set, r), 0)->next_repl_uuid,\n\t\t\t\t\tPOOL_HDR_UUID_LEN)) {\n\t\t\tERR(\"wrong replica UUID\");\n\t\t\terrno = EINVAL;\n\t\t\treturn -1;\n\t\t}\n\t\tif (!set->ignore_sds && !rep->remote && rep->nhdrs) {\n\t\t\tstruct shutdown_state sds;\n\t\t\tshutdown_state_init(&sds, NULL);\n\t\t\tfor (unsigned p = 0; p < rep->nparts; p++) {\n\t\t\t\tif (shutdown_state_add_part(&sds,\n\t\t\t\t\t\tPART(rep, p)->path, NULL))\n\t\t\t\t\treturn -1;\n\t\t\t}\n\n\t\t\tASSERTne(rep->nhdrs, 0);\n\t\t\tASSERTne(rep->nparts, 0);\n\t\t\tif (shutdown_state_check(&sds, &HDR(rep, 0)->sds,\n\t\t\t\t\trep)) {\n\t\t\t\tLOG(2, \"ADR failure detected\");\n\t\t\t\terrno = EINVAL;\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tshutdown_state_set_dirty(&HDR(rep, 0)->sds,\n\t\t\t\trep);\n\t\t}\n\t}\n\treturn 0;\n}\n\n/*\n * util_pool_has_device_dax -- (internal) check if poolset has any device dax\n */\nint\nutil_pool_has_device_dax(struct pool_set *set)\n{\n\tfor (unsigned r = 0; r < set->nreplicas; ++r) {\n\t\tstruct pool_replica *rep = REP(set, r);\n\t\t/* either all the parts must be Device DAX or none */\n\t\tif (PART(rep, 0)->is_dev_dax)\n\t\t\treturn 1;\n\t}\n\treturn 0;\n}\n\n/*\n * util_pool_open_nocheck -- open a memory pool (set or a single file)\n *\n * This function opens a pool set without checking the header values.\n */\nint\nutil_pool_open_nocheck(struct pool_set *set, unsigned flags)\n{\n\tLOG(3, \"set %p flags 0x%x\", set, flags);\n\n\tint cow = flags & POOL_OPEN_COW;\n\n\tif (cow && util_pool_has_device_dax(set)) {\n\t\tERR(\"device dax cannot be mapped privately\");\n\t\terrno = ENOTSUP;\n\t\treturn -1;\n\t}\n\n\tint mmap_flags = cow ? MAP_PRIVATE|MAP_NORESERVE : MAP_SHARED;\n\tint oerrno;\n\n\tASSERTne(set, NULL);\n\tASSERT(set->nreplicas > 0);\n\n\tif (flags & POOL_OPEN_CHECK_BAD_BLOCKS) {\n\t\t/* check if any bad block recovery file exists */\n\t\tint bfe = badblocks_recovery_file_exists(set);\n\t\tif (bfe > 0) {\n\t\t\tERR(\n\t\t\t\t\"error: a bad block recovery file exists, run 'pmempool sync --bad-blocks' utility to try to recover the pool\");\n\t\t\terrno = EINVAL;\n\t\t\treturn -1;\n\t\t}\n\t\tif (bfe < 0) {\n\t\t\tLOG(1,\n\t\t\t\t\"an error occurred when checking whether recovery file exists.\");\n\t\t\treturn -1;\n\t\t}\n\n\t\tint bbs = badblocks_check_poolset(set, 0 /* not create */);\n\t\tif (bbs < 0) {\n\t\t\tLOG(1, \"failed to check pool set for bad blocks\");\n\t\t\treturn -1;\n\t\t}\n\n\t\tif (bbs > 0) {\n\t\t\tif (flags & POOL_OPEN_IGNORE_BAD_BLOCKS) {\n\t\t\t\tLOG(1,\n\t\t\t\t\t\"WARNING: pool set contains bad blocks, ignoring\");\n\t\t\t} else {\n\t\t\t\tERR(\n\t\t\t\t\t\"pool set contains bad blocks and cannot be opened, run 'pmempool sync --bad-blocks' utility to try to recover the pool\");\n\t\t\t\terrno = EIO;\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (set->remote && util_remote_load()) {\n\t\tERR(\"the pool set requires a remote replica, \"\n\t\t\t\"but the '%s' library cannot be loaded\",\n\t\t\tLIBRARY_REMOTE);\n\t\treturn -1;\n\t}\n\n\tint ret = util_poolset_files_local(set, 0 /* minpartsize */, 0);\n\tif (ret != 0)\n\t\tgoto err_poolset;\n\n\tset->rdonly = 0;\n\n\tfor (unsigned r = 0; r < set->nreplicas; r++) {\n\t\tif (util_replica_open(set, r, mmap_flags) != 0) {\n\t\t\tLOG(2, \"replica #%u open failed\", r);\n\t\t\tgoto err_replica;\n\t\t}\n\t}\n\n\tif (set->remote) {\n\t\tret = util_poolset_files_remote(set, 0, NULL, 0);\n\t\tif (ret != 0)\n\t\t\tgoto err_replica;\n\t}\n\n\tutil_unmap_all_hdrs(set);\n\n\treturn 0;\n\nerr_replica:\n\tLOG(4, \"error clean up\");\n\toerrno = errno;\n\tfor (unsigned r = 0; r < set->nreplicas; r++)\n\t\tutil_replica_close(set, r);\n\terrno = oerrno;\nerr_poolset:\n\toerrno = errno;\n\tutil_poolset_close(set, DO_NOT_DELETE_PARTS);\n\terrno = oerrno;\n\treturn -1;\n}\n\n/*\n * util_read_compat_features -- (internal) read compat features from the header\n */\nstatic int\nutil_read_compat_features(struct pool_set *set, uint32_t *compat_features)\n{\n\tLOG(3, \"set %p pcompat_features %p\", set, compat_features);\n\n\t*compat_features = 0;\n\n\tfor (unsigned r = 0; r < set->nreplicas; r++) {\n\t\tstruct pool_replica *rep = set->replica[r];\n\n\t\tif (rep->remote)\n\t\t\tcontinue;\n\n\t\tfor (unsigned p = 0; p < rep->nparts; p++) {\n\t\t\tstruct pool_set_part *part = &rep->part[p];\n\n\t\t\tif (util_part_open(part, 0, 0 /* create */)) {\n\t\t\t\tLOG(1, \"!cannot open the part -- \\\"%s\\\"\",\n\t\t\t\t\tpart->path);\n\t\t\t\t/* try to open the next part */\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (util_map_hdr(part, MAP_SHARED, 0) != 0) {\n\t\t\t\tLOG(1, \"header mapping failed -- \\\"%s\\\"\",\n\t\t\t\t\tpart->path);\n\t\t\t\tutil_part_fdclose(part);\n\t\t\t\treturn -1;\n\t\t\t}\n\n\t\t\tstruct pool_hdr *hdrp = part->hdr;\n\t\t\t*compat_features = hdrp->features.compat;\n\n\t\t\tutil_unmap_hdr(part);\n\t\t\tutil_part_fdclose(part);\n\n\t\t\t/* exit on the first successfully opened part */\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n/*\n * unlink_remote_replicas -- removes remote replicas from poolset\n *\n * It is necessary when COW flag is set because remote replicas\n * cannot be mapped privately\n */\nstatic int\nunlink_remote_replicas(struct pool_set *set)\n{\n\tunsigned i = 0;\n\twhile (i < set->nreplicas) {\n\t\tif (set->replica[i]->remote == NULL) {\n\t\t\ti++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tutil_replica_close(set, i);\n\t\tint ret = util_replica_close_remote(set->replica[i], i,\n\t\t\t\tDO_NOT_DELETE_PARTS);\n\t\tif (ret != 0)\n\t\t\treturn ret;\n\n\t\tsize_t size = sizeof(set->replica[i]) *\n\t\t\t(set->nreplicas - i - 1);\n\t\tmemmove(&set->replica[i], &set->replica[i + 1], size);\n\t\tset->nreplicas--;\n\t}\n\n\tset->remote = 0;\n\treturn 0;\n}\n\n/*\n * util_pool_open -- open a memory pool (set or a single file)\n *\n * This routine does all the work, but takes a rdonly flag so internal\n * calls can map a read-only pool if required.\n */\nint\nutil_pool_open(struct pool_set **setp, const char *path, size_t minpartsize,\n\tconst struct pool_attr *attr, unsigned *nlanes, void *addr,\n\tunsigned flags)\n{\n\tLOG(3, \"setp %p path %s minpartsize %zu attr %p nlanes %p \"\n\t\t\"addr %p flags 0x%x \", setp, path, minpartsize, attr, nlanes,\n\t\taddr, flags);\n\n\tint cow = flags & POOL_OPEN_COW;\n\tint mmap_flags = cow ? MAP_PRIVATE|MAP_NORESERVE : MAP_SHARED;\n\tint oerrno;\n\n\t/* do not check minsize */\n\tint ret = util_poolset_create_set(setp, path, 0, 0,\n\t\t\t\t\t\tflags & POOL_OPEN_IGNORE_SDS);\n\tif (ret < 0) {\n\t\tLOG(2, \"cannot open pool set -- '%s'\", path);\n\t\treturn -1;\n\t}\n\n\tif ((*setp)->replica[0]->nparts == 0) {\n\t\terrno = ENOENT;\n\t\tERR(\"!no parts in replicas\");\n\t\tgoto err_poolset_free;\n\t}\n\n\tif (cow && (*setp)->replica[0]->part[0].is_dev_dax) {\n\t\tERR(\"device dax cannot be mapped privately\");\n\t\terrno = ENOTSUP;\n\t\tgoto err_poolset_free;\n\t}\n\n\tstruct pool_set *set = *setp;\n\n\tASSERT(set->nreplicas > 0);\n\n\tuint32_t compat_features;\n\n\tif (util_read_compat_features(set, &compat_features)) {\n\t\tLOG(1, \"reading compat features failed\");\n\t\tgoto err_poolset_free;\n\t}\n\n\tif (compat_features & POOL_FEAT_CHECK_BAD_BLOCKS) {\n\t\t/* check if any bad block recovery file exists */\n\t\tint bfe = badblocks_recovery_file_exists(set);\n\t\tif (bfe > 0) {\n\t\t\tERR(\n\t\t\t\t\"error: a bad block recovery file exists, run 'pmempool sync --bad-blocks' utility to try to recover the pool\");\n\t\t\terrno = EINVAL;\n\t\t\tgoto err_poolset_free;\n\t\t}\n\n\t\tif (bfe < 0) {\n\t\t\tLOG(1,\n\t\t\t\t\"an error occurred when checking whether recovery file exists.\");\n\t\t\tgoto err_poolset_free;\n\t\t}\n\n\t\tint bbs = badblocks_check_poolset(set, 0 /* not create */);\n\t\tif (bbs < 0) {\n\t\t\tLOG(1,\n\t\t\t\t\"failed to check pool set for bad blocks -- '%s'\",\n\t\t\t\tpath);\n\t\t\tgoto err_poolset_free;\n\t\t}\n\n\t\tif (bbs > 0) {\n\t\t\tif (flags & POOL_OPEN_IGNORE_BAD_BLOCKS) {\n\t\t\t\tLOG(1,\n\t\t\t\t\t\"WARNING: pool set contains bad blocks, ignoring -- '%s'\",\n\t\t\t\t\tpath);\n\t\t\t} else {\n\t\t\t\tERR(\n\t\t\t\t\t\"pool set contains bad blocks and cannot be opened, run 'pmempool sync --bad-blocks' utility to try to recover the pool -- '%s'\",\n\t\t\t\t\tpath);\n\t\t\t\terrno = EIO;\n\t\t\t\tgoto err_poolset_free;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (set->remote && util_remote_load()) {\n\t\tERR(\n\t\t\t\"the pool set requires a remote replica, but the '%s' library cannot be loaded\",\n\t\t\tLIBRARY_REMOTE);\n\t\tgoto err_poolset_free;\n\t}\n\n\tret = util_poolset_files_local(set, minpartsize, 0);\n\tif (ret != 0)\n\t\tgoto err_poolset;\n\n\tfor (unsigned r = 0; r < set->nreplicas; r++) {\n\t\tif (util_replica_open(set, r, mmap_flags) != 0) {\n\t\t\tLOG(2, \"replica #%u open failed\", r);\n\t\t\tgoto err_replica;\n\t\t}\n\t}\n\n\tif (set->remote) {\n\t\t/* do not check minsize */\n\t\tret = util_poolset_files_remote(set, 0, nlanes, 0);\n\t\tif (ret != 0)\n\t\t\tgoto err_replica;\n\t}\n\n\t/* check headers, check UUID's, check replicas linkage */\n\tif (attr != NULL && util_replica_check(set, attr))\n\t\tgoto err_replica;\n\n\t/* unmap all headers */\n\tutil_unmap_all_hdrs(set);\n\n\t/* remove all remote replicas from poolset when cow */\n\tif (cow && set->remote) {\n\t\tret = unlink_remote_replicas(set);\n\t\tif (ret != 0)\n\t\t\tgoto err_replica;\n\t}\n\n\treturn 0;\n\nerr_replica:\n\tLOG(4, \"error clean up\");\n\toerrno = errno;\n\tfor (unsigned r = 0; r < set->nreplicas; r++)\n\t\tutil_replica_close(set, r);\n\terrno = oerrno;\nerr_poolset:\n\toerrno = errno;\n\tutil_poolset_close(set, DO_NOT_DELETE_PARTS);\n\terrno = oerrno;\n\treturn -1;\n\nerr_poolset_free:\n\toerrno = errno;\n\tutil_poolset_free(*setp);\n\terrno = oerrno;\n\treturn -1;\n}\n\n/*\n * util_pool_open_remote -- open a remote pool set file\n *\n * This routine does all the work, but takes a rdonly flag so internal\n * calls can map a read-only pool if required.\n */\nint\nutil_pool_open_remote(struct pool_set **setp, const char *path, int cow,\n\tsize_t minpartsize, struct rpmem_pool_attr *rattr)\n{\n\tLOG(3, \"setp %p path %s cow %d minpartsize %zu rattr %p\",\n\t\tsetp, path, cow, minpartsize, rattr);\n\n\tint flags = cow ? MAP_PRIVATE|MAP_NORESERVE : MAP_SHARED;\n\tint oerrno;\n\n\t/* do not check minsize */\n\tint ret = util_poolset_create_set(setp, path, 0, 0, 0);\n\tif (ret < 0) {\n\t\tLOG(2, \"cannot open pool set -- '%s'\", path);\n\t\treturn -1;\n\t}\n\n\tif (cow && (*setp)->replica[0]->part[0].is_dev_dax) {\n\t\tERR(\"device dax cannot be mapped privately\");\n\t\terrno = ENOTSUP;\n\t\treturn -1;\n\t}\n\n\tstruct pool_set *set = *setp;\n\n\tif (set->nreplicas > 1) {\n\t\tLOG(2, \"remote pool set cannot have replicas\");\n\t\tgoto err_poolset;\n\t}\n\n\tuint32_t compat_features;\n\n\tif (util_read_compat_features(set, &compat_features)) {\n\t\tLOG(1, \"reading compat features failed\");\n\t\tgoto err_poolset;\n\t}\n\n\tif (compat_features & POOL_FEAT_CHECK_BAD_BLOCKS) {\n\t\t/* check if there are any bad blocks */\n\t\tint bbs = badblocks_check_poolset(set, 0 /* not create */);\n\t\tif (bbs < 0) {\n\t\t\tLOG(1,\n\t\t\t\t\"failed to check the remote replica for bad blocks -- '%s'\",\n\t\t\t\tpath);\n\t\t\tgoto err_poolset;\n\t\t}\n\n\t\tif (bbs > 0) {\n\t\t\tERR(\n\t\t\t\t\"remote replica contains bad blocks and cannot be opened, run 'pmempool sync --bad-blocks' utility to recreate it -- '%s'\",\n\t\t\t\tpath);\n\t\t\terrno = EIO;\n\t\t\tgoto err_poolset;\n\t\t}\n\t}\n\n\tret = util_poolset_files_local(set, minpartsize, 0);\n\tif (ret != 0)\n\t\tgoto err_poolset;\n\n\tif (util_replica_open(set, 0, flags) != 0) {\n\t\tLOG(2, \"replica open failed\");\n\t\tgoto err_replica;\n\t}\n\n\tstruct pool_replica *rep = set->replica[0];\n\n\tset->rdonly |= rep->part[0].rdonly;\n\n\t/* check headers, check UUID's, check replicas linkage */\n\tfor (unsigned p = 0; p < rep->nhdrs; p++) {\n\t\tif (util_header_check_remote(set, p) != 0) {\n\t\t\tLOG(2, \"header check failed - part #%d\", p);\n\t\t\tgoto err_replica;\n\t\t}\n\t\tset->rdonly |= rep->part[p].rdonly;\n\t}\n\n\tif (rep->nhdrs > 0) {\n\t\t/* header exists, copy pool attributes */\n\t\tstruct pool_hdr *hdr = rep->part[0].hdr;\n\t\tutil_get_rpmem_attr(rattr, hdr);\n\t} else {\n\t\t/* header does not exist, zero pool attributes */\n\t\tmemset(rattr, 0, sizeof(*rattr));\n\t}\n\n\t/* unmap all headers */\n\tfor (unsigned p = 0; p < rep->nhdrs; p++)\n\t\tutil_unmap_hdr(&rep->part[p]);\n\n\treturn 0;\n\nerr_replica:\n\tLOG(4, \"error clean up\");\n\toerrno = errno;\n\tutil_replica_close(set, 0);\n\terrno = oerrno;\nerr_poolset:\n\toerrno = errno;\n\tutil_poolset_close(set, DO_NOT_DELETE_PARTS);\n\terrno = oerrno;\n\treturn -1;\n}\n\n/*\n * util_is_poolset_file -- check if specified file is a poolset file\n *\n * Return value:\n * -1 - error\n *  0 - not a poolset\n *  1 - is a poolset\n */\nint\nutil_is_poolset_file(const char *path)\n{\n\tenum file_type type = util_file_get_type(path);\n\tif (type < 0)\n\t\treturn -1;\n\n\tif (type == TYPE_DEVDAX)\n\t\treturn 0;\n\n\tint fd = util_file_open(path, NULL, 0, O_RDONLY);\n\tif (fd < 0)\n\t\treturn -1;\n\n\tint ret = 0;\n\tssize_t sret;\n\tchar signature[POOLSET_HDR_SIG_LEN];\n\tsize_t rd = 0;\n\tdo {\n\t\tsret = util_read(fd, &signature[rd], sizeof(signature) - rd);\n\t\tif (sret > 0)\n\t\t\trd += (size_t)sret;\n\t} while (sret > 0);\n\tif (sret < 0) {\n\t\tERR(\"!read\");\n\t\tret = -1;\n\t\tgoto out;\n\t} else if (rd != sizeof(signature)) {\n\t\tret = 0;\n\t\tgoto out;\n\t}\n\n\tif (memcmp(signature, POOLSET_HDR_SIG, POOLSET_HDR_SIG_LEN) == 0)\n\t\tret = 1;\nout:\n\tos_close(fd);\n\treturn ret;\n}\n/*\n * util_poolset_foreach_part_struct -- walk through all poolset file parts\n *                                  of the given set\n *\n * Stops processing if callback returns non-zero value.\n * The value returned by callback is returned to the caller.\n */\nint\nutil_poolset_foreach_part_struct(struct pool_set *set,\n\tint (*callback)(struct part_file *pf, void *arg), void *arg)\n{\n\tLOG(3, \"set %p callback %p arg %p\", set, callback, arg);\n\n\tASSERTne(callback, NULL);\n\n\tint ret;\n\n\tfor (unsigned r = 0; r < set->nreplicas; r++) {\n\t\tstruct part_file cbdata;\n\t\tif (set->replica[r]->remote) {\n\t\t\tcbdata.is_remote = 1;\n\t\t\tcbdata.remote = set->replica[r]->remote;\n\t\t\tcbdata.part = NULL;\n\t\t\tret = (*callback)(&cbdata, arg);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t} else {\n\t\t\tcbdata.is_remote = 0;\n\t\t\tcbdata.remote = NULL;\n\t\t\tfor (unsigned p = 0; p < set->replica[r]->nparts; p++) {\n\t\t\t\tcbdata.part = &set->replica[r]->part[p];\n\t\t\t\tret = (*callback)(&cbdata, arg);\n\t\t\t\tif (ret)\n\t\t\t\t\treturn ret;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n/*\n * util_poolset_foreach_part -- walk through all poolset file parts\n *\n * Stops processing if callback returns non-zero value.\n * The value returned by callback is returned to the caller.\n *\n * Return value:\n *  0 - all part files have been processed\n * -1 - parsing poolset file error\n */\nint\nutil_poolset_foreach_part(const char *path,\n\tint (*callback)(struct part_file *pf, void *arg), void *arg)\n{\n\tLOG(3, \"path %s callback %p arg %p\", path, callback, arg);\n\n\tASSERTne(callback, NULL);\n\n\tint fd = os_open(path, O_RDONLY);\n\tif (fd < 0) {\n\t\tERR(\"!open: path \\\"%s\\\"\", path);\n\t\treturn -1;\n\t}\n\n\tstruct pool_set *set;\n\tint ret = util_poolset_parse(&set, path, fd);\n\tif (ret) {\n\t\tERR(\"util_poolset_parse failed -- '%s'\", path);\n\t\tret = -1;\n\t\tgoto err_close;\n\t}\n\n\tret = util_poolset_foreach_part_struct(set, callback, arg);\n\n\t/*\n\t * Make sure callback does not return -1,\n\t * because this value is reserved for parsing\n\t * error.\n\t */\n\tASSERTne(ret, -1);\n\tutil_poolset_free(set);\n\nerr_close:\n\tos_close(fd);\n\treturn ret;\n}\n\n/*\n * util_poolset_size -- get size of poolset, returns 0 on error\n */\nsize_t\nutil_poolset_size(const char *path)\n{\n\tint fd = os_open(path, O_RDONLY);\n\tif (fd < 0)\n\t\treturn 0;\n\n\tsize_t size = 0;\n\tstruct pool_set *set;\n\tif (util_poolset_parse(&set, path, fd))\n\t\tgoto err_close;\n\n\tsize = set->poolsize;\n\n\tutil_poolset_free(set);\nerr_close:\n\tos_close(fd);\n\treturn size;\n}\n\n/*\n * util_replica_fdclose -- close all parts of given replica\n */\nvoid\nutil_replica_fdclose(struct pool_replica *rep)\n{\n\tfor (unsigned p = 0; p < rep->nparts; p++) {\n\t\tstruct pool_set_part *part = &rep->part[p];\n\t\tutil_part_fdclose(part);\n\t}\n}\n\n/*\n * util_replica_deep_common -- performs common calculations\n * on all parts from replica to define intersection ranges\n * for final flushing operations that take place in\n * os_part_deep_common function.\n */\nint\nutil_replica_deep_common(const void *addr, size_t len, struct pool_set *set,\n\t\t\t\tunsigned replica_id, int flush)\n{\n\tLOG(3, \"addr %p len %zu set %p replica_id %u flush %d\",\n\t\taddr, len, set, replica_id, flush);\n\n\tstruct pool_replica *rep = set->replica[replica_id];\n\tuintptr_t rep_start = (uintptr_t)rep->part[0].addr;\n\tuintptr_t rep_end = rep_start + rep->repsize;\n\tuintptr_t start = (uintptr_t)addr;\n\tuintptr_t end = start + len;\n\n\tASSERT(start >= rep_start);\n\tASSERT(end <= rep_end);\n\n\tfor (unsigned p = 0; p < rep->nparts; p++) {\n\t\tstruct pool_set_part *part = &rep->part[p];\n\t\tuintptr_t part_start = (uintptr_t)part->addr;\n\t\tuintptr_t part_end = part_start + part->size;\n\t\t/* init intersection start and end addresses */\n\t\tuintptr_t range_start = start;\n\t\tuintptr_t range_end = end;\n\n\t\tif (part_start > end || part_end < start)\n\t\t\tcontinue;\n\t\t/* recalculate intersection addresses */\n\t\tif (part_start > start)\n\t\t\trange_start = part_start;\n\t\tif (part_end < end)\n\t\t\trange_end = part_end;\n\t\tsize_t range_len = range_end - range_start;\n\n\t\tLOG(15, \"perform deep flushing for replica %u \"\n\t\t\t\"part %p, addr %p, len %lu\",\n\t\t\treplica_id, part, (void *)range_start, range_len);\n\t\tif (os_part_deep_common(rep, p, (void *)range_start,\n\t\t\t\trange_len, flush)) {\n\t\t\tLOG(1, \"os_part_deep_common(%p, %p, %lu)\",\n\t\t\t\tpart, (void *)range_start, range_len);\n\t\t\treturn -1;\n\t\t}\n\t}\n\treturn 0;\n}\n\n/*\n * util_replica_deep_persist -- wrapper for util_replica_deep_common\n * Calling the target precedes initialization of function that\n * partly defines way of deep replica flushing.\n */\nint\nutil_replica_deep_persist(const void *addr, size_t len, struct pool_set *set,\n\t\t\t\tunsigned replica_id)\n{\n\tLOG(3, \"addr %p len %zu set %p replica_id %u\",\n\t\taddr, len, set, replica_id);\n\n\tint flush = 1;\n\treturn util_replica_deep_common(addr, len, set, replica_id, flush);\n}\n\n/*\n * util_replica_deep_drain -- wrapper for util_replica_deep_common\n * Calling the target precedes initialization of function that\n * partly defines way of deep replica flushing.\n */\nint\nutil_replica_deep_drain(const void *addr, size_t len, struct pool_set *set,\n\t\t\t\tunsigned replica_id)\n{\n\tLOG(3, \"addr %p len %zu set %p replica_id %u\",\n\t\taddr, len, set, replica_id);\n\n\tint flush = 0;\n\treturn util_replica_deep_common(addr, len, set, replica_id, flush);\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-pmdk-1.8-vkfgscx7enzm2hpgfrtndnbmwkp76kum/spack-src/src/common/os.h": "/*\n * Copyright 2017-2020, Intel Corporation\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n *\n *     * Redistributions of source code must retain the above copyright\n *       notice, this list of conditions and the following disclaimer.\n *\n *     * Redistributions in binary form must reproduce the above copyright\n *       notice, this list of conditions and the following disclaimer in\n *       the documentation and/or other materials provided with the\n *       distribution.\n *\n *     * Neither the name of the copyright holder nor the names of its\n *       contributors may be used to endorse or promote products derived\n *       from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n * \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n\n/*\n * os.h -- os abstraction layer\n */\n\n#ifndef PMDK_OS_H\n#define PMDK_OS_H 1\n\n#include <sys/stat.h>\n#include <stdio.h>\n#include <unistd.h>\n\n#include \"errno_freebsd.h\"\n\n#ifdef __cplusplus\nextern \"C\" {\n#endif\n\n#ifndef _WIN32\n#define OS_DIR_SEPARATOR '/'\n#define OS_DIR_SEP_STR \"/\"\n#else\n#define OS_DIR_SEPARATOR '\\\\'\n#define OS_DIR_SEP_STR \"\\\\\"\n#endif\n\n#ifndef _WIN32\n\n/* madvise() */\n#ifdef __FreeBSD__\n#define os_madvise minherit\n#define MADV_DONTFORK INHERIT_NONE\n#else\n#define os_madvise madvise\n#endif\n\n/* dlopen() */\n#ifdef __FreeBSD__\n#define RTLD_DEEPBIND 0\t/* XXX */\n#endif\n\n/* major(), minor() */\n#ifdef __FreeBSD__\n#define os_major (unsigned)major\n#define os_minor (unsigned)minor\n#else\n#define os_major major\n#define os_minor minor\n#endif\n\n#endif /* #ifndef _WIN32 */\n\nstruct iovec;\n\n/* os_flock */\n#define OS_LOCK_SH 1\n#define OS_LOCK_EX 2\n#define OS_LOCK_NB 4\n#define OS_LOCK_UN 8\n\n#ifndef _WIN32\ntypedef struct stat os_stat_t;\n#define os_fstat\tfstat\n#define os_lseek\tlseek\n#else\ntypedef struct _stat64 os_stat_t;\n#define os_fstat\t_fstat64\n#define os_lseek\t_lseeki64\n#endif\n\n#define os_close close\n#define os_fclose fclose\n\n#ifndef _WIN32\ntypedef off_t os_off_t;\n#else\n/* XXX: os_off_t defined in platform.h */\n#endif\nint os_open(const char *pathname, int flags, ...);\nint os_fsync(int fd);\nint os_fsync_dir(const char *dir_name);\nint os_stat(const char *pathname, os_stat_t *buf);\nint os_unlink(const char *pathname);\nint os_access(const char *pathname, int mode);\nFILE *os_fopen(const char *pathname, const char *mode);\nFILE *os_fdopen(int fd, const char *mode);\nint os_chmod(const char *pathname, mode_t mode);\nint os_mkstemp(char *temp);\nint os_posix_fallocate(int fd, os_off_t offset, os_off_t len);\nint os_ftruncate(int fd, os_off_t length);\nint os_flock(int fd, int operation);\nssize_t os_writev(int fd, const struct iovec *iov, int iovcnt);\nint os_clock_gettime(int id, struct timespec *ts);\nunsigned os_rand_r(unsigned *seedp);\nint os_unsetenv(const char *name);\nint os_setenv(const char *name, const char *value, int overwrite);\nchar *os_getenv(const char *name);\nconst char *os_strsignal(int sig);\nint os_execv(const char *path, char *const argv[]);\n\n/*\n * XXX: missing APis (used in ut_file.c)\n *\n * rename\n * read\n * write\n */\n\n#ifdef __cplusplus\n}\n#endif\n\n#endif /* os.h */\n",
        "/tmp/vanessa/spack-stage/spack-stage-pmdk-1.8-vkfgscx7enzm2hpgfrtndnbmwkp76kum/spack-src/src/test/ld.supp": "{\n   <insert_a_suppression_name_here>\n   Memcheck:Cond\n   fun:index\n   fun:expand_dynamic_string_token\n   fun:_dl_map_object\n   fun:map_doit\n   fun:_dl_catch_error\n   fun:do_preload\n   fun:dl_main\n   fun:_dl_sysdep_start\n   fun:_dl_start\n   obj:/lib/x86_64-linux-gnu/ld-2.*.so\n   obj:*\n   obj:*\n}\n{\n   <insert_a_suppression_name_here>\n   Memcheck:Cond\n   fun:index\n   fun:expand_dynamic_string_token\n   fun:_dl_map_object\n   fun:map_doit\n   fun:_dl_catch_error\n   fun:do_preload\n   fun:handle_ld_preload\n   fun:dl_main\n   fun:_dl_sysdep_start\n   fun:_dl_start\n   obj:/lib/x86_64-linux-gnu/ld-2.*.so\n   obj:*\n}\n{\n   <Leak in dlopen, pmem/issues#858>\n   Memcheck:Leak\n   ...\n   fun:_dl_init\n   ...\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-pmdk-1.8-vkfgscx7enzm2hpgfrtndnbmwkp76kum/spack-src/src/test/memcheck-dlopen.supp": "{\n   dlopen suppression\n   Memcheck:Leak\n   fun:malloc\n   fun:strdup\n   ...\n   fun:call_init\n   fun:_dl_init\n   fun:dl_open_worker\n   fun:_dl_catch_exception\n   fun:_dl_open\n   ...\n}\n{\n   <dlopen suppression, pmem/issues#1098>\n   Memcheck:Leak\n   ...\n   fun:_dlerror_run\n   fun:dlopen@@GLIBC*\n   ...\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-pmdk-1.8-vkfgscx7enzm2hpgfrtndnbmwkp76kum/spack-src/src/test/unittest/unittest.sh": "#\n# Copyright 2014-2020, Intel Corporation\n# Copyright (c) 2016, Microsoft Corporation. All rights reserved.\n#\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions\n# are met:\n#\n#     * Redistributions of source code must retain the above copyright\n#       notice, this list of conditions and the following disclaimer.\n#\n#     * Redistributions in binary form must reproduce the above copyright\n#       notice, this list of conditions and the following disclaimer in\n#       the documentation and/or other materials provided with the\n#       distribution.\n#\n#     * Neither the name of the copyright holder nor the names of its\n#       contributors may be used to endorse or promote products derived\n#       from this software without specific prior written permission.\n#\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n# \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n# A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n# OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n# LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n# DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n# THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n#\nset -e\n\n# make sure we have a well defined locale for string operations here\nexport LC_ALL=\"C\"\n#export LC_ALL=\"en_US.UTF-8\"\n\nif ! [ -f ../envconfig.sh ]; then\n\techo >&2 \"envconfig.sh is missing -- is the tree built?\"\n\texit 1\nfi\n\n. ../testconfig.sh\n. ../envconfig.sh\n\nif [ -t 1 ]; then\n\tIS_TERMINAL_STDOUT=YES\nfi\nif [ -t 2 ]; then\n\tIS_TERMINAL_STDERR=YES\nfi\n\nfunction is_terminal() {\n\tlocal fd\n\tfd=$1\n\tcase $(eval \"echo \\${IS_TERMINAL_${fd}}\") in\n\tYES) : ;;\n\t*) false ;;\n\tesac\n}\n\nfunction interactive_color() {\n\tlocal color fd\n\tcolor=$1\n\tfd=$2\n\tshift 2\n\n\tif is_terminal ${fd} && command -v tput >/dev/null; then\n\t\techo \"$(tput setaf $color || :)$*$(tput sgr0 || :)\"\n\telse\n\t\techo \"$*\"\n\tfi\n}\n\nfunction interactive_red() {\n\tinteractive_color 1 \"$@\"\n}\n\nfunction interactive_green() {\n\tinteractive_color 2 \"$@\"\n}\n\nfunction verbose_msg() {\n\tif [ \"$UNITTEST_LOG_LEVEL\" -ge 2 ]; then\n\t\techo \"$*\"\n\tfi\n}\n\nfunction msg() {\n\tif [ \"$UNITTEST_LOG_LEVEL\" -ge 1 ]; then\n\t\techo \"$*\"\n\tfi\n}\n\nfunction fatal() {\n\techo \"$*\" >&2\n\texit 1\n}\n\nif [ -z \"${UNITTEST_NAME}\" ]; then\n\tCURDIR=$(basename $(pwd))\n\tSCRIPTNAME=$(basename $0)\n\n\texport UNITTEST_NAME=$CURDIR/$SCRIPTNAME\n\texport UNITTEST_NUM=$(echo $SCRIPTNAME | sed \"s/TEST//\")\nfi\n\n# defaults\n[ \"$UNITTEST_LOG_LEVEL\" ] || UNITTEST_LOG_LEVEL=2\n[ \"$GREP\" ] || GREP=\"grep -a\"\n[ \"$TEST\" ] || TEST=check\n[ \"$FS\" ] || FS=any\n[ \"$BUILD\" ] || BUILD=debug\n[ \"$CHECK_TYPE\" ] || CHECK_TYPE=auto\n[ \"$CHECK_POOL\" ] || CHECK_POOL=0\n[ \"$VERBOSE\" ] || VERBOSE=0\n[ -n \"${SUFFIX+x}\" ] || SUFFIX=\"\ud83d\ude18\u280f\u280d\u2819\u2805\u0257PMDK\u04dc\u297a\ud83d\ude4b\"\n\nexport UNITTEST_LOG_LEVEL GREP TEST FS BUILD CHECK_TYPE CHECK_POOL VERBOSE SUFFIX\n\nTOOLS=../tools\nLIB_TOOLS=\"../../tools\"\n# Paths to some useful tools\n[ \"$PMEMPOOL\" ] || PMEMPOOL=$LIB_TOOLS/pmempool/pmempool\n[ \"$DAXIO\" ] || DAXIO=$LIB_TOOLS/daxio/daxio\n[ \"$PMEMSPOIL\" ] || PMEMSPOIL=$TOOLS/pmemspoil/pmemspoil.static-nondebug\n[ \"$BTTCREATE\" ] || BTTCREATE=$TOOLS/bttcreate/bttcreate.static-nondebug\n[ \"$PMEMWRITE\" ] || PMEMWRITE=$TOOLS/pmemwrite/pmemwrite\n[ \"$PMEMALLOC\" ] || PMEMALLOC=$TOOLS/pmemalloc/pmemalloc\n[ \"$PMEMOBJCLI\" ] || PMEMOBJCLI=$TOOLS/pmemobjcli/pmemobjcli\n[ \"$PMEMDETECT\" ] || PMEMDETECT=$TOOLS/pmemdetect/pmemdetect.static-nondebug\n[ \"$PMREORDER\" ] || PMREORDER=$LIB_TOOLS/pmreorder/pmreorder.py\n[ \"$FIP\" ] || FIP=$TOOLS/fip/fip\n[ \"$DDMAP\" ] || DDMAP=$TOOLS/ddmap/ddmap\n[ \"$CMPMAP\" ] || CMPMAP=$TOOLS/cmpmap/cmpmap\n[ \"$EXTENTS\" ] || EXTENTS=$TOOLS/extents/extents\n[ \"$FALLOCATE_DETECT\" ] || FALLOCATE_DETECT=$TOOLS/fallocate_detect/fallocate_detect.static-nondebug\n[ \"$OBJ_VERIFY\" ] || OBJ_VERIFY=$TOOLS/obj_verify/obj_verify\n[ \"$USC_PERMISSION\" ] || USC_PERMISSION=$TOOLS/usc_permission_check/usc_permission_check.static-nondebug\n[ \"$ANONYMOUS_MMAP\" ] || ANONYMOUS_MMAP=$TOOLS/anonymous_mmap/anonymous_mmap.static-nondebug\n\n# force globs to fail if they don't match\nshopt -s failglob\n\n# number of remote nodes required in the current unit test\nNODES_MAX=-1\n\n# sizes of alignments\nSIZE_4KB=4096\nSIZE_2MB=2097152\n\n# PMEMOBJ limitations\nPMEMOBJ_MAX_ALLOC_SIZE=17177771968\n\n# SSH and SCP options\nSSH_OPTS=\"-o BatchMode=yes\"\nSCP_OPTS=\"-o BatchMode=yes -r -p\"\n\n# list of common files to be copied to all remote nodes\nDIR_SRC=\"../..\"\nFILES_COMMON_DIR=\"\\\n$DIR_SRC/test/*.supp \\\n$DIR_SRC/tools/rpmemd/rpmemd \\\n$DIR_SRC/tools/pmempool/pmempool \\\n$DIR_SRC/test/tools/extents/extents \\\n$DIR_SRC/test/tools/obj_verify/obj_verify \\\n$DIR_SRC/test/tools/ctrld/ctrld \\\n$DIR_SRC/test/tools/fip/fip\"\n\n# Portability\nVALGRIND_SUPP=\"--suppressions=../ld.supp \\\n\t--suppressions=../memcheck-libunwind.supp \\\n\t--suppressions=../memcheck-ndctl.supp\"\nif [ \"$(uname -s)\" = \"FreeBSD\" ]; then\n\tDATE=\"gdate\"\n\tDD=\"gdd\"\n\tFALLOCATE=\"mkfile\"\n\tVM_OVERCOMMIT=\"[ $(sysctl vm.overcommit | awk '{print $2}') == 0 ]\"\n\tRM_ONEFS=\"-x\"\n\tSTAT_MODE=\"-f%Lp\"\n\tSTAT_PERM=\"-f%Sp\"\n\tSTAT_SIZE=\"-f%z\"\n\tSTRACE=\"truss\"\n\tVALGRIND_SUPP=\"$VALGRIND_SUPP --suppressions=../freebsd.supp\"\nelse\n\tDATE=\"date\"\n\tDD=\"dd\"\n\tFALLOCATE=\"fallocate -l\"\n\tVM_OVERCOMMIT=\"[ $(cat /proc/sys/vm/overcommit_memory) != 2 ]\"\n\tRM_ONEFS=\"--one-file-system\"\n\tSTAT_MODE=\"-c%a\"\n\tSTAT_PERM=\"-c%A\"\n\tSTAT_SIZE=\"-c%s\"\n\tSTRACE=\"strace\"\nfi\n\n# array of lists of PID files to be cleaned in case of an error\nNODE_PID_FILES[0]=\"\"\n\ncase \"$BUILD\"\nin\ndebug|static-debug)\n\tif [ -z \"$PMDK_LIB_PATH_DEBUG\" ]; then\n\t\tPMDK_LIB_PATH=../../debug\n\t\tREMOTE_PMDK_LIB_PATH=../debug\n\telse\n\t\tPMDK_LIB_PATH=$PMDK_LIB_PATH_DEBUG\n\t\tREMOTE_PMDK_LIB_PATH=$PMDK_LIB_PATH_DEBUG\n\tfi\n\t;;\nnondebug|static-nondebug)\n\tif [ -z \"$PMDK_LIB_PATH_NONDEBUG\" ]; then\n\t\tPMDK_LIB_PATH=../../nondebug\n\t\tREMOTE_PMDK_LIB_PATH=../nondebug\n\telse\n\t\tPMDK_LIB_PATH=$PMDK_LIB_PATH_NONDEBUG\n\t\tREMOTE_PMDK_LIB_PATH=$PMDK_LIB_PATH_NONDEBUG\n\tfi\n\t;;\nesac\n\nexport LD_LIBRARY_PATH=$PMDK_LIB_PATH:$GLOBAL_LIB_PATH:$LD_LIBRARY_PATH\nexport REMOTE_LD_LIBRARY_PATH=$REMOTE_PMDK_LIB_PATH:$GLOBAL_LIB_PATH:\\$LD_LIBRARY_PATH\n\n#\n# When running static binary tests, append the build type to the binary\n#\ncase \"$BUILD\"\nin\n\tstatic-*)\n\t\tEXESUFFIX=.$BUILD\n\t\t;;\nesac\n\n#\n# The variable DIR is constructed so the test uses that directory when\n# constructing test files.  DIR is chosen based on the fs-type for\n# this test, and if the appropriate fs-type doesn't have a directory\n# defined in testconfig.sh, the test is skipped.\n#\n# This behavior can be overridden by setting DIR.  For example:\n#\tDIR=/force/test/dir ./TEST0\n#\ncurtestdir=`basename $PWD`\n\n# just in case\nif [ ! \"$curtestdir\" ]; then\n\tfatal \"curtestdir does not have a value\"\nfi\n\ncurtestdir=test_$curtestdir\n\nif [ ! \"$UNITTEST_NUM\" ]; then\n\tfatal \"UNITTEST_NUM does not have a value\"\nfi\n\nif [ ! \"$UNITTEST_NAME\" ]; then\n\tfatal \"UNITTEST_NAME does not have a value\"\nfi\n\nREAL_FS=$FS\nif [ \"$DIR\" ]; then\n\tDIR=$DIR/$curtestdir$UNITTEST_NUM\nelse\n\tcase \"$FS\"\n\tin\n\tpmem)\n\t\t# if a variable is set - it must point to a valid directory\n\t\tif [ \"$PMEM_FS_DIR\" == \"\" ]; then\n\t\t\tfatal \"$UNITTEST_NAME: PMEM_FS_DIR is not set\"\n\t\tfi\n\t\tDIR=$PMEM_FS_DIR/$DIRSUFFIX/$curtestdir$UNITTEST_NUM\n\t\tif [ \"$PMEM_FS_DIR_FORCE_PMEM\" = \"1\" ] || [ \"$PMEM_FS_DIR_FORCE_PMEM\" = \"2\" ]; then\n\t\t\texport PMEM_IS_PMEM_FORCE=1\n\t\tfi\n\t\t;;\n\tnon-pmem)\n\t\t# if a variable is set - it must point to a valid directory\n\t\tif [ \"$NON_PMEM_FS_DIR\" == \"\" ]; then\n\t\t\tfatal \"$UNITTEST_NAME: NON_PMEM_FS_DIR is not set\"\n\t\tfi\n\t\tDIR=$NON_PMEM_FS_DIR/$DIRSUFFIX/$curtestdir$UNITTEST_NUM\n\t\t;;\n\tany)\n\t\tif [ \"$PMEM_FS_DIR\" != \"\" ]; then\n\t\t\tDIR=$PMEM_FS_DIR/$DIRSUFFIX/$curtestdir$UNITTEST_NUM\n\t\t\tREAL_FS=pmem\n\t\t\tif [ \"$PMEM_FS_DIR_FORCE_PMEM\" = \"1\" ] || [ \"$PMEM_FS_DIR_FORCE_PMEM\" = \"2\" ]; then\n\t\t\t\texport PMEM_IS_PMEM_FORCE=1\n\t\t\tfi\n\t\telif [ \"$NON_PMEM_FS_DIR\" != \"\" ]; then\n\t\t\tDIR=$NON_PMEM_FS_DIR/$DIRSUFFIX/$curtestdir$UNITTEST_NUM\n\t\t\tREAL_FS=non-pmem\n\t\telse\n\t\t\tfatal \"$UNITTEST_NAME: fs-type=any and both env vars are empty\"\n\t\tfi\n\t\t;;\n\tnone)\n\t\tDIR=/dev/null/not_existing_dir/$DIRSUFFIX/$curtestdir$UNITTEST_NUM\n\t\t;;\n\t*)\n\t\tverbose_msg \"$UNITTEST_NAME: SKIP fs-type $FS (not configured)\"\n\t\texit 0\n\t\t;;\n\tesac\nfi\n\n#\n# The default is to turn on library logging to level 3 and save it to local files.\n# Tests that don't want it on, should override these environment variables.\n#\nexport PMEM_LOG_LEVEL=3\nexport PMEM_LOG_FILE=pmem$UNITTEST_NUM.log\nexport PMEMBLK_LOG_LEVEL=3\nexport PMEMBLK_LOG_FILE=pmemblk$UNITTEST_NUM.log\nexport PMEMLOG_LOG_LEVEL=3\nexport PMEMLOG_LOG_FILE=pmemlog$UNITTEST_NUM.log\nexport PMEMOBJ_LOG_LEVEL=3\nexport PMEMOBJ_LOG_FILE=pmemobj$UNITTEST_NUM.log\nexport PMEMPOOL_LOG_LEVEL=3\nexport PMEMPOOL_LOG_FILE=pmempool$UNITTEST_NUM.log\nexport PMREORDER_LOG_FILE=pmreorder$UNITTEST_NUM.log\n\nexport OUT_LOG_FILE=out$UNITTEST_NUM.log\nexport ERR_LOG_FILE=err$UNITTEST_NUM.log\nexport TRACE_LOG_FILE=trace$UNITTEST_NUM.log\nexport PREP_LOG_FILE=prep$UNITTEST_NUM.log\n\nexport VALGRIND_LOG_FILE=${CHECK_TYPE}${UNITTEST_NUM}.log\nexport VALIDATE_VALGRIND_LOG=1\n\nexport RPMEM_LOG_LEVEL=3\nexport RPMEM_LOG_FILE=rpmem$UNITTEST_NUM.log\nexport RPMEMD_LOG_LEVEL=info\nexport RPMEMD_LOG_FILE=rpmemd$UNITTEST_NUM.log\n\nexport REMOTE_VARS=\"\nRPMEMD_LOG_FILE\nRPMEMD_LOG_LEVEL\nRPMEM_LOG_FILE\nRPMEM_LOG_LEVEL\nPMEM_LOG_FILE\nPMEM_LOG_LEVEL\nPMEMOBJ_LOG_FILE\nPMEMOBJ_LOG_LEVEL\nPMEMPOOL_LOG_FILE\nPMEMPOOL_LOG_LEVEL\"\n\n[ \"$UT_DUMP_LINES\" ] || UT_DUMP_LINES=30\n\nexport CHECK_POOL_LOG_FILE=check_pool_${BUILD}_${UNITTEST_NUM}.log\n\n# In case a lock is required for Device DAXes\nDEVDAX_LOCK=../devdax.lock\n\n#\n# store_exit_on_error -- store on a stack a sign that reflects the current state\n#                        of the 'errexit' shell option\n#\nfunction store_exit_on_error() {\n\tif [ \"${-#*e}\" != \"$-\" ]; then\n\t\testack+=-\n\telse\n\t\testack+=+\n\tfi\n}\n\n#\n# restore_exit_on_error -- restore the state of the 'errexit' shell option\n#\nfunction restore_exit_on_error() {\n\tif [ -z $estack ]; then\n\t\tfatal \"error: store_exit_on_error function has to be called first\"\n\tfi\n\n\teval \"set ${estack:${#estack}-1:1}e\"\n\testack=${estack%?}\n}\n\n#\n# disable_exit_on_error -- store the state of the 'errexit' shell option and\n#                          disable it\n#\nfunction disable_exit_on_error() {\n\tstore_exit_on_error\n\tset +e\n}\n\n#\n# get_files -- print list of files in the current directory matching the given regex to stdout\n#\n# This function has been implemented to workaround a race condition in\n# `find`, which fails if any file disappears in the middle of the operation.\n#\n# example, to list all *.log files in the current directory\n#\tget_files \".*\\.log\"\nfunction get_files() {\n\tdisable_exit_on_error\n\tls -1 | grep -E \"^$*$\"\n\trestore_exit_on_error\n}\n\n#\n# get_executables -- print list of executable files in the current directory to stdout\n#\n# This function has been implemented to workaround a race condition in\n# `find`, which fails if any file disappears in the middle of the operation.\n#\nfunction get_executables() {\n\tdisable_exit_on_error\n\tfor c in *\n\tdo\n\t\tif [ -f $c -a -x $c ]\n\t\tthen\n\t\t\techo \"$c\"\n\t\tfi\n\tdone\n\trestore_exit_on_error\n}\n\n#\n# convert_to_bytes -- converts the string with K, M, G or T suffixes\n# to bytes\n#\n# example:\n#   \"1G\" --> \"1073741824\"\n#   \"2T\" --> \"2199023255552\"\n#   \"3k\" --> \"3072\"\n#   \"1K\" --> \"1024\"\n#   \"10\" --> \"10\"\n#\nfunction convert_to_bytes() {\n\tsize=\"$(echo $1 | tr '[:upper:]' '[:lower:]')\"\n\tif [[ $size == *kib ]]\n\tthen size=$(($(echo $size | tr -d 'kib') * 1024))\n\telif [[ $size == *mib ]]\n\tthen size=$(($(echo $size | tr -d 'mib') * 1024 * 1024))\n\telif [[ $size == *gib ]]\n\tthen size=$(($(echo $size | tr -d 'gib') * 1024 * 1024 * 1024))\n\telif [[ $size == *tib ]]\n\tthen size=$(($(echo $size | tr -d 'tib') * 1024 * 1024 * 1024 * 1024))\n\telif [[ $size == *pib ]]\n\tthen size=$(($(echo $size | tr -d 'pib') * 1024 * 1024 * 1024 * 1024 * 1024))\n\telif [[ $size == *kb ]]\n\tthen size=$(($(echo $size | tr -d 'kb') * 1000))\n\telif [[ $size == *mb ]]\n\tthen size=$(($(echo $size | tr -d 'mb') * 1000 * 1000))\n\telif [[ $size == *gb ]]\n\tthen size=$(($(echo $size | tr -d 'gb') * 1000 * 1000 * 1000))\n\telif [[ $size == *tb ]]\n\tthen size=$(($(echo $size | tr -d 'tb') * 1000 * 1000 * 1000 * 1000))\n\telif [[ $size == *pb ]]\n\tthen size=$(($(echo $size | tr -d 'pb') * 1000 * 1000 * 1000 * 1000 * 1000))\n\telif [[ $size == *b ]]\n\tthen size=$(($(echo $size | tr -d 'b')))\n\telif [[ $size == *k ]]\n\tthen size=$(($(echo $size | tr -d 'k') * 1024))\n\telif [[ $size == *m ]]\n\tthen size=$(($(echo $size | tr -d 'm') * 1024 * 1024))\n\telif [[ $size == *g ]]\n\tthen size=$(($(echo $size | tr -d 'g') * 1024 * 1024 * 1024))\n\telif [[ $size == *t ]]\n\tthen size=$(($(echo $size | tr -d 't') * 1024 * 1024 * 1024 * 1024))\n\telif [[ $size == *p ]]\n\tthen size=$(($(echo $size | tr -d 'p') * 1024 * 1024 * 1024 * 1024 * 1024))\n\tfi\n\n\techo \"$size\"\n}\n\n#\n# create_file -- create zeroed out files of a given length\n#\n# example, to create two files, each 1GB in size:\n#\tcreate_file 1G testfile1 testfile2\n#\nfunction create_file() {\n\tsize=$(convert_to_bytes $1)\n\tshift\n\tfor file in $*\n\tdo\n\t\t$DD if=/dev/zero of=$file bs=1M count=$size iflag=count_bytes status=none >> $PREP_LOG_FILE\n\tdone\n}\n\n#\n# create_nonzeroed_file -- create non-zeroed files of a given length\n#\n# A given first kilobytes of the file is zeroed out.\n#\n# example, to create two files, each 1GB in size, with first 4K zeroed\n#\tcreate_nonzeroed_file 1G 4K testfile1 testfile2\n#\nfunction create_nonzeroed_file() {\n\toffset=$(convert_to_bytes $2)\n\tsize=$(($(convert_to_bytes $1) - $offset))\n\tshift 2\n\tfor file in $*\n\tdo\n\t\ttruncate -s ${offset} $file >> $PREP_LOG_FILE\n\t\t$DD if=/dev/zero bs=1K count=${size} iflag=count_bytes 2>>$PREP_LOG_FILE | tr '\\0' '\\132' >> $file\n\tdone\n}\n\n#\n# create_holey_file -- create holey files of a given length\n#\n# examples:\n#\tcreate_holey_file 1024k testfile1 testfile2\n#\tcreate_holey_file 2048M testfile1 testfile2\n#\tcreate_holey_file 234 testfile1\n#\tcreate_holey_file 2340b testfile1\n#\n# Input unit size is in bytes with optional suffixes like k, KB, M, etc.\n#\n\nfunction create_holey_file() {\n\tsize=$(convert_to_bytes $1)\n\tshift\n\tfor file in $*\n\tdo\n\t\ttruncate -s ${size} $file >> $PREP_LOG_FILE\n\tdone\n}\n\n#\n# create_poolset -- create a dummy pool set\n#\n# Creates a pool set file using the provided list of part sizes and paths.\n# Optionally, it also creates the selected part files (zeroed, partially zeroed\n# or non-zeroed) with requested size and mode.  The actual file size may be\n# different than the part size in the pool set file.\n# 'r' or 'R' on the list of arguments indicate the beginning of the next\n# replica set and 'm' or 'M' the beginning of the next remote replica set.\n# 'o' or 'O' indicates the next argument is a pool set option.\n# A remote replica requires two parameters: a target node and a pool set\n# descriptor.\n#\n# Each part argument has the following format:\n#   psize:ppath[:cmd[:fsize[:mode]]]\n#\n# where:\n#   psize - part size or AUTO (only for DAX device)\n#   ppath - path\n#   cmd   - (optional) can be:\n#            x - do nothing (may be skipped if there's no 'fsize', 'mode')\n#            z - create zeroed (holey) file\n#            n - create non-zeroed file\n#            h - create non-zeroed file, but with zeroed header (first 4KB)\n#            d - create directory\n#   fsize - (optional) the actual size of the part file (if 'cmd' is not 'x')\n#   mode  - (optional) same format as for 'chmod' command\n#\n# Each remote replica argument has the following format:\n#   node:desc\n#\n# where:\n#   node - target node\n#   desc - pool set descriptor\n#\n# example:\n#   The following command define a pool set consisting of two parts: 16MB\n#   and 32MB, a local replica with only one part of 48MB and a remote replica.\n#   The first part file is not created, the second is zeroed.  The only replica\n#   part is non-zeroed. Also, the last file is read-only and its size\n#   does not match the information from pool set file. The last but one line\n#   describes a remote replica. The SINGLEHDR poolset option is set, so only\n#   the first part in each replica contains a pool header. The remote poolset\n#   also has to have the SINGLEHDR option.\n#\n#\tcreate_poolset ./pool.set 16M:testfile1 32M:testfile2:z \\\n#\t\t\t\tR 48M:testfile3:n:11M:0400 \\\n#\t\t\t\tM remote_node:remote_pool.set \\\n#                               O SINGLEHDR\n#\nfunction create_poolset() {\n\tpsfile=$1\n\tshift 1\n\techo \"PMEMPOOLSET\" > $psfile\n\twhile [ \"$1\" ]\n\tdo\n\t\tif [ \"$1\" = \"M\" ] || [ \"$1\" = \"m\" ] # remote replica\n\t\tthen\n\t\t\tshift 1\n\n\t\t\tcmd=$1\n\t\t\tshift 1\n\n\t\t\t# extract last \":\" separated segment as descriptor\n\t\t\t# extract everything before last \":\" as node address\n\t\t\t# this extraction method is compatible with IPv6 and IPv4\n\t\t\tnode=${cmd%:*}\n\t\t\tdesc=${cmd##*:}\n\n\t\t\techo \"REPLICA $node $desc\" >> $psfile\n\t\t\tcontinue\n\t\tfi\n\n\t\tif [ \"$1\" = \"R\" ] || [ \"$1\" = \"r\" ]\n\t\tthen\n\t\t\techo \"REPLICA\" >> $psfile\n\t\t\tshift 1\n\t\t\tcontinue\n\t\tfi\n\n\t\tif [ \"$1\" = \"O\" ] || [ \"$1\" = \"o\" ]\n\t\tthen\n\t\t\techo \"OPTION $2\" >> $psfile\n\t\t\tshift 2\n\t\t\tcontinue\n\t\tfi\n\n\t\tcmd=$1\n\t\tfparms=(${cmd//:/ })\n\t\tshift 1\n\n\t\tfsize=${fparms[0]}\n\t\tfpath=${fparms[1]}\n\t\tcmd=${fparms[2]}\n\t\tasize=${fparms[3]}\n\t\tmode=${fparms[4]}\n\n\t\tif [ ! $asize ]; then\n\t\t\tasize=$fsize\n\t\tfi\n\n\t\tif [ \"$asize\" != \"AUTO\" ]; then\n\t\t\tasize=$(convert_to_bytes $asize)\n\t\tfi\n\n\t\tcase \"$cmd\"\n\t\tin\n\t\tx)\n\t\t\t# do nothing\n\t\t\t;;\n\t\tz)\n\t\t\t# zeroed (holey) file\n\t\t\ttruncate -s $asize $fpath >> $PREP_LOG_FILE\n\t\t\t;;\n\t\tn)\n\t\t\t# non-zeroed file\n\t\t\t$DD if=/dev/zero bs=$asize count=1 2>>$PREP_LOG_FILE | tr '\\0' '\\132' >> $fpath\n\t\t\t;;\n\t\th)\n\t\t\t# non-zeroed file, except 4K header\n\t\t\ttruncate -s 4K $fpath >> prep$UNITTEST_NUM.log\n\t\t\t$DD if=/dev/zero bs=$asize count=1 2>>$PREP_LOG_FILE | tr '\\0' '\\132' >> $fpath\n\t\t\ttruncate -s $asize $fpath >> $PREP_LOG_FILE\n\t\t\t;;\n\t\td)\n\t\t\tmkdir -p $fpath\n\t\t\t;;\n\t\tesac\n\n\t\tif [ $mode ]; then\n\t\t\tchmod $mode $fpath\n\t\tfi\n\n\t\techo \"$fsize $fpath\" >> $psfile\n\tdone\n}\n\nfunction dump_last_n_lines() {\n\tif [ \"$1\" != \"\" -a -f \"$1\" ]; then\n\t\tln=`wc -l < $1`\n\t\tif [ $ln -gt $UT_DUMP_LINES ]; then\n\t\t\techo -e \"Last $UT_DUMP_LINES lines of $1 below (whole file has $ln lines).\" >&2\n\t\t\tln=$UT_DUMP_LINES\n\t\telse\n\t\t\techo -e \"$1 below.\" >&2\n\t\tfi\n\t\tpaste -d \" \" <(yes $UNITTEST_NAME $1 | head -n $ln) <(tail -n $ln $1) >&2\n\t\techo >&2\n\tfi\n}\n\n# https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=810295\n# https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=780173\n# https://bugs.kde.org/show_bug.cgi?id=303877\n#\n# valgrind issues an unsuppressable warning when exceeding\n# the brk segment, causing matching failures. We can safely\n# ignore it because malloc() will fallback to mmap() anyway.\nfunction valgrind_ignore_warnings() {\n\tcat $1 | grep -v \\\n\t\t-e \"WARNING: Serious error when reading debug info\" \\\n\t\t-e \"When reading debug info from \" \\\n\t\t-e \"Ignoring non-Dwarf2/3/4 block in .debug_info\" \\\n\t\t-e \"Last block truncated in .debug_info; ignoring\" \\\n\t\t-e \"parse_CU_Header: is neither DWARF2 nor DWARF3 nor DWARF4\" \\\n\t\t-e \"brk segment overflow\" \\\n\t\t-e \"see section Limitations in user manual\" \\\n\t\t-e \"Warning: set address range perms: large range\"\\\n\t\t-e \"further instances of this message will not be shown\"\\\n\t\t-e \"get_Form_contents: DW_FORM_GNU_strp_alt used, but no alternate .debug_str\"\\\n\t\t>  $1.tmp\n\tmv $1.tmp $1\n}\n\n#\n# valgrind_ignore_messages -- cuts off Valgrind messages that are irrelevant\n#\tto the correctness of the test, but changes during Valgrind rebase\n#\tusage: valgrind_ignore_messages <log-file>\n#\nfunction valgrind_ignore_messages() {\n\tif [ -e \"$1.match\" ]; then\n\t\tcat $1 | grep -v \\\n\t\t\t-e \"For lists of detected and suppressed errors, rerun with: -s\" \\\n\t\t\t-e \"For counts of detected and suppressed errors, rerun with: -v\" \\\n\t\t\t>  $1.tmp\n\t\tmv $1.tmp $1\n\tfi\n}\n\n#\n# get_trace -- return tracing tool command line if applicable\n#\tusage: get_trace <check type> <log file> [<node>]\n#\nfunction get_trace() {\n\tif [ \"$1\" == \"none\" ]; then\n\t\techo \"$TRACE\"\n\t\treturn\n\tfi\n\tlocal exe=$VALGRINDEXE\n\tlocal check_type=$1\n\tlocal log_file=$2\n\tlocal opts=\"$VALGRIND_OPTS\"\n\tlocal node=-1\n\t[ \"$#\" -eq 3 ] && node=$3\n\n\tif [ \"$check_type\" = \"memcheck\" -a \"$MEMCHECK_DONT_CHECK_LEAKS\" != \"1\" ]; then\n\t\topts=\"$opts --leak-check=full\"\n\tfi\n\tif [ \"$check_type\" = \"pmemcheck\" ]; then\n\t\t# Before Skylake, Intel CPUs did not have clflushopt instruction, so\n\t\t# pmem_flush and pmem_persist both translated to clflush.\n\t\t# This means that missing pmem_drain after pmem_flush could only be\n\t\t# detected on Skylake+ CPUs.\n\t\t# This option tells pmemcheck to expect fence (sfence or\n\t\t# VALGRIND_PMC_DO_FENCE client request, used by pmem_drain) after\n\t\t# clflush and makes pmemcheck output the same on pre-Skylake and\n\t\t# post-Skylake CPUs.\n\t\topts=\"$opts --expect-fence-after-clflush=yes\"\n\tfi\n\n\topts=\"$opts $VALGRIND_SUPP\"\n\tif [ \"$node\" -ne -1 ]; then\n\t\texe=${NODE_VALGRINDEXE[$node]}\n\t\topts=\"$opts\"\n\n\t\tcase \"$check_type\" in\n\t\tmemcheck)\n\t\t\topts=\"$opts --suppressions=../memcheck-libibverbs.supp\"\n\t\t\t;;\n\t\thelgrind)\n\t\t\topts=\"$opts --suppressions=../helgrind-cxgb4.supp\"\n\t\t\topts=\"$opts --suppressions=../helgrind-libfabric.supp\"\n\t\t\t;;\n\t\tdrd)\n\t\t\topts=\"$opts --suppressions=../drd-libfabric.supp\"\n\t\t\t;;\n\t\tesac\n\tfi\n\n\techo \"$exe --tool=$check_type --log-file=$log_file $opts $TRACE\"\n\treturn\n}\n\n#\n# validate_valgrind_log -- validate valgrind log\n#\tusage: validate_valgrind_log <log-file>\n#\nfunction validate_valgrind_log() {\n\t[ \"$VALIDATE_VALGRIND_LOG\" != \"1\" ] && return\n\t# fail if there are valgrind errors found or\n\t# if it detects overlapping chunks\n\tif [ ! -e \"$1.match\" ] && grep \\\n\t\t-e \"ERROR SUMMARY: [^0]\" \\\n\t\t-e \"Bad mempool\" \\\n\t\t$1 >/dev/null ;\n\tthen\n\t\tmsg=$(interactive_red STDERR \"failed\")\n\t\techo -e \"$UNITTEST_NAME $msg with Valgrind. See $1. Last 20 lines below.\" >&2\n\t\tpaste -d \" \" <(yes $UNITTEST_NAME $1 | head -n 20) <(tail -n 20 $1) >&2\n\t\tfalse\n\tfi\n}\n\n#\n# expect_normal_exit -- run a given command, expect it to exit 0\n#\n# if VALGRIND_DISABLED is not empty valgrind tool will be omitted\n#\nfunction expect_normal_exit() {\n\tlocal VALGRIND_LOG_FILE=${CHECK_TYPE}${UNITTEST_NUM}.log\n\tlocal N=$2\n\n\t# in case of a remote execution disable valgrind check if valgrind is not\n\t# enabled on node\n\tlocal _CHECK_TYPE=$CHECK_TYPE\n\tif [ \"x$VALGRIND_DISABLED\" != \"x\" ]; then\n\t\t_CHECK_TYPE=none\n\tfi\n\tif [ \"$1\" == \"run_on_node\" -o \"$1\" == \"run_on_node_background\" ]; then\n\t\tif [ -z $(is_valgrind_enabled_on_node $N) ]; then\n\t\t\t_CHECK_TYPE=\"none\"\n\t\tfi\n\telse\n\t\tN=-1\n\tfi\n\n\tif [ -n \"$TRACE\" ]; then\n\t\tcase \"$1\"\n\t\tin\n\t\t*_on_node*)\n\t\t\tmsg \"$UNITTEST_NAME: SKIP: TRACE is not supported if test is executed on remote nodes\"\n\t\t\texit 0\n\t\tesac\n\tfi\n\n\tlocal trace=$(get_trace $_CHECK_TYPE $VALGRIND_LOG_FILE $N)\n\n\tif [ \"$MEMCHECK_DONT_CHECK_LEAKS\" = \"1\" -a \"$CHECK_TYPE\" = \"memcheck\" ]; then\n\t\texport OLD_ASAN_OPTIONS=\"${ASAN_OPTIONS}\"\n\t\texport ASAN_OPTIONS=\"detect_leaks=0 ${ASAN_OPTIONS}\"\n\tfi\n\n\tif [ \"$CHECK_TYPE\" = \"helgrind\" ]; then\n\t\texport VALGRIND_OPTS=\"--suppressions=../helgrind-log.supp\"\n\tfi\n\n\tif [ \"$CHECK_TYPE\" = \"memcheck\" ]; then\n\t\texport VALGRIND_OPTS=\"$VALGRIND_OPTS --suppressions=../memcheck-dlopen.supp\"\n\tfi\n\n\tlocal REMOTE_VALGRIND_LOG=0\n\tif [ \"$CHECK_TYPE\" != \"none\" ]; then\n\t        case \"$1\"\n\t        in\n\t        run_on_node)\n\t\t\tREMOTE_VALGRIND_LOG=1\n\t\t\ttrace=\"$1 $2 $trace\"\n\t\t\t[ $# -ge 2  ] && shift 2 || shift $#\n\t                ;;\n\t        run_on_node_background)\n\t\t\ttrace=\"$1 $2 $3 $trace\"\n\t\t\t[ $# -ge 3  ] && shift 3 || shift $#\n\t                ;;\n\t        wait_on_node|wait_on_node_port|kill_on_node)\n\t\t\t[ \"$1\" = \"wait_on_node\" ] && REMOTE_VALGRIND_LOG=1\n\t\t\ttrace=\"$1 $2 $3 $4\"\n\t\t\t[ $# -ge 4  ] && shift 4 || shift $#\n\t                ;;\n\t        esac\n\tfi\n\n\tif [ \"$CHECK_TYPE\" = \"drd\" ]; then\n\t\texport VALGRIND_OPTS=\"$VALGRIND_OPTS --suppressions=../drd-log.supp\"\n\tfi\n\n\tdisable_exit_on_error\n\n\teval $ECHO $trace \"$*\"\n\tret=$?\n\n\tif [ $REMOTE_VALGRIND_LOG -eq 1 ]; then\n\t\tfor node in $CHECK_NODES\n\t\tdo\n\t\t\tlocal new_log_file=node\\_$node\\_$VALGRIND_LOG_FILE\n\t\t\tcopy_files_from_node $node \".\" ${NODE_TEST_DIR[$node]}/$VALGRIND_LOG_FILE\n\t\t\tmv $VALGRIND_LOG_FILE $new_log_file\n\t\tdone\n\tfi\n\trestore_exit_on_error\n\n\tif [ \"$ret\" -ne \"0\" ]; then\n\t\tif [ \"$ret\" -gt \"128\" ]; then\n\t\t\tmsg=\"crashed (signal $(($ret - 128)))\"\n\t\telse\n\t\t\tmsg=\"failed with exit code $ret\"\n\t\tfi\n\t\tmsg=$(interactive_red STDERR $msg)\n\n\t\tif [ -f $ERR_LOG_FILE ]; then\n\t\t\tif [ \"$UNITTEST_LOG_LEVEL\" -ge \"1\" ]; then\n\t\t\t\techo -e \"$UNITTEST_NAME $msg. $ERR_LOG_FILE below.\" >&2\n\t\t\t\tcat $ERR_LOG_FILE >&2\n\t\t\telse\n\t\t\t\techo -e \"$UNITTEST_NAME $msg. $ERR_LOG_FILE above.\" >&2\n\t\t\tfi\n\t\telse\n\t\t\techo -e \"$UNITTEST_NAME $msg.\" >&2\n\t\tfi\n\n\t\t# ignore Ctrl-C\n\t\tif [ $ret != 130 ]; then\n\t\t\tfor f in $(get_files \".*[a-zA-Z_]${UNITTEST_NUM}\\.log\"); do\n\t\t\t\tdump_last_n_lines $f\n\t\t\tdone\n\t\tfi\n\n\t\t[ $NODES_MAX -ge 0 ] && clean_all_remote_nodes\n\n\t\tfalse\n\tfi\n\tif [ \"$CHECK_TYPE\" != \"none\" ]; then\n\t\tif [ $REMOTE_VALGRIND_LOG -eq 1 ]; then\n\t\t\tfor node in $CHECK_NODES\n\t\t\tdo\n\t\t\t\tlocal log_file=node\\_$node\\_$VALGRIND_LOG_FILE\n\t\t\t\tvalgrind_ignore_warnings $new_log_file\n\t\t\t\tvalgrind_ignore_messages $new_log_file\n\t\t\t\tvalidate_valgrind_log $new_log_file\n\t\t\tdone\n\t\telse\n\t\t\tif [ -f $VALGRIND_LOG_FILE ]; then\n\t\t\t\tvalgrind_ignore_warnings $VALGRIND_LOG_FILE\n\t\t\t\tvalgrind_ignore_messages $VALGRIND_LOG_FILE\n\t\t\t\tvalidate_valgrind_log $VALGRIND_LOG_FILE\n\t\t\tfi\n\t\tfi\n\tfi\n\n\tif [ \"$MEMCHECK_DONT_CHECK_LEAKS\" = \"1\" -a \"$CHECK_TYPE\" = \"memcheck\" ]; then\n\t\texport ASAN_OPTIONS=\"${OLD_ASAN_OPTIONS}\"\n\tfi\n}\n\n#\n# expect_abnormal_exit -- run a given command, expect it to exit non-zero\n#\nfunction expect_abnormal_exit() {\n\tif [ -n \"$TRACE\" ]; then\n\t\tcase \"$1\"\n\t\tin\n\t\t*_on_node*)\n\t\t\tmsg \"$UNITTEST_NAME: SKIP: TRACE is not supported if test is executed on remote nodes\"\n\t\t\texit 0\n\t\tesac\n\tfi\n\n\tif [ \"$CHECK_TYPE\" = \"drd\" ]; then\n\t\texport VALGRIND_OPTS=\"$VALGRIND_OPTS --suppressions=../drd-log.supp\"\n\tfi\n\n\tdisable_exit_on_error\n\teval $ECHO ASAN_OPTIONS=\"detect_leaks=0 ${ASAN_OPTIONS}\" $TRACE \"$*\"\n\tret=$?\n\trestore_exit_on_error\n\n\tif [ \"$ret\" -eq \"0\" ]; then\n\t\tmsg=$(interactive_red STDERR \"succeeded\")\n\n\t\techo -e \"$UNITTEST_NAME command $msg unexpectedly.\" >&2\n\n\t\t[ $NODES_MAX -ge 0 ] && clean_all_remote_nodes\n\n\t\tfalse\n\tfi\n}\n\n#\n# check_pool -- run pmempool check on specified pool file\n#\nfunction check_pool() {\n\tif [ \"$CHECK_POOL\" == \"1\" ]\n\tthen\n\t\tif [ \"$VERBOSE\" != \"0\" ]\n\t\tthen\n\t\t\techo \"$UNITTEST_NAME: checking consistency of pool ${1}\"\n\t\tfi\n\t\t${PMEMPOOL}.static-nondebug check $1 2>&1 1>>$CHECK_POOL_LOG_FILE\n\tfi\n}\n\n#\n# check_pools -- run pmempool check on specified pool files\n#\nfunction check_pools() {\n\tif [ \"$CHECK_POOL\" == \"1\" ]\n\tthen\n\t\tfor f in $*\n\t\tdo\n\t\t\tcheck_pool $f\n\t\tdone\n\tfi\n}\n\n#\n# require_unlimited_vm -- require unlimited virtual memory\n#\n# This implies requirements for:\n# - overcommit_memory enabled (/proc/sys/vm/overcommit_memory is 0 or 1)\n# - unlimited virtual memory (ulimit -v is unlimited)\n#\nfunction require_unlimited_vm() {\n\t$VM_OVERCOMMIT && [ $(ulimit -v) = \"unlimited\" ] && return\n\tmsg \"$UNITTEST_NAME: SKIP required: overcommit_memory enabled and unlimited virtual memory\"\n\texit 0\n}\n\n#\n# require_linked_with_ndctl -- require an executable linked with libndctl\n#\n# usage: require_linked_with_ndctl <executable-file>\n#\nfunction require_linked_with_ndctl() {\n\t[ \"$1\" == \"\" -o ! -x \"$1\" ] && \\\n\t\tfatal \"$UNITTEST_NAME: ERROR: require_linked_with_ndctl() requires one argument - an executable file\"\n\tlocal lddndctl=$(ldd $1 | $GREP -ce \"libndctl\")\n\t[ \"$lddndctl\" == \"1\" ] && return\n\tmsg \"$UNITTEST_NAME: SKIP required: executable $1 linked with libndctl\"\n\texit 0\n}\n\n#\n# require_sudo_allowed -- require sudo command is allowed\n#\nfunction require_sudo_allowed() {\n\tif [ \"$ENABLE_SUDO_TESTS\" != \"y\" ]; then\n\t\tmsg \"$UNITTEST_NAME: SKIP: tests using 'sudo' are not enabled in testconfig.sh (ENABLE_SUDO_TESTS)\"\n\t\texit 0\n\tfi\n\n\tif ! sh -c \"timeout --signal=SIGKILL --kill-after=3s 3s sudo date\" >/dev/null 2>&1\n\tthen\n\t\tmsg \"$UNITTEST_NAME: SKIP required: sudo allowed\"\n\t\texit 0\n\tfi\n}\n\n#\n# require_sudo_allowed_node -- require sudo command on a remote node\n#\n# usage: require_sudo_allowed_node <node-number>\n#\nfunction require_sudo_allowed_node() {\n\tif [ \"$ENABLE_SUDO_TESTS\" != \"y\" ]; then\n\t\tmsg \"$UNITTEST_NAME: SKIP: tests using 'sudo' are not enabled in testconfig.sh (ENABLE_SUDO_TESTS)\"\n\t\texit 0\n\tfi\n\n\tif ! run_on_node $1 \"timeout --signal=SIGKILL --kill-after=3s 3s sudo date\" >/dev/null 2>&1\n\tthen\n\t\tmsg \"$UNITTEST_NAME: SKIP required: sudo allowed on node $1\"\n\t\texit 0\n\tfi\n}\n\n#\n# require_no_superuser -- require user without superuser rights\n#\nfunction require_no_superuser() {\n\tlocal user_id=$(id -u)\n\t[ \"$user_id\" != \"0\" ] && return\n\tmsg \"$UNITTEST_NAME: SKIP required: run without superuser rights\"\n\texit 0\n}\n\n#\n# require_no_freebsd -- Skip test on FreeBSD\n#\nfunction require_no_freebsd() {\n\t[ \"$(uname -s)\" != \"FreeBSD\" ] && return\n\tmsg \"$UNITTEST_NAME: SKIP: Not supported on FreeBSD\"\n\texit 0\n}\n\n#\n# require_procfs -- Skip test if /proc is not mounted\n#\nfunction require_procfs() {\n\tmount | grep -q \"/proc\" && return\n\tmsg \"$UNITTEST_NAME: SKIP: /proc not mounted\"\n\texit 0\n}\n\n#\n# require_arch -- Skip tests if the running platform not matches\n# any of the input list.\n#\nfunction require_arch() {\n\tfor i in \"$@\"; do\n\t\t[[ \"$(arch)\" == \"$i\" ]] && return\n\tdone\n\tmsg \"$UNITTEST_NAME: SKIP: Only supported on $1\"\n\texit 0\n}\n\n#\n# exclude_arch -- Skip tests if the running platform matches\n# any of the input list.\n#\nfunction exclude_arch() {\n\tfor i in \"$@\"; do\n\t\tif [[ \"$(arch)\" == \"$i\" ]]; then\n\t\t\tmsg \"$UNITTEST_NAME: SKIP: Not supported on $1\"\n\t\t\texit 0\n\t\tfi\n\tdone\n}\n\n#\n# require_x86_64 -- Skip tests if the running platform is not x86_64\n#\nfunction require_x86_64() {\n\trequire_arch x86_64\n}\n\n#\n# require_ppc64 -- Skip tests if the running platform is not ppc64 or ppc64le\n#\nfunction require_ppc64() {\n\trequire_arch \"ppc64\" \"ppc64le\" \"ppc64el\"\n}\n\n#\n# exclude_ppc64 -- Skip tests if the running platform is ppc64 or ppc64le\n#\nfunction exclude_ppc64() {\n\texclude_arch \"ppc64\" \"ppc64le\" \"ppc64el\"\n}\n\n#\n# require_test_type -- only allow script to continue for a certain test type\n#\nfunction require_test_type() {\n\treq_test_type=1\n\tfor type in $*\n\tdo\n\t\tcase \"$TEST\"\n\t\tin\n\t\tall)\n\t\t\t# \"all\" is a synonym of \"short + medium + long\"\n\t\t\treturn\n\t\t\t;;\n\t\tcheck)\n\t\t\t# \"check\" is a synonym of \"short + medium\"\n\t\t\t[ \"$type\" = \"short\" -o \"$type\" = \"medium\" ] && return\n\t\t\t;;\n\t\t*)\n\t\t\t[ \"$type\" = \"$TEST\" ] && return\n\t\t\t;;\n\t\tesac\n\tdone\n\tverbose_msg \"$UNITTEST_NAME: SKIP test-type $TEST ($* required)\"\n\texit 0\n}\n\n#\n# require_dev_dax_region -- check if region id file exist for dev dax\n#\nfunction require_dev_dax_region() {\n\tlocal prefix=\"$UNITTEST_NAME: SKIP\"\n\tlocal cmd=\"$PMEMDETECT -r\"\n\n\tfor path in ${DEVICE_DAX_PATH[@]}\n\tdo\n\t\tdisable_exit_on_error\n\t\tout=$($cmd $path 2>&1)\n\t\tret=$?\n\t\trestore_exit_on_error\n\n\t\tif [ \"$ret\" == \"0\" ]; then\n\t\t\tcontinue\n\t\telif [ \"$ret\" == \"1\" ]; then\n\t\t\tmsg \"$prefix $out\"\n\t\t\texit 0\n\t\telse\n\t\t\tfatal \"$UNITTEST_NAME: pmemdetect: $out\"\n\t\tfi\n\tdone\n\tDEVDAX_TO_LOCK=1\n}\n\n#\n# lock_devdax -- acquire a lock on Device DAXes\n#\nlock_devdax() {\n\texec {DEVDAX_LOCK_FD}> $DEVDAX_LOCK\n\tflock $DEVDAX_LOCK_FD\n}\n\n#\n# unlock_devdax -- release a lock on Device DAXes\n#\nunlock_devdax() {\n\tflock -u $DEVDAX_LOCK_FD\n\teval \"exec ${DEVDAX_LOCK_FD}>&-\"\n}\n\n#\n# require_dev_dax_node -- common function for require_dax_devices and\n# node_require_dax_device\n#\n# usage: require_dev_dax_node <N devices> [<node>]\n#\nfunction require_dev_dax_node() {\n\treq_dax_dev=1\n\tif  [ \"$req_dax_dev_align\" == \"1\" ]; then\n\t\tfatal \"$UNITTEST_NAME: Do not use 'require_(node_)dax_devices' and \"\n\t\t\t\"'require_(node_)dax_device_alignments' together. Use the latter instead.\"\n\tfi\n\n\tlocal min=$1\n\tlocal node=$2\n\tif [ -n \"$node\" ]; then\n\t\tlocal DIR=${NODE_WORKING_DIR[$node]}/$curtestdir\n\t\tlocal prefix=\"$UNITTEST_NAME: SKIP NODE $node:\"\n\t\tlocal device_dax_path=(${NODE_DEVICE_DAX_PATH[$node]})\n\t\tif [  ${#device_dax_path[@]} -lt $min ]; then\n\t\t\tmsg \"$prefix NODE_${node}_DEVICE_DAX_PATH does not specify enough dax devices (min: $min)\"\n\t\t\texit 0\n\t\tfi\n\t\tlocal cmd=\"ssh $SSH_OPTS ${NODE[$node]} cd $DIR && LD_LIBRARY_PATH=$REMOTE_LD_LIBRARY_PATH ../pmemdetect -d\"\n\telse\n\t\tlocal prefix=\"$UNITTEST_NAME: SKIP\"\n\t\tif [ ${#DEVICE_DAX_PATH[@]} -lt $min ]; then\n\t\t\tmsg \"$prefix DEVICE_DAX_PATH does not specify enough dax devices (min: $min)\"\n\t\t\texit 0\n\t\tfi\n\t\tlocal device_dax_path=${DEVICE_DAX_PATH[@]}\n\t\tlocal cmd=\"$PMEMDETECT -d\"\n\tfi\n\n\tfor path in ${device_dax_path[@]}\n\tdo\n\t\tdisable_exit_on_error\n\t\tout=$($cmd $path 2>&1)\n\t\tret=$?\n\t\trestore_exit_on_error\n\n\t\tif [ \"$ret\" == \"0\" ]; then\n\t\t\tcontinue\n\t\telif [ \"$ret\" == \"1\" ]; then\n\t\t\tmsg \"$prefix $out\"\n\t\t\texit 0\n\t\telse\n\t\t\tfatal \"$UNITTEST_NAME: pmemdetect: $out\"\n\t\tfi\n\tdone\n\tDEVDAX_TO_LOCK=1\n}\n\n#\n# require_dax_devices -- only allow script to continue if there is a required\n# number of Device DAX devices\n#\nfunction require_dax_devices() {\n\tREQUIRE_DAX_DEVICES=$1\n\trequire_dev_dax_node $1\n}\n\n#\n# require_node_dax_device -- only allow script to continue if specified node\n# has enough Device DAX devices defined in testconfig.sh\n#\nfunction require_node_dax_device() {\n\tvalidate_node_number $1\n\trequire_dev_dax_node $2 $1\n}\n\n#\n# require_no_unicode -- overwrite unicode suffix to empty string\n#\nfunction require_no_unicode() {\n\texport SUFFIX=\"\"\n}\n\n#\n# get_node_devdax_path -- get path of a Device DAX device on a node\n#\n# usage: get_node_devdax_path <node> <device>\n#\nget_node_devdax_path() {\n\tlocal node=$1\n\tlocal device=$2\n\tlocal device_dax_path=(${NODE_DEVICE_DAX_PATH[$node]})\n\techo ${device_dax_path[$device]}\n}\n\n#\n# dax_device_zero -- zero all local dax devices\n#\ndax_device_zero() {\n\tfor path in ${DEVICE_DAX_PATH[@]}\n\tdo\n\t\t${PMEMPOOL}.static-debug rm -f $path\n\tdone\n}\n\n#\n# node_dax_device_zero -- zero all dax devices on a node\n#\nnode_dax_device_zero() {\n\tlocal node=$1\n\tlocal DIR=${NODE_WORKING_DIR[$node]}/$curtestdir\n\tlocal prefix=\"$UNITTEST_NAME: SKIP NODE $node:\"\n\tlocal device_dax_path=(${NODE_DEVICE_DAX_PATH[$node]})\n\tlocal cmd=\"ssh $SSH_OPTS ${NODE[$node]} cd $DIR && LD_LIBRARY_PATH=$REMOTE_LD_LIBRARY_PATH ../pmempool rm -f\"\n\n\tfor path in ${device_dax_path[@]}\n\tdo\n\t\tdisable_exit_on_error\n\t\tout=$($cmd $path 2>&1)\n\t\tret=$?\n\t\trestore_exit_on_error\n\n\t\tif [ \"$ret\" == \"0\" ]; then\n\t\t\tcontinue\n\t\telif [ \"$ret\" == \"1\" ]; then\n\t\t\tmsg \"$prefix $out\"\n\t\t\texit 0\n\t\telse\n\t\t\tfatal \"$UNITTEST_NAME: pmempool rm: $out\"\n\t\tfi\n\tdone\n\n}\n\n#\n# get_devdax_size -- get the size of a device dax\n#\nfunction get_devdax_size() {\n\tlocal device=$1\n\tlocal path=${DEVICE_DAX_PATH[$device]}\n\tlocal major_hex=$(stat -c \"%t\" $path)\n\tlocal minor_hex=$(stat -c \"%T\" $path)\n\tlocal major_dec=$((16#$major_hex))\n\tlocal minor_dec=$((16#$minor_hex))\n\tcat /sys/dev/char/$major_dec:$minor_dec/size\n}\n\n#\n# get_node_devdax_size -- get the size of a device dax on a node\n#\nfunction get_node_devdax_size() {\n\tlocal node=$1\n\tlocal device=$2\n\tlocal device_dax_path=(${NODE_DEVICE_DAX_PATH[$node]})\n\tlocal path=${device_dax_path[$device]}\n\tlocal cmd_prefix=\"ssh $SSH_OPTS ${NODE[$node]} \"\n\n\tdisable_exit_on_error\n\tout=$($cmd_prefix stat -c %t $path 2>&1)\n\tret=$?\n\trestore_exit_on_error\n\tif [ \"$ret\" != \"0\" ]; then\n\t\tfatal \"$UNITTEST_NAME: stat on node $node: $out\"\n\tfi\n\tlocal major=$((16#$out))\n\n\tdisable_exit_on_error\n\tout=$($cmd_prefix stat -c %T $path 2>&1)\n\tret=$?\n\trestore_exit_on_error\n\tif [ \"$ret\" != \"0\" ]; then\n\t\tfatal \"$UNITTEST_NAME: stat on node $node: $out\"\n\tfi\n\tlocal minor=$((16#$out))\n\n\tdisable_exit_on_error\n\tout=$($cmd_prefix \"cat /sys/dev/char/$major:$minor/size\" 2>&1)\n\tret=$?\n\trestore_exit_on_error\n\tif [ \"$ret\" != \"0\" ]; then\n\t\tfatal \"$UNITTEST_NAME: stat on node $node: $out\"\n\tfi\n\techo $out\n}\n\n#\n# require_dax_device_node_alignments -- only allow script to continue if\n#    the internal Device DAX alignments on a remote nodes are as specified.\n# If necessary, it sorts DEVICE_DAX_PATH entries to match\n# the requested alignment order.\n#\n# usage: require_node_dax_device_alignments <node> <alignment1> [ alignment2 ... ]\n#\nfunction require_node_dax_device_alignments() {\n\treq_dax_dev_align=1\n\tif  [ \"$req_dax_dev\" == \"$1\" ]; then\n\t\tfatal \"$UNITTEST_NAME: Do not use 'require_(node_)dax_devices' and \"\n\t\t\t\"'require_(node_)dax_device_alignments' together. Use the latter instead.\"\n\tfi\n\n\tlocal node=$1\n\tshift\n\n\tif [ \"$node\" == \"-1\" ]; then\n\t\tlocal device_dax_path=(${DEVICE_DAX_PATH[@]})\n\t\tlocal cmd=\"$PMEMDETECT -a\"\n\telse\n\t\tlocal device_dax_path=(${NODE_DEVICE_DAX_PATH[$node]})\n\t\tlocal DIR=${NODE_WORKING_DIR[$node]}/$curtestdir\n\t\tlocal cmd=\"ssh $SSH_OPTS ${NODE[$node]} cd $DIR && LD_LIBRARY_PATH=$REMOTE_LD_LIBRARY_PATH ../pmemdetect -a\"\n\tfi\n\n\tlocal cnt=${#device_dax_path[@]}\n\tlocal j=0\n\n\tfor alignment in $*\n\tdo\n\t\tfor (( i=j; i<cnt; i++ ))\n\t\tdo\n\t\t\tpath=${device_dax_path[$i]}\n\n\t\t\tdisable_exit_on_error\n\t\t\tout=$($cmd $alignment $path 2>&1)\n\t\t\tret=$?\n\t\t\trestore_exit_on_error\n\n\t\t\tif [ \"$ret\" == \"0\" ]; then\n\t\t\t\tif [ $i -ne $j ]; then\n\t\t\t\t\t# swap device paths\n\t\t\t\t\ttmp=${device_dax_path[$j]}\n\t\t\t\t\tdevice_dax_path[$j]=$path\n\t\t\t\t\tdevice_dax_path[$i]=$tmp\n\t\t\t\t\tif [ \"$node\" == \"-1\" ]; then\n\t\t\t\t\t\tDEVICE_DAX_PATH=(${device_dax_path[@]})\n\t\t\t\t\telse\n\t\t\t\t\t\tNODE_DEVICE_DAX_PATH[$node]=${device_dax_path[@]}\n\t\t\t\t\tfi\n\t\t\t\tfi\n\t\t\t\tbreak\n\t\t\tfi\n\t\tdone\n\n\t\tif [ $i -eq $cnt ]; then\n\t\t\tif [ \"$node\" == \"-1\" ]; then\n\t\t\t\tmsg \"$UNITTEST_NAME: SKIP DEVICE_DAX_PATH\"\\\n\t\t\t\t\t\"does not specify enough dax devices or they don't have required alignments (min: $#, alignments: $*)\"\n\t\t\telse\n\t\t\t\tmsg \"$UNITTEST_NAME: SKIP NODE $node: NODE_${node}_DEVICE_DAX_PATH\"\\\n\t\t\t\t\t\"does not specify enough dax devices or they don't have required alignments (min: $#, alignments: $*)\"\n\t\t\tfi\n\t\t\texit 0\n\t\tfi\n\n\t\tj=$(( j + 1 ))\n\tdone\n}\n\n#\n# require_dax_device_alignments -- only allow script to continue if\n#    the internal Device DAX alignments are as specified.\n# If necessary, it sorts DEVICE_DAX_PATH entries to match\n# the requested alignment order.\n#\n# usage: require_dax_device_alignments alignment1 [ alignment2 ... ]\n#\nrequire_dax_device_alignments() {\n\trequire_node_dax_device_alignments -1 $*\n}\n\n#\n# disable_eatmydata -- ensure invalid msyncs fail\n#\n# Distros (and people) like to use eatmydata to kill fsync-likes during builds\n# and testing. This is nice for speed, but we actually rely on msync failing\n# in some tests.\n#\ndisable_eatmydata() {\n\texport LD_PRELOAD=\"${LD_PRELOAD/#libeatmydata.so/}\"\n\texport LD_PRELOAD=\"${LD_PRELOAD/ libeatmydata.so/}\"\n\texport LD_PRELOAD=\"${LD_PRELOAD/:libeatmydata.so/}\"\n}\n\n#\n# require_fs_type -- only allow script to continue for a certain fs type\n#\nfunction require_fs_type() {\n\treq_fs_type=1\n\tfor type in $*\n\tdo\n\t\t# treat any as either pmem or non-pmem\n\t\t[ \"$type\" = \"$FS\" ] ||\n\t\t\t([ -n \"${FORCE_FS:+x}\" ] && [ \"$type\" = \"any\" ] &&\n\t\t\t[ \"$FS\" != \"none\" ]) && return\n\tdone\n\tverbose_msg \"$UNITTEST_NAME: SKIP fs-type $FS ($* required)\"\n\texit 0\n}\n\n#\n# require_native_fallocate -- verify if filesystem supports fallocate\n#\nfunction require_native_fallocate() {\n\trequire_fs_type pmem non-pmem\n\n\tset +e\n\t$FALLOCATE_DETECT $1\n\tstatus=$?\n\tset -e\n\n\tif [ $status -eq 1 ]; then\n\t\tmsg \"$UNITTEST_NAME: SKIP: filesystem does not support fallocate\"\n\t\texit 0\n\telif [ $status -ne 0 ]; then\n\t\tmsg \"$UNITTEST_NAME: fallocate_detect failed\"\n\t\texit 1\n\tfi\n}\n\n#\n# require_usc_permission -- verify if usc can be read with current permissions\n#\nfunction require_usc_permission() {\n\tset +e\n\t$USC_PERMISSION $1 2> $DIR/usc_permission.txt\n\tstatus=$?\n\tset -e\n\n\t# check if there were any messages printed to stderr, skip test if there were\n\tusc_stderr=$(cat $DIR/usc_permission.txt | wc -c)\n\n\trm -f $DIR/usc_permission.txt\n\n\tif [ $status -eq 1 ] || [ $usc_stderr -ne 0 ]; then\n\t\tmsg \"$UNITTEST_NAME: SKIP: missing permissions to read usc\"\n\t\texit 0\n\telif [ $status -ne 0 ]; then\n\t\tmsg \"$UNITTEST_NAME: usc_permission_check failed\"\n\t\texit 1\n\tfi\n}\n\n#\n# require_fs_name -- verify if the $DIR is on the required file system\n#\n# Must be AFTER setup() because $DIR must exist\n#\nfunction require_fs_name() {\n\tfsname=`df $DIR -PT | awk '{if (NR == 2) print $2}'`\n\n\tfor name in $*\n\tdo\n\t\tif [ \"$name\" == \"$fsname\" ]; then\n\t\t\treturn\n\t\tfi\n\tdone\n\n\tmsg \"$UNITTEST_NAME: SKIP file system $fsname ($* required)\"\n\texit 0\n}\n\n#\n# require_build_type -- only allow script to continue for a certain build type\n#\nfunction require_build_type() {\n\tfor type in $*\n\tdo\n\t\t[ \"$type\" = \"$BUILD\" ] && return\n\tdone\n\tverbose_msg \"$UNITTEST_NAME: SKIP build-type $BUILD ($* required)\"\n\texit 0\n}\n\n#\n# require_command -- only allow script to continue if specified command exists\n#\nfunction require_command() {\n\tif ! which $1 &>/dev/null; then\n\t\tmsg \"$UNITTEST_NAME: SKIP: '$1' command required\"\n\t\texit 0\n\tfi\n}\n\n#\n# require_command_node -- only allow script to continue if specified command exists on a remote node\n#\n# usage: require_command_node <node-number>\n#\nfunction require_command_node() {\n\tif ! run_on_node $1 \"which $2 &>/dev/null\"; then\n\t\tmsg \"$UNITTEST_NAME: SKIP: node $1: '$2' command required\"\n\t\texit 0\n\tfi\n}\n\n#\n# require_kernel_module -- only allow script to continue if specified kernel module exists\n#\n# usage: require_kernel_module <module_name> [path_to_modinfo]\n#\nfunction require_kernel_module() {\n\tMODULE=$1\n\tMODINFO=$2\n\n\tif [ \"$MODINFO\" == \"\" ]; then\n\t\tset +e\n\t\t[ \"$MODINFO\" == \"\" ] && \\\n\t\t\tMODINFO=$(which modinfo 2>/dev/null)\n\t\tset -e\n\n\t\t[ \"$MODINFO\" == \"\" ] && \\\n\t\t\t[ -x /usr/sbin/modinfo ] && MODINFO=/usr/sbin/modinfo\n\t\t[ \"$MODINFO\" == \"\" ] && \\\n\t\t\t[ -x /sbin/modinfo ] && MODINFO=/sbin/modinfo\n\t\t[ \"$MODINFO\" == \"\" ] && \\\n\t\t\tmsg \"$UNITTEST_NAME: SKIP: modinfo command required\" && \\\n\t\t\texit 0\n\telse\n\t\t[ ! -x $MODINFO ] && \\\n\t\t\tmsg \"$UNITTEST_NAME: SKIP: modinfo command required\" && \\\n\t\t\texit 0\n\tfi\n\n\t$MODINFO -F name $MODULE &>/dev/null && true\n\tif [ $? -ne 0 ]; then\n\t\tmsg \"$UNITTEST_NAME: SKIP: '$MODULE' kernel module required\"\n\t\texit 0\n\tfi\n}\n\n#\n# require_kernel_module_node -- only allow script to continue if specified kernel module exists on a remote node\n#\n# usage: require_kernel_module_node <node> <module_name> [path_to_modinfo]\n#\nfunction require_kernel_module_node() {\n\tNODE_N=$1\n\tMODULE=$2\n\tMODINFO=$3\n\n\tif [ \"$MODINFO\" == \"\" ]; then\n\t\tset +e\n\t\t[ \"$MODINFO\" == \"\" ] && \\\n\t\t\tMODINFO=$(run_on_node $NODE_N which modinfo 2>/dev/null)\n\t\tset -e\n\n\t\t[ \"$MODINFO\" == \"\" ] && \\\n\t\t\trun_on_node $NODE_N \"test -x /usr/sbin/modinfo\" && MODINFO=/usr/sbin/modinfo\n\t\t[ \"$MODINFO\" == \"\" ] && \\\n\t\t\trun_on_node $NODE_N \"test -x /sbin/modinfo\" && MODINFO=/sbin/modinfo\n\t\t[ \"$MODINFO\" == \"\" ] && \\\n\t\t\tmsg \"$UNITTEST_NAME: SKIP: node $NODE_N: modinfo command required\" && \\\n\t\t\texit 0\n\telse\n\t\trun_on_node $NODE_N \"test ! -x $MODINFO\" && \\\n\t\t\tmsg \"$UNITTEST_NAME: SKIP: node $NODE_N: modinfo command required\" && \\\n\t\t\texit 0\n\tfi\n\n\trun_on_node $NODE_N \"$MODINFO -F name $MODULE &>/dev/null\" && true\n\tif [ $? -ne 0 ]; then\n\t\tmsg \"$UNITTEST_NAME: SKIP: node $NODE_N: '$MODULE' kernel module required\"\n\t\texit 0\n\tfi\n}\n\n#\n# require_pkg -- only allow script to continue if specified package exists\n#    usage: require_pkg <package name> [<package minimal version>]\n#\nfunction require_pkg() {\n\tif ! command -v pkg-config 1>/dev/null\n\tthen\n\t\tmsg \"$UNITTEST_NAME: SKIP pkg-config required\"\n\t\texit 0\n\tfi\n\n\tlocal COMMAND=\"pkg-config $1\"\n\tlocal MSG=\"$UNITTEST_NAME: SKIP '$1' package\"\n\tif [ \"$#\" -eq \"2\" ]; then\n\t\tCOMMAND=\"$COMMAND --atleast-version $2\"\n\t\tMSG=\"$MSG (version >= $2)\"\n\tfi\n\tMSG=\"$MSG required\"\n\tif ! $COMMAND\n\tthen\n\t\tmsg \"$MSG\"\n\t\texit 0\n\tfi\n}\n\n#\n# require_node_pkg -- only allow script to continue if specified package exists\n# on specified node\n#    usage: require_node_pkg <node> <package name> [<package minimal version>]\n#\nfunction require_node_pkg() {\n\tvalidate_node_number $1\n\n\tlocal N=$1\n\tshift\n\n\tlocal DIR=${NODE_WORKING_DIR[$N]}/$curtestdir\n\tlocal COMMAND=\"${NODE_ENV[$N]}\"\n\tif [ -n \"${NODE_LD_LIBRARY_PATH[$N]}\" ]; then\n\t\tlocal PKG_CONFIG_PATH=${NODE_LD_LIBRARY_PATH[$N]//:/\\/pkgconfig:}/pkgconfig\n\t\tCOMMAND=\"$COMMAND PKG_CONFIG_PATH=\\$PKG_CONFIG_PATH:$PKG_CONFIG_PATH\"\n\tfi\n\n\tCOMMAND=\"$COMMAND pkg-config $1\"\n\tMSG=\"$UNITTEST_NAME: SKIP NODE $N: '$1' package\"\n\tif [ \"$#\" -eq \"2\" ]; then\n\t\tCOMMAND=\"$COMMAND --atleast-version $2\"\n\t\tMSG=\"$MSG (version >= $2)\"\n\tfi\n\tMSG=\"$MSG required\"\n\n\tdisable_exit_on_error\n\trun_command ssh $SSH_OPTS ${NODE[$N]} \"$COMMAND\" 2>&1\n\tret=$?\n\trestore_exit_on_error\n\n\tif [ \"$ret\" == 1 ]; then\n\t\tmsg \"$MSG\"\n\t\texit 0\n\tfi\n}\n\n#\n# configure_valgrind -- only allow script to continue when settings match\n#\nfunction configure_valgrind() {\n\tcase \"$1\"\n\tin\n\tmemcheck|pmemcheck|helgrind|drd|force-disable)\n\t\t;;\n\t*)\n\t\tusage \"bad test-type: $1\"\n\t\t;;\n\tesac\n\n\tif [ \"$CHECK_TYPE\" == \"none\" ]; then\n\t\tif [ \"$1\" == \"force-disable\" ]; then\n\t\t\tmsg \"$UNITTEST_NAME: all valgrind tests disabled\"\n\t\telif [ \"$2\" = \"force-enable\" ]; then\n\t\t\tCHECK_TYPE=\"$1\"\n\t\t\trequire_valgrind_tool $1 $3\n\t\telif [ \"$2\" = \"force-disable\" ]; then\n\t\t\tCHECK_TYPE=none\n\t\telse\n\t\t\tfatal \"invalid parameter\"\n\t\tfi\n\telse\n\t\tif [ \"$1\" == \"force-disable\" ]; then\n\t\t\tmsg \"$UNITTEST_NAME: SKIP RUNTESTS script parameter $CHECK_TYPE tries to enable valgrind test when all valgrind tests are disabled in TEST\"\n\t\t\texit 0\n\t\telif [ \"$CHECK_TYPE\" != \"$1\" -a \"$2\" == \"force-enable\" ]; then\n\t\t\tmsg \"$UNITTEST_NAME: SKIP RUNTESTS script parameter $CHECK_TYPE tries to enable different valgrind test than one defined in TEST\"\n\t\t\texit 0\n\t\telif [ \"$CHECK_TYPE\" == \"$1\" -a \"$2\" == \"force-disable\" ]; then\n\t\t\tmsg \"$UNITTEST_NAME: SKIP RUNTESTS script parameter $CHECK_TYPE tries to enable test defined in TEST as force-disable\"\n\t\t\texit 0\n\t\tfi\n\t\trequire_valgrind_tool $CHECK_TYPE $3\n\tfi\n\n\tif [ \"$UT_VALGRIND_SKIP_PRINT_MISMATCHED\" == 1 ]; then\n\t\texport UT_SKIP_PRINT_MISMATCHED=1\n\tfi\n}\n\n#\n# valgrind_version_no_check -- returns Valgrind version without checking\n#   for valgrind first\n#\nfunction valgrind_version_no_check() {\n\t$VALGRINDEXE --version | sed \"s/valgrind-\\([0-9]*\\)\\.\\([0-9]*\\).*/\\1*100+\\2/\" | bc\n}\n\n#\n# require_valgrind -- continue script execution only if\n#\tvalgrind package is installed\n#\nfunction require_valgrind() {\n\t# bc is used inside valgrind_version_no_check\n\trequire_command bc\n\trequire_no_asan\n\tdisable_exit_on_error\n\tVALGRINDEXE=`which valgrind 2>/dev/null`\n\tlocal ret=$?\n\trestore_exit_on_error\n\tif [ $ret -ne 0 ]; then\n\t\tmsg \"$UNITTEST_NAME: SKIP valgrind required\"\n\t\texit 0\n\tfi\n\t[ $NODES_MAX -lt 0 ] && return;\n\n\tif [ ! -z \"$1\" ]; then\n\t\tavailable=$(valgrind_version_no_check)\n\t\trequired=`echo $1 | sed \"s/\\([0-9]*\\)\\.\\([0-9]*\\).*/\\1*100+\\2/\" | bc`\n\n\t\tif [ $available -lt $required ]; then\n\t\t\tmsg \"$UNITTEST_NAME: SKIP valgrind required (ver $1 or later)\"\n\t\t\texit 0\n\t\tfi\n\tfi\n\n\tfor N in $NODES_SEQ; do\n\t\tif [ \"${NODE_VALGRINDEXE[$N]}\" = \"\" ]; then\n\t\t\tdisable_exit_on_error\n\t\t\tNODE_VALGRINDEXE[$N]=$(ssh $SSH_OPTS ${NODE[$N]} \"which valgrind 2>/dev/null\")\n\t\t\tret=$?\n\t\t\trestore_exit_on_error\n\t\t\tif [ $ret -ne 0 ]; then\n\t\t\t\tmsg \"$UNITTEST_NAME: SKIP valgrind required on remote node #$N\"\n\t\t\t\texit 0\n\t\t\tfi\n\t\tfi\n\tdone\n}\n\n#\n# valgrind_version -- returns Valgrind version\n#\nfunction valgrind_version() {\n\trequire_valgrind\n\tvalgrind_version_no_check\n}\n\n#\n# require_valgrind_tool -- continue script execution only if valgrind with\n#\tspecified tool is installed\n#\n#\tusage: require_valgrind_tool <tool> [<binary>]\n#\nfunction require_valgrind_tool() {\n\trequire_valgrind\n\tlocal tool=$1\n\tlocal binary=$2\n\tlocal dir=.\n\t[ -d \"$2\" ] && dir=\"$2\" && binary=\n\tpushd \"$dir\" > /dev/null\n\t[ -n \"$binary\" ] || binary=$(get_executables)\n\tif [ -z \"$binary\" ]; then\n\t\tfatal \"require_valgrind_tool: error: no binary found\"\n\tfi\n\tstrings ${binary} 2>&1 | \\\n\tgrep -q \"compiled with support for Valgrind $tool\" && true\n\tif [ $? -ne 0 ]; then\n\t\tmsg \"$UNITTEST_NAME: SKIP not compiled with support for Valgrind $tool\"\n\t\texit 0\n\tfi\n\n\tif [ \"$tool\" == \"helgrind\" ]; then\n\t\tvalgrind --tool=$tool --help 2>&1 | \\\n\t\tgrep -qi \"$tool is Copyright (c)\" && true\n\t\tif [ $? -ne 0 ]; then\n\t\t\tmsg \"$UNITTEST_NAME: SKIP Valgrind with $tool required\"\n\t\t\texit 0;\n\t\tfi\n\tfi\n\tif [ \"$tool\" == \"pmemcheck\" ]; then\n\t\tout=`valgrind --tool=$tool --help 2>&1` && true\n\t\techo \"$out\" | grep -qi \"$tool is Copyright (c)\" && true\n\t\tif [ $? -ne 0 ]; then\n\t\t\tmsg \"$UNITTEST_NAME: SKIP Valgrind with $tool required\"\n\t\t\texit 0;\n\t\tfi\n\t\techo \"$out\" | grep -qi \"expect-fence-after-clflush\" && true\n\t\tif [ $? -ne 0 ]; then\n\t\t\tmsg \"$UNITTEST_NAME: SKIP pmemcheck does not support --expect-fence-after-clflush option. Please update it to the latest version.\"\n\t\t\texit 0;\n\t\tfi\n\tfi\n\tpopd > /dev/null\n\treturn 0\n}\n\n#\n# set_valgrind_exe_name -- set the actual Valgrind executable name\n#\n# On some systems (Ubuntu), \"valgrind\" is a shell script that calls\n# the actual executable \"valgrind.bin\".\n# The wrapper script doesn't work well with LD_PRELOAD, so we want\n# to call Valgrind directly.\n#\nfunction set_valgrind_exe_name() {\n\tif [ \"$VALGRINDEXE\" = \"\" ]; then\n\t\tfatal \"set_valgrind_exe_name: error: valgrind is not set up\"\n\tfi\n\n\tlocal VALGRINDDIR=`dirname $VALGRINDEXE`\n\tif [ -x $VALGRINDDIR/valgrind.bin ]; then\n\t\tVALGRINDEXE=$VALGRINDDIR/valgrind.bin\n\tfi\n\n\t[ $NODES_MAX -lt 0 ] && return;\n\tfor N in $NODES_SEQ; do\n\t\tlocal COMMAND=\"\\\n\t\t\t[ -x $(dirname ${NODE_VALGRINDEXE[$N]})/valgrind.bin ] && \\\n\t\t\techo $(dirname ${NODE_VALGRINDEXE[$N]})/valgrind.bin || \\\n\t\t\techo ${NODE_VALGRINDEXE[$N]}\"\n\t\tNODE_VALGRINDEXE[$N]=$(ssh $SSH_OPTS ${NODE[$N]} $COMMAND)\n\t\tif [ $? -ne 0 ]; then\n\t\t\tfatal ${NODE_VALGRINDEXE[$N]}\n\t\tfi\n\tdone\n}\n\n#\n# require_no_asan_for - continue script execution only if passed binary does\n#\tNOT require libasan\n#\nfunction require_no_asan_for() {\n\tdisable_exit_on_error\n\tnm $1 | grep -q __asan_\n\tASAN_ENABLED=$?\n\trestore_exit_on_error\n\tif [ \"$ASAN_ENABLED\" == \"0\" ]; then\n\t\tmsg \"$UNITTEST_NAME: SKIP: ASAN enabled\"\n\t\texit 0\n\tfi\n}\n\n#\n# require_cxx11 -- continue script execution only if C++11 supporting compiler\n#\tis installed\n#\nfunction require_cxx11() {\n\t[ \"$CXX\" ] || CXX=c++\n\n\tCXX11_AVAILABLE=`echo \"int main(){return 0;}\" |\\\n\t\t$CXX -std=c++11 -x c++ -o /dev/null - 2>/dev/null &&\\\n\t\techo y || echo n`\n\n\tif [ \"$CXX11_AVAILABLE\" == \"n\" ]; then\n\t\tmsg \"$UNITTEST_NAME: SKIP: C++11 required\"\n\t\texit 0\n\tfi\n}\n\n#\n# require_no_asan - continue script execution only if libpmem does NOT require\n#\tlibasan\n#\nfunction require_no_asan() {\n\tcase \"$BUILD\"\n\tin\n\tdebug)\n\t\trequire_no_asan_for ../../debug/libpmem.so\n\t\t;;\n\tnondebug)\n\t\trequire_no_asan_for ../../nondebug/libpmem.so\n\t\t;;\n\tstatic-debug)\n\t\trequire_no_asan_for ../../debug/libpmem.a\n\t\t;;\n\tstatic-nondebug)\n\t\trequire_no_asan_for ../../nondebug/libpmem.a\n\t\t;;\n\tesac\n}\n\n#\n# require_tty - continue script execution only if standard output is a terminal\n#\nfunction require_tty() {\n\tif ! tty >/dev/null; then\n\t\tmsg \"$UNITTEST_NAME: SKIP no terminal\"\n\t\texit 0\n\tfi\n}\n\n#\n# require_binary -- continue script execution only if the binary has been compiled\n#\n# In case of conditional compilation, skip this test.\n#\nfunction require_binary() {\n\tif [ -z \"$1\" ]; then\n\t\tfatal \"require_binary: error: binary not provided\"\n\tfi\n\tif [ ! -x \"$1\" ]; then\n\t\tmsg \"$UNITTEST_NAME: SKIP no binary found\"\n\t\texit 0\n\tfi\n\n\treturn\n}\n\n#\n# require_sds -- continue script execution only if binary is compiled with\n#\tshutdown state support\n#\n#\tusage: require_sds <binary>\n#\nfunction require_sds() {\n\tlocal binary=$1\n\tlocal dir=.\n\tif [ -z \"$binary\" ]; then\n\t\tfatal \"require_sds: error: no binary found\"\n\tfi\n\tstrings ${binary} 2>&1 | \\\n\t\tgrep -q \"compiled with support for shutdown state\" && true\n\tif [ $? -ne 0 ]; then\n\t\tmsg \"$UNITTEST_NAME: SKIP not compiled with support for shutdown state\"\n\t\texit 0\n\tfi\n\treturn 0\n}\n\n#\n# require_no_sds -- continue script execution only if binary is NOT compiled with\n#\tshutdown state support\n#\n#\tusage: require_no_sds <binary>\n#\nfunction require_no_sds() {\n\tlocal binary=$1\n\tlocal dir=.\n\tif [ -z \"$binary\" ]; then\n\t\tfatal \"require_sds: error: no binary found\"\n\tfi\n\tset +e\n\tfound=$(strings ${binary} 2>&1 | \\\n\t\tgrep -c \"compiled with support for shutdown state\")\n\tset -e\n\tif [ \"$found\" -ne \"0\" ]; then\n\t\tmsg \"$UNITTEST_NAME: SKIP compiled with support for shutdown state\"\n\t\texit 0\n\tfi\n\treturn 0\n}\n\n#\n# is_ndctl_enabled -- check if binary is compiled with libndctl\n#\n#\tusage: is_ndctl_enabled <binary>\n#\nfunction is_ndctl_enabled() {\n\tlocal binary=$1\n\tlocal dir=.\n\tif [ -z \"$binary\" ]; then\n\t\tfatal \"is_ndctl_enabled: error: no binary found\"\n\tfi\n\n\tstrings ${binary} 2>&1 | \\\n\t\tgrep -q \"compiled with libndctl\" && true\n\n\treturn $?\n}\n\n#\n# require_bb_enabled_by_default -- check if the binary has bad block\n#                                     checking feature enabled by default\n#\n#\tusage: require_bb_enabled_by_default <binary>\n#\nfunction require_bb_enabled_by_default() {\n\tif ! is_ndctl_enabled $1 &> /dev/null ; then\n\t\tmsg \"$UNITTEST_NAME: SKIP bad block checking feature disabled by default\"\n\t\texit 0\n\tfi\n\n\treturn 0\n}\n\n#\n# require_bb_disabled_by_default -- check if the binary does not have bad\n#                                      block checking feature enabled by default\n#\n#\tusage: require_bb_disabled_by_default <binary>\n#\nfunction require_bb_disabled_by_default() {\n\tif is_ndctl_enabled $1 &> /dev/null ; then\n\t\tmsg \"$UNITTEST_NAME: SKIP bad block checking feature enabled by default\"\n\t\texit 0\n\tfi\n\treturn 0\n}\n\n#\n# check_absolute_path -- continue script execution only if $DIR path is\n#                        an absolute path; do not resolve symlinks\n#\nfunction check_absolute_path() {\n\tif [ \"${DIR:0:1}\" != \"/\" ]; then\n\t\tfatal \"Directory \\$DIR has to be an absolute path. $DIR was given.\"\n\tfi\n}\n\n#\n# run_command -- run a command in a verbose or quiet way\n#\nfunction run_command()\n{\n\tlocal COMMAND=\"$*\"\n\tif [ \"$VERBOSE\" != \"0\" ]; then\n\t\techo \"$ $COMMAND\"\n\t\t$COMMAND\n\telse\n\t\t$COMMAND\n\tfi\n}\n\n#\n# validate_node_number -- validate a node number\n#\nfunction validate_node_number() {\n\t[ $1 -gt $NODES_MAX ] \\\n\t\t&& fatal \"error: node number ($1) greater than maximum allowed node number ($NODES_MAX)\"\n\treturn 0\n}\n\n#\n# clean_remote_node -- usage: clean_remote_node <node> <list-of-pid-files>\n#\nfunction clean_remote_node() {\n\n\tvalidate_node_number $1\n\n\tlocal N=$1\n\tshift\n\tlocal DIR=${NODE_WORKING_DIR[$N]}/$curtestdir\n\n\t# register the list of PID files to be cleaned in case of an error\n\tNODE_PID_FILES[$N]=\"${NODE_PID_FILES[$N]} $*\"\n\n\t# clean the remote node\n\tdisable_exit_on_error\n\tfor pidfile in ${NODE_PID_FILES[$N]}; do\n\t\trequire_ctrld_err $N $pidfile\n\t\trun_command ssh $SSH_OPTS ${NODE[$N]} \"\\\n\t\t\tcd $DIR && [ -f $pidfile ] && \\\n\t\t\t../ctrld $pidfile kill SIGINT && \\\n\t\t\t../ctrld $pidfile wait 1 ; \\\n\t\t\trm -f $pidfile\"\n\tdone;\n\trestore_exit_on_error\n\n\treturn 0\n}\n\n#\n# clean_all_remote_nodes -- clean all remote nodes in case of an error\n#\nfunction clean_all_remote_nodes() {\n\n\tmsg \"$UNITTEST_NAME: CLEAN (cleaning processes on remote nodes)\"\n\n\tlocal N=0\n\tdisable_exit_on_error\n\tfor N in $NODES_SEQ; do\n\t\tlocal DIR=${NODE_WORKING_DIR[$N]}/$curtestdir\n\t\tfor pidfile in ${NODE_PID_FILES[$N]}; do\n\t\t\trun_command ssh $SSH_OPTS ${NODE[$N]} \"\\\n\t\t\t\tcd $DIR && [ -f $pidfile ] && \\\n\t\t\t\t../ctrld $pidfile kill SIGINT && \\\n\t\t\t\t../ctrld $pidfile wait 1 ; \\\n\t\t\t\trm -f $pidfile\"\n\t\tdone\n\tdone\n\trestore_exit_on_error\n\n\treturn 0\n}\n\n#\n# export_vars_node -- export specified variables on specified node\n#\nfunction export_vars_node() {\n\tlocal N=$1\n\tshift\n\tvalidate_node_number $N\n\tfor var in \"$@\"; do\n\t\tNODE_ENV[$N]=\"${NODE_ENV[$N]} $var=${!var}\"\n\tdone\n}\n\n#\n# require_nodes_libfabric -- only allow script to continue if libfabric with\n#                            optionally specified provider is available on\n#                            specified node\n#    usage: require_nodes_libfabric <node> <provider> [<libfabric-version>]\n#\nfunction require_node_libfabric() {\n\tvalidate_node_number $1\n\n\tlocal N=$1\n\tlocal provider=$2\n\t# Minimal required version of libfabric.\n\t# Keep in sync with requirements in src/common.inc.\n\tlocal version=${3:-1.4.2}\n\n\trequire_pkg libfabric \"$version\"\n\t# fi_info can be found in libfabric-bin\n\trequire_command fi_info\n\trequire_node_pkg $N libfabric \"$version\"\n\trequire_command_node $N fi_info\n\tif [ \"$RPMEM_PROVIDER\" == \"verbs\" ]; then\n\t\tif ! fi_info --list | grep -q verbs; then\n\t\t\tmsg \"$UNITTEST_NAME: SKIP libfabric not compiled with verbs provider\"\n\t\t\texit 0\n\t\tfi\n\n\t\tif ! run_on_node $N \"fi_info --list | grep -q verbs\"; then\n\t\t\tmsg \"$UNITTEST_NAME: SKIP libfabric on node $N not compiled with verbs provider\"\n\t\t\texit 0\n\n\t\tfi\n\tfi\n\n\tlocal DIR=${NODE_WORKING_DIR[$N]}/$curtestdir\n\tlocal COMMAND=\"$COMMAND ${NODE_ENV[$N]}\"\n\tCOMMAND=\"$COMMAND LD_LIBRARY_PATH=${NODE_LD_LIBRARY_PATH[$N]}:$REMOTE_LD_LIBRARY_PATH\"\n\tCOMMAND=\"$COMMAND ../fip ${NODE_ADDR[$N]} $provider\"\n\n\tdisable_exit_on_error\n\tfip_out=$(ssh $SSH_OPTS ${NODE[$N]} \"cd $DIR && $COMMAND\" 2>&1)\n\tret=$?\n\trestore_exit_on_error\n\n\tif [ \"$ret\" == \"0\" ]; then\n\t\treturn\n\telif [ \"$ret\" == \"1\" ]; then\n\t\tmsg \"$UNITTEST_NAME: SKIP NODE $N: $fip_out\"\n\t\texit 0\n\telse\n\t\tfatal \"NODE $N: require_libfabric $provider: $fip_out\"\n\tfi\n}\n\n#\n# check_if_node_is_reachable -- check if the $1 node is reachable\n#\nfunction check_if_node_is_reachable() {\n\tdisable_exit_on_error\n\trun_command ssh $SSH_OPTS ${NODE[$1]} exit\n\tlocal ret=$?\n\trestore_exit_on_error\n\treturn $ret\n}\n\n#\n# require_nodes -- only allow script to continue for a certain number\n#                  of defined and reachable nodes\n#\n# Input arguments:\n#   NODE[]               - (required) array of nodes' addresses\n#   NODE_WORKING_DIR[]   - (required) array of nodes' working directories\n#\nfunction require_nodes() {\n\n\tlocal N_NODES=${#NODE[@]}\n\tlocal N=$1\n\n\t[ -z \"$N\" ] \\\n\t\t&& fatal \"require_nodes: missing reguired parameter: number of nodes\"\n\n\t# if it has already been called, check if number of required nodes is bigger than previously\n\t[ -n \"$NODES_MAX\" ] \\\n\t\t&& [ $(($N - 1)) -le $NODES_MAX ] && return\n\n\t[ $N -gt $N_NODES ] \\\n\t\t&& msg \"$UNITTEST_NAME: SKIP: requires $N node(s), but $N_NODES node(s) provided\" \\\n\t\t&& exit 0\n\n\tNODES_MAX=$(($N - 1))\n\tNODES_SEQ=$(seq -s' ' 0 $NODES_MAX)\n\n\t# check if all required nodes are reachable\n\tfor N in $NODES_SEQ; do\n\t\t# validate node's address\n\t\t[ \"${NODE[$N]}\" = \"\" ] \\\n\t\t\t&& msg \"$UNITTEST_NAME: SKIP: address of node #$N is not provided\" \\\n\t\t\t&& exit 0\n\n\t\t# validate the working directory\n\t\t[ \"${NODE_WORKING_DIR[$N]}\" = \"\" ] \\\n\t\t\t&& fatal \"error: working directory for node #$N (${NODE[$N]}) is not provided\"\n\n\t\t# check if the node is reachable\n\t\tcheck_if_node_is_reachable $N\n\t\t[ $? -ne 0 ] \\\n\t\t\t&& fatal \"error: node #$N (${NODE[$N]}) is unreachable\"\n\n\t\t# clear the list of PID files for each node\n\t\tNODE_PID_FILES[$N]=\"\"\n\t\tNODE_TEST_DIR[$N]=${NODE_WORKING_DIR[$N]}/$curtestdir\n\t\tNODE_DIR[$N]=${NODE_WORKING_DIR[$N]}/$curtestdir/data/\n\n\t\trequire_node_log_files $N $ERR_LOG_FILE $OUT_LOG_FILE $TRACE_LOG_FILE\n\n\t\tif [ \"$CHECK_TYPE\" != \"none\" -a \"${NODE_VALGRINDEXE[$N]}\" = \"\" ]; then\n\t\t\tdisable_exit_on_error\n\t\t\tNODE_VALGRINDEXE[$N]=$(ssh $SSH_OPTS ${NODE[$N]} \"which valgrind 2>/dev/null\")\n\t\t\tlocal ret=$?\n\t\t\trestore_exit_on_error\n\t\t\tif [ $ret -ne 0 ]; then\n\t\t\t\tmsg \"$UNITTEST_NAME: SKIP valgrind required on remote node #$N\"\n\t\t\t\texit 0\n\t\t\tfi\n\t\tfi\n\tdone\n\n\t# remove all log files of the current unit test from the required nodes\n\t# and export the 'log' variables to these nodes\n\tfor N in $NODES_SEQ; do\n\t\tfor f in $(get_files \"node_${N}.*${UNITTEST_NUM}\\.log\"); do\n\t\t\trm -f $f\n\t\tdone\n\t\texport_vars_node $N $REMOTE_VARS\n\tdone\n\n\t# register function to clean all remote nodes in case of an error or SIGINT\n\ttrap clean_all_remote_nodes ERR SIGINT\n\n\treturn 0\n}\n\n#\n# check_files_on_node -- check if specified files exist on given node\n#\nfunction check_files_on_node() {\n\tvalidate_node_number $1\n\tlocal N=$1\n\tshift\n\tlocal REMOTE_DIR=${NODE_DIR[$N]}\n\trun_command ssh $SSH_OPTS ${NODE[$N]} \"for f in $*; do if [ ! -f $REMOTE_DIR/\\$f ]; then echo \\\"Missing file \\$f on node #$N\\\" 1>&2; exit 1; fi; done\"\n}\n\n#\n# check_no_files_on_node -- check if specified files does not exist on given node\n#\nfunction check_no_files_on_node() {\n\tvalidate_node_number $1\n\tlocal N=$1\n\tshift\n\tlocal REMOTE_DIR=${NODE_DIR[$N]}\n\trun_command ssh $SSH_OPTS ${NODE[$N]} \"for f in $*; do if [ -f $REMOTE_DIR/\\$f ]; then echo \\\"Not deleted file \\$f on node #$N\\\" 1>&2; exit 1; fi; done\"\n}\n\n#\n# copy_files_to_node -- copy all required files to the given remote node\n#    usage: copy_files_to_node <node> <destination dir> <file_1> [<file_2>] ...\n#\nfunction copy_files_to_node() {\n\n\tvalidate_node_number $1\n\n\tlocal N=$1\n\tlocal DEST_DIR=$2\n\tshift 2\n\t[ $# -eq 0 ] &&\\\n\t\tfatal \"error: copy_files_to_node(): no files provided\"\n\n\t# copy all required files\n\trun_command scp $SCP_OPTS $@ ${NODE[$N]}:$DEST_DIR > /dev/null\n\n\treturn 0\n}\n\n#\n# copy_files_from_node -- copy all required files from the given remote node\n#    usage: copy_files_from_node <node> <destination_dir> <file_1> [<file_2>] ...\n#\nfunction copy_files_from_node() {\n\n\tvalidate_node_number $1\n\n\tlocal N=$1\n\tlocal DEST_DIR=$2\n\t[ ! -d $DEST_DIR ] &&\\\n\t\tfatal \"error: destination directory $DEST_DIR does not exist\"\n\tshift 2\n\t[ $# -eq 0 ] &&\\\n\t\tfatal \"error: copy_files_from_node(): no files provided\"\n\n\t# compress required files, copy and extract\n\tlocal temp_file=node_${N}_temp_file.tar\n\tfiles=\"\"\n\tdir_name=\"\"\n\n\tfiles=$(basename -a $@)\n\tdir_name=$(dirname $1)\n\trun_command ssh $SSH_OPTS ${NODE[$N]} \"cd $dir_name && tar -czf $temp_file $files\"\n\trun_command scp $SCP_OPTS ${NODE[$N]}:$dir_name/$temp_file $DEST_DIR > /dev/null\n\n\tcd $DEST_DIR \\\n\t\t&& tar -xzf $temp_file \\\n\t\t&& rm $temp_file \\\n\t\t&& cd - > /dev/null\n\n\treturn 0\n}\n\n#\n# copy_log_files -- copy log files from remote node\n#\nfunction copy_log_files() {\n\tlocal NODE_SCP_LOG_FILES[0]=\"\"\n\tfor N in $NODES_SEQ; do\n\t\tlocal DIR=${NODE_WORKING_DIR[$N]}/$curtestdir\n\t\tfor file in ${NODE_LOG_FILES[$N]}; do\n\t\t\tNODE_SCP_LOG_FILES[$N]=\"${NODE_SCP_LOG_FILES[$N]} ${NODE[$N]}:$DIR/${file}\"\n\t\tdone\n\t\t[ \"${NODE_SCP_LOG_FILES[$N]}\" ] && run_command scp $SCP_OPTS ${NODE_SCP_LOG_FILES[$N]} . &>> $PREP_LOG_FILE\n\t\tfor file in ${NODE_LOG_FILES[$N]}; do\n\t\t\t[ -f $file ] && mv $file node_${N}_${file}\n\t\tdone\n\tdone\n}\n\n#\n# rm_files_from_node -- removes all listed files from the given remote node\n#    usage: rm_files_from_node <node> <file_1> [<file_2>] ...\n#\nfunction rm_files_from_node() {\n\n\tvalidate_node_number $1\n\n\tlocal N=$1\n\tshift\n\t[ $# -eq 0 ] &&\\\n\t\tfatal \"error: rm_files_from_node(): no files provided\"\n\n\trun_command ssh $SSH_OPTS ${NODE[$N]} \"rm -f $@\"\n\n\treturn 0\n}\n\n#\n#\n# require_node_log_files -- store log files which must be copied from\n#                           specified node on failure\n#\nfunction require_node_log_files() {\n\tvalidate_node_number $1\n\n\tlocal N=$1\n\tshift\n\n\tNODE_LOG_FILES[$N]=\"${NODE_LOG_FILES[$N]} $*\"\n}\n\n#\n# require_ctrld_err -- store ctrld's log files to copy from specified\n#                      node on failure\n#\nfunction require_ctrld_err() {\n\tlocal N=$1\n\tlocal PID_FILE=$2\n\tlocal DIR=${NODE_WORKING_DIR[$N]}/$curtestdir\n\tfor cmd in run wait kill wait_port; do\n\t\tNODE_LOG_FILES[$N]=\"${NODE_LOG_FILES[$N]} $PID_FILE.$cmd.ctrld.log\"\n\tdone\n}\n\n#\n# run_on_node -- usage: run_on_node <node> <command>\n#\n#                Run the <command> in background on the remote <node>.\n#                LD_LIBRARY_PATH for the n-th remote node can be provided\n#                in the array NODE_LD_LIBRARY_PATH[n]\n#\nfunction run_on_node() {\n\n\tvalidate_node_number $1\n\n\tlocal N=$1\n\tshift\n\tlocal DIR=${NODE_WORKING_DIR[$N]}/$curtestdir\n\tlocal COMMAND=\"UNITTEST_NUM=$UNITTEST_NUM UNITTEST_NAME=$UNITTEST_NAME\"\n\tCOMMAND=\"$COMMAND UNITTEST_LOG_LEVEL=1\"\n\tCOMMAND=\"$COMMAND ${NODE_ENV[$N]}\"\n\tCOMMAND=\"$COMMAND LD_LIBRARY_PATH=${NODE_LD_LIBRARY_PATH[$N]}:$REMOTE_LD_LIBRARY_PATH $*\"\n\n\trun_command ssh $SSH_OPTS ${NODE[$N]} \"cd $DIR && $COMMAND\"\n\tret=$?\n\tif [ \"$ret\" -ne \"0\" ]; then\n\t\tcopy_log_files\n\tfi\n\n\treturn $ret\n}\n\n#\n# run_on_node_background -- usage:\n#                           run_on_node_background <node> <pid-file> <command>\n#\n#                           Run the <command> in background on the remote <node>\n#                           and create a <pid-file> for this process.\n#                           LD_LIBRARY_PATH for the n-th remote node\n#                           can be provided in the array NODE_LD_LIBRARY_PATH[n]\n#\nfunction run_on_node_background() {\n\n\tvalidate_node_number $1\n\n\tlocal N=$1\n\tlocal PID_FILE=$2\n\tshift\n\tshift\n\tlocal DIR=${NODE_WORKING_DIR[$N]}/$curtestdir\n\tlocal COMMAND=\"UNITTEST_NUM=$UNITTEST_NUM UNITTEST_NAME=$UNITTEST_NAME\"\n\tCOMMAND=\"$COMMAND UNITTEST_LOG_LEVEL=1\"\n\tCOMMAND=\"$COMMAND ${NODE_ENV[$N]}\"\n\tCOMMAND=\"$COMMAND LD_LIBRARY_PATH=${NODE_LD_LIBRARY_PATH[$N]}:$REMOTE_LD_LIBRARY_PATH\"\n\tCOMMAND=\"$COMMAND ../ctrld $PID_FILE run $RUNTEST_TIMEOUT $*\"\n\n\t# register the PID file to be cleaned in case of an error\n\tNODE_PID_FILES[$N]=\"${NODE_PID_FILES[$N]} $PID_FILE\"\n\n\trun_command ssh $SSH_OPTS ${NODE[$N]} \"cd $DIR && $COMMAND\"\n\tret=$?\n\tif [ \"$ret\" -ne \"0\" ]; then\n\t\tcopy_log_files\n\tfi\n\n\treturn $ret\n}\n\n#\n# wait_on_node -- usage: wait_on_node <node> <pid-file> [<timeout>]\n#\n#                 Wait until the process with the <pid-file> on the <node>\n#                 exits or <timeout> expires.\n#\nfunction wait_on_node() {\n\n\tvalidate_node_number $1\n\n\tlocal N=$1\n\tlocal PID_FILE=$2\n\tlocal TIMEOUT=$3\n\tlocal DIR=${NODE_WORKING_DIR[$N]}/$curtestdir\n\n\trun_command ssh $SSH_OPTS ${NODE[$N]} \"cd $DIR && ../ctrld $PID_FILE wait $TIMEOUT\"\n\tret=$?\n\tif [ \"$ret\" -ne \"0\" ]; then\n\t\tcopy_log_files\n\tfi\n\n\treturn $ret\n}\n\n#\n# wait_on_node_port -- usage: wait_on_node_port <node> <pid-file> <portno>\n#\n#                      Wait until the process with the <pid-file> on the <node>\n#                      opens the port <portno>.\n#\nfunction wait_on_node_port() {\n\n\tvalidate_node_number $1\n\n\tlocal N=$1\n\tlocal PID_FILE=$2\n\tlocal PORTNO=$3\n\tlocal DIR=${NODE_WORKING_DIR[$N]}/$curtestdir\n\n\trun_command ssh $SSH_OPTS ${NODE[$N]} \"cd $DIR && ../ctrld $PID_FILE wait_port $PORTNO\"\n\tret=$?\n\tif [ \"$ret\" -ne \"0\" ]; then\n\t\tcopy_log_files\n\tfi\n\n\treturn $ret\n}\n\n#\n# kill_on_node -- usage: kill_on_node <node> <pid-file> <signo>\n#\n#                 Send the <signo> signal to the process with the <pid-file>\n#                 on the <node>.\n#\nfunction kill_on_node() {\n\n\tvalidate_node_number $1\n\n\tlocal N=$1\n\tlocal PID_FILE=$2\n\tlocal SIGNO=$3\n\tlocal DIR=${NODE_WORKING_DIR[$N]}/$curtestdir\n\n\trun_command ssh $SSH_OPTS ${NODE[$N]} \"cd $DIR && ../ctrld $PID_FILE kill $SIGNO\"\n\tret=$?\n\tif [ \"$ret\" -ne \"0\" ]; then\n\t\tcopy_log_files\n\tfi\n\n\treturn $ret\n}\n\n#\n# obj_pool_desc_size -- returns the obj_pool_desc_size macro value\n# in bytes which is two times the actual pagesize.\n#\n# This should be use to calculate the minimum zero size for pool\n# creation on some tests.\n#\nfunction obj_pool_desc_size() {\n\techo \"$(expr $(getconf PAGESIZE) \\* 2)\"\n}\n\n#\n# log_pool_desc_size -- returns the minimum size of pool header\n# in bytes which is two times the actual pagesize.\n#\n# This should be use to calculate the minimum zero size for pool\n# creation on some tests.\n#\nfunction log_pool_desc_size() {\n\techo \"$(expr $(getconf PAGESIZE) \\* 2)\"\n}\n\n#\n# blk_pool_desc_size -- returns the minimum size of pool header\n# in bytes which is two times the actual pagesize.\n#\n# This should be use to calculate the minimum zero size for pool\n# creation on some tests.\n#\nfunction blk_pool_desc_size() {\n\techo \"$(expr $(getconf PAGESIZE) \\* 2)\"\n}\n\n#\n# create_holey_file_on_node -- create holey files of a given length\n#   usage: create_holey_file_on_node <node> <size>\n#\n# example, to create two files, each 1GB in size on node 0:\n#\tcreate_holey_file_on_node 0 1G testfile1 testfile2\n#\n# Input unit size is in bytes with optional suffixes like k, KB, M, etc.\n#\nfunction create_holey_file_on_node() {\n\n\tvalidate_node_number $1\n\n\tlocal N=$1\n\tsize=$(convert_to_bytes $2)\n\tshift 2\n\tfor file in $*\n\tdo\n\t\trun_on_node $N truncate -s ${size} $file >> $PREP_LOG_FILE\n\tdone\n}\n\n#\n# require_mmap_under_valgrind -- only allow script to continue if mapping is\n#\t\t\t\tpossible under Valgrind with required length\n#\t\t\t\t(sum of required DAX devices size).\n#\t\t\t\tThis function is being called internally in\n#\t\t\t\tsetup() function.\n#\nfunction require_mmap_under_valgrind() {\n\n\tlocal FILE_MAX_DAX_DEVICES=\"../tools/anonymous_mmap/max_dax_devices\"\n\n\tif [ -z \"$REQUIRE_DAX_DEVICES\" ]; then\n\t\treturn\n\tfi\n\n\tif [ ! -f \"$FILE_MAX_DAX_DEVICES\" ]; then\n\t\tfatal \"$FILE_MAX_DAX_DEVICES not found. Run make test.\"\n\tfi\n\n\tif [ \"$REQUIRE_DAX_DEVICES\" -gt \"$(< $FILE_MAX_DAX_DEVICES)\" ]; then\n\t\tmsg \"$UNITTEST_NAME: SKIP: anonymous mmap under Valgrind not possible for $REQUIRE_DAX_DEVICES DAX device(s).\"\n\t\texit 0\n\tfi\n}\n\n#\n# setup -- print message that test setup is commencing\n#\nfunction setup() {\n\n\tDIR=$DIR$SUFFIX\n\n\t# writes test working directory to temporary file\n\t# that allows read location of data after test failure\n\tif [ -f \"$TEMP_LOC\" ]; then\n\t\techo \"$DIR\" > $TEMP_LOC\n\tfi\n\n\t# test type must be explicitly specified\n\tif [ \"$req_test_type\" != \"1\" ]; then\n\t\tfatal \"error: required test type is not specified\"\n\tfi\n\n\t# fs type \"none\" must be explicitly enabled\n\tif [ \"$FS\" = \"none\" -a \"$req_fs_type\" != \"1\" ]; then\n\t\texit 0\n\tfi\n\n\t# fs type \"any\" must be explicitly enabled\n\tif [ \"$FS\" = \"any\" -a \"$req_fs_type\" != \"1\" ]; then\n\t\texit 0\n\tfi\n\n\tif [ \"$CHECK_TYPE\" != \"none\" ]; then\n\t\trequire_valgrind\n\n\t\t# detect possible Valgrind mmap issues and skip uncertain tests\n\t\trequire_mmap_under_valgrind\n\n\t\texport VALGRIND_LOG_FILE=$CHECK_TYPE${UNITTEST_NUM}.log\n\t\tMCSTR=\"/$CHECK_TYPE\"\n\telse\n\t\tMCSTR=\"\"\n\tfi\n\n\t[ -n \"$RPMEM_PROVIDER\" ] && PROV=\"/$RPMEM_PROVIDER\"\n\t[ -n \"$RPMEM_PM\" ] && PM=\"/$RPMEM_PM\"\n\n\tmsg \"$UNITTEST_NAME: SETUP ($TEST/$REAL_FS/$BUILD$MCSTR$PROV$PM)\"\n\n\tfor f in $(get_files \".*[a-zA-Z_]${UNITTEST_NUM}\\.log\"); do\n\t\trm -f $f\n\tdone\n\n\t# $DIR has to be an absolute path\n\tcheck_absolute_path\n\n\tif [ \"$FS\" != \"none\" ]; then\n\t\tif [ -d \"$DIR\" ]; then\n\t\t\trm $RM_ONEFS -rf -- $DIR\n\t\tfi\n\n\t\tmkdir -p $DIR\n\tfi\n\tif [ \"$TM\" = \"1\" ]; then\n\t\tstart_time=$($DATE +%s.%N)\n\tfi\n\n\tif [ \"$DEVDAX_TO_LOCK\" == 1 ]; then\n\t\tlock_devdax\n\tfi\n\n\texport PMEMBLK_CONF=\"fallocate.at_create=0;\"\n\texport PMEMOBJ_CONF=\"fallocate.at_create=0;\"\n\texport PMEMLOG_CONF=\"fallocate.at_create=0;\"\n}\n\n#\n# check_log_empty -- if match file does not exist, assume log should be empty\n#\nfunction check_log_empty() {\n\tif [ ! -f ${1}.match ] && [ $(get_size $1) -ne 0 ]; then\n\t\techo \"unexpected output in $1\"\n\t\tdump_last_n_lines $1\n\t\texit 1\n\tfi\n}\n\n#\n# check_local -- check local test results (using .match files)\n#\nfunction check_local() {\n\tif [ \"$UT_SKIP_PRINT_MISMATCHED\" == 1 ]; then\n\t\toption=-q\n\tfi\n\n\tcheck_log_empty $ERR_LOG_FILE\n\n\tFILES=$(get_files \"[^0-9w]*${UNITTEST_NUM}\\.log\\.match\")\n\tif [ -n \"$FILES\" ]; then\n\t\t../match $option $FILES\n\tfi\n}\n\n#\n# match -- execute match\n#\nfunction match() {\n\t../match $@\n}\n\n#\n# check -- check local or remote test results (using .match files)\n#\nfunction check() {\n\tif [ $NODES_MAX -lt 0 ]; then\n\t\tcheck_local\n\telse\n\t\tFILES=$(get_files \"node_[0-9]+_[^0-9w]*${UNITTEST_NUM}\\.log\\.match\")\n\n\t\tlocal NODE_MATCH_FILES[0]=\"\"\n\t\tlocal NODE_SCP_MATCH_FILES[0]=\"\"\n\t\tfor file in $FILES; do\n\t\t\tlocal N=`echo $file | cut -d\"_\" -f2`\n\t\t\tlocal DIR=${NODE_WORKING_DIR[$N]}/$curtestdir\n\t\t\tlocal FILE=`echo $file | cut -d\"_\" -f3 | sed \"s/\\.match$//g\"`\n\t\t\tvalidate_node_number $N\n\t\t\tNODE_MATCH_FILES[$N]=\"${NODE_MATCH_FILES[$N]} $FILE\"\n\t\t\tNODE_SCP_MATCH_FILES[$N]=\"${NODE_SCP_MATCH_FILES[$N]} ${NODE[$N]}:$DIR/$FILE\"\n\t\tdone\n\n\t\tfor N in $NODES_SEQ; do\n\t\t\t[ \"${NODE_SCP_MATCH_FILES[$N]}\" ] && run_command scp $SCP_OPTS ${NODE_SCP_MATCH_FILES[$N]} . > /dev/null\n\t\t\tfor file in ${NODE_MATCH_FILES[$N]}; do\n\t\t\t\tmv $file node_${N}_${file}\n\t\t\tdone\n\t\tdone\n\n\t\tif [ \"$UT_SKIP_PRINT_MISMATCHED\" == 1 ]; then\n\t\t\toption=-q\n\t\tfi\n\n\t\tfor N in $NODES_SEQ; do\n\t\t\tcheck_log_empty node_${N}_${ERR_LOG_FILE}\n\t\tdone\n\n\t\tif [ -n \"$FILES\" ]; then\n\t\t\tmatch $option $FILES\n\t\tfi\n\tfi\n}\n\n#\n# pass -- print message that the test has passed\n#\nfunction pass() {\n\tif [ \"$DEVDAX_TO_LOCK\" == 1 ]; then\n\t\tunlock_devdax\n\tfi\n\n\tif [ \"$TM\" = \"1\" ]; then\n\t\tend_time=$($DATE +%s.%N)\n\n\t\tstart_time_sec=$($DATE -d \"0 $start_time sec\" +%s)\n\t\tend_time_sec=$($DATE -d \"0 $end_time sec\" +%s)\n\n\t\tdays=$(((end_time_sec - start_time_sec) / (24*3600)))\n\t\tdays=$(printf \"%03d\" $days)\n\n\t\ttm=$($DATE -d \"0 $end_time sec - $start_time sec\" +%H:%M:%S.%N)\n\t\ttm=$(echo \"$days:$tm\" | sed -e \"s/^000://g\" -e \"s/^00://g\" -e \"s/^00://g\" -e \"s/\\([0-9]*\\)\\.\\([0-9][0-9][0-9]\\).*/\\1.\\2/\")\n\t\ttm=\"\\t\\t\\t[$tm s]\"\n\telse\n\t\ttm=\"\"\n\tfi\n\tmsg=$(interactive_green STDOUT \"PASS\")\n\tif [ \"$UNITTEST_LOG_LEVEL\" -ge 1 ]; then\n\t\techo -e \"$UNITTEST_NAME: $msg$tm\"\n\tfi\n\tif [ \"$FS\" != \"none\" ]; then\n\t\trm $RM_ONEFS -rf -- $DIR\n\tfi\n}\n\n# Length of pool file's signature\nSIG_LEN=8\n\n# Offset and length of pmemobj layout\nLAYOUT_OFFSET=$(getconf PAGE_SIZE)\nLAYOUT_LEN=1024\n\n# Length of arena's signature\nARENA_SIG_LEN=16\n\n# Signature of BTT Arena\nARENA_SIG=\"BTT_ARENA_INFO\"\n\n# Offset to first arena\nARENA_OFF=$(($(getconf PAGE_SIZE) * 2))\n\n#\n# check_file -- check if file exists and print error message if not\n#\ncheck_file()\n{\n\tif [ ! -f $1 ]\n\tthen\n\t\tfatal \"Missing file: ${1}\"\n\tfi\n}\n\n#\n# check_files -- check if files exist and print error message if not\n#\ncheck_files()\n{\n\tfor file in $*\n\tdo\n\t\tcheck_file $file\n\tdone\n}\n\n#\n# check_no_file -- check if file has been deleted and print error message if not\n#\ncheck_no_file()\n{\n\tif [ -f $1 ]\n\tthen\n\t\tfatal \"Not deleted file: ${1}\"\n\tfi\n}\n\n#\n# check_no_files -- check if files has been deleted and print error message if not\n#\ncheck_no_files()\n{\n\tfor file in $*\n\tdo\n\t\tcheck_no_file $file\n\tdone\n}\n\n#\n# get_size -- return size of file (0 if file does not exist)\n#\nget_size()\n{\n\tif [ ! -f $1 ]; then\n\t\techo \"0\"\n\telse\n\t\tstat $STAT_SIZE $1\n\tfi\n}\n\n#\n# get_mode -- return mode of file\n#\nget_mode()\n{\n\tstat $STAT_MODE $1\n}\n\n#\n# check_size -- validate file size\n#\ncheck_size()\n{\n\tlocal size=$1\n\tlocal file=$2\n\tlocal file_size=$(get_size $file)\n\n\tif [[ $size != $file_size ]]\n\tthen\n\t\tfatal \"error: wrong size ${file_size} != ${size}\"\n\tfi\n}\n\n#\n# check_mode -- validate file mode\n#\ncheck_mode()\n{\n\tlocal mode=$1\n\tlocal file=$2\n\tlocal file_mode=$(get_mode $file)\n\n\tif [[ $mode != $file_mode ]]\n\tthen\n\t\tfatal \"error: wrong mode ${file_mode} != ${mode}\"\n\tfi\n}\n\n#\n# check_signature -- check if file contains specified signature\n#\ncheck_signature()\n{\n\tlocal sig=$1\n\tlocal file=$2\n\tlocal file_sig=$($DD if=$file bs=1 count=$SIG_LEN 2>/dev/null | tr -d \\\\0)\n\n\tif [[ $sig != $file_sig ]]\n\tthen\n\t\tfatal \"error: $file: signature doesn't match ${file_sig} != ${sig}\"\n\tfi\n}\n\n#\n# check_signatures -- check if multiple files contain specified signature\n#\ncheck_signatures()\n{\n\tlocal sig=$1\n\tshift 1\n\tfor file in $*\n\tdo\n\t\tcheck_signature $sig $file\n\tdone\n}\n\n#\n# check_layout -- check if pmemobj pool contains specified layout\n#\ncheck_layout()\n{\n\tlocal layout=$1\n\tlocal file=$2\n\tlocal file_layout=$($DD if=$file bs=1\\\n\t\tskip=$LAYOUT_OFFSET count=$LAYOUT_LEN 2>/dev/null | tr -d \\\\0)\n\n\tif [[ $layout != $file_layout ]]\n\tthen\n\t\tfatal \"error: layout doesn't match ${file_layout} != ${layout}\"\n\tfi\n}\n\n#\n# check_arena -- check if file contains specified arena signature\n#\ncheck_arena()\n{\n\tlocal file=$1\n\tlocal sig=$($DD if=$file bs=1 skip=$ARENA_OFF count=$ARENA_SIG_LEN 2>/dev/null | tr -d \\\\0)\n\n\tif [[ $sig != $ARENA_SIG ]]\n\tthen\n\t\tfatal \"error: can't find arena signature\"\n\tfi\n}\n\n#\n# dump_pool_info -- dump selected pool metadata and/or user data\n#\nfunction dump_pool_info() {\n\t# ignore selected header fields that differ by definition\n\t${PMEMPOOL}.static-nondebug info $* | sed -e \"/^UUID/,/^Checksum/d\"\n}\n\n#\n# compare_replicas -- check replicas consistency by comparing `pmempool info` output\n#\nfunction compare_replicas() {\n\tdisable_exit_on_error\n\tdiff <(dump_pool_info $1 $2) <(dump_pool_info $1 $3) -I \"^path\" -I \"^size\"\n\trestore_exit_on_error\n}\n\n#\n# get_node_dir -- returns node dir for current test\n#    usage: get_node_dir <node>\n#\nfunction get_node_dir() {\n\tvalidate_node_number $1\n\techo ${NODE_WORKING_DIR[$1]}/$curtestdir\n}\n\n#\n# init_rpmem_on_node -- prepare rpmem environment variables on node\n#    usage: init_rpmem_on_node <master-node> <slave-node-1> [<slave-node-2> ...]\n#\n# example:\n#    The following command initialize rpmem environment variables on the node 1\n#    to perform replication to node 0, node 2 and node 3.\n#    Additionally:\n#    - on node 2 rpmemd pid will be stored in file.pid\n#    - on node 3 no pid file will be created (SKIP) and rpmemd will use\n#      file.conf config file\n#\n#       init_rpmem_on_node 1 0 2:file.pid 3:SKIP:file.conf\n#\nfunction init_rpmem_on_node() {\n\tlocal master=$1\n\tshift\n\n\tvalidate_node_number $master\n\n\tcase \"$RPMEM_PM\" in\n\tAPM|GPSPM)\n\t\t;;\n\t*)\n\t\tmsg \"$UNITTEST_NAME: SKIP required: RPMEM_PM is invalid or empty\"\n\t\texit 0\n\t\t;;\n\tesac\n\n\t# Workaround for SIGSEGV in the infinipath-psm during abort\n\t# The infinipath-psm is registering a signal handler and do not unregister\n\t# it when rpmem handle is dlclosed. SIGABRT (potentially any other signal)\n\t# would try to call the signal handler which does not exist after dlclose.\n\t# Issue require a fix in the infinipath-psm or the libfabric.\n\tIPATH_NO_BACKTRACE=1\n\texport_vars_node $master IPATH_NO_BACKTRACE\n\n\tRPMEM_CMD=\"\"\n\tlocal SEPARATOR=\"|\"\n\tfor slave in \"$@\"\n\tdo\n\t\tslave=(${slave//:/ })\n\t\tconf=${slave[2]}\n\t\tpid=${slave[1]}\n\t\tslave=${slave[0]}\n\n\t\tvalidate_node_number $slave\n\t\tlocal poolset_dir=${NODE_DIR[$slave]}\n\t\tif [ -n \"${RPMEM_POOLSET_DIR[$slave]}\" ]; then\n\t\t\tpoolset_dir=${RPMEM_POOLSET_DIR[$slave]}\n\t\tfi\n\t\tlocal trace=\n\t\tif [ -n \"$(is_valgrind_enabled_on_node $slave)\" ]; then\n\t\t\tlog_file=${CHECK_TYPE}${UNITTEST_NUM}.log\n\t\t\ttrace=$(get_trace $CHECK_TYPE $log_file $slave)\n\t\tfi\n\t\tif [ -n \"$pid\" -a \"$pid\" != \"SKIP\" ]; then\n\t\t\ttrace=\"$trace ../ctrld $pid exe\"\n\t\tfi\n\t\tif [ -n ${UNITTEST_DO_NOT_CHECK_OPEN_FILES+x} ]; then\n\t\t\texport_vars_node $slave UNITTEST_DO_NOT_CHECK_OPEN_FILES\n\t\tfi\n\t\tif [ -n ${IPATH_NO_BACKTRACE+x} ]; then\n\t\t\texport_vars_node $slave IPATH_NO_BACKTRACE\n\t\tfi\n\t\tCMD=\"cd ${NODE_TEST_DIR[$slave]} && \"\n\n\t\t# Force pmem for APM. Otherwise in case of lack of a pmem rpmemd will\n\t\t# silently fallback to GPSPM.\n\t\t[ \"$RPMEM_PM\" == \"APM\" ] && CMD=\"$CMD PMEM_IS_PMEM_FORCE=1\"\n\n\t\tCMD=\"$CMD ${NODE_ENV[$slave]}\"\n\t\tCMD=\"$CMD LD_LIBRARY_PATH=${NODE_LD_LIBRARY_PATH[$slave]}:$REMOTE_LD_LIBRARY_PATH\"\n\t\tCMD=\"$CMD $trace ../rpmemd\"\n\t\tCMD=\"$CMD --log-file=$RPMEMD_LOG_FILE\"\n\t\tCMD=\"$CMD --log-level=$RPMEMD_LOG_LEVEL\"\n\t\tCMD=\"$CMD --poolset-dir=$poolset_dir\"\n\n\t\tif [ -n \"$conf\" ]; then\n\t\t\tCMD=\"$CMD --config=$conf\"\n\t\tfi\n\n\t\tif [ \"$RPMEM_PM\" == \"APM\" ]; then\n\t\t\tCMD=\"$CMD --persist-apm\"\n\t\tfi\n\n\t\tif [ \"$RPMEM_CMD\" ]; then\n\t\t\tRPMEM_CMD=\"$RPMEM_CMD$SEPARATOR$CMD\"\n\t\telse\n\t\t\tRPMEM_CMD=$CMD\n\t\tfi\n\n\t\trequire_node_log_files $slave rpmemd$UNITTEST_NUM.log\n\tdone\n\tRPMEM_CMD=\"\\\"$RPMEM_CMD\\\"\"\n\n\tRPMEM_ENABLE_SOCKETS=0\n\tRPMEM_ENABLE_VERBS=0\n\n\tcase \"$RPMEM_PROVIDER\" in\n\tsockets)\n\t\tRPMEM_ENABLE_SOCKETS=1\n\t\t;;\n\tverbs)\n\t\tRPMEM_ENABLE_VERBS=1\n\t\t;;\n\t*)\n\t\tmsg \"$UNITTEST_NAME: SKIP required: RPMEM_PROVIDER is invalid or empty\"\n\t\texit 0\n\t\t;;\n\tesac\n\n\texport_vars_node $master RPMEM_CMD\n\texport_vars_node $master RPMEM_ENABLE_SOCKETS\n\texport_vars_node $master RPMEM_ENABLE_VERBS\n\n\tif [ -n ${UNITTEST_DO_NOT_CHECK_OPEN_FILES+x} ]; then\n\t\texport_vars_node $master UNITTEST_DO_NOT_CHECK_OPEN_FILES\n\tfi\n\tif [ -n ${PMEMOBJ_NLANES+x} ]; then\n\t\texport_vars_node $master PMEMOBJ_NLANES\n\tfi\n\tif [ -n ${RPMEM_MAX_NLANES+x} ]; then\n\t\texport_vars_node $master RPMEM_MAX_NLANES\n\tfi\n\n\trequire_node_log_files $master rpmem$UNITTEST_NUM.log\n\trequire_node_log_files $master $PMEMOBJ_LOG_FILE\n}\n\n#\n# init_valgrind_on_node -- prepare valgrind on nodes\n#    usage: init_valgrind_on_node <node list>\n#\nfunction init_valgrind_on_node() {\n\t# When librpmem is preloaded libfabric does not close all opened files\n\t# before list of opened files is checked.\n\tlocal UNITTEST_DO_NOT_CHECK_OPEN_FILES=1\n\tlocal LD_PRELOAD=../$BUILD/librpmem.so\n\tCHECK_NODES=\"\"\n\n\tfor node in \"$@\"\n\tdo\n\t\tvalidate_node_number $node\n\t\texport_vars_node $node LD_PRELOAD\n\t\texport_vars_node $node UNITTEST_DO_NOT_CHECK_OPEN_FILES\n\t\tCHECK_NODES=\"$CHECK_NODES $node\"\n\tdone\n}\n\n#\n# is_valgrind_enabled_on_node -- echo the node number if the node has\n#                                initialized valgrind environment by calling\n#                                init_valgrind_on_node\n#    usage: is_valgrind_enabled_on_node <node>\n#\nfunction is_valgrind_enabled_on_node() {\n\tfor node in $CHECK_NODES\n\tdo\n\t\tif [ \"$node\" -eq \"$1\" ]; then\n\t\t\techo $1\n\t\t\treturn\n\t\tfi\n\tdone\n\treturn\n}\n\n#\n# pack_all_libs -- put all libraries and their links to one tarball\n#\nfunction pack_all_libs() {\n\tlocal LIBS_TAR_DIR=$(pwd)/$1\n\tcd $DIR_SRC\n\ttar -cf $LIBS_TAR_DIR ./debug/*.so* ./nondebug/*.so*\n\tcd - > /dev/null\n}\n\n#\n# copy_common_to_remote_nodes -- copy common files to all remote nodes\n#\nfunction copy_common_to_remote_nodes() {\n\n\tlocal NODES_ALL_MAX=$((${#NODE[@]} - 1))\n\tlocal NODES_ALL_SEQ=$(seq -s' ' 0 $NODES_ALL_MAX)\n\n\tDIR_SYNC=$1\n\tif [ \"$DIR_SYNC\" != \"\" ]; then\n\t\t[ ! -d $DIR_SYNC ] \\\n\t\t&& fatal \"error: $DIR_SYNC does not exist or is not a directory\"\n\tfi\n\n\t# add all libraries to the 'to-copy' list\n\tlocal LIBS_TAR=libs.tar\n\tpack_all_libs $LIBS_TAR\n\n\tif [ \"$DIR_SYNC\" != \"\" -a \"$(ls $DIR_SYNC)\" != \"\" ]; then\n\t\tFILES_COMMON_DIR=\"$DIR_SYNC/* $LIBS_TAR\"\n\telse\n\t\tFILES_COMMON_DIR=\"$FILES_COMMON_DIR $LIBS_TAR\"\n\tfi\n\n\tfor N in $NODES_ALL_SEQ; do\n\t\t# validate node's address\n\t\t[ \"${NODE[$N]}\" = \"\" ] \\\n\t\t\t&& fatal \"error: address of node #$N is not provided\"\n\n\t\tcheck_if_node_is_reachable $N\n\t\t[ $? -ne 0 ] \\\n\t\t\t&& msg \"warning: node #$N (${NODE[$N]}) is unreachable, skipping...\" \\\n\t\t\t&& continue\n\n\t\t# validate the working directory\n\t\t[ \"${NODE_WORKING_DIR[$N]}\" = \"\" ] \\\n\t\t\t&& msg \": warning: working directory for node #$N (${NODE[$N]}) is not provided, skipping...\" \\\n\t\t\t&& continue\n\n\t\t# create the working dir if it does not exist\n\t\trun_command ssh $SSH_OPTS ${NODE[$N]} \"mkdir -p ${NODE_WORKING_DIR[$N]}\"\n\n\t\t# copy all common files\n\t\trun_command scp $SCP_OPTS $FILES_COMMON_DIR ${NODE[$N]}:${NODE_WORKING_DIR[$N]} > /dev/null\n\t\t# unpack libraries\n\t\trun_command ssh $SSH_OPTS ${NODE[$N]} \"cd ${NODE_WORKING_DIR[$N]} \\\n\t\t\t&& tar -xf $LIBS_TAR && rm -f $LIBS_TAR\"\n\tdone\n\n\trm -f $LIBS_TAR\n}\n\n#\n# copy_test_to_remote_nodes -- copy all unit test binaries to all remote nodes\n#\nfunction copy_test_to_remote_nodes() {\n\n\tlocal NODES_ALL_MAX=$((${#NODE[@]} - 1))\n\tlocal NODES_ALL_SEQ=$(seq -s' ' 0 $NODES_ALL_MAX)\n\n\tfor N in $NODES_ALL_SEQ; do\n\t\t# validate node's address\n\t\t[ \"${NODE[$N]}\" = \"\" ] \\\n\t\t\t&& fatal \"error: address of node #$N is not provided\"\n\n\t\tcheck_if_node_is_reachable $N\n\t\t[ $? -ne 0 ] \\\n\t\t\t&& msg \"warning: node #$N (${NODE[$N]}) is unreachable, skipping...\" \\\n\t\t\t&& continue\n\n\t\t# validate the working directory\n\t\t[ \"${NODE_WORKING_DIR[$N]}\" = \"\" ] \\\n\t\t\t&& msg \": warning: working directory for node #$N (${NODE[$N]}) is not provided, skipping...\" \\\n\t\t\t&& continue\n\n\t\tlocal DIR=${NODE_WORKING_DIR[$N]}/$curtestdir\n\n\t\t# create a new test dir\n\t\trun_command ssh $SSH_OPTS ${NODE[$N]} \"rm -rf $DIR && mkdir -p $DIR\"\n\n\t\t# create the working data dir\n\t\trun_command ssh $SSH_OPTS ${NODE[$N]} \"mkdir -p \\\n\t\t\t${DIR}/data\"\n\n\t\t# copy all required files\n\t\t[ $# -gt 0 ] && run_command scp $SCP_OPTS $* ${NODE[$N]}:$DIR > /dev/null\n\tdone\n\n\treturn 0\n}\n\n#\n# enable_log_append -- turn on appending to the log files rather than truncating them\n# It also removes all log files created by tests: out*.log, err*.log and trace*.log\n#\nfunction enable_log_append() {\n\trm -f $OUT_LOG_FILE\n\trm -f $ERR_LOG_FILE\n\trm -f $TRACE_LOG_FILE\n\texport UNITTEST_LOG_APPEND=1\n}\n\n# clean data directory on all remote\n# nodes if remote test failed\nif [ \"$CLEAN_FAILED_REMOTE\" == \"y\" ]; then\n\tNODES_ALL=$((${#NODE[@]} - 1))\n\tMYPID=$$\n\n\tfor ((i=0;i<=$NODES_ALL;i++));\n\tdo\n\n\t\tif [[ -z \"${NODE_WORKING_DIR[$i]}\" || -z \"$curtestdir\" ]]; then\n\t\t\techo \"Invalid path to tests data: ${NODE_WORKING_DIR[$i]}/$curtestdir/data/\"\n\t\t\texit 1\n\t\tfi\n\n\t\tN[$i]=${NODE_WORKING_DIR[$i]}/$curtestdir/data/\n\t\trun_command ssh $SSH_OPTS ${NODE[$i]} \"rm -rf ${N[$i]}; mkdir ${N[$i]}\"\n\n\t\tif [ $? -eq 0 ]; then\n\t\t\tverbose_msg \"Removed data from: ${NODE[$i]}:${N[$i]}\"\n\t\tfi\n\tdone\n\texit 0\nfi\n\n# calculate the minimum of two or more numbers\nminimum() {\n\tlocal min=$1\n\tshift\n\tfor val in $*; do\n\t\tif [[ \"$val\" < \"$min\" ]]; then\n\t\t\tmin=$val\n\t\tfi\n\tdone\n\techo $min\n}\n\n#\n# count_lines - count number of lines that match pattern $1 in file $2\n#\nfunction count_lines() {\n\t# grep returns 1 on no match\n\tdisable_exit_on_error\n\t$GREP -ce \"$1\" $2\n\trestore_exit_on_error\n}\n\n#\n# get_pmemcheck_version() - return pmemcheck API major or minor version\n#\tusage: get_pmemcheck_version <0|1>\n#\nfunction get_pmemcheck_version()\n{\n\tPMEMCHECK_VERSION=$($VALGRINDEXE --tool=pmemcheck true 2>&1 \\\n\t\t\t| head -n 1 | sed \"s/.*-\\([0-9.]*\\),.*/\\1/\")\n\n\tOIFS=$IFS\n\tIFS=\".\"\n\tPMEMCHECK_MAJ_MIN=($PMEMCHECK_VERSION)\n\tIFS=$OIFS\n\tPMEMCHECK_VERSION_PART=${PMEMCHECK_MAJ_MIN[$1]}\n\n\techo \"$PMEMCHECK_VERSION_PART\"\n}\n\n#\n# require_pmemcheck_version_ge - check if pmemcheck API\n# version is greater or equal to required value\n#\tusage: require_pmemcheck_version_ge <major> <minor> [binary]\n#\nfunction require_pmemcheck_version_ge()\n{\n\trequire_valgrind_tool pmemcheck $3\n\n\tREQUIRE_MAJOR=$1\n\tREQUIRE_MINOR=$2\n\tPMEMCHECK_MAJOR=$(get_pmemcheck_version 0)\n\tPMEMCHECK_MINOR=$(get_pmemcheck_version 1)\n\n\t# compare MAJOR\n\tif [ $PMEMCHECK_MAJOR -gt $REQUIRE_MAJOR ]; then\n\t\treturn 0\n\tfi\n\n\t# compare MINOR\n\tif [ $PMEMCHECK_MAJOR -eq $REQUIRE_MAJOR ]; then\n\t\tif [ $PMEMCHECK_MINOR -ge $REQUIRE_MINOR ]; then\n\t\t\treturn 0\n\t\tfi\n\tfi\n\n\tmsg \"$UNITTEST_NAME: SKIP pmemcheck API version:\" \\\n\t\t\"$PMEMCHECK_MAJOR.$PMEMCHECK_MINOR\" \\\n\t\t\"is less than required\" \\\n\t\t\"$REQUIRE_MAJOR.$REQUIRE_MINOR\"\n\n\texit 0\n}\n\n#\n# require_pmemcheck_version_lt - check if pmemcheck API\n# version is less than required value\n#\tusage: require_pmemcheck_version_lt <major> <minor> [binary]\n#\nfunction require_pmemcheck_version_lt()\n{\n\trequire_valgrind_tool pmemcheck $3\n\n\tREQUIRE_MAJOR=$1\n\tREQUIRE_MINOR=$2\n\tPMEMCHECK_MAJOR=$(get_pmemcheck_version 0)\n\tPMEMCHECK_MINOR=$(get_pmemcheck_version 1)\n\n\t# compare MAJOR\n\tif [ $PMEMCHECK_MAJOR -lt $REQUIRE_MAJOR ]; then\n\t\treturn 0\n\tfi\n\n\t# compare MINOR\n\tif [ $PMEMCHECK_MAJOR -eq $REQUIRE_MAJOR ]; then\n\t\tif [ $PMEMCHECK_MINOR -lt $REQUIRE_MINOR ]; then\n\t\t\treturn 0\n\t\tfi\n\tfi\n\n\tmsg \"$UNITTEST_NAME: SKIP pmemcheck API version:\" \\\n\t\t\"$PMEMCHECK_MAJOR.$PMEMCHECK_MINOR\" \\\n\t\t\"is greater or equal than\" \\\n\t\t\"$REQUIRE_MAJOR.$REQUIRE_MINOR\"\n\n\texit 0\n}\n\n#\n# require_python_3 -- check if python3 is available\n#\nfunction require_python3()\n{\n\tif hash python3 &>/dev/null;\n\tthen\n\t\tPYTHON_EXE=python3\n\telse\n\t\tPYTHON_EXE=python\n\tfi\n\n\tcase \"$($PYTHON_EXE --version 2>&1)\" in\n\t    *\" 3.\"*)\n\t\treturn\n\t\t;;\n\t    *)\n\t\tmsg \"$UNITTEST_NAME: SKIP: required python version 3\"\n\t\texit 0\n\t\t;;\n\tesac\n}\n\n#\n# require_pmreorder -- check all necessary conditions to run pmreorder\n# usage: require_pmreorder [binary]\n#\nfunction require_pmreorder()\n{\n\t# python3 and valgrind are necessary\n\trequire_python3\n\t# pmemcheck is required to generate store_log\n\tconfigure_valgrind pmemcheck force-enable $1\n\t# pmreorder tool does not support unicode yet\n\trequire_no_unicode\n}\n\n#\n# pmreorder_run_tool -- run pmreorder with parameters and return exit status\n#\n# 1 - reorder engine type [nochecker|full|noreorder|partial|accumulative]\n# 2 - marker-engine pairs in format: MARKER=ENGINE,MARKER1=ENGINE1 or\n#     config file in json format: { \"MARKER\":\"ENGINE\",\"MARKER1\":\"ENGINE1\" }\n# 3 - the path to the checker binary/library and  remaining parameters which\n#     will be passed to the consistency checker binary.\n#     If you are using a library checker, prepend '-n funcname'\n#\nfunction pmreorder_run_tool()\n{\n\trm -f pmreorder$UNITTEST_NUM.log\n\tdisable_exit_on_error\n\t$PYTHON_EXE $PMREORDER \\\n\t\t-l store_log$UNITTEST_NUM.log \\\n\t\t-o pmreorder$UNITTEST_NUM.log \\\n\t\t-r $1 \\\n\t\t-x $2 \\\n\t\t-p \"$3\"\n\tret=$?\n\trestore_exit_on_error\n\techo $ret\n}\n\n#\n# pmreorder_expect_success -- run pmreoreder with forwarded parameters,\n#\t\t\t\texpect it to exit zero\n#\nfunction pmreorder_expect_success()\n{\n\tret=$(pmreorder_run_tool \"$@\")\n\n\tif [ \"$ret\" -ne \"0\" ]; then\n\t\tmsg=$(interactive_red STDERR \"failed with exit code $ret\")\n\n\t\t# exit code 130 - script terminated by user (Control-C)\n\t\tif [ \"$ret\" -ne \"130\" ]; then\n\n\t\t\techo -e \"$UNITTEST_NAME $msg.\" >&2\n\t\t\tdump_last_n_lines $PMREORDER_LOG_FILE\n\t\tfi\n\n\t\tfalse\n\tfi\n}\n\n#\n# pmreorder_expect_failure -- run pmreoreder with forwarded parameters,\n#\t\t\t\texpect it to exit non zero\n#\nfunction pmreorder_expect_failure()\n{\n\tret=$(pmreorder_run_tool \"$@\")\n\n\tif [ \"$ret\" -eq \"0\" ]; then\n\t\tmsg=$(interactive_red STDERR \"succeeded\")\n\n\t\techo -e \"$UNITTEST_NAME command $msg unexpectedly.\" >&2\n\n\t\tfalse\n\tfi\n}\n\n#\n# pmreorder_create_store_log -- perform a reordering test\n#\n# This function expects 5 additional parameters. They are in order:\n# 1 - the pool file to be tested\n# 2 - the application and necessary parameters to run pmemcheck logging\n#\nfunction pmreorder_create_store_log()\n{\n\t#copy original file and perform store logging\n\tcp $1 \"$1.pmr\"\n\trm -f store_log$UNITTEST_NUM.log\n\n\t$VALGRINDEXE \\\n\t\t\t--tool=pmemcheck -q \\\n\t\t\t--log-stores=yes \\\n\t\t\t--print-summary=no \\\n\t\t\t--log-file=store_log$UNITTEST_NUM.log \\\n\t\t\t--log-stores-stacktraces=yes \\\n\t\t\t--log-stores-stacktraces-depth=2 \\\n\t\t\t--expect-fence-after-clflush=yes \\\n\t\t\t$2\n\n\t# uncomment this line for debug purposes\n\t# mv $1 \"$1.bak\"\n\tmv \"$1.pmr\" $1\n}\n\n#\n# require_free_space -- check if there is enough free space to run the test\n# Example, checking if there is 1 GB of free space on disk:\n# require_free_space 1G\n#\nfunction require_free_space() {\n\treq_free_space=$(convert_to_bytes $1)\n\n\t# actually require 5% or 8MB (whichever is higher) more, just in case\n\t# file system requires some space for its meta data\n\tpct=$((5 * $req_free_space / 100))\n\tabs=$(convert_to_bytes 8M)\n\tif [ $pct -gt $abs ]; then\n\t\treq_free_space=$(($req_free_space + $pct))\n\telse\n\t\treq_free_space=$(($req_free_space + $abs))\n\tfi\n\n\toutput=$(df -k $DIR)\n\tfound=false\n\ti=1\n\tfor elem in $(echo \"$output\" | head -1); do\n\t\tif [ ${elem:0:5} == \"Avail\" ]; then\n\t\t\tfound=true\n\t\t\tbreak\n\t\telse\n\t\t\tlet \"i+=1\"\n\t\tfi\n\tdone\n\tif [ $found = true ]; then\n\t\trow=$(echo \"$output\" | tail -1)\n\t\tfree_space=$(( $(echo $row | awk \"{print \\$$i}\")*1024 ))\n\telse\n\t\tmsg \"$UNITTEST_NAME: SKIP: unable to check free space\"\n\t\texit 0\n\tfi\n\tif [ $free_space -lt $req_free_space ]; then\n\t\tmsg \"$UNITTEST_NAME: SKIP: not enough free space ($1 required)\"\n\t\texit 0\n\tfi\n}\n\n#\n# require_max_devdax_size -- checks that dev dax is smaller than requested\n#\n# usage: require_max_devdax_size <dev-dax-num> <max-size>\n#\nfunction require_max_devdax_size() {\n\tcur_sz=$(get_devdax_size 0)\n\tmax_size=$2\n\tif [ $cur_sz -ge $max_size ]; then\n\t\tmsg \"$UNITTEST_NAME: SKIP: DevDAX $1 is too big for this test (max $2 required)\"\n\t\texit 0\n\tfi\n}\n\n#\n# require_max_block_size -- checks that block size is smaller or equal than requested\n#\n# usage: require_max_block_size <file> <max-block-size>\n#\nfunction require_max_block_size() {\n\tcur_sz=$(stat --file-system --format=%S $1)\n\tmax_size=$2\n\tif [ $cur_sz -gt $max_size ]; then\n\t\tmsg \"$UNITTEST_NAME: SKIP: block size of $1 is too big for this test (max $2 required)\"\n\t\texit 0\n\tfi\n}\n\n#\n# require_badblock_tests_enabled - check if tests for bad block support are not enabled\n# Input arguments:\n# 1) test device type\n#\nfunction require_badblock_tests_enabled() {\n\trequire_sudo_allowed\n\trequire_command ndctl\n\trequire_bb_enabled_by_default $PMEMPOOL$EXESUFFIX\n\n\tif [ \"$BADBLOCK_TEST_TYPE\" == \"nfit_test\" ]; then\n\n\t\trequire_kernel_module nfit_test\n\n\t\t# nfit_test dax device is created by the test and is\n\t\t# used directly - no device dax path is needed to be provided by the\n\t\t# user. Some tests though may use an additional filesystem for the\n\t\t# pool replica - hence 'any' filesystem is required.\n\t\tif [ $1 == \"dax_device\" ]; then\n\t\t\trequire_fs_type any\n\n\t\t# nfit_test block device is created by the test and mounted on\n\t\t# a filesystem of any type provided by the user\n\t\telif [ $1 == \"block_device\" ]; then\n\t\t\trequire_fs_type any\n\t\tfi\n\n\telif [ \"$BADBLOCK_TEST_TYPE\" == \"real_pmem\" ]; then\n\n\t\tif [ $1 == \"dax_device\" ]; then\n\t\t\trequire_fs_type any\n\t\t\trequire_dax_devices 1\n\t\t\trequire_binary $DAXIO$EXESUFFIX\n\n\t\telif [ $1 == \"block_device\" ]; then\n\t\t\trequire_fs_type pmem\n\t\tfi\n\n\telse\n\t\tmsg \"$UNITTEST_NAME: SKIP: bad block tests are not enabled in testconfig.sh\"\n\t\texit 0\n\tfi\n}\n\n#\n# require_badblock_tests_enabled_node - check if tests for bad block support are not enabled\n# on given remote node\n#\nfunction require_badblock_tests_enabled_node() {\n\trequire_sudo_allowed_node $1\n\trequire_command_node $1 ndctl\n\trequire_bb_enabled_by_default $PMEMPOOL$EXESUFFIX\n\n\tif [ \"$BADBLOCK_TEST_TYPE\" == \"nfit_test\" ]; then\n\t\trequire_kernel_module_node $1 nfit_test\n\telif [ \"$BADBLOCK_TEST_TYPE\" == \"real_pmem\" ]; then\n\t\t:\n\telse\n\t\tmsg \"$UNITTEST_NAME: SKIP: bad block tests are not enabled in testconfig.sh\"\n\t\texit 0\n\tfi\n\trequire_sudo_allowed\n\trequire_kernel_module nfit_test\n\trequire_command ndctl\n}\n\n#\n# create_recovery_file - create bad block recovery file\n#\n# Usage: create_recovery_file <file> [<offset_1> <length_1> ...]\n#\nfunction create_recovery_file() {\n\t[ $# -lt 1 ] && fatal \"create_recovery_file(): not enough parameters: $*\"\n\n\tFILE=$1\n\tshift\n\trm -f $FILE\n\n\twhile [ $# -ge 2 ]; do\n\t\tOFFSET=$1\n\t\tLENGTH=$2\n\t\tshift 2\n\t\techo \"$(($OFFSET * 512)) $(($LENGTH * 512))\" >> $FILE\n\tdone\n\n\t# write the finish flag\n\techo \"0 0\" >> $FILE\n}\n\n#\n# zero_blocks - zero blocks in a file\n#\n# Usage: zero_blocks <file> <offset> <length>\n#\nfunction zero_blocks() {\n\t[ $# -lt 3 ] && fatal \"zero_blocks(): not enough parameters: $*\"\n\n\tFILE=$1\n\tshift\n\n\twhile [ $# -ge 2 ]; do\n\t\tOFFSET=$1\n\t\tLENGTH=$2\n\t\tshift 2\n\t\tdd if=/dev/zero of=$FILE bs=512 seek=$OFFSET count=$LENGTH conv=notrunc status=none\n\tdone\n}\n\n#\n# turn_on_checking_bad_blocks -- set the compat_feature POOL_FEAT_CHECK_BAD_BLOCKS on\n#\nfunction turn_on_checking_bad_blocks()\n{\n\tFILE=$1\n\n\texpect_normal_exit \"$PMEMPOOL feature -e CHECK_BAD_BLOCKS $FILE &>> $PREP_LOG_FILE\"\n}\n\n#\n# turn_on_checking_bad_blocks_node -- set the compat_feature POOL_FEAT_CHECK_BAD_BLOCKS on\n#\nfunction turn_on_checking_bad_blocks_node()\n{\n\tFILE=$2\n\n\texpect_normal_exit run_on_node $1 \"../pmempool feature -e CHECK_BAD_BLOCKS $FILE &>> $PREP_LOG_FILE\"\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-pmdk-1.8-vkfgscx7enzm2hpgfrtndnbmwkp76kum/spack-src/src/test/unittest/valgrind.py": "#\n# Copyright 2019, Intel Corporation\n#\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions\n# are met:\n#\n#     * Redistributions of source code must retain the above copyright\n#       notice, this list of conditions and the following disclaimer.\n#\n#     * Redistributions in binary form must reproduce the above copyright\n#       notice, this list of conditions and the following disclaimer in\n#       the documentation and/or other materials provided with the\n#       distribution.\n#\n#     * Neither the name of the copyright holder nor the names of its\n#       contributors may be used to endorse or promote products derived\n#       from this software without specific prior written permission.\n#\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n# \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n# A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n# OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n# LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n# DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n# THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n#\n\"\"\"Valgrind handling tools\"\"\"\n\nimport sys\nimport re\nimport subprocess as sp\nfrom enum import Enum, unique\nfrom os import path\n\nimport futils\n\n\nDISABLE = -1\nENABLE = 1\nAUTO = 0\n\n_IGNORED = (\n    \"WARNING: Serious error when reading debug info\",\n    \"When reading debug info from \",\n    \"Ignoring non-Dwarf2/3/4 block in .debug_info\",\n    \"Last block truncated in .debug_info; ignoring\",\n    \"parse_CU_Header: is neither DWARF2 nor DWARF3 nor DWARF4\",\n    \"brk segment overflow\",\n    \"see section Limitations in user manual\",\n    \"Warning: set address range perms: large range\",\n    \"further instances of this message will not be shown\",\n    \"get_Form_contents: DW_FORM_GNU_strp_alt used, but no alternate .debug_str\"\n)\n\n\n@unique\nclass _Tool(Enum):\n    MEMCHECK = 1\n    PMEMCHECK = 2\n    HELGRIND = 3\n    DRD = 4\n    NONE = 5\n\n    def __str__(self):\n        return self.name.lower()\n\n\nTOOLS = tuple(t for t in _Tool if t != _Tool.NONE)\n\nMEMCHECK = _Tool.MEMCHECK\nPMEMCHECK = _Tool.PMEMCHECK\nHELGRIND = _Tool.HELGRIND\nDRD = _Tool.DRD\nNONE = _Tool.NONE\n\n\ndef enabled_tool(test):\n    \"\"\"Get Valgrind tool enabled by test\"\"\"\n    enabled = [t for t in TOOLS if getattr(test, t.name.lower()) == ENABLE]\n    if len(enabled) > 1:\n        raise ValueError('test \"{}\" enables more than one Valgrind tool'\n                         .format(test))\n    elif len(enabled) == 1:\n        return enabled[0]\n    else:\n        return None\n\n\ndef disabled_tools(test):\n    \"\"\"Get Valgrind tools disabled by test\"\"\"\n    disabled = [t for t in TOOLS if getattr(test, t.name.lower()) == DISABLE]\n    return disabled\n\n\nclass Valgrind:\n    \"\"\"Valgrind management\"\"\"\n\n    def __init__(self, tool, cwd, testnum, memcheck_check_leaks=True):\n        if sys.platform == 'win32':\n            raise NotImplementedError(\n                'Valgrind class should not be used on Windows')\n\n        self.tool = NONE if tool is None else tool\n        self.tool_name = self.tool.name.lower()\n        self.cwd = cwd\n\n        log_file_name = '{}{}.log'.format(self.tool.name.lower(), testnum)\n        self.log_file = path.join(cwd, log_file_name)\n\n        if tool is None:\n            self.valgrind_exe = None\n        else:\n            self.valgrind_exe = self._get_valgrind_exe()\n\n        if self.valgrind_exe is None:\n            return\n\n        self.opts = []\n        self.memcheck_check_leaks = memcheck_check_leaks\n\n        self.add_suppression('ld.supp')\n\n        if 'freebsd' in sys.platform:\n            self.add_suppression('freebsd.supp')\n\n        if tool == MEMCHECK:\n            self.add_suppression('memcheck-libunwind.supp')\n            self.add_suppression('memcheck-ndctl.supp')\n            self.add_suppression('memcheck-dlopen.supp')\n            if memcheck_check_leaks:\n                self.add_opt('--leak-check=full')\n\n        # Before Skylake, Intel CPUs did not have clflushopt instruction, so\n        # pmem_flush and pmem_persist both translated to clflush.\n        # This means that missing pmem_drain after pmem_flush could only be\n        # detected on Skylake+ CPUs.\n        # This option tells pmemcheck to expect fence (sfence or\n        # VALGRIND_PMC_DO_FENCE client request, used by pmem_drain) after\n        # clflush and makes pmemcheck output the same on pre-Skylake and\n        # post-Skylake CPUs.\n        elif tool == PMEMCHECK:\n            self.add_opt('--expect-fence-after-clflush=yes')\n\n        elif tool == HELGRIND:\n            self.add_suppression('helgrind-log.supp')\n\n        elif tool == DRD:\n            self.add_suppression('drd-log.supp')\n\n    def __str__(self):\n        return self.tool.name.lower()\n\n    def __bool__(self):\n        return self.tool != NONE\n\n    @property\n    def cmd(self):\n        \"\"\"Get Valgrind command with specified arguments\"\"\"\n        if self.tool == NONE:\n            return []\n\n        cmd = [self.valgrind_exe, '--tool={}'.format(self.tool_name),\n               '--log-file={}'.format(self.log_file)] + self.opts\n        return cmd\n\n    def _get_valgrind_exe(self):\n        \"\"\"\n        On some systems \"valgrind\" is a shell script that calls the actual\n        executable \"valgrind.bin\".\n        The wrapper script does not work well with LD_PRELOAD so we want\n        to call Valgrind directly\n        \"\"\"\n        try:\n            out = sp.check_output('which valgrind', shell=True,\n                                  universal_newlines=True)\n        except sp.CalledProcessError:\n            return None\n\n        valgrind_bin = path.join(path.dirname(out), 'valgrind.bin')\n        if path.isfile(valgrind_bin):\n            return valgrind_bin\n        return 'valgrind'\n\n    def add_opt(self, opt):\n        \"\"\"Add option to Valgrind command\"\"\"\n        self.opts.append(opt)\n\n    def _get_version(self):\n        \"\"\"\n        Get Valgrind version represented as integer with patch version ignored\n        \"\"\"\n        out = sp.check_output('{} --version'.format(self.valgrind_exe),\n                              shell=True, universal_newlines=True)\n        version = out.split('valgrind-')[1]\n        version_as_int = int(version.rsplit('.', 1)[0].replace('.', ''))\n        return version_as_int\n\n    def add_suppression(self, f):\n        \"\"\"\n        Add suppression file. Provided file path is\n        relative to tests root directory (pmdk/src/test)\n        \"\"\"\n        self.opts.append('--suppressions={}'\n                         .format(path.join(futils.ROOTDIR, f)))\n\n    def validate_log(self):\n        \"\"\"\n        Check Valgrind test result based on Valgrind log file.\n        Return True if passed, False otherwise\n        \"\"\"\n        if self.tool == NONE or sys.platform == 'win32':\n            return True\n\n        no_ignored = []\n        # remove ignored warnings from log file\n        with open(self.log_file, 'r+') as f:\n            no_ignored = [l for l in f if not any(w in l for w in _IGNORED)]\n            f.seek(0)\n            f.writelines(no_ignored)\n            f.truncate()\n\n        if path.isfile(self.log_file + '.match'):\n            # if there is a Valgrind log match file, do nothing - log file\n            # will be checked by 'match' tool\n            return True\n\n        non_zero_errors = 'ERROR SUMMARY: [^0]'\n        errors_found = any(re.search(non_zero_errors, l) for l in no_ignored)\n        if any('Bad pmempool' in l for l in no_ignored) or errors_found:\n            return False\n\n        return True\n\n    def verify(self):\n        \"\"\"\n        Checks that Valgrind can be used.\n        \"\"\"\n        if self.valgrind_exe is None:\n            raise futils.Skip('Valgrind not found')\n\n        # verify tool\n        cmd = '{} --tool={} --help'.format(self.valgrind_exe, self.tool_name)\n        try:\n            sp.check_output(cmd, shell=True, stderr=sp.STDOUT)\n        except sp.CalledProcessError:\n            raise futils.Skip(\"Valgrind tool '{}' was not found\"\n                              .format(self.tool_name))\n",
        "/tmp/vanessa/spack-stage/spack-stage-pmdk-1.8-vkfgscx7enzm2hpgfrtndnbmwkp76kum/spack-src/doc/librpmem/librpmem.7.md": "---\nlayout: manual\nContent-Style: 'text/css'\ntitle: _MP(LIBRPMEM, 7)\ncollection: librpmem\nheader: PMDK\ndate: rpmem API version 1.3\n...\n\n[comment]: <> (Copyright 2016-2019, Intel Corporation)\n\n[comment]: <> (Redistribution and use in source and binary forms, with or without)\n[comment]: <> (modification, are permitted provided that the following conditions)\n[comment]: <> (are met:)\n[comment]: <> (    * Redistributions of source code must retain the above copyright)\n[comment]: <> (      notice, this list of conditions and the following disclaimer.)\n[comment]: <> (    * Redistributions in binary form must reproduce the above copyright)\n[comment]: <> (      notice, this list of conditions and the following disclaimer in)\n[comment]: <> (      the documentation and/or other materials provided with the)\n[comment]: <> (      distribution.)\n[comment]: <> (    * Neither the name of the copyright holder nor the names of its)\n[comment]: <> (      contributors may be used to endorse or promote products derived)\n[comment]: <> (      from this software without specific prior written permission.)\n\n[comment]: <> (THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS)\n[comment]: <> (\"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT)\n[comment]: <> (LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR)\n[comment]: <> (A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT)\n[comment]: <> (OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,)\n[comment]: <> (SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT)\n[comment]: <> (LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,)\n[comment]: <> (DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY)\n[comment]: <> (THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT)\n[comment]: <> ((INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE)\n[comment]: <> (OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.)\n\n[comment]: <> (librpmem.7 -- man page for librpmem)\n\n[NAME](#name)<br />\n[SYNOPSIS](#synopsis)<br />\n[DESCRIPTION](#description)<br />\n[TARGET NODE ADDRESS FORMAT](#target-node-address-format)<br />\n[REMOTE POOL ATTRIBUTES](#remote-pool-attributes)<br />\n[SSH](#ssh)<br />\n[FORK](#fork)<br />\n[CAVEATS](#caveats)<br />\n[LIBRARY API VERSIONING](#library-api-versioning-1)<br />\n[ENVIRONMENT](#environment)<br />\n[DEBUGGING AND ERROR HANDLING](#debugging-and-error-handling)<br />\n[EXAMPLE](#example)<br />\n[ACKNOWLEDGEMENTS](#acknowledgements)<br />\n[SEE ALSO](#see-also)\n\n# NAME #\n\n**librpmem** - remote persistent memory support library (EXPERIMENTAL)\n\n# SYNOPSIS #\n\n```c\n#include <librpmem.h>\ncc ... -lrpmem\n```\n\n##### Library API versioning: #####\n\n```c\nconst char *rpmem_check_version(\n\tunsigned major_required,\n\tunsigned minor_required);\n```\n\n##### Error handling: #####\n\n```c\nconst char *rpmem_errormsg(void);\n```\n\n##### Other library functions: #####\n\nA description of other **librpmem** functions can be found on the following\nmanual pages:\n\n+ **rpmem_create**(3), **rpmem_persist**(3)\n\n# DESCRIPTION #\n\n**librpmem** provides low-level support for remote access to\n*persistent memory* (pmem) utilizing RDMA-capable RNICs. The library can be\nused to remotely replicate a memory region over the RDMA protocol. It utilizes\nan appropriate persistency mechanism based on the remote node's platform\ncapabilities. **librpmem** utilizes the **ssh**(1) client to authenticate\na user on the remote node, and for encryption of the connection's out-of-band\nconfiguration data. See **SSH**, below, for details.\n\nThe maximum replicated memory region size can not be bigger than the maximum\nlocked-in-memory address space limit. See **memlock** in **limits.conf**(5)\nfor more details.\n\nThis library is for applications that use remote persistent memory directly,\nwithout the help of any library-supplied transactions or memory\nallocation. Higher-level libraries that build on **libpmem**(7) are\navailable and are recommended for most applications, see:\n\n+ **libpmemobj**(7), a general use persistent memory API, providing memory\nallocation and transactional operations on variable-sized objects.\n\n# TARGET NODE ADDRESS FORMAT #\n\n```\n[<user>@]<hostname>[:<port>]\n```\n\nThe target node address is described by the *hostname* which the client\nconnects to, with an optional *user* name. The user must be authorized\nto authenticate to the remote machine without querying for password/passphrase.\nThe optional *port* number is used to establish the SSH connection. The default\nport number is 22.\n\n# REMOTE POOL ATTRIBUTES #\n\nThe *rpmem_pool_attr* structure describes a remote pool and is stored in remote\npool's metadata. This structure must be passed to the **rpmem_create**(3)\nfunction by caller when creating a pool on remote node. When opening the pool\nusing **rpmem_open**(3) function the appropriate fields are read from pool's\nmetadata and returned back to the caller.\n\n```c\n#define RPMEM_POOL_HDR_SIG_LEN    8\n#define RPMEM_POOL_HDR_UUID_LEN   16\n#define RPMEM_POOL_USER_FLAGS_LEN 16\n\nstruct rpmem_pool_attr {\n\tchar signature[RPMEM_POOL_HDR_SIG_LEN];\n\tuint32_t major;\n\tuint32_t compat_features;\n\tuint32_t incompat_features;\n\tuint32_t ro_compat_features;\n\tunsigned char poolset_uuid[RPMEM_POOL_HDR_UUID_LEN];\n\tunsigned char uuid[RPMEM_POOL_HDR_UUID_LEN];\n\tunsigned char next_uuid[RPMEM_POOL_HDR_UUID_LEN];\n\tunsigned char prev_uuid[RPMEM_POOL_HDR_UUID_LEN];\n\tunsigned char user_flags[RPMEM_POOL_USER_FLAGS_LEN];\n};\n```\n\nThe *signature* field is an 8-byte field which describes the pool's on-media\nformat.\n\nThe *major* field is a major version number of the pool's on-media format.\n\nThe *compat_features* field is a mask describing compatibility of pool's\non-media format optional features.\n\nThe *incompat_features* field is a mask describing compatibility of pool's\non-media format required features.\n\nThe *ro_compat_features* field is a mask describing compatibility of pool's\non-media format features. If these features are not available,\nthe pool shall be opened in read-only mode.\n\nThe *poolset_uuid* field is an UUID of the pool which the remote pool is\nassociated with.\n\nThe *uuid* field is an UUID of a first part of the remote pool. This field can\nbe used to connect the remote pool with other pools in a list.\n\nThe *next_uuid* and *prev_uuid* fields are UUIDs of next and previous replicas\nrespectively. These fields can be used to connect the remote pool with other\npools in a list.\n\nThe *user_flags* field is a 16-byte user-defined flags.\n\n# SSH #\n\n**librpmem** utilizes the **ssh**(1) client to login and execute the\n**rpmemd**(1) process on the remote node. By default, **ssh**(1)\nis executed with the **-4** option, which forces using **IPv4** addressing.\n\nFor debugging purposes, both the ssh client and the commands executed\non the remote node may be overridden by setting the **RPMEM_SSH** and\n**RPMEM_CMD** environment variables, respectively. See **ENVIRONMENT**\nfor details.\n\n# FORK #\nThe **ssh**(1) client is executed\nby **rpmem_open**(3) and **rpmem_create**(3) after forking a child process\nusing **fork**(2).  The application must take this into account when\nusing **wait**(2) and **waitpid**(2), which may return the *PID* of\nthe **ssh**(1) process executed by **librpmem**.\n\nIf **fork**(2) support is not enabled in **libibverbs**,\n**rpmem_open**(3) and **rpmem_create**(3) will fail.\nBy default, **fabric**(7) initializes **libibverbs** with **fork**(2) support\nby calling the **ibv_fork_init**(3) function. See **fi_verbs**(7) for more\ndetails.\n\n# CAVEATS #\n\n**librpmem** relies on the library destructor being called from the main thread.\nFor this reason, all functions that might trigger destruction (e.g.\n**dlclose**(3)) should be called in the main thread. Otherwise some of the\nresources associated with that thread might not be cleaned up properly.\n\n**librpmem** registers a pool as a single memory region. A Chelsio T4 and T5\nhardware can not handle a memory region greater than or equal to 8GB due to\na hardware bug. So *pool_size* value for **rpmem_create**(3) and **rpmem_open**(3)\nusing this hardware can not be greater than or equal to 8GB.\n\n# LIBRARY API VERSIONING #\n\nThis section describes how the library API is versioned,\nallowing applications to work with an evolving API.\n\nThe **rpmem_check_version**() function is used to see if the installed\n**librpmem** supports the version of the library API required by an\napplication. The easiest way to do this is for the application to supply\nthe compile-time version information, supplied by defines in\n**\\<librpmem.h\\>**, like this:\n\n```c\nreason = rpmem_check_version(RPMEM_MAJOR_VERSION,\n                             RPMEM_MINOR_VERSION);\nif (reason != NULL) {\n\t/* version check failed, reason string tells you why */\n}\n```\n\nAny mismatch in the major version number is considered a failure, but a\nlibrary with a newer minor version number will pass this check since\nincreasing minor versions imply backwards compatibility.\n\nAn application can also check specifically for the existence of an\ninterface by checking for the version where that interface was\nintroduced. These versions are documented in this man page as follows:\nunless otherwise specified, all interfaces described here are available\nin version 1.0 of the library. Interfaces added after version 1.0 will\ncontain the text *introduced in version x.y* in the section of this\nmanual describing the feature.\n\nWhen the version check performed by **rpmem_check_version**() is\nsuccessful, the return value is NULL. Otherwise the return value is a\nstatic string describing the reason for failing the version check. The\nstring returned by **rpmem_check_version**() must not be modified or\nfreed.\n\n# ENVIRONMENT #\n\n**librpmem** can change its default behavior based on the following\nenvironment variables. These are largely intended for testing and are\nnot normally required.\n\n+ **RPMEM_SSH**=*ssh_client*\n\nSetting this environment variable overrides the default **ssh**(1) client\ncommand name.\n\n+ **RPMEM_CMD**=*cmd*\n\nSetting this environment variable overrides the default command executed on\nthe remote node using either **ssh**(1) or the alternative remote shell command\nspecified by **RPMEM_SSH**.\n\n**RPMEM_CMD** can contain multiple commands separated by a vertical bar (`|`).\nEach consecutive command is executed on the remote node in order read from a\npool set file. This environment variable is read when the library is\ninitialized, so **RPMEM_CMD** must be set prior to application launch (or\nprior to **dlopen**(3) if **librpmem** is being dynamically loaded).\n\n+ **RPMEM_ENABLE_SOCKETS**=0\\|1\n\nSetting this variable to 1 enables using **fi_sockets**(7) provider for\nin-band RDMA connection. The *sockets* provider does not support IPv6.\nIt is required to disable IPv6 system wide if **RPMEM_ENABLE_SOCKETS** == 1 and\n*target* == localhost (or any other loopback interface address) and\n**SSH_CONNECTION** variable (see **ssh**(1) for more details) contains IPv6\naddress after ssh to loopback interface. By default the *sockets* provider is\ndisabled.\n\n* **RPMEM_ENABLE_VERBS**=0\\|1\n\nSetting this variable to 0 disables using **fi_verbs**(7) provider for\nin-band RDMA connection. The *verbs* provider is enabled by default.\n\n* **RPMEM_MAX_NLANES**=*num*\n\nLimit the maximum number of lanes to *num*. See **LANES**, in **rpmem_create**(3), for details.\n\n* **RPMEM_WORK_QUEUE_SIZE**=*size*\n\nSuggest the work queue size. The effective work queue size can be greater than\nsuggested if **librpmem** requires it or it can be smaller if underlying hardware\ndoes not support the suggested size. The work queue size affects the performance\nof communication to the remote node.\n**rpmem_flush**(3) operations can be added to the work queue up to the size of\nthis queue. When work queue is full any subsequent call has to wait till the work\nqueue will be drained. **rpmem_drain**(3) and **rpmem_persist**(3) among other\nthings also drain the work queue.\n\n# DEBUGGING AND ERROR HANDLING #\n\nIf an error is detected during the call to a **librpmem** function, the\napplication may retrieve an error message describing the reason for the failure\nfrom **rpmem_errormsg**(). This function returns a pointer to a static buffer\ncontaining the last error message logged for the current thread. If *errno*\nwas set, the error message may include a description of the corresponding\nerror code as returned by **strerror**(3). The error message buffer is\nthread-local; errors encountered in one thread do not affect its value in\nother threads. The buffer is never cleared by any library function; its\ncontent is significant only when the return value of the immediately preceding\ncall to a **librpmem** function indicated an error, or if *errno* was set.\nThe application must not modify or free the error message string, but it may\nbe modified by subsequent calls to other library functions.\n\nTwo versions of **librpmem** are typically available on a development\nsystem. The normal version, accessed when a program is linked using the\n**-lrpmem** option, is optimized for performance. That version skips checks\nthat impact performance and never logs any trace information or performs any\nrun-time assertions.\n\nA second version of **librpmem**, accessed when a program uses the libraries\nunder _DEBUGLIBPATH(), contains run-time assertions and trace points. The\ntypical way to access the debug version is to set the environment variable\n**LD_LIBRARY_PATH** to _LDLIBPATH(). Debugging output is\ncontrolled using the following environment variables. These variables have\nno effect on the non-debug version of the library.\n\n+ **RPMEM_LOG_LEVEL**\n\nThe value of **RPMEM_LOG_LEVEL** enables trace points in the debug version\nof the library, as follows:\n\n+ **0** - This is the default level when **RPMEM_LOG_LEVEL** is not set.\nNo log messages are emitted at this level.\n\n+ **1** - Additional details on any errors detected are logged\n(in addition to returning the *errno*-based errors as usual).\nThe same information may be retrieved using **rpmem_errormsg**().\n\n+ **2** - A trace of basic operations is logged.\n\n+ **3** - Enables a very verbose amount of function call\ntracing in the library.\n\n+ **4** - Enables voluminous and fairly obscure tracing information\nthat is likely only useful to the **librpmem** developers.\n\nUnless **RPMEM_LOG_FILE** is set, debugging output is written to *stderr*.\n\n+ **RPMEM_LOG_FILE**\n\nSpecifies the name of a file where all logging information should be written.\nIf the last character in the name is \"-\", the *PID* of the current process will\nbe appended to the file name when the log file is created. If\n**RPMEM_LOG_FILE** is not set, logging output is written to *stderr*.\n\n# EXAMPLE #\n\nThe following example uses **librpmem** to create a remote pool on given\ntarget node identified by given pool set name. The associated local memory\npool is zeroed and the data is made persistent on remote node. Upon success\nthe remote pool is closed.\n\n```c\n#include <assert.h>\n#include <unistd.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n\n#include <librpmem.h>\n\n#define POOL_SIGNATURE\t\"MANPAGE\"\n#define POOL_SIZE\t(32 * 1024 * 1024)\n#define NLANES\t\t4\n\n#define DATA_OFF\t4096\n#define DATA_SIZE\t(POOL_SIZE - DATA_OFF)\n\nstatic void\nparse_args(int argc, char *argv[], const char **target, const char **poolset)\n{\n\tif (argc < 3) {\n\t\tfprintf(stderr, \"usage:\\t%s <target> <poolset>\\n\", argv[0]);\n\t\texit(1);\n\t}\n\n\t*target = argv[1];\n\t*poolset = argv[2];\n}\n\nstatic void *\nalloc_memory()\n{\n\tlong pagesize = sysconf(_SC_PAGESIZE);\n\tif (pagesize < 0) {\n\t\tperror(\"sysconf\");\n\t\texit(1);\n\t}\n\n\t/* allocate a page size aligned local memory pool */\n\tvoid *mem;\n\tint ret = posix_memalign(&mem, pagesize, POOL_SIZE);\n\tif (ret) {\n\t\tfprintf(stderr, \"posix_memalign: %s\\n\", strerror(ret));\n\t\texit(1);\n\t}\n\n\tassert(mem != NULL);\n\n\treturn mem;\n}\n\nint\nmain(int argc, char *argv[])\n{\n\tconst char *target, *poolset;\n\tparse_args(argc, argv, &target, &poolset);\n\n\tunsigned nlanes = NLANES;\n\tvoid *pool = alloc_memory();\n\tint ret;\n\n\t/* fill pool_attributes */\n\tstruct rpmem_pool_attr pool_attr;\n\tmemset(&pool_attr, 0, sizeof(pool_attr));\n\tstrncpy(pool_attr.signature, POOL_SIGNATURE, RPMEM_POOL_HDR_SIG_LEN);\n\n\t/* create a remote pool */\n\tRPMEMpool *rpp = rpmem_create(target, poolset, pool, POOL_SIZE,\n\t\t\t&nlanes, &pool_attr);\n\tif (!rpp) {\n\t\tfprintf(stderr, \"rpmem_create: %s\\n\", rpmem_errormsg());\n\t\treturn 1;\n\t}\n\n\t/* store data on local pool */\n\tmemset(pool, 0, POOL_SIZE);\n\n\t/* make local data persistent on remote node */\n\tret = rpmem_persist(rpp, DATA_OFF, DATA_SIZE, 0, 0);\n\tif (ret) {\n\t\tfprintf(stderr, \"rpmem_persist: %s\\n\", rpmem_errormsg());\n\t\treturn 1;\n\t}\n\n\t/* close the remote pool */\n\tret = rpmem_close(rpp);\n\tif (ret) {\n\t\tfprintf(stderr, \"rpmem_close: %s\\n\", rpmem_errormsg());\n\t\treturn 1;\n\t}\n\n\tfree(pool);\n\n\treturn 0;\n}\n```\n\n# NOTE #\n\nThe **librpmem** API is experimental and may be subject to change in the future.\nHowever, using the remote replication in **libpmemobj**(7) is safe and backward\ncompatibility will be preserved.\n\n# ACKNOWLEDGEMENTS #\n\n**librpmem** builds on the persistent memory programming model\nrecommended by the SNIA NVM Programming Technical Work Group:\n<https://snia.org/nvmp>\n\n# SEE ALSO #\n\n**rpmemd**(1), **ssh**(1), **fork**(2), **dlclose**(3), **dlopen**(3),\n**ibv_fork_init**(3), **rpmem_create**(3), **rpmem_drain**(3), **rpmem_flush**(3),\n**rpmem_open**(3), **rpmem_persist**(3), **strerror**(3), **limits.conf**(5),\n**fabric**(7), **fi_sockets**(7), **fi_verbs**(7), **libpmem**(7), **libpmemblk**(7),\n**libpmemlog**(7), **libpmemobj**(7)\nand **<https://pmem.io>**\n"
    },
    "skipped": [
        "/tmp/vanessa/spack-stage/spack-stage-pmdk-1.8-vkfgscx7enzm2hpgfrtndnbmwkp76kum/spack-src/src/test/util_poolset/grep5w.log.match",
        "/tmp/vanessa/spack-stage/spack-stage-pmdk-1.8-vkfgscx7enzm2hpgfrtndnbmwkp76kum/spack-src/src/test/util_poolset/grep4w.log.match",
        "/tmp/vanessa/spack-stage/spack-stage-pmdk-1.8-vkfgscx7enzm2hpgfrtndnbmwkp76kum/spack-src/src/test/util_poolset/grep6w.log.match",
        "/tmp/vanessa/spack-stage/spack-stage-pmdk-1.8-vkfgscx7enzm2hpgfrtndnbmwkp76kum/spack-src/src/tools/pmempool/pmempool.rc",
        "/tmp/vanessa/spack-stage/spack-stage-pmdk-1.8-vkfgscx7enzm2hpgfrtndnbmwkp76kum/spack-src/res/PMDK.ico"
    ],
    "total_files": 3747
}