{
    "matches": {
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/configure.ac": "## Process this file with autoconf to produce configure.\n##\n## Copyright by The HDF Group.\n## Copyright by the Board of Trustees of the University of Illinois.\n## All rights reserved.\n##\n## This file is part of HDF5.  The full HDF5 copyright notice, including\n## terms governing use, modification, and redistribution, is contained in\n## the COPYING file, which can be found at the root of the source code\n## distribution tree, or in https://support.hdfgroup.org/ftp/HDF5/releases.\n## If you do not have access to either file, you may request a copy from\n## help@hdfgroup.org.\n\n## ----------------------------------------------------------------------\n## Initialize configure.\n##\nAC_REVISION($Id: configure.ac 22697 2012-08-19 14:35:47Z hdftest $)\nAC_PREREQ([2.69])\n\n## AC_INIT takes the name of the package, the version number, and an\n## email address to report bugs. AC_CONFIG_SRCDIR takes a unique file\n## as its argument.\n##\n## NOTE: Do not forget to change the version number here when we do a\n## release!!!\n##\nAC_INIT([HDF5], [1.13.0], [help@hdfgroup.org])\n\nAC_CONFIG_SRCDIR([src/H5.c])\nAC_CONFIG_HEADERS([src/H5config.h])\n\nAC_CONFIG_AUX_DIR([bin])\nAC_CONFIG_MACRO_DIR([m4])\n\n## AM_INIT_AUTOMAKE takes a list of options that should be applied to\n## every Makefile.am when automake is run.\nAM_INIT_AUTOMAKE([foreign subdir-objects])\nm4_ifdef([AM_SILENT_RULES], [AM_SILENT_RULES([yes])]) # use silent rules where available - automake 1.11\n\n## AM_MAINTAINER_MODE turns off \"rebuild rules\" that contain dependencies\n## for Makefiles, configure, src/H5config.h, etc. If AM_MAINTAINER_MODE\n## is enabled, these files will be rebuilt if out of date. This is a\n## problem because if users try to build on a machine with\n## the wrong versions of autoconf and automake, these files will be\n## rebuilt with the wrong versions and bad things can happen.\n## Also, CVS doesn't preserve dependencies between timestamps, so\n## Makefiles will often think rebuilding needs to occur when it doesn't.\n##\n## By default, it is enabled. Users can configure with\n## --disable-maintainer-mode to prevent running the autotools.\nAM_MAINTAINER_MODE([disable])\n\n## ----------------------------------------------------------------------\n## Set prefix default (install directory) to a directory in the build area.\n## This allows multiple src-dir builds within one host.\nAC_PREFIX_DEFAULT([`pwd`/hdf5])\n\n## Run post processing on files created by configure.\n## src/H5pubconf.h:\n## Generate src/H5pubconf.h from src/H5config.h by prepending H5_ to all\n## macro names. This avoid name conflict between HDF5 macro names and those\n## generated by another software package that uses the HDF5 library.\n## src/libhdf5.settings:\n## Remove all lines begun with \"#\" which are generated by CONDITIONAL's of\n## configure.\nAC_CONFIG_COMMANDS([pubconf], [\n  echo \"creating src/H5pubconf.h\"\n  sed 's/#define /#define H5_/' <src/H5config.h |\\\n    sed 's/#undef /#undef H5_/' >pubconf\n  if test ! -f src/H5pubconf.h; then\n    /bin/mv -f pubconf src/H5pubconf.h\n  elif (diff pubconf src/H5pubconf.h >/dev/null); then\n    rm -f pubconf\n    echo \"src/H5pubconf.h is unchanged\"\n  else\n    /bin/mv -f pubconf src/H5pubconf.h\n  fi\n  echo \"Post process src/libhdf5.settings\"\n  sed '/^#/d' < src/libhdf5.settings > libhdf5.settings.TMP\n  cp libhdf5.settings.TMP src/libhdf5.settings\n  rm -f libhdf5.settings.TMP\n])\n\n## It's possible to configure for a host other than the one on which\n## configure is currently running by using the --host=foo flag.\n## For machines on which HDF5 is often configured, it can be convenient\n## to specify the name of the machine rather than its canonical type.\n##\n## There are currently no hosts, but if there were they would be\n## listed by hostname and the alias would point to a file in\n## the config directory:\n##\n##case $host_alias in\n##  <some host>)\n##    host_alias=<config file in config directory>\n##    ;;\n##esac\n\nAC_CANONICAL_HOST\nAC_SUBST([CPPFLAGS])\nAC_SUBST([JNIFLAGS])\nAC_SUBST([AR_FLAGS])\n\n## H5_CFLAGS (and company) are for CFLAGS that should be used on HDF5, but\n## not exported to h5cc (or h5fc, etc.)\n##\n## H5_ECFLAGS (and company) are for warnings that should be treated as errors.\n##\nAC_SUBST([H5_CFLAGS])\nAC_SUBST([H5_ECFLAGS])\nAC_SUBST([H5_CPPFLAGS])\nAC_SUBST([H5_FCFLAGS])\nAC_SUBST([H5_CXXFLAGS])\nAC_SUBST([H5_ECXXFLAGS])\nAC_SUBST([H5_JNIFLAGS])\nAC_SUBST([H5_JAVACFLAGS])\nAC_SUBST([H5_JAVAFLAGS])\nAC_SUBST([H5_LDFLAGS])\n\n## AM_CFLAGS (and company) are for CFLAGS that should be used on HDF5,\n## and WILL be exported to h5cc (or h5fc, etc) if set by configure.\nAC_SUBST([AM_CFLAGS])\nAC_SUBST([AM_FCFLAGS])\nAC_SUBST([AM_CXXFLAGS])\nAC_SUBST([AM_CPPFLAGS])\nAC_SUBST([AM_JNIFLAGS])\nAC_SUBST([AM_JAVACFLAGS])\nAC_SUBST([AM_JAVAFLAGS])\nAC_SUBST([AM_LDFLAGS])\n\n## Make sure flags are initialized.\nAM_CFLAGS=\"${AM_CFLAGS}\"\nAM_CXXFLAGS=\"${AM_CXXFLAGS}\"\nAM_FCFLAGS=\"${AM_FCFLAGS}\"\nAM_CPPFLAGS=\"${AM_CPPFLAGS}\"\nAM_JNIFLAGS=\"${AM_JNIFLAGS}\"\nAM_JAVACFLAGS=\"${AM_JAVACFLAGS}\"\nAM_JAVAFLAGS=\"${AM_JAVAFLAGS}\"\nAM_LDFLAGS=\"${AM_LDFLAGS}\"\nCFLAGS=\"${CFLAGS}\"\nCXXFLAGS=\"${CXXFLAGS}\"\nFCFLAGS=\"${FCFLAGS}\"\nCPPFLAGS=\"${CPPFLAGS}\"\nJNIFLAGS=\"${JNIFLAGS}\"\nJAVACFLAGS=\"${JAVACFLAGS}\"\nJAVAFLAGS=\"${JAVAFLAGS}\"\nLDFLAGS=\"${LDFLAGS}\"\nAR_FLAGS=\"${AR_FLAGS}\"\n\n## Configure may need to alter any of the *FLAGS variables in order for\n## various checks to work correctly. Save the user's value here so it\n## can be restored once all configure checks are complete.\nsaved_user_CFLAGS=\"$CFLAGS\"\nsaved_user_CXXFLAGS=\"$CXXFLAGS\"\nsaved_user_FCFLAGS=\"$FCFLAGS\"\nsaved_user_JAVACFLAGS=\"$JAVACFLAGS\"\nsaved_user_JAVAFLAGS=\"$JAVAFLAGS\"\nsaved_user_LDFLAGS=\"$LDFLAGS\"\nsaved_user_CPPFLAGS=\"$CPPFLAGS\"\n\n## Support F9X variable to define Fortran compiler if FC variable is\n## not used.  This should be deprecated in the future.\nif test \"x\" = \"x$FC\"; then\n  FC=${F9X}\nfi\n\n## ----------------------------------------------------------------------\n## Dump all shell variables values.\n##\nAC_MSG_CHECKING([shell variables initial values])\nset >&AS_MESSAGE_LOG_FD\nAC_MSG_RESULT([done])\n\n## ----------------------------------------------------------------------\n## Save system information for the library settings file.\n##\nAC_SUBST([UNAME_INFO])\nUNAME_INFO=`uname -a`\n\n## ----------------------------------------------------------------------\n## Some platforms have broken basename, and/or xargs programs. Check\n## that it actually does what it's supposed to do. Catch this early\n## since configure and scripts relies upon them heavily and there's\n## no use continuing if it's broken.\n##\nAC_MSG_CHECKING([if basename works])\nBASENAME_TEST=\"`basename /foo/bar/baz/qux/basename_works`\"\nif test $BASENAME_TEST != \"basename_works\"; then\n  AC_MSG_ERROR([basename program doesn't work])\nelse\n  AC_MSG_RESULT([yes])\nfi\n\n## xargs basename used in configure to get the CC_BASENAME value\nAC_MSG_CHECKING([if xargs works])\nXARGS_TEST=\"`echo /foo/bar/baz/qux/xargs_works | xargs basename`\"\nif test $XARGS_TEST != \"xargs_works\"; then\n  AC_MSG_ERROR([xargs program doesn't work])\nelse\n  AC_MSG_RESULT([yes])\nfi\n\n## ----------------------------------------------------------------------\n## Check that the cache file was build on the same host as what we're\n## running on now.\n##\nAC_CACHE_CHECK([for cached host], [hdf5_cv_host], [hdf5_cv_host=\"none\"]);\nif test $hdf5_cv_host = \"none\"; then\n  hdf5_cv_host=$host\nelif test $hdf5_cv_host != $host; then\n  echo \"The config.cache file was generated on $hdf5_cv_host but\"\n  echo \"this is $host.  Please remove that file and try again.\"\n  AC_MSG_ERROR([config.cache file is invalid])\nfi\n\n## ----------------------------------------------------------------------\n## Source any special files that we need.  These files normally aren't\n## present but can be used by the maintainers to fine tune things like\n## turning on debug or profiling flags for the compiler.  The search order\n## is:\n##\n##    CPU-VENDOR-OS\n##    VENDOR-OS\n##    CPU-OS\n##    CPU-VENDOR\n##    OS\n##    VENDOR\n##    CPU\n##\n## If the `OS' ends with a version number then remove it. For instance,\n## `freebsd3.1' would become `freebsd'\n\ncase $host_os in\n  aix*)\n    host_os_novers=aix\n    ;;\n  freebsd*)\n    host_os_novers=freebsd\n    ;;\n  netbsd*)\n    host_os_novers=netbsd\n    ;;\n  solaris*)\n    host_os_novers=solaris\n    ;;\n  *)\n    host_os_novers=$host_os\n    ;;\nesac\n\nhost_config=\"none\"\nfor f in $host_cpu-$host_vendor-$host_os \\\n         $host_cpu-$host_vendor-$host_os_novers \\\n         $host_vendor-$host_os \\\n         $host_vendor-$host_os_novers \\\n         $host_cpu-$host_os \\\n         $host_cpu-$host_os_novers \\\n         $host_cpu-$host_vendor \\\n         $host_os \\\n         $host_os_novers \\\n         $host_vendor \\\n         $host_cpu ; do\n  AC_MSG_CHECKING([for config $f])\n  if test -f \"$srcdir/config/$f\"; then\n    host_config=$srcdir/config/$f\n    AC_MSG_RESULT([found])\n    break\n  fi\n  AC_MSG_RESULT([no])\ndone\nif test \"X$host_config\" != \"Xnone\"; then\n  CC_BASENAME=\"`echo $CC | cut -f1 -d' ' | xargs basename 2>/dev/null`\"\n  . $host_config\nfi\n\n## Source any special site-specific file\nhname=\"`hostname`\"\nwhile test -n \"$hname\"; do\n  file=$srcdir/config/site-specific/host-$hname\n  AC_MSG_CHECKING([for config $file])\n  if test -f \"$file\"; then\n    . $file\n    AC_MSG_RESULT([found])\n    break\n  fi\n  AC_MSG_RESULT([no])\n  hname_tmp=$hname\n  hname=\"`echo $hname | cut -d. -f2-99`\"\n  test \"$hname_tmp\" = \"$hname\" && break\ndone\n\n##\n## Enable/disable sanitizer checks for clang compilers, initially address sanitizer\n##\nAC_MSG_CHECKING([for clang sanitizer checks])\nAC_ARG_ENABLE([sanitize-checks],\n              [AS_HELP_STRING([--enable-sanitize-checks=address],\n                              [(clang/clang++ compilers only) Enable sanitize checks.\n                               Address is useful for detecting issues dealing with \n                               memory. See AddressSanitizer in config/sanitizer/README.md\n                               for more information.\n                               [default=none]\n                               ])],\n              [CLANG_SANITIZE_CHECKS=$enableval])\n\n# Set default\nif test \"X-$CLANG_SANITIZE_CHECKS\" = X- ; then\n  CLANG_SANITIZE_CHECKS=none\nfi\n\nif test \"X$CC_BASENAME\" = \"Xclang\"; then\n  AC_SUBST([CLANG_SANITIZE_CHECKS])\n\n  # There are several sanitizer tools.  At present we are testing \n  # and describing only -fsanitizer=address with autotools.\n  case \"X-$CLANG_SANITIZE_CHECKS\" in\n    X-no|X-none)\n      CLANG_SANITIZE_CHECKS=none\n      CLANG_SANITIZE_LIST=\n      ;;\n    *)\n      CLANG_SANITIZE_LIST=$CLANG_SANITIZE_CHECKS\n      ;;\n  esac\n  AC_MSG_RESULT([$CLANG_SANITIZE_CHECKS])\n\n  # Other tools can be added to the list of checks\n  # The clang compiler doesn't support some of them; they should be\n  # checked before adding them to the list in the help message.\n  # The sanitizers/sanitizers.cmake file lists these options:\n  # address, memory, memoryWithOrigins, undefined, thread, leak, \n  # 'address;undefined'.  Which and which combinations of these are \n  #  supported varies by compiler version, but unsupported options\n  # or combinations will result in configure errors reported in config.log.\n  # Comma separated lists of sanitize options wil be entered intact in\n  # one -fsanitize=<list> flag.  Space separated lists will be entered in\n  # separate -fsanitize=<item> flags.\n  # NOTE: No sanity checking done here!\n  if test -n \"$CLANG_SANITIZE_LIST\"; then\n    H5_CFLAGS=\"$H5_CFLAGS -fno-omit-frame-pointer\"\n    H5_CXXFLAGS=\"$H5_CXXFLAGS -fno-omit-frame-pointer\"\n    for sanitizer in `echo $CLANG_SANITIZE_LIST`; do\n      H5_CFLAGS=\"$H5_CFLAGS -fsanitize=${sanitizer}\"\n      H5_CXXFLAGS=\"$H5_CXXFLAGS -fsanitize=${sanitizer}\"\n    done\n  fi\nfi\n\n## ----------------------------------------------------------------------\n## Determine build mode (debug, production, clean).\n## This has to be done early since the build mode is referred to\n## frequently.\n##\nAC_MSG_CHECKING([build mode])\nAC_ARG_ENABLE([build-mode],\n              [AS_HELP_STRING([--enable-build-mode=(debug|production|clean)],\n                              [Sets the build mode. Debug turns on symbols, API\n                               tracing, asserts, and debug optimization,\n                               as well as several other minor configure options\n                               that aid in debugging.\n                               Production turns high optimizations on.\n                               Clean turns nothing on and disables optimization\n                               (i.e.: a 'clean slate' configuration).\n                               All these settings can be overridden by using\n                               specific configure flags.\n                               [default=debug]\n                               ])],\n              [BUILD_MODE=$enableval])\n\n## Set the default\n## Depends on branch, set via script at branch creation time\nif test \"X-$BUILD_MODE\" = X- ; then\n    BUILD_MODE=debug\nfi\n\n## Allow this variable to be substituted in\n## other files (src/libhdf5.settings.in, etc.)\nAC_SUBST([BUILD_MODE])\n\ncase \"X-$BUILD_MODE\" in\n  X-clean)\n    AC_MSG_RESULT([clean])\n    ;;\n  X-debug)\n    AC_DEFINE([DEBUG_BUILD], [1], [Define if this is a debug build.])\n    H5_CFLAGS=\"$H5_CFLAGS $DEBUG_CFLAGS\"\n    H5_CPPFLAGS=\"$H5_CPPFLAGS $DEBUG_CPPFLAGS\"\n    H5_CXXFLAGS=\"$H5_CXXFLAGS $DEBUG_CXXFLAGS\"\n    H5_FCFLAGS=\"$H5_FCFLAGS $DEBUG_FCFLAGS\"\n    AC_MSG_RESULT([debug])\n    ;;\n  X-production)\n    H5_CFLAGS=\"$H5_CFLAGS $PROD_CFLAGS\"\n    H5_CPPFLAGS=\"$H5_CPPFLAGS $PROD_CPPFLAGS\"\n    H5_CXXFLAGS=\"$H5_CXXFLAGS $PROD_CXXFLAGS\"\n    H5_FCFLAGS=\"$H5_FCFLAGS $PROD_FCFLAGS\"\n    AC_MSG_RESULT([production])\n    ;;\n  *)\n    AC_MSG_ERROR([Unrecognized build mode: $BUILD_MODE. Use debug, production, or clean.])\nesac\n\n## ----------------------------------------------------------------------\n## Some built-in configure checks can only see CFLAGS (not AM_CFLAGS), so\n## we need to add this in so configure works as intended. We will need to\n## reset this value at the end of configure, to preserve the user's settings.\nCFLAGS=\"${AM_CFLAGS} ${CFLAGS}\"\nFCFLAGS=\"${AM_FCFLAGS} ${FCFLAGS}\"\nJAVACFLAGS=\"${AM_JAVACFLAGS} ${JAVACFLAGS}\"\nJAVAFLAGS=\"${AM_JAVAFLAGS} ${JAVAFLAGS}\"\nCXXFLAGS=\"${AM_CXXFLAGS} ${CXXFLAGS}\"\nCPPFLAGS=\"${AM_CPPFLAGS} ${CPPFLAGS}\"\nLDFLAGS=\"${AM_LDFLAGS} ${LDFLAGS}\"\n\n## ----------------------------------------------------------------------\n## Enable dependency tracking unless the configure options or a\n## site-specific file told us not to.  This prevents configure from\n## silently disabling dependencies for some compilers.\n##\nif test -z \"${enable_dependency_tracking}\"; then\n  enable_dependency_tracking=\"yes\"\nfi\n\n## ----------------------------------------------------------------------\n## Check for programs.\n##\nAC_PROG_CC\nCC_BASENAME=\"`echo $CC | cut -f1 -d' ' | xargs basename 2>/dev/null`\"\n\n## ----------------------------------------------------------------------------\n## Configure disallows unsupported combinations of options. However, users\n## may want to override and build with unsupported combinations for their\n## own use. They can use the --enable-unsupported configure flag, which\n## ignores any errors from configure due to incompatible flags.\nAC_MSG_CHECKING([if unsupported combinations of configure options are allowed])\nAC_ARG_ENABLE([unsupported],\n              [AS_HELP_STRING([--enable-unsupported],\n                              [Allow unsupported combinations of configure options])],\n              [ALLOW_UNSUPPORTED=$enableval])\n\ncase \"X-$ALLOW_UNSUPPORTED\" in\n  X-|X-no)\n    AC_MSG_RESULT([no])\n    ;;\n  X-yes)\n    AC_MSG_RESULT([yes])\n    ;;\n  *)\n    ;;\nesac\n\n## ----------------------------------------------------------------------\n## Data types and their sizes.\n##\nAC_TYPE_OFF_T\nAC_CHECK_TYPE([size_t], [],\n        [AC_DEFINE_UNQUOTED([size_t], [unsigned long],\n                [Define to `unsigned long' if <sys/types.h> does not define.])])\nAC_CHECK_TYPE([ssize_t], [],\n        [AC_DEFINE_UNQUOTED([ssize_t], [long],\n                [Define to `long' if <sys/types.h> does not define.])])\nAC_CHECK_TYPE([ptrdiff_t], [],\n        [AC_DEFINE_UNQUOTED([ptrdiff_t], [long],\n                [Define to `long' if <sys/types.h> does not define.])])\nAC_C_BIGENDIAN\nAC_CHECK_SIZEOF([char])\nAC_CHECK_SIZEOF([short])\nAC_CHECK_SIZEOF([int])\nAC_CHECK_SIZEOF([unsigned])\nAC_CHECK_SIZEOF([long])\nAC_CHECK_SIZEOF([long long])\nAC_CHECK_SIZEOF([__int64])\nAC_CHECK_SIZEOF([float])\nAC_CHECK_SIZEOF([double])\nAC_CHECK_SIZEOF([long double])\n\n## ----------------------------------------------------------------------\n## Check for non-standard extension __FLOAT128\n##\nHAVE_FLOAT128=0\nHAVE_QUADMATH=0\nFLT128_DIG=0\nLDBL_DIG=0\n\nAC_CHECK_SIZEOF([__float128])\nAC_CHECK_SIZEOF([_Quad])\nAC_CHECK_HEADERS([quadmath.h], [HAVE_QUADMATH=1], [])\nPAC_FC_LDBL_DIG\n\nAC_SUBST([PAC_C_MAX_REAL_PRECISION])\n\nif test \"$ac_cv_sizeof___float128\" != 0 && test \"$FLT128_DIG\" != 0 ; then\n  AC_DEFINE([HAVE_FLOAT128], [1], [Determine if __float128 is available])\n  PAC_C_MAX_REAL_PRECISION=$FLT128_DIG\nelse\n  PAC_C_MAX_REAL_PRECISION=$LDBL_DIG\nfi\nAC_DEFINE_UNQUOTED([PAC_C_MAX_REAL_PRECISION], $PAC_C_MAX_REAL_PRECISION, [Determine the maximum decimal precision in C])\nAC_MSG_RESULT([$PAC_C_MAX_REAL_PRECISION])\n\n## ----------------------------------------------------------------------\n## Check if they would like the Fortran interface compiled\n##\n\n## This needs to be exposed for the library info file even if Fortran is disabled.\nAC_SUBST([HDF_FORTRAN])\n\n## Default is no Fortran\nHDF_FORTRAN=no\n\nAC_SUBST([HDF5_INTERFACES]) HDF5_INTERFACES=\"\"\nAC_MSG_CHECKING([if Fortran interface enabled])\nAC_ARG_ENABLE([fortran],\n              [AS_HELP_STRING([--enable-fortran],\n                              [Compile the Fortran interface [default=no]])],\n              [HDF_FORTRAN=$enableval])\n\nif test \"X$HDF_FORTRAN\" = \"Xyes\"; then\n  echo \"yes\"\nelse\n  echo \"no\"\nfi\n\nif test \"X$HDF_FORTRAN\" = \"Xyes\"; then\n\n## We will output an include file for Fortran, H5config_f.inc which\n## contains various configure definitions used by the Fortran Library.\n## Prepend H5_ to all macro names. This avoids name conflict between HDF5 macro\n## names and those generated by another software package that uses the HDF5 library.\n  AC_CONFIG_HEADERS([fortran/src/H5config_f.inc],\n    [cat fortran/src/H5config_f.inc | sed '1d;s%^/\\* \\(.*\\) \\*/%\\1%;s/#define /#define H5_/;s/#undef /#undef H5_/' >fortran/src/H5config_f.inc.tmp; mv -f fortran/src/H5config_f.inc.tmp fortran/src/H5config_f.inc])\n\n  AC_SUBST([FC])\n\n  HDF5_INTERFACES=\"$HDF5_INTERFACES fortran\"\n\n  ## --------------------------------------------------------------------\n  ## HDF5 integer variables for the H5fortran_types.f90 file.\n  ##\n  AC_SUBST([R_LARGE])\n  AC_SUBST([R_INTEGER])\n  AC_SUBST([HADDR_T])\n  AC_SUBST([HSIZE_T])\n  AC_SUBST([HSSIZE_T])\n  AC_SUBST([HID_T])\n  AC_SUBST([SIZE_T])\n  AC_SUBST([OBJECT_NAMELEN_DEFAULT_F])\n\n  ## --------------------------------------------------------------------\n  ## Fortran source extention\n  ##\n  AC_FC_SRCEXT([f90])\n\n  AC_SUBST([F9XSUFFIXFLAG])\n  AC_SUBST([FSEARCH_DIRS])\n\n  ## --------------------------------------------------------------------\n  ## Check for a Fortran compiler and how to include modules.\n  ##\n  AC_PROG_FC([PAC_FC_SEARCH_LIST],)\n  AC_F9X_MODS\n\n  ## Change to the Fortran 90 language\n  AC_LANG_PUSH(Fortran)\n\n  ## Checking if the compiler supports the required Fortran 2003 features and\n  ## stopping if it does not.\n  PAC_PROG_FC_HAVE_F2003_REQUIREMENTS\n\n  if test \"X$HAVE_F2003_REQUIREMENTS\" = \"Xno\"; then\n    AC_MSG_ERROR([Fortran compiler lacks required Fortran 2003 features; unsupported Fortran 2003 compiler, remove --enable-fortran])\n  fi\n\n  ## --------------------------------------------------------------------\n  ## Define wrappers for the C compiler to use Fortran function names\n  ##\n  AC_FC_WRAPPERS\n\n  ## --------------------------------------------------------------------\n  ## See if the fortran compiler supports the intrinsic function \"SIZEOF\"\n  PAC_PROG_FC_SIZEOF\n\n  ## See if the fortran compiler supports the intrinsic function \"C_SIZEOF\"\n  PAC_PROG_FC_C_SIZEOF\n\n  ## See if the fortran compiler supports the intrinsic function \"STORAGE_SIZE\"\n  PAC_PROG_FC_STORAGE_SIZE\n\n  ## Set the sizeof function for use later in the fortran tests\n  if test \"X$HAVE_STORAGE_SIZE_FORTRAN\" = \"Xyes\";then\n    FC_SIZEOF_A=\"STORAGE_SIZE(a, c_size_t)/STORAGE_SIZE(c_char_'a',c_size_t)\"\n    FC_SIZEOF_B=\"STORAGE_SIZE(b, c_size_t)/STORAGE_SIZE(c_char_'a',c_size_t)\"\n    FC_SIZEOF_C=\"STORAGE_SIZE(c, c_size_t)/STORAGE_SIZE(c_char_'a',c_size_t)\"\n  else\n    if test \"X$HAVE_SIZEOF_FORTRAN\" = \"Xyes\";then\n      FC_SIZEOF_A=\"SIZEOF(a)\"\n      FC_SIZEOF_B=\"SIZEOF(b)\"\n      FC_SIZEOF_C=\"SIZEOF(c)\"\n    else\n      ## If neither intrinsic functions SIZEOF or STORAGE_SIZE is available then stop configure with an error\n      AC_MSG_ERROR([Fortran compiler requires either intrinsic functions SIZEOF or STORAGE_SIZE])\n    fi\n  fi\n\n  ## See if the fortran compiler supports the intrinsic module \"ISO_FORTRAN_ENV\"\n  PAC_PROG_FC_ISO_FORTRAN_ENV\n  ## Check KIND and size of native integer\n  PAC_FC_NATIVE_INTEGER\n\n  ## Find all available KINDs\n  PAC_FC_AVAIL_KINDS\n  ## Find all sizeofs for available KINDs\n  PAC_FC_SIZEOF_INT_KINDS\n  PAC_FC_SIZEOF_REAL_KINDS\n\n  AC_SUBST([PAC_FC_ALL_REAL_KINDS])\n  AC_SUBST([PAC_FC_MAX_REAL_PRECISION])\n  AC_SUBST([PAC_FORTRAN_NUM_INTEGER_KINDS])\n  AC_SUBST([PAC_FC_ALL_INTEGER_KINDS])\n  AC_SUBST([PAC_FC_ALL_REAL_KINDS_SIZEOF])\n  AC_SUBST([PAC_FC_ALL_INTEGER_KINDS_SIZEOF])\n  AC_SUBST([PAC_FORTRAN_NATIVE_INTEGER_KIND])\n  AC_SUBST([PAC_FORTRAN_NATIVE_INTEGER_SIZEOF])\n  AC_SUBST([PAC_FORTRAN_NATIVE_REAL_KIND])\n  AC_SUBST([PAC_FORTRAN_NATIVE_REAL_SIZEOF])\n  AC_SUBST([PAC_FORTRAN_NATIVE_DOUBLE_KIND])\n  AC_SUBST([PAC_FORTRAN_NATIVE_DOUBLE_SIZEOF])\n  AC_SUBST([HAVE_Fortran_INTEGER_SIZEOF_16])\n  AC_SUBST([FORTRAN_HAVE_C_LONG_DOUBLE])\n  AC_SUBST([FORTRAN_C_LONG_DOUBLE_IS_UNIQUE])\n  AC_SUBST([H5CONFIG_F_NUM_RKIND])\n  AC_SUBST([H5CONFIG_F_RKIND])\n  AC_SUBST([H5CONFIG_F_RKIND_SIZEOF])\n  AC_SUBST([H5CONFIG_F_NUM_IKIND])\n  AC_SUBST([H5CONFIG_F_IKIND])\n  AC_SUBST([Fortran_COMPILER_ID])\n  Fortran_COMPILER_ID=none\n  AC_DEFINE_UNQUOTED([Fortran_COMPILER_ID], $Fortran_COMPILER_ID, [Define Fortran compiler ID])\n\n  ## Setting definition if there is a 16 byte fortran integer\n  if `echo $PAC_FC_ALL_INTEGER_KINDS_SIZEOF | grep '16' >/dev/null`; then\n    HAVE_Fortran_INTEGER_SIZEOF_16=\"1\"\n    AC_DEFINE([HAVE_Fortran_INTEGER_SIZEOF_16], [1], [Determine if INTEGER*16 is available])\n  else\n    HAVE_Fortran_INTEGER_SIZEOF_16=\"0\"\n    AC_DEFINE([HAVE_Fortran_INTEGER_SIZEOF_16], [0], [Determine if INTEGER*16 is available])\n  fi\n\n  if test \"X$HAVE_STORAGE_SIZE_FORTRAN\" = \"Xyes\"; then\n    AC_DEFINE([FORTRAN_HAVE_STORAGE_SIZE], [1], [Define if we have Fortran intrinsic STORAGE_SIZE])\n  fi\n\n  if test \"X$HAVE_C_SIZEOF_FORTRAN\" = \"Xyes\"; then\n    AC_DEFINE([FORTRAN_HAVE_C_SIZEOF], [1], [Define if we have Fortran intrinsic C_SIZEOF])\n  fi\n\n  if test \"X$HAVE_SIZEOF_FORTRAN\" = \"Xyes\"; then\n    AC_DEFINE([FORTRAN_HAVE_SIZEOF], [1], [Define if we have Fortran intrinsic SIZEOF])\n  fi\n\n  ## See if C_LONG_DOUBLE is available\n  PAC_PROG_FC_HAVE_C_LONG_DOUBLE\n\n  FORTRAN_HAVE_C_LONG_DOUBLE=\"0\"\n  if test \"X$HAVE_C_LONG_DOUBLE_FORTRAN\" = \"Xyes\"; then\n    FORTRAN_HAVE_C_LONG_DOUBLE=\"1\"\n    AC_DEFINE([FORTRAN_HAVE_C_LONG_DOUBLE], [1], [Define if we have Fortran C_LONG_DOUBLE])\n  fi\n\n  ## Is C_LONG_DOUBLE different from C_DOUBLE\n  FORTRAN_C_LONG_DOUBLE_IS_UNIQUE=\"0\"\n  if test \"$FORTRAN_HAVE_C_LONG_DOUBLE\" = \"1\"; then\n    PAC_PROG_FC_C_LONG_DOUBLE_EQ_C_DOUBLE\n    if test \"X$C_LONG_DOUBLE_IS_UNIQUE_FORTRAN\" = \"Xyes\"; then\n      FORTRAN_C_LONG_DOUBLE_IS_UNIQUE=\"1\"\n      AC_DEFINE([FORTRAN_C_LONG_DOUBLE_IS_UNIQUE], [1], [Define if Fortran C_LONG_DOUBLE is different from C_DOUBLE])\n    else\n      FORTRAN_C_LONG_DOUBLE_IS_UNIQUE=\"0\"\n    fi\n  fi\n\n  FORTRAN_SIZEOF_LONG_DOUBLE=${ac_cv_sizeof_long_double}\n  AC_DEFINE_UNQUOTED([FORTRAN_SIZEOF_LONG_DOUBLE], [\"${ac_cv_sizeof_long_double}\"], [Determine the size of C long double])\n\n  dnl get the largest sizeof for REAL kinds\n  max_real_fortran_sizeof=\"`echo $PAC_FC_ALL_REAL_KINDS_SIZEOF | sed -ne 's/.*,\\([[0-9]]*\\)}/\\1/p'`\"\n  max_real_fortran_kind=\"`echo $PAC_FC_ALL_REAL_KINDS | sed -ne 's/.*,\\([[0-9]]*\\)}/\\1/p'`\"\n\n  dnl remove the invalid kind from the list\n  if test \"$ac_cv_sizeof___float128\" != 0;then\n    if test \"$ac_cv_sizeof___float128\" != \"$max_real_fortran_sizeof\" &&\n       test \"${ac_cv_sizeof_long_double}\" != \"$max_real_fortran_sizeof\" &&\n       dnl account for the fact that the C compiler can have 16-byte __float128 and the Fortran compiler only has 8-byte doubles,\n       dnl so we don't want to remove the 8-byte Fortran doubles. This is sometimes the case if different C and Fortran vendors\n       dnl are used (for example gnu and pgi).\n       test \"${ac_cv_sizeof_double}\" != \"$max_real_fortran_sizeof\" ; then\n          AC_MSG_WARN([\n           Fortran REAL(KIND=$max_real_fortran_kind) is $max_real_fortran_sizeof Bytes, but no corresponding C float type exists of that size\n                     !!! Fortran interfaces will not be generated for REAL(KIND=$max_real_fortran_kind) !!!\n          ])\n      PAC_FC_ALL_REAL_KINDS=\"`echo $PAC_FC_ALL_REAL_KINDS | sed -e 's/,[[0-9]]\\+}/}/g'`\"\n      PAC_FC_ALL_REAL_KINDS_SIZEOF=\"`echo $PAC_FC_ALL_REAL_KINDS_SIZEOF | sed -e 's/,[[0-9]]\\+}/}/g'`\"\n\n    fi\n  fi\n  AC_MSG_CHECKING([for Fortran interoperable KINDS with C])\n  AC_MSG_RESULT([$PAC_FC_ALL_REAL_KINDS])\n\n  dnl count the number of real kinds\n  H5CONFIG_F_NUM_RKIND=\"INTEGER, PARAMETER :: num_rkinds = `echo \\\"[$]PAC_FC_ALL_REAL_KINDS\\\" |  tr -d -c ',\\n' | awk '{ print length + 1; }'`\"\n  H5CONFIG_F_RKIND=\"INTEGER, DIMENSION(1:num_rkinds) :: rkind = (/`echo $PAC_FC_ALL_REAL_KINDS | sed -e 's/{//g' | sed -e 's/}//g' | sed -e 's/ /,/g'`/)\"\n  H5CONFIG_F_RKIND_SIZEOF=\"INTEGER, DIMENSION(1:num_rkinds) :: rkind_sizeof = (/`echo $PAC_FC_ALL_REAL_KINDS_SIZEOF | sed -e 's/{//g' | sed -e 's/}//g'| sed -e 's/ /,/g'`/)\"\n\n  AC_DEFINE_UNQUOTED([H5CONFIG_F_NUM_RKIND], $H5CONFIG_F_NUM_RKIND, [Define number of valid Fortran REAL KINDs])\n  AC_DEFINE_UNQUOTED([H5CONFIG_F_RKIND], $H5CONFIG_F_RKIND, [Define valid Fortran REAL KINDs])\n  AC_DEFINE_UNQUOTED([H5CONFIG_F_RKIND_SIZEOF], $H5CONFIG_F_RKIND_SIZEOF, [Define valid Fortran REAL KINDs Sizeof])\n\n## Change back to the C language\n  AC_LANG_POP(Fortran)\nelse\n  FC=\"no\"\nfi\n\n## ----------------------------------------------------------------------\n## Check if they would like the C++ interface compiled\n##\n## This needs to be exposed for the library info file even if C++ is disabled.\nAC_SUBST([HDF_CXX])\n\n## Default is no C++\nHDF_CXX=no\n\n## We need to check for a C++ compiler unconditionally, since\n## AC_PROG_CXX defines some macros that Automake 1.9.x uses and will\n## miss even if c++ is not enabled.\nAC_PROG_CXX\nAC_PROG_CXXCPP    ## this is checked for when AC_HEADER_STDC is done\n\nAC_MSG_CHECKING([if c++ interface enabled])\n\nAC_ARG_ENABLE([cxx],\n              [AS_HELP_STRING([--enable-cxx],\n                              [Compile the C++ interface [default=no]])],\n              [HDF_CXX=$enableval])\n\nif test \"X$HDF_CXX\" = \"Xyes\"; then\n  echo \"yes\"\n  HDF5_INTERFACES=\"$HDF5_INTERFACES c++\"\n\n  ## Expose the compiler for *.in files\n  AC_SUBST([CXX])\n\n  ## Change to the C++ language\n  AC_LANG_PUSH(C++)\n\n  ## Checking if C++ needs old style header files in includes\n  PAC_PROG_CXX_HEADERS\n\n  ## Checking if C++ can handle namespaces\n  PAC_PROG_CXX_NAMESPACE\n\n  ## if C++ can handle static cast\n  PAC_PROG_CXX_STATIC_CAST\n\n  ## Checking if C++ has offsetof extension,\n  ## note: this test has to be the last of the C++ tests because it sets a definition\n  ## which would be used in the other tests, causing them to fail.\n  PAC_PROG_CXX_OFFSETOF\n\nelse\n  AC_MSG_RESULT([no])\n  CXX=\"no\"\nfi\n\n## Change back to the C language\nAC_LANG_POP(C++)\n\n\n## ----------------------------------------------------------------------\n## Check if they would like the High Level library  compiled\n##\n\n## This needs to be exposed for the library info file even if the HL\n## library is disabled.\nAC_SUBST([HDF5_HL])\n\n## The high-level library is enabled unless the build mode is clean.\nif test \"X-$BUILD_MODE\" = \"X-clean\" ; then\n  HDF5_HL=no\nelse\n  HDF5_HL=yes\nfi\n\n## high-level library directories (set when needed, blank until then)\n##\n## main high-level library\nAC_SUBST(HL)\nHL=\"\"\n## Fortran high-level library\nAC_SUBST(HL_FOR)\nHL_FOR=\"\"\n\nAC_MSG_CHECKING([if the high-level library is enabled])\nAC_ARG_ENABLE([hl],\n     [AS_HELP_STRING([--enable-hl],\n                     [Enable the high-level library.\n                     [default=yes (unless build mode = clean)]\n                     ])],\n     [HDF5_HL=$enableval])\n\nif test \"X-$HDF5_HL\" = \"X-yes\"; then\n AC_MSG_RESULT([yes])\n HL=\"hl\"\n AC_DEFINE([INCLUDE_HL], [1],\n           [Define if the high-level library headers should be included in hdf5.h])\nelse\n  AC_MSG_RESULT([no])\nfi\n\n\n## ----------------------------------------------------------------------\n## Check which archiving tool to use. This needs to be done before\n## the AM_PROG_LIBTOOL macro.\n##\nif test -z \"$AR\"; then\n  AC_CHECK_PROGS([AR], [ar xar], [:], [$PATH])\nfi\nAC_SUBST([AR])\n\n# Set the default ar flags to cr\n# The Automake default is to use cru and the 'u' causes ar\n# to emit warnings on some platforms.\nAR_FLAGS=cr\n\n\n## Export the AR macro so that it will be placed in the libtool file\n## correctly.\nexport AR\n\nAC_PROG_MAKE_SET\nAC_PROG_INSTALL\n\n\n## ----------------------------------------------------------------------\n## Set up ${TR} which is used to process the package list for extra\n## debugging output in the C library.\n\nAC_PATH_PROG([TR], [tr])\n\n\n## ----------------------------------------------------------------------\n## Check that time can be used with srcdir.  This is okay on most systems,\n## but seems to cause problems on Cygwin.\n## The solution on Cygwin is not to record execution time for tests.\n##\n## Note: This is still true as of Cygwin 1.7.32 (Aug 2014) on both 32-\n## and 64-bit platforms. Given how long this has been true, it seems\n## unlikely to change, but we should probably re-test this periodically.\n\nAC_MSG_CHECKING([if srcdir= and time commands work together])\n\nAC_SUBST([TIME])\nTIME=time\nTIME_TEST=`foo=\"bar\" ${TIME} echo 'baz' 2> /dev/null | grep baz`\n\nif test \"X${TIME_TEST}\" = \"Xbaz\"; then\n  AC_MSG_RESULT([yes])\nelse\n  AC_MSG_RESULT([no])\n  TIME=\nfi\n\n\n## The following variables are used to distinguish between building a\n## serial and parallel library.\n##\n##    HAVE_PARALLEL    -- defined in H5config.h if we are building\n##               a parallel library even if configure wasn't\n##               able to find some header file or library that\n##               might be required. This is defined if the\n##               user explicitly states\n##               that a parallel library is being built by supplying\n##               the `--enable-parallel' configure switch.\n##\n##    PARALLEL        -- This variable is set to a non-null value if\n##               we're building a parallel version of the library.\n##\n##    RUNSERIAL            -- This is a command which will be prepended to\n##               the executable name to run the executable using\n##               a single process. For serial versions of the\n##               library this will normally be empty. For parallel\n##               versions it might be something like `mpiexec -n 1'.\n##               The value of this variable is substituted in *.in\n##               files.\n##\n##    RUNPARALLEL    -- This is a command which will be prepended to\n##               the executable name to run the executable on\n##               multiple processors. For the serial library the\n##               value will normally be the empty string. For\n##               parallel library it should be something like\n##               \"mpiexec -n \\$\\${NPROCS:=6}\" where NPROCS will\n##               eventually contain the number of processors on which\n##               to run the executable (the double dollarsigns are to\n##               protect the expansion until make executes the\n##               command).  The value of this variable is\n##               substituted in *.in files.\n##\nAC_SUBST([PARALLEL])\nAC_SUBST([RUNSERIAL])\nAC_SUBST([RUNPARALLEL])\nAC_SUBST([TESTPARALLEL])\n\n## ----------------------------------------------------------------------\n## Check if they would like the Java native interface (JNI) compiled\n##\n\n## This needs to be exposed for the library info file even if Java is disabled.\nAC_SUBST([HDF_JAVA])\n\n## Default is no Java\nHDF_JAVA=no\n\nAC_SUBST([H5_CLASSPATH]) H5_CLASSPATH=\"\"\nAC_MSG_CHECKING([if Java JNI interface enabled])\n\nAC_ARG_ENABLE([java],\n              [AS_HELP_STRING([--enable-java],\n                              [Compile the Java JNI interface [default=no]])],\n              [HDF_JAVA=$enableval])\n\nif test \"X$HDF_JAVA\" = \"Xyes\"; then\n  if test \"X${enable_shared}\" != \"Xno\"; then\n    echo \"yes\"\n    if test \"X$CLASSPATH\" = \"X\"; then\n      H5_CLASSPATH=\".:$srcdir/java/lib\"\n    else\n      H5_CLASSPATH=\".:$CLASSPATH:$srcdir/java/lib\"\n    fi\n    ## Checks for programs.\n    AX_JAVA_OPTIONS\n    H5_JAVACFLAGS=$JAVACFLAGS\n    H5_JAVAFLAGS=$JAVAFLAGS\n    AX_PROG_JAVAC\n    AX_PROG_JAVA\n    AX_PROG_JAR\n    AX_PROG_JAVADOC\n    ## Find the include directories needed for building JNI code\n    AX_JNI_INCLUDE_DIR()\n    for JNI_INCLUDE_DIR in $JNI_INCLUDE_DIRS\n    do\n      JNIFLAGS=\"$JNIFLAGS -I$JNI_INCLUDE_DIR\"\n    done\n    ## Find junit for testing the JNI code\n    AX_CHECK_CLASSPATH()\n    CLASSPATH_ENV=$H5_CLASSPATH\n    AX_CHECK_JUNIT()\n    AX_CHECK_JAVA_HOME\n\n    AC_MSG_RESULT([yes])\n  else\n    AC_MSG_ERROR([Java requires shared libraries to be built])\n    HDF_JAVA=\"no\"\n    AC_MSG_RESULT([no])\n  fi\nelse\n  AC_MSG_RESULT([no])\nfi\n\n## ----------------------------------------------------------------------\n## Fortran libraries are not currently supported on Mac. Disable them.\n## (this is overridable with --enable-unsupported).\n##\nAC_SUBST([H5_FORTRAN_SHARED])\nH5_FORTRAN_SHARED=\"no\"\nif test \"X${HDF_FORTRAN}\" = \"Xyes\" && test \"X${enable_shared}\" != \"Xno\"; then\n  AC_MSG_CHECKING([if shared Fortran libraries are supported])\n  H5_FORTRAN_SHARED=\"yes\"\n  ## tell libtool to do the right thing with COMMON symbols, this fixes\n  ## corrupt values with COMMON and EQUIVALENCE when building shared\n  ## Fortran libraries on OSX with gnu and Intel compilers (HDFFV-2772).\n  case \"`uname`\" in\n    Darwin*)\n    H5_LDFLAGS=\"$H5_LDFLAGS -Wl,-commons,use_dylibs\"\n    ;;\n  esac\n\n  ## Report results of check(s)\n\n  if test \"X${H5_FORTRAN_SHARED}\" = \"Xno\"; then\n    AC_MSG_RESULT([no])\n    AC_MSG_WARN([$CHECK_WARN])\n    if test \"X${ALLOW_UNSUPPORTED}\" != \"Xyes\"; then\n      AC_MSG_WARN([Disabling shared Fortran libraries.])\n      AC_MSG_WARN([To override this behavior, please use --enable-unsupported configure option.])\n        if test \"X${enable_static}\" = \"Xno\"; then\n          AC_MSG_ERROR([both static and shared Fortran libraries are disabled])\n        fi\n    else\n      AC_MSG_WARN([Allowing unsupported Fortran shared libraries due to use of --enable-unsupported flag])\n      H5_FORTRAN_SHARED=\"yes\"\n    fi\n  else\n    AC_MSG_RESULT([yes])\n  fi\nfi\n\nAM_CONDITIONAL([FORTRAN_SHARED_CONDITIONAL], [test \"X$H5_FORTRAN_SHARED\" = \"Xyes\"])\n\n## ----------------------------------------------------------------------\n## Check if they would like to disable building tests\n##\n\n## This needs to be exposed for the library info file.\nAC_SUBST([HDF5_TESTS])\n\n## Default is to build tests\nHDF5_TESTS=yes\n\nAC_MSG_CHECKING([if building tests is disabled])\n\nAC_ARG_ENABLE([tests],\n              [AS_HELP_STRING([--enable-tests],\n                              [Compile the HDF5 tests [default=yes]])],\n              [HDF5_TESTS=$enableval])\n\nif test \"X$HDF5_TESTS\" = \"Xno\"; then\n  echo \"Building HDF5 tests is disabled\"\nfi\n\n## ----------------------------------------------------------------------\n## Check if they would like to disable building tools\n##\n\n## This needs to be exposed for the library info file.\nAC_SUBST([HDF5_TOOLS])\n\n## Default is to build tests and tools\nHDF5_TOOLS=yes\n\nAC_MSG_CHECKING([if building tools is disabled])\n\nAC_ARG_ENABLE([tools],\n              [AS_HELP_STRING([--enable-tools],\n                              [Compile the HDF5 tools [default=yes]])],\n              [HDF5_TOOLS=$enableval])\n\nif test \"X$HDF5_TOOLS\" = \"Xno\"; then\n  echo \"Building HDF5 tools is disabled\"\nfi\n\n## ----------------------------------------------------------------------\n## Create libtool.  If shared/static libraries are going to be enabled\n## or disabled, it should happen before these macros.\nLT_PREREQ([2.2])\n\n## ----------------------------------------------------------------------\n## dlopen - This will use an improved version of libtool\n## win32-dll - This will build clean dlls on win32 platforms.\nLT_INIT([dlopen,win32-dll])\n\n## ----------------------------------------------------------------------\n## Check if we should install only statically linked executables.\n##   This check needs to occur after libtool is initialized because\n##   we check a libtool cache value and may issue a warning based\n##   on its result.\nAC_SUBST([STATIC_EXEC])\n\n## Default is no\nSTATIC_EXEC=no\n\nAC_MSG_CHECKING([if we should install only statically linked executables])\nAC_ARG_ENABLE([static_exec],\n              [AS_HELP_STRING([--enable-static-exec],\n                              [Install only statically linked executables\n                               [default=no]])],\n              [STATIC_EXEC=$enableval])\n\nif test \"X$STATIC_EXEC\" = \"Xyes\"; then\n  echo \"yes\"\n  ## Issue a warning if -static flag is not supported.\n  if test \"X$lt_cv_prog_compiler_static_works\" = \"Xno\"; then\n    echo \"    warning: -static flag not supported on this system; executable won't statically link shared system libraries.\"\n    LT_STATIC_EXEC=\"\"\n  else\n    LT_STATIC_EXEC=\"-all-static\"\n  fi\nelse\n  echo \"no\"\n  LT_STATIC_EXEC=\"\"\nfi\nAM_CONDITIONAL([USE_PLUGINS_CONDITIONAL], [test \"X$LT_STATIC_EXEC\" = X])\n\nAC_SUBST([LT_STATIC_EXEC])\n\n## Fix up the INSTALL macro if it's a relative path. We want the\n## full-path to the binary instead.\ncase \"$INSTALL\" in\n  *install-sh*)\n    INSTALL='\\${top_srcdir}/bin/install-sh -c'\n    ;;\nesac\n\n## ----------------------------------------------------------------------\n## Some users have reported problems with libtool's use of '-Wl,-rpath' to\n## link shared libraries in nondefault directories. Allow users to\n## disable embedding the rpath information in the executables and to\n## instead solely rely on the information in LD_LIBRARY_PATH.\nAC_MSG_CHECKING([if -Wl,-rpath should be used to link shared libs in nondefault directories])\nAC_ARG_ENABLE([sharedlib-rpath],\n              [AS_HELP_STRING([--disable-sharedlib-rpath],\n               [Disable use of the '=Wl,-rpath' linker option])],\n              [RPATH=$enableval])\n\ncase \"X-$RPATH\" in\n  X-no)\n    AC_MSG_RESULT([no])\n    runpath_var=\n    hardcode_libdir_flag_spec=\n    hardcode_libdir_flag_spec_ld=\n    hardcode_into_libs=no\n    ;;\n  X-|X-yes)\n    AC_MSG_RESULT([yes])\n    ;;\n  *)\n    AC_MSG_RESULT([error])\n    AC_MSG_ERROR([\\'$enableval\\' is not a valid rpath type])\n    ;;\nesac\n\n## ----------------------------------------------------------------------\n## Check for system libraries. \"dl\" stands for dynamically loaded library\n##\nAC_CHECK_LIB([m], [ceil])\nAC_CHECK_LIB([dl], [dlopen])\n\n## ----------------------------------------------------------------------\n## Check for system header files.\n##\nAC_HEADER_STDC\nAC_HEADER_TIME\n\n## Unix\nAC_CHECK_HEADERS([sys/resource.h sys/time.h unistd.h sys/ioctl.h sys/stat.h])\nAC_CHECK_HEADERS([sys/socket.h sys/types.h sys/file.h])\nAC_CHECK_HEADERS([stddef.h setjmp.h features.h])\nAC_CHECK_HEADERS([dirent.h])\nAC_CHECK_HEADERS([stdint.h], [C9x=yes])\nAC_CHECK_HEADERS([stdbool.h])\nAC_CHECK_HEADERS([netdb.h netinet/in.h arpa/inet.h])\n\n## Darwin\nAC_SUBST([H5_IS_DARWIN])\nH5_IS_DARWIN=\"no\"\ncase $host_os in\n  darwin*)\n    AC_DEFINE([HAVE_DARWIN], [1], [Define if Darwin or Mac OS X])\n    H5_IS_DARWIN=\"yes\"\n    ;;\nesac\n\n## Windows\ncase \"`uname`\" in\n  CYGWIN*)\n    AC_CHECK_HEADERS([io.h sys/timeb.h])\n    UNAME_CYGWIN=\"yes\"\n    ;;\n  MINGW*)\n    AC_CHECK_HEADERS([io.h winsock2.h sys/timeb.h])\n    AC_HAVE_LIBRARY([ws2_32])\n    ;;\n  *)\n    AC_CHECK_HEADERS([io.h winsock2.h sys/timeb.h])\n    ;;\nesac\n\n## ----------------------------------------------------------------------\n## Some platforms require that all symbols are resolved when a library\n## is linked. We can use the -no-undefined flag to tell libtool that\n## it will be able to build shared libraries on these architectures,\n## as it will not do so by default.\n##\nif test \"X${enable_shared}\" = \"Xyes\"; then\n  AC_MSG_CHECKING([if libtool needs -no-undefined flag to build shared libraries])\n  case \"`uname`\" in\n    CYGWIN*|MINGW*|AIX*)\n      ## Add in the -no-undefined flag to LDFLAGS for libtool.\n      AC_MSG_RESULT([yes])\n      H5_LDFLAGS=\"$H5_LDFLAGS -no-undefined\"\n      ;;\n    *)\n      ## Don't add in anything.\n      AC_MSG_RESULT([no])\n      ;;\n  esac\nfi\n\n## ----------------------------------------------------------------------\n## Use the macro _AC_SYS_LARGEFILE_MACRO_VALUE to test defines\n## that might need to be set for largefile support to behave\n## correctly. This macro is defined in acsite.m4 and overrides\n## the version provided by Autoconf (as of v2.65). The custom\n## macro additionally adds the appropriate defines to AM_CPPFLAGS\n## so that later configure checks have them visible.\n\n## Check for _FILE_OFFSET_BITS\n_AC_SYS_LARGEFILE_MACRO_VALUE([_FILE_OFFSET_BITS], [64],\n  [ac_cv_sys_file_offset_bits],\n  [Number of bits in a file offset, on hosts where this is settable.],\n  [_AC_SYS_LARGEFILE_TEST_INCLUDES])\n\n## Check for _LARGE_FILES\nif test \"$ac_cv_sys_file_offset_bits\" = unknown; then\n  _AC_SYS_LARGEFILE_MACRO_VALUE([_LARGE_FILES], [1],\n    [ac_cv_sys_large_files],\n    [Define for large files, on AIX-style hosts.],\n    [_AC_SYS_LARGEFILE_TEST_INCLUDES])\nfi\n\n## ----------------------------------------------------------------------\n## Add necessary defines for Linux Systems.\n##\ncase \"$host_cpu-$host_vendor-$host_os\" in\n  *linux*)\n    ## Add POSIX support on Linux systems, so <features.h> defines\n    ## __USE_POSIX, which is required to get the prototype for fdopen\n    ## defined correctly in <stdio.h>.\n    ##\n    ## This flag was removed from h5cc as of 2009-10-17 when it was found\n    ## that the flag broke compiling netCDF-4 code with h5cc, but kept in\n    ## H5_CPPFLAGS because fdopen and HDfdopen fail without it. HDfdopen\n    ## is used only by H5_debug_mask which is used only when debugging in\n    ## H5_init_library (all in H5.c).  When the flag was removed this was\n    ## the only compile failure noted.\n    ##\n    ## This was originally defined as _POSIX_SOURCE which was updated to\n    ## _POSIX_C_SOURCE=199506L to expose a greater amount of POSIX\n    ## functionality so clock_gettime and CLOCK_MONOTONIC are defined\n    ## correctly. This was later updated to 200112L so that\n    ## posix_memalign() is visible for the direct VFD code on Linux\n    ## systems. Even later, this was changed to 200809L to support\n    ## pread/pwrite in VFDs.\n    ##\n    ## POSIX feature information can be found in the gcc manual at:\n    ## http://www.gnu.org/s/libc/manual/html_node/Feature-Test-Macros.html\n    H5_CPPFLAGS=\"-D_POSIX_C_SOURCE=200809L $H5_CPPFLAGS\"\n\n    ## Need to add this so that O_DIRECT is visible for the direct\n    ## VFD on Linux systems.\n    H5_CPPFLAGS=\"-D_GNU_SOURCE $H5_CPPFLAGS\"\n    ;;\n\nesac\n\n## Need to add the AM_ and H5_ into CFLAGS/CPPFLAGS to make them visible\n## for configure checks.\n## Note: Both will be restored by the end of configure.\nCPPFLAGS=\"$H5_CPPFLAGS $AM_CPPFLAGS $CPPFLAGS\"\nCFLAGS=\"$H5_CFLAGS $AM_CFLAGS $CFLAGS\"\n\n## Checkpoint the cache\nAC_CACHE_SAVE\n\n## Posix.1g types (C9x)\ncat >>confdefs.h <<\\EOF\n#include <sys/types.h>\nEOF\n\nif test \"X$C9x\" = \"Xyes\"; then\n  cat >>confdefs.h <<\\EOF\n#include <stdint.h>\nEOF\nfi\n\nAC_CHECK_SIZEOF(        [int8_t])\nAC_CHECK_SIZEOF(       [uint8_t])\nAC_CHECK_SIZEOF(  [int_least8_t])\nAC_CHECK_SIZEOF( [uint_least8_t])\nAC_CHECK_SIZEOF(   [int_fast8_t])\nAC_CHECK_SIZEOF(  [uint_fast8_t])\n\nAC_CHECK_SIZEOF(       [int16_t])\nAC_CHECK_SIZEOF(      [uint16_t])\nAC_CHECK_SIZEOF( [int_least16_t])\nAC_CHECK_SIZEOF([uint_least16_t])\nAC_CHECK_SIZEOF(  [int_fast16_t])\nAC_CHECK_SIZEOF( [uint_fast16_t])\n\nAC_CHECK_SIZEOF(       [int32_t])\nAC_CHECK_SIZEOF(      [uint32_t])\nAC_CHECK_SIZEOF( [int_least32_t])\nAC_CHECK_SIZEOF([uint_least32_t])\nAC_CHECK_SIZEOF(  [int_fast32_t])\nAC_CHECK_SIZEOF( [uint_fast32_t])\n\nAC_CHECK_SIZEOF(       [int64_t])\nAC_CHECK_SIZEOF(      [uint64_t])\nAC_CHECK_SIZEOF( [int_least64_t])\nAC_CHECK_SIZEOF([uint_least64_t])\nAC_CHECK_SIZEOF(  [int_fast64_t])\nAC_CHECK_SIZEOF( [uint_fast64_t])\n\nAC_CHECK_SIZEOF([size_t])\nAC_CHECK_SIZEOF([ssize_t])\nAC_CHECK_SIZEOF([ptrdiff_t])\n\ncat >>confdefs.h <<\\EOF\n#include <sys/types.h> /*for off_t definition*/\nEOF\nAC_CHECK_SIZEOF([off_t])\n\nif test \"X$C9x\" = \"Xyes\"; then\n  cat >>confdefs.h <<\\EOF\n#ifdef HAVE_STDBOOL_H\n#include <stdbool.h> /* for bool definition */\n#else\n#define bool _Bool\n#endif\nEOF\nAC_CHECK_SIZEOF([bool])\nfi\n\nAC_CHECK_SIZEOF(time_t, [], [\n#ifdef HAVE_SYS_TYPES_H\n#include <sys/types.h>\n#endif\n#ifdef HAVE_TIME_H\n#include <time.h>\n#endif\n])\n\n## Checkpoint the cache\nAC_CACHE_SAVE\n\n## ----------------------------------------------------------------------\n## Check if the dev_t type is a scalar type (must come after the check for\n## sys/types.h)\nAC_MSG_CHECKING([if dev_t is scalar])\nAC_COMPILE_IFELSE([AC_LANG_PROGRAM([[\n#ifdef HAVE_SYS_TYPES_H\n#include <sys/types.h>\n#endif\n  ]],\n  [[dev_t d1, d2; if(d1==d2) return 0;]])],\n  [AC_DEFINE([DEV_T_IS_SCALAR], [1],\n            [Define if dev_t is a scalar])\n  AC_MSG_RESULT([yes])],\n  [AC_MSG_RESULT([no])])\n\n## ----------------------------------------------------------------------\n## Fake --with-xxx option to allow us to create a help message for the\n## following --with-xxx options which can take either a =DIR or =INC,LIB\n## specifier.\n##\nAC_ARG_WITH([fnord],\n  [\n For the following --with-xxx options, you can specify where the header\n files and libraries are in two different ways:\n\n    --with-xxx=INC,LIB - Specify individually the include directory and\n                         library directory separated by a comma\n    --with-xxx=DIR     - Specify only the directory which contains the\n                         include/ and lib/ subdirectories\n  ])\n\n## ----------------------------------------------------------------------\n## Is dmalloc (debug malloc library) requested? It has a header file\n## `dmalloc.h' and a library `-ldmalloc' and their locations might be\n## specified with the `--with-dmalloc' command-line switch. The value\n## is an include path and/or a library path. If the library path is\n## specified then it must be preceded by a comma.\n##\nAC_SUBST([HAVE_DMALLOC])\n\n## Default is not present\nHAVE_DMALLOC=no\n\nAC_ARG_WITH([dmalloc],\n            [AS_HELP_STRING([--with-dmalloc=DIR],\n                            [Use dmalloc memory debugging aid [default=no]])],,\n            [withval=no])\n\ncase \"X-$withval\" in\n  X-yes)\n    HAVE_DMALLOC=\"yes\"\n    AC_CHECK_HEADERS([dmalloc.h],, [unset HAVE_DMALLOC])\n    if test \"x$HAVE_DMALLOC\" = \"xyes\"; then\n      AC_CHECK_LIB([dmalloc], [dmalloc_shutdown],, [unset HAVE_DMALLOC])\n    fi\n    if test -z \"$HAVE_DMALLOC\" -a -n \"$HDF5_CONFIG_ABORT\"; then\n      AC_MSG_ERROR([couldn't find dmalloc library])\n    fi\n    ;;\n  X-|X-no|X-none)\n    HAVE_DMALLOC=\"no\"\n    AC_MSG_CHECKING([for dmalloc library])\n    AC_MSG_RESULT([suppressed])\n    ;;\n  *)\n    HAVE_DMALLOC=\"yes\"\n    case \"$withval\" in\n      *,*)\n        dmalloc_inc=\"`echo $withval |cut -f1 -d,`\"\n        dmalloc_lib=\"`echo $withval |cut -f2 -d, -s`\"\n        ;;\n      *)\n        if test -n \"$withval\"; then\n          dmalloc_inc=\"$withval/include\"\n          dmalloc_lib=\"$withval/lib\"\n        fi\n        ;;\n    esac\n\n    saved_CPPFLAGS=\"$CPPFLAGS\"\n    saved_AM_CPPFLAGS=\"$AM_CPPFLAGS\"\n    saved_LDFLAGS=\"$LDFLAGS\"\n    saved_AM_LDFLAGS=\"$AM_LDFLAGS\"\n\n    if test -n \"$dmalloc_inc\"; then\n      CPPFLAGS=\"$CPPFLAGS -I$dmalloc_inc\"\n      AM_CPPFLAGS=\"$AM_CPPFLAGS -I$dmalloc_inc\"\n    fi\n\n    AC_CHECK_HEADERS([dmalloc.h],,[CPPFLAGS=\"$saved_CPPFLAGS\"; AM_CPPFLAGS=\"$saved_AM_CPPFLAGS\"] [unset HAVE_DMALLOC])\n\n    if test \"x$HAVE_DMALLOC\" = \"xyes\"; then\n      if test -n \"$dmalloc_lib\"; then\n        LDFLAGS=\"$LDFLAGS -L$dmalloc_lib\"\n        AM_LDFLAGS=\"$AM_LDFLAGS -L$dmalloc_lib\"\n      fi\n\n      AC_CHECK_LIB([dmalloc], [dmalloc_shutdown],, [LDFLAGS=\"$saved_LDFLAGS\"; AM_LDFLAGS=\"$saved_AM_LDFLAGS\"; unset HAVE_DMALLOC])\n    fi\n\n    if test -z \"$HAVE_DMALLOC\" -a -n \"$HDF5_CONFIG_ABORT\"; then\n      AC_MSG_ERROR([couldn't find dmalloc library])\n    fi\n    ;;\nesac\n\n## ----------------------------------------------------------------------\n## Make the external filters list available to *.in files\n## At this point it's unset (no external filters by default) but it\n## will be filled in during the deflate (zlib) and szip processing\n## below.\n##\nAC_SUBST([EXTERNAL_FILTERS])\n\n## ----------------------------------------------------------------------\n## Is the GNU zlib present? It has a header file `zlib.h' and a library\n## `-lz' and their locations might be specified with the `--with-zlib'\n## command-line switch. The value is an include path and/or a library path.\n## If the library path is specified then it must be preceded by a comma.\n##\nAC_SUBST([USE_FILTER_DEFLATE]) USE_FILTER_DEFLATE=\"no\"\nAC_ARG_WITH([zlib],\n            [AS_HELP_STRING([--with-zlib=DIR],\n                            [Use zlib library for external deflate I/O\n                             filter [default=yes]])],,\n            [withval=yes])\n\ncase \"X-$withval\" in\n  X-yes)\n    HAVE_ZLIB=\"yes\"\n    AC_CHECK_HEADERS([zlib.h], [HAVE_ZLIB_H=\"yes\"], [unset HAVE_ZLIB])\n    if test \"x$HAVE_ZLIB\" = \"xyes\" -a \"x$HAVE_ZLIB_H\" = \"xyes\"; then\n      AC_CHECK_LIB([z], [compress2],, [unset HAVE_ZLIB])\n    fi\n    if test -z \"$HAVE_ZLIB\"; then\n      if test -n \"$HDF5_CONFIG_ABORT\"; then\n        AC_MSG_ERROR([couldn't find zlib library])\n      fi\n    else\n      AC_CHECK_FUNC([compress2], [HAVE_COMPRESS2=\"yes\"])\n    fi\n    ;;\n  X-|X-no|X-none)\n    HAVE_ZLIB=\"no\"\n    AC_MSG_CHECKING([for zlib])\n    AC_MSG_RESULT([suppressed])\n    ;;\n  *)\n    HAVE_ZLIB=\"yes\"\n    case \"$withval\" in\n      *,*)\n        zlib_inc=\"`echo $withval | cut -f1 -d,`\"\n        zlib_lib=\"`echo $withval | cut -f2 -d, -s`\"\n        ;;\n      *)\n        if test -n \"$withval\"; then\n          zlib_inc=\"$withval/include\"\n          zlib_lib=\"$withval/lib\"\n        fi\n        ;;\n    esac\n\n    saved_CPPFLAGS=\"$CPPFLAGS\"\n    saved_AM_CPPFLAGS=\"$AM_CPPFLAGS\"\n    saved_LDFLAGS=\"$LDFLAGS\"\n    saved_AM_LDFLAGS=\"$AM_LDFLAGS\"\n\n    if test -n \"$zlib_inc\"; then\n      CPPFLAGS=\"$CPPFLAGS -I$zlib_inc\"\n      AM_CPPFLAGS=\"$AM_CPPFLAGS -I$zlib_inc\"\n    fi\n\n    AC_CHECK_HEADERS([zlib.h],\n                     [HAVE_ZLIB_H=\"yes\"],\n                     [CPPFLAGS=\"$saved_CPPFLAGS\"; AM_CPPFLAGS=\"$saved_AM_CPPFLAGS\"] [unset HAVE_ZLIB])\n\n    if test -n \"$zlib_lib\"; then\n      LDFLAGS=\"$LDFLAGS -L$zlib_lib\"\n      AM_LDFLAGS=\"$AM_LDFLAGS -L$zlib_lib\"\n    fi\n\n    if test \"x$HAVE_ZLIB\" = \"xyes\" -a \"x$HAVE_ZLIB_H\" = \"xyes\"; then\n      AC_CHECK_LIB([z], [compress2],,\n                   [LDFLAGS=\"$saved_LDFLAGS\"; AM_LDFLAGS=\"$saved_AM_LDFLAGS\"; unset HAVE_ZLIB])\n    fi\n\n    if test -z \"$HAVE_ZLIB\"; then\n      if test -n \"$HDF5_CONFIG_ABORT\"; then\n        AC_MSG_ERROR([couldn't find zlib library])\n      fi\n    else\n      AC_CHECK_FUNC([compress2], [HAVE_COMPRESS2=\"yes\"])\n    fi\n    ;;\nesac\n\nif test \"x$HAVE_ZLIB\" = \"xyes\" -a \"x$HAVE_ZLIB_H\" = \"xyes\" -a \"x$HAVE_COMPRESS2\" = \"xyes\"; then\n  AC_DEFINE([HAVE_FILTER_DEFLATE], [1], [Define if support for deflate (zlib) filter is enabled])\n  USE_FILTER_DEFLATE=\"yes\"\n\n  ## Add \"deflate\" to external filter list\n  if test \"X$EXTERNAL_FILTERS\" != \"X\"; then\n    EXTERNAL_FILTERS=\"${EXTERNAL_FILTERS},\"\n  fi\n    EXTERNAL_FILTERS=\"${EXTERNAL_FILTERS}deflate(zlib)\"\nfi\n\n\n## ----------------------------------------------------------------------\n## Is the szlib present? It has a header file `szlib.h' and a library\n## `-lsz' and their locations might be specified with the `--with-szlib'\n## command-line switch. The value is an include path and/or a library path.\n## If the library path is specified then it must be preceded by a comma.\n##\nAC_SUBST([USE_FILTER_SZIP]) USE_FILTER_SZIP=\"no\"\nAC_ARG_WITH([szlib],\n            [AS_HELP_STRING([--with-szlib=DIR],\n                            [Use szlib library for external szlib I/O\n                             filter [default=no]])],,\n            [withval=no])\n\ncase \"X-$withval\" in\n  X-yes)\n    HAVE_SZLIB=\"yes\"\n    AC_CHECK_HEADERS([szlib.h], [HAVE_SZLIB_H=\"yes\"], [unset HAVE_SZLIB])\n    if test \"x$HAVE_SZLIB\" = \"xyes\" -a \"x$HAVE_SZLIB_H\" = \"xyes\"; then\n      AC_CHECK_LIB([sz], [SZ_BufftoBuffCompress],, [unset HAVE_SZLIB])\n    fi\n    if test -z \"$HAVE_SZLIB\" -a -n \"$HDF5_CONFIG_ABORT\"; then\n      AC_MSG_ERROR([couldn't find szlib library])\n    fi\n    ;;\n  X-|X-no|X-none)\n    HAVE_SZLIB=\"no\"\n    AC_MSG_CHECKING([for szlib])\n    AC_MSG_RESULT([suppressed])\n    ;;\n  *)\n    HAVE_SZLIB=\"yes\"\n    case \"$withval\" in\n      *,*)\n        szlib_inc=\"`echo $withval |cut -f1 -d,`\"\n        szlib_lib=\"`echo $withval |cut -f2 -d, -s`\"\n        ;;\n      *)\n        if test -n \"$withval\"; then\n          szlib_inc=\"$withval/include\"\n          szlib_lib=\"$withval/lib\"\n        fi\n        ;;\n    esac\n\n    saved_CPPFLAGS=\"$CPPFLAGS\"\n    saved_AM_CPPFLAGS=\"$AM_CPPFLAGS\"\n    saved_LDFLAGS=\"$LDFLAGS\"\n    saved_AM_LDFLAGS=\"$AM_LDFLAGS\"\n\n    if test -n \"$szlib_inc\"; then\n      CPPFLAGS=\"$CPPFLAGS -I$szlib_inc\"\n      AM_CPPFLAGS=\"$AM_CPPFLAGS -I$szlib_inc\"\n    fi\n\n    if test -n \"$szlib_lib\"; then\n      LDFLAGS=\"$LDFLAGS -L$szlib_lib\"\n      AM_LDFLAGS=\"$AM_LDFLAGS -L$szlib_lib\"\n    fi\n\n    if test \"x$HAVE_SZLIB\" = \"xyes\"; then\n      AC_CHECK_LIB([sz], [SZ_BufftoBuffCompress],,\n                   [CPPFLAGS=\"$saved_CPPFLAGS\"; AM_CPPFLAGS=\"$saved_AM_CPPFLAGS\"; LDFLAGS=\"$saved_LDFLAGS\"; AM_LDFLAGS=\"$saved_AM_LDFLAGS\"; unset HAVE_SZLIB])\n      if test -n \"$HAVE_SZLIB\"; then\n        AC_CHECK_HEADERS([szlib.h],\n                         [HAVE_SZLIB_H=\"yes\"],\n                         [CPPFLAGS=\"$saved_CPPFLAGS\"; AM_CPPFLAGS=\"$saved_AM_CPPFLAGS\"] [unset HAVE_SZLIB])\n      else\n        AC_MSG_RESULT([Using SZ_BufftoBuffCompress from libsz in $szlib_lib failed.  Szip not enabled.])\n      fi\n    fi\n\n    if test -z \"$HAVE_SZLIB\" -a -n \"$HDF5_CONFIG_ABORT\"; then\n      AC_MSG_ERROR([couldn't find szlib library])\n    fi\n    ;;\nesac\n\nif test \"x$HAVE_SZLIB\" = \"xyes\" -a \"x$HAVE_SZLIB_H\" = \"xyes\"; then\n  ## SZLIB library is available.  Check if it can encode\n  AC_MSG_CHECKING([for szlib encoder])\n\n  ## Set LD_LIBRARY_PATH so encoder test can find the library and run.\n  ## Also add LL_PATH substitution to Makefiles so they can use the\n  ## path as well, for testing examples.\n  if test -z \"$LD_LIBRARY_PATH\"; then\n    export LD_LIBRARY_PATH=\"$szlib_lib\"\n  else\n    export LD_LIBRARY_PATH=\"$LD_LIBRARY_PATH:$szlib_lib\"\n  fi\n\n  AC_SUBST([LL_PATH]) LL_PATH=\"$LD_LIBRARY_PATH\"\n\n  AC_CACHE_VAL([hdf5_cv_szlib_can_encode],\n        [AC_RUN_IFELSE(\n            [AC_LANG_PROGRAM([\n                #include \"szlib.h\"\n            ],[[\n                /* SZ_encoder_enabled returns 1 if encoder is present */\n                if(SZ_encoder_enabled() == 1)\n                    exit(0);\n                else\n                    exit(1);\n            ]])]\n        , [hdf5_cv_szlib_can_encode=yes], [hdf5_cv_szlib_can_encode=no],)]\n   )\n\n  AC_DEFINE([HAVE_FILTER_SZIP], [1],\n            [Define if support for szip filter is enabled])\n  USE_FILTER_SZIP=\"yes\"\n\n  if test ${hdf5_cv_szlib_can_encode} = \"yes\"; then\n    AC_MSG_RESULT([yes])\n  fi\n  if test ${hdf5_cv_szlib_can_encode} = \"no\"; then\n    AC_MSG_RESULT([no])\n  fi\n\n  ## Add \"szip\" to external filter list\n  if test ${hdf5_cv_szlib_can_encode} = \"yes\"; then\n    if test \"X$EXTERNAL_FILTERS\" != \"X\"; then\n      EXTERNAL_FILTERS=\"${EXTERNAL_FILTERS},\"\n    fi\n      EXTERNAL_FILTERS=\"${EXTERNAL_FILTERS}szip(encoder)\"\n  fi\n  if test ${hdf5_cv_szlib_can_encode} = \"no\"; then\n    if test \"X$EXTERNAL_FILTERS\" != \"X\"; then\n      EXTERNAL_FILTERS=\"${EXTERNAL_FILTERS},\"\n    fi\n      EXTERNAL_FILTERS=\"${EXTERNAL_FILTERS}szip(no encoder)\"\n  fi\nfi\n\nAM_CONDITIONAL([BUILD_SHARED_SZIP_CONDITIONAL], [test \"X$USE_FILTER_SZIP\" = \"Xyes\" && test \"X$LL_PATH\" != \"X\"])\n\n## Checkpoint the cache\nAC_CACHE_SAVE\n\n## ----------------------------------------------------------------------\n## Enable thread-safe version of library.  It requires Pthreads support\n## on POSIX systems.\n##\nAC_SUBST([THREADSAFE])\n\n## Default is no thread-safety\nTHREADSAFE=no\n\nAC_MSG_CHECKING([for thread safe support])\nAC_ARG_ENABLE([threadsafe],\n              [AS_HELP_STRING([--enable-threadsafe],\n                              [Enable thread-safe capability. Not compatible with the high-level library, Fortran, or C++ wrappers.\n                              [default=no]])],\n              [THREADSAFE=$enableval])\n\n## The high-level, C++, Fortran and Java interfaces are not compatible\n## with the thread-safety option because the lock is not hoisted\n## into the higher-level API calls.\n\n## --enable-threadsafe is incompatible with --enable-hl unless\n## --enable-unsupported has been specified on the configure line.\n##\n## Note that the high-level library is enabled by default so most\n## users will have to add --disable-hl to the configure options.\nif test \"X${ALLOW_UNSUPPORTED}\" != \"Xyes\"; then\n  if test \"X${HDF5_HL}\" = \"Xyes\" -a \"X${enable_threadsafe}\" = \"Xyes\"; then\n    AC_MSG_ERROR([The thread-safe library is incompatible with the high-level library. --disable-hl can be used to prevent building the high-level library (recommended). Alternatively, --enable-unsupported will allow building the high-level library, though this configuration is not supported by The HDF Group.])\n  fi\nfi\n\n## The --enable-threadsafe flag is not compatible with --enable-cxx.\n## If the user tried to specify both flags, throw an error, unless\n## they also provided the --enable-unsupported flag.\nif test \"X${ALLOW_UNSUPPORTED}\" != \"Xyes\"; then\n  if test \"X${HDF_CXX}\" = \"Xyes\" -a \"X${enable_threadsafe}\" = \"Xyes\"; then\n    AC_MSG_ERROR([--enable-cxx and --enable-threadsafe flags are incompatible. Use --enable-unsupported to override this error.])\n  fi\nfi\n\n## --enable-threadsafe is also incompatible with --enable-fortran unless\n## --enable-unsupported has been specified on the configure line.\nif test \"X${ALLOW_UNSUPPORTED}\" != \"Xyes\"; then\n  if test \"X${HDF_FORTRAN}\" = \"Xyes\" -a \"X${enable_threadsafe}\" = \"Xyes\"; then\n    AC_MSG_ERROR([--enable-fortran and --enable-threadsafe flags are incompatible. Use --enable-unsupported to override this error.])\n  fi\nfi\n\n## --enable-threadsafe is also incompatible with --enable-java unless\n## --enable-unsupported has been specified on the configure line.\nif test \"X${ALLOW_UNSUPPORTED}\" != \"Xyes\"; then\n  if test \"X${HDF_JAVA}\" = \"Xyes\" -a \"X${enable_threadsafe}\" = \"Xyes\"; then\n    AC_MSG_ERROR([--enable-java and --enable-threadsafe flags are incompatible. Use --enable-unsupported to override this error.])\n  fi\nfi\n\n\ncase \"X-$THREADSAFE\" in\n  X-|X-no)\n    AC_MSG_RESULT([no])\n    ;;\n  X-yes)\n    THREADSAFE=yes\n    AC_MSG_RESULT([yes])\n    ;;\n  *)\n    AC_MSG_RESULT([error])\n    AC_MSG_ERROR([\\'$enableval\\' is not a valid threadsafe type])\n    ;;\nesac\n\nif test \"X$THREADSAFE\" = \"Xyes\"; then\n    AC_DEFINE([HAVE_THREADSAFE], [1], [Define if we have thread safe support])\n\n    ## ----------------------------------------------------------------------\n    ## Is the Pthreads library present?  It has a header file `pthread.h' and\n    ## a library `-lpthread' and their locations might be specified with the\n    ## `--with-pthread' command-line switch.  The value is an include path\n    ## and/or a library path.  If the library path is specified then it must\n    ## be preceded by a comma.\n    ##\n    ## Thread-safety in HDF5 only uses Pthreads via configure, so the\n    ## default is \"check\", though this only has an effect when\n    ## --enable-threadsafe is specified.\n    AC_SUBST([HAVE_PTHREAD]) HAVE_PTHREAD=yes\n    AC_ARG_WITH([pthread],\n                [AS_HELP_STRING([--with-pthread=DIR],\n                                [Specify alternative path to Pthreads library when\n                                thread-safe capability is built.])],,\n                [withval=check])\n\n    case \"$withval\" in\n      check | yes)\n        AC_CHECK_HEADERS([pthread.h],, [unset HAVE_PTHREAD])\n        if test \"x$HAVE_PTHREAD\" = \"xyes\"; then\n          AC_CHECK_LIB([pthread], [pthread_self],, [unset HAVE_PTHREAD])\n        fi\n        ;;\n      no)\n        AC_MSG_ERROR([Must use Pthreads with thread safety])\n        ;;\n      *)\n        case \"$withval\" in\n          *,*)\n            pthread_inc=\"`echo $withval | cut -f1 -d,`\"\n            pthread_lib=\"`echo $withval | cut -f2 -d, -s`\"\n            ;;\n          *)\n            if test -n \"$withval\"; then\n              pthread_inc=\"$withval/include\"\n              pthread_lib=\"$withval/lib\"\n            fi\n            ;;\n        esac\n\n        if test -n \"$pthread_inc\"; then\n          saved_CPPFLAGS=\"$CPPFLAGS\"\n          saved_AM_CPPFLAGS=\"$AM_CPPFLAGS\"\n          CPPFLAGS=\"$CPPFLAGS -I$pthread_inc\"\n          AM_CPPFLAGS=\"$AM_CPPFLAGS -I$pthread_inc\"\n          AC_CHECK_HEADERS([pthread.h],, [CPPFLAGS=\"$saved_CPPFLAGS\"; AM_CPPFLAGS=\"$saved_AM_CPPFLAGS\"; unset HAVE_PTHREAD])\n        else\n          AC_CHECK_HEADERS([pthread.h],, [unset HAVE_PTHREAD])\n        fi\n\n        if test \"x$HAVE_PTHREAD\" = \"xyes\"; then\n          if test -n \"$pthread_lib\"; then\n            saved_LDFLAGS=\"$LDFLAGS\"\n            saved_AM_LDFLAGS=\"$AM_LDFLAGS\"\n            LDFLAGS=\"$LDFLAGS -L$pthread_lib\"\n            AM_LDFLAGS=\"$AM_LDFLAGS -L$pthread_lib\"\n            AC_CHECK_LIB([pthread], [pthread_self],,\n                         [LDFLAGS=\"$saved_LDFLAGS\"; AM_LDFLAGS=\"$saved_AM_LDFLAGS\"; unset HAVE_PTHREAD])\n          else\n            AC_CHECK_LIB([pthread], [pthread_self],, [unset HAVE_PTHREAD])\n          fi\n        fi\n        ;;\n    esac\n\n    ## ----------------------------------------------------------------------\n    ## Check if pthread_attr_setscope(&attribute, PTHREAD_SCOPE_SYSTEM)\n    ## is supported on this system\n    ##\n    ## Unfortunately, this probably needs to be an AC_RUN_IFELSE since\n    ## it's impossible to determine if PTHREAD_SCOPE_SYSTEM is\n    ## supported a priori. POSIX.1-2001 requires that a conformant\n    ## system need only support one of SYSTEM or PROCESS scopes.\n    ##\n    ## For cross-compiling, we've added a pessimistic 'no'. You can\n    ## hand-hack the config file if you know otherwise.\n    AC_MSG_CHECKING([Pthreads supports system scope])\n    AC_CACHE_VAL([hdf5_cv_system_scope_threads],\n      [AC_RUN_IFELSE(\n        [AC_LANG_PROGRAM([\n            #if STDC_HEADERS\n            #include <stdlib.h>\n            #include <pthread.h>\n            #endif\n        ],[\n              pthread_attr_t attribute;\n              int ret;\n\n              pthread_attr_init(&attribute);\n              ret=pthread_attr_setscope(&attribute, PTHREAD_SCOPE_SYSTEM);\n              exit(ret==0 ? 0 : 1);\n        ])]\n      , [hdf5_cv_system_scope_threads=yes], [hdf5_cv_system_scope_threads=no], [hdf5_cv_system_scope_threads=no])])\n\n    if test ${hdf5_cv_system_scope_threads} = \"yes\"; then\n      AC_DEFINE([SYSTEM_SCOPE_THREADS], [1],\n                [Define if your system supports pthread_attr_setscope(&attribute, PTHREAD_SCOPE_SYSTEM) call.])\n      AC_MSG_RESULT([yes])\n    else\n      AC_MSG_RESULT([no])\n      AC_MSG_NOTICE([Always 'no' if cross-compiling. Edit the config file if your platform supports pthread_attr_setscope(&attribute, PTHREAD_SCOPE_SYSTEM).])\n    fi\nfi\n\n## ----------------------------------------------------------------------\n## Check for MONOTONIC_TIMER support (used in clock_gettime).  This has\n## to be done after any POSIX defines to ensure that the test gets\n## the correct POSIX level on linux.\nAC_CHECK_DECL([CLOCK_MONOTONIC],[have_clock_monotonic=\"yes\"],[have_clock_monotonic=\"no\"],[[#include <time.h>]])\n\n## ----------------------------------------------------------------------\n## How does one figure out the local time zone?  Anyone know of a\n## Posix way to do this?\n##\n\n## First check if `struct tm' has a `tm_gmtoff' member.\nAC_MSG_CHECKING([for tm_gmtoff in struct tm])\nAC_COMPILE_IFELSE([AC_LANG_PROGRAM([[\n  #include <sys/time.h>\n  #include <time.h>\n]], [[struct tm tm; tm.tm_gmtoff=0;]])],\n  [AC_DEFINE([HAVE_TM_GMTOFF], [1],\n          [Define if tm_gmtoff is a member of struct tm])\n    AC_MSG_RESULT([yes])],\n  [AC_MSG_RESULT([no])])\n\n## Check whether the global variable `timezone' is defined.\nAC_MSG_CHECKING([for global timezone variable])\n\ncase \"`uname`\" in\n  CYGWIN*)\n    AC_MSG_RESULT([disabled in CYGWIN])\n    ;;\n  *)\n    AC_LINK_IFELSE([AC_LANG_PROGRAM([[\n    #include <sys/time.h>\n    #include <time.h>]], [[timezone=0;]])],\n    [AC_DEFINE([HAVE_TIMEZONE], [1],\n              [Define if timezone is a global variable])\n      AC_MSG_RESULT([yes])],\n    [AC_MSG_RESULT([no])])\n    ;;\nesac\n\n\n## ----------------------------------------------------------------------\n## Does the struct stat have the st_blocks field?  This field is not Posix.\n##\nAC_MSG_CHECKING([for st_blocks in struct stat])\nAC_COMPILE_IFELSE([AC_LANG_PROGRAM[[\n  #include <sys/stat.h>]],[[struct stat sb; sb.st_blocks=0;]])],\n  [AC_DEFINE([HAVE_STAT_ST_BLOCKS], [1],\n          [Define if struct stat has the st_blocks field])\n    AC_MSG_RESULT([yes])],\n  [AC_MSG_RESULT([no])])\n\n## ----------------------------------------------------------------------\n## How do we figure out the width of a tty in characters?\n##\nAC_CHECK_FUNCS([_getvideoconfig gettextinfo])\ncase \"`uname`\" in\n  CYGWIN*)\n    ;;\n  *)\n    AC_CHECK_FUNCS([GetConsoleScreenBufferInfo getpwuid])\n    ;;\nesac\nAC_CHECK_FUNCS([_scrsize ioctl])\n\nAC_MSG_CHECKING([for struct videoconfig])\nAC_COMPILE_IFELSE([AC_LANG_PROGRAM([[]],[[struct videoconfig w; w.numtextcols=0;]])],\n  [AC_DEFINE([HAVE_STRUCT_VIDEOCONFIG], [1],\n          [Define if struct videoconfig is defined])\n    AC_MSG_RESULT([yes])],\n  [AC_MSG_RESULT([no])])\n\nAC_MSG_CHECKING([for struct text_info])\nAC_COMPILE_IFELSE([AC_LANG_PROGRAM([[]], [[struct text_info w; w.screenwidth=0;]])],\n  [AC_DEFINE([HAVE_STRUCT_TEXT_INFO], [1],\n          [Define if struct text_info is defined])\n    AC_MSG_RESULT([yes])],\n  [AC_MSG_RESULT([no])])\n\nAC_MSG_CHECKING([for TIOCGWINSZ])\nAC_COMPILE_IFELSE([AC_LANG_PROGRAM([[\n#include <sys/ioctl.h>\n]],[[int w=TIOCGWINSZ;]])],\n  [AC_DEFINE([HAVE_TIOCGWINSZ], [1],\n          [Define if the ioctl TIOGWINSZ is defined])\n    AC_MSG_RESULT([yes])],\n  [AC_MSG_RESULT([no])])\n\nAC_MSG_CHECKING([for TIOCGETD])\nAC_COMPILE_IFELSE([AC_LANG_PROGRAM([[\n#include <sys/ioctl.h>\n]],[[int w=TIOCGETD;]])],\n  [AC_DEFINE([HAVE_TIOCGETD], [1],\n          [Define if the ioctl TIOCGETD is defined])\n    AC_MSG_RESULT([yes])],\n  [AC_MSG_RESULT([no])])\n\n\n## ----------------------------------------------------------------------\n## Check for functions.\n##\n## NOTE: clock_gettime may require linking to the rt or posix4 library\n##       so we'll search for it before calling AC_CHECK_FUNCS.\nAC_SEARCH_LIBS([clock_gettime], [rt posix4])\nAC_CHECK_FUNCS([alarm clock_gettime difftime fcntl flock fork frexpf])\nAC_CHECK_FUNCS([frexpl gethostname getrusage gettimeofday])\nAC_CHECK_FUNCS([lstat rand_r random setsysinfo])\nAC_CHECK_FUNCS([signal longjmp setjmp siglongjmp sigsetjmp sigprocmask])\nAC_CHECK_FUNCS([snprintf srandom strdup symlink system])\nAC_CHECK_FUNCS([strtoll strtoull])\nAC_CHECK_FUNCS([tmpfile asprintf vasprintf vsnprintf waitpid])\nAC_CHECK_FUNCS([roundf lroundf llroundf round lround llround])\n\n## ----------------------------------------------------------------------\n## Check compiler characteristics\n##\nAC_C_CONST\n\nAC_MSG_CHECKING([if the compiler understands  __inline__])\nAC_COMPILE_IFELSE(\n    [AC_LANG_SOURCE([[static __inline__ void f(void){return;};]])],\n    [AC_DEFINE([HAVE___INLINE__], [1], [Define if the compiler understands __inline__]) AC_MSG_RESULT([yes])],\n    [AC_MSG_RESULT([no])]\n)\n\nAC_MSG_CHECKING([if the compiler understands __inline])\nAC_COMPILE_IFELSE(\n    [AC_LANG_SOURCE([[static __inline void f(void){return;};]])],\n    [AC_DEFINE([HAVE___INLINE], [1], [Define if the compiler understands __inline]) AC_MSG_RESULT([yes])],\n    [AC_MSG_RESULT([no])]\n)\n\nAC_MSG_CHECKING([if the compiler understands inline])\nAC_COMPILE_IFELSE(\n    [AC_LANG_SOURCE([[static inline void f(void){return;};]])],\n    [AC_DEFINE([HAVE_INLINE], [1], [Define if the compiler understands inline]) AC_MSG_RESULT([yes])],\n    [AC_MSG_RESULT([no])]\n)\n\nAC_MSG_CHECKING([for __attribute__ extension])\nAC_COMPILE_IFELSE([AC_LANG_PROGRAM([[]],[[int __attribute__((unused)) x]])],\n               [AC_DEFINE([HAVE_ATTRIBUTE], [1],\n                         [Define if the __attribute__(()) extension is present])\n                 AC_MSG_RESULT([yes])],\n               [AC_MSG_RESULT([no])])\n\nAC_MSG_CHECKING([for __func__ extension])\nAC_COMPILE_IFELSE([AC_LANG_PROGRAM([[]],[[ const char *fname = __func__; ]])],\n               [AC_DEFINE([HAVE_C99_FUNC], [1],\n                         [Define if the compiler understands the __func__ keyword])\n                 AC_MSG_RESULT([yes])],\n               [AC_MSG_RESULT([no])])\nAC_MSG_CHECKING([for __FUNCTION__ extension])\nAC_COMPILE_IFELSE([AC_LANG_PROGRAM([[]],,[[ const char *fname = __FUNCTION__; ]])],\n               [AC_DEFINE([HAVE_FUNCTION], [1],\n                         [Define if the compiler understands the __FUNCTION__ keyword])\n                 AC_MSG_RESULT([yes])],\n               [AC_MSG_RESULT([no])])\nAC_MSG_CHECKING([for C99 designated initialization support])\nAC_COMPILE_IFELSE([AC_LANG_PROGRAM([[]], [[\n                typedef struct {\n                    int x;\n                    union {\n                        int i;\n                        double d;\n                    } u;\n                } di_struct_t;\n                di_struct_t x = {0, { .d = 0.0}}; ]])],\n               [AC_DEFINE([HAVE_C99_DESIGNATED_INITIALIZER], [1],\n                         [Define if the compiler understands C99 designated initialization of structs and unions])\n                 AC_MSG_RESULT([yes])],\n               [AC_MSG_RESULT([no])])\n\n## ----------------------------------------------------------------------\n## Try to figure out how to print `long long'.  Some machines use `%lld'\n## and others use `%qd'.  There may be more!  The final `l' is a\n## default in case none of the others work.\n##\nAC_MSG_CHECKING([how to print long long])\nAC_CACHE_VAL([hdf5_cv_printf_ll], [\n\nfor hdf5_cv_printf_ll in ll l L q unknown; do\n   AC_RUN_IFELSE(\n        [AC_LANG_PROGRAM([\n            #include <stdio.h>\n            #include <stdlib.h>\n            #include <string.h>\n        ],[[\n            char *s = malloc(128);\n            long long x = (long long)1048576 * (long long)1048576;\n            sprintf(s,\"%${hdf5_cv_printf_ll}d\",x);\n            exit(strcmp(s,\"1099511627776\"));\n        ]])]\n   , [break],,[continue])\ndone])\n\nAC_MSG_RESULT([%${hdf5_cv_printf_ll}d and %${hdf5_cv_printf_ll}u])\nAC_DEFINE_UNQUOTED([PRINTF_LL_WIDTH], [\"$hdf5_cv_printf_ll\"],\n                   [Width for printf() for type `long long' or `__int64', use `ll'])\n\n## ----------------------------------------------------------------------\n## Remove old ways of determining debug/production build.\n## These were used in 1.8.x and earlier. We should probably keep these checks\n## around to help people migrate to 1.10.x and newer versions.\n##\nAC_ARG_ENABLE([debug],\n              [AS_HELP_STRING([--enable-debug], [OPTION CHANGE: use --enable-build-mode=debug])],\n              [AC_MSG_ERROR([--enable-debug is no longer supported, use --enable-build-mode=debug instead.])])\n\nAC_ARG_ENABLE([production],\n              [AS_HELP_STRING([--enable-production], [OPTION CHANGE: use --enable-build-mode=production])],\n              [AC_MSG_ERROR([--enable-production is no longer supported, use --enable-build-mode=production instead.])])\n\n\n## ----------------------------------------------------------------------\n## Check if the compiler should include symbols\n##\nAC_MSG_CHECKING([enable debugging symbols])\nAC_ARG_ENABLE([symbols],\n              [AS_HELP_STRING([--enable-symbols=(yes|no|<custom>)],\n                              [Add debug symbols to the library (e.g.: build with -g).\n                               This is independent of the build mode and optimization\n                               level. The custom string allows special settings like\n                               -ggdb, etc. to be used.\n                               [default=yes if debug build, otherwise no]\n                               ])],\n              [SYMBOLS=$enableval])\n\n## Set default\nif test \"X-$SYMBOLS\" = X- ; then\n  if test \"X-$BUILD_MODE\" = \"X-debug\" ; then\n    SYMBOLS=yes\n  else\n    SYMBOLS=no\n  fi\nfi\n\n## Allow this variable to be substituted in\n## other files (src/libhdf5.settings.in, etc.)\nAC_SUBST([SYMBOLS])\n\ncase \"X-$SYMBOLS\" in\n  X-yes)\n    H5_CFLAGS=\"$H5_CFLAGS $SYMBOLS_CFLAGS\"\n    H5_CXXFLAGS=\"$H5_CXXFLAGS $SYMBOLS_CXXFLAGS\"\n    H5_FCFLAGS=\"$H5_FCFLAGS $SYMBOLS_FCFLAGS\"\n    AC_MSG_RESULT([yes])\n    ;;\n  X-no)\n    H5_CFLAGS=\"$H5_CFLAGS $NO_SYMBOLS_CFLAGS\"\n    H5_CXXFLAGS=\"$H5_CXXFLAGS $NO_SYMBOLS_CXXFLAGS\"\n    H5_FCFLAGS=\"$H5_FCFLAGS $NO_SYMBOLS_FCFLAGS\"\n    AC_MSG_RESULT([no])\n    ;;\n  *)\n    H5_CFLAGS=\"$H5_CFLAGS $SYMBOLS\"\n    H5_CXXFLAGS=\"$H5_CXXFLAGS $SYMBOLS\"\n    H5_FCFLAGS=\"$H5_FCFLAGS $SYMBOLS\"\n    SYMBOLS=\"custom ($SYMBOLS)\"\n    AC_MSG_RESULT([$SYMBOLS])\n    ;;\nesac\n\n## ----------------------------------------------------------------------\n## Check if the assert macro should be enabled\n##\nAC_MSG_CHECKING([enable asserts])\nAC_ARG_ENABLE([asserts],\n              [AS_HELP_STRING([--enable-asserts],\n                              [Determines whether NDEBUG is defined or not, which\n                               controls assertions.\n                               This is independent of the build mode and presence\n                               of debugging symbols.\n                               [default=yes if debug build, otherwise no]\n                               ])],\n              [ASSERTS=$enableval])\n\n## Set default\nif test \"X-$ASSERTS\" = X- ; then\n  if test \"X-$BUILD_MODE\" = \"X-debug\" ; then\n    ASSERTS=yes\n  else\n    ASSERTS=no\n  fi\nfi\n\n## Allow this variable to be substituted in\n## other files (src/libhdf5.settings.in, etc.)\nAC_SUBST([ASSERTS])\n\ncase \"X-$ASSERTS\" in\n  X-yes)\n    H5_CPPFLAGS=\"$H5_CPPFLAGS -UNDEBUG\"\n    AC_MSG_RESULT([yes])\n    ;;\n  X-no)\n    H5_CPPFLAGS=\"$H5_CPPFLAGS -DNDEBUG\"\n    AC_MSG_RESULT([no])\n    ;;\n  *)\n    AC_MSG_ERROR([Unrecognized value: $ASSERTS])\n    ;;\nesac\n\n## ----------------------------------------------------------------------\n## Check if developer warnings should be turned on\n## These are warnings that provide suggestions like gcc's -Wsuggest-attribute.\n## They do not indicate code problems.\n##\n## Note that developers don't need to build with these regularly. They\n## are just handy to check once in a while (before releases, etc.).\n##\nAC_MSG_CHECKING([enable developer warnings])\nAC_ARG_ENABLE([developer-warnings],\n              [AS_HELP_STRING([--enable-developer-warnings],\n                              [Determines whether developer warnings will be\n                               emitted. These are usually performance suggestions\n                               (e.g. -Wsuggest-attribute) and do not flag poor code\n                               quality.\n                               [default=no]\n                               ])],\n              [DEV_WARNINGS=$enableval])\n\n## Set default\nif test \"X-$DEV_WARNINGS\" = X- ; then\n  DEV_WARNINGS=no\nfi\n\n## Allow this variable to be substituted in\n## other files (src/libhdf5.settings.in, etc.)\nAC_SUBST([DEV_WARNINGS])\n\ncase \"X-$DEV_WARNINGS\" in\n  X-yes)\n    H5_CFLAGS=\"$H5_CFLAGS $DEVELOPER_WARNING_CFLAGS\"\n    AC_MSG_RESULT([yes])\n    ;;\n  X-no)\n    H5_CFLAGS=\"$H5_CFLAGS $NO_DEVELOPER_WARNING_CFLAGS\"\n    AC_MSG_RESULT([no])\n    ;;\n  *)\n    AC_MSG_ERROR([Unrecognized value: $DEV_WARNINGS])\n    ;;\nesac\n\n## ----------------------------------------------------------------------\n## Check if the compiler should use profiling flags/settings\n##\nAC_MSG_CHECKING([profiling])\nAC_ARG_ENABLE([profiling],\n              [AS_HELP_STRING([--enable-profiling=(yes|no|<custom>)],\n                              [Enable profiling flags (e.g.: -pg).\n                               This can be set independently from the build mode.\n                               The custom setting can be used to pass alternative\n                               profiling flags (e.g.: -P for using Prof with gcc).\n                               [default=no]\n                               ])],\n              [PROFILING=$enableval])\n\n## Default is no profiling\nif test \"X-$PROFILING\" = X- ; then\n    PROFILING=no\nfi\n\n## Allow this variable to be substituted in\n## other files (src/libhdf5.settings.in, etc.)\nAC_SUBST([PROFILING])\n\ncase \"X-$PROFILING\" in\n  X-yes)\n    H5_CFLAGS=\"$H5_CFLAGS $PROFILE_CFLAGS\"\n    H5_CXXFLAGS=\"$H5_CXXFLAGS $PROFILE_CXXFLAGS\"\n    H5_FCFLAGS=\"$H5_FCFLAGS $PROFILE_FCFLAGS\"\n    AC_MSG_RESULT([yes])\n    ;;\n  X-no)\n    AC_MSG_RESULT([no])\n    ;;\n  *)\n    H5_CFLAGS=\"$H5_CFLAGS $PROFILING\"\n    H5_CXXFLAGS=\"$H5_CXXFLAGS $PROFILING\"\n    H5_FCFLAGS=\"$H5_FCFLAGS $PROFILING\"\n    PROFILING=\"custom ($PROFILING)\"\n    AC_MSG_RESULT([$PROFILING])\n    ;;\nesac\n\n## ----------------------------------------------------------------------\n## Check if the compiler should use a particular optimization setting\n##\nAC_MSG_CHECKING([optimization level])\nAC_ARG_ENABLE([optimization],\n              [AS_HELP_STRING([--enable-optimization=(high|debug|none|<custom>)],\n                              [Enable optimization flags/settings (e.g.: -O3).\n                               This can be set independently from the build mode.\n                               Optimizations for a given compiler can be specified\n                               at several levels: High, with aggressive optimizations\n                               turned on; debug, with optimizations that are\n                               unlikely to interfere with debugging or profiling;\n                               and none, with no optimizations at all.\n                               See the compiler-specific config/*-flags file for more\n                               details.\n                               Alternatively, optimization options can\n                               be specified directly by specifying them as a\n                               string value. These custom optimzation flags will\n                               completely replace all other optimization flags.\n                               [default depends on build mode: debug=debug,\n                                production=high, clean=none]\n                               ])],\n              [OPTIMIZATION=$enableval])\n\n## Set the default optimization level. This depends on the compiler mode.\nif test \"X-$OPTIMIZATION\" = X- ; then\n  case \"X-$BUILD_MODE\" in\n  X-debug)\n    OPTIMIZATION=debug\n    ;;\n  X-production)\n    OPTIMIZATION=high\n    ;;\n  X-clean)\n    OPTIMIZATION=none\n    ;;\n  esac\nfi\n\n## Allow this variable to be substituted in\n## other files (src/libhdf5.settings.in, etc.)\nAC_SUBST([OPTIMIZATION])\n\ncase \"X-$OPTIMIZATION\" in\n  X-high)\n    H5_CFLAGS=\"$H5_CFLAGS $HIGH_OPT_CFLAGS\"\n    H5_CXXFLAGS=\"$H5_CXXFLAGS $HIGH_OPT_CXXFLAGS\"\n    H5_FCFLAGS=\"$H5_FCFLAGS $HIGH_OPT_FCFLAGS\"\n    AC_MSG_RESULT([high])\n    ;;\n  X-debug)\n    H5_CFLAGS=\"$H5_CFLAGS $DEBUG_OPT_CFLAGS\"\n    H5_CXXFLAGS=\"$H5_CXXFLAGS $DEBUG_OPT_CXXFLAGS\"\n    H5_FCFLAGS=\"$H5_FCFLAGS $DEBUG_OPT_FCFLAGS\"\n    AC_MSG_RESULT([debug])\n    ;;\n  X-none)\n    H5_CFLAGS=\"$H5_CFLAGS $NO_OPT_CFLAGS\"\n    H5_CXXFLAGS=\"$H5_CXXFLAGS $NO_OPT_CXXFLAGS\"\n    H5_FCFLAGS=\"$H5_FCFLAGS $NO_OPT_FCFLAGS\"\n    AC_MSG_RESULT([none])\n    ;;\n  *)\n    H5_CFLAGS=\"$H5_CFLAGS $OPTIMIZATION\"\n    H5_CXXFLAGS=\"$H5_CXXFLAGS $OPTIMIZATION\"\n    H5_FCFLAGS=\"$H5_FCFLAGS $OPTIMIZATION\"\n    OPTIMIZATION=\"custom ($OPTIMIZATION)\"\n    AC_MSG_RESULT([$OPTIMIZATION])\n    ;;\nesac\n\n## ----------------------------------------------------------------------\n## Check if file locking should be used\n##\nAC_MSG_CHECKING([enable file locking])\nAC_ARG_ENABLE([file-locking],\n              [AS_HELP_STRING([--enable-file-locking=(yes|no|best-effort)],\n                              [Sets the default for whether or not to use file\n                               locking when opening files. Can be overridden\n                               with the HDF5_USE_FILE_LOCKING environment variable\n                               and the H5Pset_file_locking() API call.\n                               best-effort attempts to use file locking but does\n                               not fail when file locks have been disabled on\n                               the file system (useful with Lustre).\n                               [default=best-effort]\n                               ])],\n              [DESIRED_FILE_LOCKING=$enableval])\n\n## Set defaults\nif test \"X-$DESIRED_FILE_LOCKING\" = X- ; then\n  DESIRED_FILE_LOCKING=best-effort\nfi\n\n## Allow this variable to be substituted in\n## other files (src/libhdf5.settings.in, etc.)\nAC_SUBST([DESIRED_FILE_LOCKING])\nAC_SUBST([USE_FILE_LOCKING])\nAC_SUBST([IGNORE_DISABLED_FILE_LOCKS])\n\ncase \"X-$DESIRED_FILE_LOCKING\" in\n  X-best-effort)\n      AC_MSG_RESULT([best-effort])\n      AC_DEFINE([USE_FILE_LOCKING], [1],\n                [Define if the library will use file locking])\n      AC_DEFINE([IGNORE_DISABLED_FILE_LOCKS], [1],\n                [Define if the library will ignore file locks when disabled])\n    ;;\n  X-yes)\n      AC_MSG_RESULT([yes])\n      AC_DEFINE([USE_FILE_LOCKING], [1],\n                [Define if the library will use file locking])\n    ;;\n  X-no)\n      AC_MSG_RESULT([no])\n    ;;\n  *)\n      AC_MSG_ERROR([Unrecognized value: $USE_FILE_LOCKING])\n    ;;\nesac\n\n\n## ----------------------------------------------------------------------\n## Enable/disable internal package-level debugging output\n##\nAC_MSG_CHECKING([for internal debug output])\nAC_ARG_ENABLE([internal-debug],\n              [AS_HELP_STRING([--enable-internal-debug=(yes|all|no|none|<pkg list>)],\n                              [Enable extra debugging output on HDF5 library\n                               errors. One may also specify a comma-separated\n                               list of package names without the leading H5.\n                               This is independent of the build mode\n                               and is mainly of interest to HDF Group developers.\n                               Yes/all and no/none are synonymous.\n                               [default=all if debug build, otherwise none]\n                               ])],\n              [INTERNAL_DEBUG_OUTPUT=$enableval])\n\n## Set default\nif test \"X-$INTERNAL_DEBUG_OUTPUT\" = X- ; then\n  if test \"X-$BUILD_MODE\" = \"X-debug\" ; then\n    INTERNAL_DEBUG_OUTPUT=all\n  else\n    INTERNAL_DEBUG_OUTPUT=none\n  fi\nfi\n\nAC_SUBST([INTERNAL_DEBUG_OUTPUT])\n\n## These are all the packages that use H5*_DEBUG.\n## There is no harm in specifying a package not in this list;\n## you'll just get an unused H5<pkg>_DEBUG symbol.\n##\n## Some packages that define debug checks or output are\n## too specialized or have huge performance hits. These\n## are not listed in the \"all\" packages list.\n##\n## all_packages=\"AC,B,B2,D,F,FA,FL,FS,HL,I,O,S,ST,T,Z\"\nall_packages=\"AC,B2,CX,D,F,HL,I,O,S,ST,T,Z\"\n\ncase \"X-$INTERNAL_DEBUG_OUTPUT\" in\n  X-yes|X-all)\n    INTERNAL_DEBUG_OUTPUT=$all_packages\n    DEBUG_PKG_LIST=$all_packages\n    ;;\n  X-no|X-none)\n    INTERNAL_DEBUG_OUTPUT=none\n    DEBUG_PKG_LIST=\n    ;;\n  *)\n    DEBUG_PKG_LIST=$INTERNAL_DEBUG_OUTPUT\n    ;;\nesac\nAC_MSG_RESULT([$INTERNAL_DEBUG_OUTPUT])\n\n## Define H5*_DEBUG symbols that control package output\n## NOTE: No sanity checking done here!\nif test -n \"$DEBUG_PKG_LIST\"; then\n  for pkg in `echo $DEBUG_PKG_LIST | ${TR} ${as_cr_letters}\",\" ${as_cr_LETTERS}\" \"`; do\n    H5_CPPFLAGS=\"$H5_CPPFLAGS -DH5${pkg}_DEBUG\"\n  done\nfi\n\n## ----------------------------------------------------------------------\n## Check if they would like the function stack support compiled in\n##\nAC_MSG_CHECKING([whether function stack tracking is enabled])\nAC_ARG_ENABLE([codestack],\n              [AS_HELP_STRING([--enable-codestack],\n                              [Enable the function stack tracing (for developer debugging).\n                               [default=no]\n                              ])],\n              [CODESTACK=$enableval])\n\n## Set the default level.\nif test \"X-$CODESTACK\" = X- ; then\n  CODESTACK=no\nfi\n\n## Allow this variable to be substituted in\n## other files (src/libhdf5.settings.in, etc.)\nAC_SUBST([CODESTACK])\n\ncase \"X-$CODESTACK\" in\n  X-yes)\n      AC_MSG_RESULT([yes])\n      AC_DEFINE([HAVE_CODESTACK], [1],\n                [Define if the function stack tracing code is to be compiled in])\n    ;;\n  X-no)\n      AC_MSG_RESULT([no])\n    ;;\n  *)\n      AC_MSG_ERROR([Unrecognized value: $CODESTACK])\n    ;;\nesac\n\n## ----------------------------------------------------------------------\n## Enable tracing of the API\n##\nAC_MSG_CHECKING([for API tracing]);\nAC_ARG_ENABLE([trace],\n              [AS_HELP_STRING([--enable-trace],\n                              [Enable HDF5 API tracing capability.\n                               [default=yes if debug build, otherwise no]\n                               ])],\n              [TRACE_API=$enableval])\n\n## Set the default level.\nif test \"X-$TRACE_API\" = X- ; then\n  if test \"X-$BUILD_MODE\" = \"X-debug\" ; then\n    TRACE_API=yes\n  else\n    TRACE_API=no\n  fi\nfi\n\n## Allow this variable to be substituted in\n## other files (src/libhdf5.settings.in, etc.)\nAC_SUBST([TRACE_API])\n\ncase \"X-$TRACE_API\" in\n  X-yes)\n    AC_MSG_RESULT([yes])\n    H5_CPPFLAGS=\"$H5_CPPFLAGS -DH5_DEBUG_API\"\n    ;;\n  X-no)\n    AC_MSG_RESULT([no])\n    H5_CPPFLAGS=\"$H5_CPPFLAGS -UH5_DEBUG_API\"\n    ;;\n  *)\n    AC_MSG_ERROR([Unrecognized value: $TRACE_API])\n    ;;\nesac\n\n## ----------------------------------------------------------------------\n## Check if they would like to use a memory checking tool (like valgrind's\n##     'memcheck' tool, or Rational Purify, etc) and the library should be\n##     more scrupulous with it's memory operations.  Enabling this also\n##     disables the library's free space manager code.\n##\nAC_MSG_CHECKING([whether a memory checking tool will be used])\nAC_ARG_ENABLE([using-memchecker],\n              [AS_HELP_STRING([--enable-using-memchecker],\n                              [Enable this option if a memory allocation and/or\n                              bounds checking tool will be used on the HDF5\n                              library.  Enabling this causes the library to be\n                              more picky about its memory operations and also\n                              disables the library's free space manager code.\n                              This option is orthogonal to the\n                              --enable-memory-alloc-sanity-check option.\n                              [default=no]\n                              ])],\n              [USINGMEMCHECKER=$enableval])\n\n## Allow this variable to be substituted in\n## other files (src/libhdf5.settings.in, etc.)\nAC_SUBST([USINGMEMCHECKER])\n\n## Set the default level.\nif test \"X-$USINGMEMCHECKER\" = X- ; then\n  USINGMEMCHECKER=no\nfi\n\ncase \"X-$USINGMEMCHECKER\" in\n  X-yes)\n      AC_DEFINE([USING_MEMCHECKER], [1],\n                [Define if a memory checking tool will be used on the library,\n                to cause library to be very picky about memory operations and\n                also disable the internal free list manager code.])\n      AC_MSG_RESULT([yes])\n    ;;\n  X-no)\n      AC_MSG_RESULT([no])\n    ;;\n  *)\n      AC_MSG_ERROR([Unrecognized value: $USINGMEMCHECKER])\n    ;;\nesac\n\n## ----------------------------------------------------------------------\n## Check if they would like to enable the internal memory allocation sanity\n##     checking code.\n##\nAC_MSG_CHECKING([whether internal memory allocation sanity checking is used])\nAC_ARG_ENABLE([memory-alloc-sanity-check],\n              [AS_HELP_STRING([--enable-memory-alloc-sanity-check],\n                              [Enable this option to turn on internal memory\n                              allocation sanity checking.  This could cause\n                              more memory use and somewhat slower allocation.\n                              This option is orthogonal to the\n                              --enable-using-memchecker option.\n                               [default=yes if debug build, otherwise no]\n                              ])],\n              [MEMORYALLOCSANITYCHECK=$enableval])\n\n## Allow this variable to be substituted in\n## other files (src/libhdf5.settings.in, etc.)\nAC_SUBST([MEMORYALLOCSANITYCHECK])\n\n## Set default\nif test \"X-$MEMORYALLOCSANITYCHECK\" = X- ; then\n  if test \"X-$BUILD_MODE\" = \"X-debug\" ; then\n    MEMORYALLOCSANITYCHECK=yes\n  else\n    MEMORYALLOCSANITYCHECK=no\n  fi\nfi\n\ncase \"X-$MEMORYALLOCSANITYCHECK\" in\n  X-yes)\n      AC_DEFINE([MEMORY_ALLOC_SANITY_CHECK], [1],\n                [Define to enable internal memory allocation sanity checking.])\n      AC_MSG_RESULT([yes])\n    ;;\n  X-no)\n      AC_MSG_RESULT([no])\n    ;;\n  *)\n      AC_MSG_ERROR([Unrecognized value: $MEMORYALLOCSANITYCHECK])\n    ;;\nesac\n\n## Checkpoint the cache\nAC_CACHE_SAVE\n\n## What header files and libraries do we have to look for for parallel\n## support?  For the most part, search paths are already specified with\n## CPPFLAGS and LDFLAGS or are known to the compiler.\n##\nAC_ARG_ENABLE([parallel],\n              [AS_HELP_STRING([--enable-parallel],\n                              [Search for MPI-IO and MPI support files])])\n\n## The --enable-parallel flag is not compatible with --enable-cxx.\n## If the user tried to specify both flags, throw an error, unless\n## they also provided the --enable-unsupported flag.\nif test \"X${ALLOW_UNSUPPORTED}\" != \"Xyes\"; then\n  if test \"X${HDF_CXX}\" = \"Xyes\" -a \"X${enable_parallel}\" = \"Xyes\"; then\n    AC_MSG_ERROR([--enable-cxx and --enable-parallel flags are incompatible. Use --enable-unsupported to override this error.])\n  fi\nfi\n\n## The --enable-parallel flag is not compatible with --enable-java.\n## If the user tried to specify both flags, throw an error, unless\n## they also provided the --enable-unsupported flag.\nif test \"X${ALLOW_UNSUPPORTED}\" != \"Xyes\"; then\n  if test \"X${HDF_JAVA}\" = \"Xyes\" -a \"X${enable_parallel}\" = \"Xyes\"; then\n    AC_MSG_ERROR([--enable-java and --enable-parallel flags are incompatible. Use --enable-unsupported to override this error.])\n  fi\nfi\n\n## --enable-parallel is also incompatible with --enable-threadsafe, unless\n## --enable-unsupported has been specified on the configure line.\nif test \"X${ALLOW_UNSUPPORTED}\" != \"Xyes\"; then\n  if test \"X${THREADSAFE}\" = \"Xyes\" -a \"X${enable_parallel}\" = \"Xyes\"; then\n    AC_MSG_ERROR([--enable-threadsafe and --enable-parallel flags are incompatible. Use --enable-unsupported to override this error.])\n  fi\nfi\n\nAC_MSG_CHECKING([for parallel support files])\ncase \"X-$enable_parallel\" in\n  X-|X-no|X-none)\n    ## We are not compiling for parallel.\n    AC_MSG_RESULT([skipped])\n    ;;\n\n  X-yes)\n    ## We want to compile a parallel library with a compiler that\n    ## may already know how to link with MPI and MPI-IO.\n    AC_MSG_RESULT([provided by compiler])\n    PARALLEL=yes\n\n    ## Try link a simple MPI program.\n    AC_MSG_CHECKING([whether a simple MPI-IO C program can be linked])\n    AC_LINK_IFELSE([AC_LANG_PROGRAM([[#include <mpi.h>]],\n                   [[ MPI_Init(0, (void *)0);\n            MPI_File_open(0, (void *)0, 0, 0, (void *)0);]])],\n        [AC_MSG_RESULT([yes])],\n            [AC_MSG_RESULT([no])\n            AC_MSG_ERROR([unable to link a simple MPI-IO C program])])\n\n    if test \"X$HDF_FORTRAN\" = \"Xyes\"; then\n      PAC_PROG_FC_MPI_CHECK\n    fi\n\n    ## Set RUNPARALLEL to mpiexec if not set yet.\n    if test \"X$PARALLEL\" = \"Xyes\" -a -z \"$RUNPARALLEL\"; then\n      RUNPARALLEL=\"mpiexec -n \\$\\${NPROCS:=6}\"\n    fi\n    ;;\n\n  *)\n    AC_MSG_RESULT([error])\n    AC_MSG_ERROR([\\'$enable_parallel\\' is not a valid parallel search type])\n    ;;\nesac\n\n## ----------------------------------------------------------------------\n## Print some other parallel information and do some sanity checks.\n## Needs to be done outside of the PARALLEL block since the serial\n## build also needs to have values defined.\n##\nAC_SUBST([ADD_PARALLEL_FILES]) ADD_PARALLEL_FILES=\"no\"\nAC_SUBST([MPE]) MPE=no\nAC_SUBST([INSTRUMENT_LIBRARY]) INSTRUMENT_LIBRARY=no\nAC_SUBST([PARALLEL_FILTERED_WRITES])\nAC_SUBST([LARGE_PARALLEL_IO])\n\nif test -n \"$PARALLEL\"; then\n  if test \"X$HDF5_TESTS\" = \"Xyes\"; then\n    ## The 'testpar' directory should participate in the build\n    TESTPARALLEL=testpar\n  fi\n\n  ## We are building a parallel library\n  AC_DEFINE([HAVE_PARALLEL], [1], [Define if we have parallel support])\n\n  ## Display what we found about running programs\n  AC_MSG_CHECKING([prefix for running on one processor])\n  AC_MSG_RESULT([$RUNSERIAL])\n  AC_MSG_CHECKING([prefix for running in parallel])\n  AC_MSG_RESULT([$RUNPARALLEL])\n\n  ## There *must* be some way to run in parallel even if it's just the\n  ## word `none'.\n  if test -z \"$RUNPARALLEL\"; then\n    AC_MSG_ERROR([no way to run a parallel program])\n  fi\n\n  ## If RUNSERIAL or RUNPARALLEL is the word `none' then replace it with\n  ## the empty string. This means that no launch commands were requested,\n  ## so we will not use any launch commands.\n  if test \"X$RUNSERIAL\" = \"Xnone\"; then\n    RUNSERIAL=\"\"\n  fi\n  if test \"X$RUNPARALLEL\" = \"Xnone\"; then\n    RUNPARALLEL=\"\"\n  fi\n\n  if test \"X$HDF_FORTRAN\" = \"Xyes\"; then\n    ADD_PARALLEL_FILES=\"yes\"\n    AC_MSG_CHECKING([for MPI_Comm_c2f and MPI_Comm_f2c functions])\n\n    AC_LINK_IFELSE([AC_LANG_PROGRAM([[\n    #include <mpi.h>\n    ]],\n      [[MPI_Comm c_comm; MPI_Comm_c2f(c_comm)]])],\n      [AC_DEFINE([HAVE_MPI_MULTI_LANG_Comm], [1],\n                 [Define if MPI_Comm_c2f and MPI_Comm_f2c exist])\n                 AC_MSG_RESULT([yes])],\n                 [AC_MSG_RESULT([no])]\n    )\n\n    AC_MSG_CHECKING([for MPI_Info_c2f and MPI_Info_f2c functions])\n    AC_LINK_IFELSE([AC_LANG_PROGRAM([[#include <mpi.h>]],\n      [[MPI_Info c_info; MPI_Info_c2f(c_info)]])],\n      [AC_DEFINE([HAVE_MPI_MULTI_LANG_Info], [1],\n                [Define if MPI_Info_c2f and MPI_Info_f2c exist])\n                AC_MSG_RESULT([yes])],\n                [AC_MSG_RESULT([no])]\n    )\n  fi\n\n  ## ----------------------------------------------------------------------\n  ## Enable instrumenting of the library's internal operations\n  ## in parallel builds.\n  ##\n\n  ## Set default\n  if test \"X-$BUILD_MODE\" = \"X-debug\" ; then\n    INSTRUMENT_LIBRARY=yes\n  else\n    INSTRUMENT_LIBRARY=no\n  fi\n\n  AC_MSG_CHECKING([for instrumented library]);\n  AC_ARG_ENABLE([instrument],\n                [AS_HELP_STRING([--enable-instrument],\n                                [Enable library instrumentation of optimization\n                                  tracing (only used with parallel builds).\n                                  [default=yes if a parallel debug build, otherwise no]\n                                ])],\n                [INSTRUMENT_LIBRARY=$enableval])\n\n  ## Allow this variable to be substituted in\n  ## other files (src/libhdf5.settings.in, etc.)\n  AC_SUBST([INSTRUMENT_LIBRARY])\n\n  case \"X-$INSTRUMENT_LIBRARY\" in\n    X-yes)\n      AC_DEFINE([HAVE_INSTRUMENTED_LIBRARY], [1],\n                [Define if parallel library will contain instrumentation to detect correct optimization operation])\n      AC_MSG_RESULT([yes])\n      ;;\n    X-no)\n      AC_MSG_RESULT([no])\n      ;;\n    *)\n      AC_MSG_ERROR([Unrecognized value: $INSTRUMENT_LIBRARY])\n      ;;\n  esac\n\n  ## --------------------------------------------------------------------\n  ## Do we want MPE instrumentation feature on?\n  ##\n  ## This must be done after enable-parallel is checked since it depends\n  ## on a mpich compiler.\n  ##\n  MPE=yes\n  AC_ARG_WITH([mpe],\n              [AS_HELP_STRING([--with-mpe=DIR],\n                              [Use MPE instrumentation [default=no]])],,\n              [withval=no])\n\n  case \"X-$withval\" in\n    X-|X-no|X-none)\n      AC_MSG_CHECKING([for MPE])\n      AC_MSG_RESULT([suppressed])\n      unset MPE\n      ;;\n    X-yes)\n      AC_CHECK_HEADERS([mpe.h],, [unset MPE])\n      AC_CHECK_LIB([mpe], [MPE_Init_log],, [unset MPE])\n      ;;\n    *)\n      case \"$withval\" in\n        *,*)\n          mpe_inc=\"`echo $withval | cut -f1 -d,`\"\n          mpe_lib=\"`echo $withval | cut -f2 -d, -s`\"\n          ;;\n        *)\n          if test -n \"$withval\"; then\n            mpe_inc=\"$withval/include\"\n            mpe_lib=\"$withval/lib\"\n          fi\n          ;;\n      esac\n\n      if test -n \"$mpe_inc\"; then\n        saved_CPPFLAGS=\"$CPPFLAGS\"\n        saved_AM_CPPFLAGS=\"$AM_CPPFLAGS\"\n        CPPFLAGS=\"$CPPFLAGS -I$mpe_inc\"\n        AM_CPPFLAGS=\"$AM_CPPFLAGS -I$mpe_inc\"\n        AC_CHECK_HEADERS([mpe.h],, [CPPFLAGS=\"$saved_CPPFLAGS\"; AM_CPPFLAGS=\"$saved_AM_CPPFLAGS\"; unset MPE])\n      else\n        AC_CHECK_HEADERS([mpe.h],, [unset MPE])\n      fi\n\n      if test -n \"$mpe_lib\"; then\n        saved_LDFLAGS=\"$LDFLAGS\"\n        saved_AM_LDFLAGS=\"$AM_LDFLAGS\"\n        LDFLAGS=\"$LDFLAGS -L$mpe_lib\"\n        AM_LDFLAGS=\"$AM_LDFLAGS -L$mpe_lib\"\n        AC_CHECK_LIB([mpe], [MPE_Init_log],,\n                     [LDFLAGS=\"$saved_LDFLAGS\"; AM_LDFLAGS=\"$saved_AM_LDFLAGS\"; unset MPE])\n      else\n        AC_CHECK_LIB([mpe], [MPE_Init_log],, [unset MPE])\n      fi\n      ;;\n  esac\n\n  if test \"X-$MPE\" = \"X-yes\"; then\n    AC_DEFINE([HAVE_MPE], [1], [Define if we have MPE support])\n  fi\n\n  ## ----------------------------------------------------------------------\n  ## Check for the MPI-3 functions necessary for the Parallel Compression\n  ## feature. If these are not present, issue a warning that Parallel\n  ## Compression will be disabled.\n  ##\n  AC_MSG_CHECKING([for MPI_Mprobe and MPI_Imrecv functions])\n\n  AC_LINK_IFELSE(\n      [AC_LANG_PROGRAM(\n          [[\n              #include <mpi.h>\n          ]],\n          [[\n              MPI_Message message;\n              MPI_Init(0, (void *) 0);\n              MPI_Mprobe(0, 0, 0, &message, (void *) 0);\n              MPI_Imrecv((void *) 0, 0, 0, (void *) 0, (void *) 0);\n          ]]\n      )],\n      [AC_MSG_RESULT([yes])\n       PARALLEL_FILTERED_WRITES=yes],\n      [AC_MSG_RESULT([no])\n       AC_MSG_WARN([A simple MPI program using the MPI_Mprobe and MPI_Imrecv functions could not be compiled and linked.\n                    Parallel writes of filtered data will be disabled.])\n       PARALLEL_FILTERED_WRITES=no]\n  )\n\n  ## ----------------------------------------------------------------------\n  ## Check for the MPI-3 functions necessary for the big I/O feature.\n  ## If these are not present, issue a warning that the big I/O feature\n  ## will be disabled.\n  ##\n  AC_MSG_CHECKING([for MPI_Get_elements_x and MPI_Type_size_x functions])\n\n  AC_LINK_IFELSE(\n      [AC_LANG_PROGRAM(\n          [[\n              #include <mpi.h>\n          ]],\n          [[\n              MPI_Count count;\n              MPI_Init(0, (void *) 0);\n              MPI_Get_elements_x(0, 0, &count);\n              MPI_Type_size_x(0, &count);\n          ]]\n      )],\n      [AC_MSG_RESULT([yes])\n       LARGE_PARALLEL_IO=yes],\n      [AC_MSG_RESULT([no])\n       AC_MSG_WARN([A simple MPI program using the MPI_Get_elements_x and MPI_Type_size_x functions could not be compiled and linked.\n                    Reading/Writing >2GB of data in a single parallel I/O operation will be disabled.])\n       LARGE_PARALLEL_IO=no]\n  )\n\nfi\n\n## ----------------------------------------------------------------------\n## Check if the map API is enabled by --enable-map-api\n##\nAC_SUBST([MAP_API])\n\n## Default is no map API\nMAP_API=no\n\nAC_MSG_CHECKING([if the map API (H5M) is enabled])\n\nAC_ARG_ENABLE([map-api],\n              [AS_HELP_STRING([--enable-map-api],\n                              [Build the map API (H5M).\n                               This is not yet supported in the native file format\n                               and requires a VOL connector that supports it.\n                               [default=no]])],\n              [MAP_API=$enableval], [MAP_API=no])\n\nif test \"X$MAP_API\" = \"Xyes\"; then\n    AC_MSG_RESULT([yes])\n    AC_DEFINE([HAVE_MAP_API], [1],\n            [Define if the map API (H5M) should be compiled])\nelse\n    AC_MSG_RESULT([no])\nfi\n\n## ----------------------------------------------------------------------\n## Check if Direct I/O driver is enabled by --enable-direct-vfd\n##\nAC_SUBST([DIRECT_VFD])\n\n## Default is no direct VFD\nDIRECT_VFD=no\n\nAC_CACHE_VAL([hdf5_cv_direct_io],\n    AC_CHECK_DECL([O_DIRECT], [hdf5_cv_direct_io=yes], [hdf5_cv_direct_io=no], [[#include <fcntl.h>]]))\nAC_CACHE_VAL([hdf5_cv_posix_memalign],\n    AC_CHECK_FUNC([posix_memalign], [hdf5_cv_posix_memalign=yes], [hdf5_cv_posix_memalign=no]))\n\nAC_MSG_CHECKING([if the direct I/O virtual file driver (VFD) is enabled])\n\nAC_ARG_ENABLE([direct-vfd],\n              [AS_HELP_STRING([--enable-direct-vfd],\n                              [Build the direct I/O virtual file driver (VFD).\n                               This is based on the POSIX (sec2) VFD and\n                               requires the open() call to take the O_DIRECT\n                               flag. [default=no]])],\n              [DIRECT_VFD=$enableval], [DIRECT_VFD=no])\n\nif test \"X$DIRECT_VFD\" = \"Xyes\"; then\n    if test ${hdf5_cv_direct_io} = \"yes\" && test ${hdf5_cv_posix_memalign} = \"yes\" ; then\n        AC_MSG_RESULT([yes])\n        AC_DEFINE([HAVE_DIRECT], [1],\n                [Define if the direct I/O virtual file driver (VFD) should be compiled])\n    else\n        AC_MSG_RESULT([no])\n        DIRECT_VFD=no\n        AC_MSG_ERROR([The direct VFD was requested but cannot be built. This is either\n                     due to O_DIRECT not being found in fcntl.h or a lack of\n                     posix_memalign() on your system. Please re-configure without\n                     specifying --enable-direct-vfd.])\n    fi\nelse\n    AC_MSG_RESULT([no])\nfi\n\n## Direct VFD files are not built if not required.\nAM_CONDITIONAL([DIRECT_VFD_CONDITIONAL], [test \"X$DIRECT_VFD\" = \"Xyes\"])\n\n## ----------------------------------------------------------------------\n## Check whether the Mirror VFD can be built.\n## Auto-enabled if the required libraries are present.\n##\nAC_SUBST([MIRROR_VFD])\n\n## Default is no Mirror VFD\nMIRROR_VFD=no\n\nAC_ARG_ENABLE([mirror-vfd],\n              [AS_HELP_STRING([--enable-mirror-vfd],\n                              [Build the socket-based Mirror virtual file driver (VFD).\n                               [default=no]])],\n              [MIRROR_VFD=$enableval], [MIRROR_VFD=no])\n\nif test \"X$MIRROR_VFD\" = \"Xyes\"; then\n\n    AC_CHECK_HEADERS([arpa/inet.h],, [unset MIRROR_VFD])\n    AC_CHECK_HEADERS([netinet/in.h],, [unset MIRROR_VFD])\n    AC_CHECK_HEADERS([netdb.h],, [unset MIRROR_VFD])\n    AC_CHECK_HEADERS([sys/socket.h],, [unset MIRROR_VFD])\n    AC_CHECK_FUNC([fork], [], [unset MIRROR_VFD])\n\n    AC_MSG_CHECKING([if the Mirror virtual file driver (VFD) can be built])\n    if test \"X$MIRROR_VFD\" = \"Xyes\"; then\n        AC_DEFINE([HAVE_MIRROR_VFD], [1],\n                [Define whether the Mirror virtual file driver (VFD) will be compiled])\n        AC_MSG_RESULT([yes])\n    else\n        AC_MSG_RESULT([no])\n        MIRROR_VFD=no\n        AC_MSG_ERROR([The Mirror VFD cannot be built.\n                      Missing one or more of: arpa/inet.h, netinet/in.h,\n                      netdb.h, sys/socket.h, fork().])\n    fi\nelse\n    AC_MSG_CHECKING([if the Mirror virtual file driver (VFD) is enabled])\n    AC_MSG_RESULT([no])\n    MIRROR_VFD=no\nfi\n\n## Mirror VFD files built only if able.\nAM_CONDITIONAL([MIRROR_VFD_CONDITIONAL], [test \"X$MIRROR_VFD\" = \"Xyes\"])\n\n## ----------------------------------------------------------------------\n## Check if Read-Only S3 virtual file driver is enabled by --enable-ros3-vfd\n##\nAC_SUBST([ROS3_VFD])\n\n## Default is no Read-Only S3 VFD\nROS3_VFD=no\n\nAC_ARG_ENABLE([ros3-vfd],\n              [AS_HELP_STRING([--enable-ros3-vfd],\n                              [Build the Read-Only S3 virtual file driver (VFD).\n                               [default=no]])],\n              [ROS3_VFD=$enableval], [ROS3_VFD=no])\n\nif test \"X$ROS3_VFD\" = \"Xyes\"; then\n    AC_CHECK_HEADERS([curl/curl.h],, [unset ROS3_VFD])\n    AC_CHECK_HEADERS([openssl/evp.h],, [unset ROS3_VFD])\n    AC_CHECK_HEADERS([openssl/hmac.h],, [unset ROS3_VFD])\n    AC_CHECK_HEADERS([openssl/sha.h],, [unset ROS3_VFD])\n    if test \"X$ROS3_VFD\" = \"Xyes\"; then\n        AC_CHECK_LIB([curl], [curl_global_init],, [unset ROS3_VFD])\n        AC_CHECK_LIB([crypto], [EVP_sha256],, [unset ROS3_VFD])\n    fi\n\n    AC_MSG_CHECKING([if the Read-Only S3 virtual file driver (VFD) is enabled])\n    if test \"X$ROS3_VFD\" = \"Xyes\"; then\n        AC_DEFINE([HAVE_ROS3_VFD], [1],\n                [Define whether the Read-Only S3 virtual file driver (VFD) should be compiled])\n        AC_MSG_RESULT([yes])\n    else\n        AC_MSG_RESULT([no])\n        ROS3_VFD=no\n        AC_MSG_ERROR([The Read-Only S3 VFD was requested but cannot be built.\n                      Please check that openssl and cURL are available on your\n                      system, and/or re-configure without option\n                      --enable-ros3-vfd.])\n    fi\nelse\n    AC_MSG_CHECKING([if the Read-Only S3 virtual file driver (VFD) is enabled])\n    AC_MSG_RESULT([no])\n    ROS3_VFD=no\n\nfi\n\n## Read-only S3 files are not built if not required.\nAM_CONDITIONAL([ROS3_VFD_CONDITIONAL], [test \"X$ROS3_VFD\" = \"Xyes\"])\n\n\n## ----------------------------------------------------------------------\n## Is libhdfs (Hadoop Distributed File System) present?\n## It might be specified with the `--with-libhdfs' command-line switch.\n## If found, enables the HDFS VFD.\n##\nAC_SUBST([HAVE_LIBHDFS])\nAC_ARG_WITH([libhdfs],\n            [AS_HELP_STRING([--with-libhdfs=DIR],\n                            [Provide libhdfs library to enable HDFS virtual file driver (VFD) [default=no]])],,\n            [withval=no])\n\ncase $withval in\n  no)\n    HAVE_LIBHDFS=\"no\"\n    AC_MSG_CHECKING([for libhdfs])\n    AC_MSG_RESULT([suppressed])\n    ;;\n  *)\n    HAVE_LIBHDFS=\"yes\"\n    case \"$withval\" in\n      *,*)\n        libhdfs_inc=\"`echo $withval |cut -f1 -d,`\"\n        libhdfs_lib=\"`echo $withval |cut -f2 -d, -s`\"\n        ;;\n      yes)\n        libhdfs_inc=\"$HADOOP_HOME/include\"\n        libhdfs_lib=\"$HADOOP_HOME/lib\"\n        ;;\n      *)\n        if test -n \"$withval\"; then\n          libhdfs_inc=\"$withval/include\"\n          libhdfs_lib=\"$withval/lib\"\n        fi\n        ;;\n    esac\n\n    if test -n \"$libhdfs_inc\"; then\n      CPPFLAGS=\"$CPPFLAGS -I$libhdfs_inc\"\n      AM_CPPFLAGS=\"$AM_CPPFLAGS -I$libhdfs_inc\"\n    fi\n    AC_CHECK_HEADERS([hdfs.h],,\n                     [unset HAVE_LIBHDFS])\n\n    if test \"x$HAVE_LIBHDFS\" = \"xyes\"; then\n      dnl Check for '-ljvm' needed by libhdfs\n      JNI_LDFLAGS=\"\"\n      if test $JAVA_HOME != \"\"\n      then\n        JNI_LDFLAGS=\"-L$JAVA_HOME/jre/lib/$OS_ARCH -L$JAVA_HOME/jre/lib/$OS_ARCH/server\"\n      fi\n      ldflags_bak=$LDFLAGS\n      LDFLAGS=\"$LDFLAGS $JNI_LDFLAGS\"\n      AC_CHECK_LIB([jvm], [JNI_GetCreatedJavaVMs])\n      LDFLAGS=$ldflags_bak\n      AC_SUBST([JNI_LDFLAGS])\n      if test -n \"$libhdfs_lib\"; then\n        ## Hadoop distribution hides libraries down one level in 'lib/native'\n        libhdfs_lib=\"$libhdfs_lib/native\"\n        LDFLAGS=\"$LDFLAGS -L$libhdfs_lib $JNI_LDFLAGS\"\n        AM_LDFLAGS=\"$AM_LDFLAGS -L$libhdfs_lib $JNI_LDFLAGS\"\n      fi\n      AC_CHECK_LIB([hdfs], [hdfsConnect],,\n                   [unset HAVE_LIBHDFS])\n    fi\n\n    if test -z \"$HAVE_LIBHDFS\"; then\n      AC_MSG_ERROR([Set to use libhdfs library, but could not find or use\n                    libhdfs. Please verify that the path to HADOOP_HOME is\n                    valid, and/or reconfigure without --with-libhdfs.])\n    fi\n    ;;\nesac\n\nif test \"x$HAVE_LIBHDFS\" = \"xyes\"; then\n  AC_DEFINE([HAVE_LIBHDFS], [1],\n            [Proceed to build with libhdfs])\nfi\n\n## Checkpoint the cache\nAC_CACHE_SAVE\n\n## ----------------------------------------------------------------------\n## Use custom examples path.\n##\nAC_MSG_CHECKING([for custom examples path definition])\nAC_ARG_WITH([examplesdir],\n            [AS_HELP_STRING([--with-examplesdir=location],\n                            [Specify path for examples\n                            [default=\"DATAROOTDIR/hdf5_examples\"]])],,\n            withval=\"${datarootdir}/hdf5_examples\")\n\nif test \"X$withval\" = \"X\"; then\n    AC_MSG_RESULT([default])\n    examplesdir=\"${datarootdir}/hdf5_examples\"\nelse\n    AC_MSG_RESULT([$withval])\n    examplesdir=$withval\nfi\n\nAC_SUBST([examplesdir])\nAC_DEFINE_UNQUOTED([EXAMPLESDIR], [\"$examplesdir\"],\n            [Define the examples directory])\n\n## ----------------------------------------------------------------------\n## Enable custom plugin default path for library.  It requires SHARED support.\n##\nAC_MSG_CHECKING([for custom plugin default path definition])\nAC_ARG_WITH([default-plugindir],\n            [AS_HELP_STRING([--with-default-plugindir=location],\n                            [Specify default location for plugins\n                            [default=\"/usr/local/hdf5/lib/plugin\"]])],,\n            withval=\"/usr/local/hdf5/lib/plugin\")\n\nif test \"X$withval\" = \"X\"; then\n    AC_MSG_RESULT([default])\n    default_plugindir=\"/usr/local/hdf5/lib/plugin\"\nelse\n    AC_MSG_RESULT([$withval])\n    default_plugindir=$withval\nfi\n\nAC_DEFINE_UNQUOTED([DEFAULT_PLUGINDIR], [\"$default_plugindir\"],\n            [Define the default plugins path to compile])\n\n## ----------------------------------------------------------------------\n## Decide whether the presence of user's exception handling functions is\n## checked and data conversion exceptions are returned.  This is mainly\n## for the speed optimization of hard conversions.  Soft conversions can\n## actually benefit little.\n##\nAC_MSG_CHECKING([whether exception handling functions is checked during data conversions])\nAC_ARG_ENABLE([dconv-exception],\n              [AS_HELP_STRING([--enable-dconv-exception],\n                              [if exception handling functions is checked during\n                              data conversions [default=yes]])],\n              [DCONV_EXCEPTION=$enableval], [DCONV_EXCEPTION=yes])\n\nif test \"$DCONV_EXCEPTION\" = \"yes\"; then\n  AC_MSG_RESULT([yes])\n  AC_DEFINE([WANT_DCONV_EXCEPTION], [1],\n            [Check exception handling functions during data conversions])\nelse\n  AC_MSG_RESULT([no])\nfi\n\n## ----------------------------------------------------------------------\n## Decide whether the data accuracy has higher priority during data\n## conversions.  If not, some hard conversions will still be prefered even\n## though the data may be wrong (for example, some compilers don't\n## support denormalized floating values) to maximize speed.\n##\nAC_MSG_CHECKING([whether data accuracy is guaranteed during data conversions])\nAC_ARG_ENABLE([dconv-accuracy],\n              [AS_HELP_STRING([--enable-dconv-accuracy],\n                              [if data accuracy is guaranteed during\n                              data conversions [default=yes]])],\n              [DATA_ACCURACY=$enableval], [DATA_ACCURACY=yes])\n\nif test \"$DATA_ACCURACY\" = \"yes\"; then\n  AC_MSG_RESULT([yes])\n  AC_DEFINE([WANT_DATA_ACCURACY], [1],\n            [Data accuracy is prefered to speed during data conversions])\nelse\n  AC_MSG_RESULT([no])\nfi\n\n## ----------------------------------------------------------------------\n## Set the flag to indicate that the machine has window style pathname,\n## that is, \"drive-letter:\\\" (e.g. \"C:\") or \"drive-letter:/\" (e.g. \"C:/\").\n## (This flag should be _unset_ for all machines, except for Windows, where\n## it's set in the custom Windows H5pubconf.h file)\n##\nAC_MSG_CHECKING([if the machine has window style path name])\n\ncase \"`uname`\" in\n  MINGW*)\n    AC_DEFINE([HAVE_WINDOW_PATH], [1],\n              [Define if your system has window style path name.])\n    AC_MSG_RESULT([yes])\n    ;;\n  *)\n    AC_MSG_RESULT([no])\n    ;;\nesac\n\n## ----------------------------------------------------------------------\n## Set the flag to indicate that the machine is using a special algorithm to convert\n## 'long double' to '(unsigned) long' values.  (This flag should only be set for\n## the IBM Power6 Linux.  When the bit sequence of long double is\n## 0x4351ccf385ebc8a0bfcc2a3c3d855620, the converted value of (unsigned)long\n## is 0x004733ce17af227f, not the same as the library's conversion to 0x004733ce17af2282.\n## The machine's conversion gets the correct value.  We define the macro and disable\n## this kind of test until we figure out what algorithm they use.\n##\nAC_MSG_CHECKING([if using special algorithm to convert long double to (unsigned) long values])\n\n## NOTE: Place all configure test programs into cmake's source file, then use a preprocessor directive\n## to select the proper test program. This is done by echoing the #define and cat'ing the cmake\n## source file. (HDFFV-9467)\n\nTEST_SRC=\"`(echo \\\"#define H5_LDOUBLE_TO_LONG_SPECIAL_TEST 1\\\"; cat $srcdir/config/cmake/ConversionTests.c)`\"\n\nif test ${ac_cv_sizeof_long_double} = 0; then\n   hdf5_cv_ldouble_to_long_special=${hdf5_cv_ldouble_to_long_special=no}\nelse\n   AC_CACHE_VAL([hdf5_cv_ldouble_to_long_special],\n        [AC_RUN_IFELSE(\n            [AC_LANG_SOURCE([$TEST_SRC])]\n    , [hdf5_cv_ldouble_to_long_special=yes], [hdf5_cv_ldouble_to_long_special=no],)])\nfi\n\nif test ${hdf5_cv_ldouble_to_long_special} = \"yes\"; then\n  AC_DEFINE([LDOUBLE_TO_LONG_SPECIAL], [1],\n            [Define if your system converts long double to (unsigned) long values with special algorithm.])\n  AC_MSG_RESULT([yes])\nelse\n  AC_MSG_RESULT([no])\nfi\n\n## ----------------------------------------------------------------------\n## Set the flag to indicate that the machine is using a special algorithm\n## to convert some values of '(unsigned) long' to 'long double' values.\n## (This flag should be off for all machines, except for IBM Power6 Linux,\n## when the bit sequences are 003fff..., 007fff..., 00ffff..., 01ffff...,\n## ..., 7fffff..., the compiler uses a unknown algorithm.  We define a\n## macro and skip the test for now until we know about the algorithm.\n##\nAC_MSG_CHECKING([if using special algorithm to convert (unsigned) long to long double values])\n\nTEST_SRC=\"`(echo \\\"#define H5_LONG_TO_LDOUBLE_SPECIAL_TEST 1\\\"; cat $srcdir/config/cmake/ConversionTests.c)`\"\n\nif test ${ac_cv_sizeof_long_double} = 0; then\n   hdf5_cv_long_to_ldouble_special=${hdf5_cv_long_to_ldouble_special=no}\nelse\n   AC_CACHE_VAL([hdf5_cv_long_to_ldouble_special],\n        [AC_RUN_IFELSE(\n            [AC_LANG_SOURCE([$TEST_SRC])]\n    , [hdf5_cv_long_to_ldouble_special=yes], [hdf5_cv_long_to_ldouble_special=no],)])\nfi\n\nif test ${hdf5_cv_long_to_ldouble_special} = \"yes\"; then\n  AC_DEFINE([LONG_TO_LDOUBLE_SPECIAL], [1],\n            [Define if your system can convert (unsigned) long to long double values with special algorithm.])\n  AC_MSG_RESULT([yes])\nelse\n  AC_MSG_RESULT([no])\nfi\n\n## ----------------------------------------------------------------------\n## Set the flag to indicate that the machine can accurately convert\n## 'long double' to '(unsigned) long long' values.  (This flag should\n## be set for all machines, except for Mac OS 10.4, SGI IRIX64 6.5 and\n## Powerpc Linux using XL compilers.\n## When the bit sequence of long double is 0x4351ccf385ebc8a0bfcc2a3c...,\n## the values of (unsigned)long long start to go wrong on these\n## two machines.  Adjusting it higher to 0x4351ccf385ebc8a0dfcc... or\n## 0x4351ccf385ebc8a0ffcc... will make the converted values wildly wrong.\n## This test detects this wrong behavior and disable the test.\n##\nAC_MSG_CHECKING([if correctly converting long double to (unsigned) long long values])\n\nTEST_SRC=\"`(echo \\\"#define H5_LDOUBLE_TO_LLONG_ACCURATE_TEST 1\\\"; cat $srcdir/config/cmake/ConversionTests.c)`\"\n\nif test ${ac_cv_sizeof_long_double} = 0; then\n   hdf5_cv_ldouble_to_llong_accurate=${hdf5_cv_ldouble_to_llong_accurate=no}\nelse\n   AC_CACHE_VAL([hdf5_cv_ldouble_to_llong_accurate],\n        [AC_RUN_IFELSE([AC_LANG_SOURCE([$TEST_SRC])],\n        [hdf5_cv_ldouble_to_llong_accurate=yes], [hdf5_cv_ldouble_to_llong_accurate=no],[])])\nfi\n\nif test ${hdf5_cv_ldouble_to_llong_accurate} = \"yes\"; then\n  AC_DEFINE([LDOUBLE_TO_LLONG_ACCURATE], [1],\n            [Define if your system can convert long double to (unsigned) long long values correctly.])\n  AC_MSG_RESULT([yes])\nelse\n  AC_MSG_RESULT([no])\nfi\n\n\n## ----------------------------------------------------------------------\n## Set the flag to indicate that the machine can accurately convert\n## '(unsigned) long long' to 'long double' values.  (This flag should be\n## set for all machines, except for Mac OS 10.4 and Powerpc Linux using\n## XL compilers.\n## When the bit sequences are 003fff..., 007fff..., 00ffff..., 01ffff...,\n## ..., 7fffff..., the converted values are twice as big as they should be.\n##\nAC_MSG_CHECKING([if correctly converting (unsigned) long long to long double values])\n\nTEST_SRC=\"`(echo \\\"#define H5_LLONG_TO_LDOUBLE_CORRECT_TEST 1\\\"; cat $srcdir/config/cmake/ConversionTests.c)`\"\n\nif test ${ac_cv_sizeof_long_double} = 0; then\n   hdf5_cv_llong_to_ldouble_correct=${hdf5_cv_llong_to_ldouble_correct=no}\nelse\n   AC_CACHE_VAL([hdf5_cv_llong_to_ldouble_correct],\n        [AC_RUN_IFELSE([AC_LANG_SOURCE([$TEST_SRC])],\n        [hdf5_cv_llong_to_ldouble_correct=yes], [hdf5_cv_llong_to_ldouble_correct=no],[])])\nfi\n\nif test ${hdf5_cv_llong_to_ldouble_correct} = \"yes\"; then\n  AC_DEFINE([LLONG_TO_LDOUBLE_CORRECT], [1],\n            [Define if your system can convert (unsigned) long long to long double values correctly.])\n  AC_MSG_RESULT([yes])\nelse\n  AC_MSG_RESULT([no])\nfi\n\n## ----------------------------------------------------------------------\n## Set the flag to indicate that the machine is IBM ppc64le and cannot\n## accurately convert some long double values.\n##\nAC_MSG_CHECKING([if the system is IBM ppc64le and cannot correctly convert some long double values])\n\nTEST_SRC=\"`(echo \\\"#define H5_DISABLE_SOME_LDOUBLE_CONV_TEST 1\\\"; cat $srcdir/config/cmake/ConversionTests.c)`\"\n\nif test ${ac_cv_sizeof_long_double} = 0; then\n   hdf5_cv_disable_some_ldouble_conv=${hdf5_cv_disable_some_ldouble_conv=no}\nelse\n   AC_CACHE_VAL([hdf5_cv_disable_some_ldouble_conv],\n        [AC_RUN_IFELSE([AC_LANG_SOURCE([$TEST_SRC])],\n        [hdf5_cv_disable_some_ldouble_conv=yes], [hdf5_cv_disable_some_ldouble_conv=no],[])])\nfi\n\nif test ${hdf5_cv_disable_some_ldouble_conv} = \"yes\"; then\n  AC_DEFINE([DISABLE_SOME_LDOUBLE_CONV], [1],\n            [Define if your system is IBM ppc64le and cannot convert some long double values correctly.])\n  AC_MSG_RESULT([yes])\nelse\n  AC_MSG_RESULT([no])\nfi\n\n## ----------------------------------------------------------------------\n## Set some variables for general configuration information to be saved\n## and installed with the libraries (used to generate libhdf5.settings).\n##\n\n## HDF5 version from the first line of the README.txt file.\nH5_VERSION=\"`cut -d' ' -f3 $srcdir/README.txt | head -1`\"\nAC_SUBST([H5_VERSION])\n\n## Configuration date\nAC_SUBST([CONFIG_DATE]) CONFIG_DATE=\"`date`\"\n\n## User doing the configuration\nAC_SUBST([CONFIG_USER]) CONFIG_USER=\"`whoami`@`hostname`\"\nif test -n \"$ORGANIZATION\"; then\n  CONFIG_USER=\"$CONFIG_USER at $ORGANIZATION\"\nfi\n\n## Configuration mode (production, debug, etc.) saved above.\nAC_SUBST([CONFIG_MODE])\n\n## Byte sex from the AC_C_BIGENDIAN macro.\nAC_SUBST([BYTESEX])\nif test \"X$ac_cv_c_bigendian\" = \"Xyes\"; then\n  BYTESEX=\"big-endian\"\nelse\n  BYTESEX=\"little-endian\"\nfi\n\n\nif test \"X$ac_cv_c_bigendian\" = \"Xyes\"; then\n  WORDS_BIGENDIAN=\"yes\"\nelse\n  WORDS_BIGENDIAN=\"no\"\nfi\nAC_SUBST([WORDS_BIGENDIAN])\n\n## Parallel support? (set above except empty if none)\nPARALLEL=${PARALLEL:-no}\n\n## Parallel writes to filtered datasets support?\nPARALLEL_FILTERED_WRITES=${PARALLEL_FILTERED_WRITES:-no}\n\n## >2GB writes in parallel support?\nLARGE_PARALLEL_IO=${LARGE_PARALLEL_IO:-no}\n\n## Compiler with version information. This consists of the full path\n## name of the compiler and the reported version number.\nAC_SUBST([CC_VERSION])\n## Strip anything that looks like a flag off of $CC\nCC_NOFLAGS=`echo $CC | sed 's/ -.*//'`\n\nif `echo $CC_NOFLAGS | grep ^/ >/dev/null 2>&1`; then\n  CC_VERSION=\"$CC\"\nelse\n  CC_VERSION=\"$CC\";\n  for x in `echo $PATH | sed -e 's/:/ /g'`; do\n    if test -x $x/$CC_NOFLAGS; then\n      CC_VERSION=\"$x/$CC\"\n      break\n    fi\n  done\nfi\nif test -n \"$cc_version_info\"; then\n  CC_VERSION=\"$CC_VERSION ( $cc_version_info)\"\nfi\n\nAC_SUBST([FC_VERSION])\n## Strip anything that looks like a flag off of $FC\nFC_NOFLAGS=`echo $FC | sed 's/ -.*//'`\n\nif `echo $FC_NOFLAGS | grep ^/ >/dev/null 2>&1`; then\n  FC_VERSION=\"$FC\"\nelse\n  FC_VERSION=\"$FC\";\n  for x in `echo $PATH | sed -e 's/:/ /g'`; do\n    if test -x $x/$FC_NOFLAGS; then\n      FC_VERSION=\"$x/$FC\"\n      break\n    fi\n  done\nfi\nif test -n \"$fc_version_info\"; then\n  FC_VERSION=\"$FC_VERSION ( $fc_version_info)\"\nfi\n\nAC_SUBST([CXX_VERSION])\n## Strip anything that looks like a flag off of $CXX\nCXX_NOFLAGS=`echo $CXX | sed 's/ -.*//'`\n\nif `echo $CXX_NOFLAGS | grep ^/ >/dev/null 2>&1`; then\n  CXX_VERSION=\"$CXX\"\nelse\n  CXX_VERSION=\"$CXX\";\n  for x in `echo $PATH | sed -e 's/:/ /g'`; do\n    if test -x $x/$CXX_NOFLAGS; then\n      CXX_VERSION=\"$x/$CXX\"\n      break\n    fi\n  done\nfi\nif test -n \"$cxx_version_info\"; then\n  CXX_VERSION=\"$CXX_VERSION ( $cxx_version_info)\"\nfi\n\nAC_SUBST([JAVA_VERSION])\n## Strip anything that looks like a flag off of $JAVA\nJAVA_NOFLAGS=`echo $JAVA | sed 's/ -.*//'`\n\nif `echo $JAVA_NOFLAGS | grep ^/ >/dev/null 2>&1`; then\n  JAVA_VERSION=\"$JAVA\"\nelse\n  JAVA_VERSION=\"$JAVA\";\n  for x in `echo $PATH | sed -e 's/:/ /g'`; do\n    if test -x $x/$JAVA_NOFLAGS; then\n      JAVA_VERSION=\"$x/$JAVA\"\n      break\n    fi\n  done\nfi\njava_version_info=`$JAVA -version 2>&1 |\\\n  grep 'version' | sed -e 's/version \"//' | sed -e 's/\"//'`\nif test -n \"$java_version_info\"; then\n  JAVA_VERSION=\"$JAVA_VERSION ($java_version_info)\"\nfi\n\n## ----------------------------------------------------------------------\n## Where is the root of the source tree. Give an absolute address so\n## we can find it no matter which directory of the distribution is our\n## current directory. The built-in pwd fails on some systems, but the\n## /bin/pwd version works OK.\n##\nif test -x /bin/pwd; then\n  pwd=/bin/pwd\nelse\n  pwd=pwd\nfi\nAC_SUBST([ROOT]) ROOT=\"`$pwd`\"\n\n## ----------------------------------------------------------------------\n## Some programs shouldn't be built by default (e.g., programs to generate\n## data files used by tests, some optional tests).\n## Check if they want such programs built anyway.\n##\nAC_MSG_CHECKING([additional programs should be built])\nAC_ARG_ENABLE([build-all],\n     [AS_HELP_STRING([--enable-build-all],\n                     [Build helper programs that only developers should need [default=no]])],\n     [BUILD_ALL=$enableval],\n     [BUILD_ALL=no])\n\nif test \"X$BUILD_ALL\" = \"Xyes\"; then\n echo \"yes\"\nelse\n echo \"no\"\nfi\nAM_CONDITIONAL([BUILD_ALL_CONDITIONAL], [test \"X$BUILD_ALL\" = \"Xyes\"])\n\n## ----------------------------------------------------------------------\n## Enable deprecated public API symbols\n##\n\n## Enabled unless the build mode is clean.\nif test \"X-$BUILD_MODE\" = \"X-clean\" ; then\n  DEPREC_SYMBOLS=no\nelse\n  DEPREC_SYMBOLS=yes\nfi\n\nAC_SUBST([DEPRECATED_SYMBOLS])\nAC_MSG_CHECKING([if deprecated public symbols are available]);\nAC_ARG_ENABLE([deprecated-symbols],\n              [AS_HELP_STRING([--enable-deprecated-symbols],\n                     [Enable deprecated public API symbols.\n                     [default=yes (unless build mode = clean)]\n                     ])],\n              [DEPREC_SYMBOLS=$enableval])\n\ncase \"X-$DEPREC_SYMBOLS\" in\n  X-yes)\n    AC_MSG_RESULT([yes])\n    DEPRECATED_SYMBOLS=yes\n    ;;\n  X-no|*)\n    AC_MSG_RESULT([no])\n    DEPRECATED_SYMBOLS=no\n    AC_DEFINE([NO_DEPRECATED_SYMBOLS], [1],\n              [Define if deprecated public API symbols are disabled])\n    ;;\nesac\n\n## --------------------------------------------------------------------------\n## Which version of the public APIs should the 'base' versioned symbols use?\n##\n\nAC_SUBST([DEFAULT_API_VERSION])\nAC_MSG_CHECKING([which version of public symbols to use by default])\nAC_ARG_WITH([default-api-version],\n            [AS_HELP_STRING([--with-default-api-version=(v16|v18|v110|v112|v114)],\n                            [Specify default release version of public symbols\n                             [default=v114]])],,\n            [withval=v114])\n\nif test \"X$withval\" = \"Xv16\"; then\n    AC_MSG_RESULT([v16])\n    DEFAULT_API_VERSION=v16\n    AC_DEFINE([USE_16_API_DEFAULT], [1],\n              [Define using v1.6 public API symbols by default])\nelif test \"X$withval\" = \"Xv18\"; then\n    AC_MSG_RESULT([v18])\n    DEFAULT_API_VERSION=v18\n    AC_DEFINE([USE_18_API_DEFAULT], [1],\n              [Define using v1.8 public API symbols by default])\nelif test \"X$withval\" = \"Xv110\"; then\n    AC_MSG_RESULT([v110])\n    DEFAULT_API_VERSION=v110\n    AC_DEFINE([USE_110_API_DEFAULT], [1],\n              [Define using v1.10 public API symbols by default])\nelif test \"X$withval\" = \"Xv112\"; then\n    AC_MSG_RESULT([v112])\n    DEFAULT_API_VERSION=v112\n    AC_DEFINE([USE_112_API_DEFAULT], [1],\n              [Define using v1.12 public API symbols by default])\nelif test \"X$withval\" = \"Xv114\"; then\n    AC_MSG_RESULT([v114])\n    DEFAULT_API_VERSION=v114\n    AC_DEFINE([USE_114_API_DEFAULT], [1],\n              [Define using v1.14 public API symbols by default])\nelse\n    AC_MSG_ERROR([invalid version of public symbols given])\nfi\n\n## It's an error to try to disable deprecated public API symbols while\n## choosing an older version of the public API as the default. However,\n## if the user insists on doing this via the --enable-unsupported configure\n## flag, we'll let them.\nif test \"X${ALLOW_UNSUPPORTED}\" != \"Xyes\"; then\n  if test \"X${DEFAULT_API_VERSION}\" != \"Xv114\" -a \"X${DEPRECATED_SYMBOLS}\" = \"Xno\" ; then\n    AC_MSG_ERROR([Removing old public API symbols not allowed when using them as default public API symbols. Use --enable-unsupported to override this error.])\n  fi\nfi\n\n## ----------------------------------------------------------------------\n## Enable strict file format checks\n##\nAC_SUBST([STRICT_FORMAT_CHECKS])\nAC_MSG_CHECKING([whether to perform strict file format checks]);\nAC_ARG_ENABLE([strict-format-checks],\n              [AS_HELP_STRING([--enable-strict-format-checks],\n                     [Enable strict file format checks.\n                      [default=yes if debug build, otherwise no]\n                     ])],\n             [STRICT_FORMAT_CHECKS=$enableval])\n\n## Set the default level. This depends on the compiler mode.\nif test \"X-$STRICT_FORMAT_CHECKS\" = X- ; then\n  if test \"X-$BUILD_MODE\" = \"X-debug\" ; then\n    STRICT_FORMAT_CHECKS=yes\n  else\n    STRICT_FORMAT_CHECKS=no\n  fi\nfi\n\ncase \"X-$STRICT_FORMAT_CHECKS\" in\n  X-yes)\n    AC_MSG_RESULT([yes])\n    AC_DEFINE([STRICT_FORMAT_CHECKS], [1],\n              [Define if strict file format checks are enabled])\n    ;;\n  X-no)\n    AC_MSG_RESULT([no])\n    ;;\n  *)\n    AC_MSG_ERROR([Unrecognized value: $STRICT_FORMAT_CHECKS])\n    ;;\nesac\n\n\n## ----------------------------------------------------------------------\n## Enable use of pread/pwrite instead of read/write in certain VFDs.\n##\nAC_SUBST([PREADWRITE])\n\n## Check these first to avoid interspersed output in the AC_ARG_ENABLE line\n## below. (Probably overkill to check for both, but we'll be extra careful)\nPREADWRITE_HAVE_BOTH=yes\nAC_CHECK_FUNC([pread], [], [PREADWRITE_HAVE_BOTH=no])\nAC_CHECK_FUNC([pwrite], [], [PREADWRITE_HAVE_BOTH=no])\n\nAC_MSG_CHECKING([whether to use pread/pwrite instead of read/write in certain VFDs])\nAC_ARG_ENABLE([preadwrite],\n              [AS_HELP_STRING([--enable-preadwrite],\n                              [Enable using pread/pwrite instead of read/write in sec2/log/core VFDs.\n                              [default=yes if pread/pwrite are present]])],\n              [PREADWRITE=$enableval])\n\n## Set the default level.\nif test \"X-$PREADWRITE\" = X- ; then\n  PREADWRITE=yes\nfi\n\ncase \"X-$PREADWRITE\" in\n  X-yes)\n      if test \"X-$PREADWRITE_HAVE_BOTH\" = \"X-yes\"; then\n        AC_DEFINE([HAVE_PREADWRITE], [1], [Define if both pread and pwrite exist.])\n        AC_MSG_RESULT([yes])\n      else\n        AC_MSG_RESULT([no])\n      fi\n    ;;\n  X-no)\n      AC_MSG_RESULT([no])\n    ;;\n  *)\n      AC_MSG_ERROR([Unrecognized value: $PREADWRITE])\n    ;;\nesac\n\n\n## ----------------------------------------------------------------------\n## Enable embedded library information\n##\nAC_MSG_CHECKING([whether to have library information embedded in the executables])\nAC_ARG_ENABLE([embedded-libinfo],\n    [AS_HELP_STRING([--enable-embedded-libinfo],\n    [Enable embedded library information [default=yes]])],\n    [enable_embedded_libinfo=$enableval],\n    [enable_embedded_libinfo=yes])\n\n   if test \"${enable_embedded_libinfo}\" = \"yes\"; then\n      AC_MSG_RESULT([yes])\n      AC_DEFINE([HAVE_EMBEDDED_LIBINFO], [1],\n                [Define if library information should be embedded in the executables])\n   else\n      AC_MSG_RESULT([no])\n    fi\n\n\n## ----------------------------------------------------------------------\n## Check if pointer alignments are enforced\n##\nAC_MSG_CHECKING([if alignment restrictions are strictly enforced])\n\nTEST_SRC=\"`(echo \\\"#define H5_NO_ALIGNMENT_RESTRICTIONS_TEST 1\\\"; cat $srcdir/config/cmake/ConversionTests.c)`\"\n\nAC_RUN_IFELSE([\n    AC_LANG_SOURCE([$TEST_SRC])\n    ], [\n    AC_DEFINE([NO_ALIGNMENT_RESTRICTIONS], [1], [Define if we can violate pointer alignment restrictions])\n    AC_MSG_RESULT([no])\n    ], [\n    AC_MSG_RESULT([yes])\n    ], [\n    AC_MSG_RESULT([unknown, assuming yes])\n    ])\n\n\n## ----------------------------------------------------------------------\n## Restore user's CFLAGS.\nCFLAGS=\"$saved_user_CFLAGS\"\nFCFLAGS=\"$saved_user_FCFLAGS\"\nCXXFLAGS=\"$saved_user_CXXFLAGS\"\nCPPFLAGS=\"$saved_user_CPPFLAGS\"\nJAVACFLAGS=\"$saved_user_JAVACFLAGS\"\nJAVAFLAGS=\"$saved_user_JAVAFLAGS\"\nLDFLAGS=\"$saved_user_LDFLAGS\"\n\n\n## ----------------------------------------------------------------------\n## Create automake conditionals to tell automake makefiles which directories\n## need to be compiled\n\nAM_CONDITIONAL([BUILD_CXX_CONDITIONAL], [test \"X$HDF_CXX\" = \"Xyes\"])\nAM_CONDITIONAL([BUILD_PARALLEL_CONDITIONAL], [test \"X$PARALLEL\" = \"Xyes\"])\nAM_CONDITIONAL([BUILD_FORTRAN_CONDITIONAL], [test \"X$HDF_FORTRAN\" = \"Xyes\"])\nAM_CONDITIONAL([BUILD_JAVA_CONDITIONAL], [test \"X$HDF_JAVA\" = \"Xyes\"])\nAM_CONDITIONAL([BUILD_HDF5_HL_CONDITIONAL], [test \"X$HDF5_HL\" = \"Xyes\"])\nAM_CONDITIONAL([BUILD_TESTS_CONDITIONAL], [test \"X$HDF5_TESTS\" = \"Xyes\"])\nAM_CONDITIONAL([BUILD_TESTS_PARALLEL_CONDITIONAL], [test -n \"$TESTPARALLEL\"])\nAM_CONDITIONAL([BUILD_TOOLS_CONDITIONAL], [test \"X$HDF5_TOOLS\" = \"Xyes\"])\n\n## ----------------------------------------------------------------------\n## Build the Makefiles.\n##\n\n## The directory search list\nAC_SUBST([SEARCH]) SEARCH='$(srcdir) $(top_builddir)/src $(top_srcdir)/src'\nexport SEARCH\n\n## Some cleanup stuff\nrm -f conftest conftest.o conftest.c dummy.o *.mod\n\n## Build config.status, touch the stamp files, and build all the Makefiles.\n## The order is such that the first `make' does not need to update any\n## configuration information. See config/commence.in for the order in which\n## things need to be done.\n\n## First the stamp1 file for H5config.h.in\nmkdir ./config >/dev/null 2>&1\ntouch ./config/stamp1\n\n## Then the config.status file (but not makefiles)\nsaved_no_create=$no_create\nno_create=yes\n\nPARALLEL_MAKE=\"\"\nFORTRAN_PARALLEL_MAKE=\"\"\n\nif test -n \"$TESTPARALLEL\"; then\n  PARALLEL_MAKE=\"$TESTPARALLEL/Makefile\"\n\n  if test \"X$HDF_FORTRAN\" = \"Xyes\"; then\n    FORTRAN_PARALLEL_MAKE=fortran/$TESTPARALLEL/Makefile\n  fi\nfi\nLT_OUTPUT\nno_create=$saved_no_create\n\n## Then the stamp2 file for H5config.h\ntouch ./config/stamp2\n\n## Finally the makefiles\ntest \"$no_create\" = yes || ${CONFIG_SHELL-/bin/sh} $CONFIG_STATUS || exit 1\n\n## Are we compiling static libraries, shared libraries, or both?  This\n## is only used for the libhdf5.settings file. We can't just look at\n## $enable_static and $enable_shared because if they're yes the ltconfig\n## might have decided that one or the other is simply not possible.\n## Therefore we have to ask the generated `libtool' shell script\n## which 'features' it has enabled.\nif (./libtool --features | grep '^enable shared libraries' > /dev/null); then\n  enable_shared=yes\nelse\n  enable_shared=no\nfi\n\nif (./libtool --features | grep '^enable static libraries' > /dev/null); then\n  enable_static=yes\nelse\n  enable_static=no\nfi\n\n## Expose things for *.in markup\nAC_SUBST([STATIC_SHARED])\nAC_SUBST([enable_shared])\nAC_SUBST([enable_static])\n\nif test \"X$enable_static\" = \"Xyes\" && test \"X$enable_shared\" = \"Xyes\"; then\n  STATIC_SHARED=\"static, shared\"\nelif test \"X$enable_static\" = \"Xyes\"; then\n  STATIC_SHARED=\"static\"\nelif test \"X$enable_shared\" = \"Xyes\"; then\n  STATIC_SHARED=\"shared\"\nelse\n  STATIC_SHARED=\"none\"\nfi\n\nif test \"X$HDF_FORTRAN\" = \"Xyes\"; then\n\n  ### libtool does not pass the correct argument linking (-Wl,-Wl,,) for the NAG Fortran compiler\n  ### on Linux (other OSs have not been tested).\n  ### Therefore, detect if we are using the NAG Fortran compiler, and replace the wl=\"-Wl,\" for Fortran to\n  ### wl=\"-Wl,-Wl,,\" in the libtool file. (HDFFV-10037)\n  case \"`uname`\" in\n    Linux*)\n\n    fortran_linux_linker_option=\"-Wl,\"\n    if test \"X$FC_BASENAME\" = \"Xnagfor\"; then\n       fortran_linux_linker_option=\"-Wl,-Wl,,\"\n    fi\n\n    ## Set the correct linker option for use in h5fc.in markup\n    AC_SUBST([fortran_linux_linker_option])\n    ;;\n  esac\n\nfi\n\n## ----------------------------------------------------------------------\n## Set a macro if shared library is enabled.\n##\nAM_CONDITIONAL([HAVE_SHARED_CONDITIONAL], [test \"X$enable_shared\" = \"Xyes\"])\n\nAC_CONFIG_FILES([src/libhdf5.settings\n                 Makefile\n                 src/Makefile\n                 test/Makefile\n                 test/H5srcdir_str.h\n                 test/testabort_fail.sh\n                 test/testcheck_version.sh\n                 test/testerror.sh\n                 test/testexternal_env.sh\n                 test/testflushrefresh.sh\n                 test/testlibinfo.sh\n                 test/testlinks_env.sh\n                 test/testswmr.sh\n                 test/testvds_env.sh\n                 test/testvdsswmr.sh\n                 test/test_filter_plugin.sh\n                 test/test_mirror.sh\n                 test/test_usecases.sh\n                 test/test_vol_plugin.sh\n                 testpar/Makefile\n                 testpar/testpflush.sh\n                 utils/Makefile\n                 utils/mirror_vfd/Makefile\n                 tools/Makefile\n                 tools/lib/Makefile\n                 tools/libtest/Makefile\n                 tools/src/Makefile\n                 tools/src/h5dump/Makefile\n                 tools/src/h5import/Makefile\n                 tools/src/h5diff/Makefile\n                 tools/src/h5jam/Makefile\n                 tools/src/h5repack/Makefile\n                 tools/src/h5ls/Makefile\n                 tools/src/h5copy/Makefile\n                 tools/src/misc/Makefile\n                 tools/src/h5stat/Makefile\n                 tools/test/Makefile\n                 tools/test/h5dump/Makefile\n                 tools/test/h5dump/h5dump_plugin.sh\n                 tools/test/h5dump/testh5dump.sh\n                 tools/test/h5dump/testh5dumppbits.sh\n                 tools/test/h5dump/testh5dumpvds.sh\n                 tools/test/h5dump/testh5dumpxml.sh\n                 tools/test/h5ls/Makefile\n                 tools/test/h5ls/h5ls_plugin.sh\n                 tools/test/h5ls/testh5ls.sh\n                 tools/test/h5ls/testh5lsvds.sh\n                 tools/test/h5import/Makefile\n                 tools/test/h5import/h5importtestutil.sh\n                 tools/test/h5diff/Makefile\n                 tools/test/h5diff/h5diff_plugin.sh\n                 tools/test/h5diff/testh5diff.sh\n                 tools/test/h5diff/testph5diff.sh\n                 tools/src/h5format_convert/Makefile\n                 tools/test/h5format_convert/Makefile\n                 tools/test/h5format_convert/testh5fc.sh\n                 tools/test/h5jam/Makefile\n                 tools/test/h5jam/testh5jam.sh\n                 tools/test/h5repack/Makefile\n                 tools/test/h5repack/h5repack.sh\n                 tools/test/h5repack/h5repack_plugin.sh\n                 tools/test/h5copy/Makefile\n                 tools/test/h5copy/testh5copy.sh\n                 tools/test/misc/Makefile\n                 tools/test/misc/testh5clear.sh\n                 tools/test/misc/testh5mkgrp.sh\n                 tools/test/misc/testh5repart.sh\n                 tools/test/misc/vds/Makefile\n                 tools/test/h5stat/Makefile\n                 tools/test/h5stat/testh5stat.sh\n                 tools/test/perform/Makefile\n                 examples/Makefile\n                 examples/run-c-ex.sh\n                 examples/testh5cc.sh\n                 bin/h5cc\n                 bin/Makefile\n                 c++/Makefile\n                 c++/src/Makefile\n                 c++/src/h5c++\n                 c++/test/Makefile\n                 c++/test/H5srcdir_str.h\n                 c++/examples/Makefile\n                 c++/examples/run-c++-ex.sh\n                 c++/examples/testh5c++.sh\n                 fortran/Makefile\n                 fortran/src/h5fc\n                 fortran/src/Makefile\n                 fortran/src/H5fort_type_defines.h\n                 fortran/test/Makefile\n                 fortran/testpar/Makefile\n                 fortran/examples/Makefile\n                 fortran/examples/run-fortran-ex.sh\n                 fortran/examples/testh5fc.sh\n                 java/Makefile\n                 java/src/Makefile\n                 java/src/jni/Makefile\n                 java/test/Makefile\n                 java/test/junit.sh\n                 java/examples/Makefile\n                 java/examples/intro/Makefile\n                 java/examples/intro/JavaIntroExample.sh\n                 java/examples/datasets/Makefile\n                 java/examples/datasets/JavaDatasetExample.sh\n                 java/examples/datatypes/Makefile\n                 java/examples/datatypes/JavaDatatypeExample.sh\n                 java/examples/groups/Makefile\n                 java/examples/groups/JavaGroupExample.sh\n                 hl/Makefile\n                 hl/src/Makefile\n                 hl/test/Makefile\n                 hl/test/H5srcdir_str.h\n                 hl/tools/Makefile\n                 hl/tools/gif2h5/Makefile\n                 hl/tools/gif2h5/h52giftest.sh\n                 hl/tools/h5watch/Makefile\n                 hl/tools/h5watch/testh5watch.sh\n                 hl/examples/Makefile\n                 hl/examples/run-hlc-ex.sh\n                 hl/c++/Makefile\n                 hl/c++/src/Makefile\n                 hl/c++/test/Makefile\n                 hl/c++/examples/Makefile\n                 hl/c++/examples/run-hlc++-ex.sh\n                 hl/fortran/Makefile\n                 hl/fortran/src/Makefile\n                 hl/fortran/test/Makefile\n                 hl/fortran/examples/Makefile\n                 hl/fortran/examples/run-hlfortran-ex.sh])\n\nAC_CONFIG_COMMANDS([.classes], [], [$MKDIR_P java/src/.classes;\n                $MKDIR_P java/test/.classes;\n                $MKDIR_P java/examples/intro/.classes;\n                $MKDIR_P java/examples/datasets/.classes;\n                $MKDIR_P java/examples/datatypes/.classes;\n                $MKDIR_P java/examples/groups/.classes])\n\nAC_OUTPUT\n\nchmod 755 bin/h5cc\nif test \"X$HDF_CXX\" = \"Xyes\"; then\n  chmod 755 c++/src/h5c++\nfi\n\n\nif test \"X$HDF_FORTRAN\" = \"Xyes\"; then\n  chmod 755 fortran/src/h5fc\n  ## libtool does not pass the correct argument linker (wl=) for the Intel Fortran compiler\n  ## on OS X, which is needed when building shared libraries on OS X.  This script\n  ## replaces the 3rd occurrence, which is for Fortran, of wl=\"\" with wl=\"-Wl,\" (HDFFV-2772)\n  case \"`uname`\" in\n    Darwin*)\n      cat libtool | awk '/wl=\\\"/{c++;if(c==3){sub(\"wl=\\\"\\\"\",\"wl=\\\"-Wl,\\\"\");c=0}}1' > libtool.tmp && mv -f libtool.tmp libtool && chmod 755 libtool\n      ;;\n  esac\n\n  ### libtool does not pass the correct argument linking (-Wl,-Wl,,) for the NAG Fortran compiler\n  ### on Linux (other OSs have not been tested).\n  ### Therefore, detect if we are using the NAG Fortran compiler, and replace the wl=\"-Wl,\" for Fortran to\n  ### wl=\"-Wl,-Wl,,\" in the libtool file. (HDFFV-10037)\n  case \"`uname`\" in\n    Linux*)\n      if test \"X$FC_BASENAME\" = \"Xnagfor\"; then\n         cat libtool | awk '/BEGIN LIBTOOL TAG CONFIG: FC/{flag=1}flag&&/wl=/{$NF=\"wl=\\\"-Wl,-Wl,,\\\"\";flag=0}1' > libtool.tmp && mv -f libtool.tmp libtool && chmod 755 libtool\n      fi\n      ;;\n  esac\nfi\n\n## HDF5 configure code created by autotools with gcc 4.9.2 is adding problematic\n## linker flags:  -l with no library name; -l <libname>, specifically gfortran or m.\n## This sed script corrects \"-l <libname>\" first and then \"-l \" with no library name.\n## If the order is not preserved, all instances of \"-l \" will be removed.\nsed -e '/^postdeps/ s/-l \\([a-zA-Z]\\)/-l\\1/g' -e '/^postdeps/ s/-l //g' -i libtool\n\n## show the configure settings\ncat src/libhdf5.settings\n",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/config/cmake_ext_mod/ConfigureChecks.cmake": "#\n# Copyright by The HDF Group.\n# All rights reserved.\n#\n# This file is part of HDF5.  The full HDF5 copyright notice, including\n# terms governing use, modification, and redistribution, is contained in\n# the COPYING file, which can be found at the root of the source code\n# distribution tree, or in https://support.hdfgroup.org/ftp/HDF5/releases.\n# If you do not have access to either file, you may request a copy from\n# help@hdfgroup.org.\n#\n#-----------------------------------------------------------------------------\n# Include all the necessary files for macros\n#-----------------------------------------------------------------------------\ninclude (CheckFunctionExists)\ninclude (CheckIncludeFile)\ninclude (CheckIncludeFiles)\ninclude (CheckLibraryExists)\ninclude (CheckSymbolExists)\ninclude (CheckTypeSize)\ninclude (CheckVariableExists)\ninclude (TestBigEndian)\ninclude (CheckStructHasMember)\n\n#-----------------------------------------------------------------------------\n# APPLE/Darwin setup\n#-----------------------------------------------------------------------------\nif (APPLE)\n  list (LENGTH CMAKE_OSX_ARCHITECTURES ARCH_LENGTH)\n  if (ARCH_LENGTH GREATER 1)\n    set (CMAKE_OSX_ARCHITECTURES \"\" CACHE STRING \"\" FORCE)\n    message (FATAL_ERROR \"Building Universal Binaries on OS X is NOT supported by the HDF5 project. This is\"\n    \"due to technical reasons. The best approach would be build each architecture in separate directories\"\n    \"and use the 'lipo' tool to combine them into a single executable or library. The 'CMAKE_OSX_ARCHITECTURES'\"\n    \"variable has been set to a blank value which will build the default architecture for this system.\")\n  endif ()\n  set (${HDF_PREFIX}_AC_APPLE_UNIVERSAL_BUILD 0)\nendif ()\n\n# Check for Darwin (not just Apple - we also want to catch OpenDarwin)\nif (${CMAKE_SYSTEM_NAME} MATCHES \"Darwin\")\n    set (${HDF_PREFIX}_HAVE_DARWIN 1)\nendif ()\n\n# Check for Solaris\nif (${CMAKE_SYSTEM_NAME} MATCHES \"SunOS\")\n    set (${HDF_PREFIX}_HAVE_SOLARIS 1)\nendif ()\n\n#-----------------------------------------------------------------------------\n# This MACRO checks IF the symbol exists in the library and IF it\n# does, it appends library to the list.\n#-----------------------------------------------------------------------------\nset (LINK_LIBS \"\")\nmacro (CHECK_LIBRARY_EXISTS_CONCAT LIBRARY SYMBOL VARIABLE)\n  CHECK_LIBRARY_EXISTS (\"${LIBRARY};${LINK_LIBS}\" ${SYMBOL} \"\" ${VARIABLE})\n  if (${VARIABLE})\n    set (LINK_LIBS ${LINK_LIBS} ${LIBRARY})\n  endif ()\nendmacro ()\n\n# ----------------------------------------------------------------------\n# WINDOWS Hard code Values\n# ----------------------------------------------------------------------\nset (WINDOWS)\n\nif (MINGW)\n  set (${HDF_PREFIX}_HAVE_MINGW 1)\n  set (WINDOWS 1) # MinGW tries to imitate Windows\n  set (CMAKE_REQUIRED_FLAGS \"-DWIN32_LEAN_AND_MEAN=1 -DNOGDI=1\")\n  set (${HDF_PREFIX}_HAVE_WINSOCK2_H 1)\nendif ()\n\nif (WIN32 AND NOT MINGW)\n  if (NOT UNIX)\n    set (WINDOWS 1)\n    set (CMAKE_REQUIRED_FLAGS \"/DWIN32_LEAN_AND_MEAN=1 /DNOGDI=1\")\n    if (MSVC)\n      set (${HDF_PREFIX}_HAVE_VISUAL_STUDIO 1)\n    endif ()\n  endif ()\nendif ()\n\nif (WINDOWS)\n  set (HDF5_REQUIRED_LIBRARIES \"ws2_32.lib;wsock32.lib\")\n  set (${HDF_PREFIX}_HAVE_WIN32_API 1)\n  set (${HDF_PREFIX}_HAVE_LIBM 1)\n  set (${HDF_PREFIX}_HAVE_STRDUP 1)\n  set (${HDF_PREFIX}_HAVE_SYSTEM 1)\n  set (${HDF_PREFIX}_HAVE_LONGJMP 1)\n  if (NOT MINGW)\n    set (${HDF_PREFIX}_HAVE_GETHOSTNAME 1)\n    set (${HDF_PREFIX}_HAVE_FUNCTION 1)\n  endif ()\n  if (NOT UNIX AND NOT CYGWIN)\n    set (${HDF_PREFIX}_HAVE_GETCONSOLESCREENBUFFERINFO 1)\n    set (${HDF_PREFIX}_GETTIMEOFDAY_GIVES_TZ 1)\n    set (${HDF_PREFIX}_HAVE_TIMEZONE 1)\n    set (${HDF_PREFIX}_HAVE_GETTIMEOFDAY 1)\n    set (${HDF_PREFIX}_HAVE_LIBWS2_32 1)\n    set (${HDF_PREFIX}_HAVE_LIBWSOCK32 1)\n  endif ()\nendif ()\n\n# ----------------------------------------------------------------------\n# END of WINDOWS Hard code Values\n# ----------------------------------------------------------------------\n\nif (NOT WINDOWS)\n  TEST_BIG_ENDIAN (${HDF_PREFIX}_WORDS_BIGENDIAN)\nendif ()\n\n#-----------------------------------------------------------------------------\n# Check IF header file exists and add it to the list.\n#-----------------------------------------------------------------------------\nmacro (CHECK_INCLUDE_FILE_CONCAT FILE VARIABLE)\n  CHECK_INCLUDE_FILES (\"${USE_INCLUDES};${FILE}\" ${VARIABLE})\n  if (${VARIABLE})\n    set (USE_INCLUDES ${USE_INCLUDES} ${FILE})\n  endif ()\nendmacro ()\n\n#-----------------------------------------------------------------------------\n#  Check for the existence of certain header files\n#-----------------------------------------------------------------------------\nCHECK_INCLUDE_FILE_CONCAT (\"sys/file.h\"      ${HDF_PREFIX}_HAVE_SYS_FILE_H)\nCHECK_INCLUDE_FILE_CONCAT (\"sys/ioctl.h\"     ${HDF_PREFIX}_HAVE_SYS_IOCTL_H)\nCHECK_INCLUDE_FILE_CONCAT (\"sys/resource.h\"  ${HDF_PREFIX}_HAVE_SYS_RESOURCE_H)\nCHECK_INCLUDE_FILE_CONCAT (\"sys/socket.h\"    ${HDF_PREFIX}_HAVE_SYS_SOCKET_H)\nCHECK_INCLUDE_FILE_CONCAT (\"sys/stat.h\"      ${HDF_PREFIX}_HAVE_SYS_STAT_H)\nCHECK_INCLUDE_FILE_CONCAT (\"sys/time.h\"      ${HDF_PREFIX}_HAVE_SYS_TIME_H)\nCHECK_INCLUDE_FILE_CONCAT (\"sys/types.h\"     ${HDF_PREFIX}_HAVE_SYS_TYPES_H)\nCHECK_INCLUDE_FILE_CONCAT (\"features.h\"      ${HDF_PREFIX}_HAVE_FEATURES_H)\nCHECK_INCLUDE_FILE_CONCAT (\"dirent.h\"        ${HDF_PREFIX}_HAVE_DIRENT_H)\nCHECK_INCLUDE_FILE_CONCAT (\"setjmp.h\"        ${HDF_PREFIX}_HAVE_SETJMP_H)\nCHECK_INCLUDE_FILE_CONCAT (\"stddef.h\"        ${HDF_PREFIX}_HAVE_STDDEF_H)\nCHECK_INCLUDE_FILE_CONCAT (\"stdint.h\"        ${HDF_PREFIX}_HAVE_STDINT_H)\nCHECK_INCLUDE_FILE_CONCAT (\"unistd.h\"        ${HDF_PREFIX}_HAVE_UNISTD_H)\n\n# Windows\nCHECK_INCLUDE_FILE_CONCAT (\"io.h\"            ${HDF_PREFIX}_HAVE_IO_H)\nif (NOT CYGWIN)\n  CHECK_INCLUDE_FILE_CONCAT (\"winsock2.h\"      ${HDF_PREFIX}_HAVE_WINSOCK2_H)\nendif ()\n\nif (CMAKE_SYSTEM_NAME MATCHES \"OSF\")\n  CHECK_INCLUDE_FILE_CONCAT (\"sys/sysinfo.h\" ${HDF_PREFIX}_HAVE_SYS_SYSINFO_H)\n  CHECK_INCLUDE_FILE_CONCAT (\"sys/proc.h\"    ${HDF_PREFIX}_HAVE_SYS_PROC_H)\nelse ()\n  set (${HDF_PREFIX}_HAVE_SYS_SYSINFO_H \"\" CACHE INTERNAL \"\" FORCE)\n  set (${HDF_PREFIX}_HAVE_SYS_PROC_H    \"\" CACHE INTERNAL \"\" FORCE)\nendif ()\n\nCHECK_INCLUDE_FILE_CONCAT (\"globus/common.h\" ${HDF_PREFIX}_HAVE_GLOBUS_COMMON_H)\nCHECK_INCLUDE_FILE_CONCAT (\"pdb.h\"           ${HDF_PREFIX}_HAVE_PDB_H)\nCHECK_INCLUDE_FILE_CONCAT (\"pthread.h\"       ${HDF_PREFIX}_HAVE_PTHREAD_H)\nCHECK_INCLUDE_FILE_CONCAT (\"srbclient.h\"     ${HDF_PREFIX}_HAVE_SRBCLIENT_H)\nCHECK_INCLUDE_FILE_CONCAT (\"string.h\"        ${HDF_PREFIX}_HAVE_STRING_H)\nCHECK_INCLUDE_FILE_CONCAT (\"strings.h\"       ${HDF_PREFIX}_HAVE_STRINGS_H)\nCHECK_INCLUDE_FILE_CONCAT (\"stdlib.h\"        ${HDF_PREFIX}_HAVE_STDLIB_H)\nCHECK_INCLUDE_FILE_CONCAT (\"memory.h\"        ${HDF_PREFIX}_HAVE_MEMORY_H)\nCHECK_INCLUDE_FILE_CONCAT (\"dlfcn.h\"         ${HDF_PREFIX}_HAVE_DLFCN_H)\nCHECK_INCLUDE_FILE_CONCAT (\"inttypes.h\"      ${HDF_PREFIX}_HAVE_INTTYPES_H)\nCHECK_INCLUDE_FILE_CONCAT (\"netinet/in.h\"    ${HDF_PREFIX}_HAVE_NETINET_IN_H)\nCHECK_INCLUDE_FILE_CONCAT (\"netdb.h\"         ${HDF_PREFIX}_HAVE_NETDB_H)\nCHECK_INCLUDE_FILE_CONCAT (\"arpa/inet.h\"     ${HDF_PREFIX}_HAVE_ARPA_INET_H)\n# _Bool type support\nCHECK_INCLUDE_FILE_CONCAT (stdbool.h    ${HDF_PREFIX}_HAVE_STDBOOL_H)\n\n## Check for non-standard extenstion quadmath.h\n\nCHECK_INCLUDE_FILES(quadmath.h C_HAVE_QUADMATH)\nif (${C_HAVE_QUADMATH})\n  set(${HDF_PREFIX}_HAVE_QUADMATH_H 1)\nelse ()\n  set(${HDF_PREFIX}_HAVE_QUADMATH_H 0)\nendif ()\n\nif (CYGWIN)\n  set (${HDF_PREFIX}_HAVE_LSEEK64 0)\nendif ()\n\n#-----------------------------------------------------------------------------\n#  Check for the math library \"m\"\n#-----------------------------------------------------------------------------\nif (MINGW OR NOT WINDOWS)\n  CHECK_LIBRARY_EXISTS_CONCAT (\"m\" ceil     ${HDF_PREFIX}_HAVE_LIBM)\n  CHECK_LIBRARY_EXISTS_CONCAT (\"dl\" dlopen     ${HDF_PREFIX}_HAVE_LIBDL)\n  CHECK_LIBRARY_EXISTS_CONCAT (\"ws2_32\" WSAStartup  ${HDF_PREFIX}_HAVE_LIBWS2_32)\n  CHECK_LIBRARY_EXISTS_CONCAT (\"wsock32\" gethostbyname ${HDF_PREFIX}_HAVE_LIBWSOCK32)\nendif ()\n\n# UCB (BSD) compatibility library\nCHECK_LIBRARY_EXISTS_CONCAT (\"ucb\"    gethostname  ${HDF_PREFIX}_HAVE_LIBUCB)\n\n# For other tests to use the same libraries\nset (HDF5_REQUIRED_LIBRARIES ${HDF5_REQUIRED_LIBRARIES} ${LINK_LIBS})\n\nset (USE_INCLUDES \"\")\nif (WINDOWS)\n  set (USE_INCLUDES ${USE_INCLUDES} \"windows.h\")\nendif ()\n\n# For other specific tests, use this MACRO.\nmacro (HDF_FUNCTION_TEST OTHER_TEST)\n  if (NOT DEFINED ${HDF_PREFIX}_${OTHER_TEST})\n    set (MACRO_CHECK_FUNCTION_DEFINITIONS \"-D${OTHER_TEST} ${CMAKE_REQUIRED_FLAGS}\")\n\n    foreach (def\n        HAVE_SYS_TIME_H\n        HAVE_UNISTD_H\n        HAVE_SYS_TYPES_H\n        HAVE_SYS_SOCKET_H\n    )\n      if (\"${${HDF_PREFIX}_${def}}\")\n        set (MACRO_CHECK_FUNCTION_DEFINITIONS \"${MACRO_CHECK_FUNCTION_DEFINITIONS} -D${def}\")\n      endif ()\n    endforeach ()\n\n    if (LARGEFILE)\n      set (MACRO_CHECK_FUNCTION_DEFINITIONS\n          \"${MACRO_CHECK_FUNCTION_DEFINITIONS} -D_FILE_OFFSET_BITS=64 -D_LARGEFILE64_SOURCE -D_LARGEFILE_SOURCE\"\n      )\n    endif ()\n\n    #message (STATUS \"Performing ${OTHER_TEST}\")\n    try_compile (${OTHER_TEST}\n        ${CMAKE_BINARY_DIR}\n        ${HDF_RESOURCES_EXT_DIR}/HDFTests.c\n        COMPILE_DEFINITIONS \"${MACRO_CHECK_FUNCTION_DEFINITIONS}\"\n        LINK_LIBRARIES \"${HDF5_REQUIRED_LIBRARIES}\"\n        OUTPUT_VARIABLE OUTPUT\n    )\n    if (${OTHER_TEST})\n      set (${HDF_PREFIX}_${OTHER_TEST} 1 CACHE INTERNAL \"Other test ${FUNCTION}\")\n      message (STATUS \"Performing Other Test ${OTHER_TEST} - Success\")\n    else ()\n      message (STATUS \"Performing Other Test ${OTHER_TEST} - Failed\")\n      set (${HDF_PREFIX}_${OTHER_TEST} \"\" CACHE INTERNAL \"Other test ${FUNCTION}\")\n      file (APPEND ${CMAKE_BINARY_DIR}${CMAKE_FILES_DIRECTORY}/CMakeError.log\n          \"Performing Other Test ${OTHER_TEST} failed with the following output:\\n\"\n          \"${OUTPUT}\\n\"\n      )\n    endif ()\n  endif ()\nendmacro ()\n\n#-----------------------------------------------------------------------------\n# Check for these functions before the time headers are checked\n#-----------------------------------------------------------------------------\nHDF_FUNCTION_TEST (STDC_HEADERS)\n\n#-----------------------------------------------------------------------------\n#  Check for large file support\n#-----------------------------------------------------------------------------\n\n# The linux-lfs option is deprecated.\nset (LINUX_LFS 0)\n\nset (HDF_EXTRA_C_FLAGS)\nset (HDF_EXTRA_FLAGS)\nif (MINGW OR NOT WINDOWS)\n  # Might want to check explicitly for Linux and possibly Cygwin\n  # instead of checking for not Solaris or Darwin.\n  if (NOT ${HDF_PREFIX}_HAVE_SOLARIS AND NOT ${HDF_PREFIX}_HAVE_DARWIN)\n  # Linux Specific flags\n  # This was originally defined as _POSIX_SOURCE which was updated to\n  # _POSIX_C_SOURCE=199506L to expose a greater amount of POSIX\n  # functionality so clock_gettime and CLOCK_MONOTONIC are defined\n  # correctly. This was later updated to 200112L so that\n  # posix_memalign() is visible for the direct VFD code on Linux\n  # systems.\n  # POSIX feature information can be found in the gcc manual at:\n  # http://www.gnu.org/s/libc/manual/html_node/Feature-Test-Macros.html\n  set (HDF_EXTRA_C_FLAGS -D_POSIX_C_SOURCE=200809L)\n\n  # Need to add this so that O_DIRECT is visible for the direct\n  # VFD on Linux systems.\n  set (HDF_EXTRA_C_FLAGS ${HDF_EXTRA_C_FLAGS} -D_GNU_SOURCE)\n\n  option (HDF_ENABLE_LARGE_FILE \"Enable support for large (64-bit) files on Linux.\" ON)\n  if (HDF_ENABLE_LARGE_FILE AND NOT DEFINED TEST_LFS_WORKS_RUN)\n    set (msg \"Performing TEST_LFS_WORKS\")\n    try_run (TEST_LFS_WORKS_RUN   TEST_LFS_WORKS_COMPILE\n        ${CMAKE_BINARY_DIR}\n        ${HDF_RESOURCES_EXT_DIR}/HDFTests.c\n        COMPILE_DEFINITIONS \"-DTEST_LFS_WORKS\"\n    )\n\n    # The LARGEFILE definitions were from the transition period\n    # and are probably no longer needed. The FILE_OFFSET_BITS\n    # check should be generalized for all POSIX systems as it\n    # is in the Autotools.\n    if (TEST_LFS_WORKS_COMPILE)\n      if (TEST_LFS_WORKS_RUN MATCHES 0)\n        set (TEST_LFS_WORKS 1 CACHE INTERNAL ${msg})\n        set (LARGEFILE 1)\n        set (HDF_EXTRA_FLAGS ${HDF_EXTRA_FLAGS} -D_FILE_OFFSET_BITS=64 -D_LARGEFILE64_SOURCE -D_LARGEFILE_SOURCE)\n        message (STATUS \"${msg}... yes\")\n      else ()\n        set (TEST_LFS_WORKS \"\" CACHE INTERNAL ${msg})\n        message (STATUS \"${msg}... no\")\n        file (APPEND ${CMAKE_BINARY_DIR}${CMAKE_FILES_DIRECTORY}/CMakeError.log\n              \"Test TEST_LFS_WORKS Run failed with the following exit code:\\n ${TEST_LFS_WORKS_RUN}\\n\"\n        )\n      endif ()\n    else ()\n      set (TEST_LFS_WORKS \"\" CACHE INTERNAL ${msg})\n      message (STATUS \"${msg}... no\")\n      file (APPEND ${CMAKE_BINARY_DIR}${CMAKE_FILES_DIRECTORY}/CMakeError.log\n          \"Test TEST_LFS_WORKS Compile failed\\n\"\n      )\n    endif ()\n  endif ()\n  set (CMAKE_REQUIRED_DEFINITIONS ${CMAKE_REQUIRED_DEFINITIONS} ${HDF_EXTRA_FLAGS})\n  endif ()\nendif ()\n\n#-----------------------------------------------------------------------------\n# Check for HAVE_OFF64_T functionality\n#-----------------------------------------------------------------------------\nif (MINGW OR NOT WINDOWS)\n  HDF_FUNCTION_TEST (HAVE_OFF64_T)\n  if (${HDF_PREFIX}_HAVE_OFF64_T)\n    CHECK_FUNCTION_EXISTS (lseek64            ${HDF_PREFIX}_HAVE_LSEEK64)\n  endif ()\n\n  CHECK_FUNCTION_EXISTS (fseeko               ${HDF_PREFIX}_HAVE_FSEEKO)\n\n  CHECK_STRUCT_HAS_MEMBER(\"struct stat64\" st_blocks \"sys/types.h;sys/stat.h\" HAVE_STAT64_STRUCT)\n  if (HAVE_STAT64_STRUCT)\n    CHECK_FUNCTION_EXISTS (stat64             ${HDF_PREFIX}_HAVE_STAT64)\n  endif ()\nendif ()\n\n#-----------------------------------------------------------------------------\n#  Check the size in bytes of all the int and float types\n#-----------------------------------------------------------------------------\nmacro (HDF_CHECK_TYPE_SIZE type var)\n  set (aType ${type})\n  set (aVar  ${var})\n#  message (STATUS \"Checking size of ${aType} and storing into ${aVar}\")\n  CHECK_TYPE_SIZE (${aType}   ${aVar})\n  if (NOT ${aVar})\n    set (${aVar} 0 CACHE INTERNAL \"SizeOf for ${aType}\")\n#    message (STATUS \"Size of ${aType} was NOT Found\")\n  endif ()\nendmacro ()\n\nHDF_CHECK_TYPE_SIZE (char           ${HDF_PREFIX}_SIZEOF_CHAR)\nHDF_CHECK_TYPE_SIZE (short          ${HDF_PREFIX}_SIZEOF_SHORT)\nHDF_CHECK_TYPE_SIZE (int            ${HDF_PREFIX}_SIZEOF_INT)\nHDF_CHECK_TYPE_SIZE (unsigned       ${HDF_PREFIX}_SIZEOF_UNSIGNED)\nif (NOT APPLE)\n  HDF_CHECK_TYPE_SIZE (long         ${HDF_PREFIX}_SIZEOF_LONG)\nendif ()\nHDF_CHECK_TYPE_SIZE (\"long long\"    ${HDF_PREFIX}_SIZEOF_LONG_LONG)\nHDF_CHECK_TYPE_SIZE (__int64        ${HDF_PREFIX}_SIZEOF___INT64)\nif (NOT ${HDF_PREFIX}_SIZEOF___INT64)\n  set (${HDF_PREFIX}_SIZEOF___INT64 0)\nendif ()\n\nHDF_CHECK_TYPE_SIZE (float          ${HDF_PREFIX}_SIZEOF_FLOAT)\nHDF_CHECK_TYPE_SIZE (double         ${HDF_PREFIX}_SIZEOF_DOUBLE)\nHDF_CHECK_TYPE_SIZE (\"long double\"  ${HDF_PREFIX}_SIZEOF_LONG_DOUBLE)\n\nHDF_CHECK_TYPE_SIZE (int8_t         ${HDF_PREFIX}_SIZEOF_INT8_T)\nHDF_CHECK_TYPE_SIZE (uint8_t        ${HDF_PREFIX}_SIZEOF_UINT8_T)\nHDF_CHECK_TYPE_SIZE (int_least8_t   ${HDF_PREFIX}_SIZEOF_INT_LEAST8_T)\nHDF_CHECK_TYPE_SIZE (uint_least8_t  ${HDF_PREFIX}_SIZEOF_UINT_LEAST8_T)\nHDF_CHECK_TYPE_SIZE (int_fast8_t    ${HDF_PREFIX}_SIZEOF_INT_FAST8_T)\nHDF_CHECK_TYPE_SIZE (uint_fast8_t   ${HDF_PREFIX}_SIZEOF_UINT_FAST8_T)\n\nHDF_CHECK_TYPE_SIZE (int16_t        ${HDF_PREFIX}_SIZEOF_INT16_T)\nHDF_CHECK_TYPE_SIZE (uint16_t       ${HDF_PREFIX}_SIZEOF_UINT16_T)\nHDF_CHECK_TYPE_SIZE (int_least16_t  ${HDF_PREFIX}_SIZEOF_INT_LEAST16_T)\nHDF_CHECK_TYPE_SIZE (uint_least16_t ${HDF_PREFIX}_SIZEOF_UINT_LEAST16_T)\nHDF_CHECK_TYPE_SIZE (int_fast16_t   ${HDF_PREFIX}_SIZEOF_INT_FAST16_T)\nHDF_CHECK_TYPE_SIZE (uint_fast16_t  ${HDF_PREFIX}_SIZEOF_UINT_FAST16_T)\n\nHDF_CHECK_TYPE_SIZE (int32_t        ${HDF_PREFIX}_SIZEOF_INT32_T)\nHDF_CHECK_TYPE_SIZE (uint32_t       ${HDF_PREFIX}_SIZEOF_UINT32_T)\nHDF_CHECK_TYPE_SIZE (int_least32_t  ${HDF_PREFIX}_SIZEOF_INT_LEAST32_T)\nHDF_CHECK_TYPE_SIZE (uint_least32_t ${HDF_PREFIX}_SIZEOF_UINT_LEAST32_T)\nHDF_CHECK_TYPE_SIZE (int_fast32_t   ${HDF_PREFIX}_SIZEOF_INT_FAST32_T)\nHDF_CHECK_TYPE_SIZE (uint_fast32_t  ${HDF_PREFIX}_SIZEOF_UINT_FAST32_T)\n\nHDF_CHECK_TYPE_SIZE (int64_t        ${HDF_PREFIX}_SIZEOF_INT64_T)\nHDF_CHECK_TYPE_SIZE (uint64_t       ${HDF_PREFIX}_SIZEOF_UINT64_T)\nHDF_CHECK_TYPE_SIZE (int_least64_t  ${HDF_PREFIX}_SIZEOF_INT_LEAST64_T)\nHDF_CHECK_TYPE_SIZE (uint_least64_t ${HDF_PREFIX}_SIZEOF_UINT_LEAST64_T)\nHDF_CHECK_TYPE_SIZE (int_fast64_t   ${HDF_PREFIX}_SIZEOF_INT_FAST64_T)\nHDF_CHECK_TYPE_SIZE (uint_fast64_t  ${HDF_PREFIX}_SIZEOF_UINT_FAST64_T)\n\nif (NOT APPLE)\n  HDF_CHECK_TYPE_SIZE (size_t       ${HDF_PREFIX}_SIZEOF_SIZE_T)\n  HDF_CHECK_TYPE_SIZE (ssize_t      ${HDF_PREFIX}_SIZEOF_SSIZE_T)\n  if (NOT ${HDF_PREFIX}_SIZEOF_SSIZE_T)\n    set (${HDF_PREFIX}_SIZEOF_SSIZE_T 0)\n  endif ()\n  if (MINGW OR NOT WINDOWS)\n    HDF_CHECK_TYPE_SIZE (ptrdiff_t    ${HDF_PREFIX}_SIZEOF_PTRDIFF_T)\n  endif ()\nendif ()\n\nHDF_CHECK_TYPE_SIZE (off_t          ${HDF_PREFIX}_SIZEOF_OFF_T)\nHDF_CHECK_TYPE_SIZE (off64_t        ${HDF_PREFIX}_SIZEOF_OFF64_T)\nif (NOT ${HDF_PREFIX}_SIZEOF_OFF64_T)\n  set (${HDF_PREFIX}_SIZEOF_OFF64_T 0)\nendif ()\nHDF_CHECK_TYPE_SIZE (time_t          ${HDF_PREFIX}_SIZEOF_TIME_T)\n\n#-----------------------------------------------------------------------------\n# Extra C99 types\n#-----------------------------------------------------------------------------\n\n# _Bool type support\nif (HAVE_STDBOOL_H)\n  set (CMAKE_EXTRA_INCLUDE_FILES stdbool.h)\n  HDF_CHECK_TYPE_SIZE (bool         ${HDF_PREFIX}_SIZEOF_BOOL)\nelse ()\n  HDF_CHECK_TYPE_SIZE (_Bool        ${HDF_PREFIX}_SIZEOF_BOOL)\nendif ()\n\nif (MINGW OR NOT WINDOWS)\n  #-----------------------------------------------------------------------------\n  # Check if the dev_t type is a scalar type\n  #-----------------------------------------------------------------------------\n  HDF_FUNCTION_TEST (DEV_T_IS_SCALAR)\n\n  # ----------------------------------------------------------------------\n  # Check for MONOTONIC_TIMER support (used in clock_gettime).  This has\n  # to be done after any POSIX/BSD defines to ensure that the test gets\n  # the correct POSIX level on linux.\n  CHECK_VARIABLE_EXISTS (CLOCK_MONOTONIC HAVE_CLOCK_MONOTONIC)\n\n  #-----------------------------------------------------------------------------\n  # Check a bunch of time functions\n  #-----------------------------------------------------------------------------\n  CHECK_STRUCT_HAS_MEMBER(\"struct tm\" tm_gmtoff \"time.h\" ${HDF_PREFIX}_HAVE_TM_GMTOFF)\n  CHECK_STRUCT_HAS_MEMBER(\"struct tm\" __tm_gmtoff \"time.h\" ${HDF_PREFIX}_HAVE___TM_GMTOFF)\n  CHECK_STRUCT_HAS_MEMBER(\"struct tm\" tm_sec \"sys/types.h;sys/time.h;time.h\" ${HDF_PREFIX}_TIME_WITH_SYS_TIME)\n  if (${HDF_PREFIX}_HAVE_SYS_TIME_H)\n    CHECK_STRUCT_HAS_MEMBER(\"struct tm\" tz_minuteswest \"sys/types.h;sys/time.h;time.h\" ${HDF_PREFIX}_HAVE_STRUCT_TIMEZONE)\n  else ()\n    CHECK_STRUCT_HAS_MEMBER(\"struct tm\" tz_minuteswest \"sys/types.h;time.h\" ${HDF_PREFIX}_HAVE_STRUCT_TIMEZONE)\n  endif ()\n  CHECK_FUNCTION_EXISTS (gettimeofday      ${HDF_PREFIX}_HAVE_GETTIMEOFDAY)\n  foreach (time_test\n#      HAVE_TIMEZONE\n      GETTIMEOFDAY_GIVES_TZ\n      HAVE_TM_ZONE\n      HAVE_STRUCT_TM_TM_ZONE\n  )\n    HDF_FUNCTION_TEST (${time_test})\n  endforeach ()\n  if (NOT CYGWIN AND NOT MINGW)\n      HDF_FUNCTION_TEST (HAVE_TIMEZONE)\n  endif ()\n\n  # ----------------------------------------------------------------------\n  # Does the struct stat have the st_blocks field?  This field is not Posix.\n  #\n  CHECK_STRUCT_HAS_MEMBER(\"struct stat\" st_blocks \"sys/types.h;sys/stat.h\" ${HDF_PREFIX}_HAVE_STAT_ST_BLOCKS)\n\n  # ----------------------------------------------------------------------\n  # How do we figure out the width of a tty in characters?\n  #\n  CHECK_FUNCTION_EXISTS (ioctl             ${HDF_PREFIX}_HAVE_IOCTL)\n  CHECK_STRUCT_HAS_MEMBER (\"struct videoconfig\" numtextcols \"\" ${HDF_PREFIX}_HAVE_STRUCT_VIDEOCONFIG)\n  CHECK_STRUCT_HAS_MEMBER (\"struct text_info\" screenwidth \"\" ${HDF_PREFIX}_HAVE_STRUCT_TEXT_INFO)\n  CHECK_FUNCTION_EXISTS (_getvideoconfig   ${HDF_PREFIX}_HAVE__GETVIDEOCONFIG)\n  CHECK_FUNCTION_EXISTS (gettextinfo       ${HDF_PREFIX}_HAVE_GETTEXTINFO)\n  CHECK_FUNCTION_EXISTS (_scrsize          ${HDF_PREFIX}_HAVE__SCRSIZE)\n  if (NOT CYGWIN)\n    CHECK_FUNCTION_EXISTS (GetConsoleScreenBufferInfo    ${HDF_PREFIX}_HAVE_GETCONSOLESCREENBUFFERINFO)\n  endif ()\n  CHECK_SYMBOL_EXISTS (TIOCGWINSZ \"sys/ioctl.h\" ${HDF_PREFIX}_HAVE_TIOCGWINSZ)\n  CHECK_SYMBOL_EXISTS (TIOCGETD   \"sys/ioctl.h\" ${HDF_PREFIX}_HAVE_TIOCGETD)\n\n  # ----------------------------------------------------------------------\n  # cygwin user credentials are different then on linux\n  #\n  if (NOT CYGWIN AND NOT MINGW)\n    CHECK_FUNCTION_EXISTS (getpwuid        ${HDF_PREFIX}_HAVE_GETPWUID)\n  endif ()\nendif ()\n\n#-----------------------------------------------------------------------------\n# Check for some functions that are used\n#\nCHECK_FUNCTION_EXISTS (alarm             ${HDF_PREFIX}_HAVE_ALARM)\nCHECK_FUNCTION_EXISTS (fcntl             ${HDF_PREFIX}_HAVE_FCNTL)\nCHECK_FUNCTION_EXISTS (flock             ${HDF_PREFIX}_HAVE_FLOCK)\nCHECK_FUNCTION_EXISTS (fork              ${HDF_PREFIX}_HAVE_FORK)\nCHECK_FUNCTION_EXISTS (frexpf            ${HDF_PREFIX}_HAVE_FREXPF)\nCHECK_FUNCTION_EXISTS (frexpl            ${HDF_PREFIX}_HAVE_FREXPL)\n\nCHECK_FUNCTION_EXISTS (gethostname       ${HDF_PREFIX}_HAVE_GETHOSTNAME)\nCHECK_FUNCTION_EXISTS (getrusage         ${HDF_PREFIX}_HAVE_GETRUSAGE)\nCHECK_FUNCTION_EXISTS (llround           ${HDF_PREFIX}_HAVE_LLROUND)\nCHECK_FUNCTION_EXISTS (llroundf          ${HDF_PREFIX}_HAVE_LLROUNDF)\nCHECK_FUNCTION_EXISTS (lround            ${HDF_PREFIX}_HAVE_LROUND)\nCHECK_FUNCTION_EXISTS (lroundf           ${HDF_PREFIX}_HAVE_LROUNDF)\nCHECK_FUNCTION_EXISTS (lstat             ${HDF_PREFIX}_HAVE_LSTAT)\n\nCHECK_FUNCTION_EXISTS (pread             ${HDF_PREFIX}_HAVE_PREAD)\nCHECK_FUNCTION_EXISTS (pwrite            ${HDF_PREFIX}_HAVE_PWRITE)\nCHECK_FUNCTION_EXISTS (rand_r            ${HDF_PREFIX}_HAVE_RAND_R)\nCHECK_FUNCTION_EXISTS (random            ${HDF_PREFIX}_HAVE_RANDOM)\nCHECK_FUNCTION_EXISTS (round             ${HDF_PREFIX}_HAVE_ROUND)\nCHECK_FUNCTION_EXISTS (roundf            ${HDF_PREFIX}_HAVE_ROUNDF)\nCHECK_FUNCTION_EXISTS (setsysinfo        ${HDF_PREFIX}_HAVE_SETSYSINFO)\n\nCHECK_FUNCTION_EXISTS (signal            ${HDF_PREFIX}_HAVE_SIGNAL)\nCHECK_FUNCTION_EXISTS (longjmp           ${HDF_PREFIX}_HAVE_LONGJMP)\nCHECK_FUNCTION_EXISTS (setjmp            ${HDF_PREFIX}_HAVE_SETJMP)\nCHECK_FUNCTION_EXISTS (siglongjmp        ${HDF_PREFIX}_HAVE_SIGLONGJMP)\nCHECK_FUNCTION_EXISTS (sigsetjmp         ${HDF_PREFIX}_HAVE_SIGSETJMP)\nCHECK_FUNCTION_EXISTS (sigprocmask       ${HDF_PREFIX}_HAVE_SIGPROCMASK)\n\nCHECK_FUNCTION_EXISTS (snprintf          ${HDF_PREFIX}_HAVE_SNPRINTF)\nCHECK_FUNCTION_EXISTS (srandom           ${HDF_PREFIX}_HAVE_SRANDOM)\nCHECK_FUNCTION_EXISTS (strdup            ${HDF_PREFIX}_HAVE_STRDUP)\nCHECK_FUNCTION_EXISTS (strtoll           ${HDF_PREFIX}_HAVE_STRTOLL)\nCHECK_FUNCTION_EXISTS (strtoull          ${HDF_PREFIX}_HAVE_STRTOULL)\nCHECK_FUNCTION_EXISTS (symlink           ${HDF_PREFIX}_HAVE_SYMLINK)\nCHECK_FUNCTION_EXISTS (system            ${HDF_PREFIX}_HAVE_SYSTEM)\n\nCHECK_FUNCTION_EXISTS (tmpfile           ${HDF_PREFIX}_HAVE_TMPFILE)\nCHECK_FUNCTION_EXISTS (asprintf          ${HDF_PREFIX}_HAVE_ASPRINTF)\nCHECK_FUNCTION_EXISTS (vasprintf         ${HDF_PREFIX}_HAVE_VASPRINTF)\nCHECK_FUNCTION_EXISTS (waitpid           ${HDF_PREFIX}_HAVE_WAITPID)\n\nCHECK_FUNCTION_EXISTS (vsnprintf         ${HDF_PREFIX}_HAVE_VSNPRINTF)\nif (MINGW OR NOT WINDOWS)\n  if (${HDF_PREFIX}_HAVE_VSNPRINTF)\n    HDF_FUNCTION_TEST (VSNPRINTF_WORKS)\n  endif ()\nendif ()\n\n#-----------------------------------------------------------------------------\n# sigsetjmp is special; may actually be a macro\n#-----------------------------------------------------------------------------\nif (NOT ${HDF_PREFIX}_HAVE_SIGSETJMP)\n  if (${HDF_PREFIX}_HAVE_SETJMP_H)\n    CHECK_SYMBOL_EXISTS (sigsetjmp \"setjmp.h\" ${HDF_PREFIX}_HAVE_MACRO_SIGSETJMP)\n    if (${HDF_PREFIX}_HAVE_MACRO_SIGSETJMP)\n      set (${HDF_PREFIX}_HAVE_SIGSETJMP 1)\n    endif ()\n  endif ()\nendif ()\n\n#-----------------------------------------------------------------------------\n# Check a bunch of other functions\n#-----------------------------------------------------------------------------\nif (MINGW OR NOT WINDOWS)\n  foreach (other_test\n      HAVE_ATTRIBUTE\n      HAVE_C99_FUNC\n#      STDC_HEADERS\n      HAVE_FUNCTION\n      HAVE_C99_DESIGNATED_INITIALIZER\n      SYSTEM_SCOPE_THREADS\n      HAVE_SOCKLEN_T\n  )\n    HDF_FUNCTION_TEST (${other_test})\n  endforeach ()\nendif ()\n\n#-----------------------------------------------------------------------------\n# Check if InitOnceExecuteOnce is available\n#-----------------------------------------------------------------------------\nif (WINDOWS)\n  if (NOT HDF_NO_IOEO_TEST)\n  message (STATUS \"Checking for InitOnceExecuteOnce:\")\n  if (NOT DEFINED ${HDF_PREFIX}_HAVE_IOEO)\n    if (LARGEFILE)\n      set (CMAKE_REQUIRED_DEFINITIONS\n          \"${CURRENT_TEST_DEFINITIONS} -D_FILE_OFFSET_BITS=64 -D_LARGEFILE64_SOURCE -D_LARGEFILE_SOURCE\"\n      )\n    endif ()\n    set (MACRO_CHECK_FUNCTION_DEFINITIONS \"-DHAVE_IOEO ${CMAKE_REQUIRED_FLAGS}\")\n    if (CMAKE_REQUIRED_INCLUDES)\n      set (CHECK_C_SOURCE_COMPILES_ADD_INCLUDES \"-DINCLUDE_DIRECTORIES:STRING=${CMAKE_REQUIRED_INCLUDES}\")\n    else ()\n      set (CHECK_C_SOURCE_COMPILES_ADD_INCLUDES)\n    endif ()\n\n    TRY_RUN(HAVE_IOEO_EXITCODE HAVE_IOEO_COMPILED\n        ${CMAKE_BINARY_DIR}\n        ${HDF_RESOURCES_EXT_DIR}/HDFTests.c\n        COMPILE_DEFINITIONS \"${CMAKE_REQUIRED_DEFINITIONS} ${MACRO_CHECK_FUNCTION_DEFINITIONS}\"\n        LINK_LIBRARIES \"${HDF5_REQUIRED_LIBRARIES}\"\n        CMAKE_FLAGS \"${CHECK_C_SOURCE_COMPILES_ADD_INCLUDES} -DCMAKE_SKIP_RPATH:BOOL=${CMAKE_SKIP_RPATH}\"\n        COMPILE_OUTPUT_VARIABLE OUTPUT\n    )\n    # if it did not compile make the return value fail code of 1\n    if (NOT HAVE_IOEO_COMPILED)\n      set (HAVE_IOEO_EXITCODE 1)\n    endif ()\n    # if the return value was 0 then it worked\n    if (\"${HAVE_IOEO_EXITCODE}\" EQUAL 0)\n      set (${HDF_PREFIX}_HAVE_IOEO 1 CACHE INTERNAL \"Test InitOnceExecuteOnce\")\n      message (STATUS \"Performing Test InitOnceExecuteOnce - Success\")\n      file (APPEND ${CMAKE_BINARY_DIR}${CMAKE_FILES_DIRECTORY}/CMakeOutput.log\n        \"Performing C SOURCE FILE Test InitOnceExecuteOnce succeded with the following output:\\n\"\n        \"${OUTPUT}\\n\"\n        \"Return value: ${HAVE_IOEO}\\n\")\n    else ()\n      if (CMAKE_CROSSCOMPILING AND \"${HAVE_IOEO_EXITCODE}\" MATCHES  \"FAILED_TO_RUN\")\n        set (${HDF_PREFIX}_HAVE_IOEO \"${HAVE_IOEO_EXITCODE}\")\n      else ()\n        set (${HDF_PREFIX}_HAVE_IOEO \"\" CACHE INTERNAL \"Test InitOnceExecuteOnce\")\n      endif ()\n\n      message (STATUS \"Performing Test InitOnceExecuteOnce - Failed\")\n      file (APPEND ${CMAKE_BINARY_DIR}${CMAKE_FILES_DIRECTORY}/CMakeError.log\n        \"Performing InitOnceExecuteOnce Test  failed with the following output:\\n\"\n        \"${OUTPUT}\\n\"\n        \"Return value: ${HAVE_IOEO_EXITCODE}\\n\")\n    endif ()\n  endif ()\n  endif ()\nendif ()\n\n#-----------------------------------------------------------------------------\n# Determine how 'inline' is used\n#-----------------------------------------------------------------------------\nforeach (inline_test inline __inline__ __inline)\n  string (TOUPPER ${inline_test} INLINE_TEST_MACRO)\n  HDF_FUNCTION_TEST (HAVE_${INLINE_TEST_MACRO})\nendforeach ()\n\n#-----------------------------------------------------------------------------\n# Check how to print a Long Long integer\n#-----------------------------------------------------------------------------\nif (NOT ${HDF_PREFIX}_PRINTF_LL_WIDTH OR ${HDF_PREFIX}_PRINTF_LL_WIDTH MATCHES \"unknown\")\n  set (PRINT_LL_FOUND 0)\n  message (STATUS \"Checking for appropriate format for 64 bit long:\")\n  set (CURRENT_TEST_DEFINITIONS \"-DPRINTF_LL_WIDTH\")\n  if (${HDF_PREFIX}_SIZEOF_LONG_LONG)\n    set (CURRENT_TEST_DEFINITIONS \"${CURRENT_TEST_DEFINITIONS} -DHAVE_LONG_LONG\")\n  endif ()\n  TRY_RUN (${HDF_PREFIX}_PRINTF_LL_TEST_RUN   ${HDF_PREFIX}_PRINTF_LL_TEST_COMPILE\n      ${CMAKE_BINARY_DIR}\n      ${HDF_RESOURCES_EXT_DIR}/HDFTests.c\n      COMPILE_DEFINITIONS \"${CURRENT_TEST_DEFINITIONS}\"\n      RUN_OUTPUT_VARIABLE OUTPUT\n  )\n  if (${HDF_PREFIX}_PRINTF_LL_TEST_COMPILE)\n    if (${HDF_PREFIX}_PRINTF_LL_TEST_RUN MATCHES 0)\n      string(REGEX REPLACE \".*PRINTF_LL_WIDTH=\\\\[(.*)\\\\].*\" \"\\\\1\" ${HDF_PREFIX}_PRINTF_LL \"${OUTPUT}\")\n      set (${HDF_PREFIX}_PRINTF_LL_WIDTH \"\\\"${${HDF_PREFIX}_PRINTF_LL}\\\"\" CACHE INTERNAL \"Width for printf for type `long long' or `__int64', us. `ll\")\n      set (PRINT_LL_FOUND 1)\n    else ()\n      message (STATUS \"Width test failed with result: ${${HDF_PREFIX}_PRINTF_LL_TEST_RUN}\")\n    endif ()\n  else ()\n    file (APPEND ${CMAKE_BINARY_DIR}/CMakeFiles/CMakeError.log\n        \"Test ${HDF_PREFIX}_PRINTF_LL_WIDTH failed\\n\"\n    )\n  endif ()\n\n  if (PRINT_LL_FOUND)\n    message (STATUS \"Checking for appropriate format for 64 bit long: found ${${HDF_PREFIX}_PRINTF_LL_WIDTH}\")\n  else ()\n    message (STATUS \"Checking for appropriate format for 64 bit long: not found\")\n    set (${HDF_PREFIX}_PRINTF_LL_WIDTH \"\\\"unknown\\\"\" CACHE INTERNAL\n        \"Width for printf for type `long long' or `__int64', us. `ll\"\n    )\n  endif ()\nendif ()\n\n# ----------------------------------------------------------------------\n# Set the flag to indicate that the machine can handle converting\n# denormalized floating-point values.\n# (This flag should be set for all machines, except for the Crays, where\n# the cache value is set in it's config file)\n#\nset (${HDF_PREFIX}_CONVERT_DENORMAL_FLOAT 1)\n",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/src/H5PLpkg.h": "/* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\n * Copyright by The HDF Group.                                               *\n * Copyright by the Board of Trustees of the University of Illinois.         *\n * All rights reserved.                                                      *\n *                                                                           *\n * This file is part of HDF5.  The full HDF5 copyright notice, including     *\n * terms governing use, modification, and redistribution, is contained in    *\n * the COPYING file, which can be found at the root of the source code       *\n * distribution tree, or in https://support.hdfgroup.org/ftp/HDF5/releases.  *\n * If you do not have access to either file, you may request a copy from     *\n * help@hdfgroup.org.                                                        *\n * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * */\n\n/*\n * Purpose: This file contains declarations which are visible only within\n *          the H5PL package.  Source files outside the H5PL package should\n *          include H5PLprivate.h instead.\n */\n\n#if !(defined H5PL_FRIEND || defined H5PL_MODULE)\n#error \"Do not include this file outside the H5PL package!\"\n#endif\n\n#ifndef _H5PLpkg_H\n#define _H5PLpkg_H\n\n/* Include private header file */\n#include \"H5PLprivate.h\" /* Filter functions                */\n\n/* Other private headers needed by this file */\n\n/**************************/\n/* Package Private Macros */\n/**************************/\n\n/* Whether to pre-load pathnames for plugin libraries */\n#define H5PL_DEFAULT_PATH H5_DEFAULT_PLUGINDIR\n\n/****************************/\n/* Macros for supporting    */\n/* both Windows and POSIX   */\n/****************************/\n\n/*******************/\n/* Windows support */\n/*******************/\n/*\n * SPECIAL WINDOWS NOTE\n *\n * Some of the Win32 API functions expand to fooA or fooW depending on\n * whether UNICODE or _UNICODE are defined. You MUST explicitly use\n * the A version of the functions to force char * behavior until we\n * work out a scheme for proper Windows Unicode support.\n *\n * If you do not do this, people will be unable to incorporate our\n * source code into their own CMake builds if they define UNICODE.\n */\n#ifdef H5_HAVE_WIN32_API\n\n/* The path separator on this platform */\n#define H5PL_PATH_SEPARATOR \";\"\n\n/* Handle for dynamic library */\n#define H5PL_HANDLE HINSTANCE\n\n/* Get a handle to a plugin library.  Windows: TEXT macro handles Unicode strings */\n#define H5PL_OPEN_DLIB(S) LoadLibraryExA(S, NULL, LOAD_WITH_ALTERED_SEARCH_PATH)\n\n/* Get the address of a symbol in dynamic library */\n#define H5PL_GET_LIB_FUNC(H, N) GetProcAddress(H, N)\n\n/* Close dynamic library */\n#define H5PL_CLOSE_LIB(H) FreeLibrary(H)\n\n/* Clear error - nothing to do */\n#define H5PL_CLR_ERROR\n\n/* maximum size for expanding env vars */\n#define H5PL_EXPAND_BUFFER_SIZE 32767\n\ntypedef H5PL_type_t(__cdecl *H5PL_get_plugin_type_t)(void);\ntypedef const void *(__cdecl *H5PL_get_plugin_info_t)(void);\n\n#else /* H5_HAVE_WIN32_API */\n\n/*****************/\n/* POSIX support */\n/*****************/\n\n/* The path separator on this platform */\n#define H5PL_PATH_SEPARATOR     \":\"\n\n/* Handle for dynamic library */\n#define H5PL_HANDLE             void *\n\n/* Get a handle to a plugin library.  Windows: TEXT macro handles Unicode strings */\n#define H5PL_OPEN_DLIB(S)       dlopen(S, RTLD_LAZY | RTLD_LOCAL)\n\n/* Get the address of a symbol in dynamic library */\n#define H5PL_GET_LIB_FUNC(H, N) dlsym(H, N)\n\n/* Close dynamic library */\n#define H5PL_CLOSE_LIB(H)       dlclose(H)\n\n/* Clear error */\n#define H5PL_CLR_ERROR          HERROR(H5E_PLUGIN, H5E_CANTGET, \"can't dlopen:%s\", dlerror())\n\ntypedef H5PL_type_t (*H5PL_get_plugin_type_t)(void);\ntypedef const void *(*H5PL_get_plugin_info_t)(void);\n#endif /* H5_HAVE_WIN32_API */\n\n/****************************/\n/* Package Private Typedefs */\n/****************************/\n\n/* Data used to search for plugins */\ntypedef struct H5PL_search_params_t {\n    H5PL_type_t       type;\n    const H5PL_key_t *key;\n} H5PL_search_params_t;\n\n/*****************************/\n/* Package Private Variables */\n/*****************************/\n\n/******************************/\n/* Package Private Prototypes */\n/******************************/\n\n/* Accessors to global variables and flags */\nH5_DLL herr_t H5PL__get_plugin_control_mask(unsigned int *mask /*out*/);\nH5_DLL herr_t H5PL__set_plugin_control_mask(unsigned int mask);\n\n/* Plugin search and manipulation */\nH5_DLL herr_t H5PL__open(const char *libname, H5PL_type_t type, const H5PL_key_t *key,\n                         hbool_t *success /*out*/, const void **plugin_info /*out*/);\nH5_DLL herr_t H5PL__close(H5PL_HANDLE handle);\n\n/* Plugin cache calls */\nH5_DLL herr_t H5PL__create_plugin_cache(void);\nH5_DLL herr_t H5PL__close_plugin_cache(hbool_t *already_closed /*out*/);\nH5_DLL herr_t H5PL__add_plugin(H5PL_type_t type, const H5PL_key_t *key, H5PL_HANDLE handle);\nH5_DLL herr_t H5PL__find_plugin_in_cache(const H5PL_search_params_t *search_params, hbool_t *found /*out*/,\n                                         const void **plugin_info /*out*/);\n\n/* Plugin search path calls */\nH5_DLL herr_t      H5PL__create_path_table(void);\nH5_DLL herr_t      H5PL__close_path_table(void);\nH5_DLL unsigned    H5PL__get_num_paths(void);\nH5_DLL herr_t      H5PL__append_path(const char *path);\nH5_DLL herr_t      H5PL__prepend_path(const char *path);\nH5_DLL herr_t      H5PL__replace_path(const char *path, unsigned int index);\nH5_DLL herr_t      H5PL__insert_path(const char *path, unsigned int index);\nH5_DLL herr_t      H5PL__remove_path(unsigned int index);\nH5_DLL const char *H5PL__get_path(unsigned int index);\nH5_DLL herr_t      H5PL__find_plugin_in_path_table(const H5PL_search_params_t *search_params,\n                                                   hbool_t *found /*out*/, const void **plugin_info /*out*/);\n\n#endif /* _H5PLpkg_H */\n",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/release_docs/RELEASE.txt": "HDF5 version 1.13.0 currently under development\n================================================================================\n\n\nINTRODUCTION\n\nThis document describes the differences between this release and the previous\nHDF5 release. It contains information on the platforms tested and known\nproblems in this release. For more details check the HISTORY*.txt files in the\nHDF5 source.\n\nNote that documentation in the links below will be updated at the time of each\nfinal release.\n\nLinks to HDF5 documentation can be found on The HDF5 web page:\n\n     https://portal.hdfgroup.org/display/HDF5/HDF5\n\nThe official HDF5 releases can be obtained from:\n\n     https://www.hdfgroup.org/downloads/hdf5/\n\nChanges from Release to Release and New Features in the HDF5-1.13.x release series\ncan be found at:\n\n     https://portal.hdfgroup.org/display/HDF5/HDF5+Application+Developer%27s+Guide\n\nIf you have any questions or comments, please send them to the HDF Help Desk:\n\n     help@hdfgroup.org\n\n\nCONTENTS\n\n- New Features\n- Support for new platforms and languages\n- Bug Fixes since HDF5-1.10.3\n- Bug Fixes since HDF5-1.10.2\n- Supported Platforms\n- Tested Configuration Features Summary\n- More Tested Platforms\n- Known Problems\n- CMake vs. Autotools installations\n\n\nNew Features\n============\n\n    Configuration:\n    -------------\n    - CMake option to build the HDF filter plugins project as an external project\n\n      The HDF filter plugins project is a collection of registered compression\n      filters that can be dynamically loaded when needed to access data stored\n      in a hdf5 file. This CMake-only option allows the plugins to be built and\n      distributed with the hdf5 library and tools. Like the options for szip and\n      zlib, either a tgz file or a git repository can be specified for the source.\n\n      The necessary options are (see the INSTALL_CMake.txt file):\n          HDF5_ENABLE_PLUGIN_SUPPORT\n          PLUGIN_TGZ_NAME or PLUGIN_GIT_URL\n      There are more options necessary for various filters and the plugin project\n      documents should be referenced.\n\n      (ADB - 2020/09/27, OESS-98)\n\n    - Added CMake option to format source files\n\n      HDF5_ENABLE_FORMATTERS option will enable creation of targets using the\n      pattern - HDF5_*_SRC_FORMAT - where * corresponds to the source folder\n      or tool folder. All sources can be formatted by executing the format target;\n         make format\n\n      (ADB - 2020/08/24)\n\n    - CMake option to link the generated Fortran MOD files into the include\n      directory.\n\n      The Fortran generation of MOD files by a Fortran compile can produce\n      different binary files between SHARED and STATIC compiles with different\n      compilers and/or different platforms. Note that it has been found that\n      different versions of Fortran compilers will produce incompatible MOD\n      files. Currently, CMake will locate these MOD files in subfolders of\n      the include directory and add that path to the Fortran library target\n      in the CMake config file, which can be used by the CMake find library\n      process. For other build systems using the binary from a CMake install,\n      a new CMake configuration can be used to copy the pre-chosen version\n      of the Fortran MOD files into the install include directory.\n\n      The default will depend on the configuration of\n      BUILD_STATIC_LIBS and BUILD_SHARED_LIBS:\n            YES                   YES         Default to SHARED\n            YES                   NO          Default to STATIC\n            NO                    YES         Default to SHARED\n            NO                    NO          Default to SHARED\n      The defaults can be overriden by setting the config option\n         HDF5_INSTALL_MOD_FORTRAN to one of NO, SHARED, or STATIC\n\n      (ADB - 2020/07/9, HDFFV-11116)\n\n    - CMake option to use AEC (open source SZip) library instead of SZip\n\n      The open source AEC library is a replacement library for SZip. In\n      order to use it for hdf5 the libaec CMake source was changed to add\n      \"-fPIC\" and exclude test files. Autotools does not build the\n      compression libraries within hdf5 builds. New option USE_LIBAEC is\n      required to compensate for the different files produced by AEC build.\n\n      (ADB - 2020/04/22, OESS-65)\n\n    - CMake ConfigureChecks.cmake file now uses CHECK_STRUCT_HAS_MEMBER\n\n      Some handcrafted tests in HDFTests.c has been removed and the CMake\n      CHECK_STRUCT_HAS_MEMBER module has been used.\n\n      (ADB - 2020/03/24, TRILAB-24)\n\n    - Both build systems use same set of warnings flags\n\n      GNU C, C++ and gfortran warnings flags were moved to files in a config\n      sub-folder named gnu-warnings. Flags that only are available for a specific\n      version of the compiler are in files named with that version.\n      Clang C warnings flags were moved to files in a config sub-folder\n      named clang-warnings.\n      Intel C, Fortran warnings flags were moved to files in a config sub-folder\n      named intel-warnings.\n\n      There are flags in named \"error-xxx\" files with warnings that may\n      be promoted to errors. Some source files may still need fixes.\n\n      There are also pairs of files named \"developer-xxx\" and \"no-developer-xxx\"\n      that are chosen by the CMake option:HDF5_ENABLE_DEV_WARNINGS or the\n      configure option:--enable-developer-warnings.\n\n      In addition, CMake no longer applies these warnings for examples.\n\n      (ADB - 2020/03/24, TRILAB-192)\n\n    - Added test script for file size compare\n\n      if CMake minimum version is at least 3.14, the fileCompareTest.cmake\n      script will compare file sizes.\n\n      (ADB - 2020/02/24, HDFFV-11036)\n\n    - Update CMake minimum version to 3.12\n\n      Updated CMake minimum version to 3.12 and added version checks\n      for Windows features.\n\n      (ADB - 2020/02/05, TRILABS-142)\n\n    - Fixed CMake include properties for Fortran libraries\n\n      Corrected the library properties for Fortran to use the\n      correct path for the Fortran module files.\n\n      (ADB - 2020/02/04, HDFFV-11012)\n\n    - Added common warnings files for gnu and intel\n\n      Added warnings files to use one common set of flags\n      during configure for both autotools and CMake build\n      systems. The initial implementation only affects a\n      general set of flags for gnu and intel compilers.\n\n      (ADB - 2020/01/17)\n\n    - Added new options to CMake for control of testing\n\n      Added CMake options (default ON);\n          HDF5_TEST_SERIAL AND/OR HDF5_TEST_PARALLEL\n          combined with:\n            HDF5_TEST_TOOLS\n            HDF5_TEST_EXAMPLES\n            HDF5_TEST_SWMR\n            HDF5_TEST_FORTRAN\n            HDF5_TEST_CPP\n            HDF5_TEST_JAVA\n\n      (ADB - 2020/01/15, HDFFV-11001)\n\n    - Added Clang sanitizers to CMake for analyzer support if compiler is clang.\n\n      Added CMake code and files to execute the Clang sanitizers if\n      HDF5_ENABLE_SANITIZERS is enabled and the USE_SANITIZER option\n      is set to one of the following:\n          Address\n          Memory\n          MemoryWithOrigins\n          Undefined\n          Thread\n          Leak\n          'Address;Undefined'\n\n      (ADB - 2019/12/12, TRILAB-135)\n\n    - Update CMake for VS2019 support\n\n      CMake added support for VS2019 in version 3.15. Changes to the CMake\n      generator setting required changes to scripts. Also updated version\n      references in CMake files as necessary.\n\n      (ADB - 2019/11/18, HDFFV-10962)\n\n    - Update CMake options to match new autotools options\n\n      Add configure options (autotools - CMake):\n            enable-asserts       HDF5_ENABLE_ASSERTS\n            enable-symbols       HDF5_ENABLE_SYMBOLS\n            enable-profiling     HDF5_ENABLE_PROFILING\n            enable-optimization  HDF5_ENABLE_OPTIMIZATION\n      In addition NDEBUG is no longer forced defined and relies on the CMake\n      process.\n\n      (ADB - 2019/10/07, HDFFV-100901, HDFFV-10637, TRILAB-97)\n\n    - Update CMake tests to use FIXTURES\n\n      CMake test fixtures allow setup/cleanup tests and other dependency\n      requirements as properties for tests. This is more flexible for\n      modern CMake code.\n\n      (ADB - 2019/07/23, HDFFV-10529)\n\n    - Windows PDB files are always installed\n\n      There are build configuration or flag settings for Windows that may not\n      generate PDB files. If those files are not generated then the install\n      utility will fail because those PDB files are not found. An optional\n      variable, DISABLE_PDB_FILES, was added to not install PDB files.\n\n      (ADB - 2019/07/17, HDFFV-10424)\n\n    - Add mingw CMake support with a toolchain file\n\n      There has been a number of mingw issues that has been linked under\n      HDFFV-10845. It has been decided to implement the CMake cross-compiling\n      technique of toolchain files. We will use a linux platform with the mingw\n      compiler stack for testing. Only the C language is fully supported, and\n      the error tests are skipped. The C++ language works for static but shared\n      builds has a shared library issue with the mingw Standard Exception Handling\n      library, which is not available on Windows. Fortran has a common cross-compile\n      problem with the fortran configure tests.\n\n      (ADB - 2019/07/12, HDFFV-10845, HDFFV-10595)\n\n    - Windows PDB files are installed incorrectly\n\n      For static builds, the PDB files for windows should be installed next\n      to the static libraries in the lib folder. Also the debug versions of\n      libraries and PDB files are now correctly built using the default\n      CMAKE_DEBUG_POSTFIX setting.\n\n      (ADB - 2019/07/09, HDFFV-10581)\n\n    - Add option to build only shared libs\n\n      A request was made to prevent building static libraries and only build\n      shared.  A new option was added to CMake, ONLY_SHARED_LIBS, which will\n      skip building static libraries. Certain utility functions will build with\n      static libs but are not published. Tests are adjusted to use the correct\n      libraries depending on SHARED/STATIC settings.\n\n      (ADB - 2019/06/12, HDFFV-10805)\n\n    - Add options to enable or disable building tools and tests\n\n      Configure options --enable-tests and --enable-tools were added for\n      autotools configure.  These options are enabled by default, and can be\n      disabled with either --disable-tests (or tools) or --enable-tests=no\n      (or --enable-tools=no).  Build time is reduced ~20% when tools are\n      disabled, 35% when tests are disabled, 45% when both are disabled.\n      Reenabling them after the initial build requires running configure\n      again with the option(s) enabled.\n\n      (LRK - 2019/06/12, HDFFV-9976)\n\n    - Change tools test that test the error stack\n\n      There are some use cases which can cause the error stack of tools to be\n      different then the expected output. These tests now use grepTest.cmake,\n      this was changed to allow the error file to be searched for an expected string.\n\n      (ADB - 2019/04/15, HDFFV-10741)\n\n    - Keep stderr and stdout separate in tests\n\n      Changed test handling of output capture. Tests now keep the stderr\n      output separate from the stdout output. It is up to the test to decide\n      which output to check against a reference. Also added the option\n      to grep for a string in either output.\n\n      (ADB - 2018/12/12, HDFFV-10632)\n\n    - Add toolchain and cross-compile support\n\n      Added info on using a toolchain file to INSTALL_CMAKE.txt. A\n      toolchain file is also used in cross-compiling, which requires\n      CMAKE_CROSSCOMPILING_EMULATOR to be set. To help with cross-compiling\n      the fortran configure process, the HDF5UseFortran.cmake file macros\n      were improved. Fixed a Fortran configure file issue that incorrectly\n      used #cmakedefine instead of #define.\n\n      (ADB - 2018/10/04, HDFFV-10594)\n\n    - Add warning flags for Intel compilers\n\n      Identified Intel compiler specific warnings flags that should be used\n      instead of GNU flags.\n\n      (ADB - 2018/10/04, TRILABS-21)\n\n    - Add default rpath to targets\n\n      Default rpaths should be set in shared executables and\n      libraries to allow the use of loading dependent libraries\n      without requiring LD_LIBRARY_PATH to be set. The default\n      path should be relative using @rpath on osx and $ORIGIN\n      on linux. Windows is not affected.\n\n      (ADB - 2018/09/26, HDFFV-10594)\n\n    - Add missing USE_110_API_DEFAULT option.\n\n      Option USE_110_API_DEFAULT sets the default version of\n      versioned APIs. The bin/makevers perl script did not set\n      the maxidx variable correctly when the 1.10 branch was\n      created. This caused the versioning process to always use\n      the latest version of any API.\n\n      (ADB - 2018/08/17, HDFFV-10552)\n\n    - Added configuration checks for the following MPI functions:\n\n      MPI_Mprobe - Used for the Parallel Compression feature\n      MPI_Imrecv - Used for the Parallel Compression feature\n\n      MPI_Get_elements_x - Used for the \"big Parallel I/O\" feature\n      MPI_Type_size_x - Used for the \"big Parallel I/O\" feature\n\n      (JTH - 2018/08/02, HDFFV-10512)\n\n    - Added section to the libhdf5.settings file to indicate\n      the status of the Parallel Compression and \"big Parallel I/O\"\n      features.\n\n      (JTH - 2018/08/02, HDFFV-10512)\n\n    - Add option to execute swmr shell scripts from CMake.\n\n      Option TEST_SHELL_SCRIPTS redirects processing into a\n      separate ShellTests.cmake file for UNIX types. The tests\n      execute the shell scripts if a SH program is found.\n\n      (ADB - 2018/07/16)\n\n    - Add file locking configure and CMake options\n\n      HDF5 1.10.0 introduced a file locking scheme, primarily to help\n      enforce SWMR setup. Formerly, the only user-level control of the scheme\n      was via the HDF5_USE_FILE_LOCKING environment variable.\n\n      This change introduces configure-time options that control whether\n      or not file locking will be used and whether or not the library\n      ignores errors when locking has been disabled on the file system\n      (useful on some HPC Lustre installations).\n\n      In both the Autotools and CMake, the settings have the effect of changing\n      the default property list settings (see the H5Pset/get_file_locking()\n      entry, below).\n\n      The yes/no/best-effort file locking configure setting has also been\n      added to the libhdf5.settings file.\n\n      Autotools:\n\n        An --enable-file-locking=(yes|no|best-effort) option has been added.\n\n        yes:          Use file locking.\n        no:           Do not use file locking.\n        best-effort:  Use file locking and ignore \"disabled\" errors.\n\n      CMake:\n\n        Two self-explanatory options have been added:\n\n        HDF5_USE_FILE_LOCKING\n        HDF5_IGNORE_DISABLED_FILE_LOCKS\n\n        Setting both of these to ON is the equivalent to the Autotools'\n        best-effort setting.\n\n      NOTE:\n      The precedence order of the various file locking control mechanisms is:\n\n        1) HDF5_USE_FILE_LOCKING environment variable (highest)\n\n        2) H5Pset_file_locking()\n\n        3) configure/CMake options (which set the property list defaults)\n\n        4) library defaults (currently best-effort)\n\n      (DER - 2020/07/30, HDFFV-11092)\n\n\n    Library:\n    --------\n    - Add new public function H5Ssel_iter_reset\n\n      This function resets a dataspace selection iterator back to an\n      initial state so that it may be used for iteration once more.\n      This can be useful when needing to iterate over a selection\n      multiple times without having to repeatedly create/destroy\n      a selection iterator for that dataspace selection.\n\n      (JTH - 2020/09/18)\n\n    - Remove HDFS VFD stubs\n\n      The original implementation of the HDFS VFD included non-functional\n      versions of the following public API calls when the HDFS VFD is\n      not built as a part of the HDF5 library:\n\n      * H5FD_hdfs_init()\n      * H5Pget_fapl_hdfs()\n      * H5Pset_fapl_hdfs()\n\n      They will remain present in HDF5 1.10 and HDF5 1.12 releases\n      for binary compatibility purposes but have been removed as of 1.14.0.\n\n      Note that this has nothing to do with the real HDFS VFD API calls\n      that are fully functional when the HDFS VFD is configured and built.\n\n      We simply changed:\n\n      #ifdef LIBHDFS\n        <real API call>\n      #else\n        <useless stub>\n      #endif\n\n      to:\n\n      #ifdef LIBHDFS\n        <real API call>\n      #endif\n\n      Which is how the other optional VFDs are handled.\n\n      (DER - 2020/08/27)\n\n    - Add Mirror VFD\n\n      Use TCP/IP sockets to perform write-only (W/O) file I/O on a remote\n      machine. Must be used in conjunction with the Splitter VFD.\n\n      (JOS - 2020/03/13, TBD)\n\n    - Add Splitter VFD\n\n      Maintain separate R/W and W/O channels for \"concurrent\" file writes\n      to two files using a single HDF5 file handle.\n\n     (JOS - 2020/03/13, TBD)\n\n    - Refactored public exposure of haddr_t type in favor of \"object tokens\"\n\n      To better accommodate HDF5 VOL connectors where \"object addresses in a file\"\n      may not make much sense, the following changes were made to the library:\n\n      * Introduced new H5O_token_t \"object token\" type, which represents a\n        unique and permanent identifier for referencing an HDF5 object within\n        a container; these \"object tokens\" are meant to replace object addresses.\n        Along with the new type, a new H5Oopen_by_token API call was introduced\n        to open an object by a token, similar to how object addresses were\n        previously used with H5Oopen_by_addr.\n\n      * Introduced new H5Lget_info2, H5Lget_info_by_idx2, H5Literate2, H5Literate_by_name2,\n        H5Lvisit2 and H5Lvisit_by_name2 API calls, along with their associated H5L_info2_t\n        struct and H5L_iterate2_t callback function, which work with the newly-introduced\n        object tokens, instead of object addresses. The original functions have been\n        renamed to version 1 functions and are deprecated in favor of the new version 2\n        functions. The H5L_info_t and H5L_iterate_t types have been renamed to version 1\n        types and are now deprecated in favor of their version 2 counterparts. For each of\n        the functions and types, compatibility macros take place of the original symbols.\n\n      * Introduced new H5Oget_info3, H5Oget_info_by_name3, H5Oget_info_by_idx3,\n        H5Ovisit3 and H5Ovisit_by_name3 API calls, along with their associated H5O_info2_t\n        struct and H5O_iterate2_t callback function, which work with the newly-introduced\n        object tokens, instead of object addresses. The version 2 functions are now\n        deprecated in favor of the version 3 functions. The H5O_info_t and H5O_iterate_t\n        types have been renamed to version 1 types and are now deprecated in favor of their\n        version 2 counterparts. For each, compatibility macros take place of the original\n        symbols.\n\n      * Introduced new H5Oget_native_info, H5Oget_native_info_by_name and\n        H5Oget_native_info_by_idx API calls, along with their associated H5O_native_info_t\n        struct, which are used to retrieve the native HDF5 file format-specific information\n        about an object. This information (such as object header info and B-tree/heap info)\n        has been removed from the new H5O_info2_t struct so that the more generic\n        H5Oget_info(_by_name/_by_idx)3 routines will not try to retrieve it for non-native\n        VOL connectors.\n\n      * Added new H5Otoken_cmp, H5Otoken_to_str and H5Otoken_from_str routines to compare\n        two object tokens, convert an object token into a nicely-readable string format and\n        to convert an object token string back into a real object token, respectively.\n\n      (DER, QAK, JTH - 2020/01/16)\n\n    - Add new public function H5Sselect_adjust.\n\n      This function shifts a dataspace selection by a specified logical offset\n      within the dataspace extent.  This can be useful for VOL developers to\n      implement chunked datasets.\n\n      (NAF - 2019/11/18)\n\n    - Add new public function H5Sselect_project_intersection.\n\n      This function computes the intersection between two dataspace selections\n      and projects that intersection into a third selection.  This can be useful\n      for VOL developers to implement chunked or virtual datasets.\n\n      (NAF - 2019/11/13, ID-148)\n\n    - Add new public function H5VLget_file_type.\n\n      This function returns a datatype equivalent to the supplied datatype but\n      with the location set to be in the file.  This datatype can then be used\n      with H5Tconvert to convert data between file and in-memory representation.\n      This funcition is intended for use only by VOL connector developers.\n\n      (NAF - 2019/11/08, ID-127)\n\n    - Add S3 and HDFS VFDs to HDF5 maintenance\n\n      Fix windows requirements and java tests. Windows requires CMake 3.13.\n            Install openssl library (with dev files);\n            from \"Shining Light Productions\". msi package preferred.\n\n            PATH should have been updated with the installation dir.\n            set ENV variable OPENSSL_ROOT_DIR to the installation dir.\n            set ENV variable OPENSSL_CONF to the cfg file, likely %OPENSSL_ROOT_DIR%\\bin\\openssl.cfg\n            Install libcurl library (with dev files);\n            download the latest released version using git: https://github.com/curl/curl.git\n\n            Open a Visual Studio Command prompt\n            change to the libcurl root folder\n            run the \"buildconf.bat\" batch file\n            change to the winbuild directory\n            nmake /f Makefile.vc mode=dll MACHINE=x64\n            copy libcurl-vc-x64-release-dll-ipv6-sspi-winssl dir to C:\\curl (installation dir)\n            set ENV variable CURL_ROOT to C:\\curl (installation dir)\n            update PATH ENV variable to %CURL_ROOT%\\bin (installation bin dir).\n            the aws credentials file should be in %USERPROFILE%\\.aws folder\n            set the ENV variable \"HDF5_ROS3_TEST_BUCKET_URL=https://s3.us-east-2.amazonaws.com/hdf5ros3\"\n\n      (ADB - 2019/09/12, HDFFV-10854)\n\n    - Added new chunk query functions\n\n      The following public functions were added to discover information about\n      the chunks in an HDF5 file.\n        herr_t H5Dget_num_chunks(dset_id, fspace_id, *nchunks)\n        herr_t H5Dget_chunk_info_by_coord(dset_id, *coord, *filter_mask, *addr, *size)\n        herr_t H5Dget_chunk_info(dset_id, fspace_id, index, *coord, *filter_mask, *addr, *size)\n\n      (BMR - 2019/06/11, HDFFV-10677)\n\n    - Improved the performance of virtual dataset I/O\n\n      Refactored the internal dataspace routines used by the virtual dataset\n      code to improve performance, especially when one of the selections\n      involved is very long and non-contiguous.\n\n      (NAF - 2019/05/31, HDFFV-10693)\n\n    - Added the ability to open files with UTF-8 file names on Windows.\n\n      The POSIX open(2) API call on Windows is limited to ASCII\n      file names. The library has been updated to convert incoming file\n      names to UTF-16 (via MultiByteToWideChar(CP_UTF8, ...) and use\n      _wopen() instead.\n\n     (DER - 2019/03/15, HDFFV-2714, HDFFV-3914, HDFFV-3895, HDFFV-8237, HDFFV-10413, HDFFV-10691)\n\n    - Add new API H5M for map objects.  Currently not supported by native\n      library, can be supported by VOL connectors.\n\n      (NAF - 2019/03/01)\n\n    - Add new H5R_ref_t type for object, dataset region and _attribute_\n      references. This new type will deprecate the current hobj_ref_t\n      and hdset_reg_ref_t types for references. Added H5T_REF datatype\n      to read and write new reference types. As opposed to previous\n      reference types, reference creation no longer modifies existing\n      files. New reference types also now support references to external\n      files.\n\n      (JS - 2019/10/08)\n\n    - Remove H5I_REFERENCE from the library\n\n      This ID class was never used by the library and has been removed.\n\n      (DER - 2018/12/08, HDFFV-10252)\n\n    - Allow pre-generated H5Tinit.c and H5make_libsettings.c to be used.\n\n      Rather than always running H5detect and generating H5Tinit.c and\n      H5make_libsettings.c, supply a location for those files.\n\n      (ADB - 2018/09/18, HDFFV-10332)\n\n    - Fix shutdown failure when using H5VLregister_connector_by_name/value\n\n      When using H5VLregister_connector_by_name/value to dynamically load a\n      VOL connector plugin, the library can experience segmentation faults\n      when the library is closed. This is due to the library unloading\n      the plugin interface before the virtual object layer. Then, when the\n      VOL shutdown occurs, it will attempt to close the VOL connector,\n      however this will fail since the plugin will already have been unloaded.\n\n      (DER - 2020/03/18, HDFFV-11057)\n\n    - Add BEST_EFFORT value to HDF5_USE_FILE_LOCKING environment variable\n\n      This change adds a BEST_EFFORT to the TRUE/FALSE, 1/0 settings that\n      were previously accepted. This option turns on file locking but\n      ignores locking errors when the library detects that file locking\n      has been disabled on a file system (useful on some HPC Lustre\n      installations).\n\n      The capitalization of BEST_EFFORT is mandatory.\n\n      See the configure option discussion for HDFFV-11092 (above) for more\n      information on the file locking feature and how it's controlled.\n\n      (DER - 2020/07/30, HDFFV-11092)\n\n\n    - Add H5Pset/get_file_locking() API calls\n\n      This change adds new API calls which can be used to set or get the\n      file locking parameters. The single API call sets both the \"use file\n      locking\" flag and the \"ignore disabled file locking\" flag.\n\n      See the configure option discussion for HDFFV-11092 (above) for more\n      information on the file locking feature and how it's controlled.\n\n      (DER - 2020/07/30, HDFFV-11092)\n\n    Parallel Library:\n    -----------------\n    - Changed the default behavior in parallel when reading the same dataset in its entirely\n      (i.e. H5S_ALL dataset selection) which is being read by all the processes collectively.\n      The dataset mush be contiguous, less than 2GB, and of an atomic datatype.\n      The new behavior is the HDF5 library will use an MPI_Bcast to pass the data read from\n      the disk by the root process to the remain processes in the MPI communicator associated\n      with the HDF5 file.\n\n      (MSB - 2019/01/02, HDFFV-10652)\n\n    Fortran Library:\n    ----------------\n    - Added new Fortran derived type, c_h5o_info_t, which is interoperable with\n      C's h5o_info_t. This is needed for callback functions which\n      pass C's h5o_info_t data type definition.\n\n      (MSB, 2019/01/08, HDFFV-10443)\n\n    - Added new Fortran API, H5gmtime, which converts (C) 'time_t' structure\n      to Fortran DATE AND TIME storage format.\n\n      (MSB, 2019/01/08, HDFFV-10443)\n\n    - Added new Fortran 'fields' optional parameter to: h5ovisit_f, h5oget_info_by_name_f,\n      h5oget_info, h5oget_info_by_idx and h5ovisit_by_name_f.\n\n      (MSB, 2019/01/08, HDFFV-10443)\n\n    - Add wrappers for H5Pset/get_file_locking() API calls\n\n      h5pget_file_locking_f()\n      h5pset_file_locking_f()\n\n      See the configure option discussion for HDFFV-11092 (above) for more\n      information on the file locking feature and how it's controlled.\n\n      (DER - 2020/07/30, HDFFV-11092)\n\n    C++ Library:\n    ------------\n    - Added new wrappers for H5Pset/get_create_intermediate_group()\n        LinkCreatPropList::getCreateIntermediateGroup()\n        LinkCreatPropList::setCreateIntermediateGroup()\n\n      (BMR - 2019/04/22, HDFFV-10622)\n\n    - Added new wrapper for H5Ovisit2()\n          H5Object::visit()\n\n      (BMR - 2019/02/14, HDFFV-10532)\n\n    - Add wrappers for H5Pset/get_file_locking() API calls\n\n      FileAccPropList::setFileLocking()\n      FileAccPropList::getFileLocking()\n\n      See the configure option discussion for HDFFV-11092 (above) for more\n      information on the file locking feature and how it's controlled.\n\n      (DER - 2020/07/30, HDFFV-11092)\n\n\n    Java Library:\n    ----------------\n    - Added ability to test java library with VOLs.\n\n      Created new CMake script that combines the java and vol test scripts.\n\n      (ADB - 2020/02/03, HDFFV-10996)\n\n    - Tests fail for non-English locale.\n\n      In the JUnit tests with a non-English locale, only the part before\n      the decimal comma is replaced by XXXX and this leads to a comparison\n      error. Changed the regex for the Time substitution.\n\n      (ADB - 2020/01/09, HDFFV-10995)\n\n    - Fix a failure in JUnit-TestH5P on 32-bit architectures\n\n      (JTH - 2019/04/30)\n\n    - Duplicate the data read/write functions of Datasets for Attributes.\n\n      Region references could not be displayed for attributes as they could\n      for datasets. Datasets had overloaded read and write functions for different\n      datatypes that were not available for attributes. After adding similar\n      functions, attribute region references work normally.\n\n      (ADB - 2018/12/12, HDFVIEW-4)\n\n    - Removed H5I_REFERENCE from the Java wrappers\n\n      This ID class was never used by the library and has been removed\n      from the Java wrappers.\n\n      (DER - 2018/12/08, HDFFV-10252)\n\n    - Add wrappers for H5Pset/get_file_locking() API calls\n\n      H5Pset_file_locking()\n      H5Pget_use_file_locking()\n      H5Pget_ignore_disabled_file_locking()\n\n      Unlike the C++ and Fortran wrappers, there are separate getters for the\n      two file locking settings, each of which returns a boolean value.\n\n      See the configure option discussion for HDFFV-11092 (above) for more\n      information on the file locking feature and how it's controlled.\n\n      (DER - 2020/07/30, HDFFV-11092)\n\n\n    Tools:\n    ------\n    - h5repack added options to control how external links are handled.\n\n      Currently h5repack preserves external links and cannot copy and merge\n      data from the external files. Two options, merge and prune, were added to\n      control how to merge data from an external link into the resulting file.\n       --merge             Follow external soft link recursively and merge data.\n       --prune             Do not follow external soft links and remove link.\n       --merge --prune     Follow external link, merge data and remove dangling link.\n\n      (ADB - 2020/08/05, HDFFV-9984)\n\n    - h5repack was fixed to repack the reference attributes properly.\n      The code line that checks if the update of reference inside a compound\n      datatype is misplaced outside the code block loop that carries out the\n      check. In consequence, the next attribute that is not the reference\n      type was repacked again as the reference type and caused the failure of\n      repacking. The fix is to move the corresponding code line to the correct\n      code block.\n\n      (KY -2020/02/07, HDFFV-11014)\n\n    - h5diff was updated to use the new reference APIs.\n\n      h5diff uses the new reference APIs to compare references.\n      Attribute references can also be compared.\n\n      (ADB - 2019/12/19, HDFFV-10980)\n\n    - h5dump and h5ls were updated to use the new reference APIs.\n\n      The tools library now use the new reference APIs to inspect a\n      file. Also the DDL spec was updated to reflect the format\n      changes produced with the new APIs. The export API and support\n      functions in the JNI were updated to match.\n\n      (ADB - 2019/12/06, HDFFV-10876 and HDFFV-10877)\n\n    - h5repack was fixed to repack datasets with external storage\n      to other types of storage.\n\n      New test added to repack files and verify the correct data using h5diff.\n\n      (JS - 2019/09/25, HDFFV-10408)\n      (ADB - 2019/10/02, HDFFV-10918)\n\n    - h5dump was fixed for 128-bit floats, but was missing a test.\n\n      New test greps for the first 15 numbers of the 128-bit value.\n\n      (ADB - 2019/06/23, HDFFV-9407)\n\n\n    High-Level APIs:\n    ---------------\n    -\n\n    C Packet Table API\n    ------------------\n    -\n\n    Internal header file\n    --------------------\n    -\n\n    Documentation\n    -------------\n    -\n\nSupport for new platforms, languages and compilers.\n=======================================\n    -\n\nBug Fixes since HDF5-1.10.3 release\n==================================\n\n    Library\n    -------\n    - Creation of dataset with optional filter\n\n      When the combination of type, space, etc doesn't work for filter\n      and the filter is optional, it was supposed to be skipped but it was\n      not skipped and the creation failed.\n\n      Allowed the creation of the dataset in such situation.\n\n      (BMR - 2020/8/13, HDFFV-10933)\n\n    - Explicitly declared dlopen to use RTLD_LOCAL\n\n      dlopen documentation states that if neither RTLD_GLOBAL nor\n      RTLD_LOCAL are specified, then the default behavior is unspecified.\n      The default on linux is usually RTLD_LOCAL while macos will default\n      to RTLD_GLOBAL.\n\n      (ADB - 2020/08/12, HDFFV-11127)\n\n    - Fixed issues CVE-2018-13870 and CVE-2018-13869\n\n      When a buffer overflow occurred because a name length was corrupted\n      and became very large, h5dump crashed on memory access violation.\n\n      A check for reading pass the end of the buffer was added to multiple\n      locations to prevent the crashes and h5dump now simply fails with an\n      error message when this error condition occurs.\n\n      (BMR - 2020/07/22, HDFFV-11120 and HDFFV-11121)\n\n    - Fixed the segmentation fault when reading attributes with multiple threads\n\n      It was reported that the reading of attributes with variable length string\n      datatype will crash with segmentation fault particularly when the number of\n      threads is high (>16 threads).  The problem was due to the file pointer that\n      was set in the variable length string datatype for the attribute.  That file\n      pointer was already closed when the attribute was accessed.\n\n      The problem was fixed by setting the file pointer to the current opened file pointer\n      when the attribute was accessed.  Similar patch up was done before when reading\n      dataset with variable length string datatype.\n\n      (VC - 2020/07/13, HDFFV-11080)\n\n    - Fixed CVE-2020-10810\n\n      The tool h5clear produced a segfault during an error recovery in\n      the superblock decoding.  An internal pointer was reset to prevent\n      further accessing when it is not assigned with a value.\n\n      (BMR - 2020/6/29, HDFFV-11053)\n\n    - Fixed CVE-2018-17435\n\n      The tool h52gif produced a segfault when the size of an attribute\n      message was corrupted and caused a buffer overflow.\n\n      The problem was fixed by verifying the attribute message's size\n      against the buffer size before accessing the buffer.  h52gif was\n      also fixed to display the failure instead of silently exiting\n      after the segfault was eliminated.\n\n      (BMR - 2020/6/19, HDFFV-10591)\n\n    - Improved peformance when creating a large number of small datasets by\n      retrieving default property values from the API context instead of doing\n      skip list searches.\n\n      (CJH - 2019/12/10, HDFFV-10658)\n\n    - Fixed user-created data access properties not existing in the property list\n      returned by H5Dget_access_plist. Thanks to Steven Varga for submitting a\n      reproducer and a patch.\n\n      (CJH - 2019/12/9, HDFFV-10934)\n\n    - Fixed an assertion failure in the parallel library when collectively\n      filling chunks. As it is required that chunks be written in\n      monotonically non-decreasing order of offset in the file, this assertion\n      was being triggered when the list of chunk file space allocations being\n      passed to the collective chunk filling routine was not sorted according\n      to this particular requirement.\n\n      The addition of a sort of the out of order chunks trades a bit of\n      performance for the elimination of this assertion and of any complaints\n      from MPI implementations about the file offsets used being out of order.\n\n      (JTH - 2019/10/07, HDFFV-10792)\n\n    - Fixed the iteration error in test_versionbounds() in test/dtypes.c\n\n      The test was supposed to loop through all valid combinations of\n      low and high bounds in the array versions[], but they were set to\n      H5F_LIBVER_EARLIEST always without changing.\n\n      The problem was fixed by indexing low and high into the array versions[].\n\n      (VC - 2019/09/30)\n\n    - Fixed the slowness of regular hyperslab selection in a chunked dataset\n\n      It was reported that the selection of every 10th element from a 20G\n      chunked dataset was extremely slow and sometimes could hang the system.\n      The problem was due to the iteration and the building of the span tree\n      for all the selected elements in file space.\n\n      As the selected elements are going to a 1-d contiguous single block\n      memory space, the problem was fixed by building regular hyperslab selections\n      in memory space for the selected elements in file space.\n\n      (VC - 2019/09/26, HDFFV-10585)\n\n    - Fixed a bug caused by bad tag value when condensing object header\n      messages\n\n      There was an assertion failure when moving meessages from running a\n      user test program with library release hdf5.1.10.4. It was because\n      the tag value (object header's address) was not set up when entering\n      the library routine H5O__chunk_update_idx(), which will eventually\n      verifies the metadata tag value when protecting the object header.\n\n      The problem was fixed by replacing FUNC_ENTER_PACKAGE in H5O__chunk_update_idx()\n      with FUNC_ENTER_PACKAGE_TAG(oh->cache_info.addr) to set up the metadata tag.\n\n      (VC - 2019/08/23, HDFFV-10873)\n\n    - Fixed the test failure from test_metadata_read_retry_info() in\n      test/swmr.c\n\n      The test failure is due to the incorrect number of bins returned for\n      retry info (info.nbins).  The # of bins expected for 101 read attempts\n      is 3 instead of 2.  The routine H5F_set_retries() in src/H5Fint.c\n      calculates the # of bins by first obtaining the log10 value for\n      (read attempts - 1).  For PGI/19, the log10 value for 100 read attempts\n      is 1.9999999999999998 instead of 2.00000.  When casting the log10 value\n      to unsigned later on, the decimal part is chopped off causing the test\n      failure.\n\n      This was fixed by obtaining the rounded integer value (HDceil) for the\n      log10 value of read attempts first before casting the result to unsigned.\n\n      (VC - 2019/8/14, HDFFV-10813)\n\n    - Fixed an issue where creating a file with non-default file space info\n      together with library high bound setting to H5F_LIBVER_V18.\n\n      When setting non-default file space info in fcpl via\n      H5Pset_file_space_strategy() and then creating a file with\n      both high and low library bounds set to\n      H5F_LIBVER_V18 in fapl, the library succeeds in creating the file.\n      File creation should fail because the feature of setting non-default\n      file space info does not exist in library release 1.8 or earlier.\n\n      This was fixed by setting and checking the proper version in the\n      file space info message based on the library low and high bounds\n      when creating and opening the HDF5 file.\n\n      (VC - 2019/6/25, HDFFV-10808)\n\n    - When iterating over an old-style group (i.e., when not using the latest\n      file format) of size 0, a NULL pointer representing the empty links\n      table would be sent to qsort(3) for sorting, which is undefined behavior.\n\n      Iterating over an empty group is explicitly tested in the links test.\n      This has not caused any failures to date and was flagged by gcc's\n      -fsanitize=undefined.\n\n      The library no longer attempts to sort an empty array.\n\n      (DER - 2019/06/18, HDFFV-10829)\n\n    - Fixed an issue where copying a version 1.8 dataset between files using\n      H5Ocopy fails due to an incompatible fill version\n\n      When using the HDF5 1.10.x H5Ocopy() API call to copy a version 1.8\n      dataset to a file created with both high and low library bounds set to\n      H5F_LIBVER_V18, the H5Ocopy() call will fail with the error stack indicating\n      that the fill value version is out of bounds.\n\n      This was fixed by changing the fill value message version to H5O_FILL_VERSION_3\n      (from H5O_FILL_VERSION_2) for H5F_LIBVER_V18.\n\n      (VC - 2019/6/14, HDFFV-10800)\n\n    - Some oversights in the index iterating area of the library caused\n      a callback function to continue iterating even though it's supposed\n      to stop.\n\n      Added the returned value check to the for loop's conditions in\n      H5EA_iterate(), H5FA_iterate(), and H5D__none_idx_iterate().  The\n      iteration now stops when it should.\n\n      (BMR - 2019/06/11, HDFFV-10661)\n\n    - Fixed a bug that would cause an error or cause fill values to be\n      incorrectly read from a chunked dataset using the \"single chunk\" index if\n      the data was held in cache and there was no data on disk.\n\n      (NAF - 2019/03/06)\n\n    - Fixed a bug that could cause an error or cause fill values to be\n      incorrectly read from a dataset that was written to using H5Dwrite_chunk\n      if the dataset was not closed after writing.\n\n      (NAF - 2019/03/06, HDFFV-10716)\n\n    - Fixed memory leak in scale offset filter\n\n      In a special case where the MinBits is the same as the number of bits in\n      the datatype's precision, the filter's data buffer was not freed, causing\n      the memory usage to grow. In general the buffer was freed correctly.  The\n      Minbits are the minimal number of bits to store the data values.  Please\n      see the reference manual for H5Pset_scaleoffset for the detail.\n\n      (RL - 2019/3/4, HDFFV-10705)\n\n    - Fix hangs with collective metadata reads during chunked dataset I/O\n\n      In the parallel library, it was discovered that when a particular\n      sequence of operations following a pattern of:\n\n      \"write to chunked dataset\" -> \"flush file\" -> \"read from dataset\"\n\n      occurred with collective metadata reads enabled, hangs could be\n      observed due to certain MPI ranks not participating in the collective\n      metadata reads.\n\n      To fix the issue, collective metadata reads are now disabled during\n      chunked dataset raw data I/O.\n\n      (JTH - 2019/02/11, HDFFV-10563, HDFFV-10688)\n\n    - Performance issue when closing an object\n\n      The slow down is due to the search of the \"tag_list\" to find\n      out the \"corked\" status of an object and \"uncork\" it if so.\n\n      Improve porformance by skipping the search of the \"tag_list\"\n      if there are no \"corked\" objects when closing an object.\n\n      (VC - 2019/2/6)\n\n    - Fixed a potential invalid memory access and failure that could occur when\n      decoding an unknown object header message (from a future version of the\n      library).\n\n      (NAF - 2019/01/07)\n\n    - Deleting attributes in dense storage\n\n      The library aborts with \"infinite loop closing library\" after\n      attributes in dense storage are created and then deleted.\n\n      When deleting the attribute nodes from the name index v2 B-tree,\n      if an attribute is found in the intermediate B-tree nodes,\n      which may be merged/redistributed in the process, we need to\n      free the dynamically allocated spaces for the intermediate\n      decoded attribute.\n\n      (VC - 2018/12/26, HDFFV-10659)\n\n    - Allow H5detect and H5make_libsettings to take a file as an argument.\n\n      Rather than only writing to stdout, add a command argument to name\n      the file that H5detect and H5make_libsettings will use for output.\n      Without an argument, stdout is still used, so backwards compatibility\n      is maintained.\n\n      (ADB - 2018/09/05, HDFFV-9059)\n\n    - A bug was discovered in the parallel library where an application\n      would hang if a collective read/write of a chunked dataset occurred\n      when collective metadata reads were enabled and some of the ranks\n      had no selection in the dataset's dataspace. The ranks which had no\n      selection in the dataset's dataspace called H5D__chunk_addrmap() to\n      retrieve the lowest chunk address in the dataset. This is because we\n      require reads/writes to be performed in strictly non-decreasing order\n      of chunk address in the file.\n\n      When the chunk index used was a version 1 or 2 B-tree, these\n      non-participating ranks would issue a collective MPI_Bcast() call\n      that the participating ranks would not issue, causing the hang. Since\n      the non-participating ranks are not actually reading/writing anything,\n      the H5D__chunk_addrmap() call can be safely removed and the address used\n      for the read/write can be set to an arbitrary number (0 was chosen).\n\n      (JTH - 2018/08/25, HDFFV-10501)\n\n    - fcntl(2)-based file locking incorrectly passed the lock argument struct\n      instead of a pointer to the struct, causing errors on systems where\n      flock(2) is not available.\n\n      File locking is used when files are opened to enforce SWMR semantics. A\n      lock operation takes place on all file opens unless the\n      HDF5_USE_FILE_LOCKING environment variable is set to the string \"FALSE\".\n      flock(2) is preferentially used, with fcntl(2) locks as a backup if\n      flock(2) is unavailable on a system (if neither is available, the lock\n      operation fails). On these systems, the file lock will often fail, which\n      causes HDF5 to not open the file and report an error.\n\n      This bug only affects POSIX systems. Win32 builds on Windows use a no-op\n      locking call which always succeeds. Systems which exhibit this bug will\n      have H5_HAVE_FCNTL defined but not H5_HAVE_FLOCK in the configure output.\n\n      This bug affects HDF5 1.10.0 through 1.10.5.\n\n      fcntl(2)-based file locking now correctly passes the struct pointer.\n\n      (DER - 2019/08/27, HDFFV-10892)\n\n    - Torn pread/pwrite I/O would result in read and write corruption.\n\n      In the sec2, log, and core (with backing store) virtual file drivers\n      (VFDs), the read and write calls incorrectly reset the offset parameter\n      on torn pread and pwrite operations (i.e., I/O operations which fail to\n      be written atomically by the OS). For this bug to occur, pread/pwrite\n      have to be configured (this is the default if they are present on the\n      system) and the pread/pwrite operation has to fail to transfer all\n      the bytes, resulting in a multiple pread/pwrite calls.\n\n      This feature was initially enabled in HDF5 1.10.5 so the bug is\n      limited to that version.\n\n      (DER - 2019/12/09, HDFFV-10945)\n\n    - H5Sset_extent_none() sets the dataspace class to H5S_NO_CLASS which\n      causes asserts/errors when passed to other dataspace API calls.\n\n      H5S_NO_CLASS is an internal class value that should not have been\n      exposed via a public API call.\n\n      In debug builds of the library, this can cause asserts to trip. In\n      non-debug builds, it will produce normal library errors.\n\n      The new library behavior is for H5Sset_extent_none() to convert\n      the dataspace into one of type H5S_NULL, which is better handled\n      by the library and easier for developers to reason about.\n\n      (DER - 2020/07/27, HDFFV-11027)\n\n\n    Java Library:\n    ----------------\n    - JNI native library dependencies\n\n      The build for the hdf5_java native library used the wrong\n      hdf5 target library for CMake builds. Correcting the hdf5_java\n      library to build with the shared hdf5 library required testing\n      paths to change also.\n\n      (ADB - 2018/08/31, HDFFV-10568)\n     - Java iterator callbacks\n\n      Change global callback object to a small stack structure in order\n      to fix a runtime crash. This crash was discovered when iterating\n      through a file with nested group members. The global variable\n      visit_callback is overwritten when recursion starts. When recursion\n      completes, visit_callback will be pointing to the wrong callback method.\n\n      (ADB - 2018/08/15, HDFFV-10536)\n\n    - Java HDFLibraryException class\n\n      Change parent class from Exception to RuntimeException.\n\n      (ADB - 2018/07/30, HDFFV-10534)\n\n    - JNI Read and Write\n\n      Refactored variable-length functions, H5DreadVL and H5AreadVL,\n      to correct dataset and attribute reads. New write functions,\n      H5DwriteVL and H5AwriteVL, are under construction.\n\n      (ADB - 2018/06/02, HDFFV-10519)\n\n    Configuration\n    -------------\n    - Correct option for default API version\n\n      CMake options for default API version are not mutually exclusive.\n      Change the multiple BOOL options to a single STRING option with the\n      strings; v16, v18, v110, v112.\n\n      (ADB - 2019/08/12, HDFFV-10879)\n\n    Performance\n    -------------\n    -\n\n    Fortran\n    --------\n    - Added symbolic links libhdf5_hl_fortran.so to libhdf5hl_fortran.so and\n      libhdf5_hl_fortran.a to libhdf5hl_fortran.a in hdf5/lib directory for\n      autotools installs.  These were added to match the name of the files\n      installed by cmake and the general pattern of hl lib files.  We will\n      change the names of the installed lib files to the matching name in\n      the next major release.\n\n      (LRK - 2019/01/04, HDFFV-10596)\n\n    - Made Fortran specific subroutines PRIVATE in generic procedures.\n\n      Effected generic procedures were functions in H5A, H5D, H5P, H5R and H5T.\n\n      (MSB, 2018/12/04, HDFFV-10511)\n\n    - Fixed issue with Fortran not returning h5o_info_t field values\n      meta_size%attr%index_size and  meta_size%attr%heap_size.\n\n      (MSB, 2018/1/8, HDFFV-10443)\n\n    - Corrected INTERFACE INTENT(IN) to INTENT(OUT) for buf_size in h5fget_file_image_f.\n\n      (MSB - 2020/2/18, HDFFV-11029)\n\n    Tools\n    -----\n    - The tools library was updated by standardizing the error stack process.\n\n      General sequence is:\n          h5tools_setprogname(PROGRAMNAME);\n          h5tools_setstatus(EXIT_SUCCESS);\n          h5tools_init();\n          ... process the command-line (check for error-stack enable) ...\n          h5tools_error_report();\n          ... (do work) ...\n          h5diff_exit(ret);\n\n      (ADB - 2020/07/20, HDFFV-11066)\n\n    - h5diff fixed a command line parsing error.\n\n      h5diff would ignore the argument to -d (delta) if it is smaller than DBL_EPSILON.\n      The macro H5_DBL_ABS_EQUAL was removed and a direct value comparision was used.\n\n      (ADB - 2020/07/20, HDFFV-10897)\n\n    - h5diff added a command line option to ignore attributes.\n\n      h5diff would ignore all objects with a supplied path if the exclude-path argument is used.\n      Adding the exclude-attribute argument will only eclude attributes, with the supplied path,\n      from comparision.\n\n      (ADB - 2020/07/20, HDFFV-5935)\n\n    - h5diff added another level to the verbose argument to print filenames.\n\n      Added verbose level 3 that is level 2 plus the filenames. The levels are:\n          0 : Identical to '-v' or '--verbose'\n          1 : All level 0 information plus one-line attribute status summary\n          2 : All level 1 information plus extended attribute status report\n          3 : All level 2 information plus file names\n\n      (ADB - 2020/07/20, HDFFV-10005)\n\n    High-Level APIs:\n    ------\n    - The H5DSis_scale function was updated to return \"not a dimension scale\" (0)\n      instead of failing (-1), when CLASS or DIMENSION_SCALE attributes are\n      not written according to Dimension Scales Specification.\n\n     (EIP - 2020/08/12, HDFFV-10436)\n\n    Fortran High-Level APIs:\n    ------\n    -\n\n    Documentation\n    -------------\n    -\n\n    F90 APIs\n    --------\n    -\n\n    C++ APIs\n    --------\n    -\n\n    Testing\n    -------\n    - Stopped java/test/junit.sh.in installing libs for testing under ${prefix}\n\n      Lib files needed are now copied to a subdirectory in the java/test\n      directory, and on Macs the loader path for libhdf5.xxxs.so is changed\n      in the temporary copy of libhdf5_java.dylib.\n\n      (LRK, 2020/7/2, HDFFV-11063)\n\n    - Fixed a test failure in testpar/t_dset.c caused by\n      the test trying to use the parallel filters feature\n      on MPI-2 implementations.\n\n      (JTH, 2019/2/7)\n\nBug Fixes since HDF5-1.10.2 release\n==================================\n\n    Library\n    -------\n    - Java HDF5LibraryException class\n\n      The error minor and major values would be lost after the\n      constructor executed.\n\n      Created two local class variables to hold the values obtained during\n      execution of the constructor. Refactored the class functions to retrieve\n      the class values rather then calling the native functions.\n      The native functions were renamed and called only during execution\n      of the constructor.\n      Added error checking to calling class constructors in JNI classes.\n\n      (ADB - 2018/08/06, HDFFV-10544)\n\n    - Added checks of the defined MPI_VERSION to guard against usage of\n      MPI-3 functions in the Parallel Compression and \"big Parallel I/O\"\n      features when HDF5 is built with MPI-2. Previously, the configure\n      step would pass but the build itself would fail when it could not\n      locate the MPI-3 functions used.\n\n      As a result of these new checks, HDF5 can again be built with MPI-2,\n      but the Parallel Compression feature will be disabled as it relies\n      on the MPI-3 functions used.\n\n      (JTH - 2018/08/02, HDFFV-10512)\n\n    - User's patches: CVEs\n\n      The following patches have been applied:\n\n      CVE-2018-11202 - NULL pointer dereference was discovered in\n                       H5S_hyper_make_spans in H5Shyper.c (HDFFV-10476)\n        https://security-tracker.debian.org/tracker/CVE-2018-11202\n        https://cve.mitre.org/cgi-bin/cvename.cgi?name=3DCVE-2018-11202\n\n      CVE-2018-11203 - A division by zero was discovered in\n                       H5D__btree_decode_key in H5Dbtree.c (HDFFV-10477)\n        https://security-tracker.debian.org/tracker/CVE-2018-11203\n        https://cve.mitre.org/cgi-bin/cvename.cgi?name=3DCVE-2018-11203\n\n      CVE-2018-11204 - A NULL pointer dereference was discovered in\n                       H5O__chunk_deserialize in H5Ocache.c (HDFFV-10478)\n        https://security-tracker.debian.org/tracker/CVE-2018-11204\n        https://cve.mitre.org/cgi-bin/cvename.cgi?name=3DCVE-2018-11204\n\n      CVE-2018-11206 - An out of bound read was discovered in\n                       H5O_fill_new_decode and H5O_fill_old_decode in H5Ofill.c\n                       (HDFFV-10480)\n        https://security-tracker.debian.org/tracker/CVE-2018-11206\n        https://cve.mitre.org/cgi-bin/cvename.cgi?name=3DCVE-2018-11206\n\n      CVE-2018-11207 - A division by zero was discovered in\n                       H5D__chunk_init in H5Dchunk.c  (HDFFV-10481)\n        https://security-tracker.debian.org/tracker/CVE-2018-11207\n        https://cve.mitre.org/cgi-bin/cvename.cgi?name=3DCVE-2018-11207\n\n      (BMR - 2018/7/22, PR#s: 1134 and 1139,\n       HDFFV-10476, HDFFV-10477, HDFFV-10478, HDFFV-10480, HDFFV-10481)\n\n    - H5Adelete\n\n      H5Adelete failed when deleting the last \"large\" attribute that\n      is stored densely via fractal heap/v2 b-tree.\n\n      After removing the attribute, update the ainfo message.  If the\n      number of attributes goes to zero, remove the message.\n\n      (VC - 2018/07/20, HDFFV-9277)\n\n    - A bug was discovered in the parallel library which caused partial\n      parallel reads of filtered datasets to return incorrect data. The\n      library used the incorrect dataspace for each chunk read, causing\n      the selection used in each chunk to be wrong.\n\n      The bug was not caught during testing because all of the current\n      tests which do parallel reads of filtered data read all of the data\n      using an H5S_ALL selection. Several tests were added which exercise\n      partial parallel reads.\n\n      (JTH - 2018/07/16, HDFFV-10467)\n\n    - A bug was discovered in the parallel library which caused parallel\n      writes of filtered datasets to trigger an assertion failure in the\n      file free space manager.\n\n      This occurred when the filter used caused chunks to repeatedly shrink\n      and grow over the course of several dataset writes. The previous chunk\n      information, such as the size of the chunk and the offset in the file,\n      was being cached and not updated after each write, causing the next write\n      to the chunk to retrieve the incorrect cached information and run into\n      issues when reallocating space in the file for the chunk.\n\n      (JTH - 2018/07/16, HDFFV-10509)\n\n    - A bug was discovered in the parallel library which caused the\n      H5D__mpio_array_gatherv() function to allocate too much memory.\n\n      When the function is called with the 'allgather' parameter set\n      to a non-true value, the function will receive data from all MPI\n      ranks and gather it to the single rank specied by the 'root'\n      parameter. However, the bug in the function caused memory for\n      the received data to be allocated on all MPI ranks, not just the\n      singular rank specified as the receiver. In some circumstances,\n      this would cause an application to fail due to the large amounts\n      of memory being allocated.\n\n      (JTH - 2018/07/16, HDFFV-10467)\n\n    - Error checks in h5stat and when decoding messages\n\n      h5stat exited with seg fault/core dumped when\n      errors are encountered in the internal library.\n\n      Add error checks and --enable-error-stack option to h5stat.\n      Add range checks when decoding messages: old fill value, old\n      layout and refcount.\n\n      (VC - 2018/07/11, HDFFV-10333)\n\n    - If an HDF5 file contains a malformed compound datatype with a\n      suitably large offset, the type conversion code can run off\n      the end of the type conversion buffer, causing a segmentation\n      fault.\n\n      This issue was reported to The HDF Group as issue #CVE-2017-17507.\n\n      NOTE: The HDF5 C library cannot produce such a file. This condition\n            should only occur in a corrupt (or deliberately altered) file\n            or a file created by third-party software.\n\n      THE HDF GROUP WILL NOT FIX THIS BUG AT THIS TIME\n\n      Fixing this problem would involve updating the publicly visible\n      H5T_conv_t function pointer typedef and versioning the API calls\n      which use it. We normally only modify the public API during\n      major releases, so this bug will not be fixed at this time.\n\n      (DER - 2018/02/26, HDFFV-10356)\n\n    - Inappropriate linking with deprecated MPI C++ libraries\n\n      HDF5 does not define *_SKIP_MPICXX in the public headers, so applications\n      can inadvertently wind up linking to the deprecated MPI C++ wrappers.\n\n      MPICH_SKIP_MPICXX and OMPI_SKIP_MPICXX have both been defined in H5public.h\n      so this should no longer be an issue. HDF5 makes no use of the deprecated\n      MPI C++ wrappers.\n\n      (DER - 2019/09/17, HDFFV-10893)\n\n\n\n    Configuration\n    -------------\n    - Applied patches to address Cywin build issues\n\n      There were three issues for Cygwin builds:\n      - Shared libs were not built.\n      - The -std=c99 flag caused a SIG_SETMASK undeclared error.\n      - Undefined errors when buildbing test shared libraries.\n\n      Patches to address these issues were received and incorporated in this version.\n\n      (LRK - 2018/07/18, HDFFV-10475)\n\n    - Moved the location of gcc attribute.\n\n      The gcc attribute(no_sanitize), named as the macro HDF_NO_UBSAN,\n      was located after the function name. Builds with GCC 7 did not\n      indicate any problem, but GCC 8 issued errors. Moved the\n      attribute before the function name, as required.\n\n      (ADB - 2018/05/22, HDFFV-10473)\n\n    - Reworked java test suite into individual JUnit tests.\n\n      Testing the whole suite of java unit tests in a single JUnit run\n      made it difficult to determine actual failures when tests would fail.\n      Running each file set of tests individually, allows individual failures\n      to be diagnosed easier. A side benefit is that tests for optional components\n      of the library can be disabled if not configured.\n\n      (ADB - 2018/05/16, HDFFV-9739)\n\n    - Converted CMake global commands ADD_DEFINITIONS and INCLUDE_DIRECTORIES\n      to use target_* type commands. This change modernizes the CMake usage\n      in the HDF5 library.\n\n      In addition, there is the intention to convert to generator expressions,\n      where possible. The exception is Fortran FLAGS on Windows Visual Studio.\n      The HDF macros TARGET_C_PROPERTIES and TARGET_FORTRAN_PROPERTIES have\n      been removed with this change in usage.\n\n      The additional language (C++ and Fortran) checks have also been localized\n      to only be checked when that language is enabled.\n\n      (ADB - 2018/05/08)\n\n    Performance\n    -------------\n    -\n\n    Fortran\n    --------\n    -\n\n    Tools\n    -----\n    -\n\n    High-Level APIs:\n    ------\n    -\n\n    Fortran High-Level APIs:\n    ------\n    -\n\n    Documentation\n    -------------\n    -\n\n    F90 APIs\n    --------\n    -\n\n    C++ APIs\n    --------\n    - Adding default arguments to existing functions\n\n      Added the following items:\n      + Two more property list arguments are added to H5Location::createDataSet:\n        const DSetAccPropList& dapl = DSetAccPropList::DEFAULT\n        const LinkCreatPropList& lcpl = LinkCreatPropList::DEFAULT\n\n      + One more property list argument is added to H5Location::openDataSet:\n        const DSetAccPropList& dapl = DSetAccPropList::DEFAULT\n\n      (BMR - 2018/07/21, PR# 1146)\n\n    - Improvement C++ documentation\n\n      Replaced the table in main page of the C++ documentation from mht to htm format\n      for portability.\n\n      (BMR - 2018/07/17, PR# 1141)\n\n    Testing\n    -------\n    - The dt_arith test failed on IBM Power8 and Power9 machines when testing\n      conversions from or to long double types, especially when special values\n      such as infinity or NAN were involved.  In some cases the results differed\n      by extremely small amounts from those on other machines, while some other\n      tests resulted in segmentation faults.  These conversion tests with long\n      double types have been disabled for ppc64 machines until the problems are\n      better understood and can be properly addressed.\n\n      (SRL - 2019/01/07, TRILAB-98)\n\nSupported Platforms\n===================\n\n    Linux 2.6.32-696.16.1.el6.ppc64 gcc (GCC) 4.4.7 20120313 (Red Hat 4.4.7-18)\n    #1 SMP ppc64 GNU/Linux        g++ (GCC) 4.4.7 20120313 (Red Hat 4.4.7-18)\n    (ostrich)                     GNU Fortran (GCC) 4.4.7 20120313 (Red Hat 4.4.7-18)\n                                  IBM XL C/C++ V13.1\n                                  IBM XL Fortran V15.1\n\n    Linux 3.10.0-327.10.1.el7   GNU C (gcc), Fortran (gfortran), C++ (g++)\n    #1 SMP x86_64 GNU/Linux       compilers:\n    (kituo/moohan)                Version 4.8.5 20150623 (Red Hat 4.8.5-4)\n                                    Version 4.9.3, Version 5.2.0,\n                                  Intel(R) C (icc), C++ (icpc), Fortran (icc)\n                                  compilers:\n                                     Version 17.0.0.098 Build 20160721\n                                  MPICH 3.1.4 compiled with GCC 4.9.3\n\n    SunOS 5.11 32- and 64-bit     Sun C 5.12 SunOS_sparc\n    (emu)                         Sun Fortran 95 8.6 SunOS_sparc\n                                  Sun C++ 5.12 SunOS_sparc\n\n    Windows 7 x64                 Visual Studio 2015 w/ Intel C, Fortran 2018 (cmake)\n                                  Visual Studio 2015 w/ MSMPI 10 (cmake)\n\n    Windows 10 x64                Visual Studio 2015 w/ Intel Fortran 18 (cmake)\n                                  Visual Studio 2017 w/ Intel Fortran 19 (cmake)\n                                  Visual Studio 2019 w/ Intel Fortran 19 (cmake)\n\n    Mac OS X Yosemite 10.10.5     Apple clang/clang++ version 6.1 from Xcode 7.0\n    64-bit                        gfortran GNU Fortran (GCC) 4.9.2\n    (osx1010dev/osx1010test)      Intel icc/icpc/ifort version 15.0.3\n\n    Mac OS X El Capitan 10.11.6   Apple clang/clang++ version 7.3.0 from Xcode 7.3\n    64-bit                        gfortran GNU Fortran (GCC) 5.2.0\n    (osx1011dev/osx1011test)      Intel icc/icpc/ifort version 16.0.2\n\n    Mac OS Sierra 10.12.6         Apple LLVM version 8.1.0 (clang/clang++-802.0.42)\n    64-bit                        gfortran GNU Fortran (GCC) 7.1.0\n    (swallow/kite)                Intel icc/icpc/ifort version 17.0.2\n\n\nTested Configuration Features Summary\n=====================================\n\n    In the tables below\n          y   = tested\n          n   = not tested in this release\n          C   = Cluster\n          W   = Workstation\n          x   = not working in this release\n          dna = does not apply\n          ( ) = footnote appears below second table\n          <blank> = testing incomplete on this feature or platform\n\nPlatform                              C         F90/   F90      C++  zlib  SZIP\n                                      parallel  F2003  parallel\nSolaris2.11 32-bit                      n        y/y    n        y    y     y\nSolaris2.11 64-bit                      n        y/n    n        y    y     y\nWindows 7                               y        y/y    n        y    y     y\nWindows 7 x64                           y        y/y    y        y    y     y\nWindows 7 Cygwin                        n        y/n    n        y    y     y\nWindows 7 x64 Cygwin                    n        y/n    n        y    y     y\nWindows 10                              y        y/y    n        y    y     y\nWindows 10 x64                          y        y/y    n        y    y     y\nMac OS X Mountain Lion 10.8.5 64-bit    n        y/y    n        y    y     y\nMac OS X Mavericks 10.9.5 64-bit        n        y/y    n        y    y     ?\nMac OS X Yosemite 10.10.5 64-bit        n        y/y    n        y    y     ?\nMac OS X El Capitan 10.11.6 64-bit      n        y/y    n        y    y     ?\nCentOS 6.7 Linux 2.6.18 x86_64 GNU      n        y/y    n        y    y     y\nCentOS 6.7 Linux 2.6.18 x86_64 Intel    n        y/y    n        y    y     y\nCentOS 6.7 Linux 2.6.32 x86_64 PGI      n        y/y    n        y    y     y\nCentOS 7.2 Linux 2.6.32 x86_64 GNU      y        y/y    y        y    y     y\nCentOS 7.2 Linux 2.6.32 x86_64 Intel    n        y/y    n        y    y     y\nLinux 2.6.32-573.18.1.el6.ppc64         n        y/n    n        y    y     y\n\n\nPlatform                                 Shared  Shared    Shared    Thread-\n                                         C libs  F90 libs  C++ libs  safe\nSolaris2.11 32-bit                         y       y         y         y\nSolaris2.11 64-bit                         y       y         y         y\nWindows 7                                  y       y         y         y\nWindows 7 x64                              y       y         y         y\nWindows 7 Cygwin                           n       n         n         y\nWindows 7 x64 Cygwin                       n       n         n         y\nWindows 10                                 y       y         y         y\nWindows 10 x64                             y       y         y         y\nMac OS X Mountain Lion 10.8.5 64-bit       y       n         y         y\nMac OS X Mavericks 10.9.5 64-bit           y       n         y         y\nMac OS X Yosemite 10.10.5 64-bit           y       n         y         y\nMac OS X El Capitan 10.11.6 64-bit         y       n         y         y\nCentOS 6.7 Linux 2.6.18 x86_64 GNU         y       y         y         y\nCentOS 6.7 Linux 2.6.18 x86_64 Intel       y       y         y         n\nCentOS 6.7 Linux 2.6.32 x86_64 PGI         y       y         y         n\nCentOS 7.2 Linux 2.6.32 x86_64 GNU         y       y         y         n\nCentOS 7.2 Linux 2.6.32 x86_64 Intel       y       y         y         n\nLinux 2.6.32-573.18.1.el6.ppc64            y       y         y         n\n\nCompiler versions for each platform are listed in the preceding\n\"Supported Platforms\" table.\n\n\nMore Tested Platforms\n=====================\nThe following platforms are not supported but have been tested for this release.\n\n    Linux 2.6.32-573.22.1.el6    GNU C (gcc), Fortran (gfortran), C++ (g++)\n    #1 SMP x86_64 GNU/Linux       compilers:\n    (mayll/platypus)                 Version 4.4.7 20120313\n                                     Version 4.9.3, 5.3.0, 6.2.0\n                                  PGI C, Fortran, C++ for 64-bit target on\n                                  x86-64;\n                                      Version 17.10-0\n                                  Intel(R) C (icc), C++ (icpc), Fortran (icc)\n                                  compilers:\n                                     Version 17.0.4.196 Build 20170411\n                                  MPICH 3.1.4 compiled with GCC 4.9.3\n\n    Linux 3.10.0-327.18.2.el7     GNU C (gcc) and C++ (g++) compilers\n    #1 SMP x86_64 GNU/Linux          Version 4.8.5 20150623 (Red Hat 4.8.5-4)\n    (jelly)                       with NAG Fortran Compiler Release 6.1(Tozai)\n                                  GCC Version 7.1.0\n                                  OpenMPI 3.0.0-GCC-7.2.0-2.29\n                                  Intel(R) C (icc) and C++ (icpc) compilers\n                                     Version 17.0.0.098 Build 20160721\n                                  with NAG Fortran Compiler Release 6.1(Tozai)\n\n    Linux 3.10.0-327.10.1.el7     MPICH 3.2 compiled with GCC 5.3.0\n    #1 SMP x86_64 GNU/Linux\n    (moohan)\n\n    Linux 2.6.32-573.18.1.el6.ppc64  MPICH mpich 3.1.4 compiled with\n    #1 SMP ppc64 GNU/Linux           IBM XL C/C++ for Linux, V13.1\n    (ostrich)                        and IBM XL Fortran for Linux, V15.1\n\n   Fedora30 5.3.11-200.fc30.x86_64\n   #1 SMP x86_64  GNU/Linux          GNU gcc (GCC) 9.2.1 20190827 (Red Hat 9.2.1 20190827)\n                                     GNU Fortran (GCC) 9.2.1 20190827 (Red Hat 9.2.1 20190827)\n                                     (cmake and autotools)\n\n\nKnown Problems\n==============\n    CMake files do not behave correctly with paths containing spaces.\n    Do not use spaces in paths because the required escaping for handling spaces\n    results in very complex and fragile build files.\n    ADB - 2019/05/07\n\n    At present, metadata cache images may not be generated by parallel\n    applications.  Parallel applications can read files with metadata cache\n    images, but since this is a collective operation, a deadlock is possible\n    if one or more processes do not participate.\n\n    Known problems in previous releases can be found in the HISTORY*.txt files\n    in the HDF5 source. Please report any new problems found to\n    help@hdfgroup.org.\n\n\nCMake vs. Autotools installations\n=================================\nWhile both build systems produce similar results, there are differences.\nEach system produces the same set of folders on linux (only CMake works\non standard Windows); bin, include, lib and share. Autotools places the\nCOPYING and RELEASE.txt file in the root folder, CMake places them in\nthe share folder.\n\nThe bin folder contains the tools and the build scripts. Additionally, CMake\ncreates dynamic versions of the tools with the suffix \"-shared\". Autotools\ninstalls one set of tools depending on the \"--enable-shared\" configuration\noption.\n  build scripts\n  -------------\n  Autotools: h5c++, h5cc, h5fc\n  CMake: h5c++, h5cc, h5hlc++, h5hlcc\n\nThe include folder holds the header files and the fortran mod files. CMake\nplaces the fortran mod files into separate shared and static subfolders,\nwhile Autotools places one set of mod files into the include folder. Because\nCMake produces a tools library, the header files for tools will appear in\nthe include folder.\n\nThe lib folder contains the library files, and CMake adds the pkgconfig\nsubfolder with the hdf5*.pc files used by the bin/build scripts created by\nthe CMake build. CMake separates the C interface code from the fortran code by\ncreating C-stub libraries for each Fortran library. In addition, only CMake\ninstalls the tools library. The names of the szip libraries are different\nbetween the build systems.\n\nThe share folder will have the most differences because CMake builds include\na number of CMake specific files for support of CMake's find_package and support\nfor the HDF5 Examples CMake project.\n\n",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/release_docs/HISTORY-1_10.txt": "HDF5 History\n============\n\nThis file contains development history of the HDF5 1.10 branch\n\n06.      Release Information for hdf5-1.10.4\n05.      Release Information for hdf5-1.10.3\n04.      Release Information for hdf5-1.10.2\n03.      Release Information for hdf5-1.10.1\n02.      Release Information for hdf5-1.10.0-patch1\n01.      Release Information for hdf5-1.10.0\n\n[Search on the string '%%%%' for section breaks of each release.]\n\n%%%%1.10.4%%%%\n\nHDF5 version 1.10.4 released on 2018-10-05\n================================================================================\n\n\nINTRODUCTION\n\nThis document describes the differences between this release and the previous\nHDF5 release. It contains information on the platforms tested and known\nproblems in this release. For more details check the HISTORY*.txt files in the\nHDF5 source.\n\nNote that documentation in the links below will be updated at the time of each\nfinal release.\n\nLinks to HDF5 documentation can be found on The HDF5 web page:\n\n     https://portal.hdfgroup.org/display/HDF5/HDF5\n\nThe official HDF5 releases can be obtained from:\n\n     https://www.hdfgroup.org/downloads/hdf5/\n\nChanges from Release to Release and New Features in the HDF5-1.10.x release series\ncan be found at:\n\n     https://portal.hdfgroup.org/display/HDF5/HDF5+Application+Developer%27s+Guide\n\nIf you have any questions or comments, please send them to the HDF Help Desk:\n\n     help@hdfgroup.org\n\n\nCONTENTS\n\n- Bug Fixes since HDF5-1.10.3\n- Supported Platforms\n- Tested Configuration Features Summary\n- More Tested Platforms\n- Known Problems\n- CMake vs. Autotools installations\n\n\nNew Features\n============\n\n    Configuration:\n    -------------\n    - Add toolchain and cross-compile support\n\n      Added info on using a toolchain file to INSTALL_CMAKE.txt. A\n      toolchain file is also used in cross-compiling, which requires\n      CMAKE_CROSSCOMPILING_EMULATOR to be set. To help with cross-compiling\n      the fortran configure process, the HDF5UseFortran.cmake file macros\n      were improved. Fixed a Fortran configure file issue that incorrectly\n      used #cmakedefine instead of #define.\n\n      (ADB - 2018/10/04, HDFFV-10594)\n\n    - Add warning flags for Intel compilers\n\n      Identified Intel compiler specific warnings flags that should be used\n      instead of GNU flags.\n\n      (ADB - 2018/10/04, TRILABS-21)\n\n    - Add default rpath to targets\n\n      Default rpaths should be set in shared executables and\n      libraries to allow the use of loading dependent libraries\n      without requiring LD_LIBRARY_PATH to be set. The default\n      path should be relative using @rpath on osx and $ORIGIN\n      on linux. Windows is not affected.\n\n      (ADB - 2018/09/26, HDFFV-10594)\n\n    Library:\n    --------\n    - Allow pre-generated H5Tinit.c and H5make_libsettings.c to be used.\n\n      Rather than always running H5detect and generating H5Tinit.c and\n      H5make_libsettings.c, supply a location for those files.\n\n      (ADB - 2018/09/18, HDFFV-10332)\n\n\nBug Fixes since HDF5-1.10.3 release\n==================================\n\n    Library\n    -------\n    - Allow H5detect and H5make_libsettings to take a file as an argument.\n\n      Rather than only writing to stdout, add a command argument to name\n      the file that H5detect and H5make_libsettings will use for output.\n      Without an argument, stdout is still used, so backwards compatibility\n      is maintained.\n\n      (ADB - 2018/09/05, HDFFV-9059)\n\n    - A bug was discovered in the parallel library where an application\n      would hang if a collective read/write of a chunked dataset occurred\n      when collective metadata reads were enabled and some of the ranks\n      had no selection in the dataset's dataspace. The ranks which had no\n      selection in the dataset's dataspace called H5D__chunk_addrmap() to\n      retrieve the lowest chunk address in the dataset. This is because we\n      require reads/writes to be performed in strictly non-decreasing order\n      of chunk address in the file.\n\n      When the chunk index used was a version 1 or 2 B-tree, these\n      non-participating ranks would issue a collective MPI_Bcast() call\n      that the participating ranks would not issue, causing the hang. Since\n      the non-participating ranks are not actually reading/writing anything,\n      the H5D__chunk_addrmap() call can be safely removed and the address used\n      for the read/write can be set to an arbitrary number (0 was chosen).\n\n      (JTH - 2018/08/25, HDFFV-10501)\n\n    Java Library:\n    ----------------\n    - JNI native library dependencies\n\n      The build for the hdf5_java native library used the wrong\n      hdf5 target library for CMake builds. Correcting the hdf5_java\n      library to build with the shared hdf5 library required testing\n      paths to change also.\n\n      (ADB - 2018/08/31, HDFFV-10568)\n\n    - Java iterator callbacks\n\n      Change global callback object to a small stack structure in order\n      to fix a runtime crash. This crash was discovered when iterating\n      through a file with nested group members. The global variable\n      visit_callback is overwritten when recursion starts. When recursion\n      completes, visit_callback will be pointing to the wrong callback method.\n\n      (ADB - 2018/08/15, HDFFV-10536)\n\n    - Java HDFLibraryException class\n\n      Change parent class from Exception to RuntimeException.\n\n      (ADB - 2018/07/30, HDFFV-10534)\n\n    - JNI Read and Write\n\n      Refactored variable-length functions, H5DreadVL and H5AreadVL,\n      to correct dataset and attribute reads. New write functions,\n      H5DwriteVL and H5AwriteVL, are under construction.\n\n      (ADB - 2018/06/02, HDFFV-10519)\n\n\nSupported Platforms\n===================\n\n    Linux 2.6.32-696.16.1.el6.ppc64 gcc (GCC) 4.4.7 20120313 (Red Hat 4.4.7-18)\n    #1 SMP ppc64 GNU/Linux        g++ (GCC) 4.4.7 20120313 (Red Hat 4.4.7-18)\n    (ostrich)                     GNU Fortran (GCC) 4.4.7 20120313 (Red Hat 4.4.7-18)\n                                  IBM XL C/C++ V13.1\n                                  IBM XL Fortran V15.1\n\n    Linux 3.10.0-327.10.1.el7   GNU C (gcc), Fortran (gfortran), C++ (g++)\n    #1 SMP x86_64 GNU/Linux       compilers:\n    (kituo/moohan)                Version 4.8.5 20150623 (Red Hat 4.8.5-4)\n                                    Version 4.9.3, Version 5.2.0\n                                  Intel(R) C (icc), C++ (icpc), Fortran (icc)\n                                  compilers:\n                                     Version 17.0.0.098 Build 20160721\n                                  MPICH 3.1.4 compiled with GCC 4.9.3\n\n    SunOS 5.11 32- and 64-bit     Sun C 5.12 SunOS_sparc\n    (emu)                         Sun Fortran 95 8.6 SunOS_sparc\n                                  Sun C++ 5.12 SunOS_sparc\n\n    Windows 7                     Visual Studio 2015 w/ Intel Fortran 16 (cmake)\n\n    Windows 7 x64                 Visual Studio 2012 w/ Intel Fortran 15 (cmake)\n                                  Visual Studio 2013 w/ Intel Fortran 15 (cmake)\n                                  Visual Studio 2015 w/ Intel Fortran 16 (cmake)\n                                  Visual Studio 2015 w/ Intel C, Fortran 2017 (cmake)\n                                  Visual Studio 2015 w/ MSMPI 8 (cmake)\n\n    Windows 10                    Visual Studio 2015 w/ Intel Fortran 18 (cmake)\n\n    Windows 10 x64                Visual Studio 2015 w/ Intel Fortran 18 (cmake)\n                                  Visual Studio 2017 w/ Intel Fortran 18 (cmake)\n\n    Mac OS X Yosemite 10.10.5     Apple clang/clang++ version 6.1 from Xcode 7.0\n    64-bit                        gfortran GNU Fortran (GCC) 4.9.2\n    (osx1010dev/osx1010test)      Intel icc/icpc/ifort version 15.0.3\n\n    Mac OS X El Capitan 10.11.6   Apple clang/clang++ version 7.3.0 from Xcode 7.3\n    64-bit                        gfortran GNU Fortran (GCC) 5.2.0\n    (osx1011dev/osx1011test)      Intel icc/icpc/ifort version 16.0.2\n\n    Mac OS Sierra 10.12.6         Apple LLVM version 8.1.0 (clang/clang++-802.0.42)\n    64-bit                        gfortran GNU Fortran (GCC) 7.1.0\n    (kite)                        Intel icc/icpc/ifort version 17.0.2\n\n\nTested Configuration Features Summary\n=====================================\n\n    In the tables below\n          y   = tested\n          n   = not tested in this release\n          C   = Cluster\n          W   = Workstation\n          x   = not working in this release\n          dna = does not apply\n          ( ) = footnote appears below second table\n          <blank> = testing incomplete on this feature or platform\n\nPlatform                              C         F90/   F90      C++  zlib  SZIP\n                                      parallel  F2003  parallel\nSolaris2.11 32-bit                      n        y/y    n        y    y     y\nSolaris2.11 64-bit                      n        y/n    n        y    y     y\nWindows 7                               y        y/y    n        y    y     y\nWindows 7 x64                           y        y/y    y        y    y     y\nWindows 7 Cygwin                        n        y/n    n        y    y     y\nWindows 7 x64 Cygwin                    n        y/n    n        y    y     y\nWindows 10                              y        y/y    n        y    y     y\nWindows 10 x64                          y        y/y    n        y    y     y\nMac OS X Mavericks 10.9.5 64-bit        n        y/y    n        y    y     y\nMac OS X Yosemite 10.10.5 64-bit        n        y/y    n        y    y     y\nMac OS X El Capitan 10.11.6 64-bit      n        y/y    n        y    y     y\nMac OS Sierra 10.12.6 64-bit            n        y/y    n        y    y     y\nCentOS 7.2 Linux 3.10.0 x86_64 PGI      n        y/y    n        y    y     y\nCentOS 7.2 Linux 3.10.0 x86_64 GNU      y        y/y    y        y    y     y\nCentOS 7.2 Linux 3.10.0 x86_64 Intel    n        y/y    n        y    y     y\nLinux 2.6.32-573.18.1.el6.ppc64         n        y/y    n        y    y     y\n\n\nPlatform                                 Shared  Shared    Shared    Thread-\n                                         C libs  F90 libs  C++ libs  safe\nSolaris2.11 32-bit                         y       y         y         y\nSolaris2.11 64-bit                         y       y         y         y\nWindows 7                                  y       y         y         y\nWindows 7 x64                              y       y         y         y\nWindows 7 Cygwin                           n       n         n         y\nWindows 7 x64 Cygwin                       n       n         n         y\nWindows 10                                 y       y         y         y\nWindows 10 x64                             y       y         y         y\nMac OS X Mavericks 10.9.5 64-bit           y       n         y         y\nMac OS X Yosemite 10.10.5 64-bit           y       n         y         y\nMac OS X El Capitan 10.11.6 64-bit         y       n         y         y\nMac OS Sierra 10.12.6 64-bit               y       n         y         y\nCentOS 7.2 Linux 3.10.0 x86_64 PGI         y       y         y         n\nCentOS 7.2 Linux 3.10.0 x86_64 GNU         y       y         y         y\nCentOS 7.2 Linux 3.10.0 x86_64 Intel       y       y         y         n\nLinux 2.6.32-573.18.1.el6.ppc64            y       y         y         n\n\nCompiler versions for each platform are listed in the preceding\n\"Supported Platforms\" table.\n\n\nMore Tested Platforms\n=====================\nThe following platforms are not supported but have been tested for this release.\n\n    Linux 2.6.32-573.22.1.el6    GNU C (gcc), Fortran (gfortran), C++ (g++)\n    #1 SMP x86_64 GNU/Linux       compilers:\n    (mayll/platypus)                 Version 4.4.7 20120313\n                                     Version 4.9.3, 5.3.0, 6.2.0\n                                  PGI C, Fortran, C++ for 64-bit target on\n                                  x86-64;\n                                     Version 17.10-0\n                                  Intel(R) C (icc), C++ (icpc), Fortran (icc)\n                                  compilers:\n                                     Version 17.0.4.196 Build 20170411\n                                  MPICH 3.1.4 compiled with GCC 4.9.3\n\n    Linux 3.10.0-327.18.2.el7     GNU C (gcc) and C++ (g++) compilers\n    #1 SMP x86_64 GNU/Linux          Version 4.8.5 20150623 (Red Hat 4.8.5-4)\n    (jelly)                       with NAG Fortran Compiler Release 6.1(Tozai)\n                                  GCC Version 7.1.0\n                                  OpenMPI 3.0.0-GCC-7.2.0-2.29,\n                                     3.1.0-GCC-7.2.0-2.29\n                                  Intel(R) C (icc) and C++ (icpc) compilers\n                                     Version 17.0.0.098 Build 20160721\n                                  with NAG Fortran Compiler Release 6.1(Tozai)\n\n    Linux 3.10.0-327.10.1.el7     MPICH 3.2 compiled with GCC 5.3.0\n    #1 SMP x86_64 GNU/Linux\n    (moohan)\n\n    Linux 2.6.32-573.18.1.el6.ppc64  MPICH mpich 3.1.4 compiled with\n    #1 SMP ppc64 GNU/Linux           IBM XL C/C++ for Linux, V13.1\n    (ostrich)                        and IBM XL Fortran for Linux, V15.1\n\n    Debian 8.4 3.16.0-4-amd64 #1 SMP Debian 3.16.36-1 x86_64 GNU/Linux\n                                  gcc, g++ (Debian 4.9.2-10) 4.9.2\n                                  GNU Fortran (Debian 4.9.2-10) 4.9.2\n                                  (cmake and autotools)\n\n    Fedora 24  4.7.2-201.fc24.x86_64 #1 SMP x86_64 x86_64 x86_64 GNU/Linux\n                                  gcc, g++ (GCC) 6.1.1 20160621\n                                      (Red Hat 6.1.1-3)\n                                  GNU Fortran (GCC) 6.1.1 20160621\n                                      (Red Hat 6.1.1-3)\n                                  (cmake and autotools)\n\n    Ubuntu 16.04.1 4.4.0-38-generic #57-Ubuntu SMP x86_64 GNU/Linux\n                                  gcc, g++ (Ubuntu 5.4.0-6ubuntu1~16.04.2)\n                                      5.4.0 20160609\n                                  GNU Fortran (Ubuntu 5.4.0-6ubuntu1~16.04.2)\n                                      5.4.0 20160609\n                                  (cmake and autotools)\n\n\nKnown Problems\n==============\n\n    At present, metadata cache images may not be generated by parallel\n    applications.  Parallel applications can read files with metadata cache\n    images, but since this is a collective operation, a deadlock is possible\n    if one or more processes do not participate.\n\n    Three tests fail with OpenMPI 3.0.0/GCC-7.2.0-2.29:\n        testphdf5 (ecdsetw, selnone, cchunk1, cchunk3, cchunk4, and actualio)\n        t_shapesame (sscontig2)\n        t_pflush1/fails on exit\n    The first two tests fail attempting collective writes.\n\n    Known problems in previous releases can be found in the HISTORY*.txt files\n    in the HDF5 source. Please report any new problems found to\n    help@hdfgroup.org.\n\n\nCMake vs. Autotools installations\n=================================\nWhile both build systems produce similar results, there are differences.\nEach system produces the same set of folders on linux (only CMake works\non standard Windows); bin, include, lib and share. Autotools places the\nCOPYING and RELEASE.txt file in the root folder, CMake places them in\nthe share folder.\n\nThe bin folder contains the tools and the build scripts. Additionally, CMake\ncreates dynamic versions of the tools with the suffix \"-shared\". Autotools\ninstalls one set of tools depending on the \"--enable-shared\" configuration\noption.\n  build scripts\n  -------------\n  Autotools: h5c++, h5cc, h5fc\n  CMake: h5c++, h5cc, h5hlc++, h5hlcc\n\nThe include folder holds the header files and the fortran mod files. CMake\nplaces the fortran mod files into separate shared and static subfolders,\nwhile Autotools places one set of mod files into the include folder. Because\nCMake produces a tools library, the header files for tools will appear in\nthe include folder.\n\nThe lib folder contains the library files, and CMake adds the pkgconfig\nsubfolder with the hdf5*.pc files used by the bin/build scripts created by\nthe CMake build. CMake separates the C interface code from the fortran code by\ncreating C-stub libraries for each Fortran library. In addition, only CMake\ninstalls the tools library. The names of the szip libraries are different\nbetween the build systems.\n\nThe share folder will have the most differences because CMake builds include\na number of CMake specific files for support of CMake's find_package and support\nfor the HDF5 Examples CMake project.\n\n%%%%1.10.3%%%%\n\nHDF5 version 1.10.3 released on 2018-08-21\n================================================================================\n\n\nINTRODUCTION\n\nThis document describes the differences between this release and the previous\nHDF5 release. It contains information on the platforms tested and known\nproblems in this release. For more details check the HISTORY*.txt files in the\nHDF5 source.\n\nNote that documentation in the links below will be updated at the time of each\nfinal release.\n\nLinks to HDF5 documentation can be found on The HDF5 web page:\n\n     https://portal.hdfgroup.org/display/HDF5/HDF5\n\nThe official HDF5 releases can be obtained from:\n\n     https://www.hdfgroup.org/downloads/hdf5/\n\nChanges from Release to Release and New Features in the HDF5-1.10.x release series\ncan be found at:\n\n     https://portal.hdfgroup.org/display/HDF5/HDF5+Application+Developer%27s+Guide\n\nIf you have any questions or comments, please send them to the HDF Help Desk:\n\n     help@hdfgroup.org\n\n\nCONTENTS\n\n- New Features\n- Bug Fixes since HDF5-1.10.2\n- Supported Platforms\n- Tested Configuration Features Summary\n- More Tested Platforms\n- Known Problems\n- CMake vs. Autotools installations\n\n\nNew Features\n============\n\n    Library\n    -------\n    - Moved the H5DOread/write_chunk() API calls to H5Dread/write_chunk()\n\n      The functionality of the direct chunk I/O calls in the high-level\n      library has been moved to the H5D package in the main library. This\n      will allow using those functions without building the high-level\n      library. The parameters and functionality of the H5D calls are\n      identical to the H5DO calls.\n\n      The original H5DO high-level API calls have been retained, though\n      they are now just wrappers for the H5D calls. They are marked as\n      deprecated and are only available when the library is built with\n      deprecated functions. New code should use the H5D calls for this\n      reason.\n\n      As a part of this work, the following symbols from H5Dpublic.h are no\n      longer used:\n\n        H5D_XFER_DIRECT_CHUNK_WRITE_FLAG_NAME\n        H5D_XFER_DIRECT_CHUNK_WRITE_FILTERS_NAME\n        H5D_XFER_DIRECT_CHUNK_WRITE_OFFSET_NAME\n        H5D_XFER_DIRECT_CHUNK_WRITE_DATASIZE_NAME\n        H5D_XFER_DIRECT_CHUNK_READ_FLAG_NAME\n        H5D_XFER_DIRECT_CHUNK_READ_OFFSET_NAME\n        H5D_XFER_DIRECT_CHUNK_READ_FILTERS_NAME\n\n      And properties with these names are no longer stored in the dataset\n      transfer property lists. The symbols are still defined in H5Dpublic.h,\n      but only when the library is built with deprecated symbols.\n\n      (DER - 2018/05/04)\n\n    Configuration:\n    -------------\n    - Add missing USE_110_API_DEFAULT option.\n\n      Option USE_110_API_DEFAULT sets the default version of\n      versioned APIs. The bin/makevers perl script did not set\n      the maxidx variable correctly when the 1.10 branch was\n      created. This caused the versioning process to always use\n      the latest version of any API.\n\n      (ADB - 2018/08/17, HDFFV-10552)\n\n    - Added configuration checks for the following MPI functions:\n\n      MPI_Mprobe - Used for the Parallel Compression feature\n      MPI_Imrecv - Used for the Parallel Compression feature\n\n      MPI_Get_elements_x - Used for the \"big Parallel I/O\" feature\n      MPI_Type_size_x - Used for the \"big Parallel I/O\" feature\n\n      (JTH - 2018/08/02, HDFFV-10512)\n\n    - Added section to the libhdf5.settings file to indicate\n      the status of the Parallel Compression and \"big Parallel I/O\"\n      features.\n\n      (JTH - 2018/08/02, HDFFV-10512)\n\n    - Add option to execute swmr shell scripts from CMake.\n\n      Option TEST_SHELL_SCRIPTS redirects processing into a\n      separate ShellTests.cmake file for UNIX types. The tests\n      execute the shell scripts if a SH program is found.\n\n      (ADB - 2018/07/16)\n\n\n    C++ Library:\n    ------------\n    - New wrappers\n\n      Added the following items:\n\n      + Class DSetAccPropList for the dataset access property list.\n\n      + Wrapper for H5Dget_access_plist to class DataSet\n        // Gets the access property list of this dataset.\n        DSetAccPropList getAccessPlist() const;\n\n      + Wrappers for H5Pset_chunk_cache and H5Pget_chunk_cache to class DSetAccPropList\n        // Sets the raw data chunk cache parameters.\n        void setChunkCache(size_t rdcc_nslots, size_t rdcc_nbytes, double rdcc_w0)\n\n        // Retrieves the raw data chunk cache parameters.\n        void getChunkCache(size_t &rdcc_nslots, size_t &rdcc_nbytes, double &rdcc_w0)\n\n      + New operator!= to class DataType (HDFFV-10472)\n        // Determines whether two datatypes are not the same.\n        bool operator!=(const DataType& compared_type)\n\n      + Wrappers for H5Oget_info2, H5Oget_info_by_name2, and H5Oget_info_by_idx2\n        (HDFFV-10458)\n\n        // Retrieves information about an HDF5 object.\n        void getObjinfo(H5O_info_t& objinfo, unsigned fields = H5O_INFO_BASIC) const;\n\n        // Retrieves information about an HDF5 object, given its name.\n        void getObjinfo(const char* name, H5O_info_t& objinfo,\n                unsigned fields = H5O_INFO_BASIC,\n                const LinkAccPropList& lapl = LinkAccPropList::DEFAULT) const;\n        void getObjinfo(const H5std_string& name, H5O_info_t& objinfo,\n                unsigned fields = H5O_INFO_BASIC,\n                const LinkAccPropList& lapl = LinkAccPropList::DEFAULT) const;\n\n        // Retrieves information about an HDF5 object, given its index.\n        void getObjinfo(const char* grp_name, H5_index_t idx_type,\n                H5_iter_order_t order, hsize_t idx, H5O_info_t& objinfo,\n                unsigned fields = H5O_INFO_BASIC,\n                const LinkAccPropList& lapl = LinkAccPropList::DEFAULT) const;\n        void getObjinfo(const H5std_string& grp_name, H5_index_t idx_type,\n                H5_iter_order_t order, hsize_t idx, H5O_info_t& objinfo,\n                unsigned fields = H5O_INFO_BASIC,\n                const LinkAccPropList& lapl = LinkAccPropList::DEFAULT) const;\n\n      (BMR - 2018/07/22, HDFFV-10150, HDFFV-10458, HDFFV-1047)\n\n\n    Java Library:\n    ----------------\n    - Java HDFLibraryException class\n\n      Change parent class from Exception to RuntimeException.\n\n      (ADB - 2018/07/30, HDFFV-10534)\n\n    - JNI Read and Write\n\n      Refactored variable-length functions, H5DreadVL and H5AreadVL,\n      to correct dataset and attribute reads. New write functions,\n      H5DwriteVL and H5AwriteVL, are under construction.\n\n      (ADB - 2018/06/02, HDFFV-10519)\n\n\nBug Fixes since HDF5-1.10.2 release\n==================================\n\n    Library\n    -------\n    - Performance issue with H5Oget_info\n\n      H5Oget_info family of routines retrieves information for an object such\n      as object type, access time, number of attributes, and storage space etc.\n      Retrieving all such information regardless is an overkill and causes\n      performance issue when doing so for many objects.\n\n      Add an additional parameter \"fields\" to the the H5Oget_info family of routines\n      indicating the type of information to be retrieved.  The same is done to\n      the H5Ovisit family of routines which recursively visits an object\n      returning object information in a callback function.  Both sets of routines\n      are versioned and the corresponding compatibility macros are added.\n\n      The version 2 names of the two sets of routines are:\n        (1) H5Oget_info2, H5Oget_info_by_idx2, H5Oget_info_by_name2\n        (2) H5Ovisit2, H5Ovisit_by_name2\n\n      (VC - 2018/08/15, HDFFV-10180)\n\n    - Test failure due to metadata size in test/vds.c\n\n      The size of metadata from test_api_get_ex_dcpl() in test/vds.c is not as expected\n      because the latest format should be used when encoding the layout for VDS.\n\n      Set the latest format in a temporary fapl and pass the setting to the routines that\n      encode the dataset selection for VDS.\n\n      (VC - 2018/08/14 HDFFV-10469)\n\n    - Java HDF5LibraryException class\n\n      The error minor and major values would be lost after the\n      constructor executed.\n\n      Created two local class variables to hold the values obtained during\n      execution of the constructor. Refactored the class functions to retrieve\n      the class values rather then calling the native functions.\n      The native functions were renamed and called only during execution\n      of the constructor.\n      Added error checking to calling class constructors in JNI classes.\n\n      (ADB - 2018/08/06, HDFFV-10544)\n\n    - Added checks of the defined MPI_VERSION to guard against usage of\n      MPI-3 functions in the Parallel Compression and \"big Parallel I/O\"\n      features when HDF5 is built with MPI-2. Previously, the configure\n      step would pass but the build itself would fail when it could not\n      locate the MPI-3 functions used.\n\n      As a result of these new checks, HDF5 can again be built with MPI-2,\n      but the Parallel Compression feature will be disabled as it relies\n      on the MPI-3 functions used.\n\n      (JTH - 2018/08/02, HDFFV-10512)\n\n    - User's patches: CVEs\n\n      The following patches have been applied:\n\n      CVE-2018-11202 - NULL pointer dereference was discovered in\n                       H5S_hyper_make_spans in H5Shyper.c (HDFFV-10476)\n        https://security-tracker.debian.org/tracker/CVE-2018-11202\n        https://cve.mitre.org/cgi-bin/cvename.cgi?name=3DCVE-2018-11202\n\n      CVE-2018-11203 - A division by zero was discovered in\n                       H5D__btree_decode_key in H5Dbtree.c (HDFFV-10477)\n        https://security-tracker.debian.org/tracker/CVE-2018-11203\n        https://cve.mitre.org/cgi-bin/cvename.cgi?name=3DCVE-2018-11203\n\n      CVE-2018-11204 - A NULL pointer dereference was discovered in\n                       H5O__chunk_deserialize in H5Ocache.c (HDFFV-10478)\n        https://security-tracker.debian.org/tracker/CVE-2018-11204\n        https://cve.mitre.org/cgi-bin/cvename.cgi?name=3DCVE-2018-11204\n\n      CVE-2018-11206 - An out of bound read was discovered in\n                       H5O_fill_new_decode and H5O_fill_old_decode in H5Ofill.c\n                       (HDFFV-10480)\n        https://security-tracker.debian.org/tracker/CVE-2018-11206\n        https://cve.mitre.org/cgi-bin/cvename.cgi?name=3DCVE-2018-11206\n\n      CVE-2018-11207 - A division by zero was discovered in\n                       H5D__chunk_init in H5Dchunk.c  (HDFFV-10481)\n        https://security-tracker.debian.org/tracker/CVE-2018-11207\n        https://cve.mitre.org/cgi-bin/cvename.cgi?name=3DCVE-2018-11207\n\n      (BMR - 2018/7/22, PR#s: 1134 and 1139,\n       HDFFV-10476, HDFFV-10477, HDFFV-10478, HDFFV-10480, HDFFV-10481)\n\n    - H5Adelete\n\n      H5Adelete failed when deleting the last \"large\" attribute that\n      is stored densely via fractal heap/v2 b-tree.\n\n      After removing the attribute, update the ainfo message.  If the\n      number of attributes goes to zero, remove the message.\n\n      (VC - 2018/07/20, HDFFV-9277)\n\n    - A bug was discovered in the parallel library which caused partial\n      parallel reads of filtered datasets to return incorrect data. The\n      library used the incorrect dataspace for each chunk read, causing\n      the selection used in each chunk to be wrong.\n\n      The bug was not caught during testing because all of the current\n      tests which do parallel reads of filtered data read all of the data\n      using an H5S_ALL selection. Several tests were added which exercise\n      partial parallel reads.\n\n      (JTH - 2018/07/16, HDFFV-10467)\n\n    - A bug was discovered in the parallel library which caused parallel\n      writes of filtered datasets to trigger an assertion failure in the\n      file free space manager.\n\n      This occurred when the filter used caused chunks to repeatedly shrink\n      and grow over the course of several dataset writes. The previous chunk\n      information, such as the size of the chunk and the offset in the file,\n      was being cached and not updated after each write, causing the next write\n      to the chunk to retrieve the incorrect cached information and run into\n      issues when reallocating space in the file for the chunk.\n\n      (JTH - 2018/07/16, HDFFV-10509)\n\n    - A bug was discovered in the parallel library which caused the\n      H5D__mpio_array_gatherv() function to allocate too much memory.\n\n      When the function is called with the 'allgather' parameter set\n      to a non-true value, the function will receive data from all MPI\n      ranks and gather it to the single rank specied by the 'root'\n      parameter. However, the bug in the function caused memory for\n      the received data to be allocated on all MPI ranks, not just the\n      singular rank specified as the receiver. In some circumstances,\n      this would cause an application to fail due to the large amounts\n      of memory being allocated.\n\n      (JTH - 2018/07/16, HDFFV-10467)\n\n    - Error checks in h5stat and when decoding messages\n\n      h5stat exited with seg fault/core dumped when\n      errors are encountered in the internal library.\n\n      Add error checks and --enable-error-stack option to h5stat.\n      Add range checks when decoding messages: old fill value, old\n      layout and refcount.\n\n      (VC - 2018/07/11, HDFFV-10333)\n\n    - If an HDF5 file contains a malformed compound datatype with a\n      suitably large offset, the type conversion code can run off\n      the end of the type conversion buffer, causing a segmentation\n      fault.\n\n      This issue was reported to The HDF Group as issue #CVE-2017-17507.\n\n      NOTE: The HDF5 C library cannot produce such a file. This condition\n            should only occur in a corrupt (or deliberately altered) file\n            or a file created by third-party software.\n\n      THE HDF GROUP WILL NOT FIX THIS BUG AT THIS TIME\n\n      Fixing this problem would involve updating the publicly visible\n      H5T_conv_t function pointer typedef and versioning the API calls\n      which use it. We normally only modify the public API during\n      major releases, so this bug will not be fixed at this time.\n\n      (DER - 2018/02/26, HDFFV-10356)\n\n\n    Configuration\n    -------------\n    - Applied patches to address Cywin build issues\n\n      There were three issues for Cygwin builds:\n      - Shared libs were not built.\n      - The -std=c99 flag caused a SIG_SETMASK undeclared error.\n      - Undefined errors when buildbing test shared libraries.\n\n      Patches to address these issues were received and incorporated in this version.\n\n      (LRK - 2018/07/18, HDFFV-10475)\n\n    - The --enable-debug/production configure flags are listed as 'deprecated'\n      when they should really be listed as 'removed'.\n\n      In the autotools overhaul several years ago, we removed these flags and\n      implemented a new --enable-build-mode= flag. This was done because we\n      changed the semantics of the modes and didn't want users to silently\n      be exposed to them. The newer system is also more flexible and us to\n      add other modes (like 'clean').\n\n      The --enable-debug/production flags are now listed as removed.\n\n      (DER - 2018/05/31, HDFFV-10505)\n\n    - Moved the location of gcc attribute.\n\n      The gcc attribute(no_sanitize), named as the macro HDF_NO_UBSAN,\n      was located after the function name. Builds with GCC 7 did not\n      indicate any problem, but GCC 8 issued errors. Moved the\n      attribute before the function name, as required.\n\n      (ADB - 2018/05/22, HDFFV-10473)\n\n    - Reworked java test suite into individual JUnit tests.\n\n      Testing the whole suite of java unit tests in a single JUnit run\n      made it difficult to determine actual failures when tests would fail.\n      Running each file set of tests individually, allows individual failures\n      to be diagnosed easier. A side benefit is that tests for optional components\n      of the library can be disabled if not configured.\n\n      (ADB - 2018/05/16, HDFFV-9739)\n\n    - Converted CMake global commands ADD_DEFINITIONS and INCLUDE_DIRECTORIES\n      to use target_* type commands. This change modernizes the CMake usage\n      in the HDF5 library.\n\n      In addition, there is the intention to convert to generator expressions,\n      where possible. The exception is Fortran FLAGS on Windows Visual Studio.\n      The HDF macros TARGET_C_PROPERTIES and TARGET_FORTRAN_PROPERTIES have\n      been removed with this change in usage.\n\n      The additional language (C++ and Fortran) checks have also been localized\n      to only be checked when that language is enabled.\n\n      (ADB - 2018/05/08)\n\n\n    Performance\n    -------------\n    - Revamped internal use of DXPLs, improving performance\n\n      (QAK - 2018/05/20)\n\n\n    Fortran\n    --------\n    - Fixed issue with h5fget_obj_count_f and using a file id of H5F_OBJ_ALL_F not\n      returning the correct count.\n\n      (MSB - 2018/5/15, HDFFV-10405)\n\n\n    C++ APIs\n    --------\n    - Adding default arguments to existing functions\n\n      Added the following items:\n      + Two more property list arguments are added to H5Location::createDataSet:\n        const DSetAccPropList& dapl = DSetAccPropList::DEFAULT\n        const LinkCreatPropList& lcpl = LinkCreatPropList::DEFAULT\n\n      + One more property list argument is added to H5Location::openDataSet:\n        const DSetAccPropList& dapl = DSetAccPropList::DEFAULT\n\n      (BMR - 2018/07/21, PR# 1146)\n\n    - Improvement C++ documentation\n\n      Replaced the table in main page of the C++ documentation from mht to htm format\n      for portability.\n\n      (BMR - 2018/07/17, PR# 1141)\n\n\nSupported Platforms\n===================\n\n    Linux 2.6.32-696.16.1.el6.ppc64 gcc (GCC) 4.4.7 20120313 (Red Hat 4.4.7-18)\n    #1 SMP ppc64 GNU/Linux        g++ (GCC) 4.4.7 20120313 (Red Hat 4.4.7-18)\n    (ostrich)                     GNU Fortran (GCC) 4.4.7 20120313 (Red Hat 4.4.7-18)\n                                  IBM XL C/C++ V13.1\n                                  IBM XL Fortran V15.1\n\n    Linux 3.10.0-327.10.1.el7   GNU C (gcc), Fortran (gfortran), C++ (g++)\n    #1 SMP x86_64 GNU/Linux       compilers:\n    (kituo/moohan)                Version 4.8.5 20150623 (Red Hat 4.8.5-4)\n                                    Version 4.9.3, Version 5.2.0\n                                  Intel(R) C (icc), C++ (icpc), Fortran (icc)\n                                  compilers:\n                                     Version 17.0.0.098 Build 20160721\n                                  MPICH 3.1.4 compiled with GCC 4.9.3\n\n    SunOS 5.11 32- and 64-bit     Sun C 5.12 SunOS_sparc\n    (emu)                         Sun Fortran 95 8.6 SunOS_sparc\n                                  Sun C++ 5.12 SunOS_sparc\n\n    Windows 7                     Visual Studio 2015 w/ Intel Fortran 16 (cmake)\n\n    Windows 7 x64                 Visual Studio 2012 w/ Intel Fortran 15 (cmake)\n                                  Visual Studio 2013 w/ Intel Fortran 15 (cmake)\n                                  Visual Studio 2015 w/ Intel Fortran 16 (cmake)\n                                  Visual Studio 2015 w/ Intel C, Fortran 2017 (cmake)\n                                  Visual Studio 2015 w/ MSMPI 8 (cmake)\n\n    Windows 10                    Visual Studio 2015 w/ Intel Fortran 18 (cmake)\n\n    Windows 10 x64                Visual Studio 2015 w/ Intel Fortran 18 (cmake)\n                                  Visual Studio 2017 w/ Intel Fortran 18 (cmake)\n\n    Mac OS X Yosemite 10.10.5     Apple clang/clang++ version 6.1 from Xcode 7.0\n    64-bit                        gfortran GNU Fortran (GCC) 4.9.2\n    (osx1010dev/osx1010test)      Intel icc/icpc/ifort version 15.0.3\n\n    Mac OS X El Capitan 10.11.6   Apple clang/clang++ version 7.3.0 from Xcode 7.3\n    64-bit                        gfortran GNU Fortran (GCC) 5.2.0\n    (osx1011dev/osx1011test)      Intel icc/icpc/ifort version 16.0.2\n\n    Mac OS Sierra 10.12.6         Apple LLVM version 8.1.0 (clang/clang++-802.0.42)\n    64-bit                        gfortran GNU Fortran (GCC) 7.1.0\n    (swallow/kite)                Intel icc/icpc/ifort version 17.0.2\n\nTested Configuration Features Summary\n=====================================\n\n    In the tables below\n          y   = tested\n          n   = not tested in this release\n          C   = Cluster\n          W   = Workstation\n          x   = not working in this release\n          dna = does not apply\n          ( ) = footnote appears below second table\n          <blank> = testing incomplete on this feature or platform\n\nPlatform                              C         F90/   F90      C++  zlib  SZIP\n                                      parallel  F2003  parallel\nSolaris2.11 32-bit                      n        y/y    n        y    y     y\nSolaris2.11 64-bit                      n        y/n    n        y    y     y\nWindows 7                               y        y/y    n        y    y     y\nWindows 7 x64                           y        y/y    y        y    y     y\nWindows 7 Cygwin                        n        y/n    n        y    y     y\nWindows 7 x64 Cygwin                    n        y/n    n        y    y     y\nWindows 10                              y        y/y    n        y    y     y\nWindows 10 x64                          y        y/y    n        y    y     y\nMac OS X Mavericks 10.9.5 64-bit        n        y/y    n        y    y     y\nMac OS X Yosemite 10.10.5 64-bit        n        y/y    n        y    y     y\nMac OS X El Capitan 10.11.6 64-bit      n        y/y    n        y    y     y\nMac OS Sierra 10.12.6 64-bit            n        y/y    n        y    y     y\nCentOS 7.2 Linux 2.6.32 x86_64 PGI      n        y/y    n        y    y     y\nCentOS 7.2 Linux 2.6.32 x86_64 GNU      y        y/y    y        y    y     y\nCentOS 7.2 Linux 2.6.32 x86_64 Intel    n        y/y    n        y    y     y\nLinux 2.6.32-573.18.1.el6.ppc64         n        y/y    n        y    y     y\n\n\nPlatform                                 Shared  Shared    Shared    Thread-\n                                         C libs  F90 libs  C++ libs  safe\nSolaris2.11 32-bit                         y       y         y         y\nSolaris2.11 64-bit                         y       y         y         y\nWindows 7                                  y       y         y         y\nWindows 7 x64                              y       y         y         y\nWindows 7 Cygwin                           n       n         n         y\nWindows 7 x64 Cygwin                       n       n         n         y\nWindows 10                                 y       y         y         y\nWindows 10 x64                             y       y         y         y\nMac OS X Mavericks 10.9.5 64-bit           y       n         y         y\nMac OS X Yosemite 10.10.5 64-bit           y       n         y         y\nMac OS X El Capitan 10.11.6 64-bit         y       n         y         y\nMac OS Sierra 10.12.6 64-bit               y       n         y         y\nCentOS 7.2 Linux 2.6.32 x86_64 PGI         y       y         y         n\nCentOS 7.2 Linux 2.6.32 x86_64 GNU         y       y         y         y\nCentOS 7.2 Linux 2.6.32 x86_64 Intel       y       y         y         n\nLinux 2.6.32-573.18.1.el6.ppc64            y       y         y         n\n\nCompiler versions for each platform are listed in the preceding\n\"Supported Platforms\" table.\n\n\nMore Tested Platforms\n=====================\nThe following platforms are not supported but have been tested for this release.\n\n    Linux 2.6.32-573.22.1.el6    GNU C (gcc), Fortran (gfortran), C++ (g++)\n    #1 SMP x86_64 GNU/Linux       compilers:\n    (mayll/platypus)                 Version 4.4.7 20120313\n                                     Version 4.9.3, 5.3.0, 6.2.0\n                                  PGI C, Fortran, C++ for 64-bit target on\n                                  x86-64;\n                                     Version 17.10-0\n                                  Intel(R) C (icc), C++ (icpc), Fortran (icc)\n                                  compilers:\n                                     Version 17.0.4.196 Build 20170411\n                                  MPICH 3.1.4 compiled with GCC 4.9.3\n\n    Linux 3.10.0-327.18.2.el7     GNU C (gcc) and C++ (g++) compilers\n    #1 SMP x86_64 GNU/Linux          Version 4.8.5 20150623 (Red Hat 4.8.5-4)\n    (jelly)                       with NAG Fortran Compiler Release 6.1(Tozai)\n                                  GCC Version 7.1.0\n                                  OpenMPI 3.0.0-GCC-7.2.0-2.29,\n                                     3.1.0-GCC-7.2.0-2.29\n                                  Intel(R) C (icc) and C++ (icpc) compilers\n                                     Version 17.0.0.098 Build 20160721\n                                  with NAG Fortran Compiler Release 6.1(Tozai)\n\n    Linux 3.10.0-327.10.1.el7     MPICH 3.2 compiled with GCC 5.3.0\n    #1 SMP x86_64 GNU/Linux\n    (moohan)\n\n    Linux 2.6.32-573.18.1.el6.ppc64  MPICH mpich 3.1.4 compiled with\n    #1 SMP ppc64 GNU/Linux           IBM XL C/C++ for Linux, V13.1\n    (ostrich)                        and IBM XL Fortran for Linux, V15.1\n\n    Debian 8.4 3.16.0-4-amd64 #1 SMP Debian 3.16.36-1 x86_64 GNU/Linux\n                                  gcc, g++ (Debian 4.9.2-10) 4.9.2\n                                  GNU Fortran (Debian 4.9.2-10) 4.9.2\n                                  (cmake and autotools)\n\n    Fedora 24  4.7.2-201.fc24.x86_64 #1 SMP x86_64 x86_64 x86_64 GNU/Linux\n                                  gcc, g++ (GCC) 6.1.1 20160621\n                                      (Red Hat 6.1.1-3)\n                                  GNU Fortran (GCC) 6.1.1 20160621\n                                      (Red Hat 6.1.1-3)\n                                  (cmake and autotools)\n\n    Ubuntu 16.04.1 4.4.0-38-generic #57-Ubuntu SMP x86_64 GNU/Linux\n                                  gcc, g++ (Ubuntu 5.4.0-6ubuntu1~16.04.2)\n                                      5.4.0 20160609\n                                  GNU Fortran (Ubuntu 5.4.0-6ubuntu1~16.04.2)\n                                      5.4.0 20160609\n                                  (cmake and autotools)\n\n\nKnown Problems\n==============\n\n    At present, metadata cache images may not be generated by parallel\n    applications.  Parallel applications can read files with metadata cache\n    images, but since this is a collective operation, a deadlock is possible\n    if one or more processes do not participate.\n\n    Three tests fail with OpenMPI 3.0.0/GCC-7.2.0-2.29:\n        testphdf5 (ecdsetw, selnone, cchunk1, cchunk3, cchunk4, and actualio)\n        t_shapesame (sscontig2)\n        t_pflush1/fails on exit\n    The first two tests fail attempting collective writes.\n\n    Known problems in previous releases can be found in the HISTORY*.txt files\n    in the HDF5 source. Please report any new problems found to\n    help@hdfgroup.org.\n\n\nCMake vs. Autotools installations\n=================================\nWhile both build systems produce similar results, there are differences.\nEach system produces the same set of folders on linux (only CMake works\non standard Windows); bin, include, lib and share. Autotools places the\nCOPYING and RELEASE.txt file in the root folder, CMake places them in\nthe share folder.\n\nThe bin folder contains the tools and the build scripts. Additionally, CMake\ncreates dynamic versions of the tools with the suffix \"-shared\". Autotools\ninstalls one set of tools depending on the \"--enable-shared\" configuration\noption.\n  build scripts\n  -------------\n  Autotools: h5c++, h5cc, h5fc\n  CMake: h5c++, h5cc, h5hlc++, h5hlcc\n\nThe include folder holds the header files and the fortran mod files. CMake\nplaces the fortran mod files into separate shared and static subfolders,\nwhile Autotools places one set of mod files into the include folder. Because\nCMake produces a tools library, the header files for tools will appear in\nthe include folder.\n\nThe lib folder contains the library files, and CMake adds the pkgconfig\nsubfolder with the hdf5*.pc files used by the bin/build scripts created by\nthe CMake build. CMake separates the C interface code from the fortran code by\ncreating C-stub libraries for each Fortran library. In addition, only CMake\ninstalls the tools library. The names of the szip libraries are different\nbetween the build systems.\n\nThe share folder will have the most differences because CMake builds include\na number of CMake specific files for support of CMake's find_package and support\nfor the HDF5 Examples CMake project.\n\n\n%%%%1.10.2%%%%\n\nHDF5 version 1.10.2 released on 2018-03-29\n================================================================================\n\n\nINTRODUCTION\n\nThis document describes the differences between this release and the previous\nHDF5 release. It contains information on the platforms tested and known\nproblems in this release. For more details check the HISTORY*.txt files in the\nHDF5 source.\n\nNote that documentation in the links below will be updated at the time of each\nfinal release.\n\nLinks to HDF5 documentation can be found on The HDF5 web page:\n\n     https://portal.hdfgroup.org/display/HDF5/HDF5\n\nThe official HDF5 releases can be obtained from:\n\n     https://www.hdfgroup.org/downloads/hdf5/\n\nChanges from Release to Release and New Features in the HDF5-1.10.x release series\ncan be found at:\n\n     https://portal.hdfgroup.org/display/HDF5/HDF5+Application+Developer%27s+Guide\n\nIf you have any questions or comments, please send them to the HDF Help Desk:\n\n     help@hdfgroup.org\n\n\nCONTENTS\n\n- New Features\n- Support for new platforms and languages\n- Bug Fixes since HDF5-1.10.1\n- Supported Platforms\n- Tested Configuration Features Summary\n- More Tested Platforms\n- Known Problems\n\n\nNew Features\n============\n\n    Configuration and Build Systems:\n    --------------------------------\n    - CMake builds\n    --------------\n\n      - Changed minimum CMake required version to 3.10.\n\n      This change removed the need to support a copy of the FindMPI.cmake module,\n      which has been removed, along with its subfolder in the config/cmake_ext_mod\n      location.\n\n      (ADB - 2018/03/09)\n\n      - Added pkg-config file generation\n\n      Added pkg-config file generation for the C, C++, HL, and HL C++ libraries.\n      In addition, builds on Linux will create h5cc, h5c++, h5hlcc, and h5hlc++ scripts in the bin\n      directory that use the pkg-config files. The scripts can be used to build HDF5 C and C++\n      applications (i.e, similar to the compiler scripts produced by the Autotools builds).\n\n      (ADB - 2018/03/08, HDFFV-4359)\n\n       - Refactored use of CMAKE_BUILD_TYPE for new variable, which understands\n      the type of generator in use.\n\n      Added new configuration macros to use new HDF_BUILD_TYPE variable. This\n      variable is set correctly for the type of generator being used for the build.\n\n      (ADB - 2018/01/08, HDFFV-10385, HDFFV-10296)\n\n    - Autotools builds\n    ------------------\n\n       - Removed version-specific gcc/gfortran flags for version 4.0 (inclusive)\n      and earlier.\n\n      The config/gnu-flags file, which is sourced as a part of the configure\n      process, adds version-specific flags for use when building HDF5. Most of\n      these flags control warnings and do not affect the final product.\n\n      Flags for older versions of the compiler were consolidated into the\n      common flags section. Moving these flags simplifies maintenance of\n      the file.\n\n      The upshot of this is that building with ancient versions of gcc\n      (<= 4.0) will possibly no longer work without hand-hacking the file\n      to remove the flags not understood by that version of the compiler.\n      Nothing should change when building with gcc >= 4.1.\n\n      (DER - 2017/05/31, HDFFV-9937)\n\n       - -fno-omit-frame-pointer was added when building with debugging symbols\n      enabled.\n\n      Debugging symbols can be enabled independently of the overall build\n      mode in both the autotools and CMake. This allows (limited) debugging\n      of optimized code. Since many debuggers rely on the frame pointer,\n      we've disabled this optimization when debugging symbols are requested\n      (e.g.: via building with --enable-symbols).\n\n      (DER - 2017/05/31, HDFFV-10226)\n\n\n    Library:\n    --------\n    - Added an enumerated value to H5F_libver_t for H5Pset_libver_bounds().\n\n      Currently, the library defines two values for H5F_libver_t and supports\n      only two pairs of (low, high) combinations as derived from these values.\n      Thus the bounds setting via H5Pset_libver_bounds() is rather restricted.\n\n      Added an enumerated value (H5F_LIBVER_V18) to H5F_libver_t and\n      H5Pset_libver_bounds() now supports five pairs of (low, high) combinations\n      as derived from these values.  This addition provides the user more\n      flexibility in setting bounds for object creation.\n\n      (VC - 2018/03/14)\n\n    - Added prefix option to VDS files.\n\n      Currently, VDS source files must be in the active directory to be\n      found by the virtual file. Adding the option of a prefix to be set\n      on the virtual file, using a data access property list (DAPL),\n      allows the source files to locate at an absolute or relative path\n      to the virtual file.\n      Private utility functions in H5D and H5L packages merged into single\n      function in H5F package.\n\n      New public APIs:\n            herr_t H5Pset_virtual_prefix(hid_t dapl_id, const char* prefix);\n            ssize_t H5Pget_virtual_prefix(hid_t dapl_id, char* prefix /*out*/, size_t size);\n      The prefix can also be set with an environment variable, HDF5_VDS_PREFIX.\n\n      (ADB - 2017/12/12, HDFFV-9724, HDFFV-10361)\n\n    - H5FDdriver_query() API call added to the C library.\n\n      This new library call allows the user to query a virtual file driver\n      (VFD) for the feature flags it supports (listed in H5FDpublic.h).\n      This can be useful to determine if a VFD supports SWMR, for example.\n\n      Note that some VFDs have feature flags that may only be present\n      after a file has been created or opened (e.g.: the core VFD will\n      have the H5FD_FEAT_POSIX_COMPAT_HANDLE flag set if the backing\n      store is switched on). Since the new API call queries a generic VFD\n      unassociated with a file, these flags will never be returned.\n\n      (DER - 2017/05/31, HDFFV-10215)\n\n    - H5FD_FEAT_DEFAULT_VFD_COMPATIBLE VFD feature flag added to the C library.\n\n      This new feature flag indicates that the VFD is compatible with the\n      default VFD. VFDs that set this flag create single files that follow\n      the canonical HDF5 file format.\n\n      (DER - 2017/05/31, HDFFV-10214)\n\n    - The H5I_REFERENCE value in the H5I_type_t enum (defined in H5Ipublic.h)\n      has been marked as deprecated.\n\n      This ID type value is not used in the C library. i.e.: There are no\n      hid_t values that are of ID type H5I_REFERENCE.\n\n      This enum value will be removed in a future major version of the library.\n      The code will remain unchanged in the HDF5 1.10.x  releases and branches.\n\n      (DER - 2017/04/05, HDFFV-10252)\n\n\n    Parallel Library:\n    -----------------\n    - Enabled compression for parallel applications.\n\n      With this release parallel applications can create and write compressed\n      datasets (or the datasets with the filters such as Fletcher32 applied).\n\n      (EIP - 2018/03/29)\n\n    - Addressed slow file close on some Lustre file systems.\n\n      Slow file close has been reported on some Lustre file systems.\n      While the ultimate cause is not understood fully, the proximate\n      cause appears to be long delays in MPI_File_set_size() calls at\n      file close and flush.\n\n      To minimize this problem pending a definitive diagnosis and fix,\n      PHDF5 has been modified to avoid MPI_File_set_size() calls when\n      possible.  This is done by comparing the library's EOA (End of\n      Allocation) with the file systems EOF, and skipping the\n      MPI_File_set_size() call if the two match.\n\n      (JRM - 2018/03/29)\n\n    - Optimized parallel open/location of the HDF5 super-block.\n\n      Previous releases of PHDF5 required all parallel ranks to\n      search for the HDF5 superblock signature when opening the\n      file. As this is accomplished more or less as a synchronous\n      operation, a large number of processes can experience a\n      slowdown in the file open due to filesystem contention.\n\n      As a first step in improving the startup/file-open performance,\n      we allow MPI rank 0 of the associated MPI communicator to locate\n      the base offset of the super-block and then broadcast that result\n      to the remaining ranks in the parallel group.  Note that this\n      approach is utilized ONLY during file opens which employ the MPIO\n      file driver in HDF5 by previously having called H5Pset_fapl_mpio().\n\n      HDF5 parallel file operations which do not employ multiple ranks\n      e.g. specifiying MPI_COMM_SELF (whose MPI_Comm_size == 1)\n      as opposed to MPI_COMM_WORLD, will not be affected by this\n      optimization.  Conversely, parallel file operations on subgroups\n      of MPI_COMM_WORLD are allowed to be run in parallel with each\n      subgroup operating as an independant collection of processes.\n\n      (RAW - 2017/10/10, HDFFV-10294)\n\n    - Added large (>2GB)  MPI-IO transfers.\n\n      Previous releases of PHDF5 would fail when attempting to\n      read or write greater than 2GB of data in a single IO operation.\n      This issue stems principally from an MPI API whose definitions\n      utilize 32 bit integers to describe the number of data elements\n      and datatype that MPI should use to effect a data transfer.\n      Historically, HDF5 has invoked MPI-IO with the number of\n      elements in a contiguous buffer represented as the length\n      of that buffer in bytes.\n\n      Resolving the issue and thus enabling larger MPI-IO transfers\n      is accomplished first, by detecting when a user IO request would\n      exceed the 2GB limit as described above.  Once a transfer request\n      is identified as requiring special handling, PHDF5 now creates a\n      derived datatype consisting of a vector of fixed sized blocks\n      which is in turn wrapped within a single MPI_Type_struct to\n      contain the vector and any remaining data.   The newly created\n      datatype is then used in place of MPI_BYTE and can be used to\n      fulfill the original user request without encountering API\n      errors.\n\n      (RAW - 2017/09/10, HDFFV-8839)\n\n\n    C++ Library:\n    ------------\n    - The following C++ API wrappers have been added to the C++ Library:\n      + H5Lcreate_soft:\n        // Creates a soft link from link_name to target_name.\n        void link(const char *target_name, const char *link_name,...)\n        void link(const H5std_string& target_name,...)\n\n      + H5Lcreate_hard:\n        // Creates a hard link from new_name to curr_name.\n        void link(const char *curr_name, const Group& new_loc,...)\n        void link(const H5std_string& curr_name, const Group& new_loc,...)\n\n        // Creates a hard link from new_name to curr_name in same location.\n        void link(const char *curr_name, const hid_t same_loc,...)\n        void link(const H5std_string& curr_name, const hid_t same_loc,...)\n\n        Note: previous version of H5Location::link will be deprecated.\n\n      + H5Lcopy:\n        // Copy an object from a group of file to another.\n        void copyLink(const char *src_name, const Group& dst,...)\n        void copyLink(const H5std_string& src_name, const Group& dst,...)\n\n        // Copy an object from a group of file to the same location.\n        void copyLink(const char *src_name, const char *dst_name,...)\n        void copyLink(const H5std_string& src_name,...)\n\n      + H5Lmove:\n        // Rename an object in a group or file to a new location.\n        void moveLink(const char* src_name, const Group& dst,...)\n        void moveLink(const H5std_string& src_name, const Group& dst,...)\n\n        // Rename an object in a group or file to the same location.\n        void moveLink(const char* src_name, const char* dst_name,...)\n        void moveLink(const H5std_string& src_name,...)\n\n        Note: previous version H5Location::move will be deprecated.\n\n      + H5Ldelete:\n        // Removes the specified link from this location.\n        void unlink(const char *link_name,\n            const LinkAccPropList& lapl = LinkAccPropList::DEFAULT)\n        void unlink(const H5std_string& link_name,\n            const LinkAccPropList& lapl = LinkAccPropList::DEFAULT)\n\n        Note: additional parameter is added to previous H5Location::unlink.\n\n      + H5Tencode and H5Tdecode:\n        // Creates a binary object description of this datatype.\n        void DataType::encode() - C API H5Tencode()\n\n        // Returns the decoded type from the binary object description.\n        DataType::decode() - C API H5Tdecode()\n        ArrayType::decode() - C API H5Tdecode()\n        CompType::decode() - C API H5Tdecode()\n        DataType::decode() - C API H5Tdecode()\n        EnumType::decode() - C API H5Tdecode()\n        FloatType::decode() - C API H5Tdecode()\n        IntType::decode() - C API H5Tdecode()\n        StrType::decode() - C API H5Tdecode()\n        VarLenType::decode() - C API H5Tdecode()\n\n      + H5Lget_info:\n        // Returns the information of the named link.\n        H5L_info_t getLinkInfo(const H5std_string& link_name,...)\n\n      (BMR - 2018/03/11, HDFFV-10149)\n\n    - Added class LinkCreatPropList for link create property list.\n\n      (BMR - 2018/03/11, HDFFV-10149)\n\n    - Added overloaded functions H5Location::createGroup to take a link\n      creation property list.\n        Group createGroup(const char* name, const LinkCreatPropList& lcpl)\n        Group createGroup(const H5std_string& name, const LinkCreatPropList& lcpl)\n\n      (BMR - 2018/03/11, HDFFV-10149)\n\n    - A document is added to the HDF5 C++ API Reference Manual to show the\n      mapping from a C API to C++ wrappers.  It can be found from the main\n      page of the C++ API Reference Manual.\n\n      (BMR - 2017/10/17, HDFFV-10151)\n\n\n    Java Library:\n    ----------------\n    - Wrapper added for enabling the error stack.\n\n      H5error_off would disable the error stack reporting. In order\n      to re-enable the reporting, the error stack info needs to be\n      saved so that H5error_on can revert state.\n\n      (ADB - 2018/03/13, HDFFV-10412)\n\n    - Wrappers were added for the following C APIs:\n      H5Pset_evict_on_close\n      H5Pget_evict_on_close\n      H5Pset_chunk_opts\n      H5Pget_chunk_opts\n      H5Pset_efile_prefix\n      H5Pget_efile_prefix\n      H5Pset_virtual_prefix\n      H5Pget_virtual_prefix\n\n      (ADB - 2017/12/20)\n\n    - The H5I_REFERENCE value in the H5I_type_t enum (defined in H5Ipublic.h)\n      has been marked as deprectated.\n\n      JNI code which refers to this value will be removed in a future\n      major version of the library. The code will remain unchanged in the\n      1.10.x releases and branches.\n\n      See the C library section, above, for further information.\n\n      (HDFFV-10252, DER, 2017/04/05)\n\n\n    Tools:\n    ------\n    - h5diff has a new option to display error stack.\n\n      Updated h5diff with the --enable-error-stack argument, which\n      enables the display of the hdf5 error stack. This completes the\n      improvement to the main tools: h5copy, h5diff, h5dump, h5ls and\n      h5repack.\n\n      (ADB - 2017/08/30, HDFFV-9774)\n\n\nSupport for new platforms, languages and compilers.\n=======================================\n    - None\n\nBug Fixes since HDF5-1.10.1 release\n==================================\n\n    Library\n    -------\n    - The data read after a direct chunk write to a chunked dataset with\n      one chunk was incorrect.\n\n      The problem was due to the passing of a null dataset pointer to\n      the insert callback for the chunk index in the routine\n      H5D__chunk_direct_write() in H5Dchunk.c\n      The dataset was a single-chunked dataset which will use the\n      single chunk index when latest format was enabled on file creation.\n      The single chunk index was the only index that used this pointer\n      in the insert callback.\n\n      Passed the dataset pointer to the insert callback for the chunk\n      index in H5D__chunk_direct_write().\n\n      (VC - 2018/03/20, HDFFV-10425)\n\n    - Added public routine H5DOread_chunk to the high-level C library.\n\n      The patch for H5DOwrite_chunk() to write an entire chunk to the file\n      directly was contributed by GE Healthcare and integrated by The HDF Group\n      developers.\n\n      (VC - 2017/05/19, HDFFV-9934)\n\n    - Freeing of object header after failed checksum verification.\n\n      It was discovered that the object header (in H5Ocache.c) was not released properly\n      when the checksum verification failed and a re-load of the object\n      header was needed.\n\n      Freed the object header that failed the chksum verification only\n      after the new object header is reloaded, deserialized and set up.\n\n      (VC - 2018/03/14, HDFFV-10209)\n\n    - Updated H5Pset_evict_on_close in H5Pfapl.c\n\n      Changed the minor error number from H5E_CANTSET to H5E_UNSUPPORTED for\n      parallel library.\n\n      (ADB - 2018/03/06, HDFFV-10414)\n\n    - Fixed the problems with the utility function that could not handle lowercase\n      Windows drive letters.\n\n      Added call to upper function for drive letter.\n\n      (ADB - 2017/12/18, HDFFV-10307)\n\n    - Fixed H5Sencode() bug when the number of elements selected was > 2^32.\n\n      H5Sencode() incorrectly encodes dataspace selection with number of\n      elements exceeding 2^32.  When decoding such selection via H5Sdecode(),\n      the number of elements in the decoded dataspace is not the same as\n      what is encoded.  This problem exists for H5S_SEL_HYPER and\n      H5S_SEL_POINTS encoding.\n\n      The cause of the problem is due to the fact that the library uses 32 bits to\n      encode counts and block offsets for the selection.\n      The solution is to use the original 32 bit encodings if possible,\n      but use a different way to encode selection if more that 32 bits is needed.\n      See details in the RFC: H5Sencode/H5Sdecode Format Change i\n      https://bitbucket.hdfgroup.org/projects/HDFFV/repos/hdf5doc/browse/RFCs/HDF5_Library/H5SencodeFormatChange.\n\n      (VC - 2017/11/28, HDFFV-9947)\n\n    - Fixed filter plugin handling in H5PL.c and H5Z.c to not require i availability of\n      dependent libraries (e.g., szip or zlib).\n\n      It was discovered that the dynamic loading process used by\n      filter plugins had issues with library dependencies.\n\n      CMake build process changed to use LINK INTERFACE keywords, which\n      allowed HDF5 C library to make dependent libraries private. The\n      filter plugin libraries no longer require dependent libraries\n      (such as szip or zlib) to be available.\n\n      (ADB - 2017/11/16, HDFFV-10328)\n\n    - Fixed rare object header corruption bug.\n\n      In certain cases, such as when converting large attributes to dense\n      storage, an error could occur which would either fail an assertion or\n      cause file corruption. Fixed and added test.\n\n      (NAF - 2017/11/14, HDFFV-10274)\n\n    - Updated H5Zfilter_avail in H5Z.c.\n\n      The public function checked for plugins, while the private\n      function did not.\n\n      Modified H5Zfilter_avail and private function, H5Z_filter_avail.\n      Moved check for plugin from public to private function. Updated\n      H5P__set_filter due to change in H5Z_filter_avail. Updated tests.\n\n      (ADB - 2017/10/10, HDFFV-10297, HDFFV-10319)\n\n    - h5dump produced SEGFAULT when dumping corrypted file.\n\n      The behavior was due to the error in the internal function H5HL_offset_into().\n\n      (1) Fixed H5HL_offset_into() to return error when offset exceeds heap data\n          block size.\n      (2) Fixed other places in the library that call this routine to detect\n          error routine.\n\n      (VC - 2017/08/30, HDFFV-10216)\n\n    - Fixes for paged aggregation feature.\n\n      Skip test in test/fheap.c when:\n      (1) multi/split drivers and\n      (2) persisting free-space or using paged aggregation strategy\n\n      (VC, 2017/07/10)\n\n      Changes made based on RFC review comments:\n      (1) Added maximum value for file space page size\n      (2) Dropped check for page end metadata threshold\n      (3) Removed \"can_shrink\" and \"shrink\" callbacks for small section class\n\n      (VC - 2017/06/09)\n\n    - Fixed for infinite loop in H5VM_power2up().\n\n      The function H5VM_power2up() returns the next power of 2\n      for n. When n exceeds 2^63, it overflows and becomes 0 causing\n      the infinite looping.\n\n      The fix ensures that the function checks for n >= 2^63\n      and returns 0.\n\n      (VC - 2017/07/10, HDFFV-10217)\n\n    - Fixed for H5Ocopy doesn't work with open identifiers.\n\n      Changes made so that raw data for dataset objects are copied from\n      cached info when possible instead of flushing objects to file and\n      read them back in again.\n\n      (VC - 2017/07/05, HDFFV-7853)\n\n    - An uninitialized struct could cause a memory access error when using\n      variable-length or reference types in a compressed, chunked dataset.\n\n      A struct containing a callback function pointer and a pointer to some\n      associated data was used before initialization. This could cause a\n      memory access error and system crash. This could only occur under\n      unusual conditions when using variable-lenth and reference types in\n      a compressed, chunked dataset.\n\n      On recent versions of Visual Studio, when built in debug mode, the\n      debug heap will complain and cause a crash if the code in question\n      is executed (this will cause the objcopy test to fail).\n\n      (DER - 2017/11/21, HDFFV-10330)\n\n    - Fixed collective metadata writes on file close.\n\n      It was discovered that metadata was being written twice as part of\n      the parallel file close behavior, once independently and once\n      collectively.\n\n      A fix for this error was included as part of the parallel compression\n      feature but remained undocumented here.\n\n      (RAW - 2017/12/01, HDFFV-10272)\n\n    - If an HDF5 file contains a filter pipeline message with a 'number of\n      filters' field that exceeds the maximum number of allowed filters,\n      the error handling code will attempt to dereference a NULL pointer.\n\n      This issue was reported to The HDF Group as issue #CVE-2017-17505.\n          https://security-tracker.debian.org/tracker/CVE-2017-17505\n          https://cve.mitre.org/cgi-bin/cvename.cgi?name=3DCVE-2017-17505\n\n      NOTE: The HDF5 C library cannot produce such a file. This condition\n            should only occur in a corrupt (or deliberately altered) file\n            or a file created by third-party software.\n\n      This problem arose because the error handling code assumed that\n      the 'number of filters' field implied that a dynamic array of that\n      size had already been created and that the cleanup code should\n      iterate over that array and clean up each element's resources. If\n      an error occurred before the array has been allocated, this will\n      not be true.\n\n      This has been changed so that the number of filters is set to\n      zero on errors. Additionally, the filter array traversal in the\n      error handling code now requires that the filter array not be NULL.\n\n      (DER - 2018/02/06, HDFFV-10354)\n\n    - If an HDF5 file contains a filter pipeline message which contains\n      a 'number of filters' field that exceeds the actual number of\n      filters in the message, the HDF5 C library will read off the end of\n      the read buffer.\n\n      This issue was reported to The HDF Group as issue #CVE-2017-17506.\n          https://security-tracker.debian.org/tracker/CVE-2017-17506\n          https://cve.mitre.org/cgi-bin/cvename.cgi?name=3DCVE-2017-17506\n\n      NOTE: The HDF5 C library cannot produce such a file. This condition\n            should only occur in a corrupt (or deliberately altered) file\n            or a file created by third-party software.\n\n      The problem was fixed by passing the buffer size with the buffer\n      and ensuring that the pointer cannot be incremented off the end\n      of the buffer. A mismatch between the number of filters declared\n      and the actual number of filters will now invoke normal HDF5\n      error handling.\n\n      (DER - 2018/02/26, HDFFV-10355)\n\n    - If an HDF5 file contains a malformed compound datatype with a\n      suitably large offset, the type conversion code can run off\n      the end of the type conversion buffer, causing a segmentation\n      fault.\n\n      This issue was reported to The HDF Group as issue #CVE-2017-17507.\n          https://security-tracker.debian.org/tracker/CVE-2017-17506\n          https://cve.mitre.org/cgi-bin/cvename.cgi?name=3DCVE-2017-17506\n\n      NOTE: The HDF5 C library cannot produce such a file. This condition\n            should only occur in a corrupt (or deliberately altered) file\n            or a file created by third-party software.\n\n      THE HDF GROUP WILL NOT FIX THIS BUG AT THIS TIME\n\n      Fixing this problem would involve updating the publicly visible\n      H5T_conv_t function pointer typedef and versioning the API calls\n      which use it. We normally only modify the public API during\n      major releases, so this bug will not be fixed at this time.\n\n      (DER - 2018/02/26, HDFFV-10356)\n\n    - If an HDF5 file contains a malformed compound type which contains\n      a member of size zero, a division by zero error will occur while\n      processing the type.\n\n      This issue was reported to The HDF Group as issue #CVE-2017-17508.\n          https://security-tracker.debian.org/tracker/CVE-2017-17508\n          https://cve.mitre.org/cgi-bin/cvename.cgi?name=3DCVE-2017-17508\n\n      NOTE: The HDF5 C library cannot produce such a file. This condition\n            should only occur in a corrupt (or deliberately altered) file\n            or a file created by third-party software.\n\n      Checking for zero before dividing fixes the problem. Instead of the\n      division by zero, the normal HDF5 error handling is invoked.\n\n      (DER - 2018/02/26, HDFFV-10357)\n\n    - If an HDF5 file contains a malformed symbol table node that declares\n      it contains more symbols than it actually contains, the library\n      can run off the end of the metadata cache buffer while processing\n      the symbol table node.\n\n      This issue was reported to The HDF Group as issue #CVE-2017-17509.\n          https://security-tracker.debian.org/tracker/CVE-2017-17509\n          https://cve.mitre.org/cgi-bin/cvename.cgi?name=3DCVE-2017-17509\n\n      NOTE: The HDF5 C library cannot produce such a file. This condition\n            should only occur in a corrupt (or deliberately altered) file\n            or a file created by third-party software.\n\n      Performing bounds checks on the buffer while processing fixes the\n      problem. Instead of the segmentation fault, the normal HDF5 error\n      handling is invoked.\n\n      (DER - 2018/03/12, HDFFV-10358)\n\n    - Fixed permissions passed to open(2) on file create.\n\n      On Windows, the POSIX permissions passed to open(2) when creating files\n      were only incidentally correct. They are now set to the correct value of\n      (_S_IREAD | _S_IWRITE).\n\n      On other platforms, the permissions were set to a mix of 666, 644, and\n      000. They are now set uniformly to 666.\n\n      (DER - 2017/04/28, HDFFV-9877)\n\n    - The H5FD_FEAT_POSIX_COMPAT_HANDLE flag is no longer used to determine\n      if a virtual file driver (VFD) is compatible with SWMR.\n\n      Use of this VFD feature flag was not in line with the documentation in\n      the public H5FDpublic.h file. In particular, it was being used as a\n      proxy for determining if SWMR I/O is allowed. This is unecessary as we\n      already have a feature flag for this (H5FD_SUPPORTS_SWMR_IO).\n\n      (DER - 2017/05/31, HDFFV-10214)\n\n\n    Configuration\n    -------------\n    - CMake changes\n\n       - Updated CMake commands configuration.\n\n      A number of improvements were made to the CMake commands. Most\n      changes simplify usage or eliminate unused constructs. Also,\n      some changes support better cross-platform support.\n\n      (ADB - 2018/02/01, HDFFV-10398)\n\n       - Corrected usage of CMAKE_BUILD_TYPE variable.\n\n      The use of the CMAKE_BUILD_TYPE is incorrect for multi-config\n      generators (Visual Studio and XCode) and is optional for single\n      config generators. Created a new macro to check\n        GLOBAL PROPERTY -> GENERATOR_IS_MULTI_CONFIG\n      Created two new HDF variable, HDF_BUILD_TYPE and HDF_CFG_BUILD_TYPE.\n      Defaults for these variables is \"Release\".\n\n      (ADB - 2018/01/10, HDFFV-10385)\n\n       - Added replacement of fortran flags if using static CRT.\n\n      Added TARGET_STATIC_CRT_FLAGS call to HDFUseFortran.cmake file in\n      config/cmake_ext_mod folder.\n\n      (ADB - 2018/01/08, HDFFV-10334)\n\n\n       - The hdf5 library used shared szip and zlib, which needlessly required\n      applications to link with the same szip and zlib libraries.\n\n      Changed the target_link_libraries commands to use the static libs.\n      Removed improper link duplication of szip and zlib.\n      Adjusted the link dependencies and the link interface values of\n      the target_link_libraries commands.\n\n      (ADB - 2017/11/14, HDFFV-10329)\n\n    - CMake MPI\n\n      CMake implementation for MPI was problematic and would create incorrect\n      MPI library references in the hdf5 libraries.\n\n      Reworked the CMake MPI code to properly create CMake targets. Also merged\n      the latest CMake FindMPI.cmake changes to the local copy. This is necessary\n      until HDF changes the CMake minimum to 3.9 or greater.\n\n      (ADB - 2017/11/02, HDFFV-10321)\n\n    - Corrected FORTRAN_HAVE_C_LONG_DOUBLE processing in the autotools.\n\n      A bug in the autotools Fortran processing code always set the\n      FORTRAN_HAVE_C_LONG_DOUBLE variable to be true regardless of\n      whether or not a C long double type was present.\n\n      This would cause compilation failures on platforms where a C\n      long double type was not available and the Fortran wrappers\n      were being built.\n\n      (DER - 2017/07/05, HDFFV-10247)\n\n    - The deprecated --enable-production and --enable-debug configure options\n      failed to emit errors when passed an empty string\n      (e.g.: --enable-debug=\"\").\n\n      Due to the way we checked for these options being set, it was possible\n      to avoid the error message and continue configuration if an empty string\n      was passed to the option.\n\n      Any use of --enable-production or --enable-debug will now halt the\n      configuration step and emit a helpful error message\n      (use --enable-build-mode=debug|production instead).\n\n      (DER - 2017/07/05, HDFFV-10248)\n\n    - CMake\n\n      Too many commands for POST_BUILD step caused command line to be\n      too big on windows.\n\n      Changed foreach of copy command to use a custom command with the\n      use of the HDFTEST_COPY_FILE macro.\n\n      (ADB - 2017/07/12, HDFFV-10254)\n\n    - CMake test execution environment\n\n      The parallel HDF5 test: 't_pread' assumed the use of autotools\n      and the directory structure associated with that testing approach.\n      Modified the test code to check whether the 'h5jam' utility can be\n      found in the same directory as the test executable (which is\n      preferred directory structure utilized by cmake) and if found\n      will invoke the tool directly rather than utilizing a relative path.\n\n      (RAW - 2017/11/03, HDFFV-10318)\n\n    - Fortran compilation fails for xlf and CMake builds.\n\n      Fixed CMake shared library build for H5match_types and modules\n\n      (MSB - 2017/12/19, HDFFV-10363)\n\n    - Shared libraries fail test on OSX with Fortran enabled with CMake.\n\n      Fixed by removing the F77 use of EQUIVALENCE and COMMON, replaced\n      using MODULES. Updated CMake.\n\n      (MSB - 2017/12/07, HDFFV-10223)\n\n    - The bin/trace script now emits an error code on problems and autogen.sh\n      will fail if bin/trace fails.\n\n      The bin/trace script adds tracing functionality to public HDF5 API calls.\n      It is only of interest to developers who modify the HDF5 source code.\n      Previously, bin/trace just wrote an error message to stdout when it\n      encountered problems, so autogen.sh processing did not halt and a broken\n      version of the library could be built. The script will now return an\n      error code when it encounters problems, and autogen.sh will fail.\n\n      This only affects users who run autogen.sh to rebuild the Autotools files,\n      which is not necessary to build HDF5 from source in official releases of the\n      library. CMake users are unaffected as bin/trace is not run via CMake\n      at this time.\n\n      (DER - 2017/04/25, HDFFV-10178)\n\n    - FC_BASENAME was changed from gfortran40 to gfortran in a few places.\n\n      In the autotools, FC_BASENAME was set to gfortran40 in a few locations\n      (config/gnu-fflags and config/freebsd). This was probably a historical\n      artifact and did not seem to affect many users.\n\n      The value is now correctly set to gfortran.\n\n      (DER - 2017/05/26, HDFFV-10249)\n\n    - The ar flags were changed to -cr (was: -cru)\n\n      The autotools set the flags for ar to -cru by default. The -u flag,\n      which allows selective replacement of only the members which have\n      changed, raises warnings on some platforms, so the flags are now set to\n      -cr via AR_FLAGS in configure.ac. This causes the static library to\n      always be completely recreated from the object files on each build.\n\n      (DER - 2017/11/15, HDFFV-10428)\n\n\n    Fortran\n    --------\n    - Fixed compilation errors when using Intel 18 Fortran compilers\n      (MSB - 2017/11/3, HDFFV-10322)\n\n    Tools\n    -----\n    - h5clear\n\n      An enhancement to the tool in setting a file's stored EOA.\n\n      It was discovered that a crashed file's stored EOA in the superblock\n      was smaller than the actual file's EOF.  When the file was reopened\n      and closed, the library truncated the file to the stored EOA.\n\n      Added an option to the tool in setting the file's stored EOA in the\n      superblock to the maximum of (EOA, EOF) + increment.\n      An option was also added to print the file's EOA and EOF.\n\n      (VC - 2018/03/14, HDFFV-10360)\n\n    - h5repack\n\n      h5repack changes the chunk parameters when a change of layout is not\n      specified and a filter is applied.\n\n      HDFFV-10297, HDFFV-10319 reworked code for h5repack and h5diff code\n      in the tools library. The check for an existing layout was incorrectly\n      placed into an if block and not executed. The check was moved into\n      the normal path of the function.\n\n      (ADB - 2018/02/21, HDFFV-10412)\n\n    - h5dump\n\n      The tools library will hide the error stack during file open.\n\n      While this is preferable almost always, there are reasons to enable\n      display of the error stack when a tool will not open a file. Adding an\n      optional argument to the --enable-error-stack will provide this use case.\n      As an optional argument it will not affect the operation of the\n      --enable-error-stack. h5dump is the only tool to implement this change.\n\n      (ADB - 2018/02/15, HDFFV-10384)\n\n    - h5dump\n\n      h5dump would output an indented blank line in the filters section.\n\n      h5dump overused the h5tools_simple_prefix function, which is a\n      function intended to account for the data index (x,y,z) option.\n      Removed the function call for header information.\n\n      (ADB - 2018/01/25, HDFFV-10396)\n\n    - h5repack\n\n      h5repack incorrectly searched internal object table for name.\n\n      h5repack would search the table of objects for a name, if the\n      name did not match it tried to determine if the name without a\n      leading slash would match. The logic was flawed! The table\n      stored names(paths) without a leading slash and did a strstr\n      of the table path to the name.\n      The assumption was that if there was a difference of one then\n      it was a match, however \"pressure\" would match \"/pressure\" as\n      well as \"/pressure1\", \"/pressure2\", etc. Changed logic to remove\n      any leading slash and then do a full compare of the name.\n\n      (ADB - 2018/01/18, HDFFV-10393)\n\n    - h5repack\n\n      h5repack failed to handle command line parameters for customer filters.\n\n      User defined filter parameter conversions would fail when integers were\n      represented on the command line with character string\n      larger then 9 characters. Increased local variable array for storing\n      the current command line parameter to prevent buffer overflows.\n\n      (ADB - 2018/01/17, HDFFV-10392)\n\n    - h5diff\n\n      h5diff seg faulted if comparing VL strings against fixed strings.\n\n      Reworked solution for HDFFV-8625 and HDFFV-8639. Implemented the check\n      for string objects of same type in the diff_can_type function by\n      adding an if(tclass1 == H5T_STRING) block. This \"if block\" moves the\n      same check that was added for attributes to this function, which is\n      used by all object types. This function handles complex type structures.\n      Also added a new test file in h5diffgenttest for testing this issue\n      and removed the temporary files used in the test scripts.\n\n      (ADB - 2018/01/04, HDFFV-8745)\n\n    - h5repack\n\n      h5repack failed to copy a dataset with existing filter.\n\n      Reworked code for h5repack and h5diff code in the tools library. Added\n      improved error handling, cleanup of resources and checks of calls.\n      Modified H5Zfilter_avail and private function, H5Z_filter_avail.\n      Moved check for plugin from public to private function. Updated\n      H5P__set_filter due to change in H5Z_filter_avail. Updated tests.\n      Note, h5repack output display has changed to clarify the individual\n      steps of the repack process. The output indicates if an operation\n      applies to all objects. Lines with notation and no information\n      have been removed.\n\n      (ADB - 2017/10/10, HDFFV-10297, HDFFV-10319)\n\n    - h5repack\n\n      h5repack always set the User Defined filter flag to H5Z_FLAG_MANDATORY.\n\n      Added another parameter to the 'UD=' option to set the flag by default\n      to '0' or H5Z_FLAG_MANDATORY, the other choice is '1' or H5Z_FLAG_OPTIONAL.\n\n      (ADB - 2017/08/31, HDFFV-10269)\n\n    - h5ls\n\n      h5ls generated error on stack when it encountered a H5S_NULL\n      dataspace.\n\n      Adding checks for H5S_NULL before calling H5Sis_simple (located\n      in the h5tools_dump_mem function) fixed the issue.\n\n      (ADB - 2017/08/17, HDFFV-10188)\n\n    - h5repack\n\n      Added tests to h5repack.sh.in to verify options added for paged\n      aggregation work as expected.\n\n      (VC - 2017/08/03)\n\n    - h5dump\n\n      h5dump segfaulted on output of XML file.\n\n      Function that escape'd strings used the full buffer length\n      instead of just the length of the replacement string in a\n      strncpy call. Using the correct length fixed the issue.\n\n      (ADB - 2017/08/01, HDFFV-10256)\n\n    - h5diff\n\n      h5diff segfaulted on compare of a  NULL variable length string.\n\n      Improved h5diff compare of strings by adding a check for\n      NULL strings and setting the lengths to zero.\n\n      (ADB - 2017/07/25, HDFFV-10246)\n\n    - h5import\n\n      h5import crashed trying to import data from a subset of a dataset.\n\n      Improved h5import by adding the SUBSET keyword. h5import understands\n      to use the Count times the Block as the size of the dimensions.\n      Added INPUT_B_ORDER keyword to old-style configuration files.\n      The import from h5dump function expects the binary files to use native\n      types (FILE '-b' option) in the binary file.\n\n      (ADB - 2017/06/15, HDFFV-10219)\n\n    - h5repack\n\n      h5repack did not maintain the creation order flag of the root\n      group.\n\n      Improved h5repack by reading the creation order and applying the\n      flag to the new root group. Also added arguments to set the\n      order and index direction, which applies to the traversing of the\n      original file, on the command line.\n\n      (ADB - 2017/05/26, HDFFV-8611)\n\n    - h5diff\n\n      h5diff failed to account for strpad type and null terminators\n      of char strings. Also, h5diff failed to account for string length\n      differences and would give a different result depending on file\n      order in the command line.\n\n      Improved h5diff compare of strings and arrays by adding a check for\n      string lengths and if the strpad was null filled.\n\n      (ADB - 2017/05/18, HDFFV-9055, HDFFV-10128)\n\n    High-Level APIs:\n    ------\n    - H5DOwrite_chunk() problems when overwriting an existing chunk with\n      no filters enabled.\n\n      When overwriting chunks and no filters were being used, the library would\n      fail (when asserts are enabled, e.g. debug builds) or incorrectly\n      insert additional chunks instead of overwriting (when asserts are not\n      enabled, e.g. production builds).\n\n      This has been fixed and a test was added to the hl/test_dset_opt test.\n\n      (DER - 2017/05/11, HDFFV-10187)\n\n    C++ APIs\n    --------\n    - Removal of memory leaks.\n\n      A private function was inadvertently called, causing memory leaks.  This\n      is now fixed.\n\n      (BMR - 2018/03/12 - User's reported in email)\n\n    Testing\n    -------\n    - Memory for three variables in testphdf5's coll_write_test was malloced\n      but not freed, leaking memory when running the test.\n\n      The variables' memory is now freed.\n\n      (LRK - 2018/03/12, HDFFV-10397)\n\n    - Refactored the testpar/t_bigio.c test to include ALARM macros\n\n      Changed the test to include the ALARM_ON and ALARM_OFF macros which\n      are intended to prevent nightly test hangs that have been observed\n      with this particular parallel test example.  The code was also modified to\n      simplify status reporting (only from MPI rank 0) and additional\n      status checking added.\n\n      (RAW - 2017/11/08, HDFFV-10301)\n\n\nSupported Platforms\n===================\n\n    Linux 2.6.32-696.16.1.el6.ppc64 gcc (GCC) 4.4.7 20120313 (Red Hat 4.4.7-18)\n    #1 SMP ppc64 GNU/Linux        g++ (GCC) 4.4.7 20120313 (Red Hat 4.4.7-18)\n    (ostrich)                     GNU Fortran (GCC) 4.4.7 20120313 (Red Hat 4.4.7-18)\n                                  IBM XL C/C++ V13.1\n                                  IBM XL Fortran V15.1\n\n    Linux 3.10.0-327.10.1.el7   GNU C (gcc), Fortran (gfortran), C++ (g++)\n    #1 SMP x86_64 GNU/Linux       compilers:\n    (kituo/moohan)                Version 4.8.5 20150623 (Red Hat 4.8.5-4)\n                                    Version 4.9.3, Version 5.2.0,\n                                  Intel(R) C (icc), C++ (icpc), Fortran (icc)\n                                  compilers:\n                                     Version 17.0.0.098 Build 20160721\n                                  MPICH 3.1.4 compiled with GCC 4.9.3\n\n    SunOS 5.11 32- and 64-bit     Sun C 5.12 SunOS_sparc\n    (emu)                         Sun Fortran 95 8.6 SunOS_sparc\n                                  Sun C++ 5.12 SunOS_sparc\n\n    Windows 7                     Visual Studio 2012 w/ Intel Fortran 15 (cmake)\n                                  Visual Studio 2013 w/ Intel Fortran 15 (cmake)\n                                  Visual Studio 2015 w/ Intel Fortran 16 (cmake)\n\n    Windows 7 x64                 Visual Studio 2012 w/ Intel Fortran 15 (cmake)\n                                  Visual Studio 2013 w/ Intel Fortran 15 (cmake)\n                                  Visual Studio 2015 w/ Intel Fortran 16 (cmake)\n                                  Visual Studio 2015 w/ Intel C, Fortran 2017 (cmake)\n                                  Visual Studio 2015 w/ MSMPI 8 (cmake)\n                                  Cygwin(CYGWIN_NT-6.1 2.8.0(0.309/5/3)\n                                      gcc and gfortran compilers (GCC 5.4.0)\n                                      (cmake and autotools)\n\n    Windows 10                    Visual Studio 2015 w/ Intel Fortran 16 (cmake)\n                                  Cygwin(CYGWIN_NT-6.1 2.8.0(0.309/5/3)\n                                      gcc and gfortran compilers (GCC 5.4.0)\n                                      (cmake and autotools)\n\n    Windows 10 x64                Visual Studio 2015 w/ Intel Fortran 16 (cmake)\n\n    Mac OS X Yosemite 10.10.5     Apple clang/clang++ version 6.1 from Xcode 7.0\n    64-bit                        gfortran GNU Fortran (GCC) 4.9.2\n    (osx1010dev/osx1010test)      Intel icc/icpc/ifort version 15.0.3\n\n    Mac OS X El Capitan 10.11.6   Apple clang/clang++ version 7.3.0 from Xcode 7.3\n    64-bit                        gfortran GNU Fortran (GCC) 5.2.0\n    (osx1011dev/osx1011test)      Intel icc/icpc/ifort version 16.0.2\n\n    Mac OS Sierra 10.12.6         Apple LLVM version 8.1.0 (clang/clang++-802.0.42)\n    64-bit                        gfortran GNU Fortran (GCC) 7.1.0\n    (swallow/kite)                Intel icc/icpc/ifort version 17.0.2\n\n\nTested Configuration Features Summary\n=====================================\n\n    In the tables below\n          y   = tested\n          n   = not tested in this release\n          C   = Cluster\n          W   = Workstation\n          x   = not working in this release\n          dna = does not apply\n          ( ) = footnote appears below second table\n          <blank> = testing incomplete on this feature or platform\n\nPlatform                              C         F90/   F90      C++  zlib  SZIP\n                                      parallel  F2003  parallel\nSolaris2.11 32-bit                      n        y/y    n        y    y     y\nSolaris2.11 64-bit                      n        y/n    n        y    y     y\nWindows 7                               y        y/y    n        y    y     y\nWindows 7 x64                           y        y/y    y        y    y     y\nWindows 7 Cygwin                        n        y/n    n        y    y     y\nWindows 7 x64 Cygwin                    n        y/n    n        y    y     y\nWindows 10                              y        y/y    n        y    y     y\nWindows 10 x64                          y        y/y    n        y    y     y\nMac OS X Mountain Lion 10.8.5 64-bit    n        y/y    n        y    y     y\nMac OS X Mavericks 10.9.5 64-bit        n        y/y    n        y    y     y\nMac OS X Yosemite 10.10.5 64-bit        n        y/y    n        y    y     y\nMac OS X El Capitan 10.11.6 64-bit      n        y/y    n        y    y     y\nCentOS 7.2 Linux 2.6.32 x86_64 PGI      n        y/y    n        y    y     y\nCentOS 7.2 Linux 2.6.32 x86_64 GNU      y        y/y    y        y    y     y\nCentOS 7.2 Linux 2.6.32 x86_64 Intel    n        y/y    n        y    y     y\nLinux 2.6.32-573.18.1.el6.ppc64         n        y/y    n        y    y     y\n\n\nPlatform                                 Shared  Shared    Shared    Thread-\n                                         C libs  F90 libs  C++ libs  safe\nSolaris2.11 32-bit                         y       y         y         y\nSolaris2.11 64-bit                         y       y         y         y\nWindows 7                                  y       y         y         y\nWindows 7 x64                              y       y         y         y\nWindows 7 Cygwin                           n       n         n         y\nWindows 7 x64 Cygwin                       n       n         n         y\nWindows 10                                 y       y         y         y\nWindows 10 x64                             y       y         y         y\nMac OS X Mountain Lion 10.8.5 64-bit       y       n         y         y\nMac OS X Mavericks 10.9.5 64-bit           y       n         y         y\nMac OS X Yosemite 10.10.5 64-bit           y       n         y         y\nMac OS X El Capitan 10.11.6 64-bit         y       n         y         y\nCentOS 7.2 Linux 2.6.32 x86_64 PGI         y       y         y         n\nCentOS 7.2 Linux 2.6.32 x86_64 GNU         y       y         y         y\nCentOS 7.2 Linux 2.6.32 x86_64 Intel       y       y         y         n\nLinux 2.6.32-573.18.1.el6.ppc64            y       y         y         n\n\nCompiler versions for each platform are listed in the preceding\n\"Supported Platforms\" table.\n\n\nMore Tested Platforms\n=====================\nThe following platforms are not supported but have been tested for this release.\n\n    Linux 2.6.32-573.22.1.el6    GNU C (gcc), Fortran (gfortran), C++ (g++)\n    #1 SMP x86_64 GNU/Linux       compilers:\n    (mayll/platypus)                 Version 4.4.7 20120313\n                                     Version 4.9.3, 5.3.0, 6.2.0\n                                  PGI C, Fortran, C++ for 64-bit target on\n                                  x86-64;\n                                      Version 17.10-0\n                                  Intel(R) C (icc), C++ (icpc), Fortran (icc)\n                                  compilers:\n                                     Version 17.0.4.196 Build 20170411\n                                  MPICH 3.1.4 compiled with GCC 4.9.3\n\n    Linux 3.10.0-327.18.2.el7     GNU C (gcc) and C++ (g++) compilers\n    #1 SMP x86_64 GNU/Linux          Version 4.8.5 20150623 (Red Hat 4.8.5-4)\n    (jelly)                       with NAG Fortran Compiler Release 6.1(Tozai)\n                                  GCC Version 7.1.0\n                                  OpenMPI 3.0.0-GCC-7.2.0-2.29\n                                  Intel(R) C (icc) and C++ (icpc) compilers\n                                     Version 17.0.0.098 Build 20160721\n                                  with NAG Fortran Compiler Release 6.1(Tozai)\n\n    Linux 3.10.0-327.10.1.el7     MPICH 3.2 compiled with GCC 5.3.0\n    #1 SMP x86_64 GNU/Linux\n    (moohan)\n\n    Linux 2.6.32-573.18.1.el6.ppc64  MPICH mpich 3.1.4 compiled with\n    #1 SMP ppc64 GNU/Linux           IBM XL C/C++ for Linux, V13.1\n    (ostrich)                        and IBM XL Fortran for Linux, V15.1\n\n    Debian 8.4 3.16.0-4-amd64 #1 SMP Debian 3.16.36-1 x86_64 GNU/Linux\n                                  gcc, g++ (Debian 4.9.2-10) 4.9.2\n                                  GNU Fortran (Debian 4.9.2-10) 4.9.2\n                                  (cmake and autotools)\n\n    Fedora 24  4.7.2-201.fc24.x86_64 #1 SMP x86_64 x86_64 x86_64 GNU/Linux\n                                  gcc, g++ (GCC) 6.1.1 20160621\n                                      (Red Hat 6.1.1-3)\n                                  GNU Fortran (GCC) 6.1.1 20160621\n                                      (Red Hat 6.1.1-3)\n                                  (cmake and autotools)\n\n    Ubuntu 16.04.1 4.4.0-38-generic #57-Ubuntu SMP x86_64 GNU/Linux\n                                  gcc, g++ (Ubuntu 5.4.0-6ubuntu1~16.04.2)\n                                      5.4.0 20160609\n                                  GNU Fortran (Ubuntu 5.4.0-6ubuntu1~16.04.2)\n                                      5.4.0 20160609\n                                  (cmake and autotools)\n\n\nKnown Problems\n==============\n\n    At present, metadata cache images may not be generated by parallel\n    applications.  Parallel applications can read files with metadata cache\n    images, but since this is a collective operation, a deadlock is possible\n    if one or more processes do not participate.\n\n    Three tests fail with OpenMPI 3.0.0/GCC-7.2.0-2.29:\n        testphdf5 (ecdsetw, selnone, cchunk1, cchunk3, cchunk4, and actualio)\n        t_shapesame (sscontig2)\n        t_pflush1/fails on exit\n    The first two tests fail attempting collective writes.\n\n    Known problems in previous releases can be found in the HISTORY*.txt files\n    in the HDF5 source. Please report any new problems found to\n    help@hdfgroup.org.\n\n\n%%%%1.10.1%%%%\n\nHDF5 version 1.10.1 released on 2017-04-27\n================================================================================\n\nINTRODUCTION\n\nThis document describes the differences between HDF5-1.10.0-patch1 and\nHDF5 1.10.1, and contains information on the platforms tested and known\nproblems in HDF5-1.10.1. For more details check the HISTORY*.txt files\nin the HDF5 source.\n\nLinks to HDF5 1.10.1 source code, documentation, and additional materials can\nbe found on The HDF5 web page at:\n\n     https://support.hdfgroup.org/HDF5/\n\nThe HDF5 1.10.1 release can be obtained from:\n\n     https://support.hdfgroup.org/HDF5/release/obtain5.html\n\nUser documentation for the snapshot can be accessed directly at this location:\n\n     https://support.hdfgroup.org/HDF5/doc/\n\nNew features in the HDF5-1.10.x release series, including brief general\ndescriptions of some new and modified APIs, are described in the \"New Features\nin HDF5 Release 1.10\" document:\n\n     https://support.hdfgroup.org/HDF5/docNewFeatures/index.html\n\nAll new and modified APIs are listed in detail in the \"HDF5 Software Changes\nfrom Release to Release\" document, in the section \"Release 10.1 (current\nrelease) versus Release 1.10.0\n\n     https://support.hdfgroup.org/HDF5/doc/ADGuide/Changes.html\n\nIf you have any questions or comments, please send them to the HDF Help Desk:\n\n    help@hdfgroup.org\n\n\nCONTENTS\n\n- Major New Features Introduced in HDF5 1.10.1\n- Other New Features and Enhancements\n- Support for New Platforms, Languages, and Compilers\n- Bug Fixes since HDF5-1.10.0-patch1\n- Supported Platforms\n- Tested Configuration Features Summary\n- More Tested Platforms\n- Known Problems\n\n\nMajor New Features Introduced in HDF5 1.10.1\n============================================\n\nFor links to the RFCs and documentation in this section please view\nhttps://support.hdfgroup.org/HDF5/docNewFeatures in a web browser.\n\n________________________________________\nMetadata Cache Image\n________________________________________\n\n    HDF5 metadata is typically small, and scattered throughout the HDF5 file.\n    This can affect performance, particularly on large HPC systems. The\n    Metadata Cache Image feature can improve performance by writing the\n    metadata cache in a single block on file close, and then populating the\n    cache with the contents of this block on file open, thus avoiding the many\n    small I/O operations that would otherwise be required on file open and\n    close. See the RFC for complete details regarding this feature. Also,\n    see the Fine Tuning the Metadata Cache documentation.\n\n    At present, metadata cache images may not be generated by parallel\n    applications.  Parallel applications can read files with metadata cache\n    images, but since this is a collective operation, a deadlock is possible\n    if one or more processes do not participate.\n\n________________________________________\nMetadata Cache Evict on Close\n________________________________________\n\n    The HDF5 library's metadata cache is fairly conservative about holding on\n    to HDF5 object metadata (object headers, chunk index structures, etc.),\n    which can cause the cache size to grow, resulting in memory pressure on\n    an application or system. The \"evict on close\" property will cause all\n    metadata for an object to be evicted from the cache as long as metadata\n    is not referenced from any other open object. See the Fine Tuning the\n    Metadata Cache documentation for information on the APIs.\n\n    At present, evict on close is disabled in parallel builds.\n\n________________________________________\nPaged Aggregation\n________________________________________\n\n    The current HDF5 file space allocation accumulates small pieces of metadata\n    and raw data in aggregator blocks which are not page aligned and vary\n    widely in sizes. The paged aggregation feature was implemented to provide\n    efficient paged access of these small pieces of metadata and raw data.\n    See the RFC for details. Also, see the File Space Management documentation.\n\n________________________________________\nPage Buffering\n________________________________________\n\n    Small and random I/O accesses on parallel file systems result in poor\n    performance for applications. Page buffering in conjunction with paged\n    aggregation can improve performance by giving an application control of\n    minimizing HDF5 I/O requests to a specific granularity and alignment.\n    See the RFC for details. Also, see the Page Buffering documentation.\n\n    At present, page buffering is disabled in parallel builds.\n\n\n\nOther New Features and Enhancements\n===================================\n\n    Library\n    -------\n    - Added a mechanism for disabling the SWMR file locking scheme.\n\n      The file locking calls used in HDF5 1.10.0 (including patch1)\n      will fail when the underlying file system does not support file\n      locking or where locks have been disabled. To disable all file\n      locking operations, an environment variable named\n      HDF5_USE_FILE_LOCKING can be set to the five-character string\n      'FALSE'. This does not fundamentally change HDF5 library\n      operation (aside from initial file open/create, SWMR is lock-free),\n      but users will have to be more careful about opening files\n      to avoid problematic access patterns (i.e.: multiple writers)\n      that the file locking was designed to prevent.\n\n      Additionally, the error message that is emitted when file lock\n      operations set errno to ENOSYS (typical when file locking has been\n      disabled) has been updated to describe the problem and potential\n      resolution better.\n\n      (DER, 2016/10/26, HDFFV-9918)\n\n    - The return type of H5Pget_driver_info() has been changed from void *\n      to const void *.\n\n      The pointer returned by this function points to internal library\n      memory and should not be freed by the user.\n\n      (DER, 2016/11/04, HDFFV-10017)\n\n    - The direct I/O VFD has been removed from the list of VFDs that\n      support SWMR.\n\n      This configuration was never officially tested and several SWMR\n      tests fail when this VFD is set.\n\n      (DER, 2016/11/03, HDFFV-10169)\n\n    Configuration:\n    --------------\n    - The minimum version of CMake required to build HDF5 is now 3.2.2.\n\n      (ADB, 2017/01/10)\n\n    - An --enable/disable-developer-warnings option has been added to\n      configure.\n\n      This disables warnings that do not indicate poor code quality such\n      as -Winline and gcc's -Wsuggest-attribute. Developer warnings are\n      disabled by default.\n\n      (DER, 2017/01/10)\n\n    - A bin/restore.sh script was added that reverts autogen.sh processing.\n\n      (DER, 2016/11/08)\n\n    - CMake: Added NAMESPACE hdf5:: to package configuration files to allow\n      projects using installed HDF5 binaries built with CMake to link with\n      them without specifying the HDF5 library location via IMPORTED_LOCATION.\n\n      (ABD, 2016/10/17, HDFFV-10003)\n\n    - CMake: Changed the CTEST_BUILD_CONFIGURATION option to\n      CTEST_CONFIGURATION_TYPE as recommended by the CMake documentation.\n\n      (ABD, 2016/10/17, HDFFV-9971)\n\n\n    Fortran Library:\n    ----------------\n\n    - The HDF5 Fortran library can now be compiled with the NAG compiler.\n\n      (MSB, 2017/2/10, HDFFV-9973)\n\n\n    C++ Library:\n    ------------\n\n    - The following C++ API wrappers have been added to the C++ Library:\n\n        // Sets/Gets the strategy and the threshold value that the library\n        // will employ in managing file space.\n        FileCreatPropList::setFileSpaceStrategy - H5Pset_file_space_strategy\n        FileCreatPropList::getFileSpaceStrategy - H5Pget_file_space_strategy\n\n        // Sets/Gets the file space page size for paged aggregation.\n        FileCreatPropList::setFileSpacePagesize - H5Pset_file_space_page_size\n        FileCreatPropList::getFileSpacePagesize - H5Pget_file_space_page_size\n\n        // Checks if the given ID is valid.\n        IdComponent::isValid - H5Iis_valid\n\n        // Sets/Gets the number of soft or user-defined links that can be\n        // traversed before a failure occurs.\n        LinkAccPropList::setNumLinks - H5Pset_nlinks\n        LinkAccPropList::getNumLinks - H5Pget_nlinks\n\n        // Returns a copy of the creation property list of a datatype.\n        DataType::getCreatePlist - H5Tget_create_plist\n\n        // Opens/Closes an object within a group or a file, regardless of object\n        // type\n        Group::getObjId - H5Oopen\n        Group::closeObjId - H5Oclose\n\n        // Maps elements of a virtual dataset to elements of the source dataset.\n        DSetCreatPropList::setVirtual - H5Pset_virtual\n\n        // Gets general information about this file.\n        H5File::getFileInfo - H5Fget_info2\n\n        // Returns the number of members in a type.\n        IdComponent::getNumMembers - H5Inmembers\n\n        // Determines if an element type exists.\n        IdComponent::typeExists - H5Itype_exists\n\n        // Determines if an object exists.\n        H5Location::exists - H5Lexists.\n\n        // Returns the header version of an HDF5 object.\n        H5Object::objVersion - H5Oget_info for version\n\n      (BMR, 2017/03/20, HDFFV-10004, HDFFV-10139, HDFFV-10145)\n\n    - New exception: ObjHeaderIException for H5O interface.\n\n      (BMR, 2017/03/15, HDFFV-10145)\n\n    - New class LinkAccPropList for link access property list, to be used by\n      wrappers of H5Lexists.\n\n      (BMR, 2017/01/04, HDFFV-10145)\n\n    - New constructors to open datatypes in ArrayType, CompType, DataType,\n      EnumType, FloatType, IntType, StrType, and VarLenType.\n\n      (BMR, 2016/12/26, HDFFV-10056)\n\n    - New member functions:\n\n        DSetCreatPropList::setNbit() to setup N-bit compression for a dataset.\n\n        ArrayType::getArrayNDims() const\n        ArrayType::getArrayDims() const\n        both to replace the non-const versions.\n\n      (BMR, 2016/04/25, HDFFV-8623, HDFFV-9725)\n\n\n    Tools:\n    ------\n     - The following options have been added to h5clear:\n       -s: clear the status_flags field in the file's superblock\n       -m: Remove the metadata cache image from the file\n\n       (QAK, 2017/03/22, PR#361)\n\n\n    High-Level APIs:\n    ---------------\n     - Added New Fortran 2003 API for h5tbmake_table_f.\n\n       (MSB, 2017/02/10, HDFFV-8486)\n\n\n\nSupport for New Platforms, Languages, and Compilers\n===================================================\n\n    - Added NAG compiler\n\n\n\nBug Fixes since HDF5-1.10.0-patch1 release\n==================================\n\n    Library\n    -------\n    - Outdated data structure was used in H5D_CHUNK_DEBUG blocks, causing\n      compilation errors when H5D_CHUNK_DEBUG was defined.  This is fixed.\n\n      (BMR, 2017/04/04, HDFFV-8089)\n\n    - SWMR implementation in the HDF5 1.10.0 and 1.10.0-patch1 releases has a\n      broken metadata flush dependency that manifested itself with the following\n      error at the end of the HDF5 error stack:\n\n      H5Dint.c line 846 in H5D__swmr_setup(): dataspace chunk index must be 0\n      for SWMR access, chunkno = 1\n      major: Dataset\n      minor: Bad value\n\n      It was also reported at https://github.com/areaDetector/ADCore/issues/203\n\n      The flush dependency is fixed in this release.\n\n    - Changed the plugins dlopen option from RTLD_NOW to RTLD_LAZY\n\n      (ABD, 2016/12/12, PR#201)\n\n    - A number of issues were fixed when reading/writing from/to corrupted\n      files to ensure that the library fails gracefully in these cases:\n\n      * Writing to a corrupted file that has an object message which is\n        incorrectly marked as sharable on disk results in a buffer overflow /\n        invalid write instead of a clean error message.\n\n      * Decoding data from a corrupted file with a dataset encoded with the\n        H5Z_NBIT decoding can result in a code execution vulnerability under\n        the context of the application using the HDF5 library.\n\n      * When decoding an array datatype from a corrupted file, the HDF5 library\n        fails to return an error in production if the number of dimensions\n        decoded is greater than the maximum rank.\n\n      * When decoding an \"old style\" array datatype from a corrupted file, the\n        HDF5 library fails to return an error in production if the number of\n        dimensions decoded is greater than the maximum rank.\n\n      (NAF, 2016/10/06, HDFFV-9950, HDFFV-9951, HDFFV-9992, HDFFV-9993)\n\n    - Fixed an error that would occur when copying an object with an attribute\n      which is a compound datatype consisting of a variable length string.\n\n      (VC, 2016/08/24, HDFFV-7991)\n\n    - H5DOappend will no longer fail if a dataset has no append callback\n      registered.\n\n      (VC, 2016/08/14, HDFFV-9960)\n\n    - Fixed an issue where H5Pset_alignment could result in misaligned blocks\n      with some input combinations, causing an assertion failure in debug mode.\n\n      (NAF, 2016/08/11, HDFFV-9948)\n\n    - Fixed a problem where a plugin compiled into a DLL in the default plugin\n      directory could not be found by the HDF5 library at runtime on Windows\n      when the HDF5_PLUGIN_PATH environment variable was not set.\n\n      (ABD, 2016/08/01, HDFFV-9706)\n\n    - Fixed an error that would occur when calling H5Adelete on an attribute\n      which is attached to an externally linked object in the target file and\n      whose datatype is a committed datatype in the main file.\n\n      (VC, 2016/07/06, HDFFV-9940)\n\n    - (a) Throw an error instead of assertion when v1 btree level hits the 1\n          byte limit.\n      (b) Modifications to better handle error recovery when conversion by\n          h5format_convert fails.\n\n      (VC, 2016/05/29, HDFFV-9434)\n\n    - Fixed a memory leak where an array used by the library to track SWMR\n      read retries was unfreed.\n\n      The leaked memory was small (on the order of a few tens of ints) and\n      allocated per-file. The memory was allocated (and lost) only when a\n      file was opened for SWMR access.\n\n      (DER, 2016/04/27, HDFFV-9786)\n\n    - Fixed a memory leak that could occur when opening a file for the first\n      time (including creating) and the call fails.\n\n      This occurred when the file-driver-specific info was not cleaned up.\n      The amount of memory leaked varied with the file driver, but would\n      normally be less than 1 kB.\n\n      (DER, 2016/12/06, HDFFV-10168)\n\n    - Fixed a failure in collective metadata writes.\n\n      This failure only appeared when collective metadata writes\n      were enabled (via H5Pset_coll_metadata_write()).\n\n      (JRM, 2017/04/10, HDFFV-10055)\n\n\n    Parallel Library\n    ----------------\n    - Fixed a bug that could occur when allocating a chunked dataset in parallel\n      with an alignment set and an alignment threshold greater than the chunk\n      size but less than or equal to the raw data aggregator size.\n\n      (NAF, 2016/08/11, HDFFV-9969)\n\n\n    Configuration\n    -------------\n    - Configuration will check for the strtoll and strtoull functions\n      before using alternatives\n\n      (ABD, 2017/03/17, PR#340)\n\n    - CMake uses a Windows pdb directory variable if available and\n      will generate both static and shared pdb files.\n\n      (ABD, 2017/02/06, HDFFV-9875)\n\n    - CMake now builds shared versions of tools.\n\n      (ABD, 2017/02/01, HDFFV-10123)\n\n    - Makefiles and test scripts have been updated to correctly remove files\n      created when running \"make check\" and to avoid removing any files under\n      source control.  In-source builds followed by \"make clean\" and \"make\n      distclean\" should result in the original source files.\n      (LRK, 2017/01/17, HDFFV-10099)\n\n    - The tools directory has been divided into two separate source and test\n      directories. This resolves a build dependency and, as a result,\n      'make check' will no longer fail in the tools directory if 'make' was\n      not executed first.\n\n      (ABD, 2016/10/27, HDFFV-9719)\n\n    - CMake: Fixed a timeout error that would occasionally occur when running\n      the virtual file driver tests simultaneously due to test directory\n      and file name collisions.\n\n      (ABD, 2016/09/19, HDFFV-9431)\n\n    - CMake: Fixed a command length overflow error by converting custom\n      commands inside CMakeTest.cmake files into regular dependencies and\n      targets.\n\n      (ABD, 2016/07/12, HDFFV-9939)\n\n    - Fixed a problem preventing HDF5 to be built on 32-bit CYGWIN by\n      condensing cygwin configuration files into a single file and\n      removing outdated compiler settings.\n\n      (ABD, 2016/07/12, HDFFV-9946)\n\n\n    Fortran\n    --------\n    - Changed H5S_ALL_F from INTEGER to INTEGER(HID_T)\n\n      (MSB, 2016/10/14, HDFFV-9987)\n\n\n    Tools\n    -----\n    - h5diff now correctly ignores strpad in comparing strings.\n\n      (ABD, 2017/03/03, HDFFV-10128)\n\n    - h5repack now correctly parses the command line filter options.\n\n      (ABD, 2017/01/24, HDFFV-10046)\n\n    - h5diff now correctly returns an error when it cannot read data due\n      to an unavailable filter plugin.\n\n      (ADB 2017/01/18, HDFFV-9994 )\n\n    - Fixed an error in the compiler wrapper scripts (h5cc, h5fc, et al.)\n      in which they would erroneously drop the file argument specified via\n      the -o flag when the -o flag was specified before the -c flag on the\n      command line, resulting in a failure to compile.\n\n      (LRK, 2016/11/04, HDFFV-9938, HDFFV-9530)\n\n    - h5repack User Defined (UD) filter parameters were not parsed correctly.\n\n      The UD filter parameters were not being parsed correctly. Reworked coding\n      section to parse the correct values and verify number of parameters.\n\n      (ABD, 2016/10/19, HDFFV-9996, HDFFV-9974, HDFFV-9515, HDFFV-9039)\n\n    - h5repack allows the --enable-error-stack option on the command line.\n\n      (ADB, 2016/08/08, HDFFV-9775)\n\n\n    C++ APIs\n    --------\n    - The member function H5Location::getNumObjs() is moved to\n      class Group because the objects are in a group or a file only,\n      and H5Object::getNumAttrs to H5Location to get the number of\n      attributes at a given location.\n\n      (BMR, 2017/03/17, PR#466)\n\n    - Due to the change in the C API, the overloaded functions of\n      PropList::setProperty now need const for some arguments.  They are\n      planned for deprecation and are replaced by new versions with proper\n      consts.\n\n      (BMR, 2017/03/17, PR#344)\n\n    - The high-level API Packet Table (PT) did not write data correctly when\n      the datatype is a compound type that has string type as one of the\n      members.  This problem started in 1.8.15, after the fix of HDFFV-9042\n      was applied, which caused the Packet Table to use native type to access\n      the data.  It should be up to the application to specify whether the\n      buffer to be read into memory is in the machine's native architecture.\n      Thus, the PT is fixed to not use native type but to make a copy of the\n      user's provided datatype during creation or the packet table's datatype\n      during opening.  If an application wishes to use native type to read the\n      data, then the application will request that.  However, the Packet Table\n      doesn't provide a way to specify memory datatype in this release.  This\n      feature will be available in future releases.\n\n      (BMR, 2016/10/27, HDFFV-9758)\n\n    - The obsolete macros H5_NO_NAMESPACE and H5_NO_STD have been removed from\n      the HDF5 C++ API library.\n\n      (BMR, 2016/10/23, HDFFV-9532)\n\n    - The problem where a user-defined function cannot access both, attribute\n      and dataset, using only one argument is now fixed.\n\n      (BMR, 2016/10/11, HDFFV-9920)\n\n    - In-memory array information, ArrayType::rank and\n      ArrayType::dimensions, were removed. This is an implementation\n      detail and should not affect applications.\n\n      (BMR, 2016/04/25, HDFFV-9725)\n\n\n    Testing\n    -------\n    - Fixed a problem that caused tests using SWMR to occasionally fail when\n      running \"make check\" using parallel make.\n\n      (LRK, 2016/03/22, PR#338, PR#346, PR#358)\n\n\nSupported Platforms\n===================\n\n    Linux 2.6.32-573.18.1.el6.ppc64 gcc (GCC) 4.4.7 20120313 (Red Hat 4.4.7-4)\n    #1 SMP ppc64 GNU/Linux        g++ (GCC) 4.4.7 20120313 (Red Hat 4.4.7-4)\n    (ostrich)                     GNU Fortran (GCC) 4.4.7 20120313\n                                      (Red Hat 4.4.7-4)\n                                  IBM XL C/C++ V13.1\n                                  IBM XL Fortran V15.1\n\n    Linux 3.10.0-327.10.1.el7     GNU C (gcc), Fortran (gfortran), C++ (g++)\n    #1 SMP x86_64 GNU/Linux       compilers:\n    (kituo/moohan)                  Version 4.8.5 20150623 (Red Hat 4.8.5-4)\n                                    Version 4.9.3, Version 5.2.0\n                                  Intel(R) C (icc), C++ (icpc), Fortran (icc)\n                                  compilers:\n                                     Version 15.0.3.187 Build 20150407\n                                  MPICH 3.1.4 compiled with GCC 4.9.3\n\n    SunOS 5.11 32- and 64-bit     Sun C 5.12 SunOS_sparc\n    (emu)                         Sun Fortran 95 8.6 SunOS_sparc\n                                  Sun C++ 5.12 SunOS_sparc\n\n    Windows 7                     Visual Studio 2012 w/ Intel Fortran 15 (cmake)\n                                  Visual Studio 2013 w/ Intel Fortran 15 (cmake)\n                                  Visual Studio 2015 w/ Intel Fortran 16 (cmake)\n\n    Windows 7 x64                 Visual Studio 2012 w/ Intel Fortran 15 (cmake)\n                                  Visual Studio 2013 w/ Intel Fortran 15 (cmake)\n                                  Visual Studio 2015 w/ Intel Fortran 16 (cmake)\n                                  Visual Studio 2015 w/ MSMPI 8 (cmake)\n                                  Cygwin(CYGWIN_NT-6.1 2.8.0(0.309/5/3)\n                                      gcc and gfortran compilers (GCC 5.4.0)\n                                      (cmake and autotools)\n\n    Windows 10                    Visual Studio 2015 w/ Intel Fortran 16 (cmake)\n                                  Cygwin(CYGWIN_NT-6.1 2.8.0(0.309/5/3)\n                                      gcc and gfortran compilers (GCC 5.4.0)\n                                      (cmake and autotools)\n\n    Windows 10 x64                Visual Studio 2015 w/ Intel Fortran 16 (cmake)\n\n    Mac OS X Mt. Lion 10.8.5      Apple clang/clang++ version 5.1 from Xcode 5.1\n    64-bit                        gfortran GNU Fortran (GCC) 4.8.2\n    (swallow/kite)                Intel icc/icpc/ifort version 15.0.3\n\n    Mac OS X Mavericks 10.9.5     Apple clang/clang++ version 6.0 from Xcode 6.2\n    64-bit                        gfortran GNU Fortran (GCC) 4.9.2\n    (wren/quail)                  Intel icc/icpc/ifort version 15.0.3\n\n    Mac OS X Yosemite 10.10.5     Apple clang/clang++ version 6.1 from Xcode 7.0\n    64-bit                        gfortran GNU Fortran (GCC) 4.9.2\n    (osx1010dev/osx1010test)      Intel icc/icpc/ifort version 15.0.3\n\n    Mac OS X El Capitan 10.11.6   Apple clang/clang++ version 7.3 from Xcode 7.3\n    64-bit                        gfortran GNU Fortran (GCC) 5.2.0\n    (osx1010dev/osx1010test)      Intel icc/icpc/ifort version 16.0.2\n\n\nTested Configuration Features Summary\n=====================================\n\n    In the tables below\n          y   = tested\n          n   = not tested in this release\n          C   = Cluster\n          W   = Workstation\n          x   = not working in this release\n          dna = does not apply\n          ( ) = footnote appears below second table\n          <blank> = testing incomplete on this feature or platform\n\nPlatform                              C         F90/   F90      C++  zlib  SZIP\n                                      parallel  F2003  parallel\nSolaris2.11 32-bit                      n        y/y    n        y    y     y\nSolaris2.11 64-bit                      n        y/n    n        y    y     y\nWindows 7                               y        y/y    n        y    y     y\nWindows 7 x64                           y        y/y    y        y    y     y\nWindows 7 Cygwin                        n        y/n    n        y    y     y\nWindows 7 x64 Cygwin                    n        y/n    n        y    y     y\nWindows 10                              y        y/y    n        y    y     y\nWindows 10 x64                          y        y/y    n        y    y     y\nMac OS X Mountain Lion 10.8.5 64-bit    n        y/y    n        y    y     y\nMac OS X Mavericks 10.9.5 64-bit        n        y/y    n        y    y     y\nMac OS X Yosemite 10.10.5 64-bit        n        y/y    n        y    y     y\nMac OS X El Capitan 10.11.6 64-bit      n        y/y    n        y    y     y\nCentOS 7.2 Linux 2.6.32 x86_64 PGI      n        y/y    n        y    y     y\nCentOS 7.2 Linux 2.6.32 x86_64 GNU      y        y/y    y        y    y     y\nCentOS 7.2 Linux 2.6.32 x86_64 Intel    n        y/y    n        y    y     y\nLinux 2.6.32-573.18.1.el6.ppc64         n        y/y    n        y    y     y\n\n\nPlatform                                 Shared  Shared    Shared    Thread-\n                                         C libs  F90 libs  C++ libs  safe\nSolaris2.11 32-bit                         y       y         y         y\nSolaris2.11 64-bit                         y       y         y         y\nWindows 7                                  y       y         y         y\nWindows 7 x64                              y       y         y         y\nWindows 7 Cygwin                           n       n         n         y\nWindows 7 x64 Cygwin                       n       n         n         y\nWindows 10                                 y       y         y         y\nWindows 10 x64                             y       y         y         y\nMac OS X Mountain Lion 10.8.5 64-bit       y       n         y         y\nMac OS X Mavericks 10.9.5 64-bit           y       n         y         y\nMac OS X Yosemite 10.10.5 64-bit           y       n         y         y\nMac OS X El Capitan 10.11.6 64-bit         y       n         y         y\nCentOS 7.2 Linux 2.6.32 x86_64 PGI         y       y         y         n\nCentOS 7.2 Linux 2.6.32 x86_64 GNU         y       y         y         y\nCentOS 7.2 Linux 2.6.32 x86_64 Intel       y       y         y         n\nLinux 2.6.32-573.18.1.el6.ppc64            y       y         y         n\n\nCompiler versions for each platform are listed in the preceding\n\"Supported Platforms\" table.\n\n\nMore Tested Platforms\n=====================\n\nThe following platforms are not supported but have been tested for this release.\n\n    Linux 2.6.32-573.22.1.el6     GNU C (gcc), Fortran (gfortran), C++ (g++)\n    #1 SMP x86_64 GNU/Linux       compilers:\n    (mayll/platypus)                 Version 4.4.7 20120313\n                                     Version 4.8.4\n                                  PGI C, Fortran, C++ for 64-bit target on\n                                  x86-64;\n                                      Version 16.10-0\n                                  Intel(R) C (icc), C++ (icpc), Fortran (icc)\n                                  compilers:\n                                     Version 15.0.3.187 (Build 20150407)\n                                  MPICH 3.1.4 compiled with GCC 4.9.3\n\n    Linux 3.10.0-327.18.2.el7     GNU C (gcc) and C++ (g++) compilers\n    #1 SMP x86_64 GNU/Linux          Version 4.8.5 20150623 (Red Hat 4.8.5-4)\n    (jelly)                       with NAG Fortran Compiler Release 6.1(Tozai)\n                                  Intel(R) C (icc) and C++ (icpc) compilers\n                                     Version 15.0.3.187 (Build 20150407)\n                                  with NAG Fortran Compiler Release 6.1(Tozai)\n\n    Linux 2.6.32-573.18.1.el6.ppc64  MPICH mpich 3.1.4 compiled with\n    #1 SMP ppc64 GNU/Linux           IBM XL C/C++ for Linux, V13.1\n    (ostrich)                        and IBM XL Fortran for Linux, V15.1\n\n    Debian 8.4 3.16.0-4-amd64 #1 SMP Debian 3.16.36-1 x86_64 GNU/Linux\n                                  gcc, g++ (Debian 4.9.2-10) 4.9.2\n                                  GNU Fortran (Debian 4.9.2-10) 4.9.2\n                                  (cmake and autotools)\n\n    Fedora 24  4.7.2-201.fc24.x86_64 #1 SMP x86_64 x86_64 x86_64 GNU/Linux\n                                  gcc, g++ (GCC) 6.1.1 20160621\n                                      (Red Hat 6.1.1-3)\n                                  GNU Fortran (GCC) 6.1.1 20160621\n                                      (Red Hat 6.1.1-3)\n                                  (cmake and autotools)\n\n    Ubuntu 16.04.1 4.4.0-38-generic #57-Ubuntu SMP x86_64 GNU/Linux\n                                  gcc, g++ (Ubuntu 5.4.0-6ubuntu1~16.04.2)\n                                      5.4.0 20160609\n                                  GNU Fortran (Ubuntu 5.4.0-6ubuntu1~16.04.2)\n                                      5.4.0 20160609\n                                  (cmake and autotools)\n\n\nKnown Problems\n==============\n\n    At present, metadata cache images may not be generated by parallel\n    applications.  Parallel applications can read files with metadata cache\n    images, but since this is a collective operation, a deadlock is possible\n    if one or more processes do not participate.\n\n    Known problems in previous releases can be found in the HISTORY*.txt files\n    in the HDF5 source. Please report any new problems found to\n    help@hdfgroup.org.\n\n\n%%%%1.10.0-patch1%%%%\n\n\nHDF5 version 1.10.0-patch1 released on 2016-05-23\n================================================================================\n\nINTRODUCTION\n\nThis document describes the differences between HDF5-1.8 series and\nHDF5 1.10.0 releases, and contains information on the platforms\ntested.\n\nLinks to HDF5 1.10.0 source code can be found on The HDF Group's\ndevelopment FTP server at the following location:\n\n    https://www.hdfgroup.org/HDF5/release/obtain5110.html\n\nUser documentation can be accessed directly at this location:\n\n    https://www.hdfgroup.org/HDF5/docNewFeatures/\n\nFor more information, see the HDF5 home page:\n\n    https://www.hdfgroup.org/HDF5/\n\nIf you have any questions or comments, please send them to the HDF\nHelp Desk:\n\n    help@hdfgroup.org\n\n\n\nCONTENTS\n\n- New Features\n- Issues Addressed in this Release\n- Supported Platforms\n- Tested Configuration Features Summary\n- More Tested Platforms\n- Known Problems and Limitations\n\n\n\nNew Features\n============\nThis release supports the following features:\n\n    Configuration\n    -------------\n    - API Compatibility with HDF5 1.8 Flag Was Added\n\n      The 1.10 version of the HDF5 Library can be configured to operate\n      identically to the 1.8 library with the --with-default-api-version=v18\n      configure flag. This allows existing code to be compiled with the 1.10\n      library without requiring immediate changes to the application source\n      code. For addtional configuration options and other details, see\n      \"API Compatibility Macros in HDF5\" at\n      https://www.hdfgroup.org/HDF5/doc/RM/APICompatMacros.html.\n\n    - Autotools Configuration Has Been Extensively Reworked\n\n      The autotools configuration options have been updated to allow more\n      fine-grained control of the build options and to correct some bugs.\n      See configure --help for comprehensive information on each option.\n\n      Specific changes:\n\n      * --enable-debug and --enable-production are no longer accepted.\n        Use --enable-build-mode=(debug | production) instead. These set\n        appropriate defaults for symbols, optimizations, and other\n        configuration options. These defaults can be overridden by the\n        user.\n\n      * Extra debug output messages are no longer enabled with\n        --enable-debug=<package list>. Use --enable-internal-debug=<pkg list>\n        instead.\n\n      * A new --enable-symbols option allows symbols to be generated\n        independently of the build mode. --disable-symbols can be used\n        to strip symbols from the binary.\n\n      * A new --enable-asserts option sets/unsets NDEBUG. This is\n        independent of the build mode. This also enables some extra\n        low-overhead debug checks in the library.\n\n      * A new --enable-profiling option sets profiling flags. This is\n        independent of the build mode.\n\n      * A new --enable-optimization option sets the optimization level.\n        This is independent of the build mode.\n\n      * Many of these options can take a flags string that will be used\n        to build the library. This can be useful for specifying custom\n        optimization flags such as -Os and -Ofast.\n\n      * gnu C++ and Fortran use configure sub-files that update the\n        build flags and turn on warnings. The increase in warnings when\n        building these wrapper libraries is due to these flag changes\n        and not to a decrease in code quality.\n\n      * The option to clear file buffers has been removed. Any buffer that\n        will eventually be written to disk will now always be memset\n        to zero. This prevents the previous contents of the buffer from\n        being written to the disk if the buffer contents are not\n        completely overwritten, which has security implications.\n\n    - LFS Changes\n\n      The way the autotools handle large file support (LFS) has been\n      overhauled in this release.\n\n      * We assume ftello and fseeko exist\n\n      * We no longer explicitly use the *64 I/O functions. Instead, we\n        rely on a mapping provided by _FILE_OFFSET_BITS or its equivalent.\n\n      * _LARGEFILE(64)_SOURCE is no longer exported via AM_CPPFLAGS.\n\n\n\n    Parallel Library\n    -----------------\n    - Collective Metadata I/O\n\n      Calls for HDF5 metadata can result in many small reads and writes.\n      On metadata reads, collective metadata I/O can improve performance\n      by allowing the library to perform optimizations when reading the\n      metadata by having one rank read the data and broadcasting it to\n      all other ranks.\n\n      Collective metadata I/O improves metadata write performance through\n      the construction of an MPI derived datatype that is then written\n      collectively in a single call. For more information, see\n      https://www.hdfgroup.org/HDF5/docNewFeatures/NewFeaturesCollectiveMetadataIoDocs.html.\n\n\n\n    Library\n    --------\n    - Concurrent Access to HDF5 Files - Single Writer/ Multple Reader (SWMR)\n\n      The Single Writer/ Multiple Reader or SWMR feature enables users to\n      read data concurrently while writing it. Communications between the\n      processes and file locking are not required. The processes can run\n      on the same or on different platforms as long as they share a common\n      file system that is POSIX compliant. For more information, see the\n      Single-Writer/Multiple-Reader (SWMR) documentation at\n      https://www.hdfgroup.org/HDF5/docNewFeatures/NewFeaturesSwmrDocs.html.\n\n    - Virtual Dataset (VDS)\n\n      The VDS feature enables data to be accessed across HDF5 files\n      using standard HDF5 objects such as groups and datasets without\n      rewriting or rearranging the data. An HDF5 virtual dataset (VDS)\n      is an HDF5 dataset that is composed of source HDF5 datasets in\n      a predefined mapping. VDS can be used with the SWMR feature. For\n      documentation, check\n      https://www.hdfgroup.org/HDF5/docNewFeatures/NewFeaturesVirtualDatasetDocs.html.\n\n    - Persistent Free File Space Tracking\n\n      Usage patterns when working with an HDF5 file sometimes result in\n      wasted space within the file. This can also impair access times\n      when working with the resulting files. The new file space management\n      feature provides strategies for managing space in a file to improve\n      performance in both of these areas. For more information, see\n      https://www.hdfgroup.org/HDF5/docNewFeatures/NewFeaturesFileSpaceMgmtDocs.html.\n\n    - Version 3 Metadata Cache\n\n      The version 3 metadata cache moves management of metadata I/O from\n      the clients to the metadata cache proper.  This change is essential for\n      SWMR and other features that have yet to be released.\n\n\n\n    C++ Library\n    ------------\n    - New Member Function Added to H5::ArrayType\n\n      The assignment operator ArrayType::operator= was added because\n      ArrayType has pointer data members.\n\n      (BMR - 2016/03/07, HDFFV-9562)\n\n\n\n    Tools\n    ------\n    - h5watch\n\n      The h5watch tool allows users to output new records appended to\n      a dataset under SWMR access as it grows. The functionality is\n      similar to the Unix user command \"tail\" with the follow option,\n      which outputs appended data as the file grows. For more\n      information, see\n      https://www.hdfgroup.org/HDF5/docNewFeatures/NewFeaturesSwmrDocs.html#Tools.\n\n    - h5format_convert\n\n      The h5format_convert tool allows users to convert the indexing\n      type of a chunked dataset made with a 1.10.x version of the HDF5\n      Library when the latest file format is used to the 1.8.x version 1 B-tree indexing\n      type. For example, datasets created using SWMR access, can be\n      converted to be accessed by the HDF5 1.18 library and tools. The\n      tool does not rewrite raw data, but it does rewrite HDF5 metadata.\n\n\n\n    High-Level APIs\n    ----------------\n    - H5DOappend\n\n      The function appends data to a dataset along a specified dimension.\n\n\n    C Packet Table API\n    ------------------\n    - Replacement of a Public Function with H5PTcreate\n\n      The existing function H5PTcreate_fl limits applications so they\n      can use the deflate compression only. The public function\n      H5PTcreate has been added to replace H5PTcreate_fl. H5PTcreate\n      takes a property list identifier to provide flexibility on\n      creation properties.\n\n      (BMR - 2016/03/04, HDFFV-8623)\n\n    - New Public Functions: H5PTget_dataset and H5PTget_type\n\n      Two accessor functions have been added. H5PTget_dataset returns\n      the identifier of the dataset associated with the packet table,\n      and H5PTget_type returns the identifier of the datatype used by\n      the packet table.\n\n      (BMR, 2016/03/04, HDFFV-8623)\n\n    - Regarding #ifdef VLPT_REMOVED\n\n      The #ifdef VLPT_REMOVED blocks have been removed from the packet\n      table (PT) library source except for the following functions:\n        + H5PTis_varlen() has been made available again\n        + H5PTfree_vlen_readbuff() is now H5PTfree_vlen_buff()\n\n      (BMR - 2016/03/04, HDFFV-442)\n\n    C++ Packet Table API\n    --------------------\n    - New Constructor Added to FL_PacketTable\n\n      An overloaded constructor has been added to FL_PacketTable and\n      takes a property list identifier to provide flexibility on\n      creation properties.\n\n      (BMR - 2016/03/08, HDFFV-8623)\n\n    - New Public Functions\n\n      Two accessor wrappers are added to class PacketTable.\n      PacketTable::GetDataset() returns the identifier of the dataset\n      associated with the packet table, and PacketTable::GetDatatype()\n      returns the identifier of the datatype that the packet table uses.\n\n      (BMR - 2016/03/04, HDFFV-8623)\n\n    - Member Functions with \"char*\" as an Argument\n\n      Overloaded functions were added to provide the \"const char*\"\n      argument; the existing version will be deprecated in future\n      releases.\n\n      (BMR - 2016/03/04, HDFFV-8623)\n\n    - Regarding #ifdef VLPT_REMOVED\n\n      The #ifdef VLPT_REMOVED blocks have been removed from the packet\n      table library source code except for the following functions:\n        + VL_PacketTable::IsVariableLength() was moved to PacketTable\n        + VL_PacketTable::FreeReadBuff() is now PacketTable::FreeBuff()\n\n      (BMR - 2016/03/04, HDFFV-442)\n\n\n\n    Java Wrapper Library\n    --------------------\n\n    The Java HDF5 JNI library has been integrated into the HDF5 repository.\n    The configure option is \"--enable-java\", and the CMake option is\n    HDF5_BUILD_JAVA:BOOL=ON. The package hierarchy has changed from the\n    HDF5 1.8 JNI, which was \"ncsa.hdf.hdflib.hdf5\", to HDF5 1.10,\n    \"hdf.hdflib.hdf5\".\n\n    A number of new APIs were added including some for VDS and SWMR.\n\n\n\n    Other Important Changes\n    -----------------------\n\n    The hid_t type was changed from 32-bit to a 64-bit value.\n\n\n\nIssues Addressed in this Release Since 1.10.0\n=============================================\n\n     - h5diff would return from a compare attributes abnormally if one of the datatypes\n       was a vlen. This resulted in a memory leak as well as an incorrect report of\n       attribute comparison.\n\n       Fixed.\n       (ADB - 2016/04/26, HDFFV-9784)\n\n     - The JUnit-interface test may fail on Solaris platforms. The result of\n       a test for verifying the content of the error stack to stdout is\n       in a different order on Solaris then other platforms.\n\n       This test is skipped on Solaris\n       (ADB - 2016/04/21, HDFFV-9734)\n\n     - When building HDF5 with Java using CMake and specifying Debug for CMAKE_BUILD_TYPE,\n       there was a missing command argument for the tests of the examples.\n\n       Fixed.\n       (ADB - 2016/04/21, HDFFV-9743)\n\n     - Changed h5diff to print a warning when a dataset is virtual, enabling\n       the data to be compared. In addition h5repack failed to copy the data\n       of a virtual dataset to the new file. Function H5D__get_space_status changed\n       to correctly determine the H5D_space_status_t allocation value.\n\n       CMake added the Fixed Array indexing tests that were only in the autotools\n       test scripts.\n\n       Fixed and tests added for vds issues.\n       (ADB,NAF - 2016/04/21, HDFFV-9756)\n\n     - CMake added the h5format_convert tool and tests that were only in the autotools\n       build and test scripts. The autotools test script was reworked to allow CMake\n       to execute the test suite in parallel.\n\n       Also, h5clear tool and tests were added to the misc folder.\n\n       Fixed.\n       (ADB - 2016/04/21, HDFFV-9766)\n\n     - CMake added the h5watch tool and argument tests that were only in the autotools\n       build and test scripts. The POSIX only tests were not added to CMake.\n\n       CMake HL tools files were refactored to move the CMake test scripts into each tool folder.\n\n       Fixed.\n       (ADB - 2016/04/21, HDFFV-9770)\n\n     - Configure fails to detect valid real KINDs on FreeBSD 9.3 (i386) with Fortran enabled.\n\n       Fixed. Added the exponential option to SELECTED_REAL_KIND to distinguish\n       KINDs of same precision\n       (MSB - 2016/05/14,HDFFV-9912)\n\n\n     - Corrected the f90 H5AWRITE_F integer interface's buf to be INTENT(IN).\n       (MSB - 2016/05/14)\n\n     - Configure fails in sed command on FreeBSD 9.3 (i386) with Fortran enabled.\n\n       Fixed.\n       (MSB - 2016/05/14,HDFFV-9912)\n\n     - Compile time error in H5f90global.F90 with IBM XL Fortran 14.1.0.13 on BG/Q with Fortran\n       enabled.\n\n       Fixed.\n       (MSB - 2016/05/16,HDFFV-9917)\n\n     - A cmake build with Fortran enabled does not install module h5fortkit\n\n       Fixed.\n       (MSB - 2016/05/23,HDFFV-9923)\n\n\nIssues Addressed in this Release Since alpha1\n=============================================\n\n     - H5Pget_virtual_printf_gap, H5Pget_virtual_view, H5Pget_efile_prefix\n\n       The correct access property list settings from the\n       H5Pget_virtual_printf_gap, H5Pget_virtual_view, and\n       H5Pget_efile_prefix function calls could not be retrieved\n       using H5Dget_access_plist().\n\n       Fixed.\n\n       (DER and NAF - 2016/03/14, HDFFV-9716)\n\n     - h5dump\n\n       When h5dump was provided with the name of a non-existing file or\n       when optional arguments were the last option on the command line,\n       h5dump would segfault.\n\n       Fixed.\n\n       (ADB 2016/02/28 HDFFV-9639, HDFFV-9684)\n\n     - No Error Message for Corrupt Metadata\n\n       The HDF5 Library did not propagate an error when it encountered\n       corrupt metadata in an HDF5 file. The issue was fixed for a\n       specific file provided by a user. If you still see the problem,\n       please contact help@hdfgroup.org\n\n       Fixed.\n\n       (MC - 2016/02/18, HDFFV-9670)\n\n     - Problem Reading Chunked Datasets with a String Datatype Larger\n       Than the Chunk Size in Bytes\n\n       When the latest file format was used and when a chunked dataset\n       was created with a datatype with the size bigger than a chunk\n       size, the data could not be read back. The issue was reported\n       for chunked datasets with a string datatype and was confirmed\n       for other datatypes with the sizes bigger than the chunk size in\n       bytes.\n\n       Fixed.\n\n       (JM - 2016/02/13, HDFFV-9672)\n\n     - Control over the Location of External Files\n\n       Users were unable to specify the locations of external files.\n\n       Two APIs - H5Pget_efile_prefix and H5Pset_efile_prefix - were\n       added so that users could specify the locations of external files.\n\n       (DER - 2016/02/04, HDFFV-8740)\n\n\n\nIssues Addressed in this Release Since alpha0\n=============================================\n    - h5format_convert\n\n      The h5format_convert tool did not downgrade the version of the\n      superblock.\n\n      Fixed. The tool now will downgrade the version of the superblock.\n\n      (EIP 2016/01/11)\n\n    - Crashes with multiple threads: invalid pointers\n\n      It was reported that alpha0 crashed when used with multiple\n      threads. The issue exists in the HDF5 Library versions 1.8 and\n      1.9. The problem is related to a shared file pointer used in some\n      miscellaneous data structures. The thread-safe library exposed\n      paths in the library where a file pointer became invalid.\n\n      The alpha1 release contains the fixes for the specific use case\n      as described in HDFFV-9643. We will keep working on identifying\n      and fixing other paths in the library with similar problems.\n\n      (EIP - 2016/01/15, HDFFV-9643)\n\n\n\nSupported Platforms\n===================\nThe following platforms are supported and have been tested for this release.\nThey are built with the configure process unless specified otherwise.\n\n    AIX 6.1                       xlc/xlc_r 10.1.0.5\n    (NASA G-ADA)                  xlC/xlC_r 10.1.0.5\n                                  xlf90/xlf90_r 12.1.0.6\n\n    Linux 2.6.32-573.22.1.el6     GNU C (gcc), Fortran (gfortran), C++ (g++)\n    #1 SMP x86_64 GNU/Linux       compilers:\n    (mayll/platypus)                 Version 4.4.7 20120313 (Red Hat 4.4.7-16)\n                                     Version 4.9.3, Version 5.2.0\n                                  PGI C, Fortran, C++ for 64-bit target on\n                                  x86-64;\n                                      Version 15.7-0\n                                  Intel(R) C (icc), C++ (icpc), Fortran (icc)\n                                  compilers:\n                                     Version 15.0.3.187 Build 20150407\n                                  MPICH 3.1.4 compiled with GCC 4.9.3\n\n    Linux 2.6.32-573.18.1.el6.ppc64 gcc (GCC) 4.4.7 20120313 (Red Hat 4.4.7-11)\n    #1 SMP ppc64 GNU/Linux        g++ (GCC) 4.4.7 20120313 (Red Hat 4.4.7-11)\n    (ostrich)                     GNU Fortran (GCC) 4.4.7 20120313 (Red Hat 4.4.7-11)\n                                  IBM XL C/C++ V13.1\n                                  IBM XL Fortran V15.1\n\n    Linux 3.10.0-327.10.1.el7   GNU C (gcc), Fortran (gfortran), C++ (g++)\n    #1 SMP x86_64 GNU/Linux       compilers:\n    (kituo/moohan)                  Version 4.8.5 20150623 (Red Hat 4.8.5-4)\n                                    Version 4.9.3, Version 5.2.0\n                                  Intel(R) C (icc), C++ (icpc), Fortran (icc)\n                                  compilers:\n                                     Version 15.0.3.187 Build 20150407\n                                  MPICH 3.1.4 compiled with GCC 4.9.3\n\n    SunOS 5.11 32- and 64-bit     Sun C 5.12 SunOS_sparc\n    (emu)                         Sun Fortran 95 8.6 SunOS_sparc\n                                  Sun C++ 5.12 SunOS_sparc\n\n    Windows 7                     Visual Studio 2012 w/ Intel Fortran 15 (cmake)\n                                  Visual Studio 2013 w/ Intel Fortran 15 (cmake)\n                                  Visual Studio 2015 w/ Intel Fortran 16 (cmake)\n                                  Cygwin(CYGWIN_NT-6.1 2.2.1(0.289/5/3) gcc(4.9.3) compiler and gfortran)\n                                  (cmake and autotools)\n\n    Windows 7 x64                 Visual Studio 2012 w/ Intel Fortran 15 (cmake)\n                                  Visual Studio 2013 w/ Intel Fortran 15 (cmake)\n                                  Visual Studio 2015 w/ Intel Fortran 16 (cmake)\n\n    Windows 8.1                   Visual Studio 2012 w/ Intel Fortran 15 (cmake)\n                                  Visual Studio 2013 w/ Intel Fortran 15 (cmake)\n\n    Windows 8.1 x64               Visual Studio 2012 w/ Intel Fortran 15 (cmake)\n                                  Visual Studio 2013 w/ Intel Fortran 15 (cmake)\n\n    Mac OS X Mt. Lion 10.8.5      Apple clang/clang++ version 5.1 from Xcode 5.1\n    64-bit                        gfortran GNU Fortran (GCC) 4.8.2\n    (swallow/kite)                Intel icc/icpc/ifort version 15.0.3\n\n    Mac OS X Mavericks 10.9.5     Apple clang/clang++ version 6.0 from Xcode 6.2\n    64-bit                        gfortran GNU Fortran (GCC) 4.9.2\n    (wren/quail)                  Intel icc/icpc/ifort version 15.0.3\n\n    Mac OS X Yosemite 10.10.5     Apple clang/clang++ version 6.0 from Xcode 7.0\n    64-bit                        gfortran GNU Fortran (GCC) 4.9.2\n    (osx1010dev/osx1010test)      Intel icc/icpc/ifort version 15.0.3\n\n    Mac OS X El Capitan 10.11.4   Apple clang/clang++ version 7.3.0 from Xcode 7.3\n    64-bit                        gfortran GNU Fortran (GCC) 5.2.0\n    (osx1010dev/osx1010test)      Intel icc/icpc/ifort version 15.0.3\n\n\n\nTested Configuration Features Summary\n=====================================\n\n    In the tables below\n          y   = tested\n          n   = not tested in this release\n          C   = Cluster\n          W   = Workstation\n          x   = not working in this release\n          dna = does not apply\n          ( ) = footnote appears below second table\n          <blank> = testing incomplete on this feature or platform\n\nPlatform                              C         F90/   F90      C++  zlib  SZIP\n                                      parallel  F2003  parallel\nSunOS 5.11 32-bit                       n        y/y    n        y    y     y\nSunOS 5.11 64-bit                       n        y/y    n        y    y     y\nWindows 7                               y        y/y    n        y    y     y\nWindows 7 x64                           y        y/y    n        y    y     y\nWindows 7 Cygwin                        n        y/y    n        y    y     n\nWindows 8.1                             n        y/y    n        y    y     y\nWindows 8.1 x64                         n        y/y    n        y    y     y\nMac OS X Mountain Lion 10.8.5 64-bit    n        y/y    n        y    y     y\nMac OS X Mavericks 10.9.5 64-bit        n        y/y    n        y    y     y\nMac OS X Yosemeti 10.10.5 64-bit        n        y/y    n        y    y     y\nAIX 6.1 32- and 64-bit                  n        y/n    n        y    y     y\nCentOS 6.7 Linux 2.6.32 x86_64 GNU      y        y/y    y        y    y     y\nCentOS 6.7 Linux 2.6.32 x86_64 Intel    n        y/y    n        y    y     y\nCentOS 6.7 Linux 2.6.32 x86_64 PGI      n        y/y    n        y    y     y\nCentOS 7.1 Linux 3.10.0 x86_64 GNU      y        y/y    y        y    y     y\nCentOS 7.1 Linux 3.10.0 x86_64 Intel    n        y/y    n        y    y     y\nLinux 2.6.32-431.11.2.el6.ppc64         n        y/n    n        y    y     y\n\nPlatform                                 Shared  Shared    Shared    Thread-\n                                         C libs  F90 libs  C++ libs  safe\nSunOS 5.11 32-bit                          y       y         y         y\nSunOS 5.11 64-bit                          y       y         y         y\nWindows 7                                  y       y         y         y\nWindows 7 x64                              y       y         y         y\nWindows 7 Cygwin                           n       n         n         y\nWindows 8.1                                y       y         y         y\nWindows 8.1 x64                            y       y         y         y\nMac OS X Mountain Lion 10.8.5 64-bit       y       n         y         y\nMac OS X Mavericks 10.9.5 64-bit           y       n         y         y\nMac OS X Yosemeti 10.10.5 64-bit           y       n         y         y\nAIX 6.1 32- and 64-bit                     y       n         n         y\nCentOS 6.7 Linux 2.6.32 x86_64 GNU         y       y         y         y\nCentOS 6.7 Linux 2.6.32 x86_64 Intel       y       y         y         y\nCentOS 6.7 Linux 2.6.32 x86_64 PGI         y       y         y         y\nCentOS 7.1 Linux 3.10.0 x86_64 GNU         y       y         y         y\nCentOS 7.1 Linux 3.10.0 x86_64 Intel       y       y         y         y\nLinux 2.6.32-431.11.2.el6.ppc64            y       y         y         y\n\nCompiler versions for each platform are listed in the preceding\n\"Supported Platforms\" table.\n\n\n\nMore Tested Platforms\n=====================\nThe following platforms are not supported but have been tested for this release.\n\n    Linux 2.6.18-431.11.2.el6     g95 (GCC 4.0.3 (g95 0.94!)\n    #1 SMP x86_64 GNU/Linux\n    (platypus)\n\n    Windows 7                     Visual Studio 2008  (cmake)\n\n    Windows 7 x64                 Visual Studio 2008  (cmake)\n\n    Windows 7 x64                 Visual Studio 2010  (cmake) with SWMR using GPFS\n\n    Windows 10                    Visual Studio 2013 w/ Intel Fortran 15 (cmake)\n\n    Windows 10 x64                Visual Studio 2013 w/ Intel Fortran 15 (cmake)\n\n    Debian7.5.0 3.2.0-4-amd64 #1 SMP Debian 3.2.51-1 x86_64 GNU/Linux\n                                  gcc (Debian 4.7.2-5) 4.7.2\n                                  GNU Fortran (Debian 4.7.2-5) 4.7.2\n                                  (cmake and autotools)\n\n    Fedora20 3.15.3-200.fc20.x86_64 #1 SMP x86_64 x86_64 x86_64 GNU/Linux\n                                  gcc (GCC) 4.8.3 20140624 (Red Hat 4.8.3-1)\n                                  GNU Fortran (GCC) 4.8.3 20140624 (Red Hat 4.8.3-1)\n                                  (cmake and autotools)\n\n    SUSE 13.1 3.11.10-17-desktop #1 SMP PREEMPT x86_64 x86_64 x86_64 GNU/Linux\n                                  gcc (SUSE Linux) 4.8.1\n                                  GNU Fortran (SUSE Linux) 4.8.1\n                                  (cmake and autotools)\n\n    Ubuntu 14.04 3.13.0-35-generic #62-Ubuntu SMP x86_64 GNU/Linux\n                                  gcc (Ubuntu/Linaro 4.9.1-0ubuntu1) 4.9.1\n                                  GNU Fortran (Ubuntu/Linaro 4.9.1-0ubuntu1) 4.9.1\n                                  (cmake and autotools)\n\n    hopper.nersc.gov              PrgEnv-gnu/5.2.40\n                                  gcc (GCC) 4.9.2 20141030 (Cray Inc.)\n                                  GNU Fortran (GCC) 4.9.2 20141030 (Cray Inc.)\n                                  g++ (GCC) 4.9.2 20141030 (Cray Inc.)\n\n\n\nKnown Problems and Limitations\n==============================\nThis section contains the list of known problems and limitations introduced\nin this release of HDF5.\n\nNote: this list is not exhaustive of all known issues discovered in HDF5\nsoftware to date. For a list of significant problems and known workarounds\nidentified in past releases, please refer to:\n\nhttps://www.hdfgroup.org/HDF5/release/known_problems/\n\nThe HDF Group also maintains a JIRA issue-tracking database which is used to\ncapture all known issues which are too numerous to reasonably list in this\ndocument. The HDF Group is taking steps to make our JIRA issue database\nopen to the public, and this section will refer to that database in a future\nrelease. In the meantime, please contact help@hdfgroup.org if you come across\nan issue not listed here or at the link above, and we will provide any\ninformation about known workarounds that we have or add it to our list of\nknown issues if it is a new issue.\n\n - The flush/refresh test occasionally fails on OS X platforms. This is\n   being investigated but no fix or workaround is available at this time.\n   (DER - 2016/03/22, HDFFV-9731)\n\n - The VDS/SWMR test will fail with a segmentation fault if the library\n   is built with --enable-using-memchecker. The is due to a VDS shutdown\n   procedure freeing a shared resource too early when the memory\n   checker changes are built. This problem does not arise when the\n   memory checker changes are not used since the internal library free\n   lists behave differently. The memory checker configure option should\n   normally only be used under special circumstances so this should not\n   affect most users. Users should be aware that the --enable-using-memchecker\n   + VDS combination may cause a segfault, however, so Valgrind et al. may\n   have to be used with an HDF5 library built without the feature if this\n   proves to be a problem.\n   (DER - 2016/03/21, HDFFV-9732)\n\n - SWMR feature limitations\n   The SWMR feature will only work if an HDF5 file under SWMR access resides\n   on a file system that obeys POSIX write() ordering semantics. Because of\n   this, SWMR will not work on  network file systems such as NFS or SMB/Windows\n   file shares since those systems do not guarantee write odering. SWMR\n   regression tests are likely to fail if run on a network file system. SWMR\n   is currently not tested on Windows though it can be tested manually\n   (some of the SWMR test programs are built by CMake), and there are no\n   obvious reasons for it to not work on NTFS or GPFS.\n   (EIP - 2016/03/20, HDFFV-9733)\n\n - VDS feature limitation\n   Currently, the path to a VDS source file is interpreted as relative to the\n   directory where the executable program runs and not to the HDF5 file with\n   the VDS dataset unless a full path to the source file is specified during\n   the mapping.\n   (EIP - 2016/03/20, HDFFV-9724)\n\n - The H5Lexists API changed behavior in HDF5-1.10 when used with a file handle\n   and root group name (\"/\"):\n\n   H5Lexists(fileid, \"/\")\n\n   In HDF5-1.8 it returns false (0) and in HDF5-1.10 it returns true (1).\n   The documentation will be updated with information regarding this change.\n   (LRK - 2016/03/30, HDFFV-8746)\n\n\n%%%%1.10.0%%%%\n\nHDF5 version 1.10.0 released on 2016-03-30\n================================================================================\n\n\n\nINTRODUCTION\n\nThis document describes the differences between HDF5-1.8 series and\nHDF5 1.10.0 releases, and contains information on the platforms\ntested.\n\nLinks to HDF5 1.10.0 source code can be found on The HDF Group's\ndevelopment FTP server at the following location:\n\n    https://www.hdfgroup.org/HDF5/release/obtain5110.html\n\nUser documentation can be accessed directly at this location:\n\n    https://www.hdfgroup.org/HDF5/docNewFeatures/\n\nFor more information, see the HDF5 home page:\n\n    https://www.hdfgroup.org/HDF5/\n\nIf you have any questions or comments, please send them to the HDF\nHelp Desk:\n\n    help@hdfgroup.org\n\n\n\nCONTENTS\n\n- New Features\n- Issues Addressed in this Release\n- Supported Platforms\n- Tested Configuration Features Summary\n- More Tested Platforms\n- Known Problems and Limitations\n\n\n\nNew Features\n============\nThis release supports the following features:\n\n    Configuration\n    -------------\n    - API Compatibility with HDF5 1.8 Flag Was Added\n\n      The 1.10 version of the HDF5 Library can be configured to operate\n      identically to the 1.8 library with the --with-default-api-version=v18\n      configure flag. This allows existing code to be compiled with the 1.10\n      library without requiring immediate changes to the application source\n      code. For addtional configuration options and other details, see\n      \"API Compatibility Macros in HDF5\" at\n      https://www.hdfgroup.org/HDF5/doc/RM/APICompatMacros.html.\n\n    - Autotools Configuration Has Been Extensively Reworked\n\n      The autotools configuration options have been updated to allow more\n      fine-grained control of the build options and to correct some bugs.\n      See configure --help for comprehensive information on each option.\n\n      Specific changes:\n\n      * --enable-debug and --enable-production are no longer accepted.\n        Use --enable-build-mode=(debug | production) instead. These set\n        appropriate defaults for symbols, optimizations, and other\n        configuration options. These defaults can be overridden by the\n        user.\n\n      * Extra debug output messages are no longer enabled with\n        --enable-debug=<package list>. Use --enable-internal-debug=<pkg list>\n        instead.\n\n      * A new --enable-symbols option allows symbols to be generated\n        independently of the build mode. --disable-symbols can be used\n        to strip symbols from the binary.\n\n      * A new --enable-asserts option sets/unsets NDEBUG. This is\n        independent of the build mode. This also enables some extra\n        low-overhead debug checks in the library.\n\n      * A new --enable-profiling option sets profiling flags. This is\n        independent of the build mode.\n\n      * A new --enable-optimization option sets the optimization level.\n        This is independent of the build mode.\n\n      * Many of these options can take a flags string that will be used\n        to build the library. This can be useful for specifying custom\n        optimization flags such as -Os and -Ofast.\n\n      * gnu C++ and Fortran use configure sub-files that update the\n        build flags and turn on warnings. The increase in warnings when\n        building these wrapper libraries is due to these flag changes\n        and not to a decrease in code quality.\n\n      * The option to clear file buffers has been removed. Any buffer that\n        will eventually be written to disk will now always be memset\n        to zero. This prevents the previous contents of the buffer from\n        being written to the disk if the buffer contents are not\n        completely overwritten, which has security implications.\n\n    - LFS Changes\n\n      The way the autotools handle large file support (LFS) has been\n      overhauled in this release.\n\n      * We assume ftello and fseeko exist\n\n      * We no longer explicitly use the *64 I/O functions. Instead, we\n        rely on a mapping provided by _FILE_OFFSET_BITS or its equivalent.\n\n      * _LARGEFILE(64)_SOURCE is no longer exported via AM_CPPFLAGS.\n\n\n\n    Parallel Library\n    -----------------\n    - Collective Metadata I/O\n\n      Calls for HDF5 metadata can result in many small reads and writes.\n      On metadata reads, collective metadata I/O can improve performance\n      by allowing the library to perform optimizations when reading the\n      metadata by having one rank read the data and broadcasting it to\n      all other ranks.\n\n      Collective metadata I/O improves metadata write performance through\n      the construction of an MPI derived datatype that is then written\n      collectively in a single call. For more information, see\n      https://www.hdfgroup.org/HDF5/docNewFeatures/NewFeaturesCollectiveMetadataIoDocs.html.\n\n\n\n    Library\n    --------\n    - Concurrent Access to HDF5 Files - Single Writer/ Multple Reader (SWMR)\n\n      The Single Writer/ Multiple Reader or SWMR feature enables users to\n      read data concurrently while writing it. Communications between the\n      processes and file locking are not required. The processes can run\n      on the same or on different platforms as long as they share a common\n      file system that is POSIX compliant. For more information, see the\n      Single-Writer/Multiple-Reader (SWMR) documentation at\n      https://www.hdfgroup.org/HDF5/docNewFeatures/NewFeaturesSwmrDocs.html.\n\n    - Virtual Dataset (VDS)\n\n      The VDS feature enables data to be accessed across HDF5 files\n      using standard HDF5 objects such as groups and datasets without\n      rewriting or rearranging the data. An HDF5 virtual dataset (VDS)\n      is an HDF5 dataset that is composed of source HDF5 datasets in\n      a predefined mapping. VDS can be used with the SWMR feature. For\n      documentation, check\n      https://www.hdfgroup.org/HDF5/docNewFeatures/NewFeaturesVirtualDatasetDocs.html.\n\n    - Persistent Free File Space Tracking\n\n      Usage patterns when working with an HDF5 file sometimes result in\n      wasted space within the file. This can also impair access times\n      when working with the resulting files. The new file space management\n      feature provides strategies for managing space in a file to improve\n      performance in both of these areas. For more information, see\n      https://www.hdfgroup.org/HDF5/docNewFeatures/NewFeaturesFileSpaceMgmtDocs.html.\n\n    - Version 3 Metadata Cache\n\n      The version 3 metadata cache moves management of metadata I/O from\n      the clients to the metadata cache proper.  This change is essential for\n      SWMR and other features that have yet to be released.\n\n\n\n    C++ Library\n    ------------\n    - New Member Function Added to H5::ArrayType\n\n      The assignment operator ArrayType::operator= was added because\n      ArrayType has pointer data members.\n\n      (BMR - 2016/03/07, HDFFV-9562)\n\n\n\n    Tools\n    ------\n    - h5watch\n\n      The h5watch tool allows users to output new records appended to\n      a dataset under SWMR access as it grows. The functionality is\n      similar to the Unix user command \"tail\" with the follow option,\n      which outputs appended data as the file grows. For more\n      information, see\n      https://www.hdfgroup.org/HDF5/docNewFeatures/NewFeaturesSwmrDocs.html#Tools.\n\n    - h5format_convert\n\n      The h5format_convert tool allows users to convert the indexing\n      type of a chunked dataset made with a 1.10.x version of the HDF5\n      Library when the latest file format is used to the 1.8.x version 1 B-tree indexing\n      type. For example, datasets created using SWMR access, can be\n      converted to be accessed by the HDF5 1.18 library and tools. The\n      tool does not rewrite raw data, but it does rewrite HDF5 metadata.\n\n\n\n    High-Level APIs\n    ----------------\n    - H5DOappend\n\n      The function appends data to a dataset along a specified dimension.\n\n\n    C Packet Table API\n    ------------------\n    - Replacement of a Public Function with H5PTcreate\n\n      The existing function H5PTcreate_fl limits applications so they\n      can use the deflate compression only. The public function\n      H5PTcreate has been added to replace H5PTcreate_fl. H5PTcreate\n      takes a property list identifier to provide flexibility on\n      creation properties.\n\n      (BMR - 2016/03/04, HDFFV-8623)\n\n    - New Public Functions: H5PTget_dataset and H5PTget_type\n\n      Two accessor functions have been added. H5PTget_dataset returns\n      the identifier of the dataset associated with the packet table,\n      and H5PTget_type returns the identifier of the datatype used by\n      the packet table.\n\n      (BMR, 2016/03/04, HDFFV-8623)\n\n    - Regarding #ifdef VLPT_REMOVED\n\n      The #ifdef VLPT_REMOVED blocks have been removed from the packet\n      table (PT) library source except for the following functions:\n        + H5PTis_varlen() has been made available again\n        + H5PTfree_vlen_readbuff() is now H5PTfree_vlen_buff()\n\n      (BMR - 2016/03/04, HDFFV-442)\n\n    C++ Packet Table API\n    --------------------\n    - New Constructor Added to FL_PacketTable\n\n      An overloaded constructor has been added to FL_PacketTable and\n      takes a property list identifier to provide flexibility on\n      creation properties.\n\n      (BMR - 2016/03/08, HDFFV-8623)\n\n    - New Public Functions\n\n      Two accessor wrappers are added to class PacketTable.\n      PacketTable::GetDataset() returns the identifier of the dataset\n      associated with the packet table, and PacketTable::GetDatatype()\n      returns the identifier of the datatype that the packet table uses.\n\n      (BMR - 2016/03/04, HDFFV-8623)\n\n    - Member Functions with \"char*\" as an Argument\n\n      Overloaded functions were added to provide the \"const char*\"\n      argument; the existing version will be deprecated in future\n      releases.\n\n      (BMR - 2016/03/04, HDFFV-8623)\n\n    - Regarding #ifdef VLPT_REMOVED\n\n      The #ifdef VLPT_REMOVED blocks have been removed from the packet\n      table library source code except for the following functions:\n        + VL_PacketTable::IsVariableLength() was moved to PacketTable\n        + VL_PacketTable::FreeReadBuff() is now PacketTable::FreeBuff()\n\n      (BMR - 2016/03/04, HDFFV-442)\n\n\n\n    Java Wrapper Library\n    --------------------\n\n    The Java HDF5 JNI library has been integrated into the HDF5 repository.\n    The configure option is \"--enable-java\", and the CMake option is\n    HDF5_BUILD_JAVA:BOOL=ON. The package hierarchy has changed from the\n    HDF5 1.8 JNI, which was \"ncsa.hdf.hdflib.hdf5\", to HDF5 1.10,\n    \"hdf.hdflib.hdf5\".\n\n    A number of new APIs were added including some for VDS and SWMR.\n\n\n\n    Other Important Changes\n    -----------------------\n\n    The hid_t type was changed from 32-bit to a 64-bit value.\n\n\n\nIssues Addressed in this Release Since alpha1\n=============================================\n\n     - H5Pget_virtual_printf_gap, H5Pget_virtual_view, H5Pget_efile_prefix\n\n       The correct access property list settings from the\n       H5Pget_virtual_printf_gap, H5Pget_virtual_view, and\n       H5Pget_efile_prefix function calls could not be retrieved\n       using H5Dget_access_plist().\n\n       Fixed.\n\n       (DER and NAF - 2016/03/14, HDFFV-9716)\n\n     - h5dump\n\n       When h5dump was provided with the name of a non-existing file or\n       when optional arguments were the last option on the command line,\n       h5dump would segfault.\n\n       Fixed.\n\n       (ADB 2016/02/28 HDFFV-9639, HDFFV-9684)\n\n     - No Error Message for Corrupt Metadata\n\n       The HDF5 Library did not propagate an error when it encountered\n       corrupt metadata in an HDF5 file. The issue was fixed for a\n       specific file provided by a user. If you still see the problem,\n       please contact help@hdfgroup.org\n\n       Fixed.\n\n       (MC - 2016/02/18, HDFFV-9670)\n\n     - Problem Reading Chunked Datasets with a String Datatype Larger\n       Than the Chunk Size in Bytes\n\n       When the latest file format was used and when a chunked dataset\n       was created with a datatype with the size bigger than a chunk\n       size, the data could not be read back. The issue was reported\n       for chunked datasets with a string datatype and was confirmed\n       for other datatypes with the sizes bigger than the chunk size in\n       bytes.\n\n       Fixed.\n\n       (JM - 2016/02/13, HDFFV-9672)\n\n     - Control over the Location of External Files\n\n       Users were unable to specify the locations of external files.\n\n       Two APIs - H5Pget_efile_prefix and H5Pset_efile_prefix - were\n       added so that users could specify the locations of external files.\n\n       (DER - 2016/02/04, HDFFV-8740)\n\n\n\nIssues Addressed in this Release Since alpha0\n=============================================\n    - h5format_convert\n\n      The h5format_convert tool did not downgrade the version of the\n      superblock.\n\n      Fixed. The tool now will downgrade the version of the superblock.\n\n      (EIP 2016/01/11)\n\n    - Crashes with multiple threads: invalid pointers\n\n      It was reported that alpha0 crashed when used with multiple\n      threads. The issue exists in the HDF5 Library versions 1.8 and\n      1.9. The problem is related to a shared file pointer used in some\n      miscellaneous data structures. The thread-safe library exposed\n      paths in the library where a file pointer became invalid.\n\n      The alpha1 release contains the fixes for the specific use case\n      as described in HDFFV-9643. We will keep working on identifying\n      and fixing other paths in the library with similar problems.\n\n      (EIP - 2016/01/15, HDFFV-9643)\n\n\n\nSupported Platforms\n===================\nThe following platforms are supported and have been tested for this release.\nThey are built with the configure process unless specified otherwise.\n\n    AIX 6.1                       xlc/xlc_r 10.1.0.5\n    (NASA G-ADA)                  xlC/xlC_r 10.1.0.5\n                                  xlf90/xlf90_r 12.1.0.6\n\n    Linux 2.6.32-573.18.1.el6    GNU C (gcc), Fortran (gfortran), C++ (g++)\n    #1 SMP x86_64 GNU/Linux       compilers:\n    (mayll/platypus)                 Version 4.4.7 20120313 (Red Hat 4.4.7-16)\n                                     Version 4.9.3, Version 5.2.0\n                                  PGI C, Fortran, C++ for 64-bit target on\n                                  x86-64;\n                                      Version 15.7-0\n                                  Intel(R) C (icc), C++ (icpc), Fortran (icc)\n                                  compilers:\n                                     Version 15.0.3.187 Build 20150407\n                                  MPICH 3.1.4 compiled with GCC 4.9.3\n\n    Linux 2.6.32-504.8.1.el6.ppc64 gcc (GCC) 4.4.7 20120313 (Red Hat 4.4.7-11)\n    #1 SMP ppc64 GNU/Linux        g++ (GCC) 4.4.7 20120313 (Red Hat 4.4.7-11)\n    (ostrich)                     GNU Fortran (GCC) 4.4.7 20120313 (Red Hat 4.4.7-11)\n                                  IBM XL C/C++ V13.1\n                                  IBM XL Fortran V15.1\n\n    Linux 3.10.0-327.10.1.el7   GNU C (gcc), Fortran (gfortran), C++ (g++)\n    #1 SMP x86_64 GNU/Linux       compilers:\n    (kituo/moohan)                  Version 4.8.5 20150623 (Red Hat 4.8.5-4)\n                                    Version 4.9.3, Version 5.2.0\n                                  Intel(R) C (icc), C++ (icpc), Fortran (icc)\n                                  compilers:\n                                     Version 15.0.3.187 Build 20150407\n                                  MPICH 3.1.4 compiled with GCC 4.9.3\n\n    SunOS 5.11 32- and 64-bit     Sun C 5.12 SunOS_sparc\n    (emu)                         Sun Fortran 95 8.6 SunOS_sparc\n                                  Sun C++ 5.12 SunOS_sparc\n\n    Windows 7                     Visual Studio 2012 w/ Intel Fortran 15 (cmake)\n                                  Visual Studio 2013 w/ Intel Fortran 15 (cmake)\n                                  Visual Studio 2015 w/ Intel Fortran 16 (cmake)\n                                  Cygwin(CYGWIN_NT-6.1 2.2.1(0.289/5/3) gcc(4.9.3) compiler and gfortran)\n                                  (cmake and autotools)\n\n    Windows 7 x64                 Visual Studio 2012 w/ Intel Fortran 15 (cmake)\n                                  Visual Studio 2013 w/ Intel Fortran 15 (cmake)\n                                  Visual Studio 2015 w/ Intel Fortran 16 (cmake)\n\n    Windows 8.1                   Visual Studio 2012 w/ Intel Fortran 15 (cmake)\n                                  Visual Studio 2013 w/ Intel Fortran 15 (cmake)\n\n    Windows 8.1 x64               Visual Studio 2012 w/ Intel Fortran 15 (cmake)\n                                  Visual Studio 2013 w/ Intel Fortran 15 (cmake)\n\n    Mac OS X Mt. Lion 10.8.5      Apple clang/clang++ version 5.1 from Xcode 5.1\n    64-bit                  gfortran GNU Fortran (GCC) 4.8.2\n    (swallow/kite)                Intel icc/icpc/ifort version 15.0.3\n\n    Mac OS X Mavericks 10.9.5     Apple clang/clang++ version 6.0 from Xcode 6.2.0\n    64-bit                  gfortran GNU Fortran (GCC) 4.9.2\n    (wren/quail)                  Intel icc/icpc/ifort version 15.0.3\n\n    Mac OS X Yosemite 10.10.5     Apple clang/clang++ version 6.0 from Xcode 7.0.0\n    64-bit                  gfortran GNU Fortran (GCC) 4.9.2\n    (osx1010dev/osx1010test)      Intel icc/icpc/ifort version 15.0.3\n\n    Mac OS X El Capitan 10.11.3     Apple clang/clang++ version 7.0.2 from Xcode 7.0.2\n    64-bit                  gfortran GNU Fortran (GCC) 5.2.0\n    (osx1010dev/osx1010test)      Intel icc/icpc/ifort version 15.0.3\n\n\n\nTested Configuration Features Summary\n=====================================\n\n    In the tables below\n          y   = tested\n          n   = not tested in this release\n          C   = Cluster\n          W   = Workstation\n          x   = not working in this release\n          dna = does not apply\n          ( ) = footnote appears below second table\n          <blank> = testing incomplete on this feature or platform\n\nPlatform                              C         F90/   F90      C++  zlib  SZIP\n                                      parallel  F2003  parallel\nSunOS 5.11 32-bit                       n        y/y    n        y    y     y\nSunOS 5.11 64-bit                       n        y/y    n        y    y     y\nWindows 7                               y        y/y    n        y    y     y\nWindows 7 x64                           y        y/y    n        y    y     y\nWindows 7 Cygwin                        n        y/y    n        y    y     n\nWindows 8.1                             n        y/y    n        y    y     y\nWindows 8.1 x64                         n        y/y    n        y    y     y\nMac OS X Mountain Lion 10.8.5 64-bit    n        y/y    n        y    y     y\nMac OS X Mavericks 10.9.5 64-bit        n        y/y    n        y    y     y\nMac OS X Yosemeti 10.10.5 64-bit        n        y/y    n        y    y     y\nAIX 6.1 32- and 64-bit                  n        y/n    n        y    y     y\nCentOS 6.7 Linux 2.6.32 x86_64 GNU      y        y/y    y        y    y     y\nCentOS 6.7 Linux 2.6.32 x86_64 Intel    n        y/y    n        y    y     y\nCentOS 6.7 Linux 2.6.32 x86_64 PGI      n        y/y    n        y    y     y\nCentOS 7.1 Linux 3.10.0 x86_64 GNU      y        y/y    y        y    y     y\nCentOS 7.1 Linux 3.10.0 x86_64 Intel    n        y/y    n        y    y     y\nLinux 2.6.32-431.11.2.el6.ppc64         n        y/n    n        y    y     y\n\nPlatform                                 Shared  Shared    Shared    Thread-\n                                         C libs  F90 libs  C++ libs  safe\nSunOS 5.11 32-bit                          y       y         y         y\nSunOS 5.11 64-bit                          y       y         y         y\nWindows 7                                  y       y         y         y\nWindows 7 x64                              y       y         y         y\nWindows 7 Cygwin                           n       n         n         y\nWindows 8.1                                y       y         y         y\nWindows 8.1 x64                            y       y         y         y\nMac OS X Mountain Lion 10.8.5 64-bit       y       n         y         y\nMac OS X Mavericks 10.9.5 64-bit           y       n         y         y\nMac OS X Yosemeti 10.10.5 64-bit           y       n         y         y\nAIX 6.1 32- and 64-bit                     y       n         n         y\nCentOS 6.7 Linux 2.6.32 x86_64 GNU         y       y         y         y\nCentOS 6.7 Linux 2.6.32 x86_64 Intel       y       y         y         y\nCentOS 6.7 Linux 2.6.32 x86_64 PGI         y       y         y         y\nCentOS 7.1 Linux 3.10.0 x86_64 GNU         y       y         y         y\nCentOS 7.1 Linux 3.10.0 x86_64 Intel       y       y         y         y\nLinux 2.6.32-431.11.2.el6.ppc64            y       y         y         y\n\nCompiler versions for each platform are listed in the preceding\n\"Supported Platforms\" table.\n\n\n\nMore Tested Platforms\n=====================\nThe following platforms are not supported but have been tested for this release.\n\n    Linux 2.6.18-431.11.2.el6     g95 (GCC 4.0.3 (g95 0.94!)\n    #1 SMP x86_64 GNU/Linux\n    (platypus)\n\n    Windows 7                     Visual Studio 2008  (cmake)\n\n    Windows 7 x64                 Visual Studio 2008  (cmake)\n\n    Windows 7 x64                 Visual Studio 2010  (cmake) with SWMR using GPFS\n\n    Windows 10                    Visual Studio 2013 w/ Intel Fortran 15 (cmake)\n\n    Windows 10 x64                Visual Studio 2013 w/ Intel Fortran 15 (cmake)\n\n    Debian7.5.0 3.2.0-4-amd64 #1 SMP Debian 3.2.51-1 x86_64 GNU/Linux\n                                  gcc (Debian 4.7.2-5) 4.7.2\n                                  GNU Fortran (Debian 4.7.2-5) 4.7.2\n                                  (cmake and autotools)\n\n    Fedora20 3.15.3-200.fc20.x86_64 #1 SMP x86_64 x86_64 x86_64 GNU/Linux\n                                  gcc (GCC) 4.8.3 20140624 (Red Hat 4.8.3-1)\n                                  GNU Fortran (GCC) 4.8.3 20140624 (Red Hat 4.8.3-1)\n                                  (cmake and autotools)\n\n    SUSE 13.1 3.11.10-17-desktop #1 SMP PREEMPT x86_64 x86_64 x86_64 GNU/Linux\n                                  gcc (SUSE Linux) 4.8.1\n                                  GNU Fortran (SUSE Linux) 4.8.1\n                                  (cmake and autotools)\n\n    Ubuntu 14.04 3.13.0-35-generic #62-Ubuntu SMP x86_64 GNU/Linux\n                                  gcc (Ubuntu/Linaro 4.9.1-0ubuntu1) 4.9.1\n                                  GNU Fortran (Ubuntu/Linaro 4.9.1-0ubuntu1) 4.9.1\n                                  (cmake and autotools)\n\n    hopper.nersc.gov              PrgEnv-gnu/5.2.40\n                                  gcc (GCC) 4.9.2 20141030 (Cray Inc.)\n                                  GNU Fortran (GCC) 4.9.2 20141030 (Cray Inc.)\n                                  g++ (GCC) 4.9.2 20141030 (Cray Inc.)\n\n\n\nKnown Problems and Limitations\n==============================\nThis section contains the list of known problems and limitations introduced\nin this release of HDF5.\n\nNote: this list is not exhaustive of all known issues discovered in HDF5\nsoftware to date. For a list of significant problems and known workarounds\nidentified in past releases, please refer to:\n\nhttps://www.hdfgroup.org/HDF5/release/known_problems/\n\nThe HDF Group also maintains a JIRA issue-tracking database which is used to\ncapture all known issues which are too numerous to reasonably list in this\ndocument. The HDF Group is taking steps to make our JIRA issue database\nopen to the public, and this section will refer to that database in a future\nrelease. In the meantime, please contact help@hdfgroup.org if you come across\nan issue not listed here or at the link above, and we will provide any\ninformation about known workarounds that we have or add it to our list of\nknown issues if it is a new issue.\n\n - The JUnit-interface test may fail on Solaris platforms. The result of\n   a test for verifying the content of the error stack to stdout is\n   in a different order on Solaris then other platforms. Use make -i option\n   to test beyond the java/test folder.\n   (ADB - 2016/03/22, HDFFV-9734)\n\n - The flush/refresh test occasionally fails on OS X platforms. This is\n   being investigated but no fix or workaround is available at this time.\n   (DER - 2016/03/22, HDFFV-9731)\n\n - The VDS/SWMR test will fail with a segmentation fault if the library\n   is built with --enable-using-memchecker. The is due to a VDS shutdown\n   procedure freeing a shared resource too early when the memory\n   checker changes are built. This problem does not arise when the\n   memory checker changes are not used since the internal library free\n   lists behave differently. The memory checker configure option should\n   normally only be used under special circumstances so this should not\n   affect most users. Users should be aware that the --enable-using-memchecker\n   + VDS combination may cause a segfault, however, so Valgrind et al. may\n   have to be used with an HDF5 library built without the feature if this\n   proves to be a problem.\n   (DER - 2016/03/21, HDFFV-9732)\n\n - SWMR feature limitations\n   The SWMR feature will only work if an HDF5 file under SWMR access resides\n   on a file system that obeys POSIX write() ordering semantics. Because of\n   this, SWMR will not work on  network file systems such as NFS or SMB/Windows\n   file shares since those systems do not guarantee write odering. SWMR\n   regression tests are likely to fail if run on a network file system. SWMR\n   is currently not tested on Windows though it can be tested manually\n   (some of the SWMR test programs are built by CMake), and there are no\n   obvious reasons for it to not work on NTFS or GPFS.\n   (EIP - 2016/03/20, HDFFV-9733)\n\n - VDS feature limitation\n   Currently, the path to a VDS source file is interpreted as relative to the\n   directory where the executable program runs and not to the HDF5 file with\n   the VDS dataset unless a full path to the source file is specified during\n   the mapping.\n   (EIP - 2016/03/20, HDFFV-9724)\n\n - When building HDF5 with Java using CMake and specifying Debug for CMAKE_BUILD_TYPE,\n   there is a missing command argument for the tests of the examples.\n\n   This error can be avoided by not building Java with Debug, HDF5_BUILD_JAVA:BOOL=OFF,\n   or not building Examples, HDF5_BUILD_EXAMPLES:BOOL=OFF.\n   (LRK - 2016/03/30, HDFFV-9743)\n\n - The H5Lexists API changed behavior in HDF5-1.10 when used with a file handle\n   and root group name (\"/\"):\n\n   H5Lexists(fileid, \"/\")\n\n   In HDF5-1.8 it returns false (0) and in HDF5-1.10 it returns true (1).\n   The documentation will be updated with information regarding this change.\n   (LRK - 2016/03/30, HDFFV-8746)\n\n",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/java/test/TestH5PL.java": "/* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\n * Copyright by The HDF Group.                                               *\n * Copyright by the Board of Trustees of the University of Illinois.         *\n * All rights reserved.                                                      *\n *                                                                           *\n * This file is part of HDF5.  The full HDF5 copyright notice, including     *\n * terms governing use, modification, and redistribution, is contained in    *\n * the COPYING file, which can be found at the root of the source code       *\n * distribution tree, or in https://support.hdfgroup.org/ftp/HDF5/releases.  *\n * If you do not have access to either file, you may request a copy from     *\n * help@hdfgroup.org.                                                        *\n * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * */\n\npackage test;\n\nimport static org.junit.Assert.assertTrue;\nimport static org.junit.Assert.fail;\nimport hdf.hdf5lib.H5;\nimport hdf.hdf5lib.HDF5Constants;\nimport hdf.hdf5lib.exceptions.HDF5LibraryException;\n\nimport org.junit.After;\nimport org.junit.Before;\nimport org.junit.Ignore;\nimport org.junit.Rule;\nimport org.junit.Test;\nimport org.junit.rules.TestName;\n\npublic class TestH5PL {\n    @Rule public TestName testname = new TestName();\n    private static String FILENAME = \"h5_dlopenChunk.h5\";\n    private static String DATASETNAME = \"DS1\";\n    private static final int DIM_X = 6;\n    private static final int DIM_Y = 8;\n    private static final int CHUNK_X = 4;\n    private static final int CHUNK_Y = 4;\n    private static final int RANK = 2;\n    private static final int NDIMS = 2;\n    private static final int H5Z_FILTER_DYNLIB4 = 260;\n\n    @Before\n    public void checkOpenIDs() {\n        assertTrue(\"H5 open ids is 0\",H5.getOpenIDCount()==0);\n        System.out.print(testname.getMethodName());\n    }\n    @After\n    public void nextTestName() {\n        System.out.println();\n    }\n\n    @Test\n    public void TestH5PLplugins() {\n        try {\n            int plugin_flags = H5.H5PLget_loading_state();\n            assertTrue(\"H5.H5PLget_loading_state: \"+plugin_flags, plugin_flags == HDF5Constants.H5PL_ALL_PLUGIN);\n            int new_setting = plugin_flags & ~HDF5Constants.H5PL_FILTER_PLUGIN;\n            H5.H5PLset_loading_state (new_setting);\n            int changed_flags = H5.H5PLget_loading_state();\n            assertTrue(\"H5.H5PLget_loading_state: \"+changed_flags, changed_flags == new_setting);\n            H5.H5PLset_loading_state (plugin_flags);\n            changed_flags = H5.H5PLget_loading_state();\n            assertTrue(\"H5.H5PLget_loading_state: \"+changed_flags, changed_flags == HDF5Constants.H5PL_ALL_PLUGIN);\n        }\n        catch (Throwable err) {\n            err.printStackTrace();\n            fail(\"TestH5PLplugins \" + err);\n        }\n    }\n\n    @Test\n    public void TestH5PLpaths() {\n        try {\n            // Get the original number of paths\n            int nStartPaths = H5.H5PLsize();\n\n            int nPaths;                     /* # paths from H5PLSize()      */\n            int nTruePaths = nStartPaths;   /* What the # paths should be   */\n            int index;                      /* Path table index             */\n            String path;                    /* Path from H5PLget()          */\n\n            // APPEND a path and ensure it was added correctly\n            String pathAppend = \"path_append\";\n            H5.H5PLappend(pathAppend);\n\n            nPaths = H5.H5PLsize();\n            nTruePaths++;\n            assertTrue(\"# paths should be \" + nTruePaths + \" but was \" + nPaths, nTruePaths == nPaths);\n\n            index = nTruePaths - 1;\n            path = H5.H5PLget(index);\n            assertTrue(\"Path should be \" + pathAppend + \" but was \" + path, path.compareToIgnoreCase(pathAppend) == 0);\n\n            // PREPEND a path and ensure it was added correctly\n            String pathPrepend = \"path_prepend\";\n            H5.H5PLprepend(pathPrepend);\n\n            nPaths = H5.H5PLsize();\n            nTruePaths++;\n            assertTrue(\"# paths should be \" + nTruePaths + \" but was \" + nPaths, nTruePaths == nPaths);\n\n            index = 0;\n            path = H5.H5PLget(index);\n            assertTrue(\"Path should be \" + pathPrepend + \" but was \" + path, path.compareToIgnoreCase(pathPrepend) == 0);\n\n            // INSERT a path and ensure it was added correctly\n            // Inserting at the index == # of start paths ensures we're in the middle\n            String pathInsert = \"path_insert\";\n            index = nStartPaths;\n            H5.H5PLinsert(pathInsert, index);\n\n            nPaths = H5.H5PLsize();\n            nTruePaths++;\n            assertTrue(\"# paths should be \" + nTruePaths + \" but was \" + nPaths, nTruePaths == nPaths);\n\n            path = H5.H5PLget(index);\n            assertTrue(\"Path should be \" + pathInsert + \" but was \" + path, path.compareToIgnoreCase(pathInsert) == 0);\n\n            // REPLACE the path we just added and ensure it updated correctly\n            String pathReplace = \"path_replace\";\n            index = nStartPaths;\n            H5.H5PLreplace(pathReplace, index);\n\n            nPaths = H5.H5PLsize();\n            assertTrue(\"# paths should be \" + nTruePaths + \" but was \" + nPaths, nTruePaths == nPaths);\n\n            path = H5.H5PLget(index);\n            assertTrue(\"Path should be \" + pathReplace + \" but was \" + path, path.compareToIgnoreCase(pathReplace) == 0);\n\n            // REMOVE the path we just replaced and check that the table was compacted\n            // The (index+1) path should move down to fill the space when the path is removed.\n            index = nStartPaths;\n            String pathRemove = H5.H5PLget(index + 1);\n            H5.H5PLremove(index);\n\n            nPaths = H5.H5PLsize();\n            nTruePaths--;\n            assertTrue(\"# paths should be \" + nTruePaths + \" but was \" + nPaths, nTruePaths == nPaths);\n\n            path = H5.H5PLget(index);\n            assertTrue(\"Path should be \" + pathRemove + \" but was \" + path, path.compareToIgnoreCase(pathRemove) == 0);\n        }\n        catch (Throwable err) {\n            err.printStackTrace();\n            fail(\"TestH5PLpaths \" + err);\n        }\n    }\n\n    @Ignore\n    public void TestH5PLdlopen() {\n        long file_id = -1;\n        long filespace_id = -1;\n        long dataset_id = -1;\n        long fapl_id = -1;\n        long dcpl_id = -1;\n        try {\n            int[]  cd_values = {9, 0, 0, 0};\n            int[] libversion = {0, 0, 0};\n            long[] dims = { DIM_X, DIM_Y };\n            long[] chunk_dims = { CHUNK_X, CHUNK_Y };\n            int[][] dset_data = new int[DIM_X][DIM_Y];\n            int[] mdc_nelmts = {0};\n            long[] rdcc_nelmts = {0};\n            long[] rdcc_nbytes = {0};\n            double[] rdcc_w0 = {0};\n\n            // Initialize data to \"1\", to make it easier to see the selections.\n            for (int indx = 0; indx < DIM_X; indx++)\n                for (int jndx = 0; jndx < DIM_Y; jndx++)\n                    dset_data[indx][jndx] = 1;\n\n            // Create a new file using default properties.\n            try {\n                file_id = H5.H5Fcreate(FILENAME, HDF5Constants.H5F_ACC_TRUNC, HDF5Constants.H5P_DEFAULT,\n                        HDF5Constants.H5P_DEFAULT);\n            }\n            catch (Exception e) {\n                e.printStackTrace();\n                fail(\"TestH5PLdlopen H5Fcreate:\" + e);\n            }\n\n            // Create dataspace. Setting maximum size to NULL sets the maximum\n            // size to be the current size.\n            try {\n                filespace_id = H5.H5Screate_simple(RANK, dims, null);\n            }\n            catch (Exception e) {\n                e.printStackTrace();\n                fail(\"TestH5PLdlopen H5Screate_simple:\" + e);\n            }\n\n            // Create the dataset creation property list.\n            try {\n                dcpl_id = H5.H5Pcreate(HDF5Constants.H5P_DATASET_CREATE);\n            }\n            catch (Exception e) {\n                e.printStackTrace();\n                fail(\"TestH5PLdlopen H5Pcreate:\" + e);\n            }\n\n            // Set the chunk size.\n            try {\n                if (dcpl_id >= 0)\n                    H5.H5Pset_chunk(dcpl_id, NDIMS, chunk_dims);\n            }\n            catch (Exception e) {\n                e.printStackTrace();\n                fail(\"TestH5PLdlopen H5Pset_chunk:\" + e);\n            }\n\n            try {\n                H5.H5get_libversion(libversion);\n                cd_values[1] = libversion[0];\n                cd_values[2] = libversion[1];\n                cd_values[3] = libversion[2];\n                if (dcpl_id >= 0)\n                    H5.H5Pset_filter(dcpl_id, H5Z_FILTER_DYNLIB4, HDF5Constants.H5Z_FLAG_MANDATORY, 4, cd_values);\n            }\n            catch (Exception e) {\n                e.printStackTrace();\n                fail(\"TestH5PLdlopen H5Pset_filter:\" + e);\n            }\n\n            // Create the chunked dataset.\n            try {\n                if ((file_id >= 0) && (filespace_id >= 0) && (dcpl_id >= 0))\n                    dataset_id = H5.H5Dcreate(file_id, DATASETNAME, HDF5Constants.H5T_NATIVE_INT, filespace_id,\n                            HDF5Constants.H5P_DEFAULT, dcpl_id, HDF5Constants.H5P_DEFAULT);\n            }\n            catch (Exception e) {\n                e.printStackTrace();\n                fail(\"TestH5PLdlopen H5Dcreate:\" + e);\n            }\n\n            try {\n                if (dataset_id >= 0)\n                    H5.H5Dwrite(dataset_id, HDF5Constants.H5T_NATIVE_INT, HDF5Constants.H5S_ALL, HDF5Constants.H5S_ALL,\n                            HDF5Constants.H5S_ALL, dset_data);\n            }\n            catch (Exception e) {\n                e.printStackTrace();\n                fail(\"TestH5PLdlopen H5Dwrite:\" + e);\n            }\n        }\n        catch (Throwable err) {\n            err.printStackTrace();\n            fail(\"TestH5PLdlopen \" + err);\n        }\n        finally {\n            // End access to the dataset and release resources used by it.\n            if (dcpl_id >= 0)\n                try {H5.H5Pclose_class(dcpl_id);} catch (Throwable err) {}\n            if (dataset_id >= 0)\n                try {H5.H5Dclose(dataset_id);} catch (Throwable err) {}\n            if (filespace_id >= 0)\n                try {H5.H5Sclose(filespace_id);} catch (Throwable err) {}\n            if (file_id >= 0)\n                try {H5.H5Fclose(file_id);} catch (Throwable err) {}\n        }\n    }\n}\n"
    },
    "skipped": [
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/config/cmake_ext_mod/hdf.ico",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/config/cmake_ext_mod/hdf.bmp",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/config/cmake_ext_mod/hdf.icns",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/.git/objects/pack/pack-639c996540289034558527409720d405641bbeeb.idx",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/.git/objects/pack/pack-639c996540289034558527409720d405641bbeeb.pack",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/hl/test/test_table_le.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/hl/test/test_ds_le.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/hl/test/test_table_cray.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/hl/test/test_ld.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/hl/test/test_ds_be.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/hl/test/test_table_be.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/hl/tools/gif2h5/testfiles/image1.gif",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/hl/tools/gif2h5/testfiles/ex_image2.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/hl/tools/gif2h5/testfiles/h52giftst.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/tbogus.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/be_data.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/corrupt_stab_msg.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/family_v16_00002.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/tmtimeo.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/family_v16_00003.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/multi_file_v16-r.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/test_filters_be.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/mergemsg.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/family_v16_00000.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/btree_idx_1_6.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/none.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/tmtimen.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/bad_compound.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/group_old.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/tarrold.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/bad_offset.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/btree_idx_1_8.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/multi_file_v16-s.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/fsm_aggr_nopersist.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/be_extlink1.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/filter_error.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/be_extlink2.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/h5fc_ext3_isf.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/tbad_msg_count.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/le_extlink1.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/POSIX_Order_Write_Test_Report.docx",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/le_extlink2.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/filespace_1_8.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/noencoder.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/file_image_core_test.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/tlayouto.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/paged_nopersist.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/fsm_aggr_persist.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/h5fc_ext_none.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/fill18.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/le_data.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/tsizeslheap.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/aggr.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/paged_persist.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/filespace_1_6.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/deflate.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/h5fc_ext2_sf.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/fill_old.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/th5s.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/family_v16_00001.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/POSIX_Order_Write_Test_Report.pdf",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/h5fc_ext1_i.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/specmetaread.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/h5fc_ext1_f.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/test_filters_le.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/memleak_H5O_dtype_decode_helper_H5Odtype.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/test/h5fc_ext2_if.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5jam/testfiles/twithub513.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5jam/testfiles/twithub.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5jam/testfiles/tall.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5repack_uint8be_ex-3.dat",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5repack_nested_8bit_enum.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5repack_fletcher.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5repack_nested_8bit_enum_deflated.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5repack_int32le_1d_ex-0.dat",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5repack_int32le_3d_ex-0.dat",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5repack_f32le_ex.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5repack_refs.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5repack_uint8be_ex.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/bounds_latest_latest.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5copy_extlinks_trg.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5copy_extlinks_src.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5repack_layout.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5repack_shuffle.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5repack_attr.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5repack_layout.UD.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5repack_paged_nopersist.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5repack_f32le.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5repack_int32le_3d_ex.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5repack_hlink.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5repack_soffset.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5repack_named_dtypes.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5repack_layout3.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5repack_int32le_2d_ex-0.dat",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5repack_ext.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5repack_fsm_aggr_nopersist.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5repack_none.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5repack_uint8be_ex-0.dat",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5repack_int32le_3d.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5repack_int32le_2d.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5repack_fill.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5repack_f32le_ex-0.dat",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5repack_int32le_2d_ex.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5repack_deflate.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5repack_paged_persist.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5repack_layouto.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5repack_early.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5repack_fsm_aggr_persist.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5repack_layout2.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5repack_int32le_1d_ex.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5repack_szip.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5repack_filters.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5repack_nbit.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5repack_uint8be_ex-1.dat",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5repack_attr_refs.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5repack_uint8be.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5repack_uint8be_ex-2.dat",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5repack_aggr.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5repack_objs.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5repack/testfiles/h5repack_int32le_1d.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5copy/testfiles/h5copytst_new.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5copy/testfiles/h5copy_ref.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5copy/testfiles/h5copy_extlinks_trg.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5copy/testfiles/h5copy_extlinks_src.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5copy/testfiles/h5copytst.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5copy/testfiles/tudfilter.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5copy/testfiles/tudfilter2.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5stat/testfiles/h5stat_newgrat.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5stat/testfiles/h5stat_filters.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5stat/testfiles/h5stat_threshold.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5stat/testfiles/h5stat_idx.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5stat/testfiles/h5stat_err_old_fill.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5stat/testfiles/h5stat_err_refcount.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5stat/testfiles/h5stat_tsohm.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5stat/testfiles/h5stat_err_old_layout.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/h5diff_grp_recurse_ext2-2.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/h5diff_dset_zero_dim_size2.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/h5diff_strings1.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/h5diff_dset2.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/h5diff_ext2softlink_src.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/h5diff_attr3.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/h5diff_attr_v_level2.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/h5diff_exclude3-2.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/h5diff_grp_recurse2.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/non_comparables1.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/h5diff_attr_v_level1.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/h5diff_dset1.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/h5diff_strings2.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/h5diff_comp_vl_strs.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/non_comparables2.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/h5diff_types.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/h5diff_exclude2-1.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/compounds_array_vlen2.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/h5diff_hyper1.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/h5diff_exclude1-2.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/h5diff_softlinks.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/h5diff_danglelinks2.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/h5diff_exclude2-2.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/h5diff_links.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/h5diff_linked_softlink.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/h5diff_grp_recurse_ext2-1.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/h5diff_empty.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/h5diff_dtypes.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/tudfilter.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/h5diff_danglelinks1.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/h5diff_attr2.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/h5diff_eps2.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/tudfilter2.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/h5diff_ext2softlink_trg.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/h5diff_dset3.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/h5diff_enum_invalid_values.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/h5diff_attr1.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/h5diff_extlink_trg.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/h5diff_basic1.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/compounds_array_vlen1.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/h5diff_grp_recurse_ext2-3.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/h5diff_grp_recurse1.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/h5diff_basic2.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/h5diff_grp_recurse_ext1.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/h5diff_exclude1-1.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/h5diff_hyper2.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/h5diff_extlink_src.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/h5diff_eps1.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/h5diff_exclude3-1.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5diff/testfiles/h5diff_dset_zero_dim_size1.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/misc/testfiles/h5clear_sec2_v0.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/misc/testfiles/h5clear_fsm_persist_equal.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/misc/testfiles/h5clear_mdc_image.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/misc/testfiles/h5clear_fsm_persist_user_equal.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/misc/testfiles/h5clear_fsm_persist_noclose.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/misc/testfiles/h5clear_fsm_persist_less.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/misc/testfiles/mod_h5clear_mdc_image.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/misc/testfiles/h5clear_log_v3.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/misc/testfiles/h5clear_status_noclose.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/misc/testfiles/latest_h5clear_log_v3.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/misc/testfiles/h5clear_sec2_v2.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/misc/testfiles/h5clear_fsm_persist_greater.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/misc/testfiles/h5clear_fsm_persist_user_greater.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/misc/testfiles/h5clear_sec2_v3.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/misc/testfiles/latest_h5clear_sec2_v3.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/misc/testfiles/h5clear_fsm_persist_user_less.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5format_convert/testfiles/old_h5fc_ext3_isf.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5format_convert/testfiles/old_h5fc_ext2_sf.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5format_convert/testfiles/h5fc_edge_v3.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5format_convert/testfiles/h5fc_err_level.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5format_convert/testfiles/old_h5fc_ext_none.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5format_convert/testfiles/old_h5fc_ext1_s.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5format_convert/testfiles/old_h5fc_ext2_if.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5format_convert/testfiles/h5fc_ext1_s.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5format_convert/testfiles/old_h5fc_ext1_f.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5format_convert/testfiles/h5fc_ext3_isf.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5format_convert/testfiles/old_h5fc_ext2_is.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5format_convert/testfiles/h5fc_non_v3.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5format_convert/testfiles/h5fc_ext_none.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5format_convert/testfiles/h5fc_ext2_is.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5format_convert/testfiles/h5fc_ext2_sf.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5format_convert/testfiles/old_h5fc_ext1_i.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5format_convert/testfiles/h5fc_ext1_i.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5format_convert/testfiles/h5fc_ext1_f.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5format_convert/testfiles/h5fc_ext2_if.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5import/testfiles/binuin32.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5import/testfiles/txtin32.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5import/testfiles/txtstr.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5import/testfiles/txtuin32.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5import/testfiles/binuin16.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5import/testfiles/txtin16.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5import/testfiles/txtuin16.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5import/testfiles/binin8.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5import/testfiles/txtfp64.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5import/testfiles/textpfe.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5import/testfiles/binin8w.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5import/testfiles/binin32.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5import/testfiles/binin16.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5import/testfiles/txtin8.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5import/testfiles/binfp64.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/test/h5import/testfiles/txtfp32.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/family_file00015.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tcmpdints.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tbitnopaque.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tfamily00001.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/family_file00009.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tarray8.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tdatareg.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/zerodim.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/file_space.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tgrp_comments.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tattrreg.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/test35.nc",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tnamed_dtype_attr.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tarray1_big.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tgrpnullspace.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tname-sp.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tscalarintsize.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tmulti-s.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/family_file00016.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/trefer_ext2.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tbitfields.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tnestedcomp.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tldouble.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tstring-at.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tref.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tarray6.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tsaf.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tvlstr.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tstr3.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tfamily00000.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tfamily00003.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tbigdims.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/thlink.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tcmpdintarray.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tref-escapes-at.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tfpformat.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tcompound_complex.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tmulti-l.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tdset2.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tints4dims.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tempty.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tloop2.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tstring.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tgroup.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/family_file00006.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tfilters.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tlonglinks.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/torderattr.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tintsattrs.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/topaque.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tobjref.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/family_file00012.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tsoftlinks.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tintsnodata.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tcompound2.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tvldtypes4.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tnullspace.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tstr2.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tstr.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/textlinksrc.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tarray2.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tmany.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tscalarstring.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tno-subset.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tname-lt.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/family_file00007.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/family_file00008.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tsplit_file-m.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/family_file00010.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tattr.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tdset_idx.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/thyperslab.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tvldtypes2.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/family_file00002.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tfvalues.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tcompound.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tfcontents1.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tudfilter.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/trefer_param.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/trefer_reg_1d.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/trefer_ext1.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tmulti-b.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tname-gt.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/family_file00005.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/trefer_obj.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/filter_fail.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tname-quot.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/family_file00014.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tcmpdattrintsize.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/family_file00000.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/t128bit_float.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tname-amp.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/family_file00013.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tarray4.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tudlink.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tnestedcmpddt.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/trefer_reg.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/family_file00011.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/packedbits.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tloop.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tattr2.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tvldtypes5.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tarray7.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/err_attr_dspace.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tscalarattrintsize.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tattrintsize.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tcompound_complex2.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tfamily00004.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tarray5.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tbinary.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tslink.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/family_file00003.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/textlink.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/family_file00017.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tattr4_be.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/trefer_compat.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tname-apos.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/family_file00004.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tnodata.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tvldtypes1.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tordergr.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/textlinktar.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/trefer_grp.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tenum.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tdset.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tfcontents2.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/trefer_attr.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/trefer_obj_del.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tlarge_objname.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tscalarintattrsize.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/charsets.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/taindices.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/textlinkfar.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tvldtypes3.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/family_file00001.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tcmpdintsize.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tmulti-o.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tall.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tarray3.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tarray1.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tchar.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tref-escapes.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tvms.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/tvlenstr_array.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/vds/4_0.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/vds/2_a.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/vds/1_d.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/vds/3_2_vds.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/vds/2_b.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/vds/4_1.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/vds/d.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/vds/f-0.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/vds/5_vds.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/vds/a.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/vds/1_f.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/vds/2_d.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/vds/2_c.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/vds/1_e.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/vds/1_a.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/vds/vds-eiger.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/vds/4_2.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/vds/1_vds.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/vds/1_b.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/vds/1_c.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/vds/5_a.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/vds/4_vds.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/vds/5_c.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/vds/5_b.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/vds/vds-percival-unlim-maxmin.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/vds/2_e.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/vds/2_vds.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/vds/3_1_vds.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/vds/f-3.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/vds/c.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/tools/testfiles/vds/b.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/c++/src/C2Cppfunction_map.htm",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/c++/src/header.html",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/c++/src/header_files/image002.jpg",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/c++/src/header_files/help.jpg",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/c++/src/header_files/hdf_logo.jpg",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/c++/src/header_files/image001.jpg",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/c++/test/th5s.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/java/lib/hamcrest-core.jar",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/java/lib/junit.jar",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/java/lib/slf4j-api-1.7.25.jar",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/java/lib/ext/slf4j-simple-1.7.25.jar",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/java/lib/ext/slf4j-nop-1.7.25.jar",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/java/test/h5ex_g_iterate.orig",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/java/examples/groups/h5ex_g_iterate.h5",
        "/tmp/vanessa/spack-stage/spack-stage-hdf5-develop-djopuqbnd6fquwaanpqtaa26cwdaxt65/spack-src/java/examples/groups/h5ex_g_visit.h5"
    ],
    "total_files": 3238
}