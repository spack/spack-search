{
    "matches": {
        "/tmp/vanessa/spack-stage/spack-stage-folly-2016.10.24.00-dz44s3v2vbl37w6qsb2lzwp2t5jy6f5w/spack-src/folly/VersionCheck.h": "/*\n * Copyright 2016 Facebook, Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n#pragma once\n\n#include <cstdio>\n#include <cstdlib>\n#include <cstring>\n\n#include <folly/Portability.h>\n#include <folly/Preprocessor.h>\n\n/**\n * Check if the currently loaded version of a library is what you expect.\n *\n * It is possible for multiple versions of the same shared library to end up\n * being loaded simultaneously in the same address space, usually with\n * disastrous results.\n *\n * For example, let's say you have a shared library (foo) that doesn't keep\n * binary compatbility between releases, and so each version is distributed as\n * a SO with different SONAME. Let's say you build another shared library, bar\n * that depends on version 1 of foo: libbar.so depends on libfoo1.so.\n * Your main executable now (baz) depends on version 2 of foo, and also\n * depends on bar: baz depends on libfoo2.so and libbar.so.\n *\n * At load time, baz loads libfoo2.so first, then libbar.so; libbar.so will\n * load libfoo1.so, but, as this is normal dynamic loading (and not explicit\n * dlopen calls with RTLD_DEEPBIND), any symbols from libfoo1.so that are\n * also present in libfoo2.so will be satisfied from the (already loaded)\n * libfoo2.so.\n *\n * But foo does not preserve binary compatibility between versions, so all\n * hell breaks loose (the symbols from libfoo2.so are not necessarily direct\n * replacements of the identically-named symbols in libfoo1.so).\n *\n * It is better to crash with a helpful error message instead, which is what\n * this macro provides. FOLLY_VERSION_CHECK verifies at load time that\n * the compiled-in version is the same as the currently loaded version.\n *\n * Usage: use this macro at namespace scope in a .cpp file (IMPORTANT: NOT\n * in the unnamed namespace):\n *\n * FOLLY_VERSION_CHECK(mylib, \"1\")\n *\n * The first argument identifies your library; the second argument is a\n * string literal containing the desired version string.\n *\n * In order to avoid changing the file for each version, the version string\n * could be provided on the compiler command line with -D:\n *\n * FOLLY_VERSION_CHECK(mylib, MYLIB_VERSION)\n *\n * ... and then commpile your file with -DMYLIB_VERSION=\\\"1\\\"\n */\n\n#if defined(_MSC_VER)\n// MSVC doesn't support constructor priorities. Just pray it works, I guess.\n// We could implement a link-time mechanism for MSVC,\n// via #pragma detect_mismatch but that would only handle\n// static library linking.\n# define FOLLY_VERSION_CHECK_PRIORITY(Ret, name) \\\n    __pragma(section(\".CRT$XCU\",read)) \\\n    static Ret __cdecl name(void); \\\n    __declspec(allocate(\".CRT$XCU\")) \\\n    Ret (__cdecl*name##_)(void) = name; \\\n    Ret __cdecl name()\n\n#elif defined(__APPLE__)\n// OS X doesn't support constructor priorities. Just pray it works, I guess.\n# define FOLLY_VERSION_CHECK_PRIORITY(Ret, name) \\\n  __attribute__((__constructor__)) Ret name()\n\n#else\n# define FOLLY_VERSION_CHECK_PRIORITY(Ret, name) \\\n  __attribute__((__constructor__(101))) Ret name()\n#endif\n\n// Note that this is carefully crafted: PRODUCT##Version must have external\n// linkage (so it collides among versions), versionCheck must have internal\n// linkage (so it does NOT collide between versions); if we're trying to have\n// multiple versions loaded at the same time, they must each run their copy\n// of versionCheck, but share the PRODUCT##Version variable.\n#define FOLLY_VERSION_CHECK(PRODUCT, VERSION) \\\n  const char* PRODUCT##Version = VERSION; \\\n  namespace { \\\n  FOLLY_VERSION_CHECK_PRIORITY(void, versionCheck) { \\\n    if (strcmp(PRODUCT##Version, VERSION)) { \\\n      fprintf(stderr, \\\n              \"Invalid %s version: desired [%s], currently loaded [%s]\\n\", \\\n              FB_STRINGIZE(PRODUCT), PRODUCT##Version, VERSION); \\\n      abort(); \\\n    } \\\n  } \\\n  }\n",
        "/tmp/vanessa/spack-stage/spack-stage-folly-2016.10.24.00-dz44s3v2vbl37w6qsb2lzwp2t5jy6f5w/spack-src/folly/configure.ac": "\n#                                               -*- Autoconf -*-\n# Process this file with autoconf to produce a configure script.\n\nAC_PREREQ(2.59)\n\nm4_define([folly_version_str], m4_esyscmd_s([cat VERSION]))\n\nAC_INIT([folly], m4_translit(folly_version_str, [:], [.]), [folly@fb.com])\n\n# We assume all revisions are backwards incompatible.\nLT_VERSION=folly_version_str:0\nAC_SUBST([LT_VERSION])\n\n#declare pkg-config variables\nPKG_VERSION=m4_join([.], m4_reverse(m4_translit(folly_version_str, [:], [,])))\nAC_SUBST([PKG_VERSION])\nAC_SUBST([PKG_CXXFLAGS])\nAC_SUBST([PKG_DEPS])\nAC_SUBST([PKG_LIBS])\n\nAC_CONFIG_SRCDIR([Likely.h])\nAC_CONFIG_HEADERS([config.h])\nAX_PREFIX_CONFIG_H([folly-config.h], [folly], [config.h])\nAC_CONFIG_AUX_DIR([build-aux])\n\nAM_INIT_AUTOMAKE([foreign dist-bzip2 nostdinc subdir-objects])\n\nAC_CONFIG_MACRO_DIR([m4])\n\nAX_CONFIG_FEATURE_DEFAULT_DISABLED\nAX_CONFIG_FEATURE(\n        [deprecated-assoc],\n        [supports deprecated associative containers (hash_map/hash_set)],\n        [HAVE_DEPRECATED_ASSOC],\n        [Define if you want to support deprecated associative containers])\n\nAC_PROG_INSTALL\nAM_PROG_LIBTOOL\n\nAC_LANG([C++])\n\n# Checks for programs.\nAC_PROG_CXX\nAC_PROG_CC\n\nAC_CXX_COMPILE_STDCXX_1Y\n\n# Be sure to add any -std option to CXXFLAGS before we invoke any\n# AC_COMPILE_IFELSE() or similar macros. Any such macros that are invoked\n# before we update CXXFLAGS will not be run with the same options that we use\n# during the real build.\nSTD=\"\"\nif test \"x$ac_cv_cxx_compile_cxx1y_cxx\" = xyes; then\n   STD=\"-std=c++1y\"\nfi\nif test \"x$ac_cv_cxx_compile_cxx1y_gxx\" = xyes; then\n   STD=\"-std=gnu++1y\"\nfi\n\nCXXFLAGS=\"$STD $CXXFLAGS\"\n\n# expose required -std option via pkg-config\nPKG_CXXFLAGS=$STD\n\n# See if -Wshadow-local and -Wshadow-compatible-local are supported\nAC_MSG_CHECKING(\n  [whether -Wshadow-local and -Wshadow-compatible-local are supported])\nAC_CACHE_VAL([folly_cv_cxx_shadow_local_support], [\n  folly_save_CXXFLAGS=\"$CXXFLAGS\"\n  CXXFLAGS=\"$CXXFLAGS -Wshadow-local -Wshadow-compatible-local\"\n  AC_COMPILE_IFELSE(\n    [AC_LANG_PROGRAM([[]], [[]])],\n    [folly_cv_cxx_shadow_local_support=yes],\n    [folly_cv_cxx_shadow_local_support=no])\n  CXXFLAGS=\"$folly_save_CXXFLAGS\"])\nAC_MSG_RESULT([$folly_cv_cxx_shadow_local_support])\nif test \"$folly_cv_cxx_shadow_local_support\" = yes; then\n  AC_DEFINE([HAVE_SHADOW_LOCAL_WARNINGS], [1],\n  [Define if both -Wshadow-local and -Wshadow-compatible-local are supported.])\nfi\n\n# Checks for glog and gflags\n# There are no symbols with C linkage, so we do a try-run\nAC_HAVE_LIBRARY([gflags],[],[AC_MSG_ERROR(\n                [Please install google-gflags library])])\nAC_CACHE_CHECK(\n  [for gflags viability],\n  [folly_cv_prog_cc_gflags],\n  [AC_RUN_IFELSE(\n    [AC_LANG_SOURCE[\n      #include <gflags/gflags.h>\n      DEFINE_bool(folly_truthy, true, \"Sample truthy flag\");\n      DEFINE_bool(folly_falsey, false, \"Sample falsey flag\");\n      int main(int argc, char** argv) {\n        return (FLAGS_folly_truthy && !FLAGS_folly_falsey) ? 0 : 1;\n      }\n    ]],\n    [folly_cv_prog_cc_gflags=yes],\n    [folly_cv_prog_cc_gflags=no]\n  )]\n)\n\nif test \"$folly_cv_prog_cc_gflags\" != \"yes\"; then\n  AC_MSG_ERROR([\"libgflags invalid, see config.log for details\"])\nfi\nFB_CHECK_PKG_CONFIG([GFLAGS], [libgflags])\n\nAC_HAVE_LIBRARY([glog],[],[AC_MSG_ERROR(\n                [Please install google-glog library])])\nAC_CACHE_CHECK(\n  [for glog viability],\n  [folly_cv_prog_cc_glog],\n  [AC_RUN_IFELSE(\n    [AC_LANG_SOURCE[\n      #include <glog/logging.h>\n      int main(int argc, char** argv) {\n        google::InitGoogleLogging(argv[0]);\n        google::ShutdownGoogleLogging();\n        return 0;\n      }\n    ]],\n    [folly_cv_prog_cc_glog=yes],\n    [folly_cv_prog_cc_glog=no]\n  )]\n)\n\nif test \"$folly_cv_prog_cc_glog\" != \"yes\"; then\n  AC_MSG_ERROR([\"libglog invalid, see config.log for details\"])\nfi\nFB_CHECK_PKG_CONFIG([GLOG], [libglog])\n\nAX_CHECK_OPENSSL([],\n        [AC_MSG_ERROR([\"Error: libssl required\"])])\nFB_CHECK_PKG_CONFIG([OPENSSL], [openssl])\n\n# check for boost libs\nAX_BOOST_BASE([1.51.0], [], [AC_MSG_ERROR(\n              [Please install boost >= 1.51.0 (context, thread, program_options, regex, system and chrono)])])\nAX_BOOST_CONTEXT\nAX_BOOST_PROGRAM_OPTIONS\nAX_BOOST_THREAD\nAX_BOOST_REGEX\nAX_BOOST_SYSTEM\nAX_BOOST_FILESYSTEM\nAX_BOOST_CHRONO\n\n# Check for python interpreter\nAM_PATH_PYTHON\n\n# Checks for header files.\nAC_HEADER_STDC\nAC_CHECK_HEADERS([fcntl.h features.h inttypes.h limits.h sched.h stdint.h stdlib.h string.h sys/time.h unistd.h mutex.h malloc.h byteswap.h bits/functexcept.h bits/c++config.h])\n\nAC_CHECK_HEADER(double-conversion/double-conversion.h, [], [AC_MSG_ERROR(\n                [Couldn't find double-conversion.h, please download from \\\n                 https://github.com/google/double-conversion/])], [])\nAC_CHECK_LIB([double-conversion],[ceil],[],[AC_MSG_ERROR(\n             [Please install double-conversion library])])\n\nAC_CHECK_LIB([event], [event_set], [], [AC_MSG_ERROR([Unable to find libevent])])\nFB_CHECK_PKG_CONFIG([EVENT], [libevent])\n\nAC_CHECK_LIB([jemalloc], [xallocx])\n\n# Checks for typedefs, structures, and compiler characteristics.\nAC_HEADER_STDBOOL\nAC_C_CONST\nAC_C_INLINE\nAC_TYPE_SIZE_T\nAC_HEADER_TIME\nAC_C_VOLATILE\nAC_CHECK_TYPE([__int128], [folly_cv_prog_cc_int128=yes],\n    [folly_cv_prog_cc_int128=no])\nif test \"$folly_cv_prog_cc_int128\" = \"yes\"; then\n  AC_DEFINE([HAVE_INT128_T], [1], [Define if we have __int128])\n  AC_CACHE_CHECK(\n    [for __int128 type traits],\n    [folly_cv_prog_cc_int128traits],\n    [AC_COMPILE_IFELSE(\n      [AC_LANG_SOURCE([[\n#include <type_traits>\nstatic_assert(\n  ::std::is_same<::std::make_signed<unsigned __int128>::type, __int128>::value,\n  \"signed form of `unsigned __uint128` must be `__int128`.\");\n      ]])],\n      [folly_cv_prog_cc_int128traits=yes],\n      [folly_cv_prog_cc_int128traits=no])\n    ])\n  if test \"$folly_cv_prog_cc_int128traits\" = \"no\"; then\n    AC_DEFINE([SUPPLY_MISSING_INT128_TRAITS], [1], [Define if we need the standard integer traits defined for the type `__int128'.])\n  fi\nfi\n\nAC_CHECK_TYPES([ptrdiff_t, pthread_spinlock_t])\n\nAC_CACHE_CHECK(\n  [for ifunc support],\n  [folly_cv_prog_cc_ifunc],\n  [AC_COMPILE_IFELSE(\n    [AC_LANG_SOURCE[\n      #pragma GCC diagnostic error \"-Wattributes\"\n      extern \"C\" void (*test_ifunc(void))() { return 0; }\n      void func() __attribute__((ifunc(\"test_ifunc\")));]\n    ],\n    [folly_cv_prog_cc_ifunc=yes],\n    [folly_cv_prog_cc_ifunc=no])])\n\nif test \"$folly_cv_prog_cc_ifunc\" = \"yes\"; then\n  AC_DEFINE([HAVE_IFUNC], [1], [Define to 1 if the compiler supports ifunc])\nfi\n\nAC_CACHE_CHECK(\n  [for final and override support],\n  [folly_cv_c_final_override],\n  [AC_COMPILE_IFELSE(\n    [AC_LANG_SOURCE[class C { virtual void f() final {} virtual void g() {} };\n                    class D : public C { virtual void g() override {} };]],\n    [folly_cv_c_final_override=yes],\n    [folly_cv_c_final_override=no])])\n\nif test \"$folly_cv_c_final_override\" = \"yes\"; then\n  final_val=final\n  override_val=override\nelse\n  final_val=\n  override_val=\nfi\n\nAC_DEFINE_UNQUOTED(\n  [FINAL], [$final_val],\n  [Define to \"final\" if the compiler supports C++11 \"final\"])\nAC_DEFINE_UNQUOTED(\n  [OVERRIDE], [$override_val],\n  [Define to \"override\" if the compiler supports C++11 \"override\"])\n\nAC_CACHE_CHECK(\n  [for std::this_thread::sleep_for],\n  [folly_cv_func_this_thread_sleep_for],\n  [AC_COMPILE_IFELSE(\n    [AC_LANG_SOURCE[\n      #include <thread>\n      #include <chrono>\n      void func() { std::this_thread::sleep_for(std::chrono::seconds(1)); }]],\n    [folly_cv_func_this_thread_sleep_for=yes],\n    [folly_cv_func_this_thread_sleep_for=no])])\n\nif test \"$folly_cv_func_this_thread_sleep_for\" = yes; then\n    AC_DEFINE([HAVE_STD__THIS_THREAD__SLEEP_FOR], [1],\n              [Define to 1 if std::this_thread::sleep_for() is defined.])\nfi\n\nAC_CACHE_CHECK(\n  [for constexpr strlen],\n  [folly_cv_func_constexpr_strlen],\n  [AC_COMPILE_IFELSE(\n    [AC_LANG_SOURCE[\n      #include <cstring>\n      static constexpr int val = strlen(\"foo\");]],\n    [folly_cv_func_constexpr_strlen=yes],\n    [folly_cv_func_constexpr_strlen=no])])\n\nif test \"$folly_cv_func_constexpr_strlen\" = yes; then\n    AC_DEFINE([HAVE_CONSTEXPR_STRLEN], [1],\n              [Define to 1 if strlen(3) is constexpr.])\nfi\n\nAC_CACHE_CHECK(\n  [for libc++],\n  [folly_cv_lib_libcpp],\n  [AC_COMPILE_IFELSE(\n    [AC_LANG_SOURCE[\n      #include <type_traits>\n      #if !_LIBCPP_VERSION\n      #error No libc++\n      #endif\n      void func() {}]\n    ],\n    [folly_cv_lib_libcpp=yes],\n    [folly_cv_lib_libcpp=no])])\n\nif test \"$folly_cv_lib_libcpp\" = yes; then\n  AC_DEFINE([USE_LIBCPP], [1], [Define to 1 if we are using libc++.])\nfi\n\nAC_CACHE_CHECK(\n  [for c++11 atomic support without GNU Atomic library],\n  [folly_cv_lib_libatomic],\n  [AC_LINK_IFELSE(\n    [AC_LANG_SOURCE[\n      #include <atomic>\n      int main() {\n        struct Test { int val; };\n        std::atomic<Test> s;\n        s.is_lock_free();\n      }\n    ]],\n    [folly_cv_lib_libatomic=yes],\n    [folly_cv_lib_libatomic=no])])\n\nif test \"$folly_cv_lib_libatomic\" = no; then\n  AC_HAVE_LIBRARY([atomic],[],[AC_MSG_ERROR(\n                  [Please install the GNU Atomic library])])\nfi\n\nAC_CACHE_CHECK(\n  [for liblinux-vdso support],\n  [folly_cv_lib_liblinux_vdso],\n  [AC_RUN_IFELSE(\n    [AC_LANG_PROGRAM[\n      #include <dlfcn.h>\n      int main() {\n        void *h = dlopen(\"linux-vdso.so.1\", RTLD_LAZY | RTLD_LOCAL | RTLD_NOLOAD);\n        if (h == nullptr) {\n          return -1;\n        }\n        dlclose(h);\n        return 0;\n      }\n    ]],\n    [folly_cv_lib_liblinux_vdso=yes],\n    [folly_cv_lib_liblinux_vdso=no])])\n\nif test \"$folly_cv_lib_liblinux_vdso\" = yes; then\n  AC_DEFINE([HAVE_LINUX_VDSO], [1], [Define to 1 if liblinux-vdso is available])\nfi\n\nAC_CACHE_CHECK(\n  [for usable std::is_trivially_copyable],\n  [folly_cv_decl_std_is_trivially_copyable],\n  [AC_COMPILE_IFELSE(\n    [AC_LANG_SOURCE[\n      #include <type_traits>\n      const bool val = std::is_trivially_copyable<bool>::value;]\n    ],\n    [folly_cv_decl_std_is_trivially_copyable=yes],\n    [folly_cv_decl_std_is_trivially_copyable=no])])\n\nif test \"$folly_cv_decl_std_is_trivially_copyable\" = yes; then\n  AC_DEFINE([HAVE_STD__IS_TRIVIALLY_COPYABLE], [1],\n            [Define to 1 if we have a usable std::is_trivially_copyable<T>\n             implementation.])\nfi\n\nAC_CACHE_CHECK(\n  [gflags namespace],\n  [folly_cv_decl_gflags_namespace],\n  [AC_COMPILE_IFELSE(\n    [AC_LANG_SOURCE[\n      #include <gflags/gflags.h>\n      void foo() { gflags::GetArgv(); }]\n    ],\n    [folly_cv_decl_gflags_namespace=gflags],\n    [AC_COMPILE_IFELSE(\n      [AC_LANG_SOURCE[\n        #include <gflags/gflags.h>\n        void foo() { google::GetArgv(); }]\n      ],\n      [folly_cv_decl_gflags_namespace=google],\n      [folly_cv_decl_gflags_namespace=error])])])\n\nif test \"$folly_cv_decl_gflags_namespace\" = error; then\n  AC_MSG_ERROR([Cannot determine gflags namespace])\nelse\n  AC_DEFINE_UNQUOTED(\n    [GFLAGS_NAMESPACE], [$folly_cv_decl_gflags_namespace],\n    [Define to gflags namespace (usually \"google\" or \"gflags\")])\n  if test \"$folly_cv_decl_gflags_namespace\" != gflags; then\n     AC_DEFINE([UNUSUAL_GFLAGS_NAMESPACE], [1],\n               [Define to 1 if the gflags namespace is not \"gflags\"])\n  fi\nfi\n\n# Figure out if we support weak symbols. If not, we will link in some null\n# stubs for functions that would otherwise be weak.\nAC_CACHE_CHECK(\n  [for weak symbol support],\n  [folly_cv_prog_cc_weak_symbols],\n  [AC_LINK_IFELSE(\n    [AC_LANG_SOURCE[\n      extern \"C\" void configure_link_extern_weak_test() __attribute__((weak));\n      int main(int argc, char** argv) {\n          return configure_link_extern_weak_test == nullptr;\n      }]],\n    [folly_cv_prog_cc_weak_symbols=\"yes\"],\n    [folly_cv_prog_cc_weak_symbols=\"no\"])])\n\nif test \"$folly_cv_prog_cc_weak_symbols\" = yes; then\n  AC_DEFINE([HAVE_WEAK_SYMBOLS], [1],\n            [Define to 1 if the linker supports weak symbols.])\nfi\n\n\n# Figure out if we support wchar well\nAC_CACHE_CHECK(\n  [for wchar support],\n  [folly_cv_prog_cc_wchar_support],\n  [AC_RUN_IFELSE(\n    [AC_LANG_SOURCE[\n      #include <cstddef>\n      #include <cwchar>\n\n      int main(int argc, char** argv) {\n        return wcstol(L\"01\", nullptr, 10) == 1 ? 0 : 1;\n      }\n    ]],\n    [folly_cv_prog_cc_wchar_support=yes],\n    [folly_cv_prog_cc_wchar_support=no])])\n\nif test \"$folly_cv_prog_cc_wchar_support\" = \"yes\"; then\n  AC_DEFINE([HAVE_WCHAR_SUPPORT], [1], [Define to 1 if the libc supports wchar well])\nfi\n\n# Figure out whether the architecture supports unaligned accesses\nAC_CACHE_CHECK(\n  [for unaligned access support],\n  [folly_cv_prog_cc_unaligned_access],\n  [AC_RUN_IFELSE(\n    [AC_LANG_SOURCE[\n      int main(int argc, char** argv) {\n        char buf[64] = {0};\n        unsigned long *ptr = (unsigned long *)(buf + 1);\n        *ptr = 0xdeadbeef;\n        return (*ptr & 0xff) == 0xef ? 0 : 1;\n      }\n    ]],\n    [folly_cv_prog_cc_unaligned_access=yes],\n    [folly_cv_prog_cc_unaligned_access=no])])\n\nif test \"$folly_cv_prog_cc_unaligned_access\" = \"yes\"; then\n  AC_DEFINE([HAVE_UNALIGNED_ACCESS], [1], [Define to 1 if the architecture allows unaligned accesses])\nfi\n\nAC_CACHE_CHECK(\n  [for vsnprintf reporting bad format strings],\n  [folly_cv_prog_vsnprintf_bad_format],\n  [AC_RUN_IFELSE(\n    [AC_LANG_SOURCE[\n      #include <stdio.h>\n\n      int main(int argc, char** argv) {\n          char buf[256];\n          return vsnprintf(buf, sizeof(buf), \"%\", 1) < 0 ? 0 : 1;\n      }]],\n    [folly_cv_prog_vsnprintf_bad_format=\"yes\"],\n    [folly_cv_prog_vsnprintf_bad_format=\"no\"])])\n\nif test \"$folly_cv_prog_vsnprintf_bad_format\" = yes; then\n  AC_DEFINE([HAVE_VSNPRINTF_ERRORS], [1],\n            [Define to 1 if the vsnprintf supports returning errors on bad format strings.])\nfi\n\nAC_SEARCH_LIBS([cplus_demangle_v3_callback], [iberty_pic iberty])\nif test \"$ac_cv_search_cplus_demangle_v3_callback\" != \"no\" ; then\n  AC_DEFINE([HAVE_CPLUS_DEMANGLE_V3_CALLBACK], [1],\n            [Define to 1 if we have cplus_demangle_v3_callback.])\nfi\n\n# Check for clock_gettime(2). This is not in an AC_CHECK_FUNCS() because we\n# want to link with librt if necessary.\nAC_SEARCH_LIBS([clock_gettime], [rt],\n  AC_DEFINE(\n    [HAVE_CLOCK_GETTIME],\n    [1],\n    [Define to 1 if we support clock_gettime(2).]),\n  [])\n\n# Check for pthread_atfork(3). This is not in an AC_CHECK_FUNCS() because we\n# want to include pthread.h if necessary.\nAC_CACHE_CHECK(\n  [for pthread_atfork support],\n  [folly_cv_prog_cc_pthread_atfork],\n  [AC_COMPILE_IFELSE(\n    [AC_LANG_SOURCE[\n      #include <pthread.h>\n      void func() {pthread_atfork(NULL, NULL, NULL);}]\n    ],\n    [folly_cv_prog_cc_pthread_atfork=yes],\n    [folly_cv_prog_cc_pthread_atfork=no])])\n\nif test \"$folly_cv_prog_cc_pthread_atfork\" = \"yes\"; then\n  AC_DEFINE([HAVE_PTHREAD_ATFORK], [1], [Define to 1 if the compiler supports pthread_atfork])\nfi\n\n# Check for XSI-compatible strerror_r as default implementation\nAC_CACHE_CHECK(\n  [for XSI style strerror_r support],\n  [folly_cv_prog_cc_xsi_strerror_r],\n  [AC_RUN_IFELSE(\n    [AC_LANG_SOURCE[\n      #include <string.h>\n      #include <errno.h>\n      int main(int argc, char** argv) {\n        char buf[1024];\n        buf[0] = 0;\n        int ret = strerror_r(ENOMEM, buf, sizeof(buf));\n        return ret;\n      }\n    ]],\n    [folly_cv_prog_cc_xsi_strerror_r=yes],\n    [folly_cv_prog_cc_xsi_strerror_r=no])])\n\nif test \"$folly_cv_prog_cc_xsi_strerror_r\" = \"yes\"; then\n  AC_DEFINE([HAVE_XSI_STRERROR_R], [1], [Define to 1 if the runtime supports XSI-style strerror_r])\nfi\n\nAC_CACHE_CHECK(\n  [for ext/random and __gnu_cxx::sfmt19937],\n  [folly_cv_prog_cc_have_extrandom_sfmt19937],\n  [AC_COMPILE_IFELSE(\n    [AC_LANG_SOURCE[\n      #include <ext/random>\n      int main(int argc, char** argv) {\n        __gnu_cxx::sfmt19937 rng;\n        return 0;\n      }\n    ]],\n    [folly_cv_prog_cc_have_extrandom_sfmt19937=yes],\n    [folly_cv_prog_cc_have_extrandom_sfmt19937=no])])\n\nAC_CACHE_CHECK(\n  [for VLA (variable-length array) support],\n  [folly_cv_prog_cc_have_vla],\n  [AC_COMPILE_IFELSE(\n    [AC_LANG_SOURCE[\n      int main(int argc, char** argv) {\n        unsigned size = argc;\n        char data[size];\n        return 0;\n      }\n    ]],\n    [folly_cv_prog_cc_have_vla=yes],\n    [folly_cv_prog_cc_have_vla=no])])\n\ntest \"$folly_cv_prog_cc_have_vla\" = yes && have_vla=1 || have_vla=0\nAC_DEFINE_UNQUOTED(\n  [HAVE_VLA],\n  [$have_vla],\n  [Define to 1 if the compiler has VLA (variable-length array) support,\n   otherwise define to 0])\n\n# Checks for library functions.\nAC_CHECK_FUNCS([getdelim \\\n                gettimeofday \\\n                memmove \\\n                memset \\\n                pow \\\n                strerror \\\n                sched_yield \\\n                malloc_size \\\n                malloc_usable_size \\\n                memrchr \\\n                pipe2 \\\n                preadv \\\n                pwritev \\\n              ])\n\nAC_CHECK_HEADER([lz4.h], AC_CHECK_LIB([lz4], [LZ4_decompress_safe]))\nAC_CHECK_HEADER([snappy.h], AC_CHECK_LIB([snappy], [main]))\nAC_CHECK_HEADER([zlib.h], AC_CHECK_LIB([z], [main]))\nAC_CHECK_HEADER([lzma.h], AC_CHECK_LIB([lzma], [main]))\nAC_CHECK_HEADER([zstd.h], AC_CHECK_LIB([zstd], [main]))\nAC_CHECK_HEADER([linux/membarrier.h], AC_DEFINE([HAVE_LINUX_MEMBARRIER_H], [1], [Define to 1 if membarrier.h is available]))\n\nAC_ARG_ENABLE([follytestmain],\n   AS_HELP_STRING([--enable-follytestmain], [enables using main function from folly for tests]),\n   [follytestmain=${enableval}], [follytestmain=no])\n\nuse_follytestmain=yes\n# libdwarf used to install in /usr/include, now installs in /usr/include/libdwarf.\nAC_SEARCH_LIBS([dwarf_init], [dwarf])\nAC_CHECK_HEADERS([libdwarf/dwarf.h dwarf.h], [break])\n# Check whether we have both the library and the header\nhave_libdwarf=no\nAS_IF([test \"x${ac_cv_search_dwarf_init}\" != xno && test \"x${ac_cv_header_libdwarf_dwarf_h}\" = xyes], [have_libdwarf=yes])\nAS_IF([test \"x${ac_cv_search_dwarf_init}\" != xno && test \"x${ac_cv_header_dwarf_h}\" = xyes], [have_libdwarf=yes])\nif test \"x${follytestmain}\" = \"xyes\"; then\n   AS_IF([test \"x${have_libdwarf}\" = xno], [AC_MSG_ERROR([Please install libdwarf development library and headers])])\n   AC_CHECK_HEADERS([elf.h],, AC_MSG_ERROR([Please install libelf development package]))\n   AC_CHECK_HEADERS([libunwind.h],, AC_MSG_ERROR([Please install libunwind development package]))\nelse\n   AS_IF([test \"x${have_libdwarf}\" = xno],, [use_follytestmain=no])\n   AC_CHECK_HEADERS([elf.h],, [use_follytestmain=no])\n   AC_CHECK_HEADERS([libunwind.h],, [use_follytestmain=no])\nfi\n\nAC_ARG_ENABLE([mobile],\n   AS_HELP_STRING([--enable-mobile],\n                  [enables using main function from folly for tests]),\n                  [mobile=${enableval}], [mobile=no])\nAS_IF([test \"x${mobile}\" = \"xyes\"], [\n    AC_DEFINE([MOBILE], [1],\n              [Define to 1 for compiler guards for mobile targets.])\n])\n\n# Include directory that contains \"folly\" so #include <folly/Foo.h> works\nAM_CPPFLAGS='-I$(top_srcdir)/..'\nAM_CPPFLAGS=\"$AM_CPPFLAGS $BOOST_CPPFLAGS\"\nAM_LDFLAGS=\"$AM_LDFLAGS $BOOST_CONTEXT_LIB $BOOST_PROGRAM_OPTIONS_LIB\"\nAM_LDFLAGS=\"$AM_LDFLAGS $BOOST_THREAD_LIB $BOOST_FILESYSTEM_LIB\"\nAM_LDFLAGS=\"$AM_LDFLAGS $BOOST_SYSTEM_LIB $BOOST_REGEX_LIB -lpthread\"\nAM_LDFLAGS=\"$AM_LDFLAGS $BOOST_CHRONO_LIB\"\n\nAM_LDFLAGS=\"$AM_LDFLAGS $OPENSSL_LDFLAGS $OPENSSL_LIBS\"\n\nAC_SUBST([AM_CPPFLAGS])\nAC_SUBST([AM_LDFLAGS])\n\nAM_CONDITIONAL([HAVE_STD_THREAD], [test \"$ac_cv_header_features\" = \"yes\"])\nAM_CONDITIONAL([HAVE_X86_64], [test \"$build_cpu\" = \"x86_64\"])\nAM_CONDITIONAL([HAVE_PPC64], [test \"$build_cpu\" = \"powerpc64le\"])\nAM_CONDITIONAL([RUN_ARCH_SPECIFIC_TESTS], [test \"$build_cpu\" = \"x86_64\" || test \"$build_cpu\" = \"powerpc64le\"])\nAM_CONDITIONAL([HAVE_LINUX], [test \"$build_os\" == \"linux-gnu\"])\nAM_CONDITIONAL([HAVE_WEAK_SYMBOLS],\n               [test \"$folly_cv_prog_cc_weak_symbols\" = \"yes\"])\nAM_CONDITIONAL([HAVE_BITS_FUNCTEXCEPT_H], [test \"$ac_cv_header_bits_functexcept_h\" = \"yes\"])\nAM_CONDITIONAL([HAVE_EXTRANDOM_SFMT19937],\n               [test \"$folly_cv_prog_cc_have_extrandom_sfmt19937\" = \"yes\"])\nAM_CONDITIONAL([FOLLY_TESTMAIN], [test \"x${use_follytestmain}\" = \"xyes\"])\nAM_CONDITIONAL([HAVE_BOOST_CONTEXT], [test \"x${ax_cv_boost_context}\" = \"xyes\"])\n\n# remove pkg-config deps from dependent libraries\n# (at least for pkg-config file purposes)\nFB_FILTER_PKG_LIBS([$AM_LDFLAGS $LIBS])\n\n# Output\nAC_CONFIG_FILES([Makefile\n                 libfolly.pc\n                 test/Makefile\n                 test/function_benchmark/Makefile\n                 experimental/Makefile\n                 experimental/symbolizer/Makefile\n                 init/Makefile])\nAC_OUTPUT\n",
        "/tmp/vanessa/spack-stage/spack-stage-folly-2016.10.24.00-dz44s3v2vbl37w6qsb2lzwp2t5jy6f5w/spack-src/folly/ClockGettimeWrappers.cpp": "/*\n * Copyright 2016 Facebook, Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n#include <folly/ClockGettimeWrappers.h>\n#include <folly/Likely.h>\n#include <folly/portability/Time.h>\n\n#include <chrono>\n\n#include <time.h>\n\n#ifndef _WIN32\n#define _GNU_SOURCE 1\n#include <dlfcn.h>\n#endif\n\nnamespace folly {\nnamespace chrono {\n\nstatic int64_t clock_gettime_ns_fallback(clockid_t clock) {\n  struct timespec ts;\n  int r = clock_gettime(clock, &ts);\n  if (UNLIKELY(r != 0)) {\n    // Mimic what __clock_gettime_ns does (even though this can be a legit\n    // value).\n    return -1;\n  }\n  std::chrono::nanoseconds result =\n      std::chrono::seconds(ts.tv_sec) + std::chrono::nanoseconds(ts.tv_nsec);\n  return result.count();\n}\n\n// Initialize with default behavior, which we might override on Linux hosts\n// with VDSO support.\nint (*clock_gettime)(clockid_t, timespec* ts) = &::clock_gettime;\nint64_t (*clock_gettime_ns)(clockid_t) = &clock_gettime_ns_fallback;\n\n#ifdef __linux__\n\nnamespace {\n\nstruct VdsoInitializer {\n  VdsoInitializer() {\n    m_handle = dlopen(\"linux-vdso.so.1\", RTLD_LAZY | RTLD_LOCAL | RTLD_NOLOAD);\n    if (!m_handle) {\n      return;\n    }\n\n    void* p = dlsym(m_handle, \"__vdso_clock_gettime\");\n    if (p) {\n      folly::chrono::clock_gettime = (int (*)(clockid_t, timespec*))p;\n    }\n    p = dlsym(m_handle, \"__vdso_clock_gettime_ns\");\n    if (p) {\n      folly::chrono::clock_gettime_ns = (int64_t(*)(clockid_t))p;\n    }\n  }\n\n  ~VdsoInitializer() {\n    if (m_handle) {\n      clock_gettime = &::clock_gettime;\n      clock_gettime_ns = &clock_gettime_ns_fallback;\n      dlclose(m_handle);\n    }\n  }\n\n private:\n  void* m_handle;\n};\n\nstatic const VdsoInitializer vdso_initializer;\n}\n\n#endif\n}\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-folly-2016.10.24.00-dz44s3v2vbl37w6qsb2lzwp2t5jy6f5w/spack-src/folly/Malloc.h": "/*\n * Copyright 2016 Facebook, Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n// Functions to provide smarter use of jemalloc, if jemalloc is being used.\n// http://www.canonware.com/download/jemalloc/jemalloc-latest/doc/jemalloc.html\n\n#pragma once\n\n/**\n * Define various MALLOCX_* macros normally provided by jemalloc.  We define\n * them so that we don't have to include jemalloc.h, in case the program is\n * built without jemalloc support.\n */\n#ifndef MALLOCX_LG_ALIGN\n#define MALLOCX_LG_ALIGN(la) (la)\n#endif\n#ifndef MALLOCX_ZERO\n#define MALLOCX_ZERO (static_cast<int>(0x40))\n#endif\n\n// If using fbstring from libstdc++ (see comment in FBString.h), then\n// just define stub code here to typedef the fbstring type into the\n// folly namespace.\n// This provides backwards compatibility for code that explicitly\n// includes and uses fbstring.\n#if defined(_GLIBCXX_USE_FB) && !defined(_LIBSTDCXX_FBSTRING)\n\n#include <folly/detail/Malloc.h>\n#include <folly/portability/BitsFunctexcept.h>\n\n#include <string>\n\nnamespace folly {\n  using std::goodMallocSize;\n  using std::jemallocMinInPlaceExpandable;\n  using std::usingJEMalloc;\n  using std::smartRealloc;\n  using std::checkedMalloc;\n  using std::checkedCalloc;\n  using std::checkedRealloc;\n}\n\n#else // !defined(_GLIBCXX_USE_FB) || defined(_LIBSTDCXX_FBSTRING)\n\n#ifdef _LIBSTDCXX_FBSTRING\n#pragma GCC system_header\n\n/**\n * Declare *allocx() and mallctl*() as weak symbols. These will be provided by\n * jemalloc if we are using jemalloc, or will be NULL if we are using another\n * malloc implementation.\n */\nextern \"C\" void* mallocx(size_t, int)\n__attribute__((__weak__));\nextern \"C\" void* rallocx(void*, size_t, int)\n__attribute__((__weak__));\nextern \"C\" size_t xallocx(void*, size_t, size_t, int)\n__attribute__((__weak__));\nextern \"C\" size_t sallocx(const void*, int)\n__attribute__((__weak__));\nextern \"C\" void dallocx(void*, int)\n__attribute__((__weak__));\nextern \"C\" void sdallocx(void*, size_t, int)\n__attribute__((__weak__));\nextern \"C\" size_t nallocx(size_t, int)\n__attribute__((__weak__));\nextern \"C\" int mallctl(const char*, void*, size_t*, void*, size_t)\n__attribute__((__weak__));\nextern \"C\" int mallctlnametomib(const char*, size_t*, size_t*)\n__attribute__((__weak__));\nextern \"C\" int mallctlbymib(const size_t*, size_t, void*, size_t*, void*,\n                            size_t)\n__attribute__((__weak__));\n\n#include <bits/functexcept.h>\n\n#define FOLLY_HAVE_MALLOC_H 1\n\n#else // !defined(_LIBSTDCXX_FBSTRING)\n\n#include <folly/detail/Malloc.h> /* nolint */\n#include <folly/portability/BitsFunctexcept.h> /* nolint */\n\n#endif\n\n// for malloc_usable_size\n// NOTE: FreeBSD 9 doesn't have malloc.h.  Its definitions\n// are found in stdlib.h.\n#if FOLLY_HAVE_MALLOC_H\n#include <malloc.h>\n#else\n#include <stdlib.h>\n#endif\n\n#include <cassert>\n#include <cstddef>\n#include <cstdint>\n#include <cstdlib>\n#include <cstring>\n\n#include <atomic>\n#include <new>\n\n#ifdef _LIBSTDCXX_FBSTRING\nnamespace std _GLIBCXX_VISIBILITY(default) {\n_GLIBCXX_BEGIN_NAMESPACE_VERSION\n#else\nnamespace folly {\n#endif\n\n// Cannot depend on Portability.h when _LIBSTDCXX_FBSTRING.\n#if defined(__GNUC__)\n#define FOLLY_MALLOC_NOINLINE __attribute__((__noinline__))\n#if (__GNUC__ * 10000 + __GNUC_MINOR__ * 100 + __GNUC_PATCHLEVEL) >= 40900\n// This is for checked malloc-like functions (returns non-null pointer\n// which cannot alias any outstanding pointer).\n#define FOLLY_MALLOC_CHECKED_MALLOC                     \\\n  __attribute__((__returns_nonnull__, __malloc__))\n#else\n#define FOLLY_MALLOC_CHECKED_MALLOC __attribute__((__malloc__))\n#endif\n#else\n#define FOLLY_MALLOC_NOINLINE\n#define FOLLY_MALLOC_CHECKED_MALLOC\n#endif\n\n/**\n * Determine if we are using jemalloc or not.\n */\nFOLLY_MALLOC_NOINLINE inline bool usingJEMalloc() noexcept {\n  // Checking for rallocx != NULL is not sufficient; we may be in a dlopen()ed\n  // module that depends on libjemalloc, so rallocx is resolved, but the main\n  // program might be using a different memory allocator.\n  // How do we determine that we're using jemalloc? In the hackiest\n  // way possible. We allocate memory using malloc() and see if the\n  // per-thread counter of allocated memory increases. This makes me\n  // feel dirty inside. Also note that this requires jemalloc to have\n  // been compiled with --enable-stats.\n  static const bool result = [] () noexcept {\n    // Some platforms (*cough* OSX *cough*) require weak symbol checks to be\n    // in the form if (mallctl != nullptr). Not if (mallctl) or if (!mallctl)\n    // (!!). http://goo.gl/xpmctm\n    if (mallocx == nullptr || rallocx == nullptr || xallocx == nullptr\n        || sallocx == nullptr || dallocx == nullptr || sdallocx == nullptr\n        || nallocx == nullptr || mallctl == nullptr\n        || mallctlnametomib == nullptr || mallctlbymib == nullptr) {\n      return false;\n    }\n\n    // \"volatile\" because gcc optimizes out the reads from *counter, because\n    // it \"knows\" malloc doesn't modify global state...\n    /* nolint */ volatile uint64_t* counter;\n    size_t counterLen = sizeof(uint64_t*);\n\n    if (mallctl(\"thread.allocatedp\", static_cast<void*>(&counter), &counterLen,\n                nullptr, 0) != 0) {\n      return false;\n    }\n\n    if (counterLen != sizeof(uint64_t*)) {\n      return false;\n    }\n\n    uint64_t origAllocated = *counter;\n\n    // Static because otherwise clever compilers will find out that\n    // the ptr is not used and does not escape the scope, so they will\n    // just optimize away the malloc.\n    static const void* ptr = malloc(1);\n    if (!ptr) {\n      // wtf, failing to allocate 1 byte\n      return false;\n    }\n\n    return (origAllocated != *counter);\n  }();\n\n  return result;\n}\n\ninline size_t goodMallocSize(size_t minSize) noexcept {\n  if (minSize == 0) {\n    return 0;\n  }\n\n  if (!usingJEMalloc()) {\n    // Not using jemalloc - no smarts\n    return minSize;\n  }\n\n  return nallocx(minSize, 0);\n}\n\n// We always request \"good\" sizes for allocation, so jemalloc can\n// never grow in place small blocks; they're already occupied to the\n// brim.  Blocks larger than or equal to 4096 bytes can in fact be\n// expanded in place, and this constant reflects that.\nstatic const size_t jemallocMinInPlaceExpandable = 4096;\n\n/**\n * Trivial wrappers around malloc, calloc, realloc that check for allocation\n * failure and throw std::bad_alloc in that case.\n */\ninline void* checkedMalloc(size_t size) {\n  void* p = malloc(size);\n  if (!p) std::__throw_bad_alloc();\n  return p;\n}\n\ninline void* checkedCalloc(size_t n, size_t size) {\n  void* p = calloc(n, size);\n  if (!p) std::__throw_bad_alloc();\n  return p;\n}\n\ninline void* checkedRealloc(void* ptr, size_t size) {\n  void* p = realloc(ptr, size);\n  if (!p) std::__throw_bad_alloc();\n  return p;\n}\n\n/**\n * This function tries to reallocate a buffer of which only the first\n * currentSize bytes are used. The problem with using realloc is that\n * if currentSize is relatively small _and_ if realloc decides it\n * needs to move the memory chunk to a new buffer, then realloc ends\n * up copying data that is not used. It's impossible to hook into\n * GNU's malloc to figure whether expansion will occur in-place or as\n * a malloc-copy-free troika. (If an expand_in_place primitive would\n * be available, smartRealloc would use it.) As things stand, this\n * routine just tries to call realloc() (thus benefitting of potential\n * copy-free coalescing) unless there's too much slack memory.\n */\nFOLLY_MALLOC_CHECKED_MALLOC FOLLY_MALLOC_NOINLINE inline void* smartRealloc(\n    void* p,\n    const size_t currentSize,\n    const size_t currentCapacity,\n    const size_t newCapacity) {\n  assert(p);\n  assert(currentSize <= currentCapacity &&\n         currentCapacity < newCapacity);\n\n  if (usingJEMalloc()) {\n    // using jemalloc's API. Don't forget that jemalloc can never grow\n    // in place blocks smaller than 4096 bytes.\n    //\n    // NB: newCapacity may not be precisely equal to a jemalloc size class,\n    // i.e. newCapacity is not guaranteed to be the result of a\n    // goodMallocSize() call, therefore xallocx() may return more than\n    // newCapacity bytes of space.  Use >= rather than == to check whether\n    // xallocx() successfully expanded in place.\n    if (currentCapacity >= jemallocMinInPlaceExpandable &&\n        xallocx(p, newCapacity, 0, 0) >= newCapacity) {\n      // Managed to expand in place\n      return p;\n    }\n    // Cannot expand; must move\n    auto const result = checkedMalloc(newCapacity);\n    std::memcpy(result, p, currentSize);\n    free(p);\n    return result;\n  }\n\n  // No jemalloc no honey\n  auto const slack = currentCapacity - currentSize;\n  if (slack * 2 > currentSize) {\n    // Too much slack, malloc-copy-free cycle:\n    auto const result = checkedMalloc(newCapacity);\n    std::memcpy(result, p, currentSize);\n    free(p);\n    return result;\n  }\n  // If there's not too much slack, we realloc in hope of coalescing\n  return checkedRealloc(p, newCapacity);\n}\n\n#ifdef _LIBSTDCXX_FBSTRING\n_GLIBCXX_END_NAMESPACE_VERSION\n#endif\n\n} // folly\n\n#endif // !defined(_GLIBCXX_USE_FB) || defined(_LIBSTDCXX_FBSTRING)\n",
        "/tmp/vanessa/spack-stage/spack-stage-folly-2016.10.24.00-dz44s3v2vbl37w6qsb2lzwp2t5jy6f5w/spack-src/folly/detail/CacheLocality.cpp": "/*\n * Copyright 2016 Facebook, Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n#include <folly/detail/CacheLocality.h>\n\n#ifndef _MSC_VER\n#define _GNU_SOURCE 1 // for RTLD_NOLOAD\n#include <dlfcn.h>\n#endif\n#include <fstream>\n\n#include <folly/Conv.h>\n#include <folly/Exception.h>\n#include <folly/FileUtil.h>\n#include <folly/Format.h>\n#include <folly/ScopeGuard.h>\n\nnamespace folly {\nnamespace detail {\n\n///////////// CacheLocality\n\n/// Returns the best real CacheLocality information available\nstatic CacheLocality getSystemLocalityInfo() {\n#ifdef __linux__\n  try {\n    return CacheLocality::readFromSysfs();\n  } catch (...) {\n    // keep trying\n  }\n#endif\n\n  long numCpus = sysconf(_SC_NPROCESSORS_CONF);\n  if (numCpus <= 0) {\n    // This shouldn't happen, but if it does we should try to keep\n    // going.  We are probably not going to be able to parse /sys on\n    // this box either (although we will try), which means we are going\n    // to fall back to the SequentialThreadId splitter.  On my 16 core\n    // (x hyperthreading) dev box 16 stripes is enough to get pretty good\n    // contention avoidance with SequentialThreadId, and there is little\n    // improvement from going from 32 to 64.  This default gives us some\n    // wiggle room\n    numCpus = 32;\n  }\n  return CacheLocality::uniform(numCpus);\n}\n\ntemplate <>\nconst CacheLocality& CacheLocality::system<std::atomic>() {\n  static auto* cache = new CacheLocality(getSystemLocalityInfo());\n  return *cache;\n}\n\n// Each level of cache has sharing sets, which are the set of cpus\n// that share a common cache at that level.  These are available in a\n// hex bitset form (/sys/devices/system/cpu/cpu0/index0/shared_cpu_map,\n// for example).  They are also available in a human-readable list form,\n// as in /sys/devices/system/cpu/cpu0/index0/shared_cpu_list.  The list\n// is a comma-separated list of numbers and ranges, where the ranges are\n// a pair of decimal numbers separated by a '-'.\n//\n// To sort the cpus for optimum locality we don't really need to parse\n// the sharing sets, we just need a unique representative from the\n// equivalence class.  The smallest value works fine, and happens to be\n// the first decimal number in the file.  We load all of the equivalence\n// class information from all of the cpu*/index* directories, order the\n// cpus first by increasing last-level cache equivalence class, then by\n// the smaller caches.  Finally, we break ties with the cpu number itself.\n\n/// Returns the first decimal number in the string, or throws an exception\n/// if the string does not start with a number terminated by ',', '-',\n/// '\\n', or eos.\nstatic size_t parseLeadingNumber(const std::string& line) {\n  auto raw = line.c_str();\n  char* end;\n  unsigned long val = strtoul(raw, &end, 10);\n  if (end == raw || (*end != ',' && *end != '-' && *end != '\\n' && *end != 0)) {\n    throw std::runtime_error(\n        to<std::string>(\"error parsing list '\", line, \"'\").c_str());\n  }\n  return val;\n}\n\nCacheLocality CacheLocality::readFromSysfsTree(\n    const std::function<std::string(std::string)>& mapping) {\n  // number of equivalence classes per level\n  std::vector<size_t> numCachesByLevel;\n\n  // the list of cache equivalence classes, where equivalance classes\n  // are named by the smallest cpu in the class\n  std::vector<std::vector<size_t>> equivClassesByCpu;\n\n  std::vector<size_t> cpus;\n\n  while (true) {\n    auto cpu = cpus.size();\n    std::vector<size_t> levels;\n    for (size_t index = 0;; ++index) {\n      auto dir =\n          sformat(\"/sys/devices/system/cpu/cpu{}/cache/index{}/\", cpu, index);\n      auto cacheType = mapping(dir + \"type\");\n      auto equivStr = mapping(dir + \"shared_cpu_list\");\n      if (cacheType.size() == 0 || equivStr.size() == 0) {\n        // no more caches\n        break;\n      }\n      if (cacheType[0] == 'I') {\n        // cacheType in { \"Data\", \"Instruction\", \"Unified\" }. skip icache\n        continue;\n      }\n      auto equiv = parseLeadingNumber(equivStr);\n      auto level = levels.size();\n      levels.push_back(equiv);\n\n      if (equiv == cpu) {\n        // we only want to count the equiv classes once, so we do it when\n        // we first encounter them\n        while (numCachesByLevel.size() <= level) {\n          numCachesByLevel.push_back(0);\n        }\n        numCachesByLevel[level]++;\n      }\n    }\n\n    if (levels.size() == 0) {\n      // no levels at all for this cpu, we must be done\n      break;\n    }\n    equivClassesByCpu.emplace_back(std::move(levels));\n    cpus.push_back(cpu);\n  }\n\n  if (cpus.size() == 0) {\n    throw std::runtime_error(\"unable to load cache sharing info\");\n  }\n\n  std::sort(cpus.begin(),\n            cpus.end(),\n            [&](size_t lhs, size_t rhs) -> bool {\n              // sort first by equiv class of cache with highest index,\n              // direction doesn't matter.  If different cpus have\n              // different numbers of caches then this code might produce\n              // a sub-optimal ordering, but it won't crash\n              auto& lhsEquiv = equivClassesByCpu[lhs];\n              auto& rhsEquiv = equivClassesByCpu[rhs];\n              for (int i = std::min(lhsEquiv.size(), rhsEquiv.size()) - 1;\n                   i >= 0;\n                   --i) {\n                if (lhsEquiv[i] != rhsEquiv[i]) {\n                  return lhsEquiv[i] < rhsEquiv[i];\n                }\n              }\n\n              // break ties deterministically by cpu\n              return lhs < rhs;\n            });\n\n  // the cpus are now sorted by locality, with neighboring entries closer\n  // to each other than entries that are far away.  For striping we want\n  // the inverse map, since we are starting with the cpu\n  std::vector<size_t> indexes(cpus.size());\n  for (size_t i = 0; i < cpus.size(); ++i) {\n    indexes[cpus[i]] = i;\n  }\n\n  return CacheLocality{\n      cpus.size(), std::move(numCachesByLevel), std::move(indexes)};\n}\n\nCacheLocality CacheLocality::readFromSysfs() {\n  return readFromSysfsTree([](std::string name) {\n    std::ifstream xi(name.c_str());\n    std::string rv;\n    std::getline(xi, rv);\n    return rv;\n  });\n}\n\nCacheLocality CacheLocality::uniform(size_t numCpus) {\n  CacheLocality rv;\n\n  rv.numCpus = numCpus;\n\n  // one cache shared by all cpus\n  rv.numCachesByLevel.push_back(numCpus);\n\n  // no permutations in locality index mapping\n  for (size_t cpu = 0; cpu < numCpus; ++cpu) {\n    rv.localityIndexByCpu.push_back(cpu);\n  }\n\n  return rv;\n}\n\n////////////// Getcpu\n\nGetcpu::Func Getcpu::resolveVdsoFunc() {\n#if !FOLLY_HAVE_LINUX_VDSO\n  return nullptr;\n#else\n  void* h = dlopen(\"linux-vdso.so.1\", RTLD_LAZY | RTLD_LOCAL | RTLD_NOLOAD);\n  if (h == nullptr) {\n    return nullptr;\n  }\n\n  auto func = Getcpu::Func(dlsym(h, \"__vdso_getcpu\"));\n  if (func == nullptr) {\n    // technically a null result could either be a failure or a successful\n    // lookup of a symbol with the null value, but the second can't actually\n    // happen for this symbol.  No point holding the handle forever if\n    // we don't need the code\n    dlclose(h);\n  }\n\n  return func;\n#endif\n}\n\n#ifdef FOLLY_TLS\n/////////////// SequentialThreadId\ntemplate struct SequentialThreadId<std::atomic>;\n#endif\n\n/////////////// AccessSpreader\ntemplate struct AccessSpreader<std::atomic>;\n\n} // namespace detail\n} // namespace folly\n",
        "/tmp/vanessa/spack-stage/spack-stage-folly-2016.10.24.00-dz44s3v2vbl37w6qsb2lzwp2t5jy6f5w/spack-src/folly/test/ThreadLocalTest.cpp": "/*\n * Copyright 2016 Facebook, Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n#include <folly/ThreadLocal.h>\n\n#ifndef _WIN32\n#include <dlfcn.h>\n#include <sys/wait.h>\n#endif\n\n#include <sys/types.h>\n\n#include <array>\n#include <atomic>\n#include <chrono>\n#include <condition_variable>\n#include <limits.h>\n#include <map>\n#include <mutex>\n#include <set>\n#include <thread>\n#include <unordered_map>\n\n#include <glog/logging.h>\n\n#include <folly/Baton.h>\n#include <folly/Memory.h>\n#include <folly/experimental/io/FsUtil.h>\n#include <folly/portability/GTest.h>\n#include <folly/portability/Unistd.h>\n\nusing namespace folly;\n\nstruct Widget {\n  static int totalVal_;\n  int val_;\n  ~Widget() {\n    totalVal_ += val_;\n  }\n\n  static void customDeleter(Widget* w, TLPDestructionMode mode) {\n    totalVal_ += (mode == TLPDestructionMode::ALL_THREADS) ? 1000 : 1;\n    delete w;\n  }\n};\nint Widget::totalVal_ = 0;\n\nTEST(ThreadLocalPtr, BasicDestructor) {\n  Widget::totalVal_ = 0;\n  ThreadLocalPtr<Widget> w;\n  std::thread([&w]() {\n      w.reset(new Widget());\n      w.get()->val_ += 10;\n    }).join();\n  EXPECT_EQ(10, Widget::totalVal_);\n}\n\nTEST(ThreadLocalPtr, CustomDeleter1) {\n  Widget::totalVal_ = 0;\n  {\n    ThreadLocalPtr<Widget> w;\n    std::thread([&w]() {\n        w.reset(new Widget(), Widget::customDeleter);\n        w.get()->val_ += 10;\n      }).join();\n    EXPECT_EQ(11, Widget::totalVal_);\n  }\n  EXPECT_EQ(11, Widget::totalVal_);\n}\n\nTEST(ThreadLocalPtr, CustomDeleterOwnershipTransfer) {\n  Widget::totalVal_ = 0;\n  {\n    ThreadLocalPtr<Widget> w;\n    auto deleter = [](Widget* ptr) {\n      Widget::customDeleter(ptr, TLPDestructionMode::THIS_THREAD);\n    };\n    std::unique_ptr<Widget, decltype(deleter)> source(new Widget(), deleter);\n    std::thread([&w, &source]() {\n      w.reset(std::move(source));\n      w.get()->val_ += 10;\n    }).join();\n    EXPECT_EQ(11, Widget::totalVal_);\n  }\n  EXPECT_EQ(11, Widget::totalVal_);\n}\n\nTEST(ThreadLocalPtr, DefaultDeleterOwnershipTransfer) {\n  Widget::totalVal_ = 0;\n  {\n    ThreadLocalPtr<Widget> w;\n    auto source = folly::make_unique<Widget>();\n    std::thread([&w, &source]() {\n      w.reset(std::move(source));\n      w.get()->val_ += 10;\n    }).join();\n    EXPECT_EQ(10, Widget::totalVal_);\n  }\n  EXPECT_EQ(10, Widget::totalVal_);\n}\n\nTEST(ThreadLocalPtr, resetNull) {\n  ThreadLocalPtr<int> tl;\n  EXPECT_FALSE(tl);\n  tl.reset(new int(4));\n  EXPECT_TRUE(static_cast<bool>(tl));\n  EXPECT_EQ(*tl.get(), 4);\n  tl.reset();\n  EXPECT_FALSE(tl);\n}\n\nTEST(ThreadLocalPtr, TestRelease) {\n  Widget::totalVal_ = 0;\n  ThreadLocalPtr<Widget> w;\n  std::unique_ptr<Widget> wPtr;\n  std::thread([&w, &wPtr]() {\n      w.reset(new Widget());\n      w.get()->val_ += 10;\n\n      wPtr.reset(w.release());\n    }).join();\n  EXPECT_EQ(0, Widget::totalVal_);\n  wPtr.reset();\n  EXPECT_EQ(10, Widget::totalVal_);\n}\n\nTEST(ThreadLocalPtr, CreateOnThreadExit) {\n  Widget::totalVal_ = 0;\n  ThreadLocal<Widget> w;\n  ThreadLocalPtr<int> tl;\n\n  std::thread([&] {\n    tl.reset(new int(1),\n             [&](int* ptr, TLPDestructionMode /* mode */) {\n               delete ptr;\n               // This test ensures Widgets allocated here are not leaked.\n               ++w.get()->val_;\n               ThreadLocal<Widget> wl;\n               ++wl.get()->val_;\n             });\n  }).join();\n  EXPECT_EQ(2, Widget::totalVal_);\n}\n\n// Test deleting the ThreadLocalPtr object\nTEST(ThreadLocalPtr, CustomDeleter2) {\n  Widget::totalVal_ = 0;\n  std::thread t;\n  std::mutex mutex;\n  std::condition_variable cv;\n  enum class State {\n    START,\n    DONE,\n    EXIT\n  };\n  State state = State::START;\n  {\n    ThreadLocalPtr<Widget> w;\n    t = std::thread([&]() {\n        w.reset(new Widget(), Widget::customDeleter);\n        w.get()->val_ += 10;\n\n        // Notify main thread that we're done\n        {\n          std::unique_lock<std::mutex> lock(mutex);\n          state = State::DONE;\n          cv.notify_all();\n        }\n\n        // Wait for main thread to allow us to exit\n        {\n          std::unique_lock<std::mutex> lock(mutex);\n          while (state != State::EXIT) {\n            cv.wait(lock);\n          }\n        }\n    });\n\n    // Wait for main thread to start (and set w.get()->val_)\n    {\n      std::unique_lock<std::mutex> lock(mutex);\n      while (state != State::DONE) {\n        cv.wait(lock);\n      }\n    }\n\n    // Thread started but hasn't exited yet\n    EXPECT_EQ(0, Widget::totalVal_);\n\n    // Destroy ThreadLocalPtr<Widget> (by letting it go out of scope)\n  }\n\n  EXPECT_EQ(1010, Widget::totalVal_);\n\n  // Allow thread to exit\n  {\n    std::unique_lock<std::mutex> lock(mutex);\n    state = State::EXIT;\n    cv.notify_all();\n  }\n  t.join();\n\n  EXPECT_EQ(1010, Widget::totalVal_);\n}\n\nTEST(ThreadLocal, BasicDestructor) {\n  Widget::totalVal_ = 0;\n  ThreadLocal<Widget> w;\n  std::thread([&w]() { w->val_ += 10; }).join();\n  EXPECT_EQ(10, Widget::totalVal_);\n}\n\nTEST(ThreadLocal, SimpleRepeatDestructor) {\n  Widget::totalVal_ = 0;\n  {\n    ThreadLocal<Widget> w;\n    w->val_ += 10;\n  }\n  {\n    ThreadLocal<Widget> w;\n    w->val_ += 10;\n  }\n  EXPECT_EQ(20, Widget::totalVal_);\n}\n\nTEST(ThreadLocal, InterleavedDestructors) {\n  Widget::totalVal_ = 0;\n  std::unique_ptr<ThreadLocal<Widget>> w;\n  int wVersion = 0;\n  const int wVersionMax = 2;\n  int thIter = 0;\n  std::mutex lock;\n  auto th = std::thread([&]() {\n    int wVersionPrev = 0;\n    while (true) {\n      while (true) {\n        std::lock_guard<std::mutex> g(lock);\n        if (wVersion > wVersionMax) {\n          return;\n        }\n        if (wVersion > wVersionPrev) {\n          // We have a new version of w, so it should be initialized to zero\n          EXPECT_EQ((*w)->val_, 0);\n          break;\n        }\n      }\n      std::lock_guard<std::mutex> g(lock);\n      wVersionPrev = wVersion;\n      (*w)->val_ += 10;\n      ++thIter;\n    }\n  });\n  FOR_EACH_RANGE(i, 0, wVersionMax) {\n    int thIterPrev = 0;\n    {\n      std::lock_guard<std::mutex> g(lock);\n      thIterPrev = thIter;\n      w.reset(new ThreadLocal<Widget>());\n      ++wVersion;\n    }\n    while (true) {\n      std::lock_guard<std::mutex> g(lock);\n      if (thIter > thIterPrev) {\n        break;\n      }\n    }\n  }\n  {\n    std::lock_guard<std::mutex> g(lock);\n    wVersion = wVersionMax + 1;\n  }\n  th.join();\n  EXPECT_EQ(wVersionMax * 10, Widget::totalVal_);\n}\n\nclass SimpleThreadCachedInt {\n\n  class NewTag;\n  ThreadLocal<int,NewTag> val_;\n\n public:\n  void add(int val) {\n    *val_ += val;\n  }\n\n  int read() {\n    int ret = 0;\n    for (const auto& i : val_.accessAllThreads()) {\n      ret += i;\n    }\n    return ret;\n  }\n};\n\nTEST(ThreadLocalPtr, AccessAllThreadsCounter) {\n  const int kNumThreads = 10;\n  SimpleThreadCachedInt stci;\n  std::atomic<bool> run(true);\n  std::atomic<int> totalAtomic(0);\n  std::vector<std::thread> threads;\n  for (int i = 0; i < kNumThreads; ++i) {\n    threads.push_back(std::thread([&,i]() {\n      stci.add(1);\n      totalAtomic.fetch_add(1);\n      while (run.load()) { usleep(100); }\n    }));\n  }\n  while (totalAtomic.load() != kNumThreads) { usleep(100); }\n  EXPECT_EQ(kNumThreads, stci.read());\n  run.store(false);\n  for (auto& t : threads) {\n    t.join();\n  }\n}\n\nTEST(ThreadLocal, resetNull) {\n  ThreadLocal<int> tl;\n  tl.reset(new int(4));\n  EXPECT_EQ(*tl.get(), 4);\n  tl.reset();\n  EXPECT_EQ(*tl.get(), 0);\n  tl.reset(new int(5));\n  EXPECT_EQ(*tl.get(), 5);\n}\n\nnamespace {\nstruct Tag {};\n\nstruct Foo {\n  folly::ThreadLocal<int, Tag> tl;\n};\n}  // namespace\n\nTEST(ThreadLocal, Movable1) {\n  Foo a;\n  Foo b;\n  EXPECT_TRUE(a.tl.get() != b.tl.get());\n\n  a = Foo();\n  b = Foo();\n  EXPECT_TRUE(a.tl.get() != b.tl.get());\n}\n\nTEST(ThreadLocal, Movable2) {\n  std::map<int, Foo> map;\n\n  map[42];\n  map[10];\n  map[23];\n  map[100];\n\n  std::set<void*> tls;\n  for (auto& m : map) {\n    tls.insert(m.second.tl.get());\n  }\n\n  // Make sure that we have 4 different instances of *tl\n  EXPECT_EQ(4, tls.size());\n}\n\nnamespace {\n\nconstexpr size_t kFillObjectSize = 300;\n\nstd::atomic<uint64_t> gDestroyed;\n\n/**\n * Fill a chunk of memory with a unique-ish pattern that includes the thread id\n * (so deleting one of these from another thread would cause a failure)\n *\n * Verify it explicitly and on destruction.\n */\nclass FillObject {\n public:\n  explicit FillObject(uint64_t idx) : idx_(idx) {\n    uint64_t v = val();\n    for (size_t i = 0; i < kFillObjectSize; ++i) {\n      data_[i] = v;\n    }\n  }\n\n  void check() {\n    uint64_t v = val();\n    for (size_t i = 0; i < kFillObjectSize; ++i) {\n      CHECK_EQ(v, data_[i]);\n    }\n  }\n\n  ~FillObject() {\n    ++gDestroyed;\n  }\n\n private:\n  uint64_t val() const {\n    return (idx_ << 40) | uint64_t(pthread_self());\n  }\n\n  uint64_t idx_;\n  uint64_t data_[kFillObjectSize];\n};\n\n}  // namespace\n\n#if FOLLY_HAVE_STD_THIS_THREAD_SLEEP_FOR\nTEST(ThreadLocal, Stress) {\n  constexpr size_t numFillObjects = 250;\n  std::array<ThreadLocalPtr<FillObject>, numFillObjects> objects;\n\n  constexpr size_t numThreads = 32;\n  constexpr size_t numReps = 20;\n\n  std::vector<std::thread> threads;\n  threads.reserve(numThreads);\n\n  for (size_t k = 0; k < numThreads; ++k) {\n    threads.emplace_back([&objects] {\n      for (size_t rep = 0; rep < numReps; ++rep) {\n        for (size_t i = 0; i < objects.size(); ++i) {\n          objects[i].reset(new FillObject(rep * objects.size() + i));\n          std::this_thread::sleep_for(std::chrono::microseconds(100));\n        }\n        for (size_t i = 0; i < objects.size(); ++i) {\n          objects[i]->check();\n        }\n      }\n    });\n  }\n\n  for (auto& t : threads) {\n    t.join();\n  }\n\n  EXPECT_EQ(numFillObjects * numThreads * numReps, gDestroyed);\n}\n#endif\n\n// Yes, threads and fork don't mix\n// (http://cppwisdom.quora.com/Why-threads-and-fork-dont-mix) but if you're\n// stupid or desperate enough to try, we shouldn't stand in your way.\nnamespace {\nclass HoldsOne {\n public:\n  HoldsOne() : value_(1) { }\n  // Do an actual access to catch the buggy case where this == nullptr\n  int value() const { return value_; }\n private:\n  int value_;\n};\n\nstruct HoldsOneTag {};\n\nThreadLocal<HoldsOne, HoldsOneTag> ptr;\n\nint totalValue() {\n  int value = 0;\n  for (auto& p : ptr.accessAllThreads()) {\n    value += p.value();\n  }\n  return value;\n}\n\n}  // namespace\n\n#ifdef FOLLY_HAVE_PTHREAD_ATFORK\nTEST(ThreadLocal, Fork) {\n  EXPECT_EQ(1, ptr->value());  // ensure created\n  EXPECT_EQ(1, totalValue());\n  // Spawn a new thread\n\n  std::mutex mutex;\n  bool started = false;\n  std::condition_variable startedCond;\n  bool stopped = false;\n  std::condition_variable stoppedCond;\n\n  std::thread t([&] () {\n    EXPECT_EQ(1, ptr->value());  // ensure created\n    {\n      std::unique_lock<std::mutex> lock(mutex);\n      started = true;\n      startedCond.notify_all();\n    }\n    {\n      std::unique_lock<std::mutex> lock(mutex);\n      while (!stopped) {\n        stoppedCond.wait(lock);\n      }\n    }\n  });\n\n  {\n    std::unique_lock<std::mutex> lock(mutex);\n    while (!started) {\n      startedCond.wait(lock);\n    }\n  }\n\n  EXPECT_EQ(2, totalValue());\n\n  pid_t pid = fork();\n  if (pid == 0) {\n    // in child\n    int v = totalValue();\n\n    // exit successfully if v == 1 (one thread)\n    // diagnostic error code otherwise :)\n    switch (v) {\n    case 1: _exit(0);\n    case 0: _exit(1);\n    }\n    _exit(2);\n  } else if (pid > 0) {\n    // in parent\n    int status;\n    EXPECT_EQ(pid, waitpid(pid, &status, 0));\n    EXPECT_TRUE(WIFEXITED(status));\n    EXPECT_EQ(0, WEXITSTATUS(status));\n  } else {\n    EXPECT_TRUE(false) << \"fork failed\";\n  }\n\n  EXPECT_EQ(2, totalValue());\n\n  {\n    std::unique_lock<std::mutex> lock(mutex);\n    stopped = true;\n    stoppedCond.notify_all();\n  }\n\n  t.join();\n\n  EXPECT_EQ(1, totalValue());\n}\n#endif\n\n#ifndef _WIN32\nstruct HoldsOneTag2 {};\n\nTEST(ThreadLocal, Fork2) {\n  // A thread-local tag that was used in the parent from a *different* thread\n  // (but not the forking thread) would cause the child to hang in a\n  // ThreadLocalPtr's object destructor. Yeah.\n  ThreadLocal<HoldsOne, HoldsOneTag2> p;\n  {\n    // use tag in different thread\n    std::thread t([&p] { p.get(); });\n    t.join();\n  }\n  pid_t pid = fork();\n  if (pid == 0) {\n    {\n      ThreadLocal<HoldsOne, HoldsOneTag2> q;\n      q.get();\n    }\n    _exit(0);\n  } else if (pid > 0) {\n    int status;\n    EXPECT_EQ(pid, waitpid(pid, &status, 0));\n    EXPECT_TRUE(WIFEXITED(status));\n    EXPECT_EQ(0, WEXITSTATUS(status));\n  } else {\n    EXPECT_TRUE(false) << \"fork failed\";\n  }\n}\n\n// Elide this test when using any sanitizer. Otherwise, the dlopen'ed code\n// would end up running without e.g., ASAN-initialized data structures and\n// failing right away.\n#if !defined FOLLY_SANITIZE_ADDRESS && !defined UNDEFINED_SANITIZER && \\\n    !defined FOLLY_SANITIZE_THREAD\n\nTEST(ThreadLocal, SharedLibrary) {\n  auto exe = fs::executable_path();\n  auto lib = exe.parent_path() / \"lib_thread_local_test.so\";\n  auto handle = dlopen(lib.string().c_str(), RTLD_LAZY);\n  EXPECT_NE(nullptr, handle);\n\n  typedef void (*useA_t)();\n  dlerror();\n  useA_t useA = (useA_t) dlsym(handle, \"useA\");\n\n  const char *dlsym_error = dlerror();\n  EXPECT_EQ(nullptr, dlsym_error);\n\n  useA();\n\n  folly::Baton<> b11, b12, b21, b22;\n\n  std::thread t1([&]() {\n      useA();\n      b11.post();\n      b12.wait();\n    });\n\n  std::thread t2([&]() {\n      useA();\n      b21.post();\n      b22.wait();\n    });\n\n  b11.wait();\n  b21.wait();\n\n  dlclose(handle);\n\n  b12.post();\n  b22.post();\n\n  t1.join();\n  t2.join();\n}\n\n#endif\n#endif\n\nnamespace folly { namespace threadlocal_detail {\nstruct PthreadKeyUnregisterTester {\n  PthreadKeyUnregister p;\n  constexpr PthreadKeyUnregisterTester() = default;\n};\n}}\n\nTEST(ThreadLocal, UnregisterClassHasConstExprCtor) {\n  folly::threadlocal_detail::PthreadKeyUnregisterTester x;\n  // yep!\n  SUCCEED();\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-folly-2016.10.24.00-dz44s3v2vbl37w6qsb2lzwp2t5jy6f5w/spack-src/folly/docs/Overview.md": "### `folly/`\n\nFor a high level overview see the [README](../../README.md)\n\n### Components\n\nBelow is a list of (some) Folly components in alphabetical order, along with\na brief description of each.\n\n#### `Arena.h`, `ThreadCachedArena.h`\n\nSimple arena for memory allocation: multiple allocations get freed all\nat once. With threaded version.\n\n#### [`AtomicHashMap.h`, `AtomicHashArray.h`](AtomicHashMap.md), `AtomicHashArray.h`, `AtomicLinkedList.h`, ...\n\nHigh-performance atomic data-structures. Many of these are built with very specific\ntradeoffs and constraints in mind that make them faster than their more general\ncounterparts. Each header should contain information about what these tradeoffs are.\n\n#### `Baton.h`\n\nA Baton allows a thread to block once and be awoken: it captures a single handoff. It is\nessentially a (very small, very fast) semaphore that supports only a single call to `sem_call`\nand `sem_wait`.\n\n#### [`Benchmark.h`](Benchmark.md)\n\nA small framework for benchmarking code. Client code registers\nbenchmarks, optionally with an argument that dictates the scale of the\nbenchmark (iterations, working set size etc). The framework runs\nbenchmarks (subject to a command-line flag) and produces formatted\noutput with timing information.\n\n#### `Bits.h`\n\nVarious bit manipulation utilities optimized for speed; includes functions\nthat wrap the\n[ffsl(l)](http://linux.die.net/man/3/ffsll) primitives in a uniform\ninterface.\n\n#### `ConcurrentSkipList.h`\n\nAn implementation of the structure described in [A Provably Correct\nScalable Concurrent Skip\nList](http://www.cs.tau.ac.il/~shanir/nir-pubs-web/Papers/OPODIS2006-BA.pdf)\nby Herlihy et al.\n\n#### [`Conv.h`](Conv.md)\n\nA variety of data conversion routines (notably to and from string),\noptimized for speed and safety.\n\n#### `Demangle.h`\n\nPretty-printing C++ types.\n\n#### `DiscriminatedPtr.h`\n\nSimilar to `boost::variant`, but restricted to pointers only. Uses the\nhighest-order unused 16 bits in a pointer as discriminator. So\n`sizeof(DiscriminatedPtr<int, string, Widget>) == sizeof(void*)`.\n\n#### [`dynamic.h`](Dynamic.md)\n\nDynamically-typed object, created with JSON objects in mind. `DynamicConverter.h` is\na utility for effeciently converting from a `dynamic` to a more concrete structure when\nthe scheme is known (e.g. json -> `map<int,int>`).\n\n#### `EvictingCacheMap.h`\n\nA simple LRU hash map.\n\n####[`FBString.h`](FBString.md)\n\nA drop-in implementation of `std::string` with a variety of optimizations.\n\n####[`FBVector.h`](FBVector.md)\n\nA mostly drop-in implementation of `std::vector` with a variety of\noptimizations.\n\n#### `File.h`\n\nA C++ abstraction around files.\n\n#### `Fingerprint.h`\n\nRabin fingerprinting.\n\n### [`Function.h`](Function.md)\n\nA polymorphic wrapper for callables similar to `std::function` but not copyable and therefore able to wrap non-copyable callables, such as lambdas that capture move-only types like `std::unique_ptr` or `folly::Promise`.\n\n### [`futures/`](../futures/README.md)\n\nFutures is a framework for expressing asynchronous code in C++ using the Promise/Future pattern.\n\n####[`Format.h`](Format.md)\n\nPython-style formatting utilities.\n\n#### `gen/`\n\nThis library makes it possible to write declarative comprehensions for\nprocessing sequences of values efficiently in C++ akin to C#'s LINQ.\n\n####[`GroupVarint.h`](GroupVarint.md)\n\n[Group Varint\nencoding](http://www.ir.uwaterloo.ca/book/addenda-06-index-compression.html)\nfor 32-bit values.\n\n####`IpAddress.h`\n\nA collection of utilities to deal with IPAddresses, including ipv4 and ipv6.\n\n#### `io/`\n\nA collection of useful of abstractions for high-performance io. This is heavily relied upon\nin Facebook's internally networking code.\n\n####`Hash.h`\n\nVarious popular hash function implementations.\n\n####[`Histogram.h`](Histogram.md)\n\nA simple class for collecting histogram data.\n\n####`IntrusiveList.h`\n\nConvenience type definitions for using `boost::intrusive_list`.\n\n####`json.h`\n\nJSON serializer and deserializer. Uses `dynamic.h`.\n\n####`Likely.h`\n\nWrappers around [`__builtin_expect`](http://gcc.gnu.org/onlinedocs/gcc/Other-Builtins.html).\n\n####`Malloc.h`, `Memory.h`\n\nMemory allocation helpers, particularly when using jemalloc.\n\n####`MicroSpinLock.h`\n\nA really, *really* small spinlock for fine-grained locking of lots of teeny-tiny data.\n\n####`MPMCQueue.h`\n\nMPMCQueue<typename> is a high-performance bounded concurrent queue that\nsupports multiple producers, multiple consumers, and optional blocking.\nThe queue has a fixed capacity, for which all memory will be allocated\n up front.\n\nThe additional utility `MPMCPipeline.h` is an extension that lets you\nchain several queues together with processing steps in between.\n\n####[`PackedSyncPtr.h`](PackedSyncPtr.md)\n\nA highly specialized data structure consisting of a pointer, a 1-bit\nspin lock, and a 15-bit integral, all inside one 64-bit word.\n\n####`Preprocessor.h`\n\nNecessarily evil stuff.\n\n####[`ProducerConsumerQueue.h`](ProducerConsumerQueue.md)\n\nLock free single-reader, single-writer queue.\n\n####`Random.h`\n\nDefines only one function---`randomNumberSeed()`.\n\n####`Range.h`\n\nBoost-style range facility and the `StringPiece` specialization.\n\n####`RWSpinLock.h`\n\nFast and compact reader-writer spin lock.\n\n####`ScopeGuard.h`\n\nC++11 incarnation of the old [ScopeGuard](http://drdobbs.com/184403758) idiom.\n\n####`Singleton.h`\n\nA singleton to rule the singletons. This is an attempt to insert a layer between\nC++ statics and the fiasco that ensues, so that things can be created, and destroyed,\ncorrectly upon program creation, program end and sometimes `dlopen` and `fork`.\n\nSingletons are bad for you, but this may help.\n\n####[`SmallLocks.h`](SmallLocks.md)\n\nVery small spin locks (1 byte and 1 bit).\n\n####`small_vector.h`\n\nVector with the small buffer optimization and an optional embedded\n`PicoSpinLock`.\n\n####`sorted_vector_types.h`\n\nCollections similar to `std::map` but implemented as sorted vectors.\n\n#### `stats/`\n\nA collection of efficient utilities for collecting statistics (often of\ntime series data).\n\n####`StlAllocator.h`\n\nSTL allocator wrapping a simple allocate/deallocate interface.\n\n####`String.h`\n\nString utilities that connect `folly::fbstring` with `std::string`.\n\n####`Subprocess.h`\n\nSubprocess library, modeled after Python's subprocess module.\n\n####[`Synchronized.h`](Synchronized.md)\n\nHigh-level synchronization library.\n\n####`System.h`\n\nDemangling and errno utilities.\n\n####[`ThreadCachedInt.h`](ThreadCachedInt.md)\n\nHigh-performance atomic increment using thread caching.\n\n####[`ThreadLocal.h`](ThreadLocal.md)\n\nImproved thread local storage for non-trivial types.\n\n####`TimeoutQueue.h`\n\nQueue with per-item timeout.\n\n####`Traits.h`\n\nType traits that complement those defined in the standard C++11 header\n`<traits>`.\n\n####`Unicode.h`\n\nDefines the `codePointToUtf8` function.\n\n####`Uri.h`\n\nA collection of utilities to deal with URIs."
    },
    "skipped": [
        "/tmp/vanessa/spack-stage/spack-stage-folly-2016.10.24.00-dz44s3v2vbl37w6qsb2lzwp2t5jy6f5w/spack-src/folly/docs/Fbvector--graphical_solutions.png"
    ],
    "total_files": 906
}