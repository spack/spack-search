{
    "matches": {
        "/tmp/vanessa/spack-stage/spack-stage-qcachegrind-20.08.0-oxxtqoalamluitigegnz4wltg5kjf7xd/spack-src/doc/index.docbook": "<?xml version=\"1.0\" ?>\n<!DOCTYPE book PUBLIC \"-//KDE//DTD DocBook XML V4.5-Based Variant V1.1//EN\" \"dtd/kdedbx45.dtd\" [\n  <!ENTITY kcachegrind '<application>KCachegrind</application>'>\n  <!ENTITY cachegrind \"<application>Cachegrind</application>\">\n  <!ENTITY calltree \"<application>Calltree</application>\">\n  <!ENTITY callgrind \"<application>Callgrind</application>\">\n  <!ENTITY valgrind \"<application>Valgrind</application>\">\n  <!ENTITY oprofile \"<application>OProfile</application>\">\n  <!ENTITY EBS \"<acronym>EBS</acronym>\">\n  <!ENTITY TBS \"<acronym>TBS</acronym>\">\n  <!ENTITY % addindex \"IGNORE\">\n  <!ENTITY % English \"INCLUDE\">\n]>\n\n<book id=\"kcachegrind\" lang=\"&language;\">\n\n<bookinfo>\n<title>The &kcachegrind; Handbook</title>\n\n<authorgroup>\n<author>\n<firstname>Josef</firstname>\n<surname>Weidendorfer</surname>\n<affiliation>\n<address><email>Josef.Weidendorfer@gmx.de</email></address>\n</affiliation>\n<contrib>Original author of the documentation</contrib>\n</author>\n\n<author>\n<firstname>Federico</firstname>\n<surname>Zenith</surname>\n<affiliation>\n<address><email>federico.zenith@member.fsf.org</email></address>\n</affiliation>\n<contrib>Updates and corrections</contrib>\n</author>\n\n<!-- TRANS:ROLES_OF_TRANSLATORS -->\n\n</authorgroup>\n\n<copyright>\n<year>2002-2004</year>\n<holder>&Josef.Weidendorfer;</holder>\t\n</copyright>\n<copyright>\n<year>2009</year>\n<holder>Federico Zenith</holder>\n</copyright>\n<legalnotice>&FDLNotice;</legalnotice>\n\n<date>2016-11-18</date>\n<releaseinfo>0.8.0 (Applications 17.04)</releaseinfo>\n\n<abstract>\n<para>\n&kcachegrind; is a profile data visualization tool, written using &kf5-full;.\n</para>\n</abstract>\n\n<keywordset>\n<keyword>KDE</keyword>\n<keyword>kdesdk</keyword>\n<keyword>Cachegrind</keyword>\n<keyword>Callgrind</keyword>\n<keyword>Valgrind</keyword>\n<keyword>Profiling</keyword>\n</keywordset>\n\n</bookinfo>\n\n\n<chapter id=\"introduction\">\n<title>Introduction</title>\n\n<para>\n&kcachegrind; is a browser for data produced by profiling tools.\nThis chapter explains what profiling is for, how it is done, and\ngives some examples of profiling tools available.\n</para>\n\n<sect1 id=\"introduction-profiling\">\n<title>Profiling</title>\n\n<para>\nWhen developing a program, one of the last steps often involves performance\noptimizations.  As it makes no sense to optimize functions rarely used, because\nthat would be a waste of time, one needs to know in which part of a program most\nof the time is spent.\n</para>\n\n<para>\nFor sequential code, collecting statistical data of the programs runtime\ncharacteristic like time numbers spent in functions and code lines usually is\nenough.\nThis is called Profiling. The program is run under control of a profiling tool,\nwhich gives the summary of an execution run at the end.\nIn contrast, for parallel code, performance problems typically are caused when\none processor is waiting for data from another. As this waiting time usually\ncannot easily attributed, here it is better to generate timestamped event\ntraces. &kcachegrind; cannot visualize this kind of data.\n</para>\n\n<para>\nAfter analyzing the produced profile data, it should be easy to see the hot\nspots and bottlenecks of the code: for example, assumptions about call counts\ncan be checked, and identified code regions can be optimized.\nAfterwards, the success of the optimization should be verified with another\nprofile run.\n</para>\n</sect1>\n\n<sect1 id=\"introduction-methods\">\n<title>Profiling Methods</title>\n\n<para>To exactly measure the time passed or record the events happening during\nthe execution of a code region (&eg; a function), additional measurement code\nneeds to be inserted before and after the given region. This code reads the\ntime, or a global event count, and calculates differences. Thus, the original\ncode has to be changed before execution. This is called instrumentation.\nInstrumentation can be done by the programmer itself, the compiler, or by the\nruntime system. As interesting regions usually are nested, the overhead of\nmeasurement always influences the measurement itself. Thus, instrumentation\nshould be done selectively and results have to be interpreted with care. Of\ncourse, this makes performance analysis by exact measurement a very complex\nprocess.</para>\n\n<para>Exact measurement is possible because of hardware counters (including\ncounters incrementing on a time tick) provided in modern processors, which are\nincremented whenever an event is happening. As we want to attribute events to\ncode regions, without the counters, we would have to handle every event by\nincrementing a counter for the current code region ourself. Doing this in\nsoftware is, of course, not possible; but, on the assumption that the event\ndistribution over source code is similar when looking only at every n-th event\ninstead of every event, a measurement method whose overhead is tunable has been\ndeveloped: it is called Sampling. Time Based Sampling (&TBS;) uses a timer to\nregularly look at the program counter to create a histogram over the program\ncode. Event Based Sampling (&EBS;) exploits the hardware counters of modern\nprocessors, and uses a mode where an interrupt handler is called on counter\nunderflow to generate a histogram of the corresponding event distribution:\nin the handler, the event counter is always reinitialized to the\n<symbol>n</symbol> of the sampling method. The advantage of sampling is that the\ncode does not have to be changed, but it is still a compromise: the above\nassumption will be more correct if <symbol>n</symbol> is small, but the smaller\nthe <symbol>n</symbol>, the higher the overhead of the interrupt handler.</para>\n\n<para>Another measurement method is to simulate things happening in the computer\nsystem when executing a given code, &ie; execution driven simulation. The\nsimulation is always derived from a more or less accurate machine model;\nhowever, with very detailed machine models, giving very close approximations to\nreality, the simulation time can be unacceptably high in practice.\nThe advantage of simulation is that arbitrarily complex measurement/simulation\ncode can be inserted in a given code without perturbing results. Doing this\ndirectly before execution (called runtime instrumentation), using the original\nbinary, is very comfortable for the user: no re-compilation is necessary.\nSimulation becomes usable when simulating only parts of a machine with a simple\nmodel; another advantage is that the results produced by simple models are often\neasier to understand: often, the problem with real hardware is that results\ninclude overlapping effects from different parts of the machine.</para>\n</sect1>\n\n<sect1 id=\"introduction-tools\">\n<title>Profiling Tools</title>\n\n<para>\nMost known is the GCC profiling tool <application>gprof</application>: one needs\nto compile the program with option <option>-pg</option>; running the program\ngenerates a file <filename>gmon.out</filename>, which can be transformed into\nhuman-readable form with <command>gprof</command>.\nOne disadvantage is the required re-compilation step to prepare the executable,\nwhich has to be statically linked.\nThe method used here is compiler-generated instrumentation, which measures call\narcs happening among functions and corresponding call counts, in conjunction\nwith &TBS;, which gives a histogram of time distribution over the code. Using\nboth pieces of information, it is possible to heuristically calculate inclusive\ntime of functions, &ie; time spent in a function together with all functions\ncalled from it.\n</para>\n\n<para>For exact measurement of events happening, libraries exist with functions\nable to read out hardware performance counters. Most known here is the PerfCtr\npatch for &Linux;, and the architecture independent libraries PAPI and PCL.\nStill, exact measurement needs instrumentation of code, as stated above. Either\none uses the libraries itself or uses automatic instrumentation systems like\nADAPTOR (for FORTRAN source instrumentation) or DynaProf (code injection via\nDynInst).</para>\n\n<para>\n&oprofile; is a system-wide profiling tool for &Linux; using Sampling.\n</para>\n\n<para>\nIn many aspects, a comfortable way of Profiling is using &cachegrind; or\n&callgrind;, which are simulators using the runtime instrumentation framework\n&valgrind;. Because there is no need to access hardware counters (often\ndifficult with today's &Linux; installations), and binaries to be profiled can\nbe left unmodified, it is a good alternative to other profiling tools.\nThe disadvantage of simulation - slowdown - can be reduced by doing the\nsimulation on only the interesting program parts, and perhaps only on a few\niterations of a loop. Without measurement/simulation instrumentation,\n&valgrind;'s usage only has a slowdown factor in the range of 3 to 5.\nAlso, when only the call graph and call counts are of interest, the cache\nsimulator can be switched off.\n</para>\n\n<para>\nCache simulation is the first step in approximating real times, since runtime is\nvery sensitive to the exploitation of so-called <emphasis>caches</emphasis>,\nsmall and fast buffers which accelerate repeated accesses to the same main\nmemory cells, on modern systems.\n&cachegrind; does cache simulation by catching memory accesses.\nThe data produced includes the number of instruction/data memory accesses and\nfirst- and second-level cache misses, and relates it to source lines and\nfunctions of the run program.\nBy combining these miss counts, using miss latencies from typical processors,\nan estimation of spent time can be given.\n</para>\n\n<para>\n&callgrind; is an extension of &cachegrind; that builds up the call graph of a\nprogram on-the-fly, &ie; how the functions call each other and how many events\nhappen while running a function. Also, the profile data to be collected can\nseparated by threads and call chain contexts. It can provide profiling data on\nan instruction level to allow for annotation of disassembled code.\n</para>\n</sect1>\n\n<sect1 id=\"introduction-visualization\">\n<title>Visualization</title>\n\n<para>\nProfiling tools typically produce a large amount of data. The wish to easily\nbrowse down and up the call graph, together with fast switching of the sorting\nmode of functions and display of different event types, motivates a &GUI;\napplication to accomplish this task.\n</para>\n\n<para>\n&kcachegrind; is a visualization tool for profile data fulfilling these wishes.\nDespite being programmed first with browsing the data from &cachegrind; and\n&calltree; in mind, there are converters available to be able to display profile\ndata produced by other tools. In the appendix, a description of the\n&cachegrind;/&callgrind; file format is given.\n</para>\n\n<para>\nBesides a list of functions sorted according exclusive or inclusive cost\nmetrics, and optionally grouped by source file, shared library or C++ class,\n&kcachegrind; features various views for a selected function, namely:\n<itemizedlist>\n<listitem><para>a call-graph view, which shows a section of the call graph\naround the selected function,</para>\n</listitem>\n<listitem><para>a tree-map view, which allows nested-call relations to be\nvisualized, together with inclusive cost metric for fast visual detection of\nproblematic functions,</para>\n</listitem>\n<listitem><para>source code and disassembler annotation views, allowing to see\ndetails of cost related to source lines and assembler instructions.</para>\n</listitem>\n</itemizedlist>\n\n</para>\n</sect1>\n</chapter>\n\n<chapter id=\"using-kcachegrind\">\n<title>Using &kcachegrind;</title>\n\n<sect1 id=\"using-profile\">\n<title>Generate Data to Visualize</title>\n\n<para>First, one wants to generate performance data by measuring aspects of the\nruntime characteristics of an application, using a profiling tool. &kcachegrind;\nitself does not include any profiling tool, but is good in being used together\nwith &callgrind;, and by using a converter, also can be used to visualize data\nproduced with &oprofile;.  Although the scope of this manual is not to document\nprofiling with these tools, the next section provides short quickstart tutorials\nto get you started.\n</para>\n\n<sect2>\n<title>&callgrind;</title>\n\n<para>\n&callgrind; is a part of <ulink url=\"http://valgrind.org\">&valgrind;</ulink>.\nNote that it previously was called &calltree;, but that name was misleading.\n</para>\n\n<para>\nThe most common use is to prefix the command line to start your application with\n<userinput><command>valgrind</command> <option>--tool=callgrind</option>\n</userinput>, as in:\n\n<blockquote><para><userinput>\n<command>valgrind</command> <option>--tool=callgrind</option>\n<replaceable>myprogram</replaceable> <replaceable>myargs</replaceable>\n</userinput></para></blockquote>\n\nAt program termination, a file\n<filename>callgrind.out.<replaceable>pid</replaceable></filename> will be\ngenerated, which can be loaded into &kcachegrind;.\n</para>\n\n<para>\nMore advanced use is to dump out profile data whenever a given function of your\napplication is called. E.g. for &konqueror;, to see profile data only for the\nrendering of a Web page, you could decide to dump the data whenever you select\nthe menu item <menuchoice><guimenu>View</guimenu><guimenuitem>Reload\n</guimenuitem></menuchoice>. This corresponds to a call to\n<methodname>KonqMainWindow::slotReload</methodname>. Use:\n\n<blockquote><para><userinput>\n<command>valgrind</command> <option>--tool=callgrind</option>\n<option>--dump-before=KonqMainWindow::slotReload</option>\n<replaceable>konqueror</replaceable>\n</userinput></para></blockquote>\n\nThis will produce multiple profile data files with an additional sequential\nnumber at the end of the filename. A file without such an number at the end\n(only ending in the process PID) will also be produced; by loading this file\ninto &kcachegrind;, all others are loaded too, and can be seen in the\n<guilabel>Parts Overview</guilabel> and <guilabel>Parts</guilabel> list.\n</para>\n\n</sect2>\n\n<sect2>\n<title>&oprofile;</title>\n\n<para>\n&oprofile; is available from <ulink url=\"http://oprofile.sf.net\">its home\npage</ulink>. Follow the installation instructions on the Web site, but, before\nyou do, check whether your distribution does not already provide it as package\n(like &SuSE;).\n</para>\n\n<para>\nSystem-wide profiling is only permitted to the root user, as all actions on the\nsystem can be observed; therefore, the following has to be done as root.\nFirst, configure the profiling process, using the &GUI;\n<command>oprof_start</command> or the command-line tool\n<command>opcontrol</command>. Standard configuration should be timer mode\n(&TBS;, see introduction).\nTo start the measurement, run <userinput><command>opcontrol</command>\n<option>-s</option></userinput>.\nThen run the application you are interested in and, afterwards, do a\n<userinput><command>opcontrol</command> <option>-d</option></userinput>. This\nwill write out the measurement results into files under folder <filename\nclass=\"directory\">/var/lib/oprofile/samples/</filename>.\nTo be able to visualize the data in &kcachegrind;, do in an empty directory:\n\n<blockquote><para><userinput>\n<command>opreport</command> <option>-gdf</option> |\n<command>op2callgrind</command>\n</userinput></para></blockquote>\n\nThis will produce a lot of files, one for every program which was running\non the system. Each one can be loaded into &kcachegrind; on its own.\n</para>\n\n</sect2>\n</sect1>\n\n<sect1 id=\"using-basics\">\n<title>User Interface Basics</title>\n\n<para>\nWhen starting &kcachegrind; with a profile data file as argument, or after\nloading one with <menuchoice><guimenu>File</guimenu>\n<guimenuitem>Open</guimenuitem></menuchoice>, you will see a navigation panel\ncontaining the function list at the left; and, on the right the main part, an\narea with views for a selected function. This view area can be arbitrarily\nconfigured to show multiple views at once.\n</para>\n\n<para>\nAt first start, this area will be\ndivided into a top and a bottom part, each with different tab-selectable views.\nTo move views, use the tabs' context menu, and adjust the splitters between\nviews. To switch quickly between different viewing layouts, use\n<menuchoice><shortcut><keycombo action=\"simul\">&Ctrl;<keycap>\u2192</keycap>\n</keycombo></shortcut> <guimenu>View</guimenu><guisubmenu>Layout</guisubmenu>\n<guimenuitem>Go to Next</guimenuitem></menuchoice> and\n<menuchoice><shortcut><keycombo action=\"simul\">&Ctrl;<keycap>\u2190</keycap>\n</keycombo></shortcut> <guimenu>View</guimenu><guisubmenu>Layout</guisubmenu>\n<guimenuitem>Go to Previous</guimenuitem></menuchoice>.\n</para>\n\n<para>\nThe active event type is important for visualization: for &callgrind;, this is,\nfor example, cache misses or cycle estimation; for &oprofile;, this is\n<quote>Timer</quote> in the simplest case. You can change the event type via a\ncombobox in the toolbar or in the <guilabel>Event Type</guilabel> view.\nA first overview of the runtime characteristics should be given when you select\nfunction <function>main</function> in the left list; look then at the call graph\nview. There, you see the calls occurring in your program. Note that the call\ngraph view only shows functions with high event count.\nBy double-clicking a function in the graph, it will change to show the called\nfunctions around the selected one.\n</para>\n\n<para>\nTo explore the &GUI; further, in addition to this manual, also have a look at\nthe documentation section <ulink url=\"https://kcachegrind.github.io\">on the Web\nsite</ulink>.\nAlso, every widget in &kcachegrind; has <quote>What's this</quote> help.\n</para>\n</sect1>\n\n</chapter>\n\n\n<chapter id=\"kcachegrind-concepts\">\n<title>Basic Concepts</title>\n\n<para>This chapter explains some concepts of the &kcachegrind;, and introduces\nterms used in the interface.\n</para>\n\n<sect1 id=\"concepts-model\">\n<title>The Data Model for Profile Data</title>\n\n<sect2>\n<title>Cost Entities</title>\n\n<para>\nCost counts of event types (like L2 Misses) are attributed to cost entities,\nwhich are items with relationship to source code or data structures of a given\nprogram. Cost entities not only can be simple code or data positions, but also\nposition tuples. For example, a call has a source and a target, or a data\naddress can have a data type and a code position where its allocation happened.\n</para>\n\n<para>\nThe cost entities known to &kcachegrind; are given in the following.\nSimple Positions:\n<variablelist>\n<varlistentry>\n<term>Instruction</term>\n<listitem><para>\nAn assembler instruction at a specified address.\n</para></listitem>\n</varlistentry>\n<varlistentry>\n<term>Source Line of a Function</term>\n<listitem><para>\nAll instructions that the compiler (via debug information) maps to a given\nsource line specified by source file name and line number, and which are\nexecuted in the context of some function. The latter is needed because a source\nline inside of an inlined function can appear in the context of multiple\nfunctions. Instructions without any mapping to an actual source line are mapped\nto line number 0 in file <filename>???</filename>.\n</para></listitem>\n</varlistentry>\n<varlistentry>\n<term>Function</term>\n<listitem><para>\nAll source lines of a given function make up the function itself. A function is\nspecified by its name and its location in some binary object if available. The\nlatter is needed because binary objects of a single program each can hold\nfunctions with the same name (these can be accessed &eg; with\n<function>dlopen</function> or <function>dlsym</function>; the runtime linker\nresolves functions in a given search order of binary objects used). If a\nprofiling tool cannot detect the symbol name of a function, &eg; because debug\ninformation is not available, either the address of the first executed\ninstruction typically is used, or <function>???</function>.\n</para></listitem>\n</varlistentry>\n<varlistentry>\n<term>Binary Object</term>\n<listitem><para>\nAll functions whose code is inside the range of a given binary object, either\nthe main executable or a shared library.\n</para></listitem>\n</varlistentry>\n<varlistentry>\n<term>Source File</term>\n<listitem><para>\nAll functions whose first instruction is mapped to a line of the given source\nfile.\n</para></listitem>\n</varlistentry>\n<varlistentry>\n<term>Class</term>\n<listitem><para>\nSymbol names of functions typically are hierarchically ordered in name spaces,\n&eg; C++ namespaces, or classes of object-oriented languages; thus, a class can\nhold functions of the class or embedded classes itself.\n</para></listitem>\n</varlistentry>\n<varlistentry>\n<term>Profile Part</term>\n<listitem><para>\nSome time section of a profile run, with a given thread ID, process ID, and\ncommand line executed.\n</para></listitem>\n</varlistentry>\n</variablelist>\nAs can be seen from the list, a set of cost entities often defines another cost\nentity; thus, there is a inclusion hierarchy of cost entities.\n</para>\n\n<para>\nPositions tuples:\n<itemizedlist>\n<listitem><para>\nCall from instruction address to target function.\n</para></listitem>\n<listitem><para>\nCall from source line to target function.\n</para></listitem>\n<listitem><para>\nCall from source function to target function.\n</para></listitem>\n<listitem><para>\n(Un)conditional jump from source to target instruction.\n</para></listitem>\n<listitem><para>\n(Un)conditional jump from source to target line.\n</para></listitem>\n</itemizedlist>\nJumps between functions are not allowed, as this makes no sense in a call graph;\nthus, constructs like exception handling and long jumps in C have to be\ntranslated to popping the call stack as needed.\n</para>\n\n</sect2>\n\n\n<sect2>\n<title>Event Types</title>\n\n<para>\nArbitrary event types can be specified in the profile data by giving them a\nname. Their cost related to a cost entity is a 64-bit integer.\n</para>\n<para>\nEvent types whose costs are specified in a profile data file are called real\nevents. Additionally, one can specify formulas for event types calculated from\nreal events, which are called inherited events.\n</para>\n</sect2>\n\n</sect1>\n\n<sect1 id=\"concepts-state\">\n<title>Visualization State</title>\n\n<para>\nThe visualization state of a &kcachegrind; window includes:\n<itemizedlist>\n<listitem><para>\nthe primary and secondary event type chosen for display,\n</para></listitem>\n<listitem><para>\nthe function grouping (used in the <guilabel>Function Profile</guilabel> list\nand entity coloring),\n</para></listitem>\n<listitem><para>\nthe profile parts whose costs are to be included in visualization,\n</para></listitem>\n<listitem><para>\nan active cost entity (&eg; a function selected from the function profile\nsidedock),\n</para></listitem>\n<listitem><para>\na selected cost entity.\n</para></listitem>\n</itemizedlist>\nThis state influences the views.\n</para>\n\n<para>\nViews are always shown for one cost entity, the active one. When a given view\nis inappropriate for a cost entity, it is disabled: when selecting &eg; an &ELF;\nobject in the group list, source annotation makes no sense.\n</para>\n\n<para>\nFor example, for an active function, the callee list shows all the functions\ncalled from the active one: one can select one of these functions without making\nit active. Also, if the call graph is shown beside, it will automatically select\nthe same function.\n</para>\n\n</sect1>\n\n<sect1 id=\"concepts-guiparts\">\n<title>Parts of the &GUI;</title>\n\n<sect2>\n<title>Sidedocks</title>\n<para>\nSidedocks are side windows which can be placed at any border of a &kcachegrind;\nwindow. They always contain a list of cost entities sorted in some way.\n<itemizedlist>\n<listitem><para>\nThe <guilabel>Function Profile</guilabel> is a list of functions showing\ninclusive and exclusive cost, call count, name and position of functions.\n</para></listitem>\n<listitem><para>\n<guilabel>Parts Overview</guilabel>\n</para></listitem>\n<listitem><para>\n<guilabel>Call Stack</guilabel>\n</para></listitem>\n</itemizedlist>\n</para>\n</sect2>\n\n<sect2>\n<title>View Area</title>\n<para>\nThe view area, typically the right part of a &kcachegrind; main window, is made\nup of one (default) or more tabs, lined up either horizontally or vertically.\nEach tab holds different views of only one cost entity at a time.\nThe name of this entity is given at the top of the tab. If there are multiple\ntabs, only one is active. The entity name in the active tab is shown in bold,\nand determines the active cost entity of the &kcachegrind; window.\n</para>\n</sect2>\n\n<sect2>\n<title>Areas of a Tab</title>\n<para>\nEach tab can hold up to four view areas, namely Top, Right, Left, and Bottom.\nEach area can hold multiple stacked views. The visible part of an area is\nselected by a tab bar. The tab bars of the top and right area are at the top;\nthe tab bars of the left and bottom area are at the bottom. You can specify\nwhich kind of view should go into which area by using the tabs' context menus.\n</para>\n</sect2>\n\n<sect2>\n<title>Synchronized View with Selected Entity in a Tab</title>\n<para>\nBesides an active entity, each tab has a selected entity. As most view types\nshow multiple entities with the active one somehow centered, you can change\nthe selected item by navigating inside a view (by clicking with the mouse\nor using the keyboard). Typically, selected items are shown in a highlighted\nstate. By changing the selected entity in one of the views of a tab, all other\nviews highlight the new selected entity accordingly.\n</para>\n</sect2>\n\n<sect2>\n<title>Synchronization between Tabs</title>\n<para>\nIf there are multiple tabs, a selection change in one tab leads to an activation\nchange in the next tab, be it right of the former or under it. This kind of\nlinkage should, for example, allow for fast browsing in call graphs.\n</para>\n</sect2>\n\n<sect2>\n<title>Layouts</title>\n<para>\nThe layout of all the tabs of a window can be saved (<menuchoice><guimenu>View\n</guimenu><guisubmenu>Layout</guisubmenu></menuchoice>). After duplicating the\ncurrent layout (<menuchoice><shortcut><keycombo action=\"simul\">&Ctrl;\n<keycap>+</keycap></keycombo></shortcut> <guimenu>View</guimenu>\n<guisubmenu>Layout</guisubmenu><guimenuitem>Duplicate</guimenuitem>\n</menuchoice>)\nand changing some sizes or moving a view to another area of a tab, you can\nquickly switch between the old and the new layout via <keycombo action=\"simul\">\n&Ctrl;<keycap>\u2190</keycap></keycombo> and <keycombo action=\"simul\">&Ctrl;\n<keycap>\u2192</keycap></keycombo>. The set of layouts will be stored between\n&kcachegrind; sessions of the same profiled command. You can make the current\nset of layouts the default one for new &kcachegrind; sessions, or restore the\ndefault layout set.\n</para>\n</sect2>\n</sect1>\n\n<sect1 id=\"concepts-sidedocks\">\n<title>Sidedocks</title>\n\n<sect2>\n<title>Flat Profile</title>\n<para>\nThe <guilabel>Flat Profile</guilabel> contains a group list and a function list.\nThe group list contains all groups where cost is spent in, depending on the\nchosen group type. The group list is hidden when grouping is switched off.\n</para>\n<para>\nThe function list contains the functions of the selected group (or all functions\nif grouping is switched off), ordered by some column, &eg; inclusive or self\ncosts spent therein. There is a maximum number of functions shown in the list,\nconfigurable in <menuchoice><guimenu>Settings</guimenu><guimenuitem>Configure\nKCachegrind</guimenuitem></menuchoice>.\n</para>\n</sect2>\n\n<sect2>\n<title>Parts Overview</title>\n<para>\nIn a profile run, multiple profile data files can be produced, which can be\nloaded together into &kcachegrind;. The <guilabel>Parts Overview</guilabel>\nsidedock shows these, ordered horizontally according to creation time; the\nrectangle sizes are proportional to the cost spent each part. You can select one\nor several parts to constrain the costs shown in the other &kcachegrind; views\nto these parts only.\n</para>\n<para>\nThe parts are further subdivided between a partitioning and an inclusive cost\nsplit mode:\n<variablelist>\n<varlistentry>\n<term><guilabel>Partitioning Mode</guilabel></term>\n<listitem><para>\nThe partitioning is shown in groups for a profile data part, according to the\ngroup type selected. For example, if &ELF; object groups are selected, you see\ncolored rectangles for each used &ELF; object (shared library or executable),\nsized according to the cost spent therein.\n</para></listitem>\n</varlistentry>\n<varlistentry>\n<term><guilabel>Diagram Mode</guilabel></term>\n<listitem><para>\nA rectangle showing the inclusive cost of the current active function in the\npart is shown. This, again, is split up to show the inclusive costs of its\ncallees.\n</para></listitem>\n</varlistentry>\n</variablelist>\n</para>\n</sect2>\n\n<sect2>\n<title>Call Stack</title>\n<para>\nThis is a purely fictional <quote>most probable</quote> call stack. It is built\nup by starting with the current active function, and adds the callers and\ncallees with highest cost at the top and to bottom.\n</para>\n<para>\nThe <guilabel>Cost</guilabel> and <guilabel>Calls</guilabel> columns show the\ncost used for all calls from the function in the line above.\n</para>\n</sect2>\n</sect1>\n\n<sect1 id=\"concepts-views\">\n<title>Views</title>\n\n<sect2>\n<title>Event Type</title>\n<para>\nThe <guilabel>Event Type</guilabel> list shows all cost types available and the\ncorresponding self and inclusive cost of the current active function for that\nevent type.\n</para>\n<para>\nBy choosing an event type from the list, you change the type of costs shown all\nover &kcachegrind; to the selected one.\n</para>\n</sect2>\n\n<sect2>\n<title>Call Lists</title>\n<para>\nThese lists show calls to and from the current active function. With\n<guilabel>All Callers</guilabel> and <guilabel>All Callees</guilabel> are meant\nthose functions reachable in the caller and callee direction, even when other\nfunctions are in between.\n</para>\n\n<para>\nCall list views include:\n<itemizedlist>\n<listitem><para>Direct <guilabel>Callers</guilabel></para></listitem>\n<listitem><para>Direct <guilabel>Callees</guilabel></para></listitem>\n<listitem><para><guilabel>All Callers</guilabel></para></listitem>\n<listitem><para><guilabel>All Callees</guilabel></para></listitem>\n</itemizedlist>\n</para>\n</sect2>\n\n<sect2>\n<title>Maps</title>\n<para>\nA treemap view of the primary event type, up or down the call\nhierarchy. Each colored rectangle represents a function; its size is\napproximately proportional to the cost spent therein while the active function\nis running (however, there are drawing constrains).\n</para>\n<para>\nFor the <guilabel>Caller Map</guilabel>, the graph shows the nested hierarchy of\nall callers of the currently activated function; for the <guilabel>Callee\nMap</guilabel>, it shows that of all callees.\n</para>\n<para>\nAppearance options can be found in the context menu. To get exact size\nproportions, choose <guimenuitem>Skip Incorrect Borders</guimenuitem>. As this\nmode can be very time-consuming, you may want to limit the maximum drawn\nnesting level before. <guilabel>Best</guilabel> determinates the split direction\nfor children from the aspect ratio of the parent. <guilabel>Always\nBest</guilabel> decides on remaining space for each sibling. <guilabel>Ignore\nProportions</guilabel> takes space for function name drawing before drawing\nchildren. Note that size proportions can get heavily wrong.\n</para>\n<para>\nKeyboard navigation is available with the left and right arrow keys for\ntraversing siblings, and up and down arrow keys to go a nesting level up and\ndown. &Enter; activates the current item.\n</para>\n</sect2>\n\n<sect2>\n<title>Call Graph</title>\n<para>\nThis view shows the call graph around the active function. The cost shown is\nonly the cost spent while the active function was actually running, &ie; the\ncost shown for <function>main()</function> (if it's visible) should be the same\nas the cost of the active function, as that is the part of inclusive cost of\n<function>main()</function> spent while the active function was running.\n</para>\n<para>\nFor cycles, blue call arrows indicate that this is an artificial call, which\nnever actually happened, added for correct drawing.\n</para>\n<para>\nIf the graph is larger than the drawing area, a bird's eye view is shown on a\nside. There are view options similar to those of the call maps; the selected\nfunction is highlighted.\n</para>\n</sect2>\n\n<sect2>\n<title>Annotations</title>\n<para>\nThe annotated source or assembler lists show the source lines or disassembled\ninstructions of the current active function together with the (self) cost spent\nexecuting the code of a source line or instruction. If there was a call, lines\nwith details on the call are inserted into the source: the (inclusive) cost\nspent inside of the call, the number of calls happening, and the call\ndestination.\n</para>\n<para>\nSelect such a call information line to activate the call destination.\n</para>\n</sect2>\n</sect1>\n\n</chapter>\n\n\n<chapter id=\"commands\">\n<title>Command Reference</title>\n\n<sect1 id=\"kcachegrind-mainwindow\">\n<title>The main &kcachegrind; window</title>\n\n<sect2>\n<title>The File Menu</title>\n<para>\n<variablelist>\n\n<varlistentry>\n<term><menuchoice>\n<shortcut>\n<keycombo>&Ctrl;<keycap>N</keycap></keycombo>\n</shortcut>\n<guimenu>File</guimenu><guimenuitem>New</guimenuitem>\n</menuchoice></term>\n<listitem><para>\n<action>Opens an empty top-level window</action> in which you can\nload profile data. This action is not really necessary, as <menuchoice>\n<guimenu>File</guimenu><guimenuitem>Open</guimenuitem></menuchoice> gives you a\nnew top-level window if the current one already shows some data.\n</para></listitem>\n</varlistentry>\n\n<varlistentry>\n<term><menuchoice>\n<shortcut>\n<keycombo>&Ctrl;<keycap>O</keycap></keycombo>\n</shortcut>\n<guimenu>File</guimenu><guimenuitem>Open</guimenuitem>\n</menuchoice></term>\n<listitem>\n<para>\n<action>Pops up the &kde; file selector</action> to choose a\nprofile data file to be loaded. If there is some data already shown in the\ncurrent top-level window, this will open a new window; if you want to open\nadditional profile data in the current window, use <menuchoice>\n<guimenu>File</guimenu><guimenuitem>Add</guimenuitem></menuchoice>.\n</para>\n<para>\nThe name of profile data files usually ends in <literal role=\"extension\"\n>.<replaceable>pid</replaceable>.<replaceable>part</replaceable>-<replaceable\n>threadID</replaceable></literal>, where <replaceable>part</replaceable> and\n<replaceable>threadID</replaceable> are optional. <replaceable>pid</replaceable>\nand <replaceable>part</replaceable> are used for multiple profile data files\nbelonging to one application run.\nBy loading a file ending only in <literal role=\"extension\"><replaceable\n>pid</replaceable></literal>, any existing data files for this run with\nadditional endings are loaded as well.\n</para>\n<informalexample><para>\nIf there exist profile data files <filename>cachegrind.out.123</filename> and\n<filename>cachegrind.out.123.1</filename>, by loading the first, the second will\nbe automatically loaded too.\n</para></informalexample></listitem>\n</varlistentry>\n\n<varlistentry>\n<term><menuchoice>\n<guimenu>File</guimenu><guimenuitem>Add</guimenuitem>\n</menuchoice></term>\n<listitem><para>\n<action>Adds a profile data file</action> to the current window.\nUsing this, you can force multiple data files to be loaded into the same\ntop-level window even if they are not from the same run, as given by the profile\ndata file naming convention. For example, this can be used for side-by-side\ncomparison.\n</para></listitem>\n</varlistentry>\n\n<varlistentry>\n<term><menuchoice>\n<shortcut>\n<keycombo><keycap>F5</keycap></keycombo>\n</shortcut>\n<guimenu>File</guimenu><guimenuitem>Reload</guimenuitem>\n</menuchoice></term>\n<listitem><para>\n<action>Reload the profile data</action>. This is useful when another profile\ndata file was generated for an already loaded application run.\n</para></listitem>\n</varlistentry>\n\n<varlistentry>\n<term><menuchoice>\n<shortcut>\n<keycombo>&Ctrl;<keycap>Q</keycap></keycombo>\n</shortcut>\n<guimenu>File</guimenu><guimenuitem>Quit</guimenuitem>\n</menuchoice></term>\n<listitem><para><action>Quits</action> &kcachegrind;</para></listitem>\n</varlistentry>\n</variablelist>\n</para>\n\n</sect2>\n\n</sect1>\n</chapter>\n\n<chapter id=\"faq\">\n<title>Questions and Answers</title>\n\n<qandaset id=\"faqlist\">\n\n\n<qandaentry>\n<question>\n<para>\nWhat is &kcachegrind; for? I have no idea.\n</para>\n</question>\n<answer>\n<para>\n&kcachegrind; is a helpful at a late stage in software development, called\nprofiling. If you don't develop applications, you don't need &kcachegrind;.\n</para>\n</answer>\n</qandaentry>\n\n<qandaentry>\n<question>\n<para>\nWhat is the difference between <guilabel>Incl.</guilabel> and\n<guilabel>Self</guilabel>?\n</para>\n</question>\n<answer>\n<para>These are cost attributes for functions regarding some event type. As\nfunctions can call each other, it makes sense to distinguish the cost of the\nfunction itself (<quote>Self Cost</quote>) and the cost including all called\nfunctions (<quote>Inclusive Cost</quote>). <quote>Self</quote> is sometimes also\nreferred to as <quote>Exclusive</quote> costs.\n</para>\n<para>\nSo, for example, for <function>main()</function>, you will always have an\ninclusive cost of almost 100%, whereas the self cost is negligible when the real\nwork is done in another function.\n</para>\n</answer>\n</qandaentry>\n\n<qandaentry>\n<question>\n<para>\nIf I double-click on a function down in the <guilabel>Call Graph</guilabel>\nview, it shows for function <function>main()</function> the same cost as the\nselected function. Isn't this supposed to be constant at 100%?\n</para>\n</question>\n<answer>\n<para>\nYou have activated a function below <function>main()</function>, which obviously\ncosts less than <function>main()</function> itself. For every function, it is\nshown only the part of the cost spent while the <emphasis>activated</emphasis>\nfunction is running; that is, the cost shown for any function can never be\nhigher than the cost of the activated function.\n</para>\n</answer>\n</qandaentry>\n\n\n</qandaset>\n</chapter>\n\n\n<glossary>\n\n<glossentry id=\"costentity\">\n<glossterm>Cost Entity</glossterm>\n<glossdef><para>An abstract item related to source code to which event counts\ncan be attributed. Dimensions for cost entities are code location (&eg; source\nline, function), data location (&eg; accessed data type, data object), execution\nlocation (&eg; thread, process), and tuples or triples of the aforementioned\npositions (&eg; calls, object access from statement, evicted data from\ncache).</para></glossdef>\n</glossentry>\n\n<glossentry id=\"eventcosts\">\n<glossterm>Event Costs</glossterm>\n<glossdef><para>Sum of events of some event type occurring while the execution\nis related to some cost entity. The cost is attributed to the\nentity.</para></glossdef>\n</glossentry>\n\n<glossentry id=\"eventtype\">\n<glossterm>Event Type</glossterm>\n<glossdef><para>The kind of event of which costs can be attributed to a cost\nentity. There are real event types and inherited event types.</para></glossdef>\n</glossentry>\n\n<glossentry id=\"inheritedeventtype\">\n<glossterm>Inherited Event Type</glossterm>\n<glossdef><para>A virtual event type only visible in the view, defined by a\nformula to be calculated from real event types.</para></glossdef>\n</glossentry>\n\n<glossentry id=\"profiledatafile\">\n<glossterm>Profile Data File</glossterm>\n<glossdef><para>A file containing data measured in a profile experiment, or part\nof one, or produced by post-processing a trace. Its size is typically linear\nwith the code size of the program.</para></glossdef>\n</glossentry>\n\n<glossentry id=\"profiledatapart\">\n<glossterm>Profile Data Part</glossterm>\n<glossdef><para>Data from a profile data file.</para></glossdef>\n</glossentry>\n\n<glossentry id=\"profileexperiment\">\n<glossterm>Profile Experiment</glossterm>\n<glossdef><para>A program run supervised by a profiling tool, producing possibly\nmultiple profile data files from parts or threads of the run.</para></glossdef>\n</glossentry>\n\n<glossentry id=\"profileproject\">\n<glossterm>Profile Project</glossterm>\n<glossdef><para>A configuration for profile experiments used for one program to\nprofile, perhaps in multiple versions. Comparisons of profile data typically\nonly makes sense between profile data produced in experiments of one profile\nproject.</para></glossdef>\n</glossentry>\n\n<glossentry id=\"profiling\">\n<glossterm>Profiling</glossterm>\n<glossdef><para>The process of collecting statistical information about runtime\ncharacteristics of program runs.</para></glossdef>\n</glossentry>\n\n<glossentry id=\"realeventtype\">\n<glossterm>Real Event Type</glossterm>\n<glossdef><para>An event type that can be measured by a tool. This requires the\nexistence of a sensor for the given event type.</para></glossdef>\n</glossentry>\n\n<glossentry id=\"trace\">\n<glossterm>Trace</glossterm>\n<glossdef><para>A sequence of timestamped events that occurred while tracing a\nprogram run. Its size is typically linear with the execution time of the program\nrun.</para></glossdef>\n</glossentry>\n\n<glossentry id=\"tracepart\">\n<glossterm>Trace Part</glossterm>\n<glosssee otherterm=\"profiledatapart\"/>\n</glossentry>\n\n<glossentry id=\"tracing\">\n<glossterm>Tracing</glossterm>\n<glossdef><para>The process of supervising a program run and storing its events,\nsorted by a timestamp, in an output file, the trace.</para></glossdef>\n</glossentry>\n\n</glossary>\n\n<chapter id=\"credits\">\n\n<title>Credits and License</title>\n\n<para>\nThanks to Julian Seward for his excellent &valgrind;, and Nicholas Nethercote\nfor the &cachegrind; addition. Without these programs, &kcachegrind; would not\nexist. Some ideas for this &GUI; were from them, too.\n</para>\n<para>\nThanks for all the bug reports and suggestions from different users.\n</para>\n\n<!-- TRANS:CREDIT_FOR_TRANSLATORS -->\n&underFDL;        \t <!-- FDL License -->\n\n</chapter>\n\n&documentation.index;\n</book>\n"
    },
    "skipped": [
        "/tmp/vanessa/spack-stage/spack-stage-qcachegrind-20.08.0-oxxtqoalamluitigegnz4wltg5kjf7xd/spack-src/logo.png",
        "/tmp/vanessa/spack-stage/spack-stage-qcachegrind-20.08.0-oxxtqoalamluitigegnz4wltg5kjf7xd/spack-src/pics/hicolor/22-actions-hidetemplates.png",
        "/tmp/vanessa/spack-stage/spack-stage-qcachegrind-20.08.0-oxxtqoalamluitigegnz4wltg5kjf7xd/spack-src/pics/hicolor/16-actions-move.png",
        "/tmp/vanessa/spack-stage/spack-stage-qcachegrind-20.08.0-oxxtqoalamluitigegnz4wltg5kjf7xd/spack-src/pics/hicolor/16-actions-percent.png",
        "/tmp/vanessa/spack-stage/spack-stage-qcachegrind-20.08.0-oxxtqoalamluitigegnz4wltg5kjf7xd/spack-src/pics/hicolor/22-actions-move.png",
        "/tmp/vanessa/spack-stage/spack-stage-qcachegrind-20.08.0-oxxtqoalamluitigegnz4wltg5kjf7xd/spack-src/pics/hicolor/32-actions-percent.png",
        "/tmp/vanessa/spack-stage/spack-stage-qcachegrind-20.08.0-oxxtqoalamluitigegnz4wltg5kjf7xd/spack-src/pics/hicolor/22-actions-percent.png",
        "/tmp/vanessa/spack-stage/spack-stage-qcachegrind-20.08.0-oxxtqoalamluitigegnz4wltg5kjf7xd/spack-src/kcachegrind/128-apps-kcachegrind.png",
        "/tmp/vanessa/spack-stage/spack-stage-qcachegrind-20.08.0-oxxtqoalamluitigegnz4wltg5kjf7xd/spack-src/kcachegrind/32-apps-kcachegrind.png",
        "/tmp/vanessa/spack-stage/spack-stage-qcachegrind-20.08.0-oxxtqoalamluitigegnz4wltg5kjf7xd/spack-src/kcachegrind/48-apps-kcachegrind.png",
        "/tmp/vanessa/spack-stage/spack-stage-qcachegrind-20.08.0-oxxtqoalamluitigegnz4wltg5kjf7xd/spack-src/kcachegrind/64-apps-kcachegrind.png"
    ],
    "total_files": 164
}