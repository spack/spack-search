{
    "matches": {
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/rali/rali_pybind/third_party_lib/pybind11/include/pybind11/detail/internals.h": "/*\n    pybind11/detail/internals.h: Internal data structure and related functions\n\n    Copyright (c) 2017 Wenzel Jakob <wenzel.jakob@epfl.ch>\n\n    All rights reserved. Use of this source code is governed by a\n    BSD-style license that can be found in the LICENSE file.\n*/\n\n#pragma once\n\n#include \"../pytypes.h\"\n\nNAMESPACE_BEGIN(PYBIND11_NAMESPACE)\nNAMESPACE_BEGIN(detail)\n// Forward declarations\ninline PyTypeObject *make_static_property_type();\ninline PyTypeObject *make_default_metaclass();\ninline PyObject *make_object_base_type(PyTypeObject *metaclass);\n\n// The old Python Thread Local Storage (TLS) API is deprecated in Python 3.7 in favor of the new\n// Thread Specific Storage (TSS) API.\n#if PY_VERSION_HEX >= 0x03070000\n#    define PYBIND11_TLS_KEY_INIT(var) Py_tss_t *var = nullptr\n#    define PYBIND11_TLS_GET_VALUE(key) PyThread_tss_get((key))\n#    define PYBIND11_TLS_REPLACE_VALUE(key, value) PyThread_tss_set((key), (value))\n#    define PYBIND11_TLS_DELETE_VALUE(key) PyThread_tss_set((key), nullptr)\n#    define PYBIND11_TLS_FREE(key) PyThread_tss_free(key)\n#else\n    // Usually an int but a long on Cygwin64 with Python 3.x\n#    define PYBIND11_TLS_KEY_INIT(var) decltype(PyThread_create_key()) var = 0\n#    define PYBIND11_TLS_GET_VALUE(key) PyThread_get_key_value((key))\n#    if PY_MAJOR_VERSION < 3\n#        define PYBIND11_TLS_DELETE_VALUE(key)                               \\\n             PyThread_delete_key_value(key)\n#        define PYBIND11_TLS_REPLACE_VALUE(key, value)                       \\\n             do {                                                            \\\n                 PyThread_delete_key_value((key));                           \\\n                 PyThread_set_key_value((key), (value));                     \\\n             } while (false)\n#    else\n#        define PYBIND11_TLS_DELETE_VALUE(key)                               \\\n             PyThread_set_key_value((key), nullptr)\n#        define PYBIND11_TLS_REPLACE_VALUE(key, value)                       \\\n             PyThread_set_key_value((key), (value))\n#    endif\n#    define PYBIND11_TLS_FREE(key) (void)key\n#endif\n\n// Python loads modules by default with dlopen with the RTLD_LOCAL flag; under libc++ and possibly\n// other STLs, this means `typeid(A)` from one module won't equal `typeid(A)` from another module\n// even when `A` is the same, non-hidden-visibility type (e.g. from a common include).  Under\n// libstdc++, this doesn't happen: equality and the type_index hash are based on the type name,\n// which works.  If not under a known-good stl, provide our own name-based hash and equality\n// functions that use the type name.\n#if defined(__GLIBCXX__)\ninline bool same_type(const std::type_info &lhs, const std::type_info &rhs) { return lhs == rhs; }\nusing type_hash = std::hash<std::type_index>;\nusing type_equal_to = std::equal_to<std::type_index>;\n#else\ninline bool same_type(const std::type_info &lhs, const std::type_info &rhs) {\n    return lhs.name() == rhs.name() || std::strcmp(lhs.name(), rhs.name()) == 0;\n}\n\nstruct type_hash {\n    size_t operator()(const std::type_index &t) const {\n        size_t hash = 5381;\n        const char *ptr = t.name();\n        while (auto c = static_cast<unsigned char>(*ptr++))\n            hash = (hash * 33) ^ c;\n        return hash;\n    }\n};\n\nstruct type_equal_to {\n    bool operator()(const std::type_index &lhs, const std::type_index &rhs) const {\n        return lhs.name() == rhs.name() || std::strcmp(lhs.name(), rhs.name()) == 0;\n    }\n};\n#endif\n\ntemplate <typename value_type>\nusing type_map = std::unordered_map<std::type_index, value_type, type_hash, type_equal_to>;\n\nstruct overload_hash {\n    inline size_t operator()(const std::pair<const PyObject *, const char *>& v) const {\n        size_t value = std::hash<const void *>()(v.first);\n        value ^= std::hash<const void *>()(v.second)  + 0x9e3779b9 + (value<<6) + (value>>2);\n        return value;\n    }\n};\n\n/// Internal data structure used to track registered instances and types.\n/// Whenever binary incompatible changes are made to this structure,\n/// `PYBIND11_INTERNALS_VERSION` must be incremented.\nstruct internals {\n    type_map<type_info *> registered_types_cpp; // std::type_index -> pybind11's type information\n    std::unordered_map<PyTypeObject *, std::vector<type_info *>> registered_types_py; // PyTypeObject* -> base type_info(s)\n    std::unordered_multimap<const void *, instance*> registered_instances; // void * -> instance*\n    std::unordered_set<std::pair<const PyObject *, const char *>, overload_hash> inactive_overload_cache;\n    type_map<std::vector<bool (*)(PyObject *, void *&)>> direct_conversions;\n    std::unordered_map<const PyObject *, std::vector<PyObject *>> patients;\n    std::forward_list<void (*) (std::exception_ptr)> registered_exception_translators;\n    std::unordered_map<std::string, void *> shared_data; // Custom data to be shared across extensions\n    std::vector<PyObject *> loader_patient_stack; // Used by `loader_life_support`\n    std::forward_list<std::string> static_strings; // Stores the std::strings backing detail::c_str()\n    PyTypeObject *static_property_type;\n    PyTypeObject *default_metaclass;\n    PyObject *instance_base;\n#if defined(WITH_THREAD)\n    PYBIND11_TLS_KEY_INIT(tstate);\n    PyInterpreterState *istate = nullptr;\n    ~internals() {\n        // This destructor is called *after* Py_Finalize() in finalize_interpreter().\n        // That *SHOULD BE* fine. The following details what happens whe PyThread_tss_free is called.\n        // PYBIND11_TLS_FREE is PyThread_tss_free on python 3.7+. On older python, it does nothing.\n        // PyThread_tss_free calls PyThread_tss_delete and PyMem_RawFree.\n        // PyThread_tss_delete just calls TlsFree (on Windows) or pthread_key_delete (on *NIX). Neither\n        // of those have anything to do with CPython internals.\n        // PyMem_RawFree *requires* that the `tstate` be allocated with the CPython allocator.\n        PYBIND11_TLS_FREE(tstate);\n    }\n#endif\n};\n\n/// Additional type information which does not fit into the PyTypeObject.\n/// Changes to this struct also require bumping `PYBIND11_INTERNALS_VERSION`.\nstruct type_info {\n    PyTypeObject *type;\n    const std::type_info *cpptype;\n    size_t type_size, type_align, holder_size_in_ptrs;\n    void *(*operator_new)(size_t);\n    void (*init_instance)(instance *, const void *);\n    void (*dealloc)(value_and_holder &v_h);\n    std::vector<PyObject *(*)(PyObject *, PyTypeObject *)> implicit_conversions;\n    std::vector<std::pair<const std::type_info *, void *(*)(void *)>> implicit_casts;\n    std::vector<bool (*)(PyObject *, void *&)> *direct_conversions;\n    buffer_info *(*get_buffer)(PyObject *, void *) = nullptr;\n    void *get_buffer_data = nullptr;\n    void *(*module_local_load)(PyObject *, const type_info *) = nullptr;\n    /* A simple type never occurs as a (direct or indirect) parent\n     * of a class that makes use of multiple inheritance */\n    bool simple_type : 1;\n    /* True if there is no multiple inheritance in this type's inheritance tree */\n    bool simple_ancestors : 1;\n    /* for base vs derived holder_type checks */\n    bool default_holder : 1;\n    /* true if this is a type registered with py::module_local */\n    bool module_local : 1;\n};\n\n/// Tracks the `internals` and `type_info` ABI version independent of the main library version\n#define PYBIND11_INTERNALS_VERSION 4\n\n/// On MSVC, debug and release builds are not ABI-compatible!\n#if defined(_MSC_VER) && defined(_DEBUG)\n#   define PYBIND11_BUILD_TYPE \"_debug\"\n#else\n#   define PYBIND11_BUILD_TYPE \"\"\n#endif\n\n/// Let's assume that different compilers are ABI-incompatible.\n#if defined(_MSC_VER)\n#   define PYBIND11_COMPILER_TYPE \"_msvc\"\n#elif defined(__INTEL_COMPILER)\n#   define PYBIND11_COMPILER_TYPE \"_icc\"\n#elif defined(__clang__)\n#   define PYBIND11_COMPILER_TYPE \"_clang\"\n#elif defined(__PGI)\n#   define PYBIND11_COMPILER_TYPE \"_pgi\"\n#elif defined(__MINGW32__)\n#   define PYBIND11_COMPILER_TYPE \"_mingw\"\n#elif defined(__CYGWIN__)\n#   define PYBIND11_COMPILER_TYPE \"_gcc_cygwin\"\n#elif defined(__GNUC__)\n#   define PYBIND11_COMPILER_TYPE \"_gcc\"\n#else\n#   define PYBIND11_COMPILER_TYPE \"_unknown\"\n#endif\n\n#if defined(_LIBCPP_VERSION)\n#  define PYBIND11_STDLIB \"_libcpp\"\n#elif defined(__GLIBCXX__) || defined(__GLIBCPP__)\n#  define PYBIND11_STDLIB \"_libstdcpp\"\n#else\n#  define PYBIND11_STDLIB \"\"\n#endif\n\n/// On Linux/OSX, changes in __GXX_ABI_VERSION__ indicate ABI incompatibility.\n#if defined(__GXX_ABI_VERSION)\n#  define PYBIND11_BUILD_ABI \"_cxxabi\" PYBIND11_TOSTRING(__GXX_ABI_VERSION)\n#else\n#  define PYBIND11_BUILD_ABI \"\"\n#endif\n\n#if defined(WITH_THREAD)\n#  define PYBIND11_INTERNALS_KIND \"\"\n#else\n#  define PYBIND11_INTERNALS_KIND \"_without_thread\"\n#endif\n\n#define PYBIND11_INTERNALS_ID \"__pybind11_internals_v\" \\\n    PYBIND11_TOSTRING(PYBIND11_INTERNALS_VERSION) PYBIND11_INTERNALS_KIND PYBIND11_COMPILER_TYPE PYBIND11_STDLIB PYBIND11_BUILD_ABI PYBIND11_BUILD_TYPE \"__\"\n\n#define PYBIND11_MODULE_LOCAL_ID \"__pybind11_module_local_v\" \\\n    PYBIND11_TOSTRING(PYBIND11_INTERNALS_VERSION) PYBIND11_INTERNALS_KIND PYBIND11_COMPILER_TYPE PYBIND11_STDLIB PYBIND11_BUILD_ABI PYBIND11_BUILD_TYPE \"__\"\n\n/// Each module locally stores a pointer to the `internals` data. The data\n/// itself is shared among modules with the same `PYBIND11_INTERNALS_ID`.\ninline internals **&get_internals_pp() {\n    static internals **internals_pp = nullptr;\n    return internals_pp;\n}\n\ninline void translate_exception(std::exception_ptr p) {\n    try {\n        if (p) std::rethrow_exception(p);\n    } catch (error_already_set &e)           { e.restore();                                    return;\n    } catch (const builtin_exception &e)     { e.set_error();                                  return;\n    } catch (const std::bad_alloc &e)        { PyErr_SetString(PyExc_MemoryError,   e.what()); return;\n    } catch (const std::domain_error &e)     { PyErr_SetString(PyExc_ValueError,    e.what()); return;\n    } catch (const std::invalid_argument &e) { PyErr_SetString(PyExc_ValueError,    e.what()); return;\n    } catch (const std::length_error &e)     { PyErr_SetString(PyExc_ValueError,    e.what()); return;\n    } catch (const std::out_of_range &e)     { PyErr_SetString(PyExc_IndexError,    e.what()); return;\n    } catch (const std::range_error &e)      { PyErr_SetString(PyExc_ValueError,    e.what()); return;\n    } catch (const std::overflow_error &e)   { PyErr_SetString(PyExc_OverflowError, e.what()); return;\n    } catch (const std::exception &e)        { PyErr_SetString(PyExc_RuntimeError,  e.what()); return;\n    } catch (...) {\n        PyErr_SetString(PyExc_RuntimeError, \"Caught an unknown exception!\");\n        return;\n    }\n}\n\n#if !defined(__GLIBCXX__)\ninline void translate_local_exception(std::exception_ptr p) {\n    try {\n        if (p) std::rethrow_exception(p);\n    } catch (error_already_set &e)       { e.restore();   return;\n    } catch (const builtin_exception &e) { e.set_error(); return;\n    }\n}\n#endif\n\n/// Return a reference to the current `internals` data\nPYBIND11_NOINLINE inline internals &get_internals() {\n    auto **&internals_pp = get_internals_pp();\n    if (internals_pp && *internals_pp)\n        return **internals_pp;\n\n    // Ensure that the GIL is held since we will need to make Python calls.\n    // Cannot use py::gil_scoped_acquire here since that constructor calls get_internals.\n    struct gil_scoped_acquire_local {\n        gil_scoped_acquire_local() : state (PyGILState_Ensure()) {}\n        ~gil_scoped_acquire_local() { PyGILState_Release(state); }\n        const PyGILState_STATE state;\n    } gil;\n\n    constexpr auto *id = PYBIND11_INTERNALS_ID;\n    auto builtins = handle(PyEval_GetBuiltins());\n    if (builtins.contains(id) && isinstance<capsule>(builtins[id])) {\n        internals_pp = static_cast<internals **>(capsule(builtins[id]));\n\n        // We loaded builtins through python's builtins, which means that our `error_already_set`\n        // and `builtin_exception` may be different local classes than the ones set up in the\n        // initial exception translator, below, so add another for our local exception classes.\n        //\n        // libstdc++ doesn't require this (types there are identified only by name)\n#if !defined(__GLIBCXX__)\n        (*internals_pp)->registered_exception_translators.push_front(&translate_local_exception);\n#endif\n    } else {\n        if (!internals_pp) internals_pp = new internals*();\n        auto *&internals_ptr = *internals_pp;\n        internals_ptr = new internals();\n#if defined(WITH_THREAD)\n        PyEval_InitThreads();\n        PyThreadState *tstate = PyThreadState_Get();\n        #if PY_VERSION_HEX >= 0x03070000\n            internals_ptr->tstate = PyThread_tss_alloc();\n            if (!internals_ptr->tstate || PyThread_tss_create(internals_ptr->tstate))\n                pybind11_fail(\"get_internals: could not successfully initialize the TSS key!\");\n            PyThread_tss_set(internals_ptr->tstate, tstate);\n        #else\n            internals_ptr->tstate = PyThread_create_key();\n            if (internals_ptr->tstate == -1)\n                pybind11_fail(\"get_internals: could not successfully initialize the TLS key!\");\n            PyThread_set_key_value(internals_ptr->tstate, tstate);\n        #endif\n        internals_ptr->istate = tstate->interp;\n#endif\n        builtins[id] = capsule(internals_pp);\n        internals_ptr->registered_exception_translators.push_front(&translate_exception);\n        internals_ptr->static_property_type = make_static_property_type();\n        internals_ptr->default_metaclass = make_default_metaclass();\n        internals_ptr->instance_base = make_object_base_type(internals_ptr->default_metaclass);\n    }\n    return **internals_pp;\n}\n\n/// Works like `internals.registered_types_cpp`, but for module-local registered types:\ninline type_map<type_info *> &registered_local_types_cpp() {\n    static type_map<type_info *> locals{};\n    return locals;\n}\n\n/// Constructs a std::string with the given arguments, stores it in `internals`, and returns its\n/// `c_str()`.  Such strings objects have a long storage duration -- the internal strings are only\n/// cleared when the program exits or after interpreter shutdown (when embedding), and so are\n/// suitable for c-style strings needed by Python internals (such as PyTypeObject's tp_name).\ntemplate <typename... Args>\nconst char *c_str(Args &&...args) {\n    auto &strings = get_internals().static_strings;\n    strings.emplace_front(std::forward<Args>(args)...);\n    return strings.front().c_str();\n}\n\nNAMESPACE_END(detail)\n\n/// Returns a named pointer that is shared among all extension modules (using the same\n/// pybind11 version) running in the current interpreter. Names starting with underscores\n/// are reserved for internal usage. Returns `nullptr` if no matching entry was found.\ninline PYBIND11_NOINLINE void *get_shared_data(const std::string &name) {\n    auto &internals = detail::get_internals();\n    auto it = internals.shared_data.find(name);\n    return it != internals.shared_data.end() ? it->second : nullptr;\n}\n\n/// Set the shared data that can be later recovered by `get_shared_data()`.\ninline PYBIND11_NOINLINE void *set_shared_data(const std::string &name, void *data) {\n    detail::get_internals().shared_data[name] = data;\n    return data;\n}\n\n/// Returns a typed reference to a shared data entry (by using `get_shared_data()`) if\n/// such entry exists. Otherwise, a new object of default-constructible type `T` is\n/// added to the shared data under the given name and a reference to it is returned.\ntemplate<typename T>\nT &get_or_create_shared_data(const std::string &name) {\n    auto &internals = detail::get_internals();\n    auto it = internals.shared_data.find(name);\n    T *ptr = (T *) (it != internals.shared_data.end() ? it->second : nullptr);\n    if (!ptr) {\n        ptr = new T();\n        internals.shared_data[name] = ptr;\n    }\n    return *ptr;\n}\n\nNAMESPACE_END(PYBIND11_NAMESPACE)\n",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/model_compiler/python/nnir_to_clib.py": "# Copyright (c) 2018 - 2020 Advanced Micro Devices, Inc. All rights reserved.\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the \"Software\"), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in\n# all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n# THE SOFTWARE.\n\nimport os, sys, struct, subprocess\nimport datetime, pytz\nfrom nnir import *\n\ntensor_type_nnir2openvx = {\n    'F032' : 'VX_TYPE_FLOAT32',\n    'F016' : 'VX_TYPE_FLOAT16',\n    'U016' : 'VX_TYPE_UINT16',\n    'I016' : 'VX_TYPE_INT16',\n    'U008' : 'VX_TYPE_UINT8'\n}\n\ntensor_type2size = {\n    'F032' : 4,\n    'F016' : 2,\n    'U016' : 2,\n    'I016' : 2,\n    'U008' : 1    \n}\n\ndef generateLicenseForCPP(f):\n        f.write( \\\n\"\"\"/*\nMIT License\n\nCopyright (c) 2019 - 2020 Advanced Micro Devices, Inc. All rights reserved.\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\n/* This file is generated by nnir_to_clib.py on %s */\n\"\"\" % (datetime.datetime.now(tz=pytz.timezone('America/Los_Angeles')).isoformat()))\n\ndef generateLicenseForScript(f):\n        f.write( \\\n\"\"\"################################################################################\n#\n# MIT License\n#\n# Copyright (c) 2019 - 2020 Advanced Micro Devices, Inc.\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the \"Software\"), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in all\n# copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n# SOFTWARE.\n#\n################################################################################\n\n# This file is generated by nnir_to_clib.py on %s\n\"\"\" % (datetime.datetime.now(tz=pytz.timezone('America/Los_Angeles')).isoformat()))\n\ndef generateCMakeFiles(graph,outputFolder):\n    fileName = outputFolder + '/CMakeLists.txt'\n    print('creating ' + fileName + ' ...')\n    with open(fileName, 'w') as f:\n        generateLicenseForScript(f)\n        f.write( \\\n\"\"\"\ncmake_minimum_required (VERSION 2.8)\nproject (mvdeploy)\nset (CMAKE_CXX_STANDARD 11)\nset(CMAKE_LIBRARY_OUTPUT_DIRECTORY ${PROJECT_SOURCE_DIR}/lib)\nset(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${PROJECT_SOURCE_DIR}/bin)\nset(CMAKE_INSTALL_PREFIX /opt/rocm/mivisionx)\n\nlist(APPEND CMAKE_MODULE_PATH ${PROJECT_SOURCE_DIR}/cmake)\nfind_package(OpenCL REQUIRED)\nfind_package(OpenCV QUIET)\ninclude_directories (${OpenCL_INCLUDE_DIRS} ${OpenCL_INCLUDE_DIRS}/Headers )\ninclude_directories (/opt/rocm/mivisionx/include)\nlink_directories    (/opt/rocm/mivisionx/lib)\nlist(APPEND SOURCES mvmodule.cpp)\nadd_library(mv_deploy SHARED ${SOURCES})\nset(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -msse4.2 -std=c++11\")\ntarget_compile_definitions(mv_deploy PRIVATE ENABLE_MVDEPLOY=1)\ntarget_link_libraries(mv_deploy openvx vx_nn pthread ${CMAKE_DL_LIBS})\ninstall (TARGETS mv_deploy DESTINATION lib)\n\noption (USE_POSTPROC  \"Use postprocessing module implementation\" OFF) \nadd_executable(mvtestdeploy mvtestdeploy.cpp mvdeploy_api.cpp)\nif (OpenCV_FOUND)\n  target_compile_definitions(mvtestdeploy PUBLIC ENABLE_OPENCV=1)\n  include_directories(${OpenCV_INCLUDE_DIRS} ${PROJECT_SOURCE_DIR}/lib)\n  target_link_libraries(mvtestdeploy ${OpenCV_LIBRARIES})\nelse(OpenCV_FOUND)\n  target_compile_definitions(mvtestdeploy PUBLIC ENABLE_OPENCV=0)\n  include_directories(${PROJECT_SOURCE_DIR}/lib)\nendif(OpenCV_FOUND)\n#add optional postprocess module\nif (USE_POSTPROC)\n  include_directories (\"${PROJECT_SOURCE_DIR}/mv_extras\")\n  add_subdirectory (mv_extras)\n  set (EXTRA_LIBS ${EXTRA_LIBS} mv_extras)\nendif (USE_POSTPROC)\ntarget_compile_definitions (mvtestdeploy PRIVATE ENABLE_MVDEPLOY=1)\ntarget_link_libraries(mvtestdeploy openvx vx_nn vx_amd_media pthread mv_deploy ${EXTRA_LIBS} ${CMAKE_DL_LIBS})\ninstall (TARGETS mvtestdeploy DESTINATION bin)\n\n\"\"\")\n    if not os.path.isdir(outputFolder + '/cmake'):\n        os.mkdir(outputFolder + '/cmake')\n    fileName = outputFolder + '/cmake/FindOpenCL.cmake'\n    print('creating ' + fileName + ' ...')\n    with open(fileName, 'w') as f:\n        generateLicenseForScript(f)\n        f.write( \\\n\"\"\"\nfind_path(OPENCL_INCLUDE_DIRS\n    NAMES OpenCL/cl.h CL/cl.h\n    HINTS\n    ${OPENCL_ROOT}/include\n    $ENV{AMDAPPSDKROOT}/include\n    PATHS\n    /usr/include\n    /usr/local/include\n    /opt/rocm/opencl/include\n    DOC \"OpenCL header file path\"\n    )\nmark_as_advanced( OPENCL_INCLUDE_DIRS )\n\nif(\"${CMAKE_SIZEOF_VOID_P}\" EQUAL \"8\")\n    find_library( OPENCL_LIBRARIES\n        NAMES OpenCL\n        HINTS\n        ${OPENCL_ROOT}/lib\n        $ENV{AMDAPPSDKROOT}/lib\n        DOC \"OpenCL dynamic library path\"\n        PATH_SUFFIXES x86_64 x64 x86_64/sdk\n        PATHS\n        /usr/lib\n        /opt/rocm/opencl/lib\n        )\nelse( )\n    find_library( OPENCL_LIBRARIES\n        NAMES OpenCL\n        HINTS\n        ${OPENCL_ROOT}/lib\n        $ENV{AMDAPPSDKROOT}/lib\n        DOC \"OpenCL dynamic library path\"\n        PATH_SUFFIXES x86 Win32\n\n        PATHS\n        /usr/lib\n        )\nendif( )\nmark_as_advanced( OPENCL_LIBRARIES )\n\ninclude( FindPackageHandleStandardArgs )\nfind_package_handle_standard_args( OPENCL DEFAULT_MSG OPENCL_LIBRARIES OPENCL_INCLUDE_DIRS )\n\nset(OpenCL_FOUND ${OPENCL_FOUND} CACHE INTERNAL \"\")\nset(OpenCL_LIBRARIES ${OPENCL_LIBRARIES} CACHE INTERNAL \"\")\nset(OpenCL_INCLUDE_DIRS ${OPENCL_INCLUDE_DIRS} CACHE INTERNAL \"\")\n\nif( NOT OPENCL_FOUND )\n    message( STATUS \"FindOpenCL looked for libraries named: OpenCL\" )\nendif()\n\"\"\")\n\ndef generateCMakeExtras(graph,outputFolder):\n    fileName = outputFolder + '/CMakeLists.txt'\n    print('creating ' + fileName + ' ...')\n    with open(fileName, 'w') as f:\n        generateLicenseForScript(f)\n        f.write( \\\n\"\"\"\ncmake_minimum_required (VERSION 2.8)\nproject (mv_extras)\nset (CMAKE_CXX_STANDARD 11)\nlist(APPEND CMAKE_MODULE_PATH ../cmake)\nfind_package(OpenCL REQUIRED)\nfind_package(OpenCV QUIET)\ninclude_directories (${OpenCL_INCLUDE_DIRS} ${OpenCL_INCLUDE_DIRS}/Headers )\ninclude_directories (/opt/rocm/mivisionx/include ../)\nlink_directories    (/opt/rocm/mivisionx/lib)\nadd_library(${PROJECT_NAME} SHARED mv_extras_postproc.cpp)\nset(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -msse4.2 -std=c++11\")\nif (OpenCV_FOUND)\n  target_compile_definitions(mv_extras PUBLIC ENABLE_OPENCV=1)\n  include_directories(${OpenCV_INCLUDE_DIRS})\n  target_link_libraries(mv_extras ${OpenCV_LIBRARIES})\nelse(OpenCV_FOUND)\n  target_compile_definitions(mv_extras PUBLIC ENABLE_OPENCV=0)\nendif(OpenCV_FOUND)\ntarget_link_libraries(mv_extras openvx vx_nn vx_amd_media pthread ${CMAKE_DL_LIBS})\n\"\"\")\n\ndef generateModuleCPP(graph,fileName):\n    print('creating ' + fileName + ' ...')\n    with open(fileName, 'w') as f:\n        generateLicenseForCPP(f)\n        if len(graph.inputs) < 1 or len(graph.outputs) < 1:\n            f.write( \\\n\"\"\"\n#include \"mvdeploy.h\"\n\nMIVID_API_ENTRY void MIVID_API_CALL mvSetLogCallback(mivid_log_callback_f log_callback_f)\n{\n    return;\n}\n\nMIVID_API_ENTRY void MIVID_API_CALL mvSetPreProcessCallback(mivid_add_preprocess_callback_f preproc_f, mv_preprocess_callback_args *preproc_args)\n{\n    return;\n}\n\nMIVID_API_ENTRY void MIVID_API_CALL mvSetPostProcessCallback(mivid_add_postprocess_callback_f postproc_f)\n{\n    return;\n}\n\n\nMIVID_API_ENTRY mv_status MIVID_API_CALL mvQueryInference(int *num_inputs, int *num_outputs, const char **inp_out_config)\n{\n    return MV_FAILURE;\n}\n\nMIVID_API_ENTRY mivid_handle MIVID_API_CALL mvCreateInference(const char * binaryFilename, int mem_type)\n{\n    return nullptr;\n}\n\nMIVID_API_ENTRY mv_status MIVID_API_CALL mvCopyToTensorFromMem(mivid_handle handle, int input_num, void *input_data_ptr, size_t size, mivid_memory_type type)\n{\n    return MV_FAILURE;\n}\n\nMIVID_API_ENTRY mv_status MIVID_API_CALL mvCopyToTensorFromFile(mivid_handle handle, int input_num, const char *input_name, bool reverseOrder, float preprocess_mulfac, float preprocess_addfac)\n{\n    return MV_FAILURE;\n}\n\nMIVID_API_ENTRY mv_status MIVID_API_CALL mvGetOutput(mivid_handle handle, int output_num, void *out_tensor_mem, vx_size size)\n{\n    return MV_FAILURE;    \n}\n\nMIVID_API_ENTRY mv_status MIVID_API_CALL mvProcessInference(mivid_handle handle, float *ptime_in_ms, int num_iterations)\n{\n    return MV_FAILURE;\n}\n\nMIVID_API_ENTRY mv_status MIVID_API_CALL mvScheduleInference(mivid_handle handle);\n{\n    return MV_FAILURE;\n}\n\nMIVID_API_ENTRY mv_status MIVID_API_CALL mvWaitForCompletion(mivid_handle handle)\n{\n    return MV_FAILURE;\n}\n\nMIVID_API_ENTRY mv_status MIVID_API_CALL mvReleaseInference(mivid_handle handle)\n{\n    return MV_FAILURE;\n}\n\n\"\"\")\n\n        else:\n            input_shape = graph.inputs[0].shape\n            input_elm_size = tensor_type2size[graph.inputs[0].type]\n            output_elm_size =  tensor_type2size[graph.outputs[0].type]           \n            input_buf_size = eval('*'.join([str(v) for v in input_shape])) * input_elm_size\n            output_shape = []\n            output_buf_size = []\n            output_str = []\n            input_str = []\n            for i in range(len(graph.inputs)):\n                if i==0:\n                    config = 'input,' + graph.inputs[0].name + ',' + ','.join(str(v) for v in input_shape) + ';'\n                else:\n                    config += 'input' + str(i) + ',' +graph.inputs[i].name + ',' + ','.join(str(v) for v in input_shape) + ';'                    \n                input_str.append('handle->inputs['+ str(i) + ']')\n            for i in range(len(graph.outputs)):\n                output_shape.append(graph.outputs[i].shape)\n                output_buf_size.append(eval('*'.join([str(v) for v in output_shape[i]])) * tensor_type2size[graph.outputs[i].type])\n                config += 'output' + str(i) + ',' +graph.outputs[i].name + ',' + ','.join(str(v) for v in output_shape[i])+';'\n                output_str.append('handle->outputs['+ str(i) + ']')\n            f.write( \\\n\"\"\"\n#include \"mvdeploy.h\"\n\nstatic mivid_log_callback_f g_mv_log_message_callback = nullptr;\nstatic mivid_add_preprocess_callback_f g_mv_preprocess_callback = nullptr;\nstatic mivid_add_postprocess_callback_f g_mv_postprocess_callback = nullptr;\nstatic mv_preprocess_callback_args *g_mv_preproc_args = nullptr;\n\ninline int64_t clockCounter()\n{\n    return std::chrono::high_resolution_clock::now().time_since_epoch().count();\n}\n\ninline int64_t clockFrequency()\n{\n    return std::chrono::high_resolution_clock::period::den / std::chrono::high_resolution_clock::period::num;\n}\n\nstatic void MIVID_CALLBACK log_callback(vx_context context, vx_reference ref, vx_status status, const vx_char string[])\n{\n    if (g_mv_log_message_callback) {\n        g_mv_log_message_callback(string);\n    }else\n    {\n        size_t len = strlen(string);\n        if (len > 0) {\n            printf(\"%%s\", string);\n            if (string[len - 1] != '\\\\n')\n                printf(\"\\\\n\");\n            fflush(stdout);\n        }\n    }\n}\n\nstatic mv_status MIVID_CALLBACK preprocess_callback(mivid_session session, vx_tensor inp_tensor)\n{\n    if (g_mv_preprocess_callback) {\n        return (mv_status)g_mv_preprocess_callback(session, inp_tensor, g_mv_preproc_args);\n    }else\n    {\n        printf(\"ERROR: preprocess callback function is not set by user \\\\n\");\n        return MV_FAILURE;\n    }\n}\n\nstatic mv_status MIVID_CALLBACK postprocess_callback(mivid_session session, vx_tensor outp_tensor)\n{\n    if (g_mv_preprocess_callback) {\n        return (mv_status)g_mv_postprocess_callback(session, outp_tensor);\n    }else\n    {\n        printf(\"ERROR: postprocess callback function is not set by user \\\\n\");\n        return MV_FAILURE;\n    }\n}\n\nstatic vx_status initializeTensor(vx_context context, vx_tensor tensor, FILE * fp, const char * binaryFilename)\n{\n    vx_enum data_type = VX_TYPE_FLOAT32;\n    vx_size num_of_dims = 4, dims[4] = { 1, 1, 1, 1 }, stride[4];\n    ERROR_CHECK_STATUS(vxQueryTensor(tensor, VX_TENSOR_DATA_TYPE, &data_type, sizeof(vx_enum)));\n    ERROR_CHECK_STATUS(vxQueryTensor(tensor, VX_TENSOR_NUMBER_OF_DIMS, &num_of_dims, sizeof(vx_size)));\n    ERROR_CHECK_STATUS(vxQueryTensor(tensor, VX_TENSOR_DIMS, &dims, num_of_dims * sizeof(vx_size)));\n    vx_size itemsize = sizeof(float);\n    if(data_type == VX_TYPE_UINT8 || data_type == VX_TYPE_INT8) {\n        itemsize = sizeof(vx_uint8);\n    }\n    else if(data_type == VX_TYPE_UINT16 || data_type == VX_TYPE_INT16 || data_type == VX_TYPE_FLOAT16) {\n        itemsize = sizeof(vx_uint16);\n    }\n    vx_size count = dims[0] * dims[1] * dims[2] * dims[3];\n\n    vx_uint32 h[2] = { 0 };\n    fread(h, 1, sizeof(h), fp);\n    if(h[0] != 0xf00dd1e1 || (vx_size)h[1] != (count*itemsize)) {\n      vxAddLogEntry((vx_reference)tensor, VX_FAILURE, \"ERROR: invalid data (magic,size)=(0x%%x,%%d) in %%s at byte position %%d -- expected size is %%ld\\\\n\", h[0], h[1], binaryFilename, ftell(fp)-sizeof(h), count*itemsize);\n      return VX_FAILURE;\n    }\n\n    vx_map_id map_id;\n    void * ptr;\n    ERROR_CHECK_STATUS(vxMapTensorPatch(tensor, num_of_dims, nullptr, nullptr, &map_id, stride, (void **)&ptr, VX_WRITE_ONLY, VX_MEMORY_TYPE_HOST, 0));\n    vx_size n = fread(ptr, itemsize, count, fp);\n    if(n != count) {\n        vxAddLogEntry((vx_reference)tensor, VX_FAILURE, \"ERROR: expected char[%%ld], but got char[%%ld] in %%s\\\\n\", count*itemsize, n*itemsize, binaryFilename);\n        return VX_FAILURE;\n    }\n    ERROR_CHECK_STATUS(vxUnmapTensorPatch(tensor, map_id));\n\n    return VX_SUCCESS;\n}\n\n\n//! \\brief Set callback for log messages.\n//  - by default, log messages from library will be printed to stdout\n//  - the log messages can be redirected to application using a callback\nMIVID_API_ENTRY void MIVID_API_CALL mvSetLogCallback(mivid_log_callback_f log_callback_f)\n{\n    g_mv_log_message_callback = log_callback_f;\n}\n\n//! \\brief: load and add preprocessing module/nodes to graph if needed.\n// need to call this before calling CreateInferenceSession\n// output of the preprocessing node should be same as input tensor NN module\nMIVID_API_ENTRY void MIVID_API_CALL mvSetPreProcessCallback(mivid_add_preprocess_callback_f preproc_f, mv_preprocess_callback_args *preproc_args)\n{\n    g_mv_preprocess_callback = preproc_f;\n    g_mv_preproc_args = preproc_args;\n}\n\n//! \\brief: load and add postprocessing modules/nodes to graph if needed.\n// need to call this before calling CreateInferenceSession\n// input to the preprocessing node should be same as output tensor of NN module\nMIVID_API_ENTRY void MIVID_API_CALL mvSetPostProcessCallback(mivid_add_postprocess_callback_f postproc_f)\n{\n    g_mv_postprocess_callback = postproc_f;\n}\n\n\nMIVID_API_ENTRY vx_status MIVID_API_CALL mvAddToGraph(vx_graph graph, %s, %s, const char * binaryFilename)\n{\n    vx_context context = vxGetContext((vx_reference)graph);\n    ERROR_CHECK_OBJECT(context);\n\n    // create variables\n\"\"\" % (', '.join(['vx_tensor ' + tensor.name for tensor in graph.inputs]), \\\n       ', '.join(['vx_tensor ' + tensor.name for tensor in graph.outputs])))\n        for tensor in graph.initializers:\n            f.write( \\\n\"\"\"    vx_size dims_%s[%d] = { %s };\n    vx_tensor %s = vxCreateTensor(context, %d, dims_%s, %s, 0);\n    ERROR_CHECK_OBJECT(%s);\n\"\"\" %(tensor.name, len(tensor.shape), ', '.join([str(v) for v in reversed(tensor.shape)]), \\\n      tensor.name, len(tensor.shape), tensor.name, tensor_type_nnir2openvx[tensor.type], tensor.name))\n        f.write( \\\n\"\"\"\n    // initialize variables\n    FILE * fp__variables = fopen(binaryFilename, \"rb\");\n    if(!fp__variables) {\n        vxAddLogEntry((vx_reference)context, VX_FAILURE, \"ERROR: unable to open: %s\\\\n\", binaryFilename);\n        return VX_FAILURE;\n    }\n    { vx_uint32 magic = 0;\n      fread(&magic, 1, sizeof(magic), fp__variables);\n      if(magic != 0xf00dd1e0) {\n        vxAddLogEntry((vx_reference)context, VX_FAILURE, \"ERROR: invalid file magic in %s\\\\n\", binaryFilename);\n        return VX_FAILURE;\n      }\n    }\n\"\"\")\n        for tensor in graph.initializers:\n            f.write( \\\n\"\"\"    ERROR_CHECK_STATUS(initializeTensor(context, %s, fp__variables, binaryFilename));\n\"\"\" %(tensor.name))\n        f.write( \\\n\"\"\"    { vx_uint32 magic = 0;\n      fread(&magic, 1, sizeof(magic), fp__variables);\n      if(magic != 0xf00dd1e2) {\n        vxAddLogEntry((vx_reference)context, VX_FAILURE, \"ERROR: invalid eoff magic in %s\\\\n\", binaryFilename);\n        return VX_FAILURE;\n      }\n      fclose(fp__variables);\n    }\n\n    // create local tensors used in graph\n\"\"\")\n        localList = []\n        for tensor in graph.locals:\n            localList.append(tensor.name)\n        outputList = []\n        for tensor in graph.outputs:\n            outputList.append(tensor.name)\n        for idx, tensor in enumerate(graph.locals):\n            if (not tensor.name in outputList) and (not tensor.name in localList[:idx]):\n                f.write( \\\n\"\"\"    vx_size dims_%s[%d] = { %s };\n    vx_tensor %s = vxCreateVirtualTensor(graph, %d, dims_%s, %s, 0);\n    ERROR_CHECK_OBJECT(%s);\n\"\"\" %(tensor.name, len(tensor.shape), ', '.join([str(v) for v in reversed(tensor.shape)]), \\\n      tensor.name, len(tensor.shape), tensor.name, tensor_type_nnir2openvx[tensor.type], tensor.name))\n        f.write( \\\n\"\"\"\n    // create nodes in graph\n\"\"\")\n        for node in graph.nodes:\n            if node.type == 'conv':\n                pads = node.attr.get('pads')\n                dilations = node.attr.get('dilations')\n                f.write( \\\n\"\"\"\n    { vx_nn_convolution_params_t conv_params = { 0 };\n      conv_params.padding_x = %d;\n      conv_params.padding_y = %d;\n      conv_params.overflow_policy = VX_CONVERT_POLICY_SATURATE;\n      conv_params.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;\n      conv_params.down_scale_size_rounding = VX_NN_DS_SIZE_ROUNDING_FLOOR;\n      conv_params.dilation_x = %d;\n      conv_params.dilation_y = %d;\n      vx_node node = vxConvolutionLayer(graph, %s, %s, %s, &conv_params, sizeof(conv_params), %s);\n      ERROR_CHECK_OBJECT(node);\n\"\"\" % (pads[0], pads[1], dilations[0] - 1, dilations[1] - 1, \\\n      node.inputs[0], node.inputs[1], node.inputs[2] if len(node.inputs) == 3 else 'nullptr', node.outputs[0]))\n                if (node.attr.get('mode') != 0):\n                    f.write( \\\n\"\"\"      vx_float32 alpha = 0;\n      vx_scalar s_alpha = vxCreateScalarWithSize(context, VX_TYPE_FLOAT32, &alpha, sizeof(alpha));\n      ERROR_CHECK_STATUS(vxSetParameterByIndex(node, 5, (vx_reference) s_alpha));\n      ERROR_CHECK_STATUS(vxReleaseScalar(&s_alpha));\n\"\"\")\n                f.write( \\\n\"\"\"      ERROR_CHECK_STATUS(vxReleaseNode(&node));\n    }\n\"\"\")\n            elif node.type == 'conv_transpose':\n                pads = node.attr.get('pads')\n                dilations = node.attr.get('dilations')\n                kernel_shape = node.attr.get('kernel_shape')\n                output_pads = [(dilations[0] - 1) * (kernel_shape[0] - 1), \\\n                                (dilations[1] - 1) * (kernel_shape[1] - 1)]\n                f.write( \\\n\"\"\"\n    { vx_nn_deconvolution_params_t conv_params = { 0 };\n      conv_params.padding_x = %d;\n      conv_params.padding_y = %d;\n      conv_params.overflow_policy = VX_CONVERT_POLICY_SATURATE;\n      conv_params.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;\n      conv_params.a_x = %d;\n      conv_params.a_y = %d;\n      vx_node node = vxDeconvolutionLayer(graph, %s, %s, %s, &conv_params, sizeof(conv_params), %s);\n      ERROR_CHECK_OBJECT(node);\n      ERROR_CHECK_STATUS(vxReleaseNode(&node));\n    }\n\"\"\" % (pads[0], pads[1], output_pads[0] , output_pads[1] , \\\n      node.inputs[0], node.inputs[1], node.inputs[2] if len(node.inputs) == 3 else 'nullptr', node.outputs[0]))\n            elif node.type == 'gemm':\n                alpha = node.attr.get('alpha')\n                beta = node.attr.get('beta')\n                transA = node.attr.get('transA')\n                transB = node.attr.get('transB')\n                hasBias = False\n                if beta == 1.0 and len(node.inputs) == 3 and len(graph.tensor_shapes[node.inputs[2]]) <= 2:\n                    hasBias = True\n                if alpha == 1.0 and transA == 0 and transB == 1 and (beta == 0.0 or hasBias):\n                    f.write( \\\n\"\"\"\n    { vx_node node = vxFullyConnectedLayer(graph, %s, %s, %s, VX_CONVERT_POLICY_SATURATE, VX_ROUND_POLICY_TO_NEAREST_EVEN, %s);\n      ERROR_CHECK_OBJECT(node);\n      ERROR_CHECK_STATUS(vxReleaseNode(&node));\n    }\n\"\"\" % ( \\\n        node.inputs[0], node.inputs[1], node.inputs[2] if hasBias else 'nullptr', node.outputs[0]))\n                else:\n                    raise ValueError(\"Unsupported gemm configuration by OpenVX: alpha={} beta={} transA={} transB={}\".format(alpha, beta, transA, transB))\n            elif node.type == 'max_pool' or node.type == 'avg_pool':\n                f.write( \\\n\"\"\"\n    { vx_node node = vxPoolingLayer(graph, %s, %s, %d, %d, %d, %d, VX_ROUND_POLICY_TO_NEAREST_EVEN, %s);\n      ERROR_CHECK_OBJECT(node);\n      vx_enum border_mode = %d;\n      vx_scalar s_border_mode = vxCreateScalarWithSize(context, VX_TYPE_ENUM, &border_mode, sizeof(border_mode));\n      ERROR_CHECK_OBJECT(s_border_mode);\n      ERROR_CHECK_STATUS(vxSetParameterByIndex(node, 8, (vx_reference) s_border_mode));\n      ERROR_CHECK_STATUS(vxReleaseScalar(&s_border_mode));\n\"\"\" % (node.inputs[0], 'VX_NN_POOLING_AVG' if node.type == 'avg_pool' else 'VX_NN_POOLING_MAX', \\\n       node.attr.get('kernel_shape')[0], node.attr.get('kernel_shape')[1], \\\n       node.attr.get('pads')[0], node.attr.get('pads')[1], node.outputs[0], \\\n       (1 if node.attr.get('border_mode') == 'discard' else 0)))\n                if (node.attr.get('mode') != 0):\n                    f.write( \\\n\"\"\"      vx_int32 mode = %s;\n      vx_scalar s_mode = vxCreateScalarWithSize(context, VX_TYPE_INT32, &mode, sizeof(mode));\n      ERROR_CHECK_STATUS(vxSetParameterByIndex(node, 9, (vx_reference) s_mode));\n      ERROR_CHECK_STATUS(vxReleaseScalar(&s_mode));\n\"\"\" % (node.attr.get('mode')))\n                f.write( \\\n\"\"\"      ERROR_CHECK_STATUS(vxReleaseNode(&node));\n    }\n\"\"\")\n            elif node.type == 'global_avg_pool':\n                f.write( \\\n\"\"\"\n    { vx_node node = vxPoolingLayer(graph, %s, VX_NN_POOLING_AVG, %d, %d, %d, %d, VX_ROUND_POLICY_TO_NEAREST_EVEN, %s);\n      ERROR_CHECK_OBJECT(node);\n\"\"\" % (node.inputs[0], graph.tensor_shapes[node.inputs[0]][2], graph.tensor_shapes[node.inputs[0]][3], \\\n       node.attr.get('pads')[0], node.attr.get('pads')[1], node.outputs[0]))\n                if (node.attr.get('mode') != 0):\n                    f.write( \\\n\"\"\"      vx_int32 mode = %s;\n      vx_scalar s_mode = vxCreateScalarWithSize(context, VX_TYPE_INT32, &mode, sizeof(mode));\n      ERROR_CHECK_STATUS(vxSetParameterByIndex(node, 9, (vx_reference) s_mode));\n      ERROR_CHECK_STATUS(vxReleaseScalar(&s_mode));\n\"\"\" % (node.attr.get('mode')))\n                f.write( \\\n\"\"\"      ERROR_CHECK_STATUS(vxReleaseNode(&node));\n    }\n\"\"\")\n            elif node.type == 'relu':\n                f.write( \\\n\"\"\"\n    { vx_node node = vxActivationLayer(graph, %s, VX_NN_ACTIVATION_RELU, 0.0f, 0.0f, %s);\n      ERROR_CHECK_OBJECT(node);\n      ERROR_CHECK_STATUS(vxReleaseNode(&node));\n    }\n\"\"\" % (node.inputs[0], node.outputs[0]))\n            elif node.type == 'leaky_relu':\n                f.write( \\\n\"\"\"\n    {  vx_node node = vxActivationLayer(graph, %s, VX_NN_ACTIVATION_LEAKY_RELU, %f, 0.0f, %s);\n       ERROR_CHECK_OBJECT(node);\n       ERROR_CHECK_STATUS(vxReleaseNode(&node));\n    }\n\"\"\" % (node.inputs[0], node.attr.get('alpha'), node.outputs[0]))\n            elif node.type == 'add' or node.type == 'sum':\n                if len(node.inputs) == 2:\n                    f.write( \\\n\"\"\"\n    { vx_node node = vxTensorAddNode(graph, %s, %s, VX_CONVERT_POLICY_SATURATE, %s);\n      ERROR_CHECK_OBJECT(node);\n      ERROR_CHECK_STATUS(vxReleaseNode(&node));\n    }\n\"\"\" % (node.inputs[0], node.inputs[1], node.outputs[0]))\n                else:\n                    raise ValueError(\"Unsupported number of input arguments by OpenVX: {}\".format(node.type))\n            elif node.type == 'sub':\n                if len(node.inputs) == 2:\n                    f.write( \\\n\"\"\"\n    { vx_node node = vxTensorSubtractNode(graph, %s, %s, VX_CONVERT_POLICY_SATURATE, %s);\n      ERROR_CHECK_OBJECT(node);\n      ERROR_CHECK_STATUS(vxReleaseNode(&node));\n    }\n\"\"\" % (node.inputs[0], node.inputs[1], node.outputs[0]))\n                else:\n                    raise ValueError(\"Unsupported number of input arguments by OpenVX: {}\".format(node.type))\n            elif node.type == 'mul':\n                if len(node.inputs) == 2:\n                    f.write( \\\n\"\"\"\n    { vx_float32 value = 1.0f;\n      vx_scalar scale = vxCreateScalar(context, VX_TYPE_FLOAT32, &value);\n      ERROR_CHECK_OBJECT(scale);\n      vx_node node = vxTensorMultiplyNode(graph, %s, %s, scale, VX_CONVERT_POLICY_SATURATE, VX_ROUND_POLICY_TO_NEAREST_EVEN, %s);\n      ERROR_CHECK_STATUS(vxReleaseScalar(&scale));\n      ERROR_CHECK_OBJECT(node);\n      ERROR_CHECK_STATUS(vxReleaseNode(&node));\n    }\n\"\"\" % (node.inputs[0], node.inputs[1], node.outputs[0]))\n                else:\n                    raise ValueError(\"Unsupported number of input arguments by OpenVX: {}\".format(node.type))\n            elif node.type == 'muladd':\n                tensor = graph.tensor_dict[node.inputs[0]]\n                f.write( \\\n\"\"\"\n    { vx_float32 value = 1.0f;\n      vx_scalar scale = vxCreateScalar(context, VX_TYPE_FLOAT32, &value);\n      ERROR_CHECK_OBJECT(scale);\n      vx_size dims[%d] = { %s };\n      vx_tensor tmp__tensor = vxCreateVirtualTensor(graph, %d, dims, %s, 0);\n      ERROR_CHECK_OBJECT(tmp__tensor);\n      vx_node node = vxTensorMultiplyNode(graph, %s, %s, scale, VX_CONVERT_POLICY_SATURATE, VX_ROUND_POLICY_TO_NEAREST_EVEN, tmp__tensor);\n      ERROR_CHECK_STATUS(vxReleaseScalar(&scale));\n      ERROR_CHECK_OBJECT(node);\n      ERROR_CHECK_STATUS(vxReleaseNode(&node));\n      node = vxTensorAddNode(graph, tmp__tensor, %s, VX_CONVERT_POLICY_SATURATE, %s);\n      ERROR_CHECK_OBJECT(node);\n      ERROR_CHECK_STATUS(vxReleaseNode(&node));\n    }\n\"\"\" % (len(tensor.shape), ', '.join([str(v) for v in reversed(tensor.shape)]), len(tensor.shape), \\\n       tensor_type_nnir2openvx[tensor.type], node.inputs[0], node.inputs[1], node.inputs[2], node.outputs[0]))\n            elif node.type == 'batch_norm':\n                f.write( \\\n\"\"\"\n    { vx_node node = vxBatchNormalizationLayer(graph, %s, %s, %s, %s, %s, %ef, %s);\n      ERROR_CHECK_OBJECT(node);\n      ERROR_CHECK_STATUS(vxReleaseNode(&node));\n    }\n\"\"\" % (node.inputs[0], node.inputs[3], node.inputs[4], node.inputs[1], node.inputs[2], node.attr.get('epsilon'), node.outputs[0]))\n            elif node.type == 'lrn':\n                f.write( \\\n\"\"\"\n    { vx_node node = vxNormalizationLayer(graph, %s, %s , %d, %ef, %ef, %s);\n\"\"\" % (node.inputs[0], \"VX_NN_NORMALIZATION_SAME_MAP\" if node.attr.get('mode') == 0 else \"VX_NN_NORMALIZATION_ACROSS_MAPS\" , \\\n       node.attr.get('size'), node.attr.get('alpha'), node.attr.get('beta'), node.outputs[0]))\n                if (node.attr.get('bias') != 1.0):\n                    f.write( \\\n\"\"\"   vx_float32 bias = %s;\n      vx_scalar s_bias = vxCreateScalarWithSize(context, VX_TYPE_FLOAT32, &bias, sizeof(bias));\n      ERROR_CHECK_STATUS(vxSetParameterByIndex(node, 6, (vx_reference) s_bias));\n      ERROR_CHECK_STATUS(vxReleaseScalar(&s_bias));\n\"\"\" % (node.attr.get('bias')))\n                f.write( \\\n\"\"\"   ERROR_CHECK_OBJECT(node);\n      ERROR_CHECK_STATUS(vxReleaseNode(&node));\n    }\n\"\"\")                        \n            elif node.type == 'slice':\n                f.write( \\\n\"\"\"\n    { vx_node node = vxSliceLayer(graph, %s, %s, %s);\n      ERROR_CHECK_OBJECT(node);\n      ERROR_CHECK_STATUS(vxReleaseNode(&node));\n    }\n\"\"\" % (node.inputs[0], ', '.join([name for name in node.outputs]), \\\n       ', '.join(['nullptr' for i in range(8 - len(node.outputs))])))\n            elif node.type == 'concat':\n                f.write( \\\n\"\"\"\n    { vx_node node = vxConcatLayer(graph, %s, %s, %s);\n      ERROR_CHECK_OBJECT(node);\n      ERROR_CHECK_STATUS(vxReleaseNode(&node));\n    }\n\"\"\" % (node.outputs[0], ', '.join([name for name in node.inputs]), \\\n       ', '.join(['nullptr' for i in range(8 - len(node.inputs))])))\n            elif node.type == 'softmax':\n                f.write( \\\n\"\"\"\n    { vx_node node = vxSoftmaxLayer(graph, %s, %s);\n      ERROR_CHECK_OBJECT(node);\n      ERROR_CHECK_STATUS(vxReleaseNode(&node));\n    }\n\"\"\" % (node.inputs[0], node.outputs[0]))\n            elif node.type == 'reshape':\n                f.write( \\\n\"\"\"\n    { vx_node node = vxReshapeLayer(graph, %s, %s);\n      ERROR_CHECK_OBJECT(node);\n      ERROR_CHECK_STATUS(vxReleaseNode(&node));\n    }\n\"\"\" % (node.inputs[0], node.outputs[0]))\n            elif node.type == 'copy'or node.type == 'transpose':\n                f.write( \\\n\"\"\"\n      ERROR_CHECK_OBJECT(node);\n      ERROR_CHECK_STATUS(vxReleaseNode(&node));\n    }\n\"\"\" % (node.inputs[0], node.outputs[0]))\n            elif node.type == 'upsample':\n                f.write( \\\n\"\"\"\n    { vx_node node = vxUpsampleNearestLayer(graph, %s, %s);\n      ERROR_CHECK_OBJECT(node);\n      ERROR_CHECK_STATUS(vxReleaseNode(&node));\n    }    \n\"\"\" % (node.inputs[0], node.outputs[0]))\n            else:\n                raise ValueError(\"Unsupported node by OpenVX: {}\".format(node.type))\n        f.write( \\\n\"\"\"\n    // release local tensors\n\"\"\")\n        for idx, tensor in enumerate(graph.locals):\n            if (not tensor.name in outputList) and (not tensor.name in localList[:idx]):\n                f.write( \\\n\"\"\"    ERROR_CHECK_STATUS(vxReleaseTensor(&%s));\n\"\"\" %(tensor.name))\n        f.write( \\\n\"\"\"\n    // release initializer tensors\n\"\"\")\n        for tensor in graph.initializers:\n            f.write( \\\n\"\"\"    ERROR_CHECK_STATUS(vxReleaseTensor(&%s));\n\"\"\" %(tensor.name))\n        f.write( \\\n\"\"\"\n    return VX_SUCCESS;\n}\n\nconst char * MIVID_API_CALL mvQueryInference(int *num_inputs, int *num_outputs)\n{\n    *num_inputs = %d;\n    *num_outputs = %d;\n    return \"%s\";\n}\n\"\"\" % (len(graph.inputs), len(graph.outputs), config))\n        f.write( \\\n\"\"\"\n\nMIVID_API_ENTRY mivid_handle MIVID_API_CALL mvCreateInference(const char * binaryFilename, int mem_type)\n{\n    bool successful = false;\n\n    mivid_handle handle = new mivid_handle_t();\n    memset(handle, 0, sizeof(mivid_handle_t));\n    if(!handle) {\n        printf(\"ERROR: new mv_handle: failed (nullptr)\\\\n\");\n        return handle;\n    }\n    else {\n        vx_status status;\n        handle->mv_add_preprocess_cb = g_mv_preprocess_callback;\n        handle->mv_add_postprocess_cb = g_mv_postprocess_callback;        \n        handle->context = vxCreateContext();\n        if((status = vxGetStatus((vx_reference)handle->context)) != VX_SUCCESS) {\n            printf(\"ERROR: vxCreateContext: failed (%d)\\\\n\", status);\n        }\n        else {\n            vxRegisterLogCallback(handle->context, log_callback, vx_false_e);\n            handle->graph = vxCreateGraph(handle->context);\n            if((status = vxGetStatus((vx_reference)handle->graph)) != VX_SUCCESS) {\n                printf(\"ERROR: vxCreateGraph: failed (%d)\\\\n\", status);\n                goto fallback;\n            }\n            vx_tensor input_tensor;\n            vx_tensor output_tensor;\n            vx_size inp_stride[4];\n            handle->mem_type_in = mem_type;\n            if (( status = vxLoadKernels(handle->context, \"vx_nn\")) != VX_SUCCESS) {\n                printf(\"ERROR: vxLoadKernels for vx_nn: failed (%d)\\\\n\", status);\n                goto fallback;\n            }\n\"\"\")\n        for tensor in graph.inputs:\n            f.write( \\\n\"\"\"            vx_size inp_dim_%s[%d] = { %s };\n            inp_stride[0] = %d, inp_stride[1] = %d, inp_stride[2] = %d, inp_stride[3] = %d;\n            cl_mem inp_mem = nullptr;\n            if (g_mv_preprocess_callback != nullptr) {\n                input_tensor = vxCreateVirtualTensor(handle->graph, 4, inp_dim_%s, %s, 0);\n                preprocess_callback(handle, input_tensor);\n                handle->inputs.push_back(input_tensor);\n            } else {\n                if (!mem_type) {\n                    input_tensor = vxCreateTensorFromHandle(handle->context, 4, inp_dim_%s, %s, 0, inp_stride, inp_mem, VX_MEMORY_TYPE_HOST);\n                }\n                else {\n                    input_tensor = vxCreateTensorFromHandle(handle->context, 4, inp_dim_%s, %s, 0, inp_stride, inp_mem, VX_MEMORY_TYPE_OPENCL);\n                }\n                if ((status = vxGetStatus((vx_reference)input_tensor)) != VX_SUCCESS) {\n                    printf(\"ERROR: vxCreateTensor(input:[%s]): failed (%%d)\\\\n\", status);\n                }else\n                {\n                    handle->inputs.push_back(input_tensor);\n                }\n            }\n\"\"\" % (tensor.name, len(tensor.shape), ', '.join([str(v) for v in reversed(tensor.shape)]), \\\n        input_elm_size, tensor.shape[3]*input_elm_size, tensor.shape[2]*tensor.shape[3]*input_elm_size, tensor.shape[1]*tensor.shape[2]*tensor.shape[3]*input_elm_size, \\\n        tensor.name, tensor_type_nnir2openvx[tensor.type], tensor.name, tensor_type_nnir2openvx[tensor.type], tensor.name, tensor_type_nnir2openvx[tensor.type], tensor.name))\n        for tensor in graph.outputs:\n            f.write( \\\n\"\"\"            vx_size out_dim_%d[%d] = { %s };\n            output_tensor = vxCreateTensor(handle->context, %d, out_dim_%d, %s, 0);\n            if ((status = vxGetStatus((vx_reference)output_tensor)) != VX_SUCCESS) {\n                printf(\"ERROR: vxCreateTensor(output:[%s]): failed (%%d)\\\\n\", status);\n            }\n            else {\n                handle->outputs.push_back(output_tensor);\n\"\"\" % (i, len(tensor.shape), ', '.join([str(v) for v in reversed(tensor.shape)]), \\\n       len(tensor.shape), i, tensor_type_nnir2openvx[tensor.type], 'x'.join([str(v) for v in tensor.shape])))\n            f.write( \\\n\"\"\"\n                if((status = mvAddToGraph(handle->graph, %s, %s, binaryFilename)) != VX_SUCCESS) {\n                    printf(\"ERROR: mvAddToGraph: failed (%%d)\\\\n\", status);\n                }\n                else if((status = vxVerifyGraph(handle->graph)) != VX_SUCCESS) {\n                    printf(\"ERROR: vxVerifyGraph: failed (%%d)\\\\n\", status);\n                }\n                else {\n                    successful = true;\n                }\n            }\n        }\n    }\nfallback:\n    if(!successful && handle) {\n\"\"\" % (', '.join(input_str), ', '.join(output_str)))\n            for i in range(len(graph.inputs)):\n                f.write( \\\n\"\"\"        if(handle->inputs[%d])\n            vxReleaseTensor(&handle->inputs[%d]);\n\"\"\" % ( i, i))          \n            for i in range(len(graph.outputs)):\n                f.write( \\\n\"\"\"        if(handle->outputs[%d])\n            vxReleaseTensor(&handle->outputs[%d]);\n\"\"\" % ( i, i))          \n            f.write( \\\n\"\"\"        if(handle->graph)\n            vxReleaseGraph(&handle->graph);\n        if(handle->context)\n            vxReleaseContext(&handle->context);\n        delete handle;\n        handle = nullptr;\n    }\n    return handle;\n}\n\nstatic mv_status copyTensor(std::string fileName, vx_size *dims, vx_size *stride, void *write_ptr, vx_enum data_type, float preprocess_mulfac, float preprocess_addfac)\n{\n#if ENABLE_OPENCV\n    if(dims[2] == 3 && fileName.size() > 4 && (fileName.substr(fileName.size()-4, 4) == \".png\" || fileName.substr(fileName.size()-4, 4) == \".jpg\"))\n    {\n        for(size_t n = 0; n < dims[3]; n++) {\n            char imgFileName[1024];\n            sprintf(imgFileName, fileName.c_str(), (int)n);\n            Mat img = imread(imgFileName, CV_LOAD_IMAGE_COLOR);\n            if(!img.data || img.rows != dims[1] || img.cols != dims[0]) {\n                printf(\"ERROR: invalid image or dimensions: %%s\\\\n\", imgFileName);\n                return MV_ERROR_INVALID_TYPE;\n            }\n            for(vx_size y = 0; y < dims[1]; y++) {\n                unsigned char * src = img.data + y*dims[0]*3;\n                if(data_type == VX_TYPE_FLOAT32) {\n                    float * dstR = (float *)write_ptr + ((n * stride[3] + y * stride[1]) >> 2);\n                    float * dstG = dstR + (stride[2] >> 2);\n                    float * dstB = dstG + (stride[2] >> 2);\n                    for(vx_size x = 0; x < dims[0]; x++, src += 3) {\n                        *dstR++ = src[2]*preprocess_mulfac + preprocess_addfac;\n                        *dstG++ = src[1]*preprocess_mulfac + preprocess_addfac;\n                        *dstB++ = src[0]*preprocess_mulfac + preprocess_addfac;\n                    }\n                } else\n                {\n                    unsigned short * dstR = (unsigned short *)write_ptr + ((n * stride[3] + y * stride[1]) >> 2);\n                    unsigned short * dstG = dstR + (stride[2] >> 2);\n                    unsigned short * dstB = dstG + (stride[2] >> 2);                    \n                    for(vx_size x = 0; x < dims[0]; x++, src += 3) {\n                        *dstR++ = _cvtss_sh((float)(src[2]*preprocess_mulfac + preprocess_addfac), 0);\n                        *dstG++ = _cvtss_sh((float)(src[2]*preprocess_mulfac + preprocess_addfac), 0);\n                        *dstB++ = _cvtss_sh((float)(src[2]*preprocess_mulfac + preprocess_addfac), 0);\n                    }\n                }\n            }\n        }\n    }\n    else\n#endif    \n    {\n        FILE * fp = fopen(fileName.c_str(), \"rb\");\n        if(!fp) {\n            std::cerr << \"ERROR: unable to open: \" << fileName << std::endl;\n            return MV_ERROR_INVALID_REFERENCE;\n        }\n        for(size_t n = 0; n < dims[3]; n++) {\n            for(size_t c = 0; c < dims[2]; c++) {\n                for(size_t y = 0; y < dims[1]; y++) {\n                    if(data_type == VX_TYPE_FLOAT32) {\n                        float * ptrY = (float *)write_ptr + ((n * stride[3] + c * stride[2] + y * stride[1]) >> 2);\n                        vx_size n = fread(ptrY, sizeof(float), dims[0], fp);\n                        if(n != dims[0]) {\n                            std::cerr << \"ERROR: couldn't read expected num. of bytes from file \" << fileName << std::endl;\n                            return MV_ERROR_INVALID_DIMENSION;\n                        }\n                    } else {\n                        unsigned short * ptrY = (unsigned short *)write_ptr + ((n * stride[3] + c * stride[2] + y * stride[1]) >> 2);\n                        vx_size n = fread(ptrY, sizeof(unsigned short), dims[0], fp);\n                        if(n != dims[0]) {\n                            std::cerr << \"couldn't read expected num. of bytes from file \" << fileName << std::endl;\n                            return MV_ERROR_INVALID_DIMENSION;\n                        }\n                    }\n                }\n            }\n        }\n        fclose(fp);\n    }\n    return MV_SUCCESS;\n}\n\n\nMIVID_API_ENTRY mv_status MIVID_API_CALL mvCopyToTensorFromMem(mivid_handle handle, int input_num, void *input_data_ptr, size_t size, mivid_memory_type type)\n{\n    // create local tensors used in graph: mem_type = 0 for CPU buffer and 1 for OpenCL\n    vx_status status = VX_SUCCESS;\n    if (!input_data_ptr || !handle) {\n        printf(\"ERROR: mvCopyToTensorFromMem: invalid input memory pointer or inference handle\\\\n\");\n        return MV_FAILURE;\n    }else {\n        // application is passing device memory pointer, do SwapTensorHandle()\n        vx_enum data_type = VX_TYPE_FLOAT32;\n        vx_size num_of_dims = 4, dims[4] = { 1, 1, 1, 1 }, stride[4];\n        vxQueryTensor(handle->inputs[input_num], VX_TENSOR_DATA_TYPE, &data_type, sizeof(data_type));\n        vxQueryTensor(handle->inputs[input_num], VX_TENSOR_NUMBER_OF_DIMS, &num_of_dims, sizeof(num_of_dims));\n        vxQueryTensor(handle->inputs[input_num], VX_TENSOR_DIMS, &dims, sizeof(dims[0])*num_of_dims);\n        if((data_type != VX_TYPE_FLOAT32) && (data_type != VX_TYPE_FLOAT16)) {\n            std::cerr << \"ERROR: mvCopyToTensorFromMem() supports only VX_TYPE_FLOAT32 or VX_TYPE_FLOAT16:\" << std::endl;\n            return MV_ERROR_INVALID_TYPE;\n        }\n        vx_size count = dims[0] * dims[1] * dims[2] * dims[3];\n        if (size != count*%d )\n            return MV_ERROR_INVALID_VALUE;\n\n        if ((status = vxSwapTensorHandle(handle->inputs[input_num], input_data_ptr, nullptr)) != VX_SUCCESS) {\n            printf(\"ERROR: mvCopyToTensorFromMem: vxSwapTensorHandle: failed (%%d)\\\\n\", status);\n        }\n    }\n    return (mv_status)status;\n}\n\"\"\" % (input_elm_size))          \n            f.write( \\\n\"\"\"\n\nMIVID_API_ENTRY mv_status MIVID_API_CALL mvCopyToTensorFromFile(mivid_handle handle, int input_num, const char *input_name, bool reverseOrder, float preprocess_mulfac, float preprocess_addfac)\n{\n    // create local tensors used in graph: mem_type = 0 for CPU buffer and 1 for OpenCL\n    vx_status status = VX_SUCCESS;\n    if (input_name == nullptr) {\n        printf(\"ERROR: mvCopyToTensorFromFile: invalid input memory pointer or inference handle\\\\n\");\n        return MV_FAILURE;\n    }else {\n        std::string fileName(input_name);\n        // application is passing device memory pointer, do SwapTensorHandle()\n        vx_enum data_type = VX_TYPE_FLOAT32;\n        vx_size num_of_dims = 4, dims[4] = { 1, 1, 1, 1 };\n        vxQueryTensor(handle->inputs[input_num], VX_TENSOR_DATA_TYPE, &data_type, sizeof(data_type));\n        vxQueryTensor(handle->inputs[input_num], VX_TENSOR_NUMBER_OF_DIMS, &num_of_dims, sizeof(num_of_dims));\n        vxQueryTensor(handle->inputs[input_num], VX_TENSOR_DIMS, &dims, sizeof(dims[0])*num_of_dims);\n        if((data_type != VX_TYPE_FLOAT32) && (data_type != VX_TYPE_FLOAT16)) {\n            std::cerr << \"ERROR: mvCopyToTensorFromMem() supports only VX_TYPE_FLOAT32 or VX_TYPE_FLOAT16:\" << std::endl;\n            return MV_ERROR_INVALID_TYPE;\n        }\n        if (handle->mem_type_in == mv_mem_type_host) {\n            void * ptr;\n            vx_map_id map_id;\n            vx_size stride[4] = {%d, dims[0]*%d, dims[0]*dims[1]*%d, dims[0]*dims[1]*dims[2]*%d};\n            vx_status status = vxMapTensorPatch(handle->inputs[input_num], num_of_dims, nullptr, nullptr, &map_id, stride, (void **)&ptr, VX_WRITE_ONLY, VX_MEMORY_TYPE_HOST, 0);\n            if(status) {\n                std::cerr << \"ERROR: vxMapTensorPatch() failed for \" << fileName << std::endl;\n                return MV_FAILURE;\n            }\n            status = copyTensor(fileName, dims, stride, ptr, data_type, preprocess_mulfac, preprocess_addfac);\n            status = vxUnmapTensorPatch(handle->inputs[input_num], map_id);\n            if(status) {\n                std::cerr << \"ERROR: vxUnmapTensorPatch() failed for \" << fileName << std::endl;\n                return MV_FAILURE;\n            }\n        } else if (handle->mem_type_in == mv_mem_type_opencl) {\n            printf(\"ERROR: mvSetInputDataFromFile: INVALID_MEM_TYPE\\\\n\");\n            return MV_ERROR_INVALID_VALUE;\n\n        } else {\n            printf(\"ERROR: mvSetInputDataFromFile: INVALID_MEM_TYPE\\\\n\");\n            return MV_ERROR_INVALID_VALUE;\n        }\n    }\n    return (mv_status)status;\n}\n\"\"\" % (input_elm_size, input_elm_size, input_elm_size, input_elm_size))          \n            f.write( \\\n\"\"\"\n\nMIVID_API_ENTRY mv_status MIVID_API_CALL mvGetOutput(mivid_handle handle, int output_num, void *out_tensor_mem, vx_size size)\n{\n    vx_status status = VX_SUCCESS;\n    if(!handle || !handle->outputs[output_num] || !out_tensor_mem) {\n        printf(\"ERROR: mvGetOutput: invalid handle or output_mem pointer\\\\n\");\n        status = MV_FAILURE;\n    }\n    else if(handle->outputs[output_num]) {\n        // access the tensor object\n        vx_enum data_type = VX_TYPE_FLOAT32;\n        vx_size num_of_dims = 4, dims[4] = { 1, 1, 1, 1 };\n        vxQueryTensor(handle->outputs[output_num], VX_TENSOR_DATA_TYPE, &data_type, sizeof(data_type));\n        vxQueryTensor(handle->outputs[output_num], VX_TENSOR_NUMBER_OF_DIMS, &num_of_dims, sizeof(num_of_dims));\n        vxQueryTensor(handle->outputs[output_num], VX_TENSOR_DIMS, &dims, sizeof(dims[0])*num_of_dims);\n        if((data_type != VX_TYPE_FLOAT32) && (data_type != VX_TYPE_FLOAT16)) {\n            std::cerr << \"ERROR: mvGetOutput() supports only VX_TYPE_FLOAT32 or VX_TYPE_FLOAT16 \" << std::endl;\n            return MV_ERROR_INVALID_TYPE;\n        }\n        vx_size count = dims[0] * dims[1] * dims[2] * dims[3];\n        vx_size stride[4] = {%d, dims[0]*%d, dims[0]*dims[1]*%d, dims[0]*dims[1]*dims[2]*%d};\n        if (size < count*%d){\n            return MV_ERROR_INVALID_DIMENSION;\n        }\n\n        if ((status = vxCopyTensorPatch(handle->outputs[output_num], num_of_dims, nullptr, nullptr, stride, out_tensor_mem, VX_READ_ONLY, VX_MEMORY_TYPE_HOST)) != VX_SUCCESS) {\n            printf(\"ERROR: ideGetOutput: vxCopyTensorPatch: failed (%%d)\\\\n\", status);\n        }\n    }\n    return (mv_status)status;\n}\n\"\"\" % (output_elm_size, output_elm_size, output_elm_size, output_elm_size, output_elm_size))          \n        f.write( \\\n\"\"\"\nMIVID_API_ENTRY mv_status MIVID_API_CALL mvProcessInference(mivid_handle handle, float *ptime_in_ms, int num_iterations)\n{\n    vx_status status = VX_SUCCESS;\n    if(!handle) {\n        printf(\"ERROR: mvProcessInference: invalid handle\\\\n\");\n        status = MV_FAILURE;\n    }\n    else {\n        if (num_iterations > 1) {\n            int64_t freq = clockFrequency(), t0, t1;\n            t0 = clockCounter();\n            for(int i = 0; i < num_iterations; i++) {\n                status = vxProcessGraph(handle->graph);\n                if(status != VX_SUCCESS)\n                    break;\n            }\n            t1 = clockCounter();\n            *ptime_in_ms = (float)(t1-t0)*1000.0f/(float)freq/(float)num_iterations;\n            printf(\"OK: mvProcessInference() took %.3f msec (average over %d iterations)\\\\n\", *ptime_in_ms, num_iterations);\n        } else {\n            status = vxProcessGraph(handle->graph);\n        }\n    }\n    return (mv_status)status;\n}\n\nMIVID_API_ENTRY mv_status MIVID_API_CALL mvScheduleInference(mivid_handle handle)\n{\n    vx_status status = VX_SUCCESS;\n    if(!handle) {\n        status = VX_FAILURE;\n        printf(\"ERROR: ideScheduleInference: invalid handle\\\\n\");\n    }\n    else if ((status = vxScheduleGraph(handle->graph)) == VX_SUCCESS)\n        handle->scheduled = true;\n    else {\n        handle->scheduled = false;\n        printf(\"ERROR: mvScheduleInference: failed (%d)\\\\n\", status);\n    }\n    return (mv_status)status;\n}\n\nMIVID_API_ENTRY mv_status MIVID_API_CALL mvWaitForCompletion(mivid_handle handle)\n{\n    vx_status status = VX_SUCCESS;\n    if(!handle || !handle->scheduled) {\n        status = VX_FAILURE;\n        printf(\"ERROR: ideWaitForCompletion: invalid handle\\\\n\");\n    }\n    else if(handle->scheduled && ((status = vxWaitGraph(handle->graph)) == VX_SUCCESS)) {\n        handle->scheduled = false;\n    } else\n        printf(\"ERROR: mvWaitForCompletion: failed\\\\n\");\n\n    return (mv_status)status;\n}\n\nmv_status MIVID_API_CALL mvReleaseInference(mivid_handle handle)\n{\n    mv_status status = MV_SUCCESS;\n    vx_status ret;\n    if(!handle) {\n        printf(\"ERROR: mvReleaseInference: invalid handle\\\\n\");\n        status = MV_FAILURE;\n    }\n    else if(handle->graph && (ret = vxReleaseGraph(&handle->graph)) != VX_SUCCESS) {\n        printf(\"ERROR: mvReleaseInference: vxReleaseGraph: failed (%d)\\\\n\", ret);\n        status = MV_FAILURE;\n    }\n    else {\n        for (int i=0; i<handle->num_inputs; i++) {\n            if(handle->inputs[i] && (ret = vxReleaseTensor(&handle->inputs[i])) != VX_SUCCESS) {\n                printf(\"ERROR: mvReleaseInference: vxReleaseTensor(input<%d>): failed (%d)\\\\n\", i,ret);\n                status = MV_FAILURE;\n            }\n        }\n        for (int i=0; i<handle->num_outputs; i++) {\n            if(handle->outputs[i] && (ret = vxReleaseTensor(&handle->outputs[i])) != VX_SUCCESS) {\n                printf(\"ERROR: mvReleaseInference: vxReleaseTensor(output<%d>): failed (%d)\\\\n\", i,ret);\n                status = MV_FAILURE;\n            }\n        }\n    }\n    if(handle->context && (ret = vxReleaseContext(&handle->context)) != VX_SUCCESS) {\n        printf(\"ERROR: mvReleaseInference: vxReleaseContext: failed (%d)\\\\n\", ret);\n        status = MV_FAILURE;\n    }\n    else {\n        delete handle;\n    }\n    return status;\n}\n\n\"\"\")\n\ndef generateDeployCPP(graph, fileName):\n    print('creating ' + fileName + ' ...')\n    with open(fileName, 'w') as f:\n        generateLicenseForCPP(f)\n        f.write( \\\n\"\"\"\n//mivid_api.cpp :: some definitions for mivid_api.cpp\n#include \"mvdeploy.h\"\n\nmvDeployAPI::mvDeployAPI(const char *library_name)\n{\n    libHandle = dlopen(library_name, RTLD_NOW | RTLD_LOCAL);\n    if (!libHandle)\n    {\n        printf(\"ERROR: couldn't load MIVisionX deployment lib %s errorcode: %s \\\\n\", library_name, dlerror());\n        mvQueryInference_f          = nullptr;\n        mvSetLogCallback_f          = nullptr;\n        mvSetPreProcessCallback_f   = nullptr;\n        mvSetPostProcessCallback_f  = nullptr;\n        mvCreateInference_f         = nullptr;\n        mvCopyToTensorFromMem_f     = nullptr;\n        mvCopyToTensorFromFile_f    = nullptr;\n        mvProcessInference_f        = nullptr;\n        mvGetOutput_f               = nullptr;\n        mvScheduleInference_f       = nullptr;\n        mvWaitForCompletion_f       = nullptr;\n        mvReleaseInference_f        = nullptr;\n    } else {\n        mvQueryInference_f          = (mvQueryInference_t) dlsym(libHandle, \"mvQueryInference\");\n        mvSetLogCallback_f          = (mvSetLogCallback_t) dlsym(libHandle, \"mvSetLogCallback\");\n        mvSetPreProcessCallback_f   = (mvSetPreProcessCallback_t) dlsym(libHandle, \"mvSetPreProcessCallback\");\n        mvSetPostProcessCallback_f  = (mvSetPostProcessCallback_t) dlsym(libHandle, \"mvSetPostProcessCallback\");\n        mvCreateInference_f         = (mvCreateInference_t) dlsym(libHandle, \"mvCreateInference\");\n        mvCopyToTensorFromMem_f     = (mvCopyToTensorFromMem_t) dlsym(libHandle, \"mvCopyToTensorFromMem\");\n        mvCopyToTensorFromFile_f    = (mvCopyToTensorFromFile_t) dlsym(libHandle, \"mvCopyToTensorFromFile\");\n        mvProcessInference_f        = (mvProcessInference_t) dlsym(libHandle, \"mvProcessInference\");\n        mvGetOutput_f               = (mvGetOutput_t) dlsym(libHandle, \"mvGetOutput\");\n        mvScheduleInference_f       = (mvScheduleInference_t) dlsym(libHandle, \"mvScheduleInference\");\n        mvWaitForCompletion_f       = (mvWaitForCompletion_t) dlsym(libHandle, \"mvWaitForCompletion\");\n        mvReleaseInference_f        = (mvReleaseInference_t) dlsym(libHandle, \"mvReleaseInference\");\n    }\n\n    if (!mvQueryInference_f) {\n        printf(\"ERROR: couldn't find function mvQueryInference_f in module %s \\\\n\", library_name);      \n    }\n    if (!mvSetLogCallback_f) {\n        printf(\"ERROR: couldn't find function mvSetLogCallback_f in module %s \\\\n\", library_name);      \n    }\n    if (!mvSetPreProcessCallback_f) {\n        printf(\"ERROR: couldn't find function mvSetPreProcessCallback_f in module %s \\\\n\", library_name);      \n    }\n    if (!mvSetPostProcessCallback_f) {\n        printf(\"ERROR: couldn't find function mvSetPostProcessCallback_f in module %s \\\\n\", library_name);      \n    }\n    if (!mvCreateInference_f) {\n        printf(\"ERROR: couldn't find function mvCreateInference_f in module %s \\\\n\", library_name);      \n    }\n    if (!mvCopyToTensorFromFile_f) {\n        printf(\"ERROR: couldn't find function mvCopyToTensorFromFile_f in module %s \\\\n\", library_name);      \n    }\n    if (!mvCopyToTensorFromMem_f) {\n        printf(\"ERROR: couldn't find function mvCopyToTensorFromMem_f in module %s \\\\n\", library_name);      \n    }\n    if (!mvProcessInference_f) {\n        printf(\"ERROR: couldn't find function mvProcessInference_f in module %s \\\\n\", library_name);      \n    }\n    if (!mvGetOutput_f) {\n        printf(\"ERROR: couldn't find function mvGetOutput_f in module %s \\\\n\", library_name);      \n    }\n    if (!mvScheduleInference_f) {\n        printf(\"ERROR: couldn't find function mvScheduleInference_f in module %s \\\\n\", library_name);      \n    }\n    if (!mvReleaseInference_f) {\n        printf(\"ERROR: couldn't find function mvReleaseInference_f in module %s \\\\n\", library_name);      \n    }\n}\n\nstatic mvDeployAPI *mvDeploy = nullptr;\nstatic std::string INF_DEPLOY_LIB_NAME  = \"libmv_deploy.so\";\n\n// helper function\nvoid error(const char * format, ...)\n{\n    printf(\"ERROR: \");\n    va_list args;\n    va_start(args, format);\n    int r = vprintf(format, args);\n    va_end(args);\n    printf(\"\\\\n\");\n}\n\n//! \\\\brief Query the version of the MivisionX inference engine.\nMIVID_API_ENTRY const char * MIVID_API_CALL mvGetVersion()\n{\n    return MIVIDA_VERSION;\n}\n\n//! \\\\brief Creates deployment instance (loads the deployment library for the specific compiled backend and intializes all function pointers)\nMIVID_API_ENTRY mv_status MIVID_API_CALL mvInitializeDeployment(const char* install_folder)\n{\n    std::string libname = std::string(install_folder);\n    libname += \"/lib/\" + INF_DEPLOY_LIB_NAME;\n    mvDeploy = new mvDeployAPI((const char *)libname.c_str());\n    if (!mvDeploy || !mvDeploy->mvQueryInference_f) {\n        return MV_FAILURE;          \n    }\n    printf(\"Success::loading deployment library %s \\\\n\", libname.c_str());\n    return MV_SUCCESS;\n}\n\nMIVID_API_ENTRY mv_status MIVID_API_CALL QueryInference(int *num_inputs, int *num_outputs,  const char **inp_out_config)\n{\n    if (mvDeploy) {\n        *inp_out_config = mvDeploy->mvQueryInference_f(num_inputs, num_outputs);\n        return MV_SUCCESS;\n    }else\n        return MV_FAILURE;\n}\n\nvoid MIVID_API_CALL SetLogCallback(mivid_log_callback_f log_callback_f)\n{\n    if (mvDeploy) mvDeploy->mvSetLogCallback_f(log_callback_f);\n}\n\n//! \\\\brief: load and add preprocessing module/nodes to graph if needed.\n// need to call this before calling CreateInferenceSession\n// output of the preprocessing node should be same as input tensor NN module\nMIVID_API_ENTRY void MIVID_API_CALL SetPreProcessCallback(mivid_add_preprocess_callback_f preproc_f, mv_preprocess_callback_args *preproc_args)\n{\n    if (mvDeploy) mvDeploy->mvSetPreProcessCallback_f(preproc_f, preproc_args);\n}\n\n//! \\\\brief: load and add postprocessing modules/nodes to graph if needed.\n// need to call this before calling CreateInferenceSession\n// input to the preprocessing node should be same as output tensor of NN module\nMIVID_API_ENTRY void MIVID_API_CALL SetPostProcessCallback(mivid_add_postprocess_callback_f postproc_f)\n{\n    if (mvDeploy) mvDeploy->mvSetPostProcessCallback_f(postproc_f);\n}\n\nMIVID_API_ENTRY mv_status MIVID_API_CALL mvCreateInferenceSession(mivid_session *inf_session, const char *install_folder, mivid_memory_type in_type)\n{\n    //load automatically build inference deplyment library and intialize the functions. \n    std::string binfilename = std::string(install_folder) + \"/weights.bin\";\n    mivid_handle mv_handle;\n\n    if (mvDeploy && ((mv_handle = mvDeploy->mvCreateInference_f(binfilename.c_str(), in_type)) != nullptr)) {\n        mv_handle->install_folder = install_folder;\n        *inf_session = (mivid_session)mv_handle;\n        printf(\"OK::mvCreateInferenceSession\\\\n\");\n        return MV_SUCCESS;\n    } else {\n        return MV_FAILURE;\n    }\n}\n\n//! \\\\brief: Releases inference session and all the resources associated\nMIVID_API_ENTRY mv_status MIVID_API_CALL mvReleaseInferenceSession(mivid_session inf_session)\n{\n    if (inf_session && mvDeploy) {\n        return mvDeploy->mvReleaseInference_f((mivid_handle) inf_session);\n    }else\n        return MV_FAILURE;      \n}\n\nMIVID_API_ENTRY mv_status MIVID_API_CALL mvSetInputDataFromMemory(mivid_session inf_session, int input_num, void *input_data, size_t size, mivid_memory_type type)\n{\n    if (inf_session && mvDeploy) {\n        return mvDeploy->mvCopyToTensorFromMem_f((mivid_handle)inf_session, input_num, input_data, size, type);\n    }else\n        return MV_FAILURE;\n}\n\nMIVID_API_ENTRY mv_status MIVID_API_CALL mvSetInputDataFromFile(mivid_session inf_session, int input_num, char *input_name, bool reverseOrder, float preprocess_mulfac, float preprocess_addfac)\n{\n    if (inf_session && mvDeploy) {\n        return mvDeploy->mvCopyToTensorFromFile_f((mivid_handle)inf_session, input_num, input_name, reverseOrder, preprocess_mulfac, preprocess_addfac);\n    }else\n        return MV_FAILURE;  \n}\n\n//! \\\\brief: run an instance of the inference engine: can be run multiple iterations for performance timing\nMIVID_API_ENTRY mv_status MIVID_API_CALL mvRunInference(mivid_session inf_session, float *p_time_in_millisec, int num_iterations)\n{\n    if (inf_session && mvDeploy) {\n        return mvDeploy->mvProcessInference_f((mivid_handle)inf_session, p_time_in_millisec, num_iterations);\n    }else\n        return MV_FAILURE;  \n\n}\n\n//! \\\\brief: run an instance of the inference engine: can be run multiple iterations for performance timing\nMIVID_API_ENTRY mv_status MIVID_API_CALL mvGetOutputData(mivid_session inf_session, int out_num, void *out_buf, size_t size)\n{\n    if (inf_session && mvDeploy) {\n        return mvDeploy->mvGetOutput_f((mivid_handle)inf_session, out_num, out_buf, size);\n    }else\n        return MV_FAILURE;      \n}\n\nMIVID_API_ENTRY mv_status MIVID_API_CALL mvScheduleInferenceSession(mivid_session inf_session)\n{\n    if (inf_session && mvDeploy) {\n        return mvDeploy->mvScheduleInference_f((mivid_handle)inf_session);\n    }else\n        return MV_FAILURE;          \n}\n\nMIVID_API_ENTRY mv_status MIVID_API_CALL mvWaitForSessionCompletion(mivid_session inf_session)\n{\n    if (inf_session && mvDeploy) {\n        return mvDeploy->mvWaitForCompletion_f((mivid_handle)inf_session);\n    }else\n        return MV_FAILURE;          \n}\n\nMIVID_API_ENTRY void MIVID_API_CALL mvShutdown()\n{\n    if (mvDeploy) {\n        delete mvDeploy;\n        mvDeploy = nullptr;\n    }\n}\n\"\"\")\n\ndef generateDeployH(graph,fileName):\n    print('creating ' + fileName + ' ...')\n    with open(fileName, 'w') as f:\n        generateLicenseForCPP(f)\n        f.write( \\\n\"\"\"\n#ifndef included_file_mvdeploy_h\n#define included_file_mvdeploy_h\n\n#define ENABLE_MV_DEPLOY\n\n#include <VX/vx.h>\n#include \"mvdeploy_api.h\"\n#include <CL/cl.h>\n#include <VX/vx_khr_nn.h>\n#include <vx_amd_nn.h>\n#include <vx_ext_amd.h>\n#include <stdarg.h>\n#include <iostream>\n#include <sstream>\n#include <vector>\n#include <stdio.h>\n#include <string.h>\n#include <string>\n#include <chrono>\n#include <inttypes.h>\n#include <dlfcn.h>\n#include <unistd.h> \n\n#if ENABLE_OPENCV\n#include <opencv2/opencv.hpp>\n#include <opencv/cv.h>\n#include <opencv/highgui.h>\nusing namespace cv;\n#endif\n#include <half.hpp>\n#include <immintrin.h>\nusing half_float::half;\n\n#define MIVIDA_VERSION  \"0.9.1\"\n\n#define ERROR_CHECK_OBJECT(obj) { vx_status status = vxGetStatus((vx_reference)(obj)); if(status != VX_SUCCESS) { vxAddLogEntry((vx_reference)context, status     , \"ERROR: failed with status = (%%d) at \" __FILE__ \"#%%d\\\\n\", status, __LINE__); return status; } }\n#define ERROR_CHECK_STATUS(call) { vx_status status = (call); if(status != VX_SUCCESS) { vxAddLogEntry((vx_reference)context, status, \"ERROR: failed with status = (%%d) at \" __FILE__ \"#%%d\\\\n\", status, __LINE__); return status; } }\n\ntypedef struct mivid_handle_t {\n    vx_context  context;\n    vx_graph    graph;\n    const char        *install_folder;\n    mivid_log_callback_f mv_log_message_callback;\n    mivid_add_preprocess_callback_f mv_add_preprocess_cb;\n    mivid_add_postprocess_callback_f mv_add_postprocess_cb;\n    std::vector<vx_tensor>   inputs;\n    std::vector<vx_tensor>   outputs;\n    vx_image inp_image;\n    int mem_type_in;\n    std::string model_url, model_name;\n    int num_inputs, num_outputs;\n    bool scheduled;\n    void *postproc_data;\n} *mivid_handle;\n\n////\n// MIVision Inference Deployment Engine(mivid) input output\n\"\"\")\n        for tensor in graph.inputs:\n            f.write( \\\n\"\"\"//   %s -- dims[] = { %s } (input)\n\"\"\" % (tensor.name, ', '.join([str(v) for v in reversed(tensor.shape)])))\n        for tensor in graph.outputs:\n            f.write( \\\n\"\"\"//   %s -- dims[] = { %s, } (output)\n\"\"\" % (tensor.name, ', '.join([str(v) for v in reversed(tensor.shape)])))\n        f.write( \\\n\"\"\"//\nextern \"C\" {\n    MIVID_API_ENTRY void MIVID_API_CALL mvSetLogCallback(mivid_log_callback_f log_callback_f);\n    MIVID_API_ENTRY void MIVID_API_CALL mvSetPreProcessCallback(mivid_add_preprocess_callback_f preproc_f, mv_preprocess_callback_args *preproc_args);\n    MIVID_API_ENTRY void MIVID_API_CALL mvSetPostProcessCallback(mivid_add_postprocess_callback_f postproc_f);\n    MIVID_API_ENTRY const char * MIVID_API_CALL mvQueryInference(int *num_inputs, int *num_outputs);\n    MIVID_API_ENTRY mivid_handle MIVID_API_CALL mvCreateInference(const char * binaryFilename, int mem_type);\n    MIVID_API_ENTRY mv_status MIVID_API_CALL mvReleaseInference(mivid_handle handle);\n    MIVID_API_ENTRY mv_status MIVID_API_CALL mvCopyToTensorFromMem(mivid_handle handle, int input_num, void *input_data_ptr, size_t size, mivid_memory_type type);\n    MIVID_API_ENTRY mv_status MIVID_API_CALL mvCopyToTensorFromFile(mivid_handle handle, int input_num, const char *input_name, bool reverseOrder, float preprocess_mulfac, float preprocess_addfac);\n    MIVID_API_ENTRY mv_status MIVID_API_CALL mvGetOutput(mivid_handle handle, int output_num, void *out_tensor_mem, vx_size size);\n    MIVID_API_ENTRY mv_status MIVID_API_CALL mvProcessInference(mivid_handle handle, float *ptime_in_ms, int num_iterations);\n    MIVID_API_ENTRY mv_status MIVID_API_CALL mvScheduleInference(mivid_handle handle);\n    MIVID_API_ENTRY mv_status MIVID_API_CALL mvWaitForCompletion(mivid_handle handle);\n    MIVID_API_ENTRY mv_status MIVID_API_CALL mvReleaseInference(mivid_handle handle);\n};\n\n\nextern \"C\" {\n    typedef MIVID_API_ENTRY mv_status (MIVID_API_CALL *mvGetVersion_t)();\n    typedef MIVID_API_ENTRY const char * (MIVID_API_CALL *mvQueryInference_t)(int *num_inputs, int *num_outputs);\n    typedef MIVID_API_ENTRY mv_status (MIVID_API_CALL *mvSetLogCallback_t)(mivid_log_callback_f log_callback_f);\n    typedef MIVID_API_ENTRY void (MIVID_API_CALL *mvSetPreProcessCallback_t)(mivid_add_preprocess_callback_f preproc_f, mv_preprocess_callback_args *preproc_args);\n    typedef MIVID_API_ENTRY void (MIVID_API_CALL *mvSetPostProcessCallback_t)(mivid_add_postprocess_callback_f postproc_f);\n    typedef MIVID_API_ENTRY mivid_handle (MIVID_API_CALL *mvCreateInference_t)(const char * binaryFilename, int mem_type);\n    typedef MIVID_API_ENTRY mv_status (MIVID_API_CALL *mvReleaseInference_t)(mivid_handle handle);    \n    typedef MIVID_API_ENTRY mv_status (MIVID_API_CALL *mvCopyToTensorFromMem_t)(mivid_handle inf_session, int input_num, void *input_data, size_t size, mivid_memory_type type);\n    typedef MIVID_API_ENTRY mv_status (MIVID_API_CALL *mvCopyToTensorFromFile_t)(mivid_handle inf_session, int input_num, char *input_name, bool reverseOrder, float preprocess_mulfac, float preprocess_addfac);\n    typedef MIVID_API_ENTRY mv_status (MIVID_API_CALL *mvProcessInference_t)(mivid_handle inf_session, float *p_time_in_millisec, int num_iterations);\n    typedef MIVID_API_ENTRY mv_status (MIVID_API_CALL *mvGetOutput_t)(mivid_handle handle, int output_num, void *out_tensor_mem, vx_size size);\n    typedef MIVID_API_ENTRY mv_status (MIVID_API_CALL *mvScheduleInference_t)(mivid_handle inf_session);\n    typedef MIVID_API_ENTRY mv_status (MIVID_API_CALL *mvWaitForCompletion_t)(mivid_handle inf_session);\n};\n\nclass mvDeployAPI\n{\npublic:\n    mvQueryInference_t          mvQueryInference_f;\n    mvSetLogCallback_t          mvSetLogCallback_f;\n    mvSetPreProcessCallback_t   mvSetPreProcessCallback_f;\n    mvSetPostProcessCallback_t  mvSetPostProcessCallback_f;\n    mvCreateInference_t         mvCreateInference_f;\n    mvCopyToTensorFromMem_t     mvCopyToTensorFromMem_f;\n    mvCopyToTensorFromFile_t    mvCopyToTensorFromFile_f;\n    mvProcessInference_t        mvProcessInference_f;\n    mvGetOutput_t               mvGetOutput_f;\n    mvScheduleInference_t       mvScheduleInference_f;\n    mvWaitForCompletion_t       mvWaitForCompletion_f;\n    mvReleaseInference_t        mvReleaseInference_f;\nprivate:    \n    void * libHandle;\n\npublic: \n    mvDeployAPI(const char *library_name);\n    ~mvDeployAPI(){dlclose(libHandle);}\n};\n\n#endif\n\n\"\"\")\n\ndef generateBinary(graph,fileName):\n    VARIABLES_FILE_MAGIC = 0xF00DD1E0\n    VARIABLES_DATA_MAGIC = 0xF00DD1E1\n    VARIABLES_EOFF_MAGIC = 0xF00DD1E2\n    print('creating ' + fileName + ' ...')\n    with open(fileName, 'wb') as f:\n        f.write(struct.pack('I', VARIABLES_FILE_MAGIC))\n        for tensor in graph.initializers:\n            binary = graph.binaries[tensor.name]\n            f.write(struct.pack('II', VARIABLES_DATA_MAGIC, len(binary)))\n            f.write(binary)\n        f.write(struct.pack('I', VARIABLES_EOFF_MAGIC))\n\n\ndef generateTestCPP(graph,argmaxOutput,fileName):        \n    print('creating ' + fileName + ' ...')\n    with open(fileName, 'w') as f:\n        generateLicenseForCPP(f)\n        f.write( \\\n\"\"\"\n#include \"mvdeploy.h\"\n#include \"vx_amd_media.h\"\n#include <iterator>\n\n// callback function for adding preprocessing nodes\n// the module should output in the outp_tensor passed by the callback function\ninline int64_t clockCounter()\n{\n    return std::chrono::high_resolution_clock::now().time_since_epoch().count();\n}\n\ninline int64_t clockFrequency()\n{\n    return std::chrono::high_resolution_clock::period::den / std::chrono::high_resolution_clock::period::num;\n}\n\nstatic vx_status MIVID_CALLBACK preprocess_addnodes_callback_fn(mivid_session inf_session, vx_tensor outp_tensor, const char *inp_string, float a, float b)\n{\n    if (inf_session) {\n        // add your preprocessing OpenVX nodes here. Output of preprocessing goes to outp_tensor \n        return MV_ERROR_NOT_IMPLEMENTED;\n    } else {\n        printf(\"preprocess_addnodes_callback_fn:: inf_session not valid\\\\n\");\n        return VX_FAILURE;\n    }\n}\n\nvoid printUsage() {\n    printf(\"Usage: mvtestdeploy <options>\\\\n\"\n        \"\\t<input-data-file>: is raw tensor file OR .jpg/.png file OR <-> for empty input\\t[required]\\\\n\"\n        \"\\t<output-data-file>: output file for inference output OR <-> for no output     \\t[required]\\\\n\"\n        \"\\t--install_folder <install_folder>: location of the compiled model binary      \\t[optional: default-current folder]\\\\n\"\n        \"\\t--backend <backend>: the name of the backend for compilation                  \\t[optional: default-OpenVX_Rocm_OpenCL]\\\\n\"\n        \"\\t--t <num of interations>: to run for performance                              \\t[optional: default 1]\\\\n\"\n        \"\\t--argmax <UINT/Lut>: give argmax output in UINT or LUT                        \\t[optional: default no argmax]\\\\n\"\n        \"\\t--label <labels.txt>: labels file for classes                                 \\t[optional: default no class detected]\\\\n\"        \n        \"\\t--preprocess <pmul, padd>: prepeocess multiply and add in floats              \\t[optional: default (1.f, 0.f)]\\\\n\"        \n    );\n}\n\n\nint main(int argc, const char ** argv)\n{\n    // check command-line usage\n    if(argc < 3) {\n        printUsage();\n        return -1;\n    }\n    mv_status status;\n    size_t out_dims[4];\n    const char *inoutConfig;\n    int num_inputs=1, num_outputs=1;\n    std::string install_folder = \".\";       // default for install folder\n    std::string  weightsFile  = \"./weights.bin\";    // default for weights file\n    mivid_backend backend = OpenVX_Rocm_OpenCL;\n    std::string inpFileName  = std::string(argv[1]);\n    std::string outFileName  = std::string(argv[2]);\n    int bPeformanceRun = 0, numIterations = 1;\n    int  argmaxOutput = 0, gotLabels = 0;\n    std::string labelText[1000];       // to read labels file\n    float padd = 0.f, pmul = 1.f;\n\n    for (int arg = 3; arg < argc; arg++) {\n        if (!strcmp(argv[arg], \"--install_folder\")) {\n            arg++;\n            install_folder = std::string(argv[arg]);\n            weightsFile = install_folder + \"/\" + \"weights.bin\";\n        }\n        if (!strcmp(argv[arg], \"--backend\")) {\n            arg++;\n            backend = (mivid_backend)atoi(argv[arg]);\n        } \n        if (!strcmp(argv[arg], \"--t\")) {\n            arg++;\n            numIterations = atoi(argv[arg]);\n        }\n        if (!strcmp(argv[arg], \"--argmax\")) {\n            arg++;\n            if (!strcmp(argv[arg], \"UINT\")) {\n                argmaxOutput = 1;\n            }\n            else if (!strcmp(argv[arg], \"LUT\")) {\n                argmaxOutput = 2;\n            }\n        }\n        if (!strcmp(argv[arg], \"--label\")) {\n            if ((arg + 1) == argc)\n            {\n                printf(\"ERROR: missing label.txt file on command-line (see help for details)\\\\n\");\n                return -1;\n            }            \n            arg++;\n            std::string labelFileName = argv[arg];\n            std::string line;\n            std::ifstream out(labelFileName);\n            int lineNum = 0;\n            while(getline(out, line)) {\n                labelText[lineNum] = line;\n                lineNum++;\n            }\n            out.close(); \n            gotLabels = 1;           \n        }                \n        if (!strcmp(argv[arg], \"--preprocess\")) {\n            if ((arg + 2) == argc)\n            {\n                printf(\"ERROR: missing pmul and padd parameters on command-line (see help for details)\\\\n\");\n                return -1;\n            }\n            arg++;\n            pmul = atof(argv[arg++]);\n            padd = atof(argv[arg]);\n        }\n    }\n    // initialize deployment\n    if ((status = mvInitializeDeployment(install_folder.c_str()))){\n        printf(\"ERROR: mvInitializeDeployment failed with status %d\\\\n\", status);\n        return -1;\n    }\n\n    if ((status = QueryInference(&num_inputs, &num_outputs, &inoutConfig))) {\n        printf(\"ERROR: QueryInference returned status %d\\\\n\", status);      \n    }\n    else {\n        float *inpMem = nullptr;\n        float *outMem = nullptr;\n        size_t inp_dims[4], out_dims[4];        \n        mivid_session infSession;\n        mv_status status;\n        float time_in_millisec;\n\n        // get input and output dimensions from inoutConfig\n        std::stringstream inout_dims(inoutConfig);\n        std::vector<std::string> config_vec;\n        std::string substr;\n        std::string in_names[num_inputs];\n        std::string out_names[num_outputs];\n        std::vector<std::tuple<int, int, int, int>> input_dims;\n        std::vector<std::tuple<int, int, int, int>> output_dims;\n        while( inout_dims.good()) {\n            getline(inout_dims, substr, ';' );\n            if (!substr.empty()) {\n                config_vec.push_back(substr);\n            }\n        }\n        int in_num = 0, out_num = 0, n, c, h, w;        \n        for (int i=0; i < config_vec.size(); i++)\n        {\n            std::stringstream ss(config_vec[i]);\n            getline(ss, substr, ',');\n            if ((substr.compare(0,5,\"input\") == 0))\n            {\n                getline(ss, substr, ',');\n                in_names[in_num] =  substr;\n                getline(ss, substr, ','); w = atoi(substr.c_str());\n                getline(ss, substr, ','); h = atoi(substr.c_str());\n                getline(ss, substr, ','); c = atoi(substr.c_str());\n                getline(ss, substr, ','); n = atoi(substr.c_str());\n                printf(\"Config_input::<%d %d %d %d>:%s \\\\n\", w,h,c,n, in_names[in_num].c_str());\n                input_dims.push_back(std::tuple<int,int,int,int>(w,h,c,n));\n                in_num++;\n            }\n            else if ((substr.compare(0,6,\"output\") == 0))\n            {\n                getline(ss, substr, ',');\n                out_names[out_num] =  substr;\n                getline(ss, substr, ','); w = atoi(substr.c_str());\n                getline(ss, substr, ','); h = atoi(substr.c_str());\n                getline(ss, substr, ','); c = atoi(substr.c_str());\n                getline(ss, substr, ','); n = atoi(substr.c_str());\n                printf(\"Config_output::<%d %d %d %d>:%s \\\\n\", w,h,c,n, out_names[out_num].c_str());\n                output_dims.push_back(std::tuple<int,int,int,int>(w,h,c,n));\n                out_num ++;\n            }\n        }\n\n        inp_dims[3] = std::get<0>(input_dims[0]);\n        inp_dims[2] = std::get<1>(input_dims[0]);\n        inp_dims[1] = std::get<2>(input_dims[0]);\n        inp_dims[0] = std::get<3>(input_dims[0]);\n        out_dims[3] = std::get<0>(output_dims[0]);\n        out_dims[2] = std::get<1>(output_dims[0]);\n        out_dims[1] = std::get<2>(output_dims[0]);\n        out_dims[0] = std::get<3>(output_dims[0]);\n\n        status = mvCreateInferenceSession(&infSession, install_folder.c_str(), mv_mem_type_host);\n        if (status != MV_SUCCESS)\n        {\n            printf(\"ERROR: mvCreateInferenceSession returned failure \\\\n\");\n            return -1;      \n        }\n        if (input_dims.size() == 0 || output_dims.size() == 0 ) {\n            printf(\"ERROR: Couldn't get input and output dims %d %d \\\\n\", (int)input_dims.size(), (int)output_dims.size());\n            return -1;      \n        }\n        // create input tensor memory for swaphandle\n        size_t inputSizeInBytes = 4 *inp_dims[0] * inp_dims[1] * inp_dims[2] * inp_dims[3];\n\n        // read input and call mvSetInputDataFromMemory\n        if ((strcmp(inpFileName.c_str(), \"-\") != 0)) {\n            inpMem = (float *)new char[inputSizeInBytes];\n            size_t istride[4] = { 4, (size_t)4 * inp_dims[0], (size_t)4 * inp_dims[0] * inp_dims[1], (size_t)4 * inp_dims[0] * inp_dims[1] * inp_dims[2] };\n    #if ENABLE_OPENCV\n            if(inp_dims[2] == 3 && inpFileName.size() > 4 && (inpFileName.substr(inpFileName.size()-4, 4) == \".png\" || inpFileName.substr(inpFileName.size()-4, 4) == \".jpg\" ||\n                                                             inpFileName.substr(inpFileName.size()-4, 4) == \".PNG\" || inpFileName.substr(inpFileName.size()-4, 4) == \".JPG\"))\n            {\n                for(size_t n = 0; n < inp_dims[3]; n++) {\n                    char imgFileName[1024];\n                    sprintf(imgFileName, inpFileName.c_str(), (int)n);\n                    unsigned char *img_data;\n                    Mat img = imread(imgFileName, CV_LOAD_IMAGE_COLOR);\n                    img_data = img.data;\n                    if(!img.data || img.rows != inp_dims[1] || img.cols != inp_dims[0]) {\n                        Mat matScaled;\n                        cv::resize(img, matScaled, cv::Size(inp_dims[0], inp_dims[1]));\n                        img_data = matScaled.data;\n                    }\n                    for(vx_size y = 0; y < inp_dims[1]; y++) {\n                        unsigned char * src = img_data + y*inp_dims[0]*3;\n                        float * dstR = inpMem + ((n * istride[3] + y * istride[1]) >> 2);\n                        float * dstG = dstR + (istride[2] >> 2);\n                        float * dstB = dstG + (istride[2] >> 2);\n                        for(vx_size x = 0; x < inp_dims[0]; x++, src += 3) {\n                            *dstR++ = src[2]*pmul + padd;\n                            *dstG++ = src[1]*pmul + padd;\n                            *dstB++ = src[0]*pmul + padd;\n                        }\n                    }\n                }\n            }\n            else\n    #endif\n            {\n                FILE * fp = fopen(inpFileName.c_str(), \"rb\");\n                if(!fp) {\n                    std::cerr << \"ERROR: unable to open: \" << inpFileName << std::endl;\n                    return -1;\n                }\n                for(size_t n = 0; n < inp_dims[3]; n++) {\n                    for(size_t c = 0; c < inp_dims[2]; c++) {\n                        for(size_t y = 0; y < inp_dims[1]; y++) {\n                            float * ptrY = inpMem + ((n * istride[3] + c * istride[2] + y * istride[1]) >> 2);\n                            vx_size n = fread(ptrY, sizeof(float), inp_dims[0], fp);\n                            if(n != inp_dims[0]) {\n                                std::cerr << \"ERROR: reading from file less than expected # of bytes \" << inpFileName << std::endl;\n                                return -1;\n                            }\n                        }\n                    }\n                }\n                fclose(fp);\n            }\n            if ((status = mvSetInputDataFromMemory(infSession, 0, (void *)inpMem, inputSizeInBytes, mv_mem_type_host)) != MV_SUCCESS) {\n                printf(\"ERROR: mvSetInputDataFromMemory returned failure(%d) \\\\n\", status);\n                return -1;\n            }\n        }\n        // allocate output buffer corresponding to the first output\n        size_t outputSizeInBytes = 4 *out_dims[0]*out_dims[1]*out_dims[2]*out_dims[3];\n        outMem = (float *)new char[outputSizeInBytes];\n        FILE *fp = nullptr;\n\n        if (strcmp(outFileName.c_str(), \"-\") != 0)\n        {\n            fp = fopen(outFileName.c_str(), \"wb\");\n            if(!fp) {\n                std::cerr << \"ERROR: unable to open: \" << outFileName << std::endl;\n                return -1;\n            }\n        }\n        int64_t freq = clockFrequency(), t0, t1;\n        if (numIterations == 1) t0 = clockCounter();\n\n        if ((status = mvRunInference(infSession, &time_in_millisec, numIterations))) {\n            printf(\"ERROR: mvRunInference terminated with status(%d) \\\\n\", status);\n            return -1;\n        }\n        if (numIterations == 1) {\n            t1 = clockCounter();\n            time_in_millisec = (float)(t1-t0)*1000.0f/(float)freq;\n        }\n\n        // get output\n        if ((status = mvGetOutputData(infSession, 0, (void *) outMem, outputSizeInBytes)) != MV_SUCCESS) {\n            printf(\"ERROR: mvGetOutputData returned failure(%d) \\\\n\", status);\n            return -1;\n        }\n        if (fp) {\n            fwrite(outMem, sizeof(float), outputSizeInBytes>>2, fp);\n        }\n        if (fp) fclose(fp);\n        printf(\"OK: mvRunInference() took %.3f msec (average over %d iterations)\\\\n\", time_in_millisec, numIterations);\n\n        if (argmaxOutput) {\n            float *out_elements = (float*)outMem;\n            int classID = std::distance(out_elements, std::max_element(out_elements, (out_elements + out_dims[1])));\n            if (gotLabels)\n                printf(\"Argmax output is %d with label: %s\\\\n\", classID, labelText[classID].c_str());\n            else\n                printf(\"Argmax output is %d \\\\n\", classID);\n        }\n        // Relese Inference\n        mvReleaseInferenceSession(infSession);\n        printf(\"OK: Inference Deploy Successful \\\\n\");\n        // delete resources\n        if (inpMem) delete[] inpMem;\n        if (outMem) delete[] outMem;\n        mvShutdown();\n    }\n}\n\"\"\")\n\ndef generateExtrasCPP(graph,extraFolder):\n    print('copying mv_extras_postproc.cpp to ' + extraFolder + ' ...')\n    file_dir = os.path.dirname(os.path.abspath(__file__))\n    cmd = \"cp \" + file_dir + \"/../mv_extras_postproc.cpp \" + \"./\" + extraFolder\n    ret = subprocess.call(cmd, shell=True)\n    if ret:\n        print('ERROR: generateExtrasCPP', ret)\n    else:  \n        print('OK: generateExtrasCPP')\n\ndef generateExtrasH(graph,extraFolder):\n    print('copying mv_extras_postproc.h to ' + extraFolder + ' ...')\n    file_dir = os.path.dirname(os.path.abspath(__file__))\n    cmd = \"cp \" + file_dir + \"/../mv_extras_postproc.h \" + \"./\" + extraFolder\n    ret = subprocess.call(cmd, shell=True)\n    if ret:\n        print('ERROR: generateExtrasCPP', ret)\n    else:\n        print('OK: generateExtrasCPP')\n\ndef generateCode(graph,argmaxOutput,outputFolder):\n    extraFolder = outputFolder + '/mv_extras'\n    if not os.path.isdir(outputFolder):\n        os.mkdir(outputFolder)\n    if not os.path.isdir(extraFolder):\n        os.mkdir(extraFolder)\n    generateCMakeFiles(graph,outputFolder)\n    generateCMakeExtras(graph, extraFolder)\n    generateModuleCPP(graph,outputFolder + '/mvmodule.cpp')\n    generateBinary(graph,outputFolder + '/weights.bin')\n    generateDeployH(graph, outputFolder + '/mvdeploy.h')\n    generateDeployCPP(graph, outputFolder + '/mvdeploy_api.cpp')\n    generateTestCPP(graph,argmaxOutput,outputFolder + '/mvtestdeploy.cpp')\n    generateExtrasH(graph,extraFolder)\n    generateExtrasCPP(graph,extraFolder)\n\ndef main():\n    usage = \"\"\"\nUsage: python nnir_to_clib.py [OPTIONS] <nnirInputFolder> <outputFolder>\n\n  OPTIONS:\n    --argmax UINT8                    -- argmax at the end with 8-bit output\n    --argmax UINT16                   -- argmax at the end with 16-bit output\n    --argmax <fileNamePrefix>rgb.txt  -- argmax at the end with RGB color mapping using LUT\n    --argmax <fileNamePrefix>rgba.txt -- argmax at the end with RGBA color mapping using LUT\n    --help                            -- show this help message\n\n  LUT File Format (RGB): 8-bit R G B values one per each label in text format\n    R0 G0 B0\n    R1 G1 B1\n    ...\n\n  LUT File Format (RGBA): 8-bit R G B A values one per each label in text format\n    R0 G0 B0 A0\n    R1 G1 B1 A1\n    ...\n\n\"\"\"\n    pos = 1;\n    argmaxOutput = None\n    while len(sys.argv[pos:]) >= 2 and sys.argv[pos][:2] == '--':\n        if sys.argv[pos] == '--argmax':\n            argmaxOutput = sys.argv[pos+1]\n            if argmaxOutput == 'UINT8':\n                argmaxOutput = 'vx_uint8'\n            elif argmaxOutput == 'UINT16':\n                argmaxOutput = 'vx_uint16'\n            else:\n                if not os.path.isfile(argmaxOutput):\n                    print('ERROR: unable to open: %s' % (argmaxOutput))\n                    sys.exit(1)\n                with open(argmaxOutput,'r') as f:\n                    if argmaxOutput[-8:] == 'rgba.txt':\n                        argmaxOutput = np.reshape(np.array([int(v) for v in f.read().split()]), [-1, 4]).transpose()\n                    else:\n                        argmaxOutput = np.reshape(np.array([int(v) for v in f.read().split()]), [-1, 3]).transpose()\n        else:\n            if sys.argv[pos] != '--help':\n                print('ERROR: invalid option: %s' % (sys.argv[pos]))\n            print(usage)\n            sys.exit(1)\n        pos = pos + 2\n    if len(sys.argv[pos:]) < 2:\n        print(usage)\n        sys.exit(1)\n    inputFolder = sys.argv[pos]\n    outputFolder = sys.argv[pos+1]\n    print('reading IR model from ' + inputFolder + ' ...')\n    graph = IrGraph(True)\n    graph.fromFile(inputFolder)\n    print('creating C code in ' + outputFolder + ' ...')\n    generateCode(graph,argmaxOutput,outputFolder)\n\nif __name__ == '__main__':\n    main()\n",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/apps/cloud_inference/server_app/inference.cpp": "#include \"inference.h\"\n#include \"netutil.h\"\n#include \"common.h\"\n#include <thread>\n#include <chrono>\n#include <dlfcn.h>\n#include <opencv2/opencv.hpp>\n#include <highgui.h>\n#include <numeric>\n\n#if USE_SSE_OPTIMIZATION\n#if _WIN32\n#include <intrin.h>\n#else\n#include <x86intrin.h>\n#include <immintrin.h>\n#endif\n#endif\n\nstatic void VX_CALLBACK log_callback(vx_context context, vx_reference ref, vx_status status, const vx_char string[])\n{\n    size_t len = strlen(string);\n    if (len > 0) {\n        printf(\"%s\", string);\n        if (string[len - 1] != '\\n')\n            printf(\"\\n\");\n        fflush(stdout);\n    }\n}\n\nconst float BB_biases[10]             = {1.08,1.19,  3.42,4.41,  6.63,11.38,  9.42,5.11,  16.62,10.52};     // bounding box biases\n\n// sort indexes based on comparing values in v\ntemplate <typename T>\nvoid sort_indexes(const std::vector<T> &v, std::vector<size_t> &idx) {\n  sort(idx.begin(), idx.end(),\n       [&v](size_t i1, size_t i2) {return v[i1] > v[i2];});\n}\n\nInferenceEngine::InferenceEngine(int sock_, Arguments * args_, std::string clientName_, InfComCommand * cmd)\n    : sock{ sock_ }, args{ args_ }, clientName{ clientName_ },\n      GPUs{ cmd->data[1] },\n      dimInput{ cmd->data[2], cmd->data[3], cmd->data[4] },\n      dimOutput{ cmd->data[5], cmd->data[6], cmd->data[7] },\n      receiveFileNames { (bool)cmd->data[8] }, topK { cmd->data[9] }, detectBoundingBoxes { cmd->data[10] },\n      reverseInputChannelOrder{ 0 }, preprocessMpy{ 1, 1, 1 }, preprocessAdd{ 0, 0, 0 },\n      moduleHandle{ nullptr }, annCreateGraph{ nullptr }, annAddtoGraph { nullptr},\n      device_id{ nullptr }, deviceLockSuccess{ false }, useShadowFilenames{ false }\n#if INFERENCE_SCHEDULER_MODE == NO_INFERENCE_SCHEDULER && !DONOT_RUN_INFERENCE\n    , openvx_context{ nullptr }, openvx_graph{ nullptr }, openvx_input{ nullptr }, openvx_output{ nullptr }\n#elif INFERENCE_SCHEDULER_MODE == LIBRE_INFERENCE_SCHEDULER\n    , threadMasterInputQ{ nullptr },\n      opencl_context{ nullptr }, opencl_cmdq{ nullptr },\n      openvx_context{ nullptr }, openvx_graph{ nullptr }, openvx_input{ nullptr }, openvx_output{ nullptr },\n      threadDeviceInputCopy{ nullptr }, threadDeviceProcess{ nullptr }, threadDeviceOutputCopy{ nullptr },\n      queueDeviceTagQ{ nullptr }, queueDeviceImageQ{ nullptr },\n      queueDeviceInputMemIdle{ nullptr }, queueDeviceInputMemBusy{ nullptr },\n      queueDeviceOutputMemIdle{ nullptr }, queueDeviceOutputMemBusy{ nullptr },\n      region { nullptr }, useFp16 { 0 }\n#if  USE_ADVANCED_MESSAGE_Q\n    , inputQ(MAX_INPUT_QUEUE_DEPTH)\n#endif\n#endif\n{\n    // extract model name, options, and module path\n    char modelName_[128] = { 0 }, options_[128] = { 0 };\n    sscanf(cmd->message, \"%s%s\", modelName_, options_);\n    modelName = modelName_;\n    options = options_;\n    // configuration\n    batchSize = args->getBatchSize();\n    if (!args->fp16Inference()) {\n        inputSizeInBytes = 4 * dimInput[0] * dimInput[1] * dimInput[2] * batchSize;\n        outputSizeInBytes = 4 * dimOutput[0] * dimOutput[1] * dimOutput[2] * batchSize;\n    }else\n    {\n        useFp16 = 1;\n        inputSizeInBytes = 2 * dimInput[0] * dimInput[1] * dimInput[2] * batchSize;\n        outputSizeInBytes = 2 * dimOutput[0] * dimOutput[1] * dimOutput[2] * batchSize;\n        std::cout << \"INFO::inferenceserver is running with FP16 inference\" << std::endl;\n    }\n    numDecThreads = args->decThreads();\n    if (numDecThreads){\n        numDecThreads = (numDecThreads + 1) & ~1;    // make it multiple of 2\n        numDecThreads = std::min(numDecThreads, batchSize); // can't be more than batch_size\n    }\n\n    if (detectBoundingBoxes)\n        region = new CYoloRegion();\n    // lock devices\n    if(!args->lockGpuDevices(GPUs, device_id))\n        deviceLockSuccess = true;\n    if (!args->getlocalShadowRootDir().empty()){\n        useShadowFilenames = true;\n        std::cout << \"INFO::inferenceserver is running with LocalShadowFolder and infcom command receiving only filenames\" << std::endl;\n    }\n\n    PROFILER_INITIALIZE();\n}\n\nInferenceEngine::~InferenceEngine()\n{\n#if INFERENCE_SCHEDULER_MODE == NO_INFERENCE_SCHEDULER && !DONOT_RUN_INFERENCE\n    if(openvx_graph) {\n        vxReleaseGraph(&openvx_graph);\n    }\n    if(openvx_input) {\n        vxReleaseTensor(&openvx_input);\n    }\n    if(openvx_output) {\n        vxReleaseTensor(&openvx_output);\n    }\n    if(openvx_context) {\n        vxReleaseContext(&openvx_context);\n    }\n#elif INFERENCE_SCHEDULER_MODE == LIBRE_INFERENCE_SCHEDULER\n    // wait for all threads to complete and release all resources\n    std::tuple<int,char*,int> endOfSequenceInput(-1,nullptr,0);\n    inputQ.enqueue(endOfSequenceInput);\n    if(threadMasterInputQ && threadMasterInputQ->joinable()) {\n        threadMasterInputQ->join();\n    }\n    std::tuple<char*,int> endOfSequenceImage(nullptr,0);\n    int endOfSequenceTag = -1;\n    for(int i = 0; i < GPUs; i++) {\n        if(queueDeviceTagQ[i]) {\n            queueDeviceTagQ[i]->enqueue(endOfSequenceTag);\n        }\n        if(queueDeviceImageQ[i]) {\n            queueDeviceImageQ[i]->enqueue(endOfSequenceImage);\n        }\n        if(threadDeviceInputCopy[i] && threadDeviceInputCopy[i]->joinable()) {\n            threadDeviceInputCopy[i]->join();\n        }\n        if(threadDeviceProcess[i] && threadDeviceProcess[i]->joinable()) {\n            threadDeviceProcess[i]->join();\n        }\n        if(threadDeviceOutputCopy[i] && threadDeviceOutputCopy[i]->joinable()) {\n            threadDeviceOutputCopy[i]->join();\n        }\n        while(queueDeviceInputMemIdle[i] && queueDeviceInputMemIdle[i]->size() > 0) {\n            cl_mem mem;\n            queueDeviceInputMemIdle[i]->dequeue(mem);\n            clReleaseMemObject(mem);\n        }\n        while(queueDeviceOutputMemIdle[i] && queueDeviceOutputMemIdle[i]->size() > 0) {\n            cl_mem mem;\n            queueDeviceOutputMemIdle[i]->dequeue(mem);\n            clReleaseMemObject(mem);\n        }\n        if(queueDeviceTagQ[i]) {\n            delete queueDeviceTagQ[i];\n        }\n        if(queueDeviceImageQ[i]) {\n            delete queueDeviceImageQ[i];\n        }\n        if(queueDeviceInputMemIdle[i]) {\n            delete queueDeviceInputMemIdle[i];\n        }\n        if(queueDeviceInputMemBusy[i]) {\n            delete queueDeviceInputMemBusy[i];\n        }\n        if(queueDeviceOutputMemIdle[i]) {\n            delete queueDeviceOutputMemIdle[i];\n        }\n        if(queueDeviceOutputMemBusy[i]) {\n            delete queueDeviceOutputMemBusy[i];\n        }\n        if(openvx_graph[i]) {\n            vxReleaseGraph(&openvx_graph[i]);\n        }\n        if(openvx_input[i]) {\n            vxReleaseTensor(&openvx_input[i]);\n        }\n        if(openvx_output[i]) {\n            vxReleaseTensor(&openvx_output[i]);\n        }\n        if(openvx_context[i]) {\n            vxReleaseContext(&openvx_context[i]);\n        }\n        if(opencl_cmdq[i]) {\n            clReleaseCommandQueue(opencl_cmdq[i]);\n        }\n        if(opencl_context[i]) {\n            clReleaseContext(opencl_context[i]);\n        }\n    }\n#endif\n    // release all device resources\n    if(deviceLockSuccess) {\n        args->releaseGpuDevices(GPUs, device_id);\n    }\n    if(moduleHandle) {\n        dlclose(moduleHandle);\n    }\n    if (region) delete region;\n    PROFILER_SHUTDOWN();\n}\n\nvx_status InferenceEngine::DecodeScaleAndConvertToTensor(vx_size width, vx_size height, int size, unsigned char *inp, float *buf, int use_fp16)\n{\n    int length = width*height;\n    cv::Mat matOrig = cv::imdecode(cv::Mat(1, size, CV_8UC1, inp), CV_LOAD_IMAGE_COLOR);\n\n#if USE_SSE_OPTIMIZATION\n    unsigned char *data_resize = nullptr;\n    unsigned char * img;\n    if ((width == matOrig.cols) && (height == matOrig.rows))\n    {\n        // no resize required\n        img = matOrig.data;\n    }else\n    {\n        unsigned int aligned_size = ((length+width) * 3 + 128)&~127;\n        data_resize = new unsigned char[aligned_size];\n        RGB_resize(matOrig.data, data_resize, matOrig.cols, matOrig.rows, matOrig.step, width, height);\n        img = data_resize;\n    }\n    PROFILER_START(inference_server_app, workRGBtoTensor);\n\n    __m128i mask_B, mask_G, mask_R;\n    if (reverseInputChannelOrder)\n    {\n        mask_B = _mm_setr_epi8((char)0x0, (char)0x80, (char)0x80, (char)0x80, (char)0x3, (char)0x80, (char)0x80, (char)0x80, (char)0x6, (char)0x80, (char)0x80, (char)0x80, (char)0x9, (char)0x80, (char)0x80, (char)0x80);\n        mask_G = _mm_setr_epi8((char)0x1, (char)0x80, (char)0x80, (char)0x80, (char)0x4, (char)0x80, (char)0x80, (char)0x80, (char)0x7, (char)0x80, (char)0x80, (char)0x80, (char)0xA, (char)0x80, (char)0x80, (char)0x80);\n        mask_R = _mm_setr_epi8((char)0x2, (char)0x80, (char)0x80, (char)0x80, (char)0x5, (char)0x80, (char)0x80, (char)0x80, (char)0x8, (char)0x80, (char)0x80, (char)0x80, (char)0xB, (char)0x80, (char)0x80, (char)0x80);\n    }\n    else\n    {\n        mask_R = _mm_setr_epi8((char)0x0, (char)0x80, (char)0x80, (char)0x80, (char)0x3, (char)0x80, (char)0x80, (char)0x80, (char)0x6, (char)0x80, (char)0x80, (char)0x80, (char)0x9, (char)0x80, (char)0x80, (char)0x80);\n        mask_G = _mm_setr_epi8((char)0x1, (char)0x80, (char)0x80, (char)0x80, (char)0x4, (char)0x80, (char)0x80, (char)0x80, (char)0x7, (char)0x80, (char)0x80, (char)0x80, (char)0xA, (char)0x80, (char)0x80, (char)0x80);\n        mask_B = _mm_setr_epi8((char)0x2, (char)0x80, (char)0x80, (char)0x80, (char)0x5, (char)0x80, (char)0x80, (char)0x80, (char)0x8, (char)0x80, (char)0x80, (char)0x80, (char)0xB, (char)0x80, (char)0x80, (char)0x80);\n    }\n    int alignedLength = (length-2)& ~3;\n    bool bPreprocess = (preprocessMpy[0] != 1) & (preprocessAdd[0] != 0) ;\n    if (!use_fp16) {\n        float * B_buf = buf;\n        float * G_buf = B_buf + length;\n        float * R_buf = G_buf + length;\n        int i = 0;\n\n        __m128 fR, fG, fB;\n        if (bPreprocess) {\n            for (; i < alignedLength; i += 4)\n            {\n                __m128i pix0 = _mm_loadu_si128((__m128i *) img);\n                fB = _mm_cvtepi32_ps(_mm_shuffle_epi8(pix0, mask_B));\n                fG = _mm_cvtepi32_ps(_mm_shuffle_epi8(pix0, mask_G));\n                fR = _mm_cvtepi32_ps(_mm_shuffle_epi8(pix0, mask_R));\n                fB = _mm_mul_ps(fB, _mm_set1_ps(preprocessMpy[0]));\n                fG = _mm_mul_ps(fG, _mm_set1_ps(preprocessMpy[1]));\n                fR = _mm_mul_ps(fR, _mm_set1_ps(preprocessMpy[2]));\n                fB = _mm_add_ps(fB, _mm_set1_ps(preprocessAdd[0]));\n                fG = _mm_add_ps(fG, _mm_set1_ps(preprocessAdd[1]));\n                fR = _mm_add_ps(fR, _mm_set1_ps(preprocessAdd[2]));\n                _mm_storeu_ps(B_buf, fB);\n                _mm_storeu_ps(G_buf, fG);\n                _mm_storeu_ps(R_buf, fR);\n                B_buf += 4; G_buf += 4; R_buf += 4;\n                img += 12;\n            }\n            for (; i < length; i++, img += 3) {\n                *B_buf++ = (img[0] * preprocessMpy[0]) + preprocessAdd[0];\n                *G_buf++ = (img[1] * preprocessMpy[1]) + preprocessAdd[1];\n                *R_buf++ = (img[2] * preprocessMpy[2]) + preprocessAdd[2];\n            }\n        }else\n        {\n            for (; i < alignedLength; i += 4)\n            {\n                __m128i pix0 = _mm_loadu_si128((__m128i *) img);\n                fB = _mm_cvtepi32_ps(_mm_shuffle_epi8(pix0, mask_B));\n                fG = _mm_cvtepi32_ps(_mm_shuffle_epi8(pix0, mask_G));\n                fR = _mm_cvtepi32_ps(_mm_shuffle_epi8(pix0, mask_R));\n                _mm_storeu_ps(B_buf, fB);\n                _mm_storeu_ps(G_buf, fG);\n                _mm_storeu_ps(R_buf, fR);\n                B_buf += 4; G_buf += 4; R_buf += 4;\n                img += 12;\n            }\n            for (; i < length; i++, img += 3) {\n                *B_buf++ = img[0];\n                *G_buf++ = img[1];\n                *R_buf++ = img[2];\n            }\n        }\n    } else\n    {\n        unsigned short * B_buf = (unsigned short *)buf;\n        unsigned short * G_buf = B_buf + length;\n        unsigned short * R_buf = G_buf + length;\n        int i = 0;\n\n        __m128 fR, fG, fB;\n        __m128i hR, hG, hB;\n        if (bPreprocess) {\n            for (; i < alignedLength; i += 4)\n            {\n                __m128i pix0 = _mm_loadu_si128((__m128i *) img);\n                fB = _mm_cvtepi32_ps(_mm_shuffle_epi8(pix0, mask_B));\n                fG = _mm_cvtepi32_ps(_mm_shuffle_epi8(pix0, mask_G));\n                fR = _mm_cvtepi32_ps(_mm_shuffle_epi8(pix0, mask_R));\n                fB = _mm_mul_ps(fB, _mm_set1_ps(preprocessMpy[0]));\n                fG = _mm_mul_ps(fG, _mm_set1_ps(preprocessMpy[1]));\n                fR = _mm_mul_ps(fR, _mm_set1_ps(preprocessMpy[2]));\n                fB = _mm_add_ps(fB, _mm_set1_ps(preprocessAdd[0]));\n                fG = _mm_add_ps(fG, _mm_set1_ps(preprocessAdd[1]));\n                fR = _mm_add_ps(fR, _mm_set1_ps(preprocessAdd[2]));\n                // convert to half\n                hB = _mm_cvtps_ph(fB, 0xF);\n                hG = _mm_cvtps_ph(fG, 0xF);\n                hR = _mm_cvtps_ph(fR, 0xF);\n                _mm_storel_epi64((__m128i*)B_buf, hB);\n                _mm_storel_epi64((__m128i*)G_buf, hG);\n                _mm_storel_epi64((__m128i*)R_buf, hR);\n                B_buf += 4; G_buf += 4; R_buf += 4;\n                img += 12;\n            }\n            for (; i < length; i++, img += 3) {\n                *B_buf++ = _cvtss_sh((float)((img[0] * preprocessMpy[0]) + preprocessAdd[0]), 1);\n                *G_buf++ = _cvtss_sh((float)((img[1] * preprocessMpy[1]) + preprocessAdd[1]), 1);\n                *R_buf++ = _cvtss_sh((float)((img[2] * preprocessMpy[2]) + preprocessAdd[2]), 1);\n            }\n        } else\n        {\n            for (; i < alignedLength; i += 4)\n            {\n                __m128i pix0 = _mm_loadu_si128((__m128i *) img);\n                fB = _mm_cvtepi32_ps(_mm_shuffle_epi8(pix0, mask_B));\n                fG = _mm_cvtepi32_ps(_mm_shuffle_epi8(pix0, mask_G));\n                fR = _mm_cvtepi32_ps(_mm_shuffle_epi8(pix0, mask_R));\n                // convert to half\n                hB = _mm_cvtps_ph(fB, 0xF);\n                hG = _mm_cvtps_ph(fG, 0xF);\n                hR = _mm_cvtps_ph(fR, 0xF);\n                _mm_storel_epi64((__m128i*)B_buf, hB);\n                _mm_storel_epi64((__m128i*)G_buf, hG);\n                _mm_storel_epi64((__m128i*)R_buf, hR);\n                B_buf += 4; G_buf += 4; R_buf += 4;\n                img += 12;\n            }\n            for (; i < length; i++, img += 3) {\n                *B_buf++ = _cvtss_sh((float)img[0], 1);\n                *G_buf++ = _cvtss_sh((float)img[1], 1);\n                *R_buf++ = _cvtss_sh((float)img[2], 1);\n            }\n        }\n    }\n    PROFILER_STOP(inference_server_app, workRGBtoTensor);\n    if (data_resize != nullptr) delete[] data_resize;\n#else\n    cv::Mat matScaled;\n    cv::resize(matOrig, matScaled, cv::Size(width, height));\n    float *ptr = buf;\n    for (int c = 0; c < 3; c++, ptr += length) {\n        float a = preprocessMpy[c], b = preprocessAdd[c];\n        unsigned char * img = matScaled.data + (reverseInputChannelOrder ? c : (2 - c));\n        for (int i = 0; i < length; i++, img += 3) {\n            ptr[i] = *img * a + b;\n        }\n    }\n    matScaled.release();\n#endif\n    matOrig.release();\n    return VX_SUCCESS;\n}\n\n#define FP_BITS     16\n#define FP_MUL      (1<<FP_BITS)\n\nvoid InferenceEngine::RGB_resize(unsigned char *Rgb_in, unsigned char *Rgb_out, unsigned int swidth, unsigned int sheight,  unsigned int sstride, unsigned int dwidth, unsigned int dheight)\n{\n    float xscale = (float)((double)swidth / (double)dwidth);\n    float yscale = (float)((double)sheight / (double)dheight);\n    int alignW = (dwidth + 15)&~15;\n    unsigned int *Xmap = new unsigned int[alignW*2];\n    unsigned short *Xf = (unsigned short *)(Xmap + alignW);\n    unsigned short *Xf1 = Xf + alignW;\n\n    int xpos = (int)(FP_MUL * (xscale*0.5 - 0.5));\n    int xinc = (int)(FP_MUL * xscale);\n    int yinc = (int)(FP_MUL * yscale);\t\t// to convert to fixed point\n    unsigned int aligned_width = dwidth;\n    // generate xmap\n    for (unsigned int x = 0; x < dwidth; x++, xpos += xinc)\n    {\n        int xf;\n        int xmap = (xpos >> FP_BITS);\n        if (xmap >= (int)(swidth - 8)){\n            aligned_width = x;\n        }\n        if (xmap >= (int)(swidth - 1)){\n            Xmap[x] = (swidth - 1)*3;\n        }\n        else\n            Xmap[x] = (xmap<0)? 0: xmap*3;\n        xf = ((xpos & 0xffff) + 0x80) >> 8;\n        Xf[x] = xf;\n        Xf1[x] = (0x100 - xf);\n    }\n    aligned_width &= ~3;\n    int dstride = dwidth * 3;\n    unsigned char *pSrcBorder = Rgb_in + (sheight*sstride) - 3;    // points to the last pixel\n\n    int ypos = (int)(FP_MUL * (yscale*0.5 - 0.5));\n    for (int y = 0; y < (int)dheight; y++, ypos += yinc)\n    {\n        int ym, fy, fy1;\n        unsigned char *pSrc1, *pSrc2;\n        unsigned char *pdst = Rgb_out + y*dstride;\n\n        ym = (ypos >> FP_BITS);\n        fy = ((ypos & 0xffff) + 0x80) >> 8;\n        fy1 = (0x100 - fy);\n        if (ym >= (int)(sheight - 1)){\n            pSrc1 = pSrc2 = Rgb_in + (sheight - 1)*sstride;\n        }\n        else\n        {\n            pSrc1 = (ym<0)? Rgb_in : (Rgb_in + ym*sstride);\n            pSrc2 = pSrc1 + sstride;\n        }\n        __m128i w_y = _mm_setr_epi32(fy1, fy, fy1, fy);\n        const __m128i mm_zeros = _mm_setzero_si128();\n        const __m128i mm_round = _mm_set1_epi32((int)0x80);\n        __m128i p01, p23, ps01, ps23, pRG1, pRG2, pRG3;\n        unsigned int x = 0;\n        for (; x < aligned_width; x += 4)\n        {\n            // load 2 pixels each\n            p01 = _mm_loadl_epi64((const __m128i*) &pSrc1[Xmap[x]]);\n            p23 = _mm_loadl_epi64((const __m128i*) &pSrc1[Xmap[x+1]]);\n            ps01 = _mm_loadl_epi64((const __m128i*) &pSrc2[Xmap[x]]);\n            ps23 = _mm_loadl_epi64((const __m128i*) &pSrc2[Xmap[x + 1]]);\n            // unpcklo for p01 and ps01\n            p01 = _mm_unpacklo_epi8(p01, ps01);\n            p23 = _mm_unpacklo_epi8(p23, ps23);\n            p01 = _mm_unpacklo_epi16(p01, _mm_srli_si128(p01, 6));     //R0R1R2R3 G0G1G2G3 B0B1B2B3 XXXX for first pixel\n            p23 = _mm_unpacklo_epi16(p23, _mm_srli_si128(p23, 6));      //R0R1R2R3 G0G1G2G3 B0B1B2B3 XXXX for second pixel\n\n            // load xf and 1-xf\n            ps01 = _mm_setr_epi32(Xf1[x], Xf1[x], Xf[x], Xf[x]);\t\t\t// xfxfxf1xf1\n            ps01 = _mm_mullo_epi32(ps01, w_y);                      // W0W1W2W3 for first pixel\n            ps23 = _mm_setr_epi32(Xf1[x + 1], Xf1[x + 1], Xf[x + 1], Xf[x + 1]);\n            ps23 = _mm_mullo_epi32(ps23, w_y);                      // W0W1W2W3 for second pixel\n            ps01 = _mm_srli_epi32(ps01, 8);                 // convert to 16bit\n            ps23 = _mm_srli_epi32(ps23, 8);                 // convert to 16bit\n            ps01 = _mm_packus_epi32(ps01, ps01);                 // convert to 16bit\n            ps23 = _mm_packus_epi32(ps23, ps23);                 // convert to 16bit\n\n            // extend to 16bit\n            pRG1 = _mm_unpacklo_epi8(p01, mm_zeros);        // R0R1R2R3 and G0G1G2G3\n            p01 = _mm_srli_si128(p01, 8);             // B0B1B2B3xxxx\n            p01 = _mm_unpacklo_epi32(p01, p23);       // B0B1B2B3 R0R1R2R3: ist and second\n            p23 = _mm_srli_si128(p23, 4);             // G0G1G2G3 B0B1B2B3 for second pixel\n            p01 = _mm_unpacklo_epi8(p01, mm_zeros);         // B0B1B2B3 R0R1R2R3\n            pRG2 = _mm_unpacklo_epi8(p23, mm_zeros);        // G0G1G2G3 B0B1B2B3 for second pixel\n\n            pRG1 = _mm_madd_epi16(pRG1, ps01);                  // (W0*R0+W1*R1), (W2*R2+W3*R3), (W0*G0+W1*G1), (W2*G2+W3*G3)\n            pRG2 = _mm_madd_epi16(pRG2, ps23);                  //(W0*R0+W1*R1), (W2*R2+W3*R3), (W0*G0+W1*G1), (W2*G2+W3*G3) for seond pixel\n            ps01 = _mm_unpacklo_epi64(ps01, ps23);\n            p01 = _mm_madd_epi16(p01, ps01);                  //(W0*B0+W1*B1), (W2*B2+W3*B3), (W0*R0+W1*R1), (W2*R2+W3*R3) 1st and second pixel\n\n            pRG1 = _mm_hadd_epi32(pRG1, p01);      // R0,G0, B0, R1 (32bit)\n            p01 = _mm_loadl_epi64((const __m128i*) &pSrc1[Xmap[x+2]]);\n            p23 = _mm_loadl_epi64((const __m128i*) &pSrc1[Xmap[x+3]]);\n            ps01 = _mm_loadl_epi64((const __m128i*) &pSrc2[Xmap[x+2]]);\n            ps23 = _mm_loadl_epi64((const __m128i*) &pSrc2[Xmap[x+3]]);\n            pRG1 = _mm_add_epi32(pRG1, mm_round);\n            // unpcklo for p01 and ps01\n            p01 = _mm_unpacklo_epi8(p01, ps01);\n            p01 = _mm_unpacklo_epi16(p01, _mm_srli_si128(p01, 6));     //R0R1R2R3 G0G1G2G3 B0B1B2B3 XXXX for first pixel\n            p23 = _mm_unpacklo_epi8(p23, ps23);\n            p23 = _mm_unpacklo_epi16(p23, _mm_srli_si128(p23, 6));      //R0R1R2R3 G0G1G2G3 B0B1B2B3 XXXX for second pixel\n            // load xf and 1-xf\n            ps01 = _mm_setr_epi32(Xf1[x+2], Xf1[x+2], Xf[x+2], Xf[x+2]);\t\t\t// xfxfxf1xf1\n            ps01 = _mm_mullo_epi32(ps01, w_y);                      // W0W1W2W3 for first pixel\n            ps23 = _mm_setr_epi32(Xf1[x + 3], Xf1[x + 3], Xf[x + 3], Xf[x + 3]);\n            ps23 = _mm_mullo_epi32(ps23, w_y);                      // W0W1W2W3 for second pixel\n            ps01 = _mm_srli_epi32(ps01, 8);                 // convert to 16bit\n            ps23 = _mm_srli_epi32(ps23, 8);                 // convert to 16bit\n            ps01 = _mm_packus_epi32(ps01, ps01);                 // convert to 16bit\n            ps23 = _mm_packus_epi32(ps23, ps23);                 // convert to 16bit\n            // extend to 16bit\n            pRG3 = _mm_unpacklo_epi8(p01, mm_zeros);        // R0R1R2R3 and G0G1G2G3\n            p01 = _mm_srli_si128(p01, 8);             // B0B1B2B3xxxx\n            p01 = _mm_unpacklo_epi32(p01, p23);       // B0B1B2B3 R0R1R2R3: ist and second\n            p23 = _mm_srli_si128(p23, 4);             // G0G1G2G3 B0B1B2B3 for second pixel\n            p01 = _mm_unpacklo_epi8(p01, mm_zeros);         // B0B1B2B3 R0R1R2R3\n            p23 = _mm_unpacklo_epi8(p23, mm_zeros);        // G0G1G2G3 B0B1B2B3 for second pixel\n\n            pRG3 = _mm_madd_epi16(pRG3, ps01);                  // (W0*R0+W1*R1), (W2*R2+W3*R3), (W0*G0+W1*G1), (W2*G2+W3*G3)\n            p23 = _mm_madd_epi16(p23, ps23);                  //(W0*R0+W1*R1), (W2*R2+W3*R3), (W0*G0+W1*G1), (W2*G2+W3*G3) for seond pixel\n            ps01 = _mm_unpacklo_epi64(ps01, ps23);\n            p01 = _mm_madd_epi16(p01, ps01);                  //(W0*B0+W1*B1), (W2*B2+W3*B3), (W0*B0+W1*B1), (W2*B2+W3*B3) for seond pixel\n\n            pRG2 = _mm_hadd_epi32(pRG2, pRG3);      // G1, B1, R2,G2 (32bit)\n            p01 = _mm_hadd_epi32(p01, p23);      // B2,R3, G3, B3 (32bit)\n            pRG2 = _mm_add_epi32(pRG2, mm_round);\n            p01 = _mm_add_epi32(p01, mm_round);\n            pRG1 = _mm_srli_epi32(pRG1, 8);      // /256\n            pRG2 = _mm_srli_epi32(pRG2, 8);      // /256\n            p01 = _mm_srli_epi32(p01, 8);      // /256\n\n            // convert to 16bit\n            pRG1 = _mm_packus_epi32(pRG1, pRG2); //R0G0B0R1G1B1R2G2\n            p01 = _mm_packus_epi32(p01, p01); //B2R3B3G3\n            pRG1 = _mm_packus_epi16(pRG1, mm_zeros);\n            p01 = _mm_packus_epi16(p01, mm_zeros);\n            _mm_storeu_si128((__m128i *)pdst, _mm_unpacklo_epi64(pRG1, p01));\n            pdst += 12;\n        }\n\n        for (; x < dwidth; x++) {\n            int result;\n            const unsigned char *p0 = pSrc1 + Xmap[x];\n            const unsigned char *p01 = p0 + 3;\n            const unsigned char *p1 = pSrc2 + Xmap[x];\n            const unsigned char *p11 = p1 + 3;\n            if (p0 > pSrcBorder) p0 = pSrcBorder;\n            if (p1 > pSrcBorder) p1 = pSrcBorder;\n            if (p01 > pSrcBorder) p01 = pSrcBorder;\n            if (p11 > pSrcBorder) p11 = pSrcBorder;\n            result = ((Xf1[x] * fy1*p0[0]) + (Xf[x] * fy1*p01[0]) + (Xf1[x] * fy*p1[0]) + (Xf[x] * fy*p11[0]) + 0x8000) >> 16;\n            *pdst++ = (unsigned char) std::max(0, std::min(result, 255));\n            result = ((Xf1[x] * fy1*p0[1]) + (Xf[x] * fy1*p01[1]) + (Xf1[x] * fy*p1[1]) + (Xf[x] * fy*p11[1]) + 0x8000) >> 16;\n            *pdst++ = (unsigned char)std::max(0, std::min(result, 255));\n            result = ((Xf1[x] * fy1*p0[2]) + (Xf[x] * fy1*p01[2]) + (Xf1[x] * fy*p1[2]) + (Xf[x] * fy*p11[2]) + 0x8000) >> 16;\n            *pdst++ = (unsigned char)std::max(0, std::min(result, 255));\n        }\n    }\n    if (Xmap) delete[] Xmap;\n}\n\n\nvoid InferenceEngine::DecodeScaleAndConvertToTensorBatch(std::vector<std::tuple<char*, int>>& batch_Q, int start, int end, int dim[3], float *tens_buf)\n{\n    for (int i = start; i <= end; i++)\n    {\n        std::tuple<char*, int> image = batch_Q[i];\n        char * byteStream = std::get<0>(image);\n        int size = std::get<1>(image);\n        if (byteStream == nullptr || size == 0) {\n            break;\n        }\n        // decode, scale, and format convert into the OpenCL buffer\n        float *buf;\n        if (useFp16)\n            buf = (float *) ((unsigned short *)tens_buf + dim[0] * dim[1] * dim[2] * i);\n        else\n            buf = (float *) tens_buf + dim[0] * dim[1] * dim[2] * i;\n        DecodeScaleAndConvertToTensor(dim[0], dim[1], size, (unsigned char *)byteStream, buf, useFp16);\n        delete[] byteStream;\n    }\n}\n\n\nint InferenceEngine::run()\n{\n    //////\n    /// make device lock is successful\n    ///\n    if(!deviceLockSuccess) {\n        return error_close(sock, \"could not lock %d GPUs devices for inference request from %s\", GPUs, clientName.c_str());\n    }\n\n    //////\n    /// check if server and client are in the same mode for data\n    ///\n    if (receiveFileNames && !useShadowFilenames)\n    {\n        return error_close(sock, \"client is sending filenames but server is not configured with shadow folder\\n\");\n    }\n\n    //////\n    /// check if client is requesting topK which is not supported\n    ///\n    if (topK > 5)\n    {\n        return error_close(sock, \"Number of topK confidances: %d not supported\\n\", topK);\n    }\n\n    //////\n    /// check for model validity\n    ///\n    bool found = false;\n    for(size_t i = 0; i < args->getNumConfigureddModels(); i++) {\n        std::tuple<std::string,int,int,int,int,int,int,int,float,float,float,float,float,float,std::string> info = args->getConfiguredModelInfo(i);\n        if(std::get<0>(info) == modelName &&\n           std::get<1>(info) == dimInput[0] &&\n           std::get<2>(info) == dimInput[1] &&\n           std::get<3>(info) == dimInput[2] &&\n           std::get<4>(info) == dimOutput[0] &&\n           std::get<5>(info) == dimOutput[1] &&\n           std::get<6>(info) == dimOutput[2])\n        {\n            reverseInputChannelOrder = std::get<7>(info);\n            preprocessMpy[0] = std::get<8>(info);\n            preprocessMpy[1] = std::get<9>(info);\n            preprocessMpy[2] = std::get<10>(info);\n            preprocessAdd[0] = std::get<11>(info);\n            preprocessAdd[1] = std::get<12>(info);\n            preprocessAdd[2] = std::get<13>(info);\n            modelPath = args->getConfigurationDir() + \"/\" + std::get<14>(info);\n            found = true;\n            break;\n        }\n    }\n    if(!found) {\n        for(size_t i = 0; i < args->getNumUploadedModels(); i++) {\n            std::tuple<std::string,int,int,int,int,int,int,int,float,float,float,float,float,float> info = args->getUploadedModelInfo(i);\n            if(std::get<0>(info) == modelName &&\n               std::get<1>(info) == dimInput[0] &&\n               std::get<2>(info) == dimInput[1] &&\n               std::get<3>(info) == dimInput[2] &&\n               std::get<4>(info) == dimOutput[0] &&\n               std::get<5>(info) == dimOutput[1] &&\n               std::get<6>(info) == dimOutput[2])\n            {\n                reverseInputChannelOrder = std::get<7>(info);\n                preprocessMpy[0] = std::get<8>(info);\n                preprocessMpy[1] = std::get<9>(info);\n                preprocessMpy[2] = std::get<10>(info);\n                preprocessAdd[0] = std::get<11>(info);\n                preprocessAdd[1] = std::get<12>(info);\n                preprocessAdd[2] = std::get<13>(info);\n                modelPath = args->getConfigurationDir() + \"/\" + modelName;\n                found = true;\n                break;\n            }\n        }\n    }\n    if(found) {\n        modulePath = modelPath + \"/build/\" + MODULE_LIBNAME;\n        moduleHandle = dlopen(modulePath.c_str(), RTLD_NOW | RTLD_LOCAL);\n        if(!moduleHandle) {\n            found = false;\n            error(\"could not locate module %s for %s\", modulePath.c_str(), clientName.c_str());\n        }\n        if (args->getModelCompilerPath().empty()) {\n            if(!(annCreateGraph = (type_annCreateGraph *) dlsym(moduleHandle, \"annCreateGraph\"))) {\n                found = false;\n                error(\"could not find function annCreateGraph() in module %s for %s\", modulePath.c_str(), clientName.c_str());\n            }\n        }\n        else if(!(annAddtoGraph = (type_annAddToGraph *) dlsym(moduleHandle, \"annAddToGraph\"))) {\n            found = false;\n            error(\"could not find function annAddToGraph() in module %s for %s\", modulePath.c_str(), clientName.c_str());\n        }\n    }\n    else {\n        error(\"unable to find requested model:%s input:%dx%dx%d output:%dx%dx%d from %s\", modelName.c_str(),\n              dimInput[2], dimInput[1], dimInput[0], dimOutput[2], dimOutput[1], dimOutput[0], clientName.c_str());\n    }\n    if(!found) {\n        // send and wait for INFCOM_CMD_DONE message\n        InfComCommand reply = {\n            INFCOM_MAGIC, INFCOM_CMD_DONE, { 0 }, { 0 }\n        };\n        ERRCHK(sendCommand(sock, reply, clientName));\n        ERRCHK(recvCommand(sock, reply, clientName, INFCOM_CMD_DONE));\n        close(sock);\n        return -1;\n    }\n    info(\"found requested model:%s input:%dx%dx%d output:%dx%dx%d from %s\", modelName.c_str(),\n          dimInput[2], dimInput[1], dimInput[0], dimOutput[2], dimOutput[1], dimOutput[0], clientName.c_str());\n\n    // send and wait for INFCOM_CMD_INFERENCE_INITIALIZATION message\n    InfComCommand updateCmd = {\n        INFCOM_MAGIC, INFCOM_CMD_INFERENCE_INITIALIZATION, { 0 }, \"started initialization\"\n    };\n    ERRCHK(sendCommand(sock, updateCmd, clientName));\n    ERRCHK(recvCommand(sock, updateCmd, clientName, INFCOM_CMD_INFERENCE_INITIALIZATION));\n    info(updateCmd.message);\n\n#if INFERENCE_SCHEDULER_MODE == NO_INFERENCE_SCHEDULER\n#if DONOT_RUN_INFERENCE\n    info(\"InferenceEngine: using NO_INFERENCE_SCHEDULER and DONOT_RUN_INFERENCE\");\n#else\n    { // create OpenVX resources\n        info(\"InferenceEngine: using NO_INFERENCE_SCHEDULER\");\n        vx_status status;\n        openvx_context = vxCreateContext();\n        if((status = vxGetStatus((vx_reference)openvx_context)) != VX_SUCCESS)\n            fatal(\"InferenceEngine: vxCreateContext() failed (%d)\", status);\n        vx_size idim[4] = { (vx_size)dimInput[0], (vx_size)dimInput[1], (vx_size)dimInput[2], (vx_size)batchSize };\n        vx_size odim[4] = { (vx_size)dimOutput[0], (vx_size)dimOutput[1], (vx_size)dimOutput[2], (vx_size)batchSize };\n        openvx_input = vxCreateTensor(openvx_context, 4, idim, VX_TYPE_FLOAT32, 0);\n        openvx_output = vxCreateTensor(openvx_context, 4, odim, VX_TYPE_FLOAT32, 0);\n        if((status = vxGetStatus((vx_reference)openvx_input)) != VX_SUCCESS)\n            fatal(\"InferenceEngine: vxCreateTensor(input) failed (%d)\", status);\n        if((status = vxGetStatus((vx_reference)openvx_output)) != VX_SUCCESS)\n            fatal(\"InferenceEngine: vxCreateTensor(output) failed (%d)\", status);\n        //////\n        // load the model\n        openvx_graph = annCreateGraph(openvx_context, openvx_input, openvx_output, modelPath.c_str());\n        if((status = vxGetStatus((vx_reference)openvx_graph)) != VX_SUCCESS)\n            fatal(\"InferenceEngine: annCreateGraph() failed (%d)\", status);\n\n        // send and wait for INFCOM_CMD_INFERENCE_INITIALIZATION message\n        updateCmd.data[0] = 80;\n        sprintf(updateCmd.message, \"completed OpenVX graph\");\n        ERRCHK(sendCommand(sock, updateCmd, clientName));\n        ERRCHK(recvCommand(sock, updateCmd, clientName, INFCOM_CMD_INFERENCE_INITIALIZATION));\n        info(updateCmd.message);\n    }\n#endif\n#elif INFERENCE_SCHEDULER_MODE == LIBRE_INFERENCE_SCHEDULER\n    info(\"InferenceEngine: using LIBRE_INFERENCE_SCHEDULER\");\n    //////\n    /// allocate OpenVX and OpenCL resources\n    /// \n    for(int gpu = 0; gpu < GPUs; gpu++) {\n        //////\n        // create OpenCL context\n        cl_context_properties ctxprop[] = {\n            CL_CONTEXT_PLATFORM, (cl_context_properties)args->getPlatformId(),\n            0, 0\n        };\n        cl_int err;\n        opencl_context[gpu] = clCreateContext(ctxprop, 1, &device_id[gpu], NULL, NULL, &err);\n        if(err)\n            fatal(\"InferenceEngine: clCreateContext(#%d) failed (%d)\", gpu, err);\n#if defined(CL_VERSION_2_0)\n        cl_queue_properties properties[] = { CL_QUEUE_PROPERTIES, 0, 0, 0 };\n        opencl_cmdq[gpu] = clCreateCommandQueueWithProperties(opencl_context[gpu], device_id[gpu], properties, &err);\n#else\n        opencl_cmdq[gpu] = clCreateCommandQueue(opencl_context[gpu], device_id[gpu], 0, &err);\n#endif\n        if(err) {\n            fatal(\"InferenceEngine: clCreateCommandQueue(device_id[%d]) failed (%d)\", gpu, err);\n        }\n\n        // create scheduler device queues\n#if  USE_ADVANCED_MESSAGE_Q\n        queueDeviceTagQ[gpu] = new MessageQueueAdvanced<int>(MAX_DEVICE_QUEUE_DEPTH);\n        queueDeviceImageQ[gpu] = new MessageQueueAdvanced<std::tuple<char*,int>>(MAX_INPUT_QUEUE_DEPTH);\n#else\n        queueDeviceTagQ[gpu] = new MessageQueue<int>();\n        queueDeviceTagQ[gpu]->setMaxQueueDepth(MAX_DEVICE_QUEUE_DEPTH);\n        queueDeviceImageQ[gpu] = new MessageQueue<std::tuple<char*,int>>();\n#endif\n        queueDeviceInputMemIdle[gpu] = new MessageQueue<cl_mem>();\n        queueDeviceInputMemBusy[gpu] = new MessageQueue<cl_mem>();\n        queueDeviceOutputMemIdle[gpu] = new MessageQueue<cl_mem>();\n        queueDeviceOutputMemBusy[gpu] = new MessageQueue<cl_mem>();\n\n        // create OpenCL buffers for input/output and add them to queueDeviceInputMemIdle/queueDeviceOutputMemIdle\n        cl_mem memInput = nullptr, memOutput = nullptr;\n        for(int i = 0; i < INFERENCE_PIPE_QUEUE_DEPTH; i++) {\n            cl_int err;\n            memInput = clCreateBuffer(opencl_context[gpu], CL_MEM_READ_WRITE, inputSizeInBytes, NULL, &err);\n            if(err) {\n                fatal(\"InferenceEngine: clCreateBuffer(#%d,%d) [#%d] failed (%d)\", gpu, inputSizeInBytes, i, err);\n            }\n            memOutput = clCreateBuffer(opencl_context[gpu], CL_MEM_READ_WRITE, outputSizeInBytes, NULL, &err);\n            if(err) {\n                fatal(\"InferenceEngine: clCreateBuffer(#%d,%d) [#%d] failed (%d)\", gpu, outputSizeInBytes, i, err);\n            }\n            queueDeviceInputMemIdle[gpu]->enqueue(memInput);\n            queueDeviceOutputMemIdle[gpu]->enqueue(memOutput);\n        }\n\n        //////\n        // create OpenVX context\n        vx_status status;\n        openvx_context[gpu] = vxCreateContext();\n        if((status = vxGetStatus((vx_reference)openvx_context[gpu])) != VX_SUCCESS)\n            fatal(\"InferenceEngine: vxCreateContext(#%d) failed (%d)\", gpu, status);\n        if((status = vxSetContextAttribute(openvx_context[gpu], VX_CONTEXT_ATTRIBUTE_AMD_OPENCL_CONTEXT,\n                                          &opencl_context[gpu], sizeof(cl_context))) != VX_SUCCESS)\n            fatal(\"InferenceEngine: vxSetContextAttribute(#%d,VX_CONTEXT_ATTRIBUTE_AMD_OPENCL_CONTEXT) failed (%d)\", gpu, status);\n        vx_size idim[4] = { (vx_size)dimInput[0], (vx_size)dimInput[1], (vx_size)dimInput[2], (vx_size)batchSize };\n        vx_size odim[4] = { (vx_size)dimOutput[0], (vx_size)dimOutput[1], (vx_size)dimOutput[2], (vx_size)batchSize };\n        if (useFp16) {\n            vx_size istride[4] = { 2, (vx_size)2 * dimInput[0], (vx_size)2 * dimInput[0] * dimInput[1], (vx_size)2 * dimInput[0] * dimInput[1] * dimInput[2] };\n            vx_size ostride[4] = { 2, (vx_size)2 * dimOutput[0], (vx_size)2 * dimOutput[0] * dimOutput[1], (vx_size)2 * dimOutput[0] * dimOutput[1] * dimOutput[2] };\n            openvx_input[gpu] = vxCreateTensorFromHandle(openvx_context[gpu], 4, idim, VX_TYPE_FLOAT16, 0, istride, memInput, VX_MEMORY_TYPE_OPENCL);\n            openvx_output[gpu] = vxCreateTensorFromHandle(openvx_context[gpu], 4, odim, VX_TYPE_FLOAT16, 0, ostride, memOutput, VX_MEMORY_TYPE_OPENCL);\n            if (openvx_output[gpu] == nullptr)\n                printf(\" vxCreateTensorFromHandle(output) failed for gpu#%d\\n\", gpu);\n        } else {\n            vx_size istride[4] = { 4, (vx_size)4 * dimInput[0], (vx_size)4 * dimInput[0] * dimInput[1], (vx_size)4 * dimInput[0] * dimInput[1] * dimInput[2] };\n            vx_size ostride[4] = { 4, (vx_size)4 * dimOutput[0], (vx_size)4 * dimOutput[0] * dimOutput[1], (vx_size)4 * dimOutput[0] * dimOutput[1] * dimOutput[2] };\n            openvx_input[gpu] = vxCreateTensorFromHandle(openvx_context[gpu], 4, idim, VX_TYPE_FLOAT32, 0, istride, memInput, VX_MEMORY_TYPE_OPENCL);\n            openvx_output[gpu] = vxCreateTensorFromHandle(openvx_context[gpu], 4, odim, VX_TYPE_FLOAT32, 0, ostride, memOutput, VX_MEMORY_TYPE_OPENCL);\n        }\n        if((status = vxGetStatus((vx_reference)openvx_input[gpu])) != VX_SUCCESS)\n            fatal(\"InferenceEngine: vxCreateTensorFromHandle(input#%d) failed (%d)\", gpu, status);\n        if((status = vxGetStatus((vx_reference)openvx_output[gpu])) != VX_SUCCESS)\n            fatal(\"InferenceEngine: vxCreateTensorFromHandle(output#%d) failed (%d)\", gpu, status);\n\n        //////\n        // load the model\n        if (annCreateGraph != nullptr) {\n            openvx_graph[gpu] = annCreateGraph(openvx_context[gpu], openvx_input[gpu], openvx_output[gpu], modelPath.c_str());\n            if((status = vxGetStatus((vx_reference)openvx_graph[gpu])) != VX_SUCCESS)\n                fatal(\"InferenceEngine: annCreateGraph(#%d) failed (%d)\", gpu, status);\n        }\n        else if (annAddtoGraph != nullptr) {\n            std::string weightsFile = modelPath + \"/weights.bin\";\n            vxRegisterLogCallback(openvx_context[gpu], log_callback, vx_false_e);\n            openvx_graph[gpu] = vxCreateGraph(openvx_context[gpu]);\n            status = vxGetStatus((vx_reference)openvx_graph[gpu]);\n            if(status) {\n                fatal(\"InferenceEngine: vxCreateGraph(#%d) failed (%d)\", gpu, status);\n                return -1;\n            }\n            status = annAddtoGraph(openvx_graph[gpu], openvx_input[gpu], openvx_output[gpu], weightsFile.c_str());\n            if(status) {\n                fatal(\"InferenceEngine: annAddToGraph(#%d) failed (%d)\", gpu, status);\n                return -1;\n            }\n        }\n\n        // send and wait for INFCOM_CMD_INFERENCE_INITIALIZATION message\n        updateCmd.data[0] = 80 * (gpu + 1) / GPUs;\n        sprintf(updateCmd.message, \"completed OpenVX graph for GPU#%d\", gpu);\n        ERRCHK(sendCommand(sock, updateCmd, clientName));\n        ERRCHK(recvCommand(sock, updateCmd, clientName, INFCOM_CMD_INFERENCE_INITIALIZATION));\n        info(updateCmd.message);\n    }\n#endif\n\n    //////\n    /// start scheduler threads\n    ///\n#if INFERENCE_SCHEDULER_MODE == NO_INFERENCE_SCHEDULER\n    // nothing to do\n#elif INFERENCE_SCHEDULER_MODE == LIBRE_INFERENCE_SCHEDULER\n    threadMasterInputQ = new std::thread(&InferenceEngine::workMasterInputQ, this);\n    for(int gpu = 0; gpu < GPUs; gpu++) {\n        threadDeviceInputCopy[gpu] = new std::thread(&InferenceEngine::workDeviceInputCopy, this, gpu);\n        threadDeviceProcess[gpu] = new std::thread(&InferenceEngine::workDeviceProcess, this, gpu);\n        threadDeviceOutputCopy[gpu] = new std::thread(&InferenceEngine::workDeviceOutputCopy, this, gpu);\n    }\n#endif\n\n    // send and wait for INFCOM_CMD_INFERENCE_INITIALIZATION message\n    updateCmd.data[0] = 100;\n    sprintf(updateCmd.message, \"inference engine is ready\");\n    ERRCHK(sendCommand(sock, updateCmd, clientName));\n    ERRCHK(recvCommand(sock, updateCmd, clientName, INFCOM_CMD_INFERENCE_INITIALIZATION));\n    info(updateCmd.message);\n\n    ////////\n    /// \\brief keep running the inference in loop\n    ///\n    bool endOfImageRequested = false;\n    for(bool endOfSequence = false; !endOfSequence; ) {\n        bool didSomething = false;\n\n        // send all the available results to the client\n        int resultCountAvailable = outputQ.size();\n        if(resultCountAvailable > 0) {\n            didSomething = true;\n            while(resultCountAvailable > 0) {\n                if (!detectBoundingBoxes){\n                    if (topK < 1){\n                        int resultCount = std::min(resultCountAvailable, (INFCOM_MAX_IMAGES_FOR_TOP1_PER_PACKET/2));\n                        InfComCommand cmd = {\n                            INFCOM_MAGIC, INFCOM_CMD_INFERENCE_RESULT, { resultCount, 0 }, { 0 }\n                        };\n                        for(int i = 0; i < resultCount; i++) {\n                            std::tuple<int,int> result;\n                            outputQ.dequeue(result);\n                            int tag = std::get<0>(result);\n                            int label = std::get<1>(result);\n                            if(tag < 0) {\n                                endOfSequence = true;\n                                resultCount = i;\n                                break;\n                            }\n                            cmd.data[2 + i * 2 + 0] = tag; // tag\n                            cmd.data[2 + i * 2 + 1] = label; // label\n                        }\n                        if(resultCount > 0) {\n                            cmd.data[0] = resultCount;\n                            ERRCHK(sendCommand(sock, cmd, clientName));\n                            resultCountAvailable -= resultCount;\n                            ERRCHK(recvCommand(sock, cmd, clientName, INFCOM_CMD_INFERENCE_RESULT));\n                        }\n                        if(endOfSequence) {\n                            break;\n                        }\n                    }else {\n                        // send topK labels\n                        int maxResults = INFCOM_MAX_IMAGES_FOR_TOP1_PER_PACKET/(topK+1);\n                        int resultCount = std::min(resultCountAvailable, maxResults);\n                        InfComCommand cmd = {\n                            INFCOM_MAGIC, INFCOM_CMD_TOPK_INFERENCE_RESULT, { resultCount, topK }, { 0 }\n                        };\n                        for(int i = 0; i < resultCount; i++) {\n                            std::tuple<int,int> result;\n                            std::vector<unsigned int> labels;\n                            outputQ.dequeue(result);\n                            int tag = std::get<0>(result);\n                            if(tag < 0) {\n                                endOfSequence = true;\n                                resultCount = i;\n                                break;\n                            }\n                            outputQTopk.dequeue(labels);\n                            cmd.data[2 + i * (topK+1) + 0] = tag; // tag\n                            for (int j=0; j<topK; j++){\n                                cmd.data[3 + i * (topK+1) + j] = labels[j]; // label[j]\n                            }\n                            labels.clear();\n                        }\n                        if(resultCount > 0) {\n                            cmd.data[0] = resultCount;\n                            ERRCHK(sendCommand(sock, cmd, clientName));\n                            resultCountAvailable -= resultCount;\n                            ERRCHK(recvCommand(sock, cmd, clientName, INFCOM_CMD_TOPK_INFERENCE_RESULT));\n                        }\n                        if(endOfSequence) {\n                            break;\n                        }\n                    }\n                }else\n                {\n                    // Dequeue the bounding box\n                    std::tuple<int,int> result;\n                    std::vector<ObjectBB> bounding_boxes;\n                    outputQ.dequeue(result);\n                    int tag = std::get<0>(result);\n                    int label = std::get<1>(result);        // label of first bounding box\n                    if(tag < 0) {\n                        endOfSequence = true;\n                        resultCountAvailable--;\n                        break;\n                    }else\n                    {\n                        int numBB = 0;\n                        int numMessages = 0;\n                        if (label >= 0) {\n                            OutputQBB.dequeue(bounding_boxes);\n                            numBB = bounding_boxes.size();\n                            if (numBB) numMessages = numBB/3;   // max 3 bb per mesasge\n                            if (numBB % 3) numMessages++;\n                        }\n                        if (!numBB) {\n                            InfComCommand cmd = {\n                                INFCOM_MAGIC, INFCOM_CMD_BB_INFERENCE_RESULT, { tag, 0 }, { 0 }        // no bb detected\n                            };\n                            ERRCHK(sendCommand(sock, cmd, clientName));\n                            ERRCHK(recvCommand(sock, cmd, clientName, INFCOM_CMD_BB_INFERENCE_RESULT));\n                        } else\n                        {\n                            ObjectBB *pObj= &bounding_boxes[0];\n                            for (int i=0, j=0; (i < numMessages && j < numBB); i++) {\n                                int numBB_per_message = std::min((numBB-j), 3);\n                                int bb_info = (numBB_per_message & 0xFFFF) | (numBB << 16);\n                                InfComCommand cmd = {\n                                    INFCOM_MAGIC, INFCOM_CMD_BB_INFERENCE_RESULT, { tag, bb_info }, { 0 }        // 3 bounding boxes in one message\n                                };\n                                cmd.data[2] = (unsigned int)((pObj->y*0x7FFF)+0.5)<<16  | (unsigned int)((pObj->x*0x7FFF)+0.5);\n                                cmd.data[3] = (unsigned int)((pObj->h*0x7FFF)+0.5)<<16  | (unsigned int)((pObj->w*0x7FFF)+0.5);\n                                cmd.data[4] = (unsigned int) ((pObj->confidence*0x3FFFFFFF)+0.5);    // convert float to Q30.1\n                                cmd.data[5] = pObj->label;\n                                pObj++;\n                                if (numBB_per_message > 1) {\n                                    cmd.data[6] = (unsigned int)((pObj->y*0x7FFF)+0.5)<<16  | (unsigned int)((pObj->x*0x7FFF)+0.5);\n                                    cmd.data[7] = (unsigned int)((pObj->h*0x7FFF)+0.5)<<16  | (unsigned int)((pObj->w*0x7FFF)+0.5);\n                                    cmd.data[8] = (unsigned int) ((pObj->confidence*0x3FFFFFFF)+0.5);    // convert float to Q30.1\n                                    cmd.data[9] = pObj->label;\n                                    pObj++;\n                                }\n                                if (numBB_per_message > 2) {\n                                    cmd.data[10] = (unsigned int)((pObj->y*0x7FFF)+0.5)<<16  | (unsigned int)((pObj->x*0x7FFF)+0.5);\n                                    cmd.data[11] = (unsigned int)((pObj->h*0x7FFF)+0.5)<<16  | (unsigned int)((pObj->w*0x7FFF)+0.5);\n                                    cmd.data[12] = (unsigned int) ((pObj->confidence*0x3FFFFFFF)+0.5);    // convert float to Q30.1;\n                                    cmd.data[13] = pObj->label;\n                                    pObj++;\n                                }\n                                ERRCHK(sendCommand(sock, cmd, clientName));\n                                ERRCHK(recvCommand(sock, cmd, clientName, INFCOM_CMD_BB_INFERENCE_RESULT));\n                                j += numBB_per_message;\n                            }\n                        }\n                        resultCountAvailable--;\n                    }\n                    bounding_boxes.clear();\n                }\n            }\n        }\n\n        // if not endOfImageRequested, request client to send images\n        if(!endOfImageRequested) {\n            // get number of empty slots in the input queue\n            int imageCountRequested = 0;\n#if INFERENCE_SCHEDULER_MODE == NO_INFERENCE_SCHEDULER\n            imageCountRequested = 1;\n#elif INFERENCE_SCHEDULER_MODE == LIBRE_INFERENCE_SCHEDULER\n            imageCountRequested = MAX_INPUT_QUEUE_DEPTH - inputQ.size();\n#endif\n            if(imageCountRequested > 0) {\n                didSomething = true;\n                // send request for upto INFCOM_MAX_IMAGES_PER_PACKET images\n                imageCountRequested = std::min(imageCountRequested, (INFCOM_MAX_IMAGES_FOR_TOP1_PER_PACKET/2));\n                InfComCommand cmd = {\n                    INFCOM_MAGIC, INFCOM_CMD_SEND_IMAGES, { imageCountRequested }, { 0 }\n                };\n                ERRCHK(sendCommand(sock, cmd, clientName));\n                ERRCHK(recvCommand(sock, cmd, clientName, INFCOM_CMD_SEND_IMAGES));\n\n                // check of endOfImageRequested and receive images one at a time\n                int imageCountReceived = cmd.data[0];\n                if(imageCountReceived < 0) {\n                    // submit the endOfSequence indicator to scheduler\n#if INFERENCE_SCHEDULER_MODE == NO_INFERENCE_SCHEDULER\n                    endOfSequence = true;\n#elif INFERENCE_SCHEDULER_MODE == LIBRE_INFERENCE_SCHEDULER\n                    inputQ.enqueue(std::tuple<int,char*,int>(-1,nullptr,0));\n#endif\n                    endOfImageRequested = true;\n                }\n                int i = 0;\n                for(; i < imageCountReceived; i++) {\n                    // get header with tag and size info\n                    int header[2] = { 0, 0 };\n                    ERRCHK(recvBuffer(sock, &header, sizeof(header), clientName));\n                    int tag = header[0];\n                    int size = header[1];\n                    // do sanity check with unreasonable parameters\n                    if(tag < 0 || size <= 0 || size > 50000000) {\n                        return error_close(sock, \"invalid (tag:%d,size:%d) from %s\", tag, size, clientName.c_str());\n                    }\n                    char * byteStream = 0;\n                    if (receiveFileNames)\n                    {\n                        std::string fileNameDir = args->getlocalShadowRootDir() + \"/\";\n                        char * buff = new char [size];\n                        ERRCHK(recvBuffer(sock, buff, size, clientName));\n                        fileNameDir.append(std::string(buff, size));\n                        FILE * fp = fopen(fileNameDir.c_str(), \"rb\");\n                        if(!fp) {\n                            return error_close(sock, \"filename %s (incorrect)\", fileNameDir.c_str());\n                        }\n                        fseek(fp,0,SEEK_END);\n                        int fsize = ftell(fp);\n                        fseek(fp,0,SEEK_SET);\n                        byteStream = new char [fsize];\n                        size = (int)fread(byteStream, 1, fsize, fp);\n                        fclose(fp);\n                        delete[] buff;\n                        if (size != fsize) {\n                            return error_close(sock, \"error reading %d bytes from file:%s\", fsize, fileNameDir.c_str());\n                        }\n                    }\n                    else\n                    {\n                        // allocate and receive the image and EOF market\n                        byteStream = new char [size];\n                        ERRCHK(recvBuffer(sock, byteStream, size, clientName));\n                    }\n                    int eofMarker = 0;\n                    ERRCHK(recvBuffer(sock, &eofMarker, sizeof(eofMarker), clientName));\n                    if(eofMarker != INFCOM_EOF_MARKER) {\n                        return error_close(sock, \"eofMarker 0x%08x (incorrect)\", eofMarker);\n                    }\n\n#if INFERENCE_SCHEDULER_MODE == NO_INFERENCE_SCHEDULER\n#if DONOT_RUN_INFERENCE\n                    // consume the input immediately since there is no scheduler\n                    // simulate the input (tag,byteStream,size) processing using a 4ms sleep\n                    int label = tag % dimOutput[2];\n                    std::this_thread::sleep_for(std::chrono::milliseconds(4));\n                    // release byteStream and keep the results in outputQ\n                    delete[] byteStream;\n                    outputQ.enqueue(std::tuple<int,int>(tag,label));\n#else\n                    // process the input immediately since there is no scheduler\n                    // decode, scale, and format convert into the OpenVX input buffer\n                    vx_map_id map_id;\n                    vx_size stride[4];\n                    float * ptr = nullptr;\n                    vx_status status;\n                    status = vxMapTensorPatch(openvx_input, 4, NULL, NULL, &map_id, stride, (void **)&ptr, VX_WRITE_ONLY, VX_MEMORY_TYPE_HOST, 0);\n                    if(status != VX_SUCCESS) {\n                        fatal(\"workDeviceProcess: vxMapTensorPatch(input)) failed(%d)\", status);\n                    }\n                    DecodeScaleAndConvertToTensor(dimInput[0], dimInput[1], size, (unsigned char *)byteStream, ptr, useFp16);\n                    status = vxUnmapTensorPatch(openvx_input, map_id);\n                    if(status != VX_SUCCESS) {\n                        fatal(\"workDeviceProcess: vxUnmapTensorPatch(input)) failed(%d)\", status);\n                    }\n                    // process the graph\n                    status = vxProcessGraph(openvx_graph);\n                    if(status != VX_SUCCESS) {\n                        fatal(\"workDeviceProcess: vxProcessGraph()) failed(%d)\", status);\n                    }\n                    ptr = nullptr;\n                    status = vxMapTensorPatch(openvx_output, 4, NULL, NULL, &map_id, stride, (void **)&ptr, VX_READ_ONLY, VX_MEMORY_TYPE_HOST, 0);\n                    if(status != VX_SUCCESS) {\n                        fatal(\"workDeviceProcess: vxMapTensorPatch(output)) failed(%d)\", status);\n                    }\n                    int label = 0;\n                    float max_prob = ptr[0];\n                    for(int c = 1; c < dimOutput[2]; c++) {\n                        float prob = ptr[c];\n                        if(prob > max_prob) {\n                            label = c;\n                            max_prob = prob;\n                        }\n                    }\n                    status = vxUnmapTensorPatch(openvx_output, map_id);\n                    if(status != VX_SUCCESS) {\n                        fatal(\"workDeviceProcess: vxUnmapTensorPatch(output)) failed(%d)\", status);\n                    }\n                    // release byteStream and keep the results in outputQ\n                    delete[] byteStream;\n                    outputQ.enqueue(std::tuple<int,int>(tag,label));\n#endif\n#elif INFERENCE_SCHEDULER_MODE == LIBRE_INFERENCE_SCHEDULER\n                    // submit the input (tag,byteStream,size) to scheduler\n                    inputQ.enqueue(std::tuple<int,char*,int>(tag,byteStream,size));\n#endif\n                }\n            }\n        }\n\n        // if nothing done, wait for sometime\n        if(!didSomething && INFERENCE_SERVICE_IDLE_TIME > 0) {\n            std::this_thread::sleep_for(std::chrono::milliseconds(INFERENCE_SERVICE_IDLE_TIME));\n        }\n    }\n    info(\"runInference: terminated for %s\", clientName.c_str());\n\n    // send and wait for INFCOM_CMD_DONE message\n    InfComCommand reply = {\n        INFCOM_MAGIC, INFCOM_CMD_DONE, { 0 }, { 0 }\n    };\n    ERRCHK(sendCommand(sock, reply, clientName));\n    ERRCHK(recvCommand(sock, reply, clientName, INFCOM_CMD_DONE));\n\n    return 0;\n}\n\n#if INFERENCE_SCHEDULER_MODE == LIBRE_INFERENCE_SCHEDULER\nvoid InferenceEngine::workMasterInputQ()\n{\n    args->lock();\n    info(\"workMasterInputQ: started for %s\", clientName.c_str());\n    args->unlock();\n\n    int batchSize = args->getBatchSize();\n    int totalInputCount = 0;\n    int inputCountInBatch = 0, gpu = 0;\n    for(;;) {\n        PROFILER_START(inference_server_app, workMasterInputQ);\n         // get next item from the input queue\n        std::tuple<int,char*,int> input;\n        inputQ.dequeue(input);\n        int tag = std::get<0>(input);\n        char * byteStream = std::get<1>(input);\n        int size = std::get<2>(input);\n\n        // check for end of input\n        if(tag < 0 || byteStream == nullptr || size == 0)\n            break;\n        totalInputCount++;\n\n        // add the image to selected deviceQ\n        std::tuple<char*,int> image(byteStream,size);\n        queueDeviceTagQ[gpu]->enqueue(tag);\n        queueDeviceImageQ[gpu]->enqueue(image);\n        PROFILER_STOP(inference_server_app, workMasterInputQ);\n\n        // at the end of Batch pick another device\n        inputCountInBatch++;\n        if(inputCountInBatch == batchSize) {\n            inputCountInBatch = 0;\n            gpu = (gpu + 1) % GPUs;\n            for(int i = 0; i < GPUs; i++) {\n                if(i != gpu && queueDeviceTagQ[i]->size() < queueDeviceTagQ[gpu]->size()) {\n                    gpu = i;\n                }\n            }\n        }\n    }\n\n    // send endOfSequence indicator to all scheduler threads\n    for(int i = 0; i < GPUs; i++) {\n        int endOfSequenceTag = -1;\n        std::tuple<char*,int> endOfSequenceImage(nullptr,0);\n        queueDeviceTagQ[i]->enqueue(endOfSequenceTag);\n        queueDeviceImageQ[i]->enqueue(endOfSequenceImage);\n    }\n    args->lock();\n    info(\"workMasterInputQ: terminated for %s [scheduled %d images]\", clientName.c_str(), totalInputCount);\n    args->unlock();\n}\n\nvoid InferenceEngine::workDeviceInputCopy(int gpu)\n{\n    args->lock();\n    info(\"workDeviceInputCopy: GPU#%d started for %s\", gpu, clientName.c_str());\n    args->unlock();\n\n    // create OpenCL command-queue\n    cl_command_queue cmdq;\n    cl_int err;\n#if defined(CL_VERSION_2_0)\n    cl_queue_properties properties[] = { CL_QUEUE_PROPERTIES, 0, 0 };\n    cmdq = clCreateCommandQueueWithProperties(opencl_context[gpu], device_id[gpu], properties, &err);\n#else\n    cmdq = clCreateCommandQueue(opencl_context[gpu], device_id[gpu], 0, &err);\n#endif\n    if(err) {\n        fatal(\"workDeviceInputCopy: clCreateCommandQueue(device_id[%d]) failed (%d)\", gpu, err);\n    }\n\n    int totalBatchCounter = 0, totalImageCounter = 0;\n    for(bool endOfSequenceReached = false; !endOfSequenceReached; ) {\n        PROFILER_START(inference_server_app, workDeviceInputCopyBatch);\n        // get an empty OpenCL buffer and lock the buffer for writing\n        cl_mem mem = nullptr;\n        queueDeviceInputMemIdle[gpu]->dequeue(mem);\n        if(mem == nullptr) {\n            fatal(\"workDeviceInputCopy: unexpected nullptr in queueDeviceInputMemIdle[%d]\", gpu);\n        }\n        cl_int err;\n        void * mapped_ptr = (void *)clEnqueueMapBuffer(cmdq, mem, CL_TRUE, CL_MAP_WRITE_INVALIDATE_REGION, 0, inputSizeInBytes, 0, NULL, NULL, &err);\n        if(err) {\n            fatal(\"workDeviceInputCopy: clEnqueueMapBuffer(#%d) failed (%d)\", gpu, err);\n        }\n\n        // get next batch of inputs and convert them into tensor and release input byteStream\n        // TODO: replace with an efficient implementation\n        int inputCount = 0;\n        if (numDecThreads > 0) {\n            std::vector<std::tuple<char*, int>> batch_q;\n            int sub_batch_size = batchSize/numDecThreads;\n            std::thread dec_threads[numDecThreads];\n            int numT = numDecThreads;\n            // dequeue batch\n            for (; inputCount<batchSize; inputCount++)\n            {\n                std::tuple<char*, int> image;\n                queueDeviceImageQ[gpu]->dequeue(image);\n                char * byteStream = std::get<0>(image);\n                int size = std::get<1>(image);\n                if(byteStream == nullptr || size == 0) {\n                    printf(\"workDeviceInputCopy:: Eos reached inputCount: %d\\n\", inputCount);\n                    endOfSequenceReached = true;\n                    break;\n                }\n                batch_q.push_back(image);\n            }\n            if (inputCount){\n                PROFILER_START(inference_server_app, workDeviceInputCopyJpegDecode);\n                if (inputCount < batchSize)\n                {\n                    sub_batch_size = (inputCount+numT-1)/numT;\n                    numT = (inputCount+(sub_batch_size-1))/sub_batch_size;\n                }\n                int start = 0; int end = sub_batch_size-1;\n                for (unsigned int t = 0; t < (numT - 1); t++)\n                {\n                    dec_threads[t]  = std::thread(&InferenceEngine::DecodeScaleAndConvertToTensorBatch, this, std::ref(batch_q), start, end, dimInput, (float *)mapped_ptr);\n                    start += sub_batch_size;\n                    end += sub_batch_size;\n                }\n                start = std::min(start, (inputCount - 1));\n                end = std::min(end, (inputCount-1));\n                // do some work in this thread\n                DecodeScaleAndConvertToTensorBatch(batch_q, start, end, dimInput, (float *)mapped_ptr);\n                for (unsigned int t = 0; t < (numT - 1); t++)\n                {\n                    dec_threads[t].join();\n                }\n                PROFILER_STOP(inference_server_app, workDeviceInputCopyJpegDecode);\n            }\n        } else {\n            for(; inputCount < batchSize; inputCount++) {\n                // get next item from the input queue and check for end of input\n                std::tuple<char*,int> image;\n                queueDeviceImageQ[gpu]->dequeue(image);\n                char * byteStream = std::get<0>(image);\n                int size = std::get<1>(image);\n                if(byteStream == nullptr || size == 0) {\n                    endOfSequenceReached = true;\n                    break;\n                }\n                // decode, scale, and format convert into the OpenCL buffer\n                float *buf;\n                if (useFp16)\n                    buf = (float *) ((unsigned short *)mapped_ptr + dimInput[0] * dimInput[1] * dimInput[2] * inputCount);\n                else\n                    buf = (float *) mapped_ptr + dimInput[0] * dimInput[1] * dimInput[2] * inputCount;\n\n                PROFILER_START(inference_server_app, workDeviceInputCopyJpegDecode);\n                DecodeScaleAndConvertToTensor(dimInput[0], dimInput[1], size, (unsigned char *)byteStream, buf, useFp16);\n                PROFILER_STOP(inference_server_app, workDeviceInputCopyJpegDecode);\n                // release byteStream\n                delete[] byteStream;\n            }\n        }\n        // unlock the OpenCL buffer to perform the writing\n        err = clEnqueueUnmapMemObject(cmdq, mem, mapped_ptr, 0, NULL, NULL);\n        if(err) {\n            fatal(\"workDeviceInputCopy: clEnqueueMapBuffer(#%d) failed (%d)\", gpu, err);\n        }\n        err = clFinish(cmdq);\n        if(err) {\n            fatal(\"workDeviceInputCopy: clFinish(#%d) failed (%d)\", gpu, err);\n        }\n\n        if(inputCount > 0) {\n            // add the input for processing\n            queueDeviceInputMemBusy[gpu]->enqueue(mem);\n            // update counters\n            totalBatchCounter++;\n            totalImageCounter += inputCount;\n        }\n        else {\n            // add the input back to idle queue\n            queueDeviceInputMemIdle[gpu]->enqueue(mem);\n        }\n        PROFILER_STOP(inference_server_app, workDeviceInputCopyBatch);\n    }\n    // release OpenCL command queue\n    clReleaseCommandQueue(cmdq);\n\n    // add the endOfSequenceMarker to next stage\n    cl_mem endOfSequenceMarker = nullptr;\n    queueDeviceInputMemBusy[gpu]->enqueue(endOfSequenceMarker);\n\n    args->lock();\n    info(\"workDeviceInputCopy: GPU#%d terminated for %s [processed %d batches, %d images]\", gpu, clientName.c_str(), totalBatchCounter, totalImageCounter);\n    args->unlock();\n}\n\nvoid InferenceEngine::workDeviceProcess(int gpu)\n{\n    args->lock();\n    info(\"workDeviceProcess: GPU#%d started for %s\", gpu, clientName.c_str());\n    args->unlock();\n\n    int processCounter = 0;\n    for(;;) {\n        // get a busy OpenCL buffer for input and check for end of sequence marker\n        cl_mem input = nullptr;\n        queueDeviceInputMemBusy[gpu]->dequeue(input);\n        if(!input) {\n            break;\n        }\n\n        // get an empty OpenCL buffer for output and a busy OpenCL buffer for input\n        cl_mem output = nullptr;\n        queueDeviceOutputMemIdle[gpu]->dequeue(output);\n        if(input == nullptr) {\n            fatal(\"workDeviceProcess: unexpected nullptr in queueDeviceOutputMemIdle[%d]\", gpu);\n        }\n\n        // process the graph\n        vx_status status;\n        status = vxSwapTensorHandle(openvx_input[gpu], input, nullptr);\n        if(status != VX_SUCCESS) {\n            fatal(\"workDeviceProcess: vxSwapTensorHandle(input#%d) failed(%d)\", gpu, status);\n        }\n        status = vxSwapTensorHandle(openvx_output[gpu], output, nullptr);\n        if(status != VX_SUCCESS) {\n            fatal(\"workDeviceProcess: vxSwapTensorHandle(output#%d) failed(%d)\", gpu, status);\n        }\n#if !DONOT_RUN_INFERENCE\n        PROFILER_START(inference_server_app, workDeviceProcess);\n        status = vxProcessGraph(openvx_graph[gpu]);\n        PROFILER_STOP(inference_server_app, workDeviceProcess);\n        if(status != VX_SUCCESS) {\n            fatal(\"workDeviceProcess: vxProcessGraph(#%d) failed(%d)\", gpu, status);\n        }\n#else\n        info(\"InferenceEngine:workDeviceProcess DONOT_RUN_INFERENCE mode\");\n        std::this_thread::sleep_for(std::chrono::milliseconds(1));  // simulate some work\n#endif\n        // add the input for idle queue and output to busy queue\n        queueDeviceInputMemIdle[gpu]->enqueue(input);\n        queueDeviceOutputMemBusy[gpu]->enqueue(output);\n        processCounter++;\n    }\n\n    // add the endOfSequenceMarker to next stage\n    cl_mem endOfSequenceMarker = nullptr;\n    queueDeviceOutputMemBusy[gpu]->enqueue(endOfSequenceMarker);\n\n    args->lock();\n    info(\"workDeviceProcess: GPU#%d terminated for %s [processed %d batches]\", gpu, clientName.c_str(), processCounter);\n    args->unlock();\n}\n\nvoid InferenceEngine::workDeviceOutputCopy(int gpu)\n{\n    args->lock();\n    info(\"workDeviceOutputCopy: GPU#%d started for %s\", gpu, clientName.c_str());\n    args->unlock();\n\n    // create OpenCL command-queue\n    cl_command_queue cmdq;\n    cl_int err;\n#if defined(CL_VERSION_2_0)\n    cl_queue_properties properties[] = { CL_QUEUE_PROPERTIES, 0, 0 };\n    cmdq = clCreateCommandQueueWithProperties(opencl_context[gpu], device_id[gpu], properties, &err);\n#else\n    cmdq = clCreateCommandQueue(opencl_context[gpu], device_id[gpu], 0, &err);\n#endif\n    if(err) {\n        fatal(\"workDeviceOutputCopy: clCreateCommandQueue(device_id[%d]) failed (%d)\", gpu, err);\n    }\n\n    int totalBatchCounter = 0, totalImageCounter = 0;\n    for(bool endOfSequenceReached = false; !endOfSequenceReached; ) {\n        // get an output OpenCL buffer and lock the buffer for reading\n        cl_mem mem = nullptr;\n        queueDeviceOutputMemBusy[gpu]->dequeue(mem);\n        if(mem == nullptr) {\n            break;\n        }\n        PROFILER_START(inference_server_app, workDeviceOutputCopy);\n        cl_int err;\n        void * mapped_ptr = (float *)clEnqueueMapBuffer(cmdq, mem, CL_TRUE, CL_MAP_READ, 0, outputSizeInBytes, 0, NULL, NULL, &err);\n        if(err) {\n            fatal(\"workDeviceOutputCopy: clEnqueueMapBuffer(#%d) failed (%d)\", gpu, err);\n        }\n\n        // get next batch of inputs\n        int outputCount = 0;\n        int useFp16 = args->fp16Inference();\n        for(; outputCount < batchSize; outputCount++) {\n            // get next item from the tag queue and check for end of input\n            int tag;\n            queueDeviceTagQ[gpu]->dequeue(tag);\n            if(tag < 0) {\n                endOfSequenceReached = true;\n                break;\n            }\n\n            // decode, scale, and format convert into the OpenCL buffer\n            void *buf;\n            if (!useFp16)\n                buf = (float *)mapped_ptr + dimOutput[0] * dimOutput[1] * dimOutput[2] * outputCount;\n            else\n                buf = (unsigned short *)mapped_ptr + dimOutput[0] * dimOutput[1] * dimOutput[2] * outputCount;\n\n            if (!detectBoundingBoxes)\n            {\n                if (topK < 1){\n                    int label = 0;\n                    if (!useFp16) {\n                        float *out = (float *)buf;\n                        float max_prob = out[0];\n                        for(int c = 1; c < dimOutput[2]; c++) {\n                            float prob = out[c];\n                            if(prob > max_prob) {\n                                label = c;\n                                max_prob = prob;\n                            }\n                        }\n                    } else {\n                        unsigned short *out = (unsigned short *)buf;\n                        float max_prob = _cvtsh_ss(out[0]);\n                        for(int c = 1; c < dimOutput[2]; c++) {\n                            float prob = _cvtsh_ss(out[c]);\n                            if(prob > max_prob) {\n                                label = c;\n                                max_prob = prob;\n                            }\n                        }\n                    }\n                    outputQ.enqueue(std::tuple<int,int>(tag,label));\n                }else {\n                    // todo:: add support for fp16\n                    std::vector<float>  prob_vec((float*)buf, (float*)buf + dimOutput[2]);\n                    std::vector<size_t> idx(prob_vec.size());\n                    std::iota(idx.begin(), idx.end(), 0);\n                    sort_indexes(prob_vec, idx);            // sort indeces based on prob\n                    std::vector<unsigned int>    labels;\n                    outputQ.enqueue(std::tuple<int,int>(tag,idx[0]));\n                    int j=0;\n                    for (auto i: idx) {\n                        // make label which is index and prob\n                        int packed_label_prob = (i&0xFFFF)|(((unsigned int)((prob_vec[i]*0x7FFF)+0.5))<<16);   // convert prob to 16bit float and store in MSBs\n                        labels.push_back(packed_label_prob);\n                        if (++j >= topK) break;\n                    }\n                    outputQTopk.enqueue(labels);\n                }\n            }else\n            {\n                std::vector<ObjectBB> detected_objects;\n                region->GetObjectDetections((float *)buf, BB_biases, dimOutput[2], dimOutput[1], dimOutput[0], BOUNDING_BOX_NUMBER_OF_CLASSES, dimInput[0], dimInput[1], BOUNDING_BOX_CONFIDENCE_THRESHHOLD, BOUNDING_BOX_NMS_THRESHHOLD, 13, detected_objects);\n                if (detected_objects.size() > 0) {\n                    // add it to outputQ\n                    outputQ.enqueue(std::tuple<int,int>(tag,detected_objects[0].label));\n                    // add detected objects with BB into BoundingBox Q\n                    OutputQBB.enqueue(detected_objects);\n                } else\n                {\n                    // add it to outputQ\n                    outputQ.enqueue(std::tuple<int,int>(tag,-1));\n                }\n            }\n        }\n\n        // unlock the OpenCL buffer to perform the writing\n        err = clEnqueueUnmapMemObject(cmdq, mem, mapped_ptr, 0, NULL, NULL);\n        if(err) {\n            fatal(\"workDeviceOutputCopy: clEnqueueMapBuffer(#%d) failed (%d)\", gpu, err);\n        }\n        err = clFinish(cmdq);\n        if(err) {\n            fatal(\"workDeviceOutputCopy: clFinish(#%d) failed (%d)\", gpu, err);\n        }\n\n        // add the output back to idle queue\n        queueDeviceOutputMemIdle[gpu]->enqueue(mem);\n        PROFILER_STOP(inference_server_app, workDeviceOutputCopy);\n\n        // update counter\n        if(outputCount > 0) {\n            totalBatchCounter++;\n            totalImageCounter += outputCount;\n        }\n    }\n\n    // release OpenCL command queue\n    clReleaseCommandQueue(cmdq);\n\n    // send end of sequence marker to next stage\n    outputQ.enqueue(std::tuple<int,int>(-1,-1));\n    args->lock();\n    info(\"workDeviceOutputCopy: GPU#%d terminated for %s [processed %d batches, %d images]\", gpu, clientName.c_str(), totalBatchCounter, totalImageCounter);\n    args->unlock();\n}\n#endif\n\nvoid InferenceEngine::dumpBuffer(cl_command_queue cmdq, cl_mem mem, std::string fileName)\n{\n    cl_int err;\n    size_t size = 0;\n    err = clGetMemObjectInfo(mem, CL_MEM_SIZE, sizeof(size), &size, NULL);\n    if(err) return;\n    unsigned char * ptr = (unsigned char *)clEnqueueMapBuffer(cmdq, mem, CL_TRUE, CL_MAP_READ, 0, size, 0, NULL, NULL, &err);\n    if(err) return;\n    err = clFinish(cmdq);\n    if(err) return;\n    FILE * fp = fopen(fileName.c_str(), \"wb\");\n    if(err) return;\n    fwrite(ptr, 1, size, fp);\n    fclose(fp);\n    err = clEnqueueUnmapMemObject(cmdq, mem, ptr, 0, NULL, NULL);\n    if(err) return;\n    err = clFinish(cmdq);\n    if(err) return;\n    printf(\"OK: dumped %ld bytes into %s\\n\", size, fileName.c_str());\n}\n",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/amd_openvx/openvx/ago/ago_platform.cpp": "/* \nCopyright (c) 2015 - 2020 Advanced Micro Devices, Inc. All rights reserved.\n \nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n \nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n \nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\n\n#include \"ago_platform.h\"\n\n// macro to port VisualStudio __cpuid to g++\n#if !_WIN32\n#define __cpuid(out, infoType) asm(\"cpuid\": \"=a\" (out[0]), \"=b\" (out[1]), \"=c\" (out[2]), \"=d\" (out[3]): \"a\" (infoType));\n#endif\n\n#if _WIN32 && ENABLE_OPENCL\n#pragma comment(lib, \"OpenCL.lib\")\n#endif\n\nbool agoIsCpuHardwareSupported()\n{\n\tbool isHardwareSupported = false;\n\tint CPUInfo[4] = { -1 };\n\t__cpuid(CPUInfo, 0);\n\tif (CPUInfo[0] > 1) {\n\t\t__cpuid(CPUInfo, 1);\n\t\t// check for SSE4.2 support\n\t\tif (CPUInfo[2] & 0x100000)\n\t\t\tisHardwareSupported = true;\n\t}\n\treturn isHardwareSupported;\n}\n\nuint32_t agoControlFpSetRoundEven()\n{\n\tuint32_t state;\n#if _WIN32\n\tstate = _controlfp(0, 0);\n\t_controlfp(_RC_NEAR, _MCW_RC); // round to nearest even: RC_CHOP gives matching output with sample code\n\treturn state;\n#else\n\tstate = fegetround();\n\tfesetround(FE_TONEAREST);\n#endif\n\treturn state;\n}\n\nvoid agoControlFpReset(uint32_t state)\n{\n#if _WIN32\n\t_controlfp(state, _MCW_RC);\n#else\n\tfesetround(state);\n#endif\n}\n\nbool agoGetEnvironmentVariable(const char * name, char * value, size_t valueSize)\n{\n#if _WIN32\n\tDWORD len = GetEnvironmentVariableA(name, value, (DWORD)valueSize);\n\tvalue[valueSize-1] = 0;\n\treturn (len > 0) ? true : false;\n#else\n\tconst char * v = getenv(name);\n\tif (v) {\n\t\tstrncpy(value, v, valueSize);\n\t\tvalue[valueSize-1] = 0;\n\t}\n\treturn v ? true : false;\n#endif\n}\n\nago_module agoOpenModule(const char * libFileName)\n{\n#if _WIN32\n\treturn (ago_module)LoadLibraryA(libFileName);\n#else\n\treturn (ago_module) dlopen(libFileName, RTLD_NOW | RTLD_LOCAL);\n#endif\n}\n\nvoid * agoGetFunctionAddress(ago_module module, const char * functionName)\n{\n#if _WIN32\n\treturn GetProcAddress((HMODULE)module, functionName);\n#else\n\treturn dlsym(module, functionName);\n#endif\n}\n\nvoid agoCloseModule(ago_module module)\n{\n#if _WIN32\n\tFreeLibrary((HMODULE)module);\n#else\n\tdlclose(module);\n#endif\n}\n\nint64_t agoGetClockCounter()\n{\n#if _WIN32\n\tLARGE_INTEGER v;\n\tQueryPerformanceCounter(&v);\n\treturn v.QuadPart;\n#else\n\treturn chrono::high_resolution_clock::now().time_since_epoch().count();\n#endif\n}\n\nint64_t agoGetClockFrequency()\n{\n#if _WIN32\n\tLARGE_INTEGER v;\n\tQueryPerformanceFrequency(&v);\n\treturn v.QuadPart;\n#else\n\treturn chrono::high_resolution_clock::period::den / chrono::high_resolution_clock::period::num;\n#endif\n}\n\n#if !_WIN32\n#include \"ago_internal.h\"\n\n#include <mutex>\n#include <condition_variable>\n#include <fenv.h>\n#include <dlfcn.h>\n\n#define VX_SEMAPHORE    1\n#define VX_THREAD       2\n#define VX_CRITICAL_SECTION       3\n\ntypedef struct {\n\tint type; // should be VX_SEMAPHORE\n\tint count;\n\tmutex mtx;\n\tcondition_variable cv;\n} vx_semaphore;\n\ntypedef struct {\n    int type;   // should be VX_THREAD\n    thread thread_obj;\n    void* thread_param;\n} vx_thread;\n\ntypedef struct {\n    int type;   // should be VX_CRITICAL_SECTION\n    mutex mtx;\n} vx_critical_section;\n\n\n// Emulates EnterCriticalSection for non_windows platform\nvoid EnterCriticalSection(CRITICAL_SECTION* cs)\n{\n    vx_critical_section * crit_sec = (vx_critical_section *)*cs;\n    std::lock_guard<std::mutex> lock(crit_sec->mtx);\n}\n\n// Emulates LeaveCriticalSection for non_windows platform\nvoid LeaveCriticalSection(CRITICAL_SECTION* cs)\n{\n    vx_critical_section * crit_sec = (vx_critical_section *)*cs;\n    crit_sec->mtx.unlock();\n}\n\n// Emulates InitializeCriticalSection for non_windows platform\nvoid InitializeCriticalSection(CRITICAL_SECTION* cs)\n{\n    vx_critical_section *crit_sec = new vx_critical_section;\n    crit_sec->type = VX_CRITICAL_SECTION;\n    *cs = crit_sec;\n}\n\n// Emulates DeleteCriticalSection for non_windows platform\nvoid DeleteCriticalSection(CRITICAL_SECTION* cs)\n{\n    vx_critical_section * crit_sec = (vx_critical_section *)*cs;\n    crit_sec->type = 0;\n    delete crit_sec;\n}\n\nHANDLE CreateSemaphore(void *, LONG, LONG, void *)\n{\n\tvx_semaphore * sem = new vx_semaphore;\n\tsem->type = VX_SEMAPHORE;\n\tsem->count = 0;\n\treturn sem;\n}\n\nHANDLE CreateThread(void *, size_t dwStackSize, LPTHREAD_START_ROUTINE lpStartAddress, LPVOID lpParameter, DWORD dwCreationFlags, void *)\n{\n    vx_thread *thd = new vx_thread;\n    thd->type = VX_THREAD;\n    thd->thread_obj = thread(lpStartAddress, lpParameter);\n    return thd;\n}\n\nvoid CloseHandle(HANDLE h)\n{\n\tif(h) {\n\t\tif(*(int*)h == VX_SEMAPHORE) {\n\t\t\tvx_semaphore * sem = (vx_semaphore *)h;\n\t\t\tsem->type = 0;\n\t\t\tdelete sem;\n\t\t}\n\t\telse if(*(int*)h == VX_THREAD) {\n            vx_thread * th = (vx_thread *)h;\n            th->type = 0;\n            th->thread_obj.join();\n            delete th;\n        }\n\t}\n}\nDWORD WaitForSingleObject(HANDLE h, DWORD dwMilliseconds)\n{\n\tif(h) {\n\t\tif(*(int*)h == VX_SEMAPHORE) {\n\t\t\tvx_semaphore * sem = (vx_semaphore *)h;\n\t\t\t{\n\t\t\t\tunique_lock<mutex> lk(sem->mtx);\n\t\t\t\tsem->cv.wait(lk); // TBD: implement with timeout\n\t\t\t}\n\t\t\t{\n\t\t\t\tlock_guard<mutex> lk(sem->mtx);\n\t\t\t\tsem->count--;\n\t\t\t}\n\t\t}\n    } else\n    {\n        printf(\"Invalid Handle for WaitObject\\n\");\n        return -1;\n    }\n\treturn 0;\n}\n\nBOOL ReleaseSemaphore(HANDLE h, LONG lReleaseCount, LPLONG lpPreviousCount)\n{\n\tif(h) {\n\t\tif(*(int*)h == VX_SEMAPHORE) {\n\t\t\tvx_semaphore * sem = (vx_semaphore *)h;\n\t\t\t{\n\t\t\t\tlock_guard<mutex> lk(sem->mtx);\n\t\t\t\tif(lpPreviousCount) *lpPreviousCount = sem->count;\n\t\t\t\tsem->count += lReleaseCount;\n\t\t\t}\n\t\t\tfor(LONG i = 0; i < lReleaseCount; i++) {\n\t\t\t\tsem->cv.notify_one();\n\t\t\t}\n\t\t}\n    } else\n    {\n        printf(\"Invalid Handle for Semaphore\\n\");\n        return 0;\n    }\n    return 1;\n}\n\n#endif\n"
    },
    "skipped": [
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/toolkit/analysis_and_visualization/bounding_box/icons/small_amd_logo.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/toolkit/analysis_and_visualization/bounding_box/icons/GitHub_logo_white.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/toolkit/analysis_and_visualization/bounding_box/icons/small_radeon_logo.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/toolkit/analysis_and_visualization/bounding_box/icons/AMD_logo_white.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/toolkit/analysis_and_visualization/bounding_box/icons/vega_icon_200.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/toolkit/analysis_and_visualization/bounding_box/icons/amd-logo-150x150.jpg",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/toolkit/analysis_and_visualization/bounding_box/icons/AIToolKit_400x90.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/toolkit/analysis_and_visualization/bounding_box/icons/ADAT_500x100.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/toolkit/analysis_and_visualization/bounding_box/icons/display_panel_logo.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/toolkit/analysis_and_visualization/bounding_box/icons/inference_app_splash.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/toolkit/analysis_and_visualization/bounding_box/icons/vega_icon_150.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/toolkit/analysis_and_visualization/bounding_box/icons/sampleOutput.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/toolkit/analysis_and_visualization/bounding_box/icons/vega_icon_250.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/toolkit/analysis_and_visualization/bounding_box/icons/small_github_logo.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/toolkit/analysis_and_visualization/classification/icons/small_amd_logo.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/toolkit/analysis_and_visualization/classification/icons/GitHub_logo_white.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/toolkit/analysis_and_visualization/classification/icons/small_radeon_logo.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/toolkit/analysis_and_visualization/classification/icons/AMD_logo_white.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/toolkit/analysis_and_visualization/classification/icons/vega_icon_200.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/toolkit/analysis_and_visualization/classification/icons/amd-logo-150x150.jpg",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/toolkit/analysis_and_visualization/classification/icons/AIToolKit_400x90.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/toolkit/analysis_and_visualization/classification/icons/ADAT_500x100.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/toolkit/analysis_and_visualization/classification/icons/display_panel_logo.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/toolkit/analysis_and_visualization/classification/icons/inference_app_splash.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/toolkit/analysis_and_visualization/classification/icons/vega_icon_150.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/toolkit/analysis_and_visualization/classification/icons/vega_icon_250.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/toolkit/analysis_and_visualization/classification/icons/small_github_logo.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0062.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0171.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0021.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0202.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0206.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0139.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0166.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0120.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0229.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0028.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0253.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0044.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0220.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0076.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0019.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0184.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0242.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0111.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0026.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0095.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0016.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0039.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0097.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0140.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0211.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0045.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0125.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0034.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0017.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0221.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0218.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0128.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0248.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0055.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0246.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0194.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0105.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0073.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0244.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0109.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0163.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0083.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0188.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0216.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0033.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0046.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0237.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0183.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0224.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0208.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0124.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0084.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0181.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0029.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0176.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0243.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0000.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0177.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0122.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0143.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0149.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0135.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0219.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0136.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0077.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0117.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0104.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0161.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0065.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0071.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0052.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0004.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0006.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0022.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0020.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0007.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0121.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0093.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0241.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0195.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0155.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0137.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0153.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0240.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0234.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0191.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0012.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0187.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0041.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0167.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0225.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0199.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0249.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0107.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0251.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0170.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0089.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0040.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0156.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0110.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0054.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0146.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0098.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0154.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0213.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0072.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0042.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0196.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0215.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0158.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0049.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0245.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0053.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0148.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0011.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0018.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0189.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0015.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0131.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0068.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0066.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0059.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0178.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0186.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0027.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0231.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0037.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0223.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0060.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0078.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0032.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0239.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0090.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0047.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0205.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0192.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0082.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0081.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0079.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0247.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0150.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0250.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0236.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0232.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0092.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0025.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0061.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0172.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0210.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0101.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0118.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0209.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0254.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0165.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0091.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0160.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0103.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0074.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0048.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0207.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0130.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0051.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0030.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0127.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0152.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0031.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0200.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0050.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0255.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0023.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0132.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0222.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0134.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0151.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0193.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0003.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0138.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0057.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0174.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0005.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0227.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0063.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0126.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0185.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0157.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0147.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0133.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0067.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0100.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0008.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0058.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0203.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0169.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0013.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0226.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0075.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0198.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0141.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0069.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0087.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0214.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0238.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0180.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0108.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0168.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0230.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0175.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0173.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0252.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0009.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0182.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0123.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0112.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0024.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0197.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0002.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0228.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0129.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0212.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0080.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0096.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0035.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0014.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0233.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0164.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0162.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0085.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0116.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0038.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0102.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0086.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0142.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0204.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0064.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0043.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0179.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0190.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0113.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0094.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0001.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0114.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0201.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0088.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0119.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0056.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0036.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0115.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0106.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0070.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0235.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0144.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0217.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0145.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0159.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0010.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-tinyDataSet/AMD-tinyDataSet_0099.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0047.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0037.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0092.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0042.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0001.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0100.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0094.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0029.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0009.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0093.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0049.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0068.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0062.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0038.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0030.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0034.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0086.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0044.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0082.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0032.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0058.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0014.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0069.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0028.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0054.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0064.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0075.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0055.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0090.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0050.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0024.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0073.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0057.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0041.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0053.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0059.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0019.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0076.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0045.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0006.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0002.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0096.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0078.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0097.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0005.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0043.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0085.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0084.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0071.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0048.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0033.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0081.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0017.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0066.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0000.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0089.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0020.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0061.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0027.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0016.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0056.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0010.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0088.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0039.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0004.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0091.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0070.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0067.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0025.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0035.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0099.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0052.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0007.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0080.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0031.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0072.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0079.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0003.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0015.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0013.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0083.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0008.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0087.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0060.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0098.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0018.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0065.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0012.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0051.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0063.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0023.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0074.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0021.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0095.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0036.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0077.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0046.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0022.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0011.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0026.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/images/AMD-dataSet-416X416/resize_416x416_0040.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/data/videos/AMD_driving_virtual_20.mp4",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/apps/mivisionx_inference_analyzer/data/images/model.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/apps/mivisionx_inference_analyzer/data/images/MIVisionX-logo.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/apps/mivisionx_inference_analyzer/data/images/rocm_logo.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/apps/mivisionx_inference_analyzer/data/images/AMD Radeon.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/apps/mivisionx_inference_analyzer/data/images/model_icon.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/apps/mivisionx_inference_analyzer/data/images/inference_icon.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/apps/mivisionx_inference_analyzer/data/images/EPYC-blue.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/apps/dg_test/data/weights.bin",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/apps/cloud_inference/client_app/images/small_amd_logo.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/apps/cloud_inference/client_app/images/small_radeon_logo.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/apps/cloud_inference/client_app/images/AMD_logo_white.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/apps/cloud_inference/client_app/images/vega_icon_200.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/apps/cloud_inference/client_app/images/rocm_logo.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/apps/cloud_inference/client_app/images/amd-logo-150x150.jpg",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/apps/cloud_inference/client_app/images/display_panel_logo.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/apps/cloud_inference/client_app/images/inference_app_splash.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/apps/cloud_inference/client_app/images/vega_icon_150.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/apps/cloud_inference/client_app/images/vega_icon_250.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/apps/mivisionx_winml_classifier/images/MIVisionX-ImageClassification-WinML.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/apps/mivisionx_winml_classifier/images/MIVisionX-ImageClassification.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/apps/mivisionx_validation_tool/data/images/inference_analyzer.gif",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/apps/mivisionx_validation_tool/data/images/AMD_Radeon-white.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/apps/mivisionx_validation_tool/data/images/model.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/apps/mivisionx_validation_tool/data/images/MIVisionX-logo-white.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/apps/mivisionx_validation_tool/data/images/Graph-image-white.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/apps/mivisionx_validation_tool/data/images/RALI.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/apps/mivisionx_validation_tool/data/images/MIVisionX-logo.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/apps/mivisionx_validation_tool/data/images/rocm_logo.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/apps/mivisionx_validation_tool/data/images/filmStrip.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/apps/mivisionx_validation_tool/data/images/Docker.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/apps/mivisionx_validation_tool/data/images/RALI-white.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/apps/mivisionx_validation_tool/data/images/EPYC-blue-white.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/apps/mivisionx_validation_tool/data/images/model_icon.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/apps/mivisionx_validation_tool/data/images/Singularity.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/apps/mivisionx_validation_tool/data/images/inference_icon.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/apps/mivisionx_validation_tool/data/images/Graph-image.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/apps/mivisionx_validation_tool/data/images/EPYC-blue.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/apps/mivisionx_validation_tool/data/images/AMD_Radeon.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/apps/mivisionx_winml_yolov2/image/cat-yolo.jpg",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/apps/mivisionx_winml_yolov2/image/person.jpg",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/apps/mivisionx_winml_yolov2/image/cat.jpg",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/apps/mivisionx_winml_yolov2/image/bicycle.jpg",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/apps/bubble_pop/image/b20.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/amd_openvx_extensions/amd_winml/utilities/MIVisionX-WinML-Validate/sample/car.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/amd_openvx_extensions/amd_winml/samples/data/vgg16_results.PNG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/amd_openvx_extensions/amd_winml/samples/data/emotions_results.PNG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/amd_openvx_extensions/amd_winml/samples/data/squeezenet_results.PNG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/amd_openvx_extensions/amd_winml/samples/data/dog.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/amd_openvx_extensions/amd_winml/samples/data/bird.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/amd_openvx_extensions/amd_winml/samples/data/car.JPEG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/samples/images/face1.jpg",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/samples/images/canny_image.PNG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/samples/images/face.jpg",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/samples/images/skinToneDetect_image.PNG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/samples/model_compiler_samples/images/detection_display.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/samples/model_compiler_samples/images/squeezenet_legend.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/samples/model_compiler_samples/images/segmentation_legend.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/samples/model_compiler_samples/images/flow-3-openvx-b.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/samples/model_compiler_samples/images/flow-3-openvx-a.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/samples/model_compiler_samples/images/detection_legend.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/samples/model_compiler_samples/images/app_display.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/samples/model_compiler_samples/images/flow-1-model.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/samples/model_compiler_samples/images/squeezenet_display.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/samples/model_compiler_samples/images/app-control.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/samples/model_compiler_samples/images/flow-2-nnir.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/samples/model_compiler_samples/data/images/img_01.JPG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/samples/model_compiler_samples/data/images/img_03.JPG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/samples/model_compiler_samples/data/images/img_05.JPG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/samples/model_compiler_samples/data/images/img_04.JPG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/samples/model_compiler_samples/data/images/img_02.JPG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/samples/inference/mv_objdetect/data/images/img_04.JPG",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/samples/inference/mv_objdetect/data/images/Video_4_screenshot.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/analyzer-1.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/bounding_box_graph.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/LOOM_LOGO_250X125.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/winmlFrameWorks.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/modelTrainedFrameWorks.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/loom-2.jpg",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/MIVisionX-OpenVX-Extensions.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/vx-pop-app.gif",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/inference_analyzer.gif",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/block_diagram_inference_workflow.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/loom-4.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/modelCompilerWorkflow.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/sample-1-4.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/mivisionx_openvx_classifier_classifier.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/loom-3.jpg",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/validation-1.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/sample-1-5.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/sample-1-3.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/client_app.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/sample-2-1.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/frameworks.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/classification_graph.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/client_app_1.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/loom-1.jpg",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/dg_test_sample.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/sample-1-1.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/mivisionx_openvx_classifier_imageClassification.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/MIVisionX-applications.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/client_app-3.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/client_app_2.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/analyzer-2.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/MIVisionX.bmp",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/modelCompilerFrameWorks.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/image_augmentation.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/DGtest.gif",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/sample-3-1.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/sample-1-2.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/bounding_box_summary.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/analyzer-4.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/sample-3-2.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/analyzer-3.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/validation-2.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/runtime.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/sample-2-2.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/classification_summary.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/NetFlow.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/inferenceVideo.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/block_diagram_inference_sample.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/MIVisionX.png",
        "/tmp/vanessa/spack-stage/spack-stage-mivisionx-3.7.0-yooeqjapmhnjc56hlnvlv3okjah4csme/spack-src/docs/images/winmlRuntime.png"
    ],
    "total_files": 1695
}