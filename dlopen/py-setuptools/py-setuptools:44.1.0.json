{
    "matches": {
        "/tmp/vanessa/spack-stage/spack-stage-py-setuptools-44.1.0-x2oqqwegszantfph3vyt5qy3hkqvctxw/spack-src/setuptools/_vendor/packaging/tags.py": "# This file is dual licensed under the terms of the Apache License, Version\n# 2.0, and the BSD License. See the LICENSE file in the root of this repository\n# for complete details.\n\nfrom __future__ import absolute_import\n\nimport distutils.util\n\ntry:\n    from importlib.machinery import EXTENSION_SUFFIXES\nexcept ImportError:  # pragma: no cover\n    import imp\n\n    EXTENSION_SUFFIXES = [x[0] for x in imp.get_suffixes()]\n    del imp\nimport platform\nimport re\nimport sys\nimport sysconfig\nimport warnings\n\n\nINTERPRETER_SHORT_NAMES = {\n    \"python\": \"py\",  # Generic.\n    \"cpython\": \"cp\",\n    \"pypy\": \"pp\",\n    \"ironpython\": \"ip\",\n    \"jython\": \"jy\",\n}\n\n\n_32_BIT_INTERPRETER = sys.maxsize <= 2 ** 32\n\n\nclass Tag(object):\n\n    __slots__ = [\"_interpreter\", \"_abi\", \"_platform\"]\n\n    def __init__(self, interpreter, abi, platform):\n        self._interpreter = interpreter.lower()\n        self._abi = abi.lower()\n        self._platform = platform.lower()\n\n    @property\n    def interpreter(self):\n        return self._interpreter\n\n    @property\n    def abi(self):\n        return self._abi\n\n    @property\n    def platform(self):\n        return self._platform\n\n    def __eq__(self, other):\n        return (\n            (self.platform == other.platform)\n            and (self.abi == other.abi)\n            and (self.interpreter == other.interpreter)\n        )\n\n    def __hash__(self):\n        return hash((self._interpreter, self._abi, self._platform))\n\n    def __str__(self):\n        return \"{}-{}-{}\".format(self._interpreter, self._abi, self._platform)\n\n    def __repr__(self):\n        return \"<{self} @ {self_id}>\".format(self=self, self_id=id(self))\n\n\ndef parse_tag(tag):\n    tags = set()\n    interpreters, abis, platforms = tag.split(\"-\")\n    for interpreter in interpreters.split(\".\"):\n        for abi in abis.split(\".\"):\n            for platform_ in platforms.split(\".\"):\n                tags.add(Tag(interpreter, abi, platform_))\n    return frozenset(tags)\n\n\ndef _normalize_string(string):\n    return string.replace(\".\", \"_\").replace(\"-\", \"_\")\n\n\ndef _cpython_interpreter(py_version):\n    # TODO: Is using py_version_nodot for interpreter version critical?\n    return \"cp{major}{minor}\".format(major=py_version[0], minor=py_version[1])\n\n\ndef _cpython_abis(py_version):\n    abis = []\n    version = \"{}{}\".format(*py_version[:2])\n    debug = pymalloc = ucs4 = \"\"\n    with_debug = sysconfig.get_config_var(\"Py_DEBUG\")\n    has_refcount = hasattr(sys, \"gettotalrefcount\")\n    # Windows doesn't set Py_DEBUG, so checking for support of debug-compiled\n    # extension modules is the best option.\n    # https://github.com/pypa/pip/issues/3383#issuecomment-173267692\n    has_ext = \"_d.pyd\" in EXTENSION_SUFFIXES\n    if with_debug or (with_debug is None and (has_refcount or has_ext)):\n        debug = \"d\"\n    if py_version < (3, 8):\n        with_pymalloc = sysconfig.get_config_var(\"WITH_PYMALLOC\")\n        if with_pymalloc or with_pymalloc is None:\n            pymalloc = \"m\"\n        if py_version < (3, 3):\n            unicode_size = sysconfig.get_config_var(\"Py_UNICODE_SIZE\")\n            if unicode_size == 4 or (\n                unicode_size is None and sys.maxunicode == 0x10FFFF\n            ):\n                ucs4 = \"u\"\n    elif debug:\n        # Debug builds can also load \"normal\" extension modules.\n        # We can also assume no UCS-4 or pymalloc requirement.\n        abis.append(\"cp{version}\".format(version=version))\n    abis.insert(\n        0,\n        \"cp{version}{debug}{pymalloc}{ucs4}\".format(\n            version=version, debug=debug, pymalloc=pymalloc, ucs4=ucs4\n        ),\n    )\n    return abis\n\n\ndef _cpython_tags(py_version, interpreter, abis, platforms):\n    for abi in abis:\n        for platform_ in platforms:\n            yield Tag(interpreter, abi, platform_)\n    for tag in (Tag(interpreter, \"abi3\", platform_) for platform_ in platforms):\n        yield tag\n    for tag in (Tag(interpreter, \"none\", platform_) for platform_ in platforms):\n        yield tag\n    # PEP 384 was first implemented in Python 3.2.\n    for minor_version in range(py_version[1] - 1, 1, -1):\n        for platform_ in platforms:\n            interpreter = \"cp{major}{minor}\".format(\n                major=py_version[0], minor=minor_version\n            )\n            yield Tag(interpreter, \"abi3\", platform_)\n\n\ndef _pypy_interpreter():\n    return \"pp{py_major}{pypy_major}{pypy_minor}\".format(\n        py_major=sys.version_info[0],\n        pypy_major=sys.pypy_version_info.major,\n        pypy_minor=sys.pypy_version_info.minor,\n    )\n\n\ndef _generic_abi():\n    abi = sysconfig.get_config_var(\"SOABI\")\n    if abi:\n        return _normalize_string(abi)\n    else:\n        return \"none\"\n\n\ndef _pypy_tags(py_version, interpreter, abi, platforms):\n    for tag in (Tag(interpreter, abi, platform) for platform in platforms):\n        yield tag\n    for tag in (Tag(interpreter, \"none\", platform) for platform in platforms):\n        yield tag\n\n\ndef _generic_tags(interpreter, py_version, abi, platforms):\n    for tag in (Tag(interpreter, abi, platform) for platform in platforms):\n        yield tag\n    if abi != \"none\":\n        tags = (Tag(interpreter, \"none\", platform_) for platform_ in platforms)\n        for tag in tags:\n            yield tag\n\n\ndef _py_interpreter_range(py_version):\n    \"\"\"\n    Yield Python versions in descending order.\n\n    After the latest version, the major-only version will be yielded, and then\n    all following versions up to 'end'.\n    \"\"\"\n    yield \"py{major}{minor}\".format(major=py_version[0], minor=py_version[1])\n    yield \"py{major}\".format(major=py_version[0])\n    for minor in range(py_version[1] - 1, -1, -1):\n        yield \"py{major}{minor}\".format(major=py_version[0], minor=minor)\n\n\ndef _independent_tags(interpreter, py_version, platforms):\n    \"\"\"\n    Return the sequence of tags that are consistent across implementations.\n\n    The tags consist of:\n    - py*-none-<platform>\n    - <interpreter>-none-any\n    - py*-none-any\n    \"\"\"\n    for version in _py_interpreter_range(py_version):\n        for platform_ in platforms:\n            yield Tag(version, \"none\", platform_)\n    yield Tag(interpreter, \"none\", \"any\")\n    for version in _py_interpreter_range(py_version):\n        yield Tag(version, \"none\", \"any\")\n\n\ndef _mac_arch(arch, is_32bit=_32_BIT_INTERPRETER):\n    if not is_32bit:\n        return arch\n\n    if arch.startswith(\"ppc\"):\n        return \"ppc\"\n\n    return \"i386\"\n\n\ndef _mac_binary_formats(version, cpu_arch):\n    formats = [cpu_arch]\n    if cpu_arch == \"x86_64\":\n        if version < (10, 4):\n            return []\n        formats.extend([\"intel\", \"fat64\", \"fat32\"])\n\n    elif cpu_arch == \"i386\":\n        if version < (10, 4):\n            return []\n        formats.extend([\"intel\", \"fat32\", \"fat\"])\n\n    elif cpu_arch == \"ppc64\":\n        # TODO: Need to care about 32-bit PPC for ppc64 through 10.2?\n        if version > (10, 5) or version < (10, 4):\n            return []\n        formats.append(\"fat64\")\n\n    elif cpu_arch == \"ppc\":\n        if version > (10, 6):\n            return []\n        formats.extend([\"fat32\", \"fat\"])\n\n    formats.append(\"universal\")\n    return formats\n\n\ndef _mac_platforms(version=None, arch=None):\n    version_str, _, cpu_arch = platform.mac_ver()\n    if version is None:\n        version = tuple(map(int, version_str.split(\".\")[:2]))\n    if arch is None:\n        arch = _mac_arch(cpu_arch)\n    platforms = []\n    for minor_version in range(version[1], -1, -1):\n        compat_version = version[0], minor_version\n        binary_formats = _mac_binary_formats(compat_version, arch)\n        for binary_format in binary_formats:\n            platforms.append(\n                \"macosx_{major}_{minor}_{binary_format}\".format(\n                    major=compat_version[0],\n                    minor=compat_version[1],\n                    binary_format=binary_format,\n                )\n            )\n    return platforms\n\n\n# From PEP 513.\ndef _is_manylinux_compatible(name, glibc_version):\n    # Check for presence of _manylinux module.\n    try:\n        import _manylinux\n\n        return bool(getattr(_manylinux, name + \"_compatible\"))\n    except (ImportError, AttributeError):\n        # Fall through to heuristic check below.\n        pass\n\n    return _have_compatible_glibc(*glibc_version)\n\n\ndef _glibc_version_string():\n    # Returns glibc version string, or None if not using glibc.\n    import ctypes\n\n    # ctypes.CDLL(None) internally calls dlopen(NULL), and as the dlopen\n    # manpage says, \"If filename is NULL, then the returned handle is for the\n    # main program\". This way we can let the linker do the work to figure out\n    # which libc our process is actually using.\n    process_namespace = ctypes.CDLL(None)\n    try:\n        gnu_get_libc_version = process_namespace.gnu_get_libc_version\n    except AttributeError:\n        # Symbol doesn't exist -> therefore, we are not linked to\n        # glibc.\n        return None\n\n    # Call gnu_get_libc_version, which returns a string like \"2.5\"\n    gnu_get_libc_version.restype = ctypes.c_char_p\n    version_str = gnu_get_libc_version()\n    # py2 / py3 compatibility:\n    if not isinstance(version_str, str):\n        version_str = version_str.decode(\"ascii\")\n\n    return version_str\n\n\n# Separated out from have_compatible_glibc for easier unit testing.\ndef _check_glibc_version(version_str, required_major, minimum_minor):\n    # Parse string and check against requested version.\n    #\n    # We use a regexp instead of str.split because we want to discard any\n    # random junk that might come after the minor version -- this might happen\n    # in patched/forked versions of glibc (e.g. Linaro's version of glibc\n    # uses version strings like \"2.20-2014.11\"). See gh-3588.\n    m = re.match(r\"(?P<major>[0-9]+)\\.(?P<minor>[0-9]+)\", version_str)\n    if not m:\n        warnings.warn(\n            \"Expected glibc version with 2 components major.minor,\"\n            \" got: %s\" % version_str,\n            RuntimeWarning,\n        )\n        return False\n    return (\n        int(m.group(\"major\")) == required_major\n        and int(m.group(\"minor\")) >= minimum_minor\n    )\n\n\ndef _have_compatible_glibc(required_major, minimum_minor):\n    version_str = _glibc_version_string()\n    if version_str is None:\n        return False\n    return _check_glibc_version(version_str, required_major, minimum_minor)\n\n\ndef _linux_platforms(is_32bit=_32_BIT_INTERPRETER):\n    linux = _normalize_string(distutils.util.get_platform())\n    if linux == \"linux_x86_64\" and is_32bit:\n        linux = \"linux_i686\"\n    manylinux_support = (\n        (\"manylinux2014\", (2, 17)),  # CentOS 7 w/ glibc 2.17 (PEP 599)\n        (\"manylinux2010\", (2, 12)),  # CentOS 6 w/ glibc 2.12 (PEP 571)\n        (\"manylinux1\", (2, 5)),  # CentOS 5 w/ glibc 2.5 (PEP 513)\n    )\n    manylinux_support_iter = iter(manylinux_support)\n    for name, glibc_version in manylinux_support_iter:\n        if _is_manylinux_compatible(name, glibc_version):\n            platforms = [linux.replace(\"linux\", name)]\n            break\n    else:\n        platforms = []\n    # Support for a later manylinux implies support for an earlier version.\n    platforms += [linux.replace(\"linux\", name) for name, _ in manylinux_support_iter]\n    platforms.append(linux)\n    return platforms\n\n\ndef _generic_platforms():\n    platform = _normalize_string(distutils.util.get_platform())\n    return [platform]\n\n\ndef _interpreter_name():\n    name = platform.python_implementation().lower()\n    return INTERPRETER_SHORT_NAMES.get(name) or name\n\n\ndef _generic_interpreter(name, py_version):\n    version = sysconfig.get_config_var(\"py_version_nodot\")\n    if not version:\n        version = \"\".join(map(str, py_version[:2]))\n    return \"{name}{version}\".format(name=name, version=version)\n\n\ndef sys_tags():\n    \"\"\"\n    Returns the sequence of tag triples for the running interpreter.\n\n    The order of the sequence corresponds to priority order for the\n    interpreter, from most to least important.\n    \"\"\"\n    py_version = sys.version_info[:2]\n    interpreter_name = _interpreter_name()\n    if platform.system() == \"Darwin\":\n        platforms = _mac_platforms()\n    elif platform.system() == \"Linux\":\n        platforms = _linux_platforms()\n    else:\n        platforms = _generic_platforms()\n\n    if interpreter_name == \"cp\":\n        interpreter = _cpython_interpreter(py_version)\n        abis = _cpython_abis(py_version)\n        for tag in _cpython_tags(py_version, interpreter, abis, platforms):\n            yield tag\n    elif interpreter_name == \"pp\":\n        interpreter = _pypy_interpreter()\n        abi = _generic_abi()\n        for tag in _pypy_tags(py_version, interpreter, abi, platforms):\n            yield tag\n    else:\n        interpreter = _generic_interpreter(interpreter_name, py_version)\n        abi = _generic_abi()\n        for tag in _generic_tags(interpreter, py_version, abi, platforms):\n            yield tag\n    for tag in _independent_tags(interpreter, py_version, platforms):\n        yield tag\n",
        "/tmp/vanessa/spack-stage/spack-stage-py-setuptools-44.1.0-x2oqqwegszantfph3vyt5qy3hkqvctxw/spack-src/setuptools/command/build_ext.py": "import os\nimport sys\nimport itertools\nfrom distutils.command.build_ext import build_ext as _du_build_ext\nfrom distutils.file_util import copy_file\nfrom distutils.ccompiler import new_compiler\nfrom distutils.sysconfig import customize_compiler, get_config_var\nfrom distutils.errors import DistutilsError\nfrom distutils import log\n\nfrom setuptools.extension import Library\nfrom setuptools.extern import six\n\nif six.PY2:\n    import imp\n\n    EXTENSION_SUFFIXES = [s for s, _, tp in imp.get_suffixes() if tp == imp.C_EXTENSION]\nelse:\n    from importlib.machinery import EXTENSION_SUFFIXES\n\ntry:\n    # Attempt to use Cython for building extensions, if available\n    from Cython.Distutils.build_ext import build_ext as _build_ext\n    # Additionally, assert that the compiler module will load\n    # also. Ref #1229.\n    __import__('Cython.Compiler.Main')\nexcept ImportError:\n    _build_ext = _du_build_ext\n\n# make sure _config_vars is initialized\nget_config_var(\"LDSHARED\")\nfrom distutils.sysconfig import _config_vars as _CONFIG_VARS\n\n\ndef _customize_compiler_for_shlib(compiler):\n    if sys.platform == \"darwin\":\n        # building .dylib requires additional compiler flags on OSX; here we\n        # temporarily substitute the pyconfig.h variables so that distutils'\n        # 'customize_compiler' uses them before we build the shared libraries.\n        tmp = _CONFIG_VARS.copy()\n        try:\n            # XXX Help!  I don't have any idea whether these are right...\n            _CONFIG_VARS['LDSHARED'] = (\n                \"gcc -Wl,-x -dynamiclib -undefined dynamic_lookup\")\n            _CONFIG_VARS['CCSHARED'] = \" -dynamiclib\"\n            _CONFIG_VARS['SO'] = \".dylib\"\n            customize_compiler(compiler)\n        finally:\n            _CONFIG_VARS.clear()\n            _CONFIG_VARS.update(tmp)\n    else:\n        customize_compiler(compiler)\n\n\nhave_rtld = False\nuse_stubs = False\nlibtype = 'shared'\n\nif sys.platform == \"darwin\":\n    use_stubs = True\nelif os.name != 'nt':\n    try:\n        import dl\n        use_stubs = have_rtld = hasattr(dl, 'RTLD_NOW')\n    except ImportError:\n        pass\n\nif_dl = lambda s: s if have_rtld else ''\n\n\ndef get_abi3_suffix():\n    \"\"\"Return the file extension for an abi3-compliant Extension()\"\"\"\n    for suffix in EXTENSION_SUFFIXES:\n        if '.abi3' in suffix:  # Unix\n            return suffix\n        elif suffix == '.pyd':  # Windows\n            return suffix\n\n\nclass build_ext(_build_ext):\n    def run(self):\n        \"\"\"Build extensions in build directory, then copy if --inplace\"\"\"\n        old_inplace, self.inplace = self.inplace, 0\n        _build_ext.run(self)\n        self.inplace = old_inplace\n        if old_inplace:\n            self.copy_extensions_to_source()\n\n    def copy_extensions_to_source(self):\n        build_py = self.get_finalized_command('build_py')\n        for ext in self.extensions:\n            fullname = self.get_ext_fullname(ext.name)\n            filename = self.get_ext_filename(fullname)\n            modpath = fullname.split('.')\n            package = '.'.join(modpath[:-1])\n            package_dir = build_py.get_package_dir(package)\n            dest_filename = os.path.join(package_dir,\n                                         os.path.basename(filename))\n            src_filename = os.path.join(self.build_lib, filename)\n\n            # Always copy, even if source is older than destination, to ensure\n            # that the right extensions for the current Python/platform are\n            # used.\n            copy_file(\n                src_filename, dest_filename, verbose=self.verbose,\n                dry_run=self.dry_run\n            )\n            if ext._needs_stub:\n                self.write_stub(package_dir or os.curdir, ext, True)\n\n    def get_ext_filename(self, fullname):\n        filename = _build_ext.get_ext_filename(self, fullname)\n        if fullname in self.ext_map:\n            ext = self.ext_map[fullname]\n            use_abi3 = (\n                not six.PY2\n                and getattr(ext, 'py_limited_api')\n                and get_abi3_suffix()\n            )\n            if use_abi3:\n                so_ext = get_config_var('EXT_SUFFIX')\n                filename = filename[:-len(so_ext)]\n                filename = filename + get_abi3_suffix()\n            if isinstance(ext, Library):\n                fn, ext = os.path.splitext(filename)\n                return self.shlib_compiler.library_filename(fn, libtype)\n            elif use_stubs and ext._links_to_dynamic:\n                d, fn = os.path.split(filename)\n                return os.path.join(d, 'dl-' + fn)\n        return filename\n\n    def initialize_options(self):\n        _build_ext.initialize_options(self)\n        self.shlib_compiler = None\n        self.shlibs = []\n        self.ext_map = {}\n\n    def finalize_options(self):\n        _build_ext.finalize_options(self)\n        self.extensions = self.extensions or []\n        self.check_extensions_list(self.extensions)\n        self.shlibs = [ext for ext in self.extensions\n                       if isinstance(ext, Library)]\n        if self.shlibs:\n            self.setup_shlib_compiler()\n        for ext in self.extensions:\n            ext._full_name = self.get_ext_fullname(ext.name)\n        for ext in self.extensions:\n            fullname = ext._full_name\n            self.ext_map[fullname] = ext\n\n            # distutils 3.1 will also ask for module names\n            # XXX what to do with conflicts?\n            self.ext_map[fullname.split('.')[-1]] = ext\n\n            ltd = self.shlibs and self.links_to_dynamic(ext) or False\n            ns = ltd and use_stubs and not isinstance(ext, Library)\n            ext._links_to_dynamic = ltd\n            ext._needs_stub = ns\n            filename = ext._file_name = self.get_ext_filename(fullname)\n            libdir = os.path.dirname(os.path.join(self.build_lib, filename))\n            if ltd and libdir not in ext.library_dirs:\n                ext.library_dirs.append(libdir)\n            if ltd and use_stubs and os.curdir not in ext.runtime_library_dirs:\n                ext.runtime_library_dirs.append(os.curdir)\n\n    def setup_shlib_compiler(self):\n        compiler = self.shlib_compiler = new_compiler(\n            compiler=self.compiler, dry_run=self.dry_run, force=self.force\n        )\n        _customize_compiler_for_shlib(compiler)\n\n        if self.include_dirs is not None:\n            compiler.set_include_dirs(self.include_dirs)\n        if self.define is not None:\n            # 'define' option is a list of (name,value) tuples\n            for (name, value) in self.define:\n                compiler.define_macro(name, value)\n        if self.undef is not None:\n            for macro in self.undef:\n                compiler.undefine_macro(macro)\n        if self.libraries is not None:\n            compiler.set_libraries(self.libraries)\n        if self.library_dirs is not None:\n            compiler.set_library_dirs(self.library_dirs)\n        if self.rpath is not None:\n            compiler.set_runtime_library_dirs(self.rpath)\n        if self.link_objects is not None:\n            compiler.set_link_objects(self.link_objects)\n\n        # hack so distutils' build_extension() builds a library instead\n        compiler.link_shared_object = link_shared_object.__get__(compiler)\n\n    def get_export_symbols(self, ext):\n        if isinstance(ext, Library):\n            return ext.export_symbols\n        return _build_ext.get_export_symbols(self, ext)\n\n    def build_extension(self, ext):\n        ext._convert_pyx_sources_to_lang()\n        _compiler = self.compiler\n        try:\n            if isinstance(ext, Library):\n                self.compiler = self.shlib_compiler\n            _build_ext.build_extension(self, ext)\n            if ext._needs_stub:\n                cmd = self.get_finalized_command('build_py').build_lib\n                self.write_stub(cmd, ext)\n        finally:\n            self.compiler = _compiler\n\n    def links_to_dynamic(self, ext):\n        \"\"\"Return true if 'ext' links to a dynamic lib in the same package\"\"\"\n        # XXX this should check to ensure the lib is actually being built\n        # XXX as dynamic, and not just using a locally-found version or a\n        # XXX static-compiled version\n        libnames = dict.fromkeys([lib._full_name for lib in self.shlibs])\n        pkg = '.'.join(ext._full_name.split('.')[:-1] + [''])\n        return any(pkg + libname in libnames for libname in ext.libraries)\n\n    def get_outputs(self):\n        return _build_ext.get_outputs(self) + self.__get_stubs_outputs()\n\n    def __get_stubs_outputs(self):\n        # assemble the base name for each extension that needs a stub\n        ns_ext_bases = (\n            os.path.join(self.build_lib, *ext._full_name.split('.'))\n            for ext in self.extensions\n            if ext._needs_stub\n        )\n        # pair each base with the extension\n        pairs = itertools.product(ns_ext_bases, self.__get_output_extensions())\n        return list(base + fnext for base, fnext in pairs)\n\n    def __get_output_extensions(self):\n        yield '.py'\n        yield '.pyc'\n        if self.get_finalized_command('build_py').optimize:\n            yield '.pyo'\n\n    def write_stub(self, output_dir, ext, compile=False):\n        log.info(\"writing stub loader for %s to %s\", ext._full_name,\n                 output_dir)\n        stub_file = (os.path.join(output_dir, *ext._full_name.split('.')) +\n                     '.py')\n        if compile and os.path.exists(stub_file):\n            raise DistutilsError(stub_file + \" already exists! Please delete.\")\n        if not self.dry_run:\n            f = open(stub_file, 'w')\n            f.write(\n                '\\n'.join([\n                    \"def __bootstrap__():\",\n                    \"   global __bootstrap__, __file__, __loader__\",\n                    \"   import sys, os, pkg_resources, imp\" + if_dl(\", dl\"),\n                    \"   __file__ = pkg_resources.resource_filename\"\n                    \"(__name__,%r)\"\n                    % os.path.basename(ext._file_name),\n                    \"   del __bootstrap__\",\n                    \"   if '__loader__' in globals():\",\n                    \"       del __loader__\",\n                    if_dl(\"   old_flags = sys.getdlopenflags()\"),\n                    \"   old_dir = os.getcwd()\",\n                    \"   try:\",\n                    \"     os.chdir(os.path.dirname(__file__))\",\n                    if_dl(\"     sys.setdlopenflags(dl.RTLD_NOW)\"),\n                    \"     imp.load_dynamic(__name__,__file__)\",\n                    \"   finally:\",\n                    if_dl(\"     sys.setdlopenflags(old_flags)\"),\n                    \"     os.chdir(old_dir)\",\n                    \"__bootstrap__()\",\n                    \"\"  # terminal \\n\n                ])\n            )\n            f.close()\n        if compile:\n            from distutils.util import byte_compile\n\n            byte_compile([stub_file], optimize=0,\n                         force=True, dry_run=self.dry_run)\n            optimize = self.get_finalized_command('install_lib').optimize\n            if optimize > 0:\n                byte_compile([stub_file], optimize=optimize,\n                             force=True, dry_run=self.dry_run)\n            if os.path.exists(stub_file) and not self.dry_run:\n                os.unlink(stub_file)\n\n\nif use_stubs or os.name == 'nt':\n    # Build shared libraries\n    #\n    def link_shared_object(\n            self, objects, output_libname, output_dir=None, libraries=None,\n            library_dirs=None, runtime_library_dirs=None, export_symbols=None,\n            debug=0, extra_preargs=None, extra_postargs=None, build_temp=None,\n            target_lang=None):\n        self.link(\n            self.SHARED_LIBRARY, objects, output_libname,\n            output_dir, libraries, library_dirs, runtime_library_dirs,\n            export_symbols, debug, extra_preargs, extra_postargs,\n            build_temp, target_lang\n        )\nelse:\n    # Build static libraries everywhere else\n    libtype = 'static'\n\n    def link_shared_object(\n            self, objects, output_libname, output_dir=None, libraries=None,\n            library_dirs=None, runtime_library_dirs=None, export_symbols=None,\n            debug=0, extra_preargs=None, extra_postargs=None, build_temp=None,\n            target_lang=None):\n        # XXX we need to either disallow these attrs on Library instances,\n        # or warn/abort here if set, or something...\n        # libraries=None, library_dirs=None, runtime_library_dirs=None,\n        # export_symbols=None, extra_preargs=None, extra_postargs=None,\n        # build_temp=None\n\n        assert output_dir is None  # distutils build_ext doesn't pass this\n        output_dir, filename = os.path.split(output_libname)\n        basename, ext = os.path.splitext(filename)\n        if self.library_filename(\"x\").startswith('lib'):\n            # strip 'lib' prefix; this is kludgy if some platform uses\n            # a different prefix\n            basename = basename[3:]\n\n        self.create_static_lib(\n            objects, basename, output_dir, debug, target_lang\n        )\n"
    },
    "skipped": [
        "/tmp/vanessa/spack-stage/spack-stage-py-setuptools-44.1.0-x2oqqwegszantfph3vyt5qy3hkqvctxw/spack-src/setuptools/gui.exe",
        "/tmp/vanessa/spack-stage/spack-stage-py-setuptools-44.1.0-x2oqqwegszantfph3vyt5qy3hkqvctxw/spack-src/setuptools/cli-32.exe",
        "/tmp/vanessa/spack-stage/spack-stage-py-setuptools-44.1.0-x2oqqwegszantfph3vyt5qy3hkqvctxw/spack-src/setuptools/cli-64.exe",
        "/tmp/vanessa/spack-stage/spack-stage-py-setuptools-44.1.0-x2oqqwegszantfph3vyt5qy3hkqvctxw/spack-src/setuptools/cli.exe",
        "/tmp/vanessa/spack-stage/spack-stage-py-setuptools-44.1.0-x2oqqwegszantfph3vyt5qy3hkqvctxw/spack-src/setuptools/gui-32.exe",
        "/tmp/vanessa/spack-stage/spack-stage-py-setuptools-44.1.0-x2oqqwegszantfph3vyt5qy3hkqvctxw/spack-src/setuptools/gui-64.exe"
    ],
    "total_files": 191
}