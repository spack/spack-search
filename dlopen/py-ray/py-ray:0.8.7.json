{
    "matches": {
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/BUILD.bazel": "# Bazel build\n# C/C++ documentation: https://docs.bazel.build/versions/master/be/c-cpp.html\n\nload(\"@rules_proto//proto:defs.bzl\", \"proto_library\")\nload(\"@rules_cc//cc:defs.bzl\", \"cc_binary\", \"cc_library\", \"cc_proto_library\", \"cc_test\")\nload(\"@com_github_grpc_grpc//bazel:cc_grpc_library.bzl\", \"cc_grpc_library\")\nload(\"@com_github_grpc_grpc//bazel:cython_library.bzl\", \"pyx_library\")\nload(\"@rules_proto_grpc//python:defs.bzl\", \"python_grpc_compile\")\nload(\"@com_github_google_flatbuffers//:build_defs.bzl\", \"flatbuffer_cc_library\")\nload(\"//bazel:ray.bzl\", \"COPTS\", \"PYX_COPTS\", \"PYX_SRCS\", \"copy_to_workspace\")\n\nconfig_setting(\n    name = \"msvc-cl\",\n    flag_values = {\"@bazel_tools//tools/cpp:compiler\": \"msvc-cl\"},\n)\n\nconfig_setting(\n    name = \"clang-cl\",\n    flag_values = {\"@bazel_tools//tools/cpp:compiler\": \"clang-cl\"},\n)\n\nconfig_setting(\n    name = \"opt\",\n    values = {\"compilation_mode\": \"opt\"},\n)\n\n# === Begin of protobuf definitions ===\n\nproto_library(\n    name = \"common_proto\",\n    srcs = [\"src/ray/protobuf/common.proto\"],\n    visibility = [\"//java:__subpackages__\"],\n)\n\ncc_proto_library(\n    name = \"common_cc_proto\",\n    deps = [\":common_proto\"],\n)\n\npython_grpc_compile(\n    name = \"common_py_proto\",\n    deps = [\":common_proto\"],\n)\n\nproto_library(\n    name = \"gcs_proto\",\n    srcs = [\"src/ray/protobuf/gcs.proto\"],\n    visibility = [\"//java:__subpackages__\"],\n    deps = [\":common_proto\"],\n)\n\ncc_proto_library(\n    name = \"gcs_cc_proto\",\n    deps = [\":gcs_proto\"],\n)\n\npython_grpc_compile(\n    name = \"gcs_py_proto\",\n    deps = [\":gcs_proto\"],\n)\n\nproto_library(\n    name = \"node_manager_proto\",\n    srcs = [\"src/ray/protobuf/node_manager.proto\"],\n    deps = [\":common_proto\"],\n)\n\ncc_proto_library(\n    name = \"node_manager_cc_proto\",\n    deps = [\":node_manager_proto\"],\n)\n\npython_grpc_compile(\n    name = \"node_manager_py_proto\",\n    deps = [\":node_manager_proto\"],\n)\n\nproto_library(\n    name = \"reporter_proto\",\n    srcs = [\"src/ray/protobuf/reporter.proto\"],\n    deps = [\":common_proto\"],\n)\n\ncc_proto_library(\n    name = \"reporter_cc_proto\",\n    deps = [\":reporter_proto\"],\n)\n\npython_grpc_compile(\n    name = \"reporter_py_proto\",\n    deps = [\":reporter_proto\"],\n)\n\nproto_library(\n    name = \"gcs_service_proto\",\n    srcs = [\"src/ray/protobuf/gcs_service.proto\"],\n    deps = [\n        \":common_proto\",\n        \":gcs_proto\",\n    ],\n)\n\ncc_proto_library(\n    name = \"gcs_service_cc_proto\",\n    deps = [\":gcs_service_proto\"],\n)\n\nproto_library(\n    name = \"object_manager_proto\",\n    srcs = [\"src/ray/protobuf/object_manager.proto\"],\n)\n\ncc_proto_library(\n    name = \"object_manager_cc_proto\",\n    deps = [\":object_manager_proto\"],\n)\n\nproto_library(\n    name = \"core_worker_proto\",\n    srcs = [\"src/ray/protobuf/core_worker.proto\"],\n    deps = [\":common_proto\"],\n)\n\npython_grpc_compile(\n    name = \"core_worker_py_proto\",\n    deps = [\":core_worker_proto\"],\n)\n\ncc_proto_library(\n    name = \"worker_cc_proto\",\n    deps = [\"core_worker_proto\"],\n)\n\nproto_library(\n    name = \"serialization_proto\",\n    srcs = [\"src/ray/protobuf/serialization.proto\"],\n)\n\ncc_proto_library(\n    name = \"serialization_cc_proto\",\n    deps = [\"serialization_proto\"],\n)\n\n# === End of protobuf definitions ===\n\n# === Begin of rpc definitions ===\n\n# GRPC common lib.\ncc_library(\n    name = \"grpc_common_lib\",\n    srcs = glob([\n        \"src/ray/rpc/*.cc\",\n    ]),\n    hdrs = glob([\n        \"src/ray/rpc/*.h\",\n    ]),\n    copts = COPTS,\n    strip_include_prefix = \"src\",\n    deps = [\n        \":ray_common\",\n        \"@boost//:asio\",\n        \"@com_github_grpc_grpc//:grpc++\",\n        \"@com_google_protobuf//:protobuf\",\n    ],\n)\n\n# Node manager gRPC lib.\ncc_grpc_library(\n    name = \"node_manager_cc_grpc\",\n    srcs = [\":node_manager_proto\"],\n    grpc_only = True,\n    deps = [\":node_manager_cc_proto\"],\n)\n\n# Node manager server and client.\ncc_library(\n    name = \"node_manager_rpc\",\n    hdrs = glob([\n        \"src/ray/rpc/node_manager/*.h\",\n    ]),\n    copts = COPTS,\n    strip_include_prefix = \"src\",\n    deps = [\n        \":grpc_common_lib\",\n        \":node_manager_cc_grpc\",\n        \":ray_common\",\n        \"@boost//:asio\",\n        \"@com_github_grpc_grpc//:grpc++\",\n    ],\n)\n\n# gcs_service gRPC lib.\ncc_grpc_library(\n    name = \"gcs_service_cc_grpc\",\n    srcs = [\":gcs_service_proto\"],\n    grpc_only = True,\n    deps = [\":gcs_service_cc_proto\"],\n)\n\n# gcs rpc server and client.\ncc_library(\n    name = \"gcs_service_rpc\",\n    hdrs = glob([\n        \"src/ray/rpc/gcs_server/gcs_rpc_server.h\",\n        \"src/ray/rpc/gcs_server/gcs_rpc_client.h\",\n    ]),\n    copts = COPTS,\n    strip_include_prefix = \"src\",\n    deps = [\n        \":gcs_service_cc_grpc\",\n        \":grpc_common_lib\",\n        \":ray_common\",\n        \"@boost//:asio\",\n        \"@com_github_grpc_grpc//:grpc++\",\n    ],\n)\n\n# Object manager gRPC lib.\ncc_grpc_library(\n    name = \"object_manager_cc_grpc\",\n    srcs = [\":object_manager_proto\"],\n    grpc_only = True,\n    deps = [\":object_manager_cc_proto\"],\n)\n\n# Object manager rpc server and client.\ncc_library(\n    name = \"object_manager_rpc\",\n    hdrs = glob([\n        \"src/ray/rpc/object_manager/*.h\",\n    ]),\n    copts = COPTS,\n    strip_include_prefix = \"src\",\n    deps = [\n        \":grpc_common_lib\",\n        \":object_manager_cc_grpc\",\n        \":ray_common\",\n        \"@boost//:asio\",\n        \"@com_github_grpc_grpc//:grpc++\",\n    ],\n)\n\n# Worker gRPC lib.\ncc_grpc_library(\n    name = \"worker_cc_grpc\",\n    srcs = [\":core_worker_proto\"],\n    grpc_only = True,\n    deps = [\":worker_cc_proto\"],\n)\n\n# worker server and client.\ncc_library(\n    name = \"worker_rpc\",\n    hdrs = glob([\n        \"src/ray/rpc/worker/*.h\",\n    ]),\n    copts = COPTS,\n    strip_include_prefix = \"src\",\n    deps = [\n        \":grpc_common_lib\",\n        \":ray_common\",\n        \":worker_cc_grpc\",\n        \"@boost//:asio\",\n        \"@boost//:thread\",\n        \"@com_github_grpc_grpc//:grpc++\",\n    ],\n)\n\n# Metrics Agent gRPC lib.\ncc_grpc_library(\n    name = \"reporter_cc_grpc\",\n    srcs = [\":reporter_proto\"],\n    grpc_only = True,\n    deps = [\":reporter_cc_proto\"],\n)\n\n# Metrics Agent client.\ncc_library(\n    name = \"reporter_rpc\",\n    hdrs = glob([\n        \"src/ray/rpc/metrics_agent_client.h\",\n    ]),\n    copts = COPTS,\n    strip_include_prefix = \"src\",\n    deps = [\n        \":grpc_common_lib\",\n        \":ray_common\",\n        \":reporter_cc_grpc\",\n        \"@boost//:asio\",\n        \"@boost//:thread\",\n        \"@com_github_grpc_grpc//:grpc++\",\n    ],\n)\n\n# === End of rpc definitions ===\n\n# === Begin of plasma definitions ===\n\n# TODO(mehrdadn): (How to) support dynamic linking?\nPROPAGATED_WINDOWS_DEFINES = [\"ARROW_STATIC\"]\n\nPLASMA_COPTS = COPTS + select({\n    \"@bazel_tools//src/conditions:windows\": [\n    ] + [\"-D\" + define for define in PROPAGATED_WINDOWS_DEFINES],\n    \"//conditions:default\": [\n        \"-DARROW_USE_GLOG\",\n    ],\n})\n\nPLASMA_LINKOPTS = [] + select({\n    \"@bazel_tools//src/conditions:windows\": [\n        \"-DefaultLib:\" + \"ws2_32.lib\",\n    ],\n    \"//conditions:default\": [\n    ],\n})\n\ncc_library(\n    name = \"plasma_client\",\n    srcs = [\n        \"src/ray/object_manager/plasma/client.cc\",\n        \"src/ray/object_manager/plasma/connection.cc\",\n        \"src/ray/object_manager/plasma/malloc.cc\",\n        \"src/ray/object_manager/plasma/plasma.cc\",\n        \"src/ray/object_manager/plasma/protocol.cc\",\n        \"src/ray/object_manager/plasma/shared_memory.cc\",\n    ] + select({\n        \"@bazel_tools//src/conditions:windows\": [\n        ],\n        \"//conditions:default\": [\n            \"src/ray/object_manager/plasma/fling.cc\",\n        ],\n    }),\n    hdrs = [\n        \"src/ray/object_manager/format/object_manager_generated.h\",\n        \"src/ray/object_manager/notification/object_store_notification_manager.h\",\n        \"src/ray/object_manager/plasma/client.h\",\n        \"src/ray/object_manager/plasma/common.h\",\n        \"src/ray/object_manager/plasma/compat.h\",\n        \"src/ray/object_manager/plasma/external_store.h\",\n        \"src/ray/object_manager/plasma/connection.h\",\n        \"src/ray/object_manager/plasma/malloc.h\",\n        \"src/ray/object_manager/plasma/plasma.h\",\n        \"src/ray/object_manager/plasma/plasma_generated.h\",\n        \"src/ray/object_manager/plasma/protocol.h\",\n        \"src/ray/object_manager/plasma/shared_memory.h\",\n    ] + select({\n        \"@bazel_tools//src/conditions:windows\": [\n        ],\n        \"//conditions:default\": [\n            \"src/ray/object_manager/plasma/fling.h\",\n        ],\n    }),\n    copts = PLASMA_COPTS,\n    defines = select({\n        \"@bazel_tools//src/conditions:windows\": PROPAGATED_WINDOWS_DEFINES,\n        \"//conditions:default\": [],\n    }),\n    linkopts = PLASMA_LINKOPTS,\n    strip_include_prefix = \"src\",\n    deps = [\n        \":object_manager_fbs\",\n        \":plasma_fbs\",\n        \":ray_common\",\n        \":ray_util\",\n        \"@arrow\",\n        \"@com_github_google_glog//:glog\",\n        \"@msgpack\",\n    ],\n)\n\ncc_library(\n    name = \"plasma_store_server_lib\",\n    srcs = [\n        \"src/ray/object_manager/plasma/dlmalloc.cc\",\n        \"src/ray/object_manager/plasma/eviction_policy.cc\",\n        \"src/ray/object_manager/plasma/external_store.cc\",\n        \"src/ray/object_manager/plasma/plasma_allocator.cc\",\n        \"src/ray/object_manager/plasma/quota_aware_policy.cc\",\n        \"src/ray/object_manager/plasma/store.cc\",\n        \"src/ray/object_manager/plasma/store_runner.cc\",\n    ],\n    hdrs = [\n        \"src/ray/object_manager/plasma/eviction_policy.h\",\n        \"src/ray/object_manager/plasma/external_store.h\",\n        \"src/ray/object_manager/plasma/plasma_allocator.h\",\n        \"src/ray/object_manager/plasma/quota_aware_policy.h\",\n        \"src/ray/object_manager/plasma/store.h\",\n        \"src/ray/object_manager/plasma/store_runner.h\",\n        \"src/ray/thirdparty/dlmalloc.c\",\n    ],\n    copts = PLASMA_COPTS,\n    linkopts = PLASMA_LINKOPTS,\n    strip_include_prefix = \"src\",\n    deps = [\n        \":plasma_client\",\n        \"@com_github_google_glog//:glog\",\n    ],\n)\n\ncc_binary(\n    name = \"plasma_store_server\",\n    srcs = [\n        \"src/ray/plasma/store_exec.cc\",\n    ],\n    copts = PLASMA_COPTS,\n    visibility = [\"//visibility:public\"],\n    deps = [\n        \":plasma_store_server_lib\",\n    ],\n)\n\nFLATC_ARGS = [\n    \"--gen-object-api\",\n    \"--gen-mutable\",\n    \"--scoped-enums\",\n]\n\nflatbuffer_cc_library(\n    name = \"plasma_fbs\",\n    srcs = [\"src/ray/object_manager/plasma/plasma.fbs\"],\n    flatc_args = FLATC_ARGS,\n    out_prefix = \"src/ray/object_manager/plasma/\",\n)\n\n# === End of plasma definitions ===\n\ncc_library(\n    name = \"ray_common\",\n    srcs = glob(\n        [\n            \"src/ray/common/**/*.cc\",\n        ],\n        exclude = [\n            \"src/ray/common/**/*_test.cc\",\n        ],\n    ),\n    hdrs = glob(\n        [\n            \"src/ray/common/**/*.h\",\n        ],\n    ),\n    copts = COPTS,\n    strip_include_prefix = \"src\",\n    visibility = [\"//visibility:public\"],\n    deps = [\n        \":common_cc_proto\",\n        \":gcs_cc_proto\",\n        \":node_manager_fbs\",\n        \":ray_util\",\n        \"@arrow\",\n        \"@boost//:asio\",\n        \"@com_github_grpc_grpc//:grpc++\",\n        \"@com_google_absl//absl/container:flat_hash_map\",\n        \"@com_google_absl//absl/container:flat_hash_set\",\n        \"@com_google_absl//absl/memory\",\n        \"@com_google_googletest//:gtest\",\n        \"@msgpack\",\n    ],\n)\n\ncc_binary(\n    name = \"raylet\",\n    srcs = [\"src/ray/raylet/main.cc\"],\n    copts = COPTS,\n    visibility = [\"//java:__subpackages__\"],\n    deps = [\n        \":ray_util\",\n        \":raylet_lib\",\n        \"@com_github_gflags_gflags//:gflags\",\n    ],\n)\n\ncc_library(\n    name = \"gcs_pub_sub_lib\",\n    srcs = glob(\n        [\n            \"src/ray/gcs/pubsub/gcs_pub_sub.cc\",\n        ],\n    ),\n    hdrs = glob(\n        [\n            \"src/ray/gcs/pubsub/gcs_pub_sub.h\",\n        ],\n    ),\n    copts = COPTS,\n    strip_include_prefix = \"src\",\n    deps = [\n        \":gcs\",\n        \":ray_common\",\n        \":redis_client\",\n    ],\n)\n\ncc_test(\n    name = \"gcs_pub_sub_test\",\n    srcs = [\"src/ray/gcs/pubsub/test/gcs_pub_sub_test.cc\"],\n    args = [\n        \"$(location redis-server)\",\n        \"$(location redis-cli)\",\n        \"$(location libray_redis_module.so)\",\n    ],\n    copts = COPTS,\n    data = [\n        \"//:libray_redis_module.so\",\n        \"//:redis-cli\",\n        \"//:redis-server\",\n    ],\n    deps = [\n        \":gcs_pub_sub_lib\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\ncc_library(\n    name = \"gcs_server_lib\",\n    srcs = glob(\n        [\n            \"src/ray/gcs/gcs_server/*.cc\",\n        ],\n        exclude = [\n            \"src/ray/gcs/gcs_server/gcs_server_main.cc\",\n            \"src/ray/gcs/gcs_server/test/*.cc\",\n        ],\n    ),\n    hdrs = glob(\n        [\n            \"src/ray/gcs/gcs_server/*.h\",\n        ],\n    ),\n    copts = COPTS,\n    strip_include_prefix = \"src\",\n    deps = [\n        \":gcs\",\n        \":gcs_pub_sub_lib\",\n        \":gcs_service_rpc\",\n        \":gcs_table_storage_lib\",\n        \":node_manager_rpc\",\n        \":raylet_client_lib\",\n        \":worker_rpc\",\n    ],\n)\n\ncc_binary(\n    name = \"gcs_server\",\n    srcs = [\n        \"src/ray/gcs/gcs_server/gcs_server_main.cc\",\n    ],\n    copts = COPTS,\n    visibility = [\"//java:__subpackages__\"],\n    deps = [\n        \":gcs_server_lib\",\n        \":stats_lib\",\n        \"@com_github_gflags_gflags//:gflags\",\n    ],\n)\n\ncc_library(\n    name = \"stats_lib\",\n    srcs = glob(\n        [\n            \"src/ray/stats/*.cc\",\n        ],\n        exclude = [\n            \"src/ray/stats/*_test.cc\",\n        ],\n    ),\n    hdrs = glob(\n        [\n            \"src/ray/stats/*.h\",\n        ],\n    ),\n    copts = COPTS,\n    linkopts = select({\n        \"@bazel_tools//src/conditions:windows\": [\n        ],\n        \"//conditions:default\": [\n            \"-lpthread\",\n        ],\n    }),\n    strip_include_prefix = \"src\",\n    deps = [\n        \":ray_util\",\n        \":reporter_rpc\",\n        \"@com_github_jupp0r_prometheus_cpp//pull\",\n        \"@com_google_absl//absl/base:core_headers\",\n        \"@com_google_absl//absl/memory\",\n        \"@com_google_absl//absl/strings\",\n        \"@com_google_googletest//:gtest\",\n        \"@io_opencensus_cpp//opencensus/exporters/stats/prometheus:prometheus_exporter\",\n        \"@io_opencensus_cpp//opencensus/exporters/stats/stdout:stdout_exporter\",\n        \"@io_opencensus_cpp//opencensus/stats\",\n        \"@io_opencensus_cpp//opencensus/tags\",\n    ],\n)\n\ncc_library(\n    name = \"raylet_lib\",\n    srcs = glob(\n        [\n            \"src/ray/raylet/**/*.cc\",\n        ],\n        exclude = [\n            \"src/ray/raylet/**/*_test.cc\",\n            \"src/ray/raylet/main.cc\",\n        ],\n    ),\n    hdrs = glob(\n        [\n            \"src/ray/raylet/**/*.h\",\n            \"src/ray/core_worker/common.h\",\n        ],\n    ),\n    copts = COPTS,\n    linkopts = select({\n        \"@bazel_tools//src/conditions:windows\": [\n        ],\n        \"//conditions:default\": [\n            \"-lpthread\",\n        ],\n    }),\n    strip_include_prefix = \"src\",\n    visibility = [\"//streaming:__subpackages__\"],\n    deps = [\n        \":common_cc_proto\",\n        \":gcs\",\n        \":node_manager_fbs\",\n        \":node_manager_rpc\",\n        \":object_manager\",\n        \":plasma_client\",\n        \":ray_common\",\n        \":ray_util\",\n        \":service_based_gcs_client_lib\",\n        \":stats_lib\",\n        \":worker_rpc\",\n        \"@boost//:asio\",\n        \"@com_github_jupp0r_prometheus_cpp//pull\",\n        \"@com_google_absl//absl/base:core_headers\",\n        \"@com_google_absl//absl/container:flat_hash_set\",\n        \"@com_google_absl//absl/memory\",\n        \"@com_google_absl//absl/strings\",\n        \"@com_google_googletest//:gtest\",\n        \"@io_opencensus_cpp//opencensus/exporters/stats/prometheus:prometheus_exporter\",\n        \"@io_opencensus_cpp//opencensus/stats\",\n        \"@io_opencensus_cpp//opencensus/tags\",\n    ],\n)\n\ncc_library(\n    name = \"raylet_client_lib\",\n    srcs = glob([\n        \"src/ray/raylet_client/*.cc\",\n    ]),\n    hdrs = glob([\n        \"src/ray/raylet_client/*.h\",\n    ]),\n    copts = COPTS,\n    linkopts = select({\n        \"@bazel_tools//src/conditions:windows\": [\n        ],\n        \"//conditions:default\": [\n            \"-lpthread\",\n        ],\n    }),\n    strip_include_prefix = \"src\",\n    visibility = [\"//streaming:__subpackages__\"],\n    deps = [\n        \":gcs_cc_proto\",\n        \":node_manager_fbs\",\n        \":node_manager_rpc\",\n        \":ray_common\",\n        \":ray_util\",\n        \"@boost//:asio\",\n    ],\n)\n\ncc_library(\n    name = \"core_worker_lib\",\n    srcs = glob(\n        [\n            \"src/ray/core_worker/*.cc\",\n            \"src/ray/core_worker/store_provider/*.cc\",\n            \"src/ray/core_worker/store_provider/memory_store/*.cc\",\n            \"src/ray/core_worker/transport/*.cc\",\n            \"src/ray/rpc/worker/*.cc\",\n        ],\n        exclude = [\n            \"src/ray/core_worker/**/*_test.cc\",\n            \"src/ray/core_worker/mock_worker.cc\",\n        ],\n    ),\n    hdrs = glob([\n        \"src/ray/core_worker/*.h\",\n        \"src/ray/core_worker/store_provider/*.h\",\n        \"src/ray/core_worker/store_provider/memory_store/*.h\",\n        \"src/ray/core_worker/transport/*.h\",\n    ]),\n    copts = COPTS,\n    strip_include_prefix = \"src\",\n    visibility = [\"//visibility:public\"],\n    deps = [\n        \":gcs\",\n        \":plasma_client\",\n        \":ray_common\",\n        \":ray_util\",\n        \":raylet_client_lib\",\n        \":service_based_gcs_client_lib\",\n        \":stats_lib\",\n        \":worker_cc_proto\",\n        \":worker_rpc\",\n        \"@boost//:fiber\",\n        \"@com_google_absl//absl/container:flat_hash_map\",\n        \"@com_google_absl//absl/container:flat_hash_set\",\n    ],\n)\n\ncc_library(\n    name = \"mock_worker_lib\",\n    srcs = [\"src/ray/core_worker/test/mock_worker.cc\"],\n    hdrs = glob([\n        \"src/ray/core_worker/test/*.h\",\n    ]),\n    copts = COPTS,\n    strip_include_prefix = \"src\",\n    deps = [\n        \":core_worker_lib\",\n    ],\n)\n\ncc_binary(\n    name = \"mock_worker\",\n    copts = COPTS,\n    deps = [\n        \":mock_worker_lib\",\n    ],\n)\n\ncc_test(\n    name = \"core_worker_test\",\n    srcs = [\"src/ray/core_worker/test/core_worker_test.cc\"],\n    args = [\n        \"$(location //:plasma_store_server)\",\n        \"$(location raylet)\",\n        \"$(location mock_worker)\",\n        \"$(location gcs_server)\",\n        \"$(location redis-cli)\",\n        \"$(location redis-server)\",\n        \"$(location libray_redis_module.so)\",\n    ],\n    copts = COPTS,\n    data = [\n        \"//:gcs_server\",\n        \"//:libray_redis_module.so\",\n        \"//:mock_worker\",\n        \"//:plasma_store_server\",\n        \"//:raylet\",\n        \"//:redis-cli\",\n        \"//:redis-server\",\n    ],\n    deps = [\n        \":core_worker_lib\",\n        \":gcs\",\n        \"@com_google_absl//absl/container:flat_hash_map\",\n        \"@com_google_absl//absl/container:flat_hash_set\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\ncc_test(\n    name = \"direct_actor_transport_test\",\n    srcs = [\"src/ray/core_worker/test/direct_actor_transport_test.cc\"],\n    copts = COPTS,\n    deps = [\n        \":core_worker_lib\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\ncc_test(\n    name = \"direct_task_transport_test\",\n    srcs = [\"src/ray/core_worker/test/direct_task_transport_test.cc\"],\n    copts = COPTS,\n    deps = [\n        \":core_worker_lib\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\ncc_test(\n    name = \"reference_count_test\",\n    srcs = [\"src/ray/core_worker/reference_count_test.cc\"],\n    copts = COPTS,\n    deps = [\n        \":core_worker_lib\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\ncc_test(\n    name = \"object_recovery_manager_test\",\n    srcs = [\"src/ray/core_worker/test/object_recovery_manager_test.cc\"],\n    copts = COPTS,\n    deps = [\n        \":core_worker_lib\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\ncc_test(\n    name = \"scheduling_queue_test\",\n    srcs = [\"src/ray/core_worker/test/scheduling_queue_test.cc\"],\n    copts = COPTS,\n    deps = [\n        \":core_worker_lib\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\ncc_test(\n    name = \"task_manager_test\",\n    srcs = [\"src/ray/core_worker/test/task_manager_test.cc\"],\n    copts = COPTS,\n    deps = [\n        \":core_worker_lib\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\ncc_test(\n    name = \"actor_manager_test\",\n    srcs = [\"src/ray/core_worker/test/actor_manager_test.cc\"],\n    copts = COPTS,\n    deps = [\n        \":core_worker_lib\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\ncc_test(\n    name = \"cluster_resource_scheduler_test\",\n    srcs = [\n        \"src/ray/raylet/scheduling/cluster_resource_scheduler_test.cc\",\n    ],\n    copts = COPTS,\n    deps = [\n        \":raylet_lib\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\ncc_test(\n    name = \"cluster_task_manager_test\",\n    srcs = [\n        \"src/ray/raylet/scheduling/cluster_task_manager_test.cc\",\n    ],\n    copts = COPTS,\n    deps = [\n        \":raylet_lib\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\ncc_test(\n    name = \"lineage_cache_test\",\n    srcs = [\"src/ray/raylet/lineage_cache_test.cc\"],\n    copts = COPTS,\n    deps = [\n        \":node_manager_fbs\",\n        \":raylet_lib\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\ncc_test(\n    name = \"reconstruction_policy_test\",\n    srcs = [\"src/ray/raylet/reconstruction_policy_test.cc\"],\n    copts = COPTS + select({\n        \"//:msvc-cl\": [\n        ],\n        \"//conditions:default\": [\n            # Ignore this warning since it's impractical to fix in the relevant headers\n            \"-Wno-inconsistent-missing-override\",\n        ],\n    }),\n    deps = [\n        \":node_manager_fbs\",\n        \":object_manager\",\n        \":raylet_lib\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\ncc_test(\n    name = \"worker_pool_test\",\n    srcs = [\"src/ray/raylet/worker_pool_test.cc\"],\n    copts = COPTS,\n    deps = [\n        \":raylet_lib\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\ncc_test(\n    name = \"scheduling_resources_test\",\n    srcs = [\"src/ray/common/task/scheduling_resources_test.cc\"],\n    copts = COPTS,\n    deps = [\n        \"ray_common\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\ncc_test(\n    name = \"id_test\",\n    srcs = [\"src/ray/common/id_test.cc\"],\n    copts = COPTS,\n    deps = [\n        \"ray_common\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\ncc_test(\n    name = \"logging_test\",\n    srcs = [\"src/ray/util/logging_test.cc\"],\n    args = [\"--gtest_filter=PrintLogTest*\"],\n    copts = COPTS,\n    deps = [\n        \":ray_util\",\n        \"@boost//:asio\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\ncc_test(\n    name = \"filesystem_test\",\n    srcs = [\"src/ray/util/filesystem_test.cc\"],\n    copts = COPTS,\n    deps = [\n        \":ray_util\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\ncc_test(\n    name = \"util_test\",\n    srcs = [\"src/ray/util/util_test.cc\"],\n    copts = COPTS,\n    deps = [\n        \":ray_util\",\n        \"@boost//:asio\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\ncc_test(\n    name = \"sample_test\",\n    srcs = [\"src/ray/util/sample_test.cc\"],\n    copts = COPTS,\n    deps = [\n        \":ray_common\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\ncc_test(\n    name = \"task_dependency_manager_test\",\n    srcs = [\"src/ray/raylet/task_dependency_manager_test.cc\"],\n    copts = COPTS,\n    deps = [\n        \":raylet_lib\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\ncc_test(\n    name = \"client_connection_test\",\n    srcs = [\"src/ray/common/test/client_connection_test.cc\"],\n    copts = COPTS,\n    deps = [\n        \":ray_common\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\ncc_test(\n    name = \"signal_test\",\n    srcs = [\"src/ray/util/signal_test.cc\"],\n    copts = COPTS,\n    deps = [\n        \":raylet_lib\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\ncc_test(\n    name = \"sequencer_test\",\n    srcs = [\"src/ray/util/sequencer_test.cc\"],\n    copts = COPTS,\n    deps = [\n        \":ray_util\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\ncc_test(\n    name = \"stats_test\",\n    srcs = [\"src/ray/stats/stats_test.cc\"],\n    copts = COPTS,\n    tags = [\"stats\"],\n    deps = [\n        \":stats_lib\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\ncc_test(\n    name = \"metric_exporter_client_test\",\n    srcs = [\"src/ray/stats/metric_exporter_client_test.cc\"],\n    copts = COPTS,\n    tags = [\"stats\"],\n    deps = [\n        \":stats_lib\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\ncc_library(\n    name = \"gcs_test_util_lib\",\n    hdrs = [\n        \"src/ray/gcs/test/accessor_test_base.h\",\n        \"src/ray/gcs/test/gcs_test_util.h\",\n    ],\n    copts = COPTS,\n    strip_include_prefix = \"src\",\n    deps = [\n        \":gcs\",\n        \":gcs_service_rpc\",\n    ],\n)\n\ncc_test(\n    name = \"gcs_server_rpc_test\",\n    srcs = [\n        \"src/ray/gcs/gcs_server/test/gcs_server_rpc_test.cc\",\n    ],\n    args = [\n        \"$(location redis-server)\",\n        \"$(location redis-cli)\",\n        \"$(location libray_redis_module.so)\",\n    ],\n    copts = COPTS,\n    data = [\n        \"//:libray_redis_module.so\",\n        \"//:redis-cli\",\n        \"//:redis-server\",\n    ],\n    deps = [\n        \":gcs_server_lib\",\n        \":gcs_test_util_lib\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\ncc_library(\n    name = \"gcs_server_test_util\",\n    hdrs = [\n        \"src/ray/gcs/gcs_server/test/gcs_server_test_util.h\",\n    ],\n    copts = COPTS,\n    strip_include_prefix = \"src\",\n)\n\ncc_test(\n    name = \"gcs_node_manager_test\",\n    srcs = [\n        \"src/ray/gcs/gcs_server/test/gcs_node_manager_test.cc\",\n    ],\n    copts = COPTS,\n    deps = [\n        \":gcs_server_lib\",\n        \":gcs_server_test_util\",\n        \":gcs_test_util_lib\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\ncc_test(\n    name = \"gcs_placement_group_manager_test\",\n    srcs = [\n        \"src/ray/gcs/gcs_server/test/gcs_placement_group_manager_test.cc\",\n    ],\n    copts = COPTS,\n    deps = [\n        \":gcs_server_lib\",\n        \":gcs_server_test_util\",\n        \":gcs_test_util_lib\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\ncc_test(\n    name = \"gcs_placement_group_scheduler_test\",\n    srcs = [\n        \"src/ray/gcs/gcs_server/test/gcs_placement_group_scheduler_test.cc\",\n    ],\n    copts = COPTS,\n    deps = [\n        \":gcs_server_lib\",\n        \":gcs_server_test_util\",\n        \":gcs_test_util_lib\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\ncc_test(\n    name = \"gcs_actor_scheduler_test\",\n    srcs = [\n        \"src/ray/gcs/gcs_server/test/gcs_actor_scheduler_test.cc\",\n    ],\n    copts = COPTS,\n    deps = [\n        \":gcs_server_lib\",\n        \":gcs_server_test_util\",\n        \":gcs_test_util_lib\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\ncc_test(\n    name = \"gcs_actor_manager_test\",\n    srcs = [\n        \"src/ray/gcs/gcs_server/test/gcs_actor_manager_test.cc\",\n    ],\n    copts = COPTS,\n    deps = [\n        \":gcs_server_lib\",\n        \":gcs_server_test_util\",\n        \":gcs_test_util_lib\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\ncc_library(\n    name = \"gcs_table_storage_lib\",\n    srcs = glob(\n        [\n            \"src/ray/gcs/gcs_server/gcs_table_storage.cc\",\n        ],\n    ),\n    hdrs = glob(\n        [\n            \"src/ray/gcs/gcs_server/gcs_table_storage.h\",\n        ],\n    ),\n    copts = COPTS,\n    strip_include_prefix = \"src\",\n    deps = [\n        \":gcs\",\n        \":gcs_in_memory_store_client\",\n        \":ray_common\",\n        \":redis_store_client\",\n    ],\n)\n\ncc_library(\n    name = \"gcs_table_storage_test_lib\",\n    hdrs = [\n        \"src/ray/gcs/gcs_server/test/gcs_table_storage_test_base.h\",\n    ],\n    copts = COPTS,\n    strip_include_prefix = \"src\",\n    deps = [\n        \"redis_store_client\",\n    ],\n)\n\ncc_test(\n    name = \"redis_gcs_table_storage_test\",\n    srcs = [\n        \"src/ray/gcs/gcs_server/test/redis_gcs_table_storage_test.cc\",\n    ],\n    args = [\n        \"$(location redis-server)\",\n        \"$(location redis-cli)\",\n        \"$(location libray_redis_module.so)\",\n    ],\n    copts = COPTS,\n    data = [\n        \"//:libray_redis_module.so\",\n        \"//:redis-cli\",\n        \"//:redis-server\",\n    ],\n    deps = [\n        \":gcs_table_storage_lib\",\n        \":gcs_table_storage_test_lib\",\n        \":gcs_test_util_lib\",\n        \":store_client_test_lib\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\ncc_test(\n    name = \"in_memory_gcs_table_storage_test\",\n    srcs = [\n        \"src/ray/gcs/gcs_server/test/in_memory_gcs_table_storage_test.cc\",\n    ],\n    copts = COPTS,\n    deps = [\n        \":gcs_table_storage_lib\",\n        \":gcs_table_storage_test_lib\",\n        \":gcs_test_util_lib\",\n        \":store_client_test_lib\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\ncc_library(\n    name = \"service_based_gcs_client_lib\",\n    srcs = glob(\n        [\n            \"src/ray/gcs/gcs_client/service_based_*.cc\",\n        ],\n    ),\n    hdrs = glob(\n        [\n            \"src/ray/gcs/gcs_client/service_based_*.h\",\n        ],\n    ),\n    copts = COPTS,\n    strip_include_prefix = \"src\",\n    deps = [\n        \":gcs\",\n        \":gcs_pub_sub_lib\",\n        \":gcs_service_rpc\",\n        \":redis_store_client\",\n    ],\n)\n\ncc_library(\n    name = \"global_state_accessor_lib\",\n    srcs = glob(\n        [\n            \"src/ray/gcs/gcs_client/global_state_accessor.cc\",\n        ],\n    ),\n    hdrs = glob(\n        [\n            \"src/ray/gcs/gcs_client/global_state_accessor.h\",\n        ],\n    ),\n    copts = COPTS,\n    strip_include_prefix = \"src\",\n    deps = [\n        \":service_based_gcs_client_lib\",\n    ],\n)\n\ncc_test(\n    name = \"global_state_accessor_test\",\n    srcs = [\n        \"src/ray/gcs/gcs_client/test/global_state_accessor_test.cc\",\n    ],\n    args = [\n        \"$(location redis-server)\",\n        \"$(location redis-cli)\",\n        \"$(location libray_redis_module.so)\",\n    ],\n    copts = COPTS,\n    data = [\n        \"//:libray_redis_module.so\",\n        \"//:redis-cli\",\n        \"//:redis-server\",\n    ],\n    deps = [\n        \":gcs_server_lib\",\n        \":gcs_test_util_lib\",\n        \":global_state_accessor_lib\",\n        \":service_based_gcs_client_lib\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\ncc_test(\n    name = \"gcs_server_test\",\n    srcs = [\n        \"src/ray/gcs/gcs_client/test/service_based_gcs_client_test.cc\",\n    ],\n    args = [\n        \"$(location redis-server)\",\n        \"$(location redis-cli)\",\n        \"$(location libray_redis_module.so)\",\n    ],\n    copts = COPTS,\n    data = [\n        \"//:libray_redis_module.so\",\n        \"//:redis-cli\",\n        \"//:redis-server\",\n    ],\n    deps = [\n        \":gcs_server_lib\",\n        \":gcs_test_util_lib\",\n        \":service_based_gcs_client_lib\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\ncc_test(\n    name = \"gcs_object_manager_test\",\n    srcs = [\n        \"src/ray/gcs/gcs_server/test/gcs_object_manager_test.cc\",\n    ],\n    copts = COPTS,\n    deps = [\n        \":gcs_server_lib\",\n        \":gcs_server_test_util\",\n        \":gcs_test_util_lib\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\ncc_library(\n    name = \"object_manager\",\n    srcs = glob([\n        \"src/ray/object_manager/*.cc\",\n        \"src/ray/object_manager/notification/*.cc\",\n    ]),\n    hdrs = glob([\n        \"src/ray/object_manager/*.h\",\n        \"src/ray/object_manager/notification/*.h\",\n    ]),\n    copts = COPTS,\n    strip_include_prefix = \"src\",\n    deps = [\n        \":gcs\",\n        \":object_manager_fbs\",\n        \":object_manager_rpc\",\n        \":plasma_store_server_lib\",\n        \":ray_common\",\n        \":ray_util\",\n        \"@boost//:asio\",\n    ],\n)\n\ncc_binary(\n    name = \"object_manager_test\",\n    testonly = 1,\n    srcs = [\"src/ray/object_manager/test/object_manager_test.cc\"],\n    copts = COPTS,\n    deps = [\n        \":object_manager\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\ncc_binary(\n    name = \"object_manager_stress_test\",\n    testonly = 1,\n    srcs = [\"src/ray/object_manager/test/object_manager_stress_test.cc\"],\n    copts = COPTS,\n    deps = [\n        \":object_manager\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\ncc_library(\n    name = \"platform_shims\",\n    srcs = [] + select({\n        \"@bazel_tools//src/conditions:windows\": glob([\n            \"src/shims/windows/**/*.c\",\n            \"src/shims/windows/**/*.cc\",\n            \"src/shims/windows/**/*.h\",\n        ]),\n        \"//conditions:default\": [],\n    }),\n    hdrs = [] + select({\n        \"@bazel_tools//src/conditions:windows\": glob([\n            \"src/shims/windows/**/*.h\",\n        ]),\n        \"//conditions:default\": [],\n    }),\n    copts = COPTS,\n    strip_include_prefix = select({\n        \"@bazel_tools//src/conditions:windows\": \"src/shims/windows\",\n        \"//conditions:default\": \"\",\n    }),\n    visibility = [\"//visibility:public\"],\n)\n\ncc_library(\n    name = \"ray_util\",\n    srcs = glob(\n        [\n            \"src/ray/util/*.cc\",\n        ],\n        exclude = [\n            \"src/ray/util/*_test.cc\",\n        ],\n    ),\n    hdrs = glob([\n        \"src/ray/util/*.h\",\n    ]),\n    copts = COPTS,\n    strip_include_prefix = \"src\",\n    visibility = [\"//visibility:public\"],\n    deps = [\n        \":sha256\",\n        \"@boost//:asio\",\n        \"@com_github_google_glog//:glog\",\n        \"@com_google_absl//absl/synchronization\",\n        \"@com_google_absl//absl/time\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\nfilegroup(\n    name = \"iwyu_sh\",\n    srcs = [\"ci/travis/iwyu.sh\"],\n)\n\nfilegroup(\n    name = \"extra_actions_base_proto\",\n    srcs = [\n        # TODO: Replace our file with the built-in copy once this issue is resolved:\n        #   https://github.com/bazelbuild/bazel/issues/8738\n        \"thirdparty/protobuf/extra_actions_base.proto\",\n        #\"@bazel_tools//src/main/protobuf:extra_actions_base.proto\",\n    ],\n)\n\naction_listener(\n    name = \"iwyu_cpp\",\n    extra_actions = [\":iwyu_action\"],\n    mnemonics = [\"CppCompile\"],\n)\n\nextra_action(\n    name = \"iwyu_action\",\n    cmd = \"$(location :iwyu_sh) $(location @com_google_protobuf//:protoc) $(location :extra_actions_base_proto) --extra_action_file=$(EXTRA_ACTION_FILE)\",\n    tools = [\n        \":extra_actions_base_proto\",\n        \":iwyu_sh\",\n        \"@com_google_protobuf//:protoc\",\n    ],\n)\n\ncc_library(\n    name = \"sha256\",\n    srcs = [\n        \"src/ray/thirdparty/sha256.c\",\n    ],\n    hdrs = [\n        \"src/ray/thirdparty/sha256.h\",\n    ],\n    copts = COPTS,\n    strip_include_prefix = \"src\",\n)\n\nalias(\n    name = \"hiredis\",\n    actual = \"@com_github_redis_hiredis//:hiredis\",\n)\n\ncc_library(\n    name = \"redis_client\",\n    srcs = [\n        \"src/ray/gcs/asio.cc\",\n        \"src/ray/gcs/redis_async_context.cc\",\n        \"src/ray/gcs/redis_client.cc\",\n        \"src/ray/gcs/redis_context.cc\",\n    ],\n    hdrs = [\n        \"src/ray/gcs/asio.h\",\n        \"src/ray/gcs/redis_async_context.h\",\n        \"src/ray/gcs/redis_client.h\",\n        \"src/ray/gcs/redis_context.h\",\n    ],\n    copts = COPTS,\n    strip_include_prefix = \"src\",\n    deps = [\n        \":hiredis\",\n        \":ray_common\",\n        \":ray_util\",\n        \":stats_lib\",\n        \"@boost//:asio\",\n    ],\n)\n\ncc_library(\n    name = \"redis_store_client\",\n    srcs = [\n        \"src/ray/gcs/store_client/redis_store_client.cc\",\n    ],\n    hdrs = [\n        \"src/ray/gcs/callback.h\",\n        \"src/ray/gcs/store_client/redis_store_client.h\",\n        \"src/ray/gcs/store_client/store_client.h\",\n    ],\n    copts = COPTS,\n    strip_include_prefix = \"src\",\n    deps = [\n        \"redis_client\",\n    ],\n)\n\ncc_library(\n    name = \"gcs_in_memory_store_client\",\n    srcs = [\n        \"src/ray/gcs/store_client/in_memory_store_client.cc\",\n    ],\n    hdrs = [\n        \"src/ray/gcs/callback.h\",\n        \"src/ray/gcs/store_client/in_memory_store_client.h\",\n        \"src/ray/gcs/store_client/store_client.h\",\n    ],\n    copts = COPTS,\n    strip_include_prefix = \"src\",\n    deps = [\n        \":ray_common\",\n        \":ray_util\",\n    ],\n)\n\ncc_library(\n    name = \"store_client_test_lib\",\n    hdrs = [\n        \"src/ray/gcs/store_client/test/store_client_test_base.h\",\n    ],\n    copts = COPTS,\n    strip_include_prefix = \"src\",\n    deps = [\n        \"redis_store_client\",\n    ],\n)\n\ncc_test(\n    name = \"redis_store_client_test\",\n    srcs = [\"src/ray/gcs/store_client/test/redis_store_client_test.cc\"],\n    args = [\n        \"$(location redis-server)\",\n        \"$(location redis-cli)\",\n        \"$(location libray_redis_module.so)\",\n    ],\n    copts = COPTS,\n    data = [\n        \"//:libray_redis_module.so\",\n        \"//:redis-cli\",\n        \"//:redis-server\",\n    ],\n    deps = [\n        \":redis_store_client\",\n        \":store_client_test_lib\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\ncc_test(\n    name = \"in_memory_store_client_test\",\n    srcs = [\"src/ray/gcs/store_client/test/in_memory_store_client_test.cc\"],\n    copts = COPTS,\n    deps = [\n        \":gcs_in_memory_store_client\",\n        \":store_client_test_lib\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\ncc_library(\n    name = \"gcs\",\n    srcs = glob(\n        [\n            \"src/ray/gcs/*.cc\",\n        ],\n        exclude = [\n            \"src/ray/gcs/*_test.cc\",\n        ],\n    ),\n    hdrs = glob([\n        \"src/ray/gcs/*.h\",\n    ]),\n    copts = COPTS,\n    strip_include_prefix = \"src\",\n    deps = [\n        \":gcs_cc_proto\",\n        \":hiredis\",\n        \":node_manager_fbs\",\n        \":node_manager_rpc\",\n        \":ray_common\",\n        \":ray_util\",\n        \":stats_lib\",\n        \"@boost//:asio\",\n    ],\n)\n\n# TODO(micafan) Support test group in future. Use test group we can run all gcs test once.\ncc_test(\n    name = \"redis_gcs_client_test\",\n    srcs = [\"src/ray/gcs/test/redis_gcs_client_test.cc\"],\n    args = [\n        \"$(location redis-server)\",\n        \"$(location redis-cli)\",\n        \"$(location libray_redis_module.so)\",\n    ],\n    copts = COPTS,\n    data = [\n        \"//:libray_redis_module.so\",\n        \"//:redis-cli\",\n        \"//:redis-server\",\n    ],\n    deps = [\n        \":gcs\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\ncc_test(\n    name = \"redis_actor_info_accessor_test\",\n    srcs = [\"src/ray/gcs/test/redis_actor_info_accessor_test.cc\"],\n    args = [\n        \"$(location redis-server)\",\n        \"$(location redis-cli)\",\n        \"$(location libray_redis_module.so)\",\n    ],\n    copts = COPTS,\n    data = [\n        \"//:libray_redis_module.so\",\n        \"//:redis-cli\",\n        \"//:redis-server\",\n    ],\n    deps = [\n        \":gcs\",\n        \":gcs_test_util_lib\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\ncc_test(\n    name = \"redis_object_info_accessor_test\",\n    srcs = [\"src/ray/gcs/test/redis_object_info_accessor_test.cc\"],\n    args = [\n        \"$(location redis-server)\",\n        \"$(location redis-cli)\",\n        \"$(location libray_redis_module.so)\",\n    ],\n    copts = COPTS,\n    data = [\n        \"//:libray_redis_module.so\",\n        \"//:redis-cli\",\n        \"//:redis-server\",\n    ],\n    deps = [\n        \":gcs\",\n        \":gcs_test_util_lib\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\ncc_test(\n    name = \"subscription_executor_test\",\n    srcs = [\"src/ray/gcs/test/subscription_executor_test.cc\"],\n    args = [\n        \"$(location redis-server)\",\n        \"$(location redis-cli)\",\n        \"$(location libray_redis_module.so)\",\n    ],\n    copts = COPTS,\n    data = [\n        \"//:libray_redis_module.so\",\n        \"//:redis-cli\",\n        \"//:redis-server\",\n    ],\n    deps = [\n        \":gcs\",\n        \":gcs_test_util_lib\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\ncc_test(\n    name = \"redis_job_info_accessor_test\",\n    srcs = [\"src/ray/gcs/test/redis_job_info_accessor_test.cc\"],\n    args = [\n        \"$(location redis-server)\",\n        \"$(location redis-cli)\",\n        \"$(location libray_redis_module.so)\",\n    ],\n    copts = COPTS,\n    data = [\n        \"//:libray_redis_module.so\",\n        \"//:redis-cli\",\n        \"//:redis-server\",\n    ],\n    deps = [\n        \":gcs\",\n        \":gcs_test_util_lib\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\ncc_test(\n    name = \"redis_node_info_accessor_test\",\n    srcs = [\"src/ray/gcs/test/redis_node_info_accessor_test.cc\"],\n    args = [\n        \"$(location redis-server)\",\n        \"$(location redis-cli)\",\n        \"$(location libray_redis_module.so)\",\n    ],\n    copts = COPTS,\n    data = [\n        \"//:libray_redis_module.so\",\n        \"//:redis-cli\",\n        \"//:redis-server\",\n    ],\n    deps = [\n        \":gcs\",\n        \":gcs_test_util_lib\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\ncc_test(\n    name = \"asio_test\",\n    srcs = [\"src/ray/gcs/test/asio_test.cc\"],\n    args = [\n        \"$(location redis-server)\",\n        \"$(location redis-cli)\",\n        \"$(location libray_redis_module.so)\",\n    ],\n    copts = COPTS,\n    data = [\n        \"//:libray_redis_module.so\",\n        \"//:redis-cli\",\n        \"//:redis-server\",\n    ],\n    deps = [\n        \":gcs\",\n        \":ray_util\",\n        \"@com_google_googletest//:gtest_main\",\n    ],\n)\n\nflatbuffer_cc_library(\n    name = \"node_manager_fbs\",\n    srcs = [\"src/ray/raylet/format/node_manager.fbs\"],\n    flatc_args = FLATC_ARGS,\n    out_prefix = \"ray/raylet/format/\",\n)\n\nflatbuffer_cc_library(\n    name = \"object_manager_fbs\",\n    srcs = [\"src/ray/object_manager/format/object_manager.fbs\"],\n    flatc_args = FLATC_ARGS,\n    out_prefix = \"src/ray/object_manager/format/\",\n)\n\npyx_library(\n    name = \"_raylet\",\n    srcs = glob([\n        \"python/ray/__init__.py\",\n        \"python/ray/_raylet.pxd\",\n        \"python/ray/_raylet.pyx\",\n        \"python/ray/includes/*.pxd\",\n        \"python/ray/includes/*.pxi\",\n    ]),\n    # Export ray ABI symbols, which can then be used by _streaming.so.\n    # We need to dlopen this lib with RTLD_GLOBAL to use ABI in this\n    # shared lib, see python/ray/__init__.py.\n    cc_kwargs = dict(\n        srcs = PYX_SRCS,\n        copts = COPTS + PYX_COPTS,\n        # see https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/lite/BUILD#L444\n        linkopts = select({\n            \"@bazel_tools//src/conditions:darwin\": [\n                \"-Wl,-exported_symbols_list,$(location //:src/ray/ray_exported_symbols.lds)\",\n            ],\n            \"@bazel_tools//src/conditions:windows\": [\n            ],\n            \"//conditions:default\": [\n                \"-Wl,--version-script,$(location //:src/ray/ray_version_script.lds)\",\n            ],\n        }),\n        linkstatic = 1,\n    ),\n    deps = [\n        \"//:core_worker_lib\",\n        \"//:global_state_accessor_lib\",\n        \"//:ray_util\",\n        \"//:raylet_lib\",\n        \"//:serialization_cc_proto\",\n        \"//:src/ray/ray_exported_symbols.lds\",\n        \"//:src/ray/ray_version_script.lds\",\n        \"//:stats_lib\",\n    ],\n)\n\npyx_library(\n    name = \"_streaming\",\n    srcs = glob([\n        \"python/ray/streaming/_streaming.pyx\",\n        \"python/ray/__init__.py\",\n        \"python/ray/_raylet.pxd\",\n        \"python/ray/includes/*.pxd\",\n        \"python/ray/includes/*.pxi\",\n        \"python/ray/streaming/__init__.pxd\",\n        \"python/ray/streaming/includes/*.pxd\",\n        \"python/ray/streaming/includes/*.pxi\",\n    ]),\n    cc_kwargs = dict(\n        srcs = PYX_SRCS,\n        copts = COPTS + PYX_COPTS,\n    ),\n    deps = [\n        \"//streaming:streaming_lib\",\n    ],\n)\n\ncc_binary(\n    name = \"libcore_worker_library_java.so\",\n    srcs = glob([\n        \"src/ray/core_worker/lib/java/*.h\",\n        \"src/ray/core_worker/lib/java/*.cc\",\n    ]),\n    copts = COPTS,\n    # Export ray ABI symbols, which can then be used by libstreaming_java.so. see `//:_raylet`\n    linkopts = select({\n        \"@bazel_tools//src/conditions:darwin\": [\n            \"-Wl,-exported_symbols_list,$(location //:src/ray/ray_exported_symbols.lds)\",\n        ],\n        \"@bazel_tools//src/conditions:windows\": [\n        ],\n        \"//conditions:default\": [\n            \"-Wl,--version-script,$(location //:src/ray/ray_version_script.lds)\",\n        ],\n    }),\n    linkshared = 1,\n    linkstatic = 1,\n    visibility = [\"//java:__subpackages__\"],\n    deps = [\n        \"//:core_worker_lib\",\n        \"//:global_state_accessor_lib\",\n        \"//:src/ray/ray_exported_symbols.lds\",\n        \"//:src/ray/ray_version_script.lds\",\n        \"//:stats_lib\",\n        \"@bazel_tools//tools/jdk:jni\",\n    ],\n)\n\nfilegroup(\n    name = \"python_sources\",\n    srcs = glob([\n        \"python/ray/*.py\",\n        \"python/ray/autoscaler/*.py\",\n        \"python/ray/autoscaler/aws/example-full.yaml\",\n        \"python/ray/autoscaler/azure/example-full.yaml\",\n        \"python/ray/autoscaler/gcp/example-full.yaml\",\n        \"python/ray/autoscaler/local/example-full.yaml\",\n        \"python/ray/cloudpickle/*.py\",\n        \"python/ray/core/__init__.py\",\n        \"python/ray/core/generated/__init__.py\",\n        \"python/ray/core/generated/ray/__init__.py\",\n        \"python/ray/core/generated/ray/protocol/__init__.py\",\n        \"python/ray/dashboard/*.py\",\n        \"python/ray/dashboard/metrics_exporter/*.py\",\n        \"python/ray/experimental/*.py\",\n        \"python/ray/util/*.py\",\n        \"python/ray/internal/*.py\",\n        \"python/ray/projects/*.py\",\n        \"python/ray/projects/schema.json\",\n        \"python/ray/projects/templates/cluster_template.yaml\",\n        \"python/ray/projects/templates/project_template.yaml\",\n        \"python/ray/projects/templates/requirements.txt\",\n        \"python/ray/workers/default_worker.py\",\n    ]),\n)\n\nalias(\n    name = \"redis-server\",\n    actual = select({\n        \"@bazel_tools//src/conditions:windows\": \"@com_github_tporadowski_redis_bin//:redis-server.exe\",\n        \"//conditions:default\": \"@com_github_antirez_redis//:redis-server\",\n    }),\n    visibility = [\"//visibility:public\"],\n)\n\nalias(\n    name = \"redis-cli\",\n    actual = select({\n        \"@bazel_tools//src/conditions:windows\": \"@com_github_tporadowski_redis_bin//:redis-cli.exe\",\n        \"//conditions:default\": \"@com_github_antirez_redis//:redis-cli\",\n    }),\n    visibility = [\"//visibility:public\"],\n)\n\ncc_library(\n    name = \"ray_redis_module\",\n    hdrs = [\n        \"src/ray/gcs/redis_module/redis_string.h\",\n        \"src/ray/gcs/redis_module/redismodule.h\",\n    ],\n    copts = COPTS,\n    strip_include_prefix = \"src\",\n)\n\ncc_binary(\n    name = \"libray_redis_module.so\",\n    srcs = [\n        \"src/ray/gcs/redis_module/ray_redis_module.cc\",\n    ],\n    copts = COPTS,\n    linkshared = 1,\n    linkstatic = 1,\n    visibility = [\"//java:__subpackages__\"],\n    deps = [\n        \":gcs_cc_proto\",\n        \":ray_common\",\n        \":ray_redis_module\",\n    ],\n)\n\nfilegroup(\n    name = \"all_py_proto\",\n    srcs = [\n        \"common_py_proto\",\n        \"core_worker_py_proto\",\n        \"gcs_py_proto\",\n        \"node_manager_py_proto\",\n        \"reporter_py_proto\",\n    ],\n)\n\n# This is a dummy test dependency that causes the python tests to be\n# re-run if any of these files changes.\npy_library(\n    name = \"ray_lib\",\n    srcs = glob(\n        [\"python/ray/**/*.py\"],\n        exclude = [\"python/ray/tests/*.py\"],\n    ),\n    visibility = [\"__subpackages__\"],\n)\n\ncopy_to_workspace(\n    name = \"cp_raylet_so\",\n    srcs = [\"python/ray/_raylet.so\"],\n    dstdir = \"python/ray\",\n)\n\ncopy_to_workspace(\n    name = \"cp_streaming\",\n    srcs = [\"python/ray/streaming/_streaming.so\"],\n    dstdir = \"python/ray/streaming\",\n)\n\ncopy_to_workspace(\n    name = \"cp_all_py_proto\",\n    srcs = [\":all_py_proto\"],\n    dstdir = \"python/ray/core/generated\",\n)\n\ncopy_to_workspace(\n    name = \"cp_redis\",\n    srcs = [\n        \":redis-cli\",\n        \":redis-server\",\n    ],\n    dstdir = \"python/ray/core/src/ray/thirdparty/redis/src\",\n)\n\ncopy_to_workspace(\n    name = \"cp_libray_redis_module\",\n    srcs = [\":libray_redis_module.so\"],\n    dstdir = \"python/ray/core/src/ray/gcs/redis_module\",\n)\n\ncopy_to_workspace(\n    name = \"cp_raylet\",\n    srcs = [\":raylet\"],\n    dstdir = \"python/ray/core/src/ray/raylet\",\n)\n\ncopy_to_workspace(\n    name = \"cp_gcs_server\",\n    srcs = [\":gcs_server\"],\n    dstdir = \"python/ray/core/src/ray/gcs\",\n)\n\ncopy_to_workspace(\n    name = \"cp_plasma_store_server\",\n    srcs = [\":plasma_store_server\"],\n    dstdir = \"python/ray/core/src/plasma\",\n)\n\ngenrule(\n    name = \"ray_pkg\",\n    srcs = [\n        \":cp_raylet_so\",\n        \":cp_streaming\",\n        \":python_sources\",\n        \":cp_all_py_proto\",\n        \":cp_redis\",\n        \":cp_libray_redis_module\",\n        \":cp_raylet\",\n        \":cp_gcs_server\",\n        \":cp_plasma_store_server\",\n        \"//streaming:copy_streaming_py_proto\",\n    ],\n    outs = [\"ray_pkg.out\"],\n    cmd = \"\"\"\n        if [ \"$${OSTYPE-}\" = \"msys\" ]; then\n            ln -P -f -- python/ray/_raylet.so python/ray/_raylet.pyd\n        fi\n        # NOTE(hchen): Protobuf doesn't allow specifying Python package name. So we use this `sed`\n        # command to change the import path in the generated file.\n        files=(\n            python/ray/core/generated/gcs_pb2.py\n            python/ray/core/generated/common_pb2.py\n            python/ray/core/generated/node_manager_pb2.py\n            python/ray/core/generated/node_manager_pb2_grpc.py\n            python/ray/core/generated/reporter_pb2.py\n            python/ray/core/generated/reporter_pb2_grpc.py\n            python/ray/core/generated/core_worker_pb2.py\n            python/ray/core/generated/core_worker_pb2_grpc.py\n        )\n        sed -i -E 's/from src.ray.protobuf/from ./' \"$${files[@]}\"\n        echo \"$${PWD}\" > $@\n    \"\"\",\n    local = 1,\n)\n",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/src/ray/gcs/redis_module/ray_redis_module.cc": "// Copyright 2017 The Ray Authors.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//  http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n#include <string.h>\n\n#include <sstream>\n\n#include \"ray/common/common_protocol.h\"\n#include \"ray/common/id.h\"\n#include \"ray/common/status.h\"\n#include \"ray/gcs/redis_module/redis_string.h\"\n#include \"ray/gcs/redis_module/redismodule.h\"\n#include \"ray/util/logging.h\"\n#include \"src/ray/protobuf/gcs.pb.h\"\n\nusing ray::Status;\nusing ray::rpc::GcsChangeMode;\nusing ray::rpc::GcsEntry;\nusing ray::rpc::TablePrefix;\nusing ray::rpc::TablePubsub;\n\n#if RAY_USE_NEW_GCS\n// Under this flag, ray-project/credis will be loaded.  Specifically, via\n// \"path/redis-server --loadmodule <credis module> --loadmodule <current\n// libray_redis_module>\" (dlopen() under the hood) will a definition of \"module\"\n// be supplied.\n//\n// All commands in this file that depend on \"module\" must be wrapped by \"#if\n// RAY_USE_NEW_GCS\", until we switch to this launch configuration as the\n// default.\n#include \"ray/gcs/redis_module/chain_module.h\"\nextern RedisChainModule module;\n#endif\n\n#define REPLY_AND_RETURN_IF_FALSE(CONDITION, MESSAGE) \\\n  if (!(CONDITION)) {                                 \\\n    RedisModule_ReplyWithError(ctx, (MESSAGE));       \\\n    return REDISMODULE_ERR;                           \\\n  }\n\n// This macro can be used at the top level of redis module.\n#define REPLY_AND_RETURN_IF_NOT_OK(STATUS)                       \\\n  {                                                              \\\n    auto status = (STATUS);                                      \\\n    if (!status.ok()) {                                          \\\n      RedisModule_ReplyWithError(ctx, status.message().c_str()); \\\n      return REDISMODULE_ERR;                                    \\\n    }                                                            \\\n  }\n\n// Wrap a Redis command with automatic memory management.\n#define AUTO_MEMORY(FUNC)                                             \\\n  int FUNC(RedisModuleCtx *ctx, RedisModuleString **argv, int argc) { \\\n    RedisModule_AutoMemory(ctx);                                      \\\n    return internal_redis_commands::FUNC(ctx, argv, argc);            \\\n  }\n\n// Commands in this namespace should not be used directly. They should first be\n// wrapped with AUTO_MEMORY in the global namespace to enable automatic memory\n// management.\n// TODO(swang): Ideally, we would make the commands that don't have auto memory\n// management inaccessible instead of just using a separate namespace.\nnamespace internal_redis_commands {\n\n/// Map from pub sub channel to clients that are waiting on that channel.\nstd::unordered_map<std::string, std::vector<std::string>> notification_map;\n\n/// Parse a Redis string into a TablePubsub channel.\nStatus ParseTablePubsub(TablePubsub *out, const RedisModuleString *pubsub_channel_str) {\n  long long pubsub_channel_long;\n  if (RedisModule_StringToLongLong(pubsub_channel_str, &pubsub_channel_long) !=\n      REDISMODULE_OK) {\n    return Status::RedisError(\"Pubsub channel must be a valid integer.\");\n  }\n  if (pubsub_channel_long >= static_cast<long long>(TablePubsub::TABLE_PUBSUB_MAX) ||\n      pubsub_channel_long <= static_cast<long long>(TablePubsub::TABLE_PUBSUB_MIN)) {\n    return Status::RedisError(\"Pubsub channel must be in the TablePubsub range.\");\n  } else {\n    *out = static_cast<TablePubsub>(pubsub_channel_long);\n    return Status::OK();\n  }\n}\n\n/// Format a pubsub channel for a specific key. pubsub_channel_str should\n/// contain a valid TablePubsub.\nStatus FormatPubsubChannel(RedisModuleString **out, RedisModuleCtx *ctx,\n                           const RedisModuleString *pubsub_channel_str,\n                           const RedisModuleString *id) {\n  // Format the pubsub channel enum to a string. TablePubsub_MAX should be more\n  // than enough digits, but add 1 just in case for the null terminator.\n  char pubsub_channel[static_cast<int>(TablePubsub::TABLE_PUBSUB_MAX) + 1];\n  TablePubsub table_pubsub;\n  RAY_RETURN_NOT_OK(ParseTablePubsub(&table_pubsub, pubsub_channel_str));\n  sprintf(pubsub_channel, \"%d\", static_cast<int>(table_pubsub));\n  *out = RedisString_Format(ctx, \"%s:%S\", pubsub_channel, id);\n  return Status::OK();\n}\n\n/// Parse a Redis string into a TablePrefix channel.\nStatus ParseTablePrefix(const RedisModuleString *table_prefix_str, TablePrefix *out) {\n  long long table_prefix_long;\n  if (RedisModule_StringToLongLong(table_prefix_str, &table_prefix_long) !=\n      REDISMODULE_OK) {\n    return Status::RedisError(\"Prefix must be a valid TablePrefix integer\");\n  }\n  if (table_prefix_long >= static_cast<long long>(TablePrefix::TABLE_PREFIX_MAX) ||\n      table_prefix_long <= static_cast<long long>(TablePrefix::TABLE_PREFIX_MIN)) {\n    return Status::RedisError(\"Prefix must be in the TablePrefix range\");\n  } else {\n    *out = static_cast<TablePrefix>(table_prefix_long);\n    return Status::OK();\n  }\n}\n\n/// Format the string for a table key. `prefix_enum` must be a valid\n/// TablePrefix as a RedisModuleString. `keyname` is usually a UniqueID as a\n/// RedisModuleString.\nRedisModuleString *PrefixedKeyString(RedisModuleCtx *ctx, RedisModuleString *prefix_enum,\n                                     RedisModuleString *keyname) {\n  TablePrefix prefix;\n  if (!ParseTablePrefix(prefix_enum, &prefix).ok()) {\n    return nullptr;\n  }\n  return RedisString_Format(ctx, \"%s%S\", TablePrefix_Name(prefix).c_str(), keyname);\n}\n\n// TODO(swang): This helper function should be deprecated by the version below,\n// which uses enums for table prefixes.\nRedisModuleKey *OpenPrefixedKey(RedisModuleCtx *ctx, const char *prefix,\n                                RedisModuleString *keyname, int mode,\n                                RedisModuleString **mutated_key_str) {\n  RedisModuleString *prefixed_keyname = RedisString_Format(ctx, \"%s%S\", prefix, keyname);\n  // Pass out the key being mutated, should the caller request so.\n  if (mutated_key_str != nullptr) {\n    *mutated_key_str = prefixed_keyname;\n  }\n  RedisModuleKey *key = reinterpret_cast<RedisModuleKey *>(\n      RedisModule_OpenKey(ctx, prefixed_keyname, mode));\n  return key;\n}\n\nStatus OpenPrefixedKey(RedisModuleKey **out, RedisModuleCtx *ctx,\n                       RedisModuleString *prefix_enum, RedisModuleString *keyname,\n                       int mode, RedisModuleString **mutated_key_str) {\n  TablePrefix prefix;\n  RAY_RETURN_NOT_OK(ParseTablePrefix(prefix_enum, &prefix));\n  *out = OpenPrefixedKey(ctx, TablePrefix_Name(prefix).c_str(), keyname, mode,\n                         mutated_key_str);\n  return Status::OK();\n}\n\nRedisModuleKey *OpenPrefixedKey(RedisModuleCtx *ctx, const char *prefix,\n                                RedisModuleString *keyname, int mode) {\n  return OpenPrefixedKey(ctx, prefix, keyname, mode,\n                         /*mutated_key_str=*/nullptr);\n}\n\nStatus OpenPrefixedKey(RedisModuleKey **out, RedisModuleCtx *ctx,\n                       RedisModuleString *prefix_enum, RedisModuleString *keyname,\n                       int mode) {\n  return OpenPrefixedKey(out, ctx, prefix_enum, keyname, mode,\n                         /*mutated_key_str=*/nullptr);\n}\n\n/// Open the key used to store the channels that should be published to when an\n/// update happens at the given keyname.\nStatus GetBroadcastKey(RedisModuleCtx *ctx, RedisModuleString *pubsub_channel_str,\n                       RedisModuleString *keyname, std::string *out) {\n  RedisModuleString *channel;\n  RAY_RETURN_NOT_OK(FormatPubsubChannel(&channel, ctx, pubsub_channel_str, keyname));\n  RedisModuleString *prefixed_keyname = RedisString_Format(ctx, \"BCAST:%S\", channel);\n  *out = RedisString_ToString(prefixed_keyname);\n  return Status::OK();\n}\n\n/// A helper function that creates `GcsEntry` protobuf object.\n///\n/// \\param[in] id Id of the entry.\n/// \\param[in] change_mode Change mode of the entry.\n/// \\param[in] entries Vector of entries.\n/// \\param[out] result The created `GcsEntry` object.\ninline void CreateGcsEntry(RedisModuleString *id, GcsChangeMode change_mode,\n                           const std::vector<RedisModuleString *> &entries,\n                           GcsEntry *result) {\n  const char *data;\n  size_t size;\n  data = RedisModule_StringPtrLen(id, &size);\n  result->set_id(data, size);\n  result->set_change_mode(change_mode);\n  for (const auto &entry : entries) {\n    data = RedisModule_StringPtrLen(entry, &size);\n    result->add_entries(data, size);\n  }\n}\n\n/// Helper method to publish formatted data to target channel.\n///\n/// \\param pubsub_channel_str The pubsub channel name that notifications for\n/// this key should be published to. When publishing to a specific client, the\n/// channel name should be <pubsub_channel>:<client_id>.\n/// \\param id The ID of the key that the notification is about.\n/// \\param data_buffer The data to publish, which is a GcsEntry buffer.\n/// \\return OK if there is no error during a publish.\nint PublishDataHelper(RedisModuleCtx *ctx, RedisModuleString *pubsub_channel_str,\n                      RedisModuleString *id, RedisModuleString *data_buffer) {\n  // Write the data back to any subscribers that are listening to all table\n  // notifications.\n  RedisModuleCallReply *reply =\n      RedisModule_Call(ctx, \"PUBLISH\", \"ss\", pubsub_channel_str, data_buffer);\n  if (reply == NULL) {\n    return RedisModule_ReplyWithError(ctx, \"error during PUBLISH\");\n  }\n\n  std::string notification_key;\n  REPLY_AND_RETURN_IF_NOT_OK(\n      GetBroadcastKey(ctx, pubsub_channel_str, id, &notification_key));\n  // Publish the data to any clients who requested notifications on this key.\n  auto it = notification_map.find(notification_key);\n  if (it != notification_map.end()) {\n    for (const std::string &client_channel : it->second) {\n      // RedisModule_Call seems to be broken and cannot accept \"bb\",\n      // therefore we construct a temporary redis string here, which\n      // will be garbage collected by redis.\n      auto channel =\n          RedisModule_CreateString(ctx, client_channel.data(), client_channel.size());\n      RedisModuleCallReply *reply =\n          RedisModule_Call(ctx, \"PUBLISH\", \"ss\", channel, data_buffer);\n      if (reply == NULL) {\n        return RedisModule_ReplyWithError(ctx, \"error during PUBLISH\");\n      }\n    }\n  }\n  return RedisModule_ReplyWithSimpleString(ctx, \"OK\");\n}\n\n/// Publish a notification for an entry update at a key. This publishes a\n/// notification to all subscribers of the table, as well as every client that\n/// has requested notifications for this key.\n///\n/// \\param pubsub_channel_str The pubsub channel name that notifications for\n/// this key should be published to. When publishing to a specific client, the\n/// channel name should be <pubsub_channel>:<client_id>.\n/// \\param id The ID of the key that the notification is about.\n/// \\param mode the update mode, such as append or remove.\n/// \\param data The appended/removed data.\n/// \\return OK if there is no error during a publish.\nint PublishTableUpdate(RedisModuleCtx *ctx, RedisModuleString *pubsub_channel_str,\n                       RedisModuleString *id, GcsChangeMode change_mode,\n                       RedisModuleString *data) {\n  // Serialize the notification to send.\n  GcsEntry gcs_entry;\n  CreateGcsEntry(id, change_mode, {data}, &gcs_entry);\n  std::string str = gcs_entry.SerializeAsString();\n  auto data_buffer = RedisModule_CreateString(ctx, str.data(), str.size());\n  return PublishDataHelper(ctx, pubsub_channel_str, id, data_buffer);\n}\n\n// RAY.TABLE_ADD:\n//   TableAdd_RedisCommand: the actual command handler.\n//   (helper) TableAdd_DoWrite: performs the write to redis state.\n//   (helper) TableAdd_DoPublish: performs a publish after the write.\n//   ChainTableAdd_RedisCommand: the same command, chain-enabled.\n\nint TableAdd_DoWrite(RedisModuleCtx *ctx, RedisModuleString **argv, int argc,\n                     RedisModuleString **mutated_key_str) {\n  if (argc != 5) {\n    return RedisModule_WrongArity(ctx);\n  }\n  RedisModuleString *prefix_str = argv[1];\n  RedisModuleString *id = argv[3];\n  RedisModuleString *data = argv[4];\n\n  RedisModuleKey *key;\n  REPLY_AND_RETURN_IF_NOT_OK(OpenPrefixedKey(\n      &key, ctx, prefix_str, id, REDISMODULE_READ | REDISMODULE_WRITE, mutated_key_str));\n  RedisModule_StringSet(key, data);\n  return REDISMODULE_OK;\n}\n\nint TableAdd_DoPublish(RedisModuleCtx *ctx, RedisModuleString **argv, int argc) {\n  if (argc != 5) {\n    return RedisModule_WrongArity(ctx);\n  }\n  RedisModuleString *pubsub_channel_str = argv[2];\n  RedisModuleString *id = argv[3];\n  RedisModuleString *data = argv[4];\n\n  TablePubsub pubsub_channel;\n  REPLY_AND_RETURN_IF_NOT_OK(ParseTablePubsub(&pubsub_channel, pubsub_channel_str));\n\n  if (pubsub_channel != TablePubsub::NO_PUBLISH) {\n    // All other pubsub channels write the data back directly onto the channel.\n    return PublishTableUpdate(ctx, pubsub_channel_str, id, GcsChangeMode::APPEND_OR_ADD,\n                              data);\n  } else {\n    return RedisModule_ReplyWithSimpleString(ctx, \"OK\");\n  }\n}\n\n/// Add an entry at a key. This overwrites any existing data at the key.\n/// Publishes a notification about the update to all subscribers, if a pubsub\n/// channel is provided.\n///\n/// This is called from a client with the command:\n///\n///    RAY.TABLE_ADD <table_prefix> <pubsub_channel> <id> <data>\n///\n/// \\param table_prefix The prefix string for keys in this table.\n/// \\param pubsub_channel The pubsub channel name that notifications for\n/// this key should be published to. When publishing to a specific client, the\n/// channel name should be <pubsub_channel>:<client_id>.\n/// \\param id The ID of the key to set.\n/// \\param data The data to insert at the key.\n/// \\return The current value at the key, or OK if there is no value.\nint TableAdd_RedisCommand(RedisModuleCtx *ctx, RedisModuleString **argv, int argc) {\n  TableAdd_DoWrite(ctx, argv, argc, /*mutated_key_str=*/nullptr);\n  return TableAdd_DoPublish(ctx, argv, argc);\n}\n\n#if RAY_USE_NEW_GCS\nint ChainTableAdd_RedisCommand(RedisModuleCtx *ctx, RedisModuleString **argv, int argc) {\n  return module.ChainReplicate(ctx, argv, argc, /*node_func=*/TableAdd_DoWrite,\n                               /*tail_func=*/TableAdd_DoPublish);\n}\n#endif\n\nint TableAppend_DoWrite(RedisModuleCtx *ctx, RedisModuleString **argv, int argc,\n                        RedisModuleString **mutated_key_str) {\n  if (argc < 5 || argc > 6) {\n    return RedisModule_WrongArity(ctx);\n  }\n\n  RedisModuleString *prefix_str = argv[1];\n  RedisModuleString *id = argv[3];\n  RedisModuleString *data = argv[4];\n  RedisModuleString *index_str = nullptr;\n  if (argc == 6) {\n    index_str = argv[5];\n  }\n\n  // Set the keys in the table.\n  RedisModuleKey *key;\n  REPLY_AND_RETURN_IF_NOT_OK(OpenPrefixedKey(\n      &key, ctx, prefix_str, id, REDISMODULE_READ | REDISMODULE_WRITE, mutated_key_str));\n  int type = RedisModule_KeyType(key);\n  REPLY_AND_RETURN_IF_FALSE(\n      type == REDISMODULE_KEYTYPE_LIST || type == REDISMODULE_KEYTYPE_EMPTY,\n      \"TABLE_APPEND entries must be a list or an empty list\");\n\n  // Determine the index at which the data should be appended. If no index is\n  // requested, then is the current length of the log.\n  size_t index = RedisModule_ValueLength(key);\n  if (index_str != nullptr) {\n    // Parse the requested index.\n    long long requested_index;\n    REPLY_AND_RETURN_IF_FALSE(\n        RedisModule_StringToLongLong(index_str, &requested_index) == REDISMODULE_OK,\n        \"Index is not a number.\");\n    REPLY_AND_RETURN_IF_FALSE(requested_index >= 0, \"Index is less than 0.\");\n    index = static_cast<size_t>(requested_index);\n  }\n  // Only perform the append if the requested index matches the current length\n  // of the log, or if no index was requested.\n  if (index == RedisModule_ValueLength(key)) {\n    // The requested index matches the current length of the log or no index\n    // was requested. Perform the append.\n    if (RedisModule_ListPush(key, REDISMODULE_LIST_TAIL, data) == REDISMODULE_OK) {\n      return REDISMODULE_OK;\n    } else {\n      static const char *reply = \"Unexpected error during TABLE_APPEND\";\n      RedisModule_ReplyWithError(ctx, reply);\n      return REDISMODULE_ERR;\n    }\n  } else {\n    // The requested index did not match the current length of the log. Return\n    // an error message as a string.\n    static const char *reply = \"ERR entry exists\";\n    RedisModule_ReplyWithSimpleString(ctx, reply);\n    return REDISMODULE_ERR;\n  }\n}\n\nint TableAppend_DoPublish(RedisModuleCtx *ctx, RedisModuleString **argv, int /*argc*/) {\n  RedisModuleString *pubsub_channel_str = argv[2];\n  RedisModuleString *id = argv[3];\n  RedisModuleString *data = argv[4];\n  // Publish a message on the requested pubsub channel if necessary.\n  TablePubsub pubsub_channel;\n  REPLY_AND_RETURN_IF_NOT_OK(ParseTablePubsub(&pubsub_channel, pubsub_channel_str));\n  if (pubsub_channel != TablePubsub::NO_PUBLISH) {\n    // All other pubsub channels write the data back directly onto the\n    // channel.\n    return PublishTableUpdate(ctx, pubsub_channel_str, id, GcsChangeMode::APPEND_OR_ADD,\n                              data);\n  } else {\n    return RedisModule_ReplyWithSimpleString(ctx, \"OK\");\n  }\n}\n\n/// Append an entry to the log stored at a key. Publishes a notification about\n/// the update to all subscribers, if a pubsub channel is provided.\n///\n/// This is called from a client with the command:\n//\n///    RAY.TABLE_APPEND <table_prefix> <pubsub_channel> <id> <data>\n///                     <index (optional)>\n///\n/// \\param table_prefix The prefix string for keys in this table.\n/// \\param pubsub_channel The pubsub channel name that notifications for this\n/// key should be published to. When publishing to a specific client, the\n/// channel name should be <pubsub_channel>:<client_id>.\n/// \\param id The ID of the key to append to.\n/// \\param data The data to append to the key.\n/// \\param index If this is set, then the data must be appended at this index.\n/// If the current log is shorter or longer than the requested index, then the\n/// append will fail and an error message will be returned as a string.\n/// \\return OK if the append succeeds, or an error message string if the append\n/// fails.\nint TableAppend_RedisCommand(RedisModuleCtx *ctx, RedisModuleString **argv, int argc) {\n  if (TableAppend_DoWrite(ctx, argv, argc, /*mutated_key_str=*/nullptr) !=\n      REDISMODULE_OK) {\n    return REDISMODULE_ERR;\n  }\n  return TableAppend_DoPublish(ctx, argv, argc);\n}\n\n#if RAY_USE_NEW_GCS\nint ChainTableAppend_RedisCommand(RedisModuleCtx *ctx, RedisModuleString **argv,\n                                  int argc) {\n  return module.ChainReplicate(ctx, argv, argc,\n                               /*node_func=*/TableAppend_DoWrite,\n                               /*tail_func=*/TableAppend_DoPublish);\n}\n#endif\n\nint Set_DoPublish(RedisModuleCtx *ctx, RedisModuleString **argv, bool is_add) {\n  RedisModuleString *pubsub_channel_str = argv[2];\n  RedisModuleString *id = argv[3];\n  RedisModuleString *data = argv[4];\n  // Publish a message on the requested pubsub channel if necessary.\n  TablePubsub pubsub_channel;\n  REPLY_AND_RETURN_IF_NOT_OK(ParseTablePubsub(&pubsub_channel, pubsub_channel_str));\n  if (pubsub_channel != TablePubsub::NO_PUBLISH) {\n    // All other pubsub channels write the data back directly onto the\n    // channel.\n    return PublishTableUpdate(\n        ctx, pubsub_channel_str, id,\n        is_add ? GcsChangeMode::APPEND_OR_ADD : GcsChangeMode::REMOVE, data);\n  } else {\n    return RedisModule_ReplyWithSimpleString(ctx, \"OK\");\n  }\n}\n\nint Set_DoWrite(RedisModuleCtx *ctx, RedisModuleString **argv, int argc, bool is_add,\n                bool *changed) {\n  if (argc != 5) {\n    return RedisModule_WrongArity(ctx);\n  }\n\n  RedisModuleString *prefix_str = argv[1];\n  RedisModuleString *id = argv[3];\n  RedisModuleString *data = argv[4];\n\n  RedisModuleString *key_string = PrefixedKeyString(ctx, prefix_str, id);\n  // TODO(kfstorm): According to https://redis.io/topics/modules-intro,\n  // set type API is not available yet. We can change RedisModule_Call to\n  // set type API later.\n  RedisModuleCallReply *reply =\n      RedisModule_Call(ctx, is_add ? \"SADD\" : \"SREM\", \"ss\", key_string, data);\n  if (RedisModule_CallReplyType(reply) != REDISMODULE_REPLY_ERROR) {\n    *changed = RedisModule_CallReplyInteger(reply) > 0;\n    if (!is_add && *changed) {\n      // try to delete the empty set.\n      RedisModuleKey *key;\n      REPLY_AND_RETURN_IF_NOT_OK(\n          OpenPrefixedKey(&key, ctx, prefix_str, id, REDISMODULE_WRITE));\n      auto size = RedisModule_ValueLength(key);\n      if (size == 0) {\n        REPLY_AND_RETURN_IF_FALSE(RedisModule_DeleteKey(key) == REDISMODULE_OK,\n                                  \"ERR Failed to delete empty set.\");\n      }\n    }\n    return REDISMODULE_OK;\n  } else {\n    // the SADD/SREM command failed\n    RedisModule_ReplyWithCallReply(ctx, reply);\n    return REDISMODULE_ERR;\n  }\n}\n\n/// Add an entry to the set stored at a key. Publishes a notification about\n/// the update to all subscribers, if a pubsub channel is provided.\n///\n/// This is called from a client with the command:\n//\n///    RAY.SET_ADD <table_prefix> <pubsub_channel> <id> <data>\n///\n/// \\param table_prefix The prefix string for keys in this set.\n/// \\param pubsub_channel The pubsub channel name that notifications for this\n/// key should be published to. When publishing to a specific client, the\n/// channel name should be <pubsub_channel>:<client_id>.\n/// \\param id The ID of the key to add to.\n/// \\param data The data to add to the key.\n/// \\return OK if the add succeeds, or an error message string if the add fails.\nint SetAdd_RedisCommand(RedisModuleCtx *ctx, RedisModuleString **argv, int argc) {\n  bool changed;\n  if (Set_DoWrite(ctx, argv, argc, /*is_add=*/true, &changed) != REDISMODULE_OK) {\n    return REDISMODULE_ERR;\n  }\n  if (changed) {\n    return Set_DoPublish(ctx, argv, /*is_add=*/true);\n  }\n  return RedisModule_ReplyWithSimpleString(ctx, \"OK\");\n}\n\n/// Remove an entry from the set stored at a key. Publishes a notification about\n/// the update to all subscribers, if a pubsub channel is provided.\n///\n/// This is called from a client with the command:\n//\n///    RAY.SET_REMOVE <table_prefix> <pubsub_channel> <id> <data>\n///\n/// \\param table_prefix The prefix string for keys in this table.\n/// \\param pubsub_channel The pubsub channel name that notifications for this\n/// key should be published to. When publishing to a specific client, the\n/// channel name should be <pubsub_channel>:<client_id>.\n/// \\param id The ID of the key to remove from.\n/// \\param data The data to remove from the key.\n/// \\return OK if the remove succeeds, or an error message string if the remove\n/// fails.\nint SetRemove_RedisCommand(RedisModuleCtx *ctx, RedisModuleString **argv, int argc) {\n  bool changed;\n  if (Set_DoWrite(ctx, argv, argc, /*is_add=*/false, &changed) != REDISMODULE_OK) {\n    return REDISMODULE_ERR;\n  }\n  if (changed) {\n    return Set_DoPublish(ctx, argv, /*is_add=*/false);\n  } else {\n    RAY_LOG(ERROR) << \"The entry to remove doesn't exist.\";\n  }\n  return RedisModule_ReplyWithSimpleString(ctx, \"OK\");\n}\n\nint Hash_DoPublish(RedisModuleCtx *ctx, RedisModuleString **argv) {\n  RedisModuleString *pubsub_channel_str = argv[2];\n  RedisModuleString *id = argv[3];\n  RedisModuleString *data = argv[4];\n  // Publish a message on the requested pubsub channel if necessary.\n  TablePubsub pubsub_channel;\n  REPLY_AND_RETURN_IF_NOT_OK(ParseTablePubsub(&pubsub_channel, pubsub_channel_str));\n  if (pubsub_channel != TablePubsub::NO_PUBLISH) {\n    // All other pubsub channels write the data back directly onto the\n    // channel.\n    return PublishDataHelper(ctx, pubsub_channel_str, id, data);\n  } else {\n    return RedisModule_ReplyWithSimpleString(ctx, \"OK\");\n  }\n}\n\n/// Do the hash table write operation. This is called from by HashUpdate_RedisCommand.\n///\n/// \\param change_mode Output the mode of the operation: APPEND_OR_ADD or REMOVE.\n/// \\param deleted_data Output data if the deleted data is not the same as required.\nint HashUpdate_DoWrite(RedisModuleCtx *ctx, RedisModuleString **argv, int argc,\n                       GcsChangeMode *change_mode, RedisModuleString **changed_data) {\n  if (argc != 5) {\n    return RedisModule_WrongArity(ctx);\n  }\n  RedisModuleString *prefix_str = argv[1];\n  RedisModuleString *id = argv[3];\n  RedisModuleString *update_data = argv[4];\n\n  RedisModuleKey *key;\n  REPLY_AND_RETURN_IF_NOT_OK(OpenPrefixedKey(\n      &key, ctx, prefix_str, id, REDISMODULE_READ | REDISMODULE_WRITE, nullptr));\n  int type = RedisModule_KeyType(key);\n  REPLY_AND_RETURN_IF_FALSE(\n      type == REDISMODULE_KEYTYPE_HASH || type == REDISMODULE_KEYTYPE_EMPTY,\n      \"HashUpdate_DoWrite: entries must be a hash or an empty hash\");\n\n  size_t update_data_len = 0;\n  const char *update_data_buf = RedisModule_StringPtrLen(update_data, &update_data_len);\n\n  GcsEntry gcs_entry;\n  gcs_entry.ParseFromArray(update_data_buf, update_data_len);\n  *change_mode = gcs_entry.change_mode();\n\n  if (*change_mode == GcsChangeMode::APPEND_OR_ADD) {\n    // This code path means they are updating command.\n    size_t total_size = gcs_entry.entries_size();\n    REPLY_AND_RETURN_IF_FALSE(total_size % 2 == 0, \"Invalid Hash Update data vector.\");\n    for (size_t i = 0; i < total_size; i += 2) {\n      // Reconstruct a key-value pair from a flattened list.\n      RedisModuleString *entry_key = RedisModule_CreateString(\n          ctx, gcs_entry.entries(i).data(), gcs_entry.entries(i).size());\n      RedisModuleString *entry_value = RedisModule_CreateString(\n          ctx, gcs_entry.entries(i + 1).data(), gcs_entry.entries(i + 1).size());\n      // Returning 0 if key exists(still updated), 1 if the key is created.\n      RAY_IGNORE_EXPR(\n          RedisModule_HashSet(key, REDISMODULE_HASH_NONE, entry_key, entry_value, NULL));\n    }\n    *changed_data = update_data;\n  } else {\n    // This code path means the command wants to remove the entries.\n    GcsEntry updated;\n    updated.set_id(gcs_entry.id());\n    updated.set_change_mode(gcs_entry.change_mode());\n\n    size_t total_size = gcs_entry.entries_size();\n    for (size_t i = 0; i < total_size; i++) {\n      RedisModuleString *entry_key = RedisModule_CreateString(\n          ctx, gcs_entry.entries(i).data(), gcs_entry.entries(i).size());\n      int deleted_num = RedisModule_HashSet(key, REDISMODULE_HASH_NONE, entry_key,\n                                            REDISMODULE_HASH_DELETE, NULL);\n      if (deleted_num != 0) {\n        // The corresponding key is removed.\n        updated.add_entries(gcs_entry.entries(i));\n      }\n    }\n\n    // Serialize updated data.\n    std::string str = updated.SerializeAsString();\n    *changed_data = RedisModule_CreateString(ctx, str.data(), str.size());\n    auto size = RedisModule_ValueLength(key);\n    if (size == 0) {\n      REPLY_AND_RETURN_IF_FALSE(RedisModule_DeleteKey(key) == REDISMODULE_OK,\n                                \"ERR Failed to delete empty hash.\");\n    }\n  }\n  return REDISMODULE_OK;\n}\n\n/// Update entries for a hash table.\n///\n/// This is called from a client with the command:\n//\n///    RAY.HASH_UPDATE <table_prefix> <pubsub_channel> <id> <data>\n///\n/// \\param table_prefix The prefix string for keys in this table.\n/// \\param pubsub_channel The pubsub channel name that notifications for this\n/// key should be published to. When publishing to a specific client, the\n/// channel name should be <pubsub_channel>:<client_id>.\n/// \\param id The ID of the key to remove from.\n/// \\param data The GcsEntry protobuf data used to update this hash table.\n///     1). For deletion, this is a list of keys.\n///     2). For updating, this is a list of pairs with each key followed by the value.\n/// \\return OK if the remove succeeds, or an error message string if the remove\n/// fails.\nint HashUpdate_RedisCommand(RedisModuleCtx *ctx, RedisModuleString **argv, int argc) {\n  GcsChangeMode mode;\n  RedisModuleString *changed_data = nullptr;\n  if (HashUpdate_DoWrite(ctx, argv, argc, &mode, &changed_data) != REDISMODULE_OK) {\n    return REDISMODULE_ERR;\n  }\n  // Replace the data with the changed data to do the publish.\n  std::vector<RedisModuleString *> new_argv(argv, argv + argc);\n  new_argv[4] = changed_data;\n  return Hash_DoPublish(ctx, new_argv.data());\n}\n\n/// A helper function to create a GcsEntry protobuf, based on the\n/// current value or values at the given key.\n///\n/// \\param ctx The Redis module context.\n/// \\param table_key The Redis key whose entry should be read out. The key must\n/// be open when this function is called and may be closed in this function.\n/// The key's name format is <prefix_str><entry_id>.\n/// \\param prefix_str The string prefix associated with the open Redis key.\n/// When parsed, this is expected to be a TablePrefix.\n/// \\param entry_id The UniqueID associated with the open Redis key.\n/// \\param[out] gcs_entry The created GcsEntry.\nStatus TableEntryToProtobuf(RedisModuleCtx *ctx, RedisModuleKey *table_key,\n                            RedisModuleString *prefix_str, RedisModuleString *entry_id,\n                            GcsEntry *gcs_entry) {\n  auto key_type = RedisModule_KeyType(table_key);\n  switch (key_type) {\n  case REDISMODULE_KEYTYPE_STRING: {\n    // Build the GcsEntry from the string data.\n    CreateGcsEntry(entry_id, GcsChangeMode::APPEND_OR_ADD, {}, gcs_entry);\n    size_t data_len = 0;\n    char *data_buf = RedisModule_StringDMA(table_key, &data_len, REDISMODULE_READ);\n    gcs_entry->add_entries(data_buf, data_len);\n  } break;\n  case REDISMODULE_KEYTYPE_LIST:\n  case REDISMODULE_KEYTYPE_HASH:\n  case REDISMODULE_KEYTYPE_SET: {\n    RedisModule_CloseKey(table_key);\n    // Close the key before executing the command. NOTE(swang): According to\n    // https://github.com/RedisLabs/RedisModulesSDK/blob/master/API.md, \"While\n    // a key is open, it should only be accessed via the low level key API.\"\n    RedisModuleString *table_key_str = PrefixedKeyString(ctx, prefix_str, entry_id);\n    // TODO(swang): This could potentially be replaced with the native redis\n    // server list iterator, once it is implemented for redis modules.\n    RedisModuleCallReply *reply = nullptr;\n    switch (key_type) {\n    case REDISMODULE_KEYTYPE_LIST:\n      reply = RedisModule_Call(ctx, \"LRANGE\", \"sll\", table_key_str, 0, -1);\n      break;\n    case REDISMODULE_KEYTYPE_SET:\n      reply = RedisModule_Call(ctx, \"SMEMBERS\", \"s\", table_key_str);\n      break;\n    case REDISMODULE_KEYTYPE_HASH:\n      reply = RedisModule_Call(ctx, \"HGETALL\", \"s\", table_key_str);\n      break;\n    }\n    // Build the GcsEntry from the set of log entries.\n    if (reply == nullptr || RedisModule_CallReplyType(reply) != REDISMODULE_REPLY_ARRAY) {\n      return Status::RedisError(\"Empty list/set/hash or wrong type\");\n    }\n    CreateGcsEntry(entry_id, GcsChangeMode::APPEND_OR_ADD, {}, gcs_entry);\n    for (size_t i = 0; i < RedisModule_CallReplyLength(reply); i++) {\n      RedisModuleCallReply *element = RedisModule_CallReplyArrayElement(reply, i);\n      size_t len;\n      const char *element_str = RedisModule_CallReplyStringPtr(element, &len);\n      gcs_entry->add_entries(element_str, len);\n    }\n  } break;\n  case REDISMODULE_KEYTYPE_EMPTY: {\n    CreateGcsEntry(entry_id, GcsChangeMode::APPEND_OR_ADD, {}, gcs_entry);\n  } break;\n  default:\n    return Status::RedisError(\"Invalid Redis type during lookup.\");\n  }\n  return Status::OK();\n}\n\n/// Lookup the current value or values at a key. Returns the current value or\n/// values at the key.\n///\n/// This is called from a client with the command:\n//\n///    RAY.TABLE_LOOKUP <table_prefix> <pubsub_channel> <id>\n///\n/// \\param table_prefix The prefix string for keys in this table.\n/// \\param pubsub_channel The pubsub channel name that notifications for\n///        this key should be published to. This field is unused for lookups.\n/// \\param id The ID of the key to lookup.\n/// \\return nil if the key is empty, the current value if the key type is a\n///         string, or an array of the current values if the key type is a set.\nint TableLookup_RedisCommand(RedisModuleCtx *ctx, RedisModuleString **argv, int argc) {\n  if (argc < 4) {\n    return RedisModule_WrongArity(ctx);\n  }\n\n  RedisModuleString *prefix_str = argv[1];\n  RedisModuleString *id = argv[3];\n\n  // Lookup the data at the key.\n  RedisModuleKey *table_key;\n  REPLY_AND_RETURN_IF_NOT_OK(\n      OpenPrefixedKey(&table_key, ctx, prefix_str, id, REDISMODULE_READ));\n  if (table_key == nullptr) {\n    RedisModule_ReplyWithNull(ctx);\n  } else {\n    // Serialize the data to a GcsEntry to return to the client.\n    GcsEntry gcs_entry;\n    REPLY_AND_RETURN_IF_NOT_OK(\n        TableEntryToProtobuf(ctx, table_key, prefix_str, id, &gcs_entry));\n    std::string str = gcs_entry.SerializeAsString();\n    RedisModule_ReplyWithStringBuffer(ctx, str.data(), str.size());\n  }\n  return REDISMODULE_OK;\n}\n\n// The deleting helper function.\nstatic Status DeleteKeyHelper(RedisModuleCtx *ctx, RedisModuleString *prefix_str,\n                              RedisModuleString *id_data) {\n  RedisModuleKey *delete_key = nullptr;\n  RAY_RETURN_NOT_OK(\n      OpenPrefixedKey(&delete_key, ctx, prefix_str, id_data, REDISMODULE_READ));\n  if (delete_key == nullptr) {\n    return Status::RedisError(\"Key does not exist.\");\n  }\n  auto key_type = RedisModule_KeyType(delete_key);\n  // Set/Hash will delete itself when the length is 0.\n  if (key_type == REDISMODULE_KEYTYPE_STRING || key_type == REDISMODULE_KEYTYPE_LIST) {\n    // Current Table or Log only has this two types of entries.\n    RAY_RETURN_NOT_OK(\n        OpenPrefixedKey(&delete_key, ctx, prefix_str, id_data, REDISMODULE_WRITE));\n    RedisModule_DeleteKey(delete_key);\n  } else {\n    std::ostringstream ostream;\n    size_t redis_string_size;\n    const char *redis_string_str = RedisModule_StringPtrLen(id_data, &redis_string_size);\n    auto id_binary = std::string(redis_string_str, redis_string_size);\n    ostream << \"Undesired type for RAY.TableDelete: \" << key_type\n            << \" id:\" << ray::UniqueID::FromBinary(id_binary);\n    RAY_LOG(ERROR) << ostream.str();\n    return Status::RedisError(ostream.str());\n  }\n  return Status::OK();\n}\n\n/// Delete a list of redis keys in batch mode.\n///\n/// This is called from a client with the command:\n//\n///    RAY.TABLE_DELETE <table_prefix> <pubsub_channel> <id> <data>\n///\n/// \\param table_prefix The prefix string for keys in this table.\n/// \\param pubsub_channel Unused but follow the interface.\n/// \\param id This id will be ignored but follow the interface.\n/// \\param data The list of Unique Ids, kUniqueIDSize bytes for each.\n/// \\return Always return OK unless the arguments are invalid.\nint TableDelete_RedisCommand(RedisModuleCtx *ctx, RedisModuleString **argv, int argc) {\n  if (argc != 5) {\n    return RedisModule_WrongArity(ctx);\n  }\n  RedisModuleString *prefix_str = argv[1];\n  RedisModuleString *data = argv[4];\n\n  size_t len = 0;\n  const char *data_ptr = nullptr;\n  data_ptr = RedisModule_StringPtrLen(data, &len);\n  // The first uint16_t are used to encode the number of ids to delete.\n  size_t ids_to_delete = *reinterpret_cast<const uint16_t *>(data_ptr);\n  size_t id_length = (len - sizeof(uint16_t)) / ids_to_delete;\n  REPLY_AND_RETURN_IF_FALSE((len - sizeof(uint16_t)) % ids_to_delete == 0,\n                            \"The deletion data length must be multiple of the ID size\");\n  data_ptr += sizeof(uint16_t);\n  for (size_t i = 0; i < ids_to_delete; ++i) {\n    RedisModuleString *id_data =\n        RedisModule_CreateString(ctx, data_ptr + i * id_length, id_length);\n    RAY_IGNORE_EXPR(DeleteKeyHelper(ctx, prefix_str, id_data));\n  }\n  return RedisModule_ReplyWithSimpleString(ctx, \"OK\");\n}\n\n/// Request notifications for changes to a key. Returns the current value or\n/// values at the key. Notifications will be sent to the requesting client for\n/// every subsequent TABLE_ADD to the key.\n///\n/// This is called from a client with the command:\n//\n///    RAY.TABLE_REQUEST_NOTIFICATIONS <table_prefix> <pubsub_channel> <id>\n///        <client_id>\n///\n/// \\param table_prefix The prefix string for keys in this table.\n/// \\param pubsub_channel The pubsub channel name that notifications for\n///        this key should be published to. When publishing to a specific\n///        client, the channel name should be <pubsub_channel>:<client_id>.\n/// \\param id The ID of the key to publish notifications for.\n/// \\param client_id The ID of the client that is being notified.\n/// \\return nil if the key is empty, the current value if the key type is a\n///         string, or an array of the current values if the key type is a set.\nint TableRequestNotifications_RedisCommand(RedisModuleCtx *ctx, RedisModuleString **argv,\n                                           int argc) {\n  if (argc != 5) {\n    return RedisModule_WrongArity(ctx);\n  }\n\n  RedisModuleString *prefix_str = argv[1];\n  RedisModuleString *pubsub_channel_str = argv[2];\n  RedisModuleString *id = argv[3];\n  RedisModuleString *client_id = argv[4];\n  RedisModuleString *client_channel;\n  REPLY_AND_RETURN_IF_NOT_OK(\n      FormatPubsubChannel(&client_channel, ctx, pubsub_channel_str, client_id));\n\n  // Add this client to the set of clients that should be notified when there\n  // are changes to the key.\n  std::string notification_key;\n  REPLY_AND_RETURN_IF_NOT_OK(\n      GetBroadcastKey(ctx, pubsub_channel_str, id, &notification_key));\n  notification_map[notification_key].push_back(RedisString_ToString(client_channel));\n\n  // Lookup the current value at the key.\n  RedisModuleKey *table_key;\n  REPLY_AND_RETURN_IF_NOT_OK(\n      OpenPrefixedKey(&table_key, ctx, prefix_str, id, REDISMODULE_READ));\n  // Publish the current value at the key to the client that is requesting\n  // notifications. An empty notification will be published if the key is\n  // empty.\n  GcsEntry gcs_entry;\n  REPLY_AND_RETURN_IF_NOT_OK(\n      TableEntryToProtobuf(ctx, table_key, prefix_str, id, &gcs_entry));\n  std::string str = gcs_entry.SerializeAsString();\n  RedisModule_Call(ctx, \"PUBLISH\", \"sb\", client_channel, str.data(), str.size());\n\n  return RedisModule_ReplyWithNull(ctx);\n}\n\n/// Cancel notifications for changes to a key. The client will no longer\n/// receive notifications for this key. This does not check if the client\n/// first requested notifications before canceling them.\n///\n/// This is called from a client with the command:\n//\n///    RAY.TABLE_CANCEL_NOTIFICATIONS <table_prefix> <pubsub_channel> <id>\n///        <client_id>\n///\n/// \\param table_prefix The prefix string for keys in this table.\n/// \\param pubsub_channel The pubsub channel name that notifications for\n///        this key should be published to. If publishing to a specific client,\n///        then the channel name should be <pubsub_channel>:<client_id>.\n/// \\param id The ID of the key to publish notifications for.\n/// \\param client_id The ID of the client to cancel notifications for.\n/// \\return OK.\nint TableCancelNotifications_RedisCommand(RedisModuleCtx *ctx, RedisModuleString **argv,\n                                          int argc) {\n  if (argc < 5) {\n    return RedisModule_WrongArity(ctx);\n  }\n\n  RedisModuleString *pubsub_channel_str = argv[2];\n  RedisModuleString *id = argv[3];\n  RedisModuleString *client_id = argv[4];\n  RedisModuleString *client_channel;\n  REPLY_AND_RETURN_IF_NOT_OK(\n      FormatPubsubChannel(&client_channel, ctx, pubsub_channel_str, client_id));\n\n  // Remove this client from the set of clients that should be notified when\n  // there are changes to the key.\n  std::string notification_key;\n  REPLY_AND_RETURN_IF_NOT_OK(\n      GetBroadcastKey(ctx, pubsub_channel_str, id, &notification_key));\n  auto it = notification_map.find(notification_key);\n  if (it != notification_map.end()) {\n    it->second.erase(std::remove(it->second.begin(), it->second.end(),\n                                 RedisString_ToString(client_channel)),\n                     it->second.end());\n    if (it->second.size() == 0) {\n      notification_map.erase(it);\n    }\n  }\n\n  RedisModule_ReplyWithSimpleString(ctx, \"OK\");\n  return REDISMODULE_OK;\n}\n\nStatus IsNil(bool *out, const std::string &data) {\n  if (data.size() != kUniqueIDSize) {\n    return Status::RedisError(\"Size of data doesn't match size of UniqueID\");\n  }\n  const uint8_t *d = reinterpret_cast<const uint8_t *>(data.data());\n  for (size_t i = 0; i < kUniqueIDSize; ++i) {\n    if (d[i] != 255) {\n      *out = false;\n    }\n  }\n  *out = true;\n  return Status::OK();\n}\n\nstd::string DebugString() {\n  std::stringstream result;\n  result << \"RedisModule:\";\n  result << \"\\n- NotificationMap.size = \" << notification_map.size();\n  result << std::endl;\n  return result.str();\n}\n\nint DebugString_RedisCommand(RedisModuleCtx *ctx, RedisModuleString **argv, int argc) {\n  REDISMODULE_NOT_USED(argv);\n\n  if (argc != 1) {\n    return RedisModule_WrongArity(ctx);\n  }\n  std::string debug_string = DebugString();\n  return RedisModule_ReplyWithStringBuffer(ctx, debug_string.data(), debug_string.size());\n}\n};  // namespace internal_redis_commands\n\n// Wrap all Redis commands with Redis' auto memory management.\nAUTO_MEMORY(TableAdd_RedisCommand);\nAUTO_MEMORY(HashUpdate_RedisCommand);\nAUTO_MEMORY(TableAppend_RedisCommand);\nAUTO_MEMORY(SetAdd_RedisCommand);\nAUTO_MEMORY(SetRemove_RedisCommand);\nAUTO_MEMORY(TableLookup_RedisCommand);\nAUTO_MEMORY(TableRequestNotifications_RedisCommand);\nAUTO_MEMORY(TableDelete_RedisCommand);\nAUTO_MEMORY(TableCancelNotifications_RedisCommand);\nAUTO_MEMORY(DebugString_RedisCommand);\n#if RAY_USE_NEW_GCS\nAUTO_MEMORY(ChainTableAdd_RedisCommand);\nAUTO_MEMORY(ChainTableAppend_RedisCommand);\n#endif\n\nextern \"C\" {\n\n/// This function must be present on each Redis module. It is used in order to\n/// register the commands into the Redis server.\n#ifdef _WIN32\n__declspec(dllexport)\n#endif\n    int RedisModule_OnLoad(RedisModuleCtx *ctx, RedisModuleString **argv, int argc) {\n  REDISMODULE_NOT_USED(argv);\n  REDISMODULE_NOT_USED(argc);\n\n  if (RedisModule_Init(ctx, \"ray\", 1, REDISMODULE_APIVER_1) == REDISMODULE_ERR) {\n    return REDISMODULE_ERR;\n  }\n\n  if (RedisModule_CreateCommand(ctx, \"ray.table_add\", TableAdd_RedisCommand,\n                                \"write pubsub\", 0, 0, 0) == REDISMODULE_ERR) {\n    return REDISMODULE_ERR;\n  }\n\n  if (RedisModule_CreateCommand(ctx, \"ray.table_append\", TableAppend_RedisCommand,\n                                \"write pubsub\", 0, 0, 0) == REDISMODULE_ERR) {\n    return REDISMODULE_ERR;\n  }\n\n  if (RedisModule_CreateCommand(ctx, \"ray.set_add\", SetAdd_RedisCommand, \"write pubsub\",\n                                0, 0, 0) == REDISMODULE_ERR) {\n    return REDISMODULE_ERR;\n  }\n\n  if (RedisModule_CreateCommand(ctx, \"ray.set_remove\", SetRemove_RedisCommand,\n                                \"write pubsub\", 0, 0, 0) == REDISMODULE_ERR) {\n    return REDISMODULE_ERR;\n  }\n\n  if (RedisModule_CreateCommand(ctx, \"ray.table_lookup\", TableLookup_RedisCommand,\n                                \"readonly\", 0, 0, 0) == REDISMODULE_ERR) {\n    return REDISMODULE_ERR;\n  }\n\n  if (RedisModule_CreateCommand(ctx, \"ray.table_delete\", TableDelete_RedisCommand,\n                                \"write\", 0, 0, 0) == REDISMODULE_ERR) {\n    return REDISMODULE_ERR;\n  }\n\n  if (RedisModule_CreateCommand(ctx, \"ray.hash_update\", HashUpdate_RedisCommand,\n                                \"write pubsub\", 0, 0, 0) == REDISMODULE_ERR) {\n    return REDISMODULE_ERR;\n  }\n\n  if (RedisModule_CreateCommand(ctx, \"ray.table_request_notifications\",\n                                TableRequestNotifications_RedisCommand, \"write pubsub\", 0,\n                                0, 0) == REDISMODULE_ERR) {\n    return REDISMODULE_ERR;\n  }\n\n  if (RedisModule_CreateCommand(ctx, \"ray.table_cancel_notifications\",\n                                TableCancelNotifications_RedisCommand, \"write pubsub\", 0,\n                                0, 0) == REDISMODULE_ERR) {\n    return REDISMODULE_ERR;\n  }\n\n  if (RedisModule_CreateCommand(ctx, \"ray.debug_string\", DebugString_RedisCommand,\n                                \"readonly\", 0, 0, 0) == REDISMODULE_ERR) {\n    return REDISMODULE_ERR;\n  }\n\n#if RAY_USE_NEW_GCS\n  // Chain-enabled commands that depend on ray-project/credis.\n  if (RedisModule_CreateCommand(ctx, \"ray.chain.table_add\", ChainTableAdd_RedisCommand,\n                                \"write pubsub\", 0, 0, 0) == REDISMODULE_ERR) {\n    return REDISMODULE_ERR;\n  }\n  if (RedisModule_CreateCommand(ctx, \"ray.chain.table_append\",\n                                ChainTableAppend_RedisCommand, \"write pubsub\", 0, 0,\n                                0) == REDISMODULE_ERR) {\n    return REDISMODULE_ERR;\n  }\n#endif\n\n  return REDISMODULE_OK;\n}\n\n}  /// extern \"C\"\n",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/python/ray/services.py": "import collections\nimport errno\nimport io\nimport json\nimport logging\nimport multiprocessing\nimport os\nimport random\nimport signal\nimport socket\nimport subprocess\nimport sys\nimport time\nimport redis\n\nimport colorama\n# Ray modules\nimport ray\nimport ray.ray_constants as ray_constants\nimport psutil\n\nresource = None\nif sys.platform != \"win32\":\n    import resource\n\nEXE_SUFFIX = \".exe\" if sys.platform == \"win32\" else \"\"\n\n# True if processes are run in the valgrind profiler.\nRUN_RAYLET_PROFILER = False\nRUN_PLASMA_STORE_PROFILER = False\n\n# Location of the redis server and module.\nRAY_HOME = os.path.join(os.path.dirname(__file__), \"../..\")\nREDIS_EXECUTABLE = os.path.join(\n    os.path.abspath(os.path.dirname(__file__)),\n    \"core/src/ray/thirdparty/redis/src/redis-server\" + EXE_SUFFIX)\nREDIS_MODULE = os.path.join(\n    os.path.abspath(os.path.dirname(__file__)),\n    \"core/src/ray/gcs/redis_module/libray_redis_module.so\")\n\n# Location of the credis server and modules.\n# credis will be enabled if the environment variable RAY_USE_NEW_GCS is set.\nCREDIS_EXECUTABLE = os.path.join(\n    os.path.abspath(os.path.dirname(__file__)),\n    \"core/src/credis/redis/src/redis-server\" + EXE_SUFFIX)\nCREDIS_MASTER_MODULE = os.path.join(\n    os.path.abspath(os.path.dirname(__file__)),\n    \"core/src/credis/build/src/libmaster.so\")\nCREDIS_MEMBER_MODULE = os.path.join(\n    os.path.abspath(os.path.dirname(__file__)),\n    \"core/src/credis/build/src/libmember.so\")\n\n# Location of the plasma object store executable.\nPLASMA_STORE_EXECUTABLE = os.path.join(\n    os.path.abspath(os.path.dirname(__file__)),\n    \"core/src/plasma/plasma_store_server\" + EXE_SUFFIX)\n\n# Location of the raylet executables.\nRAYLET_EXECUTABLE = os.path.join(\n    os.path.abspath(os.path.dirname(__file__)),\n    \"core/src/ray/raylet/raylet\" + EXE_SUFFIX)\nGCS_SERVER_EXECUTABLE = os.path.join(\n    os.path.abspath(os.path.dirname(__file__)),\n    \"core/src/ray/gcs/gcs_server\" + EXE_SUFFIX)\n\nDEFAULT_JAVA_WORKER_CLASSPATH = [\n    os.path.join(\n        os.path.abspath(os.path.dirname(__file__)), \"../../../build/java/*\"),\n]\n\n# Logger for this module. It should be configured at the entry point\n# into the program using Ray. Ray provides a default configuration at\n# entry/init points.\nlogger = logging.getLogger(__name__)\n\nProcessInfo = collections.namedtuple(\"ProcessInfo\", [\n    \"process\",\n    \"stdout_file\",\n    \"stderr_file\",\n    \"use_valgrind\",\n    \"use_gdb\",\n    \"use_valgrind_profiler\",\n    \"use_perftools_profiler\",\n    \"use_tmux\",\n])\n\n\nclass ConsolePopen(subprocess.Popen):\n    if sys.platform == \"win32\":\n\n        def terminate(self):\n            if isinstance(self.stdin, io.IOBase):\n                self.stdin.close()\n            if self._use_signals:\n                self.send_signal(signal.CTRL_BREAK_EVENT)\n            else:\n                super(ConsolePopen, self).terminate()\n\n        def __init__(self, *args, **kwargs):\n            # CREATE_NEW_PROCESS_GROUP is used to send Ctrl+C on Windows:\n            # https://docs.python.org/3/library/subprocess.html#subprocess.Popen.send_signal\n            new_pgroup = subprocess.CREATE_NEW_PROCESS_GROUP\n            flags_to_add = 0\n            if ray.utils.detect_fate_sharing_support():\n                # If we don't have kernel-mode fate-sharing, then don't do this\n                # because our children need to be in out process group for\n                # the process reaper to properly terminate them.\n                flags_to_add = new_pgroup\n            flags_key = \"creationflags\"\n            if flags_to_add:\n                kwargs[flags_key] = (kwargs.get(flags_key) or 0) | flags_to_add\n            self._use_signals = (kwargs[flags_key] & new_pgroup)\n            super(ConsolePopen, self).__init__(*args, **kwargs)\n\n\ndef address(ip_address, port):\n    return ip_address + \":\" + str(port)\n\n\ndef new_port():\n    return random.randint(10000, 65535)\n\n\ndef include_java_from_redis(redis_client):\n    \"\"\"This is used for query include_java bool from redis.\n\n    Args:\n        redis_client (StrictRedis): The redis client to GCS.\n\n    Returns:\n        True if this cluster backend enables Java worker.\n    \"\"\"\n    return redis_client.get(\"INCLUDE_JAVA\") == b\"1\"\n\n\ndef find_redis_address_or_die():\n    pids = psutil.pids()\n    redis_addresses = set()\n    for pid in pids:\n        try:\n            proc = psutil.Process(pid)\n            # HACK: Workaround for UNIX idiosyncrasy\n            # Normally, cmdline() is supposed to return the argument list.\n            # But it in some cases (such as when setproctitle is called),\n            # an arbitrary string resembling a command-line is stored in\n            # the first argument.\n            # Explanation: https://unix.stackexchange.com/a/432681\n            # More info: https://github.com/giampaolo/psutil/issues/1179\n            for arglist in proc.cmdline():\n                # Given we're merely seeking --redis-address, we just split\n                # every argument on spaces for now.\n                for arg in arglist.split(\" \"):\n                    # TODO(ekl): Find a robust solution for locating Redis.\n                    if arg.startswith(\"--redis-address=\"):\n                        addr = arg.split(\"=\")[1]\n                        redis_addresses.add(addr)\n        except psutil.AccessDenied:\n            pass\n        except psutil.NoSuchProcess:\n            pass\n    if len(redis_addresses) > 1:\n        raise ConnectionError(\n            \"Found multiple active Ray instances: {}. \".format(redis_addresses)\n            + \"Please specify the one to connect to by setting `address`.\")\n        sys.exit(1)\n    elif not redis_addresses:\n        raise ConnectionError(\n            \"Could not find any running Ray instance. \"\n            \"Please specify the one to connect to by setting `address`.\")\n    return redis_addresses.pop()\n\n\ndef get_address_info_from_redis_helper(redis_address,\n                                       node_ip_address,\n                                       redis_password=None):\n    redis_ip_address, redis_port = redis_address.split(\":\")\n    # Get node table from global state accessor.\n    global_state = ray.state.GlobalState()\n    global_state._initialize_global_state(redis_address, redis_password)\n    client_table = global_state.node_table()\n    if len(client_table) == 0:\n        raise RuntimeError(\n            \"Redis has started but no raylets have registered yet.\")\n\n    relevant_client = None\n    for client_info in client_table:\n        client_node_ip_address = client_info[\"NodeManagerAddress\"]\n        if (client_node_ip_address == node_ip_address\n                or (client_node_ip_address == \"127.0.0.1\"\n                    and redis_ip_address == get_node_ip_address())):\n            relevant_client = client_info\n            break\n    if relevant_client is None:\n        raise RuntimeError(\n            \"Redis has started but no raylets have registered yet.\")\n\n    return {\n        \"object_store_address\": relevant_client[\"ObjectStoreSocketName\"],\n        \"raylet_socket_name\": relevant_client[\"RayletSocketName\"],\n        \"node_manager_port\": relevant_client[\"NodeManagerPort\"],\n    }\n\n\ndef get_address_info_from_redis(redis_address,\n                                node_ip_address,\n                                num_retries=5,\n                                redis_password=None):\n    counter = 0\n    while True:\n        try:\n            return get_address_info_from_redis_helper(\n                redis_address, node_ip_address, redis_password=redis_password)\n        except Exception:\n            if counter == num_retries:\n                raise\n            # Some of the information may not be in Redis yet, so wait a little\n            # bit.\n            logger.warning(\n                \"Some processes that the driver needs to connect to have \"\n                \"not registered with Redis, so retrying. Have you run \"\n                \"'ray start' on this node?\")\n            time.sleep(1)\n        counter += 1\n\n\ndef get_webui_url_from_redis(redis_client):\n    webui_url = redis_client.hmget(\"webui\", \"url\")[0]\n    return ray.utils.decode(webui_url) if webui_url is not None else None\n\n\ndef remaining_processes_alive():\n    \"\"\"See if the remaining processes are alive or not.\n\n    Note that this ignores processes that have been explicitly killed,\n    e.g., via a command like node.kill_raylet().\n\n    Returns:\n        True if the remaining processes started by ray.init() are alive and\n            False otherwise.\n\n    Raises:\n        Exception: An exception is raised if the processes were not started by\n            ray.init().\n    \"\"\"\n    if ray.worker._global_node is None:\n        raise RuntimeError(\"This process is not in a position to determine \"\n                           \"whether all processes are alive or not.\")\n    return ray.worker._global_node.remaining_processes_alive()\n\n\ndef validate_redis_address(address, redis_address):\n    \"\"\"Validates redis address parameter and splits it into host/ip components.\n\n    We temporarily support both 'address' and 'redis_address', so both are\n    handled here.\n\n    Returns:\n        redis_address: string containing the full <host:port> address.\n        redis_ip: string representing the host portion of the address.\n        redis_port: integer representing the port portion of the address.\n\n    Raises:\n        ValueError: if both address and redis_address were specified or the\n            address was malformed.\n    \"\"\"\n\n    if redis_address == \"auto\":\n        raise ValueError(\"auto address resolution not supported for \"\n                         \"redis_address parameter. Please use address.\")\n\n    if address:\n        if redis_address:\n            raise ValueError(\n                \"Both address and redis_address specified. Use only address.\")\n        if address == \"auto\":\n            address = find_redis_address_or_die()\n        redis_address = address\n\n    redis_address = address_to_ip(redis_address)\n\n    redis_address_parts = redis_address.split(\":\")\n    if len(redis_address_parts) != 2:\n        raise ValueError(\"Malformed address. Expected '<host>:<port>'.\")\n    redis_ip = redis_address_parts[0]\n    try:\n        redis_port = int(redis_address_parts[1])\n    except ValueError:\n        raise ValueError(\"Malformed address port. Must be an integer.\")\n    if redis_port < 1024 or redis_port > 65535:\n        raise ValueError(\"Invalid address port. Must \"\n                         \"be between 1024 and 65535.\")\n\n    return redis_address, redis_ip, redis_port\n\n\ndef address_to_ip(address):\n    \"\"\"Convert a hostname to a numerical IP addresses in an address.\n\n    This should be a no-op if address already contains an actual numerical IP\n    address.\n\n    Args:\n        address: This can be either a string containing a hostname (or an IP\n            address) and a port or it can be just an IP address.\n\n    Returns:\n        The same address but with the hostname replaced by a numerical IP\n            address.\n    \"\"\"\n    address_parts = address.split(\":\")\n    ip_address = socket.gethostbyname(address_parts[0])\n    # Make sure localhost isn't resolved to the loopback ip\n    if ip_address == \"127.0.0.1\":\n        ip_address = get_node_ip_address()\n    return \":\".join([ip_address] + address_parts[1:])\n\n\ndef get_node_ip_address(address=\"8.8.8.8:53\"):\n    \"\"\"Determine the IP address of the local node.\n\n    Args:\n        address (str): The IP address and port of any known live service on the\n            network you care about.\n\n    Returns:\n        The IP address of the current node.\n    \"\"\"\n    if ray.worker._global_node is not None:\n        return ray.worker._global_node.node_ip_address\n\n    ip_address, port = address.split(\":\")\n    s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n    try:\n        # This command will raise an exception if there is no internet\n        # connection.\n        s.connect((ip_address, int(port)))\n        node_ip_address = s.getsockname()[0]\n    except OSError as e:\n        node_ip_address = \"127.0.0.1\"\n        # [Errno 101] Network is unreachable\n        if e.errno == errno.ENETUNREACH:\n            try:\n                # try get node ip address from host name\n                host_name = socket.getfqdn(socket.gethostname())\n                node_ip_address = socket.gethostbyname(host_name)\n            except Exception:\n                pass\n    finally:\n        s.close()\n\n    return node_ip_address\n\n\ndef create_redis_client(redis_address, password=None):\n    \"\"\"Create a Redis client.\n\n    Args:\n        The IP address, port, and password of the Redis server.\n\n    Returns:\n        A Redis client.\n    \"\"\"\n    redis_ip_address, redis_port = redis_address.split(\":\")\n    # For this command to work, some other client (on the same machine\n    # as Redis) must have run \"CONFIG SET protected-mode no\".\n    return redis.StrictRedis(\n        host=redis_ip_address, port=int(redis_port), password=password)\n\n\ndef start_ray_process(command,\n                      process_type,\n                      fate_share,\n                      env_updates=None,\n                      cwd=None,\n                      use_valgrind=False,\n                      use_gdb=False,\n                      use_valgrind_profiler=False,\n                      use_perftools_profiler=False,\n                      use_tmux=False,\n                      stdout_file=None,\n                      stderr_file=None,\n                      pipe_stdin=False):\n    \"\"\"Start one of the Ray processes.\n\n    TODO(rkn): We need to figure out how these commands interact. For example,\n    it may only make sense to start a process in gdb if we also start it in\n    tmux. Similarly, certain combinations probably don't make sense, like\n    simultaneously running the process in valgrind and the profiler.\n\n    Args:\n        command (List[str]): The command to use to start the Ray process.\n        process_type (str): The type of the process that is being started\n            (e.g., \"raylet\").\n        fate_share: If true, the child will be killed if its parent (us) dies.\n            True must only be passed after detection of this functionality.\n        env_updates (dict): A dictionary of additional environment variables to\n            run the command with (in addition to the caller's environment\n            variables).\n        cwd (str): The directory to run the process in.\n        use_valgrind (bool): True if we should start the process in valgrind.\n        use_gdb (bool): True if we should start the process in gdb.\n        use_valgrind_profiler (bool): True if we should start the process in\n            the valgrind profiler.\n        use_perftools_profiler (bool): True if we should profile the process\n            using perftools.\n        use_tmux (bool): True if we should start the process in tmux.\n        stdout_file: A file handle opened for writing to redirect stdout to. If\n            no redirection should happen, then this should be None.\n        stderr_file: A file handle opened for writing to redirect stderr to. If\n            no redirection should happen, then this should be None.\n        pipe_stdin: If true, subprocess.PIPE will be passed to the process as\n            stdin.\n\n    Returns:\n        Information about the process that was started including a handle to\n            the process that was started.\n    \"\"\"\n    # Detect which flags are set through environment variables.\n    valgrind_env_var = \"RAY_{}_VALGRIND\".format(process_type.upper())\n    if os.environ.get(valgrind_env_var) == \"1\":\n        logger.info(\"Detected environment variable '%s'.\", valgrind_env_var)\n        use_valgrind = True\n    valgrind_profiler_env_var = \"RAY_{}_VALGRIND_PROFILER\".format(\n        process_type.upper())\n    if os.environ.get(valgrind_profiler_env_var) == \"1\":\n        logger.info(\"Detected environment variable '%s'.\",\n                    valgrind_profiler_env_var)\n        use_valgrind_profiler = True\n    perftools_profiler_env_var = \"RAY_{}_PERFTOOLS_PROFILER\".format(\n        process_type.upper())\n    if os.environ.get(perftools_profiler_env_var) == \"1\":\n        logger.info(\"Detected environment variable '%s'.\",\n                    perftools_profiler_env_var)\n        use_perftools_profiler = True\n    tmux_env_var = \"RAY_{}_TMUX\".format(process_type.upper())\n    if os.environ.get(tmux_env_var) == \"1\":\n        logger.info(\"Detected environment variable '%s'.\", tmux_env_var)\n        use_tmux = True\n    gdb_env_var = \"RAY_{}_GDB\".format(process_type.upper())\n    if os.environ.get(gdb_env_var) == \"1\":\n        logger.info(\"Detected environment variable '%s'.\", gdb_env_var)\n        use_gdb = True\n\n    if sum([\n            use_gdb,\n            use_valgrind,\n            use_valgrind_profiler,\n            use_perftools_profiler,\n    ]) > 1:\n        raise ValueError(\n            \"At most one of the 'use_gdb', 'use_valgrind', \"\n            \"'use_valgrind_profiler', and 'use_perftools_profiler' flags can \"\n            \"be used at a time.\")\n    if env_updates is None:\n        env_updates = {}\n    if not isinstance(env_updates, dict):\n        raise ValueError(\"The 'env_updates' argument must be a dictionary.\")\n\n    modified_env = os.environ.copy()\n    modified_env.update(env_updates)\n\n    if use_gdb:\n        if not use_tmux:\n            raise ValueError(\n                \"If 'use_gdb' is true, then 'use_tmux' must be true as well.\")\n\n        # TODO(suquark): Any better temp file creation here?\n        gdb_init_path = os.path.join(\n            ray.utils.get_ray_temp_dir(), \"gdb_init_{}_{}\".format(\n                process_type, time.time()))\n        ray_process_path = command[0]\n        ray_process_args = command[1:]\n        run_args = \" \".join([\"'{}'\".format(arg) for arg in ray_process_args])\n        with open(gdb_init_path, \"w\") as gdb_init_file:\n            gdb_init_file.write(\"run {}\".format(run_args))\n        command = [\"gdb\", ray_process_path, \"-x\", gdb_init_path]\n\n    if use_valgrind:\n        command = [\n            \"valgrind\",\n            \"--track-origins=yes\",\n            \"--leak-check=full\",\n            \"--show-leak-kinds=all\",\n            \"--leak-check-heuristics=stdstring\",\n            \"--error-exitcode=1\",\n        ] + command\n\n    if use_valgrind_profiler:\n        command = [\"valgrind\", \"--tool=callgrind\"] + command\n\n    if use_perftools_profiler:\n        modified_env[\"LD_PRELOAD\"] = os.environ[\"PERFTOOLS_PATH\"]\n        modified_env[\"CPUPROFILE\"] = os.environ[\"PERFTOOLS_LOGFILE\"]\n\n    if use_tmux:\n        # The command has to be created exactly as below to ensure that it\n        # works on all versions of tmux. (Tested with tmux 1.8-5, travis'\n        # version, and tmux 2.1)\n        command = [\"tmux\", \"new-session\", \"-d\", \"{}\".format(\" \".join(command))]\n\n    if fate_share:\n        assert ray.utils.detect_fate_sharing_support(), (\n            \"kernel-level fate-sharing must only be specified if \"\n            \"detect_fate_sharing_support() has returned True\")\n\n    def preexec_fn():\n        import signal\n        signal.pthread_sigmask(signal.SIG_BLOCK, {signal.SIGINT})\n        if fate_share and sys.platform.startswith(\"linux\"):\n            ray.utils.set_kill_on_parent_death_linux()\n\n    win32_fate_sharing = fate_share and sys.platform == \"win32\"\n    # With Windows fate-sharing, we need special care:\n    # The process must be added to the job before it is allowed to execute.\n    # Otherwise, there's a race condition: the process might spawn children\n    # before the process itself is assigned to the job.\n    # After that point, its children will not be added to the job anymore.\n    CREATE_SUSPENDED = 0x00000004  # from Windows headers\n\n    process = ConsolePopen(\n        command,\n        env=modified_env,\n        cwd=cwd,\n        stdout=stdout_file,\n        stderr=stderr_file,\n        stdin=subprocess.PIPE if pipe_stdin else None,\n        preexec_fn=preexec_fn if sys.platform != \"win32\" else None,\n        creationflags=CREATE_SUSPENDED if win32_fate_sharing else 0)\n\n    if win32_fate_sharing:\n        try:\n            ray.utils.set_kill_child_on_death_win32(process)\n            psutil.Process(process.pid).resume()\n        except (psutil.Error, OSError):\n            process.kill()\n            raise\n\n    return ProcessInfo(\n        process=process,\n        stdout_file=stdout_file.name if stdout_file is not None else None,\n        stderr_file=stderr_file.name if stderr_file is not None else None,\n        use_valgrind=use_valgrind,\n        use_gdb=use_gdb,\n        use_valgrind_profiler=use_valgrind_profiler,\n        use_perftools_profiler=use_perftools_profiler,\n        use_tmux=use_tmux)\n\n\ndef wait_for_redis_to_start(redis_ip_address, redis_port, password=None):\n    \"\"\"Wait for a Redis server to be available.\n\n    This is accomplished by creating a Redis client and sending a random\n    command to the server until the command gets through.\n\n    Args:\n        redis_ip_address (str): The IP address of the redis server.\n        redis_port (int): The port of the redis server.\n        password (str): The password of the redis server.\n\n    Raises:\n        Exception: An exception is raised if we could not connect with Redis.\n    \"\"\"\n    redis_client = redis.StrictRedis(\n        host=redis_ip_address, port=redis_port, password=password)\n    # Wait for the Redis server to start.\n    num_retries = 12\n    delay = 0.001\n    for _ in range(num_retries):\n        try:\n            # Run some random command and see if it worked.\n            logger.debug(\n                \"Waiting for redis server at {}:{} to respond...\".format(\n                    redis_ip_address, redis_port))\n            redis_client.client_list()\n        except redis.ConnectionError:\n            # Wait a little bit.\n            time.sleep(delay)\n            delay *= 2\n        else:\n            break\n    else:\n        raise RuntimeError(\"Unable to connect to Redis. If the Redis instance \"\n                           \"is on a different machine, check that your \"\n                           \"firewall is configured properly.\")\n\n\ndef _compute_version_info():\n    \"\"\"Compute the versions of Python, and Ray.\n\n    Returns:\n        A tuple containing the version information.\n    \"\"\"\n    ray_version = ray.__version__\n    python_version = \".\".join(map(str, sys.version_info[:3]))\n    return ray_version, python_version\n\n\ndef _put_version_info_in_redis(redis_client):\n    \"\"\"Store version information in Redis.\n\n    This will be used to detect if workers or drivers are started using\n    different versions of Python, or Ray.\n\n    Args:\n        redis_client: A client for the primary Redis shard.\n    \"\"\"\n    redis_client.set(\"VERSION_INFO\", json.dumps(_compute_version_info()))\n\n\ndef check_version_info(redis_client):\n    \"\"\"Check if various version info of this process is correct.\n\n    This will be used to detect if workers or drivers are started using\n    different versions of Python, or Ray. If the version\n    information is not present in Redis, then no check is done.\n\n    Args:\n        redis_client: A client for the primary Redis shard.\n\n    Raises:\n        Exception: An exception is raised if there is a version mismatch.\n    \"\"\"\n    redis_reply = redis_client.get(\"VERSION_INFO\")\n\n    # Don't do the check if there is no version information in Redis. This\n    # is to make it easier to do things like start the processes by hand.\n    if redis_reply is None:\n        return\n\n    true_version_info = tuple(json.loads(ray.utils.decode(redis_reply)))\n    version_info = _compute_version_info()\n    if version_info != true_version_info:\n        node_ip_address = get_node_ip_address()\n        error_message = (\"Version mismatch: The cluster was started with:\\n\"\n                         \"    Ray: \" + true_version_info[0] + \"\\n\"\n                         \"    Python: \" + true_version_info[1] + \"\\n\"\n                         \"This process on node \" + node_ip_address +\n                         \" was started with:\" + \"\\n\"\n                         \"    Ray: \" + version_info[0] + \"\\n\"\n                         \"    Python: \" + version_info[1] + \"\\n\")\n        if version_info[:2] != true_version_info[:2]:\n            raise RuntimeError(error_message)\n        else:\n            logger.warning(error_message)\n\n\ndef start_reaper(fate_share=None):\n    \"\"\"Start the reaper process.\n\n    This is a lightweight process that simply\n    waits for its parent process to die and then terminates its own\n    process group. This allows us to ensure that ray processes are always\n    terminated properly so long as that process itself isn't SIGKILLed.\n\n    Returns:\n        ProcessInfo for the process that was started.\n    \"\"\"\n    # Make ourselves a process group leader so that the reaper can clean\n    # up other ray processes without killing the process group of the\n    # process that started us.\n    try:\n        if sys.platform != \"win32\":\n            os.setpgrp()\n    except OSError as e:\n        errcode = e.errno\n        if errcode == errno.EPERM and os.getpgrp() == os.getpid():\n            # Nothing to do; we're already a session leader.\n            pass\n        else:\n            logger.warning(\"setpgrp failed, processes may not be \"\n                           \"cleaned up properly: {}.\".format(e))\n            # Don't start the reaper in this case as it could result in killing\n            # other user processes.\n            return None\n\n    reaper_filepath = os.path.join(\n        os.path.dirname(os.path.abspath(__file__)), \"ray_process_reaper.py\")\n    command = [sys.executable, \"-u\", reaper_filepath]\n    process_info = start_ray_process(\n        command,\n        ray_constants.PROCESS_TYPE_REAPER,\n        pipe_stdin=True,\n        fate_share=fate_share)\n    return process_info\n\n\ndef start_redis(node_ip_address,\n                redirect_files,\n                resource_spec,\n                port=None,\n                redis_shard_ports=None,\n                num_redis_shards=1,\n                redis_max_clients=None,\n                redirect_worker_output=False,\n                password=None,\n                use_credis=None,\n                include_java=False,\n                fate_share=None):\n    \"\"\"Start the Redis global state store.\n\n    Args:\n        node_ip_address: The IP address of the current node. This is only used\n            for recording the log filenames in Redis.\n        redirect_files: The list of (stdout, stderr) file pairs.\n        resource_spec (ResourceSpec): Resources for the node.\n        port (int): If provided, the primary Redis shard will be started on\n            this port.\n        redis_shard_ports: A list of the ports to use for the non-primary Redis\n            shards.\n        num_redis_shards (int): If provided, the number of Redis shards to\n            start, in addition to the primary one. The default value is one\n            shard.\n        redis_max_clients: If this is provided, Ray will attempt to configure\n            Redis with this maxclients number.\n        redirect_worker_output (bool): True if worker output should be\n            redirected to a file and false otherwise. Workers will have access\n            to this value when they start up.\n        password (str): Prevents external clients without the password\n            from connecting to Redis if provided.\n        use_credis: If True, additionally load the chain-replicated libraries\n            into the redis servers.  Defaults to None, which means its value is\n            set by the presence of \"RAY_USE_NEW_GCS\" in os.environ.\n        include_java (bool): If True, the raylet backend can also support\n            Java worker.\n\n    Returns:\n        A tuple of the address for the primary Redis shard, a list of\n            addresses for the remaining shards, and the processes that were\n            started.\n    \"\"\"\n\n    if len(redirect_files) != 1 + num_redis_shards:\n        raise ValueError(\"The number of redirect file pairs should be equal \"\n                         \"to the number of redis shards (including the \"\n                         \"primary shard) we will start.\")\n    if redis_shard_ports is None:\n        redis_shard_ports = num_redis_shards * [None]\n    elif len(redis_shard_ports) != num_redis_shards:\n        raise RuntimeError(\"The number of Redis shard ports does not match \"\n                           \"the number of Redis shards.\")\n\n    processes = []\n\n    if use_credis is None:\n        use_credis = (\"RAY_USE_NEW_GCS\" in os.environ)\n    if use_credis:\n        if password is not None:\n            # TODO(pschafhalter) remove this once credis supports\n            # authenticating Redis ports\n            raise ValueError(\"Setting the `redis_password` argument is not \"\n                             \"supported in credis. To run Ray with \"\n                             \"password-protected Redis ports, ensure that \"\n                             \"the environment variable `RAY_USE_NEW_GCS=off`.\")\n        assert num_redis_shards == 1, (\n            \"For now, RAY_USE_NEW_GCS supports 1 shard, and credis \"\n            \"supports 1-node chain for that shard only.\")\n\n    if use_credis:\n        redis_executable = CREDIS_EXECUTABLE\n        # TODO(suquark): We need credis here because some symbols need to be\n        # imported from credis dynamically through dlopen when Ray is built\n        # with RAY_USE_NEW_GCS=on. We should remove them later for the primary\n        # shard.\n        # See src/ray/gcs/redis_module/ray_redis_module.cc\n        redis_modules = [CREDIS_MASTER_MODULE, REDIS_MODULE]\n    else:\n        redis_executable = REDIS_EXECUTABLE\n        redis_modules = [REDIS_MODULE]\n\n    redis_stdout_file, redis_stderr_file = redirect_files[0]\n    # Start the primary Redis shard.\n    port, p = _start_redis_instance(\n        redis_executable,\n        modules=redis_modules,\n        port=port,\n        password=password,\n        redis_max_clients=redis_max_clients,\n        # Below we use None to indicate no limit on the memory of the\n        # primary Redis shard.\n        redis_max_memory=None,\n        stdout_file=redis_stdout_file,\n        stderr_file=redis_stderr_file,\n        fate_share=fate_share)\n    processes.append(p)\n    redis_address = address(node_ip_address, port)\n\n    # Register the number of Redis shards in the primary shard, so that clients\n    # know how many redis shards to expect under RedisShards.\n    primary_redis_client = redis.StrictRedis(\n        host=node_ip_address, port=port, password=password)\n    primary_redis_client.set(\"NumRedisShards\", str(num_redis_shards))\n\n    # Put the redirect_worker_output bool in the Redis shard so that workers\n    # can access it and know whether or not to redirect their output.\n    primary_redis_client.set(\"RedirectOutput\", 1\n                             if redirect_worker_output else 0)\n\n    # put the include_java bool to primary redis-server, so that other nodes\n    # can access it and know whether or not to enable cross-languages.\n    primary_redis_client.set(\"INCLUDE_JAVA\", 1 if include_java else 0)\n\n    # Init job counter to GCS.\n    primary_redis_client.set(\"JobCounter\", 0)\n\n    # Store version information in the primary Redis shard.\n    _put_version_info_in_redis(primary_redis_client)\n\n    # Calculate the redis memory.\n    assert resource_spec.resolved()\n    redis_max_memory = resource_spec.redis_max_memory\n\n    # Start other Redis shards. Each Redis shard logs to a separate file,\n    # prefixed by \"redis-<shard number>\".\n    redis_shards = []\n    for i in range(num_redis_shards):\n        redis_stdout_file, redis_stderr_file = redirect_files[i + 1]\n        if use_credis:\n            redis_executable = CREDIS_EXECUTABLE\n            # It is important to load the credis module BEFORE the ray module,\n            # as the latter contains an extern declaration that the former\n            # supplies.\n            redis_modules = [CREDIS_MEMBER_MODULE, REDIS_MODULE]\n        else:\n            redis_executable = REDIS_EXECUTABLE\n            redis_modules = [REDIS_MODULE]\n\n        redis_shard_port, p = _start_redis_instance(\n            redis_executable,\n            modules=redis_modules,\n            port=redis_shard_ports[i],\n            password=password,\n            redis_max_clients=redis_max_clients,\n            redis_max_memory=redis_max_memory,\n            stdout_file=redis_stdout_file,\n            stderr_file=redis_stderr_file,\n            fate_share=fate_share)\n        processes.append(p)\n\n        shard_address = address(node_ip_address, redis_shard_port)\n        redis_shards.append(shard_address)\n        # Store redis shard information in the primary redis shard.\n        primary_redis_client.rpush(\"RedisShards\", shard_address)\n\n    if use_credis:\n        # Configure the chain state. The way it is intended to work is\n        # the following:\n        #\n        # PRIMARY_SHARD\n        #\n        # SHARD_1 (master replica) -> SHARD_1 (member replica)\n        #                                        -> SHARD_1 (member replica)\n        #\n        # SHARD_2 (master replica) -> SHARD_2 (member replica)\n        #                                        -> SHARD_2 (member replica)\n        # ...\n        #\n        #\n        # If we have credis members in future, their modules should be:\n        # [CREDIS_MEMBER_MODULE, REDIS_MODULE], and they will be initialized by\n        # execute_command(\"MEMBER.CONNECT_TO_MASTER\", node_ip_address, port)\n        #\n        # Currently we have num_redis_shards == 1, so only one chain will be\n        # created, and the chain only contains master.\n\n        # TODO(suquark): Currently, this is not correct because we are\n        # using the master replica as the primary shard. This should be\n        # fixed later. I had tried to fix it but failed because of heartbeat\n        # issues.\n        primary_client = redis.StrictRedis(\n            host=node_ip_address, port=port, password=password)\n        shard_client = redis.StrictRedis(\n            host=node_ip_address, port=redis_shard_port, password=password)\n        primary_client.execute_command(\"MASTER.ADD\", node_ip_address,\n                                       redis_shard_port)\n        shard_client.execute_command(\"MEMBER.CONNECT_TO_MASTER\",\n                                     node_ip_address, port)\n\n    return redis_address, redis_shards, processes\n\n\ndef _start_redis_instance(executable,\n                          modules,\n                          port=None,\n                          redis_max_clients=None,\n                          num_retries=20,\n                          stdout_file=None,\n                          stderr_file=None,\n                          password=None,\n                          redis_max_memory=None,\n                          fate_share=None):\n    \"\"\"Start a single Redis server.\n\n    Notes:\n        If \"port\" is not None, then we will only use this port and try\n        only once. Otherwise, we will first try the default redis port,\n        and if it is unavailable, we will try random ports with\n        maximum retries of \"num_retries\".\n\n    Args:\n        executable (str): Full path of the redis-server executable.\n        modules (list of str): A list of pathnames, pointing to the redis\n            module(s) that will be loaded in this redis server.\n        port (int): If provided, start a Redis server with this port.\n        redis_max_clients: If this is provided, Ray will attempt to configure\n            Redis with this maxclients number.\n        num_retries (int): The number of times to attempt to start Redis. If a\n            port is provided, this defaults to 1.\n        stdout_file: A file handle opened for writing to redirect stdout to. If\n            no redirection should happen, then this should be None.\n        stderr_file: A file handle opened for writing to redirect stderr to. If\n            no redirection should happen, then this should be None.\n        password (str): Prevents external clients without the password\n            from connecting to Redis if provided.\n        redis_max_memory: The max amount of memory (in bytes) to allow redis\n            to use, or None for no limit. Once the limit is exceeded, redis\n            will start LRU eviction of entries.\n\n    Returns:\n        A tuple of the port used by Redis and ProcessInfo for the process that\n            was started. If a port is passed in, then the returned port value\n            is the same.\n\n    Raises:\n        Exception: An exception is raised if Redis could not be started.\n    \"\"\"\n    assert os.path.isfile(executable)\n    for module in modules:\n        assert os.path.isfile(module)\n    counter = 0\n    if port is not None:\n        # If a port is specified, then try only once to connect.\n        # This ensures that we will use the given port.\n        num_retries = 1\n    else:\n        port = ray_constants.DEFAULT_PORT\n\n    load_module_args = []\n    for module in modules:\n        load_module_args += [\"--loadmodule\", module]\n\n    while counter < num_retries:\n        # Construct the command to start the Redis server.\n        command = [executable]\n        if password:\n            if \" \" in password:\n                raise ValueError(\"Spaces not permitted in redis password.\")\n            command += [\"--requirepass\", password]\n        command += (\n            [\"--port\", str(port), \"--loglevel\", \"warning\"] + load_module_args)\n        process_info = start_ray_process(\n            command,\n            ray_constants.PROCESS_TYPE_REDIS_SERVER,\n            stdout_file=stdout_file,\n            stderr_file=stderr_file,\n            fate_share=fate_share)\n        time.sleep(0.1)\n        # Check if Redis successfully started (or at least if it the executable\n        # did not exit within 0.1 seconds).\n        if process_info.process.poll() is None:\n            break\n        port = new_port()\n        counter += 1\n    if counter == num_retries:\n        raise RuntimeError(\"Couldn't start Redis. \"\n                           \"Check log files: {} {}\".format(\n                               stdout_file.name if stdout_file is not None else\n                               \"<stdout>\", stderr_file.name\n                               if stdout_file is not None else \"<stderr>\"))\n\n    # Create a Redis client just for configuring Redis.\n    redis_client = redis.StrictRedis(\n        host=\"127.0.0.1\", port=port, password=password)\n    # Wait for the Redis server to start.\n    wait_for_redis_to_start(\"127.0.0.1\", port, password=password)\n    # Configure Redis to generate keyspace notifications. TODO(rkn): Change\n    # this to only generate notifications for the export keys.\n    redis_client.config_set(\"notify-keyspace-events\", \"Kl\")\n\n    # Configure Redis to not run in protected mode so that processes on other\n    # hosts can connect to it. TODO(rkn): Do this in a more secure way.\n    redis_client.config_set(\"protected-mode\", \"no\")\n\n    # Discard old task and object metadata.\n    if redis_max_memory is not None:\n        redis_client.config_set(\"maxmemory\", str(redis_max_memory))\n        redis_client.config_set(\"maxmemory-policy\", \"allkeys-lru\")\n        redis_client.config_set(\"maxmemory-samples\", \"10\")\n        logger.debug(\"Starting Redis shard with {} GB max memory.\".format(\n            round(redis_max_memory / 1e9, 2)))\n\n    # If redis_max_clients is provided, attempt to raise the number of maximum\n    # number of Redis clients.\n    if redis_max_clients is not None:\n        redis_client.config_set(\"maxclients\", str(redis_max_clients))\n    elif resource is not None:\n        # If redis_max_clients is not provided, determine the current ulimit.\n        # We will use this to attempt to raise the maximum number of Redis\n        # clients.\n        current_max_clients = int(\n            redis_client.config_get(\"maxclients\")[\"maxclients\"])\n        # The below command should be the same as doing ulimit -n.\n        ulimit_n = resource.getrlimit(resource.RLIMIT_NOFILE)[0]\n        # The quantity redis_client_buffer appears to be the required buffer\n        # between the maximum number of redis clients and ulimit -n. That is,\n        # if ulimit -n returns 10000, then we can set maxclients to\n        # 10000 - redis_client_buffer.\n        redis_client_buffer = 32\n        if current_max_clients < ulimit_n - redis_client_buffer:\n            redis_client.config_set(\"maxclients\",\n                                    ulimit_n - redis_client_buffer)\n\n    # Increase the hard and soft limits for the redis client pubsub buffer to\n    # 128MB. This is a hack to make it less likely for pubsub messages to be\n    # dropped and for pubsub connections to therefore be killed.\n    cur_config = (redis_client.config_get(\"client-output-buffer-limit\")[\n        \"client-output-buffer-limit\"])\n    cur_config_list = cur_config.split()\n    assert len(cur_config_list) == 12\n    cur_config_list[8:] = [\"pubsub\", \"134217728\", \"134217728\", \"60\"]\n    redis_client.config_set(\"client-output-buffer-limit\",\n                            \" \".join(cur_config_list))\n    # Put a time stamp in Redis to indicate when it was started.\n    redis_client.set(\"redis_start_time\", time.time())\n    return port, process_info\n\n\ndef start_log_monitor(redis_address,\n                      logs_dir,\n                      stdout_file=None,\n                      stderr_file=None,\n                      redis_password=None,\n                      fate_share=None):\n    \"\"\"Start a log monitor process.\n\n    Args:\n        redis_address (str): The address of the Redis instance.\n        logs_dir (str): The directory of logging files.\n        stdout_file: A file handle opened for writing to redirect stdout to. If\n            no redirection should happen, then this should be None.\n        stderr_file: A file handle opened for writing to redirect stderr to. If\n            no redirection should happen, then this should be None.\n        redis_password (str): The password of the redis server.\n\n    Returns:\n        ProcessInfo for the process that was started.\n    \"\"\"\n    log_monitor_filepath = os.path.join(\n        os.path.dirname(os.path.abspath(__file__)), \"log_monitor.py\")\n    command = [\n        sys.executable,\n        \"-u\",\n        log_monitor_filepath,\n        \"--redis-address={}\".format(redis_address),\n        \"--logs-dir={}\".format(logs_dir),\n    ]\n    if redis_password:\n        command += [\"--redis-password\", redis_password]\n    process_info = start_ray_process(\n        command,\n        ray_constants.PROCESS_TYPE_LOG_MONITOR,\n        stdout_file=stdout_file,\n        stderr_file=stderr_file,\n        fate_share=fate_share)\n    return process_info\n\n\ndef start_reporter(redis_address,\n                   port,\n                   stdout_file=None,\n                   stderr_file=None,\n                   redis_password=None,\n                   fate_share=None):\n    \"\"\"Start a reporter process.\n\n    Args:\n        redis_address (str): The address of the Redis instance.\n        port(int): The port to bind the reporter process.\n        stdout_file: A file handle opened for writing to redirect stdout to. If\n            no redirection should happen, then this should be None.\n        stderr_file: A file handle opened for writing to redirect stderr to. If\n            no redirection should happen, then this should be None.\n        redis_password (str): The password of the redis server.\n\n    Returns:\n        ProcessInfo for the process that was started.\n    \"\"\"\n    reporter_filepath = os.path.join(\n        os.path.dirname(os.path.abspath(__file__)), \"reporter.py\")\n    command = [\n        sys.executable, \"-u\", reporter_filepath,\n        \"--redis-address={}\".format(redis_address), \"--port={}\".format(port)\n    ]\n    if redis_password:\n        command += [\"--redis-password\", redis_password]\n\n    process_info = start_ray_process(\n        command,\n        ray_constants.PROCESS_TYPE_REPORTER,\n        stdout_file=stdout_file,\n        stderr_file=stderr_file,\n        fate_share=fate_share)\n    return process_info\n\n\ndef start_dashboard(require_dashboard,\n                    host,\n                    redis_address,\n                    temp_dir,\n                    port=ray_constants.DEFAULT_DASHBOARD_PORT,\n                    stdout_file=None,\n                    stderr_file=None,\n                    redis_password=None,\n                    fate_share=None):\n    \"\"\"Start a dashboard process.\n\n    Args:\n        require_dashboard (bool): If true, this will raise an exception if we\n            fail to start the dashboard. Otherwise it will print a warning if\n            we fail to start the dashboard.\n        host (str): The host to bind the dashboard web server to.\n        port (str): The port to bind the dashboard web server to.\n            Defaults to 8265.\n        redis_address (str): The address of the Redis instance.\n        temp_dir (str): The temporary directory used for log files and\n            information for this Ray session.\n        stdout_file: A file handle opened for writing to redirect stdout to. If\n            no redirection should happen, then this should be None.\n        stderr_file: A file handle opened for writing to redirect stderr to. If\n            no redirection should happen, then this should be None.\n        redis_password (str): The password of the redis server.\n\n    Returns:\n        ProcessInfo for the process that was started.\n    \"\"\"\n    if port == ray_constants.DEFAULT_DASHBOARD_PORT:\n        while True:\n            try:\n                port_test_socket = socket.socket()\n                port_test_socket.bind((\"127.0.0.1\", port))\n                port_test_socket.close()\n                break\n            except socket.error:\n                port += 1\n    else:\n        try:\n            port_test_socket = socket.socket()\n            port_test_socket.bind((\"127.0.0.1\", port))\n            port_test_socket.close()\n        except socket.error:\n            raise ValueError(\"The given dashboard port {}\"\n                             \" is already in use\".format(port))\n\n    dashboard_filepath = os.path.join(\n        os.path.dirname(os.path.abspath(__file__)), \"dashboard/dashboard.py\")\n    command = [\n        sys.executable,\n        \"-u\",\n        dashboard_filepath,\n        \"--host={}\".format(host),\n        \"--port={}\".format(port),\n        \"--redis-address={}\".format(redis_address),\n        \"--temp-dir={}\".format(temp_dir),\n    ]\n    if redis_password:\n        command += [\"--redis-password\", redis_password]\n\n    webui_dependencies_present = True\n    try:\n        import aiohttp  # noqa: F401\n        import grpc  # noqa: F401\n    except ImportError:\n        webui_dependencies_present = False\n        warning_message = (\n            \"Failed to start the dashboard. The dashboard requires Python 3 \"\n            \"as well as 'pip install aiohttp grpcio'.\")\n        if require_dashboard:\n            raise ImportError(warning_message)\n        else:\n            logger.warning(warning_message)\n\n    if webui_dependencies_present:\n        process_info = start_ray_process(\n            command,\n            ray_constants.PROCESS_TYPE_DASHBOARD,\n            stdout_file=stdout_file,\n            stderr_file=stderr_file,\n            fate_share=fate_share)\n\n        dashboard_url = \"{}:{}\".format(\n            host if host != \"0.0.0.0\" else get_node_ip_address(), port)\n        logger.info(\"View the Ray dashboard at {}{}{}{}{}\".format(\n            colorama.Style.BRIGHT, colorama.Fore.GREEN, dashboard_url,\n            colorama.Fore.RESET, colorama.Style.NORMAL))\n\n        return dashboard_url, process_info\n    else:\n        return None, None\n\n\ndef start_gcs_server(redis_address,\n                     stdout_file=None,\n                     stderr_file=None,\n                     redis_password=None,\n                     config=None,\n                     fate_share=None,\n                     gcs_server_port=None,\n                     metrics_agent_port=None):\n    \"\"\"Start a gcs server.\n    Args:\n        redis_address (str): The address that the Redis server is listening on.\n        stdout_file: A file handle opened for writing to redirect stdout to. If\n            no redirection should happen, then this should be None.\n        stderr_file: A file handle opened for writing to redirect stderr to. If\n            no redirection should happen, then this should be None.\n        redis_password (str): The password of the redis server.\n        config (dict|None): Optional configuration that will\n            override defaults in RayConfig.\n        gcs_server_port (int): Port number of the gcs server.\n        metrics_agent_port(int): The port where metrics agent is bound to.\n    Returns:\n        ProcessInfo for the process that was started.\n    \"\"\"\n    gcs_ip_address, gcs_port = redis_address.split(\":\")\n    redis_password = redis_password or \"\"\n    config_str = \",\".join([\"{},{}\".format(*kv) for kv in config.items()])\n    if gcs_server_port is None:\n        gcs_server_port = 0\n\n    command = [\n        GCS_SERVER_EXECUTABLE,\n        \"--redis_address={}\".format(gcs_ip_address),\n        \"--redis_port={}\".format(gcs_port),\n        \"--config_list={}\".format(config_str),\n        \"--gcs_server_port={}\".format(gcs_server_port),\n        \"--metrics-agent-port={}\".format(metrics_agent_port),\n    ]\n    if redis_password:\n        command += [\"--redis_password={}\".format(redis_password)]\n    process_info = start_ray_process(\n        command,\n        ray_constants.PROCESS_TYPE_GCS_SERVER,\n        stdout_file=stdout_file,\n        stderr_file=stderr_file,\n        fate_share=fate_share)\n    return process_info\n\n\ndef start_raylet(redis_address,\n                 node_ip_address,\n                 node_manager_port,\n                 raylet_name,\n                 plasma_store_name,\n                 worker_path,\n                 temp_dir,\n                 session_dir,\n                 resource_spec,\n                 min_worker_port=None,\n                 max_worker_port=None,\n                 object_manager_port=None,\n                 redis_password=None,\n                 metrics_agent_port=None,\n                 use_valgrind=False,\n                 use_profiler=False,\n                 stdout_file=None,\n                 stderr_file=None,\n                 config=None,\n                 include_java=False,\n                 java_worker_options=None,\n                 load_code_from_local=False,\n                 plasma_directory=None,\n                 huge_pages=False,\n                 fate_share=None,\n                 socket_to_use=None,\n                 head_node=False):\n    \"\"\"Start a raylet, which is a combined local scheduler and object manager.\n\n    Args:\n        redis_address (str): The address of the primary Redis server.\n        node_ip_address (str): The IP address of this node.\n        node_manager_port(int): The port to use for the node manager. This must\n            not be 0.\n        raylet_name (str): The name of the raylet socket to create.\n        plasma_store_name (str): The name of the plasma store socket to connect\n             to.\n        worker_path (str): The path of the Python file that new worker\n            processes will execute.\n        temp_dir (str): The path of the temporary directory Ray will use.\n        session_dir (str): The path of this session.\n        resource_spec (ResourceSpec): Resources for this raylet.\n        object_manager_port: The port to use for the object manager. If this is\n            None, then the object manager will choose its own port.\n        min_worker_port (int): The lowest port number that workers will bind\n            on. If not set, random ports will be chosen.\n        max_worker_port (int): The highest port number that workers will bind\n            on. If set, min_worker_port must also be set.\n        redis_password: The password to use when connecting to Redis.\n        metrics_agent_port(int): The port where metrics agent is bound to.\n        use_valgrind (bool): True if the raylet should be started inside\n            of valgrind. If this is True, use_profiler must be False.\n        use_profiler (bool): True if the raylet should be started inside\n            a profiler. If this is True, use_valgrind must be False.\n        stdout_file: A file handle opened for writing to redirect stdout to. If\n            no redirection should happen, then this should be None.\n        stderr_file: A file handle opened for writing to redirect stderr to. If\n            no redirection should happen, then this should be None.\n        config (dict|None): Optional Raylet configuration that will\n            override defaults in RayConfig.\n        include_java (bool): If True, the raylet backend can also support\n            Java worker.\n        java_worker_options (list): The command options for Java worker.\n    Returns:\n        ProcessInfo for the process that was started.\n    \"\"\"\n    # The caller must provide a node manager port so that we can correctly\n    # populate the command to start a worker.\n    assert node_manager_port is not None and node_manager_port != 0\n    config_str = \",\".join([\"{},{}\".format(*kv) for kv in config.items()])\n\n    if use_valgrind and use_profiler:\n        raise ValueError(\"Cannot use valgrind and profiler at the same time.\")\n\n    assert resource_spec.resolved()\n    num_initial_workers = resource_spec.num_cpus\n    static_resources = resource_spec.to_resource_dict()\n\n    # Limit the number of workers that can be started in parallel by the\n    # raylet. However, make sure it is at least 1.\n    num_cpus_static = static_resources.get(\"CPU\", 0)\n    maximum_startup_concurrency = max(\n        1, min(multiprocessing.cpu_count(), num_cpus_static))\n\n    # Format the resource argument in a form like 'CPU,1.0,GPU,0,Custom,3'.\n    resource_argument = \",\".join(\n        [\"{},{}\".format(*kv) for kv in static_resources.items()])\n\n    gcs_ip_address, gcs_port = redis_address.split(\":\")\n\n    if include_java is True:\n        default_cp = os.pathsep.join(DEFAULT_JAVA_WORKER_CLASSPATH)\n        java_worker_command = build_java_worker_command(\n            json.loads(java_worker_options)\n            if java_worker_options else [\"-classpath\", default_cp],\n            redis_address,\n            node_manager_port,\n            plasma_store_name,\n            raylet_name,\n            redis_password,\n            session_dir,\n        )\n    else:\n        java_worker_command = []\n\n    # Create the command that the Raylet will use to start workers.\n    start_worker_command = [\n        sys.executable,\n        worker_path,\n        \"--node-ip-address={}\".format(node_ip_address),\n        \"--node-manager-port={}\".format(node_manager_port),\n        \"--object-store-name={}\".format(plasma_store_name),\n        \"--raylet-name={}\".format(raylet_name),\n        \"--redis-address={}\".format(redis_address),\n        \"--config-list={}\".format(config_str),\n        \"--temp-dir={}\".format(temp_dir),\n    ]\n    if redis_password:\n        start_worker_command += [\"--redis-password={}\".format(redis_password)]\n\n    # If the object manager port is None, then use 0 to cause the object\n    # manager to choose its own port.\n    if object_manager_port is None:\n        object_manager_port = 0\n\n    if min_worker_port is None:\n        min_worker_port = 0\n\n    if max_worker_port is None:\n        max_worker_port = 0\n\n    if load_code_from_local:\n        start_worker_command += [\"--load-code-from-local\"]\n\n    command = [\n        RAYLET_EXECUTABLE,\n        \"--raylet_socket_name={}\".format(raylet_name),\n        \"--store_socket_name={}\".format(plasma_store_name),\n        \"--object_manager_port={}\".format(object_manager_port),\n        \"--min_worker_port={}\".format(min_worker_port),\n        \"--max_worker_port={}\".format(max_worker_port),\n        \"--node_manager_port={}\".format(node_manager_port),\n        \"--node_ip_address={}\".format(node_ip_address),\n        \"--redis_address={}\".format(gcs_ip_address),\n        \"--redis_port={}\".format(gcs_port),\n        \"--num_initial_workers={}\".format(num_initial_workers),\n        \"--maximum_startup_concurrency={}\".format(maximum_startup_concurrency),\n        \"--static_resource_list={}\".format(resource_argument),\n        \"--config_list={}\".format(config_str),\n        \"--python_worker_command={}\".format(\n            subprocess.list2cmdline(start_worker_command)),\n        \"--java_worker_command={}\".format(\n            subprocess.list2cmdline(java_worker_command)),\n        \"--redis_password={}\".format(redis_password or \"\"),\n        \"--temp_dir={}\".format(temp_dir),\n        \"--session_dir={}\".format(session_dir),\n        \"--metrics-agent-port={}\".format(metrics_agent_port),\n    ]\n    if config.get(\"plasma_store_as_thread\"):\n        # command related to the plasma store\n        plasma_directory, object_store_memory = determine_plasma_store_config(\n            resource_spec.object_store_memory, plasma_directory, huge_pages)\n        command += [\n            \"--object_store_memory={}\".format(object_store_memory),\n            \"--plasma_directory={}\".format(plasma_directory),\n        ]\n        if huge_pages:\n            command.append(\"--huge_pages\")\n    if socket_to_use:\n        socket_to_use.close()\n    if head_node:\n        command.append(\"--head_node\")\n    process_info = start_ray_process(\n        command,\n        ray_constants.PROCESS_TYPE_RAYLET,\n        use_valgrind=use_valgrind,\n        use_gdb=False,\n        use_valgrind_profiler=use_profiler,\n        use_perftools_profiler=(\"RAYLET_PERFTOOLS_PATH\" in os.environ),\n        stdout_file=stdout_file,\n        stderr_file=stderr_file,\n        fate_share=fate_share)\n\n    return process_info\n\n\ndef get_ray_jars_dir():\n    \"\"\"Return a directory where all ray-related jars and\n      their dependencies locate.\"\"\"\n    current_dir = os.path.abspath(os.path.dirname(__file__))\n    jars_dir = os.path.abspath(os.path.join(current_dir, \"jars\"))\n    if not os.path.exists(jars_dir):\n        raise RuntimeError(\"Ray jars is not packaged into ray. \"\n                           \"Please build ray with java enabled \"\n                           \"(set env var RAY_INSTALL_JAVA=1)\")\n    return os.path.abspath(os.path.join(current_dir, \"jars\"))\n\n\ndef build_java_worker_command(\n        java_worker_options,\n        redis_address,\n        node_manager_port,\n        plasma_store_name,\n        raylet_name,\n        redis_password,\n        session_dir,\n):\n    \"\"\"This method assembles the command used to start a Java worker.\n\n    Args:\n        java_worker_options (list): The command options for Java worker.\n        redis_address (str): Redis address of GCS.\n        plasma_store_name (str): The name of the plasma store socket to connect\n           to.\n        raylet_name (str): The name of the raylet socket to create.\n        redis_password (str): The password of connect to redis.\n        session_dir (str): The path of this session.\n    Returns:\n        The command string for starting Java worker.\n    \"\"\"\n    pairs = []\n    if redis_address is not None:\n        pairs.append((\"ray.redis.address\", redis_address))\n    pairs.append((\"ray.raylet.node-manager-port\", node_manager_port))\n\n    if plasma_store_name is not None:\n        pairs.append((\"ray.object-store.socket-name\", plasma_store_name))\n\n    if raylet_name is not None:\n        pairs.append((\"ray.raylet.socket-name\", raylet_name))\n\n    if redis_password is not None:\n        pairs.append((\"ray.redis.password\", redis_password))\n\n    pairs.append((\"ray.home\", RAY_HOME))\n    pairs.append((\"ray.logging.dir\", os.path.join(session_dir, \"logs\")))\n    pairs.append((\"ray.session-dir\", session_dir))\n\n    command = [\"java\"] + [\"-D{}={}\".format(*pair) for pair in pairs]\n\n    command += [\"RAY_WORKER_RAYLET_CONFIG_PLACEHOLDER\"]\n\n    # Add ray jars path to java classpath\n    ray_jars = os.path.join(get_ray_jars_dir(), \"*\")\n    if java_worker_options is None:\n        options = []\n    else:\n        assert isinstance(java_worker_options, (tuple, list))\n        options = list(java_worker_options)\n    cp_index = -1\n    for i in range(len(options)):\n        option = options[i]\n        if option == \"-cp\" or option == \"-classpath\":\n            cp_index = i + 1\n            break\n    if cp_index != -1:\n        options[cp_index] = options[cp_index] + os.pathsep + ray_jars\n    else:\n        options = [\"-cp\", ray_jars] + options\n    # Put `java_worker_options` in the last, so it can overwrite the\n    # above options.\n    command += options\n\n    command += [\"RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER_0\"]\n    command += [\"io.ray.runtime.runner.worker.DefaultWorker\"]\n\n    return command\n\n\ndef determine_plasma_store_config(object_store_memory,\n                                  plasma_directory=None,\n                                  huge_pages=False):\n    \"\"\"Figure out how to configure the plasma object store.\n\n    This will determine which directory to use for the plasma store. On Linux,\n    we will try to use /dev/shm unless the shared memory file system is too\n    small, in which case we will fall back to /tmp. If any of the object store\n    memory or plasma directory parameters are specified by the user, then those\n    values will be preserved.\n\n    Args:\n        object_store_memory (int): The objec store memory to use.\n        plasma_directory (str): The user-specified plasma directory parameter.\n        huge_pages (bool): The user-specified huge pages parameter.\n\n    Returns:\n        The plasma directory to use. If it is specified by the user, then that\n            value will be preserved.\n    \"\"\"\n    if not isinstance(object_store_memory, int):\n        object_store_memory = int(object_store_memory)\n\n    if huge_pages and not (sys.platform == \"linux\"\n                           or sys.platform == \"linux2\"):\n        raise ValueError(\"The huge_pages argument is only supported on \"\n                         \"Linux.\")\n\n    system_memory = ray.utils.get_system_memory()\n\n    # Determine which directory to use. By default, use /tmp on MacOS and\n    # /dev/shm on Linux, unless the shared-memory file system is too small,\n    # in which case we default to /tmp on Linux.\n    if plasma_directory is None:\n        if sys.platform == \"linux\" or sys.platform == \"linux2\":\n            shm_avail = ray.utils.get_shared_memory_bytes()\n            # Compare the requested memory size to the memory available in\n            # /dev/shm.\n            if shm_avail > object_store_memory:\n                plasma_directory = \"/dev/shm\"\n            else:\n                plasma_directory = ray.utils.get_user_temp_dir()\n                logger.warning(\n                    \"WARNING: The object store is using {} instead of \"\n                    \"/dev/shm because /dev/shm has only {} bytes available. \"\n                    \"This may slow down performance! You may be able to free \"\n                    \"up space by deleting files in /dev/shm or terminating \"\n                    \"any running plasma_store_server processes. If you are \"\n                    \"inside a Docker container, you may need to pass an \"\n                    \"argument with the flag '--shm-size' to 'docker run'.\".\n                    format(ray.utils.get_user_temp_dir(), shm_avail))\n        else:\n            plasma_directory = ray.utils.get_user_temp_dir()\n\n        # Do some sanity checks.\n        if object_store_memory > system_memory:\n            raise ValueError(\n                \"The requested object store memory size is greater \"\n                \"than the total available memory.\")\n    else:\n        plasma_directory = os.path.abspath(plasma_directory)\n        logger.warning(\"WARNING: object_store_memory is not verified when \"\n                       \"plasma_directory is set.\")\n\n    if not os.path.isdir(plasma_directory):\n        raise ValueError(\n            \"The file {} does not exist or is not a directory.\".format(\n                plasma_directory))\n\n    if huge_pages and plasma_directory is None:\n        raise ValueError(\"If huge_pages is True, then the \"\n                         \"plasma_directory argument must be provided.\")\n\n    if object_store_memory < ray_constants.OBJECT_STORE_MINIMUM_MEMORY_BYTES:\n        raise ValueError(\"Attempting to cap object store memory usage at {} \"\n                         \"bytes, but the minimum allowed is {} bytes.\".format(\n                             object_store_memory,\n                             ray_constants.OBJECT_STORE_MINIMUM_MEMORY_BYTES))\n\n    # Print the object store memory using two decimal places.\n    logger.debug(\n        \"Determine to start the Plasma object store with {} GB memory \"\n        \"using {}.\".format(\n            round(object_store_memory / 10**9, 2), plasma_directory))\n\n    return plasma_directory, object_store_memory\n\n\ndef start_plasma_store(resource_spec,\n                       plasma_store_socket_name,\n                       stdout_file=None,\n                       stderr_file=None,\n                       plasma_directory=None,\n                       keep_idle=False,\n                       huge_pages=False,\n                       fate_share=None,\n                       use_valgrind=False):\n    \"\"\"This method starts an object store process.\n\n    Args:\n        resource_spec (ResourceSpec): Resources for the node.\n        plasma_store_socket_name (str): The path/name of the plasma\n            store socket.\n        stdout_file: A file handle opened for writing to redirect stdout\n            to. If no redirection should happen, then this should be None.\n        stderr_file: A file handle opened for writing to redirect stderr\n            to. If no redirection should happen, then this should be None.\n        plasma_directory: A directory where the Plasma memory mapped files will\n            be created.\n        huge_pages: Boolean flag indicating whether to start the Object\n            Store with hugetlbfs support. Requires plasma_directory.\n        keep_idle: If True, run the plasma store as an idle placeholder.\n\n    Returns:\n        ProcessInfo for the process that was started.\n    \"\"\"\n    # Start the Plasma store.\n    if use_valgrind and RUN_PLASMA_STORE_PROFILER:\n        raise ValueError(\"Cannot use valgrind and profiler at the same time.\")\n\n    assert resource_spec.resolved()\n    plasma_directory, object_store_memory = determine_plasma_store_config(\n        resource_spec.object_store_memory, plasma_directory, huge_pages)\n\n    command = [\n        PLASMA_STORE_EXECUTABLE,\n        \"-s\",\n        plasma_store_socket_name,\n        \"-m\",\n        str(object_store_memory),\n    ]\n    if plasma_directory is not None:\n        command += [\"-d\", plasma_directory]\n    if huge_pages:\n        command += [\"-h\"]\n    if keep_idle:\n        command.append(\"-z\")\n    process_info = start_ray_process(\n        command,\n        ray_constants.PROCESS_TYPE_PLASMA_STORE,\n        use_valgrind=use_valgrind,\n        use_valgrind_profiler=RUN_PLASMA_STORE_PROFILER,\n        stdout_file=stdout_file,\n        stderr_file=stderr_file,\n        fate_share=fate_share)\n    return process_info\n\n\ndef start_worker(node_ip_address,\n                 object_store_name,\n                 raylet_name,\n                 redis_address,\n                 worker_path,\n                 temp_dir,\n                 raylet_ip_address=None,\n                 stdout_file=None,\n                 stderr_file=None,\n                 fate_share=None):\n    \"\"\"This method starts a worker process.\n\n    Args:\n        node_ip_address (str): The IP address of the node that this worker is\n            running on.\n        object_store_name (str): The socket name of the object store.\n        raylet_name (str): The socket name of the raylet server.\n        redis_address (str): The address that the Redis server is listening on.\n        worker_path (str): The path of the source code which the worker process\n            will run.\n        temp_dir (str): The path of the temp dir.\n        raylet_ip_address (str): The IP address of the worker's raylet. If not\n            provided, it defaults to the node_ip_address.\n        stdout_file: A file handle opened for writing to redirect stdout to. If\n            no redirection should happen, then this should be None.\n        stderr_file: A file handle opened for writing to redirect stderr to. If\n            no redirection should happen, then this should be None.\n\n    Returns:\n        ProcessInfo for the process that was started.\n    \"\"\"\n    command = [\n        sys.executable,\n        \"-u\",\n        worker_path,\n        \"--node-ip-address=\" + node_ip_address,\n        \"--object-store-name=\" + object_store_name,\n        \"--raylet-name=\" + raylet_name,\n        \"--redis-address=\" + str(redis_address),\n        \"--temp-dir=\" + temp_dir,\n    ]\n    if raylet_ip_address is not None:\n        command.append(\"--raylet-ip-address=\" + raylet_ip_address)\n    process_info = start_ray_process(\n        command,\n        ray_constants.PROCESS_TYPE_WORKER,\n        stdout_file=stdout_file,\n        stderr_file=stderr_file,\n        fate_share=fate_share)\n    return process_info\n\n\ndef start_monitor(redis_address,\n                  stdout_file=None,\n                  stderr_file=None,\n                  autoscaling_config=None,\n                  redis_password=None,\n                  fate_share=None):\n    \"\"\"Run a process to monitor the other processes.\n\n    Args:\n        redis_address (str): The address that the Redis server is listening on.\n        stdout_file: A file handle opened for writing to redirect stdout to. If\n            no redirection should happen, then this should be None.\n        stderr_file: A file handle opened for writing to redirect stderr to. If\n            no redirection should happen, then this should be None.\n        autoscaling_config: path to autoscaling config file.\n        redis_password (str): The password of the redis server.\n\n    Returns:\n        ProcessInfo for the process that was started.\n    \"\"\"\n    monitor_path = os.path.join(\n        os.path.dirname(os.path.abspath(__file__)), \"monitor.py\")\n    command = [\n        sys.executable,\n        \"-u\",\n        monitor_path,\n        \"--redis-address=\" + str(redis_address),\n    ]\n    if autoscaling_config:\n        command.append(\"--autoscaling-config=\" + str(autoscaling_config))\n    if redis_password:\n        command.append(\"--redis-password=\" + redis_password)\n    process_info = start_ray_process(\n        command,\n        ray_constants.PROCESS_TYPE_MONITOR,\n        stdout_file=stdout_file,\n        stderr_file=stderr_file,\n        fate_share=fate_share)\n    return process_info\n"
    },
    "skipped": [
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/rllib/tests/data/model_weights/weights.h5",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/rllib/contrib/alpha_zero/doc/cartpole_plot.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/python/ray/dashboard/client/public/favicon.ico",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/python/ray/dashboard/client/public/speedscope-1.5.3/favicon-32x32.1165a94e.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/python/ray/dashboard/client/public/speedscope-1.5.3/favicon-16x16.361d2b26.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/python/ray/util/sgd/torch/examples/mnist_cnn.pt",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/python/ray/util/sgd/torch/examples/benchmarks/raysgd_multigpu_benchmark.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/python/ray/util/sgd/torch/examples/benchmarks/raysgd_multinode_benchmark.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/python/ray/tune/examples/pbt_transformers/test_data/rte.zip",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/python/ray/tune/examples/pbt_dcgan_mnist/mnist_cnn.pt",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/timeline.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/pbt.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/sgd.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/impala.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/throughput.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/apex.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/pytorch.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/ppo.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/ray-tune-parcoords.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/struct-tensor.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/es.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/ray-tune-viskit.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/ray-tune-tensorboard.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/tensorflow.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/custom_metric.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/rock-paper-scissors.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/offline-q.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/images/pytorch_logo.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/images/tune-arch.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/images/hyperband_eta.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/images/tune_advanced_paper1.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/images/tune_advanced_plot1.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/images/ray_logo.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/images/hyperband_allocation.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/images/pytorch_lightning_full.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/images/tune-upload.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/images/param_actor.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/images/tune-start-tb.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/images/yarn-job.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/images/pytorch_lightning_small.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/images/rllib-stack.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/images/rllib-training-inside-a-unity3d-env.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/images/hyperband_bracket.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/images/rllib-wide.jpg",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/images/tune-hparams-coord.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/images/ray_header_logo.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/images/tune-workflow.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/images/a3c.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/images/wandb_logo.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/images/tune-df-plot.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/images/tune-hparams.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/images/tune.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/images/autoscaler-status.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/images/wandb_logo_full.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/images/tune-pbt-small.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/images/tune-sklearn.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/images/xgboost_logo.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/images/hyperparameter.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/images/tune_advanced_dcgan_inscore.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/images/tune_advanced_dcgan_Gloss.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/images/tune-wide.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/images/pong.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/raysgd/raysgdlogo.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/raysgd/raysgd-custom.jpg",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/source/_static/img/thumbnails/default.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/site/assets/ray_0.2_release/timeline_visualization.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/site/assets/announcing_ray/graph1.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/site/assets/announcing_ray/graph2.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/site/assets/announcing_ray/graph3.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/site/assets/fast_python_serialization_with_ray_and_arrow/speedups0.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/site/assets/fast_python_serialization_with_ray_and_arrow/speedups3.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/site/assets/fast_python_serialization_with_ray_and_arrow/arrow_object.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/site/assets/fast_python_serialization_with_ray_and_arrow/speedups2.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/site/assets/fast_python_serialization_with_ray_and_arrow/speedups1.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/doc/site/assets/fast_python_serialization_with_ray_and_arrow/python_object.png",
        "/tmp/vanessa/spack-stage/spack-stage-py-ray-0.8.7-zmo7oz2ayx56egx42aui2netf6ht55yw/spack-src/ci/travis/bazel_cache_credential.json.enc"
    ],
    "total_files": 2662
}